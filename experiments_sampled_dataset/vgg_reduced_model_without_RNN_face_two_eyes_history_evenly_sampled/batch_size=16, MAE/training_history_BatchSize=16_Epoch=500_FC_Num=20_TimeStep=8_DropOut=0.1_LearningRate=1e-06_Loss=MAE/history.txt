Epoch: 1| Step: 0
Training loss: 5.287303924560547
Validation loss: 4.826393629914971

Epoch: 6| Step: 1
Training loss: 5.311568260192871
Validation loss: 4.82060517034223

Epoch: 6| Step: 2
Training loss: 5.550907611846924
Validation loss: 4.8157509988354095

Epoch: 6| Step: 3
Training loss: 4.6996283531188965
Validation loss: 4.810512183814921

Epoch: 6| Step: 4
Training loss: 5.453791618347168
Validation loss: 4.80357297261556

Epoch: 6| Step: 5
Training loss: 4.18652868270874
Validation loss: 4.799566673976119

Epoch: 6| Step: 6
Training loss: 3.4544525146484375
Validation loss: 4.79412971004363

Epoch: 6| Step: 7
Training loss: 3.428914785385132
Validation loss: 4.787172917396791

Epoch: 6| Step: 8
Training loss: 3.177093267440796
Validation loss: 4.7834697641352175

Epoch: 6| Step: 9
Training loss: 5.0285420417785645
Validation loss: 4.777525189102337

Epoch: 6| Step: 10
Training loss: 4.874859809875488
Validation loss: 4.772485825323289

Epoch: 6| Step: 11
Training loss: 4.470328330993652
Validation loss: 4.767689715149582

Epoch: 6| Step: 12
Training loss: 4.657218933105469
Validation loss: 4.761164624203918

Epoch: 6| Step: 13
Training loss: 4.66524600982666
Validation loss: 4.755120492750598

Epoch: 2| Step: 0
Training loss: 5.292402267456055
Validation loss: 4.753122206657164

Epoch: 6| Step: 1
Training loss: 5.141275405883789
Validation loss: 4.746494308594735

Epoch: 6| Step: 2
Training loss: 4.461582660675049
Validation loss: 4.741314165053829

Epoch: 6| Step: 3
Training loss: 3.644737958908081
Validation loss: 4.738369018800797

Epoch: 6| Step: 4
Training loss: 4.396286964416504
Validation loss: 4.731587797082881

Epoch: 6| Step: 5
Training loss: 4.032265663146973
Validation loss: 4.7260088869320445

Epoch: 6| Step: 6
Training loss: 4.0076189041137695
Validation loss: 4.722568958036361

Epoch: 6| Step: 7
Training loss: 2.7481231689453125
Validation loss: 4.715959031094787

Epoch: 6| Step: 8
Training loss: 5.641849517822266
Validation loss: 4.710734449407106

Epoch: 6| Step: 9
Training loss: 5.488278388977051
Validation loss: 4.706076909137028

Epoch: 6| Step: 10
Training loss: 5.319578170776367
Validation loss: 4.7009910562986965

Epoch: 6| Step: 11
Training loss: 5.024198532104492
Validation loss: 4.697330515871766

Epoch: 6| Step: 12
Training loss: 3.3145227432250977
Validation loss: 4.691519270661057

Epoch: 6| Step: 13
Training loss: 4.75709867477417
Validation loss: 4.686750991370088

Epoch: 3| Step: 0
Training loss: 6.427879333496094
Validation loss: 4.683375250908636

Epoch: 6| Step: 1
Training loss: 4.70896053314209
Validation loss: 4.676930327569285

Epoch: 6| Step: 2
Training loss: 6.087716102600098
Validation loss: 4.672426023790913

Epoch: 6| Step: 3
Training loss: 3.7400388717651367
Validation loss: 4.664633904733965

Epoch: 6| Step: 4
Training loss: 4.049323558807373
Validation loss: 4.662549905879523

Epoch: 6| Step: 5
Training loss: 4.028096675872803
Validation loss: 4.655330083703482

Epoch: 6| Step: 6
Training loss: 5.289824485778809
Validation loss: 4.6524938562864895

Epoch: 6| Step: 7
Training loss: 4.063928604125977
Validation loss: 4.644805251911122

Epoch: 6| Step: 8
Training loss: 3.9933764934539795
Validation loss: 4.639840305492442

Epoch: 6| Step: 9
Training loss: 4.499598503112793
Validation loss: 4.63368397374307

Epoch: 6| Step: 10
Training loss: 3.6912479400634766
Validation loss: 4.6313347816467285

Epoch: 6| Step: 11
Training loss: 3.339355230331421
Validation loss: 4.625916768145817

Epoch: 6| Step: 12
Training loss: 4.764820098876953
Validation loss: 4.621001940901562

Epoch: 6| Step: 13
Training loss: 2.799859046936035
Validation loss: 4.61402464425692

Epoch: 4| Step: 0
Training loss: 5.631348133087158
Validation loss: 4.609586305515741

Epoch: 6| Step: 1
Training loss: 3.9628798961639404
Validation loss: 4.604641873349426

Epoch: 6| Step: 2
Training loss: 3.755293130874634
Validation loss: 4.5992180814025225

Epoch: 6| Step: 3
Training loss: 3.1595239639282227
Validation loss: 4.59291107936572

Epoch: 6| Step: 4
Training loss: 4.202908515930176
Validation loss: 4.587879401381298

Epoch: 6| Step: 5
Training loss: 4.165686130523682
Validation loss: 4.584281347131216

Epoch: 6| Step: 6
Training loss: 4.4473676681518555
Validation loss: 4.575945864441574

Epoch: 6| Step: 7
Training loss: 4.2031660079956055
Validation loss: 4.571851473982616

Epoch: 6| Step: 8
Training loss: 5.24615478515625
Validation loss: 4.567495417851274

Epoch: 6| Step: 9
Training loss: 3.9653992652893066
Validation loss: 4.561720750665152

Epoch: 6| Step: 10
Training loss: 4.8821916580200195
Validation loss: 4.554079230113696

Epoch: 6| Step: 11
Training loss: 4.841042995452881
Validation loss: 4.550562248435072

Epoch: 6| Step: 12
Training loss: 3.934964895248413
Validation loss: 4.543555805760045

Epoch: 6| Step: 13
Training loss: 5.100568771362305
Validation loss: 4.539175700115901

Epoch: 5| Step: 0
Training loss: 4.034160137176514
Validation loss: 4.534645136966501

Epoch: 6| Step: 1
Training loss: 5.1695556640625
Validation loss: 4.527512555481286

Epoch: 6| Step: 2
Training loss: 3.4672932624816895
Validation loss: 4.521909513781147

Epoch: 6| Step: 3
Training loss: 4.155455112457275
Validation loss: 4.512507838587607

Epoch: 6| Step: 4
Training loss: 4.248353958129883
Validation loss: 4.507160432877079

Epoch: 6| Step: 5
Training loss: 4.218513011932373
Validation loss: 4.502852829553747

Epoch: 6| Step: 6
Training loss: 4.871534824371338
Validation loss: 4.497059804137035

Epoch: 6| Step: 7
Training loss: 3.224647045135498
Validation loss: 4.488876178700437

Epoch: 6| Step: 8
Training loss: 5.079963684082031
Validation loss: 4.483421146228749

Epoch: 6| Step: 9
Training loss: 4.1811089515686035
Validation loss: 4.477225201104277

Epoch: 6| Step: 10
Training loss: 4.557761192321777
Validation loss: 4.471032450276036

Epoch: 6| Step: 11
Training loss: 4.138789176940918
Validation loss: 4.464073678498627

Epoch: 6| Step: 12
Training loss: 4.4694318771362305
Validation loss: 4.459702248214393

Epoch: 6| Step: 13
Training loss: 4.225161075592041
Validation loss: 4.449344342754733

Epoch: 6| Step: 0
Training loss: 5.005602836608887
Validation loss: 4.445175724644815

Epoch: 6| Step: 1
Training loss: 4.565345287322998
Validation loss: 4.4353574578480055

Epoch: 6| Step: 2
Training loss: 3.9753432273864746
Validation loss: 4.428270232292913

Epoch: 6| Step: 3
Training loss: 4.124051570892334
Validation loss: 4.420715455086

Epoch: 6| Step: 4
Training loss: 3.6201345920562744
Validation loss: 4.414662689291021

Epoch: 6| Step: 5
Training loss: 4.048815727233887
Validation loss: 4.408815337765601

Epoch: 6| Step: 6
Training loss: 3.506377696990967
Validation loss: 4.39890597456245

Epoch: 6| Step: 7
Training loss: 4.113389492034912
Validation loss: 4.3949436526144705

Epoch: 6| Step: 8
Training loss: 3.700299024581909
Validation loss: 4.386798494605608

Epoch: 6| Step: 9
Training loss: 3.777653217315674
Validation loss: 4.378063381359142

Epoch: 6| Step: 10
Training loss: 4.601315498352051
Validation loss: 4.37189426729756

Epoch: 6| Step: 11
Training loss: 4.253927230834961
Validation loss: 4.363942418047177

Epoch: 6| Step: 12
Training loss: 4.721871376037598
Validation loss: 4.355295458147602

Epoch: 6| Step: 13
Training loss: 5.173314571380615
Validation loss: 4.346602414243964

Epoch: 7| Step: 0
Training loss: 3.565037250518799
Validation loss: 4.3399989733131985

Epoch: 6| Step: 1
Training loss: 3.9171998500823975
Validation loss: 4.332741311801377

Epoch: 6| Step: 2
Training loss: 4.6690802574157715
Validation loss: 4.320551528725573

Epoch: 6| Step: 3
Training loss: 6.228418350219727
Validation loss: 4.315796077892345

Epoch: 6| Step: 4
Training loss: 5.254006385803223
Validation loss: 4.307796375725859

Epoch: 6| Step: 5
Training loss: 4.125358581542969
Validation loss: 4.298204611706478

Epoch: 6| Step: 6
Training loss: 3.1417341232299805
Validation loss: 4.28857954086796

Epoch: 6| Step: 7
Training loss: 3.883680820465088
Validation loss: 4.2813674711412

Epoch: 6| Step: 8
Training loss: 4.043838977813721
Validation loss: 4.2724220316897155

Epoch: 6| Step: 9
Training loss: 3.597691297531128
Validation loss: 4.263718415332097

Epoch: 6| Step: 10
Training loss: 3.2094480991363525
Validation loss: 4.255109146077146

Epoch: 6| Step: 11
Training loss: 3.5337581634521484
Validation loss: 4.24696780532919

Epoch: 6| Step: 12
Training loss: 3.827871322631836
Validation loss: 4.2364384589656705

Epoch: 6| Step: 13
Training loss: 4.488718032836914
Validation loss: 4.227077386712515

Epoch: 8| Step: 0
Training loss: 4.508907318115234
Validation loss: 4.217336746954149

Epoch: 6| Step: 1
Training loss: 2.7313530445098877
Validation loss: 4.211969119246288

Epoch: 6| Step: 2
Training loss: 4.09279727935791
Validation loss: 4.201746104865946

Epoch: 6| Step: 3
Training loss: 3.9924259185791016
Validation loss: 4.190976496665709

Epoch: 6| Step: 4
Training loss: 2.9183645248413086
Validation loss: 4.18125271284452

Epoch: 6| Step: 5
Training loss: 5.115059852600098
Validation loss: 4.170837904817315

Epoch: 6| Step: 6
Training loss: 4.406946182250977
Validation loss: 4.164840416241717

Epoch: 6| Step: 7
Training loss: 4.184240818023682
Validation loss: 4.1555255074654855

Epoch: 6| Step: 8
Training loss: 4.705434799194336
Validation loss: 4.145154440274802

Epoch: 6| Step: 9
Training loss: 4.168148994445801
Validation loss: 4.138317190190797

Epoch: 6| Step: 10
Training loss: 3.778326988220215
Validation loss: 4.125048939899732

Epoch: 6| Step: 11
Training loss: 3.8722333908081055
Validation loss: 4.116533597310384

Epoch: 6| Step: 12
Training loss: 3.949713706970215
Validation loss: 4.105418464188935

Epoch: 6| Step: 13
Training loss: 2.687087297439575
Validation loss: 4.095460325159053

Epoch: 9| Step: 0
Training loss: 3.7093310356140137
Validation loss: 4.085709771802349

Epoch: 6| Step: 1
Training loss: 3.722614288330078
Validation loss: 4.075074242007348

Epoch: 6| Step: 2
Training loss: 4.550771713256836
Validation loss: 4.0639043674674085

Epoch: 6| Step: 3
Training loss: 4.806271553039551
Validation loss: 4.05830027211097

Epoch: 6| Step: 4
Training loss: 4.049141883850098
Validation loss: 4.045577115910028

Epoch: 6| Step: 5
Training loss: 3.1915128231048584
Validation loss: 4.033516022466844

Epoch: 6| Step: 6
Training loss: 4.641153335571289
Validation loss: 4.024165148376136

Epoch: 6| Step: 7
Training loss: 2.5407462120056152
Validation loss: 4.013950778592017

Epoch: 6| Step: 8
Training loss: 3.8024916648864746
Validation loss: 4.001497453258883

Epoch: 6| Step: 9
Training loss: 3.6169230937957764
Validation loss: 3.993243027758855

Epoch: 6| Step: 10
Training loss: 3.783886194229126
Validation loss: 3.981359822775728

Epoch: 6| Step: 11
Training loss: 4.162487030029297
Validation loss: 3.9645353337769866

Epoch: 6| Step: 12
Training loss: 3.5410423278808594
Validation loss: 3.95854700252574

Epoch: 6| Step: 13
Training loss: 3.8477673530578613
Validation loss: 3.9472162902996106

Epoch: 10| Step: 0
Training loss: 4.031286716461182
Validation loss: 3.9370528523639967

Epoch: 6| Step: 1
Training loss: 4.044659614562988
Validation loss: 3.9279531919828026

Epoch: 6| Step: 2
Training loss: 4.101656913757324
Validation loss: 3.91476591684485

Epoch: 6| Step: 3
Training loss: 4.875694274902344
Validation loss: 3.9049000637505644

Epoch: 6| Step: 4
Training loss: 3.107970714569092
Validation loss: 3.895416175165484

Epoch: 6| Step: 5
Training loss: 4.481483459472656
Validation loss: 3.8830429559112876

Epoch: 6| Step: 6
Training loss: 4.734340667724609
Validation loss: 3.8708637452894643

Epoch: 6| Step: 7
Training loss: 3.0330393314361572
Validation loss: 3.858236923012682

Epoch: 6| Step: 8
Training loss: 3.3228635787963867
Validation loss: 3.8508864320734495

Epoch: 6| Step: 9
Training loss: 3.4853551387786865
Validation loss: 3.837413449441233

Epoch: 6| Step: 10
Training loss: 3.424881935119629
Validation loss: 3.825624965852307

Epoch: 6| Step: 11
Training loss: 3.5582196712493896
Validation loss: 3.817355207217637

Epoch: 6| Step: 12
Training loss: 2.819631814956665
Validation loss: 3.808240854611961

Epoch: 6| Step: 13
Training loss: 2.6610796451568604
Validation loss: 3.791806682463615

Epoch: 11| Step: 0
Training loss: 2.982177734375
Validation loss: 3.7767423686160835

Epoch: 6| Step: 1
Training loss: 3.2167739868164062
Validation loss: 3.765766195071641

Epoch: 6| Step: 2
Training loss: 3.445831298828125
Validation loss: 3.7592131758248932

Epoch: 6| Step: 3
Training loss: 4.791986465454102
Validation loss: 3.7469776881638395

Epoch: 6| Step: 4
Training loss: 3.4639527797698975
Validation loss: 3.737234825729042

Epoch: 6| Step: 5
Training loss: 3.6217780113220215
Validation loss: 3.726751801788166

Epoch: 6| Step: 6
Training loss: 4.324418067932129
Validation loss: 3.7159183614997455

Epoch: 6| Step: 7
Training loss: 2.800693988800049
Validation loss: 3.702190122296733

Epoch: 6| Step: 8
Training loss: 3.7569525241851807
Validation loss: 3.6855410709176013

Epoch: 6| Step: 9
Training loss: 3.099553108215332
Validation loss: 3.676451377971198

Epoch: 6| Step: 10
Training loss: 3.5658586025238037
Validation loss: 3.661818976043373

Epoch: 6| Step: 11
Training loss: 4.578708648681641
Validation loss: 3.6492830553362445

Epoch: 6| Step: 12
Training loss: 3.0787456035614014
Validation loss: 3.6356025280491

Epoch: 6| Step: 13
Training loss: 3.206023931503296
Validation loss: 3.6199406398239957

Epoch: 12| Step: 0
Training loss: 3.0742177963256836
Validation loss: 3.610337431712817

Epoch: 6| Step: 1
Training loss: 2.193113088607788
Validation loss: 3.5927122305798274

Epoch: 6| Step: 2
Training loss: 3.48954176902771
Validation loss: 3.577660209389143

Epoch: 6| Step: 3
Training loss: 3.2947983741760254
Validation loss: 3.5712601087426625

Epoch: 6| Step: 4
Training loss: 3.6776182651519775
Validation loss: 3.5555951979852494

Epoch: 6| Step: 5
Training loss: 5.1162567138671875
Validation loss: 3.5423878033955893

Epoch: 6| Step: 6
Training loss: 2.697910785675049
Validation loss: 3.5246787173773653

Epoch: 6| Step: 7
Training loss: 3.257253646850586
Validation loss: 3.509035200201055

Epoch: 6| Step: 8
Training loss: 2.8630948066711426
Validation loss: 3.498929872307726

Epoch: 6| Step: 9
Training loss: 3.365684747695923
Validation loss: 3.4864535100998415

Epoch: 6| Step: 10
Training loss: 4.304178714752197
Validation loss: 3.4700225014840402

Epoch: 6| Step: 11
Training loss: 3.3925912380218506
Validation loss: 3.452723718458606

Epoch: 6| Step: 12
Training loss: 3.4482645988464355
Validation loss: 3.4336604072201635

Epoch: 6| Step: 13
Training loss: 3.6627917289733887
Validation loss: 3.415848831976614

Epoch: 13| Step: 0
Training loss: 3.957108974456787
Validation loss: 3.392999597775039

Epoch: 6| Step: 1
Training loss: 3.178760528564453
Validation loss: 3.378390609577138

Epoch: 6| Step: 2
Training loss: 3.839700698852539
Validation loss: 3.370113521493891

Epoch: 6| Step: 3
Training loss: 3.211461067199707
Validation loss: 3.342111059414443

Epoch: 6| Step: 4
Training loss: 4.043471813201904
Validation loss: 3.3253121299128376

Epoch: 6| Step: 5
Training loss: 1.8855140209197998
Validation loss: 3.3071851268891366

Epoch: 6| Step: 6
Training loss: 3.6165971755981445
Validation loss: 3.293058672258931

Epoch: 6| Step: 7
Training loss: 3.4757027626037598
Validation loss: 3.2655503570392566

Epoch: 6| Step: 8
Training loss: 3.0924365520477295
Validation loss: 3.2581641981678624

Epoch: 6| Step: 9
Training loss: 2.20369291305542
Validation loss: 3.2387063759629444

Epoch: 6| Step: 10
Training loss: 2.5716772079467773
Validation loss: 3.2182079950968423

Epoch: 6| Step: 11
Training loss: 2.943113088607788
Validation loss: 3.1955666952235724

Epoch: 6| Step: 12
Training loss: 4.227377891540527
Validation loss: 3.18891417595648

Epoch: 6| Step: 13
Training loss: 2.3484387397766113
Validation loss: 3.1593774211022163

Epoch: 14| Step: 0
Training loss: 2.5952818393707275
Validation loss: 3.1441303042955298

Epoch: 6| Step: 1
Training loss: 4.201632976531982
Validation loss: 3.1243597307512836

Epoch: 6| Step: 2
Training loss: 2.768120288848877
Validation loss: 3.110976929305702

Epoch: 6| Step: 3
Training loss: 2.7903518676757812
Validation loss: 3.0841988953210975

Epoch: 6| Step: 4
Training loss: 2.3568191528320312
Validation loss: 3.0776932495896534

Epoch: 6| Step: 5
Training loss: 3.403409481048584
Validation loss: 3.0549401621664725

Epoch: 6| Step: 6
Training loss: 1.916015863418579
Validation loss: 3.0377672205689135

Epoch: 6| Step: 7
Training loss: 2.985685348510742
Validation loss: 3.0222770142298874

Epoch: 6| Step: 8
Training loss: 2.5505361557006836
Validation loss: 3.0086713785766275

Epoch: 6| Step: 9
Training loss: 4.166253566741943
Validation loss: 2.988469457113615

Epoch: 6| Step: 10
Training loss: 3.5767998695373535
Validation loss: 2.976932943508189

Epoch: 6| Step: 11
Training loss: 2.8060545921325684
Validation loss: 2.957930564880371

Epoch: 6| Step: 12
Training loss: 2.9703288078308105
Validation loss: 2.937519960505988

Epoch: 6| Step: 13
Training loss: 3.159667491912842
Validation loss: 2.9131973558856594

Epoch: 15| Step: 0
Training loss: 3.191941022872925
Validation loss: 2.8985243869084183

Epoch: 6| Step: 1
Training loss: 2.9870970249176025
Validation loss: 2.88801573681575

Epoch: 6| Step: 2
Training loss: 2.6937646865844727
Validation loss: 2.8626666479213263

Epoch: 6| Step: 3
Training loss: 2.301124095916748
Validation loss: 2.847723750657933

Epoch: 6| Step: 4
Training loss: 3.417839765548706
Validation loss: 2.8319689432779946

Epoch: 6| Step: 5
Training loss: 2.997248888015747
Validation loss: 2.810452566351942

Epoch: 6| Step: 6
Training loss: 2.9542574882507324
Validation loss: 2.7948161453329106

Epoch: 6| Step: 7
Training loss: 2.7804508209228516
Validation loss: 2.7771008065951768

Epoch: 6| Step: 8
Training loss: 2.849057197570801
Validation loss: 2.7575997716637066

Epoch: 6| Step: 9
Training loss: 3.3210182189941406
Validation loss: 2.7454840624204246

Epoch: 6| Step: 10
Training loss: 2.728005886077881
Validation loss: 2.7333981529358895

Epoch: 6| Step: 11
Training loss: 2.8016278743743896
Validation loss: 2.721444781108569

Epoch: 6| Step: 12
Training loss: 2.4421215057373047
Validation loss: 2.6914628654397945

Epoch: 6| Step: 13
Training loss: 2.2588958740234375
Validation loss: 2.672394742247879

Epoch: 16| Step: 0
Training loss: 2.878563404083252
Validation loss: 2.6517884756929133

Epoch: 6| Step: 1
Training loss: 2.601091146469116
Validation loss: 2.6409849684725524

Epoch: 6| Step: 2
Training loss: 3.493870973587036
Validation loss: 2.6207111368897142

Epoch: 6| Step: 3
Training loss: 2.4918317794799805
Validation loss: 2.613223559112959

Epoch: 6| Step: 4
Training loss: 1.9940885305404663
Validation loss: 2.5950057019469557

Epoch: 6| Step: 5
Training loss: 2.582923173904419
Validation loss: 2.58467855504764

Epoch: 6| Step: 6
Training loss: 2.8357930183410645
Validation loss: 2.5682944302917807

Epoch: 6| Step: 7
Training loss: 3.311127185821533
Validation loss: 2.5399684418914137

Epoch: 6| Step: 8
Training loss: 2.522129535675049
Validation loss: 2.5204958044072634

Epoch: 6| Step: 9
Training loss: 2.1688897609710693
Validation loss: 2.5118791980128132

Epoch: 6| Step: 10
Training loss: 2.9984545707702637
Validation loss: 2.4960913709414903

Epoch: 6| Step: 11
Training loss: 2.620004653930664
Validation loss: 2.485396278801785

Epoch: 6| Step: 12
Training loss: 2.5713796615600586
Validation loss: 2.4531391154053392

Epoch: 6| Step: 13
Training loss: 3.0243170261383057
Validation loss: 2.4566255436148694

Epoch: 17| Step: 0
Training loss: 3.0980224609375
Validation loss: 2.4404520552645446

Epoch: 6| Step: 1
Training loss: 2.842160224914551
Validation loss: 2.421930423346899

Epoch: 6| Step: 2
Training loss: 2.8283629417419434
Validation loss: 2.412294744163431

Epoch: 6| Step: 3
Training loss: 2.9295191764831543
Validation loss: 2.3825016380638204

Epoch: 6| Step: 4
Training loss: 2.4963603019714355
Validation loss: 2.3654270274664766

Epoch: 6| Step: 5
Training loss: 3.0739076137542725
Validation loss: 2.3530473657833633

Epoch: 6| Step: 6
Training loss: 2.2718448638916016
Validation loss: 2.3331758950346257

Epoch: 6| Step: 7
Training loss: 2.576817274093628
Validation loss: 2.3269898481266473

Epoch: 6| Step: 8
Training loss: 2.287118434906006
Validation loss: 2.321429452588481

Epoch: 6| Step: 9
Training loss: 2.800323009490967
Validation loss: 2.3086179200039116

Epoch: 6| Step: 10
Training loss: 2.493133544921875
Validation loss: 2.3044279416402182

Epoch: 6| Step: 11
Training loss: 2.4492650032043457
Validation loss: 2.293463732606621

Epoch: 6| Step: 12
Training loss: 1.8697350025177002
Validation loss: 2.2984668285615983

Epoch: 6| Step: 13
Training loss: 2.0751101970672607
Validation loss: 2.27837767524104

Epoch: 18| Step: 0
Training loss: 2.57584810256958
Validation loss: 2.264681341827557

Epoch: 6| Step: 1
Training loss: 2.418208599090576
Validation loss: 2.269647544430148

Epoch: 6| Step: 2
Training loss: 2.7622880935668945
Validation loss: 2.2632606132056123

Epoch: 6| Step: 3
Training loss: 2.9220995903015137
Validation loss: 2.270795383761006

Epoch: 6| Step: 4
Training loss: 2.1142048835754395
Validation loss: 2.2488422060525544

Epoch: 6| Step: 5
Training loss: 2.694781541824341
Validation loss: 2.2621451193286526

Epoch: 6| Step: 6
Training loss: 2.6092636585235596
Validation loss: 2.244461456934611

Epoch: 6| Step: 7
Training loss: 2.256059169769287
Validation loss: 2.2340779919778146

Epoch: 6| Step: 8
Training loss: 2.603710174560547
Validation loss: 2.2366732064113823

Epoch: 6| Step: 9
Training loss: 2.287122964859009
Validation loss: 2.223561936809171

Epoch: 6| Step: 10
Training loss: 1.7101413011550903
Validation loss: 2.2139426944076375

Epoch: 6| Step: 11
Training loss: 2.63067626953125
Validation loss: 2.2040928102308706

Epoch: 6| Step: 12
Training loss: 3.0333874225616455
Validation loss: 2.2016561928615777

Epoch: 6| Step: 13
Training loss: 2.4709701538085938
Validation loss: 2.201200310901929

Epoch: 19| Step: 0
Training loss: 2.0802321434020996
Validation loss: 2.19668508345081

Epoch: 6| Step: 1
Training loss: 2.652557134628296
Validation loss: 2.183641423461258

Epoch: 6| Step: 2
Training loss: 2.190019130706787
Validation loss: 2.1930509459587837

Epoch: 6| Step: 3
Training loss: 2.4261884689331055
Validation loss: 2.171083284962562

Epoch: 6| Step: 4
Training loss: 2.4537734985351562
Validation loss: 2.172592325877118

Epoch: 6| Step: 5
Training loss: 3.3892035484313965
Validation loss: 2.170197270249808

Epoch: 6| Step: 6
Training loss: 2.831239700317383
Validation loss: 2.1729074242294475

Epoch: 6| Step: 7
Training loss: 2.642535448074341
Validation loss: 2.153412312589666

Epoch: 6| Step: 8
Training loss: 2.6801886558532715
Validation loss: 2.163720287302489

Epoch: 6| Step: 9
Training loss: 1.9469163417816162
Validation loss: 2.1421567804069928

Epoch: 6| Step: 10
Training loss: 2.9154722690582275
Validation loss: 2.1459964962415796

Epoch: 6| Step: 11
Training loss: 2.2792837619781494
Validation loss: 2.147247927163237

Epoch: 6| Step: 12
Training loss: 1.9489693641662598
Validation loss: 2.14492033373925

Epoch: 6| Step: 13
Training loss: 2.0552926063537598
Validation loss: 2.155763837598985

Epoch: 20| Step: 0
Training loss: 2.5596234798431396
Validation loss: 2.1211552107205955

Epoch: 6| Step: 1
Training loss: 2.6898980140686035
Validation loss: 2.1325848448661064

Epoch: 6| Step: 2
Training loss: 2.889920949935913
Validation loss: 2.145214501247611

Epoch: 6| Step: 3
Training loss: 2.2599313259124756
Validation loss: 2.1312839805438952

Epoch: 6| Step: 4
Training loss: 2.3539159297943115
Validation loss: 2.14102453185666

Epoch: 6| Step: 5
Training loss: 2.2769298553466797
Validation loss: 2.13255206231148

Epoch: 6| Step: 6
Training loss: 2.4856748580932617
Validation loss: 2.1243037023851947

Epoch: 6| Step: 7
Training loss: 2.1312458515167236
Validation loss: 2.1330693832007785

Epoch: 6| Step: 8
Training loss: 3.036534547805786
Validation loss: 2.1241177525571597

Epoch: 6| Step: 9
Training loss: 1.8716046810150146
Validation loss: 2.1268044197431175

Epoch: 6| Step: 10
Training loss: 2.3508169651031494
Validation loss: 2.1266850925260976

Epoch: 6| Step: 11
Training loss: 2.5965614318847656
Validation loss: 2.1169546957938903

Epoch: 6| Step: 12
Training loss: 2.599640369415283
Validation loss: 2.1344423960613947

Epoch: 6| Step: 13
Training loss: 2.4532206058502197
Validation loss: 2.118218407836012

Epoch: 21| Step: 0
Training loss: 3.3975653648376465
Validation loss: 2.1164792353107083

Epoch: 6| Step: 1
Training loss: 2.473860263824463
Validation loss: 2.1351855724088606

Epoch: 6| Step: 2
Training loss: 2.5782995223999023
Validation loss: 2.1295678641206477

Epoch: 6| Step: 3
Training loss: 2.4930291175842285
Validation loss: 2.128213108226817

Epoch: 6| Step: 4
Training loss: 1.5578113794326782
Validation loss: 2.116954380466092

Epoch: 6| Step: 5
Training loss: 2.027785539627075
Validation loss: 2.135714771927044

Epoch: 6| Step: 6
Training loss: 2.246006965637207
Validation loss: 2.123587485282652

Epoch: 6| Step: 7
Training loss: 2.1722729206085205
Validation loss: 2.1322007756079397

Epoch: 6| Step: 8
Training loss: 2.654266834259033
Validation loss: 2.1210508372194026

Epoch: 6| Step: 9
Training loss: 2.5941402912139893
Validation loss: 2.136072590786924

Epoch: 6| Step: 10
Training loss: 2.3629086017608643
Validation loss: 2.1194161394590973

Epoch: 6| Step: 11
Training loss: 2.197073459625244
Validation loss: 2.1131956461937196

Epoch: 6| Step: 12
Training loss: 2.496074676513672
Validation loss: 2.120398957242248

Epoch: 6| Step: 13
Training loss: 3.646866798400879
Validation loss: 2.127336794330228

Epoch: 22| Step: 0
Training loss: 2.348324775695801
Validation loss: 2.115575590441304

Epoch: 6| Step: 1
Training loss: 1.7592428922653198
Validation loss: 2.117172033556046

Epoch: 6| Step: 2
Training loss: 1.6516984701156616
Validation loss: 2.126775231412662

Epoch: 6| Step: 3
Training loss: 3.1760993003845215
Validation loss: 2.1304435396707184

Epoch: 6| Step: 4
Training loss: 1.8041939735412598
Validation loss: 2.131899572187854

Epoch: 6| Step: 5
Training loss: 2.624699115753174
Validation loss: 2.124246786999446

Epoch: 6| Step: 6
Training loss: 2.9160146713256836
Validation loss: 2.1358007666885213

Epoch: 6| Step: 7
Training loss: 2.648138999938965
Validation loss: 2.1466171177484656

Epoch: 6| Step: 8
Training loss: 2.7043251991271973
Validation loss: 2.1363913038725495

Epoch: 6| Step: 9
Training loss: 2.6648268699645996
Validation loss: 2.1531321182045886

Epoch: 6| Step: 10
Training loss: 2.990457773208618
Validation loss: 2.124930512520575

Epoch: 6| Step: 11
Training loss: 1.9102044105529785
Validation loss: 2.135248355968024

Epoch: 6| Step: 12
Training loss: 2.546204090118408
Validation loss: 2.138166303275734

Epoch: 6| Step: 13
Training loss: 2.760422706604004
Validation loss: 2.1389005799447336

Epoch: 23| Step: 0
Training loss: 2.2393219470977783
Validation loss: 2.1360636116355978

Epoch: 6| Step: 1
Training loss: 2.9289474487304688
Validation loss: 2.139141313491329

Epoch: 6| Step: 2
Training loss: 2.578268527984619
Validation loss: 2.1443427762677594

Epoch: 6| Step: 3
Training loss: 2.1337156295776367
Validation loss: 2.1364456492085613

Epoch: 6| Step: 4
Training loss: 1.4371373653411865
Validation loss: 2.142935094013009

Epoch: 6| Step: 5
Training loss: 2.1417479515075684
Validation loss: 2.1394671214524137

Epoch: 6| Step: 6
Training loss: 2.451284408569336
Validation loss: 2.14317827070913

Epoch: 6| Step: 7
Training loss: 3.2333507537841797
Validation loss: 2.1380942611284155

Epoch: 6| Step: 8
Training loss: 2.457583427429199
Validation loss: 2.145250469125727

Epoch: 6| Step: 9
Training loss: 2.5981860160827637
Validation loss: 2.1481140557155816

Epoch: 6| Step: 10
Training loss: 2.206739902496338
Validation loss: 2.1465338096823743

Epoch: 6| Step: 11
Training loss: 2.6859192848205566
Validation loss: 2.142322491574031

Epoch: 6| Step: 12
Training loss: 2.800920248031616
Validation loss: 2.1424168181675736

Epoch: 6| Step: 13
Training loss: 2.0482993125915527
Validation loss: 2.150762527219711

Epoch: 24| Step: 0
Training loss: 2.303948402404785
Validation loss: 2.1316736282840854

Epoch: 6| Step: 1
Training loss: 2.0126748085021973
Validation loss: 2.147000256405082

Epoch: 6| Step: 2
Training loss: 2.670112371444702
Validation loss: 2.1481272687194166

Epoch: 6| Step: 3
Training loss: 2.1853415966033936
Validation loss: 2.133885622024536

Epoch: 6| Step: 4
Training loss: 3.2143993377685547
Validation loss: 2.1323637090703493

Epoch: 6| Step: 5
Training loss: 1.9999887943267822
Validation loss: 2.138565645422987

Epoch: 6| Step: 6
Training loss: 2.3093652725219727
Validation loss: 2.1413543583244405

Epoch: 6| Step: 7
Training loss: 3.2498929500579834
Validation loss: 2.1597691274458364

Epoch: 6| Step: 8
Training loss: 1.9792630672454834
Validation loss: 2.140875430517299

Epoch: 6| Step: 9
Training loss: 2.6649622917175293
Validation loss: 2.158985271248766

Epoch: 6| Step: 10
Training loss: 2.8489162921905518
Validation loss: 2.14568038909666

Epoch: 6| Step: 11
Training loss: 1.876674771308899
Validation loss: 2.135957343603975

Epoch: 6| Step: 12
Training loss: 2.501262664794922
Validation loss: 2.1472440611931587

Epoch: 6| Step: 13
Training loss: 2.2799410820007324
Validation loss: 2.130888585121401

Epoch: 25| Step: 0
Training loss: 2.4398162364959717
Validation loss: 2.13073718419639

Epoch: 6| Step: 1
Training loss: 2.5679430961608887
Validation loss: 2.146306359639732

Epoch: 6| Step: 2
Training loss: 2.692523717880249
Validation loss: 2.1495169695987495

Epoch: 6| Step: 3
Training loss: 1.6741142272949219
Validation loss: 2.1315780096156622

Epoch: 6| Step: 4
Training loss: 2.3605918884277344
Validation loss: 2.1293999943681943

Epoch: 6| Step: 5
Training loss: 2.3252687454223633
Validation loss: 2.1344861292069957

Epoch: 6| Step: 6
Training loss: 2.461759567260742
Validation loss: 2.128124419079032

Epoch: 6| Step: 7
Training loss: 2.5493760108947754
Validation loss: 2.1296653234830467

Epoch: 6| Step: 8
Training loss: 2.6455345153808594
Validation loss: 2.1146585736223447

Epoch: 6| Step: 9
Training loss: 2.2750608921051025
Validation loss: 2.1250058463824693

Epoch: 6| Step: 10
Training loss: 2.2105484008789062
Validation loss: 2.1234761681607974

Epoch: 6| Step: 11
Training loss: 2.8773436546325684
Validation loss: 2.1237027734838505

Epoch: 6| Step: 12
Training loss: 2.6116220951080322
Validation loss: 2.12402335802714

Epoch: 6| Step: 13
Training loss: 2.113826036453247
Validation loss: 2.1215683849908973

Epoch: 26| Step: 0
Training loss: 2.899071216583252
Validation loss: 2.112012346585592

Epoch: 6| Step: 1
Training loss: 2.164079427719116
Validation loss: 2.123277456529679

Epoch: 6| Step: 2
Training loss: 2.562960386276245
Validation loss: 2.12269260550058

Epoch: 6| Step: 3
Training loss: 2.1898608207702637
Validation loss: 2.123273480323053

Epoch: 6| Step: 4
Training loss: 1.7861980199813843
Validation loss: 2.1194382662414224

Epoch: 6| Step: 5
Training loss: 2.564375162124634
Validation loss: 2.1354456793877388

Epoch: 6| Step: 6
Training loss: 2.3798298835754395
Validation loss: 2.124340154791391

Epoch: 6| Step: 7
Training loss: 1.951584815979004
Validation loss: 2.1248314021736063

Epoch: 6| Step: 8
Training loss: 2.7914466857910156
Validation loss: 2.104649579653176

Epoch: 6| Step: 9
Training loss: 3.0858571529388428
Validation loss: 2.114496279788274

Epoch: 6| Step: 10
Training loss: 2.529914140701294
Validation loss: 2.1273776100527857

Epoch: 6| Step: 11
Training loss: 2.57857608795166
Validation loss: 2.124068303774762

Epoch: 6| Step: 12
Training loss: 2.253443717956543
Validation loss: 2.1145186231982325

Epoch: 6| Step: 13
Training loss: 1.8653526306152344
Validation loss: 2.113906697560382

Epoch: 27| Step: 0
Training loss: 2.6091675758361816
Validation loss: 2.1058344559002946

Epoch: 6| Step: 1
Training loss: 2.1464896202087402
Validation loss: 2.089726895414373

Epoch: 6| Step: 2
Training loss: 1.6757843494415283
Validation loss: 2.1257816822298112

Epoch: 6| Step: 3
Training loss: 1.994826316833496
Validation loss: 2.111181277100758

Epoch: 6| Step: 4
Training loss: 2.6551661491394043
Validation loss: 2.098759315347159

Epoch: 6| Step: 5
Training loss: 3.034386157989502
Validation loss: 2.1187884679404636

Epoch: 6| Step: 6
Training loss: 2.293515920639038
Validation loss: 2.110134058101203

Epoch: 6| Step: 7
Training loss: 2.6103556156158447
Validation loss: 2.1097223040878132

Epoch: 6| Step: 8
Training loss: 2.010545492172241
Validation loss: 2.1165157800079673

Epoch: 6| Step: 9
Training loss: 2.6040003299713135
Validation loss: 2.1216242646658294

Epoch: 6| Step: 10
Training loss: 3.3285269737243652
Validation loss: 2.123626334692842

Epoch: 6| Step: 11
Training loss: 2.559314727783203
Validation loss: 2.113286787463773

Epoch: 6| Step: 12
Training loss: 2.327622890472412
Validation loss: 2.1208774415395593

Epoch: 6| Step: 13
Training loss: 1.668372631072998
Validation loss: 2.1132820229376517

Epoch: 28| Step: 0
Training loss: 2.6105473041534424
Validation loss: 2.11788506918056

Epoch: 6| Step: 1
Training loss: 3.089616537094116
Validation loss: 2.1121306778282247

Epoch: 6| Step: 2
Training loss: 2.2627291679382324
Validation loss: 2.113657723190964

Epoch: 6| Step: 3
Training loss: 2.2854251861572266
Validation loss: 2.1194637180656515

Epoch: 6| Step: 4
Training loss: 2.4700324535369873
Validation loss: 2.110112226137551

Epoch: 6| Step: 5
Training loss: 2.3996832370758057
Validation loss: 2.1010378381257415

Epoch: 6| Step: 6
Training loss: 2.2353932857513428
Validation loss: 2.1119300306484265

Epoch: 6| Step: 7
Training loss: 2.487783908843994
Validation loss: 2.113374307591428

Epoch: 6| Step: 8
Training loss: 2.243710517883301
Validation loss: 2.10221496705086

Epoch: 6| Step: 9
Training loss: 2.2941806316375732
Validation loss: 2.1072540885658673

Epoch: 6| Step: 10
Training loss: 3.20576810836792
Validation loss: 2.1167092989849787

Epoch: 6| Step: 11
Training loss: 2.173895835876465
Validation loss: 2.1146954490292456

Epoch: 6| Step: 12
Training loss: 1.5196340084075928
Validation loss: 2.116593712119646

Epoch: 6| Step: 13
Training loss: 2.621260166168213
Validation loss: 2.1007043136063444

Epoch: 29| Step: 0
Training loss: 2.301919937133789
Validation loss: 2.109657120961015

Epoch: 6| Step: 1
Training loss: 2.4035120010375977
Validation loss: 2.1032517674148723

Epoch: 6| Step: 2
Training loss: 2.979799270629883
Validation loss: 2.102621031063859

Epoch: 6| Step: 3
Training loss: 2.418586254119873
Validation loss: 2.094704356244815

Epoch: 6| Step: 4
Training loss: 2.398348331451416
Validation loss: 2.0997945775267897

Epoch: 6| Step: 5
Training loss: 1.7984023094177246
Validation loss: 2.0984446579410183

Epoch: 6| Step: 6
Training loss: 3.14490008354187
Validation loss: 2.093251125786894

Epoch: 6| Step: 7
Training loss: 2.4903059005737305
Validation loss: 2.086990858918877

Epoch: 6| Step: 8
Training loss: 2.39756441116333
Validation loss: 2.090132846627184

Epoch: 6| Step: 9
Training loss: 2.432422637939453
Validation loss: 2.0863517151083997

Epoch: 6| Step: 10
Training loss: 2.1146388053894043
Validation loss: 2.0975220741764193

Epoch: 6| Step: 11
Training loss: 2.2055797576904297
Validation loss: 2.093971385750719

Epoch: 6| Step: 12
Training loss: 2.3241491317749023
Validation loss: 2.101419759053056

Epoch: 6| Step: 13
Training loss: 2.1999337673187256
Validation loss: 2.098123622196977

Epoch: 30| Step: 0
Training loss: 2.333888530731201
Validation loss: 2.091851715118654

Epoch: 6| Step: 1
Training loss: 2.466844320297241
Validation loss: 2.0904171671918643

Epoch: 6| Step: 2
Training loss: 2.2143805027008057
Validation loss: 2.0959445045840357

Epoch: 6| Step: 3
Training loss: 2.7023091316223145
Validation loss: 2.0799279520588536

Epoch: 6| Step: 4
Training loss: 1.7837530374526978
Validation loss: 2.1103956378916258

Epoch: 6| Step: 5
Training loss: 2.557180404663086
Validation loss: 2.089515896253688

Epoch: 6| Step: 6
Training loss: 2.2092230319976807
Validation loss: 2.0997333244610856

Epoch: 6| Step: 7
Training loss: 2.425873279571533
Validation loss: 2.0970531048313266

Epoch: 6| Step: 8
Training loss: 2.4933013916015625
Validation loss: 2.098084488222676

Epoch: 6| Step: 9
Training loss: 2.875555992126465
Validation loss: 2.086166822782127

Epoch: 6| Step: 10
Training loss: 2.828760862350464
Validation loss: 2.0995508470842914

Epoch: 6| Step: 11
Training loss: 2.7669525146484375
Validation loss: 2.0906392579437583

Epoch: 6| Step: 12
Training loss: 1.8570088148117065
Validation loss: 2.081757071197674

Epoch: 6| Step: 13
Training loss: 1.7118929624557495
Validation loss: 2.0812308480662685

Epoch: 31| Step: 0
Training loss: 2.161142587661743
Validation loss: 2.0985790401376705

Epoch: 6| Step: 1
Training loss: 2.41866397857666
Validation loss: 2.098440149778961

Epoch: 6| Step: 2
Training loss: 2.8691582679748535
Validation loss: 2.0960854227824877

Epoch: 6| Step: 3
Training loss: 2.6487932205200195
Validation loss: 2.098505312396634

Epoch: 6| Step: 4
Training loss: 2.2663187980651855
Validation loss: 2.086537625200005

Epoch: 6| Step: 5
Training loss: 1.4801076650619507
Validation loss: 2.0973770720984346

Epoch: 6| Step: 6
Training loss: 2.772514820098877
Validation loss: 2.0874110062917075

Epoch: 6| Step: 7
Training loss: 2.4851438999176025
Validation loss: 2.0825426296521257

Epoch: 6| Step: 8
Training loss: 2.624236822128296
Validation loss: 2.0874202225797918

Epoch: 6| Step: 9
Training loss: 2.178110122680664
Validation loss: 2.1007390637551584

Epoch: 6| Step: 10
Training loss: 2.4297678470611572
Validation loss: 2.081267405581731

Epoch: 6| Step: 11
Training loss: 2.8132200241088867
Validation loss: 2.088314494779033

Epoch: 6| Step: 12
Training loss: 1.6904230117797852
Validation loss: 2.0993904990534626

Epoch: 6| Step: 13
Training loss: 2.857180595397949
Validation loss: 2.102498380086755

Epoch: 32| Step: 0
Training loss: 2.1933398246765137
Validation loss: 2.0840487531436387

Epoch: 6| Step: 1
Training loss: 2.3649754524230957
Validation loss: 2.088069587625483

Epoch: 6| Step: 2
Training loss: 2.940201759338379
Validation loss: 2.085142904712308

Epoch: 6| Step: 3
Training loss: 2.4367311000823975
Validation loss: 2.096124545220406

Epoch: 6| Step: 4
Training loss: 2.160574197769165
Validation loss: 2.088968840978479

Epoch: 6| Step: 5
Training loss: 1.9680137634277344
Validation loss: 2.089091016400245

Epoch: 6| Step: 6
Training loss: 2.9189453125
Validation loss: 2.0961481730143228

Epoch: 6| Step: 7
Training loss: 2.2046573162078857
Validation loss: 2.094323194155129

Epoch: 6| Step: 8
Training loss: 2.140493392944336
Validation loss: 2.0936016985165176

Epoch: 6| Step: 9
Training loss: 3.0730600357055664
Validation loss: 2.0877614623756817

Epoch: 6| Step: 10
Training loss: 2.0764923095703125
Validation loss: 2.0909417316477787

Epoch: 6| Step: 11
Training loss: 2.7923121452331543
Validation loss: 2.0907397180475216

Epoch: 6| Step: 12
Training loss: 2.000490665435791
Validation loss: 2.0796629574991043

Epoch: 6| Step: 13
Training loss: 2.0304932594299316
Validation loss: 2.070888985869705

Epoch: 33| Step: 0
Training loss: 2.243530511856079
Validation loss: 2.0863192107087825

Epoch: 6| Step: 1
Training loss: 2.995352268218994
Validation loss: 2.079462794847386

Epoch: 6| Step: 2
Training loss: 2.5996508598327637
Validation loss: 2.082574341886787

Epoch: 6| Step: 3
Training loss: 2.467834234237671
Validation loss: 2.0879846516475884

Epoch: 6| Step: 4
Training loss: 2.075477123260498
Validation loss: 2.0895334123283305

Epoch: 6| Step: 5
Training loss: 2.33784556388855
Validation loss: 2.101769442199379

Epoch: 6| Step: 6
Training loss: 2.42617130279541
Validation loss: 2.079911506304177

Epoch: 6| Step: 7
Training loss: 2.4975485801696777
Validation loss: 2.0719379660903767

Epoch: 6| Step: 8
Training loss: 1.8403363227844238
Validation loss: 2.0891276354430826

Epoch: 6| Step: 9
Training loss: 2.8454394340515137
Validation loss: 2.079682719322943

Epoch: 6| Step: 10
Training loss: 1.77716863155365
Validation loss: 2.0861747277680265

Epoch: 6| Step: 11
Training loss: 2.5737314224243164
Validation loss: 2.0765326664011967

Epoch: 6| Step: 12
Training loss: 2.162782669067383
Validation loss: 2.0928395871193177

Epoch: 6| Step: 13
Training loss: 2.5849924087524414
Validation loss: 2.0952693211135043

Epoch: 34| Step: 0
Training loss: 2.8484225273132324
Validation loss: 2.0968640824799896

Epoch: 6| Step: 1
Training loss: 2.693983554840088
Validation loss: 2.082662300396991

Epoch: 6| Step: 2
Training loss: 2.8206214904785156
Validation loss: 2.0787373588931177

Epoch: 6| Step: 3
Training loss: 2.805050849914551
Validation loss: 2.0755688605769986

Epoch: 6| Step: 4
Training loss: 1.702165961265564
Validation loss: 2.0892298503588607

Epoch: 6| Step: 5
Training loss: 2.060929775238037
Validation loss: 2.08137018962573

Epoch: 6| Step: 6
Training loss: 1.5797446966171265
Validation loss: 2.0811779499053955

Epoch: 6| Step: 7
Training loss: 2.3155570030212402
Validation loss: 2.07697836173478

Epoch: 6| Step: 8
Training loss: 1.9094762802124023
Validation loss: 2.091491703064211

Epoch: 6| Step: 9
Training loss: 2.7671942710876465
Validation loss: 2.073243433429349

Epoch: 6| Step: 10
Training loss: 2.504535436630249
Validation loss: 2.067504764885031

Epoch: 6| Step: 11
Training loss: 2.398348331451416
Validation loss: 2.077440631005072

Epoch: 6| Step: 12
Training loss: 2.352675437927246
Validation loss: 2.0895256880790956

Epoch: 6| Step: 13
Training loss: 2.489687919616699
Validation loss: 2.0956562590855423

Epoch: 35| Step: 0
Training loss: 1.9385775327682495
Validation loss: 2.079156437227803

Epoch: 6| Step: 1
Training loss: 2.0840799808502197
Validation loss: 2.0766660551871023

Epoch: 6| Step: 2
Training loss: 2.755647897720337
Validation loss: 2.0925506058559624

Epoch: 6| Step: 3
Training loss: 2.276355266571045
Validation loss: 2.094993891254548

Epoch: 6| Step: 4
Training loss: 2.294217109680176
Validation loss: 2.0849461760572208

Epoch: 6| Step: 5
Training loss: 2.290161609649658
Validation loss: 2.0778986407864477

Epoch: 6| Step: 6
Training loss: 2.152944564819336
Validation loss: 2.093896685108062

Epoch: 6| Step: 7
Training loss: 2.0890402793884277
Validation loss: 2.0704308684154222

Epoch: 6| Step: 8
Training loss: 3.0484962463378906
Validation loss: 2.079476994852866

Epoch: 6| Step: 9
Training loss: 2.574084997177124
Validation loss: 2.0906538501862557

Epoch: 6| Step: 10
Training loss: 2.107363700866699
Validation loss: 2.0744597219651744

Epoch: 6| Step: 11
Training loss: 3.0482888221740723
Validation loss: 2.077124064968478

Epoch: 6| Step: 12
Training loss: 2.460627317428589
Validation loss: 2.0889265101443053

Epoch: 6| Step: 13
Training loss: 1.6006327867507935
Validation loss: 2.078470872294518

Epoch: 36| Step: 0
Training loss: 3.139775514602661
Validation loss: 2.0896902263805432

Epoch: 6| Step: 1
Training loss: 2.4828240871429443
Validation loss: 2.059619403654529

Epoch: 6| Step: 2
Training loss: 1.7708557844161987
Validation loss: 2.06896056923815

Epoch: 6| Step: 3
Training loss: 2.3046188354492188
Validation loss: 2.073086097676267

Epoch: 6| Step: 4
Training loss: 2.0756635665893555
Validation loss: 2.064815849386236

Epoch: 6| Step: 5
Training loss: 2.2988247871398926
Validation loss: 2.0685300211752615

Epoch: 6| Step: 6
Training loss: 1.7959078550338745
Validation loss: 2.0667927675349738

Epoch: 6| Step: 7
Training loss: 3.1140904426574707
Validation loss: 2.0883764720732167

Epoch: 6| Step: 8
Training loss: 1.999786615371704
Validation loss: 2.0636130199637464

Epoch: 6| Step: 9
Training loss: 2.647022247314453
Validation loss: 2.0746235001471733

Epoch: 6| Step: 10
Training loss: 2.250190258026123
Validation loss: 2.064977406173624

Epoch: 6| Step: 11
Training loss: 2.7032270431518555
Validation loss: 2.075407833181402

Epoch: 6| Step: 12
Training loss: 2.050506114959717
Validation loss: 2.0638681201524633

Epoch: 6| Step: 13
Training loss: 2.5717382431030273
Validation loss: 2.0677219936924596

Epoch: 37| Step: 0
Training loss: 1.781853199005127
Validation loss: 2.0749993273006972

Epoch: 6| Step: 1
Training loss: 2.0397281646728516
Validation loss: 2.0589231124488254

Epoch: 6| Step: 2
Training loss: 2.757801055908203
Validation loss: 2.072011511812928

Epoch: 6| Step: 3
Training loss: 2.3525991439819336
Validation loss: 2.0578722107794976

Epoch: 6| Step: 4
Training loss: 2.9438886642456055
Validation loss: 2.0536011572807067

Epoch: 6| Step: 5
Training loss: 2.0075523853302
Validation loss: 2.0663582983837334

Epoch: 6| Step: 6
Training loss: 2.933330774307251
Validation loss: 2.0461656303815943

Epoch: 6| Step: 7
Training loss: 1.712862491607666
Validation loss: 2.0464083597224247

Epoch: 6| Step: 8
Training loss: 1.6696562767028809
Validation loss: 2.0585179200736423

Epoch: 6| Step: 9
Training loss: 1.9398419857025146
Validation loss: 2.0583956267244075

Epoch: 6| Step: 10
Training loss: 2.872191905975342
Validation loss: 2.070777198319794

Epoch: 6| Step: 11
Training loss: 2.832010269165039
Validation loss: 2.053542492210224

Epoch: 6| Step: 12
Training loss: 2.8822309970855713
Validation loss: 2.0572468234646704

Epoch: 6| Step: 13
Training loss: 2.0874669551849365
Validation loss: 2.0490917082755797

Epoch: 38| Step: 0
Training loss: 2.4423828125
Validation loss: 2.053699815145103

Epoch: 6| Step: 1
Training loss: 2.5670175552368164
Validation loss: 2.058799300783424

Epoch: 6| Step: 2
Training loss: 2.220684289932251
Validation loss: 2.062743344614583

Epoch: 6| Step: 3
Training loss: 2.5646703243255615
Validation loss: 2.05816940979291

Epoch: 6| Step: 4
Training loss: 3.116604804992676
Validation loss: 2.0500954197299097

Epoch: 6| Step: 5
Training loss: 2.7566070556640625
Validation loss: 2.0552882776465466

Epoch: 6| Step: 6
Training loss: 1.9930042028427124
Validation loss: 2.0626106339116252

Epoch: 6| Step: 7
Training loss: 2.018861770629883
Validation loss: 2.0665681413424912

Epoch: 6| Step: 8
Training loss: 2.0685622692108154
Validation loss: 2.0571055040564588

Epoch: 6| Step: 9
Training loss: 2.491243362426758
Validation loss: 2.0618141312753

Epoch: 6| Step: 10
Training loss: 2.5017569065093994
Validation loss: 2.0493554863878476

Epoch: 6| Step: 11
Training loss: 2.0486161708831787
Validation loss: 2.0462781536963677

Epoch: 6| Step: 12
Training loss: 2.0985050201416016
Validation loss: 2.0591435483706895

Epoch: 6| Step: 13
Training loss: 1.9035004377365112
Validation loss: 2.0353462593529814

Epoch: 39| Step: 0
Training loss: 2.0852842330932617
Validation loss: 2.0486089183438208

Epoch: 6| Step: 1
Training loss: 3.068490982055664
Validation loss: 2.036370917033124

Epoch: 6| Step: 2
Training loss: 2.6529340744018555
Validation loss: 2.047224385764009

Epoch: 6| Step: 3
Training loss: 2.4319701194763184
Validation loss: 2.042151717729466

Epoch: 6| Step: 4
Training loss: 2.6564853191375732
Validation loss: 2.052304349919801

Epoch: 6| Step: 5
Training loss: 2.2811977863311768
Validation loss: 2.044018914622645

Epoch: 6| Step: 6
Training loss: 1.8855152130126953
Validation loss: 2.0397483418064732

Epoch: 6| Step: 7
Training loss: 2.323209047317505
Validation loss: 2.0539042154947915

Epoch: 6| Step: 8
Training loss: 1.8093379735946655
Validation loss: 2.045648951684275

Epoch: 6| Step: 9
Training loss: 2.384006977081299
Validation loss: 2.0411542718128493

Epoch: 6| Step: 10
Training loss: 2.3605151176452637
Validation loss: 2.04525581482918

Epoch: 6| Step: 11
Training loss: 2.4610679149627686
Validation loss: 2.0555118078826577

Epoch: 6| Step: 12
Training loss: 1.6068148612976074
Validation loss: 2.0454605125611827

Epoch: 6| Step: 13
Training loss: 3.1721465587615967
Validation loss: 2.037233511606852

Epoch: 40| Step: 0
Training loss: 2.330923557281494
Validation loss: 2.047287082159391

Epoch: 6| Step: 1
Training loss: 2.232088565826416
Validation loss: 2.044207893392091

Epoch: 6| Step: 2
Training loss: 2.4081974029541016
Validation loss: 2.038791448839249

Epoch: 6| Step: 3
Training loss: 2.2940354347229004
Validation loss: 2.0495727805681128

Epoch: 6| Step: 4
Training loss: 2.00702166557312
Validation loss: 2.0371371187189573

Epoch: 6| Step: 5
Training loss: 2.9706130027770996
Validation loss: 2.0325746305527224

Epoch: 6| Step: 6
Training loss: 2.2087855339050293
Validation loss: 2.0410872326102307

Epoch: 6| Step: 7
Training loss: 2.6364619731903076
Validation loss: 2.0509247651664158

Epoch: 6| Step: 8
Training loss: 1.7781615257263184
Validation loss: 2.04356486053877

Epoch: 6| Step: 9
Training loss: 2.9663331508636475
Validation loss: 2.042040373689385

Epoch: 6| Step: 10
Training loss: 2.289133310317993
Validation loss: 2.04313660693425

Epoch: 6| Step: 11
Training loss: 1.665626049041748
Validation loss: 2.0533077152826453

Epoch: 6| Step: 12
Training loss: 2.8151068687438965
Validation loss: 2.04791227463753

Epoch: 6| Step: 13
Training loss: 2.0205047130584717
Validation loss: 2.037545329780989

Epoch: 41| Step: 0
Training loss: 2.2573349475860596
Validation loss: 2.0531436884275047

Epoch: 6| Step: 1
Training loss: 2.280144691467285
Validation loss: 2.0497959916309645

Epoch: 6| Step: 2
Training loss: 3.2373409271240234
Validation loss: 2.042744436571675

Epoch: 6| Step: 3
Training loss: 2.3381528854370117
Validation loss: 2.0403731843476653

Epoch: 6| Step: 4
Training loss: 2.5140058994293213
Validation loss: 2.0422341695395847

Epoch: 6| Step: 5
Training loss: 2.3306665420532227
Validation loss: 2.0315810647062076

Epoch: 6| Step: 6
Training loss: 2.2845044136047363
Validation loss: 2.043746563696092

Epoch: 6| Step: 7
Training loss: 1.8785948753356934
Validation loss: 2.0397988852634223

Epoch: 6| Step: 8
Training loss: 2.307433843612671
Validation loss: 2.0525591629807667

Epoch: 6| Step: 9
Training loss: 2.139725685119629
Validation loss: 2.0480813313555974

Epoch: 6| Step: 10
Training loss: 2.4834952354431152
Validation loss: 2.0309156397337556

Epoch: 6| Step: 11
Training loss: 2.711082696914673
Validation loss: 2.0514954802810506

Epoch: 6| Step: 12
Training loss: 1.588623285293579
Validation loss: 2.0275878444794686

Epoch: 6| Step: 13
Training loss: 2.353609085083008
Validation loss: 2.0163008102806668

Epoch: 42| Step: 0
Training loss: 2.03606915473938
Validation loss: 2.0397644465969456

Epoch: 6| Step: 1
Training loss: 2.619683265686035
Validation loss: 2.033571413768235

Epoch: 6| Step: 2
Training loss: 2.4661808013916016
Validation loss: 2.038290492949947

Epoch: 6| Step: 3
Training loss: 2.355921506881714
Validation loss: 2.0316763103649182

Epoch: 6| Step: 4
Training loss: 2.417842388153076
Validation loss: 2.03602094804087

Epoch: 6| Step: 5
Training loss: 2.1626148223876953
Validation loss: 2.032900348786385

Epoch: 6| Step: 6
Training loss: 2.1061463356018066
Validation loss: 2.0232617021888815

Epoch: 6| Step: 7
Training loss: 2.292908191680908
Validation loss: 2.0393404883723103

Epoch: 6| Step: 8
Training loss: 2.1230905055999756
Validation loss: 2.031543211270404

Epoch: 6| Step: 9
Training loss: 2.310495138168335
Validation loss: 2.031519305321478

Epoch: 6| Step: 10
Training loss: 3.2171764373779297
Validation loss: 2.0315772512907624

Epoch: 6| Step: 11
Training loss: 1.8985782861709595
Validation loss: 2.031782022086523

Epoch: 6| Step: 12
Training loss: 1.9119923114776611
Validation loss: 2.035130362356863

Epoch: 6| Step: 13
Training loss: 3.076815605163574
Validation loss: 2.0259006318225654

Epoch: 43| Step: 0
Training loss: 3.039246082305908
Validation loss: 2.0362644375011487

Epoch: 6| Step: 1
Training loss: 2.6056437492370605
Validation loss: 2.0253452011334

Epoch: 6| Step: 2
Training loss: 1.730567216873169
Validation loss: 2.017755393059023

Epoch: 6| Step: 3
Training loss: 1.9315367937088013
Validation loss: 2.0247406831351658

Epoch: 6| Step: 4
Training loss: 2.264267921447754
Validation loss: 2.0321732938930555

Epoch: 6| Step: 5
Training loss: 2.423508644104004
Validation loss: 2.040145630477577

Epoch: 6| Step: 6
Training loss: 2.419903039932251
Validation loss: 2.0417168973594584

Epoch: 6| Step: 7
Training loss: 2.102954626083374
Validation loss: 2.020536499638711

Epoch: 6| Step: 8
Training loss: 2.775071144104004
Validation loss: 2.0370145202964864

Epoch: 6| Step: 9
Training loss: 1.6528680324554443
Validation loss: 2.0286753703189153

Epoch: 6| Step: 10
Training loss: 2.110825538635254
Validation loss: 2.037673830986023

Epoch: 6| Step: 11
Training loss: 2.670760154724121
Validation loss: 2.030718443214252

Epoch: 6| Step: 12
Training loss: 2.737577438354492
Validation loss: 2.03164477245782

Epoch: 6| Step: 13
Training loss: 1.7412056922912598
Validation loss: 2.0280843011794554

Epoch: 44| Step: 0
Training loss: 2.72548770904541
Validation loss: 2.034052760370316

Epoch: 6| Step: 1
Training loss: 1.9619202613830566
Validation loss: 2.036784556604201

Epoch: 6| Step: 2
Training loss: 2.3870482444763184
Validation loss: 2.0130618515835015

Epoch: 6| Step: 3
Training loss: 2.2220635414123535
Validation loss: 2.0326743241279357

Epoch: 6| Step: 4
Training loss: 1.8201030492782593
Validation loss: 2.0258417385880665

Epoch: 6| Step: 5
Training loss: 3.016594409942627
Validation loss: 2.0154079006564234

Epoch: 6| Step: 6
Training loss: 2.494929313659668
Validation loss: 2.043253262837728

Epoch: 6| Step: 7
Training loss: 2.5683794021606445
Validation loss: 2.0262166633400867

Epoch: 6| Step: 8
Training loss: 2.2436110973358154
Validation loss: 2.050840787990119

Epoch: 6| Step: 9
Training loss: 2.0132088661193848
Validation loss: 2.0231564532044115

Epoch: 6| Step: 10
Training loss: 3.038051128387451
Validation loss: 2.028481601386942

Epoch: 6| Step: 11
Training loss: 1.77360999584198
Validation loss: 2.0128650678101407

Epoch: 6| Step: 12
Training loss: 1.7354304790496826
Validation loss: 2.023510412503314

Epoch: 6| Step: 13
Training loss: 2.4907994270324707
Validation loss: 2.025735124464958

Epoch: 45| Step: 0
Training loss: 2.082693099975586
Validation loss: 2.0228659850294872

Epoch: 6| Step: 1
Training loss: 1.7852122783660889
Validation loss: 1.9987603400343208

Epoch: 6| Step: 2
Training loss: 2.4700703620910645
Validation loss: 2.0246962578065935

Epoch: 6| Step: 3
Training loss: 2.60610294342041
Validation loss: 2.0270753752800728

Epoch: 6| Step: 4
Training loss: 2.585205078125
Validation loss: 2.027004293216172

Epoch: 6| Step: 5
Training loss: 2.177011013031006
Validation loss: 2.016884339753018

Epoch: 6| Step: 6
Training loss: 2.4469656944274902
Validation loss: 2.025178814447054

Epoch: 6| Step: 7
Training loss: 2.5868592262268066
Validation loss: 2.0302966589568765

Epoch: 6| Step: 8
Training loss: 2.3113269805908203
Validation loss: 2.0180084192624657

Epoch: 6| Step: 9
Training loss: 2.5016088485717773
Validation loss: 2.01565642510691

Epoch: 6| Step: 10
Training loss: 2.1488070487976074
Validation loss: 2.0121279429363947

Epoch: 6| Step: 11
Training loss: 1.8201904296875
Validation loss: 2.030261108952184

Epoch: 6| Step: 12
Training loss: 2.7644381523132324
Validation loss: 2.0303095617601947

Epoch: 6| Step: 13
Training loss: 2.0598177909851074
Validation loss: 2.0296949981361307

Epoch: 46| Step: 0
Training loss: 2.3845226764678955
Validation loss: 2.022987610550337

Epoch: 6| Step: 1
Training loss: 2.4603347778320312
Validation loss: 2.023518708444411

Epoch: 6| Step: 2
Training loss: 2.3976290225982666
Validation loss: 2.017135202243764

Epoch: 6| Step: 3
Training loss: 1.990539789199829
Validation loss: 2.0200496719729517

Epoch: 6| Step: 4
Training loss: 2.6543850898742676
Validation loss: 2.01799363218328

Epoch: 6| Step: 5
Training loss: 1.5492441654205322
Validation loss: 2.009098566988463

Epoch: 6| Step: 6
Training loss: 3.095146656036377
Validation loss: 2.0066678498380925

Epoch: 6| Step: 7
Training loss: 2.541341781616211
Validation loss: 2.017887423115392

Epoch: 6| Step: 8
Training loss: 1.8434123992919922
Validation loss: 2.018319435017083

Epoch: 6| Step: 9
Training loss: 1.831499457359314
Validation loss: 2.020213039972449

Epoch: 6| Step: 10
Training loss: 2.166785717010498
Validation loss: 2.0143086961520615

Epoch: 6| Step: 11
Training loss: 2.469733715057373
Validation loss: 2.0274508935149

Epoch: 6| Step: 12
Training loss: 2.3615469932556152
Validation loss: 2.0242045464054232

Epoch: 6| Step: 13
Training loss: 2.7989156246185303
Validation loss: 2.020462368124275

Epoch: 47| Step: 0
Training loss: 2.4996144771575928
Validation loss: 2.0225831116399458

Epoch: 6| Step: 1
Training loss: 1.996145486831665
Validation loss: 2.0017520368740125

Epoch: 6| Step: 2
Training loss: 2.2903363704681396
Validation loss: 2.0150313479925996

Epoch: 6| Step: 3
Training loss: 2.3141794204711914
Validation loss: 2.0307499939395535

Epoch: 6| Step: 4
Training loss: 2.3485207557678223
Validation loss: 2.024402165925631

Epoch: 6| Step: 5
Training loss: 2.3404245376586914
Validation loss: 2.0170018672943115

Epoch: 6| Step: 6
Training loss: 2.689706325531006
Validation loss: 2.0284421187575146

Epoch: 6| Step: 7
Training loss: 2.571652889251709
Validation loss: 2.0236369935415124

Epoch: 6| Step: 8
Training loss: 2.44970965385437
Validation loss: 2.024063966607535

Epoch: 6| Step: 9
Training loss: 2.2337656021118164
Validation loss: 2.0415365875408216

Epoch: 6| Step: 10
Training loss: 2.306199550628662
Validation loss: 2.0211145672746884

Epoch: 6| Step: 11
Training loss: 2.0696868896484375
Validation loss: 2.0148311994409047

Epoch: 6| Step: 12
Training loss: 2.008033275604248
Validation loss: 2.0115342627289476

Epoch: 6| Step: 13
Training loss: 1.997841715812683
Validation loss: 2.0260956082292783

Epoch: 48| Step: 0
Training loss: 2.1059651374816895
Validation loss: 2.0167432831179712

Epoch: 6| Step: 1
Training loss: 2.251756429672241
Validation loss: 2.0371074484240626

Epoch: 6| Step: 2
Training loss: 2.589078903198242
Validation loss: 2.002459015897525

Epoch: 6| Step: 3
Training loss: 1.9284785985946655
Validation loss: 2.0035089908107633

Epoch: 6| Step: 4
Training loss: 2.503235340118408
Validation loss: 2.002480870933943

Epoch: 6| Step: 5
Training loss: 2.8908700942993164
Validation loss: 2.003442177208521

Epoch: 6| Step: 6
Training loss: 2.3414530754089355
Validation loss: 2.0223456915988716

Epoch: 6| Step: 7
Training loss: 2.4268436431884766
Validation loss: 2.0227298736572266

Epoch: 6| Step: 8
Training loss: 1.8868529796600342
Validation loss: 2.0087662832711333

Epoch: 6| Step: 9
Training loss: 1.9750699996948242
Validation loss: 2.021135078963413

Epoch: 6| Step: 10
Training loss: 2.7207460403442383
Validation loss: 2.0117718237702564

Epoch: 6| Step: 11
Training loss: 2.423693895339966
Validation loss: 1.9967422023896249

Epoch: 6| Step: 12
Training loss: 2.058391571044922
Validation loss: 2.0031372936823035

Epoch: 6| Step: 13
Training loss: 1.862009882926941
Validation loss: 2.0142730154016966

Epoch: 49| Step: 0
Training loss: 1.9973995685577393
Validation loss: 2.028546510204192

Epoch: 6| Step: 1
Training loss: 2.8482613563537598
Validation loss: 2.01015890541897

Epoch: 6| Step: 2
Training loss: 2.286998748779297
Validation loss: 2.0123749138206564

Epoch: 6| Step: 3
Training loss: 2.7189202308654785
Validation loss: 2.0050956997820126

Epoch: 6| Step: 4
Training loss: 2.7085437774658203
Validation loss: 2.0105395752896547

Epoch: 6| Step: 5
Training loss: 1.8402937650680542
Validation loss: 1.9991711647279802

Epoch: 6| Step: 6
Training loss: 2.6018686294555664
Validation loss: 2.02520759900411

Epoch: 6| Step: 7
Training loss: 2.779266595840454
Validation loss: 2.0089769209584882

Epoch: 6| Step: 8
Training loss: 2.4193170070648193
Validation loss: 2.009091338803691

Epoch: 6| Step: 9
Training loss: 2.4929563999176025
Validation loss: 2.006739447193761

Epoch: 6| Step: 10
Training loss: 2.0129668712615967
Validation loss: 2.003709771299875

Epoch: 6| Step: 11
Training loss: 1.9724256992340088
Validation loss: 2.0142652078341414

Epoch: 6| Step: 12
Training loss: 1.2658665180206299
Validation loss: 2.0078473719217445

Epoch: 6| Step: 13
Training loss: 2.1522951126098633
Validation loss: 2.01055702470964

Epoch: 50| Step: 0
Training loss: 3.0797574520111084
Validation loss: 2.027471500058328

Epoch: 6| Step: 1
Training loss: 2.06038761138916
Validation loss: 2.0143893444409935

Epoch: 6| Step: 2
Training loss: 2.351747989654541
Validation loss: 1.9920806679674374

Epoch: 6| Step: 3
Training loss: 2.019899368286133
Validation loss: 2.003623834220312

Epoch: 6| Step: 4
Training loss: 2.3976197242736816
Validation loss: 2.0065076966439523

Epoch: 6| Step: 5
Training loss: 2.496825695037842
Validation loss: 2.015466114526154

Epoch: 6| Step: 6
Training loss: 2.3556103706359863
Validation loss: 2.014266921627906

Epoch: 6| Step: 7
Training loss: 1.8778884410858154
Validation loss: 2.0029737744280087

Epoch: 6| Step: 8
Training loss: 2.0740199089050293
Validation loss: 2.0190644674403693

Epoch: 6| Step: 9
Training loss: 2.3878791332244873
Validation loss: 2.032101559382613

Epoch: 6| Step: 10
Training loss: 2.55716609954834
Validation loss: 2.0348044954320437

Epoch: 6| Step: 11
Training loss: 2.424192428588867
Validation loss: 2.001102360345984

Epoch: 6| Step: 12
Training loss: 2.0468106269836426
Validation loss: 2.0203050362166537

Epoch: 6| Step: 13
Training loss: 1.6442203521728516
Validation loss: 2.011018435160319

Epoch: 51| Step: 0
Training loss: 2.56510591506958
Validation loss: 2.0053132105899114

Epoch: 6| Step: 1
Training loss: 2.013641834259033
Validation loss: 2.012602117753798

Epoch: 6| Step: 2
Training loss: 2.7615556716918945
Validation loss: 2.009752027450069

Epoch: 6| Step: 3
Training loss: 1.9762394428253174
Validation loss: 2.0125554133487005

Epoch: 6| Step: 4
Training loss: 2.272524356842041
Validation loss: 2.024727270167361

Epoch: 6| Step: 5
Training loss: 1.6189595460891724
Validation loss: 2.007685230624291

Epoch: 6| Step: 6
Training loss: 2.483835220336914
Validation loss: 2.0004582366635724

Epoch: 6| Step: 7
Training loss: 2.0812087059020996
Validation loss: 2.005641142527262

Epoch: 6| Step: 8
Training loss: 2.3020317554473877
Validation loss: 2.0056136115904777

Epoch: 6| Step: 9
Training loss: 2.463545799255371
Validation loss: 2.003851011235227

Epoch: 6| Step: 10
Training loss: 2.1061673164367676
Validation loss: 2.005826937255039

Epoch: 6| Step: 11
Training loss: 2.4716970920562744
Validation loss: 1.9929723637078398

Epoch: 6| Step: 12
Training loss: 2.419919967651367
Validation loss: 1.9824871324723767

Epoch: 6| Step: 13
Training loss: 2.444045066833496
Validation loss: 1.9914626921376875

Epoch: 52| Step: 0
Training loss: 1.844191551208496
Validation loss: 1.9935706200138215

Epoch: 6| Step: 1
Training loss: 2.104703903198242
Validation loss: 1.9951209329789685

Epoch: 6| Step: 2
Training loss: 2.640137195587158
Validation loss: 2.010423114222865

Epoch: 6| Step: 3
Training loss: 2.046717405319214
Validation loss: 2.0020217857053204

Epoch: 6| Step: 4
Training loss: 1.4071060419082642
Validation loss: 2.016131538216786

Epoch: 6| Step: 5
Training loss: 1.8673231601715088
Validation loss: 1.9945242968938683

Epoch: 6| Step: 6
Training loss: 2.439244508743286
Validation loss: 1.9923013922988728

Epoch: 6| Step: 7
Training loss: 2.347055435180664
Validation loss: 2.0120102692675847

Epoch: 6| Step: 8
Training loss: 2.1719167232513428
Validation loss: 1.9883570260899042

Epoch: 6| Step: 9
Training loss: 2.4589080810546875
Validation loss: 1.9996395264902422

Epoch: 6| Step: 10
Training loss: 2.9146132469177246
Validation loss: 1.9996002386975031

Epoch: 6| Step: 11
Training loss: 3.118372917175293
Validation loss: 1.9970988996567265

Epoch: 6| Step: 12
Training loss: 2.8031249046325684
Validation loss: 1.9997252623240154

Epoch: 6| Step: 13
Training loss: 1.5659985542297363
Validation loss: 2.002497652525543

Epoch: 53| Step: 0
Training loss: 1.9520065784454346
Validation loss: 2.009501279041331

Epoch: 6| Step: 1
Training loss: 2.51108717918396
Validation loss: 1.995353062947591

Epoch: 6| Step: 2
Training loss: 1.9090160131454468
Validation loss: 1.9925871741387151

Epoch: 6| Step: 3
Training loss: 2.571044445037842
Validation loss: 1.978415777606349

Epoch: 6| Step: 4
Training loss: 1.6963248252868652
Validation loss: 1.981834118084241

Epoch: 6| Step: 5
Training loss: 2.760613441467285
Validation loss: 1.9926809059676303

Epoch: 6| Step: 6
Training loss: 2.5588550567626953
Validation loss: 2.0081280482712613

Epoch: 6| Step: 7
Training loss: 2.141617774963379
Validation loss: 2.0017266658044632

Epoch: 6| Step: 8
Training loss: 2.882063865661621
Validation loss: 1.9960828032544864

Epoch: 6| Step: 9
Training loss: 1.8250808715820312
Validation loss: 2.00387054874051

Epoch: 6| Step: 10
Training loss: 2.190781593322754
Validation loss: 1.995167229765205

Epoch: 6| Step: 11
Training loss: 2.0158004760742188
Validation loss: 1.9830126506026073

Epoch: 6| Step: 12
Training loss: 2.4014859199523926
Validation loss: 1.9974945898978942

Epoch: 6| Step: 13
Training loss: 2.6619741916656494
Validation loss: 1.987313324405301

Epoch: 54| Step: 0
Training loss: 2.563734531402588
Validation loss: 2.0031496222301195

Epoch: 6| Step: 1
Training loss: 2.3842663764953613
Validation loss: 2.006770363418005

Epoch: 6| Step: 2
Training loss: 2.312119245529175
Validation loss: 2.005227364519591

Epoch: 6| Step: 3
Training loss: 3.1160950660705566
Validation loss: 1.9939837263476463

Epoch: 6| Step: 4
Training loss: 2.1346888542175293
Validation loss: 1.9950106284951652

Epoch: 6| Step: 5
Training loss: 2.0981459617614746
Validation loss: 1.9933250847683157

Epoch: 6| Step: 6
Training loss: 1.8964712619781494
Validation loss: 2.0032778837347545

Epoch: 6| Step: 7
Training loss: 2.0132761001586914
Validation loss: 2.0135463937636344

Epoch: 6| Step: 8
Training loss: 2.5284857749938965
Validation loss: 1.997963825861613

Epoch: 6| Step: 9
Training loss: 1.9873809814453125
Validation loss: 2.0038853024923675

Epoch: 6| Step: 10
Training loss: 2.6786346435546875
Validation loss: 2.012461552055933

Epoch: 6| Step: 11
Training loss: 2.3132379055023193
Validation loss: 1.9992159643480856

Epoch: 6| Step: 12
Training loss: 1.9791688919067383
Validation loss: 2.0016131208788965

Epoch: 6| Step: 13
Training loss: 1.259864330291748
Validation loss: 2.01041672050312

Epoch: 55| Step: 0
Training loss: 1.8677000999450684
Validation loss: 2.0102420686393656

Epoch: 6| Step: 1
Training loss: 2.4308226108551025
Validation loss: 1.9939597242621965

Epoch: 6| Step: 2
Training loss: 1.9016448259353638
Validation loss: 1.9949251861982449

Epoch: 6| Step: 3
Training loss: 2.9523489475250244
Validation loss: 1.9953700188667542

Epoch: 6| Step: 4
Training loss: 2.1312615871429443
Validation loss: 2.0067033998427855

Epoch: 6| Step: 5
Training loss: 1.841884970664978
Validation loss: 2.001393352785418

Epoch: 6| Step: 6
Training loss: 1.9766069650650024
Validation loss: 2.006095773430281

Epoch: 6| Step: 7
Training loss: 2.0401053428649902
Validation loss: 2.005567818559626

Epoch: 6| Step: 8
Training loss: 2.4886674880981445
Validation loss: 2.0133157545520413

Epoch: 6| Step: 9
Training loss: 3.4034852981567383
Validation loss: 2.000957409540812

Epoch: 6| Step: 10
Training loss: 2.135653495788574
Validation loss: 2.0093644921497633

Epoch: 6| Step: 11
Training loss: 2.261181354522705
Validation loss: 2.0064934376747376

Epoch: 6| Step: 12
Training loss: 2.2089390754699707
Validation loss: 2.0067190675325293

Epoch: 6| Step: 13
Training loss: 1.8341799974441528
Validation loss: 1.999376158560476

Epoch: 56| Step: 0
Training loss: 2.6012020111083984
Validation loss: 1.995197185906031

Epoch: 6| Step: 1
Training loss: 2.3427515029907227
Validation loss: 1.9978532445046209

Epoch: 6| Step: 2
Training loss: 2.3949990272521973
Validation loss: 2.003453298281598

Epoch: 6| Step: 3
Training loss: 2.1105732917785645
Validation loss: 1.9932176092619538

Epoch: 6| Step: 4
Training loss: 2.5345959663391113
Validation loss: 1.9943897442151142

Epoch: 6| Step: 5
Training loss: 1.9620015621185303
Validation loss: 1.9885703222725981

Epoch: 6| Step: 6
Training loss: 2.598740577697754
Validation loss: 1.99876154622724

Epoch: 6| Step: 7
Training loss: 2.1189684867858887
Validation loss: 1.9994304257054483

Epoch: 6| Step: 8
Training loss: 2.290872573852539
Validation loss: 1.99783282895242

Epoch: 6| Step: 9
Training loss: 2.0955405235290527
Validation loss: 1.9879579902977071

Epoch: 6| Step: 10
Training loss: 2.4001455307006836
Validation loss: 1.9954028155214043

Epoch: 6| Step: 11
Training loss: 2.069716691970825
Validation loss: 2.0036978849800686

Epoch: 6| Step: 12
Training loss: 1.7417712211608887
Validation loss: 1.9887989208262453

Epoch: 6| Step: 13
Training loss: 2.4798498153686523
Validation loss: 1.9798804983015983

Epoch: 57| Step: 0
Training loss: 2.8143084049224854
Validation loss: 1.986185102052586

Epoch: 6| Step: 1
Training loss: 2.955064535140991
Validation loss: 2.0002044477770404

Epoch: 6| Step: 2
Training loss: 2.3195109367370605
Validation loss: 1.994845845366037

Epoch: 6| Step: 3
Training loss: 1.73017418384552
Validation loss: 2.002329699454769

Epoch: 6| Step: 4
Training loss: 2.452244281768799
Validation loss: 1.9993167538796701

Epoch: 6| Step: 5
Training loss: 2.4447991847991943
Validation loss: 1.986672160446003

Epoch: 6| Step: 6
Training loss: 2.2105979919433594
Validation loss: 1.9839154366523988

Epoch: 6| Step: 7
Training loss: 2.335073471069336
Validation loss: 1.9881011952636063

Epoch: 6| Step: 8
Training loss: 1.7335309982299805
Validation loss: 1.987416475049911

Epoch: 6| Step: 9
Training loss: 1.7884316444396973
Validation loss: 1.9851572718671573

Epoch: 6| Step: 10
Training loss: 2.0137763023376465
Validation loss: 1.9886038457193682

Epoch: 6| Step: 11
Training loss: 1.9234693050384521
Validation loss: 1.9918058867095618

Epoch: 6| Step: 12
Training loss: 2.7179088592529297
Validation loss: 1.9902353222652147

Epoch: 6| Step: 13
Training loss: 2.3731753826141357
Validation loss: 1.9919775903865855

Epoch: 58| Step: 0
Training loss: 2.449380397796631
Validation loss: 1.992067842073338

Epoch: 6| Step: 1
Training loss: 2.59059476852417
Validation loss: 1.982980961440712

Epoch: 6| Step: 2
Training loss: 2.420276641845703
Validation loss: 1.9968064190239034

Epoch: 6| Step: 3
Training loss: 1.561057209968567
Validation loss: 1.991685172562958

Epoch: 6| Step: 4
Training loss: 2.6667089462280273
Validation loss: 1.9883967240651448

Epoch: 6| Step: 5
Training loss: 2.253073215484619
Validation loss: 1.9885053288552068

Epoch: 6| Step: 6
Training loss: 2.427183151245117
Validation loss: 1.9778879406631633

Epoch: 6| Step: 7
Training loss: 2.287898302078247
Validation loss: 1.9865053866499214

Epoch: 6| Step: 8
Training loss: 2.2663350105285645
Validation loss: 1.9781550309991325

Epoch: 6| Step: 9
Training loss: 2.242183208465576
Validation loss: 1.970107973262828

Epoch: 6| Step: 10
Training loss: 2.699234962463379
Validation loss: 1.9733702162260651

Epoch: 6| Step: 11
Training loss: 1.8555556535720825
Validation loss: 1.9838573573738016

Epoch: 6| Step: 12
Training loss: 1.8148568868637085
Validation loss: 1.9810102050022413

Epoch: 6| Step: 13
Training loss: 2.073110342025757
Validation loss: 1.9954500300909883

Epoch: 59| Step: 0
Training loss: 2.155038833618164
Validation loss: 1.985264419227518

Epoch: 6| Step: 1
Training loss: 2.467047691345215
Validation loss: 1.981537526653659

Epoch: 6| Step: 2
Training loss: 2.4280502796173096
Validation loss: 2.0048990070178943

Epoch: 6| Step: 3
Training loss: 2.425525188446045
Validation loss: 1.9922607252674718

Epoch: 6| Step: 4
Training loss: 2.299391746520996
Validation loss: 1.9826793504017655

Epoch: 6| Step: 5
Training loss: 2.8067092895507812
Validation loss: 1.97830186095289

Epoch: 6| Step: 6
Training loss: 1.9133011102676392
Validation loss: 2.015065825113686

Epoch: 6| Step: 7
Training loss: 2.2870006561279297
Validation loss: 1.9822943210601807

Epoch: 6| Step: 8
Training loss: 2.0549774169921875
Validation loss: 1.9875219483529367

Epoch: 6| Step: 9
Training loss: 2.845635175704956
Validation loss: 1.9946401516596477

Epoch: 6| Step: 10
Training loss: 1.8139042854309082
Validation loss: 1.9957466253670313

Epoch: 6| Step: 11
Training loss: 1.8888148069381714
Validation loss: 2.005752517331031

Epoch: 6| Step: 12
Training loss: 1.7899606227874756
Validation loss: 1.9931568804607596

Epoch: 6| Step: 13
Training loss: 2.286525249481201
Validation loss: 1.9946518008426954

Epoch: 60| Step: 0
Training loss: 2.6681671142578125
Validation loss: 1.992968297773792

Epoch: 6| Step: 1
Training loss: 2.1683707237243652
Validation loss: 1.9980325314306444

Epoch: 6| Step: 2
Training loss: 2.2048001289367676
Validation loss: 1.9777505897706555

Epoch: 6| Step: 3
Training loss: 2.418488025665283
Validation loss: 2.00177409443804

Epoch: 6| Step: 4
Training loss: 2.7616794109344482
Validation loss: 2.013974881941272

Epoch: 6| Step: 5
Training loss: 1.4751389026641846
Validation loss: 1.9794741381881058

Epoch: 6| Step: 6
Training loss: 2.4521775245666504
Validation loss: 1.9883052469581686

Epoch: 6| Step: 7
Training loss: 2.079566240310669
Validation loss: 2.0048761701071136

Epoch: 6| Step: 8
Training loss: 1.7723506689071655
Validation loss: 2.0002940367626887

Epoch: 6| Step: 9
Training loss: 2.19942569732666
Validation loss: 1.9880768458048503

Epoch: 6| Step: 10
Training loss: 2.4285104274749756
Validation loss: 1.9944109775686776

Epoch: 6| Step: 11
Training loss: 2.0963492393493652
Validation loss: 2.000153510801254

Epoch: 6| Step: 12
Training loss: 2.0011937618255615
Validation loss: 1.9816514343343756

Epoch: 6| Step: 13
Training loss: 3.364997386932373
Validation loss: 1.9733688267328406

Epoch: 61| Step: 0
Training loss: 1.8353389501571655
Validation loss: 1.9891007869474349

Epoch: 6| Step: 1
Training loss: 1.5693563222885132
Validation loss: 1.9939485416617444

Epoch: 6| Step: 2
Training loss: 3.3637092113494873
Validation loss: 1.9861810463731007

Epoch: 6| Step: 3
Training loss: 2.8416805267333984
Validation loss: 1.9944282116428498

Epoch: 6| Step: 4
Training loss: 2.324138879776001
Validation loss: 1.9801588558381604

Epoch: 6| Step: 5
Training loss: 2.448655843734741
Validation loss: 1.9764954197791316

Epoch: 6| Step: 6
Training loss: 2.0832359790802
Validation loss: 2.002237699365103

Epoch: 6| Step: 7
Training loss: 2.4172935485839844
Validation loss: 1.9646174548774638

Epoch: 6| Step: 8
Training loss: 2.1670010089874268
Validation loss: 1.9787075558016378

Epoch: 6| Step: 9
Training loss: 1.8342502117156982
Validation loss: 1.974517301846576

Epoch: 6| Step: 10
Training loss: 2.5227463245391846
Validation loss: 1.9820586327583558

Epoch: 6| Step: 11
Training loss: 2.023045539855957
Validation loss: 1.9799196053576726

Epoch: 6| Step: 12
Training loss: 1.6450049877166748
Validation loss: 1.9676264665460075

Epoch: 6| Step: 13
Training loss: 2.6349992752075195
Validation loss: 1.988201190066594

Epoch: 62| Step: 0
Training loss: 1.8801676034927368
Validation loss: 1.9906930590188632

Epoch: 6| Step: 1
Training loss: 2.7317662239074707
Validation loss: 2.00673157681701

Epoch: 6| Step: 2
Training loss: 2.67577862739563
Validation loss: 1.9682496516935286

Epoch: 6| Step: 3
Training loss: 2.5974884033203125
Validation loss: 2.003462658133558

Epoch: 6| Step: 4
Training loss: 2.47670841217041
Validation loss: 1.9860348547658613

Epoch: 6| Step: 5
Training loss: 2.190164566040039
Validation loss: 1.9945150985512683

Epoch: 6| Step: 6
Training loss: 2.082902669906616
Validation loss: 1.9916103347655265

Epoch: 6| Step: 7
Training loss: 1.8456835746765137
Validation loss: 1.9884278248715144

Epoch: 6| Step: 8
Training loss: 2.3776960372924805
Validation loss: 1.9910872200483918

Epoch: 6| Step: 9
Training loss: 1.9493004083633423
Validation loss: 1.9896812887601956

Epoch: 6| Step: 10
Training loss: 2.3429017066955566
Validation loss: 2.0015060735005203

Epoch: 6| Step: 11
Training loss: 1.8234093189239502
Validation loss: 1.989480064761254

Epoch: 6| Step: 12
Training loss: 2.227433204650879
Validation loss: 2.0082296094586773

Epoch: 6| Step: 13
Training loss: 2.3260960578918457
Validation loss: 2.0159973893114316

Epoch: 63| Step: 0
Training loss: 3.257904052734375
Validation loss: 1.9900240744313886

Epoch: 6| Step: 1
Training loss: 2.094149589538574
Validation loss: 1.9901988967772453

Epoch: 6| Step: 2
Training loss: 2.1719141006469727
Validation loss: 2.0058639434076126

Epoch: 6| Step: 3
Training loss: 2.224493980407715
Validation loss: 1.9987961502485379

Epoch: 6| Step: 4
Training loss: 1.8794509172439575
Validation loss: 1.9923882792072911

Epoch: 6| Step: 5
Training loss: 2.34399676322937
Validation loss: 2.003114438826038

Epoch: 6| Step: 6
Training loss: 2.160017490386963
Validation loss: 1.99559449636808

Epoch: 6| Step: 7
Training loss: 1.7726459503173828
Validation loss: 2.0092076614338863

Epoch: 6| Step: 8
Training loss: 1.978576898574829
Validation loss: 2.0103700250707646

Epoch: 6| Step: 9
Training loss: 2.7113804817199707
Validation loss: 1.994413686055009

Epoch: 6| Step: 10
Training loss: 2.419189929962158
Validation loss: 1.9866319394880725

Epoch: 6| Step: 11
Training loss: 2.142693042755127
Validation loss: 1.979716104845847

Epoch: 6| Step: 12
Training loss: 2.172940254211426
Validation loss: 1.9824576711141935

Epoch: 6| Step: 13
Training loss: 1.9076207876205444
Validation loss: 1.9947408322365052

Epoch: 64| Step: 0
Training loss: 2.451681613922119
Validation loss: 1.9807691599733086

Epoch: 6| Step: 1
Training loss: 2.130012035369873
Validation loss: 1.9967211266999603

Epoch: 6| Step: 2
Training loss: 2.3726086616516113
Validation loss: 1.9961162177465295

Epoch: 6| Step: 3
Training loss: 2.0126609802246094
Validation loss: 1.9734745717817737

Epoch: 6| Step: 4
Training loss: 2.5222954750061035
Validation loss: 1.9826221363518828

Epoch: 6| Step: 5
Training loss: 2.511533260345459
Validation loss: 1.9895915754379765

Epoch: 6| Step: 6
Training loss: 1.8838073015213013
Validation loss: 1.9759645564581758

Epoch: 6| Step: 7
Training loss: 1.7989983558654785
Validation loss: 1.9714638084493659

Epoch: 6| Step: 8
Training loss: 2.801271915435791
Validation loss: 1.9909610825200235

Epoch: 6| Step: 9
Training loss: 2.50496244430542
Validation loss: 1.9812760635088849

Epoch: 6| Step: 10
Training loss: 2.067075729370117
Validation loss: 1.9791392741664764

Epoch: 6| Step: 11
Training loss: 1.7171800136566162
Validation loss: 1.9867580026708624

Epoch: 6| Step: 12
Training loss: 2.0147595405578613
Validation loss: 1.9835042979127617

Epoch: 6| Step: 13
Training loss: 2.6390864849090576
Validation loss: 1.9946620182324482

Epoch: 65| Step: 0
Training loss: 2.317047119140625
Validation loss: 1.9765065652067944

Epoch: 6| Step: 1
Training loss: 1.6536884307861328
Validation loss: 1.973920650379632

Epoch: 6| Step: 2
Training loss: 2.3240389823913574
Validation loss: 1.9881320973878265

Epoch: 6| Step: 3
Training loss: 1.9947350025177002
Validation loss: 1.9891196630334342

Epoch: 6| Step: 4
Training loss: 2.288440704345703
Validation loss: 1.967242952316038

Epoch: 6| Step: 5
Training loss: 2.167613983154297
Validation loss: 1.9671328336961809

Epoch: 6| Step: 6
Training loss: 2.2289326190948486
Validation loss: 1.9650976901413293

Epoch: 6| Step: 7
Training loss: 2.4515838623046875
Validation loss: 1.9707457352710027

Epoch: 6| Step: 8
Training loss: 1.9954124689102173
Validation loss: 1.9632871112515848

Epoch: 6| Step: 9
Training loss: 2.2504453659057617
Validation loss: 1.962485699243443

Epoch: 6| Step: 10
Training loss: 2.320777416229248
Validation loss: 1.9533168961924892

Epoch: 6| Step: 11
Training loss: 2.3414571285247803
Validation loss: 1.9687183416017922

Epoch: 6| Step: 12
Training loss: 3.071441173553467
Validation loss: 1.9479495427941764

Epoch: 6| Step: 13
Training loss: 1.836998462677002
Validation loss: 1.9690876865899691

Epoch: 66| Step: 0
Training loss: 2.8096675872802734
Validation loss: 1.9554666267928256

Epoch: 6| Step: 1
Training loss: 2.323009490966797
Validation loss: 1.978948890521962

Epoch: 6| Step: 2
Training loss: 1.749521255493164
Validation loss: 1.9510432186947073

Epoch: 6| Step: 3
Training loss: 2.4247429370880127
Validation loss: 1.9764966451993553

Epoch: 6| Step: 4
Training loss: 1.5603935718536377
Validation loss: 1.965351794355659

Epoch: 6| Step: 5
Training loss: 1.9152748584747314
Validation loss: 1.9841174066707652

Epoch: 6| Step: 6
Training loss: 2.190784454345703
Validation loss: 1.9736094782429356

Epoch: 6| Step: 7
Training loss: 2.341646432876587
Validation loss: 1.9583435712322113

Epoch: 6| Step: 8
Training loss: 2.2727224826812744
Validation loss: 1.968997727158249

Epoch: 6| Step: 9
Training loss: 2.477510690689087
Validation loss: 1.9797231215302662

Epoch: 6| Step: 10
Training loss: 2.1818017959594727
Validation loss: 1.9670106800653602

Epoch: 6| Step: 11
Training loss: 1.9449557065963745
Validation loss: 1.9799562615732993

Epoch: 6| Step: 12
Training loss: 2.269308090209961
Validation loss: 1.9958216951739403

Epoch: 6| Step: 13
Training loss: 3.213624954223633
Validation loss: 1.9616045080205446

Epoch: 67| Step: 0
Training loss: 2.357856273651123
Validation loss: 1.977213728812433

Epoch: 6| Step: 1
Training loss: 2.347170352935791
Validation loss: 1.9718047059992307

Epoch: 6| Step: 2
Training loss: 2.039811372756958
Validation loss: 1.9754576093407088

Epoch: 6| Step: 3
Training loss: 2.0204789638519287
Validation loss: 1.985112201782965

Epoch: 6| Step: 4
Training loss: 2.2114157676696777
Validation loss: 1.9784190424026982

Epoch: 6| Step: 5
Training loss: 1.7369862794876099
Validation loss: 1.9597406412965508

Epoch: 6| Step: 6
Training loss: 2.615326404571533
Validation loss: 1.981601171596076

Epoch: 6| Step: 7
Training loss: 2.1537303924560547
Validation loss: 1.9942157704343078

Epoch: 6| Step: 8
Training loss: 1.9205260276794434
Validation loss: 2.0003279819283435

Epoch: 6| Step: 9
Training loss: 2.3893685340881348
Validation loss: 1.9756927926053283

Epoch: 6| Step: 10
Training loss: 2.43353533744812
Validation loss: 1.994920922863868

Epoch: 6| Step: 11
Training loss: 1.9609224796295166
Validation loss: 1.990398419800625

Epoch: 6| Step: 12
Training loss: 2.5783920288085938
Validation loss: 1.9812844453319427

Epoch: 6| Step: 13
Training loss: 2.4804224967956543
Validation loss: 2.00026108372596

Epoch: 68| Step: 0
Training loss: 1.4576268196105957
Validation loss: 1.9799752261049004

Epoch: 6| Step: 1
Training loss: 2.487767219543457
Validation loss: 2.0007246284074682

Epoch: 6| Step: 2
Training loss: 2.029620409011841
Validation loss: 2.000402009615334

Epoch: 6| Step: 3
Training loss: 2.0898330211639404
Validation loss: 1.975318283163091

Epoch: 6| Step: 4
Training loss: 2.2924933433532715
Validation loss: 1.9923555979164698

Epoch: 6| Step: 5
Training loss: 2.26989483833313
Validation loss: 1.9830560722658712

Epoch: 6| Step: 6
Training loss: 1.6190677881240845
Validation loss: 2.0122614317042853

Epoch: 6| Step: 7
Training loss: 2.1847734451293945
Validation loss: 1.972935873975036

Epoch: 6| Step: 8
Training loss: 2.5510451793670654
Validation loss: 1.9757892931661298

Epoch: 6| Step: 9
Training loss: 2.0480244159698486
Validation loss: 1.9940249919891357

Epoch: 6| Step: 10
Training loss: 2.1581172943115234
Validation loss: 1.9797638872618317

Epoch: 6| Step: 11
Training loss: 3.4584946632385254
Validation loss: 1.9656436738147531

Epoch: 6| Step: 12
Training loss: 2.018115520477295
Validation loss: 1.9836114811640915

Epoch: 6| Step: 13
Training loss: 2.689014434814453
Validation loss: 1.9924296948217577

Epoch: 69| Step: 0
Training loss: 1.8301756381988525
Validation loss: 1.9634086393540906

Epoch: 6| Step: 1
Training loss: 2.6366796493530273
Validation loss: 1.9878089145947528

Epoch: 6| Step: 2
Training loss: 1.2809526920318604
Validation loss: 1.9800752196260678

Epoch: 6| Step: 3
Training loss: 2.0571706295013428
Validation loss: 1.9893879736623457

Epoch: 6| Step: 4
Training loss: 2.256913185119629
Validation loss: 1.989622607026049

Epoch: 6| Step: 5
Training loss: 2.192962169647217
Validation loss: 1.972064466886623

Epoch: 6| Step: 6
Training loss: 1.9859895706176758
Validation loss: 1.9829882267982728

Epoch: 6| Step: 7
Training loss: 2.4975686073303223
Validation loss: 1.9827271584541566

Epoch: 6| Step: 8
Training loss: 1.7201616764068604
Validation loss: 1.9798036454826273

Epoch: 6| Step: 9
Training loss: 2.8622052669525146
Validation loss: 1.987084355405582

Epoch: 6| Step: 10
Training loss: 2.5236318111419678
Validation loss: 1.986242373784383

Epoch: 6| Step: 11
Training loss: 2.389951229095459
Validation loss: 1.9918938964925788

Epoch: 6| Step: 12
Training loss: 2.6576168537139893
Validation loss: 1.9895790623080345

Epoch: 6| Step: 13
Training loss: 2.116953134536743
Validation loss: 1.9813122685237596

Epoch: 70| Step: 0
Training loss: 1.9801188707351685
Validation loss: 1.9794223680291125

Epoch: 6| Step: 1
Training loss: 2.558441638946533
Validation loss: 1.98189502890392

Epoch: 6| Step: 2
Training loss: 1.835841417312622
Validation loss: 1.9669594585254628

Epoch: 6| Step: 3
Training loss: 2.6649725437164307
Validation loss: 1.9918393101743472

Epoch: 6| Step: 4
Training loss: 2.3728954792022705
Validation loss: 1.9737410109530213

Epoch: 6| Step: 5
Training loss: 1.9483118057250977
Validation loss: 1.978506108765961

Epoch: 6| Step: 6
Training loss: 2.169126033782959
Validation loss: 1.9732537192683066

Epoch: 6| Step: 7
Training loss: 2.857597827911377
Validation loss: 1.9828283120227117

Epoch: 6| Step: 8
Training loss: 1.9164814949035645
Validation loss: 1.9734329715851815

Epoch: 6| Step: 9
Training loss: 2.017551898956299
Validation loss: 1.9833859935883553

Epoch: 6| Step: 10
Training loss: 2.481814384460449
Validation loss: 1.991934230250697

Epoch: 6| Step: 11
Training loss: 2.2337393760681152
Validation loss: 1.9793178291730984

Epoch: 6| Step: 12
Training loss: 1.990990400314331
Validation loss: 1.986854371204171

Epoch: 6| Step: 13
Training loss: 1.9803929328918457
Validation loss: 1.9854764989627305

Epoch: 71| Step: 0
Training loss: 2.113630771636963
Validation loss: 1.9934127343598234

Epoch: 6| Step: 1
Training loss: 1.9056901931762695
Validation loss: 1.986880563920544

Epoch: 6| Step: 2
Training loss: 1.9989616870880127
Validation loss: 1.9649397070689867

Epoch: 6| Step: 3
Training loss: 2.8062801361083984
Validation loss: 1.9783963605921755

Epoch: 6| Step: 4
Training loss: 2.200784206390381
Validation loss: 1.954888815520912

Epoch: 6| Step: 5
Training loss: 2.189995050430298
Validation loss: 1.9737093166638446

Epoch: 6| Step: 6
Training loss: 1.7178505659103394
Validation loss: 1.9613552811325237

Epoch: 6| Step: 7
Training loss: 2.654568672180176
Validation loss: 1.9772715030177948

Epoch: 6| Step: 8
Training loss: 2.2183117866516113
Validation loss: 1.975118294838936

Epoch: 6| Step: 9
Training loss: 1.5747792720794678
Validation loss: 1.9924517241857385

Epoch: 6| Step: 10
Training loss: 2.246394634246826
Validation loss: 1.9675207778971682

Epoch: 6| Step: 11
Training loss: 2.2435505390167236
Validation loss: 1.9613325916310793

Epoch: 6| Step: 12
Training loss: 2.544511556625366
Validation loss: 1.9809298310228574

Epoch: 6| Step: 13
Training loss: 2.921581268310547
Validation loss: 1.9895767652860252

Epoch: 72| Step: 0
Training loss: 2.112962484359741
Validation loss: 1.9653304392291653

Epoch: 6| Step: 1
Training loss: 2.099595785140991
Validation loss: 1.9613293819530035

Epoch: 6| Step: 2
Training loss: 2.2055273056030273
Validation loss: 1.9642342316207064

Epoch: 6| Step: 3
Training loss: 2.03450870513916
Validation loss: 1.97245232905111

Epoch: 6| Step: 4
Training loss: 2.0850136280059814
Validation loss: 1.9554451563025033

Epoch: 6| Step: 5
Training loss: 2.1143198013305664
Validation loss: 1.9675682603671987

Epoch: 6| Step: 6
Training loss: 1.9610462188720703
Validation loss: 1.9709074727950557

Epoch: 6| Step: 7
Training loss: 2.4349923133850098
Validation loss: 1.9616765514496834

Epoch: 6| Step: 8
Training loss: 2.1512680053710938
Validation loss: 1.9805622382830548

Epoch: 6| Step: 9
Training loss: 2.26910662651062
Validation loss: 1.9748822463456022

Epoch: 6| Step: 10
Training loss: 2.23703670501709
Validation loss: 1.9656668580988401

Epoch: 6| Step: 11
Training loss: 2.069312572479248
Validation loss: 1.9626485070874613

Epoch: 6| Step: 12
Training loss: 2.648007392883301
Validation loss: 1.9676934775485788

Epoch: 6| Step: 13
Training loss: 2.9098761081695557
Validation loss: 1.9807889833245227

Epoch: 73| Step: 0
Training loss: 2.3050458431243896
Validation loss: 1.975669760857859

Epoch: 6| Step: 1
Training loss: 2.578601121902466
Validation loss: 1.9586606961424633

Epoch: 6| Step: 2
Training loss: 2.6198158264160156
Validation loss: 1.973160236112533

Epoch: 6| Step: 3
Training loss: 2.182560920715332
Validation loss: 1.98369502123966

Epoch: 6| Step: 4
Training loss: 2.2303109169006348
Validation loss: 1.9776363808621642

Epoch: 6| Step: 5
Training loss: 2.0940709114074707
Validation loss: 1.9641985047248103

Epoch: 6| Step: 6
Training loss: 2.1770522594451904
Validation loss: 1.9891868970727409

Epoch: 6| Step: 7
Training loss: 2.0568830966949463
Validation loss: 1.9749155018919258

Epoch: 6| Step: 8
Training loss: 2.224275827407837
Validation loss: 1.9853723074800225

Epoch: 6| Step: 9
Training loss: 2.384355068206787
Validation loss: 1.9799746492857575

Epoch: 6| Step: 10
Training loss: 2.350574493408203
Validation loss: 1.9797716243292696

Epoch: 6| Step: 11
Training loss: 1.861321210861206
Validation loss: 1.987808487748587

Epoch: 6| Step: 12
Training loss: 1.737001657485962
Validation loss: 1.9758585281269525

Epoch: 6| Step: 13
Training loss: 1.988656997680664
Validation loss: 1.958282647594329

Epoch: 74| Step: 0
Training loss: 2.5134851932525635
Validation loss: 1.9684580859317575

Epoch: 6| Step: 1
Training loss: 2.875706195831299
Validation loss: 1.984358113299134

Epoch: 6| Step: 2
Training loss: 2.733203887939453
Validation loss: 1.9639810182714974

Epoch: 6| Step: 3
Training loss: 3.0305633544921875
Validation loss: 1.9761238995418753

Epoch: 6| Step: 4
Training loss: 1.5059051513671875
Validation loss: 1.9741229190621326

Epoch: 6| Step: 5
Training loss: 1.90184485912323
Validation loss: 1.968915403530162

Epoch: 6| Step: 6
Training loss: 1.9731353521347046
Validation loss: 1.9706746173161331

Epoch: 6| Step: 7
Training loss: 2.98437237739563
Validation loss: 1.971457955657795

Epoch: 6| Step: 8
Training loss: 1.6976025104522705
Validation loss: 1.9789329933863815

Epoch: 6| Step: 9
Training loss: 2.205305814743042
Validation loss: 1.9833478043156285

Epoch: 6| Step: 10
Training loss: 1.553436279296875
Validation loss: 1.9885834506762925

Epoch: 6| Step: 11
Training loss: 2.2237887382507324
Validation loss: 1.9805738836206415

Epoch: 6| Step: 12
Training loss: 1.707945704460144
Validation loss: 1.9675210483612553

Epoch: 6| Step: 13
Training loss: 1.9095730781555176
Validation loss: 1.9822772677226732

Epoch: 75| Step: 0
Training loss: 1.8116767406463623
Validation loss: 1.967109913467079

Epoch: 6| Step: 1
Training loss: 1.6938953399658203
Validation loss: 1.9873733597417031

Epoch: 6| Step: 2
Training loss: 2.539999008178711
Validation loss: 1.997189998626709

Epoch: 6| Step: 3
Training loss: 2.5445456504821777
Validation loss: 1.9812523575239285

Epoch: 6| Step: 4
Training loss: 2.0867061614990234
Validation loss: 1.9801879672593967

Epoch: 6| Step: 5
Training loss: 2.2886266708374023
Validation loss: 1.9640635495544763

Epoch: 6| Step: 6
Training loss: 2.083076238632202
Validation loss: 1.9787891141829952

Epoch: 6| Step: 7
Training loss: 2.135350465774536
Validation loss: 1.9714088875760314

Epoch: 6| Step: 8
Training loss: 2.065303325653076
Validation loss: 1.9766892938203708

Epoch: 6| Step: 9
Training loss: 1.6616290807724
Validation loss: 1.9817967760947444

Epoch: 6| Step: 10
Training loss: 2.245542526245117
Validation loss: 1.971201632612495

Epoch: 6| Step: 11
Training loss: 3.272176742553711
Validation loss: 1.9799891287280666

Epoch: 6| Step: 12
Training loss: 1.5927067995071411
Validation loss: 1.9776359552978187

Epoch: 6| Step: 13
Training loss: 3.50171160697937
Validation loss: 1.9906758057173861

Epoch: 76| Step: 0
Training loss: 1.627142310142517
Validation loss: 1.9691605465386504

Epoch: 6| Step: 1
Training loss: 2.622326374053955
Validation loss: 1.972748484662784

Epoch: 6| Step: 2
Training loss: 2.230910539627075
Validation loss: 1.9712945017763364

Epoch: 6| Step: 3
Training loss: 2.122844696044922
Validation loss: 1.974168900520571

Epoch: 6| Step: 4
Training loss: 2.6664059162139893
Validation loss: 1.9787952951205674

Epoch: 6| Step: 5
Training loss: 1.9849107265472412
Validation loss: 1.9805767689981768

Epoch: 6| Step: 6
Training loss: 2.8785321712493896
Validation loss: 1.9848279081365114

Epoch: 6| Step: 7
Training loss: 1.9290105104446411
Validation loss: 1.9816238982703096

Epoch: 6| Step: 8
Training loss: 1.7558910846710205
Validation loss: 1.989021534560829

Epoch: 6| Step: 9
Training loss: 2.4330594539642334
Validation loss: 1.9833822801548948

Epoch: 6| Step: 10
Training loss: 2.4369986057281494
Validation loss: 1.974632276001797

Epoch: 6| Step: 11
Training loss: 1.8186277151107788
Validation loss: 1.9758305946985881

Epoch: 6| Step: 12
Training loss: 2.305386781692505
Validation loss: 1.9663455947752921

Epoch: 6| Step: 13
Training loss: 2.005368232727051
Validation loss: 1.9853071948533416

Epoch: 77| Step: 0
Training loss: 1.9317213296890259
Validation loss: 1.9882920839453255

Epoch: 6| Step: 1
Training loss: 2.772571086883545
Validation loss: 1.9774729692807762

Epoch: 6| Step: 2
Training loss: 2.3526275157928467
Validation loss: 1.9796314213865547

Epoch: 6| Step: 3
Training loss: 2.4676146507263184
Validation loss: 1.9875397489916893

Epoch: 6| Step: 4
Training loss: 2.1725034713745117
Validation loss: 1.981962054006515

Epoch: 6| Step: 5
Training loss: 1.6214914321899414
Validation loss: 1.9768401448444655

Epoch: 6| Step: 6
Training loss: 2.37894344329834
Validation loss: 1.9783686412278043

Epoch: 6| Step: 7
Training loss: 2.142885684967041
Validation loss: 1.9838623564730409

Epoch: 6| Step: 8
Training loss: 2.2682833671569824
Validation loss: 1.9593077910843717

Epoch: 6| Step: 9
Training loss: 2.530121326446533
Validation loss: 1.9734572928438905

Epoch: 6| Step: 10
Training loss: 2.4878435134887695
Validation loss: 1.9918210198802333

Epoch: 6| Step: 11
Training loss: 2.099458694458008
Validation loss: 2.0028382296203286

Epoch: 6| Step: 12
Training loss: 1.8500773906707764
Validation loss: 1.9747671529810915

Epoch: 6| Step: 13
Training loss: 1.3579565286636353
Validation loss: 1.9939934207547096

Epoch: 78| Step: 0
Training loss: 1.9126348495483398
Validation loss: 1.995626631603446

Epoch: 6| Step: 1
Training loss: 2.3135581016540527
Validation loss: 1.9869045749787362

Epoch: 6| Step: 2
Training loss: 1.987064242362976
Validation loss: 1.9917187806098693

Epoch: 6| Step: 3
Training loss: 2.491529941558838
Validation loss: 1.978728530227497

Epoch: 6| Step: 4
Training loss: 2.967001438140869
Validation loss: 1.9761252633986934

Epoch: 6| Step: 5
Training loss: 2.214069366455078
Validation loss: 1.9880324730309107

Epoch: 6| Step: 6
Training loss: 2.2632906436920166
Validation loss: 1.9904509654609106

Epoch: 6| Step: 7
Training loss: 1.8717384338378906
Validation loss: 1.9901140941086637

Epoch: 6| Step: 8
Training loss: 2.02608060836792
Validation loss: 1.987974569361697

Epoch: 6| Step: 9
Training loss: 2.0118539333343506
Validation loss: 1.9848644374519266

Epoch: 6| Step: 10
Training loss: 2.108766794204712
Validation loss: 1.9828837558787356

Epoch: 6| Step: 11
Training loss: 2.086153507232666
Validation loss: 1.9948186015570035

Epoch: 6| Step: 12
Training loss: 2.2799437046051025
Validation loss: 1.9708369316593293

Epoch: 6| Step: 13
Training loss: 2.304056167602539
Validation loss: 1.9790162142886911

Epoch: 79| Step: 0
Training loss: 1.991738200187683
Validation loss: 1.9794281208386986

Epoch: 6| Step: 1
Training loss: 1.6416430473327637
Validation loss: 1.9852237739870626

Epoch: 6| Step: 2
Training loss: 2.4347474575042725
Validation loss: 1.9737117213587607

Epoch: 6| Step: 3
Training loss: 2.299862861633301
Validation loss: 1.9762583048112932

Epoch: 6| Step: 4
Training loss: 2.3073410987854004
Validation loss: 1.9585016273683118

Epoch: 6| Step: 5
Training loss: 2.2385354042053223
Validation loss: 1.9741876791882258

Epoch: 6| Step: 6
Training loss: 2.833804130554199
Validation loss: 1.9756721168436029

Epoch: 6| Step: 7
Training loss: 2.208001136779785
Validation loss: 1.9647256046213128

Epoch: 6| Step: 8
Training loss: 2.2846755981445312
Validation loss: 1.9608359003579745

Epoch: 6| Step: 9
Training loss: 2.5074172019958496
Validation loss: 1.9770920815006379

Epoch: 6| Step: 10
Training loss: 1.638859510421753
Validation loss: 1.978303099191317

Epoch: 6| Step: 11
Training loss: 2.2713565826416016
Validation loss: 1.9898398883881108

Epoch: 6| Step: 12
Training loss: 2.3755202293395996
Validation loss: 1.9804265550387803

Epoch: 6| Step: 13
Training loss: 1.4520689249038696
Validation loss: 1.972825168281473

Epoch: 80| Step: 0
Training loss: 1.9440219402313232
Validation loss: 1.9748087980413949

Epoch: 6| Step: 1
Training loss: 2.398137092590332
Validation loss: 1.9794062029930852

Epoch: 6| Step: 2
Training loss: 2.6867213249206543
Validation loss: 1.9755055007114206

Epoch: 6| Step: 3
Training loss: 2.245149612426758
Validation loss: 1.9728007995954124

Epoch: 6| Step: 4
Training loss: 2.6708178520202637
Validation loss: 1.9803878248378795

Epoch: 6| Step: 5
Training loss: 1.9830611944198608
Validation loss: 1.990019900824434

Epoch: 6| Step: 6
Training loss: 1.936854600906372
Validation loss: 1.9869443370449928

Epoch: 6| Step: 7
Training loss: 2.2658791542053223
Validation loss: 1.973594948809634

Epoch: 6| Step: 8
Training loss: 2.3996057510375977
Validation loss: 1.9836119862012966

Epoch: 6| Step: 9
Training loss: 1.8952687978744507
Validation loss: 1.9884503990091302

Epoch: 6| Step: 10
Training loss: 1.871013879776001
Validation loss: 1.9751295722940916

Epoch: 6| Step: 11
Training loss: 2.2193353176116943
Validation loss: 1.9771908816470896

Epoch: 6| Step: 12
Training loss: 2.329497814178467
Validation loss: 1.9590604971813899

Epoch: 6| Step: 13
Training loss: 1.8822956085205078
Validation loss: 1.9750854276841687

Epoch: 81| Step: 0
Training loss: 2.1014485359191895
Validation loss: 1.9822000354848883

Epoch: 6| Step: 1
Training loss: 2.8975138664245605
Validation loss: 1.975264872274091

Epoch: 6| Step: 2
Training loss: 2.149653911590576
Validation loss: 1.9920798937479656

Epoch: 6| Step: 3
Training loss: 1.7534760236740112
Validation loss: 1.978926968830888

Epoch: 6| Step: 4
Training loss: 1.8402060270309448
Validation loss: 1.9849481480095976

Epoch: 6| Step: 5
Training loss: 1.5665936470031738
Validation loss: 1.976392138388849

Epoch: 6| Step: 6
Training loss: 2.457839012145996
Validation loss: 1.9791537484815043

Epoch: 6| Step: 7
Training loss: 2.04447865486145
Validation loss: 1.9896935121987456

Epoch: 6| Step: 8
Training loss: 2.7555811405181885
Validation loss: 1.9634240827252787

Epoch: 6| Step: 9
Training loss: 2.8588037490844727
Validation loss: 1.9983646228749266

Epoch: 6| Step: 10
Training loss: 1.930363655090332
Validation loss: 1.992062746837575

Epoch: 6| Step: 11
Training loss: 2.395723342895508
Validation loss: 1.981632730012299

Epoch: 6| Step: 12
Training loss: 1.8227343559265137
Validation loss: 2.0065140390908844

Epoch: 6| Step: 13
Training loss: 2.0842151641845703
Validation loss: 1.9848123417105725

Epoch: 82| Step: 0
Training loss: 1.963212251663208
Validation loss: 1.9830324111446258

Epoch: 6| Step: 1
Training loss: 1.6181625127792358
Validation loss: 1.9885075656316613

Epoch: 6| Step: 2
Training loss: 1.3378474712371826
Validation loss: 1.9748340870744439

Epoch: 6| Step: 3
Training loss: 2.5286264419555664
Validation loss: 1.9873261067175096

Epoch: 6| Step: 4
Training loss: 3.0297887325286865
Validation loss: 1.9794287976398264

Epoch: 6| Step: 5
Training loss: 1.845496654510498
Validation loss: 1.9746626961615779

Epoch: 6| Step: 6
Training loss: 2.591214179992676
Validation loss: 1.9734194765808761

Epoch: 6| Step: 7
Training loss: 1.8629138469696045
Validation loss: 1.9445849208421604

Epoch: 6| Step: 8
Training loss: 2.785438060760498
Validation loss: 1.9828642517007806

Epoch: 6| Step: 9
Training loss: 2.5069785118103027
Validation loss: 1.9753179639898322

Epoch: 6| Step: 10
Training loss: 2.1682586669921875
Validation loss: 1.9738074515455513

Epoch: 6| Step: 11
Training loss: 2.399620532989502
Validation loss: 1.9633601814187982

Epoch: 6| Step: 12
Training loss: 1.9456994533538818
Validation loss: 1.9693506520281556

Epoch: 6| Step: 13
Training loss: 2.1563940048217773
Validation loss: 1.9807877566224785

Epoch: 83| Step: 0
Training loss: 2.437513828277588
Validation loss: 1.9966285818366594

Epoch: 6| Step: 1
Training loss: 1.7905865907669067
Validation loss: 1.9768710751687326

Epoch: 6| Step: 2
Training loss: 2.3804128170013428
Validation loss: 1.978672771043675

Epoch: 6| Step: 3
Training loss: 1.9706311225891113
Validation loss: 1.9827850454597062

Epoch: 6| Step: 4
Training loss: 2.020866870880127
Validation loss: 1.9781333284993325

Epoch: 6| Step: 5
Training loss: 1.8833502531051636
Validation loss: 1.975658773094095

Epoch: 6| Step: 6
Training loss: 2.189586639404297
Validation loss: 1.9677237285080778

Epoch: 6| Step: 7
Training loss: 2.0144388675689697
Validation loss: 1.9691512687231905

Epoch: 6| Step: 8
Training loss: 2.2279577255249023
Validation loss: 1.965027928352356

Epoch: 6| Step: 9
Training loss: 2.493572473526001
Validation loss: 1.9685024471693142

Epoch: 6| Step: 10
Training loss: 2.8830904960632324
Validation loss: 1.964690972399968

Epoch: 6| Step: 11
Training loss: 2.1753108501434326
Validation loss: 1.9786160376764113

Epoch: 6| Step: 12
Training loss: 1.696441888809204
Validation loss: 1.9808440913436234

Epoch: 6| Step: 13
Training loss: 2.749851942062378
Validation loss: 1.9704680109536776

Epoch: 84| Step: 0
Training loss: 2.573922872543335
Validation loss: 1.981147120075841

Epoch: 6| Step: 1
Training loss: 2.324176549911499
Validation loss: 1.9663883140010219

Epoch: 6| Step: 2
Training loss: 2.3915743827819824
Validation loss: 1.963160366140386

Epoch: 6| Step: 3
Training loss: 2.5478529930114746
Validation loss: 1.9607971086296985

Epoch: 6| Step: 4
Training loss: 2.455564498901367
Validation loss: 1.9815537916716708

Epoch: 6| Step: 5
Training loss: 1.6505002975463867
Validation loss: 1.9925788602521342

Epoch: 6| Step: 6
Training loss: 1.775437355041504
Validation loss: 1.9699251600491103

Epoch: 6| Step: 7
Training loss: 2.1471238136291504
Validation loss: 1.9808667513632006

Epoch: 6| Step: 8
Training loss: 2.1280570030212402
Validation loss: 1.9639330935734574

Epoch: 6| Step: 9
Training loss: 1.9145622253417969
Validation loss: 1.9618013930577103

Epoch: 6| Step: 10
Training loss: 2.0944888591766357
Validation loss: 1.9599516866027669

Epoch: 6| Step: 11
Training loss: 2.0551576614379883
Validation loss: 1.9722012627509333

Epoch: 6| Step: 12
Training loss: 2.4172911643981934
Validation loss: 1.9759059631696312

Epoch: 6| Step: 13
Training loss: 2.0254952907562256
Validation loss: 1.9479578054079445

Epoch: 85| Step: 0
Training loss: 1.2248222827911377
Validation loss: 1.9841785123271327

Epoch: 6| Step: 1
Training loss: 2.3005666732788086
Validation loss: 1.9528613410970217

Epoch: 6| Step: 2
Training loss: 2.2774956226348877
Validation loss: 1.9842676962575605

Epoch: 6| Step: 3
Training loss: 2.1707584857940674
Validation loss: 1.9740096638279576

Epoch: 6| Step: 4
Training loss: 1.6890215873718262
Validation loss: 1.9585362480532738

Epoch: 6| Step: 5
Training loss: 2.4636802673339844
Validation loss: 1.9620529015858967

Epoch: 6| Step: 6
Training loss: 2.4029221534729004
Validation loss: 1.9726290933547481

Epoch: 6| Step: 7
Training loss: 2.073935031890869
Validation loss: 1.957434945209052

Epoch: 6| Step: 8
Training loss: 2.7158515453338623
Validation loss: 1.9695960078188168

Epoch: 6| Step: 9
Training loss: 2.2071077823638916
Validation loss: 1.969792781337615

Epoch: 6| Step: 10
Training loss: 1.7960288524627686
Validation loss: 1.9531776033422

Epoch: 6| Step: 11
Training loss: 2.714982509613037
Validation loss: 1.9472597414447415

Epoch: 6| Step: 12
Training loss: 2.184720516204834
Validation loss: 1.9477333945612754

Epoch: 6| Step: 13
Training loss: 2.6464388370513916
Validation loss: 1.9442478277349984

Epoch: 86| Step: 0
Training loss: 2.997549533843994
Validation loss: 1.9670118798491776

Epoch: 6| Step: 1
Training loss: 2.454285144805908
Validation loss: 1.9617518160932808

Epoch: 6| Step: 2
Training loss: 2.009984016418457
Validation loss: 1.9637292777338335

Epoch: 6| Step: 3
Training loss: 2.9362785816192627
Validation loss: 1.9565061805068806

Epoch: 6| Step: 4
Training loss: 1.8130645751953125
Validation loss: 1.979186265699325

Epoch: 6| Step: 5
Training loss: 2.475684881210327
Validation loss: 1.9745061089915614

Epoch: 6| Step: 6
Training loss: 1.7566273212432861
Validation loss: 1.9637758578023603

Epoch: 6| Step: 7
Training loss: 1.4154703617095947
Validation loss: 1.9767215956923783

Epoch: 6| Step: 8
Training loss: 2.3742053508758545
Validation loss: 1.9740363244087464

Epoch: 6| Step: 9
Training loss: 1.5019060373306274
Validation loss: 1.9700761392552366

Epoch: 6| Step: 10
Training loss: 2.300718307495117
Validation loss: 1.9879191819057669

Epoch: 6| Step: 11
Training loss: 1.9121891260147095
Validation loss: 1.9783697999933714

Epoch: 6| Step: 12
Training loss: 2.603616714477539
Validation loss: 1.991063061580863

Epoch: 6| Step: 13
Training loss: 1.8862299919128418
Validation loss: 1.984196073265486

Epoch: 87| Step: 0
Training loss: 2.2413065433502197
Validation loss: 1.9901435157304168

Epoch: 6| Step: 1
Training loss: 2.6048388481140137
Validation loss: 2.000536628948745

Epoch: 6| Step: 2
Training loss: 2.0392794609069824
Validation loss: 1.9739745150330246

Epoch: 6| Step: 3
Training loss: 2.8932502269744873
Validation loss: 1.9766314901331419

Epoch: 6| Step: 4
Training loss: 2.0340471267700195
Validation loss: 1.984493455579204

Epoch: 6| Step: 5
Training loss: 2.2389864921569824
Validation loss: 1.9713512415527015

Epoch: 6| Step: 6
Training loss: 1.8465638160705566
Validation loss: 1.968464054087157

Epoch: 6| Step: 7
Training loss: 1.6720659732818604
Validation loss: 1.996686045841504

Epoch: 6| Step: 8
Training loss: 2.264139413833618
Validation loss: 1.9833396339929232

Epoch: 6| Step: 9
Training loss: 1.79496169090271
Validation loss: 1.9759466866011262

Epoch: 6| Step: 10
Training loss: 2.2046926021575928
Validation loss: 1.9782621886140557

Epoch: 6| Step: 11
Training loss: 2.20849871635437
Validation loss: 1.967568079630534

Epoch: 6| Step: 12
Training loss: 1.9282197952270508
Validation loss: 1.9720981403063702

Epoch: 6| Step: 13
Training loss: 2.8081157207489014
Validation loss: 1.9807367299192695

Epoch: 88| Step: 0
Training loss: 2.1436400413513184
Validation loss: 1.9734239962793165

Epoch: 6| Step: 1
Training loss: 2.0663657188415527
Validation loss: 1.9766583160687519

Epoch: 6| Step: 2
Training loss: 1.46108078956604
Validation loss: 1.9724001871642245

Epoch: 6| Step: 3
Training loss: 2.226418972015381
Validation loss: 1.9740943729236562

Epoch: 6| Step: 4
Training loss: 2.7182483673095703
Validation loss: 1.988455275053619

Epoch: 6| Step: 5
Training loss: 2.629603385925293
Validation loss: 1.9718067671663018

Epoch: 6| Step: 6
Training loss: 2.42708683013916
Validation loss: 1.9820386773796492

Epoch: 6| Step: 7
Training loss: 1.5504422187805176
Validation loss: 1.961983637143207

Epoch: 6| Step: 8
Training loss: 2.267014503479004
Validation loss: 1.9816142858997468

Epoch: 6| Step: 9
Training loss: 2.234804630279541
Validation loss: 1.9741854962482248

Epoch: 6| Step: 10
Training loss: 2.000673294067383
Validation loss: 1.9563822015639274

Epoch: 6| Step: 11
Training loss: 2.5678796768188477
Validation loss: 1.9540564360157135

Epoch: 6| Step: 12
Training loss: 1.9899847507476807
Validation loss: 1.9659013055985974

Epoch: 6| Step: 13
Training loss: 2.3692450523376465
Validation loss: 1.954843186563061

Epoch: 89| Step: 0
Training loss: 1.5954968929290771
Validation loss: 1.9792596563216178

Epoch: 6| Step: 1
Training loss: 1.6243197917938232
Validation loss: 1.962426595790412

Epoch: 6| Step: 2
Training loss: 2.2512295246124268
Validation loss: 1.9609016564584547

Epoch: 6| Step: 3
Training loss: 2.705873489379883
Validation loss: 1.985254660729439

Epoch: 6| Step: 4
Training loss: 1.5512503385543823
Validation loss: 1.9599750413689563

Epoch: 6| Step: 5
Training loss: 1.8284342288970947
Validation loss: 1.9788928237012637

Epoch: 6| Step: 6
Training loss: 1.5399823188781738
Validation loss: 1.9738684982381842

Epoch: 6| Step: 7
Training loss: 1.756070613861084
Validation loss: 1.9590699723971787

Epoch: 6| Step: 8
Training loss: 2.7235491275787354
Validation loss: 1.9562404104458389

Epoch: 6| Step: 9
Training loss: 2.4796013832092285
Validation loss: 1.9674675772267003

Epoch: 6| Step: 10
Training loss: 2.7503013610839844
Validation loss: 1.9601984408593947

Epoch: 6| Step: 11
Training loss: 2.45918607711792
Validation loss: 1.954323745542957

Epoch: 6| Step: 12
Training loss: 2.5789527893066406
Validation loss: 1.9613455649345153

Epoch: 6| Step: 13
Training loss: 3.0515031814575195
Validation loss: 1.9618242863685853

Epoch: 90| Step: 0
Training loss: 1.933620810508728
Validation loss: 1.9528977717122724

Epoch: 6| Step: 1
Training loss: 2.389578104019165
Validation loss: 1.9597420025897283

Epoch: 6| Step: 2
Training loss: 2.2025389671325684
Validation loss: 1.966433027739166

Epoch: 6| Step: 3
Training loss: 2.782897710800171
Validation loss: 1.954158075394169

Epoch: 6| Step: 4
Training loss: 1.71669340133667
Validation loss: 1.9685351515329013

Epoch: 6| Step: 5
Training loss: 2.103717565536499
Validation loss: 1.9660385526636595

Epoch: 6| Step: 6
Training loss: 2.7696261405944824
Validation loss: 1.9737150797279932

Epoch: 6| Step: 7
Training loss: 2.390763759613037
Validation loss: 1.9872414706855692

Epoch: 6| Step: 8
Training loss: 2.0448553562164307
Validation loss: 1.9715837650401618

Epoch: 6| Step: 9
Training loss: 2.1537322998046875
Validation loss: 1.985937100584789

Epoch: 6| Step: 10
Training loss: 1.9428985118865967
Validation loss: 1.990845682800457

Epoch: 6| Step: 11
Training loss: 2.021324634552002
Validation loss: 1.9886851849094513

Epoch: 6| Step: 12
Training loss: 2.239046573638916
Validation loss: 1.98687118868674

Epoch: 6| Step: 13
Training loss: 1.4134085178375244
Validation loss: 1.991139232471425

Epoch: 91| Step: 0
Training loss: 1.9929437637329102
Validation loss: 1.994399824450093

Epoch: 6| Step: 1
Training loss: 2.2443642616271973
Validation loss: 2.0009589349069903

Epoch: 6| Step: 2
Training loss: 2.2278621196746826
Validation loss: 1.9916063893225886

Epoch: 6| Step: 3
Training loss: 1.8795068264007568
Validation loss: 1.978147816914384

Epoch: 6| Step: 4
Training loss: 2.148146152496338
Validation loss: 1.9700207043719549

Epoch: 6| Step: 5
Training loss: 2.406799554824829
Validation loss: 1.9762861703031807

Epoch: 6| Step: 6
Training loss: 1.8173420429229736
Validation loss: 1.9838594698136853

Epoch: 6| Step: 7
Training loss: 2.053093194961548
Validation loss: 1.9830786310216433

Epoch: 6| Step: 8
Training loss: 2.786316394805908
Validation loss: 1.9850860590575843

Epoch: 6| Step: 9
Training loss: 1.767507791519165
Validation loss: 1.9823559407264955

Epoch: 6| Step: 10
Training loss: 2.019570827484131
Validation loss: 2.0036725498014882

Epoch: 6| Step: 11
Training loss: 2.744175434112549
Validation loss: 1.9849331660937237

Epoch: 6| Step: 12
Training loss: 1.814251184463501
Validation loss: 1.9871104994127828

Epoch: 6| Step: 13
Training loss: 2.540755271911621
Validation loss: 1.971834780067526

Epoch: 92| Step: 0
Training loss: 2.9975478649139404
Validation loss: 1.9798624541169854

Epoch: 6| Step: 1
Training loss: 1.8999022245407104
Validation loss: 1.999607252818282

Epoch: 6| Step: 2
Training loss: 2.4731531143188477
Validation loss: 1.9904343171786236

Epoch: 6| Step: 3
Training loss: 2.7618937492370605
Validation loss: 1.9781740634672103

Epoch: 6| Step: 4
Training loss: 1.9620695114135742
Validation loss: 1.954808776096631

Epoch: 6| Step: 5
Training loss: 1.5214271545410156
Validation loss: 1.972214933364622

Epoch: 6| Step: 6
Training loss: 2.2325875759124756
Validation loss: 1.9916120177956038

Epoch: 6| Step: 7
Training loss: 2.217373847961426
Validation loss: 1.9686007422785605

Epoch: 6| Step: 8
Training loss: 2.0439748764038086
Validation loss: 2.0014484441408547

Epoch: 6| Step: 9
Training loss: 1.9128282070159912
Validation loss: 1.9855203679812852

Epoch: 6| Step: 10
Training loss: 2.079285144805908
Validation loss: 1.9750481446584065

Epoch: 6| Step: 11
Training loss: 1.9515166282653809
Validation loss: 1.993524500118789

Epoch: 6| Step: 12
Training loss: 2.3474724292755127
Validation loss: 1.9814695953040995

Epoch: 6| Step: 13
Training loss: 1.6353862285614014
Validation loss: 1.9839858931879844

Epoch: 93| Step: 0
Training loss: 2.6047487258911133
Validation loss: 1.9716328510674097

Epoch: 6| Step: 1
Training loss: 1.4486411809921265
Validation loss: 1.9698705609126756

Epoch: 6| Step: 2
Training loss: 2.1916279792785645
Validation loss: 1.946228245253204

Epoch: 6| Step: 3
Training loss: 1.6572158336639404
Validation loss: 1.9713351508622527

Epoch: 6| Step: 4
Training loss: 2.0918896198272705
Validation loss: 1.9769663682547949

Epoch: 6| Step: 5
Training loss: 2.1892290115356445
Validation loss: 1.9615845064963064

Epoch: 6| Step: 6
Training loss: 2.7649693489074707
Validation loss: 1.9631950573254657

Epoch: 6| Step: 7
Training loss: 2.1734302043914795
Validation loss: 1.9686053773408294

Epoch: 6| Step: 8
Training loss: 2.061368227005005
Validation loss: 1.970028624739698

Epoch: 6| Step: 9
Training loss: 2.329763412475586
Validation loss: 1.9600676746778591

Epoch: 6| Step: 10
Training loss: 2.221651792526245
Validation loss: 1.9612312650167814

Epoch: 6| Step: 11
Training loss: 2.5223593711853027
Validation loss: 1.9647212695049983

Epoch: 6| Step: 12
Training loss: 2.4197394847869873
Validation loss: 1.9533902445147115

Epoch: 6| Step: 13
Training loss: 1.2666014432907104
Validation loss: 1.9667736650795065

Epoch: 94| Step: 0
Training loss: 2.094357490539551
Validation loss: 1.9523391967178674

Epoch: 6| Step: 1
Training loss: 2.467417001724243
Validation loss: 1.965808778680781

Epoch: 6| Step: 2
Training loss: 2.1598124504089355
Validation loss: 1.9519100137936172

Epoch: 6| Step: 3
Training loss: 2.6668214797973633
Validation loss: 1.9770700854639853

Epoch: 6| Step: 4
Training loss: 2.300032615661621
Validation loss: 1.9783218958044564

Epoch: 6| Step: 5
Training loss: 1.709141731262207
Validation loss: 1.973703501045063

Epoch: 6| Step: 6
Training loss: 2.1644816398620605
Validation loss: 1.9461194007627425

Epoch: 6| Step: 7
Training loss: 2.3804521560668945
Validation loss: 1.9481260853428994

Epoch: 6| Step: 8
Training loss: 1.740816593170166
Validation loss: 1.9578892351478658

Epoch: 6| Step: 9
Training loss: 1.7045148611068726
Validation loss: 1.9798558130059192

Epoch: 6| Step: 10
Training loss: 2.237797498703003
Validation loss: 1.9576189928157355

Epoch: 6| Step: 11
Training loss: 1.6094670295715332
Validation loss: 1.950288165000177

Epoch: 6| Step: 12
Training loss: 2.290757656097412
Validation loss: 1.9574286489076511

Epoch: 6| Step: 13
Training loss: 3.2112433910369873
Validation loss: 1.9619246413630824

Epoch: 95| Step: 0
Training loss: 2.1061415672302246
Validation loss: 1.9604733195356143

Epoch: 6| Step: 1
Training loss: 2.131302833557129
Validation loss: 1.9532456526192286

Epoch: 6| Step: 2
Training loss: 2.109285354614258
Validation loss: 1.9638741452206847

Epoch: 6| Step: 3
Training loss: 2.265277624130249
Validation loss: 1.9672472066776727

Epoch: 6| Step: 4
Training loss: 1.7683324813842773
Validation loss: 1.967569766506072

Epoch: 6| Step: 5
Training loss: 2.1290926933288574
Validation loss: 1.960922174556281

Epoch: 6| Step: 6
Training loss: 2.5633842945098877
Validation loss: 1.9559407670010802

Epoch: 6| Step: 7
Training loss: 2.293071985244751
Validation loss: 1.9683343671983289

Epoch: 6| Step: 8
Training loss: 1.6434543132781982
Validation loss: 1.9705523701124295

Epoch: 6| Step: 9
Training loss: 1.8588318824768066
Validation loss: 1.9716968433831328

Epoch: 6| Step: 10
Training loss: 2.719656467437744
Validation loss: 1.9447064361264628

Epoch: 6| Step: 11
Training loss: 1.8802907466888428
Validation loss: 1.9728252221179265

Epoch: 6| Step: 12
Training loss: 2.418262481689453
Validation loss: 1.9677617293532177

Epoch: 6| Step: 13
Training loss: 2.5635814666748047
Validation loss: 1.9670994794496925

Epoch: 96| Step: 0
Training loss: 2.0844948291778564
Validation loss: 1.9468873598242318

Epoch: 6| Step: 1
Training loss: 1.7192740440368652
Validation loss: 1.959972043191233

Epoch: 6| Step: 2
Training loss: 1.9991227388381958
Validation loss: 1.954428045980392

Epoch: 6| Step: 3
Training loss: 1.993403673171997
Validation loss: 1.9397391529493435

Epoch: 6| Step: 4
Training loss: 2.952333688735962
Validation loss: 1.9584772458640478

Epoch: 6| Step: 5
Training loss: 1.6767407655715942
Validation loss: 1.9432359869762132

Epoch: 6| Step: 6
Training loss: 1.973512887954712
Validation loss: 1.963341277132752

Epoch: 6| Step: 7
Training loss: 2.610443115234375
Validation loss: 1.9530773598660705

Epoch: 6| Step: 8
Training loss: 2.050729513168335
Validation loss: 1.9583012698799052

Epoch: 6| Step: 9
Training loss: 1.5941619873046875
Validation loss: 1.9626789298108829

Epoch: 6| Step: 10
Training loss: 2.8770945072174072
Validation loss: 1.9552814550297235

Epoch: 6| Step: 11
Training loss: 2.5437021255493164
Validation loss: 1.9521726203221146

Epoch: 6| Step: 12
Training loss: 2.172703742980957
Validation loss: 1.9545503354841662

Epoch: 6| Step: 13
Training loss: 1.756093144416809
Validation loss: 1.9458547138398694

Epoch: 97| Step: 0
Training loss: 2.4234344959259033
Validation loss: 1.934907159497661

Epoch: 6| Step: 1
Training loss: 2.313258171081543
Validation loss: 1.9467471261178293

Epoch: 6| Step: 2
Training loss: 2.1020541191101074
Validation loss: 1.9476897588340185

Epoch: 6| Step: 3
Training loss: 1.8774874210357666
Validation loss: 1.9634223240678028

Epoch: 6| Step: 4
Training loss: 2.7569193840026855
Validation loss: 1.9590348133476831

Epoch: 6| Step: 5
Training loss: 2.7031702995300293
Validation loss: 1.9571885344802693

Epoch: 6| Step: 6
Training loss: 2.0021612644195557
Validation loss: 1.9704676571712698

Epoch: 6| Step: 7
Training loss: 2.7484841346740723
Validation loss: 1.9660635520053167

Epoch: 6| Step: 8
Training loss: 1.4938195943832397
Validation loss: 1.9752647722921064

Epoch: 6| Step: 9
Training loss: 2.3560853004455566
Validation loss: 1.9572665486284482

Epoch: 6| Step: 10
Training loss: 1.7252919673919678
Validation loss: 1.9832681840465916

Epoch: 6| Step: 11
Training loss: 1.226147174835205
Validation loss: 1.9521071372493621

Epoch: 6| Step: 12
Training loss: 2.083143949508667
Validation loss: 1.9774863963486047

Epoch: 6| Step: 13
Training loss: 2.428816795349121
Validation loss: 1.9668268644681541

Epoch: 98| Step: 0
Training loss: 2.802957534790039
Validation loss: 1.9696513811747234

Epoch: 6| Step: 1
Training loss: 1.6956021785736084
Validation loss: 1.9699791580118158

Epoch: 6| Step: 2
Training loss: 1.91338312625885
Validation loss: 1.9776130132777716

Epoch: 6| Step: 3
Training loss: 2.363156795501709
Validation loss: 1.9643288145783127

Epoch: 6| Step: 4
Training loss: 1.8225328922271729
Validation loss: 1.9564966719637635

Epoch: 6| Step: 5
Training loss: 2.3634414672851562
Validation loss: 1.9644720015987274

Epoch: 6| Step: 6
Training loss: 2.4355318546295166
Validation loss: 1.9923077514094691

Epoch: 6| Step: 7
Training loss: 2.7340331077575684
Validation loss: 1.980868818939373

Epoch: 6| Step: 8
Training loss: 1.6959547996520996
Validation loss: 1.9793384728893157

Epoch: 6| Step: 9
Training loss: 1.8697102069854736
Validation loss: 1.9840986318485712

Epoch: 6| Step: 10
Training loss: 1.9713003635406494
Validation loss: 1.9679514618330105

Epoch: 6| Step: 11
Training loss: 2.210982322692871
Validation loss: 1.9751119741829493

Epoch: 6| Step: 12
Training loss: 2.187798023223877
Validation loss: 1.9795114994049072

Epoch: 6| Step: 13
Training loss: 1.9011789560317993
Validation loss: 1.9822711252397107

Epoch: 99| Step: 0
Training loss: 2.1114282608032227
Validation loss: 1.98318443118885

Epoch: 6| Step: 1
Training loss: 2.5060343742370605
Validation loss: 1.9700937988937541

Epoch: 6| Step: 2
Training loss: 1.9282028675079346
Validation loss: 1.9589621841266591

Epoch: 6| Step: 3
Training loss: 2.2461447715759277
Validation loss: 1.9646439577943535

Epoch: 6| Step: 4
Training loss: 2.384396553039551
Validation loss: 1.9617997984732352

Epoch: 6| Step: 5
Training loss: 2.1498451232910156
Validation loss: 1.9577974196403258

Epoch: 6| Step: 6
Training loss: 2.096731662750244
Validation loss: 1.9668916720215992

Epoch: 6| Step: 7
Training loss: 2.796142578125
Validation loss: 1.9687717986363236

Epoch: 6| Step: 8
Training loss: 2.3715925216674805
Validation loss: 1.9481592896164104

Epoch: 6| Step: 9
Training loss: 1.7827032804489136
Validation loss: 1.956906710901568

Epoch: 6| Step: 10
Training loss: 1.90838623046875
Validation loss: 1.957790651629048

Epoch: 6| Step: 11
Training loss: 2.1625165939331055
Validation loss: 1.960134949735416

Epoch: 6| Step: 12
Training loss: 1.736186146736145
Validation loss: 1.9706803060347033

Epoch: 6| Step: 13
Training loss: 1.5414166450500488
Validation loss: 1.9545555550565001

Epoch: 100| Step: 0
Training loss: 2.5504119396209717
Validation loss: 1.9607845429451234

Epoch: 6| Step: 1
Training loss: 1.513697862625122
Validation loss: 1.954552363323909

Epoch: 6| Step: 2
Training loss: 1.846977710723877
Validation loss: 1.9524513124137797

Epoch: 6| Step: 3
Training loss: 2.3269600868225098
Validation loss: 1.9489085892195344

Epoch: 6| Step: 4
Training loss: 1.868417739868164
Validation loss: 1.963320570607339

Epoch: 6| Step: 5
Training loss: 2.449308156967163
Validation loss: 1.963603392724068

Epoch: 6| Step: 6
Training loss: 2.2102537155151367
Validation loss: 1.9507399451348089

Epoch: 6| Step: 7
Training loss: 1.6984214782714844
Validation loss: 1.9573057979665778

Epoch: 6| Step: 8
Training loss: 2.7199370861053467
Validation loss: 1.9424967304352792

Epoch: 6| Step: 9
Training loss: 2.244771957397461
Validation loss: 1.9477499018433273

Epoch: 6| Step: 10
Training loss: 2.135897159576416
Validation loss: 1.96084076358426

Epoch: 6| Step: 11
Training loss: 2.294382095336914
Validation loss: 1.956681933454288

Epoch: 6| Step: 12
Training loss: 2.0062146186828613
Validation loss: 1.9555504065687939

Epoch: 6| Step: 13
Training loss: 2.0308825969696045
Validation loss: 1.9541275129523328

Epoch: 101| Step: 0
Training loss: 1.5656522512435913
Validation loss: 1.9614640576865083

Epoch: 6| Step: 1
Training loss: 2.3888440132141113
Validation loss: 1.9434067677426081

Epoch: 6| Step: 2
Training loss: 2.2852046489715576
Validation loss: 1.9563118693649129

Epoch: 6| Step: 3
Training loss: 2.9319162368774414
Validation loss: 1.9460134544680197

Epoch: 6| Step: 4
Training loss: 2.829895257949829
Validation loss: 1.9389731038001277

Epoch: 6| Step: 5
Training loss: 2.3941445350646973
Validation loss: 1.9582587365181214

Epoch: 6| Step: 6
Training loss: 1.99357008934021
Validation loss: 1.9676321424463743

Epoch: 6| Step: 7
Training loss: 2.0979480743408203
Validation loss: 1.9469663661013368

Epoch: 6| Step: 8
Training loss: 2.46075177192688
Validation loss: 1.9470193591169132

Epoch: 6| Step: 9
Training loss: 1.6338763236999512
Validation loss: 1.9664190558977024

Epoch: 6| Step: 10
Training loss: 1.9967224597930908
Validation loss: 1.947142994532021

Epoch: 6| Step: 11
Training loss: 1.28193998336792
Validation loss: 1.9500436757200508

Epoch: 6| Step: 12
Training loss: 1.9544175863265991
Validation loss: 1.9601532272113267

Epoch: 6| Step: 13
Training loss: 1.9669435024261475
Validation loss: 1.9760449483830442

Epoch: 102| Step: 0
Training loss: 2.4804494380950928
Validation loss: 1.961178102800923

Epoch: 6| Step: 1
Training loss: 2.1205687522888184
Validation loss: 1.9667970826548915

Epoch: 6| Step: 2
Training loss: 1.9393079280853271
Validation loss: 1.9546294955797092

Epoch: 6| Step: 3
Training loss: 2.3808701038360596
Validation loss: 1.9450545221246698

Epoch: 6| Step: 4
Training loss: 3.081395149230957
Validation loss: 1.9463598933271182

Epoch: 6| Step: 5
Training loss: 1.6733307838439941
Validation loss: 1.9601545679953791

Epoch: 6| Step: 6
Training loss: 2.0561721324920654
Validation loss: 1.94952311951627

Epoch: 6| Step: 7
Training loss: 1.9782007932662964
Validation loss: 1.959935131893363

Epoch: 6| Step: 8
Training loss: 2.1916093826293945
Validation loss: 1.9524858920804915

Epoch: 6| Step: 9
Training loss: 1.7411304712295532
Validation loss: 1.9762297176545667

Epoch: 6| Step: 10
Training loss: 2.271637439727783
Validation loss: 1.9407882357156405

Epoch: 6| Step: 11
Training loss: 2.1166698932647705
Validation loss: 1.9651083074590212

Epoch: 6| Step: 12
Training loss: 1.7071328163146973
Validation loss: 1.9486819864601217

Epoch: 6| Step: 13
Training loss: 2.257205009460449
Validation loss: 1.9734707045298752

Epoch: 103| Step: 0
Training loss: 1.7337048053741455
Validation loss: 1.9394533557276572

Epoch: 6| Step: 1
Training loss: 1.920796513557434
Validation loss: 1.9677075160446988

Epoch: 6| Step: 2
Training loss: 1.73930025100708
Validation loss: 1.967963045643222

Epoch: 6| Step: 3
Training loss: 2.0984413623809814
Validation loss: 1.9595063950425835

Epoch: 6| Step: 4
Training loss: 1.6726254224777222
Validation loss: 1.9393577985866095

Epoch: 6| Step: 5
Training loss: 2.203899383544922
Validation loss: 1.9411182788110548

Epoch: 6| Step: 6
Training loss: 2.577528476715088
Validation loss: 1.9464558324506205

Epoch: 6| Step: 7
Training loss: 1.6670091152191162
Validation loss: 1.9448644243260866

Epoch: 6| Step: 8
Training loss: 3.142493486404419
Validation loss: 1.9516173921605593

Epoch: 6| Step: 9
Training loss: 1.948463797569275
Validation loss: 1.9526947723921908

Epoch: 6| Step: 10
Training loss: 1.7407760620117188
Validation loss: 1.961243974265232

Epoch: 6| Step: 11
Training loss: 3.068448066711426
Validation loss: 1.9410053094228108

Epoch: 6| Step: 12
Training loss: 2.1169064044952393
Validation loss: 1.945619252420241

Epoch: 6| Step: 13
Training loss: 2.3565845489501953
Validation loss: 1.9388290887237878

Epoch: 104| Step: 0
Training loss: 2.1972906589508057
Validation loss: 1.95911148799363

Epoch: 6| Step: 1
Training loss: 1.925293207168579
Validation loss: 1.933454462276992

Epoch: 6| Step: 2
Training loss: 1.885251760482788
Validation loss: 1.9434301853179932

Epoch: 6| Step: 3
Training loss: 1.5927691459655762
Validation loss: 1.9380300634650773

Epoch: 6| Step: 4
Training loss: 2.5701122283935547
Validation loss: 1.952060599480906

Epoch: 6| Step: 5
Training loss: 2.3899452686309814
Validation loss: 1.9500423990270144

Epoch: 6| Step: 6
Training loss: 2.013685941696167
Validation loss: 1.9589023602906095

Epoch: 6| Step: 7
Training loss: 2.1483612060546875
Validation loss: 1.964451354037049

Epoch: 6| Step: 8
Training loss: 1.3568408489227295
Validation loss: 1.9615493846196

Epoch: 6| Step: 9
Training loss: 1.5595126152038574
Validation loss: 1.9699329804348689

Epoch: 6| Step: 10
Training loss: 2.818485736846924
Validation loss: 1.9690654662347609

Epoch: 6| Step: 11
Training loss: 2.4309816360473633
Validation loss: 1.9309146288902528

Epoch: 6| Step: 12
Training loss: 2.434802770614624
Validation loss: 1.9547218686790877

Epoch: 6| Step: 13
Training loss: 3.0235595703125
Validation loss: 1.9652432421202302

Epoch: 105| Step: 0
Training loss: 1.670649766921997
Validation loss: 1.9487625501489128

Epoch: 6| Step: 1
Training loss: 2.457798957824707
Validation loss: 1.9742776091380785

Epoch: 6| Step: 2
Training loss: 2.0198161602020264
Validation loss: 1.969372477582706

Epoch: 6| Step: 3
Training loss: 1.6160527467727661
Validation loss: 1.9519227384239115

Epoch: 6| Step: 4
Training loss: 2.385960578918457
Validation loss: 1.9543386608041742

Epoch: 6| Step: 5
Training loss: 2.075232982635498
Validation loss: 1.9629339646267634

Epoch: 6| Step: 6
Training loss: 2.8794174194335938
Validation loss: 1.9513769085689256

Epoch: 6| Step: 7
Training loss: 1.7860240936279297
Validation loss: 1.9587718415003952

Epoch: 6| Step: 8
Training loss: 2.650200128555298
Validation loss: 1.9654031620230725

Epoch: 6| Step: 9
Training loss: 2.3951165676116943
Validation loss: 1.9505179543648996

Epoch: 6| Step: 10
Training loss: 2.1573941707611084
Validation loss: 1.959664693442724

Epoch: 6| Step: 11
Training loss: 1.8530054092407227
Validation loss: 1.9431494448774604

Epoch: 6| Step: 12
Training loss: 2.0618066787719727
Validation loss: 1.9447460007923905

Epoch: 6| Step: 13
Training loss: 1.4751142263412476
Validation loss: 1.9578351538668397

Epoch: 106| Step: 0
Training loss: 2.252558946609497
Validation loss: 1.9499023575936594

Epoch: 6| Step: 1
Training loss: 2.054577589035034
Validation loss: 1.9627882011475102

Epoch: 6| Step: 2
Training loss: 2.415250778198242
Validation loss: 1.9691584661442747

Epoch: 6| Step: 3
Training loss: 2.6103944778442383
Validation loss: 1.9462729436095043

Epoch: 6| Step: 4
Training loss: 1.7029974460601807
Validation loss: 1.9649587779916742

Epoch: 6| Step: 5
Training loss: 1.9763730764389038
Validation loss: 1.964109577158446

Epoch: 6| Step: 6
Training loss: 2.1088640689849854
Validation loss: 1.9776320790731778

Epoch: 6| Step: 7
Training loss: 2.0884275436401367
Validation loss: 1.9543778793786162

Epoch: 6| Step: 8
Training loss: 1.804115653038025
Validation loss: 1.9640904857266335

Epoch: 6| Step: 9
Training loss: 1.562653660774231
Validation loss: 1.9511042974328483

Epoch: 6| Step: 10
Training loss: 2.3181049823760986
Validation loss: 1.9510554293150544

Epoch: 6| Step: 11
Training loss: 1.8980259895324707
Validation loss: 1.9795839837802354

Epoch: 6| Step: 12
Training loss: 2.4889566898345947
Validation loss: 1.9547791096471971

Epoch: 6| Step: 13
Training loss: 2.652219533920288
Validation loss: 1.9777392777063514

Epoch: 107| Step: 0
Training loss: 2.379779815673828
Validation loss: 1.9734665604047879

Epoch: 6| Step: 1
Training loss: 2.509673595428467
Validation loss: 1.9586706033316992

Epoch: 6| Step: 2
Training loss: 2.3761520385742188
Validation loss: 1.9662172320068523

Epoch: 6| Step: 3
Training loss: 1.8568809032440186
Validation loss: 1.9670374085826259

Epoch: 6| Step: 4
Training loss: 1.994236946105957
Validation loss: 1.9640658952856576

Epoch: 6| Step: 5
Training loss: 1.6082847118377686
Validation loss: 1.9503646384003341

Epoch: 6| Step: 6
Training loss: 2.838336706161499
Validation loss: 1.9604230414154709

Epoch: 6| Step: 7
Training loss: 2.067455291748047
Validation loss: 1.939696115832175

Epoch: 6| Step: 8
Training loss: 1.8901088237762451
Validation loss: 1.9473843779615176

Epoch: 6| Step: 9
Training loss: 2.0975699424743652
Validation loss: 1.9608113534988896

Epoch: 6| Step: 10
Training loss: 2.639498233795166
Validation loss: 1.9629519985568138

Epoch: 6| Step: 11
Training loss: 1.3530101776123047
Validation loss: 1.9599162814437703

Epoch: 6| Step: 12
Training loss: 1.941394329071045
Validation loss: 1.96850920748967

Epoch: 6| Step: 13
Training loss: 2.130669116973877
Validation loss: 1.9529466577755508

Epoch: 108| Step: 0
Training loss: 2.427835464477539
Validation loss: 1.967410623386342

Epoch: 6| Step: 1
Training loss: 2.164076328277588
Validation loss: 1.9601942031614241

Epoch: 6| Step: 2
Training loss: 1.8881402015686035
Validation loss: 1.9736048175442604

Epoch: 6| Step: 3
Training loss: 1.8151178359985352
Validation loss: 1.947218341212119

Epoch: 6| Step: 4
Training loss: 2.439180850982666
Validation loss: 1.9503819327200613

Epoch: 6| Step: 5
Training loss: 2.4375720024108887
Validation loss: 1.984899176064358

Epoch: 6| Step: 6
Training loss: 2.299950122833252
Validation loss: 1.9651179300841464

Epoch: 6| Step: 7
Training loss: 2.0331382751464844
Validation loss: 1.9651500909559187

Epoch: 6| Step: 8
Training loss: 1.6395093202590942
Validation loss: 1.9817749274674283

Epoch: 6| Step: 9
Training loss: 1.4472522735595703
Validation loss: 1.9856391606792327

Epoch: 6| Step: 10
Training loss: 2.6017518043518066
Validation loss: 1.9920303949745752

Epoch: 6| Step: 11
Training loss: 2.001361131668091
Validation loss: 1.9937396228954356

Epoch: 6| Step: 12
Training loss: 2.154359817504883
Validation loss: 1.999275234437758

Epoch: 6| Step: 13
Training loss: 2.7384557723999023
Validation loss: 1.9769617972835418

Epoch: 109| Step: 0
Training loss: 1.7228858470916748
Validation loss: 1.9861097489633868

Epoch: 6| Step: 1
Training loss: 1.8315598964691162
Validation loss: 1.987048049126902

Epoch: 6| Step: 2
Training loss: 2.0182676315307617
Validation loss: 1.969741936652891

Epoch: 6| Step: 3
Training loss: 1.7350492477416992
Validation loss: 1.967160940170288

Epoch: 6| Step: 4
Training loss: 2.141692876815796
Validation loss: 1.9801266013935048

Epoch: 6| Step: 5
Training loss: 2.4271068572998047
Validation loss: 1.9736624533130276

Epoch: 6| Step: 6
Training loss: 1.4787954092025757
Validation loss: 1.9568136097282491

Epoch: 6| Step: 7
Training loss: 2.3122289180755615
Validation loss: 1.9523443868083339

Epoch: 6| Step: 8
Training loss: 1.98762845993042
Validation loss: 1.9600953786603865

Epoch: 6| Step: 9
Training loss: 2.0348148345947266
Validation loss: 1.944720648950146

Epoch: 6| Step: 10
Training loss: 2.644155263900757
Validation loss: 1.955087387433616

Epoch: 6| Step: 11
Training loss: 2.699369192123413
Validation loss: 1.953068733215332

Epoch: 6| Step: 12
Training loss: 2.5738322734832764
Validation loss: 1.9465586036764166

Epoch: 6| Step: 13
Training loss: 1.4756587743759155
Validation loss: 1.945969279094409

Epoch: 110| Step: 0
Training loss: 2.766307830810547
Validation loss: 1.9415925895014117

Epoch: 6| Step: 1
Training loss: 1.706892967224121
Validation loss: 1.9303404541425808

Epoch: 6| Step: 2
Training loss: 1.8205550909042358
Validation loss: 1.9302448970015331

Epoch: 6| Step: 3
Training loss: 2.0420103073120117
Validation loss: 1.957295661331505

Epoch: 6| Step: 4
Training loss: 1.933236002922058
Validation loss: 1.9444998054094211

Epoch: 6| Step: 5
Training loss: 2.240696668624878
Validation loss: 1.9593049095522972

Epoch: 6| Step: 6
Training loss: 2.1469037532806396
Validation loss: 1.9570832919049006

Epoch: 6| Step: 7
Training loss: 1.842933177947998
Validation loss: 1.9522784397166262

Epoch: 6| Step: 8
Training loss: 2.1180338859558105
Validation loss: 1.9340619528165428

Epoch: 6| Step: 9
Training loss: 2.27961802482605
Validation loss: 1.9234364622382707

Epoch: 6| Step: 10
Training loss: 2.242725133895874
Validation loss: 1.9724894441584104

Epoch: 6| Step: 11
Training loss: 1.938676357269287
Validation loss: 1.948847911691153

Epoch: 6| Step: 12
Training loss: 2.147165060043335
Validation loss: 1.9367939861871863

Epoch: 6| Step: 13
Training loss: 2.2592005729675293
Validation loss: 1.9405982725081905

Epoch: 111| Step: 0
Training loss: 1.8694628477096558
Validation loss: 1.9411511421203613

Epoch: 6| Step: 1
Training loss: 1.7979953289031982
Validation loss: 1.9487404425938923

Epoch: 6| Step: 2
Training loss: 2.08815860748291
Validation loss: 1.9527296032956851

Epoch: 6| Step: 3
Training loss: 1.8222553730010986
Validation loss: 1.9526283753815519

Epoch: 6| Step: 4
Training loss: 2.1335411071777344
Validation loss: 1.9484629079859743

Epoch: 6| Step: 5
Training loss: 2.206319808959961
Validation loss: 1.9514627918120353

Epoch: 6| Step: 6
Training loss: 1.7571111917495728
Validation loss: 1.9529852456943964

Epoch: 6| Step: 7
Training loss: 2.230419397354126
Validation loss: 1.9615582291797926

Epoch: 6| Step: 8
Training loss: 2.9979655742645264
Validation loss: 1.9494670526955717

Epoch: 6| Step: 9
Training loss: 2.14676570892334
Validation loss: 1.939897708995368

Epoch: 6| Step: 10
Training loss: 1.504460334777832
Validation loss: 1.9532988609806183

Epoch: 6| Step: 11
Training loss: 2.366811513900757
Validation loss: 1.9322845538457234

Epoch: 6| Step: 12
Training loss: 2.4961509704589844
Validation loss: 1.9569528974512571

Epoch: 6| Step: 13
Training loss: 1.7952897548675537
Validation loss: 1.9499593332249632

Epoch: 112| Step: 0
Training loss: 1.9782510995864868
Validation loss: 1.9394869240381385

Epoch: 6| Step: 1
Training loss: 1.3359096050262451
Validation loss: 1.945577839369415

Epoch: 6| Step: 2
Training loss: 2.3170580863952637
Validation loss: 1.9494200214262931

Epoch: 6| Step: 3
Training loss: 2.2744410037994385
Validation loss: 1.962448678990846

Epoch: 6| Step: 4
Training loss: 2.006247043609619
Validation loss: 1.9585580236168318

Epoch: 6| Step: 5
Training loss: 2.8099966049194336
Validation loss: 1.9502956046853015

Epoch: 6| Step: 6
Training loss: 1.988875389099121
Validation loss: 1.9464098176648539

Epoch: 6| Step: 7
Training loss: 2.459289789199829
Validation loss: 1.9616844628446846

Epoch: 6| Step: 8
Training loss: 1.6340326070785522
Validation loss: 1.9509145982803837

Epoch: 6| Step: 9
Training loss: 2.640746593475342
Validation loss: 1.9605852967949324

Epoch: 6| Step: 10
Training loss: 2.6997759342193604
Validation loss: 1.9639859430251583

Epoch: 6| Step: 11
Training loss: 1.4978893995285034
Validation loss: 1.9707109723039853

Epoch: 6| Step: 12
Training loss: 1.5725244283676147
Validation loss: 1.947009587800631

Epoch: 6| Step: 13
Training loss: 2.2234885692596436
Validation loss: 1.9692277267415037

Epoch: 113| Step: 0
Training loss: 2.4504992961883545
Validation loss: 1.9576891212053196

Epoch: 6| Step: 1
Training loss: 2.038085460662842
Validation loss: 1.946860541579544

Epoch: 6| Step: 2
Training loss: 1.864384651184082
Validation loss: 1.9606641146444506

Epoch: 6| Step: 3
Training loss: 2.285370349884033
Validation loss: 1.947326188446373

Epoch: 6| Step: 4
Training loss: 2.2345938682556152
Validation loss: 1.9498795399101831

Epoch: 6| Step: 5
Training loss: 2.103026866912842
Validation loss: 1.941185664105159

Epoch: 6| Step: 6
Training loss: 1.3228248357772827
Validation loss: 1.9634180825243714

Epoch: 6| Step: 7
Training loss: 2.8266353607177734
Validation loss: 1.9495435427593928

Epoch: 6| Step: 8
Training loss: 2.3940529823303223
Validation loss: 1.9607686932368944

Epoch: 6| Step: 9
Training loss: 2.4011611938476562
Validation loss: 1.9471690629118232

Epoch: 6| Step: 10
Training loss: 2.4754655361175537
Validation loss: 1.9523700488510953

Epoch: 6| Step: 11
Training loss: 1.4642457962036133
Validation loss: 1.9747929214149393

Epoch: 6| Step: 12
Training loss: 1.4887781143188477
Validation loss: 1.975217996105071

Epoch: 6| Step: 13
Training loss: 2.0064377784729004
Validation loss: 1.9587570903121785

Epoch: 114| Step: 0
Training loss: 2.0694708824157715
Validation loss: 1.9520560156914495

Epoch: 6| Step: 1
Training loss: 2.4068636894226074
Validation loss: 1.964555145591818

Epoch: 6| Step: 2
Training loss: 1.9213268756866455
Validation loss: 1.9507917050392396

Epoch: 6| Step: 3
Training loss: 2.0317492485046387
Validation loss: 1.954450713690891

Epoch: 6| Step: 4
Training loss: 2.1496832370758057
Validation loss: 1.9752001916208575

Epoch: 6| Step: 5
Training loss: 2.465942859649658
Validation loss: 1.9392241457457184

Epoch: 6| Step: 6
Training loss: 2.1613781452178955
Validation loss: 1.9538862923140168

Epoch: 6| Step: 7
Training loss: 2.047959566116333
Validation loss: 1.9499884728462464

Epoch: 6| Step: 8
Training loss: 2.2203590869903564
Validation loss: 1.958627841805899

Epoch: 6| Step: 9
Training loss: 2.466796875
Validation loss: 1.95688727466009

Epoch: 6| Step: 10
Training loss: 1.9344028234481812
Validation loss: 1.954385272918209

Epoch: 6| Step: 11
Training loss: 2.059704303741455
Validation loss: 1.9848703825345604

Epoch: 6| Step: 12
Training loss: 1.5528180599212646
Validation loss: 1.9549038756278254

Epoch: 6| Step: 13
Training loss: 1.8269238471984863
Validation loss: 1.9746158020470732

Epoch: 115| Step: 0
Training loss: 2.146939277648926
Validation loss: 1.9601697550025037

Epoch: 6| Step: 1
Training loss: 2.4878406524658203
Validation loss: 1.9544127833458684

Epoch: 6| Step: 2
Training loss: 2.1963725090026855
Validation loss: 1.971251456968246

Epoch: 6| Step: 3
Training loss: 1.9162853956222534
Validation loss: 1.9917806130583569

Epoch: 6| Step: 4
Training loss: 1.7655006647109985
Validation loss: 1.9870178212401688

Epoch: 6| Step: 5
Training loss: 1.9572460651397705
Validation loss: 1.962929509019339

Epoch: 6| Step: 6
Training loss: 2.3351879119873047
Validation loss: 1.9774110471048663

Epoch: 6| Step: 7
Training loss: 2.352691173553467
Validation loss: 1.9693745720771052

Epoch: 6| Step: 8
Training loss: 1.7257609367370605
Validation loss: 2.0015149347243772

Epoch: 6| Step: 9
Training loss: 1.7999372482299805
Validation loss: 1.9932540962772984

Epoch: 6| Step: 10
Training loss: 2.3282549381256104
Validation loss: 1.9922303550986833

Epoch: 6| Step: 11
Training loss: 1.787877082824707
Validation loss: 1.9713659055771366

Epoch: 6| Step: 12
Training loss: 2.2706551551818848
Validation loss: 1.9558433819842596

Epoch: 6| Step: 13
Training loss: 2.6581082344055176
Validation loss: 1.9662511374360772

Epoch: 116| Step: 0
Training loss: 1.4573204517364502
Validation loss: 1.9842334511459514

Epoch: 6| Step: 1
Training loss: 1.5515350103378296
Validation loss: 1.9674890810443508

Epoch: 6| Step: 2
Training loss: 1.9600272178649902
Validation loss: 1.96584479911353

Epoch: 6| Step: 3
Training loss: 2.071174383163452
Validation loss: 1.9565564534997428

Epoch: 6| Step: 4
Training loss: 2.1100456714630127
Validation loss: 1.9470823810946556

Epoch: 6| Step: 5
Training loss: 2.9312124252319336
Validation loss: 1.9433663199024815

Epoch: 6| Step: 6
Training loss: 2.3979921340942383
Validation loss: 1.9287453492482503

Epoch: 6| Step: 7
Training loss: 2.10911226272583
Validation loss: 1.9486627783826602

Epoch: 6| Step: 8
Training loss: 1.8014442920684814
Validation loss: 1.9399782842205417

Epoch: 6| Step: 9
Training loss: 2.7256250381469727
Validation loss: 1.9416198922741799

Epoch: 6| Step: 10
Training loss: 1.9197008609771729
Validation loss: 1.9271329449069114

Epoch: 6| Step: 11
Training loss: 2.262866973876953
Validation loss: 1.9609388061749038

Epoch: 6| Step: 12
Training loss: 2.063133716583252
Validation loss: 1.949460316729802

Epoch: 6| Step: 13
Training loss: 2.1662611961364746
Validation loss: 1.951775017605033

Epoch: 117| Step: 0
Training loss: 2.0199532508850098
Validation loss: 1.950128839861962

Epoch: 6| Step: 1
Training loss: 2.292300224304199
Validation loss: 1.956741621417384

Epoch: 6| Step: 2
Training loss: 2.418875217437744
Validation loss: 1.950894045573409

Epoch: 6| Step: 3
Training loss: 2.466837167739868
Validation loss: 1.9538553837806947

Epoch: 6| Step: 4
Training loss: 2.5187430381774902
Validation loss: 1.9581350767484276

Epoch: 6| Step: 5
Training loss: 1.8507039546966553
Validation loss: 1.9612224986476283

Epoch: 6| Step: 6
Training loss: 2.372187614440918
Validation loss: 1.9559024533917826

Epoch: 6| Step: 7
Training loss: 2.6028523445129395
Validation loss: 1.9687437485623103

Epoch: 6| Step: 8
Training loss: 2.249699592590332
Validation loss: 1.9614018317191833

Epoch: 6| Step: 9
Training loss: 1.8831084966659546
Validation loss: 1.9540158497389926

Epoch: 6| Step: 10
Training loss: 1.463338851928711
Validation loss: 1.9669973209340086

Epoch: 6| Step: 11
Training loss: 1.582334280014038
Validation loss: 1.9518061068750197

Epoch: 6| Step: 12
Training loss: 1.8654851913452148
Validation loss: 1.9678417585229362

Epoch: 6| Step: 13
Training loss: 1.445973515510559
Validation loss: 1.9713188960988035

Epoch: 118| Step: 0
Training loss: 1.7642641067504883
Validation loss: 1.9486935241248018

Epoch: 6| Step: 1
Training loss: 2.182595729827881
Validation loss: 1.965694107035155

Epoch: 6| Step: 2
Training loss: 1.6293702125549316
Validation loss: 1.9570068569593533

Epoch: 6| Step: 3
Training loss: 2.634817600250244
Validation loss: 1.9763438355538152

Epoch: 6| Step: 4
Training loss: 2.3364691734313965
Validation loss: 1.978635230372029

Epoch: 6| Step: 5
Training loss: 2.330386161804199
Validation loss: 1.9694591106907013

Epoch: 6| Step: 6
Training loss: 2.231626033782959
Validation loss: 1.965928921135523

Epoch: 6| Step: 7
Training loss: 2.3299009799957275
Validation loss: 1.9653709973058393

Epoch: 6| Step: 8
Training loss: 2.0397071838378906
Validation loss: 1.9726852088846185

Epoch: 6| Step: 9
Training loss: 1.8180701732635498
Validation loss: 1.963399899903164

Epoch: 6| Step: 10
Training loss: 1.8417022228240967
Validation loss: 1.9755590859279837

Epoch: 6| Step: 11
Training loss: 1.5591425895690918
Validation loss: 1.9945931665359005

Epoch: 6| Step: 12
Training loss: 2.0923500061035156
Validation loss: 2.000668466732066

Epoch: 6| Step: 13
Training loss: 2.315751552581787
Validation loss: 1.9888218461826284

Epoch: 119| Step: 0
Training loss: 1.8792623281478882
Validation loss: 1.994923049403775

Epoch: 6| Step: 1
Training loss: 1.972691297531128
Validation loss: 1.9862238219989243

Epoch: 6| Step: 2
Training loss: 2.478797674179077
Validation loss: 1.9986077636800788

Epoch: 6| Step: 3
Training loss: 1.858662486076355
Validation loss: 1.9926285897531817

Epoch: 6| Step: 4
Training loss: 2.6153292655944824
Validation loss: 1.9915978408628894

Epoch: 6| Step: 5
Training loss: 1.974212646484375
Validation loss: 1.9790632135124617

Epoch: 6| Step: 6
Training loss: 2.51322603225708
Validation loss: 1.9727996780026344

Epoch: 6| Step: 7
Training loss: 1.8332245349884033
Validation loss: 1.9603851315795735

Epoch: 6| Step: 8
Training loss: 1.933555245399475
Validation loss: 1.9806123151574084

Epoch: 6| Step: 9
Training loss: 1.703681230545044
Validation loss: 1.9985479411258493

Epoch: 6| Step: 10
Training loss: 2.3825767040252686
Validation loss: 1.9853762221592728

Epoch: 6| Step: 11
Training loss: 1.7006511688232422
Validation loss: 1.9836407797310942

Epoch: 6| Step: 12
Training loss: 2.043677568435669
Validation loss: 1.9956768661416986

Epoch: 6| Step: 13
Training loss: 2.08373761177063
Validation loss: 1.9934141174439461

Epoch: 120| Step: 0
Training loss: 1.4232152700424194
Validation loss: 1.9885823777926865

Epoch: 6| Step: 1
Training loss: 2.2741339206695557
Validation loss: 1.984190179455665

Epoch: 6| Step: 2
Training loss: 1.9100241661071777
Validation loss: 1.9837266591287428

Epoch: 6| Step: 3
Training loss: 1.904036045074463
Validation loss: 1.9829597678235782

Epoch: 6| Step: 4
Training loss: 2.4944214820861816
Validation loss: 1.9828949871883597

Epoch: 6| Step: 5
Training loss: 2.132185459136963
Validation loss: 1.9863810744336856

Epoch: 6| Step: 6
Training loss: 1.4690001010894775
Validation loss: 1.9659132957458496

Epoch: 6| Step: 7
Training loss: 2.1233510971069336
Validation loss: 1.9776327353651806

Epoch: 6| Step: 8
Training loss: 1.97711980342865
Validation loss: 1.9503448086400186

Epoch: 6| Step: 9
Training loss: 1.7246150970458984
Validation loss: 1.9615443573203137

Epoch: 6| Step: 10
Training loss: 2.01450777053833
Validation loss: 1.9368353736016057

Epoch: 6| Step: 11
Training loss: 2.5106024742126465
Validation loss: 1.9592854066561627

Epoch: 6| Step: 12
Training loss: 3.3010377883911133
Validation loss: 1.952811606468693

Epoch: 6| Step: 13
Training loss: 1.6333086490631104
Validation loss: 1.9849825366850822

Epoch: 121| Step: 0
Training loss: 2.212878465652466
Validation loss: 1.9710622654166272

Epoch: 6| Step: 1
Training loss: 2.307084560394287
Validation loss: 1.966590235310216

Epoch: 6| Step: 2
Training loss: 2.0741355419158936
Validation loss: 1.9548809092531922

Epoch: 6| Step: 3
Training loss: 2.3506388664245605
Validation loss: 1.9642973202531055

Epoch: 6| Step: 4
Training loss: 2.0092763900756836
Validation loss: 1.9694441646657965

Epoch: 6| Step: 5
Training loss: 2.0331931114196777
Validation loss: 1.948253862319454

Epoch: 6| Step: 6
Training loss: 2.505624771118164
Validation loss: 1.9690939482822214

Epoch: 6| Step: 7
Training loss: 1.9819207191467285
Validation loss: 1.961126140368882

Epoch: 6| Step: 8
Training loss: 1.9355969429016113
Validation loss: 1.9645408584225563

Epoch: 6| Step: 9
Training loss: 2.2944822311401367
Validation loss: 1.9432027596299366

Epoch: 6| Step: 10
Training loss: 1.6779959201812744
Validation loss: 1.966870569413708

Epoch: 6| Step: 11
Training loss: 2.0530037879943848
Validation loss: 1.9511566610746487

Epoch: 6| Step: 12
Training loss: 1.470821738243103
Validation loss: 1.9677040269297938

Epoch: 6| Step: 13
Training loss: 2.289900779724121
Validation loss: 1.945397287286738

Epoch: 122| Step: 0
Training loss: 2.530139923095703
Validation loss: 1.9329912867597354

Epoch: 6| Step: 1
Training loss: 2.5134568214416504
Validation loss: 1.9495232861529115

Epoch: 6| Step: 2
Training loss: 1.725031852722168
Validation loss: 1.9472386606277958

Epoch: 6| Step: 3
Training loss: 2.6743812561035156
Validation loss: 1.944275777827027

Epoch: 6| Step: 4
Training loss: 2.41107439994812
Validation loss: 1.9515351992781445

Epoch: 6| Step: 5
Training loss: 1.4660630226135254
Validation loss: 1.9471882658620034

Epoch: 6| Step: 6
Training loss: 1.7312633991241455
Validation loss: 1.9333205697357014

Epoch: 6| Step: 7
Training loss: 1.6010339260101318
Validation loss: 1.9393841041031705

Epoch: 6| Step: 8
Training loss: 1.741147518157959
Validation loss: 1.9400610385402557

Epoch: 6| Step: 9
Training loss: 1.708091378211975
Validation loss: 1.9618467310423493

Epoch: 6| Step: 10
Training loss: 1.6827392578125
Validation loss: 1.9396828823192145

Epoch: 6| Step: 11
Training loss: 2.242429733276367
Validation loss: 1.9573485697469404

Epoch: 6| Step: 12
Training loss: 2.508201837539673
Validation loss: 1.9539052568456179

Epoch: 6| Step: 13
Training loss: 3.0275487899780273
Validation loss: 1.9712179514669603

Epoch: 123| Step: 0
Training loss: 2.331474781036377
Validation loss: 1.9517121827730568

Epoch: 6| Step: 1
Training loss: 2.3935811519622803
Validation loss: 1.9405430811707691

Epoch: 6| Step: 2
Training loss: 2.9387588500976562
Validation loss: 1.9583500521157378

Epoch: 6| Step: 3
Training loss: 1.1018526554107666
Validation loss: 1.972349343761321

Epoch: 6| Step: 4
Training loss: 1.8172028064727783
Validation loss: 1.9429765029620099

Epoch: 6| Step: 5
Training loss: 2.1357951164245605
Validation loss: 1.9613687402458602

Epoch: 6| Step: 6
Training loss: 1.752541184425354
Validation loss: 1.9582528696265271

Epoch: 6| Step: 7
Training loss: 2.409151077270508
Validation loss: 1.9357525046153734

Epoch: 6| Step: 8
Training loss: 2.0378518104553223
Validation loss: 1.9533609421022478

Epoch: 6| Step: 9
Training loss: 1.8753383159637451
Validation loss: 1.9538356232386764

Epoch: 6| Step: 10
Training loss: 1.5790727138519287
Validation loss: 1.9663053571536977

Epoch: 6| Step: 11
Training loss: 2.813138961791992
Validation loss: 1.9544053359698224

Epoch: 6| Step: 12
Training loss: 1.5403425693511963
Validation loss: 1.973624534504388

Epoch: 6| Step: 13
Training loss: 2.1585092544555664
Validation loss: 1.9654547963091122

Epoch: 124| Step: 0
Training loss: 2.1520068645477295
Validation loss: 1.963042607871435

Epoch: 6| Step: 1
Training loss: 1.8291282653808594
Validation loss: 1.9832171881070702

Epoch: 6| Step: 2
Training loss: 1.8215675354003906
Validation loss: 1.964504252197922

Epoch: 6| Step: 3
Training loss: 2.1769909858703613
Validation loss: 1.9542169135103944

Epoch: 6| Step: 4
Training loss: 2.7477636337280273
Validation loss: 1.932330842941038

Epoch: 6| Step: 5
Training loss: 1.847273349761963
Validation loss: 1.9511287289281045

Epoch: 6| Step: 6
Training loss: 2.247851610183716
Validation loss: 1.944037506657262

Epoch: 6| Step: 7
Training loss: 1.8269240856170654
Validation loss: 1.9421824255297262

Epoch: 6| Step: 8
Training loss: 1.8940577507019043
Validation loss: 1.952094836901593

Epoch: 6| Step: 9
Training loss: 2.1766796112060547
Validation loss: 1.9572105651260705

Epoch: 6| Step: 10
Training loss: 2.0505127906799316
Validation loss: 1.9383980330600534

Epoch: 6| Step: 11
Training loss: 1.6124961376190186
Validation loss: 1.9436680616871003

Epoch: 6| Step: 12
Training loss: 2.7190942764282227
Validation loss: 1.9635868200691797

Epoch: 6| Step: 13
Training loss: 1.4853508472442627
Validation loss: 1.9557976107443533

Epoch: 125| Step: 0
Training loss: 1.8142393827438354
Validation loss: 1.9513739027002805

Epoch: 6| Step: 1
Training loss: 1.7776243686676025
Validation loss: 1.9633485168539069

Epoch: 6| Step: 2
Training loss: 1.7893307209014893
Validation loss: 1.9645791463954474

Epoch: 6| Step: 3
Training loss: 2.422253370285034
Validation loss: 1.9444969341319094

Epoch: 6| Step: 4
Training loss: 2.143280029296875
Validation loss: 1.9654384428454983

Epoch: 6| Step: 5
Training loss: 2.2359824180603027
Validation loss: 1.9565910370119157

Epoch: 6| Step: 6
Training loss: 2.2495923042297363
Validation loss: 1.9583213072951122

Epoch: 6| Step: 7
Training loss: 2.3718490600585938
Validation loss: 1.9577723703076761

Epoch: 6| Step: 8
Training loss: 2.247866153717041
Validation loss: 1.9538623645741453

Epoch: 6| Step: 9
Training loss: 2.647916316986084
Validation loss: 1.9569258382243495

Epoch: 6| Step: 10
Training loss: 2.0137696266174316
Validation loss: 1.9370032625813638

Epoch: 6| Step: 11
Training loss: 1.7312257289886475
Validation loss: 1.9640594528567406

Epoch: 6| Step: 12
Training loss: 1.4155116081237793
Validation loss: 1.9664202556815198

Epoch: 6| Step: 13
Training loss: 1.7816671133041382
Validation loss: 1.9548840907312208

Epoch: 126| Step: 0
Training loss: 1.8723347187042236
Validation loss: 1.9710528876191826

Epoch: 6| Step: 1
Training loss: 2.0937886238098145
Validation loss: 1.9842333255275604

Epoch: 6| Step: 2
Training loss: 2.431550979614258
Validation loss: 1.9537047878388436

Epoch: 6| Step: 3
Training loss: 1.8427194356918335
Validation loss: 1.9588729386688561

Epoch: 6| Step: 4
Training loss: 2.373690605163574
Validation loss: 1.9654369072247577

Epoch: 6| Step: 5
Training loss: 1.959341287612915
Validation loss: 1.9455888373877412

Epoch: 6| Step: 6
Training loss: 1.802104115486145
Validation loss: 1.9903426298531153

Epoch: 6| Step: 7
Training loss: 1.8349125385284424
Validation loss: 1.9758361731806109

Epoch: 6| Step: 8
Training loss: 1.8037680387496948
Validation loss: 1.9726650702056063

Epoch: 6| Step: 9
Training loss: 2.3603687286376953
Validation loss: 1.9947210793854089

Epoch: 6| Step: 10
Training loss: 1.8927042484283447
Validation loss: 1.9844375092496154

Epoch: 6| Step: 11
Training loss: 2.567195415496826
Validation loss: 1.9624574299781554

Epoch: 6| Step: 12
Training loss: 1.8940774202346802
Validation loss: 1.9864215158647107

Epoch: 6| Step: 13
Training loss: 2.2118759155273438
Validation loss: 1.9817141922571326

Epoch: 127| Step: 0
Training loss: 1.7865312099456787
Validation loss: 1.9731803837642874

Epoch: 6| Step: 1
Training loss: 2.396341323852539
Validation loss: 1.9823022324551818

Epoch: 6| Step: 2
Training loss: 1.5712358951568604
Validation loss: 1.9786851662461475

Epoch: 6| Step: 3
Training loss: 2.9884450435638428
Validation loss: 1.9736496274189284

Epoch: 6| Step: 4
Training loss: 2.5636048316955566
Validation loss: 1.974000084784723

Epoch: 6| Step: 5
Training loss: 1.4457688331604004
Validation loss: 1.9550410547564108

Epoch: 6| Step: 6
Training loss: 1.3363144397735596
Validation loss: 1.9523893017922678

Epoch: 6| Step: 7
Training loss: 1.761584997177124
Validation loss: 1.958907747781405

Epoch: 6| Step: 8
Training loss: 2.4248814582824707
Validation loss: 1.949807579799365

Epoch: 6| Step: 9
Training loss: 2.652151107788086
Validation loss: 1.970402084371095

Epoch: 6| Step: 10
Training loss: 1.365450143814087
Validation loss: 1.940128085433796

Epoch: 6| Step: 11
Training loss: 1.6499688625335693
Validation loss: 1.9353047365783362

Epoch: 6| Step: 12
Training loss: 2.5711669921875
Validation loss: 1.9622422956651258

Epoch: 6| Step: 13
Training loss: 2.392909049987793
Validation loss: 1.96885863683557

Epoch: 128| Step: 0
Training loss: 1.8129692077636719
Validation loss: 1.9514442823266471

Epoch: 6| Step: 1
Training loss: 1.7200396060943604
Validation loss: 1.956539442462306

Epoch: 6| Step: 2
Training loss: 1.7991065979003906
Validation loss: 1.9573339710953415

Epoch: 6| Step: 3
Training loss: 2.5704784393310547
Validation loss: 1.9286382095788115

Epoch: 6| Step: 4
Training loss: 1.1008410453796387
Validation loss: 1.9364339164508286

Epoch: 6| Step: 5
Training loss: 1.9504525661468506
Validation loss: 1.9336837722409157

Epoch: 6| Step: 6
Training loss: 2.4141809940338135
Validation loss: 1.9309471781535814

Epoch: 6| Step: 7
Training loss: 2.1432108879089355
Validation loss: 1.9358149151648245

Epoch: 6| Step: 8
Training loss: 1.6310703754425049
Validation loss: 1.9514393345002206

Epoch: 6| Step: 9
Training loss: 2.8299098014831543
Validation loss: 1.9334000579772457

Epoch: 6| Step: 10
Training loss: 2.72680926322937
Validation loss: 1.9447764978613904

Epoch: 6| Step: 11
Training loss: 2.2139370441436768
Validation loss: 1.9361673734521354

Epoch: 6| Step: 12
Training loss: 1.9748482704162598
Validation loss: 1.9499282606186406

Epoch: 6| Step: 13
Training loss: 1.6899418830871582
Validation loss: 1.956274147956602

Epoch: 129| Step: 0
Training loss: 2.729633331298828
Validation loss: 1.953832378951452

Epoch: 6| Step: 1
Training loss: 1.8107450008392334
Validation loss: 1.9645478263978036

Epoch: 6| Step: 2
Training loss: 2.5956015586853027
Validation loss: 1.9544545886337117

Epoch: 6| Step: 3
Training loss: 1.4676105976104736
Validation loss: 1.9510105681675736

Epoch: 6| Step: 4
Training loss: 2.1459274291992188
Validation loss: 1.9554534560890608

Epoch: 6| Step: 5
Training loss: 1.6124162673950195
Validation loss: 1.9889256608101629

Epoch: 6| Step: 6
Training loss: 1.9159259796142578
Validation loss: 1.9543362086819065

Epoch: 6| Step: 7
Training loss: 2.59710693359375
Validation loss: 1.95569489079137

Epoch: 6| Step: 8
Training loss: 2.228714942932129
Validation loss: 1.9557229652199695

Epoch: 6| Step: 9
Training loss: 1.7856261730194092
Validation loss: 1.954651786435035

Epoch: 6| Step: 10
Training loss: 1.7629226446151733
Validation loss: 1.9765287522346742

Epoch: 6| Step: 11
Training loss: 1.9606657028198242
Validation loss: 1.9555803383550336

Epoch: 6| Step: 12
Training loss: 2.1490321159362793
Validation loss: 1.9929022853092482

Epoch: 6| Step: 13
Training loss: 1.6676595211029053
Validation loss: 1.994692983165864

Epoch: 130| Step: 0
Training loss: 2.304922342300415
Validation loss: 1.9604559816339964

Epoch: 6| Step: 1
Training loss: 2.5552759170532227
Validation loss: 1.9650886930445188

Epoch: 6| Step: 2
Training loss: 1.8258116245269775
Validation loss: 1.976405579556701

Epoch: 6| Step: 3
Training loss: 1.7391221523284912
Validation loss: 1.977524157493345

Epoch: 6| Step: 4
Training loss: 2.021987199783325
Validation loss: 1.9611432103700535

Epoch: 6| Step: 5
Training loss: 2.2191944122314453
Validation loss: 1.9814426232409734

Epoch: 6| Step: 6
Training loss: 1.9566187858581543
Validation loss: 1.9703479300263107

Epoch: 6| Step: 7
Training loss: 2.150009870529175
Validation loss: 1.9609516179689797

Epoch: 6| Step: 8
Training loss: 2.4910407066345215
Validation loss: 1.9583143777744745

Epoch: 6| Step: 9
Training loss: 1.4971907138824463
Validation loss: 1.9607113330594954

Epoch: 6| Step: 10
Training loss: 2.0614495277404785
Validation loss: 1.9665709003325431

Epoch: 6| Step: 11
Training loss: 2.1627964973449707
Validation loss: 1.9656659146790862

Epoch: 6| Step: 12
Training loss: 1.404894232749939
Validation loss: 1.9524290407857587

Epoch: 6| Step: 13
Training loss: 2.289245843887329
Validation loss: 1.9603419624349123

Epoch: 131| Step: 0
Training loss: 1.6405658721923828
Validation loss: 1.9602129843927198

Epoch: 6| Step: 1
Training loss: 2.9345602989196777
Validation loss: 1.965920614939864

Epoch: 6| Step: 2
Training loss: 2.3398046493530273
Validation loss: 1.9583964258111932

Epoch: 6| Step: 3
Training loss: 1.875688076019287
Validation loss: 1.9296982096087547

Epoch: 6| Step: 4
Training loss: 2.207709789276123
Validation loss: 1.9596320800883795

Epoch: 6| Step: 5
Training loss: 2.308767318725586
Validation loss: 1.979772880513181

Epoch: 6| Step: 6
Training loss: 2.3666207790374756
Validation loss: 1.9562777601262575

Epoch: 6| Step: 7
Training loss: 1.7794445753097534
Validation loss: 1.981495411165299

Epoch: 6| Step: 8
Training loss: 1.9839017391204834
Validation loss: 1.9726653970697874

Epoch: 6| Step: 9
Training loss: 1.6039893627166748
Validation loss: 1.9534982039082436

Epoch: 6| Step: 10
Training loss: 1.7595291137695312
Validation loss: 1.9759283168341524

Epoch: 6| Step: 11
Training loss: 1.8016088008880615
Validation loss: 1.9692338922972321

Epoch: 6| Step: 12
Training loss: 1.7348763942718506
Validation loss: 1.9780078844357563

Epoch: 6| Step: 13
Training loss: 2.1526761054992676
Validation loss: 1.980833927790324

Epoch: 132| Step: 0
Training loss: 2.5316667556762695
Validation loss: 1.9546352137801468

Epoch: 6| Step: 1
Training loss: 2.886396646499634
Validation loss: 1.97237999849422

Epoch: 6| Step: 2
Training loss: 1.2718172073364258
Validation loss: 1.9492343971806187

Epoch: 6| Step: 3
Training loss: 2.9609341621398926
Validation loss: 1.978516173619096

Epoch: 6| Step: 4
Training loss: 2.4074177742004395
Validation loss: 1.9425099203663487

Epoch: 6| Step: 5
Training loss: 1.8378257751464844
Validation loss: 1.9635529159217753

Epoch: 6| Step: 6
Training loss: 2.1415140628814697
Validation loss: 1.9524351396868307

Epoch: 6| Step: 7
Training loss: 1.015976905822754
Validation loss: 1.9454508289214103

Epoch: 6| Step: 8
Training loss: 1.9051042795181274
Validation loss: 1.9548389616832937

Epoch: 6| Step: 9
Training loss: 2.386817455291748
Validation loss: 1.9324417601349533

Epoch: 6| Step: 10
Training loss: 1.6084511280059814
Validation loss: 1.9585103886101836

Epoch: 6| Step: 11
Training loss: 1.8956706523895264
Validation loss: 1.9508186386477562

Epoch: 6| Step: 12
Training loss: 2.0056679248809814
Validation loss: 1.9550133635920863

Epoch: 6| Step: 13
Training loss: 1.5723392963409424
Validation loss: 1.9447389443715413

Epoch: 133| Step: 0
Training loss: 2.716891288757324
Validation loss: 1.9321998139863372

Epoch: 6| Step: 1
Training loss: 2.1768486499786377
Validation loss: 1.926790693754791

Epoch: 6| Step: 2
Training loss: 1.8889211416244507
Validation loss: 1.9702809446601457

Epoch: 6| Step: 3
Training loss: 1.566493034362793
Validation loss: 1.9498609163427865

Epoch: 6| Step: 4
Training loss: 2.1547012329101562
Validation loss: 1.9470320106834493

Epoch: 6| Step: 5
Training loss: 2.104524850845337
Validation loss: 1.9407839672539824

Epoch: 6| Step: 6
Training loss: 2.3418126106262207
Validation loss: 1.959135655433901

Epoch: 6| Step: 7
Training loss: 2.175893783569336
Validation loss: 1.9518446383937713

Epoch: 6| Step: 8
Training loss: 2.548861026763916
Validation loss: 1.9414486808161582

Epoch: 6| Step: 9
Training loss: 1.7080464363098145
Validation loss: 1.933966589230363

Epoch: 6| Step: 10
Training loss: 2.0338149070739746
Validation loss: 1.9399569111485635

Epoch: 6| Step: 11
Training loss: 1.6606369018554688
Validation loss: 1.969161762986132

Epoch: 6| Step: 12
Training loss: 1.6137504577636719
Validation loss: 1.9311385282906153

Epoch: 6| Step: 13
Training loss: 1.4391669034957886
Validation loss: 1.9642831728022585

Epoch: 134| Step: 0
Training loss: 1.5206257104873657
Validation loss: 1.9545085442963468

Epoch: 6| Step: 1
Training loss: 2.768397092819214
Validation loss: 1.9500895905238327

Epoch: 6| Step: 2
Training loss: 1.8623839616775513
Validation loss: 1.9592189314544841

Epoch: 6| Step: 3
Training loss: 1.742077350616455
Validation loss: 1.9739544442904893

Epoch: 6| Step: 4
Training loss: 2.3583216667175293
Validation loss: 1.9464906107994817

Epoch: 6| Step: 5
Training loss: 1.8831855058670044
Validation loss: 1.9503252711347354

Epoch: 6| Step: 6
Training loss: 2.232069492340088
Validation loss: 1.966013890440746

Epoch: 6| Step: 7
Training loss: 1.968894600868225
Validation loss: 1.951123014573128

Epoch: 6| Step: 8
Training loss: 1.5305061340332031
Validation loss: 1.9377343603359756

Epoch: 6| Step: 9
Training loss: 1.9548306465148926
Validation loss: 1.954130954639886

Epoch: 6| Step: 10
Training loss: 2.4954662322998047
Validation loss: 1.94913899642165

Epoch: 6| Step: 11
Training loss: 1.2462912797927856
Validation loss: 1.9550524193753478

Epoch: 6| Step: 12
Training loss: 2.9288196563720703
Validation loss: 1.9667817290111254

Epoch: 6| Step: 13
Training loss: 1.758442759513855
Validation loss: 1.9420315014418734

Epoch: 135| Step: 0
Training loss: 1.9104019403457642
Validation loss: 1.9410706079134377

Epoch: 6| Step: 1
Training loss: 1.775244951248169
Validation loss: 1.9578966479147635

Epoch: 6| Step: 2
Training loss: 2.9727134704589844
Validation loss: 1.936299124071675

Epoch: 6| Step: 3
Training loss: 1.9961130619049072
Validation loss: 1.9607903342093191

Epoch: 6| Step: 4
Training loss: 1.9560834169387817
Validation loss: 1.9567646467557518

Epoch: 6| Step: 5
Training loss: 2.4935302734375
Validation loss: 1.940804084142049

Epoch: 6| Step: 6
Training loss: 2.3258118629455566
Validation loss: 1.9693896514113232

Epoch: 6| Step: 7
Training loss: 1.4720041751861572
Validation loss: 1.9390034444870488

Epoch: 6| Step: 8
Training loss: 1.785406470298767
Validation loss: 1.9253454169919413

Epoch: 6| Step: 9
Training loss: 1.693607211112976
Validation loss: 1.9256832586821688

Epoch: 6| Step: 10
Training loss: 2.3671507835388184
Validation loss: 1.9340216139311432

Epoch: 6| Step: 11
Training loss: 1.9133658409118652
Validation loss: 1.9449066859419628

Epoch: 6| Step: 12
Training loss: 2.0932958126068115
Validation loss: 1.935767089166949

Epoch: 6| Step: 13
Training loss: 1.4228837490081787
Validation loss: 1.9486622502726894

Epoch: 136| Step: 0
Training loss: 1.4858043193817139
Validation loss: 1.9284763477181877

Epoch: 6| Step: 1
Training loss: 1.6759564876556396
Validation loss: 1.9500495362025436

Epoch: 6| Step: 2
Training loss: 1.9475524425506592
Validation loss: 1.9360288855850056

Epoch: 6| Step: 3
Training loss: 2.3908581733703613
Validation loss: 1.9627206607531476

Epoch: 6| Step: 4
Training loss: 2.1001787185668945
Validation loss: 1.9713909574734267

Epoch: 6| Step: 5
Training loss: 2.6040544509887695
Validation loss: 1.962250817206598

Epoch: 6| Step: 6
Training loss: 2.3832924365997314
Validation loss: 1.9616396196426884

Epoch: 6| Step: 7
Training loss: 2.141563653945923
Validation loss: 1.9473135240616337

Epoch: 6| Step: 8
Training loss: 1.9723081588745117
Validation loss: 1.9446912568102601

Epoch: 6| Step: 9
Training loss: 2.5165090560913086
Validation loss: 1.9431131373169601

Epoch: 6| Step: 10
Training loss: 1.8065755367279053
Validation loss: 1.961179551257882

Epoch: 6| Step: 11
Training loss: 1.8497978448867798
Validation loss: 1.9541365203037058

Epoch: 6| Step: 12
Training loss: 1.4647479057312012
Validation loss: 1.961185122048983

Epoch: 6| Step: 13
Training loss: 1.7597440481185913
Validation loss: 1.9534305782728298

Epoch: 137| Step: 0
Training loss: 1.2618207931518555
Validation loss: 1.9589160398770404

Epoch: 6| Step: 1
Training loss: 2.091742753982544
Validation loss: 1.9734875104760612

Epoch: 6| Step: 2
Training loss: 2.2928457260131836
Validation loss: 1.966865929224158

Epoch: 6| Step: 3
Training loss: 1.323014736175537
Validation loss: 1.972810899057696

Epoch: 6| Step: 4
Training loss: 2.5354747772216797
Validation loss: 1.9690059705447125

Epoch: 6| Step: 5
Training loss: 1.8649381399154663
Validation loss: 1.982699045570948

Epoch: 6| Step: 6
Training loss: 2.0829296112060547
Validation loss: 1.9926767785062072

Epoch: 6| Step: 7
Training loss: 1.4610788822174072
Validation loss: 1.9894629498963714

Epoch: 6| Step: 8
Training loss: 1.3235275745391846
Validation loss: 1.9515389063025033

Epoch: 6| Step: 9
Training loss: 2.0087153911590576
Validation loss: 1.9616128808708602

Epoch: 6| Step: 10
Training loss: 2.6527280807495117
Validation loss: 1.9664601433661677

Epoch: 6| Step: 11
Training loss: 2.435042381286621
Validation loss: 2.001866820038006

Epoch: 6| Step: 12
Training loss: 2.1328115463256836
Validation loss: 1.949226672931384

Epoch: 6| Step: 13
Training loss: 3.41811466217041
Validation loss: 1.9619938609420613

Epoch: 138| Step: 0
Training loss: 1.8045676946640015
Validation loss: 1.9535380358337073

Epoch: 6| Step: 1
Training loss: 1.7810704708099365
Validation loss: 1.9724118696746005

Epoch: 6| Step: 2
Training loss: 2.0965280532836914
Validation loss: 1.9511054600438764

Epoch: 6| Step: 3
Training loss: 2.3391168117523193
Validation loss: 1.948541880935751

Epoch: 6| Step: 4
Training loss: 2.1653075218200684
Validation loss: 1.9486433998230965

Epoch: 6| Step: 5
Training loss: 1.520787000656128
Validation loss: 1.9455189807440645

Epoch: 6| Step: 6
Training loss: 2.1031556129455566
Validation loss: 1.9620571815839378

Epoch: 6| Step: 7
Training loss: 2.5526013374328613
Validation loss: 1.9637057576128232

Epoch: 6| Step: 8
Training loss: 1.7600584030151367
Validation loss: 1.9789189907812303

Epoch: 6| Step: 9
Training loss: 2.152545690536499
Validation loss: 1.9699098487054147

Epoch: 6| Step: 10
Training loss: 2.110607385635376
Validation loss: 1.9561264284195439

Epoch: 6| Step: 11
Training loss: 2.3276784420013428
Validation loss: 1.962385836467948

Epoch: 6| Step: 12
Training loss: 1.2518908977508545
Validation loss: 1.9428346695438508

Epoch: 6| Step: 13
Training loss: 1.9723188877105713
Validation loss: 1.9648700247528732

Epoch: 139| Step: 0
Training loss: 2.417407512664795
Validation loss: 1.963455259159047

Epoch: 6| Step: 1
Training loss: 2.1232380867004395
Validation loss: 1.9570768622941868

Epoch: 6| Step: 2
Training loss: 2.1318519115448
Validation loss: 1.9359578496666365

Epoch: 6| Step: 3
Training loss: 1.6612366437911987
Validation loss: 1.9530209161901986

Epoch: 6| Step: 4
Training loss: 1.8507726192474365
Validation loss: 1.9541720190355856

Epoch: 6| Step: 5
Training loss: 2.0419201850891113
Validation loss: 1.9305555769192275

Epoch: 6| Step: 6
Training loss: 2.127549648284912
Validation loss: 1.9652976220653904

Epoch: 6| Step: 7
Training loss: 2.2277207374572754
Validation loss: 1.9454956105960313

Epoch: 6| Step: 8
Training loss: 2.0179104804992676
Validation loss: 1.950407612708307

Epoch: 6| Step: 9
Training loss: 1.96844482421875
Validation loss: 1.9368111446339598

Epoch: 6| Step: 10
Training loss: 1.7851749658584595
Validation loss: 1.9620942454184256

Epoch: 6| Step: 11
Training loss: 2.7897820472717285
Validation loss: 1.9302058604455763

Epoch: 6| Step: 12
Training loss: 1.193934679031372
Validation loss: 1.9156044003784016

Epoch: 6| Step: 13
Training loss: 1.6258374452590942
Validation loss: 1.9455589209833453

Epoch: 140| Step: 0
Training loss: 1.913451075553894
Validation loss: 1.9438360609034055

Epoch: 6| Step: 1
Training loss: 1.6803261041641235
Validation loss: 1.9314679868759648

Epoch: 6| Step: 2
Training loss: 2.786771774291992
Validation loss: 1.9350154348599014

Epoch: 6| Step: 3
Training loss: 2.292604446411133
Validation loss: 1.9346288288793256

Epoch: 6| Step: 4
Training loss: 2.4244847297668457
Validation loss: 1.9399948671299925

Epoch: 6| Step: 5
Training loss: 1.6655622720718384
Validation loss: 1.9427051505734843

Epoch: 6| Step: 6
Training loss: 2.1321091651916504
Validation loss: 1.9312434837382326

Epoch: 6| Step: 7
Training loss: 2.2500410079956055
Validation loss: 1.9420196933131064

Epoch: 6| Step: 8
Training loss: 1.2764043807983398
Validation loss: 1.9362445941535376

Epoch: 6| Step: 9
Training loss: 1.2280290126800537
Validation loss: 1.9567893589696577

Epoch: 6| Step: 10
Training loss: 2.720466136932373
Validation loss: 1.9611820379892986

Epoch: 6| Step: 11
Training loss: 1.9334802627563477
Validation loss: 1.9524454429585447

Epoch: 6| Step: 12
Training loss: 1.8170888423919678
Validation loss: 1.9470216228115944

Epoch: 6| Step: 13
Training loss: 1.9887534379959106
Validation loss: 1.9551422813887238

Epoch: 141| Step: 0
Training loss: 2.50229549407959
Validation loss: 1.9418148609899706

Epoch: 6| Step: 1
Training loss: 1.5129190683364868
Validation loss: 1.9712182667947584

Epoch: 6| Step: 2
Training loss: 1.9901686906814575
Validation loss: 1.9519728409346713

Epoch: 6| Step: 3
Training loss: 1.8290742635726929
Validation loss: 1.9647214566507647

Epoch: 6| Step: 4
Training loss: 2.5479660034179688
Validation loss: 1.9797941907759635

Epoch: 6| Step: 5
Training loss: 1.8671774864196777
Validation loss: 1.962183835685894

Epoch: 6| Step: 6
Training loss: 2.256305694580078
Validation loss: 1.9828375693290465

Epoch: 6| Step: 7
Training loss: 2.0853583812713623
Validation loss: 1.9801985192042526

Epoch: 6| Step: 8
Training loss: 1.9481160640716553
Validation loss: 1.974156960364311

Epoch: 6| Step: 9
Training loss: 1.9158419370651245
Validation loss: 1.9747285868531914

Epoch: 6| Step: 10
Training loss: 2.038339138031006
Validation loss: 1.9691826810118973

Epoch: 6| Step: 11
Training loss: 2.1894378662109375
Validation loss: 1.969422483956942

Epoch: 6| Step: 12
Training loss: 1.5575916767120361
Validation loss: 1.9404530896935412

Epoch: 6| Step: 13
Training loss: 1.3413227796554565
Validation loss: 1.9574318829403128

Epoch: 142| Step: 0
Training loss: 1.8676865100860596
Validation loss: 1.9596495397629277

Epoch: 6| Step: 1
Training loss: 1.2729589939117432
Validation loss: 1.9548602963006625

Epoch: 6| Step: 2
Training loss: 1.7619491815567017
Validation loss: 1.9549836458698395

Epoch: 6| Step: 3
Training loss: 1.6021404266357422
Validation loss: 1.9754141069227649

Epoch: 6| Step: 4
Training loss: 1.4358397722244263
Validation loss: 1.9698590181207145

Epoch: 6| Step: 5
Training loss: 2.5011255741119385
Validation loss: 1.977355601967022

Epoch: 6| Step: 6
Training loss: 2.1837892532348633
Validation loss: 1.9719660935863372

Epoch: 6| Step: 7
Training loss: 1.8597464561462402
Validation loss: 1.9604988110962736

Epoch: 6| Step: 8
Training loss: 2.0087392330169678
Validation loss: 1.973201387672014

Epoch: 6| Step: 9
Training loss: 2.520528793334961
Validation loss: 1.9660493930180867

Epoch: 6| Step: 10
Training loss: 1.6170415878295898
Validation loss: 1.9544329566340293

Epoch: 6| Step: 11
Training loss: 2.540220260620117
Validation loss: 1.94295637325574

Epoch: 6| Step: 12
Training loss: 1.9072182178497314
Validation loss: 1.9359556551902526

Epoch: 6| Step: 13
Training loss: 3.3029584884643555
Validation loss: 1.9517441770081878

Epoch: 143| Step: 0
Training loss: 2.073085308074951
Validation loss: 1.9573392150222615

Epoch: 6| Step: 1
Training loss: 2.3861353397369385
Validation loss: 1.9305429740618634

Epoch: 6| Step: 2
Training loss: 1.8312911987304688
Validation loss: 1.9462062210165045

Epoch: 6| Step: 3
Training loss: 1.5081192255020142
Validation loss: 1.94091659720226

Epoch: 6| Step: 4
Training loss: 2.7096500396728516
Validation loss: 1.9394898837612522

Epoch: 6| Step: 5
Training loss: 1.9156584739685059
Validation loss: 1.9434687834914013

Epoch: 6| Step: 6
Training loss: 1.8105576038360596
Validation loss: 1.9525309775465278

Epoch: 6| Step: 7
Training loss: 1.6579536199569702
Validation loss: 1.9406497440030497

Epoch: 6| Step: 8
Training loss: 2.1805179119110107
Validation loss: 1.9343993356150966

Epoch: 6| Step: 9
Training loss: 1.602079153060913
Validation loss: 1.9324447852309032

Epoch: 6| Step: 10
Training loss: 2.4272284507751465
Validation loss: 1.9179040270466958

Epoch: 6| Step: 11
Training loss: 1.8520174026489258
Validation loss: 1.9180223275256414

Epoch: 6| Step: 12
Training loss: 1.7764410972595215
Validation loss: 1.9267160943759385

Epoch: 6| Step: 13
Training loss: 2.4945948123931885
Validation loss: 1.933093463220904

Epoch: 144| Step: 0
Training loss: 1.9208017587661743
Validation loss: 1.9573460689155004

Epoch: 6| Step: 1
Training loss: 1.8627727031707764
Validation loss: 1.9578602031994892

Epoch: 6| Step: 2
Training loss: 1.490977168083191
Validation loss: 1.9574371614763815

Epoch: 6| Step: 3
Training loss: 2.521827220916748
Validation loss: 1.9397771717399679

Epoch: 6| Step: 4
Training loss: 1.20749032497406
Validation loss: 1.9555512192428752

Epoch: 6| Step: 5
Training loss: 2.150852680206299
Validation loss: 1.9683380255135157

Epoch: 6| Step: 6
Training loss: 2.1849968433380127
Validation loss: 1.9427740291882587

Epoch: 6| Step: 7
Training loss: 1.8669195175170898
Validation loss: 1.951239784558614

Epoch: 6| Step: 8
Training loss: 2.134777545928955
Validation loss: 1.962866352450463

Epoch: 6| Step: 9
Training loss: 2.220404624938965
Validation loss: 1.9583132728453605

Epoch: 6| Step: 10
Training loss: 1.651530385017395
Validation loss: 1.9663882229917793

Epoch: 6| Step: 11
Training loss: 2.4030227661132812
Validation loss: 1.9499755713247484

Epoch: 6| Step: 12
Training loss: 1.877393126487732
Validation loss: 1.9836507125567364

Epoch: 6| Step: 13
Training loss: 2.6554651260375977
Validation loss: 1.957448628640944

Epoch: 145| Step: 0
Training loss: 1.7246983051300049
Validation loss: 1.9582399347777009

Epoch: 6| Step: 1
Training loss: 2.1144254207611084
Validation loss: 1.9778781142286075

Epoch: 6| Step: 2
Training loss: 2.1527910232543945
Validation loss: 1.944795245765358

Epoch: 6| Step: 3
Training loss: 2.7649834156036377
Validation loss: 1.9543489281849196

Epoch: 6| Step: 4
Training loss: 2.420215129852295
Validation loss: 1.9583541539407545

Epoch: 6| Step: 5
Training loss: 2.0469970703125
Validation loss: 1.954590820497082

Epoch: 6| Step: 6
Training loss: 2.386108875274658
Validation loss: 1.9402714595999768

Epoch: 6| Step: 7
Training loss: 1.445995807647705
Validation loss: 1.9423665692729335

Epoch: 6| Step: 8
Training loss: 1.5162739753723145
Validation loss: 1.9426867167154949

Epoch: 6| Step: 9
Training loss: 2.0755252838134766
Validation loss: 1.919685685506431

Epoch: 6| Step: 10
Training loss: 2.1286702156066895
Validation loss: 1.9520449894730763

Epoch: 6| Step: 11
Training loss: 1.7872958183288574
Validation loss: 1.9403370272728704

Epoch: 6| Step: 12
Training loss: 1.3406217098236084
Validation loss: 1.9459826612985263

Epoch: 6| Step: 13
Training loss: 2.1366584300994873
Validation loss: 1.9350014617366176

Epoch: 146| Step: 0
Training loss: 1.3920788764953613
Validation loss: 1.9534562505701536

Epoch: 6| Step: 1
Training loss: 2.8307340145111084
Validation loss: 1.9328646736760293

Epoch: 6| Step: 2
Training loss: 2.127641439437866
Validation loss: 1.943328228048099

Epoch: 6| Step: 3
Training loss: 1.5345473289489746
Validation loss: 1.9563557601744128

Epoch: 6| Step: 4
Training loss: 1.7592287063598633
Validation loss: 1.963230545802783

Epoch: 6| Step: 5
Training loss: 2.535745620727539
Validation loss: 1.9521656203013595

Epoch: 6| Step: 6
Training loss: 2.0505712032318115
Validation loss: 1.965907726236569

Epoch: 6| Step: 7
Training loss: 1.7198185920715332
Validation loss: 1.9541107364880141

Epoch: 6| Step: 8
Training loss: 2.5024170875549316
Validation loss: 1.9430003691745061

Epoch: 6| Step: 9
Training loss: 1.6366727352142334
Validation loss: 1.952499105084327

Epoch: 6| Step: 10
Training loss: 2.0646352767944336
Validation loss: 1.945269315473495

Epoch: 6| Step: 11
Training loss: 1.9653939008712769
Validation loss: 1.9595485553946546

Epoch: 6| Step: 12
Training loss: 1.4469374418258667
Validation loss: 1.959374091958487

Epoch: 6| Step: 13
Training loss: 1.8420634269714355
Validation loss: 1.9766675336386568

Epoch: 147| Step: 0
Training loss: 1.8091630935668945
Validation loss: 1.9658849008621708

Epoch: 6| Step: 1
Training loss: 2.158693313598633
Validation loss: 1.946320262006534

Epoch: 6| Step: 2
Training loss: 2.5542802810668945
Validation loss: 1.9480214465049006

Epoch: 6| Step: 3
Training loss: 2.5260860919952393
Validation loss: 1.9418110847473145

Epoch: 6| Step: 4
Training loss: 1.9853317737579346
Validation loss: 1.9553477507765575

Epoch: 6| Step: 5
Training loss: 1.988510012626648
Validation loss: 1.9210094277576735

Epoch: 6| Step: 6
Training loss: 2.339539051055908
Validation loss: 1.937668320953205

Epoch: 6| Step: 7
Training loss: 1.398019790649414
Validation loss: 1.9363860455892419

Epoch: 6| Step: 8
Training loss: 1.829831600189209
Validation loss: 1.9487764514902586

Epoch: 6| Step: 9
Training loss: 1.2498986721038818
Validation loss: 1.9293187100400206

Epoch: 6| Step: 10
Training loss: 1.9048819541931152
Validation loss: 1.921722819728236

Epoch: 6| Step: 11
Training loss: 1.6997332572937012
Validation loss: 1.9362950081466346

Epoch: 6| Step: 12
Training loss: 1.8062115907669067
Validation loss: 1.946893533070882

Epoch: 6| Step: 13
Training loss: 2.7612292766571045
Validation loss: 1.9122759847230808

Epoch: 148| Step: 0
Training loss: 2.1066980361938477
Validation loss: 1.9215372864918043

Epoch: 6| Step: 1
Training loss: 2.0873074531555176
Validation loss: 1.9330049176369943

Epoch: 6| Step: 2
Training loss: 2.6376492977142334
Validation loss: 1.9344389310447119

Epoch: 6| Step: 3
Training loss: 2.184329032897949
Validation loss: 1.9331962882831533

Epoch: 6| Step: 4
Training loss: 1.3377561569213867
Validation loss: 1.953364351744293

Epoch: 6| Step: 5
Training loss: 1.5296106338500977
Validation loss: 1.952277147641746

Epoch: 6| Step: 6
Training loss: 2.234646797180176
Validation loss: 1.9339037838802542

Epoch: 6| Step: 7
Training loss: 1.6912921667099
Validation loss: 1.9461749548553138

Epoch: 6| Step: 8
Training loss: 2.196066379547119
Validation loss: 1.9376412591626566

Epoch: 6| Step: 9
Training loss: 1.7863625288009644
Validation loss: 1.9559317070950744

Epoch: 6| Step: 10
Training loss: 1.8051142692565918
Validation loss: 1.972473221440469

Epoch: 6| Step: 11
Training loss: 2.2149605751037598
Validation loss: 1.9579607209851664

Epoch: 6| Step: 12
Training loss: 1.5845588445663452
Validation loss: 1.9595183467352262

Epoch: 6| Step: 13
Training loss: 2.333669424057007
Validation loss: 1.942689049628473

Epoch: 149| Step: 0
Training loss: 1.6103065013885498
Validation loss: 1.9662290837175103

Epoch: 6| Step: 1
Training loss: 1.4297447204589844
Validation loss: 1.9375308354695637

Epoch: 6| Step: 2
Training loss: 1.5446412563323975
Validation loss: 1.9584082788036716

Epoch: 6| Step: 3
Training loss: 2.463563919067383
Validation loss: 1.9696180641010244

Epoch: 6| Step: 4
Training loss: 1.6479445695877075
Validation loss: 1.9719127403792513

Epoch: 6| Step: 5
Training loss: 2.548945665359497
Validation loss: 1.937109278094384

Epoch: 6| Step: 6
Training loss: 1.8113882541656494
Validation loss: 1.9625464959811139

Epoch: 6| Step: 7
Training loss: 2.017782211303711
Validation loss: 1.9906447484929075

Epoch: 6| Step: 8
Training loss: 2.3380727767944336
Validation loss: 1.9581011854192263

Epoch: 6| Step: 9
Training loss: 2.0359749794006348
Validation loss: 1.93821963443551

Epoch: 6| Step: 10
Training loss: 2.2596471309661865
Validation loss: 1.9374103981961486

Epoch: 6| Step: 11
Training loss: 1.7064167261123657
Validation loss: 1.9388048469379384

Epoch: 6| Step: 12
Training loss: 2.0434184074401855
Validation loss: 1.9170710002222369

Epoch: 6| Step: 13
Training loss: 1.8505967855453491
Validation loss: 1.9630423476619105

Epoch: 150| Step: 0
Training loss: 1.8652124404907227
Validation loss: 1.9474200946028515

Epoch: 6| Step: 1
Training loss: 1.655959963798523
Validation loss: 1.929249176415064

Epoch: 6| Step: 2
Training loss: 1.468100666999817
Validation loss: 1.9390346837300125

Epoch: 6| Step: 3
Training loss: 1.3312873840332031
Validation loss: 1.947614901809282

Epoch: 6| Step: 4
Training loss: 1.8350950479507446
Validation loss: 1.9794803691166702

Epoch: 6| Step: 5
Training loss: 2.2334866523742676
Validation loss: 1.9894759834453624

Epoch: 6| Step: 6
Training loss: 1.743695855140686
Validation loss: 1.9549980355847267

Epoch: 6| Step: 7
Training loss: 1.8796559572219849
Validation loss: 1.9726842475193802

Epoch: 6| Step: 8
Training loss: 2.7108280658721924
Validation loss: 1.9726786434009511

Epoch: 6| Step: 9
Training loss: 1.9097810983657837
Validation loss: 1.9847302590647051

Epoch: 6| Step: 10
Training loss: 2.699894666671753
Validation loss: 1.9731068380417363

Epoch: 6| Step: 11
Training loss: 2.8286869525909424
Validation loss: 1.9842198112959504

Epoch: 6| Step: 12
Training loss: 1.901068925857544
Validation loss: 1.9544241710375714

Epoch: 6| Step: 13
Training loss: 1.6827069520950317
Validation loss: 1.966416694784677

Epoch: 151| Step: 0
Training loss: 2.367227077484131
Validation loss: 1.969292236912635

Epoch: 6| Step: 1
Training loss: 1.5325675010681152
Validation loss: 1.957881554480522

Epoch: 6| Step: 2
Training loss: 2.3609774112701416
Validation loss: 1.9446791884719685

Epoch: 6| Step: 3
Training loss: 2.6053414344787598
Validation loss: 1.9473975448198215

Epoch: 6| Step: 4
Training loss: 1.7316311597824097
Validation loss: 1.9725271142939085

Epoch: 6| Step: 5
Training loss: 1.4438273906707764
Validation loss: 1.9442886793485252

Epoch: 6| Step: 6
Training loss: 2.0056023597717285
Validation loss: 1.9407839954540294

Epoch: 6| Step: 7
Training loss: 2.12160587310791
Validation loss: 1.9465457624004734

Epoch: 6| Step: 8
Training loss: 2.2684288024902344
Validation loss: 1.9426902801759782

Epoch: 6| Step: 9
Training loss: 1.694015383720398
Validation loss: 1.9544835398274083

Epoch: 6| Step: 10
Training loss: 1.8768031597137451
Validation loss: 1.9566075853122178

Epoch: 6| Step: 11
Training loss: 1.6106586456298828
Validation loss: 1.9612589677174885

Epoch: 6| Step: 12
Training loss: 2.164207696914673
Validation loss: 1.9333440091020317

Epoch: 6| Step: 13
Training loss: 1.7584604024887085
Validation loss: 1.9606602755925988

Epoch: 152| Step: 0
Training loss: 2.0002799034118652
Validation loss: 1.9615031673062233

Epoch: 6| Step: 1
Training loss: 1.582948923110962
Validation loss: 1.940404813776734

Epoch: 6| Step: 2
Training loss: 1.946236252784729
Validation loss: 1.943734779152819

Epoch: 6| Step: 3
Training loss: 1.7935149669647217
Validation loss: 1.9193471452241302

Epoch: 6| Step: 4
Training loss: 1.603424310684204
Validation loss: 1.9457845431502148

Epoch: 6| Step: 5
Training loss: 2.892536163330078
Validation loss: 1.9433652021551644

Epoch: 6| Step: 6
Training loss: 1.709708571434021
Validation loss: 1.9479846556981404

Epoch: 6| Step: 7
Training loss: 1.8181378841400146
Validation loss: 1.9291716698677308

Epoch: 6| Step: 8
Training loss: 1.8910647630691528
Validation loss: 1.9560062782738799

Epoch: 6| Step: 9
Training loss: 1.8207597732543945
Validation loss: 1.9298346632270402

Epoch: 6| Step: 10
Training loss: 2.107776641845703
Validation loss: 1.9175994434664327

Epoch: 6| Step: 11
Training loss: 2.5144901275634766
Validation loss: 1.9353978339061941

Epoch: 6| Step: 12
Training loss: 2.3068623542785645
Validation loss: 1.9446720589873612

Epoch: 6| Step: 13
Training loss: 1.2608128786087036
Validation loss: 1.9384180140751663

Epoch: 153| Step: 0
Training loss: 2.799471139907837
Validation loss: 1.913390290352606

Epoch: 6| Step: 1
Training loss: 1.8692548274993896
Validation loss: 1.91876470786269

Epoch: 6| Step: 2
Training loss: 1.965691328048706
Validation loss: 1.9363002200280466

Epoch: 6| Step: 3
Training loss: 2.0550804138183594
Validation loss: 1.9196043475981681

Epoch: 6| Step: 4
Training loss: 2.5431790351867676
Validation loss: 1.9177954619930637

Epoch: 6| Step: 5
Training loss: 1.798912763595581
Validation loss: 1.9261477852380404

Epoch: 6| Step: 6
Training loss: 1.06398344039917
Validation loss: 1.937430917575795

Epoch: 6| Step: 7
Training loss: 1.321138858795166
Validation loss: 1.9639172605288926

Epoch: 6| Step: 8
Training loss: 1.6214863061904907
Validation loss: 1.9571579694747925

Epoch: 6| Step: 9
Training loss: 2.0853610038757324
Validation loss: 1.9267622091436898

Epoch: 6| Step: 10
Training loss: 1.972272515296936
Validation loss: 1.9493545050262122

Epoch: 6| Step: 11
Training loss: 2.5809597969055176
Validation loss: 1.9301111928878292

Epoch: 6| Step: 12
Training loss: 1.976593255996704
Validation loss: 1.9490069522652576

Epoch: 6| Step: 13
Training loss: 1.8204975128173828
Validation loss: 1.9609487249005226

Epoch: 154| Step: 0
Training loss: 1.5765163898468018
Validation loss: 1.9563568522853236

Epoch: 6| Step: 1
Training loss: 1.5876401662826538
Validation loss: 1.973691027651551

Epoch: 6| Step: 2
Training loss: 1.4301010370254517
Validation loss: 1.9742436306450957

Epoch: 6| Step: 3
Training loss: 1.5681283473968506
Validation loss: 1.9762689516108523

Epoch: 6| Step: 4
Training loss: 1.996633768081665
Validation loss: 1.9559384084516955

Epoch: 6| Step: 5
Training loss: 2.368591785430908
Validation loss: 1.972123166566254

Epoch: 6| Step: 6
Training loss: 2.508178234100342
Validation loss: 1.958449145799042

Epoch: 6| Step: 7
Training loss: 2.703129291534424
Validation loss: 1.998412266854317

Epoch: 6| Step: 8
Training loss: 1.5977470874786377
Validation loss: 1.979870319366455

Epoch: 6| Step: 9
Training loss: 2.089099168777466
Validation loss: 1.9430358717518468

Epoch: 6| Step: 10
Training loss: 1.6128078699111938
Validation loss: 1.9836200411601732

Epoch: 6| Step: 11
Training loss: 2.8775548934936523
Validation loss: 1.9813035188182708

Epoch: 6| Step: 12
Training loss: 1.8883967399597168
Validation loss: 1.972413114322129

Epoch: 6| Step: 13
Training loss: 1.109240174293518
Validation loss: 1.9542169006921912

Epoch: 155| Step: 0
Training loss: 2.464130401611328
Validation loss: 1.9572812613620554

Epoch: 6| Step: 1
Training loss: 1.4181677103042603
Validation loss: 1.9773874449473556

Epoch: 6| Step: 2
Training loss: 2.687727928161621
Validation loss: 1.9714639571405226

Epoch: 6| Step: 3
Training loss: 2.1443753242492676
Validation loss: 1.9823489522421232

Epoch: 6| Step: 4
Training loss: 1.8989980220794678
Validation loss: 1.9695738502728042

Epoch: 6| Step: 5
Training loss: 1.4419018030166626
Validation loss: 1.9994209530533

Epoch: 6| Step: 6
Training loss: 1.4769291877746582
Validation loss: 1.9925495527123893

Epoch: 6| Step: 7
Training loss: 2.3701510429382324
Validation loss: 1.9673162109108382

Epoch: 6| Step: 8
Training loss: 1.8520524501800537
Validation loss: 1.9562468400565527

Epoch: 6| Step: 9
Training loss: 1.8803908824920654
Validation loss: 1.9647629671199347

Epoch: 6| Step: 10
Training loss: 1.6384453773498535
Validation loss: 1.9471923087232856

Epoch: 6| Step: 11
Training loss: 2.317355155944824
Validation loss: 1.977539808519425

Epoch: 6| Step: 12
Training loss: 1.3116095066070557
Validation loss: 1.95081344983911

Epoch: 6| Step: 13
Training loss: 2.6195034980773926
Validation loss: 1.935243619385586

Epoch: 156| Step: 0
Training loss: 1.8169251680374146
Validation loss: 1.9641853186392015

Epoch: 6| Step: 1
Training loss: 1.9414105415344238
Validation loss: 1.9440009517054404

Epoch: 6| Step: 2
Training loss: 2.3848674297332764
Validation loss: 1.933621932101506

Epoch: 6| Step: 3
Training loss: 1.5650732517242432
Validation loss: 1.9239808359453756

Epoch: 6| Step: 4
Training loss: 2.5225775241851807
Validation loss: 1.919342525543705

Epoch: 6| Step: 5
Training loss: 1.7091550827026367
Validation loss: 1.9070186948263517

Epoch: 6| Step: 6
Training loss: 2.1004528999328613
Validation loss: 1.9070544089040449

Epoch: 6| Step: 7
Training loss: 2.335980176925659
Validation loss: 1.9083254055310321

Epoch: 6| Step: 8
Training loss: 2.2014214992523193
Validation loss: 1.9208416964418145

Epoch: 6| Step: 9
Training loss: 2.1549806594848633
Validation loss: 1.922311213708693

Epoch: 6| Step: 10
Training loss: 1.0006508827209473
Validation loss: 1.928971726407287

Epoch: 6| Step: 11
Training loss: 2.14823055267334
Validation loss: 1.9419048896399878

Epoch: 6| Step: 12
Training loss: 1.8748626708984375
Validation loss: 1.9135756697705997

Epoch: 6| Step: 13
Training loss: 1.2896831035614014
Validation loss: 1.937828601047557

Epoch: 157| Step: 0
Training loss: 1.7100892066955566
Validation loss: 1.9329820448352444

Epoch: 6| Step: 1
Training loss: 2.4325203895568848
Validation loss: 1.94401216506958

Epoch: 6| Step: 2
Training loss: 1.7121758460998535
Validation loss: 1.9520526829586233

Epoch: 6| Step: 3
Training loss: 2.138404369354248
Validation loss: 1.9495864145217403

Epoch: 6| Step: 4
Training loss: 1.940914511680603
Validation loss: 1.9516766455865675

Epoch: 6| Step: 5
Training loss: 2.4241230487823486
Validation loss: 1.9386951705460906

Epoch: 6| Step: 6
Training loss: 2.180278778076172
Validation loss: 1.94092002607161

Epoch: 6| Step: 7
Training loss: 1.2760815620422363
Validation loss: 1.9641357750021002

Epoch: 6| Step: 8
Training loss: 1.8116035461425781
Validation loss: 1.947640565133864

Epoch: 6| Step: 9
Training loss: 1.7065443992614746
Validation loss: 1.950073290896672

Epoch: 6| Step: 10
Training loss: 1.7111440896987915
Validation loss: 1.94801680503353

Epoch: 6| Step: 11
Training loss: 2.146397590637207
Validation loss: 1.967598379299205

Epoch: 6| Step: 12
Training loss: 1.6381118297576904
Validation loss: 1.9390702555256505

Epoch: 6| Step: 13
Training loss: 2.93788743019104
Validation loss: 1.961116724116828

Epoch: 158| Step: 0
Training loss: 1.742915153503418
Validation loss: 1.9570411930802047

Epoch: 6| Step: 1
Training loss: 1.7943934202194214
Validation loss: 1.9487200539599183

Epoch: 6| Step: 2
Training loss: 2.981844425201416
Validation loss: 1.9430304368336995

Epoch: 6| Step: 3
Training loss: 2.075958251953125
Validation loss: 1.9194040349734727

Epoch: 6| Step: 4
Training loss: 1.543414831161499
Validation loss: 1.9379699396830734

Epoch: 6| Step: 5
Training loss: 1.7173155546188354
Validation loss: 1.94570416532537

Epoch: 6| Step: 6
Training loss: 1.741964340209961
Validation loss: 1.933042307053843

Epoch: 6| Step: 7
Training loss: 2.1011290550231934
Validation loss: 1.9296045175162695

Epoch: 6| Step: 8
Training loss: 1.8152045011520386
Validation loss: 1.944788848200152

Epoch: 6| Step: 9
Training loss: 2.556380033493042
Validation loss: 1.943384244877805

Epoch: 6| Step: 10
Training loss: 1.5192279815673828
Validation loss: 1.920865547272467

Epoch: 6| Step: 11
Training loss: 2.1170406341552734
Validation loss: 1.9477214223595076

Epoch: 6| Step: 12
Training loss: 1.491673231124878
Validation loss: 1.9556847900472663

Epoch: 6| Step: 13
Training loss: 1.8506450653076172
Validation loss: 1.9257925197642336

Epoch: 159| Step: 0
Training loss: 1.363020896911621
Validation loss: 1.9425369513932096

Epoch: 6| Step: 1
Training loss: 1.4558520317077637
Validation loss: 1.9366261023347096

Epoch: 6| Step: 2
Training loss: 2.2773473262786865
Validation loss: 1.9445436462279289

Epoch: 6| Step: 3
Training loss: 1.828616738319397
Validation loss: 1.9682684713794338

Epoch: 6| Step: 4
Training loss: 1.9098358154296875
Validation loss: 1.9358257452646892

Epoch: 6| Step: 5
Training loss: 2.1485605239868164
Validation loss: 1.9407868718588224

Epoch: 6| Step: 6
Training loss: 2.015231132507324
Validation loss: 1.9513890973983272

Epoch: 6| Step: 7
Training loss: 2.1378588676452637
Validation loss: 1.9620437211887811

Epoch: 6| Step: 8
Training loss: 1.7135440111160278
Validation loss: 1.9452136408898137

Epoch: 6| Step: 9
Training loss: 2.105940341949463
Validation loss: 1.96206420980474

Epoch: 6| Step: 10
Training loss: 2.1863925457000732
Validation loss: 1.9525871020491405

Epoch: 6| Step: 11
Training loss: 2.3952102661132812
Validation loss: 1.9598713587689143

Epoch: 6| Step: 12
Training loss: 1.8950154781341553
Validation loss: 1.9571889215900051

Epoch: 6| Step: 13
Training loss: 1.7174172401428223
Validation loss: 1.9621291493856778

Epoch: 160| Step: 0
Training loss: 2.6330652236938477
Validation loss: 1.975654339277616

Epoch: 6| Step: 1
Training loss: 2.083731174468994
Validation loss: 1.9207003757517824

Epoch: 6| Step: 2
Training loss: 1.9394382238388062
Validation loss: 1.9346614345427482

Epoch: 6| Step: 3
Training loss: 2.012629985809326
Validation loss: 1.9392219589602562

Epoch: 6| Step: 4
Training loss: 2.276705741882324
Validation loss: 1.9433564114314255

Epoch: 6| Step: 5
Training loss: 2.086918354034424
Validation loss: 1.953764364283572

Epoch: 6| Step: 6
Training loss: 1.4107990264892578
Validation loss: 1.9535483185962965

Epoch: 6| Step: 7
Training loss: 1.9058561325073242
Validation loss: 1.9343674810983802

Epoch: 6| Step: 8
Training loss: 2.3678317070007324
Validation loss: 1.9540177211966565

Epoch: 6| Step: 9
Training loss: 1.7790868282318115
Validation loss: 1.9570209403191843

Epoch: 6| Step: 10
Training loss: 1.70871901512146
Validation loss: 1.9528363930281771

Epoch: 6| Step: 11
Training loss: 1.4664959907531738
Validation loss: 1.9220268508439422

Epoch: 6| Step: 12
Training loss: 1.723538875579834
Validation loss: 1.9634169160678823

Epoch: 6| Step: 13
Training loss: 1.4016965627670288
Validation loss: 1.9446045391021236

Epoch: 161| Step: 0
Training loss: 1.8453357219696045
Validation loss: 1.9343575110999487

Epoch: 6| Step: 1
Training loss: 2.1426987648010254
Validation loss: 1.9667152717549314

Epoch: 6| Step: 2
Training loss: 2.00199031829834
Validation loss: 1.9520603841350925

Epoch: 6| Step: 3
Training loss: 1.770583152770996
Validation loss: 1.9461464240986814

Epoch: 6| Step: 4
Training loss: 2.046332836151123
Validation loss: 1.9291785173518683

Epoch: 6| Step: 5
Training loss: 1.9429669380187988
Validation loss: 1.90795652327999

Epoch: 6| Step: 6
Training loss: 1.1446397304534912
Validation loss: 1.9205939872290498

Epoch: 6| Step: 7
Training loss: 1.6820182800292969
Validation loss: 1.9184057917646182

Epoch: 6| Step: 8
Training loss: 1.9777127504348755
Validation loss: 1.9360224072651198

Epoch: 6| Step: 9
Training loss: 2.8142220973968506
Validation loss: 1.9261213194939397

Epoch: 6| Step: 10
Training loss: 1.7506834268569946
Validation loss: 1.9636805570253761

Epoch: 6| Step: 11
Training loss: 2.367522716522217
Validation loss: 1.9473984279940206

Epoch: 6| Step: 12
Training loss: 1.2110655307769775
Validation loss: 1.964244222128263

Epoch: 6| Step: 13
Training loss: 2.626288414001465
Validation loss: 1.9445836095399753

Epoch: 162| Step: 0
Training loss: 1.8838592767715454
Validation loss: 1.9793622288652646

Epoch: 6| Step: 1
Training loss: 1.8483283519744873
Validation loss: 1.9612928885285572

Epoch: 6| Step: 2
Training loss: 1.8738725185394287
Validation loss: 1.9349601781496437

Epoch: 6| Step: 3
Training loss: 1.6223926544189453
Validation loss: 1.9533485866362048

Epoch: 6| Step: 4
Training loss: 1.6805124282836914
Validation loss: 1.9160536591724684

Epoch: 6| Step: 5
Training loss: 2.3770933151245117
Validation loss: 1.9204561441175398

Epoch: 6| Step: 6
Training loss: 1.2269190549850464
Validation loss: 1.944710777651879

Epoch: 6| Step: 7
Training loss: 1.6753191947937012
Validation loss: 1.9414586046690583

Epoch: 6| Step: 8
Training loss: 1.651125192642212
Validation loss: 1.9293548855730283

Epoch: 6| Step: 9
Training loss: 2.106088399887085
Validation loss: 1.9405804129057034

Epoch: 6| Step: 10
Training loss: 1.9766130447387695
Validation loss: 1.9461197442905878

Epoch: 6| Step: 11
Training loss: 2.7544050216674805
Validation loss: 1.930752238919658

Epoch: 6| Step: 12
Training loss: 1.967604637145996
Validation loss: 1.9543209357928204

Epoch: 6| Step: 13
Training loss: 2.5103743076324463
Validation loss: 1.9307718135977303

Epoch: 163| Step: 0
Training loss: 2.578728675842285
Validation loss: 1.948073229482097

Epoch: 6| Step: 1
Training loss: 2.460186004638672
Validation loss: 1.9475136803042503

Epoch: 6| Step: 2
Training loss: 1.1783406734466553
Validation loss: 1.931783950457009

Epoch: 6| Step: 3
Training loss: 1.4893693923950195
Validation loss: 1.9616674428345056

Epoch: 6| Step: 4
Training loss: 1.974340796470642
Validation loss: 1.9265610453903035

Epoch: 6| Step: 5
Training loss: 1.8662075996398926
Validation loss: 1.9345550203836093

Epoch: 6| Step: 6
Training loss: 1.9594491720199585
Validation loss: 1.959248391530847

Epoch: 6| Step: 7
Training loss: 1.8737297058105469
Validation loss: 1.9620358405574676

Epoch: 6| Step: 8
Training loss: 1.6318016052246094
Validation loss: 1.9304342410897697

Epoch: 6| Step: 9
Training loss: 2.5401129722595215
Validation loss: 1.9674017736988683

Epoch: 6| Step: 10
Training loss: 1.8445707559585571
Validation loss: 1.9571415878111316

Epoch: 6| Step: 11
Training loss: 2.176074981689453
Validation loss: 1.9583649558405722

Epoch: 6| Step: 12
Training loss: 1.773848533630371
Validation loss: 1.9129047752708517

Epoch: 6| Step: 13
Training loss: 1.173297643661499
Validation loss: 1.9562213267049482

Epoch: 164| Step: 0
Training loss: 1.5850194692611694
Validation loss: 1.9144864838610414

Epoch: 6| Step: 1
Training loss: 1.896653652191162
Validation loss: 1.9419983125502063

Epoch: 6| Step: 2
Training loss: 1.1503417491912842
Validation loss: 1.948018745709491

Epoch: 6| Step: 3
Training loss: 2.1106135845184326
Validation loss: 1.9238736885850147

Epoch: 6| Step: 4
Training loss: 1.9655674695968628
Validation loss: 1.9478866207984187

Epoch: 6| Step: 5
Training loss: 2.505977153778076
Validation loss: 1.928953609158916

Epoch: 6| Step: 6
Training loss: 2.2574057579040527
Validation loss: 1.9213462516825686

Epoch: 6| Step: 7
Training loss: 2.119845151901245
Validation loss: 1.91272263116734

Epoch: 6| Step: 8
Training loss: 1.9179080724716187
Validation loss: 1.9114677188217

Epoch: 6| Step: 9
Training loss: 1.5379397869110107
Validation loss: 1.938695942201922

Epoch: 6| Step: 10
Training loss: 1.6807138919830322
Validation loss: 1.9071214583612257

Epoch: 6| Step: 11
Training loss: 1.456010341644287
Validation loss: 1.929329103039157

Epoch: 6| Step: 12
Training loss: 2.502748727798462
Validation loss: 1.9493831505057633

Epoch: 6| Step: 13
Training loss: 2.6066970825195312
Validation loss: 1.9285597134661931

Epoch: 165| Step: 0
Training loss: 2.3491501808166504
Validation loss: 1.9499658871722478

Epoch: 6| Step: 1
Training loss: 1.6363455057144165
Validation loss: 1.9295007182705788

Epoch: 6| Step: 2
Training loss: 2.062490940093994
Validation loss: 1.9115725947964577

Epoch: 6| Step: 3
Training loss: 2.2800822257995605
Validation loss: 1.9324296469329505

Epoch: 6| Step: 4
Training loss: 2.038933038711548
Validation loss: 1.9444403417648808

Epoch: 6| Step: 5
Training loss: 1.3484718799591064
Validation loss: 1.9705887174093595

Epoch: 6| Step: 6
Training loss: 2.0209553241729736
Validation loss: 1.9414510675655898

Epoch: 6| Step: 7
Training loss: 1.9484857320785522
Validation loss: 1.9399210791434012

Epoch: 6| Step: 8
Training loss: 1.5371026992797852
Validation loss: 1.94270795647816

Epoch: 6| Step: 9
Training loss: 2.4483418464660645
Validation loss: 1.9318085819162347

Epoch: 6| Step: 10
Training loss: 1.5489768981933594
Validation loss: 1.9158483115575646

Epoch: 6| Step: 11
Training loss: 1.6136360168457031
Validation loss: 1.95935574910974

Epoch: 6| Step: 12
Training loss: 2.0016980171203613
Validation loss: 1.947946281843288

Epoch: 6| Step: 13
Training loss: 2.0859642028808594
Validation loss: 1.947862272621483

Epoch: 166| Step: 0
Training loss: 2.233463764190674
Validation loss: 1.9467356794623918

Epoch: 6| Step: 1
Training loss: 1.6919758319854736
Validation loss: 1.9593507038649691

Epoch: 6| Step: 2
Training loss: 1.6799532175064087
Validation loss: 1.9459372502501293

Epoch: 6| Step: 3
Training loss: 1.9329779148101807
Validation loss: 1.940674130634595

Epoch: 6| Step: 4
Training loss: 2.085252046585083
Validation loss: 1.9472480153524747

Epoch: 6| Step: 5
Training loss: 2.23404598236084
Validation loss: 1.974375460737495

Epoch: 6| Step: 6
Training loss: 1.630040168762207
Validation loss: 1.961219979870704

Epoch: 6| Step: 7
Training loss: 1.479048252105713
Validation loss: 1.939083368547501

Epoch: 6| Step: 8
Training loss: 1.418215036392212
Validation loss: 1.933594834419989

Epoch: 6| Step: 9
Training loss: 2.6138954162597656
Validation loss: 1.9308756333525463

Epoch: 6| Step: 10
Training loss: 1.596245527267456
Validation loss: 1.9385645030647196

Epoch: 6| Step: 11
Training loss: 1.9454057216644287
Validation loss: 1.938787934600666

Epoch: 6| Step: 12
Training loss: 2.4460792541503906
Validation loss: 1.9664958446256575

Epoch: 6| Step: 13
Training loss: 1.6152721643447876
Validation loss: 1.9560794061230076

Epoch: 167| Step: 0
Training loss: 2.383373498916626
Validation loss: 1.9183304720027472

Epoch: 6| Step: 1
Training loss: 1.4730216264724731
Validation loss: 1.9420436172075168

Epoch: 6| Step: 2
Training loss: 1.616978645324707
Validation loss: 1.943295217329456

Epoch: 6| Step: 3
Training loss: 1.7293548583984375
Validation loss: 1.9586844828820997

Epoch: 6| Step: 4
Training loss: 2.6252965927124023
Validation loss: 1.9459084810749177

Epoch: 6| Step: 5
Training loss: 2.1104137897491455
Validation loss: 1.929832225204796

Epoch: 6| Step: 6
Training loss: 1.6520627737045288
Validation loss: 1.9387483135346444

Epoch: 6| Step: 7
Training loss: 2.1954147815704346
Validation loss: 1.9586789684910928

Epoch: 6| Step: 8
Training loss: 1.45417320728302
Validation loss: 1.9302525622870332

Epoch: 6| Step: 9
Training loss: 1.6304419040679932
Validation loss: 1.929038166999817

Epoch: 6| Step: 10
Training loss: 2.072547197341919
Validation loss: 1.9486352166821879

Epoch: 6| Step: 11
Training loss: 1.6846377849578857
Validation loss: 1.9383737130831646

Epoch: 6| Step: 12
Training loss: 1.9764900207519531
Validation loss: 1.9395666224982149

Epoch: 6| Step: 13
Training loss: 1.880983591079712
Validation loss: 1.9575545249446746

Epoch: 168| Step: 0
Training loss: 1.7540971040725708
Validation loss: 1.9494619241324804

Epoch: 6| Step: 1
Training loss: 1.8564152717590332
Validation loss: 1.9362959554118495

Epoch: 6| Step: 2
Training loss: 1.5145699977874756
Validation loss: 1.9325468976010558

Epoch: 6| Step: 3
Training loss: 1.4871121644973755
Validation loss: 1.938915757722752

Epoch: 6| Step: 4
Training loss: 2.637028217315674
Validation loss: 1.937325334036222

Epoch: 6| Step: 5
Training loss: 1.876286268234253
Validation loss: 1.9379057884216309

Epoch: 6| Step: 6
Training loss: 2.4457898139953613
Validation loss: 1.9237777058796217

Epoch: 6| Step: 7
Training loss: 1.8003603219985962
Validation loss: 1.938209605473344

Epoch: 6| Step: 8
Training loss: 2.0300607681274414
Validation loss: 1.9407981928958689

Epoch: 6| Step: 9
Training loss: 1.7302322387695312
Validation loss: 1.9487173877736574

Epoch: 6| Step: 10
Training loss: 1.9323983192443848
Validation loss: 1.9419229940701557

Epoch: 6| Step: 11
Training loss: 2.372727394104004
Validation loss: 1.9354576936332129

Epoch: 6| Step: 12
Training loss: 1.5566070079803467
Validation loss: 1.9196178438842937

Epoch: 6| Step: 13
Training loss: 1.4986778497695923
Validation loss: 1.9534821894861036

Epoch: 169| Step: 0
Training loss: 1.3851714134216309
Validation loss: 1.938307664727652

Epoch: 6| Step: 1
Training loss: 2.50229549407959
Validation loss: 1.9323471387227376

Epoch: 6| Step: 2
Training loss: 1.7562096118927002
Validation loss: 1.9075217067554433

Epoch: 6| Step: 3
Training loss: 2.482199192047119
Validation loss: 1.9417942147101126

Epoch: 6| Step: 4
Training loss: 2.0854110717773438
Validation loss: 1.9575404749121716

Epoch: 6| Step: 5
Training loss: 1.078572154045105
Validation loss: 1.9466215538722214

Epoch: 6| Step: 6
Training loss: 2.587810516357422
Validation loss: 1.9454716379924486

Epoch: 6| Step: 7
Training loss: 2.0482449531555176
Validation loss: 1.9413111209869385

Epoch: 6| Step: 8
Training loss: 1.851269006729126
Validation loss: 1.958533202448199

Epoch: 6| Step: 9
Training loss: 1.5904879570007324
Validation loss: 1.966317625455959

Epoch: 6| Step: 10
Training loss: 1.5663548707962036
Validation loss: 1.9350919544055898

Epoch: 6| Step: 11
Training loss: 1.9615002870559692
Validation loss: 1.925285267573531

Epoch: 6| Step: 12
Training loss: 1.757311224937439
Validation loss: 1.93938490908633

Epoch: 6| Step: 13
Training loss: 1.791525959968567
Validation loss: 1.9414864406790784

Epoch: 170| Step: 0
Training loss: 1.5266178846359253
Validation loss: 1.9327477742266912

Epoch: 6| Step: 1
Training loss: 1.652012586593628
Validation loss: 1.912156347305544

Epoch: 6| Step: 2
Training loss: 2.2864861488342285
Validation loss: 1.9124056088027133

Epoch: 6| Step: 3
Training loss: 1.2913135290145874
Validation loss: 1.961375351875059

Epoch: 6| Step: 4
Training loss: 2.756868362426758
Validation loss: 1.947729536282119

Epoch: 6| Step: 5
Training loss: 2.51648211479187
Validation loss: 1.9448518496687695

Epoch: 6| Step: 6
Training loss: 1.4041988849639893
Validation loss: 1.939612057901198

Epoch: 6| Step: 7
Training loss: 2.599973440170288
Validation loss: 1.9417415780405844

Epoch: 6| Step: 8
Training loss: 0.8910467028617859
Validation loss: 1.9145353250606085

Epoch: 6| Step: 9
Training loss: 1.6896700859069824
Validation loss: 1.9546164953580467

Epoch: 6| Step: 10
Training loss: 1.175674319267273
Validation loss: 1.9358859421104513

Epoch: 6| Step: 11
Training loss: 2.412759304046631
Validation loss: 1.9379299276618547

Epoch: 6| Step: 12
Training loss: 2.0905685424804688
Validation loss: 1.9273621587343113

Epoch: 6| Step: 13
Training loss: 1.6497039794921875
Validation loss: 1.9645767186277656

Epoch: 171| Step: 0
Training loss: 1.864394187927246
Validation loss: 1.9315762122472127

Epoch: 6| Step: 1
Training loss: 1.3366076946258545
Validation loss: 1.9352120302056754

Epoch: 6| Step: 2
Training loss: 2.2752304077148438
Validation loss: 1.9141987959543865

Epoch: 6| Step: 3
Training loss: 1.870834231376648
Validation loss: 1.9259679061110302

Epoch: 6| Step: 4
Training loss: 2.90791916847229
Validation loss: 1.9364704239752986

Epoch: 6| Step: 5
Training loss: 1.7836261987686157
Validation loss: 1.9579462402610368

Epoch: 6| Step: 6
Training loss: 1.8631185293197632
Validation loss: 1.929311776673922

Epoch: 6| Step: 7
Training loss: 1.5262794494628906
Validation loss: 1.9707209987025107

Epoch: 6| Step: 8
Training loss: 1.7965720891952515
Validation loss: 1.9616035005097747

Epoch: 6| Step: 9
Training loss: 1.50841224193573
Validation loss: 1.9337271951859998

Epoch: 6| Step: 10
Training loss: 1.7853870391845703
Validation loss: 1.9191985591765373

Epoch: 6| Step: 11
Training loss: 2.062912940979004
Validation loss: 1.9690022058384393

Epoch: 6| Step: 12
Training loss: 1.9005722999572754
Validation loss: 1.94708340655091

Epoch: 6| Step: 13
Training loss: 1.6799182891845703
Validation loss: 1.9503539685280091

Epoch: 172| Step: 0
Training loss: 1.9816327095031738
Validation loss: 1.9440760253578104

Epoch: 6| Step: 1
Training loss: 0.8973410725593567
Validation loss: 1.9513029834275604

Epoch: 6| Step: 2
Training loss: 1.8431446552276611
Validation loss: 1.9638069137450187

Epoch: 6| Step: 3
Training loss: 1.5652738809585571
Validation loss: 1.942011735772574

Epoch: 6| Step: 4
Training loss: 1.8828129768371582
Validation loss: 1.9505409835487284

Epoch: 6| Step: 5
Training loss: 2.834519863128662
Validation loss: 1.9312458794604066

Epoch: 6| Step: 6
Training loss: 1.7498328685760498
Validation loss: 1.9391009628131826

Epoch: 6| Step: 7
Training loss: 1.955822229385376
Validation loss: 1.940540853367057

Epoch: 6| Step: 8
Training loss: 1.353175401687622
Validation loss: 1.933121810677231

Epoch: 6| Step: 9
Training loss: 2.3400304317474365
Validation loss: 1.933968283796823

Epoch: 6| Step: 10
Training loss: 1.4926261901855469
Validation loss: 1.9403078504787978

Epoch: 6| Step: 11
Training loss: 2.136107921600342
Validation loss: 1.9204861297402331

Epoch: 6| Step: 12
Training loss: 2.2916736602783203
Validation loss: 1.8946319126313733

Epoch: 6| Step: 13
Training loss: 2.568270206451416
Validation loss: 1.9131992311887844

Epoch: 173| Step: 0
Training loss: 1.6913337707519531
Validation loss: 1.8987887636307748

Epoch: 6| Step: 1
Training loss: 2.209846019744873
Validation loss: 1.8997577492908766

Epoch: 6| Step: 2
Training loss: 1.2458745241165161
Validation loss: 1.9244487157431982

Epoch: 6| Step: 3
Training loss: 1.5542490482330322
Validation loss: 1.9017494647733626

Epoch: 6| Step: 4
Training loss: 1.4766013622283936
Validation loss: 1.9219691535477996

Epoch: 6| Step: 5
Training loss: 2.104806661605835
Validation loss: 1.9521328838922645

Epoch: 6| Step: 6
Training loss: 2.173320770263672
Validation loss: 1.9348563199402184

Epoch: 6| Step: 7
Training loss: 1.3152637481689453
Validation loss: 1.9277238871461602

Epoch: 6| Step: 8
Training loss: 1.6143076419830322
Validation loss: 1.9525663263054305

Epoch: 6| Step: 9
Training loss: 2.5148537158966064
Validation loss: 1.8857061888581963

Epoch: 6| Step: 10
Training loss: 2.374906063079834
Validation loss: 1.9338588676144999

Epoch: 6| Step: 11
Training loss: 2.424117088317871
Validation loss: 1.9089028245659285

Epoch: 6| Step: 12
Training loss: 1.8229894638061523
Validation loss: 1.905575620230808

Epoch: 6| Step: 13
Training loss: 1.9328397512435913
Validation loss: 1.9459286171902892

Epoch: 174| Step: 0
Training loss: 1.8037482500076294
Validation loss: 1.9335159870886034

Epoch: 6| Step: 1
Training loss: 3.0238797664642334
Validation loss: 1.9361095351557578

Epoch: 6| Step: 2
Training loss: 1.4686317443847656
Validation loss: 1.9628997977061937

Epoch: 6| Step: 3
Training loss: 1.8641533851623535
Validation loss: 1.966701985687338

Epoch: 6| Step: 4
Training loss: 1.479292869567871
Validation loss: 1.9652214127202188

Epoch: 6| Step: 5
Training loss: 1.5001026391983032
Validation loss: 1.9505714498540407

Epoch: 6| Step: 6
Training loss: 1.2788794040679932
Validation loss: 1.9815912413340744

Epoch: 6| Step: 7
Training loss: 2.555506944656372
Validation loss: 1.959799099993962

Epoch: 6| Step: 8
Training loss: 2.261092185974121
Validation loss: 1.9664965598813948

Epoch: 6| Step: 9
Training loss: 1.9817147254943848
Validation loss: 2.001503834160425

Epoch: 6| Step: 10
Training loss: 2.178586006164551
Validation loss: 1.9461550007584274

Epoch: 6| Step: 11
Training loss: 2.071943998336792
Validation loss: 1.9528914138834963

Epoch: 6| Step: 12
Training loss: 1.2129230499267578
Validation loss: 1.9532613472271991

Epoch: 6| Step: 13
Training loss: 1.8029509782791138
Validation loss: 1.9565596195959276

Epoch: 175| Step: 0
Training loss: 2.1381030082702637
Validation loss: 1.943988856448922

Epoch: 6| Step: 1
Training loss: 1.3204686641693115
Validation loss: 1.9568488033868934

Epoch: 6| Step: 2
Training loss: 1.9778038263320923
Validation loss: 1.938876639130295

Epoch: 6| Step: 3
Training loss: 1.5163406133651733
Validation loss: 1.9270423407195716

Epoch: 6| Step: 4
Training loss: 2.0024514198303223
Validation loss: 1.9177335949354275

Epoch: 6| Step: 5
Training loss: 2.317410469055176
Validation loss: 1.943944167065364

Epoch: 6| Step: 6
Training loss: 1.542075276374817
Validation loss: 1.9262708194794194

Epoch: 6| Step: 7
Training loss: 1.4312074184417725
Validation loss: 1.9107797748299056

Epoch: 6| Step: 8
Training loss: 2.426457405090332
Validation loss: 1.938701610411367

Epoch: 6| Step: 9
Training loss: 1.6117279529571533
Validation loss: 1.9166056622741043

Epoch: 6| Step: 10
Training loss: 1.7425466775894165
Validation loss: 1.930635433043203

Epoch: 6| Step: 11
Training loss: 1.1505355834960938
Validation loss: 1.9362719981901106

Epoch: 6| Step: 12
Training loss: 2.471259593963623
Validation loss: 1.9370481121924616

Epoch: 6| Step: 13
Training loss: 2.7145025730133057
Validation loss: 1.9150303704764253

Epoch: 176| Step: 0
Training loss: 1.1109074354171753
Validation loss: 1.926590637494159

Epoch: 6| Step: 1
Training loss: 1.4324589967727661
Validation loss: 1.9147854440955705

Epoch: 6| Step: 2
Training loss: 1.5701279640197754
Validation loss: 1.9252933968779862

Epoch: 6| Step: 3
Training loss: 1.5455763339996338
Validation loss: 1.902523358662923

Epoch: 6| Step: 4
Training loss: 1.9355151653289795
Validation loss: 1.9048084751252206

Epoch: 6| Step: 5
Training loss: 2.2712368965148926
Validation loss: 1.9356611249267415

Epoch: 6| Step: 6
Training loss: 2.0678014755249023
Validation loss: 1.914224773324946

Epoch: 6| Step: 7
Training loss: 2.0758652687072754
Validation loss: 1.9481692416693575

Epoch: 6| Step: 8
Training loss: 1.6636114120483398
Validation loss: 1.938722925801431

Epoch: 6| Step: 9
Training loss: 2.0576364994049072
Validation loss: 1.9273724325241581

Epoch: 6| Step: 10
Training loss: 2.381218910217285
Validation loss: 1.934523659367715

Epoch: 6| Step: 11
Training loss: 2.2147200107574463
Validation loss: 1.9283662957529868

Epoch: 6| Step: 12
Training loss: 1.9898791313171387
Validation loss: 1.9322584213749054

Epoch: 6| Step: 13
Training loss: 1.967893123626709
Validation loss: 1.94695879567054

Epoch: 177| Step: 0
Training loss: 1.7226321697235107
Validation loss: 1.924319448009614

Epoch: 6| Step: 1
Training loss: 2.250115394592285
Validation loss: 1.9287645688620947

Epoch: 6| Step: 2
Training loss: 1.6359333992004395
Validation loss: 1.941245889150968

Epoch: 6| Step: 3
Training loss: 2.0081393718719482
Validation loss: 1.9576373766827326

Epoch: 6| Step: 4
Training loss: 1.5957698822021484
Validation loss: 1.9326828243911907

Epoch: 6| Step: 5
Training loss: 2.095874786376953
Validation loss: 1.935733800293297

Epoch: 6| Step: 6
Training loss: 1.7759661674499512
Validation loss: 1.903893111854471

Epoch: 6| Step: 7
Training loss: 1.4603283405303955
Validation loss: 1.9403749870997604

Epoch: 6| Step: 8
Training loss: 2.084970712661743
Validation loss: 1.9468785960187194

Epoch: 6| Step: 9
Training loss: 1.8549473285675049
Validation loss: 1.9559224010795675

Epoch: 6| Step: 10
Training loss: 2.016178607940674
Validation loss: 1.9591391804397746

Epoch: 6| Step: 11
Training loss: 1.8114913702011108
Validation loss: 1.9540614812604842

Epoch: 6| Step: 12
Training loss: 1.7809213399887085
Validation loss: 1.9321589213545605

Epoch: 6| Step: 13
Training loss: 1.9504135847091675
Validation loss: 1.9645513719128025

Epoch: 178| Step: 0
Training loss: 1.6812665462493896
Validation loss: 1.9641103385597147

Epoch: 6| Step: 1
Training loss: 1.8723210096359253
Validation loss: 1.9426068234187301

Epoch: 6| Step: 2
Training loss: 1.9598236083984375
Validation loss: 1.914900058059282

Epoch: 6| Step: 3
Training loss: 1.9289628267288208
Validation loss: 1.96395964776316

Epoch: 6| Step: 4
Training loss: 1.4892780780792236
Validation loss: 1.9474713725428427

Epoch: 6| Step: 5
Training loss: 1.9960408210754395
Validation loss: 1.948450549956291

Epoch: 6| Step: 6
Training loss: 1.9635343551635742
Validation loss: 1.9591760943012853

Epoch: 6| Step: 7
Training loss: 1.4265172481536865
Validation loss: 1.9519635964465398

Epoch: 6| Step: 8
Training loss: 2.293138027191162
Validation loss: 1.9537142989456013

Epoch: 6| Step: 9
Training loss: 1.7394249439239502
Validation loss: 1.9478732027033323

Epoch: 6| Step: 10
Training loss: 1.7193067073822021
Validation loss: 1.9533515617411623

Epoch: 6| Step: 11
Training loss: 2.6193761825561523
Validation loss: 1.9526910064040974

Epoch: 6| Step: 12
Training loss: 1.5456554889678955
Validation loss: 1.9148838878959737

Epoch: 6| Step: 13
Training loss: 2.031240701675415
Validation loss: 1.9011261642620128

Epoch: 179| Step: 0
Training loss: 1.2392797470092773
Validation loss: 1.9262963033491565

Epoch: 6| Step: 1
Training loss: 1.8679534196853638
Validation loss: 1.9525697718384445

Epoch: 6| Step: 2
Training loss: 1.5464686155319214
Validation loss: 1.936972818066997

Epoch: 6| Step: 3
Training loss: 1.3402842283248901
Validation loss: 1.94076584487833

Epoch: 6| Step: 4
Training loss: 1.4865953922271729
Validation loss: 1.918083688264252

Epoch: 6| Step: 5
Training loss: 1.3462390899658203
Validation loss: 1.9387312204607072

Epoch: 6| Step: 6
Training loss: 2.8897078037261963
Validation loss: 1.9254315771082395

Epoch: 6| Step: 7
Training loss: 2.5743792057037354
Validation loss: 1.9103634344634188

Epoch: 6| Step: 8
Training loss: 1.8869997262954712
Validation loss: 1.9038007246550692

Epoch: 6| Step: 9
Training loss: 1.943312644958496
Validation loss: 1.920145527009041

Epoch: 6| Step: 10
Training loss: 2.1207525730133057
Validation loss: 1.9090336279202533

Epoch: 6| Step: 11
Training loss: 1.721160888671875
Validation loss: 1.9307390720613542

Epoch: 6| Step: 12
Training loss: 2.318951368331909
Validation loss: 1.9312664372946626

Epoch: 6| Step: 13
Training loss: 1.744572639465332
Validation loss: 1.939469470772692

Epoch: 180| Step: 0
Training loss: 1.7535746097564697
Validation loss: 1.9730593953081357

Epoch: 6| Step: 1
Training loss: 2.297769546508789
Validation loss: 1.930137034385435

Epoch: 6| Step: 2
Training loss: 2.4721531867980957
Validation loss: 1.9298422003305087

Epoch: 6| Step: 3
Training loss: 1.9784599542617798
Validation loss: 1.951483711119621

Epoch: 6| Step: 4
Training loss: 2.1192328929901123
Validation loss: 1.9557553516921176

Epoch: 6| Step: 5
Training loss: 1.8750110864639282
Validation loss: 1.9405576849496493

Epoch: 6| Step: 6
Training loss: 1.4447247982025146
Validation loss: 1.9685431193279963

Epoch: 6| Step: 7
Training loss: 1.2029964923858643
Validation loss: 1.931574941963278

Epoch: 6| Step: 8
Training loss: 1.4023420810699463
Validation loss: 1.951515878400495

Epoch: 6| Step: 9
Training loss: 1.7540512084960938
Validation loss: 1.9913628139803488

Epoch: 6| Step: 10
Training loss: 1.7456125020980835
Validation loss: 1.9615424115170714

Epoch: 6| Step: 11
Training loss: 2.11124324798584
Validation loss: 1.9218039345997635

Epoch: 6| Step: 12
Training loss: 2.325385093688965
Validation loss: 1.9281124773845877

Epoch: 6| Step: 13
Training loss: 1.4667754173278809
Validation loss: 1.9525378775852982

Epoch: 181| Step: 0
Training loss: 1.9074890613555908
Validation loss: 1.9545413858147078

Epoch: 6| Step: 1
Training loss: 1.6362698078155518
Validation loss: 1.9333615931131507

Epoch: 6| Step: 2
Training loss: 2.0941457748413086
Validation loss: 1.9272345778762654

Epoch: 6| Step: 3
Training loss: 1.5541355609893799
Validation loss: 1.9441485058876775

Epoch: 6| Step: 4
Training loss: 1.709438681602478
Validation loss: 1.94548592387989

Epoch: 6| Step: 5
Training loss: 1.8503206968307495
Validation loss: 1.8920373262897614

Epoch: 6| Step: 6
Training loss: 2.2533154487609863
Validation loss: 1.9163128663134832

Epoch: 6| Step: 7
Training loss: 1.8930541276931763
Validation loss: 1.9033311631089898

Epoch: 6| Step: 8
Training loss: 1.9379682540893555
Validation loss: 1.8869901267431115

Epoch: 6| Step: 9
Training loss: 2.380114793777466
Validation loss: 1.8706880231057443

Epoch: 6| Step: 10
Training loss: 2.2123541831970215
Validation loss: 1.8971470299587454

Epoch: 6| Step: 11
Training loss: 1.4546445608139038
Validation loss: 1.8945115791854037

Epoch: 6| Step: 12
Training loss: 1.769157886505127
Validation loss: 1.906409090565097

Epoch: 6| Step: 13
Training loss: 1.8518136739730835
Validation loss: 1.904911607824346

Epoch: 182| Step: 0
Training loss: 1.4517252445220947
Validation loss: 1.8930544750664824

Epoch: 6| Step: 1
Training loss: 1.6756680011749268
Validation loss: 1.9125177526986727

Epoch: 6| Step: 2
Training loss: 1.657172679901123
Validation loss: 1.917275289053558

Epoch: 6| Step: 3
Training loss: 2.8369545936584473
Validation loss: 1.906342529481457

Epoch: 6| Step: 4
Training loss: 1.2216806411743164
Validation loss: 1.9151846619062527

Epoch: 6| Step: 5
Training loss: 1.8568583726882935
Validation loss: 1.9142463886609642

Epoch: 6| Step: 6
Training loss: 2.009143829345703
Validation loss: 1.9508185335384902

Epoch: 6| Step: 7
Training loss: 1.6499123573303223
Validation loss: 1.9878013005820654

Epoch: 6| Step: 8
Training loss: 2.1591830253601074
Validation loss: 1.9533742191970989

Epoch: 6| Step: 9
Training loss: 2.3608288764953613
Validation loss: 1.9810563530973209

Epoch: 6| Step: 10
Training loss: 1.657724380493164
Validation loss: 1.9887114750441683

Epoch: 6| Step: 11
Training loss: 1.478240728378296
Validation loss: 1.9691201089530863

Epoch: 6| Step: 12
Training loss: 2.463563919067383
Validation loss: 1.9939244101124425

Epoch: 6| Step: 13
Training loss: 1.8096286058425903
Validation loss: 1.9460930619188535

Epoch: 183| Step: 0
Training loss: 3.036529302597046
Validation loss: 1.9606877001382972

Epoch: 6| Step: 1
Training loss: 1.7726068496704102
Validation loss: 1.9239575388611003

Epoch: 6| Step: 2
Training loss: 1.2782139778137207
Validation loss: 1.9457861992620653

Epoch: 6| Step: 3
Training loss: 1.7144525051116943
Validation loss: 1.9438337331177087

Epoch: 6| Step: 4
Training loss: 2.0897343158721924
Validation loss: 1.9392140693562006

Epoch: 6| Step: 5
Training loss: 1.4243555068969727
Validation loss: 1.9205487030808643

Epoch: 6| Step: 6
Training loss: 1.420243501663208
Validation loss: 1.9482034380717943

Epoch: 6| Step: 7
Training loss: 2.5956132411956787
Validation loss: 1.9342628678967875

Epoch: 6| Step: 8
Training loss: 1.8112016916275024
Validation loss: 1.914210888647264

Epoch: 6| Step: 9
Training loss: 1.2001285552978516
Validation loss: 1.8886107642163512

Epoch: 6| Step: 10
Training loss: 1.9602618217468262
Validation loss: 1.9173503460422638

Epoch: 6| Step: 11
Training loss: 1.8477309942245483
Validation loss: 1.9052953220182849

Epoch: 6| Step: 12
Training loss: 2.263580322265625
Validation loss: 1.9148989339028635

Epoch: 6| Step: 13
Training loss: 1.4993011951446533
Validation loss: 1.8894360232096847

Epoch: 184| Step: 0
Training loss: 2.1895859241485596
Validation loss: 1.9087003943740681

Epoch: 6| Step: 1
Training loss: 1.7821321487426758
Validation loss: 1.9535627442021524

Epoch: 6| Step: 2
Training loss: 1.5392158031463623
Validation loss: 1.900235200441012

Epoch: 6| Step: 3
Training loss: 1.669130563735962
Validation loss: 1.9095641977043563

Epoch: 6| Step: 4
Training loss: 1.8587994575500488
Validation loss: 1.9277663846169748

Epoch: 6| Step: 5
Training loss: 1.866294503211975
Validation loss: 1.9134899262459046

Epoch: 6| Step: 6
Training loss: 1.672777771949768
Validation loss: 1.8963838559325024

Epoch: 6| Step: 7
Training loss: 1.8916878700256348
Validation loss: 1.8917562038667741

Epoch: 6| Step: 8
Training loss: 2.079961061477661
Validation loss: 1.9117396313657042

Epoch: 6| Step: 9
Training loss: 1.7152352333068848
Validation loss: 1.8916062757533083

Epoch: 6| Step: 10
Training loss: 1.5034294128417969
Validation loss: 1.9206957765804824

Epoch: 6| Step: 11
Training loss: 1.7428053617477417
Validation loss: 1.9125152454581311

Epoch: 6| Step: 12
Training loss: 2.394063949584961
Validation loss: 1.9438406780201902

Epoch: 6| Step: 13
Training loss: 1.9987629652023315
Validation loss: 1.923087646884303

Epoch: 185| Step: 0
Training loss: 1.9605412483215332
Validation loss: 1.9710180477429462

Epoch: 6| Step: 1
Training loss: 1.5622363090515137
Validation loss: 1.9480600203237226

Epoch: 6| Step: 2
Training loss: 1.457761287689209
Validation loss: 1.9831721603229482

Epoch: 6| Step: 3
Training loss: 1.300597071647644
Validation loss: 1.9929750439941243

Epoch: 6| Step: 4
Training loss: 2.1058459281921387
Validation loss: 1.9871163278497674

Epoch: 6| Step: 5
Training loss: 2.1871590614318848
Validation loss: 1.9590681804123746

Epoch: 6| Step: 6
Training loss: 1.482247233390808
Validation loss: 1.9639355174956783

Epoch: 6| Step: 7
Training loss: 2.1312057971954346
Validation loss: 1.9694037732257639

Epoch: 6| Step: 8
Training loss: 1.5796951055526733
Validation loss: 1.9609190828056746

Epoch: 6| Step: 9
Training loss: 2.1897525787353516
Validation loss: 1.956692886608903

Epoch: 6| Step: 10
Training loss: 1.8594372272491455
Validation loss: 1.9591328815747333

Epoch: 6| Step: 11
Training loss: 2.0110864639282227
Validation loss: 1.9230890248411445

Epoch: 6| Step: 12
Training loss: 1.7821917533874512
Validation loss: 1.9582831654497372

Epoch: 6| Step: 13
Training loss: 2.6494171619415283
Validation loss: 1.9251890708041448

Epoch: 186| Step: 0
Training loss: 2.381063461303711
Validation loss: 1.917889920614099

Epoch: 6| Step: 1
Training loss: 1.5737743377685547
Validation loss: 1.9249671377161497

Epoch: 6| Step: 2
Training loss: 2.0483803749084473
Validation loss: 1.94703794294788

Epoch: 6| Step: 3
Training loss: 2.1848931312561035
Validation loss: 1.9238687381949475

Epoch: 6| Step: 4
Training loss: 1.1684339046478271
Validation loss: 1.943871372489519

Epoch: 6| Step: 5
Training loss: 1.266056776046753
Validation loss: 1.9008941919572893

Epoch: 6| Step: 6
Training loss: 1.3514132499694824
Validation loss: 1.9374744892120361

Epoch: 6| Step: 7
Training loss: 2.0243799686431885
Validation loss: 1.970005977538324

Epoch: 6| Step: 8
Training loss: 1.6502556800842285
Validation loss: 1.9150182739380868

Epoch: 6| Step: 9
Training loss: 1.5125057697296143
Validation loss: 1.904356441190166

Epoch: 6| Step: 10
Training loss: 2.471220016479492
Validation loss: 1.9604781353345482

Epoch: 6| Step: 11
Training loss: 2.090897560119629
Validation loss: 1.9279320252838956

Epoch: 6| Step: 12
Training loss: 1.6756449937820435
Validation loss: 1.9319281988246466

Epoch: 6| Step: 13
Training loss: 2.043776750564575
Validation loss: 1.9490659211271553

Epoch: 187| Step: 0
Training loss: 2.292673110961914
Validation loss: 1.954758531303816

Epoch: 6| Step: 1
Training loss: 1.4046282768249512
Validation loss: 1.9695333447507632

Epoch: 6| Step: 2
Training loss: 2.0792388916015625
Validation loss: 1.9253864685694377

Epoch: 6| Step: 3
Training loss: 1.354958176612854
Validation loss: 1.9172704835091867

Epoch: 6| Step: 4
Training loss: 2.1526308059692383
Validation loss: 1.95037559411859

Epoch: 6| Step: 5
Training loss: 2.0012319087982178
Validation loss: 1.9423813025156658

Epoch: 6| Step: 6
Training loss: 1.822615623474121
Validation loss: 1.9133664126037269

Epoch: 6| Step: 7
Training loss: 2.0905447006225586
Validation loss: 1.930237377843549

Epoch: 6| Step: 8
Training loss: 1.5977073907852173
Validation loss: 1.9095600061519171

Epoch: 6| Step: 9
Training loss: 2.083230495452881
Validation loss: 1.9340269360491025

Epoch: 6| Step: 10
Training loss: 1.6339330673217773
Validation loss: 1.9023190185587893

Epoch: 6| Step: 11
Training loss: 1.942847490310669
Validation loss: 1.9681815126890778

Epoch: 6| Step: 12
Training loss: 1.4174920320510864
Validation loss: 1.8999998813034387

Epoch: 6| Step: 13
Training loss: 1.6515761613845825
Validation loss: 1.946029370830905

Epoch: 188| Step: 0
Training loss: 1.892174482345581
Validation loss: 1.9393008780735794

Epoch: 6| Step: 1
Training loss: 1.9285295009613037
Validation loss: 1.9438294364560036

Epoch: 6| Step: 2
Training loss: 1.5694009065628052
Validation loss: 1.9365538397142965

Epoch: 6| Step: 3
Training loss: 1.134243369102478
Validation loss: 1.9281631144144202

Epoch: 6| Step: 4
Training loss: 1.974631428718567
Validation loss: 1.9138027801308581

Epoch: 6| Step: 5
Training loss: 1.6503121852874756
Validation loss: 1.907547935362785

Epoch: 6| Step: 6
Training loss: 1.8960764408111572
Validation loss: 1.9230260772089804

Epoch: 6| Step: 7
Training loss: 1.8789974451065063
Validation loss: 1.909856419409475

Epoch: 6| Step: 8
Training loss: 1.840928554534912
Validation loss: 1.9009510137701546

Epoch: 6| Step: 9
Training loss: 2.311127185821533
Validation loss: 1.9007823210890575

Epoch: 6| Step: 10
Training loss: 2.191950798034668
Validation loss: 1.9388786900428034

Epoch: 6| Step: 11
Training loss: 1.7149598598480225
Validation loss: 1.9182580696639193

Epoch: 6| Step: 12
Training loss: 1.8582723140716553
Validation loss: 1.9444135671020837

Epoch: 6| Step: 13
Training loss: 2.0908010005950928
Validation loss: 1.9530312732983661

Epoch: 189| Step: 0
Training loss: 1.7522767782211304
Validation loss: 1.9489069228531213

Epoch: 6| Step: 1
Training loss: 0.9133536219596863
Validation loss: 1.93368431445091

Epoch: 6| Step: 2
Training loss: 1.8235108852386475
Validation loss: 1.9354211566268757

Epoch: 6| Step: 3
Training loss: 1.446250319480896
Validation loss: 1.9224813035739365

Epoch: 6| Step: 4
Training loss: 1.7289652824401855
Validation loss: 1.951978406598491

Epoch: 6| Step: 5
Training loss: 1.9781938791275024
Validation loss: 1.9632741879391413

Epoch: 6| Step: 6
Training loss: 1.9000775814056396
Validation loss: 1.974801177619606

Epoch: 6| Step: 7
Training loss: 1.6924693584442139
Validation loss: 1.9564860931006811

Epoch: 6| Step: 8
Training loss: 2.488281011581421
Validation loss: 1.9388868693382508

Epoch: 6| Step: 9
Training loss: 1.8382890224456787
Validation loss: 1.9457846559504026

Epoch: 6| Step: 10
Training loss: 1.3050496578216553
Validation loss: 1.9271191191929642

Epoch: 6| Step: 11
Training loss: 2.053893804550171
Validation loss: 1.9571238897180046

Epoch: 6| Step: 12
Training loss: 2.294224977493286
Validation loss: 1.9235131215023737

Epoch: 6| Step: 13
Training loss: 2.578314781188965
Validation loss: 1.9391215334656418

Epoch: 190| Step: 0
Training loss: 1.4670013189315796
Validation loss: 1.9544474950400732

Epoch: 6| Step: 1
Training loss: 2.0057644844055176
Validation loss: 1.9062795177582772

Epoch: 6| Step: 2
Training loss: 2.0106279850006104
Validation loss: 1.8859684685225129

Epoch: 6| Step: 3
Training loss: 2.212723731994629
Validation loss: 1.9095139054841892

Epoch: 6| Step: 4
Training loss: 1.406906247138977
Validation loss: 1.9373068835145684

Epoch: 6| Step: 5
Training loss: 2.2341270446777344
Validation loss: 1.9393190299310992

Epoch: 6| Step: 6
Training loss: 1.3862802982330322
Validation loss: 1.9249947609439972

Epoch: 6| Step: 7
Training loss: 2.1831583976745605
Validation loss: 1.9293849032412294

Epoch: 6| Step: 8
Training loss: 2.1711313724517822
Validation loss: 1.9011191501412341

Epoch: 6| Step: 9
Training loss: 1.1031174659729004
Validation loss: 1.9269039887253956

Epoch: 6| Step: 10
Training loss: 2.67587947845459
Validation loss: 1.9271627087746896

Epoch: 6| Step: 11
Training loss: 1.555867075920105
Validation loss: 1.9361158237662366

Epoch: 6| Step: 12
Training loss: 1.0730327367782593
Validation loss: 1.936136802037557

Epoch: 6| Step: 13
Training loss: 2.2948999404907227
Validation loss: 1.9046804763937508

Epoch: 191| Step: 0
Training loss: 1.6644870042800903
Validation loss: 1.9420354212484052

Epoch: 6| Step: 1
Training loss: 2.0903615951538086
Validation loss: 1.93721802003922

Epoch: 6| Step: 2
Training loss: 1.3247520923614502
Validation loss: 1.9316650898225847

Epoch: 6| Step: 3
Training loss: 2.090249538421631
Validation loss: 1.9050311170598513

Epoch: 6| Step: 4
Training loss: 2.4379429817199707
Validation loss: 1.9224031753437494

Epoch: 6| Step: 5
Training loss: 2.1782119274139404
Validation loss: 1.9302663546736523

Epoch: 6| Step: 6
Training loss: 1.6258407831192017
Validation loss: 1.9275349173494565

Epoch: 6| Step: 7
Training loss: 1.5725581645965576
Validation loss: 1.9310128329902567

Epoch: 6| Step: 8
Training loss: 1.723015308380127
Validation loss: 1.9231860637664795

Epoch: 6| Step: 9
Training loss: 2.312155246734619
Validation loss: 1.940081904011388

Epoch: 6| Step: 10
Training loss: 1.1372225284576416
Validation loss: 1.9300553209038191

Epoch: 6| Step: 11
Training loss: 2.0204737186431885
Validation loss: 1.9063519585517146

Epoch: 6| Step: 12
Training loss: 1.961333155632019
Validation loss: 1.9113388215341875

Epoch: 6| Step: 13
Training loss: 1.056946039199829
Validation loss: 1.908286521511693

Epoch: 192| Step: 0
Training loss: 2.1119203567504883
Validation loss: 1.92379226223115

Epoch: 6| Step: 1
Training loss: 1.1682124137878418
Validation loss: 1.8985055236406223

Epoch: 6| Step: 2
Training loss: 1.8157134056091309
Validation loss: 1.9123865404436666

Epoch: 6| Step: 3
Training loss: 1.795265555381775
Validation loss: 1.9264109442310948

Epoch: 6| Step: 4
Training loss: 2.0058085918426514
Validation loss: 1.9069382067649596

Epoch: 6| Step: 5
Training loss: 1.4534204006195068
Validation loss: 1.8894348862350627

Epoch: 6| Step: 6
Training loss: 2.0043468475341797
Validation loss: 1.8972891902410856

Epoch: 6| Step: 7
Training loss: 1.688659906387329
Validation loss: 1.895735579152261

Epoch: 6| Step: 8
Training loss: 1.644029140472412
Validation loss: 1.931866768867739

Epoch: 6| Step: 9
Training loss: 2.3700876235961914
Validation loss: 1.8868113051178634

Epoch: 6| Step: 10
Training loss: 1.6198375225067139
Validation loss: 1.8828811863417267

Epoch: 6| Step: 11
Training loss: 1.6568143367767334
Validation loss: 1.9137660559787546

Epoch: 6| Step: 12
Training loss: 2.2215466499328613
Validation loss: 1.9463923233811573

Epoch: 6| Step: 13
Training loss: 1.735332727432251
Validation loss: 1.918138696301368

Epoch: 193| Step: 0
Training loss: 2.3199405670166016
Validation loss: 1.9358121361783756

Epoch: 6| Step: 1
Training loss: 1.8467397689819336
Validation loss: 1.9311738244948848

Epoch: 6| Step: 2
Training loss: 1.7451595067977905
Validation loss: 1.938704611152731

Epoch: 6| Step: 3
Training loss: 1.8688592910766602
Validation loss: 1.972453208379848

Epoch: 6| Step: 4
Training loss: 1.1874868869781494
Validation loss: 1.9639543730725524

Epoch: 6| Step: 5
Training loss: 1.5911805629730225
Validation loss: 1.9775861578602945

Epoch: 6| Step: 6
Training loss: 2.3660244941711426
Validation loss: 1.9733107653997277

Epoch: 6| Step: 7
Training loss: 1.8367657661437988
Validation loss: 1.9983327875855148

Epoch: 6| Step: 8
Training loss: 1.9513996839523315
Validation loss: 1.9595941599979196

Epoch: 6| Step: 9
Training loss: 1.442549705505371
Validation loss: 1.9795207515839608

Epoch: 6| Step: 10
Training loss: 2.351227283477783
Validation loss: 1.9851352219940515

Epoch: 6| Step: 11
Training loss: 1.4277780055999756
Validation loss: 1.958453914170624

Epoch: 6| Step: 12
Training loss: 1.7312325239181519
Validation loss: 1.9694885925580097

Epoch: 6| Step: 13
Training loss: 1.7086607217788696
Validation loss: 1.9410794447827082

Epoch: 194| Step: 0
Training loss: 2.1533923149108887
Validation loss: 1.9169581064613916

Epoch: 6| Step: 1
Training loss: 1.8390562534332275
Validation loss: 1.918782776401889

Epoch: 6| Step: 2
Training loss: 1.6360090970993042
Validation loss: 1.935494892058834

Epoch: 6| Step: 3
Training loss: 2.0993785858154297
Validation loss: 1.928436666406611

Epoch: 6| Step: 4
Training loss: 1.7535284757614136
Validation loss: 1.883405335487858

Epoch: 6| Step: 5
Training loss: 1.8204576969146729
Validation loss: 1.9148450679676507

Epoch: 6| Step: 6
Training loss: 1.9790291786193848
Validation loss: 1.9006201682552215

Epoch: 6| Step: 7
Training loss: 1.809685468673706
Validation loss: 1.9228722818436161

Epoch: 6| Step: 8
Training loss: 1.8329112529754639
Validation loss: 1.9131904212377404

Epoch: 6| Step: 9
Training loss: 1.860387921333313
Validation loss: 1.9267219471675094

Epoch: 6| Step: 10
Training loss: 1.7971680164337158
Validation loss: 1.9137734982275194

Epoch: 6| Step: 11
Training loss: 1.6533145904541016
Validation loss: 1.8970944471256708

Epoch: 6| Step: 12
Training loss: 1.220343828201294
Validation loss: 1.9396187977124286

Epoch: 6| Step: 13
Training loss: 1.7863996028900146
Validation loss: 1.9122256668665076

Epoch: 195| Step: 0
Training loss: 1.950882911682129
Validation loss: 1.8957800890809746

Epoch: 6| Step: 1
Training loss: 1.5553858280181885
Validation loss: 1.9114521870049097

Epoch: 6| Step: 2
Training loss: 1.7363680601119995
Validation loss: 1.9368828265897688

Epoch: 6| Step: 3
Training loss: 2.050767421722412
Validation loss: 1.9296894432396017

Epoch: 6| Step: 4
Training loss: 1.5949116945266724
Validation loss: 1.9394960159896522

Epoch: 6| Step: 5
Training loss: 1.8067989349365234
Validation loss: 1.8950244393399966

Epoch: 6| Step: 6
Training loss: 1.4805392026901245
Validation loss: 1.9150367808598343

Epoch: 6| Step: 7
Training loss: 1.6892117261886597
Validation loss: 1.9210392813528738

Epoch: 6| Step: 8
Training loss: 1.4166202545166016
Validation loss: 1.9172142833791754

Epoch: 6| Step: 9
Training loss: 2.1726455688476562
Validation loss: 1.8996007314292334

Epoch: 6| Step: 10
Training loss: 2.3153438568115234
Validation loss: 1.9171946087191183

Epoch: 6| Step: 11
Training loss: 1.7889198064804077
Validation loss: 1.9179031336179344

Epoch: 6| Step: 12
Training loss: 1.6202211380004883
Validation loss: 1.9240729654988935

Epoch: 6| Step: 13
Training loss: 2.0085039138793945
Validation loss: 1.8551797969366914

Epoch: 196| Step: 0
Training loss: 1.5018281936645508
Validation loss: 1.921626752422702

Epoch: 6| Step: 1
Training loss: 1.1842947006225586
Validation loss: 1.9310180474353094

Epoch: 6| Step: 2
Training loss: 1.6502766609191895
Validation loss: 1.955605346669433

Epoch: 6| Step: 3
Training loss: 2.0448007583618164
Validation loss: 1.994380872736695

Epoch: 6| Step: 4
Training loss: 1.9117997884750366
Validation loss: 1.9669210321159774

Epoch: 6| Step: 5
Training loss: 1.7298394441604614
Validation loss: 1.9877868942035142

Epoch: 6| Step: 6
Training loss: 1.6824712753295898
Validation loss: 2.024047661853093

Epoch: 6| Step: 7
Training loss: 2.23197078704834
Validation loss: 1.9755035395263343

Epoch: 6| Step: 8
Training loss: 1.968091368675232
Validation loss: 1.9894846049688195

Epoch: 6| Step: 9
Training loss: 1.5706772804260254
Validation loss: 1.998067686634679

Epoch: 6| Step: 10
Training loss: 1.4410407543182373
Validation loss: 2.006827208303636

Epoch: 6| Step: 11
Training loss: 2.2356066703796387
Validation loss: 1.9671770013788694

Epoch: 6| Step: 12
Training loss: 2.6157164573669434
Validation loss: 1.9748772446827223

Epoch: 6| Step: 13
Training loss: 1.390882134437561
Validation loss: 1.9523711794166154

Epoch: 197| Step: 0
Training loss: 2.140232563018799
Validation loss: 1.9363437506460375

Epoch: 6| Step: 1
Training loss: 1.246661901473999
Validation loss: 1.9356582600583312

Epoch: 6| Step: 2
Training loss: 1.645099401473999
Validation loss: 1.9050525029500325

Epoch: 6| Step: 3
Training loss: 1.9099797010421753
Validation loss: 1.9020175869746874

Epoch: 6| Step: 4
Training loss: 2.063732147216797
Validation loss: 1.9210324979597522

Epoch: 6| Step: 5
Training loss: 1.7745559215545654
Validation loss: 1.9223826546822824

Epoch: 6| Step: 6
Training loss: 2.0001165866851807
Validation loss: 1.9042825980853009

Epoch: 6| Step: 7
Training loss: 1.8973087072372437
Validation loss: 1.873987582422072

Epoch: 6| Step: 8
Training loss: 2.183933734893799
Validation loss: 1.9189903095204344

Epoch: 6| Step: 9
Training loss: 1.7974519729614258
Validation loss: 1.9273039653737059

Epoch: 6| Step: 10
Training loss: 1.040472149848938
Validation loss: 1.8972680107239754

Epoch: 6| Step: 11
Training loss: 1.818453073501587
Validation loss: 1.9164535666024813

Epoch: 6| Step: 12
Training loss: 1.938719630241394
Validation loss: 1.8917665097021288

Epoch: 6| Step: 13
Training loss: 2.4813754558563232
Validation loss: 1.8715513547261555

Epoch: 198| Step: 0
Training loss: 2.6275100708007812
Validation loss: 1.9030174363044001

Epoch: 6| Step: 1
Training loss: 1.7528529167175293
Validation loss: 1.9063515804147209

Epoch: 6| Step: 2
Training loss: 1.452246069908142
Validation loss: 1.9262429116874613

Epoch: 6| Step: 3
Training loss: 2.0267319679260254
Validation loss: 1.9162732965202742

Epoch: 6| Step: 4
Training loss: 1.434036135673523
Validation loss: 1.9619831244150798

Epoch: 6| Step: 5
Training loss: 1.808563470840454
Validation loss: 1.9521632450883106

Epoch: 6| Step: 6
Training loss: 1.6318670511245728
Validation loss: 1.9931187501517675

Epoch: 6| Step: 7
Training loss: 1.650000810623169
Validation loss: 1.9596019329563263

Epoch: 6| Step: 8
Training loss: 1.6376678943634033
Validation loss: 1.9707201296283352

Epoch: 6| Step: 9
Training loss: 1.1655359268188477
Validation loss: 1.9590260969695223

Epoch: 6| Step: 10
Training loss: 2.600064516067505
Validation loss: 1.9775961983588435

Epoch: 6| Step: 11
Training loss: 1.6051950454711914
Validation loss: 1.947024747889529

Epoch: 6| Step: 12
Training loss: 2.3728818893432617
Validation loss: 1.9502021164022467

Epoch: 6| Step: 13
Training loss: 1.2308965921401978
Validation loss: 1.9302188529763171

Epoch: 199| Step: 0
Training loss: 1.842693567276001
Validation loss: 1.9516547213318527

Epoch: 6| Step: 1
Training loss: 1.3727431297302246
Validation loss: 1.9728376544931883

Epoch: 6| Step: 2
Training loss: 1.6563692092895508
Validation loss: 1.9445295180043867

Epoch: 6| Step: 3
Training loss: 2.3154244422912598
Validation loss: 1.9339577920975224

Epoch: 6| Step: 4
Training loss: 2.0498642921447754
Validation loss: 1.9187587435527513

Epoch: 6| Step: 5
Training loss: 1.9289026260375977
Validation loss: 1.9502129888021817

Epoch: 6| Step: 6
Training loss: 1.3448342084884644
Validation loss: 1.9095259084496448

Epoch: 6| Step: 7
Training loss: 1.3259438276290894
Validation loss: 1.953209259176767

Epoch: 6| Step: 8
Training loss: 1.6316273212432861
Validation loss: 1.9362470821667743

Epoch: 6| Step: 9
Training loss: 1.2797741889953613
Validation loss: 1.900610795585058

Epoch: 6| Step: 10
Training loss: 1.4942216873168945
Validation loss: 1.9245000475196428

Epoch: 6| Step: 11
Training loss: 2.300652503967285
Validation loss: 1.927266897693757

Epoch: 6| Step: 12
Training loss: 2.068089485168457
Validation loss: 1.9176582841462986

Epoch: 6| Step: 13
Training loss: 2.3240156173706055
Validation loss: 1.9512123548856346

Epoch: 200| Step: 0
Training loss: 2.2360570430755615
Validation loss: 1.8911873358552174

Epoch: 6| Step: 1
Training loss: 2.012166976928711
Validation loss: 1.9075859951716598

Epoch: 6| Step: 2
Training loss: 1.4792454242706299
Validation loss: 1.934503150242631

Epoch: 6| Step: 3
Training loss: 1.7232601642608643
Validation loss: 1.927551209285695

Epoch: 6| Step: 4
Training loss: 1.7787597179412842
Validation loss: 1.8931469302023611

Epoch: 6| Step: 5
Training loss: 1.6042711734771729
Validation loss: 1.865322684728971

Epoch: 6| Step: 6
Training loss: 1.500948429107666
Validation loss: 1.8938466297682894

Epoch: 6| Step: 7
Training loss: 1.759814739227295
Validation loss: 1.9287739517868205

Epoch: 6| Step: 8
Training loss: 1.5975830554962158
Validation loss: 1.9100056079126173

Epoch: 6| Step: 9
Training loss: 2.573129653930664
Validation loss: 1.8984958100062546

Epoch: 6| Step: 10
Training loss: 1.276044249534607
Validation loss: 1.9221360734713975

Epoch: 6| Step: 11
Training loss: 1.7226215600967407
Validation loss: 1.9350660590715305

Epoch: 6| Step: 12
Training loss: 2.059351921081543
Validation loss: 1.9082210781753703

Epoch: 6| Step: 13
Training loss: 1.1631654500961304
Validation loss: 1.8977418356044318

Epoch: 201| Step: 0
Training loss: 1.679328441619873
Validation loss: 1.91544387930183

Epoch: 6| Step: 1
Training loss: 1.2124698162078857
Validation loss: 1.9025946983727076

Epoch: 6| Step: 2
Training loss: 2.0366806983947754
Validation loss: 1.9124618730237406

Epoch: 6| Step: 3
Training loss: 2.4643514156341553
Validation loss: 1.9308142841503184

Epoch: 6| Step: 4
Training loss: 2.2201056480407715
Validation loss: 1.944130305320986

Epoch: 6| Step: 5
Training loss: 1.6949617862701416
Validation loss: 1.9248704154004332

Epoch: 6| Step: 6
Training loss: 1.3733651638031006
Validation loss: 1.9555736510984358

Epoch: 6| Step: 7
Training loss: 1.5052729845046997
Validation loss: 1.9375154882348993

Epoch: 6| Step: 8
Training loss: 2.057345390319824
Validation loss: 1.9588270853924494

Epoch: 6| Step: 9
Training loss: 1.8767778873443604
Validation loss: 1.949658779687779

Epoch: 6| Step: 10
Training loss: 1.5172065496444702
Validation loss: 1.9913097850738033

Epoch: 6| Step: 11
Training loss: 1.4752824306488037
Validation loss: 1.9778586420961606

Epoch: 6| Step: 12
Training loss: 2.2272143363952637
Validation loss: 1.9839905423502768

Epoch: 6| Step: 13
Training loss: 1.579046607017517
Validation loss: 1.9179212918845556

Epoch: 202| Step: 0
Training loss: 1.573896050453186
Validation loss: 1.944699803988139

Epoch: 6| Step: 1
Training loss: 1.648840308189392
Validation loss: 1.9526235531735163

Epoch: 6| Step: 2
Training loss: 1.66429603099823
Validation loss: 1.9460274609186317

Epoch: 6| Step: 3
Training loss: 1.7578446865081787
Validation loss: 1.9183863811595465

Epoch: 6| Step: 4
Training loss: 2.0341849327087402
Validation loss: 1.9056525550862795

Epoch: 6| Step: 5
Training loss: 1.7797954082489014
Validation loss: 1.891985336939494

Epoch: 6| Step: 6
Training loss: 1.3520580530166626
Validation loss: 1.8951590702097902

Epoch: 6| Step: 7
Training loss: 1.9508023262023926
Validation loss: 1.8842538864381853

Epoch: 6| Step: 8
Training loss: 1.4729292392730713
Validation loss: 1.8889649132246613

Epoch: 6| Step: 9
Training loss: 1.686732292175293
Validation loss: 1.913502783544602

Epoch: 6| Step: 10
Training loss: 1.648341417312622
Validation loss: 1.9002288413304154

Epoch: 6| Step: 11
Training loss: 2.3272922039031982
Validation loss: 1.9200983842213948

Epoch: 6| Step: 12
Training loss: 2.465186357498169
Validation loss: 1.9094067773511332

Epoch: 6| Step: 13
Training loss: 1.522195816040039
Validation loss: 1.9195341538357478

Epoch: 203| Step: 0
Training loss: 1.953086256980896
Validation loss: 1.88963347096597

Epoch: 6| Step: 1
Training loss: 1.3962253332138062
Validation loss: 1.8930983594668809

Epoch: 6| Step: 2
Training loss: 1.7089018821716309
Validation loss: 1.8988061963870961

Epoch: 6| Step: 3
Training loss: 1.836222529411316
Validation loss: 1.8952996115530691

Epoch: 6| Step: 4
Training loss: 1.3926880359649658
Validation loss: 1.9076805871020082

Epoch: 6| Step: 5
Training loss: 1.9315292835235596
Validation loss: 1.9368541074055496

Epoch: 6| Step: 6
Training loss: 1.4046193361282349
Validation loss: 1.8784629811522782

Epoch: 6| Step: 7
Training loss: 1.677603006362915
Validation loss: 1.9131879498881679

Epoch: 6| Step: 8
Training loss: 2.624009132385254
Validation loss: 1.9173697207563667

Epoch: 6| Step: 9
Training loss: 2.081925868988037
Validation loss: 1.9097333031315957

Epoch: 6| Step: 10
Training loss: 1.3987102508544922
Validation loss: 1.9123608194371706

Epoch: 6| Step: 11
Training loss: 1.4056867361068726
Validation loss: 1.9034375016407301

Epoch: 6| Step: 12
Training loss: 2.0085630416870117
Validation loss: 1.9033606103671494

Epoch: 6| Step: 13
Training loss: 2.2563560009002686
Validation loss: 1.9244709758348362

Epoch: 204| Step: 0
Training loss: 1.748213291168213
Validation loss: 1.9161865301029657

Epoch: 6| Step: 1
Training loss: 1.8888885974884033
Validation loss: 1.9066726905043407

Epoch: 6| Step: 2
Training loss: 1.5194307565689087
Validation loss: 1.9245838119137673

Epoch: 6| Step: 3
Training loss: 1.6371121406555176
Validation loss: 1.9594881598667433

Epoch: 6| Step: 4
Training loss: 2.2071313858032227
Validation loss: 1.9358097276379984

Epoch: 6| Step: 5
Training loss: 1.7073408365249634
Validation loss: 1.9441192457752843

Epoch: 6| Step: 6
Training loss: 2.2251064777374268
Validation loss: 1.9341491037799465

Epoch: 6| Step: 7
Training loss: 1.9274564981460571
Validation loss: 1.9650030815473167

Epoch: 6| Step: 8
Training loss: 1.5417165756225586
Validation loss: 1.9696571865389425

Epoch: 6| Step: 9
Training loss: 2.0200343132019043
Validation loss: 1.9569131379486413

Epoch: 6| Step: 10
Training loss: 1.754143238067627
Validation loss: 1.9161779085795085

Epoch: 6| Step: 11
Training loss: 1.754844069480896
Validation loss: 1.9510948683625908

Epoch: 6| Step: 12
Training loss: 1.2465945482254028
Validation loss: 1.9158757540487474

Epoch: 6| Step: 13
Training loss: 1.6801155805587769
Validation loss: 1.9339939625032487

Epoch: 205| Step: 0
Training loss: 1.4388340711593628
Validation loss: 1.9231536798579718

Epoch: 6| Step: 1
Training loss: 1.8031656742095947
Validation loss: 1.9442678369501585

Epoch: 6| Step: 2
Training loss: 1.9285178184509277
Validation loss: 1.9373051248570925

Epoch: 6| Step: 3
Training loss: 2.266202211380005
Validation loss: 1.9291729632244314

Epoch: 6| Step: 4
Training loss: 1.774275302886963
Validation loss: 1.909820951441283

Epoch: 6| Step: 5
Training loss: 1.8457530736923218
Validation loss: 1.8994232018788655

Epoch: 6| Step: 6
Training loss: 1.723648190498352
Validation loss: 1.9097978940574072

Epoch: 6| Step: 7
Training loss: 1.6917908191680908
Validation loss: 1.9156364753682127

Epoch: 6| Step: 8
Training loss: 2.0313560962677
Validation loss: 1.9452745363276491

Epoch: 6| Step: 9
Training loss: 1.7187960147857666
Validation loss: 1.9072190535965787

Epoch: 6| Step: 10
Training loss: 1.3111976385116577
Validation loss: 1.9206419965272308

Epoch: 6| Step: 11
Training loss: 2.0190820693969727
Validation loss: 1.9095917645321097

Epoch: 6| Step: 12
Training loss: 1.5123255252838135
Validation loss: 1.8928683124562746

Epoch: 6| Step: 13
Training loss: 1.2841275930404663
Validation loss: 1.8988210616573211

Epoch: 206| Step: 0
Training loss: 1.276652216911316
Validation loss: 1.912946903577415

Epoch: 6| Step: 1
Training loss: 2.311866283416748
Validation loss: 1.9028132115640948

Epoch: 6| Step: 2
Training loss: 2.1076865196228027
Validation loss: 1.9165928056163173

Epoch: 6| Step: 3
Training loss: 1.6594088077545166
Validation loss: 1.9256589002506708

Epoch: 6| Step: 4
Training loss: 1.8860814571380615
Validation loss: 1.911067384545521

Epoch: 6| Step: 5
Training loss: 1.9634473323822021
Validation loss: 1.8993723430941183

Epoch: 6| Step: 6
Training loss: 1.331783413887024
Validation loss: 1.9075386485745829

Epoch: 6| Step: 7
Training loss: 2.043163299560547
Validation loss: 1.9077177496366604

Epoch: 6| Step: 8
Training loss: 1.713257074356079
Validation loss: 1.905286406957975

Epoch: 6| Step: 9
Training loss: 1.7019835710525513
Validation loss: 1.9009027173442226

Epoch: 6| Step: 10
Training loss: 2.1164238452911377
Validation loss: 1.9381141611324844

Epoch: 6| Step: 11
Training loss: 1.5651919841766357
Validation loss: 1.9122261539582284

Epoch: 6| Step: 12
Training loss: 1.2494785785675049
Validation loss: 1.9143731927358976

Epoch: 6| Step: 13
Training loss: 2.0543782711029053
Validation loss: 1.9225413671103857

Epoch: 207| Step: 0
Training loss: 1.951030969619751
Validation loss: 1.9187134363318001

Epoch: 6| Step: 1
Training loss: 1.5476610660552979
Validation loss: 1.9288238812518377

Epoch: 6| Step: 2
Training loss: 2.5217058658599854
Validation loss: 1.9174836963735602

Epoch: 6| Step: 3
Training loss: 1.7711474895477295
Validation loss: 1.9009262848925847

Epoch: 6| Step: 4
Training loss: 1.8731963634490967
Validation loss: 1.911642256603446

Epoch: 6| Step: 5
Training loss: 1.0958926677703857
Validation loss: 1.9019448103443268

Epoch: 6| Step: 6
Training loss: 1.9076366424560547
Validation loss: 1.8834486687055199

Epoch: 6| Step: 7
Training loss: 1.269392728805542
Validation loss: 1.902114781000281

Epoch: 6| Step: 8
Training loss: 2.019899368286133
Validation loss: 1.9073810654301797

Epoch: 6| Step: 9
Training loss: 1.638777494430542
Validation loss: 1.9096004078465123

Epoch: 6| Step: 10
Training loss: 1.7293987274169922
Validation loss: 1.9038135261945828

Epoch: 6| Step: 11
Training loss: 1.9938328266143799
Validation loss: 1.9003169369953934

Epoch: 6| Step: 12
Training loss: 1.7918132543563843
Validation loss: 1.9122901065375215

Epoch: 6| Step: 13
Training loss: 1.1323827505111694
Validation loss: 1.9028587597672657

Epoch: 208| Step: 0
Training loss: 1.5684545040130615
Validation loss: 1.8937589660767586

Epoch: 6| Step: 1
Training loss: 1.7673779726028442
Validation loss: 1.8991433523034538

Epoch: 6| Step: 2
Training loss: 1.5826427936553955
Validation loss: 1.9020096807069675

Epoch: 6| Step: 3
Training loss: 1.7015862464904785
Validation loss: 1.9117614940930439

Epoch: 6| Step: 4
Training loss: 1.6050350666046143
Validation loss: 1.8945503260499688

Epoch: 6| Step: 5
Training loss: 2.2359464168548584
Validation loss: 1.8808970669264435

Epoch: 6| Step: 6
Training loss: 2.551029682159424
Validation loss: 1.8693641103723997

Epoch: 6| Step: 7
Training loss: 1.484107255935669
Validation loss: 1.8714128848045104

Epoch: 6| Step: 8
Training loss: 1.5168812274932861
Validation loss: 1.875745109332505

Epoch: 6| Step: 9
Training loss: 1.4359434843063354
Validation loss: 1.9098254153805394

Epoch: 6| Step: 10
Training loss: 1.9003338813781738
Validation loss: 1.8916819377612042

Epoch: 6| Step: 11
Training loss: 1.7675851583480835
Validation loss: 1.9074850877126057

Epoch: 6| Step: 12
Training loss: 1.7518162727355957
Validation loss: 1.873839710348396

Epoch: 6| Step: 13
Training loss: 1.9258875846862793
Validation loss: 1.9315271454472696

Epoch: 209| Step: 0
Training loss: 1.9729797840118408
Validation loss: 1.8972693386898245

Epoch: 6| Step: 1
Training loss: 1.3566064834594727
Validation loss: 1.9264820724405267

Epoch: 6| Step: 2
Training loss: 1.847873568534851
Validation loss: 1.9274447887174544

Epoch: 6| Step: 3
Training loss: 2.2230308055877686
Validation loss: 1.9347903831030733

Epoch: 6| Step: 4
Training loss: 1.1891006231307983
Validation loss: 1.9467939894686463

Epoch: 6| Step: 5
Training loss: 2.3457841873168945
Validation loss: 1.9193640729432464

Epoch: 6| Step: 6
Training loss: 1.1190342903137207
Validation loss: 1.9499954651760798

Epoch: 6| Step: 7
Training loss: 2.184441566467285
Validation loss: 1.9090462679504066

Epoch: 6| Step: 8
Training loss: 2.191377639770508
Validation loss: 1.9616999139067948

Epoch: 6| Step: 9
Training loss: 1.5482289791107178
Validation loss: 1.9552178818692443

Epoch: 6| Step: 10
Training loss: 0.8794628381729126
Validation loss: 1.9154608467573762

Epoch: 6| Step: 11
Training loss: 1.9145846366882324
Validation loss: 1.9292149466852988

Epoch: 6| Step: 12
Training loss: 2.2060694694519043
Validation loss: 1.9274802066946541

Epoch: 6| Step: 13
Training loss: 1.8175283670425415
Validation loss: 1.8490795371352986

Epoch: 210| Step: 0
Training loss: 1.805429220199585
Validation loss: 1.9132100830795944

Epoch: 6| Step: 1
Training loss: 1.4804775714874268
Validation loss: 1.9014119525109567

Epoch: 6| Step: 2
Training loss: 1.9689608812332153
Validation loss: 1.875007939595048

Epoch: 6| Step: 3
Training loss: 1.8022701740264893
Validation loss: 1.8734685759390555

Epoch: 6| Step: 4
Training loss: 2.0249483585357666
Validation loss: 1.8848651814204391

Epoch: 6| Step: 5
Training loss: 1.3859189748764038
Validation loss: 1.8568361856604134

Epoch: 6| Step: 6
Training loss: 1.6754405498504639
Validation loss: 1.8794620703625422

Epoch: 6| Step: 7
Training loss: 2.9369192123413086
Validation loss: 1.881560000040198

Epoch: 6| Step: 8
Training loss: 1.9010571241378784
Validation loss: 1.9005827596110683

Epoch: 6| Step: 9
Training loss: 1.6608227491378784
Validation loss: 1.9127371157369306

Epoch: 6| Step: 10
Training loss: 1.3594989776611328
Validation loss: 1.8501262946795392

Epoch: 6| Step: 11
Training loss: 1.1316065788269043
Validation loss: 1.9051611320946806

Epoch: 6| Step: 12
Training loss: 1.7318521738052368
Validation loss: 1.8885943223071355

Epoch: 6| Step: 13
Training loss: 1.5595874786376953
Validation loss: 1.9333336045665126

Epoch: 211| Step: 0
Training loss: 1.533625841140747
Validation loss: 1.9129125802747664

Epoch: 6| Step: 1
Training loss: 2.648914337158203
Validation loss: 1.9138370713879984

Epoch: 6| Step: 2
Training loss: 1.1258578300476074
Validation loss: 1.8564339171173752

Epoch: 6| Step: 3
Training loss: 1.5111197233200073
Validation loss: 1.9154253928892073

Epoch: 6| Step: 4
Training loss: 2.2019073963165283
Validation loss: 1.9093351928136681

Epoch: 6| Step: 5
Training loss: 1.3675682544708252
Validation loss: 1.8852865836953605

Epoch: 6| Step: 6
Training loss: 2.143270492553711
Validation loss: 1.8995729249010804

Epoch: 6| Step: 7
Training loss: 2.1149227619171143
Validation loss: 1.9197961912360242

Epoch: 6| Step: 8
Training loss: 1.4636504650115967
Validation loss: 1.9168000733980568

Epoch: 6| Step: 9
Training loss: 1.7856483459472656
Validation loss: 1.8759615472567979

Epoch: 6| Step: 10
Training loss: 1.2267415523529053
Validation loss: 1.904355848989179

Epoch: 6| Step: 11
Training loss: 2.2563443183898926
Validation loss: 1.924357445009293

Epoch: 6| Step: 12
Training loss: 1.3312220573425293
Validation loss: 1.8572072905878867

Epoch: 6| Step: 13
Training loss: 1.273475170135498
Validation loss: 1.9010892952642133

Epoch: 212| Step: 0
Training loss: 1.8059170246124268
Validation loss: 1.9211775743833153

Epoch: 6| Step: 1
Training loss: 1.5690934658050537
Validation loss: 1.8735975321903025

Epoch: 6| Step: 2
Training loss: 1.6311746835708618
Validation loss: 1.9004713437890495

Epoch: 6| Step: 3
Training loss: 1.345703363418579
Validation loss: 1.8834260112495833

Epoch: 6| Step: 4
Training loss: 1.9352211952209473
Validation loss: 1.9186647989416634

Epoch: 6| Step: 5
Training loss: 1.3435847759246826
Validation loss: 1.9069983215742214

Epoch: 6| Step: 6
Training loss: 1.7869758605957031
Validation loss: 1.9052101847946004

Epoch: 6| Step: 7
Training loss: 2.2889952659606934
Validation loss: 1.9263333492381598

Epoch: 6| Step: 8
Training loss: 2.271294593811035
Validation loss: 1.902190887799827

Epoch: 6| Step: 9
Training loss: 1.7339200973510742
Validation loss: 1.9253304030305596

Epoch: 6| Step: 10
Training loss: 1.3801881074905396
Validation loss: 1.9078891687495734

Epoch: 6| Step: 11
Training loss: 1.460307240486145
Validation loss: 1.925393517299365

Epoch: 6| Step: 12
Training loss: 2.0870747566223145
Validation loss: 1.9101332387616556

Epoch: 6| Step: 13
Training loss: 1.3106266260147095
Validation loss: 1.9368038382581485

Epoch: 213| Step: 0
Training loss: 1.6060255765914917
Validation loss: 1.9283777885539557

Epoch: 6| Step: 1
Training loss: 2.2278645038604736
Validation loss: 1.934780151613297

Epoch: 6| Step: 2
Training loss: 1.811410665512085
Validation loss: 1.9521791460693523

Epoch: 6| Step: 3
Training loss: 1.8583403825759888
Validation loss: 1.8936625167887697

Epoch: 6| Step: 4
Training loss: 1.5256142616271973
Validation loss: 1.889544105017057

Epoch: 6| Step: 5
Training loss: 1.8123409748077393
Validation loss: 1.9462536240136752

Epoch: 6| Step: 6
Training loss: 1.4017938375473022
Validation loss: 1.9395751337851248

Epoch: 6| Step: 7
Training loss: 1.6646850109100342
Validation loss: 1.9380939545169953

Epoch: 6| Step: 8
Training loss: 0.9885550737380981
Validation loss: 1.9018125431511992

Epoch: 6| Step: 9
Training loss: 1.7447556257247925
Validation loss: 1.9241592525154032

Epoch: 6| Step: 10
Training loss: 2.096257209777832
Validation loss: 1.9156807686692925

Epoch: 6| Step: 11
Training loss: 1.582369089126587
Validation loss: 1.9079672739069948

Epoch: 6| Step: 12
Training loss: 1.1043117046356201
Validation loss: 1.8894963264465332

Epoch: 6| Step: 13
Training loss: 3.6805436611175537
Validation loss: 1.955712192802019

Epoch: 214| Step: 0
Training loss: 1.2554473876953125
Validation loss: 1.8843580112662366

Epoch: 6| Step: 1
Training loss: 2.7704687118530273
Validation loss: 1.9172318314993253

Epoch: 6| Step: 2
Training loss: 1.8364057540893555
Validation loss: 1.906379025469544

Epoch: 6| Step: 3
Training loss: 1.721277117729187
Validation loss: 1.9120608581009733

Epoch: 6| Step: 4
Training loss: 1.733119249343872
Validation loss: 1.8756865493712886

Epoch: 6| Step: 5
Training loss: 1.5615570545196533
Validation loss: 1.9346409254176642

Epoch: 6| Step: 6
Training loss: 1.4048560857772827
Validation loss: 1.904744243109098

Epoch: 6| Step: 7
Training loss: 2.1023764610290527
Validation loss: 1.9071671270555066

Epoch: 6| Step: 8
Training loss: 1.9004619121551514
Validation loss: 1.9098651075875888

Epoch: 6| Step: 9
Training loss: 1.619577169418335
Validation loss: 1.9143217891775153

Epoch: 6| Step: 10
Training loss: 1.8973770141601562
Validation loss: 1.885855128688197

Epoch: 6| Step: 11
Training loss: 1.6448489427566528
Validation loss: 1.8784339120311122

Epoch: 6| Step: 12
Training loss: 1.572242021560669
Validation loss: 1.8905171835294334

Epoch: 6| Step: 13
Training loss: 0.937773585319519
Validation loss: 1.8959262473608858

Epoch: 215| Step: 0
Training loss: 1.6733968257904053
Validation loss: 1.9262838799466369

Epoch: 6| Step: 1
Training loss: 1.913649559020996
Validation loss: 1.9006402069522488

Epoch: 6| Step: 2
Training loss: 1.660830020904541
Validation loss: 1.9145301772702126

Epoch: 6| Step: 3
Training loss: 2.156130075454712
Validation loss: 1.8648204034374607

Epoch: 6| Step: 4
Training loss: 1.4025895595550537
Validation loss: 1.896591144223367

Epoch: 6| Step: 5
Training loss: 1.5772345066070557
Validation loss: 1.9144111089808966

Epoch: 6| Step: 6
Training loss: 1.3413074016571045
Validation loss: 1.9029158930624686

Epoch: 6| Step: 7
Training loss: 2.169067144393921
Validation loss: 1.9074035549676547

Epoch: 6| Step: 8
Training loss: 1.53904128074646
Validation loss: 1.8901698332960888

Epoch: 6| Step: 9
Training loss: 2.0346484184265137
Validation loss: 1.8861752530579925

Epoch: 6| Step: 10
Training loss: 1.8109610080718994
Validation loss: 1.8800293040531937

Epoch: 6| Step: 11
Training loss: 2.0709075927734375
Validation loss: 1.8941942299565961

Epoch: 6| Step: 12
Training loss: 1.5717629194259644
Validation loss: 1.8746192275836904

Epoch: 6| Step: 13
Training loss: 1.179465651512146
Validation loss: 1.8927048560111754

Epoch: 216| Step: 0
Training loss: 2.280932664871216
Validation loss: 1.8866598618927823

Epoch: 6| Step: 1
Training loss: 1.2408593893051147
Validation loss: 1.8758604552156182

Epoch: 6| Step: 2
Training loss: 2.4311094284057617
Validation loss: 1.8479162275150258

Epoch: 6| Step: 3
Training loss: 1.3938652276992798
Validation loss: 1.872260401325841

Epoch: 6| Step: 4
Training loss: 2.0672807693481445
Validation loss: 1.9119078446460027

Epoch: 6| Step: 5
Training loss: 1.100654125213623
Validation loss: 1.8630994007151613

Epoch: 6| Step: 6
Training loss: 1.9610930681228638
Validation loss: 1.8405083174346595

Epoch: 6| Step: 7
Training loss: 1.0805898904800415
Validation loss: 1.909473733235431

Epoch: 6| Step: 8
Training loss: 1.4948829412460327
Validation loss: 1.8539169629414876

Epoch: 6| Step: 9
Training loss: 1.8104158639907837
Validation loss: 1.8720582300616848

Epoch: 6| Step: 10
Training loss: 2.1559457778930664
Validation loss: 1.9032880593371648

Epoch: 6| Step: 11
Training loss: 1.3368380069732666
Validation loss: 1.9036248883893412

Epoch: 6| Step: 12
Training loss: 1.5529680252075195
Validation loss: 1.873892472636315

Epoch: 6| Step: 13
Training loss: 2.5011470317840576
Validation loss: 1.873987118403117

Epoch: 217| Step: 0
Training loss: 1.7752251625061035
Validation loss: 1.9111646452257711

Epoch: 6| Step: 1
Training loss: 1.7959179878234863
Validation loss: 1.904031120320802

Epoch: 6| Step: 2
Training loss: 1.3101401329040527
Validation loss: 1.8842387686493576

Epoch: 6| Step: 3
Training loss: 1.4285943508148193
Validation loss: 1.9293629495046472

Epoch: 6| Step: 4
Training loss: 1.8955371379852295
Validation loss: 1.9499812190250685

Epoch: 6| Step: 5
Training loss: 1.561326503753662
Validation loss: 1.9122860047125048

Epoch: 6| Step: 6
Training loss: 1.4056298732757568
Validation loss: 1.9259314844685216

Epoch: 6| Step: 7
Training loss: 2.271132469177246
Validation loss: 1.900096857419578

Epoch: 6| Step: 8
Training loss: 1.6597368717193604
Validation loss: 1.9502101123973887

Epoch: 6| Step: 9
Training loss: 1.809586524963379
Validation loss: 1.9222671934353408

Epoch: 6| Step: 10
Training loss: 1.4503470659255981
Validation loss: 1.968203883017263

Epoch: 6| Step: 11
Training loss: 1.2061104774475098
Validation loss: 1.9381018941120436

Epoch: 6| Step: 12
Training loss: 2.2846953868865967
Validation loss: 1.9004491759884743

Epoch: 6| Step: 13
Training loss: 2.477482795715332
Validation loss: 1.8490374370287823

Epoch: 218| Step: 0
Training loss: 1.156778335571289
Validation loss: 1.887084004699543

Epoch: 6| Step: 1
Training loss: 1.1848623752593994
Validation loss: 1.8584704988746232

Epoch: 6| Step: 2
Training loss: 1.624656319618225
Validation loss: 1.8740790813199935

Epoch: 6| Step: 3
Training loss: 2.5183959007263184
Validation loss: 1.8774124524926628

Epoch: 6| Step: 4
Training loss: 2.046112537384033
Validation loss: 1.8707914813872306

Epoch: 6| Step: 5
Training loss: 2.063037872314453
Validation loss: 1.8588478308852001

Epoch: 6| Step: 6
Training loss: 2.1446967124938965
Validation loss: 1.9101919922777402

Epoch: 6| Step: 7
Training loss: 1.6762275695800781
Validation loss: 1.8722791120570192

Epoch: 6| Step: 8
Training loss: 1.956714391708374
Validation loss: 1.9050196883498982

Epoch: 6| Step: 9
Training loss: 1.146222710609436
Validation loss: 1.9262059657804427

Epoch: 6| Step: 10
Training loss: 1.6046470403671265
Validation loss: 1.864037008695705

Epoch: 6| Step: 11
Training loss: 1.4709153175354004
Validation loss: 1.9117406875856462

Epoch: 6| Step: 12
Training loss: 1.687013864517212
Validation loss: 1.873247782389323

Epoch: 6| Step: 13
Training loss: 1.7771553993225098
Validation loss: 1.8895873100526872

Epoch: 219| Step: 0
Training loss: 1.9103038311004639
Validation loss: 1.9015553318044192

Epoch: 6| Step: 1
Training loss: 1.1245958805084229
Validation loss: 1.8948686609986007

Epoch: 6| Step: 2
Training loss: 1.409435510635376
Validation loss: 1.8634804500046598

Epoch: 6| Step: 3
Training loss: 1.1883127689361572
Validation loss: 1.9037300976373817

Epoch: 6| Step: 4
Training loss: 1.4734617471694946
Validation loss: 1.888710368064142

Epoch: 6| Step: 5
Training loss: 1.877890706062317
Validation loss: 1.8858378984594857

Epoch: 6| Step: 6
Training loss: 1.7111427783966064
Validation loss: 1.9199042409978888

Epoch: 6| Step: 7
Training loss: 1.3041253089904785
Validation loss: 1.8643985243253811

Epoch: 6| Step: 8
Training loss: 1.8649990558624268
Validation loss: 1.9180520196114816

Epoch: 6| Step: 9
Training loss: 2.3968334197998047
Validation loss: 1.8955042810850247

Epoch: 6| Step: 10
Training loss: 1.8088160753250122
Validation loss: 1.904123552383915

Epoch: 6| Step: 11
Training loss: 1.3116145133972168
Validation loss: 1.9117311495606617

Epoch: 6| Step: 12
Training loss: 2.7079148292541504
Validation loss: 1.9088705291030228

Epoch: 6| Step: 13
Training loss: 2.0594937801361084
Validation loss: 1.8860876944757277

Epoch: 220| Step: 0
Training loss: 2.0902724266052246
Validation loss: 1.923170228158274

Epoch: 6| Step: 1
Training loss: 1.9032542705535889
Validation loss: 1.920046269252736

Epoch: 6| Step: 2
Training loss: 2.044640064239502
Validation loss: 1.9083646420509583

Epoch: 6| Step: 3
Training loss: 1.1669234037399292
Validation loss: 1.9279909749184885

Epoch: 6| Step: 4
Training loss: 1.5858547687530518
Validation loss: 1.9017045779894757

Epoch: 6| Step: 5
Training loss: 1.7629156112670898
Validation loss: 1.926269967068908

Epoch: 6| Step: 6
Training loss: 1.6293737888336182
Validation loss: 1.885303698560243

Epoch: 6| Step: 7
Training loss: 1.400673270225525
Validation loss: 1.8993128063858196

Epoch: 6| Step: 8
Training loss: 1.6210765838623047
Validation loss: 1.8969379073830062

Epoch: 6| Step: 9
Training loss: 2.0377511978149414
Validation loss: 1.9156933112811017

Epoch: 6| Step: 10
Training loss: 1.6409473419189453
Validation loss: 1.9252112245046964

Epoch: 6| Step: 11
Training loss: 2.488157033920288
Validation loss: 1.9372848567142282

Epoch: 6| Step: 12
Training loss: 1.2817347049713135
Validation loss: 1.9099750185525546

Epoch: 6| Step: 13
Training loss: 0.8843943476676941
Validation loss: 1.9056721695007817

Epoch: 221| Step: 0
Training loss: 1.8477094173431396
Validation loss: 1.9345205522352649

Epoch: 6| Step: 1
Training loss: 1.481785535812378
Validation loss: 1.8732766130919098

Epoch: 6| Step: 2
Training loss: 2.643193244934082
Validation loss: 1.9222254445475917

Epoch: 6| Step: 3
Training loss: 1.4441213607788086
Validation loss: 1.9074768545807048

Epoch: 6| Step: 4
Training loss: 1.495720624923706
Validation loss: 1.8807060628808954

Epoch: 6| Step: 5
Training loss: 0.931954026222229
Validation loss: 1.8588284523256364

Epoch: 6| Step: 6
Training loss: 1.8992292881011963
Validation loss: 1.8862584214056692

Epoch: 6| Step: 7
Training loss: 1.7974340915679932
Validation loss: 1.9323528274413078

Epoch: 6| Step: 8
Training loss: 1.0471079349517822
Validation loss: 1.9163525296795754

Epoch: 6| Step: 9
Training loss: 1.3740432262420654
Validation loss: 1.8917360587786602

Epoch: 6| Step: 10
Training loss: 1.8795115947723389
Validation loss: 1.891743460009175

Epoch: 6| Step: 11
Training loss: 2.0556187629699707
Validation loss: 1.878421632192468

Epoch: 6| Step: 12
Training loss: 1.7730917930603027
Validation loss: 1.8540328318072903

Epoch: 6| Step: 13
Training loss: 2.006746768951416
Validation loss: 1.8925138852929557

Epoch: 222| Step: 0
Training loss: 1.8222801685333252
Validation loss: 1.872832199578644

Epoch: 6| Step: 1
Training loss: 1.8537099361419678
Validation loss: 1.8668650991173201

Epoch: 6| Step: 2
Training loss: 1.3410029411315918
Validation loss: 1.8689642067878478

Epoch: 6| Step: 3
Training loss: 1.4162381887435913
Validation loss: 1.8592689921779018

Epoch: 6| Step: 4
Training loss: 2.420835494995117
Validation loss: 1.871352098321402

Epoch: 6| Step: 5
Training loss: 1.6473132371902466
Validation loss: 1.9318626785791049

Epoch: 6| Step: 6
Training loss: 2.0760064125061035
Validation loss: 1.884916461924071

Epoch: 6| Step: 7
Training loss: 1.3944244384765625
Validation loss: 1.8926224990557599

Epoch: 6| Step: 8
Training loss: 1.0418920516967773
Validation loss: 1.8315928828331731

Epoch: 6| Step: 9
Training loss: 1.5143821239471436
Validation loss: 1.8904960334941905

Epoch: 6| Step: 10
Training loss: 1.4133127927780151
Validation loss: 1.8726604266833233

Epoch: 6| Step: 11
Training loss: 1.7569575309753418
Validation loss: 1.8817140876605947

Epoch: 6| Step: 12
Training loss: 2.1234376430511475
Validation loss: 1.8817656168373682

Epoch: 6| Step: 13
Training loss: 2.275418281555176
Validation loss: 1.8613658041082404

Epoch: 223| Step: 0
Training loss: 1.9297502040863037
Validation loss: 1.898271623478141

Epoch: 6| Step: 1
Training loss: 1.7929216623306274
Validation loss: 1.8677313558516964

Epoch: 6| Step: 2
Training loss: 1.4367601871490479
Validation loss: 1.8927261649921376

Epoch: 6| Step: 3
Training loss: 1.6252728700637817
Validation loss: 1.8831324474785918

Epoch: 6| Step: 4
Training loss: 1.6351542472839355
Validation loss: 1.9132051493531914

Epoch: 6| Step: 5
Training loss: 1.3469345569610596
Validation loss: 1.8853356979226554

Epoch: 6| Step: 6
Training loss: 2.934624433517456
Validation loss: 1.8914112980647753

Epoch: 6| Step: 7
Training loss: 1.306860327720642
Validation loss: 1.885479082343399

Epoch: 6| Step: 8
Training loss: 1.7980985641479492
Validation loss: 1.9185088757545716

Epoch: 6| Step: 9
Training loss: 1.4327633380889893
Validation loss: 1.900664875584264

Epoch: 6| Step: 10
Training loss: 1.0916508436203003
Validation loss: 1.8511124708319222

Epoch: 6| Step: 11
Training loss: 2.1418020725250244
Validation loss: 1.8859016908112394

Epoch: 6| Step: 12
Training loss: 2.0021257400512695
Validation loss: 1.879541338130992

Epoch: 6| Step: 13
Training loss: 1.343907356262207
Validation loss: 1.872664600290278

Epoch: 224| Step: 0
Training loss: 1.508305549621582
Validation loss: 1.8740202432037683

Epoch: 6| Step: 1
Training loss: 1.8089830875396729
Validation loss: 1.8718734723265453

Epoch: 6| Step: 2
Training loss: 1.4975430965423584
Validation loss: 1.9045112133026123

Epoch: 6| Step: 3
Training loss: 1.8149237632751465
Validation loss: 1.9016808079135032

Epoch: 6| Step: 4
Training loss: 1.758223533630371
Validation loss: 1.833779675986177

Epoch: 6| Step: 5
Training loss: 2.096177339553833
Validation loss: 1.914209314571914

Epoch: 6| Step: 6
Training loss: 2.011425256729126
Validation loss: 1.8702257089717413

Epoch: 6| Step: 7
Training loss: 1.6007378101348877
Validation loss: 1.8659583060972151

Epoch: 6| Step: 8
Training loss: 1.006476640701294
Validation loss: 1.8607003688812256

Epoch: 6| Step: 9
Training loss: 1.7983475923538208
Validation loss: 1.876702776519201

Epoch: 6| Step: 10
Training loss: 0.920902669429779
Validation loss: 1.8572005776948826

Epoch: 6| Step: 11
Training loss: 1.8662917613983154
Validation loss: 1.9155623002718853

Epoch: 6| Step: 12
Training loss: 1.9626498222351074
Validation loss: 1.895781974638662

Epoch: 6| Step: 13
Training loss: 2.638288974761963
Validation loss: 1.8864470553654495

Epoch: 225| Step: 0
Training loss: 1.6426893472671509
Validation loss: 1.866983562387446

Epoch: 6| Step: 1
Training loss: 1.6924234628677368
Validation loss: 1.9305888222109886

Epoch: 6| Step: 2
Training loss: 1.852942943572998
Validation loss: 1.881756833804551

Epoch: 6| Step: 3
Training loss: 1.1911890506744385
Validation loss: 1.8819822752347557

Epoch: 6| Step: 4
Training loss: 2.0783121585845947
Validation loss: 1.8916373150323027

Epoch: 6| Step: 5
Training loss: 1.1482515335083008
Validation loss: 1.8815249986546014

Epoch: 6| Step: 6
Training loss: 2.1959309577941895
Validation loss: 1.8636829314693328

Epoch: 6| Step: 7
Training loss: 2.471402168273926
Validation loss: 1.903569471451544

Epoch: 6| Step: 8
Training loss: 1.8188364505767822
Validation loss: 1.8933010280773204

Epoch: 6| Step: 9
Training loss: 1.8844757080078125
Validation loss: 1.889682440347569

Epoch: 6| Step: 10
Training loss: 1.9390714168548584
Validation loss: 1.885426687937911

Epoch: 6| Step: 11
Training loss: 1.359692096710205
Validation loss: 1.8824927845308859

Epoch: 6| Step: 12
Training loss: 1.2792866230010986
Validation loss: 1.8487150528097664

Epoch: 6| Step: 13
Training loss: 1.079906940460205
Validation loss: 1.8679301123465262

Epoch: 226| Step: 0
Training loss: 2.1593081951141357
Validation loss: 1.8230992158253987

Epoch: 6| Step: 1
Training loss: 2.2808003425598145
Validation loss: 1.8394062147345593

Epoch: 6| Step: 2
Training loss: 1.7489731311798096
Validation loss: 1.8849593811137701

Epoch: 6| Step: 3
Training loss: 1.5173521041870117
Validation loss: 1.8884595408234546

Epoch: 6| Step: 4
Training loss: 1.5281058549880981
Validation loss: 1.8843269886509064

Epoch: 6| Step: 5
Training loss: 1.2593398094177246
Validation loss: 1.9178279907472673

Epoch: 6| Step: 6
Training loss: 1.7331092357635498
Validation loss: 1.861296050010189

Epoch: 6| Step: 7
Training loss: 1.202181339263916
Validation loss: 1.8982152169750584

Epoch: 6| Step: 8
Training loss: 1.1633285284042358
Validation loss: 1.9004141502482916

Epoch: 6| Step: 9
Training loss: 1.9523835182189941
Validation loss: 1.8999708724278275

Epoch: 6| Step: 10
Training loss: 2.225769519805908
Validation loss: 1.9079139232635498

Epoch: 6| Step: 11
Training loss: 1.18941068649292
Validation loss: 1.891206577260007

Epoch: 6| Step: 12
Training loss: 1.7940683364868164
Validation loss: 1.901115559762524

Epoch: 6| Step: 13
Training loss: 1.9001952409744263
Validation loss: 1.8911029241418327

Epoch: 227| Step: 0
Training loss: 1.5884628295898438
Validation loss: 1.87991774723094

Epoch: 6| Step: 1
Training loss: 1.5919325351715088
Validation loss: 1.8927697673920663

Epoch: 6| Step: 2
Training loss: 1.6246049404144287
Validation loss: 1.8786229613006755

Epoch: 6| Step: 3
Training loss: 1.8576240539550781
Validation loss: 1.9093428145172775

Epoch: 6| Step: 4
Training loss: 1.5144646167755127
Validation loss: 1.9072156272908694

Epoch: 6| Step: 5
Training loss: 1.7786637544631958
Validation loss: 1.8632411085149294

Epoch: 6| Step: 6
Training loss: 1.49497652053833
Validation loss: 1.8494456865454232

Epoch: 6| Step: 7
Training loss: 1.037766456604004
Validation loss: 1.9059466367126794

Epoch: 6| Step: 8
Training loss: 2.2718327045440674
Validation loss: 1.9034472332205823

Epoch: 6| Step: 9
Training loss: 1.0610097646713257
Validation loss: 1.8543975596786828

Epoch: 6| Step: 10
Training loss: 1.3232004642486572
Validation loss: 1.8763250138169976

Epoch: 6| Step: 11
Training loss: 2.591154098510742
Validation loss: 1.889280080795288

Epoch: 6| Step: 12
Training loss: 1.7056297063827515
Validation loss: 1.8497633934020996

Epoch: 6| Step: 13
Training loss: 1.939160704612732
Validation loss: 1.896816542071681

Epoch: 228| Step: 0
Training loss: 2.1947669982910156
Validation loss: 1.8841011075563328

Epoch: 6| Step: 1
Training loss: 1.6798157691955566
Validation loss: 1.879609771954116

Epoch: 6| Step: 2
Training loss: 1.858668565750122
Validation loss: 1.830301074571507

Epoch: 6| Step: 3
Training loss: 1.4458153247833252
Validation loss: 1.8251533533937188

Epoch: 6| Step: 4
Training loss: 1.307549238204956
Validation loss: 1.8840944254270164

Epoch: 6| Step: 5
Training loss: 1.883129596710205
Validation loss: 1.9020667332474903

Epoch: 6| Step: 6
Training loss: 1.9487295150756836
Validation loss: 1.8662529837700628

Epoch: 6| Step: 7
Training loss: 1.7636325359344482
Validation loss: 1.8684179295775711

Epoch: 6| Step: 8
Training loss: 1.1371031999588013
Validation loss: 1.861152869398876

Epoch: 6| Step: 9
Training loss: 1.7945159673690796
Validation loss: 1.8888597616585352

Epoch: 6| Step: 10
Training loss: 1.7926548719406128
Validation loss: 1.8495175377015145

Epoch: 6| Step: 11
Training loss: 2.1355273723602295
Validation loss: 1.845498328567833

Epoch: 6| Step: 12
Training loss: 1.1228952407836914
Validation loss: 1.8831277021797754

Epoch: 6| Step: 13
Training loss: 1.0048377513885498
Validation loss: 1.8708380281284291

Epoch: 229| Step: 0
Training loss: 1.2661272287368774
Validation loss: 1.9285403502884733

Epoch: 6| Step: 1
Training loss: 1.9473108053207397
Validation loss: 1.9020544021360335

Epoch: 6| Step: 2
Training loss: 1.802058458328247
Validation loss: 1.9179450824696531

Epoch: 6| Step: 3
Training loss: 1.0392762422561646
Validation loss: 1.9544007239803192

Epoch: 6| Step: 4
Training loss: 1.3380520343780518
Validation loss: 1.914847368835121

Epoch: 6| Step: 5
Training loss: 1.217597246170044
Validation loss: 1.9294910917999923

Epoch: 6| Step: 6
Training loss: 1.9161819219589233
Validation loss: 1.9451256695614065

Epoch: 6| Step: 7
Training loss: 2.2427897453308105
Validation loss: 1.9160023197051017

Epoch: 6| Step: 8
Training loss: 1.3230305910110474
Validation loss: 1.8925364812215169

Epoch: 6| Step: 9
Training loss: 1.6414282321929932
Validation loss: 1.9184568082132647

Epoch: 6| Step: 10
Training loss: 2.5001180171966553
Validation loss: 1.8709989927148307

Epoch: 6| Step: 11
Training loss: 1.3947046995162964
Validation loss: 1.896556540202069

Epoch: 6| Step: 12
Training loss: 2.1673755645751953
Validation loss: 1.8776483997221916

Epoch: 6| Step: 13
Training loss: 1.7379125356674194
Validation loss: 1.936622909320298

Epoch: 230| Step: 0
Training loss: 1.2977871894836426
Validation loss: 1.861878159225628

Epoch: 6| Step: 1
Training loss: 1.5455485582351685
Validation loss: 1.8874645579245783

Epoch: 6| Step: 2
Training loss: 1.073126196861267
Validation loss: 1.8333691012474798

Epoch: 6| Step: 3
Training loss: 1.6571027040481567
Validation loss: 1.8553271960186701

Epoch: 6| Step: 4
Training loss: 1.3237245082855225
Validation loss: 1.8710765479713358

Epoch: 6| Step: 5
Training loss: 1.6691609621047974
Validation loss: 1.8964925453227053

Epoch: 6| Step: 6
Training loss: 1.0351731777191162
Validation loss: 1.8581582218088128

Epoch: 6| Step: 7
Training loss: 1.9366858005523682
Validation loss: 1.8788070717165548

Epoch: 6| Step: 8
Training loss: 2.473094940185547
Validation loss: 1.8917668532299738

Epoch: 6| Step: 9
Training loss: 2.056760311126709
Validation loss: 1.8567857921764415

Epoch: 6| Step: 10
Training loss: 2.0098066329956055
Validation loss: 1.9105004610553864

Epoch: 6| Step: 11
Training loss: 2.286076784133911
Validation loss: 1.850375303658106

Epoch: 6| Step: 12
Training loss: 1.6761531829833984
Validation loss: 1.903405757360561

Epoch: 6| Step: 13
Training loss: 1.4320114850997925
Validation loss: 1.8416027984311503

Epoch: 231| Step: 0
Training loss: 1.758181095123291
Validation loss: 1.8702891821502357

Epoch: 6| Step: 1
Training loss: 1.9626719951629639
Validation loss: 1.8738139085872199

Epoch: 6| Step: 2
Training loss: 1.5881320238113403
Validation loss: 1.8614498838301627

Epoch: 6| Step: 3
Training loss: 1.6992746591567993
Validation loss: 1.8800097947479577

Epoch: 6| Step: 4
Training loss: 1.4281928539276123
Validation loss: 1.861758360298731

Epoch: 6| Step: 5
Training loss: 1.5450079441070557
Validation loss: 1.843169484087216

Epoch: 6| Step: 6
Training loss: 1.193447470664978
Validation loss: 1.8731602648253083

Epoch: 6| Step: 7
Training loss: 1.788679838180542
Validation loss: 1.8904506493640203

Epoch: 6| Step: 8
Training loss: 2.457975387573242
Validation loss: 1.8664460182189941

Epoch: 6| Step: 9
Training loss: 1.2851512432098389
Validation loss: 1.9156488423706384

Epoch: 6| Step: 10
Training loss: 1.7295420169830322
Validation loss: 1.8702864147001697

Epoch: 6| Step: 11
Training loss: 1.497704267501831
Validation loss: 1.8571047680352324

Epoch: 6| Step: 12
Training loss: 1.896906852722168
Validation loss: 1.9137455109627015

Epoch: 6| Step: 13
Training loss: 1.3956998586654663
Validation loss: 1.8821880138048561

Epoch: 232| Step: 0
Training loss: 1.954934000968933
Validation loss: 1.8808722162759433

Epoch: 6| Step: 1
Training loss: 1.7990078926086426
Validation loss: 1.8691660422150806

Epoch: 6| Step: 2
Training loss: 1.8774609565734863
Validation loss: 1.8890247421879922

Epoch: 6| Step: 3
Training loss: 1.999633550643921
Validation loss: 1.8919337154716573

Epoch: 6| Step: 4
Training loss: 1.2408121824264526
Validation loss: 1.8814574569784186

Epoch: 6| Step: 5
Training loss: 1.9756038188934326
Validation loss: 1.8738826987563924

Epoch: 6| Step: 6
Training loss: 1.7539139986038208
Validation loss: 1.877129247111659

Epoch: 6| Step: 7
Training loss: 1.3305609226226807
Validation loss: 1.8718092108285556

Epoch: 6| Step: 8
Training loss: 1.5387554168701172
Validation loss: 1.9107655696971442

Epoch: 6| Step: 9
Training loss: 1.4463415145874023
Validation loss: 1.8882984179322437

Epoch: 6| Step: 10
Training loss: 1.6516602039337158
Validation loss: 1.8907965562676872

Epoch: 6| Step: 11
Training loss: 1.7952313423156738
Validation loss: 1.930474858130178

Epoch: 6| Step: 12
Training loss: 1.3398470878601074
Validation loss: 1.9368450205813172

Epoch: 6| Step: 13
Training loss: 1.9346245527267456
Validation loss: 1.907032238539829

Epoch: 233| Step: 0
Training loss: 2.6282153129577637
Validation loss: 1.8953588572881555

Epoch: 6| Step: 1
Training loss: 2.1803879737854004
Validation loss: 1.8732594892542849

Epoch: 6| Step: 2
Training loss: 1.7484955787658691
Validation loss: 1.837211101285873

Epoch: 6| Step: 3
Training loss: 1.6551082134246826
Validation loss: 1.8679966849665488

Epoch: 6| Step: 4
Training loss: 0.916498601436615
Validation loss: 1.9264178276062012

Epoch: 6| Step: 5
Training loss: 1.6307392120361328
Validation loss: 1.8750135975499307

Epoch: 6| Step: 6
Training loss: 2.1667909622192383
Validation loss: 1.8919946186004146

Epoch: 6| Step: 7
Training loss: 1.6736831665039062
Validation loss: 1.8890437938833748

Epoch: 6| Step: 8
Training loss: 1.5933992862701416
Validation loss: 1.836076767213883

Epoch: 6| Step: 9
Training loss: 1.6035618782043457
Validation loss: 1.8806902631636588

Epoch: 6| Step: 10
Training loss: 1.1405128240585327
Validation loss: 1.8866280009669643

Epoch: 6| Step: 11
Training loss: 1.0739437341690063
Validation loss: 1.8668868772445186

Epoch: 6| Step: 12
Training loss: 1.2432548999786377
Validation loss: 1.8807539273333806

Epoch: 6| Step: 13
Training loss: 1.9876954555511475
Validation loss: 1.8482789916376914

Epoch: 234| Step: 0
Training loss: 2.170609474182129
Validation loss: 1.8680359958320536

Epoch: 6| Step: 1
Training loss: 2.0113253593444824
Validation loss: 1.843168213803281

Epoch: 6| Step: 2
Training loss: 1.461264729499817
Validation loss: 1.8680728148388606

Epoch: 6| Step: 3
Training loss: 1.876556396484375
Validation loss: 1.872098938111336

Epoch: 6| Step: 4
Training loss: 1.844447374343872
Validation loss: 1.8869051779470136

Epoch: 6| Step: 5
Training loss: 1.4644596576690674
Validation loss: 1.8673315971128401

Epoch: 6| Step: 6
Training loss: 1.5471477508544922
Validation loss: 1.815399613431705

Epoch: 6| Step: 7
Training loss: 1.7602342367172241
Validation loss: 1.8728156705056467

Epoch: 6| Step: 8
Training loss: 1.7926726341247559
Validation loss: 1.85564435169261

Epoch: 6| Step: 9
Training loss: 1.8489198684692383
Validation loss: 1.8884852983618294

Epoch: 6| Step: 10
Training loss: 1.7453980445861816
Validation loss: 1.9153917976604995

Epoch: 6| Step: 11
Training loss: 1.6112087965011597
Validation loss: 1.895656894612056

Epoch: 6| Step: 12
Training loss: 1.2041563987731934
Validation loss: 1.8989650382790515

Epoch: 6| Step: 13
Training loss: 0.9888736009597778
Validation loss: 1.915284159362957

Epoch: 235| Step: 0
Training loss: 1.5574157238006592
Validation loss: 1.8913948382100751

Epoch: 6| Step: 1
Training loss: 2.211097240447998
Validation loss: 1.879864195341705

Epoch: 6| Step: 2
Training loss: 1.348294973373413
Validation loss: 1.8788478118117138

Epoch: 6| Step: 3
Training loss: 1.5540125370025635
Validation loss: 1.8989086561305548

Epoch: 6| Step: 4
Training loss: 1.5240066051483154
Validation loss: 1.9205078207036501

Epoch: 6| Step: 5
Training loss: 1.7997318506240845
Validation loss: 1.879558842669251

Epoch: 6| Step: 6
Training loss: 1.8138964176177979
Validation loss: 1.8766213719562819

Epoch: 6| Step: 7
Training loss: 1.7917683124542236
Validation loss: 1.8928485749870219

Epoch: 6| Step: 8
Training loss: 1.8790714740753174
Validation loss: 1.8866743221077868

Epoch: 6| Step: 9
Training loss: 2.621903419494629
Validation loss: 1.8554487113029725

Epoch: 6| Step: 10
Training loss: 1.016600251197815
Validation loss: 1.8730302279995334

Epoch: 6| Step: 11
Training loss: 1.1229891777038574
Validation loss: 1.8464468922666324

Epoch: 6| Step: 12
Training loss: 1.3671481609344482
Validation loss: 1.8639236803977721

Epoch: 6| Step: 13
Training loss: 1.2507084608078003
Validation loss: 1.8503943066443167

Epoch: 236| Step: 0
Training loss: 1.3831497430801392
Validation loss: 1.8667544472602107

Epoch: 6| Step: 1
Training loss: 1.162410020828247
Validation loss: 1.9088253385277205

Epoch: 6| Step: 2
Training loss: 1.1647411584854126
Validation loss: 1.8565040865252096

Epoch: 6| Step: 3
Training loss: 1.9393515586853027
Validation loss: 1.859520512242471

Epoch: 6| Step: 4
Training loss: 1.4536175727844238
Validation loss: 1.879258071222613

Epoch: 6| Step: 5
Training loss: 1.3206377029418945
Validation loss: 1.8399181853058517

Epoch: 6| Step: 6
Training loss: 2.2218987941741943
Validation loss: 1.8386171440924368

Epoch: 6| Step: 7
Training loss: 1.4896421432495117
Validation loss: 1.9362331513435609

Epoch: 6| Step: 8
Training loss: 1.9531490802764893
Validation loss: 1.9058492914322884

Epoch: 6| Step: 9
Training loss: 1.5192780494689941
Validation loss: 1.8849081018919587

Epoch: 6| Step: 10
Training loss: 1.916776180267334
Validation loss: 1.905480723227224

Epoch: 6| Step: 11
Training loss: 2.084185838699341
Validation loss: 1.8517011160491614

Epoch: 6| Step: 12
Training loss: 2.1830077171325684
Validation loss: 1.92374974296939

Epoch: 6| Step: 13
Training loss: 1.0335392951965332
Validation loss: 1.8876715834422777

Epoch: 237| Step: 0
Training loss: 1.5205707550048828
Validation loss: 1.9215750053364744

Epoch: 6| Step: 1
Training loss: 1.3379815816879272
Validation loss: 1.9096757596538914

Epoch: 6| Step: 2
Training loss: 1.4299986362457275
Validation loss: 1.9189696991315452

Epoch: 6| Step: 3
Training loss: 1.3669575452804565
Validation loss: 1.882429999689902

Epoch: 6| Step: 4
Training loss: 1.8485645055770874
Validation loss: 1.879667523086712

Epoch: 6| Step: 5
Training loss: 1.5557386875152588
Validation loss: 1.846496033412154

Epoch: 6| Step: 6
Training loss: 2.563584566116333
Validation loss: 1.8888909868014756

Epoch: 6| Step: 7
Training loss: 2.2567319869995117
Validation loss: 1.86364229776526

Epoch: 6| Step: 8
Training loss: 1.9029709100723267
Validation loss: 1.8979230106517833

Epoch: 6| Step: 9
Training loss: 1.5710415840148926
Validation loss: 1.8854005490579913

Epoch: 6| Step: 10
Training loss: 1.297025203704834
Validation loss: 1.9021024421979023

Epoch: 6| Step: 11
Training loss: 1.3222734928131104
Validation loss: 1.8580773607377084

Epoch: 6| Step: 12
Training loss: 1.969208002090454
Validation loss: 1.853641092136342

Epoch: 6| Step: 13
Training loss: 0.7765586376190186
Validation loss: 1.838155226040912

Epoch: 238| Step: 0
Training loss: 1.4436324834823608
Validation loss: 1.898465702610631

Epoch: 6| Step: 1
Training loss: 1.5186514854431152
Validation loss: 1.8429000070018153

Epoch: 6| Step: 2
Training loss: 2.0074315071105957
Validation loss: 1.8896234445674445

Epoch: 6| Step: 3
Training loss: 1.4907504320144653
Validation loss: 1.8495061871826008

Epoch: 6| Step: 4
Training loss: 1.5512516498565674
Validation loss: 1.8855292515088153

Epoch: 6| Step: 5
Training loss: 1.199756383895874
Validation loss: 1.886127701369665

Epoch: 6| Step: 6
Training loss: 1.641728401184082
Validation loss: 1.8601223089361703

Epoch: 6| Step: 7
Training loss: 1.515681266784668
Validation loss: 1.9031111988970029

Epoch: 6| Step: 8
Training loss: 1.689943790435791
Validation loss: 1.8582523176746983

Epoch: 6| Step: 9
Training loss: 1.8626708984375
Validation loss: 1.8624751349931121

Epoch: 6| Step: 10
Training loss: 1.2681643962860107
Validation loss: 1.8528517061664211

Epoch: 6| Step: 11
Training loss: 1.8663548231124878
Validation loss: 1.8727517115172518

Epoch: 6| Step: 12
Training loss: 2.1286611557006836
Validation loss: 1.8512846282733384

Epoch: 6| Step: 13
Training loss: 2.067232131958008
Validation loss: 1.8581352772251252

Epoch: 239| Step: 0
Training loss: 1.5125175714492798
Validation loss: 1.84623513555014

Epoch: 6| Step: 1
Training loss: 1.441737174987793
Validation loss: 1.861299430170367

Epoch: 6| Step: 2
Training loss: 1.6483118534088135
Validation loss: 1.882719979491285

Epoch: 6| Step: 3
Training loss: 1.616710901260376
Validation loss: 1.8368672273492301

Epoch: 6| Step: 4
Training loss: 0.9694871306419373
Validation loss: 1.8756321886534333

Epoch: 6| Step: 5
Training loss: 1.140064001083374
Validation loss: 1.8840252686572332

Epoch: 6| Step: 6
Training loss: 2.1801815032958984
Validation loss: 1.8997301632358181

Epoch: 6| Step: 7
Training loss: 1.633062481880188
Validation loss: 1.8787828389034475

Epoch: 6| Step: 8
Training loss: 1.4868797063827515
Validation loss: 1.9206504949959375

Epoch: 6| Step: 9
Training loss: 2.5055792331695557
Validation loss: 1.8880683504125124

Epoch: 6| Step: 10
Training loss: 1.2087491750717163
Validation loss: 1.8789030377582838

Epoch: 6| Step: 11
Training loss: 1.8978567123413086
Validation loss: 1.8550858830892911

Epoch: 6| Step: 12
Training loss: 1.463391900062561
Validation loss: 1.9005046249717794

Epoch: 6| Step: 13
Training loss: 2.1195333003997803
Validation loss: 1.892652173196116

Epoch: 240| Step: 0
Training loss: 1.2147812843322754
Validation loss: 1.874372620736399

Epoch: 6| Step: 1
Training loss: 2.0702743530273438
Validation loss: 1.8717534875357023

Epoch: 6| Step: 2
Training loss: 1.822096824645996
Validation loss: 1.895399305128282

Epoch: 6| Step: 3
Training loss: 1.9657446146011353
Validation loss: 1.8654812459022767

Epoch: 6| Step: 4
Training loss: 1.7880055904388428
Validation loss: 1.849798971606839

Epoch: 6| Step: 5
Training loss: 1.6160743236541748
Validation loss: 1.8814835599673692

Epoch: 6| Step: 6
Training loss: 1.971512794494629
Validation loss: 1.8765009218646633

Epoch: 6| Step: 7
Training loss: 1.0168026685714722
Validation loss: 1.826663447964576

Epoch: 6| Step: 8
Training loss: 1.4931718111038208
Validation loss: 1.8547877111742574

Epoch: 6| Step: 9
Training loss: 1.3034241199493408
Validation loss: 1.8703711686595794

Epoch: 6| Step: 10
Training loss: 1.9298808574676514
Validation loss: 1.8837281093802503

Epoch: 6| Step: 11
Training loss: 1.418534278869629
Validation loss: 1.8836924286298855

Epoch: 6| Step: 12
Training loss: 1.5332332849502563
Validation loss: 1.881036691768195

Epoch: 6| Step: 13
Training loss: 1.486614465713501
Validation loss: 1.8603580408198859

Epoch: 241| Step: 0
Training loss: 1.3299870491027832
Validation loss: 1.8552944326913485

Epoch: 6| Step: 1
Training loss: 1.4230663776397705
Validation loss: 1.859411358833313

Epoch: 6| Step: 2
Training loss: 1.6946296691894531
Validation loss: 1.8805996679490613

Epoch: 6| Step: 3
Training loss: 1.7751548290252686
Validation loss: 1.8843631705930155

Epoch: 6| Step: 4
Training loss: 1.5220452547073364
Validation loss: 1.8333552216970792

Epoch: 6| Step: 5
Training loss: 1.4034361839294434
Validation loss: 1.865677184956048

Epoch: 6| Step: 6
Training loss: 1.9763455390930176
Validation loss: 1.8987303164697462

Epoch: 6| Step: 7
Training loss: 1.10471510887146
Validation loss: 1.8481434519572923

Epoch: 6| Step: 8
Training loss: 1.1158514022827148
Validation loss: 1.8708616059313539

Epoch: 6| Step: 9
Training loss: 2.520233154296875
Validation loss: 1.886781008012833

Epoch: 6| Step: 10
Training loss: 1.5440189838409424
Validation loss: 1.8865318734158751

Epoch: 6| Step: 11
Training loss: 2.0025556087493896
Validation loss: 1.8661681208559262

Epoch: 6| Step: 12
Training loss: 1.754704236984253
Validation loss: 1.8712409375816264

Epoch: 6| Step: 13
Training loss: 1.7161189317703247
Validation loss: 1.921387949297505

Epoch: 242| Step: 0
Training loss: 1.3824435472488403
Validation loss: 1.8595373553614463

Epoch: 6| Step: 1
Training loss: 1.0178710222244263
Validation loss: 1.888742123880694

Epoch: 6| Step: 2
Training loss: 1.6730265617370605
Validation loss: 1.9067273293772051

Epoch: 6| Step: 3
Training loss: 2.3797006607055664
Validation loss: 1.940709057674613

Epoch: 6| Step: 4
Training loss: 1.1009886264801025
Validation loss: 1.9565632984202395

Epoch: 6| Step: 5
Training loss: 1.5336096286773682
Validation loss: 1.9201129867184548

Epoch: 6| Step: 6
Training loss: 1.263117790222168
Validation loss: 1.918964179613257

Epoch: 6| Step: 7
Training loss: 1.4206384420394897
Validation loss: 1.8759419277150144

Epoch: 6| Step: 8
Training loss: 1.8009153604507446
Validation loss: 1.8819239088284072

Epoch: 6| Step: 9
Training loss: 2.2163939476013184
Validation loss: 1.8856267544531053

Epoch: 6| Step: 10
Training loss: 2.2377278804779053
Validation loss: 1.8381858089918732

Epoch: 6| Step: 11
Training loss: 2.2835166454315186
Validation loss: 1.8561334174166444

Epoch: 6| Step: 12
Training loss: 1.0927425622940063
Validation loss: 1.8718471155371716

Epoch: 6| Step: 13
Training loss: 2.033623218536377
Validation loss: 1.894163481650814

Epoch: 243| Step: 0
Training loss: 1.821944236755371
Validation loss: 1.8478460337526055

Epoch: 6| Step: 1
Training loss: 1.757908582687378
Validation loss: 1.8816103319967947

Epoch: 6| Step: 2
Training loss: 1.3898510932922363
Validation loss: 1.8565347925309212

Epoch: 6| Step: 3
Training loss: 1.2860174179077148
Validation loss: 1.8161082703580138

Epoch: 6| Step: 4
Training loss: 1.2450048923492432
Validation loss: 1.7991543290435628

Epoch: 6| Step: 5
Training loss: 1.9761199951171875
Validation loss: 1.8174283427576865

Epoch: 6| Step: 6
Training loss: 1.321037769317627
Validation loss: 1.8417632938713155

Epoch: 6| Step: 7
Training loss: 2.0955920219421387
Validation loss: 1.8479542398965487

Epoch: 6| Step: 8
Training loss: 1.390549659729004
Validation loss: 1.8809309159555743

Epoch: 6| Step: 9
Training loss: 0.8626267313957214
Validation loss: 1.8811155954996746

Epoch: 6| Step: 10
Training loss: 1.5447616577148438
Validation loss: 1.9359379019788516

Epoch: 6| Step: 11
Training loss: 1.6024560928344727
Validation loss: 1.8822450073816444

Epoch: 6| Step: 12
Training loss: 2.183609962463379
Validation loss: 1.8825583445128573

Epoch: 6| Step: 13
Training loss: 2.1844406127929688
Validation loss: 1.8764490773600917

Epoch: 244| Step: 0
Training loss: 1.7571656703948975
Validation loss: 1.884785525260433

Epoch: 6| Step: 1
Training loss: 0.9873794317245483
Validation loss: 1.8628295929201188

Epoch: 6| Step: 2
Training loss: 0.9505711197853088
Validation loss: 1.848450900405966

Epoch: 6| Step: 3
Training loss: 1.9229047298431396
Validation loss: 1.8994984216587518

Epoch: 6| Step: 4
Training loss: 1.6643409729003906
Validation loss: 1.9127682549979097

Epoch: 6| Step: 5
Training loss: 1.6092673540115356
Validation loss: 1.8789632525495303

Epoch: 6| Step: 6
Training loss: 1.1046364307403564
Validation loss: 1.8548420347193235

Epoch: 6| Step: 7
Training loss: 1.0974888801574707
Validation loss: 1.8862155252887356

Epoch: 6| Step: 8
Training loss: 2.3907814025878906
Validation loss: 1.8836073516517557

Epoch: 6| Step: 9
Training loss: 1.897200345993042
Validation loss: 1.8637813855242986

Epoch: 6| Step: 10
Training loss: 1.7011445760726929
Validation loss: 1.8949303242468065

Epoch: 6| Step: 11
Training loss: 2.1571245193481445
Validation loss: 1.8877120607642717

Epoch: 6| Step: 12
Training loss: 1.4740827083587646
Validation loss: 1.8194532830228087

Epoch: 6| Step: 13
Training loss: 3.1340694427490234
Validation loss: 1.8650280878108034

Epoch: 245| Step: 0
Training loss: 1.8898372650146484
Validation loss: 1.8691566759540188

Epoch: 6| Step: 1
Training loss: 1.3278467655181885
Validation loss: 1.8718851074095695

Epoch: 6| Step: 2
Training loss: 2.129720449447632
Validation loss: 1.8769290485689718

Epoch: 6| Step: 3
Training loss: 2.0236735343933105
Validation loss: 1.8869536551096107

Epoch: 6| Step: 4
Training loss: 1.3716495037078857
Validation loss: 1.887202411569575

Epoch: 6| Step: 5
Training loss: 1.1275460720062256
Validation loss: 1.9295658860155331

Epoch: 6| Step: 6
Training loss: 2.157979726791382
Validation loss: 1.9488486141286872

Epoch: 6| Step: 7
Training loss: 1.367638349533081
Validation loss: 1.9203941860506613

Epoch: 6| Step: 8
Training loss: 2.0055527687072754
Validation loss: 1.8941363455146871

Epoch: 6| Step: 9
Training loss: 2.3697116374969482
Validation loss: 1.8964919005670855

Epoch: 6| Step: 10
Training loss: 1.115078091621399
Validation loss: 1.924553309717486

Epoch: 6| Step: 11
Training loss: 1.6809202432632446
Validation loss: 1.9006482683202273

Epoch: 6| Step: 12
Training loss: 1.1924265623092651
Validation loss: 1.8699753925364504

Epoch: 6| Step: 13
Training loss: 1.2575595378875732
Validation loss: 1.8714796458521197

Epoch: 246| Step: 0
Training loss: 1.5076651573181152
Validation loss: 1.8682558549347745

Epoch: 6| Step: 1
Training loss: 1.5420949459075928
Validation loss: 1.8529927858742334

Epoch: 6| Step: 2
Training loss: 2.3964216709136963
Validation loss: 1.8363269157307123

Epoch: 6| Step: 3
Training loss: 1.7606428861618042
Validation loss: 1.8800420056107223

Epoch: 6| Step: 4
Training loss: 1.858489751815796
Validation loss: 1.834813933218679

Epoch: 6| Step: 5
Training loss: 1.8244364261627197
Validation loss: 1.827981246415005

Epoch: 6| Step: 6
Training loss: 0.9035643339157104
Validation loss: 1.8482783738002981

Epoch: 6| Step: 7
Training loss: 1.8455417156219482
Validation loss: 1.8703757063035042

Epoch: 6| Step: 8
Training loss: 1.5523840188980103
Validation loss: 1.8870367196298414

Epoch: 6| Step: 9
Training loss: 1.728963851928711
Validation loss: 1.8531533928327664

Epoch: 6| Step: 10
Training loss: 2.008547782897949
Validation loss: 1.8644194679875528

Epoch: 6| Step: 11
Training loss: 1.582749843597412
Validation loss: 1.8539406458536785

Epoch: 6| Step: 12
Training loss: 1.1902835369110107
Validation loss: 1.8790838949141964

Epoch: 6| Step: 13
Training loss: 1.0011667013168335
Validation loss: 1.8433555403063375

Epoch: 247| Step: 0
Training loss: 1.0153203010559082
Validation loss: 1.8343551735724173

Epoch: 6| Step: 1
Training loss: 1.8426721096038818
Validation loss: 1.8703281815334032

Epoch: 6| Step: 2
Training loss: 1.5252103805541992
Validation loss: 1.8533474053106

Epoch: 6| Step: 3
Training loss: 1.4855430126190186
Validation loss: 1.8615699891121156

Epoch: 6| Step: 4
Training loss: 2.4466121196746826
Validation loss: 1.8587833040504045

Epoch: 6| Step: 5
Training loss: 1.6696652173995972
Validation loss: 1.8536424662477227

Epoch: 6| Step: 6
Training loss: 1.9874687194824219
Validation loss: 1.8451222706866521

Epoch: 6| Step: 7
Training loss: 1.595900297164917
Validation loss: 1.834914558677263

Epoch: 6| Step: 8
Training loss: 1.3246225118637085
Validation loss: 1.868587456082785

Epoch: 6| Step: 9
Training loss: 1.6348788738250732
Validation loss: 1.8806741904186945

Epoch: 6| Step: 10
Training loss: 1.4706236124038696
Validation loss: 1.8564149077220629

Epoch: 6| Step: 11
Training loss: 2.128401756286621
Validation loss: 1.880280299853253

Epoch: 6| Step: 12
Training loss: 1.0906025171279907
Validation loss: 1.916183558843469

Epoch: 6| Step: 13
Training loss: 1.7284995317459106
Validation loss: 1.870082462987592

Epoch: 248| Step: 0
Training loss: 1.1369283199310303
Validation loss: 1.8900836013978528

Epoch: 6| Step: 1
Training loss: 1.5862425565719604
Validation loss: 1.8664743156843289

Epoch: 6| Step: 2
Training loss: 1.701934576034546
Validation loss: 1.8901568779381372

Epoch: 6| Step: 3
Training loss: 1.782221794128418
Validation loss: 1.8796567737415273

Epoch: 6| Step: 4
Training loss: 1.8894360065460205
Validation loss: 1.9080534711960824

Epoch: 6| Step: 5
Training loss: 1.6094636917114258
Validation loss: 1.8484409432257376

Epoch: 6| Step: 6
Training loss: 1.7611815929412842
Validation loss: 1.8197895096194359

Epoch: 6| Step: 7
Training loss: 1.7218713760375977
Validation loss: 1.8935785588397775

Epoch: 6| Step: 8
Training loss: 1.3469669818878174
Validation loss: 1.8981434119644987

Epoch: 6| Step: 9
Training loss: 1.3872599601745605
Validation loss: 1.809250703421972

Epoch: 6| Step: 10
Training loss: 1.7673983573913574
Validation loss: 1.8425976178979362

Epoch: 6| Step: 11
Training loss: 1.262892723083496
Validation loss: 1.8487656552304503

Epoch: 6| Step: 12
Training loss: 2.257561683654785
Validation loss: 1.821001261793157

Epoch: 6| Step: 13
Training loss: 1.3032474517822266
Validation loss: 1.8760658566669752

Epoch: 249| Step: 0
Training loss: 1.4460372924804688
Validation loss: 1.8675525457628313

Epoch: 6| Step: 1
Training loss: 1.4957784414291382
Validation loss: 1.8778018477142497

Epoch: 6| Step: 2
Training loss: 1.2836170196533203
Validation loss: 1.8738368608618294

Epoch: 6| Step: 3
Training loss: 1.875091314315796
Validation loss: 1.855711055058305

Epoch: 6| Step: 4
Training loss: 1.5035488605499268
Validation loss: 1.8913164702794885

Epoch: 6| Step: 5
Training loss: 1.8672475814819336
Validation loss: 1.8229199635085238

Epoch: 6| Step: 6
Training loss: 1.600149154663086
Validation loss: 1.8510931473906322

Epoch: 6| Step: 7
Training loss: 1.913002371788025
Validation loss: 1.8852520476105392

Epoch: 6| Step: 8
Training loss: 1.4603792428970337
Validation loss: 1.8270785770108622

Epoch: 6| Step: 9
Training loss: 1.8419818878173828
Validation loss: 1.8420829260221092

Epoch: 6| Step: 10
Training loss: 1.7577917575836182
Validation loss: 1.8702726979409494

Epoch: 6| Step: 11
Training loss: 0.9641353487968445
Validation loss: 1.8547230946120394

Epoch: 6| Step: 12
Training loss: 1.8798872232437134
Validation loss: 1.8422565780660158

Epoch: 6| Step: 13
Training loss: 2.1850152015686035
Validation loss: 1.8871572697034447

Epoch: 250| Step: 0
Training loss: 1.749833583831787
Validation loss: 1.860750359873618

Epoch: 6| Step: 1
Training loss: 0.9597691297531128
Validation loss: 1.865547037893726

Epoch: 6| Step: 2
Training loss: 1.4140222072601318
Validation loss: 1.8795465410396617

Epoch: 6| Step: 3
Training loss: 2.229645252227783
Validation loss: 1.8623043619176394

Epoch: 6| Step: 4
Training loss: 0.9536291360855103
Validation loss: 1.8402563987239715

Epoch: 6| Step: 5
Training loss: 1.7777233123779297
Validation loss: 1.8552233070455573

Epoch: 6| Step: 6
Training loss: 1.4029911756515503
Validation loss: 1.8473131079827585

Epoch: 6| Step: 7
Training loss: 1.7034220695495605
Validation loss: 1.8682741913744199

Epoch: 6| Step: 8
Training loss: 1.840214729309082
Validation loss: 1.8302190688348585

Epoch: 6| Step: 9
Training loss: 1.3214666843414307
Validation loss: 1.8820081859506586

Epoch: 6| Step: 10
Training loss: 1.7720131874084473
Validation loss: 1.8632049304182812

Epoch: 6| Step: 11
Training loss: 2.1126787662506104
Validation loss: 1.8461187116561397

Epoch: 6| Step: 12
Training loss: 1.9368470907211304
Validation loss: 1.9002391048656997

Epoch: 6| Step: 13
Training loss: 1.0904979705810547
Validation loss: 1.8691389560699463

Epoch: 251| Step: 0
Training loss: 1.488386869430542
Validation loss: 1.8948971122823737

Epoch: 6| Step: 1
Training loss: 1.896662950515747
Validation loss: 1.8795219288077405

Epoch: 6| Step: 2
Training loss: 1.2253108024597168
Validation loss: 1.8708051199554114

Epoch: 6| Step: 3
Training loss: 1.320528268814087
Validation loss: 1.8599731178693875

Epoch: 6| Step: 4
Training loss: 1.4252041578292847
Validation loss: 1.9073561314613587

Epoch: 6| Step: 5
Training loss: 1.7365138530731201
Validation loss: 1.8667693215031778

Epoch: 6| Step: 6
Training loss: 1.3355497121810913
Validation loss: 1.8475847577535978

Epoch: 6| Step: 7
Training loss: 1.508191466331482
Validation loss: 1.8522311820778796

Epoch: 6| Step: 8
Training loss: 1.577869176864624
Validation loss: 1.8832723632935555

Epoch: 6| Step: 9
Training loss: 1.6558732986450195
Validation loss: 1.8678684362801172

Epoch: 6| Step: 10
Training loss: 2.0693655014038086
Validation loss: 1.8837527280212731

Epoch: 6| Step: 11
Training loss: 1.33733069896698
Validation loss: 1.804818146972246

Epoch: 6| Step: 12
Training loss: 1.8201675415039062
Validation loss: 1.8790472476713118

Epoch: 6| Step: 13
Training loss: 2.1986334323883057
Validation loss: 1.859680183472172

Epoch: 252| Step: 0
Training loss: 1.9401781558990479
Validation loss: 1.877299706141154

Epoch: 6| Step: 1
Training loss: 1.782196283340454
Validation loss: 1.8238076215149255

Epoch: 6| Step: 2
Training loss: 1.865230679512024
Validation loss: 1.862963996907716

Epoch: 6| Step: 3
Training loss: 2.2397944927215576
Validation loss: 1.8477895208584365

Epoch: 6| Step: 4
Training loss: 1.1047452688217163
Validation loss: 1.8570777703357

Epoch: 6| Step: 5
Training loss: 1.3812158107757568
Validation loss: 1.8870581324382494

Epoch: 6| Step: 6
Training loss: 1.0619137287139893
Validation loss: 1.8218524840570265

Epoch: 6| Step: 7
Training loss: 1.8759324550628662
Validation loss: 1.8720434609279837

Epoch: 6| Step: 8
Training loss: 1.24369478225708
Validation loss: 1.8208769136859524

Epoch: 6| Step: 9
Training loss: 1.4480035305023193
Validation loss: 1.878767623696276

Epoch: 6| Step: 10
Training loss: 1.402134895324707
Validation loss: 1.8799934899935158

Epoch: 6| Step: 11
Training loss: 1.9817140102386475
Validation loss: 1.89391448420863

Epoch: 6| Step: 12
Training loss: 1.7315222024917603
Validation loss: 1.9026106006355696

Epoch: 6| Step: 13
Training loss: 2.2986080646514893
Validation loss: 1.8907361735579788

Epoch: 253| Step: 0
Training loss: 1.7607735395431519
Validation loss: 1.891759757072695

Epoch: 6| Step: 1
Training loss: 1.4924402236938477
Validation loss: 1.9395548771786433

Epoch: 6| Step: 2
Training loss: 1.9802830219268799
Validation loss: 1.90648284522436

Epoch: 6| Step: 3
Training loss: 1.5083969831466675
Validation loss: 1.9367803732554119

Epoch: 6| Step: 4
Training loss: 1.3902082443237305
Validation loss: 1.9143859442844187

Epoch: 6| Step: 5
Training loss: 1.646437168121338
Validation loss: 1.8786557707735287

Epoch: 6| Step: 6
Training loss: 2.177456855773926
Validation loss: 1.8610807887969478

Epoch: 6| Step: 7
Training loss: 1.5618840456008911
Validation loss: 1.909737310101909

Epoch: 6| Step: 8
Training loss: 1.3184020519256592
Validation loss: 1.8592350277849423

Epoch: 6| Step: 9
Training loss: 1.4304020404815674
Validation loss: 1.850320480203116

Epoch: 6| Step: 10
Training loss: 1.632508635520935
Validation loss: 1.8455800971677225

Epoch: 6| Step: 11
Training loss: 1.5364099740982056
Validation loss: 1.8559948936585458

Epoch: 6| Step: 12
Training loss: 1.8840222358703613
Validation loss: 1.8525522524310696

Epoch: 6| Step: 13
Training loss: 1.8334674835205078
Validation loss: 1.857395823283862

Epoch: 254| Step: 0
Training loss: 1.5825223922729492
Validation loss: 1.8901821938894128

Epoch: 6| Step: 1
Training loss: 1.2383877038955688
Validation loss: 1.8371685256240189

Epoch: 6| Step: 2
Training loss: 1.8169984817504883
Validation loss: 1.897741577958548

Epoch: 6| Step: 3
Training loss: 2.251866579055786
Validation loss: 1.8481773740501815

Epoch: 6| Step: 4
Training loss: 2.024339199066162
Validation loss: 1.9134756262584398

Epoch: 6| Step: 5
Training loss: 1.6461182832717896
Validation loss: 1.9131590089490336

Epoch: 6| Step: 6
Training loss: 1.2078769207000732
Validation loss: 1.909857674311566

Epoch: 6| Step: 7
Training loss: 1.0253725051879883
Validation loss: 1.882389646704479

Epoch: 6| Step: 8
Training loss: 1.4322340488433838
Validation loss: 1.8853076965578142

Epoch: 6| Step: 9
Training loss: 1.7607085704803467
Validation loss: 1.8429939977584346

Epoch: 6| Step: 10
Training loss: 1.7356468439102173
Validation loss: 1.8624699308026222

Epoch: 6| Step: 11
Training loss: 1.94475257396698
Validation loss: 1.9030452197597874

Epoch: 6| Step: 12
Training loss: 1.2270463705062866
Validation loss: 1.8786666777826124

Epoch: 6| Step: 13
Training loss: 0.9493653774261475
Validation loss: 1.8313878326005832

Epoch: 255| Step: 0
Training loss: 1.4337232112884521
Validation loss: 1.8788979168861144

Epoch: 6| Step: 1
Training loss: 1.9328058958053589
Validation loss: 1.8804292883924258

Epoch: 6| Step: 2
Training loss: 1.2278716564178467
Validation loss: 1.8591691832388602

Epoch: 6| Step: 3
Training loss: 2.371029853820801
Validation loss: 1.8376100960598196

Epoch: 6| Step: 4
Training loss: 1.4182811975479126
Validation loss: 1.816307681863026

Epoch: 6| Step: 5
Training loss: 1.0846357345581055
Validation loss: 1.838226423468641

Epoch: 6| Step: 6
Training loss: 1.2254775762557983
Validation loss: 1.843085773529545

Epoch: 6| Step: 7
Training loss: 1.324070692062378
Validation loss: 1.8214996425054406

Epoch: 6| Step: 8
Training loss: 2.1760356426239014
Validation loss: 1.8427027399821947

Epoch: 6| Step: 9
Training loss: 2.5108020305633545
Validation loss: 1.83600006821335

Epoch: 6| Step: 10
Training loss: 1.2178627252578735
Validation loss: 1.8741192561323925

Epoch: 6| Step: 11
Training loss: 0.9831286668777466
Validation loss: 1.8898345424282936

Epoch: 6| Step: 12
Training loss: 1.8000552654266357
Validation loss: 1.8676017304902435

Epoch: 6| Step: 13
Training loss: 2.1753406524658203
Validation loss: 1.8659398478846396

Epoch: 256| Step: 0
Training loss: 1.75604248046875
Validation loss: 1.9339452764039398

Epoch: 6| Step: 1
Training loss: 1.6750962734222412
Validation loss: 1.8940930892062444

Epoch: 6| Step: 2
Training loss: 1.7072815895080566
Validation loss: 1.9106657556308213

Epoch: 6| Step: 3
Training loss: 1.5528382062911987
Validation loss: 1.8708414005976852

Epoch: 6| Step: 4
Training loss: 1.866228699684143
Validation loss: 1.9081718473024265

Epoch: 6| Step: 5
Training loss: 1.6644259691238403
Validation loss: 1.9096706374999015

Epoch: 6| Step: 6
Training loss: 2.1881024837493896
Validation loss: 1.9476099603919572

Epoch: 6| Step: 7
Training loss: 1.2165793180465698
Validation loss: 1.88448578311551

Epoch: 6| Step: 8
Training loss: 1.4369208812713623
Validation loss: 1.8680589481066632

Epoch: 6| Step: 9
Training loss: 1.9107275009155273
Validation loss: 1.8519419111231321

Epoch: 6| Step: 10
Training loss: 1.4500974416732788
Validation loss: 1.8680680233945128

Epoch: 6| Step: 11
Training loss: 1.3260973691940308
Validation loss: 1.8504327292083411

Epoch: 6| Step: 12
Training loss: 1.4162423610687256
Validation loss: 1.8550694270800518

Epoch: 6| Step: 13
Training loss: 1.1796284914016724
Validation loss: 1.8683051011895622

Epoch: 257| Step: 0
Training loss: 1.4598796367645264
Validation loss: 1.8469619289521249

Epoch: 6| Step: 1
Training loss: 1.6603028774261475
Validation loss: 1.8561381011880853

Epoch: 6| Step: 2
Training loss: 1.2263646125793457
Validation loss: 1.816271629384769

Epoch: 6| Step: 3
Training loss: 0.7115536332130432
Validation loss: 1.8626396245853876

Epoch: 6| Step: 4
Training loss: 1.8338046073913574
Validation loss: 1.8631147966589978

Epoch: 6| Step: 5
Training loss: 2.019514560699463
Validation loss: 1.8144638384542158

Epoch: 6| Step: 6
Training loss: 1.5855958461761475
Validation loss: 1.8950230152376237

Epoch: 6| Step: 7
Training loss: 1.930598258972168
Validation loss: 1.8523670140133108

Epoch: 6| Step: 8
Training loss: 1.8267874717712402
Validation loss: 1.836739924646193

Epoch: 6| Step: 9
Training loss: 1.7025370597839355
Validation loss: 1.860705014198057

Epoch: 6| Step: 10
Training loss: 1.0221407413482666
Validation loss: 1.8055299776856617

Epoch: 6| Step: 11
Training loss: 1.6566613912582397
Validation loss: 1.8505422953636415

Epoch: 6| Step: 12
Training loss: 2.094973564147949
Validation loss: 1.8231652411081458

Epoch: 6| Step: 13
Training loss: 1.7982845306396484
Validation loss: 1.8498148713060605

Epoch: 258| Step: 0
Training loss: 0.9150277376174927
Validation loss: 1.8711612532215733

Epoch: 6| Step: 1
Training loss: 1.7160260677337646
Validation loss: 1.8126539543110838

Epoch: 6| Step: 2
Training loss: 1.8832275867462158
Validation loss: 1.8790702127641248

Epoch: 6| Step: 3
Training loss: 1.5876123905181885
Validation loss: 1.8921587262102353

Epoch: 6| Step: 4
Training loss: 1.1397035121917725
Validation loss: 1.8868629112038562

Epoch: 6| Step: 5
Training loss: 1.9648149013519287
Validation loss: 1.8488513538914342

Epoch: 6| Step: 6
Training loss: 1.501586675643921
Validation loss: 1.8349356497487714

Epoch: 6| Step: 7
Training loss: 1.9181773662567139
Validation loss: 1.8829533617983583

Epoch: 6| Step: 8
Training loss: 1.7609517574310303
Validation loss: 1.8929373961622997

Epoch: 6| Step: 9
Training loss: 1.4486202001571655
Validation loss: 1.903012647423693

Epoch: 6| Step: 10
Training loss: 1.5940805673599243
Validation loss: 1.8694262914760138

Epoch: 6| Step: 11
Training loss: 1.5178873538970947
Validation loss: 1.8364880610537786

Epoch: 6| Step: 12
Training loss: 1.8912394046783447
Validation loss: 1.897074027728009

Epoch: 6| Step: 13
Training loss: 1.1709542274475098
Validation loss: 1.8502273405751875

Epoch: 259| Step: 0
Training loss: 1.5036877393722534
Validation loss: 1.8830348381432154

Epoch: 6| Step: 1
Training loss: 1.5024888515472412
Validation loss: 1.8343220423626643

Epoch: 6| Step: 2
Training loss: 1.2324910163879395
Validation loss: 1.8380421233433548

Epoch: 6| Step: 3
Training loss: 1.6397078037261963
Validation loss: 1.8507899404853903

Epoch: 6| Step: 4
Training loss: 1.2614285945892334
Validation loss: 1.8541171819933

Epoch: 6| Step: 5
Training loss: 1.279602289199829
Validation loss: 1.8719372646782988

Epoch: 6| Step: 6
Training loss: 1.3149263858795166
Validation loss: 1.8294826284531625

Epoch: 6| Step: 7
Training loss: 1.3654651641845703
Validation loss: 1.7913377605458742

Epoch: 6| Step: 8
Training loss: 1.8419060707092285
Validation loss: 1.8226570634431736

Epoch: 6| Step: 9
Training loss: 2.315365791320801
Validation loss: 1.7871359625170309

Epoch: 6| Step: 10
Training loss: 1.8520002365112305
Validation loss: 1.8272373189208329

Epoch: 6| Step: 11
Training loss: 2.142615795135498
Validation loss: 1.8834343135997813

Epoch: 6| Step: 12
Training loss: 1.3954198360443115
Validation loss: 1.8202561947607225

Epoch: 6| Step: 13
Training loss: 1.5374794006347656
Validation loss: 1.8117264573292067

Epoch: 260| Step: 0
Training loss: 1.9648226499557495
Validation loss: 1.8908533973078574

Epoch: 6| Step: 1
Training loss: 1.3862829208374023
Validation loss: 1.8586173467738654

Epoch: 6| Step: 2
Training loss: 2.151402473449707
Validation loss: 1.8395026960680563

Epoch: 6| Step: 3
Training loss: 1.5668543577194214
Validation loss: 1.8592861480610345

Epoch: 6| Step: 4
Training loss: 1.1349687576293945
Validation loss: 1.8432288387770295

Epoch: 6| Step: 5
Training loss: 2.947873830795288
Validation loss: 1.798643978693152

Epoch: 6| Step: 6
Training loss: 1.0809165239334106
Validation loss: 1.8328308046505015

Epoch: 6| Step: 7
Training loss: 1.6247397661209106
Validation loss: 1.8517173208216184

Epoch: 6| Step: 8
Training loss: 1.4626115560531616
Validation loss: 1.8846055794787664

Epoch: 6| Step: 9
Training loss: 1.027688980102539
Validation loss: 1.811983807112581

Epoch: 6| Step: 10
Training loss: 1.0768712759017944
Validation loss: 1.8219251991600118

Epoch: 6| Step: 11
Training loss: 1.6552406549453735
Validation loss: 1.888008347121618

Epoch: 6| Step: 12
Training loss: 1.5699082612991333
Validation loss: 1.84757004245635

Epoch: 6| Step: 13
Training loss: 1.5350432395935059
Validation loss: 1.832787908533568

Epoch: 261| Step: 0
Training loss: 1.9858200550079346
Validation loss: 1.8626313529988772

Epoch: 6| Step: 1
Training loss: 2.101975679397583
Validation loss: 1.878293429651568

Epoch: 6| Step: 2
Training loss: 1.2979028224945068
Validation loss: 1.8531773064726142

Epoch: 6| Step: 3
Training loss: 2.782853603363037
Validation loss: 1.8855640247303953

Epoch: 6| Step: 4
Training loss: 1.818904161453247
Validation loss: 1.824426176727459

Epoch: 6| Step: 5
Training loss: 1.6356273889541626
Validation loss: 1.8383957596235379

Epoch: 6| Step: 6
Training loss: 1.5493426322937012
Validation loss: 1.891611099243164

Epoch: 6| Step: 7
Training loss: 1.1077210903167725
Validation loss: 1.7852014649298884

Epoch: 6| Step: 8
Training loss: 1.0579595565795898
Validation loss: 1.8435279412936139

Epoch: 6| Step: 9
Training loss: 1.6394398212432861
Validation loss: 1.8812495252137542

Epoch: 6| Step: 10
Training loss: 1.2179479598999023
Validation loss: 1.8310149818338373

Epoch: 6| Step: 11
Training loss: 1.3853964805603027
Validation loss: 1.8656441960283505

Epoch: 6| Step: 12
Training loss: 1.1016192436218262
Validation loss: 1.8409718185342767

Epoch: 6| Step: 13
Training loss: 0.6729046702384949
Validation loss: 1.8717156533272035

Epoch: 262| Step: 0
Training loss: 1.713761806488037
Validation loss: 1.8524143247194187

Epoch: 6| Step: 1
Training loss: 1.4205660820007324
Validation loss: 1.8477226124014905

Epoch: 6| Step: 2
Training loss: 1.2829493284225464
Validation loss: 1.855741544436383

Epoch: 6| Step: 3
Training loss: 0.8211849927902222
Validation loss: 1.8901950723381453

Epoch: 6| Step: 4
Training loss: 1.7817604541778564
Validation loss: 1.86273362816021

Epoch: 6| Step: 5
Training loss: 1.9533685445785522
Validation loss: 1.8978570712509977

Epoch: 6| Step: 6
Training loss: 1.6731600761413574
Validation loss: 1.9212434343112412

Epoch: 6| Step: 7
Training loss: 1.9304312467575073
Validation loss: 1.9241363963773173

Epoch: 6| Step: 8
Training loss: 1.2605772018432617
Validation loss: 1.9237446720882128

Epoch: 6| Step: 9
Training loss: 1.7001558542251587
Validation loss: 1.918626977551368

Epoch: 6| Step: 10
Training loss: 1.5647082328796387
Validation loss: 1.8892970931145452

Epoch: 6| Step: 11
Training loss: 1.9496086835861206
Validation loss: 1.8592198638505832

Epoch: 6| Step: 12
Training loss: 1.4708800315856934
Validation loss: 1.842865059452672

Epoch: 6| Step: 13
Training loss: 1.6439974308013916
Validation loss: 1.87698196852079

Epoch: 263| Step: 0
Training loss: 1.7380445003509521
Validation loss: 1.8590259539183749

Epoch: 6| Step: 1
Training loss: 1.8825273513793945
Validation loss: 1.8536437096134308

Epoch: 6| Step: 2
Training loss: 1.191756248474121
Validation loss: 1.8010320637815742

Epoch: 6| Step: 3
Training loss: 1.564823865890503
Validation loss: 1.8230282760435534

Epoch: 6| Step: 4
Training loss: 1.3375890254974365
Validation loss: 1.805750944281137

Epoch: 6| Step: 5
Training loss: 1.322279691696167
Validation loss: 1.8593100053007885

Epoch: 6| Step: 6
Training loss: 1.6422677040100098
Validation loss: 1.8534726519738474

Epoch: 6| Step: 7
Training loss: 1.6176563501358032
Validation loss: 1.8819646630235898

Epoch: 6| Step: 8
Training loss: 1.8199543952941895
Validation loss: 1.8601617326018631

Epoch: 6| Step: 9
Training loss: 1.5770026445388794
Validation loss: 1.8007098244082542

Epoch: 6| Step: 10
Training loss: 1.4629825353622437
Validation loss: 1.829705225524082

Epoch: 6| Step: 11
Training loss: 1.658705711364746
Validation loss: 1.863070463621488

Epoch: 6| Step: 12
Training loss: 1.869877815246582
Validation loss: 1.8492858512427217

Epoch: 6| Step: 13
Training loss: 1.8552651405334473
Validation loss: 1.850942555294242

Epoch: 264| Step: 0
Training loss: 1.50887930393219
Validation loss: 1.9033189781250492

Epoch: 6| Step: 1
Training loss: 1.7772109508514404
Validation loss: 1.8325331762272825

Epoch: 6| Step: 2
Training loss: 1.2714722156524658
Validation loss: 1.899057880524666

Epoch: 6| Step: 3
Training loss: 1.0590629577636719
Validation loss: 1.8567833746633222

Epoch: 6| Step: 4
Training loss: 2.03281831741333
Validation loss: 1.8855740178015925

Epoch: 6| Step: 5
Training loss: 1.5426905155181885
Validation loss: 1.8746568208099694

Epoch: 6| Step: 6
Training loss: 1.4226715564727783
Validation loss: 1.871883366697578

Epoch: 6| Step: 7
Training loss: 1.118011713027954
Validation loss: 1.8890333201295586

Epoch: 6| Step: 8
Training loss: 1.518568992614746
Validation loss: 1.8291980938244892

Epoch: 6| Step: 9
Training loss: 1.9526164531707764
Validation loss: 1.8716740979943225

Epoch: 6| Step: 10
Training loss: 0.7916663885116577
Validation loss: 1.8326186249333043

Epoch: 6| Step: 11
Training loss: 1.7699542045593262
Validation loss: 1.8405918305920017

Epoch: 6| Step: 12
Training loss: 1.739678144454956
Validation loss: 1.8345977337129655

Epoch: 6| Step: 13
Training loss: 2.439990520477295
Validation loss: 1.8597806679305209

Epoch: 265| Step: 0
Training loss: 1.4651563167572021
Validation loss: 1.8629753192265828

Epoch: 6| Step: 1
Training loss: 1.9584321975708008
Validation loss: 1.8196944164973434

Epoch: 6| Step: 2
Training loss: 1.364234209060669
Validation loss: 1.7996037583197317

Epoch: 6| Step: 3
Training loss: 1.1826953887939453
Validation loss: 1.8193886433878252

Epoch: 6| Step: 4
Training loss: 1.2175079584121704
Validation loss: 1.8620373818182177

Epoch: 6| Step: 5
Training loss: 2.1775684356689453
Validation loss: 1.8439757823944092

Epoch: 6| Step: 6
Training loss: 1.9775053262710571
Validation loss: 1.8366111273406653

Epoch: 6| Step: 7
Training loss: 1.6264314651489258
Validation loss: 1.8702233401677941

Epoch: 6| Step: 8
Training loss: 1.1833935976028442
Validation loss: 1.8444778585946688

Epoch: 6| Step: 9
Training loss: 2.184929132461548
Validation loss: 1.8216333414918633

Epoch: 6| Step: 10
Training loss: 2.077122211456299
Validation loss: 1.8276386440441172

Epoch: 6| Step: 11
Training loss: 0.888816237449646
Validation loss: 1.8416283553646458

Epoch: 6| Step: 12
Training loss: 0.9405874013900757
Validation loss: 1.8458481116961407

Epoch: 6| Step: 13
Training loss: 1.9996291399002075
Validation loss: 1.8369367455923429

Epoch: 266| Step: 0
Training loss: 1.480013132095337
Validation loss: 1.879530672104128

Epoch: 6| Step: 1
Training loss: 1.37516450881958
Validation loss: 1.8350980371557257

Epoch: 6| Step: 2
Training loss: 1.6068506240844727
Validation loss: 1.887096804957236

Epoch: 6| Step: 3
Training loss: 1.462167501449585
Validation loss: 1.8923021721583542

Epoch: 6| Step: 4
Training loss: 2.1198136806488037
Validation loss: 1.8808044541266657

Epoch: 6| Step: 5
Training loss: 1.800926923751831
Validation loss: 1.9019411956110308

Epoch: 6| Step: 6
Training loss: 1.8647785186767578
Validation loss: 1.9144432801072315

Epoch: 6| Step: 7
Training loss: 2.03267502784729
Validation loss: 1.8720810977361535

Epoch: 6| Step: 8
Training loss: 0.8900341987609863
Validation loss: 1.9002135517776653

Epoch: 6| Step: 9
Training loss: 1.6258058547973633
Validation loss: 1.9136956250795754

Epoch: 6| Step: 10
Training loss: 1.1249709129333496
Validation loss: 1.827329263892225

Epoch: 6| Step: 11
Training loss: 1.605058193206787
Validation loss: 1.8164805622511013

Epoch: 6| Step: 12
Training loss: 1.577694058418274
Validation loss: 1.826295341214826

Epoch: 6| Step: 13
Training loss: 1.3568222522735596
Validation loss: 1.8450750971353183

Epoch: 267| Step: 0
Training loss: 2.280721426010132
Validation loss: 1.8139117020432667

Epoch: 6| Step: 1
Training loss: 1.785001516342163
Validation loss: 1.826407189010292

Epoch: 6| Step: 2
Training loss: 1.1722478866577148
Validation loss: 1.837705450673257

Epoch: 6| Step: 3
Training loss: 1.3036432266235352
Validation loss: 1.7997728560560493

Epoch: 6| Step: 4
Training loss: 1.876147747039795
Validation loss: 1.8418736573188537

Epoch: 6| Step: 5
Training loss: 1.4444255828857422
Validation loss: 1.799576138937345

Epoch: 6| Step: 6
Training loss: 1.3650702238082886
Validation loss: 1.8539967075470956

Epoch: 6| Step: 7
Training loss: 1.6039243936538696
Validation loss: 1.8318405151367188

Epoch: 6| Step: 8
Training loss: 1.4341553449630737
Validation loss: 1.8553077610590125

Epoch: 6| Step: 9
Training loss: 1.5237023830413818
Validation loss: 1.8433785105264315

Epoch: 6| Step: 10
Training loss: 1.0979719161987305
Validation loss: 1.831369710224931

Epoch: 6| Step: 11
Training loss: 1.7042207717895508
Validation loss: 1.870666915370572

Epoch: 6| Step: 12
Training loss: 1.546590805053711
Validation loss: 1.870832549628391

Epoch: 6| Step: 13
Training loss: 1.2373757362365723
Validation loss: 1.8512318262489893

Epoch: 268| Step: 0
Training loss: 1.2564988136291504
Validation loss: 1.865609307442942

Epoch: 6| Step: 1
Training loss: 1.7066051959991455
Validation loss: 1.8919786804465837

Epoch: 6| Step: 2
Training loss: 1.2735790014266968
Validation loss: 1.8704280212361326

Epoch: 6| Step: 3
Training loss: 1.4816771745681763
Validation loss: 1.8383952033135198

Epoch: 6| Step: 4
Training loss: 1.5630682706832886
Validation loss: 1.8928961471844745

Epoch: 6| Step: 5
Training loss: 1.6775834560394287
Validation loss: 1.8243841560938026

Epoch: 6| Step: 6
Training loss: 1.3373534679412842
Validation loss: 1.8181035390464209

Epoch: 6| Step: 7
Training loss: 1.5724940299987793
Validation loss: 1.8589632652139152

Epoch: 6| Step: 8
Training loss: 1.0536527633666992
Validation loss: 1.8228676754941222

Epoch: 6| Step: 9
Training loss: 1.5934120416641235
Validation loss: 1.8273282127995645

Epoch: 6| Step: 10
Training loss: 1.0309436321258545
Validation loss: 1.8639172315597534

Epoch: 6| Step: 11
Training loss: 1.6389027833938599
Validation loss: 1.8497135562281455

Epoch: 6| Step: 12
Training loss: 2.373143196105957
Validation loss: 1.8158672778837142

Epoch: 6| Step: 13
Training loss: 2.334052085876465
Validation loss: 1.8086668906673309

Epoch: 269| Step: 0
Training loss: 1.5342841148376465
Validation loss: 1.8228633442232687

Epoch: 6| Step: 1
Training loss: 1.2175102233886719
Validation loss: 1.8870572736186366

Epoch: 6| Step: 2
Training loss: 1.6049764156341553
Validation loss: 1.8480281188923826

Epoch: 6| Step: 3
Training loss: 1.298813819885254
Validation loss: 1.8735364406339583

Epoch: 6| Step: 4
Training loss: 1.1373827457427979
Validation loss: 1.8935945418573195

Epoch: 6| Step: 5
Training loss: 1.8269901275634766
Validation loss: 1.8009617969553957

Epoch: 6| Step: 6
Training loss: 1.8943625688552856
Validation loss: 1.8782447204794934

Epoch: 6| Step: 7
Training loss: 1.0503039360046387
Validation loss: 1.8038018198423489

Epoch: 6| Step: 8
Training loss: 1.5405548810958862
Validation loss: 1.839752802284815

Epoch: 6| Step: 9
Training loss: 1.5690500736236572
Validation loss: 1.84911133140646

Epoch: 6| Step: 10
Training loss: 1.112430453300476
Validation loss: 1.8447627047056794

Epoch: 6| Step: 11
Training loss: 1.8815606832504272
Validation loss: 1.9092140223390313

Epoch: 6| Step: 12
Training loss: 1.484926700592041
Validation loss: 1.8508702990829304

Epoch: 6| Step: 13
Training loss: 2.475922107696533
Validation loss: 1.867858127881122

Epoch: 270| Step: 0
Training loss: 1.6021978855133057
Validation loss: 1.8810728378193353

Epoch: 6| Step: 1
Training loss: 1.3547942638397217
Validation loss: 1.8536473269103675

Epoch: 6| Step: 2
Training loss: 1.0770450830459595
Validation loss: 1.8382834106363275

Epoch: 6| Step: 3
Training loss: 1.2409435510635376
Validation loss: 1.834423553559088

Epoch: 6| Step: 4
Training loss: 1.8218843936920166
Validation loss: 1.8057167888969503

Epoch: 6| Step: 5
Training loss: 1.1667028665542603
Validation loss: 1.8332608694671302

Epoch: 6| Step: 6
Training loss: 2.154219150543213
Validation loss: 1.8679494652696835

Epoch: 6| Step: 7
Training loss: 1.3302433490753174
Validation loss: 1.883934546542424

Epoch: 6| Step: 8
Training loss: 1.5406982898712158
Validation loss: 1.843555159466241

Epoch: 6| Step: 9
Training loss: 1.334629774093628
Validation loss: 1.838952713115241

Epoch: 6| Step: 10
Training loss: 1.3849267959594727
Validation loss: 1.8378307409183954

Epoch: 6| Step: 11
Training loss: 1.7774537801742554
Validation loss: 1.8538015568128197

Epoch: 6| Step: 12
Training loss: 1.8344002962112427
Validation loss: 1.8860433909200853

Epoch: 6| Step: 13
Training loss: 2.2198493480682373
Validation loss: 1.8325052222897928

Epoch: 271| Step: 0
Training loss: 1.0912351608276367
Validation loss: 1.8456596213002359

Epoch: 6| Step: 1
Training loss: 0.9559564590454102
Validation loss: 1.833292584265432

Epoch: 6| Step: 2
Training loss: 1.0825096368789673
Validation loss: 1.8657430782113025

Epoch: 6| Step: 3
Training loss: 1.2383958101272583
Validation loss: 1.899266351935684

Epoch: 6| Step: 4
Training loss: 1.5115435123443604
Validation loss: 1.8391789851650115

Epoch: 6| Step: 5
Training loss: 1.6852082014083862
Validation loss: 1.8437037288501699

Epoch: 6| Step: 6
Training loss: 2.2745065689086914
Validation loss: 1.8399050171657274

Epoch: 6| Step: 7
Training loss: 2.090325117111206
Validation loss: 1.8402882391406643

Epoch: 6| Step: 8
Training loss: 1.8163611888885498
Validation loss: 1.8610508903380363

Epoch: 6| Step: 9
Training loss: 1.6176410913467407
Validation loss: 1.8332507405229794

Epoch: 6| Step: 10
Training loss: 1.4561846256256104
Validation loss: 1.840457695786671

Epoch: 6| Step: 11
Training loss: 1.2763698101043701
Validation loss: 1.8245557354342552

Epoch: 6| Step: 12
Training loss: 1.8106907606124878
Validation loss: 1.8503567287998814

Epoch: 6| Step: 13
Training loss: 1.8209642171859741
Validation loss: 1.8446165130984398

Epoch: 272| Step: 0
Training loss: 1.49086594581604
Validation loss: 1.8653182803943593

Epoch: 6| Step: 1
Training loss: 0.8169004917144775
Validation loss: 1.8377691853430964

Epoch: 6| Step: 2
Training loss: 1.42768132686615
Validation loss: 1.817157865852438

Epoch: 6| Step: 3
Training loss: 1.61074960231781
Validation loss: 1.863067021933935

Epoch: 6| Step: 4
Training loss: 1.273681402206421
Validation loss: 1.8505666114950692

Epoch: 6| Step: 5
Training loss: 1.182077407836914
Validation loss: 1.8240366725511448

Epoch: 6| Step: 6
Training loss: 2.295470714569092
Validation loss: 1.7965456490875573

Epoch: 6| Step: 7
Training loss: 1.4690415859222412
Validation loss: 1.8213623544221282

Epoch: 6| Step: 8
Training loss: 2.2542266845703125
Validation loss: 1.8641597737548172

Epoch: 6| Step: 9
Training loss: 1.4591495990753174
Validation loss: 1.8292715241832118

Epoch: 6| Step: 10
Training loss: 2.2497200965881348
Validation loss: 1.841236840012253

Epoch: 6| Step: 11
Training loss: 1.1355420351028442
Validation loss: 1.816295518670031

Epoch: 6| Step: 12
Training loss: 1.3635145425796509
Validation loss: 1.8006078171473678

Epoch: 6| Step: 13
Training loss: 1.4328378438949585
Validation loss: 1.8239904039649553

Epoch: 273| Step: 0
Training loss: 1.3667032718658447
Validation loss: 1.8198443740926764

Epoch: 6| Step: 1
Training loss: 1.5529835224151611
Validation loss: 1.8492231574109805

Epoch: 6| Step: 2
Training loss: 1.5342092514038086
Validation loss: 1.8969930295021302

Epoch: 6| Step: 3
Training loss: 1.3752543926239014
Validation loss: 1.9191617260697067

Epoch: 6| Step: 4
Training loss: 2.1975932121276855
Validation loss: 1.9059197287405691

Epoch: 6| Step: 5
Training loss: 1.2645139694213867
Validation loss: 1.8643363265581028

Epoch: 6| Step: 6
Training loss: 1.662475824356079
Validation loss: 1.8889261445691508

Epoch: 6| Step: 7
Training loss: 1.504324197769165
Validation loss: 1.8740922994511102

Epoch: 6| Step: 8
Training loss: 1.7051286697387695
Validation loss: 1.8656960020783127

Epoch: 6| Step: 9
Training loss: 1.0071295499801636
Validation loss: 1.8873284811614661

Epoch: 6| Step: 10
Training loss: 1.4765958786010742
Validation loss: 1.8640498679171327

Epoch: 6| Step: 11
Training loss: 1.3442070484161377
Validation loss: 1.8854057340211765

Epoch: 6| Step: 12
Training loss: 2.0456371307373047
Validation loss: 1.8636073796979842

Epoch: 6| Step: 13
Training loss: 1.569591760635376
Validation loss: 1.8239878351970384

Epoch: 274| Step: 0
Training loss: 1.4194985628128052
Validation loss: 1.837156177848898

Epoch: 6| Step: 1
Training loss: 1.5607990026474
Validation loss: 1.8639313238923267

Epoch: 6| Step: 2
Training loss: 1.7113213539123535
Validation loss: 1.861216861714599

Epoch: 6| Step: 3
Training loss: 0.8955854177474976
Validation loss: 1.8249884036279493

Epoch: 6| Step: 4
Training loss: 2.2863011360168457
Validation loss: 1.7777663200132308

Epoch: 6| Step: 5
Training loss: 1.3753530979156494
Validation loss: 1.8388639342400335

Epoch: 6| Step: 6
Training loss: 1.8251665830612183
Validation loss: 1.8071690015895392

Epoch: 6| Step: 7
Training loss: 1.569936990737915
Validation loss: 1.8256229046852357

Epoch: 6| Step: 8
Training loss: 1.2478010654449463
Validation loss: 1.8548737366994221

Epoch: 6| Step: 9
Training loss: 1.5710980892181396
Validation loss: 1.8300417674485074

Epoch: 6| Step: 10
Training loss: 1.269381046295166
Validation loss: 1.8120413480266448

Epoch: 6| Step: 11
Training loss: 1.799910068511963
Validation loss: 1.8056430970468829

Epoch: 6| Step: 12
Training loss: 1.9119443893432617
Validation loss: 1.839809577952149

Epoch: 6| Step: 13
Training loss: 1.0406485795974731
Validation loss: 1.8190561699610885

Epoch: 275| Step: 0
Training loss: 1.813835859298706
Validation loss: 1.8512183927720594

Epoch: 6| Step: 1
Training loss: 1.435019612312317
Validation loss: 1.8534394066820863

Epoch: 6| Step: 2
Training loss: 1.852226734161377
Validation loss: 1.9065705704432663

Epoch: 6| Step: 3
Training loss: 1.3537802696228027
Validation loss: 1.8935491564453288

Epoch: 6| Step: 4
Training loss: 1.6105180978775024
Validation loss: 1.9255976664122714

Epoch: 6| Step: 5
Training loss: 1.5339207649230957
Validation loss: 1.9258433657307779

Epoch: 6| Step: 6
Training loss: 1.3650951385498047
Validation loss: 1.9395358203559794

Epoch: 6| Step: 7
Training loss: 1.2733653783798218
Validation loss: 1.9389872807328419

Epoch: 6| Step: 8
Training loss: 1.4948104619979858
Validation loss: 1.8685530731754918

Epoch: 6| Step: 9
Training loss: 1.9781920909881592
Validation loss: 1.851341075794671

Epoch: 6| Step: 10
Training loss: 1.9377554655075073
Validation loss: 1.8739476921737834

Epoch: 6| Step: 11
Training loss: 1.1800439357757568
Validation loss: 1.8360338544332853

Epoch: 6| Step: 12
Training loss: 1.446345329284668
Validation loss: 1.8535976358639297

Epoch: 6| Step: 13
Training loss: 1.643347144126892
Validation loss: 1.7839656670888264

Epoch: 276| Step: 0
Training loss: 1.7443095445632935
Validation loss: 1.8793889719952819

Epoch: 6| Step: 1
Training loss: 1.6357719898223877
Validation loss: 1.8207657644825597

Epoch: 6| Step: 2
Training loss: 1.2978322505950928
Validation loss: 1.8359984774743356

Epoch: 6| Step: 3
Training loss: 1.1264095306396484
Validation loss: 1.8317629278347056

Epoch: 6| Step: 4
Training loss: 1.7751686573028564
Validation loss: 1.8789980308983916

Epoch: 6| Step: 5
Training loss: 0.7415041923522949
Validation loss: 1.8737672977550055

Epoch: 6| Step: 6
Training loss: 2.271749496459961
Validation loss: 1.8626336936027772

Epoch: 6| Step: 7
Training loss: 1.6087677478790283
Validation loss: 1.8560818754216677

Epoch: 6| Step: 8
Training loss: 1.5173184871673584
Validation loss: 1.8434414889222832

Epoch: 6| Step: 9
Training loss: 1.6047284603118896
Validation loss: 1.8596261675639818

Epoch: 6| Step: 10
Training loss: 1.7305423021316528
Validation loss: 1.8484447284411358

Epoch: 6| Step: 11
Training loss: 1.409624457359314
Validation loss: 1.8622326722709082

Epoch: 6| Step: 12
Training loss: 1.5231168270111084
Validation loss: 1.8346973196152718

Epoch: 6| Step: 13
Training loss: 1.0986469984054565
Validation loss: 1.8003243964205506

Epoch: 277| Step: 0
Training loss: 1.359876275062561
Validation loss: 1.8566592252382668

Epoch: 6| Step: 1
Training loss: 1.630598545074463
Validation loss: 1.8059450836591824

Epoch: 6| Step: 2
Training loss: 1.105536699295044
Validation loss: 1.8285100370325067

Epoch: 6| Step: 3
Training loss: 1.3920485973358154
Validation loss: 1.8853767110455422

Epoch: 6| Step: 4
Training loss: 1.5127941370010376
Validation loss: 1.8506599126323577

Epoch: 6| Step: 5
Training loss: 1.4542851448059082
Validation loss: 1.9478512707576956

Epoch: 6| Step: 6
Training loss: 1.2370049953460693
Validation loss: 1.9003775773509857

Epoch: 6| Step: 7
Training loss: 1.5730805397033691
Validation loss: 1.9107455656092653

Epoch: 6| Step: 8
Training loss: 1.5066332817077637
Validation loss: 1.8932410273500668

Epoch: 6| Step: 9
Training loss: 2.301384449005127
Validation loss: 1.8973159110674294

Epoch: 6| Step: 10
Training loss: 1.614715814590454
Validation loss: 1.8349443225450413

Epoch: 6| Step: 11
Training loss: 1.4394824504852295
Validation loss: 1.8438388429662234

Epoch: 6| Step: 12
Training loss: 1.512000560760498
Validation loss: 1.8692949087389055

Epoch: 6| Step: 13
Training loss: 1.6831836700439453
Validation loss: 1.8606483051853795

Epoch: 278| Step: 0
Training loss: 1.2868242263793945
Validation loss: 1.8244391256763088

Epoch: 6| Step: 1
Training loss: 2.4108095169067383
Validation loss: 1.7929514774712183

Epoch: 6| Step: 2
Training loss: 1.09513521194458
Validation loss: 1.7922792960238714

Epoch: 6| Step: 3
Training loss: 1.6949493885040283
Validation loss: 1.810170232608754

Epoch: 6| Step: 4
Training loss: 1.1668117046356201
Validation loss: 1.8044847865258493

Epoch: 6| Step: 5
Training loss: 1.5570437908172607
Validation loss: 1.8331517199034333

Epoch: 6| Step: 6
Training loss: 1.7819409370422363
Validation loss: 1.8115964435761975

Epoch: 6| Step: 7
Training loss: 1.5024915933609009
Validation loss: 1.8142020369088778

Epoch: 6| Step: 8
Training loss: 1.2884031534194946
Validation loss: 1.847234341406053

Epoch: 6| Step: 9
Training loss: 1.752107858657837
Validation loss: 1.7969972625855477

Epoch: 6| Step: 10
Training loss: 1.4772372245788574
Validation loss: 1.8283930491375666

Epoch: 6| Step: 11
Training loss: 1.2673944234848022
Validation loss: 1.807960182107905

Epoch: 6| Step: 12
Training loss: 0.9622272253036499
Validation loss: 1.85782967716135

Epoch: 6| Step: 13
Training loss: 2.1510660648345947
Validation loss: 1.7762145444911013

Epoch: 279| Step: 0
Training loss: 1.181835651397705
Validation loss: 1.8003089722766672

Epoch: 6| Step: 1
Training loss: 1.3836138248443604
Validation loss: 1.885802168999949

Epoch: 6| Step: 2
Training loss: 1.4641847610473633
Validation loss: 1.8633770968324395

Epoch: 6| Step: 3
Training loss: 1.7072263956069946
Validation loss: 1.850012065261923

Epoch: 6| Step: 4
Training loss: 0.6691012382507324
Validation loss: 1.831317493992467

Epoch: 6| Step: 5
Training loss: 1.4876813888549805
Validation loss: 1.8498607515006937

Epoch: 6| Step: 6
Training loss: 1.5345158576965332
Validation loss: 1.8666027092164563

Epoch: 6| Step: 7
Training loss: 1.6167467832565308
Validation loss: 1.8794280969968407

Epoch: 6| Step: 8
Training loss: 1.7842899560928345
Validation loss: 1.8163526596561554

Epoch: 6| Step: 9
Training loss: 1.7020690441131592
Validation loss: 1.869993414930118

Epoch: 6| Step: 10
Training loss: 1.9905014038085938
Validation loss: 1.8644415691334715

Epoch: 6| Step: 11
Training loss: 1.592782735824585
Validation loss: 1.8783360706862582

Epoch: 6| Step: 12
Training loss: 1.7143239974975586
Validation loss: 1.7882753597792758

Epoch: 6| Step: 13
Training loss: 1.4825079441070557
Validation loss: 1.848008737769178

Epoch: 280| Step: 0
Training loss: 1.6008398532867432
Validation loss: 1.826927900314331

Epoch: 6| Step: 1
Training loss: 2.0427846908569336
Validation loss: 1.7908774293879026

Epoch: 6| Step: 2
Training loss: 1.3522326946258545
Validation loss: 1.8256073408229376

Epoch: 6| Step: 3
Training loss: 1.4760158061981201
Validation loss: 1.857696690867024

Epoch: 6| Step: 4
Training loss: 1.903135061264038
Validation loss: 1.8353399012678413

Epoch: 6| Step: 5
Training loss: 1.932560682296753
Validation loss: 1.8022162017001901

Epoch: 6| Step: 6
Training loss: 1.1966596841812134
Validation loss: 1.8315983177513204

Epoch: 6| Step: 7
Training loss: 1.3436503410339355
Validation loss: 1.8523252164163897

Epoch: 6| Step: 8
Training loss: 1.4088783264160156
Validation loss: 1.8151477767575173

Epoch: 6| Step: 9
Training loss: 1.6321754455566406
Validation loss: 1.845371384774485

Epoch: 6| Step: 10
Training loss: 1.4746644496917725
Validation loss: 1.819117017971572

Epoch: 6| Step: 11
Training loss: 0.7852948307991028
Validation loss: 1.8285297309198687

Epoch: 6| Step: 12
Training loss: 1.6008821725845337
Validation loss: 1.8693764748111847

Epoch: 6| Step: 13
Training loss: 1.3245359659194946
Validation loss: 1.8620635822255125

Epoch: 281| Step: 0
Training loss: 1.01692533493042
Validation loss: 1.9037719465071155

Epoch: 6| Step: 1
Training loss: 1.9606597423553467
Validation loss: 1.894887460175381

Epoch: 6| Step: 2
Training loss: 1.0019352436065674
Validation loss: 1.8760957974259571

Epoch: 6| Step: 3
Training loss: 1.6949925422668457
Validation loss: 1.9268408744565901

Epoch: 6| Step: 4
Training loss: 1.8658292293548584
Validation loss: 1.9340871995495212

Epoch: 6| Step: 5
Training loss: 1.8425695896148682
Validation loss: 1.9377894170822636

Epoch: 6| Step: 6
Training loss: 2.0607995986938477
Validation loss: 1.941427364144274

Epoch: 6| Step: 7
Training loss: 1.6516685485839844
Validation loss: 1.9061962673741002

Epoch: 6| Step: 8
Training loss: 0.9289143085479736
Validation loss: 1.89663726540022

Epoch: 6| Step: 9
Training loss: 1.6567273139953613
Validation loss: 1.8895072590920232

Epoch: 6| Step: 10
Training loss: 1.6488898992538452
Validation loss: 1.880132608516242

Epoch: 6| Step: 11
Training loss: 1.4127256870269775
Validation loss: 1.8806091559830533

Epoch: 6| Step: 12
Training loss: 1.4453799724578857
Validation loss: 1.8890749075079476

Epoch: 6| Step: 13
Training loss: 1.4212303161621094
Validation loss: 1.8471912312251266

Epoch: 282| Step: 0
Training loss: 1.6856575012207031
Validation loss: 1.8495959594685545

Epoch: 6| Step: 1
Training loss: 1.5512473583221436
Validation loss: 1.8549989128625521

Epoch: 6| Step: 2
Training loss: 1.6659108400344849
Validation loss: 1.8994117193324591

Epoch: 6| Step: 3
Training loss: 1.0456295013427734
Validation loss: 1.8009395599365234

Epoch: 6| Step: 4
Training loss: 1.7880473136901855
Validation loss: 1.8425025055485387

Epoch: 6| Step: 5
Training loss: 1.9779901504516602
Validation loss: 1.8546451445548766

Epoch: 6| Step: 6
Training loss: 1.0203088521957397
Validation loss: 1.8705434824830742

Epoch: 6| Step: 7
Training loss: 1.1679259538650513
Validation loss: 1.8386682874412947

Epoch: 6| Step: 8
Training loss: 2.0663018226623535
Validation loss: 1.8941596477262435

Epoch: 6| Step: 9
Training loss: 0.91084885597229
Validation loss: 1.8250730159462139

Epoch: 6| Step: 10
Training loss: 1.7412841320037842
Validation loss: 1.8613665796095324

Epoch: 6| Step: 11
Training loss: 1.5405843257904053
Validation loss: 1.8392174461836457

Epoch: 6| Step: 12
Training loss: 1.5448057651519775
Validation loss: 1.8292510817127843

Epoch: 6| Step: 13
Training loss: 1.0326447486877441
Validation loss: 1.8238691770902244

Epoch: 283| Step: 0
Training loss: 1.5554075241088867
Validation loss: 1.815696770145047

Epoch: 6| Step: 1
Training loss: 1.4411134719848633
Validation loss: 1.863786066732099

Epoch: 6| Step: 2
Training loss: 1.670185923576355
Validation loss: 1.8429606447937668

Epoch: 6| Step: 3
Training loss: 1.4210442304611206
Validation loss: 1.8478214894571612

Epoch: 6| Step: 4
Training loss: 1.4566142559051514
Validation loss: 1.8140750392790763

Epoch: 6| Step: 5
Training loss: 1.4901506900787354
Validation loss: 1.826946545672673

Epoch: 6| Step: 6
Training loss: 1.7092702388763428
Validation loss: 1.7894916149877733

Epoch: 6| Step: 7
Training loss: 1.8320209980010986
Validation loss: 1.8215510024819324

Epoch: 6| Step: 8
Training loss: 1.1389782428741455
Validation loss: 1.8158209939156809

Epoch: 6| Step: 9
Training loss: 1.6971207857131958
Validation loss: 1.8193401546888455

Epoch: 6| Step: 10
Training loss: 1.183528184890747
Validation loss: 1.790201824198487

Epoch: 6| Step: 11
Training loss: 1.137918472290039
Validation loss: 1.809077529497044

Epoch: 6| Step: 12
Training loss: 1.289421558380127
Validation loss: 1.8784726947866461

Epoch: 6| Step: 13
Training loss: 1.594096302986145
Validation loss: 1.7968378925836215

Epoch: 284| Step: 0
Training loss: 0.9810925126075745
Validation loss: 1.828368430496544

Epoch: 6| Step: 1
Training loss: 1.5143240690231323
Validation loss: 1.8460902065359137

Epoch: 6| Step: 2
Training loss: 1.291904091835022
Validation loss: 1.9040486812591553

Epoch: 6| Step: 3
Training loss: 1.403397798538208
Validation loss: 1.848298462488318

Epoch: 6| Step: 4
Training loss: 1.5147383213043213
Validation loss: 1.8126580638270224

Epoch: 6| Step: 5
Training loss: 1.6141419410705566
Validation loss: 1.8377712875284173

Epoch: 6| Step: 6
Training loss: 1.2503776550292969
Validation loss: 1.8953803034238919

Epoch: 6| Step: 7
Training loss: 1.6192383766174316
Validation loss: 1.8669969727916103

Epoch: 6| Step: 8
Training loss: 1.4738426208496094
Validation loss: 1.9074151913324993

Epoch: 6| Step: 9
Training loss: 1.5047211647033691
Validation loss: 1.8395894496671614

Epoch: 6| Step: 10
Training loss: 1.741801381111145
Validation loss: 1.8675029111164871

Epoch: 6| Step: 11
Training loss: 1.2985421419143677
Validation loss: 1.8130838383910477

Epoch: 6| Step: 12
Training loss: 1.2422336339950562
Validation loss: 1.8338522654707714

Epoch: 6| Step: 13
Training loss: 2.63460636138916
Validation loss: 1.795773406182566

Epoch: 285| Step: 0
Training loss: 1.3754305839538574
Validation loss: 1.8614650977555143

Epoch: 6| Step: 1
Training loss: 1.2745779752731323
Validation loss: 1.796984375164073

Epoch: 6| Step: 2
Training loss: 1.8017996549606323
Validation loss: 1.8690300385157268

Epoch: 6| Step: 3
Training loss: 1.7179582118988037
Validation loss: 1.8366983526496476

Epoch: 6| Step: 4
Training loss: 1.3589513301849365
Validation loss: 1.7948127792727562

Epoch: 6| Step: 5
Training loss: 0.8479158878326416
Validation loss: 1.860543748383881

Epoch: 6| Step: 6
Training loss: 1.965314269065857
Validation loss: 1.852387862820779

Epoch: 6| Step: 7
Training loss: 0.941925585269928
Validation loss: 1.8533774768152544

Epoch: 6| Step: 8
Training loss: 0.9039770364761353
Validation loss: 1.8622648382699618

Epoch: 6| Step: 9
Training loss: 1.7949163913726807
Validation loss: 1.8424881158336517

Epoch: 6| Step: 10
Training loss: 1.3371679782867432
Validation loss: 1.8156170729667909

Epoch: 6| Step: 11
Training loss: 1.8150769472122192
Validation loss: 1.8642698308472991

Epoch: 6| Step: 12
Training loss: 1.5925140380859375
Validation loss: 1.8437688043040614

Epoch: 6| Step: 13
Training loss: 2.641200065612793
Validation loss: 1.857699667253802

Epoch: 286| Step: 0
Training loss: 1.3254172801971436
Validation loss: 1.8125842412312825

Epoch: 6| Step: 1
Training loss: 1.3167054653167725
Validation loss: 1.8759878066278273

Epoch: 6| Step: 2
Training loss: 1.8654645681381226
Validation loss: 1.9018377155385993

Epoch: 6| Step: 3
Training loss: 1.6107311248779297
Validation loss: 1.9683497810876498

Epoch: 6| Step: 4
Training loss: 0.9965527653694153
Validation loss: 1.8211101870382986

Epoch: 6| Step: 5
Training loss: 1.5492920875549316
Validation loss: 1.8781701723734539

Epoch: 6| Step: 6
Training loss: 1.904082179069519
Validation loss: 1.8443988830812517

Epoch: 6| Step: 7
Training loss: 1.2924546003341675
Validation loss: 1.9058963483379734

Epoch: 6| Step: 8
Training loss: 1.428593397140503
Validation loss: 1.8729035149338424

Epoch: 6| Step: 9
Training loss: 1.593489408493042
Validation loss: 1.8819774517449

Epoch: 6| Step: 10
Training loss: 1.6001207828521729
Validation loss: 1.8025261637985066

Epoch: 6| Step: 11
Training loss: 1.039687156677246
Validation loss: 1.866912047068278

Epoch: 6| Step: 12
Training loss: 1.939069151878357
Validation loss: 1.8266002106410202

Epoch: 6| Step: 13
Training loss: 1.5119951963424683
Validation loss: 1.831954151071528

Epoch: 287| Step: 0
Training loss: 1.7497119903564453
Validation loss: 1.7845730986646426

Epoch: 6| Step: 1
Training loss: 1.7566179037094116
Validation loss: 1.8235328684570968

Epoch: 6| Step: 2
Training loss: 1.392600655555725
Validation loss: 1.811461793479099

Epoch: 6| Step: 3
Training loss: 1.9430606365203857
Validation loss: 1.8371418432522846

Epoch: 6| Step: 4
Training loss: 1.2474945783615112
Validation loss: 1.8172625674996326

Epoch: 6| Step: 5
Training loss: 1.3950986862182617
Validation loss: 1.8372166579769504

Epoch: 6| Step: 6
Training loss: 1.5022977590560913
Validation loss: 1.800753580626621

Epoch: 6| Step: 7
Training loss: 1.0193440914154053
Validation loss: 1.8385366470583024

Epoch: 6| Step: 8
Training loss: 1.005685567855835
Validation loss: 1.8279256307950584

Epoch: 6| Step: 9
Training loss: 1.7209947109222412
Validation loss: 1.8821874677494008

Epoch: 6| Step: 10
Training loss: 1.7036651372909546
Validation loss: 1.8270631221032911

Epoch: 6| Step: 11
Training loss: 2.2564353942871094
Validation loss: 1.8562533547801356

Epoch: 6| Step: 12
Training loss: 1.282830834388733
Validation loss: 1.8299327281213575

Epoch: 6| Step: 13
Training loss: 0.7109349370002747
Validation loss: 1.8243063367823118

Epoch: 288| Step: 0
Training loss: 1.0741721391677856
Validation loss: 1.8566707616211267

Epoch: 6| Step: 1
Training loss: 1.3548357486724854
Validation loss: 1.832491127393579

Epoch: 6| Step: 2
Training loss: 1.3093822002410889
Validation loss: 1.8334290853110693

Epoch: 6| Step: 3
Training loss: 1.7938756942749023
Validation loss: 1.7878135583734

Epoch: 6| Step: 4
Training loss: 1.201324462890625
Validation loss: 1.826128577673307

Epoch: 6| Step: 5
Training loss: 1.7965857982635498
Validation loss: 1.7838042218198058

Epoch: 6| Step: 6
Training loss: 1.7517802715301514
Validation loss: 1.811248247341443

Epoch: 6| Step: 7
Training loss: 1.158846378326416
Validation loss: 1.8207265561626804

Epoch: 6| Step: 8
Training loss: 1.7185208797454834
Validation loss: 1.834455382439398

Epoch: 6| Step: 9
Training loss: 1.8061457872390747
Validation loss: 1.7660589974413636

Epoch: 6| Step: 10
Training loss: 1.376448392868042
Validation loss: 1.814388071337054

Epoch: 6| Step: 11
Training loss: 1.234908938407898
Validation loss: 1.8321788810914563

Epoch: 6| Step: 12
Training loss: 1.7081055641174316
Validation loss: 1.8323154885281798

Epoch: 6| Step: 13
Training loss: 2.1529035568237305
Validation loss: 1.8324228076524631

Epoch: 289| Step: 0
Training loss: 1.4323198795318604
Validation loss: 1.8594598026685818

Epoch: 6| Step: 1
Training loss: 1.5402846336364746
Validation loss: 1.8301551700920187

Epoch: 6| Step: 2
Training loss: 1.9453167915344238
Validation loss: 1.826399641652261

Epoch: 6| Step: 3
Training loss: 1.654584527015686
Validation loss: 1.8336104398132653

Epoch: 6| Step: 4
Training loss: 1.2885987758636475
Validation loss: 1.8697674825627317

Epoch: 6| Step: 5
Training loss: 1.480830430984497
Validation loss: 1.8238776255679388

Epoch: 6| Step: 6
Training loss: 1.6666765213012695
Validation loss: 1.878450108471737

Epoch: 6| Step: 7
Training loss: 1.8949506282806396
Validation loss: 1.8904261063503962

Epoch: 6| Step: 8
Training loss: 1.512449026107788
Validation loss: 1.8907369670047556

Epoch: 6| Step: 9
Training loss: 1.9612308740615845
Validation loss: 1.8770392838344778

Epoch: 6| Step: 10
Training loss: 1.3497061729431152
Validation loss: 1.850896914800008

Epoch: 6| Step: 11
Training loss: 1.0083181858062744
Validation loss: 1.865587524188462

Epoch: 6| Step: 12
Training loss: 0.8096325397491455
Validation loss: 1.8238777806681972

Epoch: 6| Step: 13
Training loss: 1.2480946779251099
Validation loss: 1.869247862087783

Epoch: 290| Step: 0
Training loss: 1.0534093379974365
Validation loss: 1.7900687263857933

Epoch: 6| Step: 1
Training loss: 1.4469285011291504
Validation loss: 1.8187539833848194

Epoch: 6| Step: 2
Training loss: 1.3144980669021606
Validation loss: 1.8243440222996536

Epoch: 6| Step: 3
Training loss: 1.6101133823394775
Validation loss: 1.8141089844447311

Epoch: 6| Step: 4
Training loss: 2.0433709621429443
Validation loss: 1.8056923625289754

Epoch: 6| Step: 5
Training loss: 1.944974660873413
Validation loss: 1.830061959963973

Epoch: 6| Step: 6
Training loss: 0.9650499820709229
Validation loss: 1.8343222641175794

Epoch: 6| Step: 7
Training loss: 1.0779194831848145
Validation loss: 1.7671764486579484

Epoch: 6| Step: 8
Training loss: 1.9032033681869507
Validation loss: 1.787113364024829

Epoch: 6| Step: 9
Training loss: 1.296743631362915
Validation loss: 1.7800837383475354

Epoch: 6| Step: 10
Training loss: 1.2524067163467407
Validation loss: 1.795220418642926

Epoch: 6| Step: 11
Training loss: 1.7427608966827393
Validation loss: 1.7970963754961569

Epoch: 6| Step: 12
Training loss: 1.3841323852539062
Validation loss: 1.8075410999277586

Epoch: 6| Step: 13
Training loss: 2.1330766677856445
Validation loss: 1.8582040981579853

Epoch: 291| Step: 0
Training loss: 1.4131420850753784
Validation loss: 1.8761321293410433

Epoch: 6| Step: 1
Training loss: 1.3408966064453125
Validation loss: 1.8772205716820174

Epoch: 6| Step: 2
Training loss: 1.7024281024932861
Validation loss: 1.8385845666290612

Epoch: 6| Step: 3
Training loss: 1.6243140697479248
Validation loss: 1.8867761563229304

Epoch: 6| Step: 4
Training loss: 1.7197777032852173
Validation loss: 1.8787934651938818

Epoch: 6| Step: 5
Training loss: 1.387225866317749
Validation loss: 1.85975984860492

Epoch: 6| Step: 6
Training loss: 1.1407032012939453
Validation loss: 1.8522601358352169

Epoch: 6| Step: 7
Training loss: 1.8144700527191162
Validation loss: 1.8671132544035554

Epoch: 6| Step: 8
Training loss: 1.6051466464996338
Validation loss: 1.8908319011811288

Epoch: 6| Step: 9
Training loss: 1.5154013633728027
Validation loss: 1.8961562072077105

Epoch: 6| Step: 10
Training loss: 1.0192692279815674
Validation loss: 1.9014318245713429

Epoch: 6| Step: 11
Training loss: 1.3901273012161255
Validation loss: 1.8615449782340758

Epoch: 6| Step: 12
Training loss: 1.3150135278701782
Validation loss: 1.8564962110211771

Epoch: 6| Step: 13
Training loss: 2.3469953536987305
Validation loss: 1.8050052478749266

Epoch: 292| Step: 0
Training loss: 1.6057933568954468
Validation loss: 1.8304200249333535

Epoch: 6| Step: 1
Training loss: 1.6051862239837646
Validation loss: 1.8441448673125236

Epoch: 6| Step: 2
Training loss: 1.7017878293991089
Validation loss: 1.8354687793280489

Epoch: 6| Step: 3
Training loss: 1.772504210472107
Validation loss: 1.8366316582566948

Epoch: 6| Step: 4
Training loss: 1.7378400564193726
Validation loss: 1.9073338303514706

Epoch: 6| Step: 5
Training loss: 1.1731772422790527
Validation loss: 1.7890309505565192

Epoch: 6| Step: 6
Training loss: 1.7994003295898438
Validation loss: 1.8443802902775426

Epoch: 6| Step: 7
Training loss: 1.8599919080734253
Validation loss: 1.8413436028265184

Epoch: 6| Step: 8
Training loss: 0.8590396642684937
Validation loss: 1.8043582939332532

Epoch: 6| Step: 9
Training loss: 1.2737443447113037
Validation loss: 1.7856635739726405

Epoch: 6| Step: 10
Training loss: 0.9866679906845093
Validation loss: 1.7878513669454923

Epoch: 6| Step: 11
Training loss: 1.2582581043243408
Validation loss: 1.8432218656745007

Epoch: 6| Step: 12
Training loss: 1.6470921039581299
Validation loss: 1.804957676959294

Epoch: 6| Step: 13
Training loss: 0.7072643637657166
Validation loss: 1.80372057935243

Epoch: 293| Step: 0
Training loss: 1.6954426765441895
Validation loss: 1.83485496300523

Epoch: 6| Step: 1
Training loss: 1.4116768836975098
Validation loss: 1.829232959337132

Epoch: 6| Step: 2
Training loss: 1.526018738746643
Validation loss: 1.8279182577645907

Epoch: 6| Step: 3
Training loss: 1.5390238761901855
Validation loss: 1.8552786714287215

Epoch: 6| Step: 4
Training loss: 1.9493563175201416
Validation loss: 1.8690243651790004

Epoch: 6| Step: 5
Training loss: 1.1841604709625244
Validation loss: 1.8218689131480392

Epoch: 6| Step: 6
Training loss: 1.5480260848999023
Validation loss: 1.825278030928745

Epoch: 6| Step: 7
Training loss: 1.3545646667480469
Validation loss: 1.8837354106287802

Epoch: 6| Step: 8
Training loss: 1.4528883695602417
Validation loss: 1.8365875674832253

Epoch: 6| Step: 9
Training loss: 1.0316294431686401
Validation loss: 1.8284156207115418

Epoch: 6| Step: 10
Training loss: 1.555182695388794
Validation loss: 1.8335338523311

Epoch: 6| Step: 11
Training loss: 1.8680098056793213
Validation loss: 1.8546489233611732

Epoch: 6| Step: 12
Training loss: 1.3195154666900635
Validation loss: 1.8782383536779752

Epoch: 6| Step: 13
Training loss: 1.3871326446533203
Validation loss: 1.8420272745111936

Epoch: 294| Step: 0
Training loss: 1.8767186403274536
Validation loss: 1.81020555444943

Epoch: 6| Step: 1
Training loss: 2.036623477935791
Validation loss: 1.7931373888446438

Epoch: 6| Step: 2
Training loss: 1.1370420455932617
Validation loss: 1.8200479399773382

Epoch: 6| Step: 3
Training loss: 1.3913476467132568
Validation loss: 1.7276431347734185

Epoch: 6| Step: 4
Training loss: 0.9245285391807556
Validation loss: 1.811833430362004

Epoch: 6| Step: 5
Training loss: 1.5722999572753906
Validation loss: 1.8282415815578994

Epoch: 6| Step: 6
Training loss: 1.0882993936538696
Validation loss: 1.8392103231081398

Epoch: 6| Step: 7
Training loss: 1.780139684677124
Validation loss: 1.8211936155954997

Epoch: 6| Step: 8
Training loss: 1.9418898820877075
Validation loss: 1.7972782927174722

Epoch: 6| Step: 9
Training loss: 0.6896033883094788
Validation loss: 1.8273188080838931

Epoch: 6| Step: 10
Training loss: 1.3307111263275146
Validation loss: 1.8000722598004084

Epoch: 6| Step: 11
Training loss: 2.0596799850463867
Validation loss: 1.8390490649848856

Epoch: 6| Step: 12
Training loss: 1.5626530647277832
Validation loss: 1.8192673575493596

Epoch: 6| Step: 13
Training loss: 0.929128110408783
Validation loss: 1.8889335240087202

Epoch: 295| Step: 0
Training loss: 1.205430269241333
Validation loss: 1.8141113455577562

Epoch: 6| Step: 1
Training loss: 1.2723870277404785
Validation loss: 1.8635557082391554

Epoch: 6| Step: 2
Training loss: 1.8817124366760254
Validation loss: 1.8307920014986427

Epoch: 6| Step: 3
Training loss: 1.2949680089950562
Validation loss: 1.8561021076735629

Epoch: 6| Step: 4
Training loss: 1.015344262123108
Validation loss: 1.8561481519411969

Epoch: 6| Step: 5
Training loss: 1.5508402585983276
Validation loss: 1.8409285288985058

Epoch: 6| Step: 6
Training loss: 1.8638031482696533
Validation loss: 1.8267774440908944

Epoch: 6| Step: 7
Training loss: 2.1229400634765625
Validation loss: 1.8685754486309585

Epoch: 6| Step: 8
Training loss: 1.1978487968444824
Validation loss: 1.9246923462037118

Epoch: 6| Step: 9
Training loss: 0.7927256226539612
Validation loss: 1.8572160120933288

Epoch: 6| Step: 10
Training loss: 1.2211551666259766
Validation loss: 1.8568645356803812

Epoch: 6| Step: 11
Training loss: 1.860194444656372
Validation loss: 1.8449596653702438

Epoch: 6| Step: 12
Training loss: 1.567908525466919
Validation loss: 1.8271949855230187

Epoch: 6| Step: 13
Training loss: 1.8649258613586426
Validation loss: 1.7837712226375457

Epoch: 296| Step: 0
Training loss: 1.5264840126037598
Validation loss: 1.7409914091069212

Epoch: 6| Step: 1
Training loss: 1.1852482557296753
Validation loss: 1.8393985417581373

Epoch: 6| Step: 2
Training loss: 0.9885207414627075
Validation loss: 1.86526245199224

Epoch: 6| Step: 3
Training loss: 1.7999248504638672
Validation loss: 1.7807498490938576

Epoch: 6| Step: 4
Training loss: 1.9409329891204834
Validation loss: 1.829870944382042

Epoch: 6| Step: 5
Training loss: 1.5900707244873047
Validation loss: 1.830861468468943

Epoch: 6| Step: 6
Training loss: 1.633103609085083
Validation loss: 1.8374838867495138

Epoch: 6| Step: 7
Training loss: 1.718932032585144
Validation loss: 1.826829933351086

Epoch: 6| Step: 8
Training loss: 1.566078543663025
Validation loss: 1.8163774321156163

Epoch: 6| Step: 9
Training loss: 0.8260785341262817
Validation loss: 1.8105732164075297

Epoch: 6| Step: 10
Training loss: 1.4509695768356323
Validation loss: 1.8565389622924149

Epoch: 6| Step: 11
Training loss: 1.8953182697296143
Validation loss: 1.8834747665671892

Epoch: 6| Step: 12
Training loss: 1.0293431282043457
Validation loss: 1.8669284466774232

Epoch: 6| Step: 13
Training loss: 1.4060931205749512
Validation loss: 1.8440942084917458

Epoch: 297| Step: 0
Training loss: 1.3300645351409912
Validation loss: 1.802702106455321

Epoch: 6| Step: 1
Training loss: 1.3025329113006592
Validation loss: 1.7915381769980154

Epoch: 6| Step: 2
Training loss: 1.7829874753952026
Validation loss: 1.8962533038149598

Epoch: 6| Step: 3
Training loss: 1.7526354789733887
Validation loss: 1.826242080298803

Epoch: 6| Step: 4
Training loss: 1.5486679077148438
Validation loss: 1.8479026671378844

Epoch: 6| Step: 5
Training loss: 1.3858182430267334
Validation loss: 1.8711850976431241

Epoch: 6| Step: 6
Training loss: 1.4899380207061768
Validation loss: 1.7968184614694247

Epoch: 6| Step: 7
Training loss: 1.4796823263168335
Validation loss: 1.8177063567664034

Epoch: 6| Step: 8
Training loss: 1.0399231910705566
Validation loss: 1.8486604793097383

Epoch: 6| Step: 9
Training loss: 0.8845954537391663
Validation loss: 1.817689384183576

Epoch: 6| Step: 10
Training loss: 1.2087247371673584
Validation loss: 1.8357917724117156

Epoch: 6| Step: 11
Training loss: 1.5835514068603516
Validation loss: 1.835115219957085

Epoch: 6| Step: 12
Training loss: 1.1607873439788818
Validation loss: 1.79086810029963

Epoch: 6| Step: 13
Training loss: 2.325617551803589
Validation loss: 1.8950699939522693

Epoch: 298| Step: 0
Training loss: 1.8096070289611816
Validation loss: 1.8054003305332635

Epoch: 6| Step: 1
Training loss: 1.8102561235427856
Validation loss: 1.827569064273629

Epoch: 6| Step: 2
Training loss: 1.697422981262207
Validation loss: 1.8661515353828348

Epoch: 6| Step: 3
Training loss: 1.112492322921753
Validation loss: 1.8134082235315794

Epoch: 6| Step: 4
Training loss: 1.4890142679214478
Validation loss: 1.8462755474992978

Epoch: 6| Step: 5
Training loss: 1.8894685506820679
Validation loss: 1.825282709572905

Epoch: 6| Step: 6
Training loss: 1.209272861480713
Validation loss: 1.7995680198874524

Epoch: 6| Step: 7
Training loss: 1.1698029041290283
Validation loss: 1.8277199460614113

Epoch: 6| Step: 8
Training loss: 1.384812831878662
Validation loss: 1.8019831616391417

Epoch: 6| Step: 9
Training loss: 1.2811174392700195
Validation loss: 1.8977357059396722

Epoch: 6| Step: 10
Training loss: 1.5472841262817383
Validation loss: 1.8522998415013796

Epoch: 6| Step: 11
Training loss: 1.9775723218917847
Validation loss: 1.8339571324727868

Epoch: 6| Step: 12
Training loss: 0.9699492454528809
Validation loss: 1.7740346693223523

Epoch: 6| Step: 13
Training loss: 0.9842807054519653
Validation loss: 1.8423495382390997

Epoch: 299| Step: 0
Training loss: 1.0513312816619873
Validation loss: 1.8389165350185928

Epoch: 6| Step: 1
Training loss: 1.350494623184204
Validation loss: 1.7910793981244486

Epoch: 6| Step: 2
Training loss: 1.4873157739639282
Validation loss: 1.8027414352663103

Epoch: 6| Step: 3
Training loss: 1.3387501239776611
Validation loss: 1.8654109034486996

Epoch: 6| Step: 4
Training loss: 1.5296821594238281
Validation loss: 1.8584434601568407

Epoch: 6| Step: 5
Training loss: 2.0340170860290527
Validation loss: 1.806570291519165

Epoch: 6| Step: 6
Training loss: 1.1828258037567139
Validation loss: 1.7993914414477605

Epoch: 6| Step: 7
Training loss: 1.576538324356079
Validation loss: 1.8897688683643137

Epoch: 6| Step: 8
Training loss: 1.423515796661377
Validation loss: 1.7845908211123558

Epoch: 6| Step: 9
Training loss: 1.8893964290618896
Validation loss: 1.8042932069429787

Epoch: 6| Step: 10
Training loss: 0.84954833984375
Validation loss: 1.799398878569244

Epoch: 6| Step: 11
Training loss: 2.183250904083252
Validation loss: 1.8140765236270042

Epoch: 6| Step: 12
Training loss: 1.1297069787979126
Validation loss: 1.8144761413656256

Epoch: 6| Step: 13
Training loss: 1.299325704574585
Validation loss: 1.8839435167210077

Epoch: 300| Step: 0
Training loss: 1.4686052799224854
Validation loss: 1.887509576735958

Epoch: 6| Step: 1
Training loss: 1.5439478158950806
Validation loss: 1.870768113802838

Epoch: 6| Step: 2
Training loss: 1.576066255569458
Validation loss: 1.876056667297117

Epoch: 6| Step: 3
Training loss: 1.8050997257232666
Validation loss: 1.8332539091828048

Epoch: 6| Step: 4
Training loss: 1.3593270778656006
Validation loss: 1.8704029642125612

Epoch: 6| Step: 5
Training loss: 1.4091506004333496
Validation loss: 1.8768605532184723

Epoch: 6| Step: 6
Training loss: 1.2369364500045776
Validation loss: 1.8852596936687347

Epoch: 6| Step: 7
Training loss: 1.8176558017730713
Validation loss: 1.8125217204452844

Epoch: 6| Step: 8
Training loss: 2.657684803009033
Validation loss: 1.8288582986400974

Epoch: 6| Step: 9
Training loss: 1.1099623441696167
Validation loss: 1.8393548304034817

Epoch: 6| Step: 10
Training loss: 0.8568975925445557
Validation loss: 1.8755965502031389

Epoch: 6| Step: 11
Training loss: 1.150592565536499
Validation loss: 1.794595629938187

Epoch: 6| Step: 12
Training loss: 1.151364803314209
Validation loss: 1.811185831664711

Epoch: 6| Step: 13
Training loss: 1.4009687900543213
Validation loss: 1.7850593815567672

Epoch: 301| Step: 0
Training loss: 1.2966948747634888
Validation loss: 1.828086450535764

Epoch: 6| Step: 1
Training loss: 1.231938123703003
Validation loss: 1.8147016968778384

Epoch: 6| Step: 2
Training loss: 1.4226300716400146
Validation loss: 1.8575468396627774

Epoch: 6| Step: 3
Training loss: 1.5241749286651611
Validation loss: 1.8765868730442499

Epoch: 6| Step: 4
Training loss: 1.205871343612671
Validation loss: 1.8934097828403595

Epoch: 6| Step: 5
Training loss: 1.131387710571289
Validation loss: 1.84360368533801

Epoch: 6| Step: 6
Training loss: 1.3100316524505615
Validation loss: 1.8652668973451019

Epoch: 6| Step: 7
Training loss: 1.3423268795013428
Validation loss: 1.8502063071855934

Epoch: 6| Step: 8
Training loss: 0.9701603651046753
Validation loss: 1.8056238543602727

Epoch: 6| Step: 9
Training loss: 2.10744047164917
Validation loss: 1.8398020485396027

Epoch: 6| Step: 10
Training loss: 2.1155319213867188
Validation loss: 1.802856542730844

Epoch: 6| Step: 11
Training loss: 1.9204875230789185
Validation loss: 1.7929198511185185

Epoch: 6| Step: 12
Training loss: 1.3114902973175049
Validation loss: 1.805570924153892

Epoch: 6| Step: 13
Training loss: 1.0570069551467896
Validation loss: 1.8697100134306057

Epoch: 302| Step: 0
Training loss: 0.9193387031555176
Validation loss: 1.8328289242200955

Epoch: 6| Step: 1
Training loss: 1.048957347869873
Validation loss: 1.8519360788406865

Epoch: 6| Step: 2
Training loss: 1.4441399574279785
Validation loss: 1.7895105192738194

Epoch: 6| Step: 3
Training loss: 1.7754544019699097
Validation loss: 1.8390020580701931

Epoch: 6| Step: 4
Training loss: 1.5646839141845703
Validation loss: 1.820456971404373

Epoch: 6| Step: 5
Training loss: 2.0815064907073975
Validation loss: 1.913272862793297

Epoch: 6| Step: 6
Training loss: 2.0720419883728027
Validation loss: 1.8140276196182414

Epoch: 6| Step: 7
Training loss: 1.45890474319458
Validation loss: 1.9294693572546846

Epoch: 6| Step: 8
Training loss: 1.4522559642791748
Validation loss: 1.8332100055551017

Epoch: 6| Step: 9
Training loss: 1.6275904178619385
Validation loss: 1.8846762257237588

Epoch: 6| Step: 10
Training loss: 1.3624827861785889
Validation loss: 1.9015825794589134

Epoch: 6| Step: 11
Training loss: 0.8558775186538696
Validation loss: 1.8910122353543517

Epoch: 6| Step: 12
Training loss: 1.1330387592315674
Validation loss: 1.8151500827522689

Epoch: 6| Step: 13
Training loss: 1.4977668523788452
Validation loss: 1.7944845255985056

Epoch: 303| Step: 0
Training loss: 1.9381065368652344
Validation loss: 1.8013839349951795

Epoch: 6| Step: 1
Training loss: 1.2690837383270264
Validation loss: 1.8248950717269734

Epoch: 6| Step: 2
Training loss: 1.2541935443878174
Validation loss: 1.791347683116954

Epoch: 6| Step: 3
Training loss: 1.6387856006622314
Validation loss: 1.8133123651627572

Epoch: 6| Step: 4
Training loss: 1.2401065826416016
Validation loss: 1.7857041820403068

Epoch: 6| Step: 5
Training loss: 2.2818455696105957
Validation loss: 1.7950705405204528

Epoch: 6| Step: 6
Training loss: 0.8594861030578613
Validation loss: 1.8470308883215791

Epoch: 6| Step: 7
Training loss: 1.6584203243255615
Validation loss: 1.8347736814970612

Epoch: 6| Step: 8
Training loss: 0.9933738708496094
Validation loss: 1.7986690575076687

Epoch: 6| Step: 9
Training loss: 1.4770216941833496
Validation loss: 1.8178652307038665

Epoch: 6| Step: 10
Training loss: 1.147560477256775
Validation loss: 1.8691690416746243

Epoch: 6| Step: 11
Training loss: 1.6380244493484497
Validation loss: 1.7740882071115638

Epoch: 6| Step: 12
Training loss: 1.3682154417037964
Validation loss: 1.831370476753481

Epoch: 6| Step: 13
Training loss: 1.9366391897201538
Validation loss: 1.8366031275000623

Epoch: 304| Step: 0
Training loss: 1.4838933944702148
Validation loss: 1.789022308523937

Epoch: 6| Step: 1
Training loss: 1.435265302658081
Validation loss: 1.8225312925154162

Epoch: 6| Step: 2
Training loss: 1.4219169616699219
Validation loss: 1.788516826527093

Epoch: 6| Step: 3
Training loss: 1.6568515300750732
Validation loss: 1.8341663255486438

Epoch: 6| Step: 4
Training loss: 1.4738481044769287
Validation loss: 1.8484916225556405

Epoch: 6| Step: 5
Training loss: 1.3615834712982178
Validation loss: 1.8559437605642504

Epoch: 6| Step: 6
Training loss: 1.16717529296875
Validation loss: 1.8779410905735467

Epoch: 6| Step: 7
Training loss: 1.7491278648376465
Validation loss: 1.8658656010063746

Epoch: 6| Step: 8
Training loss: 1.657981276512146
Validation loss: 1.8968496591814104

Epoch: 6| Step: 9
Training loss: 2.1773388385772705
Validation loss: 1.9000707954488776

Epoch: 6| Step: 10
Training loss: 1.32310950756073
Validation loss: 1.8653969521163611

Epoch: 6| Step: 11
Training loss: 1.3128557205200195
Validation loss: 1.9123582058055426

Epoch: 6| Step: 12
Training loss: 1.0564087629318237
Validation loss: 1.8772222585575555

Epoch: 6| Step: 13
Training loss: 0.4119738042354584
Validation loss: 1.857556123887339

Epoch: 305| Step: 0
Training loss: 1.6116881370544434
Validation loss: 1.8139423606216267

Epoch: 6| Step: 1
Training loss: 1.3093926906585693
Validation loss: 1.8849573545558478

Epoch: 6| Step: 2
Training loss: 1.3835166692733765
Validation loss: 1.84916349123883

Epoch: 6| Step: 3
Training loss: 1.6577208042144775
Validation loss: 1.76816100458945

Epoch: 6| Step: 4
Training loss: 1.6619484424591064
Validation loss: 1.8176740356670913

Epoch: 6| Step: 5
Training loss: 2.0358693599700928
Validation loss: 1.7772830916989235

Epoch: 6| Step: 6
Training loss: 1.6888291835784912
Validation loss: 1.79417710919534

Epoch: 6| Step: 7
Training loss: 1.554699420928955
Validation loss: 1.8229258752638293

Epoch: 6| Step: 8
Training loss: 1.418823003768921
Validation loss: 1.799234288994984

Epoch: 6| Step: 9
Training loss: 0.9801744818687439
Validation loss: 1.8152362813231766

Epoch: 6| Step: 10
Training loss: 1.458223581314087
Validation loss: 1.7819028797970022

Epoch: 6| Step: 11
Training loss: 1.2848126888275146
Validation loss: 1.825376223492366

Epoch: 6| Step: 12
Training loss: 0.9163393378257751
Validation loss: 1.7818318259331487

Epoch: 6| Step: 13
Training loss: 1.415805459022522
Validation loss: 1.8038207292556763

Epoch: 306| Step: 0
Training loss: 0.9213576316833496
Validation loss: 1.8396142528903099

Epoch: 6| Step: 1
Training loss: 1.085920810699463
Validation loss: 1.8685325102139545

Epoch: 6| Step: 2
Training loss: 1.4938075542449951
Validation loss: 1.8687018784143592

Epoch: 6| Step: 3
Training loss: 1.5173413753509521
Validation loss: 1.8506829007979362

Epoch: 6| Step: 4
Training loss: 1.4121456146240234
Validation loss: 1.8582678892279183

Epoch: 6| Step: 5
Training loss: 1.3894803524017334
Validation loss: 1.8447909970437326

Epoch: 6| Step: 6
Training loss: 1.5635898113250732
Validation loss: 1.8078124177071355

Epoch: 6| Step: 7
Training loss: 1.1019749641418457
Validation loss: 1.8754066139139154

Epoch: 6| Step: 8
Training loss: 1.9287954568862915
Validation loss: 1.8284367771558865

Epoch: 6| Step: 9
Training loss: 1.3665211200714111
Validation loss: 1.811127584467652

Epoch: 6| Step: 10
Training loss: 1.6093112230300903
Validation loss: 1.8134465038135488

Epoch: 6| Step: 11
Training loss: 1.3613749742507935
Validation loss: 1.7739787742655764

Epoch: 6| Step: 12
Training loss: 1.5981082916259766
Validation loss: 1.8273242878657516

Epoch: 6| Step: 13
Training loss: 1.3331495523452759
Validation loss: 1.8373634199942313

Epoch: 307| Step: 0
Training loss: 1.0869054794311523
Validation loss: 1.8240332193272089

Epoch: 6| Step: 1
Training loss: 1.1554197072982788
Validation loss: 1.7917705274397326

Epoch: 6| Step: 2
Training loss: 1.4089314937591553
Validation loss: 1.7992436424378426

Epoch: 6| Step: 3
Training loss: 1.529475212097168
Validation loss: 1.8146173979646416

Epoch: 6| Step: 4
Training loss: 1.4396841526031494
Validation loss: 1.8051941548624346

Epoch: 6| Step: 5
Training loss: 1.5772435665130615
Validation loss: 1.8197852847396687

Epoch: 6| Step: 6
Training loss: 1.4321116209030151
Validation loss: 1.7860731578642322

Epoch: 6| Step: 7
Training loss: 1.2708094120025635
Validation loss: 1.7796722458254906

Epoch: 6| Step: 8
Training loss: 1.5830421447753906
Validation loss: 1.8491332543793546

Epoch: 6| Step: 9
Training loss: 1.377612829208374
Validation loss: 1.8559780428486485

Epoch: 6| Step: 10
Training loss: 1.8705416917800903
Validation loss: 1.8062372207641602

Epoch: 6| Step: 11
Training loss: 1.3472645282745361
Validation loss: 1.8542776556425198

Epoch: 6| Step: 12
Training loss: 1.712684988975525
Validation loss: 1.829306182040963

Epoch: 6| Step: 13
Training loss: 1.0865228176116943
Validation loss: 1.8187745694191224

Epoch: 308| Step: 0
Training loss: 1.611952304840088
Validation loss: 1.8430347724627423

Epoch: 6| Step: 1
Training loss: 2.3282723426818848
Validation loss: 1.8546797819035028

Epoch: 6| Step: 2
Training loss: 0.9803133010864258
Validation loss: 1.841870952677983

Epoch: 6| Step: 3
Training loss: 2.0456326007843018
Validation loss: 1.8206803914039367

Epoch: 6| Step: 4
Training loss: 1.4339888095855713
Validation loss: 1.828826004459012

Epoch: 6| Step: 5
Training loss: 0.9550263285636902
Validation loss: 1.848416147693511

Epoch: 6| Step: 6
Training loss: 1.0792677402496338
Validation loss: 1.8938401873393724

Epoch: 6| Step: 7
Training loss: 0.564383864402771
Validation loss: 1.899186006156347

Epoch: 6| Step: 8
Training loss: 1.6283998489379883
Validation loss: 1.869111317460255

Epoch: 6| Step: 9
Training loss: 1.6846786737442017
Validation loss: 1.8303593845777615

Epoch: 6| Step: 10
Training loss: 1.222921371459961
Validation loss: 1.8665867428625784

Epoch: 6| Step: 11
Training loss: 1.2044641971588135
Validation loss: 1.8284590321202432

Epoch: 6| Step: 12
Training loss: 1.2425612211227417
Validation loss: 1.8730114083136282

Epoch: 6| Step: 13
Training loss: 1.8775575160980225
Validation loss: 1.8086020010773853

Epoch: 309| Step: 0
Training loss: 1.5853965282440186
Validation loss: 1.7982316440151584

Epoch: 6| Step: 1
Training loss: 1.9083267450332642
Validation loss: 1.801959204417403

Epoch: 6| Step: 2
Training loss: 1.349161148071289
Validation loss: 1.7822918404815018

Epoch: 6| Step: 3
Training loss: 1.3549673557281494
Validation loss: 1.8330875058327951

Epoch: 6| Step: 4
Training loss: 1.8547656536102295
Validation loss: 1.7868738251347696

Epoch: 6| Step: 5
Training loss: 0.8949455618858337
Validation loss: 1.811289692437777

Epoch: 6| Step: 6
Training loss: 1.458780288696289
Validation loss: 1.8471754994443668

Epoch: 6| Step: 7
Training loss: 1.410484790802002
Validation loss: 1.8471665792567755

Epoch: 6| Step: 8
Training loss: 1.2050738334655762
Validation loss: 1.8224910805302281

Epoch: 6| Step: 9
Training loss: 1.8212310075759888
Validation loss: 1.8461563318006453

Epoch: 6| Step: 10
Training loss: 1.4850107431411743
Validation loss: 1.8633735859265892

Epoch: 6| Step: 11
Training loss: 1.2688195705413818
Validation loss: 1.8384039709644933

Epoch: 6| Step: 12
Training loss: 1.1280109882354736
Validation loss: 1.8585670712173625

Epoch: 6| Step: 13
Training loss: 1.4154362678527832
Validation loss: 1.8959512684934883

Epoch: 310| Step: 0
Training loss: 1.4393600225448608
Validation loss: 1.8784007692849765

Epoch: 6| Step: 1
Training loss: 1.4220935106277466
Validation loss: 1.850853914855629

Epoch: 6| Step: 2
Training loss: 1.8919353485107422
Validation loss: 1.853272271412675

Epoch: 6| Step: 3
Training loss: 1.2475249767303467
Validation loss: 1.836210899455573

Epoch: 6| Step: 4
Training loss: 1.3143048286437988
Validation loss: 1.8342537149306266

Epoch: 6| Step: 5
Training loss: 1.5020968914031982
Validation loss: 1.8346808482241888

Epoch: 6| Step: 6
Training loss: 1.3470276594161987
Validation loss: 1.7939403057098389

Epoch: 6| Step: 7
Training loss: 1.5925815105438232
Validation loss: 1.8607989882910123

Epoch: 6| Step: 8
Training loss: 1.3985490798950195
Validation loss: 1.808415589794036

Epoch: 6| Step: 9
Training loss: 1.2332892417907715
Validation loss: 1.8485229963897376

Epoch: 6| Step: 10
Training loss: 1.1500848531723022
Validation loss: 1.7769425171677784

Epoch: 6| Step: 11
Training loss: 1.5408117771148682
Validation loss: 1.7749559097392584

Epoch: 6| Step: 12
Training loss: 1.3627073764801025
Validation loss: 1.8405812517289193

Epoch: 6| Step: 13
Training loss: 0.7438564896583557
Validation loss: 1.8404878929097166

Epoch: 311| Step: 0
Training loss: 1.1771774291992188
Validation loss: 1.8630174975241385

Epoch: 6| Step: 1
Training loss: 1.2329961061477661
Validation loss: 1.8664342395720943

Epoch: 6| Step: 2
Training loss: 1.1312360763549805
Validation loss: 1.847435712814331

Epoch: 6| Step: 3
Training loss: 1.2252840995788574
Validation loss: 1.8393154516015002

Epoch: 6| Step: 4
Training loss: 1.276268720626831
Validation loss: 1.9117524854598507

Epoch: 6| Step: 5
Training loss: 1.315011739730835
Validation loss: 1.8390456758519655

Epoch: 6| Step: 6
Training loss: 1.411461591720581
Validation loss: 1.8340639696326306

Epoch: 6| Step: 7
Training loss: 1.6832754611968994
Validation loss: 1.8421039042934295

Epoch: 6| Step: 8
Training loss: 0.9717985391616821
Validation loss: 1.8445911856107815

Epoch: 6| Step: 9
Training loss: 2.505059003829956
Validation loss: 1.8046896085944226

Epoch: 6| Step: 10
Training loss: 1.9933594465255737
Validation loss: 1.8564526163121706

Epoch: 6| Step: 11
Training loss: 1.2275984287261963
Validation loss: 1.847869598737327

Epoch: 6| Step: 12
Training loss: 1.545182228088379
Validation loss: 1.831410393919996

Epoch: 6| Step: 13
Training loss: 0.6285464763641357
Validation loss: 1.7880484032374557

Epoch: 312| Step: 0
Training loss: 1.220202922821045
Validation loss: 1.8557819140854703

Epoch: 6| Step: 1
Training loss: 1.8726422786712646
Validation loss: 1.866916105311404

Epoch: 6| Step: 2
Training loss: 1.0624537467956543
Validation loss: 1.824316765672417

Epoch: 6| Step: 3
Training loss: 0.9939164519309998
Validation loss: 1.8397612956262404

Epoch: 6| Step: 4
Training loss: 1.1029527187347412
Validation loss: 1.8199469812454716

Epoch: 6| Step: 5
Training loss: 1.679175615310669
Validation loss: 1.860584379524313

Epoch: 6| Step: 6
Training loss: 1.4516143798828125
Validation loss: 1.8349244966301868

Epoch: 6| Step: 7
Training loss: 1.2478712797164917
Validation loss: 1.8580093153061406

Epoch: 6| Step: 8
Training loss: 1.8695600032806396
Validation loss: 1.8726410186418923

Epoch: 6| Step: 9
Training loss: 1.7029308080673218
Validation loss: 1.8280295569409606

Epoch: 6| Step: 10
Training loss: 1.356161117553711
Validation loss: 1.8286780413760935

Epoch: 6| Step: 11
Training loss: 1.3815864324569702
Validation loss: 1.7703857447511406

Epoch: 6| Step: 12
Training loss: 1.591078519821167
Validation loss: 1.8311079471342024

Epoch: 6| Step: 13
Training loss: 1.3526009321212769
Validation loss: 1.7951450886264924

Epoch: 313| Step: 0
Training loss: 1.0032795667648315
Validation loss: 1.7900407634755617

Epoch: 6| Step: 1
Training loss: 1.0295720100402832
Validation loss: 1.7956292065241004

Epoch: 6| Step: 2
Training loss: 0.8843238353729248
Validation loss: 1.7809594728613412

Epoch: 6| Step: 3
Training loss: 2.0750834941864014
Validation loss: 1.7961853934872536

Epoch: 6| Step: 4
Training loss: 2.248908519744873
Validation loss: 1.799023271888815

Epoch: 6| Step: 5
Training loss: 1.0760226249694824
Validation loss: 1.8437134053117485

Epoch: 6| Step: 6
Training loss: 1.3096959590911865
Validation loss: 1.8128878326826199

Epoch: 6| Step: 7
Training loss: 1.478672981262207
Validation loss: 1.874839077713669

Epoch: 6| Step: 8
Training loss: 1.4226435422897339
Validation loss: 1.885813695128246

Epoch: 6| Step: 9
Training loss: 1.4273316860198975
Validation loss: 1.8567124284723753

Epoch: 6| Step: 10
Training loss: 1.1969678401947021
Validation loss: 1.8823419629886586

Epoch: 6| Step: 11
Training loss: 2.024252414703369
Validation loss: 1.8665852597964707

Epoch: 6| Step: 12
Training loss: 1.1518361568450928
Validation loss: 1.8413673870025142

Epoch: 6| Step: 13
Training loss: 1.4256137609481812
Validation loss: 1.8822321776420838

Epoch: 314| Step: 0
Training loss: 1.066590666770935
Validation loss: 1.8591975883771015

Epoch: 6| Step: 1
Training loss: 1.6839656829833984
Validation loss: 1.8159365154081775

Epoch: 6| Step: 2
Training loss: 1.4749946594238281
Validation loss: 1.838983202493319

Epoch: 6| Step: 3
Training loss: 1.0124537944793701
Validation loss: 1.8449498735448366

Epoch: 6| Step: 4
Training loss: 1.4546430110931396
Validation loss: 1.8023004531860352

Epoch: 6| Step: 5
Training loss: 1.5233842134475708
Validation loss: 1.812902460816086

Epoch: 6| Step: 6
Training loss: 2.0391736030578613
Validation loss: 1.8073797059315506

Epoch: 6| Step: 7
Training loss: 2.3396525382995605
Validation loss: 1.857426921526591

Epoch: 6| Step: 8
Training loss: 1.7344765663146973
Validation loss: 1.7984491509775962

Epoch: 6| Step: 9
Training loss: 1.531093955039978
Validation loss: 1.8230607612158662

Epoch: 6| Step: 10
Training loss: 1.0714176893234253
Validation loss: 1.8186027016690982

Epoch: 6| Step: 11
Training loss: 0.8888057470321655
Validation loss: 1.8658053900605889

Epoch: 6| Step: 12
Training loss: 0.7547529935836792
Validation loss: 1.8349113413082656

Epoch: 6| Step: 13
Training loss: 1.0673006772994995
Validation loss: 1.7946967719703593

Epoch: 315| Step: 0
Training loss: 1.780527949333191
Validation loss: 1.8252806278967089

Epoch: 6| Step: 1
Training loss: 1.0340155363082886
Validation loss: 1.8207061906014719

Epoch: 6| Step: 2
Training loss: 1.012380599975586
Validation loss: 1.7934121598479569

Epoch: 6| Step: 3
Training loss: 0.9853129386901855
Validation loss: 1.7958181058206866

Epoch: 6| Step: 4
Training loss: 1.1081510782241821
Validation loss: 1.8706235808710898

Epoch: 6| Step: 5
Training loss: 0.6860910654067993
Validation loss: 1.7545658029535764

Epoch: 6| Step: 6
Training loss: 1.2993242740631104
Validation loss: 1.8061930517996512

Epoch: 6| Step: 7
Training loss: 1.9807636737823486
Validation loss: 1.7871811812923801

Epoch: 6| Step: 8
Training loss: 1.2000515460968018
Validation loss: 1.7512869834899902

Epoch: 6| Step: 9
Training loss: 1.9818549156188965
Validation loss: 1.787567820600284

Epoch: 6| Step: 10
Training loss: 1.3956608772277832
Validation loss: 1.8473310624399493

Epoch: 6| Step: 11
Training loss: 1.339907169342041
Validation loss: 1.8344983272655035

Epoch: 6| Step: 12
Training loss: 1.8652238845825195
Validation loss: 1.8400350950097526

Epoch: 6| Step: 13
Training loss: 2.0336217880249023
Validation loss: 1.8340557236825266

Epoch: 316| Step: 0
Training loss: 1.1188771724700928
Validation loss: 1.7985552228907102

Epoch: 6| Step: 1
Training loss: 1.5663317441940308
Validation loss: 1.8869113704209686

Epoch: 6| Step: 2
Training loss: 0.899358868598938
Validation loss: 1.8746336301167805

Epoch: 6| Step: 3
Training loss: 1.177875280380249
Validation loss: 1.7816582290075158

Epoch: 6| Step: 4
Training loss: 1.488999605178833
Validation loss: 1.8424803287752214

Epoch: 6| Step: 5
Training loss: 1.6360857486724854
Validation loss: 1.834474435416601

Epoch: 6| Step: 6
Training loss: 1.8536089658737183
Validation loss: 1.9148751894632976

Epoch: 6| Step: 7
Training loss: 1.601958990097046
Validation loss: 1.839268094749861

Epoch: 6| Step: 8
Training loss: 1.712965965270996
Validation loss: 1.8728706887973252

Epoch: 6| Step: 9
Training loss: 1.5426115989685059
Validation loss: 1.8117887332875242

Epoch: 6| Step: 10
Training loss: 1.3576709032058716
Validation loss: 1.9067591031392415

Epoch: 6| Step: 11
Training loss: 1.2485558986663818
Validation loss: 1.8876155243125012

Epoch: 6| Step: 12
Training loss: 1.2322313785552979
Validation loss: 1.8970181813804052

Epoch: 6| Step: 13
Training loss: 1.1027077436447144
Validation loss: 1.8515788329544889

Epoch: 317| Step: 0
Training loss: 1.5207281112670898
Validation loss: 1.863169539359308

Epoch: 6| Step: 1
Training loss: 1.4004950523376465
Validation loss: 1.813664520940473

Epoch: 6| Step: 2
Training loss: 1.7913482189178467
Validation loss: 1.7939336710078742

Epoch: 6| Step: 3
Training loss: 1.475990891456604
Validation loss: 1.8122227755925988

Epoch: 6| Step: 4
Training loss: 1.303657054901123
Validation loss: 1.798875839479508

Epoch: 6| Step: 5
Training loss: 1.153490662574768
Validation loss: 1.7963547386148924

Epoch: 6| Step: 6
Training loss: 1.5552513599395752
Validation loss: 1.8306338210259714

Epoch: 6| Step: 7
Training loss: 1.5229941606521606
Validation loss: 1.7697338993831346

Epoch: 6| Step: 8
Training loss: 0.9809836149215698
Validation loss: 1.8109247710115166

Epoch: 6| Step: 9
Training loss: 1.5984492301940918
Validation loss: 1.802893897538544

Epoch: 6| Step: 10
Training loss: 1.5076345205307007
Validation loss: 1.8272813289396224

Epoch: 6| Step: 11
Training loss: 0.8198590874671936
Validation loss: 1.7930066713722803

Epoch: 6| Step: 12
Training loss: 1.9797908067703247
Validation loss: 1.8622981066344886

Epoch: 6| Step: 13
Training loss: 0.5943260192871094
Validation loss: 1.8493180838964318

Epoch: 318| Step: 0
Training loss: 0.8926922082901001
Validation loss: 1.8383802265249274

Epoch: 6| Step: 1
Training loss: 2.472360610961914
Validation loss: 1.8688898612094182

Epoch: 6| Step: 2
Training loss: 1.367851734161377
Validation loss: 1.805214640914753

Epoch: 6| Step: 3
Training loss: 1.4586527347564697
Validation loss: 1.8182495665806595

Epoch: 6| Step: 4
Training loss: 1.173079252243042
Validation loss: 1.8024201534127677

Epoch: 6| Step: 5
Training loss: 1.1361503601074219
Validation loss: 1.7833886582364318

Epoch: 6| Step: 6
Training loss: 1.243678331375122
Validation loss: 1.7862236845877864

Epoch: 6| Step: 7
Training loss: 1.0457059144973755
Validation loss: 1.8598266493889593

Epoch: 6| Step: 8
Training loss: 1.6792716979980469
Validation loss: 1.810208958964194

Epoch: 6| Step: 9
Training loss: 1.1243655681610107
Validation loss: 1.8662381402907833

Epoch: 6| Step: 10
Training loss: 1.6632883548736572
Validation loss: 1.8748675289974417

Epoch: 6| Step: 11
Training loss: 1.5269410610198975
Validation loss: 1.7798397758955598

Epoch: 6| Step: 12
Training loss: 1.011083960533142
Validation loss: 1.8726734730505175

Epoch: 6| Step: 13
Training loss: 2.010981321334839
Validation loss: 1.8526363308711717

Epoch: 319| Step: 0
Training loss: 1.5894184112548828
Validation loss: 1.804974937951693

Epoch: 6| Step: 1
Training loss: 0.6828302145004272
Validation loss: 1.8192921774361723

Epoch: 6| Step: 2
Training loss: 1.766672968864441
Validation loss: 1.8907594296240038

Epoch: 6| Step: 3
Training loss: 1.0853452682495117
Validation loss: 1.8838836557121688

Epoch: 6| Step: 4
Training loss: 1.257775902748108
Validation loss: 1.8289690043336602

Epoch: 6| Step: 5
Training loss: 2.0355968475341797
Validation loss: 1.8643324810971496

Epoch: 6| Step: 6
Training loss: 1.1559116840362549
Validation loss: 1.8197710949887511

Epoch: 6| Step: 7
Training loss: 1.9207912683486938
Validation loss: 1.8527937550698557

Epoch: 6| Step: 8
Training loss: 0.6199619174003601
Validation loss: 1.8225438530727098

Epoch: 6| Step: 9
Training loss: 1.5499088764190674
Validation loss: 1.8436841054629254

Epoch: 6| Step: 10
Training loss: 1.2120455503463745
Validation loss: 1.84641767573613

Epoch: 6| Step: 11
Training loss: 1.8392385244369507
Validation loss: 1.7567403444679834

Epoch: 6| Step: 12
Training loss: 0.8724044561386108
Validation loss: 1.797092681290001

Epoch: 6| Step: 13
Training loss: 1.9327272176742554
Validation loss: 1.8325002577997023

Epoch: 320| Step: 0
Training loss: 1.1723456382751465
Validation loss: 1.8214513704340944

Epoch: 6| Step: 1
Training loss: 1.9107704162597656
Validation loss: 1.8641994012299405

Epoch: 6| Step: 2
Training loss: 1.0965887308120728
Validation loss: 1.883702157646097

Epoch: 6| Step: 3
Training loss: 1.7025686502456665
Validation loss: 1.8259562292406637

Epoch: 6| Step: 4
Training loss: 1.4397670030593872
Validation loss: 1.8768526700235182

Epoch: 6| Step: 5
Training loss: 1.2632135152816772
Validation loss: 1.867159064098071

Epoch: 6| Step: 6
Training loss: 1.3624569177627563
Validation loss: 1.8659578702783073

Epoch: 6| Step: 7
Training loss: 1.2513692378997803
Validation loss: 1.8246280224092546

Epoch: 6| Step: 8
Training loss: 1.1596148014068604
Validation loss: 1.8457848769362255

Epoch: 6| Step: 9
Training loss: 1.6850268840789795
Validation loss: 1.8857310587360012

Epoch: 6| Step: 10
Training loss: 1.4671776294708252
Validation loss: 1.861464117162971

Epoch: 6| Step: 11
Training loss: 1.2091050148010254
Validation loss: 1.8812826564235072

Epoch: 6| Step: 12
Training loss: 1.0039284229278564
Validation loss: 1.903900481039478

Epoch: 6| Step: 13
Training loss: 1.2757892608642578
Validation loss: 1.8170014555736254

Epoch: 321| Step: 0
Training loss: 1.3022533655166626
Validation loss: 1.8075482140305221

Epoch: 6| Step: 1
Training loss: 1.8750630617141724
Validation loss: 1.843142947842998

Epoch: 6| Step: 2
Training loss: 1.1842546463012695
Validation loss: 1.8299830895598217

Epoch: 6| Step: 3
Training loss: 1.344775676727295
Validation loss: 1.7886455981962142

Epoch: 6| Step: 4
Training loss: 1.5233436822891235
Validation loss: 1.78266107010585

Epoch: 6| Step: 5
Training loss: 1.0841948986053467
Validation loss: 1.8312291957998788

Epoch: 6| Step: 6
Training loss: 1.4512510299682617
Validation loss: 1.8196573488173946

Epoch: 6| Step: 7
Training loss: 1.8777042627334595
Validation loss: 1.8774354816764913

Epoch: 6| Step: 8
Training loss: 0.9187647104263306
Validation loss: 1.83375374860661

Epoch: 6| Step: 9
Training loss: 1.466071367263794
Validation loss: 1.8086525752980223

Epoch: 6| Step: 10
Training loss: 1.7330267429351807
Validation loss: 1.7528641685362785

Epoch: 6| Step: 11
Training loss: 0.9882177114486694
Validation loss: 1.7886458340511526

Epoch: 6| Step: 12
Training loss: 0.9128561019897461
Validation loss: 1.7790330661240445

Epoch: 6| Step: 13
Training loss: 1.8100640773773193
Validation loss: 1.8154971009941512

Epoch: 322| Step: 0
Training loss: 1.423608422279358
Validation loss: 1.7679308050422258

Epoch: 6| Step: 1
Training loss: 1.4622418880462646
Validation loss: 1.8455168303622995

Epoch: 6| Step: 2
Training loss: 0.9843378663063049
Validation loss: 1.9084475758255168

Epoch: 6| Step: 3
Training loss: 0.91106116771698
Validation loss: 1.824159183809834

Epoch: 6| Step: 4
Training loss: 1.1433088779449463
Validation loss: 1.845208885849163

Epoch: 6| Step: 5
Training loss: 1.7562894821166992
Validation loss: 1.8414847389344247

Epoch: 6| Step: 6
Training loss: 1.5143673419952393
Validation loss: 1.9067148136836227

Epoch: 6| Step: 7
Training loss: 1.7217960357666016
Validation loss: 1.8884663671575568

Epoch: 6| Step: 8
Training loss: 1.475294589996338
Validation loss: 1.8731462263291883

Epoch: 6| Step: 9
Training loss: 1.3264799118041992
Validation loss: 1.8799891394953574

Epoch: 6| Step: 10
Training loss: 1.173740029335022
Validation loss: 1.8341002579658263

Epoch: 6| Step: 11
Training loss: 1.2943834066390991
Validation loss: 1.8790033671163744

Epoch: 6| Step: 12
Training loss: 1.7356693744659424
Validation loss: 1.8184206331929853

Epoch: 6| Step: 13
Training loss: 1.3303875923156738
Validation loss: 1.8188245014477802

Epoch: 323| Step: 0
Training loss: 0.9478271007537842
Validation loss: 1.7698239498240973

Epoch: 6| Step: 1
Training loss: 1.4536179304122925
Validation loss: 1.7871339192954443

Epoch: 6| Step: 2
Training loss: 1.0880130529403687
Validation loss: 1.7981358330736879

Epoch: 6| Step: 3
Training loss: 1.5864678621292114
Validation loss: 1.8053379199838127

Epoch: 6| Step: 4
Training loss: 1.7611926794052124
Validation loss: 1.8077545524925314

Epoch: 6| Step: 5
Training loss: 1.5314464569091797
Validation loss: 1.8368396489850936

Epoch: 6| Step: 6
Training loss: 1.5140540599822998
Validation loss: 1.7923734957172024

Epoch: 6| Step: 7
Training loss: 1.2221500873565674
Validation loss: 1.8250570425423243

Epoch: 6| Step: 8
Training loss: 1.2518796920776367
Validation loss: 1.8246650644527969

Epoch: 6| Step: 9
Training loss: 1.5181312561035156
Validation loss: 1.8093510302164222

Epoch: 6| Step: 10
Training loss: 1.1325247287750244
Validation loss: 1.7840050240998626

Epoch: 6| Step: 11
Training loss: 1.5987714529037476
Validation loss: 1.808279287430548

Epoch: 6| Step: 12
Training loss: 1.4282734394073486
Validation loss: 1.7673006775558635

Epoch: 6| Step: 13
Training loss: 0.8362537026405334
Validation loss: 1.7901423836267123

Epoch: 324| Step: 0
Training loss: 1.4911224842071533
Validation loss: 1.8202509316064979

Epoch: 6| Step: 1
Training loss: 0.7842220067977905
Validation loss: 1.8363222037592242

Epoch: 6| Step: 2
Training loss: 1.293199062347412
Validation loss: 1.7376000778649443

Epoch: 6| Step: 3
Training loss: 1.2097197771072388
Validation loss: 1.8407533014974287

Epoch: 6| Step: 4
Training loss: 1.4821205139160156
Validation loss: 1.8205271946486605

Epoch: 6| Step: 5
Training loss: 1.1657214164733887
Validation loss: 1.876048864856843

Epoch: 6| Step: 6
Training loss: 1.7976775169372559
Validation loss: 1.8322649309712071

Epoch: 6| Step: 7
Training loss: 1.6441442966461182
Validation loss: 1.8337242167483094

Epoch: 6| Step: 8
Training loss: 1.2994964122772217
Validation loss: 1.8690951947242982

Epoch: 6| Step: 9
Training loss: 1.426612377166748
Validation loss: 1.8673312100031043

Epoch: 6| Step: 10
Training loss: 1.1992090940475464
Validation loss: 1.838583952637129

Epoch: 6| Step: 11
Training loss: 1.2881900072097778
Validation loss: 1.7889165557840818

Epoch: 6| Step: 12
Training loss: 1.7014106512069702
Validation loss: 1.7883300832522813

Epoch: 6| Step: 13
Training loss: 1.237886905670166
Validation loss: 1.795519939032934

Epoch: 325| Step: 0
Training loss: 0.6665455102920532
Validation loss: 1.7785946464025846

Epoch: 6| Step: 1
Training loss: 1.6458587646484375
Validation loss: 1.87578413819754

Epoch: 6| Step: 2
Training loss: 1.8593350648880005
Validation loss: 1.8663153776558496

Epoch: 6| Step: 3
Training loss: 1.3230705261230469
Validation loss: 1.7661181790854341

Epoch: 6| Step: 4
Training loss: 1.8157377243041992
Validation loss: 1.7955617058661677

Epoch: 6| Step: 5
Training loss: 1.0040922164916992
Validation loss: 1.8092840538229993

Epoch: 6| Step: 6
Training loss: 1.0578217506408691
Validation loss: 1.7984503956251248

Epoch: 6| Step: 7
Training loss: 1.1508996486663818
Validation loss: 1.7585570068769558

Epoch: 6| Step: 8
Training loss: 1.0789823532104492
Validation loss: 1.8737092018127441

Epoch: 6| Step: 9
Training loss: 1.6531769037246704
Validation loss: 1.8127362189754364

Epoch: 6| Step: 10
Training loss: 1.6430598497390747
Validation loss: 1.864403505479136

Epoch: 6| Step: 11
Training loss: 1.4646177291870117
Validation loss: 1.794395718523251

Epoch: 6| Step: 12
Training loss: 1.6995192766189575
Validation loss: 1.8267471636495283

Epoch: 6| Step: 13
Training loss: 1.135752558708191
Validation loss: 1.899912331693916

Epoch: 326| Step: 0
Training loss: 1.9438693523406982
Validation loss: 1.835062244886993

Epoch: 6| Step: 1
Training loss: 1.419426441192627
Validation loss: 1.8644439866465907

Epoch: 6| Step: 2
Training loss: 1.648897409439087
Validation loss: 1.828277334090202

Epoch: 6| Step: 3
Training loss: 1.0856513977050781
Validation loss: 1.8921557934053483

Epoch: 6| Step: 4
Training loss: 0.9265962839126587
Validation loss: 1.8320979315747496

Epoch: 6| Step: 5
Training loss: 1.0965768098831177
Validation loss: 1.781869847287414

Epoch: 6| Step: 6
Training loss: 1.3561387062072754
Validation loss: 1.7972719400159773

Epoch: 6| Step: 7
Training loss: 1.2778656482696533
Validation loss: 1.8588138946922876

Epoch: 6| Step: 8
Training loss: 1.1995983123779297
Validation loss: 1.8595098423701462

Epoch: 6| Step: 9
Training loss: 1.3537604808807373
Validation loss: 1.8522793246853737

Epoch: 6| Step: 10
Training loss: 1.274674654006958
Validation loss: 1.812320586173765

Epoch: 6| Step: 11
Training loss: 2.0578980445861816
Validation loss: 1.8214142501995128

Epoch: 6| Step: 12
Training loss: 1.492747187614441
Validation loss: 1.8401115812281126

Epoch: 6| Step: 13
Training loss: 0.8220886588096619
Validation loss: 1.8272251429096344

Epoch: 327| Step: 0
Training loss: 0.937636137008667
Validation loss: 1.8411857492180281

Epoch: 6| Step: 1
Training loss: 1.4889252185821533
Validation loss: 1.7960748698121758

Epoch: 6| Step: 2
Training loss: 1.7037739753723145
Validation loss: 1.8150420188903809

Epoch: 6| Step: 3
Training loss: 2.220654249191284
Validation loss: 1.8798896561386764

Epoch: 6| Step: 4
Training loss: 1.175023078918457
Validation loss: 1.8325615185563282

Epoch: 6| Step: 5
Training loss: 0.9791146516799927
Validation loss: 1.7969610088615007

Epoch: 6| Step: 6
Training loss: 0.9436907768249512
Validation loss: 1.8222050871900333

Epoch: 6| Step: 7
Training loss: 1.0694228410720825
Validation loss: 1.821567702037032

Epoch: 6| Step: 8
Training loss: 1.3592698574066162
Validation loss: 1.792396826128806

Epoch: 6| Step: 9
Training loss: 1.3033092021942139
Validation loss: 1.8066012538889402

Epoch: 6| Step: 10
Training loss: 1.1609164476394653
Validation loss: 1.8516267243252005

Epoch: 6| Step: 11
Training loss: 1.7850143909454346
Validation loss: 1.8638358218695528

Epoch: 6| Step: 12
Training loss: 1.5109394788742065
Validation loss: 1.881772833485757

Epoch: 6| Step: 13
Training loss: 1.8926184177398682
Validation loss: 1.8299144801273142

Epoch: 328| Step: 0
Training loss: 1.575457215309143
Validation loss: 1.8503615420351747

Epoch: 6| Step: 1
Training loss: 1.900163173675537
Validation loss: 1.843570622064734

Epoch: 6| Step: 2
Training loss: 1.2458701133728027
Validation loss: 1.7533263442336873

Epoch: 6| Step: 3
Training loss: 1.3244267702102661
Validation loss: 1.7996085946277907

Epoch: 6| Step: 4
Training loss: 0.7883268594741821
Validation loss: 1.7745655621251752

Epoch: 6| Step: 5
Training loss: 1.50875723361969
Validation loss: 1.8681296263971636

Epoch: 6| Step: 6
Training loss: 1.5807987451553345
Validation loss: 1.8236084727830784

Epoch: 6| Step: 7
Training loss: 1.121413230895996
Validation loss: 1.8208213980479906

Epoch: 6| Step: 8
Training loss: 1.5838055610656738
Validation loss: 1.8034041132978214

Epoch: 6| Step: 9
Training loss: 1.134648323059082
Validation loss: 1.7996381610952399

Epoch: 6| Step: 10
Training loss: 1.342058777809143
Validation loss: 1.8665701625167683

Epoch: 6| Step: 11
Training loss: 1.4046227931976318
Validation loss: 1.8472285937237483

Epoch: 6| Step: 12
Training loss: 1.192969799041748
Validation loss: 1.8028610342292375

Epoch: 6| Step: 13
Training loss: 0.7979633808135986
Validation loss: 1.8003690088948896

Epoch: 329| Step: 0
Training loss: 1.2831498384475708
Validation loss: 1.826930925410281

Epoch: 6| Step: 1
Training loss: 1.2187297344207764
Validation loss: 1.8135133071612286

Epoch: 6| Step: 2
Training loss: 1.7785475254058838
Validation loss: 1.8563971801470684

Epoch: 6| Step: 3
Training loss: 1.5608241558074951
Validation loss: 1.8452255777133408

Epoch: 6| Step: 4
Training loss: 1.3056185245513916
Validation loss: 1.7651996561276015

Epoch: 6| Step: 5
Training loss: 1.5670946836471558
Validation loss: 1.7949186191763928

Epoch: 6| Step: 6
Training loss: 1.321436882019043
Validation loss: 1.8338162463198426

Epoch: 6| Step: 7
Training loss: 0.8561246395111084
Validation loss: 1.8611486675918743

Epoch: 6| Step: 8
Training loss: 1.010904312133789
Validation loss: 1.859879429622363

Epoch: 6| Step: 9
Training loss: 1.4230740070343018
Validation loss: 1.7973780209018337

Epoch: 6| Step: 10
Training loss: 1.6524937152862549
Validation loss: 1.74415244466515

Epoch: 6| Step: 11
Training loss: 1.4120137691497803
Validation loss: 1.843178597829675

Epoch: 6| Step: 12
Training loss: 1.0551941394805908
Validation loss: 1.8262742168159896

Epoch: 6| Step: 13
Training loss: 1.5046507120132446
Validation loss: 1.8079669321736982

Epoch: 330| Step: 0
Training loss: 0.9366812109947205
Validation loss: 1.8120303179628106

Epoch: 6| Step: 1
Training loss: 1.7188533544540405
Validation loss: 1.818264667705823

Epoch: 6| Step: 2
Training loss: 0.9252641797065735
Validation loss: 1.8619301678032003

Epoch: 6| Step: 3
Training loss: 1.881626844406128
Validation loss: 1.8501554368644633

Epoch: 6| Step: 4
Training loss: 0.757349967956543
Validation loss: 1.803043960243143

Epoch: 6| Step: 5
Training loss: 1.435697078704834
Validation loss: 1.8047255469906716

Epoch: 6| Step: 6
Training loss: 1.8708820343017578
Validation loss: 1.8543109201615857

Epoch: 6| Step: 7
Training loss: 1.091951847076416
Validation loss: 1.8269851156460342

Epoch: 6| Step: 8
Training loss: 1.5769840478897095
Validation loss: 1.836628742115472

Epoch: 6| Step: 9
Training loss: 0.8914791345596313
Validation loss: 1.8622133334477742

Epoch: 6| Step: 10
Training loss: 1.2476087808609009
Validation loss: 1.8052101353163361

Epoch: 6| Step: 11
Training loss: 1.5245232582092285
Validation loss: 1.864004078731742

Epoch: 6| Step: 12
Training loss: 1.1025733947753906
Validation loss: 1.825348392609627

Epoch: 6| Step: 13
Training loss: 1.78615403175354
Validation loss: 1.849319872035775

Epoch: 331| Step: 0
Training loss: 1.1964740753173828
Validation loss: 1.8509179328077583

Epoch: 6| Step: 1
Training loss: 1.188775658607483
Validation loss: 1.8147781664325344

Epoch: 6| Step: 2
Training loss: 0.9057695865631104
Validation loss: 1.8870359095194007

Epoch: 6| Step: 3
Training loss: 2.0121684074401855
Validation loss: 1.853681864277009

Epoch: 6| Step: 4
Training loss: 1.3781712055206299
Validation loss: 1.8737354688746954

Epoch: 6| Step: 5
Training loss: 1.6328086853027344
Validation loss: 1.8846043540585427

Epoch: 6| Step: 6
Training loss: 1.2477372884750366
Validation loss: 1.9692430047578708

Epoch: 6| Step: 7
Training loss: 0.6513060927391052
Validation loss: 1.873037576675415

Epoch: 6| Step: 8
Training loss: 1.1320111751556396
Validation loss: 1.9175413577787337

Epoch: 6| Step: 9
Training loss: 1.823002815246582
Validation loss: 1.9198265755048363

Epoch: 6| Step: 10
Training loss: 1.741879940032959
Validation loss: 1.8950100137341408

Epoch: 6| Step: 11
Training loss: 1.3041688203811646
Validation loss: 1.8618077334537302

Epoch: 6| Step: 12
Training loss: 1.8824119567871094
Validation loss: 1.8191970804686188

Epoch: 6| Step: 13
Training loss: 1.347216248512268
Validation loss: 1.8125385007550638

Epoch: 332| Step: 0
Training loss: 0.6797115802764893
Validation loss: 1.812213961796094

Epoch: 6| Step: 1
Training loss: 1.9457650184631348
Validation loss: 1.829487967234786

Epoch: 6| Step: 2
Training loss: 1.146669626235962
Validation loss: 1.8029164601397771

Epoch: 6| Step: 3
Training loss: 1.453775405883789
Validation loss: 1.824463234152845

Epoch: 6| Step: 4
Training loss: 1.2813642024993896
Validation loss: 1.7707062626397738

Epoch: 6| Step: 5
Training loss: 1.5560667514801025
Validation loss: 1.832849157753811

Epoch: 6| Step: 6
Training loss: 1.291825532913208
Validation loss: 1.7961194810046945

Epoch: 6| Step: 7
Training loss: 1.0966479778289795
Validation loss: 1.7938972416744436

Epoch: 6| Step: 8
Training loss: 1.1445337533950806
Validation loss: 1.8085448113820886

Epoch: 6| Step: 9
Training loss: 1.5987699031829834
Validation loss: 1.8438346629501672

Epoch: 6| Step: 10
Training loss: 1.4962007999420166
Validation loss: 1.8067712860722696

Epoch: 6| Step: 11
Training loss: 1.0928033590316772
Validation loss: 1.8681371083823584

Epoch: 6| Step: 12
Training loss: 1.4349076747894287
Validation loss: 1.838311105646113

Epoch: 6| Step: 13
Training loss: 1.942240595817566
Validation loss: 1.8198967261980938

Epoch: 333| Step: 0
Training loss: 1.3982263803482056
Validation loss: 1.857323158171869

Epoch: 6| Step: 1
Training loss: 0.5836126804351807
Validation loss: 1.844805653377246

Epoch: 6| Step: 2
Training loss: 2.106152057647705
Validation loss: 1.8916600788793256

Epoch: 6| Step: 3
Training loss: 1.5665011405944824
Validation loss: 1.8953572242490706

Epoch: 6| Step: 4
Training loss: 1.8934500217437744
Validation loss: 1.9292743218842374

Epoch: 6| Step: 5
Training loss: 1.245222568511963
Validation loss: 1.9207478774491178

Epoch: 6| Step: 6
Training loss: 1.4664595127105713
Validation loss: 1.8550457159678142

Epoch: 6| Step: 7
Training loss: 1.248101830482483
Validation loss: 1.8008984186316048

Epoch: 6| Step: 8
Training loss: 0.6775498390197754
Validation loss: 1.8739125690152567

Epoch: 6| Step: 9
Training loss: 1.126403570175171
Validation loss: 1.8791112412688553

Epoch: 6| Step: 10
Training loss: 1.0192375183105469
Validation loss: 1.8447841751960017

Epoch: 6| Step: 11
Training loss: 1.7573002576828003
Validation loss: 1.9022825725616948

Epoch: 6| Step: 12
Training loss: 0.8316102027893066
Validation loss: 1.8748949138067101

Epoch: 6| Step: 13
Training loss: 1.9331640005111694
Validation loss: 1.8011775170603106

Epoch: 334| Step: 0
Training loss: 1.130820631980896
Validation loss: 1.8187809964661956

Epoch: 6| Step: 1
Training loss: 0.9482173919677734
Validation loss: 1.79027178723325

Epoch: 6| Step: 2
Training loss: 1.1571155786514282
Validation loss: 1.8312867008229738

Epoch: 6| Step: 3
Training loss: 1.496448278427124
Validation loss: 1.815153141175547

Epoch: 6| Step: 4
Training loss: 1.6571142673492432
Validation loss: 1.8301117753469816

Epoch: 6| Step: 5
Training loss: 1.6677786111831665
Validation loss: 1.8199651023393035

Epoch: 6| Step: 6
Training loss: 1.3940036296844482
Validation loss: 1.8321663923161005

Epoch: 6| Step: 7
Training loss: 1.4968409538269043
Validation loss: 1.8494405195277224

Epoch: 6| Step: 8
Training loss: 1.7591848373413086
Validation loss: 1.8053237084419496

Epoch: 6| Step: 9
Training loss: 1.1252835988998413
Validation loss: 1.830900038442304

Epoch: 6| Step: 10
Training loss: 1.2950329780578613
Validation loss: 1.8264376886429325

Epoch: 6| Step: 11
Training loss: 1.0603256225585938
Validation loss: 1.8145647818042385

Epoch: 6| Step: 12
Training loss: 1.2223095893859863
Validation loss: 1.7794895338755783

Epoch: 6| Step: 13
Training loss: 1.0616601705551147
Validation loss: 1.754007959878573

Epoch: 335| Step: 0
Training loss: 1.7738515138626099
Validation loss: 1.7926239595618298

Epoch: 6| Step: 1
Training loss: 1.6120116710662842
Validation loss: 1.8041618844514251

Epoch: 6| Step: 2
Training loss: 1.2915520668029785
Validation loss: 1.7855420920156664

Epoch: 6| Step: 3
Training loss: 1.4724724292755127
Validation loss: 1.7730217338890157

Epoch: 6| Step: 4
Training loss: 1.0018723011016846
Validation loss: 1.8093753194296232

Epoch: 6| Step: 5
Training loss: 0.905200719833374
Validation loss: 1.8228558289107455

Epoch: 6| Step: 6
Training loss: 1.5679256916046143
Validation loss: 1.7984955362094346

Epoch: 6| Step: 7
Training loss: 0.8888130187988281
Validation loss: 1.7942444303984284

Epoch: 6| Step: 8
Training loss: 1.082108974456787
Validation loss: 1.733573159863872

Epoch: 6| Step: 9
Training loss: 1.499764323234558
Validation loss: 1.8513690220412387

Epoch: 6| Step: 10
Training loss: 1.3753628730773926
Validation loss: 1.7899625852543821

Epoch: 6| Step: 11
Training loss: 1.332129955291748
Validation loss: 1.8795661387904998

Epoch: 6| Step: 12
Training loss: 1.4897186756134033
Validation loss: 1.8409872849782307

Epoch: 6| Step: 13
Training loss: 1.7629568576812744
Validation loss: 1.8811975781635573

Epoch: 336| Step: 0
Training loss: 1.4939279556274414
Validation loss: 1.879022272684241

Epoch: 6| Step: 1
Training loss: 1.4982036352157593
Validation loss: 1.850510294719409

Epoch: 6| Step: 2
Training loss: 1.0144693851470947
Validation loss: 1.8569141908358502

Epoch: 6| Step: 3
Training loss: 1.05515456199646
Validation loss: 1.8456623887503019

Epoch: 6| Step: 4
Training loss: 1.454748272895813
Validation loss: 1.850805946575698

Epoch: 6| Step: 5
Training loss: 1.3674910068511963
Validation loss: 1.8619335646270423

Epoch: 6| Step: 6
Training loss: 0.8756113648414612
Validation loss: 1.901304667995822

Epoch: 6| Step: 7
Training loss: 1.5330901145935059
Validation loss: 1.826514841407858

Epoch: 6| Step: 8
Training loss: 1.138380527496338
Validation loss: 1.8220927894756358

Epoch: 6| Step: 9
Training loss: 1.390351414680481
Validation loss: 1.8488270569873113

Epoch: 6| Step: 10
Training loss: 1.186105489730835
Validation loss: 1.8760656900303339

Epoch: 6| Step: 11
Training loss: 1.8092048168182373
Validation loss: 1.836506833312332

Epoch: 6| Step: 12
Training loss: 1.4558403491973877
Validation loss: 1.8059299197248233

Epoch: 6| Step: 13
Training loss: 1.0107040405273438
Validation loss: 1.8204981011729087

Epoch: 337| Step: 0
Training loss: 1.447303295135498
Validation loss: 1.7857692510850969

Epoch: 6| Step: 1
Training loss: 1.0152649879455566
Validation loss: 1.8232315560822845

Epoch: 6| Step: 2
Training loss: 1.2594636678695679
Validation loss: 1.8886473819773684

Epoch: 6| Step: 3
Training loss: 1.482863426208496
Validation loss: 1.8103360899033085

Epoch: 6| Step: 4
Training loss: 0.7178572416305542
Validation loss: 1.801325091751673

Epoch: 6| Step: 5
Training loss: 2.208702325820923
Validation loss: 1.843242560663531

Epoch: 6| Step: 6
Training loss: 1.9508635997772217
Validation loss: 1.7960214666140977

Epoch: 6| Step: 7
Training loss: 1.2916243076324463
Validation loss: 1.8314734710160123

Epoch: 6| Step: 8
Training loss: 1.4909768104553223
Validation loss: 1.8416223756728634

Epoch: 6| Step: 9
Training loss: 1.2099459171295166
Validation loss: 1.809197046423471

Epoch: 6| Step: 10
Training loss: 1.6846530437469482
Validation loss: 1.8816426005414737

Epoch: 6| Step: 11
Training loss: 0.7558028101921082
Validation loss: 1.807608005821064

Epoch: 6| Step: 12
Training loss: 1.3309324979782104
Validation loss: 1.8086580512344197

Epoch: 6| Step: 13
Training loss: 1.4050108194351196
Validation loss: 1.8784753225182975

Epoch: 338| Step: 0
Training loss: 1.5561882257461548
Validation loss: 1.8613245205212665

Epoch: 6| Step: 1
Training loss: 1.7198467254638672
Validation loss: 1.8768807034338675

Epoch: 6| Step: 2
Training loss: 1.838890552520752
Validation loss: 1.8073328297625306

Epoch: 6| Step: 3
Training loss: 0.9626302123069763
Validation loss: 1.8006933914717806

Epoch: 6| Step: 4
Training loss: 0.8868807554244995
Validation loss: 1.813130082622651

Epoch: 6| Step: 5
Training loss: 1.4589498043060303
Validation loss: 1.8036662942619734

Epoch: 6| Step: 6
Training loss: 1.2473797798156738
Validation loss: 1.850128399428501

Epoch: 6| Step: 7
Training loss: 1.3605360984802246
Validation loss: 1.8353144763618388

Epoch: 6| Step: 8
Training loss: 1.679099678993225
Validation loss: 1.9008892787400113

Epoch: 6| Step: 9
Training loss: 0.9751456379890442
Validation loss: 1.795845588048299

Epoch: 6| Step: 10
Training loss: 1.3766261339187622
Validation loss: 1.7900668254462622

Epoch: 6| Step: 11
Training loss: 1.2196266651153564
Validation loss: 1.8599766685116677

Epoch: 6| Step: 12
Training loss: 1.261185884475708
Validation loss: 1.8361258583684121

Epoch: 6| Step: 13
Training loss: 1.3678288459777832
Validation loss: 1.830473619122659

Epoch: 339| Step: 0
Training loss: 1.647723913192749
Validation loss: 1.7753891073247439

Epoch: 6| Step: 1
Training loss: 1.0248771905899048
Validation loss: 1.7973701159159343

Epoch: 6| Step: 2
Training loss: 1.1100538969039917
Validation loss: 1.8409623253730036

Epoch: 6| Step: 3
Training loss: 1.494736671447754
Validation loss: 1.8556510222855436

Epoch: 6| Step: 4
Training loss: 1.180257797241211
Validation loss: 1.8231532573699951

Epoch: 6| Step: 5
Training loss: 1.710521936416626
Validation loss: 1.8315474999848234

Epoch: 6| Step: 6
Training loss: 1.1963064670562744
Validation loss: 1.747012330639747

Epoch: 6| Step: 7
Training loss: 1.8144975900650024
Validation loss: 1.797371764336863

Epoch: 6| Step: 8
Training loss: 1.2698960304260254
Validation loss: 1.824674428150218

Epoch: 6| Step: 9
Training loss: 1.5756398439407349
Validation loss: 1.8074405065146826

Epoch: 6| Step: 10
Training loss: 1.6116230487823486
Validation loss: 1.756992506724532

Epoch: 6| Step: 11
Training loss: 1.2429713010787964
Validation loss: 1.8623188605872534

Epoch: 6| Step: 12
Training loss: 1.0830695629119873
Validation loss: 1.8084586205021027

Epoch: 6| Step: 13
Training loss: 0.9617525935173035
Validation loss: 1.8829124512210969

Epoch: 340| Step: 0
Training loss: 0.8305065035820007
Validation loss: 1.827003582831352

Epoch: 6| Step: 1
Training loss: 2.0982282161712646
Validation loss: 1.8784867512282504

Epoch: 6| Step: 2
Training loss: 0.6504402756690979
Validation loss: 1.8705938618670228

Epoch: 6| Step: 3
Training loss: 1.3349716663360596
Validation loss: 1.908074200794261

Epoch: 6| Step: 4
Training loss: 1.7155455350875854
Validation loss: 1.9471111964153986

Epoch: 6| Step: 5
Training loss: 1.1400680541992188
Validation loss: 1.942881714913153

Epoch: 6| Step: 6
Training loss: 1.2946504354476929
Validation loss: 1.8597341429802678

Epoch: 6| Step: 7
Training loss: 1.268612265586853
Validation loss: 1.8696305533891082

Epoch: 6| Step: 8
Training loss: 1.9790842533111572
Validation loss: 1.890978177388509

Epoch: 6| Step: 9
Training loss: 1.720579743385315
Validation loss: 1.8496740979533042

Epoch: 6| Step: 10
Training loss: 0.8760249018669128
Validation loss: 1.8276897912384362

Epoch: 6| Step: 11
Training loss: 1.3896609544754028
Validation loss: 1.8241437135204193

Epoch: 6| Step: 12
Training loss: 1.1388323307037354
Validation loss: 1.800553746120904

Epoch: 6| Step: 13
Training loss: 1.583265781402588
Validation loss: 1.8670917390495219

Epoch: 341| Step: 0
Training loss: 1.5046308040618896
Validation loss: 1.7395344011245235

Epoch: 6| Step: 1
Training loss: 1.1460390090942383
Validation loss: 1.7650694821470527

Epoch: 6| Step: 2
Training loss: 2.351837158203125
Validation loss: 1.8374731566316338

Epoch: 6| Step: 3
Training loss: 1.520271897315979
Validation loss: 1.873465343188214

Epoch: 6| Step: 4
Training loss: 1.114198923110962
Validation loss: 1.7960027187101302

Epoch: 6| Step: 5
Training loss: 1.1120661497116089
Validation loss: 1.856099800396991

Epoch: 6| Step: 6
Training loss: 0.9350663423538208
Validation loss: 1.8339332585693688

Epoch: 6| Step: 7
Training loss: 0.8807179927825928
Validation loss: 1.789920804321125

Epoch: 6| Step: 8
Training loss: 1.3299643993377686
Validation loss: 1.8645381594216952

Epoch: 6| Step: 9
Training loss: 2.548834800720215
Validation loss: 1.8410119061828942

Epoch: 6| Step: 10
Training loss: 0.8672576546669006
Validation loss: 1.855069306588942

Epoch: 6| Step: 11
Training loss: 1.1801605224609375
Validation loss: 1.8974973270970006

Epoch: 6| Step: 12
Training loss: 0.8997417092323303
Validation loss: 1.8164921409340316

Epoch: 6| Step: 13
Training loss: 1.1270331144332886
Validation loss: 1.8171359697977703

Epoch: 342| Step: 0
Training loss: 0.6806506514549255
Validation loss: 1.7963441251426615

Epoch: 6| Step: 1
Training loss: 1.5054161548614502
Validation loss: 1.7937931412009782

Epoch: 6| Step: 2
Training loss: 1.337552547454834
Validation loss: 1.8431407508029733

Epoch: 6| Step: 3
Training loss: 1.9137463569641113
Validation loss: 1.828863646394463

Epoch: 6| Step: 4
Training loss: 1.444239616394043
Validation loss: 1.809340779499341

Epoch: 6| Step: 5
Training loss: 1.4979596138000488
Validation loss: 1.819688525251163

Epoch: 6| Step: 6
Training loss: 1.7154303789138794
Validation loss: 1.8045179587538525

Epoch: 6| Step: 7
Training loss: 0.9450382590293884
Validation loss: 1.7807759315736833

Epoch: 6| Step: 8
Training loss: 1.0897760391235352
Validation loss: 1.8010915786989274

Epoch: 6| Step: 9
Training loss: 1.430422306060791
Validation loss: 1.7942533954497306

Epoch: 6| Step: 10
Training loss: 1.0829777717590332
Validation loss: 1.8619679302297614

Epoch: 6| Step: 11
Training loss: 1.0609391927719116
Validation loss: 1.8147043681913806

Epoch: 6| Step: 12
Training loss: 1.852043628692627
Validation loss: 1.8663354560893068

Epoch: 6| Step: 13
Training loss: 1.2941977977752686
Validation loss: 1.823332175131767

Epoch: 343| Step: 0
Training loss: 1.4303953647613525
Validation loss: 1.866903357608344

Epoch: 6| Step: 1
Training loss: 1.9361292123794556
Validation loss: 1.905457362051933

Epoch: 6| Step: 2
Training loss: 1.1677507162094116
Validation loss: 1.8602123363043672

Epoch: 6| Step: 3
Training loss: 0.8488771915435791
Validation loss: 1.8419683338493429

Epoch: 6| Step: 4
Training loss: 1.031682014465332
Validation loss: 1.830100420982607

Epoch: 6| Step: 5
Training loss: 1.521986722946167
Validation loss: 1.823498277254002

Epoch: 6| Step: 6
Training loss: 1.2622756958007812
Validation loss: 1.8533627499816239

Epoch: 6| Step: 7
Training loss: 1.6767220497131348
Validation loss: 1.751996281326458

Epoch: 6| Step: 8
Training loss: 1.066016435623169
Validation loss: 1.8251189929182812

Epoch: 6| Step: 9
Training loss: 1.5376629829406738
Validation loss: 1.8533837859348585

Epoch: 6| Step: 10
Training loss: 1.4825899600982666
Validation loss: 1.8022017709670528

Epoch: 6| Step: 11
Training loss: 1.0604667663574219
Validation loss: 1.778089105442006

Epoch: 6| Step: 12
Training loss: 0.9561205506324768
Validation loss: 1.8742057251673874

Epoch: 6| Step: 13
Training loss: 1.6182926893234253
Validation loss: 1.8163680491908905

Epoch: 344| Step: 0
Training loss: 1.60567307472229
Validation loss: 1.8043132020581154

Epoch: 6| Step: 1
Training loss: 1.2033418416976929
Validation loss: 1.8496863303645965

Epoch: 6| Step: 2
Training loss: 1.7889494895935059
Validation loss: 1.8805844053145377

Epoch: 6| Step: 3
Training loss: 1.250281810760498
Validation loss: 1.901276591003582

Epoch: 6| Step: 4
Training loss: 1.30560302734375
Validation loss: 1.8550072254673127

Epoch: 6| Step: 5
Training loss: 1.2159022092819214
Validation loss: 1.8932193633048766

Epoch: 6| Step: 6
Training loss: 1.3778222799301147
Validation loss: 1.8620638026986072

Epoch: 6| Step: 7
Training loss: 1.3989436626434326
Validation loss: 1.8907962229944044

Epoch: 6| Step: 8
Training loss: 1.1334553956985474
Validation loss: 1.9210185415001326

Epoch: 6| Step: 9
Training loss: 1.3549270629882812
Validation loss: 1.9023476569883284

Epoch: 6| Step: 10
Training loss: 1.459002137184143
Validation loss: 1.8837696941949988

Epoch: 6| Step: 11
Training loss: 1.5146892070770264
Validation loss: 1.8749540249506633

Epoch: 6| Step: 12
Training loss: 1.2502086162567139
Validation loss: 1.819172131117954

Epoch: 6| Step: 13
Training loss: 1.1603591442108154
Validation loss: 1.8117960076178274

Epoch: 345| Step: 0
Training loss: 1.214808464050293
Validation loss: 1.769492942799804

Epoch: 6| Step: 1
Training loss: 2.1594972610473633
Validation loss: 1.7864030740594352

Epoch: 6| Step: 2
Training loss: 1.8857351541519165
Validation loss: 1.8120350709525488

Epoch: 6| Step: 3
Training loss: 1.085027813911438
Validation loss: 1.7848066655538415

Epoch: 6| Step: 4
Training loss: 1.3469831943511963
Validation loss: 1.8072458518448697

Epoch: 6| Step: 5
Training loss: 1.596131682395935
Validation loss: 1.8143335004006662

Epoch: 6| Step: 6
Training loss: 1.271700143814087
Validation loss: 1.7867762670722058

Epoch: 6| Step: 7
Training loss: 0.942320704460144
Validation loss: 1.8242661683790145

Epoch: 6| Step: 8
Training loss: 0.7623674869537354
Validation loss: 1.8195087461061374

Epoch: 6| Step: 9
Training loss: 1.6242743730545044
Validation loss: 1.8001024223143054

Epoch: 6| Step: 10
Training loss: 1.4911651611328125
Validation loss: 1.75096107170146

Epoch: 6| Step: 11
Training loss: 1.4511656761169434
Validation loss: 1.7784262575129026

Epoch: 6| Step: 12
Training loss: 0.6215757131576538
Validation loss: 1.8381729933523363

Epoch: 6| Step: 13
Training loss: 1.7922918796539307
Validation loss: 1.7969477535575948

Epoch: 346| Step: 0
Training loss: 1.6190674304962158
Validation loss: 1.82780671376054

Epoch: 6| Step: 1
Training loss: 1.4509681463241577
Validation loss: 1.8233050428411013

Epoch: 6| Step: 2
Training loss: 1.2565462589263916
Validation loss: 1.8470879857258131

Epoch: 6| Step: 3
Training loss: 1.1872875690460205
Validation loss: 1.8135096847370107

Epoch: 6| Step: 4
Training loss: 1.0995129346847534
Validation loss: 1.8619406684752433

Epoch: 6| Step: 5
Training loss: 1.068143606185913
Validation loss: 1.8689991940734207

Epoch: 6| Step: 6
Training loss: 1.4541049003601074
Validation loss: 1.8386642984164658

Epoch: 6| Step: 7
Training loss: 1.190895915031433
Validation loss: 1.8625195193034347

Epoch: 6| Step: 8
Training loss: 1.199675440788269
Validation loss: 1.8640278641895582

Epoch: 6| Step: 9
Training loss: 0.878822922706604
Validation loss: 1.8155344711836947

Epoch: 6| Step: 10
Training loss: 1.1808879375457764
Validation loss: 1.8101105792548067

Epoch: 6| Step: 11
Training loss: 1.2896301746368408
Validation loss: 1.7806749754054572

Epoch: 6| Step: 12
Training loss: 1.7275134325027466
Validation loss: 1.8153532243544055

Epoch: 6| Step: 13
Training loss: 2.0571320056915283
Validation loss: 1.8509012537617837

Epoch: 347| Step: 0
Training loss: 1.3768787384033203
Validation loss: 1.7664599892913655

Epoch: 6| Step: 1
Training loss: 1.153334617614746
Validation loss: 1.8033867138688282

Epoch: 6| Step: 2
Training loss: 1.5164833068847656
Validation loss: 1.7901341710039365

Epoch: 6| Step: 3
Training loss: 1.551440715789795
Validation loss: 1.7617111359873125

Epoch: 6| Step: 4
Training loss: 0.9193134307861328
Validation loss: 1.818647667925845

Epoch: 6| Step: 5
Training loss: 0.9761387705802917
Validation loss: 1.7880423479182745

Epoch: 6| Step: 6
Training loss: 1.515826940536499
Validation loss: 1.7553752622296732

Epoch: 6| Step: 7
Training loss: 1.213049292564392
Validation loss: 1.8233091254388132

Epoch: 6| Step: 8
Training loss: 1.8244750499725342
Validation loss: 1.8437298754210114

Epoch: 6| Step: 9
Training loss: 1.6432331800460815
Validation loss: 1.7787634300929245

Epoch: 6| Step: 10
Training loss: 1.564056634902954
Validation loss: 1.8027100768140567

Epoch: 6| Step: 11
Training loss: 1.177380084991455
Validation loss: 1.8629666156666254

Epoch: 6| Step: 12
Training loss: 0.9208437204360962
Validation loss: 1.8174491326014202

Epoch: 6| Step: 13
Training loss: 0.7942959666252136
Validation loss: 1.8614261791270266

Epoch: 348| Step: 0
Training loss: 1.6948508024215698
Validation loss: 1.8015016753186461

Epoch: 6| Step: 1
Training loss: 0.8784236907958984
Validation loss: 1.7746379657458233

Epoch: 6| Step: 2
Training loss: 1.0051679611206055
Validation loss: 1.857486851753727

Epoch: 6| Step: 3
Training loss: 1.4601317644119263
Validation loss: 1.7582235502940353

Epoch: 6| Step: 4
Training loss: 1.925965428352356
Validation loss: 1.8340617905380905

Epoch: 6| Step: 5
Training loss: 1.3425641059875488
Validation loss: 1.881255938160804

Epoch: 6| Step: 6
Training loss: 1.302616834640503
Validation loss: 1.8696740775979974

Epoch: 6| Step: 7
Training loss: 1.2816113233566284
Validation loss: 1.8687068095771215

Epoch: 6| Step: 8
Training loss: 1.1248478889465332
Validation loss: 1.8867806273121988

Epoch: 6| Step: 9
Training loss: 1.1678764820098877
Validation loss: 1.880655275878086

Epoch: 6| Step: 10
Training loss: 1.7327427864074707
Validation loss: 1.9149510578442646

Epoch: 6| Step: 11
Training loss: 0.8843674659729004
Validation loss: 1.8822797588122788

Epoch: 6| Step: 12
Training loss: 1.6251235008239746
Validation loss: 1.851102138078341

Epoch: 6| Step: 13
Training loss: 1.1508941650390625
Validation loss: 1.8624156572485482

Epoch: 349| Step: 0
Training loss: 1.009873867034912
Validation loss: 1.83407211560075

Epoch: 6| Step: 1
Training loss: 1.2517931461334229
Validation loss: 1.8361936653814008

Epoch: 6| Step: 2
Training loss: 1.8039740324020386
Validation loss: 1.8396530612822501

Epoch: 6| Step: 3
Training loss: 2.079941749572754
Validation loss: 1.8840246136470506

Epoch: 6| Step: 4
Training loss: 1.0780596733093262
Validation loss: 1.8195651756819857

Epoch: 6| Step: 5
Training loss: 1.0748324394226074
Validation loss: 1.8109994088449786

Epoch: 6| Step: 6
Training loss: 1.7364182472229004
Validation loss: 1.8403723303989699

Epoch: 6| Step: 7
Training loss: 1.6337549686431885
Validation loss: 1.7711789979729602

Epoch: 6| Step: 8
Training loss: 1.1351842880249023
Validation loss: 1.833084201300016

Epoch: 6| Step: 9
Training loss: 1.007697343826294
Validation loss: 1.8193778786607968

Epoch: 6| Step: 10
Training loss: 0.8320703506469727
Validation loss: 1.8398036546604608

Epoch: 6| Step: 11
Training loss: 1.6866295337677002
Validation loss: 1.8275869443852415

Epoch: 6| Step: 12
Training loss: 1.1568341255187988
Validation loss: 1.7770992709744362

Epoch: 6| Step: 13
Training loss: 1.1435282230377197
Validation loss: 1.8125009100924256

Epoch: 350| Step: 0
Training loss: 1.6559699773788452
Validation loss: 1.777818952837298

Epoch: 6| Step: 1
Training loss: 1.0893185138702393
Validation loss: 1.8134377374443957

Epoch: 6| Step: 2
Training loss: 1.1981589794158936
Validation loss: 1.8626727173405309

Epoch: 6| Step: 3
Training loss: 1.4491337537765503
Validation loss: 1.7908396220976306

Epoch: 6| Step: 4
Training loss: 0.9993974566459656
Validation loss: 1.842401635262274

Epoch: 6| Step: 5
Training loss: 0.8504616022109985
Validation loss: 1.7962163853388962

Epoch: 6| Step: 6
Training loss: 1.0604941844940186
Validation loss: 1.7571444716504825

Epoch: 6| Step: 7
Training loss: 1.6266766786575317
Validation loss: 1.8313212804896857

Epoch: 6| Step: 8
Training loss: 0.8550173044204712
Validation loss: 1.7918444641174809

Epoch: 6| Step: 9
Training loss: 1.5242611169815063
Validation loss: 1.8557006325773013

Epoch: 6| Step: 10
Training loss: 1.9369878768920898
Validation loss: 1.8171432172098467

Epoch: 6| Step: 11
Training loss: 1.2821102142333984
Validation loss: 1.8855710978149085

Epoch: 6| Step: 12
Training loss: 1.427534580230713
Validation loss: 1.8540914520140617

Epoch: 6| Step: 13
Training loss: 1.3217508792877197
Validation loss: 1.7867359089595016

Epoch: 351| Step: 0
Training loss: 1.1610124111175537
Validation loss: 1.7940682929049256

Epoch: 6| Step: 1
Training loss: 0.9035351276397705
Validation loss: 1.8207837227852113

Epoch: 6| Step: 2
Training loss: 1.2677297592163086
Validation loss: 1.8432236512502034

Epoch: 6| Step: 3
Training loss: 1.0657577514648438
Validation loss: 1.8359664306845715

Epoch: 6| Step: 4
Training loss: 1.327602505683899
Validation loss: 1.8104820046373593

Epoch: 6| Step: 5
Training loss: 1.381115198135376
Validation loss: 1.8074429022368563

Epoch: 6| Step: 6
Training loss: 0.9142719507217407
Validation loss: 1.8170323474432832

Epoch: 6| Step: 7
Training loss: 1.3351924419403076
Validation loss: 1.8346214486706642

Epoch: 6| Step: 8
Training loss: 2.0919570922851562
Validation loss: 1.8704926698438582

Epoch: 6| Step: 9
Training loss: 1.154903531074524
Validation loss: 1.848763365899363

Epoch: 6| Step: 10
Training loss: 1.7213070392608643
Validation loss: 1.8254435908409856

Epoch: 6| Step: 11
Training loss: 1.4902009963989258
Validation loss: 1.822478586627591

Epoch: 6| Step: 12
Training loss: 1.0527395009994507
Validation loss: 1.8544833352488856

Epoch: 6| Step: 13
Training loss: 1.4311633110046387
Validation loss: 1.83753111029184

Epoch: 352| Step: 0
Training loss: 1.2961957454681396
Validation loss: 1.8274271372825868

Epoch: 6| Step: 1
Training loss: 1.46471107006073
Validation loss: 1.8422517327852146

Epoch: 6| Step: 2
Training loss: 1.4475094079971313
Validation loss: 1.8691677406270018

Epoch: 6| Step: 3
Training loss: 1.3101341724395752
Validation loss: 1.8027766981432516

Epoch: 6| Step: 4
Training loss: 1.2604868412017822
Validation loss: 1.80742097157304

Epoch: 6| Step: 5
Training loss: 1.8107455968856812
Validation loss: 1.8901743594036307

Epoch: 6| Step: 6
Training loss: 1.4493720531463623
Validation loss: 1.8818409929993332

Epoch: 6| Step: 7
Training loss: 0.7360245585441589
Validation loss: 1.8307293076669016

Epoch: 6| Step: 8
Training loss: 1.5551564693450928
Validation loss: 1.7685478348885812

Epoch: 6| Step: 9
Training loss: 0.8111092448234558
Validation loss: 1.8705846789062663

Epoch: 6| Step: 10
Training loss: 1.6353867053985596
Validation loss: 1.8451218502495879

Epoch: 6| Step: 11
Training loss: 1.590367078781128
Validation loss: 1.794972695330138

Epoch: 6| Step: 12
Training loss: 1.0755560398101807
Validation loss: 1.7917291374616726

Epoch: 6| Step: 13
Training loss: 0.7980939149856567
Validation loss: 1.808605847820159

Epoch: 353| Step: 0
Training loss: 1.0251301527023315
Validation loss: 1.744617937713541

Epoch: 6| Step: 1
Training loss: 1.9160635471343994
Validation loss: 1.8044634634448635

Epoch: 6| Step: 2
Training loss: 1.4886361360549927
Validation loss: 1.8145935035520984

Epoch: 6| Step: 3
Training loss: 1.2100502252578735
Validation loss: 1.8299257460460867

Epoch: 6| Step: 4
Training loss: 1.6534359455108643
Validation loss: 1.8468724271302581

Epoch: 6| Step: 5
Training loss: 1.538083791732788
Validation loss: 1.7980716741213234

Epoch: 6| Step: 6
Training loss: 1.182592749595642
Validation loss: 1.7879572145400509

Epoch: 6| Step: 7
Training loss: 1.1194636821746826
Validation loss: 1.7911282059966878

Epoch: 6| Step: 8
Training loss: 1.1732144355773926
Validation loss: 1.8032355334169121

Epoch: 6| Step: 9
Training loss: 1.7279709577560425
Validation loss: 1.8242241156998502

Epoch: 6| Step: 10
Training loss: 0.5311732888221741
Validation loss: 1.8487014898689844

Epoch: 6| Step: 11
Training loss: 1.2782924175262451
Validation loss: 1.795934469469132

Epoch: 6| Step: 12
Training loss: 0.8390803933143616
Validation loss: 1.8486904187869

Epoch: 6| Step: 13
Training loss: 1.4806883335113525
Validation loss: 1.8234699015976281

Epoch: 354| Step: 0
Training loss: 0.8103756904602051
Validation loss: 1.8051575729923863

Epoch: 6| Step: 1
Training loss: 1.9216744899749756
Validation loss: 1.7770678958585184

Epoch: 6| Step: 2
Training loss: 1.1483988761901855
Validation loss: 1.8686157721345142

Epoch: 6| Step: 3
Training loss: 1.3685137033462524
Validation loss: 1.7973774992009646

Epoch: 6| Step: 4
Training loss: 1.4810317754745483
Validation loss: 1.8285764045612787

Epoch: 6| Step: 5
Training loss: 1.4129638671875
Validation loss: 1.8024180461001653

Epoch: 6| Step: 6
Training loss: 1.65809166431427
Validation loss: 1.8170598911982712

Epoch: 6| Step: 7
Training loss: 1.0256283283233643
Validation loss: 1.7276360962980537

Epoch: 6| Step: 8
Training loss: 1.4448825120925903
Validation loss: 1.7969622432544667

Epoch: 6| Step: 9
Training loss: 1.61763334274292
Validation loss: 1.7623750702027352

Epoch: 6| Step: 10
Training loss: 1.273707389831543
Validation loss: 1.862689782214421

Epoch: 6| Step: 11
Training loss: 0.7207038402557373
Validation loss: 1.7814685388277935

Epoch: 6| Step: 12
Training loss: 1.3119721412658691
Validation loss: 1.8227992878165296

Epoch: 6| Step: 13
Training loss: 0.8826791048049927
Validation loss: 1.8408890917736997

Epoch: 355| Step: 0
Training loss: 0.9592093229293823
Validation loss: 1.796638750260876

Epoch: 6| Step: 1
Training loss: 0.8888433575630188
Validation loss: 1.8373231400725663

Epoch: 6| Step: 2
Training loss: 1.6117489337921143
Validation loss: 1.8479299288924023

Epoch: 6| Step: 3
Training loss: 1.3807039260864258
Validation loss: 1.8137967714699366

Epoch: 6| Step: 4
Training loss: 1.1489033699035645
Validation loss: 1.822415497995192

Epoch: 6| Step: 5
Training loss: 1.748477578163147
Validation loss: 1.8246492583264586

Epoch: 6| Step: 6
Training loss: 1.5516748428344727
Validation loss: 1.827251349726031

Epoch: 6| Step: 7
Training loss: 1.5772708654403687
Validation loss: 1.8475733790346371

Epoch: 6| Step: 8
Training loss: 0.6400334239006042
Validation loss: 1.813610747296323

Epoch: 6| Step: 9
Training loss: 0.9826267957687378
Validation loss: 1.8111564241429812

Epoch: 6| Step: 10
Training loss: 1.9416781663894653
Validation loss: 1.8459836142037505

Epoch: 6| Step: 11
Training loss: 1.218048334121704
Validation loss: 1.8917882647565616

Epoch: 6| Step: 12
Training loss: 1.5924420356750488
Validation loss: 1.8379010949083554

Epoch: 6| Step: 13
Training loss: 0.4107932448387146
Validation loss: 1.8333220994600685

Epoch: 356| Step: 0
Training loss: 1.4497673511505127
Validation loss: 1.8550751209259033

Epoch: 6| Step: 1
Training loss: 1.2274892330169678
Validation loss: 1.84496864580339

Epoch: 6| Step: 2
Training loss: 1.266740322113037
Validation loss: 1.7642884164728143

Epoch: 6| Step: 3
Training loss: 1.888913869857788
Validation loss: 1.8244996378498692

Epoch: 6| Step: 4
Training loss: 1.3107998371124268
Validation loss: 1.8321012117529427

Epoch: 6| Step: 5
Training loss: 0.5958160161972046
Validation loss: 1.8428191010669996

Epoch: 6| Step: 6
Training loss: 1.3556808233261108
Validation loss: 1.8610635098590647

Epoch: 6| Step: 7
Training loss: 1.8617377281188965
Validation loss: 1.8051789447825441

Epoch: 6| Step: 8
Training loss: 1.1608495712280273
Validation loss: 1.8210556532747002

Epoch: 6| Step: 9
Training loss: 0.9281064867973328
Validation loss: 1.8726000042371853

Epoch: 6| Step: 10
Training loss: 1.9619172811508179
Validation loss: 1.8099074511117832

Epoch: 6| Step: 11
Training loss: 1.1227447986602783
Validation loss: 1.8351134715541717

Epoch: 6| Step: 12
Training loss: 0.8357903957366943
Validation loss: 1.8568125796574417

Epoch: 6| Step: 13
Training loss: 1.197477102279663
Validation loss: 1.8842853858906736

Epoch: 357| Step: 0
Training loss: 1.082794189453125
Validation loss: 1.8307907747965988

Epoch: 6| Step: 1
Training loss: 0.9108509421348572
Validation loss: 1.8389605604192263

Epoch: 6| Step: 2
Training loss: 1.479202389717102
Validation loss: 1.8215369511676092

Epoch: 6| Step: 3
Training loss: 1.1479984521865845
Validation loss: 1.8117270341483496

Epoch: 6| Step: 4
Training loss: 0.87062668800354
Validation loss: 1.8037963862060218

Epoch: 6| Step: 5
Training loss: 1.254953145980835
Validation loss: 1.8287499720050442

Epoch: 6| Step: 6
Training loss: 1.0263854265213013
Validation loss: 1.7772715937706731

Epoch: 6| Step: 7
Training loss: 1.6831954717636108
Validation loss: 1.7862642529190227

Epoch: 6| Step: 8
Training loss: 1.5331001281738281
Validation loss: 1.7572910119128484

Epoch: 6| Step: 9
Training loss: 1.7503896951675415
Validation loss: 1.8541235103402087

Epoch: 6| Step: 10
Training loss: 1.3039708137512207
Validation loss: 1.8358055750528972

Epoch: 6| Step: 11
Training loss: 1.1324769258499146
Validation loss: 1.8510698785064041

Epoch: 6| Step: 12
Training loss: 1.2069803476333618
Validation loss: 1.7759422948283534

Epoch: 6| Step: 13
Training loss: 2.149456262588501
Validation loss: 1.7922840297863047

Epoch: 358| Step: 0
Training loss: 1.281614899635315
Validation loss: 1.831688384855947

Epoch: 6| Step: 1
Training loss: 1.426809310913086
Validation loss: 1.8159906671893211

Epoch: 6| Step: 2
Training loss: 1.2052143812179565
Validation loss: 1.8122295666766424

Epoch: 6| Step: 3
Training loss: 1.3675669431686401
Validation loss: 1.804471021057457

Epoch: 6| Step: 4
Training loss: 1.5333367586135864
Validation loss: 1.853262618023862

Epoch: 6| Step: 5
Training loss: 1.129399299621582
Validation loss: 1.881351182537694

Epoch: 6| Step: 6
Training loss: 1.4531892538070679
Validation loss: 1.8332576982436641

Epoch: 6| Step: 7
Training loss: 1.0944161415100098
Validation loss: 1.826670895340622

Epoch: 6| Step: 8
Training loss: 1.1866176128387451
Validation loss: 1.8094597401157502

Epoch: 6| Step: 9
Training loss: 1.1552467346191406
Validation loss: 1.8028205645981656

Epoch: 6| Step: 10
Training loss: 1.0851197242736816
Validation loss: 1.8047056582666212

Epoch: 6| Step: 11
Training loss: 1.0995416641235352
Validation loss: 1.8218961992571432

Epoch: 6| Step: 12
Training loss: 1.6048768758773804
Validation loss: 1.8166073188986829

Epoch: 6| Step: 13
Training loss: 1.4327987432479858
Validation loss: 1.822873769267913

Epoch: 359| Step: 0
Training loss: 1.2620795965194702
Validation loss: 1.819064914539296

Epoch: 6| Step: 1
Training loss: 1.4423413276672363
Validation loss: 1.7430200320418163

Epoch: 6| Step: 2
Training loss: 2.0242092609405518
Validation loss: 1.8058655223538798

Epoch: 6| Step: 3
Training loss: 0.946194052696228
Validation loss: 1.834812250188602

Epoch: 6| Step: 4
Training loss: 0.875994861125946
Validation loss: 1.775598793901423

Epoch: 6| Step: 5
Training loss: 1.0031254291534424
Validation loss: 1.863562096831619

Epoch: 6| Step: 6
Training loss: 1.5534541606903076
Validation loss: 1.943474176109478

Epoch: 6| Step: 7
Training loss: 1.1062357425689697
Validation loss: 1.9165385230895011

Epoch: 6| Step: 8
Training loss: 1.6255595684051514
Validation loss: 1.904854969311786

Epoch: 6| Step: 9
Training loss: 1.7410202026367188
Validation loss: 1.812566945629735

Epoch: 6| Step: 10
Training loss: 1.1338460445404053
Validation loss: 1.8720859032805248

Epoch: 6| Step: 11
Training loss: 0.9375410079956055
Validation loss: 1.8090993537697742

Epoch: 6| Step: 12
Training loss: 1.3216989040374756
Validation loss: 1.8551041221105924

Epoch: 6| Step: 13
Training loss: 0.7181612849235535
Validation loss: 1.731669073463768

Epoch: 360| Step: 0
Training loss: 1.3272489309310913
Validation loss: 1.8918307160818448

Epoch: 6| Step: 1
Training loss: 1.2193973064422607
Validation loss: 1.8023028296809043

Epoch: 6| Step: 2
Training loss: 1.3507611751556396
Validation loss: 1.8369197973641016

Epoch: 6| Step: 3
Training loss: 1.1082358360290527
Validation loss: 1.8432820932839507

Epoch: 6| Step: 4
Training loss: 0.8547899723052979
Validation loss: 1.8364159932700537

Epoch: 6| Step: 5
Training loss: 1.5724624395370483
Validation loss: 1.7862093717821184

Epoch: 6| Step: 6
Training loss: 0.6365432143211365
Validation loss: 1.846600717113864

Epoch: 6| Step: 7
Training loss: 1.4374947547912598
Validation loss: 1.7869576497744488

Epoch: 6| Step: 8
Training loss: 1.1873266696929932
Validation loss: 1.8156513116692985

Epoch: 6| Step: 9
Training loss: 1.4100779294967651
Validation loss: 1.809812384267007

Epoch: 6| Step: 10
Training loss: 1.2853405475616455
Validation loss: 1.81952235134699

Epoch: 6| Step: 11
Training loss: 1.1696367263793945
Validation loss: 1.8330791368279407

Epoch: 6| Step: 12
Training loss: 2.3402254581451416
Validation loss: 1.8249473584595548

Epoch: 6| Step: 13
Training loss: 1.0614962577819824
Validation loss: 1.8204775817932621

Epoch: 361| Step: 0
Training loss: 1.2588979005813599
Validation loss: 1.83590623640245

Epoch: 6| Step: 1
Training loss: 1.0866587162017822
Validation loss: 1.8196399583611438

Epoch: 6| Step: 2
Training loss: 1.4483239650726318
Validation loss: 1.817093103162704

Epoch: 6| Step: 3
Training loss: 1.0315585136413574
Validation loss: 1.8241442044576008

Epoch: 6| Step: 4
Training loss: 1.276043176651001
Validation loss: 1.872426272720419

Epoch: 6| Step: 5
Training loss: 1.4590370655059814
Validation loss: 1.8160716795152234

Epoch: 6| Step: 6
Training loss: 1.4112286567687988
Validation loss: 1.8482524682116765

Epoch: 6| Step: 7
Training loss: 1.3856322765350342
Validation loss: 1.8544432745184949

Epoch: 6| Step: 8
Training loss: 1.228515386581421
Validation loss: 1.804071387936992

Epoch: 6| Step: 9
Training loss: 1.4786558151245117
Validation loss: 1.8413932477274249

Epoch: 6| Step: 10
Training loss: 1.1110988855361938
Validation loss: 1.88219319235894

Epoch: 6| Step: 11
Training loss: 1.5381641387939453
Validation loss: 1.8562553364743468

Epoch: 6| Step: 12
Training loss: 1.1815893650054932
Validation loss: 1.864457832869663

Epoch: 6| Step: 13
Training loss: 1.1928540468215942
Validation loss: 1.8698449750100412

Epoch: 362| Step: 0
Training loss: 0.8362663984298706
Validation loss: 1.8140842324943953

Epoch: 6| Step: 1
Training loss: 0.9811770915985107
Validation loss: 1.8429088425892655

Epoch: 6| Step: 2
Training loss: 1.681531310081482
Validation loss: 1.7839784186373475

Epoch: 6| Step: 3
Training loss: 1.1752842664718628
Validation loss: 1.8065614110680037

Epoch: 6| Step: 4
Training loss: 1.3377456665039062
Validation loss: 1.8194487402516026

Epoch: 6| Step: 5
Training loss: 1.0532047748565674
Validation loss: 1.8552362970126572

Epoch: 6| Step: 6
Training loss: 0.9575365781784058
Validation loss: 1.8558306719667168

Epoch: 6| Step: 7
Training loss: 1.3678845167160034
Validation loss: 1.8451338980787544

Epoch: 6| Step: 8
Training loss: 1.3757240772247314
Validation loss: 1.8379165049522155

Epoch: 6| Step: 9
Training loss: 1.2974053621292114
Validation loss: 1.816340624645192

Epoch: 6| Step: 10
Training loss: 1.8062264919281006
Validation loss: 1.858348936162969

Epoch: 6| Step: 11
Training loss: 1.4798774719238281
Validation loss: 1.851388474946381

Epoch: 6| Step: 12
Training loss: 1.6303012371063232
Validation loss: 1.8205021914615427

Epoch: 6| Step: 13
Training loss: 1.2172391414642334
Validation loss: 1.8707760508342455

Epoch: 363| Step: 0
Training loss: 1.1514906883239746
Validation loss: 1.8488326585420998

Epoch: 6| Step: 1
Training loss: 0.86388099193573
Validation loss: 1.8091076010016984

Epoch: 6| Step: 2
Training loss: 1.5757741928100586
Validation loss: 1.8446537192149828

Epoch: 6| Step: 3
Training loss: 1.4315664768218994
Validation loss: 1.766654428615365

Epoch: 6| Step: 4
Training loss: 1.480036973953247
Validation loss: 1.834305056961634

Epoch: 6| Step: 5
Training loss: 1.7015960216522217
Validation loss: 1.8668049945626208

Epoch: 6| Step: 6
Training loss: 1.115593433380127
Validation loss: 1.816527687093263

Epoch: 6| Step: 7
Training loss: 1.4112251996994019
Validation loss: 1.8021626203290877

Epoch: 6| Step: 8
Training loss: 1.005265235900879
Validation loss: 1.8218685427019674

Epoch: 6| Step: 9
Training loss: 1.417073369026184
Validation loss: 1.8295918779988443

Epoch: 6| Step: 10
Training loss: 0.8346065878868103
Validation loss: 1.7850413988995295

Epoch: 6| Step: 11
Training loss: 1.6097975969314575
Validation loss: 1.8716429715515466

Epoch: 6| Step: 12
Training loss: 1.4173760414123535
Validation loss: 1.79262291103281

Epoch: 6| Step: 13
Training loss: 1.3500932455062866
Validation loss: 1.7764948593672885

Epoch: 364| Step: 0
Training loss: 0.9932049512863159
Validation loss: 1.8431346698473858

Epoch: 6| Step: 1
Training loss: 1.8194576501846313
Validation loss: 1.8141228306678034

Epoch: 6| Step: 2
Training loss: 1.2834612131118774
Validation loss: 1.7995994142306748

Epoch: 6| Step: 3
Training loss: 1.1010072231292725
Validation loss: 1.8717056641014673

Epoch: 6| Step: 4
Training loss: 2.005265235900879
Validation loss: 1.8775763998749435

Epoch: 6| Step: 5
Training loss: 0.9110316038131714
Validation loss: 1.8799615957403695

Epoch: 6| Step: 6
Training loss: 0.8213573098182678
Validation loss: 1.8577988904009584

Epoch: 6| Step: 7
Training loss: 1.2124067544937134
Validation loss: 1.8535264999635759

Epoch: 6| Step: 8
Training loss: 1.395057201385498
Validation loss: 1.859641827562804

Epoch: 6| Step: 9
Training loss: 0.8443610072135925
Validation loss: 1.867760427536503

Epoch: 6| Step: 10
Training loss: 1.044409155845642
Validation loss: 1.8206174937627648

Epoch: 6| Step: 11
Training loss: 1.4431312084197998
Validation loss: 1.8942594630743868

Epoch: 6| Step: 12
Training loss: 1.6783992052078247
Validation loss: 1.822555770156204

Epoch: 6| Step: 13
Training loss: 1.2613530158996582
Validation loss: 1.814058885779432

Epoch: 365| Step: 0
Training loss: 1.366660237312317
Validation loss: 1.7982142484316261

Epoch: 6| Step: 1
Training loss: 1.0734474658966064
Validation loss: 1.8580467470230595

Epoch: 6| Step: 2
Training loss: 1.2381367683410645
Validation loss: 1.8139168165063346

Epoch: 6| Step: 3
Training loss: 1.4170410633087158
Validation loss: 1.8266487160036642

Epoch: 6| Step: 4
Training loss: 1.1621872186660767
Validation loss: 1.8581210028740667

Epoch: 6| Step: 5
Training loss: 1.8771172761917114
Validation loss: 1.7970998761474446

Epoch: 6| Step: 6
Training loss: 1.4349418878555298
Validation loss: 1.8254563705895537

Epoch: 6| Step: 7
Training loss: 0.8873715400695801
Validation loss: 1.7672925328695646

Epoch: 6| Step: 8
Training loss: 1.272876262664795
Validation loss: 1.793545489670128

Epoch: 6| Step: 9
Training loss: 1.1780909299850464
Validation loss: 1.8386117617289226

Epoch: 6| Step: 10
Training loss: 1.158383846282959
Validation loss: 1.7822780993676954

Epoch: 6| Step: 11
Training loss: 0.89561527967453
Validation loss: 1.801673916078383

Epoch: 6| Step: 12
Training loss: 1.580217957496643
Validation loss: 1.856367629061463

Epoch: 6| Step: 13
Training loss: 0.9027428030967712
Validation loss: 1.8070706564893004

Epoch: 366| Step: 0
Training loss: 0.8794370293617249
Validation loss: 1.7538629911279167

Epoch: 6| Step: 1
Training loss: 1.4422178268432617
Validation loss: 1.8181749197744554

Epoch: 6| Step: 2
Training loss: 1.0533204078674316
Validation loss: 1.758675895711427

Epoch: 6| Step: 3
Training loss: 0.9159956574440002
Validation loss: 1.8097756934422318

Epoch: 6| Step: 4
Training loss: 0.9512341022491455
Validation loss: 1.8060643237124208

Epoch: 6| Step: 5
Training loss: 1.0933128595352173
Validation loss: 1.8258486332431916

Epoch: 6| Step: 6
Training loss: 1.2817800045013428
Validation loss: 1.7891252707409602

Epoch: 6| Step: 7
Training loss: 1.367118239402771
Validation loss: 1.8632873540283532

Epoch: 6| Step: 8
Training loss: 1.3445281982421875
Validation loss: 1.8176467367397842

Epoch: 6| Step: 9
Training loss: 1.598705768585205
Validation loss: 1.7838167593043337

Epoch: 6| Step: 10
Training loss: 1.329007863998413
Validation loss: 1.7990039112747356

Epoch: 6| Step: 11
Training loss: 1.763780117034912
Validation loss: 1.8561045098048385

Epoch: 6| Step: 12
Training loss: 1.6590161323547363
Validation loss: 1.8141586985639346

Epoch: 6| Step: 13
Training loss: 0.5691745281219482
Validation loss: 1.8279093414224603

Epoch: 367| Step: 0
Training loss: 1.7146953344345093
Validation loss: 1.8089410361423288

Epoch: 6| Step: 1
Training loss: 1.422101616859436
Validation loss: 1.8525950588205808

Epoch: 6| Step: 2
Training loss: 1.1415245532989502
Validation loss: 1.8415542443593342

Epoch: 6| Step: 3
Training loss: 0.7390078902244568
Validation loss: 1.8073266167794504

Epoch: 6| Step: 4
Training loss: 1.4497191905975342
Validation loss: 1.8323747586178523

Epoch: 6| Step: 5
Training loss: 1.1058555841445923
Validation loss: 1.802197817833193

Epoch: 6| Step: 6
Training loss: 0.9359866976737976
Validation loss: 1.7797922498436385

Epoch: 6| Step: 7
Training loss: 1.4705489873886108
Validation loss: 1.8263578235462148

Epoch: 6| Step: 8
Training loss: 0.7403095364570618
Validation loss: 1.7833570498292164

Epoch: 6| Step: 9
Training loss: 1.1575706005096436
Validation loss: 1.8060537256220335

Epoch: 6| Step: 10
Training loss: 1.2550594806671143
Validation loss: 1.8521932299419115

Epoch: 6| Step: 11
Training loss: 1.2263089418411255
Validation loss: 1.8162309956806961

Epoch: 6| Step: 12
Training loss: 2.145537853240967
Validation loss: 1.8199989206047469

Epoch: 6| Step: 13
Training loss: 1.2175790071487427
Validation loss: 1.8050412811258787

Epoch: 368| Step: 0
Training loss: 1.303629994392395
Validation loss: 1.8850919277437272

Epoch: 6| Step: 1
Training loss: 1.4379644393920898
Validation loss: 1.8218164879788634

Epoch: 6| Step: 2
Training loss: 0.9469293355941772
Validation loss: 1.831631250278924

Epoch: 6| Step: 3
Training loss: 1.2927870750427246
Validation loss: 1.8230034779476862

Epoch: 6| Step: 4
Training loss: 1.917565941810608
Validation loss: 1.8691177086163593

Epoch: 6| Step: 5
Training loss: 1.3101205825805664
Validation loss: 1.8012298755748297

Epoch: 6| Step: 6
Training loss: 1.5224180221557617
Validation loss: 1.8186047102815361

Epoch: 6| Step: 7
Training loss: 1.2202191352844238
Validation loss: 1.8248413839647848

Epoch: 6| Step: 8
Training loss: 0.5354375839233398
Validation loss: 1.864706946957496

Epoch: 6| Step: 9
Training loss: 1.150892972946167
Validation loss: 1.8350009328575545

Epoch: 6| Step: 10
Training loss: 1.2698628902435303
Validation loss: 1.849370930784492

Epoch: 6| Step: 11
Training loss: 1.2888545989990234
Validation loss: 1.7604845339252102

Epoch: 6| Step: 12
Training loss: 1.2732388973236084
Validation loss: 1.8709891816621185

Epoch: 6| Step: 13
Training loss: 1.9262733459472656
Validation loss: 1.8391990494984451

Epoch: 369| Step: 0
Training loss: 1.504807949066162
Validation loss: 1.8111692141461115

Epoch: 6| Step: 1
Training loss: 0.9739402532577515
Validation loss: 1.8245580760381555

Epoch: 6| Step: 2
Training loss: 0.9951357841491699
Validation loss: 1.825374750680821

Epoch: 6| Step: 3
Training loss: 1.1936780214309692
Validation loss: 1.825246290494037

Epoch: 6| Step: 4
Training loss: 0.7730501294136047
Validation loss: 1.8312235519450197

Epoch: 6| Step: 5
Training loss: 0.622014045715332
Validation loss: 1.861591798003002

Epoch: 6| Step: 6
Training loss: 1.429572343826294
Validation loss: 1.8286109842279905

Epoch: 6| Step: 7
Training loss: 1.2069368362426758
Validation loss: 1.811819040647117

Epoch: 6| Step: 8
Training loss: 1.7212481498718262
Validation loss: 1.8147550449576428

Epoch: 6| Step: 9
Training loss: 1.2356488704681396
Validation loss: 1.865475062401064

Epoch: 6| Step: 10
Training loss: 1.383417010307312
Validation loss: 1.7998511483592372

Epoch: 6| Step: 11
Training loss: 1.6761139631271362
Validation loss: 1.8228878923641738

Epoch: 6| Step: 12
Training loss: 0.9252880811691284
Validation loss: 1.81905456255841

Epoch: 6| Step: 13
Training loss: 2.4876327514648438
Validation loss: 1.82685137051408

Epoch: 370| Step: 0
Training loss: 1.5021201372146606
Validation loss: 1.8033585215127597

Epoch: 6| Step: 1
Training loss: 0.806387186050415
Validation loss: 1.7928458426588325

Epoch: 6| Step: 2
Training loss: 1.4651798009872437
Validation loss: 1.835029076504451

Epoch: 6| Step: 3
Training loss: 0.9278953075408936
Validation loss: 1.8385334450711486

Epoch: 6| Step: 4
Training loss: 1.2819454669952393
Validation loss: 1.8531434766707882

Epoch: 6| Step: 5
Training loss: 0.8671571016311646
Validation loss: 1.8026922441297961

Epoch: 6| Step: 6
Training loss: 0.9730517864227295
Validation loss: 1.8695898184212305

Epoch: 6| Step: 7
Training loss: 1.0766851902008057
Validation loss: 1.8372621305527226

Epoch: 6| Step: 8
Training loss: 1.145444393157959
Validation loss: 1.8688901650008334

Epoch: 6| Step: 9
Training loss: 1.1909544467926025
Validation loss: 1.8012892482101277

Epoch: 6| Step: 10
Training loss: 0.8781077861785889
Validation loss: 1.8287239061888827

Epoch: 6| Step: 11
Training loss: 1.956482172012329
Validation loss: 1.7938797999453802

Epoch: 6| Step: 12
Training loss: 1.8530333042144775
Validation loss: 1.804019566505186

Epoch: 6| Step: 13
Training loss: 1.546520709991455
Validation loss: 1.807922943945854

Epoch: 371| Step: 0
Training loss: 1.1741036176681519
Validation loss: 1.8540302233029438

Epoch: 6| Step: 1
Training loss: 1.07682204246521
Validation loss: 1.7472271778250252

Epoch: 6| Step: 2
Training loss: 1.1119441986083984
Validation loss: 1.8570346037546794

Epoch: 6| Step: 3
Training loss: 0.9170818328857422
Validation loss: 1.857005185978387

Epoch: 6| Step: 4
Training loss: 1.7387182712554932
Validation loss: 1.8864277870424333

Epoch: 6| Step: 5
Training loss: 1.459911584854126
Validation loss: 1.8552017775915002

Epoch: 6| Step: 6
Training loss: 1.0968170166015625
Validation loss: 1.7852802597066408

Epoch: 6| Step: 7
Training loss: 0.7584540843963623
Validation loss: 1.8346698053421513

Epoch: 6| Step: 8
Training loss: 0.9806486368179321
Validation loss: 1.8532632653431227

Epoch: 6| Step: 9
Training loss: 1.2505362033843994
Validation loss: 1.8950946382296983

Epoch: 6| Step: 10
Training loss: 1.3328813314437866
Validation loss: 1.8305974903927054

Epoch: 6| Step: 11
Training loss: 1.5773136615753174
Validation loss: 1.8349672081649944

Epoch: 6| Step: 12
Training loss: 1.5419387817382812
Validation loss: 1.8185461413475774

Epoch: 6| Step: 13
Training loss: 1.3876051902770996
Validation loss: 1.8300151748041953

Epoch: 372| Step: 0
Training loss: 1.1159707307815552
Validation loss: 1.8448288389431533

Epoch: 6| Step: 1
Training loss: 1.1806304454803467
Validation loss: 1.8504491647084553

Epoch: 6| Step: 2
Training loss: 1.6549149751663208
Validation loss: 1.8503382769964074

Epoch: 6| Step: 3
Training loss: 1.1543893814086914
Validation loss: 1.8117063506957023

Epoch: 6| Step: 4
Training loss: 1.252094030380249
Validation loss: 1.8071574177793277

Epoch: 6| Step: 5
Training loss: 1.2487707138061523
Validation loss: 1.8234695157697123

Epoch: 6| Step: 6
Training loss: 0.9376124143600464
Validation loss: 1.83851166694395

Epoch: 6| Step: 7
Training loss: 1.8019369840621948
Validation loss: 1.7900358669219478

Epoch: 6| Step: 8
Training loss: 1.2570648193359375
Validation loss: 1.849695550498142

Epoch: 6| Step: 9
Training loss: 0.9878275394439697
Validation loss: 1.8493540312654229

Epoch: 6| Step: 10
Training loss: 0.880454421043396
Validation loss: 1.8018498305351502

Epoch: 6| Step: 11
Training loss: 1.1524943113327026
Validation loss: 1.8432230744310605

Epoch: 6| Step: 12
Training loss: 1.5375953912734985
Validation loss: 1.828874385485085

Epoch: 6| Step: 13
Training loss: 1.6163771152496338
Validation loss: 1.807506904807142

Epoch: 373| Step: 0
Training loss: 0.8216915130615234
Validation loss: 1.8197097919320548

Epoch: 6| Step: 1
Training loss: 1.7582041025161743
Validation loss: 1.8143762849992322

Epoch: 6| Step: 2
Training loss: 0.9823335409164429
Validation loss: 1.8421104800316594

Epoch: 6| Step: 3
Training loss: 0.7878603935241699
Validation loss: 1.8251371127302929

Epoch: 6| Step: 4
Training loss: 1.4346446990966797
Validation loss: 1.8508906646441388

Epoch: 6| Step: 5
Training loss: 0.8390867114067078
Validation loss: 1.7251634508050897

Epoch: 6| Step: 6
Training loss: 1.4374170303344727
Validation loss: 1.8116392525293494

Epoch: 6| Step: 7
Training loss: 1.177522897720337
Validation loss: 1.8546887456729848

Epoch: 6| Step: 8
Training loss: 0.9874461889266968
Validation loss: 1.8237637922328005

Epoch: 6| Step: 9
Training loss: 1.2926585674285889
Validation loss: 1.8359468521610383

Epoch: 6| Step: 10
Training loss: 1.3434888124465942
Validation loss: 1.8550073792857509

Epoch: 6| Step: 11
Training loss: 1.5745532512664795
Validation loss: 1.8679097121761692

Epoch: 6| Step: 12
Training loss: 1.7181050777435303
Validation loss: 1.841471984822263

Epoch: 6| Step: 13
Training loss: 1.3948999643325806
Validation loss: 1.803616395560644

Epoch: 374| Step: 0
Training loss: 1.041156530380249
Validation loss: 1.8379674585916663

Epoch: 6| Step: 1
Training loss: 1.30202317237854
Validation loss: 1.8285301782751595

Epoch: 6| Step: 2
Training loss: 1.52928626537323
Validation loss: 1.8375202917283582

Epoch: 6| Step: 3
Training loss: 0.9120850563049316
Validation loss: 1.7733708222707112

Epoch: 6| Step: 4
Training loss: 1.4168156385421753
Validation loss: 1.8169786468628915

Epoch: 6| Step: 5
Training loss: 1.7452718019485474
Validation loss: 1.8158376678343742

Epoch: 6| Step: 6
Training loss: 0.7781578302383423
Validation loss: 1.8000700396876181

Epoch: 6| Step: 7
Training loss: 1.1528197526931763
Validation loss: 1.8209390588985976

Epoch: 6| Step: 8
Training loss: 1.6346536874771118
Validation loss: 1.841070298225649

Epoch: 6| Step: 9
Training loss: 1.0210384130477905
Validation loss: 1.7965899244431527

Epoch: 6| Step: 10
Training loss: 1.4646379947662354
Validation loss: 1.8065815894834456

Epoch: 6| Step: 11
Training loss: 1.6658437252044678
Validation loss: 1.858535164146013

Epoch: 6| Step: 12
Training loss: 1.1742236614227295
Validation loss: 1.8573162530058174

Epoch: 6| Step: 13
Training loss: 0.6129589080810547
Validation loss: 1.7852090507425287

Epoch: 375| Step: 0
Training loss: 1.5780298709869385
Validation loss: 1.8514597031377977

Epoch: 6| Step: 1
Training loss: 0.9199720621109009
Validation loss: 1.8486571094041229

Epoch: 6| Step: 2
Training loss: 0.9257087707519531
Validation loss: 1.8394053853968138

Epoch: 6| Step: 3
Training loss: 1.5907394886016846
Validation loss: 1.8288298435108636

Epoch: 6| Step: 4
Training loss: 1.0019640922546387
Validation loss: 1.8478683310170327

Epoch: 6| Step: 5
Training loss: 1.464210867881775
Validation loss: 1.8419257799784343

Epoch: 6| Step: 6
Training loss: 1.2662869691848755
Validation loss: 1.8495105030716106

Epoch: 6| Step: 7
Training loss: 1.1001973152160645
Validation loss: 1.8585610171800018

Epoch: 6| Step: 8
Training loss: 1.3381974697113037
Validation loss: 1.869579130603421

Epoch: 6| Step: 9
Training loss: 1.0932652950286865
Validation loss: 1.8589615027109783

Epoch: 6| Step: 10
Training loss: 1.544803500175476
Validation loss: 1.8540316422780354

Epoch: 6| Step: 11
Training loss: 1.693709373474121
Validation loss: 1.803939680899343

Epoch: 6| Step: 12
Training loss: 0.9959228038787842
Validation loss: 1.8564741816571964

Epoch: 6| Step: 13
Training loss: 1.1637670993804932
Validation loss: 1.827706568984575

Epoch: 376| Step: 0
Training loss: 0.7075201272964478
Validation loss: 1.844826941849083

Epoch: 6| Step: 1
Training loss: 1.770456075668335
Validation loss: 1.8024902779568908

Epoch: 6| Step: 2
Training loss: 0.9479612112045288
Validation loss: 1.8419314738242858

Epoch: 6| Step: 3
Training loss: 1.946012020111084
Validation loss: 1.7818905409946237

Epoch: 6| Step: 4
Training loss: 1.6612972021102905
Validation loss: 1.778358454345375

Epoch: 6| Step: 5
Training loss: 1.5543692111968994
Validation loss: 1.839255593156302

Epoch: 6| Step: 6
Training loss: 0.7651536464691162
Validation loss: 1.820917376907923

Epoch: 6| Step: 7
Training loss: 0.8611539006233215
Validation loss: 1.7637168053657777

Epoch: 6| Step: 8
Training loss: 1.3979917764663696
Validation loss: 1.7708757846586165

Epoch: 6| Step: 9
Training loss: 0.9195965528488159
Validation loss: 1.7870738467862528

Epoch: 6| Step: 10
Training loss: 1.0857772827148438
Validation loss: 1.861818762235744

Epoch: 6| Step: 11
Training loss: 1.6797819137573242
Validation loss: 1.809022662460163

Epoch: 6| Step: 12
Training loss: 0.9388577342033386
Validation loss: 1.8589742119594286

Epoch: 6| Step: 13
Training loss: 1.651370644569397
Validation loss: 1.853778854493172

Epoch: 377| Step: 0
Training loss: 1.392082691192627
Validation loss: 1.799679337009307

Epoch: 6| Step: 1
Training loss: 1.3013696670532227
Validation loss: 1.830439954675654

Epoch: 6| Step: 2
Training loss: 1.032629370689392
Validation loss: 1.8371117012475127

Epoch: 6| Step: 3
Training loss: 0.9742571115493774
Validation loss: 1.8782251201650149

Epoch: 6| Step: 4
Training loss: 1.671647071838379
Validation loss: 1.8792266307338592

Epoch: 6| Step: 5
Training loss: 1.3951926231384277
Validation loss: 1.8248053878866217

Epoch: 6| Step: 6
Training loss: 1.4865280389785767
Validation loss: 1.8683608001278293

Epoch: 6| Step: 7
Training loss: 1.0870213508605957
Validation loss: 1.8655623620556248

Epoch: 6| Step: 8
Training loss: 0.8644636869430542
Validation loss: 1.8307854565241004

Epoch: 6| Step: 9
Training loss: 1.034031867980957
Validation loss: 1.8314196832718388

Epoch: 6| Step: 10
Training loss: 2.105931282043457
Validation loss: 1.870206880313094

Epoch: 6| Step: 11
Training loss: 1.1667945384979248
Validation loss: 1.7520738929830573

Epoch: 6| Step: 12
Training loss: 0.43742167949676514
Validation loss: 1.7870647804711455

Epoch: 6| Step: 13
Training loss: 1.4686532020568848
Validation loss: 1.8639655343947872

Epoch: 378| Step: 0
Training loss: 0.9123002290725708
Validation loss: 1.8291554220261113

Epoch: 6| Step: 1
Training loss: 1.9721019268035889
Validation loss: 1.8083135158784929

Epoch: 6| Step: 2
Training loss: 1.7542377710342407
Validation loss: 1.7751837456098167

Epoch: 6| Step: 3
Training loss: 1.7864854335784912
Validation loss: 1.810025457412966

Epoch: 6| Step: 4
Training loss: 1.2305530309677124
Validation loss: 1.7505504726081766

Epoch: 6| Step: 5
Training loss: 1.262425184249878
Validation loss: 1.7912854122859176

Epoch: 6| Step: 6
Training loss: 0.688204288482666
Validation loss: 1.7780682566345378

Epoch: 6| Step: 7
Training loss: 1.1798162460327148
Validation loss: 1.8474352846863449

Epoch: 6| Step: 8
Training loss: 0.7820062637329102
Validation loss: 1.8592152339155956

Epoch: 6| Step: 9
Training loss: 0.9716705083847046
Validation loss: 1.81846740681638

Epoch: 6| Step: 10
Training loss: 1.0358706712722778
Validation loss: 1.8108381789217713

Epoch: 6| Step: 11
Training loss: 0.7287912368774414
Validation loss: 1.8188001135344147

Epoch: 6| Step: 12
Training loss: 1.033482551574707
Validation loss: 1.796511560358027

Epoch: 6| Step: 13
Training loss: 1.6243985891342163
Validation loss: 1.83360368205655

Epoch: 379| Step: 0
Training loss: 0.8979946374893188
Validation loss: 1.760588312661776

Epoch: 6| Step: 1
Training loss: 0.9160561561584473
Validation loss: 1.7934916942350325

Epoch: 6| Step: 2
Training loss: 1.1733334064483643
Validation loss: 1.7749306078880065

Epoch: 6| Step: 3
Training loss: 1.2647273540496826
Validation loss: 1.7762609156229163

Epoch: 6| Step: 4
Training loss: 0.8238502740859985
Validation loss: 1.8764003784425798

Epoch: 6| Step: 5
Training loss: 0.7917245626449585
Validation loss: 1.7772567502913936

Epoch: 6| Step: 6
Training loss: 1.730233907699585
Validation loss: 1.8293770461954095

Epoch: 6| Step: 7
Training loss: 1.7319531440734863
Validation loss: 1.8196783616978636

Epoch: 6| Step: 8
Training loss: 1.5784778594970703
Validation loss: 1.8021100849233649

Epoch: 6| Step: 9
Training loss: 1.7031364440917969
Validation loss: 1.8124140283112884

Epoch: 6| Step: 10
Training loss: 0.9111830592155457
Validation loss: 1.7927191372840636

Epoch: 6| Step: 11
Training loss: 1.1537591218948364
Validation loss: 1.8403893568182503

Epoch: 6| Step: 12
Training loss: 1.5345925092697144
Validation loss: 1.8952778052258235

Epoch: 6| Step: 13
Training loss: 1.0303683280944824
Validation loss: 1.838942591862012

Epoch: 380| Step: 0
Training loss: 1.056365728378296
Validation loss: 1.866189500337006

Epoch: 6| Step: 1
Training loss: 1.3645203113555908
Validation loss: 1.8311449898186551

Epoch: 6| Step: 2
Training loss: 1.4559686183929443
Validation loss: 1.8746750803403958

Epoch: 6| Step: 3
Training loss: 1.5367141962051392
Validation loss: 1.87848711270158

Epoch: 6| Step: 4
Training loss: 1.1475107669830322
Validation loss: 1.9204849248291345

Epoch: 6| Step: 5
Training loss: 1.2770384550094604
Validation loss: 1.8634268878608622

Epoch: 6| Step: 6
Training loss: 1.5029020309448242
Validation loss: 1.8502606653398084

Epoch: 6| Step: 7
Training loss: 1.431807518005371
Validation loss: 1.8896375317727365

Epoch: 6| Step: 8
Training loss: 1.2456581592559814
Validation loss: 1.8101328829283356

Epoch: 6| Step: 9
Training loss: 1.2839187383651733
Validation loss: 1.8279423444501814

Epoch: 6| Step: 10
Training loss: 0.7562764883041382
Validation loss: 1.8013638129798315

Epoch: 6| Step: 11
Training loss: 1.2567729949951172
Validation loss: 1.8254600609502485

Epoch: 6| Step: 12
Training loss: 0.797777533531189
Validation loss: 1.7999714061778078

Epoch: 6| Step: 13
Training loss: 1.1269285678863525
Validation loss: 1.825587264953121

Epoch: 381| Step: 0
Training loss: 1.1767189502716064
Validation loss: 1.8285140093936716

Epoch: 6| Step: 1
Training loss: 1.610715627670288
Validation loss: 1.7819832781309723

Epoch: 6| Step: 2
Training loss: 1.295865774154663
Validation loss: 1.818964881281699

Epoch: 6| Step: 3
Training loss: 0.8548671007156372
Validation loss: 1.7838008480687295

Epoch: 6| Step: 4
Training loss: 1.3555610179901123
Validation loss: 1.7552831916398899

Epoch: 6| Step: 5
Training loss: 1.1589637994766235
Validation loss: 1.7872897707005984

Epoch: 6| Step: 6
Training loss: 1.3867807388305664
Validation loss: 1.7878092347934682

Epoch: 6| Step: 7
Training loss: 1.155975103378296
Validation loss: 1.8664105297416769

Epoch: 6| Step: 8
Training loss: 1.1963040828704834
Validation loss: 1.84129544227354

Epoch: 6| Step: 9
Training loss: 1.418272852897644
Validation loss: 1.79414031838858

Epoch: 6| Step: 10
Training loss: 1.2964754104614258
Validation loss: 1.893112644072502

Epoch: 6| Step: 11
Training loss: 1.0833553075790405
Validation loss: 1.7996695990203528

Epoch: 6| Step: 12
Training loss: 0.8195857405662537
Validation loss: 1.884840875543574

Epoch: 6| Step: 13
Training loss: 1.466298222541809
Validation loss: 1.8669940886958953

Epoch: 382| Step: 0
Training loss: 1.2158384323120117
Validation loss: 1.8165117361212288

Epoch: 6| Step: 1
Training loss: 1.125678539276123
Validation loss: 1.8693196209528113

Epoch: 6| Step: 2
Training loss: 1.3714948892593384
Validation loss: 1.818582001552787

Epoch: 6| Step: 3
Training loss: 1.1295543909072876
Validation loss: 1.8285048597602434

Epoch: 6| Step: 4
Training loss: 1.5934711694717407
Validation loss: 1.839007903170842

Epoch: 6| Step: 5
Training loss: 1.0491949319839478
Validation loss: 1.8045156771136868

Epoch: 6| Step: 6
Training loss: 1.4270027875900269
Validation loss: 1.7945803647400231

Epoch: 6| Step: 7
Training loss: 1.1601512432098389
Validation loss: 1.7998651253279818

Epoch: 6| Step: 8
Training loss: 1.2359001636505127
Validation loss: 1.797158161799113

Epoch: 6| Step: 9
Training loss: 1.3185415267944336
Validation loss: 1.851063887278239

Epoch: 6| Step: 10
Training loss: 0.8958871364593506
Validation loss: 1.8384236827973397

Epoch: 6| Step: 11
Training loss: 1.472866177558899
Validation loss: 1.8100736115568428

Epoch: 6| Step: 12
Training loss: 1.193784475326538
Validation loss: 1.795159257868285

Epoch: 6| Step: 13
Training loss: 1.3604681491851807
Validation loss: 1.8484666808958976

Epoch: 383| Step: 0
Training loss: 1.231296420097351
Validation loss: 1.8515124308165682

Epoch: 6| Step: 1
Training loss: 0.8834754228591919
Validation loss: 1.7591486694992229

Epoch: 6| Step: 2
Training loss: 0.9469708800315857
Validation loss: 1.8343713052811161

Epoch: 6| Step: 3
Training loss: 1.4683184623718262
Validation loss: 1.8159787244694208

Epoch: 6| Step: 4
Training loss: 1.2646164894104004
Validation loss: 1.7716793475612518

Epoch: 6| Step: 5
Training loss: 1.5831422805786133
Validation loss: 1.774777966160928

Epoch: 6| Step: 6
Training loss: 0.6169247031211853
Validation loss: 1.8050663484040128

Epoch: 6| Step: 7
Training loss: 1.183091640472412
Validation loss: 1.825195925210112

Epoch: 6| Step: 8
Training loss: 1.5722018480300903
Validation loss: 1.7873852214505594

Epoch: 6| Step: 9
Training loss: 0.9935364723205566
Validation loss: 1.855934718603729

Epoch: 6| Step: 10
Training loss: 1.3560264110565186
Validation loss: 1.8306873280514953

Epoch: 6| Step: 11
Training loss: 1.2161768674850464
Validation loss: 1.8035453263149466

Epoch: 6| Step: 12
Training loss: 1.663311243057251
Validation loss: 1.874127164963753

Epoch: 6| Step: 13
Training loss: 1.2101576328277588
Validation loss: 1.8197607609533495

Epoch: 384| Step: 0
Training loss: 1.2855864763259888
Validation loss: 1.8683875709451654

Epoch: 6| Step: 1
Training loss: 1.0014538764953613
Validation loss: 1.8476310891489829

Epoch: 6| Step: 2
Training loss: 0.846409797668457
Validation loss: 1.7958934909553939

Epoch: 6| Step: 3
Training loss: 1.4298537969589233
Validation loss: 1.827531708184109

Epoch: 6| Step: 4
Training loss: 1.3659847974777222
Validation loss: 1.7894696932966991

Epoch: 6| Step: 5
Training loss: 1.0665444135665894
Validation loss: 1.8255727573107647

Epoch: 6| Step: 6
Training loss: 1.3882677555084229
Validation loss: 1.851535116472552

Epoch: 6| Step: 7
Training loss: 1.0464565753936768
Validation loss: 1.8348518097272484

Epoch: 6| Step: 8
Training loss: 0.8050106763839722
Validation loss: 1.7748557072813793

Epoch: 6| Step: 9
Training loss: 1.4172824621200562
Validation loss: 1.7786871489658151

Epoch: 6| Step: 10
Training loss: 1.1762813329696655
Validation loss: 1.7712722721920218

Epoch: 6| Step: 11
Training loss: 1.78791081905365
Validation loss: 1.783443885464822

Epoch: 6| Step: 12
Training loss: 1.0635309219360352
Validation loss: 1.7434930891119025

Epoch: 6| Step: 13
Training loss: 1.5766668319702148
Validation loss: 1.8418790678824148

Epoch: 385| Step: 0
Training loss: 1.1302528381347656
Validation loss: 1.9095111354704826

Epoch: 6| Step: 1
Training loss: 1.3060907125473022
Validation loss: 1.8062123214044878

Epoch: 6| Step: 2
Training loss: 1.2245213985443115
Validation loss: 1.817791227371462

Epoch: 6| Step: 3
Training loss: 1.0517109632492065
Validation loss: 1.8564867358053885

Epoch: 6| Step: 4
Training loss: 1.054581880569458
Validation loss: 1.8108717997868855

Epoch: 6| Step: 5
Training loss: 1.1315968036651611
Validation loss: 1.8615574977731193

Epoch: 6| Step: 6
Training loss: 1.650463342666626
Validation loss: 1.8761228476801226

Epoch: 6| Step: 7
Training loss: 1.3884735107421875
Validation loss: 1.804413700616488

Epoch: 6| Step: 8
Training loss: 1.1211466789245605
Validation loss: 1.848405074047786

Epoch: 6| Step: 9
Training loss: 1.822943091392517
Validation loss: 1.8747064246926257

Epoch: 6| Step: 10
Training loss: 1.0480098724365234
Validation loss: 1.8922650044964207

Epoch: 6| Step: 11
Training loss: 1.3145214319229126
Validation loss: 1.8418363422475836

Epoch: 6| Step: 12
Training loss: 0.915807843208313
Validation loss: 1.8440536939969627

Epoch: 6| Step: 13
Training loss: 1.1909584999084473
Validation loss: 1.8654429374202606

Epoch: 386| Step: 0
Training loss: 0.6000403165817261
Validation loss: 1.8555843881381455

Epoch: 6| Step: 1
Training loss: 0.948426365852356
Validation loss: 1.7913834382128972

Epoch: 6| Step: 2
Training loss: 1.887880563735962
Validation loss: 1.7965368609274588

Epoch: 6| Step: 3
Training loss: 1.3479442596435547
Validation loss: 1.7725412127792195

Epoch: 6| Step: 4
Training loss: 1.5652529001235962
Validation loss: 1.7954552147978096

Epoch: 6| Step: 5
Training loss: 1.2246813774108887
Validation loss: 1.766701579093933

Epoch: 6| Step: 6
Training loss: 1.3017181158065796
Validation loss: 1.8091698179962814

Epoch: 6| Step: 7
Training loss: 1.1208322048187256
Validation loss: 1.8793600810471403

Epoch: 6| Step: 8
Training loss: 1.2900385856628418
Validation loss: 1.8722871836795603

Epoch: 6| Step: 9
Training loss: 1.8468445539474487
Validation loss: 1.8070953789577688

Epoch: 6| Step: 10
Training loss: 1.6833961009979248
Validation loss: 1.8193995080968386

Epoch: 6| Step: 11
Training loss: 0.7784358263015747
Validation loss: 1.7590956521290604

Epoch: 6| Step: 12
Training loss: 0.9593638181686401
Validation loss: 1.8414634504625875

Epoch: 6| Step: 13
Training loss: 1.3444323539733887
Validation loss: 1.8398284578836093

Epoch: 387| Step: 0
Training loss: 1.7997348308563232
Validation loss: 1.8164540490796488

Epoch: 6| Step: 1
Training loss: 1.1488869190216064
Validation loss: 1.7965330231574275

Epoch: 6| Step: 2
Training loss: 1.0998313426971436
Validation loss: 1.8737755590869534

Epoch: 6| Step: 3
Training loss: 1.24751615524292
Validation loss: 1.820067799219521

Epoch: 6| Step: 4
Training loss: 1.765013575553894
Validation loss: 1.9031252707204511

Epoch: 6| Step: 5
Training loss: 0.9295212626457214
Validation loss: 1.9359449853179276

Epoch: 6| Step: 6
Training loss: 1.1355267763137817
Validation loss: 1.9152605866873136

Epoch: 6| Step: 7
Training loss: 0.6072260141372681
Validation loss: 1.921091361712384

Epoch: 6| Step: 8
Training loss: 1.8454638719558716
Validation loss: 1.8412354210371613

Epoch: 6| Step: 9
Training loss: 1.5642980337142944
Validation loss: 1.8530533006114345

Epoch: 6| Step: 10
Training loss: 0.6642532348632812
Validation loss: 1.8153603833208802

Epoch: 6| Step: 11
Training loss: 1.575524091720581
Validation loss: 1.836290285151492

Epoch: 6| Step: 12
Training loss: 1.065803050994873
Validation loss: 1.8393640402824647

Epoch: 6| Step: 13
Training loss: 0.7586345672607422
Validation loss: 1.8006091617768811

Epoch: 388| Step: 0
Training loss: 0.7706646919250488
Validation loss: 1.8087192530273108

Epoch: 6| Step: 1
Training loss: 1.2485628128051758
Validation loss: 1.7745618948372461

Epoch: 6| Step: 2
Training loss: 1.1424288749694824
Validation loss: 1.7862229501047442

Epoch: 6| Step: 3
Training loss: 1.2764534950256348
Validation loss: 1.822104742450099

Epoch: 6| Step: 4
Training loss: 1.5574951171875
Validation loss: 1.7711067045888593

Epoch: 6| Step: 5
Training loss: 1.0132924318313599
Validation loss: 1.752069470702961

Epoch: 6| Step: 6
Training loss: 1.612107753753662
Validation loss: 1.7785752127247472

Epoch: 6| Step: 7
Training loss: 1.4797475337982178
Validation loss: 1.744815186787677

Epoch: 6| Step: 8
Training loss: 1.474490761756897
Validation loss: 1.8038516518890217

Epoch: 6| Step: 9
Training loss: 0.8139601945877075
Validation loss: 1.7937777247480167

Epoch: 6| Step: 10
Training loss: 1.6090797185897827
Validation loss: 1.775862427167995

Epoch: 6| Step: 11
Training loss: 1.0354716777801514
Validation loss: 1.8038657044851651

Epoch: 6| Step: 12
Training loss: 1.0266820192337036
Validation loss: 1.860260522493752

Epoch: 6| Step: 13
Training loss: 2.124499559402466
Validation loss: 1.7972727757628246

Epoch: 389| Step: 0
Training loss: 1.5437300205230713
Validation loss: 1.846131440131895

Epoch: 6| Step: 1
Training loss: 1.1985291242599487
Validation loss: 1.7759371508834183

Epoch: 6| Step: 2
Training loss: 1.401176929473877
Validation loss: 1.8679461902187717

Epoch: 6| Step: 3
Training loss: 1.66975998878479
Validation loss: 1.8175888343523907

Epoch: 6| Step: 4
Training loss: 0.9561780691146851
Validation loss: 1.8556799016973025

Epoch: 6| Step: 5
Training loss: 0.9592188596725464
Validation loss: 1.9002916825714933

Epoch: 6| Step: 6
Training loss: 0.5734130144119263
Validation loss: 1.893321459011365

Epoch: 6| Step: 7
Training loss: 1.67232346534729
Validation loss: 1.8310333733917565

Epoch: 6| Step: 8
Training loss: 1.509333848953247
Validation loss: 1.8539448732970862

Epoch: 6| Step: 9
Training loss: 1.1389439105987549
Validation loss: 1.8401478798158708

Epoch: 6| Step: 10
Training loss: 1.4264633655548096
Validation loss: 1.821628902548103

Epoch: 6| Step: 11
Training loss: 0.9982187747955322
Validation loss: 1.7595224418947775

Epoch: 6| Step: 12
Training loss: 1.1617599725723267
Validation loss: 1.789401787583546

Epoch: 6| Step: 13
Training loss: 1.1784334182739258
Validation loss: 1.810842119237428

Epoch: 390| Step: 0
Training loss: 1.8714728355407715
Validation loss: 1.8173576939490534

Epoch: 6| Step: 1
Training loss: 1.2434887886047363
Validation loss: 1.8175915146386752

Epoch: 6| Step: 2
Training loss: 0.9492409229278564
Validation loss: 1.7843093179887342

Epoch: 6| Step: 3
Training loss: 1.5895156860351562
Validation loss: 1.8382429025506462

Epoch: 6| Step: 4
Training loss: 0.6799110174179077
Validation loss: 1.7628483913278068

Epoch: 6| Step: 5
Training loss: 1.232149600982666
Validation loss: 1.8691684174281296

Epoch: 6| Step: 6
Training loss: 1.5377970933914185
Validation loss: 1.8186740336879608

Epoch: 6| Step: 7
Training loss: 1.1831624507904053
Validation loss: 1.7919726371765137

Epoch: 6| Step: 8
Training loss: 1.8035938739776611
Validation loss: 1.8477778947481545

Epoch: 6| Step: 9
Training loss: 1.2658592462539673
Validation loss: 1.8513943533743582

Epoch: 6| Step: 10
Training loss: 0.42184978723526
Validation loss: 1.823456971876083

Epoch: 6| Step: 11
Training loss: 1.4201581478118896
Validation loss: 1.8637460559927008

Epoch: 6| Step: 12
Training loss: 1.2245744466781616
Validation loss: 1.851228452497913

Epoch: 6| Step: 13
Training loss: 0.6777087450027466
Validation loss: 1.810384883675524

Epoch: 391| Step: 0
Training loss: 1.5555636882781982
Validation loss: 1.858758491854514

Epoch: 6| Step: 1
Training loss: 1.4690964221954346
Validation loss: 1.8355900305573658

Epoch: 6| Step: 2
Training loss: 0.9413616061210632
Validation loss: 1.80385374253796

Epoch: 6| Step: 3
Training loss: 1.3819518089294434
Validation loss: 1.8265514450688516

Epoch: 6| Step: 4
Training loss: 1.225799322128296
Validation loss: 1.8526604290931457

Epoch: 6| Step: 5
Training loss: 1.3662476539611816
Validation loss: 1.8406119397891465

Epoch: 6| Step: 6
Training loss: 0.7289454340934753
Validation loss: 1.847127640119163

Epoch: 6| Step: 7
Training loss: 1.3616840839385986
Validation loss: 1.8372458373346636

Epoch: 6| Step: 8
Training loss: 0.7728005647659302
Validation loss: 1.8373712801164197

Epoch: 6| Step: 9
Training loss: 1.2655315399169922
Validation loss: 1.8072638806476389

Epoch: 6| Step: 10
Training loss: 1.3598589897155762
Validation loss: 1.8094040879639246

Epoch: 6| Step: 11
Training loss: 1.3721446990966797
Validation loss: 1.8760139237168014

Epoch: 6| Step: 12
Training loss: 1.2383265495300293
Validation loss: 1.8091020789197696

Epoch: 6| Step: 13
Training loss: 0.9303196668624878
Validation loss: 1.836169888896327

Epoch: 392| Step: 0
Training loss: 1.7418930530548096
Validation loss: 1.8483553906922698

Epoch: 6| Step: 1
Training loss: 1.4686577320098877
Validation loss: 1.8365844859871814

Epoch: 6| Step: 2
Training loss: 1.7868226766586304
Validation loss: 1.8723071749492357

Epoch: 6| Step: 3
Training loss: 1.2436500787734985
Validation loss: 1.8120807883560017

Epoch: 6| Step: 4
Training loss: 1.4271082878112793
Validation loss: 1.779511796530857

Epoch: 6| Step: 5
Training loss: 1.1036436557769775
Validation loss: 1.8476356255110873

Epoch: 6| Step: 6
Training loss: 1.239429235458374
Validation loss: 1.8804560797188872

Epoch: 6| Step: 7
Training loss: 0.8696303367614746
Validation loss: 1.8055537041797434

Epoch: 6| Step: 8
Training loss: 0.7958973050117493
Validation loss: 1.7878362312111804

Epoch: 6| Step: 9
Training loss: 0.6694800853729248
Validation loss: 1.7759120528415968

Epoch: 6| Step: 10
Training loss: 0.9030788540840149
Validation loss: 1.8760679998705465

Epoch: 6| Step: 11
Training loss: 1.263310432434082
Validation loss: 1.7613274628116238

Epoch: 6| Step: 12
Training loss: 1.3780837059020996
Validation loss: 1.7976247046583442

Epoch: 6| Step: 13
Training loss: 0.6947846412658691
Validation loss: 1.7581258999404086

Epoch: 393| Step: 0
Training loss: 1.2087111473083496
Validation loss: 1.8464946849371797

Epoch: 6| Step: 1
Training loss: 1.0516303777694702
Validation loss: 1.844937773161037

Epoch: 6| Step: 2
Training loss: 1.051332712173462
Validation loss: 1.8063416045199159

Epoch: 6| Step: 3
Training loss: 1.4083616733551025
Validation loss: 1.835038669647709

Epoch: 6| Step: 4
Training loss: 0.9831328988075256
Validation loss: 1.8349236365287536

Epoch: 6| Step: 5
Training loss: 1.4237958192825317
Validation loss: 1.8825014919363043

Epoch: 6| Step: 6
Training loss: 1.0572800636291504
Validation loss: 1.9087081788688578

Epoch: 6| Step: 7
Training loss: 1.2746965885162354
Validation loss: 1.8057034682202082

Epoch: 6| Step: 8
Training loss: 1.1519787311553955
Validation loss: 1.8528726716195383

Epoch: 6| Step: 9
Training loss: 1.3113417625427246
Validation loss: 1.8177176431943012

Epoch: 6| Step: 10
Training loss: 0.8725866675376892
Validation loss: 1.8245186985179942

Epoch: 6| Step: 11
Training loss: 0.8887461423873901
Validation loss: 1.8452143669128418

Epoch: 6| Step: 12
Training loss: 2.2277541160583496
Validation loss: 1.8154721695889708

Epoch: 6| Step: 13
Training loss: 1.0815417766571045
Validation loss: 1.7976345541656658

Epoch: 394| Step: 0
Training loss: 1.1427366733551025
Validation loss: 1.7612882993554557

Epoch: 6| Step: 1
Training loss: 1.3163952827453613
Validation loss: 1.746427091219092

Epoch: 6| Step: 2
Training loss: 1.4361653327941895
Validation loss: 1.8245063340792091

Epoch: 6| Step: 3
Training loss: 1.1027547121047974
Validation loss: 1.7439048085161435

Epoch: 6| Step: 4
Training loss: 1.1361936330795288
Validation loss: 1.7756548171402307

Epoch: 6| Step: 5
Training loss: 1.4634160995483398
Validation loss: 1.7732573337452386

Epoch: 6| Step: 6
Training loss: 0.9199109077453613
Validation loss: 1.775921921576223

Epoch: 6| Step: 7
Training loss: 1.6238255500793457
Validation loss: 1.8044973650286276

Epoch: 6| Step: 8
Training loss: 0.9419394731521606
Validation loss: 1.7953830329320764

Epoch: 6| Step: 9
Training loss: 0.5117380619049072
Validation loss: 1.8371952913140739

Epoch: 6| Step: 10
Training loss: 1.462317705154419
Validation loss: 1.8261710956532469

Epoch: 6| Step: 11
Training loss: 1.2240570783615112
Validation loss: 1.8043124214295418

Epoch: 6| Step: 12
Training loss: 1.3811333179473877
Validation loss: 1.8372823166590866

Epoch: 6| Step: 13
Training loss: 1.723207950592041
Validation loss: 1.8054226559977378

Epoch: 395| Step: 0
Training loss: 1.4835777282714844
Validation loss: 1.8494601211240214

Epoch: 6| Step: 1
Training loss: 0.9217398762702942
Validation loss: 1.8150608847218175

Epoch: 6| Step: 2
Training loss: 1.066285252571106
Validation loss: 1.872463172481906

Epoch: 6| Step: 3
Training loss: 1.5671398639678955
Validation loss: 1.8069526226289812

Epoch: 6| Step: 4
Training loss: 1.480377435684204
Validation loss: 1.8385947032641339

Epoch: 6| Step: 5
Training loss: 1.2238633632659912
Validation loss: 1.8546369485957648

Epoch: 6| Step: 6
Training loss: 1.4350249767303467
Validation loss: 1.8054896336729809

Epoch: 6| Step: 7
Training loss: 0.8609309792518616
Validation loss: 1.8658519906382407

Epoch: 6| Step: 8
Training loss: 1.0370012521743774
Validation loss: 1.9314512821935839

Epoch: 6| Step: 9
Training loss: 1.336714744567871
Validation loss: 1.8007005107018255

Epoch: 6| Step: 10
Training loss: 0.8546266555786133
Validation loss: 1.8240749374512704

Epoch: 6| Step: 11
Training loss: 1.7455579042434692
Validation loss: 1.8310315250068583

Epoch: 6| Step: 12
Training loss: 1.039472222328186
Validation loss: 1.8778296696242465

Epoch: 6| Step: 13
Training loss: 1.188294529914856
Validation loss: 1.8072021379265735

Epoch: 396| Step: 0
Training loss: 0.9787753820419312
Validation loss: 1.7657982367341236

Epoch: 6| Step: 1
Training loss: 1.053941011428833
Validation loss: 1.836606200023364

Epoch: 6| Step: 2
Training loss: 1.488242268562317
Validation loss: 1.7824969599323888

Epoch: 6| Step: 3
Training loss: 1.0352721214294434
Validation loss: 1.8330662083882157

Epoch: 6| Step: 4
Training loss: 1.2566152811050415
Validation loss: 1.7557641254958285

Epoch: 6| Step: 5
Training loss: 1.5106289386749268
Validation loss: 1.8148667722619989

Epoch: 6| Step: 6
Training loss: 0.8167346715927124
Validation loss: 1.7908211382486487

Epoch: 6| Step: 7
Training loss: 1.1943670511245728
Validation loss: 1.8147214394743725

Epoch: 6| Step: 8
Training loss: 1.1951513290405273
Validation loss: 1.7826489530583864

Epoch: 6| Step: 9
Training loss: 1.3450860977172852
Validation loss: 1.7781253335296467

Epoch: 6| Step: 10
Training loss: 1.5173476934432983
Validation loss: 1.7898421736173733

Epoch: 6| Step: 11
Training loss: 1.1738492250442505
Validation loss: 1.7526998981352775

Epoch: 6| Step: 12
Training loss: 1.0510295629501343
Validation loss: 1.8138648412560905

Epoch: 6| Step: 13
Training loss: 1.5195591449737549
Validation loss: 1.7934276647465204

Epoch: 397| Step: 0
Training loss: 1.52949857711792
Validation loss: 1.8474240482494395

Epoch: 6| Step: 1
Training loss: 1.5760400295257568
Validation loss: 1.8446665451090822

Epoch: 6| Step: 2
Training loss: 1.181542158126831
Validation loss: 1.8216009639924573

Epoch: 6| Step: 3
Training loss: 0.9614564180374146
Validation loss: 1.9198480165132912

Epoch: 6| Step: 4
Training loss: 1.2024242877960205
Validation loss: 1.8229598742659374

Epoch: 6| Step: 5
Training loss: 0.6834683418273926
Validation loss: 1.8922532091858566

Epoch: 6| Step: 6
Training loss: 0.6855430603027344
Validation loss: 1.869378871815179

Epoch: 6| Step: 7
Training loss: 1.348954439163208
Validation loss: 1.8499331935759513

Epoch: 6| Step: 8
Training loss: 1.3026340007781982
Validation loss: 1.7952523334051973

Epoch: 6| Step: 9
Training loss: 0.926215648651123
Validation loss: 1.797750437131492

Epoch: 6| Step: 10
Training loss: 1.45132577419281
Validation loss: 1.7939770849802161

Epoch: 6| Step: 11
Training loss: 1.6809710264205933
Validation loss: 1.79065030108216

Epoch: 6| Step: 12
Training loss: 1.2622253894805908
Validation loss: 1.7947615423510153

Epoch: 6| Step: 13
Training loss: 1.324083685874939
Validation loss: 1.7929079917169386

Epoch: 398| Step: 0
Training loss: 1.7050873041152954
Validation loss: 1.7991844941211004

Epoch: 6| Step: 1
Training loss: 0.9037032127380371
Validation loss: 1.8092680643963557

Epoch: 6| Step: 2
Training loss: 1.6948717832565308
Validation loss: 1.808085472353043

Epoch: 6| Step: 3
Training loss: 0.9304971694946289
Validation loss: 1.813001532708445

Epoch: 6| Step: 4
Training loss: 0.9226219654083252
Validation loss: 1.826899064484463

Epoch: 6| Step: 5
Training loss: 1.1250616312026978
Validation loss: 1.8067375126705374

Epoch: 6| Step: 6
Training loss: 1.4760674238204956
Validation loss: 1.816428953601468

Epoch: 6| Step: 7
Training loss: 0.8733327984809875
Validation loss: 1.8442537835849229

Epoch: 6| Step: 8
Training loss: 1.0834248065948486
Validation loss: 1.8847206228522844

Epoch: 6| Step: 9
Training loss: 1.0768218040466309
Validation loss: 1.7829991861056256

Epoch: 6| Step: 10
Training loss: 1.4317083358764648
Validation loss: 1.8539305528004963

Epoch: 6| Step: 11
Training loss: 1.106776237487793
Validation loss: 1.8482979497601908

Epoch: 6| Step: 12
Training loss: 1.0630760192871094
Validation loss: 1.812738105814944

Epoch: 6| Step: 13
Training loss: 1.4993212223052979
Validation loss: 1.8231610982648787

Epoch: 399| Step: 0
Training loss: 0.9133479595184326
Validation loss: 1.8191606639533915

Epoch: 6| Step: 1
Training loss: 0.7099161744117737
Validation loss: 1.8261169041356733

Epoch: 6| Step: 2
Training loss: 1.0784695148468018
Validation loss: 1.8252468570586173

Epoch: 6| Step: 3
Training loss: 1.5940825939178467
Validation loss: 1.8331417755414081

Epoch: 6| Step: 4
Training loss: 1.358198642730713
Validation loss: 1.7713426672002321

Epoch: 6| Step: 5
Training loss: 0.9883222579956055
Validation loss: 1.8041682768893499

Epoch: 6| Step: 6
Training loss: 0.613487958908081
Validation loss: 1.8294884184355378

Epoch: 6| Step: 7
Training loss: 1.6489710807800293
Validation loss: 1.822623788669545

Epoch: 6| Step: 8
Training loss: 1.8187252283096313
Validation loss: 1.8366450404608121

Epoch: 6| Step: 9
Training loss: 1.2317447662353516
Validation loss: 1.8599956368887296

Epoch: 6| Step: 10
Training loss: 1.2632246017456055
Validation loss: 1.8273650689791607

Epoch: 6| Step: 11
Training loss: 1.3541938066482544
Validation loss: 1.8478470899725472

Epoch: 6| Step: 12
Training loss: 1.3005918264389038
Validation loss: 1.7677331868038382

Epoch: 6| Step: 13
Training loss: 1.2837148904800415
Validation loss: 1.7789336994130125

Epoch: 400| Step: 0
Training loss: 0.7568140029907227
Validation loss: 1.789424318139271

Epoch: 6| Step: 1
Training loss: 1.7426459789276123
Validation loss: 1.7834621680680143

Epoch: 6| Step: 2
Training loss: 1.431300163269043
Validation loss: 1.7827754648782874

Epoch: 6| Step: 3
Training loss: 1.0265228748321533
Validation loss: 1.8442354240725118

Epoch: 6| Step: 4
Training loss: 1.0262829065322876
Validation loss: 1.8554315259379726

Epoch: 6| Step: 5
Training loss: 1.4076144695281982
Validation loss: 1.784164861966205

Epoch: 6| Step: 6
Training loss: 1.7352793216705322
Validation loss: 1.8272975516575638

Epoch: 6| Step: 7
Training loss: 1.6157689094543457
Validation loss: 1.800976178979361

Epoch: 6| Step: 8
Training loss: 0.9668329954147339
Validation loss: 1.873675020792151

Epoch: 6| Step: 9
Training loss: 1.231095790863037
Validation loss: 1.764634229803598

Epoch: 6| Step: 10
Training loss: 0.7840214967727661
Validation loss: 1.8229795091895646

Epoch: 6| Step: 11
Training loss: 1.1354527473449707
Validation loss: 1.8766533418368267

Epoch: 6| Step: 12
Training loss: 1.0011811256408691
Validation loss: 1.859285528941821

Epoch: 6| Step: 13
Training loss: 1.3372398614883423
Validation loss: 1.7718724730194255

Epoch: 401| Step: 0
Training loss: 1.1052911281585693
Validation loss: 1.8228995018107916

Epoch: 6| Step: 1
Training loss: 1.2325061559677124
Validation loss: 1.8012169971260974

Epoch: 6| Step: 2
Training loss: 1.2330105304718018
Validation loss: 1.807995295011869

Epoch: 6| Step: 3
Training loss: 1.1075727939605713
Validation loss: 1.8337015208377634

Epoch: 6| Step: 4
Training loss: 1.0921289920806885
Validation loss: 1.8007595718547862

Epoch: 6| Step: 5
Training loss: 1.1100475788116455
Validation loss: 1.830639535380948

Epoch: 6| Step: 6
Training loss: 0.9183088541030884
Validation loss: 1.8547579037245883

Epoch: 6| Step: 7
Training loss: 1.7286732196807861
Validation loss: 1.7891663735912693

Epoch: 6| Step: 8
Training loss: 0.6469330787658691
Validation loss: 1.8534166864169541

Epoch: 6| Step: 9
Training loss: 1.7601008415222168
Validation loss: 1.7818580712041547

Epoch: 6| Step: 10
Training loss: 1.3300995826721191
Validation loss: 1.8286141246877692

Epoch: 6| Step: 11
Training loss: 1.3279504776000977
Validation loss: 1.7752896098680393

Epoch: 6| Step: 12
Training loss: 0.9818146228790283
Validation loss: 1.7985972486516482

Epoch: 6| Step: 13
Training loss: 1.867105484008789
Validation loss: 1.766666163680374

Epoch: 402| Step: 0
Training loss: 0.6358944773674011
Validation loss: 1.8383336695291663

Epoch: 6| Step: 1
Training loss: 0.9793428182601929
Validation loss: 1.845692310281979

Epoch: 6| Step: 2
Training loss: 1.4089393615722656
Validation loss: 1.8485794682656564

Epoch: 6| Step: 3
Training loss: 0.9725976586341858
Validation loss: 1.7955537713984007

Epoch: 6| Step: 4
Training loss: 1.519230604171753
Validation loss: 1.801949575383176

Epoch: 6| Step: 5
Training loss: 1.25345778465271
Validation loss: 1.8444455003225675

Epoch: 6| Step: 6
Training loss: 1.5514521598815918
Validation loss: 1.8331468284771006

Epoch: 6| Step: 7
Training loss: 1.351279377937317
Validation loss: 1.826297954846454

Epoch: 6| Step: 8
Training loss: 1.1288220882415771
Validation loss: 1.842428179197414

Epoch: 6| Step: 9
Training loss: 1.962354302406311
Validation loss: 1.851005918236189

Epoch: 6| Step: 10
Training loss: 1.2384192943572998
Validation loss: 1.8710742201856387

Epoch: 6| Step: 11
Training loss: 1.1808207035064697
Validation loss: 1.8025236514306837

Epoch: 6| Step: 12
Training loss: 0.8620573282241821
Validation loss: 1.8465182473582606

Epoch: 6| Step: 13
Training loss: 1.0578714609146118
Validation loss: 1.8421471990564817

Epoch: 403| Step: 0
Training loss: 1.3376529216766357
Validation loss: 1.8189755755086099

Epoch: 6| Step: 1
Training loss: 0.9659368991851807
Validation loss: 1.8009645426145164

Epoch: 6| Step: 2
Training loss: 0.6268438100814819
Validation loss: 1.8160218320867068

Epoch: 6| Step: 3
Training loss: 1.0855422019958496
Validation loss: 1.9111326663724837

Epoch: 6| Step: 4
Training loss: 1.1823041439056396
Validation loss: 1.8524134492361417

Epoch: 6| Step: 5
Training loss: 1.1721761226654053
Validation loss: 1.8020785162525792

Epoch: 6| Step: 6
Training loss: 1.5183595418930054
Validation loss: 1.8407893437211231

Epoch: 6| Step: 7
Training loss: 1.3574104309082031
Validation loss: 1.8241545282384402

Epoch: 6| Step: 8
Training loss: 1.1808863878250122
Validation loss: 1.809559396518174

Epoch: 6| Step: 9
Training loss: 1.434972882270813
Validation loss: 1.8278827180144608

Epoch: 6| Step: 10
Training loss: 0.9527935981750488
Validation loss: 1.8255135397757254

Epoch: 6| Step: 11
Training loss: 0.9844234585762024
Validation loss: 1.8326779180957424

Epoch: 6| Step: 12
Training loss: 1.5147664546966553
Validation loss: 1.8028653667819114

Epoch: 6| Step: 13
Training loss: 1.0582002401351929
Validation loss: 1.7834440072377522

Epoch: 404| Step: 0
Training loss: 1.1447837352752686
Validation loss: 1.8503801309934227

Epoch: 6| Step: 1
Training loss: 1.1143221855163574
Validation loss: 1.7917228065511233

Epoch: 6| Step: 2
Training loss: 1.097989559173584
Validation loss: 1.7870235507206251

Epoch: 6| Step: 3
Training loss: 1.4092371463775635
Validation loss: 1.7672303145931614

Epoch: 6| Step: 4
Training loss: 1.8717031478881836
Validation loss: 1.808132722813596

Epoch: 6| Step: 5
Training loss: 1.0886927843093872
Validation loss: 1.7445868022980229

Epoch: 6| Step: 6
Training loss: 0.6861698627471924
Validation loss: 1.7999115643962738

Epoch: 6| Step: 7
Training loss: 0.9561530947685242
Validation loss: 1.7977623311422204

Epoch: 6| Step: 8
Training loss: 1.1524248123168945
Validation loss: 1.8301607498558619

Epoch: 6| Step: 9
Training loss: 1.671196460723877
Validation loss: 1.8455864819147254

Epoch: 6| Step: 10
Training loss: 1.7751730680465698
Validation loss: 1.8697092994566886

Epoch: 6| Step: 11
Training loss: 1.1823570728302002
Validation loss: 1.8619440576081634

Epoch: 6| Step: 12
Training loss: 0.9233791828155518
Validation loss: 1.8314958977442917

Epoch: 6| Step: 13
Training loss: 0.6079385280609131
Validation loss: 1.8719013532002766

Epoch: 405| Step: 0
Training loss: 0.938255786895752
Validation loss: 1.8238904091619677

Epoch: 6| Step: 1
Training loss: 1.0861084461212158
Validation loss: 1.8345678365358742

Epoch: 6| Step: 2
Training loss: 1.6452674865722656
Validation loss: 1.784820964259486

Epoch: 6| Step: 3
Training loss: 1.3077987432479858
Validation loss: 1.8020366109827513

Epoch: 6| Step: 4
Training loss: 1.2387778759002686
Validation loss: 1.8532190681785665

Epoch: 6| Step: 5
Training loss: 1.5084564685821533
Validation loss: 1.8297227992806384

Epoch: 6| Step: 6
Training loss: 0.7900741696357727
Validation loss: 1.8339037369656306

Epoch: 6| Step: 7
Training loss: 1.0279879570007324
Validation loss: 1.7701145641265377

Epoch: 6| Step: 8
Training loss: 1.0747331380844116
Validation loss: 1.8551862650020148

Epoch: 6| Step: 9
Training loss: 1.0598914623260498
Validation loss: 1.780301640110631

Epoch: 6| Step: 10
Training loss: 0.8803772926330566
Validation loss: 1.7507717237677625

Epoch: 6| Step: 11
Training loss: 1.4827308654785156
Validation loss: 1.7678115572980655

Epoch: 6| Step: 12
Training loss: 1.2641775608062744
Validation loss: 1.792338866059498

Epoch: 6| Step: 13
Training loss: 1.1843926906585693
Validation loss: 1.7321749605158323

Epoch: 406| Step: 0
Training loss: 1.1155200004577637
Validation loss: 1.8030027292108024

Epoch: 6| Step: 1
Training loss: 1.3393521308898926
Validation loss: 1.7408325095330515

Epoch: 6| Step: 2
Training loss: 1.3200252056121826
Validation loss: 1.8265084579426756

Epoch: 6| Step: 3
Training loss: 1.4937968254089355
Validation loss: 1.7711583260566957

Epoch: 6| Step: 4
Training loss: 0.6387604475021362
Validation loss: 1.7886431832467355

Epoch: 6| Step: 5
Training loss: 0.9548911452293396
Validation loss: 1.8110431214814544

Epoch: 6| Step: 6
Training loss: 1.1117087602615356
Validation loss: 1.8510914041150002

Epoch: 6| Step: 7
Training loss: 1.1438965797424316
Validation loss: 1.8601054837626796

Epoch: 6| Step: 8
Training loss: 1.0370450019836426
Validation loss: 1.845045945977652

Epoch: 6| Step: 9
Training loss: 1.4325690269470215
Validation loss: 1.856785842167434

Epoch: 6| Step: 10
Training loss: 0.8992390632629395
Validation loss: 1.9159069856007893

Epoch: 6| Step: 11
Training loss: 1.0970277786254883
Validation loss: 1.9031412665561964

Epoch: 6| Step: 12
Training loss: 1.636596441268921
Validation loss: 1.95366536032769

Epoch: 6| Step: 13
Training loss: 1.4254441261291504
Validation loss: 1.9128861452943535

Epoch: 407| Step: 0
Training loss: 0.8684486150741577
Validation loss: 1.9197021876612017

Epoch: 6| Step: 1
Training loss: 1.6177785396575928
Validation loss: 1.8822350066195253

Epoch: 6| Step: 2
Training loss: 0.8103870153427124
Validation loss: 1.8463377606484197

Epoch: 6| Step: 3
Training loss: 1.0646092891693115
Validation loss: 1.8284536766749557

Epoch: 6| Step: 4
Training loss: 1.3753293752670288
Validation loss: 1.8127726149815384

Epoch: 6| Step: 5
Training loss: 0.8980109691619873
Validation loss: 1.7994003013897968

Epoch: 6| Step: 6
Training loss: 0.9915527105331421
Validation loss: 1.852670318336897

Epoch: 6| Step: 7
Training loss: 1.1879589557647705
Validation loss: 1.7997786101474558

Epoch: 6| Step: 8
Training loss: 1.2596678733825684
Validation loss: 1.7811262466574227

Epoch: 6| Step: 9
Training loss: 0.8490482568740845
Validation loss: 1.751414042647167

Epoch: 6| Step: 10
Training loss: 1.9896345138549805
Validation loss: 1.8001271537555161

Epoch: 6| Step: 11
Training loss: 1.319810152053833
Validation loss: 1.823831744091485

Epoch: 6| Step: 12
Training loss: 1.2414977550506592
Validation loss: 1.799065436086347

Epoch: 6| Step: 13
Training loss: 1.285797357559204
Validation loss: 1.8512001396507345

Epoch: 408| Step: 0
Training loss: 0.9818984270095825
Validation loss: 1.7632427882122736

Epoch: 6| Step: 1
Training loss: 0.9472375512123108
Validation loss: 1.8485841879280664

Epoch: 6| Step: 2
Training loss: 1.558398962020874
Validation loss: 1.8814730772408106

Epoch: 6| Step: 3
Training loss: 1.3527026176452637
Validation loss: 1.8529667418490174

Epoch: 6| Step: 4
Training loss: 0.7805023789405823
Validation loss: 1.9006767029403357

Epoch: 6| Step: 5
Training loss: 1.6433833837509155
Validation loss: 1.863979447272516

Epoch: 6| Step: 6
Training loss: 0.8550208806991577
Validation loss: 1.8657697285375288

Epoch: 6| Step: 7
Training loss: 1.2783524990081787
Validation loss: 1.8582747264574933

Epoch: 6| Step: 8
Training loss: 1.823324203491211
Validation loss: 1.8300305399843442

Epoch: 6| Step: 9
Training loss: 0.6564795970916748
Validation loss: 1.81509490166941

Epoch: 6| Step: 10
Training loss: 1.2323086261749268
Validation loss: 1.7988442643996208

Epoch: 6| Step: 11
Training loss: 1.3510982990264893
Validation loss: 1.8757727389694543

Epoch: 6| Step: 12
Training loss: 1.1294209957122803
Validation loss: 1.8400169905795847

Epoch: 6| Step: 13
Training loss: 0.5757922530174255
Validation loss: 1.8285751086409374

Epoch: 409| Step: 0
Training loss: 1.7580599784851074
Validation loss: 1.83530976182671

Epoch: 6| Step: 1
Training loss: 0.5534583926200867
Validation loss: 1.7809216655710691

Epoch: 6| Step: 2
Training loss: 1.3478684425354004
Validation loss: 1.8675948714697233

Epoch: 6| Step: 3
Training loss: 1.256568193435669
Validation loss: 1.7720050914313203

Epoch: 6| Step: 4
Training loss: 1.067706823348999
Validation loss: 1.8823570577047204

Epoch: 6| Step: 5
Training loss: 1.1439518928527832
Validation loss: 1.8176637567499632

Epoch: 6| Step: 6
Training loss: 1.0116292238235474
Validation loss: 1.8609935698970672

Epoch: 6| Step: 7
Training loss: 1.7160533666610718
Validation loss: 1.7807928759564635

Epoch: 6| Step: 8
Training loss: 0.9627631902694702
Validation loss: 1.7937543238362958

Epoch: 6| Step: 9
Training loss: 1.2076916694641113
Validation loss: 1.768917170904016

Epoch: 6| Step: 10
Training loss: 0.9180365204811096
Validation loss: 1.767568676702438

Epoch: 6| Step: 11
Training loss: 1.1257050037384033
Validation loss: 1.8416292205933602

Epoch: 6| Step: 12
Training loss: 1.4183306694030762
Validation loss: 1.7923034519277594

Epoch: 6| Step: 13
Training loss: 1.1220167875289917
Validation loss: 1.7748257293496081

Epoch: 410| Step: 0
Training loss: 0.6995532512664795
Validation loss: 1.7767401728578793

Epoch: 6| Step: 1
Training loss: 0.8984577059745789
Validation loss: 1.7305764626431208

Epoch: 6| Step: 2
Training loss: 1.8412173986434937
Validation loss: 1.8222876441094182

Epoch: 6| Step: 3
Training loss: 1.1176161766052246
Validation loss: 1.7672612731174757

Epoch: 6| Step: 4
Training loss: 0.7918442487716675
Validation loss: 1.8060328383599558

Epoch: 6| Step: 5
Training loss: 1.7049787044525146
Validation loss: 1.7793221063511346

Epoch: 6| Step: 6
Training loss: 0.6089746952056885
Validation loss: 1.8290787960893364

Epoch: 6| Step: 7
Training loss: 1.4869714975357056
Validation loss: 1.8011962354824107

Epoch: 6| Step: 8
Training loss: 1.105519413948059
Validation loss: 1.7959063617132043

Epoch: 6| Step: 9
Training loss: 1.0193089246749878
Validation loss: 1.779056349108296

Epoch: 6| Step: 10
Training loss: 1.3788697719573975
Validation loss: 1.8365560577761741

Epoch: 6| Step: 11
Training loss: 0.9797040820121765
Validation loss: 1.8347565909867645

Epoch: 6| Step: 12
Training loss: 1.1714330911636353
Validation loss: 1.7633790059756207

Epoch: 6| Step: 13
Training loss: 1.9004838466644287
Validation loss: 1.7459030817913752

Epoch: 411| Step: 0
Training loss: 1.3840458393096924
Validation loss: 1.8072441316420031

Epoch: 6| Step: 1
Training loss: 0.9703027009963989
Validation loss: 1.8442083276728147

Epoch: 6| Step: 2
Training loss: 1.5567595958709717
Validation loss: 1.7970798400140577

Epoch: 6| Step: 3
Training loss: 1.0738403797149658
Validation loss: 1.833050230497955

Epoch: 6| Step: 4
Training loss: 0.8803341388702393
Validation loss: 1.8431452448650072

Epoch: 6| Step: 5
Training loss: 0.9385517835617065
Validation loss: 1.814347920879241

Epoch: 6| Step: 6
Training loss: 1.4104825258255005
Validation loss: 1.791571996545279

Epoch: 6| Step: 7
Training loss: 1.0922493934631348
Validation loss: 1.8249087154224355

Epoch: 6| Step: 8
Training loss: 1.0733013153076172
Validation loss: 1.8043314449248775

Epoch: 6| Step: 9
Training loss: 1.1308364868164062
Validation loss: 1.8118706980059225

Epoch: 6| Step: 10
Training loss: 1.2121093273162842
Validation loss: 1.8818376500119445

Epoch: 6| Step: 11
Training loss: 1.0339142084121704
Validation loss: 1.7647926294675438

Epoch: 6| Step: 12
Training loss: 1.3549997806549072
Validation loss: 1.8350827642666396

Epoch: 6| Step: 13
Training loss: 1.0758213996887207
Validation loss: 1.8228584579242173

Epoch: 412| Step: 0
Training loss: 0.9356148838996887
Validation loss: 1.7990775954338811

Epoch: 6| Step: 1
Training loss: 0.7514094114303589
Validation loss: 1.830341269893031

Epoch: 6| Step: 2
Training loss: 1.38079833984375
Validation loss: 1.8515502509250437

Epoch: 6| Step: 3
Training loss: 1.2908947467803955
Validation loss: 1.8892220053621518

Epoch: 6| Step: 4
Training loss: 1.0414178371429443
Validation loss: 1.8542691917829617

Epoch: 6| Step: 5
Training loss: 1.1374305486679077
Validation loss: 1.8403189759100638

Epoch: 6| Step: 6
Training loss: 0.8988120555877686
Validation loss: 1.7968508223051667

Epoch: 6| Step: 7
Training loss: 1.288017749786377
Validation loss: 1.7845429643507926

Epoch: 6| Step: 8
Training loss: 1.929101586341858
Validation loss: 1.7530239326979524

Epoch: 6| Step: 9
Training loss: 1.028250813484192
Validation loss: 1.8100824868807228

Epoch: 6| Step: 10
Training loss: 0.9614386558532715
Validation loss: 1.7919482146539996

Epoch: 6| Step: 11
Training loss: 0.9704612493515015
Validation loss: 1.7071195789562759

Epoch: 6| Step: 12
Training loss: 0.8781294822692871
Validation loss: 1.7919688404247325

Epoch: 6| Step: 13
Training loss: 1.5724196434020996
Validation loss: 1.7984969308299403

Epoch: 413| Step: 0
Training loss: 1.5189423561096191
Validation loss: 1.8511467005616875

Epoch: 6| Step: 1
Training loss: 1.0301461219787598
Validation loss: 1.7609767093453357

Epoch: 6| Step: 2
Training loss: 1.6823580265045166
Validation loss: 1.7590827634257655

Epoch: 6| Step: 3
Training loss: 0.9856752753257751
Validation loss: 1.7800699869791667

Epoch: 6| Step: 4
Training loss: 1.1481165885925293
Validation loss: 1.7796584239570044

Epoch: 6| Step: 5
Training loss: 0.6647655963897705
Validation loss: 1.837754645655232

Epoch: 6| Step: 6
Training loss: 1.3844377994537354
Validation loss: 1.8535486088004163

Epoch: 6| Step: 7
Training loss: 1.7290043830871582
Validation loss: 1.8598176048647972

Epoch: 6| Step: 8
Training loss: 1.1447970867156982
Validation loss: 1.832190828938638

Epoch: 6| Step: 9
Training loss: 1.0691556930541992
Validation loss: 1.8627565547984133

Epoch: 6| Step: 10
Training loss: 1.06854248046875
Validation loss: 1.8497470553203295

Epoch: 6| Step: 11
Training loss: 1.3428986072540283
Validation loss: 1.7767758830901115

Epoch: 6| Step: 12
Training loss: 0.7399497628211975
Validation loss: 1.8014307727095902

Epoch: 6| Step: 13
Training loss: 0.8441914319992065
Validation loss: 1.8212932194432905

Epoch: 414| Step: 0
Training loss: 0.8800833821296692
Validation loss: 1.844612875292378

Epoch: 6| Step: 1
Training loss: 1.3090226650238037
Validation loss: 1.8663137189803585

Epoch: 6| Step: 2
Training loss: 1.4965413808822632
Validation loss: 1.833795077057295

Epoch: 6| Step: 3
Training loss: 1.7234057188034058
Validation loss: 1.8953990115914294

Epoch: 6| Step: 4
Training loss: 0.8723708987236023
Validation loss: 1.8288401698553434

Epoch: 6| Step: 5
Training loss: 1.2811884880065918
Validation loss: 1.867259233228622

Epoch: 6| Step: 6
Training loss: 1.1546571254730225
Validation loss: 1.9370840877614997

Epoch: 6| Step: 7
Training loss: 0.8414283394813538
Validation loss: 1.837379568366594

Epoch: 6| Step: 8
Training loss: 1.887101173400879
Validation loss: 1.8037447724291074

Epoch: 6| Step: 9
Training loss: 1.0174812078475952
Validation loss: 1.8257471002558225

Epoch: 6| Step: 10
Training loss: 1.0013678073883057
Validation loss: 1.8175498516328874

Epoch: 6| Step: 11
Training loss: 1.1379368305206299
Validation loss: 1.7939890610274447

Epoch: 6| Step: 12
Training loss: 1.0934923887252808
Validation loss: 1.7755032162512503

Epoch: 6| Step: 13
Training loss: 0.42680850625038147
Validation loss: 1.8120540931660643

Epoch: 415| Step: 0
Training loss: 1.0219297409057617
Validation loss: 1.7926494613770516

Epoch: 6| Step: 1
Training loss: 1.6622636318206787
Validation loss: 1.8445138162182224

Epoch: 6| Step: 2
Training loss: 1.50826096534729
Validation loss: 1.77976906043227

Epoch: 6| Step: 3
Training loss: 1.6999449729919434
Validation loss: 1.74781846743758

Epoch: 6| Step: 4
Training loss: 1.5775079727172852
Validation loss: 1.7216924364848802

Epoch: 6| Step: 5
Training loss: 0.7535215616226196
Validation loss: 1.820680191439967

Epoch: 6| Step: 6
Training loss: 1.0418171882629395
Validation loss: 1.8623169775932067

Epoch: 6| Step: 7
Training loss: 0.6799237132072449
Validation loss: 1.8528915246327717

Epoch: 6| Step: 8
Training loss: 0.7835071086883545
Validation loss: 1.9115194851352322

Epoch: 6| Step: 9
Training loss: 1.4173948764801025
Validation loss: 1.8814331126469437

Epoch: 6| Step: 10
Training loss: 0.884615421295166
Validation loss: 1.8799038446077736

Epoch: 6| Step: 11
Training loss: 0.8375145196914673
Validation loss: 1.9070353020903885

Epoch: 6| Step: 12
Training loss: 0.944568395614624
Validation loss: 1.8322945666569534

Epoch: 6| Step: 13
Training loss: 1.9239338636398315
Validation loss: 1.795296815133864

Epoch: 416| Step: 0
Training loss: 1.1383378505706787
Validation loss: 1.8463060727683447

Epoch: 6| Step: 1
Training loss: 1.060478687286377
Validation loss: 1.7887032954923567

Epoch: 6| Step: 2
Training loss: 1.2184703350067139
Validation loss: 1.7568636530189103

Epoch: 6| Step: 3
Training loss: 0.8551756143569946
Validation loss: 1.8161524970044371

Epoch: 6| Step: 4
Training loss: 0.9539923667907715
Validation loss: 1.8103921259603193

Epoch: 6| Step: 5
Training loss: 1.3234326839447021
Validation loss: 1.7650214472124655

Epoch: 6| Step: 6
Training loss: 0.9847239851951599
Validation loss: 1.8288521766662598

Epoch: 6| Step: 7
Training loss: 1.4292093515396118
Validation loss: 1.84267625757443

Epoch: 6| Step: 8
Training loss: 1.022306203842163
Validation loss: 1.8040312028700305

Epoch: 6| Step: 9
Training loss: 1.2481932640075684
Validation loss: 1.8065940013495825

Epoch: 6| Step: 10
Training loss: 0.8430641889572144
Validation loss: 1.8283885550755326

Epoch: 6| Step: 11
Training loss: 0.9998181462287903
Validation loss: 1.7879719324009393

Epoch: 6| Step: 12
Training loss: 2.039875030517578
Validation loss: 1.8087529790016912

Epoch: 6| Step: 13
Training loss: 1.6060209274291992
Validation loss: 1.806467843312089

Epoch: 417| Step: 0
Training loss: 1.6670005321502686
Validation loss: 1.8134693919971425

Epoch: 6| Step: 1
Training loss: 0.8001084923744202
Validation loss: 1.814586708622594

Epoch: 6| Step: 2
Training loss: 1.1555557250976562
Validation loss: 1.8295339102386146

Epoch: 6| Step: 3
Training loss: 1.423600196838379
Validation loss: 1.827143640928371

Epoch: 6| Step: 4
Training loss: 0.659713625907898
Validation loss: 1.8607804852147256

Epoch: 6| Step: 5
Training loss: 1.3679885864257812
Validation loss: 1.8325932077182236

Epoch: 6| Step: 6
Training loss: 1.358669400215149
Validation loss: 1.8906186255075599

Epoch: 6| Step: 7
Training loss: 1.0802571773529053
Validation loss: 1.8639944522611556

Epoch: 6| Step: 8
Training loss: 1.1768121719360352
Validation loss: 1.8981419917075866

Epoch: 6| Step: 9
Training loss: 0.9273765087127686
Validation loss: 1.8766975697650705

Epoch: 6| Step: 10
Training loss: 0.9564098119735718
Validation loss: 1.7968185742696126

Epoch: 6| Step: 11
Training loss: 0.7507245540618896
Validation loss: 1.8177449600670927

Epoch: 6| Step: 12
Training loss: 1.3105696439743042
Validation loss: 1.8144885570772233

Epoch: 6| Step: 13
Training loss: 1.8959295749664307
Validation loss: 1.7886676813966484

Epoch: 418| Step: 0
Training loss: 0.6003431081771851
Validation loss: 1.7728460591326478

Epoch: 6| Step: 1
Training loss: 1.2640002965927124
Validation loss: 1.7952932004005677

Epoch: 6| Step: 2
Training loss: 1.9673659801483154
Validation loss: 1.8558564775733537

Epoch: 6| Step: 3
Training loss: 1.0565012693405151
Validation loss: 1.7349416876351962

Epoch: 6| Step: 4
Training loss: 1.4536852836608887
Validation loss: 1.8377446295112692

Epoch: 6| Step: 5
Training loss: 1.1499345302581787
Validation loss: 1.7801262563274753

Epoch: 6| Step: 6
Training loss: 0.7505444288253784
Validation loss: 1.8333373223581622

Epoch: 6| Step: 7
Training loss: 1.2151694297790527
Validation loss: 1.796077169397826

Epoch: 6| Step: 8
Training loss: 1.221926212310791
Validation loss: 1.8046519538407684

Epoch: 6| Step: 9
Training loss: 1.0432814359664917
Validation loss: 1.8419379880351405

Epoch: 6| Step: 10
Training loss: 1.310733437538147
Validation loss: 1.833579332597794

Epoch: 6| Step: 11
Training loss: 1.1845829486846924
Validation loss: 1.8617756084729267

Epoch: 6| Step: 12
Training loss: 1.4122395515441895
Validation loss: 1.857024646574451

Epoch: 6| Step: 13
Training loss: 0.9575755000114441
Validation loss: 1.8635074810315204

Epoch: 419| Step: 0
Training loss: 1.3727750778198242
Validation loss: 1.9304102774589293

Epoch: 6| Step: 1
Training loss: 0.7175077199935913
Validation loss: 1.8879562975257955

Epoch: 6| Step: 2
Training loss: 1.339277982711792
Validation loss: 1.8760138057893323

Epoch: 6| Step: 3
Training loss: 0.9549577236175537
Validation loss: 1.8493434818842078

Epoch: 6| Step: 4
Training loss: 1.0895183086395264
Validation loss: 1.8396499964498705

Epoch: 6| Step: 5
Training loss: 1.272943139076233
Validation loss: 1.8581400571330902

Epoch: 6| Step: 6
Training loss: 1.6602632999420166
Validation loss: 1.8421313775483

Epoch: 6| Step: 7
Training loss: 1.1614067554473877
Validation loss: 1.8413173255100046

Epoch: 6| Step: 8
Training loss: 1.5499744415283203
Validation loss: 1.7827225397991877

Epoch: 6| Step: 9
Training loss: 1.5658704042434692
Validation loss: 1.7340779535232052

Epoch: 6| Step: 10
Training loss: 0.9751800298690796
Validation loss: 1.7745280470899356

Epoch: 6| Step: 11
Training loss: 1.116304874420166
Validation loss: 1.8408331268577165

Epoch: 6| Step: 12
Training loss: 0.9066766500473022
Validation loss: 1.836089971244976

Epoch: 6| Step: 13
Training loss: 0.6786746382713318
Validation loss: 1.8247222131298435

Epoch: 420| Step: 0
Training loss: 1.0734673738479614
Validation loss: 1.7805689816833825

Epoch: 6| Step: 1
Training loss: 1.3122857809066772
Validation loss: 1.8097316142051452

Epoch: 6| Step: 2
Training loss: 1.163881778717041
Validation loss: 1.846224957896817

Epoch: 6| Step: 3
Training loss: 0.706925094127655
Validation loss: 1.764366203738797

Epoch: 6| Step: 4
Training loss: 1.2050061225891113
Validation loss: 1.8340532651511572

Epoch: 6| Step: 5
Training loss: 1.7571932077407837
Validation loss: 1.8178174828970304

Epoch: 6| Step: 6
Training loss: 1.072051763534546
Validation loss: 1.7737054760738085

Epoch: 6| Step: 7
Training loss: 1.2911081314086914
Validation loss: 1.877942463403107

Epoch: 6| Step: 8
Training loss: 0.736979603767395
Validation loss: 1.825578151210662

Epoch: 6| Step: 9
Training loss: 1.2586047649383545
Validation loss: 1.8401950161944154

Epoch: 6| Step: 10
Training loss: 1.7863788604736328
Validation loss: 1.8161948688568608

Epoch: 6| Step: 11
Training loss: 1.0147297382354736
Validation loss: 1.8341621480962282

Epoch: 6| Step: 12
Training loss: 1.0243690013885498
Validation loss: 1.7775877624429681

Epoch: 6| Step: 13
Training loss: 0.5957017540931702
Validation loss: 1.8416710284448439

Epoch: 421| Step: 0
Training loss: 1.0508159399032593
Validation loss: 1.7748833587092738

Epoch: 6| Step: 1
Training loss: 0.745960533618927
Validation loss: 1.7975150686438366

Epoch: 6| Step: 2
Training loss: 1.183587908744812
Validation loss: 1.7866730907911896

Epoch: 6| Step: 3
Training loss: 1.0225838422775269
Validation loss: 1.8035470593360163

Epoch: 6| Step: 4
Training loss: 1.823586344718933
Validation loss: 1.7547059533416585

Epoch: 6| Step: 5
Training loss: 1.013573408126831
Validation loss: 1.801430186917705

Epoch: 6| Step: 6
Training loss: 1.406564712524414
Validation loss: 1.7824441156079691

Epoch: 6| Step: 7
Training loss: 0.9510162472724915
Validation loss: 1.7762262769924697

Epoch: 6| Step: 8
Training loss: 0.8483346700668335
Validation loss: 1.8107737213052728

Epoch: 6| Step: 9
Training loss: 1.0617146492004395
Validation loss: 1.819269081597687

Epoch: 6| Step: 10
Training loss: 0.9125622510910034
Validation loss: 1.8085832967553088

Epoch: 6| Step: 11
Training loss: 1.4467607736587524
Validation loss: 1.7661327674824705

Epoch: 6| Step: 12
Training loss: 1.2748582363128662
Validation loss: 1.8271328492831158

Epoch: 6| Step: 13
Training loss: 1.188902735710144
Validation loss: 1.8058334050639984

Epoch: 422| Step: 0
Training loss: 1.4797186851501465
Validation loss: 1.8320442348398187

Epoch: 6| Step: 1
Training loss: 1.35612154006958
Validation loss: 1.799092338931176

Epoch: 6| Step: 2
Training loss: 0.9092093706130981
Validation loss: 1.8093516493356356

Epoch: 6| Step: 3
Training loss: 1.1920998096466064
Validation loss: 1.780375490906418

Epoch: 6| Step: 4
Training loss: 0.9552446603775024
Validation loss: 1.8370401269646102

Epoch: 6| Step: 5
Training loss: 1.4728517532348633
Validation loss: 1.7951996326446533

Epoch: 6| Step: 6
Training loss: 1.1070430278778076
Validation loss: 1.7743731621773011

Epoch: 6| Step: 7
Training loss: 0.9008956551551819
Validation loss: 1.8776130112268592

Epoch: 6| Step: 8
Training loss: 1.0222790241241455
Validation loss: 1.8410127342388194

Epoch: 6| Step: 9
Training loss: 1.0182791948318481
Validation loss: 1.7787241628093104

Epoch: 6| Step: 10
Training loss: 1.6737419366836548
Validation loss: 1.8320242922793153

Epoch: 6| Step: 11
Training loss: 1.298741102218628
Validation loss: 1.8401500178921608

Epoch: 6| Step: 12
Training loss: 0.5827926397323608
Validation loss: 1.8149932251181653

Epoch: 6| Step: 13
Training loss: 0.368414968252182
Validation loss: 1.8432870616195023

Epoch: 423| Step: 0
Training loss: 1.5894759893417358
Validation loss: 1.8135350135064894

Epoch: 6| Step: 1
Training loss: 0.7374182343482971
Validation loss: 1.8087918450755458

Epoch: 6| Step: 2
Training loss: 0.8771817684173584
Validation loss: 1.7700875959088724

Epoch: 6| Step: 3
Training loss: 1.0651708841323853
Validation loss: 1.75418984377256

Epoch: 6| Step: 4
Training loss: 1.2961455583572388
Validation loss: 1.8325936794281006

Epoch: 6| Step: 5
Training loss: 0.9295414090156555
Validation loss: 1.8031880124922721

Epoch: 6| Step: 6
Training loss: 1.54118812084198
Validation loss: 1.7902126260983047

Epoch: 6| Step: 7
Training loss: 1.3815346956253052
Validation loss: 1.769032633432778

Epoch: 6| Step: 8
Training loss: 1.1470606327056885
Validation loss: 1.812489281418503

Epoch: 6| Step: 9
Training loss: 1.5383694171905518
Validation loss: 1.8347919243638233

Epoch: 6| Step: 10
Training loss: 0.9314062595367432
Validation loss: 1.78464795953484

Epoch: 6| Step: 11
Training loss: 0.5750546455383301
Validation loss: 1.829514544497254

Epoch: 6| Step: 12
Training loss: 1.668963074684143
Validation loss: 1.875990544596026

Epoch: 6| Step: 13
Training loss: 1.4163886308670044
Validation loss: 1.81556373898701

Epoch: 424| Step: 0
Training loss: 0.9618450403213501
Validation loss: 1.8125820608549221

Epoch: 6| Step: 1
Training loss: 1.1441998481750488
Validation loss: 1.8224268510777464

Epoch: 6| Step: 2
Training loss: 0.6772831082344055
Validation loss: 1.7731185933595062

Epoch: 6| Step: 3
Training loss: 0.7399351596832275
Validation loss: 1.8050518856253674

Epoch: 6| Step: 4
Training loss: 0.8719741702079773
Validation loss: 1.8081622046809043

Epoch: 6| Step: 5
Training loss: 1.5738221406936646
Validation loss: 1.773235369754094

Epoch: 6| Step: 6
Training loss: 1.4675977230072021
Validation loss: 1.8491828095528386

Epoch: 6| Step: 7
Training loss: 1.0055088996887207
Validation loss: 1.8186028606148177

Epoch: 6| Step: 8
Training loss: 1.8665107488632202
Validation loss: 1.7855999597939112

Epoch: 6| Step: 9
Training loss: 1.379077672958374
Validation loss: 1.8429794132068593

Epoch: 6| Step: 10
Training loss: 0.6119683980941772
Validation loss: 1.7628863344910324

Epoch: 6| Step: 11
Training loss: 0.9965527653694153
Validation loss: 1.7736880727993545

Epoch: 6| Step: 12
Training loss: 1.5552101135253906
Validation loss: 1.752678907045754

Epoch: 6| Step: 13
Training loss: 1.2913161516189575
Validation loss: 1.7821105295611965

Epoch: 425| Step: 0
Training loss: 1.312803030014038
Validation loss: 1.7979430203796716

Epoch: 6| Step: 1
Training loss: 0.9088426232337952
Validation loss: 1.8383496525467082

Epoch: 6| Step: 2
Training loss: 1.2858190536499023
Validation loss: 1.8012060324350994

Epoch: 6| Step: 3
Training loss: 1.1989752054214478
Validation loss: 1.8166179656982422

Epoch: 6| Step: 4
Training loss: 1.0551061630249023
Validation loss: 1.8859661292004328

Epoch: 6| Step: 5
Training loss: 1.3059747219085693
Validation loss: 1.7754652474516182

Epoch: 6| Step: 6
Training loss: 1.0075383186340332
Validation loss: 1.846307631461851

Epoch: 6| Step: 7
Training loss: 1.801481008529663
Validation loss: 1.8613570813209779

Epoch: 6| Step: 8
Training loss: 0.645075261592865
Validation loss: 1.8258414486403107

Epoch: 6| Step: 9
Training loss: 1.216071605682373
Validation loss: 1.796493617437219

Epoch: 6| Step: 10
Training loss: 0.8114683628082275
Validation loss: 1.7645206284779373

Epoch: 6| Step: 11
Training loss: 1.2613834142684937
Validation loss: 1.7871303109712497

Epoch: 6| Step: 12
Training loss: 1.0932848453521729
Validation loss: 1.783565080294045

Epoch: 6| Step: 13
Training loss: 1.3589117527008057
Validation loss: 1.7895767740024033

Epoch: 426| Step: 0
Training loss: 1.4020062685012817
Validation loss: 1.7749720106842697

Epoch: 6| Step: 1
Training loss: 1.040160894393921
Validation loss: 1.7750435747126097

Epoch: 6| Step: 2
Training loss: 0.9031938314437866
Validation loss: 1.8326697093184277

Epoch: 6| Step: 3
Training loss: 0.8057994842529297
Validation loss: 1.7768861260465396

Epoch: 6| Step: 4
Training loss: 0.9873668551445007
Validation loss: 1.8108178223333051

Epoch: 6| Step: 5
Training loss: 1.117274284362793
Validation loss: 1.8316486009987452

Epoch: 6| Step: 6
Training loss: 1.0918173789978027
Validation loss: 1.8016013214665074

Epoch: 6| Step: 7
Training loss: 0.8376455903053284
Validation loss: 1.8399771028949368

Epoch: 6| Step: 8
Training loss: 1.115873098373413
Validation loss: 1.8113955272141324

Epoch: 6| Step: 9
Training loss: 1.2988570928573608
Validation loss: 1.7567082476872269

Epoch: 6| Step: 10
Training loss: 1.1356890201568604
Validation loss: 1.8025081926776516

Epoch: 6| Step: 11
Training loss: 0.9236323833465576
Validation loss: 1.7949759165445964

Epoch: 6| Step: 12
Training loss: 1.648635983467102
Validation loss: 1.832779622847034

Epoch: 6| Step: 13
Training loss: 1.3453831672668457
Validation loss: 1.8359414967157508

Epoch: 427| Step: 0
Training loss: 1.0708155632019043
Validation loss: 1.828962311949781

Epoch: 6| Step: 1
Training loss: 0.9006942510604858
Validation loss: 1.8027381563699374

Epoch: 6| Step: 2
Training loss: 1.0641460418701172
Validation loss: 1.8586874456815823

Epoch: 6| Step: 3
Training loss: 0.7963488101959229
Validation loss: 1.8329972567096833

Epoch: 6| Step: 4
Training loss: 1.1072710752487183
Validation loss: 1.8628777611640193

Epoch: 6| Step: 5
Training loss: 1.464662790298462
Validation loss: 1.8511244173972838

Epoch: 6| Step: 6
Training loss: 0.7662144303321838
Validation loss: 1.8926428338532806

Epoch: 6| Step: 7
Training loss: 1.0227162837982178
Validation loss: 1.8381409452807518

Epoch: 6| Step: 8
Training loss: 1.4904263019561768
Validation loss: 1.8736986344860447

Epoch: 6| Step: 9
Training loss: 0.9107488989830017
Validation loss: 1.7690313772488666

Epoch: 6| Step: 10
Training loss: 0.8080908060073853
Validation loss: 1.808922351047557

Epoch: 6| Step: 11
Training loss: 1.633893609046936
Validation loss: 1.7929966193373486

Epoch: 6| Step: 12
Training loss: 1.3954541683197021
Validation loss: 1.8589880158824306

Epoch: 6| Step: 13
Training loss: 0.8695166110992432
Validation loss: 1.793514831091768

Epoch: 428| Step: 0
Training loss: 1.361680269241333
Validation loss: 1.798659005472737

Epoch: 6| Step: 1
Training loss: 0.8147670030593872
Validation loss: 1.8285022986832487

Epoch: 6| Step: 2
Training loss: 1.4585533142089844
Validation loss: 1.7698590140188895

Epoch: 6| Step: 3
Training loss: 1.253730297088623
Validation loss: 1.8451134620174285

Epoch: 6| Step: 4
Training loss: 1.2729442119598389
Validation loss: 1.813231337455011

Epoch: 6| Step: 5
Training loss: 1.2682232856750488
Validation loss: 1.7429694270574918

Epoch: 6| Step: 6
Training loss: 1.134028434753418
Validation loss: 1.7473216890006937

Epoch: 6| Step: 7
Training loss: 1.0580687522888184
Validation loss: 1.7390703847331386

Epoch: 6| Step: 8
Training loss: 0.9375693798065186
Validation loss: 1.8135155426558627

Epoch: 6| Step: 9
Training loss: 1.1636923551559448
Validation loss: 1.8027949756191624

Epoch: 6| Step: 10
Training loss: 1.0616719722747803
Validation loss: 1.7925640203619515

Epoch: 6| Step: 11
Training loss: 0.9198413491249084
Validation loss: 1.8508142617440992

Epoch: 6| Step: 12
Training loss: 1.280613899230957
Validation loss: 1.7589836787152033

Epoch: 6| Step: 13
Training loss: 0.751090943813324
Validation loss: 1.8249005784270584

Epoch: 429| Step: 0
Training loss: 1.448173999786377
Validation loss: 1.7624577860678396

Epoch: 6| Step: 1
Training loss: 0.4880527853965759
Validation loss: 1.810743470345774

Epoch: 6| Step: 2
Training loss: 0.8947616815567017
Validation loss: 1.8150697190274474

Epoch: 6| Step: 3
Training loss: 0.7778738141059875
Validation loss: 1.809903610137201

Epoch: 6| Step: 4
Training loss: 1.410837173461914
Validation loss: 1.813922523170389

Epoch: 6| Step: 5
Training loss: 0.7189074754714966
Validation loss: 1.7840222812468005

Epoch: 6| Step: 6
Training loss: 0.7201486825942993
Validation loss: 1.8107414809606408

Epoch: 6| Step: 7
Training loss: 1.604297399520874
Validation loss: 1.7716866334279378

Epoch: 6| Step: 8
Training loss: 1.0724291801452637
Validation loss: 1.7874363660812378

Epoch: 6| Step: 9
Training loss: 1.7815461158752441
Validation loss: 1.7964505200744958

Epoch: 6| Step: 10
Training loss: 1.0921903848648071
Validation loss: 1.7847102149840324

Epoch: 6| Step: 11
Training loss: 1.6065261363983154
Validation loss: 1.8253255659534084

Epoch: 6| Step: 12
Training loss: 1.268280029296875
Validation loss: 1.814449215448031

Epoch: 6| Step: 13
Training loss: 1.0392686128616333
Validation loss: 1.7933130597555509

Epoch: 430| Step: 0
Training loss: 1.0819144248962402
Validation loss: 1.7772216168783044

Epoch: 6| Step: 1
Training loss: 1.3060719966888428
Validation loss: 1.8028925887999996

Epoch: 6| Step: 2
Training loss: 1.0693256855010986
Validation loss: 1.874763237532749

Epoch: 6| Step: 3
Training loss: 1.9499297142028809
Validation loss: 1.861998329880417

Epoch: 6| Step: 4
Training loss: 0.8983380794525146
Validation loss: 1.7789772595128706

Epoch: 6| Step: 5
Training loss: 0.9281782507896423
Validation loss: 1.8360456869166384

Epoch: 6| Step: 6
Training loss: 0.7750552892684937
Validation loss: 1.838408572699434

Epoch: 6| Step: 7
Training loss: 0.7297860980033875
Validation loss: 1.8362353770963606

Epoch: 6| Step: 8
Training loss: 1.367904543876648
Validation loss: 1.8105521278996621

Epoch: 6| Step: 9
Training loss: 1.0766733884811401
Validation loss: 1.7651281818266837

Epoch: 6| Step: 10
Training loss: 1.0273845195770264
Validation loss: 1.8179055510028717

Epoch: 6| Step: 11
Training loss: 0.9907981157302856
Validation loss: 1.7914086003457346

Epoch: 6| Step: 12
Training loss: 1.3523691892623901
Validation loss: 1.7611455366175661

Epoch: 6| Step: 13
Training loss: 1.4133884906768799
Validation loss: 1.7745939505997526

Epoch: 431| Step: 0
Training loss: 1.188865303993225
Validation loss: 1.8618114879054408

Epoch: 6| Step: 1
Training loss: 1.12660813331604
Validation loss: 1.8057856559753418

Epoch: 6| Step: 2
Training loss: 0.806133508682251
Validation loss: 1.81785911257549

Epoch: 6| Step: 3
Training loss: 1.200709581375122
Validation loss: 1.7548754087058447

Epoch: 6| Step: 4
Training loss: 1.3766103982925415
Validation loss: 1.8119000952730897

Epoch: 6| Step: 5
Training loss: 0.9434764385223389
Validation loss: 1.8181947764529978

Epoch: 6| Step: 6
Training loss: 0.8070800304412842
Validation loss: 1.7921960225669287

Epoch: 6| Step: 7
Training loss: 1.4257705211639404
Validation loss: 1.840780436351735

Epoch: 6| Step: 8
Training loss: 1.009757161140442
Validation loss: 1.7827719744815622

Epoch: 6| Step: 9
Training loss: 1.4485328197479248
Validation loss: 1.8135313346821775

Epoch: 6| Step: 10
Training loss: 0.8288009166717529
Validation loss: 1.7840194561148202

Epoch: 6| Step: 11
Training loss: 1.1939096450805664
Validation loss: 1.7853217586394279

Epoch: 6| Step: 12
Training loss: 0.9904969930648804
Validation loss: 1.7959647422195764

Epoch: 6| Step: 13
Training loss: 1.393978476524353
Validation loss: 1.8632878526564567

Epoch: 432| Step: 0
Training loss: 1.1875346899032593
Validation loss: 1.8487497939858386

Epoch: 6| Step: 1
Training loss: 1.4910101890563965
Validation loss: 1.8371560599214287

Epoch: 6| Step: 2
Training loss: 1.2868506908416748
Validation loss: 1.870602366744831

Epoch: 6| Step: 3
Training loss: 1.097798228263855
Validation loss: 1.8768180365203528

Epoch: 6| Step: 4
Training loss: 0.6643962860107422
Validation loss: 1.8503676781090357

Epoch: 6| Step: 5
Training loss: 1.2345857620239258
Validation loss: 1.8154882307975524

Epoch: 6| Step: 6
Training loss: 1.4414504766464233
Validation loss: 1.7294103214817662

Epoch: 6| Step: 7
Training loss: 0.7892132997512817
Validation loss: 1.8961824050513647

Epoch: 6| Step: 8
Training loss: 0.9499707221984863
Validation loss: 1.727210707561944

Epoch: 6| Step: 9
Training loss: 1.0493123531341553
Validation loss: 1.7581375247688704

Epoch: 6| Step: 10
Training loss: 1.4231913089752197
Validation loss: 1.829977277786501

Epoch: 6| Step: 11
Training loss: 1.4303715229034424
Validation loss: 1.7971649823650238

Epoch: 6| Step: 12
Training loss: 1.2288968563079834
Validation loss: 1.8366222727683283

Epoch: 6| Step: 13
Training loss: 0.9697498679161072
Validation loss: 1.742421027152769

Epoch: 433| Step: 0
Training loss: 1.1561230421066284
Validation loss: 1.8351375851579892

Epoch: 6| Step: 1
Training loss: 1.0572034120559692
Validation loss: 1.8478430548021871

Epoch: 6| Step: 2
Training loss: 1.3060370683670044
Validation loss: 1.7899036125470233

Epoch: 6| Step: 3
Training loss: 1.1511781215667725
Validation loss: 1.779609105920279

Epoch: 6| Step: 4
Training loss: 1.0230510234832764
Validation loss: 1.8948650744653517

Epoch: 6| Step: 5
Training loss: 1.3221960067749023
Validation loss: 1.8670409135921027

Epoch: 6| Step: 6
Training loss: 0.5961751937866211
Validation loss: 1.8394520654473254

Epoch: 6| Step: 7
Training loss: 0.9793274402618408
Validation loss: 1.8694749916753461

Epoch: 6| Step: 8
Training loss: 0.9309163689613342
Validation loss: 1.8063741371195803

Epoch: 6| Step: 9
Training loss: 1.4790005683898926
Validation loss: 1.8678263989827966

Epoch: 6| Step: 10
Training loss: 1.5831100940704346
Validation loss: 1.863716971489691

Epoch: 6| Step: 11
Training loss: 1.279720425605774
Validation loss: 1.8526117058210476

Epoch: 6| Step: 12
Training loss: 1.1330584287643433
Validation loss: 1.7678441475796443

Epoch: 6| Step: 13
Training loss: 0.954954981803894
Validation loss: 1.7799009507702244

Epoch: 434| Step: 0
Training loss: 1.2468562126159668
Validation loss: 1.7850446047321442

Epoch: 6| Step: 1
Training loss: 1.3538355827331543
Validation loss: 1.7294488107004473

Epoch: 6| Step: 2
Training loss: 1.144404649734497
Validation loss: 1.8276874826800438

Epoch: 6| Step: 3
Training loss: 1.5907230377197266
Validation loss: 1.774009899426532

Epoch: 6| Step: 4
Training loss: 1.4599343538284302
Validation loss: 1.8531001844713766

Epoch: 6| Step: 5
Training loss: 0.998285174369812
Validation loss: 1.7871333860581922

Epoch: 6| Step: 6
Training loss: 0.9459089040756226
Validation loss: 1.7820473371013519

Epoch: 6| Step: 7
Training loss: 0.8362541198730469
Validation loss: 1.8525192788852158

Epoch: 6| Step: 8
Training loss: 1.1295154094696045
Validation loss: 1.8344571462241552

Epoch: 6| Step: 9
Training loss: 0.9289528131484985
Validation loss: 1.8215442588252406

Epoch: 6| Step: 10
Training loss: 0.7429302930831909
Validation loss: 1.7450469681011733

Epoch: 6| Step: 11
Training loss: 1.5120043754577637
Validation loss: 1.7775550478248185

Epoch: 6| Step: 12
Training loss: 1.3534610271453857
Validation loss: 1.8235276796484505

Epoch: 6| Step: 13
Training loss: 1.2835432291030884
Validation loss: 1.809874939662154

Epoch: 435| Step: 0
Training loss: 1.0672584772109985
Validation loss: 1.8469881498685448

Epoch: 6| Step: 1
Training loss: 1.6049067974090576
Validation loss: 1.8719044295690392

Epoch: 6| Step: 2
Training loss: 0.9991660714149475
Validation loss: 1.859484072654478

Epoch: 6| Step: 3
Training loss: 1.089748501777649
Validation loss: 1.8934204770672707

Epoch: 6| Step: 4
Training loss: 1.254520058631897
Validation loss: 1.937433999071839

Epoch: 6| Step: 5
Training loss: 1.8861932754516602
Validation loss: 1.9253669682369436

Epoch: 6| Step: 6
Training loss: 1.1249569654464722
Validation loss: 1.870456475083546

Epoch: 6| Step: 7
Training loss: 0.921160876750946
Validation loss: 1.9494288095863916

Epoch: 6| Step: 8
Training loss: 1.2397334575653076
Validation loss: 1.8952735354823451

Epoch: 6| Step: 9
Training loss: 0.7215242385864258
Validation loss: 1.9063108339104602

Epoch: 6| Step: 10
Training loss: 0.8581349849700928
Validation loss: 1.8644415332425026

Epoch: 6| Step: 11
Training loss: 1.326859951019287
Validation loss: 1.861122118529453

Epoch: 6| Step: 12
Training loss: 1.038567066192627
Validation loss: 1.8578648144199001

Epoch: 6| Step: 13
Training loss: 0.7488291263580322
Validation loss: 1.8370572931023055

Epoch: 436| Step: 0
Training loss: 1.2557902336120605
Validation loss: 1.784561462299798

Epoch: 6| Step: 1
Training loss: 1.1295697689056396
Validation loss: 1.8448817294131044

Epoch: 6| Step: 2
Training loss: 1.0256332159042358
Validation loss: 1.8140242022852744

Epoch: 6| Step: 3
Training loss: 0.9458601474761963
Validation loss: 1.8229436336025115

Epoch: 6| Step: 4
Training loss: 1.143589735031128
Validation loss: 1.799655088814356

Epoch: 6| Step: 5
Training loss: 0.8617777824401855
Validation loss: 1.7785440952547136

Epoch: 6| Step: 6
Training loss: 0.6655135154724121
Validation loss: 1.782367443525663

Epoch: 6| Step: 7
Training loss: 1.7039811611175537
Validation loss: 1.7602590437858336

Epoch: 6| Step: 8
Training loss: 0.9767452478408813
Validation loss: 1.7897404009296047

Epoch: 6| Step: 9
Training loss: 1.0464372634887695
Validation loss: 1.7722701334184217

Epoch: 6| Step: 10
Training loss: 0.8024989366531372
Validation loss: 1.8161667316190657

Epoch: 6| Step: 11
Training loss: 0.9172184467315674
Validation loss: 1.8047896931248326

Epoch: 6| Step: 12
Training loss: 1.5986604690551758
Validation loss: 1.80503309670315

Epoch: 6| Step: 13
Training loss: 1.8457105159759521
Validation loss: 1.8011818816584926

Epoch: 437| Step: 0
Training loss: 0.8533918857574463
Validation loss: 1.7664620748130224

Epoch: 6| Step: 1
Training loss: 0.6704056859016418
Validation loss: 1.8014991706417454

Epoch: 6| Step: 2
Training loss: 1.3708851337432861
Validation loss: 1.7545137539986642

Epoch: 6| Step: 3
Training loss: 1.1129486560821533
Validation loss: 1.812530638069235

Epoch: 6| Step: 4
Training loss: 1.4123187065124512
Validation loss: 1.7694026706039265

Epoch: 6| Step: 5
Training loss: 1.2680280208587646
Validation loss: 1.8281016362610685

Epoch: 6| Step: 6
Training loss: 0.912742018699646
Validation loss: 1.779610018576345

Epoch: 6| Step: 7
Training loss: 1.5945435762405396
Validation loss: 1.8041380733572028

Epoch: 6| Step: 8
Training loss: 1.0197067260742188
Validation loss: 1.8288343362910773

Epoch: 6| Step: 9
Training loss: 1.1233553886413574
Validation loss: 1.8031233036389915

Epoch: 6| Step: 10
Training loss: 0.8165432214736938
Validation loss: 1.839092787875924

Epoch: 6| Step: 11
Training loss: 1.0030202865600586
Validation loss: 1.8935891556483444

Epoch: 6| Step: 12
Training loss: 0.9546075463294983
Validation loss: 1.8951414797895698

Epoch: 6| Step: 13
Training loss: 1.346340298652649
Validation loss: 1.8463465334266744

Epoch: 438| Step: 0
Training loss: 1.0001782178878784
Validation loss: 1.81406989020686

Epoch: 6| Step: 1
Training loss: 1.1864060163497925
Validation loss: 1.849017753395983

Epoch: 6| Step: 2
Training loss: 0.957128643989563
Validation loss: 1.809418087364525

Epoch: 6| Step: 3
Training loss: 1.5448534488677979
Validation loss: 1.8238966208632275

Epoch: 6| Step: 4
Training loss: 1.663535714149475
Validation loss: 1.774846428184099

Epoch: 6| Step: 5
Training loss: 0.9877245426177979
Validation loss: 1.7944588571466424

Epoch: 6| Step: 6
Training loss: 1.287118911743164
Validation loss: 1.7715789297575593

Epoch: 6| Step: 7
Training loss: 1.0903490781784058
Validation loss: 1.7668590391835859

Epoch: 6| Step: 8
Training loss: 1.3072459697723389
Validation loss: 1.7594135871497534

Epoch: 6| Step: 9
Training loss: 1.679242491722107
Validation loss: 1.8189346085312545

Epoch: 6| Step: 10
Training loss: 0.7544429302215576
Validation loss: 1.7926758822574411

Epoch: 6| Step: 11
Training loss: 1.0803941488265991
Validation loss: 1.7923395646515714

Epoch: 6| Step: 12
Training loss: 0.8566490411758423
Validation loss: 1.794854203859965

Epoch: 6| Step: 13
Training loss: 1.2956600189208984
Validation loss: 1.794801736390719

Epoch: 439| Step: 0
Training loss: 1.2269747257232666
Validation loss: 1.7573236162944506

Epoch: 6| Step: 1
Training loss: 0.6876834630966187
Validation loss: 1.815446856201336

Epoch: 6| Step: 2
Training loss: 1.3004462718963623
Validation loss: 1.7629251505738945

Epoch: 6| Step: 3
Training loss: 1.4292569160461426
Validation loss: 1.8305324892843924

Epoch: 6| Step: 4
Training loss: 1.251255750656128
Validation loss: 1.827480593035298

Epoch: 6| Step: 5
Training loss: 1.2745897769927979
Validation loss: 1.8403612311168382

Epoch: 6| Step: 6
Training loss: 0.5317366719245911
Validation loss: 1.9322048259037796

Epoch: 6| Step: 7
Training loss: 1.1913435459136963
Validation loss: 1.8908138723783596

Epoch: 6| Step: 8
Training loss: 1.0617177486419678
Validation loss: 1.9510144597740584

Epoch: 6| Step: 9
Training loss: 1.2989195585250854
Validation loss: 1.8660788920617872

Epoch: 6| Step: 10
Training loss: 1.5878509283065796
Validation loss: 1.7543009237576557

Epoch: 6| Step: 11
Training loss: 0.7786327600479126
Validation loss: 1.7777270578568982

Epoch: 6| Step: 12
Training loss: 0.8962859511375427
Validation loss: 1.8193768634591052

Epoch: 6| Step: 13
Training loss: 1.3922380208969116
Validation loss: 1.766227622185984

Epoch: 440| Step: 0
Training loss: 1.0849164724349976
Validation loss: 1.8169118037787817

Epoch: 6| Step: 1
Training loss: 1.1680574417114258
Validation loss: 1.8238779511502994

Epoch: 6| Step: 2
Training loss: 0.7345407009124756
Validation loss: 1.7246395926321707

Epoch: 6| Step: 3
Training loss: 0.9553824067115784
Validation loss: 1.7574935702867405

Epoch: 6| Step: 4
Training loss: 1.7981410026550293
Validation loss: 1.7793896711000832

Epoch: 6| Step: 5
Training loss: 1.0856834650039673
Validation loss: 1.7885357602950065

Epoch: 6| Step: 6
Training loss: 1.1565927267074585
Validation loss: 1.7996870035766273

Epoch: 6| Step: 7
Training loss: 1.064241647720337
Validation loss: 1.8020736081625826

Epoch: 6| Step: 8
Training loss: 1.0453025102615356
Validation loss: 1.7635393937428792

Epoch: 6| Step: 9
Training loss: 1.0335826873779297
Validation loss: 1.8262947861866285

Epoch: 6| Step: 10
Training loss: 1.4630368947982788
Validation loss: 1.7554944984374508

Epoch: 6| Step: 11
Training loss: 1.4651182889938354
Validation loss: 1.7347069555713284

Epoch: 6| Step: 12
Training loss: 0.662808358669281
Validation loss: 1.697437176140406

Epoch: 6| Step: 13
Training loss: 1.6688883304595947
Validation loss: 1.796151718785686

Epoch: 441| Step: 0
Training loss: 0.43589627742767334
Validation loss: 1.7692898152976908

Epoch: 6| Step: 1
Training loss: 1.367842435836792
Validation loss: 1.816926230666458

Epoch: 6| Step: 2
Training loss: 1.3546332120895386
Validation loss: 1.8148501432070168

Epoch: 6| Step: 3
Training loss: 1.0877633094787598
Validation loss: 1.820139794580398

Epoch: 6| Step: 4
Training loss: 1.2209521532058716
Validation loss: 1.8634774813088038

Epoch: 6| Step: 5
Training loss: 1.047766089439392
Validation loss: 1.7771766583124797

Epoch: 6| Step: 6
Training loss: 1.2059197425842285
Validation loss: 1.8344567603962396

Epoch: 6| Step: 7
Training loss: 0.9264849424362183
Validation loss: 1.7983282317397415

Epoch: 6| Step: 8
Training loss: 1.7314430475234985
Validation loss: 1.7903469788130892

Epoch: 6| Step: 9
Training loss: 0.9768410921096802
Validation loss: 1.8081164385682793

Epoch: 6| Step: 10
Training loss: 0.8237571120262146
Validation loss: 1.8105708476035827

Epoch: 6| Step: 11
Training loss: 1.1359946727752686
Validation loss: 1.8282668449545418

Epoch: 6| Step: 12
Training loss: 0.8524192571640015
Validation loss: 1.7718333172541794

Epoch: 6| Step: 13
Training loss: 1.3937816619873047
Validation loss: 1.7593869086234801

Epoch: 442| Step: 0
Training loss: 0.8532900810241699
Validation loss: 1.7843328252915414

Epoch: 6| Step: 1
Training loss: 1.2913143634796143
Validation loss: 1.8065442051938785

Epoch: 6| Step: 2
Training loss: 0.8337583541870117
Validation loss: 1.877250156094951

Epoch: 6| Step: 3
Training loss: 1.3021349906921387
Validation loss: 1.82626941768072

Epoch: 6| Step: 4
Training loss: 0.8720270395278931
Validation loss: 1.7325191292711484

Epoch: 6| Step: 5
Training loss: 0.6176348924636841
Validation loss: 1.8126714562857023

Epoch: 6| Step: 6
Training loss: 1.8411197662353516
Validation loss: 1.7976168919635076

Epoch: 6| Step: 7
Training loss: 1.1039831638336182
Validation loss: 1.7412315209706624

Epoch: 6| Step: 8
Training loss: 1.2128705978393555
Validation loss: 1.8166489883135724

Epoch: 6| Step: 9
Training loss: 1.0328201055526733
Validation loss: 1.759942998168289

Epoch: 6| Step: 10
Training loss: 0.8704675436019897
Validation loss: 1.8094568970382854

Epoch: 6| Step: 11
Training loss: 1.0306981801986694
Validation loss: 1.8312179401356687

Epoch: 6| Step: 12
Training loss: 1.2741608619689941
Validation loss: 1.847024953493508

Epoch: 6| Step: 13
Training loss: 1.7923035621643066
Validation loss: 1.8267313190685806

Epoch: 443| Step: 0
Training loss: 1.4974552392959595
Validation loss: 1.8125785973764235

Epoch: 6| Step: 1
Training loss: 1.0892002582550049
Validation loss: 1.818946361541748

Epoch: 6| Step: 2
Training loss: 1.1589605808258057
Validation loss: 1.8325363128416

Epoch: 6| Step: 3
Training loss: 1.0927757024765015
Validation loss: 1.789722704118298

Epoch: 6| Step: 4
Training loss: 0.8659698963165283
Validation loss: 1.843772461337428

Epoch: 6| Step: 5
Training loss: 1.3712031841278076
Validation loss: 1.8614596871919529

Epoch: 6| Step: 6
Training loss: 1.2409608364105225
Validation loss: 1.8520347790051532

Epoch: 6| Step: 7
Training loss: 1.1278550624847412
Validation loss: 1.7925894388588526

Epoch: 6| Step: 8
Training loss: 1.2259820699691772
Validation loss: 1.86628810821041

Epoch: 6| Step: 9
Training loss: 0.6231099367141724
Validation loss: 1.8482760588328044

Epoch: 6| Step: 10
Training loss: 1.1306307315826416
Validation loss: 1.831287173814671

Epoch: 6| Step: 11
Training loss: 1.1284489631652832
Validation loss: 1.8057900564644926

Epoch: 6| Step: 12
Training loss: 1.0556340217590332
Validation loss: 1.8160655588232062

Epoch: 6| Step: 13
Training loss: 0.5448153614997864
Validation loss: 1.7915919160330167

Epoch: 444| Step: 0
Training loss: 1.026200771331787
Validation loss: 1.8616718361454625

Epoch: 6| Step: 1
Training loss: 1.5594416856765747
Validation loss: 1.8803846836090088

Epoch: 6| Step: 2
Training loss: 0.9152268171310425
Validation loss: 1.7480085831816479

Epoch: 6| Step: 3
Training loss: 1.761610984802246
Validation loss: 1.7714539112583283

Epoch: 6| Step: 4
Training loss: 0.81181401014328
Validation loss: 1.788012126440643

Epoch: 6| Step: 5
Training loss: 1.2723668813705444
Validation loss: 1.7976521010039954

Epoch: 6| Step: 6
Training loss: 1.2063724994659424
Validation loss: 1.7769834867087744

Epoch: 6| Step: 7
Training loss: 0.8162026405334473
Validation loss: 1.777376292854227

Epoch: 6| Step: 8
Training loss: 0.8547782897949219
Validation loss: 1.7751063313535465

Epoch: 6| Step: 9
Training loss: 1.034726858139038
Validation loss: 1.7947007712497507

Epoch: 6| Step: 10
Training loss: 0.9352432489395142
Validation loss: 1.7867458648579095

Epoch: 6| Step: 11
Training loss: 1.162697672843933
Validation loss: 1.802009565855867

Epoch: 6| Step: 12
Training loss: 1.5763466358184814
Validation loss: 1.7995451060674523

Epoch: 6| Step: 13
Training loss: 0.7752773761749268
Validation loss: 1.8348673620531637

Epoch: 445| Step: 0
Training loss: 1.959930419921875
Validation loss: 1.78640615940094

Epoch: 6| Step: 1
Training loss: 0.9634565711021423
Validation loss: 1.8284050059574906

Epoch: 6| Step: 2
Training loss: 0.8616077303886414
Validation loss: 1.783463547306676

Epoch: 6| Step: 3
Training loss: 1.2174569368362427
Validation loss: 1.787693428736861

Epoch: 6| Step: 4
Training loss: 0.7466170787811279
Validation loss: 1.8194784272101618

Epoch: 6| Step: 5
Training loss: 1.2353055477142334
Validation loss: 1.873829169939923

Epoch: 6| Step: 6
Training loss: 0.6796362400054932
Validation loss: 1.8003089530493623

Epoch: 6| Step: 7
Training loss: 1.2026110887527466
Validation loss: 1.8482854109938427

Epoch: 6| Step: 8
Training loss: 1.1812111139297485
Validation loss: 1.743979662977239

Epoch: 6| Step: 9
Training loss: 1.4823603630065918
Validation loss: 1.8647057138463503

Epoch: 6| Step: 10
Training loss: 1.365953803062439
Validation loss: 1.801344612593292

Epoch: 6| Step: 11
Training loss: 0.7692375183105469
Validation loss: 1.8090265181756788

Epoch: 6| Step: 12
Training loss: 0.9034532308578491
Validation loss: 1.8228497210369314

Epoch: 6| Step: 13
Training loss: 0.6851499080657959
Validation loss: 1.8479039874128116

Epoch: 446| Step: 0
Training loss: 0.8559689521789551
Validation loss: 1.8298349149765507

Epoch: 6| Step: 1
Training loss: 1.1160399913787842
Validation loss: 1.7985659696722542

Epoch: 6| Step: 2
Training loss: 1.5156278610229492
Validation loss: 1.8519819551898586

Epoch: 6| Step: 3
Training loss: 1.6104543209075928
Validation loss: 1.7764162350726385

Epoch: 6| Step: 4
Training loss: 0.9576764702796936
Validation loss: 1.8890465074969875

Epoch: 6| Step: 5
Training loss: 0.9495396614074707
Validation loss: 1.7856773919956659

Epoch: 6| Step: 6
Training loss: 0.7858529090881348
Validation loss: 1.7789157962286344

Epoch: 6| Step: 7
Training loss: 0.8262304067611694
Validation loss: 1.7616742323803645

Epoch: 6| Step: 8
Training loss: 1.2323415279388428
Validation loss: 1.8298065457292783

Epoch: 6| Step: 9
Training loss: 1.553536057472229
Validation loss: 1.8376878705075992

Epoch: 6| Step: 10
Training loss: 1.1155918836593628
Validation loss: 1.8227981046963764

Epoch: 6| Step: 11
Training loss: 1.2432838678359985
Validation loss: 1.7397623395407071

Epoch: 6| Step: 12
Training loss: 0.6261341571807861
Validation loss: 1.78111489998397

Epoch: 6| Step: 13
Training loss: 1.20490300655365
Validation loss: 1.7716570592695666

Epoch: 447| Step: 0
Training loss: 0.7077058553695679
Validation loss: 1.7769565325911327

Epoch: 6| Step: 1
Training loss: 1.0279754400253296
Validation loss: 1.8489730204305341

Epoch: 6| Step: 2
Training loss: 0.9415901303291321
Validation loss: 1.816965159549508

Epoch: 6| Step: 3
Training loss: 0.9522762298583984
Validation loss: 1.7736955676027524

Epoch: 6| Step: 4
Training loss: 0.7545638084411621
Validation loss: 1.8484212326747116

Epoch: 6| Step: 5
Training loss: 1.4720985889434814
Validation loss: 1.7808379524497575

Epoch: 6| Step: 6
Training loss: 1.4346520900726318
Validation loss: 1.7977272233655375

Epoch: 6| Step: 7
Training loss: 1.2144988775253296
Validation loss: 1.7991952550026677

Epoch: 6| Step: 8
Training loss: 1.4429686069488525
Validation loss: 1.7539335950728385

Epoch: 6| Step: 9
Training loss: 1.1179172992706299
Validation loss: 1.7886938228402087

Epoch: 6| Step: 10
Training loss: 1.0000662803649902
Validation loss: 1.7814086252643215

Epoch: 6| Step: 11
Training loss: 1.003088116645813
Validation loss: 1.8069326916048605

Epoch: 6| Step: 12
Training loss: 1.2852931022644043
Validation loss: 1.8273639396954608

Epoch: 6| Step: 13
Training loss: 0.8324217200279236
Validation loss: 1.7923465236540763

Epoch: 448| Step: 0
Training loss: 0.9697122573852539
Validation loss: 1.8813244476113269

Epoch: 6| Step: 1
Training loss: 0.7007389664649963
Validation loss: 1.8413033190593924

Epoch: 6| Step: 2
Training loss: 0.8820871114730835
Validation loss: 1.8113135086592806

Epoch: 6| Step: 3
Training loss: 1.3758095502853394
Validation loss: 1.8175678740265548

Epoch: 6| Step: 4
Training loss: 0.756386399269104
Validation loss: 1.8174695032899097

Epoch: 6| Step: 5
Training loss: 1.0706183910369873
Validation loss: 1.8407375709984892

Epoch: 6| Step: 6
Training loss: 0.5177338719367981
Validation loss: 1.7284165223439534

Epoch: 6| Step: 7
Training loss: 1.0308318138122559
Validation loss: 1.7899256367837229

Epoch: 6| Step: 8
Training loss: 1.824084997177124
Validation loss: 1.7929730210252988

Epoch: 6| Step: 9
Training loss: 0.9437996745109558
Validation loss: 1.7739533301322692

Epoch: 6| Step: 10
Training loss: 1.25022292137146
Validation loss: 1.8477808685712918

Epoch: 6| Step: 11
Training loss: 1.5498443841934204
Validation loss: 1.8569084290535218

Epoch: 6| Step: 12
Training loss: 1.67057466506958
Validation loss: 1.7825582488890617

Epoch: 6| Step: 13
Training loss: 0.6878916621208191
Validation loss: 1.7876975164618543

Epoch: 449| Step: 0
Training loss: 1.2473206520080566
Validation loss: 1.8387350356707008

Epoch: 6| Step: 1
Training loss: 0.9824386239051819
Validation loss: 1.7687509752088977

Epoch: 6| Step: 2
Training loss: 1.1283035278320312
Validation loss: 1.8064767596542195

Epoch: 6| Step: 3
Training loss: 1.7786157131195068
Validation loss: 1.8473147346127419

Epoch: 6| Step: 4
Training loss: 1.4541499614715576
Validation loss: 1.840955275361256

Epoch: 6| Step: 5
Training loss: 0.7694665789604187
Validation loss: 1.8525065888640702

Epoch: 6| Step: 6
Training loss: 1.1070916652679443
Validation loss: 1.8763155578285136

Epoch: 6| Step: 7
Training loss: 0.8168169260025024
Validation loss: 1.8319808052432152

Epoch: 6| Step: 8
Training loss: 1.5145900249481201
Validation loss: 1.8360823790232341

Epoch: 6| Step: 9
Training loss: 0.7263193130493164
Validation loss: 1.8875436539291053

Epoch: 6| Step: 10
Training loss: 1.3818283081054688
Validation loss: 1.8083718656211771

Epoch: 6| Step: 11
Training loss: 1.02512788772583
Validation loss: 1.77378329923076

Epoch: 6| Step: 12
Training loss: 0.7359898090362549
Validation loss: 1.8026344058334187

Epoch: 6| Step: 13
Training loss: 1.04414963722229
Validation loss: 1.7907596339461624

Epoch: 450| Step: 0
Training loss: 1.1234502792358398
Validation loss: 1.8344427898365965

Epoch: 6| Step: 1
Training loss: 1.2191309928894043
Validation loss: 1.7561450325032717

Epoch: 6| Step: 2
Training loss: 0.7255432605743408
Validation loss: 1.8252651409436298

Epoch: 6| Step: 3
Training loss: 1.5072661638259888
Validation loss: 1.8001571919328423

Epoch: 6| Step: 4
Training loss: 1.1216204166412354
Validation loss: 1.8045722874262

Epoch: 6| Step: 5
Training loss: 1.0854294300079346
Validation loss: 1.7606874729997368

Epoch: 6| Step: 6
Training loss: 1.0410950183868408
Validation loss: 1.821019854596866

Epoch: 6| Step: 7
Training loss: 1.271214485168457
Validation loss: 1.8017963952915643

Epoch: 6| Step: 8
Training loss: 1.0532114505767822
Validation loss: 1.822505025453465

Epoch: 6| Step: 9
Training loss: 0.7452961206436157
Validation loss: 1.849213022057728

Epoch: 6| Step: 10
Training loss: 1.7400096654891968
Validation loss: 1.8113574315142889

Epoch: 6| Step: 11
Training loss: 0.8878535032272339
Validation loss: 1.8435652666194464

Epoch: 6| Step: 12
Training loss: 0.9040296673774719
Validation loss: 1.8500447221981582

Epoch: 6| Step: 13
Training loss: 1.1569265127182007
Validation loss: 1.7816516276328795

Epoch: 451| Step: 0
Training loss: 1.5077924728393555
Validation loss: 1.7527258498694307

Epoch: 6| Step: 1
Training loss: 0.7894058227539062
Validation loss: 1.82438079772457

Epoch: 6| Step: 2
Training loss: 1.42828369140625
Validation loss: 1.8339841673451085

Epoch: 6| Step: 3
Training loss: 1.1466810703277588
Validation loss: 1.7693065084436888

Epoch: 6| Step: 4
Training loss: 0.8264005780220032
Validation loss: 1.8048495413154684

Epoch: 6| Step: 5
Training loss: 0.7971735000610352
Validation loss: 1.7679974391896238

Epoch: 6| Step: 6
Training loss: 1.3410251140594482
Validation loss: 1.7771064799319032

Epoch: 6| Step: 7
Training loss: 1.3884937763214111
Validation loss: 1.7709203689329085

Epoch: 6| Step: 8
Training loss: 0.7822125554084778
Validation loss: 1.721650992670367

Epoch: 6| Step: 9
Training loss: 1.1213693618774414
Validation loss: 1.7758538158991004

Epoch: 6| Step: 10
Training loss: 0.8370496034622192
Validation loss: 1.7946915972617365

Epoch: 6| Step: 11
Training loss: 1.5870473384857178
Validation loss: 1.79512531270263

Epoch: 6| Step: 12
Training loss: 1.2175644636154175
Validation loss: 1.7618205162786669

Epoch: 6| Step: 13
Training loss: 0.7468055486679077
Validation loss: 1.8000924856432023

Epoch: 452| Step: 0
Training loss: 0.8667812943458557
Validation loss: 1.7802300055821736

Epoch: 6| Step: 1
Training loss: 1.4940381050109863
Validation loss: 1.8465964512158466

Epoch: 6| Step: 2
Training loss: 1.2504432201385498
Validation loss: 1.8427500981156544

Epoch: 6| Step: 3
Training loss: 0.7131826877593994
Validation loss: 1.8200213114420574

Epoch: 6| Step: 4
Training loss: 0.97672039270401
Validation loss: 1.8587157610924012

Epoch: 6| Step: 5
Training loss: 0.8609790802001953
Validation loss: 1.8376511066190657

Epoch: 6| Step: 6
Training loss: 1.3586915731430054
Validation loss: 1.8720690460615261

Epoch: 6| Step: 7
Training loss: 0.720761775970459
Validation loss: 1.8932885187928394

Epoch: 6| Step: 8
Training loss: 1.107599139213562
Validation loss: 1.7991491966350104

Epoch: 6| Step: 9
Training loss: 1.2586033344268799
Validation loss: 1.8621381252042708

Epoch: 6| Step: 10
Training loss: 1.3156473636627197
Validation loss: 1.792022135949904

Epoch: 6| Step: 11
Training loss: 1.0644989013671875
Validation loss: 1.8356089194615681

Epoch: 6| Step: 12
Training loss: 1.0277857780456543
Validation loss: 1.8204978012269544

Epoch: 6| Step: 13
Training loss: 1.530726432800293
Validation loss: 1.8339074427081692

Epoch: 453| Step: 0
Training loss: 0.8924152255058289
Validation loss: 1.7435614870440574

Epoch: 6| Step: 1
Training loss: 1.0504223108291626
Validation loss: 1.7715711157809022

Epoch: 6| Step: 2
Training loss: 0.7746597528457642
Validation loss: 1.8210104242447884

Epoch: 6| Step: 3
Training loss: 1.2380149364471436
Validation loss: 1.7705085918467531

Epoch: 6| Step: 4
Training loss: 1.1055078506469727
Validation loss: 1.7588331122552194

Epoch: 6| Step: 5
Training loss: 0.6177648305892944
Validation loss: 1.7889498215849682

Epoch: 6| Step: 6
Training loss: 1.1814618110656738
Validation loss: 1.7792452343048588

Epoch: 6| Step: 7
Training loss: 1.7222741842269897
Validation loss: 1.7678560672267791

Epoch: 6| Step: 8
Training loss: 0.992787778377533
Validation loss: 1.7156196781384048

Epoch: 6| Step: 9
Training loss: 1.4098575115203857
Validation loss: 1.8175330495321622

Epoch: 6| Step: 10
Training loss: 1.02525794506073
Validation loss: 1.8115063944170553

Epoch: 6| Step: 11
Training loss: 1.0357873439788818
Validation loss: 1.7302341025362733

Epoch: 6| Step: 12
Training loss: 0.8889082670211792
Validation loss: 1.7993327417681295

Epoch: 6| Step: 13
Training loss: 1.3932528495788574
Validation loss: 1.7481844156019148

Epoch: 454| Step: 0
Training loss: 0.8820606470108032
Validation loss: 1.8446335792541504

Epoch: 6| Step: 1
Training loss: 1.0670616626739502
Validation loss: 1.8173235783012964

Epoch: 6| Step: 2
Training loss: 1.7725003957748413
Validation loss: 1.7455125137041974

Epoch: 6| Step: 3
Training loss: 1.048210620880127
Validation loss: 1.8075008084697108

Epoch: 6| Step: 4
Training loss: 0.9811136722564697
Validation loss: 1.818761646106679

Epoch: 6| Step: 5
Training loss: 0.9085756540298462
Validation loss: 1.78874070413651

Epoch: 6| Step: 6
Training loss: 1.219035029411316
Validation loss: 1.8091430510244062

Epoch: 6| Step: 7
Training loss: 0.6519777774810791
Validation loss: 1.7744823053318968

Epoch: 6| Step: 8
Training loss: 0.7912235856056213
Validation loss: 1.7590424219767253

Epoch: 6| Step: 9
Training loss: 1.5141232013702393
Validation loss: 1.7880269378744147

Epoch: 6| Step: 10
Training loss: 0.6215398907661438
Validation loss: 1.7854529093670588

Epoch: 6| Step: 11
Training loss: 0.8722862005233765
Validation loss: 1.7541924958587976

Epoch: 6| Step: 12
Training loss: 1.2508926391601562
Validation loss: 1.8119937399382233

Epoch: 6| Step: 13
Training loss: 2.0028350353240967
Validation loss: 1.7659317806202879

Epoch: 455| Step: 0
Training loss: 1.3054475784301758
Validation loss: 1.8345014702889226

Epoch: 6| Step: 1
Training loss: 0.8612252473831177
Validation loss: 1.779789464448088

Epoch: 6| Step: 2
Training loss: 1.4161559343338013
Validation loss: 1.8085910056226997

Epoch: 6| Step: 3
Training loss: 1.034001111984253
Validation loss: 1.836749130679715

Epoch: 6| Step: 4
Training loss: 1.0185927152633667
Validation loss: 1.805493954689272

Epoch: 6| Step: 5
Training loss: 0.8501291275024414
Validation loss: 1.8263316577480686

Epoch: 6| Step: 6
Training loss: 1.1815333366394043
Validation loss: 1.853554719237871

Epoch: 6| Step: 7
Training loss: 0.7659192085266113
Validation loss: 1.7764315605163574

Epoch: 6| Step: 8
Training loss: 1.1382851600646973
Validation loss: 1.782564305490063

Epoch: 6| Step: 9
Training loss: 0.8445872068405151
Validation loss: 1.832057858026156

Epoch: 6| Step: 10
Training loss: 0.9393094778060913
Validation loss: 1.8064054545535837

Epoch: 6| Step: 11
Training loss: 1.2273945808410645
Validation loss: 1.7774723281142533

Epoch: 6| Step: 12
Training loss: 1.1488828659057617
Validation loss: 1.8377634222789476

Epoch: 6| Step: 13
Training loss: 1.3532159328460693
Validation loss: 1.8171370478086575

Epoch: 456| Step: 0
Training loss: 0.7579667568206787
Validation loss: 1.8328969760607647

Epoch: 6| Step: 1
Training loss: 0.6937770247459412
Validation loss: 1.765409791341392

Epoch: 6| Step: 2
Training loss: 1.1521391868591309
Validation loss: 1.8129477795734201

Epoch: 6| Step: 3
Training loss: 0.680279552936554
Validation loss: 1.7431769012123026

Epoch: 6| Step: 4
Training loss: 1.2710363864898682
Validation loss: 1.7733508412555983

Epoch: 6| Step: 5
Training loss: 0.9552673101425171
Validation loss: 1.839951438288535

Epoch: 6| Step: 6
Training loss: 1.754183053970337
Validation loss: 1.8204425906622281

Epoch: 6| Step: 7
Training loss: 0.9122785925865173
Validation loss: 1.830637695968792

Epoch: 6| Step: 8
Training loss: 1.0284076929092407
Validation loss: 1.7595149060731292

Epoch: 6| Step: 9
Training loss: 1.2070164680480957
Validation loss: 1.7996468569642754

Epoch: 6| Step: 10
Training loss: 0.7264996767044067
Validation loss: 1.7590096663403254

Epoch: 6| Step: 11
Training loss: 1.2688820362091064
Validation loss: 1.7844840813708562

Epoch: 6| Step: 12
Training loss: 1.4550800323486328
Validation loss: 1.8251617313713155

Epoch: 6| Step: 13
Training loss: 1.852957010269165
Validation loss: 1.7927197679396598

Epoch: 457| Step: 0
Training loss: 0.5854738354682922
Validation loss: 1.79731656659034

Epoch: 6| Step: 1
Training loss: 0.9653146862983704
Validation loss: 1.7315178507117814

Epoch: 6| Step: 2
Training loss: 1.1293129920959473
Validation loss: 1.7860946680909844

Epoch: 6| Step: 3
Training loss: 1.126674771308899
Validation loss: 1.7864951523401404

Epoch: 6| Step: 4
Training loss: 1.1154344081878662
Validation loss: 1.8025281108835691

Epoch: 6| Step: 5
Training loss: 0.7981255054473877
Validation loss: 1.7638949104534682

Epoch: 6| Step: 6
Training loss: 1.4347120523452759
Validation loss: 1.805436885485085

Epoch: 6| Step: 7
Training loss: 0.941616952419281
Validation loss: 1.7719662112574424

Epoch: 6| Step: 8
Training loss: 1.1649717092514038
Validation loss: 1.7598831230594265

Epoch: 6| Step: 9
Training loss: 1.054013967514038
Validation loss: 1.8123139040444487

Epoch: 6| Step: 10
Training loss: 1.3891186714172363
Validation loss: 1.8541799719615648

Epoch: 6| Step: 11
Training loss: 1.4836955070495605
Validation loss: 1.849762434600502

Epoch: 6| Step: 12
Training loss: 1.1284834146499634
Validation loss: 1.8903848740362352

Epoch: 6| Step: 13
Training loss: 0.8653214573860168
Validation loss: 1.8362319161815028

Epoch: 458| Step: 0
Training loss: 0.7086232900619507
Validation loss: 1.8494415437021563

Epoch: 6| Step: 1
Training loss: 1.176307201385498
Validation loss: 1.8252415246860956

Epoch: 6| Step: 2
Training loss: 1.4908719062805176
Validation loss: 1.8211047239201044

Epoch: 6| Step: 3
Training loss: 1.537920355796814
Validation loss: 1.80307267045462

Epoch: 6| Step: 4
Training loss: 1.0181703567504883
Validation loss: 1.7955190763678601

Epoch: 6| Step: 5
Training loss: 1.095503568649292
Validation loss: 1.8382046107322938

Epoch: 6| Step: 6
Training loss: 0.9979654550552368
Validation loss: 1.7753335763049383

Epoch: 6| Step: 7
Training loss: 1.0907657146453857
Validation loss: 1.7651554038447719

Epoch: 6| Step: 8
Training loss: 1.332647442817688
Validation loss: 1.7733286708913825

Epoch: 6| Step: 9
Training loss: 1.0884511470794678
Validation loss: 1.7826054621768255

Epoch: 6| Step: 10
Training loss: 1.0014338493347168
Validation loss: 1.8017893363070745

Epoch: 6| Step: 11
Training loss: 0.7911710143089294
Validation loss: 1.7906569588568904

Epoch: 6| Step: 12
Training loss: 1.099778413772583
Validation loss: 1.7844002592948176

Epoch: 6| Step: 13
Training loss: 0.6520792841911316
Validation loss: 1.8013751096622919

Epoch: 459| Step: 0
Training loss: 0.840661883354187
Validation loss: 1.774549949553705

Epoch: 6| Step: 1
Training loss: 1.52785062789917
Validation loss: 1.828780133237121

Epoch: 6| Step: 2
Training loss: 0.9384182691574097
Validation loss: 1.7952915340341546

Epoch: 6| Step: 3
Training loss: 0.6288333535194397
Validation loss: 1.7809834082921345

Epoch: 6| Step: 4
Training loss: 1.0231726169586182
Validation loss: 1.7990471624558972

Epoch: 6| Step: 5
Training loss: 0.6408450603485107
Validation loss: 1.8535354880876438

Epoch: 6| Step: 6
Training loss: 1.0188498497009277
Validation loss: 1.837278667316642

Epoch: 6| Step: 7
Training loss: 0.9261860847473145
Validation loss: 1.7903472197953092

Epoch: 6| Step: 8
Training loss: 1.2637732028961182
Validation loss: 1.7492920634567097

Epoch: 6| Step: 9
Training loss: 1.2360565662384033
Validation loss: 1.720468057099209

Epoch: 6| Step: 10
Training loss: 0.962640106678009
Validation loss: 1.7758022918496081

Epoch: 6| Step: 11
Training loss: 0.9840285778045654
Validation loss: 1.798573354239105

Epoch: 6| Step: 12
Training loss: 1.5519853830337524
Validation loss: 1.7590305638569657

Epoch: 6| Step: 13
Training loss: 1.608980655670166
Validation loss: 1.7697841313577467

Epoch: 460| Step: 0
Training loss: 1.4639217853546143
Validation loss: 1.774169655256374

Epoch: 6| Step: 1
Training loss: 1.261075735092163
Validation loss: 1.8184740697183917

Epoch: 6| Step: 2
Training loss: 1.171341896057129
Validation loss: 1.7817965604925667

Epoch: 6| Step: 3
Training loss: 0.7803417444229126
Validation loss: 1.8373252755852156

Epoch: 6| Step: 4
Training loss: 0.8831045031547546
Validation loss: 1.8144675916241062

Epoch: 6| Step: 5
Training loss: 1.2540428638458252
Validation loss: 1.8324274247692478

Epoch: 6| Step: 6
Training loss: 1.6360020637512207
Validation loss: 1.7675617279544953

Epoch: 6| Step: 7
Training loss: 0.9329087734222412
Validation loss: 1.8250411684795091

Epoch: 6| Step: 8
Training loss: 0.9668184518814087
Validation loss: 1.8633632326638827

Epoch: 6| Step: 9
Training loss: 1.0731379985809326
Validation loss: 1.8365408861508934

Epoch: 6| Step: 10
Training loss: 1.4900720119476318
Validation loss: 1.8113923867543538

Epoch: 6| Step: 11
Training loss: 0.621955156326294
Validation loss: 1.8010583180253223

Epoch: 6| Step: 12
Training loss: 0.9515143632888794
Validation loss: 1.807650855792466

Epoch: 6| Step: 13
Training loss: 1.219663381576538
Validation loss: 1.7550421248200119

Epoch: 461| Step: 0
Training loss: 0.8517487049102783
Validation loss: 1.768681062165127

Epoch: 6| Step: 1
Training loss: 1.3070955276489258
Validation loss: 1.746122969094143

Epoch: 6| Step: 2
Training loss: 1.4775255918502808
Validation loss: 1.7976306446136967

Epoch: 6| Step: 3
Training loss: 1.746208667755127
Validation loss: 1.7794936587733607

Epoch: 6| Step: 4
Training loss: 0.7671917676925659
Validation loss: 1.8074862982637139

Epoch: 6| Step: 5
Training loss: 1.067740797996521
Validation loss: 1.8471966328159455

Epoch: 6| Step: 6
Training loss: 1.3272333145141602
Validation loss: 1.773171429993004

Epoch: 6| Step: 7
Training loss: 0.8185364007949829
Validation loss: 1.7426561899082635

Epoch: 6| Step: 8
Training loss: 1.2271274328231812
Validation loss: 1.7940872305183

Epoch: 6| Step: 9
Training loss: 1.7870264053344727
Validation loss: 1.7131649653116863

Epoch: 6| Step: 10
Training loss: 0.741055965423584
Validation loss: 1.7166837453842163

Epoch: 6| Step: 11
Training loss: 0.8417829275131226
Validation loss: 1.776854181802401

Epoch: 6| Step: 12
Training loss: 1.22645902633667
Validation loss: 1.8369495022681452

Epoch: 6| Step: 13
Training loss: 1.0701043605804443
Validation loss: 1.8501440966001121

Epoch: 462| Step: 0
Training loss: 1.4238364696502686
Validation loss: 1.8369503944150862

Epoch: 6| Step: 1
Training loss: 1.024505615234375
Validation loss: 1.8679730802453973

Epoch: 6| Step: 2
Training loss: 0.7631911039352417
Validation loss: 1.7955808101161834

Epoch: 6| Step: 3
Training loss: 0.8810843825340271
Validation loss: 1.8581294680154452

Epoch: 6| Step: 4
Training loss: 1.6581227779388428
Validation loss: 1.8068776874132053

Epoch: 6| Step: 5
Training loss: 1.0726063251495361
Validation loss: 1.782011979369707

Epoch: 6| Step: 6
Training loss: 0.9770405292510986
Validation loss: 1.8014747942647626

Epoch: 6| Step: 7
Training loss: 0.9144151210784912
Validation loss: 1.8585513138001966

Epoch: 6| Step: 8
Training loss: 0.9719730615615845
Validation loss: 1.755330765119163

Epoch: 6| Step: 9
Training loss: 1.3352069854736328
Validation loss: 1.814763965145234

Epoch: 6| Step: 10
Training loss: 1.2603507041931152
Validation loss: 1.7245679273400256

Epoch: 6| Step: 11
Training loss: 1.0600378513336182
Validation loss: 1.7866708924693446

Epoch: 6| Step: 12
Training loss: 0.7754448056221008
Validation loss: 1.7714679625726515

Epoch: 6| Step: 13
Training loss: 1.160422444343567
Validation loss: 1.8009239922287643

Epoch: 463| Step: 0
Training loss: 1.1560765504837036
Validation loss: 1.815553472888085

Epoch: 6| Step: 1
Training loss: 0.9812698364257812
Validation loss: 1.8159146308898926

Epoch: 6| Step: 2
Training loss: 1.753890037536621
Validation loss: 1.7834449237392795

Epoch: 6| Step: 3
Training loss: 1.014073371887207
Validation loss: 1.7585575990779425

Epoch: 6| Step: 4
Training loss: 1.1692818403244019
Validation loss: 1.7157336306828324

Epoch: 6| Step: 5
Training loss: 0.8607239723205566
Validation loss: 1.7532557210614603

Epoch: 6| Step: 6
Training loss: 0.8385697603225708
Validation loss: 1.7635967552020986

Epoch: 6| Step: 7
Training loss: 0.9005107283592224
Validation loss: 1.8131412716322048

Epoch: 6| Step: 8
Training loss: 0.5193313956260681
Validation loss: 1.767860133160827

Epoch: 6| Step: 9
Training loss: 0.8169805407524109
Validation loss: 1.8282839521285026

Epoch: 6| Step: 10
Training loss: 0.938144326210022
Validation loss: 1.8211447538868073

Epoch: 6| Step: 11
Training loss: 0.7839035987854004
Validation loss: 1.794070198971738

Epoch: 6| Step: 12
Training loss: 1.5716662406921387
Validation loss: 1.8066158422859766

Epoch: 6| Step: 13
Training loss: 1.2097554206848145
Validation loss: 1.8071542824468305

Epoch: 464| Step: 0
Training loss: 1.0649566650390625
Validation loss: 1.7450902744006085

Epoch: 6| Step: 1
Training loss: 1.2182974815368652
Validation loss: 1.7578476552040345

Epoch: 6| Step: 2
Training loss: 0.9938883185386658
Validation loss: 1.763928585155036

Epoch: 6| Step: 3
Training loss: 1.083115577697754
Validation loss: 1.7517536711949173

Epoch: 6| Step: 4
Training loss: 0.721160352230072
Validation loss: 1.7652312388984106

Epoch: 6| Step: 5
Training loss: 0.9195333123207092
Validation loss: 1.71401213061425

Epoch: 6| Step: 6
Training loss: 0.46191802620887756
Validation loss: 1.768039050922599

Epoch: 6| Step: 7
Training loss: 0.7410333156585693
Validation loss: 1.8064641439786522

Epoch: 6| Step: 8
Training loss: 1.117558240890503
Validation loss: 1.8061638724419378

Epoch: 6| Step: 9
Training loss: 1.4088106155395508
Validation loss: 1.7991870449435325

Epoch: 6| Step: 10
Training loss: 1.059018850326538
Validation loss: 1.7815765911532986

Epoch: 6| Step: 11
Training loss: 0.8801335692405701
Validation loss: 1.8223433238203808

Epoch: 6| Step: 12
Training loss: 1.8098843097686768
Validation loss: 1.8071066359037995

Epoch: 6| Step: 13
Training loss: 1.8555856943130493
Validation loss: 1.7854662095346758

Epoch: 465| Step: 0
Training loss: 1.243537187576294
Validation loss: 1.8080361914891068

Epoch: 6| Step: 1
Training loss: 0.8673745393753052
Validation loss: 1.758957855163082

Epoch: 6| Step: 2
Training loss: 0.9548795223236084
Validation loss: 1.8693549838117374

Epoch: 6| Step: 3
Training loss: 1.29917311668396
Validation loss: 1.816802296587216

Epoch: 6| Step: 4
Training loss: 0.8038057088851929
Validation loss: 1.80179294975855

Epoch: 6| Step: 5
Training loss: 1.3555986881256104
Validation loss: 1.8053000896207747

Epoch: 6| Step: 6
Training loss: 1.0266962051391602
Validation loss: 1.866313434416248

Epoch: 6| Step: 7
Training loss: 1.0809471607208252
Validation loss: 1.764340982642225

Epoch: 6| Step: 8
Training loss: 1.4726893901824951
Validation loss: 1.7588813074173466

Epoch: 6| Step: 9
Training loss: 1.0914537906646729
Validation loss: 1.784730903563961

Epoch: 6| Step: 10
Training loss: 1.0688235759735107
Validation loss: 1.8507913184422318

Epoch: 6| Step: 11
Training loss: 1.1592793464660645
Validation loss: 1.8139968918215843

Epoch: 6| Step: 12
Training loss: 1.2733352184295654
Validation loss: 1.72384391420631

Epoch: 6| Step: 13
Training loss: 1.218435525894165
Validation loss: 1.7559592262391122

Epoch: 466| Step: 0
Training loss: 0.47541916370391846
Validation loss: 1.8153270970108688

Epoch: 6| Step: 1
Training loss: 0.8373903036117554
Validation loss: 1.8030964943670458

Epoch: 6| Step: 2
Training loss: 1.7425289154052734
Validation loss: 1.7580512838978921

Epoch: 6| Step: 3
Training loss: 1.2630505561828613
Validation loss: 1.8201453749851515

Epoch: 6| Step: 4
Training loss: 1.1577651500701904
Validation loss: 1.7815014687917565

Epoch: 6| Step: 5
Training loss: 1.3327287435531616
Validation loss: 1.738250010757036

Epoch: 6| Step: 6
Training loss: 1.2734211683273315
Validation loss: 1.7629270617679884

Epoch: 6| Step: 7
Training loss: 1.3854005336761475
Validation loss: 1.7576000844278643

Epoch: 6| Step: 8
Training loss: 0.9276734590530396
Validation loss: 1.7664011947570308

Epoch: 6| Step: 9
Training loss: 0.9320352077484131
Validation loss: 1.7841433671212965

Epoch: 6| Step: 10
Training loss: 1.06955087184906
Validation loss: 1.762135636421942

Epoch: 6| Step: 11
Training loss: 0.9351798295974731
Validation loss: 1.7784859877760693

Epoch: 6| Step: 12
Training loss: 0.6127198338508606
Validation loss: 1.7653366070921703

Epoch: 6| Step: 13
Training loss: 0.6997331976890564
Validation loss: 1.790571738314885

Epoch: 467| Step: 0
Training loss: 1.1405696868896484
Validation loss: 1.789979693710163

Epoch: 6| Step: 1
Training loss: 0.9564729928970337
Validation loss: 1.6906869962651243

Epoch: 6| Step: 2
Training loss: 1.6632245779037476
Validation loss: 1.7878312487756052

Epoch: 6| Step: 3
Training loss: 1.2249150276184082
Validation loss: 1.7908939738427438

Epoch: 6| Step: 4
Training loss: 1.1542000770568848
Validation loss: 1.6861801121824531

Epoch: 6| Step: 5
Training loss: 1.4047584533691406
Validation loss: 1.7514473776663504

Epoch: 6| Step: 6
Training loss: 0.8038843274116516
Validation loss: 1.7523342127441077

Epoch: 6| Step: 7
Training loss: 0.6919487118721008
Validation loss: 1.7949589080708002

Epoch: 6| Step: 8
Training loss: 0.9086077809333801
Validation loss: 1.7616951927062003

Epoch: 6| Step: 9
Training loss: 1.267635464668274
Validation loss: 1.759199720557018

Epoch: 6| Step: 10
Training loss: 0.4521186947822571
Validation loss: 1.8121517422378703

Epoch: 6| Step: 11
Training loss: 1.1067779064178467
Validation loss: 1.7827474135224537

Epoch: 6| Step: 12
Training loss: 0.8181746006011963
Validation loss: 1.82392785497891

Epoch: 6| Step: 13
Training loss: 1.3071811199188232
Validation loss: 1.8856631068773166

Epoch: 468| Step: 0
Training loss: 0.9505385160446167
Validation loss: 1.8710841709567654

Epoch: 6| Step: 1
Training loss: 1.2987240552902222
Validation loss: 1.8152881847914828

Epoch: 6| Step: 2
Training loss: 1.0329264402389526
Validation loss: 1.822050545805244

Epoch: 6| Step: 3
Training loss: 1.825872778892517
Validation loss: 1.7992542853919409

Epoch: 6| Step: 4
Training loss: 1.1939873695373535
Validation loss: 1.7711333126150153

Epoch: 6| Step: 5
Training loss: 0.7965455055236816
Validation loss: 1.808123779553239

Epoch: 6| Step: 6
Training loss: 0.7432355880737305
Validation loss: 1.8070713614904752

Epoch: 6| Step: 7
Training loss: 1.0388123989105225
Validation loss: 1.7598164722483645

Epoch: 6| Step: 8
Training loss: 1.0072047710418701
Validation loss: 1.7882676701391897

Epoch: 6| Step: 9
Training loss: 0.9874967336654663
Validation loss: 1.7610966287633425

Epoch: 6| Step: 10
Training loss: 0.6970577239990234
Validation loss: 1.8440404579203615

Epoch: 6| Step: 11
Training loss: 0.9853475093841553
Validation loss: 1.7752365630160096

Epoch: 6| Step: 12
Training loss: 1.1606029272079468
Validation loss: 1.7795391005854453

Epoch: 6| Step: 13
Training loss: 0.6973464488983154
Validation loss: 1.7600837497300998

Epoch: 469| Step: 0
Training loss: 1.0781564712524414
Validation loss: 1.7751505926091184

Epoch: 6| Step: 1
Training loss: 1.2468771934509277
Validation loss: 1.803287309985007

Epoch: 6| Step: 2
Training loss: 0.8935896158218384
Validation loss: 1.7569252573033816

Epoch: 6| Step: 3
Training loss: 0.8687605261802673
Validation loss: 1.7714703621402863

Epoch: 6| Step: 4
Training loss: 0.9246010184288025
Validation loss: 1.7263464030399118

Epoch: 6| Step: 5
Training loss: 1.321424126625061
Validation loss: 1.7492298579985095

Epoch: 6| Step: 6
Training loss: 0.8310766220092773
Validation loss: 1.7878207904036327

Epoch: 6| Step: 7
Training loss: 0.9915770888328552
Validation loss: 1.747213630266087

Epoch: 6| Step: 8
Training loss: 1.0834486484527588
Validation loss: 1.7655124638670234

Epoch: 6| Step: 9
Training loss: 0.8680224418640137
Validation loss: 1.851819811328765

Epoch: 6| Step: 10
Training loss: 0.9492863416671753
Validation loss: 1.8113792416869954

Epoch: 6| Step: 11
Training loss: 1.4341686964035034
Validation loss: 1.7731240846777474

Epoch: 6| Step: 12
Training loss: 1.2324891090393066
Validation loss: 1.8131140457686556

Epoch: 6| Step: 13
Training loss: 0.9670782089233398
Validation loss: 1.8335965192446144

Epoch: 470| Step: 0
Training loss: 1.3465532064437866
Validation loss: 1.837813142807253

Epoch: 6| Step: 1
Training loss: 1.078232765197754
Validation loss: 1.7443200170352895

Epoch: 6| Step: 2
Training loss: 0.8566058874130249
Validation loss: 1.7718429168065388

Epoch: 6| Step: 3
Training loss: 1.3536611795425415
Validation loss: 1.7651257156043925

Epoch: 6| Step: 4
Training loss: 1.0586507320404053
Validation loss: 1.7945573855471868

Epoch: 6| Step: 5
Training loss: 0.686087965965271
Validation loss: 1.7834144561521468

Epoch: 6| Step: 6
Training loss: 1.1468868255615234
Validation loss: 1.7913915162445397

Epoch: 6| Step: 7
Training loss: 0.8800008893013
Validation loss: 1.7791737023220267

Epoch: 6| Step: 8
Training loss: 0.6963396072387695
Validation loss: 1.7800572585034113

Epoch: 6| Step: 9
Training loss: 1.1719928979873657
Validation loss: 1.816386289494012

Epoch: 6| Step: 10
Training loss: 1.5750452280044556
Validation loss: 1.752032897805655

Epoch: 6| Step: 11
Training loss: 1.2102596759796143
Validation loss: 1.7583715851588915

Epoch: 6| Step: 12
Training loss: 0.6712362766265869
Validation loss: 1.8080914187174972

Epoch: 6| Step: 13
Training loss: 0.7681626081466675
Validation loss: 1.7417022797369188

Epoch: 471| Step: 0
Training loss: 1.234277367591858
Validation loss: 1.7837494060557375

Epoch: 6| Step: 1
Training loss: 1.0196073055267334
Validation loss: 1.796640473027383

Epoch: 6| Step: 2
Training loss: 1.0750398635864258
Validation loss: 1.7339383094541487

Epoch: 6| Step: 3
Training loss: 1.115614891052246
Validation loss: 1.7551197992858065

Epoch: 6| Step: 4
Training loss: 0.8781150579452515
Validation loss: 1.7787034485929756

Epoch: 6| Step: 5
Training loss: 1.190834641456604
Validation loss: 1.7805840058993267

Epoch: 6| Step: 6
Training loss: 0.6158239841461182
Validation loss: 1.7734666678213304

Epoch: 6| Step: 7
Training loss: 0.9139065742492676
Validation loss: 1.7815247402396253

Epoch: 6| Step: 8
Training loss: 1.2743661403656006
Validation loss: 1.7754281733625679

Epoch: 6| Step: 9
Training loss: 1.0063443183898926
Validation loss: 1.7786456961785593

Epoch: 6| Step: 10
Training loss: 1.6397175788879395
Validation loss: 1.7874084121437483

Epoch: 6| Step: 11
Training loss: 0.9584017992019653
Validation loss: 1.8399295165974607

Epoch: 6| Step: 12
Training loss: 1.1250646114349365
Validation loss: 1.788068663689398

Epoch: 6| Step: 13
Training loss: 0.7259883880615234
Validation loss: 1.818086334454116

Epoch: 472| Step: 0
Training loss: 0.5577523708343506
Validation loss: 1.8232717052582772

Epoch: 6| Step: 1
Training loss: 1.1597813367843628
Validation loss: 1.766665030551213

Epoch: 6| Step: 2
Training loss: 1.3477752208709717
Validation loss: 1.8609204574297833

Epoch: 6| Step: 3
Training loss: 0.7377932071685791
Validation loss: 1.7919178893489223

Epoch: 6| Step: 4
Training loss: 1.048223614692688
Validation loss: 1.8132781431239138

Epoch: 6| Step: 5
Training loss: 1.423187494277954
Validation loss: 1.7812873394258562

Epoch: 6| Step: 6
Training loss: 0.5606503486633301
Validation loss: 1.8085740035580051

Epoch: 6| Step: 7
Training loss: 1.2198400497436523
Validation loss: 1.817920950151259

Epoch: 6| Step: 8
Training loss: 1.5812194347381592
Validation loss: 1.7764673079213789

Epoch: 6| Step: 9
Training loss: 1.270514726638794
Validation loss: 1.74431102250212

Epoch: 6| Step: 10
Training loss: 0.7600090503692627
Validation loss: 1.8283454679673719

Epoch: 6| Step: 11
Training loss: 1.3654569387435913
Validation loss: 1.7775148601942166

Epoch: 6| Step: 12
Training loss: 0.9775856733322144
Validation loss: 1.8358342916734758

Epoch: 6| Step: 13
Training loss: 0.8851442337036133
Validation loss: 1.7610718768130067

Epoch: 473| Step: 0
Training loss: 0.8202536106109619
Validation loss: 1.7540194962614326

Epoch: 6| Step: 1
Training loss: 1.0964746475219727
Validation loss: 1.734698075120167

Epoch: 6| Step: 2
Training loss: 1.1428836584091187
Validation loss: 1.7199563454556208

Epoch: 6| Step: 3
Training loss: 1.5179920196533203
Validation loss: 1.8074799917077506

Epoch: 6| Step: 4
Training loss: 0.8577125072479248
Validation loss: 1.780279803019698

Epoch: 6| Step: 5
Training loss: 0.7234529256820679
Validation loss: 1.7582576326144639

Epoch: 6| Step: 6
Training loss: 0.8080689907073975
Validation loss: 1.8057982485781434

Epoch: 6| Step: 7
Training loss: 1.1349678039550781
Validation loss: 1.7706470489501953

Epoch: 6| Step: 8
Training loss: 1.3274214267730713
Validation loss: 1.734017841277584

Epoch: 6| Step: 9
Training loss: 0.6148130893707275
Validation loss: 1.7630062987727504

Epoch: 6| Step: 10
Training loss: 1.4322184324264526
Validation loss: 1.7632936636606853

Epoch: 6| Step: 11
Training loss: 0.8473289012908936
Validation loss: 1.7829976030575332

Epoch: 6| Step: 12
Training loss: 1.1768770217895508
Validation loss: 1.7885075474298129

Epoch: 6| Step: 13
Training loss: 0.9919524788856506
Validation loss: 1.756408937515751

Epoch: 474| Step: 0
Training loss: 0.9354236721992493
Validation loss: 1.8067212399616037

Epoch: 6| Step: 1
Training loss: 1.8636469841003418
Validation loss: 1.788483924763177

Epoch: 6| Step: 2
Training loss: 0.5306429862976074
Validation loss: 1.8037111772003995

Epoch: 6| Step: 3
Training loss: 1.0394922494888306
Validation loss: 1.8066714758514075

Epoch: 6| Step: 4
Training loss: 0.9787456393241882
Validation loss: 1.7883063272763324

Epoch: 6| Step: 5
Training loss: 0.7789458632469177
Validation loss: 1.830848865611579

Epoch: 6| Step: 6
Training loss: 1.1881568431854248
Validation loss: 1.7709061561092254

Epoch: 6| Step: 7
Training loss: 1.2542171478271484
Validation loss: 1.799383137815742

Epoch: 6| Step: 8
Training loss: 1.124333143234253
Validation loss: 1.8700881042788107

Epoch: 6| Step: 9
Training loss: 0.716300368309021
Validation loss: 1.7786019668784192

Epoch: 6| Step: 10
Training loss: 0.3606299161911011
Validation loss: 1.804008953032955

Epoch: 6| Step: 11
Training loss: 1.0477604866027832
Validation loss: 1.7737215988097652

Epoch: 6| Step: 12
Training loss: 1.3478671312332153
Validation loss: 1.8358274313711351

Epoch: 6| Step: 13
Training loss: 1.0472331047058105
Validation loss: 1.7715716592727169

Epoch: 475| Step: 0
Training loss: 0.8453577756881714
Validation loss: 1.7919117340477564

Epoch: 6| Step: 1
Training loss: 1.569490909576416
Validation loss: 1.7980206345999112

Epoch: 6| Step: 2
Training loss: 1.061108112335205
Validation loss: 1.736263495619579

Epoch: 6| Step: 3
Training loss: 0.835334300994873
Validation loss: 1.8056555537767307

Epoch: 6| Step: 4
Training loss: 0.9841243028640747
Validation loss: 1.8127120476897045

Epoch: 6| Step: 5
Training loss: 0.823935329914093
Validation loss: 1.788409444593614

Epoch: 6| Step: 6
Training loss: 1.2810940742492676
Validation loss: 1.7689081033070881

Epoch: 6| Step: 7
Training loss: 1.2861852645874023
Validation loss: 1.8030771363166072

Epoch: 6| Step: 8
Training loss: 1.207000970840454
Validation loss: 1.8478964054456322

Epoch: 6| Step: 9
Training loss: 1.1287274360656738
Validation loss: 1.8200956301022602

Epoch: 6| Step: 10
Training loss: 0.7759215831756592
Validation loss: 1.7547959691734725

Epoch: 6| Step: 11
Training loss: 0.682583212852478
Validation loss: 1.794514085656853

Epoch: 6| Step: 12
Training loss: 1.172240972518921
Validation loss: 1.7548644850330968

Epoch: 6| Step: 13
Training loss: 0.7707979679107666
Validation loss: 1.787978054374777

Epoch: 476| Step: 0
Training loss: 0.9048534631729126
Validation loss: 1.7582378515633204

Epoch: 6| Step: 1
Training loss: 1.3903493881225586
Validation loss: 1.7622731680511146

Epoch: 6| Step: 2
Training loss: 0.9076626300811768
Validation loss: 1.8171271406194216

Epoch: 6| Step: 3
Training loss: 0.9112433195114136
Validation loss: 1.7930839164282686

Epoch: 6| Step: 4
Training loss: 1.039472222328186
Validation loss: 1.7335648036772204

Epoch: 6| Step: 5
Training loss: 0.8514484763145447
Validation loss: 1.7465356870364117

Epoch: 6| Step: 6
Training loss: 0.7398543953895569
Validation loss: 1.723415426028672

Epoch: 6| Step: 7
Training loss: 1.2658684253692627
Validation loss: 1.832645639296501

Epoch: 6| Step: 8
Training loss: 1.4497246742248535
Validation loss: 1.7490190216290054

Epoch: 6| Step: 9
Training loss: 1.2161648273468018
Validation loss: 1.7331072386874948

Epoch: 6| Step: 10
Training loss: 0.8577829599380493
Validation loss: 1.7789798526353733

Epoch: 6| Step: 11
Training loss: 0.9390385150909424
Validation loss: 1.7870906463233374

Epoch: 6| Step: 12
Training loss: 0.9753870964050293
Validation loss: 1.7778939841895975

Epoch: 6| Step: 13
Training loss: 0.4460503160953522
Validation loss: 1.7690026631919287

Epoch: 477| Step: 0
Training loss: 1.3378565311431885
Validation loss: 1.7325408945801437

Epoch: 6| Step: 1
Training loss: 1.1806163787841797
Validation loss: 1.7714678728452293

Epoch: 6| Step: 2
Training loss: 0.968402624130249
Validation loss: 1.8252777425191735

Epoch: 6| Step: 3
Training loss: 0.9746091961860657
Validation loss: 1.769843683447889

Epoch: 6| Step: 4
Training loss: 0.6587072610855103
Validation loss: 1.810101680858161

Epoch: 6| Step: 5
Training loss: 0.8531042337417603
Validation loss: 1.763890867592186

Epoch: 6| Step: 6
Training loss: 0.7778075337409973
Validation loss: 1.795896848042806

Epoch: 6| Step: 7
Training loss: 1.237750768661499
Validation loss: 1.7711969819120181

Epoch: 6| Step: 8
Training loss: 1.122140645980835
Validation loss: 1.740665602427657

Epoch: 6| Step: 9
Training loss: 1.4856934547424316
Validation loss: 1.8407884464469007

Epoch: 6| Step: 10
Training loss: 0.9106510877609253
Validation loss: 1.8274039965803905

Epoch: 6| Step: 11
Training loss: 0.9511625170707703
Validation loss: 1.8010082731964767

Epoch: 6| Step: 12
Training loss: 1.2914777994155884
Validation loss: 1.8640588483502787

Epoch: 6| Step: 13
Training loss: 1.212695598602295
Validation loss: 1.7891467668676888

Epoch: 478| Step: 0
Training loss: 0.9321639537811279
Validation loss: 1.7765348726703274

Epoch: 6| Step: 1
Training loss: 1.1809760332107544
Validation loss: 1.7954875564062467

Epoch: 6| Step: 2
Training loss: 0.714519739151001
Validation loss: 1.7350884547797583

Epoch: 6| Step: 3
Training loss: 0.8597376346588135
Validation loss: 1.776991307094533

Epoch: 6| Step: 4
Training loss: 0.8655612468719482
Validation loss: 1.8226467447896157

Epoch: 6| Step: 5
Training loss: 0.6226361393928528
Validation loss: 1.7304437647583664

Epoch: 6| Step: 6
Training loss: 1.0261027812957764
Validation loss: 1.8033156189867245

Epoch: 6| Step: 7
Training loss: 1.4546186923980713
Validation loss: 1.7689221020667785

Epoch: 6| Step: 8
Training loss: 0.8590285181999207
Validation loss: 1.731582424973929

Epoch: 6| Step: 9
Training loss: 0.6533114910125732
Validation loss: 1.798650178858029

Epoch: 6| Step: 10
Training loss: 1.3787413835525513
Validation loss: 1.742312365962613

Epoch: 6| Step: 11
Training loss: 1.2702012062072754
Validation loss: 1.7680056633487824

Epoch: 6| Step: 12
Training loss: 1.1136431694030762
Validation loss: 1.7806494889720794

Epoch: 6| Step: 13
Training loss: 1.6289172172546387
Validation loss: 1.729927198861235

Epoch: 479| Step: 0
Training loss: 0.6648187041282654
Validation loss: 1.7209036222068212

Epoch: 6| Step: 1
Training loss: 0.9111922979354858
Validation loss: 1.8442173247696252

Epoch: 6| Step: 2
Training loss: 1.6029138565063477
Validation loss: 1.7838844791535409

Epoch: 6| Step: 3
Training loss: 0.5579520463943481
Validation loss: 1.7643862821722542

Epoch: 6| Step: 4
Training loss: 0.681432843208313
Validation loss: 1.817632943071345

Epoch: 6| Step: 5
Training loss: 0.931996762752533
Validation loss: 1.8071213281282814

Epoch: 6| Step: 6
Training loss: 0.807880163192749
Validation loss: 1.781726074475114

Epoch: 6| Step: 7
Training loss: 1.1415469646453857
Validation loss: 1.7863256572395243

Epoch: 6| Step: 8
Training loss: 0.9563798904418945
Validation loss: 1.8198299536141016

Epoch: 6| Step: 9
Training loss: 1.1595172882080078
Validation loss: 1.788691154090307

Epoch: 6| Step: 10
Training loss: 1.346703290939331
Validation loss: 1.724836023904944

Epoch: 6| Step: 11
Training loss: 1.0696547031402588
Validation loss: 1.7866420758667814

Epoch: 6| Step: 12
Training loss: 1.2247592210769653
Validation loss: 1.7879536536432081

Epoch: 6| Step: 13
Training loss: 0.8052158355712891
Validation loss: 1.7416273432393228

Epoch: 480| Step: 0
Training loss: 0.8728631734848022
Validation loss: 1.8527273772865214

Epoch: 6| Step: 1
Training loss: 0.5118268132209778
Validation loss: 1.7842669974091232

Epoch: 6| Step: 2
Training loss: 0.8160702586174011
Validation loss: 1.8226127419420468

Epoch: 6| Step: 3
Training loss: 0.8713740110397339
Validation loss: 1.7778900297739173

Epoch: 6| Step: 4
Training loss: 0.86200350522995
Validation loss: 1.7666179262181765

Epoch: 6| Step: 5
Training loss: 0.8693035244941711
Validation loss: 1.7687252452296596

Epoch: 6| Step: 6
Training loss: 1.2166810035705566
Validation loss: 1.7815697680237472

Epoch: 6| Step: 7
Training loss: 0.9605680704116821
Validation loss: 1.791099650885469

Epoch: 6| Step: 8
Training loss: 1.4262545108795166
Validation loss: 1.8432797219163628

Epoch: 6| Step: 9
Training loss: 1.2225475311279297
Validation loss: 1.8113978037270166

Epoch: 6| Step: 10
Training loss: 1.4091331958770752
Validation loss: 1.8116433158997567

Epoch: 6| Step: 11
Training loss: 0.9639949798583984
Validation loss: 1.7837361148608628

Epoch: 6| Step: 12
Training loss: 1.0383299589157104
Validation loss: 1.7382922390455842

Epoch: 6| Step: 13
Training loss: 0.7981210350990295
Validation loss: 1.7566697392412411

Epoch: 481| Step: 0
Training loss: 1.227229356765747
Validation loss: 1.764318771259759

Epoch: 6| Step: 1
Training loss: 1.1914007663726807
Validation loss: 1.7961134167127712

Epoch: 6| Step: 2
Training loss: 1.145345687866211
Validation loss: 1.845141335200238

Epoch: 6| Step: 3
Training loss: 1.4203577041625977
Validation loss: 1.7508869530052267

Epoch: 6| Step: 4
Training loss: 2.0780413150787354
Validation loss: 1.7460941806916268

Epoch: 6| Step: 5
Training loss: 0.7169511318206787
Validation loss: 1.7751490044337448

Epoch: 6| Step: 6
Training loss: 0.884253740310669
Validation loss: 1.7701378355744064

Epoch: 6| Step: 7
Training loss: 0.8169636726379395
Validation loss: 1.7369728447288595

Epoch: 6| Step: 8
Training loss: 0.6354109048843384
Validation loss: 1.7984176976706392

Epoch: 6| Step: 9
Training loss: 0.8389853239059448
Validation loss: 1.7992912107898342

Epoch: 6| Step: 10
Training loss: 0.9915661215782166
Validation loss: 1.767045674785491

Epoch: 6| Step: 11
Training loss: 0.9693267345428467
Validation loss: 1.7432684334375526

Epoch: 6| Step: 12
Training loss: 0.7191725969314575
Validation loss: 1.7367687712433517

Epoch: 6| Step: 13
Training loss: 0.8308571577072144
Validation loss: 1.7130881451791333

Epoch: 482| Step: 0
Training loss: 0.8521004915237427
Validation loss: 1.7717186494540142

Epoch: 6| Step: 1
Training loss: 1.4540338516235352
Validation loss: 1.7463676160381687

Epoch: 6| Step: 2
Training loss: 1.2072135210037231
Validation loss: 1.8035854293454079

Epoch: 6| Step: 3
Training loss: 0.8852440118789673
Validation loss: 1.769755612137497

Epoch: 6| Step: 4
Training loss: 1.0822551250457764
Validation loss: 1.787206244725053

Epoch: 6| Step: 5
Training loss: 1.080377221107483
Validation loss: 1.725038520751461

Epoch: 6| Step: 6
Training loss: 1.9938368797302246
Validation loss: 1.7049235490060621

Epoch: 6| Step: 7
Training loss: 0.8852633237838745
Validation loss: 1.7677532472918112

Epoch: 6| Step: 8
Training loss: 0.6884568929672241
Validation loss: 1.7063304160230903

Epoch: 6| Step: 9
Training loss: 1.0434472560882568
Validation loss: 1.7869038107574626

Epoch: 6| Step: 10
Training loss: 1.007346272468567
Validation loss: 1.7291158847911383

Epoch: 6| Step: 11
Training loss: 0.9457298517227173
Validation loss: 1.8006195073486657

Epoch: 6| Step: 12
Training loss: 1.0047714710235596
Validation loss: 1.7823837726346907

Epoch: 6| Step: 13
Training loss: 0.5674028396606445
Validation loss: 1.825615071481274

Epoch: 483| Step: 0
Training loss: 1.2250607013702393
Validation loss: 1.7947631241172872

Epoch: 6| Step: 1
Training loss: 0.9922987818717957
Validation loss: 1.7834732776047082

Epoch: 6| Step: 2
Training loss: 1.0217366218566895
Validation loss: 1.7993129940443142

Epoch: 6| Step: 3
Training loss: 0.7159353494644165
Validation loss: 1.8239630409466323

Epoch: 6| Step: 4
Training loss: 1.331907033920288
Validation loss: 1.8340642682967647

Epoch: 6| Step: 5
Training loss: 1.0344867706298828
Validation loss: 1.8142369049851612

Epoch: 6| Step: 6
Training loss: 1.2011557817459106
Validation loss: 1.8188761985430153

Epoch: 6| Step: 7
Training loss: 0.4716753661632538
Validation loss: 1.7942953443014493

Epoch: 6| Step: 8
Training loss: 1.2459821701049805
Validation loss: 1.7694484206937975

Epoch: 6| Step: 9
Training loss: 0.871648371219635
Validation loss: 1.7970408008944603

Epoch: 6| Step: 10
Training loss: 1.2205257415771484
Validation loss: 1.7471886988609069

Epoch: 6| Step: 11
Training loss: 0.9880812168121338
Validation loss: 1.7485279883107832

Epoch: 6| Step: 12
Training loss: 0.8127686977386475
Validation loss: 1.7198314948748517

Epoch: 6| Step: 13
Training loss: 1.1127800941467285
Validation loss: 1.7739278859989618

Epoch: 484| Step: 0
Training loss: 1.0464082956314087
Validation loss: 1.7797341039103847

Epoch: 6| Step: 1
Training loss: 1.0986517667770386
Validation loss: 1.8069148858388264

Epoch: 6| Step: 2
Training loss: 1.3703304529190063
Validation loss: 1.815653839418965

Epoch: 6| Step: 3
Training loss: 1.2242859601974487
Validation loss: 1.8076534835241174

Epoch: 6| Step: 4
Training loss: 0.6891111135482788
Validation loss: 1.7351563899747786

Epoch: 6| Step: 5
Training loss: 1.0268802642822266
Validation loss: 1.769477416110295

Epoch: 6| Step: 6
Training loss: 0.7783301472663879
Validation loss: 1.761353442745824

Epoch: 6| Step: 7
Training loss: 1.0139687061309814
Validation loss: 1.764825585067913

Epoch: 6| Step: 8
Training loss: 1.245848536491394
Validation loss: 1.77667369381074

Epoch: 6| Step: 9
Training loss: 0.6943739652633667
Validation loss: 1.7817995817430559

Epoch: 6| Step: 10
Training loss: 0.77503502368927
Validation loss: 1.7461326006920106

Epoch: 6| Step: 11
Training loss: 1.295854091644287
Validation loss: 1.7803022938389932

Epoch: 6| Step: 12
Training loss: 0.7943059206008911
Validation loss: 1.7575255811855357

Epoch: 6| Step: 13
Training loss: 1.7025119066238403
Validation loss: 1.8177914593809394

Epoch: 485| Step: 0
Training loss: 0.9585498571395874
Validation loss: 1.8210000043274255

Epoch: 6| Step: 1
Training loss: 0.8385738134384155
Validation loss: 1.7778337693983508

Epoch: 6| Step: 2
Training loss: 1.0956275463104248
Validation loss: 1.776412885676148

Epoch: 6| Step: 3
Training loss: 1.3423075675964355
Validation loss: 1.7520803097755677

Epoch: 6| Step: 4
Training loss: 0.7089216709136963
Validation loss: 1.811833370116449

Epoch: 6| Step: 5
Training loss: 1.1152373552322388
Validation loss: 1.8122285386567474

Epoch: 6| Step: 6
Training loss: 0.9726275205612183
Validation loss: 1.801938945247281

Epoch: 6| Step: 7
Training loss: 1.0063512325286865
Validation loss: 1.7348137260765157

Epoch: 6| Step: 8
Training loss: 1.2043405771255493
Validation loss: 1.8401500614740516

Epoch: 6| Step: 9
Training loss: 1.1503854990005493
Validation loss: 1.7832704487667288

Epoch: 6| Step: 10
Training loss: 0.7576911449432373
Validation loss: 1.7502534966314993

Epoch: 6| Step: 11
Training loss: 1.029458999633789
Validation loss: 1.8164612516280143

Epoch: 6| Step: 12
Training loss: 0.8095014691352844
Validation loss: 1.7832099814568796

Epoch: 6| Step: 13
Training loss: 0.7063696980476379
Validation loss: 1.7443689941078104

Epoch: 486| Step: 0
Training loss: 0.6430135369300842
Validation loss: 1.8164745530774515

Epoch: 6| Step: 1
Training loss: 0.7643643617630005
Validation loss: 1.798992718419721

Epoch: 6| Step: 2
Training loss: 0.8116671442985535
Validation loss: 1.8079079863845662

Epoch: 6| Step: 3
Training loss: 1.3679686784744263
Validation loss: 1.8404487076626028

Epoch: 6| Step: 4
Training loss: 1.6371533870697021
Validation loss: 1.8609769280238817

Epoch: 6| Step: 5
Training loss: 0.8949036598205566
Validation loss: 1.8375756920024913

Epoch: 6| Step: 6
Training loss: 0.9983625411987305
Validation loss: 1.8350890592862201

Epoch: 6| Step: 7
Training loss: 0.9177376627922058
Validation loss: 1.8160227280791088

Epoch: 6| Step: 8
Training loss: 1.329735517501831
Validation loss: 1.823406018236632

Epoch: 6| Step: 9
Training loss: 1.035215139389038
Validation loss: 1.8568049553901917

Epoch: 6| Step: 10
Training loss: 0.8684446811676025
Validation loss: 1.8165707921469083

Epoch: 6| Step: 11
Training loss: 0.30981773138046265
Validation loss: 1.767149313803642

Epoch: 6| Step: 12
Training loss: 1.1334587335586548
Validation loss: 1.7451694819235033

Epoch: 6| Step: 13
Training loss: 1.7914289236068726
Validation loss: 1.7999962465737456

Epoch: 487| Step: 0
Training loss: 1.3306527137756348
Validation loss: 1.7543528182532198

Epoch: 6| Step: 1
Training loss: 1.463752031326294
Validation loss: 1.79134883675524

Epoch: 6| Step: 2
Training loss: 1.1225559711456299
Validation loss: 1.7208400375099593

Epoch: 6| Step: 3
Training loss: 0.8171764612197876
Validation loss: 1.7852295880676599

Epoch: 6| Step: 4
Training loss: 1.2715635299682617
Validation loss: 1.7438730296268259

Epoch: 6| Step: 5
Training loss: 0.9746599793434143
Validation loss: 1.7391204116164998

Epoch: 6| Step: 6
Training loss: 0.6591933369636536
Validation loss: 1.7860526897573983

Epoch: 6| Step: 7
Training loss: 0.5629225969314575
Validation loss: 1.7933977611603276

Epoch: 6| Step: 8
Training loss: 0.7645419836044312
Validation loss: 1.7929987317772322

Epoch: 6| Step: 9
Training loss: 0.9740662574768066
Validation loss: 1.7964217534629248

Epoch: 6| Step: 10
Training loss: 1.0503695011138916
Validation loss: 1.8036678119372296

Epoch: 6| Step: 11
Training loss: 0.9884370565414429
Validation loss: 1.787997958480671

Epoch: 6| Step: 12
Training loss: 1.008702278137207
Validation loss: 1.8368765756648073

Epoch: 6| Step: 13
Training loss: 1.499779462814331
Validation loss: 1.7633823220447828

Epoch: 488| Step: 0
Training loss: 1.1536595821380615
Validation loss: 1.7948357700019755

Epoch: 6| Step: 1
Training loss: 1.104771614074707
Validation loss: 1.7364555353759437

Epoch: 6| Step: 2
Training loss: 0.9738140106201172
Validation loss: 1.7627312444871472

Epoch: 6| Step: 3
Training loss: 1.0855337381362915
Validation loss: 1.7954658192972983

Epoch: 6| Step: 4
Training loss: 0.7111338973045349
Validation loss: 1.781542101214009

Epoch: 6| Step: 5
Training loss: 1.2773113250732422
Validation loss: 1.7162158540500108

Epoch: 6| Step: 6
Training loss: 1.2733923196792603
Validation loss: 1.8008987211412

Epoch: 6| Step: 7
Training loss: 0.7015794515609741
Validation loss: 1.7700162497899865

Epoch: 6| Step: 8
Training loss: 1.0157355070114136
Validation loss: 1.7754277324163785

Epoch: 6| Step: 9
Training loss: 1.378387689590454
Validation loss: 1.7456421800839004

Epoch: 6| Step: 10
Training loss: 0.8201414346694946
Validation loss: 1.778429103154008

Epoch: 6| Step: 11
Training loss: 0.9748194813728333
Validation loss: 1.7605458395455473

Epoch: 6| Step: 12
Training loss: 0.6280408501625061
Validation loss: 1.7570687519606722

Epoch: 6| Step: 13
Training loss: 1.1749309301376343
Validation loss: 1.8193576592271046

Epoch: 489| Step: 0
Training loss: 0.8640841245651245
Validation loss: 1.7161494275575042

Epoch: 6| Step: 1
Training loss: 1.1558668613433838
Validation loss: 1.8194336916810723

Epoch: 6| Step: 2
Training loss: 0.6700052618980408
Validation loss: 1.7679890214755971

Epoch: 6| Step: 3
Training loss: 0.8854679465293884
Validation loss: 1.7873780009567097

Epoch: 6| Step: 4
Training loss: 1.1439580917358398
Validation loss: 1.8183010893483316

Epoch: 6| Step: 5
Training loss: 0.9229100942611694
Validation loss: 1.803943621215

Epoch: 6| Step: 6
Training loss: 1.0545828342437744
Validation loss: 1.7612594545528453

Epoch: 6| Step: 7
Training loss: 1.3533821105957031
Validation loss: 1.8562320868174236

Epoch: 6| Step: 8
Training loss: 1.264263391494751
Validation loss: 1.8527437371592368

Epoch: 6| Step: 9
Training loss: 1.3587875366210938
Validation loss: 1.8539319653664865

Epoch: 6| Step: 10
Training loss: 1.1760289669036865
Validation loss: 1.8254433152496174

Epoch: 6| Step: 11
Training loss: 0.7676466703414917
Validation loss: 1.8318587926126295

Epoch: 6| Step: 12
Training loss: 1.0532981157302856
Validation loss: 1.8581567810427757

Epoch: 6| Step: 13
Training loss: 1.0036005973815918
Validation loss: 1.8457265925663773

Epoch: 490| Step: 0
Training loss: 1.1655185222625732
Validation loss: 1.8573475986398675

Epoch: 6| Step: 1
Training loss: 1.2886226177215576
Validation loss: 1.8727253598551596

Epoch: 6| Step: 2
Training loss: 0.9042732119560242
Validation loss: 1.7644609981967556

Epoch: 6| Step: 3
Training loss: 0.6136874556541443
Validation loss: 1.7495929989763486

Epoch: 6| Step: 4
Training loss: 1.1367125511169434
Validation loss: 1.8022105565635107

Epoch: 6| Step: 5
Training loss: 1.2115459442138672
Validation loss: 1.6936865372042502

Epoch: 6| Step: 6
Training loss: 1.295154094696045
Validation loss: 1.8048013217987553

Epoch: 6| Step: 7
Training loss: 0.703015148639679
Validation loss: 1.7581370466498918

Epoch: 6| Step: 8
Training loss: 1.1292743682861328
Validation loss: 1.7884263236035582

Epoch: 6| Step: 9
Training loss: 0.5466856956481934
Validation loss: 1.7156366071393412

Epoch: 6| Step: 10
Training loss: 0.9217877388000488
Validation loss: 1.722708623896363

Epoch: 6| Step: 11
Training loss: 1.2151281833648682
Validation loss: 1.775890431096477

Epoch: 6| Step: 12
Training loss: 0.8616379499435425
Validation loss: 1.7538984091051164

Epoch: 6| Step: 13
Training loss: 1.105202078819275
Validation loss: 1.8282240667650778

Epoch: 491| Step: 0
Training loss: 1.1297074556350708
Validation loss: 1.7550564837712113

Epoch: 6| Step: 1
Training loss: 1.0933582782745361
Validation loss: 1.8075584724385252

Epoch: 6| Step: 2
Training loss: 1.0312546491622925
Validation loss: 1.8223455413695304

Epoch: 6| Step: 3
Training loss: 1.1404304504394531
Validation loss: 1.8154333714515931

Epoch: 6| Step: 4
Training loss: 0.7838454842567444
Validation loss: 1.7784713814335484

Epoch: 6| Step: 5
Training loss: 1.3262619972229004
Validation loss: 1.8261185666566253

Epoch: 6| Step: 6
Training loss: 0.8207874298095703
Validation loss: 1.745172046845959

Epoch: 6| Step: 7
Training loss: 0.9822273254394531
Validation loss: 1.7984171272605978

Epoch: 6| Step: 8
Training loss: 0.9209635257720947
Validation loss: 1.7568797962639922

Epoch: 6| Step: 9
Training loss: 1.1377675533294678
Validation loss: 1.8474349155220935

Epoch: 6| Step: 10
Training loss: 0.9201357364654541
Validation loss: 1.7561555254843928

Epoch: 6| Step: 11
Training loss: 0.4870522916316986
Validation loss: 1.8031095932888728

Epoch: 6| Step: 12
Training loss: 1.3901357650756836
Validation loss: 1.789317218206262

Epoch: 6| Step: 13
Training loss: 1.3216410875320435
Validation loss: 1.7869291382451211

Epoch: 492| Step: 0
Training loss: 1.253207802772522
Validation loss: 1.7603139902955742

Epoch: 6| Step: 1
Training loss: 1.2969679832458496
Validation loss: 1.7985503109552528

Epoch: 6| Step: 2
Training loss: 1.0913296937942505
Validation loss: 1.7566953782112367

Epoch: 6| Step: 3
Training loss: 0.8134967684745789
Validation loss: 1.8108040812194988

Epoch: 6| Step: 4
Training loss: 1.176259994506836
Validation loss: 1.785980934737831

Epoch: 6| Step: 5
Training loss: 0.5272002220153809
Validation loss: 1.7413823168764833

Epoch: 6| Step: 6
Training loss: 1.3053983449935913
Validation loss: 1.757441823200513

Epoch: 6| Step: 7
Training loss: 0.8984895348548889
Validation loss: 1.75464004342274

Epoch: 6| Step: 8
Training loss: 0.7250261306762695
Validation loss: 1.7988020104746665

Epoch: 6| Step: 9
Training loss: 0.9292299151420593
Validation loss: 1.7391160508637786

Epoch: 6| Step: 10
Training loss: 0.5476589798927307
Validation loss: 1.7164695570545812

Epoch: 6| Step: 11
Training loss: 1.5412765741348267
Validation loss: 1.7319043861922396

Epoch: 6| Step: 12
Training loss: 0.7969272136688232
Validation loss: 1.8559942796666136

Epoch: 6| Step: 13
Training loss: 1.3406996726989746
Validation loss: 1.8046305397505402

Epoch: 493| Step: 0
Training loss: 1.3492296934127808
Validation loss: 1.811176166739515

Epoch: 6| Step: 1
Training loss: 1.0507653951644897
Validation loss: 1.7654993213633055

Epoch: 6| Step: 2
Training loss: 0.912097156047821
Validation loss: 1.7746440172195435

Epoch: 6| Step: 3
Training loss: 0.7542575001716614
Validation loss: 1.7846752276984594

Epoch: 6| Step: 4
Training loss: 0.6991132497787476
Validation loss: 1.7921135258930985

Epoch: 6| Step: 5
Training loss: 1.1191236972808838
Validation loss: 1.8088190863209386

Epoch: 6| Step: 6
Training loss: 0.7813327312469482
Validation loss: 1.768658664918715

Epoch: 6| Step: 7
Training loss: 0.6254339218139648
Validation loss: 1.8339508143804406

Epoch: 6| Step: 8
Training loss: 0.8207990527153015
Validation loss: 1.708759327088633

Epoch: 6| Step: 9
Training loss: 1.232697606086731
Validation loss: 1.7408900075061347

Epoch: 6| Step: 10
Training loss: 1.0326471328735352
Validation loss: 1.851623527465328

Epoch: 6| Step: 11
Training loss: 0.9818190932273865
Validation loss: 1.7859525424177929

Epoch: 6| Step: 12
Training loss: 1.757964849472046
Validation loss: 1.758476387428981

Epoch: 6| Step: 13
Training loss: 0.8415377140045166
Validation loss: 1.761790781892756

Epoch: 494| Step: 0
Training loss: 0.8394877910614014
Validation loss: 1.747792136284613

Epoch: 6| Step: 1
Training loss: 1.2546544075012207
Validation loss: 1.801489955635481

Epoch: 6| Step: 2
Training loss: 1.3634943962097168
Validation loss: 1.7745052191518969

Epoch: 6| Step: 3
Training loss: 1.0090364217758179
Validation loss: 1.7509616664660874

Epoch: 6| Step: 4
Training loss: 1.2360754013061523
Validation loss: 1.7712123893922376

Epoch: 6| Step: 5
Training loss: 1.5861072540283203
Validation loss: 1.777061927703119

Epoch: 6| Step: 6
Training loss: 1.222840428352356
Validation loss: 1.7618111564267067

Epoch: 6| Step: 7
Training loss: 0.7770525217056274
Validation loss: 1.769183511375099

Epoch: 6| Step: 8
Training loss: 1.0370845794677734
Validation loss: 1.7714334905788462

Epoch: 6| Step: 9
Training loss: 0.7320209741592407
Validation loss: 1.7922828030842606

Epoch: 6| Step: 10
Training loss: 1.1910536289215088
Validation loss: 1.7756152678561468

Epoch: 6| Step: 11
Training loss: 0.9005301594734192
Validation loss: 1.8420843026971305

Epoch: 6| Step: 12
Training loss: 0.7024292945861816
Validation loss: 1.780535916487376

Epoch: 6| Step: 13
Training loss: 0.582399308681488
Validation loss: 1.8894600163223922

Epoch: 495| Step: 0
Training loss: 0.890939474105835
Validation loss: 1.8878062591757825

Epoch: 6| Step: 1
Training loss: 1.0386968851089478
Validation loss: 1.9188925502120808

Epoch: 6| Step: 2
Training loss: 1.043632984161377
Validation loss: 1.8150766408571632

Epoch: 6| Step: 3
Training loss: 0.9681259393692017
Validation loss: 1.845844336735305

Epoch: 6| Step: 4
Training loss: 0.9297454357147217
Validation loss: 1.813673973083496

Epoch: 6| Step: 5
Training loss: 1.4018315076828003
Validation loss: 1.7875349085818055

Epoch: 6| Step: 6
Training loss: 0.723703920841217
Validation loss: 1.784818765937641

Epoch: 6| Step: 7
Training loss: 1.3828288316726685
Validation loss: 1.8281390564416045

Epoch: 6| Step: 8
Training loss: 1.0839388370513916
Validation loss: 1.7901947139411845

Epoch: 6| Step: 9
Training loss: 0.9985727667808533
Validation loss: 1.7813358268430155

Epoch: 6| Step: 10
Training loss: 1.2559620141983032
Validation loss: 1.7855016159754928

Epoch: 6| Step: 11
Training loss: 0.7404546737670898
Validation loss: 1.7639304104671683

Epoch: 6| Step: 12
Training loss: 0.7794378995895386
Validation loss: 1.7469868506154707

Epoch: 6| Step: 13
Training loss: 0.889302670955658
Validation loss: 1.7752268647634855

Epoch: 496| Step: 0
Training loss: 0.7254452109336853
Validation loss: 1.760292906914988

Epoch: 6| Step: 1
Training loss: 1.1477243900299072
Validation loss: 1.7229431483053392

Epoch: 6| Step: 2
Training loss: 0.6935100555419922
Validation loss: 1.7800575802403111

Epoch: 6| Step: 3
Training loss: 0.9088675379753113
Validation loss: 1.7587741985115954

Epoch: 6| Step: 4
Training loss: 0.7034333348274231
Validation loss: 1.8340061774817846

Epoch: 6| Step: 5
Training loss: 0.9846112728118896
Validation loss: 1.7554658741079352

Epoch: 6| Step: 6
Training loss: 1.2863366603851318
Validation loss: 1.784207760646779

Epoch: 6| Step: 7
Training loss: 1.0526018142700195
Validation loss: 1.7883628952887751

Epoch: 6| Step: 8
Training loss: 1.1321256160736084
Validation loss: 1.8573857174124768

Epoch: 6| Step: 9
Training loss: 0.8087201118469238
Validation loss: 1.8503317717582948

Epoch: 6| Step: 10
Training loss: 1.4709537029266357
Validation loss: 1.8387905782268894

Epoch: 6| Step: 11
Training loss: 1.2307841777801514
Validation loss: 1.819941007962791

Epoch: 6| Step: 12
Training loss: 0.8729107975959778
Validation loss: 1.793511918796006

Epoch: 6| Step: 13
Training loss: 1.392222285270691
Validation loss: 1.8374069301030969

Epoch: 497| Step: 0
Training loss: 1.3522377014160156
Validation loss: 1.8354759177853983

Epoch: 6| Step: 1
Training loss: 1.0908228158950806
Validation loss: 1.772258376562467

Epoch: 6| Step: 2
Training loss: 0.9640324711799622
Validation loss: 1.7723211037215365

Epoch: 6| Step: 3
Training loss: 1.0588533878326416
Validation loss: 1.7155976782562912

Epoch: 6| Step: 4
Training loss: 1.517082691192627
Validation loss: 1.7921520356209046

Epoch: 6| Step: 5
Training loss: 0.5048969984054565
Validation loss: 1.7398806592469573

Epoch: 6| Step: 6
Training loss: 0.7920055985450745
Validation loss: 1.7933164053065802

Epoch: 6| Step: 7
Training loss: 1.7346630096435547
Validation loss: 1.7433337088554137

Epoch: 6| Step: 8
Training loss: 0.898836612701416
Validation loss: 1.7297705950275544

Epoch: 6| Step: 9
Training loss: 1.0510003566741943
Validation loss: 1.7543893142413067

Epoch: 6| Step: 10
Training loss: 0.7882850170135498
Validation loss: 1.7910312298805482

Epoch: 6| Step: 11
Training loss: 0.8440299034118652
Validation loss: 1.751036472218011

Epoch: 6| Step: 12
Training loss: 1.0023410320281982
Validation loss: 1.7676422378068328

Epoch: 6| Step: 13
Training loss: 0.8786828517913818
Validation loss: 1.7658298630868234

Epoch: 498| Step: 0
Training loss: 0.7590348720550537
Validation loss: 1.7878349827181907

Epoch: 6| Step: 1
Training loss: 1.0351146459579468
Validation loss: 1.7853310851640598

Epoch: 6| Step: 2
Training loss: 1.6362701654434204
Validation loss: 1.7854152610225063

Epoch: 6| Step: 3
Training loss: 1.2537633180618286
Validation loss: 1.8552643586230535

Epoch: 6| Step: 4
Training loss: 1.184692144393921
Validation loss: 1.7777740083714968

Epoch: 6| Step: 5
Training loss: 1.0116654634475708
Validation loss: 1.7651208472508255

Epoch: 6| Step: 6
Training loss: 0.8166624307632446
Validation loss: 1.8078524220374323

Epoch: 6| Step: 7
Training loss: 0.816057026386261
Validation loss: 1.728870230336343

Epoch: 6| Step: 8
Training loss: 0.8475606441497803
Validation loss: 1.7762564753973356

Epoch: 6| Step: 9
Training loss: 0.9844198226928711
Validation loss: 1.7842722477451447

Epoch: 6| Step: 10
Training loss: 0.9734405875205994
Validation loss: 1.808719600400617

Epoch: 6| Step: 11
Training loss: 0.8581832051277161
Validation loss: 1.8187670502611386

Epoch: 6| Step: 12
Training loss: 0.9175662994384766
Validation loss: 1.7710995584405878

Epoch: 6| Step: 13
Training loss: 0.6655606031417847
Validation loss: 1.7516692094905402

Epoch: 499| Step: 0
Training loss: 0.44598087668418884
Validation loss: 1.8294653559243808

Epoch: 6| Step: 1
Training loss: 1.2927234172821045
Validation loss: 1.7136069677209342

Epoch: 6| Step: 2
Training loss: 1.00299072265625
Validation loss: 1.8101831302847913

Epoch: 6| Step: 3
Training loss: 0.6399267315864563
Validation loss: 1.8674197171324043

Epoch: 6| Step: 4
Training loss: 1.3045783042907715
Validation loss: 1.7431679528246644

Epoch: 6| Step: 5
Training loss: 0.8337639570236206
Validation loss: 1.7268048704311412

Epoch: 6| Step: 6
Training loss: 0.9700348377227783
Validation loss: 1.7231763550030288

Epoch: 6| Step: 7
Training loss: 0.556464433670044
Validation loss: 1.82871885197137

Epoch: 6| Step: 8
Training loss: 2.275705575942993
Validation loss: 1.8094724814097087

Epoch: 6| Step: 9
Training loss: 0.9683972597122192
Validation loss: 1.7668362535456175

Epoch: 6| Step: 10
Training loss: 1.167323112487793
Validation loss: 1.7830187441200338

Epoch: 6| Step: 11
Training loss: 0.620811939239502
Validation loss: 1.7549844172693068

Epoch: 6| Step: 12
Training loss: 0.9816007614135742
Validation loss: 1.7619469678530129

Epoch: 6| Step: 13
Training loss: 1.5661449432373047
Validation loss: 1.7388798677793114

Epoch: 500| Step: 0
Training loss: 0.8118821382522583
Validation loss: 1.740132575394005

Epoch: 6| Step: 1
Training loss: 0.8286288976669312
Validation loss: 1.7853164519033125

Epoch: 6| Step: 2
Training loss: 1.0217835903167725
Validation loss: 1.7810026830242527

Epoch: 6| Step: 3
Training loss: 0.8222990036010742
Validation loss: 1.6853718347446893

Epoch: 6| Step: 4
Training loss: 1.1604504585266113
Validation loss: 1.778752056501245

Epoch: 6| Step: 5
Training loss: 0.9647621512413025
Validation loss: 1.783155950166846

Epoch: 6| Step: 6
Training loss: 1.4156253337860107
Validation loss: 1.8204311478522517

Epoch: 6| Step: 7
Training loss: 1.5813645124435425
Validation loss: 1.805219042685724

Epoch: 6| Step: 8
Training loss: 0.6885433197021484
Validation loss: 1.7562724082700667

Epoch: 6| Step: 9
Training loss: 1.391072154045105
Validation loss: 1.80151000074161

Epoch: 6| Step: 10
Training loss: 0.9201668500900269
Validation loss: 1.7433106847988662

Epoch: 6| Step: 11
Training loss: 0.9393747448921204
Validation loss: 1.7582470550332019

Epoch: 6| Step: 12
Training loss: 1.1272642612457275
Validation loss: 1.8127981834514166

Epoch: 6| Step: 13
Training loss: 0.9107449054718018
Validation loss: 1.8458213588242889

Testing loss: 2.3067326969570585
