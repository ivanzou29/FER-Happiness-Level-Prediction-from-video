Epoch: 1| Step: 0
Training loss: 3.449458599090576
Validation loss: 4.355295460711243

Epoch: 6| Step: 1
Training loss: 3.4568562507629395
Validation loss: 4.349345517414872

Epoch: 6| Step: 2
Training loss: 4.6059370040893555
Validation loss: 4.344699182818013

Epoch: 6| Step: 3
Training loss: 3.9108147621154785
Validation loss: 4.337665098969654

Epoch: 6| Step: 4
Training loss: 4.401676177978516
Validation loss: 4.3315997482627955

Epoch: 6| Step: 5
Training loss: 4.1513824462890625
Validation loss: 4.32252477317728

Epoch: 6| Step: 6
Training loss: 4.679543972015381
Validation loss: 4.318862043401246

Epoch: 6| Step: 7
Training loss: 5.156625747680664
Validation loss: 4.311442739220076

Epoch: 6| Step: 8
Training loss: 5.341571807861328
Validation loss: 4.308280257768528

Epoch: 6| Step: 9
Training loss: 3.3472707271575928
Validation loss: 4.299923712207425

Epoch: 6| Step: 10
Training loss: 3.696601629257202
Validation loss: 4.295911896613337

Epoch: 6| Step: 11
Training loss: 2.514575958251953
Validation loss: 4.29002054788733

Epoch: 6| Step: 12
Training loss: 4.849163055419922
Validation loss: 4.28324334339429

Epoch: 6| Step: 13
Training loss: 4.52046012878418
Validation loss: 4.276392408596572

Epoch: 2| Step: 0
Training loss: 4.817414283752441
Validation loss: 4.273368497048655

Epoch: 6| Step: 1
Training loss: 3.4495091438293457
Validation loss: 4.267334491975846

Epoch: 6| Step: 2
Training loss: 5.008501052856445
Validation loss: 4.261917970513784

Epoch: 6| Step: 3
Training loss: 3.864241361618042
Validation loss: 4.254133532124181

Epoch: 6| Step: 4
Training loss: 4.205392837524414
Validation loss: 4.249635450301632

Epoch: 6| Step: 5
Training loss: 3.957472562789917
Validation loss: 4.244870865216819

Epoch: 6| Step: 6
Training loss: 2.8039255142211914
Validation loss: 4.239371063888714

Epoch: 6| Step: 7
Training loss: 5.0409836769104
Validation loss: 4.233950514947215

Epoch: 6| Step: 8
Training loss: 3.2010207176208496
Validation loss: 4.227511980200327

Epoch: 6| Step: 9
Training loss: 4.29157829284668
Validation loss: 4.221961703351749

Epoch: 6| Step: 10
Training loss: 4.151737213134766
Validation loss: 4.213610833691012

Epoch: 6| Step: 11
Training loss: 4.7188262939453125
Validation loss: 4.210978328540761

Epoch: 6| Step: 12
Training loss: 3.8474349975585938
Validation loss: 4.203682853329566

Epoch: 6| Step: 13
Training loss: 3.030951499938965
Validation loss: 4.198763483314104

Epoch: 3| Step: 0
Training loss: 5.284537315368652
Validation loss: 4.191797248778805

Epoch: 6| Step: 1
Training loss: 3.9863128662109375
Validation loss: 4.186396116851478

Epoch: 6| Step: 2
Training loss: 4.278994083404541
Validation loss: 4.180768507783131

Epoch: 6| Step: 3
Training loss: 4.275525093078613
Validation loss: 4.173100538151239

Epoch: 6| Step: 4
Training loss: 4.7575531005859375
Validation loss: 4.168839885342505

Epoch: 6| Step: 5
Training loss: 3.9982504844665527
Validation loss: 4.163397865910684

Epoch: 6| Step: 6
Training loss: 4.293522357940674
Validation loss: 4.154322711370325

Epoch: 6| Step: 7
Training loss: 2.9984707832336426
Validation loss: 4.1492552090716615

Epoch: 6| Step: 8
Training loss: 4.418020248413086
Validation loss: 4.144131301551737

Epoch: 6| Step: 9
Training loss: 2.873757839202881
Validation loss: 4.134570652438748

Epoch: 6| Step: 10
Training loss: 3.7704436779022217
Validation loss: 4.127835960798366

Epoch: 6| Step: 11
Training loss: 3.491076946258545
Validation loss: 4.120506850622034

Epoch: 6| Step: 12
Training loss: 3.396495819091797
Validation loss: 4.114246681172361

Epoch: 6| Step: 13
Training loss: 3.846649646759033
Validation loss: 4.106743074232532

Epoch: 4| Step: 0
Training loss: 3.491363286972046
Validation loss: 4.10112504548924

Epoch: 6| Step: 1
Training loss: 3.5628623962402344
Validation loss: 4.0911472202629175

Epoch: 6| Step: 2
Training loss: 2.996514320373535
Validation loss: 4.0843512550477055

Epoch: 6| Step: 3
Training loss: 4.104615688323975
Validation loss: 4.080206117322368

Epoch: 6| Step: 4
Training loss: 5.114436626434326
Validation loss: 4.071727373266733

Epoch: 6| Step: 5
Training loss: 4.404318809509277
Validation loss: 4.06484136273784

Epoch: 6| Step: 6
Training loss: 4.379673957824707
Validation loss: 4.059965231085337

Epoch: 6| Step: 7
Training loss: 3.1601967811584473
Validation loss: 4.047895577646071

Epoch: 6| Step: 8
Training loss: 4.591869354248047
Validation loss: 4.043016213242725

Epoch: 6| Step: 9
Training loss: 3.798912763595581
Validation loss: 4.035217715847876

Epoch: 6| Step: 10
Training loss: 4.2823486328125
Validation loss: 4.026849921031665

Epoch: 6| Step: 11
Training loss: 3.627333641052246
Validation loss: 4.015809966671851

Epoch: 6| Step: 12
Training loss: 3.213451385498047
Validation loss: 4.008495999920752

Epoch: 6| Step: 13
Training loss: 3.6278436183929443
Validation loss: 4.002301764744584

Epoch: 5| Step: 0
Training loss: 3.065218925476074
Validation loss: 3.993040725749026

Epoch: 6| Step: 1
Training loss: 3.18784761428833
Validation loss: 3.9868053595225015

Epoch: 6| Step: 2
Training loss: 3.8515231609344482
Validation loss: 3.978384853691183

Epoch: 6| Step: 3
Training loss: 4.519854545593262
Validation loss: 3.9704028842269734

Epoch: 6| Step: 4
Training loss: 3.3728244304656982
Validation loss: 3.959292927095967

Epoch: 6| Step: 5
Training loss: 3.909360647201538
Validation loss: 3.9544675606553272

Epoch: 6| Step: 6
Training loss: 3.8080811500549316
Validation loss: 3.9462197108935286

Epoch: 6| Step: 7
Training loss: 3.9262568950653076
Validation loss: 3.937065960258566

Epoch: 6| Step: 8
Training loss: 3.9155523777008057
Validation loss: 3.930535649740568

Epoch: 6| Step: 9
Training loss: 3.1234211921691895
Validation loss: 3.923689329495994

Epoch: 6| Step: 10
Training loss: 4.415400505065918
Validation loss: 3.916349308465117

Epoch: 6| Step: 11
Training loss: 3.9335570335388184
Validation loss: 3.9046088598107778

Epoch: 6| Step: 12
Training loss: 4.637310028076172
Validation loss: 3.8957041258453042

Epoch: 6| Step: 13
Training loss: 3.1789724826812744
Validation loss: 3.8834455397821244

Epoch: 6| Step: 0
Training loss: 4.103289604187012
Validation loss: 3.8832156529990574

Epoch: 6| Step: 1
Training loss: 4.148577690124512
Validation loss: 3.8705400907865135

Epoch: 6| Step: 2
Training loss: 3.4226930141448975
Validation loss: 3.863964260265391

Epoch: 6| Step: 3
Training loss: 3.8512120246887207
Validation loss: 3.8529188556055867

Epoch: 6| Step: 4
Training loss: 4.113541603088379
Validation loss: 3.8458600762069866

Epoch: 6| Step: 5
Training loss: 3.920804262161255
Validation loss: 3.833851486124018

Epoch: 6| Step: 6
Training loss: 3.0031557083129883
Validation loss: 3.8277897527140956

Epoch: 6| Step: 7
Training loss: 3.465634346008301
Validation loss: 3.820428740593695

Epoch: 6| Step: 8
Training loss: 3.3572659492492676
Validation loss: 3.8102737421630533

Epoch: 6| Step: 9
Training loss: 4.001348495483398
Validation loss: 3.8020447197780816

Epoch: 6| Step: 10
Training loss: 4.636895179748535
Validation loss: 3.7972597460592947

Epoch: 6| Step: 11
Training loss: 3.0584778785705566
Validation loss: 3.7843838968584613

Epoch: 6| Step: 12
Training loss: 3.435948371887207
Validation loss: 3.7731263073541785

Epoch: 6| Step: 13
Training loss: 2.929288148880005
Validation loss: 3.7700461777307654

Epoch: 7| Step: 0
Training loss: 2.563535213470459
Validation loss: 3.7588691813971407

Epoch: 6| Step: 1
Training loss: 3.9184255599975586
Validation loss: 3.7514577040108303

Epoch: 6| Step: 2
Training loss: 3.403785228729248
Validation loss: 3.7433897526033464

Epoch: 6| Step: 3
Training loss: 3.0338897705078125
Validation loss: 3.730763107217768

Epoch: 6| Step: 4
Training loss: 3.2654314041137695
Validation loss: 3.724805844727383

Epoch: 6| Step: 5
Training loss: 4.859206199645996
Validation loss: 3.7162707031414075

Epoch: 6| Step: 6
Training loss: 3.8364195823669434
Validation loss: 3.7061366573456795

Epoch: 6| Step: 7
Training loss: 3.0048110485076904
Validation loss: 3.6982563029053392

Epoch: 6| Step: 8
Training loss: 3.14487361907959
Validation loss: 3.68582494284517

Epoch: 6| Step: 9
Training loss: 3.8340039253234863
Validation loss: 3.677902644680392

Epoch: 6| Step: 10
Training loss: 3.8873190879821777
Validation loss: 3.675084606293709

Epoch: 6| Step: 11
Training loss: 4.0480146408081055
Validation loss: 3.660352478745163

Epoch: 6| Step: 12
Training loss: 3.536299228668213
Validation loss: 3.6530798327538276

Epoch: 6| Step: 13
Training loss: 4.251143455505371
Validation loss: 3.6408069082485732

Epoch: 8| Step: 0
Training loss: 3.5671114921569824
Validation loss: 3.6320370807442615

Epoch: 6| Step: 1
Training loss: 3.474181652069092
Validation loss: 3.6225809820236696

Epoch: 6| Step: 2
Training loss: 3.780134439468384
Validation loss: 3.6154393021778395

Epoch: 6| Step: 3
Training loss: 3.0959274768829346
Validation loss: 3.6009036725567234

Epoch: 6| Step: 4
Training loss: 2.7253429889678955
Validation loss: 3.59138842808303

Epoch: 6| Step: 5
Training loss: 3.8114705085754395
Validation loss: 3.579618610361571

Epoch: 6| Step: 6
Training loss: 3.6555638313293457
Validation loss: 3.5658597407802457

Epoch: 6| Step: 7
Training loss: 3.5414068698883057
Validation loss: 3.5636995428351947

Epoch: 6| Step: 8
Training loss: 3.1108546257019043
Validation loss: 3.550165827556323

Epoch: 6| Step: 9
Training loss: 4.485281944274902
Validation loss: 3.536914502420733

Epoch: 6| Step: 10
Training loss: 3.614058017730713
Validation loss: 3.5352193232505553

Epoch: 6| Step: 11
Training loss: 3.3910179138183594
Validation loss: 3.520008789595737

Epoch: 6| Step: 12
Training loss: 3.6675381660461426
Validation loss: 3.507329712631882

Epoch: 6| Step: 13
Training loss: 2.11299991607666
Validation loss: 3.4961209015179704

Epoch: 9| Step: 0
Training loss: 3.44488787651062
Validation loss: 3.491177717844645

Epoch: 6| Step: 1
Training loss: 2.7786827087402344
Validation loss: 3.476658372468846

Epoch: 6| Step: 2
Training loss: 3.4618709087371826
Validation loss: 3.461902810681251

Epoch: 6| Step: 3
Training loss: 2.929948329925537
Validation loss: 3.451359930858817

Epoch: 6| Step: 4
Training loss: 3.7183914184570312
Validation loss: 3.439772564877746

Epoch: 6| Step: 5
Training loss: 2.3756585121154785
Validation loss: 3.4269497343288955

Epoch: 6| Step: 6
Training loss: 2.9081127643585205
Validation loss: 3.4154385725657144

Epoch: 6| Step: 7
Training loss: 4.1336469650268555
Validation loss: 3.404062904337401

Epoch: 6| Step: 8
Training loss: 3.217440128326416
Validation loss: 3.393066308831656

Epoch: 6| Step: 9
Training loss: 3.860872507095337
Validation loss: 3.3791473296380814

Epoch: 6| Step: 10
Training loss: 2.6631479263305664
Validation loss: 3.372337520763438

Epoch: 6| Step: 11
Training loss: 3.7235913276672363
Validation loss: 3.36104913168056

Epoch: 6| Step: 12
Training loss: 4.056301116943359
Validation loss: 3.347113099149478

Epoch: 6| Step: 13
Training loss: 3.7424497604370117
Validation loss: 3.332609840618667

Epoch: 10| Step: 0
Training loss: 3.498908758163452
Validation loss: 3.3201297072954077

Epoch: 6| Step: 1
Training loss: 3.656825304031372
Validation loss: 3.30971017191487

Epoch: 6| Step: 2
Training loss: 3.185026168823242
Validation loss: 3.2984731556266866

Epoch: 6| Step: 3
Training loss: 2.589430809020996
Validation loss: 3.2868082036254225

Epoch: 6| Step: 4
Training loss: 3.298076629638672
Validation loss: 3.2772057928064817

Epoch: 6| Step: 5
Training loss: 2.6937055587768555
Validation loss: 3.2625222180479314

Epoch: 6| Step: 6
Training loss: 3.108614683151245
Validation loss: 3.252180658360963

Epoch: 6| Step: 7
Training loss: 2.7378008365631104
Validation loss: 3.2416255833000265

Epoch: 6| Step: 8
Training loss: 3.807802438735962
Validation loss: 3.230360769456433

Epoch: 6| Step: 9
Training loss: 2.7807483673095703
Validation loss: 3.218116342380483

Epoch: 6| Step: 10
Training loss: 4.056300640106201
Validation loss: 3.2050956833747124

Epoch: 6| Step: 11
Training loss: 3.245427131652832
Validation loss: 3.1888669203686457

Epoch: 6| Step: 12
Training loss: 3.3197009563446045
Validation loss: 3.173335588106545

Epoch: 6| Step: 13
Training loss: 2.5353028774261475
Validation loss: 3.1670837940708285

Epoch: 11| Step: 0
Training loss: 3.610915184020996
Validation loss: 3.1532260961430048

Epoch: 6| Step: 1
Training loss: 3.760998249053955
Validation loss: 3.1349593259954966

Epoch: 6| Step: 2
Training loss: 2.8981473445892334
Validation loss: 3.1213896966749624

Epoch: 6| Step: 3
Training loss: 3.436727285385132
Validation loss: 3.111967686683901

Epoch: 6| Step: 4
Training loss: 3.767054557800293
Validation loss: 3.0963684128176783

Epoch: 6| Step: 5
Training loss: 2.358609199523926
Validation loss: 3.089042899429157

Epoch: 6| Step: 6
Training loss: 2.9716014862060547
Validation loss: 3.067876039012786

Epoch: 6| Step: 7
Training loss: 3.3422513008117676
Validation loss: 3.0549531085516817

Epoch: 6| Step: 8
Training loss: 2.657752513885498
Validation loss: 3.0538394963869484

Epoch: 6| Step: 9
Training loss: 2.8190102577209473
Validation loss: 3.041205093424807

Epoch: 6| Step: 10
Training loss: 2.8969032764434814
Validation loss: 3.0242656841072986

Epoch: 6| Step: 11
Training loss: 3.6389784812927246
Validation loss: 3.009186760071785

Epoch: 6| Step: 12
Training loss: 2.025392532348633
Validation loss: 2.995840867360433

Epoch: 6| Step: 13
Training loss: 2.6066818237304688
Validation loss: 2.9931763731023318

Epoch: 12| Step: 0
Training loss: 2.3618295192718506
Validation loss: 2.9806879771653043

Epoch: 6| Step: 1
Training loss: 2.9274089336395264
Validation loss: 2.96721980392292

Epoch: 6| Step: 2
Training loss: 3.7611777782440186
Validation loss: 2.960721992677258

Epoch: 6| Step: 3
Training loss: 3.495380401611328
Validation loss: 2.948642305148545

Epoch: 6| Step: 4
Training loss: 3.6636133193969727
Validation loss: 2.9333678368599183

Epoch: 6| Step: 5
Training loss: 2.8724918365478516
Validation loss: 2.926996756625432

Epoch: 6| Step: 6
Training loss: 2.9038538932800293
Validation loss: 2.9134319956584642

Epoch: 6| Step: 7
Training loss: 3.0207622051239014
Validation loss: 2.8989511202740412

Epoch: 6| Step: 8
Training loss: 3.295285224914551
Validation loss: 2.882822508453041

Epoch: 6| Step: 9
Training loss: 2.333852529525757
Validation loss: 2.87488232633119

Epoch: 6| Step: 10
Training loss: 1.9105796813964844
Validation loss: 2.8675807906735327

Epoch: 6| Step: 11
Training loss: 3.147334575653076
Validation loss: 2.8451598741674937

Epoch: 6| Step: 12
Training loss: 2.59799861907959
Validation loss: 2.8298677347039662

Epoch: 6| Step: 13
Training loss: 3.0304455757141113
Validation loss: 2.824551782300395

Epoch: 13| Step: 0
Training loss: 3.613101005554199
Validation loss: 2.8004864467087613

Epoch: 6| Step: 1
Training loss: 2.4119622707366943
Validation loss: 2.797117858804682

Epoch: 6| Step: 2
Training loss: 2.8692843914031982
Validation loss: 2.7738702579211165

Epoch: 6| Step: 3
Training loss: 2.877681255340576
Validation loss: 2.7643956984243085

Epoch: 6| Step: 4
Training loss: 2.90936279296875
Validation loss: 2.7501610709774877

Epoch: 6| Step: 5
Training loss: 3.308846950531006
Validation loss: 2.7411745440575386

Epoch: 6| Step: 6
Training loss: 2.9709458351135254
Validation loss: 2.7204438076224378

Epoch: 6| Step: 7
Training loss: 2.3603219985961914
Validation loss: 2.7035833302364556

Epoch: 6| Step: 8
Training loss: 2.39370059967041
Validation loss: 2.6964834044056554

Epoch: 6| Step: 9
Training loss: 2.21528959274292
Validation loss: 2.6857022572589178

Epoch: 6| Step: 10
Training loss: 2.5033364295959473
Validation loss: 2.66408267072452

Epoch: 6| Step: 11
Training loss: 3.805610179901123
Validation loss: 2.654732842599192

Epoch: 6| Step: 12
Training loss: 2.7709691524505615
Validation loss: 2.6449248175467215

Epoch: 6| Step: 13
Training loss: 2.693511724472046
Validation loss: 2.631238393886115

Epoch: 14| Step: 0
Training loss: 1.8710191249847412
Validation loss: 2.6157152960377354

Epoch: 6| Step: 1
Training loss: 3.0730996131896973
Validation loss: 2.6118151936479794

Epoch: 6| Step: 2
Training loss: 2.9220082759857178
Validation loss: 2.6005402995694067

Epoch: 6| Step: 3
Training loss: 2.974672317504883
Validation loss: 2.585809676877914

Epoch: 6| Step: 4
Training loss: 2.687906265258789
Validation loss: 2.5676290373648367

Epoch: 6| Step: 5
Training loss: 2.7797765731811523
Validation loss: 2.5533657791793987

Epoch: 6| Step: 6
Training loss: 2.205031156539917
Validation loss: 2.551320473353068

Epoch: 6| Step: 7
Training loss: 2.9464614391326904
Validation loss: 2.5364264929166405

Epoch: 6| Step: 8
Training loss: 3.0002059936523438
Validation loss: 2.5209307875684512

Epoch: 6| Step: 9
Training loss: 3.1934099197387695
Validation loss: 2.5077877685587895

Epoch: 6| Step: 10
Training loss: 1.8548976182937622
Validation loss: 2.4918367503791727

Epoch: 6| Step: 11
Training loss: 3.0067694187164307
Validation loss: 2.4830090051056235

Epoch: 6| Step: 12
Training loss: 3.3959453105926514
Validation loss: 2.467214972742142

Epoch: 6| Step: 13
Training loss: 1.8643107414245605
Validation loss: 2.443791630447552

Epoch: 15| Step: 0
Training loss: 2.3214569091796875
Validation loss: 2.448242420791298

Epoch: 6| Step: 1
Training loss: 3.0879220962524414
Validation loss: 2.425570052157166

Epoch: 6| Step: 2
Training loss: 3.177643299102783
Validation loss: 2.4285901977169897

Epoch: 6| Step: 3
Training loss: 2.3715338706970215
Validation loss: 2.4049423253664406

Epoch: 6| Step: 4
Training loss: 2.7174670696258545
Validation loss: 2.3989974683330906

Epoch: 6| Step: 5
Training loss: 2.387286424636841
Validation loss: 2.3776980292412544

Epoch: 6| Step: 6
Training loss: 2.970862627029419
Validation loss: 2.377044427779413

Epoch: 6| Step: 7
Training loss: 2.577577829360962
Validation loss: 2.360344684252175

Epoch: 6| Step: 8
Training loss: 2.4523229598999023
Validation loss: 2.3524072836804133

Epoch: 6| Step: 9
Training loss: 2.68988037109375
Validation loss: 2.3437502461095012

Epoch: 6| Step: 10
Training loss: 2.369312286376953
Validation loss: 2.34579562628141

Epoch: 6| Step: 11
Training loss: 2.362358331680298
Validation loss: 2.324375388442829

Epoch: 6| Step: 12
Training loss: 2.9647626876831055
Validation loss: 2.322774041083551

Epoch: 6| Step: 13
Training loss: 2.2983901500701904
Validation loss: 2.3196604867135324

Epoch: 16| Step: 0
Training loss: 3.0972092151641846
Validation loss: 2.314115680674071

Epoch: 6| Step: 1
Training loss: 3.1021134853363037
Validation loss: 2.3050756915923087

Epoch: 6| Step: 2
Training loss: 3.1342525482177734
Validation loss: 2.290062969730746

Epoch: 6| Step: 3
Training loss: 1.972883939743042
Validation loss: 2.2796230264889297

Epoch: 6| Step: 4
Training loss: 1.5859450101852417
Validation loss: 2.2874190550978466

Epoch: 6| Step: 5
Training loss: 3.1240458488464355
Validation loss: 2.266884949899489

Epoch: 6| Step: 6
Training loss: 1.8605667352676392
Validation loss: 2.248234341221471

Epoch: 6| Step: 7
Training loss: 1.5753291845321655
Validation loss: 2.2574215858213362

Epoch: 6| Step: 8
Training loss: 2.9264488220214844
Validation loss: 2.2473846353510374

Epoch: 6| Step: 9
Training loss: 2.4900333881378174
Validation loss: 2.242514248817198

Epoch: 6| Step: 10
Training loss: 3.0737504959106445
Validation loss: 2.227107645362936

Epoch: 6| Step: 11
Training loss: 2.6693367958068848
Validation loss: 2.2217764341703026

Epoch: 6| Step: 12
Training loss: 2.6632673740386963
Validation loss: 2.22939064938535

Epoch: 6| Step: 13
Training loss: 2.162916660308838
Validation loss: 2.2244717100615143

Epoch: 17| Step: 0
Training loss: 2.3500492572784424
Validation loss: 2.214237459244267

Epoch: 6| Step: 1
Training loss: 2.3234848976135254
Validation loss: 2.2139766011186826

Epoch: 6| Step: 2
Training loss: 2.269564628601074
Validation loss: 2.20735691952449

Epoch: 6| Step: 3
Training loss: 3.411547899246216
Validation loss: 2.1962301449109147

Epoch: 6| Step: 4
Training loss: 2.607847213745117
Validation loss: 2.1903559033588698

Epoch: 6| Step: 5
Training loss: 2.1023545265197754
Validation loss: 2.1880774010894117

Epoch: 6| Step: 6
Training loss: 2.8175711631774902
Validation loss: 2.1939661067019225

Epoch: 6| Step: 7
Training loss: 2.679267406463623
Validation loss: 2.179094642721197

Epoch: 6| Step: 8
Training loss: 2.2563486099243164
Validation loss: 2.1685124930515083

Epoch: 6| Step: 9
Training loss: 2.084204912185669
Validation loss: 2.1778950127222205

Epoch: 6| Step: 10
Training loss: 2.346731185913086
Validation loss: 2.1820254582230763

Epoch: 6| Step: 11
Training loss: 2.7734038829803467
Validation loss: 2.167782788635582

Epoch: 6| Step: 12
Training loss: 2.480224132537842
Validation loss: 2.1509786344343618

Epoch: 6| Step: 13
Training loss: 2.4592885971069336
Validation loss: 2.1486024318202848

Epoch: 18| Step: 0
Training loss: 2.6802172660827637
Validation loss: 2.1588291660431893

Epoch: 6| Step: 1
Training loss: 2.7054810523986816
Validation loss: 2.1530083533256286

Epoch: 6| Step: 2
Training loss: 2.120144844055176
Validation loss: 2.1470864267759424

Epoch: 6| Step: 3
Training loss: 2.2609684467315674
Validation loss: 2.148722158965244

Epoch: 6| Step: 4
Training loss: 1.8428744077682495
Validation loss: 2.155358801605881

Epoch: 6| Step: 5
Training loss: 2.832094669342041
Validation loss: 2.1484872730829383

Epoch: 6| Step: 6
Training loss: 2.7365951538085938
Validation loss: 2.1459532732604654

Epoch: 6| Step: 7
Training loss: 2.6327438354492188
Validation loss: 2.126680483100235

Epoch: 6| Step: 8
Training loss: 2.3723292350769043
Validation loss: 2.153396539790656

Epoch: 6| Step: 9
Training loss: 2.021167516708374
Validation loss: 2.142369580525224

Epoch: 6| Step: 10
Training loss: 2.69736909866333
Validation loss: 2.1276458694088842

Epoch: 6| Step: 11
Training loss: 2.6848948001861572
Validation loss: 2.1322153332412883

Epoch: 6| Step: 12
Training loss: 2.4502391815185547
Validation loss: 2.1350685037592405

Epoch: 6| Step: 13
Training loss: 2.537346839904785
Validation loss: 2.125743386565998

Epoch: 19| Step: 0
Training loss: 3.341543197631836
Validation loss: 2.1399444418568767

Epoch: 6| Step: 1
Training loss: 2.6911497116088867
Validation loss: 2.1329467347873154

Epoch: 6| Step: 2
Training loss: 2.872006416320801
Validation loss: 2.1358189095732985

Epoch: 6| Step: 3
Training loss: 2.8683743476867676
Validation loss: 2.118299489380211

Epoch: 6| Step: 4
Training loss: 2.409076452255249
Validation loss: 2.1281458818784325

Epoch: 6| Step: 5
Training loss: 2.4870502948760986
Validation loss: 2.1357972006643973

Epoch: 6| Step: 6
Training loss: 2.095310688018799
Validation loss: 2.1257179142326437

Epoch: 6| Step: 7
Training loss: 1.894127607345581
Validation loss: 2.1231545940522225

Epoch: 6| Step: 8
Training loss: 2.1765246391296387
Validation loss: 2.1186585862149476

Epoch: 6| Step: 9
Training loss: 2.4892191886901855
Validation loss: 2.1129529014710458

Epoch: 6| Step: 10
Training loss: 2.1346826553344727
Validation loss: 2.1211019254499868

Epoch: 6| Step: 11
Training loss: 2.431992292404175
Validation loss: 2.116198329515355

Epoch: 6| Step: 12
Training loss: 2.3934903144836426
Validation loss: 2.109524328221557

Epoch: 6| Step: 13
Training loss: 1.8850549459457397
Validation loss: 2.1194928948597243

Epoch: 20| Step: 0
Training loss: 3.242732524871826
Validation loss: 2.1229962828338786

Epoch: 6| Step: 1
Training loss: 2.5639326572418213
Validation loss: 2.123574795261506

Epoch: 6| Step: 2
Training loss: 3.2543773651123047
Validation loss: 2.1145019864523285

Epoch: 6| Step: 3
Training loss: 2.3040220737457275
Validation loss: 2.1072011737413305

Epoch: 6| Step: 4
Training loss: 2.518700122833252
Validation loss: 2.1199350715965353

Epoch: 6| Step: 5
Training loss: 2.4381861686706543
Validation loss: 2.115249833753032

Epoch: 6| Step: 6
Training loss: 2.640603542327881
Validation loss: 2.10897687942751

Epoch: 6| Step: 7
Training loss: 2.1491971015930176
Validation loss: 2.1170125622903146

Epoch: 6| Step: 8
Training loss: 2.214169502258301
Validation loss: 2.104557652627268

Epoch: 6| Step: 9
Training loss: 1.644932746887207
Validation loss: 2.110547834827054

Epoch: 6| Step: 10
Training loss: 2.0378878116607666
Validation loss: 2.112402428862869

Epoch: 6| Step: 11
Training loss: 2.057462215423584
Validation loss: 2.1047824608382357

Epoch: 6| Step: 12
Training loss: 2.4520978927612305
Validation loss: 2.1037697920235257

Epoch: 6| Step: 13
Training loss: 3.075509786605835
Validation loss: 2.0988416492298083

Epoch: 21| Step: 0
Training loss: 2.2369983196258545
Validation loss: 2.112116749568652

Epoch: 6| Step: 1
Training loss: 1.610083818435669
Validation loss: 2.1022284800006497

Epoch: 6| Step: 2
Training loss: 2.2757270336151123
Validation loss: 2.0992281501011183

Epoch: 6| Step: 3
Training loss: 2.6057562828063965
Validation loss: 2.1152625468469437

Epoch: 6| Step: 4
Training loss: 2.1542999744415283
Validation loss: 2.1121019855622323

Epoch: 6| Step: 5
Training loss: 2.717069625854492
Validation loss: 2.1084795151987383

Epoch: 6| Step: 6
Training loss: 2.7360429763793945
Validation loss: 2.104618086609789

Epoch: 6| Step: 7
Training loss: 2.2613112926483154
Validation loss: 2.1084396018776843

Epoch: 6| Step: 8
Training loss: 1.920485258102417
Validation loss: 2.110447092722821

Epoch: 6| Step: 9
Training loss: 2.599945545196533
Validation loss: 2.1127572367268224

Epoch: 6| Step: 10
Training loss: 2.485255241394043
Validation loss: 2.1015125859168267

Epoch: 6| Step: 11
Training loss: 3.1167850494384766
Validation loss: 2.092813807149087

Epoch: 6| Step: 12
Training loss: 2.8173882961273193
Validation loss: 2.1070747657488753

Epoch: 6| Step: 13
Training loss: 2.8880062103271484
Validation loss: 2.0992820647455033

Epoch: 22| Step: 0
Training loss: 2.902005195617676
Validation loss: 2.0963868710302536

Epoch: 6| Step: 1
Training loss: 2.5854620933532715
Validation loss: 2.0928331882722917

Epoch: 6| Step: 2
Training loss: 2.215014696121216
Validation loss: 2.0854806541114725

Epoch: 6| Step: 3
Training loss: 2.5573811531066895
Validation loss: 2.1121878085597867

Epoch: 6| Step: 4
Training loss: 2.484046459197998
Validation loss: 2.103537849200669

Epoch: 6| Step: 5
Training loss: 1.842532992362976
Validation loss: 2.0904103555986957

Epoch: 6| Step: 6
Training loss: 1.696954369544983
Validation loss: 2.1000166503331994

Epoch: 6| Step: 7
Training loss: 2.331076145172119
Validation loss: 2.10789652024546

Epoch: 6| Step: 8
Training loss: 2.5399246215820312
Validation loss: 2.0992402004939255

Epoch: 6| Step: 9
Training loss: 2.502415180206299
Validation loss: 2.1060938399325133

Epoch: 6| Step: 10
Training loss: 2.358445644378662
Validation loss: 2.0961214368061354

Epoch: 6| Step: 11
Training loss: 2.7683918476104736
Validation loss: 2.104041891713296

Epoch: 6| Step: 12
Training loss: 2.7483081817626953
Validation loss: 2.0973662035439604

Epoch: 6| Step: 13
Training loss: 2.6505227088928223
Validation loss: 2.0982809682046213

Epoch: 23| Step: 0
Training loss: 2.5847673416137695
Validation loss: 2.088924500250047

Epoch: 6| Step: 1
Training loss: 2.716703414916992
Validation loss: 2.1017091197352253

Epoch: 6| Step: 2
Training loss: 2.12845516204834
Validation loss: 2.1020667783675657

Epoch: 6| Step: 3
Training loss: 2.5333714485168457
Validation loss: 2.1076729630911224

Epoch: 6| Step: 4
Training loss: 2.9367499351501465
Validation loss: 2.114410641372845

Epoch: 6| Step: 5
Training loss: 2.097639560699463
Validation loss: 2.089812377447723

Epoch: 6| Step: 6
Training loss: 2.7898800373077393
Validation loss: 2.0962891168491815

Epoch: 6| Step: 7
Training loss: 2.340898036956787
Validation loss: 2.102656905369092

Epoch: 6| Step: 8
Training loss: 2.096090078353882
Validation loss: 2.10753958968706

Epoch: 6| Step: 9
Training loss: 2.7471120357513428
Validation loss: 2.10455842684674

Epoch: 6| Step: 10
Training loss: 2.3699827194213867
Validation loss: 2.1136004796592136

Epoch: 6| Step: 11
Training loss: 1.589329481124878
Validation loss: 2.1077876808822795

Epoch: 6| Step: 12
Training loss: 2.797426223754883
Validation loss: 2.1009641475574945

Epoch: 6| Step: 13
Training loss: 2.317108154296875
Validation loss: 2.0951022230168825

Epoch: 24| Step: 0
Training loss: 2.012730836868286
Validation loss: 2.1128644379236365

Epoch: 6| Step: 1
Training loss: 2.064682960510254
Validation loss: 2.1106175850796443

Epoch: 6| Step: 2
Training loss: 2.004859447479248
Validation loss: 2.1047055439282487

Epoch: 6| Step: 3
Training loss: 2.988461494445801
Validation loss: 2.1119030265397924

Epoch: 6| Step: 4
Training loss: 2.142148733139038
Validation loss: 2.1069631371446835

Epoch: 6| Step: 5
Training loss: 3.2638702392578125
Validation loss: 2.096798582743573

Epoch: 6| Step: 6
Training loss: 3.0457394123077393
Validation loss: 2.096701575863746

Epoch: 6| Step: 7
Training loss: 2.504859447479248
Validation loss: 2.1022396318374144

Epoch: 6| Step: 8
Training loss: 1.8981034755706787
Validation loss: 2.0874212288087413

Epoch: 6| Step: 9
Training loss: 1.4912117719650269
Validation loss: 2.092663695735316

Epoch: 6| Step: 10
Training loss: 2.1391804218292236
Validation loss: 2.097655088670792

Epoch: 6| Step: 11
Training loss: 2.920140266418457
Validation loss: 2.101782052747665

Epoch: 6| Step: 12
Training loss: 2.288297176361084
Validation loss: 2.0957559411243727

Epoch: 6| Step: 13
Training loss: 3.694596290588379
Validation loss: 2.0840880537545807

Epoch: 25| Step: 0
Training loss: 1.4322996139526367
Validation loss: 2.091848768213744

Epoch: 6| Step: 1
Training loss: 2.8617780208587646
Validation loss: 2.0877305435877975

Epoch: 6| Step: 2
Training loss: 2.002565383911133
Validation loss: 2.0852749706596456

Epoch: 6| Step: 3
Training loss: 2.423969030380249
Validation loss: 2.0916290334475938

Epoch: 6| Step: 4
Training loss: 2.148792028427124
Validation loss: 2.091418679042529

Epoch: 6| Step: 5
Training loss: 2.1941661834716797
Validation loss: 2.0949301283846617

Epoch: 6| Step: 6
Training loss: 2.4819092750549316
Validation loss: 2.08656975787173

Epoch: 6| Step: 7
Training loss: 2.5839383602142334
Validation loss: 2.0890417662999963

Epoch: 6| Step: 8
Training loss: 3.081171989440918
Validation loss: 2.087443987528483

Epoch: 6| Step: 9
Training loss: 2.5693392753601074
Validation loss: 2.0989236729119414

Epoch: 6| Step: 10
Training loss: 2.655299186706543
Validation loss: 2.086975597566174

Epoch: 6| Step: 11
Training loss: 2.7657675743103027
Validation loss: 2.0936674738443024

Epoch: 6| Step: 12
Training loss: 2.5227787494659424
Validation loss: 2.0910774200193343

Epoch: 6| Step: 13
Training loss: 2.2961487770080566
Validation loss: 2.0951601254042758

Epoch: 26| Step: 0
Training loss: 2.525684356689453
Validation loss: 2.1074795082051265

Epoch: 6| Step: 1
Training loss: 2.5787997245788574
Validation loss: 2.092928199357884

Epoch: 6| Step: 2
Training loss: 2.8447937965393066
Validation loss: 2.09196557793566

Epoch: 6| Step: 3
Training loss: 2.0856235027313232
Validation loss: 2.0930266687946935

Epoch: 6| Step: 4
Training loss: 2.445866346359253
Validation loss: 2.086245495785949

Epoch: 6| Step: 5
Training loss: 1.9295151233673096
Validation loss: 2.083426372979277

Epoch: 6| Step: 6
Training loss: 3.1640830039978027
Validation loss: 2.071411949332042

Epoch: 6| Step: 7
Training loss: 2.504606246948242
Validation loss: 2.101039908265555

Epoch: 6| Step: 8
Training loss: 2.4218740463256836
Validation loss: 2.0869008315506803

Epoch: 6| Step: 9
Training loss: 2.0829262733459473
Validation loss: 2.0830762001775924

Epoch: 6| Step: 10
Training loss: 2.5903706550598145
Validation loss: 2.0755523827768143

Epoch: 6| Step: 11
Training loss: 2.0622544288635254
Validation loss: 2.0870620255829184

Epoch: 6| Step: 12
Training loss: 2.127208709716797
Validation loss: 2.087528928633659

Epoch: 6| Step: 13
Training loss: 2.502530813217163
Validation loss: 2.08903750552926

Epoch: 27| Step: 0
Training loss: 2.3874363899230957
Validation loss: 2.089901584450917

Epoch: 6| Step: 1
Training loss: 2.2567362785339355
Validation loss: 2.089926600456238

Epoch: 6| Step: 2
Training loss: 2.286100387573242
Validation loss: 2.0688005390987603

Epoch: 6| Step: 3
Training loss: 2.620506525039673
Validation loss: 2.0926483267097065

Epoch: 6| Step: 4
Training loss: 1.9407129287719727
Validation loss: 2.078170322602795

Epoch: 6| Step: 5
Training loss: 2.5648796558380127
Validation loss: 2.0938555412395026

Epoch: 6| Step: 6
Training loss: 1.7117919921875
Validation loss: 2.100924986664967

Epoch: 6| Step: 7
Training loss: 2.500577211380005
Validation loss: 2.0883618964943835

Epoch: 6| Step: 8
Training loss: 2.61808443069458
Validation loss: 2.0840892535383984

Epoch: 6| Step: 9
Training loss: 2.0107200145721436
Validation loss: 2.095642420553392

Epoch: 6| Step: 10
Training loss: 2.232295036315918
Validation loss: 2.0962360366698234

Epoch: 6| Step: 11
Training loss: 2.9287526607513428
Validation loss: 2.092653118154054

Epoch: 6| Step: 12
Training loss: 2.9351577758789062
Validation loss: 2.091255336679438

Epoch: 6| Step: 13
Training loss: 2.8933064937591553
Validation loss: 2.102680642117736

Epoch: 28| Step: 0
Training loss: 2.0639805793762207
Validation loss: 2.1000381310780845

Epoch: 6| Step: 1
Training loss: 2.1644463539123535
Validation loss: 2.098100575067664

Epoch: 6| Step: 2
Training loss: 2.2100272178649902
Validation loss: 2.0892568531856743

Epoch: 6| Step: 3
Training loss: 2.229281425476074
Validation loss: 2.090361323407901

Epoch: 6| Step: 4
Training loss: 2.6348366737365723
Validation loss: 2.088883335872363

Epoch: 6| Step: 5
Training loss: 2.741514205932617
Validation loss: 2.0873433313062115

Epoch: 6| Step: 6
Training loss: 2.1865127086639404
Validation loss: 2.0705304504722677

Epoch: 6| Step: 7
Training loss: 2.317460536956787
Validation loss: 2.078457711845316

Epoch: 6| Step: 8
Training loss: 2.568201780319214
Validation loss: 2.0722732108126403

Epoch: 6| Step: 9
Training loss: 2.3177919387817383
Validation loss: 2.0655133275575537

Epoch: 6| Step: 10
Training loss: 3.343351125717163
Validation loss: 2.0576386759358067

Epoch: 6| Step: 11
Training loss: 2.520251750946045
Validation loss: 2.064976333290018

Epoch: 6| Step: 12
Training loss: 2.2093958854675293
Validation loss: 2.07248931290001

Epoch: 6| Step: 13
Training loss: 2.1415584087371826
Validation loss: 2.070452687560871

Epoch: 29| Step: 0
Training loss: 2.273064613342285
Validation loss: 2.076155311317854

Epoch: 6| Step: 1
Training loss: 2.201178550720215
Validation loss: 2.075100668015019

Epoch: 6| Step: 2
Training loss: 2.2310900688171387
Validation loss: 2.0715096150675127

Epoch: 6| Step: 3
Training loss: 2.3759303092956543
Validation loss: 2.0897287425174507

Epoch: 6| Step: 4
Training loss: 1.8982186317443848
Validation loss: 2.083900716996962

Epoch: 6| Step: 5
Training loss: 2.309600591659546
Validation loss: 2.100710848326324

Epoch: 6| Step: 6
Training loss: 1.945152997970581
Validation loss: 2.0746779685379355

Epoch: 6| Step: 7
Training loss: 2.3709607124328613
Validation loss: 2.0789822250284176

Epoch: 6| Step: 8
Training loss: 2.323037624359131
Validation loss: 2.093506233666533

Epoch: 6| Step: 9
Training loss: 2.3705945014953613
Validation loss: 2.0779810951602076

Epoch: 6| Step: 10
Training loss: 3.7385802268981934
Validation loss: 2.070298610195037

Epoch: 6| Step: 11
Training loss: 3.077322006225586
Validation loss: 2.080069266339784

Epoch: 6| Step: 12
Training loss: 2.1569132804870605
Validation loss: 2.0745477317481913

Epoch: 6| Step: 13
Training loss: 2.236473798751831
Validation loss: 2.076930667764397

Epoch: 30| Step: 0
Training loss: 3.114893674850464
Validation loss: 2.0927865787218978

Epoch: 6| Step: 1
Training loss: 2.697016716003418
Validation loss: 2.0826475620269775

Epoch: 6| Step: 2
Training loss: 2.206324577331543
Validation loss: 2.0853460219598587

Epoch: 6| Step: 3
Training loss: 2.2693686485290527
Validation loss: 2.07069327241631

Epoch: 6| Step: 4
Training loss: 2.3255505561828613
Validation loss: 2.081665095462594

Epoch: 6| Step: 5
Training loss: 2.4546446800231934
Validation loss: 2.0882240597919752

Epoch: 6| Step: 6
Training loss: 2.643838405609131
Validation loss: 2.0748234679622035

Epoch: 6| Step: 7
Training loss: 2.432197093963623
Validation loss: 2.0864321493333384

Epoch: 6| Step: 8
Training loss: 2.628167152404785
Validation loss: 2.0703498060985277

Epoch: 6| Step: 9
Training loss: 1.7275283336639404
Validation loss: 2.0756378148191716

Epoch: 6| Step: 10
Training loss: 2.3627166748046875
Validation loss: 2.104175301008327

Epoch: 6| Step: 11
Training loss: 2.3446640968322754
Validation loss: 2.080930441938421

Epoch: 6| Step: 12
Training loss: 2.2771315574645996
Validation loss: 2.087773899878225

Epoch: 6| Step: 13
Training loss: 1.860148549079895
Validation loss: 2.0823945742781445

Epoch: 31| Step: 0
Training loss: 2.7625818252563477
Validation loss: 2.080612333871985

Epoch: 6| Step: 1
Training loss: 3.2486355304718018
Validation loss: 2.095820812768834

Epoch: 6| Step: 2
Training loss: 1.6815714836120605
Validation loss: 2.0840096422421035

Epoch: 6| Step: 3
Training loss: 2.152205467224121
Validation loss: 2.093072824580695

Epoch: 6| Step: 4
Training loss: 2.268704891204834
Validation loss: 2.1059951679680937

Epoch: 6| Step: 5
Training loss: 2.1403648853302
Validation loss: 2.092186007448422

Epoch: 6| Step: 6
Training loss: 2.654966115951538
Validation loss: 2.098014388033139

Epoch: 6| Step: 7
Training loss: 2.2062642574310303
Validation loss: 2.1037552484902005

Epoch: 6| Step: 8
Training loss: 2.599881172180176
Validation loss: 2.0954141283548005

Epoch: 6| Step: 9
Training loss: 2.7744553089141846
Validation loss: 2.1012323992226714

Epoch: 6| Step: 10
Training loss: 1.88362717628479
Validation loss: 2.105008579069568

Epoch: 6| Step: 11
Training loss: 2.369626045227051
Validation loss: 2.1050096814350416

Epoch: 6| Step: 12
Training loss: 2.2196640968322754
Validation loss: 2.0927075032264955

Epoch: 6| Step: 13
Training loss: 2.6631827354431152
Validation loss: 2.0924522953648723

Epoch: 32| Step: 0
Training loss: 1.8449273109436035
Validation loss: 2.092050701059321

Epoch: 6| Step: 1
Training loss: 2.6697967052459717
Validation loss: 2.0873010953267417

Epoch: 6| Step: 2
Training loss: 2.633068084716797
Validation loss: 2.085585140412854

Epoch: 6| Step: 3
Training loss: 2.465217351913452
Validation loss: 2.0598470216156333

Epoch: 6| Step: 4
Training loss: 2.0853397846221924
Validation loss: 2.086473532902297

Epoch: 6| Step: 5
Training loss: 2.7124783992767334
Validation loss: 2.069575525099231

Epoch: 6| Step: 6
Training loss: 2.220480442047119
Validation loss: 2.0777156532451673

Epoch: 6| Step: 7
Training loss: 2.3879599571228027
Validation loss: 2.0638263123009795

Epoch: 6| Step: 8
Training loss: 2.415168285369873
Validation loss: 2.0733677277001004

Epoch: 6| Step: 9
Training loss: 2.6617441177368164
Validation loss: 2.057299119169994

Epoch: 6| Step: 10
Training loss: 2.2679967880249023
Validation loss: 2.0690723144879906

Epoch: 6| Step: 11
Training loss: 2.023197889328003
Validation loss: 2.0590016431705926

Epoch: 6| Step: 12
Training loss: 2.4067177772521973
Validation loss: 2.0440151358163483

Epoch: 6| Step: 13
Training loss: 2.671023368835449
Validation loss: 2.067467035785798

Epoch: 33| Step: 0
Training loss: 2.8356122970581055
Validation loss: 2.0687242528443694

Epoch: 6| Step: 1
Training loss: 2.4317145347595215
Validation loss: 2.0688586747774513

Epoch: 6| Step: 2
Training loss: 2.008040428161621
Validation loss: 2.0670794825400076

Epoch: 6| Step: 3
Training loss: 2.943575382232666
Validation loss: 2.0595282969936246

Epoch: 6| Step: 4
Training loss: 1.9011600017547607
Validation loss: 2.068554142470001

Epoch: 6| Step: 5
Training loss: 2.54581880569458
Validation loss: 2.060503245681845

Epoch: 6| Step: 6
Training loss: 2.5006017684936523
Validation loss: 2.0698351578045915

Epoch: 6| Step: 7
Training loss: 1.7405136823654175
Validation loss: 2.069973537998815

Epoch: 6| Step: 8
Training loss: 2.812873363494873
Validation loss: 2.0762635764255317

Epoch: 6| Step: 9
Training loss: 2.472409963607788
Validation loss: 2.076248058708765

Epoch: 6| Step: 10
Training loss: 2.1815571784973145
Validation loss: 2.076705248125138

Epoch: 6| Step: 11
Training loss: 2.7864365577697754
Validation loss: 2.0808652472752396

Epoch: 6| Step: 12
Training loss: 1.3568941354751587
Validation loss: 2.0729538343286

Epoch: 6| Step: 13
Training loss: 3.1358630657196045
Validation loss: 2.0844963545440347

Epoch: 34| Step: 0
Training loss: 1.99163818359375
Validation loss: 2.081697961335541

Epoch: 6| Step: 1
Training loss: 2.5311059951782227
Validation loss: 2.076482075516896

Epoch: 6| Step: 2
Training loss: 2.3836841583251953
Validation loss: 2.066903252755442

Epoch: 6| Step: 3
Training loss: 2.514455795288086
Validation loss: 2.065790104609664

Epoch: 6| Step: 4
Training loss: 2.9125940799713135
Validation loss: 2.0778610885784192

Epoch: 6| Step: 5
Training loss: 2.6679444313049316
Validation loss: 2.056971526915027

Epoch: 6| Step: 6
Training loss: 1.8523731231689453
Validation loss: 2.0704463040956886

Epoch: 6| Step: 7
Training loss: 1.6989240646362305
Validation loss: 2.078632499582024

Epoch: 6| Step: 8
Training loss: 2.5193052291870117
Validation loss: 2.0623251661177604

Epoch: 6| Step: 9
Training loss: 1.7561461925506592
Validation loss: 2.0883263541806127

Epoch: 6| Step: 10
Training loss: 2.416806221008301
Validation loss: 2.0710714683737805

Epoch: 6| Step: 11
Training loss: 2.6557562351226807
Validation loss: 2.0647415089350876

Epoch: 6| Step: 12
Training loss: 2.5418033599853516
Validation loss: 2.053899782960133

Epoch: 6| Step: 13
Training loss: 3.056178331375122
Validation loss: 2.06040249716851

Epoch: 35| Step: 0
Training loss: 2.4358129501342773
Validation loss: 2.065238869318398

Epoch: 6| Step: 1
Training loss: 2.9341368675231934
Validation loss: 2.062869894889093

Epoch: 6| Step: 2
Training loss: 2.3509602546691895
Validation loss: 2.0689906894519763

Epoch: 6| Step: 3
Training loss: 2.2021241188049316
Validation loss: 2.0754780359165643

Epoch: 6| Step: 4
Training loss: 2.1831822395324707
Validation loss: 2.0759639150352887

Epoch: 6| Step: 5
Training loss: 2.427368640899658
Validation loss: 2.0600225425535634

Epoch: 6| Step: 6
Training loss: 2.0519626140594482
Validation loss: 2.070838761586015

Epoch: 6| Step: 7
Training loss: 2.245602607727051
Validation loss: 2.0652215250076784

Epoch: 6| Step: 8
Training loss: 2.906548261642456
Validation loss: 2.054061758902765

Epoch: 6| Step: 9
Training loss: 2.5582685470581055
Validation loss: 2.061847033039216

Epoch: 6| Step: 10
Training loss: 1.944197654724121
Validation loss: 2.050840154770882

Epoch: 6| Step: 11
Training loss: 1.718054175376892
Validation loss: 2.0556587967821347

Epoch: 6| Step: 12
Training loss: 2.655024528503418
Validation loss: 2.051048481336204

Epoch: 6| Step: 13
Training loss: 2.5701992511749268
Validation loss: 2.064074352223386

Epoch: 36| Step: 0
Training loss: 2.326491355895996
Validation loss: 2.054479255471178

Epoch: 6| Step: 1
Training loss: 2.2497329711914062
Validation loss: 2.0582460741842947

Epoch: 6| Step: 2
Training loss: 2.44925594329834
Validation loss: 2.069892442354592

Epoch: 6| Step: 3
Training loss: 2.2402944564819336
Validation loss: 2.0617819857853714

Epoch: 6| Step: 4
Training loss: 2.208298444747925
Validation loss: 2.0465502251860914

Epoch: 6| Step: 5
Training loss: 2.018016815185547
Validation loss: 2.061603384633218

Epoch: 6| Step: 6
Training loss: 2.9088501930236816
Validation loss: 2.059806921148813

Epoch: 6| Step: 7
Training loss: 1.862504243850708
Validation loss: 2.0549813496169222

Epoch: 6| Step: 8
Training loss: 2.4780657291412354
Validation loss: 2.0661805342602473

Epoch: 6| Step: 9
Training loss: 2.8480653762817383
Validation loss: 2.0658327764080417

Epoch: 6| Step: 10
Training loss: 2.762260913848877
Validation loss: 2.0455899623132523

Epoch: 6| Step: 11
Training loss: 2.4006664752960205
Validation loss: 2.0628491896455006

Epoch: 6| Step: 12
Training loss: 2.186410903930664
Validation loss: 2.0769855296739967

Epoch: 6| Step: 13
Training loss: 1.7806739807128906
Validation loss: 2.0595129689862652

Epoch: 37| Step: 0
Training loss: 2.065403938293457
Validation loss: 2.062365798540013

Epoch: 6| Step: 1
Training loss: 2.2331366539001465
Validation loss: 2.0425364714796825

Epoch: 6| Step: 2
Training loss: 2.793403148651123
Validation loss: 2.045374225544673

Epoch: 6| Step: 3
Training loss: 1.824899673461914
Validation loss: 2.0681736866633096

Epoch: 6| Step: 4
Training loss: 2.0296812057495117
Validation loss: 2.080833911895752

Epoch: 6| Step: 5
Training loss: 2.621324300765991
Validation loss: 2.0657395201344646

Epoch: 6| Step: 6
Training loss: 2.3550896644592285
Validation loss: 2.0580207404269966

Epoch: 6| Step: 7
Training loss: 2.556089401245117
Validation loss: 2.0732437128661783

Epoch: 6| Step: 8
Training loss: 2.414787530899048
Validation loss: 2.060542773174983

Epoch: 6| Step: 9
Training loss: 1.886991262435913
Validation loss: 2.068243175424555

Epoch: 6| Step: 10
Training loss: 2.85408878326416
Validation loss: 2.0654306334833943

Epoch: 6| Step: 11
Training loss: 2.1996803283691406
Validation loss: 2.0438144642819642

Epoch: 6| Step: 12
Training loss: 2.7089340686798096
Validation loss: 2.0754121452249508

Epoch: 6| Step: 13
Training loss: 2.151583433151245
Validation loss: 2.07662469597273

Epoch: 38| Step: 0
Training loss: 3.0835771560668945
Validation loss: 2.0592131768503497

Epoch: 6| Step: 1
Training loss: 2.458010196685791
Validation loss: 2.073405240171699

Epoch: 6| Step: 2
Training loss: 2.486905336380005
Validation loss: 2.0634217377631896

Epoch: 6| Step: 3
Training loss: 2.1331539154052734
Validation loss: 2.0709850736843642

Epoch: 6| Step: 4
Training loss: 1.9067320823669434
Validation loss: 2.0828357332496235

Epoch: 6| Step: 5
Training loss: 2.1235620975494385
Validation loss: 2.0563660744697816

Epoch: 6| Step: 6
Training loss: 2.104295492172241
Validation loss: 2.064452296944075

Epoch: 6| Step: 7
Training loss: 2.082430362701416
Validation loss: 2.056193810637279

Epoch: 6| Step: 8
Training loss: 1.8315178155899048
Validation loss: 2.0674887754583873

Epoch: 6| Step: 9
Training loss: 2.146904468536377
Validation loss: 2.06038466576607

Epoch: 6| Step: 10
Training loss: 1.8061113357543945
Validation loss: 2.0548937474527667

Epoch: 6| Step: 11
Training loss: 2.813504219055176
Validation loss: 2.0610182759582356

Epoch: 6| Step: 12
Training loss: 3.2284507751464844
Validation loss: 2.0616665758112425

Epoch: 6| Step: 13
Training loss: 2.7810215950012207
Validation loss: 2.0590683260271625

Epoch: 39| Step: 0
Training loss: 2.39638090133667
Validation loss: 2.060815816284508

Epoch: 6| Step: 1
Training loss: 2.302812337875366
Validation loss: 2.0489235898499847

Epoch: 6| Step: 2
Training loss: 1.867154836654663
Validation loss: 2.0532216666847147

Epoch: 6| Step: 3
Training loss: 2.205993890762329
Validation loss: 2.045258484860902

Epoch: 6| Step: 4
Training loss: 3.268115997314453
Validation loss: 2.0631309760514127

Epoch: 6| Step: 5
Training loss: 2.393345832824707
Validation loss: 2.050905873698573

Epoch: 6| Step: 6
Training loss: 2.3319480419158936
Validation loss: 2.055240520866968

Epoch: 6| Step: 7
Training loss: 2.468219518661499
Validation loss: 2.055672319986487

Epoch: 6| Step: 8
Training loss: 2.2537388801574707
Validation loss: 2.0615705008147867

Epoch: 6| Step: 9
Training loss: 2.6190578937530518
Validation loss: 2.0536302494746383

Epoch: 6| Step: 10
Training loss: 2.0144591331481934
Validation loss: 2.0508109318312777

Epoch: 6| Step: 11
Training loss: 2.2856032848358154
Validation loss: 2.037050336919805

Epoch: 6| Step: 12
Training loss: 2.3830106258392334
Validation loss: 2.0505900972632953

Epoch: 6| Step: 13
Training loss: 1.7084895372390747
Validation loss: 2.0547002694940053

Epoch: 40| Step: 0
Training loss: 2.5853471755981445
Validation loss: 2.028865001534903

Epoch: 6| Step: 1
Training loss: 2.6525912284851074
Validation loss: 2.0546861951069166

Epoch: 6| Step: 2
Training loss: 2.0555179119110107
Validation loss: 2.040220375983946

Epoch: 6| Step: 3
Training loss: 1.896003007888794
Validation loss: 2.0512574795753724

Epoch: 6| Step: 4
Training loss: 2.0179057121276855
Validation loss: 2.06947333581986

Epoch: 6| Step: 5
Training loss: 2.172111988067627
Validation loss: 2.047140141969086

Epoch: 6| Step: 6
Training loss: 2.5250906944274902
Validation loss: 2.0592693385257514

Epoch: 6| Step: 7
Training loss: 2.4802989959716797
Validation loss: 2.0536296854736986

Epoch: 6| Step: 8
Training loss: 2.736567735671997
Validation loss: 2.0525742115512973

Epoch: 6| Step: 9
Training loss: 2.737363338470459
Validation loss: 2.060899498642132

Epoch: 6| Step: 10
Training loss: 1.537806510925293
Validation loss: 2.0465660377215316

Epoch: 6| Step: 11
Training loss: 3.0904922485351562
Validation loss: 2.060727555264709

Epoch: 6| Step: 12
Training loss: 2.596571445465088
Validation loss: 2.0560818987507976

Epoch: 6| Step: 13
Training loss: 1.2193034887313843
Validation loss: 2.056947121056177

Epoch: 41| Step: 0
Training loss: 2.4691781997680664
Validation loss: 2.0642868434229205

Epoch: 6| Step: 1
Training loss: 2.4155707359313965
Validation loss: 2.0524617664275633

Epoch: 6| Step: 2
Training loss: 1.943645715713501
Validation loss: 2.054372300383865

Epoch: 6| Step: 3
Training loss: 2.7958993911743164
Validation loss: 2.0502470539462183

Epoch: 6| Step: 4
Training loss: 1.945462703704834
Validation loss: 2.045208651532409

Epoch: 6| Step: 5
Training loss: 2.6955208778381348
Validation loss: 2.048622223638719

Epoch: 6| Step: 6
Training loss: 1.7236528396606445
Validation loss: 2.0560202919026858

Epoch: 6| Step: 7
Training loss: 2.209489583969116
Validation loss: 2.041310623127927

Epoch: 6| Step: 8
Training loss: 2.278435707092285
Validation loss: 2.0429726492974067

Epoch: 6| Step: 9
Training loss: 2.9010214805603027
Validation loss: 2.057648274206346

Epoch: 6| Step: 10
Training loss: 2.137012004852295
Validation loss: 2.045253974135204

Epoch: 6| Step: 11
Training loss: 2.1832292079925537
Validation loss: 2.0331172494478125

Epoch: 6| Step: 12
Training loss: 2.6107728481292725
Validation loss: 2.064221296259152

Epoch: 6| Step: 13
Training loss: 2.598728656768799
Validation loss: 2.0487769624238372

Epoch: 42| Step: 0
Training loss: 2.664916515350342
Validation loss: 2.038590782432146

Epoch: 6| Step: 1
Training loss: 2.3271710872650146
Validation loss: 2.0418377255880706

Epoch: 6| Step: 2
Training loss: 3.05654239654541
Validation loss: 2.04018941105053

Epoch: 6| Step: 3
Training loss: 1.650796890258789
Validation loss: 2.0431735477139874

Epoch: 6| Step: 4
Training loss: 2.6770143508911133
Validation loss: 2.0471311153904086

Epoch: 6| Step: 5
Training loss: 2.583418369293213
Validation loss: 2.027447905591739

Epoch: 6| Step: 6
Training loss: 2.1023848056793213
Validation loss: 2.047098462299634

Epoch: 6| Step: 7
Training loss: 2.1087875366210938
Validation loss: 2.0509488877429756

Epoch: 6| Step: 8
Training loss: 1.837541937828064
Validation loss: 2.042233592720442

Epoch: 6| Step: 9
Training loss: 2.529921531677246
Validation loss: 2.037960111453969

Epoch: 6| Step: 10
Training loss: 2.1898040771484375
Validation loss: 2.050719859779522

Epoch: 6| Step: 11
Training loss: 1.568192958831787
Validation loss: 2.0405152382389193

Epoch: 6| Step: 12
Training loss: 2.451451301574707
Validation loss: 2.036215897529356

Epoch: 6| Step: 13
Training loss: 3.154019832611084
Validation loss: 2.03883030081308

Epoch: 43| Step: 0
Training loss: 1.9614002704620361
Validation loss: 2.034577704245044

Epoch: 6| Step: 1
Training loss: 2.364103078842163
Validation loss: 2.0285374144072175

Epoch: 6| Step: 2
Training loss: 2.2597060203552246
Validation loss: 2.0529276350493073

Epoch: 6| Step: 3
Training loss: 2.717827796936035
Validation loss: 2.030781299837174

Epoch: 6| Step: 4
Training loss: 1.6446902751922607
Validation loss: 2.0068624275986866

Epoch: 6| Step: 5
Training loss: 2.966223955154419
Validation loss: 2.030372747810938

Epoch: 6| Step: 6
Training loss: 2.691230297088623
Validation loss: 2.0340647876903577

Epoch: 6| Step: 7
Training loss: 2.265292167663574
Validation loss: 2.0314360639100433

Epoch: 6| Step: 8
Training loss: 2.7433080673217773
Validation loss: 2.041147070546304

Epoch: 6| Step: 9
Training loss: 2.2883546352386475
Validation loss: 2.027950345828969

Epoch: 6| Step: 10
Training loss: 2.0019073486328125
Validation loss: 2.0302808746214835

Epoch: 6| Step: 11
Training loss: 2.2669363021850586
Validation loss: 2.034552348557339

Epoch: 6| Step: 12
Training loss: 1.8153948783874512
Validation loss: 2.0291393072374406

Epoch: 6| Step: 13
Training loss: 2.4698054790496826
Validation loss: 2.041432305048871

Epoch: 44| Step: 0
Training loss: 2.3772525787353516
Validation loss: 2.030125189852971

Epoch: 6| Step: 1
Training loss: 2.3742763996124268
Validation loss: 2.0373246182677565

Epoch: 6| Step: 2
Training loss: 1.9733715057373047
Validation loss: 2.0384031777740805

Epoch: 6| Step: 3
Training loss: 2.2763772010803223
Validation loss: 2.027227629897415

Epoch: 6| Step: 4
Training loss: 2.9024391174316406
Validation loss: 2.01767308737642

Epoch: 6| Step: 5
Training loss: 2.37227463722229
Validation loss: 2.0211979112317486

Epoch: 6| Step: 6
Training loss: 2.3880200386047363
Validation loss: 2.026432834645753

Epoch: 6| Step: 7
Training loss: 2.5794529914855957
Validation loss: 2.040732035072901

Epoch: 6| Step: 8
Training loss: 2.2736477851867676
Validation loss: 2.0255343170576197

Epoch: 6| Step: 9
Training loss: 2.3561527729034424
Validation loss: 2.0167267732722785

Epoch: 6| Step: 10
Training loss: 1.9050501585006714
Validation loss: 2.012687280613889

Epoch: 6| Step: 11
Training loss: 2.4496700763702393
Validation loss: 2.0181610930350518

Epoch: 6| Step: 12
Training loss: 1.615343451499939
Validation loss: 2.008417824263214

Epoch: 6| Step: 13
Training loss: 2.6023497581481934
Validation loss: 2.005339212315057

Epoch: 45| Step: 0
Training loss: 2.3975260257720947
Validation loss: 2.015482520544401

Epoch: 6| Step: 1
Training loss: 2.3582406044006348
Validation loss: 2.0270955613864365

Epoch: 6| Step: 2
Training loss: 3.167776107788086
Validation loss: 2.0160892778827297

Epoch: 6| Step: 3
Training loss: 1.8338091373443604
Validation loss: 2.006807247797648

Epoch: 6| Step: 4
Training loss: 2.537126064300537
Validation loss: 2.014688435421195

Epoch: 6| Step: 5
Training loss: 2.573958396911621
Validation loss: 2.0039379365982546

Epoch: 6| Step: 6
Training loss: 2.0834054946899414
Validation loss: 2.0136287417463077

Epoch: 6| Step: 7
Training loss: 2.3969719409942627
Validation loss: 2.0081137457201557

Epoch: 6| Step: 8
Training loss: 2.39333176612854
Validation loss: 2.0135282893334665

Epoch: 6| Step: 9
Training loss: 2.340754747390747
Validation loss: 2.0117857892026185

Epoch: 6| Step: 10
Training loss: 2.198525905609131
Validation loss: 2.024655116501675

Epoch: 6| Step: 11
Training loss: 1.854979395866394
Validation loss: 2.0192574865074566

Epoch: 6| Step: 12
Training loss: 2.3926103115081787
Validation loss: 2.02189584829474

Epoch: 6| Step: 13
Training loss: 1.7265490293502808
Validation loss: 2.0139163412073606

Epoch: 46| Step: 0
Training loss: 2.51865816116333
Validation loss: 2.0059428138117634

Epoch: 6| Step: 1
Training loss: 3.131852149963379
Validation loss: 2.011872386419645

Epoch: 6| Step: 2
Training loss: 1.8533580303192139
Validation loss: 2.011821560962226

Epoch: 6| Step: 3
Training loss: 2.0629384517669678
Validation loss: 2.0288297822398524

Epoch: 6| Step: 4
Training loss: 1.8696329593658447
Validation loss: 2.005073592226992

Epoch: 6| Step: 5
Training loss: 2.4526305198669434
Validation loss: 2.018634185996107

Epoch: 6| Step: 6
Training loss: 2.3704261779785156
Validation loss: 2.0064197996611237

Epoch: 6| Step: 7
Training loss: 2.9346108436584473
Validation loss: 2.0308246561276015

Epoch: 6| Step: 8
Training loss: 1.9894472360610962
Validation loss: 1.999939707017714

Epoch: 6| Step: 9
Training loss: 1.9868268966674805
Validation loss: 2.0145643052234443

Epoch: 6| Step: 10
Training loss: 2.2438106536865234
Validation loss: 2.024136654792293

Epoch: 6| Step: 11
Training loss: 2.7294869422912598
Validation loss: 2.0161915594531643

Epoch: 6| Step: 12
Training loss: 2.385751724243164
Validation loss: 2.0025831935226277

Epoch: 6| Step: 13
Training loss: 1.385713815689087
Validation loss: 2.016234778588818

Epoch: 47| Step: 0
Training loss: 2.1600418090820312
Validation loss: 2.015392247066703

Epoch: 6| Step: 1
Training loss: 1.8646397590637207
Validation loss: 2.010648928662782

Epoch: 6| Step: 2
Training loss: 2.844332695007324
Validation loss: 2.0174652812301472

Epoch: 6| Step: 3
Training loss: 2.8321926593780518
Validation loss: 2.000813796956052

Epoch: 6| Step: 4
Training loss: 1.7670199871063232
Validation loss: 2.0141515552356677

Epoch: 6| Step: 5
Training loss: 2.180145263671875
Validation loss: 2.0116313593361967

Epoch: 6| Step: 6
Training loss: 2.6428472995758057
Validation loss: 2.0068323894213607

Epoch: 6| Step: 7
Training loss: 1.5431640148162842
Validation loss: 2.016493151264806

Epoch: 6| Step: 8
Training loss: 2.373013973236084
Validation loss: 2.012274255034744

Epoch: 6| Step: 9
Training loss: 2.3182716369628906
Validation loss: 2.0085364118699105

Epoch: 6| Step: 10
Training loss: 1.9094160795211792
Validation loss: 2.0245049743242163

Epoch: 6| Step: 11
Training loss: 2.888256311416626
Validation loss: 2.029119219831241

Epoch: 6| Step: 12
Training loss: 2.883887767791748
Validation loss: 2.004545518147048

Epoch: 6| Step: 13
Training loss: 2.056522846221924
Validation loss: 1.9872680889662875

Epoch: 48| Step: 0
Training loss: 2.225465774536133
Validation loss: 2.0177938451049147

Epoch: 6| Step: 1
Training loss: 2.7776947021484375
Validation loss: 2.014529828102358

Epoch: 6| Step: 2
Training loss: 2.4112977981567383
Validation loss: 1.9970015428399528

Epoch: 6| Step: 3
Training loss: 2.1713688373565674
Validation loss: 2.0242983448889946

Epoch: 6| Step: 4
Training loss: 2.6115846633911133
Validation loss: 2.008653694583524

Epoch: 6| Step: 5
Training loss: 2.3881988525390625
Validation loss: 2.0109638578148297

Epoch: 6| Step: 6
Training loss: 2.1138880252838135
Validation loss: 2.0056857524379605

Epoch: 6| Step: 7
Training loss: 1.8627285957336426
Validation loss: 2.0035056144960466

Epoch: 6| Step: 8
Training loss: 2.2017624378204346
Validation loss: 2.009446187685895

Epoch: 6| Step: 9
Training loss: 1.4385101795196533
Validation loss: 2.0179647578988025

Epoch: 6| Step: 10
Training loss: 3.3294172286987305
Validation loss: 2.02006559987222

Epoch: 6| Step: 11
Training loss: 2.0970778465270996
Validation loss: 2.00360006542616

Epoch: 6| Step: 12
Training loss: 2.210693359375
Validation loss: 2.019686045185212

Epoch: 6| Step: 13
Training loss: 2.4135353565216064
Validation loss: 2.0098446364043863

Epoch: 49| Step: 0
Training loss: 2.117549419403076
Validation loss: 2.0168913974556872

Epoch: 6| Step: 1
Training loss: 2.762734889984131
Validation loss: 2.00802703057566

Epoch: 6| Step: 2
Training loss: 1.8512967824935913
Validation loss: 2.0123911967841526

Epoch: 6| Step: 3
Training loss: 2.3735721111297607
Validation loss: 2.023847246682772

Epoch: 6| Step: 4
Training loss: 1.9853553771972656
Validation loss: 2.003430638262021

Epoch: 6| Step: 5
Training loss: 2.121107578277588
Validation loss: 2.0079076085039365

Epoch: 6| Step: 6
Training loss: 2.5682554244995117
Validation loss: 1.9958427400999172

Epoch: 6| Step: 7
Training loss: 2.975907802581787
Validation loss: 2.031656639550322

Epoch: 6| Step: 8
Training loss: 1.6323516368865967
Validation loss: 2.006854295730591

Epoch: 6| Step: 9
Training loss: 2.0997977256774902
Validation loss: 2.011050344795309

Epoch: 6| Step: 10
Training loss: 2.6210927963256836
Validation loss: 2.0007450657506145

Epoch: 6| Step: 11
Training loss: 2.0236470699310303
Validation loss: 1.999348391768753

Epoch: 6| Step: 12
Training loss: 2.8483848571777344
Validation loss: 2.0160096050590597

Epoch: 6| Step: 13
Training loss: 2.2525980472564697
Validation loss: 2.0154235657825263

Epoch: 50| Step: 0
Training loss: 2.291935443878174
Validation loss: 2.0073973594173307

Epoch: 6| Step: 1
Training loss: 2.0461487770080566
Validation loss: 2.0060598440067743

Epoch: 6| Step: 2
Training loss: 2.8006362915039062
Validation loss: 2.0009007377009236

Epoch: 6| Step: 3
Training loss: 1.953977346420288
Validation loss: 2.0136308670043945

Epoch: 6| Step: 4
Training loss: 2.7490134239196777
Validation loss: 2.0074989641866376

Epoch: 6| Step: 5
Training loss: 2.5274620056152344
Validation loss: 2.0125424528634674

Epoch: 6| Step: 6
Training loss: 2.9470973014831543
Validation loss: 2.0087608175892986

Epoch: 6| Step: 7
Training loss: 2.252040386199951
Validation loss: 2.0079646738626624

Epoch: 6| Step: 8
Training loss: 2.0108766555786133
Validation loss: 2.0076204858800417

Epoch: 6| Step: 9
Training loss: 2.0979630947113037
Validation loss: 2.011582495063864

Epoch: 6| Step: 10
Training loss: 1.9683696031570435
Validation loss: 2.0190688653658797

Epoch: 6| Step: 11
Training loss: 2.1570916175842285
Validation loss: 2.0153547692042526

Epoch: 6| Step: 12
Training loss: 1.9889434576034546
Validation loss: 2.009142724416589

Epoch: 6| Step: 13
Training loss: 2.2214174270629883
Validation loss: 2.013907633801942

Epoch: 51| Step: 0
Training loss: 2.7712817192077637
Validation loss: 2.004516796399188

Epoch: 6| Step: 1
Training loss: 1.9268007278442383
Validation loss: 2.0083659579676967

Epoch: 6| Step: 2
Training loss: 1.9563370943069458
Validation loss: 2.01789830705171

Epoch: 6| Step: 3
Training loss: 2.387542963027954
Validation loss: 1.9985291111853816

Epoch: 6| Step: 4
Training loss: 2.124812126159668
Validation loss: 1.9980828031416862

Epoch: 6| Step: 5
Training loss: 2.2003042697906494
Validation loss: 2.0013234679416945

Epoch: 6| Step: 6
Training loss: 2.02604603767395
Validation loss: 2.0024982716447566

Epoch: 6| Step: 7
Training loss: 2.5645387172698975
Validation loss: 1.9864341571766844

Epoch: 6| Step: 8
Training loss: 2.263239622116089
Validation loss: 2.00578087247828

Epoch: 6| Step: 9
Training loss: 2.362661361694336
Validation loss: 2.0107566925787155

Epoch: 6| Step: 10
Training loss: 2.2740399837493896
Validation loss: 2.0087189520559003

Epoch: 6| Step: 11
Training loss: 2.5097765922546387
Validation loss: 1.9992530909917687

Epoch: 6| Step: 12
Training loss: 2.1698412895202637
Validation loss: 1.9930751708246046

Epoch: 6| Step: 13
Training loss: 2.5067684650421143
Validation loss: 1.9938228437977452

Epoch: 52| Step: 0
Training loss: 2.5183396339416504
Validation loss: 2.0056972683116956

Epoch: 6| Step: 1
Training loss: 2.4456605911254883
Validation loss: 1.9887393354087748

Epoch: 6| Step: 2
Training loss: 2.492570400238037
Validation loss: 1.9849332122392551

Epoch: 6| Step: 3
Training loss: 1.915536880493164
Validation loss: 1.9840595799107705

Epoch: 6| Step: 4
Training loss: 1.9803308248519897
Validation loss: 1.9953619741624402

Epoch: 6| Step: 5
Training loss: 1.9205031394958496
Validation loss: 1.9960364513499762

Epoch: 6| Step: 6
Training loss: 2.3438782691955566
Validation loss: 1.978626073047679

Epoch: 6| Step: 7
Training loss: 2.451132297515869
Validation loss: 1.991232188799048

Epoch: 6| Step: 8
Training loss: 1.9648172855377197
Validation loss: 2.000475546365143

Epoch: 6| Step: 9
Training loss: 1.8150360584259033
Validation loss: 2.0018376406802925

Epoch: 6| Step: 10
Training loss: 2.2881546020507812
Validation loss: 1.9995506373784875

Epoch: 6| Step: 11
Training loss: 3.1805076599121094
Validation loss: 1.9799455673463884

Epoch: 6| Step: 12
Training loss: 2.6627399921417236
Validation loss: 1.9917405164369972

Epoch: 6| Step: 13
Training loss: 1.965983271598816
Validation loss: 1.9897988098923878

Epoch: 53| Step: 0
Training loss: 1.9813640117645264
Validation loss: 2.005397911994688

Epoch: 6| Step: 1
Training loss: 2.3008103370666504
Validation loss: 2.002479807023079

Epoch: 6| Step: 2
Training loss: 2.9848501682281494
Validation loss: 2.0008573429558867

Epoch: 6| Step: 3
Training loss: 2.214466094970703
Validation loss: 2.0103821959546817

Epoch: 6| Step: 4
Training loss: 1.905168056488037
Validation loss: 1.9975767033074492

Epoch: 6| Step: 5
Training loss: 2.320817470550537
Validation loss: 1.9867302192154752

Epoch: 6| Step: 6
Training loss: 2.5304317474365234
Validation loss: 1.989304281050159

Epoch: 6| Step: 7
Training loss: 2.031897783279419
Validation loss: 1.9896273266884588

Epoch: 6| Step: 8
Training loss: 1.85197913646698
Validation loss: 1.9964001127468642

Epoch: 6| Step: 9
Training loss: 2.9406185150146484
Validation loss: 1.9924249469593007

Epoch: 6| Step: 10
Training loss: 2.3542208671569824
Validation loss: 2.0020242711549163

Epoch: 6| Step: 11
Training loss: 2.1528897285461426
Validation loss: 1.9910543349481398

Epoch: 6| Step: 12
Training loss: 2.2448246479034424
Validation loss: 1.9967758565820672

Epoch: 6| Step: 13
Training loss: 2.1063404083251953
Validation loss: 2.0022591570372223

Epoch: 54| Step: 0
Training loss: 2.2798471450805664
Validation loss: 2.005842234498711

Epoch: 6| Step: 1
Training loss: 2.511023998260498
Validation loss: 2.008711512370776

Epoch: 6| Step: 2
Training loss: 2.9712204933166504
Validation loss: 1.9995594563022736

Epoch: 6| Step: 3
Training loss: 1.879865288734436
Validation loss: 2.0074937805052726

Epoch: 6| Step: 4
Training loss: 2.312133312225342
Validation loss: 1.9947876661054549

Epoch: 6| Step: 5
Training loss: 2.444077491760254
Validation loss: 1.983722597040156

Epoch: 6| Step: 6
Training loss: 2.5139167308807373
Validation loss: 2.0144655358406807

Epoch: 6| Step: 7
Training loss: 2.300562620162964
Validation loss: 2.0084962665393786

Epoch: 6| Step: 8
Training loss: 2.6522538661956787
Validation loss: 2.0042428252517537

Epoch: 6| Step: 9
Training loss: 1.8963829278945923
Validation loss: 2.0027515785668486

Epoch: 6| Step: 10
Training loss: 2.020401954650879
Validation loss: 1.994980994091239

Epoch: 6| Step: 11
Training loss: 2.3992443084716797
Validation loss: 2.0139880744359826

Epoch: 6| Step: 12
Training loss: 1.6661916971206665
Validation loss: 1.998210483981717

Epoch: 6| Step: 13
Training loss: 1.9643548727035522
Validation loss: 2.014954282391456

Epoch: 55| Step: 0
Training loss: 2.653081178665161
Validation loss: 1.9802287329909622

Epoch: 6| Step: 1
Training loss: 1.621018886566162
Validation loss: 1.991292151071692

Epoch: 6| Step: 2
Training loss: 2.5026400089263916
Validation loss: 1.9891459980318624

Epoch: 6| Step: 3
Training loss: 2.257596969604492
Validation loss: 1.9920789939101025

Epoch: 6| Step: 4
Training loss: 2.4754879474639893
Validation loss: 1.987851401811005

Epoch: 6| Step: 5
Training loss: 1.9250155687332153
Validation loss: 1.9992380667758245

Epoch: 6| Step: 6
Training loss: 2.6335320472717285
Validation loss: 1.9894800634794338

Epoch: 6| Step: 7
Training loss: 1.8017055988311768
Validation loss: 1.9926868484866234

Epoch: 6| Step: 8
Training loss: 2.512803792953491
Validation loss: 1.9752134353883806

Epoch: 6| Step: 9
Training loss: 2.1805131435394287
Validation loss: 1.9710398886793403

Epoch: 6| Step: 10
Training loss: 2.406646728515625
Validation loss: 1.9829260508219402

Epoch: 6| Step: 11
Training loss: 2.752700090408325
Validation loss: 1.9889133719987766

Epoch: 6| Step: 12
Training loss: 2.0395684242248535
Validation loss: 1.9732937197531424

Epoch: 6| Step: 13
Training loss: 1.924689769744873
Validation loss: 2.0044468538735503

Epoch: 56| Step: 0
Training loss: 1.7278282642364502
Validation loss: 1.9865763905227825

Epoch: 6| Step: 1
Training loss: 2.750422954559326
Validation loss: 1.9779319635001562

Epoch: 6| Step: 2
Training loss: 2.389683485031128
Validation loss: 1.9870934781207834

Epoch: 6| Step: 3
Training loss: 2.348146438598633
Validation loss: 1.9707139615089662

Epoch: 6| Step: 4
Training loss: 1.6795732975006104
Validation loss: 1.9893294675375826

Epoch: 6| Step: 5
Training loss: 2.4652469158172607
Validation loss: 1.9992342225966915

Epoch: 6| Step: 6
Training loss: 2.188178062438965
Validation loss: 1.9804398936610068

Epoch: 6| Step: 7
Training loss: 2.404006242752075
Validation loss: 1.977608056478603

Epoch: 6| Step: 8
Training loss: 2.4514594078063965
Validation loss: 1.9822652724481398

Epoch: 6| Step: 9
Training loss: 2.0787863731384277
Validation loss: 1.9824303555232223

Epoch: 6| Step: 10
Training loss: 1.7250075340270996
Validation loss: 1.9881751819323468

Epoch: 6| Step: 11
Training loss: 2.0710177421569824
Validation loss: 1.987280543132495

Epoch: 6| Step: 12
Training loss: 2.726923942565918
Validation loss: 1.98022186627952

Epoch: 6| Step: 13
Training loss: 3.1875998973846436
Validation loss: 1.9846854620082404

Epoch: 57| Step: 0
Training loss: 2.1263275146484375
Validation loss: 1.9830758494715537

Epoch: 6| Step: 1
Training loss: 2.1422383785247803
Validation loss: 1.9810625635167605

Epoch: 6| Step: 2
Training loss: 2.1850738525390625
Validation loss: 1.9964205475263699

Epoch: 6| Step: 3
Training loss: 2.0557589530944824
Validation loss: 1.9676715891848329

Epoch: 6| Step: 4
Training loss: 2.191171169281006
Validation loss: 1.9627498157562748

Epoch: 6| Step: 5
Training loss: 2.6034064292907715
Validation loss: 1.978734359946302

Epoch: 6| Step: 6
Training loss: 1.8980894088745117
Validation loss: 1.9908319891140025

Epoch: 6| Step: 7
Training loss: 2.4134984016418457
Validation loss: 1.9771231451342184

Epoch: 6| Step: 8
Training loss: 2.463731527328491
Validation loss: 1.9635620783734065

Epoch: 6| Step: 9
Training loss: 2.5000462532043457
Validation loss: 1.9581094967421664

Epoch: 6| Step: 10
Training loss: 2.0235636234283447
Validation loss: 1.9744424576400428

Epoch: 6| Step: 11
Training loss: 2.236116886138916
Validation loss: 1.9894078905864427

Epoch: 6| Step: 12
Training loss: 2.230842113494873
Validation loss: 1.9753308860204553

Epoch: 6| Step: 13
Training loss: 3.113391876220703
Validation loss: 1.9933755859251945

Epoch: 58| Step: 0
Training loss: 2.370044708251953
Validation loss: 1.9629351938924482

Epoch: 6| Step: 1
Training loss: 1.4885281324386597
Validation loss: 1.9815163714911348

Epoch: 6| Step: 2
Training loss: 2.713744640350342
Validation loss: 1.9705874778891121

Epoch: 6| Step: 3
Training loss: 1.8238310813903809
Validation loss: 1.985430940504997

Epoch: 6| Step: 4
Training loss: 2.123237133026123
Validation loss: 1.9835795843473045

Epoch: 6| Step: 5
Training loss: 2.3612942695617676
Validation loss: 1.9871169867054108

Epoch: 6| Step: 6
Training loss: 1.8131287097930908
Validation loss: 1.983905230799029

Epoch: 6| Step: 7
Training loss: 3.243030548095703
Validation loss: 1.9954471895771642

Epoch: 6| Step: 8
Training loss: 2.4256539344787598
Validation loss: 1.9831646898741364

Epoch: 6| Step: 9
Training loss: 2.0713655948638916
Validation loss: 1.9752080132884364

Epoch: 6| Step: 10
Training loss: 2.974990129470825
Validation loss: 1.9901479316014115

Epoch: 6| Step: 11
Training loss: 2.4303483963012695
Validation loss: 1.9917446310802172

Epoch: 6| Step: 12
Training loss: 2.0115044116973877
Validation loss: 1.9785756782818866

Epoch: 6| Step: 13
Training loss: 1.5422112941741943
Validation loss: 1.9926338605983283

Epoch: 59| Step: 0
Training loss: 2.294060707092285
Validation loss: 1.9928431498107089

Epoch: 6| Step: 1
Training loss: 3.146599769592285
Validation loss: 1.9814552184074157

Epoch: 6| Step: 2
Training loss: 1.7812063694000244
Validation loss: 2.0022194795711066

Epoch: 6| Step: 3
Training loss: 2.869993209838867
Validation loss: 2.010909030514379

Epoch: 6| Step: 4
Training loss: 1.6945815086364746
Validation loss: 2.010864652613158

Epoch: 6| Step: 5
Training loss: 2.349170684814453
Validation loss: 2.0241745441190657

Epoch: 6| Step: 6
Training loss: 2.0304555892944336
Validation loss: 2.0028101128916584

Epoch: 6| Step: 7
Training loss: 3.137641429901123
Validation loss: 2.008777472280687

Epoch: 6| Step: 8
Training loss: 2.7099456787109375
Validation loss: 2.0070164511280675

Epoch: 6| Step: 9
Training loss: 1.586564302444458
Validation loss: 2.021541104521803

Epoch: 6| Step: 10
Training loss: 2.040714740753174
Validation loss: 1.9964117452662478

Epoch: 6| Step: 11
Training loss: 1.7715342044830322
Validation loss: 2.025448379978057

Epoch: 6| Step: 12
Training loss: 1.992447853088379
Validation loss: 2.024530538948633

Epoch: 6| Step: 13
Training loss: 2.42984676361084
Validation loss: 1.9971862531477405

Epoch: 60| Step: 0
Training loss: 2.324228048324585
Validation loss: 2.0258125079575406

Epoch: 6| Step: 1
Training loss: 2.8497297763824463
Validation loss: 2.0030122136556976

Epoch: 6| Step: 2
Training loss: 2.2783851623535156
Validation loss: 2.016293469295707

Epoch: 6| Step: 3
Training loss: 1.3240430355072021
Validation loss: 2.0135259013022146

Epoch: 6| Step: 4
Training loss: 2.4763383865356445
Validation loss: 2.0209860673514743

Epoch: 6| Step: 5
Training loss: 2.1306684017181396
Validation loss: 2.0102632584110385

Epoch: 6| Step: 6
Training loss: 2.5176360607147217
Validation loss: 1.9946658918934483

Epoch: 6| Step: 7
Training loss: 2.4057750701904297
Validation loss: 2.022961437061269

Epoch: 6| Step: 8
Training loss: 2.2762413024902344
Validation loss: 2.016821292138869

Epoch: 6| Step: 9
Training loss: 2.001108169555664
Validation loss: 2.02660265532873

Epoch: 6| Step: 10
Training loss: 2.0846285820007324
Validation loss: 2.0009471601055515

Epoch: 6| Step: 11
Training loss: 1.8937885761260986
Validation loss: 2.0218898814211608

Epoch: 6| Step: 12
Training loss: 2.590895652770996
Validation loss: 2.0083975689385527

Epoch: 6| Step: 13
Training loss: 2.50177001953125
Validation loss: 2.008124279719527

Epoch: 61| Step: 0
Training loss: 2.2339751720428467
Validation loss: 1.9992171077318088

Epoch: 6| Step: 1
Training loss: 1.9164912700653076
Validation loss: 1.999677138943826

Epoch: 6| Step: 2
Training loss: 2.1602654457092285
Validation loss: 2.0121665218824982

Epoch: 6| Step: 3
Training loss: 2.4753921031951904
Validation loss: 2.023434462085847

Epoch: 6| Step: 4
Training loss: 2.346604108810425
Validation loss: 2.0030872514170985

Epoch: 6| Step: 5
Training loss: 2.8293261528015137
Validation loss: 2.0092380944118706

Epoch: 6| Step: 6
Training loss: 2.4475295543670654
Validation loss: 1.9992316384469309

Epoch: 6| Step: 7
Training loss: 2.3157801628112793
Validation loss: 2.0034782194322154

Epoch: 6| Step: 8
Training loss: 1.6767107248306274
Validation loss: 1.993239438661965

Epoch: 6| Step: 9
Training loss: 2.6675806045532227
Validation loss: 2.002174299250367

Epoch: 6| Step: 10
Training loss: 1.9191510677337646
Validation loss: 1.994519313176473

Epoch: 6| Step: 11
Training loss: 2.4738147258758545
Validation loss: 2.0136625074571177

Epoch: 6| Step: 12
Training loss: 1.884530782699585
Validation loss: 1.9833668816474177

Epoch: 6| Step: 13
Training loss: 2.468437671661377
Validation loss: 1.9898551638408373

Epoch: 62| Step: 0
Training loss: 2.2049481868743896
Validation loss: 1.9896413369845318

Epoch: 6| Step: 1
Training loss: 1.9789292812347412
Validation loss: 1.983801511026198

Epoch: 6| Step: 2
Training loss: 2.331784725189209
Validation loss: 2.00972718064503

Epoch: 6| Step: 3
Training loss: 2.1760566234588623
Validation loss: 2.0132794252005954

Epoch: 6| Step: 4
Training loss: 1.2373237609863281
Validation loss: 1.975973339490993

Epoch: 6| Step: 5
Training loss: 2.2524781227111816
Validation loss: 1.9741507089266213

Epoch: 6| Step: 6
Training loss: 2.8605003356933594
Validation loss: 1.9898326781488234

Epoch: 6| Step: 7
Training loss: 2.077392339706421
Validation loss: 2.009431077587989

Epoch: 6| Step: 8
Training loss: 2.0109901428222656
Validation loss: 1.9929761168777302

Epoch: 6| Step: 9
Training loss: 2.0749998092651367
Validation loss: 1.987419601409666

Epoch: 6| Step: 10
Training loss: 2.731962203979492
Validation loss: 1.9938164962235319

Epoch: 6| Step: 11
Training loss: 2.700103759765625
Validation loss: 1.995610426830989

Epoch: 6| Step: 12
Training loss: 2.550124406814575
Validation loss: 2.0069332045893513

Epoch: 6| Step: 13
Training loss: 2.3072526454925537
Validation loss: 1.9992750306283273

Epoch: 63| Step: 0
Training loss: 2.223721504211426
Validation loss: 1.9978615532639206

Epoch: 6| Step: 1
Training loss: 1.820408582687378
Validation loss: 1.9809017335214922

Epoch: 6| Step: 2
Training loss: 2.2162790298461914
Validation loss: 1.9941680918457687

Epoch: 6| Step: 3
Training loss: 2.1474151611328125
Validation loss: 1.988527133900632

Epoch: 6| Step: 4
Training loss: 2.352965831756592
Validation loss: 1.9873025135327411

Epoch: 6| Step: 5
Training loss: 2.0727005004882812
Validation loss: 1.9929588879308393

Epoch: 6| Step: 6
Training loss: 2.73327374458313
Validation loss: 1.992419708159662

Epoch: 6| Step: 7
Training loss: 2.5998165607452393
Validation loss: 1.9869222371808943

Epoch: 6| Step: 8
Training loss: 1.9548728466033936
Validation loss: 1.9872521379942536

Epoch: 6| Step: 9
Training loss: 2.3512184619903564
Validation loss: 1.9839614886109547

Epoch: 6| Step: 10
Training loss: 1.9735713005065918
Validation loss: 1.9919323818657988

Epoch: 6| Step: 11
Training loss: 1.9645907878875732
Validation loss: 1.983175564837712

Epoch: 6| Step: 12
Training loss: 2.1483657360076904
Validation loss: 1.971763518548781

Epoch: 6| Step: 13
Training loss: 3.239374876022339
Validation loss: 1.9776648834187498

Epoch: 64| Step: 0
Training loss: 1.9473671913146973
Validation loss: 1.9923364398300007

Epoch: 6| Step: 1
Training loss: 2.228759288787842
Validation loss: 1.9886109572584911

Epoch: 6| Step: 2
Training loss: 2.9300293922424316
Validation loss: 1.9914051922418738

Epoch: 6| Step: 3
Training loss: 2.371354579925537
Validation loss: 1.9783827092057915

Epoch: 6| Step: 4
Training loss: 2.338383913040161
Validation loss: 2.0009750166246967

Epoch: 6| Step: 5
Training loss: 2.064389944076538
Validation loss: 1.9816412976993028

Epoch: 6| Step: 6
Training loss: 2.222121000289917
Validation loss: 1.994472872826361

Epoch: 6| Step: 7
Training loss: 2.0621840953826904
Validation loss: 2.0126365718021186

Epoch: 6| Step: 8
Training loss: 1.9352059364318848
Validation loss: 2.00200419656692

Epoch: 6| Step: 9
Training loss: 2.5963973999023438
Validation loss: 1.992927014186818

Epoch: 6| Step: 10
Training loss: 2.0750319957733154
Validation loss: 1.9847928400962584

Epoch: 6| Step: 11
Training loss: 2.5427920818328857
Validation loss: 2.012401259073647

Epoch: 6| Step: 12
Training loss: 1.637901782989502
Validation loss: 1.9969998482734925

Epoch: 6| Step: 13
Training loss: 2.83362078666687
Validation loss: 2.0143302691880094

Epoch: 65| Step: 0
Training loss: 2.333148241043091
Validation loss: 2.0168520353173696

Epoch: 6| Step: 1
Training loss: 2.4128339290618896
Validation loss: 2.000022320337193

Epoch: 6| Step: 2
Training loss: 2.4677982330322266
Validation loss: 1.9917480343131608

Epoch: 6| Step: 3
Training loss: 2.2905893325805664
Validation loss: 1.9922591370920981

Epoch: 6| Step: 4
Training loss: 1.847223162651062
Validation loss: 1.9920577233837498

Epoch: 6| Step: 5
Training loss: 1.9871494770050049
Validation loss: 2.0067731539408364

Epoch: 6| Step: 6
Training loss: 2.596360683441162
Validation loss: 2.008119980494181

Epoch: 6| Step: 7
Training loss: 1.9854480028152466
Validation loss: 1.9941235742261332

Epoch: 6| Step: 8
Training loss: 2.702023506164551
Validation loss: 1.9837004215486589

Epoch: 6| Step: 9
Training loss: 2.4679853916168213
Validation loss: 1.9945276347539758

Epoch: 6| Step: 10
Training loss: 2.5485591888427734
Validation loss: 1.9827038216334518

Epoch: 6| Step: 11
Training loss: 2.1286990642547607
Validation loss: 2.0047514579629384

Epoch: 6| Step: 12
Training loss: 1.9513744115829468
Validation loss: 1.993124560643268

Epoch: 6| Step: 13
Training loss: 1.6416155099868774
Validation loss: 1.991685939091508

Epoch: 66| Step: 0
Training loss: 1.9988133907318115
Validation loss: 1.99187332840376

Epoch: 6| Step: 1
Training loss: 2.6123175621032715
Validation loss: 1.998468199083882

Epoch: 6| Step: 2
Training loss: 2.524704933166504
Validation loss: 2.001841850178216

Epoch: 6| Step: 3
Training loss: 2.245692253112793
Validation loss: 1.9917233105628722

Epoch: 6| Step: 4
Training loss: 2.2037100791931152
Validation loss: 1.9821638509791384

Epoch: 6| Step: 5
Training loss: 1.7057411670684814
Validation loss: 1.9780660701054398

Epoch: 6| Step: 6
Training loss: 2.244880199432373
Validation loss: 1.9852415771894558

Epoch: 6| Step: 7
Training loss: 2.8602075576782227
Validation loss: 1.9822597529298516

Epoch: 6| Step: 8
Training loss: 1.3414311408996582
Validation loss: 1.9819339180505404

Epoch: 6| Step: 9
Training loss: 2.726397752761841
Validation loss: 1.9886243625353741

Epoch: 6| Step: 10
Training loss: 2.3878023624420166
Validation loss: 1.9935205239121632

Epoch: 6| Step: 11
Training loss: 1.8693782091140747
Validation loss: 1.990153499828872

Epoch: 6| Step: 12
Training loss: 2.4380459785461426
Validation loss: 1.9910735468710623

Epoch: 6| Step: 13
Training loss: 2.1438355445861816
Validation loss: 1.9932882837069932

Epoch: 67| Step: 0
Training loss: 2.2483038902282715
Validation loss: 1.9952538154458488

Epoch: 6| Step: 1
Training loss: 1.7784520387649536
Validation loss: 1.9719868783027894

Epoch: 6| Step: 2
Training loss: 2.344212293624878
Validation loss: 1.9788475254530549

Epoch: 6| Step: 3
Training loss: 2.0319719314575195
Validation loss: 1.9805915522319015

Epoch: 6| Step: 4
Training loss: 2.8951518535614014
Validation loss: 1.983666750692552

Epoch: 6| Step: 5
Training loss: 2.6625638008117676
Validation loss: 1.9823931673521638

Epoch: 6| Step: 6
Training loss: 2.433089256286621
Validation loss: 1.976828864825669

Epoch: 6| Step: 7
Training loss: 2.1674132347106934
Validation loss: 1.985410331397928

Epoch: 6| Step: 8
Training loss: 2.0844156742095947
Validation loss: 1.9706148960257088

Epoch: 6| Step: 9
Training loss: 2.090998649597168
Validation loss: 1.9710471104550105

Epoch: 6| Step: 10
Training loss: 2.230264902114868
Validation loss: 1.983182055975801

Epoch: 6| Step: 11
Training loss: 2.249864339828491
Validation loss: 1.9554344736119753

Epoch: 6| Step: 12
Training loss: 1.8621759414672852
Validation loss: 1.978377321714996

Epoch: 6| Step: 13
Training loss: 2.6329667568206787
Validation loss: 1.9822028913805563

Epoch: 68| Step: 0
Training loss: 2.8911099433898926
Validation loss: 1.9681080387484642

Epoch: 6| Step: 1
Training loss: 2.4335432052612305
Validation loss: 1.9802846780387304

Epoch: 6| Step: 2
Training loss: 2.0793704986572266
Validation loss: 1.9867475878807805

Epoch: 6| Step: 3
Training loss: 2.7540431022644043
Validation loss: 1.9639322078356178

Epoch: 6| Step: 4
Training loss: 1.866434931755066
Validation loss: 1.9644917647043865

Epoch: 6| Step: 5
Training loss: 2.1176834106445312
Validation loss: 1.96229294038588

Epoch: 6| Step: 6
Training loss: 1.6117534637451172
Validation loss: 1.9668825031608663

Epoch: 6| Step: 7
Training loss: 2.7226881980895996
Validation loss: 1.9582934994851389

Epoch: 6| Step: 8
Training loss: 2.298187732696533
Validation loss: 1.972642053839981

Epoch: 6| Step: 9
Training loss: 2.1535286903381348
Validation loss: 1.972927411397298

Epoch: 6| Step: 10
Training loss: 2.238736391067505
Validation loss: 1.984274225850259

Epoch: 6| Step: 11
Training loss: 1.6512742042541504
Validation loss: 1.978144068871775

Epoch: 6| Step: 12
Training loss: 2.6401968002319336
Validation loss: 1.9532589732959706

Epoch: 6| Step: 13
Training loss: 1.787148356437683
Validation loss: 1.9713904062906902

Epoch: 69| Step: 0
Training loss: 2.2060680389404297
Validation loss: 1.9526667107817948

Epoch: 6| Step: 1
Training loss: 1.8200631141662598
Validation loss: 1.949090205213075

Epoch: 6| Step: 2
Training loss: 1.8809242248535156
Validation loss: 1.9832813650049188

Epoch: 6| Step: 3
Training loss: 1.9400653839111328
Validation loss: 1.9645826893468057

Epoch: 6| Step: 4
Training loss: 2.5579946041107178
Validation loss: 1.9824590567619569

Epoch: 6| Step: 5
Training loss: 2.3578343391418457
Validation loss: 1.97854309697305

Epoch: 6| Step: 6
Training loss: 2.4456663131713867
Validation loss: 1.9785686308337795

Epoch: 6| Step: 7
Training loss: 2.802806854248047
Validation loss: 1.964774085629371

Epoch: 6| Step: 8
Training loss: 1.6604092121124268
Validation loss: 1.9663409110038512

Epoch: 6| Step: 9
Training loss: 1.9945162534713745
Validation loss: 1.9728796200085712

Epoch: 6| Step: 10
Training loss: 2.755507707595825
Validation loss: 1.9719352863168205

Epoch: 6| Step: 11
Training loss: 2.46461820602417
Validation loss: 1.957324307451966

Epoch: 6| Step: 12
Training loss: 2.3473081588745117
Validation loss: 1.971398224112808

Epoch: 6| Step: 13
Training loss: 2.1301279067993164
Validation loss: 1.9651382225815968

Epoch: 70| Step: 0
Training loss: 1.9267462491989136
Validation loss: 1.96111588580634

Epoch: 6| Step: 1
Training loss: 2.811939239501953
Validation loss: 1.979157252978253

Epoch: 6| Step: 2
Training loss: 2.5221011638641357
Validation loss: 1.978030058645433

Epoch: 6| Step: 3
Training loss: 2.1540279388427734
Validation loss: 1.975977022160766

Epoch: 6| Step: 4
Training loss: 2.447127342224121
Validation loss: 1.9739354579679427

Epoch: 6| Step: 5
Training loss: 2.729084014892578
Validation loss: 1.9639013826206166

Epoch: 6| Step: 6
Training loss: 1.7761344909667969
Validation loss: 1.9620725839368758

Epoch: 6| Step: 7
Training loss: 2.2852489948272705
Validation loss: 1.9682559326130857

Epoch: 6| Step: 8
Training loss: 1.651714563369751
Validation loss: 1.9827647183531074

Epoch: 6| Step: 9
Training loss: 2.5411932468414307
Validation loss: 1.9716619163431146

Epoch: 6| Step: 10
Training loss: 2.225552797317505
Validation loss: 1.9727102864173152

Epoch: 6| Step: 11
Training loss: 1.651465892791748
Validation loss: 1.969033013107956

Epoch: 6| Step: 12
Training loss: 1.7525429725646973
Validation loss: 1.9766512263205744

Epoch: 6| Step: 13
Training loss: 3.320904493331909
Validation loss: 1.9740341965870192

Epoch: 71| Step: 0
Training loss: 2.006497621536255
Validation loss: 1.9695051190673665

Epoch: 6| Step: 1
Training loss: 2.656909465789795
Validation loss: 1.977881008578885

Epoch: 6| Step: 2
Training loss: 2.730069160461426
Validation loss: 1.964232599863442

Epoch: 6| Step: 3
Training loss: 1.5059171915054321
Validation loss: 1.9657869595353321

Epoch: 6| Step: 4
Training loss: 2.214179039001465
Validation loss: 1.9717120034720308

Epoch: 6| Step: 5
Training loss: 2.148479461669922
Validation loss: 1.9792618866889709

Epoch: 6| Step: 6
Training loss: 2.2364978790283203
Validation loss: 1.9801521019269062

Epoch: 6| Step: 7
Training loss: 2.1346170902252197
Validation loss: 1.9792358670183408

Epoch: 6| Step: 8
Training loss: 2.2029201984405518
Validation loss: 1.9834122965412755

Epoch: 6| Step: 9
Training loss: 2.1290249824523926
Validation loss: 1.9576809124280048

Epoch: 6| Step: 10
Training loss: 2.162433385848999
Validation loss: 1.9734949757975917

Epoch: 6| Step: 11
Training loss: 2.2961246967315674
Validation loss: 1.9700728642043246

Epoch: 6| Step: 12
Training loss: 2.0871005058288574
Validation loss: 1.9550632405024704

Epoch: 6| Step: 13
Training loss: 2.9190330505371094
Validation loss: 1.967480464648175

Epoch: 72| Step: 0
Training loss: 2.2187533378601074
Validation loss: 1.983030447395899

Epoch: 6| Step: 1
Training loss: 2.9315760135650635
Validation loss: 1.9728344512242142

Epoch: 6| Step: 2
Training loss: 2.0408191680908203
Validation loss: 1.9719430118478753

Epoch: 6| Step: 3
Training loss: 2.9735817909240723
Validation loss: 1.9772864669881842

Epoch: 6| Step: 4
Training loss: 1.4521297216415405
Validation loss: 1.9781275756897465

Epoch: 6| Step: 5
Training loss: 1.9520008563995361
Validation loss: 1.9805973883598083

Epoch: 6| Step: 6
Training loss: 2.1856985092163086
Validation loss: 1.9914040565490723

Epoch: 6| Step: 7
Training loss: 1.6302672624588013
Validation loss: 1.9782451968039236

Epoch: 6| Step: 8
Training loss: 1.9960432052612305
Validation loss: 1.9727952941771476

Epoch: 6| Step: 9
Training loss: 2.257796287536621
Validation loss: 1.940414717120509

Epoch: 6| Step: 10
Training loss: 2.002034902572632
Validation loss: 1.9596808187423214

Epoch: 6| Step: 11
Training loss: 2.5780913829803467
Validation loss: 1.9835665700256184

Epoch: 6| Step: 12
Training loss: 2.1153197288513184
Validation loss: 1.957633404321568

Epoch: 6| Step: 13
Training loss: 3.0561366081237793
Validation loss: 1.9618539053906676

Epoch: 73| Step: 0
Training loss: 2.4321651458740234
Validation loss: 1.9563539387077413

Epoch: 6| Step: 1
Training loss: 1.9212195873260498
Validation loss: 1.9523071627463064

Epoch: 6| Step: 2
Training loss: 2.2542595863342285
Validation loss: 1.9484935396461076

Epoch: 6| Step: 3
Training loss: 2.769317626953125
Validation loss: 1.9627337994114045

Epoch: 6| Step: 4
Training loss: 2.4762725830078125
Validation loss: 1.9670890864505564

Epoch: 6| Step: 5
Training loss: 2.235008716583252
Validation loss: 1.9589278851785967

Epoch: 6| Step: 6
Training loss: 2.3591675758361816
Validation loss: 1.967143294631794

Epoch: 6| Step: 7
Training loss: 2.686450719833374
Validation loss: 1.9698265996030582

Epoch: 6| Step: 8
Training loss: 2.08054780960083
Validation loss: 1.9740176623867405

Epoch: 6| Step: 9
Training loss: 1.7847554683685303
Validation loss: 1.962709988317182

Epoch: 6| Step: 10
Training loss: 1.8125677108764648
Validation loss: 1.9494086080981838

Epoch: 6| Step: 11
Training loss: 2.0366804599761963
Validation loss: 1.9499723321648055

Epoch: 6| Step: 12
Training loss: 2.586099624633789
Validation loss: 1.9730011468292565

Epoch: 6| Step: 13
Training loss: 1.452431559562683
Validation loss: 1.9321975220916092

Epoch: 74| Step: 0
Training loss: 2.9260025024414062
Validation loss: 1.9614228087086831

Epoch: 6| Step: 1
Training loss: 1.575559139251709
Validation loss: 1.9764268654648975

Epoch: 6| Step: 2
Training loss: 1.4700556993484497
Validation loss: 1.9747862110855758

Epoch: 6| Step: 3
Training loss: 1.8612086772918701
Validation loss: 1.9476983649756319

Epoch: 6| Step: 4
Training loss: 1.937962293624878
Validation loss: 1.9743449662321357

Epoch: 6| Step: 5
Training loss: 2.6642017364501953
Validation loss: 1.956561952508906

Epoch: 6| Step: 6
Training loss: 3.0232465267181396
Validation loss: 1.9497047265370686

Epoch: 6| Step: 7
Training loss: 2.1266536712646484
Validation loss: 1.9654755028345252

Epoch: 6| Step: 8
Training loss: 2.3238227367401123
Validation loss: 1.9524779588945451

Epoch: 6| Step: 9
Training loss: 1.9928127527236938
Validation loss: 1.9563960439415389

Epoch: 6| Step: 10
Training loss: 2.454012393951416
Validation loss: 1.967054315792617

Epoch: 6| Step: 11
Training loss: 2.221278190612793
Validation loss: 1.9667969493455784

Epoch: 6| Step: 12
Training loss: 1.8790284395217896
Validation loss: 1.9346800799010901

Epoch: 6| Step: 13
Training loss: 3.1544227600097656
Validation loss: 1.9607710017952868

Epoch: 75| Step: 0
Training loss: 2.2460343837738037
Validation loss: 1.951333289505333

Epoch: 6| Step: 1
Training loss: 2.9056544303894043
Validation loss: 1.9631945548519012

Epoch: 6| Step: 2
Training loss: 2.0617270469665527
Validation loss: 1.9666414209591445

Epoch: 6| Step: 3
Training loss: 1.9685457944869995
Validation loss: 1.9657478999066096

Epoch: 6| Step: 4
Training loss: 1.9580113887786865
Validation loss: 1.9620971243868592

Epoch: 6| Step: 5
Training loss: 1.6768263578414917
Validation loss: 1.962647032994096

Epoch: 6| Step: 6
Training loss: 2.7909018993377686
Validation loss: 1.9550178256086124

Epoch: 6| Step: 7
Training loss: 2.263378620147705
Validation loss: 1.9846321895558348

Epoch: 6| Step: 8
Training loss: 1.796785593032837
Validation loss: 1.967124628764327

Epoch: 6| Step: 9
Training loss: 2.0175509452819824
Validation loss: 1.9583743131288918

Epoch: 6| Step: 10
Training loss: 2.3649442195892334
Validation loss: 1.9788387590839016

Epoch: 6| Step: 11
Training loss: 3.1189522743225098
Validation loss: 1.9814040045584402

Epoch: 6| Step: 12
Training loss: 1.854566216468811
Validation loss: 1.9790173743360786

Epoch: 6| Step: 13
Training loss: 1.9376760721206665
Validation loss: 1.9471430496502948

Epoch: 76| Step: 0
Training loss: 2.283170223236084
Validation loss: 1.949212803635546

Epoch: 6| Step: 1
Training loss: 1.5678040981292725
Validation loss: 1.9860532591419835

Epoch: 6| Step: 2
Training loss: 2.2374091148376465
Validation loss: 1.9658842778974963

Epoch: 6| Step: 3
Training loss: 2.5562801361083984
Validation loss: 1.9650191696741248

Epoch: 6| Step: 4
Training loss: 1.7025401592254639
Validation loss: 1.9692216098949473

Epoch: 6| Step: 5
Training loss: 2.741858959197998
Validation loss: 1.9762338130704817

Epoch: 6| Step: 6
Training loss: 1.7780163288116455
Validation loss: 1.963881815633466

Epoch: 6| Step: 7
Training loss: 2.4571218490600586
Validation loss: 1.971270686836653

Epoch: 6| Step: 8
Training loss: 2.27645206451416
Validation loss: 1.981075680384072

Epoch: 6| Step: 9
Training loss: 2.7768449783325195
Validation loss: 1.9716673563885432

Epoch: 6| Step: 10
Training loss: 1.914629578590393
Validation loss: 1.975161825456927

Epoch: 6| Step: 11
Training loss: 2.129326820373535
Validation loss: 1.9603355443605812

Epoch: 6| Step: 12
Training loss: 2.275434970855713
Validation loss: 1.9751548010815856

Epoch: 6| Step: 13
Training loss: 2.3101110458374023
Validation loss: 1.9532770097896617

Epoch: 77| Step: 0
Training loss: 2.0334482192993164
Validation loss: 1.9623879937715427

Epoch: 6| Step: 1
Training loss: 2.5659804344177246
Validation loss: 1.9524382647647653

Epoch: 6| Step: 2
Training loss: 1.9075877666473389
Validation loss: 1.973899459326139

Epoch: 6| Step: 3
Training loss: 2.60899019241333
Validation loss: 1.9621023131955055

Epoch: 6| Step: 4
Training loss: 1.3807799816131592
Validation loss: 1.956057128085885

Epoch: 6| Step: 5
Training loss: 2.132158041000366
Validation loss: 1.9844699649400608

Epoch: 6| Step: 6
Training loss: 1.949580192565918
Validation loss: 1.954386987993794

Epoch: 6| Step: 7
Training loss: 2.478128433227539
Validation loss: 1.970221286178917

Epoch: 6| Step: 8
Training loss: 2.453101634979248
Validation loss: 1.9611245919299383

Epoch: 6| Step: 9
Training loss: 3.0016884803771973
Validation loss: 1.9602883605546848

Epoch: 6| Step: 10
Training loss: 1.6153432130813599
Validation loss: 1.971088308160023

Epoch: 6| Step: 11
Training loss: 2.138925552368164
Validation loss: 1.9728560960420998

Epoch: 6| Step: 12
Training loss: 2.6118626594543457
Validation loss: 1.9787304888489425

Epoch: 6| Step: 13
Training loss: 2.135390281677246
Validation loss: 1.9526859970502957

Epoch: 78| Step: 0
Training loss: 2.470097064971924
Validation loss: 1.97873350369033

Epoch: 6| Step: 1
Training loss: 2.237783432006836
Validation loss: 1.9843567596968783

Epoch: 6| Step: 2
Training loss: 2.0842838287353516
Validation loss: 1.98454253391553

Epoch: 6| Step: 3
Training loss: 2.4273946285247803
Validation loss: 1.9771316025846748

Epoch: 6| Step: 4
Training loss: 1.7961748838424683
Validation loss: 1.9689275756958993

Epoch: 6| Step: 5
Training loss: 2.142324924468994
Validation loss: 1.9889077704439881

Epoch: 6| Step: 6
Training loss: 2.763728141784668
Validation loss: 1.9759448074525403

Epoch: 6| Step: 7
Training loss: 2.1778697967529297
Validation loss: 1.992996201720289

Epoch: 6| Step: 8
Training loss: 2.22955322265625
Validation loss: 1.9822445377226798

Epoch: 6| Step: 9
Training loss: 1.66117262840271
Validation loss: 1.9731897756617556

Epoch: 6| Step: 10
Training loss: 2.1415510177612305
Validation loss: 1.990668696741904

Epoch: 6| Step: 11
Training loss: 2.666393756866455
Validation loss: 1.9717378321514334

Epoch: 6| Step: 12
Training loss: 1.8682612180709839
Validation loss: 1.9735237526637253

Epoch: 6| Step: 13
Training loss: 2.1182730197906494
Validation loss: 1.9772134122028147

Epoch: 79| Step: 0
Training loss: 2.1274218559265137
Validation loss: 1.9743121554774623

Epoch: 6| Step: 1
Training loss: 2.6257543563842773
Validation loss: 1.9945646024519397

Epoch: 6| Step: 2
Training loss: 1.4618350267410278
Validation loss: 1.9902084540295344

Epoch: 6| Step: 3
Training loss: 1.39693284034729
Validation loss: 1.9967381595283427

Epoch: 6| Step: 4
Training loss: 2.378465175628662
Validation loss: 1.9786502956062235

Epoch: 6| Step: 5
Training loss: 1.9181848764419556
Validation loss: 1.987062232468718

Epoch: 6| Step: 6
Training loss: 2.525744915008545
Validation loss: 1.9696801195862472

Epoch: 6| Step: 7
Training loss: 2.1784486770629883
Validation loss: 1.9592053044226863

Epoch: 6| Step: 8
Training loss: 1.9220163822174072
Validation loss: 1.982551766980079

Epoch: 6| Step: 9
Training loss: 2.661982536315918
Validation loss: 1.9978110174978934

Epoch: 6| Step: 10
Training loss: 1.8571385145187378
Validation loss: 1.985522206111621

Epoch: 6| Step: 11
Training loss: 2.522510051727295
Validation loss: 1.97900301923034

Epoch: 6| Step: 12
Training loss: 2.9363670349121094
Validation loss: 1.9656053640509163

Epoch: 6| Step: 13
Training loss: 2.231431007385254
Validation loss: 1.9678073736929125

Epoch: 80| Step: 0
Training loss: 1.7303400039672852
Validation loss: 1.978439025981452

Epoch: 6| Step: 1
Training loss: 2.575416088104248
Validation loss: 1.9723856551672823

Epoch: 6| Step: 2
Training loss: 2.2276031970977783
Validation loss: 1.9716951488166727

Epoch: 6| Step: 3
Training loss: 1.946129560470581
Validation loss: 1.9603952733419274

Epoch: 6| Step: 4
Training loss: 2.4496660232543945
Validation loss: 1.9776209721001246

Epoch: 6| Step: 5
Training loss: 2.4367215633392334
Validation loss: 1.9783611784699142

Epoch: 6| Step: 6
Training loss: 2.175833225250244
Validation loss: 1.9916605616128573

Epoch: 6| Step: 7
Training loss: 2.282149314880371
Validation loss: 1.9900962280970749

Epoch: 6| Step: 8
Training loss: 2.2793235778808594
Validation loss: 1.9705017241098548

Epoch: 6| Step: 9
Training loss: 2.221798896789551
Validation loss: 1.975620622275978

Epoch: 6| Step: 10
Training loss: 2.3899192810058594
Validation loss: 1.9787861224143737

Epoch: 6| Step: 11
Training loss: 2.2684874534606934
Validation loss: 1.97598978652749

Epoch: 6| Step: 12
Training loss: 1.8365968465805054
Validation loss: 1.9829766801608506

Epoch: 6| Step: 13
Training loss: 1.8816850185394287
Validation loss: 1.9944244148910686

Epoch: 81| Step: 0
Training loss: 1.829188346862793
Validation loss: 1.9791355504784534

Epoch: 6| Step: 1
Training loss: 1.6848737001419067
Validation loss: 1.974287509918213

Epoch: 6| Step: 2
Training loss: 2.120164394378662
Validation loss: 1.9787598989343131

Epoch: 6| Step: 3
Training loss: 2.386977434158325
Validation loss: 1.9653478719854867

Epoch: 6| Step: 4
Training loss: 2.317133903503418
Validation loss: 1.9764370072272517

Epoch: 6| Step: 5
Training loss: 1.891982078552246
Validation loss: 1.9471641791764127

Epoch: 6| Step: 6
Training loss: 2.1154861450195312
Validation loss: 1.9424763507740472

Epoch: 6| Step: 7
Training loss: 2.208308696746826
Validation loss: 1.972332937743074

Epoch: 6| Step: 8
Training loss: 2.8744847774505615
Validation loss: 1.955417215183217

Epoch: 6| Step: 9
Training loss: 1.6732462644577026
Validation loss: 1.9724301920142224

Epoch: 6| Step: 10
Training loss: 2.6534299850463867
Validation loss: 1.9503038813990932

Epoch: 6| Step: 11
Training loss: 2.32155704498291
Validation loss: 1.963072161520681

Epoch: 6| Step: 12
Training loss: 2.7929983139038086
Validation loss: 1.9646252662904802

Epoch: 6| Step: 13
Training loss: 2.0052685737609863
Validation loss: 1.9806029565872685

Epoch: 82| Step: 0
Training loss: 2.8576512336730957
Validation loss: 1.9734371195557296

Epoch: 6| Step: 1
Training loss: 2.6472883224487305
Validation loss: 1.954034646352132

Epoch: 6| Step: 2
Training loss: 2.1754109859466553
Validation loss: 1.965569237227081

Epoch: 6| Step: 3
Training loss: 2.013554811477661
Validation loss: 1.9658683756346345

Epoch: 6| Step: 4
Training loss: 3.095867395401001
Validation loss: 1.9784256271136704

Epoch: 6| Step: 5
Training loss: 1.834427833557129
Validation loss: 1.9663114804093555

Epoch: 6| Step: 6
Training loss: 1.837390422821045
Validation loss: 1.9690047028244182

Epoch: 6| Step: 7
Training loss: 1.716625452041626
Validation loss: 1.9832062772525254

Epoch: 6| Step: 8
Training loss: 2.1388168334960938
Validation loss: 1.9807951014528993

Epoch: 6| Step: 9
Training loss: 1.9807767868041992
Validation loss: 1.9871607185691915

Epoch: 6| Step: 10
Training loss: 1.9830937385559082
Validation loss: 1.9895943633971676

Epoch: 6| Step: 11
Training loss: 2.3756613731384277
Validation loss: 1.9915704547718007

Epoch: 6| Step: 12
Training loss: 2.462913990020752
Validation loss: 1.989737278671675

Epoch: 6| Step: 13
Training loss: 1.4597413539886475
Validation loss: 1.9640618934426257

Epoch: 83| Step: 0
Training loss: 2.341440439224243
Validation loss: 1.969191615299512

Epoch: 6| Step: 1
Training loss: 2.660112142562866
Validation loss: 1.9809836110761088

Epoch: 6| Step: 2
Training loss: 1.8910874128341675
Validation loss: 1.977133745788246

Epoch: 6| Step: 3
Training loss: 2.366558313369751
Validation loss: 1.9622055407493346

Epoch: 6| Step: 4
Training loss: 2.1493754386901855
Validation loss: 1.9793813202970771

Epoch: 6| Step: 5
Training loss: 1.5709586143493652
Validation loss: 1.98668005517734

Epoch: 6| Step: 6
Training loss: 1.5431647300720215
Validation loss: 1.971297981918499

Epoch: 6| Step: 7
Training loss: 2.38836669921875
Validation loss: 1.977792993668587

Epoch: 6| Step: 8
Training loss: 2.071402072906494
Validation loss: 2.003519719646823

Epoch: 6| Step: 9
Training loss: 2.1318399906158447
Validation loss: 1.9586015901257914

Epoch: 6| Step: 10
Training loss: 2.4592418670654297
Validation loss: 1.996763342170305

Epoch: 6| Step: 11
Training loss: 2.8854823112487793
Validation loss: 1.9740831070048834

Epoch: 6| Step: 12
Training loss: 2.084334135055542
Validation loss: 1.9574231409257459

Epoch: 6| Step: 13
Training loss: 2.1941604614257812
Validation loss: 1.9788374670090214

Epoch: 84| Step: 0
Training loss: 2.5689260959625244
Validation loss: 1.9549224043405184

Epoch: 6| Step: 1
Training loss: 2.408228874206543
Validation loss: 1.9492258884573495

Epoch: 6| Step: 2
Training loss: 2.9450690746307373
Validation loss: 1.9576785461876982

Epoch: 6| Step: 3
Training loss: 1.510631799697876
Validation loss: 1.9548405370404642

Epoch: 6| Step: 4
Training loss: 2.056389331817627
Validation loss: 1.9729273114153134

Epoch: 6| Step: 5
Training loss: 2.1543123722076416
Validation loss: 1.9658469333443591

Epoch: 6| Step: 6
Training loss: 2.461449146270752
Validation loss: 1.9855917448638587

Epoch: 6| Step: 7
Training loss: 2.2118289470672607
Validation loss: 1.9580497895517657

Epoch: 6| Step: 8
Training loss: 2.544332504272461
Validation loss: 1.9569880962371826

Epoch: 6| Step: 9
Training loss: 2.055926561355591
Validation loss: 1.9585968909725067

Epoch: 6| Step: 10
Training loss: 1.7575346231460571
Validation loss: 1.9626263879960584

Epoch: 6| Step: 11
Training loss: 1.7240962982177734
Validation loss: 1.9465894147913942

Epoch: 6| Step: 12
Training loss: 2.02644681930542
Validation loss: 1.9609233756219187

Epoch: 6| Step: 13
Training loss: 2.796259880065918
Validation loss: 1.9764999869049236

Epoch: 85| Step: 0
Training loss: 1.624429702758789
Validation loss: 1.9584836024110035

Epoch: 6| Step: 1
Training loss: 1.9393231868743896
Validation loss: 1.9616678132805774

Epoch: 6| Step: 2
Training loss: 1.8433239459991455
Validation loss: 1.9669501999373078

Epoch: 6| Step: 3
Training loss: 2.6734824180603027
Validation loss: 1.95887831975055

Epoch: 6| Step: 4
Training loss: 1.638561487197876
Validation loss: 1.9772818985805716

Epoch: 6| Step: 5
Training loss: 2.232174873352051
Validation loss: 1.9583730248994724

Epoch: 6| Step: 6
Training loss: 1.954030990600586
Validation loss: 1.9657303158954909

Epoch: 6| Step: 7
Training loss: 2.824777603149414
Validation loss: 1.9727335130014727

Epoch: 6| Step: 8
Training loss: 2.23250150680542
Validation loss: 1.9455252667909027

Epoch: 6| Step: 9
Training loss: 2.631776809692383
Validation loss: 1.9732003365793536

Epoch: 6| Step: 10
Training loss: 1.766601324081421
Validation loss: 1.9735574671017226

Epoch: 6| Step: 11
Training loss: 3.3116402626037598
Validation loss: 1.9777866614762174

Epoch: 6| Step: 12
Training loss: 1.8991756439208984
Validation loss: 1.9753714607607933

Epoch: 6| Step: 13
Training loss: 2.050689697265625
Validation loss: 1.974171866652786

Epoch: 86| Step: 0
Training loss: 2.3534607887268066
Validation loss: 1.9786159300035047

Epoch: 6| Step: 1
Training loss: 2.043827772140503
Validation loss: 1.9781840539747668

Epoch: 6| Step: 2
Training loss: 1.9000333547592163
Validation loss: 1.9953032796100905

Epoch: 6| Step: 3
Training loss: 2.3621296882629395
Validation loss: 1.9552023667161182

Epoch: 6| Step: 4
Training loss: 1.9898624420166016
Validation loss: 1.95815719327619

Epoch: 6| Step: 5
Training loss: 2.853516101837158
Validation loss: 1.9691463721695768

Epoch: 6| Step: 6
Training loss: 2.285578727722168
Validation loss: 1.9870505563674434

Epoch: 6| Step: 7
Training loss: 1.8960933685302734
Validation loss: 1.9789925006128126

Epoch: 6| Step: 8
Training loss: 2.8227550983428955
Validation loss: 1.9895289354426886

Epoch: 6| Step: 9
Training loss: 2.0704102516174316
Validation loss: 1.9879000315102198

Epoch: 6| Step: 10
Training loss: 2.1287713050842285
Validation loss: 1.9480324791323753

Epoch: 6| Step: 11
Training loss: 2.3018264770507812
Validation loss: 1.956339459265432

Epoch: 6| Step: 12
Training loss: 1.9891763925552368
Validation loss: 1.9852522778254684

Epoch: 6| Step: 13
Training loss: 1.3431366682052612
Validation loss: 1.9808308168124127

Epoch: 87| Step: 0
Training loss: 2.1579904556274414
Validation loss: 1.9790336066676724

Epoch: 6| Step: 1
Training loss: 2.249192237854004
Validation loss: 1.96122726573739

Epoch: 6| Step: 2
Training loss: 2.0229477882385254
Validation loss: 1.9618649123817362

Epoch: 6| Step: 3
Training loss: 1.6230206489562988
Validation loss: 1.976200181950805

Epoch: 6| Step: 4
Training loss: 2.7336535453796387
Validation loss: 1.9734004543673607

Epoch: 6| Step: 5
Training loss: 2.7314400672912598
Validation loss: 1.9682224591573079

Epoch: 6| Step: 6
Training loss: 2.083102226257324
Validation loss: 1.9613196824186592

Epoch: 6| Step: 7
Training loss: 2.0278210639953613
Validation loss: 1.9658090606812508

Epoch: 6| Step: 8
Training loss: 2.1644389629364014
Validation loss: 1.9381886092565392

Epoch: 6| Step: 9
Training loss: 2.450272798538208
Validation loss: 1.9612917079720447

Epoch: 6| Step: 10
Training loss: 1.833118200302124
Validation loss: 1.9881076940926172

Epoch: 6| Step: 11
Training loss: 2.6653599739074707
Validation loss: 1.9754349339392878

Epoch: 6| Step: 12
Training loss: 1.8698828220367432
Validation loss: 1.9637397578967515

Epoch: 6| Step: 13
Training loss: 1.814475178718567
Validation loss: 1.9717302322387695

Epoch: 88| Step: 0
Training loss: 2.242455005645752
Validation loss: 1.9369758405993063

Epoch: 6| Step: 1
Training loss: 1.876766562461853
Validation loss: 1.961820105070709

Epoch: 6| Step: 2
Training loss: 2.535729169845581
Validation loss: 1.9427623364233202

Epoch: 6| Step: 3
Training loss: 2.450240135192871
Validation loss: 1.9461412327263945

Epoch: 6| Step: 4
Training loss: 1.7929182052612305
Validation loss: 1.954829974841046

Epoch: 6| Step: 5
Training loss: 2.221358299255371
Validation loss: 1.9575796537501837

Epoch: 6| Step: 6
Training loss: 2.3511924743652344
Validation loss: 1.930297222188724

Epoch: 6| Step: 7
Training loss: 2.217527389526367
Validation loss: 1.9696450720551193

Epoch: 6| Step: 8
Training loss: 2.150686264038086
Validation loss: 1.9445871742822791

Epoch: 6| Step: 9
Training loss: 2.777635097503662
Validation loss: 1.9557139642776982

Epoch: 6| Step: 10
Training loss: 2.4082484245300293
Validation loss: 1.9592619352443243

Epoch: 6| Step: 11
Training loss: 1.851484775543213
Validation loss: 1.957367302269064

Epoch: 6| Step: 12
Training loss: 1.640790581703186
Validation loss: 1.9668677622272122

Epoch: 6| Step: 13
Training loss: 1.6963740587234497
Validation loss: 1.9686207796937676

Epoch: 89| Step: 0
Training loss: 2.7966628074645996
Validation loss: 1.9627833930394982

Epoch: 6| Step: 1
Training loss: 2.3765532970428467
Validation loss: 1.9676436275564215

Epoch: 6| Step: 2
Training loss: 2.248619794845581
Validation loss: 1.9507352793088524

Epoch: 6| Step: 3
Training loss: 2.1562585830688477
Validation loss: 1.9696882860634917

Epoch: 6| Step: 4
Training loss: 2.3242602348327637
Validation loss: 1.9667115314032442

Epoch: 6| Step: 5
Training loss: 2.014975070953369
Validation loss: 1.9728319991019465

Epoch: 6| Step: 6
Training loss: 2.1936185359954834
Validation loss: 1.969179036796734

Epoch: 6| Step: 7
Training loss: 2.0125794410705566
Validation loss: 1.9728206678103375

Epoch: 6| Step: 8
Training loss: 2.2843856811523438
Validation loss: 1.9741655229240336

Epoch: 6| Step: 9
Training loss: 2.3898158073425293
Validation loss: 1.958301523680328

Epoch: 6| Step: 10
Training loss: 2.2488133907318115
Validation loss: 1.9571778928079913

Epoch: 6| Step: 11
Training loss: 1.854804277420044
Validation loss: 1.9885138709058043

Epoch: 6| Step: 12
Training loss: 1.4854412078857422
Validation loss: 1.977509360159597

Epoch: 6| Step: 13
Training loss: 2.443336248397827
Validation loss: 1.9765736441458426

Epoch: 90| Step: 0
Training loss: 2.8127222061157227
Validation loss: 1.9812700440806728

Epoch: 6| Step: 1
Training loss: 1.6945549249649048
Validation loss: 1.9782499959391933

Epoch: 6| Step: 2
Training loss: 2.153282403945923
Validation loss: 1.9710276101225166

Epoch: 6| Step: 3
Training loss: 2.1792001724243164
Validation loss: 1.9548036090789302

Epoch: 6| Step: 4
Training loss: 1.7043603658676147
Validation loss: 1.9721509705307663

Epoch: 6| Step: 5
Training loss: 2.092055082321167
Validation loss: 1.9767885387584727

Epoch: 6| Step: 6
Training loss: 2.045840263366699
Validation loss: 1.981106847845098

Epoch: 6| Step: 7
Training loss: 3.0892374515533447
Validation loss: 1.967821503198275

Epoch: 6| Step: 8
Training loss: 1.6727473735809326
Validation loss: 1.9560935933102843

Epoch: 6| Step: 9
Training loss: 2.53192138671875
Validation loss: 1.9749555677495978

Epoch: 6| Step: 10
Training loss: 2.385126829147339
Validation loss: 1.973778268342377

Epoch: 6| Step: 11
Training loss: 2.231870651245117
Validation loss: 1.9688731496052077

Epoch: 6| Step: 12
Training loss: 1.5165919065475464
Validation loss: 1.9626367066496162

Epoch: 6| Step: 13
Training loss: 2.495957851409912
Validation loss: 1.9767196896255657

Epoch: 91| Step: 0
Training loss: 1.787729263305664
Validation loss: 1.9789285916154102

Epoch: 6| Step: 1
Training loss: 2.4483723640441895
Validation loss: 1.9810495581678165

Epoch: 6| Step: 2
Training loss: 1.99506413936615
Validation loss: 1.9786011813789286

Epoch: 6| Step: 3
Training loss: 2.5775768756866455
Validation loss: 1.9575551697002944

Epoch: 6| Step: 4
Training loss: 2.4788949489593506
Validation loss: 1.9734749383823846

Epoch: 6| Step: 5
Training loss: 2.5156924724578857
Validation loss: 1.968406456772999

Epoch: 6| Step: 6
Training loss: 1.8056244850158691
Validation loss: 1.9660456039572274

Epoch: 6| Step: 7
Training loss: 2.8134255409240723
Validation loss: 1.984689840706446

Epoch: 6| Step: 8
Training loss: 1.554246187210083
Validation loss: 1.9583064356157858

Epoch: 6| Step: 9
Training loss: 2.245725631713867
Validation loss: 1.9679939644311064

Epoch: 6| Step: 10
Training loss: 1.984442949295044
Validation loss: 1.9586099334942397

Epoch: 6| Step: 11
Training loss: 2.1647024154663086
Validation loss: 1.9459601397155433

Epoch: 6| Step: 12
Training loss: 2.33111572265625
Validation loss: 1.953403836937361

Epoch: 6| Step: 13
Training loss: 1.6003897190093994
Validation loss: 1.9603022016504759

Epoch: 92| Step: 0
Training loss: 1.948702335357666
Validation loss: 1.9787833665006904

Epoch: 6| Step: 1
Training loss: 1.8442564010620117
Validation loss: 1.9417521594673075

Epoch: 6| Step: 2
Training loss: 1.842796802520752
Validation loss: 1.9420596194523636

Epoch: 6| Step: 3
Training loss: 2.3811874389648438
Validation loss: 1.9573789463248303

Epoch: 6| Step: 4
Training loss: 2.1727237701416016
Validation loss: 1.961813671614534

Epoch: 6| Step: 5
Training loss: 1.9857548475265503
Validation loss: 1.9618650636365336

Epoch: 6| Step: 6
Training loss: 1.7726514339447021
Validation loss: 1.9708994921817575

Epoch: 6| Step: 7
Training loss: 2.3112635612487793
Validation loss: 1.9629628145566551

Epoch: 6| Step: 8
Training loss: 2.8077006340026855
Validation loss: 1.9618733570139895

Epoch: 6| Step: 9
Training loss: 2.017967700958252
Validation loss: 1.961293525593255

Epoch: 6| Step: 10
Training loss: 2.317580223083496
Validation loss: 1.9557792525137625

Epoch: 6| Step: 11
Training loss: 2.03408145904541
Validation loss: 1.9597687452070174

Epoch: 6| Step: 12
Training loss: 2.529162645339966
Validation loss: 1.9651587265793995

Epoch: 6| Step: 13
Training loss: 2.4993605613708496
Validation loss: 1.950559490470476

Epoch: 93| Step: 0
Training loss: 1.8295269012451172
Validation loss: 1.9625768353862147

Epoch: 6| Step: 1
Training loss: 2.32906436920166
Validation loss: 1.9650260991947626

Epoch: 6| Step: 2
Training loss: 2.3001585006713867
Validation loss: 1.9477795118926673

Epoch: 6| Step: 3
Training loss: 2.142556667327881
Validation loss: 1.9508509969198575

Epoch: 6| Step: 4
Training loss: 2.4662065505981445
Validation loss: 1.9677076365358086

Epoch: 6| Step: 5
Training loss: 2.897989273071289
Validation loss: 1.9531413124453636

Epoch: 6| Step: 6
Training loss: 1.9851405620574951
Validation loss: 1.948295352279499

Epoch: 6| Step: 7
Training loss: 2.157917022705078
Validation loss: 1.945792830118569

Epoch: 6| Step: 8
Training loss: 2.156651020050049
Validation loss: 1.9579513585695656

Epoch: 6| Step: 9
Training loss: 2.126140832901001
Validation loss: 1.9397808210824126

Epoch: 6| Step: 10
Training loss: 1.862263798713684
Validation loss: 1.9601822706960863

Epoch: 6| Step: 11
Training loss: 1.4055867195129395
Validation loss: 1.960099922713413

Epoch: 6| Step: 12
Training loss: 2.482267379760742
Validation loss: 1.9552754817470428

Epoch: 6| Step: 13
Training loss: 2.227813720703125
Validation loss: 1.953187581031553

Epoch: 94| Step: 0
Training loss: 1.858404278755188
Validation loss: 1.9792399637160762

Epoch: 6| Step: 1
Training loss: 2.439424514770508
Validation loss: 1.9748558152106501

Epoch: 6| Step: 2
Training loss: 2.743429183959961
Validation loss: 1.9682123366222586

Epoch: 6| Step: 3
Training loss: 1.796937108039856
Validation loss: 1.968724919903663

Epoch: 6| Step: 4
Training loss: 2.4557437896728516
Validation loss: 1.9857713894177509

Epoch: 6| Step: 5
Training loss: 1.870966911315918
Validation loss: 1.9574367615484423

Epoch: 6| Step: 6
Training loss: 1.7293365001678467
Validation loss: 1.973641671160216

Epoch: 6| Step: 7
Training loss: 2.2392241954803467
Validation loss: 1.9764472412806686

Epoch: 6| Step: 8
Training loss: 1.270485281944275
Validation loss: 1.9725637871731994

Epoch: 6| Step: 9
Training loss: 2.4809489250183105
Validation loss: 1.9738693801305627

Epoch: 6| Step: 10
Training loss: 3.2843031883239746
Validation loss: 2.006527349513064

Epoch: 6| Step: 11
Training loss: 2.008236885070801
Validation loss: 1.997107922389943

Epoch: 6| Step: 12
Training loss: 1.5344001054763794
Validation loss: 1.9764577265708678

Epoch: 6| Step: 13
Training loss: 2.9180967807769775
Validation loss: 2.0061574110420803

Epoch: 95| Step: 0
Training loss: 1.78836989402771
Validation loss: 1.9826344418269333

Epoch: 6| Step: 1
Training loss: 2.1656136512756348
Validation loss: 1.9760196452499719

Epoch: 6| Step: 2
Training loss: 2.209336757659912
Validation loss: 1.9915191076135124

Epoch: 6| Step: 3
Training loss: 2.8791561126708984
Validation loss: 1.9949174645126506

Epoch: 6| Step: 4
Training loss: 1.9863749742507935
Validation loss: 1.9861669514768867

Epoch: 6| Step: 5
Training loss: 1.6551334857940674
Validation loss: 1.9914359559294998

Epoch: 6| Step: 6
Training loss: 2.1683084964752197
Validation loss: 1.9636970668710687

Epoch: 6| Step: 7
Training loss: 2.546157121658325
Validation loss: 1.95965560020939

Epoch: 6| Step: 8
Training loss: 1.8265137672424316
Validation loss: 1.9685075193323114

Epoch: 6| Step: 9
Training loss: 2.2587294578552246
Validation loss: 1.9726503382446945

Epoch: 6| Step: 10
Training loss: 2.377629041671753
Validation loss: 1.9717008362534225

Epoch: 6| Step: 11
Training loss: 1.6841503381729126
Validation loss: 1.983006674756286

Epoch: 6| Step: 12
Training loss: 2.3820066452026367
Validation loss: 1.959125639289938

Epoch: 6| Step: 13
Training loss: 2.3637349605560303
Validation loss: 1.9658461437430432

Epoch: 96| Step: 0
Training loss: 2.485078811645508
Validation loss: 1.9714146852493286

Epoch: 6| Step: 1
Training loss: 1.515063762664795
Validation loss: 1.9656881260615524

Epoch: 6| Step: 2
Training loss: 2.8480334281921387
Validation loss: 1.9681200596594042

Epoch: 6| Step: 3
Training loss: 1.7932113409042358
Validation loss: 1.9806314181256037

Epoch: 6| Step: 4
Training loss: 3.321251153945923
Validation loss: 1.9808737257475495

Epoch: 6| Step: 5
Training loss: 1.8625895977020264
Validation loss: 1.9677350136541552

Epoch: 6| Step: 6
Training loss: 1.6699827909469604
Validation loss: 1.9885560799670476

Epoch: 6| Step: 7
Training loss: 1.8187016248703003
Validation loss: 1.9728546270760157

Epoch: 6| Step: 8
Training loss: 2.543635845184326
Validation loss: 1.9731773894320253

Epoch: 6| Step: 9
Training loss: 1.9778599739074707
Validation loss: 1.9992233822422643

Epoch: 6| Step: 10
Training loss: 2.269972324371338
Validation loss: 1.9601748322927823

Epoch: 6| Step: 11
Training loss: 2.1180169582366943
Validation loss: 1.9522330222591278

Epoch: 6| Step: 12
Training loss: 2.167041778564453
Validation loss: 1.953739881515503

Epoch: 6| Step: 13
Training loss: 1.6545889377593994
Validation loss: 1.970263627267653

Epoch: 97| Step: 0
Training loss: 2.6223630905151367
Validation loss: 1.9830753239252235

Epoch: 6| Step: 1
Training loss: 2.5105624198913574
Validation loss: 1.9760536557884627

Epoch: 6| Step: 2
Training loss: 2.640860080718994
Validation loss: 1.9660748794514646

Epoch: 6| Step: 3
Training loss: 2.772007465362549
Validation loss: 1.9764475514811854

Epoch: 6| Step: 4
Training loss: 2.6162872314453125
Validation loss: 1.9776566041413175

Epoch: 6| Step: 5
Training loss: 1.1303601264953613
Validation loss: 1.9886952907808366

Epoch: 6| Step: 6
Training loss: 2.089939594268799
Validation loss: 1.9911220278791202

Epoch: 6| Step: 7
Training loss: 2.2454962730407715
Validation loss: 1.9792905020457443

Epoch: 6| Step: 8
Training loss: 1.8582854270935059
Validation loss: 1.9938982455961165

Epoch: 6| Step: 9
Training loss: 3.2286858558654785
Validation loss: 2.012425773887224

Epoch: 6| Step: 10
Training loss: 1.5682740211486816
Validation loss: 1.9935823999425417

Epoch: 6| Step: 11
Training loss: 1.8530741930007935
Validation loss: 1.9927345398933656

Epoch: 6| Step: 12
Training loss: 1.5867916345596313
Validation loss: 1.9900518976232058

Epoch: 6| Step: 13
Training loss: 1.2338674068450928
Validation loss: 1.9834487284383466

Epoch: 98| Step: 0
Training loss: 2.0255789756774902
Validation loss: 1.9849592562644713

Epoch: 6| Step: 1
Training loss: 2.2059855461120605
Validation loss: 1.9908801868397703

Epoch: 6| Step: 2
Training loss: 1.8312041759490967
Validation loss: 1.9904407801166657

Epoch: 6| Step: 3
Training loss: 3.286832809448242
Validation loss: 1.9923488145233483

Epoch: 6| Step: 4
Training loss: 2.426318883895874
Validation loss: 1.9945216922349827

Epoch: 6| Step: 5
Training loss: 2.120272636413574
Validation loss: 1.988906547587405

Epoch: 6| Step: 6
Training loss: 1.8481731414794922
Validation loss: 1.974172394762757

Epoch: 6| Step: 7
Training loss: 2.2494235038757324
Validation loss: 1.9843019131691224

Epoch: 6| Step: 8
Training loss: 2.187932252883911
Validation loss: 1.9741072347087245

Epoch: 6| Step: 9
Training loss: 1.8787541389465332
Validation loss: 1.9690807634784329

Epoch: 6| Step: 10
Training loss: 1.9438931941986084
Validation loss: 1.9781396568462413

Epoch: 6| Step: 11
Training loss: 2.6933720111846924
Validation loss: 1.9721518562686058

Epoch: 6| Step: 12
Training loss: 1.8770530223846436
Validation loss: 1.9867434283738494

Epoch: 6| Step: 13
Training loss: 1.188621997833252
Validation loss: 1.9890304752575454

Epoch: 99| Step: 0
Training loss: 2.176741600036621
Validation loss: 1.967765172322591

Epoch: 6| Step: 1
Training loss: 2.2422244548797607
Validation loss: 1.954882852492794

Epoch: 6| Step: 2
Training loss: 2.1633496284484863
Validation loss: 1.969789037140467

Epoch: 6| Step: 3
Training loss: 2.2881858348846436
Validation loss: 1.96204629892944

Epoch: 6| Step: 4
Training loss: 2.0921597480773926
Validation loss: 1.95238362332826

Epoch: 6| Step: 5
Training loss: 1.903069257736206
Validation loss: 1.9618147983345935

Epoch: 6| Step: 6
Training loss: 2.9398844242095947
Validation loss: 1.9652581291814004

Epoch: 6| Step: 7
Training loss: 1.7905213832855225
Validation loss: 1.9881682985572404

Epoch: 6| Step: 8
Training loss: 1.906136393547058
Validation loss: 1.9501308933381112

Epoch: 6| Step: 9
Training loss: 2.6745946407318115
Validation loss: 1.9618354241053264

Epoch: 6| Step: 10
Training loss: 1.4059743881225586
Validation loss: 1.9750230696893507

Epoch: 6| Step: 11
Training loss: 1.874946117401123
Validation loss: 1.9594859589812577

Epoch: 6| Step: 12
Training loss: 2.2138004302978516
Validation loss: 1.9590612637099398

Epoch: 6| Step: 13
Training loss: 2.5761680603027344
Validation loss: 1.962130420951433

Epoch: 100| Step: 0
Training loss: 2.2333152294158936
Validation loss: 1.9852594829374743

Epoch: 6| Step: 1
Training loss: 2.350245237350464
Validation loss: 1.9644210620593

Epoch: 6| Step: 2
Training loss: 2.651517152786255
Validation loss: 1.9524632769246255

Epoch: 6| Step: 3
Training loss: 1.8862117528915405
Validation loss: 1.9559352859374015

Epoch: 6| Step: 4
Training loss: 1.7158305644989014
Validation loss: 1.950099278521794

Epoch: 6| Step: 5
Training loss: 2.1059608459472656
Validation loss: 1.9765312851116221

Epoch: 6| Step: 6
Training loss: 2.171419143676758
Validation loss: 1.9714612101995816

Epoch: 6| Step: 7
Training loss: 2.1615352630615234
Validation loss: 1.9747561165081557

Epoch: 6| Step: 8
Training loss: 1.83364737033844
Validation loss: 1.964842725825566

Epoch: 6| Step: 9
Training loss: 2.117492198944092
Validation loss: 1.9742517496949883

Epoch: 6| Step: 10
Training loss: 2.6741268634796143
Validation loss: 1.972133856947704

Epoch: 6| Step: 11
Training loss: 2.0344858169555664
Validation loss: 1.9536228808023597

Epoch: 6| Step: 12
Training loss: 1.4893152713775635
Validation loss: 1.965852798954133

Epoch: 6| Step: 13
Training loss: 2.98046612739563
Validation loss: 1.9448315828077254

Epoch: 101| Step: 0
Training loss: 2.115347385406494
Validation loss: 1.9810625994077293

Epoch: 6| Step: 1
Training loss: 2.391806125640869
Validation loss: 1.9500883189580773

Epoch: 6| Step: 2
Training loss: 2.269115447998047
Validation loss: 1.9633994128114434

Epoch: 6| Step: 3
Training loss: 2.1198391914367676
Validation loss: 1.9568001403603503

Epoch: 6| Step: 4
Training loss: 2.5861659049987793
Validation loss: 1.9619632331273889

Epoch: 6| Step: 5
Training loss: 1.536887526512146
Validation loss: 1.9689217562316566

Epoch: 6| Step: 6
Training loss: 1.9489326477050781
Validation loss: 1.9579614118863178

Epoch: 6| Step: 7
Training loss: 1.6339881420135498
Validation loss: 1.9661564724419707

Epoch: 6| Step: 8
Training loss: 2.8784780502319336
Validation loss: 1.9587317089880667

Epoch: 6| Step: 9
Training loss: 2.0252742767333984
Validation loss: 1.9670846449431552

Epoch: 6| Step: 10
Training loss: 2.6349120140075684
Validation loss: 1.9500490542381042

Epoch: 6| Step: 11
Training loss: 1.9472639560699463
Validation loss: 1.9614786806926932

Epoch: 6| Step: 12
Training loss: 1.9498004913330078
Validation loss: 1.9626493300161054

Epoch: 6| Step: 13
Training loss: 1.8399410247802734
Validation loss: 1.9643731604340255

Epoch: 102| Step: 0
Training loss: 1.3651998043060303
Validation loss: 1.9653510765362812

Epoch: 6| Step: 1
Training loss: 2.864047050476074
Validation loss: 1.9548522733872937

Epoch: 6| Step: 2
Training loss: 1.501679539680481
Validation loss: 1.962766731939008

Epoch: 6| Step: 3
Training loss: 2.3097784519195557
Validation loss: 1.9792501798240087

Epoch: 6| Step: 4
Training loss: 2.1371867656707764
Validation loss: 1.9554927451636201

Epoch: 6| Step: 5
Training loss: 2.2866885662078857
Validation loss: 1.9652090636632775

Epoch: 6| Step: 6
Training loss: 2.139826774597168
Validation loss: 1.9938038369660736

Epoch: 6| Step: 7
Training loss: 1.647719383239746
Validation loss: 1.9733601206092424

Epoch: 6| Step: 8
Training loss: 2.1673226356506348
Validation loss: 1.9613005730413622

Epoch: 6| Step: 9
Training loss: 2.3365988731384277
Validation loss: 1.9626368399589293

Epoch: 6| Step: 10
Training loss: 1.7803966999053955
Validation loss: 1.9704798703552575

Epoch: 6| Step: 11
Training loss: 2.541741371154785
Validation loss: 1.977557292548559

Epoch: 6| Step: 12
Training loss: 2.5105957984924316
Validation loss: 1.9886668882062357

Epoch: 6| Step: 13
Training loss: 2.6630444526672363
Validation loss: 1.9699502119454004

Epoch: 103| Step: 0
Training loss: 2.2562732696533203
Validation loss: 1.9508490895712247

Epoch: 6| Step: 1
Training loss: 2.0366804599761963
Validation loss: 1.9612944100492744

Epoch: 6| Step: 2
Training loss: 2.2969584465026855
Validation loss: 1.9743205193550355

Epoch: 6| Step: 3
Training loss: 2.0307345390319824
Validation loss: 1.9471785509458153

Epoch: 6| Step: 4
Training loss: 1.49345064163208
Validation loss: 1.9479953999160438

Epoch: 6| Step: 5
Training loss: 2.396249771118164
Validation loss: 1.9628623890620407

Epoch: 6| Step: 6
Training loss: 1.717707872390747
Validation loss: 1.961579502269786

Epoch: 6| Step: 7
Training loss: 2.4994564056396484
Validation loss: 1.9587744846138904

Epoch: 6| Step: 8
Training loss: 2.233726978302002
Validation loss: 1.9519471917101132

Epoch: 6| Step: 9
Training loss: 2.1468307971954346
Validation loss: 1.945618414109753

Epoch: 6| Step: 10
Training loss: 2.615894317626953
Validation loss: 1.9670024815426077

Epoch: 6| Step: 11
Training loss: 1.6736981868743896
Validation loss: 1.9654105837627123

Epoch: 6| Step: 12
Training loss: 2.318429470062256
Validation loss: 1.9642825485557638

Epoch: 6| Step: 13
Training loss: 2.2060580253601074
Validation loss: 1.9524526224341443

Epoch: 104| Step: 0
Training loss: 1.5646371841430664
Validation loss: 1.9427712796836771

Epoch: 6| Step: 1
Training loss: 2.210787773132324
Validation loss: 1.9649140886081162

Epoch: 6| Step: 2
Training loss: 2.8569822311401367
Validation loss: 1.9534887088242399

Epoch: 6| Step: 3
Training loss: 1.8422646522521973
Validation loss: 1.9542384070734824

Epoch: 6| Step: 4
Training loss: 1.8188459873199463
Validation loss: 1.988227023873278

Epoch: 6| Step: 5
Training loss: 1.7580208778381348
Validation loss: 1.9457591528533607

Epoch: 6| Step: 6
Training loss: 2.509075164794922
Validation loss: 1.9379000958575998

Epoch: 6| Step: 7
Training loss: 2.480870246887207
Validation loss: 1.9531886064878075

Epoch: 6| Step: 8
Training loss: 2.0402398109436035
Validation loss: 1.9763658738905383

Epoch: 6| Step: 9
Training loss: 2.4847164154052734
Validation loss: 1.9476353199251237

Epoch: 6| Step: 10
Training loss: 1.643122911453247
Validation loss: 1.9801027544083134

Epoch: 6| Step: 11
Training loss: 2.685899257659912
Validation loss: 1.9485409387978174

Epoch: 6| Step: 12
Training loss: 2.0717968940734863
Validation loss: 1.9495810744582966

Epoch: 6| Step: 13
Training loss: 1.850533366203308
Validation loss: 1.9786758410033358

Epoch: 105| Step: 0
Training loss: 1.575858473777771
Validation loss: 1.9514345917650449

Epoch: 6| Step: 1
Training loss: 2.0114364624023438
Validation loss: 1.9359719650719756

Epoch: 6| Step: 2
Training loss: 2.5541939735412598
Validation loss: 1.9476390423313263

Epoch: 6| Step: 3
Training loss: 2.657240390777588
Validation loss: 1.981319514654016

Epoch: 6| Step: 4
Training loss: 1.755952000617981
Validation loss: 1.950317116193874

Epoch: 6| Step: 5
Training loss: 2.2529311180114746
Validation loss: 1.9713210572478592

Epoch: 6| Step: 6
Training loss: 1.3564975261688232
Validation loss: 1.9535923145150627

Epoch: 6| Step: 7
Training loss: 2.6439876556396484
Validation loss: 1.9526627755934192

Epoch: 6| Step: 8
Training loss: 2.1005139350891113
Validation loss: 1.965384664074067

Epoch: 6| Step: 9
Training loss: 2.2317192554473877
Validation loss: 1.9477229015801543

Epoch: 6| Step: 10
Training loss: 1.592427134513855
Validation loss: 1.9634041606739003

Epoch: 6| Step: 11
Training loss: 2.685845136642456
Validation loss: 1.9539750006891066

Epoch: 6| Step: 12
Training loss: 2.576575994491577
Validation loss: 1.9841258602757608

Epoch: 6| Step: 13
Training loss: 2.021214008331299
Validation loss: 1.9589451205345891

Epoch: 106| Step: 0
Training loss: 1.8908618688583374
Validation loss: 1.9782827361937492

Epoch: 6| Step: 1
Training loss: 2.4224634170532227
Validation loss: 1.978996851110971

Epoch: 6| Step: 2
Training loss: 1.9323980808258057
Validation loss: 1.9599364803683372

Epoch: 6| Step: 3
Training loss: 2.378958225250244
Validation loss: 1.9533685535512946

Epoch: 6| Step: 4
Training loss: 2.5832579135894775
Validation loss: 1.9530429660633046

Epoch: 6| Step: 5
Training loss: 1.6476339101791382
Validation loss: 1.9359365176129084

Epoch: 6| Step: 6
Training loss: 2.2801597118377686
Validation loss: 1.9653068037443264

Epoch: 6| Step: 7
Training loss: 1.674046277999878
Validation loss: 1.9603008403572986

Epoch: 6| Step: 8
Training loss: 2.0478577613830566
Validation loss: 1.9792896047715218

Epoch: 6| Step: 9
Training loss: 1.7558188438415527
Validation loss: 1.953746432899147

Epoch: 6| Step: 10
Training loss: 1.9627163410186768
Validation loss: 1.9561191976711314

Epoch: 6| Step: 11
Training loss: 2.8343288898468018
Validation loss: 1.9561863740285237

Epoch: 6| Step: 12
Training loss: 2.3643293380737305
Validation loss: 1.9573656999936668

Epoch: 6| Step: 13
Training loss: 1.9580658674240112
Validation loss: 1.9450246185384772

Epoch: 107| Step: 0
Training loss: 1.6271803379058838
Validation loss: 1.9506538888459564

Epoch: 6| Step: 1
Training loss: 1.6896203756332397
Validation loss: 1.9596576844492266

Epoch: 6| Step: 2
Training loss: 2.06174635887146
Validation loss: 1.9724000628276537

Epoch: 6| Step: 3
Training loss: 2.5990374088287354
Validation loss: 1.96690034866333

Epoch: 6| Step: 4
Training loss: 2.9519853591918945
Validation loss: 1.9665780874990648

Epoch: 6| Step: 5
Training loss: 2.6177444458007812
Validation loss: 1.9613123068245508

Epoch: 6| Step: 6
Training loss: 1.831101894378662
Validation loss: 1.963961391038792

Epoch: 6| Step: 7
Training loss: 2.1229095458984375
Validation loss: 1.9736327407180623

Epoch: 6| Step: 8
Training loss: 1.8281902074813843
Validation loss: 1.9614855525314168

Epoch: 6| Step: 9
Training loss: 2.4655094146728516
Validation loss: 1.9695405216627224

Epoch: 6| Step: 10
Training loss: 1.619179129600525
Validation loss: 1.9561277102398615

Epoch: 6| Step: 11
Training loss: 2.0052356719970703
Validation loss: 1.9529038424132972

Epoch: 6| Step: 12
Training loss: 1.7239164113998413
Validation loss: 1.9700954652601672

Epoch: 6| Step: 13
Training loss: 2.9339780807495117
Validation loss: 1.9653878647794005

Epoch: 108| Step: 0
Training loss: 2.2716476917266846
Validation loss: 1.97867150075974

Epoch: 6| Step: 1
Training loss: 1.9683456420898438
Validation loss: 1.9782998907950617

Epoch: 6| Step: 2
Training loss: 1.7798559665679932
Validation loss: 1.9600909909894388

Epoch: 6| Step: 3
Training loss: 1.9526338577270508
Validation loss: 1.9765070305075696

Epoch: 6| Step: 4
Training loss: 1.336761474609375
Validation loss: 1.9667098419640654

Epoch: 6| Step: 5
Training loss: 2.4996252059936523
Validation loss: 1.9491229595676545

Epoch: 6| Step: 6
Training loss: 2.2413644790649414
Validation loss: 1.9430911335893857

Epoch: 6| Step: 7
Training loss: 2.0002589225769043
Validation loss: 1.962500233804026

Epoch: 6| Step: 8
Training loss: 2.843291759490967
Validation loss: 1.978337780121834

Epoch: 6| Step: 9
Training loss: 2.439985752105713
Validation loss: 1.9562727674361198

Epoch: 6| Step: 10
Training loss: 1.7286794185638428
Validation loss: 1.9471355253650295

Epoch: 6| Step: 11
Training loss: 2.3410897254943848
Validation loss: 1.9698160848309916

Epoch: 6| Step: 12
Training loss: 1.952600359916687
Validation loss: 1.948372107680126

Epoch: 6| Step: 13
Training loss: 2.2675795555114746
Validation loss: 1.9500453561864874

Epoch: 109| Step: 0
Training loss: 2.5721001625061035
Validation loss: 1.9480853824205295

Epoch: 6| Step: 1
Training loss: 1.6140930652618408
Validation loss: 1.95817917905828

Epoch: 6| Step: 2
Training loss: 2.2479159832000732
Validation loss: 1.9462374897413357

Epoch: 6| Step: 3
Training loss: 1.6405764818191528
Validation loss: 1.9568091797572311

Epoch: 6| Step: 4
Training loss: 2.482163190841675
Validation loss: 1.9784133524023078

Epoch: 6| Step: 5
Training loss: 2.698141574859619
Validation loss: 1.9771823895874845

Epoch: 6| Step: 6
Training loss: 1.7933869361877441
Validation loss: 1.9738692134939215

Epoch: 6| Step: 7
Training loss: 2.1411375999450684
Validation loss: 1.9784431790792814

Epoch: 6| Step: 8
Training loss: 1.92445969581604
Validation loss: 1.964951321642886

Epoch: 6| Step: 9
Training loss: 2.333606481552124
Validation loss: 1.9602949119383288

Epoch: 6| Step: 10
Training loss: 1.3642048835754395
Validation loss: 1.9723921475871917

Epoch: 6| Step: 11
Training loss: 2.307304859161377
Validation loss: 1.975585740099671

Epoch: 6| Step: 12
Training loss: 2.446073532104492
Validation loss: 1.973682193345921

Epoch: 6| Step: 13
Training loss: 2.2883310317993164
Validation loss: 1.9608890523192704

Epoch: 110| Step: 0
Training loss: 1.5329338312149048
Validation loss: 1.963255843808574

Epoch: 6| Step: 1
Training loss: 1.8819324970245361
Validation loss: 1.9620023812017133

Epoch: 6| Step: 2
Training loss: 2.142850637435913
Validation loss: 1.9574107431596326

Epoch: 6| Step: 3
Training loss: 1.6347074508666992
Validation loss: 1.9660896383306032

Epoch: 6| Step: 4
Training loss: 2.0855464935302734
Validation loss: 1.9549606769315657

Epoch: 6| Step: 5
Training loss: 2.170135259628296
Validation loss: 1.9560319864621727

Epoch: 6| Step: 6
Training loss: 2.211411476135254
Validation loss: 1.9710750579833984

Epoch: 6| Step: 7
Training loss: 2.262190818786621
Validation loss: 1.9442624545866443

Epoch: 6| Step: 8
Training loss: 2.488065242767334
Validation loss: 1.9578465620676677

Epoch: 6| Step: 9
Training loss: 2.0259408950805664
Validation loss: 1.9575018472568964

Epoch: 6| Step: 10
Training loss: 2.580859899520874
Validation loss: 1.970008401460545

Epoch: 6| Step: 11
Training loss: 1.9118907451629639
Validation loss: 1.9429324211612824

Epoch: 6| Step: 12
Training loss: 1.910193681716919
Validation loss: 1.9676083582703785

Epoch: 6| Step: 13
Training loss: 3.5931904315948486
Validation loss: 1.9334316074207265

Epoch: 111| Step: 0
Training loss: 2.333756923675537
Validation loss: 1.9541771719532628

Epoch: 6| Step: 1
Training loss: 2.1394801139831543
Validation loss: 1.955141121341336

Epoch: 6| Step: 2
Training loss: 2.15382719039917
Validation loss: 1.9750660670700895

Epoch: 6| Step: 3
Training loss: 1.7466727495193481
Validation loss: 1.9478974957619943

Epoch: 6| Step: 4
Training loss: 1.8520127534866333
Validation loss: 1.9808149799223869

Epoch: 6| Step: 5
Training loss: 2.2095894813537598
Validation loss: 1.9644332457614202

Epoch: 6| Step: 6
Training loss: 2.332756519317627
Validation loss: 1.9330036255621141

Epoch: 6| Step: 7
Training loss: 2.4307644367218018
Validation loss: 1.9472720789653

Epoch: 6| Step: 8
Training loss: 1.8415437936782837
Validation loss: 1.951123486283005

Epoch: 6| Step: 9
Training loss: 2.0093958377838135
Validation loss: 1.9514912277139642

Epoch: 6| Step: 10
Training loss: 1.73604154586792
Validation loss: 1.972610568487516

Epoch: 6| Step: 11
Training loss: 2.41464900970459
Validation loss: 1.9522280077780447

Epoch: 6| Step: 12
Training loss: 2.52428936958313
Validation loss: 1.9524586431441768

Epoch: 6| Step: 13
Training loss: 1.875976800918579
Validation loss: 1.9391022010516095

Epoch: 112| Step: 0
Training loss: 1.5591351985931396
Validation loss: 1.9371376729780627

Epoch: 6| Step: 1
Training loss: 1.9226168394088745
Validation loss: 1.9507790098908127

Epoch: 6| Step: 2
Training loss: 1.7446084022521973
Validation loss: 1.9625655399855746

Epoch: 6| Step: 3
Training loss: 1.4704804420471191
Validation loss: 1.9512866825185797

Epoch: 6| Step: 4
Training loss: 2.1807994842529297
Validation loss: 1.9594151409723426

Epoch: 6| Step: 5
Training loss: 2.4917187690734863
Validation loss: 1.9638875658794115

Epoch: 6| Step: 6
Training loss: 2.4618539810180664
Validation loss: 1.9606505311945432

Epoch: 6| Step: 7
Training loss: 2.049006462097168
Validation loss: 1.9656661812977125

Epoch: 6| Step: 8
Training loss: 2.4700515270233154
Validation loss: 1.9640801055457002

Epoch: 6| Step: 9
Training loss: 2.2932205200195312
Validation loss: 1.965269216927149

Epoch: 6| Step: 10
Training loss: 2.5669310092926025
Validation loss: 1.9583360636106102

Epoch: 6| Step: 11
Training loss: 1.8276543617248535
Validation loss: 1.9640968448372298

Epoch: 6| Step: 12
Training loss: 1.8261480331420898
Validation loss: 1.9541609530807824

Epoch: 6| Step: 13
Training loss: 2.9708797931671143
Validation loss: 1.9762340386708577

Epoch: 113| Step: 0
Training loss: 1.9258874654769897
Validation loss: 1.97169586407241

Epoch: 6| Step: 1
Training loss: 2.4082179069519043
Validation loss: 1.9837354588252243

Epoch: 6| Step: 2
Training loss: 2.3098626136779785
Validation loss: 1.9657445940920102

Epoch: 6| Step: 3
Training loss: 1.9467355012893677
Validation loss: 1.9592776247250137

Epoch: 6| Step: 4
Training loss: 2.5172181129455566
Validation loss: 1.9906457047308646

Epoch: 6| Step: 5
Training loss: 1.6840877532958984
Validation loss: 1.9687345591924523

Epoch: 6| Step: 6
Training loss: 2.743489980697632
Validation loss: 1.9906630874961935

Epoch: 6| Step: 7
Training loss: 1.7008068561553955
Validation loss: 1.9682859964268182

Epoch: 6| Step: 8
Training loss: 2.4167110919952393
Validation loss: 1.9764865034370012

Epoch: 6| Step: 9
Training loss: 1.937009334564209
Validation loss: 1.983790773217396

Epoch: 6| Step: 10
Training loss: 2.4237618446350098
Validation loss: 1.9736875577639508

Epoch: 6| Step: 11
Training loss: 1.4623702764511108
Validation loss: 1.9866529844140495

Epoch: 6| Step: 12
Training loss: 1.6964023113250732
Validation loss: 1.977528727182778

Epoch: 6| Step: 13
Training loss: 2.418436050415039
Validation loss: 1.9901981776760471

Epoch: 114| Step: 0
Training loss: 2.65181303024292
Validation loss: 1.9602073290014779

Epoch: 6| Step: 1
Training loss: 2.3678483963012695
Validation loss: 1.9700519756604267

Epoch: 6| Step: 2
Training loss: 1.8387051820755005
Validation loss: 1.9777057709232453

Epoch: 6| Step: 3
Training loss: 1.9321149587631226
Validation loss: 1.978847865135439

Epoch: 6| Step: 4
Training loss: 2.1108999252319336
Validation loss: 1.9545787354951263

Epoch: 6| Step: 5
Training loss: 2.068314552307129
Validation loss: 1.9597964030440136

Epoch: 6| Step: 6
Training loss: 1.8128653764724731
Validation loss: 1.9561212767836869

Epoch: 6| Step: 7
Training loss: 1.889448881149292
Validation loss: 1.9549096194646691

Epoch: 6| Step: 8
Training loss: 1.8936729431152344
Validation loss: 1.9491660312939716

Epoch: 6| Step: 9
Training loss: 2.554098606109619
Validation loss: 1.9521260389717676

Epoch: 6| Step: 10
Training loss: 2.6118783950805664
Validation loss: 1.9404037793477376

Epoch: 6| Step: 11
Training loss: 1.6298186779022217
Validation loss: 1.967630801662322

Epoch: 6| Step: 12
Training loss: 1.9399330615997314
Validation loss: 1.9461486031932216

Epoch: 6| Step: 13
Training loss: 2.207268238067627
Validation loss: 1.940917714949577

Epoch: 115| Step: 0
Training loss: 2.5531065464019775
Validation loss: 1.9385133302339943

Epoch: 6| Step: 1
Training loss: 1.8756029605865479
Validation loss: 1.9384491546179659

Epoch: 6| Step: 2
Training loss: 1.7360540628433228
Validation loss: 1.9584160979076097

Epoch: 6| Step: 3
Training loss: 2.6684091091156006
Validation loss: 1.9637429970566944

Epoch: 6| Step: 4
Training loss: 1.8571215867996216
Validation loss: 1.9642727900576848

Epoch: 6| Step: 5
Training loss: 1.8346861600875854
Validation loss: 1.9558981541664369

Epoch: 6| Step: 6
Training loss: 2.1621789932250977
Validation loss: 1.9569073710390317

Epoch: 6| Step: 7
Training loss: 2.882179021835327
Validation loss: 1.9531642852290985

Epoch: 6| Step: 8
Training loss: 2.164463996887207
Validation loss: 1.9635603145886493

Epoch: 6| Step: 9
Training loss: 2.2045493125915527
Validation loss: 1.9636522467418382

Epoch: 6| Step: 10
Training loss: 2.3282408714294434
Validation loss: 1.9442433900730585

Epoch: 6| Step: 11
Training loss: 1.490265130996704
Validation loss: 1.967815331233445

Epoch: 6| Step: 12
Training loss: 1.9303796291351318
Validation loss: 1.9651790434314358

Epoch: 6| Step: 13
Training loss: 1.4570857286453247
Validation loss: 1.9555118955591673

Epoch: 116| Step: 0
Training loss: 1.5046262741088867
Validation loss: 1.9623681819567116

Epoch: 6| Step: 1
Training loss: 2.0628833770751953
Validation loss: 1.9559948931458175

Epoch: 6| Step: 2
Training loss: 2.149362087249756
Validation loss: 1.9510424444752354

Epoch: 6| Step: 3
Training loss: 2.316028356552124
Validation loss: 1.965036589612243

Epoch: 6| Step: 4
Training loss: 1.7619143724441528
Validation loss: 1.96759997388368

Epoch: 6| Step: 5
Training loss: 2.3772149085998535
Validation loss: 1.9755134018518592

Epoch: 6| Step: 6
Training loss: 1.899074912071228
Validation loss: 1.9853398851169053

Epoch: 6| Step: 7
Training loss: 2.810379981994629
Validation loss: 1.9603414971341369

Epoch: 6| Step: 8
Training loss: 1.6385681629180908
Validation loss: 1.953017101492933

Epoch: 6| Step: 9
Training loss: 2.9280686378479004
Validation loss: 1.9570722695319884

Epoch: 6| Step: 10
Training loss: 2.2892656326293945
Validation loss: 1.9459512336279756

Epoch: 6| Step: 11
Training loss: 1.6724822521209717
Validation loss: 1.9448366472798009

Epoch: 6| Step: 12
Training loss: 1.8979079723358154
Validation loss: 1.9495741180194321

Epoch: 6| Step: 13
Training loss: 2.0305044651031494
Validation loss: 1.9352615905064408

Epoch: 117| Step: 0
Training loss: 2.7605090141296387
Validation loss: 1.946040044548691

Epoch: 6| Step: 1
Training loss: 2.497666358947754
Validation loss: 1.9628672035791541

Epoch: 6| Step: 2
Training loss: 1.5694921016693115
Validation loss: 1.988114890231881

Epoch: 6| Step: 3
Training loss: 2.4749996662139893
Validation loss: 1.9708268309152255

Epoch: 6| Step: 4
Training loss: 1.267866611480713
Validation loss: 1.969459056854248

Epoch: 6| Step: 5
Training loss: 2.271338701248169
Validation loss: 1.9685843683058215

Epoch: 6| Step: 6
Training loss: 1.7523325681686401
Validation loss: 1.9655495856397895

Epoch: 6| Step: 7
Training loss: 2.51157283782959
Validation loss: 1.9803081891869987

Epoch: 6| Step: 8
Training loss: 2.137833595275879
Validation loss: 1.9688842283782138

Epoch: 6| Step: 9
Training loss: 1.8519182205200195
Validation loss: 1.965180097087737

Epoch: 6| Step: 10
Training loss: 1.4829843044281006
Validation loss: 1.9537749085375058

Epoch: 6| Step: 11
Training loss: 2.245551586151123
Validation loss: 1.9921983621453727

Epoch: 6| Step: 12
Training loss: 1.8684628009796143
Validation loss: 1.9573332699396278

Epoch: 6| Step: 13
Training loss: 2.7275476455688477
Validation loss: 1.9672646573794785

Epoch: 118| Step: 0
Training loss: 1.7116450071334839
Validation loss: 1.9823494726611721

Epoch: 6| Step: 1
Training loss: 2.392618417739868
Validation loss: 1.960237733779415

Epoch: 6| Step: 2
Training loss: 1.7877862453460693
Validation loss: 1.9676401794597667

Epoch: 6| Step: 3
Training loss: 1.924753189086914
Validation loss: 1.966212304689551

Epoch: 6| Step: 4
Training loss: 2.3703951835632324
Validation loss: 1.988561514885195

Epoch: 6| Step: 5
Training loss: 2.606273651123047
Validation loss: 1.9557435871452413

Epoch: 6| Step: 6
Training loss: 2.375802755355835
Validation loss: 1.9709005868563088

Epoch: 6| Step: 7
Training loss: 2.03242826461792
Validation loss: 1.9814166715068202

Epoch: 6| Step: 8
Training loss: 1.9883053302764893
Validation loss: 1.965831523300499

Epoch: 6| Step: 9
Training loss: 3.0689759254455566
Validation loss: 1.9833937691104027

Epoch: 6| Step: 10
Training loss: 2.0757431983947754
Validation loss: 1.9784332372808968

Epoch: 6| Step: 11
Training loss: 1.3009496927261353
Validation loss: 1.957702777718985

Epoch: 6| Step: 12
Training loss: 1.8568601608276367
Validation loss: 1.9822161736026886

Epoch: 6| Step: 13
Training loss: 1.8312040567398071
Validation loss: 1.9920764866695608

Epoch: 119| Step: 0
Training loss: 1.4549214839935303
Validation loss: 1.967735177727156

Epoch: 6| Step: 1
Training loss: 2.575037956237793
Validation loss: 1.9757196723773915

Epoch: 6| Step: 2
Training loss: 2.0379486083984375
Validation loss: 1.9707589252020723

Epoch: 6| Step: 3
Training loss: 2.3449296951293945
Validation loss: 1.9511906229039675

Epoch: 6| Step: 4
Training loss: 1.9462683200836182
Validation loss: 1.9665744804566907

Epoch: 6| Step: 5
Training loss: 2.141631603240967
Validation loss: 1.9648992553833993

Epoch: 6| Step: 6
Training loss: 2.1579740047454834
Validation loss: 1.964777749071839

Epoch: 6| Step: 7
Training loss: 2.7713050842285156
Validation loss: 1.9674153007486814

Epoch: 6| Step: 8
Training loss: 1.992980718612671
Validation loss: 1.9681399073652042

Epoch: 6| Step: 9
Training loss: 1.9073572158813477
Validation loss: 1.9446531316285491

Epoch: 6| Step: 10
Training loss: 2.0755739212036133
Validation loss: 1.9432872085161106

Epoch: 6| Step: 11
Training loss: 1.2023615837097168
Validation loss: 1.9729048180323776

Epoch: 6| Step: 12
Training loss: 2.4608521461486816
Validation loss: 1.9561875315122708

Epoch: 6| Step: 13
Training loss: 2.442840099334717
Validation loss: 1.940117084851829

Epoch: 120| Step: 0
Training loss: 1.4203050136566162
Validation loss: 1.9424503772489485

Epoch: 6| Step: 1
Training loss: 2.0438201427459717
Validation loss: 1.9524384506287114

Epoch: 6| Step: 2
Training loss: 2.1150126457214355
Validation loss: 1.9576995885500343

Epoch: 6| Step: 3
Training loss: 2.4135663509368896
Validation loss: 1.9497345775686286

Epoch: 6| Step: 4
Training loss: 1.9749244451522827
Validation loss: 1.9741628964742024

Epoch: 6| Step: 5
Training loss: 1.8349018096923828
Validation loss: 1.967707613463043

Epoch: 6| Step: 6
Training loss: 2.6878600120544434
Validation loss: 1.9886957855634793

Epoch: 6| Step: 7
Training loss: 1.9670207500457764
Validation loss: 1.9734072557059668

Epoch: 6| Step: 8
Training loss: 1.7084226608276367
Validation loss: 1.9876198986525178

Epoch: 6| Step: 9
Training loss: 2.511179208755493
Validation loss: 1.9625882153869958

Epoch: 6| Step: 10
Training loss: 2.0827012062072754
Validation loss: 1.956414597008818

Epoch: 6| Step: 11
Training loss: 1.9764776229858398
Validation loss: 1.9648866191987069

Epoch: 6| Step: 12
Training loss: 2.2011632919311523
Validation loss: 1.9705097752232705

Epoch: 6| Step: 13
Training loss: 2.7948007583618164
Validation loss: 1.9500136080608572

Epoch: 121| Step: 0
Training loss: 2.261934280395508
Validation loss: 1.9442071273762693

Epoch: 6| Step: 1
Training loss: 1.9508389234542847
Validation loss: 1.9493810938250633

Epoch: 6| Step: 2
Training loss: 2.06559419631958
Validation loss: 1.949381248925322

Epoch: 6| Step: 3
Training loss: 1.891080379486084
Validation loss: 1.9553161680057485

Epoch: 6| Step: 4
Training loss: 2.6039865016937256
Validation loss: 1.929764986038208

Epoch: 6| Step: 5
Training loss: 2.234158992767334
Validation loss: 1.967598677963339

Epoch: 6| Step: 6
Training loss: 1.8908519744873047
Validation loss: 1.9585035142078195

Epoch: 6| Step: 7
Training loss: 2.03652286529541
Validation loss: 1.9562670133447135

Epoch: 6| Step: 8
Training loss: 2.628715991973877
Validation loss: 1.9695424546477616

Epoch: 6| Step: 9
Training loss: 1.3197546005249023
Validation loss: 1.950118064880371

Epoch: 6| Step: 10
Training loss: 2.4469854831695557
Validation loss: 1.943451202043923

Epoch: 6| Step: 11
Training loss: 2.211216926574707
Validation loss: 1.933114682474444

Epoch: 6| Step: 12
Training loss: 1.4704205989837646
Validation loss: 1.961739085053885

Epoch: 6| Step: 13
Training loss: 2.136326789855957
Validation loss: 1.9511174899275585

Epoch: 122| Step: 0
Training loss: 1.445557951927185
Validation loss: 1.9656453324902443

Epoch: 6| Step: 1
Training loss: 2.8691763877868652
Validation loss: 1.9574775157436248

Epoch: 6| Step: 2
Training loss: 2.2151718139648438
Validation loss: 1.9625582977007794

Epoch: 6| Step: 3
Training loss: 1.6078877449035645
Validation loss: 1.9407688674106394

Epoch: 6| Step: 4
Training loss: 2.4548068046569824
Validation loss: 1.9393963890690957

Epoch: 6| Step: 5
Training loss: 1.6893212795257568
Validation loss: 1.952439869603803

Epoch: 6| Step: 6
Training loss: 2.0799431800842285
Validation loss: 1.9487844295399164

Epoch: 6| Step: 7
Training loss: 1.8206902742385864
Validation loss: 1.945377351135336

Epoch: 6| Step: 8
Training loss: 1.5176465511322021
Validation loss: 1.9516922902035456

Epoch: 6| Step: 9
Training loss: 2.5162904262542725
Validation loss: 1.9527901000874017

Epoch: 6| Step: 10
Training loss: 2.5657596588134766
Validation loss: 1.945971050570088

Epoch: 6| Step: 11
Training loss: 2.8410491943359375
Validation loss: 1.9535362515398251

Epoch: 6| Step: 12
Training loss: 1.4385690689086914
Validation loss: 1.967556494538502

Epoch: 6| Step: 13
Training loss: 2.229260206222534
Validation loss: 1.9682798654802385

Epoch: 123| Step: 0
Training loss: 3.238656520843506
Validation loss: 1.9476937542679489

Epoch: 6| Step: 1
Training loss: 2.409501075744629
Validation loss: 1.953775898102791

Epoch: 6| Step: 2
Training loss: 2.130181312561035
Validation loss: 1.9480788938460811

Epoch: 6| Step: 3
Training loss: 2.4490461349487305
Validation loss: 1.963154979931411

Epoch: 6| Step: 4
Training loss: 2.0448813438415527
Validation loss: 1.9594489220649964

Epoch: 6| Step: 5
Training loss: 1.5690155029296875
Validation loss: 1.9570467266985165

Epoch: 6| Step: 6
Training loss: 2.028033494949341
Validation loss: 1.973540529128044

Epoch: 6| Step: 7
Training loss: 1.766910433769226
Validation loss: 1.954653214382869

Epoch: 6| Step: 8
Training loss: 1.5819892883300781
Validation loss: 1.9651838194939397

Epoch: 6| Step: 9
Training loss: 2.1004276275634766
Validation loss: 1.9693976653519498

Epoch: 6| Step: 10
Training loss: 1.4254601001739502
Validation loss: 1.978864323708319

Epoch: 6| Step: 11
Training loss: 2.0678024291992188
Validation loss: 1.9769807579696819

Epoch: 6| Step: 12
Training loss: 2.309601306915283
Validation loss: 1.9607982917498517

Epoch: 6| Step: 13
Training loss: 1.9113850593566895
Validation loss: 1.9612152012445594

Epoch: 124| Step: 0
Training loss: 1.6153607368469238
Validation loss: 1.9585874875386555

Epoch: 6| Step: 1
Training loss: 2.194336414337158
Validation loss: 1.9489940712528844

Epoch: 6| Step: 2
Training loss: 1.7438876628875732
Validation loss: 1.9555118750500422

Epoch: 6| Step: 3
Training loss: 1.605377435684204
Validation loss: 1.9687650383159678

Epoch: 6| Step: 4
Training loss: 1.2162072658538818
Validation loss: 1.96969892901759

Epoch: 6| Step: 5
Training loss: 2.5713753700256348
Validation loss: 1.9684356169034076

Epoch: 6| Step: 6
Training loss: 2.2385644912719727
Validation loss: 1.9613687005094302

Epoch: 6| Step: 7
Training loss: 2.0190703868865967
Validation loss: 1.9734885615687217

Epoch: 6| Step: 8
Training loss: 2.0127289295196533
Validation loss: 1.959493080774943

Epoch: 6| Step: 9
Training loss: 2.785947322845459
Validation loss: 1.9717825740896247

Epoch: 6| Step: 10
Training loss: 2.8670473098754883
Validation loss: 1.9634243006347327

Epoch: 6| Step: 11
Training loss: 2.4719204902648926
Validation loss: 1.950502823757869

Epoch: 6| Step: 12
Training loss: 2.2062342166900635
Validation loss: 1.9559150254854591

Epoch: 6| Step: 13
Training loss: 0.9608357548713684
Validation loss: 1.9648003988368536

Epoch: 125| Step: 0
Training loss: 2.5395941734313965
Validation loss: 1.9593524368860389

Epoch: 6| Step: 1
Training loss: 2.1629762649536133
Validation loss: 1.9639941005296604

Epoch: 6| Step: 2
Training loss: 1.2996599674224854
Validation loss: 1.9687031315219017

Epoch: 6| Step: 3
Training loss: 2.2963757514953613
Validation loss: 1.9406870180560696

Epoch: 6| Step: 4
Training loss: 1.7133598327636719
Validation loss: 1.970149229931575

Epoch: 6| Step: 5
Training loss: 2.6264326572418213
Validation loss: 1.970813028274044

Epoch: 6| Step: 6
Training loss: 2.4028000831604004
Validation loss: 1.9554506450571039

Epoch: 6| Step: 7
Training loss: 1.9559664726257324
Validation loss: 1.94827224105917

Epoch: 6| Step: 8
Training loss: 1.5900312662124634
Validation loss: 1.9663734871854064

Epoch: 6| Step: 9
Training loss: 1.760648250579834
Validation loss: 1.9725325774121028

Epoch: 6| Step: 10
Training loss: 1.296567678451538
Validation loss: 1.9281964020062519

Epoch: 6| Step: 11
Training loss: 2.8194093704223633
Validation loss: 1.9575851014865342

Epoch: 6| Step: 12
Training loss: 2.3822460174560547
Validation loss: 1.9566376183622627

Epoch: 6| Step: 13
Training loss: 2.152881145477295
Validation loss: 1.9623775917996642

Epoch: 126| Step: 0
Training loss: 2.094493865966797
Validation loss: 1.9487386159999396

Epoch: 6| Step: 1
Training loss: 2.0220484733581543
Validation loss: 1.9482514140426472

Epoch: 6| Step: 2
Training loss: 1.5879426002502441
Validation loss: 1.9554422978431947

Epoch: 6| Step: 3
Training loss: 1.9775513410568237
Validation loss: 1.9535707094336068

Epoch: 6| Step: 4
Training loss: 1.8985705375671387
Validation loss: 1.9382723108414681

Epoch: 6| Step: 5
Training loss: 1.8693878650665283
Validation loss: 1.9396608721825384

Epoch: 6| Step: 6
Training loss: 2.0913496017456055
Validation loss: 1.9318739111705492

Epoch: 6| Step: 7
Training loss: 2.5010781288146973
Validation loss: 1.972758549515919

Epoch: 6| Step: 8
Training loss: 1.8685901165008545
Validation loss: 1.9539897531591437

Epoch: 6| Step: 9
Training loss: 2.4140892028808594
Validation loss: 1.9728168390130485

Epoch: 6| Step: 10
Training loss: 1.8896918296813965
Validation loss: 1.944257108114099

Epoch: 6| Step: 11
Training loss: 1.8774089813232422
Validation loss: 1.9532802899678547

Epoch: 6| Step: 12
Training loss: 2.4190149307250977
Validation loss: 1.9346682615177606

Epoch: 6| Step: 13
Training loss: 2.934326648712158
Validation loss: 1.9464825827588317

Epoch: 127| Step: 0
Training loss: 1.6802747249603271
Validation loss: 1.9186414493027555

Epoch: 6| Step: 1
Training loss: 1.5039589405059814
Validation loss: 1.949949142753437

Epoch: 6| Step: 2
Training loss: 2.2168326377868652
Validation loss: 1.9444358541119484

Epoch: 6| Step: 3
Training loss: 2.381535053253174
Validation loss: 1.9637584686279297

Epoch: 6| Step: 4
Training loss: 2.886402130126953
Validation loss: 1.9515718362664665

Epoch: 6| Step: 5
Training loss: 1.9267858266830444
Validation loss: 1.9706663367568806

Epoch: 6| Step: 6
Training loss: 1.9069143533706665
Validation loss: 1.9624068147392684

Epoch: 6| Step: 7
Training loss: 2.046323776245117
Validation loss: 1.9571185393999981

Epoch: 6| Step: 8
Training loss: 1.9021039009094238
Validation loss: 1.9574821969514251

Epoch: 6| Step: 9
Training loss: 1.8106114864349365
Validation loss: 1.9631665791234663

Epoch: 6| Step: 10
Training loss: 1.829714059829712
Validation loss: 1.9741901172104703

Epoch: 6| Step: 11
Training loss: 2.394655704498291
Validation loss: 1.9666719923737228

Epoch: 6| Step: 12
Training loss: 2.2971103191375732
Validation loss: 1.9682280196938464

Epoch: 6| Step: 13
Training loss: 2.1271400451660156
Validation loss: 1.9643066583141204

Epoch: 128| Step: 0
Training loss: 1.8368918895721436
Validation loss: 1.9837706127474386

Epoch: 6| Step: 1
Training loss: 1.986167073249817
Validation loss: 1.951450087690866

Epoch: 6| Step: 2
Training loss: 2.0246472358703613
Validation loss: 1.9631530956555439

Epoch: 6| Step: 3
Training loss: 1.9850090742111206
Validation loss: 1.968015932267712

Epoch: 6| Step: 4
Training loss: 1.4001296758651733
Validation loss: 1.9383365723394579

Epoch: 6| Step: 5
Training loss: 2.5144717693328857
Validation loss: 1.9581827937915761

Epoch: 6| Step: 6
Training loss: 2.0499045848846436
Validation loss: 1.9780375367851668

Epoch: 6| Step: 7
Training loss: 1.4871054887771606
Validation loss: 1.951484421248077

Epoch: 6| Step: 8
Training loss: 2.3740406036376953
Validation loss: 1.9663069709654777

Epoch: 6| Step: 9
Training loss: 2.220231294631958
Validation loss: 1.9451994998480684

Epoch: 6| Step: 10
Training loss: 1.8288134336471558
Validation loss: 1.9605920686516711

Epoch: 6| Step: 11
Training loss: 2.0290169715881348
Validation loss: 1.9625381756854314

Epoch: 6| Step: 12
Training loss: 2.525266170501709
Validation loss: 1.9549444516499836

Epoch: 6| Step: 13
Training loss: 2.7541182041168213
Validation loss: 1.9326505020100584

Epoch: 129| Step: 0
Training loss: 2.291494607925415
Validation loss: 1.9569512246757426

Epoch: 6| Step: 1
Training loss: 2.5568952560424805
Validation loss: 1.947931275572828

Epoch: 6| Step: 2
Training loss: 1.6932106018066406
Validation loss: 1.9573629594618274

Epoch: 6| Step: 3
Training loss: 2.1156816482543945
Validation loss: 1.9655758924381708

Epoch: 6| Step: 4
Training loss: 1.8688130378723145
Validation loss: 1.951577558312365

Epoch: 6| Step: 5
Training loss: 1.6437556743621826
Validation loss: 1.936389568031475

Epoch: 6| Step: 6
Training loss: 2.29510760307312
Validation loss: 1.9506464171153244

Epoch: 6| Step: 7
Training loss: 2.379014492034912
Validation loss: 1.9571170653066328

Epoch: 6| Step: 8
Training loss: 1.3957254886627197
Validation loss: 1.9668782526446926

Epoch: 6| Step: 9
Training loss: 1.9616618156433105
Validation loss: 1.9473608052858742

Epoch: 6| Step: 10
Training loss: 2.142423152923584
Validation loss: 1.953710727794196

Epoch: 6| Step: 11
Training loss: 2.122997522354126
Validation loss: 1.9550129880187332

Epoch: 6| Step: 12
Training loss: 2.247750997543335
Validation loss: 1.9652318480194255

Epoch: 6| Step: 13
Training loss: 2.346454381942749
Validation loss: 1.9633471683789325

Epoch: 130| Step: 0
Training loss: 2.4901180267333984
Validation loss: 1.9491665747857863

Epoch: 6| Step: 1
Training loss: 1.583470344543457
Validation loss: 1.9583742874924854

Epoch: 6| Step: 2
Training loss: 2.3138604164123535
Validation loss: 1.9603550203384892

Epoch: 6| Step: 3
Training loss: 1.692203164100647
Validation loss: 1.9570832675503147

Epoch: 6| Step: 4
Training loss: 2.4370737075805664
Validation loss: 1.9508450749099895

Epoch: 6| Step: 5
Training loss: 1.8379219770431519
Validation loss: 1.9599063986091203

Epoch: 6| Step: 6
Training loss: 2.05405855178833
Validation loss: 1.9839616693476194

Epoch: 6| Step: 7
Training loss: 2.794079303741455
Validation loss: 1.9552843237435946

Epoch: 6| Step: 8
Training loss: 2.25174617767334
Validation loss: 1.992611103160407

Epoch: 6| Step: 9
Training loss: 1.7869223356246948
Validation loss: 1.9826467178201164

Epoch: 6| Step: 10
Training loss: 1.7882241010665894
Validation loss: 1.9606072787315614

Epoch: 6| Step: 11
Training loss: 1.320359230041504
Validation loss: 1.9626936886900215

Epoch: 6| Step: 12
Training loss: 2.461440086364746
Validation loss: 1.9574897699458624

Epoch: 6| Step: 13
Training loss: 2.2452261447906494
Validation loss: 1.9763014957468996

Epoch: 131| Step: 0
Training loss: 2.5600178241729736
Validation loss: 1.9428128914166523

Epoch: 6| Step: 1
Training loss: 2.1761271953582764
Validation loss: 1.9629054479701544

Epoch: 6| Step: 2
Training loss: 1.9842958450317383
Validation loss: 1.9556936717802478

Epoch: 6| Step: 3
Training loss: 2.2613086700439453
Validation loss: 1.9582753232730332

Epoch: 6| Step: 4
Training loss: 1.9392240047454834
Validation loss: 1.9614209000782301

Epoch: 6| Step: 5
Training loss: 2.1700520515441895
Validation loss: 1.9688890287953038

Epoch: 6| Step: 6
Training loss: 2.2793755531311035
Validation loss: 1.9878055562255204

Epoch: 6| Step: 7
Training loss: 1.2201459407806396
Validation loss: 1.962404876626948

Epoch: 6| Step: 8
Training loss: 3.1422231197357178
Validation loss: 1.9605262881966048

Epoch: 6| Step: 9
Training loss: 1.5769182443618774
Validation loss: 1.9562618719634188

Epoch: 6| Step: 10
Training loss: 2.143153190612793
Validation loss: 1.9945385866267706

Epoch: 6| Step: 11
Training loss: 0.9426414370536804
Validation loss: 1.9696487713885564

Epoch: 6| Step: 12
Training loss: 2.366335153579712
Validation loss: 1.9530178244395922

Epoch: 6| Step: 13
Training loss: 1.6195428371429443
Validation loss: 1.9648741163233274

Epoch: 132| Step: 0
Training loss: 2.3430001735687256
Validation loss: 1.959957529139775

Epoch: 6| Step: 1
Training loss: 2.104613780975342
Validation loss: 1.9465367024944675

Epoch: 6| Step: 2
Training loss: 2.746175527572632
Validation loss: 1.9389050006866455

Epoch: 6| Step: 3
Training loss: 1.6935303211212158
Validation loss: 1.9635258054220548

Epoch: 6| Step: 4
Training loss: 2.281435012817383
Validation loss: 1.9571575208376812

Epoch: 6| Step: 5
Training loss: 1.63407564163208
Validation loss: 1.9433751516444708

Epoch: 6| Step: 6
Training loss: 2.2001850605010986
Validation loss: 1.9323023083389446

Epoch: 6| Step: 7
Training loss: 2.2568182945251465
Validation loss: 1.9505675197929464

Epoch: 6| Step: 8
Training loss: 1.7590982913970947
Validation loss: 1.9691856420168312

Epoch: 6| Step: 9
Training loss: 1.1385389566421509
Validation loss: 1.9256653016613376

Epoch: 6| Step: 10
Training loss: 2.541698694229126
Validation loss: 1.957699966687028

Epoch: 6| Step: 11
Training loss: 1.9116764068603516
Validation loss: 1.9517227295906312

Epoch: 6| Step: 12
Training loss: 2.017909049987793
Validation loss: 1.9485631065983926

Epoch: 6| Step: 13
Training loss: 2.0706491470336914
Validation loss: 1.9412211102824057

Epoch: 133| Step: 0
Training loss: 2.68179988861084
Validation loss: 1.9375714691736365

Epoch: 6| Step: 1
Training loss: 2.0641932487487793
Validation loss: 1.9565171823706677

Epoch: 6| Step: 2
Training loss: 1.4990227222442627
Validation loss: 1.9465046531410628

Epoch: 6| Step: 3
Training loss: 1.9017717838287354
Validation loss: 1.9192846436654367

Epoch: 6| Step: 4
Training loss: 1.7848803997039795
Validation loss: 1.9485776296225927

Epoch: 6| Step: 5
Training loss: 1.6995887756347656
Validation loss: 1.952965356970346

Epoch: 6| Step: 6
Training loss: 2.245366096496582
Validation loss: 1.948330933047879

Epoch: 6| Step: 7
Training loss: 2.5957860946655273
Validation loss: 1.9667900710977533

Epoch: 6| Step: 8
Training loss: 2.0993590354919434
Validation loss: 1.9508954671121412

Epoch: 6| Step: 9
Training loss: 2.573356866836548
Validation loss: 1.9596970132602158

Epoch: 6| Step: 10
Training loss: 1.4241219758987427
Validation loss: 1.9640343650694816

Epoch: 6| Step: 11
Training loss: 1.7486393451690674
Validation loss: 1.9549130547431208

Epoch: 6| Step: 12
Training loss: 1.939397931098938
Validation loss: 1.9431653586767053

Epoch: 6| Step: 13
Training loss: 2.8518214225769043
Validation loss: 1.9641141788933867

Epoch: 134| Step: 0
Training loss: 1.9027574062347412
Validation loss: 1.9788228311846334

Epoch: 6| Step: 1
Training loss: 1.9561805725097656
Validation loss: 1.9461418069818968

Epoch: 6| Step: 2
Training loss: 1.5792012214660645
Validation loss: 1.9604303170275945

Epoch: 6| Step: 3
Training loss: 2.8083295822143555
Validation loss: 1.99069546627742

Epoch: 6| Step: 4
Training loss: 2.170279026031494
Validation loss: 1.9717836585096133

Epoch: 6| Step: 5
Training loss: 2.3621108531951904
Validation loss: 1.944041459791122

Epoch: 6| Step: 6
Training loss: 2.3959083557128906
Validation loss: 1.9729395015265352

Epoch: 6| Step: 7
Training loss: 2.125894546508789
Validation loss: 1.9481760904353151

Epoch: 6| Step: 8
Training loss: 1.5422213077545166
Validation loss: 1.9784315298962336

Epoch: 6| Step: 9
Training loss: 1.7622637748718262
Validation loss: 1.9775874371169715

Epoch: 6| Step: 10
Training loss: 1.9212086200714111
Validation loss: 1.986630029575799

Epoch: 6| Step: 11
Training loss: 2.1741716861724854
Validation loss: 1.959412190221971

Epoch: 6| Step: 12
Training loss: 1.6243923902511597
Validation loss: 1.9654684720500823

Epoch: 6| Step: 13
Training loss: 2.054967164993286
Validation loss: 1.9749677335062334

Epoch: 135| Step: 0
Training loss: 2.090847969055176
Validation loss: 1.9461419941276632

Epoch: 6| Step: 1
Training loss: 1.2875325679779053
Validation loss: 1.9591522844888831

Epoch: 6| Step: 2
Training loss: 1.7320328950881958
Validation loss: 1.956113685843765

Epoch: 6| Step: 3
Training loss: 2.0465853214263916
Validation loss: 1.9480766032331733

Epoch: 6| Step: 4
Training loss: 2.741703987121582
Validation loss: 1.959648088742328

Epoch: 6| Step: 5
Training loss: 2.8419158458709717
Validation loss: 1.9664094101998113

Epoch: 6| Step: 6
Training loss: 1.5490998029708862
Validation loss: 1.9155607197874336

Epoch: 6| Step: 7
Training loss: 1.997349739074707
Validation loss: 1.9683912877113587

Epoch: 6| Step: 8
Training loss: 1.9748055934906006
Validation loss: 1.9678749807419316

Epoch: 6| Step: 9
Training loss: 2.025862693786621
Validation loss: 1.966160379430299

Epoch: 6| Step: 10
Training loss: 1.7288234233856201
Validation loss: 1.9466056772457656

Epoch: 6| Step: 11
Training loss: 2.441565990447998
Validation loss: 1.9329384578171598

Epoch: 6| Step: 12
Training loss: 2.216792106628418
Validation loss: 1.9497803462448942

Epoch: 6| Step: 13
Training loss: 1.5243821144104004
Validation loss: 1.9481523729139758

Epoch: 136| Step: 0
Training loss: 1.8066821098327637
Validation loss: 1.9595583023563508

Epoch: 6| Step: 1
Training loss: 2.484355926513672
Validation loss: 1.9450810904143958

Epoch: 6| Step: 2
Training loss: 1.606919765472412
Validation loss: 1.9477880270250383

Epoch: 6| Step: 3
Training loss: 2.0694351196289062
Validation loss: 1.9300858718092724

Epoch: 6| Step: 4
Training loss: 2.0489213466644287
Validation loss: 1.9628964572824457

Epoch: 6| Step: 5
Training loss: 2.2708394527435303
Validation loss: 1.9423417532315819

Epoch: 6| Step: 6
Training loss: 1.7383129596710205
Validation loss: 1.956997138197704

Epoch: 6| Step: 7
Training loss: 1.6871678829193115
Validation loss: 1.9514542510432582

Epoch: 6| Step: 8
Training loss: 2.067556381225586
Validation loss: 1.9404511233811736

Epoch: 6| Step: 9
Training loss: 2.416863441467285
Validation loss: 1.960030681343489

Epoch: 6| Step: 10
Training loss: 1.9422101974487305
Validation loss: 1.9665725910535423

Epoch: 6| Step: 11
Training loss: 2.090489149093628
Validation loss: 1.9820176811628445

Epoch: 6| Step: 12
Training loss: 1.9511396884918213
Validation loss: 1.9720895726193663

Epoch: 6| Step: 13
Training loss: 2.3958215713500977
Validation loss: 1.9531175269875476

Epoch: 137| Step: 0
Training loss: 1.5412108898162842
Validation loss: 1.9345587299716087

Epoch: 6| Step: 1
Training loss: 2.0768423080444336
Validation loss: 1.9765372724943264

Epoch: 6| Step: 2
Training loss: 1.5860183238983154
Validation loss: 1.9588338457128054

Epoch: 6| Step: 3
Training loss: 1.85197114944458
Validation loss: 1.943528934191632

Epoch: 6| Step: 4
Training loss: 1.8672642707824707
Validation loss: 1.948249670767015

Epoch: 6| Step: 5
Training loss: 1.6304597854614258
Validation loss: 1.944785858995171

Epoch: 6| Step: 6
Training loss: 2.1767125129699707
Validation loss: 1.9642356800776657

Epoch: 6| Step: 7
Training loss: 2.0576765537261963
Validation loss: 1.9586726337350824

Epoch: 6| Step: 8
Training loss: 2.2804112434387207
Validation loss: 1.9392952098641345

Epoch: 6| Step: 9
Training loss: 2.6074655055999756
Validation loss: 1.9326231043825868

Epoch: 6| Step: 10
Training loss: 2.087108850479126
Validation loss: 1.9421316039177678

Epoch: 6| Step: 11
Training loss: 2.164219856262207
Validation loss: 1.9355673866887246

Epoch: 6| Step: 12
Training loss: 2.359636068344116
Validation loss: 1.9421176743763748

Epoch: 6| Step: 13
Training loss: 2.476222038269043
Validation loss: 1.9510470077555666

Epoch: 138| Step: 0
Training loss: 1.9992477893829346
Validation loss: 1.9546470283180155

Epoch: 6| Step: 1
Training loss: 1.6425282955169678
Validation loss: 1.9344144803221508

Epoch: 6| Step: 2
Training loss: 2.3243563175201416
Validation loss: 1.9440721452877086

Epoch: 6| Step: 3
Training loss: 2.4010214805603027
Validation loss: 1.952792183045418

Epoch: 6| Step: 4
Training loss: 1.7768151760101318
Validation loss: 1.9730252130057222

Epoch: 6| Step: 5
Training loss: 1.562142014503479
Validation loss: 1.9353012756634784

Epoch: 6| Step: 6
Training loss: 1.6927090883255005
Validation loss: 1.9499645925337268

Epoch: 6| Step: 7
Training loss: 2.0182151794433594
Validation loss: 1.9554528369698474

Epoch: 6| Step: 8
Training loss: 2.3578155040740967
Validation loss: 1.9647581936210714

Epoch: 6| Step: 9
Training loss: 2.151663303375244
Validation loss: 1.9495855185293383

Epoch: 6| Step: 10
Training loss: 2.5149874687194824
Validation loss: 1.9700545469919841

Epoch: 6| Step: 11
Training loss: 1.6928400993347168
Validation loss: 1.9605328421438895

Epoch: 6| Step: 12
Training loss: 2.299955368041992
Validation loss: 1.9601222084414573

Epoch: 6| Step: 13
Training loss: 2.188098907470703
Validation loss: 1.9326348381657754

Epoch: 139| Step: 0
Training loss: 2.096137523651123
Validation loss: 1.9505471465408162

Epoch: 6| Step: 1
Training loss: 1.801940679550171
Validation loss: 1.9457055522549538

Epoch: 6| Step: 2
Training loss: 2.3055081367492676
Validation loss: 1.9404612254070979

Epoch: 6| Step: 3
Training loss: 1.2981219291687012
Validation loss: 1.9641567353279359

Epoch: 6| Step: 4
Training loss: 2.595081090927124
Validation loss: 1.9519333506143222

Epoch: 6| Step: 5
Training loss: 2.6054985523223877
Validation loss: 1.9574905249380297

Epoch: 6| Step: 6
Training loss: 1.6307463645935059
Validation loss: 1.9207220026241836

Epoch: 6| Step: 7
Training loss: 2.072338581085205
Validation loss: 1.9332766302170292

Epoch: 6| Step: 8
Training loss: 2.335130214691162
Validation loss: 1.927639579260221

Epoch: 6| Step: 9
Training loss: 1.8941686153411865
Validation loss: 1.9467210692744101

Epoch: 6| Step: 10
Training loss: 1.611473798751831
Validation loss: 1.9437210982845676

Epoch: 6| Step: 11
Training loss: 1.5975580215454102
Validation loss: 1.957823181665072

Epoch: 6| Step: 12
Training loss: 2.716247081756592
Validation loss: 1.9380278805250764

Epoch: 6| Step: 13
Training loss: 1.533335566520691
Validation loss: 1.9616732187168573

Epoch: 140| Step: 0
Training loss: 1.6264898777008057
Validation loss: 1.944618781407674

Epoch: 6| Step: 1
Training loss: 1.6975986957550049
Validation loss: 1.946464857747478

Epoch: 6| Step: 2
Training loss: 1.8819695711135864
Validation loss: 1.9521979298642886

Epoch: 6| Step: 3
Training loss: 2.629218816757202
Validation loss: 1.9624160810183453

Epoch: 6| Step: 4
Training loss: 1.3672356605529785
Validation loss: 1.9816474042912966

Epoch: 6| Step: 5
Training loss: 2.3528926372528076
Validation loss: 1.960974093406431

Epoch: 6| Step: 6
Training loss: 2.0883803367614746
Validation loss: 1.9557191095044535

Epoch: 6| Step: 7
Training loss: 1.7964946031570435
Validation loss: 1.9539571833866898

Epoch: 6| Step: 8
Training loss: 1.5772665739059448
Validation loss: 1.985060720033543

Epoch: 6| Step: 9
Training loss: 2.942085027694702
Validation loss: 1.976911816545712

Epoch: 6| Step: 10
Training loss: 2.4735426902770996
Validation loss: 1.9810896842710433

Epoch: 6| Step: 11
Training loss: 1.9348392486572266
Validation loss: 1.968373711391162

Epoch: 6| Step: 12
Training loss: 2.2581558227539062
Validation loss: 1.9657665516740532

Epoch: 6| Step: 13
Training loss: 1.813352346420288
Validation loss: 1.9558272079754901

Epoch: 141| Step: 0
Training loss: 2.0815658569335938
Validation loss: 1.9633620054491105

Epoch: 6| Step: 1
Training loss: 2.0769643783569336
Validation loss: 1.967740567781592

Epoch: 6| Step: 2
Training loss: 1.8168658018112183
Validation loss: 1.9637197140724427

Epoch: 6| Step: 3
Training loss: 2.2095277309417725
Validation loss: 1.944033294595698

Epoch: 6| Step: 4
Training loss: 1.6640383005142212
Validation loss: 1.9357568333225865

Epoch: 6| Step: 5
Training loss: 2.353654384613037
Validation loss: 1.96337979326966

Epoch: 6| Step: 6
Training loss: 1.1985156536102295
Validation loss: 1.9262200837494226

Epoch: 6| Step: 7
Training loss: 2.7479281425476074
Validation loss: 1.9766826347638202

Epoch: 6| Step: 8
Training loss: 2.1572630405426025
Validation loss: 1.9500848836796258

Epoch: 6| Step: 9
Training loss: 1.8475055694580078
Validation loss: 1.9649660792402042

Epoch: 6| Step: 10
Training loss: 1.7653487920761108
Validation loss: 1.9525110580587899

Epoch: 6| Step: 11
Training loss: 1.7912817001342773
Validation loss: 1.9412574486065937

Epoch: 6| Step: 12
Training loss: 2.4506916999816895
Validation loss: 1.9393406632126018

Epoch: 6| Step: 13
Training loss: 2.129178047180176
Validation loss: 1.9435168453442153

Epoch: 142| Step: 0
Training loss: 1.661880612373352
Validation loss: 1.9438230901636102

Epoch: 6| Step: 1
Training loss: 1.372690200805664
Validation loss: 1.9164666744970507

Epoch: 6| Step: 2
Training loss: 3.050140142440796
Validation loss: 1.9534956716722058

Epoch: 6| Step: 3
Training loss: 2.30066180229187
Validation loss: 1.958619217718801

Epoch: 6| Step: 4
Training loss: 2.0215957164764404
Validation loss: 1.942557168263261

Epoch: 6| Step: 5
Training loss: 2.7944278717041016
Validation loss: 1.952345976265528

Epoch: 6| Step: 6
Training loss: 1.8914165496826172
Validation loss: 1.9371790603924823

Epoch: 6| Step: 7
Training loss: 1.6488263607025146
Validation loss: 1.9714088042577107

Epoch: 6| Step: 8
Training loss: 1.90121328830719
Validation loss: 1.9432020969288324

Epoch: 6| Step: 9
Training loss: 2.392637252807617
Validation loss: 1.9421028296152751

Epoch: 6| Step: 10
Training loss: 1.5764299631118774
Validation loss: 1.9665649731953938

Epoch: 6| Step: 11
Training loss: 1.780738115310669
Validation loss: 1.9522594277576735

Epoch: 6| Step: 12
Training loss: 2.0971243381500244
Validation loss: 1.9654919152618737

Epoch: 6| Step: 13
Training loss: 1.7337483167648315
Validation loss: 1.9419884912429317

Epoch: 143| Step: 0
Training loss: 2.385068416595459
Validation loss: 1.9484872407810663

Epoch: 6| Step: 1
Training loss: 2.51310396194458
Validation loss: 1.9443958651634954

Epoch: 6| Step: 2
Training loss: 1.6951773166656494
Validation loss: 1.9383471294115948

Epoch: 6| Step: 3
Training loss: 1.6887290477752686
Validation loss: 1.9385134866160731

Epoch: 6| Step: 4
Training loss: 2.098923683166504
Validation loss: 1.9349757291937386

Epoch: 6| Step: 5
Training loss: 2.003121852874756
Validation loss: 1.953305664882865

Epoch: 6| Step: 6
Training loss: 1.7542399168014526
Validation loss: 1.9551517066135202

Epoch: 6| Step: 7
Training loss: 2.1025829315185547
Validation loss: 1.9582641137543546

Epoch: 6| Step: 8
Training loss: 2.7975988388061523
Validation loss: 1.9644810307410456

Epoch: 6| Step: 9
Training loss: 1.3366132974624634
Validation loss: 1.9351366053345382

Epoch: 6| Step: 10
Training loss: 2.4752321243286133
Validation loss: 1.9449638551281345

Epoch: 6| Step: 11
Training loss: 1.975568175315857
Validation loss: 1.9341102543697561

Epoch: 6| Step: 12
Training loss: 1.4830842018127441
Validation loss: 1.9331054033771637

Epoch: 6| Step: 13
Training loss: 1.8345361948013306
Validation loss: 1.9452518186261576

Epoch: 144| Step: 0
Training loss: 1.8900376558303833
Validation loss: 1.9384166950820594

Epoch: 6| Step: 1
Training loss: 2.090536117553711
Validation loss: 1.9456216904424852

Epoch: 6| Step: 2
Training loss: 2.231694459915161
Validation loss: 1.9371497349072528

Epoch: 6| Step: 3
Training loss: 2.1499741077423096
Validation loss: 1.9539282245020713

Epoch: 6| Step: 4
Training loss: 1.6690423488616943
Validation loss: 1.9293181793664091

Epoch: 6| Step: 5
Training loss: 1.875689148902893
Validation loss: 1.91650301923034

Epoch: 6| Step: 6
Training loss: 2.661006212234497
Validation loss: 1.953074486024918

Epoch: 6| Step: 7
Training loss: 1.7541987895965576
Validation loss: 1.9199221339277042

Epoch: 6| Step: 8
Training loss: 2.618483781814575
Validation loss: 1.9503178724678614

Epoch: 6| Step: 9
Training loss: 1.7300703525543213
Validation loss: 1.9381688910145913

Epoch: 6| Step: 10
Training loss: 2.02260160446167
Validation loss: 1.961104962133592

Epoch: 6| Step: 11
Training loss: 1.6715483665466309
Validation loss: 1.9387016655296407

Epoch: 6| Step: 12
Training loss: 1.426203966140747
Validation loss: 1.959395711139966

Epoch: 6| Step: 13
Training loss: 2.5655593872070312
Validation loss: 1.9399430392890848

Epoch: 145| Step: 0
Training loss: 2.148381233215332
Validation loss: 1.9300686697806082

Epoch: 6| Step: 1
Training loss: 1.913999319076538
Validation loss: 1.960051731396747

Epoch: 6| Step: 2
Training loss: 2.047250270843506
Validation loss: 1.963918794867813

Epoch: 6| Step: 3
Training loss: 2.1722564697265625
Validation loss: 1.932913346957135

Epoch: 6| Step: 4
Training loss: 1.8941336870193481
Validation loss: 1.942585511874127

Epoch: 6| Step: 5
Training loss: 2.208630084991455
Validation loss: 1.9562983333423574

Epoch: 6| Step: 6
Training loss: 2.4108736515045166
Validation loss: 1.9423169858994023

Epoch: 6| Step: 7
Training loss: 1.9180078506469727
Validation loss: 1.9745833463566278

Epoch: 6| Step: 8
Training loss: 2.2181918621063232
Validation loss: 1.9290214148900842

Epoch: 6| Step: 9
Training loss: 2.0030107498168945
Validation loss: 1.9635848383749686

Epoch: 6| Step: 10
Training loss: 1.757469892501831
Validation loss: 1.946195892108384

Epoch: 6| Step: 11
Training loss: 1.7287780046463013
Validation loss: 1.9365579210301882

Epoch: 6| Step: 12
Training loss: 1.9981735944747925
Validation loss: 1.9506697923906389

Epoch: 6| Step: 13
Training loss: 1.6203149557113647
Validation loss: 1.9711773421174736

Epoch: 146| Step: 0
Training loss: 2.8673558235168457
Validation loss: 1.9517663294269192

Epoch: 6| Step: 1
Training loss: 1.5469906330108643
Validation loss: 1.9400951170152234

Epoch: 6| Step: 2
Training loss: 1.8323428630828857
Validation loss: 1.9572874153814008

Epoch: 6| Step: 3
Training loss: 2.073406219482422
Validation loss: 1.9403015528955767

Epoch: 6| Step: 4
Training loss: 2.590275764465332
Validation loss: 1.9495270662410285

Epoch: 6| Step: 5
Training loss: 0.9368587732315063
Validation loss: 1.9390487260715936

Epoch: 6| Step: 6
Training loss: 1.8900494575500488
Validation loss: 1.9478814127624675

Epoch: 6| Step: 7
Training loss: 2.364246129989624
Validation loss: 1.9260407724688131

Epoch: 6| Step: 8
Training loss: 1.965787410736084
Validation loss: 1.9552946462426135

Epoch: 6| Step: 9
Training loss: 2.074535846710205
Validation loss: 1.9572426144794752

Epoch: 6| Step: 10
Training loss: 2.288184881210327
Validation loss: 1.9499820381082513

Epoch: 6| Step: 11
Training loss: 1.8837231397628784
Validation loss: 1.9375148729611469

Epoch: 6| Step: 12
Training loss: 1.9573121070861816
Validation loss: 1.9151143963618944

Epoch: 6| Step: 13
Training loss: 1.5934667587280273
Validation loss: 1.9445462214049472

Epoch: 147| Step: 0
Training loss: 1.7267560958862305
Validation loss: 1.9604418072649228

Epoch: 6| Step: 1
Training loss: 2.1142165660858154
Validation loss: 1.938262180615497

Epoch: 6| Step: 2
Training loss: 1.5657005310058594
Validation loss: 1.9521197580522107

Epoch: 6| Step: 3
Training loss: 1.7432465553283691
Validation loss: 1.9483157165588871

Epoch: 6| Step: 4
Training loss: 1.9478930234909058
Validation loss: 1.942492324818847

Epoch: 6| Step: 5
Training loss: 1.9924681186676025
Validation loss: 1.9452254387640184

Epoch: 6| Step: 6
Training loss: 1.8411272764205933
Validation loss: 1.9423953922845985

Epoch: 6| Step: 7
Training loss: 1.598576307296753
Validation loss: 1.9502936268365512

Epoch: 6| Step: 8
Training loss: 2.4965832233428955
Validation loss: 1.9376300124711887

Epoch: 6| Step: 9
Training loss: 3.2362265586853027
Validation loss: 1.926917432456888

Epoch: 6| Step: 10
Training loss: 1.8462488651275635
Validation loss: 1.9374287743722238

Epoch: 6| Step: 11
Training loss: 2.08640718460083
Validation loss: 1.9292376451594855

Epoch: 6| Step: 12
Training loss: 2.064011812210083
Validation loss: 1.963338557110038

Epoch: 6| Step: 13
Training loss: 1.4946712255477905
Validation loss: 1.9445491426734514

Epoch: 148| Step: 0
Training loss: 1.8038614988327026
Validation loss: 1.9351968944713633

Epoch: 6| Step: 1
Training loss: 2.524465799331665
Validation loss: 1.9597613183400964

Epoch: 6| Step: 2
Training loss: 2.5036063194274902
Validation loss: 1.9645438014820058

Epoch: 6| Step: 3
Training loss: 1.8023747205734253
Validation loss: 1.9540539762025237

Epoch: 6| Step: 4
Training loss: 1.8193719387054443
Validation loss: 1.9576408209339264

Epoch: 6| Step: 5
Training loss: 2.1229891777038574
Validation loss: 1.9466785025852982

Epoch: 6| Step: 6
Training loss: 2.3505258560180664
Validation loss: 1.9331524500282862

Epoch: 6| Step: 7
Training loss: 1.8806638717651367
Validation loss: 1.9335375793518559

Epoch: 6| Step: 8
Training loss: 1.8767198324203491
Validation loss: 1.9365229606628418

Epoch: 6| Step: 9
Training loss: 2.537001371383667
Validation loss: 1.9165492506437405

Epoch: 6| Step: 10
Training loss: 1.2892913818359375
Validation loss: 1.949217034924415

Epoch: 6| Step: 11
Training loss: 1.6885126829147339
Validation loss: 1.9514934221903484

Epoch: 6| Step: 12
Training loss: 1.842545747756958
Validation loss: 1.9651189927131898

Epoch: 6| Step: 13
Training loss: 1.8850334882736206
Validation loss: 1.9585225902577883

Epoch: 149| Step: 0
Training loss: 2.2532401084899902
Validation loss: 1.936644987393451

Epoch: 6| Step: 1
Training loss: 2.2144055366516113
Validation loss: 1.9406255137535833

Epoch: 6| Step: 2
Training loss: 1.8644368648529053
Validation loss: 1.9388737781073457

Epoch: 6| Step: 3
Training loss: 2.1392464637756348
Validation loss: 1.9307257372845885

Epoch: 6| Step: 4
Training loss: 2.0513787269592285
Validation loss: 1.942681998334905

Epoch: 6| Step: 5
Training loss: 1.2976605892181396
Validation loss: 1.9683446730336835

Epoch: 6| Step: 6
Training loss: 2.222001075744629
Validation loss: 1.95770537981423

Epoch: 6| Step: 7
Training loss: 1.7738263607025146
Validation loss: 1.9550916558952742

Epoch: 6| Step: 8
Training loss: 1.9197072982788086
Validation loss: 1.921357640656092

Epoch: 6| Step: 9
Training loss: 2.43704891204834
Validation loss: 1.9398032619107155

Epoch: 6| Step: 10
Training loss: 2.1539316177368164
Validation loss: 1.9533917134807957

Epoch: 6| Step: 11
Training loss: 1.5101619958877563
Validation loss: 1.9379002201941706

Epoch: 6| Step: 12
Training loss: 2.231917142868042
Validation loss: 1.9315376948284846

Epoch: 6| Step: 13
Training loss: 1.4920045137405396
Validation loss: 1.9144920405521189

Epoch: 150| Step: 0
Training loss: 1.8501499891281128
Validation loss: 1.9360269679818103

Epoch: 6| Step: 1
Training loss: 1.6928237676620483
Validation loss: 1.9447251878758913

Epoch: 6| Step: 2
Training loss: 2.0847091674804688
Validation loss: 1.9267467555179392

Epoch: 6| Step: 3
Training loss: 1.6627662181854248
Validation loss: 1.9353727076643257

Epoch: 6| Step: 4
Training loss: 3.1777212619781494
Validation loss: 1.9505629180580057

Epoch: 6| Step: 5
Training loss: 1.9406590461730957
Validation loss: 1.9410146000564739

Epoch: 6| Step: 6
Training loss: 1.659891963005066
Validation loss: 1.9429425680509178

Epoch: 6| Step: 7
Training loss: 2.135937213897705
Validation loss: 1.9492488202228342

Epoch: 6| Step: 8
Training loss: 2.4728829860687256
Validation loss: 1.9709416768884147

Epoch: 6| Step: 9
Training loss: 2.5610532760620117
Validation loss: 1.952195563623982

Epoch: 6| Step: 10
Training loss: 2.4732141494750977
Validation loss: 1.9435771460174232

Epoch: 6| Step: 11
Training loss: 1.5777705907821655
Validation loss: 1.9458457744249733

Epoch: 6| Step: 12
Training loss: 1.1176280975341797
Validation loss: 1.9592876011325466

Epoch: 6| Step: 13
Training loss: 1.2961674928665161
Validation loss: 1.942816501022667

Epoch: 151| Step: 0
Training loss: 1.115260362625122
Validation loss: 1.9504254505198488

Epoch: 6| Step: 1
Training loss: 1.4835056066513062
Validation loss: 1.9457525207150368

Epoch: 6| Step: 2
Training loss: 2.139376163482666
Validation loss: 1.9421026578513525

Epoch: 6| Step: 3
Training loss: 1.7626872062683105
Validation loss: 1.9260359912790277

Epoch: 6| Step: 4
Training loss: 1.9775420427322388
Validation loss: 1.9671439855329451

Epoch: 6| Step: 5
Training loss: 2.3543248176574707
Validation loss: 1.9239496774570917

Epoch: 6| Step: 6
Training loss: 2.2245936393737793
Validation loss: 1.9334949088352982

Epoch: 6| Step: 7
Training loss: 2.0790045261383057
Validation loss: 1.9424472701164983

Epoch: 6| Step: 8
Training loss: 1.8840421438217163
Validation loss: 1.9332412686399234

Epoch: 6| Step: 9
Training loss: 1.9880560636520386
Validation loss: 1.9417403821022279

Epoch: 6| Step: 10
Training loss: 2.1980385780334473
Validation loss: 1.9307776663893013

Epoch: 6| Step: 11
Training loss: 2.6024861335754395
Validation loss: 1.9271389822806082

Epoch: 6| Step: 12
Training loss: 2.1307451725006104
Validation loss: 1.916654348373413

Epoch: 6| Step: 13
Training loss: 1.8217337131500244
Validation loss: 1.9197350535341489

Epoch: 152| Step: 0
Training loss: 2.718449592590332
Validation loss: 1.946464318101124

Epoch: 6| Step: 1
Training loss: 2.058917284011841
Validation loss: 1.9516938296697472

Epoch: 6| Step: 2
Training loss: 1.035552978515625
Validation loss: 1.9483132093183455

Epoch: 6| Step: 3
Training loss: 2.358139991760254
Validation loss: 1.952855504969115

Epoch: 6| Step: 4
Training loss: 1.8093414306640625
Validation loss: 1.9798612671513711

Epoch: 6| Step: 5
Training loss: 1.822939395904541
Validation loss: 1.945935264710457

Epoch: 6| Step: 6
Training loss: 1.729217290878296
Validation loss: 1.9366066199477001

Epoch: 6| Step: 7
Training loss: 1.7769386768341064
Validation loss: 1.963436818891956

Epoch: 6| Step: 8
Training loss: 1.905791163444519
Validation loss: 1.9574256622663109

Epoch: 6| Step: 9
Training loss: 2.204336166381836
Validation loss: 1.954816391391139

Epoch: 6| Step: 10
Training loss: 2.119523048400879
Validation loss: 1.9536953280048985

Epoch: 6| Step: 11
Training loss: 2.1889729499816895
Validation loss: 1.946864979241484

Epoch: 6| Step: 12
Training loss: 2.41965389251709
Validation loss: 1.9402514632030199

Epoch: 6| Step: 13
Training loss: 1.4650250673294067
Validation loss: 1.953298766125915

Epoch: 153| Step: 0
Training loss: 2.5270845890045166
Validation loss: 1.9637132536980413

Epoch: 6| Step: 1
Training loss: 2.27614164352417
Validation loss: 1.931234134140835

Epoch: 6| Step: 2
Training loss: 1.552525281906128
Validation loss: 1.9332724271282073

Epoch: 6| Step: 3
Training loss: 2.7608633041381836
Validation loss: 1.9220560789108276

Epoch: 6| Step: 4
Training loss: 1.8105080127716064
Validation loss: 1.9290288507297475

Epoch: 6| Step: 5
Training loss: 2.490985870361328
Validation loss: 1.9293310975515714

Epoch: 6| Step: 6
Training loss: 0.9459495544433594
Validation loss: 1.9542884621568906

Epoch: 6| Step: 7
Training loss: 2.321458578109741
Validation loss: 1.9194795880266415

Epoch: 6| Step: 8
Training loss: 1.5830597877502441
Validation loss: 1.931688923989573

Epoch: 6| Step: 9
Training loss: 1.6100566387176514
Validation loss: 1.9334900212544266

Epoch: 6| Step: 10
Training loss: 1.7898199558258057
Validation loss: 1.950057396324732

Epoch: 6| Step: 11
Training loss: 2.083753824234009
Validation loss: 1.9228776885617165

Epoch: 6| Step: 12
Training loss: 2.1669015884399414
Validation loss: 1.9438903908575735

Epoch: 6| Step: 13
Training loss: 1.7055870294570923
Validation loss: 1.9288847318259619

Epoch: 154| Step: 0
Training loss: 2.1658427715301514
Validation loss: 1.9158291816711426

Epoch: 6| Step: 1
Training loss: 1.993645429611206
Validation loss: 1.9188374806475896

Epoch: 6| Step: 2
Training loss: 2.0518174171447754
Validation loss: 1.949642499287923

Epoch: 6| Step: 3
Training loss: 2.03816556930542
Validation loss: 1.9128823703335178

Epoch: 6| Step: 4
Training loss: 1.4727592468261719
Validation loss: 1.918136017296904

Epoch: 6| Step: 5
Training loss: 2.7054522037506104
Validation loss: 1.9431147254923338

Epoch: 6| Step: 6
Training loss: 1.4155519008636475
Validation loss: 1.9554764891183505

Epoch: 6| Step: 7
Training loss: 1.6780166625976562
Validation loss: 1.9344770703264462

Epoch: 6| Step: 8
Training loss: 1.998201608657837
Validation loss: 1.942575167584163

Epoch: 6| Step: 9
Training loss: 2.0903046131134033
Validation loss: 1.9272191678324053

Epoch: 6| Step: 10
Training loss: 1.8469960689544678
Validation loss: 1.93470291168459

Epoch: 6| Step: 11
Training loss: 2.1082000732421875
Validation loss: 1.9415927958744827

Epoch: 6| Step: 12
Training loss: 1.7695345878601074
Validation loss: 1.9208715756734211

Epoch: 6| Step: 13
Training loss: 2.47788143157959
Validation loss: 1.9167109227949573

Epoch: 155| Step: 0
Training loss: 1.4955434799194336
Validation loss: 1.9422841200264551

Epoch: 6| Step: 1
Training loss: 2.5429728031158447
Validation loss: 1.9312629033160467

Epoch: 6| Step: 2
Training loss: 2.8315014839172363
Validation loss: 1.942901175509217

Epoch: 6| Step: 3
Training loss: 2.4605393409729004
Validation loss: 1.93166858150113

Epoch: 6| Step: 4
Training loss: 1.7133378982543945
Validation loss: 1.9617438649618497

Epoch: 6| Step: 5
Training loss: 1.946386694908142
Validation loss: 1.939032223916823

Epoch: 6| Step: 6
Training loss: 2.103604555130005
Validation loss: 1.9522375317030056

Epoch: 6| Step: 7
Training loss: 1.5423102378845215
Validation loss: 1.9514545676528767

Epoch: 6| Step: 8
Training loss: 1.9366434812545776
Validation loss: 1.9590278107632872

Epoch: 6| Step: 9
Training loss: 1.6044929027557373
Validation loss: 1.9650161035599247

Epoch: 6| Step: 10
Training loss: 2.239692449569702
Validation loss: 1.9754443207094747

Epoch: 6| Step: 11
Training loss: 1.9964512586593628
Validation loss: 1.9377592161137571

Epoch: 6| Step: 12
Training loss: 1.5350135564804077
Validation loss: 1.952442580653775

Epoch: 6| Step: 13
Training loss: 1.5343928337097168
Validation loss: 1.9630191761960265

Epoch: 156| Step: 0
Training loss: 1.506654977798462
Validation loss: 1.9651425948707006

Epoch: 6| Step: 1
Training loss: 1.752733588218689
Validation loss: 1.939163900190784

Epoch: 6| Step: 2
Training loss: 2.4478697776794434
Validation loss: 1.943987411837424

Epoch: 6| Step: 3
Training loss: 2.295924186706543
Validation loss: 1.9266525904337566

Epoch: 6| Step: 4
Training loss: 2.1580183506011963
Validation loss: 1.9098421348038541

Epoch: 6| Step: 5
Training loss: 1.6673600673675537
Validation loss: 1.9355160292758737

Epoch: 6| Step: 6
Training loss: 2.1850149631500244
Validation loss: 1.9403228952038674

Epoch: 6| Step: 7
Training loss: 1.9958930015563965
Validation loss: 1.9366400472579464

Epoch: 6| Step: 8
Training loss: 1.8413875102996826
Validation loss: 1.9433787920141732

Epoch: 6| Step: 9
Training loss: 2.4365854263305664
Validation loss: 1.9405485558253464

Epoch: 6| Step: 10
Training loss: 2.208172559738159
Validation loss: 1.9154007691209034

Epoch: 6| Step: 11
Training loss: 1.4904980659484863
Validation loss: 1.9249758412761073

Epoch: 6| Step: 12
Training loss: 1.6641721725463867
Validation loss: 1.950466150878578

Epoch: 6| Step: 13
Training loss: 1.90858793258667
Validation loss: 1.9336427770635134

Epoch: 157| Step: 0
Training loss: 2.1359832286834717
Validation loss: 1.9428700554755427

Epoch: 6| Step: 1
Training loss: 1.420764684677124
Validation loss: 1.9372374588443386

Epoch: 6| Step: 2
Training loss: 2.7695722579956055
Validation loss: 1.916960411174323

Epoch: 6| Step: 3
Training loss: 1.683469533920288
Validation loss: 1.9554957330867808

Epoch: 6| Step: 4
Training loss: 2.579558849334717
Validation loss: 1.9366475715432117

Epoch: 6| Step: 5
Training loss: 2.0034046173095703
Validation loss: 1.9409943472954534

Epoch: 6| Step: 6
Training loss: 2.8327770233154297
Validation loss: 1.9461145401000977

Epoch: 6| Step: 7
Training loss: 1.6269559860229492
Validation loss: 1.9528876901954733

Epoch: 6| Step: 8
Training loss: 1.5625874996185303
Validation loss: 1.9547481549683439

Epoch: 6| Step: 9
Training loss: 1.5615315437316895
Validation loss: 1.9526429509603849

Epoch: 6| Step: 10
Training loss: 1.9954605102539062
Validation loss: 1.9356096290772962

Epoch: 6| Step: 11
Training loss: 2.235464572906494
Validation loss: 1.9268329861343547

Epoch: 6| Step: 12
Training loss: 1.610098958015442
Validation loss: 1.9282260658920451

Epoch: 6| Step: 13
Training loss: 1.2404731512069702
Validation loss: 1.9551161566088278

Epoch: 158| Step: 0
Training loss: 1.7619448900222778
Validation loss: 1.9313132583454091

Epoch: 6| Step: 1
Training loss: 2.685485601425171
Validation loss: 1.937984074315717

Epoch: 6| Step: 2
Training loss: 1.7672101259231567
Validation loss: 1.9265368535954466

Epoch: 6| Step: 3
Training loss: 2.0999643802642822
Validation loss: 1.9300965878271288

Epoch: 6| Step: 4
Training loss: 1.900913953781128
Validation loss: 1.9145044075545443

Epoch: 6| Step: 5
Training loss: 1.3555810451507568
Validation loss: 1.9442413699242376

Epoch: 6| Step: 6
Training loss: 2.1965293884277344
Validation loss: 1.9334337967698292

Epoch: 6| Step: 7
Training loss: 2.1479454040527344
Validation loss: 1.9225301922008555

Epoch: 6| Step: 8
Training loss: 1.7875356674194336
Validation loss: 1.9335950279748568

Epoch: 6| Step: 9
Training loss: 2.477412223815918
Validation loss: 1.9479937886679044

Epoch: 6| Step: 10
Training loss: 1.533845067024231
Validation loss: 1.9153761222798338

Epoch: 6| Step: 11
Training loss: 1.8963465690612793
Validation loss: 1.9326092248321862

Epoch: 6| Step: 12
Training loss: 1.7918955087661743
Validation loss: 1.9307246413282169

Epoch: 6| Step: 13
Training loss: 2.322634220123291
Validation loss: 1.9491762486837243

Epoch: 159| Step: 0
Training loss: 1.7156085968017578
Validation loss: 1.922586428221836

Epoch: 6| Step: 1
Training loss: 2.213620185852051
Validation loss: 1.9186028383111442

Epoch: 6| Step: 2
Training loss: 1.2611913681030273
Validation loss: 1.9427564810681086

Epoch: 6| Step: 3
Training loss: 1.9290196895599365
Validation loss: 1.9530893064314319

Epoch: 6| Step: 4
Training loss: 2.241990566253662
Validation loss: 1.9276553405228483

Epoch: 6| Step: 5
Training loss: 1.3054382801055908
Validation loss: 1.9679500082487702

Epoch: 6| Step: 6
Training loss: 1.8376126289367676
Validation loss: 1.9339546042103921

Epoch: 6| Step: 7
Training loss: 1.647296667098999
Validation loss: 1.931509453763244

Epoch: 6| Step: 8
Training loss: 2.7084007263183594
Validation loss: 1.9292295235459522

Epoch: 6| Step: 9
Training loss: 2.4176573753356934
Validation loss: 1.9225356822372766

Epoch: 6| Step: 10
Training loss: 1.7695764303207397
Validation loss: 1.929579988602669

Epoch: 6| Step: 11
Training loss: 2.4181694984436035
Validation loss: 1.9421185331959878

Epoch: 6| Step: 12
Training loss: 2.0485901832580566
Validation loss: 1.9275241756951937

Epoch: 6| Step: 13
Training loss: 2.5262632369995117
Validation loss: 1.9295482776498283

Epoch: 160| Step: 0
Training loss: 1.9295262098312378
Validation loss: 1.9381693768244919

Epoch: 6| Step: 1
Training loss: 2.4646944999694824
Validation loss: 1.9509229198578866

Epoch: 6| Step: 2
Training loss: 2.095040798187256
Validation loss: 1.9603263460179812

Epoch: 6| Step: 3
Training loss: 1.4561712741851807
Validation loss: 1.9500548826750888

Epoch: 6| Step: 4
Training loss: 1.4452779293060303
Validation loss: 1.952183488876589

Epoch: 6| Step: 5
Training loss: 1.4669121503829956
Validation loss: 1.9511677244658112

Epoch: 6| Step: 6
Training loss: 2.28409481048584
Validation loss: 1.9761509638960644

Epoch: 6| Step: 7
Training loss: 1.6473639011383057
Validation loss: 1.9469509304210704

Epoch: 6| Step: 8
Training loss: 2.014145851135254
Validation loss: 1.9654923715899069

Epoch: 6| Step: 9
Training loss: 1.7529386281967163
Validation loss: 1.9382277291308168

Epoch: 6| Step: 10
Training loss: 1.9262150526046753
Validation loss: 1.9595148255748134

Epoch: 6| Step: 11
Training loss: 2.801072120666504
Validation loss: 1.928889238706199

Epoch: 6| Step: 12
Training loss: 2.3200082778930664
Validation loss: 1.944935675590269

Epoch: 6| Step: 13
Training loss: 1.8575600385665894
Validation loss: 1.9459114202889063

Epoch: 161| Step: 0
Training loss: 1.8263638019561768
Validation loss: 1.9383543358054212

Epoch: 6| Step: 1
Training loss: 2.4424962997436523
Validation loss: 1.9669034404139365

Epoch: 6| Step: 2
Training loss: 1.55828857421875
Validation loss: 1.926962714041433

Epoch: 6| Step: 3
Training loss: 1.6528956890106201
Validation loss: 1.9482189942431707

Epoch: 6| Step: 4
Training loss: 1.9818220138549805
Validation loss: 1.9577487566137826

Epoch: 6| Step: 5
Training loss: 1.3046855926513672
Validation loss: 1.933960868466285

Epoch: 6| Step: 6
Training loss: 2.503110885620117
Validation loss: 1.927177163862413

Epoch: 6| Step: 7
Training loss: 2.378086805343628
Validation loss: 1.9158528927833802

Epoch: 6| Step: 8
Training loss: 1.4347643852233887
Validation loss: 1.9265359422212005

Epoch: 6| Step: 9
Training loss: 2.0861752033233643
Validation loss: 1.9326178540465653

Epoch: 6| Step: 10
Training loss: 1.715482234954834
Validation loss: 1.9345525362158333

Epoch: 6| Step: 11
Training loss: 2.6042046546936035
Validation loss: 1.9311760702440817

Epoch: 6| Step: 12
Training loss: 1.8936344385147095
Validation loss: 1.9187810113353114

Epoch: 6| Step: 13
Training loss: 2.3403120040893555
Validation loss: 1.9406415852167274

Epoch: 162| Step: 0
Training loss: 2.3675761222839355
Validation loss: 1.9208542941718973

Epoch: 6| Step: 1
Training loss: 1.8125863075256348
Validation loss: 1.9454858379979287

Epoch: 6| Step: 2
Training loss: 2.5525739192962646
Validation loss: 1.915871427905175

Epoch: 6| Step: 3
Training loss: 2.1149191856384277
Validation loss: 1.9526912038044264

Epoch: 6| Step: 4
Training loss: 2.0517773628234863
Validation loss: 1.9307693768573064

Epoch: 6| Step: 5
Training loss: 1.8452153205871582
Validation loss: 1.9174687118940457

Epoch: 6| Step: 6
Training loss: 1.6459197998046875
Validation loss: 1.9339899837329824

Epoch: 6| Step: 7
Training loss: 1.3396432399749756
Validation loss: 1.9172485477180892

Epoch: 6| Step: 8
Training loss: 1.8649142980575562
Validation loss: 1.9342942442945255

Epoch: 6| Step: 9
Training loss: 1.3702086210250854
Validation loss: 1.948651297118074

Epoch: 6| Step: 10
Training loss: 1.7873427867889404
Validation loss: 1.960053623363536

Epoch: 6| Step: 11
Training loss: 2.3683600425720215
Validation loss: 1.9407487966681038

Epoch: 6| Step: 12
Training loss: 2.039968729019165
Validation loss: 1.9531108974128641

Epoch: 6| Step: 13
Training loss: 2.6720285415649414
Validation loss: 1.9694953298055997

Epoch: 163| Step: 0
Training loss: 1.7787690162658691
Validation loss: 1.951911731432843

Epoch: 6| Step: 1
Training loss: 2.349876880645752
Validation loss: 1.97665697784834

Epoch: 6| Step: 2
Training loss: 1.9490989446640015
Validation loss: 1.9484307137868737

Epoch: 6| Step: 3
Training loss: 2.2498037815093994
Validation loss: 1.9559223216067079

Epoch: 6| Step: 4
Training loss: 2.290591239929199
Validation loss: 1.960901261657797

Epoch: 6| Step: 5
Training loss: 1.5835695266723633
Validation loss: 1.954067430188579

Epoch: 6| Step: 6
Training loss: 2.410660743713379
Validation loss: 1.9434301109724148

Epoch: 6| Step: 7
Training loss: 1.9552180767059326
Validation loss: 1.9739093357516873

Epoch: 6| Step: 8
Training loss: 1.532594919204712
Validation loss: 1.9701264058389971

Epoch: 6| Step: 9
Training loss: 1.5758103132247925
Validation loss: 1.9569344738478303

Epoch: 6| Step: 10
Training loss: 1.8411900997161865
Validation loss: 1.9720720898720525

Epoch: 6| Step: 11
Training loss: 1.966261863708496
Validation loss: 1.9816598071846911

Epoch: 6| Step: 12
Training loss: 2.2742466926574707
Validation loss: 1.95590986487686

Epoch: 6| Step: 13
Training loss: 1.462151050567627
Validation loss: 1.945642158549319

Epoch: 164| Step: 0
Training loss: 1.9687782526016235
Validation loss: 1.9526374519512217

Epoch: 6| Step: 1
Training loss: 2.0219624042510986
Validation loss: 1.9346020747256536

Epoch: 6| Step: 2
Training loss: 1.1916619539260864
Validation loss: 1.9640752730831024

Epoch: 6| Step: 3
Training loss: 1.7677098512649536
Validation loss: 1.9446615852335447

Epoch: 6| Step: 4
Training loss: 2.7475943565368652
Validation loss: 1.927145879755738

Epoch: 6| Step: 5
Training loss: 1.020491361618042
Validation loss: 1.9484965993512062

Epoch: 6| Step: 6
Training loss: 1.4280167818069458
Validation loss: 1.9344838485922864

Epoch: 6| Step: 7
Training loss: 2.0219693183898926
Validation loss: 1.9448798177062825

Epoch: 6| Step: 8
Training loss: 1.869275450706482
Validation loss: 1.9307479076488043

Epoch: 6| Step: 9
Training loss: 2.0597543716430664
Validation loss: 1.9410281655608967

Epoch: 6| Step: 10
Training loss: 2.9184041023254395
Validation loss: 1.9319725408348987

Epoch: 6| Step: 11
Training loss: 1.6980936527252197
Validation loss: 1.947334156241468

Epoch: 6| Step: 12
Training loss: 2.5966720581054688
Validation loss: 1.9182754844747565

Epoch: 6| Step: 13
Training loss: 1.7347440719604492
Validation loss: 1.9485747173268309

Epoch: 165| Step: 0
Training loss: 1.981867790222168
Validation loss: 1.9362549371616815

Epoch: 6| Step: 1
Training loss: 2.2133877277374268
Validation loss: 1.909045885967952

Epoch: 6| Step: 2
Training loss: 1.9690579175949097
Validation loss: 1.9154850513704362

Epoch: 6| Step: 3
Training loss: 1.879909873008728
Validation loss: 1.9271406614652244

Epoch: 6| Step: 4
Training loss: 2.1435489654541016
Validation loss: 1.926223526718796

Epoch: 6| Step: 5
Training loss: 2.022840976715088
Validation loss: 1.947203770760567

Epoch: 6| Step: 6
Training loss: 1.8078469038009644
Validation loss: 1.9335410748758624

Epoch: 6| Step: 7
Training loss: 1.791863203048706
Validation loss: 1.945182470865147

Epoch: 6| Step: 8
Training loss: 2.207995891571045
Validation loss: 1.9158827950877528

Epoch: 6| Step: 9
Training loss: 1.7716597318649292
Validation loss: 1.9400256269721574

Epoch: 6| Step: 10
Training loss: 1.7233574390411377
Validation loss: 1.9330732437872118

Epoch: 6| Step: 11
Training loss: 2.2654619216918945
Validation loss: 1.9329620125473186

Epoch: 6| Step: 12
Training loss: 1.9619048833847046
Validation loss: 1.9450307238486506

Epoch: 6| Step: 13
Training loss: 1.126616358757019
Validation loss: 1.9422978124310892

Epoch: 166| Step: 0
Training loss: 1.8920185565948486
Validation loss: 1.941197669634255

Epoch: 6| Step: 1
Training loss: 2.0004048347473145
Validation loss: 1.9529245822660384

Epoch: 6| Step: 2
Training loss: 2.1428427696228027
Validation loss: 1.928188564956829

Epoch: 6| Step: 3
Training loss: 1.8224945068359375
Validation loss: 1.9647982325605167

Epoch: 6| Step: 4
Training loss: 1.492618203163147
Validation loss: 1.9453293751644831

Epoch: 6| Step: 5
Training loss: 1.8617182970046997
Validation loss: 1.928911301397508

Epoch: 6| Step: 6
Training loss: 1.868711233139038
Validation loss: 1.929095725859365

Epoch: 6| Step: 7
Training loss: 2.0372860431671143
Validation loss: 1.9595231458704958

Epoch: 6| Step: 8
Training loss: 1.774667501449585
Validation loss: 1.9400509172870266

Epoch: 6| Step: 9
Training loss: 1.5020835399627686
Validation loss: 1.931080343902752

Epoch: 6| Step: 10
Training loss: 1.7876834869384766
Validation loss: 1.9545971860167801

Epoch: 6| Step: 11
Training loss: 2.187406063079834
Validation loss: 1.9229312276327482

Epoch: 6| Step: 12
Training loss: 2.4685885906219482
Validation loss: 1.9647503886171567

Epoch: 6| Step: 13
Training loss: 2.5256998538970947
Validation loss: 1.9291869055840276

Epoch: 167| Step: 0
Training loss: 1.8242425918579102
Validation loss: 1.9577159061226794

Epoch: 6| Step: 1
Training loss: 1.8230422735214233
Validation loss: 1.9466331171733078

Epoch: 6| Step: 2
Training loss: 1.823265790939331
Validation loss: 1.9475259396337694

Epoch: 6| Step: 3
Training loss: 2.0701332092285156
Validation loss: 1.942764260435617

Epoch: 6| Step: 4
Training loss: 2.139092445373535
Validation loss: 1.94608251894674

Epoch: 6| Step: 5
Training loss: 1.7747600078582764
Validation loss: 1.9481263365796817

Epoch: 6| Step: 6
Training loss: 2.090906858444214
Validation loss: 1.9385875002030404

Epoch: 6| Step: 7
Training loss: 2.0547094345092773
Validation loss: 1.9266468978697253

Epoch: 6| Step: 8
Training loss: 2.1196305751800537
Validation loss: 1.9125469307745657

Epoch: 6| Step: 9
Training loss: 1.7599303722381592
Validation loss: 1.9237909176016366

Epoch: 6| Step: 10
Training loss: 1.96560537815094
Validation loss: 1.935486989636575

Epoch: 6| Step: 11
Training loss: 2.2864022254943848
Validation loss: 1.9293470331417617

Epoch: 6| Step: 12
Training loss: 1.7665376663208008
Validation loss: 1.9264682313447357

Epoch: 6| Step: 13
Training loss: 1.711206078529358
Validation loss: 1.9258716555051907

Epoch: 168| Step: 0
Training loss: 1.8152731657028198
Validation loss: 1.92130829698296

Epoch: 6| Step: 1
Training loss: 1.9503449201583862
Validation loss: 1.9212270603385022

Epoch: 6| Step: 2
Training loss: 1.3104171752929688
Validation loss: 1.9326717097272155

Epoch: 6| Step: 3
Training loss: 2.038571834564209
Validation loss: 1.9210793549014675

Epoch: 6| Step: 4
Training loss: 1.8731664419174194
Validation loss: 1.9253628433391612

Epoch: 6| Step: 5
Training loss: 1.9936732053756714
Validation loss: 1.9476324871022215

Epoch: 6| Step: 6
Training loss: 2.124084711074829
Validation loss: 1.9321384417113436

Epoch: 6| Step: 7
Training loss: 2.048602342605591
Validation loss: 1.9237584273020427

Epoch: 6| Step: 8
Training loss: 1.5658020973205566
Validation loss: 1.9201746961121917

Epoch: 6| Step: 9
Training loss: 2.608644962310791
Validation loss: 1.929479838699423

Epoch: 6| Step: 10
Training loss: 2.4915459156036377
Validation loss: 1.943874712913267

Epoch: 6| Step: 11
Training loss: 2.103376626968384
Validation loss: 1.9260916197171776

Epoch: 6| Step: 12
Training loss: 1.3139721155166626
Validation loss: 1.9176295649620794

Epoch: 6| Step: 13
Training loss: 1.3356355428695679
Validation loss: 1.915163832326089

Epoch: 169| Step: 0
Training loss: 1.5655962228775024
Validation loss: 1.9344386951897734

Epoch: 6| Step: 1
Training loss: 1.4854981899261475
Validation loss: 1.9227428923371017

Epoch: 6| Step: 2
Training loss: 1.4880661964416504
Validation loss: 1.9405227950824204

Epoch: 6| Step: 3
Training loss: 1.3249455690383911
Validation loss: 1.9197379337844027

Epoch: 6| Step: 4
Training loss: 2.255235195159912
Validation loss: 1.9286136024741716

Epoch: 6| Step: 5
Training loss: 2.419577121734619
Validation loss: 1.927240017921694

Epoch: 6| Step: 6
Training loss: 1.8320951461791992
Validation loss: 1.9243715527237102

Epoch: 6| Step: 7
Training loss: 1.931391954421997
Validation loss: 1.9110892434273996

Epoch: 6| Step: 8
Training loss: 2.47832989692688
Validation loss: 1.9651897030491983

Epoch: 6| Step: 9
Training loss: 2.3517980575561523
Validation loss: 1.9456871671061362

Epoch: 6| Step: 10
Training loss: 1.5125457048416138
Validation loss: 1.9107895948553597

Epoch: 6| Step: 11
Training loss: 2.460510015487671
Validation loss: 1.925862519971786

Epoch: 6| Step: 12
Training loss: 2.158722400665283
Validation loss: 1.9552903867536975

Epoch: 6| Step: 13
Training loss: 1.5155762434005737
Validation loss: 1.9311185036936114

Epoch: 170| Step: 0
Training loss: 1.3588447570800781
Validation loss: 1.939568240155456

Epoch: 6| Step: 1
Training loss: 2.1332201957702637
Validation loss: 1.9453931252161663

Epoch: 6| Step: 2
Training loss: 1.8299204111099243
Validation loss: 1.9625173396961664

Epoch: 6| Step: 3
Training loss: 2.0800106525421143
Validation loss: 1.948866310939994

Epoch: 6| Step: 4
Training loss: 1.7281525135040283
Validation loss: 1.9525724636611117

Epoch: 6| Step: 5
Training loss: 1.8070114850997925
Validation loss: 1.9566453990115915

Epoch: 6| Step: 6
Training loss: 2.4637391567230225
Validation loss: 1.9521321186455347

Epoch: 6| Step: 7
Training loss: 2.3364830017089844
Validation loss: 1.9743394544047694

Epoch: 6| Step: 8
Training loss: 2.137763500213623
Validation loss: 1.9523433921157674

Epoch: 6| Step: 9
Training loss: 1.5000905990600586
Validation loss: 1.9703836261585195

Epoch: 6| Step: 10
Training loss: 2.1054177284240723
Validation loss: 1.9669360755592264

Epoch: 6| Step: 11
Training loss: 1.6042720079421997
Validation loss: 1.932746459079045

Epoch: 6| Step: 12
Training loss: 2.056205987930298
Validation loss: 1.9465555208985523

Epoch: 6| Step: 13
Training loss: 1.7659704685211182
Validation loss: 1.9372280797650736

Epoch: 171| Step: 0
Training loss: 1.8746153116226196
Validation loss: 1.9367186382252684

Epoch: 6| Step: 1
Training loss: 2.3853654861450195
Validation loss: 1.968821184609526

Epoch: 6| Step: 2
Training loss: 2.309683322906494
Validation loss: 1.9677576147099978

Epoch: 6| Step: 3
Training loss: 1.4270845651626587
Validation loss: 1.9615127040493874

Epoch: 6| Step: 4
Training loss: 1.8459759950637817
Validation loss: 1.9351706427912558

Epoch: 6| Step: 5
Training loss: 1.6306734085083008
Validation loss: 1.9340901746544787

Epoch: 6| Step: 6
Training loss: 1.9432734251022339
Validation loss: 1.9071022028564124

Epoch: 6| Step: 7
Training loss: 1.6678247451782227
Validation loss: 1.9381798967238395

Epoch: 6| Step: 8
Training loss: 2.628443956375122
Validation loss: 1.9355938767874112

Epoch: 6| Step: 9
Training loss: 1.3091846704483032
Validation loss: 1.9363709675368441

Epoch: 6| Step: 10
Training loss: 2.3917150497436523
Validation loss: 1.9481793962499148

Epoch: 6| Step: 11
Training loss: 1.9336687326431274
Validation loss: 1.9240117688332834

Epoch: 6| Step: 12
Training loss: 1.6522045135498047
Validation loss: 1.9472971013797227

Epoch: 6| Step: 13
Training loss: 2.136261224746704
Validation loss: 1.9182334535865373

Epoch: 172| Step: 0
Training loss: 1.9590485095977783
Validation loss: 1.8948581603265577

Epoch: 6| Step: 1
Training loss: 2.1947741508483887
Validation loss: 1.9341212395698792

Epoch: 6| Step: 2
Training loss: 1.7783476114273071
Validation loss: 1.926147028964053

Epoch: 6| Step: 3
Training loss: 1.6994162797927856
Validation loss: 1.9230755477823236

Epoch: 6| Step: 4
Training loss: 2.761648654937744
Validation loss: 1.9327047550550072

Epoch: 6| Step: 5
Training loss: 2.094822883605957
Validation loss: 1.898601790910126

Epoch: 6| Step: 6
Training loss: 1.8324458599090576
Validation loss: 1.9296878819824548

Epoch: 6| Step: 7
Training loss: 1.9251303672790527
Validation loss: 1.906973219686939

Epoch: 6| Step: 8
Training loss: 1.8126170635223389
Validation loss: 1.9519243009628788

Epoch: 6| Step: 9
Training loss: 1.092350959777832
Validation loss: 1.9312254792900496

Epoch: 6| Step: 10
Training loss: 1.4713385105133057
Validation loss: 1.9269800096429803

Epoch: 6| Step: 11
Training loss: 2.339728593826294
Validation loss: 1.928388660953891

Epoch: 6| Step: 12
Training loss: 1.9734227657318115
Validation loss: 1.9048930483479654

Epoch: 6| Step: 13
Training loss: 2.26914644241333
Validation loss: 1.9371285425719393

Epoch: 173| Step: 0
Training loss: 1.5275728702545166
Validation loss: 1.937962071869963

Epoch: 6| Step: 1
Training loss: 1.968555212020874
Validation loss: 1.9071587721506755

Epoch: 6| Step: 2
Training loss: 1.3974767923355103
Validation loss: 1.9127254460447578

Epoch: 6| Step: 3
Training loss: 1.924696445465088
Validation loss: 1.9028770846705283

Epoch: 6| Step: 4
Training loss: 2.140368700027466
Validation loss: 1.9395730149361394

Epoch: 6| Step: 5
Training loss: 1.6618856191635132
Validation loss: 1.9432139140303417

Epoch: 6| Step: 6
Training loss: 2.220214366912842
Validation loss: 1.9402998724291403

Epoch: 6| Step: 7
Training loss: 1.485039234161377
Validation loss: 1.9293602166637298

Epoch: 6| Step: 8
Training loss: 2.0156257152557373
Validation loss: 1.9224248099070724

Epoch: 6| Step: 9
Training loss: 1.753637671470642
Validation loss: 1.9418254231893888

Epoch: 6| Step: 10
Training loss: 1.7364985942840576
Validation loss: 1.947428548207847

Epoch: 6| Step: 11
Training loss: 2.575942039489746
Validation loss: 1.9631732766346266

Epoch: 6| Step: 12
Training loss: 2.172149419784546
Validation loss: 1.9591044700273903

Epoch: 6| Step: 13
Training loss: 2.650641918182373
Validation loss: 1.955711692892095

Epoch: 174| Step: 0
Training loss: 2.342677354812622
Validation loss: 1.938459796290244

Epoch: 6| Step: 1
Training loss: 1.8163728713989258
Validation loss: 1.9645507015207762

Epoch: 6| Step: 2
Training loss: 1.5682801008224487
Validation loss: 1.9635727251729658

Epoch: 6| Step: 3
Training loss: 1.2986522912979126
Validation loss: 1.9648366269244943

Epoch: 6| Step: 4
Training loss: 1.885324239730835
Validation loss: 1.9521658625653995

Epoch: 6| Step: 5
Training loss: 2.0160751342773438
Validation loss: 1.9649034238630725

Epoch: 6| Step: 6
Training loss: 1.298050880432129
Validation loss: 1.930335255079372

Epoch: 6| Step: 7
Training loss: 1.7753862142562866
Validation loss: 1.958557741616362

Epoch: 6| Step: 8
Training loss: 2.4303207397460938
Validation loss: 1.9390227640828779

Epoch: 6| Step: 9
Training loss: 2.065479040145874
Validation loss: 1.9570899394250685

Epoch: 6| Step: 10
Training loss: 2.05472993850708
Validation loss: 1.932581232440087

Epoch: 6| Step: 11
Training loss: 1.9355311393737793
Validation loss: 1.9508508418195991

Epoch: 6| Step: 12
Training loss: 2.1039199829101562
Validation loss: 1.9485512959059847

Epoch: 6| Step: 13
Training loss: 2.6170504093170166
Validation loss: 1.9619413947546354

Epoch: 175| Step: 0
Training loss: 1.8808395862579346
Validation loss: 1.954596637397684

Epoch: 6| Step: 1
Training loss: 1.6239385604858398
Validation loss: 1.9151261224541614

Epoch: 6| Step: 2
Training loss: 2.2043728828430176
Validation loss: 1.93760460294703

Epoch: 6| Step: 3
Training loss: 1.9896318912506104
Validation loss: 1.91729704026253

Epoch: 6| Step: 4
Training loss: 1.8771741390228271
Validation loss: 1.9255789197901243

Epoch: 6| Step: 5
Training loss: 1.7972617149353027
Validation loss: 1.913756860199795

Epoch: 6| Step: 6
Training loss: 1.5762889385223389
Validation loss: 1.9149104241401917

Epoch: 6| Step: 7
Training loss: 1.7000514268875122
Validation loss: 1.9135203464056856

Epoch: 6| Step: 8
Training loss: 1.9614602327346802
Validation loss: 1.9261977352121824

Epoch: 6| Step: 9
Training loss: 1.8342947959899902
Validation loss: 1.9336393763942104

Epoch: 6| Step: 10
Training loss: 2.9764933586120605
Validation loss: 1.9146869656860188

Epoch: 6| Step: 11
Training loss: 1.8238428831100464
Validation loss: 1.9236807079725369

Epoch: 6| Step: 12
Training loss: 2.0255916118621826
Validation loss: 1.8908124277668614

Epoch: 6| Step: 13
Training loss: 1.7086067199707031
Validation loss: 1.8953699757975917

Epoch: 176| Step: 0
Training loss: 2.2420296669006348
Validation loss: 1.9118842283884685

Epoch: 6| Step: 1
Training loss: 1.5909857749938965
Validation loss: 1.9316913466299734

Epoch: 6| Step: 2
Training loss: 1.6153861284255981
Validation loss: 1.9320996256284817

Epoch: 6| Step: 3
Training loss: 1.9923722743988037
Validation loss: 1.9291450080051218

Epoch: 6| Step: 4
Training loss: 1.6991475820541382
Validation loss: 1.9542058616556146

Epoch: 6| Step: 5
Training loss: 1.5580140352249146
Validation loss: 1.928546420989498

Epoch: 6| Step: 6
Training loss: 1.7580933570861816
Validation loss: 1.9345580480431999

Epoch: 6| Step: 7
Training loss: 2.5801048278808594
Validation loss: 1.9444645297142766

Epoch: 6| Step: 8
Training loss: 2.4615464210510254
Validation loss: 1.9278301462050407

Epoch: 6| Step: 9
Training loss: 1.5987982749938965
Validation loss: 1.9517642938962547

Epoch: 6| Step: 10
Training loss: 1.8269202709197998
Validation loss: 1.9425671818435832

Epoch: 6| Step: 11
Training loss: 2.3003363609313965
Validation loss: 1.952812437088259

Epoch: 6| Step: 12
Training loss: 2.2617063522338867
Validation loss: 1.930894741448023

Epoch: 6| Step: 13
Training loss: 1.2736176252365112
Validation loss: 1.9415782907957673

Epoch: 177| Step: 0
Training loss: 1.9243595600128174
Validation loss: 1.9229961928500925

Epoch: 6| Step: 1
Training loss: 1.7708195447921753
Validation loss: 1.9304445187250774

Epoch: 6| Step: 2
Training loss: 1.0767199993133545
Validation loss: 1.9322632974193943

Epoch: 6| Step: 3
Training loss: 1.9800975322723389
Validation loss: 1.9215249835803945

Epoch: 6| Step: 4
Training loss: 1.8539159297943115
Validation loss: 1.9113293873366488

Epoch: 6| Step: 5
Training loss: 1.7055824995040894
Validation loss: 1.923263244731452

Epoch: 6| Step: 6
Training loss: 2.513000965118408
Validation loss: 1.9485542825473252

Epoch: 6| Step: 7
Training loss: 1.7643582820892334
Validation loss: 1.9251846844150173

Epoch: 6| Step: 8
Training loss: 2.1435964107513428
Validation loss: 1.9091414302907965

Epoch: 6| Step: 9
Training loss: 2.4317476749420166
Validation loss: 1.9021384998034405

Epoch: 6| Step: 10
Training loss: 2.239377975463867
Validation loss: 1.924962430871943

Epoch: 6| Step: 11
Training loss: 1.8121100664138794
Validation loss: 1.9288419536364976

Epoch: 6| Step: 12
Training loss: 1.577646255493164
Validation loss: 1.9384599013995099

Epoch: 6| Step: 13
Training loss: 1.8911298513412476
Validation loss: 1.9260199300704464

Epoch: 178| Step: 0
Training loss: 1.9618873596191406
Validation loss: 1.9424452691949823

Epoch: 6| Step: 1
Training loss: 1.9753425121307373
Validation loss: 1.9201458064458703

Epoch: 6| Step: 2
Training loss: 1.827742338180542
Validation loss: 1.9587646838157409

Epoch: 6| Step: 3
Training loss: 1.0870275497436523
Validation loss: 1.948687291914417

Epoch: 6| Step: 4
Training loss: 1.5907227993011475
Validation loss: 1.9203709017845891

Epoch: 6| Step: 5
Training loss: 2.1680498123168945
Validation loss: 1.9562467785291775

Epoch: 6| Step: 6
Training loss: 2.1542091369628906
Validation loss: 1.9495545394958989

Epoch: 6| Step: 7
Training loss: 2.775942325592041
Validation loss: 1.9319222281056065

Epoch: 6| Step: 8
Training loss: 2.079422950744629
Validation loss: 1.9438724466549453

Epoch: 6| Step: 9
Training loss: 1.6829309463500977
Validation loss: 1.9463549788280199

Epoch: 6| Step: 10
Training loss: 2.2188429832458496
Validation loss: 1.951917593197156

Epoch: 6| Step: 11
Training loss: 1.972834587097168
Validation loss: 1.9205466047410042

Epoch: 6| Step: 12
Training loss: 1.3596529960632324
Validation loss: 1.9534252151366203

Epoch: 6| Step: 13
Training loss: 1.5365818738937378
Validation loss: 1.9182248615449475

Epoch: 179| Step: 0
Training loss: 1.0811567306518555
Validation loss: 1.9431298599448255

Epoch: 6| Step: 1
Training loss: 1.610241174697876
Validation loss: 1.939712478268531

Epoch: 6| Step: 2
Training loss: 2.0785183906555176
Validation loss: 1.9278122917298348

Epoch: 6| Step: 3
Training loss: 1.8667877912521362
Validation loss: 1.9298074091634443

Epoch: 6| Step: 4
Training loss: 2.0223212242126465
Validation loss: 1.9180549370345248

Epoch: 6| Step: 5
Training loss: 1.8610541820526123
Validation loss: 1.949549319923565

Epoch: 6| Step: 6
Training loss: 2.2558674812316895
Validation loss: 1.9121913397183983

Epoch: 6| Step: 7
Training loss: 2.284066677093506
Validation loss: 1.9192304380478398

Epoch: 6| Step: 8
Training loss: 2.547902822494507
Validation loss: 1.9275286941118137

Epoch: 6| Step: 9
Training loss: 1.1558537483215332
Validation loss: 1.9399151263698455

Epoch: 6| Step: 10
Training loss: 1.936716079711914
Validation loss: 1.938378144336003

Epoch: 6| Step: 11
Training loss: 1.7095881700515747
Validation loss: 1.9360434547547372

Epoch: 6| Step: 12
Training loss: 1.9531149864196777
Validation loss: 1.939690605286629

Epoch: 6| Step: 13
Training loss: 2.372436761856079
Validation loss: 1.9350372155507405

Epoch: 180| Step: 0
Training loss: 1.689375877380371
Validation loss: 1.936567585955384

Epoch: 6| Step: 1
Training loss: 1.2527737617492676
Validation loss: 1.9159261039508286

Epoch: 6| Step: 2
Training loss: 1.9519538879394531
Validation loss: 1.9440454270250054

Epoch: 6| Step: 3
Training loss: 1.5651448965072632
Validation loss: 1.9329135187210575

Epoch: 6| Step: 4
Training loss: 2.663917064666748
Validation loss: 1.9516451307522353

Epoch: 6| Step: 5
Training loss: 1.8466956615447998
Validation loss: 1.9400046692099622

Epoch: 6| Step: 6
Training loss: 1.8267695903778076
Validation loss: 1.9066604850112752

Epoch: 6| Step: 7
Training loss: 2.284369468688965
Validation loss: 1.9289503776898949

Epoch: 6| Step: 8
Training loss: 1.4346585273742676
Validation loss: 1.9274118023533975

Epoch: 6| Step: 9
Training loss: 1.3781591653823853
Validation loss: 1.9407988978970436

Epoch: 6| Step: 10
Training loss: 2.4220330715179443
Validation loss: 1.9318999269957184

Epoch: 6| Step: 11
Training loss: 1.9829449653625488
Validation loss: 1.933198727587218

Epoch: 6| Step: 12
Training loss: 2.239506959915161
Validation loss: 1.9474170464341358

Epoch: 6| Step: 13
Training loss: 1.9699511528015137
Validation loss: 1.9554524934420021

Epoch: 181| Step: 0
Training loss: 1.9864487648010254
Validation loss: 1.9490729057660667

Epoch: 6| Step: 1
Training loss: 1.6470142602920532
Validation loss: 1.9450947289825768

Epoch: 6| Step: 2
Training loss: 2.1636509895324707
Validation loss: 1.9472500367831158

Epoch: 6| Step: 3
Training loss: 2.009079933166504
Validation loss: 1.9405481584610478

Epoch: 6| Step: 4
Training loss: 2.1794967651367188
Validation loss: 1.923039605540614

Epoch: 6| Step: 5
Training loss: 2.2657175064086914
Validation loss: 1.950746907982775

Epoch: 6| Step: 6
Training loss: 1.6130037307739258
Validation loss: 1.9288544565118768

Epoch: 6| Step: 7
Training loss: 1.375024437904358
Validation loss: 1.920889364775791

Epoch: 6| Step: 8
Training loss: 1.9935579299926758
Validation loss: 1.9269999329761793

Epoch: 6| Step: 9
Training loss: 2.012981414794922
Validation loss: 1.8941246668497722

Epoch: 6| Step: 10
Training loss: 1.5469810962677002
Validation loss: 1.9314104997983543

Epoch: 6| Step: 11
Training loss: 2.253950595855713
Validation loss: 1.903967624069542

Epoch: 6| Step: 12
Training loss: 1.6754858493804932
Validation loss: 1.904583687423378

Epoch: 6| Step: 13
Training loss: 2.210454225540161
Validation loss: 1.9073628789635115

Epoch: 182| Step: 0
Training loss: 2.001089096069336
Validation loss: 1.9131694198936544

Epoch: 6| Step: 1
Training loss: 1.7811956405639648
Validation loss: 1.9089923635605843

Epoch: 6| Step: 2
Training loss: 1.9519789218902588
Validation loss: 1.9005503551934355

Epoch: 6| Step: 3
Training loss: 2.3905489444732666
Validation loss: 1.9287995061566752

Epoch: 6| Step: 4
Training loss: 1.9567232131958008
Validation loss: 1.9013120922991025

Epoch: 6| Step: 5
Training loss: 2.3884081840515137
Validation loss: 1.906588549255043

Epoch: 6| Step: 6
Training loss: 1.5656967163085938
Validation loss: 1.908495318505072

Epoch: 6| Step: 7
Training loss: 1.4773521423339844
Validation loss: 1.8922911408126994

Epoch: 6| Step: 8
Training loss: 2.301206588745117
Validation loss: 1.9348787543594197

Epoch: 6| Step: 9
Training loss: 1.5960139036178589
Validation loss: 1.9123999931479012

Epoch: 6| Step: 10
Training loss: 1.1182103157043457
Validation loss: 1.9317883727371052

Epoch: 6| Step: 11
Training loss: 2.8688650131225586
Validation loss: 1.9320540197433964

Epoch: 6| Step: 12
Training loss: 1.1713999509811401
Validation loss: 1.9333861156176495

Epoch: 6| Step: 13
Training loss: 2.0764684677124023
Validation loss: 1.967961533095247

Epoch: 183| Step: 0
Training loss: 2.696922540664673
Validation loss: 1.9309573352977794

Epoch: 6| Step: 1
Training loss: 1.95118248462677
Validation loss: 1.9069781405951387

Epoch: 6| Step: 2
Training loss: 1.6239774227142334
Validation loss: 1.9396541105803622

Epoch: 6| Step: 3
Training loss: 1.6143083572387695
Validation loss: 1.9312060879122825

Epoch: 6| Step: 4
Training loss: 1.6599125862121582
Validation loss: 1.9614564244465162

Epoch: 6| Step: 5
Training loss: 1.935509204864502
Validation loss: 1.9438594836060719

Epoch: 6| Step: 6
Training loss: 1.7354514598846436
Validation loss: 1.947828265928453

Epoch: 6| Step: 7
Training loss: 2.453298807144165
Validation loss: 1.9387357106772802

Epoch: 6| Step: 8
Training loss: 2.7344470024108887
Validation loss: 1.954034254115115

Epoch: 6| Step: 9
Training loss: 1.9712735414505005
Validation loss: 1.9554821009277015

Epoch: 6| Step: 10
Training loss: 1.3033145666122437
Validation loss: 1.9563631011593727

Epoch: 6| Step: 11
Training loss: 1.8710944652557373
Validation loss: 1.941561391276698

Epoch: 6| Step: 12
Training loss: 1.5864129066467285
Validation loss: 1.9511089337769376

Epoch: 6| Step: 13
Training loss: 0.8988938927650452
Validation loss: 1.9448031520330777

Epoch: 184| Step: 0
Training loss: 2.2455201148986816
Validation loss: 1.9142444531122844

Epoch: 6| Step: 1
Training loss: 2.716405153274536
Validation loss: 1.913764379357779

Epoch: 6| Step: 2
Training loss: 2.3264894485473633
Validation loss: 1.9359275820434734

Epoch: 6| Step: 3
Training loss: 2.1139187812805176
Validation loss: 1.9231653162228164

Epoch: 6| Step: 4
Training loss: 1.211768627166748
Validation loss: 1.943017416102912

Epoch: 6| Step: 5
Training loss: 1.416619062423706
Validation loss: 1.9347840803925709

Epoch: 6| Step: 6
Training loss: 2.01900053024292
Validation loss: 1.9535520051115303

Epoch: 6| Step: 7
Training loss: 2.2429707050323486
Validation loss: 1.9329367427415745

Epoch: 6| Step: 8
Training loss: 1.2954156398773193
Validation loss: 1.9349908444189257

Epoch: 6| Step: 9
Training loss: 2.95052170753479
Validation loss: 1.9251815349824968

Epoch: 6| Step: 10
Training loss: 1.2355802059173584
Validation loss: 1.9165909123677078

Epoch: 6| Step: 11
Training loss: 1.742856502532959
Validation loss: 1.904161036655467

Epoch: 6| Step: 12
Training loss: 1.3630118370056152
Validation loss: 1.9266494679194626

Epoch: 6| Step: 13
Training loss: 0.9968039393424988
Validation loss: 1.9227101508007254

Epoch: 185| Step: 0
Training loss: 1.3462061882019043
Validation loss: 1.9215876799757763

Epoch: 6| Step: 1
Training loss: 1.8929309844970703
Validation loss: 1.921104552925274

Epoch: 6| Step: 2
Training loss: 1.920469880104065
Validation loss: 1.93526747662534

Epoch: 6| Step: 3
Training loss: 2.7850732803344727
Validation loss: 1.9144956091398835

Epoch: 6| Step: 4
Training loss: 2.119922637939453
Validation loss: 1.9311748486693188

Epoch: 6| Step: 5
Training loss: 2.64345383644104
Validation loss: 1.9010982641609766

Epoch: 6| Step: 6
Training loss: 1.5615309476852417
Validation loss: 1.9305369815518778

Epoch: 6| Step: 7
Training loss: 1.7169625759124756
Validation loss: 1.9453265308051981

Epoch: 6| Step: 8
Training loss: 1.7554688453674316
Validation loss: 1.9260826239021875

Epoch: 6| Step: 9
Training loss: 2.2339234352111816
Validation loss: 1.9556850643568142

Epoch: 6| Step: 10
Training loss: 1.4852999448776245
Validation loss: 1.9618995997213549

Epoch: 6| Step: 11
Training loss: 1.6285953521728516
Validation loss: 1.9388933027944257

Epoch: 6| Step: 12
Training loss: 2.1130781173706055
Validation loss: 1.9326646327972412

Epoch: 6| Step: 13
Training loss: 1.228355884552002
Validation loss: 1.9423534806056688

Epoch: 186| Step: 0
Training loss: 1.6951650381088257
Validation loss: 1.9645279197282688

Epoch: 6| Step: 1
Training loss: 2.194808006286621
Validation loss: 1.9531384155314455

Epoch: 6| Step: 2
Training loss: 1.8187932968139648
Validation loss: 1.9125483484678372

Epoch: 6| Step: 3
Training loss: 1.7781095504760742
Validation loss: 1.9255073839618313

Epoch: 6| Step: 4
Training loss: 2.0457963943481445
Validation loss: 1.9410252212196268

Epoch: 6| Step: 5
Training loss: 1.844423770904541
Validation loss: 1.922663923232786

Epoch: 6| Step: 6
Training loss: 2.2742583751678467
Validation loss: 1.9114173150831653

Epoch: 6| Step: 7
Training loss: 2.048755168914795
Validation loss: 1.9314003029177267

Epoch: 6| Step: 8
Training loss: 1.676297664642334
Validation loss: 1.9065936752544936

Epoch: 6| Step: 9
Training loss: 1.7680902481079102
Validation loss: 1.9081974183359454

Epoch: 6| Step: 10
Training loss: 1.6080127954483032
Validation loss: 1.935626027404621

Epoch: 6| Step: 11
Training loss: 1.4696028232574463
Validation loss: 1.9192765220519035

Epoch: 6| Step: 12
Training loss: 2.3492326736450195
Validation loss: 1.927215499262656

Epoch: 6| Step: 13
Training loss: 1.4774219989776611
Validation loss: 1.9083632551213747

Epoch: 187| Step: 0
Training loss: 1.6626183986663818
Validation loss: 1.9135409555127543

Epoch: 6| Step: 1
Training loss: 1.9944326877593994
Validation loss: 1.9406423799453243

Epoch: 6| Step: 2
Training loss: 1.8638889789581299
Validation loss: 1.899297812933563

Epoch: 6| Step: 3
Training loss: 2.3625054359436035
Validation loss: 1.9092279839259323

Epoch: 6| Step: 4
Training loss: 1.7753360271453857
Validation loss: 1.9230759195102158

Epoch: 6| Step: 5
Training loss: 2.163534164428711
Validation loss: 1.9009490961669593

Epoch: 6| Step: 6
Training loss: 1.593970537185669
Validation loss: 1.917925150163712

Epoch: 6| Step: 7
Training loss: 1.6855559349060059
Validation loss: 1.9072213070366972

Epoch: 6| Step: 8
Training loss: 1.7297512292861938
Validation loss: 1.9276857555553477

Epoch: 6| Step: 9
Training loss: 2.587878465652466
Validation loss: 1.9254695958988641

Epoch: 6| Step: 10
Training loss: 1.2546398639678955
Validation loss: 1.8956956504493632

Epoch: 6| Step: 11
Training loss: 1.8254531621932983
Validation loss: 1.9046730584995721

Epoch: 6| Step: 12
Training loss: 1.795985221862793
Validation loss: 1.8995747079131424

Epoch: 6| Step: 13
Training loss: 1.793988585472107
Validation loss: 1.9124736465433592

Epoch: 188| Step: 0
Training loss: 1.7178332805633545
Validation loss: 1.9125120870528682

Epoch: 6| Step: 1
Training loss: 1.4650523662567139
Validation loss: 1.898217599879029

Epoch: 6| Step: 2
Training loss: 2.3004002571105957
Validation loss: 1.894736284850746

Epoch: 6| Step: 3
Training loss: 2.118330240249634
Validation loss: 1.9150457266838319

Epoch: 6| Step: 4
Training loss: 2.0953965187072754
Validation loss: 1.9028522276109265

Epoch: 6| Step: 5
Training loss: 1.8239941596984863
Validation loss: 1.916415919539749

Epoch: 6| Step: 6
Training loss: 1.8340656757354736
Validation loss: 1.9156718869363107

Epoch: 6| Step: 7
Training loss: 1.9205623865127563
Validation loss: 1.909704949266167

Epoch: 6| Step: 8
Training loss: 1.5597599744796753
Validation loss: 1.9219424583578621

Epoch: 6| Step: 9
Training loss: 1.675195336341858
Validation loss: 1.9189127901548981

Epoch: 6| Step: 10
Training loss: 2.407200813293457
Validation loss: 1.9265347091100549

Epoch: 6| Step: 11
Training loss: 2.151029109954834
Validation loss: 1.948525567208567

Epoch: 6| Step: 12
Training loss: 1.6809779405593872
Validation loss: 1.9185338866326116

Epoch: 6| Step: 13
Training loss: 1.3130686283111572
Validation loss: 1.9185416160091278

Epoch: 189| Step: 0
Training loss: 1.9987261295318604
Validation loss: 1.92622592244097

Epoch: 6| Step: 1
Training loss: 2.1833865642547607
Validation loss: 1.9209519278618596

Epoch: 6| Step: 2
Training loss: 1.7206833362579346
Validation loss: 1.9388591448465984

Epoch: 6| Step: 3
Training loss: 1.6605181694030762
Validation loss: 1.920134425163269

Epoch: 6| Step: 4
Training loss: 2.1205930709838867
Validation loss: 1.9492691742476596

Epoch: 6| Step: 5
Training loss: 1.4465289115905762
Validation loss: 1.9085357573724562

Epoch: 6| Step: 6
Training loss: 2.000589609146118
Validation loss: 1.9279377332297705

Epoch: 6| Step: 7
Training loss: 2.33933687210083
Validation loss: 1.943643218727522

Epoch: 6| Step: 8
Training loss: 1.9672068357467651
Validation loss: 1.9274649325237478

Epoch: 6| Step: 9
Training loss: 1.4047930240631104
Validation loss: 1.9119286639716035

Epoch: 6| Step: 10
Training loss: 2.0023369789123535
Validation loss: 1.9259125545460691

Epoch: 6| Step: 11
Training loss: 1.596380591392517
Validation loss: 1.906486080538842

Epoch: 6| Step: 12
Training loss: 2.1616551876068115
Validation loss: 1.9276768110131706

Epoch: 6| Step: 13
Training loss: 1.1254016160964966
Validation loss: 1.9338583574500134

Epoch: 190| Step: 0
Training loss: 1.4026588201522827
Validation loss: 1.9470451519053469

Epoch: 6| Step: 1
Training loss: 1.8385488986968994
Validation loss: 1.92584438349611

Epoch: 6| Step: 2
Training loss: 1.5431208610534668
Validation loss: 1.9471527376482565

Epoch: 6| Step: 3
Training loss: 2.2022156715393066
Validation loss: 1.9227811328826412

Epoch: 6| Step: 4
Training loss: 1.9975918531417847
Validation loss: 1.9364333832135765

Epoch: 6| Step: 5
Training loss: 1.475016474723816
Validation loss: 1.9511932660174627

Epoch: 6| Step: 6
Training loss: 1.8995802402496338
Validation loss: 1.9359198936852076

Epoch: 6| Step: 7
Training loss: 1.2478110790252686
Validation loss: 1.938361612699365

Epoch: 6| Step: 8
Training loss: 1.9878050088882446
Validation loss: 1.9287252400511055

Epoch: 6| Step: 9
Training loss: 1.7098166942596436
Validation loss: 1.9608654616981425

Epoch: 6| Step: 10
Training loss: 2.656182289123535
Validation loss: 1.9078345452585528

Epoch: 6| Step: 11
Training loss: 2.174724578857422
Validation loss: 1.9256419366405857

Epoch: 6| Step: 12
Training loss: 2.201305866241455
Validation loss: 1.9237044242120558

Epoch: 6| Step: 13
Training loss: 1.8599703311920166
Validation loss: 1.9067477705658122

Epoch: 191| Step: 0
Training loss: 2.5083391666412354
Validation loss: 1.913164791240487

Epoch: 6| Step: 1
Training loss: 1.6435145139694214
Validation loss: 1.916067857896128

Epoch: 6| Step: 2
Training loss: 1.7660361528396606
Validation loss: 1.9028879404067993

Epoch: 6| Step: 3
Training loss: 1.5430567264556885
Validation loss: 1.936286530187053

Epoch: 6| Step: 4
Training loss: 2.4516682624816895
Validation loss: 1.9293556008287656

Epoch: 6| Step: 5
Training loss: 1.953790307044983
Validation loss: 1.9320157356159662

Epoch: 6| Step: 6
Training loss: 2.310145854949951
Validation loss: 1.9163354263510755

Epoch: 6| Step: 7
Training loss: 1.9474064111709595
Validation loss: 1.9173857794013074

Epoch: 6| Step: 8
Training loss: 1.637311339378357
Validation loss: 1.9562701948227421

Epoch: 6| Step: 9
Training loss: 1.640006184577942
Validation loss: 1.9284885916658627

Epoch: 6| Step: 10
Training loss: 2.1297757625579834
Validation loss: 1.9159613168367775

Epoch: 6| Step: 11
Training loss: 1.165523886680603
Validation loss: 1.9304160917958906

Epoch: 6| Step: 12
Training loss: 1.0295474529266357
Validation loss: 1.936165371248799

Epoch: 6| Step: 13
Training loss: 2.4055585861206055
Validation loss: 1.9410878330148675

Epoch: 192| Step: 0
Training loss: 1.612629771232605
Validation loss: 1.9161030887275614

Epoch: 6| Step: 1
Training loss: 1.899565577507019
Validation loss: 1.9119219805604668

Epoch: 6| Step: 2
Training loss: 1.3965234756469727
Validation loss: 1.9227265132370817

Epoch: 6| Step: 3
Training loss: 1.992753267288208
Validation loss: 1.941451245738614

Epoch: 6| Step: 4
Training loss: 1.5341391563415527
Validation loss: 1.9281693991794382

Epoch: 6| Step: 5
Training loss: 2.2139501571655273
Validation loss: 1.9464098997013544

Epoch: 6| Step: 6
Training loss: 1.8331072330474854
Validation loss: 1.9239342007585751

Epoch: 6| Step: 7
Training loss: 2.8145337104797363
Validation loss: 1.9268174991812757

Epoch: 6| Step: 8
Training loss: 2.2949371337890625
Validation loss: 1.9287251772419098

Epoch: 6| Step: 9
Training loss: 1.090806484222412
Validation loss: 1.9207062567434003

Epoch: 6| Step: 10
Training loss: 1.2597496509552002
Validation loss: 1.930545114701794

Epoch: 6| Step: 11
Training loss: 1.648953914642334
Validation loss: 1.9374641577402751

Epoch: 6| Step: 12
Training loss: 2.0646820068359375
Validation loss: 1.9376136359348093

Epoch: 6| Step: 13
Training loss: 2.6182026863098145
Validation loss: 1.8893196275157313

Epoch: 193| Step: 0
Training loss: 1.4811813831329346
Validation loss: 1.9118635218630555

Epoch: 6| Step: 1
Training loss: 1.5706312656402588
Validation loss: 1.921983161280232

Epoch: 6| Step: 2
Training loss: 1.572042465209961
Validation loss: 1.9074765584802116

Epoch: 6| Step: 3
Training loss: 1.6491498947143555
Validation loss: 1.9121322695926954

Epoch: 6| Step: 4
Training loss: 1.9805970191955566
Validation loss: 1.9339781089495587

Epoch: 6| Step: 5
Training loss: 1.9557291269302368
Validation loss: 1.8754586558188162

Epoch: 6| Step: 6
Training loss: 1.4665987491607666
Validation loss: 1.8881200564804899

Epoch: 6| Step: 7
Training loss: 1.4426929950714111
Validation loss: 1.9276411251355243

Epoch: 6| Step: 8
Training loss: 2.0017805099487305
Validation loss: 1.9269230827208488

Epoch: 6| Step: 9
Training loss: 1.8438118696212769
Validation loss: 1.902427246493678

Epoch: 6| Step: 10
Training loss: 2.6346664428710938
Validation loss: 1.9298481210585563

Epoch: 6| Step: 11
Training loss: 2.1506381034851074
Validation loss: 1.9137841578452819

Epoch: 6| Step: 12
Training loss: 2.0995006561279297
Validation loss: 1.9155469889281898

Epoch: 6| Step: 13
Training loss: 1.893919587135315
Validation loss: 1.9142759923012025

Epoch: 194| Step: 0
Training loss: 2.202326774597168
Validation loss: 1.9228579792925107

Epoch: 6| Step: 1
Training loss: 1.8990495204925537
Validation loss: 1.9475899486131565

Epoch: 6| Step: 2
Training loss: 1.1986111402511597
Validation loss: 1.9529311721042921

Epoch: 6| Step: 3
Training loss: 1.5104453563690186
Validation loss: 1.9234765729596537

Epoch: 6| Step: 4
Training loss: 1.7349767684936523
Validation loss: 1.9187884151294667

Epoch: 6| Step: 5
Training loss: 2.129685878753662
Validation loss: 1.9209377688746299

Epoch: 6| Step: 6
Training loss: 2.284369945526123
Validation loss: 1.9626138620479132

Epoch: 6| Step: 7
Training loss: 2.443894863128662
Validation loss: 1.9306979230655137

Epoch: 6| Step: 8
Training loss: 1.8354456424713135
Validation loss: 1.9455591888837918

Epoch: 6| Step: 9
Training loss: 1.977283000946045
Validation loss: 1.9544376583509548

Epoch: 6| Step: 10
Training loss: 2.0129213333129883
Validation loss: 1.9626778415454331

Epoch: 6| Step: 11
Training loss: 1.8438596725463867
Validation loss: 1.970128382405927

Epoch: 6| Step: 12
Training loss: 1.6113364696502686
Validation loss: 1.9416280279877365

Epoch: 6| Step: 13
Training loss: 1.5785659551620483
Validation loss: 1.9492127062172018

Epoch: 195| Step: 0
Training loss: 1.9548325538635254
Validation loss: 1.9475605090459187

Epoch: 6| Step: 1
Training loss: 1.858669638633728
Validation loss: 1.9061893288807203

Epoch: 6| Step: 2
Training loss: 2.024272918701172
Validation loss: 1.9248864317453036

Epoch: 6| Step: 3
Training loss: 1.8246071338653564
Validation loss: 1.918778052894018

Epoch: 6| Step: 4
Training loss: 1.5851994752883911
Validation loss: 1.8896831908533651

Epoch: 6| Step: 5
Training loss: 2.1640849113464355
Validation loss: 1.9209555284951323

Epoch: 6| Step: 6
Training loss: 2.0022687911987305
Validation loss: 1.9151834352042085

Epoch: 6| Step: 7
Training loss: 1.424846887588501
Validation loss: 1.9165491160526071

Epoch: 6| Step: 8
Training loss: 1.3358126878738403
Validation loss: 1.9272469294968473

Epoch: 6| Step: 9
Training loss: 1.6204664707183838
Validation loss: 1.949307140483651

Epoch: 6| Step: 10
Training loss: 1.7426235675811768
Validation loss: 1.933502067801773

Epoch: 6| Step: 11
Training loss: 2.4405248165130615
Validation loss: 1.8893608124025407

Epoch: 6| Step: 12
Training loss: 1.7915822267532349
Validation loss: 1.925249397113759

Epoch: 6| Step: 13
Training loss: 2.235525369644165
Validation loss: 1.9229712870813185

Epoch: 196| Step: 0
Training loss: 1.377845287322998
Validation loss: 1.9062085536218458

Epoch: 6| Step: 1
Training loss: 2.4856300354003906
Validation loss: 1.911610487968691

Epoch: 6| Step: 2
Training loss: 2.0363008975982666
Validation loss: 1.9002018795218518

Epoch: 6| Step: 3
Training loss: 1.563646912574768
Validation loss: 1.9081172468841716

Epoch: 6| Step: 4
Training loss: 2.080357551574707
Validation loss: 1.8829837960581626

Epoch: 6| Step: 5
Training loss: 2.1341941356658936
Validation loss: 1.9009378571664133

Epoch: 6| Step: 6
Training loss: 1.5899440050125122
Validation loss: 1.938433967610841

Epoch: 6| Step: 7
Training loss: 1.4773368835449219
Validation loss: 1.9045088675714308

Epoch: 6| Step: 8
Training loss: 1.8399829864501953
Validation loss: 1.9091500261778473

Epoch: 6| Step: 9
Training loss: 1.829601526260376
Validation loss: 1.8962516041212185

Epoch: 6| Step: 10
Training loss: 1.5870583057403564
Validation loss: 1.90865788408505

Epoch: 6| Step: 11
Training loss: 2.045147657394409
Validation loss: 1.9209297523703626

Epoch: 6| Step: 12
Training loss: 1.4718632698059082
Validation loss: 1.908814784019224

Epoch: 6| Step: 13
Training loss: 3.1022660732269287
Validation loss: 1.9275614420572917

Epoch: 197| Step: 0
Training loss: 1.746946930885315
Validation loss: 1.899546443775136

Epoch: 6| Step: 1
Training loss: 1.835658311843872
Validation loss: 1.8921438981127996

Epoch: 6| Step: 2
Training loss: 1.5529849529266357
Validation loss: 1.9347686165122575

Epoch: 6| Step: 3
Training loss: 2.107821464538574
Validation loss: 1.9187006668377948

Epoch: 6| Step: 4
Training loss: 1.9128139019012451
Validation loss: 1.9482860847186017

Epoch: 6| Step: 5
Training loss: 2.307457447052002
Validation loss: 1.9360827835657264

Epoch: 6| Step: 6
Training loss: 1.960309386253357
Validation loss: 1.9422905368189658

Epoch: 6| Step: 7
Training loss: 1.541430115699768
Validation loss: 1.9612531136440974

Epoch: 6| Step: 8
Training loss: 1.7425010204315186
Validation loss: 1.9256946450920516

Epoch: 6| Step: 9
Training loss: 1.4245944023132324
Validation loss: 1.926089193231316

Epoch: 6| Step: 10
Training loss: 1.8826072216033936
Validation loss: 1.9608447423545263

Epoch: 6| Step: 11
Training loss: 2.376791000366211
Validation loss: 1.937539787702663

Epoch: 6| Step: 12
Training loss: 1.5000253915786743
Validation loss: 1.9355250404727073

Epoch: 6| Step: 13
Training loss: 2.529850959777832
Validation loss: 1.932129999642731

Epoch: 198| Step: 0
Training loss: 1.7424756288528442
Validation loss: 1.9220567531483148

Epoch: 6| Step: 1
Training loss: 2.0699353218078613
Validation loss: 1.9093623840680687

Epoch: 6| Step: 2
Training loss: 2.024697780609131
Validation loss: 1.9277041663405716

Epoch: 6| Step: 3
Training loss: 1.919187307357788
Validation loss: 1.9149345467167516

Epoch: 6| Step: 4
Training loss: 1.6679623126983643
Validation loss: 1.903220727879514

Epoch: 6| Step: 5
Training loss: 2.7861876487731934
Validation loss: 1.926951418640793

Epoch: 6| Step: 6
Training loss: 1.5697121620178223
Validation loss: 1.917571872793218

Epoch: 6| Step: 7
Training loss: 2.546266794204712
Validation loss: 1.9103407962347871

Epoch: 6| Step: 8
Training loss: 1.436998963356018
Validation loss: 1.9287319824259768

Epoch: 6| Step: 9
Training loss: 1.2817308902740479
Validation loss: 1.9044771758458947

Epoch: 6| Step: 10
Training loss: 1.8609763383865356
Validation loss: 1.8999840597952566

Epoch: 6| Step: 11
Training loss: 1.3096961975097656
Validation loss: 1.8794051767677389

Epoch: 6| Step: 12
Training loss: 1.8548589944839478
Validation loss: 1.9266885813846384

Epoch: 6| Step: 13
Training loss: 1.5124768018722534
Validation loss: 1.8892115149446713

Epoch: 199| Step: 0
Training loss: 1.6205031871795654
Validation loss: 1.8995933660896875

Epoch: 6| Step: 1
Training loss: 1.9508984088897705
Validation loss: 1.9075300373056883

Epoch: 6| Step: 2
Training loss: 1.0337064266204834
Validation loss: 1.9010431035872428

Epoch: 6| Step: 3
Training loss: 1.8991395235061646
Validation loss: 1.9284220857004966

Epoch: 6| Step: 4
Training loss: 1.7225395441055298
Validation loss: 1.9134885085526334

Epoch: 6| Step: 5
Training loss: 1.7127692699432373
Validation loss: 1.9169116430385138

Epoch: 6| Step: 6
Training loss: 1.344632863998413
Validation loss: 1.911117148655717

Epoch: 6| Step: 7
Training loss: 1.7252146005630493
Validation loss: 1.9049798186107347

Epoch: 6| Step: 8
Training loss: 2.4558491706848145
Validation loss: 1.9330652759921165

Epoch: 6| Step: 9
Training loss: 2.4252769947052
Validation loss: 1.9153462443300473

Epoch: 6| Step: 10
Training loss: 1.968776822090149
Validation loss: 1.9358101032113517

Epoch: 6| Step: 11
Training loss: 1.592759370803833
Validation loss: 1.946509612503872

Epoch: 6| Step: 12
Training loss: 1.7220759391784668
Validation loss: 1.9128198956930509

Epoch: 6| Step: 13
Training loss: 3.126386880874634
Validation loss: 1.913030880753712

Epoch: 200| Step: 0
Training loss: 1.8751461505889893
Validation loss: 1.9345972602085402

Epoch: 6| Step: 1
Training loss: 1.7832450866699219
Validation loss: 1.9002018731127504

Epoch: 6| Step: 2
Training loss: 2.1752102375030518
Validation loss: 1.924152466558641

Epoch: 6| Step: 3
Training loss: 1.484851598739624
Validation loss: 1.9403970139001006

Epoch: 6| Step: 4
Training loss: 1.6885831356048584
Validation loss: 1.9146041690662343

Epoch: 6| Step: 5
Training loss: 1.566375732421875
Validation loss: 1.9182801067188222

Epoch: 6| Step: 6
Training loss: 1.570640206336975
Validation loss: 1.9068541372975996

Epoch: 6| Step: 7
Training loss: 2.526576519012451
Validation loss: 1.9148693097535001

Epoch: 6| Step: 8
Training loss: 2.180126667022705
Validation loss: 1.9386890216540265

Epoch: 6| Step: 9
Training loss: 2.2618982791900635
Validation loss: 1.9340745890012352

Epoch: 6| Step: 10
Training loss: 1.2129663228988647
Validation loss: 1.931888472649359

Epoch: 6| Step: 11
Training loss: 1.767162561416626
Validation loss: 1.928624237737348

Epoch: 6| Step: 12
Training loss: 1.8541561365127563
Validation loss: 1.8974486986796062

Epoch: 6| Step: 13
Training loss: 1.8075885772705078
Validation loss: 1.9227996872317406

Epoch: 201| Step: 0
Training loss: 2.5671911239624023
Validation loss: 1.9123967539879583

Epoch: 6| Step: 1
Training loss: 1.7481236457824707
Validation loss: 1.8961205328664472

Epoch: 6| Step: 2
Training loss: 1.8710992336273193
Validation loss: 1.9347347469740017

Epoch: 6| Step: 3
Training loss: 1.7043211460113525
Validation loss: 1.9262761018609489

Epoch: 6| Step: 4
Training loss: 1.545807123184204
Validation loss: 1.8934842078916487

Epoch: 6| Step: 5
Training loss: 2.5245611667633057
Validation loss: 1.917021889840403

Epoch: 6| Step: 6
Training loss: 1.812384843826294
Validation loss: 1.9292494763610184

Epoch: 6| Step: 7
Training loss: 1.2886731624603271
Validation loss: 1.9350757650149766

Epoch: 6| Step: 8
Training loss: 2.3369152545928955
Validation loss: 1.91657639831625

Epoch: 6| Step: 9
Training loss: 1.6577403545379639
Validation loss: 1.9192077882828251

Epoch: 6| Step: 10
Training loss: 1.821563482284546
Validation loss: 1.9182922301753875

Epoch: 6| Step: 11
Training loss: 1.7145577669143677
Validation loss: 1.9230439022023191

Epoch: 6| Step: 12
Training loss: 1.5719517469406128
Validation loss: 1.895075955698567

Epoch: 6| Step: 13
Training loss: 1.4239283800125122
Validation loss: 1.9152584819383518

Epoch: 202| Step: 0
Training loss: 1.6593990325927734
Validation loss: 1.9044524315864808

Epoch: 6| Step: 1
Training loss: 1.7691248655319214
Validation loss: 1.909607546303862

Epoch: 6| Step: 2
Training loss: 1.801882028579712
Validation loss: 1.916718562444051

Epoch: 6| Step: 3
Training loss: 1.4586106538772583
Validation loss: 1.901493610874299

Epoch: 6| Step: 4
Training loss: 1.8996421098709106
Validation loss: 1.953389826641288

Epoch: 6| Step: 5
Training loss: 1.8717631101608276
Validation loss: 1.944254720082847

Epoch: 6| Step: 6
Training loss: 1.7431349754333496
Validation loss: 1.9581260450424687

Epoch: 6| Step: 7
Training loss: 1.5535924434661865
Validation loss: 1.9705899915387552

Epoch: 6| Step: 8
Training loss: 1.5024893283843994
Validation loss: 1.9434695141289824

Epoch: 6| Step: 9
Training loss: 1.8386820554733276
Validation loss: 1.9520601252073884

Epoch: 6| Step: 10
Training loss: 1.7139573097229004
Validation loss: 1.9522017971161874

Epoch: 6| Step: 11
Training loss: 2.816115140914917
Validation loss: 1.9409897699150989

Epoch: 6| Step: 12
Training loss: 2.236734628677368
Validation loss: 1.9422166680776944

Epoch: 6| Step: 13
Training loss: 1.966034173965454
Validation loss: 1.9163663361662178

Epoch: 203| Step: 0
Training loss: 1.362886667251587
Validation loss: 1.910349540812995

Epoch: 6| Step: 1
Training loss: 1.995250940322876
Validation loss: 1.8948915940459057

Epoch: 6| Step: 2
Training loss: 2.0252087116241455
Validation loss: 1.8968899480758175

Epoch: 6| Step: 3
Training loss: 1.716033935546875
Validation loss: 1.91303418015921

Epoch: 6| Step: 4
Training loss: 2.1721558570861816
Validation loss: 1.8919467464570077

Epoch: 6| Step: 5
Training loss: 2.3213746547698975
Validation loss: 1.9098259889951317

Epoch: 6| Step: 6
Training loss: 1.5855528116226196
Validation loss: 1.8948375986468406

Epoch: 6| Step: 7
Training loss: 1.187996506690979
Validation loss: 1.8971806674875238

Epoch: 6| Step: 8
Training loss: 1.933356523513794
Validation loss: 1.9017051176358295

Epoch: 6| Step: 9
Training loss: 1.7791476249694824
Validation loss: 1.8994785893347956

Epoch: 6| Step: 10
Training loss: 1.9717252254486084
Validation loss: 1.891184856814723

Epoch: 6| Step: 11
Training loss: 1.8918589353561401
Validation loss: 1.8909485916937552

Epoch: 6| Step: 12
Training loss: 2.1887567043304443
Validation loss: 1.9141548243902062

Epoch: 6| Step: 13
Training loss: 1.1588053703308105
Validation loss: 1.9299495732912453

Epoch: 204| Step: 0
Training loss: 2.145771026611328
Validation loss: 1.8912567271981189

Epoch: 6| Step: 1
Training loss: 2.470566511154175
Validation loss: 1.927844044982746

Epoch: 6| Step: 2
Training loss: 1.3102936744689941
Validation loss: 1.9301593918954172

Epoch: 6| Step: 3
Training loss: 1.955929160118103
Validation loss: 1.9180492303704704

Epoch: 6| Step: 4
Training loss: 1.5744775533676147
Validation loss: 1.921743441653508

Epoch: 6| Step: 5
Training loss: 1.4729440212249756
Validation loss: 1.924893634293669

Epoch: 6| Step: 6
Training loss: 2.0594868659973145
Validation loss: 1.9003188187076199

Epoch: 6| Step: 7
Training loss: 1.4405405521392822
Validation loss: 1.927913341470944

Epoch: 6| Step: 8
Training loss: 1.2604045867919922
Validation loss: 1.8990361023974676

Epoch: 6| Step: 9
Training loss: 2.8256049156188965
Validation loss: 1.907175212778071

Epoch: 6| Step: 10
Training loss: 1.8059415817260742
Validation loss: 1.9256842174837667

Epoch: 6| Step: 11
Training loss: 1.7025896310806274
Validation loss: 1.9026323185172132

Epoch: 6| Step: 12
Training loss: 2.0228095054626465
Validation loss: 1.895361392728744

Epoch: 6| Step: 13
Training loss: 1.9322679042816162
Validation loss: 1.8959062202002412

Epoch: 205| Step: 0
Training loss: 1.9541311264038086
Validation loss: 1.909069574007424

Epoch: 6| Step: 1
Training loss: 1.564745545387268
Validation loss: 1.8973131243900587

Epoch: 6| Step: 2
Training loss: 2.546114444732666
Validation loss: 1.9143433391406972

Epoch: 6| Step: 3
Training loss: 2.611110210418701
Validation loss: 1.9226880073547363

Epoch: 6| Step: 4
Training loss: 2.119661331176758
Validation loss: 1.9259449871637488

Epoch: 6| Step: 5
Training loss: 1.9819661378860474
Validation loss: 1.9236427212274203

Epoch: 6| Step: 6
Training loss: 2.2056546211242676
Validation loss: 1.8883625948300926

Epoch: 6| Step: 7
Training loss: 1.4107353687286377
Validation loss: 1.905981449670689

Epoch: 6| Step: 8
Training loss: 1.2507259845733643
Validation loss: 1.9260852003610263

Epoch: 6| Step: 9
Training loss: 1.9674419164657593
Validation loss: 1.9156935894361107

Epoch: 6| Step: 10
Training loss: 1.4002439975738525
Validation loss: 1.957433246797131

Epoch: 6| Step: 11
Training loss: 1.2060232162475586
Validation loss: 1.9406766327478553

Epoch: 6| Step: 12
Training loss: 1.6105904579162598
Validation loss: 1.935242050437517

Epoch: 6| Step: 13
Training loss: 1.89112389087677
Validation loss: 1.9181186909316688

Epoch: 206| Step: 0
Training loss: 2.047574043273926
Validation loss: 1.931436172095678

Epoch: 6| Step: 1
Training loss: 1.7360541820526123
Validation loss: 1.9161495598413611

Epoch: 6| Step: 2
Training loss: 1.4711682796478271
Validation loss: 1.9009664661140853

Epoch: 6| Step: 3
Training loss: 2.8282015323638916
Validation loss: 1.9170245957630936

Epoch: 6| Step: 4
Training loss: 1.8713654279708862
Validation loss: 1.8989267233879334

Epoch: 6| Step: 5
Training loss: 1.615490436553955
Validation loss: 1.905921338706888

Epoch: 6| Step: 6
Training loss: 1.810950756072998
Validation loss: 1.9172306470973517

Epoch: 6| Step: 7
Training loss: 1.6093883514404297
Validation loss: 1.9228621900722545

Epoch: 6| Step: 8
Training loss: 1.5808292627334595
Validation loss: 1.9060887329040035

Epoch: 6| Step: 9
Training loss: 1.6246345043182373
Validation loss: 1.9204563607451737

Epoch: 6| Step: 10
Training loss: 1.5938726663589478
Validation loss: 1.905906564445906

Epoch: 6| Step: 11
Training loss: 2.4773550033569336
Validation loss: 1.8942407113249584

Epoch: 6| Step: 12
Training loss: 1.2925496101379395
Validation loss: 1.9254457399409304

Epoch: 6| Step: 13
Training loss: 1.8338508605957031
Validation loss: 1.9007675070916452

Epoch: 207| Step: 0
Training loss: 1.2470500469207764
Validation loss: 1.89213046719951

Epoch: 6| Step: 1
Training loss: 2.398620128631592
Validation loss: 1.9224087781803583

Epoch: 6| Step: 2
Training loss: 1.9197657108306885
Validation loss: 1.9367295708707584

Epoch: 6| Step: 3
Training loss: 2.1779792308807373
Validation loss: 1.9365831139267131

Epoch: 6| Step: 4
Training loss: 1.8732391595840454
Validation loss: 1.938366026006719

Epoch: 6| Step: 5
Training loss: 1.5060502290725708
Validation loss: 1.9229640704329296

Epoch: 6| Step: 6
Training loss: 2.090721845626831
Validation loss: 1.907281885864914

Epoch: 6| Step: 7
Training loss: 1.615073323249817
Validation loss: 1.9503327505562895

Epoch: 6| Step: 8
Training loss: 1.796766757965088
Validation loss: 1.9202535844618274

Epoch: 6| Step: 9
Training loss: 2.085888624191284
Validation loss: 1.9408952395121257

Epoch: 6| Step: 10
Training loss: 1.1589329242706299
Validation loss: 1.9374362089300667

Epoch: 6| Step: 11
Training loss: 1.665209174156189
Validation loss: 1.9155246891001219

Epoch: 6| Step: 12
Training loss: 2.801250457763672
Validation loss: 1.9490746990326913

Epoch: 6| Step: 13
Training loss: 0.9707167744636536
Validation loss: 1.9161430007667952

Epoch: 208| Step: 0
Training loss: 1.1334651708602905
Validation loss: 1.9062977375522736

Epoch: 6| Step: 1
Training loss: 2.047837734222412
Validation loss: 1.9237569006540443

Epoch: 6| Step: 2
Training loss: 1.4767096042633057
Validation loss: 1.9258590885387954

Epoch: 6| Step: 3
Training loss: 1.7819325923919678
Validation loss: 1.9196142214600758

Epoch: 6| Step: 4
Training loss: 2.2294888496398926
Validation loss: 1.9399119077190277

Epoch: 6| Step: 5
Training loss: 1.473675012588501
Validation loss: 1.9306415819352674

Epoch: 6| Step: 6
Training loss: 2.2383651733398438
Validation loss: 1.9208890135570238

Epoch: 6| Step: 7
Training loss: 1.7279337644577026
Validation loss: 1.9105635612241683

Epoch: 6| Step: 8
Training loss: 2.1417205333709717
Validation loss: 1.880895891497212

Epoch: 6| Step: 9
Training loss: 2.1017396450042725
Validation loss: 1.9070495405504782

Epoch: 6| Step: 10
Training loss: 2.0472702980041504
Validation loss: 1.8960776354676934

Epoch: 6| Step: 11
Training loss: 1.5716865062713623
Validation loss: 1.8821770145047096

Epoch: 6| Step: 12
Training loss: 1.764451265335083
Validation loss: 1.87932752537471

Epoch: 6| Step: 13
Training loss: 1.3776135444641113
Validation loss: 1.8893957266243555

Epoch: 209| Step: 0
Training loss: 1.578129768371582
Validation loss: 1.9134596304226947

Epoch: 6| Step: 1
Training loss: 1.6525384187698364
Validation loss: 1.8899624245141142

Epoch: 6| Step: 2
Training loss: 2.0197551250457764
Validation loss: 1.8916431626965922

Epoch: 6| Step: 3
Training loss: 2.874464273452759
Validation loss: 1.9066367585171935

Epoch: 6| Step: 4
Training loss: 1.3724889755249023
Validation loss: 1.897971700596553

Epoch: 6| Step: 5
Training loss: 1.421416997909546
Validation loss: 1.9139435252835673

Epoch: 6| Step: 6
Training loss: 2.112379550933838
Validation loss: 1.9105881644833473

Epoch: 6| Step: 7
Training loss: 2.6058237552642822
Validation loss: 1.8985112533774426

Epoch: 6| Step: 8
Training loss: 2.1651065349578857
Validation loss: 1.9135971543609456

Epoch: 6| Step: 9
Training loss: 1.8063349723815918
Validation loss: 1.9229952494303386

Epoch: 6| Step: 10
Training loss: 1.5587544441223145
Validation loss: 1.9124932853124474

Epoch: 6| Step: 11
Training loss: 1.6179360151290894
Validation loss: 1.9036553341855285

Epoch: 6| Step: 12
Training loss: 0.9809192419052124
Validation loss: 1.905742017171716

Epoch: 6| Step: 13
Training loss: 1.567394495010376
Validation loss: 1.915613624357408

Epoch: 210| Step: 0
Training loss: 2.5103776454925537
Validation loss: 1.9049334731153262

Epoch: 6| Step: 1
Training loss: 1.7447642087936401
Validation loss: 1.9058814779404671

Epoch: 6| Step: 2
Training loss: 1.9896857738494873
Validation loss: 1.9228886852982223

Epoch: 6| Step: 3
Training loss: 1.4743534326553345
Validation loss: 1.8968048121339531

Epoch: 6| Step: 4
Training loss: 1.2769118547439575
Validation loss: 1.9179522888634795

Epoch: 6| Step: 5
Training loss: 1.3934907913208008
Validation loss: 1.9220615099835139

Epoch: 6| Step: 6
Training loss: 1.5120015144348145
Validation loss: 1.927901324405465

Epoch: 6| Step: 7
Training loss: 1.8263119459152222
Validation loss: 1.8860243238428587

Epoch: 6| Step: 8
Training loss: 2.552548408508301
Validation loss: 1.908680050603805

Epoch: 6| Step: 9
Training loss: 1.2942936420440674
Validation loss: 1.9388714990308207

Epoch: 6| Step: 10
Training loss: 2.108808755874634
Validation loss: 1.9059533624238865

Epoch: 6| Step: 11
Training loss: 1.9830527305603027
Validation loss: 1.906527591008012

Epoch: 6| Step: 12
Training loss: 2.2555689811706543
Validation loss: 1.9030001753120012

Epoch: 6| Step: 13
Training loss: 1.3139559030532837
Validation loss: 1.9033709982390046

Epoch: 211| Step: 0
Training loss: 1.6871395111083984
Validation loss: 1.904785026786148

Epoch: 6| Step: 1
Training loss: 2.0880017280578613
Validation loss: 1.9081525033520115

Epoch: 6| Step: 2
Training loss: 2.072269916534424
Validation loss: 1.9013262961500434

Epoch: 6| Step: 3
Training loss: 1.7549705505371094
Validation loss: 1.9036881718584286

Epoch: 6| Step: 4
Training loss: 1.6260652542114258
Validation loss: 1.8795849725764284

Epoch: 6| Step: 5
Training loss: 1.8425981998443604
Validation loss: 1.916258467141018

Epoch: 6| Step: 6
Training loss: 1.5827405452728271
Validation loss: 1.8701348189384706

Epoch: 6| Step: 7
Training loss: 1.439777135848999
Validation loss: 1.8820912761072959

Epoch: 6| Step: 8
Training loss: 1.9370062351226807
Validation loss: 1.9131586244029384

Epoch: 6| Step: 9
Training loss: 1.806966781616211
Validation loss: 1.9132859706878662

Epoch: 6| Step: 10
Training loss: 2.0919277667999268
Validation loss: 1.907553308753557

Epoch: 6| Step: 11
Training loss: 1.1286942958831787
Validation loss: 1.8855469457564815

Epoch: 6| Step: 12
Training loss: 2.3617138862609863
Validation loss: 1.9303491794934837

Epoch: 6| Step: 13
Training loss: 1.6759668588638306
Validation loss: 1.8870596501135057

Epoch: 212| Step: 0
Training loss: 1.7246167659759521
Validation loss: 1.926919332114599

Epoch: 6| Step: 1
Training loss: 2.208258628845215
Validation loss: 1.9054385923570203

Epoch: 6| Step: 2
Training loss: 1.3535890579223633
Validation loss: 1.8982568581899006

Epoch: 6| Step: 3
Training loss: 2.112515926361084
Validation loss: 1.9129955409675516

Epoch: 6| Step: 4
Training loss: 1.7034183740615845
Validation loss: 1.901622752989492

Epoch: 6| Step: 5
Training loss: 2.4439876079559326
Validation loss: 1.8817311461253832

Epoch: 6| Step: 6
Training loss: 2.176252841949463
Validation loss: 1.8960685755616875

Epoch: 6| Step: 7
Training loss: 1.5047322511672974
Validation loss: 1.8996787071228027

Epoch: 6| Step: 8
Training loss: 1.973602294921875
Validation loss: 1.902554524842129

Epoch: 6| Step: 9
Training loss: 1.6060712337493896
Validation loss: 1.9056449346644904

Epoch: 6| Step: 10
Training loss: 1.61817467212677
Validation loss: 1.9115938768591931

Epoch: 6| Step: 11
Training loss: 1.4106121063232422
Validation loss: 1.9124491035297353

Epoch: 6| Step: 12
Training loss: 1.3155015707015991
Validation loss: 1.909713766908133

Epoch: 6| Step: 13
Training loss: 2.5772225856781006
Validation loss: 1.8811410024601927

Epoch: 213| Step: 0
Training loss: 2.1869056224823
Validation loss: 1.894534400714341

Epoch: 6| Step: 1
Training loss: 1.7098395824432373
Validation loss: 1.9086175900633617

Epoch: 6| Step: 2
Training loss: 2.3664743900299072
Validation loss: 1.9109900343802668

Epoch: 6| Step: 3
Training loss: 1.158713459968567
Validation loss: 1.895075257106494

Epoch: 6| Step: 4
Training loss: 2.38527250289917
Validation loss: 1.933252937050276

Epoch: 6| Step: 5
Training loss: 1.6597654819488525
Validation loss: 1.8865598017169583

Epoch: 6| Step: 6
Training loss: 2.011549472808838
Validation loss: 1.9275494083281486

Epoch: 6| Step: 7
Training loss: 1.8832355737686157
Validation loss: 1.9152254096923336

Epoch: 6| Step: 8
Training loss: 1.617788314819336
Validation loss: 1.9396740185317172

Epoch: 6| Step: 9
Training loss: 2.2559549808502197
Validation loss: 1.8923891205941477

Epoch: 6| Step: 10
Training loss: 1.2084481716156006
Validation loss: 1.8998292864009898

Epoch: 6| Step: 11
Training loss: 1.2973213195800781
Validation loss: 1.9330342411994934

Epoch: 6| Step: 12
Training loss: 1.7491660118103027
Validation loss: 1.8963213031009962

Epoch: 6| Step: 13
Training loss: 1.5572052001953125
Validation loss: 1.9063957250246437

Epoch: 214| Step: 0
Training loss: 1.6539039611816406
Validation loss: 1.8908593411086707

Epoch: 6| Step: 1
Training loss: 1.407187581062317
Validation loss: 1.9120142536778604

Epoch: 6| Step: 2
Training loss: 2.2465827465057373
Validation loss: 1.8950692299873597

Epoch: 6| Step: 3
Training loss: 2.549152374267578
Validation loss: 1.9008330093917025

Epoch: 6| Step: 4
Training loss: 1.5820600986480713
Validation loss: 1.8822433179424656

Epoch: 6| Step: 5
Training loss: 1.7084388732910156
Validation loss: 1.8449273186345254

Epoch: 6| Step: 6
Training loss: 1.756636619567871
Validation loss: 1.9076751816657282

Epoch: 6| Step: 7
Training loss: 2.2370080947875977
Validation loss: 1.9175324606639084

Epoch: 6| Step: 8
Training loss: 1.4568513631820679
Validation loss: 1.8886499738180509

Epoch: 6| Step: 9
Training loss: 1.6274441480636597
Validation loss: 1.8715853486009824

Epoch: 6| Step: 10
Training loss: 1.8544011116027832
Validation loss: 1.8823066167933966

Epoch: 6| Step: 11
Training loss: 1.6156032085418701
Validation loss: 1.9082545541947888

Epoch: 6| Step: 12
Training loss: 1.5516152381896973
Validation loss: 1.890201537839828

Epoch: 6| Step: 13
Training loss: 1.8780831098556519
Validation loss: 1.873687892831782

Epoch: 215| Step: 0
Training loss: 1.8528021574020386
Validation loss: 1.9024364871363486

Epoch: 6| Step: 1
Training loss: 2.1995227336883545
Validation loss: 1.8925851955208728

Epoch: 6| Step: 2
Training loss: 1.6309815645217896
Validation loss: 1.8939939775774557

Epoch: 6| Step: 3
Training loss: 1.990563154220581
Validation loss: 1.8880978656071488

Epoch: 6| Step: 4
Training loss: 2.7483644485473633
Validation loss: 1.8999052329729962

Epoch: 6| Step: 5
Training loss: 1.4524822235107422
Validation loss: 1.9128096321577668

Epoch: 6| Step: 6
Training loss: 1.379550814628601
Validation loss: 1.9116320533137168

Epoch: 6| Step: 7
Training loss: 1.7801611423492432
Validation loss: 1.9295627647830593

Epoch: 6| Step: 8
Training loss: 1.7998082637786865
Validation loss: 1.9191454661789762

Epoch: 6| Step: 9
Training loss: 2.0502753257751465
Validation loss: 1.903339275749781

Epoch: 6| Step: 10
Training loss: 1.509577989578247
Validation loss: 1.8801848465396511

Epoch: 6| Step: 11
Training loss: 1.3178331851959229
Validation loss: 1.876309319209027

Epoch: 6| Step: 12
Training loss: 1.3918917179107666
Validation loss: 1.8986117045084636

Epoch: 6| Step: 13
Training loss: 2.381377935409546
Validation loss: 1.89883678959262

Epoch: 216| Step: 0
Training loss: 2.088064193725586
Validation loss: 1.8696229534764444

Epoch: 6| Step: 1
Training loss: 1.6175214052200317
Validation loss: 1.8858776528348205

Epoch: 6| Step: 2
Training loss: 1.4834821224212646
Validation loss: 1.8927237731154247

Epoch: 6| Step: 3
Training loss: 1.0461595058441162
Validation loss: 1.8843594661322973

Epoch: 6| Step: 4
Training loss: 2.253060817718506
Validation loss: 1.901140974413964

Epoch: 6| Step: 5
Training loss: 1.6429378986358643
Validation loss: 1.9042712039844965

Epoch: 6| Step: 6
Training loss: 2.2336783409118652
Validation loss: 1.8490396481688305

Epoch: 6| Step: 7
Training loss: 1.6412298679351807
Validation loss: 1.8830714097587011

Epoch: 6| Step: 8
Training loss: 2.1530516147613525
Validation loss: 1.871350460155036

Epoch: 6| Step: 9
Training loss: 2.014158010482788
Validation loss: 1.8897494936502108

Epoch: 6| Step: 10
Training loss: 1.9344300031661987
Validation loss: 1.8981716812297862

Epoch: 6| Step: 11
Training loss: 1.565403699874878
Validation loss: 1.888302565902792

Epoch: 6| Step: 12
Training loss: 1.6235253810882568
Validation loss: 1.885089333339404

Epoch: 6| Step: 13
Training loss: 1.653082013130188
Validation loss: 1.881219349881654

Epoch: 217| Step: 0
Training loss: 1.3608474731445312
Validation loss: 1.9057359028888006

Epoch: 6| Step: 1
Training loss: 1.0833402872085571
Validation loss: 1.8840710680971864

Epoch: 6| Step: 2
Training loss: 1.5999175310134888
Validation loss: 1.899760974350796

Epoch: 6| Step: 3
Training loss: 1.948895812034607
Validation loss: 1.895839004106419

Epoch: 6| Step: 4
Training loss: 1.3597230911254883
Validation loss: 1.8951439062754314

Epoch: 6| Step: 5
Training loss: 1.63425612449646
Validation loss: 1.8711828544575682

Epoch: 6| Step: 6
Training loss: 1.6063227653503418
Validation loss: 1.905964232260181

Epoch: 6| Step: 7
Training loss: 2.0787439346313477
Validation loss: 1.887986316475817

Epoch: 6| Step: 8
Training loss: 3.0706591606140137
Validation loss: 1.8849842791916223

Epoch: 6| Step: 9
Training loss: 1.9642966985702515
Validation loss: 1.8927072773697555

Epoch: 6| Step: 10
Training loss: 1.5655832290649414
Validation loss: 1.9084591147720174

Epoch: 6| Step: 11
Training loss: 1.7784757614135742
Validation loss: 1.8807829118544055

Epoch: 6| Step: 12
Training loss: 1.4346829652786255
Validation loss: 1.8793797569890176

Epoch: 6| Step: 13
Training loss: 2.1909167766571045
Validation loss: 1.8985206311748875

Epoch: 218| Step: 0
Training loss: 1.7957344055175781
Validation loss: 1.8860349065514022

Epoch: 6| Step: 1
Training loss: 1.0980585813522339
Validation loss: 1.8829229775295462

Epoch: 6| Step: 2
Training loss: 1.895939826965332
Validation loss: 1.899159477603051

Epoch: 6| Step: 3
Training loss: 2.056295156478882
Validation loss: 1.8797964101196618

Epoch: 6| Step: 4
Training loss: 1.7053967714309692
Validation loss: 1.9165927274252779

Epoch: 6| Step: 5
Training loss: 1.9109971523284912
Validation loss: 1.8656474723610827

Epoch: 6| Step: 6
Training loss: 1.6360490322113037
Validation loss: 1.8817827265749696

Epoch: 6| Step: 7
Training loss: 1.338871955871582
Validation loss: 1.8971949123567151

Epoch: 6| Step: 8
Training loss: 1.7806532382965088
Validation loss: 1.8964672883351643

Epoch: 6| Step: 9
Training loss: 2.0341341495513916
Validation loss: 1.9015070956240419

Epoch: 6| Step: 10
Training loss: 2.922779083251953
Validation loss: 1.926043455318738

Epoch: 6| Step: 11
Training loss: 1.5685806274414062
Validation loss: 1.8948555787404378

Epoch: 6| Step: 12
Training loss: 1.2660236358642578
Validation loss: 1.9223854464869345

Epoch: 6| Step: 13
Training loss: 1.4658139944076538
Validation loss: 1.9070932595960555

Epoch: 219| Step: 0
Training loss: 1.532111644744873
Validation loss: 1.9120330272182342

Epoch: 6| Step: 1
Training loss: 1.7316728830337524
Validation loss: 1.9105263807440316

Epoch: 6| Step: 2
Training loss: 1.081267237663269
Validation loss: 1.9412243520059893

Epoch: 6| Step: 3
Training loss: 2.1741364002227783
Validation loss: 1.9077695364593177

Epoch: 6| Step: 4
Training loss: 1.6729578971862793
Validation loss: 1.8972761707921182

Epoch: 6| Step: 5
Training loss: 2.4969770908355713
Validation loss: 1.9024765927304503

Epoch: 6| Step: 6
Training loss: 1.700134038925171
Validation loss: 1.9103917101378083

Epoch: 6| Step: 7
Training loss: 2.197957992553711
Validation loss: 1.8928244165194932

Epoch: 6| Step: 8
Training loss: 1.896599292755127
Validation loss: 1.9108422020430207

Epoch: 6| Step: 9
Training loss: 1.6093065738677979
Validation loss: 1.8655661036891322

Epoch: 6| Step: 10
Training loss: 1.8858622312545776
Validation loss: 1.8824497679228425

Epoch: 6| Step: 11
Training loss: 1.5422170162200928
Validation loss: 1.8518347124899588

Epoch: 6| Step: 12
Training loss: 1.1194825172424316
Validation loss: 1.8756906909327353

Epoch: 6| Step: 13
Training loss: 2.7874557971954346
Validation loss: 1.8773119808525167

Epoch: 220| Step: 0
Training loss: 2.205273151397705
Validation loss: 1.8765741996867682

Epoch: 6| Step: 1
Training loss: 1.6711909770965576
Validation loss: 1.859570357107347

Epoch: 6| Step: 2
Training loss: 2.0605664253234863
Validation loss: 1.8876365359111498

Epoch: 6| Step: 3
Training loss: 2.0560736656188965
Validation loss: 1.920359621765793

Epoch: 6| Step: 4
Training loss: 1.5067646503448486
Validation loss: 1.898721420636741

Epoch: 6| Step: 5
Training loss: 2.4969115257263184
Validation loss: 1.9252331897776613

Epoch: 6| Step: 6
Training loss: 1.6539661884307861
Validation loss: 1.8782279119696668

Epoch: 6| Step: 7
Training loss: 1.7152719497680664
Validation loss: 1.883550565729859

Epoch: 6| Step: 8
Training loss: 1.7721508741378784
Validation loss: 1.9235453528742636

Epoch: 6| Step: 9
Training loss: 1.3075069189071655
Validation loss: 1.9320907669682656

Epoch: 6| Step: 10
Training loss: 1.126968502998352
Validation loss: 1.874503743263983

Epoch: 6| Step: 11
Training loss: 2.1435325145721436
Validation loss: 1.9006086780178932

Epoch: 6| Step: 12
Training loss: 1.6743323802947998
Validation loss: 1.890354875595339

Epoch: 6| Step: 13
Training loss: 1.6340117454528809
Validation loss: 1.9127875322936683

Epoch: 221| Step: 0
Training loss: 1.6115784645080566
Validation loss: 1.8850074288665608

Epoch: 6| Step: 1
Training loss: 2.098581314086914
Validation loss: 1.8916138756659724

Epoch: 6| Step: 2
Training loss: 2.4894368648529053
Validation loss: 1.925637419505786

Epoch: 6| Step: 3
Training loss: 1.327577829360962
Validation loss: 1.8852694880577825

Epoch: 6| Step: 4
Training loss: 1.8801801204681396
Validation loss: 1.8682381363325222

Epoch: 6| Step: 5
Training loss: 1.3203339576721191
Validation loss: 1.8930933539585402

Epoch: 6| Step: 6
Training loss: 2.087491035461426
Validation loss: 1.8790109144744052

Epoch: 6| Step: 7
Training loss: 1.2403218746185303
Validation loss: 1.899627185636951

Epoch: 6| Step: 8
Training loss: 1.9009475708007812
Validation loss: 1.9021857759003997

Epoch: 6| Step: 9
Training loss: 1.6028807163238525
Validation loss: 1.9240889369800527

Epoch: 6| Step: 10
Training loss: 2.267591714859009
Validation loss: 1.8947442218821535

Epoch: 6| Step: 11
Training loss: 1.5070257186889648
Validation loss: 1.912845116789623

Epoch: 6| Step: 12
Training loss: 1.7568541765213013
Validation loss: 1.9068709419619652

Epoch: 6| Step: 13
Training loss: 1.4945180416107178
Validation loss: 1.9008665546294181

Epoch: 222| Step: 0
Training loss: 1.2276134490966797
Validation loss: 1.901081036495906

Epoch: 6| Step: 1
Training loss: 2.332214593887329
Validation loss: 1.860678558708519

Epoch: 6| Step: 2
Training loss: 1.9515538215637207
Validation loss: 1.8889720542456514

Epoch: 6| Step: 3
Training loss: 1.8169703483581543
Validation loss: 1.8641957262510895

Epoch: 6| Step: 4
Training loss: 1.3839898109436035
Validation loss: 1.8916855332671956

Epoch: 6| Step: 5
Training loss: 1.901045799255371
Validation loss: 1.8737716854259532

Epoch: 6| Step: 6
Training loss: 2.2950167655944824
Validation loss: 1.8879851987285

Epoch: 6| Step: 7
Training loss: 2.185030937194824
Validation loss: 1.8566845450350034

Epoch: 6| Step: 8
Training loss: 2.2594187259674072
Validation loss: 1.883153876950664

Epoch: 6| Step: 9
Training loss: 1.0734946727752686
Validation loss: 1.8780839968753118

Epoch: 6| Step: 10
Training loss: 1.322039246559143
Validation loss: 1.861749666993336

Epoch: 6| Step: 11
Training loss: 1.8428794145584106
Validation loss: 1.8911627851506716

Epoch: 6| Step: 12
Training loss: 1.1898925304412842
Validation loss: 1.87406527098789

Epoch: 6| Step: 13
Training loss: 1.893474817276001
Validation loss: 1.890004463093255

Epoch: 223| Step: 0
Training loss: 1.3839631080627441
Validation loss: 1.8976282650424587

Epoch: 6| Step: 1
Training loss: 1.248856782913208
Validation loss: 1.8595998261564521

Epoch: 6| Step: 2
Training loss: 1.8462896347045898
Validation loss: 1.8806320980031004

Epoch: 6| Step: 3
Training loss: 1.692396640777588
Validation loss: 1.919332552981633

Epoch: 6| Step: 4
Training loss: 1.703935146331787
Validation loss: 1.9256156926514

Epoch: 6| Step: 5
Training loss: 2.144662618637085
Validation loss: 1.932321084442959

Epoch: 6| Step: 6
Training loss: 1.7862783670425415
Validation loss: 1.916843020787803

Epoch: 6| Step: 7
Training loss: 2.088491201400757
Validation loss: 1.8972271027103547

Epoch: 6| Step: 8
Training loss: 1.6546827554702759
Validation loss: 1.883020321528117

Epoch: 6| Step: 9
Training loss: 1.9194228649139404
Validation loss: 1.8925726516272432

Epoch: 6| Step: 10
Training loss: 2.4355106353759766
Validation loss: 1.8918598928759176

Epoch: 6| Step: 11
Training loss: 1.6821471452713013
Validation loss: 1.9263508524945987

Epoch: 6| Step: 12
Training loss: 1.8877716064453125
Validation loss: 1.9147177396282073

Epoch: 6| Step: 13
Training loss: 0.9236457347869873
Validation loss: 1.8905734221140544

Epoch: 224| Step: 0
Training loss: 1.744765281677246
Validation loss: 1.9200598680844871

Epoch: 6| Step: 1
Training loss: 1.9312986135482788
Validation loss: 1.9048481423367736

Epoch: 6| Step: 2
Training loss: 1.8359369039535522
Validation loss: 1.9017961025238037

Epoch: 6| Step: 3
Training loss: 2.082850694656372
Validation loss: 1.904953892512988

Epoch: 6| Step: 4
Training loss: 1.7372835874557495
Validation loss: 1.8918153009107035

Epoch: 6| Step: 5
Training loss: 2.039900779724121
Validation loss: 1.883716275615077

Epoch: 6| Step: 6
Training loss: 1.9464471340179443
Validation loss: 1.8801801935318978

Epoch: 6| Step: 7
Training loss: 1.2689564228057861
Validation loss: 1.8886798966315486

Epoch: 6| Step: 8
Training loss: 1.4824738502502441
Validation loss: 1.9001074593554261

Epoch: 6| Step: 9
Training loss: 2.001373052597046
Validation loss: 1.8785228306247341

Epoch: 6| Step: 10
Training loss: 1.505197525024414
Validation loss: 1.8645004136587984

Epoch: 6| Step: 11
Training loss: 1.5980221033096313
Validation loss: 1.8682352022458149

Epoch: 6| Step: 12
Training loss: 2.2593064308166504
Validation loss: 1.8917112811919181

Epoch: 6| Step: 13
Training loss: 0.7851502895355225
Validation loss: 1.9263955803327664

Epoch: 225| Step: 0
Training loss: 1.4831655025482178
Validation loss: 1.9096387458103958

Epoch: 6| Step: 1
Training loss: 2.1100411415100098
Validation loss: 1.8922680334378315

Epoch: 6| Step: 2
Training loss: 1.3591547012329102
Validation loss: 1.8815764086220854

Epoch: 6| Step: 3
Training loss: 1.7450577020645142
Validation loss: 1.8821301998630646

Epoch: 6| Step: 4
Training loss: 1.8293391466140747
Validation loss: 1.8910069350273377

Epoch: 6| Step: 5
Training loss: 1.5214018821716309
Validation loss: 1.881036361058553

Epoch: 6| Step: 6
Training loss: 1.834606409072876
Validation loss: 1.9020512706489974

Epoch: 6| Step: 7
Training loss: 1.543804407119751
Validation loss: 1.9238524847133185

Epoch: 6| Step: 8
Training loss: 1.3253846168518066
Validation loss: 1.8558188958834576

Epoch: 6| Step: 9
Training loss: 1.799850583076477
Validation loss: 1.8977590427603772

Epoch: 6| Step: 10
Training loss: 2.183701515197754
Validation loss: 1.856894475157543

Epoch: 6| Step: 11
Training loss: 1.003957748413086
Validation loss: 1.8558080452744679

Epoch: 6| Step: 12
Training loss: 2.446533203125
Validation loss: 1.896574766405167

Epoch: 6| Step: 13
Training loss: 2.6791722774505615
Validation loss: 1.8850878387369134

Epoch: 226| Step: 0
Training loss: 1.6068580150604248
Validation loss: 1.9023974800622592

Epoch: 6| Step: 1
Training loss: 1.3773877620697021
Validation loss: 1.895237438140377

Epoch: 6| Step: 2
Training loss: 1.4245922565460205
Validation loss: 1.8662212817899642

Epoch: 6| Step: 3
Training loss: 2.1872341632843018
Validation loss: 1.8880184978567145

Epoch: 6| Step: 4
Training loss: 1.957128882408142
Validation loss: 1.898568094417613

Epoch: 6| Step: 5
Training loss: 1.2867423295974731
Validation loss: 1.868070687017133

Epoch: 6| Step: 6
Training loss: 1.9471569061279297
Validation loss: 1.9045902349615609

Epoch: 6| Step: 7
Training loss: 2.18302059173584
Validation loss: 1.8846667684534544

Epoch: 6| Step: 8
Training loss: 2.3185627460479736
Validation loss: 1.87931978061635

Epoch: 6| Step: 9
Training loss: 1.9766075611114502
Validation loss: 1.9057586628903624

Epoch: 6| Step: 10
Training loss: 1.4656040668487549
Validation loss: 1.8769104852471301

Epoch: 6| Step: 11
Training loss: 1.462127923965454
Validation loss: 1.8980696342324699

Epoch: 6| Step: 12
Training loss: 1.7022333145141602
Validation loss: 1.880202586932849

Epoch: 6| Step: 13
Training loss: 1.3033041954040527
Validation loss: 1.9285340180961035

Epoch: 227| Step: 0
Training loss: 2.4023003578186035
Validation loss: 1.872610056272117

Epoch: 6| Step: 1
Training loss: 0.5365005731582642
Validation loss: 1.8899567934774584

Epoch: 6| Step: 2
Training loss: 1.5248463153839111
Validation loss: 1.8835361183330577

Epoch: 6| Step: 3
Training loss: 1.8901928663253784
Validation loss: 1.8802926463465537

Epoch: 6| Step: 4
Training loss: 2.1880431175231934
Validation loss: 1.853832116691015

Epoch: 6| Step: 5
Training loss: 1.5666370391845703
Validation loss: 1.8799491800287718

Epoch: 6| Step: 6
Training loss: 1.7608027458190918
Validation loss: 1.8737252014939503

Epoch: 6| Step: 7
Training loss: 1.5160951614379883
Validation loss: 1.892467926907283

Epoch: 6| Step: 8
Training loss: 0.9957315325737
Validation loss: 1.8833344033969346

Epoch: 6| Step: 9
Training loss: 2.3875956535339355
Validation loss: 1.9032095260517572

Epoch: 6| Step: 10
Training loss: 2.2988905906677246
Validation loss: 1.8976941839341195

Epoch: 6| Step: 11
Training loss: 2.167041063308716
Validation loss: 1.8795244386119228

Epoch: 6| Step: 12
Training loss: 1.5655148029327393
Validation loss: 1.855026610435978

Epoch: 6| Step: 13
Training loss: 1.2624648809432983
Validation loss: 1.8905909061431885

Epoch: 228| Step: 0
Training loss: 1.5174586772918701
Validation loss: 1.866009872446778

Epoch: 6| Step: 1
Training loss: 2.0615103244781494
Validation loss: 1.8632138877786615

Epoch: 6| Step: 2
Training loss: 1.7440365552902222
Validation loss: 1.8544645206902617

Epoch: 6| Step: 3
Training loss: 2.2468061447143555
Validation loss: 1.8668127764937699

Epoch: 6| Step: 4
Training loss: 1.5591121912002563
Validation loss: 1.8623407630510227

Epoch: 6| Step: 5
Training loss: 1.8536841869354248
Validation loss: 1.8947983877633208

Epoch: 6| Step: 6
Training loss: 2.264458656311035
Validation loss: 1.8915396787786996

Epoch: 6| Step: 7
Training loss: 1.5298717021942139
Validation loss: 1.8680336718918176

Epoch: 6| Step: 8
Training loss: 1.752946138381958
Validation loss: 1.8849919303770988

Epoch: 6| Step: 9
Training loss: 1.7298078536987305
Validation loss: 1.8872913596450642

Epoch: 6| Step: 10
Training loss: 1.592186689376831
Validation loss: 1.8911914953621485

Epoch: 6| Step: 11
Training loss: 1.158206582069397
Validation loss: 1.8584737726437148

Epoch: 6| Step: 12
Training loss: 1.448871374130249
Validation loss: 1.8792908960773098

Epoch: 6| Step: 13
Training loss: 1.973604440689087
Validation loss: 1.8695578203406384

Epoch: 229| Step: 0
Training loss: 1.9678499698638916
Validation loss: 1.8979746808287918

Epoch: 6| Step: 1
Training loss: 1.8207571506500244
Validation loss: 1.8645836473793111

Epoch: 6| Step: 2
Training loss: 2.2810311317443848
Validation loss: 1.8986535982419086

Epoch: 6| Step: 3
Training loss: 1.881069302558899
Validation loss: 1.8686836227293937

Epoch: 6| Step: 4
Training loss: 1.7481600046157837
Validation loss: 1.8784568617420812

Epoch: 6| Step: 5
Training loss: 1.3337479829788208
Validation loss: 1.8967102086672218

Epoch: 6| Step: 6
Training loss: 1.9243078231811523
Validation loss: 1.8948897418155466

Epoch: 6| Step: 7
Training loss: 1.9013773202896118
Validation loss: 1.8949243496823054

Epoch: 6| Step: 8
Training loss: 1.935672402381897
Validation loss: 1.871313561675369

Epoch: 6| Step: 9
Training loss: 1.6496385335922241
Validation loss: 1.9171192979299894

Epoch: 6| Step: 10
Training loss: 1.181846022605896
Validation loss: 1.9030081507980183

Epoch: 6| Step: 11
Training loss: 1.0115796327590942
Validation loss: 1.9050632497315765

Epoch: 6| Step: 12
Training loss: 2.103400707244873
Validation loss: 1.9174844347020632

Epoch: 6| Step: 13
Training loss: 1.586328148841858
Validation loss: 1.9141288829106156

Epoch: 230| Step: 0
Training loss: 2.276458740234375
Validation loss: 1.8944476932607672

Epoch: 6| Step: 1
Training loss: 1.587609052658081
Validation loss: 1.8745019666610225

Epoch: 6| Step: 2
Training loss: 1.5266332626342773
Validation loss: 1.8844212434625114

Epoch: 6| Step: 3
Training loss: 2.3727025985717773
Validation loss: 1.861987421589513

Epoch: 6| Step: 4
Training loss: 2.2605104446411133
Validation loss: 1.8617517948150635

Epoch: 6| Step: 5
Training loss: 1.6915087699890137
Validation loss: 1.8614741525342386

Epoch: 6| Step: 6
Training loss: 1.384716510772705
Validation loss: 1.8945922697744062

Epoch: 6| Step: 7
Training loss: 1.7952423095703125
Validation loss: 1.8507501348372428

Epoch: 6| Step: 8
Training loss: 1.4986329078674316
Validation loss: 1.875881859051284

Epoch: 6| Step: 9
Training loss: 1.8473260402679443
Validation loss: 1.8434335275362896

Epoch: 6| Step: 10
Training loss: 1.4866379499435425
Validation loss: 1.8712771810511106

Epoch: 6| Step: 11
Training loss: 1.336190104484558
Validation loss: 1.8801469277310114

Epoch: 6| Step: 12
Training loss: 1.4451844692230225
Validation loss: 1.8829698126803163

Epoch: 6| Step: 13
Training loss: 1.8789392709732056
Validation loss: 1.8687389076396983

Epoch: 231| Step: 0
Training loss: 1.6727123260498047
Validation loss: 1.881755316770205

Epoch: 6| Step: 1
Training loss: 2.2540793418884277
Validation loss: 1.8717122244578537

Epoch: 6| Step: 2
Training loss: 1.4497356414794922
Validation loss: 1.876126161185644

Epoch: 6| Step: 3
Training loss: 1.1691699028015137
Validation loss: 1.8974368392780263

Epoch: 6| Step: 4
Training loss: 2.0037503242492676
Validation loss: 1.8946306500383603

Epoch: 6| Step: 5
Training loss: 1.9306930303573608
Validation loss: 1.901431159306598

Epoch: 6| Step: 6
Training loss: 1.5779523849487305
Validation loss: 1.8684538551556167

Epoch: 6| Step: 7
Training loss: 0.8319091200828552
Validation loss: 1.9122306249474967

Epoch: 6| Step: 8
Training loss: 1.1340382099151611
Validation loss: 1.9231737275277414

Epoch: 6| Step: 9
Training loss: 2.15950870513916
Validation loss: 1.8909222631044285

Epoch: 6| Step: 10
Training loss: 1.6663215160369873
Validation loss: 1.8976883619062361

Epoch: 6| Step: 11
Training loss: 2.5177817344665527
Validation loss: 1.8679960658473354

Epoch: 6| Step: 12
Training loss: 2.079592227935791
Validation loss: 1.8973468272916731

Epoch: 6| Step: 13
Training loss: 1.998445749282837
Validation loss: 1.901322623734833

Epoch: 232| Step: 0
Training loss: 1.2501846551895142
Validation loss: 1.8821838389160812

Epoch: 6| Step: 1
Training loss: 1.9610800743103027
Validation loss: 1.8924964589457358

Epoch: 6| Step: 2
Training loss: 1.6668589115142822
Validation loss: 1.8885969013296149

Epoch: 6| Step: 3
Training loss: 1.6321982145309448
Validation loss: 1.8483171898831603

Epoch: 6| Step: 4
Training loss: 1.6601300239562988
Validation loss: 1.8648541973483177

Epoch: 6| Step: 5
Training loss: 1.49417245388031
Validation loss: 1.8833765214489353

Epoch: 6| Step: 6
Training loss: 1.406860113143921
Validation loss: 1.900370527339238

Epoch: 6| Step: 7
Training loss: 2.295191764831543
Validation loss: 1.8796138776245939

Epoch: 6| Step: 8
Training loss: 1.8141764402389526
Validation loss: 1.8899763950737574

Epoch: 6| Step: 9
Training loss: 1.5896540880203247
Validation loss: 1.8523772865213373

Epoch: 6| Step: 10
Training loss: 1.7051305770874023
Validation loss: 1.856375499438214

Epoch: 6| Step: 11
Training loss: 1.7068285942077637
Validation loss: 1.8996775650208997

Epoch: 6| Step: 12
Training loss: 2.2166078090667725
Validation loss: 1.8479748925855082

Epoch: 6| Step: 13
Training loss: 2.2148149013519287
Validation loss: 1.8441105170916485

Epoch: 233| Step: 0
Training loss: 2.069025993347168
Validation loss: 1.8592017581385951

Epoch: 6| Step: 1
Training loss: 1.8229150772094727
Validation loss: 1.8563241407435427

Epoch: 6| Step: 2
Training loss: 1.9049227237701416
Validation loss: 1.88589378710716

Epoch: 6| Step: 3
Training loss: 2.0808374881744385
Validation loss: 1.8871902906766502

Epoch: 6| Step: 4
Training loss: 1.7700800895690918
Validation loss: 1.8692252533410185

Epoch: 6| Step: 5
Training loss: 1.3346631526947021
Validation loss: 1.9120050604625414

Epoch: 6| Step: 6
Training loss: 1.8773202896118164
Validation loss: 1.8700347382535216

Epoch: 6| Step: 7
Training loss: 1.0691168308258057
Validation loss: 1.9076425875386884

Epoch: 6| Step: 8
Training loss: 1.7316282987594604
Validation loss: 1.8804979785796134

Epoch: 6| Step: 9
Training loss: 1.504755973815918
Validation loss: 1.8854823561124905

Epoch: 6| Step: 10
Training loss: 1.7703644037246704
Validation loss: 1.8945171576674267

Epoch: 6| Step: 11
Training loss: 2.004695415496826
Validation loss: 1.8941456707574988

Epoch: 6| Step: 12
Training loss: 1.6417183876037598
Validation loss: 1.8791121808431481

Epoch: 6| Step: 13
Training loss: 1.3427996635437012
Validation loss: 1.9231989332424697

Epoch: 234| Step: 0
Training loss: 1.2632083892822266
Validation loss: 1.9022779567267305

Epoch: 6| Step: 1
Training loss: 1.1297266483306885
Validation loss: 1.9143493098597373

Epoch: 6| Step: 2
Training loss: 1.492156982421875
Validation loss: 1.8777270265804824

Epoch: 6| Step: 3
Training loss: 1.8428385257720947
Validation loss: 1.8677364062237483

Epoch: 6| Step: 4
Training loss: 1.8921817541122437
Validation loss: 1.851106459094632

Epoch: 6| Step: 5
Training loss: 1.5049326419830322
Validation loss: 1.8810894835379817

Epoch: 6| Step: 6
Training loss: 1.5774829387664795
Validation loss: 1.873754511597336

Epoch: 6| Step: 7
Training loss: 1.6707826852798462
Validation loss: 1.8900682374995241

Epoch: 6| Step: 8
Training loss: 1.558266282081604
Validation loss: 1.84919858747913

Epoch: 6| Step: 9
Training loss: 1.8476393222808838
Validation loss: 1.852818004546627

Epoch: 6| Step: 10
Training loss: 2.6732285022735596
Validation loss: 1.8682787956730011

Epoch: 6| Step: 11
Training loss: 2.4777421951293945
Validation loss: 1.858913420349039

Epoch: 6| Step: 12
Training loss: 1.403913140296936
Validation loss: 1.8520664643215876

Epoch: 6| Step: 13
Training loss: 2.0922839641571045
Validation loss: 1.894458068314419

Epoch: 235| Step: 0
Training loss: 1.0614949464797974
Validation loss: 1.8775437314023253

Epoch: 6| Step: 1
Training loss: 1.9469841718673706
Validation loss: 1.8539023630080684

Epoch: 6| Step: 2
Training loss: 1.9210724830627441
Validation loss: 1.8540834688371228

Epoch: 6| Step: 3
Training loss: 1.4390685558319092
Validation loss: 1.8365764720465547

Epoch: 6| Step: 4
Training loss: 1.8828518390655518
Validation loss: 1.8780892433658722

Epoch: 6| Step: 5
Training loss: 1.6202101707458496
Validation loss: 1.8813240887016378

Epoch: 6| Step: 6
Training loss: 1.444678783416748
Validation loss: 1.902651133075837

Epoch: 6| Step: 7
Training loss: 2.4199681282043457
Validation loss: 1.8862337015008415

Epoch: 6| Step: 8
Training loss: 1.8137261867523193
Validation loss: 1.857855127703759

Epoch: 6| Step: 9
Training loss: 1.9072649478912354
Validation loss: 1.8535304659156389

Epoch: 6| Step: 10
Training loss: 1.7563655376434326
Validation loss: 1.8730592830206758

Epoch: 6| Step: 11
Training loss: 2.214418649673462
Validation loss: 1.870576843138664

Epoch: 6| Step: 12
Training loss: 1.4820234775543213
Validation loss: 1.8608826591122536

Epoch: 6| Step: 13
Training loss: 1.238872766494751
Validation loss: 1.8805250942066152

Epoch: 236| Step: 0
Training loss: 2.504910945892334
Validation loss: 1.885006635419784

Epoch: 6| Step: 1
Training loss: 1.6394085884094238
Validation loss: 1.8988136719631892

Epoch: 6| Step: 2
Training loss: 1.5118966102600098
Validation loss: 1.9181210789629208

Epoch: 6| Step: 3
Training loss: 2.1170895099639893
Validation loss: 1.8929215554268128

Epoch: 6| Step: 4
Training loss: 1.4216196537017822
Validation loss: 1.915918880893338

Epoch: 6| Step: 5
Training loss: 1.6776282787322998
Validation loss: 1.834762268168952

Epoch: 6| Step: 6
Training loss: 1.8768274784088135
Validation loss: 1.9281766619733585

Epoch: 6| Step: 7
Training loss: 1.2829272747039795
Validation loss: 1.8789193399490849

Epoch: 6| Step: 8
Training loss: 1.9786593914031982
Validation loss: 1.868157986671694

Epoch: 6| Step: 9
Training loss: 1.945042371749878
Validation loss: 1.8979643057751399

Epoch: 6| Step: 10
Training loss: 1.0683369636535645
Validation loss: 1.8828103234691005

Epoch: 6| Step: 11
Training loss: 1.6625573635101318
Validation loss: 1.878605652880925

Epoch: 6| Step: 12
Training loss: 2.056460380554199
Validation loss: 1.8367871520339802

Epoch: 6| Step: 13
Training loss: 1.4475219249725342
Validation loss: 1.8460364726281935

Epoch: 237| Step: 0
Training loss: 1.3488857746124268
Validation loss: 1.8388878465980611

Epoch: 6| Step: 1
Training loss: 1.5118277072906494
Validation loss: 1.841419586571314

Epoch: 6| Step: 2
Training loss: 2.0809903144836426
Validation loss: 1.8230581719388244

Epoch: 6| Step: 3
Training loss: 1.5756657123565674
Validation loss: 1.8678974566921112

Epoch: 6| Step: 4
Training loss: 1.72586989402771
Validation loss: 1.8257510303169169

Epoch: 6| Step: 5
Training loss: 2.8155622482299805
Validation loss: 1.83744304667237

Epoch: 6| Step: 6
Training loss: 1.893264651298523
Validation loss: 1.8788519854186683

Epoch: 6| Step: 7
Training loss: 1.6950346231460571
Validation loss: 1.8668710313817507

Epoch: 6| Step: 8
Training loss: 1.8529181480407715
Validation loss: 1.892134153714744

Epoch: 6| Step: 9
Training loss: 1.0770971775054932
Validation loss: 1.875750894187599

Epoch: 6| Step: 10
Training loss: 1.7375099658966064
Validation loss: 1.8672228974680747

Epoch: 6| Step: 11
Training loss: 1.945235252380371
Validation loss: 1.8820561849942772

Epoch: 6| Step: 12
Training loss: 1.2735626697540283
Validation loss: 1.8961043242485291

Epoch: 6| Step: 13
Training loss: 2.243195056915283
Validation loss: 1.8957273011566491

Epoch: 238| Step: 0
Training loss: 1.4278924465179443
Validation loss: 1.9020319933532386

Epoch: 6| Step: 1
Training loss: 1.679197907447815
Validation loss: 1.8817236641401887

Epoch: 6| Step: 2
Training loss: 2.31901216506958
Validation loss: 1.8983871577888407

Epoch: 6| Step: 3
Training loss: 1.9079917669296265
Validation loss: 1.8913183981372463

Epoch: 6| Step: 4
Training loss: 1.6505932807922363
Validation loss: 1.9107225325799757

Epoch: 6| Step: 5
Training loss: 1.8138511180877686
Validation loss: 1.8891131826626357

Epoch: 6| Step: 6
Training loss: 1.8827605247497559
Validation loss: 1.8458520391935944

Epoch: 6| Step: 7
Training loss: 2.175100326538086
Validation loss: 1.8817067761575021

Epoch: 6| Step: 8
Training loss: 1.2679076194763184
Validation loss: 1.8962985764267624

Epoch: 6| Step: 9
Training loss: 2.027357816696167
Validation loss: 1.8849927917603524

Epoch: 6| Step: 10
Training loss: 1.285711646080017
Validation loss: 1.852382367657077

Epoch: 6| Step: 11
Training loss: 1.4494757652282715
Validation loss: 1.8662220931822253

Epoch: 6| Step: 12
Training loss: 1.6074544191360474
Validation loss: 1.8735338013659242

Epoch: 6| Step: 13
Training loss: 1.416951060295105
Validation loss: 1.8430302296915362

Epoch: 239| Step: 0
Training loss: 1.2834863662719727
Validation loss: 1.8795789134117864

Epoch: 6| Step: 1
Training loss: 1.2955683469772339
Validation loss: 1.8665715289372269

Epoch: 6| Step: 2
Training loss: 1.1581990718841553
Validation loss: 1.8587320786650463

Epoch: 6| Step: 3
Training loss: 1.4093059301376343
Validation loss: 1.8380534623258857

Epoch: 6| Step: 4
Training loss: 1.7590842247009277
Validation loss: 1.871698869171963

Epoch: 6| Step: 5
Training loss: 2.4811692237854004
Validation loss: 1.8689327983446018

Epoch: 6| Step: 6
Training loss: 2.1815497875213623
Validation loss: 1.8513651765802854

Epoch: 6| Step: 7
Training loss: 2.2863643169403076
Validation loss: 1.87100738094699

Epoch: 6| Step: 8
Training loss: 1.8117395639419556
Validation loss: 1.8680206409064672

Epoch: 6| Step: 9
Training loss: 1.2587957382202148
Validation loss: 1.8710796499765048

Epoch: 6| Step: 10
Training loss: 1.8799400329589844
Validation loss: 1.8968722179371824

Epoch: 6| Step: 11
Training loss: 1.343493103981018
Validation loss: 1.8635433027821202

Epoch: 6| Step: 12
Training loss: 1.804016351699829
Validation loss: 1.903135061264038

Epoch: 6| Step: 13
Training loss: 2.2028419971466064
Validation loss: 1.8474599635729225

Epoch: 240| Step: 0
Training loss: 2.092951774597168
Validation loss: 1.890032055557415

Epoch: 6| Step: 1
Training loss: 1.7078769207000732
Validation loss: 1.8751649151566208

Epoch: 6| Step: 2
Training loss: 1.2466388940811157
Validation loss: 1.8942812847834762

Epoch: 6| Step: 3
Training loss: 1.6339021921157837
Validation loss: 1.8911079770775252

Epoch: 6| Step: 4
Training loss: 2.399819850921631
Validation loss: 1.8593909522538543

Epoch: 6| Step: 5
Training loss: 1.6391236782073975
Validation loss: 1.8506094448028072

Epoch: 6| Step: 6
Training loss: 1.5165610313415527
Validation loss: 1.8321306513201805

Epoch: 6| Step: 7
Training loss: 1.8494441509246826
Validation loss: 1.863696418782716

Epoch: 6| Step: 8
Training loss: 1.3102061748504639
Validation loss: 1.853254472055743

Epoch: 6| Step: 9
Training loss: 1.505965232849121
Validation loss: 1.8783063939822617

Epoch: 6| Step: 10
Training loss: 1.9921153783798218
Validation loss: 1.9101137409928024

Epoch: 6| Step: 11
Training loss: 1.289345383644104
Validation loss: 1.9073060148505754

Epoch: 6| Step: 12
Training loss: 1.7627900838851929
Validation loss: 1.873648121792783

Epoch: 6| Step: 13
Training loss: 2.0682666301727295
Validation loss: 1.895148972029327

Epoch: 241| Step: 0
Training loss: 1.0569970607757568
Validation loss: 1.887637206303176

Epoch: 6| Step: 1
Training loss: 1.7097406387329102
Validation loss: 1.8729375946906306

Epoch: 6| Step: 2
Training loss: 2.010284662246704
Validation loss: 1.8587086328896143

Epoch: 6| Step: 3
Training loss: 1.8293050527572632
Validation loss: 1.8894191044633106

Epoch: 6| Step: 4
Training loss: 1.518226146697998
Validation loss: 1.8946494902333906

Epoch: 6| Step: 5
Training loss: 2.505716323852539
Validation loss: 1.888160095419935

Epoch: 6| Step: 6
Training loss: 2.0434467792510986
Validation loss: 1.942391126386581

Epoch: 6| Step: 7
Training loss: 1.8686087131500244
Validation loss: 1.8864668261620305

Epoch: 6| Step: 8
Training loss: 1.499741554260254
Validation loss: 1.8948724039139286

Epoch: 6| Step: 9
Training loss: 1.069850206375122
Validation loss: 1.896266370691279

Epoch: 6| Step: 10
Training loss: 1.407766342163086
Validation loss: 1.9192596789329284

Epoch: 6| Step: 11
Training loss: 1.7510619163513184
Validation loss: 1.8814004275106615

Epoch: 6| Step: 12
Training loss: 1.7211811542510986
Validation loss: 1.8672198364811559

Epoch: 6| Step: 13
Training loss: 1.983591079711914
Validation loss: 1.8585560334626066

Epoch: 242| Step: 0
Training loss: 2.0352725982666016
Validation loss: 1.8569562832514446

Epoch: 6| Step: 1
Training loss: 1.5739898681640625
Validation loss: 1.8702585312627977

Epoch: 6| Step: 2
Training loss: 1.4343135356903076
Validation loss: 1.8712649114670292

Epoch: 6| Step: 3
Training loss: 2.4404067993164062
Validation loss: 1.8632286082031906

Epoch: 6| Step: 4
Training loss: 1.8484110832214355
Validation loss: 1.8525647591519099

Epoch: 6| Step: 5
Training loss: 1.1987993717193604
Validation loss: 1.8567284640445505

Epoch: 6| Step: 6
Training loss: 2.221965789794922
Validation loss: 1.8613556405549407

Epoch: 6| Step: 7
Training loss: 1.9736632108688354
Validation loss: 1.8426412690070368

Epoch: 6| Step: 8
Training loss: 1.6058530807495117
Validation loss: 1.8778158887740104

Epoch: 6| Step: 9
Training loss: 1.747433066368103
Validation loss: 1.8994823514774282

Epoch: 6| Step: 10
Training loss: 1.546661138534546
Validation loss: 1.8536080352721676

Epoch: 6| Step: 11
Training loss: 1.431713581085205
Validation loss: 1.873130835512633

Epoch: 6| Step: 12
Training loss: 0.8861131072044373
Validation loss: 1.8475112222856092

Epoch: 6| Step: 13
Training loss: 1.8094689846038818
Validation loss: 1.8505834738413494

Epoch: 243| Step: 0
Training loss: 1.7155029773712158
Validation loss: 1.9032916535613358

Epoch: 6| Step: 1
Training loss: 1.6915974617004395
Validation loss: 1.9044971453246249

Epoch: 6| Step: 2
Training loss: 1.399548053741455
Validation loss: 1.9021972507558844

Epoch: 6| Step: 3
Training loss: 1.5267142057418823
Validation loss: 1.9034641635033391

Epoch: 6| Step: 4
Training loss: 2.3865718841552734
Validation loss: 1.8820898661049463

Epoch: 6| Step: 5
Training loss: 1.6359882354736328
Validation loss: 1.8740905420754546

Epoch: 6| Step: 6
Training loss: 1.3454198837280273
Validation loss: 1.878333955682734

Epoch: 6| Step: 7
Training loss: 1.3396196365356445
Validation loss: 1.8593091913448867

Epoch: 6| Step: 8
Training loss: 2.038877010345459
Validation loss: 1.868096261896113

Epoch: 6| Step: 9
Training loss: 1.8656158447265625
Validation loss: 1.8590301198344077

Epoch: 6| Step: 10
Training loss: 1.8594626188278198
Validation loss: 1.8766329570483136

Epoch: 6| Step: 11
Training loss: 1.7477178573608398
Validation loss: 1.862548533306327

Epoch: 6| Step: 12
Training loss: 1.6051301956176758
Validation loss: 1.8634322074151808

Epoch: 6| Step: 13
Training loss: 1.748533010482788
Validation loss: 1.8722178833459013

Epoch: 244| Step: 0
Training loss: 2.2008254528045654
Validation loss: 1.875404824492752

Epoch: 6| Step: 1
Training loss: 1.9472243785858154
Validation loss: 1.8606895464722828

Epoch: 6| Step: 2
Training loss: 1.820420742034912
Validation loss: 1.8678658867395053

Epoch: 6| Step: 3
Training loss: 1.4987603425979614
Validation loss: 1.872988902112489

Epoch: 6| Step: 4
Training loss: 1.2835161685943604
Validation loss: 1.870938918923819

Epoch: 6| Step: 5
Training loss: 1.565453052520752
Validation loss: 1.8810859123865764

Epoch: 6| Step: 6
Training loss: 1.7845237255096436
Validation loss: 1.8750444278922132

Epoch: 6| Step: 7
Training loss: 1.7394914627075195
Validation loss: 1.8806540363578386

Epoch: 6| Step: 8
Training loss: 1.6155369281768799
Validation loss: 1.9146193688915623

Epoch: 6| Step: 9
Training loss: 2.297097682952881
Validation loss: 1.894070235631799

Epoch: 6| Step: 10
Training loss: 1.331151008605957
Validation loss: 1.9051048089099187

Epoch: 6| Step: 11
Training loss: 1.489250898361206
Validation loss: 1.8613746114956435

Epoch: 6| Step: 12
Training loss: 1.7688708305358887
Validation loss: 1.8861591662130048

Epoch: 6| Step: 13
Training loss: 1.250053882598877
Validation loss: 1.8776889821534515

Epoch: 245| Step: 0
Training loss: 1.2623255252838135
Validation loss: 1.8822527957218949

Epoch: 6| Step: 1
Training loss: 2.257145404815674
Validation loss: 1.8562385164281374

Epoch: 6| Step: 2
Training loss: 1.5889558792114258
Validation loss: 1.8765021831758562

Epoch: 6| Step: 3
Training loss: 2.166779041290283
Validation loss: 1.9002829790115356

Epoch: 6| Step: 4
Training loss: 1.2771903276443481
Validation loss: 1.9012171581227293

Epoch: 6| Step: 5
Training loss: 1.436927318572998
Validation loss: 1.8652033600755917

Epoch: 6| Step: 6
Training loss: 1.367689609527588
Validation loss: 1.8649282404171523

Epoch: 6| Step: 7
Training loss: 2.070119619369507
Validation loss: 1.900464238659028

Epoch: 6| Step: 8
Training loss: 1.4947662353515625
Validation loss: 1.8649821319887716

Epoch: 6| Step: 9
Training loss: 1.5336244106292725
Validation loss: 1.8997082915357364

Epoch: 6| Step: 10
Training loss: 1.7794439792633057
Validation loss: 1.8892706876159997

Epoch: 6| Step: 11
Training loss: 1.7533290386199951
Validation loss: 1.8651410687354304

Epoch: 6| Step: 12
Training loss: 1.7861180305480957
Validation loss: 1.873415716232792

Epoch: 6| Step: 13
Training loss: 2.24159574508667
Validation loss: 1.8547055823828584

Epoch: 246| Step: 0
Training loss: 1.7196276187896729
Validation loss: 1.8591953054551156

Epoch: 6| Step: 1
Training loss: 1.3701601028442383
Validation loss: 1.878499028503254

Epoch: 6| Step: 2
Training loss: 1.4325792789459229
Validation loss: 1.8714780140948553

Epoch: 6| Step: 3
Training loss: 2.124570846557617
Validation loss: 1.8333650250588693

Epoch: 6| Step: 4
Training loss: 2.4740488529205322
Validation loss: 1.8746831083810458

Epoch: 6| Step: 5
Training loss: 1.1824753284454346
Validation loss: 1.888861028097009

Epoch: 6| Step: 6
Training loss: 1.2147817611694336
Validation loss: 1.8695359947860881

Epoch: 6| Step: 7
Training loss: 1.3842068910598755
Validation loss: 1.8225093157060686

Epoch: 6| Step: 8
Training loss: 2.528757095336914
Validation loss: 1.8420567922694708

Epoch: 6| Step: 9
Training loss: 1.167927622795105
Validation loss: 1.860662079626514

Epoch: 6| Step: 10
Training loss: 1.3945211172103882
Validation loss: 1.8568556462564776

Epoch: 6| Step: 11
Training loss: 2.0029187202453613
Validation loss: 1.8433763570682977

Epoch: 6| Step: 12
Training loss: 1.9833765029907227
Validation loss: 1.8752070947359967

Epoch: 6| Step: 13
Training loss: 2.050259590148926
Validation loss: 1.8822602379706599

Epoch: 247| Step: 0
Training loss: 2.5440073013305664
Validation loss: 1.866306871496221

Epoch: 6| Step: 1
Training loss: 1.3047977685928345
Validation loss: 1.8791139946188977

Epoch: 6| Step: 2
Training loss: 1.1767045259475708
Validation loss: 1.9011740966509747

Epoch: 6| Step: 3
Training loss: 1.7998237609863281
Validation loss: 1.8820533906259844

Epoch: 6| Step: 4
Training loss: 1.9446702003479004
Validation loss: 1.9056439117718769

Epoch: 6| Step: 5
Training loss: 1.9712285995483398
Validation loss: 1.885323973112209

Epoch: 6| Step: 6
Training loss: 2.2654027938842773
Validation loss: 1.888611275662658

Epoch: 6| Step: 7
Training loss: 1.5947893857955933
Validation loss: 1.8837554198439403

Epoch: 6| Step: 8
Training loss: 1.6014518737792969
Validation loss: 1.9019671691361295

Epoch: 6| Step: 9
Training loss: 0.9293514490127563
Validation loss: 1.8814824588837162

Epoch: 6| Step: 10
Training loss: 1.2854466438293457
Validation loss: 1.8939886862231838

Epoch: 6| Step: 11
Training loss: 1.6468983888626099
Validation loss: 1.873461187526744

Epoch: 6| Step: 12
Training loss: 1.7342002391815186
Validation loss: 1.8957331565118605

Epoch: 6| Step: 13
Training loss: 1.4294484853744507
Validation loss: 1.8529332940296461

Epoch: 248| Step: 0
Training loss: 1.7007933855056763
Validation loss: 1.8535409742786038

Epoch: 6| Step: 1
Training loss: 1.9604610204696655
Validation loss: 1.871173854797117

Epoch: 6| Step: 2
Training loss: 1.8838262557983398
Validation loss: 1.8442159519400647

Epoch: 6| Step: 3
Training loss: 2.325942277908325
Validation loss: 1.8571027863410212

Epoch: 6| Step: 4
Training loss: 1.933945894241333
Validation loss: 1.8890859670536493

Epoch: 6| Step: 5
Training loss: 1.211496353149414
Validation loss: 1.8492667111017371

Epoch: 6| Step: 6
Training loss: 1.377177119255066
Validation loss: 1.85085254843517

Epoch: 6| Step: 7
Training loss: 1.3337666988372803
Validation loss: 1.8645841575437976

Epoch: 6| Step: 8
Training loss: 2.2020561695098877
Validation loss: 1.8431036997866888

Epoch: 6| Step: 9
Training loss: 1.6835880279541016
Validation loss: 1.853762972739435

Epoch: 6| Step: 10
Training loss: 2.076931953430176
Validation loss: 1.905553839539969

Epoch: 6| Step: 11
Training loss: 1.7426469326019287
Validation loss: 1.9004325802608202

Epoch: 6| Step: 12
Training loss: 0.9966291189193726
Validation loss: 1.848661066383444

Epoch: 6| Step: 13
Training loss: 0.749373197555542
Validation loss: 1.8655274221974034

Epoch: 249| Step: 0
Training loss: 1.4504294395446777
Validation loss: 1.8765203004242272

Epoch: 6| Step: 1
Training loss: 1.5565366744995117
Validation loss: 1.8689223015180199

Epoch: 6| Step: 2
Training loss: 2.300084352493286
Validation loss: 1.8729567194497714

Epoch: 6| Step: 3
Training loss: 1.1775697469711304
Validation loss: 1.8454488080034974

Epoch: 6| Step: 4
Training loss: 1.3232085704803467
Validation loss: 1.882725114463478

Epoch: 6| Step: 5
Training loss: 1.8018513917922974
Validation loss: 1.8602218204928982

Epoch: 6| Step: 6
Training loss: 1.7783920764923096
Validation loss: 1.903411699879554

Epoch: 6| Step: 7
Training loss: 1.447466492652893
Validation loss: 1.8755196153476674

Epoch: 6| Step: 8
Training loss: 1.5042645931243896
Validation loss: 1.8838790514135872

Epoch: 6| Step: 9
Training loss: 1.243058443069458
Validation loss: 1.8507696018424085

Epoch: 6| Step: 10
Training loss: 2.6429855823516846
Validation loss: 1.845803870949694

Epoch: 6| Step: 11
Training loss: 2.0366477966308594
Validation loss: 1.8714488603735482

Epoch: 6| Step: 12
Training loss: 1.5769047737121582
Validation loss: 1.8368652110458703

Epoch: 6| Step: 13
Training loss: 1.6897176504135132
Validation loss: 1.8670273750059065

Epoch: 250| Step: 0
Training loss: 1.4216655492782593
Validation loss: 1.8631871259340675

Epoch: 6| Step: 1
Training loss: 1.2973964214324951
Validation loss: 1.874883165923498

Epoch: 6| Step: 2
Training loss: 1.2701478004455566
Validation loss: 1.8579891240724953

Epoch: 6| Step: 3
Training loss: 2.3561959266662598
Validation loss: 1.8730211193843553

Epoch: 6| Step: 4
Training loss: 2.0034565925598145
Validation loss: 1.8778501787493307

Epoch: 6| Step: 5
Training loss: 1.623811960220337
Validation loss: 1.8808323273094751

Epoch: 6| Step: 6
Training loss: 1.5804252624511719
Validation loss: 1.8700962079468595

Epoch: 6| Step: 7
Training loss: 2.3074402809143066
Validation loss: 1.8286052032183575

Epoch: 6| Step: 8
Training loss: 1.9066522121429443
Validation loss: 1.906253695487976

Epoch: 6| Step: 9
Training loss: 2.2751102447509766
Validation loss: 1.8553207010351203

Epoch: 6| Step: 10
Training loss: 1.4899264574050903
Validation loss: 1.871393524190431

Epoch: 6| Step: 11
Training loss: 1.1839814186096191
Validation loss: 1.8643822490528066

Epoch: 6| Step: 12
Training loss: 1.1684314012527466
Validation loss: 1.872719967237083

Epoch: 6| Step: 13
Training loss: 1.439305067062378
Validation loss: 1.8694400710444297

Epoch: 251| Step: 0
Training loss: 1.0214155912399292
Validation loss: 1.8810525946719672

Epoch: 6| Step: 1
Training loss: 1.1906484365463257
Validation loss: 1.866066325095392

Epoch: 6| Step: 2
Training loss: 2.0264110565185547
Validation loss: 1.8554297160076838

Epoch: 6| Step: 3
Training loss: 1.6374040842056274
Validation loss: 1.832041008498079

Epoch: 6| Step: 4
Training loss: 2.3724069595336914
Validation loss: 1.899550376399871

Epoch: 6| Step: 5
Training loss: 1.7995527982711792
Validation loss: 1.8524418671925862

Epoch: 6| Step: 6
Training loss: 1.423810601234436
Validation loss: 1.8728923400243123

Epoch: 6| Step: 7
Training loss: 2.35540771484375
Validation loss: 1.8316680398038638

Epoch: 6| Step: 8
Training loss: 1.6027755737304688
Validation loss: 1.860720501151136

Epoch: 6| Step: 9
Training loss: 1.767775535583496
Validation loss: 1.8626275344561505

Epoch: 6| Step: 10
Training loss: 1.4402103424072266
Validation loss: 1.8669782402694866

Epoch: 6| Step: 11
Training loss: 1.1085865497589111
Validation loss: 1.855507109754829

Epoch: 6| Step: 12
Training loss: 1.8139699697494507
Validation loss: 1.8815192150813278

Epoch: 6| Step: 13
Training loss: 1.831135869026184
Validation loss: 1.8472061580227268

Epoch: 252| Step: 0
Training loss: 1.9222559928894043
Validation loss: 1.9012209215471823

Epoch: 6| Step: 1
Training loss: 1.7900556325912476
Validation loss: 1.8779344327988163

Epoch: 6| Step: 2
Training loss: 1.6276113986968994
Validation loss: 1.8878725690226401

Epoch: 6| Step: 3
Training loss: 2.1182310581207275
Validation loss: 1.8684570302245438

Epoch: 6| Step: 4
Training loss: 1.4286723136901855
Validation loss: 1.843475490488032

Epoch: 6| Step: 5
Training loss: 1.6750656366348267
Validation loss: 1.8674315419248355

Epoch: 6| Step: 6
Training loss: 1.204876184463501
Validation loss: 1.8885147815109582

Epoch: 6| Step: 7
Training loss: 1.7587032318115234
Validation loss: 1.8919096454497306

Epoch: 6| Step: 8
Training loss: 1.323500156402588
Validation loss: 1.8983999221555647

Epoch: 6| Step: 9
Training loss: 1.9855432510375977
Validation loss: 1.8967026408000658

Epoch: 6| Step: 10
Training loss: 1.4429577589035034
Validation loss: 1.8814520118057088

Epoch: 6| Step: 11
Training loss: 1.660416841506958
Validation loss: 1.9260630261513494

Epoch: 6| Step: 12
Training loss: 1.6217114925384521
Validation loss: 1.8818939911421908

Epoch: 6| Step: 13
Training loss: 1.6541001796722412
Validation loss: 1.8936210204196233

Epoch: 253| Step: 0
Training loss: 1.7178452014923096
Validation loss: 1.8604878533271052

Epoch: 6| Step: 1
Training loss: 1.5695092678070068
Validation loss: 1.8843796099385908

Epoch: 6| Step: 2
Training loss: 1.5988988876342773
Validation loss: 1.8785819186959216

Epoch: 6| Step: 3
Training loss: 1.994204044342041
Validation loss: 1.8520672705865675

Epoch: 6| Step: 4
Training loss: 0.6774202585220337
Validation loss: 1.863036104427871

Epoch: 6| Step: 5
Training loss: 1.579635739326477
Validation loss: 1.8556709263914375

Epoch: 6| Step: 6
Training loss: 1.8776289224624634
Validation loss: 1.848920960580149

Epoch: 6| Step: 7
Training loss: 1.8087866306304932
Validation loss: 1.8667668245171989

Epoch: 6| Step: 8
Training loss: 1.8389437198638916
Validation loss: 1.8443433956433368

Epoch: 6| Step: 9
Training loss: 1.5071306228637695
Validation loss: 1.8813028797026603

Epoch: 6| Step: 10
Training loss: 1.5967137813568115
Validation loss: 1.878036049104506

Epoch: 6| Step: 11
Training loss: 1.9867072105407715
Validation loss: 1.8379727089276878

Epoch: 6| Step: 12
Training loss: 1.6977375745773315
Validation loss: 1.8636227500054143

Epoch: 6| Step: 13
Training loss: 1.9908027648925781
Validation loss: 1.9056959972586682

Epoch: 254| Step: 0
Training loss: 1.0349085330963135
Validation loss: 1.8481675194155784

Epoch: 6| Step: 1
Training loss: 1.679648995399475
Validation loss: 1.8599964200809438

Epoch: 6| Step: 2
Training loss: 1.632545828819275
Validation loss: 1.864389459292094

Epoch: 6| Step: 3
Training loss: 1.4957447052001953
Validation loss: 1.8337031615677701

Epoch: 6| Step: 4
Training loss: 0.9999663829803467
Validation loss: 1.849297087679627

Epoch: 6| Step: 5
Training loss: 0.761518120765686
Validation loss: 1.8667101039681384

Epoch: 6| Step: 6
Training loss: 2.172574758529663
Validation loss: 1.8489155641166113

Epoch: 6| Step: 7
Training loss: 1.7184066772460938
Validation loss: 1.8676499371887536

Epoch: 6| Step: 8
Training loss: 2.4402098655700684
Validation loss: 1.8805876290926369

Epoch: 6| Step: 9
Training loss: 2.002032995223999
Validation loss: 1.9001214658060381

Epoch: 6| Step: 10
Training loss: 2.3525240421295166
Validation loss: 1.9084970963898527

Epoch: 6| Step: 11
Training loss: 1.4837287664413452
Validation loss: 1.9028277256155526

Epoch: 6| Step: 12
Training loss: 1.6499621868133545
Validation loss: 1.8990898350233674

Epoch: 6| Step: 13
Training loss: 2.4990804195404053
Validation loss: 1.9495363812292776

Epoch: 255| Step: 0
Training loss: 1.752922773361206
Validation loss: 1.8835930849916191

Epoch: 6| Step: 1
Training loss: 1.2082451581954956
Validation loss: 1.8970331979054276

Epoch: 6| Step: 2
Training loss: 1.920243263244629
Validation loss: 1.8942986162759925

Epoch: 6| Step: 3
Training loss: 1.5424846410751343
Validation loss: 1.8734139883390037

Epoch: 6| Step: 4
Training loss: 1.489682674407959
Validation loss: 1.878451753688115

Epoch: 6| Step: 5
Training loss: 1.3761823177337646
Validation loss: 1.8717320157635597

Epoch: 6| Step: 6
Training loss: 1.7949087619781494
Validation loss: 1.8582724935264998

Epoch: 6| Step: 7
Training loss: 1.9012025594711304
Validation loss: 1.8454710655314948

Epoch: 6| Step: 8
Training loss: 2.5103795528411865
Validation loss: 1.8544771466203915

Epoch: 6| Step: 9
Training loss: 1.5433425903320312
Validation loss: 1.8142535148128387

Epoch: 6| Step: 10
Training loss: 1.4622082710266113
Validation loss: 1.8636928143039826

Epoch: 6| Step: 11
Training loss: 2.002016305923462
Validation loss: 1.862043216664304

Epoch: 6| Step: 12
Training loss: 1.1046462059020996
Validation loss: 1.8880671044831634

Epoch: 6| Step: 13
Training loss: 1.8283495903015137
Validation loss: 1.839874397041977

Epoch: 256| Step: 0
Training loss: 1.63084876537323
Validation loss: 1.8605247876977409

Epoch: 6| Step: 1
Training loss: 1.9911495447158813
Validation loss: 1.854280041110131

Epoch: 6| Step: 2
Training loss: 2.184314727783203
Validation loss: 1.8703551151419198

Epoch: 6| Step: 3
Training loss: 1.2732925415039062
Validation loss: 1.8879368638479581

Epoch: 6| Step: 4
Training loss: 1.8095037937164307
Validation loss: 1.872481915258592

Epoch: 6| Step: 5
Training loss: 1.4334056377410889
Validation loss: 1.8345723985343851

Epoch: 6| Step: 6
Training loss: 1.7481646537780762
Validation loss: 1.8675400890329832

Epoch: 6| Step: 7
Training loss: 1.4949462413787842
Validation loss: 1.8328061091002597

Epoch: 6| Step: 8
Training loss: 1.6989045143127441
Validation loss: 1.8479414268206524

Epoch: 6| Step: 9
Training loss: 1.8508380651474
Validation loss: 1.857415819680819

Epoch: 6| Step: 10
Training loss: 2.004521608352661
Validation loss: 1.8452118519813783

Epoch: 6| Step: 11
Training loss: 1.2370779514312744
Validation loss: 1.8835759444903302

Epoch: 6| Step: 12
Training loss: 1.4694106578826904
Validation loss: 1.8525157692611858

Epoch: 6| Step: 13
Training loss: 1.4533982276916504
Validation loss: 1.8740471716850036

Epoch: 257| Step: 0
Training loss: 1.8778996467590332
Validation loss: 1.868467079695835

Epoch: 6| Step: 1
Training loss: 1.634432077407837
Validation loss: 1.846885096642279

Epoch: 6| Step: 2
Training loss: 1.4451003074645996
Validation loss: 1.8679360023108862

Epoch: 6| Step: 3
Training loss: 1.250281572341919
Validation loss: 1.8292804841072328

Epoch: 6| Step: 4
Training loss: 1.9104959964752197
Validation loss: 1.8676712359151533

Epoch: 6| Step: 5
Training loss: 1.118451714515686
Validation loss: 1.8895354527299122

Epoch: 6| Step: 6
Training loss: 2.192492961883545
Validation loss: 1.8498381401902886

Epoch: 6| Step: 7
Training loss: 1.9302657842636108
Validation loss: 1.8486790003315094

Epoch: 6| Step: 8
Training loss: 1.4346706867218018
Validation loss: 1.8569358100173294

Epoch: 6| Step: 9
Training loss: 2.0041327476501465
Validation loss: 1.8616473546592138

Epoch: 6| Step: 10
Training loss: 1.4768764972686768
Validation loss: 1.8894382048678655

Epoch: 6| Step: 11
Training loss: 1.3052254915237427
Validation loss: 1.870177371527559

Epoch: 6| Step: 12
Training loss: 1.5258781909942627
Validation loss: 1.842812858602052

Epoch: 6| Step: 13
Training loss: 2.0256710052490234
Validation loss: 1.8563490183122697

Epoch: 258| Step: 0
Training loss: 1.0108457803726196
Validation loss: 1.850533385430613

Epoch: 6| Step: 1
Training loss: 2.108534336090088
Validation loss: 1.8521759881768176

Epoch: 6| Step: 2
Training loss: 1.7582740783691406
Validation loss: 1.867990227155788

Epoch: 6| Step: 3
Training loss: 1.2737418413162231
Validation loss: 1.8342363219107352

Epoch: 6| Step: 4
Training loss: 1.4367587566375732
Validation loss: 1.8652963587032851

Epoch: 6| Step: 5
Training loss: 2.077589988708496
Validation loss: 1.854962097701206

Epoch: 6| Step: 6
Training loss: 0.9668595194816589
Validation loss: 1.8750308969969391

Epoch: 6| Step: 7
Training loss: 1.9434123039245605
Validation loss: 1.8566390750228718

Epoch: 6| Step: 8
Training loss: 1.801222562789917
Validation loss: 1.8642852062820106

Epoch: 6| Step: 9
Training loss: 1.7814655303955078
Validation loss: 1.8652147644309587

Epoch: 6| Step: 10
Training loss: 1.5790104866027832
Validation loss: 1.8723200046887962

Epoch: 6| Step: 11
Training loss: 2.233490467071533
Validation loss: 1.9065024045205885

Epoch: 6| Step: 12
Training loss: 1.6627769470214844
Validation loss: 1.844549907151089

Epoch: 6| Step: 13
Training loss: 1.4946961402893066
Validation loss: 1.8610818847533195

Epoch: 259| Step: 0
Training loss: 1.4138944149017334
Validation loss: 1.8877733651027884

Epoch: 6| Step: 1
Training loss: 0.8928285837173462
Validation loss: 1.8973064038061327

Epoch: 6| Step: 2
Training loss: 1.9916014671325684
Validation loss: 1.8702603693931334

Epoch: 6| Step: 3
Training loss: 1.6188650131225586
Validation loss: 1.8799665653577415

Epoch: 6| Step: 4
Training loss: 1.6547682285308838
Validation loss: 1.8840000590970438

Epoch: 6| Step: 5
Training loss: 2.157327175140381
Validation loss: 1.8960905536528556

Epoch: 6| Step: 6
Training loss: 1.6334654092788696
Validation loss: 1.889984247505024

Epoch: 6| Step: 7
Training loss: 1.631333827972412
Validation loss: 1.8652223848527478

Epoch: 6| Step: 8
Training loss: 2.393303871154785
Validation loss: 1.8980280917177919

Epoch: 6| Step: 9
Training loss: 1.621450662612915
Validation loss: 1.8822806599319621

Epoch: 6| Step: 10
Training loss: 1.4476583003997803
Validation loss: 1.8884238760958436

Epoch: 6| Step: 11
Training loss: 1.3225576877593994
Validation loss: 1.838237134359216

Epoch: 6| Step: 12
Training loss: 1.513782262802124
Validation loss: 1.8182651612066454

Epoch: 6| Step: 13
Training loss: 1.9532721042633057
Validation loss: 1.8531646677242812

Epoch: 260| Step: 0
Training loss: 1.701432228088379
Validation loss: 1.861752131933807

Epoch: 6| Step: 1
Training loss: 1.832574725151062
Validation loss: 1.8279021452831965

Epoch: 6| Step: 2
Training loss: 1.4946626424789429
Validation loss: 1.8393572427893197

Epoch: 6| Step: 3
Training loss: 1.368410587310791
Validation loss: 1.8478615694148566

Epoch: 6| Step: 4
Training loss: 1.979392170906067
Validation loss: 1.8397237959728445

Epoch: 6| Step: 5
Training loss: 1.6403807401657104
Validation loss: 1.8747992669382403

Epoch: 6| Step: 6
Training loss: 1.8652477264404297
Validation loss: 1.812629234406256

Epoch: 6| Step: 7
Training loss: 1.558913230895996
Validation loss: 1.8071885865221742

Epoch: 6| Step: 8
Training loss: 1.7497981786727905
Validation loss: 1.8377740472875617

Epoch: 6| Step: 9
Training loss: 1.9626944065093994
Validation loss: 1.848136366054576

Epoch: 6| Step: 10
Training loss: 1.3673930168151855
Validation loss: 1.8747130414491058

Epoch: 6| Step: 11
Training loss: 1.7687256336212158
Validation loss: 1.8739101079202467

Epoch: 6| Step: 12
Training loss: 1.2202811241149902
Validation loss: 1.8662253618240356

Epoch: 6| Step: 13
Training loss: 1.8525941371917725
Validation loss: 1.860131996934132

Epoch: 261| Step: 0
Training loss: 1.0603444576263428
Validation loss: 1.8659848090141051

Epoch: 6| Step: 1
Training loss: 1.5338215827941895
Validation loss: 1.8181889005886611

Epoch: 6| Step: 2
Training loss: 2.156665325164795
Validation loss: 1.8424237517900364

Epoch: 6| Step: 3
Training loss: 1.4408332109451294
Validation loss: 1.8705028821063299

Epoch: 6| Step: 4
Training loss: 1.9043200016021729
Validation loss: 1.8605841462330153

Epoch: 6| Step: 5
Training loss: 1.704024076461792
Validation loss: 1.8225250090322187

Epoch: 6| Step: 6
Training loss: 1.4213793277740479
Validation loss: 1.8166995433069044

Epoch: 6| Step: 7
Training loss: 1.000852108001709
Validation loss: 1.8520875771840413

Epoch: 6| Step: 8
Training loss: 2.2253918647766113
Validation loss: 1.84162433813977

Epoch: 6| Step: 9
Training loss: 2.1075868606567383
Validation loss: 1.8630810578664143

Epoch: 6| Step: 10
Training loss: 1.580122947692871
Validation loss: 1.8564904556479505

Epoch: 6| Step: 11
Training loss: 1.6801731586456299
Validation loss: 1.8458556487996092

Epoch: 6| Step: 12
Training loss: 1.1803395748138428
Validation loss: 1.8834397164724206

Epoch: 6| Step: 13
Training loss: 2.239898920059204
Validation loss: 1.850201875932755

Epoch: 262| Step: 0
Training loss: 1.750207543373108
Validation loss: 1.8771801994692894

Epoch: 6| Step: 1
Training loss: 1.8332281112670898
Validation loss: 1.8459374596995692

Epoch: 6| Step: 2
Training loss: 1.4499003887176514
Validation loss: 1.8343485401522728

Epoch: 6| Step: 3
Training loss: 1.6910868883132935
Validation loss: 1.8228887255473802

Epoch: 6| Step: 4
Training loss: 1.241490364074707
Validation loss: 1.857695460319519

Epoch: 6| Step: 5
Training loss: 1.4088772535324097
Validation loss: 1.8142626772644699

Epoch: 6| Step: 6
Training loss: 1.5431733131408691
Validation loss: 1.8624925357039257

Epoch: 6| Step: 7
Training loss: 1.6463412046432495
Validation loss: 1.8233082948192474

Epoch: 6| Step: 8
Training loss: 1.5940601825714111
Validation loss: 1.823732477362438

Epoch: 6| Step: 9
Training loss: 1.0389254093170166
Validation loss: 1.8452144271583968

Epoch: 6| Step: 10
Training loss: 1.8453986644744873
Validation loss: 1.834815538057717

Epoch: 6| Step: 11
Training loss: 1.599930763244629
Validation loss: 1.8745067683599328

Epoch: 6| Step: 12
Training loss: 1.9674630165100098
Validation loss: 1.8476129065277755

Epoch: 6| Step: 13
Training loss: 2.8736696243286133
Validation loss: 1.8496725379779775

Epoch: 263| Step: 0
Training loss: 1.8530325889587402
Validation loss: 1.8570439905248664

Epoch: 6| Step: 1
Training loss: 0.9954046607017517
Validation loss: 1.8697104864223029

Epoch: 6| Step: 2
Training loss: 1.1551200151443481
Validation loss: 1.879731309029364

Epoch: 6| Step: 3
Training loss: 1.397782802581787
Validation loss: 1.8536241567263039

Epoch: 6| Step: 4
Training loss: 1.0978550910949707
Validation loss: 1.8174761213282102

Epoch: 6| Step: 5
Training loss: 2.220320224761963
Validation loss: 1.8691624005635579

Epoch: 6| Step: 6
Training loss: 1.4943115711212158
Validation loss: 1.882516699452554

Epoch: 6| Step: 7
Training loss: 1.9212908744812012
Validation loss: 1.8472570270620368

Epoch: 6| Step: 8
Training loss: 1.6133601665496826
Validation loss: 1.8622650715612596

Epoch: 6| Step: 9
Training loss: 1.7840735912322998
Validation loss: 1.8778498429124073

Epoch: 6| Step: 10
Training loss: 1.5547250509262085
Validation loss: 1.8271272028646162

Epoch: 6| Step: 11
Training loss: 2.3633246421813965
Validation loss: 1.843773970039942

Epoch: 6| Step: 12
Training loss: 1.3792272806167603
Validation loss: 1.8187536270387712

Epoch: 6| Step: 13
Training loss: 1.8425521850585938
Validation loss: 1.8554665696236394

Epoch: 264| Step: 0
Training loss: 1.2612330913543701
Validation loss: 1.8346467069400254

Epoch: 6| Step: 1
Training loss: 1.428439736366272
Validation loss: 1.838408016389416

Epoch: 6| Step: 2
Training loss: 1.747666358947754
Validation loss: 1.8187495880229498

Epoch: 6| Step: 3
Training loss: 1.727358102798462
Validation loss: 1.8244125971230127

Epoch: 6| Step: 4
Training loss: 2.011690139770508
Validation loss: 1.881644356635309

Epoch: 6| Step: 5
Training loss: 1.7349432706832886
Validation loss: 1.8542741062820598

Epoch: 6| Step: 6
Training loss: 1.4799082279205322
Validation loss: 1.8560557660236154

Epoch: 6| Step: 7
Training loss: 1.9234684705734253
Validation loss: 1.8688691393021615

Epoch: 6| Step: 8
Training loss: 1.2096848487854004
Validation loss: 1.8489955817499468

Epoch: 6| Step: 9
Training loss: 2.1062917709350586
Validation loss: 1.835299950773998

Epoch: 6| Step: 10
Training loss: 2.0874757766723633
Validation loss: 1.879328077839267

Epoch: 6| Step: 11
Training loss: 1.6621246337890625
Validation loss: 1.8540792349846131

Epoch: 6| Step: 12
Training loss: 1.2360082864761353
Validation loss: 1.83974386671538

Epoch: 6| Step: 13
Training loss: 1.3288254737854004
Validation loss: 1.8641515470320178

Epoch: 265| Step: 0
Training loss: 1.5704197883605957
Validation loss: 1.8278410665450557

Epoch: 6| Step: 1
Training loss: 2.2229340076446533
Validation loss: 1.851018662093788

Epoch: 6| Step: 2
Training loss: 1.3805456161499023
Validation loss: 1.8333482165490427

Epoch: 6| Step: 3
Training loss: 1.9718931913375854
Validation loss: 1.8585404465275426

Epoch: 6| Step: 4
Training loss: 1.624606728553772
Validation loss: 1.8437476593960997

Epoch: 6| Step: 5
Training loss: 1.1492631435394287
Validation loss: 1.8479634382391488

Epoch: 6| Step: 6
Training loss: 2.0094101428985596
Validation loss: 1.825591202705137

Epoch: 6| Step: 7
Training loss: 1.942319393157959
Validation loss: 1.8625225764448925

Epoch: 6| Step: 8
Training loss: 1.4713655710220337
Validation loss: 1.8536823013777375

Epoch: 6| Step: 9
Training loss: 1.473372459411621
Validation loss: 1.8779022796179659

Epoch: 6| Step: 10
Training loss: 1.9978224039077759
Validation loss: 1.8229612688864432

Epoch: 6| Step: 11
Training loss: 1.364179015159607
Validation loss: 1.8662773896289129

Epoch: 6| Step: 12
Training loss: 1.4234585762023926
Validation loss: 1.839509110296926

Epoch: 6| Step: 13
Training loss: 0.6921675205230713
Validation loss: 1.8939945877239268

Epoch: 266| Step: 0
Training loss: 1.901125192642212
Validation loss: 1.8706197713011055

Epoch: 6| Step: 1
Training loss: 1.9271687269210815
Validation loss: 1.868813128881557

Epoch: 6| Step: 2
Training loss: 1.41107976436615
Validation loss: 1.8784148975085186

Epoch: 6| Step: 3
Training loss: 1.7062829732894897
Validation loss: 1.8683376055891796

Epoch: 6| Step: 4
Training loss: 1.6190478801727295
Validation loss: 1.8553246708326443

Epoch: 6| Step: 5
Training loss: 2.470217704772949
Validation loss: 1.8580288348659393

Epoch: 6| Step: 6
Training loss: 1.5156183242797852
Validation loss: 1.8467848941843996

Epoch: 6| Step: 7
Training loss: 0.8819594979286194
Validation loss: 1.8418091394568001

Epoch: 6| Step: 8
Training loss: 1.4951591491699219
Validation loss: 1.8466093591464463

Epoch: 6| Step: 9
Training loss: 2.057158946990967
Validation loss: 1.8138587679914249

Epoch: 6| Step: 10
Training loss: 1.8691883087158203
Validation loss: 1.8599833083409134

Epoch: 6| Step: 11
Training loss: 1.4065172672271729
Validation loss: 1.8269906467007053

Epoch: 6| Step: 12
Training loss: 1.2853257656097412
Validation loss: 1.8385551450073079

Epoch: 6| Step: 13
Training loss: 1.536695957183838
Validation loss: 1.8482390962621218

Epoch: 267| Step: 0
Training loss: 1.539968490600586
Validation loss: 1.835825881650371

Epoch: 6| Step: 1
Training loss: 0.9138773083686829
Validation loss: 1.8367234750460553

Epoch: 6| Step: 2
Training loss: 1.9295592308044434
Validation loss: 1.8444706445099206

Epoch: 6| Step: 3
Training loss: 1.7293188571929932
Validation loss: 1.831504826904625

Epoch: 6| Step: 4
Training loss: 1.7284799814224243
Validation loss: 1.8158943383924422

Epoch: 6| Step: 5
Training loss: 1.65987229347229
Validation loss: 1.8545689480279082

Epoch: 6| Step: 6
Training loss: 1.7709647417068481
Validation loss: 1.8235467762075446

Epoch: 6| Step: 7
Training loss: 1.5557780265808105
Validation loss: 1.8543732909746067

Epoch: 6| Step: 8
Training loss: 1.5895479917526245
Validation loss: 1.8679280255430488

Epoch: 6| Step: 9
Training loss: 1.4533182382583618
Validation loss: 1.8562770697378344

Epoch: 6| Step: 10
Training loss: 2.314485788345337
Validation loss: 1.852529082247006

Epoch: 6| Step: 11
Training loss: 1.4725861549377441
Validation loss: 1.8304139632050709

Epoch: 6| Step: 12
Training loss: 1.6352572441101074
Validation loss: 1.8445146808060267

Epoch: 6| Step: 13
Training loss: 1.7689505815505981
Validation loss: 1.8705683664609027

Epoch: 268| Step: 0
Training loss: 1.4425632953643799
Validation loss: 1.8846697691948182

Epoch: 6| Step: 1
Training loss: 2.2019925117492676
Validation loss: 1.8956350267574351

Epoch: 6| Step: 2
Training loss: 2.3262593746185303
Validation loss: 1.8503988148063741

Epoch: 6| Step: 3
Training loss: 1.925482153892517
Validation loss: 1.8683483767253097

Epoch: 6| Step: 4
Training loss: 1.3748204708099365
Validation loss: 1.8781452973683674

Epoch: 6| Step: 5
Training loss: 1.161285161972046
Validation loss: 1.8479839486460532

Epoch: 6| Step: 6
Training loss: 1.3385591506958008
Validation loss: 1.8234877086454822

Epoch: 6| Step: 7
Training loss: 1.8764739036560059
Validation loss: 1.8582415862749981

Epoch: 6| Step: 8
Training loss: 1.2122485637664795
Validation loss: 1.8276776190726989

Epoch: 6| Step: 9
Training loss: 1.5811930894851685
Validation loss: 1.832754224859258

Epoch: 6| Step: 10
Training loss: 1.254571557044983
Validation loss: 1.8581438910576604

Epoch: 6| Step: 11
Training loss: 1.5111514329910278
Validation loss: 1.8260242567267468

Epoch: 6| Step: 12
Training loss: 1.7353694438934326
Validation loss: 1.8082436156529251

Epoch: 6| Step: 13
Training loss: 1.3959976434707642
Validation loss: 1.8502554893493652

Epoch: 269| Step: 0
Training loss: 1.2819342613220215
Validation loss: 1.8369930610861829

Epoch: 6| Step: 1
Training loss: 1.7586696147918701
Validation loss: 1.8412926325234034

Epoch: 6| Step: 2
Training loss: 1.5873668193817139
Validation loss: 1.8261756012516637

Epoch: 6| Step: 3
Training loss: 1.0553985834121704
Validation loss: 1.845067976623453

Epoch: 6| Step: 4
Training loss: 2.436410427093506
Validation loss: 1.8543813536244054

Epoch: 6| Step: 5
Training loss: 1.5175812244415283
Validation loss: 1.8060647864495554

Epoch: 6| Step: 6
Training loss: 1.187835931777954
Validation loss: 1.8195513781680857

Epoch: 6| Step: 7
Training loss: 2.2975473403930664
Validation loss: 1.8600523715378137

Epoch: 6| Step: 8
Training loss: 1.6420929431915283
Validation loss: 1.8475173993777203

Epoch: 6| Step: 9
Training loss: 1.8041514158248901
Validation loss: 1.8515198333289034

Epoch: 6| Step: 10
Training loss: 2.3323006629943848
Validation loss: 1.855534202309065

Epoch: 6| Step: 11
Training loss: 1.238593339920044
Validation loss: 1.823849162747783

Epoch: 6| Step: 12
Training loss: 1.0963146686553955
Validation loss: 1.857114827761086

Epoch: 6| Step: 13
Training loss: 1.2815178632736206
Validation loss: 1.8396182598606232

Epoch: 270| Step: 0
Training loss: 1.3637261390686035
Validation loss: 1.9025368946854786

Epoch: 6| Step: 1
Training loss: 1.900366187095642
Validation loss: 1.8781508245775778

Epoch: 6| Step: 2
Training loss: 1.3395652770996094
Validation loss: 1.8962801079596243

Epoch: 6| Step: 3
Training loss: 1.7288944721221924
Validation loss: 1.886073899525468

Epoch: 6| Step: 4
Training loss: 1.675242304801941
Validation loss: 1.8962798221136934

Epoch: 6| Step: 5
Training loss: 1.5455241203308105
Validation loss: 1.898077525118346

Epoch: 6| Step: 6
Training loss: 1.020423173904419
Validation loss: 1.8438704013824463

Epoch: 6| Step: 7
Training loss: 1.3351621627807617
Validation loss: 1.9132695082695252

Epoch: 6| Step: 8
Training loss: 1.3685352802276611
Validation loss: 1.8780714773362683

Epoch: 6| Step: 9
Training loss: 1.4785043001174927
Validation loss: 1.8940994034531295

Epoch: 6| Step: 10
Training loss: 1.6597578525543213
Validation loss: 1.8693453599047918

Epoch: 6| Step: 11
Training loss: 2.1886038780212402
Validation loss: 1.8332601337022678

Epoch: 6| Step: 12
Training loss: 1.9082099199295044
Validation loss: 1.829326247656217

Epoch: 6| Step: 13
Training loss: 2.304081439971924
Validation loss: 1.8258256425139725

Epoch: 271| Step: 0
Training loss: 1.092580795288086
Validation loss: 1.8278075789892545

Epoch: 6| Step: 1
Training loss: 0.9072813391685486
Validation loss: 1.8488899084829515

Epoch: 6| Step: 2
Training loss: 2.1121792793273926
Validation loss: 1.81430297769526

Epoch: 6| Step: 3
Training loss: 1.90904700756073
Validation loss: 1.826183827974463

Epoch: 6| Step: 4
Training loss: 1.973615050315857
Validation loss: 1.8377989133199055

Epoch: 6| Step: 5
Training loss: 1.7367095947265625
Validation loss: 1.8620112378110167

Epoch: 6| Step: 6
Training loss: 2.022152900695801
Validation loss: 1.8270734625477945

Epoch: 6| Step: 7
Training loss: 1.3830510377883911
Validation loss: 1.8186301185238747

Epoch: 6| Step: 8
Training loss: 1.2302621603012085
Validation loss: 1.8390157966203586

Epoch: 6| Step: 9
Training loss: 2.0829854011535645
Validation loss: 1.8099058635773198

Epoch: 6| Step: 10
Training loss: 1.7268764972686768
Validation loss: 1.8338864247004192

Epoch: 6| Step: 11
Training loss: 1.6785123348236084
Validation loss: 1.8459504009574972

Epoch: 6| Step: 12
Training loss: 1.6830917596817017
Validation loss: 1.8560032459997362

Epoch: 6| Step: 13
Training loss: 1.1033387184143066
Validation loss: 1.842863323867962

Epoch: 272| Step: 0
Training loss: 2.2954487800598145
Validation loss: 1.8295714060465496

Epoch: 6| Step: 1
Training loss: 1.2780494689941406
Validation loss: 1.8699971296453988

Epoch: 6| Step: 2
Training loss: 2.034846782684326
Validation loss: 1.872070586809548

Epoch: 6| Step: 3
Training loss: 1.3286237716674805
Validation loss: 1.837114731470744

Epoch: 6| Step: 4
Training loss: 2.0375921726226807
Validation loss: 1.8286240241860832

Epoch: 6| Step: 5
Training loss: 1.3932454586029053
Validation loss: 1.8315059010700514

Epoch: 6| Step: 6
Training loss: 1.7720316648483276
Validation loss: 1.8602301843704716

Epoch: 6| Step: 7
Training loss: 1.3285636901855469
Validation loss: 1.8077358635522986

Epoch: 6| Step: 8
Training loss: 1.1177334785461426
Validation loss: 1.8537826755995392

Epoch: 6| Step: 9
Training loss: 1.8233866691589355
Validation loss: 1.8530820262047552

Epoch: 6| Step: 10
Training loss: 1.5784907341003418
Validation loss: 1.8233368717214113

Epoch: 6| Step: 11
Training loss: 1.2498643398284912
Validation loss: 1.846930653818192

Epoch: 6| Step: 12
Training loss: 1.3306177854537964
Validation loss: 1.8501829396012008

Epoch: 6| Step: 13
Training loss: 2.0551819801330566
Validation loss: 1.8832461590407996

Epoch: 273| Step: 0
Training loss: 1.452888011932373
Validation loss: 1.8244316039546844

Epoch: 6| Step: 1
Training loss: 1.559053897857666
Validation loss: 1.8341717335485643

Epoch: 6| Step: 2
Training loss: 2.4996347427368164
Validation loss: 1.8118291221639162

Epoch: 6| Step: 3
Training loss: 1.4560108184814453
Validation loss: 1.8494408297282394

Epoch: 6| Step: 4
Training loss: 1.768457055091858
Validation loss: 1.8185556844998432

Epoch: 6| Step: 5
Training loss: 1.4345579147338867
Validation loss: 1.846208785169868

Epoch: 6| Step: 6
Training loss: 1.4463605880737305
Validation loss: 1.8481323424205984

Epoch: 6| Step: 7
Training loss: 1.96718168258667
Validation loss: 1.8001208087449432

Epoch: 6| Step: 8
Training loss: 0.9438673257827759
Validation loss: 1.8141949522879817

Epoch: 6| Step: 9
Training loss: 1.623939037322998
Validation loss: 1.8236314442849928

Epoch: 6| Step: 10
Training loss: 1.8353041410446167
Validation loss: 1.8116296914315992

Epoch: 6| Step: 11
Training loss: 1.1156809329986572
Validation loss: 1.835586920861275

Epoch: 6| Step: 12
Training loss: 1.9611735343933105
Validation loss: 1.8572307402087795

Epoch: 6| Step: 13
Training loss: 1.317191243171692
Validation loss: 1.7955986351095221

Epoch: 274| Step: 0
Training loss: 1.7823543548583984
Validation loss: 1.8187963975373136

Epoch: 6| Step: 1
Training loss: 1.4103385210037231
Validation loss: 1.8273362190492692

Epoch: 6| Step: 2
Training loss: 1.6201800107955933
Validation loss: 1.8334104732800556

Epoch: 6| Step: 3
Training loss: 1.7091851234436035
Validation loss: 1.8225298863585278

Epoch: 6| Step: 4
Training loss: 1.4019205570220947
Validation loss: 1.8161297511028986

Epoch: 6| Step: 5
Training loss: 1.9881792068481445
Validation loss: 1.8351908653013167

Epoch: 6| Step: 6
Training loss: 1.992932677268982
Validation loss: 1.8392959884417954

Epoch: 6| Step: 7
Training loss: 1.267439365386963
Validation loss: 1.8378108855216735

Epoch: 6| Step: 8
Training loss: 1.7712018489837646
Validation loss: 1.8357006144779984

Epoch: 6| Step: 9
Training loss: 1.5682153701782227
Validation loss: 1.8414244549248808

Epoch: 6| Step: 10
Training loss: 1.7818914651870728
Validation loss: 1.8323389663491199

Epoch: 6| Step: 11
Training loss: 1.3620495796203613
Validation loss: 1.8581086897080945

Epoch: 6| Step: 12
Training loss: 1.3223106861114502
Validation loss: 1.8206568097555509

Epoch: 6| Step: 13
Training loss: 1.6436095237731934
Validation loss: 1.8421385916330482

Epoch: 275| Step: 0
Training loss: 0.9738065600395203
Validation loss: 1.8257580816104848

Epoch: 6| Step: 1
Training loss: 2.1140737533569336
Validation loss: 1.8517816194923975

Epoch: 6| Step: 2
Training loss: 1.3771746158599854
Validation loss: 1.8497577662109046

Epoch: 6| Step: 3
Training loss: 1.658487319946289
Validation loss: 1.8718258334744362

Epoch: 6| Step: 4
Training loss: 1.109533429145813
Validation loss: 1.8758692741394043

Epoch: 6| Step: 5
Training loss: 1.6304988861083984
Validation loss: 1.8472546146761986

Epoch: 6| Step: 6
Training loss: 1.886359691619873
Validation loss: 1.8572076930794665

Epoch: 6| Step: 7
Training loss: 1.6117417812347412
Validation loss: 1.8329078048788092

Epoch: 6| Step: 8
Training loss: 1.7231338024139404
Validation loss: 1.8766490156932543

Epoch: 6| Step: 9
Training loss: 1.994175910949707
Validation loss: 1.8753448019745529

Epoch: 6| Step: 10
Training loss: 1.4405789375305176
Validation loss: 1.8971374547609718

Epoch: 6| Step: 11
Training loss: 1.5637757778167725
Validation loss: 1.84490071189019

Epoch: 6| Step: 12
Training loss: 2.001042127609253
Validation loss: 1.8902767832561205

Epoch: 6| Step: 13
Training loss: 1.8629580736160278
Validation loss: 1.8442274485864947

Epoch: 276| Step: 0
Training loss: 1.6022447347640991
Validation loss: 1.8496417127629763

Epoch: 6| Step: 1
Training loss: 1.2050867080688477
Validation loss: 1.8248701339126916

Epoch: 6| Step: 2
Training loss: 1.4187442064285278
Validation loss: 1.838538267279184

Epoch: 6| Step: 3
Training loss: 1.3747789859771729
Validation loss: 1.860670707559073

Epoch: 6| Step: 4
Training loss: 1.6574351787567139
Validation loss: 1.834607934439054

Epoch: 6| Step: 5
Training loss: 1.9798827171325684
Validation loss: 1.8677873496086366

Epoch: 6| Step: 6
Training loss: 1.9503793716430664
Validation loss: 1.825945790095996

Epoch: 6| Step: 7
Training loss: 1.4845311641693115
Validation loss: 1.8708720091850526

Epoch: 6| Step: 8
Training loss: 1.4730350971221924
Validation loss: 1.8013674956496044

Epoch: 6| Step: 9
Training loss: 1.2985469102859497
Validation loss: 1.8258022005840013

Epoch: 6| Step: 10
Training loss: 1.3344489336013794
Validation loss: 1.852172940008102

Epoch: 6| Step: 11
Training loss: 2.506779670715332
Validation loss: 1.836881685000594

Epoch: 6| Step: 12
Training loss: 1.9657204151153564
Validation loss: 1.8045821805154123

Epoch: 6| Step: 13
Training loss: 0.9436997175216675
Validation loss: 1.8202794251903411

Epoch: 277| Step: 0
Training loss: 1.1635096073150635
Validation loss: 1.822491745794973

Epoch: 6| Step: 1
Training loss: 2.0180373191833496
Validation loss: 1.873348407847907

Epoch: 6| Step: 2
Training loss: 1.5204241275787354
Validation loss: 1.860494754647696

Epoch: 6| Step: 3
Training loss: 1.767449140548706
Validation loss: 1.8416055799812399

Epoch: 6| Step: 4
Training loss: 2.53444242477417
Validation loss: 1.83946132275366

Epoch: 6| Step: 5
Training loss: 2.0296030044555664
Validation loss: 1.8621497872055217

Epoch: 6| Step: 6
Training loss: 0.5437681078910828
Validation loss: 1.853470052442243

Epoch: 6| Step: 7
Training loss: 1.5949394702911377
Validation loss: 1.830674135556785

Epoch: 6| Step: 8
Training loss: 1.5979704856872559
Validation loss: 1.8162734918696906

Epoch: 6| Step: 9
Training loss: 1.0112532377243042
Validation loss: 1.8268604291382657

Epoch: 6| Step: 10
Training loss: 1.511103630065918
Validation loss: 1.8732356973873672

Epoch: 6| Step: 11
Training loss: 2.039663791656494
Validation loss: 1.843376833905456

Epoch: 6| Step: 12
Training loss: 1.2358065843582153
Validation loss: 1.8793069739495554

Epoch: 6| Step: 13
Training loss: 2.2021703720092773
Validation loss: 1.848043469972508

Epoch: 278| Step: 0
Training loss: 1.61802339553833
Validation loss: 1.8403617630722702

Epoch: 6| Step: 1
Training loss: 1.8313993215560913
Validation loss: 1.8664431687324279

Epoch: 6| Step: 2
Training loss: 1.8400589227676392
Validation loss: 1.853543560992005

Epoch: 6| Step: 3
Training loss: 1.7594026327133179
Validation loss: 1.8691503206888835

Epoch: 6| Step: 4
Training loss: 1.3685765266418457
Validation loss: 1.8777529654964324

Epoch: 6| Step: 5
Training loss: 1.0283029079437256
Validation loss: 1.8644651571909587

Epoch: 6| Step: 6
Training loss: 2.122971296310425
Validation loss: 1.8976069573433167

Epoch: 6| Step: 7
Training loss: 1.5390546321868896
Validation loss: 1.8467908085033458

Epoch: 6| Step: 8
Training loss: 1.2548058032989502
Validation loss: 1.841501046252507

Epoch: 6| Step: 9
Training loss: 1.1064434051513672
Validation loss: 1.8327661983428463

Epoch: 6| Step: 10
Training loss: 2.1287155151367188
Validation loss: 1.8481398141512306

Epoch: 6| Step: 11
Training loss: 1.685595989227295
Validation loss: 1.8251361795651015

Epoch: 6| Step: 12
Training loss: 1.983367681503296
Validation loss: 1.877755465046052

Epoch: 6| Step: 13
Training loss: 0.9031911492347717
Validation loss: 1.8222043296342254

Epoch: 279| Step: 0
Training loss: 1.5398666858673096
Validation loss: 1.8231972097068705

Epoch: 6| Step: 1
Training loss: 1.6666746139526367
Validation loss: 1.8720991611480713

Epoch: 6| Step: 2
Training loss: 1.8784493207931519
Validation loss: 1.8391372490954656

Epoch: 6| Step: 3
Training loss: 0.9376102685928345
Validation loss: 1.846373991299701

Epoch: 6| Step: 4
Training loss: 1.8446433544158936
Validation loss: 1.8318018951723654

Epoch: 6| Step: 5
Training loss: 1.0947582721710205
Validation loss: 1.8420701360189786

Epoch: 6| Step: 6
Training loss: 1.457368016242981
Validation loss: 1.8235178750048402

Epoch: 6| Step: 7
Training loss: 1.7855066061019897
Validation loss: 1.8345649370583155

Epoch: 6| Step: 8
Training loss: 2.033482074737549
Validation loss: 1.8559068582391227

Epoch: 6| Step: 9
Training loss: 1.073329210281372
Validation loss: 1.8474503101841095

Epoch: 6| Step: 10
Training loss: 1.4078012704849243
Validation loss: 1.807384571721477

Epoch: 6| Step: 11
Training loss: 1.709472417831421
Validation loss: 1.8390169092403945

Epoch: 6| Step: 12
Training loss: 1.8951090574264526
Validation loss: 1.8097431377698017

Epoch: 6| Step: 13
Training loss: 1.5412288904190063
Validation loss: 1.8742115138679423

Epoch: 280| Step: 0
Training loss: 1.720956563949585
Validation loss: 1.8347498524573542

Epoch: 6| Step: 1
Training loss: 1.5905725955963135
Validation loss: 1.8756980537086405

Epoch: 6| Step: 2
Training loss: 1.2300262451171875
Validation loss: 1.861535902946226

Epoch: 6| Step: 3
Training loss: 1.2762330770492554
Validation loss: 1.864305825643642

Epoch: 6| Step: 4
Training loss: 1.2764173746109009
Validation loss: 1.877031498057868

Epoch: 6| Step: 5
Training loss: 2.2288126945495605
Validation loss: 1.877314918784685

Epoch: 6| Step: 6
Training loss: 1.982940673828125
Validation loss: 1.8725157373694963

Epoch: 6| Step: 7
Training loss: 1.5378832817077637
Validation loss: 1.8629147775711552

Epoch: 6| Step: 8
Training loss: 1.4255194664001465
Validation loss: 1.8267899444026332

Epoch: 6| Step: 9
Training loss: 1.429018259048462
Validation loss: 1.8426478242361417

Epoch: 6| Step: 10
Training loss: 1.5108195543289185
Validation loss: 1.8340990479274462

Epoch: 6| Step: 11
Training loss: 1.5495129823684692
Validation loss: 1.8282279916988906

Epoch: 6| Step: 12
Training loss: 1.5095105171203613
Validation loss: 1.8299381489394813

Epoch: 6| Step: 13
Training loss: 2.128518581390381
Validation loss: 1.826886147581121

Epoch: 281| Step: 0
Training loss: 1.7894577980041504
Validation loss: 1.8265456961047264

Epoch: 6| Step: 1
Training loss: 1.5609769821166992
Validation loss: 1.8528775938095585

Epoch: 6| Step: 2
Training loss: 1.701733112335205
Validation loss: 1.8445821090411114

Epoch: 6| Step: 3
Training loss: 1.4587678909301758
Validation loss: 1.8649278609983382

Epoch: 6| Step: 4
Training loss: 1.501250982284546
Validation loss: 1.8400034289206229

Epoch: 6| Step: 5
Training loss: 1.8766181468963623
Validation loss: 1.8490246867620816

Epoch: 6| Step: 6
Training loss: 1.530153512954712
Validation loss: 1.8799872065103183

Epoch: 6| Step: 7
Training loss: 1.7099096775054932
Validation loss: 1.8446337317907682

Epoch: 6| Step: 8
Training loss: 1.3916245698928833
Validation loss: 1.9146771430969238

Epoch: 6| Step: 9
Training loss: 1.1469378471374512
Validation loss: 1.8869427070822766

Epoch: 6| Step: 10
Training loss: 2.0943403244018555
Validation loss: 1.8411086579804778

Epoch: 6| Step: 11
Training loss: 1.404397964477539
Validation loss: 1.8554895398437337

Epoch: 6| Step: 12
Training loss: 1.1062946319580078
Validation loss: 1.9014677206675212

Epoch: 6| Step: 13
Training loss: 1.4103628396987915
Validation loss: 1.853331788893669

Epoch: 282| Step: 0
Training loss: 1.5578055381774902
Validation loss: 1.8442030542640275

Epoch: 6| Step: 1
Training loss: 1.2688196897506714
Validation loss: 1.8359978340005363

Epoch: 6| Step: 2
Training loss: 1.4191579818725586
Validation loss: 1.8390495815584738

Epoch: 6| Step: 3
Training loss: 1.5126899480819702
Validation loss: 1.838711086139884

Epoch: 6| Step: 4
Training loss: 1.4291428327560425
Validation loss: 1.8134447836106824

Epoch: 6| Step: 5
Training loss: 2.126112699508667
Validation loss: 1.8353524720796974

Epoch: 6| Step: 6
Training loss: 1.1258877515792847
Validation loss: 1.8065360117984075

Epoch: 6| Step: 7
Training loss: 1.5603832006454468
Validation loss: 1.8498401282936014

Epoch: 6| Step: 8
Training loss: 2.213131904602051
Validation loss: 1.8205050576117732

Epoch: 6| Step: 9
Training loss: 1.379863977432251
Validation loss: 1.8494109017874605

Epoch: 6| Step: 10
Training loss: 2.052125930786133
Validation loss: 1.8203073381095805

Epoch: 6| Step: 11
Training loss: 1.3200652599334717
Validation loss: 1.8146678375941452

Epoch: 6| Step: 12
Training loss: 1.80097234249115
Validation loss: 1.8077419316896828

Epoch: 6| Step: 13
Training loss: 1.2742390632629395
Validation loss: 1.8424108643685617

Epoch: 283| Step: 0
Training loss: 2.3284730911254883
Validation loss: 1.881560456368231

Epoch: 6| Step: 1
Training loss: 2.0307579040527344
Validation loss: 1.8496677811427782

Epoch: 6| Step: 2
Training loss: 1.281367540359497
Validation loss: 1.866496616794217

Epoch: 6| Step: 3
Training loss: 1.983537197113037
Validation loss: 1.8918995318874237

Epoch: 6| Step: 4
Training loss: 1.1615179777145386
Validation loss: 1.9389722283168505

Epoch: 6| Step: 5
Training loss: 1.1834462881088257
Validation loss: 1.907138188680013

Epoch: 6| Step: 6
Training loss: 1.3986265659332275
Validation loss: 1.9044879239092591

Epoch: 6| Step: 7
Training loss: 1.3383243083953857
Validation loss: 1.912016236653892

Epoch: 6| Step: 8
Training loss: 1.8346352577209473
Validation loss: 1.906951835078578

Epoch: 6| Step: 9
Training loss: 1.2822877168655396
Validation loss: 1.8974995549007128

Epoch: 6| Step: 10
Training loss: 1.1501775979995728
Validation loss: 1.884908285192264

Epoch: 6| Step: 11
Training loss: 1.2315893173217773
Validation loss: 1.8683708829264487

Epoch: 6| Step: 12
Training loss: 1.72088623046875
Validation loss: 1.8410380553173762

Epoch: 6| Step: 13
Training loss: 2.1626203060150146
Validation loss: 1.820112310430055

Epoch: 284| Step: 0
Training loss: 1.118096113204956
Validation loss: 1.828025616625304

Epoch: 6| Step: 1
Training loss: 1.671651840209961
Validation loss: 1.8313022954489595

Epoch: 6| Step: 2
Training loss: 1.5377634763717651
Validation loss: 1.8215159946872341

Epoch: 6| Step: 3
Training loss: 1.6175408363342285
Validation loss: 1.793769855653086

Epoch: 6| Step: 4
Training loss: 1.0718740224838257
Validation loss: 1.8153108230201147

Epoch: 6| Step: 5
Training loss: 1.932808518409729
Validation loss: 1.8269546416498

Epoch: 6| Step: 6
Training loss: 1.3679922819137573
Validation loss: 1.829503777206585

Epoch: 6| Step: 7
Training loss: 2.6259713172912598
Validation loss: 1.8286595459907287

Epoch: 6| Step: 8
Training loss: 1.9769930839538574
Validation loss: 1.829093179395122

Epoch: 6| Step: 9
Training loss: 1.4598851203918457
Validation loss: 1.8424449479708107

Epoch: 6| Step: 10
Training loss: 1.3652838468551636
Validation loss: 1.839460346006578

Epoch: 6| Step: 11
Training loss: 1.9300823211669922
Validation loss: 1.8144323825836182

Epoch: 6| Step: 12
Training loss: 1.3811386823654175
Validation loss: 1.8141739919621458

Epoch: 6| Step: 13
Training loss: 1.4280694723129272
Validation loss: 1.8321115573247273

Epoch: 285| Step: 0
Training loss: 1.7930928468704224
Validation loss: 1.8289918027898318

Epoch: 6| Step: 1
Training loss: 1.3879098892211914
Validation loss: 1.8520788441422165

Epoch: 6| Step: 2
Training loss: 2.6320602893829346
Validation loss: 1.8950481273794686

Epoch: 6| Step: 3
Training loss: 1.476394534111023
Validation loss: 1.9197052704390658

Epoch: 6| Step: 4
Training loss: 1.564748764038086
Validation loss: 1.9125275599059237

Epoch: 6| Step: 5
Training loss: 1.4938933849334717
Validation loss: 1.9207545018965198

Epoch: 6| Step: 6
Training loss: 1.9683564901351929
Validation loss: 1.936821158214282

Epoch: 6| Step: 7
Training loss: 1.482907772064209
Validation loss: 1.931056220044372

Epoch: 6| Step: 8
Training loss: 1.5063583850860596
Validation loss: 1.9326407396665184

Epoch: 6| Step: 9
Training loss: 1.351753830909729
Validation loss: 1.9926581100750995

Epoch: 6| Step: 10
Training loss: 1.3736181259155273
Validation loss: 1.910471039433633

Epoch: 6| Step: 11
Training loss: 1.2873883247375488
Validation loss: 1.9044300010127406

Epoch: 6| Step: 12
Training loss: 1.8455322980880737
Validation loss: 1.9199460834585211

Epoch: 6| Step: 13
Training loss: 1.057652235031128
Validation loss: 1.880939265733124

Epoch: 286| Step: 0
Training loss: 2.2710468769073486
Validation loss: 1.867988081388576

Epoch: 6| Step: 1
Training loss: 1.7279192209243774
Validation loss: 1.8614847262700398

Epoch: 6| Step: 2
Training loss: 1.4913997650146484
Validation loss: 1.8279228889813988

Epoch: 6| Step: 3
Training loss: 1.767301082611084
Validation loss: 1.849911315466768

Epoch: 6| Step: 4
Training loss: 1.7632238864898682
Validation loss: 1.8516570432211763

Epoch: 6| Step: 5
Training loss: 1.2620819807052612
Validation loss: 1.8364147627225487

Epoch: 6| Step: 6
Training loss: 1.496840476989746
Validation loss: 1.8368054923190866

Epoch: 6| Step: 7
Training loss: 1.4246127605438232
Validation loss: 1.8095475935166883

Epoch: 6| Step: 8
Training loss: 1.3720335960388184
Validation loss: 1.7997067795004895

Epoch: 6| Step: 9
Training loss: 1.6676923036575317
Validation loss: 1.8142221127786944

Epoch: 6| Step: 10
Training loss: 1.726098656654358
Validation loss: 1.7961803213242562

Epoch: 6| Step: 11
Training loss: 1.674464464187622
Validation loss: 1.8580402994668612

Epoch: 6| Step: 12
Training loss: 1.0584343671798706
Validation loss: 1.8171837816956222

Epoch: 6| Step: 13
Training loss: 1.2357912063598633
Validation loss: 1.8394120047169347

Epoch: 287| Step: 0
Training loss: 1.438560128211975
Validation loss: 1.833958847548372

Epoch: 6| Step: 1
Training loss: 1.5686323642730713
Validation loss: 1.8560252920273812

Epoch: 6| Step: 2
Training loss: 1.301547884941101
Validation loss: 1.8350004034657632

Epoch: 6| Step: 3
Training loss: 2.08773136138916
Validation loss: 1.8489449280564503

Epoch: 6| Step: 4
Training loss: 1.1445796489715576
Validation loss: 1.857919777593305

Epoch: 6| Step: 5
Training loss: 1.328100323677063
Validation loss: 1.8472448151598695

Epoch: 6| Step: 6
Training loss: 1.3923044204711914
Validation loss: 1.8733955724264986

Epoch: 6| Step: 7
Training loss: 1.7559394836425781
Validation loss: 1.851800275105302

Epoch: 6| Step: 8
Training loss: 2.005898952484131
Validation loss: 1.8460848639088292

Epoch: 6| Step: 9
Training loss: 1.9000308513641357
Validation loss: 1.838694336593792

Epoch: 6| Step: 10
Training loss: 1.7831270694732666
Validation loss: 1.8287360245181667

Epoch: 6| Step: 11
Training loss: 1.6666662693023682
Validation loss: 1.8300342687996485

Epoch: 6| Step: 12
Training loss: 1.0609897375106812
Validation loss: 1.8199044504473287

Epoch: 6| Step: 13
Training loss: 1.0882563591003418
Validation loss: 1.8450974520816599

Epoch: 288| Step: 0
Training loss: 1.6254843473434448
Validation loss: 1.829200771547133

Epoch: 6| Step: 1
Training loss: 1.864778995513916
Validation loss: 1.8236468338197278

Epoch: 6| Step: 2
Training loss: 1.6311354637145996
Validation loss: 1.804491703228284

Epoch: 6| Step: 3
Training loss: 1.417978286743164
Validation loss: 1.84715937670841

Epoch: 6| Step: 4
Training loss: 2.2415895462036133
Validation loss: 1.7920152564202585

Epoch: 6| Step: 5
Training loss: 1.2415902614593506
Validation loss: 1.8357670717341925

Epoch: 6| Step: 6
Training loss: 1.2176682949066162
Validation loss: 1.8212707702831556

Epoch: 6| Step: 7
Training loss: 1.7478158473968506
Validation loss: 1.8366706973762923

Epoch: 6| Step: 8
Training loss: 1.249252200126648
Validation loss: 1.8239841076635546

Epoch: 6| Step: 9
Training loss: 1.3803284168243408
Validation loss: 1.8141190364796629

Epoch: 6| Step: 10
Training loss: 2.4039509296417236
Validation loss: 1.8293266680932814

Epoch: 6| Step: 11
Training loss: 1.523481845855713
Validation loss: 1.8152039973966536

Epoch: 6| Step: 12
Training loss: 1.2245720624923706
Validation loss: 1.8342848183006368

Epoch: 6| Step: 13
Training loss: 0.7846906781196594
Validation loss: 1.8603541287042762

Epoch: 289| Step: 0
Training loss: 2.148084878921509
Validation loss: 1.849045903451981

Epoch: 6| Step: 1
Training loss: 1.2586193084716797
Validation loss: 1.8401700655619304

Epoch: 6| Step: 2
Training loss: 2.2329490184783936
Validation loss: 1.8596633608623216

Epoch: 6| Step: 3
Training loss: 1.649443507194519
Validation loss: 1.8489346709302676

Epoch: 6| Step: 4
Training loss: 1.3043079376220703
Validation loss: 1.845857398484343

Epoch: 6| Step: 5
Training loss: 1.2900493144989014
Validation loss: 1.8559109677550614

Epoch: 6| Step: 6
Training loss: 1.7624517679214478
Validation loss: 1.8556287006665302

Epoch: 6| Step: 7
Training loss: 1.025322437286377
Validation loss: 1.8631158310879943

Epoch: 6| Step: 8
Training loss: 0.8941368460655212
Validation loss: 1.8545645026750461

Epoch: 6| Step: 9
Training loss: 1.4860022068023682
Validation loss: 1.8411450796229865

Epoch: 6| Step: 10
Training loss: 2.126718521118164
Validation loss: 1.8107645832082278

Epoch: 6| Step: 11
Training loss: 2.128413200378418
Validation loss: 1.8334452785471433

Epoch: 6| Step: 12
Training loss: 1.253692626953125
Validation loss: 1.8295167402554584

Epoch: 6| Step: 13
Training loss: 1.2046271562576294
Validation loss: 1.8395077797674364

Epoch: 290| Step: 0
Training loss: 1.5441155433654785
Validation loss: 1.8402965940454954

Epoch: 6| Step: 1
Training loss: 2.269850492477417
Validation loss: 1.85152478115533

Epoch: 6| Step: 2
Training loss: 1.3994642496109009
Validation loss: 1.8248597139953284

Epoch: 6| Step: 3
Training loss: 1.685623049736023
Validation loss: 1.8188737874389977

Epoch: 6| Step: 4
Training loss: 1.3693290948867798
Validation loss: 1.8367702986604424

Epoch: 6| Step: 5
Training loss: 1.2476909160614014
Validation loss: 1.858124429179776

Epoch: 6| Step: 6
Training loss: 1.604219913482666
Validation loss: 1.8360432271034486

Epoch: 6| Step: 7
Training loss: 1.1418182849884033
Validation loss: 1.8322840582939885

Epoch: 6| Step: 8
Training loss: 1.3968920707702637
Validation loss: 1.8174427273452922

Epoch: 6| Step: 9
Training loss: 1.6518290042877197
Validation loss: 1.841797774837863

Epoch: 6| Step: 10
Training loss: 1.0464372634887695
Validation loss: 1.84991927044366

Epoch: 6| Step: 11
Training loss: 1.952226161956787
Validation loss: 1.8299921738204135

Epoch: 6| Step: 12
Training loss: 1.6326179504394531
Validation loss: 1.8268234857948877

Epoch: 6| Step: 13
Training loss: 1.488396167755127
Validation loss: 1.8310731252034504

Epoch: 291| Step: 0
Training loss: 2.096740484237671
Validation loss: 1.8044621354790145

Epoch: 6| Step: 1
Training loss: 1.2860496044158936
Validation loss: 1.8045645119041525

Epoch: 6| Step: 2
Training loss: 1.579958200454712
Validation loss: 1.8251087306648173

Epoch: 6| Step: 3
Training loss: 1.6186972856521606
Validation loss: 1.8487408263708955

Epoch: 6| Step: 4
Training loss: 1.6291346549987793
Validation loss: 1.8076413062310988

Epoch: 6| Step: 5
Training loss: 1.211592674255371
Validation loss: 1.8691899302185222

Epoch: 6| Step: 6
Training loss: 1.2545065879821777
Validation loss: 1.799520661753993

Epoch: 6| Step: 7
Training loss: 1.0039911270141602
Validation loss: 1.8351941288158458

Epoch: 6| Step: 8
Training loss: 2.0039920806884766
Validation loss: 1.8456277590925976

Epoch: 6| Step: 9
Training loss: 1.9387074708938599
Validation loss: 1.8241251976259294

Epoch: 6| Step: 10
Training loss: 1.6471906900405884
Validation loss: 1.8212402969278314

Epoch: 6| Step: 11
Training loss: 1.4293084144592285
Validation loss: 1.820415214825702

Epoch: 6| Step: 12
Training loss: 1.2914396524429321
Validation loss: 1.8334243336031515

Epoch: 6| Step: 13
Training loss: 1.5975053310394287
Validation loss: 1.8030863590137933

Epoch: 292| Step: 0
Training loss: 0.73931884765625
Validation loss: 1.79817993410172

Epoch: 6| Step: 1
Training loss: 1.401132345199585
Validation loss: 1.7909957080759027

Epoch: 6| Step: 2
Training loss: 1.4866018295288086
Validation loss: 1.8128688027781825

Epoch: 6| Step: 3
Training loss: 1.4239439964294434
Validation loss: 1.8026859798739034

Epoch: 6| Step: 4
Training loss: 1.6025924682617188
Validation loss: 1.8030244086378364

Epoch: 6| Step: 5
Training loss: 1.8148466348648071
Validation loss: 1.8317077582882297

Epoch: 6| Step: 6
Training loss: 1.5786925554275513
Validation loss: 1.8045677600368377

Epoch: 6| Step: 7
Training loss: 0.9291120767593384
Validation loss: 1.8277701793178436

Epoch: 6| Step: 8
Training loss: 1.6915011405944824
Validation loss: 1.814041345350204

Epoch: 6| Step: 9
Training loss: 1.6426560878753662
Validation loss: 1.8078467640825497

Epoch: 6| Step: 10
Training loss: 1.6526079177856445
Validation loss: 1.835632675437517

Epoch: 6| Step: 11
Training loss: 1.931403636932373
Validation loss: 1.8442998560526038

Epoch: 6| Step: 12
Training loss: 1.7433631420135498
Validation loss: 1.880248390218263

Epoch: 6| Step: 13
Training loss: 2.260674476623535
Validation loss: 1.852411921306323

Epoch: 293| Step: 0
Training loss: 2.042818069458008
Validation loss: 1.8612145031652143

Epoch: 6| Step: 1
Training loss: 1.4559252262115479
Validation loss: 1.8656475646521455

Epoch: 6| Step: 2
Training loss: 1.2841579914093018
Validation loss: 1.87266021133751

Epoch: 6| Step: 3
Training loss: 0.8894262313842773
Validation loss: 1.8479370891406972

Epoch: 6| Step: 4
Training loss: 1.712640404701233
Validation loss: 1.8127710139879616

Epoch: 6| Step: 5
Training loss: 1.3778282403945923
Validation loss: 1.8386618155305103

Epoch: 6| Step: 6
Training loss: 2.1154096126556396
Validation loss: 1.8150410126614314

Epoch: 6| Step: 7
Training loss: 0.9472719430923462
Validation loss: 1.8291838194734307

Epoch: 6| Step: 8
Training loss: 1.684457540512085
Validation loss: 1.8272777603518577

Epoch: 6| Step: 9
Training loss: 1.9942433834075928
Validation loss: 1.8558969959135978

Epoch: 6| Step: 10
Training loss: 1.525077223777771
Validation loss: 1.8114536013654483

Epoch: 6| Step: 11
Training loss: 0.8958854675292969
Validation loss: 1.800040788547967

Epoch: 6| Step: 12
Training loss: 2.021146774291992
Validation loss: 1.8235242302699755

Epoch: 6| Step: 13
Training loss: 1.4975543022155762
Validation loss: 1.8535629933880222

Epoch: 294| Step: 0
Training loss: 1.4032548666000366
Validation loss: 1.8452796577125468

Epoch: 6| Step: 1
Training loss: 1.597480058670044
Validation loss: 1.8381166535039102

Epoch: 6| Step: 2
Training loss: 1.1763328313827515
Validation loss: 1.8597683983464395

Epoch: 6| Step: 3
Training loss: 1.305661916732788
Validation loss: 1.868387487626845

Epoch: 6| Step: 4
Training loss: 1.5202734470367432
Validation loss: 1.8736699165836457

Epoch: 6| Step: 5
Training loss: 2.0484070777893066
Validation loss: 1.8562969648709862

Epoch: 6| Step: 6
Training loss: 1.4408714771270752
Validation loss: 1.8612796145100747

Epoch: 6| Step: 7
Training loss: 2.1008522510528564
Validation loss: 1.8051609775071502

Epoch: 6| Step: 8
Training loss: 2.410299301147461
Validation loss: 1.860392798659622

Epoch: 6| Step: 9
Training loss: 1.1528174877166748
Validation loss: 1.8117164078579153

Epoch: 6| Step: 10
Training loss: 1.2786386013031006
Validation loss: 1.835308559479252

Epoch: 6| Step: 11
Training loss: 1.5006967782974243
Validation loss: 1.8368586327439995

Epoch: 6| Step: 12
Training loss: 1.069608449935913
Validation loss: 1.850934055543715

Epoch: 6| Step: 13
Training loss: 1.5995769500732422
Validation loss: 1.838084424054751

Epoch: 295| Step: 0
Training loss: 1.0608563423156738
Validation loss: 1.8487174895501906

Epoch: 6| Step: 1
Training loss: 1.554182767868042
Validation loss: 1.7986510107594151

Epoch: 6| Step: 2
Training loss: 1.8332836627960205
Validation loss: 1.8158657781539425

Epoch: 6| Step: 3
Training loss: 1.406375765800476
Validation loss: 1.8173875065260037

Epoch: 6| Step: 4
Training loss: 1.4446117877960205
Validation loss: 1.836970006265948

Epoch: 6| Step: 5
Training loss: 1.0045349597930908
Validation loss: 1.811160630436354

Epoch: 6| Step: 6
Training loss: 1.3567626476287842
Validation loss: 1.8367355792753157

Epoch: 6| Step: 7
Training loss: 2.005596160888672
Validation loss: 1.830295766553571

Epoch: 6| Step: 8
Training loss: 1.39066481590271
Validation loss: 1.8394774724078435

Epoch: 6| Step: 9
Training loss: 1.7369458675384521
Validation loss: 1.8037515673586118

Epoch: 6| Step: 10
Training loss: 1.693605661392212
Validation loss: 1.8133627189102994

Epoch: 6| Step: 11
Training loss: 1.2940013408660889
Validation loss: 1.8254377880404073

Epoch: 6| Step: 12
Training loss: 2.424433708190918
Validation loss: 1.841770359264907

Epoch: 6| Step: 13
Training loss: 1.1119734048843384
Validation loss: 1.8439095866295598

Epoch: 296| Step: 0
Training loss: 1.2626858949661255
Validation loss: 1.830465534681915

Epoch: 6| Step: 1
Training loss: 1.297914981842041
Validation loss: 1.8360436654859973

Epoch: 6| Step: 2
Training loss: 0.9253808259963989
Validation loss: 1.8432543354649698

Epoch: 6| Step: 3
Training loss: 1.542595386505127
Validation loss: 1.8115609563807005

Epoch: 6| Step: 4
Training loss: 1.5470666885375977
Validation loss: 1.8027361234029133

Epoch: 6| Step: 5
Training loss: 1.9767400026321411
Validation loss: 1.8354829165243334

Epoch: 6| Step: 6
Training loss: 1.9525666236877441
Validation loss: 1.809025954174739

Epoch: 6| Step: 7
Training loss: 1.606379747390747
Validation loss: 1.7924111376526535

Epoch: 6| Step: 8
Training loss: 1.465256929397583
Validation loss: 1.8018510162189443

Epoch: 6| Step: 9
Training loss: 2.088575839996338
Validation loss: 1.8265994005305792

Epoch: 6| Step: 10
Training loss: 1.4762725830078125
Validation loss: 1.8325843605943906

Epoch: 6| Step: 11
Training loss: 1.104095697402954
Validation loss: 1.840613236991308

Epoch: 6| Step: 12
Training loss: 1.3776355981826782
Validation loss: 1.838692198517502

Epoch: 6| Step: 13
Training loss: 1.7681242227554321
Validation loss: 1.8585588034763132

Epoch: 297| Step: 0
Training loss: 1.5203137397766113
Validation loss: 1.84796707348157

Epoch: 6| Step: 1
Training loss: 1.34098482131958
Validation loss: 1.8004720390483897

Epoch: 6| Step: 2
Training loss: 2.597043991088867
Validation loss: 1.7943809904078

Epoch: 6| Step: 3
Training loss: 1.2386515140533447
Validation loss: 1.8326922347468715

Epoch: 6| Step: 4
Training loss: 1.9718048572540283
Validation loss: 1.8174678010325278

Epoch: 6| Step: 5
Training loss: 1.9836266040802002
Validation loss: 1.8557917507745887

Epoch: 6| Step: 6
Training loss: 1.1651065349578857
Validation loss: 1.8392768342007872

Epoch: 6| Step: 7
Training loss: 0.9077377319335938
Validation loss: 1.8443238491653113

Epoch: 6| Step: 8
Training loss: 0.9700831174850464
Validation loss: 1.8189940170575214

Epoch: 6| Step: 9
Training loss: 1.5407801866531372
Validation loss: 1.8394382563970422

Epoch: 6| Step: 10
Training loss: 1.4737937450408936
Validation loss: 1.8381615633605628

Epoch: 6| Step: 11
Training loss: 1.255127191543579
Validation loss: 1.8705419673714587

Epoch: 6| Step: 12
Training loss: 1.5336236953735352
Validation loss: 1.8574783366213563

Epoch: 6| Step: 13
Training loss: 1.8866560459136963
Validation loss: 1.79882118650662

Epoch: 298| Step: 0
Training loss: 1.9471265077590942
Validation loss: 1.857589275606217

Epoch: 6| Step: 1
Training loss: 1.0125560760498047
Validation loss: 1.828230470739385

Epoch: 6| Step: 2
Training loss: 2.007756233215332
Validation loss: 1.8421601403144099

Epoch: 6| Step: 3
Training loss: 1.0950753688812256
Validation loss: 1.8292025417409918

Epoch: 6| Step: 4
Training loss: 1.6331684589385986
Validation loss: 1.8102197275366834

Epoch: 6| Step: 5
Training loss: 1.6622214317321777
Validation loss: 1.812271568082994

Epoch: 6| Step: 6
Training loss: 1.6802408695220947
Validation loss: 1.7956412274350402

Epoch: 6| Step: 7
Training loss: 1.4710466861724854
Validation loss: 1.8103298897384315

Epoch: 6| Step: 8
Training loss: 1.5105504989624023
Validation loss: 1.8191407470292942

Epoch: 6| Step: 9
Training loss: 1.0462340116500854
Validation loss: 1.8309792152015112

Epoch: 6| Step: 10
Training loss: 2.0098679065704346
Validation loss: 1.789798685299453

Epoch: 6| Step: 11
Training loss: 0.998900294303894
Validation loss: 1.8361636284858949

Epoch: 6| Step: 12
Training loss: 1.3853323459625244
Validation loss: 1.90881262927927

Epoch: 6| Step: 13
Training loss: 1.5735620260238647
Validation loss: 1.8231172792373165

Epoch: 299| Step: 0
Training loss: 1.6002461910247803
Validation loss: 1.8414162679385113

Epoch: 6| Step: 1
Training loss: 1.7429256439208984
Validation loss: 1.8197312111495643

Epoch: 6| Step: 2
Training loss: 1.6282976865768433
Validation loss: 1.8276007380536807

Epoch: 6| Step: 3
Training loss: 1.5917847156524658
Validation loss: 1.8246718170822307

Epoch: 6| Step: 4
Training loss: 1.375453233718872
Validation loss: 1.8432162859106576

Epoch: 6| Step: 5
Training loss: 2.4455299377441406
Validation loss: 1.812311404494829

Epoch: 6| Step: 6
Training loss: 0.8982282280921936
Validation loss: 1.8260367089702236

Epoch: 6| Step: 7
Training loss: 1.6993870735168457
Validation loss: 1.853577043420525

Epoch: 6| Step: 8
Training loss: 1.0585836172103882
Validation loss: 1.8280449631393596

Epoch: 6| Step: 9
Training loss: 1.0138548612594604
Validation loss: 1.8448631968549503

Epoch: 6| Step: 10
Training loss: 1.5856947898864746
Validation loss: 1.8240156712070588

Epoch: 6| Step: 11
Training loss: 1.385656476020813
Validation loss: 1.833969000847109

Epoch: 6| Step: 12
Training loss: 1.5295538902282715
Validation loss: 1.8059948195693314

Epoch: 6| Step: 13
Training loss: 1.46950101852417
Validation loss: 1.795225408769423

Epoch: 300| Step: 0
Training loss: 1.1432900428771973
Validation loss: 1.8440304866401098

Epoch: 6| Step: 1
Training loss: 1.2200807332992554
Validation loss: 1.8040458412580593

Epoch: 6| Step: 2
Training loss: 2.2957916259765625
Validation loss: 1.8183377340275755

Epoch: 6| Step: 3
Training loss: 1.9347615242004395
Validation loss: 1.8351201972653788

Epoch: 6| Step: 4
Training loss: 1.4836323261260986
Validation loss: 1.8152410817402664

Epoch: 6| Step: 5
Training loss: 1.7291760444641113
Validation loss: 1.8299455437608945

Epoch: 6| Step: 6
Training loss: 1.630105972290039
Validation loss: 1.7731539421184088

Epoch: 6| Step: 7
Training loss: 1.6844241619110107
Validation loss: 1.833769267605197

Epoch: 6| Step: 8
Training loss: 1.1993669271469116
Validation loss: 1.8408934839310185

Epoch: 6| Step: 9
Training loss: 1.359336018562317
Validation loss: 1.803683670618201

Epoch: 6| Step: 10
Training loss: 1.5816431045532227
Validation loss: 1.8591293186269782

Epoch: 6| Step: 11
Training loss: 1.495836853981018
Validation loss: 1.8678709435206589

Epoch: 6| Step: 12
Training loss: 1.5504786968231201
Validation loss: 1.8377919145809707

Epoch: 6| Step: 13
Training loss: 0.97041916847229
Validation loss: 1.8172343187434699

Epoch: 301| Step: 0
Training loss: 1.673804759979248
Validation loss: 1.8297923380328762

Epoch: 6| Step: 1
Training loss: 1.6932621002197266
Validation loss: 1.8574525374238209

Epoch: 6| Step: 2
Training loss: 1.1705310344696045
Validation loss: 1.8113557882206415

Epoch: 6| Step: 3
Training loss: 1.4962040185928345
Validation loss: 1.8704140032491376

Epoch: 6| Step: 4
Training loss: 1.2925487756729126
Validation loss: 1.831658055705409

Epoch: 6| Step: 5
Training loss: 0.9789945483207703
Validation loss: 1.7940186454403786

Epoch: 6| Step: 6
Training loss: 1.2825756072998047
Validation loss: 1.8106454046823646

Epoch: 6| Step: 7
Training loss: 1.6088788509368896
Validation loss: 1.7907858587080432

Epoch: 6| Step: 8
Training loss: 2.22355055809021
Validation loss: 1.8190515131078742

Epoch: 6| Step: 9
Training loss: 2.1751976013183594
Validation loss: 1.8400352257554249

Epoch: 6| Step: 10
Training loss: 0.9570653438568115
Validation loss: 1.8508198415079424

Epoch: 6| Step: 11
Training loss: 2.1861572265625
Validation loss: 1.7926172235960602

Epoch: 6| Step: 12
Training loss: 1.0744885206222534
Validation loss: 1.8833339906507922

Epoch: 6| Step: 13
Training loss: 1.2032307386398315
Validation loss: 1.8537419893408333

Epoch: 302| Step: 0
Training loss: 1.5994040966033936
Validation loss: 1.8484545471847698

Epoch: 6| Step: 1
Training loss: 1.3729486465454102
Validation loss: 1.8043167629549581

Epoch: 6| Step: 2
Training loss: 1.5685317516326904
Validation loss: 1.847400229464295

Epoch: 6| Step: 3
Training loss: 1.4094374179840088
Validation loss: 1.8475884891325427

Epoch: 6| Step: 4
Training loss: 1.945601224899292
Validation loss: 1.8276013264092066

Epoch: 6| Step: 5
Training loss: 1.0609709024429321
Validation loss: 1.8087470172553934

Epoch: 6| Step: 6
Training loss: 0.9810167551040649
Validation loss: 1.8565812892811273

Epoch: 6| Step: 7
Training loss: 1.2720686197280884
Validation loss: 1.8113049742996052

Epoch: 6| Step: 8
Training loss: 1.5494606494903564
Validation loss: 1.85131743133709

Epoch: 6| Step: 9
Training loss: 1.6091458797454834
Validation loss: 1.834274184319281

Epoch: 6| Step: 10
Training loss: 1.6662044525146484
Validation loss: 1.7927577957030265

Epoch: 6| Step: 11
Training loss: 1.9293029308319092
Validation loss: 1.833100172781175

Epoch: 6| Step: 12
Training loss: 1.641381025314331
Validation loss: 1.8015136475204139

Epoch: 6| Step: 13
Training loss: 1.4423381090164185
Validation loss: 1.8481000085030832

Epoch: 303| Step: 0
Training loss: 1.054858684539795
Validation loss: 1.836225563480008

Epoch: 6| Step: 1
Training loss: 1.509097933769226
Validation loss: 1.813663891566697

Epoch: 6| Step: 2
Training loss: 1.363706111907959
Validation loss: 1.8329663802218694

Epoch: 6| Step: 3
Training loss: 1.631206750869751
Validation loss: 1.8140214309897473

Epoch: 6| Step: 4
Training loss: 1.508274793624878
Validation loss: 1.801308467823972

Epoch: 6| Step: 5
Training loss: 1.8571491241455078
Validation loss: 1.8008558019515006

Epoch: 6| Step: 6
Training loss: 1.5231728553771973
Validation loss: 1.866530784996607

Epoch: 6| Step: 7
Training loss: 1.4241528511047363
Validation loss: 1.784851974056613

Epoch: 6| Step: 8
Training loss: 0.9006533622741699
Validation loss: 1.8145264348676127

Epoch: 6| Step: 9
Training loss: 1.443530797958374
Validation loss: 1.7746815014910955

Epoch: 6| Step: 10
Training loss: 1.2909162044525146
Validation loss: 1.753183582777618

Epoch: 6| Step: 11
Training loss: 1.572380542755127
Validation loss: 1.8139934437249297

Epoch: 6| Step: 12
Training loss: 2.36065673828125
Validation loss: 1.8186926893008653

Epoch: 6| Step: 13
Training loss: 2.4841508865356445
Validation loss: 1.8242886092073174

Epoch: 304| Step: 0
Training loss: 1.5069139003753662
Validation loss: 1.8470453267456384

Epoch: 6| Step: 1
Training loss: 1.7839645147323608
Validation loss: 1.8279979318700812

Epoch: 6| Step: 2
Training loss: 1.1922454833984375
Validation loss: 1.8029750854738298

Epoch: 6| Step: 3
Training loss: 1.7039865255355835
Validation loss: 1.7883422220906904

Epoch: 6| Step: 4
Training loss: 1.3906750679016113
Validation loss: 1.851518310526366

Epoch: 6| Step: 5
Training loss: 1.2187435626983643
Validation loss: 1.8440542451796993

Epoch: 6| Step: 6
Training loss: 1.1602425575256348
Validation loss: 1.865879471584033

Epoch: 6| Step: 7
Training loss: 1.4439815282821655
Validation loss: 1.8422285510647682

Epoch: 6| Step: 8
Training loss: 1.8600883483886719
Validation loss: 1.806326432894635

Epoch: 6| Step: 9
Training loss: 1.651953101158142
Validation loss: 1.8288281220261768

Epoch: 6| Step: 10
Training loss: 1.1249396800994873
Validation loss: 1.8010572951327088

Epoch: 6| Step: 11
Training loss: 1.7467535734176636
Validation loss: 1.8273722689638856

Epoch: 6| Step: 12
Training loss: 1.7792850732803345
Validation loss: 1.8272916245204147

Epoch: 6| Step: 13
Training loss: 1.1758737564086914
Validation loss: 1.7881742446653304

Epoch: 305| Step: 0
Training loss: 1.5964841842651367
Validation loss: 1.8325861782156012

Epoch: 6| Step: 1
Training loss: 1.170778751373291
Validation loss: 1.7896726310894053

Epoch: 6| Step: 2
Training loss: 0.9849160313606262
Validation loss: 1.786048214922669

Epoch: 6| Step: 3
Training loss: 1.3971381187438965
Validation loss: 1.8059930416845507

Epoch: 6| Step: 4
Training loss: 1.3821065425872803
Validation loss: 1.8039678976099978

Epoch: 6| Step: 5
Training loss: 2.0185611248016357
Validation loss: 1.8005453284068773

Epoch: 6| Step: 6
Training loss: 1.1961920261383057
Validation loss: 1.8073447596642278

Epoch: 6| Step: 7
Training loss: 1.6629397869110107
Validation loss: 1.840330357192665

Epoch: 6| Step: 8
Training loss: 0.8178474307060242
Validation loss: 1.7982369648512972

Epoch: 6| Step: 9
Training loss: 1.2920743227005005
Validation loss: 1.8136175345349055

Epoch: 6| Step: 10
Training loss: 1.7710330486297607
Validation loss: 1.799189716257075

Epoch: 6| Step: 11
Training loss: 1.6557385921478271
Validation loss: 1.813960644506639

Epoch: 6| Step: 12
Training loss: 2.52229380607605
Validation loss: 1.8141795896714734

Epoch: 6| Step: 13
Training loss: 1.609405755996704
Validation loss: 1.802557324850431

Epoch: 306| Step: 0
Training loss: 1.3783632516860962
Validation loss: 1.8283223670016053

Epoch: 6| Step: 1
Training loss: 1.1534608602523804
Validation loss: 1.8422395490830945

Epoch: 6| Step: 2
Training loss: 1.9114024639129639
Validation loss: 1.8448034101916897

Epoch: 6| Step: 3
Training loss: 1.2829644680023193
Validation loss: 1.8451596767671647

Epoch: 6| Step: 4
Training loss: 1.0472813844680786
Validation loss: 1.8515332488603489

Epoch: 6| Step: 5
Training loss: 1.990506649017334
Validation loss: 1.8692986516542331

Epoch: 6| Step: 6
Training loss: 1.0812404155731201
Validation loss: 1.8295974808354531

Epoch: 6| Step: 7
Training loss: 1.1730197668075562
Validation loss: 1.8267283388363418

Epoch: 6| Step: 8
Training loss: 1.4688808917999268
Validation loss: 1.8421907630018008

Epoch: 6| Step: 9
Training loss: 1.6067757606506348
Validation loss: 1.8220078445249988

Epoch: 6| Step: 10
Training loss: 1.8492588996887207
Validation loss: 1.811397949854533

Epoch: 6| Step: 11
Training loss: 1.5771900415420532
Validation loss: 1.8221626615011564

Epoch: 6| Step: 12
Training loss: 2.0205020904541016
Validation loss: 1.8048852951295915

Epoch: 6| Step: 13
Training loss: 1.2344062328338623
Validation loss: 1.8399587677371116

Epoch: 307| Step: 0
Training loss: 2.4266018867492676
Validation loss: 1.8330549911786151

Epoch: 6| Step: 1
Training loss: 1.389920711517334
Validation loss: 1.8376658103799308

Epoch: 6| Step: 2
Training loss: 1.990748643875122
Validation loss: 1.8335239938510361

Epoch: 6| Step: 3
Training loss: 1.5027132034301758
Validation loss: 1.8011800755736649

Epoch: 6| Step: 4
Training loss: 1.5285567045211792
Validation loss: 1.8024897088286698

Epoch: 6| Step: 5
Training loss: 1.3603242635726929
Validation loss: 1.8550807481170983

Epoch: 6| Step: 6
Training loss: 1.2999982833862305
Validation loss: 1.8590349407606228

Epoch: 6| Step: 7
Training loss: 1.3381354808807373
Validation loss: 1.8316114012913038

Epoch: 6| Step: 8
Training loss: 1.368561029434204
Validation loss: 1.8172418686651415

Epoch: 6| Step: 9
Training loss: 1.2917289733886719
Validation loss: 1.848744705159177

Epoch: 6| Step: 10
Training loss: 2.042747974395752
Validation loss: 1.8179931025351248

Epoch: 6| Step: 11
Training loss: 1.0258058309555054
Validation loss: 1.7880372539643319

Epoch: 6| Step: 12
Training loss: 0.8105123043060303
Validation loss: 1.8272786858261272

Epoch: 6| Step: 13
Training loss: 1.0034500360488892
Validation loss: 1.8103947383101269

Epoch: 308| Step: 0
Training loss: 1.5701053142547607
Validation loss: 1.8237291074568225

Epoch: 6| Step: 1
Training loss: 1.190920352935791
Validation loss: 1.8402909976179882

Epoch: 6| Step: 2
Training loss: 1.7777525186538696
Validation loss: 1.7889725348000884

Epoch: 6| Step: 3
Training loss: 1.0522584915161133
Validation loss: 1.7994861038782264

Epoch: 6| Step: 4
Training loss: 1.8973486423492432
Validation loss: 1.7894291864928378

Epoch: 6| Step: 5
Training loss: 1.5396205186843872
Validation loss: 1.7698637016357914

Epoch: 6| Step: 6
Training loss: 1.2369688749313354
Validation loss: 1.7751700775597685

Epoch: 6| Step: 7
Training loss: 1.878814697265625
Validation loss: 1.776619416411205

Epoch: 6| Step: 8
Training loss: 1.4800503253936768
Validation loss: 1.8020330911041589

Epoch: 6| Step: 9
Training loss: 1.6409844160079956
Validation loss: 1.8155661065091369

Epoch: 6| Step: 10
Training loss: 1.2932994365692139
Validation loss: 1.797258746239447

Epoch: 6| Step: 11
Training loss: 1.3682122230529785
Validation loss: 1.7789644579733572

Epoch: 6| Step: 12
Training loss: 1.1482480764389038
Validation loss: 1.828552422984954

Epoch: 6| Step: 13
Training loss: 2.066922187805176
Validation loss: 1.8079670321556829

Epoch: 309| Step: 0
Training loss: 1.2412328720092773
Validation loss: 1.8563131722070838

Epoch: 6| Step: 1
Training loss: 0.9270968437194824
Validation loss: 1.8218779063993884

Epoch: 6| Step: 2
Training loss: 1.3330578804016113
Validation loss: 1.9031691551208496

Epoch: 6| Step: 3
Training loss: 1.2506346702575684
Validation loss: 1.8632311359528573

Epoch: 6| Step: 4
Training loss: 1.2487599849700928
Validation loss: 1.9023102419350737

Epoch: 6| Step: 5
Training loss: 1.422591209411621
Validation loss: 1.9002109637824438

Epoch: 6| Step: 6
Training loss: 1.8547940254211426
Validation loss: 1.8743777300721856

Epoch: 6| Step: 7
Training loss: 1.7789589166641235
Validation loss: 1.8934978900417205

Epoch: 6| Step: 8
Training loss: 1.3108000755310059
Validation loss: 1.9122148303575413

Epoch: 6| Step: 9
Training loss: 1.5048846006393433
Validation loss: 1.8641731072497625

Epoch: 6| Step: 10
Training loss: 2.540834426879883
Validation loss: 1.811955754474927

Epoch: 6| Step: 11
Training loss: 1.770156979560852
Validation loss: 1.8468356734962874

Epoch: 6| Step: 12
Training loss: 0.750007688999176
Validation loss: 1.818063775698344

Epoch: 6| Step: 13
Training loss: 1.9027761220932007
Validation loss: 1.826558264352942

Epoch: 310| Step: 0
Training loss: 1.402673602104187
Validation loss: 1.80039934701817

Epoch: 6| Step: 1
Training loss: 1.5197153091430664
Validation loss: 1.774835439138515

Epoch: 6| Step: 2
Training loss: 1.7662980556488037
Validation loss: 1.8173269187250445

Epoch: 6| Step: 3
Training loss: 0.9284675121307373
Validation loss: 1.8268097972357145

Epoch: 6| Step: 4
Training loss: 1.4978573322296143
Validation loss: 1.8018519904023858

Epoch: 6| Step: 5
Training loss: 2.0115292072296143
Validation loss: 1.8311537427286948

Epoch: 6| Step: 6
Training loss: 1.2078524827957153
Validation loss: 1.7832173801237536

Epoch: 6| Step: 7
Training loss: 1.9697082042694092
Validation loss: 1.806231798664216

Epoch: 6| Step: 8
Training loss: 1.5636053085327148
Validation loss: 1.8064714221544163

Epoch: 6| Step: 9
Training loss: 1.269038200378418
Validation loss: 1.791238418189428

Epoch: 6| Step: 10
Training loss: 1.9022493362426758
Validation loss: 1.8254383020503546

Epoch: 6| Step: 11
Training loss: 0.6963950395584106
Validation loss: 1.8352313451869513

Epoch: 6| Step: 12
Training loss: 1.555760383605957
Validation loss: 1.8601255032324022

Epoch: 6| Step: 13
Training loss: 1.2228636741638184
Validation loss: 1.8347315634450605

Epoch: 311| Step: 0
Training loss: 1.4605201482772827
Validation loss: 1.8142580268203572

Epoch: 6| Step: 1
Training loss: 1.2824785709381104
Validation loss: 1.8028290117940595

Epoch: 6| Step: 2
Training loss: 0.9966729879379272
Validation loss: 1.7985234042649627

Epoch: 6| Step: 3
Training loss: 1.3735309839248657
Validation loss: 1.8112596888695993

Epoch: 6| Step: 4
Training loss: 1.3170082569122314
Validation loss: 1.846668258790047

Epoch: 6| Step: 5
Training loss: 1.1320656538009644
Validation loss: 1.8103879356897006

Epoch: 6| Step: 6
Training loss: 1.417372226715088
Validation loss: 1.7830981926251483

Epoch: 6| Step: 7
Training loss: 2.4647955894470215
Validation loss: 1.8046066696925829

Epoch: 6| Step: 8
Training loss: 1.7422178983688354
Validation loss: 1.8620094048079623

Epoch: 6| Step: 9
Training loss: 1.293393611907959
Validation loss: 1.8470245112654984

Epoch: 6| Step: 10
Training loss: 1.4841656684875488
Validation loss: 1.8433421247748918

Epoch: 6| Step: 11
Training loss: 1.5674291849136353
Validation loss: 1.8505293015510804

Epoch: 6| Step: 12
Training loss: 1.7991292476654053
Validation loss: 1.817945190655288

Epoch: 6| Step: 13
Training loss: 0.9662275314331055
Validation loss: 1.805427339769179

Epoch: 312| Step: 0
Training loss: 1.2825629711151123
Validation loss: 1.7855294186581847

Epoch: 6| Step: 1
Training loss: 1.8472509384155273
Validation loss: 1.8332005367484143

Epoch: 6| Step: 2
Training loss: 1.415202260017395
Validation loss: 1.8444066227123301

Epoch: 6| Step: 3
Training loss: 1.1879425048828125
Validation loss: 1.7947398936876686

Epoch: 6| Step: 4
Training loss: 1.2237929105758667
Validation loss: 1.8119527216880553

Epoch: 6| Step: 5
Training loss: 1.505815029144287
Validation loss: 1.823823135386231

Epoch: 6| Step: 6
Training loss: 1.7529964447021484
Validation loss: 1.8302764277304373

Epoch: 6| Step: 7
Training loss: 1.9502618312835693
Validation loss: 1.829948341974648

Epoch: 6| Step: 8
Training loss: 1.7966253757476807
Validation loss: 1.8372074724525533

Epoch: 6| Step: 9
Training loss: 1.255483627319336
Validation loss: 1.8534852471402896

Epoch: 6| Step: 10
Training loss: 1.045553207397461
Validation loss: 1.8088771194540045

Epoch: 6| Step: 11
Training loss: 1.6748957633972168
Validation loss: 1.8201489563911193

Epoch: 6| Step: 12
Training loss: 1.2296456098556519
Validation loss: 1.8341944832955637

Epoch: 6| Step: 13
Training loss: 1.6263517141342163
Validation loss: 1.872502435920059

Epoch: 313| Step: 0
Training loss: 1.7380826473236084
Validation loss: 1.820819559917655

Epoch: 6| Step: 1
Training loss: 1.388517141342163
Validation loss: 1.8489133260583366

Epoch: 6| Step: 2
Training loss: 1.3553454875946045
Validation loss: 1.8409422610395698

Epoch: 6| Step: 3
Training loss: 1.4708932638168335
Validation loss: 1.828774654737083

Epoch: 6| Step: 4
Training loss: 1.401552677154541
Validation loss: 1.8066653923321796

Epoch: 6| Step: 5
Training loss: 1.350728154182434
Validation loss: 1.785831694961876

Epoch: 6| Step: 6
Training loss: 1.186361312866211
Validation loss: 1.8309403850186257

Epoch: 6| Step: 7
Training loss: 1.3172370195388794
Validation loss: 1.7934857388978362

Epoch: 6| Step: 8
Training loss: 1.9810748100280762
Validation loss: 1.8138758072289087

Epoch: 6| Step: 9
Training loss: 1.541869878768921
Validation loss: 1.8123483004108552

Epoch: 6| Step: 10
Training loss: 0.9726476073265076
Validation loss: 1.7960281730980001

Epoch: 6| Step: 11
Training loss: 1.9220486879348755
Validation loss: 1.7809650526251843

Epoch: 6| Step: 12
Training loss: 1.4959698915481567
Validation loss: 1.7917840762804913

Epoch: 6| Step: 13
Training loss: 0.7692624926567078
Validation loss: 1.8425911088143625

Epoch: 314| Step: 0
Training loss: 1.4281312227249146
Validation loss: 1.831443594348046

Epoch: 6| Step: 1
Training loss: 1.1621417999267578
Validation loss: 1.8167527516682942

Epoch: 6| Step: 2
Training loss: 1.674052357673645
Validation loss: 1.837535390289881

Epoch: 6| Step: 3
Training loss: 1.0784735679626465
Validation loss: 1.8072885749160603

Epoch: 6| Step: 4
Training loss: 1.884894847869873
Validation loss: 1.8056374852375319

Epoch: 6| Step: 5
Training loss: 1.5538058280944824
Validation loss: 1.8188677064834102

Epoch: 6| Step: 6
Training loss: 1.1161516904830933
Validation loss: 1.7871731058243783

Epoch: 6| Step: 7
Training loss: 1.8733575344085693
Validation loss: 1.8592336613644835

Epoch: 6| Step: 8
Training loss: 1.3646098375320435
Validation loss: 1.8478280113589378

Epoch: 6| Step: 9
Training loss: 1.6241681575775146
Validation loss: 1.7905793882185412

Epoch: 6| Step: 10
Training loss: 1.1128063201904297
Validation loss: 1.7905400414620676

Epoch: 6| Step: 11
Training loss: 1.787777066230774
Validation loss: 1.805240543939734

Epoch: 6| Step: 12
Training loss: 1.5776686668395996
Validation loss: 1.7868988719037784

Epoch: 6| Step: 13
Training loss: 1.3417463302612305
Validation loss: 1.7805481110849688

Epoch: 315| Step: 0
Training loss: 0.8069990277290344
Validation loss: 1.7910730890048447

Epoch: 6| Step: 1
Training loss: 1.8553235530853271
Validation loss: 1.7869901477649648

Epoch: 6| Step: 2
Training loss: 1.9564212560653687
Validation loss: 1.8157300564550585

Epoch: 6| Step: 3
Training loss: 1.4711830615997314
Validation loss: 1.802297584472164

Epoch: 6| Step: 4
Training loss: 1.6718590259552002
Validation loss: 1.7949975344442552

Epoch: 6| Step: 5
Training loss: 1.242058277130127
Validation loss: 1.8097939798908849

Epoch: 6| Step: 6
Training loss: 1.0601310729980469
Validation loss: 1.845393919175671

Epoch: 6| Step: 7
Training loss: 1.4372204542160034
Validation loss: 1.7735051685763943

Epoch: 6| Step: 8
Training loss: 1.5613325834274292
Validation loss: 1.8679410424283756

Epoch: 6| Step: 9
Training loss: 1.3611663579940796
Validation loss: 1.7806452461468276

Epoch: 6| Step: 10
Training loss: 1.766693115234375
Validation loss: 1.82356934906334

Epoch: 6| Step: 11
Training loss: 1.7028484344482422
Validation loss: 1.799114175381199

Epoch: 6| Step: 12
Training loss: 1.3591824769973755
Validation loss: 1.8305296795342558

Epoch: 6| Step: 13
Training loss: 1.2405815124511719
Validation loss: 1.8346294190294

Epoch: 316| Step: 0
Training loss: 1.6548819541931152
Validation loss: 1.8260341023886075

Epoch: 6| Step: 1
Training loss: 1.4445018768310547
Validation loss: 1.8664251835115495

Epoch: 6| Step: 2
Training loss: 1.5087107419967651
Validation loss: 1.8386804993434618

Epoch: 6| Step: 3
Training loss: 1.6059739589691162
Validation loss: 1.8903027170447892

Epoch: 6| Step: 4
Training loss: 1.1197009086608887
Validation loss: 1.8605571690426077

Epoch: 6| Step: 5
Training loss: 1.3774278163909912
Validation loss: 1.8784490772472915

Epoch: 6| Step: 6
Training loss: 1.4200851917266846
Validation loss: 1.8378080424442087

Epoch: 6| Step: 7
Training loss: 1.4060430526733398
Validation loss: 1.8421898862367034

Epoch: 6| Step: 8
Training loss: 1.3185570240020752
Validation loss: 1.8451082039904851

Epoch: 6| Step: 9
Training loss: 1.2176268100738525
Validation loss: 1.8165649188462125

Epoch: 6| Step: 10
Training loss: 2.6277811527252197
Validation loss: 1.812682718359014

Epoch: 6| Step: 11
Training loss: 1.0378773212432861
Validation loss: 1.7897569428208053

Epoch: 6| Step: 12
Training loss: 1.2152886390686035
Validation loss: 1.8131904243141093

Epoch: 6| Step: 13
Training loss: 1.4075919389724731
Validation loss: 1.852005635538409

Epoch: 317| Step: 0
Training loss: 1.8780591487884521
Validation loss: 1.7865954842618716

Epoch: 6| Step: 1
Training loss: 1.78996741771698
Validation loss: 1.7896212057400775

Epoch: 6| Step: 2
Training loss: 1.5742919445037842
Validation loss: 1.793876286475889

Epoch: 6| Step: 3
Training loss: 1.0659761428833008
Validation loss: 1.8500704534592167

Epoch: 6| Step: 4
Training loss: 1.3956613540649414
Validation loss: 1.7521790740310506

Epoch: 6| Step: 5
Training loss: 1.594785213470459
Validation loss: 1.8057977973773915

Epoch: 6| Step: 6
Training loss: 1.5307562351226807
Validation loss: 1.810584440026232

Epoch: 6| Step: 7
Training loss: 1.3687670230865479
Validation loss: 1.7872645713949715

Epoch: 6| Step: 8
Training loss: 1.3801641464233398
Validation loss: 1.8086719397575624

Epoch: 6| Step: 9
Training loss: 1.7970733642578125
Validation loss: 1.8442197820191741

Epoch: 6| Step: 10
Training loss: 1.275534987449646
Validation loss: 1.8203904590299052

Epoch: 6| Step: 11
Training loss: 1.28218412399292
Validation loss: 1.7804427044365996

Epoch: 6| Step: 12
Training loss: 1.679911494255066
Validation loss: 1.7895181153410225

Epoch: 6| Step: 13
Training loss: 0.45877572894096375
Validation loss: 1.7880264687281784

Epoch: 318| Step: 0
Training loss: 1.2205634117126465
Validation loss: 1.7951305066385577

Epoch: 6| Step: 1
Training loss: 1.6895862817764282
Validation loss: 1.8131318297437442

Epoch: 6| Step: 2
Training loss: 1.000680923461914
Validation loss: 1.8019459427043956

Epoch: 6| Step: 3
Training loss: 1.7840303182601929
Validation loss: 1.8333515582546112

Epoch: 6| Step: 4
Training loss: 1.1441160440444946
Validation loss: 1.8042074698273853

Epoch: 6| Step: 5
Training loss: 1.458175778388977
Validation loss: 1.7546289736224758

Epoch: 6| Step: 6
Training loss: 1.2840286493301392
Validation loss: 1.8205134009802213

Epoch: 6| Step: 7
Training loss: 1.2322864532470703
Validation loss: 1.8030948844007266

Epoch: 6| Step: 8
Training loss: 1.7750095129013062
Validation loss: 1.79674102926767

Epoch: 6| Step: 9
Training loss: 1.6820518970489502
Validation loss: 1.825598096334806

Epoch: 6| Step: 10
Training loss: 1.8287019729614258
Validation loss: 1.8142506742990145

Epoch: 6| Step: 11
Training loss: 1.7342705726623535
Validation loss: 1.7901277695932696

Epoch: 6| Step: 12
Training loss: 1.3341288566589355
Validation loss: 1.7993132645084011

Epoch: 6| Step: 13
Training loss: 1.2747942209243774
Validation loss: 1.762066783443574

Epoch: 319| Step: 0
Training loss: 2.2004995346069336
Validation loss: 1.8319817358447659

Epoch: 6| Step: 1
Training loss: 0.9909942746162415
Validation loss: 1.7694637621602705

Epoch: 6| Step: 2
Training loss: 1.1905142068862915
Validation loss: 1.7991002426352551

Epoch: 6| Step: 3
Training loss: 1.4362807273864746
Validation loss: 1.8059607449398245

Epoch: 6| Step: 4
Training loss: 1.280847430229187
Validation loss: 1.8134819692181003

Epoch: 6| Step: 5
Training loss: 1.9026037454605103
Validation loss: 1.790348493924705

Epoch: 6| Step: 6
Training loss: 1.4564168453216553
Validation loss: 1.781079533279583

Epoch: 6| Step: 7
Training loss: 1.2299010753631592
Validation loss: 1.8462207163533857

Epoch: 6| Step: 8
Training loss: 0.9249060153961182
Validation loss: 1.8013851745154268

Epoch: 6| Step: 9
Training loss: 2.107147216796875
Validation loss: 1.8546060349351616

Epoch: 6| Step: 10
Training loss: 1.4313416481018066
Validation loss: 1.8390696664010324

Epoch: 6| Step: 11
Training loss: 1.610616683959961
Validation loss: 1.8278864570843276

Epoch: 6| Step: 12
Training loss: 1.080083966255188
Validation loss: 1.802750664372598

Epoch: 6| Step: 13
Training loss: 1.4364877939224243
Validation loss: 1.8114850841542727

Epoch: 320| Step: 0
Training loss: 1.4270939826965332
Validation loss: 1.8015384815072502

Epoch: 6| Step: 1
Training loss: 1.0856876373291016
Validation loss: 1.823717240364321

Epoch: 6| Step: 2
Training loss: 1.494628667831421
Validation loss: 1.8360582884921823

Epoch: 6| Step: 3
Training loss: 1.1608659029006958
Validation loss: 1.7588744330149826

Epoch: 6| Step: 4
Training loss: 1.3060601949691772
Validation loss: 1.8102389022868166

Epoch: 6| Step: 5
Training loss: 1.635617733001709
Validation loss: 1.8201254606246948

Epoch: 6| Step: 6
Training loss: 1.8115687370300293
Validation loss: 1.7927987242257724

Epoch: 6| Step: 7
Training loss: 1.3064509630203247
Validation loss: 1.801097349453998

Epoch: 6| Step: 8
Training loss: 1.6241295337677002
Validation loss: 1.8027480674046341

Epoch: 6| Step: 9
Training loss: 1.8269473314285278
Validation loss: 1.7909040963777931

Epoch: 6| Step: 10
Training loss: 2.0675551891326904
Validation loss: 1.8200087226847166

Epoch: 6| Step: 11
Training loss: 1.2747468948364258
Validation loss: 1.816371863888156

Epoch: 6| Step: 12
Training loss: 0.8858395218849182
Validation loss: 1.7937312446614748

Epoch: 6| Step: 13
Training loss: 0.9461653828620911
Validation loss: 1.775696994155966

Epoch: 321| Step: 0
Training loss: 1.6585044860839844
Validation loss: 1.8055633050139233

Epoch: 6| Step: 1
Training loss: 1.5664325952529907
Validation loss: 1.8378852080273371

Epoch: 6| Step: 2
Training loss: 1.7062585353851318
Validation loss: 1.8074232314222602

Epoch: 6| Step: 3
Training loss: 1.7531276941299438
Validation loss: 1.8014102494844826

Epoch: 6| Step: 4
Training loss: 1.686786413192749
Validation loss: 1.852286365724379

Epoch: 6| Step: 5
Training loss: 1.326543927192688
Validation loss: 1.8378294449980541

Epoch: 6| Step: 6
Training loss: 1.1362073421478271
Validation loss: 1.8177821533654326

Epoch: 6| Step: 7
Training loss: 1.2984113693237305
Validation loss: 1.8090747428196732

Epoch: 6| Step: 8
Training loss: 1.4840998649597168
Validation loss: 1.823984274300196

Epoch: 6| Step: 9
Training loss: 1.5485327243804932
Validation loss: 1.8578716683131393

Epoch: 6| Step: 10
Training loss: 1.1681759357452393
Validation loss: 1.8268277593838271

Epoch: 6| Step: 11
Training loss: 1.4285938739776611
Validation loss: 1.8503377719592022

Epoch: 6| Step: 12
Training loss: 1.15822434425354
Validation loss: 1.8461003918801584

Epoch: 6| Step: 13
Training loss: 0.8364285230636597
Validation loss: 1.8479507943635345

Epoch: 322| Step: 0
Training loss: 1.6956803798675537
Validation loss: 1.819881736591298

Epoch: 6| Step: 1
Training loss: 1.3030617237091064
Validation loss: 1.8186653173098

Epoch: 6| Step: 2
Training loss: 1.7103500366210938
Validation loss: 1.7887770770698466

Epoch: 6| Step: 3
Training loss: 1.7878644466400146
Validation loss: 1.8003482536603046

Epoch: 6| Step: 4
Training loss: 2.0027217864990234
Validation loss: 1.788786865049793

Epoch: 6| Step: 5
Training loss: 1.1910028457641602
Validation loss: 1.7654691511584866

Epoch: 6| Step: 6
Training loss: 1.3943402767181396
Validation loss: 1.800297994767466

Epoch: 6| Step: 7
Training loss: 1.6899865865707397
Validation loss: 1.8084164357954455

Epoch: 6| Step: 8
Training loss: 1.0271227359771729
Validation loss: 1.7586544200938234

Epoch: 6| Step: 9
Training loss: 1.6358541250228882
Validation loss: 1.7954237486726494

Epoch: 6| Step: 10
Training loss: 1.7169734239578247
Validation loss: 1.7941796497632099

Epoch: 6| Step: 11
Training loss: 1.585067629814148
Validation loss: 1.8134645877345916

Epoch: 6| Step: 12
Training loss: 0.5061066150665283
Validation loss: 1.799020915903071

Epoch: 6| Step: 13
Training loss: 1.3240031003952026
Validation loss: 1.8378253675276233

Epoch: 323| Step: 0
Training loss: 1.4404520988464355
Validation loss: 1.8218135590194373

Epoch: 6| Step: 1
Training loss: 1.7146711349487305
Validation loss: 1.8552015571184055

Epoch: 6| Step: 2
Training loss: 1.7121104001998901
Validation loss: 1.8452248163120721

Epoch: 6| Step: 3
Training loss: 1.6682510375976562
Validation loss: 1.8591544640961515

Epoch: 6| Step: 4
Training loss: 1.0145374536514282
Validation loss: 1.853413648502801

Epoch: 6| Step: 5
Training loss: 1.5241882801055908
Validation loss: 1.8066421401116155

Epoch: 6| Step: 6
Training loss: 1.2777583599090576
Validation loss: 1.8738094209342875

Epoch: 6| Step: 7
Training loss: 1.330875039100647
Validation loss: 1.8563722205418411

Epoch: 6| Step: 8
Training loss: 1.4454200267791748
Validation loss: 1.839058353054908

Epoch: 6| Step: 9
Training loss: 0.7985520958900452
Validation loss: 1.7714412135462607

Epoch: 6| Step: 10
Training loss: 1.4704393148422241
Validation loss: 1.791436190246254

Epoch: 6| Step: 11
Training loss: 1.7733750343322754
Validation loss: 1.8278398052338631

Epoch: 6| Step: 12
Training loss: 1.529968023300171
Validation loss: 1.7849665303384104

Epoch: 6| Step: 13
Training loss: 1.2945427894592285
Validation loss: 1.8257225764695035

Epoch: 324| Step: 0
Training loss: 1.397517442703247
Validation loss: 1.8034763797636955

Epoch: 6| Step: 1
Training loss: 1.94988214969635
Validation loss: 1.8143097251974127

Epoch: 6| Step: 2
Training loss: 2.0025296211242676
Validation loss: 1.7746724826033398

Epoch: 6| Step: 3
Training loss: 1.600407600402832
Validation loss: 1.7905621810625958

Epoch: 6| Step: 4
Training loss: 0.6853811740875244
Validation loss: 1.7892066022401214

Epoch: 6| Step: 5
Training loss: 1.9302215576171875
Validation loss: 1.7622746549626833

Epoch: 6| Step: 6
Training loss: 1.5608456134796143
Validation loss: 1.776870543597847

Epoch: 6| Step: 7
Training loss: 1.223718523979187
Validation loss: 1.7762710689216532

Epoch: 6| Step: 8
Training loss: 1.4236204624176025
Validation loss: 1.8145201449753137

Epoch: 6| Step: 9
Training loss: 1.8686444759368896
Validation loss: 1.8091197449673888

Epoch: 6| Step: 10
Training loss: 1.213277816772461
Validation loss: 1.8139093870757728

Epoch: 6| Step: 11
Training loss: 0.8293229341506958
Validation loss: 1.777755896250407

Epoch: 6| Step: 12
Training loss: 1.274645209312439
Validation loss: 1.7817965604925667

Epoch: 6| Step: 13
Training loss: 0.7774819731712341
Validation loss: 1.8310628667954476

Epoch: 325| Step: 0
Training loss: 1.0676099061965942
Validation loss: 1.7891791943580873

Epoch: 6| Step: 1
Training loss: 1.4618396759033203
Validation loss: 1.8339101499126804

Epoch: 6| Step: 2
Training loss: 1.7061760425567627
Validation loss: 1.8076130549112956

Epoch: 6| Step: 3
Training loss: 1.8596580028533936
Validation loss: 1.8191472189400786

Epoch: 6| Step: 4
Training loss: 1.392004370689392
Validation loss: 1.816996052700986

Epoch: 6| Step: 5
Training loss: 0.9511683583259583
Validation loss: 1.7834080675596833

Epoch: 6| Step: 6
Training loss: 1.2451039552688599
Validation loss: 1.8549475118678103

Epoch: 6| Step: 7
Training loss: 1.3885997533798218
Validation loss: 1.7959759337927705

Epoch: 6| Step: 8
Training loss: 1.143834114074707
Validation loss: 1.8711699760088356

Epoch: 6| Step: 9
Training loss: 1.6124231815338135
Validation loss: 1.8287052544214393

Epoch: 6| Step: 10
Training loss: 1.9164046049118042
Validation loss: 1.811492593057694

Epoch: 6| Step: 11
Training loss: 1.6489499807357788
Validation loss: 1.8179082139845817

Epoch: 6| Step: 12
Training loss: 1.0839617252349854
Validation loss: 1.843729983093918

Epoch: 6| Step: 13
Training loss: 1.4704418182373047
Validation loss: 1.8244703405646867

Epoch: 326| Step: 0
Training loss: 0.8677244186401367
Validation loss: 1.7903740623945832

Epoch: 6| Step: 1
Training loss: 0.8714450597763062
Validation loss: 1.8038339371322303

Epoch: 6| Step: 2
Training loss: 1.9017988443374634
Validation loss: 1.8118746331942979

Epoch: 6| Step: 3
Training loss: 1.1111233234405518
Validation loss: 1.8349893528928038

Epoch: 6| Step: 4
Training loss: 1.5360783338546753
Validation loss: 1.7962764873299548

Epoch: 6| Step: 5
Training loss: 1.2264900207519531
Validation loss: 1.787032950309015

Epoch: 6| Step: 6
Training loss: 1.6348397731781006
Validation loss: 1.8039809439771919

Epoch: 6| Step: 7
Training loss: 1.3143929243087769
Validation loss: 1.810131654944471

Epoch: 6| Step: 8
Training loss: 2.0850586891174316
Validation loss: 1.7603284210287116

Epoch: 6| Step: 9
Training loss: 1.0608614683151245
Validation loss: 1.8120321009748726

Epoch: 6| Step: 10
Training loss: 2.067953109741211
Validation loss: 1.7851195796843498

Epoch: 6| Step: 11
Training loss: 1.5406739711761475
Validation loss: 1.8202977385572208

Epoch: 6| Step: 12
Training loss: 1.2546744346618652
Validation loss: 1.7621576119494695

Epoch: 6| Step: 13
Training loss: 1.3348312377929688
Validation loss: 1.8304927861818703

Epoch: 327| Step: 0
Training loss: 2.009772300720215
Validation loss: 1.7954610637439194

Epoch: 6| Step: 1
Training loss: 1.5158191919326782
Validation loss: 1.8117864183200303

Epoch: 6| Step: 2
Training loss: 1.5985451936721802
Validation loss: 1.8574844739770378

Epoch: 6| Step: 3
Training loss: 1.1691426038742065
Validation loss: 1.8607693590143675

Epoch: 6| Step: 4
Training loss: 1.252846121788025
Validation loss: 1.8564961366755988

Epoch: 6| Step: 5
Training loss: 1.4097487926483154
Validation loss: 1.8422510418840634

Epoch: 6| Step: 6
Training loss: 1.5434273481369019
Validation loss: 1.813963936221215

Epoch: 6| Step: 7
Training loss: 1.9868361949920654
Validation loss: 1.8139469597929267

Epoch: 6| Step: 8
Training loss: 1.3469669818878174
Validation loss: 1.8617865898275887

Epoch: 6| Step: 9
Training loss: 0.7008795738220215
Validation loss: 1.793465760446364

Epoch: 6| Step: 10
Training loss: 2.2968173027038574
Validation loss: 1.7988985251354914

Epoch: 6| Step: 11
Training loss: 0.9012513756752014
Validation loss: 1.8053242493701238

Epoch: 6| Step: 12
Training loss: 1.6186044216156006
Validation loss: 1.803476390018258

Epoch: 6| Step: 13
Training loss: 0.8456604480743408
Validation loss: 1.770016816354567

Epoch: 328| Step: 0
Training loss: 1.020277500152588
Validation loss: 1.7894283187004827

Epoch: 6| Step: 1
Training loss: 1.2301013469696045
Validation loss: 1.8559363862519622

Epoch: 6| Step: 2
Training loss: 1.7757948637008667
Validation loss: 1.7801244540881085

Epoch: 6| Step: 3
Training loss: 1.0827034711837769
Validation loss: 1.7945297815466439

Epoch: 6| Step: 4
Training loss: 1.182511329650879
Validation loss: 1.8016084522329352

Epoch: 6| Step: 5
Training loss: 1.8277084827423096
Validation loss: 1.8488094037578953

Epoch: 6| Step: 6
Training loss: 1.158968210220337
Validation loss: 1.835188195269595

Epoch: 6| Step: 7
Training loss: 1.2551020383834839
Validation loss: 1.8132850700809109

Epoch: 6| Step: 8
Training loss: 1.4641132354736328
Validation loss: 1.833016400696129

Epoch: 6| Step: 9
Training loss: 1.5452728271484375
Validation loss: 1.8003560420005553

Epoch: 6| Step: 10
Training loss: 1.9361557960510254
Validation loss: 1.8012352425565001

Epoch: 6| Step: 11
Training loss: 1.2130444049835205
Validation loss: 1.8506555403432539

Epoch: 6| Step: 12
Training loss: 1.4140983819961548
Validation loss: 1.8301467177688435

Epoch: 6| Step: 13
Training loss: 1.2368360757827759
Validation loss: 1.8395574605593117

Epoch: 329| Step: 0
Training loss: 1.9470973014831543
Validation loss: 1.790887007149317

Epoch: 6| Step: 1
Training loss: 1.6475673913955688
Validation loss: 1.812503900579227

Epoch: 6| Step: 2
Training loss: 1.3818823099136353
Validation loss: 1.819718905674514

Epoch: 6| Step: 3
Training loss: 1.4912116527557373
Validation loss: 1.7925279948019213

Epoch: 6| Step: 4
Training loss: 1.1329536437988281
Validation loss: 1.832604444155129

Epoch: 6| Step: 5
Training loss: 1.0830148458480835
Validation loss: 1.8302132852615849

Epoch: 6| Step: 6
Training loss: 1.8689770698547363
Validation loss: 1.8132177706687682

Epoch: 6| Step: 7
Training loss: 1.6996338367462158
Validation loss: 1.8254272771138016

Epoch: 6| Step: 8
Training loss: 2.1097187995910645
Validation loss: 1.8327155510584514

Epoch: 6| Step: 9
Training loss: 1.2757500410079956
Validation loss: 1.8208937029684744

Epoch: 6| Step: 10
Training loss: 0.9596314430236816
Validation loss: 1.8166206934118783

Epoch: 6| Step: 11
Training loss: 0.9359742999076843
Validation loss: 1.862499334478891

Epoch: 6| Step: 12
Training loss: 0.8941565752029419
Validation loss: 1.8241246989978257

Epoch: 6| Step: 13
Training loss: 0.9576855897903442
Validation loss: 1.8363128413436234

Epoch: 330| Step: 0
Training loss: 1.2007821798324585
Validation loss: 1.847610519778344

Epoch: 6| Step: 1
Training loss: 1.5598716735839844
Validation loss: 1.8443131459656583

Epoch: 6| Step: 2
Training loss: 2.5008578300476074
Validation loss: 1.8041587875735374

Epoch: 6| Step: 3
Training loss: 1.486253023147583
Validation loss: 1.8299697073557044

Epoch: 6| Step: 4
Training loss: 1.7204537391662598
Validation loss: 1.795223779575799

Epoch: 6| Step: 5
Training loss: 0.9430240988731384
Validation loss: 1.791136239164619

Epoch: 6| Step: 6
Training loss: 1.1280391216278076
Validation loss: 1.8157997977349065

Epoch: 6| Step: 7
Training loss: 1.2256605625152588
Validation loss: 1.8402615631780317

Epoch: 6| Step: 8
Training loss: 1.3555569648742676
Validation loss: 1.8040559689203899

Epoch: 6| Step: 9
Training loss: 1.556484341621399
Validation loss: 1.7884977299679992

Epoch: 6| Step: 10
Training loss: 1.8234195709228516
Validation loss: 1.8306612596716931

Epoch: 6| Step: 11
Training loss: 0.9534302949905396
Validation loss: 1.7937021011947303

Epoch: 6| Step: 12
Training loss: 1.3050172328948975
Validation loss: 1.772769049931598

Epoch: 6| Step: 13
Training loss: 0.9562424421310425
Validation loss: 1.7984774189610635

Epoch: 331| Step: 0
Training loss: 1.0409096479415894
Validation loss: 1.8145512432180426

Epoch: 6| Step: 1
Training loss: 0.9485432505607605
Validation loss: 1.7931254012610323

Epoch: 6| Step: 2
Training loss: 1.2453396320343018
Validation loss: 1.8162573614428121

Epoch: 6| Step: 3
Training loss: 2.1436853408813477
Validation loss: 1.8603364677839382

Epoch: 6| Step: 4
Training loss: 1.4471222162246704
Validation loss: 1.8127077266734133

Epoch: 6| Step: 5
Training loss: 1.4973292350769043
Validation loss: 1.8002575328273158

Epoch: 6| Step: 6
Training loss: 1.211792230606079
Validation loss: 1.8345306419557141

Epoch: 6| Step: 7
Training loss: 1.260486364364624
Validation loss: 1.813112615257181

Epoch: 6| Step: 8
Training loss: 1.1298727989196777
Validation loss: 1.8476310981217252

Epoch: 6| Step: 9
Training loss: 2.0190091133117676
Validation loss: 1.8157067939799318

Epoch: 6| Step: 10
Training loss: 1.0680813789367676
Validation loss: 1.8343941191191315

Epoch: 6| Step: 11
Training loss: 1.5867745876312256
Validation loss: 1.8074588980726016

Epoch: 6| Step: 12
Training loss: 1.2069355249404907
Validation loss: 1.8192622225771669

Epoch: 6| Step: 13
Training loss: 1.5971431732177734
Validation loss: 1.8534025146115212

Epoch: 332| Step: 0
Training loss: 1.275946021080017
Validation loss: 1.822522126218324

Epoch: 6| Step: 1
Training loss: 1.639932632446289
Validation loss: 1.811291742068465

Epoch: 6| Step: 2
Training loss: 1.3188875913619995
Validation loss: 1.814698890973163

Epoch: 6| Step: 3
Training loss: 1.5074639320373535
Validation loss: 1.7822734130326139

Epoch: 6| Step: 4
Training loss: 1.2723886966705322
Validation loss: 1.8312659391792871

Epoch: 6| Step: 5
Training loss: 1.9159706830978394
Validation loss: 1.7793350835000314

Epoch: 6| Step: 6
Training loss: 1.139189600944519
Validation loss: 1.7944419384002686

Epoch: 6| Step: 7
Training loss: 1.5491931438446045
Validation loss: 1.7863742587386922

Epoch: 6| Step: 8
Training loss: 0.8635243773460388
Validation loss: 1.8016734225775606

Epoch: 6| Step: 9
Training loss: 1.2628021240234375
Validation loss: 1.7813683440608363

Epoch: 6| Step: 10
Training loss: 1.680356502532959
Validation loss: 1.8004637008072228

Epoch: 6| Step: 11
Training loss: 1.2705004215240479
Validation loss: 1.8010473789707306

Epoch: 6| Step: 12
Training loss: 1.1823647022247314
Validation loss: 1.7865869601567586

Epoch: 6| Step: 13
Training loss: 1.9360626935958862
Validation loss: 1.7876118293372534

Epoch: 333| Step: 0
Training loss: 1.2797037363052368
Validation loss: 1.8204788443862752

Epoch: 6| Step: 1
Training loss: 1.590517520904541
Validation loss: 1.8249994426645257

Epoch: 6| Step: 2
Training loss: 1.1910886764526367
Validation loss: 1.8254412399825228

Epoch: 6| Step: 3
Training loss: 0.7974171042442322
Validation loss: 1.8010159730911255

Epoch: 6| Step: 4
Training loss: 1.2072440385818481
Validation loss: 1.8837628915745726

Epoch: 6| Step: 5
Training loss: 0.6100029945373535
Validation loss: 1.8141404864608601

Epoch: 6| Step: 6
Training loss: 1.5355937480926514
Validation loss: 1.8154303591738465

Epoch: 6| Step: 7
Training loss: 1.6534345149993896
Validation loss: 1.7764827218106998

Epoch: 6| Step: 8
Training loss: 0.7840868234634399
Validation loss: 1.7945489306603708

Epoch: 6| Step: 9
Training loss: 1.6801563501358032
Validation loss: 1.8078624509995984

Epoch: 6| Step: 10
Training loss: 1.5919287204742432
Validation loss: 1.7933710082884757

Epoch: 6| Step: 11
Training loss: 2.2762584686279297
Validation loss: 1.8149936814461984

Epoch: 6| Step: 12
Training loss: 1.7129311561584473
Validation loss: 1.8397299756285965

Epoch: 6| Step: 13
Training loss: 1.3492217063903809
Validation loss: 1.807201644425751

Epoch: 334| Step: 0
Training loss: 1.8278461694717407
Validation loss: 1.8058484087708175

Epoch: 6| Step: 1
Training loss: 1.177358627319336
Validation loss: 1.8519821115719375

Epoch: 6| Step: 2
Training loss: 0.8632833957672119
Validation loss: 1.813020146021279

Epoch: 6| Step: 3
Training loss: 1.8394417762756348
Validation loss: 1.8042939952624741

Epoch: 6| Step: 4
Training loss: 1.2631101608276367
Validation loss: 1.807167758223831

Epoch: 6| Step: 5
Training loss: 1.4434723854064941
Validation loss: 1.7799954927095802

Epoch: 6| Step: 6
Training loss: 1.3449324369430542
Validation loss: 1.8460709100128503

Epoch: 6| Step: 7
Training loss: 1.4269227981567383
Validation loss: 1.8411641313183693

Epoch: 6| Step: 8
Training loss: 1.2458140850067139
Validation loss: 1.7777273116573211

Epoch: 6| Step: 9
Training loss: 1.2170755863189697
Validation loss: 1.8196873126491424

Epoch: 6| Step: 10
Training loss: 0.9306454062461853
Validation loss: 1.8315238965454923

Epoch: 6| Step: 11
Training loss: 1.5672005414962769
Validation loss: 1.836422602335612

Epoch: 6| Step: 12
Training loss: 1.7648640871047974
Validation loss: 1.787630747723323

Epoch: 6| Step: 13
Training loss: 1.4913796186447144
Validation loss: 1.7785443080368863

Epoch: 335| Step: 0
Training loss: 1.061010718345642
Validation loss: 1.8120956177352576

Epoch: 6| Step: 1
Training loss: 2.3490796089172363
Validation loss: 1.84180183692645

Epoch: 6| Step: 2
Training loss: 1.0980817079544067
Validation loss: 1.8187620665437432

Epoch: 6| Step: 3
Training loss: 1.0684089660644531
Validation loss: 1.7789714977305422

Epoch: 6| Step: 4
Training loss: 1.4713701009750366
Validation loss: 1.7987559469797278

Epoch: 6| Step: 5
Training loss: 1.3113105297088623
Validation loss: 1.819920216837237

Epoch: 6| Step: 6
Training loss: 1.5551543235778809
Validation loss: 1.8207696201980754

Epoch: 6| Step: 7
Training loss: 1.2389137744903564
Validation loss: 1.822943405438495

Epoch: 6| Step: 8
Training loss: 0.9762945771217346
Validation loss: 1.7859154811469458

Epoch: 6| Step: 9
Training loss: 1.3429808616638184
Validation loss: 1.8035508266059301

Epoch: 6| Step: 10
Training loss: 1.2783019542694092
Validation loss: 1.791618521495532

Epoch: 6| Step: 11
Training loss: 2.038024663925171
Validation loss: 1.8114479998106598

Epoch: 6| Step: 12
Training loss: 1.5476890802383423
Validation loss: 1.7877468601349862

Epoch: 6| Step: 13
Training loss: 1.385191559791565
Validation loss: 1.8211457434520926

Epoch: 336| Step: 0
Training loss: 1.500368356704712
Validation loss: 1.803646860584136

Epoch: 6| Step: 1
Training loss: 1.031266689300537
Validation loss: 1.839126116486006

Epoch: 6| Step: 2
Training loss: 1.2410032749176025
Validation loss: 1.8407173772012033

Epoch: 6| Step: 3
Training loss: 1.6839057207107544
Validation loss: 1.8341015615770895

Epoch: 6| Step: 4
Training loss: 1.6067386865615845
Validation loss: 1.8717858932351554

Epoch: 6| Step: 5
Training loss: 1.4904711246490479
Validation loss: 1.8731795075119182

Epoch: 6| Step: 6
Training loss: 1.3433945178985596
Validation loss: 1.8659677454220351

Epoch: 6| Step: 7
Training loss: 1.319252848625183
Validation loss: 1.8756781393481838

Epoch: 6| Step: 8
Training loss: 0.6410945653915405
Validation loss: 1.8786953008303078

Epoch: 6| Step: 9
Training loss: 0.7329047322273254
Validation loss: 1.842953937028044

Epoch: 6| Step: 10
Training loss: 1.8076400756835938
Validation loss: 1.8638547235919583

Epoch: 6| Step: 11
Training loss: 1.5855329036712646
Validation loss: 1.8161538493248723

Epoch: 6| Step: 12
Training loss: 1.9618223905563354
Validation loss: 1.8199529724736367

Epoch: 6| Step: 13
Training loss: 1.765440583229065
Validation loss: 1.8316224390460598

Epoch: 337| Step: 0
Training loss: 1.2414520978927612
Validation loss: 1.771723824162637

Epoch: 6| Step: 1
Training loss: 1.091306209564209
Validation loss: 1.7943859587433517

Epoch: 6| Step: 2
Training loss: 1.0100058317184448
Validation loss: 1.8062725515775784

Epoch: 6| Step: 3
Training loss: 1.1757134199142456
Validation loss: 1.8408709085115822

Epoch: 6| Step: 4
Training loss: 1.6365200281143188
Validation loss: 1.797034396920153

Epoch: 6| Step: 5
Training loss: 1.4767872095108032
Validation loss: 1.7910873813013877

Epoch: 6| Step: 6
Training loss: 1.9000146389007568
Validation loss: 1.8048752469401206

Epoch: 6| Step: 7
Training loss: 2.029474973678589
Validation loss: 1.7747414163363877

Epoch: 6| Step: 8
Training loss: 1.3014453649520874
Validation loss: 1.833008167564228

Epoch: 6| Step: 9
Training loss: 1.2629774808883667
Validation loss: 1.7791622684847923

Epoch: 6| Step: 10
Training loss: 0.5605563521385193
Validation loss: 1.7999517712541806

Epoch: 6| Step: 11
Training loss: 1.5770244598388672
Validation loss: 1.838744241704223

Epoch: 6| Step: 12
Training loss: 1.373378038406372
Validation loss: 1.8226427621738885

Epoch: 6| Step: 13
Training loss: 1.6294732093811035
Validation loss: 1.8148535656672653

Epoch: 338| Step: 0
Training loss: 1.0319883823394775
Validation loss: 1.7565122432606195

Epoch: 6| Step: 1
Training loss: 1.5342786312103271
Validation loss: 1.8344554542213358

Epoch: 6| Step: 2
Training loss: 1.5215651988983154
Validation loss: 1.8320033780990108

Epoch: 6| Step: 3
Training loss: 1.5289971828460693
Validation loss: 1.815187092750303

Epoch: 6| Step: 4
Training loss: 1.4326307773590088
Validation loss: 1.849053398255379

Epoch: 6| Step: 5
Training loss: 1.2488632202148438
Validation loss: 1.8274011535029258

Epoch: 6| Step: 6
Training loss: 0.8491863012313843
Validation loss: 1.8229120674953665

Epoch: 6| Step: 7
Training loss: 1.1879527568817139
Validation loss: 1.8435982606744254

Epoch: 6| Step: 8
Training loss: 1.3477890491485596
Validation loss: 1.7965969834276425

Epoch: 6| Step: 9
Training loss: 1.5121039152145386
Validation loss: 1.8252663381638066

Epoch: 6| Step: 10
Training loss: 1.2532161474227905
Validation loss: 1.806630672947053

Epoch: 6| Step: 11
Training loss: 1.9900598526000977
Validation loss: 1.828019775370116

Epoch: 6| Step: 12
Training loss: 1.479081392288208
Validation loss: 1.8071295369055964

Epoch: 6| Step: 13
Training loss: 1.3049142360687256
Validation loss: 1.8111504431693786

Epoch: 339| Step: 0
Training loss: 1.4706249237060547
Validation loss: 1.8050001821210306

Epoch: 6| Step: 1
Training loss: 1.6782432794570923
Validation loss: 1.8197176789724698

Epoch: 6| Step: 2
Training loss: 1.8037583827972412
Validation loss: 1.8131697280432588

Epoch: 6| Step: 3
Training loss: 0.9546177983283997
Validation loss: 1.7998350948415778

Epoch: 6| Step: 4
Training loss: 1.4642565250396729
Validation loss: 1.8215141809114845

Epoch: 6| Step: 5
Training loss: 1.6516144275665283
Validation loss: 1.8219189323404783

Epoch: 6| Step: 6
Training loss: 1.323707938194275
Validation loss: 1.8918297085710751

Epoch: 6| Step: 7
Training loss: 1.5459954738616943
Validation loss: 1.8345271695044734

Epoch: 6| Step: 8
Training loss: 1.2798742055892944
Validation loss: 1.8366767770500594

Epoch: 6| Step: 9
Training loss: 1.433712363243103
Validation loss: 1.8530588124388008

Epoch: 6| Step: 10
Training loss: 1.3395048379898071
Validation loss: 1.889379750015915

Epoch: 6| Step: 11
Training loss: 1.1081842184066772
Validation loss: 1.8805535916359193

Epoch: 6| Step: 12
Training loss: 1.6403791904449463
Validation loss: 1.8518904486010153

Epoch: 6| Step: 13
Training loss: 0.8671652674674988
Validation loss: 1.80662606223937

Epoch: 340| Step: 0
Training loss: 1.5863051414489746
Validation loss: 1.838811602643741

Epoch: 6| Step: 1
Training loss: 1.1031875610351562
Validation loss: 1.800298419049991

Epoch: 6| Step: 2
Training loss: 1.033294677734375
Validation loss: 1.8231168408547678

Epoch: 6| Step: 3
Training loss: 1.2411210536956787
Validation loss: 1.789364767330949

Epoch: 6| Step: 4
Training loss: 1.5883781909942627
Validation loss: 1.7956495438852618

Epoch: 6| Step: 5
Training loss: 1.2795779705047607
Validation loss: 1.8224906254840154

Epoch: 6| Step: 6
Training loss: 1.2136785984039307
Validation loss: 1.8153387192756898

Epoch: 6| Step: 7
Training loss: 1.6581664085388184
Validation loss: 1.8084368885204356

Epoch: 6| Step: 8
Training loss: 1.8072576522827148
Validation loss: 1.8338151747180569

Epoch: 6| Step: 9
Training loss: 1.408300518989563
Validation loss: 1.7858507684482041

Epoch: 6| Step: 10
Training loss: 1.37125563621521
Validation loss: 1.8045591756861696

Epoch: 6| Step: 11
Training loss: 1.0991957187652588
Validation loss: 1.783414206197185

Epoch: 6| Step: 12
Training loss: 1.2360601425170898
Validation loss: 1.8048306331839612

Epoch: 6| Step: 13
Training loss: 1.2265596389770508
Validation loss: 1.8099395587880125

Epoch: 341| Step: 0
Training loss: 1.6297918558120728
Validation loss: 1.7800187769756521

Epoch: 6| Step: 1
Training loss: 1.2028944492340088
Validation loss: 1.806974393706168

Epoch: 6| Step: 2
Training loss: 0.9255475997924805
Validation loss: 1.8337062340910717

Epoch: 6| Step: 3
Training loss: 0.9805819988250732
Validation loss: 1.8529357038518435

Epoch: 6| Step: 4
Training loss: 1.440924882888794
Validation loss: 1.8650762945093133

Epoch: 6| Step: 5
Training loss: 1.7481030225753784
Validation loss: 1.8237182286477858

Epoch: 6| Step: 6
Training loss: 1.5299476385116577
Validation loss: 1.8193455690978675

Epoch: 6| Step: 7
Training loss: 1.3814725875854492
Validation loss: 1.7886911015356741

Epoch: 6| Step: 8
Training loss: 0.9066885113716125
Validation loss: 1.815601138658421

Epoch: 6| Step: 9
Training loss: 1.5944887399673462
Validation loss: 1.7802770740242415

Epoch: 6| Step: 10
Training loss: 1.6211352348327637
Validation loss: 1.8026575965266074

Epoch: 6| Step: 11
Training loss: 1.1792091131210327
Validation loss: 1.7313966507552772

Epoch: 6| Step: 12
Training loss: 1.644315481185913
Validation loss: 1.8232573360525153

Epoch: 6| Step: 13
Training loss: 1.4994909763336182
Validation loss: 1.8049170483825028

Epoch: 342| Step: 0
Training loss: 1.4898358583450317
Validation loss: 1.7867750621611072

Epoch: 6| Step: 1
Training loss: 1.2395482063293457
Validation loss: 1.8116462230682373

Epoch: 6| Step: 2
Training loss: 1.238937258720398
Validation loss: 1.802519295805244

Epoch: 6| Step: 3
Training loss: 1.5056955814361572
Validation loss: 1.8198529597251647

Epoch: 6| Step: 4
Training loss: 1.6524553298950195
Validation loss: 1.7835520223904682

Epoch: 6| Step: 5
Training loss: 0.7176693677902222
Validation loss: 1.805090860653949

Epoch: 6| Step: 6
Training loss: 1.4873123168945312
Validation loss: 1.833311471887814

Epoch: 6| Step: 7
Training loss: 1.8007978200912476
Validation loss: 1.8322335955917195

Epoch: 6| Step: 8
Training loss: 1.2411308288574219
Validation loss: 1.8210226271742134

Epoch: 6| Step: 9
Training loss: 1.0632169246673584
Validation loss: 1.792615185501755

Epoch: 6| Step: 10
Training loss: 1.3293142318725586
Validation loss: 1.8299300747532998

Epoch: 6| Step: 11
Training loss: 1.3473972082138062
Validation loss: 1.7928009187021563

Epoch: 6| Step: 12
Training loss: 1.3754441738128662
Validation loss: 1.8177989503388763

Epoch: 6| Step: 13
Training loss: 1.8117408752441406
Validation loss: 1.8128866841716151

Epoch: 343| Step: 0
Training loss: 1.8187490701675415
Validation loss: 1.7854474975216774

Epoch: 6| Step: 1
Training loss: 0.9155255556106567
Validation loss: 1.787871209524011

Epoch: 6| Step: 2
Training loss: 1.025048017501831
Validation loss: 1.7815950788477415

Epoch: 6| Step: 3
Training loss: 1.5049843788146973
Validation loss: 1.844407881459882

Epoch: 6| Step: 4
Training loss: 1.1486268043518066
Validation loss: 1.7929540731573617

Epoch: 6| Step: 5
Training loss: 1.5293455123901367
Validation loss: 1.797050058200795

Epoch: 6| Step: 6
Training loss: 0.7197904586791992
Validation loss: 1.8138859195093955

Epoch: 6| Step: 7
Training loss: 1.549108624458313
Validation loss: 1.8600939909617107

Epoch: 6| Step: 8
Training loss: 1.0323338508605957
Validation loss: 1.797737088254703

Epoch: 6| Step: 9
Training loss: 1.8392276763916016
Validation loss: 1.8137084348227388

Epoch: 6| Step: 10
Training loss: 1.6649072170257568
Validation loss: 1.8292165969007759

Epoch: 6| Step: 11
Training loss: 1.6119319200515747
Validation loss: 1.8244594707283923

Epoch: 6| Step: 12
Training loss: 1.659076452255249
Validation loss: 1.8211215273026498

Epoch: 6| Step: 13
Training loss: 1.1366639137268066
Validation loss: 1.8119203377795476

Epoch: 344| Step: 0
Training loss: 0.8101279735565186
Validation loss: 1.7895880181302306

Epoch: 6| Step: 1
Training loss: 1.1013555526733398
Validation loss: 1.852317548567249

Epoch: 6| Step: 2
Training loss: 1.4827121496200562
Validation loss: 1.7774246482438938

Epoch: 6| Step: 3
Training loss: 2.0485575199127197
Validation loss: 1.8368649213544783

Epoch: 6| Step: 4
Training loss: 2.1219401359558105
Validation loss: 1.844701144003099

Epoch: 6| Step: 5
Training loss: 1.0508549213409424
Validation loss: 1.7921340939819173

Epoch: 6| Step: 6
Training loss: 1.2303333282470703
Validation loss: 1.8078128637806061

Epoch: 6| Step: 7
Training loss: 1.3710166215896606
Validation loss: 1.800569438165234

Epoch: 6| Step: 8
Training loss: 1.3953639268875122
Validation loss: 1.7760478668315436

Epoch: 6| Step: 9
Training loss: 1.1380212306976318
Validation loss: 1.840210868466285

Epoch: 6| Step: 10
Training loss: 0.830780029296875
Validation loss: 1.838123361269633

Epoch: 6| Step: 11
Training loss: 1.0759302377700806
Validation loss: 1.7917352273900022

Epoch: 6| Step: 12
Training loss: 1.6524338722229004
Validation loss: 1.7749018156400291

Epoch: 6| Step: 13
Training loss: 2.2741498947143555
Validation loss: 1.8126201475820234

Epoch: 345| Step: 0
Training loss: 0.8127410411834717
Validation loss: 1.7594563755937802

Epoch: 6| Step: 1
Training loss: 1.5403952598571777
Validation loss: 1.78256699603091

Epoch: 6| Step: 2
Training loss: 1.0580122470855713
Validation loss: 1.805412797517674

Epoch: 6| Step: 3
Training loss: 1.7268974781036377
Validation loss: 1.8322297373125631

Epoch: 6| Step: 4
Training loss: 1.4641236066818237
Validation loss: 1.7938070950969573

Epoch: 6| Step: 5
Training loss: 0.9556567072868347
Validation loss: 1.8609799185106832

Epoch: 6| Step: 6
Training loss: 1.4441074132919312
Validation loss: 1.8320593321195213

Epoch: 6| Step: 7
Training loss: 1.6534289121627808
Validation loss: 1.7797225906002907

Epoch: 6| Step: 8
Training loss: 1.2576186656951904
Validation loss: 1.848323029856528

Epoch: 6| Step: 9
Training loss: 1.1196863651275635
Validation loss: 1.8095758602183352

Epoch: 6| Step: 10
Training loss: 1.707763671875
Validation loss: 1.817893051332043

Epoch: 6| Step: 11
Training loss: 1.852239727973938
Validation loss: 1.8241958348981795

Epoch: 6| Step: 12
Training loss: 1.46822190284729
Validation loss: 1.7932251896909488

Epoch: 6| Step: 13
Training loss: 0.41622310876846313
Validation loss: 1.8248407148545789

Epoch: 346| Step: 0
Training loss: 1.4820895195007324
Validation loss: 1.8178539917033205

Epoch: 6| Step: 1
Training loss: 1.5051933526992798
Validation loss: 1.8320730322150773

Epoch: 6| Step: 2
Training loss: 1.0686390399932861
Validation loss: 1.8258066459368634

Epoch: 6| Step: 3
Training loss: 1.3433845043182373
Validation loss: 1.7801545871201383

Epoch: 6| Step: 4
Training loss: 1.7577335834503174
Validation loss: 1.7830581177947342

Epoch: 6| Step: 5
Training loss: 1.0586040019989014
Validation loss: 1.783131666080926

Epoch: 6| Step: 6
Training loss: 1.5467586517333984
Validation loss: 1.8011395431333972

Epoch: 6| Step: 7
Training loss: 1.3205569982528687
Validation loss: 1.8139383613422353

Epoch: 6| Step: 8
Training loss: 1.0420809984207153
Validation loss: 1.8061780878292617

Epoch: 6| Step: 9
Training loss: 1.350361943244934
Validation loss: 1.865222172070575

Epoch: 6| Step: 10
Training loss: 1.6936984062194824
Validation loss: 1.8580492363181165

Epoch: 6| Step: 11
Training loss: 1.2704616785049438
Validation loss: 1.848765879549006

Epoch: 6| Step: 12
Training loss: 1.0771095752716064
Validation loss: 1.8638441357561337

Epoch: 6| Step: 13
Training loss: 1.8555344343185425
Validation loss: 1.8319658476819274

Epoch: 347| Step: 0
Training loss: 1.3579527139663696
Validation loss: 1.8590910127086024

Epoch: 6| Step: 1
Training loss: 1.802560806274414
Validation loss: 1.855811909962726

Epoch: 6| Step: 2
Training loss: 1.2786383628845215
Validation loss: 1.8056440930212698

Epoch: 6| Step: 3
Training loss: 0.9103670120239258
Validation loss: 1.8106995141634377

Epoch: 6| Step: 4
Training loss: 1.760725498199463
Validation loss: 1.8040586748430807

Epoch: 6| Step: 5
Training loss: 1.467736005783081
Validation loss: 1.8249042252058625

Epoch: 6| Step: 6
Training loss: 1.025705337524414
Validation loss: 1.7776606698190012

Epoch: 6| Step: 7
Training loss: 1.6666429042816162
Validation loss: 1.8021646071505804

Epoch: 6| Step: 8
Training loss: 2.103421688079834
Validation loss: 1.8157270941683041

Epoch: 6| Step: 9
Training loss: 0.9338940978050232
Validation loss: 1.7632560678707656

Epoch: 6| Step: 10
Training loss: 1.0757139921188354
Validation loss: 1.7572024535107356

Epoch: 6| Step: 11
Training loss: 1.0658526420593262
Validation loss: 1.7949816744814637

Epoch: 6| Step: 12
Training loss: 1.0860780477523804
Validation loss: 1.8253723088131155

Epoch: 6| Step: 13
Training loss: 1.25630784034729
Validation loss: 1.8415973981221516

Epoch: 348| Step: 0
Training loss: 0.7127946615219116
Validation loss: 1.7862495273672125

Epoch: 6| Step: 1
Training loss: 1.2272313833236694
Validation loss: 1.7825253804524739

Epoch: 6| Step: 2
Training loss: 1.4435768127441406
Validation loss: 1.822736241484201

Epoch: 6| Step: 3
Training loss: 1.069153070449829
Validation loss: 1.800753064053033

Epoch: 6| Step: 4
Training loss: 1.1682500839233398
Validation loss: 1.8319037601511965

Epoch: 6| Step: 5
Training loss: 1.5579760074615479
Validation loss: 1.8649252973577028

Epoch: 6| Step: 6
Training loss: 1.5451581478118896
Validation loss: 1.8649615574908514

Epoch: 6| Step: 7
Training loss: 0.9404588937759399
Validation loss: 1.8267734909570346

Epoch: 6| Step: 8
Training loss: 1.5654327869415283
Validation loss: 1.8507116571549447

Epoch: 6| Step: 9
Training loss: 1.3503742218017578
Validation loss: 1.8551994574967252

Epoch: 6| Step: 10
Training loss: 2.042011260986328
Validation loss: 1.8266571362813313

Epoch: 6| Step: 11
Training loss: 1.8989248275756836
Validation loss: 1.846835397904919

Epoch: 6| Step: 12
Training loss: 0.715134859085083
Validation loss: 1.8286108393822946

Epoch: 6| Step: 13
Training loss: 1.401145100593567
Validation loss: 1.8222006495280931

Epoch: 349| Step: 0
Training loss: 1.4198652505874634
Validation loss: 1.777216806206652

Epoch: 6| Step: 1
Training loss: 1.2154510021209717
Validation loss: 1.8158898789395568

Epoch: 6| Step: 2
Training loss: 1.3626141548156738
Validation loss: 1.811497910048372

Epoch: 6| Step: 3
Training loss: 1.5447916984558105
Validation loss: 1.8039216738875195

Epoch: 6| Step: 4
Training loss: 1.5693726539611816
Validation loss: 1.7963549552425262

Epoch: 6| Step: 5
Training loss: 1.1424733400344849
Validation loss: 1.8085511794654272

Epoch: 6| Step: 6
Training loss: 1.1941808462142944
Validation loss: 1.7713624379968131

Epoch: 6| Step: 7
Training loss: 1.2444164752960205
Validation loss: 1.8305182508243028

Epoch: 6| Step: 8
Training loss: 1.286646842956543
Validation loss: 1.7805717119606592

Epoch: 6| Step: 9
Training loss: 1.420825719833374
Validation loss: 1.817586261739013

Epoch: 6| Step: 10
Training loss: 1.5930747985839844
Validation loss: 1.7930720083175167

Epoch: 6| Step: 11
Training loss: 1.370050072669983
Validation loss: 1.80100070276568

Epoch: 6| Step: 12
Training loss: 1.3394262790679932
Validation loss: 1.8020121064237369

Epoch: 6| Step: 13
Training loss: 1.3769068717956543
Validation loss: 1.8183707101370699

Epoch: 350| Step: 0
Training loss: 1.5923529863357544
Validation loss: 1.8000580239039596

Epoch: 6| Step: 1
Training loss: 1.2959022521972656
Validation loss: 1.8308217230663504

Epoch: 6| Step: 2
Training loss: 1.235260248184204
Validation loss: 1.7806374693429599

Epoch: 6| Step: 3
Training loss: 1.7367095947265625
Validation loss: 1.8113456785037954

Epoch: 6| Step: 4
Training loss: 1.4708062410354614
Validation loss: 1.8297588568861767

Epoch: 6| Step: 5
Training loss: 0.9229593873023987
Validation loss: 1.8191365144586051

Epoch: 6| Step: 6
Training loss: 1.2539185285568237
Validation loss: 1.8196129965525802

Epoch: 6| Step: 7
Training loss: 0.9218301773071289
Validation loss: 1.7685729854850358

Epoch: 6| Step: 8
Training loss: 1.6688597202301025
Validation loss: 1.8211381294394051

Epoch: 6| Step: 9
Training loss: 1.1246576309204102
Validation loss: 1.8535541795915174

Epoch: 6| Step: 10
Training loss: 1.546822190284729
Validation loss: 1.815049894394413

Epoch: 6| Step: 11
Training loss: 1.017198085784912
Validation loss: 1.8618581589832102

Epoch: 6| Step: 12
Training loss: 1.569411277770996
Validation loss: 1.8344766709112352

Epoch: 6| Step: 13
Training loss: 1.2312005758285522
Validation loss: 1.7741907950370543

Epoch: 351| Step: 0
Training loss: 0.9485745429992676
Validation loss: 1.84069029490153

Epoch: 6| Step: 1
Training loss: 1.7871956825256348
Validation loss: 1.7715624609301168

Epoch: 6| Step: 2
Training loss: 1.2864086627960205
Validation loss: 1.7996644845572851

Epoch: 6| Step: 3
Training loss: 0.9947570562362671
Validation loss: 1.8168491214834235

Epoch: 6| Step: 4
Training loss: 0.9739729762077332
Validation loss: 1.8312051680780226

Epoch: 6| Step: 5
Training loss: 2.068300724029541
Validation loss: 1.8023649697662683

Epoch: 6| Step: 6
Training loss: 0.9382771253585815
Validation loss: 1.8014875445314633

Epoch: 6| Step: 7
Training loss: 1.849159836769104
Validation loss: 1.7827578667671449

Epoch: 6| Step: 8
Training loss: 1.6397089958190918
Validation loss: 1.8024533410226145

Epoch: 6| Step: 9
Training loss: 1.2342722415924072
Validation loss: 1.75782532845774

Epoch: 6| Step: 10
Training loss: 1.1865007877349854
Validation loss: 1.8022585812435354

Epoch: 6| Step: 11
Training loss: 1.8261133432388306
Validation loss: 1.762122081812992

Epoch: 6| Step: 12
Training loss: 1.0177030563354492
Validation loss: 1.8004096528535247

Epoch: 6| Step: 13
Training loss: 0.7740797400474548
Validation loss: 1.814362831013177

Epoch: 352| Step: 0
Training loss: 1.7547820806503296
Validation loss: 1.76249986310159

Epoch: 6| Step: 1
Training loss: 1.7961057424545288
Validation loss: 1.8231626915675339

Epoch: 6| Step: 2
Training loss: 1.0589816570281982
Validation loss: 1.8764732114730343

Epoch: 6| Step: 3
Training loss: 1.2692924737930298
Validation loss: 1.8139356874650525

Epoch: 6| Step: 4
Training loss: 1.9680778980255127
Validation loss: 1.8456565346769107

Epoch: 6| Step: 5
Training loss: 0.851067066192627
Validation loss: 1.8620083934517317

Epoch: 6| Step: 6
Training loss: 1.7919962406158447
Validation loss: 1.867915056085074

Epoch: 6| Step: 7
Training loss: 1.7278368473052979
Validation loss: 1.8919314927952264

Epoch: 6| Step: 8
Training loss: 0.9002224206924438
Validation loss: 1.833451065965878

Epoch: 6| Step: 9
Training loss: 1.0982017517089844
Validation loss: 1.8281019041615147

Epoch: 6| Step: 10
Training loss: 1.5644193887710571
Validation loss: 1.8375385717679096

Epoch: 6| Step: 11
Training loss: 0.8027010560035706
Validation loss: 1.8474756081899006

Epoch: 6| Step: 12
Training loss: 1.0201421976089478
Validation loss: 1.8495368598609843

Epoch: 6| Step: 13
Training loss: 1.196163535118103
Validation loss: 1.7996780154525593

Epoch: 353| Step: 0
Training loss: 1.0353456735610962
Validation loss: 1.7833475874316307

Epoch: 6| Step: 1
Training loss: 1.8175463676452637
Validation loss: 1.805837967062509

Epoch: 6| Step: 2
Training loss: 0.7634475827217102
Validation loss: 1.7740749133530485

Epoch: 6| Step: 3
Training loss: 1.1121001243591309
Validation loss: 1.8020687795454455

Epoch: 6| Step: 4
Training loss: 1.3964331150054932
Validation loss: 1.7918999297644502

Epoch: 6| Step: 5
Training loss: 1.6814548969268799
Validation loss: 1.807203156973726

Epoch: 6| Step: 6
Training loss: 1.3352229595184326
Validation loss: 1.7854864917775637

Epoch: 6| Step: 7
Training loss: 0.9856465458869934
Validation loss: 1.798848803325366

Epoch: 6| Step: 8
Training loss: 0.8475213050842285
Validation loss: 1.7919087615064395

Epoch: 6| Step: 9
Training loss: 2.2097740173339844
Validation loss: 1.7841090169004215

Epoch: 6| Step: 10
Training loss: 1.9309601783752441
Validation loss: 1.845435521935904

Epoch: 6| Step: 11
Training loss: 1.4239201545715332
Validation loss: 1.8464500327264108

Epoch: 6| Step: 12
Training loss: 0.92530357837677
Validation loss: 1.805459640359366

Epoch: 6| Step: 13
Training loss: 1.5605963468551636
Validation loss: 1.8292583906522362

Epoch: 354| Step: 0
Training loss: 1.7001605033874512
Validation loss: 1.8582814765232865

Epoch: 6| Step: 1
Training loss: 1.0370314121246338
Validation loss: 1.8552588109047181

Epoch: 6| Step: 2
Training loss: 1.4045984745025635
Validation loss: 1.8227411713651431

Epoch: 6| Step: 3
Training loss: 1.4020235538482666
Validation loss: 1.8460602375768846

Epoch: 6| Step: 4
Training loss: 1.2427709102630615
Validation loss: 1.8403029288015058

Epoch: 6| Step: 5
Training loss: 1.160773754119873
Validation loss: 1.9058632966010802

Epoch: 6| Step: 6
Training loss: 1.482600450515747
Validation loss: 1.86257037039726

Epoch: 6| Step: 7
Training loss: 1.1473658084869385
Validation loss: 1.8543635991311842

Epoch: 6| Step: 8
Training loss: 1.3160310983657837
Validation loss: 1.8299435005393079

Epoch: 6| Step: 9
Training loss: 1.718416452407837
Validation loss: 1.8440156585426741

Epoch: 6| Step: 10
Training loss: 1.6476716995239258
Validation loss: 1.8042011466077579

Epoch: 6| Step: 11
Training loss: 1.3084971904754639
Validation loss: 1.7828235754402735

Epoch: 6| Step: 12
Training loss: 0.8917862772941589
Validation loss: 1.8266457806351364

Epoch: 6| Step: 13
Training loss: 0.9717742204666138
Validation loss: 1.7745764922070246

Epoch: 355| Step: 0
Training loss: 1.1411614418029785
Validation loss: 1.7696177959442139

Epoch: 6| Step: 1
Training loss: 1.4035084247589111
Validation loss: 1.7952895895127328

Epoch: 6| Step: 2
Training loss: 1.7755146026611328
Validation loss: 1.8322340109015023

Epoch: 6| Step: 3
Training loss: 1.4130220413208008
Validation loss: 1.8278997098245928

Epoch: 6| Step: 4
Training loss: 1.9915865659713745
Validation loss: 1.7574842911894604

Epoch: 6| Step: 5
Training loss: 0.5168149471282959
Validation loss: 1.791818323955741

Epoch: 6| Step: 6
Training loss: 0.5884054899215698
Validation loss: 1.806270989038611

Epoch: 6| Step: 7
Training loss: 1.1742299795150757
Validation loss: 1.8399797319084086

Epoch: 6| Step: 8
Training loss: 1.5290014743804932
Validation loss: 1.7993470955920476

Epoch: 6| Step: 9
Training loss: 1.4111886024475098
Validation loss: 1.8600010782159784

Epoch: 6| Step: 10
Training loss: 1.4704561233520508
Validation loss: 1.8430943386529082

Epoch: 6| Step: 11
Training loss: 1.7891058921813965
Validation loss: 1.8286475891708045

Epoch: 6| Step: 12
Training loss: 1.2510390281677246
Validation loss: 1.8249827097820979

Epoch: 6| Step: 13
Training loss: 1.2104086875915527
Validation loss: 1.8871316807244414

Epoch: 356| Step: 0
Training loss: 1.137756586074829
Validation loss: 1.8492270413265433

Epoch: 6| Step: 1
Training loss: 1.698777675628662
Validation loss: 1.8741841111131894

Epoch: 6| Step: 2
Training loss: 1.4320924282073975
Validation loss: 1.8786352424211399

Epoch: 6| Step: 3
Training loss: 1.6749345064163208
Validation loss: 1.8724166911135438

Epoch: 6| Step: 4
Training loss: 0.8984960317611694
Validation loss: 1.84497054161564

Epoch: 6| Step: 5
Training loss: 1.6587014198303223
Validation loss: 1.8206184474370812

Epoch: 6| Step: 6
Training loss: 1.4651087522506714
Validation loss: 1.7799464348823792

Epoch: 6| Step: 7
Training loss: 1.7742493152618408
Validation loss: 1.867543069265222

Epoch: 6| Step: 8
Training loss: 1.285754680633545
Validation loss: 1.8136408687919698

Epoch: 6| Step: 9
Training loss: 1.2530362606048584
Validation loss: 1.791873211501747

Epoch: 6| Step: 10
Training loss: 0.5090514421463013
Validation loss: 1.8232480261915474

Epoch: 6| Step: 11
Training loss: 1.3795902729034424
Validation loss: 1.7872765000148485

Epoch: 6| Step: 12
Training loss: 1.2315714359283447
Validation loss: 1.768373127906553

Epoch: 6| Step: 13
Training loss: 1.4243899583816528
Validation loss: 1.7732058635321997

Epoch: 357| Step: 0
Training loss: 1.4163362979888916
Validation loss: 1.8150940095224688

Epoch: 6| Step: 1
Training loss: 1.207475185394287
Validation loss: 1.8118337379988803

Epoch: 6| Step: 2
Training loss: 1.7408578395843506
Validation loss: 1.8465488649183703

Epoch: 6| Step: 3
Training loss: 1.1669999361038208
Validation loss: 1.8092348549955635

Epoch: 6| Step: 4
Training loss: 1.394676685333252
Validation loss: 1.7888775410190705

Epoch: 6| Step: 5
Training loss: 1.5196762084960938
Validation loss: 1.8589008444099016

Epoch: 6| Step: 6
Training loss: 0.9276817440986633
Validation loss: 1.8497190629282305

Epoch: 6| Step: 7
Training loss: 1.2588205337524414
Validation loss: 1.7953573798620572

Epoch: 6| Step: 8
Training loss: 1.299055576324463
Validation loss: 1.81312378503943

Epoch: 6| Step: 9
Training loss: 1.661773443222046
Validation loss: 1.8587861035459785

Epoch: 6| Step: 10
Training loss: 0.977259635925293
Validation loss: 1.7983550410116873

Epoch: 6| Step: 11
Training loss: 1.4339723587036133
Validation loss: 1.805754961506013

Epoch: 6| Step: 12
Training loss: 1.380473017692566
Validation loss: 1.7962253580811203

Epoch: 6| Step: 13
Training loss: 1.4651001691818237
Validation loss: 1.8130905871750207

Epoch: 358| Step: 0
Training loss: 1.3923258781433105
Validation loss: 1.8346917398514286

Epoch: 6| Step: 1
Training loss: 1.2919259071350098
Validation loss: 1.7841737244718818

Epoch: 6| Step: 2
Training loss: 1.6257479190826416
Validation loss: 1.8211808422560334

Epoch: 6| Step: 3
Training loss: 1.3971426486968994
Validation loss: 1.839270971154654

Epoch: 6| Step: 4
Training loss: 1.3649834394454956
Validation loss: 1.8110828322748984

Epoch: 6| Step: 5
Training loss: 1.3595489263534546
Validation loss: 1.7911430546032485

Epoch: 6| Step: 6
Training loss: 1.1392688751220703
Validation loss: 1.755394870235074

Epoch: 6| Step: 7
Training loss: 1.3800808191299438
Validation loss: 1.8147871968566731

Epoch: 6| Step: 8
Training loss: 1.7369859218597412
Validation loss: 1.7909837909924087

Epoch: 6| Step: 9
Training loss: 1.4581446647644043
Validation loss: 1.7836263295142882

Epoch: 6| Step: 10
Training loss: 1.054068684577942
Validation loss: 1.7712865478249007

Epoch: 6| Step: 11
Training loss: 0.979843020439148
Validation loss: 1.748545233921338

Epoch: 6| Step: 12
Training loss: 1.3074392080307007
Validation loss: 1.7895137956065517

Epoch: 6| Step: 13
Training loss: 1.1309880018234253
Validation loss: 1.8101875602558095

Epoch: 359| Step: 0
Training loss: 1.177706241607666
Validation loss: 1.7731483854273313

Epoch: 6| Step: 1
Training loss: 1.2259719371795654
Validation loss: 1.8121748085944884

Epoch: 6| Step: 2
Training loss: 1.3563569784164429
Validation loss: 1.7977662509487522

Epoch: 6| Step: 3
Training loss: 1.302168607711792
Validation loss: 1.8284153476838143

Epoch: 6| Step: 4
Training loss: 1.2589948177337646
Validation loss: 1.8219069063022573

Epoch: 6| Step: 5
Training loss: 1.3128094673156738
Validation loss: 1.7931484278812204

Epoch: 6| Step: 6
Training loss: 1.4602835178375244
Validation loss: 1.806085318647405

Epoch: 6| Step: 7
Training loss: 1.424694299697876
Validation loss: 1.823385871866698

Epoch: 6| Step: 8
Training loss: 1.0639996528625488
Validation loss: 1.7785800580055482

Epoch: 6| Step: 9
Training loss: 1.8299999237060547
Validation loss: 1.8085019255197177

Epoch: 6| Step: 10
Training loss: 1.3949480056762695
Validation loss: 1.794470904975809

Epoch: 6| Step: 11
Training loss: 1.0327602624893188
Validation loss: 1.8364777283001972

Epoch: 6| Step: 12
Training loss: 1.175304889678955
Validation loss: 1.8093225468871414

Epoch: 6| Step: 13
Training loss: 1.6241493225097656
Validation loss: 1.79396302212951

Epoch: 360| Step: 0
Training loss: 1.3050494194030762
Validation loss: 1.8037793636322021

Epoch: 6| Step: 1
Training loss: 1.52644944190979
Validation loss: 1.8041841932522353

Epoch: 6| Step: 2
Training loss: 1.2369506359100342
Validation loss: 1.7825366168893793

Epoch: 6| Step: 3
Training loss: 0.8715192079544067
Validation loss: 1.7984181924532818

Epoch: 6| Step: 4
Training loss: 1.5935707092285156
Validation loss: 1.762286046499847

Epoch: 6| Step: 5
Training loss: 1.1774574518203735
Validation loss: 1.8141980325022051

Epoch: 6| Step: 6
Training loss: 1.5328779220581055
Validation loss: 1.7829378817671089

Epoch: 6| Step: 7
Training loss: 1.359552025794983
Validation loss: 1.8056130345149706

Epoch: 6| Step: 8
Training loss: 1.629678726196289
Validation loss: 1.8139686661381875

Epoch: 6| Step: 9
Training loss: 1.4537477493286133
Validation loss: 1.830234072541678

Epoch: 6| Step: 10
Training loss: 1.2176693677902222
Validation loss: 1.8623345423770208

Epoch: 6| Step: 11
Training loss: 1.2908169031143188
Validation loss: 1.840375974614133

Epoch: 6| Step: 12
Training loss: 0.6005513668060303
Validation loss: 1.8000774357908516

Epoch: 6| Step: 13
Training loss: 2.4606425762176514
Validation loss: 1.8516475641599266

Epoch: 361| Step: 0
Training loss: 1.4824366569519043
Validation loss: 1.8770854755114483

Epoch: 6| Step: 1
Training loss: 1.3213496208190918
Validation loss: 1.7803383232444845

Epoch: 6| Step: 2
Training loss: 1.517040729522705
Validation loss: 1.7866330236516974

Epoch: 6| Step: 3
Training loss: 1.3289735317230225
Validation loss: 1.8156493017750401

Epoch: 6| Step: 4
Training loss: 0.9970052242279053
Validation loss: 1.795207005675121

Epoch: 6| Step: 5
Training loss: 0.6332551836967468
Validation loss: 1.7914971113204956

Epoch: 6| Step: 6
Training loss: 1.274357557296753
Validation loss: 1.7821924417249617

Epoch: 6| Step: 7
Training loss: 1.4986016750335693
Validation loss: 1.8016714767743183

Epoch: 6| Step: 8
Training loss: 1.485537052154541
Validation loss: 1.7998340578489407

Epoch: 6| Step: 9
Training loss: 0.7887390851974487
Validation loss: 1.8375020565525177

Epoch: 6| Step: 10
Training loss: 1.0256285667419434
Validation loss: 1.8220234135145783

Epoch: 6| Step: 11
Training loss: 1.8250813484191895
Validation loss: 1.8096584171377204

Epoch: 6| Step: 12
Training loss: 1.7037408351898193
Validation loss: 1.8618315958207654

Epoch: 6| Step: 13
Training loss: 1.295278549194336
Validation loss: 1.7992464624425417

Epoch: 362| Step: 0
Training loss: 0.6068253517150879
Validation loss: 1.8398792307863954

Epoch: 6| Step: 1
Training loss: 1.5493731498718262
Validation loss: 1.7949709943545762

Epoch: 6| Step: 2
Training loss: 1.6442539691925049
Validation loss: 1.8043052099084342

Epoch: 6| Step: 3
Training loss: 1.2664875984191895
Validation loss: 1.8123936473682363

Epoch: 6| Step: 4
Training loss: 1.1899465322494507
Validation loss: 1.8416850977046515

Epoch: 6| Step: 5
Training loss: 1.6430625915527344
Validation loss: 1.8424952722364856

Epoch: 6| Step: 6
Training loss: 1.0036611557006836
Validation loss: 1.859474564111361

Epoch: 6| Step: 7
Training loss: 1.9275681972503662
Validation loss: 1.7944400977062922

Epoch: 6| Step: 8
Training loss: 1.100053071975708
Validation loss: 1.8034459262765863

Epoch: 6| Step: 9
Training loss: 1.5343153476715088
Validation loss: 1.836197422396752

Epoch: 6| Step: 10
Training loss: 1.5855176448822021
Validation loss: 1.7748400524098387

Epoch: 6| Step: 11
Training loss: 0.910207211971283
Validation loss: 1.8023923930301462

Epoch: 6| Step: 12
Training loss: 1.0753108263015747
Validation loss: 1.7990585886022097

Epoch: 6| Step: 13
Training loss: 1.2528233528137207
Validation loss: 1.803602885174495

Epoch: 363| Step: 0
Training loss: 1.6564749479293823
Validation loss: 1.8524569542177263

Epoch: 6| Step: 1
Training loss: 0.9611227512359619
Validation loss: 1.8338299771790862

Epoch: 6| Step: 2
Training loss: 1.2963151931762695
Validation loss: 1.774390971788796

Epoch: 6| Step: 3
Training loss: 1.5069597959518433
Validation loss: 1.7899111842596402

Epoch: 6| Step: 4
Training loss: 1.0141898393630981
Validation loss: 1.7801431276464974

Epoch: 6| Step: 5
Training loss: 0.8572673797607422
Validation loss: 1.798194085398028

Epoch: 6| Step: 6
Training loss: 1.6001560688018799
Validation loss: 1.7855969077797347

Epoch: 6| Step: 7
Training loss: 1.1842883825302124
Validation loss: 1.812685215344993

Epoch: 6| Step: 8
Training loss: 1.2269281148910522
Validation loss: 1.8399851411901496

Epoch: 6| Step: 9
Training loss: 1.6449387073516846
Validation loss: 1.7374540810943933

Epoch: 6| Step: 10
Training loss: 1.7384854555130005
Validation loss: 1.8061159259529525

Epoch: 6| Step: 11
Training loss: 1.1099036931991577
Validation loss: 1.8110443187016312

Epoch: 6| Step: 12
Training loss: 1.1980363130569458
Validation loss: 1.7939059452344013

Epoch: 6| Step: 13
Training loss: 1.1143312454223633
Validation loss: 1.824291262575375

Epoch: 364| Step: 0
Training loss: 0.8931970000267029
Validation loss: 1.8189415290791502

Epoch: 6| Step: 1
Training loss: 0.943017303943634
Validation loss: 1.820426679426624

Epoch: 6| Step: 2
Training loss: 1.3355690240859985
Validation loss: 1.8426058933299074

Epoch: 6| Step: 3
Training loss: 1.994070291519165
Validation loss: 1.8279698471869192

Epoch: 6| Step: 4
Training loss: 0.853733241558075
Validation loss: 1.8268064132300756

Epoch: 6| Step: 5
Training loss: 1.2905644178390503
Validation loss: 1.8247501747582549

Epoch: 6| Step: 6
Training loss: 1.569188117980957
Validation loss: 1.8102974994208223

Epoch: 6| Step: 7
Training loss: 1.314718246459961
Validation loss: 1.8190087015910814

Epoch: 6| Step: 8
Training loss: 1.4725605249404907
Validation loss: 1.820467524631049

Epoch: 6| Step: 9
Training loss: 1.1050008535385132
Validation loss: 1.8151846521644182

Epoch: 6| Step: 10
Training loss: 0.8218213319778442
Validation loss: 1.8126249287718086

Epoch: 6| Step: 11
Training loss: 1.7705435752868652
Validation loss: 1.833410196406867

Epoch: 6| Step: 12
Training loss: 1.4824888706207275
Validation loss: 1.7989002402110765

Epoch: 6| Step: 13
Training loss: 1.0993846654891968
Validation loss: 1.7462976735125306

Epoch: 365| Step: 0
Training loss: 1.1819334030151367
Validation loss: 1.7970968677151589

Epoch: 6| Step: 1
Training loss: 1.5732026100158691
Validation loss: 1.7740173647480626

Epoch: 6| Step: 2
Training loss: 1.8351428508758545
Validation loss: 1.7884105187590404

Epoch: 6| Step: 3
Training loss: 1.006723403930664
Validation loss: 1.7847687941725536

Epoch: 6| Step: 4
Training loss: 0.8780426979064941
Validation loss: 1.7971918531643447

Epoch: 6| Step: 5
Training loss: 1.365513563156128
Validation loss: 1.8111354920171923

Epoch: 6| Step: 6
Training loss: 1.1852750778198242
Validation loss: 1.844252344100706

Epoch: 6| Step: 7
Training loss: 1.2800941467285156
Validation loss: 1.8438161034737863

Epoch: 6| Step: 8
Training loss: 1.0277749300003052
Validation loss: 1.8148246144735685

Epoch: 6| Step: 9
Training loss: 1.7588250637054443
Validation loss: 1.8602164919658373

Epoch: 6| Step: 10
Training loss: 1.0144848823547363
Validation loss: 1.8403129141817811

Epoch: 6| Step: 11
Training loss: 1.0339865684509277
Validation loss: 1.7897891947018203

Epoch: 6| Step: 12
Training loss: 1.2349600791931152
Validation loss: 1.8164112696083643

Epoch: 6| Step: 13
Training loss: 2.141840934753418
Validation loss: 1.8473134130559943

Epoch: 366| Step: 0
Training loss: 0.7984512448310852
Validation loss: 1.8001032490884104

Epoch: 6| Step: 1
Training loss: 1.620640516281128
Validation loss: 1.8024127227003857

Epoch: 6| Step: 2
Training loss: 0.872950553894043
Validation loss: 1.7917337558602775

Epoch: 6| Step: 3
Training loss: 1.2187637090682983
Validation loss: 1.7664692504431612

Epoch: 6| Step: 4
Training loss: 1.4216221570968628
Validation loss: 1.7742920511512346

Epoch: 6| Step: 5
Training loss: 1.5272797346115112
Validation loss: 1.8140661729279386

Epoch: 6| Step: 6
Training loss: 1.1974895000457764
Validation loss: 1.8425296057936966

Epoch: 6| Step: 7
Training loss: 1.0828008651733398
Validation loss: 1.771618232932142

Epoch: 6| Step: 8
Training loss: 1.6943706274032593
Validation loss: 1.7791270235533356

Epoch: 6| Step: 9
Training loss: 1.8466532230377197
Validation loss: 1.7954374731227916

Epoch: 6| Step: 10
Training loss: 0.7258766889572144
Validation loss: 1.7763562869000178

Epoch: 6| Step: 11
Training loss: 1.8296396732330322
Validation loss: 1.8078625484179425

Epoch: 6| Step: 12
Training loss: 0.8361806869506836
Validation loss: 1.8372077570166638

Epoch: 6| Step: 13
Training loss: 1.57679283618927
Validation loss: 1.8077695626084522

Epoch: 367| Step: 0
Training loss: 0.8922470808029175
Validation loss: 1.8490873895665652

Epoch: 6| Step: 1
Training loss: 2.053400993347168
Validation loss: 1.8226073544512513

Epoch: 6| Step: 2
Training loss: 1.635897159576416
Validation loss: 1.8275924472398655

Epoch: 6| Step: 3
Training loss: 1.1605278253555298
Validation loss: 1.8600479108031078

Epoch: 6| Step: 4
Training loss: 1.114612102508545
Validation loss: 1.7894958783221502

Epoch: 6| Step: 5
Training loss: 1.0020222663879395
Validation loss: 1.8116212455175256

Epoch: 6| Step: 6
Training loss: 1.3825691938400269
Validation loss: 1.815186631294989

Epoch: 6| Step: 7
Training loss: 1.3337947130203247
Validation loss: 1.78004918431723

Epoch: 6| Step: 8
Training loss: 1.0764130353927612
Validation loss: 1.8198576819512151

Epoch: 6| Step: 9
Training loss: 1.018104076385498
Validation loss: 1.804248926460102

Epoch: 6| Step: 10
Training loss: 1.8105278015136719
Validation loss: 1.8009192174480808

Epoch: 6| Step: 11
Training loss: 1.3827414512634277
Validation loss: 1.8266418005830498

Epoch: 6| Step: 12
Training loss: 0.9394786357879639
Validation loss: 1.7692486547654676

Epoch: 6| Step: 13
Training loss: 1.1473902463912964
Validation loss: 1.8139931527517175

Epoch: 368| Step: 0
Training loss: 1.4451472759246826
Validation loss: 1.8217188876162294

Epoch: 6| Step: 1
Training loss: 1.5696299076080322
Validation loss: 1.8271383841832478

Epoch: 6| Step: 2
Training loss: 1.081687331199646
Validation loss: 1.870351783690914

Epoch: 6| Step: 3
Training loss: 1.5637346506118774
Validation loss: 1.8975280587391188

Epoch: 6| Step: 4
Training loss: 1.0859864950180054
Validation loss: 1.857887537248673

Epoch: 6| Step: 5
Training loss: 1.1279852390289307
Validation loss: 1.8396901238349177

Epoch: 6| Step: 6
Training loss: 0.8309524655342102
Validation loss: 1.8452292591012933

Epoch: 6| Step: 7
Training loss: 0.9828152656555176
Validation loss: 1.8123000616668372

Epoch: 6| Step: 8
Training loss: 1.4078315496444702
Validation loss: 1.7836908601945447

Epoch: 6| Step: 9
Training loss: 1.3928594589233398
Validation loss: 1.8427261819121659

Epoch: 6| Step: 10
Training loss: 0.9922822713851929
Validation loss: 1.8238295060332104

Epoch: 6| Step: 11
Training loss: 1.4638597965240479
Validation loss: 1.8565638513975247

Epoch: 6| Step: 12
Training loss: 1.0430264472961426
Validation loss: 1.8384474221096243

Epoch: 6| Step: 13
Training loss: 1.8275926113128662
Validation loss: 1.8814786403409895

Epoch: 369| Step: 0
Training loss: 0.9163662195205688
Validation loss: 1.788826714279831

Epoch: 6| Step: 1
Training loss: 1.3306381702423096
Validation loss: 1.8142047018133185

Epoch: 6| Step: 2
Training loss: 1.061752438545227
Validation loss: 1.8230980698780348

Epoch: 6| Step: 3
Training loss: 1.1412951946258545
Validation loss: 1.8443265153515724

Epoch: 6| Step: 4
Training loss: 1.1888542175292969
Validation loss: 1.807445550477633

Epoch: 6| Step: 5
Training loss: 1.4820204973220825
Validation loss: 1.8273229778453868

Epoch: 6| Step: 6
Training loss: 1.7274302244186401
Validation loss: 1.791329437686551

Epoch: 6| Step: 7
Training loss: 1.4150335788726807
Validation loss: 1.8410426365431918

Epoch: 6| Step: 8
Training loss: 1.3813375234603882
Validation loss: 1.8661435278513099

Epoch: 6| Step: 9
Training loss: 0.8848488330841064
Validation loss: 1.8250123980224773

Epoch: 6| Step: 10
Training loss: 1.2328991889953613
Validation loss: 1.8349695231324883

Epoch: 6| Step: 11
Training loss: 1.2439658641815186
Validation loss: 1.7922088394882858

Epoch: 6| Step: 12
Training loss: 1.8578369617462158
Validation loss: 1.7505159583143008

Epoch: 6| Step: 13
Training loss: 0.9635030031204224
Validation loss: 1.7907757220729705

Epoch: 370| Step: 0
Training loss: 1.4061102867126465
Validation loss: 1.8066750457209926

Epoch: 6| Step: 1
Training loss: 1.3937337398529053
Validation loss: 1.792585419070336

Epoch: 6| Step: 2
Training loss: 1.207040548324585
Validation loss: 1.7700789179853214

Epoch: 6| Step: 3
Training loss: 1.2752764225006104
Validation loss: 1.7595634114357732

Epoch: 6| Step: 4
Training loss: 1.3258945941925049
Validation loss: 1.7796398990897722

Epoch: 6| Step: 5
Training loss: 1.1904256343841553
Validation loss: 1.8155991326096237

Epoch: 6| Step: 6
Training loss: 1.1374355554580688
Validation loss: 1.7868350898065875

Epoch: 6| Step: 7
Training loss: 1.1900166273117065
Validation loss: 1.8163659893056399

Epoch: 6| Step: 8
Training loss: 0.6182774901390076
Validation loss: 1.8409263318584812

Epoch: 6| Step: 9
Training loss: 1.7360742092132568
Validation loss: 1.8464312527769355

Epoch: 6| Step: 10
Training loss: 1.0380473136901855
Validation loss: 1.8077344753408944

Epoch: 6| Step: 11
Training loss: 1.9048372507095337
Validation loss: 1.7795307072260047

Epoch: 6| Step: 12
Training loss: 1.2712780237197876
Validation loss: 1.8445487560764435

Epoch: 6| Step: 13
Training loss: 1.55436110496521
Validation loss: 1.86439517236525

Epoch: 371| Step: 0
Training loss: 0.4554131329059601
Validation loss: 1.823749771682165

Epoch: 6| Step: 1
Training loss: 1.0742449760437012
Validation loss: 1.8750965979791456

Epoch: 6| Step: 2
Training loss: 0.8900043368339539
Validation loss: 1.8560714734497892

Epoch: 6| Step: 3
Training loss: 1.9079538583755493
Validation loss: 1.7981319965854767

Epoch: 6| Step: 4
Training loss: 1.6147489547729492
Validation loss: 1.8388459259463894

Epoch: 6| Step: 5
Training loss: 1.6445233821868896
Validation loss: 1.816302808382178

Epoch: 6| Step: 6
Training loss: 0.8838781118392944
Validation loss: 1.808159578231073

Epoch: 6| Step: 7
Training loss: 1.138521671295166
Validation loss: 1.8178289205797258

Epoch: 6| Step: 8
Training loss: 1.3646044731140137
Validation loss: 1.8037359176143524

Epoch: 6| Step: 9
Training loss: 1.7295271158218384
Validation loss: 1.7774868088383828

Epoch: 6| Step: 10
Training loss: 1.2426385879516602
Validation loss: 1.8195434437003186

Epoch: 6| Step: 11
Training loss: 0.8557908535003662
Validation loss: 1.853937997612902

Epoch: 6| Step: 12
Training loss: 1.223602533340454
Validation loss: 1.8078523464100336

Epoch: 6| Step: 13
Training loss: 1.7955379486083984
Validation loss: 1.8010900776873353

Epoch: 372| Step: 0
Training loss: 1.0171750783920288
Validation loss: 1.789366332433557

Epoch: 6| Step: 1
Training loss: 1.894255518913269
Validation loss: 1.8384261541469122

Epoch: 6| Step: 2
Training loss: 2.211771011352539
Validation loss: 1.8115165797613

Epoch: 6| Step: 3
Training loss: 1.1121759414672852
Validation loss: 1.775019517508886

Epoch: 6| Step: 4
Training loss: 1.470808982849121
Validation loss: 1.8326820622208297

Epoch: 6| Step: 5
Training loss: 1.0548923015594482
Validation loss: 1.7867928576725784

Epoch: 6| Step: 6
Training loss: 0.9296739101409912
Validation loss: 1.8355374695152364

Epoch: 6| Step: 7
Training loss: 1.2860008478164673
Validation loss: 1.7823746358194659

Epoch: 6| Step: 8
Training loss: 0.8665710687637329
Validation loss: 1.7761889901212466

Epoch: 6| Step: 9
Training loss: 1.0402920246124268
Validation loss: 1.7546466242882512

Epoch: 6| Step: 10
Training loss: 0.8813514113426208
Validation loss: 1.773275258720562

Epoch: 6| Step: 11
Training loss: 1.1825450658798218
Validation loss: 1.7851742506027222

Epoch: 6| Step: 12
Training loss: 1.4552016258239746
Validation loss: 1.8363865703664801

Epoch: 6| Step: 13
Training loss: 1.3004980087280273
Validation loss: 1.8519173758004301

Epoch: 373| Step: 0
Training loss: 1.3994951248168945
Validation loss: 1.8352502725457633

Epoch: 6| Step: 1
Training loss: 1.5444520711898804
Validation loss: 1.864890089599035

Epoch: 6| Step: 2
Training loss: 1.031036138534546
Validation loss: 1.8079624227298203

Epoch: 6| Step: 3
Training loss: 1.0134539604187012
Validation loss: 1.8211052981756066

Epoch: 6| Step: 4
Training loss: 0.757821261882782
Validation loss: 1.826913713127054

Epoch: 6| Step: 5
Training loss: 1.8499326705932617
Validation loss: 1.8985205863111763

Epoch: 6| Step: 6
Training loss: 1.204085350036621
Validation loss: 1.82833775525452

Epoch: 6| Step: 7
Training loss: 1.2463338375091553
Validation loss: 1.8362580319886566

Epoch: 6| Step: 8
Training loss: 1.1995242834091187
Validation loss: 1.8206772073622672

Epoch: 6| Step: 9
Training loss: 1.0717146396636963
Validation loss: 1.8419777885560067

Epoch: 6| Step: 10
Training loss: 1.8147063255310059
Validation loss: 1.807833707460793

Epoch: 6| Step: 11
Training loss: 1.2783793210983276
Validation loss: 1.8453426220083748

Epoch: 6| Step: 12
Training loss: 1.1930145025253296
Validation loss: 1.8228626943403674

Epoch: 6| Step: 13
Training loss: 1.4497077465057373
Validation loss: 1.8036946506910427

Epoch: 374| Step: 0
Training loss: 1.2962414026260376
Validation loss: 1.7652200229706303

Epoch: 6| Step: 1
Training loss: 1.0281283855438232
Validation loss: 1.7733966048045824

Epoch: 6| Step: 2
Training loss: 1.4606075286865234
Validation loss: 1.79365627227291

Epoch: 6| Step: 3
Training loss: 1.3213354349136353
Validation loss: 1.7870724201202393

Epoch: 6| Step: 4
Training loss: 1.3051893711090088
Validation loss: 1.7885429269524031

Epoch: 6| Step: 5
Training loss: 1.2747528553009033
Validation loss: 1.7646989732660272

Epoch: 6| Step: 6
Training loss: 0.9218310713768005
Validation loss: 1.7902656011683966

Epoch: 6| Step: 7
Training loss: 1.1065871715545654
Validation loss: 1.8217905452174525

Epoch: 6| Step: 8
Training loss: 1.578946828842163
Validation loss: 1.846911641859239

Epoch: 6| Step: 9
Training loss: 1.3854546546936035
Validation loss: 1.8106993206085698

Epoch: 6| Step: 10
Training loss: 1.2085150480270386
Validation loss: 1.849103235429333

Epoch: 6| Step: 11
Training loss: 1.0281087160110474
Validation loss: 1.8551729456070931

Epoch: 6| Step: 12
Training loss: 1.1671102046966553
Validation loss: 1.7958482234708724

Epoch: 6| Step: 13
Training loss: 1.8803855180740356
Validation loss: 1.858402277833672

Epoch: 375| Step: 0
Training loss: 1.4839365482330322
Validation loss: 1.878307552747829

Epoch: 6| Step: 1
Training loss: 1.5131639242172241
Validation loss: 1.849052244617093

Epoch: 6| Step: 2
Training loss: 1.260595440864563
Validation loss: 1.9036469023714784

Epoch: 6| Step: 3
Training loss: 1.3286293745040894
Validation loss: 1.9208239457940544

Epoch: 6| Step: 4
Training loss: 1.346132516860962
Validation loss: 1.9301362050476896

Epoch: 6| Step: 5
Training loss: 0.9770338535308838
Validation loss: 1.8689654514353762

Epoch: 6| Step: 6
Training loss: 1.8369097709655762
Validation loss: 1.8559420839432748

Epoch: 6| Step: 7
Training loss: 1.0390111207962036
Validation loss: 1.8661513046551776

Epoch: 6| Step: 8
Training loss: 0.8374086022377014
Validation loss: 1.8590313849910614

Epoch: 6| Step: 9
Training loss: 1.4370784759521484
Validation loss: 1.822911980331585

Epoch: 6| Step: 10
Training loss: 1.5147427320480347
Validation loss: 1.8451310691013132

Epoch: 6| Step: 11
Training loss: 0.822984516620636
Validation loss: 1.7977371023547264

Epoch: 6| Step: 12
Training loss: 1.2714630365371704
Validation loss: 1.8143303137953564

Epoch: 6| Step: 13
Training loss: 2.1620614528656006
Validation loss: 1.8015722228634743

Epoch: 376| Step: 0
Training loss: 1.8747682571411133
Validation loss: 1.8046309614694247

Epoch: 6| Step: 1
Training loss: 1.0093209743499756
Validation loss: 1.808780316383608

Epoch: 6| Step: 2
Training loss: 1.2586708068847656
Validation loss: 1.7389307893732542

Epoch: 6| Step: 3
Training loss: 1.2299604415893555
Validation loss: 1.786749691091558

Epoch: 6| Step: 4
Training loss: 1.517500400543213
Validation loss: 1.8137058237547516

Epoch: 6| Step: 5
Training loss: 1.1838302612304688
Validation loss: 1.7830699079780168

Epoch: 6| Step: 6
Training loss: 1.29571533203125
Validation loss: 1.7676633557965677

Epoch: 6| Step: 7
Training loss: 1.3855650424957275
Validation loss: 1.8298126728303972

Epoch: 6| Step: 8
Training loss: 1.1030491590499878
Validation loss: 1.80296104825953

Epoch: 6| Step: 9
Training loss: 1.2897758483886719
Validation loss: 1.8366088457004999

Epoch: 6| Step: 10
Training loss: 0.8142814636230469
Validation loss: 1.844826235566088

Epoch: 6| Step: 11
Training loss: 1.4798016548156738
Validation loss: 1.8256185259870303

Epoch: 6| Step: 12
Training loss: 1.0729762315750122
Validation loss: 1.7917760418307396

Epoch: 6| Step: 13
Training loss: 1.3431715965270996
Validation loss: 1.7482969196893836

Epoch: 377| Step: 0
Training loss: 0.7255939245223999
Validation loss: 1.7862160859569427

Epoch: 6| Step: 1
Training loss: 1.2349872589111328
Validation loss: 1.7942068871631418

Epoch: 6| Step: 2
Training loss: 1.0491385459899902
Validation loss: 1.8459707331913773

Epoch: 6| Step: 3
Training loss: 1.3475279808044434
Validation loss: 1.806230188697897

Epoch: 6| Step: 4
Training loss: 1.3102003335952759
Validation loss: 1.8535158095821258

Epoch: 6| Step: 5
Training loss: 0.929699718952179
Validation loss: 1.8334460527666154

Epoch: 6| Step: 6
Training loss: 1.549239993095398
Validation loss: 1.8541060775838873

Epoch: 6| Step: 7
Training loss: 1.5659008026123047
Validation loss: 1.8540009144813783

Epoch: 6| Step: 8
Training loss: 1.3018951416015625
Validation loss: 1.8542459357169367

Epoch: 6| Step: 9
Training loss: 1.7319002151489258
Validation loss: 1.8272062796418385

Epoch: 6| Step: 10
Training loss: 1.0141875743865967
Validation loss: 1.8124032892206663

Epoch: 6| Step: 11
Training loss: 1.1140124797821045
Validation loss: 1.8061763355808873

Epoch: 6| Step: 12
Training loss: 1.489574670791626
Validation loss: 1.7586988710588025

Epoch: 6| Step: 13
Training loss: 1.5099446773529053
Validation loss: 1.7978546106687157

Epoch: 378| Step: 0
Training loss: 1.4081430435180664
Validation loss: 1.787097651471374

Epoch: 6| Step: 1
Training loss: 1.505075216293335
Validation loss: 1.830224080752301

Epoch: 6| Step: 2
Training loss: 0.8552608489990234
Validation loss: 1.8018251875395417

Epoch: 6| Step: 3
Training loss: 1.192589282989502
Validation loss: 1.8234007281641806

Epoch: 6| Step: 4
Training loss: 1.2683411836624146
Validation loss: 1.808128713279642

Epoch: 6| Step: 5
Training loss: 0.8995363116264343
Validation loss: 1.7944889094239922

Epoch: 6| Step: 6
Training loss: 1.4529118537902832
Validation loss: 1.770187743248478

Epoch: 6| Step: 7
Training loss: 1.3747782707214355
Validation loss: 1.8110811710357666

Epoch: 6| Step: 8
Training loss: 0.9233077764511108
Validation loss: 1.8022285622935141

Epoch: 6| Step: 9
Training loss: 1.1679084300994873
Validation loss: 1.7884165099872056

Epoch: 6| Step: 10
Training loss: 1.5229649543762207
Validation loss: 1.8300314731495355

Epoch: 6| Step: 11
Training loss: 1.4330406188964844
Validation loss: 1.8254667456432054

Epoch: 6| Step: 12
Training loss: 1.6512231826782227
Validation loss: 1.8784538853553034

Epoch: 6| Step: 13
Training loss: 0.4709526598453522
Validation loss: 1.857187791537213

Epoch: 379| Step: 0
Training loss: 1.1059461832046509
Validation loss: 1.845666664902882

Epoch: 6| Step: 1
Training loss: 1.4261149168014526
Validation loss: 1.910038916013574

Epoch: 6| Step: 2
Training loss: 1.3935085535049438
Validation loss: 1.9000916968109787

Epoch: 6| Step: 3
Training loss: 1.7396224737167358
Validation loss: 1.8665960142689366

Epoch: 6| Step: 4
Training loss: 1.5382983684539795
Validation loss: 1.9099354692684707

Epoch: 6| Step: 5
Training loss: 1.12990140914917
Validation loss: 1.859689643306117

Epoch: 6| Step: 6
Training loss: 1.1783263683319092
Validation loss: 1.8588349639728505

Epoch: 6| Step: 7
Training loss: 1.143465280532837
Validation loss: 1.8517052101832565

Epoch: 6| Step: 8
Training loss: 1.174837589263916
Validation loss: 1.8223923098656438

Epoch: 6| Step: 9
Training loss: 1.6136759519577026
Validation loss: 1.8094813669881513

Epoch: 6| Step: 10
Training loss: 1.3816289901733398
Validation loss: 1.8257062640241397

Epoch: 6| Step: 11
Training loss: 0.8308440446853638
Validation loss: 1.8883379684981478

Epoch: 6| Step: 12
Training loss: 1.2487337589263916
Validation loss: 1.802613212216285

Epoch: 6| Step: 13
Training loss: 0.9926587343215942
Validation loss: 1.7930930814435404

Epoch: 380| Step: 0
Training loss: 1.055474042892456
Validation loss: 1.7949887103931879

Epoch: 6| Step: 1
Training loss: 1.2189552783966064
Validation loss: 1.8183811005725656

Epoch: 6| Step: 2
Training loss: 0.9398552775382996
Validation loss: 1.817693002762333

Epoch: 6| Step: 3
Training loss: 1.3982471227645874
Validation loss: 1.8003356956666516

Epoch: 6| Step: 4
Training loss: 1.5903661251068115
Validation loss: 1.8346630757854832

Epoch: 6| Step: 5
Training loss: 0.9654269218444824
Validation loss: 1.8284404277801514

Epoch: 6| Step: 6
Training loss: 1.250598430633545
Validation loss: 1.841966111172912

Epoch: 6| Step: 7
Training loss: 2.119802951812744
Validation loss: 1.856456031081497

Epoch: 6| Step: 8
Training loss: 1.2171931266784668
Validation loss: 1.797122924558578

Epoch: 6| Step: 9
Training loss: 0.8801486492156982
Validation loss: 1.8290217986670874

Epoch: 6| Step: 10
Training loss: 1.0740327835083008
Validation loss: 1.8054392440344698

Epoch: 6| Step: 11
Training loss: 1.5311650037765503
Validation loss: 1.823987501923756

Epoch: 6| Step: 12
Training loss: 0.7887123227119446
Validation loss: 1.8439110773865894

Epoch: 6| Step: 13
Training loss: 0.8449054956436157
Validation loss: 1.776022462434666

Epoch: 381| Step: 0
Training loss: 0.9726381301879883
Validation loss: 1.8114958540085824

Epoch: 6| Step: 1
Training loss: 1.4243500232696533
Validation loss: 1.779181525271426

Epoch: 6| Step: 2
Training loss: 1.7491694688796997
Validation loss: 1.7408758555689166

Epoch: 6| Step: 3
Training loss: 1.6824569702148438
Validation loss: 1.827498116800862

Epoch: 6| Step: 4
Training loss: 1.0198969841003418
Validation loss: 1.8469756162294777

Epoch: 6| Step: 5
Training loss: 1.6730940341949463
Validation loss: 1.7871753990009267

Epoch: 6| Step: 6
Training loss: 0.5664730668067932
Validation loss: 1.8376057365889191

Epoch: 6| Step: 7
Training loss: 1.0493440628051758
Validation loss: 1.8331343191926197

Epoch: 6| Step: 8
Training loss: 1.2559382915496826
Validation loss: 1.8304992734744985

Epoch: 6| Step: 9
Training loss: 1.299476981163025
Validation loss: 1.8621729791805308

Epoch: 6| Step: 10
Training loss: 1.094996690750122
Validation loss: 1.8863228751767067

Epoch: 6| Step: 11
Training loss: 1.6119734048843384
Validation loss: 1.8435508487045125

Epoch: 6| Step: 12
Training loss: 1.2450922727584839
Validation loss: 1.83749000359607

Epoch: 6| Step: 13
Training loss: 0.6249939203262329
Validation loss: 1.8281091669554352

Epoch: 382| Step: 0
Training loss: 0.682614803314209
Validation loss: 1.800884755708838

Epoch: 6| Step: 1
Training loss: 1.8421556949615479
Validation loss: 1.779583473359385

Epoch: 6| Step: 2
Training loss: 0.7910321950912476
Validation loss: 1.7398418777732438

Epoch: 6| Step: 3
Training loss: 1.216430425643921
Validation loss: 1.819246607442056

Epoch: 6| Step: 4
Training loss: 1.3146638870239258
Validation loss: 1.820527220285067

Epoch: 6| Step: 5
Training loss: 1.4461185932159424
Validation loss: 1.7768351518979637

Epoch: 6| Step: 6
Training loss: 1.174238681793213
Validation loss: 1.7319458159067298

Epoch: 6| Step: 7
Training loss: 1.294944167137146
Validation loss: 1.769745788266582

Epoch: 6| Step: 8
Training loss: 0.9953285455703735
Validation loss: 1.752028944671795

Epoch: 6| Step: 9
Training loss: 1.6735894680023193
Validation loss: 1.7407262645741945

Epoch: 6| Step: 10
Training loss: 0.9326575398445129
Validation loss: 1.811348149853368

Epoch: 6| Step: 11
Training loss: 1.3871721029281616
Validation loss: 1.7772935616072787

Epoch: 6| Step: 12
Training loss: 1.7603460550308228
Validation loss: 1.8079649415067447

Epoch: 6| Step: 13
Training loss: 1.095247745513916
Validation loss: 1.8413974828617548

Epoch: 383| Step: 0
Training loss: 1.4682199954986572
Validation loss: 1.8473265427415089

Epoch: 6| Step: 1
Training loss: 1.3703492879867554
Validation loss: 1.8433944640621063

Epoch: 6| Step: 2
Training loss: 0.7790111899375916
Validation loss: 1.8156493069023214

Epoch: 6| Step: 3
Training loss: 1.4252170324325562
Validation loss: 1.8493720818591375

Epoch: 6| Step: 4
Training loss: 1.3212826251983643
Validation loss: 1.8744415390876032

Epoch: 6| Step: 5
Training loss: 1.4111377000808716
Validation loss: 1.8447369324263705

Epoch: 6| Step: 6
Training loss: 1.02036714553833
Validation loss: 1.8660876943219094

Epoch: 6| Step: 7
Training loss: 1.180490493774414
Validation loss: 1.838423518724339

Epoch: 6| Step: 8
Training loss: 0.9084771871566772
Validation loss: 1.859720722321541

Epoch: 6| Step: 9
Training loss: 1.2480342388153076
Validation loss: 1.854063541658463

Epoch: 6| Step: 10
Training loss: 1.610911250114441
Validation loss: 1.8458676633014475

Epoch: 6| Step: 11
Training loss: 1.8866571187973022
Validation loss: 1.8626466951062601

Epoch: 6| Step: 12
Training loss: 1.1005398035049438
Validation loss: 1.808133682897014

Epoch: 6| Step: 13
Training loss: 1.2848865985870361
Validation loss: 1.7874217456386936

Epoch: 384| Step: 0
Training loss: 1.1416900157928467
Validation loss: 1.7665810636294785

Epoch: 6| Step: 1
Training loss: 1.1896419525146484
Validation loss: 1.8322389741097727

Epoch: 6| Step: 2
Training loss: 0.62608802318573
Validation loss: 1.7758338054021199

Epoch: 6| Step: 3
Training loss: 1.444236397743225
Validation loss: 1.8119420031065583

Epoch: 6| Step: 4
Training loss: 1.7645695209503174
Validation loss: 1.8122068041114396

Epoch: 6| Step: 5
Training loss: 1.0128527879714966
Validation loss: 1.8089785345139042

Epoch: 6| Step: 6
Training loss: 0.9630241990089417
Validation loss: 1.8171183678411669

Epoch: 6| Step: 7
Training loss: 1.1153311729431152
Validation loss: 1.817242173738377

Epoch: 6| Step: 8
Training loss: 1.0806845426559448
Validation loss: 1.7924605915623326

Epoch: 6| Step: 9
Training loss: 1.098071813583374
Validation loss: 1.8303599537059825

Epoch: 6| Step: 10
Training loss: 1.047264814376831
Validation loss: 1.8086905274339902

Epoch: 6| Step: 11
Training loss: 1.3815672397613525
Validation loss: 1.8147737890161493

Epoch: 6| Step: 12
Training loss: 1.9595369100570679
Validation loss: 1.7501114542766283

Epoch: 6| Step: 13
Training loss: 1.771079659461975
Validation loss: 1.8143105827352053

Epoch: 385| Step: 0
Training loss: 0.5888141393661499
Validation loss: 1.836396466019333

Epoch: 6| Step: 1
Training loss: 0.9768132567405701
Validation loss: 1.8007978393185524

Epoch: 6| Step: 2
Training loss: 1.1226348876953125
Validation loss: 1.8356000582377117

Epoch: 6| Step: 3
Training loss: 1.5797357559204102
Validation loss: 1.8240546500811012

Epoch: 6| Step: 4
Training loss: 1.3338720798492432
Validation loss: 1.8321854452933035

Epoch: 6| Step: 5
Training loss: 1.4508817195892334
Validation loss: 1.8359438001468618

Epoch: 6| Step: 6
Training loss: 1.4013590812683105
Validation loss: 1.8266862054024973

Epoch: 6| Step: 7
Training loss: 1.739408016204834
Validation loss: 1.8149638714328888

Epoch: 6| Step: 8
Training loss: 1.7321264743804932
Validation loss: 1.8047702479106125

Epoch: 6| Step: 9
Training loss: 0.46540436148643494
Validation loss: 1.8320448885681808

Epoch: 6| Step: 10
Training loss: 1.1280404329299927
Validation loss: 1.8353766113199212

Epoch: 6| Step: 11
Training loss: 1.2720983028411865
Validation loss: 1.772524933661184

Epoch: 6| Step: 12
Training loss: 1.215725302696228
Validation loss: 1.785961776651362

Epoch: 6| Step: 13
Training loss: 1.4871087074279785
Validation loss: 1.7820922674671296

Epoch: 386| Step: 0
Training loss: 0.6700959801673889
Validation loss: 1.7672870453967844

Epoch: 6| Step: 1
Training loss: 1.4624650478363037
Validation loss: 1.8223873594755768

Epoch: 6| Step: 2
Training loss: 0.8104968667030334
Validation loss: 1.8160293397083078

Epoch: 6| Step: 3
Training loss: 1.1311408281326294
Validation loss: 1.8141478569276872

Epoch: 6| Step: 4
Training loss: 1.5764148235321045
Validation loss: 1.8381485759571035

Epoch: 6| Step: 5
Training loss: 1.1184117794036865
Validation loss: 1.8168643777088453

Epoch: 6| Step: 6
Training loss: 1.3027088642120361
Validation loss: 1.8067997206923783

Epoch: 6| Step: 7
Training loss: 0.9890888929367065
Validation loss: 1.7929237875887143

Epoch: 6| Step: 8
Training loss: 1.7709639072418213
Validation loss: 1.8046581719511299

Epoch: 6| Step: 9
Training loss: 1.1950479745864868
Validation loss: 1.8430030948372298

Epoch: 6| Step: 10
Training loss: 1.437084436416626
Validation loss: 1.8796674487411336

Epoch: 6| Step: 11
Training loss: 1.453627586364746
Validation loss: 1.8449987185898649

Epoch: 6| Step: 12
Training loss: 1.064655065536499
Validation loss: 1.8718557767970587

Epoch: 6| Step: 13
Training loss: 0.9537244439125061
Validation loss: 1.8570687796479912

Epoch: 387| Step: 0
Training loss: 1.4138455390930176
Validation loss: 1.8019196320605535

Epoch: 6| Step: 1
Training loss: 0.752316415309906
Validation loss: 1.8492840759215816

Epoch: 6| Step: 2
Training loss: 1.3261374235153198
Validation loss: 1.8114616973425752

Epoch: 6| Step: 3
Training loss: 1.49247145652771
Validation loss: 1.8495887402565248

Epoch: 6| Step: 4
Training loss: 1.1531952619552612
Validation loss: 1.847891103836798

Epoch: 6| Step: 5
Training loss: 1.0267612934112549
Validation loss: 1.8521773789518623

Epoch: 6| Step: 6
Training loss: 1.3773164749145508
Validation loss: 1.8649659438799786

Epoch: 6| Step: 7
Training loss: 1.0741593837738037
Validation loss: 1.826078152143827

Epoch: 6| Step: 8
Training loss: 1.312549352645874
Validation loss: 1.8857650705563125

Epoch: 6| Step: 9
Training loss: 1.1187434196472168
Validation loss: 1.7942093700490973

Epoch: 6| Step: 10
Training loss: 1.2251710891723633
Validation loss: 1.805560012017527

Epoch: 6| Step: 11
Training loss: 1.1468815803527832
Validation loss: 1.7675083632110267

Epoch: 6| Step: 12
Training loss: 1.715010643005371
Validation loss: 1.7885323801348287

Epoch: 6| Step: 13
Training loss: 1.1978691816329956
Validation loss: 1.7805627058911067

Epoch: 388| Step: 0
Training loss: 1.282618522644043
Validation loss: 1.8178862243570306

Epoch: 6| Step: 1
Training loss: 0.9979310631752014
Validation loss: 1.818447305310157

Epoch: 6| Step: 2
Training loss: 0.9695048928260803
Validation loss: 1.8026269059027396

Epoch: 6| Step: 3
Training loss: 1.0587080717086792
Validation loss: 1.8160543493045274

Epoch: 6| Step: 4
Training loss: 1.853785514831543
Validation loss: 1.7693438760695919

Epoch: 6| Step: 5
Training loss: 1.7806289196014404
Validation loss: 1.7658860542440926

Epoch: 6| Step: 6
Training loss: 1.7878806591033936
Validation loss: 1.8053216267657537

Epoch: 6| Step: 7
Training loss: 1.5772874355316162
Validation loss: 1.7998737058331888

Epoch: 6| Step: 8
Training loss: 0.8746838569641113
Validation loss: 1.8546271965067873

Epoch: 6| Step: 9
Training loss: 0.8150464296340942
Validation loss: 1.8287184904980403

Epoch: 6| Step: 10
Training loss: 1.398253083229065
Validation loss: 1.8126550874402445

Epoch: 6| Step: 11
Training loss: 1.1797089576721191
Validation loss: 1.8022390283564085

Epoch: 6| Step: 12
Training loss: 1.0074543952941895
Validation loss: 1.8144783505829432

Epoch: 6| Step: 13
Training loss: 1.0248578786849976
Validation loss: 1.846715634868991

Epoch: 389| Step: 0
Training loss: 0.9573825597763062
Validation loss: 1.8682899218733593

Epoch: 6| Step: 1
Training loss: 1.3006263971328735
Validation loss: 1.8132596554294709

Epoch: 6| Step: 2
Training loss: 1.8045610189437866
Validation loss: 1.8293567216524513

Epoch: 6| Step: 3
Training loss: 0.9038084745407104
Validation loss: 1.8492856576878538

Epoch: 6| Step: 4
Training loss: 0.8908218145370483
Validation loss: 1.8237476169422109

Epoch: 6| Step: 5
Training loss: 0.8044689893722534
Validation loss: 1.8007161399369598

Epoch: 6| Step: 6
Training loss: 1.8032112121582031
Validation loss: 1.775860563401253

Epoch: 6| Step: 7
Training loss: 1.3934082984924316
Validation loss: 1.783689127173475

Epoch: 6| Step: 8
Training loss: 1.0878986120224
Validation loss: 1.7615844152306999

Epoch: 6| Step: 9
Training loss: 1.3291220664978027
Validation loss: 1.7831964210797382

Epoch: 6| Step: 10
Training loss: 1.0210566520690918
Validation loss: 1.7758017509214339

Epoch: 6| Step: 11
Training loss: 1.0318747758865356
Validation loss: 1.8000248427032142

Epoch: 6| Step: 12
Training loss: 1.533875823020935
Validation loss: 1.8105379817306355

Epoch: 6| Step: 13
Training loss: 1.849343180656433
Validation loss: 1.7911302030727427

Epoch: 390| Step: 0
Training loss: 1.1841360330581665
Validation loss: 1.8299993148414038

Epoch: 6| Step: 1
Training loss: 1.1066980361938477
Validation loss: 1.7806175024278703

Epoch: 6| Step: 2
Training loss: 1.4302749633789062
Validation loss: 1.7692861877461916

Epoch: 6| Step: 3
Training loss: 1.0031964778900146
Validation loss: 1.826155553581894

Epoch: 6| Step: 4
Training loss: 1.4305403232574463
Validation loss: 1.7865443229675293

Epoch: 6| Step: 5
Training loss: 1.082235336303711
Validation loss: 1.845424359844577

Epoch: 6| Step: 6
Training loss: 1.8941028118133545
Validation loss: 1.8242133945547125

Epoch: 6| Step: 7
Training loss: 1.0722615718841553
Validation loss: 1.8187200087372974

Epoch: 6| Step: 8
Training loss: 0.6121249198913574
Validation loss: 1.8865342870835335

Epoch: 6| Step: 9
Training loss: 1.2261567115783691
Validation loss: 1.8021464437566779

Epoch: 6| Step: 10
Training loss: 1.7897958755493164
Validation loss: 1.8020055210718544

Epoch: 6| Step: 11
Training loss: 0.9028533697128296
Validation loss: 1.8220472181996992

Epoch: 6| Step: 12
Training loss: 0.9590893387794495
Validation loss: 1.8155374885887228

Epoch: 6| Step: 13
Training loss: 1.1956888437271118
Validation loss: 1.8071798022075365

Epoch: 391| Step: 0
Training loss: 1.1868497133255005
Validation loss: 1.851848143403248

Epoch: 6| Step: 1
Training loss: 0.7247428894042969
Validation loss: 1.8091753759691793

Epoch: 6| Step: 2
Training loss: 1.1986308097839355
Validation loss: 1.7838200792189567

Epoch: 6| Step: 3
Training loss: 2.0335464477539062
Validation loss: 1.816333414405905

Epoch: 6| Step: 4
Training loss: 1.3187918663024902
Validation loss: 1.8282402266738236

Epoch: 6| Step: 5
Training loss: 1.8356268405914307
Validation loss: 1.8065261046091716

Epoch: 6| Step: 6
Training loss: 1.0040626525878906
Validation loss: 1.8365543119369014

Epoch: 6| Step: 7
Training loss: 0.7285317182540894
Validation loss: 1.8410100488252537

Epoch: 6| Step: 8
Training loss: 1.0678476095199585
Validation loss: 1.8007834778037122

Epoch: 6| Step: 9
Training loss: 1.6027629375457764
Validation loss: 1.8298922982267154

Epoch: 6| Step: 10
Training loss: 0.9350423812866211
Validation loss: 1.7649686733881633

Epoch: 6| Step: 11
Training loss: 1.0222766399383545
Validation loss: 1.7823420775833951

Epoch: 6| Step: 12
Training loss: 0.9477522373199463
Validation loss: 1.7801683436157882

Epoch: 6| Step: 13
Training loss: 0.9112589359283447
Validation loss: 1.782207146767647

Epoch: 392| Step: 0
Training loss: 1.5103330612182617
Validation loss: 1.8504444014641546

Epoch: 6| Step: 1
Training loss: 1.7212097644805908
Validation loss: 1.7763139842658915

Epoch: 6| Step: 2
Training loss: 0.9965640902519226
Validation loss: 1.7883083730615594

Epoch: 6| Step: 3
Training loss: 1.0654549598693848
Validation loss: 1.7456033358009913

Epoch: 6| Step: 4
Training loss: 0.6443432569503784
Validation loss: 1.7691339215924662

Epoch: 6| Step: 5
Training loss: 0.5985666513442993
Validation loss: 1.7818711034713253

Epoch: 6| Step: 6
Training loss: 1.214893102645874
Validation loss: 1.8179786512928624

Epoch: 6| Step: 7
Training loss: 1.6532063484191895
Validation loss: 1.7806611599460724

Epoch: 6| Step: 8
Training loss: 1.735292673110962
Validation loss: 1.8073434099074333

Epoch: 6| Step: 9
Training loss: 1.2399652004241943
Validation loss: 1.8327852449109476

Epoch: 6| Step: 10
Training loss: 1.3007851839065552
Validation loss: 1.8114951502892278

Epoch: 6| Step: 11
Training loss: 1.1348220109939575
Validation loss: 1.815741974820373

Epoch: 6| Step: 12
Training loss: 1.338104248046875
Validation loss: 1.7947356905988467

Epoch: 6| Step: 13
Training loss: 0.48419925570487976
Validation loss: 1.8199112312768095

Epoch: 393| Step: 0
Training loss: 1.401545524597168
Validation loss: 1.827393070344002

Epoch: 6| Step: 1
Training loss: 1.022254467010498
Validation loss: 1.7599811618046095

Epoch: 6| Step: 2
Training loss: 1.6716325283050537
Validation loss: 1.8213455612941454

Epoch: 6| Step: 3
Training loss: 1.0601948499679565
Validation loss: 1.7978335336972309

Epoch: 6| Step: 4
Training loss: 1.2653145790100098
Validation loss: 1.7785909098963584

Epoch: 6| Step: 5
Training loss: 0.994098424911499
Validation loss: 1.810190082878195

Epoch: 6| Step: 6
Training loss: 1.546341896057129
Validation loss: 1.7873450709927468

Epoch: 6| Step: 7
Training loss: 1.1854631900787354
Validation loss: 1.8623203090442124

Epoch: 6| Step: 8
Training loss: 1.3587960004806519
Validation loss: 1.8095715943203177

Epoch: 6| Step: 9
Training loss: 1.135115146636963
Validation loss: 1.790176668474751

Epoch: 6| Step: 10
Training loss: 1.1013600826263428
Validation loss: 1.7963956556012552

Epoch: 6| Step: 11
Training loss: 1.0960392951965332
Validation loss: 1.7606459535578245

Epoch: 6| Step: 12
Training loss: 1.00452721118927
Validation loss: 1.7793880008882093

Epoch: 6| Step: 13
Training loss: 1.1926500797271729
Validation loss: 1.7672973281593733

Epoch: 394| Step: 0
Training loss: 0.7797400951385498
Validation loss: 1.8267088526038713

Epoch: 6| Step: 1
Training loss: 1.0827627182006836
Validation loss: 1.8124716076799618

Epoch: 6| Step: 2
Training loss: 0.9230461120605469
Validation loss: 1.790691574414571

Epoch: 6| Step: 3
Training loss: 1.0557233095169067
Validation loss: 1.8071014368405907

Epoch: 6| Step: 4
Training loss: 1.352910041809082
Validation loss: 1.7981441072238389

Epoch: 6| Step: 5
Training loss: 0.5332090854644775
Validation loss: 1.8328181377021215

Epoch: 6| Step: 6
Training loss: 1.4936505556106567
Validation loss: 1.805254344017275

Epoch: 6| Step: 7
Training loss: 1.5092689990997314
Validation loss: 1.7851537222503333

Epoch: 6| Step: 8
Training loss: 1.3687450885772705
Validation loss: 1.7689854803905691

Epoch: 6| Step: 9
Training loss: 1.139761209487915
Validation loss: 1.8329590469278314

Epoch: 6| Step: 10
Training loss: 1.1111462116241455
Validation loss: 1.7954857272486533

Epoch: 6| Step: 11
Training loss: 1.804353952407837
Validation loss: 1.7952331650641657

Epoch: 6| Step: 12
Training loss: 1.2858631610870361
Validation loss: 1.789108617331392

Epoch: 6| Step: 13
Training loss: 2.196742057800293
Validation loss: 1.815813502957744

Epoch: 395| Step: 0
Training loss: 1.47090482711792
Validation loss: 1.812136516776136

Epoch: 6| Step: 1
Training loss: 1.243467092514038
Validation loss: 1.8149512557573215

Epoch: 6| Step: 2
Training loss: 0.957592248916626
Validation loss: 1.7832188119170487

Epoch: 6| Step: 3
Training loss: 1.1752045154571533
Validation loss: 1.8197639680677844

Epoch: 6| Step: 4
Training loss: 0.8284586668014526
Validation loss: 1.7617030553920294

Epoch: 6| Step: 5
Training loss: 1.6675218343734741
Validation loss: 1.7962597903384958

Epoch: 6| Step: 6
Training loss: 1.1633596420288086
Validation loss: 1.8119091474881737

Epoch: 6| Step: 7
Training loss: 0.7909078598022461
Validation loss: 1.7893850284238015

Epoch: 6| Step: 8
Training loss: 1.004280924797058
Validation loss: 1.7616019377144434

Epoch: 6| Step: 9
Training loss: 1.462212085723877
Validation loss: 1.8047674291877336

Epoch: 6| Step: 10
Training loss: 1.0904546976089478
Validation loss: 1.782134940547328

Epoch: 6| Step: 11
Training loss: 1.5524718761444092
Validation loss: 1.7474326087582497

Epoch: 6| Step: 12
Training loss: 0.9552173614501953
Validation loss: 1.7785718364100302

Epoch: 6| Step: 13
Training loss: 0.9076576232910156
Validation loss: 1.8192678625865648

Epoch: 396| Step: 0
Training loss: 1.157928228378296
Validation loss: 1.8104622235862158

Epoch: 6| Step: 1
Training loss: 1.1438584327697754
Validation loss: 1.745143066170395

Epoch: 6| Step: 2
Training loss: 1.6438424587249756
Validation loss: 1.797647624887446

Epoch: 6| Step: 3
Training loss: 1.476381778717041
Validation loss: 1.7968747551723192

Epoch: 6| Step: 4
Training loss: 1.0333597660064697
Validation loss: 1.7461234215767152

Epoch: 6| Step: 5
Training loss: 1.4649267196655273
Validation loss: 1.783281518566993

Epoch: 6| Step: 6
Training loss: 0.9881173372268677
Validation loss: 1.777149103021109

Epoch: 6| Step: 7
Training loss: 1.1047463417053223
Validation loss: 1.8150003546027726

Epoch: 6| Step: 8
Training loss: 1.097682237625122
Validation loss: 1.8002210868302213

Epoch: 6| Step: 9
Training loss: 0.8886380195617676
Validation loss: 1.8407608168099516

Epoch: 6| Step: 10
Training loss: 1.800461769104004
Validation loss: 1.8275773166328348

Epoch: 6| Step: 11
Training loss: 1.2314810752868652
Validation loss: 1.8135743987175725

Epoch: 6| Step: 12
Training loss: 1.1998927593231201
Validation loss: 1.822634930251747

Epoch: 6| Step: 13
Training loss: 0.5014987587928772
Validation loss: 1.8368883107298164

Epoch: 397| Step: 0
Training loss: 1.2892367839813232
Validation loss: 1.801971988011432

Epoch: 6| Step: 1
Training loss: 0.8525583148002625
Validation loss: 1.8088195529035342

Epoch: 6| Step: 2
Training loss: 0.9199615716934204
Validation loss: 1.8215749161217802

Epoch: 6| Step: 3
Training loss: 1.1107289791107178
Validation loss: 1.8297477793949906

Epoch: 6| Step: 4
Training loss: 1.293555736541748
Validation loss: 1.759817074703914

Epoch: 6| Step: 5
Training loss: 0.8793018460273743
Validation loss: 1.8190933632594284

Epoch: 6| Step: 6
Training loss: 1.1953790187835693
Validation loss: 1.8267959420399

Epoch: 6| Step: 7
Training loss: 1.6590559482574463
Validation loss: 1.8285373346779936

Epoch: 6| Step: 8
Training loss: 1.8136948347091675
Validation loss: 1.8052699412069013

Epoch: 6| Step: 9
Training loss: 1.252788782119751
Validation loss: 1.833320798412446

Epoch: 6| Step: 10
Training loss: 1.4206047058105469
Validation loss: 1.817566124341821

Epoch: 6| Step: 11
Training loss: 0.9710822701454163
Validation loss: 1.8007582836253668

Epoch: 6| Step: 12
Training loss: 1.058468222618103
Validation loss: 1.827379318975633

Epoch: 6| Step: 13
Training loss: 1.6700119972229004
Validation loss: 1.827102102259154

Epoch: 398| Step: 0
Training loss: 0.7938788533210754
Validation loss: 1.8029066144779164

Epoch: 6| Step: 1
Training loss: 1.132143259048462
Validation loss: 1.7900630389490435

Epoch: 6| Step: 2
Training loss: 1.077890157699585
Validation loss: 1.8370536091507121

Epoch: 6| Step: 3
Training loss: 2.144778251647949
Validation loss: 1.810175839290824

Epoch: 6| Step: 4
Training loss: 0.946079671382904
Validation loss: 1.812654350393562

Epoch: 6| Step: 5
Training loss: 1.4863638877868652
Validation loss: 1.7950267138019684

Epoch: 6| Step: 6
Training loss: 1.2556275129318237
Validation loss: 1.8721278239321966

Epoch: 6| Step: 7
Training loss: 1.1705647706985474
Validation loss: 1.8707104934159147

Epoch: 6| Step: 8
Training loss: 1.4535307884216309
Validation loss: 1.8567601250063988

Epoch: 6| Step: 9
Training loss: 1.2653028964996338
Validation loss: 1.8429096642360892

Epoch: 6| Step: 10
Training loss: 0.7031617164611816
Validation loss: 1.820063699958145

Epoch: 6| Step: 11
Training loss: 0.9565999507904053
Validation loss: 1.76883106077871

Epoch: 6| Step: 12
Training loss: 1.1465060710906982
Validation loss: 1.7334071384963168

Epoch: 6| Step: 13
Training loss: 1.244964599609375
Validation loss: 1.7870934330007082

Epoch: 399| Step: 0
Training loss: 1.2609837055206299
Validation loss: 1.778035161315754

Epoch: 6| Step: 1
Training loss: 0.7909786105155945
Validation loss: 1.7538751850845993

Epoch: 6| Step: 2
Training loss: 0.8952933549880981
Validation loss: 1.7998580650616718

Epoch: 6| Step: 3
Training loss: 1.394822359085083
Validation loss: 1.7715253317227928

Epoch: 6| Step: 4
Training loss: 1.061396837234497
Validation loss: 1.7753434476032053

Epoch: 6| Step: 5
Training loss: 1.5455985069274902
Validation loss: 1.7614855791932793

Epoch: 6| Step: 6
Training loss: 1.0678720474243164
Validation loss: 1.8307807342980498

Epoch: 6| Step: 7
Training loss: 1.2201241254806519
Validation loss: 1.807310632480088

Epoch: 6| Step: 8
Training loss: 1.1716127395629883
Validation loss: 1.8520694035355763

Epoch: 6| Step: 9
Training loss: 1.230405569076538
Validation loss: 1.8225554535465855

Epoch: 6| Step: 10
Training loss: 0.9515341520309448
Validation loss: 1.826050619925222

Epoch: 6| Step: 11
Training loss: 0.9880605340003967
Validation loss: 1.8514393580857145

Epoch: 6| Step: 12
Training loss: 1.831167221069336
Validation loss: 1.7896343790074831

Epoch: 6| Step: 13
Training loss: 1.5493848323822021
Validation loss: 1.8461350112833002

Epoch: 400| Step: 0
Training loss: 1.1669225692749023
Validation loss: 1.7803915828786872

Epoch: 6| Step: 1
Training loss: 1.6937466859817505
Validation loss: 1.7903396403917702

Epoch: 6| Step: 2
Training loss: 1.2651654481887817
Validation loss: 1.8316869222989647

Epoch: 6| Step: 3
Training loss: 1.0490589141845703
Validation loss: 1.7353801445294452

Epoch: 6| Step: 4
Training loss: 2.1418557167053223
Validation loss: 1.8075115039784422

Epoch: 6| Step: 5
Training loss: 1.0854425430297852
Validation loss: 1.8183612362031014

Epoch: 6| Step: 6
Training loss: 1.140272855758667
Validation loss: 1.7577322106207571

Epoch: 6| Step: 7
Training loss: 1.38619065284729
Validation loss: 1.7740864945996193

Epoch: 6| Step: 8
Training loss: 1.0823242664337158
Validation loss: 1.7633950056568268

Epoch: 6| Step: 9
Training loss: 1.116560459136963
Validation loss: 1.8466930773950392

Epoch: 6| Step: 10
Training loss: 1.158071517944336
Validation loss: 1.8071783986142886

Epoch: 6| Step: 11
Training loss: 0.9056431651115417
Validation loss: 1.801741292399745

Epoch: 6| Step: 12
Training loss: 1.2748569250106812
Validation loss: 1.772366895470568

Epoch: 6| Step: 13
Training loss: 0.5089393854141235
Validation loss: 1.765532079563346

Testing loss: 2.3772402975294327
