Epoch: 1| Step: 0
Training loss: 3.312023162841797
Validation loss: 3.018764188212733

Epoch: 5| Step: 1
Training loss: 2.7187907695770264
Validation loss: 3.0167481053260063

Epoch: 5| Step: 2
Training loss: 2.8383371829986572
Validation loss: 3.0114337705796763

Epoch: 5| Step: 3
Training loss: 2.4519221782684326
Validation loss: 3.0070624889866

Epoch: 5| Step: 4
Training loss: 3.0802524089813232
Validation loss: 3.0026319001310613

Epoch: 5| Step: 5
Training loss: 3.5621674060821533
Validation loss: 2.9996711695066063

Epoch: 5| Step: 6
Training loss: 3.397803544998169
Validation loss: 2.9990366633220384

Epoch: 5| Step: 7
Training loss: 2.002073049545288
Validation loss: 2.994707981745402

Epoch: 5| Step: 8
Training loss: 4.389457702636719
Validation loss: 2.991092412702499

Epoch: 5| Step: 9
Training loss: 2.852145195007324
Validation loss: 2.9863118587001676

Epoch: 5| Step: 10
Training loss: 3.158843517303467
Validation loss: 2.982330414556688

Epoch: 2| Step: 0
Training loss: 2.870482921600342
Validation loss: 2.980569065258067

Epoch: 5| Step: 1
Training loss: 3.44977068901062
Validation loss: 2.9764689296804447

Epoch: 5| Step: 2
Training loss: 3.425297260284424
Validation loss: 2.9723927077426704

Epoch: 5| Step: 3
Training loss: 4.261180877685547
Validation loss: 2.9687144423043854

Epoch: 5| Step: 4
Training loss: 2.940822124481201
Validation loss: 2.96602487820451

Epoch: 5| Step: 5
Training loss: 3.0393669605255127
Validation loss: 2.961211589074904

Epoch: 5| Step: 6
Training loss: 2.8073318004608154
Validation loss: 2.957252474241359

Epoch: 5| Step: 7
Training loss: 2.1658806800842285
Validation loss: 2.953528276053808

Epoch: 5| Step: 8
Training loss: 2.224658966064453
Validation loss: 2.950910875874181

Epoch: 5| Step: 9
Training loss: 3.114267110824585
Validation loss: 2.94651557296835

Epoch: 5| Step: 10
Training loss: 3.163250684738159
Validation loss: 2.945199220411239

Epoch: 3| Step: 0
Training loss: 3.044036865234375
Validation loss: 2.939450092213128

Epoch: 5| Step: 1
Training loss: 3.0283522605895996
Validation loss: 2.937771148579095

Epoch: 5| Step: 2
Training loss: 2.8501369953155518
Validation loss: 2.935383476236815

Epoch: 5| Step: 3
Training loss: 4.161620140075684
Validation loss: 2.9293487789810344

Epoch: 5| Step: 4
Training loss: 3.0751285552978516
Validation loss: 2.9271261794592744

Epoch: 5| Step: 5
Training loss: 2.962167263031006
Validation loss: 2.921288505677254

Epoch: 5| Step: 6
Training loss: 2.3271896839141846
Validation loss: 2.9198677642371065

Epoch: 5| Step: 7
Training loss: 3.127622604370117
Validation loss: 2.917258588216638

Epoch: 5| Step: 8
Training loss: 2.7231481075286865
Validation loss: 2.9129952461488786

Epoch: 5| Step: 9
Training loss: 3.0852010250091553
Validation loss: 2.9108240219854538

Epoch: 5| Step: 10
Training loss: 2.732551336288452
Validation loss: 2.907567219067645

Epoch: 4| Step: 0
Training loss: 2.723273515701294
Validation loss: 2.9012099773653093

Epoch: 5| Step: 1
Training loss: 2.4339253902435303
Validation loss: 2.9007267618692048

Epoch: 5| Step: 2
Training loss: 2.7749619483947754
Validation loss: 2.8985466752001035

Epoch: 5| Step: 3
Training loss: 3.128990888595581
Validation loss: 2.894109833625055

Epoch: 5| Step: 4
Training loss: 3.262950897216797
Validation loss: 2.8923452669574368

Epoch: 5| Step: 5
Training loss: 3.3398690223693848
Validation loss: 2.886724066990678

Epoch: 5| Step: 6
Training loss: 2.638244152069092
Validation loss: 2.883373527116673

Epoch: 5| Step: 7
Training loss: 3.2033817768096924
Validation loss: 2.880252702261812

Epoch: 5| Step: 8
Training loss: 2.3980560302734375
Validation loss: 2.876781686659782

Epoch: 5| Step: 9
Training loss: 3.6221911907196045
Validation loss: 2.872709330692086

Epoch: 5| Step: 10
Training loss: 3.3463070392608643
Validation loss: 2.8678774320951073

Epoch: 5| Step: 0
Training loss: 3.2774593830108643
Validation loss: 2.8648690767185663

Epoch: 5| Step: 1
Training loss: 2.151095151901245
Validation loss: 2.861141312506891

Epoch: 5| Step: 2
Training loss: 2.84533953666687
Validation loss: 2.8578969458098054

Epoch: 5| Step: 3
Training loss: 3.0478856563568115
Validation loss: 2.853197354142384

Epoch: 5| Step: 4
Training loss: 2.404271125793457
Validation loss: 2.8484441541856333

Epoch: 5| Step: 5
Training loss: 2.895040988922119
Validation loss: 2.8459358907515004

Epoch: 5| Step: 6
Training loss: 3.2789158821105957
Validation loss: 2.8422728174476215

Epoch: 5| Step: 7
Training loss: 2.593085765838623
Validation loss: 2.837635624793268

Epoch: 5| Step: 8
Training loss: 3.58811616897583
Validation loss: 2.8329276987301406

Epoch: 5| Step: 9
Training loss: 3.262362003326416
Validation loss: 2.828296579340453

Epoch: 5| Step: 10
Training loss: 3.2022218704223633
Validation loss: 2.8246379949713267

Epoch: 6| Step: 0
Training loss: 2.931786060333252
Validation loss: 2.8215906261115946

Epoch: 5| Step: 1
Training loss: 2.977459192276001
Validation loss: 2.8161476658236597

Epoch: 5| Step: 2
Training loss: 2.9135499000549316
Validation loss: 2.811080768544187

Epoch: 5| Step: 3
Training loss: 2.395200729370117
Validation loss: 2.805144730434623

Epoch: 5| Step: 4
Training loss: 2.8541183471679688
Validation loss: 2.803314232057141

Epoch: 5| Step: 5
Training loss: 3.373870849609375
Validation loss: 2.7984738837006273

Epoch: 5| Step: 6
Training loss: 3.2096571922302246
Validation loss: 2.794907921104021

Epoch: 5| Step: 7
Training loss: 2.224430799484253
Validation loss: 2.7904104237915366

Epoch: 5| Step: 8
Training loss: 2.8991565704345703
Validation loss: 2.786004617650022

Epoch: 5| Step: 9
Training loss: 3.68074107170105
Validation loss: 2.780107484068922

Epoch: 5| Step: 10
Training loss: 2.6752493381500244
Validation loss: 2.7769927773424374

Epoch: 7| Step: 0
Training loss: 3.4155654907226562
Validation loss: 2.77471177552336

Epoch: 5| Step: 1
Training loss: 3.1492621898651123
Validation loss: 2.769945257453508

Epoch: 5| Step: 2
Training loss: 3.077785015106201
Validation loss: 2.762701021727695

Epoch: 5| Step: 3
Training loss: 3.1895933151245117
Validation loss: 2.760901040928338

Epoch: 5| Step: 4
Training loss: 2.5304081439971924
Validation loss: 2.753242790058095

Epoch: 5| Step: 5
Training loss: 1.7880370616912842
Validation loss: 2.7487793225114063

Epoch: 5| Step: 6
Training loss: 3.1808390617370605
Validation loss: 2.7443790358881794

Epoch: 5| Step: 7
Training loss: 3.1258645057678223
Validation loss: 2.7440768723846762

Epoch: 5| Step: 8
Training loss: 3.072876453399658
Validation loss: 2.736625163785873

Epoch: 5| Step: 9
Training loss: 2.554870128631592
Validation loss: 2.7326400459453626

Epoch: 5| Step: 10
Training loss: 2.738760232925415
Validation loss: 2.727653113744592

Epoch: 8| Step: 0
Training loss: 2.4061214923858643
Validation loss: 2.7242428769347486

Epoch: 5| Step: 1
Training loss: 2.758340835571289
Validation loss: 2.719250830270911

Epoch: 5| Step: 2
Training loss: 2.5542755126953125
Validation loss: 2.7161756407830024

Epoch: 5| Step: 3
Training loss: 3.3507609367370605
Validation loss: 2.7151545145178355

Epoch: 5| Step: 4
Training loss: 2.6034252643585205
Validation loss: 2.7096540415158836

Epoch: 5| Step: 5
Training loss: 2.492483615875244
Validation loss: 2.704525047732938

Epoch: 5| Step: 6
Training loss: 3.111391544342041
Validation loss: 2.700316006137479

Epoch: 5| Step: 7
Training loss: 3.4598171710968018
Validation loss: 2.6980278491973877

Epoch: 5| Step: 8
Training loss: 2.7611165046691895
Validation loss: 2.6924328291287987

Epoch: 5| Step: 9
Training loss: 3.2317607402801514
Validation loss: 2.689440640070105

Epoch: 5| Step: 10
Training loss: 2.7015867233276367
Validation loss: 2.6863585056797152

Epoch: 9| Step: 0
Training loss: 2.339195728302002
Validation loss: 2.6827567956780873

Epoch: 5| Step: 1
Training loss: 3.3968231678009033
Validation loss: 2.6759327021978234

Epoch: 5| Step: 2
Training loss: 2.4543893337249756
Validation loss: 2.6733773857034664

Epoch: 5| Step: 3
Training loss: 3.766461133956909
Validation loss: 2.6676796277364097

Epoch: 5| Step: 4
Training loss: 2.515018939971924
Validation loss: 2.6659576508306686

Epoch: 5| Step: 5
Training loss: 2.780735731124878
Validation loss: 2.6590216954549155

Epoch: 5| Step: 6
Training loss: 3.38506817817688
Validation loss: 2.6543065373615553

Epoch: 5| Step: 7
Training loss: 2.7711117267608643
Validation loss: 2.650365585921913

Epoch: 5| Step: 8
Training loss: 2.4325432777404785
Validation loss: 2.6462495711541947

Epoch: 5| Step: 9
Training loss: 2.3224852085113525
Validation loss: 2.6430269133660103

Epoch: 5| Step: 10
Training loss: 2.944650173187256
Validation loss: 2.637165146489297

Epoch: 10| Step: 0
Training loss: 2.4914309978485107
Validation loss: 2.6329257257523073

Epoch: 5| Step: 1
Training loss: 2.8876399993896484
Validation loss: 2.629787906523674

Epoch: 5| Step: 2
Training loss: 2.924158811569214
Validation loss: 2.621864544448032

Epoch: 5| Step: 3
Training loss: 3.1688387393951416
Validation loss: 2.621908792885401

Epoch: 5| Step: 4
Training loss: 2.9487223625183105
Validation loss: 2.614476675628334

Epoch: 5| Step: 5
Training loss: 1.9254144430160522
Validation loss: 2.613709436949863

Epoch: 5| Step: 6
Training loss: 3.12927508354187
Validation loss: 2.6051541297666487

Epoch: 5| Step: 7
Training loss: 3.5250868797302246
Validation loss: 2.6018822526419036

Epoch: 5| Step: 8
Training loss: 2.167160749435425
Validation loss: 2.5993807469644854

Epoch: 5| Step: 9
Training loss: 2.960340976715088
Validation loss: 2.5971617621760212

Epoch: 5| Step: 10
Training loss: 2.592618465423584
Validation loss: 2.5932876986842

Epoch: 11| Step: 0
Training loss: 3.1132938861846924
Validation loss: 2.5860348568167737

Epoch: 5| Step: 1
Training loss: 2.5001699924468994
Validation loss: 2.5797613820722027

Epoch: 5| Step: 2
Training loss: 2.5494213104248047
Validation loss: 2.5743630188767628

Epoch: 5| Step: 3
Training loss: 2.610474109649658
Validation loss: 2.5730125519537155

Epoch: 5| Step: 4
Training loss: 2.3298044204711914
Validation loss: 2.568774997547109

Epoch: 5| Step: 5
Training loss: 2.8610875606536865
Validation loss: 2.5630547077425065

Epoch: 5| Step: 6
Training loss: 2.822173595428467
Validation loss: 2.56272227661584

Epoch: 5| Step: 7
Training loss: 2.5731937885284424
Validation loss: 2.5548577693200882

Epoch: 5| Step: 8
Training loss: 2.950946092605591
Validation loss: 2.5536706370692097

Epoch: 5| Step: 9
Training loss: 2.8162550926208496
Validation loss: 2.5469749358392533

Epoch: 5| Step: 10
Training loss: 3.386850357055664
Validation loss: 2.5385656818266837

Epoch: 12| Step: 0
Training loss: 3.1381382942199707
Validation loss: 2.53820534675352

Epoch: 5| Step: 1
Training loss: 2.2740769386291504
Validation loss: 2.531366212393648

Epoch: 5| Step: 2
Training loss: 2.704599380493164
Validation loss: 2.527840047754267

Epoch: 5| Step: 3
Training loss: 2.8336386680603027
Validation loss: 2.5206283959009315

Epoch: 5| Step: 4
Training loss: 2.8992974758148193
Validation loss: 2.51134987800352

Epoch: 5| Step: 5
Training loss: 2.134387254714966
Validation loss: 2.5093957608745945

Epoch: 5| Step: 6
Training loss: 2.800832748413086
Validation loss: 2.501258788570281

Epoch: 5| Step: 7
Training loss: 2.9008560180664062
Validation loss: 2.5039763783895843

Epoch: 5| Step: 8
Training loss: 2.7878925800323486
Validation loss: 2.4955941912948445

Epoch: 5| Step: 9
Training loss: 2.5999515056610107
Validation loss: 2.487558462286508

Epoch: 5| Step: 10
Training loss: 3.0446226596832275
Validation loss: 2.482391462531141

Epoch: 13| Step: 0
Training loss: 2.493818759918213
Validation loss: 2.478503019578995

Epoch: 5| Step: 1
Training loss: 2.398559093475342
Validation loss: 2.469116269901235

Epoch: 5| Step: 2
Training loss: 2.676621198654175
Validation loss: 2.4651168495096187

Epoch: 5| Step: 3
Training loss: 2.637998104095459
Validation loss: 2.4636164019184728

Epoch: 5| Step: 4
Training loss: 3.9591705799102783
Validation loss: 2.459481739228772

Epoch: 5| Step: 5
Training loss: 3.169698715209961
Validation loss: 2.4482660165397068

Epoch: 5| Step: 6
Training loss: 2.682539463043213
Validation loss: 2.4450307994760494

Epoch: 5| Step: 7
Training loss: 2.443000078201294
Validation loss: 2.4380692076939408

Epoch: 5| Step: 8
Training loss: 2.5928452014923096
Validation loss: 2.436975912381244

Epoch: 5| Step: 9
Training loss: 2.6916956901550293
Validation loss: 2.4313614983712473

Epoch: 5| Step: 10
Training loss: 1.8145164251327515
Validation loss: 2.4207048185410036

Epoch: 14| Step: 0
Training loss: 2.600379467010498
Validation loss: 2.4194884992414907

Epoch: 5| Step: 1
Training loss: 2.1177592277526855
Validation loss: 2.4086531336589525

Epoch: 5| Step: 2
Training loss: 2.7274062633514404
Validation loss: 2.4046017662171395

Epoch: 5| Step: 3
Training loss: 3.0375466346740723
Validation loss: 2.3963627661428144

Epoch: 5| Step: 4
Training loss: 2.822460651397705
Validation loss: 2.391511727404851

Epoch: 5| Step: 5
Training loss: 2.4578278064727783
Validation loss: 2.3906702790209042

Epoch: 5| Step: 6
Training loss: 2.8472683429718018
Validation loss: 2.3791841691540134

Epoch: 5| Step: 7
Training loss: 3.1694226264953613
Validation loss: 2.3683739798043364

Epoch: 5| Step: 8
Training loss: 2.588784694671631
Validation loss: 2.3640420949587257

Epoch: 5| Step: 9
Training loss: 2.284222364425659
Validation loss: 2.3565532904799267

Epoch: 5| Step: 10
Training loss: 2.607605457305908
Validation loss: 2.3517066099310435

Epoch: 15| Step: 0
Training loss: 2.8841392993927
Validation loss: 2.3466883654235513

Epoch: 5| Step: 1
Training loss: 2.1031036376953125
Validation loss: 2.337145613085839

Epoch: 5| Step: 2
Training loss: 3.1906192302703857
Validation loss: 2.332434772163309

Epoch: 5| Step: 3
Training loss: 2.9780807495117188
Validation loss: 2.3308459020430043

Epoch: 5| Step: 4
Training loss: 2.4934115409851074
Validation loss: 2.320199233229442

Epoch: 5| Step: 5
Training loss: 2.606840133666992
Validation loss: 2.316497197715185

Epoch: 5| Step: 6
Training loss: 2.667942762374878
Validation loss: 2.3130854073391167

Epoch: 5| Step: 7
Training loss: 2.9312727451324463
Validation loss: 2.312030933236563

Epoch: 5| Step: 8
Training loss: 2.27262544631958
Validation loss: 2.302777051925659

Epoch: 5| Step: 9
Training loss: 1.9927695989608765
Validation loss: 2.297901976493097

Epoch: 5| Step: 10
Training loss: 2.81413197517395
Validation loss: 2.294947393478886

Epoch: 16| Step: 0
Training loss: 2.612534761428833
Validation loss: 2.2899983159957396

Epoch: 5| Step: 1
Training loss: 2.3448004722595215
Validation loss: 2.287633224200177

Epoch: 5| Step: 2
Training loss: 2.617574691772461
Validation loss: 2.2817381299952024

Epoch: 5| Step: 3
Training loss: 2.661961078643799
Validation loss: 2.2755216936911307

Epoch: 5| Step: 4
Training loss: 3.2519383430480957
Validation loss: 2.2712156118885165

Epoch: 5| Step: 5
Training loss: 1.9091155529022217
Validation loss: 2.265436259649133

Epoch: 5| Step: 6
Training loss: 2.4667091369628906
Validation loss: 2.2596087865932013

Epoch: 5| Step: 7
Training loss: 2.666064500808716
Validation loss: 2.2593644408769507

Epoch: 5| Step: 8
Training loss: 3.1490111351013184
Validation loss: 2.2533714822543565

Epoch: 5| Step: 9
Training loss: 2.4073593616485596
Validation loss: 2.245002656854609

Epoch: 5| Step: 10
Training loss: 2.5437867641448975
Validation loss: 2.2442844055032216

Epoch: 17| Step: 0
Training loss: 2.881640672683716
Validation loss: 2.2399359505663634

Epoch: 5| Step: 1
Training loss: 2.6798105239868164
Validation loss: 2.2320234621724775

Epoch: 5| Step: 2
Training loss: 2.8735291957855225
Validation loss: 2.2352299151882047

Epoch: 5| Step: 3
Training loss: 2.7897634506225586
Validation loss: 2.2253802514845327

Epoch: 5| Step: 4
Training loss: 2.457563877105713
Validation loss: 2.2156602310877975

Epoch: 5| Step: 5
Training loss: 2.0201518535614014
Validation loss: 2.21918470885164

Epoch: 5| Step: 6
Training loss: 2.2608752250671387
Validation loss: 2.212095522111462

Epoch: 5| Step: 7
Training loss: 2.3968560695648193
Validation loss: 2.204086821566346

Epoch: 5| Step: 8
Training loss: 2.1856460571289062
Validation loss: 2.1954314272890807

Epoch: 5| Step: 9
Training loss: 2.697148323059082
Validation loss: 2.199346967922744

Epoch: 5| Step: 10
Training loss: 3.231106758117676
Validation loss: 2.191629559763016

Epoch: 18| Step: 0
Training loss: 2.976801633834839
Validation loss: 2.1867659630314

Epoch: 5| Step: 1
Training loss: 2.7581417560577393
Validation loss: 2.188005993443151

Epoch: 5| Step: 2
Training loss: 2.5315353870391846
Validation loss: 2.186128993188181

Epoch: 5| Step: 3
Training loss: 2.571497917175293
Validation loss: 2.1803536979101037

Epoch: 5| Step: 4
Training loss: 3.1748993396759033
Validation loss: 2.1860563242307274

Epoch: 5| Step: 5
Training loss: 1.7950212955474854
Validation loss: 2.185181990746529

Epoch: 5| Step: 6
Training loss: 2.34065580368042
Validation loss: 2.1821001114383822

Epoch: 5| Step: 7
Training loss: 2.3747570514678955
Validation loss: 2.1743270107494888

Epoch: 5| Step: 8
Training loss: 2.6091055870056152
Validation loss: 2.166219634394492

Epoch: 5| Step: 9
Training loss: 2.406237840652466
Validation loss: 2.1700310630183064

Epoch: 5| Step: 10
Training loss: 2.559466600418091
Validation loss: 2.1665506491097073

Epoch: 19| Step: 0
Training loss: 2.278163194656372
Validation loss: 2.1597166240856214

Epoch: 5| Step: 1
Training loss: 2.712876796722412
Validation loss: 2.1588234721973376

Epoch: 5| Step: 2
Training loss: 2.1447386741638184
Validation loss: 2.157584162168605

Epoch: 5| Step: 3
Training loss: 2.8365039825439453
Validation loss: 2.156801192991195

Epoch: 5| Step: 4
Training loss: 2.860320568084717
Validation loss: 2.147913912291168

Epoch: 5| Step: 5
Training loss: 2.704127073287964
Validation loss: 2.1508473375792145

Epoch: 5| Step: 6
Training loss: 2.005990743637085
Validation loss: 2.143821308689733

Epoch: 5| Step: 7
Training loss: 2.5665345191955566
Validation loss: 2.1413092613220215

Epoch: 5| Step: 8
Training loss: 2.7993102073669434
Validation loss: 2.139950139548189

Epoch: 5| Step: 9
Training loss: 2.0109994411468506
Validation loss: 2.134373311073549

Epoch: 5| Step: 10
Training loss: 2.9653539657592773
Validation loss: 2.1386645109422746

Epoch: 20| Step: 0
Training loss: 2.44978666305542
Validation loss: 2.1311819040647118

Epoch: 5| Step: 1
Training loss: 2.559715509414673
Validation loss: 2.1274052512261177

Epoch: 5| Step: 2
Training loss: 2.7969677448272705
Validation loss: 2.123985690455283

Epoch: 5| Step: 3
Training loss: 2.2030558586120605
Validation loss: 2.1232405362590665

Epoch: 5| Step: 4
Training loss: 2.87758469581604
Validation loss: 2.1156127734850814

Epoch: 5| Step: 5
Training loss: 1.728080153465271
Validation loss: 2.116694442687496

Epoch: 5| Step: 6
Training loss: 3.058469772338867
Validation loss: 2.1022375232429913

Epoch: 5| Step: 7
Training loss: 2.7873787879943848
Validation loss: 2.1029061476389566

Epoch: 5| Step: 8
Training loss: 2.0608317852020264
Validation loss: 2.095326490299676

Epoch: 5| Step: 9
Training loss: 2.564760446548462
Validation loss: 2.0961968578318113

Epoch: 5| Step: 10
Training loss: 2.523846387863159
Validation loss: 2.0922815825349543

Epoch: 21| Step: 0
Training loss: 2.9680168628692627
Validation loss: 2.0906477820488716

Epoch: 5| Step: 1
Training loss: 2.726398468017578
Validation loss: 2.0863172367054927

Epoch: 5| Step: 2
Training loss: 2.470841884613037
Validation loss: 2.085407213498187

Epoch: 5| Step: 3
Training loss: 2.519879102706909
Validation loss: 2.0766079810357865

Epoch: 5| Step: 4
Training loss: 2.958550453186035
Validation loss: 2.0816906780324955

Epoch: 5| Step: 5
Training loss: 2.567185163497925
Validation loss: 2.065471879897579

Epoch: 5| Step: 6
Training loss: 2.357537031173706
Validation loss: 2.0762062277845157

Epoch: 5| Step: 7
Training loss: 2.1150245666503906
Validation loss: 2.0730528652027087

Epoch: 5| Step: 8
Training loss: 2.2773401737213135
Validation loss: 2.0613093030068184

Epoch: 5| Step: 9
Training loss: 2.3381094932556152
Validation loss: 2.068965070991106

Epoch: 5| Step: 10
Training loss: 2.0770273208618164
Validation loss: 2.0672737501000844

Epoch: 22| Step: 0
Training loss: 2.9112319946289062
Validation loss: 2.0594567470653082

Epoch: 5| Step: 1
Training loss: 2.446971893310547
Validation loss: 2.0575958528826312

Epoch: 5| Step: 2
Training loss: 2.235478162765503
Validation loss: 2.0554683721193703

Epoch: 5| Step: 3
Training loss: 2.4568612575531006
Validation loss: 2.052992520793792

Epoch: 5| Step: 4
Training loss: 2.3874382972717285
Validation loss: 2.055682187439293

Epoch: 5| Step: 5
Training loss: 2.1724724769592285
Validation loss: 2.0511161588853404

Epoch: 5| Step: 6
Training loss: 3.1426501274108887
Validation loss: 2.0495076858869163

Epoch: 5| Step: 7
Training loss: 1.982789397239685
Validation loss: 2.0460444393978325

Epoch: 5| Step: 8
Training loss: 2.875377655029297
Validation loss: 2.0516444765111452

Epoch: 5| Step: 9
Training loss: 2.5646681785583496
Validation loss: 2.048778837726962

Epoch: 5| Step: 10
Training loss: 2.036574125289917
Validation loss: 2.052528400574961

Epoch: 23| Step: 0
Training loss: 2.5556557178497314
Validation loss: 2.044513048664216

Epoch: 5| Step: 1
Training loss: 2.739607334136963
Validation loss: 2.0434317409351306

Epoch: 5| Step: 2
Training loss: 2.323530673980713
Validation loss: 2.0426938687601397

Epoch: 5| Step: 3
Training loss: 2.7971675395965576
Validation loss: 2.0395300734427666

Epoch: 5| Step: 4
Training loss: 2.821925640106201
Validation loss: 2.0393576775827715

Epoch: 5| Step: 5
Training loss: 1.8181053400039673
Validation loss: 2.038352838126562

Epoch: 5| Step: 6
Training loss: 2.163172960281372
Validation loss: 2.0350284653325237

Epoch: 5| Step: 7
Training loss: 1.8879518508911133
Validation loss: 2.035258711025279

Epoch: 5| Step: 8
Training loss: 2.747943878173828
Validation loss: 2.0366443075159544

Epoch: 5| Step: 9
Training loss: 3.094904661178589
Validation loss: 2.033489037585515

Epoch: 5| Step: 10
Training loss: 2.0927038192749023
Validation loss: 2.036561850578554

Epoch: 24| Step: 0
Training loss: 2.4260213375091553
Validation loss: 2.023622633308493

Epoch: 5| Step: 1
Training loss: 2.6902694702148438
Validation loss: 2.0353196961905367

Epoch: 5| Step: 2
Training loss: 2.3859686851501465
Validation loss: 2.025811181273512

Epoch: 5| Step: 3
Training loss: 2.5779285430908203
Validation loss: 2.0278542605779504

Epoch: 5| Step: 4
Training loss: 2.3989334106445312
Validation loss: 2.021015090327109

Epoch: 5| Step: 5
Training loss: 2.964585304260254
Validation loss: 2.02678168717251

Epoch: 5| Step: 6
Training loss: 2.8807480335235596
Validation loss: 2.0166649305692284

Epoch: 5| Step: 7
Training loss: 2.4887852668762207
Validation loss: 2.019803503508209

Epoch: 5| Step: 8
Training loss: 2.6988651752471924
Validation loss: 2.01831441925418

Epoch: 5| Step: 9
Training loss: 1.7130886316299438
Validation loss: 2.021414231228572

Epoch: 5| Step: 10
Training loss: 1.6849360466003418
Validation loss: 2.020325881178661

Epoch: 25| Step: 0
Training loss: 2.7972500324249268
Validation loss: 2.0158348006586873

Epoch: 5| Step: 1
Training loss: 1.8879940509796143
Validation loss: 2.0145231498185026

Epoch: 5| Step: 2
Training loss: 2.885164260864258
Validation loss: 2.0110914655911025

Epoch: 5| Step: 3
Training loss: 2.5045886039733887
Validation loss: 2.014332591846425

Epoch: 5| Step: 4
Training loss: 2.6571478843688965
Validation loss: 2.013861016560626

Epoch: 5| Step: 5
Training loss: 2.1832001209259033
Validation loss: 2.0109578832503288

Epoch: 5| Step: 6
Training loss: 2.698169231414795
Validation loss: 2.0141769070779123

Epoch: 5| Step: 7
Training loss: 2.8621010780334473
Validation loss: 2.0039583893232447

Epoch: 5| Step: 8
Training loss: 1.9882838726043701
Validation loss: 2.0118865351523123

Epoch: 5| Step: 9
Training loss: 1.855432152748108
Validation loss: 2.003612240155538

Epoch: 5| Step: 10
Training loss: 2.657498836517334
Validation loss: 2.0057279115082114

Epoch: 26| Step: 0
Training loss: 2.695021390914917
Validation loss: 2.0066001479343702

Epoch: 5| Step: 1
Training loss: 2.14046049118042
Validation loss: 2.008597981545233

Epoch: 5| Step: 2
Training loss: 1.8046289682388306
Validation loss: 2.00038045196123

Epoch: 5| Step: 3
Training loss: 2.228365659713745
Validation loss: 1.9930563524205198

Epoch: 5| Step: 4
Training loss: 2.4425899982452393
Validation loss: 1.997503025557405

Epoch: 5| Step: 5
Training loss: 2.3282573223114014
Validation loss: 1.992931681294595

Epoch: 5| Step: 6
Training loss: 2.087055206298828
Validation loss: 2.0001809263742096

Epoch: 5| Step: 7
Training loss: 2.7872371673583984
Validation loss: 1.9950691730745378

Epoch: 5| Step: 8
Training loss: 2.6083827018737793
Validation loss: 1.9911569446645758

Epoch: 5| Step: 9
Training loss: 3.3394761085510254
Validation loss: 1.9872541760885587

Epoch: 5| Step: 10
Training loss: 2.335141181945801
Validation loss: 1.992273622943509

Epoch: 27| Step: 0
Training loss: 2.1927950382232666
Validation loss: 1.9813146245095037

Epoch: 5| Step: 1
Training loss: 2.2885541915893555
Validation loss: 1.988340248343765

Epoch: 5| Step: 2
Training loss: 2.5837106704711914
Validation loss: 1.9920472150207849

Epoch: 5| Step: 3
Training loss: 2.691798448562622
Validation loss: 1.9845164309265793

Epoch: 5| Step: 4
Training loss: 1.9448989629745483
Validation loss: 1.9898453784245316

Epoch: 5| Step: 5
Training loss: 2.2922801971435547
Validation loss: 1.9883307705643356

Epoch: 5| Step: 6
Training loss: 3.1106553077697754
Validation loss: 1.9839204575425835

Epoch: 5| Step: 7
Training loss: 2.4216809272766113
Validation loss: 1.9849740343709146

Epoch: 5| Step: 8
Training loss: 2.11236310005188
Validation loss: 1.978025108255366

Epoch: 5| Step: 9
Training loss: 2.7243247032165527
Validation loss: 1.9868202440200313

Epoch: 5| Step: 10
Training loss: 2.4061882495880127
Validation loss: 1.9788361826250631

Epoch: 28| Step: 0
Training loss: 2.448108673095703
Validation loss: 1.9808490635246359

Epoch: 5| Step: 1
Training loss: 2.7640769481658936
Validation loss: 1.9838052206141974

Epoch: 5| Step: 2
Training loss: 2.900782346725464
Validation loss: 1.9817840771008564

Epoch: 5| Step: 3
Training loss: 2.0851340293884277
Validation loss: 1.9823168836614138

Epoch: 5| Step: 4
Training loss: 1.8154090642929077
Validation loss: 1.9811355362656295

Epoch: 5| Step: 5
Training loss: 1.9619137048721313
Validation loss: 1.9779492514107817

Epoch: 5| Step: 6
Training loss: 2.6713051795959473
Validation loss: 1.9824495738552463

Epoch: 5| Step: 7
Training loss: 2.4004063606262207
Validation loss: 1.983171570685602

Epoch: 5| Step: 8
Training loss: 2.2635085582733154
Validation loss: 1.983211362233726

Epoch: 5| Step: 9
Training loss: 2.878530979156494
Validation loss: 1.9832543839690506

Epoch: 5| Step: 10
Training loss: 2.4510881900787354
Validation loss: 1.9798869599578202

Epoch: 29| Step: 0
Training loss: 2.425703763961792
Validation loss: 1.9844655913691367

Epoch: 5| Step: 1
Training loss: 2.584897041320801
Validation loss: 1.9818977489266345

Epoch: 5| Step: 2
Training loss: 2.689699411392212
Validation loss: 1.9754711722814908

Epoch: 5| Step: 3
Training loss: 2.029330253601074
Validation loss: 1.9786285841336815

Epoch: 5| Step: 4
Training loss: 2.0485997200012207
Validation loss: 1.9864161309375559

Epoch: 5| Step: 5
Training loss: 2.441685914993286
Validation loss: 1.9839175926741732

Epoch: 5| Step: 6
Training loss: 2.530484437942505
Validation loss: 1.9786423380656908

Epoch: 5| Step: 7
Training loss: 2.7516980171203613
Validation loss: 1.9736760047174269

Epoch: 5| Step: 8
Training loss: 2.420412540435791
Validation loss: 1.9835434729053127

Epoch: 5| Step: 9
Training loss: 2.5600037574768066
Validation loss: 1.9816074909702424

Epoch: 5| Step: 10
Training loss: 2.0372278690338135
Validation loss: 1.983621310162288

Epoch: 30| Step: 0
Training loss: 2.885023593902588
Validation loss: 1.9773754201909548

Epoch: 5| Step: 1
Training loss: 1.9423878192901611
Validation loss: 1.9776973916638283

Epoch: 5| Step: 2
Training loss: 2.1567769050598145
Validation loss: 1.974723413426389

Epoch: 5| Step: 3
Training loss: 3.1043624877929688
Validation loss: 1.9771993237157022

Epoch: 5| Step: 4
Training loss: 2.3343005180358887
Validation loss: 1.9759413068012526

Epoch: 5| Step: 5
Training loss: 1.8464142084121704
Validation loss: 1.9731872133029404

Epoch: 5| Step: 6
Training loss: 2.875077962875366
Validation loss: 1.9756695275665612

Epoch: 5| Step: 7
Training loss: 2.357905864715576
Validation loss: 1.979598411949732

Epoch: 5| Step: 8
Training loss: 2.328892707824707
Validation loss: 1.985547927118117

Epoch: 5| Step: 9
Training loss: 2.6648082733154297
Validation loss: 1.9739413620323263

Epoch: 5| Step: 10
Training loss: 2.0224859714508057
Validation loss: 1.9757375845345118

Epoch: 31| Step: 0
Training loss: 1.9452183246612549
Validation loss: 1.9796184493649391

Epoch: 5| Step: 1
Training loss: 2.6970367431640625
Validation loss: 1.9752516079974431

Epoch: 5| Step: 2
Training loss: 2.3796226978302
Validation loss: 1.973292145677792

Epoch: 5| Step: 3
Training loss: 3.2650561332702637
Validation loss: 1.9763344257108626

Epoch: 5| Step: 4
Training loss: 2.1130523681640625
Validation loss: 1.9737361143994074

Epoch: 5| Step: 5
Training loss: 2.573585033416748
Validation loss: 1.9694510954682545

Epoch: 5| Step: 6
Training loss: 2.5058860778808594
Validation loss: 1.9755817087747718

Epoch: 5| Step: 7
Training loss: 2.0825703144073486
Validation loss: 1.9711445531537455

Epoch: 5| Step: 8
Training loss: 2.458897352218628
Validation loss: 1.9771478355571788

Epoch: 5| Step: 9
Training loss: 2.6376569271087646
Validation loss: 1.9721978992544196

Epoch: 5| Step: 10
Training loss: 1.8346531391143799
Validation loss: 1.97199660219172

Epoch: 32| Step: 0
Training loss: 2.6757047176361084
Validation loss: 1.955533532686131

Epoch: 5| Step: 1
Training loss: 2.4351208209991455
Validation loss: 1.9589818549412552

Epoch: 5| Step: 2
Training loss: 2.902550220489502
Validation loss: 1.9712277022741174

Epoch: 5| Step: 3
Training loss: 2.1698639392852783
Validation loss: 1.9717915417045675

Epoch: 5| Step: 4
Training loss: 2.26786732673645
Validation loss: 1.9641421533400012

Epoch: 5| Step: 5
Training loss: 2.1549811363220215
Validation loss: 1.9656814016321653

Epoch: 5| Step: 6
Training loss: 2.7677061557769775
Validation loss: 1.973311726764966

Epoch: 5| Step: 7
Training loss: 2.3929309844970703
Validation loss: 1.9732509107999905

Epoch: 5| Step: 8
Training loss: 2.515133857727051
Validation loss: 1.975991766939881

Epoch: 5| Step: 9
Training loss: 2.178285598754883
Validation loss: 1.9661951667519026

Epoch: 5| Step: 10
Training loss: 1.9145723581314087
Validation loss: 1.973703017798803

Epoch: 33| Step: 0
Training loss: 2.305586099624634
Validation loss: 1.9695211149031115

Epoch: 5| Step: 1
Training loss: 2.114452600479126
Validation loss: 1.9719849773632583

Epoch: 5| Step: 2
Training loss: 2.560591459274292
Validation loss: 1.9735604127248128

Epoch: 5| Step: 3
Training loss: 2.8180699348449707
Validation loss: 1.9653462376645816

Epoch: 5| Step: 4
Training loss: 2.6837821006774902
Validation loss: 1.9669475247783046

Epoch: 5| Step: 5
Training loss: 2.4858083724975586
Validation loss: 1.965658700594338

Epoch: 5| Step: 6
Training loss: 2.6609714031219482
Validation loss: 1.9639422765342138

Epoch: 5| Step: 7
Training loss: 2.3424720764160156
Validation loss: 1.9654876557729577

Epoch: 5| Step: 8
Training loss: 2.1173081398010254
Validation loss: 1.962014156003152

Epoch: 5| Step: 9
Training loss: 2.0147008895874023
Validation loss: 1.9603115794479207

Epoch: 5| Step: 10
Training loss: 2.2898995876312256
Validation loss: 1.965135125703709

Epoch: 34| Step: 0
Training loss: 2.7972748279571533
Validation loss: 1.9632204296768352

Epoch: 5| Step: 1
Training loss: 2.410823345184326
Validation loss: 1.9589937489519837

Epoch: 5| Step: 2
Training loss: 2.64521861076355
Validation loss: 1.963703723363979

Epoch: 5| Step: 3
Training loss: 2.5402934551239014
Validation loss: 1.9661254421357186

Epoch: 5| Step: 4
Training loss: 2.546419620513916
Validation loss: 1.9627976955906037

Epoch: 5| Step: 5
Training loss: 2.03079891204834
Validation loss: 1.9672905604044597

Epoch: 5| Step: 6
Training loss: 2.6114258766174316
Validation loss: 1.959788381412465

Epoch: 5| Step: 7
Training loss: 2.0970616340637207
Validation loss: 1.9565713995246476

Epoch: 5| Step: 8
Training loss: 2.4838778972625732
Validation loss: 1.9699391344542145

Epoch: 5| Step: 9
Training loss: 1.918975591659546
Validation loss: 1.963036964016576

Epoch: 5| Step: 10
Training loss: 2.2976584434509277
Validation loss: 1.9652700578012774

Epoch: 35| Step: 0
Training loss: 2.060941219329834
Validation loss: 1.961931969529839

Epoch: 5| Step: 1
Training loss: 2.9925055503845215
Validation loss: 1.9669242981941468

Epoch: 5| Step: 2
Training loss: 2.6300594806671143
Validation loss: 1.953231168049638

Epoch: 5| Step: 3
Training loss: 2.3417508602142334
Validation loss: 1.9594436243016233

Epoch: 5| Step: 4
Training loss: 2.46269154548645
Validation loss: 1.9631150563557942

Epoch: 5| Step: 5
Training loss: 2.356005907058716
Validation loss: 1.951872246239775

Epoch: 5| Step: 6
Training loss: 1.867074728012085
Validation loss: 1.960416091385708

Epoch: 5| Step: 7
Training loss: 2.996828317642212
Validation loss: 1.9516188380538777

Epoch: 5| Step: 8
Training loss: 1.8366953134536743
Validation loss: 1.9611512384107035

Epoch: 5| Step: 9
Training loss: 2.4591751098632812
Validation loss: 1.9615423038441648

Epoch: 5| Step: 10
Training loss: 2.232487678527832
Validation loss: 1.953179487618067

Epoch: 36| Step: 0
Training loss: 1.9827083349227905
Validation loss: 1.9534897676078222

Epoch: 5| Step: 1
Training loss: 2.9950473308563232
Validation loss: 1.962291681638328

Epoch: 5| Step: 2
Training loss: 2.364593029022217
Validation loss: 1.9559945919180428

Epoch: 5| Step: 3
Training loss: 2.2487452030181885
Validation loss: 1.9544371661319528

Epoch: 5| Step: 4
Training loss: 2.589008331298828
Validation loss: 1.9570424313186316

Epoch: 5| Step: 5
Training loss: 1.9072526693344116
Validation loss: 1.956187653285201

Epoch: 5| Step: 6
Training loss: 2.730778932571411
Validation loss: 1.9545743939697102

Epoch: 5| Step: 7
Training loss: 2.3090178966522217
Validation loss: 1.954180181667369

Epoch: 5| Step: 8
Training loss: 1.970724105834961
Validation loss: 1.9579994409315047

Epoch: 5| Step: 9
Training loss: 2.8204007148742676
Validation loss: 1.9433542964279011

Epoch: 5| Step: 10
Training loss: 2.3245391845703125
Validation loss: 1.9511156300062775

Epoch: 37| Step: 0
Training loss: 2.4204466342926025
Validation loss: 1.941410990171535

Epoch: 5| Step: 1
Training loss: 2.0039405822753906
Validation loss: 1.953271440280381

Epoch: 5| Step: 2
Training loss: 2.6228859424591064
Validation loss: 1.9422343007979854

Epoch: 5| Step: 3
Training loss: 2.196894884109497
Validation loss: 1.9496487904620428

Epoch: 5| Step: 4
Training loss: 1.708404541015625
Validation loss: 1.957521233507382

Epoch: 5| Step: 5
Training loss: 2.6053037643432617
Validation loss: 1.9586117280426847

Epoch: 5| Step: 6
Training loss: 2.3240654468536377
Validation loss: 1.9492548434965071

Epoch: 5| Step: 7
Training loss: 2.6791656017303467
Validation loss: 1.9511498135905112

Epoch: 5| Step: 8
Training loss: 2.9234111309051514
Validation loss: 1.952425229933954

Epoch: 5| Step: 9
Training loss: 2.690110445022583
Validation loss: 1.9542563064123994

Epoch: 5| Step: 10
Training loss: 1.9608118534088135
Validation loss: 1.9543625667531004

Epoch: 38| Step: 0
Training loss: 2.462972402572632
Validation loss: 1.956872054325637

Epoch: 5| Step: 1
Training loss: 2.5698413848876953
Validation loss: 1.952358454786321

Epoch: 5| Step: 2
Training loss: 2.514348268508911
Validation loss: 1.9449072537883636

Epoch: 5| Step: 3
Training loss: 2.0345749855041504
Validation loss: 1.9548777354660856

Epoch: 5| Step: 4
Training loss: 2.1919138431549072
Validation loss: 1.9529465603572067

Epoch: 5| Step: 5
Training loss: 2.4724438190460205
Validation loss: 1.9510690678832352

Epoch: 5| Step: 6
Training loss: 2.4143929481506348
Validation loss: 1.9483335966704993

Epoch: 5| Step: 7
Training loss: 2.1007862091064453
Validation loss: 1.946478602706745

Epoch: 5| Step: 8
Training loss: 2.523380756378174
Validation loss: 1.9532816845883605

Epoch: 5| Step: 9
Training loss: 2.417208433151245
Validation loss: 1.9453018967823317

Epoch: 5| Step: 10
Training loss: 2.4308207035064697
Validation loss: 1.9578605300636702

Epoch: 39| Step: 0
Training loss: 3.2196033000946045
Validation loss: 1.9434021211439563

Epoch: 5| Step: 1
Training loss: 2.4234485626220703
Validation loss: 1.9492477460574078

Epoch: 5| Step: 2
Training loss: 2.314100980758667
Validation loss: 1.9452682477171703

Epoch: 5| Step: 3
Training loss: 1.7270441055297852
Validation loss: 1.9514464460393435

Epoch: 5| Step: 4
Training loss: 2.5863373279571533
Validation loss: 1.954270944800428

Epoch: 5| Step: 5
Training loss: 2.1842122077941895
Validation loss: 1.9458226452591598

Epoch: 5| Step: 6
Training loss: 1.9475396871566772
Validation loss: 1.947710314104634

Epoch: 5| Step: 7
Training loss: 2.721158266067505
Validation loss: 1.9561560564143683

Epoch: 5| Step: 8
Training loss: 2.210528612136841
Validation loss: 1.9491946069143151

Epoch: 5| Step: 9
Training loss: 2.6943445205688477
Validation loss: 1.9539123709483812

Epoch: 5| Step: 10
Training loss: 2.010653257369995
Validation loss: 1.9506723996131652

Epoch: 40| Step: 0
Training loss: 2.3974061012268066
Validation loss: 1.9506880865302136

Epoch: 5| Step: 1
Training loss: 2.3117284774780273
Validation loss: 1.9478205711610856

Epoch: 5| Step: 2
Training loss: 2.2968811988830566
Validation loss: 1.9472708778996621

Epoch: 5| Step: 3
Training loss: 2.267306089401245
Validation loss: 1.9398502867708924

Epoch: 5| Step: 4
Training loss: 2.1871917247772217
Validation loss: 1.9439624599231187

Epoch: 5| Step: 5
Training loss: 2.286808729171753
Validation loss: 1.9426672958558606

Epoch: 5| Step: 6
Training loss: 2.0293939113616943
Validation loss: 1.9506427664910593

Epoch: 5| Step: 7
Training loss: 2.706225872039795
Validation loss: 1.9483547825967111

Epoch: 5| Step: 8
Training loss: 2.463331460952759
Validation loss: 1.9449330786223054

Epoch: 5| Step: 9
Training loss: 2.8359744548797607
Validation loss: 1.9409478069633566

Epoch: 5| Step: 10
Training loss: 2.235839366912842
Validation loss: 1.9415409423971688

Epoch: 41| Step: 0
Training loss: 2.1496353149414062
Validation loss: 1.9339081984694286

Epoch: 5| Step: 1
Training loss: 2.286001205444336
Validation loss: 1.9376927345029769

Epoch: 5| Step: 2
Training loss: 2.650850296020508
Validation loss: 1.942906969337053

Epoch: 5| Step: 3
Training loss: 1.8628078699111938
Validation loss: 1.932018324893008

Epoch: 5| Step: 4
Training loss: 2.498561382293701
Validation loss: 1.9306268410016132

Epoch: 5| Step: 5
Training loss: 2.6416640281677246
Validation loss: 1.9314031062587615

Epoch: 5| Step: 6
Training loss: 2.0808098316192627
Validation loss: 1.9296773556740052

Epoch: 5| Step: 7
Training loss: 2.2298715114593506
Validation loss: 1.9398930854694818

Epoch: 5| Step: 8
Training loss: 2.3035364151000977
Validation loss: 1.927309081118594

Epoch: 5| Step: 9
Training loss: 2.81038761138916
Validation loss: 1.9374326890514744

Epoch: 5| Step: 10
Training loss: 2.507452964782715
Validation loss: 1.9348138891240603

Epoch: 42| Step: 0
Training loss: 2.720637083053589
Validation loss: 1.9318038468719811

Epoch: 5| Step: 1
Training loss: 1.9357712268829346
Validation loss: 1.9349641799926758

Epoch: 5| Step: 2
Training loss: 2.9859366416931152
Validation loss: 1.933072461876818

Epoch: 5| Step: 3
Training loss: 3.079684019088745
Validation loss: 1.9357680466867262

Epoch: 5| Step: 4
Training loss: 2.3794524669647217
Validation loss: 1.934933823923911

Epoch: 5| Step: 5
Training loss: 1.9269260168075562
Validation loss: 1.9349587040562783

Epoch: 5| Step: 6
Training loss: 2.279796838760376
Validation loss: 1.9367193009263726

Epoch: 5| Step: 7
Training loss: 2.2947845458984375
Validation loss: 1.9353519267933343

Epoch: 5| Step: 8
Training loss: 2.5228731632232666
Validation loss: 1.9330713428476805

Epoch: 5| Step: 9
Training loss: 1.6714754104614258
Validation loss: 1.9283500627804828

Epoch: 5| Step: 10
Training loss: 2.136420488357544
Validation loss: 1.9327376491280013

Epoch: 43| Step: 0
Training loss: 2.7163026332855225
Validation loss: 1.94418405589237

Epoch: 5| Step: 1
Training loss: 2.3605804443359375
Validation loss: 1.9389561171172767

Epoch: 5| Step: 2
Training loss: 2.0636119842529297
Validation loss: 1.931805549129363

Epoch: 5| Step: 3
Training loss: 2.7897543907165527
Validation loss: 1.93233318995404

Epoch: 5| Step: 4
Training loss: 2.291553497314453
Validation loss: 1.9377011842625116

Epoch: 5| Step: 5
Training loss: 2.5723371505737305
Validation loss: 1.9276533537013556

Epoch: 5| Step: 6
Training loss: 2.3568012714385986
Validation loss: 1.9364324231301584

Epoch: 5| Step: 7
Training loss: 1.7955461740493774
Validation loss: 1.933219099557528

Epoch: 5| Step: 8
Training loss: 2.7228941917419434
Validation loss: 1.9302069256382604

Epoch: 5| Step: 9
Training loss: 1.8194692134857178
Validation loss: 1.9397908487627584

Epoch: 5| Step: 10
Training loss: 2.374253034591675
Validation loss: 1.94555417952999

Epoch: 44| Step: 0
Training loss: 1.938542366027832
Validation loss: 1.9434675170529274

Epoch: 5| Step: 1
Training loss: 2.528123378753662
Validation loss: 1.9395988282336984

Epoch: 5| Step: 2
Training loss: 2.0332465171813965
Validation loss: 1.9419164875502228

Epoch: 5| Step: 3
Training loss: 2.542367696762085
Validation loss: 1.9437137355086624

Epoch: 5| Step: 4
Training loss: 2.4167473316192627
Validation loss: 1.946509567640161

Epoch: 5| Step: 5
Training loss: 2.5199079513549805
Validation loss: 1.936755520041271

Epoch: 5| Step: 6
Training loss: 1.8607184886932373
Validation loss: 1.9338106224613805

Epoch: 5| Step: 7
Training loss: 2.7667198181152344
Validation loss: 1.9425785028806297

Epoch: 5| Step: 8
Training loss: 2.4747860431671143
Validation loss: 1.9291488739752

Epoch: 5| Step: 9
Training loss: 2.188519239425659
Validation loss: 1.9314313498876428

Epoch: 5| Step: 10
Training loss: 2.601078748703003
Validation loss: 1.9320244276395409

Epoch: 45| Step: 0
Training loss: 2.5085020065307617
Validation loss: 1.9294972932466896

Epoch: 5| Step: 1
Training loss: 2.4483182430267334
Validation loss: 1.9237514682995376

Epoch: 5| Step: 2
Training loss: 2.293255567550659
Validation loss: 1.9327568264417752

Epoch: 5| Step: 3
Training loss: 2.2986509799957275
Validation loss: 1.9357205475530317

Epoch: 5| Step: 4
Training loss: 2.0152652263641357
Validation loss: 1.9435333539080877

Epoch: 5| Step: 5
Training loss: 1.9846775531768799
Validation loss: 1.9299217834267566

Epoch: 5| Step: 6
Training loss: 2.7178802490234375
Validation loss: 1.9362252502031223

Epoch: 5| Step: 7
Training loss: 2.3317677974700928
Validation loss: 1.9309052113563783

Epoch: 5| Step: 8
Training loss: 2.7571330070495605
Validation loss: 1.9368935746531333

Epoch: 5| Step: 9
Training loss: 2.2653706073760986
Validation loss: 1.934769218967807

Epoch: 5| Step: 10
Training loss: 2.121987819671631
Validation loss: 1.934154531007172

Epoch: 46| Step: 0
Training loss: 2.0470941066741943
Validation loss: 1.946226058467742

Epoch: 5| Step: 1
Training loss: 2.255282163619995
Validation loss: 1.9305492549814203

Epoch: 5| Step: 2
Training loss: 2.4877066612243652
Validation loss: 1.9362813964966805

Epoch: 5| Step: 3
Training loss: 2.295386791229248
Validation loss: 1.9277466522750033

Epoch: 5| Step: 4
Training loss: 2.3584556579589844
Validation loss: 1.9293401369484522

Epoch: 5| Step: 5
Training loss: 2.005408763885498
Validation loss: 1.9267248697178339

Epoch: 5| Step: 6
Training loss: 2.6022708415985107
Validation loss: 1.9366054188820623

Epoch: 5| Step: 7
Training loss: 2.591402530670166
Validation loss: 1.931215645164572

Epoch: 5| Step: 8
Training loss: 2.527911424636841
Validation loss: 1.9300218833390104

Epoch: 5| Step: 9
Training loss: 2.295396089553833
Validation loss: 1.9327394872583368

Epoch: 5| Step: 10
Training loss: 2.247591972351074
Validation loss: 1.9269550692650579

Epoch: 47| Step: 0
Training loss: 2.527066230773926
Validation loss: 1.9317527163413264

Epoch: 5| Step: 1
Training loss: 2.087938070297241
Validation loss: 1.9318949791692919

Epoch: 5| Step: 2
Training loss: 2.0718421936035156
Validation loss: 1.9329690484590427

Epoch: 5| Step: 3
Training loss: 2.1408324241638184
Validation loss: 1.9336097214811592

Epoch: 5| Step: 4
Training loss: 2.1462886333465576
Validation loss: 1.9241079540662869

Epoch: 5| Step: 5
Training loss: 2.218705415725708
Validation loss: 1.930712293553096

Epoch: 5| Step: 6
Training loss: 2.562431812286377
Validation loss: 1.935970312805586

Epoch: 5| Step: 7
Training loss: 2.7433922290802
Validation loss: 1.9300285500864829

Epoch: 5| Step: 8
Training loss: 2.4029171466827393
Validation loss: 1.9266841514136201

Epoch: 5| Step: 9
Training loss: 2.110888719558716
Validation loss: 1.9255119485239829

Epoch: 5| Step: 10
Training loss: 2.7957684993743896
Validation loss: 1.927164609714221

Epoch: 48| Step: 0
Training loss: 2.456183433532715
Validation loss: 1.9383327012420983

Epoch: 5| Step: 1
Training loss: 2.093862533569336
Validation loss: 1.926457876800209

Epoch: 5| Step: 2
Training loss: 2.784006357192993
Validation loss: 1.9231880377697688

Epoch: 5| Step: 3
Training loss: 1.9918591976165771
Validation loss: 1.9220361555776289

Epoch: 5| Step: 4
Training loss: 2.9241788387298584
Validation loss: 1.9278976865994033

Epoch: 5| Step: 5
Training loss: 2.024585008621216
Validation loss: 1.931505746738885

Epoch: 5| Step: 6
Training loss: 2.264564275741577
Validation loss: 1.9256283903634677

Epoch: 5| Step: 7
Training loss: 2.082210063934326
Validation loss: 1.9382340267140379

Epoch: 5| Step: 8
Training loss: 2.7016775608062744
Validation loss: 1.9368404111554545

Epoch: 5| Step: 9
Training loss: 2.23635196685791
Validation loss: 1.9270765525038525

Epoch: 5| Step: 10
Training loss: 2.053136110305786
Validation loss: 1.930570965172142

Epoch: 49| Step: 0
Training loss: 2.4018609523773193
Validation loss: 1.9296624814310381

Epoch: 5| Step: 1
Training loss: 2.3765907287597656
Validation loss: 1.9229706307893157

Epoch: 5| Step: 2
Training loss: 2.186946392059326
Validation loss: 1.9179391835325508

Epoch: 5| Step: 3
Training loss: 2.2993669509887695
Validation loss: 1.939220025975217

Epoch: 5| Step: 4
Training loss: 2.0027389526367188
Validation loss: 1.9334089602193525

Epoch: 5| Step: 5
Training loss: 1.6408084630966187
Validation loss: 1.922290704583609

Epoch: 5| Step: 6
Training loss: 2.9825520515441895
Validation loss: 1.927386712002498

Epoch: 5| Step: 7
Training loss: 2.30071759223938
Validation loss: 1.9252139240182855

Epoch: 5| Step: 8
Training loss: 2.729637861251831
Validation loss: 1.9196004598371443

Epoch: 5| Step: 9
Training loss: 2.785468578338623
Validation loss: 1.9231869994953115

Epoch: 5| Step: 10
Training loss: 1.8294579982757568
Validation loss: 1.9271374979326803

Epoch: 50| Step: 0
Training loss: 2.281832456588745
Validation loss: 1.9239186740690661

Epoch: 5| Step: 1
Training loss: 2.8547003269195557
Validation loss: 1.9224087858712802

Epoch: 5| Step: 2
Training loss: 2.76692271232605
Validation loss: 1.9139052719198248

Epoch: 5| Step: 3
Training loss: 2.348520040512085
Validation loss: 1.9239599884197276

Epoch: 5| Step: 4
Training loss: 1.776633858680725
Validation loss: 1.924246020214532

Epoch: 5| Step: 5
Training loss: 1.9242916107177734
Validation loss: 1.9252730954077937

Epoch: 5| Step: 6
Training loss: 2.370068073272705
Validation loss: 1.926009993399343

Epoch: 5| Step: 7
Training loss: 2.129326343536377
Validation loss: 1.9193179774028

Epoch: 5| Step: 8
Training loss: 2.2305750846862793
Validation loss: 1.92476902725876

Epoch: 5| Step: 9
Training loss: 2.3525214195251465
Validation loss: 1.927583376566569

Epoch: 5| Step: 10
Training loss: 2.545197010040283
Validation loss: 1.9207168586792485

Epoch: 51| Step: 0
Training loss: 2.615556240081787
Validation loss: 1.9240629647367744

Epoch: 5| Step: 1
Training loss: 1.824114203453064
Validation loss: 1.923336809681308

Epoch: 5| Step: 2
Training loss: 2.586824893951416
Validation loss: 1.921097856695934

Epoch: 5| Step: 3
Training loss: 2.3188209533691406
Validation loss: 1.9314422402330624

Epoch: 5| Step: 4
Training loss: 2.057910203933716
Validation loss: 1.916673771796688

Epoch: 5| Step: 5
Training loss: 2.290593385696411
Validation loss: 1.9128891306538736

Epoch: 5| Step: 6
Training loss: 2.4809985160827637
Validation loss: 1.9363410242142216

Epoch: 5| Step: 7
Training loss: 2.2075812816619873
Validation loss: 1.9233483652914725

Epoch: 5| Step: 8
Training loss: 2.342125415802002
Validation loss: 1.9165896818202028

Epoch: 5| Step: 9
Training loss: 2.2014942169189453
Validation loss: 1.9164536486389816

Epoch: 5| Step: 10
Training loss: 2.638732671737671
Validation loss: 1.912950993866049

Epoch: 52| Step: 0
Training loss: 2.5610272884368896
Validation loss: 1.910831723161923

Epoch: 5| Step: 1
Training loss: 1.9504413604736328
Validation loss: 1.9106775765777917

Epoch: 5| Step: 2
Training loss: 3.149543285369873
Validation loss: 1.9235107552620672

Epoch: 5| Step: 3
Training loss: 2.308509349822998
Validation loss: 1.9240944244528329

Epoch: 5| Step: 4
Training loss: 2.5300793647766113
Validation loss: 1.9074323074792021

Epoch: 5| Step: 5
Training loss: 1.5710428953170776
Validation loss: 1.9198039577853294

Epoch: 5| Step: 6
Training loss: 2.3165104389190674
Validation loss: 1.9163290198131273

Epoch: 5| Step: 7
Training loss: 2.121445417404175
Validation loss: 1.91082162626328

Epoch: 5| Step: 8
Training loss: 2.5726356506347656
Validation loss: 1.9111600819454397

Epoch: 5| Step: 9
Training loss: 1.9936336278915405
Validation loss: 1.919598324324495

Epoch: 5| Step: 10
Training loss: 2.5426254272460938
Validation loss: 1.9113600343786261

Epoch: 53| Step: 0
Training loss: 1.7816669940948486
Validation loss: 1.9060217885560886

Epoch: 5| Step: 1
Training loss: 2.323273181915283
Validation loss: 1.915382787745486

Epoch: 5| Step: 2
Training loss: 1.945183515548706
Validation loss: 1.9099432088995492

Epoch: 5| Step: 3
Training loss: 2.017124652862549
Validation loss: 1.904029219381271

Epoch: 5| Step: 4
Training loss: 2.7548410892486572
Validation loss: 1.9198221339974353

Epoch: 5| Step: 5
Training loss: 2.492166757583618
Validation loss: 1.9143888027437272

Epoch: 5| Step: 6
Training loss: 2.7220005989074707
Validation loss: 1.919648644744709

Epoch: 5| Step: 7
Training loss: 2.0618975162506104
Validation loss: 1.914464036623637

Epoch: 5| Step: 8
Training loss: 2.328636407852173
Validation loss: 1.9229135167214177

Epoch: 5| Step: 9
Training loss: 2.5740890502929688
Validation loss: 1.9090608999293337

Epoch: 5| Step: 10
Training loss: 2.531759262084961
Validation loss: 1.9137744801018828

Epoch: 54| Step: 0
Training loss: 2.330667018890381
Validation loss: 1.9139607542304582

Epoch: 5| Step: 1
Training loss: 2.440305471420288
Validation loss: 1.9183827407898442

Epoch: 5| Step: 2
Training loss: 2.2695744037628174
Validation loss: 1.9200085645080895

Epoch: 5| Step: 3
Training loss: 1.9699742794036865
Validation loss: 1.9131167755332044

Epoch: 5| Step: 4
Training loss: 2.0707104206085205
Validation loss: 1.9205253944602063

Epoch: 5| Step: 5
Training loss: 1.9675222635269165
Validation loss: 1.9190445202653126

Epoch: 5| Step: 6
Training loss: 2.544583320617676
Validation loss: 1.923542650797034

Epoch: 5| Step: 7
Training loss: 2.558403491973877
Validation loss: 1.9299453073932278

Epoch: 5| Step: 8
Training loss: 2.441948413848877
Validation loss: 1.915937921052338

Epoch: 5| Step: 9
Training loss: 2.52677583694458
Validation loss: 1.9250188566023303

Epoch: 5| Step: 10
Training loss: 2.3029227256774902
Validation loss: 1.9152451228070002

Epoch: 55| Step: 0
Training loss: 1.9927232265472412
Validation loss: 1.9268128154098347

Epoch: 5| Step: 1
Training loss: 2.9516024589538574
Validation loss: 1.9186152783773278

Epoch: 5| Step: 2
Training loss: 2.3376100063323975
Validation loss: 1.91630264764191

Epoch: 5| Step: 3
Training loss: 1.9678337574005127
Validation loss: 1.9243564092984764

Epoch: 5| Step: 4
Training loss: 2.608412265777588
Validation loss: 1.9141778074285036

Epoch: 5| Step: 5
Training loss: 2.4061636924743652
Validation loss: 1.9119500626799881

Epoch: 5| Step: 6
Training loss: 2.6072371006011963
Validation loss: 1.9176303840452624

Epoch: 5| Step: 7
Training loss: 1.9670162200927734
Validation loss: 1.917345170051821

Epoch: 5| Step: 8
Training loss: 1.9423701763153076
Validation loss: 1.9347126714644893

Epoch: 5| Step: 9
Training loss: 2.2256298065185547
Validation loss: 1.9225838697084816

Epoch: 5| Step: 10
Training loss: 2.449751377105713
Validation loss: 1.9100221433947164

Epoch: 56| Step: 0
Training loss: 2.6779561042785645
Validation loss: 1.915922837872659

Epoch: 5| Step: 1
Training loss: 2.432260513305664
Validation loss: 1.9129000004901682

Epoch: 5| Step: 2
Training loss: 2.0619614124298096
Validation loss: 1.923655706067239

Epoch: 5| Step: 3
Training loss: 2.5174906253814697
Validation loss: 1.923637464482297

Epoch: 5| Step: 4
Training loss: 2.34907865524292
Validation loss: 1.9108363530969108

Epoch: 5| Step: 5
Training loss: 1.7956146001815796
Validation loss: 1.9200238566244803

Epoch: 5| Step: 6
Training loss: 2.241760730743408
Validation loss: 1.914195010738988

Epoch: 5| Step: 7
Training loss: 2.0954737663269043
Validation loss: 1.9148377680009412

Epoch: 5| Step: 8
Training loss: 2.468301773071289
Validation loss: 1.9063703603641962

Epoch: 5| Step: 9
Training loss: 2.353815793991089
Validation loss: 1.9017034986967682

Epoch: 5| Step: 10
Training loss: 2.28346586227417
Validation loss: 1.917003939228673

Epoch: 57| Step: 0
Training loss: 2.3128151893615723
Validation loss: 1.909603920034183

Epoch: 5| Step: 1
Training loss: 2.6340179443359375
Validation loss: 1.9063905323705366

Epoch: 5| Step: 2
Training loss: 2.460076093673706
Validation loss: 1.907809075488839

Epoch: 5| Step: 3
Training loss: 2.592514753341675
Validation loss: 1.9052426558668896

Epoch: 5| Step: 4
Training loss: 1.9644267559051514
Validation loss: 1.912298943406792

Epoch: 5| Step: 5
Training loss: 2.6688122749328613
Validation loss: 1.909778771861907

Epoch: 5| Step: 6
Training loss: 1.7572925090789795
Validation loss: 1.9112874718122586

Epoch: 5| Step: 7
Training loss: 2.0846030712127686
Validation loss: 1.9051565124142555

Epoch: 5| Step: 8
Training loss: 2.561781644821167
Validation loss: 1.9086493881799842

Epoch: 5| Step: 9
Training loss: 2.0562736988067627
Validation loss: 1.8952682402826124

Epoch: 5| Step: 10
Training loss: 2.197371006011963
Validation loss: 1.9131080873550907

Epoch: 58| Step: 0
Training loss: 2.3977444171905518
Validation loss: 1.917518997705111

Epoch: 5| Step: 1
Training loss: 2.352768898010254
Validation loss: 1.904162835049373

Epoch: 5| Step: 2
Training loss: 1.5571812391281128
Validation loss: 1.8996652492912867

Epoch: 5| Step: 3
Training loss: 2.1799604892730713
Validation loss: 1.9060495873933196

Epoch: 5| Step: 4
Training loss: 2.4666748046875
Validation loss: 1.9041017460566696

Epoch: 5| Step: 5
Training loss: 2.219137191772461
Validation loss: 1.901801351578005

Epoch: 5| Step: 6
Training loss: 2.6595957279205322
Validation loss: 1.9053609896731634

Epoch: 5| Step: 7
Training loss: 2.765916109085083
Validation loss: 1.9082714460229362

Epoch: 5| Step: 8
Training loss: 2.2796876430511475
Validation loss: 1.898129395259324

Epoch: 5| Step: 9
Training loss: 2.408308982849121
Validation loss: 1.9121436867662656

Epoch: 5| Step: 10
Training loss: 1.942076325416565
Validation loss: 1.8917459903224823

Epoch: 59| Step: 0
Training loss: 2.5932118892669678
Validation loss: 1.9076090128191057

Epoch: 5| Step: 1
Training loss: 2.6109132766723633
Validation loss: 1.9048726686867334

Epoch: 5| Step: 2
Training loss: 2.3585665225982666
Validation loss: 1.9018887345508864

Epoch: 5| Step: 3
Training loss: 2.409122943878174
Validation loss: 1.9074707851615003

Epoch: 5| Step: 4
Training loss: 2.1781482696533203
Validation loss: 1.901695305301297

Epoch: 5| Step: 5
Training loss: 1.9560915231704712
Validation loss: 1.9055074350808257

Epoch: 5| Step: 6
Training loss: 1.9036462306976318
Validation loss: 1.9003499284867318

Epoch: 5| Step: 7
Training loss: 2.1718451976776123
Validation loss: 1.898979667694338

Epoch: 5| Step: 8
Training loss: 2.4539594650268555
Validation loss: 1.8870999120896863

Epoch: 5| Step: 9
Training loss: 2.290705680847168
Validation loss: 1.9040061402064499

Epoch: 5| Step: 10
Training loss: 2.2288734912872314
Validation loss: 1.9012164761943202

Epoch: 60| Step: 0
Training loss: 2.1094777584075928
Validation loss: 1.9010228341625584

Epoch: 5| Step: 1
Training loss: 2.5585474967956543
Validation loss: 1.9040805678213797

Epoch: 5| Step: 2
Training loss: 2.049448013305664
Validation loss: 1.9002278927833802

Epoch: 5| Step: 3
Training loss: 2.7979989051818848
Validation loss: 1.901143152226684

Epoch: 5| Step: 4
Training loss: 2.5610756874084473
Validation loss: 1.891429070503481

Epoch: 5| Step: 5
Training loss: 1.7479686737060547
Validation loss: 1.8854339327863467

Epoch: 5| Step: 6
Training loss: 1.9412858486175537
Validation loss: 1.8977354918756792

Epoch: 5| Step: 7
Training loss: 2.2244510650634766
Validation loss: 1.9031576700108026

Epoch: 5| Step: 8
Training loss: 2.348437786102295
Validation loss: 1.889115374575379

Epoch: 5| Step: 9
Training loss: 2.6625285148620605
Validation loss: 1.8951185441786242

Epoch: 5| Step: 10
Training loss: 2.179377555847168
Validation loss: 1.8867878580606112

Epoch: 61| Step: 0
Training loss: 2.5456511974334717
Validation loss: 1.895559134021882

Epoch: 5| Step: 1
Training loss: 2.2339704036712646
Validation loss: 1.8928272467787548

Epoch: 5| Step: 2
Training loss: 2.1321277618408203
Validation loss: 1.8888457526442826

Epoch: 5| Step: 3
Training loss: 2.3045804500579834
Validation loss: 1.8933491745302755

Epoch: 5| Step: 4
Training loss: 2.2701470851898193
Validation loss: 1.8953119952191588

Epoch: 5| Step: 5
Training loss: 2.350158214569092
Validation loss: 1.8916552861531575

Epoch: 5| Step: 6
Training loss: 2.299464225769043
Validation loss: 1.9094000298489806

Epoch: 5| Step: 7
Training loss: 2.2842299938201904
Validation loss: 1.8898963671858593

Epoch: 5| Step: 8
Training loss: 2.534538507461548
Validation loss: 1.8969917963909846

Epoch: 5| Step: 9
Training loss: 2.127800464630127
Validation loss: 1.897754164152248

Epoch: 5| Step: 10
Training loss: 2.019341230392456
Validation loss: 1.893382526213123

Epoch: 62| Step: 0
Training loss: 1.6782947778701782
Validation loss: 1.8970499371969571

Epoch: 5| Step: 1
Training loss: 2.589648723602295
Validation loss: 1.9035232541381673

Epoch: 5| Step: 2
Training loss: 2.1825203895568848
Validation loss: 1.8946499465614237

Epoch: 5| Step: 3
Training loss: 2.2062833309173584
Validation loss: 1.8826051655636038

Epoch: 5| Step: 4
Training loss: 2.6648380756378174
Validation loss: 1.8844173544196672

Epoch: 5| Step: 5
Training loss: 1.999638319015503
Validation loss: 1.8898884839909051

Epoch: 5| Step: 6
Training loss: 2.0885238647460938
Validation loss: 1.8921803812826834

Epoch: 5| Step: 7
Training loss: 1.8899602890014648
Validation loss: 1.8851860646278626

Epoch: 5| Step: 8
Training loss: 2.7528798580169678
Validation loss: 1.8949284194618143

Epoch: 5| Step: 9
Training loss: 2.250044822692871
Validation loss: 1.893169613294704

Epoch: 5| Step: 10
Training loss: 2.8352293968200684
Validation loss: 1.8985982312951037

Epoch: 63| Step: 0
Training loss: 2.402785062789917
Validation loss: 1.8936879852766633

Epoch: 5| Step: 1
Training loss: 2.42403244972229
Validation loss: 1.8895916605508456

Epoch: 5| Step: 2
Training loss: 2.7250962257385254
Validation loss: 1.896366391130673

Epoch: 5| Step: 3
Training loss: 2.2081525325775146
Validation loss: 1.8932591868985085

Epoch: 5| Step: 4
Training loss: 2.341559886932373
Validation loss: 1.8954491640931816

Epoch: 5| Step: 5
Training loss: 2.160299777984619
Validation loss: 1.8948159076834237

Epoch: 5| Step: 6
Training loss: 2.0434584617614746
Validation loss: 1.8880110248442619

Epoch: 5| Step: 7
Training loss: 2.2924129962921143
Validation loss: 1.8840398557724491

Epoch: 5| Step: 8
Training loss: 1.9021562337875366
Validation loss: 1.8859157959620159

Epoch: 5| Step: 9
Training loss: 2.4159436225891113
Validation loss: 1.9041682879130046

Epoch: 5| Step: 10
Training loss: 2.1369287967681885
Validation loss: 1.88577179754934

Epoch: 64| Step: 0
Training loss: 1.768276572227478
Validation loss: 1.883077709905563

Epoch: 5| Step: 1
Training loss: 2.488189220428467
Validation loss: 1.88480088274966

Epoch: 5| Step: 2
Training loss: 2.049332857131958
Validation loss: 1.887920512947985

Epoch: 5| Step: 3
Training loss: 2.1209335327148438
Validation loss: 1.8761480803130774

Epoch: 5| Step: 4
Training loss: 1.7847957611083984
Validation loss: 1.8923429237898959

Epoch: 5| Step: 5
Training loss: 2.076582431793213
Validation loss: 1.8872364285171672

Epoch: 5| Step: 6
Training loss: 2.610926389694214
Validation loss: 1.8964265123490365

Epoch: 5| Step: 7
Training loss: 2.0171751976013184
Validation loss: 1.8819178278728197

Epoch: 5| Step: 8
Training loss: 2.7336294651031494
Validation loss: 1.883911386612923

Epoch: 5| Step: 9
Training loss: 2.670866012573242
Validation loss: 1.8845800251089118

Epoch: 5| Step: 10
Training loss: 2.785195827484131
Validation loss: 1.8845938828683668

Epoch: 65| Step: 0
Training loss: 2.1512792110443115
Validation loss: 1.8784833018497755

Epoch: 5| Step: 1
Training loss: 1.855531930923462
Validation loss: 1.8866116346851471

Epoch: 5| Step: 2
Training loss: 2.515542507171631
Validation loss: 1.8825866176236061

Epoch: 5| Step: 3
Training loss: 1.8393285274505615
Validation loss: 1.892429381288508

Epoch: 5| Step: 4
Training loss: 2.521235227584839
Validation loss: 1.8928072965273293

Epoch: 5| Step: 5
Training loss: 2.4505951404571533
Validation loss: 1.890602155398297

Epoch: 5| Step: 6
Training loss: 2.306062936782837
Validation loss: 1.885388034646229

Epoch: 5| Step: 7
Training loss: 2.5653557777404785
Validation loss: 1.895517397952336

Epoch: 5| Step: 8
Training loss: 2.4331657886505127
Validation loss: 1.8880042106874528

Epoch: 5| Step: 9
Training loss: 2.2340023517608643
Validation loss: 1.8941761037354827

Epoch: 5| Step: 10
Training loss: 2.053831100463867
Validation loss: 1.910257807341955

Epoch: 66| Step: 0
Training loss: 2.7163310050964355
Validation loss: 1.8867384874692528

Epoch: 5| Step: 1
Training loss: 2.9987730979919434
Validation loss: 1.8884584672989384

Epoch: 5| Step: 2
Training loss: 2.2908706665039062
Validation loss: 1.8973300072454637

Epoch: 5| Step: 3
Training loss: 2.084390163421631
Validation loss: 1.8886793454488118

Epoch: 5| Step: 4
Training loss: 1.5909887552261353
Validation loss: 1.8957016955139816

Epoch: 5| Step: 5
Training loss: 2.575005054473877
Validation loss: 1.8991649266212218

Epoch: 5| Step: 6
Training loss: 2.163154125213623
Validation loss: 1.8860082241796678

Epoch: 5| Step: 7
Training loss: 2.0070807933807373
Validation loss: 1.8806470581280288

Epoch: 5| Step: 8
Training loss: 2.2771718502044678
Validation loss: 1.8805459878777946

Epoch: 5| Step: 9
Training loss: 2.076077699661255
Validation loss: 1.882099800212409

Epoch: 5| Step: 10
Training loss: 2.1917026042938232
Validation loss: 1.8794036232015139

Epoch: 67| Step: 0
Training loss: 1.9778083562850952
Validation loss: 1.8883897950572353

Epoch: 5| Step: 1
Training loss: 2.701047658920288
Validation loss: 1.8848760922749836

Epoch: 5| Step: 2
Training loss: 2.6958632469177246
Validation loss: 1.897881789874005

Epoch: 5| Step: 3
Training loss: 1.588932991027832
Validation loss: 1.8855417941206245

Epoch: 5| Step: 4
Training loss: 2.2060272693634033
Validation loss: 1.8813341292001868

Epoch: 5| Step: 5
Training loss: 2.116365432739258
Validation loss: 1.8917492589642924

Epoch: 5| Step: 6
Training loss: 2.3298134803771973
Validation loss: 1.8907389281898417

Epoch: 5| Step: 7
Training loss: 2.863668918609619
Validation loss: 1.8847984537001579

Epoch: 5| Step: 8
Training loss: 2.1687402725219727
Validation loss: 1.8957290982687345

Epoch: 5| Step: 9
Training loss: 2.3621418476104736
Validation loss: 1.8796051227918236

Epoch: 5| Step: 10
Training loss: 1.7032963037490845
Validation loss: 1.8865126256019837

Epoch: 68| Step: 0
Training loss: 2.83994722366333
Validation loss: 1.885015715834915

Epoch: 5| Step: 1
Training loss: 2.2129414081573486
Validation loss: 1.8836178023328063

Epoch: 5| Step: 2
Training loss: 1.6785571575164795
Validation loss: 1.8782220886599632

Epoch: 5| Step: 3
Training loss: 1.918948769569397
Validation loss: 1.875401722487583

Epoch: 5| Step: 4
Training loss: 2.6268844604492188
Validation loss: 1.8904645481417257

Epoch: 5| Step: 5
Training loss: 2.8233466148376465
Validation loss: 1.8723511452315955

Epoch: 5| Step: 6
Training loss: 1.785668969154358
Validation loss: 1.8910737691387054

Epoch: 5| Step: 7
Training loss: 1.8090715408325195
Validation loss: 1.8806855140193817

Epoch: 5| Step: 8
Training loss: 2.3292794227600098
Validation loss: 1.8672078835066928

Epoch: 5| Step: 9
Training loss: 2.7809555530548096
Validation loss: 1.8684279072669245

Epoch: 5| Step: 10
Training loss: 1.9590591192245483
Validation loss: 1.883103996194819

Epoch: 69| Step: 0
Training loss: 2.5066046714782715
Validation loss: 1.8712136950544132

Epoch: 5| Step: 1
Training loss: 2.4225096702575684
Validation loss: 1.8795630944672452

Epoch: 5| Step: 2
Training loss: 2.1354033946990967
Validation loss: 1.8645656929221204

Epoch: 5| Step: 3
Training loss: 2.4160473346710205
Validation loss: 1.8769594559105494

Epoch: 5| Step: 4
Training loss: 2.335106372833252
Validation loss: 1.8726680342869093

Epoch: 5| Step: 5
Training loss: 2.3400802612304688
Validation loss: 1.8891584975745088

Epoch: 5| Step: 6
Training loss: 2.4124755859375
Validation loss: 1.866300921286306

Epoch: 5| Step: 7
Training loss: 2.2230019569396973
Validation loss: 1.8799524063705115

Epoch: 5| Step: 8
Training loss: 2.0124154090881348
Validation loss: 1.8829718982019732

Epoch: 5| Step: 9
Training loss: 2.156409740447998
Validation loss: 1.8823100994992

Epoch: 5| Step: 10
Training loss: 1.802072286605835
Validation loss: 1.8659287652661722

Epoch: 70| Step: 0
Training loss: 1.952491044998169
Validation loss: 1.8759823665823987

Epoch: 5| Step: 1
Training loss: 2.117187023162842
Validation loss: 1.8660533530737764

Epoch: 5| Step: 2
Training loss: 2.534384250640869
Validation loss: 1.8736624486984745

Epoch: 5| Step: 3
Training loss: 1.8058557510375977
Validation loss: 1.8833655952125468

Epoch: 5| Step: 4
Training loss: 2.1483378410339355
Validation loss: 1.8710625569025676

Epoch: 5| Step: 5
Training loss: 1.8254066705703735
Validation loss: 1.8696414219435824

Epoch: 5| Step: 6
Training loss: 2.576641082763672
Validation loss: 1.867358971667546

Epoch: 5| Step: 7
Training loss: 2.0928070545196533
Validation loss: 1.8704496609267367

Epoch: 5| Step: 8
Training loss: 2.3596272468566895
Validation loss: 1.8781168101936259

Epoch: 5| Step: 9
Training loss: 2.584531307220459
Validation loss: 1.8711443947207542

Epoch: 5| Step: 10
Training loss: 2.839299201965332
Validation loss: 1.8678751773731683

Epoch: 71| Step: 0
Training loss: 2.4878971576690674
Validation loss: 1.8760042421279415

Epoch: 5| Step: 1
Training loss: 2.152830123901367
Validation loss: 1.873361538815242

Epoch: 5| Step: 2
Training loss: 2.573223829269409
Validation loss: 1.8652840378463909

Epoch: 5| Step: 3
Training loss: 2.0154781341552734
Validation loss: 1.8755469181204354

Epoch: 5| Step: 4
Training loss: 2.5972304344177246
Validation loss: 1.8746379690785562

Epoch: 5| Step: 5
Training loss: 2.623267650604248
Validation loss: 1.8813404383197907

Epoch: 5| Step: 6
Training loss: 1.5020722150802612
Validation loss: 1.8643283254356795

Epoch: 5| Step: 7
Training loss: 2.5439743995666504
Validation loss: 1.8756109296634633

Epoch: 5| Step: 8
Training loss: 2.7325222492218018
Validation loss: 1.8693534071727465

Epoch: 5| Step: 9
Training loss: 1.6864063739776611
Validation loss: 1.8798133814206688

Epoch: 5| Step: 10
Training loss: 1.768279790878296
Validation loss: 1.8746264057774698

Epoch: 72| Step: 0
Training loss: 2.0318081378936768
Validation loss: 1.8715840578079224

Epoch: 5| Step: 1
Training loss: 2.2826650142669678
Validation loss: 1.8771592481161958

Epoch: 5| Step: 2
Training loss: 2.0293405055999756
Validation loss: 1.8761513797185754

Epoch: 5| Step: 3
Training loss: 2.1546378135681152
Validation loss: 1.8735853625882057

Epoch: 5| Step: 4
Training loss: 2.296616792678833
Validation loss: 1.8722001814073133

Epoch: 5| Step: 5
Training loss: 1.6135565042495728
Validation loss: 1.8861031006741267

Epoch: 5| Step: 6
Training loss: 2.5599820613861084
Validation loss: 1.8817883409479612

Epoch: 5| Step: 7
Training loss: 2.2430825233459473
Validation loss: 1.8745942000419862

Epoch: 5| Step: 8
Training loss: 2.5856449604034424
Validation loss: 1.875666913165841

Epoch: 5| Step: 9
Training loss: 2.9039883613586426
Validation loss: 1.864133055492114

Epoch: 5| Step: 10
Training loss: 1.970123291015625
Validation loss: 1.8689880550548594

Epoch: 73| Step: 0
Training loss: 1.5231298208236694
Validation loss: 1.8710881574179536

Epoch: 5| Step: 1
Training loss: 2.8818695545196533
Validation loss: 1.8815016977248653

Epoch: 5| Step: 2
Training loss: 2.2517571449279785
Validation loss: 1.876875562052573

Epoch: 5| Step: 3
Training loss: 3.1819052696228027
Validation loss: 1.8633217542402205

Epoch: 5| Step: 4
Training loss: 2.3336527347564697
Validation loss: 1.8707687854766846

Epoch: 5| Step: 5
Training loss: 2.0981268882751465
Validation loss: 1.8778474792357414

Epoch: 5| Step: 6
Training loss: 1.9755144119262695
Validation loss: 1.8594812423952165

Epoch: 5| Step: 7
Training loss: 2.0398144721984863
Validation loss: 1.8779213556679346

Epoch: 5| Step: 8
Training loss: 1.8509948253631592
Validation loss: 1.8879235252257316

Epoch: 5| Step: 9
Training loss: 2.150980234146118
Validation loss: 1.8782806268302343

Epoch: 5| Step: 10
Training loss: 2.381258964538574
Validation loss: 1.8779602358418126

Epoch: 74| Step: 0
Training loss: 2.6333725452423096
Validation loss: 1.8746239805734286

Epoch: 5| Step: 1
Training loss: 1.8710358142852783
Validation loss: 1.8709029741184686

Epoch: 5| Step: 2
Training loss: 1.8555042743682861
Validation loss: 1.8653318753806494

Epoch: 5| Step: 3
Training loss: 2.4547622203826904
Validation loss: 1.8763397662870345

Epoch: 5| Step: 4
Training loss: 2.4951682090759277
Validation loss: 1.8651123636512346

Epoch: 5| Step: 5
Training loss: 2.6091396808624268
Validation loss: 1.875671794337611

Epoch: 5| Step: 6
Training loss: 2.930720090866089
Validation loss: 1.887292690174554

Epoch: 5| Step: 7
Training loss: 1.7792117595672607
Validation loss: 1.8765642796793292

Epoch: 5| Step: 8
Training loss: 2.075373411178589
Validation loss: 1.8711975723184564

Epoch: 5| Step: 9
Training loss: 1.7066367864608765
Validation loss: 1.8654876268038185

Epoch: 5| Step: 10
Training loss: 2.1558268070220947
Validation loss: 1.8532469785341652

Epoch: 75| Step: 0
Training loss: 1.9852384328842163
Validation loss: 1.8736259770649735

Epoch: 5| Step: 1
Training loss: 1.6471303701400757
Validation loss: 1.8544276683561263

Epoch: 5| Step: 2
Training loss: 1.9331763982772827
Validation loss: 1.8725195815486293

Epoch: 5| Step: 3
Training loss: 3.1496918201446533
Validation loss: 1.8840638001759846

Epoch: 5| Step: 4
Training loss: 2.612860679626465
Validation loss: 1.864631147794826

Epoch: 5| Step: 5
Training loss: 2.4360244274139404
Validation loss: 1.8786651562618952

Epoch: 5| Step: 6
Training loss: 2.2581241130828857
Validation loss: 1.8703774175336283

Epoch: 5| Step: 7
Training loss: 1.8864980936050415
Validation loss: 1.8563360808998026

Epoch: 5| Step: 8
Training loss: 1.8246333599090576
Validation loss: 1.8572454170514179

Epoch: 5| Step: 9
Training loss: 2.346219539642334
Validation loss: 1.8517928097837715

Epoch: 5| Step: 10
Training loss: 2.533557176589966
Validation loss: 1.8736032978180917

Epoch: 76| Step: 0
Training loss: 2.087299346923828
Validation loss: 1.867776613081655

Epoch: 5| Step: 1
Training loss: 3.2472660541534424
Validation loss: 1.8740120036627657

Epoch: 5| Step: 2
Training loss: 1.6278409957885742
Validation loss: 1.881487368255533

Epoch: 5| Step: 3
Training loss: 1.9081436395645142
Validation loss: 1.8648368184284498

Epoch: 5| Step: 4
Training loss: 2.6921916007995605
Validation loss: 1.8665880874920917

Epoch: 5| Step: 5
Training loss: 2.2034499645233154
Validation loss: 1.8759067558473157

Epoch: 5| Step: 6
Training loss: 1.6074025630950928
Validation loss: 1.8654198018453454

Epoch: 5| Step: 7
Training loss: 2.096104860305786
Validation loss: 1.8733547887494486

Epoch: 5| Step: 8
Training loss: 2.2919821739196777
Validation loss: 1.849916756794017

Epoch: 5| Step: 9
Training loss: 2.258434534072876
Validation loss: 1.871151226823048

Epoch: 5| Step: 10
Training loss: 2.57098126411438
Validation loss: 1.871559243048391

Epoch: 77| Step: 0
Training loss: 2.155224084854126
Validation loss: 1.8645077751528831

Epoch: 5| Step: 1
Training loss: 2.497013568878174
Validation loss: 1.861799511858212

Epoch: 5| Step: 2
Training loss: 2.0503945350646973
Validation loss: 1.8700666863431212

Epoch: 5| Step: 3
Training loss: 2.592301845550537
Validation loss: 1.8790809851820751

Epoch: 5| Step: 4
Training loss: 2.2243399620056152
Validation loss: 1.8696880109848515

Epoch: 5| Step: 5
Training loss: 2.633971691131592
Validation loss: 1.86203553599696

Epoch: 5| Step: 6
Training loss: 2.55289626121521
Validation loss: 1.8622173442635486

Epoch: 5| Step: 7
Training loss: 2.0477747917175293
Validation loss: 1.8676734137278732

Epoch: 5| Step: 8
Training loss: 2.4691243171691895
Validation loss: 1.8624797803099438

Epoch: 5| Step: 9
Training loss: 1.481215000152588
Validation loss: 1.865767801961591

Epoch: 5| Step: 10
Training loss: 1.6225979328155518
Validation loss: 1.8520504800222253

Epoch: 78| Step: 0
Training loss: 1.6225392818450928
Validation loss: 1.8550115644290883

Epoch: 5| Step: 1
Training loss: 2.074915647506714
Validation loss: 1.8631417879494288

Epoch: 5| Step: 2
Training loss: 2.847546100616455
Validation loss: 1.8559440002646497

Epoch: 5| Step: 3
Training loss: 2.591776132583618
Validation loss: 1.8707913429506364

Epoch: 5| Step: 4
Training loss: 1.7267084121704102
Validation loss: 1.8613714377085369

Epoch: 5| Step: 5
Training loss: 2.533137321472168
Validation loss: 1.8678418846540554

Epoch: 5| Step: 6
Training loss: 2.568471670150757
Validation loss: 1.8505770775579637

Epoch: 5| Step: 7
Training loss: 2.0097262859344482
Validation loss: 1.8534561767373035

Epoch: 5| Step: 8
Training loss: 1.9623839855194092
Validation loss: 1.8638313354984406

Epoch: 5| Step: 9
Training loss: 2.29974102973938
Validation loss: 1.8570126961636286

Epoch: 5| Step: 10
Training loss: 2.2590689659118652
Validation loss: 1.8592004212000037

Epoch: 79| Step: 0
Training loss: 2.966024398803711
Validation loss: 1.8626946659498318

Epoch: 5| Step: 1
Training loss: 1.8753608465194702
Validation loss: 1.868534440635353

Epoch: 5| Step: 2
Training loss: 1.9600788354873657
Validation loss: 1.847970627969311

Epoch: 5| Step: 3
Training loss: 2.5482165813446045
Validation loss: 1.866267966967757

Epoch: 5| Step: 4
Training loss: 2.4682600498199463
Validation loss: 1.8613441477539718

Epoch: 5| Step: 5
Training loss: 2.228783369064331
Validation loss: 1.8750748249792284

Epoch: 5| Step: 6
Training loss: 1.7847391366958618
Validation loss: 1.8620440549747919

Epoch: 5| Step: 7
Training loss: 2.277146577835083
Validation loss: 1.8643652598063152

Epoch: 5| Step: 8
Training loss: 1.8356406688690186
Validation loss: 1.855083482239836

Epoch: 5| Step: 9
Training loss: 2.3405094146728516
Validation loss: 1.8704793914671867

Epoch: 5| Step: 10
Training loss: 2.214567184448242
Validation loss: 1.8684732247424383

Epoch: 80| Step: 0
Training loss: 1.8469902276992798
Validation loss: 1.87268022055267

Epoch: 5| Step: 1
Training loss: 2.426687240600586
Validation loss: 1.8852712569698211

Epoch: 5| Step: 2
Training loss: 2.0340662002563477
Validation loss: 1.8706241935812018

Epoch: 5| Step: 3
Training loss: 2.2279934883117676
Validation loss: 1.8801355259392851

Epoch: 5| Step: 4
Training loss: 2.101864814758301
Validation loss: 1.8760888332961707

Epoch: 5| Step: 5
Training loss: 1.946266770362854
Validation loss: 1.8769636320811447

Epoch: 5| Step: 6
Training loss: 2.6638400554656982
Validation loss: 1.8759214954991494

Epoch: 5| Step: 7
Training loss: 1.7954776287078857
Validation loss: 1.8827901886355491

Epoch: 5| Step: 8
Training loss: 2.1401257514953613
Validation loss: 1.8600382676688574

Epoch: 5| Step: 9
Training loss: 2.330038070678711
Validation loss: 1.864063477003446

Epoch: 5| Step: 10
Training loss: 2.9655210971832275
Validation loss: 1.8648196779271609

Epoch: 81| Step: 0
Training loss: 1.7882087230682373
Validation loss: 1.8712645807573873

Epoch: 5| Step: 1
Training loss: 2.3096377849578857
Validation loss: 1.863216571910407

Epoch: 5| Step: 2
Training loss: 2.355834484100342
Validation loss: 1.8659811365988948

Epoch: 5| Step: 3
Training loss: 1.8049681186676025
Validation loss: 1.872158419701361

Epoch: 5| Step: 4
Training loss: 2.127225160598755
Validation loss: 1.8670671793722338

Epoch: 5| Step: 5
Training loss: 2.2478225231170654
Validation loss: 1.8558569890196606

Epoch: 5| Step: 6
Training loss: 2.061389207839966
Validation loss: 1.8797473112742107

Epoch: 5| Step: 7
Training loss: 2.539588451385498
Validation loss: 1.857866624350189

Epoch: 5| Step: 8
Training loss: 2.406273603439331
Validation loss: 1.8619914221507248

Epoch: 5| Step: 9
Training loss: 2.4311280250549316
Validation loss: 1.8626709010011406

Epoch: 5| Step: 10
Training loss: 2.367945909500122
Validation loss: 1.8604574414991564

Epoch: 82| Step: 0
Training loss: 2.271475315093994
Validation loss: 1.8535534592084988

Epoch: 5| Step: 1
Training loss: 2.0257697105407715
Validation loss: 1.8590187180426814

Epoch: 5| Step: 2
Training loss: 1.6699730157852173
Validation loss: 1.846840170121962

Epoch: 5| Step: 3
Training loss: 2.193061113357544
Validation loss: 1.847694589245704

Epoch: 5| Step: 4
Training loss: 2.1911780834198
Validation loss: 1.8552115681350871

Epoch: 5| Step: 5
Training loss: 1.9493144750595093
Validation loss: 1.8752507983997304

Epoch: 5| Step: 6
Training loss: 2.041503429412842
Validation loss: 1.8612244834182083

Epoch: 5| Step: 7
Training loss: 2.431962728500366
Validation loss: 1.8603634167742986

Epoch: 5| Step: 8
Training loss: 2.714144229888916
Validation loss: 1.858149379812261

Epoch: 5| Step: 9
Training loss: 2.507213592529297
Validation loss: 1.8667219364514915

Epoch: 5| Step: 10
Training loss: 2.248253107070923
Validation loss: 1.8612821358506397

Epoch: 83| Step: 0
Training loss: 2.204794406890869
Validation loss: 1.8534736517936952

Epoch: 5| Step: 1
Training loss: 2.2284679412841797
Validation loss: 1.8597717310792656

Epoch: 5| Step: 2
Training loss: 1.8932898044586182
Validation loss: 1.8493926140569872

Epoch: 5| Step: 3
Training loss: 2.387399196624756
Validation loss: 1.8779675729813115

Epoch: 5| Step: 4
Training loss: 2.172438859939575
Validation loss: 1.8434672035196775

Epoch: 5| Step: 5
Training loss: 2.1959118843078613
Validation loss: 1.8589072637660529

Epoch: 5| Step: 6
Training loss: 1.8825767040252686
Validation loss: 1.8681286099136516

Epoch: 5| Step: 7
Training loss: 2.055194139480591
Validation loss: 1.8537506864916893

Epoch: 5| Step: 8
Training loss: 2.290780544281006
Validation loss: 1.8680101812526744

Epoch: 5| Step: 9
Training loss: 2.3377277851104736
Validation loss: 1.8531687105855634

Epoch: 5| Step: 10
Training loss: 2.6774847507476807
Validation loss: 1.8496920383104714

Epoch: 84| Step: 0
Training loss: 2.3412041664123535
Validation loss: 1.8571594876627768

Epoch: 5| Step: 1
Training loss: 1.760571837425232
Validation loss: 1.8487034369540472

Epoch: 5| Step: 2
Training loss: 2.0025036334991455
Validation loss: 1.8658968479402605

Epoch: 5| Step: 3
Training loss: 2.149228572845459
Validation loss: 1.8616499464998963

Epoch: 5| Step: 4
Training loss: 2.078622341156006
Validation loss: 1.8688783209810975

Epoch: 5| Step: 5
Training loss: 2.95540189743042
Validation loss: 1.8568442816375403

Epoch: 5| Step: 6
Training loss: 2.016524314880371
Validation loss: 1.850296481963127

Epoch: 5| Step: 7
Training loss: 2.4084362983703613
Validation loss: 1.8670870668144637

Epoch: 5| Step: 8
Training loss: 2.2155795097351074
Validation loss: 1.8654349209159933

Epoch: 5| Step: 9
Training loss: 2.5570621490478516
Validation loss: 1.8542058980593117

Epoch: 5| Step: 10
Training loss: 1.766725778579712
Validation loss: 1.8550865829631846

Epoch: 85| Step: 0
Training loss: 2.289337158203125
Validation loss: 1.875964831280452

Epoch: 5| Step: 1
Training loss: 2.064124584197998
Validation loss: 1.8566968953737648

Epoch: 5| Step: 2
Training loss: 2.1345269680023193
Validation loss: 1.8616868706159695

Epoch: 5| Step: 3
Training loss: 2.565398693084717
Validation loss: 1.8546069129820792

Epoch: 5| Step: 4
Training loss: 2.4818978309631348
Validation loss: 1.8589877159364763

Epoch: 5| Step: 5
Training loss: 2.4221134185791016
Validation loss: 1.842588697710345

Epoch: 5| Step: 6
Training loss: 2.22751522064209
Validation loss: 1.86138105136092

Epoch: 5| Step: 7
Training loss: 1.9707629680633545
Validation loss: 1.838877667662918

Epoch: 5| Step: 8
Training loss: 1.7426025867462158
Validation loss: 1.8504600794084611

Epoch: 5| Step: 9
Training loss: 2.2215428352355957
Validation loss: 1.8552614181272444

Epoch: 5| Step: 10
Training loss: 2.029920816421509
Validation loss: 1.848573725710633

Epoch: 86| Step: 0
Training loss: 1.9605661630630493
Validation loss: 1.8374951206227785

Epoch: 5| Step: 1
Training loss: 2.5396745204925537
Validation loss: 1.8493972645010999

Epoch: 5| Step: 2
Training loss: 2.089432716369629
Validation loss: 1.853818739614179

Epoch: 5| Step: 3
Training loss: 1.9147930145263672
Validation loss: 1.8566288717331425

Epoch: 5| Step: 4
Training loss: 1.9229705333709717
Validation loss: 1.8572742862086142

Epoch: 5| Step: 5
Training loss: 2.5249135494232178
Validation loss: 1.849171128324283

Epoch: 5| Step: 6
Training loss: 2.188784122467041
Validation loss: 1.842570456125403

Epoch: 5| Step: 7
Training loss: 2.231301784515381
Validation loss: 1.8692141861043952

Epoch: 5| Step: 8
Training loss: 2.0477607250213623
Validation loss: 1.8406048410682267

Epoch: 5| Step: 9
Training loss: 2.1453747749328613
Validation loss: 1.8549455032553723

Epoch: 5| Step: 10
Training loss: 2.5313913822174072
Validation loss: 1.8505281991856073

Epoch: 87| Step: 0
Training loss: 2.2557132244110107
Validation loss: 1.8573113000521095

Epoch: 5| Step: 1
Training loss: 2.1224758625030518
Validation loss: 1.8521709288320234

Epoch: 5| Step: 2
Training loss: 2.181443929672241
Validation loss: 1.8525925605527815

Epoch: 5| Step: 3
Training loss: 2.222174882888794
Validation loss: 1.8629982266374814

Epoch: 5| Step: 4
Training loss: 2.6618123054504395
Validation loss: 1.8496947942241546

Epoch: 5| Step: 5
Training loss: 2.232414722442627
Validation loss: 1.847811081076181

Epoch: 5| Step: 6
Training loss: 2.321294069290161
Validation loss: 1.8586679914946198

Epoch: 5| Step: 7
Training loss: 2.2281956672668457
Validation loss: 1.8580465906409807

Epoch: 5| Step: 8
Training loss: 2.0412795543670654
Validation loss: 1.852484062153806

Epoch: 5| Step: 9
Training loss: 1.8313367366790771
Validation loss: 1.8713863998331048

Epoch: 5| Step: 10
Training loss: 1.957910418510437
Validation loss: 1.8415837826267365

Epoch: 88| Step: 0
Training loss: 2.2105841636657715
Validation loss: 1.8516921484342186

Epoch: 5| Step: 1
Training loss: 1.832406997680664
Validation loss: 1.869636897117861

Epoch: 5| Step: 2
Training loss: 2.736027479171753
Validation loss: 1.8633361567733109

Epoch: 5| Step: 3
Training loss: 2.1315865516662598
Validation loss: 1.8558947527280418

Epoch: 5| Step: 4
Training loss: 1.8306324481964111
Validation loss: 1.8626121372304938

Epoch: 5| Step: 5
Training loss: 2.2366013526916504
Validation loss: 1.8563454612608878

Epoch: 5| Step: 6
Training loss: 2.135329484939575
Validation loss: 1.8405807838645032

Epoch: 5| Step: 7
Training loss: 1.9656791687011719
Validation loss: 1.8589659455001994

Epoch: 5| Step: 8
Training loss: 2.5964272022247314
Validation loss: 1.8706788029721988

Epoch: 5| Step: 9
Training loss: 2.009343385696411
Validation loss: 1.866879968233006

Epoch: 5| Step: 10
Training loss: 2.3777897357940674
Validation loss: 1.8547053926734514

Epoch: 89| Step: 0
Training loss: 2.2849385738372803
Validation loss: 1.84927414565958

Epoch: 5| Step: 1
Training loss: 1.5644656419754028
Validation loss: 1.8591133522731003

Epoch: 5| Step: 2
Training loss: 2.4286704063415527
Validation loss: 1.856746873547954

Epoch: 5| Step: 3
Training loss: 1.8818995952606201
Validation loss: 1.8601613019102363

Epoch: 5| Step: 4
Training loss: 1.9441684484481812
Validation loss: 1.8577741781870525

Epoch: 5| Step: 5
Training loss: 2.591343402862549
Validation loss: 1.8558045253958753

Epoch: 5| Step: 6
Training loss: 2.208437919616699
Validation loss: 1.8482378887873825

Epoch: 5| Step: 7
Training loss: 2.1163601875305176
Validation loss: 1.8421141703923543

Epoch: 5| Step: 8
Training loss: 2.26493501663208
Validation loss: 1.828000707011069

Epoch: 5| Step: 9
Training loss: 2.511751651763916
Validation loss: 1.8410809270797237

Epoch: 5| Step: 10
Training loss: 2.14102840423584
Validation loss: 1.8471827596746466

Epoch: 90| Step: 0
Training loss: 2.465845823287964
Validation loss: 1.832285633651159

Epoch: 5| Step: 1
Training loss: 2.062227964401245
Validation loss: 1.843928406315465

Epoch: 5| Step: 2
Training loss: 3.8359451293945312
Validation loss: 1.8388770113709152

Epoch: 5| Step: 3
Training loss: 1.9976552724838257
Validation loss: 1.852728888552676

Epoch: 5| Step: 4
Training loss: 1.6786197423934937
Validation loss: 1.8461447338904104

Epoch: 5| Step: 5
Training loss: 1.956396460533142
Validation loss: 1.8449327074071413

Epoch: 5| Step: 6
Training loss: 1.6762977838516235
Validation loss: 1.8605510932143017

Epoch: 5| Step: 7
Training loss: 2.145244598388672
Validation loss: 1.8531028070757467

Epoch: 5| Step: 8
Training loss: 1.7015655040740967
Validation loss: 1.8525453767468851

Epoch: 5| Step: 9
Training loss: 2.1303672790527344
Validation loss: 1.841784918180076

Epoch: 5| Step: 10
Training loss: 2.3021042346954346
Validation loss: 1.8401332542460451

Epoch: 91| Step: 0
Training loss: 1.625585913658142
Validation loss: 1.8481891488516202

Epoch: 5| Step: 1
Training loss: 1.9929797649383545
Validation loss: 1.8554362673913278

Epoch: 5| Step: 2
Training loss: 2.529036045074463
Validation loss: 1.8494332169973722

Epoch: 5| Step: 3
Training loss: 2.336146831512451
Validation loss: 1.8376497055894585

Epoch: 5| Step: 4
Training loss: 2.2777864933013916
Validation loss: 1.8437373394607215

Epoch: 5| Step: 5
Training loss: 2.5186452865600586
Validation loss: 1.8388861699770855

Epoch: 5| Step: 6
Training loss: 1.7874329090118408
Validation loss: 1.8359754418814054

Epoch: 5| Step: 7
Training loss: 2.2193548679351807
Validation loss: 1.8280423469440912

Epoch: 5| Step: 8
Training loss: 2.7014310359954834
Validation loss: 1.840410118461937

Epoch: 5| Step: 9
Training loss: 1.9870860576629639
Validation loss: 1.835073963288338

Epoch: 5| Step: 10
Training loss: 1.9134432077407837
Validation loss: 1.8267448653456986

Epoch: 92| Step: 0
Training loss: 1.694729208946228
Validation loss: 1.8398499078648065

Epoch: 5| Step: 1
Training loss: 2.6415562629699707
Validation loss: 1.8317966397090624

Epoch: 5| Step: 2
Training loss: 2.196981430053711
Validation loss: 1.8371539692724905

Epoch: 5| Step: 3
Training loss: 1.9863526821136475
Validation loss: 1.8141750802275955

Epoch: 5| Step: 4
Training loss: 2.181812286376953
Validation loss: 1.8312213202958465

Epoch: 5| Step: 5
Training loss: 2.341251850128174
Validation loss: 1.8274436073918496

Epoch: 5| Step: 6
Training loss: 2.186558485031128
Validation loss: 1.8418314687667354

Epoch: 5| Step: 7
Training loss: 2.591688632965088
Validation loss: 1.8442153571754374

Epoch: 5| Step: 8
Training loss: 1.9434053897857666
Validation loss: 1.8399445062042565

Epoch: 5| Step: 9
Training loss: 2.0436809062957764
Validation loss: 1.8387852971271803

Epoch: 5| Step: 10
Training loss: 1.9658243656158447
Validation loss: 1.8437490258165585

Epoch: 93| Step: 0
Training loss: 2.2467188835144043
Validation loss: 1.8279419893859534

Epoch: 5| Step: 1
Training loss: 2.0277137756347656
Validation loss: 1.833836172216682

Epoch: 5| Step: 2
Training loss: 2.4458248615264893
Validation loss: 1.846963539559354

Epoch: 5| Step: 3
Training loss: 1.933214783668518
Validation loss: 1.8354386180959723

Epoch: 5| Step: 4
Training loss: 2.7084221839904785
Validation loss: 1.8422770551455918

Epoch: 5| Step: 5
Training loss: 1.6781975030899048
Validation loss: 1.841957038448703

Epoch: 5| Step: 6
Training loss: 2.1495752334594727
Validation loss: 1.8437038198594125

Epoch: 5| Step: 7
Training loss: 2.583618640899658
Validation loss: 1.8402514560248262

Epoch: 5| Step: 8
Training loss: 1.8078184127807617
Validation loss: 1.8371197023699362

Epoch: 5| Step: 9
Training loss: 1.8134466409683228
Validation loss: 1.8349997843465498

Epoch: 5| Step: 10
Training loss: 2.3626508712768555
Validation loss: 1.844351149374439

Epoch: 94| Step: 0
Training loss: 1.9343849420547485
Validation loss: 1.8260309914106965

Epoch: 5| Step: 1
Training loss: 2.409797191619873
Validation loss: 1.8513527749687113

Epoch: 5| Step: 2
Training loss: 1.920309066772461
Validation loss: 1.8399644628647835

Epoch: 5| Step: 3
Training loss: 1.5318162441253662
Validation loss: 1.8365008997660812

Epoch: 5| Step: 4
Training loss: 1.7896865606307983
Validation loss: 1.8340022192206433

Epoch: 5| Step: 5
Training loss: 2.2668492794036865
Validation loss: 1.8496189021295117

Epoch: 5| Step: 6
Training loss: 3.541536331176758
Validation loss: 1.8447131149230465

Epoch: 5| Step: 7
Training loss: 2.632711172103882
Validation loss: 1.8325884675466886

Epoch: 5| Step: 8
Training loss: 1.5613638162612915
Validation loss: 1.8278682795904015

Epoch: 5| Step: 9
Training loss: 2.1210811138153076
Validation loss: 1.824849768351483

Epoch: 5| Step: 10
Training loss: 1.8938441276550293
Validation loss: 1.826742213259461

Epoch: 95| Step: 0
Training loss: 2.3016674518585205
Validation loss: 1.8221938661349717

Epoch: 5| Step: 1
Training loss: 2.3056819438934326
Validation loss: 1.8420249826164656

Epoch: 5| Step: 2
Training loss: 2.043992757797241
Validation loss: 1.8248796181012226

Epoch: 5| Step: 3
Training loss: 2.3562915325164795
Validation loss: 1.838927069017964

Epoch: 5| Step: 4
Training loss: 1.7870795726776123
Validation loss: 1.8220672927876955

Epoch: 5| Step: 5
Training loss: 2.072049379348755
Validation loss: 1.8317211392105266

Epoch: 5| Step: 6
Training loss: 2.5245726108551025
Validation loss: 1.839372295205311

Epoch: 5| Step: 7
Training loss: 1.5387681722640991
Validation loss: 1.8487542547205442

Epoch: 5| Step: 8
Training loss: 2.444749355316162
Validation loss: 1.8440503164004254

Epoch: 5| Step: 9
Training loss: 1.9295467138290405
Validation loss: 1.8433654641592374

Epoch: 5| Step: 10
Training loss: 2.3163681030273438
Validation loss: 1.8448954448905042

Epoch: 96| Step: 0
Training loss: 2.568114757537842
Validation loss: 1.8403020674182522

Epoch: 5| Step: 1
Training loss: 2.5296790599823
Validation loss: 1.8313813632534397

Epoch: 5| Step: 2
Training loss: 1.4329707622528076
Validation loss: 1.838532982334014

Epoch: 5| Step: 3
Training loss: 1.769396424293518
Validation loss: 1.8263426006481212

Epoch: 5| Step: 4
Training loss: 2.0111169815063477
Validation loss: 1.840137190716241

Epoch: 5| Step: 5
Training loss: 1.8253974914550781
Validation loss: 1.834096662459835

Epoch: 5| Step: 6
Training loss: 2.308284282684326
Validation loss: 1.829944941305345

Epoch: 5| Step: 7
Training loss: 2.3060150146484375
Validation loss: 1.821972249656595

Epoch: 5| Step: 8
Training loss: 2.191723346710205
Validation loss: 1.8205323001389861

Epoch: 5| Step: 9
Training loss: 2.1348319053649902
Validation loss: 1.8335224813030613

Epoch: 5| Step: 10
Training loss: 2.681743860244751
Validation loss: 1.8444347304682578

Epoch: 97| Step: 0
Training loss: 2.1938207149505615
Validation loss: 1.8451235217432822

Epoch: 5| Step: 1
Training loss: 1.7334247827529907
Validation loss: 1.8265469868977864

Epoch: 5| Step: 2
Training loss: 2.1580638885498047
Validation loss: 1.8284776659422024

Epoch: 5| Step: 3
Training loss: 2.7738513946533203
Validation loss: 1.8303151028130644

Epoch: 5| Step: 4
Training loss: 2.267256259918213
Validation loss: 1.8397115327978646

Epoch: 5| Step: 5
Training loss: 1.9664723873138428
Validation loss: 1.8394658860339914

Epoch: 5| Step: 6
Training loss: 1.675472617149353
Validation loss: 1.8234568385667698

Epoch: 5| Step: 7
Training loss: 2.1347198486328125
Validation loss: 1.841629482084705

Epoch: 5| Step: 8
Training loss: 2.065133571624756
Validation loss: 1.850446536976804

Epoch: 5| Step: 9
Training loss: 2.6932239532470703
Validation loss: 1.8369950440622145

Epoch: 5| Step: 10
Training loss: 1.7626867294311523
Validation loss: 1.8334538590523504

Epoch: 98| Step: 0
Training loss: 1.8550636768341064
Validation loss: 1.8341517832971388

Epoch: 5| Step: 1
Training loss: 2.9297831058502197
Validation loss: 1.8366850665820542

Epoch: 5| Step: 2
Training loss: 2.1013495922088623
Validation loss: 1.8392087695419148

Epoch: 5| Step: 3
Training loss: 2.023120403289795
Validation loss: 1.8408819629300026

Epoch: 5| Step: 4
Training loss: 2.168043375015259
Validation loss: 1.8372153312929216

Epoch: 5| Step: 5
Training loss: 2.107085704803467
Validation loss: 1.817090618994928

Epoch: 5| Step: 6
Training loss: 2.405355215072632
Validation loss: 1.8393658271399878

Epoch: 5| Step: 7
Training loss: 1.8658311367034912
Validation loss: 1.85051344543375

Epoch: 5| Step: 8
Training loss: 2.1850759983062744
Validation loss: 1.8362123491943523

Epoch: 5| Step: 9
Training loss: 1.589540719985962
Validation loss: 1.836101141027225

Epoch: 5| Step: 10
Training loss: 2.2226502895355225
Validation loss: 1.8464374734509377

Epoch: 99| Step: 0
Training loss: 1.3357155323028564
Validation loss: 1.8431289977924799

Epoch: 5| Step: 1
Training loss: 2.2864158153533936
Validation loss: 1.8251021164719776

Epoch: 5| Step: 2
Training loss: 1.4741177558898926
Validation loss: 1.8189911252708846

Epoch: 5| Step: 3
Training loss: 2.149599552154541
Validation loss: 1.8416358194043558

Epoch: 5| Step: 4
Training loss: 2.5200278759002686
Validation loss: 1.8409387655155633

Epoch: 5| Step: 5
Training loss: 2.813821315765381
Validation loss: 1.818862335656279

Epoch: 5| Step: 6
Training loss: 1.8943023681640625
Validation loss: 1.821232835451762

Epoch: 5| Step: 7
Training loss: 2.124413013458252
Validation loss: 1.8352236850287325

Epoch: 5| Step: 8
Training loss: 2.0216729640960693
Validation loss: 1.8372461475351805

Epoch: 5| Step: 9
Training loss: 2.194784641265869
Validation loss: 1.8372406459623767

Epoch: 5| Step: 10
Training loss: 2.8038501739501953
Validation loss: 1.8264238757471885

Epoch: 100| Step: 0
Training loss: 1.863901138305664
Validation loss: 1.8254360921921269

Epoch: 5| Step: 1
Training loss: 2.628021001815796
Validation loss: 1.8297120883900633

Epoch: 5| Step: 2
Training loss: 2.079481601715088
Validation loss: 1.8376440950619277

Epoch: 5| Step: 3
Training loss: 2.095026731491089
Validation loss: 1.8384698129469348

Epoch: 5| Step: 4
Training loss: 1.5352227687835693
Validation loss: 1.8559959793603549

Epoch: 5| Step: 5
Training loss: 2.1869850158691406
Validation loss: 1.8296151955922444

Epoch: 5| Step: 6
Training loss: 2.040813446044922
Validation loss: 1.8404754836072204

Epoch: 5| Step: 7
Training loss: 1.946112036705017
Validation loss: 1.8420370009637648

Epoch: 5| Step: 8
Training loss: 2.4003098011016846
Validation loss: 1.860461054309722

Epoch: 5| Step: 9
Training loss: 2.1377358436584473
Validation loss: 1.8473531251312585

Epoch: 5| Step: 10
Training loss: 2.703310012817383
Validation loss: 1.853224867133684

Epoch: 101| Step: 0
Training loss: 2.0929417610168457
Validation loss: 1.8383596340815227

Epoch: 5| Step: 1
Training loss: 1.8409748077392578
Validation loss: 1.8539174551604896

Epoch: 5| Step: 2
Training loss: 1.9130117893218994
Validation loss: 1.836130319103118

Epoch: 5| Step: 3
Training loss: 2.597503423690796
Validation loss: 1.8351975282033284

Epoch: 5| Step: 4
Training loss: 2.9423351287841797
Validation loss: 1.8296276215584046

Epoch: 5| Step: 5
Training loss: 1.3757832050323486
Validation loss: 1.8426468577436221

Epoch: 5| Step: 6
Training loss: 2.294654369354248
Validation loss: 1.8206818962609896

Epoch: 5| Step: 7
Training loss: 2.1133511066436768
Validation loss: 1.8312806403765114

Epoch: 5| Step: 8
Training loss: 2.5300557613372803
Validation loss: 1.8312541323323404

Epoch: 5| Step: 9
Training loss: 2.375584602355957
Validation loss: 1.8289922847542712

Epoch: 5| Step: 10
Training loss: 1.1430217027664185
Validation loss: 1.8205818104487594

Epoch: 102| Step: 0
Training loss: 1.7887537479400635
Validation loss: 1.8136265995681926

Epoch: 5| Step: 1
Training loss: 2.595689535140991
Validation loss: 1.8013440139832035

Epoch: 5| Step: 2
Training loss: 2.0999178886413574
Validation loss: 1.8232756276284494

Epoch: 5| Step: 3
Training loss: 2.212517738342285
Validation loss: 1.8445918893301358

Epoch: 5| Step: 4
Training loss: 2.232224941253662
Validation loss: 1.811930489796464

Epoch: 5| Step: 5
Training loss: 1.5927385091781616
Validation loss: 1.8309598199782833

Epoch: 5| Step: 6
Training loss: 1.5846168994903564
Validation loss: 1.8325594471346947

Epoch: 5| Step: 7
Training loss: 2.391307830810547
Validation loss: 1.8398590613436956

Epoch: 5| Step: 8
Training loss: 2.4632692337036133
Validation loss: 1.8452268262063303

Epoch: 5| Step: 9
Training loss: 2.4302945137023926
Validation loss: 1.812859208353104

Epoch: 5| Step: 10
Training loss: 1.8940826654434204
Validation loss: 1.8209389948075818

Epoch: 103| Step: 0
Training loss: 1.8183437585830688
Validation loss: 1.8173320178062684

Epoch: 5| Step: 1
Training loss: 2.2022926807403564
Validation loss: 1.809363813810451

Epoch: 5| Step: 2
Training loss: 1.9345070123672485
Validation loss: 1.8176707080615464

Epoch: 5| Step: 3
Training loss: 1.5460879802703857
Validation loss: 1.8105718910053212

Epoch: 5| Step: 4
Training loss: 2.417632579803467
Validation loss: 1.8189341316940963

Epoch: 5| Step: 5
Training loss: 2.4102463722229004
Validation loss: 1.8354286147702126

Epoch: 5| Step: 6
Training loss: 2.384326934814453
Validation loss: 1.8221234224175895

Epoch: 5| Step: 7
Training loss: 2.4284708499908447
Validation loss: 1.8237671557293142

Epoch: 5| Step: 8
Training loss: 1.6424890756607056
Validation loss: 1.8481413548992527

Epoch: 5| Step: 9
Training loss: 1.984405755996704
Validation loss: 1.8106846271022674

Epoch: 5| Step: 10
Training loss: 2.6010327339172363
Validation loss: 1.8234545415447605

Epoch: 104| Step: 0
Training loss: 2.255354642868042
Validation loss: 1.814259579104762

Epoch: 5| Step: 1
Training loss: 2.129782199859619
Validation loss: 1.8254452405437347

Epoch: 5| Step: 2
Training loss: 1.9248735904693604
Validation loss: 1.8234354334492837

Epoch: 5| Step: 3
Training loss: 2.29337215423584
Validation loss: 1.833041109064574

Epoch: 5| Step: 4
Training loss: 1.510883092880249
Validation loss: 1.8308305099446287

Epoch: 5| Step: 5
Training loss: 2.036975145339966
Validation loss: 1.8377097370803996

Epoch: 5| Step: 6
Training loss: 2.622760772705078
Validation loss: 1.8247461959879885

Epoch: 5| Step: 7
Training loss: 2.014525890350342
Validation loss: 1.8270703156789143

Epoch: 5| Step: 8
Training loss: 2.468208074569702
Validation loss: 1.8342347221989785

Epoch: 5| Step: 9
Training loss: 1.6077333688735962
Validation loss: 1.8453557722030147

Epoch: 5| Step: 10
Training loss: 2.35199236869812
Validation loss: 1.8335783994326027

Epoch: 105| Step: 0
Training loss: 1.9758141040802002
Validation loss: 1.8242765793236353

Epoch: 5| Step: 1
Training loss: 2.608635425567627
Validation loss: 1.8415039200936594

Epoch: 5| Step: 2
Training loss: 2.124575138092041
Validation loss: 1.8194068131908294

Epoch: 5| Step: 3
Training loss: 2.4307851791381836
Validation loss: 1.844514593001335

Epoch: 5| Step: 4
Training loss: 2.8274052143096924
Validation loss: 1.8349553167179067

Epoch: 5| Step: 5
Training loss: 2.0727005004882812
Validation loss: 1.823460676336801

Epoch: 5| Step: 6
Training loss: 1.650031328201294
Validation loss: 1.8244394217768023

Epoch: 5| Step: 7
Training loss: 2.263467788696289
Validation loss: 1.824116256929213

Epoch: 5| Step: 8
Training loss: 1.448164701461792
Validation loss: 1.8326311175541212

Epoch: 5| Step: 9
Training loss: 2.0635204315185547
Validation loss: 1.8332399014503724

Epoch: 5| Step: 10
Training loss: 1.6729131937026978
Validation loss: 1.8373097758139334

Epoch: 106| Step: 0
Training loss: 1.8259834051132202
Validation loss: 1.823195900968326

Epoch: 5| Step: 1
Training loss: 2.326143264770508
Validation loss: 1.827687842871553

Epoch: 5| Step: 2
Training loss: 2.3243308067321777
Validation loss: 1.7959620696242138

Epoch: 5| Step: 3
Training loss: 2.3158459663391113
Validation loss: 1.8287210823387228

Epoch: 5| Step: 4
Training loss: 1.4577157497406006
Validation loss: 1.824083496165532

Epoch: 5| Step: 5
Training loss: 2.25231671333313
Validation loss: 1.8327191132371143

Epoch: 5| Step: 6
Training loss: 2.0307862758636475
Validation loss: 1.81458451414621

Epoch: 5| Step: 7
Training loss: 2.449720859527588
Validation loss: 1.8472162267213226

Epoch: 5| Step: 8
Training loss: 1.9975879192352295
Validation loss: 1.8374516117957331

Epoch: 5| Step: 9
Training loss: 1.8405441045761108
Validation loss: 1.8132757448380994

Epoch: 5| Step: 10
Training loss: 2.2755091190338135
Validation loss: 1.8376984173251736

Epoch: 107| Step: 0
Training loss: 2.058842182159424
Validation loss: 1.8369268512213102

Epoch: 5| Step: 1
Training loss: 2.541717052459717
Validation loss: 1.8249940359464256

Epoch: 5| Step: 2
Training loss: 2.4406328201293945
Validation loss: 1.8288618480005572

Epoch: 5| Step: 3
Training loss: 1.9615204334259033
Validation loss: 1.8284506477335447

Epoch: 5| Step: 4
Training loss: 2.2522101402282715
Validation loss: 1.8462268716545516

Epoch: 5| Step: 5
Training loss: 2.098761796951294
Validation loss: 1.816030817647134

Epoch: 5| Step: 6
Training loss: 2.1408958435058594
Validation loss: 1.8159981081562657

Epoch: 5| Step: 7
Training loss: 2.7083792686462402
Validation loss: 1.838578160091113

Epoch: 5| Step: 8
Training loss: 2.120537281036377
Validation loss: 1.8186382785920174

Epoch: 5| Step: 9
Training loss: 1.5609241724014282
Validation loss: 1.8154219440234605

Epoch: 5| Step: 10
Training loss: 1.127314805984497
Validation loss: 1.8434899263484503

Epoch: 108| Step: 0
Training loss: 1.8409427404403687
Validation loss: 1.8312505624627555

Epoch: 5| Step: 1
Training loss: 2.222452163696289
Validation loss: 1.8279137995935255

Epoch: 5| Step: 2
Training loss: 2.398618698120117
Validation loss: 1.8338084733614357

Epoch: 5| Step: 3
Training loss: 1.710457444190979
Validation loss: 1.825100960270051

Epoch: 5| Step: 4
Training loss: 1.9305137395858765
Validation loss: 1.8308077422521447

Epoch: 5| Step: 5
Training loss: 2.3047549724578857
Validation loss: 1.8209903868295814

Epoch: 5| Step: 6
Training loss: 1.9300308227539062
Validation loss: 1.8253271349014775

Epoch: 5| Step: 7
Training loss: 1.5473921298980713
Validation loss: 1.8276645227145123

Epoch: 5| Step: 8
Training loss: 2.375680685043335
Validation loss: 1.848907010529631

Epoch: 5| Step: 9
Training loss: 2.360853672027588
Validation loss: 1.8328240231801105

Epoch: 5| Step: 10
Training loss: 2.5433785915374756
Validation loss: 1.8198835337033836

Epoch: 109| Step: 0
Training loss: 1.5297694206237793
Validation loss: 1.8135319922560005

Epoch: 5| Step: 1
Training loss: 2.032646894454956
Validation loss: 1.8056349587696854

Epoch: 5| Step: 2
Training loss: 2.0271430015563965
Validation loss: 1.827370088587525

Epoch: 5| Step: 3
Training loss: 2.355375289916992
Validation loss: 1.8352519927486297

Epoch: 5| Step: 4
Training loss: 2.4382736682891846
Validation loss: 1.831759932220623

Epoch: 5| Step: 5
Training loss: 2.8892030715942383
Validation loss: 1.8225226145918652

Epoch: 5| Step: 6
Training loss: 2.295480251312256
Validation loss: 1.8133809553679598

Epoch: 5| Step: 7
Training loss: 1.750600814819336
Validation loss: 1.820104214452928

Epoch: 5| Step: 8
Training loss: 1.7957298755645752
Validation loss: 1.8168347920140913

Epoch: 5| Step: 9
Training loss: 1.7519073486328125
Validation loss: 1.8191830291542956

Epoch: 5| Step: 10
Training loss: 2.204655408859253
Validation loss: 1.8163810237761466

Epoch: 110| Step: 0
Training loss: 1.7962491512298584
Validation loss: 1.8218975067138672

Epoch: 5| Step: 1
Training loss: 2.692788600921631
Validation loss: 1.844371344453545

Epoch: 5| Step: 2
Training loss: 2.868105411529541
Validation loss: 1.8171062213118359

Epoch: 5| Step: 3
Training loss: 1.9708576202392578
Validation loss: 1.8155852581865044

Epoch: 5| Step: 4
Training loss: 1.7402549982070923
Validation loss: 1.8356720862850067

Epoch: 5| Step: 5
Training loss: 2.335132598876953
Validation loss: 1.814000298899989

Epoch: 5| Step: 6
Training loss: 2.3162858486175537
Validation loss: 1.8154867015859133

Epoch: 5| Step: 7
Training loss: 1.7981386184692383
Validation loss: 1.8300530525945848

Epoch: 5| Step: 8
Training loss: 1.7345199584960938
Validation loss: 1.8294552500529955

Epoch: 5| Step: 9
Training loss: 1.9181365966796875
Validation loss: 1.8308321686201199

Epoch: 5| Step: 10
Training loss: 1.7694836854934692
Validation loss: 1.827412889849755

Epoch: 111| Step: 0
Training loss: 2.1556332111358643
Validation loss: 1.8400442574613838

Epoch: 5| Step: 1
Training loss: 1.8269544839859009
Validation loss: 1.8324378651957358

Epoch: 5| Step: 2
Training loss: 1.9599034786224365
Validation loss: 1.832398465884629

Epoch: 5| Step: 3
Training loss: 2.671473741531372
Validation loss: 1.8406006366975847

Epoch: 5| Step: 4
Training loss: 2.619145154953003
Validation loss: 1.842760193732477

Epoch: 5| Step: 5
Training loss: 1.5610947608947754
Validation loss: 1.8302739025444112

Epoch: 5| Step: 6
Training loss: 2.2139954566955566
Validation loss: 1.8213452754482147

Epoch: 5| Step: 7
Training loss: 1.5354340076446533
Validation loss: 1.832062921216411

Epoch: 5| Step: 8
Training loss: 2.083005905151367
Validation loss: 1.828873085719283

Epoch: 5| Step: 9
Training loss: 2.40171217918396
Validation loss: 1.8506887394894835

Epoch: 5| Step: 10
Training loss: 1.924645185470581
Validation loss: 1.8501876605454313

Epoch: 112| Step: 0
Training loss: 2.1740198135375977
Validation loss: 1.8490477479914182

Epoch: 5| Step: 1
Training loss: 1.7959226369857788
Validation loss: 1.8474051901089248

Epoch: 5| Step: 2
Training loss: 1.5703377723693848
Validation loss: 1.846861267602572

Epoch: 5| Step: 3
Training loss: 1.5167691707611084
Validation loss: 1.8314288764871576

Epoch: 5| Step: 4
Training loss: 2.188032865524292
Validation loss: 1.8597532895303541

Epoch: 5| Step: 5
Training loss: 2.5491347312927246
Validation loss: 1.829242319189092

Epoch: 5| Step: 6
Training loss: 2.483793020248413
Validation loss: 1.8375358863543438

Epoch: 5| Step: 7
Training loss: 2.209136486053467
Validation loss: 1.8263792991638184

Epoch: 5| Step: 8
Training loss: 2.3092494010925293
Validation loss: 1.8464324781971593

Epoch: 5| Step: 9
Training loss: 1.9657573699951172
Validation loss: 1.8387487203844133

Epoch: 5| Step: 10
Training loss: 1.984381914138794
Validation loss: 1.8384819735762894

Epoch: 113| Step: 0
Training loss: 1.819311499595642
Validation loss: 1.836832913019324

Epoch: 5| Step: 1
Training loss: 2.883748769760132
Validation loss: 1.8260259371931835

Epoch: 5| Step: 2
Training loss: 2.2479465007781982
Validation loss: 1.8291392454537012

Epoch: 5| Step: 3
Training loss: 2.455343008041382
Validation loss: 1.8328772411551526

Epoch: 5| Step: 4
Training loss: 1.755133032798767
Validation loss: 1.8312645907043128

Epoch: 5| Step: 5
Training loss: 2.7919228076934814
Validation loss: 1.8168132138508621

Epoch: 5| Step: 6
Training loss: 1.5051735639572144
Validation loss: 1.8394946500819216

Epoch: 5| Step: 7
Training loss: 2.028597593307495
Validation loss: 1.7945209613410376

Epoch: 5| Step: 8
Training loss: 1.8532406091690063
Validation loss: 1.8265089873344666

Epoch: 5| Step: 9
Training loss: 1.5304938554763794
Validation loss: 1.8361494989805325

Epoch: 5| Step: 10
Training loss: 2.0469298362731934
Validation loss: 1.833417369473365

Epoch: 114| Step: 0
Training loss: 1.8737157583236694
Validation loss: 1.8264220171077277

Epoch: 5| Step: 1
Training loss: 2.119389772415161
Validation loss: 1.8130111245698826

Epoch: 5| Step: 2
Training loss: 2.6554362773895264
Validation loss: 1.8246807218879781

Epoch: 5| Step: 3
Training loss: 1.8128366470336914
Validation loss: 1.8057377133318173

Epoch: 5| Step: 4
Training loss: 1.7120717763900757
Validation loss: 1.8187359738093551

Epoch: 5| Step: 5
Training loss: 1.8435570001602173
Validation loss: 1.8031503115930865

Epoch: 5| Step: 6
Training loss: 2.445279359817505
Validation loss: 1.8134905881779169

Epoch: 5| Step: 7
Training loss: 1.9969927072525024
Validation loss: 1.8278399923796296

Epoch: 5| Step: 8
Training loss: 2.4924023151397705
Validation loss: 1.834503989065847

Epoch: 5| Step: 9
Training loss: 1.8579738140106201
Validation loss: 1.8110508021487985

Epoch: 5| Step: 10
Training loss: 2.0618395805358887
Validation loss: 1.8448857261288552

Epoch: 115| Step: 0
Training loss: 1.7307968139648438
Validation loss: 1.8285099870415145

Epoch: 5| Step: 1
Training loss: 1.552583932876587
Validation loss: 1.8222979499447731

Epoch: 5| Step: 2
Training loss: 1.8730875253677368
Validation loss: 1.8454615146883073

Epoch: 5| Step: 3
Training loss: 2.111306667327881
Validation loss: 1.8222367020063504

Epoch: 5| Step: 4
Training loss: 2.421543598175049
Validation loss: 1.8204093479341077

Epoch: 5| Step: 5
Training loss: 2.119353771209717
Validation loss: 1.835233570427023

Epoch: 5| Step: 6
Training loss: 2.2114856243133545
Validation loss: 1.8259459182780275

Epoch: 5| Step: 7
Training loss: 1.4283281564712524
Validation loss: 1.7889356664431992

Epoch: 5| Step: 8
Training loss: 2.443493366241455
Validation loss: 1.8307624145220684

Epoch: 5| Step: 9
Training loss: 2.6834959983825684
Validation loss: 1.834264252775459

Epoch: 5| Step: 10
Training loss: 2.3075103759765625
Validation loss: 1.826886801309483

Epoch: 116| Step: 0
Training loss: 2.094010829925537
Validation loss: 1.8424057204236266

Epoch: 5| Step: 1
Training loss: 2.0314621925354004
Validation loss: 1.8290961980819702

Epoch: 5| Step: 2
Training loss: 2.0757415294647217
Validation loss: 1.8410086516411073

Epoch: 5| Step: 3
Training loss: 2.044114589691162
Validation loss: 1.8240137202765352

Epoch: 5| Step: 4
Training loss: 1.4821784496307373
Validation loss: 1.8454902659180343

Epoch: 5| Step: 5
Training loss: 2.3082869052886963
Validation loss: 1.8333447722978489

Epoch: 5| Step: 6
Training loss: 2.190256357192993
Validation loss: 1.8291293241644417

Epoch: 5| Step: 7
Training loss: 1.9112703800201416
Validation loss: 1.841990541386348

Epoch: 5| Step: 8
Training loss: 2.2434470653533936
Validation loss: 1.8312296470006306

Epoch: 5| Step: 9
Training loss: 2.186664342880249
Validation loss: 1.825914349607242

Epoch: 5| Step: 10
Training loss: 2.0787854194641113
Validation loss: 1.8262104962461738

Epoch: 117| Step: 0
Training loss: 2.23111629486084
Validation loss: 1.8423993510584677

Epoch: 5| Step: 1
Training loss: 2.6837990283966064
Validation loss: 1.8238447276494836

Epoch: 5| Step: 2
Training loss: 1.8030242919921875
Validation loss: 1.8397078501280917

Epoch: 5| Step: 3
Training loss: 1.7392810583114624
Validation loss: 1.8459027531326457

Epoch: 5| Step: 4
Training loss: 1.8943382501602173
Validation loss: 1.8314364187179073

Epoch: 5| Step: 5
Training loss: 2.0151376724243164
Validation loss: 1.8359285195668538

Epoch: 5| Step: 6
Training loss: 1.6390867233276367
Validation loss: 1.8302093680186937

Epoch: 5| Step: 7
Training loss: 2.0155298709869385
Validation loss: 1.836376259403844

Epoch: 5| Step: 8
Training loss: 2.0629475116729736
Validation loss: 1.8416782784205612

Epoch: 5| Step: 9
Training loss: 2.2534213066101074
Validation loss: 1.8082405315932406

Epoch: 5| Step: 10
Training loss: 2.5496573448181152
Validation loss: 1.827559756976302

Epoch: 118| Step: 0
Training loss: 1.7962512969970703
Validation loss: 1.825496005755599

Epoch: 5| Step: 1
Training loss: 2.155275583267212
Validation loss: 1.8309756132864183

Epoch: 5| Step: 2
Training loss: 2.0486981868743896
Validation loss: 1.8318459474912254

Epoch: 5| Step: 3
Training loss: 2.2771036624908447
Validation loss: 1.8318783570361394

Epoch: 5| Step: 4
Training loss: 2.005742311477661
Validation loss: 1.8534508789739301

Epoch: 5| Step: 5
Training loss: 2.3144466876983643
Validation loss: 1.8301535396165745

Epoch: 5| Step: 6
Training loss: 1.9080429077148438
Validation loss: 1.8258521774763703

Epoch: 5| Step: 7
Training loss: 2.033689022064209
Validation loss: 1.832397182782491

Epoch: 5| Step: 8
Training loss: 1.7565507888793945
Validation loss: 1.8379771863260577

Epoch: 5| Step: 9
Training loss: 1.611108422279358
Validation loss: 1.8227360299838486

Epoch: 5| Step: 10
Training loss: 2.5712482929229736
Validation loss: 1.8501609166463215

Epoch: 119| Step: 0
Training loss: 2.1363673210144043
Validation loss: 1.8373438658252839

Epoch: 5| Step: 1
Training loss: 2.4071969985961914
Validation loss: 1.8264382616166146

Epoch: 5| Step: 2
Training loss: 1.857000708580017
Validation loss: 1.8218662290162937

Epoch: 5| Step: 3
Training loss: 1.80500066280365
Validation loss: 1.8297916612317484

Epoch: 5| Step: 4
Training loss: 1.684075117111206
Validation loss: 1.8177329724834812

Epoch: 5| Step: 5
Training loss: 2.230264186859131
Validation loss: 1.821488126631706

Epoch: 5| Step: 6
Training loss: 2.032808303833008
Validation loss: 1.818201034299789

Epoch: 5| Step: 7
Training loss: 2.138280153274536
Validation loss: 1.8189325794096916

Epoch: 5| Step: 8
Training loss: 2.0140717029571533
Validation loss: 1.8114273650671846

Epoch: 5| Step: 9
Training loss: 2.1816892623901367
Validation loss: 1.8284972072929464

Epoch: 5| Step: 10
Training loss: 2.2581675052642822
Validation loss: 1.8192270391730851

Epoch: 120| Step: 0
Training loss: 1.7320811748504639
Validation loss: 1.8404826271918513

Epoch: 5| Step: 1
Training loss: 2.244690418243408
Validation loss: 1.8301680395680089

Epoch: 5| Step: 2
Training loss: 2.150800943374634
Validation loss: 1.8108728649795696

Epoch: 5| Step: 3
Training loss: 1.6505218744277954
Validation loss: 1.8190549996591383

Epoch: 5| Step: 4
Training loss: 2.862579345703125
Validation loss: 1.8303362733574324

Epoch: 5| Step: 5
Training loss: 2.1025185585021973
Validation loss: 1.8290044723018524

Epoch: 5| Step: 6
Training loss: 2.0170135498046875
Validation loss: 1.8091967157138291

Epoch: 5| Step: 7
Training loss: 2.263444423675537
Validation loss: 1.8312759707050938

Epoch: 5| Step: 8
Training loss: 1.8004604578018188
Validation loss: 1.8137710863544094

Epoch: 5| Step: 9
Training loss: 2.218708038330078
Validation loss: 1.8421015598440682

Epoch: 5| Step: 10
Training loss: 1.350843071937561
Validation loss: 1.8250213976829284

Epoch: 121| Step: 0
Training loss: 2.6711790561676025
Validation loss: 1.8385936098714029

Epoch: 5| Step: 1
Training loss: 2.0400516986846924
Validation loss: 1.8382704975784465

Epoch: 5| Step: 2
Training loss: 1.984701156616211
Validation loss: 1.8360606893416374

Epoch: 5| Step: 3
Training loss: 1.4829370975494385
Validation loss: 1.8419358038133191

Epoch: 5| Step: 4
Training loss: 1.935294508934021
Validation loss: 1.8464248385480655

Epoch: 5| Step: 5
Training loss: 1.864169716835022
Validation loss: 1.857040028418264

Epoch: 5| Step: 6
Training loss: 2.3322014808654785
Validation loss: 1.8554015133970527

Epoch: 5| Step: 7
Training loss: 2.3198089599609375
Validation loss: 1.8493001435392646

Epoch: 5| Step: 8
Training loss: 1.6980888843536377
Validation loss: 1.8613224747360393

Epoch: 5| Step: 9
Training loss: 2.3237931728363037
Validation loss: 1.87292782978345

Epoch: 5| Step: 10
Training loss: 1.9153740406036377
Validation loss: 1.8465440811649445

Epoch: 122| Step: 0
Training loss: 1.9985170364379883
Validation loss: 1.8754044860921881

Epoch: 5| Step: 1
Training loss: 1.7619209289550781
Validation loss: 1.8428795119767547

Epoch: 5| Step: 2
Training loss: 2.6835079193115234
Validation loss: 1.8457263080022668

Epoch: 5| Step: 3
Training loss: 2.378904342651367
Validation loss: 1.8376104216421805

Epoch: 5| Step: 4
Training loss: 0.9276857376098633
Validation loss: 1.8599551621303763

Epoch: 5| Step: 5
Training loss: 2.199531078338623
Validation loss: 1.837425757479924

Epoch: 5| Step: 6
Training loss: 2.1163170337677
Validation loss: 1.8479618180182673

Epoch: 5| Step: 7
Training loss: 1.5733779668807983
Validation loss: 1.8402960223536338

Epoch: 5| Step: 8
Training loss: 2.509915590286255
Validation loss: 1.8377379025182417

Epoch: 5| Step: 9
Training loss: 1.8353736400604248
Validation loss: 1.8382909169761084

Epoch: 5| Step: 10
Training loss: 2.5684423446655273
Validation loss: 1.8228029974045292

Epoch: 123| Step: 0
Training loss: 1.9538509845733643
Validation loss: 1.8264164450348064

Epoch: 5| Step: 1
Training loss: 2.423678398132324
Validation loss: 1.8140161152808898

Epoch: 5| Step: 2
Training loss: 2.5563831329345703
Validation loss: 1.8141124261322843

Epoch: 5| Step: 3
Training loss: 2.1975290775299072
Validation loss: 1.8235557245951828

Epoch: 5| Step: 4
Training loss: 1.915029525756836
Validation loss: 1.8300684664839058

Epoch: 5| Step: 5
Training loss: 1.6751916408538818
Validation loss: 1.8354509517710695

Epoch: 5| Step: 6
Training loss: 1.6128246784210205
Validation loss: 1.8316338190468409

Epoch: 5| Step: 7
Training loss: 2.2668960094451904
Validation loss: 1.8327339297981673

Epoch: 5| Step: 8
Training loss: 2.570746898651123
Validation loss: 1.8266727052709109

Epoch: 5| Step: 9
Training loss: 1.7495183944702148
Validation loss: 1.8242336447520922

Epoch: 5| Step: 10
Training loss: 1.3648594617843628
Validation loss: 1.837673505147298

Epoch: 124| Step: 0
Training loss: 1.6806310415267944
Validation loss: 1.8055063588644868

Epoch: 5| Step: 1
Training loss: 1.9003245830535889
Validation loss: 1.8386911525521228

Epoch: 5| Step: 2
Training loss: 1.7496910095214844
Validation loss: 1.839332357529671

Epoch: 5| Step: 3
Training loss: 1.7587223052978516
Validation loss: 1.8287480287654425

Epoch: 5| Step: 4
Training loss: 2.1492111682891846
Validation loss: 1.8090888633522937

Epoch: 5| Step: 5
Training loss: 2.1078696250915527
Validation loss: 1.818883070381739

Epoch: 5| Step: 6
Training loss: 2.428356170654297
Validation loss: 1.802232885873446

Epoch: 5| Step: 7
Training loss: 1.6139755249023438
Validation loss: 1.854542378456362

Epoch: 5| Step: 8
Training loss: 2.3409132957458496
Validation loss: 1.8217436882757372

Epoch: 5| Step: 9
Training loss: 2.1215567588806152
Validation loss: 1.81938164336707

Epoch: 5| Step: 10
Training loss: 2.4104185104370117
Validation loss: 1.8246103576434556

Epoch: 125| Step: 0
Training loss: 1.7169904708862305
Validation loss: 1.8316888937386133

Epoch: 5| Step: 1
Training loss: 2.1459898948669434
Validation loss: 1.8273270668522004

Epoch: 5| Step: 2
Training loss: 1.8856112957000732
Validation loss: 1.8296703882114862

Epoch: 5| Step: 3
Training loss: 1.935071587562561
Validation loss: 1.8272676621713946

Epoch: 5| Step: 4
Training loss: 2.199171543121338
Validation loss: 1.8325787487850393

Epoch: 5| Step: 5
Training loss: 2.297271728515625
Validation loss: 1.8225341881475141

Epoch: 5| Step: 6
Training loss: 1.616091012954712
Validation loss: 1.8268627517966813

Epoch: 5| Step: 7
Training loss: 2.449336528778076
Validation loss: 1.8181568063715452

Epoch: 5| Step: 8
Training loss: 1.8349345922470093
Validation loss: 1.8255297214754167

Epoch: 5| Step: 9
Training loss: 1.9004640579223633
Validation loss: 1.8550133923048615

Epoch: 5| Step: 10
Training loss: 2.369391918182373
Validation loss: 1.8548646767934163

Epoch: 126| Step: 0
Training loss: 1.8865617513656616
Validation loss: 1.834014202958794

Epoch: 5| Step: 1
Training loss: 2.295766830444336
Validation loss: 1.8534046937060613

Epoch: 5| Step: 2
Training loss: 2.368258237838745
Validation loss: 1.8539384526591147

Epoch: 5| Step: 3
Training loss: 1.3344978094100952
Validation loss: 1.8356367362442838

Epoch: 5| Step: 4
Training loss: 2.0955748558044434
Validation loss: 1.8308775424957275

Epoch: 5| Step: 5
Training loss: 1.644879937171936
Validation loss: 1.8289491258641726

Epoch: 5| Step: 6
Training loss: 2.447741985321045
Validation loss: 1.8338371733183503

Epoch: 5| Step: 7
Training loss: 1.8041160106658936
Validation loss: 1.831545727227324

Epoch: 5| Step: 8
Training loss: 2.1730551719665527
Validation loss: 1.8595385538634432

Epoch: 5| Step: 9
Training loss: 2.7032227516174316
Validation loss: 1.8243909369232834

Epoch: 5| Step: 10
Training loss: 1.4842852354049683
Validation loss: 1.8381333299862441

Epoch: 127| Step: 0
Training loss: 2.805495262145996
Validation loss: 1.8350556153123097

Epoch: 5| Step: 1
Training loss: 1.996010422706604
Validation loss: 1.8290787025164532

Epoch: 5| Step: 2
Training loss: 1.783007025718689
Validation loss: 1.8316849213774486

Epoch: 5| Step: 3
Training loss: 1.590135931968689
Validation loss: 1.8393955692168205

Epoch: 5| Step: 4
Training loss: 2.4694530963897705
Validation loss: 1.8397550070157616

Epoch: 5| Step: 5
Training loss: 2.2302136421203613
Validation loss: 1.8374606383744108

Epoch: 5| Step: 6
Training loss: 2.5795178413391113
Validation loss: 1.850553419000359

Epoch: 5| Step: 7
Training loss: 1.8468281030654907
Validation loss: 1.8353493828927316

Epoch: 5| Step: 8
Training loss: 1.6061652898788452
Validation loss: 1.8545384650589318

Epoch: 5| Step: 9
Training loss: 1.7765777111053467
Validation loss: 1.8429169167754471

Epoch: 5| Step: 10
Training loss: 1.4468196630477905
Validation loss: 1.8243037962144422

Epoch: 128| Step: 0
Training loss: 1.9521070718765259
Validation loss: 1.8148462426277898

Epoch: 5| Step: 1
Training loss: 2.0478363037109375
Validation loss: 1.846452174648162

Epoch: 5| Step: 2
Training loss: 2.5253260135650635
Validation loss: 1.8435430834370274

Epoch: 5| Step: 3
Training loss: 2.026578187942505
Validation loss: 1.820471332919213

Epoch: 5| Step: 4
Training loss: 2.1007065773010254
Validation loss: 1.8432424863179524

Epoch: 5| Step: 5
Training loss: 2.113914966583252
Validation loss: 1.8539813872306579

Epoch: 5| Step: 6
Training loss: 1.6054487228393555
Validation loss: 1.8077768202750915

Epoch: 5| Step: 7
Training loss: 1.5554578304290771
Validation loss: 1.8274024955687984

Epoch: 5| Step: 8
Training loss: 2.2483534812927246
Validation loss: 1.8121024985467233

Epoch: 5| Step: 9
Training loss: 1.898424744606018
Validation loss: 1.8341737383155412

Epoch: 5| Step: 10
Training loss: 2.0903875827789307
Validation loss: 1.8064436412626697

Epoch: 129| Step: 0
Training loss: 2.2382137775421143
Validation loss: 1.806176349680911

Epoch: 5| Step: 1
Training loss: 2.3158888816833496
Validation loss: 1.8033788896376086

Epoch: 5| Step: 2
Training loss: 1.490037202835083
Validation loss: 1.8291277667527557

Epoch: 5| Step: 3
Training loss: 1.615552306175232
Validation loss: 1.8472552607136388

Epoch: 5| Step: 4
Training loss: 2.962263822555542
Validation loss: 1.8324309023477698

Epoch: 5| Step: 5
Training loss: 2.2571561336517334
Validation loss: 1.8336437786779096

Epoch: 5| Step: 6
Training loss: 1.7675784826278687
Validation loss: 1.8242829807343022

Epoch: 5| Step: 7
Training loss: 2.0274200439453125
Validation loss: 1.8200559513543242

Epoch: 5| Step: 8
Training loss: 1.8578765392303467
Validation loss: 1.8199801022006619

Epoch: 5| Step: 9
Training loss: 1.6360841989517212
Validation loss: 1.8524957933733541

Epoch: 5| Step: 10
Training loss: 1.9951484203338623
Validation loss: 1.8491099906224076

Epoch: 130| Step: 0
Training loss: 2.132650852203369
Validation loss: 1.8400410657287927

Epoch: 5| Step: 1
Training loss: 1.9026119709014893
Validation loss: 1.807572054606612

Epoch: 5| Step: 2
Training loss: 2.6938226222991943
Validation loss: 1.8256977424826673

Epoch: 5| Step: 3
Training loss: 1.8751806020736694
Validation loss: 1.8464059227256364

Epoch: 5| Step: 4
Training loss: 1.9609864950180054
Validation loss: 1.838848183231969

Epoch: 5| Step: 5
Training loss: 1.8611980676651
Validation loss: 1.8355206597235896

Epoch: 5| Step: 6
Training loss: 2.161282777786255
Validation loss: 1.8226414380535003

Epoch: 5| Step: 7
Training loss: 1.9563852548599243
Validation loss: 1.8199281333595194

Epoch: 5| Step: 8
Training loss: 2.122070074081421
Validation loss: 1.8128431048444522

Epoch: 5| Step: 9
Training loss: 1.693946123123169
Validation loss: 1.8496444456038936

Epoch: 5| Step: 10
Training loss: 1.6285409927368164
Validation loss: 1.821551506237317

Epoch: 131| Step: 0
Training loss: 1.6823999881744385
Validation loss: 1.8253668700495074

Epoch: 5| Step: 1
Training loss: 2.0456223487854004
Validation loss: 1.8380735522957259

Epoch: 5| Step: 2
Training loss: 1.613451600074768
Validation loss: 1.815899351591705

Epoch: 5| Step: 3
Training loss: 2.035393238067627
Validation loss: 1.8448563198889456

Epoch: 5| Step: 4
Training loss: 1.9274896383285522
Validation loss: 1.8373076826013544

Epoch: 5| Step: 5
Training loss: 2.0854544639587402
Validation loss: 1.8293604338040916

Epoch: 5| Step: 6
Training loss: 2.0429844856262207
Validation loss: 1.8406938968166229

Epoch: 5| Step: 7
Training loss: 1.9183433055877686
Validation loss: 1.8215504564264768

Epoch: 5| Step: 8
Training loss: 2.200118064880371
Validation loss: 1.8058082890766922

Epoch: 5| Step: 9
Training loss: 1.9323310852050781
Validation loss: 1.8236084599648752

Epoch: 5| Step: 10
Training loss: 2.818828582763672
Validation loss: 1.8363204348471858

Epoch: 132| Step: 0
Training loss: 2.13594651222229
Validation loss: 1.7973418799779748

Epoch: 5| Step: 1
Training loss: 1.9517854452133179
Validation loss: 1.837491561007756

Epoch: 5| Step: 2
Training loss: 1.962148666381836
Validation loss: 1.8386267333902337

Epoch: 5| Step: 3
Training loss: 1.8281118869781494
Validation loss: 1.824312360055985

Epoch: 5| Step: 4
Training loss: 1.7338788509368896
Validation loss: 1.846039342623885

Epoch: 5| Step: 5
Training loss: 2.598611354827881
Validation loss: 1.8361975569878854

Epoch: 5| Step: 6
Training loss: 2.080300807952881
Validation loss: 1.8322071029293923

Epoch: 5| Step: 7
Training loss: 1.8417850732803345
Validation loss: 1.8379181790095505

Epoch: 5| Step: 8
Training loss: 2.0122647285461426
Validation loss: 1.8358049187608945

Epoch: 5| Step: 9
Training loss: 1.8896013498306274
Validation loss: 1.8487184521972493

Epoch: 5| Step: 10
Training loss: 1.7743154764175415
Validation loss: 1.825696014588879

Epoch: 133| Step: 0
Training loss: 2.361353635787964
Validation loss: 1.821359247289678

Epoch: 5| Step: 1
Training loss: 1.9583158493041992
Validation loss: 1.8413496068728867

Epoch: 5| Step: 2
Training loss: 2.5504493713378906
Validation loss: 1.8418708257777716

Epoch: 5| Step: 3
Training loss: 1.6079375743865967
Validation loss: 1.8138658231304539

Epoch: 5| Step: 4
Training loss: 1.4641965627670288
Validation loss: 1.8458628039206229

Epoch: 5| Step: 5
Training loss: 2.208836555480957
Validation loss: 1.8352502494729974

Epoch: 5| Step: 6
Training loss: 2.3116791248321533
Validation loss: 1.824580579675654

Epoch: 5| Step: 7
Training loss: 1.998370885848999
Validation loss: 1.8365639102074407

Epoch: 5| Step: 8
Training loss: 1.877800703048706
Validation loss: 1.8169945747621599

Epoch: 5| Step: 9
Training loss: 2.0131354331970215
Validation loss: 1.8250516947879587

Epoch: 5| Step: 10
Training loss: 1.6021074056625366
Validation loss: 1.8104914824167888

Epoch: 134| Step: 0
Training loss: 2.0879769325256348
Validation loss: 1.8197922757876817

Epoch: 5| Step: 1
Training loss: 2.22672438621521
Validation loss: 1.8300025463104248

Epoch: 5| Step: 2
Training loss: 1.6241519451141357
Validation loss: 1.826875985309642

Epoch: 5| Step: 3
Training loss: 2.193899631500244
Validation loss: 1.808269287950249

Epoch: 5| Step: 4
Training loss: 1.5701982975006104
Validation loss: 1.8209852787756151

Epoch: 5| Step: 5
Training loss: 2.815720319747925
Validation loss: 1.844056075619113

Epoch: 5| Step: 6
Training loss: 1.6274532079696655
Validation loss: 1.8480800377425326

Epoch: 5| Step: 7
Training loss: 1.6789233684539795
Validation loss: 1.8232164165025115

Epoch: 5| Step: 8
Training loss: 2.1605520248413086
Validation loss: 1.8328416321867256

Epoch: 5| Step: 9
Training loss: 1.8502190113067627
Validation loss: 1.8435805561721965

Epoch: 5| Step: 10
Training loss: 2.0305938720703125
Validation loss: 1.8491213552413448

Epoch: 135| Step: 0
Training loss: 2.4872260093688965
Validation loss: 1.8224674758090769

Epoch: 5| Step: 1
Training loss: 2.586862325668335
Validation loss: 1.8483893858489169

Epoch: 5| Step: 2
Training loss: 1.9964683055877686
Validation loss: 1.8377492825190227

Epoch: 5| Step: 3
Training loss: 2.563025712966919
Validation loss: 1.8267297334568475

Epoch: 5| Step: 4
Training loss: 1.4725404977798462
Validation loss: 1.8508459137332054

Epoch: 5| Step: 5
Training loss: 1.951237440109253
Validation loss: 1.831958543869757

Epoch: 5| Step: 6
Training loss: 1.7396866083145142
Validation loss: 1.8498211650438205

Epoch: 5| Step: 7
Training loss: 1.551237940788269
Validation loss: 1.8365470773430281

Epoch: 5| Step: 8
Training loss: 1.758935570716858
Validation loss: 1.8368449749485138

Epoch: 5| Step: 9
Training loss: 1.8737924098968506
Validation loss: 1.8369257386012743

Epoch: 5| Step: 10
Training loss: 1.668757438659668
Validation loss: 1.8267004066897976

Epoch: 136| Step: 0
Training loss: 1.3723475933074951
Validation loss: 1.812158816604204

Epoch: 5| Step: 1
Training loss: 2.108973741531372
Validation loss: 1.8274588302899433

Epoch: 5| Step: 2
Training loss: 2.021505117416382
Validation loss: 1.8555366300767469

Epoch: 5| Step: 3
Training loss: 1.9137086868286133
Validation loss: 1.8562649872995192

Epoch: 5| Step: 4
Training loss: 2.128422737121582
Validation loss: 1.8400679096098869

Epoch: 5| Step: 5
Training loss: 1.3588602542877197
Validation loss: 1.8315331205244987

Epoch: 5| Step: 6
Training loss: 2.727221965789795
Validation loss: 1.829402357019404

Epoch: 5| Step: 7
Training loss: 1.7793413400650024
Validation loss: 1.8243267202890048

Epoch: 5| Step: 8
Training loss: 2.0515105724334717
Validation loss: 1.8295675887856433

Epoch: 5| Step: 9
Training loss: 2.045278310775757
Validation loss: 1.8237269616896106

Epoch: 5| Step: 10
Training loss: 2.0595245361328125
Validation loss: 1.8413577900137952

Epoch: 137| Step: 0
Training loss: 1.5050395727157593
Validation loss: 1.8151906831290132

Epoch: 5| Step: 1
Training loss: 1.56703782081604
Validation loss: 1.8560373834384385

Epoch: 5| Step: 2
Training loss: 1.8549153804779053
Validation loss: 1.8479291162183207

Epoch: 5| Step: 3
Training loss: 2.154836893081665
Validation loss: 1.830131269270374

Epoch: 5| Step: 4
Training loss: 1.7844231128692627
Validation loss: 1.832480081947901

Epoch: 5| Step: 5
Training loss: 1.3738174438476562
Validation loss: 1.8507960496410247

Epoch: 5| Step: 6
Training loss: 1.7710462808609009
Validation loss: 1.8424129665538829

Epoch: 5| Step: 7
Training loss: 2.5441534519195557
Validation loss: 1.8452049070788967

Epoch: 5| Step: 8
Training loss: 2.7241528034210205
Validation loss: 1.8287862526473178

Epoch: 5| Step: 9
Training loss: 1.8349663019180298
Validation loss: 1.8139890227266537

Epoch: 5| Step: 10
Training loss: 2.697665214538574
Validation loss: 1.853831765472248

Epoch: 138| Step: 0
Training loss: 2.060581684112549
Validation loss: 1.8185458465289044

Epoch: 5| Step: 1
Training loss: 2.0732152462005615
Validation loss: 1.8406992984074417

Epoch: 5| Step: 2
Training loss: 1.4514753818511963
Validation loss: 1.8596211428283362

Epoch: 5| Step: 3
Training loss: 1.9760119915008545
Validation loss: 1.847971857234996

Epoch: 5| Step: 4
Training loss: 2.3269362449645996
Validation loss: 1.8180697579537668

Epoch: 5| Step: 5
Training loss: 1.6668249368667603
Validation loss: 1.822658443963656

Epoch: 5| Step: 6
Training loss: 1.8898143768310547
Validation loss: 1.8174252920253302

Epoch: 5| Step: 7
Training loss: 1.719223976135254
Validation loss: 1.8262594951096403

Epoch: 5| Step: 8
Training loss: 1.902579665184021
Validation loss: 1.8083221527837938

Epoch: 5| Step: 9
Training loss: 2.2229506969451904
Validation loss: 1.8256704076643913

Epoch: 5| Step: 10
Training loss: 2.519683361053467
Validation loss: 1.8112725903910976

Epoch: 139| Step: 0
Training loss: 2.24808931350708
Validation loss: 1.8226507376599055

Epoch: 5| Step: 1
Training loss: 2.21510648727417
Validation loss: 1.8546903453847414

Epoch: 5| Step: 2
Training loss: 1.8767521381378174
Validation loss: 1.8311973669195687

Epoch: 5| Step: 3
Training loss: 1.5032713413238525
Validation loss: 1.806914003946448

Epoch: 5| Step: 4
Training loss: 2.0527360439300537
Validation loss: 1.8280942337487334

Epoch: 5| Step: 5
Training loss: 2.3151116371154785
Validation loss: 1.8133052651600172

Epoch: 5| Step: 6
Training loss: 2.369595766067505
Validation loss: 1.8150837177871375

Epoch: 5| Step: 7
Training loss: 1.4927467107772827
Validation loss: 1.8394021398277693

Epoch: 5| Step: 8
Training loss: 1.7082185745239258
Validation loss: 1.806647067428917

Epoch: 5| Step: 9
Training loss: 1.6706148386001587
Validation loss: 1.8209494621522966

Epoch: 5| Step: 10
Training loss: 1.9606105089187622
Validation loss: 1.8548905875093193

Epoch: 140| Step: 0
Training loss: 2.3416852951049805
Validation loss: 1.8474408977775163

Epoch: 5| Step: 1
Training loss: 2.1983540058135986
Validation loss: 1.8649348084644606

Epoch: 5| Step: 2
Training loss: 1.9606136083602905
Validation loss: 1.8464317757596251

Epoch: 5| Step: 3
Training loss: 1.467466115951538
Validation loss: 1.8593163464659004

Epoch: 5| Step: 4
Training loss: 1.2915202379226685
Validation loss: 1.835425692219888

Epoch: 5| Step: 5
Training loss: 1.880178451538086
Validation loss: 1.8327661944973854

Epoch: 5| Step: 6
Training loss: 2.3746116161346436
Validation loss: 1.8595805373243106

Epoch: 5| Step: 7
Training loss: 2.141144037246704
Validation loss: 1.8361707425886584

Epoch: 5| Step: 8
Training loss: 2.1370677947998047
Validation loss: 1.8509277169422438

Epoch: 5| Step: 9
Training loss: 1.5999667644500732
Validation loss: 1.8391797222116941

Epoch: 5| Step: 10
Training loss: 2.121931791305542
Validation loss: 1.8265989121570383

Epoch: 141| Step: 0
Training loss: 2.0732274055480957
Validation loss: 1.8276509725919334

Epoch: 5| Step: 1
Training loss: 1.8661693334579468
Validation loss: 1.8219360766872283

Epoch: 5| Step: 2
Training loss: 1.9666290283203125
Validation loss: 1.8356607960116478

Epoch: 5| Step: 3
Training loss: 1.9664722681045532
Validation loss: 1.8482874234517415

Epoch: 5| Step: 4
Training loss: 2.41196870803833
Validation loss: 1.8406588364672918

Epoch: 5| Step: 5
Training loss: 1.7984285354614258
Validation loss: 1.826663863274359

Epoch: 5| Step: 6
Training loss: 1.726976752281189
Validation loss: 1.8137506708022086

Epoch: 5| Step: 7
Training loss: 1.2214267253875732
Validation loss: 1.8258532708691013

Epoch: 5| Step: 8
Training loss: 1.9757274389266968
Validation loss: 1.83293483718749

Epoch: 5| Step: 9
Training loss: 1.7215359210968018
Validation loss: 1.8253732573601507

Epoch: 5| Step: 10
Training loss: 2.5487585067749023
Validation loss: 1.832520184978362

Epoch: 142| Step: 0
Training loss: 1.6132175922393799
Validation loss: 1.8354766804684874

Epoch: 5| Step: 1
Training loss: 2.1186490058898926
Validation loss: 1.8398681174042404

Epoch: 5| Step: 2
Training loss: 2.1318306922912598
Validation loss: 1.832071292784906

Epoch: 5| Step: 3
Training loss: 2.0512499809265137
Validation loss: 1.8097953245203982

Epoch: 5| Step: 4
Training loss: 1.780790090560913
Validation loss: 1.8078008262060021

Epoch: 5| Step: 5
Training loss: 1.7804111242294312
Validation loss: 1.8323162153203

Epoch: 5| Step: 6
Training loss: 1.9484758377075195
Validation loss: 1.8058789007125362

Epoch: 5| Step: 7
Training loss: 1.4814494848251343
Validation loss: 1.8195254443794169

Epoch: 5| Step: 8
Training loss: 1.8743650913238525
Validation loss: 1.8319793772953812

Epoch: 5| Step: 9
Training loss: 2.332594633102417
Validation loss: 1.8231670420656922

Epoch: 5| Step: 10
Training loss: 2.329313278198242
Validation loss: 1.817779153905889

Epoch: 143| Step: 0
Training loss: 1.6804111003875732
Validation loss: 1.81585140638454

Epoch: 5| Step: 1
Training loss: 2.525740146636963
Validation loss: 1.8194865462600545

Epoch: 5| Step: 2
Training loss: 1.308458685874939
Validation loss: 1.8519844137212282

Epoch: 5| Step: 3
Training loss: 1.5812686681747437
Validation loss: 1.8775775240313621

Epoch: 5| Step: 4
Training loss: 1.4795783758163452
Validation loss: 1.8557977855846446

Epoch: 5| Step: 5
Training loss: 2.0906028747558594
Validation loss: 1.8623913731626285

Epoch: 5| Step: 6
Training loss: 1.9741413593292236
Validation loss: 1.8863203615270636

Epoch: 5| Step: 7
Training loss: 1.8736635446548462
Validation loss: 1.888204074675037

Epoch: 5| Step: 8
Training loss: 2.9314348697662354
Validation loss: 1.87935681240533

Epoch: 5| Step: 9
Training loss: 1.7083041667938232
Validation loss: 1.8941365749605241

Epoch: 5| Step: 10
Training loss: 2.1551568508148193
Validation loss: 1.865022974629556

Epoch: 144| Step: 0
Training loss: 2.1102752685546875
Validation loss: 1.8504485827620312

Epoch: 5| Step: 1
Training loss: 1.6366703510284424
Validation loss: 1.8775507070684945

Epoch: 5| Step: 2
Training loss: 2.105048418045044
Validation loss: 1.8427966140931653

Epoch: 5| Step: 3
Training loss: 1.4258769750595093
Validation loss: 1.8110685835602462

Epoch: 5| Step: 4
Training loss: 2.1305413246154785
Validation loss: 1.8240931469907042

Epoch: 5| Step: 5
Training loss: 1.8322235345840454
Validation loss: 1.8258177670099403

Epoch: 5| Step: 6
Training loss: 1.9030609130859375
Validation loss: 1.8241432559105657

Epoch: 5| Step: 7
Training loss: 2.2727036476135254
Validation loss: 1.8315011044984222

Epoch: 5| Step: 8
Training loss: 1.9268217086791992
Validation loss: 1.8292637768612112

Epoch: 5| Step: 9
Training loss: 1.710436463356018
Validation loss: 1.7810580935529483

Epoch: 5| Step: 10
Training loss: 2.3346807956695557
Validation loss: 1.8313634703236241

Epoch: 145| Step: 0
Training loss: 2.0454254150390625
Validation loss: 1.8022202061068626

Epoch: 5| Step: 1
Training loss: 1.3896980285644531
Validation loss: 1.8289657433827717

Epoch: 5| Step: 2
Training loss: 1.6018699407577515
Validation loss: 1.8164670659649758

Epoch: 5| Step: 3
Training loss: 1.4502170085906982
Validation loss: 1.8355221799624863

Epoch: 5| Step: 4
Training loss: 2.3558712005615234
Validation loss: 1.8428741014131935

Epoch: 5| Step: 5
Training loss: 2.315054416656494
Validation loss: 1.8034545426727624

Epoch: 5| Step: 6
Training loss: 1.6516571044921875
Validation loss: 1.8289611339569092

Epoch: 5| Step: 7
Training loss: 2.138728618621826
Validation loss: 1.8346928114532142

Epoch: 5| Step: 8
Training loss: 2.0330464839935303
Validation loss: 1.8565636168244064

Epoch: 5| Step: 9
Training loss: 1.8390175104141235
Validation loss: 1.8293050899300525

Epoch: 5| Step: 10
Training loss: 2.2312886714935303
Validation loss: 1.8520026719698341

Epoch: 146| Step: 0
Training loss: 2.071045160293579
Validation loss: 1.8583124017202726

Epoch: 5| Step: 1
Training loss: 2.353524684906006
Validation loss: 1.8302510540972474

Epoch: 5| Step: 2
Training loss: 1.9249740839004517
Validation loss: 1.8505724104501868

Epoch: 5| Step: 3
Training loss: 1.625328779220581
Validation loss: 1.8279155992692517

Epoch: 5| Step: 4
Training loss: 1.5341135263442993
Validation loss: 1.8645794981269426

Epoch: 5| Step: 5
Training loss: 2.0649466514587402
Validation loss: 1.8350494196338039

Epoch: 5| Step: 6
Training loss: 2.1531965732574463
Validation loss: 1.8365807430718535

Epoch: 5| Step: 7
Training loss: 1.8573246002197266
Validation loss: 1.861008151885002

Epoch: 5| Step: 8
Training loss: 1.7440478801727295
Validation loss: 1.8470699864049112

Epoch: 5| Step: 9
Training loss: 1.6533496379852295
Validation loss: 1.8376039638314197

Epoch: 5| Step: 10
Training loss: 2.0402231216430664
Validation loss: 1.8631049074152464

Epoch: 147| Step: 0
Training loss: 2.23032283782959
Validation loss: 1.829320062873184

Epoch: 5| Step: 1
Training loss: 1.8972069025039673
Validation loss: 1.8024284621720672

Epoch: 5| Step: 2
Training loss: 1.981956124305725
Validation loss: 1.8092616117128761

Epoch: 5| Step: 3
Training loss: 1.977378487586975
Validation loss: 1.8135468626535067

Epoch: 5| Step: 4
Training loss: 2.01285719871521
Validation loss: 1.8365422999987038

Epoch: 5| Step: 5
Training loss: 1.7303428649902344
Validation loss: 1.8074678015965286

Epoch: 5| Step: 6
Training loss: 2.705174684524536
Validation loss: 1.8131082839863275

Epoch: 5| Step: 7
Training loss: 1.3366453647613525
Validation loss: 1.8144663482583978

Epoch: 5| Step: 8
Training loss: 1.7097222805023193
Validation loss: 1.8025587233163978

Epoch: 5| Step: 9
Training loss: 1.8844616413116455
Validation loss: 1.8044860401461202

Epoch: 5| Step: 10
Training loss: 1.7760990858078003
Validation loss: 1.8095898884598927

Epoch: 148| Step: 0
Training loss: 1.7590926885604858
Validation loss: 1.8099275853044243

Epoch: 5| Step: 1
Training loss: 1.8628807067871094
Validation loss: 1.8207039909978067

Epoch: 5| Step: 2
Training loss: 2.0772671699523926
Validation loss: 1.8254301035276024

Epoch: 5| Step: 3
Training loss: 1.9669939279556274
Validation loss: 1.833736253041093

Epoch: 5| Step: 4
Training loss: 1.9144248962402344
Validation loss: 1.8597934246063232

Epoch: 5| Step: 5
Training loss: 1.6665432453155518
Validation loss: 1.8435177380038845

Epoch: 5| Step: 6
Training loss: 1.9769668579101562
Validation loss: 1.8501333690458728

Epoch: 5| Step: 7
Training loss: 2.0290846824645996
Validation loss: 1.8643056372160554

Epoch: 5| Step: 8
Training loss: 2.420879364013672
Validation loss: 1.8826017123396679

Epoch: 5| Step: 9
Training loss: 1.5558735132217407
Validation loss: 1.878521639813659

Epoch: 5| Step: 10
Training loss: 1.628880500793457
Validation loss: 1.8624223150232786

Epoch: 149| Step: 0
Training loss: 1.9903459548950195
Validation loss: 1.8539080683903029

Epoch: 5| Step: 1
Training loss: 1.6190372705459595
Validation loss: 1.860256819314854

Epoch: 5| Step: 2
Training loss: 1.3710155487060547
Validation loss: 1.8655103688598962

Epoch: 5| Step: 3
Training loss: 1.4930546283721924
Validation loss: 1.8579295848005561

Epoch: 5| Step: 4
Training loss: 1.9162533283233643
Validation loss: 1.8515333283332087

Epoch: 5| Step: 5
Training loss: 1.3552508354187012
Validation loss: 1.858477864214169

Epoch: 5| Step: 6
Training loss: 2.384953022003174
Validation loss: 1.8408672258418093

Epoch: 5| Step: 7
Training loss: 2.2338454723358154
Validation loss: 1.8677849936228927

Epoch: 5| Step: 8
Training loss: 2.157694101333618
Validation loss: 1.8461873723614601

Epoch: 5| Step: 9
Training loss: 2.343344211578369
Validation loss: 1.8302985596400436

Epoch: 5| Step: 10
Training loss: 2.0409719944000244
Validation loss: 1.8667033910751343

Epoch: 150| Step: 0
Training loss: 2.2636752128601074
Validation loss: 1.8337069506286292

Epoch: 5| Step: 1
Training loss: 2.181577205657959
Validation loss: 1.8135827664406068

Epoch: 5| Step: 2
Training loss: 1.3397817611694336
Validation loss: 1.841126641919536

Epoch: 5| Step: 3
Training loss: 1.6666818857192993
Validation loss: 1.8338788094059113

Epoch: 5| Step: 4
Training loss: 2.5517032146453857
Validation loss: 1.844178791969053

Epoch: 5| Step: 5
Training loss: 1.4084875583648682
Validation loss: 1.8359538201362855

Epoch: 5| Step: 6
Training loss: 1.493818998336792
Validation loss: 1.8312688976205804

Epoch: 5| Step: 7
Training loss: 1.2611149549484253
Validation loss: 1.8106896595288349

Epoch: 5| Step: 8
Training loss: 2.3074398040771484
Validation loss: 1.7987426570666734

Epoch: 5| Step: 9
Training loss: 1.9584095478057861
Validation loss: 1.8024055380975046

Epoch: 5| Step: 10
Training loss: 2.5579986572265625
Validation loss: 1.80631725506116

Epoch: 151| Step: 0
Training loss: 2.0536282062530518
Validation loss: 1.8093616103613248

Epoch: 5| Step: 1
Training loss: 2.13673734664917
Validation loss: 1.8114726710063156

Epoch: 5| Step: 2
Training loss: 2.132800579071045
Validation loss: 1.821408679408412

Epoch: 5| Step: 3
Training loss: 2.1666016578674316
Validation loss: 1.838007188612415

Epoch: 5| Step: 4
Training loss: 2.0281569957733154
Validation loss: 1.838232022459789

Epoch: 5| Step: 5
Training loss: 1.4376790523529053
Validation loss: 1.8662761142176967

Epoch: 5| Step: 6
Training loss: 1.7794544696807861
Validation loss: 1.8542087642095422

Epoch: 5| Step: 7
Training loss: 1.66580331325531
Validation loss: 1.8457386186045985

Epoch: 5| Step: 8
Training loss: 1.574446439743042
Validation loss: 1.880369032582929

Epoch: 5| Step: 9
Training loss: 2.2819626331329346
Validation loss: 1.853483130854945

Epoch: 5| Step: 10
Training loss: 1.849646806716919
Validation loss: 1.852070837892512

Epoch: 152| Step: 0
Training loss: 1.824951171875
Validation loss: 1.8483886770022813

Epoch: 5| Step: 1
Training loss: 2.2875280380249023
Validation loss: 1.8632082490510837

Epoch: 5| Step: 2
Training loss: 1.669190764427185
Validation loss: 1.852279378521827

Epoch: 5| Step: 3
Training loss: 2.3005053997039795
Validation loss: 1.851805156277072

Epoch: 5| Step: 4
Training loss: 1.5877487659454346
Validation loss: 1.8597362554201515

Epoch: 5| Step: 5
Training loss: 2.2610011100769043
Validation loss: 1.8746705362873692

Epoch: 5| Step: 6
Training loss: 2.0040576457977295
Validation loss: 1.877084888437743

Epoch: 5| Step: 7
Training loss: 1.672295331954956
Validation loss: 1.8382755043686076

Epoch: 5| Step: 8
Training loss: 1.9674793481826782
Validation loss: 1.83422339218919

Epoch: 5| Step: 9
Training loss: 1.6117429733276367
Validation loss: 1.8137260944612565

Epoch: 5| Step: 10
Training loss: 1.5722535848617554
Validation loss: 1.8550643664534374

Epoch: 153| Step: 0
Training loss: 1.4118573665618896
Validation loss: 1.8409354840555499

Epoch: 5| Step: 1
Training loss: 1.850012183189392
Validation loss: 1.832438317678308

Epoch: 5| Step: 2
Training loss: 1.90838623046875
Validation loss: 1.837476945692493

Epoch: 5| Step: 3
Training loss: 2.0634734630584717
Validation loss: 1.821115057955506

Epoch: 5| Step: 4
Training loss: 2.097637891769409
Validation loss: 1.8039899167194162

Epoch: 5| Step: 5
Training loss: 1.9623210430145264
Validation loss: 1.8232257032907138

Epoch: 5| Step: 6
Training loss: 1.9707176685333252
Validation loss: 1.8203596530422088

Epoch: 5| Step: 7
Training loss: 1.8423397541046143
Validation loss: 1.7874378286382204

Epoch: 5| Step: 8
Training loss: 2.100478410720825
Validation loss: 1.8129773780863772

Epoch: 5| Step: 9
Training loss: 1.6137834787368774
Validation loss: 1.8001051615643244

Epoch: 5| Step: 10
Training loss: 1.9556968212127686
Validation loss: 1.8130633215750418

Epoch: 154| Step: 0
Training loss: 2.105062246322632
Validation loss: 1.8275677901442333

Epoch: 5| Step: 1
Training loss: 1.6308656930923462
Validation loss: 1.836403577558456

Epoch: 5| Step: 2
Training loss: 2.067816972732544
Validation loss: 1.8521979367861183

Epoch: 5| Step: 3
Training loss: 1.2662197351455688
Validation loss: 1.824636802878431

Epoch: 5| Step: 4
Training loss: 2.269486665725708
Validation loss: 1.8264494237079416

Epoch: 5| Step: 5
Training loss: 1.9417212009429932
Validation loss: 1.8323670151413127

Epoch: 5| Step: 6
Training loss: 1.7610480785369873
Validation loss: 1.8425072841746832

Epoch: 5| Step: 7
Training loss: 1.748939871788025
Validation loss: 1.8161998384742326

Epoch: 5| Step: 8
Training loss: 2.3971805572509766
Validation loss: 1.8526086332977458

Epoch: 5| Step: 9
Training loss: 2.140460252761841
Validation loss: 1.832597203152154

Epoch: 5| Step: 10
Training loss: 1.3857927322387695
Validation loss: 1.8504919736616072

Epoch: 155| Step: 0
Training loss: 2.0321826934814453
Validation loss: 1.8203749272131151

Epoch: 5| Step: 1
Training loss: 2.091662883758545
Validation loss: 1.864445092857525

Epoch: 5| Step: 2
Training loss: 0.9632436037063599
Validation loss: 1.8373641519136326

Epoch: 5| Step: 3
Training loss: 1.573102593421936
Validation loss: 1.850807725742299

Epoch: 5| Step: 4
Training loss: 2.262521266937256
Validation loss: 1.8470740087570683

Epoch: 5| Step: 5
Training loss: 1.9684476852416992
Validation loss: 1.842655908676886

Epoch: 5| Step: 6
Training loss: 2.1518940925598145
Validation loss: 1.8447456949500627

Epoch: 5| Step: 7
Training loss: 1.413865089416504
Validation loss: 1.8250833685680101

Epoch: 5| Step: 8
Training loss: 2.408127546310425
Validation loss: 1.8274744185068275

Epoch: 5| Step: 9
Training loss: 1.4843648672103882
Validation loss: 1.8360556325604838

Epoch: 5| Step: 10
Training loss: 2.6036243438720703
Validation loss: 1.8172194957733154

Epoch: 156| Step: 0
Training loss: 1.8664573431015015
Validation loss: 1.8176109354983094

Epoch: 5| Step: 1
Training loss: 2.320242404937744
Validation loss: 1.8365814403821064

Epoch: 5| Step: 2
Training loss: 2.0404064655303955
Validation loss: 1.8111315645197386

Epoch: 5| Step: 3
Training loss: 1.6446716785430908
Validation loss: 1.859087400538947

Epoch: 5| Step: 4
Training loss: 1.512290358543396
Validation loss: 1.8281683357813026

Epoch: 5| Step: 5
Training loss: 2.389315605163574
Validation loss: 1.8354630726639942

Epoch: 5| Step: 6
Training loss: 1.5927984714508057
Validation loss: 1.8351691397287513

Epoch: 5| Step: 7
Training loss: 1.6898279190063477
Validation loss: 1.8534630101214173

Epoch: 5| Step: 8
Training loss: 1.9592115879058838
Validation loss: 1.8458514469926075

Epoch: 5| Step: 9
Training loss: 2.0734190940856934
Validation loss: 1.8463634175638999

Epoch: 5| Step: 10
Training loss: 1.45293390750885
Validation loss: 1.831816957842919

Epoch: 157| Step: 0
Training loss: 1.2894299030303955
Validation loss: 1.838125939010292

Epoch: 5| Step: 1
Training loss: 2.199711322784424
Validation loss: 1.8263026860452467

Epoch: 5| Step: 2
Training loss: 1.8412727117538452
Validation loss: 1.8247516783334876

Epoch: 5| Step: 3
Training loss: 1.7280795574188232
Validation loss: 1.8713909964407645

Epoch: 5| Step: 4
Training loss: 2.1157889366149902
Validation loss: 1.8539419199830742

Epoch: 5| Step: 5
Training loss: 1.5739473104476929
Validation loss: 1.8394239820459837

Epoch: 5| Step: 6
Training loss: 1.4794397354125977
Validation loss: 1.8552189219382502

Epoch: 5| Step: 7
Training loss: 2.3201451301574707
Validation loss: 1.8531764835439704

Epoch: 5| Step: 8
Training loss: 2.3002569675445557
Validation loss: 1.8511950226240261

Epoch: 5| Step: 9
Training loss: 2.304036855697632
Validation loss: 1.8586767168455227

Epoch: 5| Step: 10
Training loss: 1.4308580160140991
Validation loss: 1.8455841823290753

Epoch: 158| Step: 0
Training loss: 2.0110011100769043
Validation loss: 1.8268426054267473

Epoch: 5| Step: 1
Training loss: 2.019185781478882
Validation loss: 1.8237691181962208

Epoch: 5| Step: 2
Training loss: 1.4986283779144287
Validation loss: 1.818299651145935

Epoch: 5| Step: 3
Training loss: 1.4585731029510498
Validation loss: 1.8098574774239653

Epoch: 5| Step: 4
Training loss: 1.9442625045776367
Validation loss: 1.8089957019334197

Epoch: 5| Step: 5
Training loss: 1.3377403020858765
Validation loss: 1.7941536441926034

Epoch: 5| Step: 6
Training loss: 1.4907262325286865
Validation loss: 1.7891557088462255

Epoch: 5| Step: 7
Training loss: 1.9370603561401367
Validation loss: 1.8062522347255419

Epoch: 5| Step: 8
Training loss: 2.129347085952759
Validation loss: 1.7871982115571217

Epoch: 5| Step: 9
Training loss: 2.940863847732544
Validation loss: 1.8282518361204414

Epoch: 5| Step: 10
Training loss: 1.7756797075271606
Validation loss: 1.7792091523447344

Epoch: 159| Step: 0
Training loss: 1.7569549083709717
Validation loss: 1.8018446506992463

Epoch: 5| Step: 1
Training loss: 2.7597506046295166
Validation loss: 1.7960171443159862

Epoch: 5| Step: 2
Training loss: 1.267886757850647
Validation loss: 1.8225771534827448

Epoch: 5| Step: 3
Training loss: 1.9450397491455078
Validation loss: 1.8203847715931554

Epoch: 5| Step: 4
Training loss: 1.983282446861267
Validation loss: 1.8302733513616747

Epoch: 5| Step: 5
Training loss: 2.0714004039764404
Validation loss: 1.8229309192267797

Epoch: 5| Step: 6
Training loss: 2.1033568382263184
Validation loss: 1.841500159232847

Epoch: 5| Step: 7
Training loss: 2.1244146823883057
Validation loss: 1.8524608573605936

Epoch: 5| Step: 8
Training loss: 1.4559624195098877
Validation loss: 1.8496272563934326

Epoch: 5| Step: 9
Training loss: 1.4151208400726318
Validation loss: 1.835082063110926

Epoch: 5| Step: 10
Training loss: 1.8376586437225342
Validation loss: 1.8648748256826913

Epoch: 160| Step: 0
Training loss: 1.7030149698257446
Validation loss: 1.828224697420674

Epoch: 5| Step: 1
Training loss: 1.5797284841537476
Validation loss: 1.8312913602398289

Epoch: 5| Step: 2
Training loss: 2.0295679569244385
Validation loss: 1.833512012676526

Epoch: 5| Step: 3
Training loss: 2.2112393379211426
Validation loss: 1.8591138547466648

Epoch: 5| Step: 4
Training loss: 1.6531108617782593
Validation loss: 1.8394207210950955

Epoch: 5| Step: 5
Training loss: 1.4844515323638916
Validation loss: 1.8360342799976308

Epoch: 5| Step: 6
Training loss: 2.0663466453552246
Validation loss: 1.8119612470749886

Epoch: 5| Step: 7
Training loss: 1.9489609003067017
Validation loss: 1.8105413208725631

Epoch: 5| Step: 8
Training loss: 1.9122202396392822
Validation loss: 1.8181943931887228

Epoch: 5| Step: 9
Training loss: 1.9388628005981445
Validation loss: 1.8405916229371102

Epoch: 5| Step: 10
Training loss: 2.065814733505249
Validation loss: 1.8188555458540558

Epoch: 161| Step: 0
Training loss: 2.856555461883545
Validation loss: 1.8499910972451652

Epoch: 5| Step: 1
Training loss: 1.5212455987930298
Validation loss: 1.7926787150803434

Epoch: 5| Step: 2
Training loss: 1.7665340900421143
Validation loss: 1.8308519624894666

Epoch: 5| Step: 3
Training loss: 1.8720600605010986
Validation loss: 1.8563926091758154

Epoch: 5| Step: 4
Training loss: 2.18687105178833
Validation loss: 1.8301889460573915

Epoch: 5| Step: 5
Training loss: 1.4956029653549194
Validation loss: 1.8179183237014278

Epoch: 5| Step: 6
Training loss: 1.9204845428466797
Validation loss: 1.8465456731857792

Epoch: 5| Step: 7
Training loss: 1.752619981765747
Validation loss: 1.8738212059902888

Epoch: 5| Step: 8
Training loss: 2.0834293365478516
Validation loss: 1.8537180321190947

Epoch: 5| Step: 9
Training loss: 1.1732540130615234
Validation loss: 1.839853907144198

Epoch: 5| Step: 10
Training loss: 1.7179652452468872
Validation loss: 1.8451498041870773

Epoch: 162| Step: 0
Training loss: 1.8497540950775146
Validation loss: 1.8434606957179245

Epoch: 5| Step: 1
Training loss: 2.335930585861206
Validation loss: 1.845012313576155

Epoch: 5| Step: 2
Training loss: 1.400519609451294
Validation loss: 1.8345649742311048

Epoch: 5| Step: 3
Training loss: 1.1748979091644287
Validation loss: 1.8212407378740207

Epoch: 5| Step: 4
Training loss: 2.613417863845825
Validation loss: 1.8266161475130307

Epoch: 5| Step: 5
Training loss: 1.6800587177276611
Validation loss: 1.8174237115408785

Epoch: 5| Step: 6
Training loss: 1.5573863983154297
Validation loss: 1.828613547868626

Epoch: 5| Step: 7
Training loss: 1.5063755512237549
Validation loss: 1.829935835894718

Epoch: 5| Step: 8
Training loss: 1.6599239110946655
Validation loss: 1.8160925936955277

Epoch: 5| Step: 9
Training loss: 2.2545604705810547
Validation loss: 1.8306798832390898

Epoch: 5| Step: 10
Training loss: 2.3158621788024902
Validation loss: 1.8265327240831108

Epoch: 163| Step: 0
Training loss: 1.961008071899414
Validation loss: 1.8552260283500916

Epoch: 5| Step: 1
Training loss: 1.8081977367401123
Validation loss: 1.8204141829603462

Epoch: 5| Step: 2
Training loss: 1.5851399898529053
Validation loss: 1.813661854754212

Epoch: 5| Step: 3
Training loss: 1.958660364151001
Validation loss: 1.775532272554213

Epoch: 5| Step: 4
Training loss: 1.7955687046051025
Validation loss: 1.8172045292392853

Epoch: 5| Step: 5
Training loss: 2.058300733566284
Validation loss: 1.8112564702187814

Epoch: 5| Step: 6
Training loss: 1.842820405960083
Validation loss: 1.7947185936794485

Epoch: 5| Step: 7
Training loss: 1.8496841192245483
Validation loss: 1.8071535351455852

Epoch: 5| Step: 8
Training loss: 2.2675609588623047
Validation loss: 1.8076086544221448

Epoch: 5| Step: 9
Training loss: 1.584627389907837
Validation loss: 1.7874241528972503

Epoch: 5| Step: 10
Training loss: 1.3833816051483154
Validation loss: 1.8428484983341669

Epoch: 164| Step: 0
Training loss: 1.768402099609375
Validation loss: 1.8107001294371903

Epoch: 5| Step: 1
Training loss: 1.8815748691558838
Validation loss: 1.8424658390783495

Epoch: 5| Step: 2
Training loss: 2.1335387229919434
Validation loss: 1.84763535376518

Epoch: 5| Step: 3
Training loss: 1.5948318243026733
Validation loss: 1.840454432272142

Epoch: 5| Step: 4
Training loss: 1.444475769996643
Validation loss: 1.8435311291807441

Epoch: 5| Step: 5
Training loss: 1.835187554359436
Validation loss: 1.859891091623614

Epoch: 5| Step: 6
Training loss: 1.956437110900879
Validation loss: 1.9040195518924343

Epoch: 5| Step: 7
Training loss: 1.926865816116333
Validation loss: 1.8784850733254546

Epoch: 5| Step: 8
Training loss: 2.3610787391662598
Validation loss: 1.8639494475497995

Epoch: 5| Step: 9
Training loss: 1.5857253074645996
Validation loss: 1.8369713265408751

Epoch: 5| Step: 10
Training loss: 1.789891004562378
Validation loss: 1.874706752838627

Epoch: 165| Step: 0
Training loss: 1.667351484298706
Validation loss: 1.8350299135331185

Epoch: 5| Step: 1
Training loss: 1.7426321506500244
Validation loss: 1.848951998577323

Epoch: 5| Step: 2
Training loss: 2.0848889350891113
Validation loss: 1.8305233217054797

Epoch: 5| Step: 3
Training loss: 1.9519773721694946
Validation loss: 1.8144670929960025

Epoch: 5| Step: 4
Training loss: 1.5038607120513916
Validation loss: 1.8118732424192532

Epoch: 5| Step: 5
Training loss: 1.8607900142669678
Validation loss: 1.8298865261898245

Epoch: 5| Step: 6
Training loss: 1.46913743019104
Validation loss: 1.7900901340669202

Epoch: 5| Step: 7
Training loss: 1.8073298931121826
Validation loss: 1.8234340734379266

Epoch: 5| Step: 8
Training loss: 2.0850424766540527
Validation loss: 1.8390025797710623

Epoch: 5| Step: 9
Training loss: 2.454969882965088
Validation loss: 1.8027193956477667

Epoch: 5| Step: 10
Training loss: 1.7544649839401245
Validation loss: 1.7899237742988012

Epoch: 166| Step: 0
Training loss: 1.669790267944336
Validation loss: 1.8319437324359853

Epoch: 5| Step: 1
Training loss: 2.080338954925537
Validation loss: 1.8095033707157258

Epoch: 5| Step: 2
Training loss: 1.449989676475525
Validation loss: 1.7639549586080736

Epoch: 5| Step: 3
Training loss: 1.7925891876220703
Validation loss: 1.8129469758720809

Epoch: 5| Step: 4
Training loss: 1.7289540767669678
Validation loss: 1.807452077506691

Epoch: 5| Step: 5
Training loss: 1.99911630153656
Validation loss: 1.7880539650558143

Epoch: 5| Step: 6
Training loss: 2.564415454864502
Validation loss: 1.8111066177327146

Epoch: 5| Step: 7
Training loss: 1.4722932577133179
Validation loss: 1.8027662218257945

Epoch: 5| Step: 8
Training loss: 2.1957812309265137
Validation loss: 1.8062877091028358

Epoch: 5| Step: 9
Training loss: 1.4982601404190063
Validation loss: 1.8257651444404357

Epoch: 5| Step: 10
Training loss: 1.8166894912719727
Validation loss: 1.8007714581745926

Epoch: 167| Step: 0
Training loss: 2.219569444656372
Validation loss: 1.8248854555109495

Epoch: 5| Step: 1
Training loss: 2.1509902477264404
Validation loss: 1.8372705341667257

Epoch: 5| Step: 2
Training loss: 1.558262825012207
Validation loss: 1.8506083232100292

Epoch: 5| Step: 3
Training loss: 1.6079727411270142
Validation loss: 1.821348669708416

Epoch: 5| Step: 4
Training loss: 2.0706591606140137
Validation loss: 1.8706614509705575

Epoch: 5| Step: 5
Training loss: 1.8829882144927979
Validation loss: 1.8581430450562508

Epoch: 5| Step: 6
Training loss: 1.8482519388198853
Validation loss: 1.8865469694137573

Epoch: 5| Step: 7
Training loss: 1.934100866317749
Validation loss: 1.8341294975690945

Epoch: 5| Step: 8
Training loss: 1.7526237964630127
Validation loss: 1.8539336458329232

Epoch: 5| Step: 9
Training loss: 1.7176189422607422
Validation loss: 1.8571224417737735

Epoch: 5| Step: 10
Training loss: 1.499374508857727
Validation loss: 1.85647234096322

Epoch: 168| Step: 0
Training loss: 1.5708928108215332
Validation loss: 1.82230665094109

Epoch: 5| Step: 1
Training loss: 1.6677440404891968
Validation loss: 1.8283595884999921

Epoch: 5| Step: 2
Training loss: 1.9049991369247437
Validation loss: 1.8285967508951824

Epoch: 5| Step: 3
Training loss: 1.7739406824111938
Validation loss: 1.807115170263475

Epoch: 5| Step: 4
Training loss: 2.019958972930908
Validation loss: 1.8262363902984127

Epoch: 5| Step: 5
Training loss: 1.694200873374939
Validation loss: 1.8101797437155118

Epoch: 5| Step: 6
Training loss: 2.2677197456359863
Validation loss: 1.8242515415273688

Epoch: 5| Step: 7
Training loss: 1.7927615642547607
Validation loss: 1.792660932387075

Epoch: 5| Step: 8
Training loss: 1.9287645816802979
Validation loss: 1.8109253965398318

Epoch: 5| Step: 9
Training loss: 1.9072870016098022
Validation loss: 1.798927559647509

Epoch: 5| Step: 10
Training loss: 1.5325357913970947
Validation loss: 1.8131965526970484

Epoch: 169| Step: 0
Training loss: 2.3166420459747314
Validation loss: 1.8095505429852394

Epoch: 5| Step: 1
Training loss: 1.728925347328186
Validation loss: 1.7918941487548172

Epoch: 5| Step: 2
Training loss: 1.0483310222625732
Validation loss: 1.81968673839364

Epoch: 5| Step: 3
Training loss: 1.8198257684707642
Validation loss: 1.7999567613806775

Epoch: 5| Step: 4
Training loss: 1.9353621006011963
Validation loss: 1.8066590332215833

Epoch: 5| Step: 5
Training loss: 2.026820659637451
Validation loss: 1.8404837180209417

Epoch: 5| Step: 6
Training loss: 1.5837072134017944
Validation loss: 1.870771078653233

Epoch: 5| Step: 7
Training loss: 1.0914690494537354
Validation loss: 1.8272174558331888

Epoch: 5| Step: 8
Training loss: 2.029557704925537
Validation loss: 1.860761611692367

Epoch: 5| Step: 9
Training loss: 2.6136364936828613
Validation loss: 1.820135840805628

Epoch: 5| Step: 10
Training loss: 1.7973980903625488
Validation loss: 1.848115982547883

Epoch: 170| Step: 0
Training loss: 1.6344867944717407
Validation loss: 1.8539287428702078

Epoch: 5| Step: 1
Training loss: 1.4748904705047607
Validation loss: 1.8406962361387027

Epoch: 5| Step: 2
Training loss: 1.3723467588424683
Validation loss: 1.8385703640599405

Epoch: 5| Step: 3
Training loss: 2.0947678089141846
Validation loss: 1.8324975223951443

Epoch: 5| Step: 4
Training loss: 2.039085626602173
Validation loss: 1.7906960825766287

Epoch: 5| Step: 5
Training loss: 1.9428775310516357
Validation loss: 1.813575570301343

Epoch: 5| Step: 6
Training loss: 1.7541027069091797
Validation loss: 1.7975890059624948

Epoch: 5| Step: 7
Training loss: 2.5951545238494873
Validation loss: 1.8101920453451013

Epoch: 5| Step: 8
Training loss: 1.9217541217803955
Validation loss: 1.8288319008324736

Epoch: 5| Step: 9
Training loss: 1.7707183361053467
Validation loss: 1.8054603658696657

Epoch: 5| Step: 10
Training loss: 1.4007364511489868
Validation loss: 1.8117420519551923

Epoch: 171| Step: 0
Training loss: 1.1427961587905884
Validation loss: 1.8365013112304032

Epoch: 5| Step: 1
Training loss: 1.9166101217269897
Validation loss: 1.8180516304508332

Epoch: 5| Step: 2
Training loss: 1.9710636138916016
Validation loss: 1.8490944139419063

Epoch: 5| Step: 3
Training loss: 1.8834302425384521
Validation loss: 1.8311052995343362

Epoch: 5| Step: 4
Training loss: 1.7881495952606201
Validation loss: 1.8557469088544127

Epoch: 5| Step: 5
Training loss: 1.5655580759048462
Validation loss: 1.841348518607437

Epoch: 5| Step: 6
Training loss: 2.585627794265747
Validation loss: 1.8510629054038756

Epoch: 5| Step: 7
Training loss: 1.9389703273773193
Validation loss: 1.8211871475301764

Epoch: 5| Step: 8
Training loss: 1.8907302618026733
Validation loss: 1.8290021778434835

Epoch: 5| Step: 9
Training loss: 1.8613941669464111
Validation loss: 1.8528372792787449

Epoch: 5| Step: 10
Training loss: 1.540419578552246
Validation loss: 1.8600592549129198

Epoch: 172| Step: 0
Training loss: 1.1450707912445068
Validation loss: 1.8382771643259193

Epoch: 5| Step: 1
Training loss: 1.9949934482574463
Validation loss: 1.848349722482825

Epoch: 5| Step: 2
Training loss: 1.2203388214111328
Validation loss: 1.8404269077444588

Epoch: 5| Step: 3
Training loss: 2.0261197090148926
Validation loss: 1.853058107437626

Epoch: 5| Step: 4
Training loss: 2.21171498298645
Validation loss: 1.8193387985229492

Epoch: 5| Step: 5
Training loss: 1.7598209381103516
Validation loss: 1.826544827030551

Epoch: 5| Step: 6
Training loss: 1.7144092321395874
Validation loss: 1.8090935753237816

Epoch: 5| Step: 7
Training loss: 1.887115478515625
Validation loss: 1.8377081553141277

Epoch: 5| Step: 8
Training loss: 2.069871425628662
Validation loss: 1.830246759999183

Epoch: 5| Step: 9
Training loss: 1.979286551475525
Validation loss: 1.8275138434543405

Epoch: 5| Step: 10
Training loss: 1.9715301990509033
Validation loss: 1.8124772066711097

Epoch: 173| Step: 0
Training loss: 1.9656562805175781
Validation loss: 1.8137012284289125

Epoch: 5| Step: 1
Training loss: 1.5683677196502686
Validation loss: 1.8413073042387604

Epoch: 5| Step: 2
Training loss: 1.8616979122161865
Validation loss: 1.8301459038129417

Epoch: 5| Step: 3
Training loss: 1.735060453414917
Validation loss: 1.7986731080598728

Epoch: 5| Step: 4
Training loss: 1.8272216320037842
Validation loss: 1.8353855750894035

Epoch: 5| Step: 5
Training loss: 1.7592195272445679
Validation loss: 1.8051231984169251

Epoch: 5| Step: 6
Training loss: 1.6764910221099854
Validation loss: 1.8577370220615017

Epoch: 5| Step: 7
Training loss: 2.05768084526062
Validation loss: 1.8646029580023982

Epoch: 5| Step: 8
Training loss: 1.6728694438934326
Validation loss: 1.8525069529010403

Epoch: 5| Step: 9
Training loss: 2.396048069000244
Validation loss: 1.861499724849578

Epoch: 5| Step: 10
Training loss: 1.4170136451721191
Validation loss: 1.8694792588551838

Epoch: 174| Step: 0
Training loss: 2.2866575717926025
Validation loss: 1.8662626153679305

Epoch: 5| Step: 1
Training loss: 1.1994264125823975
Validation loss: 1.8987152050900202

Epoch: 5| Step: 2
Training loss: 1.6288907527923584
Validation loss: 1.8459363906614241

Epoch: 5| Step: 3
Training loss: 2.575167417526245
Validation loss: 1.8403320825228127

Epoch: 5| Step: 4
Training loss: 1.0501635074615479
Validation loss: 1.7782013864927395

Epoch: 5| Step: 5
Training loss: 2.104954242706299
Validation loss: 1.8509956841827722

Epoch: 5| Step: 6
Training loss: 2.465325117111206
Validation loss: 1.8064955793401247

Epoch: 5| Step: 7
Training loss: 1.6464115381240845
Validation loss: 1.8173339674549718

Epoch: 5| Step: 8
Training loss: 1.7764289379119873
Validation loss: 1.7693233579717658

Epoch: 5| Step: 9
Training loss: 1.4526548385620117
Validation loss: 1.8010829956300798

Epoch: 5| Step: 10
Training loss: 1.9986424446105957
Validation loss: 1.8004131496593516

Epoch: 175| Step: 0
Training loss: 1.9024356603622437
Validation loss: 1.784246494693141

Epoch: 5| Step: 1
Training loss: 1.6291530132293701
Validation loss: 1.8367057128619122

Epoch: 5| Step: 2
Training loss: 1.824030876159668
Validation loss: 1.8020373134202854

Epoch: 5| Step: 3
Training loss: 1.9618511199951172
Validation loss: 1.839585365787629

Epoch: 5| Step: 4
Training loss: 1.7408390045166016
Validation loss: 1.8480872005544684

Epoch: 5| Step: 5
Training loss: 1.6799726486206055
Validation loss: 1.826361738225465

Epoch: 5| Step: 6
Training loss: 1.6702091693878174
Validation loss: 1.863191311077405

Epoch: 5| Step: 7
Training loss: 1.9422372579574585
Validation loss: 1.9000715055773336

Epoch: 5| Step: 8
Training loss: 2.2028937339782715
Validation loss: 1.8710769940448064

Epoch: 5| Step: 9
Training loss: 2.005251407623291
Validation loss: 1.8800797206099316

Epoch: 5| Step: 10
Training loss: 1.4148212671279907
Validation loss: 1.8456667584757651

Epoch: 176| Step: 0
Training loss: 1.7090774774551392
Validation loss: 1.8237891453568653

Epoch: 5| Step: 1
Training loss: 1.6578470468521118
Validation loss: 1.8252232754102318

Epoch: 5| Step: 2
Training loss: 1.9268255233764648
Validation loss: 1.8394814101598596

Epoch: 5| Step: 3
Training loss: 2.153852939605713
Validation loss: 1.844098937126898

Epoch: 5| Step: 4
Training loss: 1.921908974647522
Validation loss: 1.8170374798518356

Epoch: 5| Step: 5
Training loss: 2.1320340633392334
Validation loss: 1.827940680647409

Epoch: 5| Step: 6
Training loss: 1.5695512294769287
Validation loss: 1.8328829016736758

Epoch: 5| Step: 7
Training loss: 1.472332239151001
Validation loss: 1.8401654779270131

Epoch: 5| Step: 8
Training loss: 1.9145323038101196
Validation loss: 1.8141094535909674

Epoch: 5| Step: 9
Training loss: 1.3536456823349
Validation loss: 1.8381511024249497

Epoch: 5| Step: 10
Training loss: 1.9438130855560303
Validation loss: 1.8186273792738556

Epoch: 177| Step: 0
Training loss: 1.9894068241119385
Validation loss: 1.7736651756430184

Epoch: 5| Step: 1
Training loss: 2.384594678878784
Validation loss: 1.8118796630572247

Epoch: 5| Step: 2
Training loss: 1.3968768119812012
Validation loss: 1.8476215613785612

Epoch: 5| Step: 3
Training loss: 1.185823678970337
Validation loss: 1.8523073081047303

Epoch: 5| Step: 4
Training loss: 2.1042983531951904
Validation loss: 1.848600237600265

Epoch: 5| Step: 5
Training loss: 2.2183127403259277
Validation loss: 1.8064313127148537

Epoch: 5| Step: 6
Training loss: 1.7074966430664062
Validation loss: 1.8332558203768987

Epoch: 5| Step: 7
Training loss: 1.2887701988220215
Validation loss: 1.8155658219450264

Epoch: 5| Step: 8
Training loss: 1.815447211265564
Validation loss: 1.8067795794497254

Epoch: 5| Step: 9
Training loss: 1.4328306913375854
Validation loss: 1.8479668786448817

Epoch: 5| Step: 10
Training loss: 2.0808417797088623
Validation loss: 1.8351776997248332

Epoch: 178| Step: 0
Training loss: 1.455557107925415
Validation loss: 1.8126178864509828

Epoch: 5| Step: 1
Training loss: 2.853182077407837
Validation loss: 1.8216932230098273

Epoch: 5| Step: 2
Training loss: 1.2439864873886108
Validation loss: 1.8310111376547045

Epoch: 5| Step: 3
Training loss: 1.897315263748169
Validation loss: 1.8497757937318535

Epoch: 5| Step: 4
Training loss: 1.9912770986557007
Validation loss: 1.8006250922397902

Epoch: 5| Step: 5
Training loss: 1.424740195274353
Validation loss: 1.7970125662383212

Epoch: 5| Step: 6
Training loss: 1.3490521907806396
Validation loss: 1.8231607880643619

Epoch: 5| Step: 7
Training loss: 1.2259256839752197
Validation loss: 1.778570472553212

Epoch: 5| Step: 8
Training loss: 2.4778714179992676
Validation loss: 1.7905138948912263

Epoch: 5| Step: 9
Training loss: 1.5380680561065674
Validation loss: 1.8204165645824966

Epoch: 5| Step: 10
Training loss: 2.406135320663452
Validation loss: 1.758603565154537

Epoch: 179| Step: 0
Training loss: 2.377196788787842
Validation loss: 1.8083978840099868

Epoch: 5| Step: 1
Training loss: 1.9737554788589478
Validation loss: 1.8291926486517793

Epoch: 5| Step: 2
Training loss: 1.6861114501953125
Validation loss: 1.8458701102964339

Epoch: 5| Step: 3
Training loss: 1.648988962173462
Validation loss: 1.8206151044496925

Epoch: 5| Step: 4
Training loss: 1.3204314708709717
Validation loss: 1.8223260525734193

Epoch: 5| Step: 5
Training loss: 1.6326459646224976
Validation loss: 1.8597626596368768

Epoch: 5| Step: 6
Training loss: 1.5703966617584229
Validation loss: 1.8345210552215576

Epoch: 5| Step: 7
Training loss: 1.7902284860610962
Validation loss: 1.8781729436689807

Epoch: 5| Step: 8
Training loss: 1.8749206066131592
Validation loss: 1.8775740208164338

Epoch: 5| Step: 9
Training loss: 1.9253898859024048
Validation loss: 1.8483835740755963

Epoch: 5| Step: 10
Training loss: 1.9158828258514404
Validation loss: 1.870360828215076

Epoch: 180| Step: 0
Training loss: 1.319481372833252
Validation loss: 1.851905571517124

Epoch: 5| Step: 1
Training loss: 1.884969711303711
Validation loss: 1.8250224103209793

Epoch: 5| Step: 2
Training loss: 1.80282461643219
Validation loss: 1.8498115526732577

Epoch: 5| Step: 3
Training loss: 1.6168549060821533
Validation loss: 1.79199977203082

Epoch: 5| Step: 4
Training loss: 2.021359443664551
Validation loss: 1.8330835347534509

Epoch: 5| Step: 5
Training loss: 2.015148878097534
Validation loss: 1.793681433123927

Epoch: 5| Step: 6
Training loss: 1.6327327489852905
Validation loss: 1.7774485529109996

Epoch: 5| Step: 7
Training loss: 2.046844720840454
Validation loss: 1.7693214403685702

Epoch: 5| Step: 8
Training loss: 2.2200210094451904
Validation loss: 1.7946479807617843

Epoch: 5| Step: 9
Training loss: 1.4795855283737183
Validation loss: 1.8052000480313455

Epoch: 5| Step: 10
Training loss: 2.078305244445801
Validation loss: 1.7938702580749348

Epoch: 181| Step: 0
Training loss: 1.5000360012054443
Validation loss: 1.8175375153941493

Epoch: 5| Step: 1
Training loss: 1.3630329370498657
Validation loss: 1.7890291188352851

Epoch: 5| Step: 2
Training loss: 2.033191442489624
Validation loss: 1.8116504505116453

Epoch: 5| Step: 3
Training loss: 1.5775302648544312
Validation loss: 1.793602733201878

Epoch: 5| Step: 4
Training loss: 2.13586163520813
Validation loss: 1.8274514982777257

Epoch: 5| Step: 5
Training loss: 2.056981325149536
Validation loss: 1.8340853862864996

Epoch: 5| Step: 6
Training loss: 1.6290336847305298
Validation loss: 1.8202321388388192

Epoch: 5| Step: 7
Training loss: 1.9804408550262451
Validation loss: 1.803497399053266

Epoch: 5| Step: 8
Training loss: 1.9115968942642212
Validation loss: 1.8665205765795965

Epoch: 5| Step: 9
Training loss: 2.1022067070007324
Validation loss: 1.8302581258999404

Epoch: 5| Step: 10
Training loss: 1.2387876510620117
Validation loss: 1.854004894533465

Epoch: 182| Step: 0
Training loss: 1.6490463018417358
Validation loss: 1.8250413722889398

Epoch: 5| Step: 1
Training loss: 2.2087457180023193
Validation loss: 1.81437809236588

Epoch: 5| Step: 2
Training loss: 1.5897724628448486
Validation loss: 1.8727359925546954

Epoch: 5| Step: 3
Training loss: 1.8267635107040405
Validation loss: 1.8362001449831071

Epoch: 5| Step: 4
Training loss: 2.111625909805298
Validation loss: 1.815007955797257

Epoch: 5| Step: 5
Training loss: 1.551358938217163
Validation loss: 1.8415525395383117

Epoch: 5| Step: 6
Training loss: 1.4656612873077393
Validation loss: 1.8406709419783724

Epoch: 5| Step: 7
Training loss: 2.1922218799591064
Validation loss: 1.8360464431906258

Epoch: 5| Step: 8
Training loss: 1.4814170598983765
Validation loss: 1.8501158004165978

Epoch: 5| Step: 9
Training loss: 2.025667428970337
Validation loss: 1.8440804199505878

Epoch: 5| Step: 10
Training loss: 1.4437893629074097
Validation loss: 1.849125099438493

Epoch: 183| Step: 0
Training loss: 1.6305640935897827
Validation loss: 1.8568363804971018

Epoch: 5| Step: 1
Training loss: 1.989546775817871
Validation loss: 1.844042181968689

Epoch: 5| Step: 2
Training loss: 1.8372344970703125
Validation loss: 1.8562421798706055

Epoch: 5| Step: 3
Training loss: 1.666019082069397
Validation loss: 1.8356336893573884

Epoch: 5| Step: 4
Training loss: 2.6096160411834717
Validation loss: 1.799912170697284

Epoch: 5| Step: 5
Training loss: 1.9822940826416016
Validation loss: 1.8167548833354827

Epoch: 5| Step: 6
Training loss: 1.7137199640274048
Validation loss: 1.8193870000941779

Epoch: 5| Step: 7
Training loss: 0.9769562482833862
Validation loss: 1.8498609553101242

Epoch: 5| Step: 8
Training loss: 1.2496531009674072
Validation loss: 1.8389422303886824

Epoch: 5| Step: 9
Training loss: 1.8636207580566406
Validation loss: 1.8447633122885099

Epoch: 5| Step: 10
Training loss: 2.0042672157287598
Validation loss: 1.8190665565511233

Epoch: 184| Step: 0
Training loss: 1.79122793674469
Validation loss: 1.8146917884067824

Epoch: 5| Step: 1
Training loss: 1.83119797706604
Validation loss: 1.8198577357876686

Epoch: 5| Step: 2
Training loss: 1.990468978881836
Validation loss: 1.8409340561077159

Epoch: 5| Step: 3
Training loss: 1.7027299404144287
Validation loss: 1.812129045045504

Epoch: 5| Step: 4
Training loss: 1.4397163391113281
Validation loss: 1.8096457360893168

Epoch: 5| Step: 5
Training loss: 1.9132074117660522
Validation loss: 1.7913661900387015

Epoch: 5| Step: 6
Training loss: 1.990683913230896
Validation loss: 1.8456847885603547

Epoch: 5| Step: 7
Training loss: 1.9066680669784546
Validation loss: 1.8327618997584108

Epoch: 5| Step: 8
Training loss: 1.9022334814071655
Validation loss: 1.8165619616867394

Epoch: 5| Step: 9
Training loss: 1.3497803211212158
Validation loss: 1.82836837409645

Epoch: 5| Step: 10
Training loss: 1.9138178825378418
Validation loss: 1.7942549772160028

Epoch: 185| Step: 0
Training loss: 1.5598251819610596
Validation loss: 1.828106176468634

Epoch: 5| Step: 1
Training loss: 1.8962329626083374
Validation loss: 1.8355817846072617

Epoch: 5| Step: 2
Training loss: 1.4918935298919678
Validation loss: 1.8024308630215224

Epoch: 5| Step: 3
Training loss: 1.685062050819397
Validation loss: 1.8316501622558923

Epoch: 5| Step: 4
Training loss: 1.7984373569488525
Validation loss: 1.8114376632116174

Epoch: 5| Step: 5
Training loss: 1.7493107318878174
Validation loss: 1.8069749621934788

Epoch: 5| Step: 6
Training loss: 1.4640852212905884
Validation loss: 1.8070431857980707

Epoch: 5| Step: 7
Training loss: 1.5941029787063599
Validation loss: 1.786292201729231

Epoch: 5| Step: 8
Training loss: 1.0526690483093262
Validation loss: 1.792009692038259

Epoch: 5| Step: 9
Training loss: 3.102874517440796
Validation loss: 1.8132882836044475

Epoch: 5| Step: 10
Training loss: 2.0246241092681885
Validation loss: 1.7793597354683826

Epoch: 186| Step: 0
Training loss: 1.8813893795013428
Validation loss: 1.7932095463557909

Epoch: 5| Step: 1
Training loss: 1.9908186197280884
Validation loss: 1.8446316103781424

Epoch: 5| Step: 2
Training loss: 1.6275949478149414
Validation loss: 1.8240376236618205

Epoch: 5| Step: 3
Training loss: 1.7352399826049805
Validation loss: 1.8017426383110784

Epoch: 5| Step: 4
Training loss: 1.6595712900161743
Validation loss: 1.862766537615048

Epoch: 5| Step: 5
Training loss: 1.7629926204681396
Validation loss: 1.8536847817000521

Epoch: 5| Step: 6
Training loss: 1.8941631317138672
Validation loss: 1.8601906748228176

Epoch: 5| Step: 7
Training loss: 1.612749457359314
Validation loss: 1.8197224781077395

Epoch: 5| Step: 8
Training loss: 2.1489856243133545
Validation loss: 1.8545069540700605

Epoch: 5| Step: 9
Training loss: 1.543318510055542
Validation loss: 1.8223015698053504

Epoch: 5| Step: 10
Training loss: 1.5089194774627686
Validation loss: 1.8281268855576873

Epoch: 187| Step: 0
Training loss: 1.8359355926513672
Validation loss: 1.8420564564325477

Epoch: 5| Step: 1
Training loss: 1.6566686630249023
Validation loss: 1.8263566096623738

Epoch: 5| Step: 2
Training loss: 1.5198489427566528
Validation loss: 1.828228481354252

Epoch: 5| Step: 3
Training loss: 2.109137535095215
Validation loss: 1.8131183847304313

Epoch: 5| Step: 4
Training loss: 1.2629114389419556
Validation loss: 1.8255655150259695

Epoch: 5| Step: 5
Training loss: 2.0175445079803467
Validation loss: 1.8292632077329902

Epoch: 5| Step: 6
Training loss: 2.1719324588775635
Validation loss: 1.7717407006089405

Epoch: 5| Step: 7
Training loss: 2.1397018432617188
Validation loss: 1.8221199358663251

Epoch: 5| Step: 8
Training loss: 1.7285935878753662
Validation loss: 1.8091627417072174

Epoch: 5| Step: 9
Training loss: 1.2835969924926758
Validation loss: 1.8196023792348883

Epoch: 5| Step: 10
Training loss: 1.723534345626831
Validation loss: 1.7853656891853578

Epoch: 188| Step: 0
Training loss: 1.346225380897522
Validation loss: 1.7975120723888438

Epoch: 5| Step: 1
Training loss: 1.560066819190979
Validation loss: 1.816758974905937

Epoch: 5| Step: 2
Training loss: 1.7102159261703491
Validation loss: 1.8322343775021133

Epoch: 5| Step: 3
Training loss: 1.8662269115447998
Validation loss: 1.8492354013586556

Epoch: 5| Step: 4
Training loss: 1.9472229480743408
Validation loss: 1.8710492246894426

Epoch: 5| Step: 5
Training loss: 1.9006820917129517
Validation loss: 1.8369456875708796

Epoch: 5| Step: 6
Training loss: 1.8389577865600586
Validation loss: 1.8353855763712237

Epoch: 5| Step: 7
Training loss: 2.085665464401245
Validation loss: 1.824728911922824

Epoch: 5| Step: 8
Training loss: 1.6842845678329468
Validation loss: 1.82771445474317

Epoch: 5| Step: 9
Training loss: 2.0960533618927
Validation loss: 1.8613462114846835

Epoch: 5| Step: 10
Training loss: 1.392505168914795
Validation loss: 1.8371249975696686

Epoch: 189| Step: 0
Training loss: 1.2468714714050293
Validation loss: 1.8596886486135504

Epoch: 5| Step: 1
Training loss: 1.384459376335144
Validation loss: 1.842020450099822

Epoch: 5| Step: 2
Training loss: 1.8960955142974854
Validation loss: 1.8605681068153792

Epoch: 5| Step: 3
Training loss: 1.8350073099136353
Validation loss: 1.8368312376801685

Epoch: 5| Step: 4
Training loss: 1.8454539775848389
Validation loss: 1.843090643164932

Epoch: 5| Step: 5
Training loss: 2.3587348461151123
Validation loss: 1.8524570900906798

Epoch: 5| Step: 6
Training loss: 1.2147276401519775
Validation loss: 1.8608089454712406

Epoch: 5| Step: 7
Training loss: 2.166097640991211
Validation loss: 1.8139735101371683

Epoch: 5| Step: 8
Training loss: 1.8580080270767212
Validation loss: 1.8540868810428086

Epoch: 5| Step: 9
Training loss: 1.4377703666687012
Validation loss: 1.859640388078587

Epoch: 5| Step: 10
Training loss: 2.291419267654419
Validation loss: 1.8144524135897238

Epoch: 190| Step: 0
Training loss: 2.368928909301758
Validation loss: 1.8443635317587084

Epoch: 5| Step: 1
Training loss: 1.3564281463623047
Validation loss: 1.8666904600717689

Epoch: 5| Step: 2
Training loss: 1.3070722818374634
Validation loss: 1.792936143054757

Epoch: 5| Step: 3
Training loss: 1.5840837955474854
Validation loss: 1.8270255506679576

Epoch: 5| Step: 4
Training loss: 1.5644919872283936
Validation loss: 1.81283986824815

Epoch: 5| Step: 5
Training loss: 1.8999049663543701
Validation loss: 1.786713561704082

Epoch: 5| Step: 6
Training loss: 1.886914849281311
Validation loss: 1.7775386456520326

Epoch: 5| Step: 7
Training loss: 1.7383966445922852
Validation loss: 1.7964355407222625

Epoch: 5| Step: 8
Training loss: 1.1897649765014648
Validation loss: 1.8130262154404835

Epoch: 5| Step: 9
Training loss: 1.7697054147720337
Validation loss: 1.7979778384649625

Epoch: 5| Step: 10
Training loss: 2.8338940143585205
Validation loss: 1.7894594323250554

Epoch: 191| Step: 0
Training loss: 1.6406701803207397
Validation loss: 1.8148000663326633

Epoch: 5| Step: 1
Training loss: 1.6629756689071655
Validation loss: 1.7933628430930517

Epoch: 5| Step: 2
Training loss: 2.0499672889709473
Validation loss: 1.7780850856534895

Epoch: 5| Step: 3
Training loss: 1.1980476379394531
Validation loss: 1.796889558915169

Epoch: 5| Step: 4
Training loss: 2.156771183013916
Validation loss: 1.8661573676652805

Epoch: 5| Step: 5
Training loss: 1.5497616529464722
Validation loss: 1.851873064553866

Epoch: 5| Step: 6
Training loss: 1.2645442485809326
Validation loss: 1.8455332145896008

Epoch: 5| Step: 7
Training loss: 1.9766695499420166
Validation loss: 1.8422824439182077

Epoch: 5| Step: 8
Training loss: 2.0780510902404785
Validation loss: 1.8452833903733121

Epoch: 5| Step: 9
Training loss: 2.271374225616455
Validation loss: 1.8396260905009445

Epoch: 5| Step: 10
Training loss: 1.5811796188354492
Validation loss: 1.8472478364103584

Epoch: 192| Step: 0
Training loss: 1.4151824712753296
Validation loss: 1.8510357808041316

Epoch: 5| Step: 1
Training loss: 2.3825490474700928
Validation loss: 1.8261700625060706

Epoch: 5| Step: 2
Training loss: 1.665924072265625
Validation loss: 1.821478110487743

Epoch: 5| Step: 3
Training loss: 1.4006876945495605
Validation loss: 1.7862893996700164

Epoch: 5| Step: 4
Training loss: 1.626409888267517
Validation loss: 1.8024263048684726

Epoch: 5| Step: 5
Training loss: 1.6588878631591797
Validation loss: 1.8638812406088716

Epoch: 5| Step: 6
Training loss: 1.6417795419692993
Validation loss: 1.7951577286566458

Epoch: 5| Step: 7
Training loss: 1.9801393747329712
Validation loss: 1.8173662142087055

Epoch: 5| Step: 8
Training loss: 1.7132104635238647
Validation loss: 1.80030950807756

Epoch: 5| Step: 9
Training loss: 1.8518203496932983
Validation loss: 1.7964143612051522

Epoch: 5| Step: 10
Training loss: 2.3392531871795654
Validation loss: 1.7972205479939778

Epoch: 193| Step: 0
Training loss: 2.1296424865722656
Validation loss: 1.8291094431313135

Epoch: 5| Step: 1
Training loss: 1.3124375343322754
Validation loss: 1.837386353041536

Epoch: 5| Step: 2
Training loss: 1.4319355487823486
Validation loss: 1.8388658774796354

Epoch: 5| Step: 3
Training loss: 1.7999194860458374
Validation loss: 1.875213139800615

Epoch: 5| Step: 4
Training loss: 2.0924313068389893
Validation loss: 1.8399818148664249

Epoch: 5| Step: 5
Training loss: 1.484229326248169
Validation loss: 1.9096115827560425

Epoch: 5| Step: 6
Training loss: 1.2481313943862915
Validation loss: 1.859518063965664

Epoch: 5| Step: 7
Training loss: 2.787412166595459
Validation loss: 1.8926370297708819

Epoch: 5| Step: 8
Training loss: 1.7954124212265015
Validation loss: 1.8320233360413583

Epoch: 5| Step: 9
Training loss: 1.5704209804534912
Validation loss: 1.8411590988918016

Epoch: 5| Step: 10
Training loss: 1.8254494667053223
Validation loss: 1.814074008695541

Epoch: 194| Step: 0
Training loss: 1.9535239934921265
Validation loss: 1.861033562690981

Epoch: 5| Step: 1
Training loss: 1.9264189004898071
Validation loss: 1.805578709930502

Epoch: 5| Step: 2
Training loss: 2.3119871616363525
Validation loss: 1.8278396385972218

Epoch: 5| Step: 3
Training loss: 1.640703558921814
Validation loss: 1.786539064940586

Epoch: 5| Step: 4
Training loss: 1.1001641750335693
Validation loss: 1.787919609777389

Epoch: 5| Step: 5
Training loss: 2.333374500274658
Validation loss: 1.808152715365092

Epoch: 5| Step: 6
Training loss: 1.2506372928619385
Validation loss: 1.822571639091738

Epoch: 5| Step: 7
Training loss: 1.3716440200805664
Validation loss: 1.8187794787909395

Epoch: 5| Step: 8
Training loss: 1.9662845134735107
Validation loss: 1.8071609133033342

Epoch: 5| Step: 9
Training loss: 1.593036413192749
Validation loss: 1.798351751860752

Epoch: 5| Step: 10
Training loss: 1.7132339477539062
Validation loss: 1.7986536910456996

Epoch: 195| Step: 0
Training loss: 1.8205264806747437
Validation loss: 1.8504800206871443

Epoch: 5| Step: 1
Training loss: 2.157937526702881
Validation loss: 1.8170484842792634

Epoch: 5| Step: 2
Training loss: 1.822946310043335
Validation loss: 1.8194916222685127

Epoch: 5| Step: 3
Training loss: 1.7477028369903564
Validation loss: 1.7885581011413245

Epoch: 5| Step: 4
Training loss: 2.641321897506714
Validation loss: 1.8077833434586883

Epoch: 5| Step: 5
Training loss: 1.4801957607269287
Validation loss: 1.7978091060474355

Epoch: 5| Step: 6
Training loss: 1.3265246152877808
Validation loss: 1.8295927381002774

Epoch: 5| Step: 7
Training loss: 1.7264277935028076
Validation loss: 1.8050236689147128

Epoch: 5| Step: 8
Training loss: 1.3647258281707764
Validation loss: 1.8110486435633835

Epoch: 5| Step: 9
Training loss: 1.6303523778915405
Validation loss: 1.8224403794093798

Epoch: 5| Step: 10
Training loss: 1.5775129795074463
Validation loss: 1.8535527862528318

Epoch: 196| Step: 0
Training loss: 1.7133592367172241
Validation loss: 1.8578918198103547

Epoch: 5| Step: 1
Training loss: 2.316809892654419
Validation loss: 1.8085186135384343

Epoch: 5| Step: 2
Training loss: 1.9165375232696533
Validation loss: 1.8582018472815072

Epoch: 5| Step: 3
Training loss: 1.352160930633545
Validation loss: 1.822688953850859

Epoch: 5| Step: 4
Training loss: 1.993096113204956
Validation loss: 1.8192736051415885

Epoch: 5| Step: 5
Training loss: 1.7508232593536377
Validation loss: 1.825119254409626

Epoch: 5| Step: 6
Training loss: 1.239445686340332
Validation loss: 1.85030827342823

Epoch: 5| Step: 7
Training loss: 1.283630132675171
Validation loss: 1.8522983417716077

Epoch: 5| Step: 8
Training loss: 1.6329097747802734
Validation loss: 1.8726342608851771

Epoch: 5| Step: 9
Training loss: 2.564639091491699
Validation loss: 1.8128420614427136

Epoch: 5| Step: 10
Training loss: 1.2433689832687378
Validation loss: 1.8559362811426963

Epoch: 197| Step: 0
Training loss: 1.7995119094848633
Validation loss: 1.8256977732463548

Epoch: 5| Step: 1
Training loss: 2.1890196800231934
Validation loss: 1.8306558824354602

Epoch: 5| Step: 2
Training loss: 2.3543715476989746
Validation loss: 1.838915414707635

Epoch: 5| Step: 3
Training loss: 1.7679351568222046
Validation loss: 1.8165224700845697

Epoch: 5| Step: 4
Training loss: 1.8871437311172485
Validation loss: 1.8597119110886768

Epoch: 5| Step: 5
Training loss: 1.9492599964141846
Validation loss: 1.8239885504527757

Epoch: 5| Step: 6
Training loss: 1.239200234413147
Validation loss: 1.824320888006559

Epoch: 5| Step: 7
Training loss: 1.990953803062439
Validation loss: 1.794385116587403

Epoch: 5| Step: 8
Training loss: 1.1365790367126465
Validation loss: 1.7843858324071413

Epoch: 5| Step: 9
Training loss: 1.4030683040618896
Validation loss: 1.7726055229863813

Epoch: 5| Step: 10
Training loss: 1.504108190536499
Validation loss: 1.8008069735701366

Epoch: 198| Step: 0
Training loss: 1.053850769996643
Validation loss: 1.8315209932224725

Epoch: 5| Step: 1
Training loss: 1.6427276134490967
Validation loss: 1.8352270280161211

Epoch: 5| Step: 2
Training loss: 2.379425525665283
Validation loss: 1.844095771030713

Epoch: 5| Step: 3
Training loss: 2.1500494480133057
Validation loss: 1.8131464424953665

Epoch: 5| Step: 4
Training loss: 1.6644035577774048
Validation loss: 1.8615688598284157

Epoch: 5| Step: 5
Training loss: 1.7916380167007446
Validation loss: 1.859808119394446

Epoch: 5| Step: 6
Training loss: 1.1851022243499756
Validation loss: 1.8977965847138436

Epoch: 5| Step: 7
Training loss: 1.9067405462265015
Validation loss: 1.8668606640190206

Epoch: 5| Step: 8
Training loss: 1.568848967552185
Validation loss: 1.8536527131193428

Epoch: 5| Step: 9
Training loss: 2.0667595863342285
Validation loss: 1.8763792835256106

Epoch: 5| Step: 10
Training loss: 1.6122831106185913
Validation loss: 1.8642129795525664

Epoch: 199| Step: 0
Training loss: 1.6208057403564453
Validation loss: 1.8620866267911849

Epoch: 5| Step: 1
Training loss: 1.394714593887329
Validation loss: 1.828728223359713

Epoch: 5| Step: 2
Training loss: 1.7724031209945679
Validation loss: 1.8323490837568879

Epoch: 5| Step: 3
Training loss: 1.6758403778076172
Validation loss: 1.8465628034325057

Epoch: 5| Step: 4
Training loss: 1.6162935495376587
Validation loss: 1.7960088842658586

Epoch: 5| Step: 5
Training loss: 1.2925958633422852
Validation loss: 1.8117147773824713

Epoch: 5| Step: 6
Training loss: 2.1909117698669434
Validation loss: 1.7869050682231944

Epoch: 5| Step: 7
Training loss: 1.9245096445083618
Validation loss: 1.81850133275473

Epoch: 5| Step: 8
Training loss: 1.8495489358901978
Validation loss: 1.7715282965731878

Epoch: 5| Step: 9
Training loss: 1.6361238956451416
Validation loss: 1.7763073149547781

Epoch: 5| Step: 10
Training loss: 2.286130905151367
Validation loss: 1.8138752932189612

Epoch: 200| Step: 0
Training loss: 1.4079333543777466
Validation loss: 1.8196789013442172

Epoch: 5| Step: 1
Training loss: 1.334173560142517
Validation loss: 1.7706646893614082

Epoch: 5| Step: 2
Training loss: 1.8964065313339233
Validation loss: 1.8833314372647194

Epoch: 5| Step: 3
Training loss: 1.2749817371368408
Validation loss: 1.8849828371437647

Epoch: 5| Step: 4
Training loss: 1.9383186101913452
Validation loss: 1.9032463963313768

Epoch: 5| Step: 5
Training loss: 2.503903865814209
Validation loss: 1.9197106515207598

Epoch: 5| Step: 6
Training loss: 2.276428699493408
Validation loss: 1.9373124299510833

Epoch: 5| Step: 7
Training loss: 1.6074726581573486
Validation loss: 1.922144095102946

Epoch: 5| Step: 8
Training loss: 1.533502221107483
Validation loss: 1.9459379155148742

Epoch: 5| Step: 9
Training loss: 1.904986023902893
Validation loss: 1.9259773338994672

Epoch: 5| Step: 10
Training loss: 1.6951972246170044
Validation loss: 1.9133817303565241

Epoch: 201| Step: 0
Training loss: 1.480865240097046
Validation loss: 1.8719860763959988

Epoch: 5| Step: 1
Training loss: 2.0305256843566895
Validation loss: 1.8643900655931043

Epoch: 5| Step: 2
Training loss: 1.9985215663909912
Validation loss: 1.8442014032794583

Epoch: 5| Step: 3
Training loss: 2.106206178665161
Validation loss: 1.865315483462426

Epoch: 5| Step: 4
Training loss: 1.224029541015625
Validation loss: 1.808947023525033

Epoch: 5| Step: 5
Training loss: 1.9765729904174805
Validation loss: 1.8205914881921583

Epoch: 5| Step: 6
Training loss: 1.9426904916763306
Validation loss: 1.8301924428632181

Epoch: 5| Step: 7
Training loss: 1.4658634662628174
Validation loss: 1.8131070739479476

Epoch: 5| Step: 8
Training loss: 1.5556421279907227
Validation loss: 1.7902235805347402

Epoch: 5| Step: 9
Training loss: 1.608985185623169
Validation loss: 1.7814594404671782

Epoch: 5| Step: 10
Training loss: 1.6487772464752197
Validation loss: 1.7867011177924372

Epoch: 202| Step: 0
Training loss: 1.6099761724472046
Validation loss: 1.7835617834521877

Epoch: 5| Step: 1
Training loss: 1.4283006191253662
Validation loss: 1.8277071381127963

Epoch: 5| Step: 2
Training loss: 1.487274408340454
Validation loss: 1.769866321676521

Epoch: 5| Step: 3
Training loss: 1.360243320465088
Validation loss: 1.8076375825430757

Epoch: 5| Step: 4
Training loss: 2.3929686546325684
Validation loss: 1.8109312775314494

Epoch: 5| Step: 5
Training loss: 2.34930682182312
Validation loss: 1.8116934094377743

Epoch: 5| Step: 6
Training loss: 1.3360588550567627
Validation loss: 1.8185998214188444

Epoch: 5| Step: 7
Training loss: 1.8742233514785767
Validation loss: 1.8423437944022558

Epoch: 5| Step: 8
Training loss: 1.5100796222686768
Validation loss: 1.8457180018066077

Epoch: 5| Step: 9
Training loss: 2.211094856262207
Validation loss: 1.868291688221757

Epoch: 5| Step: 10
Training loss: 1.1904208660125732
Validation loss: 1.825317452030797

Epoch: 203| Step: 0
Training loss: 1.9052127599716187
Validation loss: 1.8435036828441005

Epoch: 5| Step: 1
Training loss: 1.371435523033142
Validation loss: 1.8981857940714846

Epoch: 5| Step: 2
Training loss: 1.8889869451522827
Validation loss: 1.8754864892651957

Epoch: 5| Step: 3
Training loss: 1.6089872121810913
Validation loss: 1.9142237478686916

Epoch: 5| Step: 4
Training loss: 2.0497374534606934
Validation loss: 1.8843671634633055

Epoch: 5| Step: 5
Training loss: 1.3681707382202148
Validation loss: 1.9174509907281527

Epoch: 5| Step: 6
Training loss: 1.36863112449646
Validation loss: 1.8869355135066535

Epoch: 5| Step: 7
Training loss: 2.5153918266296387
Validation loss: 1.8945390844857821

Epoch: 5| Step: 8
Training loss: 1.2012031078338623
Validation loss: 1.8880408681848997

Epoch: 5| Step: 9
Training loss: 1.8809597492218018
Validation loss: 1.843761928619877

Epoch: 5| Step: 10
Training loss: 1.955986499786377
Validation loss: 1.852537937061761

Epoch: 204| Step: 0
Training loss: 2.3073737621307373
Validation loss: 1.8393400330697336

Epoch: 5| Step: 1
Training loss: 1.3032684326171875
Validation loss: 1.846563901952518

Epoch: 5| Step: 2
Training loss: 1.627873182296753
Validation loss: 1.8066870884228778

Epoch: 5| Step: 3
Training loss: 1.9860271215438843
Validation loss: 1.7894170630362727

Epoch: 5| Step: 4
Training loss: 2.064690113067627
Validation loss: 1.800344209517202

Epoch: 5| Step: 5
Training loss: 1.2054558992385864
Validation loss: 1.807910285970216

Epoch: 5| Step: 6
Training loss: 1.9238166809082031
Validation loss: 1.7616356316433157

Epoch: 5| Step: 7
Training loss: 1.5146446228027344
Validation loss: 1.789748639188787

Epoch: 5| Step: 8
Training loss: 1.7879377603530884
Validation loss: 1.7799049872224049

Epoch: 5| Step: 9
Training loss: 2.0578815937042236
Validation loss: 1.7704417577353857

Epoch: 5| Step: 10
Training loss: 1.2552461624145508
Validation loss: 1.7902547826049149

Epoch: 205| Step: 0
Training loss: 1.7253437042236328
Validation loss: 1.8231639733878515

Epoch: 5| Step: 1
Training loss: 1.4956670999526978
Validation loss: 1.8213352695588143

Epoch: 5| Step: 2
Training loss: 1.7995210886001587
Validation loss: 1.8388816823241532

Epoch: 5| Step: 3
Training loss: 1.4436546564102173
Validation loss: 1.8339789272636495

Epoch: 5| Step: 4
Training loss: 1.8943828344345093
Validation loss: 1.8699963349168018

Epoch: 5| Step: 5
Training loss: 1.9306437969207764
Validation loss: 1.904468346667546

Epoch: 5| Step: 6
Training loss: 1.620550513267517
Validation loss: 1.876975005672824

Epoch: 5| Step: 7
Training loss: 2.1934008598327637
Validation loss: 1.8685384565784084

Epoch: 5| Step: 8
Training loss: 1.5213305950164795
Validation loss: 1.8686937785917712

Epoch: 5| Step: 9
Training loss: 2.193570137023926
Validation loss: 1.8555966205494379

Epoch: 5| Step: 10
Training loss: 1.1562153100967407
Validation loss: 1.823737346997825

Epoch: 206| Step: 0
Training loss: 2.083958864212036
Validation loss: 1.8706823318235335

Epoch: 5| Step: 1
Training loss: 2.011030673980713
Validation loss: 1.7886752890002342

Epoch: 5| Step: 2
Training loss: 1.7649205923080444
Validation loss: 1.7794198887322539

Epoch: 5| Step: 3
Training loss: 2.0981698036193848
Validation loss: 1.7919978082820933

Epoch: 5| Step: 4
Training loss: 1.7371699810028076
Validation loss: 1.7960645485949773

Epoch: 5| Step: 5
Training loss: 1.0125747919082642
Validation loss: 1.7834824298017768

Epoch: 5| Step: 6
Training loss: 2.0821030139923096
Validation loss: 1.7879349518847722

Epoch: 5| Step: 7
Training loss: 1.1250717639923096
Validation loss: 1.7381099706055017

Epoch: 5| Step: 8
Training loss: 2.221989393234253
Validation loss: 1.7870757182439168

Epoch: 5| Step: 9
Training loss: 1.416973352432251
Validation loss: 1.7730470088220411

Epoch: 5| Step: 10
Training loss: 1.583968997001648
Validation loss: 1.8125934549557265

Epoch: 207| Step: 0
Training loss: 1.6385082006454468
Validation loss: 1.8177260865447342

Epoch: 5| Step: 1
Training loss: 1.574512004852295
Validation loss: 1.8405046668103946

Epoch: 5| Step: 2
Training loss: 1.4676010608673096
Validation loss: 1.8321555775980796

Epoch: 5| Step: 3
Training loss: 1.5463230609893799
Validation loss: 1.8381217141305246

Epoch: 5| Step: 4
Training loss: 2.1227591037750244
Validation loss: 1.8365660803292387

Epoch: 5| Step: 5
Training loss: 2.2106118202209473
Validation loss: 1.8122795935600036

Epoch: 5| Step: 6
Training loss: 1.6584049463272095
Validation loss: 1.8599613994680426

Epoch: 5| Step: 7
Training loss: 2.190464496612549
Validation loss: 1.876756364299405

Epoch: 5| Step: 8
Training loss: 1.4060958623886108
Validation loss: 1.848779373271491

Epoch: 5| Step: 9
Training loss: 1.5769809484481812
Validation loss: 1.837654786725198

Epoch: 5| Step: 10
Training loss: 1.7061376571655273
Validation loss: 1.849528315246746

Epoch: 208| Step: 0
Training loss: 2.4577677249908447
Validation loss: 1.8236005818972023

Epoch: 5| Step: 1
Training loss: 1.8992722034454346
Validation loss: 1.8186141419154342

Epoch: 5| Step: 2
Training loss: 1.238964557647705
Validation loss: 1.8725358311847975

Epoch: 5| Step: 3
Training loss: 1.2843093872070312
Validation loss: 1.83822097316865

Epoch: 5| Step: 4
Training loss: 1.6633708477020264
Validation loss: 1.79870044800543

Epoch: 5| Step: 5
Training loss: 1.7024122476577759
Validation loss: 1.814274964794036

Epoch: 5| Step: 6
Training loss: 2.663604736328125
Validation loss: 1.7885578293954172

Epoch: 5| Step: 7
Training loss: 1.617997407913208
Validation loss: 1.7945441174250778

Epoch: 5| Step: 8
Training loss: 1.0708376169204712
Validation loss: 1.8125343758572814

Epoch: 5| Step: 9
Training loss: 1.4210883378982544
Validation loss: 1.8378291040338495

Epoch: 5| Step: 10
Training loss: 1.7377506494522095
Validation loss: 1.8152928095991894

Epoch: 209| Step: 0
Training loss: 1.870197057723999
Validation loss: 1.787752083552781

Epoch: 5| Step: 1
Training loss: 1.22256600856781
Validation loss: 1.825700681696656

Epoch: 5| Step: 2
Training loss: 1.8040850162506104
Validation loss: 1.826992114384969

Epoch: 5| Step: 3
Training loss: 1.4792253971099854
Validation loss: 1.8018673722461989

Epoch: 5| Step: 4
Training loss: 1.396445631980896
Validation loss: 1.790492162909559

Epoch: 5| Step: 5
Training loss: 1.2246488332748413
Validation loss: 1.8178879189234909

Epoch: 5| Step: 6
Training loss: 2.1596431732177734
Validation loss: 1.8392315859435706

Epoch: 5| Step: 7
Training loss: 2.128649950027466
Validation loss: 1.8090782806437502

Epoch: 5| Step: 8
Training loss: 1.5554276704788208
Validation loss: 1.8285257354859383

Epoch: 5| Step: 9
Training loss: 2.064863681793213
Validation loss: 1.8007585310166883

Epoch: 5| Step: 10
Training loss: 1.8336632251739502
Validation loss: 1.791012494794784

Epoch: 210| Step: 0
Training loss: 1.5252127647399902
Validation loss: 1.8678180427961453

Epoch: 5| Step: 1
Training loss: 1.3838213682174683
Validation loss: 1.846684987827014

Epoch: 5| Step: 2
Training loss: 1.725797414779663
Validation loss: 1.8243973460248721

Epoch: 5| Step: 3
Training loss: 1.8871173858642578
Validation loss: 1.8177714014566073

Epoch: 5| Step: 4
Training loss: 1.5359227657318115
Validation loss: 1.8167023056296892

Epoch: 5| Step: 5
Training loss: 1.5865144729614258
Validation loss: 1.7963979603141866

Epoch: 5| Step: 6
Training loss: 1.6118535995483398
Validation loss: 1.8229618021236953

Epoch: 5| Step: 7
Training loss: 1.88266122341156
Validation loss: 1.7922311495709162

Epoch: 5| Step: 8
Training loss: 2.4569592475891113
Validation loss: 1.8189701316177205

Epoch: 5| Step: 9
Training loss: 1.5091333389282227
Validation loss: 1.8251974736490557

Epoch: 5| Step: 10
Training loss: 1.6371490955352783
Validation loss: 1.8230746343571653

Epoch: 211| Step: 0
Training loss: 1.3972814083099365
Validation loss: 1.8387550628313454

Epoch: 5| Step: 1
Training loss: 1.7681859731674194
Validation loss: 1.836060990569412

Epoch: 5| Step: 2
Training loss: 1.391704797744751
Validation loss: 1.8456217024915962

Epoch: 5| Step: 3
Training loss: 1.9533851146697998
Validation loss: 1.8209701084321546

Epoch: 5| Step: 4
Training loss: 2.3988194465637207
Validation loss: 1.8509397109349568

Epoch: 5| Step: 5
Training loss: 1.8176838159561157
Validation loss: 1.8778116331305554

Epoch: 5| Step: 6
Training loss: 1.5582332611083984
Validation loss: 1.8688059955514886

Epoch: 5| Step: 7
Training loss: 1.9090713262557983
Validation loss: 1.8304477686523108

Epoch: 5| Step: 8
Training loss: 1.8232433795928955
Validation loss: 1.8812698292475876

Epoch: 5| Step: 9
Training loss: 1.2825230360031128
Validation loss: 1.8430297349088935

Epoch: 5| Step: 10
Training loss: 1.418831467628479
Validation loss: 1.85167113683557

Epoch: 212| Step: 0
Training loss: 1.583792805671692
Validation loss: 1.7907029556971725

Epoch: 5| Step: 1
Training loss: 1.8889309167861938
Validation loss: 1.8334488176530408

Epoch: 5| Step: 2
Training loss: 1.9103469848632812
Validation loss: 1.796730383749931

Epoch: 5| Step: 3
Training loss: 1.1843769550323486
Validation loss: 1.8355077376929663

Epoch: 5| Step: 4
Training loss: 1.067348599433899
Validation loss: 1.825626156663382

Epoch: 5| Step: 5
Training loss: 1.7984683513641357
Validation loss: 1.7600433288082

Epoch: 5| Step: 6
Training loss: 1.8536529541015625
Validation loss: 1.7847954355260378

Epoch: 5| Step: 7
Training loss: 1.490680456161499
Validation loss: 1.8082261213692286

Epoch: 5| Step: 8
Training loss: 1.8654377460479736
Validation loss: 1.7905452071979482

Epoch: 5| Step: 9
Training loss: 2.2148008346557617
Validation loss: 1.8220110016484414

Epoch: 5| Step: 10
Training loss: 1.8875958919525146
Validation loss: 1.789572374795073

Epoch: 213| Step: 0
Training loss: 1.3588359355926514
Validation loss: 1.8435267863735076

Epoch: 5| Step: 1
Training loss: 1.706563949584961
Validation loss: 1.8253083408519786

Epoch: 5| Step: 2
Training loss: 1.619401216506958
Validation loss: 1.8123366204641198

Epoch: 5| Step: 3
Training loss: 1.9179637432098389
Validation loss: 1.7927081738748858

Epoch: 5| Step: 4
Training loss: 1.5315440893173218
Validation loss: 1.827411481129226

Epoch: 5| Step: 5
Training loss: 1.8990119695663452
Validation loss: 1.8483368530068347

Epoch: 5| Step: 6
Training loss: 2.1520161628723145
Validation loss: 1.8232219257662374

Epoch: 5| Step: 7
Training loss: 1.5398744344711304
Validation loss: 1.824339940983762

Epoch: 5| Step: 8
Training loss: 1.8904953002929688
Validation loss: 1.8679258900303994

Epoch: 5| Step: 9
Training loss: 1.6160094738006592
Validation loss: 1.849658731491335

Epoch: 5| Step: 10
Training loss: 1.5521166324615479
Validation loss: 1.86389172205361

Epoch: 214| Step: 0
Training loss: 1.587720513343811
Validation loss: 1.8751678056614374

Epoch: 5| Step: 1
Training loss: 1.4471218585968018
Validation loss: 1.8740663630988008

Epoch: 5| Step: 2
Training loss: 1.497387170791626
Validation loss: 1.7994192390031711

Epoch: 5| Step: 3
Training loss: 2.498647451400757
Validation loss: 1.8174416480525848

Epoch: 5| Step: 4
Training loss: 2.1580238342285156
Validation loss: 1.8154486892043904

Epoch: 5| Step: 5
Training loss: 1.369157314300537
Validation loss: 1.8007302220149706

Epoch: 5| Step: 6
Training loss: 2.074545383453369
Validation loss: 1.8029642117920743

Epoch: 5| Step: 7
Training loss: 1.596750259399414
Validation loss: 1.8064133723576863

Epoch: 5| Step: 8
Training loss: 1.9540996551513672
Validation loss: 1.8284541150575042

Epoch: 5| Step: 9
Training loss: 1.5529916286468506
Validation loss: 1.8141170829854987

Epoch: 5| Step: 10
Training loss: 1.2759426832199097
Validation loss: 1.8543302051482662

Epoch: 215| Step: 0
Training loss: 2.0116419792175293
Validation loss: 1.8373418456764632

Epoch: 5| Step: 1
Training loss: 1.9942744970321655
Validation loss: 1.8010447332935948

Epoch: 5| Step: 2
Training loss: 1.7458854913711548
Validation loss: 1.8431654566077775

Epoch: 5| Step: 3
Training loss: 1.8543322086334229
Validation loss: 1.8452571258750012

Epoch: 5| Step: 4
Training loss: 1.9980113506317139
Validation loss: 1.8177698119994132

Epoch: 5| Step: 5
Training loss: 1.482029676437378
Validation loss: 1.8281763548492103

Epoch: 5| Step: 6
Training loss: 1.2034177780151367
Validation loss: 1.8047987825127059

Epoch: 5| Step: 7
Training loss: 1.583698034286499
Validation loss: 1.8523634864437966

Epoch: 5| Step: 8
Training loss: 1.5820198059082031
Validation loss: 1.8274146600436139

Epoch: 5| Step: 9
Training loss: 1.4650635719299316
Validation loss: 1.823451586948928

Epoch: 5| Step: 10
Training loss: 1.844321846961975
Validation loss: 1.828914721806844

Epoch: 216| Step: 0
Training loss: 2.070054531097412
Validation loss: 1.8771752670247068

Epoch: 5| Step: 1
Training loss: 1.5254923105239868
Validation loss: 1.7962419256087272

Epoch: 5| Step: 2
Training loss: 1.4867790937423706
Validation loss: 1.8008923402396582

Epoch: 5| Step: 3
Training loss: 1.4425894021987915
Validation loss: 1.8344550184024278

Epoch: 5| Step: 4
Training loss: 1.4874507188796997
Validation loss: 1.8364675070649834

Epoch: 5| Step: 5
Training loss: 1.5126444101333618
Validation loss: 1.8241105643651818

Epoch: 5| Step: 6
Training loss: 1.9320865869522095
Validation loss: 1.81538636197326

Epoch: 5| Step: 7
Training loss: 1.7617216110229492
Validation loss: 1.8111897540348831

Epoch: 5| Step: 8
Training loss: 1.8692373037338257
Validation loss: 1.7779391234920872

Epoch: 5| Step: 9
Training loss: 1.9561426639556885
Validation loss: 1.8198038980525026

Epoch: 5| Step: 10
Training loss: 1.692914605140686
Validation loss: 1.828274546131011

Epoch: 217| Step: 0
Training loss: 2.0293946266174316
Validation loss: 1.8422924549348894

Epoch: 5| Step: 1
Training loss: 1.378166675567627
Validation loss: 1.8413362374869726

Epoch: 5| Step: 2
Training loss: 2.2369208335876465
Validation loss: 1.8219620412395847

Epoch: 5| Step: 3
Training loss: 1.0869050025939941
Validation loss: 1.8596538984647362

Epoch: 5| Step: 4
Training loss: 1.5291962623596191
Validation loss: 1.818224726184722

Epoch: 5| Step: 5
Training loss: 1.9515964984893799
Validation loss: 1.8611226556121663

Epoch: 5| Step: 6
Training loss: 1.7303009033203125
Validation loss: 1.779063376047278

Epoch: 5| Step: 7
Training loss: 1.7859081029891968
Validation loss: 1.824533449706211

Epoch: 5| Step: 8
Training loss: 1.6936368942260742
Validation loss: 1.7896519860913676

Epoch: 5| Step: 9
Training loss: 1.6600700616836548
Validation loss: 1.8512755593945902

Epoch: 5| Step: 10
Training loss: 1.5103224515914917
Validation loss: 1.8542892638073172

Epoch: 218| Step: 0
Training loss: 2.321941375732422
Validation loss: 1.8418395775620655

Epoch: 5| Step: 1
Training loss: 1.5638933181762695
Validation loss: 1.859797752031716

Epoch: 5| Step: 2
Training loss: 1.4246574640274048
Validation loss: 1.8262467166428924

Epoch: 5| Step: 3
Training loss: 2.01358699798584
Validation loss: 1.8462642149258686

Epoch: 5| Step: 4
Training loss: 2.254814624786377
Validation loss: 1.8652815741877402

Epoch: 5| Step: 5
Training loss: 1.4376804828643799
Validation loss: 1.8795460116478704

Epoch: 5| Step: 6
Training loss: 1.5751988887786865
Validation loss: 1.8525583513321415

Epoch: 5| Step: 7
Training loss: 2.0016026496887207
Validation loss: 1.876985619145055

Epoch: 5| Step: 8
Training loss: 1.3673912286758423
Validation loss: 1.8347776282218196

Epoch: 5| Step: 9
Training loss: 0.9900579452514648
Validation loss: 1.8461073188371555

Epoch: 5| Step: 10
Training loss: 1.5019288063049316
Validation loss: 1.8411226170037382

Epoch: 219| Step: 0
Training loss: 1.7334177494049072
Validation loss: 1.8070968709966189

Epoch: 5| Step: 1
Training loss: 1.7481963634490967
Validation loss: 1.830363381293512

Epoch: 5| Step: 2
Training loss: 1.841404914855957
Validation loss: 1.859487392569101

Epoch: 5| Step: 3
Training loss: 1.7927875518798828
Validation loss: 1.8221984550517092

Epoch: 5| Step: 4
Training loss: 1.4491019248962402
Validation loss: 1.8255882955366565

Epoch: 5| Step: 5
Training loss: 1.6883341073989868
Validation loss: 1.8398618877574962

Epoch: 5| Step: 6
Training loss: 1.5308376550674438
Validation loss: 1.8757976408927672

Epoch: 5| Step: 7
Training loss: 1.9358394145965576
Validation loss: 1.836645886462222

Epoch: 5| Step: 8
Training loss: 1.3471975326538086
Validation loss: 1.8173684586760819

Epoch: 5| Step: 9
Training loss: 2.5895907878875732
Validation loss: 1.8495557526106476

Epoch: 5| Step: 10
Training loss: 0.8023847937583923
Validation loss: 1.8072378827679543

Epoch: 220| Step: 0
Training loss: 1.6603758335113525
Validation loss: 1.7582677602767944

Epoch: 5| Step: 1
Training loss: 1.198994755744934
Validation loss: 1.8094449658547678

Epoch: 5| Step: 2
Training loss: 1.943781852722168
Validation loss: 1.7796324183863979

Epoch: 5| Step: 3
Training loss: 1.8430688381195068
Validation loss: 1.7846132478406351

Epoch: 5| Step: 4
Training loss: 1.7041447162628174
Validation loss: 1.790183573640803

Epoch: 5| Step: 5
Training loss: 1.7908947467803955
Validation loss: 1.8035668916599725

Epoch: 5| Step: 6
Training loss: 1.2173020839691162
Validation loss: 1.8091662724812825

Epoch: 5| Step: 7
Training loss: 1.4872251749038696
Validation loss: 1.7820996456248785

Epoch: 5| Step: 8
Training loss: 1.9190555810928345
Validation loss: 1.7898580297347038

Epoch: 5| Step: 9
Training loss: 1.6984186172485352
Validation loss: 1.7955120353288547

Epoch: 5| Step: 10
Training loss: 2.376460552215576
Validation loss: 1.8060056727419618

Epoch: 221| Step: 0
Training loss: 1.4223259687423706
Validation loss: 1.8152365581963652

Epoch: 5| Step: 1
Training loss: 1.2863664627075195
Validation loss: 1.822199220298439

Epoch: 5| Step: 2
Training loss: 1.5546611547470093
Validation loss: 1.8890711030652445

Epoch: 5| Step: 3
Training loss: 1.5271632671356201
Validation loss: 1.835976085355205

Epoch: 5| Step: 4
Training loss: 2.1047282218933105
Validation loss: 1.8369247746723953

Epoch: 5| Step: 5
Training loss: 1.9818977117538452
Validation loss: 1.8456708000552269

Epoch: 5| Step: 6
Training loss: 1.7447534799575806
Validation loss: 1.8326876150664462

Epoch: 5| Step: 7
Training loss: 1.5219812393188477
Validation loss: 1.8349629499578988

Epoch: 5| Step: 8
Training loss: 1.8138482570648193
Validation loss: 1.8434058184264808

Epoch: 5| Step: 9
Training loss: 1.6973094940185547
Validation loss: 1.8480298032042801

Epoch: 5| Step: 10
Training loss: 1.6942297220230103
Validation loss: 1.8476474900399484

Epoch: 222| Step: 0
Training loss: 1.648352861404419
Validation loss: 1.8707029499033445

Epoch: 5| Step: 1
Training loss: 1.412117600440979
Validation loss: 1.8654837582700996

Epoch: 5| Step: 2
Training loss: 1.7958791255950928
Validation loss: 1.8489658627458798

Epoch: 5| Step: 3
Training loss: 1.5880186557769775
Validation loss: 1.8863000331386444

Epoch: 5| Step: 4
Training loss: 1.683349847793579
Validation loss: 1.8543021832742999

Epoch: 5| Step: 5
Training loss: 2.1088643074035645
Validation loss: 1.8249392406914824

Epoch: 5| Step: 6
Training loss: 1.4430307149887085
Validation loss: 1.8381540980390323

Epoch: 5| Step: 7
Training loss: 1.7310950756072998
Validation loss: 1.7874169118942753

Epoch: 5| Step: 8
Training loss: 0.9242467880249023
Validation loss: 1.7909064010907245

Epoch: 5| Step: 9
Training loss: 1.9863401651382446
Validation loss: 1.765130308366591

Epoch: 5| Step: 10
Training loss: 1.913287878036499
Validation loss: 1.8326278348122873

Epoch: 223| Step: 0
Training loss: 1.5568283796310425
Validation loss: 1.7990892253896242

Epoch: 5| Step: 1
Training loss: 1.9152778387069702
Validation loss: 1.8090912565108268

Epoch: 5| Step: 2
Training loss: 1.8622955083847046
Validation loss: 1.8225511056120678

Epoch: 5| Step: 3
Training loss: 1.738703727722168
Validation loss: 1.843021394104086

Epoch: 5| Step: 4
Training loss: 1.7017803192138672
Validation loss: 1.8358526345222228

Epoch: 5| Step: 5
Training loss: 1.9412914514541626
Validation loss: 1.8109897541743454

Epoch: 5| Step: 6
Training loss: 1.6483802795410156
Validation loss: 1.858820257648345

Epoch: 5| Step: 7
Training loss: 1.7409826517105103
Validation loss: 1.8470388740621588

Epoch: 5| Step: 8
Training loss: 1.727888822555542
Validation loss: 1.817018642220446

Epoch: 5| Step: 9
Training loss: 1.4245277643203735
Validation loss: 1.847316675288703

Epoch: 5| Step: 10
Training loss: 1.2112901210784912
Validation loss: 1.8612999300802908

Epoch: 224| Step: 0
Training loss: 2.562549591064453
Validation loss: 1.8428564635656213

Epoch: 5| Step: 1
Training loss: 1.3155467510223389
Validation loss: 1.8716867252062726

Epoch: 5| Step: 2
Training loss: 1.3561369180679321
Validation loss: 1.807795516906246

Epoch: 5| Step: 3
Training loss: 1.4357032775878906
Validation loss: 1.7983684321885467

Epoch: 5| Step: 4
Training loss: 1.807531714439392
Validation loss: 1.8361033239672262

Epoch: 5| Step: 5
Training loss: 2.2057700157165527
Validation loss: 1.8265864413271669

Epoch: 5| Step: 6
Training loss: 1.4518163204193115
Validation loss: 1.7928533015712615

Epoch: 5| Step: 7
Training loss: 1.5926328897476196
Validation loss: 1.8264316666510798

Epoch: 5| Step: 8
Training loss: 1.4794209003448486
Validation loss: 1.8548604147408598

Epoch: 5| Step: 9
Training loss: 1.538203239440918
Validation loss: 1.8114832883240075

Epoch: 5| Step: 10
Training loss: 1.8850620985031128
Validation loss: 1.8273444790993967

Epoch: 225| Step: 0
Training loss: 1.6990476846694946
Validation loss: 1.7873705010260306

Epoch: 5| Step: 1
Training loss: 1.237114667892456
Validation loss: 1.8015062309080554

Epoch: 5| Step: 2
Training loss: 1.4856351613998413
Validation loss: 1.8437547991352696

Epoch: 5| Step: 3
Training loss: 2.2229037284851074
Validation loss: 1.818229777838594

Epoch: 5| Step: 4
Training loss: 1.3493090867996216
Validation loss: 1.8145098968218731

Epoch: 5| Step: 5
Training loss: 1.407921552658081
Validation loss: 1.8421666699071084

Epoch: 5| Step: 6
Training loss: 1.597067952156067
Validation loss: 1.8068807535274054

Epoch: 5| Step: 7
Training loss: 2.427419662475586
Validation loss: 1.8480798762331727

Epoch: 5| Step: 8
Training loss: 1.6302906274795532
Validation loss: 1.871087117861676

Epoch: 5| Step: 9
Training loss: 1.7125422954559326
Validation loss: 1.8470458651101718

Epoch: 5| Step: 10
Training loss: 1.4453611373901367
Validation loss: 1.8228780146568053

Epoch: 226| Step: 0
Training loss: 2.029078245162964
Validation loss: 1.8427009620974142

Epoch: 5| Step: 1
Training loss: 1.8632678985595703
Validation loss: 1.8286973276445944

Epoch: 5| Step: 2
Training loss: 1.2220269441604614
Validation loss: 1.818492934268008

Epoch: 5| Step: 3
Training loss: 0.9779243469238281
Validation loss: 1.85573378685982

Epoch: 5| Step: 4
Training loss: 1.6783510446548462
Validation loss: 1.7815872059073499

Epoch: 5| Step: 5
Training loss: 2.205470561981201
Validation loss: 1.795948075991805

Epoch: 5| Step: 6
Training loss: 1.9653205871582031
Validation loss: 1.825140130135321

Epoch: 5| Step: 7
Training loss: 1.3960292339324951
Validation loss: 1.7958123530111005

Epoch: 5| Step: 8
Training loss: 1.229185700416565
Validation loss: 1.822200608509843

Epoch: 5| Step: 9
Training loss: 2.161712408065796
Validation loss: 1.762898197738073

Epoch: 5| Step: 10
Training loss: 1.83098304271698
Validation loss: 1.839993872950154

Epoch: 227| Step: 0
Training loss: 1.4535231590270996
Validation loss: 1.8141575731256956

Epoch: 5| Step: 1
Training loss: 1.576265811920166
Validation loss: 1.7958575781955515

Epoch: 5| Step: 2
Training loss: 1.6815745830535889
Validation loss: 1.8256572984880017

Epoch: 5| Step: 3
Training loss: 1.8089157342910767
Validation loss: 1.793959048486525

Epoch: 5| Step: 4
Training loss: 1.9785149097442627
Validation loss: 1.796597897365529

Epoch: 5| Step: 5
Training loss: 1.6533889770507812
Validation loss: 1.7762205664829542

Epoch: 5| Step: 6
Training loss: 1.2256075143814087
Validation loss: 1.8045980212508992

Epoch: 5| Step: 7
Training loss: 1.1549581289291382
Validation loss: 1.8326613390317528

Epoch: 5| Step: 8
Training loss: 1.8169183731079102
Validation loss: 1.8273488180611723

Epoch: 5| Step: 9
Training loss: 2.6156954765319824
Validation loss: 1.8297893975370674

Epoch: 5| Step: 10
Training loss: 1.321850061416626
Validation loss: 1.8490858693276682

Epoch: 228| Step: 0
Training loss: 1.4532098770141602
Validation loss: 1.8012858693317702

Epoch: 5| Step: 1
Training loss: 1.194258451461792
Validation loss: 1.8697276089781074

Epoch: 5| Step: 2
Training loss: 1.5273702144622803
Validation loss: 1.8204532464345295

Epoch: 5| Step: 3
Training loss: 1.7910830974578857
Validation loss: 1.8320525384718371

Epoch: 5| Step: 4
Training loss: 1.5519955158233643
Validation loss: 1.8209284236354213

Epoch: 5| Step: 5
Training loss: 1.9543399810791016
Validation loss: 1.7633282215364519

Epoch: 5| Step: 6
Training loss: 1.591461420059204
Validation loss: 1.8036983654063234

Epoch: 5| Step: 7
Training loss: 1.822208046913147
Validation loss: 1.8687657720299178

Epoch: 5| Step: 8
Training loss: 1.9976747035980225
Validation loss: 1.826888148502637

Epoch: 5| Step: 9
Training loss: 1.6668717861175537
Validation loss: 1.8128187733311807

Epoch: 5| Step: 10
Training loss: 1.4991511106491089
Validation loss: 1.833496291150329

Epoch: 229| Step: 0
Training loss: 1.8503183126449585
Validation loss: 1.8388927162334483

Epoch: 5| Step: 1
Training loss: 1.8525279760360718
Validation loss: 1.869505229816642

Epoch: 5| Step: 2
Training loss: 1.7024753093719482
Validation loss: 1.8144837861420007

Epoch: 5| Step: 3
Training loss: 2.0175366401672363
Validation loss: 1.816383672016923

Epoch: 5| Step: 4
Training loss: 1.396587610244751
Validation loss: 1.845572840782904

Epoch: 5| Step: 5
Training loss: 1.376840353012085
Validation loss: 1.8353918393452961

Epoch: 5| Step: 6
Training loss: 1.5225646495819092
Validation loss: 1.8515196974559496

Epoch: 5| Step: 7
Training loss: 1.6522417068481445
Validation loss: 1.8226175872228478

Epoch: 5| Step: 8
Training loss: 1.481076955795288
Validation loss: 1.8017760374212777

Epoch: 5| Step: 9
Training loss: 1.4256864786148071
Validation loss: 1.8065546366476244

Epoch: 5| Step: 10
Training loss: 1.8900725841522217
Validation loss: 1.8172018194711337

Epoch: 230| Step: 0
Training loss: 1.3636808395385742
Validation loss: 1.8250886829950477

Epoch: 5| Step: 1
Training loss: 2.354346513748169
Validation loss: 1.7703976528618925

Epoch: 5| Step: 2
Training loss: 1.1217236518859863
Validation loss: 1.7735416491826375

Epoch: 5| Step: 3
Training loss: 1.6122894287109375
Validation loss: 1.7672851265117686

Epoch: 5| Step: 4
Training loss: 1.4477899074554443
Validation loss: 1.8307634720238306

Epoch: 5| Step: 5
Training loss: 1.2987937927246094
Validation loss: 1.8194394931998303

Epoch: 5| Step: 6
Training loss: 1.313585877418518
Validation loss: 1.8004624753869989

Epoch: 5| Step: 7
Training loss: 2.3051538467407227
Validation loss: 1.809920923684233

Epoch: 5| Step: 8
Training loss: 1.5260027647018433
Validation loss: 1.7755929423916725

Epoch: 5| Step: 9
Training loss: 1.52882981300354
Validation loss: 1.7930236708733343

Epoch: 5| Step: 10
Training loss: 2.371213674545288
Validation loss: 1.8117479944741854

Epoch: 231| Step: 0
Training loss: 1.5474894046783447
Validation loss: 1.8226754896102413

Epoch: 5| Step: 1
Training loss: 1.5072438716888428
Validation loss: 1.846880917908043

Epoch: 5| Step: 2
Training loss: 1.3259236812591553
Validation loss: 1.8203243286378923

Epoch: 5| Step: 3
Training loss: 1.4929425716400146
Validation loss: 1.8774608155732513

Epoch: 5| Step: 4
Training loss: 2.1414954662323
Validation loss: 1.833695150190784

Epoch: 5| Step: 5
Training loss: 1.4740686416625977
Validation loss: 1.8490373408922585

Epoch: 5| Step: 6
Training loss: 2.091958522796631
Validation loss: 1.8649103872237667

Epoch: 5| Step: 7
Training loss: 1.175045132637024
Validation loss: 1.8498293167801314

Epoch: 5| Step: 8
Training loss: 1.9305915832519531
Validation loss: 1.8464736105293356

Epoch: 5| Step: 9
Training loss: 2.1192731857299805
Validation loss: 1.8285170460260043

Epoch: 5| Step: 10
Training loss: 1.554853081703186
Validation loss: 1.8271357769607215

Epoch: 232| Step: 0
Training loss: 1.650435209274292
Validation loss: 1.8578809589468024

Epoch: 5| Step: 1
Training loss: 1.7859928607940674
Validation loss: 1.8068459982513099

Epoch: 5| Step: 2
Training loss: 2.097217559814453
Validation loss: 1.7861296746038622

Epoch: 5| Step: 3
Training loss: 1.3290594816207886
Validation loss: 1.803737860853954

Epoch: 5| Step: 4
Training loss: 1.4135324954986572
Validation loss: 1.7988746140592842

Epoch: 5| Step: 5
Training loss: 1.278893232345581
Validation loss: 1.8205096580648934

Epoch: 5| Step: 6
Training loss: 1.6245476007461548
Validation loss: 1.793485628661289

Epoch: 5| Step: 7
Training loss: 2.3148574829101562
Validation loss: 1.8108874828584733

Epoch: 5| Step: 8
Training loss: 1.3458245992660522
Validation loss: 1.8204346818308677

Epoch: 5| Step: 9
Training loss: 2.0037829875946045
Validation loss: 1.8234431448803152

Epoch: 5| Step: 10
Training loss: 1.3504209518432617
Validation loss: 1.7990967906931394

Epoch: 233| Step: 0
Training loss: 1.884810209274292
Validation loss: 1.7849728920126473

Epoch: 5| Step: 1
Training loss: 1.1414775848388672
Validation loss: 1.8164836950199579

Epoch: 5| Step: 2
Training loss: 2.011218309402466
Validation loss: 1.7905999370800552

Epoch: 5| Step: 3
Training loss: 1.0451176166534424
Validation loss: 1.8043795388231996

Epoch: 5| Step: 4
Training loss: 1.609614610671997
Validation loss: 1.8148462541641728

Epoch: 5| Step: 5
Training loss: 1.9398540258407593
Validation loss: 1.7944480655013875

Epoch: 5| Step: 6
Training loss: 1.7330280542373657
Validation loss: 1.8147186592061033

Epoch: 5| Step: 7
Training loss: 1.7938356399536133
Validation loss: 1.7945744696483816

Epoch: 5| Step: 8
Training loss: 1.4376834630966187
Validation loss: 1.8238807032185216

Epoch: 5| Step: 9
Training loss: 1.9995155334472656
Validation loss: 1.8109433125424128

Epoch: 5| Step: 10
Training loss: 1.652559757232666
Validation loss: 1.8037344614664714

Epoch: 234| Step: 0
Training loss: 2.159853935241699
Validation loss: 1.8220255362090243

Epoch: 5| Step: 1
Training loss: 1.6600427627563477
Validation loss: 1.8133531719125726

Epoch: 5| Step: 2
Training loss: 1.4925379753112793
Validation loss: 1.8310035672239078

Epoch: 5| Step: 3
Training loss: 1.7334095239639282
Validation loss: 1.8511789755154682

Epoch: 5| Step: 4
Training loss: 1.504754662513733
Validation loss: 1.8438067205490605

Epoch: 5| Step: 5
Training loss: 1.617201805114746
Validation loss: 1.8592717570643271

Epoch: 5| Step: 6
Training loss: 1.9292892217636108
Validation loss: 1.8294262783501738

Epoch: 5| Step: 7
Training loss: 1.4141515493392944
Validation loss: 1.773409366607666

Epoch: 5| Step: 8
Training loss: 1.8820728063583374
Validation loss: 1.8162289832227974

Epoch: 5| Step: 9
Training loss: 1.2476094961166382
Validation loss: 1.79743125489963

Epoch: 5| Step: 10
Training loss: 1.2251474857330322
Validation loss: 1.7741877584047214

Epoch: 235| Step: 0
Training loss: 1.2242624759674072
Validation loss: 1.8182187131656113

Epoch: 5| Step: 1
Training loss: 1.5699489116668701
Validation loss: 1.8081812832945137

Epoch: 5| Step: 2
Training loss: 1.3742691278457642
Validation loss: 1.8362607302204255

Epoch: 5| Step: 3
Training loss: 1.910784363746643
Validation loss: 1.8252217897804834

Epoch: 5| Step: 4
Training loss: 1.5317308902740479
Validation loss: 1.8150223109029955

Epoch: 5| Step: 5
Training loss: 1.338440179824829
Validation loss: 1.8215307087026618

Epoch: 5| Step: 6
Training loss: 1.581183671951294
Validation loss: 1.8200884788267073

Epoch: 5| Step: 7
Training loss: 1.620266318321228
Validation loss: 1.8558271969518354

Epoch: 5| Step: 8
Training loss: 2.250460624694824
Validation loss: 1.8086484298911145

Epoch: 5| Step: 9
Training loss: 1.8776839971542358
Validation loss: 1.8162034724348335

Epoch: 5| Step: 10
Training loss: 1.8121665716171265
Validation loss: 1.8228383333452287

Epoch: 236| Step: 0
Training loss: 1.759361982345581
Validation loss: 1.8555203099404611

Epoch: 5| Step: 1
Training loss: 1.2240383625030518
Validation loss: 1.8353216635283602

Epoch: 5| Step: 2
Training loss: 1.9568077325820923
Validation loss: 1.8675657626121276

Epoch: 5| Step: 3
Training loss: 1.7709957361221313
Validation loss: 1.826052983601888

Epoch: 5| Step: 4
Training loss: 1.3144769668579102
Validation loss: 1.8507937667190388

Epoch: 5| Step: 5
Training loss: 1.6089704036712646
Validation loss: 1.8250642796998382

Epoch: 5| Step: 6
Training loss: 1.3337852954864502
Validation loss: 1.8421263579399354

Epoch: 5| Step: 7
Training loss: 1.6955026388168335
Validation loss: 1.8279843920020646

Epoch: 5| Step: 8
Training loss: 1.7546523809432983
Validation loss: 1.8370571367202266

Epoch: 5| Step: 9
Training loss: 1.5303149223327637
Validation loss: 1.8525949806295416

Epoch: 5| Step: 10
Training loss: 1.9199905395507812
Validation loss: 1.7884528149840653

Epoch: 237| Step: 0
Training loss: 1.6298729181289673
Validation loss: 1.7977833876045801

Epoch: 5| Step: 1
Training loss: 1.296759009361267
Validation loss: 1.7955918927346506

Epoch: 5| Step: 2
Training loss: 2.0176546573638916
Validation loss: 1.8432096486450524

Epoch: 5| Step: 3
Training loss: 1.564725637435913
Validation loss: 1.819101442572891

Epoch: 5| Step: 4
Training loss: 1.421952486038208
Validation loss: 1.8254196041373796

Epoch: 5| Step: 5
Training loss: 1.9157527685165405
Validation loss: 1.8262505480038222

Epoch: 5| Step: 6
Training loss: 1.6224238872528076
Validation loss: 1.8190794952454106

Epoch: 5| Step: 7
Training loss: 2.0069448947906494
Validation loss: 1.8432982288381106

Epoch: 5| Step: 8
Training loss: 1.1358506679534912
Validation loss: 1.8201413987785258

Epoch: 5| Step: 9
Training loss: 1.5719501972198486
Validation loss: 1.8395782862940142

Epoch: 5| Step: 10
Training loss: 1.863313913345337
Validation loss: 1.812767396691025

Epoch: 238| Step: 0
Training loss: 1.5732691287994385
Validation loss: 1.8082098550693964

Epoch: 5| Step: 1
Training loss: 1.7356452941894531
Validation loss: 1.8134140686322284

Epoch: 5| Step: 2
Training loss: 1.5596561431884766
Validation loss: 1.8134357083228327

Epoch: 5| Step: 3
Training loss: 0.8157550096511841
Validation loss: 1.7700986887819024

Epoch: 5| Step: 4
Training loss: 1.4386742115020752
Validation loss: 1.7632868418129541

Epoch: 5| Step: 5
Training loss: 1.4852321147918701
Validation loss: 1.8302465113260413

Epoch: 5| Step: 6
Training loss: 1.8701130151748657
Validation loss: 1.7933630815116308

Epoch: 5| Step: 7
Training loss: 1.9545114040374756
Validation loss: 1.8171171449845838

Epoch: 5| Step: 8
Training loss: 1.4076131582260132
Validation loss: 1.8196162895489765

Epoch: 5| Step: 9
Training loss: 2.493055820465088
Validation loss: 1.8286384049282278

Epoch: 5| Step: 10
Training loss: 1.3737248182296753
Validation loss: 1.81694572330803

Epoch: 239| Step: 0
Training loss: 2.162489175796509
Validation loss: 1.8433440321235246

Epoch: 5| Step: 1
Training loss: 1.6892026662826538
Validation loss: 1.8325276502998926

Epoch: 5| Step: 2
Training loss: 1.1977039575576782
Validation loss: 1.8481603655763852

Epoch: 5| Step: 3
Training loss: 1.0804953575134277
Validation loss: 1.8595489789080877

Epoch: 5| Step: 4
Training loss: 1.2822710275650024
Validation loss: 1.851212106725221

Epoch: 5| Step: 5
Training loss: 1.6671245098114014
Validation loss: 1.8592629227586972

Epoch: 5| Step: 6
Training loss: 1.5018845796585083
Validation loss: 1.884773051866921

Epoch: 5| Step: 7
Training loss: 2.367955207824707
Validation loss: 1.846457051974471

Epoch: 5| Step: 8
Training loss: 1.5883443355560303
Validation loss: 1.8255200360410957

Epoch: 5| Step: 9
Training loss: 1.7595525979995728
Validation loss: 1.8315007212341472

Epoch: 5| Step: 10
Training loss: 1.5626122951507568
Validation loss: 1.8036044900135328

Epoch: 240| Step: 0
Training loss: 1.3395211696624756
Validation loss: 1.8302310051456574

Epoch: 5| Step: 1
Training loss: 1.6059284210205078
Validation loss: 1.8222376954170965

Epoch: 5| Step: 2
Training loss: 2.3161392211914062
Validation loss: 1.8224928955877981

Epoch: 5| Step: 3
Training loss: 1.1762354373931885
Validation loss: 1.832088739641251

Epoch: 5| Step: 4
Training loss: 2.152524471282959
Validation loss: 1.8279650672789542

Epoch: 5| Step: 5
Training loss: 1.8442550897598267
Validation loss: 1.8123225371042888

Epoch: 5| Step: 6
Training loss: 1.7538820505142212
Validation loss: 1.8373162156792098

Epoch: 5| Step: 7
Training loss: 1.9735095500946045
Validation loss: 1.7530410494855655

Epoch: 5| Step: 8
Training loss: 1.393841028213501
Validation loss: 1.8148803736573906

Epoch: 5| Step: 9
Training loss: 0.9255943298339844
Validation loss: 1.8322562709931405

Epoch: 5| Step: 10
Training loss: 1.3059521913528442
Validation loss: 1.8412603306513962

Epoch: 241| Step: 0
Training loss: 1.3750734329223633
Validation loss: 1.823213561888664

Epoch: 5| Step: 1
Training loss: 1.3572113513946533
Validation loss: 1.8119469906694146

Epoch: 5| Step: 2
Training loss: 1.7424834966659546
Validation loss: 1.8097612819363993

Epoch: 5| Step: 3
Training loss: 1.767290711402893
Validation loss: 1.8250648898463095

Epoch: 5| Step: 4
Training loss: 1.5376754999160767
Validation loss: 1.8015850564484954

Epoch: 5| Step: 5
Training loss: 1.4208052158355713
Validation loss: 1.7850379866938437

Epoch: 5| Step: 6
Training loss: 2.0732200145721436
Validation loss: 1.792611865587132

Epoch: 5| Step: 7
Training loss: 1.4788358211517334
Validation loss: 1.8377503502753474

Epoch: 5| Step: 8
Training loss: 1.016338586807251
Validation loss: 1.8616215605889597

Epoch: 5| Step: 9
Training loss: 1.9014629125595093
Validation loss: 1.8543497964900026

Epoch: 5| Step: 10
Training loss: 2.259178638458252
Validation loss: 1.8077462232241066

Epoch: 242| Step: 0
Training loss: 2.2074825763702393
Validation loss: 1.8490565233333136

Epoch: 5| Step: 1
Training loss: 1.7107681035995483
Validation loss: 1.827259002193328

Epoch: 5| Step: 2
Training loss: 1.5583863258361816
Validation loss: 1.8619489836436447

Epoch: 5| Step: 3
Training loss: 1.3983404636383057
Validation loss: 1.7811126837166407

Epoch: 5| Step: 4
Training loss: 1.1432493925094604
Validation loss: 1.8310986616278206

Epoch: 5| Step: 5
Training loss: 2.284119129180908
Validation loss: 1.8043771982192993

Epoch: 5| Step: 6
Training loss: 1.69025456905365
Validation loss: 1.7912485535426805

Epoch: 5| Step: 7
Training loss: 1.5012588500976562
Validation loss: 1.8115436671882548

Epoch: 5| Step: 8
Training loss: 1.6560156345367432
Validation loss: 1.8224166490698372

Epoch: 5| Step: 9
Training loss: 1.458465337753296
Validation loss: 1.817160402574847

Epoch: 5| Step: 10
Training loss: 1.1862735748291016
Validation loss: 1.839633664777202

Epoch: 243| Step: 0
Training loss: 1.4757156372070312
Validation loss: 1.8139676560637772

Epoch: 5| Step: 1
Training loss: 1.544236421585083
Validation loss: 1.8115108910427298

Epoch: 5| Step: 2
Training loss: 1.6958744525909424
Validation loss: 1.84749162068931

Epoch: 5| Step: 3
Training loss: 1.3104348182678223
Validation loss: 1.8161075833023235

Epoch: 5| Step: 4
Training loss: 1.746086835861206
Validation loss: 1.828051572204918

Epoch: 5| Step: 5
Training loss: 1.9012439250946045
Validation loss: 1.7988305220039942

Epoch: 5| Step: 6
Training loss: 1.1191235780715942
Validation loss: 1.832089094705479

Epoch: 5| Step: 7
Training loss: 1.6632053852081299
Validation loss: 1.84311415303138

Epoch: 5| Step: 8
Training loss: 0.9334316253662109
Validation loss: 1.8534727045284805

Epoch: 5| Step: 9
Training loss: 2.4726290702819824
Validation loss: 1.817466720458

Epoch: 5| Step: 10
Training loss: 1.8183518648147583
Validation loss: 1.8248092897476689

Epoch: 244| Step: 0
Training loss: 1.4414489269256592
Validation loss: 1.8109650663150254

Epoch: 5| Step: 1
Training loss: 1.495693325996399
Validation loss: 1.7834718419659523

Epoch: 5| Step: 2
Training loss: 1.5632104873657227
Validation loss: 1.783220588520009

Epoch: 5| Step: 3
Training loss: 1.6017595529556274
Validation loss: 1.7872242722460019

Epoch: 5| Step: 4
Training loss: 1.8363183736801147
Validation loss: 1.7729099424936439

Epoch: 5| Step: 5
Training loss: 1.781794548034668
Validation loss: 1.7512349326123473

Epoch: 5| Step: 6
Training loss: 2.046395778656006
Validation loss: 1.7769053520694855

Epoch: 5| Step: 7
Training loss: 1.1701346635818481
Validation loss: 1.7883048160101778

Epoch: 5| Step: 8
Training loss: 1.5268208980560303
Validation loss: 1.784201201572213

Epoch: 5| Step: 9
Training loss: 1.5671002864837646
Validation loss: 1.802687793649653

Epoch: 5| Step: 10
Training loss: 1.7016844749450684
Validation loss: 1.790020670942081

Epoch: 245| Step: 0
Training loss: 2.2221972942352295
Validation loss: 1.7923577882910287

Epoch: 5| Step: 1
Training loss: 1.3800435066223145
Validation loss: 1.810467057330634

Epoch: 5| Step: 2
Training loss: 1.3137812614440918
Validation loss: 1.8191018873645413

Epoch: 5| Step: 3
Training loss: 1.5983302593231201
Validation loss: 1.818319232233109

Epoch: 5| Step: 4
Training loss: 0.9738733172416687
Validation loss: 1.8226273098299581

Epoch: 5| Step: 5
Training loss: 2.1535491943359375
Validation loss: 1.8306924348236413

Epoch: 5| Step: 6
Training loss: 1.1552993059158325
Validation loss: 1.8137031844867173

Epoch: 5| Step: 7
Training loss: 1.8817116022109985
Validation loss: 1.81648043663271

Epoch: 5| Step: 8
Training loss: 1.262317419052124
Validation loss: 1.7851846474473194

Epoch: 5| Step: 9
Training loss: 1.8310966491699219
Validation loss: 1.8321212350681264

Epoch: 5| Step: 10
Training loss: 1.5722506046295166
Validation loss: 1.8364694926046556

Epoch: 246| Step: 0
Training loss: 1.5952579975128174
Validation loss: 1.8219460774493474

Epoch: 5| Step: 1
Training loss: 1.9408010244369507
Validation loss: 1.8508597343198714

Epoch: 5| Step: 2
Training loss: 1.5857986211776733
Validation loss: 1.8433000438956804

Epoch: 5| Step: 3
Training loss: 2.2549214363098145
Validation loss: 1.8358480635509695

Epoch: 5| Step: 4
Training loss: 1.1064186096191406
Validation loss: 1.817618344419746

Epoch: 5| Step: 5
Training loss: 1.4492374658584595
Validation loss: 1.8428483880976194

Epoch: 5| Step: 6
Training loss: 1.6730772256851196
Validation loss: 1.8338636775170603

Epoch: 5| Step: 7
Training loss: 1.3969306945800781
Validation loss: 1.8153189997519217

Epoch: 5| Step: 8
Training loss: 1.4411698579788208
Validation loss: 1.872564350405047

Epoch: 5| Step: 9
Training loss: 1.4774796962738037
Validation loss: 1.825326814446398

Epoch: 5| Step: 10
Training loss: 1.6545811891555786
Validation loss: 1.8244176321132208

Epoch: 247| Step: 0
Training loss: 1.7536216974258423
Validation loss: 1.8221143753297868

Epoch: 5| Step: 1
Training loss: 1.3102130889892578
Validation loss: 1.7706294803209202

Epoch: 5| Step: 2
Training loss: 2.129767894744873
Validation loss: 1.7776381738724247

Epoch: 5| Step: 3
Training loss: 1.4037586450576782
Validation loss: 1.805008360134658

Epoch: 5| Step: 4
Training loss: 1.8033138513565063
Validation loss: 1.8012709053613807

Epoch: 5| Step: 5
Training loss: 1.8022127151489258
Validation loss: 1.782181247588127

Epoch: 5| Step: 6
Training loss: 1.8867086172103882
Validation loss: 1.8005287083246375

Epoch: 5| Step: 7
Training loss: 1.4927592277526855
Validation loss: 1.7612473503235848

Epoch: 5| Step: 8
Training loss: 1.0522369146347046
Validation loss: 1.8139403699546732

Epoch: 5| Step: 9
Training loss: 1.549208641052246
Validation loss: 1.812938069784513

Epoch: 5| Step: 10
Training loss: 1.3587045669555664
Validation loss: 1.8172678639811854

Epoch: 248| Step: 0
Training loss: 1.356522798538208
Validation loss: 1.8044167564761253

Epoch: 5| Step: 1
Training loss: 0.7963002920150757
Validation loss: 1.8300532115403043

Epoch: 5| Step: 2
Training loss: 1.5503917932510376
Validation loss: 1.7847213488753124

Epoch: 5| Step: 3
Training loss: 1.8188211917877197
Validation loss: 1.8021987856075328

Epoch: 5| Step: 4
Training loss: 2.0864667892456055
Validation loss: 1.831612261392737

Epoch: 5| Step: 5
Training loss: 1.5762956142425537
Validation loss: 1.7869662943706717

Epoch: 5| Step: 6
Training loss: 2.2518646717071533
Validation loss: 1.7831304252788585

Epoch: 5| Step: 7
Training loss: 1.3207237720489502
Validation loss: 1.8061412790770173

Epoch: 5| Step: 8
Training loss: 1.4889342784881592
Validation loss: 1.8617633337615638

Epoch: 5| Step: 9
Training loss: 1.7741882801055908
Validation loss: 1.8268435488465011

Epoch: 5| Step: 10
Training loss: 1.602196216583252
Validation loss: 1.7608083627557243

Epoch: 249| Step: 0
Training loss: 1.5743272304534912
Validation loss: 1.8193650732758224

Epoch: 5| Step: 1
Training loss: 1.3426127433776855
Validation loss: 1.8728119827085925

Epoch: 5| Step: 2
Training loss: 2.010828733444214
Validation loss: 1.8336138327916462

Epoch: 5| Step: 3
Training loss: 1.300641655921936
Validation loss: 1.808713315635599

Epoch: 5| Step: 4
Training loss: 2.0313220024108887
Validation loss: 1.844742500653831

Epoch: 5| Step: 5
Training loss: 1.4814859628677368
Validation loss: 1.828869863223004

Epoch: 5| Step: 6
Training loss: 1.704546570777893
Validation loss: 1.8442900770453996

Epoch: 5| Step: 7
Training loss: 1.9720836877822876
Validation loss: 1.878399084973079

Epoch: 5| Step: 8
Training loss: 1.3435466289520264
Validation loss: 1.834313695148755

Epoch: 5| Step: 9
Training loss: 1.6590602397918701
Validation loss: 1.790605096406834

Epoch: 5| Step: 10
Training loss: 1.0550687313079834
Validation loss: 1.823500100002494

Epoch: 250| Step: 0
Training loss: 1.3459768295288086
Validation loss: 1.7897123547010525

Epoch: 5| Step: 1
Training loss: 1.7445701360702515
Validation loss: 1.8324495618061354

Epoch: 5| Step: 2
Training loss: 1.5656591653823853
Validation loss: 1.804072864593998

Epoch: 5| Step: 3
Training loss: 1.1231005191802979
Validation loss: 1.8438898491603073

Epoch: 5| Step: 4
Training loss: 2.4389328956604004
Validation loss: 1.8016973977447839

Epoch: 5| Step: 5
Training loss: 1.7091245651245117
Validation loss: 1.8164201051958146

Epoch: 5| Step: 6
Training loss: 1.1945713758468628
Validation loss: 1.7992623993145522

Epoch: 5| Step: 7
Training loss: 0.8207313418388367
Validation loss: 1.8093263846571728

Epoch: 5| Step: 8
Training loss: 1.5793501138687134
Validation loss: 1.8121942807269353

Epoch: 5| Step: 9
Training loss: 2.4010825157165527
Validation loss: 1.794979892751222

Epoch: 5| Step: 10
Training loss: 1.688285231590271
Validation loss: 1.846682898459896

Epoch: 251| Step: 0
Training loss: 1.636794090270996
Validation loss: 1.8079505582009592

Epoch: 5| Step: 1
Training loss: 1.5738309621810913
Validation loss: 1.813035242019161

Epoch: 5| Step: 2
Training loss: 0.9096201062202454
Validation loss: 1.7740622284591838

Epoch: 5| Step: 3
Training loss: 1.6166267395019531
Validation loss: 1.807639891101468

Epoch: 5| Step: 4
Training loss: 1.5446317195892334
Validation loss: 1.7947495457946614

Epoch: 5| Step: 5
Training loss: 1.643865942955017
Validation loss: 1.7425053119659424

Epoch: 5| Step: 6
Training loss: 1.9299061298370361
Validation loss: 1.8050752186006116

Epoch: 5| Step: 7
Training loss: 1.5489073991775513
Validation loss: 1.7990496132963447

Epoch: 5| Step: 8
Training loss: 1.0216953754425049
Validation loss: 1.7764322270629227

Epoch: 5| Step: 9
Training loss: 2.34567928314209
Validation loss: 1.782018175689123

Epoch: 5| Step: 10
Training loss: 1.8334687948226929
Validation loss: 1.7687262976041405

Epoch: 252| Step: 0
Training loss: 1.4816052913665771
Validation loss: 1.8126607594951507

Epoch: 5| Step: 1
Training loss: 2.0593552589416504
Validation loss: 1.7703914360333515

Epoch: 5| Step: 2
Training loss: 1.4553983211517334
Validation loss: 1.7801438621295396

Epoch: 5| Step: 3
Training loss: 1.832389235496521
Validation loss: 1.7808897443996963

Epoch: 5| Step: 4
Training loss: 1.59247624874115
Validation loss: 1.8054155175403883

Epoch: 5| Step: 5
Training loss: 1.7672746181488037
Validation loss: 1.8183149189077399

Epoch: 5| Step: 6
Training loss: 1.5599642992019653
Validation loss: 1.851066316327741

Epoch: 5| Step: 7
Training loss: 1.3218910694122314
Validation loss: 1.8582884893622449

Epoch: 5| Step: 8
Training loss: 1.4572497606277466
Validation loss: 1.8381250468633508

Epoch: 5| Step: 9
Training loss: 1.696382761001587
Validation loss: 1.785029080606276

Epoch: 5| Step: 10
Training loss: 1.3367677927017212
Validation loss: 1.7916537677088091

Epoch: 253| Step: 0
Training loss: 1.0811893939971924
Validation loss: 1.7990732962085354

Epoch: 5| Step: 1
Training loss: 1.8360035419464111
Validation loss: 1.8616366360777168

Epoch: 5| Step: 2
Training loss: 1.0775721073150635
Validation loss: 1.8095241131321076

Epoch: 5| Step: 3
Training loss: 1.850214958190918
Validation loss: 1.8279954489841257

Epoch: 5| Step: 4
Training loss: 1.9582592248916626
Validation loss: 1.798746729409823

Epoch: 5| Step: 5
Training loss: 1.3294967412948608
Validation loss: 1.8194190225293558

Epoch: 5| Step: 6
Training loss: 1.526320219039917
Validation loss: 1.8004078147231892

Epoch: 5| Step: 7
Training loss: 1.245963215827942
Validation loss: 1.80071839978618

Epoch: 5| Step: 8
Training loss: 1.3854485750198364
Validation loss: 1.7929346074340164

Epoch: 5| Step: 9
Training loss: 1.5685060024261475
Validation loss: 1.797197186818687

Epoch: 5| Step: 10
Training loss: 2.7468678951263428
Validation loss: 1.764228710564234

Epoch: 254| Step: 0
Training loss: 2.1283116340637207
Validation loss: 1.830748527280746

Epoch: 5| Step: 1
Training loss: 1.22269606590271
Validation loss: 1.7939534879499865

Epoch: 5| Step: 2
Training loss: 1.5610086917877197
Validation loss: 1.7952759265899658

Epoch: 5| Step: 3
Training loss: 1.575199842453003
Validation loss: 1.8246728886840164

Epoch: 5| Step: 4
Training loss: 1.7404342889785767
Validation loss: 1.746622395771806

Epoch: 5| Step: 5
Training loss: 1.6229217052459717
Validation loss: 1.8115514555285055

Epoch: 5| Step: 6
Training loss: 1.365527868270874
Validation loss: 1.7974504399043258

Epoch: 5| Step: 7
Training loss: 1.8093993663787842
Validation loss: 1.826890476288334

Epoch: 5| Step: 8
Training loss: 1.785925269126892
Validation loss: 1.7826059992595384

Epoch: 5| Step: 9
Training loss: 1.2818667888641357
Validation loss: 1.8335313489360194

Epoch: 5| Step: 10
Training loss: 1.371908187866211
Validation loss: 1.8062921313829319

Epoch: 255| Step: 0
Training loss: 1.0724456310272217
Validation loss: 1.8306007936436643

Epoch: 5| Step: 1
Training loss: 1.9596668481826782
Validation loss: 1.836810955437281

Epoch: 5| Step: 2
Training loss: 1.076738953590393
Validation loss: 1.8396781516331497

Epoch: 5| Step: 3
Training loss: 1.6572113037109375
Validation loss: 1.8343083345761864

Epoch: 5| Step: 4
Training loss: 1.2556087970733643
Validation loss: 1.7657537447508944

Epoch: 5| Step: 5
Training loss: 1.8100547790527344
Validation loss: 1.8222491882180656

Epoch: 5| Step: 6
Training loss: 1.8736308813095093
Validation loss: 1.7629734546907487

Epoch: 5| Step: 7
Training loss: 1.9384912252426147
Validation loss: 1.7894025887212446

Epoch: 5| Step: 8
Training loss: 1.5273780822753906
Validation loss: 1.7812327518258044

Epoch: 5| Step: 9
Training loss: 1.6723295450210571
Validation loss: 1.813277509904677

Epoch: 5| Step: 10
Training loss: 1.5575374364852905
Validation loss: 1.8076827615819953

Epoch: 256| Step: 0
Training loss: 1.492379069328308
Validation loss: 1.8058679129487725

Epoch: 5| Step: 1
Training loss: 1.7406673431396484
Validation loss: 1.7998936714664582

Epoch: 5| Step: 2
Training loss: 2.0100603103637695
Validation loss: 1.8471035060062204

Epoch: 5| Step: 3
Training loss: 1.0679019689559937
Validation loss: 1.7769406867283646

Epoch: 5| Step: 4
Training loss: 1.3447846174240112
Validation loss: 1.8074092659898984

Epoch: 5| Step: 5
Training loss: 1.9269506931304932
Validation loss: 1.7688521762048044

Epoch: 5| Step: 6
Training loss: 0.9362604022026062
Validation loss: 1.804521345323132

Epoch: 5| Step: 7
Training loss: 1.5496433973312378
Validation loss: 1.8085301922213646

Epoch: 5| Step: 8
Training loss: 1.8173589706420898
Validation loss: 1.788509476569391

Epoch: 5| Step: 9
Training loss: 1.6632496118545532
Validation loss: 1.8101875551285282

Epoch: 5| Step: 10
Training loss: 2.119363784790039
Validation loss: 1.8073698807788152

Epoch: 257| Step: 0
Training loss: 1.1997458934783936
Validation loss: 1.7879919864798104

Epoch: 5| Step: 1
Training loss: 1.8462140560150146
Validation loss: 1.8219928638909453

Epoch: 5| Step: 2
Training loss: 1.5007734298706055
Validation loss: 1.8212283234442435

Epoch: 5| Step: 3
Training loss: 2.125711679458618
Validation loss: 1.824428209694483

Epoch: 5| Step: 4
Training loss: 1.6228926181793213
Validation loss: 1.843556050331362

Epoch: 5| Step: 5
Training loss: 1.5672327280044556
Validation loss: 1.8970010049881474

Epoch: 5| Step: 6
Training loss: 1.6402575969696045
Validation loss: 1.8509862961307648

Epoch: 5| Step: 7
Training loss: 1.8306472301483154
Validation loss: 1.8896778283580657

Epoch: 5| Step: 8
Training loss: 1.6342405080795288
Validation loss: 1.8665604424732987

Epoch: 5| Step: 9
Training loss: 1.634163498878479
Validation loss: 1.8664710431970575

Epoch: 5| Step: 10
Training loss: 1.1165663003921509
Validation loss: 1.8309546362969182

Epoch: 258| Step: 0
Training loss: 1.7323192358016968
Validation loss: 1.8333918753490652

Epoch: 5| Step: 1
Training loss: 1.6159536838531494
Validation loss: 1.8435900006242978

Epoch: 5| Step: 2
Training loss: 1.2256524562835693
Validation loss: 1.8052960416322112

Epoch: 5| Step: 3
Training loss: 1.2375028133392334
Validation loss: 1.8410367222242459

Epoch: 5| Step: 4
Training loss: 1.9105002880096436
Validation loss: 1.8115631508570846

Epoch: 5| Step: 5
Training loss: 1.3394821882247925
Validation loss: 1.797729576787641

Epoch: 5| Step: 6
Training loss: 1.596222162246704
Validation loss: 1.780453722964051

Epoch: 5| Step: 7
Training loss: 1.960118293762207
Validation loss: 1.8184526530645226

Epoch: 5| Step: 8
Training loss: 1.830727219581604
Validation loss: 1.8215055452880038

Epoch: 5| Step: 9
Training loss: 1.5302503108978271
Validation loss: 1.790400574284215

Epoch: 5| Step: 10
Training loss: 1.0636067390441895
Validation loss: 1.8069403043357275

Epoch: 259| Step: 0
Training loss: 1.1106035709381104
Validation loss: 1.8197161536062918

Epoch: 5| Step: 1
Training loss: 1.4634125232696533
Validation loss: 1.7768014041326379

Epoch: 5| Step: 2
Training loss: 1.6672627925872803
Validation loss: 1.8611817462469942

Epoch: 5| Step: 3
Training loss: 1.662713646888733
Validation loss: 1.8239309249385711

Epoch: 5| Step: 4
Training loss: 1.9559608697891235
Validation loss: 1.7862772582679667

Epoch: 5| Step: 5
Training loss: 1.5722604990005493
Validation loss: 1.8042772610982258

Epoch: 5| Step: 6
Training loss: 1.2330567836761475
Validation loss: 1.7991878576176141

Epoch: 5| Step: 7
Training loss: 2.182032346725464
Validation loss: 1.7911145225647958

Epoch: 5| Step: 8
Training loss: 1.4146747589111328
Validation loss: 1.807565454513796

Epoch: 5| Step: 9
Training loss: 1.5191396474838257
Validation loss: 1.844657467257592

Epoch: 5| Step: 10
Training loss: 1.3599860668182373
Validation loss: 1.8159737651066115

Epoch: 260| Step: 0
Training loss: 1.7730624675750732
Validation loss: 1.8284913288649691

Epoch: 5| Step: 1
Training loss: 1.4985206127166748
Validation loss: 1.7961310417421403

Epoch: 5| Step: 2
Training loss: 1.1238933801651
Validation loss: 1.768937772320163

Epoch: 5| Step: 3
Training loss: 1.2998700141906738
Validation loss: 1.8028030728781095

Epoch: 5| Step: 4
Training loss: 1.1334731578826904
Validation loss: 1.8145092354025891

Epoch: 5| Step: 5
Training loss: 1.2533141374588013
Validation loss: 1.7916075350135885

Epoch: 5| Step: 6
Training loss: 1.8559929132461548
Validation loss: 1.776617524444416

Epoch: 5| Step: 7
Training loss: 1.5010900497436523
Validation loss: 1.810585186045657

Epoch: 5| Step: 8
Training loss: 2.0394561290740967
Validation loss: 1.8047394649956816

Epoch: 5| Step: 9
Training loss: 1.971518874168396
Validation loss: 1.8133460103824575

Epoch: 5| Step: 10
Training loss: 1.751916766166687
Validation loss: 1.789030674965151

Epoch: 261| Step: 0
Training loss: 1.2069488763809204
Validation loss: 1.7783217942842873

Epoch: 5| Step: 1
Training loss: 1.3664324283599854
Validation loss: 1.8333177617801133

Epoch: 5| Step: 2
Training loss: 1.4858429431915283
Validation loss: 1.7603528871331164

Epoch: 5| Step: 3
Training loss: 1.6246417760849
Validation loss: 1.8394278454524216

Epoch: 5| Step: 4
Training loss: 1.7423105239868164
Validation loss: 1.8017322094209733

Epoch: 5| Step: 5
Training loss: 1.4175310134887695
Validation loss: 1.78075211791582

Epoch: 5| Step: 6
Training loss: 2.137322187423706
Validation loss: 1.7606320970801896

Epoch: 5| Step: 7
Training loss: 1.670405626296997
Validation loss: 1.8113002431008123

Epoch: 5| Step: 8
Training loss: 0.9719368815422058
Validation loss: 1.8005242347717285

Epoch: 5| Step: 9
Training loss: 1.6664466857910156
Validation loss: 1.8027529344763806

Epoch: 5| Step: 10
Training loss: 1.9016602039337158
Validation loss: 1.8630409189449844

Epoch: 262| Step: 0
Training loss: 1.733565330505371
Validation loss: 1.8294357356204782

Epoch: 5| Step: 1
Training loss: 0.7400034666061401
Validation loss: 1.8604322492435414

Epoch: 5| Step: 2
Training loss: 1.4575762748718262
Validation loss: 1.8226240270881242

Epoch: 5| Step: 3
Training loss: 1.5632919073104858
Validation loss: 1.8637752302231327

Epoch: 5| Step: 4
Training loss: 1.5526447296142578
Validation loss: 1.8822858077223583

Epoch: 5| Step: 5
Training loss: 2.060960292816162
Validation loss: 1.8301737539229854

Epoch: 5| Step: 6
Training loss: 1.6283611059188843
Validation loss: 1.8182948404742825

Epoch: 5| Step: 7
Training loss: 1.7121165990829468
Validation loss: 1.826708770567371

Epoch: 5| Step: 8
Training loss: 1.5678848028182983
Validation loss: 1.838949154782039

Epoch: 5| Step: 9
Training loss: 1.5908552408218384
Validation loss: 1.8500234183444773

Epoch: 5| Step: 10
Training loss: 1.5397073030471802
Validation loss: 1.803071351461513

Epoch: 263| Step: 0
Training loss: 1.6048040390014648
Validation loss: 1.8114135188441123

Epoch: 5| Step: 1
Training loss: 1.9277353286743164
Validation loss: 1.80924508776716

Epoch: 5| Step: 2
Training loss: 1.4246132373809814
Validation loss: 1.7971588668002878

Epoch: 5| Step: 3
Training loss: 1.3942452669143677
Validation loss: 1.7843972790625788

Epoch: 5| Step: 4
Training loss: 1.3998425006866455
Validation loss: 1.7782321911986156

Epoch: 5| Step: 5
Training loss: 1.3324801921844482
Validation loss: 1.8023525937911002

Epoch: 5| Step: 6
Training loss: 1.678283929824829
Validation loss: 1.8285255534674532

Epoch: 5| Step: 7
Training loss: 1.3740605115890503
Validation loss: 1.7901371396997923

Epoch: 5| Step: 8
Training loss: 1.7026922702789307
Validation loss: 1.8098433799641107

Epoch: 5| Step: 9
Training loss: 1.6745789051055908
Validation loss: 1.8235340195317422

Epoch: 5| Step: 10
Training loss: 1.6088534593582153
Validation loss: 1.8400367690670876

Epoch: 264| Step: 0
Training loss: 2.216911792755127
Validation loss: 1.8182942880097257

Epoch: 5| Step: 1
Training loss: 1.3608639240264893
Validation loss: 1.8208371746924616

Epoch: 5| Step: 2
Training loss: 1.2378699779510498
Validation loss: 1.826670636412918

Epoch: 5| Step: 3
Training loss: 1.533557653427124
Validation loss: 1.857418308975876

Epoch: 5| Step: 4
Training loss: 1.3130621910095215
Validation loss: 1.8511607134214012

Epoch: 5| Step: 5
Training loss: 0.9795845150947571
Validation loss: 1.8093224007596251

Epoch: 5| Step: 6
Training loss: 1.6485984325408936
Validation loss: 1.8194276261073288

Epoch: 5| Step: 7
Training loss: 1.5419212579727173
Validation loss: 1.8058341613379858

Epoch: 5| Step: 8
Training loss: 2.3424065113067627
Validation loss: 1.8196314547651558

Epoch: 5| Step: 9
Training loss: 1.4886105060577393
Validation loss: 1.814717056930706

Epoch: 5| Step: 10
Training loss: 1.3895498514175415
Validation loss: 1.7827956920029016

Epoch: 265| Step: 0
Training loss: 1.968105673789978
Validation loss: 1.7889034568622548

Epoch: 5| Step: 1
Training loss: 1.918283462524414
Validation loss: 1.8458727585372103

Epoch: 5| Step: 2
Training loss: 1.8519092798233032
Validation loss: 1.8019818887915662

Epoch: 5| Step: 3
Training loss: 0.9352433085441589
Validation loss: 1.8309717691072853

Epoch: 5| Step: 4
Training loss: 1.5246573686599731
Validation loss: 1.8157966188205186

Epoch: 5| Step: 5
Training loss: 1.0356179475784302
Validation loss: 1.8393903214444396

Epoch: 5| Step: 6
Training loss: 1.3698279857635498
Validation loss: 1.8070560898832095

Epoch: 5| Step: 7
Training loss: 1.254595398902893
Validation loss: 1.833393125123875

Epoch: 5| Step: 8
Training loss: 2.2587530612945557
Validation loss: 1.8083380396648119

Epoch: 5| Step: 9
Training loss: 1.3156611919403076
Validation loss: 1.8262514734780917

Epoch: 5| Step: 10
Training loss: 1.665889024734497
Validation loss: 1.8087077794536468

Epoch: 266| Step: 0
Training loss: 1.3687551021575928
Validation loss: 1.7878019707177275

Epoch: 5| Step: 1
Training loss: 1.9392890930175781
Validation loss: 1.8148087711744412

Epoch: 5| Step: 2
Training loss: 1.4871326684951782
Validation loss: 1.7940496180647163

Epoch: 5| Step: 3
Training loss: 2.036329984664917
Validation loss: 1.793387665543505

Epoch: 5| Step: 4
Training loss: 1.5835511684417725
Validation loss: 1.7835585417286042

Epoch: 5| Step: 5
Training loss: 1.619206190109253
Validation loss: 1.8060944041898173

Epoch: 5| Step: 6
Training loss: 1.134881854057312
Validation loss: 1.825255314509074

Epoch: 5| Step: 7
Training loss: 1.7426331043243408
Validation loss: 1.821363123514319

Epoch: 5| Step: 8
Training loss: 1.1121824979782104
Validation loss: 1.8346081984940397

Epoch: 5| Step: 9
Training loss: 1.5509859323501587
Validation loss: 1.8275980308491697

Epoch: 5| Step: 10
Training loss: 1.4105700254440308
Validation loss: 1.7972011181616014

Epoch: 267| Step: 0
Training loss: 1.2212889194488525
Validation loss: 1.7718762838712303

Epoch: 5| Step: 1
Training loss: 1.6131789684295654
Validation loss: 1.8289424744985436

Epoch: 5| Step: 2
Training loss: 1.749779462814331
Validation loss: 1.7868833682870353

Epoch: 5| Step: 3
Training loss: 1.395570158958435
Validation loss: 1.7801233209589475

Epoch: 5| Step: 4
Training loss: 1.305283546447754
Validation loss: 1.7581945644911898

Epoch: 5| Step: 5
Training loss: 1.3198630809783936
Validation loss: 1.7635551729509908

Epoch: 5| Step: 6
Training loss: 2.108747959136963
Validation loss: 1.7961184683666434

Epoch: 5| Step: 7
Training loss: 1.3515397310256958
Validation loss: 1.7691746104148127

Epoch: 5| Step: 8
Training loss: 1.4115626811981201
Validation loss: 1.797387581999584

Epoch: 5| Step: 9
Training loss: 1.8089908361434937
Validation loss: 1.7926272205127183

Epoch: 5| Step: 10
Training loss: 1.6747270822525024
Validation loss: 1.834097716116136

Epoch: 268| Step: 0
Training loss: 1.2865303754806519
Validation loss: 1.8312622411276704

Epoch: 5| Step: 1
Training loss: 2.021005630493164
Validation loss: 1.742565119138328

Epoch: 5| Step: 2
Training loss: 1.6651216745376587
Validation loss: 1.8025501543475735

Epoch: 5| Step: 3
Training loss: 0.9133729934692383
Validation loss: 1.7990074721715783

Epoch: 5| Step: 4
Training loss: 1.48926842212677
Validation loss: 1.865635528359362

Epoch: 5| Step: 5
Training loss: 1.938073754310608
Validation loss: 1.8346653497347267

Epoch: 5| Step: 6
Training loss: 1.389005184173584
Validation loss: 1.8750628156046714

Epoch: 5| Step: 7
Training loss: 1.7810680866241455
Validation loss: 1.813743015771271

Epoch: 5| Step: 8
Training loss: 1.3524606227874756
Validation loss: 1.8376361862305672

Epoch: 5| Step: 9
Training loss: 2.02628755569458
Validation loss: 1.8377964265884892

Epoch: 5| Step: 10
Training loss: 1.566888451576233
Validation loss: 1.8266701006120252

Epoch: 269| Step: 0
Training loss: 1.2280359268188477
Validation loss: 1.824421122509946

Epoch: 5| Step: 1
Training loss: 1.4812637567520142
Validation loss: 1.8160735355910433

Epoch: 5| Step: 2
Training loss: 1.4328421354293823
Validation loss: 1.818635256059708

Epoch: 5| Step: 3
Training loss: 1.7002079486846924
Validation loss: 1.83513847602311

Epoch: 5| Step: 4
Training loss: 1.7634849548339844
Validation loss: 1.8664020774185017

Epoch: 5| Step: 5
Training loss: 0.8672696948051453
Validation loss: 1.7997553040904384

Epoch: 5| Step: 6
Training loss: 1.2883775234222412
Validation loss: 1.7928817438822922

Epoch: 5| Step: 7
Training loss: 1.6642967462539673
Validation loss: 1.7732840584170433

Epoch: 5| Step: 8
Training loss: 1.7496541738510132
Validation loss: 1.8121879921164563

Epoch: 5| Step: 9
Training loss: 1.6071786880493164
Validation loss: 1.7778799738935245

Epoch: 5| Step: 10
Training loss: 2.252932071685791
Validation loss: 1.775269986480795

Epoch: 270| Step: 0
Training loss: 1.6502399444580078
Validation loss: 1.8056415139987905

Epoch: 5| Step: 1
Training loss: 0.9862887263298035
Validation loss: 1.7805838027308065

Epoch: 5| Step: 2
Training loss: 1.7374988794326782
Validation loss: 1.8194279721988145

Epoch: 5| Step: 3
Training loss: 1.5356628894805908
Validation loss: 1.8036802327761086

Epoch: 5| Step: 4
Training loss: 1.4969027042388916
Validation loss: 1.783552323618243

Epoch: 5| Step: 5
Training loss: 2.2666921615600586
Validation loss: 1.7760072472274944

Epoch: 5| Step: 6
Training loss: 1.611877202987671
Validation loss: 1.8108174518872333

Epoch: 5| Step: 7
Training loss: 1.161686658859253
Validation loss: 1.8132681500527166

Epoch: 5| Step: 8
Training loss: 1.5668964385986328
Validation loss: 1.808531157432064

Epoch: 5| Step: 9
Training loss: 1.5983717441558838
Validation loss: 1.8239796533379504

Epoch: 5| Step: 10
Training loss: 1.1489160060882568
Validation loss: 1.835681697373749

Epoch: 271| Step: 0
Training loss: 1.6474800109863281
Validation loss: 1.7970527756598689

Epoch: 5| Step: 1
Training loss: 1.7237075567245483
Validation loss: 1.8079240399022256

Epoch: 5| Step: 2
Training loss: 1.5933746099472046
Validation loss: 1.841867587899649

Epoch: 5| Step: 3
Training loss: 1.628485918045044
Validation loss: 1.786194255275111

Epoch: 5| Step: 4
Training loss: 1.4103854894638062
Validation loss: 1.772787445334978

Epoch: 5| Step: 5
Training loss: 1.8713849782943726
Validation loss: 1.8161543774348434

Epoch: 5| Step: 6
Training loss: 1.4760255813598633
Validation loss: 1.8280621472225393

Epoch: 5| Step: 7
Training loss: 1.2885023355484009
Validation loss: 1.8051845168554654

Epoch: 5| Step: 8
Training loss: 1.3283065557479858
Validation loss: 1.8273713204168505

Epoch: 5| Step: 9
Training loss: 1.3607165813446045
Validation loss: 1.8391995314628846

Epoch: 5| Step: 10
Training loss: 1.5929850339889526
Validation loss: 1.811303488669857

Epoch: 272| Step: 0
Training loss: 2.0145742893218994
Validation loss: 1.8451976327485935

Epoch: 5| Step: 1
Training loss: 1.4140371084213257
Validation loss: 1.8184745580919328

Epoch: 5| Step: 2
Training loss: 1.9813852310180664
Validation loss: 1.7888840372844408

Epoch: 5| Step: 3
Training loss: 1.4925546646118164
Validation loss: 1.7888512534479941

Epoch: 5| Step: 4
Training loss: 1.3738162517547607
Validation loss: 1.7836100657780964

Epoch: 5| Step: 5
Training loss: 1.7354786396026611
Validation loss: 1.8056267487105502

Epoch: 5| Step: 6
Training loss: 1.07142174243927
Validation loss: 1.818181667276608

Epoch: 5| Step: 7
Training loss: 1.3478524684906006
Validation loss: 1.7945365598124843

Epoch: 5| Step: 8
Training loss: 1.5191316604614258
Validation loss: 1.778134322935535

Epoch: 5| Step: 9
Training loss: 1.3292415142059326
Validation loss: 1.7763880439983901

Epoch: 5| Step: 10
Training loss: 1.7213996648788452
Validation loss: 1.7854535220771708

Epoch: 273| Step: 0
Training loss: 1.901071548461914
Validation loss: 1.7957381612511092

Epoch: 5| Step: 1
Training loss: 1.772655725479126
Validation loss: 1.8166771332422893

Epoch: 5| Step: 2
Training loss: 1.1130197048187256
Validation loss: 1.8323916466005388

Epoch: 5| Step: 3
Training loss: 1.1724517345428467
Validation loss: 1.8086527111709758

Epoch: 5| Step: 4
Training loss: 1.4859683513641357
Validation loss: 1.7727551844812208

Epoch: 5| Step: 5
Training loss: 2.0229995250701904
Validation loss: 1.7978558758253693

Epoch: 5| Step: 6
Training loss: 2.3198275566101074
Validation loss: 1.8191789670657086

Epoch: 5| Step: 7
Training loss: 0.8741995096206665
Validation loss: 1.8129593223653815

Epoch: 5| Step: 8
Training loss: 1.2463481426239014
Validation loss: 1.7916305885520032

Epoch: 5| Step: 9
Training loss: 1.6446340084075928
Validation loss: 1.7985912433234594

Epoch: 5| Step: 10
Training loss: 1.6237587928771973
Validation loss: 1.8810750079411331

Epoch: 274| Step: 0
Training loss: 0.8613707423210144
Validation loss: 1.8289608211927517

Epoch: 5| Step: 1
Training loss: 1.7953786849975586
Validation loss: 1.8037030594323271

Epoch: 5| Step: 2
Training loss: 1.3899383544921875
Validation loss: 1.7837694152708976

Epoch: 5| Step: 3
Training loss: 1.593725562095642
Validation loss: 1.8268059402383783

Epoch: 5| Step: 4
Training loss: 1.5490963459014893
Validation loss: 1.8215125555633216

Epoch: 5| Step: 5
Training loss: 1.785614252090454
Validation loss: 1.8007824574747393

Epoch: 5| Step: 6
Training loss: 1.1896467208862305
Validation loss: 1.8442117988422353

Epoch: 5| Step: 7
Training loss: 1.733464241027832
Validation loss: 1.7918935411719865

Epoch: 5| Step: 8
Training loss: 1.587550401687622
Validation loss: 1.7841059354043776

Epoch: 5| Step: 9
Training loss: 1.335240364074707
Validation loss: 1.8279340754273117

Epoch: 5| Step: 10
Training loss: 2.0388076305389404
Validation loss: 1.768770822914698

Epoch: 275| Step: 0
Training loss: 1.245764136314392
Validation loss: 1.780650374709919

Epoch: 5| Step: 1
Training loss: 1.2071651220321655
Validation loss: 1.7897817921894852

Epoch: 5| Step: 2
Training loss: 1.4544448852539062
Validation loss: 1.7692198625174902

Epoch: 5| Step: 3
Training loss: 1.6260124444961548
Validation loss: 1.7765648954658098

Epoch: 5| Step: 4
Training loss: 1.7179933786392212
Validation loss: 1.7700978453441332

Epoch: 5| Step: 5
Training loss: 1.5477573871612549
Validation loss: 1.7846149154888686

Epoch: 5| Step: 6
Training loss: 1.4023547172546387
Validation loss: 1.8159973121458484

Epoch: 5| Step: 7
Training loss: 1.7683265209197998
Validation loss: 1.8155762918533818

Epoch: 5| Step: 8
Training loss: 1.2344133853912354
Validation loss: 1.7749431876726047

Epoch: 5| Step: 9
Training loss: 1.9003204107284546
Validation loss: 1.8543331123167468

Epoch: 5| Step: 10
Training loss: 1.5710296630859375
Validation loss: 1.8078546216410976

Epoch: 276| Step: 0
Training loss: 1.3591991662979126
Validation loss: 1.7818574315758162

Epoch: 5| Step: 1
Training loss: 2.0766348838806152
Validation loss: 1.8320767687213035

Epoch: 5| Step: 2
Training loss: 1.9839404821395874
Validation loss: 1.8361415247763357

Epoch: 5| Step: 3
Training loss: 1.8523403406143188
Validation loss: 1.8290906054999239

Epoch: 5| Step: 4
Training loss: 1.0452505350112915
Validation loss: 1.7907956864244194

Epoch: 5| Step: 5
Training loss: 1.6630289554595947
Validation loss: 1.8120922209114156

Epoch: 5| Step: 6
Training loss: 1.4319562911987305
Validation loss: 1.8510120158554406

Epoch: 5| Step: 7
Training loss: 1.5196431875228882
Validation loss: 1.7770905263962284

Epoch: 5| Step: 8
Training loss: 1.1133382320404053
Validation loss: 1.8268911684713056

Epoch: 5| Step: 9
Training loss: 1.2433650493621826
Validation loss: 1.83928434823149

Epoch: 5| Step: 10
Training loss: 1.4107346534729004
Validation loss: 1.8397219360515635

Epoch: 277| Step: 0
Training loss: 1.54655122756958
Validation loss: 1.8541138428513722

Epoch: 5| Step: 1
Training loss: 1.1075314283370972
Validation loss: 1.814433523403701

Epoch: 5| Step: 2
Training loss: 0.8949674367904663
Validation loss: 1.8077659453115156

Epoch: 5| Step: 3
Training loss: 1.489877462387085
Validation loss: 1.7831578536700177

Epoch: 5| Step: 4
Training loss: 1.2924220561981201
Validation loss: 1.818913951996834

Epoch: 5| Step: 5
Training loss: 2.1164727210998535
Validation loss: 1.829973328498102

Epoch: 5| Step: 6
Training loss: 1.2875158786773682
Validation loss: 1.7882021396390853

Epoch: 5| Step: 7
Training loss: 2.1877477169036865
Validation loss: 1.8045389447160947

Epoch: 5| Step: 8
Training loss: 1.4331541061401367
Validation loss: 1.8121207132134387

Epoch: 5| Step: 9
Training loss: 1.49452805519104
Validation loss: 1.8442427240392214

Epoch: 5| Step: 10
Training loss: 1.8194057941436768
Validation loss: 1.8380687211149482

Epoch: 278| Step: 0
Training loss: 1.4854631423950195
Validation loss: 1.7810059837115708

Epoch: 5| Step: 1
Training loss: 1.5159343481063843
Validation loss: 1.8037666813019784

Epoch: 5| Step: 2
Training loss: 1.2913974523544312
Validation loss: 1.8318905010018298

Epoch: 5| Step: 3
Training loss: 1.343100666999817
Validation loss: 1.7637435992558796

Epoch: 5| Step: 4
Training loss: 2.4172518253326416
Validation loss: 1.815101844008251

Epoch: 5| Step: 5
Training loss: 1.6280078887939453
Validation loss: 1.789336673675045

Epoch: 5| Step: 6
Training loss: 1.3919020891189575
Validation loss: 1.8311340039776218

Epoch: 5| Step: 7
Training loss: 1.073169469833374
Validation loss: 1.8073540400433283

Epoch: 5| Step: 8
Training loss: 1.4217958450317383
Validation loss: 1.796004226130824

Epoch: 5| Step: 9
Training loss: 1.5751779079437256
Validation loss: 1.763466840149254

Epoch: 5| Step: 10
Training loss: 1.2725131511688232
Validation loss: 1.7651467310485018

Epoch: 279| Step: 0
Training loss: 1.5414832830429077
Validation loss: 1.8252886469646166

Epoch: 5| Step: 1
Training loss: 1.5413410663604736
Validation loss: 1.7851080663742558

Epoch: 5| Step: 2
Training loss: 1.2797826528549194
Validation loss: 1.8232563605872534

Epoch: 5| Step: 3
Training loss: 2.004534959793091
Validation loss: 1.7645463430753319

Epoch: 5| Step: 4
Training loss: 1.0776169300079346
Validation loss: 1.8181016265705068

Epoch: 5| Step: 5
Training loss: 1.4131089448928833
Validation loss: 1.8199539594752814

Epoch: 5| Step: 6
Training loss: 1.516431212425232
Validation loss: 1.7977871407744705

Epoch: 5| Step: 7
Training loss: 1.979138970375061
Validation loss: 1.798039984959428

Epoch: 5| Step: 8
Training loss: 1.4721084833145142
Validation loss: 1.8289264786627986

Epoch: 5| Step: 9
Training loss: 1.314854383468628
Validation loss: 1.804093240409769

Epoch: 5| Step: 10
Training loss: 1.431964635848999
Validation loss: 1.7853668171872374

Epoch: 280| Step: 0
Training loss: 2.165130138397217
Validation loss: 1.7970470331048454

Epoch: 5| Step: 1
Training loss: 1.5448815822601318
Validation loss: 1.8087389469146729

Epoch: 5| Step: 2
Training loss: 1.4181324243545532
Validation loss: 1.8095139918788787

Epoch: 5| Step: 3
Training loss: 1.6273460388183594
Validation loss: 1.7829234651339951

Epoch: 5| Step: 4
Training loss: 1.4460086822509766
Validation loss: 1.8403373918225687

Epoch: 5| Step: 5
Training loss: 0.8728321194648743
Validation loss: 1.786814207671791

Epoch: 5| Step: 6
Training loss: 2.3324334621429443
Validation loss: 1.8212459241190264

Epoch: 5| Step: 7
Training loss: 1.5645397901535034
Validation loss: 1.8088723395460395

Epoch: 5| Step: 8
Training loss: 1.2918739318847656
Validation loss: 1.7972165487145866

Epoch: 5| Step: 9
Training loss: 0.9635050892829895
Validation loss: 1.8043051637629026

Epoch: 5| Step: 10
Training loss: 1.1230050325393677
Validation loss: 1.8038701972653788

Epoch: 281| Step: 0
Training loss: 1.7248239517211914
Validation loss: 1.8309387904341503

Epoch: 5| Step: 1
Training loss: 1.5484657287597656
Validation loss: 1.850347424066195

Epoch: 5| Step: 2
Training loss: 0.9476748704910278
Validation loss: 1.8590603233665548

Epoch: 5| Step: 3
Training loss: 1.7956809997558594
Validation loss: 1.8587710729209326

Epoch: 5| Step: 4
Training loss: 1.957309365272522
Validation loss: 1.7951144146662887

Epoch: 5| Step: 5
Training loss: 1.3867552280426025
Validation loss: 1.8143010113828926

Epoch: 5| Step: 6
Training loss: 1.438988447189331
Validation loss: 1.8476642741951892

Epoch: 5| Step: 7
Training loss: 1.7668861150741577
Validation loss: 1.8378180534608903

Epoch: 5| Step: 8
Training loss: 1.5513813495635986
Validation loss: 1.8555149442406111

Epoch: 5| Step: 9
Training loss: 1.5206314325332642
Validation loss: 1.8313217791177894

Epoch: 5| Step: 10
Training loss: 1.0066378116607666
Validation loss: 1.8060617241808163

Epoch: 282| Step: 0
Training loss: 0.9937092065811157
Validation loss: 1.8088101135787142

Epoch: 5| Step: 1
Training loss: 1.8343982696533203
Validation loss: 1.7748888333638508

Epoch: 5| Step: 2
Training loss: 1.15476393699646
Validation loss: 1.773288942152454

Epoch: 5| Step: 3
Training loss: 1.8101098537445068
Validation loss: 1.802395829590418

Epoch: 5| Step: 4
Training loss: 0.8858007192611694
Validation loss: 1.776745770567207

Epoch: 5| Step: 5
Training loss: 1.3785290718078613
Validation loss: 1.7938447485687912

Epoch: 5| Step: 6
Training loss: 1.800715446472168
Validation loss: 1.8200125668638496

Epoch: 5| Step: 7
Training loss: 1.9885585308074951
Validation loss: 1.8160180558440506

Epoch: 5| Step: 8
Training loss: 1.9991912841796875
Validation loss: 1.795790683838629

Epoch: 5| Step: 9
Training loss: 1.5812861919403076
Validation loss: 1.839533677665136

Epoch: 5| Step: 10
Training loss: 1.3387806415557861
Validation loss: 1.782412382864183

Epoch: 283| Step: 0
Training loss: 1.9097235202789307
Validation loss: 1.7779937739013343

Epoch: 5| Step: 1
Training loss: 1.5459932088851929
Validation loss: 1.7876421379786667

Epoch: 5| Step: 2
Training loss: 2.074420213699341
Validation loss: 1.8108989961685673

Epoch: 5| Step: 3
Training loss: 1.6755155324935913
Validation loss: 1.839740858283094

Epoch: 5| Step: 4
Training loss: 1.5995264053344727
Validation loss: 1.791101142924319

Epoch: 5| Step: 5
Training loss: 1.4144103527069092
Validation loss: 1.8234635578688754

Epoch: 5| Step: 6
Training loss: 1.0802851915359497
Validation loss: 1.8164149227962698

Epoch: 5| Step: 7
Training loss: 1.268111228942871
Validation loss: 1.8413277338909846

Epoch: 5| Step: 8
Training loss: 1.4983437061309814
Validation loss: 1.8229332380397345

Epoch: 5| Step: 9
Training loss: 1.0112674236297607
Validation loss: 1.7980954057426863

Epoch: 5| Step: 10
Training loss: 1.6813946962356567
Validation loss: 1.8328866317708006

Epoch: 284| Step: 0
Training loss: 1.6655324697494507
Validation loss: 1.8153139698889948

Epoch: 5| Step: 1
Training loss: 1.8353315591812134
Validation loss: 1.8358376667063723

Epoch: 5| Step: 2
Training loss: 1.667288064956665
Validation loss: 1.8349817081164288

Epoch: 5| Step: 3
Training loss: 1.6117416620254517
Validation loss: 1.8504316114610242

Epoch: 5| Step: 4
Training loss: 1.5058536529541016
Validation loss: 1.7818354457937262

Epoch: 5| Step: 5
Training loss: 1.1064430475234985
Validation loss: 1.82476806640625

Epoch: 5| Step: 6
Training loss: 1.7807061672210693
Validation loss: 1.7917898675446868

Epoch: 5| Step: 7
Training loss: 1.614376425743103
Validation loss: 1.8098322447910105

Epoch: 5| Step: 8
Training loss: 1.2132201194763184
Validation loss: 1.798940239414092

Epoch: 5| Step: 9
Training loss: 0.8290086984634399
Validation loss: 1.7750210223659393

Epoch: 5| Step: 10
Training loss: 1.8067781925201416
Validation loss: 1.799003170382592

Epoch: 285| Step: 0
Training loss: 1.5058603286743164
Validation loss: 1.8190357313361218

Epoch: 5| Step: 1
Training loss: 0.9637079238891602
Validation loss: 1.7921182417100476

Epoch: 5| Step: 2
Training loss: 1.2874854803085327
Validation loss: 1.7774890110056887

Epoch: 5| Step: 3
Training loss: 1.4187228679656982
Validation loss: 1.8223217072025422

Epoch: 5| Step: 4
Training loss: 1.3185663223266602
Validation loss: 1.7955332263823478

Epoch: 5| Step: 5
Training loss: 2.3143229484558105
Validation loss: 1.7962608029765468

Epoch: 5| Step: 6
Training loss: 1.3298015594482422
Validation loss: 1.7817986575506066

Epoch: 5| Step: 7
Training loss: 1.3522999286651611
Validation loss: 1.826413700657506

Epoch: 5| Step: 8
Training loss: 1.4728786945343018
Validation loss: 1.800560002685875

Epoch: 5| Step: 9
Training loss: 1.9131548404693604
Validation loss: 1.8483588105888777

Epoch: 5| Step: 10
Training loss: 1.2595058679580688
Validation loss: 1.7992186200234197

Epoch: 286| Step: 0
Training loss: 1.3309297561645508
Validation loss: 1.805118017299201

Epoch: 5| Step: 1
Training loss: 1.3118951320648193
Validation loss: 1.8115680448470577

Epoch: 5| Step: 2
Training loss: 1.9715080261230469
Validation loss: 1.8348150830115042

Epoch: 5| Step: 3
Training loss: 0.8658220171928406
Validation loss: 1.7811126093710623

Epoch: 5| Step: 4
Training loss: 1.3658881187438965
Validation loss: 1.7680143694723807

Epoch: 5| Step: 5
Training loss: 1.3381298780441284
Validation loss: 1.8013667701393046

Epoch: 5| Step: 6
Training loss: 1.6073287725448608
Validation loss: 1.7920513845259143

Epoch: 5| Step: 7
Training loss: 2.2226626873016357
Validation loss: 1.8379948985192083

Epoch: 5| Step: 8
Training loss: 1.2786152362823486
Validation loss: 1.7926764783038889

Epoch: 5| Step: 9
Training loss: 0.9496381878852844
Validation loss: 1.8319973304707518

Epoch: 5| Step: 10
Training loss: 2.2912120819091797
Validation loss: 1.7932378758666336

Epoch: 287| Step: 0
Training loss: 1.1649967432022095
Validation loss: 1.7760821439886605

Epoch: 5| Step: 1
Training loss: 2.0597527027130127
Validation loss: 1.813070278013906

Epoch: 5| Step: 2
Training loss: 1.4076120853424072
Validation loss: 1.798197566822011

Epoch: 5| Step: 3
Training loss: 1.4553956985473633
Validation loss: 1.7640802962805635

Epoch: 5| Step: 4
Training loss: 1.5540262460708618
Validation loss: 1.7867867792806318

Epoch: 5| Step: 5
Training loss: 1.3921817541122437
Validation loss: 1.8533011162152855

Epoch: 5| Step: 6
Training loss: 1.4500833749771118
Validation loss: 1.830136965679866

Epoch: 5| Step: 7
Training loss: 1.3343732357025146
Validation loss: 1.8096041717836935

Epoch: 5| Step: 8
Training loss: 1.1225935220718384
Validation loss: 1.8346664431274577

Epoch: 5| Step: 9
Training loss: 1.9624223709106445
Validation loss: 1.7866439883426954

Epoch: 5| Step: 10
Training loss: 1.2310377359390259
Validation loss: 1.8312898899919243

Epoch: 288| Step: 0
Training loss: 1.692983627319336
Validation loss: 1.863788050989951

Epoch: 5| Step: 1
Training loss: 1.213675856590271
Validation loss: 1.8064912544783724

Epoch: 5| Step: 2
Training loss: 1.0213905572891235
Validation loss: 1.7795251479712866

Epoch: 5| Step: 3
Training loss: 1.6708818674087524
Validation loss: 1.8040734580768052

Epoch: 5| Step: 4
Training loss: 1.1755831241607666
Validation loss: 1.7896358582281298

Epoch: 5| Step: 5
Training loss: 1.4372432231903076
Validation loss: 1.8175972674482612

Epoch: 5| Step: 6
Training loss: 1.3735601902008057
Validation loss: 1.8111464092808385

Epoch: 5| Step: 7
Training loss: 1.655198335647583
Validation loss: 1.8319582285419587

Epoch: 5| Step: 8
Training loss: 1.818280816078186
Validation loss: 1.7553113275958645

Epoch: 5| Step: 9
Training loss: 1.2047439813613892
Validation loss: 1.817468463733632

Epoch: 5| Step: 10
Training loss: 2.3042352199554443
Validation loss: 1.8260469116190428

Epoch: 289| Step: 0
Training loss: 1.3948090076446533
Validation loss: 1.8226098847645584

Epoch: 5| Step: 1
Training loss: 0.7734240293502808
Validation loss: 1.8140625338400564

Epoch: 5| Step: 2
Training loss: 1.516693353652954
Validation loss: 1.809682922978555

Epoch: 5| Step: 3
Training loss: 1.0352263450622559
Validation loss: 1.8553625768230808

Epoch: 5| Step: 4
Training loss: 1.4167035818099976
Validation loss: 1.831145135305261

Epoch: 5| Step: 5
Training loss: 0.9863625764846802
Validation loss: 1.8270343042189074

Epoch: 5| Step: 6
Training loss: 2.137005090713501
Validation loss: 1.8359019243589012

Epoch: 5| Step: 7
Training loss: 1.915670394897461
Validation loss: 1.8107537454174412

Epoch: 5| Step: 8
Training loss: 1.7200758457183838
Validation loss: 1.8158036431958597

Epoch: 5| Step: 9
Training loss: 1.890324592590332
Validation loss: 1.7726238389169016

Epoch: 5| Step: 10
Training loss: 1.6299632787704468
Validation loss: 1.8249702338249452

Epoch: 290| Step: 0
Training loss: 0.9661590456962585
Validation loss: 1.8080504863492903

Epoch: 5| Step: 1
Training loss: 1.6762797832489014
Validation loss: 1.811711044721706

Epoch: 5| Step: 2
Training loss: 1.2885102033615112
Validation loss: 1.8023119421415432

Epoch: 5| Step: 3
Training loss: 1.4775495529174805
Validation loss: 1.82782543090082

Epoch: 5| Step: 4
Training loss: 0.9317073822021484
Validation loss: 1.7814357383276826

Epoch: 5| Step: 5
Training loss: 1.6300255060195923
Validation loss: 1.8231062120006931

Epoch: 5| Step: 6
Training loss: 1.7128114700317383
Validation loss: 1.7784225094702937

Epoch: 5| Step: 7
Training loss: 1.6282455921173096
Validation loss: 1.8160530296705102

Epoch: 5| Step: 8
Training loss: 1.7186180353164673
Validation loss: 1.7973566465480353

Epoch: 5| Step: 9
Training loss: 1.3116235733032227
Validation loss: 1.8286309396066973

Epoch: 5| Step: 10
Training loss: 2.0909764766693115
Validation loss: 1.8303307217936362

Epoch: 291| Step: 0
Training loss: 1.4764044284820557
Validation loss: 1.83204480396804

Epoch: 5| Step: 1
Training loss: 0.9897392988204956
Validation loss: 1.774806482817537

Epoch: 5| Step: 2
Training loss: 1.2307806015014648
Validation loss: 1.8085265621062248

Epoch: 5| Step: 3
Training loss: 1.5913851261138916
Validation loss: 1.8083002144290554

Epoch: 5| Step: 4
Training loss: 1.141548752784729
Validation loss: 1.8426539795373076

Epoch: 5| Step: 5
Training loss: 1.5005316734313965
Validation loss: 1.8572964463182675

Epoch: 5| Step: 6
Training loss: 2.0122532844543457
Validation loss: 1.8337824472817041

Epoch: 5| Step: 7
Training loss: 1.8330425024032593
Validation loss: 1.8139763250145862

Epoch: 5| Step: 8
Training loss: 1.384491205215454
Validation loss: 1.780711927080667

Epoch: 5| Step: 9
Training loss: 1.6959998607635498
Validation loss: 1.7956020729516142

Epoch: 5| Step: 10
Training loss: 1.406988263130188
Validation loss: 1.8059325064382246

Epoch: 292| Step: 0
Training loss: 1.7415802478790283
Validation loss: 1.8008402470619447

Epoch: 5| Step: 1
Training loss: 1.432133674621582
Validation loss: 1.7801935736851027

Epoch: 5| Step: 2
Training loss: 1.9702688455581665
Validation loss: 1.7842147504129717

Epoch: 5| Step: 3
Training loss: 1.463212490081787
Validation loss: 1.7651073304555749

Epoch: 5| Step: 4
Training loss: 1.8968299627304077
Validation loss: 1.795595033194429

Epoch: 5| Step: 5
Training loss: 1.267111897468567
Validation loss: 1.7898945372591737

Epoch: 5| Step: 6
Training loss: 1.3567787408828735
Validation loss: 1.8105325173306208

Epoch: 5| Step: 7
Training loss: 1.0950875282287598
Validation loss: 1.8002973269390803

Epoch: 5| Step: 8
Training loss: 1.4027330875396729
Validation loss: 1.788047517499616

Epoch: 5| Step: 9
Training loss: 1.3390520811080933
Validation loss: 1.810230952437206

Epoch: 5| Step: 10
Training loss: 1.326143503189087
Validation loss: 1.7864466341592933

Epoch: 293| Step: 0
Training loss: 1.660865068435669
Validation loss: 1.8617345376681256

Epoch: 5| Step: 1
Training loss: 1.5656685829162598
Validation loss: 1.8425525055136731

Epoch: 5| Step: 2
Training loss: 1.0950493812561035
Validation loss: 1.8851188049521497

Epoch: 5| Step: 3
Training loss: 1.5470688343048096
Validation loss: 1.8567152843680432

Epoch: 5| Step: 4
Training loss: 1.821249008178711
Validation loss: 1.789063851038615

Epoch: 5| Step: 5
Training loss: 1.8315536975860596
Validation loss: 1.8340121956281765

Epoch: 5| Step: 6
Training loss: 1.23135507106781
Validation loss: 1.829316472494474

Epoch: 5| Step: 7
Training loss: 1.743172287940979
Validation loss: 1.823999817653369

Epoch: 5| Step: 8
Training loss: 0.8774803280830383
Validation loss: 1.8268219488923267

Epoch: 5| Step: 9
Training loss: 1.2132512331008911
Validation loss: 1.7901051646919661

Epoch: 5| Step: 10
Training loss: 1.327858328819275
Validation loss: 1.793958830577071

Epoch: 294| Step: 0
Training loss: 0.9942666292190552
Validation loss: 1.8103133875836608

Epoch: 5| Step: 1
Training loss: 1.4569933414459229
Validation loss: 1.8358019167377102

Epoch: 5| Step: 2
Training loss: 1.9939534664154053
Validation loss: 1.7800567278297998

Epoch: 5| Step: 3
Training loss: 1.2795339822769165
Validation loss: 1.7466213408336844

Epoch: 5| Step: 4
Training loss: 1.5025079250335693
Validation loss: 1.8059668002590057

Epoch: 5| Step: 5
Training loss: 1.251359224319458
Validation loss: 1.7768326023573517

Epoch: 5| Step: 6
Training loss: 1.6197181940078735
Validation loss: 1.7858880642921693

Epoch: 5| Step: 7
Training loss: 1.417062520980835
Validation loss: 1.812046343280423

Epoch: 5| Step: 8
Training loss: 1.328733205795288
Validation loss: 1.8522468664312874

Epoch: 5| Step: 9
Training loss: 1.6738322973251343
Validation loss: 1.870390308800564

Epoch: 5| Step: 10
Training loss: 1.6575604677200317
Validation loss: 1.7693681152918006

Epoch: 295| Step: 0
Training loss: 0.8733137249946594
Validation loss: 1.8366116067414642

Epoch: 5| Step: 1
Training loss: 1.6133778095245361
Validation loss: 1.868861318916403

Epoch: 5| Step: 2
Training loss: 1.637203574180603
Validation loss: 1.8138979929749683

Epoch: 5| Step: 3
Training loss: 1.7857093811035156
Validation loss: 1.7963044938220774

Epoch: 5| Step: 4
Training loss: 1.4521623849868774
Validation loss: 1.8412065044526131

Epoch: 5| Step: 5
Training loss: 1.689054250717163
Validation loss: 1.8408688345263082

Epoch: 5| Step: 6
Training loss: 1.684435486793518
Validation loss: 1.8462937519114504

Epoch: 5| Step: 7
Training loss: 1.5469928979873657
Validation loss: 1.8086055709469704

Epoch: 5| Step: 8
Training loss: 1.3348095417022705
Validation loss: 1.8132135919345322

Epoch: 5| Step: 9
Training loss: 1.1669683456420898
Validation loss: 1.8064210145704207

Epoch: 5| Step: 10
Training loss: 1.6631571054458618
Validation loss: 1.832961965632695

Epoch: 296| Step: 0
Training loss: 1.4653297662734985
Validation loss: 1.7856465795988679

Epoch: 5| Step: 1
Training loss: 1.8400837182998657
Validation loss: 1.819516046072847

Epoch: 5| Step: 2
Training loss: 1.3014854192733765
Validation loss: 1.8184720598241335

Epoch: 5| Step: 3
Training loss: 1.6479301452636719
Validation loss: 1.7853321875295332

Epoch: 5| Step: 4
Training loss: 1.854750633239746
Validation loss: 1.8081976982855028

Epoch: 5| Step: 5
Training loss: 1.4003534317016602
Validation loss: 1.819345078160686

Epoch: 5| Step: 6
Training loss: 1.2642014026641846
Validation loss: 1.7784260421670892

Epoch: 5| Step: 7
Training loss: 1.502719521522522
Validation loss: 1.7856027233985163

Epoch: 5| Step: 8
Training loss: 1.228780746459961
Validation loss: 1.7980698539364723

Epoch: 5| Step: 9
Training loss: 1.0876823663711548
Validation loss: 1.81882341190051

Epoch: 5| Step: 10
Training loss: 1.7488092184066772
Validation loss: 1.8038171529769897

Epoch: 297| Step: 0
Training loss: 1.0273568630218506
Validation loss: 1.7861942539932907

Epoch: 5| Step: 1
Training loss: 1.60346257686615
Validation loss: 1.7779650072897635

Epoch: 5| Step: 2
Training loss: 1.4281623363494873
Validation loss: 1.8172686561461417

Epoch: 5| Step: 3
Training loss: 1.6170189380645752
Validation loss: 1.792954114175612

Epoch: 5| Step: 4
Training loss: 1.5325238704681396
Validation loss: 1.7683532776371125

Epoch: 5| Step: 5
Training loss: 1.7182514667510986
Validation loss: 1.776874401236093

Epoch: 5| Step: 6
Training loss: 1.4367867708206177
Validation loss: 1.7965404577152704

Epoch: 5| Step: 7
Training loss: 1.366921305656433
Validation loss: 1.8532108786285564

Epoch: 5| Step: 8
Training loss: 1.373909831047058
Validation loss: 1.8231275825090305

Epoch: 5| Step: 9
Training loss: 1.5620014667510986
Validation loss: 1.7549056212107341

Epoch: 5| Step: 10
Training loss: 1.4660698175430298
Validation loss: 1.7886882994764595

Epoch: 298| Step: 0
Training loss: 1.6160036325454712
Validation loss: 1.8077740002703924

Epoch: 5| Step: 1
Training loss: 1.9772272109985352
Validation loss: 1.7629921103036532

Epoch: 5| Step: 2
Training loss: 1.3103095293045044
Validation loss: 1.8301656938368274

Epoch: 5| Step: 3
Training loss: 1.5080595016479492
Validation loss: 1.8052608274644422

Epoch: 5| Step: 4
Training loss: 1.8587729930877686
Validation loss: 1.7945918601046327

Epoch: 5| Step: 5
Training loss: 1.3033111095428467
Validation loss: 1.8316612705107658

Epoch: 5| Step: 6
Training loss: 1.5721689462661743
Validation loss: 1.7870604812457997

Epoch: 5| Step: 7
Training loss: 0.8096294403076172
Validation loss: 1.8241795314255582

Epoch: 5| Step: 8
Training loss: 1.5478463172912598
Validation loss: 1.7644697620022682

Epoch: 5| Step: 9
Training loss: 1.5067551136016846
Validation loss: 1.810661781218744

Epoch: 5| Step: 10
Training loss: 0.939816951751709
Validation loss: 1.8318198432204544

Epoch: 299| Step: 0
Training loss: 1.4964760541915894
Validation loss: 1.8213733434677124

Epoch: 5| Step: 1
Training loss: 1.0873510837554932
Validation loss: 1.7628853013438563

Epoch: 5| Step: 2
Training loss: 1.1008228063583374
Validation loss: 1.8256827169849026

Epoch: 5| Step: 3
Training loss: 1.4705430269241333
Validation loss: 1.772091551493573

Epoch: 5| Step: 4
Training loss: 1.4355429410934448
Validation loss: 1.7859659502583165

Epoch: 5| Step: 5
Training loss: 1.5650171041488647
Validation loss: 1.8129931854945358

Epoch: 5| Step: 6
Training loss: 1.420855164527893
Validation loss: 1.8481433519753077

Epoch: 5| Step: 7
Training loss: 1.7793986797332764
Validation loss: 1.8151864492765037

Epoch: 5| Step: 8
Training loss: 1.656172513961792
Validation loss: 1.797369889033738

Epoch: 5| Step: 9
Training loss: 1.3128570318222046
Validation loss: 1.8160474890021867

Epoch: 5| Step: 10
Training loss: 1.405341386795044
Validation loss: 1.8037043771436136

Epoch: 300| Step: 0
Training loss: 1.3679232597351074
Validation loss: 1.7798874378204346

Epoch: 5| Step: 1
Training loss: 1.9993565082550049
Validation loss: 1.8201749940072336

Epoch: 5| Step: 2
Training loss: 1.3820946216583252
Validation loss: 1.821838645524876

Epoch: 5| Step: 3
Training loss: 0.8932442665100098
Validation loss: 1.8069250570830477

Epoch: 5| Step: 4
Training loss: 1.318143606185913
Validation loss: 1.8543488107701784

Epoch: 5| Step: 5
Training loss: 1.3729166984558105
Validation loss: 1.8160218731049569

Epoch: 5| Step: 6
Training loss: 1.488755464553833
Validation loss: 1.8363080101628457

Epoch: 5| Step: 7
Training loss: 1.8462202548980713
Validation loss: 1.8625454787285096

Epoch: 5| Step: 8
Training loss: 0.936687171459198
Validation loss: 1.767312006283832

Epoch: 5| Step: 9
Training loss: 1.7071897983551025
Validation loss: 1.8567596955965924

Epoch: 5| Step: 10
Training loss: 1.7871443033218384
Validation loss: 1.8125973773258988

Epoch: 301| Step: 0
Training loss: 0.9617248773574829
Validation loss: 1.8270213873155656

Epoch: 5| Step: 1
Training loss: 1.2916195392608643
Validation loss: 1.7895109525290869

Epoch: 5| Step: 2
Training loss: 1.703743577003479
Validation loss: 1.7793329966965543

Epoch: 5| Step: 3
Training loss: 1.3786818981170654
Validation loss: 1.774314857298328

Epoch: 5| Step: 4
Training loss: 1.2584477663040161
Validation loss: 1.8010902763694845

Epoch: 5| Step: 5
Training loss: 1.2682139873504639
Validation loss: 1.7794444048276512

Epoch: 5| Step: 6
Training loss: 1.6547019481658936
Validation loss: 1.8043982803180654

Epoch: 5| Step: 7
Training loss: 2.2469370365142822
Validation loss: 1.797308696213589

Epoch: 5| Step: 8
Training loss: 1.6247116327285767
Validation loss: 1.7893293416628273

Epoch: 5| Step: 9
Training loss: 1.165258526802063
Validation loss: 1.7772689583480998

Epoch: 5| Step: 10
Training loss: 1.5499796867370605
Validation loss: 1.7866052222508255

Epoch: 302| Step: 0
Training loss: 1.2434214353561401
Validation loss: 1.7742111811073877

Epoch: 5| Step: 1
Training loss: 1.554831862449646
Validation loss: 1.8118810653686523

Epoch: 5| Step: 2
Training loss: 1.7002607583999634
Validation loss: 1.7936658064524333

Epoch: 5| Step: 3
Training loss: 1.215502381324768
Validation loss: 1.7979807751153105

Epoch: 5| Step: 4
Training loss: 1.3818690776824951
Validation loss: 1.7925511483223207

Epoch: 5| Step: 5
Training loss: 1.1235527992248535
Validation loss: 1.7836673528917375

Epoch: 5| Step: 6
Training loss: 1.6092411279678345
Validation loss: 1.8167716969725907

Epoch: 5| Step: 7
Training loss: 1.598393201828003
Validation loss: 1.7903868485522527

Epoch: 5| Step: 8
Training loss: 1.210864782333374
Validation loss: 1.7909953607025968

Epoch: 5| Step: 9
Training loss: 1.4508737325668335
Validation loss: 1.832451702446066

Epoch: 5| Step: 10
Training loss: 1.6803267002105713
Validation loss: 1.7695138877437961

Epoch: 303| Step: 0
Training loss: 1.5694154500961304
Validation loss: 1.7964397617565688

Epoch: 5| Step: 1
Training loss: 1.5862658023834229
Validation loss: 1.8294141318208428

Epoch: 5| Step: 2
Training loss: 1.2774198055267334
Validation loss: 1.7615964438325615

Epoch: 5| Step: 3
Training loss: 1.6709697246551514
Validation loss: 1.838659317262711

Epoch: 5| Step: 4
Training loss: 1.364830732345581
Validation loss: 1.8019539668995848

Epoch: 5| Step: 5
Training loss: 1.477203607559204
Validation loss: 1.8523816331740348

Epoch: 5| Step: 6
Training loss: 1.2547352313995361
Validation loss: 1.7959401966423116

Epoch: 5| Step: 7
Training loss: 1.2620989084243774
Validation loss: 1.765418747419952

Epoch: 5| Step: 8
Training loss: 1.6921837329864502
Validation loss: 1.807668077048435

Epoch: 5| Step: 9
Training loss: 1.0856767892837524
Validation loss: 1.8397516307010446

Epoch: 5| Step: 10
Training loss: 1.7635934352874756
Validation loss: 1.80344348056342

Epoch: 304| Step: 0
Training loss: 1.3902950286865234
Validation loss: 1.84081123593033

Epoch: 5| Step: 1
Training loss: 1.2098360061645508
Validation loss: 1.8018917255504157

Epoch: 5| Step: 2
Training loss: 1.149060606956482
Validation loss: 1.8145174134162165

Epoch: 5| Step: 3
Training loss: 2.129331111907959
Validation loss: 1.8031065182019306

Epoch: 5| Step: 4
Training loss: 1.1882091760635376
Validation loss: 1.7830522829486477

Epoch: 5| Step: 5
Training loss: 1.3996760845184326
Validation loss: 1.8000797417856031

Epoch: 5| Step: 6
Training loss: 1.255402684211731
Validation loss: 1.7478980402792654

Epoch: 5| Step: 7
Training loss: 1.4633392095565796
Validation loss: 1.8061073544204875

Epoch: 5| Step: 8
Training loss: 2.0084424018859863
Validation loss: 1.8177040392352688

Epoch: 5| Step: 9
Training loss: 1.0866587162017822
Validation loss: 1.7804894831872755

Epoch: 5| Step: 10
Training loss: 1.556572437286377
Validation loss: 1.8133301094014158

Epoch: 305| Step: 0
Training loss: 1.0201427936553955
Validation loss: 1.7919017730220672

Epoch: 5| Step: 1
Training loss: 1.1628859043121338
Validation loss: 1.8210228040654173

Epoch: 5| Step: 2
Training loss: 0.8560946583747864
Validation loss: 1.82602705237686

Epoch: 5| Step: 3
Training loss: 2.154297113418579
Validation loss: 1.78639567026528

Epoch: 5| Step: 4
Training loss: 1.4961669445037842
Validation loss: 1.864085433303669

Epoch: 5| Step: 5
Training loss: 1.674717903137207
Validation loss: 1.8341267057644424

Epoch: 5| Step: 6
Training loss: 1.3468880653381348
Validation loss: 1.7941099110470022

Epoch: 5| Step: 7
Training loss: 1.7841498851776123
Validation loss: 1.8183648483727568

Epoch: 5| Step: 8
Training loss: 1.6519016027450562
Validation loss: 1.8036860189130228

Epoch: 5| Step: 9
Training loss: 1.1216189861297607
Validation loss: 1.868461585813953

Epoch: 5| Step: 10
Training loss: 1.7388312816619873
Validation loss: 1.850083322935207

Epoch: 306| Step: 0
Training loss: 1.4960893392562866
Validation loss: 1.8269792859272291

Epoch: 5| Step: 1
Training loss: 1.6781723499298096
Validation loss: 1.8445072456072735

Epoch: 5| Step: 2
Training loss: 1.3402537107467651
Validation loss: 1.8371304030059485

Epoch: 5| Step: 3
Training loss: 1.301318645477295
Validation loss: 1.7805489276045112

Epoch: 5| Step: 4
Training loss: 1.0700726509094238
Validation loss: 1.8172058315687283

Epoch: 5| Step: 5
Training loss: 1.2949519157409668
Validation loss: 1.8408291570601925

Epoch: 5| Step: 6
Training loss: 1.9993435144424438
Validation loss: 1.8688889036896408

Epoch: 5| Step: 7
Training loss: 1.1564708948135376
Validation loss: 1.8087717384420416

Epoch: 5| Step: 8
Training loss: 1.345415711402893
Validation loss: 1.8383935113107004

Epoch: 5| Step: 9
Training loss: 1.7814089059829712
Validation loss: 1.7731876116926952

Epoch: 5| Step: 10
Training loss: 1.4059849977493286
Validation loss: 1.7418661732827463

Epoch: 307| Step: 0
Training loss: 1.307342290878296
Validation loss: 1.8074367712902766

Epoch: 5| Step: 1
Training loss: 1.4463850259780884
Validation loss: 1.8140704734351045

Epoch: 5| Step: 2
Training loss: 1.4153006076812744
Validation loss: 1.831066801983823

Epoch: 5| Step: 3
Training loss: 1.1668179035186768
Validation loss: 1.8419618324566913

Epoch: 5| Step: 4
Training loss: 1.4116085767745972
Validation loss: 1.8349709844076505

Epoch: 5| Step: 5
Training loss: 1.654667854309082
Validation loss: 1.8209403509734778

Epoch: 5| Step: 6
Training loss: 1.3907983303070068
Validation loss: 1.8335168541118663

Epoch: 5| Step: 7
Training loss: 1.4268001317977905
Validation loss: 1.8562537752172

Epoch: 5| Step: 8
Training loss: 1.550071120262146
Validation loss: 1.8253669238859607

Epoch: 5| Step: 9
Training loss: 1.7233669757843018
Validation loss: 1.7922070923671927

Epoch: 5| Step: 10
Training loss: 1.486641764640808
Validation loss: 1.793694293627175

Epoch: 308| Step: 0
Training loss: 1.8561182022094727
Validation loss: 1.8234048299891974

Epoch: 5| Step: 1
Training loss: 1.5576119422912598
Validation loss: 1.8322021518984148

Epoch: 5| Step: 2
Training loss: 1.345709204673767
Validation loss: 1.8580991760376961

Epoch: 5| Step: 3
Training loss: 0.6022354364395142
Validation loss: 1.8451240319077686

Epoch: 5| Step: 4
Training loss: 1.254747748374939
Validation loss: 1.8597379256320257

Epoch: 5| Step: 5
Training loss: 1.5628058910369873
Validation loss: 1.8092483499998688

Epoch: 5| Step: 6
Training loss: 1.301142930984497
Validation loss: 1.8140948510939074

Epoch: 5| Step: 7
Training loss: 1.3736872673034668
Validation loss: 1.7918821047711115

Epoch: 5| Step: 8
Training loss: 1.4866278171539307
Validation loss: 1.8352343177282682

Epoch: 5| Step: 9
Training loss: 1.754827857017517
Validation loss: 1.8579346928545224

Epoch: 5| Step: 10
Training loss: 1.4701224565505981
Validation loss: 1.796668077027926

Epoch: 309| Step: 0
Training loss: 1.0171496868133545
Validation loss: 1.824527976333454

Epoch: 5| Step: 1
Training loss: 1.9838898181915283
Validation loss: 1.8066577693467498

Epoch: 5| Step: 2
Training loss: 1.401535987854004
Validation loss: 1.8116118459291355

Epoch: 5| Step: 3
Training loss: 1.068819284439087
Validation loss: 1.812658881628385

Epoch: 5| Step: 4
Training loss: 1.6640536785125732
Validation loss: 1.79776519344699

Epoch: 5| Step: 5
Training loss: 1.9166244268417358
Validation loss: 1.7743903718968874

Epoch: 5| Step: 6
Training loss: 1.1533324718475342
Validation loss: 1.7950622291975125

Epoch: 5| Step: 7
Training loss: 1.8651851415634155
Validation loss: 1.8117883795051164

Epoch: 5| Step: 8
Training loss: 1.2753856182098389
Validation loss: 1.8044822831307687

Epoch: 5| Step: 9
Training loss: 1.127514362335205
Validation loss: 1.7856259179371659

Epoch: 5| Step: 10
Training loss: 1.3540080785751343
Validation loss: 1.8038973641651932

Epoch: 310| Step: 0
Training loss: 1.256155014038086
Validation loss: 1.830582530267777

Epoch: 5| Step: 1
Training loss: 1.421976089477539
Validation loss: 1.847513129634242

Epoch: 5| Step: 2
Training loss: 1.8356746435165405
Validation loss: 1.9000286107422204

Epoch: 5| Step: 3
Training loss: 1.3204439878463745
Validation loss: 1.8522256317959036

Epoch: 5| Step: 4
Training loss: 1.0767056941986084
Validation loss: 1.8053989474491408

Epoch: 5| Step: 5
Training loss: 0.911464512348175
Validation loss: 1.8185697934960807

Epoch: 5| Step: 6
Training loss: 1.5378086566925049
Validation loss: 1.814406697468091

Epoch: 5| Step: 7
Training loss: 1.744977355003357
Validation loss: 1.8578419813545801

Epoch: 5| Step: 8
Training loss: 1.5290602445602417
Validation loss: 1.8604803162236367

Epoch: 5| Step: 9
Training loss: 1.6149299144744873
Validation loss: 1.8236027609917425

Epoch: 5| Step: 10
Training loss: 1.4316307306289673
Validation loss: 1.8373253114761845

Epoch: 311| Step: 0
Training loss: 1.1799663305282593
Validation loss: 1.8416789962399391

Epoch: 5| Step: 1
Training loss: 1.3046619892120361
Validation loss: 1.783099095026652

Epoch: 5| Step: 2
Training loss: 1.950164556503296
Validation loss: 1.7745270267609627

Epoch: 5| Step: 3
Training loss: 0.7998863458633423
Validation loss: 1.8301638069973196

Epoch: 5| Step: 4
Training loss: 1.8038190603256226
Validation loss: 1.8072097250210342

Epoch: 5| Step: 5
Training loss: 1.0534617900848389
Validation loss: 1.8049921976622714

Epoch: 5| Step: 6
Training loss: 1.5240122079849243
Validation loss: 1.82237547187395

Epoch: 5| Step: 7
Training loss: 1.488550066947937
Validation loss: 1.7680897699889315

Epoch: 5| Step: 8
Training loss: 1.7072725296020508
Validation loss: 1.8375306847274944

Epoch: 5| Step: 9
Training loss: 1.665076494216919
Validation loss: 1.8023539730297622

Epoch: 5| Step: 10
Training loss: 1.0352652072906494
Validation loss: 1.7862772928771151

Epoch: 312| Step: 0
Training loss: 1.193821668624878
Validation loss: 1.8313202845152987

Epoch: 5| Step: 1
Training loss: 1.7861888408660889
Validation loss: 1.7828639476530013

Epoch: 5| Step: 2
Training loss: 1.2384107112884521
Validation loss: 1.7879353979582429

Epoch: 5| Step: 3
Training loss: 2.1442103385925293
Validation loss: 1.8130489036601076

Epoch: 5| Step: 4
Training loss: 1.3074629306793213
Validation loss: 1.807016545726407

Epoch: 5| Step: 5
Training loss: 1.491661787033081
Validation loss: 1.8033499794621621

Epoch: 5| Step: 6
Training loss: 1.3970457315444946
Validation loss: 1.8489865128711989

Epoch: 5| Step: 7
Training loss: 0.9996741414070129
Validation loss: 1.8403189669373214

Epoch: 5| Step: 8
Training loss: 1.2131516933441162
Validation loss: 1.836043288630824

Epoch: 5| Step: 9
Training loss: 1.7098251581192017
Validation loss: 1.8369925227216495

Epoch: 5| Step: 10
Training loss: 1.353319525718689
Validation loss: 1.7785178371655044

Epoch: 313| Step: 0
Training loss: 1.017063856124878
Validation loss: 1.836180224213549

Epoch: 5| Step: 1
Training loss: 1.4061815738677979
Validation loss: 1.8001841960414764

Epoch: 5| Step: 2
Training loss: 1.5985212326049805
Validation loss: 1.8064884678010018

Epoch: 5| Step: 3
Training loss: 1.0153982639312744
Validation loss: 1.8184647047391502

Epoch: 5| Step: 4
Training loss: 1.5512701272964478
Validation loss: 1.8407961476233698

Epoch: 5| Step: 5
Training loss: 1.313315987586975
Validation loss: 1.848468957408782

Epoch: 5| Step: 6
Training loss: 2.0417404174804688
Validation loss: 1.8316221442273868

Epoch: 5| Step: 7
Training loss: 1.648816704750061
Validation loss: 1.8206687383754279

Epoch: 5| Step: 8
Training loss: 1.1341180801391602
Validation loss: 1.810224679208571

Epoch: 5| Step: 9
Training loss: 1.2850209474563599
Validation loss: 1.872268335793608

Epoch: 5| Step: 10
Training loss: 1.6854982376098633
Validation loss: 1.7939781796547674

Epoch: 314| Step: 0
Training loss: 1.8881375789642334
Validation loss: 1.8195613276573919

Epoch: 5| Step: 1
Training loss: 1.2627389430999756
Validation loss: 1.8433527626017088

Epoch: 5| Step: 2
Training loss: 1.6883100271224976
Validation loss: 1.8264727874468731

Epoch: 5| Step: 3
Training loss: 1.262262225151062
Validation loss: 1.823127358190475

Epoch: 5| Step: 4
Training loss: 1.2953864336013794
Validation loss: 1.8206652954060545

Epoch: 5| Step: 5
Training loss: 1.4556565284729004
Validation loss: 1.7888386198269424

Epoch: 5| Step: 6
Training loss: 1.6078170537948608
Validation loss: 1.7933906637212282

Epoch: 5| Step: 7
Training loss: 0.9861447215080261
Validation loss: 1.8080822396022018

Epoch: 5| Step: 8
Training loss: 1.401402473449707
Validation loss: 1.8166548487960652

Epoch: 5| Step: 9
Training loss: 1.2455681562423706
Validation loss: 1.8190954359628821

Epoch: 5| Step: 10
Training loss: 1.1827393770217896
Validation loss: 1.8513372482792023

Epoch: 315| Step: 0
Training loss: 1.2338879108428955
Validation loss: 1.8071058283569992

Epoch: 5| Step: 1
Training loss: 1.3098523616790771
Validation loss: 1.8412001568783996

Epoch: 5| Step: 2
Training loss: 1.2622804641723633
Validation loss: 1.8054878404063563

Epoch: 5| Step: 3
Training loss: 1.5329796075820923
Validation loss: 1.7748483304054505

Epoch: 5| Step: 4
Training loss: 1.4383026361465454
Validation loss: 1.859518866385183

Epoch: 5| Step: 5
Training loss: 1.439192771911621
Validation loss: 1.8517478255815403

Epoch: 5| Step: 6
Training loss: 1.2136567831039429
Validation loss: 1.8294461401559974

Epoch: 5| Step: 7
Training loss: 1.7374804019927979
Validation loss: 1.84353300832933

Epoch: 5| Step: 8
Training loss: 0.9683544039726257
Validation loss: 1.8803725691251858

Epoch: 5| Step: 9
Training loss: 1.8660087585449219
Validation loss: 1.8681056755845264

Epoch: 5| Step: 10
Training loss: 1.5540471076965332
Validation loss: 1.8298096990072599

Epoch: 316| Step: 0
Training loss: 1.232210636138916
Validation loss: 1.8489369730795584

Epoch: 5| Step: 1
Training loss: 1.7110888957977295
Validation loss: 1.8286478416894072

Epoch: 5| Step: 2
Training loss: 1.5746839046478271
Validation loss: 1.8207997019572923

Epoch: 5| Step: 3
Training loss: 1.3747093677520752
Validation loss: 1.8290555515596945

Epoch: 5| Step: 4
Training loss: 0.9492337107658386
Validation loss: 1.801914180478742

Epoch: 5| Step: 5
Training loss: 1.268301248550415
Validation loss: 1.8223070354871853

Epoch: 5| Step: 6
Training loss: 1.3556420803070068
Validation loss: 1.8242487010135446

Epoch: 5| Step: 7
Training loss: 1.1497089862823486
Validation loss: 1.7885907952503493

Epoch: 5| Step: 8
Training loss: 1.4688643217086792
Validation loss: 1.8181436318223194

Epoch: 5| Step: 9
Training loss: 1.4142277240753174
Validation loss: 1.8098310507753843

Epoch: 5| Step: 10
Training loss: 2.10394024848938
Validation loss: 1.7947727992970457

Epoch: 317| Step: 0
Training loss: 1.480269432067871
Validation loss: 1.8141913093546385

Epoch: 5| Step: 1
Training loss: 1.1157416105270386
Validation loss: 1.8114111167128368

Epoch: 5| Step: 2
Training loss: 1.573851227760315
Validation loss: 1.8550486385181386

Epoch: 5| Step: 3
Training loss: 1.6312214136123657
Validation loss: 1.840314511329897

Epoch: 5| Step: 4
Training loss: 1.2181198596954346
Validation loss: 1.8309256081940026

Epoch: 5| Step: 5
Training loss: 0.8914294242858887
Validation loss: 1.7986297363876014

Epoch: 5| Step: 6
Training loss: 1.4431849718093872
Validation loss: 1.8063342622531358

Epoch: 5| Step: 7
Training loss: 1.4100488424301147
Validation loss: 1.8054793932104622

Epoch: 5| Step: 8
Training loss: 1.3090906143188477
Validation loss: 1.8449927735072311

Epoch: 5| Step: 9
Training loss: 1.2894641160964966
Validation loss: 1.7911645020208051

Epoch: 5| Step: 10
Training loss: 2.2253451347351074
Validation loss: 1.7835682848448395

Epoch: 318| Step: 0
Training loss: 1.5437196493148804
Validation loss: 1.8276972604054276

Epoch: 5| Step: 1
Training loss: 1.1673181056976318
Validation loss: 1.8345845168636692

Epoch: 5| Step: 2
Training loss: 2.0325944423675537
Validation loss: 1.7819981895467287

Epoch: 5| Step: 3
Training loss: 1.3020198345184326
Validation loss: 1.824905974890596

Epoch: 5| Step: 4
Training loss: 1.2030318975448608
Validation loss: 1.7778675312637

Epoch: 5| Step: 5
Training loss: 1.349612832069397
Validation loss: 1.8010371961901266

Epoch: 5| Step: 6
Training loss: 0.985648512840271
Validation loss: 1.7709185128570886

Epoch: 5| Step: 7
Training loss: 1.2197250127792358
Validation loss: 1.7449373916913105

Epoch: 5| Step: 8
Training loss: 1.3733477592468262
Validation loss: 1.8460574201358262

Epoch: 5| Step: 9
Training loss: 1.4663581848144531
Validation loss: 1.8288140014935566

Epoch: 5| Step: 10
Training loss: 1.6816879510879517
Validation loss: 1.8142983246875066

Epoch: 319| Step: 0
Training loss: 1.2913051843643188
Validation loss: 1.825592255079618

Epoch: 5| Step: 1
Training loss: 1.2168996334075928
Validation loss: 1.7864769158824798

Epoch: 5| Step: 2
Training loss: 1.6150245666503906
Validation loss: 1.823659602031913

Epoch: 5| Step: 3
Training loss: 1.663291335105896
Validation loss: 1.8744014565662672

Epoch: 5| Step: 4
Training loss: 1.3451225757598877
Validation loss: 1.8384622476434196

Epoch: 5| Step: 5
Training loss: 1.7386674880981445
Validation loss: 1.817188721831127

Epoch: 5| Step: 6
Training loss: 1.1208374500274658
Validation loss: 1.8080736411515104

Epoch: 5| Step: 7
Training loss: 1.2521278858184814
Validation loss: 1.7922154024083128

Epoch: 5| Step: 8
Training loss: 0.8260347247123718
Validation loss: 1.7825108189736643

Epoch: 5| Step: 9
Training loss: 1.9240013360977173
Validation loss: 1.8319380296173917

Epoch: 5| Step: 10
Training loss: 1.3812799453735352
Validation loss: 1.8246678947120585

Epoch: 320| Step: 0
Training loss: 1.4847776889801025
Validation loss: 1.7773543403994652

Epoch: 5| Step: 1
Training loss: 1.4245984554290771
Validation loss: 1.7884136169187483

Epoch: 5| Step: 2
Training loss: 1.221150517463684
Validation loss: 1.8176836993104668

Epoch: 5| Step: 3
Training loss: 1.1776487827301025
Validation loss: 1.8086677405142015

Epoch: 5| Step: 4
Training loss: 1.407970666885376
Validation loss: 1.8042296786462106

Epoch: 5| Step: 5
Training loss: 1.5836118459701538
Validation loss: 1.8015568628106067

Epoch: 5| Step: 6
Training loss: 1.1192328929901123
Validation loss: 1.7871628653618596

Epoch: 5| Step: 7
Training loss: 0.9628911018371582
Validation loss: 1.8068638386264924

Epoch: 5| Step: 8
Training loss: 1.1764662265777588
Validation loss: 1.815106661089005

Epoch: 5| Step: 9
Training loss: 1.9622247219085693
Validation loss: 1.7798992651765064

Epoch: 5| Step: 10
Training loss: 2.1406702995300293
Validation loss: 1.8245078594453874

Epoch: 321| Step: 0
Training loss: 1.0308514833450317
Validation loss: 1.875113953826248

Epoch: 5| Step: 1
Training loss: 1.728660225868225
Validation loss: 1.812529089630291

Epoch: 5| Step: 2
Training loss: 1.5954878330230713
Validation loss: 1.827619166784389

Epoch: 5| Step: 3
Training loss: 1.3363178968429565
Validation loss: 1.7996915219932474

Epoch: 5| Step: 4
Training loss: 1.723578691482544
Validation loss: 1.7870270859810613

Epoch: 5| Step: 5
Training loss: 1.1763254404067993
Validation loss: 1.792620094873572

Epoch: 5| Step: 6
Training loss: 1.4407856464385986
Validation loss: 1.793697044413577

Epoch: 5| Step: 7
Training loss: 1.8066610097885132
Validation loss: 1.7827036201312978

Epoch: 5| Step: 8
Training loss: 1.239229679107666
Validation loss: 1.783302294310703

Epoch: 5| Step: 9
Training loss: 1.0169260501861572
Validation loss: 1.7353681402821695

Epoch: 5| Step: 10
Training loss: 1.2867095470428467
Validation loss: 1.8362527560162287

Epoch: 322| Step: 0
Training loss: 1.296216368675232
Validation loss: 1.8170781045831659

Epoch: 5| Step: 1
Training loss: 2.066195011138916
Validation loss: 1.7781473680209088

Epoch: 5| Step: 2
Training loss: 1.3558825254440308
Validation loss: 1.8066943781350249

Epoch: 5| Step: 3
Training loss: 1.6749136447906494
Validation loss: 1.796527272911482

Epoch: 5| Step: 4
Training loss: 1.354055643081665
Validation loss: 1.8160873728413736

Epoch: 5| Step: 5
Training loss: 1.5954967737197876
Validation loss: 1.8240055038082985

Epoch: 5| Step: 6
Training loss: 1.322615385055542
Validation loss: 1.815745202443933

Epoch: 5| Step: 7
Training loss: 0.9607117772102356
Validation loss: 1.8153353583428167

Epoch: 5| Step: 8
Training loss: 1.2316412925720215
Validation loss: 1.8010083244692894

Epoch: 5| Step: 9
Training loss: 1.1489436626434326
Validation loss: 1.81391401444712

Epoch: 5| Step: 10
Training loss: 1.326958417892456
Validation loss: 1.8171116421299596

Epoch: 323| Step: 0
Training loss: 1.499132513999939
Validation loss: 1.854417647084882

Epoch: 5| Step: 1
Training loss: 1.3784793615341187
Validation loss: 1.8703391667335265

Epoch: 5| Step: 2
Training loss: 1.1649956703186035
Validation loss: 1.8140658999002108

Epoch: 5| Step: 3
Training loss: 0.7476876378059387
Validation loss: 1.8213854758970198

Epoch: 5| Step: 4
Training loss: 1.2171156406402588
Validation loss: 1.8377401700583837

Epoch: 5| Step: 5
Training loss: 1.8514788150787354
Validation loss: 1.833610894859478

Epoch: 5| Step: 6
Training loss: 1.7397301197052002
Validation loss: 1.8763950447882376

Epoch: 5| Step: 7
Training loss: 1.188517451286316
Validation loss: 1.820904383095362

Epoch: 5| Step: 8
Training loss: 1.4050822257995605
Validation loss: 1.833524001541958

Epoch: 5| Step: 9
Training loss: 1.2590839862823486
Validation loss: 1.8437729189472813

Epoch: 5| Step: 10
Training loss: 1.8060529232025146
Validation loss: 1.8658255864215154

Epoch: 324| Step: 0
Training loss: 0.8161429166793823
Validation loss: 1.8105386598135835

Epoch: 5| Step: 1
Training loss: 1.4496879577636719
Validation loss: 1.8464676257102721

Epoch: 5| Step: 2
Training loss: 1.2008057832717896
Validation loss: 1.8013338081298336

Epoch: 5| Step: 3
Training loss: 1.7732995748519897
Validation loss: 1.8284065249145671

Epoch: 5| Step: 4
Training loss: 1.3682762384414673
Validation loss: 1.810703641624861

Epoch: 5| Step: 5
Training loss: 1.492419958114624
Validation loss: 1.8448553713419105

Epoch: 5| Step: 6
Training loss: 2.0089597702026367
Validation loss: 1.742961807917523

Epoch: 5| Step: 7
Training loss: 1.108445405960083
Validation loss: 1.7922277424925117

Epoch: 5| Step: 8
Training loss: 1.2963823080062866
Validation loss: 1.8190769521139

Epoch: 5| Step: 9
Training loss: 1.338862657546997
Validation loss: 1.8075596799132645

Epoch: 5| Step: 10
Training loss: 1.2770179510116577
Validation loss: 1.8143133950489823

Epoch: 325| Step: 0
Training loss: 1.602850317955017
Validation loss: 1.801832127314742

Epoch: 5| Step: 1
Training loss: 1.893949270248413
Validation loss: 1.7916545611555859

Epoch: 5| Step: 2
Training loss: 1.1290932893753052
Validation loss: 1.8007500453661847

Epoch: 5| Step: 3
Training loss: 1.1515072584152222
Validation loss: 1.7968285852862942

Epoch: 5| Step: 4
Training loss: 1.1559348106384277
Validation loss: 1.787080818606961

Epoch: 5| Step: 5
Training loss: 1.534254789352417
Validation loss: 1.7910852662978634

Epoch: 5| Step: 6
Training loss: 1.342167854309082
Validation loss: 1.7978874368052329

Epoch: 5| Step: 7
Training loss: 1.3630447387695312
Validation loss: 1.7915666590454757

Epoch: 5| Step: 8
Training loss: 1.8748432397842407
Validation loss: 1.7927014763637255

Epoch: 5| Step: 9
Training loss: 1.0396981239318848
Validation loss: 1.8027384781068372

Epoch: 5| Step: 10
Training loss: 1.2498224973678589
Validation loss: 1.7968299491431123

Epoch: 326| Step: 0
Training loss: 1.3142292499542236
Validation loss: 1.8385335809441024

Epoch: 5| Step: 1
Training loss: 1.4723713397979736
Validation loss: 1.8304510129395353

Epoch: 5| Step: 2
Training loss: 0.8606861233711243
Validation loss: 1.839674908627746

Epoch: 5| Step: 3
Training loss: 1.4836242198944092
Validation loss: 1.8339292721081806

Epoch: 5| Step: 4
Training loss: 1.7037103176116943
Validation loss: 1.8090412898730206

Epoch: 5| Step: 5
Training loss: 1.410125970840454
Validation loss: 1.8038736761257212

Epoch: 5| Step: 6
Training loss: 1.468207597732544
Validation loss: 1.844594906735164

Epoch: 5| Step: 7
Training loss: 1.4855997562408447
Validation loss: 1.792666353205199

Epoch: 5| Step: 8
Training loss: 1.1914781332015991
Validation loss: 1.8445594567124561

Epoch: 5| Step: 9
Training loss: 1.1772141456604004
Validation loss: 1.8142937242343862

Epoch: 5| Step: 10
Training loss: 1.3126012086868286
Validation loss: 1.7929596721485097

Epoch: 327| Step: 0
Training loss: 1.4741837978363037
Validation loss: 1.8146723521653043

Epoch: 5| Step: 1
Training loss: 1.2395951747894287
Validation loss: 1.822430633729504

Epoch: 5| Step: 2
Training loss: 1.550093650817871
Validation loss: 1.820379320011344

Epoch: 5| Step: 3
Training loss: 1.3341937065124512
Validation loss: 1.81984539698529

Epoch: 5| Step: 4
Training loss: 1.1463394165039062
Validation loss: 1.8483720248745334

Epoch: 5| Step: 5
Training loss: 1.9748010635375977
Validation loss: 1.8060710596781906

Epoch: 5| Step: 6
Training loss: 1.1400368213653564
Validation loss: 1.7988552201178767

Epoch: 5| Step: 7
Training loss: 1.1771240234375
Validation loss: 1.827706374788797

Epoch: 5| Step: 8
Training loss: 1.443975567817688
Validation loss: 1.7961345680298344

Epoch: 5| Step: 9
Training loss: 1.6523860692977905
Validation loss: 1.825981250373266

Epoch: 5| Step: 10
Training loss: 1.0979089736938477
Validation loss: 1.811523768209642

Epoch: 328| Step: 0
Training loss: 0.8938020467758179
Validation loss: 1.8262276111110565

Epoch: 5| Step: 1
Training loss: 1.6297088861465454
Validation loss: 1.866719461256458

Epoch: 5| Step: 2
Training loss: 1.2240180969238281
Validation loss: 1.7692324551202918

Epoch: 5| Step: 3
Training loss: 1.8735663890838623
Validation loss: 1.8056506418412732

Epoch: 5| Step: 4
Training loss: 1.4354168176651
Validation loss: 1.7686902002621723

Epoch: 5| Step: 5
Training loss: 1.141430139541626
Validation loss: 1.787757799189578

Epoch: 5| Step: 6
Training loss: 1.1194145679473877
Validation loss: 1.8107025059320594

Epoch: 5| Step: 7
Training loss: 1.7243881225585938
Validation loss: 1.7715709401715187

Epoch: 5| Step: 8
Training loss: 1.5794332027435303
Validation loss: 1.8114187691801338

Epoch: 5| Step: 9
Training loss: 1.5157923698425293
Validation loss: 1.8111656147946593

Epoch: 5| Step: 10
Training loss: 1.0223581790924072
Validation loss: 1.7964084725226126

Epoch: 329| Step: 0
Training loss: 1.5943472385406494
Validation loss: 1.80347502616144

Epoch: 5| Step: 1
Training loss: 0.7808709144592285
Validation loss: 1.794386238180181

Epoch: 5| Step: 2
Training loss: 1.208739995956421
Validation loss: 1.7835941122424217

Epoch: 5| Step: 3
Training loss: 1.588031530380249
Validation loss: 1.8385857100127845

Epoch: 5| Step: 4
Training loss: 1.7265262603759766
Validation loss: 1.746080461368766

Epoch: 5| Step: 5
Training loss: 1.1435155868530273
Validation loss: 1.7623476751389042

Epoch: 5| Step: 6
Training loss: 2.3892054557800293
Validation loss: 1.807594609516923

Epoch: 5| Step: 7
Training loss: 1.1350984573364258
Validation loss: 1.8292986398102136

Epoch: 5| Step: 8
Training loss: 1.1209840774536133
Validation loss: 1.80821487211412

Epoch: 5| Step: 9
Training loss: 1.1992708444595337
Validation loss: 1.828006980239704

Epoch: 5| Step: 10
Training loss: 1.2136857509613037
Validation loss: 1.8072885082614036

Epoch: 330| Step: 0
Training loss: 1.2299718856811523
Validation loss: 1.8380777553845478

Epoch: 5| Step: 1
Training loss: 1.3597819805145264
Validation loss: 1.7982438841173727

Epoch: 5| Step: 2
Training loss: 1.0600155591964722
Validation loss: 1.8598287182469522

Epoch: 5| Step: 3
Training loss: 1.6095863580703735
Validation loss: 1.8158390214366298

Epoch: 5| Step: 4
Training loss: 1.3674914836883545
Validation loss: 1.8276516211930143

Epoch: 5| Step: 5
Training loss: 1.1903141736984253
Validation loss: 1.849923078731824

Epoch: 5| Step: 6
Training loss: 1.7962440252304077
Validation loss: 1.853764631414926

Epoch: 5| Step: 7
Training loss: 1.4793649911880493
Validation loss: 1.8516401706203338

Epoch: 5| Step: 8
Training loss: 1.3000357151031494
Validation loss: 1.8344468532070037

Epoch: 5| Step: 9
Training loss: 1.650357961654663
Validation loss: 1.8061580228549179

Epoch: 5| Step: 10
Training loss: 1.1167610883712769
Validation loss: 1.8449436246707875

Epoch: 331| Step: 0
Training loss: 1.443629503250122
Validation loss: 1.829739978236537

Epoch: 5| Step: 1
Training loss: 1.9354026317596436
Validation loss: 1.8350954901787542

Epoch: 5| Step: 2
Training loss: 1.0465878248214722
Validation loss: 1.761632239946755

Epoch: 5| Step: 3
Training loss: 1.3347065448760986
Validation loss: 1.8181950405079832

Epoch: 5| Step: 4
Training loss: 1.5224889516830444
Validation loss: 1.7750544509580057

Epoch: 5| Step: 5
Training loss: 1.17836594581604
Validation loss: 1.7728915663175686

Epoch: 5| Step: 6
Training loss: 1.5664342641830444
Validation loss: 1.7905156074031707

Epoch: 5| Step: 7
Training loss: 1.1448357105255127
Validation loss: 1.7693627867647397

Epoch: 5| Step: 8
Training loss: 1.269124984741211
Validation loss: 1.831910466635099

Epoch: 5| Step: 9
Training loss: 1.5852750539779663
Validation loss: 1.7784631790653351

Epoch: 5| Step: 10
Training loss: 1.0663833618164062
Validation loss: 1.827467756886636

Epoch: 332| Step: 0
Training loss: 1.4717352390289307
Validation loss: 1.9187313318252563

Epoch: 5| Step: 1
Training loss: 2.030137062072754
Validation loss: 1.8416370127790718

Epoch: 5| Step: 2
Training loss: 1.550193190574646
Validation loss: 1.8697755708489368

Epoch: 5| Step: 3
Training loss: 1.3258901834487915
Validation loss: 1.893510103225708

Epoch: 5| Step: 4
Training loss: 1.3951694965362549
Validation loss: 1.8673759711686002

Epoch: 5| Step: 5
Training loss: 1.5442098379135132
Validation loss: 1.9076825072688441

Epoch: 5| Step: 6
Training loss: 1.2652647495269775
Validation loss: 1.8864545693961523

Epoch: 5| Step: 7
Training loss: 1.0672006607055664
Validation loss: 1.8653482826807166

Epoch: 5| Step: 8
Training loss: 0.7242825031280518
Validation loss: 1.8747188083587154

Epoch: 5| Step: 9
Training loss: 1.4794673919677734
Validation loss: 1.889971471601917

Epoch: 5| Step: 10
Training loss: 1.430501937866211
Validation loss: 1.845528038599158

Epoch: 333| Step: 0
Training loss: 1.3761579990386963
Validation loss: 1.8617120609488538

Epoch: 5| Step: 1
Training loss: 1.2539774179458618
Validation loss: 1.7785548574181014

Epoch: 5| Step: 2
Training loss: 1.2702165842056274
Validation loss: 1.7441552787698724

Epoch: 5| Step: 3
Training loss: 1.767472505569458
Validation loss: 1.7521390248370428

Epoch: 5| Step: 4
Training loss: 1.2693392038345337
Validation loss: 1.7800523055497037

Epoch: 5| Step: 5
Training loss: 1.5941683053970337
Validation loss: 1.7789244805612872

Epoch: 5| Step: 6
Training loss: 1.3134633302688599
Validation loss: 1.7762338602414696

Epoch: 5| Step: 7
Training loss: 1.4670193195343018
Validation loss: 1.779760447881555

Epoch: 5| Step: 8
Training loss: 1.2478317022323608
Validation loss: 1.7603912802152737

Epoch: 5| Step: 9
Training loss: 1.0180319547653198
Validation loss: 1.7695248408984112

Epoch: 5| Step: 10
Training loss: 1.7581123113632202
Validation loss: 1.7577984166401688

Epoch: 334| Step: 0
Training loss: 1.1531320810317993
Validation loss: 1.8022605347376999

Epoch: 5| Step: 1
Training loss: 1.074131727218628
Validation loss: 1.8009386498440978

Epoch: 5| Step: 2
Training loss: 1.3145333528518677
Validation loss: 1.8536737131816086

Epoch: 5| Step: 3
Training loss: 1.166176438331604
Validation loss: 1.8315149481578539

Epoch: 5| Step: 4
Training loss: 1.6035373210906982
Validation loss: 1.8152527514324392

Epoch: 5| Step: 5
Training loss: 1.7596994638442993
Validation loss: 1.8790309249713857

Epoch: 5| Step: 6
Training loss: 1.4292069673538208
Validation loss: 1.8313659045004076

Epoch: 5| Step: 7
Training loss: 1.5436513423919678
Validation loss: 1.8430655361503683

Epoch: 5| Step: 8
Training loss: 1.0132114887237549
Validation loss: 1.8290166188311834

Epoch: 5| Step: 9
Training loss: 1.3897931575775146
Validation loss: 1.836802485168621

Epoch: 5| Step: 10
Training loss: 1.2153830528259277
Validation loss: 1.8490789603161555

Epoch: 335| Step: 0
Training loss: 1.5176582336425781
Validation loss: 1.816100969109484

Epoch: 5| Step: 1
Training loss: 1.3456919193267822
Validation loss: 1.7978283846250145

Epoch: 5| Step: 2
Training loss: 1.2488685846328735
Validation loss: 1.7644244522176764

Epoch: 5| Step: 3
Training loss: 1.426574468612671
Validation loss: 1.8298342817573137

Epoch: 5| Step: 4
Training loss: 1.4247527122497559
Validation loss: 1.787052700596471

Epoch: 5| Step: 5
Training loss: 1.313921570777893
Validation loss: 1.754254303952699

Epoch: 5| Step: 6
Training loss: 1.3199483156204224
Validation loss: 1.7905444509239608

Epoch: 5| Step: 7
Training loss: 1.2464134693145752
Validation loss: 1.7601439170939948

Epoch: 5| Step: 8
Training loss: 1.2243015766143799
Validation loss: 1.8373058278073546

Epoch: 5| Step: 9
Training loss: 1.725164771080017
Validation loss: 1.8438757670822965

Epoch: 5| Step: 10
Training loss: 1.1488125324249268
Validation loss: 1.8109168634619763

Epoch: 336| Step: 0
Training loss: 1.515371322631836
Validation loss: 1.833114476614101

Epoch: 5| Step: 1
Training loss: 1.4967395067214966
Validation loss: 1.8386595556812901

Epoch: 5| Step: 2
Training loss: 1.4527575969696045
Validation loss: 1.8169246296728812

Epoch: 5| Step: 3
Training loss: 1.0143306255340576
Validation loss: 1.8303866245413338

Epoch: 5| Step: 4
Training loss: 1.438081979751587
Validation loss: 1.8203542655514133

Epoch: 5| Step: 5
Training loss: 1.2699543237686157
Validation loss: 1.8075976217946699

Epoch: 5| Step: 6
Training loss: 1.2482070922851562
Validation loss: 1.8241187846788796

Epoch: 5| Step: 7
Training loss: 1.454053282737732
Validation loss: 1.8041199112451205

Epoch: 5| Step: 8
Training loss: 1.595640778541565
Validation loss: 1.8345688825012536

Epoch: 5| Step: 9
Training loss: 1.3140333890914917
Validation loss: 1.801671552401717

Epoch: 5| Step: 10
Training loss: 1.2707509994506836
Validation loss: 1.8292927395912908

Epoch: 337| Step: 0
Training loss: 1.5818856954574585
Validation loss: 1.7883935128488848

Epoch: 5| Step: 1
Training loss: 1.3592909574508667
Validation loss: 1.8104518562234857

Epoch: 5| Step: 2
Training loss: 0.9792994260787964
Validation loss: 1.818844921486352

Epoch: 5| Step: 3
Training loss: 1.4712183475494385
Validation loss: 1.7950496827402422

Epoch: 5| Step: 4
Training loss: 1.6940248012542725
Validation loss: 1.8254851666829919

Epoch: 5| Step: 5
Training loss: 1.280450463294983
Validation loss: 1.8199887890969553

Epoch: 5| Step: 6
Training loss: 1.0455204248428345
Validation loss: 1.8488599446512037

Epoch: 5| Step: 7
Training loss: 1.7199370861053467
Validation loss: 1.8354006557054416

Epoch: 5| Step: 8
Training loss: 0.8133491277694702
Validation loss: 1.805602450524607

Epoch: 5| Step: 9
Training loss: 1.5766730308532715
Validation loss: 1.8203843550015522

Epoch: 5| Step: 10
Training loss: 1.5569740533828735
Validation loss: 1.8129025787435553

Epoch: 338| Step: 0
Training loss: 1.5424180030822754
Validation loss: 1.8030044109590593

Epoch: 5| Step: 1
Training loss: 1.0721238851547241
Validation loss: 1.8282621804104056

Epoch: 5| Step: 2
Training loss: 1.3644349575042725
Validation loss: 1.8372556701783211

Epoch: 5| Step: 3
Training loss: 1.0712140798568726
Validation loss: 1.844053186396117

Epoch: 5| Step: 4
Training loss: 1.1817563772201538
Validation loss: 1.77868696694733

Epoch: 5| Step: 5
Training loss: 2.1584019660949707
Validation loss: 1.775870100144417

Epoch: 5| Step: 6
Training loss: 1.5344171524047852
Validation loss: 1.809674588582849

Epoch: 5| Step: 7
Training loss: 1.4819953441619873
Validation loss: 1.7800474801371176

Epoch: 5| Step: 8
Training loss: 1.2132917642593384
Validation loss: 1.822396711636615

Epoch: 5| Step: 9
Training loss: 1.0307693481445312
Validation loss: 1.8125694477429954

Epoch: 5| Step: 10
Training loss: 1.078452706336975
Validation loss: 1.832917962023007

Epoch: 339| Step: 0
Training loss: 1.2234437465667725
Validation loss: 1.7820655133134575

Epoch: 5| Step: 1
Training loss: 1.1765992641448975
Validation loss: 1.8616597178161784

Epoch: 5| Step: 2
Training loss: 1.3127925395965576
Validation loss: 1.8487380217480403

Epoch: 5| Step: 3
Training loss: 1.6616089344024658
Validation loss: 1.8303288003449798

Epoch: 5| Step: 4
Training loss: 0.8420103192329407
Validation loss: 1.8285833545910415

Epoch: 5| Step: 5
Training loss: 1.1889126300811768
Validation loss: 1.7831162457825036

Epoch: 5| Step: 6
Training loss: 1.098785161972046
Validation loss: 1.8259062984938264

Epoch: 5| Step: 7
Training loss: 1.827508568763733
Validation loss: 1.8434123775010467

Epoch: 5| Step: 8
Training loss: 1.781079649925232
Validation loss: 1.8235151742094307

Epoch: 5| Step: 9
Training loss: 1.310396432876587
Validation loss: 1.794307070393716

Epoch: 5| Step: 10
Training loss: 1.0240209102630615
Validation loss: 1.8388082006926179

Epoch: 340| Step: 0
Training loss: 1.4537228345870972
Validation loss: 1.7973496939546318

Epoch: 5| Step: 1
Training loss: 1.0493385791778564
Validation loss: 1.825158344802036

Epoch: 5| Step: 2
Training loss: 1.169907569885254
Validation loss: 1.8295513891404676

Epoch: 5| Step: 3
Training loss: 1.6459436416625977
Validation loss: 1.818868411484585

Epoch: 5| Step: 4
Training loss: 1.3891254663467407
Validation loss: 1.8197801779675227

Epoch: 5| Step: 5
Training loss: 1.2466957569122314
Validation loss: 1.8020084673358547

Epoch: 5| Step: 6
Training loss: 1.4359493255615234
Validation loss: 1.8393207544921546

Epoch: 5| Step: 7
Training loss: 0.9805029034614563
Validation loss: 1.8699143061073877

Epoch: 5| Step: 8
Training loss: 0.9562101364135742
Validation loss: 1.8602071141683927

Epoch: 5| Step: 9
Training loss: 1.731964349746704
Validation loss: 1.8438755184091546

Epoch: 5| Step: 10
Training loss: 1.5828170776367188
Validation loss: 1.8643934342168993

Epoch: 341| Step: 0
Training loss: 1.2176005840301514
Validation loss: 1.8330523788288076

Epoch: 5| Step: 1
Training loss: 1.4197638034820557
Validation loss: 1.8127282409257786

Epoch: 5| Step: 2
Training loss: 1.456919550895691
Validation loss: 1.7560562831099316

Epoch: 5| Step: 3
Training loss: 1.4583865404129028
Validation loss: 1.8379624043741534

Epoch: 5| Step: 4
Training loss: 1.0663387775421143
Validation loss: 1.7930416137941423

Epoch: 5| Step: 5
Training loss: 1.2483030557632446
Validation loss: 1.7637421302897955

Epoch: 5| Step: 6
Training loss: 1.738488793373108
Validation loss: 1.806859480437412

Epoch: 5| Step: 7
Training loss: 1.2086496353149414
Validation loss: 1.805215944526016

Epoch: 5| Step: 8
Training loss: 0.8611440658569336
Validation loss: 1.7797405258301766

Epoch: 5| Step: 9
Training loss: 1.41190505027771
Validation loss: 1.7720712141324115

Epoch: 5| Step: 10
Training loss: 1.3117350339889526
Validation loss: 1.779593321584886

Epoch: 342| Step: 0
Training loss: 1.311706304550171
Validation loss: 1.8257423523933656

Epoch: 5| Step: 1
Training loss: 1.3397672176361084
Validation loss: 1.8116155773080804

Epoch: 5| Step: 2
Training loss: 1.744091272354126
Validation loss: 1.8247644555184148

Epoch: 5| Step: 3
Training loss: 1.581965446472168
Validation loss: 1.828362423886535

Epoch: 5| Step: 4
Training loss: 1.2070376873016357
Validation loss: 1.830850903705884

Epoch: 5| Step: 5
Training loss: 1.4827277660369873
Validation loss: 1.8513276756450694

Epoch: 5| Step: 6
Training loss: 1.2084542512893677
Validation loss: 1.8543146335950462

Epoch: 5| Step: 7
Training loss: 1.3369648456573486
Validation loss: 1.8234935960462015

Epoch: 5| Step: 8
Training loss: 1.3531615734100342
Validation loss: 1.8517996649588309

Epoch: 5| Step: 9
Training loss: 0.690837025642395
Validation loss: 1.8222904602686565

Epoch: 5| Step: 10
Training loss: 0.9551247954368591
Validation loss: 1.795031819292294

Epoch: 343| Step: 0
Training loss: 1.2526618242263794
Validation loss: 1.825116031913347

Epoch: 5| Step: 1
Training loss: 1.259595513343811
Validation loss: 1.8086531444262433

Epoch: 5| Step: 2
Training loss: 1.5649207830429077
Validation loss: 1.7624248599493375

Epoch: 5| Step: 3
Training loss: 1.6774637699127197
Validation loss: 1.8598280747731526

Epoch: 5| Step: 4
Training loss: 1.1086536645889282
Validation loss: 1.8184911499741256

Epoch: 5| Step: 5
Training loss: 1.3605773448944092
Validation loss: 1.8487330611034105

Epoch: 5| Step: 6
Training loss: 0.9817487001419067
Validation loss: 1.8411215120746243

Epoch: 5| Step: 7
Training loss: 0.9861509203910828
Validation loss: 1.8557030693177254

Epoch: 5| Step: 8
Training loss: 1.3642923831939697
Validation loss: 1.8588962939477736

Epoch: 5| Step: 9
Training loss: 1.4224802255630493
Validation loss: 1.8059529219904253

Epoch: 5| Step: 10
Training loss: 1.360215187072754
Validation loss: 1.817801765216294

Epoch: 344| Step: 0
Training loss: 1.0969980955123901
Validation loss: 1.810597478702504

Epoch: 5| Step: 1
Training loss: 1.4317671060562134
Validation loss: 1.787322364827638

Epoch: 5| Step: 2
Training loss: 1.041851282119751
Validation loss: 1.8400187415461386

Epoch: 5| Step: 3
Training loss: 1.103482961654663
Validation loss: 1.814825237438243

Epoch: 5| Step: 4
Training loss: 0.9213302731513977
Validation loss: 1.8164164827715965

Epoch: 5| Step: 5
Training loss: 1.0232408046722412
Validation loss: 1.8046957844047136

Epoch: 5| Step: 6
Training loss: 2.013178825378418
Validation loss: 1.798849558317533

Epoch: 5| Step: 7
Training loss: 1.6312395334243774
Validation loss: 1.8209495480342577

Epoch: 5| Step: 8
Training loss: 1.1539415121078491
Validation loss: 1.8372752333200106

Epoch: 5| Step: 9
Training loss: 1.6904795169830322
Validation loss: 1.861077502209653

Epoch: 5| Step: 10
Training loss: 1.5071877241134644
Validation loss: 1.8502914636365828

Epoch: 345| Step: 0
Training loss: 1.4040216207504272
Validation loss: 1.8519320577703497

Epoch: 5| Step: 1
Training loss: 1.4989700317382812
Validation loss: 1.819631557310781

Epoch: 5| Step: 2
Training loss: 1.4223673343658447
Validation loss: 1.8900220496680147

Epoch: 5| Step: 3
Training loss: 1.0033862590789795
Validation loss: 1.8851896409065492

Epoch: 5| Step: 4
Training loss: 1.1973989009857178
Validation loss: 1.8684297992337136

Epoch: 5| Step: 5
Training loss: 0.9781950116157532
Validation loss: 1.8824253248912033

Epoch: 5| Step: 6
Training loss: 1.3176971673965454
Validation loss: 1.8888891179074523

Epoch: 5| Step: 7
Training loss: 1.4681718349456787
Validation loss: 1.805008021734094

Epoch: 5| Step: 8
Training loss: 1.713355302810669
Validation loss: 1.8281714121500652

Epoch: 5| Step: 9
Training loss: 1.2898942232131958
Validation loss: 1.7978262798760527

Epoch: 5| Step: 10
Training loss: 1.2614905834197998
Validation loss: 1.8298961154876217

Epoch: 346| Step: 0
Training loss: 1.2068687677383423
Validation loss: 1.8175398893253778

Epoch: 5| Step: 1
Training loss: 1.4101753234863281
Validation loss: 1.7905385366050146

Epoch: 5| Step: 2
Training loss: 1.4118918180465698
Validation loss: 1.7904094342262513

Epoch: 5| Step: 3
Training loss: 1.3143665790557861
Validation loss: 1.807568182227432

Epoch: 5| Step: 4
Training loss: 1.221060872077942
Validation loss: 1.824237960641102

Epoch: 5| Step: 5
Training loss: 1.2075071334838867
Validation loss: 1.8196606277137675

Epoch: 5| Step: 6
Training loss: 1.4284371137619019
Validation loss: 1.8084529061471262

Epoch: 5| Step: 7
Training loss: 1.4578323364257812
Validation loss: 1.8022804490981563

Epoch: 5| Step: 8
Training loss: 1.5389463901519775
Validation loss: 1.8223148033183107

Epoch: 5| Step: 9
Training loss: 1.4424618482589722
Validation loss: 1.8226479907189646

Epoch: 5| Step: 10
Training loss: 1.453102707862854
Validation loss: 1.8266068517520864

Epoch: 347| Step: 0
Training loss: 2.2209112644195557
Validation loss: 1.8868534693153955

Epoch: 5| Step: 1
Training loss: 1.5217571258544922
Validation loss: 1.8539539511485765

Epoch: 5| Step: 2
Training loss: 0.7466511130332947
Validation loss: 1.868453723128124

Epoch: 5| Step: 3
Training loss: 1.3500365018844604
Validation loss: 1.8748573282713532

Epoch: 5| Step: 4
Training loss: 1.3921921253204346
Validation loss: 1.8551325810852872

Epoch: 5| Step: 5
Training loss: 0.9238631129264832
Validation loss: 1.851784260042252

Epoch: 5| Step: 6
Training loss: 1.4563060998916626
Validation loss: 1.8459993882845807

Epoch: 5| Step: 7
Training loss: 1.6264092922210693
Validation loss: 1.8293664481050225

Epoch: 5| Step: 8
Training loss: 1.1834356784820557
Validation loss: 1.837796699616217

Epoch: 5| Step: 9
Training loss: 0.9794739484786987
Validation loss: 1.8563125312969249

Epoch: 5| Step: 10
Training loss: 1.0691584348678589
Validation loss: 1.8117148030188777

Epoch: 348| Step: 0
Training loss: 1.3466403484344482
Validation loss: 1.8084156974669425

Epoch: 5| Step: 1
Training loss: 1.4973429441452026
Validation loss: 1.8114829371052403

Epoch: 5| Step: 2
Training loss: 0.7564600706100464
Validation loss: 1.8443439416987921

Epoch: 5| Step: 3
Training loss: 1.5839154720306396
Validation loss: 1.8163591687397291

Epoch: 5| Step: 4
Training loss: 1.3921983242034912
Validation loss: 1.7577913704738821

Epoch: 5| Step: 5
Training loss: 1.2102041244506836
Validation loss: 1.7999929228136617

Epoch: 5| Step: 6
Training loss: 1.4019067287445068
Validation loss: 1.8166714099145704

Epoch: 5| Step: 7
Training loss: 1.1684901714324951
Validation loss: 1.8379732972832137

Epoch: 5| Step: 8
Training loss: 1.5498757362365723
Validation loss: 1.8181805431201894

Epoch: 5| Step: 9
Training loss: 0.8429366946220398
Validation loss: 1.7894318667791222

Epoch: 5| Step: 10
Training loss: 1.6707979440689087
Validation loss: 1.814913058793673

Epoch: 349| Step: 0
Training loss: 0.7398031949996948
Validation loss: 1.8860783320601269

Epoch: 5| Step: 1
Training loss: 1.3682706356048584
Validation loss: 1.8754798109813402

Epoch: 5| Step: 2
Training loss: 1.1847492456436157
Validation loss: 1.8975024582237325

Epoch: 5| Step: 3
Training loss: 1.6784213781356812
Validation loss: 1.877113607621962

Epoch: 5| Step: 4
Training loss: 1.4778059720993042
Validation loss: 1.869321543683288

Epoch: 5| Step: 5
Training loss: 0.8688223958015442
Validation loss: 1.8265094026442497

Epoch: 5| Step: 6
Training loss: 1.209285020828247
Validation loss: 1.8058950388303368

Epoch: 5| Step: 7
Training loss: 1.893576979637146
Validation loss: 1.8170670142737768

Epoch: 5| Step: 8
Training loss: 1.3337937593460083
Validation loss: 1.797832086522092

Epoch: 5| Step: 9
Training loss: 1.2312170267105103
Validation loss: 1.7690550511883152

Epoch: 5| Step: 10
Training loss: 1.6189218759536743
Validation loss: 1.7783219237481394

Epoch: 350| Step: 0
Training loss: 1.1010675430297852
Validation loss: 1.7976048377252394

Epoch: 5| Step: 1
Training loss: 0.7445554733276367
Validation loss: 1.8497706151777698

Epoch: 5| Step: 2
Training loss: 1.6323837041854858
Validation loss: 1.819792647515574

Epoch: 5| Step: 3
Training loss: 1.6016219854354858
Validation loss: 1.7700904953864314

Epoch: 5| Step: 4
Training loss: 1.2633397579193115
Validation loss: 1.8010380832097863

Epoch: 5| Step: 5
Training loss: 1.3525285720825195
Validation loss: 1.8387209984564012

Epoch: 5| Step: 6
Training loss: 1.624595046043396
Validation loss: 1.8482698548224665

Epoch: 5| Step: 7
Training loss: 1.1026558876037598
Validation loss: 1.8848666811502108

Epoch: 5| Step: 8
Training loss: 1.1088148355484009
Validation loss: 1.8960742604347967

Epoch: 5| Step: 9
Training loss: 1.5259075164794922
Validation loss: 1.902269959449768

Epoch: 5| Step: 10
Training loss: 1.1448376178741455
Validation loss: 1.9153100636697584

Epoch: 351| Step: 0
Training loss: 1.4628045558929443
Validation loss: 1.8412216248050812

Epoch: 5| Step: 1
Training loss: 1.299788475036621
Validation loss: 1.9154165483290149

Epoch: 5| Step: 2
Training loss: 1.0590736865997314
Validation loss: 1.8951068719228108

Epoch: 5| Step: 3
Training loss: 1.3707259893417358
Validation loss: 1.913076502020641

Epoch: 5| Step: 4
Training loss: 1.25736403465271
Validation loss: 1.8399983541939848

Epoch: 5| Step: 5
Training loss: 1.7915372848510742
Validation loss: 1.885050686456824

Epoch: 5| Step: 6
Training loss: 1.489739179611206
Validation loss: 1.8225475267697406

Epoch: 5| Step: 7
Training loss: 1.5560212135314941
Validation loss: 1.8279303363574448

Epoch: 5| Step: 8
Training loss: 0.9654420614242554
Validation loss: 1.8566650280388453

Epoch: 5| Step: 9
Training loss: 0.8563529849052429
Validation loss: 1.8123747200094245

Epoch: 5| Step: 10
Training loss: 1.2246519327163696
Validation loss: 1.7976198760412072

Epoch: 352| Step: 0
Training loss: 1.4297983646392822
Validation loss: 1.824372019819034

Epoch: 5| Step: 1
Training loss: 1.6342639923095703
Validation loss: 1.825773923627792

Epoch: 5| Step: 2
Training loss: 1.6474807262420654
Validation loss: 1.7776146601605158

Epoch: 5| Step: 3
Training loss: 0.7879624366760254
Validation loss: 1.7328274121848486

Epoch: 5| Step: 4
Training loss: 1.6147857904434204
Validation loss: 1.8198423308710898

Epoch: 5| Step: 5
Training loss: 0.9983895421028137
Validation loss: 1.7991640003778602

Epoch: 5| Step: 6
Training loss: 1.170907735824585
Validation loss: 1.7981403694357923

Epoch: 5| Step: 7
Training loss: 1.0794481039047241
Validation loss: 1.806535243988037

Epoch: 5| Step: 8
Training loss: 1.1416428089141846
Validation loss: 1.8067270889077136

Epoch: 5| Step: 9
Training loss: 1.8856569528579712
Validation loss: 1.847593807405041

Epoch: 5| Step: 10
Training loss: 0.959805428981781
Validation loss: 1.8058351432123492

Epoch: 353| Step: 0
Training loss: 1.4158117771148682
Validation loss: 1.876419303237751

Epoch: 5| Step: 1
Training loss: 1.2206612825393677
Validation loss: 1.8435512896507018

Epoch: 5| Step: 2
Training loss: 1.0602045059204102
Validation loss: 1.8131636804149998

Epoch: 5| Step: 3
Training loss: 1.0367059707641602
Validation loss: 1.8086603777382964

Epoch: 5| Step: 4
Training loss: 0.8661354184150696
Validation loss: 1.8662622359491163

Epoch: 5| Step: 5
Training loss: 1.7433137893676758
Validation loss: 1.8116801502884075

Epoch: 5| Step: 6
Training loss: 1.0502020120620728
Validation loss: 1.820401559593857

Epoch: 5| Step: 7
Training loss: 1.6189101934432983
Validation loss: 1.791335682715139

Epoch: 5| Step: 8
Training loss: 1.100951910018921
Validation loss: 1.8523969650268555

Epoch: 5| Step: 9
Training loss: 1.6467365026474
Validation loss: 1.8682517069642262

Epoch: 5| Step: 10
Training loss: 1.172104001045227
Validation loss: 1.8191264393509075

Epoch: 354| Step: 0
Training loss: 1.356339693069458
Validation loss: 1.83399679968434

Epoch: 5| Step: 1
Training loss: 0.9409133791923523
Validation loss: 1.8283313243619856

Epoch: 5| Step: 2
Training loss: 1.5993778705596924
Validation loss: 1.842127574387417

Epoch: 5| Step: 3
Training loss: 0.9442355036735535
Validation loss: 1.8280605731471893

Epoch: 5| Step: 4
Training loss: 1.1704262495040894
Validation loss: 1.8278748848104989

Epoch: 5| Step: 5
Training loss: 0.7918111085891724
Validation loss: 1.8357769186778734

Epoch: 5| Step: 6
Training loss: 1.6988351345062256
Validation loss: 1.836199192590611

Epoch: 5| Step: 7
Training loss: 1.278259515762329
Validation loss: 1.8529001371834868

Epoch: 5| Step: 8
Training loss: 1.633026123046875
Validation loss: 1.8184385427864649

Epoch: 5| Step: 9
Training loss: 1.3993216753005981
Validation loss: 1.8109109145338818

Epoch: 5| Step: 10
Training loss: 1.4100199937820435
Validation loss: 1.8349593352246028

Epoch: 355| Step: 0
Training loss: 1.8331760168075562
Validation loss: 1.8297310336943595

Epoch: 5| Step: 1
Training loss: 1.3533117771148682
Validation loss: 1.834535635927672

Epoch: 5| Step: 2
Training loss: 1.549019455909729
Validation loss: 1.8531991230544222

Epoch: 5| Step: 3
Training loss: 1.1658282279968262
Validation loss: 1.8836341122145295

Epoch: 5| Step: 4
Training loss: 1.1540844440460205
Validation loss: 1.8514306827258038

Epoch: 5| Step: 5
Training loss: 1.0317461490631104
Validation loss: 1.860228992277576

Epoch: 5| Step: 6
Training loss: 0.9720402956008911
Validation loss: 1.8202604504041775

Epoch: 5| Step: 7
Training loss: 1.017208456993103
Validation loss: 1.8080002236109909

Epoch: 5| Step: 8
Training loss: 1.1440595388412476
Validation loss: 1.811917192192488

Epoch: 5| Step: 9
Training loss: 1.1702954769134521
Validation loss: 1.8380280092198362

Epoch: 5| Step: 10
Training loss: 1.989092230796814
Validation loss: 1.8179772912815053

Epoch: 356| Step: 0
Training loss: 1.0509004592895508
Validation loss: 1.837776554528103

Epoch: 5| Step: 1
Training loss: 1.3818385601043701
Validation loss: 1.8434748752142793

Epoch: 5| Step: 2
Training loss: 0.855925440788269
Validation loss: 1.8112862738229896

Epoch: 5| Step: 3
Training loss: 1.528261423110962
Validation loss: 1.8671676356305358

Epoch: 5| Step: 4
Training loss: 1.5120567083358765
Validation loss: 1.786830412444248

Epoch: 5| Step: 5
Training loss: 1.0727691650390625
Validation loss: 1.798635543033641

Epoch: 5| Step: 6
Training loss: 1.5776522159576416
Validation loss: 1.7920524894550283

Epoch: 5| Step: 7
Training loss: 1.471776008605957
Validation loss: 1.8014977298757082

Epoch: 5| Step: 8
Training loss: 1.7601993083953857
Validation loss: 1.8646157223691222

Epoch: 5| Step: 9
Training loss: 1.1413389444351196
Validation loss: 1.8005651966218026

Epoch: 5| Step: 10
Training loss: 0.6917237639427185
Validation loss: 1.7859545247529143

Epoch: 357| Step: 0
Training loss: 1.257875919342041
Validation loss: 1.8347853204255462

Epoch: 5| Step: 1
Training loss: 1.2255122661590576
Validation loss: 1.825707027989049

Epoch: 5| Step: 2
Training loss: 1.283164143562317
Validation loss: 1.8118788824286511

Epoch: 5| Step: 3
Training loss: 1.1669436693191528
Validation loss: 1.8294731340100687

Epoch: 5| Step: 4
Training loss: 1.7551472187042236
Validation loss: 1.8496610323588054

Epoch: 5| Step: 5
Training loss: 0.9926465153694153
Validation loss: 1.8777779327925814

Epoch: 5| Step: 6
Training loss: 1.3659226894378662
Validation loss: 1.7858030514050556

Epoch: 5| Step: 7
Training loss: 1.203421950340271
Validation loss: 1.8511401011097817

Epoch: 5| Step: 8
Training loss: 1.3518106937408447
Validation loss: 1.8448117997056694

Epoch: 5| Step: 9
Training loss: 1.3739221096038818
Validation loss: 1.7880788785155102

Epoch: 5| Step: 10
Training loss: 1.2610505819320679
Validation loss: 1.8434693556959911

Epoch: 358| Step: 0
Training loss: 1.236730933189392
Validation loss: 1.835086787900617

Epoch: 5| Step: 1
Training loss: 1.3991568088531494
Validation loss: 1.7991465650578982

Epoch: 5| Step: 2
Training loss: 1.2537747621536255
Validation loss: 1.8600040353754514

Epoch: 5| Step: 3
Training loss: 1.5948052406311035
Validation loss: 1.7695923107926563

Epoch: 5| Step: 4
Training loss: 1.2537477016448975
Validation loss: 1.7950310425091816

Epoch: 5| Step: 5
Training loss: 1.1555945873260498
Validation loss: 1.805174216147392

Epoch: 5| Step: 6
Training loss: 1.297081708908081
Validation loss: 1.7964851023048483

Epoch: 5| Step: 7
Training loss: 1.1073987483978271
Validation loss: 1.854583809452672

Epoch: 5| Step: 8
Training loss: 1.2688920497894287
Validation loss: 1.8704625252754457

Epoch: 5| Step: 9
Training loss: 1.5528106689453125
Validation loss: 1.838099173320237

Epoch: 5| Step: 10
Training loss: 1.0650086402893066
Validation loss: 1.8046002285454863

Epoch: 359| Step: 0
Training loss: 0.9880008697509766
Validation loss: 1.8311834732691448

Epoch: 5| Step: 1
Training loss: 1.0191819667816162
Validation loss: 1.729327078788511

Epoch: 5| Step: 2
Training loss: 1.2648067474365234
Validation loss: 1.8413994030285907

Epoch: 5| Step: 3
Training loss: 1.4909018278121948
Validation loss: 1.7901470443253875

Epoch: 5| Step: 4
Training loss: 1.6113020181655884
Validation loss: 1.7859325562753985

Epoch: 5| Step: 5
Training loss: 1.3397386074066162
Validation loss: 1.8159953201970747

Epoch: 5| Step: 6
Training loss: 1.1882092952728271
Validation loss: 1.7989954115242086

Epoch: 5| Step: 7
Training loss: 1.251694917678833
Validation loss: 1.8391471011664278

Epoch: 5| Step: 8
Training loss: 1.2048949003219604
Validation loss: 1.82121794198149

Epoch: 5| Step: 9
Training loss: 1.2642184495925903
Validation loss: 1.8040255115878197

Epoch: 5| Step: 10
Training loss: 1.1836376190185547
Validation loss: 1.8501025886945828

Epoch: 360| Step: 0
Training loss: 1.2216097116470337
Validation loss: 1.8307179968844178

Epoch: 5| Step: 1
Training loss: 0.6155480146408081
Validation loss: 1.808930004796674

Epoch: 5| Step: 2
Training loss: 1.3463027477264404
Validation loss: 1.8030974300958778

Epoch: 5| Step: 3
Training loss: 1.0695806741714478
Validation loss: 1.8315855482573151

Epoch: 5| Step: 4
Training loss: 1.5917099714279175
Validation loss: 1.8348341000977384

Epoch: 5| Step: 5
Training loss: 1.4981447458267212
Validation loss: 1.779447929833525

Epoch: 5| Step: 6
Training loss: 1.5881173610687256
Validation loss: 1.8316949413668724

Epoch: 5| Step: 7
Training loss: 1.1505897045135498
Validation loss: 1.8356755933453959

Epoch: 5| Step: 8
Training loss: 0.8983939290046692
Validation loss: 1.8267328892984698

Epoch: 5| Step: 9
Training loss: 1.3390758037567139
Validation loss: 1.84701035868737

Epoch: 5| Step: 10
Training loss: 1.5191264152526855
Validation loss: 1.8241158826376802

Epoch: 361| Step: 0
Training loss: 1.3582751750946045
Validation loss: 1.8319057777363768

Epoch: 5| Step: 1
Training loss: 1.0327496528625488
Validation loss: 1.8227670679810226

Epoch: 5| Step: 2
Training loss: 1.433070421218872
Validation loss: 1.824597873995381

Epoch: 5| Step: 3
Training loss: 1.1516402959823608
Validation loss: 1.7930819642159246

Epoch: 5| Step: 4
Training loss: 1.4427635669708252
Validation loss: 1.8594530013299757

Epoch: 5| Step: 5
Training loss: 1.2858318090438843
Validation loss: 1.7928578110151394

Epoch: 5| Step: 6
Training loss: 1.1190755367279053
Validation loss: 1.8301016835756199

Epoch: 5| Step: 7
Training loss: 1.3721649646759033
Validation loss: 1.8173764367257395

Epoch: 5| Step: 8
Training loss: 1.4117584228515625
Validation loss: 1.831752807863297

Epoch: 5| Step: 9
Training loss: 1.3869370222091675
Validation loss: 1.8293938598325175

Epoch: 5| Step: 10
Training loss: 1.2865104675292969
Validation loss: 1.7933863157867103

Epoch: 362| Step: 0
Training loss: 1.7367607355117798
Validation loss: 1.861425684344384

Epoch: 5| Step: 1
Training loss: 1.6455888748168945
Validation loss: 1.7866973607770857

Epoch: 5| Step: 2
Training loss: 0.7277372479438782
Validation loss: 1.8558254716216878

Epoch: 5| Step: 3
Training loss: 1.6829726696014404
Validation loss: 1.8481072238696519

Epoch: 5| Step: 4
Training loss: 0.9115933179855347
Validation loss: 1.8547155434085476

Epoch: 5| Step: 5
Training loss: 0.8901681900024414
Validation loss: 1.843711491554014

Epoch: 5| Step: 6
Training loss: 1.565194845199585
Validation loss: 1.9243199389467958

Epoch: 5| Step: 7
Training loss: 1.2938482761383057
Validation loss: 1.8578613265868156

Epoch: 5| Step: 8
Training loss: 0.8403081893920898
Validation loss: 1.8923921405628163

Epoch: 5| Step: 9
Training loss: 1.395559549331665
Validation loss: 1.8017116285139514

Epoch: 5| Step: 10
Training loss: 1.1926096677780151
Validation loss: 1.8161992078186364

Epoch: 363| Step: 0
Training loss: 1.1818290948867798
Validation loss: 1.8393627212893577

Epoch: 5| Step: 1
Training loss: 1.3110640048980713
Validation loss: 1.8936181606784943

Epoch: 5| Step: 2
Training loss: 0.9989892244338989
Validation loss: 1.814299403980214

Epoch: 5| Step: 3
Training loss: 1.504162311553955
Validation loss: 1.7936557467265795

Epoch: 5| Step: 4
Training loss: 1.471022367477417
Validation loss: 1.865341886397331

Epoch: 5| Step: 5
Training loss: 0.6378511190414429
Validation loss: 1.855817082107708

Epoch: 5| Step: 6
Training loss: 0.9801732897758484
Validation loss: 1.8135538754924652

Epoch: 5| Step: 7
Training loss: 1.3604611158370972
Validation loss: 1.8190955667085544

Epoch: 5| Step: 8
Training loss: 1.3038349151611328
Validation loss: 1.7930228966538624

Epoch: 5| Step: 9
Training loss: 1.905480146408081
Validation loss: 1.7817340884157407

Epoch: 5| Step: 10
Training loss: 1.284806251525879
Validation loss: 1.8234577268682501

Epoch: 364| Step: 0
Training loss: 1.1134296655654907
Validation loss: 1.814713203778831

Epoch: 5| Step: 1
Training loss: 1.0882302522659302
Validation loss: 1.882124779044941

Epoch: 5| Step: 2
Training loss: 1.052929162979126
Validation loss: 1.8497611297074186

Epoch: 5| Step: 3
Training loss: 1.674375295639038
Validation loss: 1.7937963239608272

Epoch: 5| Step: 4
Training loss: 1.3401414155960083
Validation loss: 1.8110847357780702

Epoch: 5| Step: 5
Training loss: 1.5782301425933838
Validation loss: 1.831376955073367

Epoch: 5| Step: 6
Training loss: 1.3269556760787964
Validation loss: 1.7970867528710315

Epoch: 5| Step: 7
Training loss: 0.8846856951713562
Validation loss: 1.8349903283580657

Epoch: 5| Step: 8
Training loss: 1.519022822380066
Validation loss: 1.8515842447998703

Epoch: 5| Step: 9
Training loss: 1.1678435802459717
Validation loss: 1.8474864562352498

Epoch: 5| Step: 10
Training loss: 1.1713093519210815
Validation loss: 1.8486201763153076

Epoch: 365| Step: 0
Training loss: 1.3693721294403076
Validation loss: 1.8275105158487956

Epoch: 5| Step: 1
Training loss: 0.9879158735275269
Validation loss: 1.817198602102136

Epoch: 5| Step: 2
Training loss: 1.0899752378463745
Validation loss: 1.8295236428578694

Epoch: 5| Step: 3
Training loss: 1.2853949069976807
Validation loss: 1.8642465158175396

Epoch: 5| Step: 4
Training loss: 1.386372685432434
Validation loss: 1.894459173243533

Epoch: 5| Step: 5
Training loss: 1.4137210845947266
Validation loss: 1.8144305688078686

Epoch: 5| Step: 6
Training loss: 1.3421903848648071
Validation loss: 1.865700997332091

Epoch: 5| Step: 7
Training loss: 1.4384461641311646
Validation loss: 1.8419359601953977

Epoch: 5| Step: 8
Training loss: 1.323725700378418
Validation loss: 1.8425425790971326

Epoch: 5| Step: 9
Training loss: 1.302185297012329
Validation loss: 1.7956769684309601

Epoch: 5| Step: 10
Training loss: 1.2886247634887695
Validation loss: 1.82973067222103

Epoch: 366| Step: 0
Training loss: 1.4370185136795044
Validation loss: 1.8217882328135993

Epoch: 5| Step: 1
Training loss: 0.9847549200057983
Validation loss: 1.7957431372775827

Epoch: 5| Step: 2
Training loss: 1.1995028257369995
Validation loss: 1.7946634959149104

Epoch: 5| Step: 3
Training loss: 1.3062082529067993
Validation loss: 1.809563902116591

Epoch: 5| Step: 4
Training loss: 1.4142210483551025
Validation loss: 1.8060295415180985

Epoch: 5| Step: 5
Training loss: 0.8489370346069336
Validation loss: 1.8363235560796594

Epoch: 5| Step: 6
Training loss: 1.2956936359405518
Validation loss: 1.8473680327015538

Epoch: 5| Step: 7
Training loss: 1.2109228372573853
Validation loss: 1.8113001777279762

Epoch: 5| Step: 8
Training loss: 1.8796600103378296
Validation loss: 1.8278277215137277

Epoch: 5| Step: 9
Training loss: 1.0413538217544556
Validation loss: 1.8420786485877088

Epoch: 5| Step: 10
Training loss: 1.4227790832519531
Validation loss: 1.8665697369524228

Epoch: 367| Step: 0
Training loss: 1.4080545902252197
Validation loss: 1.8595838392934492

Epoch: 5| Step: 1
Training loss: 1.4367940425872803
Validation loss: 1.8671725667932981

Epoch: 5| Step: 2
Training loss: 1.1272456645965576
Validation loss: 1.8856819496359876

Epoch: 5| Step: 3
Training loss: 0.9520775675773621
Validation loss: 1.8592773816918815

Epoch: 5| Step: 4
Training loss: 1.0308102369308472
Validation loss: 1.835221944316741

Epoch: 5| Step: 5
Training loss: 1.4922828674316406
Validation loss: 1.8238720534950175

Epoch: 5| Step: 6
Training loss: 0.6886197328567505
Validation loss: 1.8319657143726145

Epoch: 5| Step: 7
Training loss: 1.308793067932129
Validation loss: 1.83120406827619

Epoch: 5| Step: 8
Training loss: 0.9603767395019531
Validation loss: 1.8067755955521778

Epoch: 5| Step: 9
Training loss: 1.7498019933700562
Validation loss: 1.8296126704062186

Epoch: 5| Step: 10
Training loss: 1.4450703859329224
Validation loss: 1.8158082603126444

Epoch: 368| Step: 0
Training loss: 1.0547785758972168
Validation loss: 1.815277789228706

Epoch: 5| Step: 1
Training loss: 1.1929212808609009
Validation loss: 1.7819711662107898

Epoch: 5| Step: 2
Training loss: 1.547330617904663
Validation loss: 1.8381882982869302

Epoch: 5| Step: 3
Training loss: 1.1545699834823608
Validation loss: 1.8596575926708918

Epoch: 5| Step: 4
Training loss: 1.4967429637908936
Validation loss: 1.8100609830630723

Epoch: 5| Step: 5
Training loss: 1.2765780687332153
Validation loss: 1.855600150682593

Epoch: 5| Step: 6
Training loss: 1.421987771987915
Validation loss: 1.9002940475299794

Epoch: 5| Step: 7
Training loss: 1.1749523878097534
Validation loss: 1.8354720941153906

Epoch: 5| Step: 8
Training loss: 1.1837103366851807
Validation loss: 1.843761562019266

Epoch: 5| Step: 9
Training loss: 1.2921764850616455
Validation loss: 1.8339315345210414

Epoch: 5| Step: 10
Training loss: 1.1544694900512695
Validation loss: 1.8364001422800043

Epoch: 369| Step: 0
Training loss: 1.244600534439087
Validation loss: 1.7969025463186286

Epoch: 5| Step: 1
Training loss: 1.3762248754501343
Validation loss: 1.8276410538663146

Epoch: 5| Step: 2
Training loss: 0.8376884460449219
Validation loss: 1.790121551482908

Epoch: 5| Step: 3
Training loss: 1.3466899394989014
Validation loss: 1.7882544218852956

Epoch: 5| Step: 4
Training loss: 1.842268705368042
Validation loss: 1.7884257506298762

Epoch: 5| Step: 5
Training loss: 1.2025657892227173
Validation loss: 1.8057747374298752

Epoch: 5| Step: 6
Training loss: 1.596092700958252
Validation loss: 1.787383364092919

Epoch: 5| Step: 7
Training loss: 1.448919653892517
Validation loss: 1.8078604154689337

Epoch: 5| Step: 8
Training loss: 1.1270002126693726
Validation loss: 1.79519530265562

Epoch: 5| Step: 9
Training loss: 1.0142492055892944
Validation loss: 1.8706074055805002

Epoch: 5| Step: 10
Training loss: 0.8067967295646667
Validation loss: 1.8247034511258524

Epoch: 370| Step: 0
Training loss: 1.3528339862823486
Validation loss: 1.8695235906108734

Epoch: 5| Step: 1
Training loss: 0.6944643259048462
Validation loss: 1.8434048365521174

Epoch: 5| Step: 2
Training loss: 1.4468998908996582
Validation loss: 1.8160761351226478

Epoch: 5| Step: 3
Training loss: 1.3581864833831787
Validation loss: 1.8593802772542483

Epoch: 5| Step: 4
Training loss: 1.6993319988250732
Validation loss: 1.8425888861379316

Epoch: 5| Step: 5
Training loss: 1.0041496753692627
Validation loss: 1.879902708914972

Epoch: 5| Step: 6
Training loss: 1.101267695426941
Validation loss: 1.816754679526052

Epoch: 5| Step: 7
Training loss: 1.8987970352172852
Validation loss: 1.8739309708277385

Epoch: 5| Step: 8
Training loss: 1.4029635190963745
Validation loss: 1.8211224745678645

Epoch: 5| Step: 9
Training loss: 0.9364506006240845
Validation loss: 1.8317814360382736

Epoch: 5| Step: 10
Training loss: 0.9801408052444458
Validation loss: 1.8080633609525618

Epoch: 371| Step: 0
Training loss: 1.4380652904510498
Validation loss: 1.8383081472048195

Epoch: 5| Step: 1
Training loss: 1.176587700843811
Validation loss: 1.8322662666279783

Epoch: 5| Step: 2
Training loss: 1.3232465982437134
Validation loss: 1.82756342041877

Epoch: 5| Step: 3
Training loss: 1.6112200021743774
Validation loss: 1.8485641774310861

Epoch: 5| Step: 4
Training loss: 1.4828362464904785
Validation loss: 1.8271538172998736

Epoch: 5| Step: 5
Training loss: 0.5354938507080078
Validation loss: 1.8541585168530863

Epoch: 5| Step: 6
Training loss: 1.2006362676620483
Validation loss: 1.8491090574572164

Epoch: 5| Step: 7
Training loss: 1.364249587059021
Validation loss: 1.849461268353206

Epoch: 5| Step: 8
Training loss: 1.1734716892242432
Validation loss: 1.8558662117168467

Epoch: 5| Step: 9
Training loss: 1.4370448589324951
Validation loss: 1.8459654238916212

Epoch: 5| Step: 10
Training loss: 1.2459392547607422
Validation loss: 1.8664657390245827

Epoch: 372| Step: 0
Training loss: 1.5964248180389404
Validation loss: 1.8809707113491592

Epoch: 5| Step: 1
Training loss: 1.1145813465118408
Validation loss: 1.8066319009309173

Epoch: 5| Step: 2
Training loss: 1.422401785850525
Validation loss: 1.7915039318864063

Epoch: 5| Step: 3
Training loss: 1.2006019353866577
Validation loss: 1.819213564677905

Epoch: 5| Step: 4
Training loss: 0.7339283227920532
Validation loss: 1.814388180291781

Epoch: 5| Step: 5
Training loss: 1.1735994815826416
Validation loss: 1.8351198345102289

Epoch: 5| Step: 6
Training loss: 1.3830440044403076
Validation loss: 1.8539477035563479

Epoch: 5| Step: 7
Training loss: 1.8209120035171509
Validation loss: 1.8057903999923377

Epoch: 5| Step: 8
Training loss: 1.1040875911712646
Validation loss: 1.824858929521294

Epoch: 5| Step: 9
Training loss: 1.2858686447143555
Validation loss: 1.8472694748191423

Epoch: 5| Step: 10
Training loss: 0.9227097630500793
Validation loss: 1.8200753119684034

Epoch: 373| Step: 0
Training loss: 1.2398197650909424
Validation loss: 1.8559105575725596

Epoch: 5| Step: 1
Training loss: 0.9876155853271484
Validation loss: 1.8094734748204548

Epoch: 5| Step: 2
Training loss: 1.4327079057693481
Validation loss: 1.8269929603863788

Epoch: 5| Step: 3
Training loss: 1.0499632358551025
Validation loss: 1.8051745763389013

Epoch: 5| Step: 4
Training loss: 1.5118106603622437
Validation loss: 1.8390244104528939

Epoch: 5| Step: 5
Training loss: 1.4545018672943115
Validation loss: 1.8106388097168298

Epoch: 5| Step: 6
Training loss: 1.5291513204574585
Validation loss: 1.8596192752161333

Epoch: 5| Step: 7
Training loss: 0.6944128274917603
Validation loss: 1.8757067239412697

Epoch: 5| Step: 8
Training loss: 1.4932912588119507
Validation loss: 1.8739119575869652

Epoch: 5| Step: 9
Training loss: 1.2860199213027954
Validation loss: 1.8880277731085335

Epoch: 5| Step: 10
Training loss: 0.8823543190956116
Validation loss: 1.8199432101300967

Epoch: 374| Step: 0
Training loss: 1.800381064414978
Validation loss: 1.8120294975978073

Epoch: 5| Step: 1
Training loss: 1.055085301399231
Validation loss: 1.868104327109552

Epoch: 5| Step: 2
Training loss: 1.3172582387924194
Validation loss: 1.8617891778228104

Epoch: 5| Step: 3
Training loss: 1.3205912113189697
Validation loss: 1.8263295773536927

Epoch: 5| Step: 4
Training loss: 1.1489942073822021
Validation loss: 1.8093746785194642

Epoch: 5| Step: 5
Training loss: 1.1180906295776367
Validation loss: 1.8219244005859538

Epoch: 5| Step: 6
Training loss: 0.938956618309021
Validation loss: 1.8150961463169386

Epoch: 5| Step: 7
Training loss: 1.656854271888733
Validation loss: 1.8076806478602911

Epoch: 5| Step: 8
Training loss: 1.1638025045394897
Validation loss: 1.7980509470867854

Epoch: 5| Step: 9
Training loss: 1.0954601764678955
Validation loss: 1.813424994868617

Epoch: 5| Step: 10
Training loss: 0.9134071469306946
Validation loss: 1.7869941085897467

Epoch: 375| Step: 0
Training loss: 1.4056634902954102
Validation loss: 1.8294335719077819

Epoch: 5| Step: 1
Training loss: 1.290614128112793
Validation loss: 1.816559914619692

Epoch: 5| Step: 2
Training loss: 1.4350135326385498
Validation loss: 1.834489901860555

Epoch: 5| Step: 3
Training loss: 1.3395984172821045
Validation loss: 1.8345829697065457

Epoch: 5| Step: 4
Training loss: 1.4341309070587158
Validation loss: 1.8282429992511708

Epoch: 5| Step: 5
Training loss: 0.9058621525764465
Validation loss: 1.809329580235225

Epoch: 5| Step: 6
Training loss: 1.2689893245697021
Validation loss: 1.8465904881877284

Epoch: 5| Step: 7
Training loss: 0.695338785648346
Validation loss: 1.9058048109854422

Epoch: 5| Step: 8
Training loss: 1.39127516746521
Validation loss: 1.8734274243795743

Epoch: 5| Step: 9
Training loss: 1.0418777465820312
Validation loss: 1.8609230723432315

Epoch: 5| Step: 10
Training loss: 1.4576876163482666
Validation loss: 1.8662910769062657

Epoch: 376| Step: 0
Training loss: 1.5695111751556396
Validation loss: 1.847238067657717

Epoch: 5| Step: 1
Training loss: 1.187432885169983
Validation loss: 1.8103528689312678

Epoch: 5| Step: 2
Training loss: 1.318105697631836
Validation loss: 1.8277251387155184

Epoch: 5| Step: 3
Training loss: 1.3920246362686157
Validation loss: 1.8249347953386204

Epoch: 5| Step: 4
Training loss: 1.1791353225708008
Validation loss: 1.872668509842247

Epoch: 5| Step: 5
Training loss: 1.1884515285491943
Validation loss: 1.7937146745702273

Epoch: 5| Step: 6
Training loss: 1.271179437637329
Validation loss: 1.8236280474611508

Epoch: 5| Step: 7
Training loss: 1.4515163898468018
Validation loss: 1.849917032385385

Epoch: 5| Step: 8
Training loss: 1.0159275531768799
Validation loss: 1.7997325927980485

Epoch: 5| Step: 9
Training loss: 1.1168012619018555
Validation loss: 1.7886735393155007

Epoch: 5| Step: 10
Training loss: 0.7211134433746338
Validation loss: 1.8415843671368015

Epoch: 377| Step: 0
Training loss: 0.9873958826065063
Validation loss: 1.8546820058617541

Epoch: 5| Step: 1
Training loss: 1.0845727920532227
Validation loss: 1.8556071930034186

Epoch: 5| Step: 2
Training loss: 1.2887654304504395
Validation loss: 1.8908684817693566

Epoch: 5| Step: 3
Training loss: 1.454148292541504
Validation loss: 1.8722555291268133

Epoch: 5| Step: 4
Training loss: 1.1893706321716309
Validation loss: 1.8503923659683557

Epoch: 5| Step: 5
Training loss: 1.1634342670440674
Validation loss: 1.9249445340966667

Epoch: 5| Step: 6
Training loss: 1.6558300256729126
Validation loss: 1.9132506296198855

Epoch: 5| Step: 7
Training loss: 1.0619003772735596
Validation loss: 1.8854789785159531

Epoch: 5| Step: 8
Training loss: 1.0280029773712158
Validation loss: 1.8870814102952198

Epoch: 5| Step: 9
Training loss: 1.493456244468689
Validation loss: 1.8588490152871737

Epoch: 5| Step: 10
Training loss: 1.5318938493728638
Validation loss: 1.8304085910961192

Epoch: 378| Step: 0
Training loss: 1.7983430624008179
Validation loss: 1.836763802395072

Epoch: 5| Step: 1
Training loss: 1.0099282264709473
Validation loss: 1.8357697276658909

Epoch: 5| Step: 2
Training loss: 1.2038739919662476
Validation loss: 1.8192654527643675

Epoch: 5| Step: 3
Training loss: 0.8535676002502441
Validation loss: 1.7891186437299174

Epoch: 5| Step: 4
Training loss: 1.4927570819854736
Validation loss: 1.8144914655275242

Epoch: 5| Step: 5
Training loss: 1.3752076625823975
Validation loss: 1.8248014655164493

Epoch: 5| Step: 6
Training loss: 1.883161187171936
Validation loss: 1.835732417721902

Epoch: 5| Step: 7
Training loss: 0.7987793684005737
Validation loss: 1.828282170398261

Epoch: 5| Step: 8
Training loss: 1.0725091695785522
Validation loss: 1.8215540724415933

Epoch: 5| Step: 9
Training loss: 1.2196252346038818
Validation loss: 1.8630801900740592

Epoch: 5| Step: 10
Training loss: 0.9334660172462463
Validation loss: 1.8412219875602311

Epoch: 379| Step: 0
Training loss: 0.7357281446456909
Validation loss: 1.817430034760506

Epoch: 5| Step: 1
Training loss: 1.8137859106063843
Validation loss: 1.829644380077239

Epoch: 5| Step: 2
Training loss: 0.9755798578262329
Validation loss: 1.831126054128011

Epoch: 5| Step: 3
Training loss: 1.3231065273284912
Validation loss: 1.8080333266206967

Epoch: 5| Step: 4
Training loss: 1.260450839996338
Validation loss: 1.8251232959890877

Epoch: 5| Step: 5
Training loss: 1.2169749736785889
Validation loss: 1.872518982938541

Epoch: 5| Step: 6
Training loss: 1.201677918434143
Validation loss: 1.8079303567127516

Epoch: 5| Step: 7
Training loss: 1.0236599445343018
Validation loss: 1.8211333059495496

Epoch: 5| Step: 8
Training loss: 0.9217262268066406
Validation loss: 1.8333336127701627

Epoch: 5| Step: 9
Training loss: 1.3494195938110352
Validation loss: 1.8061274251630228

Epoch: 5| Step: 10
Training loss: 1.6534147262573242
Validation loss: 1.8625499740723641

Epoch: 380| Step: 0
Training loss: 1.0000312328338623
Validation loss: 1.847381967370228

Epoch: 5| Step: 1
Training loss: 1.195502519607544
Validation loss: 1.8639692606464509

Epoch: 5| Step: 2
Training loss: 1.1167641878128052
Validation loss: 1.8657445753774335

Epoch: 5| Step: 3
Training loss: 1.5417406558990479
Validation loss: 1.8563168753859818

Epoch: 5| Step: 4
Training loss: 1.6039354801177979
Validation loss: 1.8606577047737696

Epoch: 5| Step: 5
Training loss: 1.3955529928207397
Validation loss: 1.8699356573884205

Epoch: 5| Step: 6
Training loss: 1.1038312911987305
Validation loss: 1.854868063362696

Epoch: 5| Step: 7
Training loss: 1.1323386430740356
Validation loss: 1.860239028930664

Epoch: 5| Step: 8
Training loss: 1.3701562881469727
Validation loss: 1.782495319202382

Epoch: 5| Step: 9
Training loss: 0.9668523669242859
Validation loss: 1.8383501498929915

Epoch: 5| Step: 10
Training loss: 1.368069052696228
Validation loss: 1.8221992561894078

Epoch: 381| Step: 0
Training loss: 0.8919426202774048
Validation loss: 1.8085250828855781

Epoch: 5| Step: 1
Training loss: 0.9955376386642456
Validation loss: 1.845341436324581

Epoch: 5| Step: 2
Training loss: 1.4232666492462158
Validation loss: 1.7678580816074083

Epoch: 5| Step: 3
Training loss: 1.3931461572647095
Validation loss: 1.8298672636349995

Epoch: 5| Step: 4
Training loss: 0.7959579229354858
Validation loss: 1.8174747907987205

Epoch: 5| Step: 5
Training loss: 1.3565088510513306
Validation loss: 1.8213994426112021

Epoch: 5| Step: 6
Training loss: 1.5027945041656494
Validation loss: 1.8328182543477705

Epoch: 5| Step: 7
Training loss: 1.7735140323638916
Validation loss: 1.8476726060272546

Epoch: 5| Step: 8
Training loss: 1.360342264175415
Validation loss: 1.8444448517214866

Epoch: 5| Step: 9
Training loss: 0.9883316159248352
Validation loss: 1.874945976400888

Epoch: 5| Step: 10
Training loss: 1.2083630561828613
Validation loss: 1.8833572595350203

Epoch: 382| Step: 0
Training loss: 1.5523250102996826
Validation loss: 1.9347414278214978

Epoch: 5| Step: 1
Training loss: 1.1673674583435059
Validation loss: 1.885612149392405

Epoch: 5| Step: 2
Training loss: 0.9814159274101257
Validation loss: 1.90512970442413

Epoch: 5| Step: 3
Training loss: 1.3508405685424805
Validation loss: 1.9086915011047034

Epoch: 5| Step: 4
Training loss: 1.215644121170044
Validation loss: 1.8617890445134972

Epoch: 5| Step: 5
Training loss: 1.472660779953003
Validation loss: 1.8542244665084346

Epoch: 5| Step: 6
Training loss: 1.3535914421081543
Validation loss: 1.8462804709711382

Epoch: 5| Step: 7
Training loss: 0.7986548542976379
Validation loss: 1.8502356698436122

Epoch: 5| Step: 8
Training loss: 1.533774733543396
Validation loss: 1.8303612701354488

Epoch: 5| Step: 9
Training loss: 0.6865332722663879
Validation loss: 1.8027120328718615

Epoch: 5| Step: 10
Training loss: 1.3734323978424072
Validation loss: 1.8012509166553456

Epoch: 383| Step: 0
Training loss: 1.3994346857070923
Validation loss: 1.8040463706498504

Epoch: 5| Step: 1
Training loss: 1.6782119274139404
Validation loss: 1.8041917124102194

Epoch: 5| Step: 2
Training loss: 0.702018141746521
Validation loss: 1.8110130397222375

Epoch: 5| Step: 3
Training loss: 1.2120599746704102
Validation loss: 1.811693267155719

Epoch: 5| Step: 4
Training loss: 1.353583574295044
Validation loss: 1.8154993569979103

Epoch: 5| Step: 5
Training loss: 1.10378897190094
Validation loss: 1.83148604823697

Epoch: 5| Step: 6
Training loss: 1.2496776580810547
Validation loss: 1.8509132169908094

Epoch: 5| Step: 7
Training loss: 1.3360464572906494
Validation loss: 1.8120091192183956

Epoch: 5| Step: 8
Training loss: 1.0324252843856812
Validation loss: 1.807165120237617

Epoch: 5| Step: 9
Training loss: 1.1788148880004883
Validation loss: 1.812472911291225

Epoch: 5| Step: 10
Training loss: 0.9150053858757019
Validation loss: 1.8157222213283661

Epoch: 384| Step: 0
Training loss: 1.4284471273422241
Validation loss: 1.802101812055034

Epoch: 5| Step: 1
Training loss: 1.270071268081665
Validation loss: 1.8141429655013546

Epoch: 5| Step: 2
Training loss: 0.9939278364181519
Validation loss: 1.8833006505043275

Epoch: 5| Step: 3
Training loss: 1.0528801679611206
Validation loss: 1.866026597638284

Epoch: 5| Step: 4
Training loss: 0.9983234405517578
Validation loss: 1.8691704286042081

Epoch: 5| Step: 5
Training loss: 1.8208162784576416
Validation loss: 1.8980812026608376

Epoch: 5| Step: 6
Training loss: 0.8656195402145386
Validation loss: 1.8527793269003592

Epoch: 5| Step: 7
Training loss: 1.0966756343841553
Validation loss: 1.903224088812387

Epoch: 5| Step: 8
Training loss: 1.103954792022705
Validation loss: 1.8662777844295706

Epoch: 5| Step: 9
Training loss: 1.24276602268219
Validation loss: 1.9101905015207106

Epoch: 5| Step: 10
Training loss: 1.4168590307235718
Validation loss: 1.8706084374458558

Epoch: 385| Step: 0
Training loss: 1.1441115140914917
Validation loss: 1.8746011462262882

Epoch: 5| Step: 1
Training loss: 0.7773022651672363
Validation loss: 1.8787810187185965

Epoch: 5| Step: 2
Training loss: 1.5002833604812622
Validation loss: 1.8343061144633959

Epoch: 5| Step: 3
Training loss: 0.8550583124160767
Validation loss: 1.8515078457452918

Epoch: 5| Step: 4
Training loss: 0.9594553709030151
Validation loss: 1.8395587218705045

Epoch: 5| Step: 5
Training loss: 0.8350920677185059
Validation loss: 1.8147911640905565

Epoch: 5| Step: 6
Training loss: 1.0990982055664062
Validation loss: 1.7881455805993849

Epoch: 5| Step: 7
Training loss: 1.4629948139190674
Validation loss: 1.817467669005035

Epoch: 5| Step: 8
Training loss: 1.1468626260757446
Validation loss: 1.8477758566538494

Epoch: 5| Step: 9
Training loss: 2.119746685028076
Validation loss: 1.8501655632449734

Epoch: 5| Step: 10
Training loss: 1.938434362411499
Validation loss: 1.8474080857410227

Epoch: 386| Step: 0
Training loss: 1.1250038146972656
Validation loss: 1.8402195015261251

Epoch: 5| Step: 1
Training loss: 1.0062534809112549
Validation loss: 1.8216081255225725

Epoch: 5| Step: 2
Training loss: 1.3859907388687134
Validation loss: 1.7974922631376533

Epoch: 5| Step: 3
Training loss: 1.2421293258666992
Validation loss: 1.861914752632059

Epoch: 5| Step: 4
Training loss: 0.894844651222229
Validation loss: 1.8046527806148733

Epoch: 5| Step: 5
Training loss: 1.3955568075180054
Validation loss: 1.8428458347115466

Epoch: 5| Step: 6
Training loss: 1.530444860458374
Validation loss: 1.8297092581308017

Epoch: 5| Step: 7
Training loss: 1.5645442008972168
Validation loss: 1.8742478368102864

Epoch: 5| Step: 8
Training loss: 1.4308974742889404
Validation loss: 1.879766898770486

Epoch: 5| Step: 9
Training loss: 1.0313831567764282
Validation loss: 1.8656140424871956

Epoch: 5| Step: 10
Training loss: 0.913628101348877
Validation loss: 1.8476279704801497

Epoch: 387| Step: 0
Training loss: 1.1713874340057373
Validation loss: 1.8599520280796995

Epoch: 5| Step: 1
Training loss: 1.2397023439407349
Validation loss: 1.833354598732405

Epoch: 5| Step: 2
Training loss: 1.0902913808822632
Validation loss: 1.8140784014937699

Epoch: 5| Step: 3
Training loss: 1.7908951044082642
Validation loss: 1.8231205081426969

Epoch: 5| Step: 4
Training loss: 1.3312532901763916
Validation loss: 1.8083976238004622

Epoch: 5| Step: 5
Training loss: 1.2209727764129639
Validation loss: 1.794675410434764

Epoch: 5| Step: 6
Training loss: 1.0014806985855103
Validation loss: 1.8050218448844007

Epoch: 5| Step: 7
Training loss: 0.7286022305488586
Validation loss: 1.851150490904367

Epoch: 5| Step: 8
Training loss: 0.850936233997345
Validation loss: 1.8266634095099665

Epoch: 5| Step: 9
Training loss: 1.493459701538086
Validation loss: 1.8150086531075098

Epoch: 5| Step: 10
Training loss: 1.4273658990859985
Validation loss: 1.8395227604014899

Epoch: 388| Step: 0
Training loss: 1.655360460281372
Validation loss: 1.8364446291359522

Epoch: 5| Step: 1
Training loss: 0.9059567451477051
Validation loss: 1.877557458416108

Epoch: 5| Step: 2
Training loss: 1.0464046001434326
Validation loss: 1.8483223017825876

Epoch: 5| Step: 3
Training loss: 0.651927649974823
Validation loss: 1.8680194680408766

Epoch: 5| Step: 4
Training loss: 0.7999178767204285
Validation loss: 1.8687707813837195

Epoch: 5| Step: 5
Training loss: 1.3093602657318115
Validation loss: 1.8205535469516632

Epoch: 5| Step: 6
Training loss: 1.48838210105896
Validation loss: 1.8655570078921575

Epoch: 5| Step: 7
Training loss: 1.3007992506027222
Validation loss: 1.8195306152425788

Epoch: 5| Step: 8
Training loss: 1.4379136562347412
Validation loss: 1.8472806305013678

Epoch: 5| Step: 9
Training loss: 1.5418400764465332
Validation loss: 1.8098529205527356

Epoch: 5| Step: 10
Training loss: 0.8423844575881958
Validation loss: 1.8130116552434943

Epoch: 389| Step: 0
Training loss: 1.1010735034942627
Validation loss: 1.7891272524351716

Epoch: 5| Step: 1
Training loss: 1.329476237297058
Validation loss: 1.806141673877675

Epoch: 5| Step: 2
Training loss: 0.7055011987686157
Validation loss: 1.799676815668742

Epoch: 5| Step: 3
Training loss: 0.8554876446723938
Validation loss: 1.8444866877730175

Epoch: 5| Step: 4
Training loss: 1.270344614982605
Validation loss: 1.7663582460854643

Epoch: 5| Step: 5
Training loss: 1.2200405597686768
Validation loss: 1.8285926336883216

Epoch: 5| Step: 6
Training loss: 1.0773111581802368
Validation loss: 1.8315667362623318

Epoch: 5| Step: 7
Training loss: 1.6271579265594482
Validation loss: 1.846053251656153

Epoch: 5| Step: 8
Training loss: 1.2171709537506104
Validation loss: 1.7872587506489088

Epoch: 5| Step: 9
Training loss: 1.5268338918685913
Validation loss: 1.8332860674909366

Epoch: 5| Step: 10
Training loss: 1.3378610610961914
Validation loss: 1.8664214636689873

Epoch: 390| Step: 0
Training loss: 1.00539231300354
Validation loss: 1.8330409219188075

Epoch: 5| Step: 1
Training loss: 1.5648185014724731
Validation loss: 1.8041197676812448

Epoch: 5| Step: 2
Training loss: 0.7312880158424377
Validation loss: 1.793125807598073

Epoch: 5| Step: 3
Training loss: 1.5818523168563843
Validation loss: 1.7914321909668625

Epoch: 5| Step: 4
Training loss: 1.1548069715499878
Validation loss: 1.7857653043603385

Epoch: 5| Step: 5
Training loss: 1.158341407775879
Validation loss: 1.8331627871400566

Epoch: 5| Step: 6
Training loss: 1.091078281402588
Validation loss: 1.8335806810727684

Epoch: 5| Step: 7
Training loss: 1.0341072082519531
Validation loss: 1.8000352318568895

Epoch: 5| Step: 8
Training loss: 0.9837601780891418
Validation loss: 1.8164326221712175

Epoch: 5| Step: 9
Training loss: 1.2329286336898804
Validation loss: 1.8304104266628143

Epoch: 5| Step: 10
Training loss: 1.4178767204284668
Validation loss: 1.763725701198783

Epoch: 391| Step: 0
Training loss: 0.9359487295150757
Validation loss: 1.84924667368653

Epoch: 5| Step: 1
Training loss: 1.120044469833374
Validation loss: 1.876562859422417

Epoch: 5| Step: 2
Training loss: 1.4098076820373535
Validation loss: 1.8999273892371886

Epoch: 5| Step: 3
Training loss: 0.92652827501297
Validation loss: 1.9064522981643677

Epoch: 5| Step: 4
Training loss: 1.7297264337539673
Validation loss: 1.8717497779477028

Epoch: 5| Step: 5
Training loss: 1.1800222396850586
Validation loss: 1.8679522058015228

Epoch: 5| Step: 6
Training loss: 1.1896991729736328
Validation loss: 1.8937654815694338

Epoch: 5| Step: 7
Training loss: 1.5155084133148193
Validation loss: 1.8065034650987195

Epoch: 5| Step: 8
Training loss: 1.291969895362854
Validation loss: 1.8130946056817168

Epoch: 5| Step: 9
Training loss: 1.1661287546157837
Validation loss: 1.8327180006170785

Epoch: 5| Step: 10
Training loss: 0.8284353613853455
Validation loss: 1.8366073434070875

Epoch: 392| Step: 0
Training loss: 1.0822309255599976
Validation loss: 1.841292001867807

Epoch: 5| Step: 1
Training loss: 1.2530438899993896
Validation loss: 1.8012865576692807

Epoch: 5| Step: 2
Training loss: 1.1399016380310059
Validation loss: 1.7735793923818937

Epoch: 5| Step: 3
Training loss: 1.2694038152694702
Validation loss: 1.8158880767001901

Epoch: 5| Step: 4
Training loss: 1.647505760192871
Validation loss: 1.8815217146309473

Epoch: 5| Step: 5
Training loss: 1.0936819314956665
Validation loss: 1.8210378692996116

Epoch: 5| Step: 6
Training loss: 1.142993688583374
Validation loss: 1.7903630707853584

Epoch: 5| Step: 7
Training loss: 1.2336146831512451
Validation loss: 1.7889463568246493

Epoch: 5| Step: 8
Training loss: 1.128652572631836
Validation loss: 1.7791430206709011

Epoch: 5| Step: 9
Training loss: 0.8856635093688965
Validation loss: 1.836413300165566

Epoch: 5| Step: 10
Training loss: 1.038537859916687
Validation loss: 1.8559368105344876

Epoch: 393| Step: 0
Training loss: 1.1541550159454346
Validation loss: 1.851112881014424

Epoch: 5| Step: 1
Training loss: 1.7565991878509521
Validation loss: 1.867791566797482

Epoch: 5| Step: 2
Training loss: 0.954872727394104
Validation loss: 1.9156026442845662

Epoch: 5| Step: 3
Training loss: 1.066264271736145
Validation loss: 1.892014281724089

Epoch: 5| Step: 4
Training loss: 1.3418123722076416
Validation loss: 1.8961699239669307

Epoch: 5| Step: 5
Training loss: 1.6317020654678345
Validation loss: 1.8431974918611589

Epoch: 5| Step: 6
Training loss: 1.4490150213241577
Validation loss: 1.852924923742971

Epoch: 5| Step: 7
Training loss: 1.5572822093963623
Validation loss: 1.8124232163993261

Epoch: 5| Step: 8
Training loss: 0.6689444780349731
Validation loss: 1.8012641270955403

Epoch: 5| Step: 9
Training loss: 1.2386913299560547
Validation loss: 1.8121456266731344

Epoch: 5| Step: 10
Training loss: 0.6487065553665161
Validation loss: 1.8134545356996599

Epoch: 394| Step: 0
Training loss: 0.9763177037239075
Validation loss: 1.847427160509171

Epoch: 5| Step: 1
Training loss: 1.5683729648590088
Validation loss: 1.8436169406419158

Epoch: 5| Step: 2
Training loss: 0.9636421203613281
Validation loss: 1.8291807687410744

Epoch: 5| Step: 3
Training loss: 1.1003010272979736
Validation loss: 1.8473394788721555

Epoch: 5| Step: 4
Training loss: 1.163775086402893
Validation loss: 1.809626620302918

Epoch: 5| Step: 5
Training loss: 1.0382312536239624
Validation loss: 1.8042291646362634

Epoch: 5| Step: 6
Training loss: 1.4807604551315308
Validation loss: 1.8506707196594567

Epoch: 5| Step: 7
Training loss: 0.9343901872634888
Validation loss: 1.8606866328947005

Epoch: 5| Step: 8
Training loss: 0.8408489227294922
Validation loss: 1.855819256074967

Epoch: 5| Step: 9
Training loss: 2.042846441268921
Validation loss: 1.8563229806961552

Epoch: 5| Step: 10
Training loss: 0.7935889959335327
Validation loss: 1.8468308666700959

Epoch: 395| Step: 0
Training loss: 1.061505675315857
Validation loss: 1.835291152359337

Epoch: 5| Step: 1
Training loss: 1.5774513483047485
Validation loss: 1.8484089707815519

Epoch: 5| Step: 2
Training loss: 1.0778642892837524
Validation loss: 1.7933192355658418

Epoch: 5| Step: 3
Training loss: 1.0580087900161743
Validation loss: 1.8432229821399977

Epoch: 5| Step: 4
Training loss: 1.059459924697876
Validation loss: 1.808636382061948

Epoch: 5| Step: 5
Training loss: 0.9533740878105164
Validation loss: 1.8244811411826842

Epoch: 5| Step: 6
Training loss: 0.9590588808059692
Validation loss: 1.8295953312227804

Epoch: 5| Step: 7
Training loss: 0.919407069683075
Validation loss: 1.8373584426859373

Epoch: 5| Step: 8
Training loss: 1.0989229679107666
Validation loss: 1.8718325514947214

Epoch: 5| Step: 9
Training loss: 1.6696536540985107
Validation loss: 1.817850250069813

Epoch: 5| Step: 10
Training loss: 1.5076795816421509
Validation loss: 1.8825710268430813

Epoch: 396| Step: 0
Training loss: 1.5621039867401123
Validation loss: 1.842773675918579

Epoch: 5| Step: 1
Training loss: 0.7788068056106567
Validation loss: 1.835375537154495

Epoch: 5| Step: 2
Training loss: 0.882021427154541
Validation loss: 1.7829616813249485

Epoch: 5| Step: 3
Training loss: 1.1670176982879639
Validation loss: 1.8920882773655716

Epoch: 5| Step: 4
Training loss: 1.1523141860961914
Validation loss: 1.8792835281741234

Epoch: 5| Step: 5
Training loss: 1.302207350730896
Validation loss: 1.8716337828225986

Epoch: 5| Step: 6
Training loss: 1.428409218788147
Validation loss: 1.8923586786434214

Epoch: 5| Step: 7
Training loss: 1.065704584121704
Validation loss: 1.883000817350162

Epoch: 5| Step: 8
Training loss: 1.309812068939209
Validation loss: 1.8570159994145876

Epoch: 5| Step: 9
Training loss: 1.1453841924667358
Validation loss: 1.8477658610190115

Epoch: 5| Step: 10
Training loss: 1.5872244834899902
Validation loss: 1.806895916179944

Epoch: 397| Step: 0
Training loss: 1.0804561376571655
Validation loss: 1.795607792433872

Epoch: 5| Step: 1
Training loss: 1.3876866102218628
Validation loss: 1.8258694551324333

Epoch: 5| Step: 2
Training loss: 1.073103904724121
Validation loss: 1.869581122552195

Epoch: 5| Step: 3
Training loss: 1.2929861545562744
Validation loss: 1.797457404034112

Epoch: 5| Step: 4
Training loss: 1.1540768146514893
Validation loss: 1.8393196610994236

Epoch: 5| Step: 5
Training loss: 1.5912421941757202
Validation loss: 1.873867916804488

Epoch: 5| Step: 6
Training loss: 0.9920014142990112
Validation loss: 1.8368523351607784

Epoch: 5| Step: 7
Training loss: 1.1471798419952393
Validation loss: 1.8324277016424364

Epoch: 5| Step: 8
Training loss: 1.1988199949264526
Validation loss: 1.8407011057740899

Epoch: 5| Step: 9
Training loss: 1.0633392333984375
Validation loss: 1.8366840757349485

Epoch: 5| Step: 10
Training loss: 1.0341928005218506
Validation loss: 1.8105898236715665

Epoch: 398| Step: 0
Training loss: 0.9782684445381165
Validation loss: 1.8810518710843978

Epoch: 5| Step: 1
Training loss: 1.2407333850860596
Validation loss: 1.916109049192039

Epoch: 5| Step: 2
Training loss: 1.3891886472702026
Validation loss: 1.8551565677888933

Epoch: 5| Step: 3
Training loss: 1.4266555309295654
Validation loss: 1.8762597294263943

Epoch: 5| Step: 4
Training loss: 1.7307298183441162
Validation loss: 1.8600927616960259

Epoch: 5| Step: 5
Training loss: 1.3173595666885376
Validation loss: 1.8516722840647544

Epoch: 5| Step: 6
Training loss: 0.8600490689277649
Validation loss: 1.8515454466624925

Epoch: 5| Step: 7
Training loss: 1.09009850025177
Validation loss: 1.839107508300453

Epoch: 5| Step: 8
Training loss: 1.2168681621551514
Validation loss: 1.8777433672258932

Epoch: 5| Step: 9
Training loss: 0.8851091265678406
Validation loss: 1.8458555077993741

Epoch: 5| Step: 10
Training loss: 0.8872810006141663
Validation loss: 1.7767388410465692

Epoch: 399| Step: 0
Training loss: 1.029897928237915
Validation loss: 1.8741244167409918

Epoch: 5| Step: 1
Training loss: 1.3484971523284912
Validation loss: 1.8616354568030244

Epoch: 5| Step: 2
Training loss: 0.8941180109977722
Validation loss: 1.8046811678076302

Epoch: 5| Step: 3
Training loss: 1.3605592250823975
Validation loss: 1.820144832775157

Epoch: 5| Step: 4
Training loss: 1.3539785146713257
Validation loss: 1.851251612427414

Epoch: 5| Step: 5
Training loss: 0.9465910196304321
Validation loss: 1.8612963127833542

Epoch: 5| Step: 6
Training loss: 1.3247114419937134
Validation loss: 1.7920676995349187

Epoch: 5| Step: 7
Training loss: 0.7378778457641602
Validation loss: 1.8300239027187388

Epoch: 5| Step: 8
Training loss: 1.2802331447601318
Validation loss: 1.7747013043331843

Epoch: 5| Step: 9
Training loss: 1.1056602001190186
Validation loss: 1.8527183019986717

Epoch: 5| Step: 10
Training loss: 1.351332664489746
Validation loss: 1.7825260604581525

Epoch: 400| Step: 0
Training loss: 1.6007035970687866
Validation loss: 1.8138734858523133

Epoch: 5| Step: 1
Training loss: 0.9594730138778687
Validation loss: 1.8328100148067679

Epoch: 5| Step: 2
Training loss: 1.0397576093673706
Validation loss: 1.8327429909859934

Epoch: 5| Step: 3
Training loss: 0.8818284273147583
Validation loss: 1.7970434747716433

Epoch: 5| Step: 4
Training loss: 1.1735212802886963
Validation loss: 1.836298245255665

Epoch: 5| Step: 5
Training loss: 1.3122990131378174
Validation loss: 1.8370427559780818

Epoch: 5| Step: 6
Training loss: 1.038036584854126
Validation loss: 1.8590961553717171

Epoch: 5| Step: 7
Training loss: 0.9842618107795715
Validation loss: 1.8801898725571171

Epoch: 5| Step: 8
Training loss: 0.9643354415893555
Validation loss: 1.8191720439541725

Epoch: 5| Step: 9
Training loss: 0.9630390405654907
Validation loss: 1.8535375492547148

Epoch: 5| Step: 10
Training loss: 1.9102338552474976
Validation loss: 1.9241805204781153

Epoch: 401| Step: 0
Training loss: 1.173678994178772
Validation loss: 1.8255978668889692

Epoch: 5| Step: 1
Training loss: 0.8074674606323242
Validation loss: 1.8580609201103129

Epoch: 5| Step: 2
Training loss: 0.7947177886962891
Validation loss: 1.8331994689920896

Epoch: 5| Step: 3
Training loss: 1.497122049331665
Validation loss: 1.8664742387751097

Epoch: 5| Step: 4
Training loss: 1.1987268924713135
Validation loss: 1.885020354742645

Epoch: 5| Step: 5
Training loss: 0.8295979499816895
Validation loss: 1.8724741256365212

Epoch: 5| Step: 6
Training loss: 1.2598662376403809
Validation loss: 1.8457494781863304

Epoch: 5| Step: 7
Training loss: 2.046276569366455
Validation loss: 1.8472433333755822

Epoch: 5| Step: 8
Training loss: 1.4786077737808228
Validation loss: 1.8414524255260345

Epoch: 5| Step: 9
Training loss: 1.0755914449691772
Validation loss: 1.803221869212325

Epoch: 5| Step: 10
Training loss: 0.8087643980979919
Validation loss: 1.8414217182385024

Epoch: 402| Step: 0
Training loss: 1.0753333568572998
Validation loss: 1.8112340460541427

Epoch: 5| Step: 1
Training loss: 0.9342862963676453
Validation loss: 1.7973734153214322

Epoch: 5| Step: 2
Training loss: 0.8027468919754028
Validation loss: 1.8188529963134437

Epoch: 5| Step: 3
Training loss: 1.235832929611206
Validation loss: 1.7926057513042162

Epoch: 5| Step: 4
Training loss: 1.717502236366272
Validation loss: 1.8425143700773998

Epoch: 5| Step: 5
Training loss: 0.9486287832260132
Validation loss: 1.8175593319759573

Epoch: 5| Step: 6
Training loss: 0.9855682253837585
Validation loss: 1.8187445799509685

Epoch: 5| Step: 7
Training loss: 1.1833007335662842
Validation loss: 1.8688291862446775

Epoch: 5| Step: 8
Training loss: 1.390285849571228
Validation loss: 1.798728673688827

Epoch: 5| Step: 9
Training loss: 1.7567495107650757
Validation loss: 1.8273230342454807

Epoch: 5| Step: 10
Training loss: 0.4799019992351532
Validation loss: 1.8429841226147068

Epoch: 403| Step: 0
Training loss: 1.2644494771957397
Validation loss: 1.8206395167176441

Epoch: 5| Step: 1
Training loss: 1.444957971572876
Validation loss: 1.8410658144181775

Epoch: 5| Step: 2
Training loss: 1.144781470298767
Validation loss: 1.8282794298664216

Epoch: 5| Step: 3
Training loss: 1.0716712474822998
Validation loss: 1.8552562844368718

Epoch: 5| Step: 4
Training loss: 1.294560194015503
Validation loss: 1.8213648373080837

Epoch: 5| Step: 5
Training loss: 1.3011709451675415
Validation loss: 1.8174046393363708

Epoch: 5| Step: 6
Training loss: 0.827320396900177
Validation loss: 1.8155892933568647

Epoch: 5| Step: 7
Training loss: 1.642418622970581
Validation loss: 1.8185068843185261

Epoch: 5| Step: 8
Training loss: 0.970441997051239
Validation loss: 1.7903090061679963

Epoch: 5| Step: 9
Training loss: 1.305620551109314
Validation loss: 1.8739080698259416

Epoch: 5| Step: 10
Training loss: 0.5778364539146423
Validation loss: 1.8102093947831022

Epoch: 404| Step: 0
Training loss: 1.2784879207611084
Validation loss: 1.8525992208911526

Epoch: 5| Step: 1
Training loss: 1.1750152111053467
Validation loss: 1.8778748435358847

Epoch: 5| Step: 2
Training loss: 1.2407381534576416
Validation loss: 1.880584462996452

Epoch: 5| Step: 3
Training loss: 1.029242753982544
Validation loss: 1.861109282380791

Epoch: 5| Step: 4
Training loss: 0.804939866065979
Validation loss: 1.887356081316548

Epoch: 5| Step: 5
Training loss: 1.2632678747177124
Validation loss: 1.8617923721190421

Epoch: 5| Step: 6
Training loss: 0.8674532175064087
Validation loss: 1.845241569703625

Epoch: 5| Step: 7
Training loss: 1.2651005983352661
Validation loss: 1.849464738240806

Epoch: 5| Step: 8
Training loss: 1.1728641986846924
Validation loss: 1.7879819536721835

Epoch: 5| Step: 9
Training loss: 1.2967075109481812
Validation loss: 1.8159631452252787

Epoch: 5| Step: 10
Training loss: 1.3915717601776123
Validation loss: 1.8216644974165066

Epoch: 405| Step: 0
Training loss: 0.5763483047485352
Validation loss: 1.8007824984929894

Epoch: 5| Step: 1
Training loss: 1.086693525314331
Validation loss: 1.853399020369335

Epoch: 5| Step: 2
Training loss: 0.9581575393676758
Validation loss: 1.7690304838201052

Epoch: 5| Step: 3
Training loss: 1.247550368309021
Validation loss: 1.8192755868357997

Epoch: 5| Step: 4
Training loss: 1.5892107486724854
Validation loss: 1.8530325889587402

Epoch: 5| Step: 5
Training loss: 1.4166786670684814
Validation loss: 1.8422437598628383

Epoch: 5| Step: 6
Training loss: 1.1381604671478271
Validation loss: 1.8447355531877088

Epoch: 5| Step: 7
Training loss: 1.0838439464569092
Validation loss: 1.8617388548389557

Epoch: 5| Step: 8
Training loss: 0.9535759687423706
Validation loss: 1.8713981015707857

Epoch: 5| Step: 9
Training loss: 0.817623496055603
Validation loss: 1.855891945541546

Epoch: 5| Step: 10
Training loss: 2.006326198577881
Validation loss: 1.8606816158499768

Epoch: 406| Step: 0
Training loss: 1.4592280387878418
Validation loss: 1.8576801502576439

Epoch: 5| Step: 1
Training loss: 1.2317688465118408
Validation loss: 1.799047016328381

Epoch: 5| Step: 2
Training loss: 1.3096433877944946
Validation loss: 1.8277938468481905

Epoch: 5| Step: 3
Training loss: 1.0580765008926392
Validation loss: 1.799768606821696

Epoch: 5| Step: 4
Training loss: 1.0151259899139404
Validation loss: 1.8635233038215226

Epoch: 5| Step: 5
Training loss: 1.0256683826446533
Validation loss: 1.829737195404627

Epoch: 5| Step: 6
Training loss: 0.8684800863265991
Validation loss: 1.792650315069383

Epoch: 5| Step: 7
Training loss: 1.2308588027954102
Validation loss: 1.877070306449808

Epoch: 5| Step: 8
Training loss: 1.0831944942474365
Validation loss: 1.8916754568776777

Epoch: 5| Step: 9
Training loss: 1.219733715057373
Validation loss: 1.8170882168636526

Epoch: 5| Step: 10
Training loss: 0.9647439122200012
Validation loss: 1.8660574574624338

Epoch: 407| Step: 0
Training loss: 0.8534629940986633
Validation loss: 1.8222621974124704

Epoch: 5| Step: 1
Training loss: 0.7350932359695435
Validation loss: 1.8006707519613288

Epoch: 5| Step: 2
Training loss: 0.7174643278121948
Validation loss: 1.8691651064862487

Epoch: 5| Step: 3
Training loss: 1.2177231311798096
Validation loss: 1.8140529612059235

Epoch: 5| Step: 4
Training loss: 1.3148338794708252
Validation loss: 1.8305237088152158

Epoch: 5| Step: 5
Training loss: 1.0050458908081055
Validation loss: 1.8317851994627266

Epoch: 5| Step: 6
Training loss: 0.864958643913269
Validation loss: 1.8496788752976285

Epoch: 5| Step: 7
Training loss: 1.0998485088348389
Validation loss: 1.8417612416769868

Epoch: 5| Step: 8
Training loss: 1.7497085332870483
Validation loss: 1.8549788562200402

Epoch: 5| Step: 9
Training loss: 1.2922732830047607
Validation loss: 1.8528074244017243

Epoch: 5| Step: 10
Training loss: 1.6987273693084717
Validation loss: 1.8791259616933844

Epoch: 408| Step: 0
Training loss: 1.2500455379486084
Validation loss: 1.8205688614999094

Epoch: 5| Step: 1
Training loss: 0.8397842645645142
Validation loss: 1.7971481315551265

Epoch: 5| Step: 2
Training loss: 0.7936081886291504
Validation loss: 1.836159033160056

Epoch: 5| Step: 3
Training loss: 0.7497082948684692
Validation loss: 1.8030682174108361

Epoch: 5| Step: 4
Training loss: 0.9248655438423157
Validation loss: 1.7869925780962872

Epoch: 5| Step: 5
Training loss: 0.9751795530319214
Validation loss: 1.8316354802859727

Epoch: 5| Step: 6
Training loss: 1.0681804418563843
Validation loss: 1.835656576259162

Epoch: 5| Step: 7
Training loss: 1.4835193157196045
Validation loss: 1.8338317883911954

Epoch: 5| Step: 8
Training loss: 1.7791935205459595
Validation loss: 1.8233423848305979

Epoch: 5| Step: 9
Training loss: 1.4317200183868408
Validation loss: 1.8146683580131941

Epoch: 5| Step: 10
Training loss: 0.9606828093528748
Validation loss: 1.816500893203161

Epoch: 409| Step: 0
Training loss: 1.6114635467529297
Validation loss: 1.815004083418077

Epoch: 5| Step: 1
Training loss: 1.183803915977478
Validation loss: 1.8122789359861804

Epoch: 5| Step: 2
Training loss: 0.9828421473503113
Validation loss: 1.7924806430775633

Epoch: 5| Step: 3
Training loss: 1.3630516529083252
Validation loss: 1.7934936233746108

Epoch: 5| Step: 4
Training loss: 1.1903915405273438
Validation loss: 1.8102394406513502

Epoch: 5| Step: 5
Training loss: 1.0221948623657227
Validation loss: 1.8161911631143222

Epoch: 5| Step: 6
Training loss: 0.9061354398727417
Validation loss: 1.801542458995696

Epoch: 5| Step: 7
Training loss: 0.6898919939994812
Validation loss: 1.8723128431586809

Epoch: 5| Step: 8
Training loss: 1.0592825412750244
Validation loss: 1.8000848139486005

Epoch: 5| Step: 9
Training loss: 1.2935501337051392
Validation loss: 1.8117067147326726

Epoch: 5| Step: 10
Training loss: 0.94544917345047
Validation loss: 1.7894406241755332

Epoch: 410| Step: 0
Training loss: 1.5488067865371704
Validation loss: 1.839741232574627

Epoch: 5| Step: 1
Training loss: 1.1519615650177002
Validation loss: 1.8422725559562765

Epoch: 5| Step: 2
Training loss: 1.296297550201416
Validation loss: 1.8916743468212824

Epoch: 5| Step: 3
Training loss: 1.033119559288025
Validation loss: 1.8977009865545458

Epoch: 5| Step: 4
Training loss: 1.239410638809204
Validation loss: 1.8814612588574808

Epoch: 5| Step: 5
Training loss: 1.0922809839248657
Validation loss: 1.8627631305366434

Epoch: 5| Step: 6
Training loss: 0.5848709344863892
Validation loss: 1.8061401933752081

Epoch: 5| Step: 7
Training loss: 0.9431174993515015
Validation loss: 1.8309700386498564

Epoch: 5| Step: 8
Training loss: 1.41131591796875
Validation loss: 1.827124951988138

Epoch: 5| Step: 9
Training loss: 1.447220802307129
Validation loss: 1.853105430961937

Epoch: 5| Step: 10
Training loss: 0.9537805914878845
Validation loss: 1.7828989028930664

Epoch: 411| Step: 0
Training loss: 1.0177866220474243
Validation loss: 1.8110568536225187

Epoch: 5| Step: 1
Training loss: 1.089888334274292
Validation loss: 1.8330988768608338

Epoch: 5| Step: 2
Training loss: 1.1871916055679321
Validation loss: 1.8296501751868957

Epoch: 5| Step: 3
Training loss: 0.717601478099823
Validation loss: 1.802220042033862

Epoch: 5| Step: 4
Training loss: 1.2994965314865112
Validation loss: 1.8690762276290565

Epoch: 5| Step: 5
Training loss: 1.3293689489364624
Validation loss: 1.8152677653938212

Epoch: 5| Step: 6
Training loss: 1.3168104887008667
Validation loss: 1.8633195738638602

Epoch: 5| Step: 7
Training loss: 1.300150990486145
Validation loss: 1.8134275636365336

Epoch: 5| Step: 8
Training loss: 1.474273681640625
Validation loss: 1.7917563056433072

Epoch: 5| Step: 9
Training loss: 0.5803830027580261
Validation loss: 1.8713910695045226

Epoch: 5| Step: 10
Training loss: 1.1508957147598267
Validation loss: 1.8421828951886905

Epoch: 412| Step: 0
Training loss: 1.3470182418823242
Validation loss: 1.788384888761787

Epoch: 5| Step: 1
Training loss: 1.1114176511764526
Validation loss: 1.8220510649424728

Epoch: 5| Step: 2
Training loss: 1.3309282064437866
Validation loss: 1.8445158389306837

Epoch: 5| Step: 3
Training loss: 1.0303497314453125
Validation loss: 1.8134818820543186

Epoch: 5| Step: 4
Training loss: 1.1507701873779297
Validation loss: 1.8134577934459974

Epoch: 5| Step: 5
Training loss: 0.9690165519714355
Validation loss: 1.8329530992815573

Epoch: 5| Step: 6
Training loss: 1.4927070140838623
Validation loss: 1.8223681270435292

Epoch: 5| Step: 7
Training loss: 1.0006483793258667
Validation loss: 1.762082202460176

Epoch: 5| Step: 8
Training loss: 0.614226222038269
Validation loss: 1.844897303529965

Epoch: 5| Step: 9
Training loss: 1.2799323797225952
Validation loss: 1.8367065101541498

Epoch: 5| Step: 10
Training loss: 1.0765517950057983
Validation loss: 1.8462444159292406

Epoch: 413| Step: 0
Training loss: 0.8615266680717468
Validation loss: 1.8459861304170342

Epoch: 5| Step: 1
Training loss: 0.9901255369186401
Validation loss: 1.8137104652261222

Epoch: 5| Step: 2
Training loss: 1.6597055196762085
Validation loss: 1.821291269794587

Epoch: 5| Step: 3
Training loss: 1.0165126323699951
Validation loss: 1.8607681925578783

Epoch: 5| Step: 4
Training loss: 1.416015863418579
Validation loss: 1.8895882483451598

Epoch: 5| Step: 5
Training loss: 0.8802230954170227
Validation loss: 1.8916256786674581

Epoch: 5| Step: 6
Training loss: 1.060364007949829
Validation loss: 1.8607288816923737

Epoch: 5| Step: 7
Training loss: 1.228584885597229
Validation loss: 1.8326236471053092

Epoch: 5| Step: 8
Training loss: 1.077229619026184
Validation loss: 1.8632103871273737

Epoch: 5| Step: 9
Training loss: 1.517948031425476
Validation loss: 1.8225501686014154

Epoch: 5| Step: 10
Training loss: 0.883018434047699
Validation loss: 1.7997840604474467

Epoch: 414| Step: 0
Training loss: 1.5316461324691772
Validation loss: 1.8610386104993923

Epoch: 5| Step: 1
Training loss: 1.1809664964675903
Validation loss: 1.8046464599588865

Epoch: 5| Step: 2
Training loss: 0.9584639668464661
Validation loss: 1.8171823909205775

Epoch: 5| Step: 3
Training loss: 0.8243523836135864
Validation loss: 1.8532629013061523

Epoch: 5| Step: 4
Training loss: 0.9405795931816101
Validation loss: 1.8023055676491029

Epoch: 5| Step: 5
Training loss: 1.0296392440795898
Validation loss: 1.8008537959027033

Epoch: 5| Step: 6
Training loss: 1.0451903343200684
Validation loss: 1.799708826567537

Epoch: 5| Step: 7
Training loss: 1.3318657875061035
Validation loss: 1.7983221046386226

Epoch: 5| Step: 8
Training loss: 0.7898685932159424
Validation loss: 1.807263840911209

Epoch: 5| Step: 9
Training loss: 1.673636794090271
Validation loss: 1.8607872070804719

Epoch: 5| Step: 10
Training loss: 0.884998083114624
Validation loss: 1.888595934837095

Epoch: 415| Step: 0
Training loss: 0.8000718951225281
Validation loss: 1.8937617565995903

Epoch: 5| Step: 1
Training loss: 1.589905023574829
Validation loss: 1.867344658861878

Epoch: 5| Step: 2
Training loss: 1.206777572631836
Validation loss: 1.9009965491551224

Epoch: 5| Step: 3
Training loss: 0.8637898564338684
Validation loss: 1.9509864648183186

Epoch: 5| Step: 4
Training loss: 1.5599793195724487
Validation loss: 1.8554369890561668

Epoch: 5| Step: 5
Training loss: 1.3358876705169678
Validation loss: 1.8617955561607116

Epoch: 5| Step: 6
Training loss: 1.2405650615692139
Validation loss: 1.8583251430142311

Epoch: 5| Step: 7
Training loss: 1.172499418258667
Validation loss: 1.837477812203028

Epoch: 5| Step: 8
Training loss: 0.8097192049026489
Validation loss: 1.8449890511010283

Epoch: 5| Step: 9
Training loss: 0.957633376121521
Validation loss: 1.8362198414341095

Epoch: 5| Step: 10
Training loss: 1.06432044506073
Validation loss: 1.8650018015215475

Epoch: 416| Step: 0
Training loss: 1.1603200435638428
Validation loss: 1.835933933975876

Epoch: 5| Step: 1
Training loss: 0.8432418704032898
Validation loss: 1.8345497564602924

Epoch: 5| Step: 2
Training loss: 1.562732458114624
Validation loss: 1.8392114844373477

Epoch: 5| Step: 3
Training loss: 1.2938287258148193
Validation loss: 1.8100655373706613

Epoch: 5| Step: 4
Training loss: 0.9890130758285522
Validation loss: 1.8212637055304743

Epoch: 5| Step: 5
Training loss: 1.089461088180542
Validation loss: 1.8678487065017864

Epoch: 5| Step: 6
Training loss: 0.812850832939148
Validation loss: 1.8623948097229004

Epoch: 5| Step: 7
Training loss: 1.362286925315857
Validation loss: 1.8096152672203638

Epoch: 5| Step: 8
Training loss: 1.7604068517684937
Validation loss: 1.861785170852497

Epoch: 5| Step: 9
Training loss: 0.7174619436264038
Validation loss: 1.844357443112199

Epoch: 5| Step: 10
Training loss: 0.6187920570373535
Validation loss: 1.8431068851101784

Epoch: 417| Step: 0
Training loss: 0.9597895741462708
Validation loss: 1.8280588388442993

Epoch: 5| Step: 1
Training loss: 1.1020677089691162
Validation loss: 1.868124008178711

Epoch: 5| Step: 2
Training loss: 0.5344763994216919
Validation loss: 1.7835086340545325

Epoch: 5| Step: 3
Training loss: 1.193760633468628
Validation loss: 1.847512616906115

Epoch: 5| Step: 4
Training loss: 1.212739109992981
Validation loss: 1.8053742249806721

Epoch: 5| Step: 5
Training loss: 1.3313002586364746
Validation loss: 1.7957133580279607

Epoch: 5| Step: 6
Training loss: 1.275896430015564
Validation loss: 1.7911220289045764

Epoch: 5| Step: 7
Training loss: 1.5190584659576416
Validation loss: 1.824370038124823

Epoch: 5| Step: 8
Training loss: 0.8373010754585266
Validation loss: 1.8677643909249255

Epoch: 5| Step: 9
Training loss: 1.1226450204849243
Validation loss: 1.841462953116304

Epoch: 5| Step: 10
Training loss: 1.0152370929718018
Validation loss: 1.8135033179354925

Epoch: 418| Step: 0
Training loss: 1.3442758321762085
Validation loss: 1.8304571772134433

Epoch: 5| Step: 1
Training loss: 1.1401958465576172
Validation loss: 1.919902822022797

Epoch: 5| Step: 2
Training loss: 1.0985746383666992
Validation loss: 1.8549156855511408

Epoch: 5| Step: 3
Training loss: 0.6971077919006348
Validation loss: 1.8319792568042714

Epoch: 5| Step: 4
Training loss: 0.8028567433357239
Validation loss: 1.8656218846638997

Epoch: 5| Step: 5
Training loss: 0.6083856821060181
Validation loss: 1.8109967990588116

Epoch: 5| Step: 6
Training loss: 2.023391008377075
Validation loss: 1.8191169308077904

Epoch: 5| Step: 7
Training loss: 1.0754917860031128
Validation loss: 1.826247222961918

Epoch: 5| Step: 8
Training loss: 1.1420457363128662
Validation loss: 1.8450853645160634

Epoch: 5| Step: 9
Training loss: 1.2756332159042358
Validation loss: 1.8057827141977125

Epoch: 5| Step: 10
Training loss: 1.2384483814239502
Validation loss: 1.8730971659383466

Epoch: 419| Step: 0
Training loss: 0.8892216682434082
Validation loss: 1.810696783886161

Epoch: 5| Step: 1
Training loss: 1.2148113250732422
Validation loss: 1.8798219311621882

Epoch: 5| Step: 2
Training loss: 1.0183498859405518
Validation loss: 1.883617498541391

Epoch: 5| Step: 3
Training loss: 1.4427640438079834
Validation loss: 1.8547545171553088

Epoch: 5| Step: 4
Training loss: 0.7030540704727173
Validation loss: 1.8596889113867154

Epoch: 5| Step: 5
Training loss: 1.6236021518707275
Validation loss: 1.8222488087992514

Epoch: 5| Step: 6
Training loss: 0.9040334820747375
Validation loss: 1.8344893545232794

Epoch: 5| Step: 7
Training loss: 1.3573936223983765
Validation loss: 1.8234929512905818

Epoch: 5| Step: 8
Training loss: 0.9968926310539246
Validation loss: 1.8275195962639266

Epoch: 5| Step: 9
Training loss: 0.872172474861145
Validation loss: 1.7978827594428934

Epoch: 5| Step: 10
Training loss: 1.0880804061889648
Validation loss: 1.861092003442908

Epoch: 420| Step: 0
Training loss: 0.9126483201980591
Validation loss: 1.843204003508373

Epoch: 5| Step: 1
Training loss: 0.8613133430480957
Validation loss: 1.8779355120915238

Epoch: 5| Step: 2
Training loss: 1.2672133445739746
Validation loss: 1.8928706492147138

Epoch: 5| Step: 3
Training loss: 1.2240240573883057
Validation loss: 1.8205408127077165

Epoch: 5| Step: 4
Training loss: 0.9901386499404907
Validation loss: 1.8910690353762718

Epoch: 5| Step: 5
Training loss: 1.0012966394424438
Validation loss: 1.8153678588969733

Epoch: 5| Step: 6
Training loss: 1.7129242420196533
Validation loss: 1.805958273590252

Epoch: 5| Step: 7
Training loss: 0.9641372561454773
Validation loss: 1.82409534915801

Epoch: 5| Step: 8
Training loss: 0.9711523056030273
Validation loss: 1.824784460888114

Epoch: 5| Step: 9
Training loss: 1.0771501064300537
Validation loss: 1.8280080108232395

Epoch: 5| Step: 10
Training loss: 1.441792607307434
Validation loss: 1.8054800648843088

Epoch: 421| Step: 0
Training loss: 1.2982723712921143
Validation loss: 1.8461995201726114

Epoch: 5| Step: 1
Training loss: 0.8075045347213745
Validation loss: 1.7853815824754777

Epoch: 5| Step: 2
Training loss: 1.0987718105316162
Validation loss: 1.8223641982642553

Epoch: 5| Step: 3
Training loss: 0.7988996505737305
Validation loss: 1.8281591733296711

Epoch: 5| Step: 4
Training loss: 1.3882230520248413
Validation loss: 1.9028656277605283

Epoch: 5| Step: 5
Training loss: 1.476344347000122
Validation loss: 1.8709345171528478

Epoch: 5| Step: 6
Training loss: 1.284704566001892
Validation loss: 1.906642492099475

Epoch: 5| Step: 7
Training loss: 0.8894139528274536
Validation loss: 1.9183577542663903

Epoch: 5| Step: 8
Training loss: 1.1138194799423218
Validation loss: 1.8690807691184423

Epoch: 5| Step: 9
Training loss: 0.67220139503479
Validation loss: 1.882768036216818

Epoch: 5| Step: 10
Training loss: 1.595158576965332
Validation loss: 1.8336322538314327

Epoch: 422| Step: 0
Training loss: 0.9219611883163452
Validation loss: 1.8338143902440225

Epoch: 5| Step: 1
Training loss: 1.4358526468276978
Validation loss: 1.7739884443180536

Epoch: 5| Step: 2
Training loss: 1.1438047885894775
Validation loss: 1.8202476219464374

Epoch: 5| Step: 3
Training loss: 1.6401252746582031
Validation loss: 1.8287215848122873

Epoch: 5| Step: 4
Training loss: 0.5741008520126343
Validation loss: 1.8356055085377028

Epoch: 5| Step: 5
Training loss: 1.3069063425064087
Validation loss: 1.799297373781922

Epoch: 5| Step: 6
Training loss: 1.119410514831543
Validation loss: 1.8294508200819775

Epoch: 5| Step: 7
Training loss: 1.0231213569641113
Validation loss: 1.804926751762308

Epoch: 5| Step: 8
Training loss: 0.9347065091133118
Validation loss: 1.8165852010891002

Epoch: 5| Step: 9
Training loss: 0.9180693626403809
Validation loss: 1.8907771264353106

Epoch: 5| Step: 10
Training loss: 1.1685364246368408
Validation loss: 1.8287802896191996

Epoch: 423| Step: 0
Training loss: 1.090890884399414
Validation loss: 1.8118334739438948

Epoch: 5| Step: 1
Training loss: 0.9646684527397156
Validation loss: 1.8649714544255247

Epoch: 5| Step: 2
Training loss: 0.6498486995697021
Validation loss: 1.8492237214119203

Epoch: 5| Step: 3
Training loss: 0.8688618540763855
Validation loss: 1.8048987926975373

Epoch: 5| Step: 4
Training loss: 1.4164724349975586
Validation loss: 1.8352161415161625

Epoch: 5| Step: 5
Training loss: 1.049738883972168
Validation loss: 1.8172844122814875

Epoch: 5| Step: 6
Training loss: 1.4809223413467407
Validation loss: 1.8076399372469993

Epoch: 5| Step: 7
Training loss: 1.316804051399231
Validation loss: 1.8266940398882794

Epoch: 5| Step: 8
Training loss: 1.1237963438034058
Validation loss: 1.795715065412624

Epoch: 5| Step: 9
Training loss: 1.236027717590332
Validation loss: 1.8165229943490797

Epoch: 5| Step: 10
Training loss: 0.8360664248466492
Validation loss: 1.806646477791571

Epoch: 424| Step: 0
Training loss: 1.1590497493743896
Validation loss: 1.830615028258293

Epoch: 5| Step: 1
Training loss: 1.385408639907837
Validation loss: 1.7781079328188332

Epoch: 5| Step: 2
Training loss: 1.3314656019210815
Validation loss: 1.8042251884296376

Epoch: 5| Step: 3
Training loss: 0.9863148927688599
Validation loss: 1.8882896720722158

Epoch: 5| Step: 4
Training loss: 0.9250930547714233
Validation loss: 1.8620648268730409

Epoch: 5| Step: 5
Training loss: 0.9286149740219116
Validation loss: 1.7883885483587942

Epoch: 5| Step: 6
Training loss: 1.3306124210357666
Validation loss: 1.8597482532583258

Epoch: 5| Step: 7
Training loss: 0.7394571304321289
Validation loss: 1.863347202218989

Epoch: 5| Step: 8
Training loss: 1.0793671607971191
Validation loss: 1.8364881315538961

Epoch: 5| Step: 9
Training loss: 0.9062167406082153
Validation loss: 1.8640142025486115

Epoch: 5| Step: 10
Training loss: 1.4056881666183472
Validation loss: 1.8498034707961544

Epoch: 425| Step: 0
Training loss: 1.4393436908721924
Validation loss: 1.833235079242337

Epoch: 5| Step: 1
Training loss: 0.9284621477127075
Validation loss: 1.8371778841941588

Epoch: 5| Step: 2
Training loss: 1.1226794719696045
Validation loss: 1.8427484702038508

Epoch: 5| Step: 3
Training loss: 0.5588976144790649
Validation loss: 1.8258736389939503

Epoch: 5| Step: 4
Training loss: 0.9537423849105835
Validation loss: 1.880801785376764

Epoch: 5| Step: 5
Training loss: 1.1725764274597168
Validation loss: 1.8511166841753068

Epoch: 5| Step: 6
Training loss: 1.0866624116897583
Validation loss: 1.8172373951122325

Epoch: 5| Step: 7
Training loss: 0.9037555456161499
Validation loss: 1.8374198893065095

Epoch: 5| Step: 8
Training loss: 1.4955971240997314
Validation loss: 1.8516940045100387

Epoch: 5| Step: 9
Training loss: 1.065722942352295
Validation loss: 1.860546576079502

Epoch: 5| Step: 10
Training loss: 1.643112063407898
Validation loss: 1.8549964850948704

Epoch: 426| Step: 0
Training loss: 1.4232491254806519
Validation loss: 1.8897823402958531

Epoch: 5| Step: 1
Training loss: 1.2917420864105225
Validation loss: 1.8271566078227053

Epoch: 5| Step: 2
Training loss: 1.0894792079925537
Validation loss: 1.8281722478969122

Epoch: 5| Step: 3
Training loss: 0.9001307487487793
Validation loss: 1.8445247347636888

Epoch: 5| Step: 4
Training loss: 0.6370862722396851
Validation loss: 1.8114413369086482

Epoch: 5| Step: 5
Training loss: 1.1943243741989136
Validation loss: 1.840859111919198

Epoch: 5| Step: 6
Training loss: 0.8245697021484375
Validation loss: 1.877648647113513

Epoch: 5| Step: 7
Training loss: 1.177930474281311
Validation loss: 1.8308623593340638

Epoch: 5| Step: 8
Training loss: 0.9430953860282898
Validation loss: 1.8484963986181444

Epoch: 5| Step: 9
Training loss: 1.1325339078903198
Validation loss: 1.834188138284991

Epoch: 5| Step: 10
Training loss: 1.2325925827026367
Validation loss: 1.8488265442591842

Epoch: 427| Step: 0
Training loss: 1.0741077661514282
Validation loss: 1.8533995689884308

Epoch: 5| Step: 1
Training loss: 1.209550142288208
Validation loss: 1.8480622383856005

Epoch: 5| Step: 2
Training loss: 0.7558003067970276
Validation loss: 1.8592930775816723

Epoch: 5| Step: 3
Training loss: 1.118074893951416
Validation loss: 1.8565260107799242

Epoch: 5| Step: 4
Training loss: 1.0556089878082275
Validation loss: 1.81057688882274

Epoch: 5| Step: 5
Training loss: 1.049344539642334
Validation loss: 1.8769633334170106

Epoch: 5| Step: 6
Training loss: 1.092254877090454
Validation loss: 1.8342922759312454

Epoch: 5| Step: 7
Training loss: 1.042717695236206
Validation loss: 1.8629652864189559

Epoch: 5| Step: 8
Training loss: 0.9625763893127441
Validation loss: 1.816757220093922

Epoch: 5| Step: 9
Training loss: 1.7583297491073608
Validation loss: 1.8358766314803914

Epoch: 5| Step: 10
Training loss: 0.9382361173629761
Validation loss: 1.8358139120122439

Epoch: 428| Step: 0
Training loss: 1.017744541168213
Validation loss: 1.8202053449487174

Epoch: 5| Step: 1
Training loss: 1.4944273233413696
Validation loss: 1.8227072787541214

Epoch: 5| Step: 2
Training loss: 0.8766399621963501
Validation loss: 1.8557019900250178

Epoch: 5| Step: 3
Training loss: 1.2666833400726318
Validation loss: 1.82923726753522

Epoch: 5| Step: 4
Training loss: 1.1863760948181152
Validation loss: 1.8204043526803293

Epoch: 5| Step: 5
Training loss: 1.1856319904327393
Validation loss: 1.8010932963381532

Epoch: 5| Step: 6
Training loss: 0.652393639087677
Validation loss: 1.8323855938449982

Epoch: 5| Step: 7
Training loss: 1.085436463356018
Validation loss: 1.8501305400684316

Epoch: 5| Step: 8
Training loss: 1.1992462873458862
Validation loss: 1.8230325201506257

Epoch: 5| Step: 9
Training loss: 1.3771803379058838
Validation loss: 1.8253019291867492

Epoch: 5| Step: 10
Training loss: 0.628016471862793
Validation loss: 1.8686705430348713

Epoch: 429| Step: 0
Training loss: 0.980473518371582
Validation loss: 1.843661992780624

Epoch: 5| Step: 1
Training loss: 1.1833851337432861
Validation loss: 1.8769133193518526

Epoch: 5| Step: 2
Training loss: 1.0722203254699707
Validation loss: 1.8955095096301007

Epoch: 5| Step: 3
Training loss: 1.1154041290283203
Validation loss: 1.8935161687994515

Epoch: 5| Step: 4
Training loss: 1.469037652015686
Validation loss: 1.849014328372094

Epoch: 5| Step: 5
Training loss: 0.9022374153137207
Validation loss: 1.8650086848966536

Epoch: 5| Step: 6
Training loss: 0.8069273829460144
Validation loss: 1.8371424239168885

Epoch: 5| Step: 7
Training loss: 1.1485697031021118
Validation loss: 1.8999857094980055

Epoch: 5| Step: 8
Training loss: 1.3399107456207275
Validation loss: 1.827854005239343

Epoch: 5| Step: 9
Training loss: 1.1283814907073975
Validation loss: 1.8245594911677863

Epoch: 5| Step: 10
Training loss: 0.9704789519309998
Validation loss: 1.8276610579541934

Epoch: 430| Step: 0
Training loss: 0.6358009576797485
Validation loss: 1.8151194639103387

Epoch: 5| Step: 1
Training loss: 1.0848829746246338
Validation loss: 1.8639037173281434

Epoch: 5| Step: 2
Training loss: 1.040229320526123
Validation loss: 1.821864571622623

Epoch: 5| Step: 3
Training loss: 1.0316240787506104
Validation loss: 1.8371529899617678

Epoch: 5| Step: 4
Training loss: 1.0419737100601196
Validation loss: 1.8450858285350185

Epoch: 5| Step: 5
Training loss: 0.8591845631599426
Validation loss: 1.8542650899579447

Epoch: 5| Step: 6
Training loss: 0.9573169946670532
Validation loss: 1.8301218248182727

Epoch: 5| Step: 7
Training loss: 1.8261587619781494
Validation loss: 1.8534879197356522

Epoch: 5| Step: 8
Training loss: 1.1494319438934326
Validation loss: 1.8901738351391209

Epoch: 5| Step: 9
Training loss: 0.9537240862846375
Validation loss: 1.9119395620079451

Epoch: 5| Step: 10
Training loss: 1.3064610958099365
Validation loss: 1.837429763168417

Epoch: 431| Step: 0
Training loss: 1.260054349899292
Validation loss: 1.9265968748318252

Epoch: 5| Step: 1
Training loss: 1.0449132919311523
Validation loss: 1.8495290920298586

Epoch: 5| Step: 2
Training loss: 1.084474802017212
Validation loss: 1.893282982610887

Epoch: 5| Step: 3
Training loss: 1.107338309288025
Validation loss: 1.81789098119223

Epoch: 5| Step: 4
Training loss: 0.8963757753372192
Validation loss: 1.8559727617489394

Epoch: 5| Step: 5
Training loss: 1.6614580154418945
Validation loss: 1.8743119034715878

Epoch: 5| Step: 6
Training loss: 1.3140891790390015
Validation loss: 1.8330697013485817

Epoch: 5| Step: 7
Training loss: 1.2843965291976929
Validation loss: 1.79075442078293

Epoch: 5| Step: 8
Training loss: 1.012820839881897
Validation loss: 1.8342341133343276

Epoch: 5| Step: 9
Training loss: 0.49977168440818787
Validation loss: 1.858602544312836

Epoch: 5| Step: 10
Training loss: 0.6324805617332458
Validation loss: 1.8239526043656051

Epoch: 432| Step: 0
Training loss: 0.8825174570083618
Validation loss: 1.812188413835341

Epoch: 5| Step: 1
Training loss: 0.9468927383422852
Validation loss: 1.8386342756209835

Epoch: 5| Step: 2
Training loss: 1.2872543334960938
Validation loss: 1.8267186559656614

Epoch: 5| Step: 3
Training loss: 1.3141402006149292
Validation loss: 1.858704605410176

Epoch: 5| Step: 4
Training loss: 1.3325132131576538
Validation loss: 1.8891045803664832

Epoch: 5| Step: 5
Training loss: 1.0427138805389404
Validation loss: 1.8611171245574951

Epoch: 5| Step: 6
Training loss: 0.8197304606437683
Validation loss: 1.886335616470665

Epoch: 5| Step: 7
Training loss: 1.6608291864395142
Validation loss: 1.881386556933003

Epoch: 5| Step: 8
Training loss: 0.9873592257499695
Validation loss: 1.8710832544552383

Epoch: 5| Step: 9
Training loss: 0.9203850626945496
Validation loss: 1.8495916474250056

Epoch: 5| Step: 10
Training loss: 0.8356491327285767
Validation loss: 1.8476054194152995

Epoch: 433| Step: 0
Training loss: 1.2084786891937256
Validation loss: 1.8098870323550316

Epoch: 5| Step: 1
Training loss: 0.752848744392395
Validation loss: 1.8245035486836587

Epoch: 5| Step: 2
Training loss: 1.1476026773452759
Validation loss: 1.7804165553021174

Epoch: 5| Step: 3
Training loss: 0.9688380360603333
Validation loss: 1.8301632724782473

Epoch: 5| Step: 4
Training loss: 0.9720045328140259
Validation loss: 1.8153645325732488

Epoch: 5| Step: 5
Training loss: 1.1297625303268433
Validation loss: 1.7924130270558019

Epoch: 5| Step: 6
Training loss: 0.9282041788101196
Validation loss: 1.8642227918870988

Epoch: 5| Step: 7
Training loss: 0.7180496454238892
Validation loss: 1.8332083686705558

Epoch: 5| Step: 8
Training loss: 1.3832727670669556
Validation loss: 1.8234161535898845

Epoch: 5| Step: 9
Training loss: 1.3724056482315063
Validation loss: 1.828944572838404

Epoch: 5| Step: 10
Training loss: 1.1987384557724
Validation loss: 1.8371814938001736

Epoch: 434| Step: 0
Training loss: 1.1858415603637695
Validation loss: 1.8664970378721915

Epoch: 5| Step: 1
Training loss: 0.914633572101593
Validation loss: 1.8082561031464608

Epoch: 5| Step: 2
Training loss: 1.13801109790802
Validation loss: 1.8670198725115867

Epoch: 5| Step: 3
Training loss: 1.6961380243301392
Validation loss: 1.8394319857320478

Epoch: 5| Step: 4
Training loss: 0.9649093747138977
Validation loss: 1.8438910233077181

Epoch: 5| Step: 5
Training loss: 1.1649689674377441
Validation loss: 1.8347885685582315

Epoch: 5| Step: 6
Training loss: 0.8871012926101685
Validation loss: 1.8660699808469383

Epoch: 5| Step: 7
Training loss: 1.2930314540863037
Validation loss: 1.8182988089899863

Epoch: 5| Step: 8
Training loss: 1.0778820514678955
Validation loss: 1.8956298469215311

Epoch: 5| Step: 9
Training loss: 0.5608617067337036
Validation loss: 1.8215668791083879

Epoch: 5| Step: 10
Training loss: 1.1626967191696167
Validation loss: 1.9015907574725408

Epoch: 435| Step: 0
Training loss: 1.1266762018203735
Validation loss: 1.8676726318174792

Epoch: 5| Step: 1
Training loss: 1.0505130290985107
Validation loss: 1.8493653138478596

Epoch: 5| Step: 2
Training loss: 1.3638710975646973
Validation loss: 1.8803159472762898

Epoch: 5| Step: 3
Training loss: 0.966455340385437
Validation loss: 1.837073669638685

Epoch: 5| Step: 4
Training loss: 1.0427640676498413
Validation loss: 1.8596442463577434

Epoch: 5| Step: 5
Training loss: 0.9309142827987671
Validation loss: 1.8729941114302604

Epoch: 5| Step: 6
Training loss: 1.1058897972106934
Validation loss: 1.855336986562257

Epoch: 5| Step: 7
Training loss: 0.9371231198310852
Validation loss: 1.87525906614078

Epoch: 5| Step: 8
Training loss: 0.49041175842285156
Validation loss: 1.8393505222053939

Epoch: 5| Step: 9
Training loss: 1.1887285709381104
Validation loss: 1.8643023249923543

Epoch: 5| Step: 10
Training loss: 1.6963483095169067
Validation loss: 1.802467619219134

Epoch: 436| Step: 0
Training loss: 1.6347726583480835
Validation loss: 1.8241421176541237

Epoch: 5| Step: 1
Training loss: 0.9784564971923828
Validation loss: 1.8152147903237292

Epoch: 5| Step: 2
Training loss: 1.2076926231384277
Validation loss: 1.8487295232793337

Epoch: 5| Step: 3
Training loss: 1.1001720428466797
Validation loss: 1.8348909142196819

Epoch: 5| Step: 4
Training loss: 1.10965895652771
Validation loss: 1.8195112789830854

Epoch: 5| Step: 5
Training loss: 1.0563071966171265
Validation loss: 1.8491219038604407

Epoch: 5| Step: 6
Training loss: 0.8607174158096313
Validation loss: 1.7992628287243586

Epoch: 5| Step: 7
Training loss: 1.4281409978866577
Validation loss: 1.8489268697718138

Epoch: 5| Step: 8
Training loss: 1.1151081323623657
Validation loss: 1.9004612507358674

Epoch: 5| Step: 9
Training loss: 1.0230480432510376
Validation loss: 1.8553188167592531

Epoch: 5| Step: 10
Training loss: 0.5367807149887085
Validation loss: 1.862499390878985

Epoch: 437| Step: 0
Training loss: 0.5555750727653503
Validation loss: 1.8775602284298147

Epoch: 5| Step: 1
Training loss: 0.9756566882133484
Validation loss: 1.8358386037170247

Epoch: 5| Step: 2
Training loss: 1.0610991716384888
Validation loss: 1.863450704082366

Epoch: 5| Step: 3
Training loss: 0.8237665891647339
Validation loss: 1.8726746677070536

Epoch: 5| Step: 4
Training loss: 1.3488588333129883
Validation loss: 1.796777880319985

Epoch: 5| Step: 5
Training loss: 1.0805944204330444
Validation loss: 1.8459891170583747

Epoch: 5| Step: 6
Training loss: 1.184307336807251
Validation loss: 1.852566337072721

Epoch: 5| Step: 7
Training loss: 1.5478129386901855
Validation loss: 1.8681019249782767

Epoch: 5| Step: 8
Training loss: 0.7949792742729187
Validation loss: 1.8577181600755261

Epoch: 5| Step: 9
Training loss: 1.2315499782562256
Validation loss: 1.84529713789622

Epoch: 5| Step: 10
Training loss: 1.3913087844848633
Validation loss: 1.8486554904650616

Epoch: 438| Step: 0
Training loss: 0.7810295224189758
Validation loss: 1.809711214034788

Epoch: 5| Step: 1
Training loss: 1.413651704788208
Validation loss: 1.8041939889231036

Epoch: 5| Step: 2
Training loss: 1.6542961597442627
Validation loss: 1.831776148529463

Epoch: 5| Step: 3
Training loss: 1.0592164993286133
Validation loss: 1.8681572842341598

Epoch: 5| Step: 4
Training loss: 0.7748219966888428
Validation loss: 1.7841236027338172

Epoch: 5| Step: 5
Training loss: 1.0913317203521729
Validation loss: 1.8405785816971973

Epoch: 5| Step: 6
Training loss: 0.6938666105270386
Validation loss: 1.8322921337619904

Epoch: 5| Step: 7
Training loss: 1.0990774631500244
Validation loss: 1.804099444420107

Epoch: 5| Step: 8
Training loss: 0.8715621829032898
Validation loss: 1.8818671062428465

Epoch: 5| Step: 9
Training loss: 1.2180677652359009
Validation loss: 1.814029101402529

Epoch: 5| Step: 10
Training loss: 1.0316119194030762
Validation loss: 1.8232614468502741

Epoch: 439| Step: 0
Training loss: 0.9696975946426392
Validation loss: 1.793780226861277

Epoch: 5| Step: 1
Training loss: 0.8585966229438782
Validation loss: 1.7521734532489572

Epoch: 5| Step: 2
Training loss: 1.2588918209075928
Validation loss: 1.8594013478166314

Epoch: 5| Step: 3
Training loss: 0.8249801397323608
Validation loss: 1.8252076692478632

Epoch: 5| Step: 4
Training loss: 1.521322250366211
Validation loss: 1.7845991644808041

Epoch: 5| Step: 5
Training loss: 1.181933879852295
Validation loss: 1.7974148450359222

Epoch: 5| Step: 6
Training loss: 1.1147024631500244
Validation loss: 1.8128477578522058

Epoch: 5| Step: 7
Training loss: 1.271226167678833
Validation loss: 1.8111280830957557

Epoch: 5| Step: 8
Training loss: 0.6232112646102905
Validation loss: 1.79784958593307

Epoch: 5| Step: 9
Training loss: 1.127305030822754
Validation loss: 1.8830584813189764

Epoch: 5| Step: 10
Training loss: 0.7988309264183044
Validation loss: 1.8917044260168587

Epoch: 440| Step: 0
Training loss: 1.319530725479126
Validation loss: 1.8978982663923694

Epoch: 5| Step: 1
Training loss: 1.7642288208007812
Validation loss: 1.8455651011518253

Epoch: 5| Step: 2
Training loss: 1.2013139724731445
Validation loss: 1.9187050506632815

Epoch: 5| Step: 3
Training loss: 0.8660796284675598
Validation loss: 1.8958967667753979

Epoch: 5| Step: 4
Training loss: 0.6412558555603027
Validation loss: 1.8189683575784006

Epoch: 5| Step: 5
Training loss: 1.3469334840774536
Validation loss: 1.8681657237391318

Epoch: 5| Step: 6
Training loss: 0.798056423664093
Validation loss: 1.8497623794822282

Epoch: 5| Step: 7
Training loss: 0.979565441608429
Validation loss: 1.7770779530207317

Epoch: 5| Step: 8
Training loss: 0.8470768928527832
Validation loss: 1.7994657319079164

Epoch: 5| Step: 9
Training loss: 1.1405601501464844
Validation loss: 1.8153322178830382

Epoch: 5| Step: 10
Training loss: 1.2870752811431885
Validation loss: 1.8200429793327086

Epoch: 441| Step: 0
Training loss: 1.133286714553833
Validation loss: 1.842414091992122

Epoch: 5| Step: 1
Training loss: 1.0134416818618774
Validation loss: 1.8003851880309403

Epoch: 5| Step: 2
Training loss: 0.7201286554336548
Validation loss: 1.8078474767746464

Epoch: 5| Step: 3
Training loss: 1.0990053415298462
Validation loss: 1.80330793575574

Epoch: 5| Step: 4
Training loss: 1.3899129629135132
Validation loss: 1.8218479899949924

Epoch: 5| Step: 5
Training loss: 1.0286670923233032
Validation loss: 1.7943877609827186

Epoch: 5| Step: 6
Training loss: 0.8102984428405762
Validation loss: 1.8527947984715945

Epoch: 5| Step: 7
Training loss: 1.1197259426116943
Validation loss: 1.860864302163483

Epoch: 5| Step: 8
Training loss: 0.7878584861755371
Validation loss: 1.8536366237107145

Epoch: 5| Step: 9
Training loss: 1.29836106300354
Validation loss: 1.833370872723159

Epoch: 5| Step: 10
Training loss: 1.233992338180542
Validation loss: 1.8337934914455618

Epoch: 442| Step: 0
Training loss: 1.2171552181243896
Validation loss: 1.8399301805803854

Epoch: 5| Step: 1
Training loss: 0.8532059788703918
Validation loss: 1.8439204077566824

Epoch: 5| Step: 2
Training loss: 0.7958352565765381
Validation loss: 1.8650862273349558

Epoch: 5| Step: 3
Training loss: 1.4794297218322754
Validation loss: 1.8370325257701259

Epoch: 5| Step: 4
Training loss: 0.7406894564628601
Validation loss: 1.8331851984864922

Epoch: 5| Step: 5
Training loss: 1.182023286819458
Validation loss: 1.8479846959472985

Epoch: 5| Step: 6
Training loss: 1.1828196048736572
Validation loss: 1.9034457181089668

Epoch: 5| Step: 7
Training loss: 1.1037089824676514
Validation loss: 1.7784495097334667

Epoch: 5| Step: 8
Training loss: 1.0215256214141846
Validation loss: 1.774977308447643

Epoch: 5| Step: 9
Training loss: 1.0527886152267456
Validation loss: 1.8933263722286429

Epoch: 5| Step: 10
Training loss: 0.6135803461074829
Validation loss: 1.8343840337568713

Epoch: 443| Step: 0
Training loss: 1.1909363269805908
Validation loss: 1.8416249239316551

Epoch: 5| Step: 1
Training loss: 1.118342638015747
Validation loss: 1.774136140782346

Epoch: 5| Step: 2
Training loss: 0.9640933871269226
Validation loss: 1.8338732386148104

Epoch: 5| Step: 3
Training loss: 1.2705403566360474
Validation loss: 1.8074832577859201

Epoch: 5| Step: 4
Training loss: 1.3179428577423096
Validation loss: 1.7997325697252828

Epoch: 5| Step: 5
Training loss: 1.123189091682434
Validation loss: 1.8139591447768673

Epoch: 5| Step: 6
Training loss: 1.1977839469909668
Validation loss: 1.8533798212646155

Epoch: 5| Step: 7
Training loss: 0.7104707360267639
Validation loss: 1.8529305278614003

Epoch: 5| Step: 8
Training loss: 0.8640483021736145
Validation loss: 1.8264388153629918

Epoch: 5| Step: 9
Training loss: 0.6592962741851807
Validation loss: 1.8423859688543505

Epoch: 5| Step: 10
Training loss: 1.0932480096817017
Validation loss: 1.8451410878089167

Epoch: 444| Step: 0
Training loss: 1.25899338722229
Validation loss: 1.8757143828176683

Epoch: 5| Step: 1
Training loss: 0.9614779353141785
Validation loss: 1.830864260273595

Epoch: 5| Step: 2
Training loss: 0.6767614483833313
Validation loss: 1.882102172861817

Epoch: 5| Step: 3
Training loss: 1.0077921152114868
Validation loss: 1.9396958017861972

Epoch: 5| Step: 4
Training loss: 1.4654408693313599
Validation loss: 1.8879297689724994

Epoch: 5| Step: 5
Training loss: 1.2618029117584229
Validation loss: 1.9129936054188719

Epoch: 5| Step: 6
Training loss: 1.0457313060760498
Validation loss: 1.8880413245129328

Epoch: 5| Step: 7
Training loss: 1.2456693649291992
Validation loss: 1.8508385445481987

Epoch: 5| Step: 8
Training loss: 0.9646393060684204
Validation loss: 1.808938446865287

Epoch: 5| Step: 9
Training loss: 1.0260334014892578
Validation loss: 1.8131080801768968

Epoch: 5| Step: 10
Training loss: 0.7876763939857483
Validation loss: 1.8192918505719913

Epoch: 445| Step: 0
Training loss: 0.969446063041687
Validation loss: 1.8266186265535251

Epoch: 5| Step: 1
Training loss: 0.6906798481941223
Validation loss: 1.8340251984134797

Epoch: 5| Step: 2
Training loss: 1.0162016153335571
Validation loss: 1.8165901168700187

Epoch: 5| Step: 3
Training loss: 0.9079114198684692
Validation loss: 1.8374160284637122

Epoch: 5| Step: 4
Training loss: 0.6241408586502075
Validation loss: 1.7951109217059227

Epoch: 5| Step: 5
Training loss: 1.3148969411849976
Validation loss: 1.8096530014468777

Epoch: 5| Step: 6
Training loss: 1.1000007390975952
Validation loss: 1.858505565633056

Epoch: 5| Step: 7
Training loss: 1.3054946660995483
Validation loss: 1.8431763174713298

Epoch: 5| Step: 8
Training loss: 1.353430986404419
Validation loss: 1.8627860853748937

Epoch: 5| Step: 9
Training loss: 1.1732170581817627
Validation loss: 1.872874495803669

Epoch: 5| Step: 10
Training loss: 1.226028561592102
Validation loss: 1.8439484334761096

Epoch: 446| Step: 0
Training loss: 1.2436531782150269
Validation loss: 1.9104264961775912

Epoch: 5| Step: 1
Training loss: 1.174971103668213
Validation loss: 1.8454857692923596

Epoch: 5| Step: 2
Training loss: 1.0152416229248047
Validation loss: 1.8290754005473147

Epoch: 5| Step: 3
Training loss: 1.111847162246704
Validation loss: 1.842126400240006

Epoch: 5| Step: 4
Training loss: 0.7090473771095276
Validation loss: 1.8414004925758607

Epoch: 5| Step: 5
Training loss: 0.864334225654602
Validation loss: 1.8762946077572402

Epoch: 5| Step: 6
Training loss: 1.2915856838226318
Validation loss: 1.8836389690317132

Epoch: 5| Step: 7
Training loss: 1.4722387790679932
Validation loss: 1.8351316452026367

Epoch: 5| Step: 8
Training loss: 0.9068762063980103
Validation loss: 1.8546280604536816

Epoch: 5| Step: 9
Training loss: 1.2621753215789795
Validation loss: 1.824114934090645

Epoch: 5| Step: 10
Training loss: 0.5978979468345642
Validation loss: 1.8194638503495084

Epoch: 447| Step: 0
Training loss: 1.1176435947418213
Validation loss: 1.8157043713395313

Epoch: 5| Step: 1
Training loss: 0.7415127754211426
Validation loss: 1.8029238331702448

Epoch: 5| Step: 2
Training loss: 1.1818017959594727
Validation loss: 1.8084713053959671

Epoch: 5| Step: 3
Training loss: 0.7343680262565613
Validation loss: 1.8098967741894465

Epoch: 5| Step: 4
Training loss: 0.9996706247329712
Validation loss: 1.825345705914241

Epoch: 5| Step: 5
Training loss: 1.095900535583496
Validation loss: 1.8080286492583573

Epoch: 5| Step: 6
Training loss: 1.0163154602050781
Validation loss: 1.8383540594449608

Epoch: 5| Step: 7
Training loss: 1.051088571548462
Validation loss: 1.8371256102797806

Epoch: 5| Step: 8
Training loss: 1.3579189777374268
Validation loss: 1.8421388441516506

Epoch: 5| Step: 9
Training loss: 1.0614817142486572
Validation loss: 1.8238895605969172

Epoch: 5| Step: 10
Training loss: 0.9602179527282715
Validation loss: 1.8594636122385662

Epoch: 448| Step: 0
Training loss: 1.2837939262390137
Validation loss: 1.8588249862834971

Epoch: 5| Step: 1
Training loss: 0.9825204610824585
Validation loss: 1.8540900368844309

Epoch: 5| Step: 2
Training loss: 0.6902243494987488
Validation loss: 1.8292240417131813

Epoch: 5| Step: 3
Training loss: 0.9131890535354614
Validation loss: 1.8383124515574465

Epoch: 5| Step: 4
Training loss: 1.1032527685165405
Validation loss: 1.833329677581787

Epoch: 5| Step: 5
Training loss: 1.0196068286895752
Validation loss: 1.8369448672058761

Epoch: 5| Step: 6
Training loss: 0.9118797183036804
Validation loss: 1.8547771425657376

Epoch: 5| Step: 7
Training loss: 1.5539408922195435
Validation loss: 1.8190536486205233

Epoch: 5| Step: 8
Training loss: 0.8269804120063782
Validation loss: 1.8261382246530184

Epoch: 5| Step: 9
Training loss: 0.9915727376937866
Validation loss: 1.8200171788533528

Epoch: 5| Step: 10
Training loss: 1.1817570924758911
Validation loss: 1.8422856535962833

Epoch: 449| Step: 0
Training loss: 0.822949230670929
Validation loss: 1.7985156543793217

Epoch: 5| Step: 1
Training loss: 1.0186220407485962
Validation loss: 1.8012617403461086

Epoch: 5| Step: 2
Training loss: 0.7556260824203491
Validation loss: 1.7853445904229277

Epoch: 5| Step: 3
Training loss: 1.7698224782943726
Validation loss: 1.8388708201787805

Epoch: 5| Step: 4
Training loss: 0.8772588968276978
Validation loss: 1.8498366161059308

Epoch: 5| Step: 5
Training loss: 0.9664148092269897
Validation loss: 1.8162228509943972

Epoch: 5| Step: 6
Training loss: 0.8638010025024414
Validation loss: 1.8554689704730947

Epoch: 5| Step: 7
Training loss: 1.2641966342926025
Validation loss: 1.8275118950874574

Epoch: 5| Step: 8
Training loss: 1.1097943782806396
Validation loss: 1.8243374645069081

Epoch: 5| Step: 9
Training loss: 0.8327391743659973
Validation loss: 1.8363840156985867

Epoch: 5| Step: 10
Training loss: 1.19017493724823
Validation loss: 1.8418401236175208

Epoch: 450| Step: 0
Training loss: 1.0885765552520752
Validation loss: 1.8266674985167801

Epoch: 5| Step: 1
Training loss: 0.9629423022270203
Validation loss: 1.8540661129900204

Epoch: 5| Step: 2
Training loss: 1.430822491645813
Validation loss: 1.884960687288674

Epoch: 5| Step: 3
Training loss: 1.2292580604553223
Validation loss: 1.8351083878547914

Epoch: 5| Step: 4
Training loss: 1.161130666732788
Validation loss: 1.8846649815959315

Epoch: 5| Step: 5
Training loss: 0.8363428115844727
Validation loss: 1.8638953124323199

Epoch: 5| Step: 6
Training loss: 0.8203073740005493
Validation loss: 1.8546426116779287

Epoch: 5| Step: 7
Training loss: 1.0650882720947266
Validation loss: 1.8987399378130514

Epoch: 5| Step: 8
Training loss: 1.0270801782608032
Validation loss: 1.877945843563285

Epoch: 5| Step: 9
Training loss: 0.9696531295776367
Validation loss: 1.8589304416410384

Epoch: 5| Step: 10
Training loss: 0.854897677898407
Validation loss: 1.8652445699578972

Epoch: 451| Step: 0
Training loss: 1.3904478549957275
Validation loss: 1.8651379872393865

Epoch: 5| Step: 1
Training loss: 0.7277504801750183
Validation loss: 1.7762620833612257

Epoch: 5| Step: 2
Training loss: 0.8785960078239441
Validation loss: 1.7865253917632564

Epoch: 5| Step: 3
Training loss: 0.7243117690086365
Validation loss: 1.761331663336805

Epoch: 5| Step: 4
Training loss: 0.9221083521842957
Validation loss: 1.8467790208837038

Epoch: 5| Step: 5
Training loss: 1.140507698059082
Validation loss: 1.7906545990256852

Epoch: 5| Step: 6
Training loss: 1.16391122341156
Validation loss: 1.8040041064703336

Epoch: 5| Step: 7
Training loss: 1.50406014919281
Validation loss: 1.863280342471215

Epoch: 5| Step: 8
Training loss: 1.0801942348480225
Validation loss: 1.8378436667944795

Epoch: 5| Step: 9
Training loss: 1.6984268426895142
Validation loss: 1.8285549866255892

Epoch: 5| Step: 10
Training loss: 0.6702466011047363
Validation loss: 1.8401120696016537

Epoch: 452| Step: 0
Training loss: 0.8963963389396667
Validation loss: 1.9188148501098796

Epoch: 5| Step: 1
Training loss: 0.9034045934677124
Validation loss: 1.8858681237825783

Epoch: 5| Step: 2
Training loss: 1.062171220779419
Validation loss: 1.939219154337401

Epoch: 5| Step: 3
Training loss: 1.2354400157928467
Validation loss: 1.8860320609102967

Epoch: 5| Step: 4
Training loss: 1.2584810256958008
Validation loss: 1.92375644048055

Epoch: 5| Step: 5
Training loss: 1.5755081176757812
Validation loss: 1.8547811200541835

Epoch: 5| Step: 6
Training loss: 1.3786475658416748
Validation loss: 1.9020797475691764

Epoch: 5| Step: 7
Training loss: 1.2744576930999756
Validation loss: 1.876779447319687

Epoch: 5| Step: 8
Training loss: 0.6789207458496094
Validation loss: 1.8393808475104712

Epoch: 5| Step: 9
Training loss: 0.7104727625846863
Validation loss: 1.8544720603573708

Epoch: 5| Step: 10
Training loss: 0.7282015085220337
Validation loss: 1.8360757238121443

Epoch: 453| Step: 0
Training loss: 0.909173846244812
Validation loss: 1.8077455412956975

Epoch: 5| Step: 1
Training loss: 1.4662939310073853
Validation loss: 1.8484921557928926

Epoch: 5| Step: 2
Training loss: 0.7767553329467773
Validation loss: 1.8765201594239922

Epoch: 5| Step: 3
Training loss: 0.8745416402816772
Validation loss: 1.835751542481043

Epoch: 5| Step: 4
Training loss: 0.7948053479194641
Validation loss: 1.8260561881526824

Epoch: 5| Step: 5
Training loss: 0.683404803276062
Validation loss: 1.8279103668787147

Epoch: 5| Step: 6
Training loss: 1.3163807392120361
Validation loss: 1.836749356280091

Epoch: 5| Step: 7
Training loss: 1.3128745555877686
Validation loss: 1.8102420530011576

Epoch: 5| Step: 8
Training loss: 0.9042997360229492
Validation loss: 1.8607918370154597

Epoch: 5| Step: 9
Training loss: 0.7532667517662048
Validation loss: 1.8537490239707373

Epoch: 5| Step: 10
Training loss: 1.4988380670547485
Validation loss: 1.8388347741096251

Epoch: 454| Step: 0
Training loss: 1.3942458629608154
Validation loss: 1.8187611846513645

Epoch: 5| Step: 1
Training loss: 0.8104392886161804
Validation loss: 1.8697181465805217

Epoch: 5| Step: 2
Training loss: 1.0624878406524658
Validation loss: 1.8381648486660374

Epoch: 5| Step: 3
Training loss: 0.702960729598999
Validation loss: 1.848647548306373

Epoch: 5| Step: 4
Training loss: 0.909400463104248
Validation loss: 1.928921417523456

Epoch: 5| Step: 5
Training loss: 1.155059576034546
Validation loss: 1.9000734872715448

Epoch: 5| Step: 6
Training loss: 0.8629145622253418
Validation loss: 1.8780510438385831

Epoch: 5| Step: 7
Training loss: 1.3989694118499756
Validation loss: 1.8467999209639847

Epoch: 5| Step: 8
Training loss: 0.7862035632133484
Validation loss: 1.8282158246604345

Epoch: 5| Step: 9
Training loss: 1.2964900732040405
Validation loss: 1.8151954822642828

Epoch: 5| Step: 10
Training loss: 1.1177009344100952
Validation loss: 1.7971658757937852

Epoch: 455| Step: 0
Training loss: 1.3564131259918213
Validation loss: 1.820467548985635

Epoch: 5| Step: 1
Training loss: 1.4155128002166748
Validation loss: 1.8559790401048557

Epoch: 5| Step: 2
Training loss: 0.7636208534240723
Validation loss: 1.8533753925754177

Epoch: 5| Step: 3
Training loss: 0.7302446365356445
Validation loss: 1.8120878101677023

Epoch: 5| Step: 4
Training loss: 1.0873534679412842
Validation loss: 1.7868227240859822

Epoch: 5| Step: 5
Training loss: 0.88384610414505
Validation loss: 1.8763759443836827

Epoch: 5| Step: 6
Training loss: 1.025119662284851
Validation loss: 1.7910976948276642

Epoch: 5| Step: 7
Training loss: 0.8565528988838196
Validation loss: 1.8450768506655129

Epoch: 5| Step: 8
Training loss: 1.1325045824050903
Validation loss: 1.8418632079196233

Epoch: 5| Step: 9
Training loss: 1.1285566091537476
Validation loss: 1.8012203055043374

Epoch: 5| Step: 10
Training loss: 0.8285247683525085
Validation loss: 1.8215837145364413

Epoch: 456| Step: 0
Training loss: 1.1744762659072876
Validation loss: 1.8836371001376901

Epoch: 5| Step: 1
Training loss: 0.9399904012680054
Validation loss: 1.904826477009763

Epoch: 5| Step: 2
Training loss: 0.9835149049758911
Validation loss: 1.8746102035686534

Epoch: 5| Step: 3
Training loss: 1.3342859745025635
Validation loss: 1.8611902203611148

Epoch: 5| Step: 4
Training loss: 0.990348219871521
Validation loss: 1.8278531970516327

Epoch: 5| Step: 5
Training loss: 0.6299937963485718
Validation loss: 1.8856920747346775

Epoch: 5| Step: 6
Training loss: 1.029114007949829
Validation loss: 1.8498969154973184

Epoch: 5| Step: 7
Training loss: 0.883529782295227
Validation loss: 1.773080643787179

Epoch: 5| Step: 8
Training loss: 1.2933943271636963
Validation loss: 1.8285686072482858

Epoch: 5| Step: 9
Training loss: 0.989301860332489
Validation loss: 1.8199081420898438

Epoch: 5| Step: 10
Training loss: 1.0229130983352661
Validation loss: 1.8073424395694528

Epoch: 457| Step: 0
Training loss: 1.3890663385391235
Validation loss: 1.826554416328348

Epoch: 5| Step: 1
Training loss: 1.6357309818267822
Validation loss: 1.8315407870918192

Epoch: 5| Step: 2
Training loss: 0.8879514932632446
Validation loss: 1.818597976879407

Epoch: 5| Step: 3
Training loss: 1.1247425079345703
Validation loss: 1.8570069113085348

Epoch: 5| Step: 4
Training loss: 0.9971804618835449
Validation loss: 1.801603678734072

Epoch: 5| Step: 5
Training loss: 0.6357384920120239
Validation loss: 1.8044870694478352

Epoch: 5| Step: 6
Training loss: 0.5733967423439026
Validation loss: 1.8365270732551493

Epoch: 5| Step: 7
Training loss: 0.6884501576423645
Validation loss: 1.8056519980071692

Epoch: 5| Step: 8
Training loss: 1.422128438949585
Validation loss: 1.8544031086788382

Epoch: 5| Step: 9
Training loss: 1.1551729440689087
Validation loss: 1.8276849408303537

Epoch: 5| Step: 10
Training loss: 0.5525638461112976
Validation loss: 1.8310380571631975

Epoch: 458| Step: 0
Training loss: 0.7480378150939941
Validation loss: 1.8497889734083606

Epoch: 5| Step: 1
Training loss: 1.5334218740463257
Validation loss: 1.8565275207642586

Epoch: 5| Step: 2
Training loss: 0.6281614899635315
Validation loss: 1.9005766491736136

Epoch: 5| Step: 3
Training loss: 1.3513376712799072
Validation loss: 1.8827992972507273

Epoch: 5| Step: 4
Training loss: 0.8658965229988098
Validation loss: 1.8891572952270508

Epoch: 5| Step: 5
Training loss: 1.2378672361373901
Validation loss: 1.8853368118245115

Epoch: 5| Step: 6
Training loss: 1.203230619430542
Validation loss: 1.8347905335887786

Epoch: 5| Step: 7
Training loss: 0.8187870979309082
Validation loss: 1.832201462919994

Epoch: 5| Step: 8
Training loss: 0.8905990719795227
Validation loss: 1.8076044359514791

Epoch: 5| Step: 9
Training loss: 1.377331018447876
Validation loss: 1.830390380274865

Epoch: 5| Step: 10
Training loss: 0.890113353729248
Validation loss: 1.804170170137959

Epoch: 459| Step: 0
Training loss: 1.2703330516815186
Validation loss: 1.8338801258353776

Epoch: 5| Step: 1
Training loss: 1.0410816669464111
Validation loss: 1.7765074827337777

Epoch: 5| Step: 2
Training loss: 1.1415534019470215
Validation loss: 1.8437474427684661

Epoch: 5| Step: 3
Training loss: 1.2835954427719116
Validation loss: 1.7924057091436079

Epoch: 5| Step: 4
Training loss: 1.1614539623260498
Validation loss: 1.8309176096352198

Epoch: 5| Step: 5
Training loss: 1.0139930248260498
Validation loss: 1.856975636174602

Epoch: 5| Step: 6
Training loss: 0.7192229628562927
Validation loss: 1.836969305110234

Epoch: 5| Step: 7
Training loss: 1.14986252784729
Validation loss: 1.8188365608133295

Epoch: 5| Step: 8
Training loss: 0.9567297697067261
Validation loss: 1.8185266576787478

Epoch: 5| Step: 9
Training loss: 0.8794716596603394
Validation loss: 1.833273394133455

Epoch: 5| Step: 10
Training loss: 0.7053418159484863
Validation loss: 1.819172384918377

Epoch: 460| Step: 0
Training loss: 0.9296765327453613
Validation loss: 1.8410800426237044

Epoch: 5| Step: 1
Training loss: 0.8713794946670532
Validation loss: 1.7758009523473761

Epoch: 5| Step: 2
Training loss: 1.1635103225708008
Validation loss: 1.8543482621510823

Epoch: 5| Step: 3
Training loss: 0.8419994115829468
Validation loss: 1.8194769569622573

Epoch: 5| Step: 4
Training loss: 0.7400906682014465
Validation loss: 1.8131102131259056

Epoch: 5| Step: 5
Training loss: 1.414529800415039
Validation loss: 1.864557836645393

Epoch: 5| Step: 6
Training loss: 0.9358234405517578
Validation loss: 1.8419858306966803

Epoch: 5| Step: 7
Training loss: 0.7381321787834167
Validation loss: 1.840738873327932

Epoch: 5| Step: 8
Training loss: 1.2507820129394531
Validation loss: 1.8395191225954282

Epoch: 5| Step: 9
Training loss: 1.07145094871521
Validation loss: 1.8097864632965417

Epoch: 5| Step: 10
Training loss: 1.052241563796997
Validation loss: 1.821983532239032

Epoch: 461| Step: 0
Training loss: 1.0809547901153564
Validation loss: 1.9079542659944104

Epoch: 5| Step: 1
Training loss: 1.1896848678588867
Validation loss: 1.8306382843243179

Epoch: 5| Step: 2
Training loss: 0.9627753496170044
Validation loss: 1.8108648330934587

Epoch: 5| Step: 3
Training loss: 1.390669822692871
Validation loss: 1.849856649675677

Epoch: 5| Step: 4
Training loss: 1.0336122512817383
Validation loss: 1.8373616126275831

Epoch: 5| Step: 5
Training loss: 0.7457575798034668
Validation loss: 1.8276793520937684

Epoch: 5| Step: 6
Training loss: 1.0462496280670166
Validation loss: 1.8466154785566433

Epoch: 5| Step: 7
Training loss: 0.9236248135566711
Validation loss: 1.8752452237631685

Epoch: 5| Step: 8
Training loss: 0.9559377431869507
Validation loss: 1.8499051806747273

Epoch: 5| Step: 9
Training loss: 1.215831995010376
Validation loss: 1.8864089737656295

Epoch: 5| Step: 10
Training loss: 1.0201696157455444
Validation loss: 1.8466743564092984

Epoch: 462| Step: 0
Training loss: 1.1365751028060913
Validation loss: 1.8728294577649844

Epoch: 5| Step: 1
Training loss: 1.1454088687896729
Validation loss: 1.9036718869722018

Epoch: 5| Step: 2
Training loss: 0.9230397939682007
Validation loss: 1.870316704114278

Epoch: 5| Step: 3
Training loss: 0.9725397229194641
Validation loss: 1.8847560139112576

Epoch: 5| Step: 4
Training loss: 0.3893820643424988
Validation loss: 1.8263472305831088

Epoch: 5| Step: 5
Training loss: 1.1423959732055664
Validation loss: 1.8501639186695058

Epoch: 5| Step: 6
Training loss: 1.0748536586761475
Validation loss: 1.8488285464625205

Epoch: 5| Step: 7
Training loss: 1.1555763483047485
Validation loss: 1.791917162556802

Epoch: 5| Step: 8
Training loss: 1.2119207382202148
Validation loss: 1.8292900362322408

Epoch: 5| Step: 9
Training loss: 1.2279274463653564
Validation loss: 1.8810321874515985

Epoch: 5| Step: 10
Training loss: 0.8252760767936707
Validation loss: 1.8420944316412813

Epoch: 463| Step: 0
Training loss: 1.170325517654419
Validation loss: 1.8328463633855183

Epoch: 5| Step: 1
Training loss: 1.1924235820770264
Validation loss: 1.8276558922183128

Epoch: 5| Step: 2
Training loss: 0.6716275215148926
Validation loss: 1.8053690156629008

Epoch: 5| Step: 3
Training loss: 0.8747126460075378
Validation loss: 1.8594763791689308

Epoch: 5| Step: 4
Training loss: 1.4231197834014893
Validation loss: 1.8642623847530735

Epoch: 5| Step: 5
Training loss: 1.1480299234390259
Validation loss: 1.8000684310031194

Epoch: 5| Step: 6
Training loss: 0.5933176279067993
Validation loss: 1.8367542323245798

Epoch: 5| Step: 7
Training loss: 1.1874370574951172
Validation loss: 1.8895763915072206

Epoch: 5| Step: 8
Training loss: 0.898999035358429
Validation loss: 1.8551827053869925

Epoch: 5| Step: 9
Training loss: 1.2949551343917847
Validation loss: 1.9007559181541525

Epoch: 5| Step: 10
Training loss: 0.5722081661224365
Validation loss: 1.8504455551024406

Epoch: 464| Step: 0
Training loss: 0.971183180809021
Validation loss: 1.8766041904367425

Epoch: 5| Step: 1
Training loss: 1.0628407001495361
Validation loss: 1.8093937776421989

Epoch: 5| Step: 2
Training loss: 1.1628596782684326
Validation loss: 1.8231810164707962

Epoch: 5| Step: 3
Training loss: 0.9835878610610962
Validation loss: 1.8308981439118743

Epoch: 5| Step: 4
Training loss: 1.190618872642517
Validation loss: 1.806930947047408

Epoch: 5| Step: 5
Training loss: 1.2244954109191895
Validation loss: 1.8122357604324177

Epoch: 5| Step: 6
Training loss: 1.0883524417877197
Validation loss: 1.8203313453223116

Epoch: 5| Step: 7
Training loss: 0.7911057472229004
Validation loss: 1.8343680392029464

Epoch: 5| Step: 8
Training loss: 1.0526857376098633
Validation loss: 1.8655816765241726

Epoch: 5| Step: 9
Training loss: 0.6438534259796143
Validation loss: 1.8432855529169883

Epoch: 5| Step: 10
Training loss: 0.8560461401939392
Validation loss: 1.8561031664571455

Epoch: 465| Step: 0
Training loss: 0.7123120427131653
Validation loss: 1.8008266982211862

Epoch: 5| Step: 1
Training loss: 1.2178899049758911
Validation loss: 1.8427632444648332

Epoch: 5| Step: 2
Training loss: 0.7874161601066589
Validation loss: 1.8038316029374317

Epoch: 5| Step: 3
Training loss: 1.19842529296875
Validation loss: 1.815739639343754

Epoch: 5| Step: 4
Training loss: 0.7834140658378601
Validation loss: 1.828690662178942

Epoch: 5| Step: 5
Training loss: 1.1193695068359375
Validation loss: 1.82292991171601

Epoch: 5| Step: 6
Training loss: 1.0462729930877686
Validation loss: 1.8110387248377646

Epoch: 5| Step: 7
Training loss: 1.6043779850006104
Validation loss: 1.8605370367726972

Epoch: 5| Step: 8
Training loss: 1.0304582118988037
Validation loss: 1.8217971453102686

Epoch: 5| Step: 9
Training loss: 1.0560978651046753
Validation loss: 1.7931517195957962

Epoch: 5| Step: 10
Training loss: 0.6576762199401855
Validation loss: 1.8659411950777935

Epoch: 466| Step: 0
Training loss: 1.0304549932479858
Validation loss: 1.8274658700471282

Epoch: 5| Step: 1
Training loss: 1.0977524518966675
Validation loss: 1.8112611014355895

Epoch: 5| Step: 2
Training loss: 0.9096860885620117
Validation loss: 1.8500765036511164

Epoch: 5| Step: 3
Training loss: 0.9496085047721863
Validation loss: 1.8337726593017578

Epoch: 5| Step: 4
Training loss: 0.9568372964859009
Validation loss: 1.850263108489334

Epoch: 5| Step: 5
Training loss: 1.0908079147338867
Validation loss: 1.8506455267629316

Epoch: 5| Step: 6
Training loss: 1.1837403774261475
Validation loss: 1.9107979023328392

Epoch: 5| Step: 7
Training loss: 0.9463114738464355
Validation loss: 1.8540372335782616

Epoch: 5| Step: 8
Training loss: 1.054468035697937
Validation loss: 1.8927540830386582

Epoch: 5| Step: 9
Training loss: 1.1792064905166626
Validation loss: 1.8034414565691383

Epoch: 5| Step: 10
Training loss: 0.790928840637207
Validation loss: 1.8425224468272219

Epoch: 467| Step: 0
Training loss: 0.743683934211731
Validation loss: 1.8764957445924

Epoch: 5| Step: 1
Training loss: 1.4424874782562256
Validation loss: 1.798648734246531

Epoch: 5| Step: 2
Training loss: 0.9599822759628296
Validation loss: 1.8564037930580877

Epoch: 5| Step: 3
Training loss: 1.4573495388031006
Validation loss: 1.8009533036139704

Epoch: 5| Step: 4
Training loss: 0.9988082647323608
Validation loss: 1.8173877128990747

Epoch: 5| Step: 5
Training loss: 0.9929476976394653
Validation loss: 1.829928554514403

Epoch: 5| Step: 6
Training loss: 0.7255744338035583
Validation loss: 1.8164575599854993

Epoch: 5| Step: 7
Training loss: 0.9244842529296875
Validation loss: 1.8372050357121292

Epoch: 5| Step: 8
Training loss: 1.0265460014343262
Validation loss: 1.8705682011060818

Epoch: 5| Step: 9
Training loss: 0.7060419321060181
Validation loss: 1.8866826629125943

Epoch: 5| Step: 10
Training loss: 0.8939333558082581
Validation loss: 1.881256143252055

Epoch: 468| Step: 0
Training loss: 1.079484224319458
Validation loss: 1.871758113625229

Epoch: 5| Step: 1
Training loss: 0.6143201589584351
Validation loss: 1.8624295701262772

Epoch: 5| Step: 2
Training loss: 0.87501060962677
Validation loss: 1.8413021743938487

Epoch: 5| Step: 3
Training loss: 0.9536676406860352
Validation loss: 1.8873052071499568

Epoch: 5| Step: 4
Training loss: 1.2271597385406494
Validation loss: 1.8729638361161756

Epoch: 5| Step: 5
Training loss: 1.3696603775024414
Validation loss: 1.8090093546016242

Epoch: 5| Step: 6
Training loss: 1.1894264221191406
Validation loss: 1.8273459596018637

Epoch: 5| Step: 7
Training loss: 0.9000229835510254
Validation loss: 1.8066687635196153

Epoch: 5| Step: 8
Training loss: 0.8690530061721802
Validation loss: 1.8138802525817708

Epoch: 5| Step: 9
Training loss: 0.9120258092880249
Validation loss: 1.8274067281394877

Epoch: 5| Step: 10
Training loss: 0.8270365595817566
Validation loss: 1.8099569659079275

Epoch: 469| Step: 0
Training loss: 1.0985218286514282
Validation loss: 1.8163976566765898

Epoch: 5| Step: 1
Training loss: 0.8853986859321594
Validation loss: 1.86872689313786

Epoch: 5| Step: 2
Training loss: 0.9090363383293152
Validation loss: 1.8083634914890412

Epoch: 5| Step: 3
Training loss: 1.208937406539917
Validation loss: 1.8700273831685383

Epoch: 5| Step: 4
Training loss: 1.3988139629364014
Validation loss: 1.8206443363620388

Epoch: 5| Step: 5
Training loss: 1.0577702522277832
Validation loss: 1.8387704254478536

Epoch: 5| Step: 6
Training loss: 0.9503313302993774
Validation loss: 1.8552454915097965

Epoch: 5| Step: 7
Training loss: 0.6629550457000732
Validation loss: 1.8263113896052043

Epoch: 5| Step: 8
Training loss: 0.8724400401115417
Validation loss: 1.8502319910193001

Epoch: 5| Step: 9
Training loss: 0.7473405599594116
Validation loss: 1.840062000418222

Epoch: 5| Step: 10
Training loss: 0.9911502599716187
Validation loss: 1.8395309832788282

Epoch: 470| Step: 0
Training loss: 1.121017575263977
Validation loss: 1.90911179460505

Epoch: 5| Step: 1
Training loss: 0.613356351852417
Validation loss: 1.850929726836502

Epoch: 5| Step: 2
Training loss: 1.5220085382461548
Validation loss: 1.8896188082233552

Epoch: 5| Step: 3
Training loss: 0.8144661784172058
Validation loss: 1.881778447858749

Epoch: 5| Step: 4
Training loss: 0.8771861791610718
Validation loss: 1.8793482434365056

Epoch: 5| Step: 5
Training loss: 0.8308621644973755
Validation loss: 1.8915566321342223

Epoch: 5| Step: 6
Training loss: 0.7057601809501648
Validation loss: 1.8500025964552356

Epoch: 5| Step: 7
Training loss: 1.301914930343628
Validation loss: 1.7876556355466124

Epoch: 5| Step: 8
Training loss: 1.355908989906311
Validation loss: 1.8239025838913456

Epoch: 5| Step: 9
Training loss: 1.166326642036438
Validation loss: 1.8178441998779133

Epoch: 5| Step: 10
Training loss: 0.8185431361198425
Validation loss: 1.8166262334392917

Epoch: 471| Step: 0
Training loss: 1.2681788206100464
Validation loss: 1.8584572679253035

Epoch: 5| Step: 1
Training loss: 1.0146968364715576
Validation loss: 1.7861624866403558

Epoch: 5| Step: 2
Training loss: 1.0289102792739868
Validation loss: 1.8510569218666322

Epoch: 5| Step: 3
Training loss: 0.9535753130912781
Validation loss: 1.814323667557009

Epoch: 5| Step: 4
Training loss: 1.1067999601364136
Validation loss: 1.833964576003372

Epoch: 5| Step: 5
Training loss: 1.084136724472046
Validation loss: 1.7905463223816247

Epoch: 5| Step: 6
Training loss: 0.8551275134086609
Validation loss: 1.840027839906754

Epoch: 5| Step: 7
Training loss: 0.4106811583042145
Validation loss: 1.8215799241937616

Epoch: 5| Step: 8
Training loss: 0.8303488492965698
Validation loss: 1.8354180756435599

Epoch: 5| Step: 9
Training loss: 1.4166538715362549
Validation loss: 1.834794884086937

Epoch: 5| Step: 10
Training loss: 0.8028469085693359
Validation loss: 1.830190707278508

Epoch: 472| Step: 0
Training loss: 1.2101562023162842
Validation loss: 1.8705554803212483

Epoch: 5| Step: 1
Training loss: 1.1928141117095947
Validation loss: 1.8418276207421416

Epoch: 5| Step: 2
Training loss: 0.9434410333633423
Validation loss: 1.8003835844737228

Epoch: 5| Step: 3
Training loss: 0.8199800252914429
Validation loss: 1.832352384444206

Epoch: 5| Step: 4
Training loss: 1.2901802062988281
Validation loss: 1.806201647686702

Epoch: 5| Step: 5
Training loss: 0.6050671339035034
Validation loss: 1.8448312679926555

Epoch: 5| Step: 6
Training loss: 1.411409616470337
Validation loss: 1.8296253924728723

Epoch: 5| Step: 7
Training loss: 0.5941237807273865
Validation loss: 1.8107239302768503

Epoch: 5| Step: 8
Training loss: 1.2759130001068115
Validation loss: 1.8219825708737938

Epoch: 5| Step: 9
Training loss: 0.4550630450248718
Validation loss: 1.8346753786968928

Epoch: 5| Step: 10
Training loss: 1.110304832458496
Validation loss: 1.8559149003797961

Epoch: 473| Step: 0
Training loss: 0.8900473713874817
Validation loss: 1.8618335723876953

Epoch: 5| Step: 1
Training loss: 0.6436565518379211
Validation loss: 1.8649008825261106

Epoch: 5| Step: 2
Training loss: 1.084407091140747
Validation loss: 1.8577324421175065

Epoch: 5| Step: 3
Training loss: 1.2594196796417236
Validation loss: 1.9076703722758959

Epoch: 5| Step: 4
Training loss: 1.3321905136108398
Validation loss: 1.8795213404522146

Epoch: 5| Step: 5
Training loss: 1.1026725769042969
Validation loss: 1.932256051289138

Epoch: 5| Step: 6
Training loss: 1.216199517250061
Validation loss: 1.919887368397046

Epoch: 5| Step: 7
Training loss: 0.8785344958305359
Validation loss: 1.8426266998373053

Epoch: 5| Step: 8
Training loss: 0.6450986266136169
Validation loss: 1.8923834728938278

Epoch: 5| Step: 9
Training loss: 1.0797810554504395
Validation loss: 1.8163982334957327

Epoch: 5| Step: 10
Training loss: 0.9368260502815247
Validation loss: 1.8532404553505681

Epoch: 474| Step: 0
Training loss: 0.9400562047958374
Validation loss: 1.893931714437341

Epoch: 5| Step: 1
Training loss: 0.7866318821907043
Validation loss: 1.8283111844011533

Epoch: 5| Step: 2
Training loss: 0.8176038861274719
Validation loss: 1.7813911348260858

Epoch: 5| Step: 3
Training loss: 0.9105173945426941
Validation loss: 1.8558300105474328

Epoch: 5| Step: 4
Training loss: 0.8799877166748047
Validation loss: 1.9006552388591151

Epoch: 5| Step: 5
Training loss: 0.9730839729309082
Validation loss: 1.832016013001883

Epoch: 5| Step: 6
Training loss: 0.6101372838020325
Validation loss: 1.844673574611705

Epoch: 5| Step: 7
Training loss: 1.5180866718292236
Validation loss: 1.8590320746103923

Epoch: 5| Step: 8
Training loss: 0.9921859502792358
Validation loss: 1.846452311802936

Epoch: 5| Step: 9
Training loss: 1.4768630266189575
Validation loss: 1.8432780299135434

Epoch: 5| Step: 10
Training loss: 1.1669504642486572
Validation loss: 1.8512077677634455

Epoch: 475| Step: 0
Training loss: 0.818798840045929
Validation loss: 1.873171765317199

Epoch: 5| Step: 1
Training loss: 0.9928351640701294
Validation loss: 1.8799311730169481

Epoch: 5| Step: 2
Training loss: 0.7449592351913452
Validation loss: 1.7976190749035086

Epoch: 5| Step: 3
Training loss: 1.031241774559021
Validation loss: 1.8126908835544382

Epoch: 5| Step: 4
Training loss: 0.9264106750488281
Validation loss: 1.8298742771148682

Epoch: 5| Step: 5
Training loss: 0.9217178225517273
Validation loss: 1.8410985841546008

Epoch: 5| Step: 6
Training loss: 0.9138346910476685
Validation loss: 1.8114971166015954

Epoch: 5| Step: 7
Training loss: 1.369816541671753
Validation loss: 1.847468032631823

Epoch: 5| Step: 8
Training loss: 1.1803629398345947
Validation loss: 1.8608701408550303

Epoch: 5| Step: 9
Training loss: 1.0375101566314697
Validation loss: 1.818470758776511

Epoch: 5| Step: 10
Training loss: 1.1859214305877686
Validation loss: 1.8183902860969625

Epoch: 476| Step: 0
Training loss: 0.8885637521743774
Validation loss: 1.8156192712886359

Epoch: 5| Step: 1
Training loss: 0.6018040776252747
Validation loss: 1.777607967776637

Epoch: 5| Step: 2
Training loss: 0.9275640249252319
Validation loss: 1.8612985328961444

Epoch: 5| Step: 3
Training loss: 0.9716634750366211
Validation loss: 1.8311452891236992

Epoch: 5| Step: 4
Training loss: 0.8752117156982422
Validation loss: 1.8611752858725927

Epoch: 5| Step: 5
Training loss: 1.0768351554870605
Validation loss: 1.874279377281025

Epoch: 5| Step: 6
Training loss: 0.8553935885429382
Validation loss: 1.8407076712577575

Epoch: 5| Step: 7
Training loss: 1.5093048810958862
Validation loss: 1.835370853383054

Epoch: 5| Step: 8
Training loss: 1.3544899225234985
Validation loss: 1.8175026062996156

Epoch: 5| Step: 9
Training loss: 0.8606016039848328
Validation loss: 1.8458177107636646

Epoch: 5| Step: 10
Training loss: 0.7746075987815857
Validation loss: 1.8679784382543256

Epoch: 477| Step: 0
Training loss: 0.718001663684845
Validation loss: 1.8684654197385233

Epoch: 5| Step: 1
Training loss: 0.9648426175117493
Validation loss: 1.8481078506797872

Epoch: 5| Step: 2
Training loss: 1.7199220657348633
Validation loss: 1.8045710427786714

Epoch: 5| Step: 3
Training loss: 0.8650561571121216
Validation loss: 1.8446768817081247

Epoch: 5| Step: 4
Training loss: 1.2521666288375854
Validation loss: 1.855981469154358

Epoch: 5| Step: 5
Training loss: 0.8278425335884094
Validation loss: 1.8135577453080045

Epoch: 5| Step: 6
Training loss: 0.8998252749443054
Validation loss: 1.8104210284448439

Epoch: 5| Step: 7
Training loss: 0.7529700994491577
Validation loss: 1.803684949874878

Epoch: 5| Step: 8
Training loss: 1.2435004711151123
Validation loss: 1.8165639356900287

Epoch: 5| Step: 9
Training loss: 0.9853532910346985
Validation loss: 1.8084581411013039

Epoch: 5| Step: 10
Training loss: 0.3482339382171631
Validation loss: 1.8350743542435348

Epoch: 478| Step: 0
Training loss: 1.055533528327942
Validation loss: 1.834354623671501

Epoch: 5| Step: 1
Training loss: 0.9986429214477539
Validation loss: 1.8634795617031794

Epoch: 5| Step: 2
Training loss: 1.0738000869750977
Validation loss: 1.8644306262334187

Epoch: 5| Step: 3
Training loss: 0.9213501214981079
Validation loss: 1.8819492363160657

Epoch: 5| Step: 4
Training loss: 0.9464726448059082
Validation loss: 1.882047628843656

Epoch: 5| Step: 5
Training loss: 0.6560953855514526
Validation loss: 1.876809904652257

Epoch: 5| Step: 6
Training loss: 0.8325561285018921
Validation loss: 1.8393560430055023

Epoch: 5| Step: 7
Training loss: 1.1441494226455688
Validation loss: 1.8806091944376628

Epoch: 5| Step: 8
Training loss: 1.5995962619781494
Validation loss: 1.8216045018165343

Epoch: 5| Step: 9
Training loss: 1.0822863578796387
Validation loss: 1.814174795663485

Epoch: 5| Step: 10
Training loss: 0.540550172328949
Validation loss: 1.8126576677445443

Epoch: 479| Step: 0
Training loss: 0.8654681444168091
Validation loss: 1.8145059718880603

Epoch: 5| Step: 1
Training loss: 1.3511605262756348
Validation loss: 1.8096272278857488

Epoch: 5| Step: 2
Training loss: 1.056943416595459
Validation loss: 1.799437531860926

Epoch: 5| Step: 3
Training loss: 1.0504934787750244
Validation loss: 1.8079900126303396

Epoch: 5| Step: 4
Training loss: 0.9343875050544739
Validation loss: 1.7938604457404024

Epoch: 5| Step: 5
Training loss: 0.9022523760795593
Validation loss: 1.792025049527486

Epoch: 5| Step: 6
Training loss: 0.6769767999649048
Validation loss: 1.7723412770096973

Epoch: 5| Step: 7
Training loss: 0.8619400262832642
Validation loss: 1.8045396932991602

Epoch: 5| Step: 8
Training loss: 1.006099820137024
Validation loss: 1.8542230975243352

Epoch: 5| Step: 9
Training loss: 1.0689361095428467
Validation loss: 1.8652378141239125

Epoch: 5| Step: 10
Training loss: 1.1282089948654175
Validation loss: 1.8572679232525569

Epoch: 480| Step: 0
Training loss: 0.8121498823165894
Validation loss: 1.846519031832295

Epoch: 5| Step: 1
Training loss: 1.0783236026763916
Validation loss: 1.8321731372546124

Epoch: 5| Step: 2
Training loss: 0.9091266393661499
Validation loss: 1.8389522734508719

Epoch: 5| Step: 3
Training loss: 1.0296533107757568
Validation loss: 1.8216123786023868

Epoch: 5| Step: 4
Training loss: 0.8360390663146973
Validation loss: 1.8234609839736775

Epoch: 5| Step: 5
Training loss: 0.7411577105522156
Validation loss: 1.869825319577289

Epoch: 5| Step: 6
Training loss: 1.4013510942459106
Validation loss: 1.8478361316906509

Epoch: 5| Step: 7
Training loss: 0.6769667863845825
Validation loss: 1.8850225915190995

Epoch: 5| Step: 8
Training loss: 1.0330126285552979
Validation loss: 1.8085940884005638

Epoch: 5| Step: 9
Training loss: 1.1105124950408936
Validation loss: 1.80430006980896

Epoch: 5| Step: 10
Training loss: 1.031325340270996
Validation loss: 1.8230297514187392

Epoch: 481| Step: 0
Training loss: 0.8684180378913879
Validation loss: 1.8774151340607674

Epoch: 5| Step: 1
Training loss: 1.13164484500885
Validation loss: 1.8384839052795081

Epoch: 5| Step: 2
Training loss: 0.8898090124130249
Validation loss: 1.820086976533295

Epoch: 5| Step: 3
Training loss: 1.011788010597229
Validation loss: 1.8283250306242256

Epoch: 5| Step: 4
Training loss: 0.8470488786697388
Validation loss: 1.8228672371115735

Epoch: 5| Step: 5
Training loss: 0.9159854054450989
Validation loss: 1.8292960684786561

Epoch: 5| Step: 6
Training loss: 0.8391609191894531
Validation loss: 1.8291425307591755

Epoch: 5| Step: 7
Training loss: 0.9418683052062988
Validation loss: 1.87701597521382

Epoch: 5| Step: 8
Training loss: 0.8599516153335571
Validation loss: 1.8418344169534662

Epoch: 5| Step: 9
Training loss: 1.6133686304092407
Validation loss: 1.8018928548341155

Epoch: 5| Step: 10
Training loss: 0.8944901823997498
Validation loss: 1.847034873500947

Epoch: 482| Step: 0
Training loss: 0.9457346200942993
Validation loss: 1.7650284344150173

Epoch: 5| Step: 1
Training loss: 1.071805715560913
Validation loss: 1.7861649182534987

Epoch: 5| Step: 2
Training loss: 0.8375695943832397
Validation loss: 1.8387669901694021

Epoch: 5| Step: 3
Training loss: 0.9361914396286011
Validation loss: 1.8139933680975309

Epoch: 5| Step: 4
Training loss: 0.9735490083694458
Validation loss: 1.8205729248703166

Epoch: 5| Step: 5
Training loss: 0.9442422986030579
Validation loss: 1.8160423207026657

Epoch: 5| Step: 6
Training loss: 1.1233733892440796
Validation loss: 1.7918017269462667

Epoch: 5| Step: 7
Training loss: 1.2032086849212646
Validation loss: 1.7902304716007684

Epoch: 5| Step: 8
Training loss: 0.8026242256164551
Validation loss: 1.8224196844203497

Epoch: 5| Step: 9
Training loss: 1.010194182395935
Validation loss: 1.8330607965428343

Epoch: 5| Step: 10
Training loss: 0.7395341396331787
Validation loss: 1.8627099593480427

Epoch: 483| Step: 0
Training loss: 1.1930394172668457
Validation loss: 1.8557166694312968

Epoch: 5| Step: 1
Training loss: 1.043163776397705
Validation loss: 1.8639821596043085

Epoch: 5| Step: 2
Training loss: 1.1280306577682495
Validation loss: 1.8210151003253074

Epoch: 5| Step: 3
Training loss: 1.2495816946029663
Validation loss: 1.8017223599136516

Epoch: 5| Step: 4
Training loss: 0.7179452776908875
Validation loss: 1.8291134193379393

Epoch: 5| Step: 5
Training loss: 0.9041522145271301
Validation loss: 1.8433771479514338

Epoch: 5| Step: 6
Training loss: 0.7721614241600037
Validation loss: 1.8449978290065643

Epoch: 5| Step: 7
Training loss: 0.8516246676445007
Validation loss: 1.8717567895048408

Epoch: 5| Step: 8
Training loss: 1.0766065120697021
Validation loss: 1.817836183373646

Epoch: 5| Step: 9
Training loss: 0.8288141489028931
Validation loss: 1.8522677178023963

Epoch: 5| Step: 10
Training loss: 0.44773852825164795
Validation loss: 1.858313686104231

Epoch: 484| Step: 0
Training loss: 0.7802039384841919
Validation loss: 1.8331433547440397

Epoch: 5| Step: 1
Training loss: 0.8380405306816101
Validation loss: 1.901052108374975

Epoch: 5| Step: 2
Training loss: 1.073897123336792
Validation loss: 1.8595041126333258

Epoch: 5| Step: 3
Training loss: 0.7167667150497437
Validation loss: 1.8831154941230692

Epoch: 5| Step: 4
Training loss: 1.4036877155303955
Validation loss: 1.7659418480370634

Epoch: 5| Step: 5
Training loss: 1.4968055486679077
Validation loss: 1.8382963160032868

Epoch: 5| Step: 6
Training loss: 0.6145257353782654
Validation loss: 1.8040967743883851

Epoch: 5| Step: 7
Training loss: 1.1056331396102905
Validation loss: 1.749981153395868

Epoch: 5| Step: 8
Training loss: 0.9386612176895142
Validation loss: 1.837415946427212

Epoch: 5| Step: 9
Training loss: 0.8869180679321289
Validation loss: 1.8255833771920973

Epoch: 5| Step: 10
Training loss: 0.7040647268295288
Validation loss: 1.8303409981471237

Epoch: 485| Step: 0
Training loss: 0.7464033365249634
Validation loss: 1.7963645253130185

Epoch: 5| Step: 1
Training loss: 1.4591763019561768
Validation loss: 1.7915994223727976

Epoch: 5| Step: 2
Training loss: 0.5022751092910767
Validation loss: 1.8190929697405906

Epoch: 5| Step: 3
Training loss: 0.6473226547241211
Validation loss: 1.8148895079089749

Epoch: 5| Step: 4
Training loss: 0.9729800224304199
Validation loss: 1.8415339069981729

Epoch: 5| Step: 5
Training loss: 0.7823662757873535
Validation loss: 1.8244206084999988

Epoch: 5| Step: 6
Training loss: 0.9246923327445984
Validation loss: 1.8542149630925988

Epoch: 5| Step: 7
Training loss: 1.2069823741912842
Validation loss: 1.8283240743862685

Epoch: 5| Step: 8
Training loss: 0.7321425676345825
Validation loss: 1.8343851912406184

Epoch: 5| Step: 9
Training loss: 1.2042179107666016
Validation loss: 1.8282913725863221

Epoch: 5| Step: 10
Training loss: 1.3497662544250488
Validation loss: 1.7961797419414725

Epoch: 486| Step: 0
Training loss: 0.682339072227478
Validation loss: 1.8234830415377052

Epoch: 5| Step: 1
Training loss: 0.9515659213066101
Validation loss: 1.8213933462737708

Epoch: 5| Step: 2
Training loss: 1.557334303855896
Validation loss: 1.863490871203843

Epoch: 5| Step: 3
Training loss: 1.1520922183990479
Validation loss: 1.8222494984185824

Epoch: 5| Step: 4
Training loss: 0.9811959266662598
Validation loss: 1.8713093393592424

Epoch: 5| Step: 5
Training loss: 0.8812271356582642
Validation loss: 1.8001755450361518

Epoch: 5| Step: 6
Training loss: 0.9216006398200989
Validation loss: 1.8341995541767409

Epoch: 5| Step: 7
Training loss: 0.9398649334907532
Validation loss: 1.8282094463225333

Epoch: 5| Step: 8
Training loss: 1.030745267868042
Validation loss: 1.8614097359359905

Epoch: 5| Step: 9
Training loss: 0.8818506002426147
Validation loss: 1.8004568994686168

Epoch: 5| Step: 10
Training loss: 0.7112079858779907
Validation loss: 1.8561991940262497

Epoch: 487| Step: 0
Training loss: 0.9896392822265625
Validation loss: 1.8357368348747172

Epoch: 5| Step: 1
Training loss: 1.1503541469573975
Validation loss: 1.8274042978081653

Epoch: 5| Step: 2
Training loss: 0.40343132615089417
Validation loss: 1.808428002941993

Epoch: 5| Step: 3
Training loss: 0.8463408350944519
Validation loss: 1.8104451510214037

Epoch: 5| Step: 4
Training loss: 1.317549705505371
Validation loss: 1.8292784383220058

Epoch: 5| Step: 5
Training loss: 0.6248313188552856
Validation loss: 1.8183708908737346

Epoch: 5| Step: 6
Training loss: 1.0119835138320923
Validation loss: 1.8187837357162147

Epoch: 5| Step: 7
Training loss: 0.8365194201469421
Validation loss: 1.8314460759521813

Epoch: 5| Step: 8
Training loss: 0.8696796298027039
Validation loss: 1.8313202883607598

Epoch: 5| Step: 9
Training loss: 1.014289140701294
Validation loss: 1.8392588989709013

Epoch: 5| Step: 10
Training loss: 1.3660717010498047
Validation loss: 1.8456083138783772

Epoch: 488| Step: 0
Training loss: 0.8957427740097046
Validation loss: 1.85934668074372

Epoch: 5| Step: 1
Training loss: 1.0711864233016968
Validation loss: 1.7965377428198372

Epoch: 5| Step: 2
Training loss: 1.1848938465118408
Validation loss: 1.8563572668260144

Epoch: 5| Step: 3
Training loss: 0.7784766554832458
Validation loss: 1.8346130399293796

Epoch: 5| Step: 4
Training loss: 1.071816086769104
Validation loss: 1.8300920032685803

Epoch: 5| Step: 5
Training loss: 0.8014148473739624
Validation loss: 1.8134557431743992

Epoch: 5| Step: 6
Training loss: 1.0240609645843506
Validation loss: 1.8232787475791028

Epoch: 5| Step: 7
Training loss: 1.0200914144515991
Validation loss: 1.820619212683811

Epoch: 5| Step: 8
Training loss: 0.7640883326530457
Validation loss: 1.8403842013369325

Epoch: 5| Step: 9
Training loss: 0.9582640528678894
Validation loss: 1.779393878034366

Epoch: 5| Step: 10
Training loss: 0.875141978263855
Validation loss: 1.8390802080913256

Epoch: 489| Step: 0
Training loss: 0.7295489311218262
Validation loss: 1.8166008790334065

Epoch: 5| Step: 1
Training loss: 1.482289433479309
Validation loss: 1.7646880816387873

Epoch: 5| Step: 2
Training loss: 0.5362024307250977
Validation loss: 1.8491463122829315

Epoch: 5| Step: 3
Training loss: 1.1585731506347656
Validation loss: 1.815922579457683

Epoch: 5| Step: 4
Training loss: 1.1276240348815918
Validation loss: 1.8517003290114864

Epoch: 5| Step: 5
Training loss: 1.1503355503082275
Validation loss: 1.829687339003368

Epoch: 5| Step: 6
Training loss: 0.899511992931366
Validation loss: 1.7892045974731445

Epoch: 5| Step: 7
Training loss: 0.6316002011299133
Validation loss: 1.805846801368139

Epoch: 5| Step: 8
Training loss: 0.9917192459106445
Validation loss: 1.774447351373652

Epoch: 5| Step: 9
Training loss: 0.8731763958930969
Validation loss: 1.8264170154448478

Epoch: 5| Step: 10
Training loss: 0.9360975027084351
Validation loss: 1.8109303212934924

Epoch: 490| Step: 0
Training loss: 0.9183005094528198
Validation loss: 1.8007098590174029

Epoch: 5| Step: 1
Training loss: 1.1211109161376953
Validation loss: 1.882792866358193

Epoch: 5| Step: 2
Training loss: 1.123281478881836
Validation loss: 1.8370247323025939

Epoch: 5| Step: 3
Training loss: 1.2548434734344482
Validation loss: 1.8597766789056922

Epoch: 5| Step: 4
Training loss: 1.0182362794876099
Validation loss: 1.8500488868323706

Epoch: 5| Step: 5
Training loss: 0.6552039384841919
Validation loss: 1.8648003173130814

Epoch: 5| Step: 6
Training loss: 1.022686243057251
Validation loss: 1.8121959047932779

Epoch: 5| Step: 7
Training loss: 0.823384165763855
Validation loss: 1.8584292909150482

Epoch: 5| Step: 8
Training loss: 1.1005728244781494
Validation loss: 1.8436980298770371

Epoch: 5| Step: 9
Training loss: 0.5786668062210083
Validation loss: 1.8479582250759166

Epoch: 5| Step: 10
Training loss: 0.8704919219017029
Validation loss: 1.878795721197641

Epoch: 491| Step: 0
Training loss: 1.2422488927841187
Validation loss: 1.792168463430097

Epoch: 5| Step: 1
Training loss: 0.6717772483825684
Validation loss: 1.848815938477875

Epoch: 5| Step: 2
Training loss: 0.8759934306144714
Validation loss: 1.8461290328733382

Epoch: 5| Step: 3
Training loss: 1.1060768365859985
Validation loss: 1.8035323119932605

Epoch: 5| Step: 4
Training loss: 0.5825899839401245
Validation loss: 1.8182508637828212

Epoch: 5| Step: 5
Training loss: 0.9025779962539673
Validation loss: 1.8504420916239421

Epoch: 5| Step: 6
Training loss: 0.9818015098571777
Validation loss: 1.823486258906703

Epoch: 5| Step: 7
Training loss: 1.4443638324737549
Validation loss: 1.814737819856213

Epoch: 5| Step: 8
Training loss: 1.0746349096298218
Validation loss: 1.8611231978221605

Epoch: 5| Step: 9
Training loss: 1.1798694133758545
Validation loss: 1.8231419876057615

Epoch: 5| Step: 10
Training loss: 0.5675421953201294
Validation loss: 1.8104330942194948

Epoch: 492| Step: 0
Training loss: 1.1163794994354248
Validation loss: 1.7988153067968224

Epoch: 5| Step: 1
Training loss: 1.135033130645752
Validation loss: 1.8310927421815935

Epoch: 5| Step: 2
Training loss: 1.1980879306793213
Validation loss: 1.891050539990907

Epoch: 5| Step: 3
Training loss: 0.5662333369255066
Validation loss: 1.8887189511329896

Epoch: 5| Step: 4
Training loss: 0.6362058520317078
Validation loss: 1.8671496145186885

Epoch: 5| Step: 5
Training loss: 0.9695279002189636
Validation loss: 1.8571347690397693

Epoch: 5| Step: 6
Training loss: 1.172808289527893
Validation loss: 1.8230743536385157

Epoch: 5| Step: 7
Training loss: 0.717974066734314
Validation loss: 1.879487649086983

Epoch: 5| Step: 8
Training loss: 1.3188350200653076
Validation loss: 1.8472203003462924

Epoch: 5| Step: 9
Training loss: 0.9104663133621216
Validation loss: 1.8583164035633046

Epoch: 5| Step: 10
Training loss: 0.9755463600158691
Validation loss: 1.870179383985458

Epoch: 493| Step: 0
Training loss: 0.7920268774032593
Validation loss: 1.8265014899674283

Epoch: 5| Step: 1
Training loss: 1.3007278442382812
Validation loss: 1.8527546710865472

Epoch: 5| Step: 2
Training loss: 0.7614442706108093
Validation loss: 1.8524271749681043

Epoch: 5| Step: 3
Training loss: 1.0449845790863037
Validation loss: 1.8614851082524946

Epoch: 5| Step: 4
Training loss: 1.017638921737671
Validation loss: 1.8154136750005907

Epoch: 5| Step: 5
Training loss: 0.7933875918388367
Validation loss: 1.8190063468871578

Epoch: 5| Step: 6
Training loss: 1.2213084697723389
Validation loss: 1.8503722772803357

Epoch: 5| Step: 7
Training loss: 0.8095480799674988
Validation loss: 1.7849793741779942

Epoch: 5| Step: 8
Training loss: 0.7126508355140686
Validation loss: 1.8583714987642022

Epoch: 5| Step: 9
Training loss: 1.0866588354110718
Validation loss: 1.8508073770871727

Epoch: 5| Step: 10
Training loss: 0.9599146246910095
Validation loss: 1.8706941117522538

Epoch: 494| Step: 0
Training loss: 0.7230488061904907
Validation loss: 1.8375162270761305

Epoch: 5| Step: 1
Training loss: 0.8441423177719116
Validation loss: 1.8260338306427002

Epoch: 5| Step: 2
Training loss: 0.9517967104911804
Validation loss: 1.8628157518243278

Epoch: 5| Step: 3
Training loss: 1.058526635169983
Validation loss: 1.839261137029176

Epoch: 5| Step: 4
Training loss: 0.8442846536636353
Validation loss: 1.8334278675817675

Epoch: 5| Step: 5
Training loss: 0.5645157098770142
Validation loss: 1.8178311714562037

Epoch: 5| Step: 6
Training loss: 1.0565898418426514
Validation loss: 1.855307004785025

Epoch: 5| Step: 7
Training loss: 0.9857250452041626
Validation loss: 1.8271404645776237

Epoch: 5| Step: 8
Training loss: 1.6549196243286133
Validation loss: 1.7740615824217438

Epoch: 5| Step: 9
Training loss: 0.6557899713516235
Validation loss: 1.8011347350253855

Epoch: 5| Step: 10
Training loss: 0.9893606901168823
Validation loss: 1.823565854821154

Epoch: 495| Step: 0
Training loss: 0.928307056427002
Validation loss: 1.8101849376514394

Epoch: 5| Step: 1
Training loss: 0.8231217265129089
Validation loss: 1.8445790147268644

Epoch: 5| Step: 2
Training loss: 0.9048469662666321
Validation loss: 1.8472142693816975

Epoch: 5| Step: 3
Training loss: 0.9012889862060547
Validation loss: 1.8713124413644113

Epoch: 5| Step: 4
Training loss: 0.7794890403747559
Validation loss: 1.8063095692665345

Epoch: 5| Step: 5
Training loss: 1.1272063255310059
Validation loss: 1.824465306856299

Epoch: 5| Step: 6
Training loss: 0.9967941045761108
Validation loss: 1.8446709827710224

Epoch: 5| Step: 7
Training loss: 0.6840711832046509
Validation loss: 1.8355107358706895

Epoch: 5| Step: 8
Training loss: 0.8342054486274719
Validation loss: 1.8167708560984621

Epoch: 5| Step: 9
Training loss: 1.3249715566635132
Validation loss: 1.8490984298849618

Epoch: 5| Step: 10
Training loss: 1.091435194015503
Validation loss: 1.7945144894302532

Epoch: 496| Step: 0
Training loss: 1.0648925304412842
Validation loss: 1.8095422290986585

Epoch: 5| Step: 1
Training loss: 0.981277585029602
Validation loss: 1.8439941560068438

Epoch: 5| Step: 2
Training loss: 0.5912953019142151
Validation loss: 1.8356200174618793

Epoch: 5| Step: 3
Training loss: 1.377755880355835
Validation loss: 1.830192377490382

Epoch: 5| Step: 4
Training loss: 0.8390185236930847
Validation loss: 1.837454552291542

Epoch: 5| Step: 5
Training loss: 1.0549895763397217
Validation loss: 1.8524440091143373

Epoch: 5| Step: 6
Training loss: 0.9606963992118835
Validation loss: 1.8739502263325516

Epoch: 5| Step: 7
Training loss: 0.6676313281059265
Validation loss: 1.858268880075024

Epoch: 5| Step: 8
Training loss: 0.7619912624359131
Validation loss: 1.8301287338297854

Epoch: 5| Step: 9
Training loss: 1.3809881210327148
Validation loss: 1.8525323034614645

Epoch: 5| Step: 10
Training loss: 0.7398157715797424
Validation loss: 1.8157653065137966

Epoch: 497| Step: 0
Training loss: 1.1452559232711792
Validation loss: 1.856999030677221

Epoch: 5| Step: 1
Training loss: 0.8652838468551636
Validation loss: 1.8792829026458084

Epoch: 5| Step: 2
Training loss: 0.6840686202049255
Validation loss: 1.8337759330708494

Epoch: 5| Step: 3
Training loss: 0.8252968788146973
Validation loss: 1.846647847083307

Epoch: 5| Step: 4
Training loss: 1.1279081106185913
Validation loss: 1.7807791130517119

Epoch: 5| Step: 5
Training loss: 1.0485624074935913
Validation loss: 1.8456945073220037

Epoch: 5| Step: 6
Training loss: 0.9938207864761353
Validation loss: 1.7836003470164474

Epoch: 5| Step: 7
Training loss: 0.7076631784439087
Validation loss: 1.8519832370101765

Epoch: 5| Step: 8
Training loss: 0.9662569761276245
Validation loss: 1.8540824587627123

Epoch: 5| Step: 9
Training loss: 1.0666652917861938
Validation loss: 1.8370404833106584

Epoch: 5| Step: 10
Training loss: 0.8848495483398438
Validation loss: 1.8493478170005224

Epoch: 498| Step: 0
Training loss: 0.8740676045417786
Validation loss: 1.8524416621013353

Epoch: 5| Step: 1
Training loss: 1.0890862941741943
Validation loss: 1.8062802360903831

Epoch: 5| Step: 2
Training loss: 0.8563022613525391
Validation loss: 1.8277019787860174

Epoch: 5| Step: 3
Training loss: 1.1050242185592651
Validation loss: 1.8298138610778316

Epoch: 5| Step: 4
Training loss: 1.1449178457260132
Validation loss: 1.8485982789788196

Epoch: 5| Step: 5
Training loss: 0.945198655128479
Validation loss: 1.7890952184636106

Epoch: 5| Step: 6
Training loss: 0.8162958025932312
Validation loss: 1.8238379980928154

Epoch: 5| Step: 7
Training loss: 0.6133596301078796
Validation loss: 1.8176419658045615

Epoch: 5| Step: 8
Training loss: 0.6753131151199341
Validation loss: 1.788040643097252

Epoch: 5| Step: 9
Training loss: 1.3152843713760376
Validation loss: 1.8266522704914052

Epoch: 5| Step: 10
Training loss: 0.7674680352210999
Validation loss: 1.8836268109659995

Epoch: 499| Step: 0
Training loss: 1.406570553779602
Validation loss: 1.8441645201816355

Epoch: 5| Step: 1
Training loss: 1.1648014783859253
Validation loss: 1.841806629652618

Epoch: 5| Step: 2
Training loss: 0.6776217222213745
Validation loss: 1.8211017834242953

Epoch: 5| Step: 3
Training loss: 0.6840659379959106
Validation loss: 1.8602816289471042

Epoch: 5| Step: 4
Training loss: 1.1369878053665161
Validation loss: 1.8473077025464786

Epoch: 5| Step: 5
Training loss: 0.6889077425003052
Validation loss: 1.817076336952948

Epoch: 5| Step: 6
Training loss: 0.738075315952301
Validation loss: 1.8656954124409666

Epoch: 5| Step: 7
Training loss: 0.7501627802848816
Validation loss: 1.8389573481775099

Epoch: 5| Step: 8
Training loss: 0.7123362421989441
Validation loss: 1.8319191035404

Epoch: 5| Step: 9
Training loss: 0.967693030834198
Validation loss: 1.8160583229475125

Epoch: 5| Step: 10
Training loss: 1.2221393585205078
Validation loss: 1.7927341640636485

Epoch: 500| Step: 0
Training loss: 0.6065281629562378
Validation loss: 1.8429964242442962

Epoch: 5| Step: 1
Training loss: 1.0770280361175537
Validation loss: 1.8251378664406397

Epoch: 5| Step: 2
Training loss: 1.6984357833862305
Validation loss: 1.8012822238347863

Epoch: 5| Step: 3
Training loss: 0.8413346409797668
Validation loss: 1.8127942726176272

Epoch: 5| Step: 4
Training loss: 0.5664380192756653
Validation loss: 1.8689640081056984

Epoch: 5| Step: 5
Training loss: 1.0572689771652222
Validation loss: 1.7964667133105698

Epoch: 5| Step: 6
Training loss: 0.6840636730194092
Validation loss: 1.8301861696345831

Epoch: 5| Step: 7
Training loss: 0.87593013048172
Validation loss: 1.8099597038761261

Epoch: 5| Step: 8
Training loss: 0.9496035575866699
Validation loss: 1.848831856122581

Epoch: 5| Step: 9
Training loss: 0.7659913301467896
Validation loss: 1.8573942748449181

Epoch: 5| Step: 10
Training loss: 1.090061902999878
Validation loss: 1.810767532676779

Epoch: 501| Step: 0
Training loss: 0.9338483810424805
Validation loss: 1.8631128470102947

Epoch: 5| Step: 1
Training loss: 1.367107629776001
Validation loss: 1.861503920247478

Epoch: 5| Step: 2
Training loss: 1.099381446838379
Validation loss: 1.8657424603739092

Epoch: 5| Step: 3
Training loss: 0.9321117401123047
Validation loss: 1.8210903918871315

Epoch: 5| Step: 4
Training loss: 1.122971773147583
Validation loss: 1.8335356173976776

Epoch: 5| Step: 5
Training loss: 0.621874213218689
Validation loss: 1.8332715406212756

Epoch: 5| Step: 6
Training loss: 0.763437032699585
Validation loss: 1.8608762166833366

Epoch: 5| Step: 7
Training loss: 0.5740255117416382
Validation loss: 1.7940193863325222

Epoch: 5| Step: 8
Training loss: 0.8199637532234192
Validation loss: 1.8165362419620636

Epoch: 5| Step: 9
Training loss: 1.2636396884918213
Validation loss: 1.776951087418423

Epoch: 5| Step: 10
Training loss: 0.6396737694740295
Validation loss: 1.8277726147764473

Epoch: 502| Step: 0
Training loss: 0.967889666557312
Validation loss: 1.803886426392422

Epoch: 5| Step: 1
Training loss: 0.45825424790382385
Validation loss: 1.8733588213561683

Epoch: 5| Step: 2
Training loss: 1.1329180002212524
Validation loss: 1.8357110792590725

Epoch: 5| Step: 3
Training loss: 1.120562195777893
Validation loss: 1.83362465904605

Epoch: 5| Step: 4
Training loss: 0.5749120712280273
Validation loss: 1.8068857949267152

Epoch: 5| Step: 5
Training loss: 1.1727526187896729
Validation loss: 1.8216590304528513

Epoch: 5| Step: 6
Training loss: 1.378415822982788
Validation loss: 1.7898096230722242

Epoch: 5| Step: 7
Training loss: 1.0795845985412598
Validation loss: 1.8541361516521824

Epoch: 5| Step: 8
Training loss: 0.8345944285392761
Validation loss: 1.8445292993258404

Epoch: 5| Step: 9
Training loss: 0.76177978515625
Validation loss: 1.8362905607428601

Epoch: 5| Step: 10
Training loss: 0.4976273775100708
Validation loss: 1.8864996240985008

Epoch: 503| Step: 0
Training loss: 0.9711389541625977
Validation loss: 1.872052292669973

Epoch: 5| Step: 1
Training loss: 0.7578562498092651
Validation loss: 1.8835865374534362

Epoch: 5| Step: 2
Training loss: 0.8702890276908875
Validation loss: 1.848446003852352

Epoch: 5| Step: 3
Training loss: 0.9182182550430298
Validation loss: 1.85704541719088

Epoch: 5| Step: 4
Training loss: 0.6965645551681519
Validation loss: 1.8237575433587516

Epoch: 5| Step: 5
Training loss: 1.0311224460601807
Validation loss: 1.8156272480564732

Epoch: 5| Step: 6
Training loss: 1.240566611289978
Validation loss: 1.8565205284344253

Epoch: 5| Step: 7
Training loss: 1.1332662105560303
Validation loss: 1.8679709934419202

Epoch: 5| Step: 8
Training loss: 0.8343130946159363
Validation loss: 1.802640930298836

Epoch: 5| Step: 9
Training loss: 1.1687750816345215
Validation loss: 1.8017764117128106

Epoch: 5| Step: 10
Training loss: 0.9587869048118591
Validation loss: 1.8277793904786468

Epoch: 504| Step: 0
Training loss: 0.8384355306625366
Validation loss: 1.8311099108829294

Epoch: 5| Step: 1
Training loss: 0.8773820996284485
Validation loss: 1.8130492343697497

Epoch: 5| Step: 2
Training loss: 0.9816814661026001
Validation loss: 1.8931497784071072

Epoch: 5| Step: 3
Training loss: 0.7166478633880615
Validation loss: 1.8598377602074736

Epoch: 5| Step: 4
Training loss: 0.725185215473175
Validation loss: 1.8836811665565736

Epoch: 5| Step: 5
Training loss: 1.300554871559143
Validation loss: 1.803695600519898

Epoch: 5| Step: 6
Training loss: 0.8057037591934204
Validation loss: 1.7682888905207317

Epoch: 5| Step: 7
Training loss: 1.540505051612854
Validation loss: 1.8389413126053349

Epoch: 5| Step: 8
Training loss: 1.0002834796905518
Validation loss: 1.8350646841910578

Epoch: 5| Step: 9
Training loss: 0.5848200917243958
Validation loss: 1.8080691688804216

Epoch: 5| Step: 10
Training loss: 0.6976159811019897
Validation loss: 1.8206434390878166

Epoch: 505| Step: 0
Training loss: 0.6000572443008423
Validation loss: 1.742956123044414

Epoch: 5| Step: 1
Training loss: 0.7706890106201172
Validation loss: 1.7834000177280878

Epoch: 5| Step: 2
Training loss: 0.7276186347007751
Validation loss: 1.8011847337086995

Epoch: 5| Step: 3
Training loss: 0.9516552090644836
Validation loss: 1.8238964555084065

Epoch: 5| Step: 4
Training loss: 1.4376029968261719
Validation loss: 1.8378425926290534

Epoch: 5| Step: 5
Training loss: 0.7752649188041687
Validation loss: 1.8309563193269955

Epoch: 5| Step: 6
Training loss: 0.5520530939102173
Validation loss: 1.8046724924477198

Epoch: 5| Step: 7
Training loss: 0.9843387603759766
Validation loss: 1.7841161489486694

Epoch: 5| Step: 8
Training loss: 1.4010117053985596
Validation loss: 1.8673657012242142

Epoch: 5| Step: 9
Training loss: 1.081078290939331
Validation loss: 1.847943131641675

Epoch: 5| Step: 10
Training loss: 1.2013417482376099
Validation loss: 1.8232299102249967

Epoch: 506| Step: 0
Training loss: 0.9500325918197632
Validation loss: 1.8445266574941657

Epoch: 5| Step: 1
Training loss: 1.3666856288909912
Validation loss: 1.8466614369423158

Epoch: 5| Step: 2
Training loss: 1.08200204372406
Validation loss: 1.858548661713959

Epoch: 5| Step: 3
Training loss: 1.0471649169921875
Validation loss: 1.8300817089696084

Epoch: 5| Step: 4
Training loss: 0.7950822114944458
Validation loss: 1.813511690785808

Epoch: 5| Step: 5
Training loss: 0.7493018507957458
Validation loss: 1.81035017454496

Epoch: 5| Step: 6
Training loss: 0.865726113319397
Validation loss: 1.8454055581041562

Epoch: 5| Step: 7
Training loss: 0.5235908627510071
Validation loss: 1.8371008814022105

Epoch: 5| Step: 8
Training loss: 1.215241551399231
Validation loss: 1.8298963885153494

Epoch: 5| Step: 9
Training loss: 0.7981196045875549
Validation loss: 1.8153777481407247

Epoch: 5| Step: 10
Training loss: 0.5667715668678284
Validation loss: 1.826000275150422

Epoch: 507| Step: 0
Training loss: 0.8750535249710083
Validation loss: 1.811923555148545

Epoch: 5| Step: 1
Training loss: 1.0985654592514038
Validation loss: 1.8016024328047229

Epoch: 5| Step: 2
Training loss: 0.7988666296005249
Validation loss: 1.8225306105870072

Epoch: 5| Step: 3
Training loss: 0.6970049142837524
Validation loss: 1.8069166393690212

Epoch: 5| Step: 4
Training loss: 0.8890438079833984
Validation loss: 1.8153564160869968

Epoch: 5| Step: 5
Training loss: 0.9208641052246094
Validation loss: 1.79494656285932

Epoch: 5| Step: 6
Training loss: 1.2251803874969482
Validation loss: 1.81824029004702

Epoch: 5| Step: 7
Training loss: 0.9264960289001465
Validation loss: 1.7962436509388748

Epoch: 5| Step: 8
Training loss: 0.7604387998580933
Validation loss: 1.837174977025678

Epoch: 5| Step: 9
Training loss: 1.0607576370239258
Validation loss: 1.8170411638034287

Epoch: 5| Step: 10
Training loss: 0.8348883390426636
Validation loss: 1.8663168978947464

Epoch: 508| Step: 0
Training loss: 1.2240186929702759
Validation loss: 1.8253779436952324

Epoch: 5| Step: 1
Training loss: 1.3191592693328857
Validation loss: 1.8412064185706518

Epoch: 5| Step: 2
Training loss: 0.6858065724372864
Validation loss: 1.8342372268758795

Epoch: 5| Step: 3
Training loss: 1.014249324798584
Validation loss: 1.8304804794249996

Epoch: 5| Step: 4
Training loss: 0.8237112760543823
Validation loss: 1.8685461218639086

Epoch: 5| Step: 5
Training loss: 1.267953872680664
Validation loss: 1.8302367989734938

Epoch: 5| Step: 6
Training loss: 1.253937005996704
Validation loss: 1.8290318366019958

Epoch: 5| Step: 7
Training loss: 0.6691941022872925
Validation loss: 1.7833712152255479

Epoch: 5| Step: 8
Training loss: 0.8278223872184753
Validation loss: 1.8357233783250213

Epoch: 5| Step: 9
Training loss: 0.41420048475265503
Validation loss: 1.840351794355659

Epoch: 5| Step: 10
Training loss: 0.6447851061820984
Validation loss: 1.7962584367362402

Epoch: 509| Step: 0
Training loss: 1.054659366607666
Validation loss: 1.8875603829660723

Epoch: 5| Step: 1
Training loss: 0.46611255407333374
Validation loss: 1.826550381157988

Epoch: 5| Step: 2
Training loss: 0.8676241636276245
Validation loss: 1.8262792479607366

Epoch: 5| Step: 3
Training loss: 0.918454647064209
Validation loss: 1.814895228673053

Epoch: 5| Step: 4
Training loss: 0.6169369220733643
Validation loss: 1.8275198423734276

Epoch: 5| Step: 5
Training loss: 1.0565097332000732
Validation loss: 1.8244858916087816

Epoch: 5| Step: 6
Training loss: 1.0210356712341309
Validation loss: 1.8617359079340452

Epoch: 5| Step: 7
Training loss: 1.3371680974960327
Validation loss: 1.8273253312674902

Epoch: 5| Step: 8
Training loss: 0.793890118598938
Validation loss: 1.8025196316421672

Epoch: 5| Step: 9
Training loss: 0.9705308675765991
Validation loss: 1.8552413307210451

Epoch: 5| Step: 10
Training loss: 0.9560487270355225
Validation loss: 1.9173659586137342

Epoch: 510| Step: 0
Training loss: 1.0913423299789429
Validation loss: 1.8509976556224208

Epoch: 5| Step: 1
Training loss: 0.6484917402267456
Validation loss: 1.8792787700571039

Epoch: 5| Step: 2
Training loss: 1.253579020500183
Validation loss: 1.906053881491384

Epoch: 5| Step: 3
Training loss: 1.1082605123519897
Validation loss: 1.88224503045441

Epoch: 5| Step: 4
Training loss: 1.0219426155090332
Validation loss: 1.8316601604543707

Epoch: 5| Step: 5
Training loss: 1.2496984004974365
Validation loss: 1.7930894051828692

Epoch: 5| Step: 6
Training loss: 0.73285311460495
Validation loss: 1.8073433035163469

Epoch: 5| Step: 7
Training loss: 0.9207512140274048
Validation loss: 1.8109647061235161

Epoch: 5| Step: 8
Training loss: 0.562506377696991
Validation loss: 1.8649588643863637

Epoch: 5| Step: 9
Training loss: 1.088893175125122
Validation loss: 1.8595645863522765

Epoch: 5| Step: 10
Training loss: 0.929847002029419
Validation loss: 1.780902672839421

Epoch: 511| Step: 0
Training loss: 0.868975818157196
Validation loss: 1.8539646158936203

Epoch: 5| Step: 1
Training loss: 0.5555704236030579
Validation loss: 1.8055065678011986

Epoch: 5| Step: 2
Training loss: 1.1920804977416992
Validation loss: 1.805443852178512

Epoch: 5| Step: 3
Training loss: 0.8379273414611816
Validation loss: 1.868992461953112

Epoch: 5| Step: 4
Training loss: 0.7257193922996521
Validation loss: 1.8734613208360569

Epoch: 5| Step: 5
Training loss: 0.8944233059883118
Validation loss: 1.8348809416576097

Epoch: 5| Step: 6
Training loss: 0.6958962678909302
Validation loss: 1.8093062139326526

Epoch: 5| Step: 7
Training loss: 0.71623295545578
Validation loss: 1.8754291278059765

Epoch: 5| Step: 8
Training loss: 1.1532955169677734
Validation loss: 1.8498873633723105

Epoch: 5| Step: 9
Training loss: 1.212258219718933
Validation loss: 1.805317037849016

Epoch: 5| Step: 10
Training loss: 1.1305160522460938
Validation loss: 1.7676418699244016

Epoch: 512| Step: 0
Training loss: 1.119903326034546
Validation loss: 1.8127292099819388

Epoch: 5| Step: 1
Training loss: 0.7713270783424377
Validation loss: 1.8141421912818827

Epoch: 5| Step: 2
Training loss: 1.1856015920639038
Validation loss: 1.8434496054085352

Epoch: 5| Step: 3
Training loss: 0.8947160840034485
Validation loss: 1.865025084505799

Epoch: 5| Step: 4
Training loss: 0.5809754133224487
Validation loss: 1.7895810616913663

Epoch: 5| Step: 5
Training loss: 0.7372685670852661
Validation loss: 1.814629690621489

Epoch: 5| Step: 6
Training loss: 0.9265416860580444
Validation loss: 1.7796361369471396

Epoch: 5| Step: 7
Training loss: 1.3194749355316162
Validation loss: 1.7600838856030536

Epoch: 5| Step: 8
Training loss: 0.7520556449890137
Validation loss: 1.772584198623575

Epoch: 5| Step: 9
Training loss: 1.0376514196395874
Validation loss: 1.8264270174887873

Epoch: 5| Step: 10
Training loss: 0.8427985906600952
Validation loss: 1.8185104041971185

Epoch: 513| Step: 0
Training loss: 0.9360983967781067
Validation loss: 1.8272129720257175

Epoch: 5| Step: 1
Training loss: 1.2354586124420166
Validation loss: 1.8596543099290581

Epoch: 5| Step: 2
Training loss: 0.622308075428009
Validation loss: 1.7753496093134726

Epoch: 5| Step: 3
Training loss: 0.8949213027954102
Validation loss: 1.8318763727782874

Epoch: 5| Step: 4
Training loss: 0.6627862453460693
Validation loss: 1.8518961578287103

Epoch: 5| Step: 5
Training loss: 1.0717146396636963
Validation loss: 1.8780601101536905

Epoch: 5| Step: 6
Training loss: 1.028195858001709
Validation loss: 1.8221133703826575

Epoch: 5| Step: 7
Training loss: 0.7978549003601074
Validation loss: 1.8091964106405936

Epoch: 5| Step: 8
Training loss: 0.8255965113639832
Validation loss: 1.817164090371901

Epoch: 5| Step: 9
Training loss: 1.1091740131378174
Validation loss: 1.8376059416801698

Epoch: 5| Step: 10
Training loss: 0.9055224061012268
Validation loss: 1.7978237546900266

Epoch: 514| Step: 0
Training loss: 0.9483529925346375
Validation loss: 1.8308897518342542

Epoch: 5| Step: 1
Training loss: 0.8128037452697754
Validation loss: 1.8284760085485314

Epoch: 5| Step: 2
Training loss: 1.270359754562378
Validation loss: 1.8414053814385527

Epoch: 5| Step: 3
Training loss: 1.1585729122161865
Validation loss: 1.8529108519195228

Epoch: 5| Step: 4
Training loss: 0.8265457153320312
Validation loss: 1.8339560967619701

Epoch: 5| Step: 5
Training loss: 0.678544819355011
Validation loss: 1.8230561030808317

Epoch: 5| Step: 6
Training loss: 0.6238325238227844
Validation loss: 1.8348710780502648

Epoch: 5| Step: 7
Training loss: 1.2159901857376099
Validation loss: 1.8164506804558538

Epoch: 5| Step: 8
Training loss: 1.0917249917984009
Validation loss: 1.863289051158454

Epoch: 5| Step: 9
Training loss: 0.7420779466629028
Validation loss: 1.8219141037233415

Epoch: 5| Step: 10
Training loss: 0.7667489051818848
Validation loss: 1.809657630100045

Epoch: 515| Step: 0
Training loss: 1.1733695268630981
Validation loss: 1.8310543414085143

Epoch: 5| Step: 1
Training loss: 0.6059967875480652
Validation loss: 1.8045318818861438

Epoch: 5| Step: 2
Training loss: 1.125765085220337
Validation loss: 1.8479164761881675

Epoch: 5| Step: 3
Training loss: 0.965835690498352
Validation loss: 1.8870830253888202

Epoch: 5| Step: 4
Training loss: 0.7259750962257385
Validation loss: 1.827957086665656

Epoch: 5| Step: 5
Training loss: 0.5907449126243591
Validation loss: 1.8275787240715438

Epoch: 5| Step: 6
Training loss: 0.6155311465263367
Validation loss: 1.8223847945531209

Epoch: 5| Step: 7
Training loss: 1.1169049739837646
Validation loss: 1.8263259241657872

Epoch: 5| Step: 8
Training loss: 1.105101227760315
Validation loss: 1.7790196339289348

Epoch: 5| Step: 9
Training loss: 0.9602397084236145
Validation loss: 1.7804802694628317

Epoch: 5| Step: 10
Training loss: 0.9160078763961792
Validation loss: 1.8172603922505532

Epoch: 516| Step: 0
Training loss: 0.8169448971748352
Validation loss: 1.8161944599561795

Epoch: 5| Step: 1
Training loss: 1.1229267120361328
Validation loss: 1.8164857510597474

Epoch: 5| Step: 2
Training loss: 0.6583961844444275
Validation loss: 1.8527561964527253

Epoch: 5| Step: 3
Training loss: 0.9861303567886353
Validation loss: 1.8280523579607728

Epoch: 5| Step: 4
Training loss: 1.05270254611969
Validation loss: 1.8876533918483283

Epoch: 5| Step: 5
Training loss: 1.0377800464630127
Validation loss: 1.820703173196444

Epoch: 5| Step: 6
Training loss: 1.1467605829238892
Validation loss: 1.83984939770032

Epoch: 5| Step: 7
Training loss: 0.631722092628479
Validation loss: 1.886362575715588

Epoch: 5| Step: 8
Training loss: 1.1367675065994263
Validation loss: 1.9022718052710257

Epoch: 5| Step: 9
Training loss: 0.7554706335067749
Validation loss: 1.8510395724286315

Epoch: 5| Step: 10
Training loss: 0.9847369194030762
Validation loss: 1.825394356122581

Epoch: 517| Step: 0
Training loss: 1.4291523694992065
Validation loss: 1.851550994380828

Epoch: 5| Step: 1
Training loss: 0.9288126230239868
Validation loss: 1.8993474988527195

Epoch: 5| Step: 2
Training loss: 0.6681477427482605
Validation loss: 1.8592904408772786

Epoch: 5| Step: 3
Training loss: 0.6547712087631226
Validation loss: 1.8401103186350998

Epoch: 5| Step: 4
Training loss: 0.8980622291564941
Validation loss: 1.808576556944078

Epoch: 5| Step: 5
Training loss: 1.0600626468658447
Validation loss: 1.8685599706506217

Epoch: 5| Step: 6
Training loss: 0.8056632280349731
Validation loss: 1.8253112582750217

Epoch: 5| Step: 7
Training loss: 1.0152919292449951
Validation loss: 1.8087106148401897

Epoch: 5| Step: 8
Training loss: 0.7556526064872742
Validation loss: 1.778853661270552

Epoch: 5| Step: 9
Training loss: 0.6081682443618774
Validation loss: 1.7999324362765077

Epoch: 5| Step: 10
Training loss: 1.0764963626861572
Validation loss: 1.8442747951835714

Epoch: 518| Step: 0
Training loss: 0.513860285282135
Validation loss: 1.8432696532177668

Epoch: 5| Step: 1
Training loss: 0.8633222579956055
Validation loss: 1.8142930679423834

Epoch: 5| Step: 2
Training loss: 1.3823988437652588
Validation loss: 1.8044971189191263

Epoch: 5| Step: 3
Training loss: 0.8694822192192078
Validation loss: 1.825135705291584

Epoch: 5| Step: 4
Training loss: 0.7190420031547546
Validation loss: 1.816402389157203

Epoch: 5| Step: 5
Training loss: 1.0725008249282837
Validation loss: 1.8311547656213083

Epoch: 5| Step: 6
Training loss: 1.1617271900177002
Validation loss: 1.8930490888575071

Epoch: 5| Step: 7
Training loss: 0.6646894812583923
Validation loss: 1.817903289230921

Epoch: 5| Step: 8
Training loss: 0.9904438257217407
Validation loss: 1.8478835193059777

Epoch: 5| Step: 9
Training loss: 0.5194284319877625
Validation loss: 1.8391050113144742

Epoch: 5| Step: 10
Training loss: 0.7871805429458618
Validation loss: 1.8337588066695838

Epoch: 519| Step: 0
Training loss: 0.8413898348808289
Validation loss: 1.8329283037493307

Epoch: 5| Step: 1
Training loss: 0.8486191630363464
Validation loss: 1.8607665390096686

Epoch: 5| Step: 2
Training loss: 1.0592501163482666
Validation loss: 1.8363953867266256

Epoch: 5| Step: 3
Training loss: 0.9469738006591797
Validation loss: 1.7966155493131248

Epoch: 5| Step: 4
Training loss: 0.9035376310348511
Validation loss: 1.7947948645519953

Epoch: 5| Step: 5
Training loss: 0.9336153864860535
Validation loss: 1.8276187578837078

Epoch: 5| Step: 6
Training loss: 1.1269433498382568
Validation loss: 1.8119305564511208

Epoch: 5| Step: 7
Training loss: 0.9840365648269653
Validation loss: 1.8337192022672264

Epoch: 5| Step: 8
Training loss: 0.9879933595657349
Validation loss: 1.8778940311042212

Epoch: 5| Step: 9
Training loss: 0.7090411186218262
Validation loss: 1.8336463384730841

Epoch: 5| Step: 10
Training loss: 0.6418353915214539
Validation loss: 1.8370579237579017

Epoch: 520| Step: 0
Training loss: 1.170130968093872
Validation loss: 1.8529729817503242

Epoch: 5| Step: 1
Training loss: 0.930284321308136
Validation loss: 1.8404043797523744

Epoch: 5| Step: 2
Training loss: 0.8507316708564758
Validation loss: 1.7974775260494602

Epoch: 5| Step: 3
Training loss: 1.1802146434783936
Validation loss: 1.8025817858275546

Epoch: 5| Step: 4
Training loss: 0.5800174474716187
Validation loss: 1.8105741264999553

Epoch: 5| Step: 5
Training loss: 0.8535828590393066
Validation loss: 1.8223108745390368

Epoch: 5| Step: 6
Training loss: 0.7732149958610535
Validation loss: 1.7978795600193802

Epoch: 5| Step: 7
Training loss: 0.5554553270339966
Validation loss: 1.8037140215596845

Epoch: 5| Step: 8
Training loss: 0.6970232129096985
Validation loss: 1.8153061379668534

Epoch: 5| Step: 9
Training loss: 1.0079258680343628
Validation loss: 1.8117238026793285

Epoch: 5| Step: 10
Training loss: 0.8801695704460144
Validation loss: 1.8057073098357006

Epoch: 521| Step: 0
Training loss: 0.7267042398452759
Validation loss: 1.8624599274768625

Epoch: 5| Step: 1
Training loss: 0.9565965533256531
Validation loss: 1.7883095446453299

Epoch: 5| Step: 2
Training loss: 0.8000102043151855
Validation loss: 1.8194088500033143

Epoch: 5| Step: 3
Training loss: 0.9211592674255371
Validation loss: 1.7693329267604376

Epoch: 5| Step: 4
Training loss: 0.9072103500366211
Validation loss: 1.8219120169198642

Epoch: 5| Step: 5
Training loss: 0.6071300506591797
Validation loss: 1.835827418552932

Epoch: 5| Step: 6
Training loss: 1.070265531539917
Validation loss: 1.8508699837551321

Epoch: 5| Step: 7
Training loss: 0.8509780168533325
Validation loss: 1.8443300339483446

Epoch: 5| Step: 8
Training loss: 0.8838264346122742
Validation loss: 1.8676969171852194

Epoch: 5| Step: 9
Training loss: 1.0338408946990967
Validation loss: 1.8659221177460046

Epoch: 5| Step: 10
Training loss: 1.0976016521453857
Validation loss: 1.8233329890876688

Epoch: 522| Step: 0
Training loss: 0.4780309200286865
Validation loss: 1.8222622999580957

Epoch: 5| Step: 1
Training loss: 0.7564243674278259
Validation loss: 1.8244225466123192

Epoch: 5| Step: 2
Training loss: 1.0438401699066162
Validation loss: 1.8405374468013804

Epoch: 5| Step: 3
Training loss: 0.9782827496528625
Validation loss: 1.8608041873542212

Epoch: 5| Step: 4
Training loss: 0.7489310503005981
Validation loss: 1.8629335049659974

Epoch: 5| Step: 5
Training loss: 1.0743134021759033
Validation loss: 1.8346117850272887

Epoch: 5| Step: 6
Training loss: 1.0749900341033936
Validation loss: 1.8497425843310613

Epoch: 5| Step: 7
Training loss: 1.1299569606781006
Validation loss: 1.8189053099642518

Epoch: 5| Step: 8
Training loss: 0.821314811706543
Validation loss: 1.821407844943385

Epoch: 5| Step: 9
Training loss: 0.6234301328659058
Validation loss: 1.8052578036503126

Epoch: 5| Step: 10
Training loss: 1.1353925466537476
Validation loss: 1.818204040168434

Epoch: 523| Step: 0
Training loss: 1.3210786581039429
Validation loss: 1.817543755295456

Epoch: 5| Step: 1
Training loss: 1.006056785583496
Validation loss: 1.7948631573748846

Epoch: 5| Step: 2
Training loss: 0.7712674140930176
Validation loss: 1.8632582925981092

Epoch: 5| Step: 3
Training loss: 0.8059927225112915
Validation loss: 1.8605323683830999

Epoch: 5| Step: 4
Training loss: 0.759714663028717
Validation loss: 1.888799641721992

Epoch: 5| Step: 5
Training loss: 0.6643590331077576
Validation loss: 1.84710177042151

Epoch: 5| Step: 6
Training loss: 0.7031735181808472
Validation loss: 1.8199657727313299

Epoch: 5| Step: 7
Training loss: 0.750409722328186
Validation loss: 1.847373858574898

Epoch: 5| Step: 8
Training loss: 1.1374117136001587
Validation loss: 1.8082726834922709

Epoch: 5| Step: 9
Training loss: 0.9387154579162598
Validation loss: 1.798785460892544

Epoch: 5| Step: 10
Training loss: 0.5751965641975403
Validation loss: 1.79509094197263

Epoch: 524| Step: 0
Training loss: 1.2843406200408936
Validation loss: 1.8590240350333593

Epoch: 5| Step: 1
Training loss: 0.8714874982833862
Validation loss: 1.8158489978441628

Epoch: 5| Step: 2
Training loss: 0.7489601373672485
Validation loss: 1.8391734259102934

Epoch: 5| Step: 3
Training loss: 0.5565319657325745
Validation loss: 1.8562151193618774

Epoch: 5| Step: 4
Training loss: 0.8729451894760132
Validation loss: 1.89134168881242

Epoch: 5| Step: 5
Training loss: 0.9738293886184692
Validation loss: 1.7984187423541982

Epoch: 5| Step: 6
Training loss: 0.9747050404548645
Validation loss: 1.798263244731452

Epoch: 5| Step: 7
Training loss: 0.9813591241836548
Validation loss: 1.8549964184402137

Epoch: 5| Step: 8
Training loss: 0.9137843251228333
Validation loss: 1.8213094998431463

Epoch: 5| Step: 9
Training loss: 0.764568567276001
Validation loss: 1.8374948937405822

Epoch: 5| Step: 10
Training loss: 0.7959062457084656
Validation loss: 1.870476948317661

Epoch: 525| Step: 0
Training loss: 0.9126980900764465
Validation loss: 1.840520405000256

Epoch: 5| Step: 1
Training loss: 0.9588974714279175
Validation loss: 1.8524701390215146

Epoch: 5| Step: 2
Training loss: 0.7802870869636536
Validation loss: 1.8328361447139452

Epoch: 5| Step: 3
Training loss: 1.0999921560287476
Validation loss: 1.8039115218706028

Epoch: 5| Step: 4
Training loss: 1.0966522693634033
Validation loss: 1.8469094076464254

Epoch: 5| Step: 5
Training loss: 0.5326135754585266
Validation loss: 1.7671696293738581

Epoch: 5| Step: 6
Training loss: 1.0065410137176514
Validation loss: 1.8561196788664787

Epoch: 5| Step: 7
Training loss: 0.8773397207260132
Validation loss: 1.8294496228618007

Epoch: 5| Step: 8
Training loss: 1.0873134136199951
Validation loss: 1.771268001166723

Epoch: 5| Step: 9
Training loss: 0.6451014280319214
Validation loss: 1.817844408814625

Epoch: 5| Step: 10
Training loss: 0.7591894268989563
Validation loss: 1.905778472141553

Epoch: 526| Step: 0
Training loss: 1.1452528238296509
Validation loss: 1.8231365655058174

Epoch: 5| Step: 1
Training loss: 0.46618205308914185
Validation loss: 1.8164452455377067

Epoch: 5| Step: 2
Training loss: 0.5177185535430908
Validation loss: 1.7917912544742707

Epoch: 5| Step: 3
Training loss: 0.43803104758262634
Validation loss: 1.820744591374551

Epoch: 5| Step: 4
Training loss: 1.3392010927200317
Validation loss: 1.873595137749949

Epoch: 5| Step: 5
Training loss: 1.239924669265747
Validation loss: 1.8427337408065796

Epoch: 5| Step: 6
Training loss: 1.0584427118301392
Validation loss: 1.8946730539362917

Epoch: 5| Step: 7
Training loss: 0.6972535848617554
Validation loss: 1.8575570814071163

Epoch: 5| Step: 8
Training loss: 0.6671488285064697
Validation loss: 1.8422606811728528

Epoch: 5| Step: 9
Training loss: 0.8129270672798157
Validation loss: 1.8726936412113968

Epoch: 5| Step: 10
Training loss: 1.1750357151031494
Validation loss: 1.8246335252638786

Epoch: 527| Step: 0
Training loss: 0.9940786361694336
Validation loss: 1.8144869483927244

Epoch: 5| Step: 1
Training loss: 0.7365571856498718
Validation loss: 1.8509659664605254

Epoch: 5| Step: 2
Training loss: 0.8406742215156555
Validation loss: 1.8540614625459075

Epoch: 5| Step: 3
Training loss: 0.8791986703872681
Validation loss: 1.8669729540424962

Epoch: 5| Step: 4
Training loss: 1.639208197593689
Validation loss: 1.8423818670293337

Epoch: 5| Step: 5
Training loss: 0.7930983304977417
Validation loss: 1.8145085150195706

Epoch: 5| Step: 6
Training loss: 0.7446651458740234
Validation loss: 1.8696786844602196

Epoch: 5| Step: 7
Training loss: 1.1167638301849365
Validation loss: 1.846600664559231

Epoch: 5| Step: 8
Training loss: 0.6522220969200134
Validation loss: 1.8733277718226116

Epoch: 5| Step: 9
Training loss: 0.7247567176818848
Validation loss: 1.7609471121141989

Epoch: 5| Step: 10
Training loss: 0.7455299496650696
Validation loss: 1.8479519146744923

Epoch: 528| Step: 0
Training loss: 0.9722703099250793
Validation loss: 1.8204577225510792

Epoch: 5| Step: 1
Training loss: 1.0493934154510498
Validation loss: 1.8614960549980082

Epoch: 5| Step: 2
Training loss: 0.9445164799690247
Validation loss: 1.821218857201197

Epoch: 5| Step: 3
Training loss: 0.6397610902786255
Validation loss: 1.763440224432176

Epoch: 5| Step: 4
Training loss: 0.946611762046814
Validation loss: 1.778915810328658

Epoch: 5| Step: 5
Training loss: 0.8188344836235046
Validation loss: 1.8197919630235242

Epoch: 5| Step: 6
Training loss: 1.1770445108413696
Validation loss: 1.8082884421912573

Epoch: 5| Step: 7
Training loss: 1.1240447759628296
Validation loss: 1.8015988437078332

Epoch: 5| Step: 8
Training loss: 0.42661887407302856
Validation loss: 1.8498550589366625

Epoch: 5| Step: 9
Training loss: 0.8425494432449341
Validation loss: 1.8402521943533292

Epoch: 5| Step: 10
Training loss: 0.8048718571662903
Validation loss: 1.8521504889252365

Epoch: 529| Step: 0
Training loss: 0.6259956359863281
Validation loss: 1.8085725076736943

Epoch: 5| Step: 1
Training loss: 0.6954485774040222
Validation loss: 1.7785691343328005

Epoch: 5| Step: 2
Training loss: 0.8487505912780762
Validation loss: 1.854315911569903

Epoch: 5| Step: 3
Training loss: 0.7964544296264648
Validation loss: 1.8158319765521633

Epoch: 5| Step: 4
Training loss: 0.8543716669082642
Validation loss: 1.825094856241698

Epoch: 5| Step: 5
Training loss: 0.8836574554443359
Validation loss: 1.810355160825996

Epoch: 5| Step: 6
Training loss: 1.286331295967102
Validation loss: 1.8674285886108235

Epoch: 5| Step: 7
Training loss: 0.7143133878707886
Validation loss: 1.7844801628461449

Epoch: 5| Step: 8
Training loss: 1.5301321744918823
Validation loss: 1.8532613682490524

Epoch: 5| Step: 9
Training loss: 0.7238660454750061
Validation loss: 1.8696369650543376

Epoch: 5| Step: 10
Training loss: 0.6705213785171509
Validation loss: 1.8608753014636297

Epoch: 530| Step: 0
Training loss: 0.7303614020347595
Validation loss: 1.8687693495904245

Epoch: 5| Step: 1
Training loss: 0.9357358813285828
Validation loss: 1.8610949067659275

Epoch: 5| Step: 2
Training loss: 1.0509685277938843
Validation loss: 1.8463141815636748

Epoch: 5| Step: 3
Training loss: 0.6510500311851501
Validation loss: 1.8065147886994064

Epoch: 5| Step: 4
Training loss: 0.9650272130966187
Validation loss: 1.8883415486222954

Epoch: 5| Step: 5
Training loss: 1.0815290212631226
Validation loss: 1.7922341067303893

Epoch: 5| Step: 6
Training loss: 0.49541887640953064
Validation loss: 1.8097277841260355

Epoch: 5| Step: 7
Training loss: 1.2912559509277344
Validation loss: 1.8016983642373035

Epoch: 5| Step: 8
Training loss: 0.8765642046928406
Validation loss: 1.8406918933314662

Epoch: 5| Step: 9
Training loss: 0.6736460328102112
Validation loss: 1.8392826088013188

Epoch: 5| Step: 10
Training loss: 0.9756718873977661
Validation loss: 1.8528038276139127

Epoch: 531| Step: 0
Training loss: 0.9652281999588013
Validation loss: 1.8148466797285183

Epoch: 5| Step: 1
Training loss: 0.868758499622345
Validation loss: 1.8568225701649983

Epoch: 5| Step: 2
Training loss: 1.066354513168335
Validation loss: 1.9005287539574407

Epoch: 5| Step: 3
Training loss: 1.0662755966186523
Validation loss: 1.9000481533747848

Epoch: 5| Step: 4
Training loss: 0.799616277217865
Validation loss: 1.9038142183775544

Epoch: 5| Step: 5
Training loss: 0.8806421160697937
Validation loss: 1.8824825081773984

Epoch: 5| Step: 6
Training loss: 1.128554105758667
Validation loss: 1.8581486850656488

Epoch: 5| Step: 7
Training loss: 1.0052952766418457
Validation loss: 1.8640172327718427

Epoch: 5| Step: 8
Training loss: 0.6782675385475159
Validation loss: 1.8296218693897288

Epoch: 5| Step: 9
Training loss: 0.896375834941864
Validation loss: 1.8077590593727686

Epoch: 5| Step: 10
Training loss: 0.5843023657798767
Validation loss: 1.8424456862993137

Epoch: 532| Step: 0
Training loss: 0.7230973839759827
Validation loss: 1.8129569227977465

Epoch: 5| Step: 1
Training loss: 0.8145288228988647
Validation loss: 1.8220614669143513

Epoch: 5| Step: 2
Training loss: 0.6822828054428101
Validation loss: 1.8279870287064584

Epoch: 5| Step: 3
Training loss: 1.229941487312317
Validation loss: 1.839185571157804

Epoch: 5| Step: 4
Training loss: 0.903156578540802
Validation loss: 1.8410557572559645

Epoch: 5| Step: 5
Training loss: 0.8060900568962097
Validation loss: 1.8356722971444488

Epoch: 5| Step: 6
Training loss: 0.9425058364868164
Validation loss: 1.8085205939508253

Epoch: 5| Step: 7
Training loss: 0.8913892507553101
Validation loss: 1.865059692372558

Epoch: 5| Step: 8
Training loss: 0.8575372695922852
Validation loss: 1.8856942205018894

Epoch: 5| Step: 9
Training loss: 0.987993597984314
Validation loss: 1.870309957893946

Epoch: 5| Step: 10
Training loss: 0.7171009182929993
Validation loss: 1.8475576190538303

Epoch: 533| Step: 0
Training loss: 0.7664329409599304
Validation loss: 1.8497569009821901

Epoch: 5| Step: 1
Training loss: 0.8724426031112671
Validation loss: 1.8498501623830488

Epoch: 5| Step: 2
Training loss: 0.5195991396903992
Validation loss: 1.799247048234427

Epoch: 5| Step: 3
Training loss: 1.0336833000183105
Validation loss: 1.840805733075706

Epoch: 5| Step: 4
Training loss: 1.338675856590271
Validation loss: 1.8099916622202883

Epoch: 5| Step: 5
Training loss: 0.6221283674240112
Validation loss: 1.8373097027501752

Epoch: 5| Step: 6
Training loss: 0.846463680267334
Validation loss: 1.8366553578325497

Epoch: 5| Step: 7
Training loss: 1.0731886625289917
Validation loss: 1.8381387597771102

Epoch: 5| Step: 8
Training loss: 0.9228960275650024
Validation loss: 1.827876724222655

Epoch: 5| Step: 9
Training loss: 0.9424125552177429
Validation loss: 1.8676614825443556

Epoch: 5| Step: 10
Training loss: 0.7346115112304688
Validation loss: 1.862319787343343

Epoch: 534| Step: 0
Training loss: 0.7563644051551819
Validation loss: 1.8731018522734284

Epoch: 5| Step: 1
Training loss: 1.099119782447815
Validation loss: 1.862925855062341

Epoch: 5| Step: 2
Training loss: 0.6782898902893066
Validation loss: 1.8954880160670127

Epoch: 5| Step: 3
Training loss: 1.0080682039260864
Validation loss: 1.906641496125088

Epoch: 5| Step: 4
Training loss: 0.8363305330276489
Validation loss: 1.8927664461956228

Epoch: 5| Step: 5
Training loss: 0.8750580549240112
Validation loss: 1.896447345774661

Epoch: 5| Step: 6
Training loss: 1.2562451362609863
Validation loss: 1.8432281940214095

Epoch: 5| Step: 7
Training loss: 1.05144464969635
Validation loss: 1.8814497570837698

Epoch: 5| Step: 8
Training loss: 1.096745252609253
Validation loss: 1.8431206223785237

Epoch: 5| Step: 9
Training loss: 0.6434585452079773
Validation loss: 1.821276504506347

Epoch: 5| Step: 10
Training loss: 0.7405691742897034
Validation loss: 1.7987622278992847

Epoch: 535| Step: 0
Training loss: 0.9823278188705444
Validation loss: 1.8105967096103135

Epoch: 5| Step: 1
Training loss: 0.8073051571846008
Validation loss: 1.8611950259054861

Epoch: 5| Step: 2
Training loss: 1.004795789718628
Validation loss: 1.838545036572282

Epoch: 5| Step: 3
Training loss: 1.4139347076416016
Validation loss: 1.7978589457850302

Epoch: 5| Step: 4
Training loss: 1.0429480075836182
Validation loss: 1.825463161673597

Epoch: 5| Step: 5
Training loss: 0.6462730169296265
Validation loss: 1.7969112755149923

Epoch: 5| Step: 6
Training loss: 0.6580031514167786
Validation loss: 1.802202514422837

Epoch: 5| Step: 7
Training loss: 0.9436675906181335
Validation loss: 1.8183904796518304

Epoch: 5| Step: 8
Training loss: 0.6503095626831055
Validation loss: 1.8536392565696471

Epoch: 5| Step: 9
Training loss: 0.884132981300354
Validation loss: 1.8529613094945108

Epoch: 5| Step: 10
Training loss: 0.6835675835609436
Validation loss: 1.8812036129736132

Epoch: 536| Step: 0
Training loss: 1.0370872020721436
Validation loss: 1.8517161915379186

Epoch: 5| Step: 1
Training loss: 0.7273228168487549
Validation loss: 1.846654982977016

Epoch: 5| Step: 2
Training loss: 0.7791818380355835
Validation loss: 1.8438061655208628

Epoch: 5| Step: 3
Training loss: 0.7230320572853088
Validation loss: 1.7900160948435466

Epoch: 5| Step: 4
Training loss: 1.0922346115112305
Validation loss: 1.8582196671475646

Epoch: 5| Step: 5
Training loss: 0.3290505111217499
Validation loss: 1.7864661947373421

Epoch: 5| Step: 6
Training loss: 0.7364581823348999
Validation loss: 1.827148078590311

Epoch: 5| Step: 7
Training loss: 0.8930975198745728
Validation loss: 1.8002284944698375

Epoch: 5| Step: 8
Training loss: 0.9925686120986938
Validation loss: 1.8745295950161514

Epoch: 5| Step: 9
Training loss: 0.9440779685974121
Validation loss: 1.826897168672213

Epoch: 5| Step: 10
Training loss: 1.5061217546463013
Validation loss: 1.8671594973533385

Epoch: 537| Step: 0
Training loss: 0.8950064778327942
Validation loss: 1.8782481762670702

Epoch: 5| Step: 1
Training loss: 0.5590130090713501
Validation loss: 1.8306541160870624

Epoch: 5| Step: 2
Training loss: 1.2277541160583496
Validation loss: 1.7805379411225677

Epoch: 5| Step: 3
Training loss: 1.149335503578186
Validation loss: 1.8299064649048673

Epoch: 5| Step: 4
Training loss: 0.8954045176506042
Validation loss: 1.8324379010867047

Epoch: 5| Step: 5
Training loss: 1.0690258741378784
Validation loss: 1.7923152164746357

Epoch: 5| Step: 6
Training loss: 0.5438714027404785
Validation loss: 1.8171553252845682

Epoch: 5| Step: 7
Training loss: 0.7976541519165039
Validation loss: 1.8163209115305254

Epoch: 5| Step: 8
Training loss: 0.7749168872833252
Validation loss: 1.8751006472495295

Epoch: 5| Step: 9
Training loss: 0.6568659543991089
Validation loss: 1.8311380064615639

Epoch: 5| Step: 10
Training loss: 0.9722616672515869
Validation loss: 1.8111691654369395

Epoch: 538| Step: 0
Training loss: 0.965890109539032
Validation loss: 1.8120815228390437

Epoch: 5| Step: 1
Training loss: 0.5912286043167114
Validation loss: 1.7617161581593175

Epoch: 5| Step: 2
Training loss: 0.7429682016372681
Validation loss: 1.8424502880342546

Epoch: 5| Step: 3
Training loss: 0.8933844566345215
Validation loss: 1.8226623483883437

Epoch: 5| Step: 4
Training loss: 0.8729456067085266
Validation loss: 1.8788894491810952

Epoch: 5| Step: 5
Training loss: 1.2248780727386475
Validation loss: 1.8509578063923826

Epoch: 5| Step: 6
Training loss: 0.9423917531967163
Validation loss: 1.8703144724651048

Epoch: 5| Step: 7
Training loss: 0.48224201798439026
Validation loss: 1.855822483698527

Epoch: 5| Step: 8
Training loss: 0.9893218874931335
Validation loss: 1.8528778706827471

Epoch: 5| Step: 9
Training loss: 1.0253784656524658
Validation loss: 1.8791043809665147

Epoch: 5| Step: 10
Training loss: 0.6635278463363647
Validation loss: 1.8272383007951962

Epoch: 539| Step: 0
Training loss: 1.0686933994293213
Validation loss: 1.8788595955858949

Epoch: 5| Step: 1
Training loss: 0.5058803558349609
Validation loss: 1.893110675196494

Epoch: 5| Step: 2
Training loss: 0.994269073009491
Validation loss: 1.87457662628543

Epoch: 5| Step: 3
Training loss: 0.8915022611618042
Validation loss: 1.8208649235387002

Epoch: 5| Step: 4
Training loss: 0.5797411203384399
Validation loss: 1.8740188434559812

Epoch: 5| Step: 5
Training loss: 1.089145541191101
Validation loss: 1.8536236696345831

Epoch: 5| Step: 6
Training loss: 0.6954619288444519
Validation loss: 1.7840415303425123

Epoch: 5| Step: 7
Training loss: 1.1566526889801025
Validation loss: 1.8646819822249874

Epoch: 5| Step: 8
Training loss: 0.49325308203697205
Validation loss: 1.820843849130856

Epoch: 5| Step: 9
Training loss: 0.8462610244750977
Validation loss: 1.8297816220150198

Epoch: 5| Step: 10
Training loss: 1.0219871997833252
Validation loss: 1.787451995316372

Epoch: 540| Step: 0
Training loss: 0.6223524808883667
Validation loss: 1.8253881341667586

Epoch: 5| Step: 1
Training loss: 0.9703140258789062
Validation loss: 1.8564604354161087

Epoch: 5| Step: 2
Training loss: 0.7464625835418701
Validation loss: 1.8395693109881492

Epoch: 5| Step: 3
Training loss: 0.6706646084785461
Validation loss: 1.8291280731078117

Epoch: 5| Step: 4
Training loss: 0.6014572381973267
Validation loss: 1.8547400120765931

Epoch: 5| Step: 5
Training loss: 0.969138503074646
Validation loss: 1.8388714136615876

Epoch: 5| Step: 6
Training loss: 0.8096885681152344
Validation loss: 1.8629094221258675

Epoch: 5| Step: 7
Training loss: 1.2983307838439941
Validation loss: 1.8445570609902824

Epoch: 5| Step: 8
Training loss: 0.8643304109573364
Validation loss: 1.8211547815671532

Epoch: 5| Step: 9
Training loss: 0.7551172971725464
Validation loss: 1.811552921930949

Epoch: 5| Step: 10
Training loss: 0.7963978052139282
Validation loss: 1.8592660170729443

Epoch: 541| Step: 0
Training loss: 1.145627498626709
Validation loss: 1.812520509125084

Epoch: 5| Step: 1
Training loss: 0.7516827583312988
Validation loss: 1.8554592786296722

Epoch: 5| Step: 2
Training loss: 1.146666407585144
Validation loss: 1.825683416858796

Epoch: 5| Step: 3
Training loss: 0.6779593229293823
Validation loss: 1.8176070785009733

Epoch: 5| Step: 4
Training loss: 1.2050962448120117
Validation loss: 1.8518541935951478

Epoch: 5| Step: 5
Training loss: 0.6901500225067139
Validation loss: 1.8163641191297961

Epoch: 5| Step: 6
Training loss: 0.5643985271453857
Validation loss: 1.840313926819832

Epoch: 5| Step: 7
Training loss: 0.7016288042068481
Validation loss: 1.842337178927596

Epoch: 5| Step: 8
Training loss: 0.43615108728408813
Validation loss: 1.8078246116638184

Epoch: 5| Step: 9
Training loss: 0.9539608955383301
Validation loss: 1.8609951837088472

Epoch: 5| Step: 10
Training loss: 1.2485977411270142
Validation loss: 1.8547125119034962

Epoch: 542| Step: 0
Training loss: 0.7049225568771362
Validation loss: 1.8448122726973666

Epoch: 5| Step: 1
Training loss: 1.282158374786377
Validation loss: 1.7747576800725793

Epoch: 5| Step: 2
Training loss: 0.7889746427536011
Validation loss: 1.8615615034616122

Epoch: 5| Step: 3
Training loss: 0.9004799127578735
Validation loss: 1.8075566419991114

Epoch: 5| Step: 4
Training loss: 0.8567851185798645
Validation loss: 1.7953803052184403

Epoch: 5| Step: 5
Training loss: 0.8006318807601929
Validation loss: 1.8218121272261425

Epoch: 5| Step: 6
Training loss: 0.3466637432575226
Validation loss: 1.8490333839129376

Epoch: 5| Step: 7
Training loss: 0.69081711769104
Validation loss: 1.8772522890439598

Epoch: 5| Step: 8
Training loss: 1.3849701881408691
Validation loss: 1.8166946544442126

Epoch: 5| Step: 9
Training loss: 0.6371370553970337
Validation loss: 1.8287449754694456

Epoch: 5| Step: 10
Training loss: 1.101629614830017
Validation loss: 1.8625499227995514

Epoch: 543| Step: 0
Training loss: 0.5272108316421509
Validation loss: 1.855473086398135

Epoch: 5| Step: 1
Training loss: 1.1149905920028687
Validation loss: 1.8423555333127257

Epoch: 5| Step: 2
Training loss: 0.9078985452651978
Validation loss: 1.8326130861877112

Epoch: 5| Step: 3
Training loss: 0.8690959811210632
Validation loss: 1.820580332509933

Epoch: 5| Step: 4
Training loss: 0.656740128993988
Validation loss: 1.780402542442404

Epoch: 5| Step: 5
Training loss: 0.6242541074752808
Validation loss: 1.8359645540996263

Epoch: 5| Step: 6
Training loss: 0.9072514772415161
Validation loss: 1.807617110590781

Epoch: 5| Step: 7
Training loss: 0.4223281741142273
Validation loss: 1.8736500509323613

Epoch: 5| Step: 8
Training loss: 1.3164911270141602
Validation loss: 1.8357210479756838

Epoch: 5| Step: 9
Training loss: 0.9099384546279907
Validation loss: 1.8062829971313477

Epoch: 5| Step: 10
Training loss: 0.5792424082756042
Validation loss: 1.8267431656519573

Epoch: 544| Step: 0
Training loss: 1.1346887350082397
Validation loss: 1.84684710092442

Epoch: 5| Step: 1
Training loss: 0.707025945186615
Validation loss: 1.8452356220573507

Epoch: 5| Step: 2
Training loss: 1.187941551208496
Validation loss: 1.8767170534339002

Epoch: 5| Step: 3
Training loss: 0.9679218530654907
Validation loss: 1.9349655976859472

Epoch: 5| Step: 4
Training loss: 0.6461424231529236
Validation loss: 1.8440136909484863

Epoch: 5| Step: 5
Training loss: 0.5027720928192139
Validation loss: 1.8744679086951799

Epoch: 5| Step: 6
Training loss: 1.2380962371826172
Validation loss: 1.8058643699974142

Epoch: 5| Step: 7
Training loss: 0.9575713872909546
Validation loss: 1.8287086102270311

Epoch: 5| Step: 8
Training loss: 0.6379398107528687
Validation loss: 1.8648357916903753

Epoch: 5| Step: 9
Training loss: 0.8325709104537964
Validation loss: 1.8606495805965957

Epoch: 5| Step: 10
Training loss: 0.5815195441246033
Validation loss: 1.8198711051735827

Epoch: 545| Step: 0
Training loss: 0.971584677696228
Validation loss: 1.8249042610968313

Epoch: 5| Step: 1
Training loss: 1.2096002101898193
Validation loss: 1.806599340131206

Epoch: 5| Step: 2
Training loss: 0.5046334266662598
Validation loss: 1.8096719493148148

Epoch: 5| Step: 3
Training loss: 0.9960977435112
Validation loss: 1.8354000455589705

Epoch: 5| Step: 4
Training loss: 0.6927536129951477
Validation loss: 1.8159191262337468

Epoch: 5| Step: 5
Training loss: 1.0690958499908447
Validation loss: 1.7725471219708842

Epoch: 5| Step: 6
Training loss: 0.6766625642776489
Validation loss: 1.8521466793552521

Epoch: 5| Step: 7
Training loss: 1.123194932937622
Validation loss: 1.809414936650184

Epoch: 5| Step: 8
Training loss: 0.5377763509750366
Validation loss: 1.8181966068924114

Epoch: 5| Step: 9
Training loss: 0.7572094202041626
Validation loss: 1.8576034422843688

Epoch: 5| Step: 10
Training loss: 0.9880574345588684
Validation loss: 1.906789642508312

Epoch: 546| Step: 0
Training loss: 1.1692804098129272
Validation loss: 1.8304962676058534

Epoch: 5| Step: 1
Training loss: 0.9694646000862122
Validation loss: 1.8606055885232904

Epoch: 5| Step: 2
Training loss: 0.7014265656471252
Validation loss: 1.8323310267540716

Epoch: 5| Step: 3
Training loss: 1.0795395374298096
Validation loss: 1.8382852808121712

Epoch: 5| Step: 4
Training loss: 0.8220651745796204
Validation loss: 1.8755126050723496

Epoch: 5| Step: 5
Training loss: 0.9615330696105957
Validation loss: 1.7939930256976877

Epoch: 5| Step: 6
Training loss: 0.6384097337722778
Validation loss: 1.8502066878862278

Epoch: 5| Step: 7
Training loss: 0.5171983242034912
Validation loss: 1.8592612179376746

Epoch: 5| Step: 8
Training loss: 0.6924092173576355
Validation loss: 1.8297639316128147

Epoch: 5| Step: 9
Training loss: 0.7030705213546753
Validation loss: 1.7858412240141182

Epoch: 5| Step: 10
Training loss: 1.3556621074676514
Validation loss: 1.817764861609346

Epoch: 547| Step: 0
Training loss: 0.6863688826560974
Validation loss: 1.7919075668499034

Epoch: 5| Step: 1
Training loss: 1.067657709121704
Validation loss: 1.84996792193382

Epoch: 5| Step: 2
Training loss: 0.9921911358833313
Validation loss: 1.8180938920667093

Epoch: 5| Step: 3
Training loss: 0.4223254323005676
Validation loss: 1.8170910496865549

Epoch: 5| Step: 4
Training loss: 0.6188777089118958
Validation loss: 1.8028581770517493

Epoch: 5| Step: 5
Training loss: 0.860517680644989
Validation loss: 1.8172672781893002

Epoch: 5| Step: 6
Training loss: 0.8825971484184265
Validation loss: 1.8140426169159591

Epoch: 5| Step: 7
Training loss: 0.6344001889228821
Validation loss: 1.864111674729214

Epoch: 5| Step: 8
Training loss: 1.1832926273345947
Validation loss: 1.7793572461733254

Epoch: 5| Step: 9
Training loss: 0.9207209348678589
Validation loss: 1.8252244777576898

Epoch: 5| Step: 10
Training loss: 0.8341562747955322
Validation loss: 1.8263951245174612

Epoch: 548| Step: 0
Training loss: 0.9408859014511108
Validation loss: 1.8302837879427019

Epoch: 5| Step: 1
Training loss: 0.7313321232795715
Validation loss: 1.8057018479993265

Epoch: 5| Step: 2
Training loss: 0.6440899968147278
Validation loss: 1.823302149772644

Epoch: 5| Step: 3
Training loss: 1.1870826482772827
Validation loss: 1.854402357532132

Epoch: 5| Step: 4
Training loss: 0.7638253569602966
Validation loss: 1.842887043952942

Epoch: 5| Step: 5
Training loss: 0.9691096544265747
Validation loss: 1.8426710508202995

Epoch: 5| Step: 6
Training loss: 1.2628726959228516
Validation loss: 1.8246077619573122

Epoch: 5| Step: 7
Training loss: 0.8715615272521973
Validation loss: 1.8545808548568397

Epoch: 5| Step: 8
Training loss: 0.7617890238761902
Validation loss: 1.8489503963019258

Epoch: 5| Step: 9
Training loss: 0.6327047944068909
Validation loss: 1.8860990616583055

Epoch: 5| Step: 10
Training loss: 0.6796746253967285
Validation loss: 1.8527341183795725

Epoch: 549| Step: 0
Training loss: 0.4569978713989258
Validation loss: 1.839516116726783

Epoch: 5| Step: 1
Training loss: 0.9926824569702148
Validation loss: 1.8418031866832445

Epoch: 5| Step: 2
Training loss: 0.8629554510116577
Validation loss: 1.8582959098200644

Epoch: 5| Step: 3
Training loss: 1.084820032119751
Validation loss: 1.832452477947358

Epoch: 5| Step: 4
Training loss: 0.5608156323432922
Validation loss: 1.8363442215868222

Epoch: 5| Step: 5
Training loss: 0.492570698261261
Validation loss: 1.8256211127004316

Epoch: 5| Step: 6
Training loss: 0.9908077120780945
Validation loss: 1.7818182232559368

Epoch: 5| Step: 7
Training loss: 0.9828201532363892
Validation loss: 1.8138181932510868

Epoch: 5| Step: 8
Training loss: 0.94292151927948
Validation loss: 1.8045477213398102

Epoch: 5| Step: 9
Training loss: 0.9495587348937988
Validation loss: 1.8107262324261408

Epoch: 5| Step: 10
Training loss: 1.048296570777893
Validation loss: 1.8281933440957019

Epoch: 550| Step: 0
Training loss: 0.48676472902297974
Validation loss: 1.8105931512771114

Epoch: 5| Step: 1
Training loss: 1.0253582000732422
Validation loss: 1.8392973830623012

Epoch: 5| Step: 2
Training loss: 0.7501004934310913
Validation loss: 1.8487315408645137

Epoch: 5| Step: 3
Training loss: 0.6924101710319519
Validation loss: 1.7979712896449591

Epoch: 5| Step: 4
Training loss: 0.6612896919250488
Validation loss: 1.8113832768573557

Epoch: 5| Step: 5
Training loss: 0.6551164388656616
Validation loss: 1.8183108965555828

Epoch: 5| Step: 6
Training loss: 1.0947418212890625
Validation loss: 1.8402683478529736

Epoch: 5| Step: 7
Training loss: 0.8904060125350952
Validation loss: 1.8095609885390087

Epoch: 5| Step: 8
Training loss: 1.0208743810653687
Validation loss: 1.8475251325996973

Epoch: 5| Step: 9
Training loss: 1.347186803817749
Validation loss: 1.7907604363656813

Epoch: 5| Step: 10
Training loss: 0.46477454900741577
Validation loss: 1.8434234844741

Epoch: 551| Step: 0
Training loss: 0.6733207106590271
Validation loss: 1.8561283926809988

Epoch: 5| Step: 1
Training loss: 0.9141605496406555
Validation loss: 1.764737371475466

Epoch: 5| Step: 2
Training loss: 0.640981137752533
Validation loss: 1.8345900043364494

Epoch: 5| Step: 3
Training loss: 1.0173752307891846
Validation loss: 1.8408044256189817

Epoch: 5| Step: 4
Training loss: 0.5897594690322876
Validation loss: 1.8028112765281432

Epoch: 5| Step: 5
Training loss: 0.8425996899604797
Validation loss: 1.8746422221583705

Epoch: 5| Step: 6
Training loss: 0.7397411465644836
Validation loss: 1.8625815478704308

Epoch: 5| Step: 7
Training loss: 0.8183151483535767
Validation loss: 1.8576154067952146

Epoch: 5| Step: 8
Training loss: 1.0725972652435303
Validation loss: 1.899719456190704

Epoch: 5| Step: 9
Training loss: 0.9140831232070923
Validation loss: 1.843676846514466

Epoch: 5| Step: 10
Training loss: 0.7482932806015015
Validation loss: 1.8559228117747972

Epoch: 552| Step: 0
Training loss: 0.7469924688339233
Validation loss: 1.8921541193480134

Epoch: 5| Step: 1
Training loss: 0.7090152502059937
Validation loss: 1.7933336970626668

Epoch: 5| Step: 2
Training loss: 0.5719005465507507
Validation loss: 1.8637026458658197

Epoch: 5| Step: 3
Training loss: 1.0406885147094727
Validation loss: 1.855448584402761

Epoch: 5| Step: 4
Training loss: 0.7614299058914185
Validation loss: 1.7934462383229246

Epoch: 5| Step: 5
Training loss: 1.1927640438079834
Validation loss: 1.8391138046018538

Epoch: 5| Step: 6
Training loss: 0.7750747799873352
Validation loss: 1.8226356070528749

Epoch: 5| Step: 7
Training loss: 1.0450465679168701
Validation loss: 1.8417896237424625

Epoch: 5| Step: 8
Training loss: 0.7701846361160278
Validation loss: 1.8345285654067993

Epoch: 5| Step: 9
Training loss: 0.6409872770309448
Validation loss: 1.8179686748853294

Epoch: 5| Step: 10
Training loss: 0.9028123021125793
Validation loss: 1.8541736320782733

Epoch: 553| Step: 0
Training loss: 0.967235267162323
Validation loss: 1.8244202342084659

Epoch: 5| Step: 1
Training loss: 1.0677237510681152
Validation loss: 1.8662101094440748

Epoch: 5| Step: 2
Training loss: 0.744929313659668
Validation loss: 1.8485545240422732

Epoch: 5| Step: 3
Training loss: 0.5915296077728271
Validation loss: 1.8768008691008373

Epoch: 5| Step: 4
Training loss: 1.0234817266464233
Validation loss: 1.873523501939671

Epoch: 5| Step: 5
Training loss: 0.7254242300987244
Validation loss: 1.8594126650082168

Epoch: 5| Step: 6
Training loss: 0.729952871799469
Validation loss: 1.8493251762082499

Epoch: 5| Step: 7
Training loss: 0.9371145963668823
Validation loss: 1.8883879492359776

Epoch: 5| Step: 8
Training loss: 0.8450285196304321
Validation loss: 1.8567978028328187

Epoch: 5| Step: 9
Training loss: 0.9065283536911011
Validation loss: 1.8038009353863296

Epoch: 5| Step: 10
Training loss: 0.498283326625824
Validation loss: 1.8721675360074608

Epoch: 554| Step: 0
Training loss: 0.6944397687911987
Validation loss: 1.8186465373603247

Epoch: 5| Step: 1
Training loss: 0.6100329160690308
Validation loss: 1.848995280522172

Epoch: 5| Step: 2
Training loss: 1.2023167610168457
Validation loss: 1.835200676354029

Epoch: 5| Step: 3
Training loss: 0.9220352172851562
Validation loss: 1.8025802309795091

Epoch: 5| Step: 4
Training loss: 0.621680498123169
Validation loss: 1.803685454912083

Epoch: 5| Step: 5
Training loss: 0.7638829946517944
Validation loss: 1.8164033992316133

Epoch: 5| Step: 6
Training loss: 0.9185525178909302
Validation loss: 1.8192350505500712

Epoch: 5| Step: 7
Training loss: 1.093558669090271
Validation loss: 1.821953546616339

Epoch: 5| Step: 8
Training loss: 0.785155177116394
Validation loss: 1.8403298111372097

Epoch: 5| Step: 9
Training loss: 0.8725374937057495
Validation loss: 1.926303252097099

Epoch: 5| Step: 10
Training loss: 0.610607922077179
Validation loss: 1.8511007524305774

Epoch: 555| Step: 0
Training loss: 0.9403462409973145
Validation loss: 1.8038260603463778

Epoch: 5| Step: 1
Training loss: 0.6231544613838196
Validation loss: 1.8486989493011146

Epoch: 5| Step: 2
Training loss: 0.7300435304641724
Validation loss: 1.8281331959591116

Epoch: 5| Step: 3
Training loss: 0.7088221907615662
Validation loss: 1.8183366970349384

Epoch: 5| Step: 4
Training loss: 0.8217926025390625
Validation loss: 1.784768359635466

Epoch: 5| Step: 5
Training loss: 0.9243023991584778
Validation loss: 1.7919359181516914

Epoch: 5| Step: 6
Training loss: 0.7105122804641724
Validation loss: 1.7952518296498123

Epoch: 5| Step: 7
Training loss: 0.8539266586303711
Validation loss: 1.856137228268449

Epoch: 5| Step: 8
Training loss: 0.9418705105781555
Validation loss: 1.8377264135627336

Epoch: 5| Step: 9
Training loss: 1.023463249206543
Validation loss: 1.8155101524886263

Epoch: 5| Step: 10
Training loss: 1.125001311302185
Validation loss: 1.7946176503294258

Epoch: 556| Step: 0
Training loss: 0.7300722002983093
Validation loss: 1.844520071501373

Epoch: 5| Step: 1
Training loss: 0.8277376294136047
Validation loss: 1.8601159959711053

Epoch: 5| Step: 2
Training loss: 0.9556301236152649
Validation loss: 1.8086097419902842

Epoch: 5| Step: 3
Training loss: 0.5483059883117676
Validation loss: 1.8481151045009654

Epoch: 5| Step: 4
Training loss: 0.5897175073623657
Validation loss: 1.786907216554047

Epoch: 5| Step: 5
Training loss: 1.3972446918487549
Validation loss: 1.8349273743168

Epoch: 5| Step: 6
Training loss: 0.7941656708717346
Validation loss: 1.8196160190848893

Epoch: 5| Step: 7
Training loss: 0.8220109939575195
Validation loss: 1.8190867535529598

Epoch: 5| Step: 8
Training loss: 0.6558663249015808
Validation loss: 1.8164693129959928

Epoch: 5| Step: 9
Training loss: 0.9527906179428101
Validation loss: 1.836214444970572

Epoch: 5| Step: 10
Training loss: 0.6250770092010498
Validation loss: 1.822536721024462

Epoch: 557| Step: 0
Training loss: 0.8415412902832031
Validation loss: 1.824868466264458

Epoch: 5| Step: 1
Training loss: 0.3773725628852844
Validation loss: 1.7967888693655691

Epoch: 5| Step: 2
Training loss: 0.8109598159790039
Validation loss: 1.8624590827572731

Epoch: 5| Step: 3
Training loss: 0.7088916897773743
Validation loss: 1.795232685663367

Epoch: 5| Step: 4
Training loss: 0.610862135887146
Validation loss: 1.8089171955662389

Epoch: 5| Step: 5
Training loss: 0.6916300058364868
Validation loss: 1.8559946398581229

Epoch: 5| Step: 6
Training loss: 1.5438288450241089
Validation loss: 1.825828016445201

Epoch: 5| Step: 7
Training loss: 0.43607598543167114
Validation loss: 1.8238586507817751

Epoch: 5| Step: 8
Training loss: 1.0672733783721924
Validation loss: 1.832809123941647

Epoch: 5| Step: 9
Training loss: 0.9056113362312317
Validation loss: 1.8110085430965628

Epoch: 5| Step: 10
Training loss: 1.2794761657714844
Validation loss: 1.8507246637857089

Epoch: 558| Step: 0
Training loss: 0.7627497911453247
Validation loss: 1.8132333717038553

Epoch: 5| Step: 1
Training loss: 0.5367323160171509
Validation loss: 1.834272664080384

Epoch: 5| Step: 2
Training loss: 0.6382452845573425
Validation loss: 1.91050765591283

Epoch: 5| Step: 3
Training loss: 0.6162270307540894
Validation loss: 1.8590083301708262

Epoch: 5| Step: 4
Training loss: 0.7025853395462036
Validation loss: 1.9225353271730485

Epoch: 5| Step: 5
Training loss: 1.2061859369277954
Validation loss: 1.8461630998119232

Epoch: 5| Step: 6
Training loss: 0.8681003451347351
Validation loss: 1.8461917472142044

Epoch: 5| Step: 7
Training loss: 1.1262707710266113
Validation loss: 1.7928767383739512

Epoch: 5| Step: 8
Training loss: 0.9496524930000305
Validation loss: 1.8045331867792274

Epoch: 5| Step: 9
Training loss: 0.7974554300308228
Validation loss: 1.8273668955731135

Epoch: 5| Step: 10
Training loss: 0.8618468642234802
Validation loss: 1.8188757550331853

Epoch: 559| Step: 0
Training loss: 1.0896626710891724
Validation loss: 1.8394468138294835

Epoch: 5| Step: 1
Training loss: 0.7019321322441101
Validation loss: 1.8407164517269339

Epoch: 5| Step: 2
Training loss: 0.6795156598091125
Validation loss: 1.8166493651687459

Epoch: 5| Step: 3
Training loss: 0.772881031036377
Validation loss: 1.7895019195413078

Epoch: 5| Step: 4
Training loss: 0.8360359072685242
Validation loss: 1.7702432447864163

Epoch: 5| Step: 5
Training loss: 1.1623547077178955
Validation loss: 1.8322615444019277

Epoch: 5| Step: 6
Training loss: 0.8076063394546509
Validation loss: 1.8277367417530348

Epoch: 5| Step: 7
Training loss: 0.7563624978065491
Validation loss: 1.8151950272180701

Epoch: 5| Step: 8
Training loss: 0.6281717419624329
Validation loss: 1.804516424414932

Epoch: 5| Step: 9
Training loss: 0.9155038595199585
Validation loss: 1.8140453061749857

Epoch: 5| Step: 10
Training loss: 0.9488357305526733
Validation loss: 1.7914518412723337

Epoch: 560| Step: 0
Training loss: 0.9435907602310181
Validation loss: 1.8260807529572518

Epoch: 5| Step: 1
Training loss: 0.7830548286437988
Validation loss: 1.8400373138407224

Epoch: 5| Step: 2
Training loss: 1.235849142074585
Validation loss: 1.8619516511117258

Epoch: 5| Step: 3
Training loss: 0.7047101259231567
Validation loss: 1.8503250563016502

Epoch: 5| Step: 4
Training loss: 0.9600814580917358
Validation loss: 1.8028709042456843

Epoch: 5| Step: 5
Training loss: 0.6611996293067932
Validation loss: 1.8163428075851933

Epoch: 5| Step: 6
Training loss: 1.1353164911270142
Validation loss: 1.806661085415912

Epoch: 5| Step: 7
Training loss: 0.6402307152748108
Validation loss: 1.8502627803433327

Epoch: 5| Step: 8
Training loss: 0.8079310655593872
Validation loss: 1.8658959083659674

Epoch: 5| Step: 9
Training loss: 0.556390106678009
Validation loss: 1.8196906094909997

Epoch: 5| Step: 10
Training loss: 0.5818445682525635
Validation loss: 1.8251134990363993

Epoch: 561| Step: 0
Training loss: 1.0473546981811523
Validation loss: 1.8044201968818583

Epoch: 5| Step: 1
Training loss: 0.543228030204773
Validation loss: 1.786195997268923

Epoch: 5| Step: 2
Training loss: 0.5338560342788696
Validation loss: 1.8061724068016134

Epoch: 5| Step: 3
Training loss: 0.856303334236145
Validation loss: 1.7907900579514042

Epoch: 5| Step: 4
Training loss: 0.7941826581954956
Validation loss: 1.8384519623171898

Epoch: 5| Step: 5
Training loss: 0.8146399259567261
Validation loss: 1.8577903445048998

Epoch: 5| Step: 6
Training loss: 0.6168081760406494
Validation loss: 1.8748917592469083

Epoch: 5| Step: 7
Training loss: 0.7767332196235657
Validation loss: 1.836602746799428

Epoch: 5| Step: 8
Training loss: 0.783815860748291
Validation loss: 1.8323559132955407

Epoch: 5| Step: 9
Training loss: 0.9755791425704956
Validation loss: 1.871404218417342

Epoch: 5| Step: 10
Training loss: 0.935208261013031
Validation loss: 1.8317111358847669

Epoch: 562| Step: 0
Training loss: 0.5984452366828918
Validation loss: 1.802775558604989

Epoch: 5| Step: 1
Training loss: 0.8288848996162415
Validation loss: 1.8092714150746663

Epoch: 5| Step: 2
Training loss: 0.5053340792655945
Validation loss: 1.8420759836832683

Epoch: 5| Step: 3
Training loss: 1.0054563283920288
Validation loss: 1.824263354783417

Epoch: 5| Step: 4
Training loss: 1.0321077108383179
Validation loss: 1.8511536839187785

Epoch: 5| Step: 5
Training loss: 0.6631582975387573
Validation loss: 1.840734343374929

Epoch: 5| Step: 6
Training loss: 0.7989699840545654
Validation loss: 1.8529651382918

Epoch: 5| Step: 7
Training loss: 0.6395471692085266
Validation loss: 1.84346761626582

Epoch: 5| Step: 8
Training loss: 0.836754322052002
Validation loss: 1.865328856693801

Epoch: 5| Step: 9
Training loss: 0.6489805579185486
Validation loss: 1.8066938231068272

Epoch: 5| Step: 10
Training loss: 1.1970829963684082
Validation loss: 1.8022814873726136

Epoch: 563| Step: 0
Training loss: 1.1785888671875
Validation loss: 1.8444722570398802

Epoch: 5| Step: 1
Training loss: 0.877322793006897
Validation loss: 1.8669211710652998

Epoch: 5| Step: 2
Training loss: 0.7574833035469055
Validation loss: 1.8408267523652764

Epoch: 5| Step: 3
Training loss: 0.7607890367507935
Validation loss: 1.8524551724874845

Epoch: 5| Step: 4
Training loss: 0.7227253913879395
Validation loss: 1.8362705733186455

Epoch: 5| Step: 5
Training loss: 0.579698920249939
Validation loss: 1.894412471402076

Epoch: 5| Step: 6
Training loss: 0.9890939593315125
Validation loss: 1.8273148357227285

Epoch: 5| Step: 7
Training loss: 0.8720538020133972
Validation loss: 1.866445364490632

Epoch: 5| Step: 8
Training loss: 0.572454571723938
Validation loss: 1.8822432051422775

Epoch: 5| Step: 9
Training loss: 0.9584250450134277
Validation loss: 1.8971687645040534

Epoch: 5| Step: 10
Training loss: 0.6255787014961243
Validation loss: 1.8844636089058333

Epoch: 564| Step: 0
Training loss: 1.226332426071167
Validation loss: 1.7994033252039263

Epoch: 5| Step: 1
Training loss: 1.0049769878387451
Validation loss: 1.8605071498501686

Epoch: 5| Step: 2
Training loss: 0.8074654340744019
Validation loss: 1.8005248692727858

Epoch: 5| Step: 3
Training loss: 0.8330322504043579
Validation loss: 1.813382516625107

Epoch: 5| Step: 4
Training loss: 0.6279110312461853
Validation loss: 1.812234809321742

Epoch: 5| Step: 5
Training loss: 0.7412293553352356
Validation loss: 1.8545957880635415

Epoch: 5| Step: 6
Training loss: 0.528644323348999
Validation loss: 1.8259840075687697

Epoch: 5| Step: 7
Training loss: 0.7092865705490112
Validation loss: 1.8322114854730585

Epoch: 5| Step: 8
Training loss: 1.0813491344451904
Validation loss: 1.7914108986495643

Epoch: 5| Step: 9
Training loss: 0.8308489918708801
Validation loss: 1.8038068663689397

Epoch: 5| Step: 10
Training loss: 0.38274264335632324
Validation loss: 1.8555237247097878

Epoch: 565| Step: 0
Training loss: 0.8660866022109985
Validation loss: 1.8436785923537387

Epoch: 5| Step: 1
Training loss: 0.8075939416885376
Validation loss: 1.7649071883129817

Epoch: 5| Step: 2
Training loss: 1.175697684288025
Validation loss: 1.847430166377816

Epoch: 5| Step: 3
Training loss: 0.6286059617996216
Validation loss: 1.851852616956157

Epoch: 5| Step: 4
Training loss: 0.7289290428161621
Validation loss: 1.901883718787983

Epoch: 5| Step: 5
Training loss: 0.7831887602806091
Validation loss: 1.814066974065637

Epoch: 5| Step: 6
Training loss: 0.9805570840835571
Validation loss: 1.8016207935989543

Epoch: 5| Step: 7
Training loss: 0.7928210496902466
Validation loss: 1.8631344649099535

Epoch: 5| Step: 8
Training loss: 0.7010559439659119
Validation loss: 1.8369861059291388

Epoch: 5| Step: 9
Training loss: 0.6848543882369995
Validation loss: 1.844086993125177

Epoch: 5| Step: 10
Training loss: 0.8827649354934692
Validation loss: 1.8256767616477063

Epoch: 566| Step: 0
Training loss: 1.164044737815857
Validation loss: 1.8225854942875523

Epoch: 5| Step: 1
Training loss: 0.9162179231643677
Validation loss: 1.8085259314506286

Epoch: 5| Step: 2
Training loss: 0.8223322033882141
Validation loss: 1.8411762919477237

Epoch: 5| Step: 3
Training loss: 0.7224148511886597
Validation loss: 1.837306514863045

Epoch: 5| Step: 4
Training loss: 0.7190393209457397
Validation loss: 1.785850896630236

Epoch: 5| Step: 5
Training loss: 0.6872345209121704
Validation loss: 1.8310675210850214

Epoch: 5| Step: 6
Training loss: 0.6716223955154419
Validation loss: 1.9060073052683184

Epoch: 5| Step: 7
Training loss: 0.6698458194732666
Validation loss: 1.856527106736296

Epoch: 5| Step: 8
Training loss: 0.7104581594467163
Validation loss: 1.7839130791284705

Epoch: 5| Step: 9
Training loss: 0.600561261177063
Validation loss: 1.7963306724384267

Epoch: 5| Step: 10
Training loss: 1.0325742959976196
Validation loss: 1.8180047876091414

Epoch: 567| Step: 0
Training loss: 0.450422465801239
Validation loss: 1.8600417772928874

Epoch: 5| Step: 1
Training loss: 0.8277291059494019
Validation loss: 1.819688940560946

Epoch: 5| Step: 2
Training loss: 1.0112097263336182
Validation loss: 1.8630140417365617

Epoch: 5| Step: 3
Training loss: 1.0947577953338623
Validation loss: 1.8560668755603094

Epoch: 5| Step: 4
Training loss: 0.8043720126152039
Validation loss: 1.844580840038997

Epoch: 5| Step: 5
Training loss: 1.1420683860778809
Validation loss: 1.7898090552258235

Epoch: 5| Step: 6
Training loss: 0.7118774652481079
Validation loss: 1.8362035930797618

Epoch: 5| Step: 7
Training loss: 0.5317152738571167
Validation loss: 1.7827100510238318

Epoch: 5| Step: 8
Training loss: 0.9396328926086426
Validation loss: 1.8268157448819888

Epoch: 5| Step: 9
Training loss: 0.6419815421104431
Validation loss: 1.8368226635840632

Epoch: 5| Step: 10
Training loss: 0.5869811773300171
Validation loss: 1.8127937765531643

Epoch: 568| Step: 0
Training loss: 1.1001191139221191
Validation loss: 1.7858939632292716

Epoch: 5| Step: 1
Training loss: 0.5801824331283569
Validation loss: 1.8668985507821525

Epoch: 5| Step: 2
Training loss: 0.7064698934555054
Validation loss: 1.7759039107189383

Epoch: 5| Step: 3
Training loss: 1.2474586963653564
Validation loss: 1.8081442899601434

Epoch: 5| Step: 4
Training loss: 0.7245358228683472
Validation loss: 1.8251103534493396

Epoch: 5| Step: 5
Training loss: 0.7303972840309143
Validation loss: 1.816462270675167

Epoch: 5| Step: 6
Training loss: 0.7017062902450562
Validation loss: 1.816788605464402

Epoch: 5| Step: 7
Training loss: 0.7149686217308044
Validation loss: 1.7984631343554425

Epoch: 5| Step: 8
Training loss: 1.02278733253479
Validation loss: 1.8421538042765793

Epoch: 5| Step: 9
Training loss: 0.6477994918823242
Validation loss: 1.813846662480344

Epoch: 5| Step: 10
Training loss: 0.8097400665283203
Validation loss: 1.8840349066642024

Epoch: 569| Step: 0
Training loss: 1.1513084173202515
Validation loss: 1.778062843507336

Epoch: 5| Step: 1
Training loss: 0.6683001518249512
Validation loss: 1.8636056659042195

Epoch: 5| Step: 2
Training loss: 1.156493067741394
Validation loss: 1.8253250327161563

Epoch: 5| Step: 3
Training loss: 0.5707840323448181
Validation loss: 1.7767097296253327

Epoch: 5| Step: 4
Training loss: 0.9110010266304016
Validation loss: 1.837831994538666

Epoch: 5| Step: 5
Training loss: 0.5014253854751587
Validation loss: 1.8276716316899946

Epoch: 5| Step: 6
Training loss: 0.827658474445343
Validation loss: 1.8284867348209504

Epoch: 5| Step: 7
Training loss: 0.8920835256576538
Validation loss: 1.8017430331117363

Epoch: 5| Step: 8
Training loss: 0.9559041857719421
Validation loss: 1.8338352275151077

Epoch: 5| Step: 9
Training loss: 0.7384544610977173
Validation loss: 1.8168559689675607

Epoch: 5| Step: 10
Training loss: 0.676970899105072
Validation loss: 1.8220638831456502

Epoch: 570| Step: 0
Training loss: 0.8535232543945312
Validation loss: 1.816901929916874

Epoch: 5| Step: 1
Training loss: 0.6532331705093384
Validation loss: 1.8844523545234435

Epoch: 5| Step: 2
Training loss: 1.2204837799072266
Validation loss: 1.8407804940336494

Epoch: 5| Step: 3
Training loss: 0.7417503595352173
Validation loss: 1.8659193259413525

Epoch: 5| Step: 4
Training loss: 0.8590012788772583
Validation loss: 1.82984193166097

Epoch: 5| Step: 5
Training loss: 0.5702913403511047
Validation loss: 1.900635721862957

Epoch: 5| Step: 6
Training loss: 1.1744410991668701
Validation loss: 1.8471841709588164

Epoch: 5| Step: 7
Training loss: 0.8337804675102234
Validation loss: 1.80380339776316

Epoch: 5| Step: 8
Training loss: 0.8273723721504211
Validation loss: 1.8365837168949906

Epoch: 5| Step: 9
Training loss: 0.547824501991272
Validation loss: 1.9056321510704615

Epoch: 5| Step: 10
Training loss: 0.3666718006134033
Validation loss: 1.8290842220347414

Epoch: 571| Step: 0
Training loss: 0.5304514765739441
Validation loss: 1.820822528613511

Epoch: 5| Step: 1
Training loss: 0.9480942487716675
Validation loss: 1.8662395092748827

Epoch: 5| Step: 2
Training loss: 1.0762170553207397
Validation loss: 1.7896938990521174

Epoch: 5| Step: 3
Training loss: 0.7915694117546082
Validation loss: 1.8304414620963476

Epoch: 5| Step: 4
Training loss: 0.8644474148750305
Validation loss: 1.8119094987069406

Epoch: 5| Step: 5
Training loss: 0.7706323266029358
Validation loss: 1.8484607537587483

Epoch: 5| Step: 6
Training loss: 0.5338546633720398
Validation loss: 1.8302958537173528

Epoch: 5| Step: 7
Training loss: 0.9750224351882935
Validation loss: 1.828016011945663

Epoch: 5| Step: 8
Training loss: 0.454629510641098
Validation loss: 1.833219062897467

Epoch: 5| Step: 9
Training loss: 1.0247468948364258
Validation loss: 1.855186713639126

Epoch: 5| Step: 10
Training loss: 0.763551652431488
Validation loss: 1.8978132150506462

Epoch: 572| Step: 0
Training loss: 0.741640567779541
Validation loss: 1.8777607076911516

Epoch: 5| Step: 1
Training loss: 0.692388117313385
Validation loss: 1.8423484128008607

Epoch: 5| Step: 2
Training loss: 0.9111638069152832
Validation loss: 1.816975752512614

Epoch: 5| Step: 3
Training loss: 0.6913395524024963
Validation loss: 1.8159382445837862

Epoch: 5| Step: 4
Training loss: 0.6158269047737122
Validation loss: 1.8550461389685189

Epoch: 5| Step: 5
Training loss: 1.0910078287124634
Validation loss: 1.8020462618079236

Epoch: 5| Step: 6
Training loss: 0.4475472867488861
Validation loss: 1.840652297901851

Epoch: 5| Step: 7
Training loss: 0.5964184999465942
Validation loss: 1.8382458815010645

Epoch: 5| Step: 8
Training loss: 0.8592079877853394
Validation loss: 1.8602976581101776

Epoch: 5| Step: 9
Training loss: 1.1587377786636353
Validation loss: 1.8927562800786828

Epoch: 5| Step: 10
Training loss: 1.1326072216033936
Validation loss: 1.8578154912558935

Epoch: 573| Step: 0
Training loss: 1.2081438302993774
Validation loss: 1.8730266030116747

Epoch: 5| Step: 1
Training loss: 0.9960905313491821
Validation loss: 1.8697661430604997

Epoch: 5| Step: 2
Training loss: 0.724298357963562
Validation loss: 1.8301813910084386

Epoch: 5| Step: 3
Training loss: 0.7187016606330872
Validation loss: 1.8711934038387832

Epoch: 5| Step: 4
Training loss: 0.8424871563911438
Validation loss: 1.8932929000546854

Epoch: 5| Step: 5
Training loss: 0.40022510290145874
Validation loss: 1.8526005475751814

Epoch: 5| Step: 6
Training loss: 0.7631136775016785
Validation loss: 1.8428446682550574

Epoch: 5| Step: 7
Training loss: 0.6818050146102905
Validation loss: 1.8116536896715882

Epoch: 5| Step: 8
Training loss: 1.2961543798446655
Validation loss: 1.8304089551330895

Epoch: 5| Step: 9
Training loss: 0.6767401099205017
Validation loss: 1.813656614672753

Epoch: 5| Step: 10
Training loss: 0.6256909370422363
Validation loss: 1.7653375710210493

Epoch: 574| Step: 0
Training loss: 1.1747851371765137
Validation loss: 1.7846592100717689

Epoch: 5| Step: 1
Training loss: 1.395578384399414
Validation loss: 1.863017697488108

Epoch: 5| Step: 2
Training loss: 0.6528534293174744
Validation loss: 1.8235936857038928

Epoch: 5| Step: 3
Training loss: 0.6482893228530884
Validation loss: 1.85356383169851

Epoch: 5| Step: 4
Training loss: 0.6513709425926208
Validation loss: 1.8951702451193204

Epoch: 5| Step: 5
Training loss: 0.7136586904525757
Validation loss: 1.834354208361718

Epoch: 5| Step: 6
Training loss: 0.2857905924320221
Validation loss: 1.8094384888167023

Epoch: 5| Step: 7
Training loss: 0.7136720418930054
Validation loss: 1.8631267944971721

Epoch: 5| Step: 8
Training loss: 1.0332584381103516
Validation loss: 1.788697220945871

Epoch: 5| Step: 9
Training loss: 0.763232946395874
Validation loss: 1.8500718942252539

Epoch: 5| Step: 10
Training loss: 0.4802705645561218
Validation loss: 1.840067312281619

Epoch: 575| Step: 0
Training loss: 0.9474163055419922
Validation loss: 1.791175337247951

Epoch: 5| Step: 1
Training loss: 0.8688170313835144
Validation loss: 1.8225469845597462

Epoch: 5| Step: 2
Training loss: 0.6593454480171204
Validation loss: 1.8465365978979296

Epoch: 5| Step: 3
Training loss: 1.322511911392212
Validation loss: 1.8216759133082565

Epoch: 5| Step: 4
Training loss: 0.8057352304458618
Validation loss: 1.8250593793007635

Epoch: 5| Step: 5
Training loss: 0.5910561680793762
Validation loss: 1.8645403244162118

Epoch: 5| Step: 6
Training loss: 0.8863042593002319
Validation loss: 1.874368417647577

Epoch: 5| Step: 7
Training loss: 0.4967445433139801
Validation loss: 1.9061100970032394

Epoch: 5| Step: 8
Training loss: 0.6283655762672424
Validation loss: 1.8615027448182464

Epoch: 5| Step: 9
Training loss: 0.7452080249786377
Validation loss: 1.8714309264254827

Epoch: 5| Step: 10
Training loss: 0.8472607731819153
Validation loss: 1.8609234902166552

Epoch: 576| Step: 0
Training loss: 0.5814627408981323
Validation loss: 1.8709152795935189

Epoch: 5| Step: 1
Training loss: 0.6713374853134155
Validation loss: 1.843450851337884

Epoch: 5| Step: 2
Training loss: 0.804267406463623
Validation loss: 1.8343992015366912

Epoch: 5| Step: 3
Training loss: 0.5925882458686829
Validation loss: 1.8307819827910392

Epoch: 5| Step: 4
Training loss: 0.8867770433425903
Validation loss: 1.8374183690676125

Epoch: 5| Step: 5
Training loss: 0.8726837038993835
Validation loss: 1.8290458494617092

Epoch: 5| Step: 6
Training loss: 1.1608014106750488
Validation loss: 1.801133619841709

Epoch: 5| Step: 7
Training loss: 0.9823201894760132
Validation loss: 1.774090286224119

Epoch: 5| Step: 8
Training loss: 0.7445212602615356
Validation loss: 1.8474963083062121

Epoch: 5| Step: 9
Training loss: 0.5147114992141724
Validation loss: 1.8291494333615868

Epoch: 5| Step: 10
Training loss: 0.7800437808036804
Validation loss: 1.8237021610301027

Epoch: 577| Step: 0
Training loss: 0.7369598746299744
Validation loss: 1.844346305375458

Epoch: 5| Step: 1
Training loss: 0.46860772371292114
Validation loss: 1.835263385567614

Epoch: 5| Step: 2
Training loss: 1.2526596784591675
Validation loss: 1.8603754697307464

Epoch: 5| Step: 3
Training loss: 0.5128795504570007
Validation loss: 1.8352505750553583

Epoch: 5| Step: 4
Training loss: 0.6235913038253784
Validation loss: 1.823553471155064

Epoch: 5| Step: 5
Training loss: 0.5599850416183472
Validation loss: 1.803870270329137

Epoch: 5| Step: 6
Training loss: 0.6734131574630737
Validation loss: 1.8557345123701199

Epoch: 5| Step: 7
Training loss: 0.7339423298835754
Validation loss: 1.8576883423712947

Epoch: 5| Step: 8
Training loss: 1.1988379955291748
Validation loss: 1.8380686583057526

Epoch: 5| Step: 9
Training loss: 0.7123750448226929
Validation loss: 1.8653955485231133

Epoch: 5| Step: 10
Training loss: 1.100679636001587
Validation loss: 1.8001943890766432

Epoch: 578| Step: 0
Training loss: 0.7764984369277954
Validation loss: 1.8060882091522217

Epoch: 5| Step: 1
Training loss: 0.5712341070175171
Validation loss: 1.8224118486527474

Epoch: 5| Step: 2
Training loss: 1.343658685684204
Validation loss: 1.8584141192897674

Epoch: 5| Step: 3
Training loss: 0.5936306715011597
Validation loss: 1.8083007643299718

Epoch: 5| Step: 4
Training loss: 1.0980056524276733
Validation loss: 1.8158353438941381

Epoch: 5| Step: 5
Training loss: 0.6870125532150269
Validation loss: 1.7988955487487137

Epoch: 5| Step: 6
Training loss: 1.0666426420211792
Validation loss: 1.8015288973367343

Epoch: 5| Step: 7
Training loss: 0.5257431864738464
Validation loss: 1.8164459915571316

Epoch: 5| Step: 8
Training loss: 0.7787748575210571
Validation loss: 1.8381434794395202

Epoch: 5| Step: 9
Training loss: 0.3796967566013336
Validation loss: 1.8138579912083124

Epoch: 5| Step: 10
Training loss: 0.9922829866409302
Validation loss: 1.8271929551196355

Epoch: 579| Step: 0
Training loss: 0.8790656924247742
Validation loss: 1.9102184580218406

Epoch: 5| Step: 1
Training loss: 1.208420991897583
Validation loss: 1.8188710545980802

Epoch: 5| Step: 2
Training loss: 0.8519555330276489
Validation loss: 1.8266677548808437

Epoch: 5| Step: 3
Training loss: 0.633938193321228
Validation loss: 1.8028195186327862

Epoch: 5| Step: 4
Training loss: 0.5931487679481506
Validation loss: 1.868538147659712

Epoch: 5| Step: 5
Training loss: 0.4504503309726715
Validation loss: 1.7794912707421087

Epoch: 5| Step: 6
Training loss: 0.5618705749511719
Validation loss: 1.828919420960129

Epoch: 5| Step: 7
Training loss: 0.500140905380249
Validation loss: 1.845271348953247

Epoch: 5| Step: 8
Training loss: 1.1819021701812744
Validation loss: 1.8622044594057146

Epoch: 5| Step: 9
Training loss: 0.8185771107673645
Validation loss: 1.8738453695850987

Epoch: 5| Step: 10
Training loss: 0.7572557926177979
Validation loss: 1.8177185520049064

Epoch: 580| Step: 0
Training loss: 1.0024043321609497
Validation loss: 1.8599574130068544

Epoch: 5| Step: 1
Training loss: 0.6285756826400757
Validation loss: 1.8344513498326784

Epoch: 5| Step: 2
Training loss: 0.703504204750061
Validation loss: 1.8645503674784014

Epoch: 5| Step: 3
Training loss: 0.9741080403327942
Validation loss: 1.869442670576034

Epoch: 5| Step: 4
Training loss: 1.0828287601470947
Validation loss: 1.8568710345093922

Epoch: 5| Step: 5
Training loss: 0.6593903303146362
Validation loss: 1.870280599081388

Epoch: 5| Step: 6
Training loss: 0.6866233944892883
Validation loss: 1.7853735018801946

Epoch: 5| Step: 7
Training loss: 0.9982386827468872
Validation loss: 1.8084732986265613

Epoch: 5| Step: 8
Training loss: 0.7296627163887024
Validation loss: 1.8132325782570788

Epoch: 5| Step: 9
Training loss: 0.6225991249084473
Validation loss: 1.823766254609631

Epoch: 5| Step: 10
Training loss: 0.6103760004043579
Validation loss: 1.8666189511617024

Epoch: 581| Step: 0
Training loss: 0.7269109487533569
Validation loss: 1.831891123966504

Epoch: 5| Step: 1
Training loss: 1.0609920024871826
Validation loss: 1.8593864735736643

Epoch: 5| Step: 2
Training loss: 0.5422208905220032
Validation loss: 1.7944266616657216

Epoch: 5| Step: 3
Training loss: 0.7620454430580139
Validation loss: 1.803898298612205

Epoch: 5| Step: 4
Training loss: 0.6833594441413879
Validation loss: 1.7768545971121839

Epoch: 5| Step: 5
Training loss: 0.7717172503471375
Validation loss: 1.828787313994541

Epoch: 5| Step: 6
Training loss: 0.49819836020469666
Validation loss: 1.79210485822411

Epoch: 5| Step: 7
Training loss: 0.8444064855575562
Validation loss: 1.842716045277093

Epoch: 5| Step: 8
Training loss: 0.446973979473114
Validation loss: 1.8494343565356346

Epoch: 5| Step: 9
Training loss: 1.365661382675171
Validation loss: 1.8391731157097766

Epoch: 5| Step: 10
Training loss: 0.816246509552002
Validation loss: 1.8496771140765118

Epoch: 582| Step: 0
Training loss: 0.4553792476654053
Validation loss: 1.8588946839814544

Epoch: 5| Step: 1
Training loss: 0.6586657762527466
Validation loss: 1.8696423333178285

Epoch: 5| Step: 2
Training loss: 0.8350326418876648
Validation loss: 1.8849899320192234

Epoch: 5| Step: 3
Training loss: 0.7876380681991577
Validation loss: 1.8614359542887697

Epoch: 5| Step: 4
Training loss: 0.8293026089668274
Validation loss: 1.8351091466924196

Epoch: 5| Step: 5
Training loss: 0.9616082906723022
Validation loss: 1.8730906055819603

Epoch: 5| Step: 6
Training loss: 0.9848639369010925
Validation loss: 1.8307568398855065

Epoch: 5| Step: 7
Training loss: 0.40738025307655334
Validation loss: 1.8425143072682042

Epoch: 5| Step: 8
Training loss: 0.7079872488975525
Validation loss: 1.8892887587188392

Epoch: 5| Step: 9
Training loss: 0.7100757360458374
Validation loss: 1.8022496341377177

Epoch: 5| Step: 10
Training loss: 1.134672999382019
Validation loss: 1.833979864274302

Epoch: 583| Step: 0
Training loss: 0.3905123770236969
Validation loss: 1.798565435153182

Epoch: 5| Step: 1
Training loss: 1.1160261631011963
Validation loss: 1.890210009390308

Epoch: 5| Step: 2
Training loss: 0.6972821354866028
Validation loss: 1.7695831380864626

Epoch: 5| Step: 3
Training loss: 0.6010597944259644
Validation loss: 1.8152410291856336

Epoch: 5| Step: 4
Training loss: 1.3363622426986694
Validation loss: 1.8154558673981698

Epoch: 5| Step: 5
Training loss: 0.8955930471420288
Validation loss: 1.8103735869930637

Epoch: 5| Step: 6
Training loss: 0.6878023743629456
Validation loss: 1.8253457520597725

Epoch: 5| Step: 7
Training loss: 0.5133942365646362
Validation loss: 1.9046419705114057

Epoch: 5| Step: 8
Training loss: 0.8559468388557434
Validation loss: 1.8933303151079404

Epoch: 5| Step: 9
Training loss: 0.8007773160934448
Validation loss: 1.832021761966008

Epoch: 5| Step: 10
Training loss: 0.6685924530029297
Validation loss: 1.8426826487305343

Epoch: 584| Step: 0
Training loss: 0.5810442566871643
Validation loss: 1.8703690651924378

Epoch: 5| Step: 1
Training loss: 1.2328717708587646
Validation loss: 1.8804334607175601

Epoch: 5| Step: 2
Training loss: 0.9245159029960632
Validation loss: 1.8861159893774218

Epoch: 5| Step: 3
Training loss: 0.9268711805343628
Validation loss: 1.8399414452173377

Epoch: 5| Step: 4
Training loss: 0.4763104021549225
Validation loss: 1.8634180868825605

Epoch: 5| Step: 5
Training loss: 0.5222185850143433
Validation loss: 1.8363073487435617

Epoch: 5| Step: 6
Training loss: 0.6406391859054565
Validation loss: 1.8703049305946595

Epoch: 5| Step: 7
Training loss: 1.0727077722549438
Validation loss: 1.901770548153949

Epoch: 5| Step: 8
Training loss: 0.9803516268730164
Validation loss: 1.8864868763954408

Epoch: 5| Step: 9
Training loss: 0.8672749400138855
Validation loss: 1.9063952892057356

Epoch: 5| Step: 10
Training loss: 0.5636700391769409
Validation loss: 1.8788144152651551

Epoch: 585| Step: 0
Training loss: 0.8525722622871399
Validation loss: 1.8541072235312512

Epoch: 5| Step: 1
Training loss: 0.7005000114440918
Validation loss: 1.834214666838287

Epoch: 5| Step: 2
Training loss: 0.7667852640151978
Validation loss: 1.8057657480239868

Epoch: 5| Step: 3
Training loss: 1.1731222867965698
Validation loss: 1.7846605277830554

Epoch: 5| Step: 4
Training loss: 0.5943814516067505
Validation loss: 1.8665605668098695

Epoch: 5| Step: 5
Training loss: 1.0531057119369507
Validation loss: 1.8097753576053086

Epoch: 5| Step: 6
Training loss: 0.9839232563972473
Validation loss: 1.811485177727156

Epoch: 5| Step: 7
Training loss: 0.5893114805221558
Validation loss: 1.8393970753556939

Epoch: 5| Step: 8
Training loss: 0.725782573223114
Validation loss: 1.8394577016112625

Epoch: 5| Step: 9
Training loss: 0.8182881474494934
Validation loss: 1.802210787291168

Epoch: 5| Step: 10
Training loss: 0.6694145202636719
Validation loss: 1.8452440243895336

Epoch: 586| Step: 0
Training loss: 0.5861814618110657
Validation loss: 1.8591523016652753

Epoch: 5| Step: 1
Training loss: 0.4689781665802002
Validation loss: 1.8692588165242185

Epoch: 5| Step: 2
Training loss: 0.9492089152336121
Validation loss: 1.8341919132458266

Epoch: 5| Step: 3
Training loss: 0.7259594798088074
Validation loss: 1.8942978446201613

Epoch: 5| Step: 4
Training loss: 0.7653895616531372
Validation loss: 1.821006710811328

Epoch: 5| Step: 5
Training loss: 1.1763094663619995
Validation loss: 1.8396826123678556

Epoch: 5| Step: 6
Training loss: 0.5230497121810913
Validation loss: 1.862038461110925

Epoch: 5| Step: 7
Training loss: 1.0397588014602661
Validation loss: 1.8480814528721634

Epoch: 5| Step: 8
Training loss: 0.9202393293380737
Validation loss: 1.8234555093191003

Epoch: 5| Step: 9
Training loss: 0.6570379137992859
Validation loss: 1.82529265393493

Epoch: 5| Step: 10
Training loss: 0.696487545967102
Validation loss: 1.8027415890847482

Epoch: 587| Step: 0
Training loss: 1.0034968852996826
Validation loss: 1.7857590080589376

Epoch: 5| Step: 1
Training loss: 0.4981849193572998
Validation loss: 1.7808401482079619

Epoch: 5| Step: 2
Training loss: 0.9189079999923706
Validation loss: 1.796693371188256

Epoch: 5| Step: 3
Training loss: 0.8796104192733765
Validation loss: 1.8397149091125817

Epoch: 5| Step: 4
Training loss: 0.5453833341598511
Validation loss: 1.8308167880581272

Epoch: 5| Step: 5
Training loss: 0.5350584983825684
Validation loss: 1.8155167487359816

Epoch: 5| Step: 6
Training loss: 0.7947821617126465
Validation loss: 1.790685938250634

Epoch: 5| Step: 7
Training loss: 0.8048874735832214
Validation loss: 1.8464890756914694

Epoch: 5| Step: 8
Training loss: 0.7295159101486206
Validation loss: 1.7887851730469735

Epoch: 5| Step: 9
Training loss: 0.9005864858627319
Validation loss: 1.8343209444835622

Epoch: 5| Step: 10
Training loss: 1.0210213661193848
Validation loss: 1.9088465654721825

Epoch: 588| Step: 0
Training loss: 0.8384107351303101
Validation loss: 1.8121652641604025

Epoch: 5| Step: 1
Training loss: 0.5567805171012878
Validation loss: 1.8792261205693728

Epoch: 5| Step: 2
Training loss: 0.8052915334701538
Validation loss: 1.8260331922961819

Epoch: 5| Step: 3
Training loss: 1.229501485824585
Validation loss: 1.84926954648828

Epoch: 5| Step: 4
Training loss: 0.7780711054801941
Validation loss: 1.8091789035386936

Epoch: 5| Step: 5
Training loss: 0.9463987350463867
Validation loss: 1.7907011739669307

Epoch: 5| Step: 6
Training loss: 0.7950559854507446
Validation loss: 1.8426100451459166

Epoch: 5| Step: 7
Training loss: 0.7937868237495422
Validation loss: 1.861337169524162

Epoch: 5| Step: 8
Training loss: 0.8354800939559937
Validation loss: 1.8714317685814315

Epoch: 5| Step: 9
Training loss: 0.45431771874427795
Validation loss: 1.803833866632113

Epoch: 5| Step: 10
Training loss: 0.5637389421463013
Validation loss: 1.8427753269031484

Epoch: 589| Step: 0
Training loss: 0.8104845285415649
Validation loss: 1.8307779988934916

Epoch: 5| Step: 1
Training loss: 0.8709640502929688
Validation loss: 1.834331001004865

Epoch: 5| Step: 2
Training loss: 0.5284444093704224
Validation loss: 1.8819493247616677

Epoch: 5| Step: 3
Training loss: 0.7142192125320435
Validation loss: 1.8488729179546397

Epoch: 5| Step: 4
Training loss: 0.4565213620662689
Validation loss: 1.8328123246469805

Epoch: 5| Step: 5
Training loss: 0.9995147585868835
Validation loss: 1.8592611371829946

Epoch: 5| Step: 6
Training loss: 0.6289743781089783
Validation loss: 1.855785039163405

Epoch: 5| Step: 7
Training loss: 1.0251766443252563
Validation loss: 1.8673429566044961

Epoch: 5| Step: 8
Training loss: 0.9568864703178406
Validation loss: 1.8452207349961804

Epoch: 5| Step: 9
Training loss: 1.110422134399414
Validation loss: 1.8323868205470424

Epoch: 5| Step: 10
Training loss: 0.688666820526123
Validation loss: 1.8408142276989516

Epoch: 590| Step: 0
Training loss: 1.0250370502471924
Validation loss: 1.8625979577341387

Epoch: 5| Step: 1
Training loss: 0.6550463438034058
Validation loss: 1.83535050576733

Epoch: 5| Step: 2
Training loss: 0.8468092083930969
Validation loss: 1.830599231104697

Epoch: 5| Step: 3
Training loss: 0.5234130620956421
Validation loss: 1.8483155632531771

Epoch: 5| Step: 4
Training loss: 0.5889633893966675
Validation loss: 1.8534951902204944

Epoch: 5| Step: 5
Training loss: 0.8393958806991577
Validation loss: 1.7449734108422392

Epoch: 5| Step: 6
Training loss: 0.929248034954071
Validation loss: 1.846257491778302

Epoch: 5| Step: 7
Training loss: 0.6823244094848633
Validation loss: 1.867086854032291

Epoch: 5| Step: 8
Training loss: 1.0300469398498535
Validation loss: 1.8035257285641086

Epoch: 5| Step: 9
Training loss: 0.5092419385910034
Validation loss: 1.791406916033837

Epoch: 5| Step: 10
Training loss: 0.9335358738899231
Validation loss: 1.8078863210575555

Epoch: 591| Step: 0
Training loss: 0.7449885606765747
Validation loss: 1.8934167328701224

Epoch: 5| Step: 1
Training loss: 0.7933758497238159
Validation loss: 1.8244757652282715

Epoch: 5| Step: 2
Training loss: 0.760681688785553
Validation loss: 1.8054454313811434

Epoch: 5| Step: 3
Training loss: 0.7181514501571655
Validation loss: 1.8216826877286356

Epoch: 5| Step: 4
Training loss: 0.5698224902153015
Validation loss: 1.8989825735809982

Epoch: 5| Step: 5
Training loss: 0.8049192428588867
Validation loss: 1.8695879802908948

Epoch: 5| Step: 6
Training loss: 0.7261413931846619
Validation loss: 1.8204450863663868

Epoch: 5| Step: 7
Training loss: 0.8126257061958313
Validation loss: 1.8591705881139284

Epoch: 5| Step: 8
Training loss: 0.5552037954330444
Validation loss: 1.908193721566149

Epoch: 5| Step: 9
Training loss: 1.2811553478240967
Validation loss: 1.869991635763517

Epoch: 5| Step: 10
Training loss: 0.6446952819824219
Validation loss: 1.8386791995776597

Epoch: 592| Step: 0
Training loss: 0.6854491233825684
Validation loss: 1.78750233111843

Epoch: 5| Step: 1
Training loss: 0.46331900358200073
Validation loss: 1.8376997734910698

Epoch: 5| Step: 2
Training loss: 0.4810773432254791
Validation loss: 1.8181777923337874

Epoch: 5| Step: 3
Training loss: 0.7600927352905273
Validation loss: 1.808465257767708

Epoch: 5| Step: 4
Training loss: 0.7873126268386841
Validation loss: 1.8495298354856429

Epoch: 5| Step: 5
Training loss: 1.0761549472808838
Validation loss: 1.7650504817244828

Epoch: 5| Step: 6
Training loss: 0.72798091173172
Validation loss: 1.8292194912510533

Epoch: 5| Step: 7
Training loss: 1.2097452878952026
Validation loss: 1.811516846379926

Epoch: 5| Step: 8
Training loss: 1.0200750827789307
Validation loss: 1.80333770731444

Epoch: 5| Step: 9
Training loss: 0.5668478012084961
Validation loss: 1.7898467285658723

Epoch: 5| Step: 10
Training loss: 0.5914784669876099
Validation loss: 1.8320688893718104

Epoch: 593| Step: 0
Training loss: 0.8592373132705688
Validation loss: 1.8393737244349655

Epoch: 5| Step: 1
Training loss: 0.8578527569770813
Validation loss: 1.8437083613487981

Epoch: 5| Step: 2
Training loss: 0.962813675403595
Validation loss: 1.7917825304051882

Epoch: 5| Step: 3
Training loss: 0.8060309290885925
Validation loss: 1.8741919789262997

Epoch: 5| Step: 4
Training loss: 0.5645983815193176
Validation loss: 1.9022780695269186

Epoch: 5| Step: 5
Training loss: 0.6743990778923035
Validation loss: 1.8652260572679582

Epoch: 5| Step: 6
Training loss: 0.7042455077171326
Validation loss: 1.8417111622389926

Epoch: 5| Step: 7
Training loss: 0.659091591835022
Validation loss: 1.8283348262950938

Epoch: 5| Step: 8
Training loss: 0.8536435961723328
Validation loss: 1.8403419038300872

Epoch: 5| Step: 9
Training loss: 0.9514721035957336
Validation loss: 1.7948709687879008

Epoch: 5| Step: 10
Training loss: 0.5925536155700684
Validation loss: 1.8377082194051435

Epoch: 594| Step: 0
Training loss: 1.1155290603637695
Validation loss: 1.8796324447918964

Epoch: 5| Step: 1
Training loss: 0.6978527307510376
Validation loss: 1.8535953708874282

Epoch: 5| Step: 2
Training loss: 0.5256317853927612
Validation loss: 1.8345429922944756

Epoch: 5| Step: 3
Training loss: 0.7662644386291504
Validation loss: 1.898187142546459

Epoch: 5| Step: 4
Training loss: 0.5289087295532227
Validation loss: 1.896008623543606

Epoch: 5| Step: 5
Training loss: 0.8501394987106323
Validation loss: 1.8529613979401127

Epoch: 5| Step: 6
Training loss: 0.9781630635261536
Validation loss: 1.8976643418753019

Epoch: 5| Step: 7
Training loss: 0.7495619654655457
Validation loss: 1.9227171738942463

Epoch: 5| Step: 8
Training loss: 0.8699755668640137
Validation loss: 1.896573692239741

Epoch: 5| Step: 9
Training loss: 0.8387888669967651
Validation loss: 1.901020553804213

Epoch: 5| Step: 10
Training loss: 0.685237467288971
Validation loss: 1.7974887586409045

Epoch: 595| Step: 0
Training loss: 0.8813954591751099
Validation loss: 1.8540266149787492

Epoch: 5| Step: 1
Training loss: 0.7659364938735962
Validation loss: 1.7913902369878625

Epoch: 5| Step: 2
Training loss: 0.9139789342880249
Validation loss: 1.8095077776139783

Epoch: 5| Step: 3
Training loss: 0.8571568727493286
Validation loss: 1.848056741940078

Epoch: 5| Step: 4
Training loss: 0.6920284032821655
Validation loss: 1.7751181792187434

Epoch: 5| Step: 5
Training loss: 0.6965864300727844
Validation loss: 1.8555108667701803

Epoch: 5| Step: 6
Training loss: 1.0131031274795532
Validation loss: 1.8235578229350429

Epoch: 5| Step: 7
Training loss: 0.5908464193344116
Validation loss: 1.822432751296669

Epoch: 5| Step: 8
Training loss: 0.6963222622871399
Validation loss: 1.8073826733455862

Epoch: 5| Step: 9
Training loss: 1.1446527242660522
Validation loss: 1.8675095599184754

Epoch: 5| Step: 10
Training loss: 0.4766407012939453
Validation loss: 1.87085162696018

Epoch: 596| Step: 0
Training loss: 0.9079958200454712
Validation loss: 1.8252262094969391

Epoch: 5| Step: 1
Training loss: 0.6634780168533325
Validation loss: 1.901861471514548

Epoch: 5| Step: 2
Training loss: 0.5977493524551392
Validation loss: 1.9205701812621085

Epoch: 5| Step: 3
Training loss: 0.5637911558151245
Validation loss: 1.862911949234624

Epoch: 5| Step: 4
Training loss: 0.4838690757751465
Validation loss: 1.8653524370603665

Epoch: 5| Step: 5
Training loss: 0.8477669954299927
Validation loss: 1.8179530584683983

Epoch: 5| Step: 6
Training loss: 0.6117878556251526
Validation loss: 1.8502888025776032

Epoch: 5| Step: 7
Training loss: 0.6259876489639282
Validation loss: 1.874556408133558

Epoch: 5| Step: 8
Training loss: 1.307196855545044
Validation loss: 1.8301886371386948

Epoch: 5| Step: 9
Training loss: 1.0899062156677246
Validation loss: 1.8947368347516624

Epoch: 5| Step: 10
Training loss: 0.45942580699920654
Validation loss: 1.8504066069920857

Epoch: 597| Step: 0
Training loss: 0.7621930837631226
Validation loss: 1.799677764215777

Epoch: 5| Step: 1
Training loss: 0.348438560962677
Validation loss: 1.8269424797386251

Epoch: 5| Step: 2
Training loss: 0.8736763000488281
Validation loss: 1.899312198802989

Epoch: 5| Step: 3
Training loss: 0.9573229551315308
Validation loss: 1.863038186104067

Epoch: 5| Step: 4
Training loss: 0.8619445562362671
Validation loss: 1.874012739427628

Epoch: 5| Step: 5
Training loss: 0.6423822641372681
Validation loss: 1.8281891063977314

Epoch: 5| Step: 6
Training loss: 0.7229284644126892
Validation loss: 1.8592287750654324

Epoch: 5| Step: 7
Training loss: 1.0465977191925049
Validation loss: 1.85003230520474

Epoch: 5| Step: 8
Training loss: 0.5902668237686157
Validation loss: 1.7920586434743737

Epoch: 5| Step: 9
Training loss: 0.4528353810310364
Validation loss: 1.8048334749796058

Epoch: 5| Step: 10
Training loss: 0.8815665245056152
Validation loss: 1.833448435670586

Epoch: 598| Step: 0
Training loss: 0.48480597138404846
Validation loss: 1.8215346182546308

Epoch: 5| Step: 1
Training loss: 0.8629385828971863
Validation loss: 1.8593162772476033

Epoch: 5| Step: 2
Training loss: 0.7491121292114258
Validation loss: 1.8211071619423487

Epoch: 5| Step: 3
Training loss: 0.8560029864311218
Validation loss: 1.821102430743556

Epoch: 5| Step: 4
Training loss: 0.8681419491767883
Validation loss: 1.797508075673093

Epoch: 5| Step: 5
Training loss: 1.0667755603790283
Validation loss: 1.829357329235282

Epoch: 5| Step: 6
Training loss: 0.9589263796806335
Validation loss: 1.8262247962336386

Epoch: 5| Step: 7
Training loss: 0.5398997068405151
Validation loss: 1.8490547236575876

Epoch: 5| Step: 8
Training loss: 0.7048422694206238
Validation loss: 1.8167362930954143

Epoch: 5| Step: 9
Training loss: 0.8267723917961121
Validation loss: 1.8225405318762666

Epoch: 5| Step: 10
Training loss: 0.4185655117034912
Validation loss: 1.8589490780266382

Epoch: 599| Step: 0
Training loss: 0.2121928185224533
Validation loss: 1.82887303444647

Epoch: 5| Step: 1
Training loss: 1.1183278560638428
Validation loss: 1.8333824808879564

Epoch: 5| Step: 2
Training loss: 1.159588098526001
Validation loss: 1.8567961890210387

Epoch: 5| Step: 3
Training loss: 0.4497807025909424
Validation loss: 1.8175439860231133

Epoch: 5| Step: 4
Training loss: 0.7726430892944336
Validation loss: 1.8803664394604263

Epoch: 5| Step: 5
Training loss: 1.0434014797210693
Validation loss: 1.8156757149645077

Epoch: 5| Step: 6
Training loss: 0.8552838563919067
Validation loss: 1.781790587209886

Epoch: 5| Step: 7
Training loss: 0.6953025460243225
Validation loss: 1.8223214495566584

Epoch: 5| Step: 8
Training loss: 0.5949286222457886
Validation loss: 1.8283915173622869

Epoch: 5| Step: 9
Training loss: 0.6713482737541199
Validation loss: 1.8622498678904709

Epoch: 5| Step: 10
Training loss: 0.6560236215591431
Validation loss: 1.7825039253439954

Epoch: 600| Step: 0
Training loss: 0.7951341867446899
Validation loss: 1.8726495324924428

Epoch: 5| Step: 1
Training loss: 0.7842862010002136
Validation loss: 1.8071466004976662

Epoch: 5| Step: 2
Training loss: 0.5407599210739136
Validation loss: 1.8354702790578206

Epoch: 5| Step: 3
Training loss: 0.6090959310531616
Validation loss: 1.8604752600833934

Epoch: 5| Step: 4
Training loss: 0.6562626361846924
Validation loss: 1.7963490870691114

Epoch: 5| Step: 5
Training loss: 0.768983006477356
Validation loss: 1.8608910627262567

Epoch: 5| Step: 6
Training loss: 0.5483068227767944
Validation loss: 1.844070416624828

Epoch: 5| Step: 7
Training loss: 0.5668196678161621
Validation loss: 1.8387116642408474

Epoch: 5| Step: 8
Training loss: 1.034209132194519
Validation loss: 1.819561530185002

Epoch: 5| Step: 9
Training loss: 1.1309230327606201
Validation loss: 1.84406021846238

Epoch: 5| Step: 10
Training loss: 0.8507691025733948
Validation loss: 1.8450005823566067

Epoch: 601| Step: 0
Training loss: 0.954494833946228
Validation loss: 1.8264235527284685

Epoch: 5| Step: 1
Training loss: 0.7593411207199097
Validation loss: 1.8274315659717848

Epoch: 5| Step: 2
Training loss: 0.6413429975509644
Validation loss: 1.8377408827504804

Epoch: 5| Step: 3
Training loss: 0.41263771057128906
Validation loss: 1.8369282137963079

Epoch: 5| Step: 4
Training loss: 0.8154240846633911
Validation loss: 1.8002716572053972

Epoch: 5| Step: 5
Training loss: 0.9631000757217407
Validation loss: 1.8616112765445505

Epoch: 5| Step: 6
Training loss: 0.46197813749313354
Validation loss: 1.8352318758605628

Epoch: 5| Step: 7
Training loss: 0.6587380766868591
Validation loss: 1.8231807101157405

Epoch: 5| Step: 8
Training loss: 0.9598991274833679
Validation loss: 1.8575199278452064

Epoch: 5| Step: 9
Training loss: 0.7783833742141724
Validation loss: 1.830780501006752

Epoch: 5| Step: 10
Training loss: 0.9073946475982666
Validation loss: 1.7850290626607916

Epoch: 602| Step: 0
Training loss: 0.5571240186691284
Validation loss: 1.7956761826751053

Epoch: 5| Step: 1
Training loss: 0.7028136253356934
Validation loss: 1.7865842337249427

Epoch: 5| Step: 2
Training loss: 1.0668058395385742
Validation loss: 1.826826125062922

Epoch: 5| Step: 3
Training loss: 0.6850227117538452
Validation loss: 1.842117291624828

Epoch: 5| Step: 4
Training loss: 0.5673187971115112
Validation loss: 1.8825457224281885

Epoch: 5| Step: 5
Training loss: 0.4340008795261383
Validation loss: 1.8369390221052273

Epoch: 5| Step: 6
Training loss: 0.9979999661445618
Validation loss: 1.8545884432331208

Epoch: 5| Step: 7
Training loss: 0.9814106225967407
Validation loss: 1.7825608830298147

Epoch: 5| Step: 8
Training loss: 0.6760721206665039
Validation loss: 1.865245621691468

Epoch: 5| Step: 9
Training loss: 0.8587826490402222
Validation loss: 1.8584909208359257

Epoch: 5| Step: 10
Training loss: 0.5198866724967957
Validation loss: 1.827985708431531

Epoch: 603| Step: 0
Training loss: 0.5440820455551147
Validation loss: 1.758008587744928

Epoch: 5| Step: 1
Training loss: 0.5099612474441528
Validation loss: 1.867024508855676

Epoch: 5| Step: 2
Training loss: 0.7708436846733093
Validation loss: 1.8532768449475687

Epoch: 5| Step: 3
Training loss: 0.4097166955471039
Validation loss: 1.8325677456394318

Epoch: 5| Step: 4
Training loss: 0.37859153747558594
Validation loss: 1.9144235926289712

Epoch: 5| Step: 5
Training loss: 0.9895088076591492
Validation loss: 1.8587895862517818

Epoch: 5| Step: 6
Training loss: 0.517413854598999
Validation loss: 1.8627972487480409

Epoch: 5| Step: 7
Training loss: 0.7325477600097656
Validation loss: 1.7749258472073464

Epoch: 5| Step: 8
Training loss: 1.1932148933410645
Validation loss: 1.8797579324373634

Epoch: 5| Step: 9
Training loss: 1.1218726634979248
Validation loss: 1.8597367527664348

Epoch: 5| Step: 10
Training loss: 0.7288053631782532
Validation loss: 1.8264919993697957

Epoch: 604| Step: 0
Training loss: 1.1407935619354248
Validation loss: 1.8367043336232503

Epoch: 5| Step: 1
Training loss: 0.7431656718254089
Validation loss: 1.7878139711195422

Epoch: 5| Step: 2
Training loss: 0.7019636034965515
Validation loss: 1.8299815552209013

Epoch: 5| Step: 3
Training loss: 0.664024293422699
Validation loss: 1.8167331782720422

Epoch: 5| Step: 4
Training loss: 1.0977776050567627
Validation loss: 1.8374899894960466

Epoch: 5| Step: 5
Training loss: 0.8716912269592285
Validation loss: 1.8190081439992434

Epoch: 5| Step: 6
Training loss: 0.47629857063293457
Validation loss: 1.8608802262172903

Epoch: 5| Step: 7
Training loss: 0.847307562828064
Validation loss: 1.805582065736094

Epoch: 5| Step: 8
Training loss: 0.6679826974868774
Validation loss: 1.8231973545525664

Epoch: 5| Step: 9
Training loss: 0.3560979962348938
Validation loss: 1.8240857457601896

Epoch: 5| Step: 10
Training loss: 0.6450680494308472
Validation loss: 1.8343127094289309

Epoch: 605| Step: 0
Training loss: 0.7264437675476074
Validation loss: 1.818750951879768

Epoch: 5| Step: 1
Training loss: 0.8489872217178345
Validation loss: 1.7865641950279154

Epoch: 5| Step: 2
Training loss: 0.6818801164627075
Validation loss: 1.8934983168878863

Epoch: 5| Step: 3
Training loss: 1.1034170389175415
Validation loss: 1.837162022949547

Epoch: 5| Step: 4
Training loss: 0.48920226097106934
Validation loss: 1.858703297953452

Epoch: 5| Step: 5
Training loss: 0.7993067502975464
Validation loss: 1.8019498368745208

Epoch: 5| Step: 6
Training loss: 0.5612524151802063
Validation loss: 1.8010401366859354

Epoch: 5| Step: 7
Training loss: 0.7373403310775757
Validation loss: 1.8466383769947996

Epoch: 5| Step: 8
Training loss: 0.9449906349182129
Validation loss: 1.7962994472954863

Epoch: 5| Step: 9
Training loss: 0.731616199016571
Validation loss: 1.8057710342509772

Epoch: 5| Step: 10
Training loss: 0.6300203204154968
Validation loss: 1.8899700064812937

Epoch: 606| Step: 0
Training loss: 0.8129515647888184
Validation loss: 1.8594876527786255

Epoch: 5| Step: 1
Training loss: 0.5617715120315552
Validation loss: 1.8885283495790215

Epoch: 5| Step: 2
Training loss: 0.5932765007019043
Validation loss: 1.841790235170754

Epoch: 5| Step: 3
Training loss: 1.0859724283218384
Validation loss: 1.8537950656747306

Epoch: 5| Step: 4
Training loss: 0.8233400583267212
Validation loss: 1.862876799798781

Epoch: 5| Step: 5
Training loss: 1.030876874923706
Validation loss: 1.8363339490787958

Epoch: 5| Step: 6
Training loss: 0.6997276544570923
Validation loss: 1.842702140090286

Epoch: 5| Step: 7
Training loss: 0.849047064781189
Validation loss: 1.8272661701325448

Epoch: 5| Step: 8
Training loss: 0.8001880645751953
Validation loss: 1.8989327056433565

Epoch: 5| Step: 9
Training loss: 0.35451000928878784
Validation loss: 1.827913438120196

Epoch: 5| Step: 10
Training loss: 0.7402859330177307
Validation loss: 1.8137108497722174

Epoch: 607| Step: 0
Training loss: 0.9996795654296875
Validation loss: 1.8177023369778869

Epoch: 5| Step: 1
Training loss: 0.5039151310920715
Validation loss: 1.8530328043045536

Epoch: 5| Step: 2
Training loss: 0.9047614932060242
Validation loss: 1.8760764393755185

Epoch: 5| Step: 3
Training loss: 0.6703847646713257
Validation loss: 1.8463658004678705

Epoch: 5| Step: 4
Training loss: 0.5580555200576782
Validation loss: 1.8601327250080724

Epoch: 5| Step: 5
Training loss: 0.5750869512557983
Validation loss: 1.8845525415994788

Epoch: 5| Step: 6
Training loss: 0.6523616909980774
Validation loss: 1.8809064460057083

Epoch: 5| Step: 7
Training loss: 0.6811652183532715
Validation loss: 1.9023186070944673

Epoch: 5| Step: 8
Training loss: 0.8104498982429504
Validation loss: 1.8023244321987193

Epoch: 5| Step: 9
Training loss: 0.8509057760238647
Validation loss: 1.8570283702624741

Epoch: 5| Step: 10
Training loss: 0.8739697337150574
Validation loss: 1.8056082007705525

Epoch: 608| Step: 0
Training loss: 1.3504749536514282
Validation loss: 1.8701369159965104

Epoch: 5| Step: 1
Training loss: 0.552524745464325
Validation loss: 1.807395911985828

Epoch: 5| Step: 2
Training loss: 0.3068743646144867
Validation loss: 1.8627504994792323

Epoch: 5| Step: 3
Training loss: 0.8076569437980652
Validation loss: 1.8511512715329406

Epoch: 5| Step: 4
Training loss: 0.935773491859436
Validation loss: 1.8388725019270373

Epoch: 5| Step: 5
Training loss: 0.687107503414154
Validation loss: 1.8501610781556816

Epoch: 5| Step: 6
Training loss: 0.5230103135108948
Validation loss: 1.8074002996567757

Epoch: 5| Step: 7
Training loss: 0.5906189680099487
Validation loss: 1.8225654645632672

Epoch: 5| Step: 8
Training loss: 1.0652700662612915
Validation loss: 1.8539543408219532

Epoch: 5| Step: 9
Training loss: 0.6980432271957397
Validation loss: 1.8736965630644111

Epoch: 5| Step: 10
Training loss: 0.5008260011672974
Validation loss: 1.8275264809208531

Epoch: 609| Step: 0
Training loss: 0.4853766858577728
Validation loss: 1.8080962152891262

Epoch: 5| Step: 1
Training loss: 0.5805267095565796
Validation loss: 1.8707570311843709

Epoch: 5| Step: 2
Training loss: 0.6113563776016235
Validation loss: 1.8303949903416377

Epoch: 5| Step: 3
Training loss: 0.8097478747367859
Validation loss: 1.8546240957834388

Epoch: 5| Step: 4
Training loss: 1.3268115520477295
Validation loss: 1.8644821874557003

Epoch: 5| Step: 5
Training loss: 0.6930481195449829
Validation loss: 1.8837827790168025

Epoch: 5| Step: 6
Training loss: 0.737167477607727
Validation loss: 1.872296764004615

Epoch: 5| Step: 7
Training loss: 0.9517335891723633
Validation loss: 1.8918779902560736

Epoch: 5| Step: 8
Training loss: 0.4674151539802551
Validation loss: 1.8294419011762064

Epoch: 5| Step: 9
Training loss: 0.8148899078369141
Validation loss: 1.8427572968185588

Epoch: 5| Step: 10
Training loss: 0.6467280983924866
Validation loss: 1.8336240424904773

Epoch: 610| Step: 0
Training loss: 0.5096086263656616
Validation loss: 1.789333652424556

Epoch: 5| Step: 1
Training loss: 0.7991968989372253
Validation loss: 1.875333309173584

Epoch: 5| Step: 2
Training loss: 0.910272479057312
Validation loss: 1.812098228803245

Epoch: 5| Step: 3
Training loss: 0.9957681894302368
Validation loss: 1.7634782060500114

Epoch: 5| Step: 4
Training loss: 0.8023951649665833
Validation loss: 1.839848005643455

Epoch: 5| Step: 5
Training loss: 0.4996660649776459
Validation loss: 1.843220700499832

Epoch: 5| Step: 6
Training loss: 0.8694947957992554
Validation loss: 1.8762241896762644

Epoch: 5| Step: 7
Training loss: 0.8374126553535461
Validation loss: 1.8559950231223978

Epoch: 5| Step: 8
Training loss: 0.38624948263168335
Validation loss: 1.860936910875382

Epoch: 5| Step: 9
Training loss: 0.8353655934333801
Validation loss: 1.9223867847073464

Epoch: 5| Step: 10
Training loss: 0.6014781594276428
Validation loss: 1.8845684951351536

Epoch: 611| Step: 0
Training loss: 0.778619647026062
Validation loss: 1.8990829221663936

Epoch: 5| Step: 1
Training loss: 0.8113611340522766
Validation loss: 1.8652062826259161

Epoch: 5| Step: 2
Training loss: 0.8244048357009888
Validation loss: 1.8846319221681165

Epoch: 5| Step: 3
Training loss: 0.7719392776489258
Validation loss: 1.8507625467033797

Epoch: 5| Step: 4
Training loss: 0.7564347982406616
Validation loss: 1.829624588771533

Epoch: 5| Step: 5
Training loss: 0.8682657480239868
Validation loss: 1.8327845232461089

Epoch: 5| Step: 6
Training loss: 0.7133063077926636
Validation loss: 1.7800346266838811

Epoch: 5| Step: 7
Training loss: 0.8718050718307495
Validation loss: 1.8009766968347694

Epoch: 5| Step: 8
Training loss: 0.7750476598739624
Validation loss: 1.8309557412260322

Epoch: 5| Step: 9
Training loss: 0.6949094533920288
Validation loss: 1.8406094056303783

Epoch: 5| Step: 10
Training loss: 0.6051819920539856
Validation loss: 1.86013110222355

Epoch: 612| Step: 0
Training loss: 0.7039921879768372
Validation loss: 1.8257948442171978

Epoch: 5| Step: 1
Training loss: 1.0990574359893799
Validation loss: 1.826151927312215

Epoch: 5| Step: 2
Training loss: 0.74596107006073
Validation loss: 1.8004056958742038

Epoch: 5| Step: 3
Training loss: 0.4791410565376282
Validation loss: 1.863016741250151

Epoch: 5| Step: 4
Training loss: 0.5073224902153015
Validation loss: 1.8471817355002127

Epoch: 5| Step: 5
Training loss: 0.42217302322387695
Validation loss: 1.8853983417634042

Epoch: 5| Step: 6
Training loss: 0.6227728128433228
Validation loss: 1.9091853582730858

Epoch: 5| Step: 7
Training loss: 1.4627516269683838
Validation loss: 1.8058331192180674

Epoch: 5| Step: 8
Training loss: 0.8741510510444641
Validation loss: 1.830093147934124

Epoch: 5| Step: 9
Training loss: 0.9286959767341614
Validation loss: 1.8775855982175438

Epoch: 5| Step: 10
Training loss: 0.39737844467163086
Validation loss: 1.8708849260883946

Epoch: 613| Step: 0
Training loss: 0.6422533392906189
Validation loss: 1.7969033423290457

Epoch: 5| Step: 1
Training loss: 0.620786190032959
Validation loss: 1.8552175439814085

Epoch: 5| Step: 2
Training loss: 0.7845431566238403
Validation loss: 1.865340446913114

Epoch: 5| Step: 3
Training loss: 1.074968695640564
Validation loss: 1.7994146705955587

Epoch: 5| Step: 4
Training loss: 0.6679521799087524
Validation loss: 1.8584297523703626

Epoch: 5| Step: 5
Training loss: 0.9339922666549683
Validation loss: 1.8807294778926398

Epoch: 5| Step: 6
Training loss: 0.8864544034004211
Validation loss: 1.8746788091557

Epoch: 5| Step: 7
Training loss: 0.6467286348342896
Validation loss: 1.8498323130351242

Epoch: 5| Step: 8
Training loss: 0.6056089401245117
Validation loss: 1.866300094512201

Epoch: 5| Step: 9
Training loss: 0.7304945588111877
Validation loss: 1.8487350761249501

Epoch: 5| Step: 10
Training loss: 0.7359488010406494
Validation loss: 1.8284691303007063

Epoch: 614| Step: 0
Training loss: 0.6200730204582214
Validation loss: 1.8676388558521066

Epoch: 5| Step: 1
Training loss: 1.3815042972564697
Validation loss: 1.8142094868485645

Epoch: 5| Step: 2
Training loss: 0.5868058800697327
Validation loss: 1.8343003065355363

Epoch: 5| Step: 3
Training loss: 0.5447184443473816
Validation loss: 1.848449763431344

Epoch: 5| Step: 4
Training loss: 0.5609335899353027
Validation loss: 1.8541764469556912

Epoch: 5| Step: 5
Training loss: 0.7012676000595093
Validation loss: 1.8091212511062622

Epoch: 5| Step: 6
Training loss: 0.8274242281913757
Validation loss: 1.8823667956936745

Epoch: 5| Step: 7
Training loss: 0.7563850283622742
Validation loss: 1.806462368657512

Epoch: 5| Step: 8
Training loss: 0.5699938535690308
Validation loss: 1.7680860693736742

Epoch: 5| Step: 9
Training loss: 0.7299233675003052
Validation loss: 1.8369067010059152

Epoch: 5| Step: 10
Training loss: 0.7779479622840881
Validation loss: 1.8725447782906153

Epoch: 615| Step: 0
Training loss: 0.6430142521858215
Validation loss: 1.8262324435736543

Epoch: 5| Step: 1
Training loss: 0.8384252786636353
Validation loss: 1.8247701609006493

Epoch: 5| Step: 2
Training loss: 0.605050265789032
Validation loss: 1.8516198704319615

Epoch: 5| Step: 3
Training loss: 1.0031797885894775
Validation loss: 1.7737036212798087

Epoch: 5| Step: 4
Training loss: 0.8174670338630676
Validation loss: 1.8379336813444733

Epoch: 5| Step: 5
Training loss: 0.8723047971725464
Validation loss: 1.7930845611838884

Epoch: 5| Step: 6
Training loss: 0.45328015089035034
Validation loss: 1.7852147766338882

Epoch: 5| Step: 7
Training loss: 0.6296619176864624
Validation loss: 1.7957732626186904

Epoch: 5| Step: 8
Training loss: 0.5525704622268677
Validation loss: 1.7949273188908894

Epoch: 5| Step: 9
Training loss: 0.5045853853225708
Validation loss: 1.8427705187951364

Epoch: 5| Step: 10
Training loss: 1.1301912069320679
Validation loss: 1.8231037496238627

Epoch: 616| Step: 0
Training loss: 0.6131870150566101
Validation loss: 1.8034110556366623

Epoch: 5| Step: 1
Training loss: 0.46286988258361816
Validation loss: 1.798302169769041

Epoch: 5| Step: 2
Training loss: 1.1231354475021362
Validation loss: 1.7962638088451919

Epoch: 5| Step: 3
Training loss: 0.668021023273468
Validation loss: 1.8135498544221282

Epoch: 5| Step: 4
Training loss: 0.8431569337844849
Validation loss: 1.7880259983001217

Epoch: 5| Step: 5
Training loss: 0.9365175366401672
Validation loss: 1.8226935081584479

Epoch: 5| Step: 6
Training loss: 0.7903584837913513
Validation loss: 1.8123465635443246

Epoch: 5| Step: 7
Training loss: 0.6040369868278503
Validation loss: 1.8260173925789454

Epoch: 5| Step: 8
Training loss: 0.9042778015136719
Validation loss: 1.8485529486851027

Epoch: 5| Step: 9
Training loss: 0.8240021467208862
Validation loss: 1.8487426234829811

Epoch: 5| Step: 10
Training loss: 0.43857669830322266
Validation loss: 1.784058641361934

Epoch: 617| Step: 0
Training loss: 1.0671923160552979
Validation loss: 1.8398088460327477

Epoch: 5| Step: 1
Training loss: 1.1332519054412842
Validation loss: 1.8753830796928816

Epoch: 5| Step: 2
Training loss: 0.5940748453140259
Validation loss: 1.814771024129724

Epoch: 5| Step: 3
Training loss: 0.47969919443130493
Validation loss: 1.810956960083336

Epoch: 5| Step: 4
Training loss: 0.6402893662452698
Validation loss: 1.856444029397862

Epoch: 5| Step: 5
Training loss: 0.7532825469970703
Validation loss: 1.813755742965206

Epoch: 5| Step: 6
Training loss: 0.64650958776474
Validation loss: 1.8199357832631757

Epoch: 5| Step: 7
Training loss: 0.73432457447052
Validation loss: 1.8483900857228104

Epoch: 5| Step: 8
Training loss: 1.060995101928711
Validation loss: 1.8297335883622527

Epoch: 5| Step: 9
Training loss: 0.7031769156455994
Validation loss: 1.8293140575449953

Epoch: 5| Step: 10
Training loss: 0.42207568883895874
Validation loss: 1.8558219248248684

Epoch: 618| Step: 0
Training loss: 0.8796857595443726
Validation loss: 1.8744055981277137

Epoch: 5| Step: 1
Training loss: 0.8546706438064575
Validation loss: 1.9024968006277596

Epoch: 5| Step: 2
Training loss: 0.9025861620903015
Validation loss: 1.8452104112153411

Epoch: 5| Step: 3
Training loss: 0.8953602910041809
Validation loss: 1.864803082199507

Epoch: 5| Step: 4
Training loss: 0.6481372714042664
Validation loss: 1.841809416329989

Epoch: 5| Step: 5
Training loss: 0.7072453498840332
Validation loss: 1.8588364752390052

Epoch: 5| Step: 6
Training loss: 0.6466120481491089
Validation loss: 1.7818999572466778

Epoch: 5| Step: 7
Training loss: 0.5447850227355957
Validation loss: 1.793121031535569

Epoch: 5| Step: 8
Training loss: 0.631501317024231
Validation loss: 1.809424957921428

Epoch: 5| Step: 9
Training loss: 0.8046125173568726
Validation loss: 1.8410663502190703

Epoch: 5| Step: 10
Training loss: 0.7739564776420593
Validation loss: 1.8247397176681026

Epoch: 619| Step: 0
Training loss: 0.8076608777046204
Validation loss: 1.8494054809693368

Epoch: 5| Step: 1
Training loss: 0.5238715410232544
Validation loss: 1.8486697673797607

Epoch: 5| Step: 2
Training loss: 0.8897914886474609
Validation loss: 1.8209667128901328

Epoch: 5| Step: 3
Training loss: 0.5608428716659546
Validation loss: 1.8442322361853816

Epoch: 5| Step: 4
Training loss: 0.39261043071746826
Validation loss: 1.8175992196606052

Epoch: 5| Step: 5
Training loss: 0.5059645175933838
Validation loss: 1.8709427823302567

Epoch: 5| Step: 6
Training loss: 0.6636060476303101
Validation loss: 1.80862166548288

Epoch: 5| Step: 7
Training loss: 0.6934856176376343
Validation loss: 1.840540788506949

Epoch: 5| Step: 8
Training loss: 0.7995340824127197
Validation loss: 1.8679954428826608

Epoch: 5| Step: 9
Training loss: 0.993604838848114
Validation loss: 1.858896114492929

Epoch: 5| Step: 10
Training loss: 0.99517822265625
Validation loss: 1.8984310755165674

Epoch: 620| Step: 0
Training loss: 0.6767528653144836
Validation loss: 1.864441083323571

Epoch: 5| Step: 1
Training loss: 0.7687433958053589
Validation loss: 1.9059053659439087

Epoch: 5| Step: 2
Training loss: 1.0515079498291016
Validation loss: 1.9163179115582538

Epoch: 5| Step: 3
Training loss: 1.2249304056167603
Validation loss: 1.8804012498547953

Epoch: 5| Step: 4
Training loss: 0.8235862851142883
Validation loss: 1.8565426552167503

Epoch: 5| Step: 5
Training loss: 0.4815497398376465
Validation loss: 1.8541634134067002

Epoch: 5| Step: 6
Training loss: 0.765964150428772
Validation loss: 1.8506376153679305

Epoch: 5| Step: 7
Training loss: 0.7139219045639038
Validation loss: 1.829063541145735

Epoch: 5| Step: 8
Training loss: 0.5486536622047424
Validation loss: 1.8084770787146784

Epoch: 5| Step: 9
Training loss: 0.6812689900398254
Validation loss: 1.8381542005846578

Epoch: 5| Step: 10
Training loss: 0.45593762397766113
Validation loss: 1.8446062021358038

Epoch: 621| Step: 0
Training loss: 0.6600720286369324
Validation loss: 1.8517815682195848

Epoch: 5| Step: 1
Training loss: 0.7485129833221436
Validation loss: 1.7891628216671687

Epoch: 5| Step: 2
Training loss: 0.8813115358352661
Validation loss: 1.8358023448656964

Epoch: 5| Step: 3
Training loss: 0.8585063219070435
Validation loss: 1.8600279490152996

Epoch: 5| Step: 4
Training loss: 0.7410389184951782
Validation loss: 1.8686674256478586

Epoch: 5| Step: 5
Training loss: 0.9809182286262512
Validation loss: 1.7962947635240452

Epoch: 5| Step: 6
Training loss: 0.7657252550125122
Validation loss: 1.7723895888174734

Epoch: 5| Step: 7
Training loss: 0.7928875088691711
Validation loss: 1.8437321019429032

Epoch: 5| Step: 8
Training loss: 0.6421924829483032
Validation loss: 1.8635443846384685

Epoch: 5| Step: 9
Training loss: 0.9342571496963501
Validation loss: 1.8473448343174432

Epoch: 5| Step: 10
Training loss: 0.40442827343940735
Validation loss: 1.8503231207529705

Epoch: 622| Step: 0
Training loss: 0.9173644185066223
Validation loss: 1.8516770114180863

Epoch: 5| Step: 1
Training loss: 1.0777003765106201
Validation loss: 1.870359654067665

Epoch: 5| Step: 2
Training loss: 0.5062276721000671
Validation loss: 1.8118029563657698

Epoch: 5| Step: 3
Training loss: 0.949830174446106
Validation loss: 1.8487325124843146

Epoch: 5| Step: 4
Training loss: 0.6185988187789917
Validation loss: 1.8373259434136011

Epoch: 5| Step: 5
Training loss: 0.7814429998397827
Validation loss: 1.8404780177659885

Epoch: 5| Step: 6
Training loss: 0.6417284607887268
Validation loss: 1.8091294380926317

Epoch: 5| Step: 7
Training loss: 0.7520386576652527
Validation loss: 1.844382850072717

Epoch: 5| Step: 8
Training loss: 0.6959575414657593
Validation loss: 1.8056762756839875

Epoch: 5| Step: 9
Training loss: 0.4627595841884613
Validation loss: 1.8751093905459169

Epoch: 5| Step: 10
Training loss: 0.6436639428138733
Validation loss: 1.8327874022145425

Epoch: 623| Step: 0
Training loss: 0.7135744690895081
Validation loss: 1.8643385723072996

Epoch: 5| Step: 1
Training loss: 0.8530352711677551
Validation loss: 1.8727863386113157

Epoch: 5| Step: 2
Training loss: 0.5001153945922852
Validation loss: 1.8598118238551642

Epoch: 5| Step: 3
Training loss: 0.8200975656509399
Validation loss: 1.8926974932352703

Epoch: 5| Step: 4
Training loss: 0.4247317910194397
Validation loss: 1.867874127562328

Epoch: 5| Step: 5
Training loss: 0.8267456293106079
Validation loss: 1.9162311271954608

Epoch: 5| Step: 6
Training loss: 0.5499461889266968
Validation loss: 1.865284078864641

Epoch: 5| Step: 7
Training loss: 0.9250112771987915
Validation loss: 1.8647438005734516

Epoch: 5| Step: 8
Training loss: 0.7618716359138489
Validation loss: 1.8063631852467854

Epoch: 5| Step: 9
Training loss: 0.9453083276748657
Validation loss: 1.834104609745805

Epoch: 5| Step: 10
Training loss: 0.4944177567958832
Validation loss: 1.8269980825403684

Epoch: 624| Step: 0
Training loss: 0.5083540081977844
Validation loss: 1.8505457652512418

Epoch: 5| Step: 1
Training loss: 0.5887880325317383
Validation loss: 1.8329063846218971

Epoch: 5| Step: 2
Training loss: 0.7805396318435669
Validation loss: 1.8614651682556316

Epoch: 5| Step: 3
Training loss: 0.7174090147018433
Validation loss: 1.7679836903848956

Epoch: 5| Step: 4
Training loss: 0.8782089352607727
Validation loss: 1.7735866808122205

Epoch: 5| Step: 5
Training loss: 0.9137682914733887
Validation loss: 1.8345447637701546

Epoch: 5| Step: 6
Training loss: 0.569295346736908
Validation loss: 1.7950473934091546

Epoch: 5| Step: 7
Training loss: 0.4511624276638031
Validation loss: 1.8353070776949647

Epoch: 5| Step: 8
Training loss: 0.5428158044815063
Validation loss: 1.8463175104510399

Epoch: 5| Step: 9
Training loss: 0.9437402486801147
Validation loss: 1.8725702493421492

Epoch: 5| Step: 10
Training loss: 0.8005233407020569
Validation loss: 1.8477190656046714

Epoch: 625| Step: 0
Training loss: 0.37177103757858276
Validation loss: 1.8683482575160202

Epoch: 5| Step: 1
Training loss: 0.7450214624404907
Validation loss: 1.9028440316518147

Epoch: 5| Step: 2
Training loss: 0.928708553314209
Validation loss: 1.8898655855527489

Epoch: 5| Step: 3
Training loss: 0.6472898721694946
Validation loss: 1.8455774220087195

Epoch: 5| Step: 4
Training loss: 0.6730364561080933
Validation loss: 1.873099124559792

Epoch: 5| Step: 5
Training loss: 0.9181293249130249
Validation loss: 1.8183640895351287

Epoch: 5| Step: 6
Training loss: 0.8170942068099976
Validation loss: 1.87229888157178

Epoch: 5| Step: 7
Training loss: 0.5514189004898071
Validation loss: 1.7567340289392779

Epoch: 5| Step: 8
Training loss: 0.526161789894104
Validation loss: 1.8437842502388904

Epoch: 5| Step: 9
Training loss: 0.6621278524398804
Validation loss: 1.7313542045572752

Epoch: 5| Step: 10
Training loss: 1.0769602060317993
Validation loss: 1.8608375826189596

Epoch: 626| Step: 0
Training loss: 0.5629170536994934
Validation loss: 1.8467998504638672

Epoch: 5| Step: 1
Training loss: 1.272497296333313
Validation loss: 1.82959500692224

Epoch: 5| Step: 2
Training loss: 0.687748908996582
Validation loss: 1.8519639340780114

Epoch: 5| Step: 3
Training loss: 0.5836635828018188
Validation loss: 1.8594370939398324

Epoch: 5| Step: 4
Training loss: 0.6844351887702942
Validation loss: 1.8370873030795847

Epoch: 5| Step: 5
Training loss: 0.5568543076515198
Validation loss: 1.796093084478891

Epoch: 5| Step: 6
Training loss: 0.874964714050293
Validation loss: 1.8415006078699583

Epoch: 5| Step: 7
Training loss: 0.5406277775764465
Validation loss: 1.8377382806552354

Epoch: 5| Step: 8
Training loss: 0.6428033113479614
Validation loss: 1.885407409360332

Epoch: 5| Step: 9
Training loss: 0.7221553921699524
Validation loss: 1.859221730180966

Epoch: 5| Step: 10
Training loss: 0.6596900224685669
Validation loss: 1.8504853197323379

Epoch: 627| Step: 0
Training loss: 0.9476634860038757
Validation loss: 1.7894893884658813

Epoch: 5| Step: 1
Training loss: 0.5247310400009155
Validation loss: 1.8177778361946024

Epoch: 5| Step: 2
Training loss: 0.6850934028625488
Validation loss: 1.8019754553353915

Epoch: 5| Step: 3
Training loss: 0.7610664367675781
Validation loss: 1.8552829642449655

Epoch: 5| Step: 4
Training loss: 0.7450467348098755
Validation loss: 1.874202965408243

Epoch: 5| Step: 5
Training loss: 0.9113309979438782
Validation loss: 1.8245035550927604

Epoch: 5| Step: 6
Training loss: 0.4566527009010315
Validation loss: 1.9242180009042062

Epoch: 5| Step: 7
Training loss: 0.5817683935165405
Validation loss: 1.886360950367425

Epoch: 5| Step: 8
Training loss: 0.5275362133979797
Validation loss: 1.8853661898643739

Epoch: 5| Step: 9
Training loss: 0.9634467959403992
Validation loss: 1.8884158083187637

Epoch: 5| Step: 10
Training loss: 0.9717802405357361
Validation loss: 1.8881821222202753

Epoch: 628| Step: 0
Training loss: 0.6235933303833008
Validation loss: 1.8033612389718332

Epoch: 5| Step: 1
Training loss: 0.44905346632003784
Validation loss: 1.860950663525571

Epoch: 5| Step: 2
Training loss: 0.6085084080696106
Validation loss: 1.8541150631443146

Epoch: 5| Step: 3
Training loss: 0.9321252107620239
Validation loss: 1.8439543772769231

Epoch: 5| Step: 4
Training loss: 0.5887255072593689
Validation loss: 1.8702689498983405

Epoch: 5| Step: 5
Training loss: 0.8803178668022156
Validation loss: 1.8174389293116908

Epoch: 5| Step: 6
Training loss: 0.7124603390693665
Validation loss: 1.840089771055406

Epoch: 5| Step: 7
Training loss: 0.6608256101608276
Validation loss: 1.8560333944136096

Epoch: 5| Step: 8
Training loss: 0.6801970601081848
Validation loss: 1.8099801207101474

Epoch: 5| Step: 9
Training loss: 0.735145628452301
Validation loss: 1.832647649190759

Epoch: 5| Step: 10
Training loss: 0.9640746116638184
Validation loss: 1.8220941200051257

Epoch: 629| Step: 0
Training loss: 0.553098201751709
Validation loss: 1.8473266863053845

Epoch: 5| Step: 1
Training loss: 0.9464820623397827
Validation loss: 1.838617273556289

Epoch: 5| Step: 2
Training loss: 0.7301854491233826
Validation loss: 1.872508466884654

Epoch: 5| Step: 3
Training loss: 0.6286450624465942
Validation loss: 1.884807050869029

Epoch: 5| Step: 4
Training loss: 0.8879114389419556
Validation loss: 1.861842914294171

Epoch: 5| Step: 5
Training loss: 0.6464147567749023
Validation loss: 1.8573243746193506

Epoch: 5| Step: 6
Training loss: 0.5794402956962585
Validation loss: 1.8206031937753

Epoch: 5| Step: 7
Training loss: 0.458627313375473
Validation loss: 1.806926578603765

Epoch: 5| Step: 8
Training loss: 0.4258948862552643
Validation loss: 1.7987023297176565

Epoch: 5| Step: 9
Training loss: 0.9248809814453125
Validation loss: 1.8513661571728286

Epoch: 5| Step: 10
Training loss: 1.211917757987976
Validation loss: 1.8266037830742456

Epoch: 630| Step: 0
Training loss: 0.8776817321777344
Validation loss: 1.7985812182067542

Epoch: 5| Step: 1
Training loss: 0.825711727142334
Validation loss: 1.781115685739825

Epoch: 5| Step: 2
Training loss: 0.6348006129264832
Validation loss: 1.830087383588155

Epoch: 5| Step: 3
Training loss: 0.9105445742607117
Validation loss: 1.7982184861295967

Epoch: 5| Step: 4
Training loss: 0.7893802523612976
Validation loss: 1.8243828537643596

Epoch: 5| Step: 5
Training loss: 0.4922589361667633
Validation loss: 1.8719923765428605

Epoch: 5| Step: 6
Training loss: 0.5632598996162415
Validation loss: 1.8466485302935365

Epoch: 5| Step: 7
Training loss: 0.40146714448928833
Validation loss: 1.7889214100376252

Epoch: 5| Step: 8
Training loss: 0.7859612107276917
Validation loss: 1.8756797621327062

Epoch: 5| Step: 9
Training loss: 0.33133816719055176
Validation loss: 1.9254454605041011

Epoch: 5| Step: 10
Training loss: 0.9301857948303223
Validation loss: 1.8378917401836765

Epoch: 631| Step: 0
Training loss: 0.9198633432388306
Validation loss: 1.8697639280749905

Epoch: 5| Step: 1
Training loss: 1.128068447113037
Validation loss: 1.8637246842025428

Epoch: 5| Step: 2
Training loss: 0.5393533706665039
Validation loss: 1.8411034935264177

Epoch: 5| Step: 3
Training loss: 0.8070915937423706
Validation loss: 1.8360006975871261

Epoch: 5| Step: 4
Training loss: 0.6574377417564392
Validation loss: 1.8813630573211177

Epoch: 5| Step: 5
Training loss: 0.562339723110199
Validation loss: 1.8273170635264406

Epoch: 5| Step: 6
Training loss: 0.5015497207641602
Validation loss: 1.8104933564380934

Epoch: 5| Step: 7
Training loss: 0.6016810536384583
Validation loss: 1.8253250301525157

Epoch: 5| Step: 8
Training loss: 0.7661696672439575
Validation loss: 1.8590309414812314

Epoch: 5| Step: 9
Training loss: 0.7152915000915527
Validation loss: 1.8838830865839475

Epoch: 5| Step: 10
Training loss: 0.514221727848053
Validation loss: 1.8501385437544955

Epoch: 632| Step: 0
Training loss: 0.7532837986946106
Validation loss: 1.864395841475456

Epoch: 5| Step: 1
Training loss: 0.662655234336853
Validation loss: 1.8473092202217347

Epoch: 5| Step: 2
Training loss: 0.7339941263198853
Validation loss: 1.8272197144005888

Epoch: 5| Step: 3
Training loss: 0.8220188021659851
Validation loss: 1.8067270273803382

Epoch: 5| Step: 4
Training loss: 0.8201168179512024
Validation loss: 1.7519308841356667

Epoch: 5| Step: 5
Training loss: 0.6153900027275085
Validation loss: 1.803987859397806

Epoch: 5| Step: 6
Training loss: 0.8947881460189819
Validation loss: 1.7828951138322071

Epoch: 5| Step: 7
Training loss: 0.38703784346580505
Validation loss: 1.809556882868531

Epoch: 5| Step: 8
Training loss: 0.4673216938972473
Validation loss: 1.835181418285575

Epoch: 5| Step: 9
Training loss: 0.9338599443435669
Validation loss: 1.7931037320885608

Epoch: 5| Step: 10
Training loss: 0.582013726234436
Validation loss: 1.8603708872231104

Epoch: 633| Step: 0
Training loss: 0.984632670879364
Validation loss: 1.8320269392382713

Epoch: 5| Step: 1
Training loss: 0.4329509139060974
Validation loss: 1.8367654751705866

Epoch: 5| Step: 2
Training loss: 0.3872712552547455
Validation loss: 1.8563655358488842

Epoch: 5| Step: 3
Training loss: 0.8306155204772949
Validation loss: 1.7845341236360612

Epoch: 5| Step: 4
Training loss: 0.7448610067367554
Validation loss: 1.8597616495624665

Epoch: 5| Step: 5
Training loss: 0.7260717153549194
Validation loss: 1.8455486477062266

Epoch: 5| Step: 6
Training loss: 0.7712224125862122
Validation loss: 1.8742354736533215

Epoch: 5| Step: 7
Training loss: 0.3884909152984619
Validation loss: 1.8990471670704503

Epoch: 5| Step: 8
Training loss: 0.613411545753479
Validation loss: 1.8303193789656445

Epoch: 5| Step: 9
Training loss: 0.9875384569168091
Validation loss: 1.835393799248562

Epoch: 5| Step: 10
Training loss: 0.6385825872421265
Validation loss: 1.8455218576615857

Epoch: 634| Step: 0
Training loss: 0.8132088780403137
Validation loss: 1.816865078864559

Epoch: 5| Step: 1
Training loss: 0.7825873494148254
Validation loss: 1.8475216409211517

Epoch: 5| Step: 2
Training loss: 0.9277356266975403
Validation loss: 1.8402509163784724

Epoch: 5| Step: 3
Training loss: 0.5365365743637085
Validation loss: 1.8124785525824434

Epoch: 5| Step: 4
Training loss: 1.0500638484954834
Validation loss: 1.8104809766174645

Epoch: 5| Step: 5
Training loss: 0.751190721988678
Validation loss: 1.7882010577827372

Epoch: 5| Step: 6
Training loss: 0.5559920072555542
Validation loss: 1.8234426385612899

Epoch: 5| Step: 7
Training loss: 0.7504457235336304
Validation loss: 1.8391802439125635

Epoch: 5| Step: 8
Training loss: 0.3651418685913086
Validation loss: 1.8504153964340047

Epoch: 5| Step: 9
Training loss: 0.48663854598999023
Validation loss: 1.7831062527113064

Epoch: 5| Step: 10
Training loss: 0.6782971620559692
Validation loss: 1.7997973567696028

Epoch: 635| Step: 0
Training loss: 0.7780207991600037
Validation loss: 1.842501494192308

Epoch: 5| Step: 1
Training loss: 0.6994670033454895
Validation loss: 1.8021620922191168

Epoch: 5| Step: 2
Training loss: 0.7795175313949585
Validation loss: 1.8808643253900672

Epoch: 5| Step: 3
Training loss: 0.9210647344589233
Validation loss: 1.8194213887696624

Epoch: 5| Step: 4
Training loss: 0.6255635023117065
Validation loss: 1.7855617089938092

Epoch: 5| Step: 5
Training loss: 0.5548495054244995
Validation loss: 1.8499666439589633

Epoch: 5| Step: 6
Training loss: 0.4995434284210205
Validation loss: 1.8074438110474618

Epoch: 5| Step: 7
Training loss: 0.9859220385551453
Validation loss: 1.8647160145544237

Epoch: 5| Step: 8
Training loss: 0.5789647698402405
Validation loss: 1.8297633330027263

Epoch: 5| Step: 9
Training loss: 0.8936871290206909
Validation loss: 1.870732525343536

Epoch: 5| Step: 10
Training loss: 0.40942826867103577
Validation loss: 1.8113447748204714

Epoch: 636| Step: 0
Training loss: 1.1630289554595947
Validation loss: 1.857185871370377

Epoch: 5| Step: 1
Training loss: 0.5522128343582153
Validation loss: 1.8336834420440018

Epoch: 5| Step: 2
Training loss: 0.6625017523765564
Validation loss: 1.8453096138533724

Epoch: 5| Step: 3
Training loss: 0.9116001129150391
Validation loss: 1.8382868677057245

Epoch: 5| Step: 4
Training loss: 0.6536316275596619
Validation loss: 1.87191593006093

Epoch: 5| Step: 5
Training loss: 0.8812689781188965
Validation loss: 1.809692944249799

Epoch: 5| Step: 6
Training loss: 0.5760352611541748
Validation loss: 1.8316551613551315

Epoch: 5| Step: 7
Training loss: 0.3870213031768799
Validation loss: 1.871892024112004

Epoch: 5| Step: 8
Training loss: 0.4440010190010071
Validation loss: 1.8576316756586875

Epoch: 5| Step: 9
Training loss: 0.8908535242080688
Validation loss: 1.8640051913517777

Epoch: 5| Step: 10
Training loss: 0.7720369696617126
Validation loss: 1.8495020033210836

Epoch: 637| Step: 0
Training loss: 0.3488427996635437
Validation loss: 1.8244123381953086

Epoch: 5| Step: 1
Training loss: 0.7703887224197388
Validation loss: 1.8235923167197936

Epoch: 5| Step: 2
Training loss: 0.47946423292160034
Validation loss: 1.8391520746292607

Epoch: 5| Step: 3
Training loss: 0.7551993131637573
Validation loss: 1.8284704749302199

Epoch: 5| Step: 4
Training loss: 1.1505794525146484
Validation loss: 1.8840716833709388

Epoch: 5| Step: 5
Training loss: 0.8349899053573608
Validation loss: 1.9178870352365638

Epoch: 5| Step: 6
Training loss: 0.5736139416694641
Validation loss: 1.8997591439113821

Epoch: 5| Step: 7
Training loss: 0.5758342742919922
Validation loss: 1.8836057468127179

Epoch: 5| Step: 8
Training loss: 0.811481773853302
Validation loss: 1.896515388642588

Epoch: 5| Step: 9
Training loss: 0.78848797082901
Validation loss: 1.889764880621305

Epoch: 5| Step: 10
Training loss: 0.5704643130302429
Validation loss: 1.844597146075259

Epoch: 638| Step: 0
Training loss: 0.9561598896980286
Validation loss: 1.862432208112491

Epoch: 5| Step: 1
Training loss: 0.6365450620651245
Validation loss: 1.7814230252337713

Epoch: 5| Step: 2
Training loss: 0.3623742163181305
Validation loss: 1.8195795025876773

Epoch: 5| Step: 3
Training loss: 0.9710519909858704
Validation loss: 1.8616011335003761

Epoch: 5| Step: 4
Training loss: 0.54180508852005
Validation loss: 1.8661436188605525

Epoch: 5| Step: 5
Training loss: 0.7414544820785522
Validation loss: 1.8346050682888235

Epoch: 5| Step: 6
Training loss: 0.8090717196464539
Validation loss: 1.8014666418875418

Epoch: 5| Step: 7
Training loss: 0.7836969494819641
Validation loss: 1.8295881338016962

Epoch: 5| Step: 8
Training loss: 0.7686792612075806
Validation loss: 1.8394555673804334

Epoch: 5| Step: 9
Training loss: 0.5674033761024475
Validation loss: 1.8753735198769519

Epoch: 5| Step: 10
Training loss: 0.4153635799884796
Validation loss: 1.8067975685160647

Epoch: 639| Step: 0
Training loss: 0.8390040397644043
Validation loss: 1.8631148030680995

Epoch: 5| Step: 1
Training loss: 0.7679995894432068
Validation loss: 1.8695752851424678

Epoch: 5| Step: 2
Training loss: 0.6475701332092285
Validation loss: 1.872704727675325

Epoch: 5| Step: 3
Training loss: 1.1540663242340088
Validation loss: 1.8746959329933248

Epoch: 5| Step: 4
Training loss: 0.504608690738678
Validation loss: 1.805890194831356

Epoch: 5| Step: 5
Training loss: 0.4574175775051117
Validation loss: 1.8425507327561736

Epoch: 5| Step: 6
Training loss: 0.6228685975074768
Validation loss: 1.852580794724085

Epoch: 5| Step: 7
Training loss: 0.8849998712539673
Validation loss: 1.9460399022666357

Epoch: 5| Step: 8
Training loss: 0.5008903741836548
Validation loss: 1.8465931159193798

Epoch: 5| Step: 9
Training loss: 0.6797433495521545
Validation loss: 1.8504959716591785

Epoch: 5| Step: 10
Training loss: 0.4505678415298462
Validation loss: 1.8819403302284978

Epoch: 640| Step: 0
Training loss: 0.7916127443313599
Validation loss: 1.8484496711402811

Epoch: 5| Step: 1
Training loss: 0.5079105496406555
Validation loss: 1.860751582730201

Epoch: 5| Step: 2
Training loss: 0.6484612226486206
Validation loss: 1.8784767017569592

Epoch: 5| Step: 3
Training loss: 0.5772625207901001
Validation loss: 1.848701879542361

Epoch: 5| Step: 4
Training loss: 0.7343457341194153
Validation loss: 1.8260814259129186

Epoch: 5| Step: 5
Training loss: 0.5866799354553223
Validation loss: 1.8557336099686161

Epoch: 5| Step: 6
Training loss: 0.9938247799873352
Validation loss: 1.829752440093666

Epoch: 5| Step: 7
Training loss: 0.5736724138259888
Validation loss: 1.9196108989818121

Epoch: 5| Step: 8
Training loss: 0.6984677314758301
Validation loss: 1.8395583911608624

Epoch: 5| Step: 9
Training loss: 0.7185460925102234
Validation loss: 1.844855785369873

Epoch: 5| Step: 10
Training loss: 0.820728063583374
Validation loss: 1.849413700001214

Epoch: 641| Step: 0
Training loss: 0.7608051896095276
Validation loss: 1.7773893981851556

Epoch: 5| Step: 1
Training loss: 0.6900497674942017
Validation loss: 1.788897660470778

Epoch: 5| Step: 2
Training loss: 0.6250029802322388
Validation loss: 1.8990928357647312

Epoch: 5| Step: 3
Training loss: 0.9920707941055298
Validation loss: 1.8385311967583113

Epoch: 5| Step: 4
Training loss: 0.7634979486465454
Validation loss: 1.8529835477952035

Epoch: 5| Step: 5
Training loss: 0.7167513966560364
Validation loss: 1.8703427468576739

Epoch: 5| Step: 6
Training loss: 0.8739161491394043
Validation loss: 1.8496673722420969

Epoch: 5| Step: 7
Training loss: 0.6530746817588806
Validation loss: 1.911055249552573

Epoch: 5| Step: 8
Training loss: 0.6340422034263611
Validation loss: 1.8827817029850458

Epoch: 5| Step: 9
Training loss: 0.560154139995575
Validation loss: 1.8506800564386512

Epoch: 5| Step: 10
Training loss: 0.4719807207584381
Validation loss: 1.7947094530187628

Epoch: 642| Step: 0
Training loss: 0.5365616083145142
Validation loss: 1.852769217183513

Epoch: 5| Step: 1
Training loss: 0.5216249227523804
Validation loss: 1.8180713986837735

Epoch: 5| Step: 2
Training loss: 0.9134708642959595
Validation loss: 1.820007481882649

Epoch: 5| Step: 3
Training loss: 0.5203399062156677
Validation loss: 1.8268229346121512

Epoch: 5| Step: 4
Training loss: 0.49175992608070374
Validation loss: 1.8404028556680168

Epoch: 5| Step: 5
Training loss: 0.9544252157211304
Validation loss: 1.8277324374004076

Epoch: 5| Step: 6
Training loss: 0.7212240099906921
Validation loss: 1.8437661419632614

Epoch: 5| Step: 7
Training loss: 0.8646847605705261
Validation loss: 1.8903180553067116

Epoch: 5| Step: 8
Training loss: 0.9377578496932983
Validation loss: 1.909352833224881

Epoch: 5| Step: 9
Training loss: 0.3064620792865753
Validation loss: 1.8476476669311523

Epoch: 5| Step: 10
Training loss: 0.5921249389648438
Validation loss: 1.8868374273341189

Epoch: 643| Step: 0
Training loss: 0.9450849294662476
Validation loss: 1.9039585282725673

Epoch: 5| Step: 1
Training loss: 1.444704532623291
Validation loss: 1.9037057468968053

Epoch: 5| Step: 2
Training loss: 0.7690311670303345
Validation loss: 1.9147749562417307

Epoch: 5| Step: 3
Training loss: 0.8967169523239136
Validation loss: 1.8834421403946415

Epoch: 5| Step: 4
Training loss: 0.6194645762443542
Validation loss: 1.879526145996586

Epoch: 5| Step: 5
Training loss: 0.3780730366706848
Validation loss: 1.8714207885085896

Epoch: 5| Step: 6
Training loss: 0.6753830909729004
Validation loss: 1.8488745279209589

Epoch: 5| Step: 7
Training loss: 0.7818979024887085
Validation loss: 1.8058527579871557

Epoch: 5| Step: 8
Training loss: 0.39990532398223877
Validation loss: 1.8514500484671643

Epoch: 5| Step: 9
Training loss: 0.5665815472602844
Validation loss: 1.7770746036242413

Epoch: 5| Step: 10
Training loss: 0.7643954157829285
Validation loss: 1.8446779058825584

Epoch: 644| Step: 0
Training loss: 0.9623550176620483
Validation loss: 1.7938225461590676

Epoch: 5| Step: 1
Training loss: 0.5938069224357605
Validation loss: 1.816636400838052

Epoch: 5| Step: 2
Training loss: 0.6970445513725281
Validation loss: 1.8478016353422595

Epoch: 5| Step: 3
Training loss: 0.7998841404914856
Validation loss: 1.863113357174781

Epoch: 5| Step: 4
Training loss: 0.7436741590499878
Validation loss: 1.8509367435209212

Epoch: 5| Step: 5
Training loss: 0.554364025592804
Validation loss: 1.8149873428447272

Epoch: 5| Step: 6
Training loss: 0.5545816421508789
Validation loss: 1.945229024015447

Epoch: 5| Step: 7
Training loss: 0.9536698460578918
Validation loss: 1.8543929912710702

Epoch: 5| Step: 8
Training loss: 0.7857030034065247
Validation loss: 1.8399780334964875

Epoch: 5| Step: 9
Training loss: 0.3491664528846741
Validation loss: 1.8354100386301677

Epoch: 5| Step: 10
Training loss: 0.5459222793579102
Validation loss: 1.8300641223948488

Epoch: 645| Step: 0
Training loss: 0.398587703704834
Validation loss: 1.8741691932883313

Epoch: 5| Step: 1
Training loss: 0.6831532716751099
Validation loss: 1.8751844065163725

Epoch: 5| Step: 2
Training loss: 0.684065043926239
Validation loss: 1.8148058524695776

Epoch: 5| Step: 3
Training loss: 0.39299044013023376
Validation loss: 1.8265985212018412

Epoch: 5| Step: 4
Training loss: 0.3928423523902893
Validation loss: 1.8639674263615762

Epoch: 5| Step: 5
Training loss: 1.0738601684570312
Validation loss: 1.8691277145057597

Epoch: 5| Step: 6
Training loss: 0.5611506700515747
Validation loss: 1.8508385996664725

Epoch: 5| Step: 7
Training loss: 0.5963002443313599
Validation loss: 1.8422621450116556

Epoch: 5| Step: 8
Training loss: 1.0383199453353882
Validation loss: 1.7557890081918368

Epoch: 5| Step: 9
Training loss: 0.6861253380775452
Validation loss: 1.787946093466974

Epoch: 5| Step: 10
Training loss: 0.7245445847511292
Validation loss: 1.8027942513906827

Epoch: 646| Step: 0
Training loss: 1.078360915184021
Validation loss: 1.8445730516987462

Epoch: 5| Step: 1
Training loss: 0.49354347586631775
Validation loss: 1.8235140167256838

Epoch: 5| Step: 2
Training loss: 0.44267845153808594
Validation loss: 1.8063019129537767

Epoch: 5| Step: 3
Training loss: 1.051986813545227
Validation loss: 1.8570504585901897

Epoch: 5| Step: 4
Training loss: 0.7292419672012329
Validation loss: 1.8492456277211506

Epoch: 5| Step: 5
Training loss: 0.5022395849227905
Validation loss: 1.8130725814450173

Epoch: 5| Step: 6
Training loss: 0.7808923125267029
Validation loss: 1.8441900232786774

Epoch: 5| Step: 7
Training loss: 0.42178019881248474
Validation loss: 1.84735627840924

Epoch: 5| Step: 8
Training loss: 0.5502620935440063
Validation loss: 1.8753907539511239

Epoch: 5| Step: 9
Training loss: 0.7720085382461548
Validation loss: 1.8666837369242022

Epoch: 5| Step: 10
Training loss: 0.6383309960365295
Validation loss: 1.8708686956795313

Epoch: 647| Step: 0
Training loss: 0.5920414924621582
Validation loss: 1.8703424789572274

Epoch: 5| Step: 1
Training loss: 0.5263282656669617
Validation loss: 1.8748036610182894

Epoch: 5| Step: 2
Training loss: 0.7054793834686279
Validation loss: 1.8248479468848116

Epoch: 5| Step: 3
Training loss: 1.0317108631134033
Validation loss: 1.8453562060991924

Epoch: 5| Step: 4
Training loss: 0.8373376727104187
Validation loss: 1.8721431609122985

Epoch: 5| Step: 5
Training loss: 0.6476826071739197
Validation loss: 1.798920839063583

Epoch: 5| Step: 6
Training loss: 0.49596071243286133
Validation loss: 1.8047503335501558

Epoch: 5| Step: 7
Training loss: 0.7816967964172363
Validation loss: 1.8385597582786315

Epoch: 5| Step: 8
Training loss: 0.3709562420845032
Validation loss: 1.7920957073088615

Epoch: 5| Step: 9
Training loss: 0.8593038320541382
Validation loss: 1.8108229919146466

Epoch: 5| Step: 10
Training loss: 0.8291025757789612
Validation loss: 1.7812678442206433

Epoch: 648| Step: 0
Training loss: 0.7190824747085571
Validation loss: 1.8325195331727304

Epoch: 5| Step: 1
Training loss: 0.40373319387435913
Validation loss: 1.805691070454095

Epoch: 5| Step: 2
Training loss: 1.1090481281280518
Validation loss: 1.8060941388530116

Epoch: 5| Step: 3
Training loss: 0.5723733901977539
Validation loss: 1.8539300490451116

Epoch: 5| Step: 4
Training loss: 0.43941402435302734
Validation loss: 1.8278742733822073

Epoch: 5| Step: 5
Training loss: 0.6357402801513672
Validation loss: 1.8309585163670201

Epoch: 5| Step: 6
Training loss: 0.6357170343399048
Validation loss: 1.8142077999730264

Epoch: 5| Step: 7
Training loss: 0.8789917230606079
Validation loss: 1.8222280804828932

Epoch: 5| Step: 8
Training loss: 0.45306485891342163
Validation loss: 1.8203272998973887

Epoch: 5| Step: 9
Training loss: 0.6677964329719543
Validation loss: 1.8306370332676878

Epoch: 5| Step: 10
Training loss: 0.9559611082077026
Validation loss: 1.8575343752420077

Epoch: 649| Step: 0
Training loss: 0.8199031949043274
Validation loss: 1.7933646120050901

Epoch: 5| Step: 1
Training loss: 0.6044648885726929
Validation loss: 1.8340065684369815

Epoch: 5| Step: 2
Training loss: 0.5836077332496643
Validation loss: 1.8097596783791818

Epoch: 5| Step: 3
Training loss: 0.6658176183700562
Validation loss: 1.8035363189635738

Epoch: 5| Step: 4
Training loss: 0.6994906067848206
Validation loss: 1.8287565874797043

Epoch: 5| Step: 5
Training loss: 0.3695569932460785
Validation loss: 1.7907485577367968

Epoch: 5| Step: 6
Training loss: 1.0888508558273315
Validation loss: 1.894212668941867

Epoch: 5| Step: 7
Training loss: 0.7435784935951233
Validation loss: 1.8137353979131228

Epoch: 5| Step: 8
Training loss: 0.5057535171508789
Validation loss: 1.808043417110238

Epoch: 5| Step: 9
Training loss: 1.0369211435317993
Validation loss: 1.801966687684418

Epoch: 5| Step: 10
Training loss: 0.3858909010887146
Validation loss: 1.7721938625458749

Epoch: 650| Step: 0
Training loss: 0.8674777746200562
Validation loss: 1.7696584873302008

Epoch: 5| Step: 1
Training loss: 0.6170308589935303
Validation loss: 1.828976854201286

Epoch: 5| Step: 2
Training loss: 0.681098222732544
Validation loss: 1.8822652268153366

Epoch: 5| Step: 3
Training loss: 0.39908066391944885
Validation loss: 1.855634771367555

Epoch: 5| Step: 4
Training loss: 0.8266168832778931
Validation loss: 1.8672639311000865

Epoch: 5| Step: 5
Training loss: 0.8312473297119141
Validation loss: 1.8117382936580206

Epoch: 5| Step: 6
Training loss: 0.5448492765426636
Validation loss: 1.8399862794465915

Epoch: 5| Step: 7
Training loss: 1.0579688549041748
Validation loss: 1.8425738426946825

Epoch: 5| Step: 8
Training loss: 0.6129670143127441
Validation loss: 1.7985790416758547

Epoch: 5| Step: 9
Training loss: 0.6500440239906311
Validation loss: 1.8047008270858436

Epoch: 5| Step: 10
Training loss: 0.6652970314025879
Validation loss: 1.8289889212577575

Epoch: 651| Step: 0
Training loss: 0.6323060989379883
Validation loss: 1.7856090376454015

Epoch: 5| Step: 1
Training loss: 0.7979369163513184
Validation loss: 1.806660000995923

Epoch: 5| Step: 2
Training loss: 1.1424347162246704
Validation loss: 1.815958128180555

Epoch: 5| Step: 3
Training loss: 0.7836621999740601
Validation loss: 1.8063344634989256

Epoch: 5| Step: 4
Training loss: 0.5293524861335754
Validation loss: 1.779727981936547

Epoch: 5| Step: 5
Training loss: 0.45713916420936584
Validation loss: 1.813683250898956

Epoch: 5| Step: 6
Training loss: 1.1649649143218994
Validation loss: 1.833342714976239

Epoch: 5| Step: 7
Training loss: 0.4979221820831299
Validation loss: 1.8757649429382817

Epoch: 5| Step: 8
Training loss: 0.6651609539985657
Validation loss: 1.830083958564266

Epoch: 5| Step: 9
Training loss: 0.49712935090065
Validation loss: 1.8457321223392282

Epoch: 5| Step: 10
Training loss: 0.6422873735427856
Validation loss: 1.7876500365554646

Epoch: 652| Step: 0
Training loss: 0.9426344633102417
Validation loss: 1.831712915051368

Epoch: 5| Step: 1
Training loss: 0.8714024424552917
Validation loss: 1.8097912675590926

Epoch: 5| Step: 2
Training loss: 0.614987850189209
Validation loss: 1.8285892509645032

Epoch: 5| Step: 3
Training loss: 0.5962138175964355
Validation loss: 1.8122297281860023

Epoch: 5| Step: 4
Training loss: 0.4696672558784485
Validation loss: 1.833944127123843

Epoch: 5| Step: 5
Training loss: 0.6971062421798706
Validation loss: 1.8303732820736465

Epoch: 5| Step: 6
Training loss: 0.48516350984573364
Validation loss: 1.830696290539157

Epoch: 5| Step: 7
Training loss: 1.0252113342285156
Validation loss: 1.8029528997277702

Epoch: 5| Step: 8
Training loss: 0.6044966578483582
Validation loss: 1.781919607552149

Epoch: 5| Step: 9
Training loss: 0.3800196945667267
Validation loss: 1.8135962986177014

Epoch: 5| Step: 10
Training loss: 0.7454329133033752
Validation loss: 1.8202911730735534

Epoch: 653| Step: 0
Training loss: 0.4560611844062805
Validation loss: 1.8407860238065001

Epoch: 5| Step: 1
Training loss: 0.7737237215042114
Validation loss: 1.8287237639068274

Epoch: 5| Step: 2
Training loss: 0.7475029826164246
Validation loss: 1.864366928736369

Epoch: 5| Step: 3
Training loss: 0.8972816467285156
Validation loss: 1.8502833407412294

Epoch: 5| Step: 4
Training loss: 0.6534717679023743
Validation loss: 1.8295905910512453

Epoch: 5| Step: 5
Training loss: 0.7614057064056396
Validation loss: 1.8600286540164743

Epoch: 5| Step: 6
Training loss: 0.7071515321731567
Validation loss: 1.8391037141123125

Epoch: 5| Step: 7
Training loss: 0.7278220057487488
Validation loss: 1.800665327297744

Epoch: 5| Step: 8
Training loss: 0.43294745683670044
Validation loss: 1.8790039195809314

Epoch: 5| Step: 9
Training loss: 1.0308529138565063
Validation loss: 1.8208504030781407

Epoch: 5| Step: 10
Training loss: 0.5153050422668457
Validation loss: 1.826379527327835

Epoch: 654| Step: 0
Training loss: 0.5637157559394836
Validation loss: 1.7763148559037076

Epoch: 5| Step: 1
Training loss: 0.6768943071365356
Validation loss: 1.8472590561835998

Epoch: 5| Step: 2
Training loss: 0.8049018979072571
Validation loss: 1.858734123168453

Epoch: 5| Step: 3
Training loss: 1.0480420589447021
Validation loss: 1.783857455817602

Epoch: 5| Step: 4
Training loss: 0.8610644340515137
Validation loss: 1.7977950521694717

Epoch: 5| Step: 5
Training loss: 0.7041754722595215
Validation loss: 1.8332532144361926

Epoch: 5| Step: 6
Training loss: 0.6263849139213562
Validation loss: 1.843356877244929

Epoch: 5| Step: 7
Training loss: 0.496797651052475
Validation loss: 1.857058334094222

Epoch: 5| Step: 8
Training loss: 0.7937377691268921
Validation loss: 1.8026067223600162

Epoch: 5| Step: 9
Training loss: 0.4652267396450043
Validation loss: 1.8318266637863652

Epoch: 5| Step: 10
Training loss: 0.5823202729225159
Validation loss: 1.7724740300127255

Epoch: 655| Step: 0
Training loss: 0.4259069561958313
Validation loss: 1.844365689062303

Epoch: 5| Step: 1
Training loss: 0.7552329897880554
Validation loss: 1.8557394640420073

Epoch: 5| Step: 2
Training loss: 0.9867037534713745
Validation loss: 1.813387245260259

Epoch: 5| Step: 3
Training loss: 0.3448547422885895
Validation loss: 1.8817552635746617

Epoch: 5| Step: 4
Training loss: 0.5719735622406006
Validation loss: 1.88169180065073

Epoch: 5| Step: 5
Training loss: 0.7712101936340332
Validation loss: 1.8113979960000643

Epoch: 5| Step: 6
Training loss: 0.5213159918785095
Validation loss: 1.8031038712429743

Epoch: 5| Step: 7
Training loss: 0.8771408200263977
Validation loss: 1.8222809094254688

Epoch: 5| Step: 8
Training loss: 0.4527614712715149
Validation loss: 1.8136263329495665

Epoch: 5| Step: 9
Training loss: 0.9036669731140137
Validation loss: 1.7902706643586517

Epoch: 5| Step: 10
Training loss: 0.6959570050239563
Validation loss: 1.859063979118101

Epoch: 656| Step: 0
Training loss: 0.49614930152893066
Validation loss: 1.81084309598451

Epoch: 5| Step: 1
Training loss: 0.7128341794013977
Validation loss: 1.7965118538948797

Epoch: 5| Step: 2
Training loss: 0.5200705528259277
Validation loss: 1.8059181769688923

Epoch: 5| Step: 3
Training loss: 0.6877129673957825
Validation loss: 1.8138007886948124

Epoch: 5| Step: 4
Training loss: 0.46380701661109924
Validation loss: 1.7673982651002946

Epoch: 5| Step: 5
Training loss: 0.8098772168159485
Validation loss: 1.7873951683762253

Epoch: 5| Step: 6
Training loss: 0.32312050461769104
Validation loss: 1.863410352378763

Epoch: 5| Step: 7
Training loss: 1.0028650760650635
Validation loss: 1.87224071000212

Epoch: 5| Step: 8
Training loss: 0.7402744889259338
Validation loss: 1.8436199208741546

Epoch: 5| Step: 9
Training loss: 0.8626805543899536
Validation loss: 1.7938883996778918

Epoch: 5| Step: 10
Training loss: 0.6870202422142029
Validation loss: 1.871268069872292

Epoch: 657| Step: 0
Training loss: 0.8213095664978027
Validation loss: 1.8727133107441727

Epoch: 5| Step: 1
Training loss: 0.6547811031341553
Validation loss: 1.888042934479252

Epoch: 5| Step: 2
Training loss: 0.43478554487228394
Validation loss: 1.8743478277678132

Epoch: 5| Step: 3
Training loss: 0.9394211769104004
Validation loss: 1.8201340629208473

Epoch: 5| Step: 4
Training loss: 0.879181981086731
Validation loss: 1.8778469716348956

Epoch: 5| Step: 5
Training loss: 0.44920262694358826
Validation loss: 1.8235976542195966

Epoch: 5| Step: 6
Training loss: 0.6781426072120667
Validation loss: 1.7858428314167967

Epoch: 5| Step: 7
Training loss: 0.8585567474365234
Validation loss: 1.8438019931957286

Epoch: 5| Step: 8
Training loss: 0.5385646820068359
Validation loss: 1.814154359602159

Epoch: 5| Step: 9
Training loss: 0.3689756989479065
Validation loss: 1.8309890506088093

Epoch: 5| Step: 10
Training loss: 0.7950125336647034
Validation loss: 1.8273105877701954

Epoch: 658| Step: 0
Training loss: 0.8646230697631836
Validation loss: 1.8055320003981232

Epoch: 5| Step: 1
Training loss: 0.7215364575386047
Validation loss: 1.8154145915021178

Epoch: 5| Step: 2
Training loss: 0.5435464382171631
Validation loss: 1.8652974379959928

Epoch: 5| Step: 3
Training loss: 0.8922325372695923
Validation loss: 1.8754690770179994

Epoch: 5| Step: 4
Training loss: 0.4583023190498352
Validation loss: 1.8665329333274596

Epoch: 5| Step: 5
Training loss: 0.7283867597579956
Validation loss: 1.8676167944426179

Epoch: 5| Step: 6
Training loss: 0.4042171537876129
Validation loss: 1.875276606570008

Epoch: 5| Step: 7
Training loss: 0.5429819822311401
Validation loss: 1.851629977585167

Epoch: 5| Step: 8
Training loss: 0.45624661445617676
Validation loss: 1.8978212033548663

Epoch: 5| Step: 9
Training loss: 0.8608573079109192
Validation loss: 1.7748635533035442

Epoch: 5| Step: 10
Training loss: 1.2910280227661133
Validation loss: 1.8173060545357325

Epoch: 659| Step: 0
Training loss: 0.4070380628108978
Validation loss: 1.8140099977934232

Epoch: 5| Step: 1
Training loss: 0.7184478640556335
Validation loss: 1.807072115200822

Epoch: 5| Step: 2
Training loss: 0.6014172434806824
Validation loss: 1.8087348373987342

Epoch: 5| Step: 3
Training loss: 0.6069707870483398
Validation loss: 1.8095257089984031

Epoch: 5| Step: 4
Training loss: 0.7806289792060852
Validation loss: 1.8209928261336459

Epoch: 5| Step: 5
Training loss: 0.5095809102058411
Validation loss: 1.809312000069567

Epoch: 5| Step: 6
Training loss: 0.6314970254898071
Validation loss: 1.8776948323813818

Epoch: 5| Step: 7
Training loss: 0.7380708456039429
Validation loss: 1.836914913628691

Epoch: 5| Step: 8
Training loss: 0.6332902908325195
Validation loss: 1.837855456977762

Epoch: 5| Step: 9
Training loss: 0.5354877710342407
Validation loss: 1.8437820378170218

Epoch: 5| Step: 10
Training loss: 1.2409955263137817
Validation loss: 1.8437045825425016

Epoch: 660| Step: 0
Training loss: 0.6532434225082397
Validation loss: 1.832251682076403

Epoch: 5| Step: 1
Training loss: 0.8279069662094116
Validation loss: 1.8413753035247966

Epoch: 5| Step: 2
Training loss: 0.7243591547012329
Validation loss: 1.8438966786989601

Epoch: 5| Step: 3
Training loss: 0.48128995299339294
Validation loss: 1.8041580787269018

Epoch: 5| Step: 4
Training loss: 0.5746214389801025
Validation loss: 1.8439787536539056

Epoch: 5| Step: 5
Training loss: 0.5199878811836243
Validation loss: 1.8645861712835168

Epoch: 5| Step: 6
Training loss: 0.8077927827835083
Validation loss: 1.78942653312478

Epoch: 5| Step: 7
Training loss: 0.7150717973709106
Validation loss: 1.8242992688250799

Epoch: 5| Step: 8
Training loss: 0.5544712543487549
Validation loss: 1.8149577238226449

Epoch: 5| Step: 9
Training loss: 0.8648658990859985
Validation loss: 1.8185902654483754

Epoch: 5| Step: 10
Training loss: 0.7806240320205688
Validation loss: 1.8282357133844847

Epoch: 661| Step: 0
Training loss: 0.5654956698417664
Validation loss: 1.865863452675522

Epoch: 5| Step: 1
Training loss: 0.9324710965156555
Validation loss: 1.8761141095110165

Epoch: 5| Step: 2
Training loss: 0.5865834355354309
Validation loss: 1.8158904942133094

Epoch: 5| Step: 3
Training loss: 0.6675997972488403
Validation loss: 1.835966452475517

Epoch: 5| Step: 4
Training loss: 1.083591341972351
Validation loss: 1.7980175659220705

Epoch: 5| Step: 5
Training loss: 1.0853021144866943
Validation loss: 1.767973994696012

Epoch: 5| Step: 6
Training loss: 0.35371944308280945
Validation loss: 1.7888434253713137

Epoch: 5| Step: 7
Training loss: 0.6692705750465393
Validation loss: 1.8119605100283058

Epoch: 5| Step: 8
Training loss: 0.8758362531661987
Validation loss: 1.8204275843917683

Epoch: 5| Step: 9
Training loss: 0.36918139457702637
Validation loss: 1.7948099028679632

Epoch: 5| Step: 10
Training loss: 0.42956212162971497
Validation loss: 1.8251488875317317

Epoch: 662| Step: 0
Training loss: 0.9915056228637695
Validation loss: 1.8397736921105334

Epoch: 5| Step: 1
Training loss: 0.5366140604019165
Validation loss: 1.8170324384525258

Epoch: 5| Step: 2
Training loss: 0.7631610035896301
Validation loss: 1.8370830141088015

Epoch: 5| Step: 3
Training loss: 0.4107210636138916
Validation loss: 1.8611582889351794

Epoch: 5| Step: 4
Training loss: 0.77851802110672
Validation loss: 1.871471833157283

Epoch: 5| Step: 5
Training loss: 0.488788366317749
Validation loss: 1.8076552626907185

Epoch: 5| Step: 6
Training loss: 0.42974764108657837
Validation loss: 1.8617010116577148

Epoch: 5| Step: 7
Training loss: 0.7015978693962097
Validation loss: 1.8127690117846254

Epoch: 5| Step: 8
Training loss: 1.1676366329193115
Validation loss: 1.8377741831605152

Epoch: 5| Step: 9
Training loss: 0.4225361943244934
Validation loss: 1.8408198382264824

Epoch: 5| Step: 10
Training loss: 0.35617682337760925
Validation loss: 1.794263352629959

Epoch: 663| Step: 0
Training loss: 0.5297220945358276
Validation loss: 1.7841651016666042

Epoch: 5| Step: 1
Training loss: 0.5823721885681152
Validation loss: 1.8164054180986138

Epoch: 5| Step: 2
Training loss: 0.8132543563842773
Validation loss: 1.82502608401801

Epoch: 5| Step: 3
Training loss: 0.5441144108772278
Validation loss: 1.8020461041440246

Epoch: 5| Step: 4
Training loss: 0.4742264151573181
Validation loss: 1.7890432752588743

Epoch: 5| Step: 5
Training loss: 0.8266528844833374
Validation loss: 1.7961323645807081

Epoch: 5| Step: 6
Training loss: 0.9431630373001099
Validation loss: 1.7834223188379759

Epoch: 5| Step: 7
Training loss: 0.8313435316085815
Validation loss: 1.8195158614907214

Epoch: 5| Step: 8
Training loss: 0.4333498477935791
Validation loss: 1.8732785037768784

Epoch: 5| Step: 9
Training loss: 0.8868072628974915
Validation loss: 1.8046235448570662

Epoch: 5| Step: 10
Training loss: 0.42154815793037415
Validation loss: 1.8701899948940481

Epoch: 664| Step: 0
Training loss: 0.4807821214199066
Validation loss: 1.8358131839383034

Epoch: 5| Step: 1
Training loss: 0.2749883532524109
Validation loss: 1.8245124509257655

Epoch: 5| Step: 2
Training loss: 0.544760525226593
Validation loss: 1.8581551300582064

Epoch: 5| Step: 3
Training loss: 1.1099050045013428
Validation loss: 1.8048170202521867

Epoch: 5| Step: 4
Training loss: 0.7224243879318237
Validation loss: 1.7843969983439292

Epoch: 5| Step: 5
Training loss: 0.48492270708084106
Validation loss: 1.80494079794935

Epoch: 5| Step: 6
Training loss: 0.7402118444442749
Validation loss: 1.7808561350709649

Epoch: 5| Step: 7
Training loss: 0.7329140901565552
Validation loss: 1.7740738173966766

Epoch: 5| Step: 8
Training loss: 0.7073038816452026
Validation loss: 1.8195846042325419

Epoch: 5| Step: 9
Training loss: 0.5995331406593323
Validation loss: 1.8300913431311165

Epoch: 5| Step: 10
Training loss: 0.6638431549072266
Validation loss: 1.766690670803029

Epoch: 665| Step: 0
Training loss: 0.9312821626663208
Validation loss: 1.8358234038916967

Epoch: 5| Step: 1
Training loss: 0.5502473711967468
Validation loss: 1.8254125041346396

Epoch: 5| Step: 2
Training loss: 0.5344821214675903
Validation loss: 1.8688471342927666

Epoch: 5| Step: 3
Training loss: 0.4818851351737976
Validation loss: 1.8543088205399052

Epoch: 5| Step: 4
Training loss: 0.7090002298355103
Validation loss: 1.813603498602426

Epoch: 5| Step: 5
Training loss: 0.916530430316925
Validation loss: 1.7942747339125602

Epoch: 5| Step: 6
Training loss: 0.8463128805160522
Validation loss: 1.7802470909651888

Epoch: 5| Step: 7
Training loss: 0.6069270372390747
Validation loss: 1.8430309962200861

Epoch: 5| Step: 8
Training loss: 0.346528023481369
Validation loss: 1.848841853039239

Epoch: 5| Step: 9
Training loss: 0.634158730506897
Validation loss: 1.8405104785837152

Epoch: 5| Step: 10
Training loss: 0.7917032241821289
Validation loss: 1.8259148648990098

Epoch: 666| Step: 0
Training loss: 0.8021643757820129
Validation loss: 1.8734391991810133

Epoch: 5| Step: 1
Training loss: 0.994369387626648
Validation loss: 1.8504690277960993

Epoch: 5| Step: 2
Training loss: 0.8132005929946899
Validation loss: 1.8257559550705778

Epoch: 5| Step: 3
Training loss: 0.6717972159385681
Validation loss: 1.830336420766769

Epoch: 5| Step: 4
Training loss: 0.534994900226593
Validation loss: 1.8345663573152275

Epoch: 5| Step: 5
Training loss: 0.7741995453834534
Validation loss: 1.7953873501029065

Epoch: 5| Step: 6
Training loss: 0.3928545117378235
Validation loss: 1.772593234174995

Epoch: 5| Step: 7
Training loss: 0.4895738959312439
Validation loss: 1.8228035408963439

Epoch: 5| Step: 8
Training loss: 0.4434427320957184
Validation loss: 1.7769784337730818

Epoch: 5| Step: 9
Training loss: 0.7687395811080933
Validation loss: 1.777564159003637

Epoch: 5| Step: 10
Training loss: 0.7524495124816895
Validation loss: 1.8256545169379121

Epoch: 667| Step: 0
Training loss: 0.6142501831054688
Validation loss: 1.8377235397215812

Epoch: 5| Step: 1
Training loss: 0.37361210584640503
Validation loss: 1.8265249934247745

Epoch: 5| Step: 2
Training loss: 0.5357562303543091
Validation loss: 1.811532324360263

Epoch: 5| Step: 3
Training loss: 0.5706530213356018
Validation loss: 1.8858207823127828

Epoch: 5| Step: 4
Training loss: 1.3122332096099854
Validation loss: 1.8167847023215344

Epoch: 5| Step: 5
Training loss: 0.5924553275108337
Validation loss: 1.9111670768389137

Epoch: 5| Step: 6
Training loss: 0.5743661522865295
Validation loss: 1.9129042727972871

Epoch: 5| Step: 7
Training loss: 0.9350511431694031
Validation loss: 1.8479325463694911

Epoch: 5| Step: 8
Training loss: 0.6036788821220398
Validation loss: 1.892063727942846

Epoch: 5| Step: 9
Training loss: 0.7727185487747192
Validation loss: 1.867888596750075

Epoch: 5| Step: 10
Training loss: 0.5555601716041565
Validation loss: 1.8195904108785814

Epoch: 668| Step: 0
Training loss: 0.5132686495780945
Validation loss: 1.837433962411778

Epoch: 5| Step: 1
Training loss: 0.8552732467651367
Validation loss: 1.8548044850749354

Epoch: 5| Step: 2
Training loss: 0.45825880765914917
Validation loss: 1.786243406675195

Epoch: 5| Step: 3
Training loss: 0.698431134223938
Validation loss: 1.7634977666280602

Epoch: 5| Step: 4
Training loss: 0.9179899096488953
Validation loss: 1.7948504122354652

Epoch: 5| Step: 5
Training loss: 0.9069385528564453
Validation loss: 1.791713794072469

Epoch: 5| Step: 6
Training loss: 0.5727071166038513
Validation loss: 1.7973572361853816

Epoch: 5| Step: 7
Training loss: 0.3720196783542633
Validation loss: 1.757157387272004

Epoch: 5| Step: 8
Training loss: 0.5281869173049927
Validation loss: 1.83613052932165

Epoch: 5| Step: 9
Training loss: 0.6626707911491394
Validation loss: 1.8421111978510374

Epoch: 5| Step: 10
Training loss: 0.7548482418060303
Validation loss: 1.8256270936740342

Epoch: 669| Step: 0
Training loss: 0.5619416236877441
Validation loss: 1.8073682259487849

Epoch: 5| Step: 1
Training loss: 0.6867247819900513
Validation loss: 1.8043515964220929

Epoch: 5| Step: 2
Training loss: 0.6556985974311829
Validation loss: 1.8355284711366058

Epoch: 5| Step: 3
Training loss: 0.9188175201416016
Validation loss: 1.8299659977677047

Epoch: 5| Step: 4
Training loss: 0.5155125260353088
Validation loss: 1.8640789690838064

Epoch: 5| Step: 5
Training loss: 1.0044469833374023
Validation loss: 1.839100186542798

Epoch: 5| Step: 6
Training loss: 0.3766528069972992
Validation loss: 1.8174843301055252

Epoch: 5| Step: 7
Training loss: 0.576818585395813
Validation loss: 1.769468007549163

Epoch: 5| Step: 8
Training loss: 0.7919327020645142
Validation loss: 1.7926655930857505

Epoch: 5| Step: 9
Training loss: 0.7626051902770996
Validation loss: 1.8614497620572326

Epoch: 5| Step: 10
Training loss: 0.5977379679679871
Validation loss: 1.7785643403248121

Epoch: 670| Step: 0
Training loss: 1.3523222208023071
Validation loss: 1.8158140772132463

Epoch: 5| Step: 1
Training loss: 0.43265923857688904
Validation loss: 1.8133733644280383

Epoch: 5| Step: 2
Training loss: 0.6055639386177063
Validation loss: 1.8569227572410338

Epoch: 5| Step: 3
Training loss: 0.40430957078933716
Validation loss: 1.85053877933051

Epoch: 5| Step: 4
Training loss: 0.6589625477790833
Validation loss: 1.8436946561259608

Epoch: 5| Step: 5
Training loss: 0.562829852104187
Validation loss: 1.8403666660349856

Epoch: 5| Step: 6
Training loss: 0.7151649594306946
Validation loss: 1.856695346934821

Epoch: 5| Step: 7
Training loss: 0.29834529757499695
Validation loss: 1.8231653039173414

Epoch: 5| Step: 8
Training loss: 0.9004822969436646
Validation loss: 1.7873238414846442

Epoch: 5| Step: 9
Training loss: 0.5224837064743042
Validation loss: 1.8026098461561306

Epoch: 5| Step: 10
Training loss: 0.9910880923271179
Validation loss: 1.7661273658916514

Epoch: 671| Step: 0
Training loss: 0.6075869798660278
Validation loss: 1.7972727642264417

Epoch: 5| Step: 1
Training loss: 0.3551550507545471
Validation loss: 1.8117271238757717

Epoch: 5| Step: 2
Training loss: 0.7787206172943115
Validation loss: 1.806998631005646

Epoch: 5| Step: 3
Training loss: 0.6828233003616333
Validation loss: 1.8600159024679532

Epoch: 5| Step: 4
Training loss: 0.6886194944381714
Validation loss: 1.8337838444658505

Epoch: 5| Step: 5
Training loss: 0.6298975348472595
Validation loss: 1.8059078544698737

Epoch: 5| Step: 6
Training loss: 0.3958904445171356
Validation loss: 1.7540064729670042

Epoch: 5| Step: 7
Training loss: 0.6101492643356323
Validation loss: 1.8378309357550837

Epoch: 5| Step: 8
Training loss: 0.8702630996704102
Validation loss: 1.8792098055603683

Epoch: 5| Step: 9
Training loss: 1.1328235864639282
Validation loss: 1.8417558823862383

Epoch: 5| Step: 10
Training loss: 0.3539070785045624
Validation loss: 1.8410953770401657

Epoch: 672| Step: 0
Training loss: 0.6396523714065552
Validation loss: 1.838428790851306

Epoch: 5| Step: 1
Training loss: 0.5108271837234497
Validation loss: 1.8445895999990485

Epoch: 5| Step: 2
Training loss: 0.5076400637626648
Validation loss: 1.8146919883707517

Epoch: 5| Step: 3
Training loss: 0.5040156245231628
Validation loss: 1.8558860389135217

Epoch: 5| Step: 4
Training loss: 0.8579109907150269
Validation loss: 1.8022231350662887

Epoch: 5| Step: 5
Training loss: 0.6063839197158813
Validation loss: 1.8319073415571643

Epoch: 5| Step: 6
Training loss: 1.3507858514785767
Validation loss: 1.8197148576859505

Epoch: 5| Step: 7
Training loss: 0.6098865866661072
Validation loss: 1.872058021124973

Epoch: 5| Step: 8
Training loss: 0.8268296122550964
Validation loss: 1.8080378476009573

Epoch: 5| Step: 9
Training loss: 0.45092353224754333
Validation loss: 1.8279976742241972

Epoch: 5| Step: 10
Training loss: 0.5467946529388428
Validation loss: 1.8539897011172386

Epoch: 673| Step: 0
Training loss: 0.4027736186981201
Validation loss: 1.8195939358844553

Epoch: 5| Step: 1
Training loss: 0.7667929530143738
Validation loss: 1.8468228309385237

Epoch: 5| Step: 2
Training loss: 0.3903714120388031
Validation loss: 1.7862290682331208

Epoch: 5| Step: 3
Training loss: 0.45109444856643677
Validation loss: 1.8236348231633503

Epoch: 5| Step: 4
Training loss: 0.5978739857673645
Validation loss: 1.860089563554333

Epoch: 5| Step: 5
Training loss: 0.9590460658073425
Validation loss: 1.8426842868969004

Epoch: 5| Step: 6
Training loss: 0.4557395577430725
Validation loss: 1.8722132893018826

Epoch: 5| Step: 7
Training loss: 0.35790103673934937
Validation loss: 1.848923449875206

Epoch: 5| Step: 8
Training loss: 0.5840538740158081
Validation loss: 1.849862608858334

Epoch: 5| Step: 9
Training loss: 0.7356988191604614
Validation loss: 1.8722820064072967

Epoch: 5| Step: 10
Training loss: 1.2324340343475342
Validation loss: 1.889910065999595

Epoch: 674| Step: 0
Training loss: 0.819238543510437
Validation loss: 1.843905225876839

Epoch: 5| Step: 1
Training loss: 0.6817771792411804
Validation loss: 1.7938210605293192

Epoch: 5| Step: 2
Training loss: 0.8043749928474426
Validation loss: 1.8345701233033211

Epoch: 5| Step: 3
Training loss: 0.9039802551269531
Validation loss: 1.8565771887379308

Epoch: 5| Step: 4
Training loss: 0.33760252594947815
Validation loss: 1.8561610278262888

Epoch: 5| Step: 5
Training loss: 0.5287696123123169
Validation loss: 1.8202914576376639

Epoch: 5| Step: 6
Training loss: 0.5339689254760742
Validation loss: 1.8615331162688553

Epoch: 5| Step: 7
Training loss: 0.7034104466438293
Validation loss: 1.807366213490886

Epoch: 5| Step: 8
Training loss: 0.5501008033752441
Validation loss: 1.8670309256481867

Epoch: 5| Step: 9
Training loss: 0.5021176934242249
Validation loss: 1.848340649758616

Epoch: 5| Step: 10
Training loss: 0.9383050799369812
Validation loss: 1.8037774319289832

Epoch: 675| Step: 0
Training loss: 0.43578872084617615
Validation loss: 1.8484271713482436

Epoch: 5| Step: 1
Training loss: 0.8036502003669739
Validation loss: 1.8532202064350087

Epoch: 5| Step: 2
Training loss: 0.8541156053543091
Validation loss: 1.8683741554137199

Epoch: 5| Step: 3
Training loss: 0.6072996854782104
Validation loss: 1.844211470696234

Epoch: 5| Step: 4
Training loss: 0.536906361579895
Validation loss: 1.8424811875948341

Epoch: 5| Step: 5
Training loss: 0.7579542398452759
Validation loss: 1.8840361231116838

Epoch: 5| Step: 6
Training loss: 0.7263652682304382
Validation loss: 1.8031658895554081

Epoch: 5| Step: 7
Training loss: 0.6911938190460205
Validation loss: 1.854639563509213

Epoch: 5| Step: 8
Training loss: 0.31813767552375793
Validation loss: 1.8644568022861276

Epoch: 5| Step: 9
Training loss: 0.5774410963058472
Validation loss: 1.89228134001455

Epoch: 5| Step: 10
Training loss: 0.7898324131965637
Validation loss: 1.8271417194797146

Epoch: 676| Step: 0
Training loss: 0.5386016964912415
Validation loss: 1.8217164213939379

Epoch: 5| Step: 1
Training loss: 0.5871074795722961
Validation loss: 1.8063281633520638

Epoch: 5| Step: 2
Training loss: 0.7941855192184448
Validation loss: 1.8286396790576238

Epoch: 5| Step: 3
Training loss: 0.8215962648391724
Validation loss: 1.8418708321868733

Epoch: 5| Step: 4
Training loss: 0.7808361053466797
Validation loss: 1.853974127000378

Epoch: 5| Step: 5
Training loss: 0.6690477728843689
Validation loss: 1.8346906759405648

Epoch: 5| Step: 6
Training loss: 0.41998404264450073
Validation loss: 1.8329310981176232

Epoch: 5| Step: 7
Training loss: 0.34330886602401733
Validation loss: 1.8489414299688032

Epoch: 5| Step: 8
Training loss: 0.6997548937797546
Validation loss: 1.8590987036305089

Epoch: 5| Step: 9
Training loss: 1.0619179010391235
Validation loss: 1.8087979016765472

Epoch: 5| Step: 10
Training loss: 0.4563102424144745
Validation loss: 1.8722017849645307

Epoch: 677| Step: 0
Training loss: 0.4052855968475342
Validation loss: 1.8510847835130588

Epoch: 5| Step: 1
Training loss: 1.1227964162826538
Validation loss: 1.8373447951450144

Epoch: 5| Step: 2
Training loss: 0.6466418504714966
Validation loss: 1.8516578597407187

Epoch: 5| Step: 3
Training loss: 0.8503818511962891
Validation loss: 1.8512729534538843

Epoch: 5| Step: 4
Training loss: 0.4820181727409363
Validation loss: 1.8351518543817664

Epoch: 5| Step: 5
Training loss: 1.1971728801727295
Validation loss: 1.8860460968427761

Epoch: 5| Step: 6
Training loss: 0.5406742095947266
Validation loss: 1.7829185096166467

Epoch: 5| Step: 7
Training loss: 0.5202109813690186
Validation loss: 1.8575386866446464

Epoch: 5| Step: 8
Training loss: 0.5498186349868774
Validation loss: 1.8792927957350207

Epoch: 5| Step: 9
Training loss: 0.40382280945777893
Validation loss: 1.8616062787271315

Epoch: 5| Step: 10
Training loss: 0.3790357708930969
Validation loss: 1.8811841985230804

Epoch: 678| Step: 0
Training loss: 0.4966067671775818
Validation loss: 1.850206693013509

Epoch: 5| Step: 1
Training loss: 0.5935853123664856
Validation loss: 1.890766095089656

Epoch: 5| Step: 2
Training loss: 0.5353758931159973
Validation loss: 1.9004000797066638

Epoch: 5| Step: 3
Training loss: 0.44291192293167114
Validation loss: 1.8587400708147275

Epoch: 5| Step: 4
Training loss: 0.5053189992904663
Validation loss: 1.8455070244368685

Epoch: 5| Step: 5
Training loss: 0.6008855104446411
Validation loss: 1.8518464514004287

Epoch: 5| Step: 6
Training loss: 0.8395872116088867
Validation loss: 1.8317501737225441

Epoch: 5| Step: 7
Training loss: 0.9962784647941589
Validation loss: 1.834113876024882

Epoch: 5| Step: 8
Training loss: 0.4751972556114197
Validation loss: 1.8416768350908834

Epoch: 5| Step: 9
Training loss: 0.8047721982002258
Validation loss: 1.8215772157074304

Epoch: 5| Step: 10
Training loss: 0.999875009059906
Validation loss: 1.8301963056287458

Epoch: 679| Step: 0
Training loss: 0.6618098616600037
Validation loss: 1.8112283060627599

Epoch: 5| Step: 1
Training loss: 0.6126970052719116
Validation loss: 1.7642325239796792

Epoch: 5| Step: 2
Training loss: 0.4540843963623047
Validation loss: 1.8090708935132591

Epoch: 5| Step: 3
Training loss: 0.4716622829437256
Validation loss: 1.8282569762199157

Epoch: 5| Step: 4
Training loss: 0.5324303507804871
Validation loss: 1.8274500485389464

Epoch: 5| Step: 5
Training loss: 0.510729193687439
Validation loss: 1.7924290011006017

Epoch: 5| Step: 6
Training loss: 0.670988917350769
Validation loss: 1.8306901775380617

Epoch: 5| Step: 7
Training loss: 0.6606666445732117
Validation loss: 1.827752346633583

Epoch: 5| Step: 8
Training loss: 0.8202453851699829
Validation loss: 1.87063528004513

Epoch: 5| Step: 9
Training loss: 0.43371644616127014
Validation loss: 1.8745513064886934

Epoch: 5| Step: 10
Training loss: 1.3390841484069824
Validation loss: 1.8600546313870339

Epoch: 680| Step: 0
Training loss: 0.6135532259941101
Validation loss: 1.8634899303477297

Epoch: 5| Step: 1
Training loss: 0.6616396307945251
Validation loss: 1.8355133251477314

Epoch: 5| Step: 2
Training loss: 0.7173222303390503
Validation loss: 1.8548846360175841

Epoch: 5| Step: 3
Training loss: 0.46628743410110474
Validation loss: 1.8166776523795178

Epoch: 5| Step: 4
Training loss: 0.6951464414596558
Validation loss: 1.841637453725261

Epoch: 5| Step: 5
Training loss: 0.5636526346206665
Validation loss: 1.8392769444373347

Epoch: 5| Step: 6
Training loss: 0.5365200042724609
Validation loss: 1.8303522730386386

Epoch: 5| Step: 7
Training loss: 1.0281822681427002
Validation loss: 1.8089753376540316

Epoch: 5| Step: 8
Training loss: 0.6131676435470581
Validation loss: 1.795495972838453

Epoch: 5| Step: 9
Training loss: 0.4279411733150482
Validation loss: 1.862706458696755

Epoch: 5| Step: 10
Training loss: 0.7537190914154053
Validation loss: 1.8409150044123332

Epoch: 681| Step: 0
Training loss: 0.658406674861908
Validation loss: 1.7700148269694338

Epoch: 5| Step: 1
Training loss: 1.0809476375579834
Validation loss: 1.8237844872218307

Epoch: 5| Step: 2
Training loss: 0.3267557919025421
Validation loss: 1.8122786732130154

Epoch: 5| Step: 3
Training loss: 0.4724828600883484
Validation loss: 1.8325615775200628

Epoch: 5| Step: 4
Training loss: 0.632737934589386
Validation loss: 1.8472857013825448

Epoch: 5| Step: 5
Training loss: 0.6100863218307495
Validation loss: 1.8294544373789141

Epoch: 5| Step: 6
Training loss: 0.7672475576400757
Validation loss: 1.8122002719551005

Epoch: 5| Step: 7
Training loss: 0.5903738737106323
Validation loss: 1.864762693323115

Epoch: 5| Step: 8
Training loss: 0.6548734903335571
Validation loss: 1.7692427442919823

Epoch: 5| Step: 9
Training loss: 0.8512681126594543
Validation loss: 1.8220599992300874

Epoch: 5| Step: 10
Training loss: 0.6177901029586792
Validation loss: 1.8163483014670752

Epoch: 682| Step: 0
Training loss: 1.0665911436080933
Validation loss: 1.8406356662832282

Epoch: 5| Step: 1
Training loss: 0.5068124532699585
Validation loss: 1.8240983665630381

Epoch: 5| Step: 2
Training loss: 0.4079052805900574
Validation loss: 1.835740348344208

Epoch: 5| Step: 3
Training loss: 0.32307949662208557
Validation loss: 1.8173075722109886

Epoch: 5| Step: 4
Training loss: 0.3943999409675598
Validation loss: 1.8350248195791756

Epoch: 5| Step: 5
Training loss: 0.5667436122894287
Validation loss: 1.7800251386498893

Epoch: 5| Step: 6
Training loss: 0.3930412828922272
Validation loss: 1.8289275605191466

Epoch: 5| Step: 7
Training loss: 0.8248246908187866
Validation loss: 1.8281620343526204

Epoch: 5| Step: 8
Training loss: 0.8168236017227173
Validation loss: 1.7982310377141482

Epoch: 5| Step: 9
Training loss: 0.9936729669570923
Validation loss: 1.8165102107550508

Epoch: 5| Step: 10
Training loss: 0.5559669137001038
Validation loss: 1.823766634028445

Epoch: 683| Step: 0
Training loss: 0.6511461138725281
Validation loss: 1.812989923261827

Epoch: 5| Step: 1
Training loss: 0.8749861717224121
Validation loss: 1.8259621563778128

Epoch: 5| Step: 2
Training loss: 0.4405224919319153
Validation loss: 1.7728909164346673

Epoch: 5| Step: 3
Training loss: 0.5815004110336304
Validation loss: 1.8594558328710578

Epoch: 5| Step: 4
Training loss: 0.667729377746582
Validation loss: 1.8275703153302592

Epoch: 5| Step: 5
Training loss: 0.6643831133842468
Validation loss: 1.848918084175356

Epoch: 5| Step: 6
Training loss: 0.8064440488815308
Validation loss: 1.8206089363303235

Epoch: 5| Step: 7
Training loss: 0.7647287249565125
Validation loss: 1.8234072321204728

Epoch: 5| Step: 8
Training loss: 0.386776328086853
Validation loss: 1.841211744534072

Epoch: 5| Step: 9
Training loss: 0.7705338597297668
Validation loss: 1.8595953141489336

Epoch: 5| Step: 10
Training loss: 0.5301476716995239
Validation loss: 1.82242250955233

Epoch: 684| Step: 0
Training loss: 0.7203056216239929
Validation loss: 1.7947680757891746

Epoch: 5| Step: 1
Training loss: 0.5483385324478149
Validation loss: 1.8522891434290076

Epoch: 5| Step: 2
Training loss: 0.32189369201660156
Validation loss: 1.802392062320504

Epoch: 5| Step: 3
Training loss: 0.8458210229873657
Validation loss: 1.7970464857675696

Epoch: 5| Step: 4
Training loss: 0.3554219603538513
Validation loss: 1.8139210618952268

Epoch: 5| Step: 5
Training loss: 0.5432682037353516
Validation loss: 1.8030255968852709

Epoch: 5| Step: 6
Training loss: 0.8687058687210083
Validation loss: 1.8281501313691497

Epoch: 5| Step: 7
Training loss: 0.47541895508766174
Validation loss: 1.8049465892135457

Epoch: 5| Step: 8
Training loss: 0.7312966585159302
Validation loss: 1.7794830927284815

Epoch: 5| Step: 9
Training loss: 0.8131338357925415
Validation loss: 1.8107612671390656

Epoch: 5| Step: 10
Training loss: 0.8480241298675537
Validation loss: 1.781208804858628

Epoch: 685| Step: 0
Training loss: 0.5659460425376892
Validation loss: 1.8398587703704834

Epoch: 5| Step: 1
Training loss: 0.9725054502487183
Validation loss: 1.834725405580254

Epoch: 5| Step: 2
Training loss: 0.9454236030578613
Validation loss: 1.8659172801561252

Epoch: 5| Step: 3
Training loss: 0.48683470487594604
Validation loss: 1.8623300636968305

Epoch: 5| Step: 4
Training loss: 0.38824084401130676
Validation loss: 1.8864439174693117

Epoch: 5| Step: 5
Training loss: 0.6257085800170898
Validation loss: 1.8732792331326393

Epoch: 5| Step: 6
Training loss: 1.0080211162567139
Validation loss: 1.855785491645977

Epoch: 5| Step: 7
Training loss: 0.45101720094680786
Validation loss: 1.8577193829321093

Epoch: 5| Step: 8
Training loss: 0.9605696797370911
Validation loss: 1.8666893538608347

Epoch: 5| Step: 9
Training loss: 0.6219136118888855
Validation loss: 1.7999516866540397

Epoch: 5| Step: 10
Training loss: 0.5625383257865906
Validation loss: 1.8292745979883338

Epoch: 686| Step: 0
Training loss: 0.5507369041442871
Validation loss: 1.8056932777486823

Epoch: 5| Step: 1
Training loss: 0.4334021508693695
Validation loss: 1.7717513743267264

Epoch: 5| Step: 2
Training loss: 0.825546383857727
Validation loss: 1.7729941760340044

Epoch: 5| Step: 3
Training loss: 0.6781002283096313
Validation loss: 1.7965038181633077

Epoch: 5| Step: 4
Training loss: 0.7143695950508118
Validation loss: 1.8238065242767334

Epoch: 5| Step: 5
Training loss: 0.722844660282135
Validation loss: 1.8002817887131886

Epoch: 5| Step: 6
Training loss: 1.135498285293579
Validation loss: 1.8520081222698253

Epoch: 5| Step: 7
Training loss: 0.4000755250453949
Validation loss: 1.8153393230130594

Epoch: 5| Step: 8
Training loss: 0.5239740610122681
Validation loss: 1.8750646165622178

Epoch: 5| Step: 9
Training loss: 0.44674405455589294
Validation loss: 1.8320863772464056

Epoch: 5| Step: 10
Training loss: 0.4192616641521454
Validation loss: 1.8037267320899553

Epoch: 687| Step: 0
Training loss: 0.47700852155685425
Validation loss: 1.902640732385779

Epoch: 5| Step: 1
Training loss: 0.6318066716194153
Validation loss: 1.8363888148338563

Epoch: 5| Step: 2
Training loss: 0.6525238156318665
Validation loss: 1.7959841579519293

Epoch: 5| Step: 3
Training loss: 0.663533627986908
Validation loss: 1.8318787300458519

Epoch: 5| Step: 4
Training loss: 0.45133286714553833
Validation loss: 1.8546594176241147

Epoch: 5| Step: 5
Training loss: 0.35360828042030334
Validation loss: 1.8030765325792375

Epoch: 5| Step: 6
Training loss: 1.0899746417999268
Validation loss: 1.8430577273009925

Epoch: 5| Step: 7
Training loss: 0.5308727622032166
Validation loss: 1.8410054932358444

Epoch: 5| Step: 8
Training loss: 0.3393546938896179
Validation loss: 1.8358105997885428

Epoch: 5| Step: 9
Training loss: 0.569632887840271
Validation loss: 1.7911030246365456

Epoch: 5| Step: 10
Training loss: 1.0608880519866943
Validation loss: 1.7887431101132465

Epoch: 688| Step: 0
Training loss: 0.6021894812583923
Validation loss: 1.8237064000098937

Epoch: 5| Step: 1
Training loss: 0.9742042422294617
Validation loss: 1.8200265361416725

Epoch: 5| Step: 2
Training loss: 0.5701213479042053
Validation loss: 1.7637076300959433

Epoch: 5| Step: 3
Training loss: 0.6487371325492859
Validation loss: 1.82183854041561

Epoch: 5| Step: 4
Training loss: 0.40872064232826233
Validation loss: 1.7907773730575398

Epoch: 5| Step: 5
Training loss: 0.48971396684646606
Validation loss: 1.7832075998347292

Epoch: 5| Step: 6
Training loss: 0.7008670568466187
Validation loss: 1.818005391346511

Epoch: 5| Step: 7
Training loss: 0.8376306295394897
Validation loss: 1.7850991987412976

Epoch: 5| Step: 8
Training loss: 0.5680317878723145
Validation loss: 1.8507967802786058

Epoch: 5| Step: 9
Training loss: 0.5343500375747681
Validation loss: 1.88199580613003

Epoch: 5| Step: 10
Training loss: 0.6026895642280579
Validation loss: 1.7807489582287368

Epoch: 689| Step: 0
Training loss: 0.505553126335144
Validation loss: 1.8170291967289423

Epoch: 5| Step: 1
Training loss: 0.317455530166626
Validation loss: 1.8226477894731747

Epoch: 5| Step: 2
Training loss: 0.7117308974266052
Validation loss: 1.7856838703155518

Epoch: 5| Step: 3
Training loss: 0.44479990005493164
Validation loss: 1.847035390074535

Epoch: 5| Step: 4
Training loss: 0.9141616821289062
Validation loss: 1.8337766149992585

Epoch: 5| Step: 5
Training loss: 0.5199192762374878
Validation loss: 1.8729614455212829

Epoch: 5| Step: 6
Training loss: 0.6646379232406616
Validation loss: 1.8920215547725718

Epoch: 5| Step: 7
Training loss: 0.816959023475647
Validation loss: 1.832841573222991

Epoch: 5| Step: 8
Training loss: 0.8918548822402954
Validation loss: 1.8844674582122474

Epoch: 5| Step: 9
Training loss: 0.6656289100646973
Validation loss: 1.8491779078719437

Epoch: 5| Step: 10
Training loss: 0.48487675189971924
Validation loss: 1.8254693028747395

Epoch: 690| Step: 0
Training loss: 0.9089739918708801
Validation loss: 1.7778612823896511

Epoch: 5| Step: 1
Training loss: 0.8536376953125
Validation loss: 1.8223926828753563

Epoch: 5| Step: 2
Training loss: 0.4808134138584137
Validation loss: 1.8387540591660367

Epoch: 5| Step: 3
Training loss: 0.5426446199417114
Validation loss: 1.8379985529889342

Epoch: 5| Step: 4
Training loss: 0.4491712152957916
Validation loss: 1.8422529787145636

Epoch: 5| Step: 5
Training loss: 0.5602409839630127
Validation loss: 1.8380119915931457

Epoch: 5| Step: 6
Training loss: 0.9647329449653625
Validation loss: 1.8108539594117032

Epoch: 5| Step: 7
Training loss: 0.3034879267215729
Validation loss: 1.8186643764536867

Epoch: 5| Step: 8
Training loss: 0.6890395879745483
Validation loss: 1.824192762374878

Epoch: 5| Step: 9
Training loss: 0.5175788998603821
Validation loss: 1.8773818323689122

Epoch: 5| Step: 10
Training loss: 0.748780369758606
Validation loss: 1.8602839836510279

Epoch: 691| Step: 0
Training loss: 0.47009801864624023
Validation loss: 1.8593953937612555

Epoch: 5| Step: 1
Training loss: 0.3481156527996063
Validation loss: 1.8379802357765935

Epoch: 5| Step: 2
Training loss: 0.4695196747779846
Validation loss: 1.8684838305237472

Epoch: 5| Step: 3
Training loss: 0.7610633969306946
Validation loss: 1.84810850697179

Epoch: 5| Step: 4
Training loss: 0.5810484886169434
Validation loss: 1.8257543822770477

Epoch: 5| Step: 5
Training loss: 1.0999888181686401
Validation loss: 1.852391419872161

Epoch: 5| Step: 6
Training loss: 0.5347254872322083
Validation loss: 1.8461571995930006

Epoch: 5| Step: 7
Training loss: 0.5005708932876587
Validation loss: 1.8042149345080059

Epoch: 5| Step: 8
Training loss: 0.7425239682197571
Validation loss: 1.8247042381635277

Epoch: 5| Step: 9
Training loss: 0.8298243284225464
Validation loss: 1.8033302637838549

Epoch: 5| Step: 10
Training loss: 0.6040453910827637
Validation loss: 1.821787876467551

Epoch: 692| Step: 0
Training loss: 0.7873820066452026
Validation loss: 1.7819938762213594

Epoch: 5| Step: 1
Training loss: 0.42107534408569336
Validation loss: 1.8677443471006168

Epoch: 5| Step: 2
Training loss: 0.3043796122074127
Validation loss: 1.8541091257526028

Epoch: 5| Step: 3
Training loss: 0.509504497051239
Validation loss: 1.8327171238519813

Epoch: 5| Step: 4
Training loss: 0.5612252354621887
Validation loss: 1.8496930265939364

Epoch: 5| Step: 5
Training loss: 0.9686117172241211
Validation loss: 1.8685540101861442

Epoch: 5| Step: 6
Training loss: 0.7877615094184875
Validation loss: 1.8488858130670363

Epoch: 5| Step: 7
Training loss: 0.6537328362464905
Validation loss: 1.8794601623729994

Epoch: 5| Step: 8
Training loss: 0.8628638982772827
Validation loss: 1.8694606596423733

Epoch: 5| Step: 9
Training loss: 0.5477107763290405
Validation loss: 1.8068814867286271

Epoch: 5| Step: 10
Training loss: 0.765510618686676
Validation loss: 1.8424424215029644

Epoch: 693| Step: 0
Training loss: 0.589514970779419
Validation loss: 1.846313811117603

Epoch: 5| Step: 1
Training loss: 0.3475884199142456
Validation loss: 1.8090089341645599

Epoch: 5| Step: 2
Training loss: 0.727157473564148
Validation loss: 1.8064702236524193

Epoch: 5| Step: 3
Training loss: 0.6565543413162231
Validation loss: 1.8601885149555821

Epoch: 5| Step: 4
Training loss: 0.5294301509857178
Validation loss: 1.8396838493244623

Epoch: 5| Step: 5
Training loss: 0.9913123250007629
Validation loss: 1.8533689937283915

Epoch: 5| Step: 6
Training loss: 0.4796828329563141
Validation loss: 1.8585622861821165

Epoch: 5| Step: 7
Training loss: 0.8710299730300903
Validation loss: 1.8568026711863856

Epoch: 5| Step: 8
Training loss: 0.427539587020874
Validation loss: 1.891126060998568

Epoch: 5| Step: 9
Training loss: 0.7468830347061157
Validation loss: 1.844124306914627

Epoch: 5| Step: 10
Training loss: 0.8937091827392578
Validation loss: 1.810858012527548

Epoch: 694| Step: 0
Training loss: 0.7332267761230469
Validation loss: 1.7456479905754008

Epoch: 5| Step: 1
Training loss: 0.5076522827148438
Validation loss: 1.820793431292298

Epoch: 5| Step: 2
Training loss: 0.4556528925895691
Validation loss: 1.793987210078906

Epoch: 5| Step: 3
Training loss: 0.7532695531845093
Validation loss: 1.763503198982567

Epoch: 5| Step: 4
Training loss: 0.5917471647262573
Validation loss: 1.8213568938675748

Epoch: 5| Step: 5
Training loss: 0.7753251791000366
Validation loss: 1.8232985452939106

Epoch: 5| Step: 6
Training loss: 0.5613471865653992
Validation loss: 1.7596302250380158

Epoch: 5| Step: 7
Training loss: 0.6341580748558044
Validation loss: 1.832476444141839

Epoch: 5| Step: 8
Training loss: 0.562274158000946
Validation loss: 1.8372662733959895

Epoch: 5| Step: 9
Training loss: 1.2344214916229248
Validation loss: 1.9052756678673528

Epoch: 5| Step: 10
Training loss: 0.46925848722457886
Validation loss: 1.9134057824329664

Epoch: 695| Step: 0
Training loss: 0.7957770228385925
Validation loss: 1.9086926778157551

Epoch: 5| Step: 1
Training loss: 0.7640436887741089
Validation loss: 1.8640301894116145

Epoch: 5| Step: 2
Training loss: 0.809405505657196
Validation loss: 1.8893063170935518

Epoch: 5| Step: 3
Training loss: 0.5857242941856384
Validation loss: 1.8301072095030098

Epoch: 5| Step: 4
Training loss: 0.5304038524627686
Validation loss: 1.8393432555660125

Epoch: 5| Step: 5
Training loss: 0.6565230488777161
Validation loss: 1.7972912109026344

Epoch: 5| Step: 6
Training loss: 0.5178453326225281
Validation loss: 1.8399700182740406

Epoch: 5| Step: 7
Training loss: 0.508404552936554
Validation loss: 1.803901815927157

Epoch: 5| Step: 8
Training loss: 0.5133212804794312
Validation loss: 1.7610577960168161

Epoch: 5| Step: 9
Training loss: 0.7073237299919128
Validation loss: 1.837742995190364

Epoch: 5| Step: 10
Training loss: 0.5890145301818848
Validation loss: 1.82492995262146

Epoch: 696| Step: 0
Training loss: 0.6794832944869995
Validation loss: 1.7865794807352045

Epoch: 5| Step: 1
Training loss: 0.4986638128757477
Validation loss: 1.779535980634792

Epoch: 5| Step: 2
Training loss: 0.9919221997261047
Validation loss: 1.8083306307433753

Epoch: 5| Step: 3
Training loss: 0.3711310029029846
Validation loss: 1.9233871813743346

Epoch: 5| Step: 4
Training loss: 0.6300370097160339
Validation loss: 1.911889458215365

Epoch: 5| Step: 5
Training loss: 0.49280691146850586
Validation loss: 1.840262932162131

Epoch: 5| Step: 6
Training loss: 0.43110671639442444
Validation loss: 1.867210865020752

Epoch: 5| Step: 7
Training loss: 0.9694312810897827
Validation loss: 1.8673140951382217

Epoch: 5| Step: 8
Training loss: 0.5349458456039429
Validation loss: 1.9377838873094129

Epoch: 5| Step: 9
Training loss: 1.0219576358795166
Validation loss: 1.926891189749523

Epoch: 5| Step: 10
Training loss: 0.4041338562965393
Validation loss: 1.8257715746920595

Epoch: 697| Step: 0
Training loss: 0.4838329255580902
Validation loss: 1.826690504627843

Epoch: 5| Step: 1
Training loss: 0.46234503388404846
Validation loss: 1.8132814668839978

Epoch: 5| Step: 2
Training loss: 0.4452025294303894
Validation loss: 1.8705794862521592

Epoch: 5| Step: 3
Training loss: 0.4410586357116699
Validation loss: 1.7858551112554406

Epoch: 5| Step: 4
Training loss: 0.6895977854728699
Validation loss: 1.8419636680233864

Epoch: 5| Step: 5
Training loss: 0.7090190052986145
Validation loss: 1.8103505603728756

Epoch: 5| Step: 6
Training loss: 0.5541331171989441
Validation loss: 1.7935469124906807

Epoch: 5| Step: 7
Training loss: 1.2063428163528442
Validation loss: 1.8507795679953791

Epoch: 5| Step: 8
Training loss: 0.5839554071426392
Validation loss: 1.864461721912507

Epoch: 5| Step: 9
Training loss: 0.5536051988601685
Validation loss: 1.8319925646628104

Epoch: 5| Step: 10
Training loss: 0.549150824546814
Validation loss: 1.7927012315360449

Epoch: 698| Step: 0
Training loss: 0.6644223928451538
Validation loss: 1.7966370185216267

Epoch: 5| Step: 1
Training loss: 0.7558448910713196
Validation loss: 1.8255225637907624

Epoch: 5| Step: 2
Training loss: 0.5674592852592468
Validation loss: 1.8331100620249265

Epoch: 5| Step: 3
Training loss: 0.5386279821395874
Validation loss: 1.803351229236972

Epoch: 5| Step: 4
Training loss: 0.5639740824699402
Validation loss: 1.8809602004225536

Epoch: 5| Step: 5
Training loss: 0.8549005389213562
Validation loss: 1.8613116689907607

Epoch: 5| Step: 6
Training loss: 0.6682804822921753
Validation loss: 1.8913086127209406

Epoch: 5| Step: 7
Training loss: 0.4411133825778961
Validation loss: 1.8931765402517011

Epoch: 5| Step: 8
Training loss: 0.920671284198761
Validation loss: 1.8752393748170586

Epoch: 5| Step: 9
Training loss: 0.5444372892379761
Validation loss: 1.8862093494784447

Epoch: 5| Step: 10
Training loss: 0.5502792596817017
Validation loss: 1.8513789920396702

Epoch: 699| Step: 0
Training loss: 0.4509660303592682
Validation loss: 1.8380823366103634

Epoch: 5| Step: 1
Training loss: 0.31404367089271545
Validation loss: 1.8495582239602202

Epoch: 5| Step: 2
Training loss: 0.833938479423523
Validation loss: 1.845104221374758

Epoch: 5| Step: 3
Training loss: 0.3369130492210388
Validation loss: 1.8698974937521002

Epoch: 5| Step: 4
Training loss: 0.6985947489738464
Validation loss: 1.8149007981823337

Epoch: 5| Step: 5
Training loss: 0.6689926385879517
Validation loss: 1.85505707545947

Epoch: 5| Step: 6
Training loss: 0.44920167326927185
Validation loss: 1.8040205201795023

Epoch: 5| Step: 7
Training loss: 0.8613688349723816
Validation loss: 1.818830051729756

Epoch: 5| Step: 8
Training loss: 0.9037864804267883
Validation loss: 1.8306905300386491

Epoch: 5| Step: 9
Training loss: 1.0185636281967163
Validation loss: 1.8417915426274782

Epoch: 5| Step: 10
Training loss: 0.36567065119743347
Validation loss: 1.8088564411286385

Epoch: 700| Step: 0
Training loss: 0.5748884081840515
Validation loss: 1.7843643067985453

Epoch: 5| Step: 1
Training loss: 0.4667396545410156
Validation loss: 1.8733951199439265

Epoch: 5| Step: 2
Training loss: 0.6971604824066162
Validation loss: 1.7950156734835716

Epoch: 5| Step: 3
Training loss: 0.7069704532623291
Validation loss: 1.8682240504090504

Epoch: 5| Step: 4
Training loss: 0.4112775921821594
Validation loss: 1.8606482205852386

Epoch: 5| Step: 5
Training loss: 0.5930589437484741
Validation loss: 1.8732408297959195

Epoch: 5| Step: 6
Training loss: 0.7503377795219421
Validation loss: 1.8767986400153047

Epoch: 5| Step: 7
Training loss: 0.5371651649475098
Validation loss: 1.846108849330615

Epoch: 5| Step: 8
Training loss: 0.6122360229492188
Validation loss: 1.8844435317541963

Epoch: 5| Step: 9
Training loss: 0.8674770593643188
Validation loss: 1.8387501957595989

Epoch: 5| Step: 10
Training loss: 0.9276635050773621
Validation loss: 1.8754125846329557

Epoch: 701| Step: 0
Training loss: 0.5279874801635742
Validation loss: 1.8327745417112946

Epoch: 5| Step: 1
Training loss: 0.64191734790802
Validation loss: 1.8294603337523758

Epoch: 5| Step: 2
Training loss: 1.0781399011611938
Validation loss: 1.7973449166103075

Epoch: 5| Step: 3
Training loss: 0.6834697127342224
Validation loss: 1.8617778875494515

Epoch: 5| Step: 4
Training loss: 0.6917307376861572
Validation loss: 1.8118702698779363

Epoch: 5| Step: 5
Training loss: 0.5817605257034302
Validation loss: 1.779545537887081

Epoch: 5| Step: 6
Training loss: 0.36331039667129517
Validation loss: 1.8232912017453102

Epoch: 5| Step: 7
Training loss: 0.45865559577941895
Validation loss: 1.813690907211714

Epoch: 5| Step: 8
Training loss: 0.6996093988418579
Validation loss: 1.8223718725224978

Epoch: 5| Step: 9
Training loss: 0.6111100912094116
Validation loss: 1.8012329775799987

Epoch: 5| Step: 10
Training loss: 0.3955744802951813
Validation loss: 1.8420459570423249

Epoch: 702| Step: 0
Training loss: 0.392499715089798
Validation loss: 1.849524454403949

Epoch: 5| Step: 1
Training loss: 0.6366173028945923
Validation loss: 1.8655905787662794

Epoch: 5| Step: 2
Training loss: 0.7465540766716003
Validation loss: 1.8411317217734553

Epoch: 5| Step: 3
Training loss: 0.820046067237854
Validation loss: 1.8706048739853727

Epoch: 5| Step: 4
Training loss: 0.5306161642074585
Validation loss: 1.8708931419157213

Epoch: 5| Step: 5
Training loss: 0.8016164898872375
Validation loss: 1.8600398584078717

Epoch: 5| Step: 6
Training loss: 0.4619380533695221
Validation loss: 1.8293654867397842

Epoch: 5| Step: 7
Training loss: 0.6429464221000671
Validation loss: 1.9216246989465529

Epoch: 5| Step: 8
Training loss: 0.4865339398384094
Validation loss: 1.8394832136810466

Epoch: 5| Step: 9
Training loss: 0.4726187586784363
Validation loss: 1.8202427407746673

Epoch: 5| Step: 10
Training loss: 0.7394827604293823
Validation loss: 1.8123888123419978

Epoch: 703| Step: 0
Training loss: 0.8601382970809937
Validation loss: 1.792185241176236

Epoch: 5| Step: 1
Training loss: 0.47241607308387756
Validation loss: 1.8347968939811952

Epoch: 5| Step: 2
Training loss: 0.40161123871803284
Validation loss: 1.7955776132563108

Epoch: 5| Step: 3
Training loss: 1.1675564050674438
Validation loss: 1.8185687449670607

Epoch: 5| Step: 4
Training loss: 0.5122562646865845
Validation loss: 1.8240825489003172

Epoch: 5| Step: 5
Training loss: 0.5836317539215088
Validation loss: 1.8277483999088247

Epoch: 5| Step: 6
Training loss: 0.5499938726425171
Validation loss: 1.8393147260912004

Epoch: 5| Step: 7
Training loss: 0.662617027759552
Validation loss: 1.8586114504004037

Epoch: 5| Step: 8
Training loss: 0.422046035528183
Validation loss: 1.8401266708168933

Epoch: 5| Step: 9
Training loss: 0.551045298576355
Validation loss: 1.7541306557193879

Epoch: 5| Step: 10
Training loss: 0.767910897731781
Validation loss: 1.7574448521419237

Epoch: 704| Step: 0
Training loss: 0.7160493731498718
Validation loss: 1.8562381229092997

Epoch: 5| Step: 1
Training loss: 1.0041874647140503
Validation loss: 1.8152150441241521

Epoch: 5| Step: 2
Training loss: 0.2139483392238617
Validation loss: 1.8204946235943866

Epoch: 5| Step: 3
Training loss: 0.7419718503952026
Validation loss: 1.8502664630131056

Epoch: 5| Step: 4
Training loss: 0.7639484405517578
Validation loss: 1.8609526734198294

Epoch: 5| Step: 5
Training loss: 0.40333956480026245
Validation loss: 1.839691703037549

Epoch: 5| Step: 6
Training loss: 0.7261251211166382
Validation loss: 1.8783479852061118

Epoch: 5| Step: 7
Training loss: 0.7881947755813599
Validation loss: 1.911660094414988

Epoch: 5| Step: 8
Training loss: 0.5450720191001892
Validation loss: 1.86271152188701

Epoch: 5| Step: 9
Training loss: 0.4460098147392273
Validation loss: 1.838154113420876

Epoch: 5| Step: 10
Training loss: 0.3913746476173401
Validation loss: 1.8855333597429338

Epoch: 705| Step: 0
Training loss: 0.4845253825187683
Validation loss: 1.8397482825863747

Epoch: 5| Step: 1
Training loss: 0.6270100474357605
Validation loss: 1.8237433869351622

Epoch: 5| Step: 2
Training loss: 0.7166651487350464
Validation loss: 1.7943650855812976

Epoch: 5| Step: 3
Training loss: 0.2686682939529419
Validation loss: 1.7768149837370841

Epoch: 5| Step: 4
Training loss: 0.5434797406196594
Validation loss: 1.7671152846787566

Epoch: 5| Step: 5
Training loss: 1.0184059143066406
Validation loss: 1.8094412819031747

Epoch: 5| Step: 6
Training loss: 0.6539773941040039
Validation loss: 1.8332317054912608

Epoch: 5| Step: 7
Training loss: 0.6210083961486816
Validation loss: 1.791867192073535

Epoch: 5| Step: 8
Training loss: 0.43859872221946716
Validation loss: 1.782627792768581

Epoch: 5| Step: 9
Training loss: 1.0762277841567993
Validation loss: 1.8092279331658476

Epoch: 5| Step: 10
Training loss: 0.24152180552482605
Validation loss: 1.8289028316415765

Epoch: 706| Step: 0
Training loss: 0.5702033638954163
Validation loss: 1.8072707217226747

Epoch: 5| Step: 1
Training loss: 0.872231125831604
Validation loss: 1.8463561996336906

Epoch: 5| Step: 2
Training loss: 0.5932403802871704
Validation loss: 1.8370372928598875

Epoch: 5| Step: 3
Training loss: 0.7995119094848633
Validation loss: 1.8475996371238463

Epoch: 5| Step: 4
Training loss: 0.7280517220497131
Validation loss: 1.8806072563253424

Epoch: 5| Step: 5
Training loss: 0.8474799394607544
Validation loss: 1.8549231547181324

Epoch: 5| Step: 6
Training loss: 0.44198542833328247
Validation loss: 1.8509782462991693

Epoch: 5| Step: 7
Training loss: 0.46852636337280273
Validation loss: 1.8497779984628

Epoch: 5| Step: 8
Training loss: 0.3649051785469055
Validation loss: 1.8569652354845436

Epoch: 5| Step: 9
Training loss: 0.30525389313697815
Validation loss: 1.7884522509831253

Epoch: 5| Step: 10
Training loss: 0.8366313576698303
Validation loss: 1.788744987980012

Epoch: 707| Step: 0
Training loss: 0.513231635093689
Validation loss: 1.8074076637145011

Epoch: 5| Step: 1
Training loss: 0.44373971223831177
Validation loss: 1.806329470808788

Epoch: 5| Step: 2
Training loss: 0.764793872833252
Validation loss: 1.7633032491130214

Epoch: 5| Step: 3
Training loss: 1.0695948600769043
Validation loss: 1.7981777357798752

Epoch: 5| Step: 4
Training loss: 0.5004302263259888
Validation loss: 1.8206167656888244

Epoch: 5| Step: 5
Training loss: 0.6180531978607178
Validation loss: 1.8438160791192004

Epoch: 5| Step: 6
Training loss: 0.4320429861545563
Validation loss: 1.8462069342213292

Epoch: 5| Step: 7
Training loss: 0.2730677127838135
Validation loss: 1.814319383713507

Epoch: 5| Step: 8
Training loss: 0.5471081137657166
Validation loss: 1.8143422090879051

Epoch: 5| Step: 9
Training loss: 0.8299797773361206
Validation loss: 1.8559780633577736

Epoch: 5| Step: 10
Training loss: 0.7730751633644104
Validation loss: 1.8340803602690339

Epoch: 708| Step: 0
Training loss: 0.5666822195053101
Validation loss: 1.8187390899145475

Epoch: 5| Step: 1
Training loss: 0.7804989814758301
Validation loss: 1.854364925815213

Epoch: 5| Step: 2
Training loss: 0.7268031239509583
Validation loss: 1.886279083067371

Epoch: 5| Step: 3
Training loss: 0.7175004482269287
Validation loss: 1.8135700405284922

Epoch: 5| Step: 4
Training loss: 0.5419261455535889
Validation loss: 1.8299197855816092

Epoch: 5| Step: 5
Training loss: 0.6054989695549011
Validation loss: 1.7853626102529547

Epoch: 5| Step: 6
Training loss: 0.7419973611831665
Validation loss: 1.8051276258243028

Epoch: 5| Step: 7
Training loss: 0.5662572979927063
Validation loss: 1.8198193644964566

Epoch: 5| Step: 8
Training loss: 0.5475561022758484
Validation loss: 1.8274804571623444

Epoch: 5| Step: 9
Training loss: 0.5787342190742493
Validation loss: 1.8068087972620481

Epoch: 5| Step: 10
Training loss: 0.4841412901878357
Validation loss: 1.7866359346656389

Epoch: 709| Step: 0
Training loss: 0.49489083886146545
Validation loss: 1.7829350117714173

Epoch: 5| Step: 1
Training loss: 0.6770051121711731
Validation loss: 1.8199534236743886

Epoch: 5| Step: 2
Training loss: 1.0102102756500244
Validation loss: 1.8165533702860597

Epoch: 5| Step: 3
Training loss: 0.5745105743408203
Validation loss: 1.8216427538984565

Epoch: 5| Step: 4
Training loss: 0.7215389609336853
Validation loss: 1.8047783451695596

Epoch: 5| Step: 5
Training loss: 0.6138045787811279
Validation loss: 1.8256214639191986

Epoch: 5| Step: 6
Training loss: 0.46589764952659607
Validation loss: 1.8362493002286522

Epoch: 5| Step: 7
Training loss: 0.43407782912254333
Validation loss: 1.8752070588450278

Epoch: 5| Step: 8
Training loss: 0.7656955122947693
Validation loss: 1.8476948584279707

Epoch: 5| Step: 9
Training loss: 0.5561519861221313
Validation loss: 1.7972675138904202

Epoch: 5| Step: 10
Training loss: 0.5365040898323059
Validation loss: 1.8425308209593578

Epoch: 710| Step: 0
Training loss: 0.40846624970436096
Validation loss: 1.8117804604191934

Epoch: 5| Step: 1
Training loss: 0.9924542307853699
Validation loss: 1.8396657769398024

Epoch: 5| Step: 2
Training loss: 0.5787068009376526
Validation loss: 1.8084987132780013

Epoch: 5| Step: 3
Training loss: 0.6283945441246033
Validation loss: 1.7838674501706195

Epoch: 5| Step: 4
Training loss: 0.2776660621166229
Validation loss: 1.806338200005152

Epoch: 5| Step: 5
Training loss: 0.5033527612686157
Validation loss: 1.8145635358748897

Epoch: 5| Step: 6
Training loss: 0.8107069134712219
Validation loss: 1.8103549275346982

Epoch: 5| Step: 7
Training loss: 0.6715441346168518
Validation loss: 1.8363929153770528

Epoch: 5| Step: 8
Training loss: 0.8139653205871582
Validation loss: 1.8255953378574823

Epoch: 5| Step: 9
Training loss: 0.576413631439209
Validation loss: 1.823918363099457

Epoch: 5| Step: 10
Training loss: 0.34869685769081116
Validation loss: 1.8068333928303053

Epoch: 711| Step: 0
Training loss: 0.6349878311157227
Validation loss: 1.8149243477852113

Epoch: 5| Step: 1
Training loss: 0.7220253944396973
Validation loss: 1.7877491648479173

Epoch: 5| Step: 2
Training loss: 0.3758698105812073
Validation loss: 1.8507833339834725

Epoch: 5| Step: 3
Training loss: 0.5200181007385254
Validation loss: 1.7902378151493687

Epoch: 5| Step: 4
Training loss: 0.43788081407546997
Validation loss: 1.8649359326208792

Epoch: 5| Step: 5
Training loss: 0.7921375036239624
Validation loss: 1.8745394547780354

Epoch: 5| Step: 6
Training loss: 0.8546022176742554
Validation loss: 1.847605202787666

Epoch: 5| Step: 7
Training loss: 0.600337028503418
Validation loss: 1.8498831872017152

Epoch: 5| Step: 8
Training loss: 0.44505900144577026
Validation loss: 1.8283000787099202

Epoch: 5| Step: 9
Training loss: 0.7526500225067139
Validation loss: 1.871761227166781

Epoch: 5| Step: 10
Training loss: 0.5741462111473083
Validation loss: 1.8160239214538245

Epoch: 712| Step: 0
Training loss: 0.8619017601013184
Validation loss: 1.8218284653079124

Epoch: 5| Step: 1
Training loss: 0.5727318525314331
Validation loss: 1.8562511795310563

Epoch: 5| Step: 2
Training loss: 0.5749756097793579
Validation loss: 1.8655315817043345

Epoch: 5| Step: 3
Training loss: 0.2537354528903961
Validation loss: 1.8258505982737387

Epoch: 5| Step: 4
Training loss: 0.596312403678894
Validation loss: 1.8861979374321558

Epoch: 5| Step: 5
Training loss: 0.44793573021888733
Validation loss: 1.7895728029230589

Epoch: 5| Step: 6
Training loss: 0.7547401189804077
Validation loss: 1.8094685462213331

Epoch: 5| Step: 7
Training loss: 0.5126241445541382
Validation loss: 1.8116960589603712

Epoch: 5| Step: 8
Training loss: 0.7910298705101013
Validation loss: 1.7686433676750428

Epoch: 5| Step: 9
Training loss: 0.5015724897384644
Validation loss: 1.8513861189606369

Epoch: 5| Step: 10
Training loss: 0.9917863011360168
Validation loss: 1.861445229540589

Epoch: 713| Step: 0
Training loss: 0.5960566401481628
Validation loss: 1.858409058663153

Epoch: 5| Step: 1
Training loss: 0.6221590042114258
Validation loss: 1.8250278401118454

Epoch: 5| Step: 2
Training loss: 0.6221392154693604
Validation loss: 1.7855228031835249

Epoch: 5| Step: 3
Training loss: 0.7471432089805603
Validation loss: 1.7696795771198888

Epoch: 5| Step: 4
Training loss: 0.5100299119949341
Validation loss: 1.8242754833672636

Epoch: 5| Step: 5
Training loss: 0.31236159801483154
Validation loss: 1.8320768161486554

Epoch: 5| Step: 6
Training loss: 0.9227190017700195
Validation loss: 1.8173824023174983

Epoch: 5| Step: 7
Training loss: 0.6095857620239258
Validation loss: 1.8395328162818827

Epoch: 5| Step: 8
Training loss: 0.8974336385726929
Validation loss: 1.811758497709869

Epoch: 5| Step: 9
Training loss: 0.4570590853691101
Validation loss: 1.8670489813691826

Epoch: 5| Step: 10
Training loss: 0.365527480840683
Validation loss: 1.8111184322705833

Epoch: 714| Step: 0
Training loss: 0.5377784967422485
Validation loss: 1.8581531509276359

Epoch: 5| Step: 1
Training loss: 0.7774590849876404
Validation loss: 1.8407240554850588

Epoch: 5| Step: 2
Training loss: 0.8160192370414734
Validation loss: 1.8084960919554516

Epoch: 5| Step: 3
Training loss: 0.7867087721824646
Validation loss: 1.751883058137791

Epoch: 5| Step: 4
Training loss: 0.533247172832489
Validation loss: 1.8237324812078988

Epoch: 5| Step: 5
Training loss: 0.8163663148880005
Validation loss: 1.8109055936977427

Epoch: 5| Step: 6
Training loss: 0.6667394042015076
Validation loss: 1.820959500728115

Epoch: 5| Step: 7
Training loss: 0.32654887437820435
Validation loss: 1.758072526865108

Epoch: 5| Step: 8
Training loss: 0.4359700083732605
Validation loss: 1.8062518694067513

Epoch: 5| Step: 9
Training loss: 0.4124205708503723
Validation loss: 1.8440966362594275

Epoch: 5| Step: 10
Training loss: 0.7944864630699158
Validation loss: 1.8081062814240814

Epoch: 715| Step: 0
Training loss: 0.40799480676651
Validation loss: 1.7839475306131507

Epoch: 5| Step: 1
Training loss: 0.48366889357566833
Validation loss: 1.786668723629367

Epoch: 5| Step: 2
Training loss: 0.369606077671051
Validation loss: 1.8709183892896097

Epoch: 5| Step: 3
Training loss: 0.8765840530395508
Validation loss: 1.803355957872124

Epoch: 5| Step: 4
Training loss: 0.42367905378341675
Validation loss: 1.783618878292781

Epoch: 5| Step: 5
Training loss: 0.36275213956832886
Validation loss: 1.8464512927557832

Epoch: 5| Step: 6
Training loss: 0.7163909673690796
Validation loss: 1.843341911992719

Epoch: 5| Step: 7
Training loss: 0.5601605176925659
Validation loss: 1.796566624795237

Epoch: 5| Step: 8
Training loss: 0.7170478105545044
Validation loss: 1.8469909262913529

Epoch: 5| Step: 9
Training loss: 0.9076118469238281
Validation loss: 1.8774902436041063

Epoch: 5| Step: 10
Training loss: 0.8388133645057678
Validation loss: 1.8740910381399176

Epoch: 716| Step: 0
Training loss: 0.7899866700172424
Validation loss: 1.8063989698245961

Epoch: 5| Step: 1
Training loss: 0.7835399508476257
Validation loss: 1.809120842205581

Epoch: 5| Step: 2
Training loss: 0.7360209226608276
Validation loss: 1.786305360896613

Epoch: 5| Step: 3
Training loss: 0.5394094586372375
Validation loss: 1.849736548239185

Epoch: 5| Step: 4
Training loss: 0.4393366873264313
Validation loss: 1.7912983138074157

Epoch: 5| Step: 5
Training loss: 0.6145250797271729
Validation loss: 1.7851649458690355

Epoch: 5| Step: 6
Training loss: 0.6131756901741028
Validation loss: 1.8016835361398675

Epoch: 5| Step: 7
Training loss: 0.6314964890480042
Validation loss: 1.7895506633225309

Epoch: 5| Step: 8
Training loss: 0.6967621445655823
Validation loss: 1.825999249694168

Epoch: 5| Step: 9
Training loss: 0.2849879860877991
Validation loss: 1.8297952554559196

Epoch: 5| Step: 10
Training loss: 0.2791510820388794
Validation loss: 1.7750092526917816

Epoch: 717| Step: 0
Training loss: 0.60759437084198
Validation loss: 1.8510095675786336

Epoch: 5| Step: 1
Training loss: 0.4984120726585388
Validation loss: 1.8479556857898671

Epoch: 5| Step: 2
Training loss: 0.6414958834648132
Validation loss: 1.8260724416343115

Epoch: 5| Step: 3
Training loss: 0.6388024091720581
Validation loss: 1.9057270070557952

Epoch: 5| Step: 4
Training loss: 0.9403113126754761
Validation loss: 1.8463548729496617

Epoch: 5| Step: 5
Training loss: 0.5786687135696411
Validation loss: 1.8517613898041427

Epoch: 5| Step: 6
Training loss: 0.5806495547294617
Validation loss: 1.8043970907888105

Epoch: 5| Step: 7
Training loss: 0.4210085868835449
Validation loss: 1.8365127783949657

Epoch: 5| Step: 8
Training loss: 0.34349361062049866
Validation loss: 1.8211202800914805

Epoch: 5| Step: 9
Training loss: 0.9038867950439453
Validation loss: 1.8067034777774607

Epoch: 5| Step: 10
Training loss: 0.8360450267791748
Validation loss: 1.7869412053015925

Epoch: 718| Step: 0
Training loss: 0.3588607609272003
Validation loss: 1.7689668670777352

Epoch: 5| Step: 1
Training loss: 0.626989483833313
Validation loss: 1.770355075918218

Epoch: 5| Step: 2
Training loss: 0.8345220685005188
Validation loss: 1.8107627002141808

Epoch: 5| Step: 3
Training loss: 0.57416832447052
Validation loss: 1.7836745913310716

Epoch: 5| Step: 4
Training loss: 0.6045315265655518
Validation loss: 1.7854331616432435

Epoch: 5| Step: 5
Training loss: 0.935013473033905
Validation loss: 1.7803717044091993

Epoch: 5| Step: 6
Training loss: 0.4946151673793793
Validation loss: 1.8034039774248678

Epoch: 5| Step: 7
Training loss: 0.3805406987667084
Validation loss: 1.8014123593607256

Epoch: 5| Step: 8
Training loss: 0.38610678911209106
Validation loss: 1.8521362504651468

Epoch: 5| Step: 9
Training loss: 0.8605138659477234
Validation loss: 1.8199921013206564

Epoch: 5| Step: 10
Training loss: 0.5006547570228577
Validation loss: 1.8897630706910165

Epoch: 719| Step: 0
Training loss: 0.7827427983283997
Validation loss: 1.9254252808068388

Epoch: 5| Step: 1
Training loss: 0.9371999502182007
Validation loss: 1.8581893072333386

Epoch: 5| Step: 2
Training loss: 0.5614800453186035
Validation loss: 1.8493297612795265

Epoch: 5| Step: 3
Training loss: 0.8121577501296997
Validation loss: 1.8268993926304642

Epoch: 5| Step: 4
Training loss: 0.32874318957328796
Validation loss: 1.8638401762131722

Epoch: 5| Step: 5
Training loss: 0.530065655708313
Validation loss: 1.8297640264675181

Epoch: 5| Step: 6
Training loss: 0.510431170463562
Validation loss: 1.7991051097070017

Epoch: 5| Step: 7
Training loss: 0.4405561089515686
Validation loss: 1.8286574720054545

Epoch: 5| Step: 8
Training loss: 0.48275747895240784
Validation loss: 1.82658681690052

Epoch: 5| Step: 9
Training loss: 0.8369215130805969
Validation loss: 1.7831476619166713

Epoch: 5| Step: 10
Training loss: 0.4171717166900635
Validation loss: 1.8151146211931783

Epoch: 720| Step: 0
Training loss: 0.438711553812027
Validation loss: 1.796484330649017

Epoch: 5| Step: 1
Training loss: 0.5656440258026123
Validation loss: 1.8350800057893157

Epoch: 5| Step: 2
Training loss: 0.46406644582748413
Validation loss: 1.8769660124214746

Epoch: 5| Step: 3
Training loss: 0.7746660113334656
Validation loss: 1.8046735281585364

Epoch: 5| Step: 4
Training loss: 0.8669420480728149
Validation loss: 1.8471509538671023

Epoch: 5| Step: 5
Training loss: 0.5271353721618652
Validation loss: 1.8622523687219108

Epoch: 5| Step: 6
Training loss: 0.6873509883880615
Validation loss: 1.8940456913363548

Epoch: 5| Step: 7
Training loss: 0.3209192752838135
Validation loss: 1.8457743724187214

Epoch: 5| Step: 8
Training loss: 0.9301124811172485
Validation loss: 1.8364450611093992

Epoch: 5| Step: 9
Training loss: 0.3645334839820862
Validation loss: 1.8585182159177718

Epoch: 5| Step: 10
Training loss: 0.6889411807060242
Validation loss: 1.8624208511844758

Epoch: 721| Step: 0
Training loss: 0.7218818664550781
Validation loss: 1.8080886333219466

Epoch: 5| Step: 1
Training loss: 0.38397017121315
Validation loss: 1.868736272217125

Epoch: 5| Step: 2
Training loss: 0.5609592199325562
Validation loss: 1.870389812736101

Epoch: 5| Step: 3
Training loss: 0.7443113327026367
Validation loss: 1.8970798369376891

Epoch: 5| Step: 4
Training loss: 0.3396565020084381
Validation loss: 1.8152545626445482

Epoch: 5| Step: 5
Training loss: 0.45606476068496704
Validation loss: 1.8585578318565124

Epoch: 5| Step: 6
Training loss: 0.5883041620254517
Validation loss: 1.793381162869033

Epoch: 5| Step: 7
Training loss: 0.5970078706741333
Validation loss: 1.8476070780907907

Epoch: 5| Step: 8
Training loss: 0.5894861221313477
Validation loss: 1.8168039168080976

Epoch: 5| Step: 9
Training loss: 0.9587261080741882
Validation loss: 1.8777195868953582

Epoch: 5| Step: 10
Training loss: 0.7267611026763916
Validation loss: 1.7994491874530751

Epoch: 722| Step: 0
Training loss: 0.5091019868850708
Validation loss: 1.8493090611632153

Epoch: 5| Step: 1
Training loss: 0.6432327628135681
Validation loss: 1.8058876273452595

Epoch: 5| Step: 2
Training loss: 0.47968974709510803
Validation loss: 1.8401837015664706

Epoch: 5| Step: 3
Training loss: 0.6315267086029053
Validation loss: 1.8332091608355123

Epoch: 5| Step: 4
Training loss: 0.4673103392124176
Validation loss: 1.8516063023638982

Epoch: 5| Step: 5
Training loss: 0.8091011047363281
Validation loss: 1.8615157194035028

Epoch: 5| Step: 6
Training loss: 0.6869637370109558
Validation loss: 1.8220182029149865

Epoch: 5| Step: 7
Training loss: 0.7576135396957397
Validation loss: 1.8396952613707511

Epoch: 5| Step: 8
Training loss: 0.2054959237575531
Validation loss: 1.862811360307919

Epoch: 5| Step: 9
Training loss: 0.5011500120162964
Validation loss: 1.7982806531331872

Epoch: 5| Step: 10
Training loss: 0.49774208664894104
Validation loss: 1.8650471330970846

Epoch: 723| Step: 0
Training loss: 0.8944770693778992
Validation loss: 1.809472789046585

Epoch: 5| Step: 1
Training loss: 0.5956707000732422
Validation loss: 1.8514011649675266

Epoch: 5| Step: 2
Training loss: 0.5146716833114624
Validation loss: 1.7875427225584626

Epoch: 5| Step: 3
Training loss: 0.39671561121940613
Validation loss: 1.8348767385687879

Epoch: 5| Step: 4
Training loss: 0.5540898442268372
Validation loss: 1.8709552467510264

Epoch: 5| Step: 5
Training loss: 0.6820358037948608
Validation loss: 1.8118615740089006

Epoch: 5| Step: 6
Training loss: 0.6348222494125366
Validation loss: 1.83822472505672

Epoch: 5| Step: 7
Training loss: 0.7012830376625061
Validation loss: 1.7911689012281355

Epoch: 5| Step: 8
Training loss: 0.2231409251689911
Validation loss: 1.8446803900503344

Epoch: 5| Step: 9
Training loss: 0.6733973026275635
Validation loss: 1.8597126186534922

Epoch: 5| Step: 10
Training loss: 0.5373256802558899
Validation loss: 1.8742463921987882

Epoch: 724| Step: 0
Training loss: 0.6101469397544861
Validation loss: 1.8321700070493965

Epoch: 5| Step: 1
Training loss: 0.32786065340042114
Validation loss: 1.8183023609140867

Epoch: 5| Step: 2
Training loss: 0.5064848065376282
Validation loss: 1.8746362347756662

Epoch: 5| Step: 3
Training loss: 0.688422679901123
Validation loss: 1.8079607935361965

Epoch: 5| Step: 4
Training loss: 0.47123709321022034
Validation loss: 1.8045113458428332

Epoch: 5| Step: 5
Training loss: 0.4989369511604309
Validation loss: 1.8318150902307162

Epoch: 5| Step: 6
Training loss: 0.4706713557243347
Validation loss: 1.8095444312659643

Epoch: 5| Step: 7
Training loss: 0.46800437569618225
Validation loss: 1.8249988735363047

Epoch: 5| Step: 8
Training loss: 0.5314237475395203
Validation loss: 1.8570194244384766

Epoch: 5| Step: 9
Training loss: 0.7739423513412476
Validation loss: 1.8259955657425748

Epoch: 5| Step: 10
Training loss: 1.3163477182388306
Validation loss: 1.7810157678460563

Epoch: 725| Step: 0
Training loss: 0.44140562415122986
Validation loss: 1.7673981510182863

Epoch: 5| Step: 1
Training loss: 0.8227092623710632
Validation loss: 1.8568285844659294

Epoch: 5| Step: 2
Training loss: 0.625369131565094
Validation loss: 1.8102170677595242

Epoch: 5| Step: 3
Training loss: 0.4378766119480133
Validation loss: 1.8459475527527511

Epoch: 5| Step: 4
Training loss: 0.6994849443435669
Validation loss: 1.8300111729611632

Epoch: 5| Step: 5
Training loss: 0.9977355003356934
Validation loss: 1.8234093586603801

Epoch: 5| Step: 6
Training loss: 0.6566042304039001
Validation loss: 1.8163998485893331

Epoch: 5| Step: 7
Training loss: 0.310495525598526
Validation loss: 1.8848484139288626

Epoch: 5| Step: 8
Training loss: 0.5806901454925537
Validation loss: 1.8683531233059463

Epoch: 5| Step: 9
Training loss: 0.5079594254493713
Validation loss: 1.8114312887191772

Epoch: 5| Step: 10
Training loss: 0.3911055326461792
Validation loss: 1.7803188062483264

Epoch: 726| Step: 0
Training loss: 0.521653413772583
Validation loss: 1.8272473350647958

Epoch: 5| Step: 1
Training loss: 0.7046899795532227
Validation loss: 1.8296320515294229

Epoch: 5| Step: 2
Training loss: 0.45820292830467224
Validation loss: 1.8642030762087913

Epoch: 5| Step: 3
Training loss: 0.49786338210105896
Validation loss: 1.816166631637081

Epoch: 5| Step: 4
Training loss: 0.4511508047580719
Validation loss: 1.810907797146869

Epoch: 5| Step: 5
Training loss: 0.4623783230781555
Validation loss: 1.79007040685223

Epoch: 5| Step: 6
Training loss: 0.5150843858718872
Validation loss: 1.80825041186425

Epoch: 5| Step: 7
Training loss: 0.8060666918754578
Validation loss: 1.8201659328194075

Epoch: 5| Step: 8
Training loss: 1.001803994178772
Validation loss: 1.8684450990410262

Epoch: 5| Step: 9
Training loss: 0.40909233689308167
Validation loss: 1.8880667930008264

Epoch: 5| Step: 10
Training loss: 0.5562636256217957
Validation loss: 1.9724665021383634

Epoch: 727| Step: 0
Training loss: 0.40823420882225037
Validation loss: 1.8480990343196417

Epoch: 5| Step: 1
Training loss: 0.664794921875
Validation loss: 1.8288785475556568

Epoch: 5| Step: 2
Training loss: 0.739413857460022
Validation loss: 1.8117112280220113

Epoch: 5| Step: 3
Training loss: 0.6723904609680176
Validation loss: 1.8716876916987921

Epoch: 5| Step: 4
Training loss: 0.32063865661621094
Validation loss: 1.7974924810471073

Epoch: 5| Step: 5
Training loss: 0.40104955434799194
Validation loss: 1.8014337555054696

Epoch: 5| Step: 6
Training loss: 0.6269657015800476
Validation loss: 1.9107306695753528

Epoch: 5| Step: 7
Training loss: 0.3578397333621979
Validation loss: 1.8154097577576995

Epoch: 5| Step: 8
Training loss: 1.026262879371643
Validation loss: 1.8370249271392822

Epoch: 5| Step: 9
Training loss: 0.5931278467178345
Validation loss: 1.8128404245581677

Epoch: 5| Step: 10
Training loss: 0.4819486141204834
Validation loss: 1.7908984262456176

Epoch: 728| Step: 0
Training loss: 0.6301497220993042
Validation loss: 1.8038817810755905

Epoch: 5| Step: 1
Training loss: 0.716866135597229
Validation loss: 1.8636685494453675

Epoch: 5| Step: 2
Training loss: 0.5521575212478638
Validation loss: 1.8105013191059072

Epoch: 5| Step: 3
Training loss: 0.49343234300613403
Validation loss: 1.8178437896954116

Epoch: 5| Step: 4
Training loss: 0.6044808626174927
Validation loss: 1.777420877128519

Epoch: 5| Step: 5
Training loss: 0.5970921516418457
Validation loss: 1.893461383799071

Epoch: 5| Step: 6
Training loss: 0.45996928215026855
Validation loss: 1.8267161077068699

Epoch: 5| Step: 7
Training loss: 0.6806758046150208
Validation loss: 1.7904731368505826

Epoch: 5| Step: 8
Training loss: 0.5641151666641235
Validation loss: 1.8444795031701364

Epoch: 5| Step: 9
Training loss: 0.5311756134033203
Validation loss: 1.797872415152929

Epoch: 5| Step: 10
Training loss: 0.43005356192588806
Validation loss: 1.7868113069124119

Epoch: 729| Step: 0
Training loss: 0.7852873206138611
Validation loss: 1.7794702834980463

Epoch: 5| Step: 1
Training loss: 0.6290961503982544
Validation loss: 1.8460431868030178

Epoch: 5| Step: 2
Training loss: 0.6023642420768738
Validation loss: 1.8267391445816203

Epoch: 5| Step: 3
Training loss: 0.5286160111427307
Validation loss: 1.8657172572228216

Epoch: 5| Step: 4
Training loss: 0.6222918629646301
Validation loss: 1.8285828354538127

Epoch: 5| Step: 5
Training loss: 0.5978822708129883
Validation loss: 1.8249072464563514

Epoch: 5| Step: 6
Training loss: 0.43283724784851074
Validation loss: 1.8691878498241465

Epoch: 5| Step: 7
Training loss: 0.4066566526889801
Validation loss: 1.8554090171731927

Epoch: 5| Step: 8
Training loss: 0.8603430986404419
Validation loss: 1.872407046697473

Epoch: 5| Step: 9
Training loss: 0.4508003294467926
Validation loss: 1.8379387086437595

Epoch: 5| Step: 10
Training loss: 0.6407477259635925
Validation loss: 1.8213708182816863

Epoch: 730| Step: 0
Training loss: 0.696556031703949
Validation loss: 1.8292544400820168

Epoch: 5| Step: 1
Training loss: 0.6910197138786316
Validation loss: 1.8126121720960062

Epoch: 5| Step: 2
Training loss: 0.6037953495979309
Validation loss: 1.8169626599998885

Epoch: 5| Step: 3
Training loss: 0.6601250767707825
Validation loss: 1.8687660976122784

Epoch: 5| Step: 4
Training loss: 0.5014399290084839
Validation loss: 1.8509238842994935

Epoch: 5| Step: 5
Training loss: 0.555202841758728
Validation loss: 1.8255225125179495

Epoch: 5| Step: 6
Training loss: 0.5877238512039185
Validation loss: 1.8641309404885897

Epoch: 5| Step: 7
Training loss: 0.4477773606777191
Validation loss: 1.793784942678226

Epoch: 5| Step: 8
Training loss: 0.5608645081520081
Validation loss: 1.8449542266066357

Epoch: 5| Step: 9
Training loss: 0.5894477963447571
Validation loss: 1.8252040442600046

Epoch: 5| Step: 10
Training loss: 0.8142491579055786
Validation loss: 1.8249098177879088

Epoch: 731| Step: 0
Training loss: 0.6102101802825928
Validation loss: 1.8816481713325746

Epoch: 5| Step: 1
Training loss: 0.5601764917373657
Validation loss: 1.8593363159446306

Epoch: 5| Step: 2
Training loss: 0.5310930013656616
Validation loss: 1.907851666532537

Epoch: 5| Step: 3
Training loss: 1.1112987995147705
Validation loss: 1.8628313054320633

Epoch: 5| Step: 4
Training loss: 0.6944460868835449
Validation loss: 1.8026339251507995

Epoch: 5| Step: 5
Training loss: 0.7315977215766907
Validation loss: 1.9078383061193651

Epoch: 5| Step: 6
Training loss: 0.6109685897827148
Validation loss: 1.8379525971669022

Epoch: 5| Step: 7
Training loss: 0.4851287007331848
Validation loss: 1.8331468002770537

Epoch: 5| Step: 8
Training loss: 0.4301725924015045
Validation loss: 1.83581284810138

Epoch: 5| Step: 9
Training loss: 0.6130339503288269
Validation loss: 1.8506064338068808

Epoch: 5| Step: 10
Training loss: 0.3308962285518646
Validation loss: 1.8349434150162565

Epoch: 732| Step: 0
Training loss: 0.8153256177902222
Validation loss: 1.8340838493839386

Epoch: 5| Step: 1
Training loss: 0.7521039843559265
Validation loss: 1.8740114588891306

Epoch: 5| Step: 2
Training loss: 0.30652567744255066
Validation loss: 1.8405268173063956

Epoch: 5| Step: 3
Training loss: 0.6214637160301208
Validation loss: 1.7862904058989657

Epoch: 5| Step: 4
Training loss: 0.36978963017463684
Validation loss: 1.8060105500682708

Epoch: 5| Step: 5
Training loss: 0.869888186454773
Validation loss: 1.7991157795793267

Epoch: 5| Step: 6
Training loss: 0.42603039741516113
Validation loss: 1.8765511538392754

Epoch: 5| Step: 7
Training loss: 0.8396328091621399
Validation loss: 1.8703139148732668

Epoch: 5| Step: 8
Training loss: 0.4580468237400055
Validation loss: 1.8384314237102386

Epoch: 5| Step: 9
Training loss: 0.3970402777194977
Validation loss: 1.8455269029063563

Epoch: 5| Step: 10
Training loss: 0.41757094860076904
Validation loss: 1.7944933842587214

Epoch: 733| Step: 0
Training loss: 0.45771676301956177
Validation loss: 1.8450159757368025

Epoch: 5| Step: 1
Training loss: 0.5620212554931641
Validation loss: 1.8542255278556579

Epoch: 5| Step: 2
Training loss: 0.8204232454299927
Validation loss: 1.7906427588514102

Epoch: 5| Step: 3
Training loss: 0.5618802309036255
Validation loss: 1.8685809578946841

Epoch: 5| Step: 4
Training loss: 0.6598631143569946
Validation loss: 1.8454165997043732

Epoch: 5| Step: 5
Training loss: 0.6069179773330688
Validation loss: 1.8412965702754196

Epoch: 5| Step: 6
Training loss: 0.7034391164779663
Validation loss: 1.8277470642520535

Epoch: 5| Step: 7
Training loss: 0.5134965777397156
Validation loss: 1.8308859140642229

Epoch: 5| Step: 8
Training loss: 0.6057506799697876
Validation loss: 1.887964512712212

Epoch: 5| Step: 9
Training loss: 0.2528206408023834
Validation loss: 1.8509432320953698

Epoch: 5| Step: 10
Training loss: 0.5914261341094971
Validation loss: 1.8310391902923584

Epoch: 734| Step: 0
Training loss: 0.42777219414711
Validation loss: 1.8291567217919134

Epoch: 5| Step: 1
Training loss: 0.4436716139316559
Validation loss: 1.81270053181597

Epoch: 5| Step: 2
Training loss: 0.3456219732761383
Validation loss: 1.8601756108704435

Epoch: 5| Step: 3
Training loss: 0.8866841197013855
Validation loss: 1.7860218017332015

Epoch: 5| Step: 4
Training loss: 0.7508753538131714
Validation loss: 1.8173393882730955

Epoch: 5| Step: 5
Training loss: 0.9091777801513672
Validation loss: 1.8753068318931005

Epoch: 5| Step: 6
Training loss: 0.5532387495040894
Validation loss: 1.8424565074264363

Epoch: 5| Step: 7
Training loss: 0.41973885893821716
Validation loss: 1.8758499558253954

Epoch: 5| Step: 8
Training loss: 0.5278934240341187
Validation loss: 1.8898737968937043

Epoch: 5| Step: 9
Training loss: 0.6256228685379028
Validation loss: 1.858710685083943

Epoch: 5| Step: 10
Training loss: 0.7868353128433228
Validation loss: 1.8260369275205879

Epoch: 735| Step: 0
Training loss: 0.7032881379127502
Validation loss: 1.8167147610777168

Epoch: 5| Step: 1
Training loss: 0.9896121025085449
Validation loss: 1.835899963173815

Epoch: 5| Step: 2
Training loss: 0.7610934376716614
Validation loss: 1.8075620589717742

Epoch: 5| Step: 3
Training loss: 0.5649016499519348
Validation loss: 1.8722292870603583

Epoch: 5| Step: 4
Training loss: 0.3426509499549866
Validation loss: 1.8718941570610128

Epoch: 5| Step: 5
Training loss: 0.2392883598804474
Validation loss: 1.8407830064014723

Epoch: 5| Step: 6
Training loss: 0.61192387342453
Validation loss: 1.8215021882005917

Epoch: 5| Step: 7
Training loss: 0.46022066473960876
Validation loss: 1.7791002488905383

Epoch: 5| Step: 8
Training loss: 0.5350218415260315
Validation loss: 1.8156836904505247

Epoch: 5| Step: 9
Training loss: 0.3353630602359772
Validation loss: 1.830511672522432

Epoch: 5| Step: 10
Training loss: 0.6582083702087402
Validation loss: 1.8481205278827297

Epoch: 736| Step: 0
Training loss: 0.5290651917457581
Validation loss: 1.8000289996465046

Epoch: 5| Step: 1
Training loss: 0.3921751379966736
Validation loss: 1.8287155897386613

Epoch: 5| Step: 2
Training loss: 0.356793075799942
Validation loss: 1.844528511006345

Epoch: 5| Step: 3
Training loss: 0.6473520994186401
Validation loss: 1.8341183508596113

Epoch: 5| Step: 4
Training loss: 0.5953577756881714
Validation loss: 1.8301020258216447

Epoch: 5| Step: 5
Training loss: 0.7298125624656677
Validation loss: 1.8214632772630261

Epoch: 5| Step: 6
Training loss: 0.7505338788032532
Validation loss: 1.7788637748328588

Epoch: 5| Step: 7
Training loss: 0.580947995185852
Validation loss: 1.8002136266359718

Epoch: 5| Step: 8
Training loss: 1.0318942070007324
Validation loss: 1.8131986638551116

Epoch: 5| Step: 9
Training loss: 0.48298972845077515
Validation loss: 1.8303056545155023

Epoch: 5| Step: 10
Training loss: 0.3567316234111786
Validation loss: 1.9014653492999334

Epoch: 737| Step: 0
Training loss: 0.6759554743766785
Validation loss: 1.8608631959525488

Epoch: 5| Step: 1
Training loss: 0.7648743391036987
Validation loss: 1.8266073516620103

Epoch: 5| Step: 2
Training loss: 0.7384014129638672
Validation loss: 1.8340012668281473

Epoch: 5| Step: 3
Training loss: 0.652051568031311
Validation loss: 1.862671370147377

Epoch: 5| Step: 4
Training loss: 0.6281946897506714
Validation loss: 1.8369335538597518

Epoch: 5| Step: 5
Training loss: 0.43867403268814087
Validation loss: 1.8085197223130094

Epoch: 5| Step: 6
Training loss: 0.5385304689407349
Validation loss: 1.8161171867001442

Epoch: 5| Step: 7
Training loss: 0.6424015164375305
Validation loss: 1.8384319761747956

Epoch: 5| Step: 8
Training loss: 0.33153969049453735
Validation loss: 1.8656332838919856

Epoch: 5| Step: 9
Training loss: 0.3914913237094879
Validation loss: 1.8483239117489065

Epoch: 5| Step: 10
Training loss: 0.6523597240447998
Validation loss: 1.8273851166489303

Epoch: 738| Step: 0
Training loss: 0.7314731478691101
Validation loss: 1.8381268491027176

Epoch: 5| Step: 1
Training loss: 0.5111672878265381
Validation loss: 1.860187912500033

Epoch: 5| Step: 2
Training loss: 0.45722389221191406
Validation loss: 1.880346211053992

Epoch: 5| Step: 3
Training loss: 0.4645739495754242
Validation loss: 1.8518663580699632

Epoch: 5| Step: 4
Training loss: 0.4371369481086731
Validation loss: 1.8269874434317313

Epoch: 5| Step: 5
Training loss: 0.37227678298950195
Validation loss: 1.8319734527218727

Epoch: 5| Step: 6
Training loss: 0.6447241306304932
Validation loss: 1.8572564522425334

Epoch: 5| Step: 7
Training loss: 0.691280722618103
Validation loss: 1.8005562033704532

Epoch: 5| Step: 8
Training loss: 0.6928083896636963
Validation loss: 1.8122058606916858

Epoch: 5| Step: 9
Training loss: 0.5577493906021118
Validation loss: 1.874666965135964

Epoch: 5| Step: 10
Training loss: 0.4931209683418274
Validation loss: 1.8771748517149238

Epoch: 739| Step: 0
Training loss: 0.5815844535827637
Validation loss: 1.8077550780388616

Epoch: 5| Step: 1
Training loss: 0.8504120111465454
Validation loss: 1.812212380029822

Epoch: 5| Step: 2
Training loss: 0.6686378717422485
Validation loss: 1.8628162466069704

Epoch: 5| Step: 3
Training loss: 0.4755640923976898
Validation loss: 1.8361671945100189

Epoch: 5| Step: 4
Training loss: 0.4626336693763733
Validation loss: 1.820318482255423

Epoch: 5| Step: 5
Training loss: 0.5258016586303711
Validation loss: 1.8298170912650324

Epoch: 5| Step: 6
Training loss: 0.7054538726806641
Validation loss: 1.8202387607225807

Epoch: 5| Step: 7
Training loss: 0.38598549365997314
Validation loss: 1.7541917293302474

Epoch: 5| Step: 8
Training loss: 0.7743099927902222
Validation loss: 1.8086860102991904

Epoch: 5| Step: 9
Training loss: 0.3927151560783386
Validation loss: 1.85121924261893

Epoch: 5| Step: 10
Training loss: 0.42061182856559753
Validation loss: 1.8126276436672415

Epoch: 740| Step: 0
Training loss: 0.7359436750411987
Validation loss: 1.8250198261712187

Epoch: 5| Step: 1
Training loss: 0.5471364259719849
Validation loss: 1.8836449756417224

Epoch: 5| Step: 2
Training loss: 0.6348955035209656
Validation loss: 1.9122792110648206

Epoch: 5| Step: 3
Training loss: 0.5726341009140015
Validation loss: 1.904285878263494

Epoch: 5| Step: 4
Training loss: 0.6281903982162476
Validation loss: 1.8591694255029

Epoch: 5| Step: 5
Training loss: 0.47048911452293396
Validation loss: 1.8110501855932257

Epoch: 5| Step: 6
Training loss: 0.8389164805412292
Validation loss: 1.8107665110659856

Epoch: 5| Step: 7
Training loss: 0.9147531390190125
Validation loss: 1.8333727518717449

Epoch: 5| Step: 8
Training loss: 0.4807418882846832
Validation loss: 1.8165778767678045

Epoch: 5| Step: 9
Training loss: 0.5969414710998535
Validation loss: 1.7822415341613114

Epoch: 5| Step: 10
Training loss: 0.3403373658657074
Validation loss: 1.8296100337018248

Epoch: 741| Step: 0
Training loss: 0.3802317678928375
Validation loss: 1.8306634426116943

Epoch: 5| Step: 1
Training loss: 0.8673915863037109
Validation loss: 1.827317237854004

Epoch: 5| Step: 2
Training loss: 0.6164535284042358
Validation loss: 1.8710675188290176

Epoch: 5| Step: 3
Training loss: 0.6517559289932251
Validation loss: 1.8330217676777993

Epoch: 5| Step: 4
Training loss: 0.6888684034347534
Validation loss: 1.8353299889513242

Epoch: 5| Step: 5
Training loss: 0.2891111969947815
Validation loss: 1.8574616216844129

Epoch: 5| Step: 6
Training loss: 0.324076771736145
Validation loss: 1.8634315408686155

Epoch: 5| Step: 7
Training loss: 0.7118328213691711
Validation loss: 1.8744793476596955

Epoch: 5| Step: 8
Training loss: 0.6117037534713745
Validation loss: 1.8181376226486698

Epoch: 5| Step: 9
Training loss: 0.5877133011817932
Validation loss: 1.8591912241392239

Epoch: 5| Step: 10
Training loss: 0.2765944004058838
Validation loss: 1.8343223294904154

Epoch: 742| Step: 0
Training loss: 0.6215087175369263
Validation loss: 1.7853012713052894

Epoch: 5| Step: 1
Training loss: 0.4167618751525879
Validation loss: 1.785780264485267

Epoch: 5| Step: 2
Training loss: 0.42022019624710083
Validation loss: 1.760104037100269

Epoch: 5| Step: 3
Training loss: 0.4621106684207916
Validation loss: 1.8285291810189523

Epoch: 5| Step: 4
Training loss: 0.7683477997779846
Validation loss: 1.8505851889169345

Epoch: 5| Step: 5
Training loss: 0.4901742935180664
Validation loss: 1.7993429578760618

Epoch: 5| Step: 6
Training loss: 0.45474833250045776
Validation loss: 1.7933598051788986

Epoch: 5| Step: 7
Training loss: 0.7719842195510864
Validation loss: 1.8452730076287382

Epoch: 5| Step: 8
Training loss: 0.47390976548194885
Validation loss: 1.8294491178245955

Epoch: 5| Step: 9
Training loss: 0.8150032162666321
Validation loss: 1.8097734297475507

Epoch: 5| Step: 10
Training loss: 0.6401492953300476
Validation loss: 1.8406259244488132

Epoch: 743| Step: 0
Training loss: 0.6293620467185974
Validation loss: 1.8456889198672386

Epoch: 5| Step: 1
Training loss: 0.4591364860534668
Validation loss: 1.8629805939171904

Epoch: 5| Step: 2
Training loss: 0.5214933156967163
Validation loss: 1.8490177969778738

Epoch: 5| Step: 3
Training loss: 0.3914637565612793
Validation loss: 1.9107796915115849

Epoch: 5| Step: 4
Training loss: 0.521473228931427
Validation loss: 1.8392349661037486

Epoch: 5| Step: 5
Training loss: 0.629158616065979
Validation loss: 1.8059248129526775

Epoch: 5| Step: 6
Training loss: 0.47029638290405273
Validation loss: 1.8010746689252957

Epoch: 5| Step: 7
Training loss: 0.7456070184707642
Validation loss: 1.8300997941724715

Epoch: 5| Step: 8
Training loss: 0.9546409845352173
Validation loss: 1.8200811134871615

Epoch: 5| Step: 9
Training loss: 0.502112090587616
Validation loss: 1.8800806217296149

Epoch: 5| Step: 10
Training loss: 0.592327892780304
Validation loss: 1.8289318328262658

Epoch: 744| Step: 0
Training loss: 0.7556123733520508
Validation loss: 1.808206299299835

Epoch: 5| Step: 1
Training loss: 0.3954789340496063
Validation loss: 1.8294179260089833

Epoch: 5| Step: 2
Training loss: 0.5804451704025269
Validation loss: 1.783760747601909

Epoch: 5| Step: 3
Training loss: 0.5160712003707886
Validation loss: 1.8313678182581419

Epoch: 5| Step: 4
Training loss: 0.7169751524925232
Validation loss: 1.8344223909480597

Epoch: 5| Step: 5
Training loss: 0.6913059949874878
Validation loss: 1.797956197492538

Epoch: 5| Step: 6
Training loss: 0.7856804132461548
Validation loss: 1.8590638432451474

Epoch: 5| Step: 7
Training loss: 0.5420317649841309
Validation loss: 1.8313098645979358

Epoch: 5| Step: 8
Training loss: 0.4290512502193451
Validation loss: 1.8906449438423238

Epoch: 5| Step: 9
Training loss: 0.4648635983467102
Validation loss: 1.870518043477048

Epoch: 5| Step: 10
Training loss: 0.612856388092041
Validation loss: 1.878961286237163

Epoch: 745| Step: 0
Training loss: 0.44932737946510315
Validation loss: 1.8501942747382707

Epoch: 5| Step: 1
Training loss: 0.8202160000801086
Validation loss: 1.870094589007798

Epoch: 5| Step: 2
Training loss: 0.4111087918281555
Validation loss: 1.758524194840462

Epoch: 5| Step: 3
Training loss: 0.4112805724143982
Validation loss: 1.8127473131302865

Epoch: 5| Step: 4
Training loss: 0.9081312417984009
Validation loss: 1.8536573353634085

Epoch: 5| Step: 5
Training loss: 0.6903479695320129
Validation loss: 1.822953688201084

Epoch: 5| Step: 6
Training loss: 0.6845059990882874
Validation loss: 1.7789626441976076

Epoch: 5| Step: 7
Training loss: 0.6260607242584229
Validation loss: 1.8186642296852604

Epoch: 5| Step: 8
Training loss: 0.6786340475082397
Validation loss: 1.804156211114699

Epoch: 5| Step: 9
Training loss: 0.37091925740242004
Validation loss: 1.8096422469744118

Epoch: 5| Step: 10
Training loss: 0.6854858994483948
Validation loss: 1.7959438908484675

Epoch: 746| Step: 0
Training loss: 0.5719419717788696
Validation loss: 1.7803645979973577

Epoch: 5| Step: 1
Training loss: 0.5266129374504089
Validation loss: 1.825689108141007

Epoch: 5| Step: 2
Training loss: 0.4179018437862396
Validation loss: 1.8542955344723118

Epoch: 5| Step: 3
Training loss: 0.3979024887084961
Validation loss: 1.86862015211454

Epoch: 5| Step: 4
Training loss: 0.6895079016685486
Validation loss: 1.8745077117796867

Epoch: 5| Step: 5
Training loss: 0.817736029624939
Validation loss: 1.864930970694429

Epoch: 5| Step: 6
Training loss: 0.5686105489730835
Validation loss: 1.898930747021911

Epoch: 5| Step: 7
Training loss: 0.7498725056648254
Validation loss: 1.8191567518377816

Epoch: 5| Step: 8
Training loss: 0.4183737635612488
Validation loss: 1.7950810847743865

Epoch: 5| Step: 9
Training loss: 0.7296319007873535
Validation loss: 1.8271543133643366

Epoch: 5| Step: 10
Training loss: 0.545461118221283
Validation loss: 1.804865897342723

Epoch: 747| Step: 0
Training loss: 0.43755707144737244
Validation loss: 1.8051595380229335

Epoch: 5| Step: 1
Training loss: 0.5635177493095398
Validation loss: 1.833897836746708

Epoch: 5| Step: 2
Training loss: 0.27783289551734924
Validation loss: 1.8140995092289423

Epoch: 5| Step: 3
Training loss: 0.6885870695114136
Validation loss: 1.8169670386980938

Epoch: 5| Step: 4
Training loss: 0.8425756692886353
Validation loss: 1.7918061876809726

Epoch: 5| Step: 5
Training loss: 0.37919920682907104
Validation loss: 1.8473924949604978

Epoch: 5| Step: 6
Training loss: 0.7993091344833374
Validation loss: 1.8111964605187858

Epoch: 5| Step: 7
Training loss: 0.6095733642578125
Validation loss: 1.858128390004558

Epoch: 5| Step: 8
Training loss: 0.5944865345954895
Validation loss: 1.8881748504536127

Epoch: 5| Step: 9
Training loss: 0.7036836743354797
Validation loss: 1.856861481102564

Epoch: 5| Step: 10
Training loss: 0.5440114736557007
Validation loss: 1.827018153282904

Epoch: 748| Step: 0
Training loss: 0.5213319659233093
Validation loss: 1.8924430390839935

Epoch: 5| Step: 1
Training loss: 0.4788208603858948
Validation loss: 1.8496807185552453

Epoch: 5| Step: 2
Training loss: 0.34503358602523804
Validation loss: 1.815843064297912

Epoch: 5| Step: 3
Training loss: 0.8266052007675171
Validation loss: 1.8131298659950175

Epoch: 5| Step: 4
Training loss: 0.6218129396438599
Validation loss: 1.818954417782445

Epoch: 5| Step: 5
Training loss: 0.4677210748195648
Validation loss: 1.8620196760341685

Epoch: 5| Step: 6
Training loss: 0.48091286420822144
Validation loss: 1.7959089022810741

Epoch: 5| Step: 7
Training loss: 0.5880334973335266
Validation loss: 1.845545866156137

Epoch: 5| Step: 8
Training loss: 0.45502638816833496
Validation loss: 1.834629851002847

Epoch: 5| Step: 9
Training loss: 0.5663690567016602
Validation loss: 1.8189046882813977

Epoch: 5| Step: 10
Training loss: 0.9003943800926208
Validation loss: 1.807800651878439

Epoch: 749| Step: 0
Training loss: 0.46066707372665405
Validation loss: 1.8683699536067184

Epoch: 5| Step: 1
Training loss: 0.6364878416061401
Validation loss: 1.8418593252858808

Epoch: 5| Step: 2
Training loss: 0.5344139337539673
Validation loss: 1.8276261885960896

Epoch: 5| Step: 3
Training loss: 0.43382662534713745
Validation loss: 1.8326758043740385

Epoch: 5| Step: 4
Training loss: 0.7167385816574097
Validation loss: 1.83550630077239

Epoch: 5| Step: 5
Training loss: 0.3630475401878357
Validation loss: 1.8498066753469489

Epoch: 5| Step: 6
Training loss: 0.5462833642959595
Validation loss: 1.7817075957534134

Epoch: 5| Step: 7
Training loss: 0.5385309457778931
Validation loss: 1.8743532101313274

Epoch: 5| Step: 8
Training loss: 0.9516569375991821
Validation loss: 1.8050163240842922

Epoch: 5| Step: 9
Training loss: 0.7664554119110107
Validation loss: 1.859868453394982

Epoch: 5| Step: 10
Training loss: 0.620522677898407
Validation loss: 1.8066754853853615

Epoch: 750| Step: 0
Training loss: 0.5263800024986267
Validation loss: 1.8504692059691235

Epoch: 5| Step: 1
Training loss: 0.8866832852363586
Validation loss: 1.8544780708128406

Epoch: 5| Step: 2
Training loss: 0.8973339200019836
Validation loss: 1.805012841378489

Epoch: 5| Step: 3
Training loss: 0.5720140933990479
Validation loss: 1.8229431336925876

Epoch: 5| Step: 4
Training loss: 0.3991016745567322
Validation loss: 1.8243454989566599

Epoch: 5| Step: 5
Training loss: 0.45383280515670776
Validation loss: 1.8137282094647806

Epoch: 5| Step: 6
Training loss: 0.5418891906738281
Validation loss: 1.8243472242868075

Epoch: 5| Step: 7
Training loss: 0.47416791319847107
Validation loss: 1.8416339594830748

Epoch: 5| Step: 8
Training loss: 0.46339917182922363
Validation loss: 1.8154854184837752

Epoch: 5| Step: 9
Training loss: 0.7492812871932983
Validation loss: 1.879961795704339

Epoch: 5| Step: 10
Training loss: 0.5072957277297974
Validation loss: 1.8312785766458

Testing loss: 2.5661718050638833
