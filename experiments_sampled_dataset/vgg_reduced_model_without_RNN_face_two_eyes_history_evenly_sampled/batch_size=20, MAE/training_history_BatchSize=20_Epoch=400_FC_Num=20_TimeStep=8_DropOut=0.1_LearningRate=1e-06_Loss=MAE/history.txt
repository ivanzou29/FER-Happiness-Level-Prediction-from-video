Epoch: 1| Step: 0
Training loss: 3.6772282123565674
Validation loss: 4.910747604985391

Epoch: 5| Step: 1
Training loss: 4.352578163146973
Validation loss: 4.9057363745986775

Epoch: 5| Step: 2
Training loss: 3.766613483428955
Validation loss: 4.902297901850875

Epoch: 5| Step: 3
Training loss: 4.49456787109375
Validation loss: 4.895984398421421

Epoch: 5| Step: 4
Training loss: 5.796468257904053
Validation loss: 4.887166843619398

Epoch: 5| Step: 5
Training loss: 5.674901008605957
Validation loss: 4.881382983217957

Epoch: 5| Step: 6
Training loss: 4.843069076538086
Validation loss: 4.876868909405124

Epoch: 5| Step: 7
Training loss: 5.466738700866699
Validation loss: 4.869779253518709

Epoch: 5| Step: 8
Training loss: 4.457244873046875
Validation loss: 4.867227118502381

Epoch: 5| Step: 9
Training loss: 4.010809898376465
Validation loss: 4.859894665338659

Epoch: 5| Step: 10
Training loss: 4.9119977951049805
Validation loss: 4.8523615252587105

Epoch: 2| Step: 0
Training loss: 5.059520721435547
Validation loss: 4.843747913196522

Epoch: 5| Step: 1
Training loss: 4.802487850189209
Validation loss: 4.837245833489202

Epoch: 5| Step: 2
Training loss: 4.35476541519165
Validation loss: 4.833478366175005

Epoch: 5| Step: 3
Training loss: 4.141894817352295
Validation loss: 4.825219092830535

Epoch: 5| Step: 4
Training loss: 5.5388994216918945
Validation loss: 4.8172358800006165

Epoch: 5| Step: 5
Training loss: 4.233598709106445
Validation loss: 4.813501224722914

Epoch: 5| Step: 6
Training loss: 5.236563205718994
Validation loss: 4.80844146461897

Epoch: 5| Step: 7
Training loss: 4.661443710327148
Validation loss: 4.802472781109554

Epoch: 5| Step: 8
Training loss: 4.469503879547119
Validation loss: 4.795541296723068

Epoch: 5| Step: 9
Training loss: 3.789024829864502
Validation loss: 4.790834678116665

Epoch: 5| Step: 10
Training loss: 4.364851951599121
Validation loss: 4.783795531078051

Epoch: 3| Step: 0
Training loss: 5.080178260803223
Validation loss: 4.776961895727342

Epoch: 5| Step: 1
Training loss: 4.266721725463867
Validation loss: 4.773165836129137

Epoch: 5| Step: 2
Training loss: 5.350642204284668
Validation loss: 4.766869929529006

Epoch: 5| Step: 3
Training loss: 4.168736934661865
Validation loss: 4.758665889822026

Epoch: 5| Step: 4
Training loss: 4.509339809417725
Validation loss: 4.750749711067446

Epoch: 5| Step: 5
Training loss: 4.514145374298096
Validation loss: 4.746958727477699

Epoch: 5| Step: 6
Training loss: 5.267790794372559
Validation loss: 4.7385850157789005

Epoch: 5| Step: 7
Training loss: 3.8051466941833496
Validation loss: 4.730488095232236

Epoch: 5| Step: 8
Training loss: 4.307675361633301
Validation loss: 4.725587788448538

Epoch: 5| Step: 9
Training loss: 4.1331305503845215
Validation loss: 4.720935585678265

Epoch: 5| Step: 10
Training loss: 4.507071495056152
Validation loss: 4.712209065755208

Epoch: 4| Step: 0
Training loss: 4.439488410949707
Validation loss: 4.707779489537721

Epoch: 5| Step: 1
Training loss: 4.585136890411377
Validation loss: 4.702399930646343

Epoch: 5| Step: 2
Training loss: 5.199125289916992
Validation loss: 4.6970814376749015

Epoch: 5| Step: 3
Training loss: 4.383519172668457
Validation loss: 4.690567883112097

Epoch: 5| Step: 4
Training loss: 5.498290061950684
Validation loss: 4.68243246693765

Epoch: 5| Step: 5
Training loss: 4.805191993713379
Validation loss: 4.677117147753315

Epoch: 5| Step: 6
Training loss: 4.383513450622559
Validation loss: 4.670582791810395

Epoch: 5| Step: 7
Training loss: 3.7965965270996094
Validation loss: 4.662225149011099

Epoch: 5| Step: 8
Training loss: 4.218052864074707
Validation loss: 4.6572294183956675

Epoch: 5| Step: 9
Training loss: 4.348589897155762
Validation loss: 4.649809206685712

Epoch: 5| Step: 10
Training loss: 3.2939035892486572
Validation loss: 4.644903131710586

Epoch: 5| Step: 0
Training loss: 4.9488959312438965
Validation loss: 4.635536224611344

Epoch: 5| Step: 1
Training loss: 5.21543025970459
Validation loss: 4.628367562447825

Epoch: 5| Step: 2
Training loss: 3.751081943511963
Validation loss: 4.622838702253116

Epoch: 5| Step: 3
Training loss: 4.48077917098999
Validation loss: 4.616300172703241

Epoch: 5| Step: 4
Training loss: 3.908916473388672
Validation loss: 4.610117573891917

Epoch: 5| Step: 5
Training loss: 4.019242286682129
Validation loss: 4.601281930041569

Epoch: 5| Step: 6
Training loss: 5.0774688720703125
Validation loss: 4.596112025681363

Epoch: 5| Step: 7
Training loss: 3.9030532836914062
Validation loss: 4.588668689932875

Epoch: 5| Step: 8
Training loss: 4.274417400360107
Validation loss: 4.581135862617082

Epoch: 5| Step: 9
Training loss: 4.545745849609375
Validation loss: 4.573146486795077

Epoch: 5| Step: 10
Training loss: 4.176863193511963
Validation loss: 4.5643501845739225

Epoch: 6| Step: 0
Training loss: 4.571612358093262
Validation loss: 4.558191535293415

Epoch: 5| Step: 1
Training loss: 4.729409217834473
Validation loss: 4.547731245717695

Epoch: 5| Step: 2
Training loss: 4.998000621795654
Validation loss: 4.541703116509222

Epoch: 5| Step: 3
Training loss: 5.242323875427246
Validation loss: 4.536431635579755

Epoch: 5| Step: 4
Training loss: 4.862593173980713
Validation loss: 4.52805818280866

Epoch: 5| Step: 5
Training loss: 4.651568412780762
Validation loss: 4.521983218449418

Epoch: 5| Step: 6
Training loss: 4.865960597991943
Validation loss: 4.509968726865707

Epoch: 5| Step: 7
Training loss: 3.0387046337127686
Validation loss: 4.500204060667304

Epoch: 5| Step: 8
Training loss: 3.448645830154419
Validation loss: 4.493188196612943

Epoch: 5| Step: 9
Training loss: 3.6592135429382324
Validation loss: 4.483438435421195

Epoch: 5| Step: 10
Training loss: 3.2151010036468506
Validation loss: 4.477794088343138

Epoch: 7| Step: 0
Training loss: 3.5302672386169434
Validation loss: 4.465304138839886

Epoch: 5| Step: 1
Training loss: 3.694699764251709
Validation loss: 4.45788558324178

Epoch: 5| Step: 2
Training loss: 3.9876275062561035
Validation loss: 4.449624456385131

Epoch: 5| Step: 3
Training loss: 5.3954973220825195
Validation loss: 4.437355082522156

Epoch: 5| Step: 4
Training loss: 4.838625431060791
Validation loss: 4.431207985006353

Epoch: 5| Step: 5
Training loss: 2.6925625801086426
Validation loss: 4.422700148756786

Epoch: 5| Step: 6
Training loss: 4.005397796630859
Validation loss: 4.409815639577886

Epoch: 5| Step: 7
Training loss: 4.577207088470459
Validation loss: 4.399299108853904

Epoch: 5| Step: 8
Training loss: 4.459380626678467
Validation loss: 4.393222780637844

Epoch: 5| Step: 9
Training loss: 4.7347283363342285
Validation loss: 4.3836559121326735

Epoch: 5| Step: 10
Training loss: 4.504945278167725
Validation loss: 4.377052255856094

Epoch: 8| Step: 0
Training loss: 3.934354305267334
Validation loss: 4.364990895794284

Epoch: 5| Step: 1
Training loss: 4.565325736999512
Validation loss: 4.355643810764436

Epoch: 5| Step: 2
Training loss: 3.0039050579071045
Validation loss: 4.342862062556769

Epoch: 5| Step: 3
Training loss: 3.757047176361084
Validation loss: 4.3337068198829565

Epoch: 5| Step: 4
Training loss: 3.724933624267578
Validation loss: 4.326217020711591

Epoch: 5| Step: 5
Training loss: 3.6831841468811035
Validation loss: 4.315786207875898

Epoch: 5| Step: 6
Training loss: 4.429705619812012
Validation loss: 4.301620016815842

Epoch: 5| Step: 7
Training loss: 3.892059326171875
Validation loss: 4.296071442224646

Epoch: 5| Step: 8
Training loss: 5.174541473388672
Validation loss: 4.28592271702264

Epoch: 5| Step: 9
Training loss: 5.1344709396362305
Validation loss: 4.279241382434804

Epoch: 5| Step: 10
Training loss: 3.9538142681121826
Validation loss: 4.263264174102455

Epoch: 9| Step: 0
Training loss: 2.935492992401123
Validation loss: 4.254313786824544

Epoch: 5| Step: 1
Training loss: 5.342555522918701
Validation loss: 4.245544448975594

Epoch: 5| Step: 2
Training loss: 3.4594688415527344
Validation loss: 4.232048265395626

Epoch: 5| Step: 3
Training loss: 4.567202568054199
Validation loss: 4.225788859910862

Epoch: 5| Step: 4
Training loss: 4.305417537689209
Validation loss: 4.217955753367434

Epoch: 5| Step: 5
Training loss: 3.804708480834961
Validation loss: 4.198743086989208

Epoch: 5| Step: 6
Training loss: 4.8646345138549805
Validation loss: 4.193444851906069

Epoch: 5| Step: 7
Training loss: 3.9598336219787598
Validation loss: 4.181005075413694

Epoch: 5| Step: 8
Training loss: 3.0622363090515137
Validation loss: 4.1701141813749905

Epoch: 5| Step: 9
Training loss: 4.409946441650391
Validation loss: 4.1594262020562285

Epoch: 5| Step: 10
Training loss: 3.306190252304077
Validation loss: 4.147919798410067

Epoch: 10| Step: 0
Training loss: 4.031026363372803
Validation loss: 4.139122834769628

Epoch: 5| Step: 1
Training loss: 4.285190105438232
Validation loss: 4.127402277402981

Epoch: 5| Step: 2
Training loss: 4.529931545257568
Validation loss: 4.114618183464132

Epoch: 5| Step: 3
Training loss: 5.038332939147949
Validation loss: 4.101871816060877

Epoch: 5| Step: 4
Training loss: 4.121858596801758
Validation loss: 4.094550389115528

Epoch: 5| Step: 5
Training loss: 3.9086813926696777
Validation loss: 4.083933004768946

Epoch: 5| Step: 6
Training loss: 2.8823859691619873
Validation loss: 4.06565171928816

Epoch: 5| Step: 7
Training loss: 3.210514545440674
Validation loss: 4.054514595257339

Epoch: 5| Step: 8
Training loss: 3.475193500518799
Validation loss: 4.041588085953907

Epoch: 5| Step: 9
Training loss: 4.050834655761719
Validation loss: 4.032351798908685

Epoch: 5| Step: 10
Training loss: 3.2890894412994385
Validation loss: 4.024580432522681

Epoch: 11| Step: 0
Training loss: 3.7226860523223877
Validation loss: 4.007414602464245

Epoch: 5| Step: 1
Training loss: 3.3248794078826904
Validation loss: 3.9933366980603946

Epoch: 5| Step: 2
Training loss: 3.7544422149658203
Validation loss: 3.9839882414828063

Epoch: 5| Step: 3
Training loss: 3.114534616470337
Validation loss: 3.9690427780151367

Epoch: 5| Step: 4
Training loss: 3.6100268363952637
Validation loss: 3.964568738014467

Epoch: 5| Step: 5
Training loss: 4.19818639755249
Validation loss: 3.947707688936623

Epoch: 5| Step: 6
Training loss: 4.559483528137207
Validation loss: 3.941205099064817

Epoch: 5| Step: 7
Training loss: 3.7935950756073
Validation loss: 3.9293508555299494

Epoch: 5| Step: 8
Training loss: 4.673616409301758
Validation loss: 3.9156592994607906

Epoch: 5| Step: 9
Training loss: 2.5841400623321533
Validation loss: 3.89820921292869

Epoch: 5| Step: 10
Training loss: 4.432972431182861
Validation loss: 3.8923243604680544

Epoch: 12| Step: 0
Training loss: 3.877531051635742
Validation loss: 3.8776141956288326

Epoch: 5| Step: 1
Training loss: 4.154399871826172
Validation loss: 3.869370501528504

Epoch: 5| Step: 2
Training loss: 3.9599547386169434
Validation loss: 3.8589274447451354

Epoch: 5| Step: 3
Training loss: 3.7100396156311035
Validation loss: 3.8437686556129047

Epoch: 5| Step: 4
Training loss: 3.287226915359497
Validation loss: 3.8297469333935807

Epoch: 5| Step: 5
Training loss: 3.858721971511841
Validation loss: 3.8200849820208806

Epoch: 5| Step: 6
Training loss: 3.5275166034698486
Validation loss: 3.803152715006182

Epoch: 5| Step: 7
Training loss: 2.9627928733825684
Validation loss: 3.7886910310355564

Epoch: 5| Step: 8
Training loss: 3.2234489917755127
Validation loss: 3.7828187634868007

Epoch: 5| Step: 9
Training loss: 4.0501203536987305
Validation loss: 3.7668434419939594

Epoch: 5| Step: 10
Training loss: 3.8718597888946533
Validation loss: 3.7593270014691096

Epoch: 13| Step: 0
Training loss: 2.936579942703247
Validation loss: 3.7356362983744633

Epoch: 5| Step: 1
Training loss: 3.9754185676574707
Validation loss: 3.7245912808243946

Epoch: 5| Step: 2
Training loss: 3.498183012008667
Validation loss: 3.7201555980149137

Epoch: 5| Step: 3
Training loss: 3.400465726852417
Validation loss: 3.7068894755455757

Epoch: 5| Step: 4
Training loss: 3.805889844894409
Validation loss: 3.6881481601345922

Epoch: 5| Step: 5
Training loss: 3.466280460357666
Validation loss: 3.682401587886195

Epoch: 5| Step: 6
Training loss: 3.8248302936553955
Validation loss: 3.669333257982808

Epoch: 5| Step: 7
Training loss: 3.482499599456787
Validation loss: 3.649531661823232

Epoch: 5| Step: 8
Training loss: 3.7910377979278564
Validation loss: 3.634507256169473

Epoch: 5| Step: 9
Training loss: 3.229005813598633
Validation loss: 3.620601331034014

Epoch: 5| Step: 10
Training loss: 3.8002350330352783
Validation loss: 3.613526331481113

Epoch: 14| Step: 0
Training loss: 4.190335273742676
Validation loss: 3.6003378642502653

Epoch: 5| Step: 1
Training loss: 3.8373215198516846
Validation loss: 3.5905086558352233

Epoch: 5| Step: 2
Training loss: 3.488762617111206
Validation loss: 3.5694427003142652

Epoch: 5| Step: 3
Training loss: 3.729161024093628
Validation loss: 3.559209854372086

Epoch: 5| Step: 4
Training loss: 3.2126030921936035
Validation loss: 3.5476587357059604

Epoch: 5| Step: 5
Training loss: 2.911212205886841
Validation loss: 3.532959004884125

Epoch: 5| Step: 6
Training loss: 4.188357830047607
Validation loss: 3.5212602615356445

Epoch: 5| Step: 7
Training loss: 2.77239990234375
Validation loss: 3.508554261217835

Epoch: 5| Step: 8
Training loss: 2.1432342529296875
Validation loss: 3.485694326380248

Epoch: 5| Step: 9
Training loss: 3.5460116863250732
Validation loss: 3.477256287810623

Epoch: 5| Step: 10
Training loss: 3.7783203125
Validation loss: 3.4650410734197146

Epoch: 15| Step: 0
Training loss: 3.4684016704559326
Validation loss: 3.4491632266711165

Epoch: 5| Step: 1
Training loss: 3.6707558631896973
Validation loss: 3.42934295182587

Epoch: 5| Step: 2
Training loss: 2.9305527210235596
Validation loss: 3.4132432988894883

Epoch: 5| Step: 3
Training loss: 2.8015849590301514
Validation loss: 3.396970925792571

Epoch: 5| Step: 4
Training loss: 3.030783176422119
Validation loss: 3.3877596829527166

Epoch: 5| Step: 5
Training loss: 2.692180633544922
Validation loss: 3.3583434063901185

Epoch: 5| Step: 6
Training loss: 3.6011085510253906
Validation loss: 3.3456163150008007

Epoch: 5| Step: 7
Training loss: 3.2943031787872314
Validation loss: 3.3368753771628104

Epoch: 5| Step: 8
Training loss: 3.2604804039001465
Validation loss: 3.3157415851469962

Epoch: 5| Step: 9
Training loss: 3.265634059906006
Validation loss: 3.299869350207749

Epoch: 5| Step: 10
Training loss: 4.266031265258789
Validation loss: 3.288369296699442

Epoch: 16| Step: 0
Training loss: 2.2433061599731445
Validation loss: 3.270078659057617

Epoch: 5| Step: 1
Training loss: 2.9290177822113037
Validation loss: 3.258332503739224

Epoch: 5| Step: 2
Training loss: 2.854644298553467
Validation loss: 3.2492980572485153

Epoch: 5| Step: 3
Training loss: 3.392399549484253
Validation loss: 3.230096758052867

Epoch: 5| Step: 4
Training loss: 2.9154019355773926
Validation loss: 3.21124207076206

Epoch: 5| Step: 5
Training loss: 3.8961784839630127
Validation loss: 3.1921803823081394

Epoch: 5| Step: 6
Training loss: 3.1247000694274902
Validation loss: 3.178940139791017

Epoch: 5| Step: 7
Training loss: 4.069856643676758
Validation loss: 3.1694527723455943

Epoch: 5| Step: 8
Training loss: 3.585176467895508
Validation loss: 3.1433516958708405

Epoch: 5| Step: 9
Training loss: 2.8916373252868652
Validation loss: 3.1261305578293337

Epoch: 5| Step: 10
Training loss: 2.528632164001465
Validation loss: 3.113214518434258

Epoch: 17| Step: 0
Training loss: 3.6751599311828613
Validation loss: 3.096145301736811

Epoch: 5| Step: 1
Training loss: 2.510871171951294
Validation loss: 3.0835673885960735

Epoch: 5| Step: 2
Training loss: 3.024400234222412
Validation loss: 3.063815842392624

Epoch: 5| Step: 3
Training loss: 2.483144760131836
Validation loss: 3.0374717353492655

Epoch: 5| Step: 4
Training loss: 3.654036045074463
Validation loss: 3.028416141386955

Epoch: 5| Step: 5
Training loss: 2.724114179611206
Validation loss: 3.008947169908913

Epoch: 5| Step: 6
Training loss: 3.1713709831237793
Validation loss: 2.997137690103182

Epoch: 5| Step: 7
Training loss: 3.0078604221343994
Validation loss: 2.977074166779877

Epoch: 5| Step: 8
Training loss: 2.8116016387939453
Validation loss: 2.9591676035235004

Epoch: 5| Step: 9
Training loss: 3.42661714553833
Validation loss: 2.939297568413519

Epoch: 5| Step: 10
Training loss: 2.653172731399536
Validation loss: 2.9237922596675094

Epoch: 18| Step: 0
Training loss: 3.359588146209717
Validation loss: 2.911470164534866

Epoch: 5| Step: 1
Training loss: 3.1704206466674805
Validation loss: 2.8962156541885866

Epoch: 5| Step: 2
Training loss: 3.375073194503784
Validation loss: 2.878037121988112

Epoch: 5| Step: 3
Training loss: 2.775023937225342
Validation loss: 2.868777915995608

Epoch: 5| Step: 4
Training loss: 2.4344351291656494
Validation loss: 2.849297579898629

Epoch: 5| Step: 5
Training loss: 3.1000447273254395
Validation loss: 2.828153271828928

Epoch: 5| Step: 6
Training loss: 2.9221980571746826
Validation loss: 2.8137256740241923

Epoch: 5| Step: 7
Training loss: 2.738133192062378
Validation loss: 2.8032996039236746

Epoch: 5| Step: 8
Training loss: 2.895493984222412
Validation loss: 2.7865747482545915

Epoch: 5| Step: 9
Training loss: 2.752812623977661
Validation loss: 2.7736767812441756

Epoch: 5| Step: 10
Training loss: 2.1212921142578125
Validation loss: 2.7589236561970045

Epoch: 19| Step: 0
Training loss: 2.7439723014831543
Validation loss: 2.7322706689116774

Epoch: 5| Step: 1
Training loss: 2.7639100551605225
Validation loss: 2.7229820938520533

Epoch: 5| Step: 2
Training loss: 2.771174192428589
Validation loss: 2.7091635452803744

Epoch: 5| Step: 3
Training loss: 2.93725848197937
Validation loss: 2.6919073084349274

Epoch: 5| Step: 4
Training loss: 2.1581883430480957
Validation loss: 2.6843638676469044

Epoch: 5| Step: 5
Training loss: 3.037292003631592
Validation loss: 2.6574175921819543

Epoch: 5| Step: 6
Training loss: 2.873802661895752
Validation loss: 2.6540937064796366

Epoch: 5| Step: 7
Training loss: 2.963045358657837
Validation loss: 2.632922431474091

Epoch: 5| Step: 8
Training loss: 2.551504135131836
Validation loss: 2.611641355740127

Epoch: 5| Step: 9
Training loss: 2.7724578380584717
Validation loss: 2.602126657321889

Epoch: 5| Step: 10
Training loss: 3.0091335773468018
Validation loss: 2.582630824017268

Epoch: 20| Step: 0
Training loss: 2.804600715637207
Validation loss: 2.57141367338037

Epoch: 5| Step: 1
Training loss: 3.127805233001709
Validation loss: 2.560295861254456

Epoch: 5| Step: 2
Training loss: 2.6345038414001465
Validation loss: 2.5516246954600015

Epoch: 5| Step: 3
Training loss: 2.35528826713562
Validation loss: 2.5329715615959576

Epoch: 5| Step: 4
Training loss: 2.5716423988342285
Validation loss: 2.5165000141307874

Epoch: 5| Step: 5
Training loss: 2.705453872680664
Validation loss: 2.505182707181541

Epoch: 5| Step: 6
Training loss: 2.3447234630584717
Validation loss: 2.5004939353594215

Epoch: 5| Step: 7
Training loss: 3.477792739868164
Validation loss: 2.4886109239311627

Epoch: 5| Step: 8
Training loss: 2.299988269805908
Validation loss: 2.474803811760359

Epoch: 5| Step: 9
Training loss: 2.231048107147217
Validation loss: 2.4625230117510726

Epoch: 5| Step: 10
Training loss: 2.8304007053375244
Validation loss: 2.4405832265013006

Epoch: 21| Step: 0
Training loss: 2.713719606399536
Validation loss: 2.4234545974321264

Epoch: 5| Step: 1
Training loss: 2.831219434738159
Validation loss: 2.4241603036080637

Epoch: 5| Step: 2
Training loss: 2.221320629119873
Validation loss: 2.405547175356137

Epoch: 5| Step: 3
Training loss: 2.110024929046631
Validation loss: 2.3989496641261603

Epoch: 5| Step: 4
Training loss: 1.7546236515045166
Validation loss: 2.3807519174391225

Epoch: 5| Step: 5
Training loss: 3.271939754486084
Validation loss: 2.3601277797452864

Epoch: 5| Step: 6
Training loss: 2.726414442062378
Validation loss: 2.352862045329104

Epoch: 5| Step: 7
Training loss: 3.108229160308838
Validation loss: 2.343393207878195

Epoch: 5| Step: 8
Training loss: 2.9519641399383545
Validation loss: 2.346492176414818

Epoch: 5| Step: 9
Training loss: 2.203338146209717
Validation loss: 2.3241539360374532

Epoch: 5| Step: 10
Training loss: 2.5252625942230225
Validation loss: 2.3150236709143526

Epoch: 22| Step: 0
Training loss: 3.0178427696228027
Validation loss: 2.305347837427611

Epoch: 5| Step: 1
Training loss: 2.0259604454040527
Validation loss: 2.305570488334984

Epoch: 5| Step: 2
Training loss: 2.6580913066864014
Validation loss: 2.296413972813596

Epoch: 5| Step: 3
Training loss: 2.5126748085021973
Validation loss: 2.2782088454051683

Epoch: 5| Step: 4
Training loss: 2.296766996383667
Validation loss: 2.2844736037715787

Epoch: 5| Step: 5
Training loss: 2.4503324031829834
Validation loss: 2.270325909378708

Epoch: 5| Step: 6
Training loss: 2.9721083641052246
Validation loss: 2.275254741791756

Epoch: 5| Step: 7
Training loss: 2.2141802310943604
Validation loss: 2.2666347975371988

Epoch: 5| Step: 8
Training loss: 2.1039071083068848
Validation loss: 2.2531595383920977

Epoch: 5| Step: 9
Training loss: 2.60654616355896
Validation loss: 2.250870563650644

Epoch: 5| Step: 10
Training loss: 3.17962908744812
Validation loss: 2.2378400807739585

Epoch: 23| Step: 0
Training loss: 2.455902099609375
Validation loss: 2.249932168632425

Epoch: 5| Step: 1
Training loss: 2.685004949569702
Validation loss: 2.250336226596627

Epoch: 5| Step: 2
Training loss: 2.589137554168701
Validation loss: 2.230869431649485

Epoch: 5| Step: 3
Training loss: 2.1252224445343018
Validation loss: 2.2232697625314035

Epoch: 5| Step: 4
Training loss: 2.6872830390930176
Validation loss: 2.2234722927052486

Epoch: 5| Step: 5
Training loss: 2.298424243927002
Validation loss: 2.219057854785714

Epoch: 5| Step: 6
Training loss: 2.5516748428344727
Validation loss: 2.2291057468742452

Epoch: 5| Step: 7
Training loss: 2.6417174339294434
Validation loss: 2.205025578057894

Epoch: 5| Step: 8
Training loss: 2.3276562690734863
Validation loss: 2.2139657646097164

Epoch: 5| Step: 9
Training loss: 2.1713950634002686
Validation loss: 2.2050336560895367

Epoch: 5| Step: 10
Training loss: 2.9931132793426514
Validation loss: 2.1909407902789373

Epoch: 24| Step: 0
Training loss: 2.3076395988464355
Validation loss: 2.1946923591757335

Epoch: 5| Step: 1
Training loss: 2.3415207862854004
Validation loss: 2.1998067825071272

Epoch: 5| Step: 2
Training loss: 2.8765876293182373
Validation loss: 2.193227211634318

Epoch: 5| Step: 3
Training loss: 2.6514647006988525
Validation loss: 2.201197960043466

Epoch: 5| Step: 4
Training loss: 2.1575047969818115
Validation loss: 2.1695358932659192

Epoch: 5| Step: 5
Training loss: 2.7859623432159424
Validation loss: 2.1834508270345707

Epoch: 5| Step: 6
Training loss: 2.5774781703948975
Validation loss: 2.1798342120262886

Epoch: 5| Step: 7
Training loss: 2.9806716442108154
Validation loss: 2.169554356605776

Epoch: 5| Step: 8
Training loss: 1.6670011281967163
Validation loss: 2.1650985748537126

Epoch: 5| Step: 9
Training loss: 2.6084141731262207
Validation loss: 2.1548994471949916

Epoch: 5| Step: 10
Training loss: 2.324338912963867
Validation loss: 2.162472604423441

Epoch: 25| Step: 0
Training loss: 2.6190991401672363
Validation loss: 2.1667341391245523

Epoch: 5| Step: 1
Training loss: 2.367295742034912
Validation loss: 2.1633441307211436

Epoch: 5| Step: 2
Training loss: 2.256944417953491
Validation loss: 2.162176021965601

Epoch: 5| Step: 3
Training loss: 3.1291613578796387
Validation loss: 2.1400355139086322

Epoch: 5| Step: 4
Training loss: 2.6491971015930176
Validation loss: 2.1559084589763353

Epoch: 5| Step: 5
Training loss: 2.1117868423461914
Validation loss: 2.160953594792274

Epoch: 5| Step: 6
Training loss: 2.9560790061950684
Validation loss: 2.1499932786469818

Epoch: 5| Step: 7
Training loss: 2.2995636463165283
Validation loss: 2.1486302037392893

Epoch: 5| Step: 8
Training loss: 2.49806547164917
Validation loss: 2.1546632448832193

Epoch: 5| Step: 9
Training loss: 1.8140207529067993
Validation loss: 2.1476849150914017

Epoch: 5| Step: 10
Training loss: 2.367664098739624
Validation loss: 2.1388033743827575

Epoch: 26| Step: 0
Training loss: 1.8176645040512085
Validation loss: 2.1362054347991943

Epoch: 5| Step: 1
Training loss: 2.1703078746795654
Validation loss: 2.141239620024158

Epoch: 5| Step: 2
Training loss: 2.435199022293091
Validation loss: 2.145738265847647

Epoch: 5| Step: 3
Training loss: 3.1090331077575684
Validation loss: 2.140484827820973

Epoch: 5| Step: 4
Training loss: 2.457979679107666
Validation loss: 2.128209501184443

Epoch: 5| Step: 5
Training loss: 2.8251757621765137
Validation loss: 2.1456981012898106

Epoch: 5| Step: 6
Training loss: 2.4396324157714844
Validation loss: 2.139581690552414

Epoch: 5| Step: 7
Training loss: 3.2007007598876953
Validation loss: 2.128683300428493

Epoch: 5| Step: 8
Training loss: 1.972515344619751
Validation loss: 2.14108209712531

Epoch: 5| Step: 9
Training loss: 2.0310683250427246
Validation loss: 2.141247723692207

Epoch: 5| Step: 10
Training loss: 2.6066949367523193
Validation loss: 2.135960760936942

Epoch: 27| Step: 0
Training loss: 2.501502513885498
Validation loss: 2.1289612964917253

Epoch: 5| Step: 1
Training loss: 2.2957749366760254
Validation loss: 2.1344853626784457

Epoch: 5| Step: 2
Training loss: 2.005092144012451
Validation loss: 2.1382308954833658

Epoch: 5| Step: 3
Training loss: 2.6282570362091064
Validation loss: 2.123575472062634

Epoch: 5| Step: 4
Training loss: 2.5249385833740234
Validation loss: 2.1297215005402923

Epoch: 5| Step: 5
Training loss: 2.801711320877075
Validation loss: 2.1241834420029835

Epoch: 5| Step: 6
Training loss: 2.9845762252807617
Validation loss: 2.1176636603570755

Epoch: 5| Step: 7
Training loss: 2.2303054332733154
Validation loss: 2.1267085229196856

Epoch: 5| Step: 8
Training loss: 2.278291702270508
Validation loss: 2.118220757412654

Epoch: 5| Step: 9
Training loss: 2.262493133544922
Validation loss: 2.1217040682351715

Epoch: 5| Step: 10
Training loss: 2.429405689239502
Validation loss: 2.124116119518075

Epoch: 28| Step: 0
Training loss: 2.4142262935638428
Validation loss: 2.114359281396353

Epoch: 5| Step: 1
Training loss: 3.1008460521698
Validation loss: 2.123878312367265

Epoch: 5| Step: 2
Training loss: 2.351306676864624
Validation loss: 2.1071907627967095

Epoch: 5| Step: 3
Training loss: 2.2617621421813965
Validation loss: 2.117291881192115

Epoch: 5| Step: 4
Training loss: 1.7652696371078491
Validation loss: 2.1175340785775134

Epoch: 5| Step: 5
Training loss: 2.195387840270996
Validation loss: 2.116232019598766

Epoch: 5| Step: 6
Training loss: 2.9578003883361816
Validation loss: 2.115456687506809

Epoch: 5| Step: 7
Training loss: 2.694432497024536
Validation loss: 2.1051578239728044

Epoch: 5| Step: 8
Training loss: 1.7175724506378174
Validation loss: 2.1137698773414857

Epoch: 5| Step: 9
Training loss: 2.754727840423584
Validation loss: 2.1080892701302805

Epoch: 5| Step: 10
Training loss: 2.7054338455200195
Validation loss: 2.0976006625801005

Epoch: 29| Step: 0
Training loss: 2.0639920234680176
Validation loss: 2.0909390449523926

Epoch: 5| Step: 1
Training loss: 3.099611282348633
Validation loss: 2.1019229042914604

Epoch: 5| Step: 2
Training loss: 2.6247732639312744
Validation loss: 2.0979109041152464

Epoch: 5| Step: 3
Training loss: 2.155726432800293
Validation loss: 2.095727297567552

Epoch: 5| Step: 4
Training loss: 2.2201943397521973
Validation loss: 2.091669072387039

Epoch: 5| Step: 5
Training loss: 3.036486864089966
Validation loss: 2.1000928366056053

Epoch: 5| Step: 6
Training loss: 2.179978847503662
Validation loss: 2.095242351614019

Epoch: 5| Step: 7
Training loss: 2.189971923828125
Validation loss: 2.0909273983329855

Epoch: 5| Step: 8
Training loss: 2.9139180183410645
Validation loss: 2.0851962386920886

Epoch: 5| Step: 9
Training loss: 2.091607093811035
Validation loss: 2.0962351932320544

Epoch: 5| Step: 10
Training loss: 2.2332749366760254
Validation loss: 2.084963877995809

Epoch: 30| Step: 0
Training loss: 2.450465679168701
Validation loss: 2.0952959868215744

Epoch: 5| Step: 1
Training loss: 2.677879571914673
Validation loss: 2.0946114165808565

Epoch: 5| Step: 2
Training loss: 3.0774898529052734
Validation loss: 2.088542310140466

Epoch: 5| Step: 3
Training loss: 2.393289804458618
Validation loss: 2.0858897393749607

Epoch: 5| Step: 4
Training loss: 1.999251365661621
Validation loss: 2.0861963431040444

Epoch: 5| Step: 5
Training loss: 1.8469527959823608
Validation loss: 2.0991286193170855

Epoch: 5| Step: 6
Training loss: 2.1294217109680176
Validation loss: 2.082394448659753

Epoch: 5| Step: 7
Training loss: 2.644902229309082
Validation loss: 2.076990919728433

Epoch: 5| Step: 8
Training loss: 1.916189432144165
Validation loss: 2.0938819839108374

Epoch: 5| Step: 9
Training loss: 3.13958740234375
Validation loss: 2.0830382224052184

Epoch: 5| Step: 10
Training loss: 2.5214152336120605
Validation loss: 2.0867839833741546

Epoch: 31| Step: 0
Training loss: 2.657912492752075
Validation loss: 2.088876132042177

Epoch: 5| Step: 1
Training loss: 2.060816526412964
Validation loss: 2.09211834784477

Epoch: 5| Step: 2
Training loss: 2.0646281242370605
Validation loss: 2.0842519344822055

Epoch: 5| Step: 3
Training loss: 2.0635151863098145
Validation loss: 2.0782549663256575

Epoch: 5| Step: 4
Training loss: 2.3644001483917236
Validation loss: 2.0702511008067797

Epoch: 5| Step: 5
Training loss: 2.4820237159729004
Validation loss: 2.087130097932713

Epoch: 5| Step: 6
Training loss: 2.3786463737487793
Validation loss: 2.0749255188049807

Epoch: 5| Step: 7
Training loss: 2.7447381019592285
Validation loss: 2.068335384450933

Epoch: 5| Step: 8
Training loss: 2.8962414264678955
Validation loss: 2.0648047911223544

Epoch: 5| Step: 9
Training loss: 2.501624584197998
Validation loss: 2.0768608393207675

Epoch: 5| Step: 10
Training loss: 2.452413558959961
Validation loss: 2.067922233253397

Epoch: 32| Step: 0
Training loss: 2.61745285987854
Validation loss: 2.0755094020597395

Epoch: 5| Step: 1
Training loss: 2.29179310798645
Validation loss: 2.091775394255115

Epoch: 5| Step: 2
Training loss: 2.1966309547424316
Validation loss: 2.0638284170499412

Epoch: 5| Step: 3
Training loss: 2.707988977432251
Validation loss: 2.08518914253481

Epoch: 5| Step: 4
Training loss: 2.579299211502075
Validation loss: 2.0786705786182034

Epoch: 5| Step: 5
Training loss: 2.2518770694732666
Validation loss: 2.0800400728820474

Epoch: 5| Step: 6
Training loss: 2.4528045654296875
Validation loss: 2.0934042956239436

Epoch: 5| Step: 7
Training loss: 2.029237985610962
Validation loss: 2.0802816139754428

Epoch: 5| Step: 8
Training loss: 2.3849880695343018
Validation loss: 2.0819755651617564

Epoch: 5| Step: 9
Training loss: 2.235102415084839
Validation loss: 2.079287605900918

Epoch: 5| Step: 10
Training loss: 2.9823570251464844
Validation loss: 2.085030855671052

Epoch: 33| Step: 0
Training loss: 2.973233461380005
Validation loss: 2.0790721690782936

Epoch: 5| Step: 1
Training loss: 2.109945774078369
Validation loss: 2.087627774925642

Epoch: 5| Step: 2
Training loss: 2.24406361579895
Validation loss: 2.0860909467102378

Epoch: 5| Step: 3
Training loss: 1.827288031578064
Validation loss: 2.0820334829309934

Epoch: 5| Step: 4
Training loss: 2.718587636947632
Validation loss: 2.0881569270164735

Epoch: 5| Step: 5
Training loss: 2.367300510406494
Validation loss: 2.083409999006538

Epoch: 5| Step: 6
Training loss: 2.0691592693328857
Validation loss: 2.0809696233400734

Epoch: 5| Step: 7
Training loss: 2.5576696395874023
Validation loss: 2.0778812695575017

Epoch: 5| Step: 8
Training loss: 2.4215705394744873
Validation loss: 2.085770683903848

Epoch: 5| Step: 9
Training loss: 2.5249228477478027
Validation loss: 2.086094715261972

Epoch: 5| Step: 10
Training loss: 2.7745673656463623
Validation loss: 2.0787650923575125

Epoch: 34| Step: 0
Training loss: 2.5828826427459717
Validation loss: 2.0764351955024143

Epoch: 5| Step: 1
Training loss: 2.606645107269287
Validation loss: 2.0802726489241405

Epoch: 5| Step: 2
Training loss: 1.8953478336334229
Validation loss: 2.0787150975196593

Epoch: 5| Step: 3
Training loss: 2.4365592002868652
Validation loss: 2.0791645165412658

Epoch: 5| Step: 4
Training loss: 3.0167317390441895
Validation loss: 2.0567351618120746

Epoch: 5| Step: 5
Training loss: 2.5076966285705566
Validation loss: 2.077584989609257

Epoch: 5| Step: 6
Training loss: 2.8311610221862793
Validation loss: 2.0877659346467707

Epoch: 5| Step: 7
Training loss: 1.683477759361267
Validation loss: 2.0762056304562475

Epoch: 5| Step: 8
Training loss: 2.1011476516723633
Validation loss: 2.0678580063645557

Epoch: 5| Step: 9
Training loss: 2.460369348526001
Validation loss: 2.075616612229296

Epoch: 5| Step: 10
Training loss: 2.4300124645233154
Validation loss: 2.07112915285172

Epoch: 35| Step: 0
Training loss: 2.1845107078552246
Validation loss: 2.0802915570556477

Epoch: 5| Step: 1
Training loss: 2.477982997894287
Validation loss: 2.0682281447995092

Epoch: 5| Step: 2
Training loss: 2.3180856704711914
Validation loss: 2.0681364023557274

Epoch: 5| Step: 3
Training loss: 2.3792724609375
Validation loss: 2.070589232188399

Epoch: 5| Step: 4
Training loss: 2.7137362957000732
Validation loss: 2.063725512514832

Epoch: 5| Step: 5
Training loss: 2.57672381401062
Validation loss: 2.0664276153810563

Epoch: 5| Step: 6
Training loss: 2.755358934402466
Validation loss: 2.067022687645369

Epoch: 5| Step: 7
Training loss: 2.742141008377075
Validation loss: 2.074903921414447

Epoch: 5| Step: 8
Training loss: 2.4357078075408936
Validation loss: 2.064023002501457

Epoch: 5| Step: 9
Training loss: 1.6271165609359741
Validation loss: 2.0656888510591243

Epoch: 5| Step: 10
Training loss: 2.1882572174072266
Validation loss: 2.0638874077027842

Epoch: 36| Step: 0
Training loss: 2.245861291885376
Validation loss: 2.0554045297766246

Epoch: 5| Step: 1
Training loss: 2.149034023284912
Validation loss: 2.0617734052801646

Epoch: 5| Step: 2
Training loss: 2.795701742172241
Validation loss: 2.0816978536626345

Epoch: 5| Step: 3
Training loss: 2.1492581367492676
Validation loss: 2.0714008692772157

Epoch: 5| Step: 4
Training loss: 2.185502052307129
Validation loss: 2.0689165387102353

Epoch: 5| Step: 5
Training loss: 2.497102737426758
Validation loss: 2.0640209464616674

Epoch: 5| Step: 6
Training loss: 2.4701693058013916
Validation loss: 2.059298042328127

Epoch: 5| Step: 7
Training loss: 2.416023015975952
Validation loss: 2.0770319328513196

Epoch: 5| Step: 8
Training loss: 1.7599754333496094
Validation loss: 2.0634316616160895

Epoch: 5| Step: 9
Training loss: 2.915360927581787
Validation loss: 2.065397265136883

Epoch: 5| Step: 10
Training loss: 2.9357354640960693
Validation loss: 2.070949431388609

Epoch: 37| Step: 0
Training loss: 2.8620657920837402
Validation loss: 2.054910680299164

Epoch: 5| Step: 1
Training loss: 2.501753330230713
Validation loss: 2.0790923308300715

Epoch: 5| Step: 2
Training loss: 2.0625386238098145
Validation loss: 2.0813310941060386

Epoch: 5| Step: 3
Training loss: 2.865273952484131
Validation loss: 2.086760884972029

Epoch: 5| Step: 4
Training loss: 2.8787143230438232
Validation loss: 2.06246680085377

Epoch: 5| Step: 5
Training loss: 2.1024985313415527
Validation loss: 2.0636103460865636

Epoch: 5| Step: 6
Training loss: 1.928166151046753
Validation loss: 2.06555776698615

Epoch: 5| Step: 7
Training loss: 2.3684027194976807
Validation loss: 2.0691626418021416

Epoch: 5| Step: 8
Training loss: 2.525080919265747
Validation loss: 2.0660680827274116

Epoch: 5| Step: 9
Training loss: 2.5068106651306152
Validation loss: 2.066228376921787

Epoch: 5| Step: 10
Training loss: 1.575486660003662
Validation loss: 2.0702987973408034

Epoch: 38| Step: 0
Training loss: 2.326795816421509
Validation loss: 2.0562693970177763

Epoch: 5| Step: 1
Training loss: 2.6407980918884277
Validation loss: 2.081331237669914

Epoch: 5| Step: 2
Training loss: 2.2782795429229736
Validation loss: 2.0789224409287974

Epoch: 5| Step: 3
Training loss: 2.4649951457977295
Validation loss: 2.0826624747245543

Epoch: 5| Step: 4
Training loss: 2.2285983562469482
Validation loss: 2.0771224960204093

Epoch: 5| Step: 5
Training loss: 2.096280574798584
Validation loss: 2.0799399806607153

Epoch: 5| Step: 6
Training loss: 2.7018370628356934
Validation loss: 2.0692182330675024

Epoch: 5| Step: 7
Training loss: 2.0228474140167236
Validation loss: 2.069965280512328

Epoch: 5| Step: 8
Training loss: 2.0706357955932617
Validation loss: 2.0646829861466602

Epoch: 5| Step: 9
Training loss: 2.718156337738037
Validation loss: 2.0636656515059935

Epoch: 5| Step: 10
Training loss: 2.7093148231506348
Validation loss: 2.0582042317236624

Epoch: 39| Step: 0
Training loss: 2.344719648361206
Validation loss: 2.0574792251792005

Epoch: 5| Step: 1
Training loss: 2.659249782562256
Validation loss: 2.067244211832682

Epoch: 5| Step: 2
Training loss: 2.1222825050354004
Validation loss: 2.06011749211178

Epoch: 5| Step: 3
Training loss: 1.5332858562469482
Validation loss: 2.044571407379643

Epoch: 5| Step: 4
Training loss: 1.9596248865127563
Validation loss: 2.0613309260337584

Epoch: 5| Step: 5
Training loss: 3.4054744243621826
Validation loss: 2.0594366263317805

Epoch: 5| Step: 6
Training loss: 2.267359495162964
Validation loss: 2.0680796254065728

Epoch: 5| Step: 7
Training loss: 2.4375579357147217
Validation loss: 2.0631527029057986

Epoch: 5| Step: 8
Training loss: 2.5057365894317627
Validation loss: 2.048632844801872

Epoch: 5| Step: 9
Training loss: 2.2573447227478027
Validation loss: 2.0729457896242858

Epoch: 5| Step: 10
Training loss: 2.7315332889556885
Validation loss: 2.079418954028878

Epoch: 40| Step: 0
Training loss: 1.829493522644043
Validation loss: 2.0638562786963677

Epoch: 5| Step: 1
Training loss: 2.2761173248291016
Validation loss: 2.06086721984289

Epoch: 5| Step: 2
Training loss: 2.194255828857422
Validation loss: 2.0744952283879763

Epoch: 5| Step: 3
Training loss: 2.7948436737060547
Validation loss: 2.07026780292552

Epoch: 5| Step: 4
Training loss: 1.52195405960083
Validation loss: 2.0612796096391577

Epoch: 5| Step: 5
Training loss: 2.357854127883911
Validation loss: 2.0679235663465274

Epoch: 5| Step: 6
Training loss: 2.076467990875244
Validation loss: 2.0733109725418912

Epoch: 5| Step: 7
Training loss: 2.5022480487823486
Validation loss: 2.0659018613958873

Epoch: 5| Step: 8
Training loss: 3.147822856903076
Validation loss: 2.0746491186080442

Epoch: 5| Step: 9
Training loss: 2.9074978828430176
Validation loss: 2.0592498804933284

Epoch: 5| Step: 10
Training loss: 2.611420154571533
Validation loss: 2.0576478627420243

Epoch: 41| Step: 0
Training loss: 2.7214818000793457
Validation loss: 2.053547059336016

Epoch: 5| Step: 1
Training loss: 2.340265989303589
Validation loss: 2.0548255661482453

Epoch: 5| Step: 2
Training loss: 2.7706263065338135
Validation loss: 2.046705315189977

Epoch: 5| Step: 3
Training loss: 2.1817615032196045
Validation loss: 2.06622322528593

Epoch: 5| Step: 4
Training loss: 2.587092161178589
Validation loss: 2.0720405117157967

Epoch: 5| Step: 5
Training loss: 2.186647891998291
Validation loss: 2.060132654764319

Epoch: 5| Step: 6
Training loss: 2.923849582672119
Validation loss: 2.0742801517568608

Epoch: 5| Step: 7
Training loss: 1.9328925609588623
Validation loss: 2.0589471786252913

Epoch: 5| Step: 8
Training loss: 2.2271032333374023
Validation loss: 2.0598306604610976

Epoch: 5| Step: 9
Training loss: 2.0361714363098145
Validation loss: 2.0597437863708823

Epoch: 5| Step: 10
Training loss: 2.225843667984009
Validation loss: 2.0691977059969338

Epoch: 42| Step: 0
Training loss: 2.301018238067627
Validation loss: 2.072079263707643

Epoch: 5| Step: 1
Training loss: 2.229872226715088
Validation loss: 2.051659091826408

Epoch: 5| Step: 2
Training loss: 2.1288084983825684
Validation loss: 2.0634517951678206

Epoch: 5| Step: 3
Training loss: 1.9573091268539429
Validation loss: 2.0687916125020673

Epoch: 5| Step: 4
Training loss: 2.3194572925567627
Validation loss: 2.0574415306891165

Epoch: 5| Step: 5
Training loss: 2.7231669425964355
Validation loss: 2.072063344781117

Epoch: 5| Step: 6
Training loss: 2.4460229873657227
Validation loss: 2.060472108984506

Epoch: 5| Step: 7
Training loss: 2.5427730083465576
Validation loss: 2.0594810798604

Epoch: 5| Step: 8
Training loss: 2.7141661643981934
Validation loss: 2.0705729325612388

Epoch: 5| Step: 9
Training loss: 2.178225040435791
Validation loss: 2.070856841661597

Epoch: 5| Step: 10
Training loss: 2.6014325618743896
Validation loss: 2.0716501282107447

Epoch: 43| Step: 0
Training loss: 2.705117702484131
Validation loss: 2.0703772293624056

Epoch: 5| Step: 1
Training loss: 2.2103047370910645
Validation loss: 2.061503659012497

Epoch: 5| Step: 2
Training loss: 3.171987533569336
Validation loss: 2.0600859862501903

Epoch: 5| Step: 3
Training loss: 2.1331965923309326
Validation loss: 2.0727323306504117

Epoch: 5| Step: 4
Training loss: 2.0348894596099854
Validation loss: 2.066995164399506

Epoch: 5| Step: 5
Training loss: 2.5368759632110596
Validation loss: 2.060760574956094

Epoch: 5| Step: 6
Training loss: 1.7681430578231812
Validation loss: 2.0662242776604107

Epoch: 5| Step: 7
Training loss: 2.8837549686431885
Validation loss: 2.0799561290330786

Epoch: 5| Step: 8
Training loss: 2.029893398284912
Validation loss: 2.0839357991372385

Epoch: 5| Step: 9
Training loss: 2.2916526794433594
Validation loss: 2.0674263097906627

Epoch: 5| Step: 10
Training loss: 2.2000598907470703
Validation loss: 2.076254721610777

Epoch: 44| Step: 0
Training loss: 2.191471576690674
Validation loss: 2.0749350145298946

Epoch: 5| Step: 1
Training loss: 2.576939582824707
Validation loss: 2.0456279734129548

Epoch: 5| Step: 2
Training loss: 2.3927206993103027
Validation loss: 2.0403018664288264

Epoch: 5| Step: 3
Training loss: 2.333794355392456
Validation loss: 2.0618896304920153

Epoch: 5| Step: 4
Training loss: 2.711874485015869
Validation loss: 2.0781986713409424

Epoch: 5| Step: 5
Training loss: 1.9605624675750732
Validation loss: 2.0745232579528645

Epoch: 5| Step: 6
Training loss: 2.4678056240081787
Validation loss: 2.063237895247757

Epoch: 5| Step: 7
Training loss: 2.7024471759796143
Validation loss: 2.06309244196902

Epoch: 5| Step: 8
Training loss: 2.33675479888916
Validation loss: 2.0702631781178136

Epoch: 5| Step: 9
Training loss: 2.2720680236816406
Validation loss: 2.065368672852875

Epoch: 5| Step: 10
Training loss: 2.0059974193573
Validation loss: 2.0675136017543014

Epoch: 45| Step: 0
Training loss: 2.5987777709960938
Validation loss: 2.0550525790901593

Epoch: 5| Step: 1
Training loss: 2.08134388923645
Validation loss: 2.0691566903104066

Epoch: 5| Step: 2
Training loss: 2.62377667427063
Validation loss: 2.0492340134036158

Epoch: 5| Step: 3
Training loss: 1.8823522329330444
Validation loss: 2.063958724339803

Epoch: 5| Step: 4
Training loss: 2.1091511249542236
Validation loss: 2.055022780613233

Epoch: 5| Step: 5
Training loss: 2.69120717048645
Validation loss: 2.0641221820667224

Epoch: 5| Step: 6
Training loss: 2.7137646675109863
Validation loss: 2.040844435332924

Epoch: 5| Step: 7
Training loss: 2.2884106636047363
Validation loss: 2.0631896577855593

Epoch: 5| Step: 8
Training loss: 2.7416000366210938
Validation loss: 2.081142364009734

Epoch: 5| Step: 9
Training loss: 1.7896373271942139
Validation loss: 2.0627006920435096

Epoch: 5| Step: 10
Training loss: 2.4913792610168457
Validation loss: 2.056366615397956

Epoch: 46| Step: 0
Training loss: 2.490992307662964
Validation loss: 2.0380280863854194

Epoch: 5| Step: 1
Training loss: 2.2258763313293457
Validation loss: 2.064956893203079

Epoch: 5| Step: 2
Training loss: 1.9986789226531982
Validation loss: 2.056169855979181

Epoch: 5| Step: 3
Training loss: 2.0597455501556396
Validation loss: 2.061291697204754

Epoch: 5| Step: 4
Training loss: 2.4682564735412598
Validation loss: 2.0557890553628244

Epoch: 5| Step: 5
Training loss: 2.1950221061706543
Validation loss: 2.063450772275207

Epoch: 5| Step: 6
Training loss: 2.41300892829895
Validation loss: 2.0515146870766916

Epoch: 5| Step: 7
Training loss: 3.346712112426758
Validation loss: 2.066525402889457

Epoch: 5| Step: 8
Training loss: 2.4244096279144287
Validation loss: 2.0451537011772074

Epoch: 5| Step: 9
Training loss: 1.9502785205841064
Validation loss: 2.0619354978684457

Epoch: 5| Step: 10
Training loss: 2.2582809925079346
Validation loss: 2.0531697888528146

Epoch: 47| Step: 0
Training loss: 2.187007188796997
Validation loss: 2.067945694410673

Epoch: 5| Step: 1
Training loss: 2.546800136566162
Validation loss: 2.0486967384174304

Epoch: 5| Step: 2
Training loss: 2.4348785877227783
Validation loss: 2.0581935810786423

Epoch: 5| Step: 3
Training loss: 2.0746312141418457
Validation loss: 2.0599741922911776

Epoch: 5| Step: 4
Training loss: 2.1642634868621826
Validation loss: 2.051272899873795

Epoch: 5| Step: 5
Training loss: 2.577399253845215
Validation loss: 2.0629650867113503

Epoch: 5| Step: 6
Training loss: 2.317211866378784
Validation loss: 2.0510797782610823

Epoch: 5| Step: 7
Training loss: 2.6028151512145996
Validation loss: 2.0489284325671453

Epoch: 5| Step: 8
Training loss: 2.5559871196746826
Validation loss: 2.0673114881720593

Epoch: 5| Step: 9
Training loss: 2.380643129348755
Validation loss: 2.066904401266447

Epoch: 5| Step: 10
Training loss: 1.946179986000061
Validation loss: 2.0575191231184107

Epoch: 48| Step: 0
Training loss: 2.2681832313537598
Validation loss: 2.0667829795550277

Epoch: 5| Step: 1
Training loss: 2.152745485305786
Validation loss: 2.056450605392456

Epoch: 5| Step: 2
Training loss: 2.096700668334961
Validation loss: 2.060504610820483

Epoch: 5| Step: 3
Training loss: 2.55165433883667
Validation loss: 2.0479959467405915

Epoch: 5| Step: 4
Training loss: 2.180258274078369
Validation loss: 2.0645384583421933

Epoch: 5| Step: 5
Training loss: 2.9787650108337402
Validation loss: 2.0620284541960685

Epoch: 5| Step: 6
Training loss: 1.887669324874878
Validation loss: 2.070863111044771

Epoch: 5| Step: 7
Training loss: 2.607933521270752
Validation loss: 2.0744476241450154

Epoch: 5| Step: 8
Training loss: 2.4947669506073
Validation loss: 2.0711914775192097

Epoch: 5| Step: 9
Training loss: 2.596320629119873
Validation loss: 2.0574343947954077

Epoch: 5| Step: 10
Training loss: 1.9219636917114258
Validation loss: 2.0639326867236885

Epoch: 49| Step: 0
Training loss: 2.6929259300231934
Validation loss: 2.0719085098594747

Epoch: 5| Step: 1
Training loss: 2.5263946056365967
Validation loss: 2.0577192357791367

Epoch: 5| Step: 2
Training loss: 2.1721091270446777
Validation loss: 2.060098003315669

Epoch: 5| Step: 3
Training loss: 1.8231315612792969
Validation loss: 2.0578996904434694

Epoch: 5| Step: 4
Training loss: 3.0791702270507812
Validation loss: 2.0522693485342045

Epoch: 5| Step: 5
Training loss: 2.0897388458251953
Validation loss: 2.0589099878905923

Epoch: 5| Step: 6
Training loss: 2.9942004680633545
Validation loss: 2.069151072091954

Epoch: 5| Step: 7
Training loss: 2.221592426300049
Validation loss: 2.0686307312339864

Epoch: 5| Step: 8
Training loss: 1.854185700416565
Validation loss: 2.0701420435341458

Epoch: 5| Step: 9
Training loss: 1.9731838703155518
Validation loss: 2.0716620927215903

Epoch: 5| Step: 10
Training loss: 2.3513131141662598
Validation loss: 2.063358099229874

Epoch: 50| Step: 0
Training loss: 2.05130934715271
Validation loss: 2.0500571881571124

Epoch: 5| Step: 1
Training loss: 1.855733871459961
Validation loss: 2.0677064798211537

Epoch: 5| Step: 2
Training loss: 2.5843591690063477
Validation loss: 2.0695738715510212

Epoch: 5| Step: 3
Training loss: 2.8696579933166504
Validation loss: 2.0597833356549664

Epoch: 5| Step: 4
Training loss: 2.529592514038086
Validation loss: 2.062091194173341

Epoch: 5| Step: 5
Training loss: 2.5097110271453857
Validation loss: 2.072199793272121

Epoch: 5| Step: 6
Training loss: 1.649303674697876
Validation loss: 2.0488400510562363

Epoch: 5| Step: 7
Training loss: 1.9241282939910889
Validation loss: 2.0451614190173406

Epoch: 5| Step: 8
Training loss: 2.546020269393921
Validation loss: 2.046555483213035

Epoch: 5| Step: 9
Training loss: 2.710566520690918
Validation loss: 2.050974298548955

Epoch: 5| Step: 10
Training loss: 2.398014545440674
Validation loss: 2.047723823978055

Epoch: 51| Step: 0
Training loss: 2.5667243003845215
Validation loss: 2.068038596901842

Epoch: 5| Step: 1
Training loss: 2.350450038909912
Validation loss: 2.052172650573074

Epoch: 5| Step: 2
Training loss: 2.0290603637695312
Validation loss: 2.055688693959226

Epoch: 5| Step: 3
Training loss: 2.7002997398376465
Validation loss: 2.0526424582286547

Epoch: 5| Step: 4
Training loss: 1.814915657043457
Validation loss: 2.065014918645223

Epoch: 5| Step: 5
Training loss: 1.7966737747192383
Validation loss: 2.0561426685702417

Epoch: 5| Step: 6
Training loss: 2.9232914447784424
Validation loss: 2.0558335601642566

Epoch: 5| Step: 7
Training loss: 2.931975841522217
Validation loss: 2.063567735815561

Epoch: 5| Step: 8
Training loss: 2.2031540870666504
Validation loss: 2.043378419773553

Epoch: 5| Step: 9
Training loss: 2.336409091949463
Validation loss: 2.0429593119570004

Epoch: 5| Step: 10
Training loss: 1.8875737190246582
Validation loss: 2.062696018526631

Epoch: 52| Step: 0
Training loss: 2.268941640853882
Validation loss: 2.0454438937607633

Epoch: 5| Step: 1
Training loss: 1.8042316436767578
Validation loss: 2.044967278357475

Epoch: 5| Step: 2
Training loss: 2.3103244304656982
Validation loss: 2.04910740160173

Epoch: 5| Step: 3
Training loss: 2.690234661102295
Validation loss: 2.056160778127691

Epoch: 5| Step: 4
Training loss: 2.2932887077331543
Validation loss: 2.054971518055085

Epoch: 5| Step: 5
Training loss: 1.5642694234848022
Validation loss: 2.0335485345573834

Epoch: 5| Step: 6
Training loss: 2.1759743690490723
Validation loss: 2.041097407699913

Epoch: 5| Step: 7
Training loss: 2.3209266662597656
Validation loss: 2.0501478782264133

Epoch: 5| Step: 8
Training loss: 2.4047322273254395
Validation loss: 2.046158798279301

Epoch: 5| Step: 9
Training loss: 2.6851813793182373
Validation loss: 2.057745300313478

Epoch: 5| Step: 10
Training loss: 3.3091554641723633
Validation loss: 2.042127759225907

Epoch: 53| Step: 0
Training loss: 1.8708102703094482
Validation loss: 2.050096768204884

Epoch: 5| Step: 1
Training loss: 2.650606632232666
Validation loss: 2.0484892629807994

Epoch: 5| Step: 2
Training loss: 1.9680707454681396
Validation loss: 2.0352573497321016

Epoch: 5| Step: 3
Training loss: 1.807803750038147
Validation loss: 2.0508600614404164

Epoch: 5| Step: 4
Training loss: 2.1709330081939697
Validation loss: 2.05789618081944

Epoch: 5| Step: 5
Training loss: 2.44307279586792
Validation loss: 2.041628635057839

Epoch: 5| Step: 6
Training loss: 2.5037031173706055
Validation loss: 2.051986105980412

Epoch: 5| Step: 7
Training loss: 2.3687336444854736
Validation loss: 2.0502731274533015

Epoch: 5| Step: 8
Training loss: 2.6600804328918457
Validation loss: 2.041400865841937

Epoch: 5| Step: 9
Training loss: 2.416796922683716
Validation loss: 2.0515568512742237

Epoch: 5| Step: 10
Training loss: 2.8757057189941406
Validation loss: 2.0417140786365797

Epoch: 54| Step: 0
Training loss: 2.487591028213501
Validation loss: 2.053640939856088

Epoch: 5| Step: 1
Training loss: 2.510373115539551
Validation loss: 2.0569918309488604

Epoch: 5| Step: 2
Training loss: 1.9600712060928345
Validation loss: 2.03363420245468

Epoch: 5| Step: 3
Training loss: 2.0727481842041016
Validation loss: 2.0415777339730212

Epoch: 5| Step: 4
Training loss: 2.397019147872925
Validation loss: 2.048470207439956

Epoch: 5| Step: 5
Training loss: 2.6083173751831055
Validation loss: 2.03844984885185

Epoch: 5| Step: 6
Training loss: 2.2746665477752686
Validation loss: 2.060452656079364

Epoch: 5| Step: 7
Training loss: 2.237888813018799
Validation loss: 2.04298432155322

Epoch: 5| Step: 8
Training loss: 2.2399232387542725
Validation loss: 2.0527015116906937

Epoch: 5| Step: 9
Training loss: 2.526365280151367
Validation loss: 2.072008402116837

Epoch: 5| Step: 10
Training loss: 2.083256244659424
Validation loss: 2.045920361754715

Epoch: 55| Step: 0
Training loss: 2.838196039199829
Validation loss: 2.0593479205203313

Epoch: 5| Step: 1
Training loss: 2.235663652420044
Validation loss: 2.050394651710346

Epoch: 5| Step: 2
Training loss: 2.28806734085083
Validation loss: 2.040678396019884

Epoch: 5| Step: 3
Training loss: 2.158336639404297
Validation loss: 2.0388602159356557

Epoch: 5| Step: 4
Training loss: 2.2160117626190186
Validation loss: 2.0391970578060357

Epoch: 5| Step: 5
Training loss: 2.384225845336914
Validation loss: 2.055497451495099

Epoch: 5| Step: 6
Training loss: 2.2237377166748047
Validation loss: 2.0532459699979393

Epoch: 5| Step: 7
Training loss: 2.468140125274658
Validation loss: 2.0521879862713557

Epoch: 5| Step: 8
Training loss: 2.191988706588745
Validation loss: 2.029444476609589

Epoch: 5| Step: 9
Training loss: 1.8996403217315674
Validation loss: 2.03902752425081

Epoch: 5| Step: 10
Training loss: 2.760673999786377
Validation loss: 2.0368011741228003

Epoch: 56| Step: 0
Training loss: 2.900308132171631
Validation loss: 2.0363104292141494

Epoch: 5| Step: 1
Training loss: 2.4289350509643555
Validation loss: 2.0346065105930453

Epoch: 5| Step: 2
Training loss: 2.143928050994873
Validation loss: 2.067321369724889

Epoch: 5| Step: 3
Training loss: 2.2993342876434326
Validation loss: 2.0438141310086815

Epoch: 5| Step: 4
Training loss: 2.012355089187622
Validation loss: 2.034471191385741

Epoch: 5| Step: 5
Training loss: 2.063523769378662
Validation loss: 2.043319002274544

Epoch: 5| Step: 6
Training loss: 2.42722487449646
Validation loss: 2.0440923603632117

Epoch: 5| Step: 7
Training loss: 2.206606149673462
Validation loss: 2.0422624208593882

Epoch: 5| Step: 8
Training loss: 2.2131412029266357
Validation loss: 2.0429065791509484

Epoch: 5| Step: 9
Training loss: 2.1632485389709473
Validation loss: 2.048407943018021

Epoch: 5| Step: 10
Training loss: 2.619156837463379
Validation loss: 2.0606374920055432

Epoch: 57| Step: 0
Training loss: 1.9842456579208374
Validation loss: 2.0619001824368715

Epoch: 5| Step: 1
Training loss: 2.1876111030578613
Validation loss: 2.036829085760219

Epoch: 5| Step: 2
Training loss: 2.4072601795196533
Validation loss: 2.028823839720859

Epoch: 5| Step: 3
Training loss: 2.3646655082702637
Validation loss: 2.045655296694848

Epoch: 5| Step: 4
Training loss: 2.260002851486206
Validation loss: 2.0590391556421914

Epoch: 5| Step: 5
Training loss: 2.028456211090088
Validation loss: 2.0491496209175355

Epoch: 5| Step: 6
Training loss: 2.2751283645629883
Validation loss: 2.045060189821387

Epoch: 5| Step: 7
Training loss: 2.3596510887145996
Validation loss: 2.0394340381827405

Epoch: 5| Step: 8
Training loss: 2.392343521118164
Validation loss: 2.059405308897777

Epoch: 5| Step: 9
Training loss: 2.3817479610443115
Validation loss: 2.0412606987901913

Epoch: 5| Step: 10
Training loss: 2.845320224761963
Validation loss: 2.0454373282770955

Epoch: 58| Step: 0
Training loss: 2.350039005279541
Validation loss: 2.0346837915400022

Epoch: 5| Step: 1
Training loss: 2.5329878330230713
Validation loss: 2.043324161601323

Epoch: 5| Step: 2
Training loss: 2.254695177078247
Validation loss: 2.045144805344202

Epoch: 5| Step: 3
Training loss: 1.4981656074523926
Validation loss: 2.062341650327047

Epoch: 5| Step: 4
Training loss: 2.510427236557007
Validation loss: 2.0160061543987644

Epoch: 5| Step: 5
Training loss: 2.6761062145233154
Validation loss: 2.0443143690786054

Epoch: 5| Step: 6
Training loss: 2.5510358810424805
Validation loss: 2.061730577099708

Epoch: 5| Step: 7
Training loss: 2.1880576610565186
Validation loss: 2.0466200382478776

Epoch: 5| Step: 8
Training loss: 2.485161066055298
Validation loss: 2.0453113022670952

Epoch: 5| Step: 9
Training loss: 1.9264955520629883
Validation loss: 2.0522711866645404

Epoch: 5| Step: 10
Training loss: 2.467475652694702
Validation loss: 2.056489754748601

Epoch: 59| Step: 0
Training loss: 2.654083728790283
Validation loss: 2.036348117295132

Epoch: 5| Step: 1
Training loss: 2.042113780975342
Validation loss: 2.0413727401405253

Epoch: 5| Step: 2
Training loss: 2.6042637825012207
Validation loss: 2.0449796645872054

Epoch: 5| Step: 3
Training loss: 2.950021982192993
Validation loss: 2.04983615362516

Epoch: 5| Step: 4
Training loss: 1.9186928272247314
Validation loss: 2.038572234492148

Epoch: 5| Step: 5
Training loss: 2.1655611991882324
Validation loss: 2.040631681360224

Epoch: 5| Step: 6
Training loss: 2.942617177963257
Validation loss: 2.048015066372451

Epoch: 5| Step: 7
Training loss: 2.0572471618652344
Validation loss: 2.076369434274653

Epoch: 5| Step: 8
Training loss: 2.4887161254882812
Validation loss: 2.0393292442444833

Epoch: 5| Step: 9
Training loss: 1.5814646482467651
Validation loss: 2.0389215843651884

Epoch: 5| Step: 10
Training loss: 1.9900710582733154
Validation loss: 2.0473405571394068

Epoch: 60| Step: 0
Training loss: 1.9163166284561157
Validation loss: 2.046765681236021

Epoch: 5| Step: 1
Training loss: 2.5721182823181152
Validation loss: 2.054683725039164

Epoch: 5| Step: 2
Training loss: 2.0166494846343994
Validation loss: 2.03811582954981

Epoch: 5| Step: 3
Training loss: 2.3143670558929443
Validation loss: 2.054049507264168

Epoch: 5| Step: 4
Training loss: 2.0587310791015625
Validation loss: 2.0508691469828286

Epoch: 5| Step: 5
Training loss: 1.9547706842422485
Validation loss: 2.040465590774372

Epoch: 5| Step: 6
Training loss: 2.891840696334839
Validation loss: 2.052262621541177

Epoch: 5| Step: 7
Training loss: 2.547398328781128
Validation loss: 2.0493370192025298

Epoch: 5| Step: 8
Training loss: 2.508878469467163
Validation loss: 2.0630204190490065

Epoch: 5| Step: 9
Training loss: 2.1247916221618652
Validation loss: 2.040689250474335

Epoch: 5| Step: 10
Training loss: 2.326206922531128
Validation loss: 2.0335742145456295

Epoch: 61| Step: 0
Training loss: 2.0785999298095703
Validation loss: 2.0483400924231416

Epoch: 5| Step: 1
Training loss: 1.3877732753753662
Validation loss: 2.0514273246129355

Epoch: 5| Step: 2
Training loss: 2.7796478271484375
Validation loss: 2.0472663038520404

Epoch: 5| Step: 3
Training loss: 2.705662965774536
Validation loss: 2.057594012188655

Epoch: 5| Step: 4
Training loss: 1.8383926153182983
Validation loss: 2.0430739592480403

Epoch: 5| Step: 5
Training loss: 2.8068454265594482
Validation loss: 2.0410694409442205

Epoch: 5| Step: 6
Training loss: 2.6996777057647705
Validation loss: 2.0399707645498295

Epoch: 5| Step: 7
Training loss: 1.9936916828155518
Validation loss: 2.0537878210826586

Epoch: 5| Step: 8
Training loss: 2.4373817443847656
Validation loss: 2.0287309436387915

Epoch: 5| Step: 9
Training loss: 2.324878215789795
Validation loss: 2.045208946351082

Epoch: 5| Step: 10
Training loss: 2.2059342861175537
Validation loss: 2.0343596448180494

Epoch: 62| Step: 0
Training loss: 2.106478691101074
Validation loss: 2.034142408319699

Epoch: 5| Step: 1
Training loss: 2.4694161415100098
Validation loss: 2.039042963776537

Epoch: 5| Step: 2
Training loss: 2.2504165172576904
Validation loss: 2.041318937014508

Epoch: 5| Step: 3
Training loss: 1.9802532196044922
Validation loss: 2.0514680903445006

Epoch: 5| Step: 4
Training loss: 2.2057368755340576
Validation loss: 2.0285590207704933

Epoch: 5| Step: 5
Training loss: 2.2401628494262695
Validation loss: 2.0586540365731842

Epoch: 5| Step: 6
Training loss: 2.5580286979675293
Validation loss: 2.047015474688622

Epoch: 5| Step: 7
Training loss: 1.9935581684112549
Validation loss: 2.0547731691791165

Epoch: 5| Step: 8
Training loss: 2.5726218223571777
Validation loss: 2.055324249370124

Epoch: 5| Step: 9
Training loss: 2.9343695640563965
Validation loss: 2.046592652156789

Epoch: 5| Step: 10
Training loss: 1.803706169128418
Validation loss: 2.036639295598512

Epoch: 63| Step: 0
Training loss: 2.0538954734802246
Validation loss: 2.0368263285647155

Epoch: 5| Step: 1
Training loss: 2.7121715545654297
Validation loss: 2.029146832804526

Epoch: 5| Step: 2
Training loss: 2.7679295539855957
Validation loss: 2.0197479519792783

Epoch: 5| Step: 3
Training loss: 1.8741058111190796
Validation loss: 2.04824802952428

Epoch: 5| Step: 4
Training loss: 1.800337791442871
Validation loss: 2.030396448668613

Epoch: 5| Step: 5
Training loss: 2.7554221153259277
Validation loss: 2.0427612437996814

Epoch: 5| Step: 6
Training loss: 2.099783182144165
Validation loss: 2.0479019175293627

Epoch: 5| Step: 7
Training loss: 2.636152744293213
Validation loss: 2.0488929107624996

Epoch: 5| Step: 8
Training loss: 1.8353906869888306
Validation loss: 2.0525246525323517

Epoch: 5| Step: 9
Training loss: 2.082303047180176
Validation loss: 2.042524348023117

Epoch: 5| Step: 10
Training loss: 2.658301830291748
Validation loss: 2.0447380465845906

Epoch: 64| Step: 0
Training loss: 2.038724184036255
Validation loss: 2.046383019416563

Epoch: 5| Step: 1
Training loss: 2.0204200744628906
Validation loss: 2.0393520785916235

Epoch: 5| Step: 2
Training loss: 2.5169196128845215
Validation loss: 2.0434746742248535

Epoch: 5| Step: 3
Training loss: 2.5042922496795654
Validation loss: 2.017205415233489

Epoch: 5| Step: 4
Training loss: 2.0867815017700195
Validation loss: 2.0188085853412585

Epoch: 5| Step: 5
Training loss: 2.459916591644287
Validation loss: 2.0182793012229343

Epoch: 5| Step: 6
Training loss: 2.5075488090515137
Validation loss: 2.0536693719125565

Epoch: 5| Step: 7
Training loss: 1.9177799224853516
Validation loss: 2.0235188968719973

Epoch: 5| Step: 8
Training loss: 2.064521312713623
Validation loss: 2.0400433078888924

Epoch: 5| Step: 9
Training loss: 2.793027877807617
Validation loss: 2.0439215578058714

Epoch: 5| Step: 10
Training loss: 2.405169725418091
Validation loss: 2.0422999115400415

Epoch: 65| Step: 0
Training loss: 2.067904472351074
Validation loss: 2.034519571129994

Epoch: 5| Step: 1
Training loss: 2.588498592376709
Validation loss: 2.054764491255565

Epoch: 5| Step: 2
Training loss: 2.2327475547790527
Validation loss: 2.046033328579318

Epoch: 5| Step: 3
Training loss: 1.7929083108901978
Validation loss: 2.0438460816619215

Epoch: 5| Step: 4
Training loss: 2.6989166736602783
Validation loss: 2.028839957329535

Epoch: 5| Step: 5
Training loss: 2.4464519023895264
Validation loss: 2.0292679827700377

Epoch: 5| Step: 6
Training loss: 2.3616223335266113
Validation loss: 2.021642715700211

Epoch: 5| Step: 7
Training loss: 2.5573906898498535
Validation loss: 2.041159813122083

Epoch: 5| Step: 8
Training loss: 2.1306636333465576
Validation loss: 2.0299056665871733

Epoch: 5| Step: 9
Training loss: 2.764991044998169
Validation loss: 2.026539164204751

Epoch: 5| Step: 10
Training loss: 1.527180790901184
Validation loss: 2.0296259054573635

Epoch: 66| Step: 0
Training loss: 1.9862966537475586
Validation loss: 2.0442055989337224

Epoch: 5| Step: 1
Training loss: 2.6668179035186768
Validation loss: 2.0506892076102634

Epoch: 5| Step: 2
Training loss: 2.397402048110962
Validation loss: 2.0290664370341966

Epoch: 5| Step: 3
Training loss: 2.199960231781006
Validation loss: 2.030461831759381

Epoch: 5| Step: 4
Training loss: 1.9398667812347412
Validation loss: 2.0452431735172065

Epoch: 5| Step: 5
Training loss: 2.3785758018493652
Validation loss: 2.0437344492122693

Epoch: 5| Step: 6
Training loss: 2.1840405464172363
Validation loss: 2.034773762508105

Epoch: 5| Step: 7
Training loss: 2.5869219303131104
Validation loss: 2.0418954613388225

Epoch: 5| Step: 8
Training loss: 2.9260714054107666
Validation loss: 2.0399317856757873

Epoch: 5| Step: 9
Training loss: 2.157787322998047
Validation loss: 2.0474400751052366

Epoch: 5| Step: 10
Training loss: 1.795318603515625
Validation loss: 2.039784582712317

Epoch: 67| Step: 0
Training loss: 2.1662039756774902
Validation loss: 2.036777147682764

Epoch: 5| Step: 1
Training loss: 2.4495980739593506
Validation loss: 2.0602164371039278

Epoch: 5| Step: 2
Training loss: 2.2345306873321533
Validation loss: 2.0321913637140745

Epoch: 5| Step: 3
Training loss: 2.4866385459899902
Validation loss: 2.038395034369602

Epoch: 5| Step: 4
Training loss: 2.13510799407959
Validation loss: 2.042607763762115

Epoch: 5| Step: 5
Training loss: 1.7323524951934814
Validation loss: 2.042589606777314

Epoch: 5| Step: 6
Training loss: 2.293766498565674
Validation loss: 2.02841805770833

Epoch: 5| Step: 7
Training loss: 2.763786792755127
Validation loss: 2.0341677178618727

Epoch: 5| Step: 8
Training loss: 2.4120967388153076
Validation loss: 2.0436818497155302

Epoch: 5| Step: 9
Training loss: 2.161459445953369
Validation loss: 2.0345251649938603

Epoch: 5| Step: 10
Training loss: 2.309453248977661
Validation loss: 2.0361159847628687

Epoch: 68| Step: 0
Training loss: 1.7428207397460938
Validation loss: 2.034215606668944

Epoch: 5| Step: 1
Training loss: 2.0524144172668457
Validation loss: 2.0590806417567755

Epoch: 5| Step: 2
Training loss: 2.042171001434326
Validation loss: 2.0292929603207495

Epoch: 5| Step: 3
Training loss: 2.116211414337158
Validation loss: 2.0364574437500327

Epoch: 5| Step: 4
Training loss: 1.6014416217803955
Validation loss: 2.037893323488133

Epoch: 5| Step: 5
Training loss: 2.5674378871917725
Validation loss: 2.045418482954784

Epoch: 5| Step: 6
Training loss: 2.739655017852783
Validation loss: 2.0405111492321057

Epoch: 5| Step: 7
Training loss: 2.8288626670837402
Validation loss: 2.031470198785105

Epoch: 5| Step: 8
Training loss: 2.850606679916382
Validation loss: 2.027697015834111

Epoch: 5| Step: 9
Training loss: 2.124863624572754
Validation loss: 2.045128958199614

Epoch: 5| Step: 10
Training loss: 2.640901565551758
Validation loss: 2.033858645346857

Epoch: 69| Step: 0
Training loss: 2.3876500129699707
Validation loss: 2.0445276050157446

Epoch: 5| Step: 1
Training loss: 2.2739758491516113
Validation loss: 2.029688912053262

Epoch: 5| Step: 2
Training loss: 2.5428221225738525
Validation loss: 2.0274209437831754

Epoch: 5| Step: 3
Training loss: 2.835297107696533
Validation loss: 2.0372882940435924

Epoch: 5| Step: 4
Training loss: 2.0026192665100098
Validation loss: 2.033887514504053

Epoch: 5| Step: 5
Training loss: 2.1793694496154785
Validation loss: 2.034478588770795

Epoch: 5| Step: 6
Training loss: 2.356640577316284
Validation loss: 2.0376305246865876

Epoch: 5| Step: 7
Training loss: 1.4438775777816772
Validation loss: 2.0387359267921856

Epoch: 5| Step: 8
Training loss: 2.667732000350952
Validation loss: 2.037168264389038

Epoch: 5| Step: 9
Training loss: 2.351879119873047
Validation loss: 2.038382311021128

Epoch: 5| Step: 10
Training loss: 2.03548526763916
Validation loss: 2.0350225228135304

Epoch: 70| Step: 0
Training loss: 2.210327625274658
Validation loss: 2.0331718921661377

Epoch: 5| Step: 1
Training loss: 2.4832093715667725
Validation loss: 2.0365601944667038

Epoch: 5| Step: 2
Training loss: 2.5000624656677246
Validation loss: 2.0264434788816716

Epoch: 5| Step: 3
Training loss: 2.3496155738830566
Validation loss: 2.036437947263

Epoch: 5| Step: 4
Training loss: 2.02717661857605
Validation loss: 2.0295701385826193

Epoch: 5| Step: 5
Training loss: 2.361726999282837
Validation loss: 2.0352890850395284

Epoch: 5| Step: 6
Training loss: 2.1729185581207275
Validation loss: 2.038430639492568

Epoch: 5| Step: 7
Training loss: 1.4603135585784912
Validation loss: 2.0371232212230725

Epoch: 5| Step: 8
Training loss: 2.5526280403137207
Validation loss: 2.050734099521432

Epoch: 5| Step: 9
Training loss: 2.8829970359802246
Validation loss: 2.0237190543964343

Epoch: 5| Step: 10
Training loss: 2.1147680282592773
Validation loss: 2.0397967036052416

Epoch: 71| Step: 0
Training loss: 2.066338062286377
Validation loss: 2.0386709782385055

Epoch: 5| Step: 1
Training loss: 2.1969685554504395
Validation loss: 2.0410353727238153

Epoch: 5| Step: 2
Training loss: 2.51912260055542
Validation loss: 2.0452264073074504

Epoch: 5| Step: 3
Training loss: 2.6163229942321777
Validation loss: 2.037356436893504

Epoch: 5| Step: 4
Training loss: 2.2747559547424316
Validation loss: 2.0410091043800436

Epoch: 5| Step: 5
Training loss: 2.4639716148376465
Validation loss: 2.048773116962884

Epoch: 5| Step: 6
Training loss: 2.2261898517608643
Validation loss: 2.0345373435686995

Epoch: 5| Step: 7
Training loss: 1.9972833395004272
Validation loss: 2.04550346251457

Epoch: 5| Step: 8
Training loss: 2.063908815383911
Validation loss: 2.0342277916528846

Epoch: 5| Step: 9
Training loss: 2.0715110301971436
Validation loss: 2.0305206852574504

Epoch: 5| Step: 10
Training loss: 2.525228977203369
Validation loss: 2.038528093727686

Epoch: 72| Step: 0
Training loss: 2.2813007831573486
Validation loss: 2.038287408890263

Epoch: 5| Step: 1
Training loss: 2.274494171142578
Validation loss: 2.0396704212311776

Epoch: 5| Step: 2
Training loss: 3.195448637008667
Validation loss: 2.027276667215491

Epoch: 5| Step: 3
Training loss: 2.489492416381836
Validation loss: 2.0316564318954304

Epoch: 5| Step: 4
Training loss: 1.8455543518066406
Validation loss: 2.038582249354291

Epoch: 5| Step: 5
Training loss: 1.9587879180908203
Validation loss: 2.0353288163420973

Epoch: 5| Step: 6
Training loss: 2.1649272441864014
Validation loss: 2.0433826728533675

Epoch: 5| Step: 7
Training loss: 2.230670213699341
Validation loss: 2.0364705900992117

Epoch: 5| Step: 8
Training loss: 1.7797492742538452
Validation loss: 2.034024692350818

Epoch: 5| Step: 9
Training loss: 2.54262113571167
Validation loss: 2.030286729976695

Epoch: 5| Step: 10
Training loss: 2.159623384475708
Validation loss: 2.037522118578675

Epoch: 73| Step: 0
Training loss: 2.28822660446167
Validation loss: 2.0549944421296478

Epoch: 5| Step: 1
Training loss: 1.8692615032196045
Validation loss: 2.0402951496903614

Epoch: 5| Step: 2
Training loss: 2.8174567222595215
Validation loss: 2.056618539235925

Epoch: 5| Step: 3
Training loss: 2.511491298675537
Validation loss: 2.065842510551535

Epoch: 5| Step: 4
Training loss: 1.8406444787979126
Validation loss: 2.048331973373249

Epoch: 5| Step: 5
Training loss: 2.0996956825256348
Validation loss: 2.0406357652397564

Epoch: 5| Step: 6
Training loss: 2.816262722015381
Validation loss: 2.0388279909728677

Epoch: 5| Step: 7
Training loss: 2.0189521312713623
Validation loss: 2.0460820531332367

Epoch: 5| Step: 8
Training loss: 2.149177074432373
Validation loss: 2.0533315186859458

Epoch: 5| Step: 9
Training loss: 2.1178135871887207
Validation loss: 2.0464461875218216

Epoch: 5| Step: 10
Training loss: 2.505680561065674
Validation loss: 2.0384599201140867

Epoch: 74| Step: 0
Training loss: 2.2979280948638916
Validation loss: 2.0601477366621777

Epoch: 5| Step: 1
Training loss: 2.4625682830810547
Validation loss: 2.0545362298206618

Epoch: 5| Step: 2
Training loss: 2.5668387413024902
Validation loss: 2.048937451454901

Epoch: 5| Step: 3
Training loss: 2.52787446975708
Validation loss: 2.0287704826683126

Epoch: 5| Step: 4
Training loss: 2.044344425201416
Validation loss: 2.039459946335003

Epoch: 5| Step: 5
Training loss: 1.6039764881134033
Validation loss: 2.043100887729276

Epoch: 5| Step: 6
Training loss: 2.519141912460327
Validation loss: 2.048946585706485

Epoch: 5| Step: 7
Training loss: 2.7897307872772217
Validation loss: 2.04715161426093

Epoch: 5| Step: 8
Training loss: 2.1640548706054688
Validation loss: 2.0570831247555312

Epoch: 5| Step: 9
Training loss: 1.8595374822616577
Validation loss: 2.03386329835461

Epoch: 5| Step: 10
Training loss: 2.1362438201904297
Validation loss: 2.0425593558178154

Epoch: 75| Step: 0
Training loss: 2.2088260650634766
Validation loss: 2.0374885810318815

Epoch: 5| Step: 1
Training loss: 1.876016616821289
Validation loss: 2.046390002773654

Epoch: 5| Step: 2
Training loss: 2.0681188106536865
Validation loss: 2.0332832631244453

Epoch: 5| Step: 3
Training loss: 1.943979263305664
Validation loss: 2.034848581078232

Epoch: 5| Step: 4
Training loss: 2.4355759620666504
Validation loss: 2.026547234545472

Epoch: 5| Step: 5
Training loss: 2.260756254196167
Validation loss: 2.0396528122245625

Epoch: 5| Step: 6
Training loss: 2.463134765625
Validation loss: 2.0595271510462605

Epoch: 5| Step: 7
Training loss: 2.5754053592681885
Validation loss: 2.0397933965088217

Epoch: 5| Step: 8
Training loss: 2.838202714920044
Validation loss: 2.0428947838403846

Epoch: 5| Step: 9
Training loss: 2.023545980453491
Validation loss: 2.043760056136757

Epoch: 5| Step: 10
Training loss: 2.2173213958740234
Validation loss: 2.057890840755996

Epoch: 76| Step: 0
Training loss: 1.9358596801757812
Validation loss: 2.031371965203234

Epoch: 5| Step: 1
Training loss: 2.1732754707336426
Validation loss: 2.049881814628519

Epoch: 5| Step: 2
Training loss: 1.9435694217681885
Validation loss: 2.0353785714795514

Epoch: 5| Step: 3
Training loss: 2.29539155960083
Validation loss: 2.0456200979089223

Epoch: 5| Step: 4
Training loss: 3.0127387046813965
Validation loss: 2.036177017355478

Epoch: 5| Step: 5
Training loss: 2.2541515827178955
Validation loss: 2.0419923797730477

Epoch: 5| Step: 6
Training loss: 2.7487845420837402
Validation loss: 2.0395980009468655

Epoch: 5| Step: 7
Training loss: 1.8707866668701172
Validation loss: 2.0233498952722035

Epoch: 5| Step: 8
Training loss: 2.053452968597412
Validation loss: 2.031170586104034

Epoch: 5| Step: 9
Training loss: 2.4412598609924316
Validation loss: 2.0490929542049283

Epoch: 5| Step: 10
Training loss: 2.2950263023376465
Validation loss: 2.033155648939071

Epoch: 77| Step: 0
Training loss: 2.430025100708008
Validation loss: 2.035840803577054

Epoch: 5| Step: 1
Training loss: 2.163731813430786
Validation loss: 2.034535828457084

Epoch: 5| Step: 2
Training loss: 2.388521432876587
Validation loss: 2.0165819891037478

Epoch: 5| Step: 3
Training loss: 2.602246046066284
Validation loss: 2.025759243196057

Epoch: 5| Step: 4
Training loss: 1.9348920583724976
Validation loss: 2.028411425570006

Epoch: 5| Step: 5
Training loss: 2.307053804397583
Validation loss: 2.021258097822948

Epoch: 5| Step: 6
Training loss: 2.5867056846618652
Validation loss: 2.036813247588373

Epoch: 5| Step: 7
Training loss: 2.228872776031494
Validation loss: 2.030095959222445

Epoch: 5| Step: 8
Training loss: 2.053774118423462
Validation loss: 2.03828529901402

Epoch: 5| Step: 9
Training loss: 2.113868236541748
Validation loss: 2.0374405845519035

Epoch: 5| Step: 10
Training loss: 1.9739370346069336
Validation loss: 2.028769862267279

Epoch: 78| Step: 0
Training loss: 2.5724635124206543
Validation loss: 2.032991752829603

Epoch: 5| Step: 1
Training loss: 1.830517053604126
Validation loss: 2.0348383585611978

Epoch: 5| Step: 2
Training loss: 2.563385009765625
Validation loss: 2.01798048070682

Epoch: 5| Step: 3
Training loss: 1.9015041589736938
Validation loss: 2.032270026463334

Epoch: 5| Step: 4
Training loss: 2.297997236251831
Validation loss: 2.0359027206256823

Epoch: 5| Step: 5
Training loss: 2.053469181060791
Validation loss: 2.0381402661723476

Epoch: 5| Step: 6
Training loss: 2.2277235984802246
Validation loss: 2.041357212169196

Epoch: 5| Step: 7
Training loss: 2.2770135402679443
Validation loss: 2.0322294606957385

Epoch: 5| Step: 8
Training loss: 1.9561169147491455
Validation loss: 2.037221925233

Epoch: 5| Step: 9
Training loss: 2.573920488357544
Validation loss: 2.0355272754546134

Epoch: 5| Step: 10
Training loss: 2.695019006729126
Validation loss: 2.0548812612410514

Epoch: 79| Step: 0
Training loss: 2.1026790142059326
Validation loss: 2.0366681045101536

Epoch: 5| Step: 1
Training loss: 2.1023313999176025
Validation loss: 2.046076128559728

Epoch: 5| Step: 2
Training loss: 2.131147861480713
Validation loss: 2.0284466974196897

Epoch: 5| Step: 3
Training loss: 2.7509841918945312
Validation loss: 2.0529470238634335

Epoch: 5| Step: 4
Training loss: 2.0227088928222656
Validation loss: 2.034909289370301

Epoch: 5| Step: 5
Training loss: 1.8178694248199463
Validation loss: 2.042663081999748

Epoch: 5| Step: 6
Training loss: 2.09741473197937
Validation loss: 2.0389723777770996

Epoch: 5| Step: 7
Training loss: 2.4799017906188965
Validation loss: 2.039499380255258

Epoch: 5| Step: 8
Training loss: 2.5774543285369873
Validation loss: 2.0468021951695925

Epoch: 5| Step: 9
Training loss: 2.1226882934570312
Validation loss: 2.028116850442784

Epoch: 5| Step: 10
Training loss: 2.7177233695983887
Validation loss: 2.043316879580098

Epoch: 80| Step: 0
Training loss: 2.332000494003296
Validation loss: 2.0385341746832735

Epoch: 5| Step: 1
Training loss: 1.9238169193267822
Validation loss: 2.025875460716986

Epoch: 5| Step: 2
Training loss: 2.38844633102417
Validation loss: 2.0396393063247844

Epoch: 5| Step: 3
Training loss: 2.241673707962036
Validation loss: 2.038555814373878

Epoch: 5| Step: 4
Training loss: 2.875495433807373
Validation loss: 2.0468959269985074

Epoch: 5| Step: 5
Training loss: 1.9162670373916626
Validation loss: 2.0327391470632246

Epoch: 5| Step: 6
Training loss: 2.3964436054229736
Validation loss: 2.030676184162017

Epoch: 5| Step: 7
Training loss: 2.4815597534179688
Validation loss: 2.0485095541964293

Epoch: 5| Step: 8
Training loss: 1.7260892391204834
Validation loss: 2.023728891085553

Epoch: 5| Step: 9
Training loss: 2.562117099761963
Validation loss: 2.0363851913841824

Epoch: 5| Step: 10
Training loss: 1.9680023193359375
Validation loss: 2.047220645412322

Epoch: 81| Step: 0
Training loss: 1.8283838033676147
Validation loss: 2.0313959249886135

Epoch: 5| Step: 1
Training loss: 2.1044650077819824
Validation loss: 2.0363559261445077

Epoch: 5| Step: 2
Training loss: 2.2744224071502686
Validation loss: 2.026000581761842

Epoch: 5| Step: 3
Training loss: 2.664175510406494
Validation loss: 2.053376946398007

Epoch: 5| Step: 4
Training loss: 2.2981791496276855
Validation loss: 2.036435756632077

Epoch: 5| Step: 5
Training loss: 1.7175487279891968
Validation loss: 2.041063598407212

Epoch: 5| Step: 6
Training loss: 1.8729747533798218
Validation loss: 2.0331988232110136

Epoch: 5| Step: 7
Training loss: 2.8142571449279785
Validation loss: 2.0429031336179344

Epoch: 5| Step: 8
Training loss: 2.814857244491577
Validation loss: 2.032721734816028

Epoch: 5| Step: 9
Training loss: 2.2840652465820312
Validation loss: 2.0390098505122687

Epoch: 5| Step: 10
Training loss: 2.019432783126831
Validation loss: 2.051147263537171

Epoch: 82| Step: 0
Training loss: 2.786170482635498
Validation loss: 2.044555749944461

Epoch: 5| Step: 1
Training loss: 1.8506819009780884
Validation loss: 2.0360343712632374

Epoch: 5| Step: 2
Training loss: 1.7722221612930298
Validation loss: 2.04473860802189

Epoch: 5| Step: 3
Training loss: 2.3994109630584717
Validation loss: 2.042912362724222

Epoch: 5| Step: 4
Training loss: 2.834259033203125
Validation loss: 2.0393440261963875

Epoch: 5| Step: 5
Training loss: 1.981652021408081
Validation loss: 2.0243391157478414

Epoch: 5| Step: 6
Training loss: 2.24446177482605
Validation loss: 2.0334819606555405

Epoch: 5| Step: 7
Training loss: 2.136199474334717
Validation loss: 2.0514507626974456

Epoch: 5| Step: 8
Training loss: 2.403639554977417
Validation loss: 2.030689763766463

Epoch: 5| Step: 9
Training loss: 2.219132423400879
Validation loss: 2.0381162974142257

Epoch: 5| Step: 10
Training loss: 2.206218957901001
Validation loss: 2.0205152791033507

Epoch: 83| Step: 0
Training loss: 2.5136513710021973
Validation loss: 2.030942392605607

Epoch: 5| Step: 1
Training loss: 2.9718539714813232
Validation loss: 2.0394715519361597

Epoch: 5| Step: 2
Training loss: 2.1520822048187256
Validation loss: 2.0481027608276694

Epoch: 5| Step: 3
Training loss: 1.7398288249969482
Validation loss: 2.0343899726867676

Epoch: 5| Step: 4
Training loss: 1.8108208179473877
Validation loss: 2.0310410376518004

Epoch: 5| Step: 5
Training loss: 2.508457660675049
Validation loss: 2.0317153776845625

Epoch: 5| Step: 6
Training loss: 2.279289960861206
Validation loss: 2.0332653291763796

Epoch: 5| Step: 7
Training loss: 2.138701915740967
Validation loss: 2.0133000868622974

Epoch: 5| Step: 8
Training loss: 2.3501346111297607
Validation loss: 2.0197655821359284

Epoch: 5| Step: 9
Training loss: 1.731431245803833
Validation loss: 2.036308632102064

Epoch: 5| Step: 10
Training loss: 2.5945277214050293
Validation loss: 2.0287627456008748

Epoch: 84| Step: 0
Training loss: 2.116407632827759
Validation loss: 2.0433088476939867

Epoch: 5| Step: 1
Training loss: 2.0451667308807373
Validation loss: 2.0333787523290163

Epoch: 5| Step: 2
Training loss: 2.1339163780212402
Validation loss: 2.0382244753581222

Epoch: 5| Step: 3
Training loss: 2.207990884780884
Validation loss: 2.0348869780058503

Epoch: 5| Step: 4
Training loss: 2.562903881072998
Validation loss: 2.0266226696711716

Epoch: 5| Step: 5
Training loss: 2.3689723014831543
Validation loss: 2.043178790359087

Epoch: 5| Step: 6
Training loss: 2.1052193641662598
Validation loss: 2.036136834852157

Epoch: 5| Step: 7
Training loss: 2.021728038787842
Validation loss: 2.040565099767459

Epoch: 5| Step: 8
Training loss: 2.3160014152526855
Validation loss: 2.0484230313249814

Epoch: 5| Step: 9
Training loss: 2.4070358276367188
Validation loss: 2.0217767415508145

Epoch: 5| Step: 10
Training loss: 2.4994609355926514
Validation loss: 2.0495112608837824

Epoch: 85| Step: 0
Training loss: 2.389679193496704
Validation loss: 2.023090268975945

Epoch: 5| Step: 1
Training loss: 2.910295009613037
Validation loss: 2.046195281449185

Epoch: 5| Step: 2
Training loss: 2.3305141925811768
Validation loss: 2.0428534630806214

Epoch: 5| Step: 3
Training loss: 2.4332690238952637
Validation loss: 2.0247551600138345

Epoch: 5| Step: 4
Training loss: 2.032738208770752
Validation loss: 2.048775256320994

Epoch: 5| Step: 5
Training loss: 2.1482200622558594
Validation loss: 2.0403830928187214

Epoch: 5| Step: 6
Training loss: 1.9407241344451904
Validation loss: 2.0296137730280557

Epoch: 5| Step: 7
Training loss: 1.955548882484436
Validation loss: 2.033058317758704

Epoch: 5| Step: 8
Training loss: 2.4616217613220215
Validation loss: 2.057970223888274

Epoch: 5| Step: 9
Training loss: 2.1646950244903564
Validation loss: 2.018955506304259

Epoch: 5| Step: 10
Training loss: 1.9877309799194336
Validation loss: 2.0506396973004906

Epoch: 86| Step: 0
Training loss: 2.5462474822998047
Validation loss: 2.034909099660894

Epoch: 5| Step: 1
Training loss: 2.499556064605713
Validation loss: 2.0297277819725776

Epoch: 5| Step: 2
Training loss: 2.690070152282715
Validation loss: 2.029486897171185

Epoch: 5| Step: 3
Training loss: 2.105431318283081
Validation loss: 2.034952930224839

Epoch: 5| Step: 4
Training loss: 1.9087460041046143
Validation loss: 2.0366204348943566

Epoch: 5| Step: 5
Training loss: 2.1432366371154785
Validation loss: 2.0350887224238408

Epoch: 5| Step: 6
Training loss: 2.0687992572784424
Validation loss: 2.037017538983335

Epoch: 5| Step: 7
Training loss: 1.9579050540924072
Validation loss: 2.0294417232595463

Epoch: 5| Step: 8
Training loss: 2.030128002166748
Validation loss: 2.013628851982855

Epoch: 5| Step: 9
Training loss: 2.126859664916992
Validation loss: 2.017943110517276

Epoch: 5| Step: 10
Training loss: 2.662923812866211
Validation loss: 2.020682938637272

Epoch: 87| Step: 0
Training loss: 2.252115488052368
Validation loss: 2.020704601400642

Epoch: 5| Step: 1
Training loss: 1.8797104358673096
Validation loss: 2.02314579871393

Epoch: 5| Step: 2
Training loss: 2.62290358543396
Validation loss: 2.010543692496515

Epoch: 5| Step: 3
Training loss: 2.088212251663208
Validation loss: 2.0286560225230392

Epoch: 5| Step: 4
Training loss: 2.366737127304077
Validation loss: 2.019218906279533

Epoch: 5| Step: 5
Training loss: 2.4439828395843506
Validation loss: 2.0275029392652613

Epoch: 5| Step: 6
Training loss: 1.7294524908065796
Validation loss: 2.016787875083185

Epoch: 5| Step: 7
Training loss: 2.47637939453125
Validation loss: 2.0167011971114785

Epoch: 5| Step: 8
Training loss: 2.46913743019104
Validation loss: 2.0065178281517437

Epoch: 5| Step: 9
Training loss: 2.411095142364502
Validation loss: 2.01898536374492

Epoch: 5| Step: 10
Training loss: 2.0048577785491943
Validation loss: 2.0092399940695813

Epoch: 88| Step: 0
Training loss: 2.8515334129333496
Validation loss: 2.028239078419183

Epoch: 5| Step: 1
Training loss: 2.4978861808776855
Validation loss: 2.0321323089702155

Epoch: 5| Step: 2
Training loss: 1.8882691860198975
Validation loss: 2.0059783317709483

Epoch: 5| Step: 3
Training loss: 1.9486010074615479
Validation loss: 2.019908097482497

Epoch: 5| Step: 4
Training loss: 2.148606061935425
Validation loss: 2.0154330345892135

Epoch: 5| Step: 5
Training loss: 2.6095833778381348
Validation loss: 2.0279224072733233

Epoch: 5| Step: 6
Training loss: 1.7374241352081299
Validation loss: 2.0244493535769883

Epoch: 5| Step: 7
Training loss: 2.02793025970459
Validation loss: 2.0513653178368845

Epoch: 5| Step: 8
Training loss: 2.000897169113159
Validation loss: 2.007064098952919

Epoch: 5| Step: 9
Training loss: 2.307337999343872
Validation loss: 2.030478428768855

Epoch: 5| Step: 10
Training loss: 2.819331169128418
Validation loss: 2.03161875150537

Epoch: 89| Step: 0
Training loss: 2.2061619758605957
Validation loss: 2.0277683388802314

Epoch: 5| Step: 1
Training loss: 1.8498313426971436
Validation loss: 2.0277183914697297

Epoch: 5| Step: 2
Training loss: 2.5207512378692627
Validation loss: 2.01997725425228

Epoch: 5| Step: 3
Training loss: 2.0139713287353516
Validation loss: 2.0233315908780662

Epoch: 5| Step: 4
Training loss: 1.6349138021469116
Validation loss: 2.036350918072526

Epoch: 5| Step: 5
Training loss: 2.3638153076171875
Validation loss: 2.036575701928908

Epoch: 5| Step: 6
Training loss: 2.5864250659942627
Validation loss: 2.035363189635738

Epoch: 5| Step: 7
Training loss: 1.793470025062561
Validation loss: 2.022806998222105

Epoch: 5| Step: 8
Training loss: 3.114109516143799
Validation loss: 2.0271378819660475

Epoch: 5| Step: 9
Training loss: 2.549414873123169
Validation loss: 2.0451227272710493

Epoch: 5| Step: 10
Training loss: 1.9234751462936401
Validation loss: 2.0201108712022022

Epoch: 90| Step: 0
Training loss: 2.3547582626342773
Validation loss: 2.0169056641158236

Epoch: 5| Step: 1
Training loss: 2.5399508476257324
Validation loss: 2.026598268939603

Epoch: 5| Step: 2
Training loss: 1.9069706201553345
Validation loss: 2.057084983394992

Epoch: 5| Step: 3
Training loss: 2.59346342086792
Validation loss: 2.03204414408694

Epoch: 5| Step: 4
Training loss: 2.4998016357421875
Validation loss: 2.0305274071231967

Epoch: 5| Step: 5
Training loss: 2.3443615436553955
Validation loss: 2.0327144463857016

Epoch: 5| Step: 6
Training loss: 2.2108099460601807
Validation loss: 2.036881298147222

Epoch: 5| Step: 7
Training loss: 1.737282395362854
Validation loss: 2.0229321679761334

Epoch: 5| Step: 8
Training loss: 2.781226396560669
Validation loss: 2.0216053916561987

Epoch: 5| Step: 9
Training loss: 1.8629213571548462
Validation loss: 2.025635883372317

Epoch: 5| Step: 10
Training loss: 1.862959861755371
Validation loss: 2.048525884587278

Epoch: 91| Step: 0
Training loss: 2.74412202835083
Validation loss: 2.034502116582727

Epoch: 5| Step: 1
Training loss: 2.2631659507751465
Validation loss: 2.0451557226078485

Epoch: 5| Step: 2
Training loss: 2.5363545417785645
Validation loss: 2.0255717269835936

Epoch: 5| Step: 3
Training loss: 2.2146947383880615
Validation loss: 2.029022051442054

Epoch: 5| Step: 4
Training loss: 2.1250109672546387
Validation loss: 2.01876760298206

Epoch: 5| Step: 5
Training loss: 2.9973998069763184
Validation loss: 2.020857790464996

Epoch: 5| Step: 6
Training loss: 1.7858368158340454
Validation loss: 2.032854196845844

Epoch: 5| Step: 7
Training loss: 1.9268178939819336
Validation loss: 2.038004711110105

Epoch: 5| Step: 8
Training loss: 2.120217800140381
Validation loss: 2.0379643209518923

Epoch: 5| Step: 9
Training loss: 1.9137541055679321
Validation loss: 2.0243336744205926

Epoch: 5| Step: 10
Training loss: 1.9480791091918945
Validation loss: 2.030613209611626

Epoch: 92| Step: 0
Training loss: 2.5431628227233887
Validation loss: 2.038686539537163

Epoch: 5| Step: 1
Training loss: 2.1411848068237305
Validation loss: 2.043624783074984

Epoch: 5| Step: 2
Training loss: 2.2203798294067383
Validation loss: 2.0368407131523214

Epoch: 5| Step: 3
Training loss: 1.684962272644043
Validation loss: 2.0348385508342455

Epoch: 5| Step: 4
Training loss: 2.6374764442443848
Validation loss: 2.0346365333885275

Epoch: 5| Step: 5
Training loss: 2.5419468879699707
Validation loss: 2.0318505456370692

Epoch: 5| Step: 6
Training loss: 2.159698009490967
Validation loss: 2.037616960463985

Epoch: 5| Step: 7
Training loss: 2.4004452228546143
Validation loss: 2.033978851892615

Epoch: 5| Step: 8
Training loss: 1.95306396484375
Validation loss: 2.026805905885594

Epoch: 5| Step: 9
Training loss: 2.236053943634033
Validation loss: 2.0493283758881273

Epoch: 5| Step: 10
Training loss: 2.115412950515747
Validation loss: 2.0185174224197224

Epoch: 93| Step: 0
Training loss: 2.338524103164673
Validation loss: 2.0425559884758404

Epoch: 5| Step: 1
Training loss: 2.5795416831970215
Validation loss: 2.0393608590608

Epoch: 5| Step: 2
Training loss: 2.326249837875366
Validation loss: 2.034338443509994

Epoch: 5| Step: 3
Training loss: 2.6389548778533936
Validation loss: 2.0490424607389714

Epoch: 5| Step: 4
Training loss: 2.138302803039551
Validation loss: 2.034163974946545

Epoch: 5| Step: 5
Training loss: 1.9403316974639893
Validation loss: 2.0338956386812272

Epoch: 5| Step: 6
Training loss: 2.0398666858673096
Validation loss: 2.022098623296266

Epoch: 5| Step: 7
Training loss: 2.0173251628875732
Validation loss: 2.027928590774536

Epoch: 5| Step: 8
Training loss: 2.66814923286438
Validation loss: 2.0325640734805854

Epoch: 5| Step: 9
Training loss: 1.5716040134429932
Validation loss: 2.038983169422355

Epoch: 5| Step: 10
Training loss: 2.3631367683410645
Validation loss: 2.0236647154695246

Epoch: 94| Step: 0
Training loss: 2.1485302448272705
Validation loss: 2.0239449444637505

Epoch: 5| Step: 1
Training loss: 2.094449520111084
Validation loss: 2.035905691885179

Epoch: 5| Step: 2
Training loss: 2.188385248184204
Validation loss: 2.014310884219344

Epoch: 5| Step: 3
Training loss: 1.9911892414093018
Validation loss: 2.036171523473596

Epoch: 5| Step: 4
Training loss: 2.273566484451294
Validation loss: 2.0347175213598434

Epoch: 5| Step: 5
Training loss: 2.5363621711730957
Validation loss: 2.0199686968198387

Epoch: 5| Step: 6
Training loss: 2.4725334644317627
Validation loss: 2.032111342235278

Epoch: 5| Step: 7
Training loss: 1.7712863683700562
Validation loss: 2.031020846418155

Epoch: 5| Step: 8
Training loss: 2.4140191078186035
Validation loss: 2.0325641529534453

Epoch: 5| Step: 9
Training loss: 2.215924024581909
Validation loss: 2.0314360972373717

Epoch: 5| Step: 10
Training loss: 2.342120409011841
Validation loss: 2.03698258374327

Epoch: 95| Step: 0
Training loss: 1.5124976634979248
Validation loss: 2.0330802163770123

Epoch: 5| Step: 1
Training loss: 2.4687812328338623
Validation loss: 2.022378824090445

Epoch: 5| Step: 2
Training loss: 2.4912545680999756
Validation loss: 2.0294605262817873

Epoch: 5| Step: 3
Training loss: 2.6058707237243652
Validation loss: 2.037482656458373

Epoch: 5| Step: 4
Training loss: 2.0813584327697754
Validation loss: 2.021238665426931

Epoch: 5| Step: 5
Training loss: 2.362751007080078
Validation loss: 2.0258986796102216

Epoch: 5| Step: 6
Training loss: 2.7827634811401367
Validation loss: 2.036938859570411

Epoch: 5| Step: 7
Training loss: 2.5075297355651855
Validation loss: 2.039640550972313

Epoch: 5| Step: 8
Training loss: 1.9759193658828735
Validation loss: 2.025896768416128

Epoch: 5| Step: 9
Training loss: 1.8433735370635986
Validation loss: 2.0292565361146004

Epoch: 5| Step: 10
Training loss: 1.851516842842102
Validation loss: 2.0371955210162747

Epoch: 96| Step: 0
Training loss: 1.9623113870620728
Validation loss: 2.0392303620615313

Epoch: 5| Step: 1
Training loss: 2.5781667232513428
Validation loss: 2.0293211347313336

Epoch: 5| Step: 2
Training loss: 2.261718273162842
Validation loss: 2.0388534530516593

Epoch: 5| Step: 3
Training loss: 1.7707195281982422
Validation loss: 2.0475427578854304

Epoch: 5| Step: 4
Training loss: 2.2730135917663574
Validation loss: 2.0399414518828034

Epoch: 5| Step: 5
Training loss: 2.00750470161438
Validation loss: 2.044669694157057

Epoch: 5| Step: 6
Training loss: 2.4096076488494873
Validation loss: 2.029430450931672

Epoch: 5| Step: 7
Training loss: 2.69404935836792
Validation loss: 2.0377539896195933

Epoch: 5| Step: 8
Training loss: 1.9611270427703857
Validation loss: 2.044127038730088

Epoch: 5| Step: 9
Training loss: 2.333650588989258
Validation loss: 2.032567947141586

Epoch: 5| Step: 10
Training loss: 2.2639598846435547
Validation loss: 2.0335057576497397

Epoch: 97| Step: 0
Training loss: 2.1274940967559814
Validation loss: 2.035420166548862

Epoch: 5| Step: 1
Training loss: 2.613724708557129
Validation loss: 2.0393254205744755

Epoch: 5| Step: 2
Training loss: 2.1637134552001953
Validation loss: 2.0394603078083327

Epoch: 5| Step: 3
Training loss: 1.5769401788711548
Validation loss: 2.0329937922057284

Epoch: 5| Step: 4
Training loss: 1.9822204113006592
Validation loss: 2.0371034734992572

Epoch: 5| Step: 5
Training loss: 2.4127049446105957
Validation loss: 2.0358245244590183

Epoch: 5| Step: 6
Training loss: 1.9102466106414795
Validation loss: 2.0351103800599293

Epoch: 5| Step: 7
Training loss: 3.0052144527435303
Validation loss: 2.0342230232813026

Epoch: 5| Step: 8
Training loss: 2.133840560913086
Validation loss: 2.0337478781259186

Epoch: 5| Step: 9
Training loss: 2.2105278968811035
Validation loss: 2.031880021095276

Epoch: 5| Step: 10
Training loss: 2.3792102336883545
Validation loss: 2.033411923275199

Epoch: 98| Step: 0
Training loss: 2.0471653938293457
Validation loss: 2.051488232868974

Epoch: 5| Step: 1
Training loss: 2.338670253753662
Validation loss: 2.0416145606707503

Epoch: 5| Step: 2
Training loss: 2.2375423908233643
Validation loss: 2.0474975237282376

Epoch: 5| Step: 3
Training loss: 2.5691447257995605
Validation loss: 2.031083027521769

Epoch: 5| Step: 4
Training loss: 2.035193681716919
Validation loss: 2.0439386060160976

Epoch: 5| Step: 5
Training loss: 2.2341957092285156
Validation loss: 2.0435798783456125

Epoch: 5| Step: 6
Training loss: 2.4515323638916016
Validation loss: 2.0347389303227907

Epoch: 5| Step: 7
Training loss: 2.2369728088378906
Validation loss: 2.046578605969747

Epoch: 5| Step: 8
Training loss: 1.9709033966064453
Validation loss: 2.0234753418994207

Epoch: 5| Step: 9
Training loss: 2.1729798316955566
Validation loss: 2.02133176660025

Epoch: 5| Step: 10
Training loss: 2.1375906467437744
Validation loss: 2.0304649440191125

Epoch: 99| Step: 0
Training loss: 2.479480266571045
Validation loss: 2.0360790734649985

Epoch: 5| Step: 1
Training loss: 2.45861554145813
Validation loss: 2.0429935378413044

Epoch: 5| Step: 2
Training loss: 2.6995961666107178
Validation loss: 2.0234575117788007

Epoch: 5| Step: 3
Training loss: 2.0198006629943848
Validation loss: 2.040018338029103

Epoch: 5| Step: 4
Training loss: 2.666334867477417
Validation loss: 2.0390588186120473

Epoch: 5| Step: 5
Training loss: 1.6559216976165771
Validation loss: 2.0432338163416874

Epoch: 5| Step: 6
Training loss: 1.6940510272979736
Validation loss: 2.0301043654000885

Epoch: 5| Step: 7
Training loss: 1.830041527748108
Validation loss: 2.0173938915293705

Epoch: 5| Step: 8
Training loss: 1.9774481058120728
Validation loss: 2.0390754515124905

Epoch: 5| Step: 9
Training loss: 2.558042049407959
Validation loss: 2.0336441211802985

Epoch: 5| Step: 10
Training loss: 2.461709976196289
Validation loss: 2.0279541553989535

Epoch: 100| Step: 0
Training loss: 1.9970906972885132
Validation loss: 2.016389477637506

Epoch: 5| Step: 1
Training loss: 2.0428457260131836
Validation loss: 2.047802334190697

Epoch: 5| Step: 2
Training loss: 2.5660455226898193
Validation loss: 2.0266242347737795

Epoch: 5| Step: 3
Training loss: 2.274531841278076
Validation loss: 2.031867032409996

Epoch: 5| Step: 4
Training loss: 2.2699642181396484
Validation loss: 2.02137170299407

Epoch: 5| Step: 5
Training loss: 2.4693870544433594
Validation loss: 2.023288162805701

Epoch: 5| Step: 6
Training loss: 2.2958359718322754
Validation loss: 2.027178600270261

Epoch: 5| Step: 7
Training loss: 2.2844576835632324
Validation loss: 2.021488553734236

Epoch: 5| Step: 8
Training loss: 1.7821323871612549
Validation loss: 2.0239733688292967

Epoch: 5| Step: 9
Training loss: 2.3516626358032227
Validation loss: 2.0223118694879676

Epoch: 5| Step: 10
Training loss: 2.0728375911712646
Validation loss: 2.0295822902392318

Epoch: 101| Step: 0
Training loss: 2.640751838684082
Validation loss: 2.0213671102318713

Epoch: 5| Step: 1
Training loss: 2.100797176361084
Validation loss: 2.014601799749559

Epoch: 5| Step: 2
Training loss: 2.5376784801483154
Validation loss: 2.0027052548623856

Epoch: 5| Step: 3
Training loss: 2.3434460163116455
Validation loss: 2.0393676091265935

Epoch: 5| Step: 4
Training loss: 2.1567649841308594
Validation loss: 2.0400599946257887

Epoch: 5| Step: 5
Training loss: 2.768970489501953
Validation loss: 2.0062350880715156

Epoch: 5| Step: 6
Training loss: 2.2453606128692627
Validation loss: 2.033393377898842

Epoch: 5| Step: 7
Training loss: 1.979116439819336
Validation loss: 2.032962788817703

Epoch: 5| Step: 8
Training loss: 1.4605430364608765
Validation loss: 2.036970951223886

Epoch: 5| Step: 9
Training loss: 2.2371530532836914
Validation loss: 2.0101320487196728

Epoch: 5| Step: 10
Training loss: 1.7631734609603882
Validation loss: 2.0334853702975857

Epoch: 102| Step: 0
Training loss: 2.395829677581787
Validation loss: 2.026584376570999

Epoch: 5| Step: 1
Training loss: 1.9233700037002563
Validation loss: 2.011311020902408

Epoch: 5| Step: 2
Training loss: 2.215405225753784
Validation loss: 2.027301234583701

Epoch: 5| Step: 3
Training loss: 2.7507388591766357
Validation loss: 2.0307634876620386

Epoch: 5| Step: 4
Training loss: 2.6010959148406982
Validation loss: 2.032441723731256

Epoch: 5| Step: 5
Training loss: 2.351090669631958
Validation loss: 2.040203500819463

Epoch: 5| Step: 6
Training loss: 2.0218305587768555
Validation loss: 2.0373757295711066

Epoch: 5| Step: 7
Training loss: 1.936905860900879
Validation loss: 2.0141866463486866

Epoch: 5| Step: 8
Training loss: 2.1569983959198
Validation loss: 2.0361893048850437

Epoch: 5| Step: 9
Training loss: 1.8144028186798096
Validation loss: 2.0233810409422843

Epoch: 5| Step: 10
Training loss: 2.110323429107666
Validation loss: 2.0220151319298694

Epoch: 103| Step: 0
Training loss: 1.8413035869598389
Validation loss: 2.023070676352388

Epoch: 5| Step: 1
Training loss: 1.987626075744629
Validation loss: 2.0175704981691096

Epoch: 5| Step: 2
Training loss: 2.016313076019287
Validation loss: 2.0244399027157853

Epoch: 5| Step: 3
Training loss: 2.4275527000427246
Validation loss: 2.033842066282867

Epoch: 5| Step: 4
Training loss: 1.9273929595947266
Validation loss: 2.028952767772059

Epoch: 5| Step: 5
Training loss: 2.7646422386169434
Validation loss: 2.0085646388351277

Epoch: 5| Step: 6
Training loss: 2.2736239433288574
Validation loss: 2.0012997529839955

Epoch: 5| Step: 7
Training loss: 2.2965686321258545
Validation loss: 2.0201380534838607

Epoch: 5| Step: 8
Training loss: 1.9789034128189087
Validation loss: 2.0075890966641006

Epoch: 5| Step: 9
Training loss: 2.3047473430633545
Validation loss: 1.9992388576589606

Epoch: 5| Step: 10
Training loss: 2.6038761138916016
Validation loss: 2.014042986336575

Epoch: 104| Step: 0
Training loss: 2.4892988204956055
Validation loss: 2.0105160846505115

Epoch: 5| Step: 1
Training loss: 2.474921703338623
Validation loss: 2.005183889019874

Epoch: 5| Step: 2
Training loss: 1.4946250915527344
Validation loss: 2.018079601308351

Epoch: 5| Step: 3
Training loss: 1.9234451055526733
Validation loss: 2.01972698139888

Epoch: 5| Step: 4
Training loss: 2.340045213699341
Validation loss: 2.025102182101178

Epoch: 5| Step: 5
Training loss: 2.4413483142852783
Validation loss: 2.014018004940402

Epoch: 5| Step: 6
Training loss: 2.1303634643554688
Validation loss: 2.022944103005112

Epoch: 5| Step: 7
Training loss: 2.4433960914611816
Validation loss: 2.0223189246269966

Epoch: 5| Step: 8
Training loss: 2.0825092792510986
Validation loss: 2.006020648505098

Epoch: 5| Step: 9
Training loss: 2.5866737365722656
Validation loss: 2.0069942448728826

Epoch: 5| Step: 10
Training loss: 1.8357607126235962
Validation loss: 2.0212459474481563

Epoch: 105| Step: 0
Training loss: 2.162322759628296
Validation loss: 2.018715912295926

Epoch: 5| Step: 1
Training loss: 2.0105583667755127
Validation loss: 2.0153289033520605

Epoch: 5| Step: 2
Training loss: 2.146137237548828
Validation loss: 2.0422115402836956

Epoch: 5| Step: 3
Training loss: 2.0178256034851074
Validation loss: 2.011398917885237

Epoch: 5| Step: 4
Training loss: 2.945979356765747
Validation loss: 2.0363723308809343

Epoch: 5| Step: 5
Training loss: 1.920310378074646
Validation loss: 2.014957812524611

Epoch: 5| Step: 6
Training loss: 2.2209105491638184
Validation loss: 2.019644319370229

Epoch: 5| Step: 7
Training loss: 1.746201515197754
Validation loss: 2.003512715780607

Epoch: 5| Step: 8
Training loss: 2.182659387588501
Validation loss: 2.0195727796964746

Epoch: 5| Step: 9
Training loss: 2.5282697677612305
Validation loss: 2.02130877330739

Epoch: 5| Step: 10
Training loss: 2.34311842918396
Validation loss: 2.027012055920016

Epoch: 106| Step: 0
Training loss: 2.077627658843994
Validation loss: 2.033960974344643

Epoch: 5| Step: 1
Training loss: 2.3776252269744873
Validation loss: 2.027460523830947

Epoch: 5| Step: 2
Training loss: 2.3989439010620117
Validation loss: 2.0106544122901013

Epoch: 5| Step: 3
Training loss: 2.090554714202881
Validation loss: 2.0154531386590775

Epoch: 5| Step: 4
Training loss: 2.013113498687744
Validation loss: 2.0209464885855235

Epoch: 5| Step: 5
Training loss: 2.2580718994140625
Validation loss: 2.025083380360757

Epoch: 5| Step: 6
Training loss: 2.8811440467834473
Validation loss: 2.007829878919868

Epoch: 5| Step: 7
Training loss: 1.9671337604522705
Validation loss: 2.016904830932617

Epoch: 5| Step: 8
Training loss: 2.104201555252075
Validation loss: 2.0232539202577327

Epoch: 5| Step: 9
Training loss: 2.1891934871673584
Validation loss: 2.011969684272684

Epoch: 5| Step: 10
Training loss: 1.9130444526672363
Validation loss: 2.014565626780192

Epoch: 107| Step: 0
Training loss: 2.185072183609009
Validation loss: 2.0302461603636384

Epoch: 5| Step: 1
Training loss: 2.071587324142456
Validation loss: 2.0271368988098635

Epoch: 5| Step: 2
Training loss: 1.9456212520599365
Validation loss: 2.038233185327181

Epoch: 5| Step: 3
Training loss: 1.922401785850525
Validation loss: 2.0015619800936792

Epoch: 5| Step: 4
Training loss: 2.757368803024292
Validation loss: 2.0075274282886135

Epoch: 5| Step: 5
Training loss: 2.13482403755188
Validation loss: 2.022475637415404

Epoch: 5| Step: 6
Training loss: 2.074598789215088
Validation loss: 2.0239994577182236

Epoch: 5| Step: 7
Training loss: 1.803842544555664
Validation loss: 2.0219452252952

Epoch: 5| Step: 8
Training loss: 2.311016082763672
Validation loss: 2.0360529730396886

Epoch: 5| Step: 9
Training loss: 2.759654998779297
Validation loss: 2.0049185522140993

Epoch: 5| Step: 10
Training loss: 2.236116409301758
Validation loss: 2.0357577621295886

Epoch: 108| Step: 0
Training loss: 2.5045406818389893
Validation loss: 2.0046065879124466

Epoch: 5| Step: 1
Training loss: 1.9728866815567017
Validation loss: 2.0087337942533594

Epoch: 5| Step: 2
Training loss: 1.5466631650924683
Validation loss: 1.9962983515954786

Epoch: 5| Step: 3
Training loss: 2.6058647632598877
Validation loss: 1.993232004104122

Epoch: 5| Step: 4
Training loss: 1.8438713550567627
Validation loss: 2.0284034923840593

Epoch: 5| Step: 5
Training loss: 2.7727863788604736
Validation loss: 1.9973802553710116

Epoch: 5| Step: 6
Training loss: 2.6970648765563965
Validation loss: 2.009375955468865

Epoch: 5| Step: 7
Training loss: 2.00538969039917
Validation loss: 2.023962115728727

Epoch: 5| Step: 8
Training loss: 1.8795280456542969
Validation loss: 1.9980429372479838

Epoch: 5| Step: 9
Training loss: 1.9601033926010132
Validation loss: 2.0174450515418925

Epoch: 5| Step: 10
Training loss: 2.4447522163391113
Validation loss: 2.0206983050992413

Epoch: 109| Step: 0
Training loss: 2.004621982574463
Validation loss: 2.0140006490933

Epoch: 5| Step: 1
Training loss: 3.0778708457946777
Validation loss: 2.011464385576146

Epoch: 5| Step: 2
Training loss: 1.5601961612701416
Validation loss: 2.0268667615869993

Epoch: 5| Step: 3
Training loss: 1.5807422399520874
Validation loss: 2.0211210507218555

Epoch: 5| Step: 4
Training loss: 2.4221889972686768
Validation loss: 2.0437383318460114

Epoch: 5| Step: 5
Training loss: 2.144296884536743
Validation loss: 2.029286276909613

Epoch: 5| Step: 6
Training loss: 2.496805191040039
Validation loss: 2.0390853599835466

Epoch: 5| Step: 7
Training loss: 2.4537811279296875
Validation loss: 2.019648831377747

Epoch: 5| Step: 8
Training loss: 2.2247109413146973
Validation loss: 2.025074105108938

Epoch: 5| Step: 9
Training loss: 2.232144832611084
Validation loss: 2.018873755649854

Epoch: 5| Step: 10
Training loss: 2.0226826667785645
Validation loss: 2.0391875415719967

Epoch: 110| Step: 0
Training loss: 2.9185595512390137
Validation loss: 2.049676061958395

Epoch: 5| Step: 1
Training loss: 1.960740327835083
Validation loss: 2.023709540726036

Epoch: 5| Step: 2
Training loss: 2.510549783706665
Validation loss: 2.020693490582128

Epoch: 5| Step: 3
Training loss: 1.69550359249115
Validation loss: 2.019435417267584

Epoch: 5| Step: 4
Training loss: 2.9082252979278564
Validation loss: 2.0244023017985846

Epoch: 5| Step: 5
Training loss: 1.7356926202774048
Validation loss: 2.025912559160622

Epoch: 5| Step: 6
Training loss: 1.9310767650604248
Validation loss: 2.013758784981184

Epoch: 5| Step: 7
Training loss: 1.8291927576065063
Validation loss: 2.0184543132781982

Epoch: 5| Step: 8
Training loss: 2.4659876823425293
Validation loss: 2.0094257426518265

Epoch: 5| Step: 9
Training loss: 2.2355122566223145
Validation loss: 2.0272070720631588

Epoch: 5| Step: 10
Training loss: 2.0504560470581055
Validation loss: 1.9975740909576416

Epoch: 111| Step: 0
Training loss: 1.7861354351043701
Validation loss: 2.0130625130027853

Epoch: 5| Step: 1
Training loss: 1.541831135749817
Validation loss: 2.010484731325539

Epoch: 5| Step: 2
Training loss: 2.3024582862854004
Validation loss: 2.010340844431231

Epoch: 5| Step: 3
Training loss: 2.7133641242980957
Validation loss: 2.0161011321570284

Epoch: 5| Step: 4
Training loss: 1.9099013805389404
Validation loss: 2.0088116225375923

Epoch: 5| Step: 5
Training loss: 2.3266115188598633
Validation loss: 2.0227713584899902

Epoch: 5| Step: 6
Training loss: 2.6411213874816895
Validation loss: 2.023785488579863

Epoch: 5| Step: 7
Training loss: 2.0976288318634033
Validation loss: 2.001131938349816

Epoch: 5| Step: 8
Training loss: 2.063612699508667
Validation loss: 2.026627548279301

Epoch: 5| Step: 9
Training loss: 2.5281050205230713
Validation loss: 1.9870025598874657

Epoch: 5| Step: 10
Training loss: 2.0423104763031006
Validation loss: 2.0185153894526984

Epoch: 112| Step: 0
Training loss: 2.2295243740081787
Validation loss: 2.0076386979831162

Epoch: 5| Step: 1
Training loss: 2.1254050731658936
Validation loss: 2.031740770545057

Epoch: 5| Step: 2
Training loss: 2.0519068241119385
Validation loss: 2.0366945433360275

Epoch: 5| Step: 3
Training loss: 1.712196707725525
Validation loss: 2.012339431752441

Epoch: 5| Step: 4
Training loss: 3.003709554672241
Validation loss: 2.0230082901575233

Epoch: 5| Step: 5
Training loss: 1.3702589273452759
Validation loss: 2.0238685813001407

Epoch: 5| Step: 6
Training loss: 2.5009164810180664
Validation loss: 2.019152197786557

Epoch: 5| Step: 7
Training loss: 2.2724900245666504
Validation loss: 2.0157197752306537

Epoch: 5| Step: 8
Training loss: 2.1860718727111816
Validation loss: 2.03831168272162

Epoch: 5| Step: 9
Training loss: 2.513143539428711
Validation loss: 2.022189373611122

Epoch: 5| Step: 10
Training loss: 2.1018660068511963
Validation loss: 2.007650001074678

Epoch: 113| Step: 0
Training loss: 2.669471025466919
Validation loss: 2.0145716462084042

Epoch: 5| Step: 1
Training loss: 2.3551039695739746
Validation loss: 2.0184574127197266

Epoch: 5| Step: 2
Training loss: 1.715441107749939
Validation loss: 1.9930217522446827

Epoch: 5| Step: 3
Training loss: 1.8375946283340454
Validation loss: 2.004341935598722

Epoch: 5| Step: 4
Training loss: 2.660348653793335
Validation loss: 2.008795525438042

Epoch: 5| Step: 5
Training loss: 2.177668333053589
Validation loss: 2.022202290514464

Epoch: 5| Step: 6
Training loss: 1.9657644033432007
Validation loss: 2.015613040616435

Epoch: 5| Step: 7
Training loss: 2.7580158710479736
Validation loss: 2.0082231849752445

Epoch: 5| Step: 8
Training loss: 2.1208930015563965
Validation loss: 2.01612336661226

Epoch: 5| Step: 9
Training loss: 1.823594331741333
Validation loss: 2.0304356877521803

Epoch: 5| Step: 10
Training loss: 2.0009403228759766
Validation loss: 2.007684571768648

Epoch: 114| Step: 0
Training loss: 2.8843491077423096
Validation loss: 2.0079263346169585

Epoch: 5| Step: 1
Training loss: 1.7595707178115845
Validation loss: 2.0087017038817048

Epoch: 5| Step: 2
Training loss: 2.112297534942627
Validation loss: 2.0099410523650465

Epoch: 5| Step: 3
Training loss: 2.056567668914795
Validation loss: 2.0222048067277476

Epoch: 5| Step: 4
Training loss: 2.415482759475708
Validation loss: 2.013642623860349

Epoch: 5| Step: 5
Training loss: 2.3629374504089355
Validation loss: 2.0113580355080227

Epoch: 5| Step: 6
Training loss: 2.452549457550049
Validation loss: 2.018097624983839

Epoch: 5| Step: 7
Training loss: 2.2922310829162598
Validation loss: 2.0056293702894643

Epoch: 5| Step: 8
Training loss: 1.5104076862335205
Validation loss: 2.0076463389140304

Epoch: 5| Step: 9
Training loss: 2.281287670135498
Validation loss: 2.0245209304235314

Epoch: 5| Step: 10
Training loss: 1.8314179182052612
Validation loss: 2.0056547375135523

Epoch: 115| Step: 0
Training loss: 1.7536327838897705
Validation loss: 2.016887628903953

Epoch: 5| Step: 1
Training loss: 1.9772319793701172
Validation loss: 2.0174510581519014

Epoch: 5| Step: 2
Training loss: 1.907396674156189
Validation loss: 2.004468805046492

Epoch: 5| Step: 3
Training loss: 1.9369494915008545
Validation loss: 2.005634093797335

Epoch: 5| Step: 4
Training loss: 2.2679660320281982
Validation loss: 2.0171668683328936

Epoch: 5| Step: 5
Training loss: 2.5231988430023193
Validation loss: 1.9949716650029665

Epoch: 5| Step: 6
Training loss: 2.213063955307007
Validation loss: 2.013375691188279

Epoch: 5| Step: 7
Training loss: 2.3115592002868652
Validation loss: 2.0214917967396397

Epoch: 5| Step: 8
Training loss: 2.1176517009735107
Validation loss: 2.0089221590308735

Epoch: 5| Step: 9
Training loss: 2.527409315109253
Validation loss: 1.9905980979242632

Epoch: 5| Step: 10
Training loss: 2.7561850547790527
Validation loss: 2.000407975207093

Epoch: 116| Step: 0
Training loss: 2.0151920318603516
Validation loss: 2.009071953835026

Epoch: 5| Step: 1
Training loss: 2.3850386142730713
Validation loss: 2.018115564059186

Epoch: 5| Step: 2
Training loss: 2.5942931175231934
Validation loss: 2.0119991097398984

Epoch: 5| Step: 3
Training loss: 2.231571674346924
Validation loss: 2.0093640653035973

Epoch: 5| Step: 4
Training loss: 2.451735496520996
Validation loss: 2.001228141528304

Epoch: 5| Step: 5
Training loss: 1.6552711725234985
Validation loss: 2.0145539775971444

Epoch: 5| Step: 6
Training loss: 2.3631067276000977
Validation loss: 2.0233173165270077

Epoch: 5| Step: 7
Training loss: 2.44938325881958
Validation loss: 2.004372776195567

Epoch: 5| Step: 8
Training loss: 2.186171054840088
Validation loss: 2.030881729177249

Epoch: 5| Step: 9
Training loss: 1.8958133459091187
Validation loss: 2.010526490467851

Epoch: 5| Step: 10
Training loss: 1.7616841793060303
Validation loss: 2.0067876615831928

Epoch: 117| Step: 0
Training loss: 2.7138419151306152
Validation loss: 2.0154576404120332

Epoch: 5| Step: 1
Training loss: 2.170947313308716
Validation loss: 2.0205409052551433

Epoch: 5| Step: 2
Training loss: 2.4349536895751953
Validation loss: 2.0264324885542675

Epoch: 5| Step: 3
Training loss: 2.10050892829895
Validation loss: 2.017477975096754

Epoch: 5| Step: 4
Training loss: 1.7680763006210327
Validation loss: 2.0203463672309794

Epoch: 5| Step: 5
Training loss: 2.4463212490081787
Validation loss: 2.0106179380929596

Epoch: 5| Step: 6
Training loss: 1.9115899801254272
Validation loss: 2.0224336808727634

Epoch: 5| Step: 7
Training loss: 2.3762969970703125
Validation loss: 1.9997999334848056

Epoch: 5| Step: 8
Training loss: 1.8321216106414795
Validation loss: 2.0186393363501436

Epoch: 5| Step: 9
Training loss: 1.6444469690322876
Validation loss: 2.0153800774646062

Epoch: 5| Step: 10
Training loss: 2.4825689792633057
Validation loss: 2.0222034915801017

Epoch: 118| Step: 0
Training loss: 2.091831684112549
Validation loss: 2.004931738299708

Epoch: 5| Step: 1
Training loss: 2.7437682151794434
Validation loss: 2.022785993032558

Epoch: 5| Step: 2
Training loss: 1.9279849529266357
Validation loss: 2.01487313291078

Epoch: 5| Step: 3
Training loss: 1.6477762460708618
Validation loss: 2.0133255579138316

Epoch: 5| Step: 4
Training loss: 1.516408920288086
Validation loss: 2.0147091086192797

Epoch: 5| Step: 5
Training loss: 1.8225736618041992
Validation loss: 2.011223614856761

Epoch: 5| Step: 6
Training loss: 2.2599990367889404
Validation loss: 2.0132219919594387

Epoch: 5| Step: 7
Training loss: 2.944751024246216
Validation loss: 1.9982150421347669

Epoch: 5| Step: 8
Training loss: 2.2566676139831543
Validation loss: 2.021046442370261

Epoch: 5| Step: 9
Training loss: 3.0330216884613037
Validation loss: 2.012261175340222

Epoch: 5| Step: 10
Training loss: 1.593843698501587
Validation loss: 1.9868309267105595

Epoch: 119| Step: 0
Training loss: 2.6939616203308105
Validation loss: 2.0181016255450506

Epoch: 5| Step: 1
Training loss: 2.1886887550354004
Validation loss: 2.0107967097272157

Epoch: 5| Step: 2
Training loss: 2.63299560546875
Validation loss: 2.0172568585283015

Epoch: 5| Step: 3
Training loss: 2.0314183235168457
Validation loss: 2.009474813297231

Epoch: 5| Step: 4
Training loss: 2.4352259635925293
Validation loss: 2.0163583165855816

Epoch: 5| Step: 5
Training loss: 2.2202799320220947
Validation loss: 1.9972804284864856

Epoch: 5| Step: 6
Training loss: 2.2985382080078125
Validation loss: 1.9986181130973242

Epoch: 5| Step: 7
Training loss: 1.7802612781524658
Validation loss: 2.022817328412046

Epoch: 5| Step: 8
Training loss: 1.879014253616333
Validation loss: 2.0161089999701387

Epoch: 5| Step: 9
Training loss: 1.7629436254501343
Validation loss: 2.0304895870147215

Epoch: 5| Step: 10
Training loss: 1.895098328590393
Validation loss: 2.008489836928665

Epoch: 120| Step: 0
Training loss: 2.3711066246032715
Validation loss: 2.0081239220916585

Epoch: 5| Step: 1
Training loss: 2.633894443511963
Validation loss: 2.0181098599587717

Epoch: 5| Step: 2
Training loss: 2.3465278148651123
Validation loss: 2.018432508232773

Epoch: 5| Step: 3
Training loss: 1.9611656665802002
Validation loss: 2.022209446917298

Epoch: 5| Step: 4
Training loss: 2.178609848022461
Validation loss: 2.005999634342809

Epoch: 5| Step: 5
Training loss: 2.0262656211853027
Validation loss: 2.006948724869759

Epoch: 5| Step: 6
Training loss: 1.9664106369018555
Validation loss: 2.0066220388617566

Epoch: 5| Step: 7
Training loss: 1.7520135641098022
Validation loss: 2.0099345381541918

Epoch: 5| Step: 8
Training loss: 2.191861391067505
Validation loss: 2.0349740033508628

Epoch: 5| Step: 9
Training loss: 2.4449751377105713
Validation loss: 2.006425185870099

Epoch: 5| Step: 10
Training loss: 2.0296261310577393
Validation loss: 2.02024596224549

Epoch: 121| Step: 0
Training loss: 2.675048351287842
Validation loss: 2.014955223247569

Epoch: 5| Step: 1
Training loss: 1.970907211303711
Validation loss: 2.0012613522109164

Epoch: 5| Step: 2
Training loss: 2.006150484085083
Validation loss: 2.0284646928951306

Epoch: 5| Step: 3
Training loss: 1.9271647930145264
Validation loss: 2.0159476854467906

Epoch: 5| Step: 4
Training loss: 1.895573377609253
Validation loss: 2.0121237795840026

Epoch: 5| Step: 5
Training loss: 1.9096237421035767
Validation loss: 2.0207203729178316

Epoch: 5| Step: 6
Training loss: 2.8188183307647705
Validation loss: 2.0220480067755586

Epoch: 5| Step: 7
Training loss: 2.0873827934265137
Validation loss: 2.0072814802969656

Epoch: 5| Step: 8
Training loss: 1.7975513935089111
Validation loss: 2.0291064452099543

Epoch: 5| Step: 9
Training loss: 2.0786900520324707
Validation loss: 2.0154479588231733

Epoch: 5| Step: 10
Training loss: 2.815983295440674
Validation loss: 2.01444366926788

Epoch: 122| Step: 0
Training loss: 2.1195197105407715
Validation loss: 2.0162319085931264

Epoch: 5| Step: 1
Training loss: 2.125476121902466
Validation loss: 2.0005266153684227

Epoch: 5| Step: 2
Training loss: 2.3182168006896973
Validation loss: 2.0089374819109516

Epoch: 5| Step: 3
Training loss: 1.8290674686431885
Validation loss: 2.0063209097872496

Epoch: 5| Step: 4
Training loss: 2.059053421020508
Validation loss: 2.029562157969321

Epoch: 5| Step: 5
Training loss: 2.552199125289917
Validation loss: 1.9989668707693777

Epoch: 5| Step: 6
Training loss: 2.432065010070801
Validation loss: 2.0126850041010047

Epoch: 5| Step: 7
Training loss: 2.111889123916626
Validation loss: 2.017706517250307

Epoch: 5| Step: 8
Training loss: 2.180483341217041
Validation loss: 2.01522558863445

Epoch: 5| Step: 9
Training loss: 2.0884525775909424
Validation loss: 2.039213034414476

Epoch: 5| Step: 10
Training loss: 2.0513064861297607
Validation loss: 2.001820497615363

Epoch: 123| Step: 0
Training loss: 2.799571990966797
Validation loss: 1.994114024664766

Epoch: 5| Step: 1
Training loss: 1.9974987506866455
Validation loss: 2.0117267562497045

Epoch: 5| Step: 2
Training loss: 1.6648426055908203
Validation loss: 2.0060852009763

Epoch: 5| Step: 3
Training loss: 2.453031063079834
Validation loss: 2.0434917378169235

Epoch: 5| Step: 4
Training loss: 2.3811020851135254
Validation loss: 2.02575058321799

Epoch: 5| Step: 5
Training loss: 1.8492225408554077
Validation loss: 2.0236477441685174

Epoch: 5| Step: 6
Training loss: 1.9585158824920654
Validation loss: 2.00829436702113

Epoch: 5| Step: 7
Training loss: 1.679461121559143
Validation loss: 2.018593298491611

Epoch: 5| Step: 8
Training loss: 2.1149845123291016
Validation loss: 2.0060796609488865

Epoch: 5| Step: 9
Training loss: 2.326838970184326
Validation loss: 2.0099089901934386

Epoch: 5| Step: 10
Training loss: 2.7693028450012207
Validation loss: 2.015179080347861

Epoch: 124| Step: 0
Training loss: 2.2126410007476807
Validation loss: 2.0138223068688506

Epoch: 5| Step: 1
Training loss: 2.4042563438415527
Validation loss: 2.0188123846566803

Epoch: 5| Step: 2
Training loss: 2.1074471473693848
Validation loss: 2.004698735411449

Epoch: 5| Step: 3
Training loss: 2.2082886695861816
Validation loss: 2.026869503400659

Epoch: 5| Step: 4
Training loss: 1.8164398670196533
Validation loss: 2.0091668482749694

Epoch: 5| Step: 5
Training loss: 2.311854600906372
Validation loss: 1.9888050274182392

Epoch: 5| Step: 6
Training loss: 2.7364232540130615
Validation loss: 2.018117714953679

Epoch: 5| Step: 7
Training loss: 1.6506869792938232
Validation loss: 2.0071267261300036

Epoch: 5| Step: 8
Training loss: 2.3581948280334473
Validation loss: 2.012853894182431

Epoch: 5| Step: 9
Training loss: 2.1573452949523926
Validation loss: 2.0063512556014524

Epoch: 5| Step: 10
Training loss: 1.7704572677612305
Validation loss: 2.008955363304384

Epoch: 125| Step: 0
Training loss: 2.376621961593628
Validation loss: 2.00688595925608

Epoch: 5| Step: 1
Training loss: 1.909908652305603
Validation loss: 2.0156211545390468

Epoch: 5| Step: 2
Training loss: 1.9082107543945312
Validation loss: 2.003630979086763

Epoch: 5| Step: 3
Training loss: 1.99819815158844
Validation loss: 2.003259854931985

Epoch: 5| Step: 4
Training loss: 1.8321841955184937
Validation loss: 2.001281161462107

Epoch: 5| Step: 5
Training loss: 2.3885772228240967
Validation loss: 2.015568492233112

Epoch: 5| Step: 6
Training loss: 2.592855930328369
Validation loss: 2.017574046247749

Epoch: 5| Step: 7
Training loss: 2.0100467205047607
Validation loss: 2.005455450345111

Epoch: 5| Step: 8
Training loss: 2.1071276664733887
Validation loss: 1.9836776288606788

Epoch: 5| Step: 9
Training loss: 2.157215118408203
Validation loss: 2.00753076230326

Epoch: 5| Step: 10
Training loss: 2.6286001205444336
Validation loss: 1.9993556468717513

Epoch: 126| Step: 0
Training loss: 2.4278416633605957
Validation loss: 2.017198311385288

Epoch: 5| Step: 1
Training loss: 2.2438416481018066
Validation loss: 2.0120805258392007

Epoch: 5| Step: 2
Training loss: 2.896894931793213
Validation loss: 1.989767700113276

Epoch: 5| Step: 3
Training loss: 2.223689556121826
Validation loss: 2.0319093991351385

Epoch: 5| Step: 4
Training loss: 1.8650596141815186
Validation loss: 2.0096364969848306

Epoch: 5| Step: 5
Training loss: 2.3148458003997803
Validation loss: 1.9991956628778929

Epoch: 5| Step: 6
Training loss: 1.2075791358947754
Validation loss: 2.011072926623847

Epoch: 5| Step: 7
Training loss: 2.398524761199951
Validation loss: 2.0187640164488103

Epoch: 5| Step: 8
Training loss: 1.9667965173721313
Validation loss: 2.021373748779297

Epoch: 5| Step: 9
Training loss: 2.222351551055908
Validation loss: 2.0028988699759207

Epoch: 5| Step: 10
Training loss: 1.9895416498184204
Validation loss: 2.007004931408872

Epoch: 127| Step: 0
Training loss: 2.60688853263855
Validation loss: 1.9944966467477943

Epoch: 5| Step: 1
Training loss: 2.1595168113708496
Validation loss: 2.022816140164611

Epoch: 5| Step: 2
Training loss: 2.695343494415283
Validation loss: 1.9914753167859969

Epoch: 5| Step: 3
Training loss: 1.8424152135849
Validation loss: 1.9996700863684378

Epoch: 5| Step: 4
Training loss: 1.7808990478515625
Validation loss: 2.0141120802971626

Epoch: 5| Step: 5
Training loss: 1.9721006155014038
Validation loss: 2.013857500527495

Epoch: 5| Step: 6
Training loss: 1.9717788696289062
Validation loss: 2.0096941609536447

Epoch: 5| Step: 7
Training loss: 2.0621821880340576
Validation loss: 2.0169083418384677

Epoch: 5| Step: 8
Training loss: 2.4777228832244873
Validation loss: 2.0171256475551154

Epoch: 5| Step: 9
Training loss: 2.0151007175445557
Validation loss: 2.0185594866352696

Epoch: 5| Step: 10
Training loss: 2.1915974617004395
Validation loss: 1.997511980354145

Epoch: 128| Step: 0
Training loss: 2.480243444442749
Validation loss: 2.005929885372039

Epoch: 5| Step: 1
Training loss: 2.0540401935577393
Validation loss: 2.008929419261153

Epoch: 5| Step: 2
Training loss: 1.4282395839691162
Validation loss: 2.014172533506988

Epoch: 5| Step: 3
Training loss: 2.2910735607147217
Validation loss: 2.0180844235163864

Epoch: 5| Step: 4
Training loss: 1.8587305545806885
Validation loss: 2.0169741210117134

Epoch: 5| Step: 5
Training loss: 2.6948165893554688
Validation loss: 2.01114627879153

Epoch: 5| Step: 6
Training loss: 1.6811988353729248
Validation loss: 1.99499636824413

Epoch: 5| Step: 7
Training loss: 2.175126552581787
Validation loss: 2.003692373152702

Epoch: 5| Step: 8
Training loss: 2.4519758224487305
Validation loss: 1.9984120399721208

Epoch: 5| Step: 9
Training loss: 2.3565149307250977
Validation loss: 1.998769780640961

Epoch: 5| Step: 10
Training loss: 2.2758021354675293
Validation loss: 2.0040610990216656

Epoch: 129| Step: 0
Training loss: 2.0175204277038574
Validation loss: 2.002329750727582

Epoch: 5| Step: 1
Training loss: 1.9022235870361328
Validation loss: 2.000232283787061

Epoch: 5| Step: 2
Training loss: 1.8524830341339111
Validation loss: 1.9978467854120399

Epoch: 5| Step: 3
Training loss: 2.1516857147216797
Validation loss: 2.027595776383595

Epoch: 5| Step: 4
Training loss: 2.155611515045166
Validation loss: 2.01345476283822

Epoch: 5| Step: 5
Training loss: 2.716181755065918
Validation loss: 2.0124301038762575

Epoch: 5| Step: 6
Training loss: 1.7615635395050049
Validation loss: 2.012633059614448

Epoch: 5| Step: 7
Training loss: 1.6747913360595703
Validation loss: 2.0264791980866463

Epoch: 5| Step: 8
Training loss: 2.07322359085083
Validation loss: 2.0274060592856458

Epoch: 5| Step: 9
Training loss: 2.2877304553985596
Validation loss: 2.0140494428655153

Epoch: 5| Step: 10
Training loss: 3.0570616722106934
Validation loss: 2.010223123335069

Epoch: 130| Step: 0
Training loss: 2.428295135498047
Validation loss: 1.9954569621752667

Epoch: 5| Step: 1
Training loss: 2.6980643272399902
Validation loss: 2.002461261646722

Epoch: 5| Step: 2
Training loss: 1.9119220972061157
Validation loss: 2.003832854250426

Epoch: 5| Step: 3
Training loss: 2.2787723541259766
Validation loss: 1.9828673588332308

Epoch: 5| Step: 4
Training loss: 1.8854124546051025
Validation loss: 1.987429367598667

Epoch: 5| Step: 5
Training loss: 1.6596357822418213
Validation loss: 2.0193458859638502

Epoch: 5| Step: 6
Training loss: 1.9462276697158813
Validation loss: 1.9949362867621965

Epoch: 5| Step: 7
Training loss: 2.3143348693847656
Validation loss: 1.9992463742533038

Epoch: 5| Step: 8
Training loss: 2.1630871295928955
Validation loss: 2.0110172020491732

Epoch: 5| Step: 9
Training loss: 1.8751089572906494
Validation loss: 2.0052942101673414

Epoch: 5| Step: 10
Training loss: 2.4894607067108154
Validation loss: 2.0266728503729707

Epoch: 131| Step: 0
Training loss: 1.76898992061615
Validation loss: 1.9967900732512116

Epoch: 5| Step: 1
Training loss: 2.014852523803711
Validation loss: 2.001549268281588

Epoch: 5| Step: 2
Training loss: 2.0372912883758545
Validation loss: 2.0060738363573627

Epoch: 5| Step: 3
Training loss: 1.6496013402938843
Validation loss: 1.9993442027799544

Epoch: 5| Step: 4
Training loss: 2.7452328205108643
Validation loss: 2.004608327342618

Epoch: 5| Step: 5
Training loss: 2.383418560028076
Validation loss: 1.9990737912475423

Epoch: 5| Step: 6
Training loss: 1.9137580394744873
Validation loss: 2.0109211949891943

Epoch: 5| Step: 7
Training loss: 2.389280080795288
Validation loss: 2.0181546006151425

Epoch: 5| Step: 8
Training loss: 2.2929272651672363
Validation loss: 2.001960198084513

Epoch: 5| Step: 9
Training loss: 1.9146521091461182
Validation loss: 2.001480033320765

Epoch: 5| Step: 10
Training loss: 2.79425311088562
Validation loss: 2.0157204879227506

Epoch: 132| Step: 0
Training loss: 1.867903470993042
Validation loss: 2.004716275840677

Epoch: 5| Step: 1
Training loss: 2.324862480163574
Validation loss: 2.0032878165603965

Epoch: 5| Step: 2
Training loss: 1.9994217157363892
Validation loss: 2.0059755694481636

Epoch: 5| Step: 3
Training loss: 1.7794740200042725
Validation loss: 2.0108907863657963

Epoch: 5| Step: 4
Training loss: 1.951422095298767
Validation loss: 2.004936738680768

Epoch: 5| Step: 5
Training loss: 2.008220672607422
Validation loss: 2.0199214617411294

Epoch: 5| Step: 6
Training loss: 2.5462241172790527
Validation loss: 1.9985608349564254

Epoch: 5| Step: 7
Training loss: 2.4538674354553223
Validation loss: 1.9979618518583235

Epoch: 5| Step: 8
Training loss: 1.6794424057006836
Validation loss: 2.012885488489623

Epoch: 5| Step: 9
Training loss: 2.381929874420166
Validation loss: 2.017372808148784

Epoch: 5| Step: 10
Training loss: 2.760014295578003
Validation loss: 1.9946341027495682

Epoch: 133| Step: 0
Training loss: 2.4058899879455566
Validation loss: 1.9960146309227071

Epoch: 5| Step: 1
Training loss: 2.47731876373291
Validation loss: 1.992960299215009

Epoch: 5| Step: 2
Training loss: 2.2045180797576904
Validation loss: 2.011451029008435

Epoch: 5| Step: 3
Training loss: 1.680665373802185
Validation loss: 2.013998164925524

Epoch: 5| Step: 4
Training loss: 1.637670874595642
Validation loss: 2.017405056184338

Epoch: 5| Step: 5
Training loss: 3.3187241554260254
Validation loss: 2.0071892148704937

Epoch: 5| Step: 6
Training loss: 1.9340248107910156
Validation loss: 1.9920944654813377

Epoch: 5| Step: 7
Training loss: 2.2995574474334717
Validation loss: 2.0048822331172165

Epoch: 5| Step: 8
Training loss: 1.6065094470977783
Validation loss: 2.008048424156763

Epoch: 5| Step: 9
Training loss: 2.055495500564575
Validation loss: 2.0089294064429497

Epoch: 5| Step: 10
Training loss: 2.072427749633789
Validation loss: 1.998887138981973

Epoch: 134| Step: 0
Training loss: 2.4948577880859375
Validation loss: 2.0171195973632154

Epoch: 5| Step: 1
Training loss: 2.773728847503662
Validation loss: 2.017165812112952

Epoch: 5| Step: 2
Training loss: 2.1936535835266113
Validation loss: 1.9929906886111024

Epoch: 5| Step: 3
Training loss: 2.2754759788513184
Validation loss: 2.002183903930008

Epoch: 5| Step: 4
Training loss: 2.0480704307556152
Validation loss: 2.020930678613724

Epoch: 5| Step: 5
Training loss: 1.9543756246566772
Validation loss: 1.9926767964516916

Epoch: 5| Step: 6
Training loss: 1.7621228694915771
Validation loss: 1.9781858690323368

Epoch: 5| Step: 7
Training loss: 1.8364677429199219
Validation loss: 1.9992146184367519

Epoch: 5| Step: 8
Training loss: 2.466585397720337
Validation loss: 2.0057535427872852

Epoch: 5| Step: 9
Training loss: 1.8506419658660889
Validation loss: 1.9978185264013146

Epoch: 5| Step: 10
Training loss: 1.8257564306259155
Validation loss: 1.9932164645964099

Epoch: 135| Step: 0
Training loss: 2.3674168586730957
Validation loss: 2.0052713912020446

Epoch: 5| Step: 1
Training loss: 1.824911117553711
Validation loss: 2.00379172448189

Epoch: 5| Step: 2
Training loss: 1.5315077304840088
Validation loss: 1.9759582652840564

Epoch: 5| Step: 3
Training loss: 2.191314697265625
Validation loss: 2.0190299762192594

Epoch: 5| Step: 4
Training loss: 1.9737999439239502
Validation loss: 2.003159297409878

Epoch: 5| Step: 5
Training loss: 1.774757742881775
Validation loss: 1.9934018606780677

Epoch: 5| Step: 6
Training loss: 2.592744827270508
Validation loss: 1.9988164209550427

Epoch: 5| Step: 7
Training loss: 1.5933709144592285
Validation loss: 1.999363673630581

Epoch: 5| Step: 8
Training loss: 2.5227575302124023
Validation loss: 2.0056599814404725

Epoch: 5| Step: 9
Training loss: 2.6340863704681396
Validation loss: 2.011501307128578

Epoch: 5| Step: 10
Training loss: 2.759876012802124
Validation loss: 2.0098322335109917

Epoch: 136| Step: 0
Training loss: 1.5613367557525635
Validation loss: 1.987695901624618

Epoch: 5| Step: 1
Training loss: 2.515817642211914
Validation loss: 2.007330354823861

Epoch: 5| Step: 2
Training loss: 2.257047176361084
Validation loss: 2.0024051012531405

Epoch: 5| Step: 3
Training loss: 2.385845899581909
Validation loss: 1.998924191280078

Epoch: 5| Step: 4
Training loss: 2.384726047515869
Validation loss: 2.019762721112979

Epoch: 5| Step: 5
Training loss: 2.706711530685425
Validation loss: 2.011626133354761

Epoch: 5| Step: 6
Training loss: 2.0438287258148193
Validation loss: 2.0035001001050396

Epoch: 5| Step: 7
Training loss: 2.085501194000244
Validation loss: 2.000582520679761

Epoch: 5| Step: 8
Training loss: 2.0606229305267334
Validation loss: 2.0090576038565686

Epoch: 5| Step: 9
Training loss: 1.6085971593856812
Validation loss: 2.0178508899545156

Epoch: 5| Step: 10
Training loss: 1.818126916885376
Validation loss: 2.0039726508561

Epoch: 137| Step: 0
Training loss: 1.969982385635376
Validation loss: 1.9993450333995204

Epoch: 5| Step: 1
Training loss: 2.3328700065612793
Validation loss: 2.001271305545684

Epoch: 5| Step: 2
Training loss: 1.968380331993103
Validation loss: 2.019442921043724

Epoch: 5| Step: 3
Training loss: 1.746996283531189
Validation loss: 1.9875679605750627

Epoch: 5| Step: 4
Training loss: 2.010911464691162
Validation loss: 2.003921398552515

Epoch: 5| Step: 5
Training loss: 2.5276927947998047
Validation loss: 2.005121633570681

Epoch: 5| Step: 6
Training loss: 2.0671701431274414
Validation loss: 2.004484171508461

Epoch: 5| Step: 7
Training loss: 2.2850804328918457
Validation loss: 2.0109993847467567

Epoch: 5| Step: 8
Training loss: 2.5057430267333984
Validation loss: 2.004102204435615

Epoch: 5| Step: 9
Training loss: 2.010920524597168
Validation loss: 2.0065821652771323

Epoch: 5| Step: 10
Training loss: 2.1651859283447266
Validation loss: 2.005662759145101

Epoch: 138| Step: 0
Training loss: 1.895655632019043
Validation loss: 2.0048685099488948

Epoch: 5| Step: 1
Training loss: 2.197038173675537
Validation loss: 2.021714125910113

Epoch: 5| Step: 2
Training loss: 2.0723586082458496
Validation loss: 2.0061467898789274

Epoch: 5| Step: 3
Training loss: 2.357280731201172
Validation loss: 2.014753827484705

Epoch: 5| Step: 4
Training loss: 2.4417319297790527
Validation loss: 1.9887939986362253

Epoch: 5| Step: 5
Training loss: 1.5924322605133057
Validation loss: 2.0113691950357087

Epoch: 5| Step: 6
Training loss: 2.1924118995666504
Validation loss: 1.9919356453803279

Epoch: 5| Step: 7
Training loss: 2.545728921890259
Validation loss: 1.985962002508102

Epoch: 5| Step: 8
Training loss: 2.119865894317627
Validation loss: 1.9942457419569775

Epoch: 5| Step: 9
Training loss: 1.7071406841278076
Validation loss: 2.008586927126813

Epoch: 5| Step: 10
Training loss: 2.292799234390259
Validation loss: 2.0239507511097896

Epoch: 139| Step: 0
Training loss: 2.168846607208252
Validation loss: 2.000704934520106

Epoch: 5| Step: 1
Training loss: 2.342897415161133
Validation loss: 2.0142382985802105

Epoch: 5| Step: 2
Training loss: 1.9497082233428955
Validation loss: 1.9896309760309034

Epoch: 5| Step: 3
Training loss: 1.5542265176773071
Validation loss: 1.9981164368250037

Epoch: 5| Step: 4
Training loss: 2.2260537147521973
Validation loss: 2.0041284317611368

Epoch: 5| Step: 5
Training loss: 2.457826614379883
Validation loss: 1.986518914981555

Epoch: 5| Step: 6
Training loss: 2.2618956565856934
Validation loss: 1.9928138230436592

Epoch: 5| Step: 7
Training loss: 2.0743815898895264
Validation loss: 2.002738401453982

Epoch: 5| Step: 8
Training loss: 2.5001778602600098
Validation loss: 2.015162315419925

Epoch: 5| Step: 9
Training loss: 1.9197126626968384
Validation loss: 2.0004828181318057

Epoch: 5| Step: 10
Training loss: 1.940205693244934
Validation loss: 2.000757077688812

Epoch: 140| Step: 0
Training loss: 1.9739373922348022
Validation loss: 2.0099628369013467

Epoch: 5| Step: 1
Training loss: 2.4988858699798584
Validation loss: 1.9872588713963826

Epoch: 5| Step: 2
Training loss: 2.2317237854003906
Validation loss: 1.9753719350343109

Epoch: 5| Step: 3
Training loss: 2.145437002182007
Validation loss: 1.9997734446679392

Epoch: 5| Step: 4
Training loss: 1.6286449432373047
Validation loss: 2.001382120193974

Epoch: 5| Step: 5
Training loss: 2.746088981628418
Validation loss: 1.9885342018578642

Epoch: 5| Step: 6
Training loss: 1.6885048151016235
Validation loss: 2.012647444202054

Epoch: 5| Step: 7
Training loss: 2.1849329471588135
Validation loss: 2.017265460824454

Epoch: 5| Step: 8
Training loss: 2.2018227577209473
Validation loss: 1.999104606207981

Epoch: 5| Step: 9
Training loss: 1.9195064306259155
Validation loss: 1.9956833572797879

Epoch: 5| Step: 10
Training loss: 2.381906509399414
Validation loss: 1.9826290697179816

Epoch: 141| Step: 0
Training loss: 2.1605372428894043
Validation loss: 2.000168837526793

Epoch: 5| Step: 1
Training loss: 2.081265449523926
Validation loss: 2.0056487719217935

Epoch: 5| Step: 2
Training loss: 2.2515625953674316
Validation loss: 2.0125636298169374

Epoch: 5| Step: 3
Training loss: 2.803676128387451
Validation loss: 2.0095762193843885

Epoch: 5| Step: 4
Training loss: 1.8228222131729126
Validation loss: 2.001405490342007

Epoch: 5| Step: 5
Training loss: 1.730743408203125
Validation loss: 2.002172613656649

Epoch: 5| Step: 6
Training loss: 1.899275779724121
Validation loss: 2.0068001260039625

Epoch: 5| Step: 7
Training loss: 2.259019613265991
Validation loss: 2.008530993615427

Epoch: 5| Step: 8
Training loss: 2.1322662830352783
Validation loss: 2.0192873554845012

Epoch: 5| Step: 9
Training loss: 1.7211366891860962
Validation loss: 1.9863028616033576

Epoch: 5| Step: 10
Training loss: 2.701559066772461
Validation loss: 1.9989177232147546

Epoch: 142| Step: 0
Training loss: 1.9293467998504639
Validation loss: 2.009754632108955

Epoch: 5| Step: 1
Training loss: 2.3426947593688965
Validation loss: 2.017804443195302

Epoch: 5| Step: 2
Training loss: 2.214317798614502
Validation loss: 1.9992708954759824

Epoch: 5| Step: 3
Training loss: 2.5417449474334717
Validation loss: 1.9901427966292187

Epoch: 5| Step: 4
Training loss: 2.1441221237182617
Validation loss: 2.0015256148512646

Epoch: 5| Step: 5
Training loss: 1.7728643417358398
Validation loss: 1.9870356898153982

Epoch: 5| Step: 6
Training loss: 2.13454270362854
Validation loss: 1.9900502825296054

Epoch: 5| Step: 7
Training loss: 2.646993637084961
Validation loss: 1.9865750587114723

Epoch: 5| Step: 8
Training loss: 1.6738088130950928
Validation loss: 1.972424643014067

Epoch: 5| Step: 9
Training loss: 1.9313685894012451
Validation loss: 1.97691894859396

Epoch: 5| Step: 10
Training loss: 1.9697855710983276
Validation loss: 1.9984494524617349

Epoch: 143| Step: 0
Training loss: 1.754220962524414
Validation loss: 2.025506786120835

Epoch: 5| Step: 1
Training loss: 1.7937806844711304
Validation loss: 1.9981861165774766

Epoch: 5| Step: 2
Training loss: 2.019083261489868
Validation loss: 2.0012155707164476

Epoch: 5| Step: 3
Training loss: 1.8358914852142334
Validation loss: 2.0070301050780923

Epoch: 5| Step: 4
Training loss: 2.893328905105591
Validation loss: 1.9866606138085807

Epoch: 5| Step: 5
Training loss: 2.2245638370513916
Validation loss: 1.999854339066372

Epoch: 5| Step: 6
Training loss: 2.227729558944702
Validation loss: 1.9924282835375877

Epoch: 5| Step: 7
Training loss: 1.7684190273284912
Validation loss: 1.9948682695306756

Epoch: 5| Step: 8
Training loss: 2.3547723293304443
Validation loss: 1.9836849140864548

Epoch: 5| Step: 9
Training loss: 2.2858223915100098
Validation loss: 1.9914373736227713

Epoch: 5| Step: 10
Training loss: 2.0452792644500732
Validation loss: 2.0055756530454083

Epoch: 144| Step: 0
Training loss: 2.2394790649414062
Validation loss: 1.982028986818047

Epoch: 5| Step: 1
Training loss: 2.552053451538086
Validation loss: 2.0006550460733394

Epoch: 5| Step: 2
Training loss: 1.8897956609725952
Validation loss: 2.0071795422543763

Epoch: 5| Step: 3
Training loss: 2.097683906555176
Validation loss: 2.0035859000298286

Epoch: 5| Step: 4
Training loss: 1.6529827117919922
Validation loss: 2.0155462782870055

Epoch: 5| Step: 5
Training loss: 1.993410348892212
Validation loss: 2.0099353264736872

Epoch: 5| Step: 6
Training loss: 2.083951950073242
Validation loss: 2.0277375354561755

Epoch: 5| Step: 7
Training loss: 2.1914167404174805
Validation loss: 1.9968312619834818

Epoch: 5| Step: 8
Training loss: 1.9352095127105713
Validation loss: 2.0090402595458494

Epoch: 5| Step: 9
Training loss: 2.0299994945526123
Validation loss: 2.004436400628859

Epoch: 5| Step: 10
Training loss: 2.8002607822418213
Validation loss: 1.9895655083399948

Epoch: 145| Step: 0
Training loss: 1.4922449588775635
Validation loss: 2.010541740284171

Epoch: 5| Step: 1
Training loss: 2.6362738609313965
Validation loss: 1.9935167425422258

Epoch: 5| Step: 2
Training loss: 2.659261465072632
Validation loss: 1.9920045791133758

Epoch: 5| Step: 3
Training loss: 2.0482921600341797
Validation loss: 1.998256383403655

Epoch: 5| Step: 4
Training loss: 2.7324016094207764
Validation loss: 2.0231646107089136

Epoch: 5| Step: 5
Training loss: 1.8265869617462158
Validation loss: 2.0128963519168157

Epoch: 5| Step: 6
Training loss: 2.185173511505127
Validation loss: 1.9998682750168668

Epoch: 5| Step: 7
Training loss: 1.5640442371368408
Validation loss: 2.0061753719083724

Epoch: 5| Step: 8
Training loss: 2.2481861114501953
Validation loss: 2.001001359314047

Epoch: 5| Step: 9
Training loss: 2.1150472164154053
Validation loss: 2.0226085493641515

Epoch: 5| Step: 10
Training loss: 1.8676273822784424
Validation loss: 2.008632275366014

Epoch: 146| Step: 0
Training loss: 2.3927557468414307
Validation loss: 1.9928301329253821

Epoch: 5| Step: 1
Training loss: 2.3984451293945312
Validation loss: 2.020565238050235

Epoch: 5| Step: 2
Training loss: 1.4897409677505493
Validation loss: 1.9910033005540089

Epoch: 5| Step: 3
Training loss: 2.104386329650879
Validation loss: 2.0134824732298493

Epoch: 5| Step: 4
Training loss: 2.236560821533203
Validation loss: 1.999820980974423

Epoch: 5| Step: 5
Training loss: 2.3405158519744873
Validation loss: 2.018976902449003

Epoch: 5| Step: 6
Training loss: 2.0515618324279785
Validation loss: 1.9898885732055993

Epoch: 5| Step: 7
Training loss: 1.7548974752426147
Validation loss: 2.021950262849049

Epoch: 5| Step: 8
Training loss: 2.0548319816589355
Validation loss: 2.0316918191089424

Epoch: 5| Step: 9
Training loss: 2.0921568870544434
Validation loss: 1.990785926900884

Epoch: 5| Step: 10
Training loss: 2.4108667373657227
Validation loss: 1.9995237858064714

Epoch: 147| Step: 0
Training loss: 1.7609198093414307
Validation loss: 1.9898412804449759

Epoch: 5| Step: 1
Training loss: 2.465953826904297
Validation loss: 1.9937613343679776

Epoch: 5| Step: 2
Training loss: 2.0723843574523926
Validation loss: 1.9978969391956125

Epoch: 5| Step: 3
Training loss: 2.5625436305999756
Validation loss: 2.018415582436387

Epoch: 5| Step: 4
Training loss: 2.4380390644073486
Validation loss: 1.9901297656438683

Epoch: 5| Step: 5
Training loss: 1.7957639694213867
Validation loss: 2.0071104726483746

Epoch: 5| Step: 6
Training loss: 1.5973790884017944
Validation loss: 2.003502857300543

Epoch: 5| Step: 7
Training loss: 2.40436053276062
Validation loss: 2.0042384234807824

Epoch: 5| Step: 8
Training loss: 1.8720918893814087
Validation loss: 1.9829164833150885

Epoch: 5| Step: 9
Training loss: 1.9120652675628662
Validation loss: 1.9830610200922976

Epoch: 5| Step: 10
Training loss: 2.3514461517333984
Validation loss: 1.9947540426767

Epoch: 148| Step: 0
Training loss: 2.1255030632019043
Validation loss: 2.015890113769039

Epoch: 5| Step: 1
Training loss: 2.2261621952056885
Validation loss: 1.9989053357032038

Epoch: 5| Step: 2
Training loss: 2.0876998901367188
Validation loss: 2.0027108384716894

Epoch: 5| Step: 3
Training loss: 1.5853016376495361
Validation loss: 2.0022035888446275

Epoch: 5| Step: 4
Training loss: 1.813327431678772
Validation loss: 1.9916434300843107

Epoch: 5| Step: 5
Training loss: 2.041172742843628
Validation loss: 1.9812886561116865

Epoch: 5| Step: 6
Training loss: 2.7628707885742188
Validation loss: 1.9932830641346593

Epoch: 5| Step: 7
Training loss: 2.070641040802002
Validation loss: 1.9835831824169363

Epoch: 5| Step: 8
Training loss: 1.8097317218780518
Validation loss: 2.006204758920977

Epoch: 5| Step: 9
Training loss: 2.7074124813079834
Validation loss: 1.9902273608792214

Epoch: 5| Step: 10
Training loss: 1.7076009511947632
Validation loss: 2.0151532209047707

Epoch: 149| Step: 0
Training loss: 2.5724594593048096
Validation loss: 1.9967929624742078

Epoch: 5| Step: 1
Training loss: 1.9597270488739014
Validation loss: 1.9917770867706628

Epoch: 5| Step: 2
Training loss: 1.6954286098480225
Validation loss: 1.9886694339013868

Epoch: 5| Step: 3
Training loss: 2.328052282333374
Validation loss: 1.9983578138453986

Epoch: 5| Step: 4
Training loss: 2.9216349124908447
Validation loss: 2.00380418890266

Epoch: 5| Step: 5
Training loss: 1.4595245122909546
Validation loss: 2.016215673056982

Epoch: 5| Step: 6
Training loss: 2.0774083137512207
Validation loss: 2.000564812332071

Epoch: 5| Step: 7
Training loss: 1.7391828298568726
Validation loss: 2.0020987064607683

Epoch: 5| Step: 8
Training loss: 1.9529098272323608
Validation loss: 2.0003323067900953

Epoch: 5| Step: 9
Training loss: 2.394125461578369
Validation loss: 1.99128262201945

Epoch: 5| Step: 10
Training loss: 2.1404387950897217
Validation loss: 1.9970005635292298

Epoch: 150| Step: 0
Training loss: 2.2484242916107178
Validation loss: 1.995458036340693

Epoch: 5| Step: 1
Training loss: 2.8599610328674316
Validation loss: 1.9919888319507721

Epoch: 5| Step: 2
Training loss: 2.294513702392578
Validation loss: 1.9761369702636555

Epoch: 5| Step: 3
Training loss: 1.3881062269210815
Validation loss: 1.9989792095717562

Epoch: 5| Step: 4
Training loss: 2.2206668853759766
Validation loss: 1.987691266562349

Epoch: 5| Step: 5
Training loss: 1.8731367588043213
Validation loss: 1.9982542222545994

Epoch: 5| Step: 6
Training loss: 1.6850725412368774
Validation loss: 1.9904203132916523

Epoch: 5| Step: 7
Training loss: 1.813881516456604
Validation loss: 1.980285152312248

Epoch: 5| Step: 8
Training loss: 2.314706325531006
Validation loss: 2.0107787578336653

Epoch: 5| Step: 9
Training loss: 2.3419110774993896
Validation loss: 2.0173106936998266

Epoch: 5| Step: 10
Training loss: 2.0556271076202393
Validation loss: 2.0099325141599103

Epoch: 151| Step: 0
Training loss: 2.156378746032715
Validation loss: 1.9806537294900546

Epoch: 5| Step: 1
Training loss: 1.6740316152572632
Validation loss: 1.9765997202165666

Epoch: 5| Step: 2
Training loss: 1.9221327304840088
Validation loss: 1.9961448279760217

Epoch: 5| Step: 3
Training loss: 1.8439810276031494
Validation loss: 1.9888347066858763

Epoch: 5| Step: 4
Training loss: 2.3955020904541016
Validation loss: 2.0003804622157926

Epoch: 5| Step: 5
Training loss: 2.2767534255981445
Validation loss: 1.9843345816417406

Epoch: 5| Step: 6
Training loss: 2.266857862472534
Validation loss: 2.0158135378232567

Epoch: 5| Step: 7
Training loss: 2.0178768634796143
Validation loss: 2.01031074472653

Epoch: 5| Step: 8
Training loss: 1.8683922290802002
Validation loss: 1.9922397726325578

Epoch: 5| Step: 9
Training loss: 2.3443093299865723
Validation loss: 1.997764669438844

Epoch: 5| Step: 10
Training loss: 2.3313040733337402
Validation loss: 1.9735000056605185

Epoch: 152| Step: 0
Training loss: 2.0965895652770996
Validation loss: 1.997261897210152

Epoch: 5| Step: 1
Training loss: 2.104090452194214
Validation loss: 1.9876190552147486

Epoch: 5| Step: 2
Training loss: 2.4611124992370605
Validation loss: 1.9974302886634745

Epoch: 5| Step: 3
Training loss: 2.4495716094970703
Validation loss: 2.0040145471531856

Epoch: 5| Step: 4
Training loss: 1.5464402437210083
Validation loss: 2.011621549565305

Epoch: 5| Step: 5
Training loss: 1.8455898761749268
Validation loss: 1.997266871954805

Epoch: 5| Step: 6
Training loss: 2.0529088973999023
Validation loss: 1.9867848016882454

Epoch: 5| Step: 7
Training loss: 1.993688941001892
Validation loss: 2.005218477659328

Epoch: 5| Step: 8
Training loss: 2.217630386352539
Validation loss: 2.0092495628582534

Epoch: 5| Step: 9
Training loss: 1.8737316131591797
Validation loss: 2.004885406904323

Epoch: 5| Step: 10
Training loss: 2.345726490020752
Validation loss: 1.9939934707457019

Epoch: 153| Step: 0
Training loss: 2.013568162918091
Validation loss: 2.0137330691019693

Epoch: 5| Step: 1
Training loss: 2.3328728675842285
Validation loss: 1.9985559217391475

Epoch: 5| Step: 2
Training loss: 1.9205642938613892
Validation loss: 1.9808571877018097

Epoch: 5| Step: 3
Training loss: 2.52302622795105
Validation loss: 1.9857426586971487

Epoch: 5| Step: 4
Training loss: 1.6299692392349243
Validation loss: 2.015410513006231

Epoch: 5| Step: 5
Training loss: 2.182145357131958
Validation loss: 1.988662128807396

Epoch: 5| Step: 6
Training loss: 2.1556591987609863
Validation loss: 1.979508287163191

Epoch: 5| Step: 7
Training loss: 2.2541089057922363
Validation loss: 1.9899155888506161

Epoch: 5| Step: 8
Training loss: 2.4260120391845703
Validation loss: 2.0098829397591214

Epoch: 5| Step: 9
Training loss: 1.9547268152236938
Validation loss: 1.9855663302124187

Epoch: 5| Step: 10
Training loss: 1.5710443258285522
Validation loss: 2.0078431201237503

Epoch: 154| Step: 0
Training loss: 2.1737098693847656
Validation loss: 1.9799113119802167

Epoch: 5| Step: 1
Training loss: 1.8480510711669922
Validation loss: 1.984933732658304

Epoch: 5| Step: 2
Training loss: 1.8329296112060547
Validation loss: 2.00419416094339

Epoch: 5| Step: 3
Training loss: 2.661357879638672
Validation loss: 1.9964591482634186

Epoch: 5| Step: 4
Training loss: 2.476073741912842
Validation loss: 1.9936840059936687

Epoch: 5| Step: 5
Training loss: 2.1443562507629395
Validation loss: 1.9872740801944528

Epoch: 5| Step: 6
Training loss: 1.8905551433563232
Validation loss: 1.987899257290748

Epoch: 5| Step: 7
Training loss: 2.2675414085388184
Validation loss: 1.9863580067952473

Epoch: 5| Step: 8
Training loss: 1.692854881286621
Validation loss: 2.0059225225961335

Epoch: 5| Step: 9
Training loss: 2.103773355484009
Validation loss: 2.00355472231424

Epoch: 5| Step: 10
Training loss: 1.7634114027023315
Validation loss: 1.9906744059695993

Epoch: 155| Step: 0
Training loss: 1.485899567604065
Validation loss: 2.005675608111966

Epoch: 5| Step: 1
Training loss: 1.3627856969833374
Validation loss: 1.9868621595444218

Epoch: 5| Step: 2
Training loss: 2.2938151359558105
Validation loss: 1.9817094751583633

Epoch: 5| Step: 3
Training loss: 1.6864789724349976
Validation loss: 1.9887807574323428

Epoch: 5| Step: 4
Training loss: 2.22322940826416
Validation loss: 1.995039434843166

Epoch: 5| Step: 5
Training loss: 1.7145839929580688
Validation loss: 1.9866528023955643

Epoch: 5| Step: 6
Training loss: 1.8339989185333252
Validation loss: 1.980456054851573

Epoch: 5| Step: 7
Training loss: 3.0609853267669678
Validation loss: 1.986464331226964

Epoch: 5| Step: 8
Training loss: 3.2860264778137207
Validation loss: 1.9911697910678001

Epoch: 5| Step: 9
Training loss: 2.2383811473846436
Validation loss: 2.000149557667394

Epoch: 5| Step: 10
Training loss: 1.7634477615356445
Validation loss: 1.9896307478668869

Epoch: 156| Step: 0
Training loss: 2.201749324798584
Validation loss: 1.9784620808016868

Epoch: 5| Step: 1
Training loss: 2.3461241722106934
Validation loss: 2.0004463016345935

Epoch: 5| Step: 2
Training loss: 1.460270643234253
Validation loss: 1.9786880477782218

Epoch: 5| Step: 3
Training loss: 2.038904905319214
Validation loss: 1.9888788910322293

Epoch: 5| Step: 4
Training loss: 2.347259759902954
Validation loss: 1.9802664595265542

Epoch: 5| Step: 5
Training loss: 2.828016996383667
Validation loss: 1.9998683903806953

Epoch: 5| Step: 6
Training loss: 2.1522037982940674
Validation loss: 2.000181741611932

Epoch: 5| Step: 7
Training loss: 1.7580831050872803
Validation loss: 2.0116249079345376

Epoch: 5| Step: 8
Training loss: 2.433565855026245
Validation loss: 2.012571284847875

Epoch: 5| Step: 9
Training loss: 1.630923867225647
Validation loss: 2.0223501061880462

Epoch: 5| Step: 10
Training loss: 1.7148689031600952
Validation loss: 1.992620886013072

Epoch: 157| Step: 0
Training loss: 1.285634994506836
Validation loss: 1.9913258424369238

Epoch: 5| Step: 1
Training loss: 2.455777645111084
Validation loss: 1.9850986080784951

Epoch: 5| Step: 2
Training loss: 2.7207248210906982
Validation loss: 1.9939920620251728

Epoch: 5| Step: 3
Training loss: 1.853131651878357
Validation loss: 2.0060052410248788

Epoch: 5| Step: 4
Training loss: 2.374616861343384
Validation loss: 2.010268315192192

Epoch: 5| Step: 5
Training loss: 2.2631747722625732
Validation loss: 1.994600087083796

Epoch: 5| Step: 6
Training loss: 2.20115065574646
Validation loss: 2.011032847947972

Epoch: 5| Step: 7
Training loss: 1.60984206199646
Validation loss: 2.0000126643847396

Epoch: 5| Step: 8
Training loss: 2.0704357624053955
Validation loss: 1.9853960826832762

Epoch: 5| Step: 9
Training loss: 2.2621009349823
Validation loss: 1.998702214610192

Epoch: 5| Step: 10
Training loss: 1.7345646619796753
Validation loss: 2.012917096896838

Epoch: 158| Step: 0
Training loss: 2.318305253982544
Validation loss: 2.0102853544296755

Epoch: 5| Step: 1
Training loss: 1.8590234518051147
Validation loss: 2.00205240198361

Epoch: 5| Step: 2
Training loss: 2.047367811203003
Validation loss: 1.9879487535004974

Epoch: 5| Step: 3
Training loss: 2.3834645748138428
Validation loss: 1.9978848888028053

Epoch: 5| Step: 4
Training loss: 2.155837059020996
Validation loss: 1.9748798929234987

Epoch: 5| Step: 5
Training loss: 2.2070960998535156
Validation loss: 1.9856168095783522

Epoch: 5| Step: 6
Training loss: 2.4544613361358643
Validation loss: 1.9758034931716097

Epoch: 5| Step: 7
Training loss: 1.6027549505233765
Validation loss: 1.9967823105473672

Epoch: 5| Step: 8
Training loss: 2.209653377532959
Validation loss: 1.9966894785563152

Epoch: 5| Step: 9
Training loss: 2.1442832946777344
Validation loss: 1.9983016624245593

Epoch: 5| Step: 10
Training loss: 1.6007689237594604
Validation loss: 1.9873197514523742

Epoch: 159| Step: 0
Training loss: 2.098109006881714
Validation loss: 1.9767644238728348

Epoch: 5| Step: 1
Training loss: 2.5505714416503906
Validation loss: 1.9879296902687318

Epoch: 5| Step: 2
Training loss: 2.8278307914733887
Validation loss: 1.991462073018474

Epoch: 5| Step: 3
Training loss: 1.9007142782211304
Validation loss: 1.9740561669872654

Epoch: 5| Step: 4
Training loss: 1.676500678062439
Validation loss: 1.9755740345165294

Epoch: 5| Step: 5
Training loss: 2.0147311687469482
Validation loss: 1.9904722603418494

Epoch: 5| Step: 6
Training loss: 1.8622642755508423
Validation loss: 1.995592822310745

Epoch: 5| Step: 7
Training loss: 1.4922627210617065
Validation loss: 2.0014903263379167

Epoch: 5| Step: 8
Training loss: 1.5440597534179688
Validation loss: 2.000672872348498

Epoch: 5| Step: 9
Training loss: 2.489941120147705
Validation loss: 2.0086598652665333

Epoch: 5| Step: 10
Training loss: 2.386445999145508
Validation loss: 2.004293364863242

Epoch: 160| Step: 0
Training loss: 1.8169876337051392
Validation loss: 1.999340582919377

Epoch: 5| Step: 1
Training loss: 1.5763952732086182
Validation loss: 2.019876782612134

Epoch: 5| Step: 2
Training loss: 2.311149835586548
Validation loss: 1.9838977372774513

Epoch: 5| Step: 3
Training loss: 2.3020291328430176
Validation loss: 1.9963619811560518

Epoch: 5| Step: 4
Training loss: 2.9731831550598145
Validation loss: 1.9917206341220486

Epoch: 5| Step: 5
Training loss: 1.7330585718154907
Validation loss: 2.0074258517193537

Epoch: 5| Step: 6
Training loss: 1.8159927129745483
Validation loss: 1.9821701895806096

Epoch: 5| Step: 7
Training loss: 1.5172381401062012
Validation loss: 1.9912072291938208

Epoch: 5| Step: 8
Training loss: 2.080186367034912
Validation loss: 2.007593867599323

Epoch: 5| Step: 9
Training loss: 2.40608549118042
Validation loss: 2.0105049148682625

Epoch: 5| Step: 10
Training loss: 2.283653497695923
Validation loss: 2.0003620270759828

Epoch: 161| Step: 0
Training loss: 1.9602867364883423
Validation loss: 2.0037712563750563

Epoch: 5| Step: 1
Training loss: 1.7678935527801514
Validation loss: 1.9806037884886547

Epoch: 5| Step: 2
Training loss: 2.0412189960479736
Validation loss: 1.9905518447199175

Epoch: 5| Step: 3
Training loss: 1.8796545267105103
Validation loss: 2.001837821416957

Epoch: 5| Step: 4
Training loss: 1.5519078969955444
Validation loss: 2.0048611753730365

Epoch: 5| Step: 5
Training loss: 2.0635714530944824
Validation loss: 2.008502342367685

Epoch: 5| Step: 6
Training loss: 1.9097439050674438
Validation loss: 1.9956484686943792

Epoch: 5| Step: 7
Training loss: 2.146233558654785
Validation loss: 2.0100982548088155

Epoch: 5| Step: 8
Training loss: 2.187188148498535
Validation loss: 2.0164924154999437

Epoch: 5| Step: 9
Training loss: 2.2867114543914795
Validation loss: 2.0072112467981156

Epoch: 5| Step: 10
Training loss: 3.0775585174560547
Validation loss: 2.0001150279916744

Epoch: 162| Step: 0
Training loss: 2.237407684326172
Validation loss: 1.9868283310244161

Epoch: 5| Step: 1
Training loss: 2.367556095123291
Validation loss: 2.015087030267203

Epoch: 5| Step: 2
Training loss: 1.678910493850708
Validation loss: 1.9940655859567786

Epoch: 5| Step: 3
Training loss: 1.9885284900665283
Validation loss: 1.9962384367501864

Epoch: 5| Step: 4
Training loss: 2.0715537071228027
Validation loss: 1.9970601476648802

Epoch: 5| Step: 5
Training loss: 3.142615795135498
Validation loss: 2.012799903910647

Epoch: 5| Step: 6
Training loss: 1.7549149990081787
Validation loss: 1.9914344767088532

Epoch: 5| Step: 7
Training loss: 1.7019569873809814
Validation loss: 1.9989298094985306

Epoch: 5| Step: 8
Training loss: 1.5216095447540283
Validation loss: 1.9869281220179733

Epoch: 5| Step: 9
Training loss: 2.244680881500244
Validation loss: 2.0038129719354774

Epoch: 5| Step: 10
Training loss: 2.111712694168091
Validation loss: 2.0041054564137615

Epoch: 163| Step: 0
Training loss: 1.9656105041503906
Validation loss: 2.007296387867261

Epoch: 5| Step: 1
Training loss: 2.1797101497650146
Validation loss: 1.987577728045884

Epoch: 5| Step: 2
Training loss: 2.2116432189941406
Validation loss: 2.000089268530569

Epoch: 5| Step: 3
Training loss: 2.0233473777770996
Validation loss: 1.9915580493147655

Epoch: 5| Step: 4
Training loss: 1.9475867748260498
Validation loss: 1.9851331069905271

Epoch: 5| Step: 5
Training loss: 2.2885916233062744
Validation loss: 1.9695194126457296

Epoch: 5| Step: 6
Training loss: 1.7588552236557007
Validation loss: 1.98703109833502

Epoch: 5| Step: 7
Training loss: 1.8280999660491943
Validation loss: 2.0018859319789435

Epoch: 5| Step: 8
Training loss: 1.7520256042480469
Validation loss: 1.9870587830902429

Epoch: 5| Step: 9
Training loss: 1.9191036224365234
Validation loss: 1.993168710380472

Epoch: 5| Step: 10
Training loss: 2.896212339401245
Validation loss: 1.990538227942682

Epoch: 164| Step: 0
Training loss: 2.1229100227355957
Validation loss: 1.965080927777034

Epoch: 5| Step: 1
Training loss: 2.08764386177063
Validation loss: 1.9857509149018155

Epoch: 5| Step: 2
Training loss: 2.204819917678833
Validation loss: 1.9745396798656834

Epoch: 5| Step: 3
Training loss: 1.8223717212677002
Validation loss: 1.9696436364163634

Epoch: 5| Step: 4
Training loss: 2.0180752277374268
Validation loss: 1.9793350529927078

Epoch: 5| Step: 5
Training loss: 2.119947671890259
Validation loss: 1.9959384984867548

Epoch: 5| Step: 6
Training loss: 2.737969160079956
Validation loss: 1.9699338815545524

Epoch: 5| Step: 7
Training loss: 2.1857051849365234
Validation loss: 1.9743092111361924

Epoch: 5| Step: 8
Training loss: 1.7153332233428955
Validation loss: 1.9976322445818173

Epoch: 5| Step: 9
Training loss: 1.5389152765274048
Validation loss: 1.9917078633462229

Epoch: 5| Step: 10
Training loss: 2.194815158843994
Validation loss: 1.9916159978476904

Epoch: 165| Step: 0
Training loss: 1.9357963800430298
Validation loss: 1.9896155429142777

Epoch: 5| Step: 1
Training loss: 2.3530468940734863
Validation loss: 1.9840854060265325

Epoch: 5| Step: 2
Training loss: 2.2221219539642334
Validation loss: 1.9855927087927376

Epoch: 5| Step: 3
Training loss: 1.7230373620986938
Validation loss: 1.9926206604126961

Epoch: 5| Step: 4
Training loss: 1.8315801620483398
Validation loss: 1.9910743903088313

Epoch: 5| Step: 5
Training loss: 1.34088933467865
Validation loss: 1.9721278913559452

Epoch: 5| Step: 6
Training loss: 2.231794834136963
Validation loss: 1.9899817128335275

Epoch: 5| Step: 7
Training loss: 2.1467063426971436
Validation loss: 1.9926614376806444

Epoch: 5| Step: 8
Training loss: 2.2000956535339355
Validation loss: 2.0070907864519345

Epoch: 5| Step: 9
Training loss: 2.2082438468933105
Validation loss: 1.9906364974155222

Epoch: 5| Step: 10
Training loss: 2.446272373199463
Validation loss: 1.9781185145019202

Epoch: 166| Step: 0
Training loss: 1.7737737894058228
Validation loss: 1.9834133348157328

Epoch: 5| Step: 1
Training loss: 1.7791974544525146
Validation loss: 1.9900370105620353

Epoch: 5| Step: 2
Training loss: 1.776545763015747
Validation loss: 1.9985115553743096

Epoch: 5| Step: 3
Training loss: 1.6287105083465576
Validation loss: 1.9703613071031467

Epoch: 5| Step: 4
Training loss: 2.2103466987609863
Validation loss: 1.9716344469337053

Epoch: 5| Step: 5
Training loss: 2.4627938270568848
Validation loss: 1.9693096222416047

Epoch: 5| Step: 6
Training loss: 1.9083448648452759
Validation loss: 2.0008401409272225

Epoch: 5| Step: 7
Training loss: 2.1110219955444336
Validation loss: 2.018987750494352

Epoch: 5| Step: 8
Training loss: 2.534665584564209
Validation loss: 1.9958768685658772

Epoch: 5| Step: 9
Training loss: 2.0987563133239746
Validation loss: 2.0049715875297465

Epoch: 5| Step: 10
Training loss: 2.35176157951355
Validation loss: 2.002447529505658

Epoch: 167| Step: 0
Training loss: 2.200361728668213
Validation loss: 2.0143212785003004

Epoch: 5| Step: 1
Training loss: 3.187711715698242
Validation loss: 1.9993984314703173

Epoch: 5| Step: 2
Training loss: 1.068287968635559
Validation loss: 1.9924739535136888

Epoch: 5| Step: 3
Training loss: 1.7309761047363281
Validation loss: 2.001888628928892

Epoch: 5| Step: 4
Training loss: 2.651886463165283
Validation loss: 2.0160766980981313

Epoch: 5| Step: 5
Training loss: 1.9791138172149658
Validation loss: 2.009337394468246

Epoch: 5| Step: 6
Training loss: 2.697587728500366
Validation loss: 1.9962824134416477

Epoch: 5| Step: 7
Training loss: 1.1749845743179321
Validation loss: 1.992741968042107

Epoch: 5| Step: 8
Training loss: 2.141136407852173
Validation loss: 2.0107078988065004

Epoch: 5| Step: 9
Training loss: 1.5156264305114746
Validation loss: 2.0049141671067927

Epoch: 5| Step: 10
Training loss: 2.246206283569336
Validation loss: 1.997352989771033

Epoch: 168| Step: 0
Training loss: 2.099377155303955
Validation loss: 2.0003835026935866

Epoch: 5| Step: 1
Training loss: 1.8646491765975952
Validation loss: 1.9964293190228042

Epoch: 5| Step: 2
Training loss: 1.1824767589569092
Validation loss: 1.9780258517111502

Epoch: 5| Step: 3
Training loss: 2.5560431480407715
Validation loss: 2.0000537518532044

Epoch: 5| Step: 4
Training loss: 2.2669436931610107
Validation loss: 1.9944077409723753

Epoch: 5| Step: 5
Training loss: 2.582277536392212
Validation loss: 1.984287526017876

Epoch: 5| Step: 6
Training loss: 1.7586721181869507
Validation loss: 2.0052533380446897

Epoch: 5| Step: 7
Training loss: 2.4585986137390137
Validation loss: 2.01033414307461

Epoch: 5| Step: 8
Training loss: 2.1495957374572754
Validation loss: 1.975255089421426

Epoch: 5| Step: 9
Training loss: 2.331024408340454
Validation loss: 1.9931823438213718

Epoch: 5| Step: 10
Training loss: 1.2351577281951904
Validation loss: 1.9823851905843264

Epoch: 169| Step: 0
Training loss: 1.3967101573944092
Validation loss: 1.9891175659753944

Epoch: 5| Step: 1
Training loss: 2.3322560787200928
Validation loss: 1.9699381346343665

Epoch: 5| Step: 2
Training loss: 2.132678747177124
Validation loss: 1.9821581353423416

Epoch: 5| Step: 3
Training loss: 2.36004638671875
Validation loss: 1.9736395830749183

Epoch: 5| Step: 4
Training loss: 1.7097463607788086
Validation loss: 1.977872056345786

Epoch: 5| Step: 5
Training loss: 2.344130039215088
Validation loss: 1.9979177995394635

Epoch: 5| Step: 6
Training loss: 2.361720561981201
Validation loss: 1.9864545406833771

Epoch: 5| Step: 7
Training loss: 2.397228956222534
Validation loss: 1.9961693594532628

Epoch: 5| Step: 8
Training loss: 1.523468255996704
Validation loss: 1.997306772457656

Epoch: 5| Step: 9
Training loss: 2.166762113571167
Validation loss: 1.9815124439936813

Epoch: 5| Step: 10
Training loss: 1.5882673263549805
Validation loss: 1.9921615841568157

Epoch: 170| Step: 0
Training loss: 2.282437801361084
Validation loss: 1.990238647307119

Epoch: 5| Step: 1
Training loss: 1.9202524423599243
Validation loss: 1.9909741481145222

Epoch: 5| Step: 2
Training loss: 2.023454189300537
Validation loss: 1.9798487463305074

Epoch: 5| Step: 3
Training loss: 2.4287190437316895
Validation loss: 1.9660686036591888

Epoch: 5| Step: 4
Training loss: 2.1175546646118164
Validation loss: 1.9844710570509716

Epoch: 5| Step: 5
Training loss: 2.169525623321533
Validation loss: 1.9646734332525602

Epoch: 5| Step: 6
Training loss: 2.0398592948913574
Validation loss: 1.9902261867318103

Epoch: 5| Step: 7
Training loss: 1.3719556331634521
Validation loss: 1.989116326455147

Epoch: 5| Step: 8
Training loss: 1.994307279586792
Validation loss: 1.9919641581914758

Epoch: 5| Step: 9
Training loss: 1.9143381118774414
Validation loss: 1.9777520138730285

Epoch: 5| Step: 10
Training loss: 2.2969956398010254
Validation loss: 1.991639494895935

Epoch: 171| Step: 0
Training loss: 1.693143606185913
Validation loss: 1.9848833391743321

Epoch: 5| Step: 1
Training loss: 2.147383213043213
Validation loss: 2.006916712689143

Epoch: 5| Step: 2
Training loss: 1.165548324584961
Validation loss: 1.997873847202588

Epoch: 5| Step: 3
Training loss: 2.255087375640869
Validation loss: 1.9667349105240197

Epoch: 5| Step: 4
Training loss: 2.0000455379486084
Validation loss: 1.9798750518470682

Epoch: 5| Step: 5
Training loss: 2.2967846393585205
Validation loss: 1.9862604859054729

Epoch: 5| Step: 6
Training loss: 2.0474112033843994
Validation loss: 1.9705857640953475

Epoch: 5| Step: 7
Training loss: 1.9747234582901
Validation loss: 1.980149822850381

Epoch: 5| Step: 8
Training loss: 2.7009036540985107
Validation loss: 1.986008688967715

Epoch: 5| Step: 9
Training loss: 2.355802297592163
Validation loss: 1.9825984585669734

Epoch: 5| Step: 10
Training loss: 1.8478657007217407
Validation loss: 1.9911419653123426

Epoch: 172| Step: 0
Training loss: 1.674411416053772
Validation loss: 1.9791553815205891

Epoch: 5| Step: 1
Training loss: 2.146674871444702
Validation loss: 2.0085978713086856

Epoch: 5| Step: 2
Training loss: 2.1815054416656494
Validation loss: 2.0111861049488025

Epoch: 5| Step: 3
Training loss: 1.9032224416732788
Validation loss: 1.9953530834567161

Epoch: 5| Step: 4
Training loss: 2.3302063941955566
Validation loss: 1.9741786936277985

Epoch: 5| Step: 5
Training loss: 1.771108865737915
Validation loss: 2.011779590319562

Epoch: 5| Step: 6
Training loss: 1.7321865558624268
Validation loss: 1.9952247424792218

Epoch: 5| Step: 7
Training loss: 1.957516074180603
Validation loss: 1.9992333676225396

Epoch: 5| Step: 8
Training loss: 2.2441954612731934
Validation loss: 1.9998676174430436

Epoch: 5| Step: 9
Training loss: 1.9100029468536377
Validation loss: 1.9940238204053653

Epoch: 5| Step: 10
Training loss: 2.5139987468719482
Validation loss: 1.9889192260721678

Epoch: 173| Step: 0
Training loss: 2.4103238582611084
Validation loss: 2.015198834480778

Epoch: 5| Step: 1
Training loss: 2.1046624183654785
Validation loss: 2.001113148145778

Epoch: 5| Step: 2
Training loss: 2.166252851486206
Validation loss: 2.0035551914604763

Epoch: 5| Step: 3
Training loss: 1.6895965337753296
Validation loss: 1.9838519686011857

Epoch: 5| Step: 4
Training loss: 2.2864632606506348
Validation loss: 1.996670284578877

Epoch: 5| Step: 5
Training loss: 1.737140417098999
Validation loss: 1.962029057164346

Epoch: 5| Step: 6
Training loss: 2.351285219192505
Validation loss: 1.9656029234650314

Epoch: 5| Step: 7
Training loss: 1.7872097492218018
Validation loss: 1.9722163702851983

Epoch: 5| Step: 8
Training loss: 2.1151208877563477
Validation loss: 1.9721464405777633

Epoch: 5| Step: 9
Training loss: 1.8636837005615234
Validation loss: 1.983450835750949

Epoch: 5| Step: 10
Training loss: 1.9153552055358887
Validation loss: 1.9758253443625666

Epoch: 174| Step: 0
Training loss: 1.8975982666015625
Validation loss: 1.9846238474692068

Epoch: 5| Step: 1
Training loss: 2.8069026470184326
Validation loss: 1.9830933796462191

Epoch: 5| Step: 2
Training loss: 1.6321017742156982
Validation loss: 1.9799867445422756

Epoch: 5| Step: 3
Training loss: 1.7143337726593018
Validation loss: 1.973470680175289

Epoch: 5| Step: 4
Training loss: 1.9041798114776611
Validation loss: 1.9877530067197737

Epoch: 5| Step: 5
Training loss: 1.666365385055542
Validation loss: 1.9872457288926648

Epoch: 5| Step: 6
Training loss: 2.42580509185791
Validation loss: 1.997044510738824

Epoch: 5| Step: 7
Training loss: 1.9406254291534424
Validation loss: 1.987838900217446

Epoch: 5| Step: 8
Training loss: 1.7846473455429077
Validation loss: 1.9873971772450272

Epoch: 5| Step: 9
Training loss: 2.7200927734375
Validation loss: 1.993495254106419

Epoch: 5| Step: 10
Training loss: 1.9511317014694214
Validation loss: 1.9803168696741904

Epoch: 175| Step: 0
Training loss: 2.5222408771514893
Validation loss: 1.9776284720308037

Epoch: 5| Step: 1
Training loss: 2.1492834091186523
Validation loss: 1.9672815966349777

Epoch: 5| Step: 2
Training loss: 2.235750675201416
Validation loss: 1.9946804546540784

Epoch: 5| Step: 3
Training loss: 2.4022083282470703
Validation loss: 1.9896696998227028

Epoch: 5| Step: 4
Training loss: 1.6790002584457397
Validation loss: 1.991323027559506

Epoch: 5| Step: 5
Training loss: 1.6699552536010742
Validation loss: 1.9883213068849297

Epoch: 5| Step: 6
Training loss: 2.24902081489563
Validation loss: 1.9853276334783083

Epoch: 5| Step: 7
Training loss: 1.987226128578186
Validation loss: 2.012265246401551

Epoch: 5| Step: 8
Training loss: 1.5055454969406128
Validation loss: 1.9816350103706442

Epoch: 5| Step: 9
Training loss: 1.9654535055160522
Validation loss: 2.0044465936640257

Epoch: 5| Step: 10
Training loss: 2.016601324081421
Validation loss: 1.998397591293499

Epoch: 176| Step: 0
Training loss: 2.0710184574127197
Validation loss: 1.9935874580055155

Epoch: 5| Step: 1
Training loss: 2.199267864227295
Validation loss: 1.9798464851994668

Epoch: 5| Step: 2
Training loss: 1.9965356588363647
Validation loss: 2.0208523991287395

Epoch: 5| Step: 3
Training loss: 1.6476436853408813
Validation loss: 1.9912195795325822

Epoch: 5| Step: 4
Training loss: 2.0694594383239746
Validation loss: 2.007577419281006

Epoch: 5| Step: 5
Training loss: 1.6369508504867554
Validation loss: 2.0030714619544243

Epoch: 5| Step: 6
Training loss: 1.7828763723373413
Validation loss: 2.018900940495153

Epoch: 5| Step: 7
Training loss: 2.6701111793518066
Validation loss: 1.9807366863373788

Epoch: 5| Step: 8
Training loss: 2.371553897857666
Validation loss: 1.9862592143397177

Epoch: 5| Step: 9
Training loss: 1.799872636795044
Validation loss: 1.9837781806145944

Epoch: 5| Step: 10
Training loss: 1.9358881711959839
Validation loss: 1.9629260340044576

Epoch: 177| Step: 0
Training loss: 1.9511280059814453
Validation loss: 2.003357107921313

Epoch: 5| Step: 1
Training loss: 1.6393654346466064
Validation loss: 1.99159074342379

Epoch: 5| Step: 2
Training loss: 2.137011766433716
Validation loss: 1.9871958840277888

Epoch: 5| Step: 3
Training loss: 1.6129487752914429
Validation loss: 1.9815068744844007

Epoch: 5| Step: 4
Training loss: 2.529456377029419
Validation loss: 1.9810538779022873

Epoch: 5| Step: 5
Training loss: 2.3616127967834473
Validation loss: 1.9766730903297343

Epoch: 5| Step: 6
Training loss: 2.027496099472046
Validation loss: 1.9727533055889992

Epoch: 5| Step: 7
Training loss: 2.2014336585998535
Validation loss: 2.007844081488989

Epoch: 5| Step: 8
Training loss: 1.7465026378631592
Validation loss: 1.9867973314818514

Epoch: 5| Step: 9
Training loss: 2.216217517852783
Validation loss: 1.9799639281406198

Epoch: 5| Step: 10
Training loss: 1.7465592622756958
Validation loss: 1.95711092282367

Epoch: 178| Step: 0
Training loss: 1.7845414876937866
Validation loss: 1.9772534472967989

Epoch: 5| Step: 1
Training loss: 2.0890941619873047
Validation loss: 1.9665614507531608

Epoch: 5| Step: 2
Training loss: 1.9816694259643555
Validation loss: 1.983038374172744

Epoch: 5| Step: 3
Training loss: 2.5202548503875732
Validation loss: 2.0010059366944017

Epoch: 5| Step: 4
Training loss: 2.2063522338867188
Validation loss: 1.9654438213635517

Epoch: 5| Step: 5
Training loss: 1.8124539852142334
Validation loss: 1.9796341849911598

Epoch: 5| Step: 6
Training loss: 1.8787243366241455
Validation loss: 1.9822054434848089

Epoch: 5| Step: 7
Training loss: 2.085099220275879
Validation loss: 1.982676016387119

Epoch: 5| Step: 8
Training loss: 2.1658387184143066
Validation loss: 1.9870907260525612

Epoch: 5| Step: 9
Training loss: 2.391913890838623
Validation loss: 2.006205751049903

Epoch: 5| Step: 10
Training loss: 1.3544222116470337
Validation loss: 1.9810217042123117

Epoch: 179| Step: 0
Training loss: 2.3805694580078125
Validation loss: 1.9887335454263995

Epoch: 5| Step: 1
Training loss: 2.00039005279541
Validation loss: 1.9788884501303396

Epoch: 5| Step: 2
Training loss: 1.259603500366211
Validation loss: 1.9931760449563303

Epoch: 5| Step: 3
Training loss: 2.013256788253784
Validation loss: 1.9974547060587073

Epoch: 5| Step: 4
Training loss: 1.9263687133789062
Validation loss: 1.9913482230196717

Epoch: 5| Step: 5
Training loss: 1.5865137577056885
Validation loss: 1.9681025012846916

Epoch: 5| Step: 6
Training loss: 2.62378191947937
Validation loss: 1.9687176571097424

Epoch: 5| Step: 7
Training loss: 2.048020839691162
Validation loss: 1.9835525481931624

Epoch: 5| Step: 8
Training loss: 2.208420991897583
Validation loss: 1.9598141690736175

Epoch: 5| Step: 9
Training loss: 2.097668170928955
Validation loss: 1.974508629050306

Epoch: 5| Step: 10
Training loss: 2.174919843673706
Validation loss: 1.9704440857774468

Epoch: 180| Step: 0
Training loss: 2.6293511390686035
Validation loss: 1.994402697009425

Epoch: 5| Step: 1
Training loss: 2.1202049255371094
Validation loss: 1.9963368510687223

Epoch: 5| Step: 2
Training loss: 1.6541255712509155
Validation loss: 1.9756392381524528

Epoch: 5| Step: 3
Training loss: 1.4767740964889526
Validation loss: 1.9597291305500975

Epoch: 5| Step: 4
Training loss: 1.4024755954742432
Validation loss: 1.9793368834321217

Epoch: 5| Step: 5
Training loss: 2.2603180408477783
Validation loss: 1.9876425138083837

Epoch: 5| Step: 6
Training loss: 2.146444797515869
Validation loss: 1.9827086053868777

Epoch: 5| Step: 7
Training loss: 2.354665756225586
Validation loss: 1.9851020100296184

Epoch: 5| Step: 8
Training loss: 1.7721710205078125
Validation loss: 1.9879159722276913

Epoch: 5| Step: 9
Training loss: 1.8872950077056885
Validation loss: 1.9872285640367897

Epoch: 5| Step: 10
Training loss: 2.7683966159820557
Validation loss: 1.989379903321625

Epoch: 181| Step: 0
Training loss: 2.431694507598877
Validation loss: 2.007547709249681

Epoch: 5| Step: 1
Training loss: 1.8074194192886353
Validation loss: 1.992436408996582

Epoch: 5| Step: 2
Training loss: 1.7720181941986084
Validation loss: 1.9883638043557443

Epoch: 5| Step: 3
Training loss: 1.590285062789917
Validation loss: 1.9897099566716019

Epoch: 5| Step: 4
Training loss: 1.765366792678833
Validation loss: 1.992046074200702

Epoch: 5| Step: 5
Training loss: 2.0853488445281982
Validation loss: 1.9768217532865462

Epoch: 5| Step: 6
Training loss: 2.0724830627441406
Validation loss: 1.996772091875794

Epoch: 5| Step: 7
Training loss: 2.369971990585327
Validation loss: 1.9764497664666945

Epoch: 5| Step: 8
Training loss: 1.2200438976287842
Validation loss: 1.9813837876883886

Epoch: 5| Step: 9
Training loss: 2.6862733364105225
Validation loss: 1.9678301657399824

Epoch: 5| Step: 10
Training loss: 2.6470584869384766
Validation loss: 1.9804573033445625

Epoch: 182| Step: 0
Training loss: 1.788323998451233
Validation loss: 1.981920019272835

Epoch: 5| Step: 1
Training loss: 2.325742721557617
Validation loss: 1.9929643331035491

Epoch: 5| Step: 2
Training loss: 2.0454766750335693
Validation loss: 1.9548496943648144

Epoch: 5| Step: 3
Training loss: 2.028383255004883
Validation loss: 1.9522657061135897

Epoch: 5| Step: 4
Training loss: 1.9008195400238037
Validation loss: 1.9785578007339149

Epoch: 5| Step: 5
Training loss: 1.9831559658050537
Validation loss: 2.019794414120336

Epoch: 5| Step: 6
Training loss: 2.56290864944458
Validation loss: 1.981260036909452

Epoch: 5| Step: 7
Training loss: 2.1893396377563477
Validation loss: 1.991402336346206

Epoch: 5| Step: 8
Training loss: 1.7739999294281006
Validation loss: 1.9911044156679543

Epoch: 5| Step: 9
Training loss: 2.208850383758545
Validation loss: 2.004803372967628

Epoch: 5| Step: 10
Training loss: 1.2722229957580566
Validation loss: 2.0012324433172903

Epoch: 183| Step: 0
Training loss: 2.580204486846924
Validation loss: 2.0012489877721316

Epoch: 5| Step: 1
Training loss: 1.808005928993225
Validation loss: 2.00066469048941

Epoch: 5| Step: 2
Training loss: 2.3584420680999756
Validation loss: 1.984414639011506

Epoch: 5| Step: 3
Training loss: 1.7271499633789062
Validation loss: 2.001253627961682

Epoch: 5| Step: 4
Training loss: 1.4289087057113647
Validation loss: 1.9865661821057718

Epoch: 5| Step: 5
Training loss: 2.4765803813934326
Validation loss: 1.9955557661671792

Epoch: 5| Step: 6
Training loss: 1.5525777339935303
Validation loss: 2.0063850264395438

Epoch: 5| Step: 7
Training loss: 2.5013649463653564
Validation loss: 1.9802121590542536

Epoch: 5| Step: 8
Training loss: 2.2692339420318604
Validation loss: 1.970482514750573

Epoch: 5| Step: 9
Training loss: 1.5482968091964722
Validation loss: 1.9634742967544063

Epoch: 5| Step: 10
Training loss: 1.7194106578826904
Validation loss: 1.9843361326443252

Epoch: 184| Step: 0
Training loss: 1.7028300762176514
Validation loss: 1.965910493686635

Epoch: 5| Step: 1
Training loss: 2.4206390380859375
Validation loss: 1.9853949392995527

Epoch: 5| Step: 2
Training loss: 2.4348273277282715
Validation loss: 1.9945552746454875

Epoch: 5| Step: 3
Training loss: 1.3957240581512451
Validation loss: 1.9967482038723525

Epoch: 5| Step: 4
Training loss: 2.1207268238067627
Validation loss: 1.9877094684108612

Epoch: 5| Step: 5
Training loss: 1.8284406661987305
Validation loss: 1.9799548323436449

Epoch: 5| Step: 6
Training loss: 2.9923622608184814
Validation loss: 1.9797527777251376

Epoch: 5| Step: 7
Training loss: 2.0074386596679688
Validation loss: 1.9903854772608767

Epoch: 5| Step: 8
Training loss: 1.5601621866226196
Validation loss: 1.9693433264250397

Epoch: 5| Step: 9
Training loss: 1.739943265914917
Validation loss: 1.9935662874611475

Epoch: 5| Step: 10
Training loss: 1.7956290245056152
Validation loss: 1.9867279862844816

Epoch: 185| Step: 0
Training loss: 1.6564337015151978
Validation loss: 1.9830454793027652

Epoch: 5| Step: 1
Training loss: 1.7725646495819092
Validation loss: 1.9772968471691172

Epoch: 5| Step: 2
Training loss: 1.6770111322402954
Validation loss: 1.96339665561594

Epoch: 5| Step: 3
Training loss: 2.1232094764709473
Validation loss: 2.001089378069806

Epoch: 5| Step: 4
Training loss: 2.1192264556884766
Validation loss: 1.9786669464521511

Epoch: 5| Step: 5
Training loss: 2.205019950866699
Validation loss: 1.9759740701285742

Epoch: 5| Step: 6
Training loss: 2.3394384384155273
Validation loss: 1.9761467774709065

Epoch: 5| Step: 7
Training loss: 2.11309814453125
Validation loss: 1.9934316553095335

Epoch: 5| Step: 8
Training loss: 2.197897434234619
Validation loss: 1.9735571081920336

Epoch: 5| Step: 9
Training loss: 1.6771758794784546
Validation loss: 1.9691264014090262

Epoch: 5| Step: 10
Training loss: 2.3387088775634766
Validation loss: 1.9736809038346814

Epoch: 186| Step: 0
Training loss: 2.2840819358825684
Validation loss: 1.9661136673342796

Epoch: 5| Step: 1
Training loss: 1.637203574180603
Validation loss: 2.0001250902811685

Epoch: 5| Step: 2
Training loss: 2.0283496379852295
Validation loss: 1.9896577712028258

Epoch: 5| Step: 3
Training loss: 2.027653694152832
Validation loss: 1.9851343554835166

Epoch: 5| Step: 4
Training loss: 1.843343734741211
Validation loss: 1.9934517978340067

Epoch: 5| Step: 5
Training loss: 2.25555419921875
Validation loss: 1.9937606896123579

Epoch: 5| Step: 6
Training loss: 2.2883172035217285
Validation loss: 1.986261898471463

Epoch: 5| Step: 7
Training loss: 2.3149774074554443
Validation loss: 1.99009031890541

Epoch: 5| Step: 8
Training loss: 1.6223455667495728
Validation loss: 1.992901877690387

Epoch: 5| Step: 9
Training loss: 2.0529584884643555
Validation loss: 1.9947159546677784

Epoch: 5| Step: 10
Training loss: 1.7650959491729736
Validation loss: 2.0114202678844495

Epoch: 187| Step: 0
Training loss: 2.692298412322998
Validation loss: 2.0073289691760974

Epoch: 5| Step: 1
Training loss: 1.87040114402771
Validation loss: 2.0060165735983078

Epoch: 5| Step: 2
Training loss: 1.876125693321228
Validation loss: 2.001240295748557

Epoch: 5| Step: 3
Training loss: 1.5161222219467163
Validation loss: 2.0030034280592397

Epoch: 5| Step: 4
Training loss: 2.1979894638061523
Validation loss: 1.9847154066126833

Epoch: 5| Step: 5
Training loss: 1.874595046043396
Validation loss: 1.9688714704205912

Epoch: 5| Step: 6
Training loss: 1.9413366317749023
Validation loss: 1.973286203158799

Epoch: 5| Step: 7
Training loss: 1.7935959100723267
Validation loss: 1.9557239829853017

Epoch: 5| Step: 8
Training loss: 2.0840864181518555
Validation loss: 1.9644996158538326

Epoch: 5| Step: 9
Training loss: 2.477536678314209
Validation loss: 1.9677864274671

Epoch: 5| Step: 10
Training loss: 1.8959375619888306
Validation loss: 1.9884053045703518

Epoch: 188| Step: 0
Training loss: 1.6542150974273682
Validation loss: 1.959810318485383

Epoch: 5| Step: 1
Training loss: 1.3387775421142578
Validation loss: 1.9707575510906916

Epoch: 5| Step: 2
Training loss: 1.7634007930755615
Validation loss: 2.002439450192195

Epoch: 5| Step: 3
Training loss: 2.429170846939087
Validation loss: 1.9657364673511957

Epoch: 5| Step: 4
Training loss: 2.1044092178344727
Validation loss: 2.000135385861961

Epoch: 5| Step: 5
Training loss: 1.6103318929672241
Validation loss: 1.9739737023589432

Epoch: 5| Step: 6
Training loss: 2.000290632247925
Validation loss: 1.9758311958723171

Epoch: 5| Step: 7
Training loss: 2.469574451446533
Validation loss: 1.9764906539711902

Epoch: 5| Step: 8
Training loss: 2.4455654621124268
Validation loss: 1.9870780334677747

Epoch: 5| Step: 9
Training loss: 2.2446303367614746
Validation loss: 1.9792593897029918

Epoch: 5| Step: 10
Training loss: 1.9418721199035645
Validation loss: 1.9776117622211415

Epoch: 189| Step: 0
Training loss: 1.7206443548202515
Validation loss: 1.9836271244992492

Epoch: 5| Step: 1
Training loss: 2.1852245330810547
Validation loss: 1.9746856932998986

Epoch: 5| Step: 2
Training loss: 2.3822720050811768
Validation loss: 1.9759390930975638

Epoch: 5| Step: 3
Training loss: 2.539646625518799
Validation loss: 1.9833580011962562

Epoch: 5| Step: 4
Training loss: 1.8548780679702759
Validation loss: 1.992608570283459

Epoch: 5| Step: 5
Training loss: 1.555459976196289
Validation loss: 1.9729190718743108

Epoch: 5| Step: 6
Training loss: 1.9275782108306885
Validation loss: 1.992547276199505

Epoch: 5| Step: 7
Training loss: 1.840981125831604
Validation loss: 1.9995234345877042

Epoch: 5| Step: 8
Training loss: 2.023061513900757
Validation loss: 1.9996837262184388

Epoch: 5| Step: 9
Training loss: 2.082016706466675
Validation loss: 1.9935422764029553

Epoch: 5| Step: 10
Training loss: 1.789374589920044
Validation loss: 2.0140971957996325

Epoch: 190| Step: 0
Training loss: 2.53225040435791
Validation loss: 2.002168998923353

Epoch: 5| Step: 1
Training loss: 1.5056520700454712
Validation loss: 1.9914270831692604

Epoch: 5| Step: 2
Training loss: 1.313919186592102
Validation loss: 1.9867700415272866

Epoch: 5| Step: 3
Training loss: 2.0510447025299072
Validation loss: 1.9793909467676634

Epoch: 5| Step: 4
Training loss: 2.2401621341705322
Validation loss: 1.9817812288961103

Epoch: 5| Step: 5
Training loss: 1.9489152431488037
Validation loss: 2.003887636687166

Epoch: 5| Step: 6
Training loss: 1.914385437965393
Validation loss: 1.9926687671292214

Epoch: 5| Step: 7
Training loss: 1.9671443700790405
Validation loss: 1.9796778899367138

Epoch: 5| Step: 8
Training loss: 2.0594725608825684
Validation loss: 1.9742122568109983

Epoch: 5| Step: 9
Training loss: 2.2824549674987793
Validation loss: 1.964216927046417

Epoch: 5| Step: 10
Training loss: 2.2627620697021484
Validation loss: 1.994892107543125

Epoch: 191| Step: 0
Training loss: 1.4760761260986328
Validation loss: 1.9780491090589953

Epoch: 5| Step: 1
Training loss: 2.0535707473754883
Validation loss: 1.9881177358729865

Epoch: 5| Step: 2
Training loss: 1.4326701164245605
Validation loss: 1.9655764167026808

Epoch: 5| Step: 3
Training loss: 1.6996691226959229
Validation loss: 1.984736160565448

Epoch: 5| Step: 4
Training loss: 2.0013070106506348
Validation loss: 1.9619190116082468

Epoch: 5| Step: 5
Training loss: 2.363138198852539
Validation loss: 1.9843969242547148

Epoch: 5| Step: 6
Training loss: 2.378291368484497
Validation loss: 1.9631244213350358

Epoch: 5| Step: 7
Training loss: 1.8068917989730835
Validation loss: 1.9755402457329534

Epoch: 5| Step: 8
Training loss: 2.700490951538086
Validation loss: 1.980515560796184

Epoch: 5| Step: 9
Training loss: 1.5887629985809326
Validation loss: 1.9754368746152489

Epoch: 5| Step: 10
Training loss: 2.408902645111084
Validation loss: 1.9857314581512122

Epoch: 192| Step: 0
Training loss: 1.7308295965194702
Validation loss: 1.955783813230453

Epoch: 5| Step: 1
Training loss: 2.1415951251983643
Validation loss: 1.9768939120795137

Epoch: 5| Step: 2
Training loss: 1.9918171167373657
Validation loss: 1.972533941268921

Epoch: 5| Step: 3
Training loss: 2.0023961067199707
Validation loss: 1.9830125198569348

Epoch: 5| Step: 4
Training loss: 2.4043941497802734
Validation loss: 1.970725869619718

Epoch: 5| Step: 5
Training loss: 1.659315824508667
Validation loss: 1.991891271324568

Epoch: 5| Step: 6
Training loss: 1.9246282577514648
Validation loss: 1.9862452386527933

Epoch: 5| Step: 7
Training loss: 2.1527111530303955
Validation loss: 1.9837648227650633

Epoch: 5| Step: 8
Training loss: 1.528066873550415
Validation loss: 1.9996702030140867

Epoch: 5| Step: 9
Training loss: 2.5119354724884033
Validation loss: 1.9795728588616976

Epoch: 5| Step: 10
Training loss: 1.6754603385925293
Validation loss: 1.9852467249798518

Epoch: 193| Step: 0
Training loss: 2.435518264770508
Validation loss: 1.9792756060118317

Epoch: 5| Step: 1
Training loss: 1.8142484426498413
Validation loss: 1.980365071245419

Epoch: 5| Step: 2
Training loss: 1.4014270305633545
Validation loss: 1.9941260840303154

Epoch: 5| Step: 3
Training loss: 2.3181815147399902
Validation loss: 1.9931778164320095

Epoch: 5| Step: 4
Training loss: 1.7998402118682861
Validation loss: 1.9832222974428566

Epoch: 5| Step: 5
Training loss: 2.0904452800750732
Validation loss: 1.9740821135941373

Epoch: 5| Step: 6
Training loss: 1.3396624326705933
Validation loss: 1.956169565518697

Epoch: 5| Step: 7
Training loss: 2.0984623432159424
Validation loss: 1.9859987279420257

Epoch: 5| Step: 8
Training loss: 2.707253932952881
Validation loss: 1.9796574064480361

Epoch: 5| Step: 9
Training loss: 2.2487845420837402
Validation loss: 1.960814445249496

Epoch: 5| Step: 10
Training loss: 1.53569495677948
Validation loss: 1.9568339329893871

Epoch: 194| Step: 0
Training loss: 2.254395008087158
Validation loss: 2.0057994678456295

Epoch: 5| Step: 1
Training loss: 2.3547518253326416
Validation loss: 1.9997970622072938

Epoch: 5| Step: 2
Training loss: 1.7987682819366455
Validation loss: 1.9608769878264396

Epoch: 5| Step: 3
Training loss: 2.7530605792999268
Validation loss: 1.959227018458869

Epoch: 5| Step: 4
Training loss: 2.1662235260009766
Validation loss: 1.9686715333692488

Epoch: 5| Step: 5
Training loss: 1.6345134973526
Validation loss: 1.9845201020599694

Epoch: 5| Step: 6
Training loss: 1.363028645515442
Validation loss: 1.9896233363818097

Epoch: 5| Step: 7
Training loss: 1.8605502843856812
Validation loss: 1.9747727071085284

Epoch: 5| Step: 8
Training loss: 1.2572224140167236
Validation loss: 1.9653943764266146

Epoch: 5| Step: 9
Training loss: 2.1743552684783936
Validation loss: 1.9657124601384646

Epoch: 5| Step: 10
Training loss: 2.022684097290039
Validation loss: 1.9859715405330862

Epoch: 195| Step: 0
Training loss: 1.4910168647766113
Validation loss: 1.9812168959648377

Epoch: 5| Step: 1
Training loss: 2.1946825981140137
Validation loss: 1.9890021713831092

Epoch: 5| Step: 2
Training loss: 2.827542543411255
Validation loss: 1.9791029307150072

Epoch: 5| Step: 3
Training loss: 1.8419582843780518
Validation loss: 1.9694394770488943

Epoch: 5| Step: 4
Training loss: 1.6682713031768799
Validation loss: 1.9853411618099417

Epoch: 5| Step: 5
Training loss: 1.8206943273544312
Validation loss: 1.9659204470214022

Epoch: 5| Step: 6
Training loss: 1.6749216318130493
Validation loss: 1.979749959002259

Epoch: 5| Step: 7
Training loss: 2.1216375827789307
Validation loss: 1.9781160559705508

Epoch: 5| Step: 8
Training loss: 2.2418174743652344
Validation loss: 1.9684302217216902

Epoch: 5| Step: 9
Training loss: 1.638869047164917
Validation loss: 1.9756326829233477

Epoch: 5| Step: 10
Training loss: 2.1552069187164307
Validation loss: 1.9543029185264342

Epoch: 196| Step: 0
Training loss: 2.225497007369995
Validation loss: 1.9690304353672972

Epoch: 5| Step: 1
Training loss: 2.2352230548858643
Validation loss: 1.9780136756999518

Epoch: 5| Step: 2
Training loss: 2.2349610328674316
Validation loss: 1.991752452747796

Epoch: 5| Step: 3
Training loss: 2.290318012237549
Validation loss: 1.9556988849434802

Epoch: 5| Step: 4
Training loss: 1.5247118473052979
Validation loss: 1.9825204956916072

Epoch: 5| Step: 5
Training loss: 1.3243645429611206
Validation loss: 1.9769092375232327

Epoch: 5| Step: 6
Training loss: 2.1219820976257324
Validation loss: 1.9720005809619863

Epoch: 5| Step: 7
Training loss: 2.3493740558624268
Validation loss: 1.9671417244019047

Epoch: 5| Step: 8
Training loss: 2.1967997550964355
Validation loss: 1.9844486956955285

Epoch: 5| Step: 9
Training loss: 1.7000404596328735
Validation loss: 1.9812201299974996

Epoch: 5| Step: 10
Training loss: 1.487926721572876
Validation loss: 2.0146947304407754

Epoch: 197| Step: 0
Training loss: 1.5624208450317383
Validation loss: 1.9957970009055188

Epoch: 5| Step: 1
Training loss: 2.7523181438446045
Validation loss: 1.9867755238727858

Epoch: 5| Step: 2
Training loss: 0.9467436075210571
Validation loss: 1.9602279611813125

Epoch: 5| Step: 3
Training loss: 1.6310312747955322
Validation loss: 1.969052517285911

Epoch: 5| Step: 4
Training loss: 2.61329984664917
Validation loss: 1.9693791917575303

Epoch: 5| Step: 5
Training loss: 1.8777666091918945
Validation loss: 1.963661927048878

Epoch: 5| Step: 6
Training loss: 2.061326503753662
Validation loss: 1.961887103255077

Epoch: 5| Step: 7
Training loss: 2.322221279144287
Validation loss: 1.9804452952518259

Epoch: 5| Step: 8
Training loss: 1.865014672279358
Validation loss: 1.9631205656195199

Epoch: 5| Step: 9
Training loss: 1.616681456565857
Validation loss: 1.97990793694732

Epoch: 5| Step: 10
Training loss: 2.654839515686035
Validation loss: 1.9760215320894796

Epoch: 198| Step: 0
Training loss: 1.989790678024292
Validation loss: 1.9654853549054874

Epoch: 5| Step: 1
Training loss: 2.020555019378662
Validation loss: 1.9638998252089306

Epoch: 5| Step: 2
Training loss: 2.3513262271881104
Validation loss: 1.9841333999428699

Epoch: 5| Step: 3
Training loss: 1.272658109664917
Validation loss: 1.9705867152060232

Epoch: 5| Step: 4
Training loss: 2.0202064514160156
Validation loss: 1.9476128137239845

Epoch: 5| Step: 5
Training loss: 2.733872890472412
Validation loss: 1.9671334143607848

Epoch: 5| Step: 6
Training loss: 1.8304353952407837
Validation loss: 1.9881661040808565

Epoch: 5| Step: 7
Training loss: 1.987322211265564
Validation loss: 1.975613804273708

Epoch: 5| Step: 8
Training loss: 2.1003775596618652
Validation loss: 1.958056749836091

Epoch: 5| Step: 9
Training loss: 1.7465219497680664
Validation loss: 1.9764624975060905

Epoch: 5| Step: 10
Training loss: 1.4094711542129517
Validation loss: 1.9812079950045514

Epoch: 199| Step: 0
Training loss: 2.4167230129241943
Validation loss: 1.9952651287919732

Epoch: 5| Step: 1
Training loss: 1.6406581401824951
Validation loss: 1.9875333257900771

Epoch: 5| Step: 2
Training loss: 2.6043765544891357
Validation loss: 1.9800939226663241

Epoch: 5| Step: 3
Training loss: 2.0251412391662598
Validation loss: 1.9776557453217045

Epoch: 5| Step: 4
Training loss: 2.2306876182556152
Validation loss: 1.969702092550134

Epoch: 5| Step: 5
Training loss: 1.8883682489395142
Validation loss: 1.9977027728993406

Epoch: 5| Step: 6
Training loss: 1.7771852016448975
Validation loss: 1.961646859363843

Epoch: 5| Step: 7
Training loss: 1.7703298330307007
Validation loss: 1.983691427015489

Epoch: 5| Step: 8
Training loss: 1.6763604879379272
Validation loss: 1.9893001471796343

Epoch: 5| Step: 9
Training loss: 1.4809616804122925
Validation loss: 2.0050269403765277

Epoch: 5| Step: 10
Training loss: 2.1902785301208496
Validation loss: 1.9908156984595842

Epoch: 200| Step: 0
Training loss: 2.1399238109588623
Validation loss: 1.9638669747178272

Epoch: 5| Step: 1
Training loss: 1.872292160987854
Validation loss: 1.9528005135956632

Epoch: 5| Step: 2
Training loss: 1.7355760335922241
Validation loss: 1.963108672890612

Epoch: 5| Step: 3
Training loss: 1.8083661794662476
Validation loss: 1.9668483516221404

Epoch: 5| Step: 4
Training loss: 2.0387706756591797
Validation loss: 1.9505923127615323

Epoch: 5| Step: 5
Training loss: 1.3292286396026611
Validation loss: 1.9649386354672012

Epoch: 5| Step: 6
Training loss: 1.466785192489624
Validation loss: 1.9548677039402786

Epoch: 5| Step: 7
Training loss: 2.466357707977295
Validation loss: 1.964546852214362

Epoch: 5| Step: 8
Training loss: 2.582279682159424
Validation loss: 1.975196066723075

Epoch: 5| Step: 9
Training loss: 2.120345115661621
Validation loss: 1.9543584931281306

Epoch: 5| Step: 10
Training loss: 2.1018269062042236
Validation loss: 1.955376031578228

Epoch: 201| Step: 0
Training loss: 1.9411370754241943
Validation loss: 1.9623296414652178

Epoch: 5| Step: 1
Training loss: 1.9819872379302979
Validation loss: 1.9669081626399871

Epoch: 5| Step: 2
Training loss: 2.2606523036956787
Validation loss: 1.9858909601806312

Epoch: 5| Step: 3
Training loss: 2.7704243659973145
Validation loss: 1.9619218995494228

Epoch: 5| Step: 4
Training loss: 1.7776973247528076
Validation loss: 1.9602079288933867

Epoch: 5| Step: 5
Training loss: 2.1446292400360107
Validation loss: 1.9849913402270245

Epoch: 5| Step: 6
Training loss: 1.1823322772979736
Validation loss: 1.9956586578840851

Epoch: 5| Step: 7
Training loss: 1.95163094997406
Validation loss: 1.9925967801001765

Epoch: 5| Step: 8
Training loss: 1.720658540725708
Validation loss: 1.9864843917149368

Epoch: 5| Step: 9
Training loss: 2.2420949935913086
Validation loss: 1.9940181586050219

Epoch: 5| Step: 10
Training loss: 1.4851200580596924
Validation loss: 1.9906418733699347

Epoch: 202| Step: 0
Training loss: 2.1695613861083984
Validation loss: 1.9936694739967264

Epoch: 5| Step: 1
Training loss: 1.770160436630249
Validation loss: 1.9803750745711788

Epoch: 5| Step: 2
Training loss: 1.8963152170181274
Validation loss: 1.977269200868504

Epoch: 5| Step: 3
Training loss: 1.6114873886108398
Validation loss: 1.9870653793375979

Epoch: 5| Step: 4
Training loss: 1.7726223468780518
Validation loss: 1.9884481814599806

Epoch: 5| Step: 5
Training loss: 1.8584158420562744
Validation loss: 1.9774731641174645

Epoch: 5| Step: 6
Training loss: 2.774930000305176
Validation loss: 1.9585522656799645

Epoch: 5| Step: 7
Training loss: 1.9532899856567383
Validation loss: 1.9845317589339388

Epoch: 5| Step: 8
Training loss: 1.8706525564193726
Validation loss: 1.9899582221943846

Epoch: 5| Step: 9
Training loss: 2.168334722518921
Validation loss: 1.993380977261451

Epoch: 5| Step: 10
Training loss: 1.7652685642242432
Validation loss: 1.9521702566454489

Epoch: 203| Step: 0
Training loss: 1.9861576557159424
Validation loss: 1.955864837092738

Epoch: 5| Step: 1
Training loss: 1.843387246131897
Validation loss: 1.9848113700907717

Epoch: 5| Step: 2
Training loss: 1.3232390880584717
Validation loss: 1.9960330686261576

Epoch: 5| Step: 3
Training loss: 2.458434820175171
Validation loss: 1.979673049783194

Epoch: 5| Step: 4
Training loss: 1.3485875129699707
Validation loss: 1.9825800388090071

Epoch: 5| Step: 5
Training loss: 2.102527618408203
Validation loss: 1.9755380871475383

Epoch: 5| Step: 6
Training loss: 1.7412736415863037
Validation loss: 1.968521688574104

Epoch: 5| Step: 7
Training loss: 1.7897274494171143
Validation loss: 1.9662118675888225

Epoch: 5| Step: 8
Training loss: 2.0282340049743652
Validation loss: 1.9821756885897728

Epoch: 5| Step: 9
Training loss: 2.1191694736480713
Validation loss: 1.9761208770095662

Epoch: 5| Step: 10
Training loss: 2.569310426712036
Validation loss: 2.000288724899292

Epoch: 204| Step: 0
Training loss: 2.1109797954559326
Validation loss: 1.977918255713678

Epoch: 5| Step: 1
Training loss: 1.353327751159668
Validation loss: 1.979428663048693

Epoch: 5| Step: 2
Training loss: 1.9416087865829468
Validation loss: 1.981661988842872

Epoch: 5| Step: 3
Training loss: 1.7143113613128662
Validation loss: 1.9647729371183662

Epoch: 5| Step: 4
Training loss: 2.211716651916504
Validation loss: 1.9961846861788022

Epoch: 5| Step: 5
Training loss: 1.8928165435791016
Validation loss: 1.98607297097483

Epoch: 5| Step: 6
Training loss: 1.9751535654067993
Validation loss: 1.9601445505695958

Epoch: 5| Step: 7
Training loss: 2.1800436973571777
Validation loss: 1.99203590039284

Epoch: 5| Step: 8
Training loss: 2.09606671333313
Validation loss: 1.986498031564938

Epoch: 5| Step: 9
Training loss: 1.6969330310821533
Validation loss: 1.9448792703690068

Epoch: 5| Step: 10
Training loss: 2.0629780292510986
Validation loss: 1.966574404829292

Epoch: 205| Step: 0
Training loss: 1.8875526189804077
Validation loss: 1.9398537041038595

Epoch: 5| Step: 1
Training loss: 1.8532400131225586
Validation loss: 1.9612755647269629

Epoch: 5| Step: 2
Training loss: 2.7749009132385254
Validation loss: 1.9832572347374373

Epoch: 5| Step: 3
Training loss: 1.9738800525665283
Validation loss: 1.9418521645248576

Epoch: 5| Step: 4
Training loss: 1.6563835144042969
Validation loss: 1.9874834552887948

Epoch: 5| Step: 5
Training loss: 1.7684520483016968
Validation loss: 1.9770463141061927

Epoch: 5| Step: 6
Training loss: 1.6933696269989014
Validation loss: 1.9835589611402122

Epoch: 5| Step: 7
Training loss: 1.7396866083145142
Validation loss: 1.9610879831416632

Epoch: 5| Step: 8
Training loss: 1.9405410289764404
Validation loss: 1.9779933870479625

Epoch: 5| Step: 9
Training loss: 1.58149254322052
Validation loss: 1.9850372191398375

Epoch: 5| Step: 10
Training loss: 2.5887060165405273
Validation loss: 1.9857401488929667

Epoch: 206| Step: 0
Training loss: 1.8239017724990845
Validation loss: 1.9784575611032464

Epoch: 5| Step: 1
Training loss: 1.4931538105010986
Validation loss: 1.9641865966140584

Epoch: 5| Step: 2
Training loss: 1.4229499101638794
Validation loss: 1.9772532780965169

Epoch: 5| Step: 3
Training loss: 1.8929998874664307
Validation loss: 1.9923040982215636

Epoch: 5| Step: 4
Training loss: 2.1959595680236816
Validation loss: 1.9574251072381132

Epoch: 5| Step: 5
Training loss: 2.13425350189209
Validation loss: 1.9673561703774236

Epoch: 5| Step: 6
Training loss: 1.916473627090454
Validation loss: 1.9492590837581183

Epoch: 5| Step: 7
Training loss: 2.3144917488098145
Validation loss: 1.9612729241771083

Epoch: 5| Step: 8
Training loss: 2.2667934894561768
Validation loss: 1.97757932191254

Epoch: 5| Step: 9
Training loss: 2.2181990146636963
Validation loss: 1.949601468219552

Epoch: 5| Step: 10
Training loss: 1.4977021217346191
Validation loss: 1.969154598892376

Epoch: 207| Step: 0
Training loss: 2.0807628631591797
Validation loss: 1.9762151497666554

Epoch: 5| Step: 1
Training loss: 2.682595729827881
Validation loss: 1.98775194280891

Epoch: 5| Step: 2
Training loss: 1.7235755920410156
Validation loss: 1.9976925773005332

Epoch: 5| Step: 3
Training loss: 1.8322296142578125
Validation loss: 1.9656900180283414

Epoch: 5| Step: 4
Training loss: 2.0998334884643555
Validation loss: 1.968064913185694

Epoch: 5| Step: 5
Training loss: 1.5371472835540771
Validation loss: 1.9676907306076379

Epoch: 5| Step: 6
Training loss: 2.209550142288208
Validation loss: 1.9802470476396623

Epoch: 5| Step: 7
Training loss: 1.4206440448760986
Validation loss: 1.9554208350437943

Epoch: 5| Step: 8
Training loss: 2.318525791168213
Validation loss: 1.960297340987831

Epoch: 5| Step: 9
Training loss: 1.6535732746124268
Validation loss: 1.9918794119229881

Epoch: 5| Step: 10
Training loss: 1.661128044128418
Validation loss: 1.9611242073838429

Epoch: 208| Step: 0
Training loss: 1.4255565404891968
Validation loss: 1.9693771357177405

Epoch: 5| Step: 1
Training loss: 2.171602964401245
Validation loss: 1.9661950116516442

Epoch: 5| Step: 2
Training loss: 1.8175640106201172
Validation loss: 1.9489693667299004

Epoch: 5| Step: 3
Training loss: 2.135942220687866
Validation loss: 1.9789411431999617

Epoch: 5| Step: 4
Training loss: 1.9733912944793701
Validation loss: 1.9786784264349169

Epoch: 5| Step: 5
Training loss: 2.0287158489227295
Validation loss: 1.9764885005130564

Epoch: 5| Step: 6
Training loss: 2.2282283306121826
Validation loss: 1.9745028608588762

Epoch: 5| Step: 7
Training loss: 1.7204509973526
Validation loss: 1.9459540767054404

Epoch: 5| Step: 8
Training loss: 1.9010708332061768
Validation loss: 1.9597323543281966

Epoch: 5| Step: 9
Training loss: 2.0296120643615723
Validation loss: 1.9585692215991277

Epoch: 5| Step: 10
Training loss: 1.8727595806121826
Validation loss: 1.967736223692535

Epoch: 209| Step: 0
Training loss: 1.96195387840271
Validation loss: 1.973487780940148

Epoch: 5| Step: 1
Training loss: 2.3408682346343994
Validation loss: 1.9707484014572636

Epoch: 5| Step: 2
Training loss: 1.6143848896026611
Validation loss: 1.9699783222649687

Epoch: 5| Step: 3
Training loss: 2.5205471515655518
Validation loss: 1.9540515022893106

Epoch: 5| Step: 4
Training loss: 1.561144232749939
Validation loss: 1.966089387093821

Epoch: 5| Step: 5
Training loss: 2.509138822555542
Validation loss: 1.9757927643355502

Epoch: 5| Step: 6
Training loss: 1.8324182033538818
Validation loss: 1.9829115816341933

Epoch: 5| Step: 7
Training loss: 1.6082608699798584
Validation loss: 1.9668564719538535

Epoch: 5| Step: 8
Training loss: 1.762772560119629
Validation loss: 1.9912246555410407

Epoch: 5| Step: 9
Training loss: 1.4814656972885132
Validation loss: 1.9540527354004562

Epoch: 5| Step: 10
Training loss: 1.9806190729141235
Validation loss: 1.9859158582584833

Epoch: 210| Step: 0
Training loss: 2.5151426792144775
Validation loss: 1.9683216169316282

Epoch: 5| Step: 1
Training loss: 1.7197681665420532
Validation loss: 1.9626274160159531

Epoch: 5| Step: 2
Training loss: 2.11045503616333
Validation loss: 1.9736238346304944

Epoch: 5| Step: 3
Training loss: 2.1573545932769775
Validation loss: 1.945248382065886

Epoch: 5| Step: 4
Training loss: 1.812107801437378
Validation loss: 1.9717066134175947

Epoch: 5| Step: 5
Training loss: 1.9897146224975586
Validation loss: 1.9488431792105398

Epoch: 5| Step: 6
Training loss: 2.270799160003662
Validation loss: 1.9587809680610575

Epoch: 5| Step: 7
Training loss: 1.8780139684677124
Validation loss: 1.9528583647102438

Epoch: 5| Step: 8
Training loss: 1.8472402095794678
Validation loss: 1.9848569644394742

Epoch: 5| Step: 9
Training loss: 1.2524837255477905
Validation loss: 1.946437915166219

Epoch: 5| Step: 10
Training loss: 1.5875091552734375
Validation loss: 1.9661884192497499

Epoch: 211| Step: 0
Training loss: 1.768362045288086
Validation loss: 1.9529065675632928

Epoch: 5| Step: 1
Training loss: 1.866880178451538
Validation loss: 1.9653931381881877

Epoch: 5| Step: 2
Training loss: 2.078557252883911
Validation loss: 1.9430834990675732

Epoch: 5| Step: 3
Training loss: 2.290569305419922
Validation loss: 1.9551683292594007

Epoch: 5| Step: 4
Training loss: 2.4454596042633057
Validation loss: 1.9753107050413727

Epoch: 5| Step: 5
Training loss: 1.6678886413574219
Validation loss: 1.9465021382095993

Epoch: 5| Step: 6
Training loss: 1.4905204772949219
Validation loss: 1.9591339749674643

Epoch: 5| Step: 7
Training loss: 2.1919188499450684
Validation loss: 1.9903888984393048

Epoch: 5| Step: 8
Training loss: 1.8980951309204102
Validation loss: 1.9730234928028558

Epoch: 5| Step: 9
Training loss: 1.7322412729263306
Validation loss: 1.9574923438410605

Epoch: 5| Step: 10
Training loss: 1.7385752201080322
Validation loss: 1.9749456054420882

Epoch: 212| Step: 0
Training loss: 2.03800630569458
Validation loss: 1.9658421162636048

Epoch: 5| Step: 1
Training loss: 2.2552530765533447
Validation loss: 1.9824572352952854

Epoch: 5| Step: 2
Training loss: 1.8704535961151123
Validation loss: 1.9725018162881174

Epoch: 5| Step: 3
Training loss: 2.067020893096924
Validation loss: 1.9764893285689815

Epoch: 5| Step: 4
Training loss: 1.9962141513824463
Validation loss: 1.9628872153579549

Epoch: 5| Step: 5
Training loss: 2.1636996269226074
Validation loss: 1.9706488527277464

Epoch: 5| Step: 6
Training loss: 2.255993604660034
Validation loss: 1.965050515308175

Epoch: 5| Step: 7
Training loss: 1.915533423423767
Validation loss: 1.9799772001081897

Epoch: 5| Step: 8
Training loss: 1.4711620807647705
Validation loss: 1.9846528550629974

Epoch: 5| Step: 9
Training loss: 1.4978911876678467
Validation loss: 1.9729628280926776

Epoch: 5| Step: 10
Training loss: 1.472273826599121
Validation loss: 1.979374135694196

Epoch: 213| Step: 0
Training loss: 2.020087718963623
Validation loss: 1.974625523372363

Epoch: 5| Step: 1
Training loss: 2.049591541290283
Validation loss: 1.9861977587464035

Epoch: 5| Step: 2
Training loss: 2.1283414363861084
Validation loss: 1.9548927981366393

Epoch: 5| Step: 3
Training loss: 1.2156522274017334
Validation loss: 1.962904614786948

Epoch: 5| Step: 4
Training loss: 2.160247564315796
Validation loss: 1.9736942604023924

Epoch: 5| Step: 5
Training loss: 1.8230165243148804
Validation loss: 1.9596846924033215

Epoch: 5| Step: 6
Training loss: 2.1462621688842773
Validation loss: 1.9788715659931142

Epoch: 5| Step: 7
Training loss: 1.9128143787384033
Validation loss: 1.9797791229781283

Epoch: 5| Step: 8
Training loss: 1.5889379978179932
Validation loss: 1.9520970493234613

Epoch: 5| Step: 9
Training loss: 1.8421924114227295
Validation loss: 1.956288735071818

Epoch: 5| Step: 10
Training loss: 1.9850685596466064
Validation loss: 1.9636369148890178

Epoch: 214| Step: 0
Training loss: 1.451124906539917
Validation loss: 1.9621615820033576

Epoch: 5| Step: 1
Training loss: 1.9512484073638916
Validation loss: 1.940183767708399

Epoch: 5| Step: 2
Training loss: 1.4623017311096191
Validation loss: 1.9956153644028531

Epoch: 5| Step: 3
Training loss: 2.660165786743164
Validation loss: 1.9728774396322106

Epoch: 5| Step: 4
Training loss: 2.0139052867889404
Validation loss: 1.984534195674363

Epoch: 5| Step: 5
Training loss: 1.864581823348999
Validation loss: 1.9950609848063479

Epoch: 5| Step: 6
Training loss: 2.0949289798736572
Validation loss: 1.9825356211713565

Epoch: 5| Step: 7
Training loss: 1.864179253578186
Validation loss: 1.9540232125148977

Epoch: 5| Step: 8
Training loss: 2.2535176277160645
Validation loss: 1.9794522613607428

Epoch: 5| Step: 9
Training loss: 1.6595067977905273
Validation loss: 1.9663940809106315

Epoch: 5| Step: 10
Training loss: 1.638907551765442
Validation loss: 1.9995522319629628

Epoch: 215| Step: 0
Training loss: 2.0118119716644287
Validation loss: 1.9638845074561335

Epoch: 5| Step: 1
Training loss: 2.1479697227478027
Validation loss: 1.9628997502788421

Epoch: 5| Step: 2
Training loss: 1.5894367694854736
Validation loss: 1.9480693776120421

Epoch: 5| Step: 3
Training loss: 1.6176550388336182
Validation loss: 1.9634194989358225

Epoch: 5| Step: 4
Training loss: 1.6871169805526733
Validation loss: 1.9457907689514982

Epoch: 5| Step: 5
Training loss: 1.8260705471038818
Validation loss: 1.976633628209432

Epoch: 5| Step: 6
Training loss: 1.8236331939697266
Validation loss: 1.9582424830364924

Epoch: 5| Step: 7
Training loss: 2.8225250244140625
Validation loss: 1.957736288347552

Epoch: 5| Step: 8
Training loss: 1.9196140766143799
Validation loss: 1.969793051801702

Epoch: 5| Step: 9
Training loss: 1.4889029264450073
Validation loss: 1.9745174402831702

Epoch: 5| Step: 10
Training loss: 2.2150518894195557
Validation loss: 1.9609895213957755

Epoch: 216| Step: 0
Training loss: 1.9239330291748047
Validation loss: 1.9668114839061615

Epoch: 5| Step: 1
Training loss: 2.23980450630188
Validation loss: 1.9834952380067559

Epoch: 5| Step: 2
Training loss: 2.1487529277801514
Validation loss: 1.956601196719754

Epoch: 5| Step: 3
Training loss: 1.6660953760147095
Validation loss: 1.9815128823762298

Epoch: 5| Step: 4
Training loss: 1.963701605796814
Validation loss: 1.9533862260080153

Epoch: 5| Step: 5
Training loss: 1.5871151685714722
Validation loss: 1.9445715488926056

Epoch: 5| Step: 6
Training loss: 2.24115252494812
Validation loss: 1.9475987906097083

Epoch: 5| Step: 7
Training loss: 1.7657619714736938
Validation loss: 1.9487622835302865

Epoch: 5| Step: 8
Training loss: 1.980268120765686
Validation loss: 1.9554305281690372

Epoch: 5| Step: 9
Training loss: 2.2171807289123535
Validation loss: 1.9510113270052019

Epoch: 5| Step: 10
Training loss: 1.035034418106079
Validation loss: 1.9462861835315663

Epoch: 217| Step: 0
Training loss: 2.002894639968872
Validation loss: 1.9593329096353183

Epoch: 5| Step: 1
Training loss: 1.859757661819458
Validation loss: 1.9752054406750588

Epoch: 5| Step: 2
Training loss: 1.8068195581436157
Validation loss: 1.9732242412464593

Epoch: 5| Step: 3
Training loss: 1.8446159362792969
Validation loss: 1.9573152885642102

Epoch: 5| Step: 4
Training loss: 2.144472599029541
Validation loss: 1.9786660876325382

Epoch: 5| Step: 5
Training loss: 1.514953374862671
Validation loss: 1.9657357174863097

Epoch: 5| Step: 6
Training loss: 1.879657506942749
Validation loss: 1.9714869299242574

Epoch: 5| Step: 7
Training loss: 2.0701091289520264
Validation loss: 1.955013196955445

Epoch: 5| Step: 8
Training loss: 1.6188347339630127
Validation loss: 1.961264310344573

Epoch: 5| Step: 9
Training loss: 2.164382219314575
Validation loss: 1.9890325223245928

Epoch: 5| Step: 10
Training loss: 1.742125153541565
Validation loss: 1.9664037881358978

Epoch: 218| Step: 0
Training loss: 2.379075288772583
Validation loss: 1.9735191893833939

Epoch: 5| Step: 1
Training loss: 2.096491575241089
Validation loss: 1.9765457978812597

Epoch: 5| Step: 2
Training loss: 1.5706499814987183
Validation loss: 1.9550319051229825

Epoch: 5| Step: 3
Training loss: 1.9505043029785156
Validation loss: 1.9563378608354958

Epoch: 5| Step: 4
Training loss: 1.569269061088562
Validation loss: 1.981979231680593

Epoch: 5| Step: 5
Training loss: 2.4634053707122803
Validation loss: 1.9277104946874803

Epoch: 5| Step: 6
Training loss: 1.749362587928772
Validation loss: 1.988123401518791

Epoch: 5| Step: 7
Training loss: 1.9769980907440186
Validation loss: 1.9533891831674883

Epoch: 5| Step: 8
Training loss: 1.9289764165878296
Validation loss: 1.9503231586948517

Epoch: 5| Step: 9
Training loss: 1.9041391611099243
Validation loss: 1.9678697406604726

Epoch: 5| Step: 10
Training loss: 1.40199875831604
Validation loss: 1.944899546202793

Epoch: 219| Step: 0
Training loss: 1.9858818054199219
Validation loss: 1.9850893558994416

Epoch: 5| Step: 1
Training loss: 1.6211942434310913
Validation loss: 1.9552713030128068

Epoch: 5| Step: 2
Training loss: 1.7459790706634521
Validation loss: 1.958696085919616

Epoch: 5| Step: 3
Training loss: 2.0384910106658936
Validation loss: 1.9904171113044984

Epoch: 5| Step: 4
Training loss: 2.1070964336395264
Validation loss: 1.9641567584007018

Epoch: 5| Step: 5
Training loss: 1.9633249044418335
Validation loss: 1.9305750054697837

Epoch: 5| Step: 6
Training loss: 1.802019476890564
Validation loss: 1.9651384199819257

Epoch: 5| Step: 7
Training loss: 1.817352533340454
Validation loss: 2.0186821619669595

Epoch: 5| Step: 8
Training loss: 1.9555152654647827
Validation loss: 1.9391190223796393

Epoch: 5| Step: 9
Training loss: 2.1389920711517334
Validation loss: 1.9367573107442548

Epoch: 5| Step: 10
Training loss: 1.5185669660568237
Validation loss: 1.9376889121147893

Epoch: 220| Step: 0
Training loss: 2.1958155632019043
Validation loss: 1.9298522690291047

Epoch: 5| Step: 1
Training loss: 2.1654043197631836
Validation loss: 1.977892691089261

Epoch: 5| Step: 2
Training loss: 1.699550986289978
Validation loss: 1.965589359242429

Epoch: 5| Step: 3
Training loss: 1.7740824222564697
Validation loss: 1.9679929235930085

Epoch: 5| Step: 4
Training loss: 1.957838773727417
Validation loss: 1.941083670944296

Epoch: 5| Step: 5
Training loss: 1.8947563171386719
Validation loss: 1.9323562755379626

Epoch: 5| Step: 6
Training loss: 1.461153507232666
Validation loss: 1.9505599878167594

Epoch: 5| Step: 7
Training loss: 2.513972043991089
Validation loss: 1.9758496899758615

Epoch: 5| Step: 8
Training loss: 1.8433516025543213
Validation loss: 1.978246691406414

Epoch: 5| Step: 9
Training loss: 1.832355260848999
Validation loss: 1.9485499717855965

Epoch: 5| Step: 10
Training loss: 1.4374969005584717
Validation loss: 1.979000037716281

Epoch: 221| Step: 0
Training loss: 1.962942123413086
Validation loss: 1.9434973578299246

Epoch: 5| Step: 1
Training loss: 1.7066901922225952
Validation loss: 1.9608627070662796

Epoch: 5| Step: 2
Training loss: 2.263402223587036
Validation loss: 1.9773145670531898

Epoch: 5| Step: 3
Training loss: 1.8000266551971436
Validation loss: 1.985694198198216

Epoch: 5| Step: 4
Training loss: 1.4887311458587646
Validation loss: 1.9861506415951637

Epoch: 5| Step: 5
Training loss: 2.257314443588257
Validation loss: 1.9815866754901024

Epoch: 5| Step: 6
Training loss: 2.459118366241455
Validation loss: 1.9933413138953588

Epoch: 5| Step: 7
Training loss: 1.3840463161468506
Validation loss: 1.9802491998159757

Epoch: 5| Step: 8
Training loss: 1.6038318872451782
Validation loss: 1.9620604361257246

Epoch: 5| Step: 9
Training loss: 1.8399797677993774
Validation loss: 1.9720021473464144

Epoch: 5| Step: 10
Training loss: 1.9017951488494873
Validation loss: 1.972034937591963

Epoch: 222| Step: 0
Training loss: 1.562957763671875
Validation loss: 1.9739055812999766

Epoch: 5| Step: 1
Training loss: 1.923130750656128
Validation loss: 1.9675710355081866

Epoch: 5| Step: 2
Training loss: 1.9608440399169922
Validation loss: 1.9453554204715195

Epoch: 5| Step: 3
Training loss: 1.3875148296356201
Validation loss: 1.932708150597029

Epoch: 5| Step: 4
Training loss: 1.7440621852874756
Validation loss: 1.9446395174149544

Epoch: 5| Step: 5
Training loss: 1.950423002243042
Validation loss: 1.9446154217566214

Epoch: 5| Step: 6
Training loss: 2.0786585807800293
Validation loss: 1.9757101587069932

Epoch: 5| Step: 7
Training loss: 1.3700592517852783
Validation loss: 1.9493529527418074

Epoch: 5| Step: 8
Training loss: 2.4563260078430176
Validation loss: 1.975246746052978

Epoch: 5| Step: 9
Training loss: 2.1814253330230713
Validation loss: 1.948786884225825

Epoch: 5| Step: 10
Training loss: 2.150710105895996
Validation loss: 1.9428160421309932

Epoch: 223| Step: 0
Training loss: 2.402169704437256
Validation loss: 1.9629829827175345

Epoch: 5| Step: 1
Training loss: 1.3359907865524292
Validation loss: 1.9355615723517634

Epoch: 5| Step: 2
Training loss: 1.4300856590270996
Validation loss: 1.9460387922102405

Epoch: 5| Step: 3
Training loss: 2.497269630432129
Validation loss: 1.9426462534935243

Epoch: 5| Step: 4
Training loss: 1.5089633464813232
Validation loss: 1.9716937324052215

Epoch: 5| Step: 5
Training loss: 2.428708791732788
Validation loss: 1.9513295312081613

Epoch: 5| Step: 6
Training loss: 1.9459764957427979
Validation loss: 1.9402283327553862

Epoch: 5| Step: 7
Training loss: 1.614081621170044
Validation loss: 1.9542073331853396

Epoch: 5| Step: 8
Training loss: 1.724890947341919
Validation loss: 1.985670429404064

Epoch: 5| Step: 9
Training loss: 1.8011462688446045
Validation loss: 1.9711238158646451

Epoch: 5| Step: 10
Training loss: 1.9563870429992676
Validation loss: 1.9684334352452268

Epoch: 224| Step: 0
Training loss: 1.604736328125
Validation loss: 1.970572413936738

Epoch: 5| Step: 1
Training loss: 2.9821441173553467
Validation loss: 1.9569865593346216

Epoch: 5| Step: 2
Training loss: 2.263249635696411
Validation loss: 1.9461570939710062

Epoch: 5| Step: 3
Training loss: 2.3496124744415283
Validation loss: 1.933387820438672

Epoch: 5| Step: 4
Training loss: 1.568693995475769
Validation loss: 1.9764797790076143

Epoch: 5| Step: 5
Training loss: 1.8752845525741577
Validation loss: 1.9625389088866532

Epoch: 5| Step: 6
Training loss: 1.5672435760498047
Validation loss: 1.9621562368126326

Epoch: 5| Step: 7
Training loss: 1.7067588567733765
Validation loss: 1.9464600124666769

Epoch: 5| Step: 8
Training loss: 2.1617677211761475
Validation loss: 1.967536005922543

Epoch: 5| Step: 9
Training loss: 1.113640308380127
Validation loss: 1.944312221260481

Epoch: 5| Step: 10
Training loss: 1.5220016241073608
Validation loss: 1.9449255851007277

Epoch: 225| Step: 0
Training loss: 1.3332414627075195
Validation loss: 1.9689010881608533

Epoch: 5| Step: 1
Training loss: 1.2326834201812744
Validation loss: 1.9826437375878776

Epoch: 5| Step: 2
Training loss: 1.8535085916519165
Validation loss: 1.9593455868382608

Epoch: 5| Step: 3
Training loss: 1.9833494424819946
Validation loss: 1.961805812774166

Epoch: 5| Step: 4
Training loss: 1.8639509677886963
Validation loss: 1.9711205023591236

Epoch: 5| Step: 5
Training loss: 2.0635387897491455
Validation loss: 1.9713010377781366

Epoch: 5| Step: 6
Training loss: 1.7759227752685547
Validation loss: 1.9677557817069433

Epoch: 5| Step: 7
Training loss: 1.808470368385315
Validation loss: 1.968607569253573

Epoch: 5| Step: 8
Training loss: 2.133885145187378
Validation loss: 1.9499003758994482

Epoch: 5| Step: 9
Training loss: 2.3734538555145264
Validation loss: 1.9629943781001593

Epoch: 5| Step: 10
Training loss: 2.1660993099212646
Validation loss: 1.9570071440871044

Epoch: 226| Step: 0
Training loss: 2.2141642570495605
Validation loss: 1.9417781291469451

Epoch: 5| Step: 1
Training loss: 1.5167945623397827
Validation loss: 1.9408039610872987

Epoch: 5| Step: 2
Training loss: 2.283693313598633
Validation loss: 1.9360487948181808

Epoch: 5| Step: 3
Training loss: 1.4485249519348145
Validation loss: 1.9332228014546056

Epoch: 5| Step: 4
Training loss: 1.5321348905563354
Validation loss: 1.9768620101354455

Epoch: 5| Step: 5
Training loss: 1.2303215265274048
Validation loss: 1.9339378546643

Epoch: 5| Step: 6
Training loss: 3.091566801071167
Validation loss: 1.9321769411845873

Epoch: 5| Step: 7
Training loss: 1.985748291015625
Validation loss: 1.9594716000300583

Epoch: 5| Step: 8
Training loss: 1.1955820322036743
Validation loss: 1.9533883807479695

Epoch: 5| Step: 9
Training loss: 2.069762706756592
Validation loss: 1.9689733546267274

Epoch: 5| Step: 10
Training loss: 1.9267131090164185
Validation loss: 1.9450660777348343

Epoch: 227| Step: 0
Training loss: 1.382536768913269
Validation loss: 1.9435309210131246

Epoch: 5| Step: 1
Training loss: 2.4486875534057617
Validation loss: 1.9562245440739456

Epoch: 5| Step: 2
Training loss: 1.845315933227539
Validation loss: 1.9338939574456984

Epoch: 5| Step: 3
Training loss: 1.5991603136062622
Validation loss: 1.9661804296637093

Epoch: 5| Step: 4
Training loss: 1.6049684286117554
Validation loss: 1.9495950565543225

Epoch: 5| Step: 5
Training loss: 1.7604610919952393
Validation loss: 1.953856921965076

Epoch: 5| Step: 6
Training loss: 2.4863879680633545
Validation loss: 1.9510896064901864

Epoch: 5| Step: 7
Training loss: 2.115072727203369
Validation loss: 1.9660225440097112

Epoch: 5| Step: 8
Training loss: 1.4132287502288818
Validation loss: 1.9731621998612598

Epoch: 5| Step: 9
Training loss: 1.79677414894104
Validation loss: 1.9535492902160974

Epoch: 5| Step: 10
Training loss: 2.200721502304077
Validation loss: 1.955434960703696

Epoch: 228| Step: 0
Training loss: 2.1752266883850098
Validation loss: 1.9546450312419603

Epoch: 5| Step: 1
Training loss: 1.9826797246932983
Validation loss: 1.9567619869785924

Epoch: 5| Step: 2
Training loss: 2.094611883163452
Validation loss: 1.9797535365627659

Epoch: 5| Step: 3
Training loss: 1.7213436365127563
Validation loss: 1.9649632323172785

Epoch: 5| Step: 4
Training loss: 1.6857753992080688
Validation loss: 1.9623832882091563

Epoch: 5| Step: 5
Training loss: 1.6333707571029663
Validation loss: 1.9539633617606214

Epoch: 5| Step: 6
Training loss: 2.0680038928985596
Validation loss: 1.9866309114681777

Epoch: 5| Step: 7
Training loss: 1.8328956365585327
Validation loss: 1.9701438501317015

Epoch: 5| Step: 8
Training loss: 1.6492822170257568
Validation loss: 1.971740553455968

Epoch: 5| Step: 9
Training loss: 1.3870282173156738
Validation loss: 1.9735396728720715

Epoch: 5| Step: 10
Training loss: 2.362367868423462
Validation loss: 1.952142564199304

Epoch: 229| Step: 0
Training loss: 2.209650754928589
Validation loss: 1.9528080788991784

Epoch: 5| Step: 1
Training loss: 1.9056850671768188
Validation loss: 1.9476310386452624

Epoch: 5| Step: 2
Training loss: 1.6269261837005615
Validation loss: 1.9321132116420294

Epoch: 5| Step: 3
Training loss: 2.053879737854004
Validation loss: 1.9330675217413134

Epoch: 5| Step: 4
Training loss: 1.9158132076263428
Validation loss: 1.914556041840584

Epoch: 5| Step: 5
Training loss: 2.2979774475097656
Validation loss: 1.9299467571320073

Epoch: 5| Step: 6
Training loss: 1.9477856159210205
Validation loss: 1.9502933179178545

Epoch: 5| Step: 7
Training loss: 1.9386913776397705
Validation loss: 1.938787382136109

Epoch: 5| Step: 8
Training loss: 1.4687449932098389
Validation loss: 1.939237145967381

Epoch: 5| Step: 9
Training loss: 1.4984807968139648
Validation loss: 1.9454082904323455

Epoch: 5| Step: 10
Training loss: 1.556370735168457
Validation loss: 1.9326429277338006

Epoch: 230| Step: 0
Training loss: 2.064828395843506
Validation loss: 1.951165303107231

Epoch: 5| Step: 1
Training loss: 2.129258394241333
Validation loss: 1.936438447685652

Epoch: 5| Step: 2
Training loss: 1.3082411289215088
Validation loss: 1.9532418545856272

Epoch: 5| Step: 3
Training loss: 2.1130354404449463
Validation loss: 1.9382691819180724

Epoch: 5| Step: 4
Training loss: 1.964917778968811
Validation loss: 1.9101800969851914

Epoch: 5| Step: 5
Training loss: 2.1791539192199707
Validation loss: 1.940755021187567

Epoch: 5| Step: 6
Training loss: 1.758832335472107
Validation loss: 1.9655909999724357

Epoch: 5| Step: 7
Training loss: 1.5544897317886353
Validation loss: 1.9360622423951344

Epoch: 5| Step: 8
Training loss: 1.3947848081588745
Validation loss: 1.9256058764714066

Epoch: 5| Step: 9
Training loss: 2.201298236846924
Validation loss: 1.9364031207176946

Epoch: 5| Step: 10
Training loss: 1.6472127437591553
Validation loss: 1.9687466980308614

Epoch: 231| Step: 0
Training loss: 1.556878685951233
Validation loss: 1.9507551757238244

Epoch: 5| Step: 1
Training loss: 1.9586122035980225
Validation loss: 1.9631052286394182

Epoch: 5| Step: 2
Training loss: 1.8142662048339844
Validation loss: 1.9794742984156455

Epoch: 5| Step: 3
Training loss: 1.193922758102417
Validation loss: 1.9670712037753033

Epoch: 5| Step: 4
Training loss: 2.204777479171753
Validation loss: 1.9419674360623924

Epoch: 5| Step: 5
Training loss: 2.411208391189575
Validation loss: 1.9700719169391099

Epoch: 5| Step: 6
Training loss: 1.9034450054168701
Validation loss: 1.9551653426180604

Epoch: 5| Step: 7
Training loss: 2.1524617671966553
Validation loss: 1.9553413698750157

Epoch: 5| Step: 8
Training loss: 2.005800485610962
Validation loss: 1.973801064234908

Epoch: 5| Step: 9
Training loss: 1.4016033411026
Validation loss: 1.956500954525445

Epoch: 5| Step: 10
Training loss: 1.6348819732666016
Validation loss: 1.9639677334857244

Epoch: 232| Step: 0
Training loss: 2.0115790367126465
Validation loss: 1.9620338511723343

Epoch: 5| Step: 1
Training loss: 1.4474916458129883
Validation loss: 1.9675105053891417

Epoch: 5| Step: 2
Training loss: 1.1305873394012451
Validation loss: 1.9751382822631507

Epoch: 5| Step: 3
Training loss: 1.9103872776031494
Validation loss: 1.9709918152901433

Epoch: 5| Step: 4
Training loss: 1.8263871669769287
Validation loss: 1.9505750325418287

Epoch: 5| Step: 5
Training loss: 1.7836532592773438
Validation loss: 1.9530973280629804

Epoch: 5| Step: 6
Training loss: 2.107959747314453
Validation loss: 1.9467289114511142

Epoch: 5| Step: 7
Training loss: 1.765064001083374
Validation loss: 1.9383693677122875

Epoch: 5| Step: 8
Training loss: 2.076413631439209
Validation loss: 1.9372302434777702

Epoch: 5| Step: 9
Training loss: 2.4909985065460205
Validation loss: 1.9542090380063621

Epoch: 5| Step: 10
Training loss: 1.780502438545227
Validation loss: 1.9493288891289824

Epoch: 233| Step: 0
Training loss: 2.2401797771453857
Validation loss: 1.944514069505917

Epoch: 5| Step: 1
Training loss: 1.8639605045318604
Validation loss: 1.9436319181996007

Epoch: 5| Step: 2
Training loss: 1.9607794284820557
Validation loss: 1.9399393322647258

Epoch: 5| Step: 3
Training loss: 2.1692206859588623
Validation loss: 1.939030852369083

Epoch: 5| Step: 4
Training loss: 1.8544261455535889
Validation loss: 1.959253982831073

Epoch: 5| Step: 5
Training loss: 1.3410050868988037
Validation loss: 1.9523477426139257

Epoch: 5| Step: 6
Training loss: 1.6528860330581665
Validation loss: 1.972455225965028

Epoch: 5| Step: 7
Training loss: 1.6940635442733765
Validation loss: 1.9650356795198174

Epoch: 5| Step: 8
Training loss: 1.7625162601470947
Validation loss: 2.0240293574589554

Epoch: 5| Step: 9
Training loss: 2.0845417976379395
Validation loss: 1.979896729992282

Epoch: 5| Step: 10
Training loss: 1.7724813222885132
Validation loss: 1.975575788046724

Epoch: 234| Step: 0
Training loss: 1.1190135478973389
Validation loss: 1.935923284099948

Epoch: 5| Step: 1
Training loss: 1.7556803226470947
Validation loss: 1.9662990723886797

Epoch: 5| Step: 2
Training loss: 1.5649360418319702
Validation loss: 1.9119284614439933

Epoch: 5| Step: 3
Training loss: 1.8638193607330322
Validation loss: 1.9466997859298543

Epoch: 5| Step: 4
Training loss: 1.8444916009902954
Validation loss: 1.9216713802788847

Epoch: 5| Step: 5
Training loss: 2.2038891315460205
Validation loss: 1.9491883990585164

Epoch: 5| Step: 6
Training loss: 1.7250444889068604
Validation loss: 1.9012760693027126

Epoch: 5| Step: 7
Training loss: 2.06122088432312
Validation loss: 1.944059286707191

Epoch: 5| Step: 8
Training loss: 2.195838212966919
Validation loss: 1.9439225863384944

Epoch: 5| Step: 9
Training loss: 1.9579193592071533
Validation loss: 1.958774511532117

Epoch: 5| Step: 10
Training loss: 2.2433478832244873
Validation loss: 1.9387205364883586

Epoch: 235| Step: 0
Training loss: 2.184843063354492
Validation loss: 1.9468149062125915

Epoch: 5| Step: 1
Training loss: 1.919961929321289
Validation loss: 1.9585187512059365

Epoch: 5| Step: 2
Training loss: 1.3923051357269287
Validation loss: 1.92855494124915

Epoch: 5| Step: 3
Training loss: 1.7997715473175049
Validation loss: 1.944475144468328

Epoch: 5| Step: 4
Training loss: 1.6640758514404297
Validation loss: 1.9484371985158613

Epoch: 5| Step: 5
Training loss: 1.66034734249115
Validation loss: 1.9498226437517392

Epoch: 5| Step: 6
Training loss: 1.7655518054962158
Validation loss: 1.9014877016826341

Epoch: 5| Step: 7
Training loss: 2.2862930297851562
Validation loss: 1.9344690794585853

Epoch: 5| Step: 8
Training loss: 1.7060718536376953
Validation loss: 1.9232423907967025

Epoch: 5| Step: 9
Training loss: 1.6664167642593384
Validation loss: 1.959613246302451

Epoch: 5| Step: 10
Training loss: 2.0946648120880127
Validation loss: 1.925208665991342

Epoch: 236| Step: 0
Training loss: 1.5961997509002686
Validation loss: 1.9409962546440862

Epoch: 5| Step: 1
Training loss: 1.6444228887557983
Validation loss: 1.9576910644449212

Epoch: 5| Step: 2
Training loss: 2.336000919342041
Validation loss: 1.971549923701953

Epoch: 5| Step: 3
Training loss: 2.005133867263794
Validation loss: 1.956114815127465

Epoch: 5| Step: 4
Training loss: 2.3228135108947754
Validation loss: 1.934116958290018

Epoch: 5| Step: 5
Training loss: 1.5837599039077759
Validation loss: 1.97087388653909

Epoch: 5| Step: 6
Training loss: 1.9528220891952515
Validation loss: 1.9630764633096673

Epoch: 5| Step: 7
Training loss: 1.9147220849990845
Validation loss: 1.9571973662222586

Epoch: 5| Step: 8
Training loss: 1.6053727865219116
Validation loss: 1.966367866403313

Epoch: 5| Step: 9
Training loss: 1.1070709228515625
Validation loss: 1.9568497647521317

Epoch: 5| Step: 10
Training loss: 2.1519694328308105
Validation loss: 1.943743468612753

Epoch: 237| Step: 0
Training loss: 2.3340935707092285
Validation loss: 1.9568768406427035

Epoch: 5| Step: 1
Training loss: 1.7707841396331787
Validation loss: 1.9685285296491397

Epoch: 5| Step: 2
Training loss: 1.8895273208618164
Validation loss: 1.9695437364680792

Epoch: 5| Step: 3
Training loss: 1.9068081378936768
Validation loss: 1.9764739838979577

Epoch: 5| Step: 4
Training loss: 2.0399012565612793
Validation loss: 1.9609753495903426

Epoch: 5| Step: 5
Training loss: 2.2588229179382324
Validation loss: 1.9877432520671556

Epoch: 5| Step: 6
Training loss: 1.9085496664047241
Validation loss: 1.9625111690131567

Epoch: 5| Step: 7
Training loss: 1.5982722043991089
Validation loss: 1.9585372042912308

Epoch: 5| Step: 8
Training loss: 1.5597784519195557
Validation loss: 1.9487096622426023

Epoch: 5| Step: 9
Training loss: 1.8152334690093994
Validation loss: 1.949504679249179

Epoch: 5| Step: 10
Training loss: 0.87968909740448
Validation loss: 1.9387779774204377

Epoch: 238| Step: 0
Training loss: 2.5495970249176025
Validation loss: 1.9512660067568544

Epoch: 5| Step: 1
Training loss: 1.7739938497543335
Validation loss: 1.9430783487135364

Epoch: 5| Step: 2
Training loss: 1.4529199600219727
Validation loss: 1.9733733925768124

Epoch: 5| Step: 3
Training loss: 2.0135018825531006
Validation loss: 1.9479319036647837

Epoch: 5| Step: 4
Training loss: 1.6303917169570923
Validation loss: 1.9406177177224109

Epoch: 5| Step: 5
Training loss: 1.7472785711288452
Validation loss: 1.924942216565532

Epoch: 5| Step: 6
Training loss: 1.4535130262374878
Validation loss: 1.9172404043136104

Epoch: 5| Step: 7
Training loss: 1.9179515838623047
Validation loss: 1.914247775590548

Epoch: 5| Step: 8
Training loss: 1.9516079425811768
Validation loss: 1.9340392569059968

Epoch: 5| Step: 9
Training loss: 1.9242603778839111
Validation loss: 1.9602028041757562

Epoch: 5| Step: 10
Training loss: 1.7835173606872559
Validation loss: 1.9281101611352736

Epoch: 239| Step: 0
Training loss: 1.9565021991729736
Validation loss: 1.9102945417486212

Epoch: 5| Step: 1
Training loss: 2.0904319286346436
Validation loss: 1.9348675179225143

Epoch: 5| Step: 2
Training loss: 2.012847900390625
Validation loss: 1.941248970647012

Epoch: 5| Step: 3
Training loss: 1.9636726379394531
Validation loss: 1.946673595777122

Epoch: 5| Step: 4
Training loss: 1.3376470804214478
Validation loss: 1.958282034884217

Epoch: 5| Step: 5
Training loss: 1.8969509601593018
Validation loss: 1.913800758700217

Epoch: 5| Step: 6
Training loss: 1.5037269592285156
Validation loss: 1.9490000201809792

Epoch: 5| Step: 7
Training loss: 1.866398572921753
Validation loss: 1.949142594491282

Epoch: 5| Step: 8
Training loss: 1.8479048013687134
Validation loss: 1.9630802767251128

Epoch: 5| Step: 9
Training loss: 1.9924414157867432
Validation loss: 1.97367008783484

Epoch: 5| Step: 10
Training loss: 1.5505958795547485
Validation loss: 1.9697615805492605

Epoch: 240| Step: 0
Training loss: 1.3094089031219482
Validation loss: 1.9534759931666876

Epoch: 5| Step: 1
Training loss: 1.652295470237732
Validation loss: 1.9383185268730245

Epoch: 5| Step: 2
Training loss: 1.5864671468734741
Validation loss: 1.9285445995228265

Epoch: 5| Step: 3
Training loss: 1.9428298473358154
Validation loss: 1.9683767762235416

Epoch: 5| Step: 4
Training loss: 2.4122583866119385
Validation loss: 1.95109123440199

Epoch: 5| Step: 5
Training loss: 1.9111725091934204
Validation loss: 1.9591966213718537

Epoch: 5| Step: 6
Training loss: 1.7840430736541748
Validation loss: 1.9175002613375265

Epoch: 5| Step: 7
Training loss: 1.7224171161651611
Validation loss: 1.9366239181128881

Epoch: 5| Step: 8
Training loss: 2.487450122833252
Validation loss: 1.913173670409828

Epoch: 5| Step: 9
Training loss: 1.6940529346466064
Validation loss: 1.930038631603282

Epoch: 5| Step: 10
Training loss: 1.4549078941345215
Validation loss: 1.9358492871766448

Epoch: 241| Step: 0
Training loss: 1.6956526041030884
Validation loss: 1.9132252303502892

Epoch: 5| Step: 1
Training loss: 1.6405982971191406
Validation loss: 1.9178746977160055

Epoch: 5| Step: 2
Training loss: 1.947188138961792
Validation loss: 1.92091864796095

Epoch: 5| Step: 3
Training loss: 2.189220428466797
Validation loss: 1.9298233473172752

Epoch: 5| Step: 4
Training loss: 1.2639473676681519
Validation loss: 1.9208691043238486

Epoch: 5| Step: 5
Training loss: 2.0425286293029785
Validation loss: 1.919654703909351

Epoch: 5| Step: 6
Training loss: 1.5461362600326538
Validation loss: 1.9239886050583215

Epoch: 5| Step: 7
Training loss: 1.7180858850479126
Validation loss: 1.9358089380366827

Epoch: 5| Step: 8
Training loss: 1.5974390506744385
Validation loss: 1.9343481922662387

Epoch: 5| Step: 9
Training loss: 2.1544816493988037
Validation loss: 1.95313690041983

Epoch: 5| Step: 10
Training loss: 2.253631830215454
Validation loss: 1.948721730580894

Epoch: 242| Step: 0
Training loss: 2.0235185623168945
Validation loss: 1.9704835055976786

Epoch: 5| Step: 1
Training loss: 2.082552433013916
Validation loss: 1.950562823203302

Epoch: 5| Step: 2
Training loss: 1.591582179069519
Validation loss: 1.9284172711833831

Epoch: 5| Step: 3
Training loss: 1.7298681735992432
Validation loss: 1.970844207271453

Epoch: 5| Step: 4
Training loss: 1.470191240310669
Validation loss: 1.9231223944694764

Epoch: 5| Step: 5
Training loss: 1.4102776050567627
Validation loss: 1.9463453510756135

Epoch: 5| Step: 6
Training loss: 1.9061558246612549
Validation loss: 1.9660310219692927

Epoch: 5| Step: 7
Training loss: 2.9644291400909424
Validation loss: 1.9510163107225973

Epoch: 5| Step: 8
Training loss: 1.776598334312439
Validation loss: 1.9524778601943806

Epoch: 5| Step: 9
Training loss: 1.6654186248779297
Validation loss: 1.9772865413337626

Epoch: 5| Step: 10
Training loss: 1.2373895645141602
Validation loss: 1.9265466992573073

Epoch: 243| Step: 0
Training loss: 1.8109543323516846
Validation loss: 1.9448396582757272

Epoch: 5| Step: 1
Training loss: 1.441554069519043
Validation loss: 1.948609798185287

Epoch: 5| Step: 2
Training loss: 1.602699875831604
Validation loss: 1.9398267326816436

Epoch: 5| Step: 3
Training loss: 1.6501318216323853
Validation loss: 1.9655328540391819

Epoch: 5| Step: 4
Training loss: 1.7394120693206787
Validation loss: 1.9406903969344271

Epoch: 5| Step: 5
Training loss: 2.2329070568084717
Validation loss: 1.9106342741238174

Epoch: 5| Step: 6
Training loss: 1.3904685974121094
Validation loss: 1.9481226757008543

Epoch: 5| Step: 7
Training loss: 2.203625440597534
Validation loss: 1.947798155969189

Epoch: 5| Step: 8
Training loss: 2.295933961868286
Validation loss: 1.937571051300213

Epoch: 5| Step: 9
Training loss: 2.011509418487549
Validation loss: 1.9368668935632194

Epoch: 5| Step: 10
Training loss: 1.355516791343689
Validation loss: 1.9221375283374582

Epoch: 244| Step: 0
Training loss: 1.570107340812683
Validation loss: 1.929951157621158

Epoch: 5| Step: 1
Training loss: 1.8502311706542969
Validation loss: 1.985379380564536

Epoch: 5| Step: 2
Training loss: 1.9705203771591187
Validation loss: 1.92351354963036

Epoch: 5| Step: 3
Training loss: 1.3282289505004883
Validation loss: 1.9121787471155967

Epoch: 5| Step: 4
Training loss: 1.6520541906356812
Validation loss: 1.914599169966995

Epoch: 5| Step: 5
Training loss: 2.8071160316467285
Validation loss: 1.9450189605835946

Epoch: 5| Step: 6
Training loss: 1.8601086139678955
Validation loss: 1.9298752712947067

Epoch: 5| Step: 7
Training loss: 1.7874902486801147
Validation loss: 1.9243190391089326

Epoch: 5| Step: 8
Training loss: 1.5840997695922852
Validation loss: 1.915441357961265

Epoch: 5| Step: 9
Training loss: 1.5913258790969849
Validation loss: 1.944313726117534

Epoch: 5| Step: 10
Training loss: 1.6698380708694458
Validation loss: 1.935445975231868

Epoch: 245| Step: 0
Training loss: 1.565129280090332
Validation loss: 1.9335637823227914

Epoch: 5| Step: 1
Training loss: 1.3604457378387451
Validation loss: 1.9358587841833792

Epoch: 5| Step: 2
Training loss: 1.541813850402832
Validation loss: 1.9373297524708573

Epoch: 5| Step: 3
Training loss: 2.4630656242370605
Validation loss: 1.9517914915597567

Epoch: 5| Step: 4
Training loss: 1.358899712562561
Validation loss: 1.9579319569372362

Epoch: 5| Step: 5
Training loss: 2.140042781829834
Validation loss: 1.9451670979940763

Epoch: 5| Step: 6
Training loss: 2.2152633666992188
Validation loss: 1.9294767661761212

Epoch: 5| Step: 7
Training loss: 2.2661385536193848
Validation loss: 1.9339004755020142

Epoch: 5| Step: 8
Training loss: 1.734429121017456
Validation loss: 1.9586993263613792

Epoch: 5| Step: 9
Training loss: 1.5179678201675415
Validation loss: 1.9422919955304874

Epoch: 5| Step: 10
Training loss: 1.5110342502593994
Validation loss: 1.9455242720983361

Epoch: 246| Step: 0
Training loss: 1.64925217628479
Validation loss: 1.9070859480929632

Epoch: 5| Step: 1
Training loss: 1.9391263723373413
Validation loss: 1.8994428444934148

Epoch: 5| Step: 2
Training loss: 1.6303784847259521
Validation loss: 1.9175042721533007

Epoch: 5| Step: 3
Training loss: 1.625828504562378
Validation loss: 1.9489756284221527

Epoch: 5| Step: 4
Training loss: 1.9104951620101929
Validation loss: 1.9341455582649476

Epoch: 5| Step: 5
Training loss: 1.5996978282928467
Validation loss: 1.9032877235002414

Epoch: 5| Step: 6
Training loss: 2.0172455310821533
Validation loss: 1.939163177244125

Epoch: 5| Step: 7
Training loss: 2.442286729812622
Validation loss: 1.9357063001202

Epoch: 5| Step: 8
Training loss: 1.6801239252090454
Validation loss: 1.9286486743598856

Epoch: 5| Step: 9
Training loss: 1.4492332935333252
Validation loss: 1.9329053381437897

Epoch: 5| Step: 10
Training loss: 1.9357129335403442
Validation loss: 1.9196513493855794

Epoch: 247| Step: 0
Training loss: 2.1470046043395996
Validation loss: 1.925774012842486

Epoch: 5| Step: 1
Training loss: 1.7445685863494873
Validation loss: 1.9075053161190403

Epoch: 5| Step: 2
Training loss: 2.2413489818573
Validation loss: 1.9097695350646973

Epoch: 5| Step: 3
Training loss: 2.32666277885437
Validation loss: 1.9384609114739202

Epoch: 5| Step: 4
Training loss: 1.5017579793930054
Validation loss: 1.9186189443834367

Epoch: 5| Step: 5
Training loss: 1.6069742441177368
Validation loss: 1.9374279360617361

Epoch: 5| Step: 6
Training loss: 1.7679798603057861
Validation loss: 1.9055032525011288

Epoch: 5| Step: 7
Training loss: 1.7915531396865845
Validation loss: 1.9167062518417195

Epoch: 5| Step: 8
Training loss: 2.0222995281219482
Validation loss: 1.9456774778263544

Epoch: 5| Step: 9
Training loss: 0.9920666813850403
Validation loss: 1.933097408663842

Epoch: 5| Step: 10
Training loss: 1.5508965253829956
Validation loss: 1.9346981304948048

Epoch: 248| Step: 0
Training loss: 2.114393949508667
Validation loss: 1.951582303611181

Epoch: 5| Step: 1
Training loss: 1.466172456741333
Validation loss: 1.958337850468133

Epoch: 5| Step: 2
Training loss: 2.0041072368621826
Validation loss: 1.945486278944118

Epoch: 5| Step: 3
Training loss: 1.2863099575042725
Validation loss: 1.918691832532165

Epoch: 5| Step: 4
Training loss: 2.0485329627990723
Validation loss: 1.8917896286133797

Epoch: 5| Step: 5
Training loss: 1.7722688913345337
Validation loss: 1.891696435148998

Epoch: 5| Step: 6
Training loss: 1.5211312770843506
Validation loss: 1.8769546631843812

Epoch: 5| Step: 7
Training loss: 1.9480518102645874
Validation loss: 1.9439268676183556

Epoch: 5| Step: 8
Training loss: 1.9268944263458252
Validation loss: 1.9185579617818196

Epoch: 5| Step: 9
Training loss: 1.6418250799179077
Validation loss: 1.9160221904836676

Epoch: 5| Step: 10
Training loss: 2.175797462463379
Validation loss: 1.943294685374024

Epoch: 249| Step: 0
Training loss: 2.2198219299316406
Validation loss: 1.9217110910723287

Epoch: 5| Step: 1
Training loss: 2.7090837955474854
Validation loss: 1.8972384955293389

Epoch: 5| Step: 2
Training loss: 1.85552978515625
Validation loss: 1.9262795986667756

Epoch: 5| Step: 3
Training loss: 1.9172073602676392
Validation loss: 1.9207406505461662

Epoch: 5| Step: 4
Training loss: 1.5727994441986084
Validation loss: 1.9188799960638887

Epoch: 5| Step: 5
Training loss: 1.5076568126678467
Validation loss: 1.9556908428028066

Epoch: 5| Step: 6
Training loss: 1.9993629455566406
Validation loss: 1.912463136898574

Epoch: 5| Step: 7
Training loss: 1.1747710704803467
Validation loss: 1.9514708352345291

Epoch: 5| Step: 8
Training loss: 1.3709076642990112
Validation loss: 1.9629068810452697

Epoch: 5| Step: 9
Training loss: 1.7898372411727905
Validation loss: 1.9467412335898286

Epoch: 5| Step: 10
Training loss: 1.5028202533721924
Validation loss: 1.954765994061706

Epoch: 250| Step: 0
Training loss: 1.5239274501800537
Validation loss: 1.938472592702476

Epoch: 5| Step: 1
Training loss: 1.5706843137741089
Validation loss: 1.9396127013749973

Epoch: 5| Step: 2
Training loss: 2.654250383377075
Validation loss: 1.9260397162488712

Epoch: 5| Step: 3
Training loss: 2.6603453159332275
Validation loss: 1.9325810363215785

Epoch: 5| Step: 4
Training loss: 1.9506973028182983
Validation loss: 1.9304620809452508

Epoch: 5| Step: 5
Training loss: 1.7445571422576904
Validation loss: 1.9266832746485227

Epoch: 5| Step: 6
Training loss: 1.3723069429397583
Validation loss: 1.902833923216789

Epoch: 5| Step: 7
Training loss: 1.4499386548995972
Validation loss: 1.9552249780265234

Epoch: 5| Step: 8
Training loss: 1.4513442516326904
Validation loss: 1.9487121220557921

Epoch: 5| Step: 9
Training loss: 1.1252028942108154
Validation loss: 1.9221727796780166

Epoch: 5| Step: 10
Training loss: 1.93191397190094
Validation loss: 1.898924804502918

Epoch: 251| Step: 0
Training loss: 2.17783784866333
Validation loss: 1.930800268726964

Epoch: 5| Step: 1
Training loss: 1.4340933561325073
Validation loss: 1.9113463894013436

Epoch: 5| Step: 2
Training loss: 1.6538279056549072
Validation loss: 1.9099257735795871

Epoch: 5| Step: 3
Training loss: 1.7907631397247314
Validation loss: 1.938658260530041

Epoch: 5| Step: 4
Training loss: 1.2108408212661743
Validation loss: 1.9357475747344315

Epoch: 5| Step: 5
Training loss: 1.9260276556015015
Validation loss: 1.9218047600920483

Epoch: 5| Step: 6
Training loss: 1.6476268768310547
Validation loss: 1.9237470703740274

Epoch: 5| Step: 7
Training loss: 2.127093553543091
Validation loss: 1.9043953482822706

Epoch: 5| Step: 8
Training loss: 1.3593339920043945
Validation loss: 1.8726777709940428

Epoch: 5| Step: 9
Training loss: 2.348083019256592
Validation loss: 1.9481568118577361

Epoch: 5| Step: 10
Training loss: 2.1744742393493652
Validation loss: 1.9238104012704664

Epoch: 252| Step: 0
Training loss: 1.3416800498962402
Validation loss: 1.904178951376228

Epoch: 5| Step: 1
Training loss: 1.2823067903518677
Validation loss: 1.8902048513453493

Epoch: 5| Step: 2
Training loss: 1.895917534828186
Validation loss: 1.9228459635088522

Epoch: 5| Step: 3
Training loss: 2.048842191696167
Validation loss: 1.959283512125733

Epoch: 5| Step: 4
Training loss: 1.9478174448013306
Validation loss: 1.9449178967424618

Epoch: 5| Step: 5
Training loss: 1.781896948814392
Validation loss: 1.940795398527576

Epoch: 5| Step: 6
Training loss: 2.0791475772857666
Validation loss: 1.9508863597787836

Epoch: 5| Step: 7
Training loss: 1.781963586807251
Validation loss: 1.9970535360356814

Epoch: 5| Step: 8
Training loss: 2.1960043907165527
Validation loss: 1.9671747069205008

Epoch: 5| Step: 9
Training loss: 1.7576024532318115
Validation loss: 1.9697763009737896

Epoch: 5| Step: 10
Training loss: 1.5439112186431885
Validation loss: 1.9499339160098825

Epoch: 253| Step: 0
Training loss: 1.2845121622085571
Validation loss: 1.92351471993231

Epoch: 5| Step: 1
Training loss: 1.7209465503692627
Validation loss: 1.93215226357983

Epoch: 5| Step: 2
Training loss: 1.8222224712371826
Validation loss: 1.9123797826869513

Epoch: 5| Step: 3
Training loss: 1.6469507217407227
Validation loss: 1.961383145342591

Epoch: 5| Step: 4
Training loss: 1.4319119453430176
Validation loss: 1.896242707006393

Epoch: 5| Step: 5
Training loss: 2.5167553424835205
Validation loss: 1.947445805354785

Epoch: 5| Step: 6
Training loss: 1.9806766510009766
Validation loss: 1.9451040170525993

Epoch: 5| Step: 7
Training loss: 2.1335768699645996
Validation loss: 1.884440952731717

Epoch: 5| Step: 8
Training loss: 1.6295236349105835
Validation loss: 1.9343100260662776

Epoch: 5| Step: 9
Training loss: 1.9376121759414673
Validation loss: 1.9198515786919543

Epoch: 5| Step: 10
Training loss: 1.3914759159088135
Validation loss: 1.9028308955571984

Epoch: 254| Step: 0
Training loss: 2.2494804859161377
Validation loss: 1.9362310517218806

Epoch: 5| Step: 1
Training loss: 1.6406726837158203
Validation loss: 1.8833384680491623

Epoch: 5| Step: 2
Training loss: 1.530476450920105
Validation loss: 1.915334979693095

Epoch: 5| Step: 3
Training loss: 2.1391761302948
Validation loss: 1.919740000078755

Epoch: 5| Step: 4
Training loss: 1.7153465747833252
Validation loss: 1.8728827430355934

Epoch: 5| Step: 5
Training loss: 1.938214898109436
Validation loss: 1.9159104683065926

Epoch: 5| Step: 6
Training loss: 1.577484130859375
Validation loss: 1.9010873481791506

Epoch: 5| Step: 7
Training loss: 1.8608224391937256
Validation loss: 1.923669340789959

Epoch: 5| Step: 8
Training loss: 1.58114492893219
Validation loss: 1.9035944310567712

Epoch: 5| Step: 9
Training loss: 1.4204970598220825
Validation loss: 1.9273081966625747

Epoch: 5| Step: 10
Training loss: 1.8071894645690918
Validation loss: 1.9209298984978789

Epoch: 255| Step: 0
Training loss: 2.0266835689544678
Validation loss: 1.9018395485416535

Epoch: 5| Step: 1
Training loss: 1.3873122930526733
Validation loss: 1.9113435335056757

Epoch: 5| Step: 2
Training loss: 1.0557507276535034
Validation loss: 1.9222054366142518

Epoch: 5| Step: 3
Training loss: 1.812645673751831
Validation loss: 1.9454242490953015

Epoch: 5| Step: 4
Training loss: 1.6843976974487305
Validation loss: 1.9511070866738596

Epoch: 5| Step: 5
Training loss: 1.4997278451919556
Validation loss: 1.9212244710614603

Epoch: 5| Step: 6
Training loss: 2.0505759716033936
Validation loss: 1.889143282367337

Epoch: 5| Step: 7
Training loss: 2.14237380027771
Validation loss: 1.912414828936259

Epoch: 5| Step: 8
Training loss: 1.9422963857650757
Validation loss: 1.8834685279477028

Epoch: 5| Step: 9
Training loss: 1.8657963275909424
Validation loss: 1.9270724378606325

Epoch: 5| Step: 10
Training loss: 2.1457359790802
Validation loss: 1.9115919336195915

Epoch: 256| Step: 0
Training loss: 1.8854995965957642
Validation loss: 1.9088450862515358

Epoch: 5| Step: 1
Training loss: 1.8803952932357788
Validation loss: 1.9182231400602607

Epoch: 5| Step: 2
Training loss: 1.800408124923706
Validation loss: 1.8894981671405096

Epoch: 5| Step: 3
Training loss: 1.2587436437606812
Validation loss: 1.9117518586497153

Epoch: 5| Step: 4
Training loss: 1.3788855075836182
Validation loss: 1.9312688894169305

Epoch: 5| Step: 5
Training loss: 1.8533328771591187
Validation loss: 1.9275579555060274

Epoch: 5| Step: 6
Training loss: 1.6062877178192139
Validation loss: 1.9098240931828816

Epoch: 5| Step: 7
Training loss: 2.283630847930908
Validation loss: 1.927510328190301

Epoch: 5| Step: 8
Training loss: 1.3898118734359741
Validation loss: 1.8749858922855829

Epoch: 5| Step: 9
Training loss: 1.9761664867401123
Validation loss: 1.9319802663659538

Epoch: 5| Step: 10
Training loss: 1.8745259046554565
Validation loss: 1.9024139681170065

Epoch: 257| Step: 0
Training loss: 1.9682775735855103
Validation loss: 1.933597171178428

Epoch: 5| Step: 1
Training loss: 2.0550408363342285
Validation loss: 1.9402747807964202

Epoch: 5| Step: 2
Training loss: 1.5054734945297241
Validation loss: 1.9184065441931448

Epoch: 5| Step: 3
Training loss: 1.6031137704849243
Validation loss: 1.887016107959132

Epoch: 5| Step: 4
Training loss: 1.809635877609253
Validation loss: 1.9142121576493787

Epoch: 5| Step: 5
Training loss: 1.6501373052597046
Validation loss: 1.9519188455356065

Epoch: 5| Step: 6
Training loss: 1.773377776145935
Validation loss: 1.9213989883340814

Epoch: 5| Step: 7
Training loss: 1.6852737665176392
Validation loss: 1.931656369598963

Epoch: 5| Step: 8
Training loss: 1.7871038913726807
Validation loss: 1.9228067680071759

Epoch: 5| Step: 9
Training loss: 1.8830363750457764
Validation loss: 1.9261807395565895

Epoch: 5| Step: 10
Training loss: 1.7398672103881836
Validation loss: 1.9260678547684864

Epoch: 258| Step: 0
Training loss: 1.8825228214263916
Validation loss: 1.926018625177363

Epoch: 5| Step: 1
Training loss: 1.8480952978134155
Validation loss: 1.9498373769944715

Epoch: 5| Step: 2
Training loss: 1.6141328811645508
Validation loss: 1.9432821491713166

Epoch: 5| Step: 3
Training loss: 1.644025444984436
Validation loss: 1.9454859828436246

Epoch: 5| Step: 4
Training loss: 1.9671642780303955
Validation loss: 1.8985295423897364

Epoch: 5| Step: 5
Training loss: 2.046408176422119
Validation loss: 1.9375090855424122

Epoch: 5| Step: 6
Training loss: 1.8221161365509033
Validation loss: 1.9414859382055139

Epoch: 5| Step: 7
Training loss: 1.840916633605957
Validation loss: 1.9259923363244662

Epoch: 5| Step: 8
Training loss: 1.4546366930007935
Validation loss: 1.9194303533082366

Epoch: 5| Step: 9
Training loss: 1.7518161535263062
Validation loss: 1.9192916911135438

Epoch: 5| Step: 10
Training loss: 1.501849889755249
Validation loss: 1.9089478215863627

Epoch: 259| Step: 0
Training loss: 1.3033065795898438
Validation loss: 1.9255329934499597

Epoch: 5| Step: 1
Training loss: 1.3517100811004639
Validation loss: 1.907890668479345

Epoch: 5| Step: 2
Training loss: 1.9889442920684814
Validation loss: 1.8797852839193037

Epoch: 5| Step: 3
Training loss: 2.597965717315674
Validation loss: 1.895068068658152

Epoch: 5| Step: 4
Training loss: 1.4586609601974487
Validation loss: 1.9017228259835193

Epoch: 5| Step: 5
Training loss: 1.091269612312317
Validation loss: 1.8941109795724191

Epoch: 5| Step: 6
Training loss: 1.616697072982788
Validation loss: 1.9019438015517367

Epoch: 5| Step: 7
Training loss: 2.162412166595459
Validation loss: 1.918505996786138

Epoch: 5| Step: 8
Training loss: 2.1768081188201904
Validation loss: 1.9355635412277714

Epoch: 5| Step: 9
Training loss: 1.429007649421692
Validation loss: 1.8993822349015104

Epoch: 5| Step: 10
Training loss: 1.9690157175064087
Validation loss: 1.9182323499392437

Epoch: 260| Step: 0
Training loss: 2.009542942047119
Validation loss: 1.919191159227843

Epoch: 5| Step: 1
Training loss: 1.5499210357666016
Validation loss: 1.9371178534723097

Epoch: 5| Step: 2
Training loss: 1.951297402381897
Validation loss: 1.937870612708471

Epoch: 5| Step: 3
Training loss: 1.7023636102676392
Validation loss: 1.9085871224762292

Epoch: 5| Step: 4
Training loss: 1.5030958652496338
Validation loss: 1.9371412902749994

Epoch: 5| Step: 5
Training loss: 1.7459672689437866
Validation loss: 1.9273179256787865

Epoch: 5| Step: 6
Training loss: 1.5142767429351807
Validation loss: 1.963878373945913

Epoch: 5| Step: 7
Training loss: 2.1636269092559814
Validation loss: 1.9573918414372269

Epoch: 5| Step: 8
Training loss: 1.6628646850585938
Validation loss: 1.9106404704432334

Epoch: 5| Step: 9
Training loss: 1.5039199590682983
Validation loss: 1.942710889283047

Epoch: 5| Step: 10
Training loss: 1.9255101680755615
Validation loss: 1.9461360605814124

Epoch: 261| Step: 0
Training loss: 1.3499424457550049
Validation loss: 1.9216657761604554

Epoch: 5| Step: 1
Training loss: 1.820937156677246
Validation loss: 1.9216901974011493

Epoch: 5| Step: 2
Training loss: 1.8472143411636353
Validation loss: 1.9147565877565773

Epoch: 5| Step: 3
Training loss: 2.0954556465148926
Validation loss: 1.9015627984077699

Epoch: 5| Step: 4
Training loss: 1.5710580348968506
Validation loss: 1.906890425630795

Epoch: 5| Step: 5
Training loss: 1.7774215936660767
Validation loss: 1.9049770729516142

Epoch: 5| Step: 6
Training loss: 2.0970232486724854
Validation loss: 1.9213446699162966

Epoch: 5| Step: 7
Training loss: 1.3217065334320068
Validation loss: 1.9024593368653329

Epoch: 5| Step: 8
Training loss: 1.7888062000274658
Validation loss: 1.8958222327693817

Epoch: 5| Step: 9
Training loss: 2.230393886566162
Validation loss: 1.8715494114865538

Epoch: 5| Step: 10
Training loss: 1.0930166244506836
Validation loss: 1.8958052537774528

Epoch: 262| Step: 0
Training loss: 1.371672511100769
Validation loss: 1.8969213578008837

Epoch: 5| Step: 1
Training loss: 1.856881856918335
Validation loss: 1.9107104821871685

Epoch: 5| Step: 2
Training loss: 1.7053226232528687
Validation loss: 1.8787898530242264

Epoch: 5| Step: 3
Training loss: 2.343900680541992
Validation loss: 1.9413097866119877

Epoch: 5| Step: 4
Training loss: 1.7462680339813232
Validation loss: 1.905177559903873

Epoch: 5| Step: 5
Training loss: 1.6180078983306885
Validation loss: 1.8953910989146079

Epoch: 5| Step: 6
Training loss: 1.1644270420074463
Validation loss: 1.9320021547296995

Epoch: 5| Step: 7
Training loss: 1.9634780883789062
Validation loss: 1.8996609641659645

Epoch: 5| Step: 8
Training loss: 2.021829128265381
Validation loss: 1.9252510532256095

Epoch: 5| Step: 9
Training loss: 1.058896780014038
Validation loss: 1.9350640466136317

Epoch: 5| Step: 10
Training loss: 2.278027296066284
Validation loss: 1.9346523259275703

Epoch: 263| Step: 0
Training loss: 1.6413490772247314
Validation loss: 1.9212202589998963

Epoch: 5| Step: 1
Training loss: 1.706517219543457
Validation loss: 1.916913510650717

Epoch: 5| Step: 2
Training loss: 1.45489501953125
Validation loss: 1.8935277180005146

Epoch: 5| Step: 3
Training loss: 1.4995174407958984
Validation loss: 1.936670587908837

Epoch: 5| Step: 4
Training loss: 2.300854444503784
Validation loss: 1.9341319004694622

Epoch: 5| Step: 5
Training loss: 1.393404245376587
Validation loss: 1.9224276517027168

Epoch: 5| Step: 6
Training loss: 1.3688489198684692
Validation loss: 1.880236159088791

Epoch: 5| Step: 7
Training loss: 2.0849528312683105
Validation loss: 1.923698163801624

Epoch: 5| Step: 8
Training loss: 1.6776840686798096
Validation loss: 1.9101147767036193

Epoch: 5| Step: 9
Training loss: 1.5718311071395874
Validation loss: 1.8839824866223078

Epoch: 5| Step: 10
Training loss: 2.1298959255218506
Validation loss: 1.8909070748154835

Epoch: 264| Step: 0
Training loss: 2.471426486968994
Validation loss: 1.90998371442159

Epoch: 5| Step: 1
Training loss: 1.6689205169677734
Validation loss: 1.8826937444748417

Epoch: 5| Step: 2
Training loss: 1.8100836277008057
Validation loss: 1.9138454070655249

Epoch: 5| Step: 3
Training loss: 2.022270679473877
Validation loss: 1.9029466503409929

Epoch: 5| Step: 4
Training loss: 1.239247441291809
Validation loss: 1.9194154867561914

Epoch: 5| Step: 5
Training loss: 1.7606818675994873
Validation loss: 1.8965734679211852

Epoch: 5| Step: 6
Training loss: 1.562212586402893
Validation loss: 1.9575971288065757

Epoch: 5| Step: 7
Training loss: 1.5592721700668335
Validation loss: 1.8992536631963586

Epoch: 5| Step: 8
Training loss: 1.6352450847625732
Validation loss: 1.9299958316228722

Epoch: 5| Step: 9
Training loss: 1.7579129934310913
Validation loss: 1.8931033072933074

Epoch: 5| Step: 10
Training loss: 1.6480207443237305
Validation loss: 1.9390890572660713

Epoch: 265| Step: 0
Training loss: 1.6770312786102295
Validation loss: 1.916065167355281

Epoch: 5| Step: 1
Training loss: 1.7619123458862305
Validation loss: 1.899673108131655

Epoch: 5| Step: 2
Training loss: 1.9836794137954712
Validation loss: 1.9205940282473

Epoch: 5| Step: 3
Training loss: 1.51264226436615
Validation loss: 1.907244618220996

Epoch: 5| Step: 4
Training loss: 1.8822768926620483
Validation loss: 1.8902963515250915

Epoch: 5| Step: 5
Training loss: 1.2957763671875
Validation loss: 1.89370757790022

Epoch: 5| Step: 6
Training loss: 2.4932262897491455
Validation loss: 1.9084054423916725

Epoch: 5| Step: 7
Training loss: 1.9559509754180908
Validation loss: 1.8574982086817424

Epoch: 5| Step: 8
Training loss: 1.0762956142425537
Validation loss: 1.9217006750004266

Epoch: 5| Step: 9
Training loss: 1.5144351720809937
Validation loss: 1.912692807054007

Epoch: 5| Step: 10
Training loss: 1.8959375619888306
Validation loss: 1.8976059754689534

Epoch: 266| Step: 0
Training loss: 1.418487787246704
Validation loss: 1.898418693132298

Epoch: 5| Step: 1
Training loss: 1.4751282930374146
Validation loss: 1.8497293533817414

Epoch: 5| Step: 2
Training loss: 1.6092755794525146
Validation loss: 1.9220309949690295

Epoch: 5| Step: 3
Training loss: 1.6424381732940674
Validation loss: 1.8914715743833972

Epoch: 5| Step: 4
Training loss: 1.7750142812728882
Validation loss: 1.8739958963086527

Epoch: 5| Step: 5
Training loss: 1.4531621932983398
Validation loss: 1.8695619478020618

Epoch: 5| Step: 6
Training loss: 1.7906147241592407
Validation loss: 1.9118590995829592

Epoch: 5| Step: 7
Training loss: 1.5014766454696655
Validation loss: 1.8827422652193295

Epoch: 5| Step: 8
Training loss: 2.0293214321136475
Validation loss: 1.8818822958136117

Epoch: 5| Step: 9
Training loss: 2.609261989593506
Validation loss: 1.8900408232083885

Epoch: 5| Step: 10
Training loss: 1.5076589584350586
Validation loss: 1.8977886669097408

Epoch: 267| Step: 0
Training loss: 1.492775797843933
Validation loss: 1.8910837147825508

Epoch: 5| Step: 1
Training loss: 2.0289740562438965
Validation loss: 1.8939631215987667

Epoch: 5| Step: 2
Training loss: 1.9928162097930908
Validation loss: 1.8785348605084162

Epoch: 5| Step: 3
Training loss: 1.491309404373169
Validation loss: 1.9172433678821852

Epoch: 5| Step: 4
Training loss: 1.4496394395828247
Validation loss: 1.887334076307153

Epoch: 5| Step: 5
Training loss: 1.6889435052871704
Validation loss: 1.9233707228014547

Epoch: 5| Step: 6
Training loss: 1.6658570766448975
Validation loss: 1.9110459358461442

Epoch: 5| Step: 7
Training loss: 1.2999004125595093
Validation loss: 1.8937375084046395

Epoch: 5| Step: 8
Training loss: 2.1510186195373535
Validation loss: 1.8957903885072278

Epoch: 5| Step: 9
Training loss: 1.8354572057724
Validation loss: 1.9399682783311414

Epoch: 5| Step: 10
Training loss: 1.6376864910125732
Validation loss: 1.9162539512880388

Epoch: 268| Step: 0
Training loss: 2.014273166656494
Validation loss: 1.9218413932349092

Epoch: 5| Step: 1
Training loss: 1.76006281375885
Validation loss: 1.9071633482492099

Epoch: 5| Step: 2
Training loss: 2.078275442123413
Validation loss: 1.9437392988512594

Epoch: 5| Step: 3
Training loss: 1.8444204330444336
Validation loss: 1.918847712137366

Epoch: 5| Step: 4
Training loss: 1.9372695684432983
Validation loss: 1.9487807314882997

Epoch: 5| Step: 5
Training loss: 1.0314851999282837
Validation loss: 1.9521918835178498

Epoch: 5| Step: 6
Training loss: 1.5580906867980957
Validation loss: 1.949667546056932

Epoch: 5| Step: 7
Training loss: 2.0512566566467285
Validation loss: 1.930819348622394

Epoch: 5| Step: 8
Training loss: 1.6556167602539062
Validation loss: 1.9553096678949171

Epoch: 5| Step: 9
Training loss: 1.2898719310760498
Validation loss: 1.9557372549528718

Epoch: 5| Step: 10
Training loss: 1.8074601888656616
Validation loss: 1.9298161255416049

Epoch: 269| Step: 0
Training loss: 1.854856252670288
Validation loss: 1.8961650069041918

Epoch: 5| Step: 1
Training loss: 1.8315858840942383
Validation loss: 1.87844342313787

Epoch: 5| Step: 2
Training loss: 0.9269657135009766
Validation loss: 1.8853997133111442

Epoch: 5| Step: 3
Training loss: 1.4415555000305176
Validation loss: 1.8872916621546592

Epoch: 5| Step: 4
Training loss: 1.8873207569122314
Validation loss: 1.9131186995455014

Epoch: 5| Step: 5
Training loss: 1.899935007095337
Validation loss: 1.8997597784124396

Epoch: 5| Step: 6
Training loss: 1.5741852521896362
Validation loss: 1.8702471307528916

Epoch: 5| Step: 7
Training loss: 1.6227529048919678
Validation loss: 1.8965508796835457

Epoch: 5| Step: 8
Training loss: 1.7007505893707275
Validation loss: 1.8859969531336138

Epoch: 5| Step: 9
Training loss: 2.0252485275268555
Validation loss: 1.8847396425021592

Epoch: 5| Step: 10
Training loss: 2.286497116088867
Validation loss: 1.8470261942955755

Epoch: 270| Step: 0
Training loss: 1.5565286874771118
Validation loss: 1.8911522614058627

Epoch: 5| Step: 1
Training loss: 1.727820634841919
Validation loss: 1.91614152795525

Epoch: 5| Step: 2
Training loss: 1.353506088256836
Validation loss: 1.94239378488192

Epoch: 5| Step: 3
Training loss: 1.4045491218566895
Validation loss: 1.895269384948156

Epoch: 5| Step: 4
Training loss: 1.677311897277832
Validation loss: 1.9301042838763165

Epoch: 5| Step: 5
Training loss: 2.2910571098327637
Validation loss: 1.9207338389529978

Epoch: 5| Step: 6
Training loss: 2.3616671562194824
Validation loss: 1.9054489648470314

Epoch: 5| Step: 7
Training loss: 1.603609323501587
Validation loss: 1.9327281264848606

Epoch: 5| Step: 8
Training loss: 1.3378386497497559
Validation loss: 1.9268137588295886

Epoch: 5| Step: 9
Training loss: 1.2751010656356812
Validation loss: 1.925278725162629

Epoch: 5| Step: 10
Training loss: 1.9757459163665771
Validation loss: 1.8985005501777894

Epoch: 271| Step: 0
Training loss: 1.9784494638442993
Validation loss: 1.928005797888643

Epoch: 5| Step: 1
Training loss: 2.0189316272735596
Validation loss: 1.9558000436393164

Epoch: 5| Step: 2
Training loss: 1.6898767948150635
Validation loss: 1.9619438007313719

Epoch: 5| Step: 3
Training loss: 1.5663118362426758
Validation loss: 1.9310725196715324

Epoch: 5| Step: 4
Training loss: 1.38115394115448
Validation loss: 1.9313942283712409

Epoch: 5| Step: 5
Training loss: 1.8483846187591553
Validation loss: 1.9171753365506408

Epoch: 5| Step: 6
Training loss: 1.7923011779785156
Validation loss: 1.909683786412721

Epoch: 5| Step: 7
Training loss: 1.2577625513076782
Validation loss: 1.940129888954983

Epoch: 5| Step: 8
Training loss: 1.5749900341033936
Validation loss: 1.9058947922081075

Epoch: 5| Step: 9
Training loss: 1.4562851190567017
Validation loss: 1.9310345188263924

Epoch: 5| Step: 10
Training loss: 2.2029011249542236
Validation loss: 1.9187748393704813

Epoch: 272| Step: 0
Training loss: 1.6690088510513306
Validation loss: 1.9176309313825382

Epoch: 5| Step: 1
Training loss: 1.5362801551818848
Validation loss: 1.918519796863679

Epoch: 5| Step: 2
Training loss: 1.4901916980743408
Validation loss: 1.8828214778695056

Epoch: 5| Step: 3
Training loss: 1.9340530633926392
Validation loss: 1.9128266021769533

Epoch: 5| Step: 4
Training loss: 1.7111012935638428
Validation loss: 1.9272695484981741

Epoch: 5| Step: 5
Training loss: 1.7582212686538696
Validation loss: 1.8813469409942627

Epoch: 5| Step: 6
Training loss: 1.9181846380233765
Validation loss: 1.895059424061929

Epoch: 5| Step: 7
Training loss: 2.117154598236084
Validation loss: 1.8975644547452208

Epoch: 5| Step: 8
Training loss: 1.396909475326538
Validation loss: 1.873181870547674

Epoch: 5| Step: 9
Training loss: 1.5537054538726807
Validation loss: 1.8958037232839933

Epoch: 5| Step: 10
Training loss: 1.9246760606765747
Validation loss: 1.8991730738711614

Epoch: 273| Step: 0
Training loss: 1.5569744110107422
Validation loss: 1.8629947554680608

Epoch: 5| Step: 1
Training loss: 1.4185469150543213
Validation loss: 1.8881885185036609

Epoch: 5| Step: 2
Training loss: 0.9045878648757935
Validation loss: 1.9018916442830076

Epoch: 5| Step: 3
Training loss: 2.239326000213623
Validation loss: 1.8667346713363484

Epoch: 5| Step: 4
Training loss: 1.3099743127822876
Validation loss: 1.9200039499549455

Epoch: 5| Step: 5
Training loss: 1.7297557592391968
Validation loss: 1.8769889121414514

Epoch: 5| Step: 6
Training loss: 1.4004114866256714
Validation loss: 1.894473465540076

Epoch: 5| Step: 7
Training loss: 2.0170865058898926
Validation loss: 1.8933692555273733

Epoch: 5| Step: 8
Training loss: 1.4476349353790283
Validation loss: 1.9266547451737106

Epoch: 5| Step: 9
Training loss: 2.358814239501953
Validation loss: 1.9058468393100205

Epoch: 5| Step: 10
Training loss: 2.3015873432159424
Validation loss: 1.8907710172796761

Epoch: 274| Step: 0
Training loss: 1.9031028747558594
Validation loss: 1.8745949601614347

Epoch: 5| Step: 1
Training loss: 1.794107437133789
Validation loss: 1.8889652041978733

Epoch: 5| Step: 2
Training loss: 1.8106911182403564
Validation loss: 1.8861593636133338

Epoch: 5| Step: 3
Training loss: 1.531638741493225
Validation loss: 1.9369872231637277

Epoch: 5| Step: 4
Training loss: 0.9634159207344055
Validation loss: 1.9415578406344178

Epoch: 5| Step: 5
Training loss: 2.0197274684906006
Validation loss: 1.9167937412056872

Epoch: 5| Step: 6
Training loss: 1.848675012588501
Validation loss: 1.909179990009595

Epoch: 5| Step: 7
Training loss: 1.670379638671875
Validation loss: 1.887406264581988

Epoch: 5| Step: 8
Training loss: 1.587066411972046
Validation loss: 1.8930105445205525

Epoch: 5| Step: 9
Training loss: 1.9975227117538452
Validation loss: 1.8953486898893952

Epoch: 5| Step: 10
Training loss: 1.6665922403335571
Validation loss: 1.9090823576014528

Epoch: 275| Step: 0
Training loss: 2.655961513519287
Validation loss: 1.894471832500991

Epoch: 5| Step: 1
Training loss: 2.041703939437866
Validation loss: 1.922161171513219

Epoch: 5| Step: 2
Training loss: 1.430233359336853
Validation loss: 1.891125968707505

Epoch: 5| Step: 3
Training loss: 1.29386305809021
Validation loss: 1.8824067243965723

Epoch: 5| Step: 4
Training loss: 1.6153110265731812
Validation loss: 1.8817241461046281

Epoch: 5| Step: 5
Training loss: 1.2383801937103271
Validation loss: 1.875189632497808

Epoch: 5| Step: 6
Training loss: 1.7027183771133423
Validation loss: 1.8792200447410665

Epoch: 5| Step: 7
Training loss: 2.1480510234832764
Validation loss: 1.8782737088459793

Epoch: 5| Step: 8
Training loss: 1.6952800750732422
Validation loss: 1.8594658784968878

Epoch: 5| Step: 9
Training loss: 1.1673799753189087
Validation loss: 1.924528250130274

Epoch: 5| Step: 10
Training loss: 1.716538429260254
Validation loss: 1.8858972864766275

Epoch: 276| Step: 0
Training loss: 1.788901686668396
Validation loss: 1.8792679886664114

Epoch: 5| Step: 1
Training loss: 1.679060697555542
Validation loss: 1.8825905502483409

Epoch: 5| Step: 2
Training loss: 1.8099749088287354
Validation loss: 1.9074475265318347

Epoch: 5| Step: 3
Training loss: 1.4739938974380493
Validation loss: 1.9052524797378048

Epoch: 5| Step: 4
Training loss: 0.9329603314399719
Validation loss: 1.9008455289307462

Epoch: 5| Step: 5
Training loss: 1.6745315790176392
Validation loss: 1.9138935753094253

Epoch: 5| Step: 6
Training loss: 2.200438976287842
Validation loss: 1.8726214631911247

Epoch: 5| Step: 7
Training loss: 1.6773093938827515
Validation loss: 1.8958007968882078

Epoch: 5| Step: 8
Training loss: 2.3139240741729736
Validation loss: 1.883698977449889

Epoch: 5| Step: 9
Training loss: 1.6427093744277954
Validation loss: 1.9017436837637296

Epoch: 5| Step: 10
Training loss: 1.3987101316452026
Validation loss: 1.9181086491512995

Epoch: 277| Step: 0
Training loss: 2.023857355117798
Validation loss: 1.8994252374095302

Epoch: 5| Step: 1
Training loss: 1.832672119140625
Validation loss: 1.9174953635020922

Epoch: 5| Step: 2
Training loss: 1.0707099437713623
Validation loss: 1.9460081913137948

Epoch: 5| Step: 3
Training loss: 1.5072352886199951
Validation loss: 1.8784820392567625

Epoch: 5| Step: 4
Training loss: 2.495051622390747
Validation loss: 1.8910161525972429

Epoch: 5| Step: 5
Training loss: 1.5362924337387085
Validation loss: 1.8690232589680662

Epoch: 5| Step: 6
Training loss: 1.2525275945663452
Validation loss: 1.8941874593816779

Epoch: 5| Step: 7
Training loss: 1.669979453086853
Validation loss: 1.883171203315899

Epoch: 5| Step: 8
Training loss: 1.7374988794326782
Validation loss: 1.9025977990960563

Epoch: 5| Step: 9
Training loss: 2.0821564197540283
Validation loss: 1.8539562097159765

Epoch: 5| Step: 10
Training loss: 1.060215711593628
Validation loss: 1.8763629031437699

Epoch: 278| Step: 0
Training loss: 1.7939783334732056
Validation loss: 1.8725925953157487

Epoch: 5| Step: 1
Training loss: 1.4802266359329224
Validation loss: 1.9072881488389866

Epoch: 5| Step: 2
Training loss: 1.2112147808074951
Validation loss: 1.8983297296749648

Epoch: 5| Step: 3
Training loss: 1.6213973760604858
Validation loss: 1.866845787212413

Epoch: 5| Step: 4
Training loss: 1.5605840682983398
Validation loss: 1.8833516823348178

Epoch: 5| Step: 5
Training loss: 2.0680932998657227
Validation loss: 1.8667747064303326

Epoch: 5| Step: 6
Training loss: 2.169100522994995
Validation loss: 1.8141781091690063

Epoch: 5| Step: 7
Training loss: 1.7925684452056885
Validation loss: 1.887063600683725

Epoch: 5| Step: 8
Training loss: 1.5510801076889038
Validation loss: 1.8616079656026696

Epoch: 5| Step: 9
Training loss: 1.6880238056182861
Validation loss: 1.8493316455553936

Epoch: 5| Step: 10
Training loss: 1.9975769519805908
Validation loss: 1.8832805156707764

Epoch: 279| Step: 0
Training loss: 2.0609424114227295
Validation loss: 1.8816145748220465

Epoch: 5| Step: 1
Training loss: 1.133786916732788
Validation loss: 1.8679108337689472

Epoch: 5| Step: 2
Training loss: 1.371646523475647
Validation loss: 1.8725770288898098

Epoch: 5| Step: 3
Training loss: 1.598154067993164
Validation loss: 1.8710673624469387

Epoch: 5| Step: 4
Training loss: 2.0851354598999023
Validation loss: 1.9080454482827136

Epoch: 5| Step: 5
Training loss: 2.6951682567596436
Validation loss: 1.878246243282031

Epoch: 5| Step: 6
Training loss: 1.5362924337387085
Validation loss: 1.9106825590133667

Epoch: 5| Step: 7
Training loss: 1.3159624338150024
Validation loss: 1.9602267216610652

Epoch: 5| Step: 8
Training loss: 1.2101879119873047
Validation loss: 1.9448872702096098

Epoch: 5| Step: 9
Training loss: 1.5876939296722412
Validation loss: 1.9367732104434763

Epoch: 5| Step: 10
Training loss: 2.0805580615997314
Validation loss: 1.938590193307528

Epoch: 280| Step: 0
Training loss: 1.2066872119903564
Validation loss: 1.9157417064071984

Epoch: 5| Step: 1
Training loss: 1.7786058187484741
Validation loss: 1.8871823856907506

Epoch: 5| Step: 2
Training loss: 1.9628499746322632
Validation loss: 1.9480636094206123

Epoch: 5| Step: 3
Training loss: 1.6200844049453735
Validation loss: 1.863737589569502

Epoch: 5| Step: 4
Training loss: 1.80184805393219
Validation loss: 1.8620001000742759

Epoch: 5| Step: 5
Training loss: 1.7738511562347412
Validation loss: 1.9094712862404444

Epoch: 5| Step: 6
Training loss: 1.8660770654678345
Validation loss: 1.838609194242826

Epoch: 5| Step: 7
Training loss: 1.861853003501892
Validation loss: 1.9105287956935104

Epoch: 5| Step: 8
Training loss: 0.7325514554977417
Validation loss: 1.8757112282578663

Epoch: 5| Step: 9
Training loss: 2.1631553173065186
Validation loss: 1.8591908485658708

Epoch: 5| Step: 10
Training loss: 1.814988613128662
Validation loss: 1.877142257587884

Epoch: 281| Step: 0
Training loss: 1.9569041728973389
Validation loss: 1.851024543085406

Epoch: 5| Step: 1
Training loss: 1.5914291143417358
Validation loss: 1.8868170271637619

Epoch: 5| Step: 2
Training loss: 1.7861286401748657
Validation loss: 1.8388222058614094

Epoch: 5| Step: 3
Training loss: 2.044574737548828
Validation loss: 1.864385981713572

Epoch: 5| Step: 4
Training loss: 1.204827070236206
Validation loss: 1.9101455416730655

Epoch: 5| Step: 5
Training loss: 1.826279878616333
Validation loss: 1.8660702000382126

Epoch: 5| Step: 6
Training loss: 1.7635962963104248
Validation loss: 1.8960385143115956

Epoch: 5| Step: 7
Training loss: 1.6466575860977173
Validation loss: 1.8598110534811532

Epoch: 5| Step: 8
Training loss: 1.6674644947052002
Validation loss: 1.8641118298294723

Epoch: 5| Step: 9
Training loss: 1.1130750179290771
Validation loss: 1.9168022012197843

Epoch: 5| Step: 10
Training loss: 1.6997640132904053
Validation loss: 1.9261007770415275

Epoch: 282| Step: 0
Training loss: 1.317211627960205
Validation loss: 1.9046608055791547

Epoch: 5| Step: 1
Training loss: 0.9286440014839172
Validation loss: 1.9021558069413709

Epoch: 5| Step: 2
Training loss: 1.4152369499206543
Validation loss: 1.8739868671663347

Epoch: 5| Step: 3
Training loss: 1.96023428440094
Validation loss: 1.8778758292557092

Epoch: 5| Step: 4
Training loss: 1.2539798021316528
Validation loss: 1.892330910569878

Epoch: 5| Step: 5
Training loss: 2.3402247428894043
Validation loss: 1.9028681221828665

Epoch: 5| Step: 6
Training loss: 2.3792243003845215
Validation loss: 1.8627094684108612

Epoch: 5| Step: 7
Training loss: 1.748231291770935
Validation loss: 1.9342744363251554

Epoch: 5| Step: 8
Training loss: 1.6146888732910156
Validation loss: 1.892971751510456

Epoch: 5| Step: 9
Training loss: 2.1248066425323486
Validation loss: 1.8975886990947108

Epoch: 5| Step: 10
Training loss: 1.306792974472046
Validation loss: 1.9114969148430774

Epoch: 283| Step: 0
Training loss: 1.6025021076202393
Validation loss: 1.910114626730642

Epoch: 5| Step: 1
Training loss: 0.8916055560112
Validation loss: 1.9139805762998519

Epoch: 5| Step: 2
Training loss: 1.3406710624694824
Validation loss: 1.9053655542353147

Epoch: 5| Step: 3
Training loss: 1.6595256328582764
Validation loss: 1.8694982490231913

Epoch: 5| Step: 4
Training loss: 2.1119956970214844
Validation loss: 1.895798833139481

Epoch: 5| Step: 5
Training loss: 1.764883041381836
Validation loss: 1.913695954507397

Epoch: 5| Step: 6
Training loss: 2.0104286670684814
Validation loss: 1.8522035332136257

Epoch: 5| Step: 7
Training loss: 1.4723411798477173
Validation loss: 1.877991960894677

Epoch: 5| Step: 8
Training loss: 2.242278575897217
Validation loss: 1.9091668077694472

Epoch: 5| Step: 9
Training loss: 1.7977691888809204
Validation loss: 1.9241837327198317

Epoch: 5| Step: 10
Training loss: 1.4165974855422974
Validation loss: 1.8745045879835724

Epoch: 284| Step: 0
Training loss: 1.8200149536132812
Validation loss: 1.8689985467541603

Epoch: 5| Step: 1
Training loss: 1.1739566326141357
Validation loss: 1.8399002500759658

Epoch: 5| Step: 2
Training loss: 2.1136276721954346
Validation loss: 1.883145829682709

Epoch: 5| Step: 3
Training loss: 1.8277677297592163
Validation loss: 1.9057165140746741

Epoch: 5| Step: 4
Training loss: 1.6573879718780518
Validation loss: 1.8881933625026415

Epoch: 5| Step: 5
Training loss: 1.9150218963623047
Validation loss: 1.8873780145440051

Epoch: 5| Step: 6
Training loss: 1.6338762044906616
Validation loss: 1.8525273953714678

Epoch: 5| Step: 7
Training loss: 1.4670331478118896
Validation loss: 1.889484941318471

Epoch: 5| Step: 8
Training loss: 1.2857109308242798
Validation loss: 1.8784998770683043

Epoch: 5| Step: 9
Training loss: 1.4661023616790771
Validation loss: 1.9179125549972698

Epoch: 5| Step: 10
Training loss: 1.8655672073364258
Validation loss: 1.8951821660482755

Epoch: 285| Step: 0
Training loss: 1.9940261840820312
Validation loss: 1.8707844570118894

Epoch: 5| Step: 1
Training loss: 1.1296910047531128
Validation loss: 1.8689699788247385

Epoch: 5| Step: 2
Training loss: 1.785588264465332
Validation loss: 1.883230575951197

Epoch: 5| Step: 3
Training loss: 1.3931033611297607
Validation loss: 1.8590779945414553

Epoch: 5| Step: 4
Training loss: 1.4067949056625366
Validation loss: 1.852809532996147

Epoch: 5| Step: 5
Training loss: 1.8435726165771484
Validation loss: 1.838465562430761

Epoch: 5| Step: 6
Training loss: 1.5296180248260498
Validation loss: 1.8774900513310586

Epoch: 5| Step: 7
Training loss: 2.1695053577423096
Validation loss: 1.8438450187765143

Epoch: 5| Step: 8
Training loss: 1.7839972972869873
Validation loss: 1.8845315223099084

Epoch: 5| Step: 9
Training loss: 1.4322800636291504
Validation loss: 1.8708785105777044

Epoch: 5| Step: 10
Training loss: 1.552947998046875
Validation loss: 1.8641782063309864

Epoch: 286| Step: 0
Training loss: 1.8658685684204102
Validation loss: 1.8611910266260947

Epoch: 5| Step: 1
Training loss: 1.6483516693115234
Validation loss: 1.868205544769123

Epoch: 5| Step: 2
Training loss: 1.9481315612792969
Validation loss: 1.8471742573604788

Epoch: 5| Step: 3
Training loss: 1.4525659084320068
Validation loss: 1.905963740041179

Epoch: 5| Step: 4
Training loss: 1.2389295101165771
Validation loss: 1.915537008675196

Epoch: 5| Step: 5
Training loss: 1.9245761632919312
Validation loss: 1.8582333659613004

Epoch: 5| Step: 6
Training loss: 1.3733950853347778
Validation loss: 1.8643915730137979

Epoch: 5| Step: 7
Training loss: 1.797228217124939
Validation loss: 1.8943476946123186

Epoch: 5| Step: 8
Training loss: 1.207118272781372
Validation loss: 1.8709614610159269

Epoch: 5| Step: 9
Training loss: 1.920845627784729
Validation loss: 1.9011086840783396

Epoch: 5| Step: 10
Training loss: 1.7891087532043457
Validation loss: 1.876406382488948

Epoch: 287| Step: 0
Training loss: 1.4562647342681885
Validation loss: 1.90243822784834

Epoch: 5| Step: 1
Training loss: 2.1619009971618652
Validation loss: 1.9100081407895653

Epoch: 5| Step: 2
Training loss: 1.5422780513763428
Validation loss: 1.878535548845927

Epoch: 5| Step: 3
Training loss: 1.456813097000122
Validation loss: 1.9082779679247128

Epoch: 5| Step: 4
Training loss: 1.8023351430892944
Validation loss: 1.9110926761422107

Epoch: 5| Step: 5
Training loss: 1.764012098312378
Validation loss: 1.9132954638491395

Epoch: 5| Step: 6
Training loss: 1.1825811862945557
Validation loss: 1.8853188355763753

Epoch: 5| Step: 7
Training loss: 1.5501339435577393
Validation loss: 1.8896655139102732

Epoch: 5| Step: 8
Training loss: 1.7155765295028687
Validation loss: 1.9194359061538533

Epoch: 5| Step: 9
Training loss: 2.0494396686553955
Validation loss: 1.9151897814966017

Epoch: 5| Step: 10
Training loss: 1.4620091915130615
Validation loss: 1.926305822146836

Epoch: 288| Step: 0
Training loss: 1.4968574047088623
Validation loss: 1.910425006702382

Epoch: 5| Step: 1
Training loss: 2.23862886428833
Validation loss: 1.9312187138424124

Epoch: 5| Step: 2
Training loss: 1.6342672109603882
Validation loss: 1.9400358533346524

Epoch: 5| Step: 3
Training loss: 1.0531307458877563
Validation loss: 1.8941386335639543

Epoch: 5| Step: 4
Training loss: 1.9790712594985962
Validation loss: 1.9013201600761824

Epoch: 5| Step: 5
Training loss: 1.4770300388336182
Validation loss: 1.9363542654181038

Epoch: 5| Step: 6
Training loss: 1.7170495986938477
Validation loss: 1.8967032599192795

Epoch: 5| Step: 7
Training loss: 1.3710647821426392
Validation loss: 1.8880237199926888

Epoch: 5| Step: 8
Training loss: 1.8574788570404053
Validation loss: 1.8691696479756346

Epoch: 5| Step: 9
Training loss: 2.1640982627868652
Validation loss: 1.8588860919398646

Epoch: 5| Step: 10
Training loss: 1.4810703992843628
Validation loss: 1.8566275694036996

Epoch: 289| Step: 0
Training loss: 1.5158607959747314
Validation loss: 1.8752049528142458

Epoch: 5| Step: 1
Training loss: 1.586126685142517
Validation loss: 1.8783813471435218

Epoch: 5| Step: 2
Training loss: 1.0058412551879883
Validation loss: 1.8884649584370274

Epoch: 5| Step: 3
Training loss: 1.6165056228637695
Validation loss: 1.8451932040593957

Epoch: 5| Step: 4
Training loss: 1.790655493736267
Validation loss: 1.8922829474172285

Epoch: 5| Step: 5
Training loss: 1.7118616104125977
Validation loss: 1.855156934389504

Epoch: 5| Step: 6
Training loss: 2.3261959552764893
Validation loss: 1.8760823665126678

Epoch: 5| Step: 7
Training loss: 1.2083511352539062
Validation loss: 1.9039061313034387

Epoch: 5| Step: 8
Training loss: 1.3232136964797974
Validation loss: 1.8857669150957497

Epoch: 5| Step: 9
Training loss: 2.362766742706299
Validation loss: 1.8888690317830732

Epoch: 5| Step: 10
Training loss: 1.6554774045944214
Validation loss: 1.9238704237886655

Epoch: 290| Step: 0
Training loss: 1.655249834060669
Validation loss: 1.8819754623597669

Epoch: 5| Step: 1
Training loss: 1.5289947986602783
Validation loss: 1.8831061560620543

Epoch: 5| Step: 2
Training loss: 1.9581677913665771
Validation loss: 1.8913308151306645

Epoch: 5| Step: 3
Training loss: 1.5631427764892578
Validation loss: 1.9449269079392957

Epoch: 5| Step: 4
Training loss: 2.2140350341796875
Validation loss: 1.9148253471620622

Epoch: 5| Step: 5
Training loss: 1.7989635467529297
Validation loss: 1.8941868030896751

Epoch: 5| Step: 6
Training loss: 1.5998237133026123
Validation loss: 1.870621972186591

Epoch: 5| Step: 7
Training loss: 1.2710773944854736
Validation loss: 1.877835012251331

Epoch: 5| Step: 8
Training loss: 1.4064702987670898
Validation loss: 1.846119547402987

Epoch: 5| Step: 9
Training loss: 1.5357224941253662
Validation loss: 1.8885969602933494

Epoch: 5| Step: 10
Training loss: 1.4499880075454712
Validation loss: 1.871915073804958

Epoch: 291| Step: 0
Training loss: 1.8008229732513428
Validation loss: 1.8625547642348914

Epoch: 5| Step: 1
Training loss: 0.9132954478263855
Validation loss: 1.8548847834269206

Epoch: 5| Step: 2
Training loss: 2.0939249992370605
Validation loss: 1.880843532982693

Epoch: 5| Step: 3
Training loss: 0.9780709147453308
Validation loss: 1.8783393662462953

Epoch: 5| Step: 4
Training loss: 1.394744634628296
Validation loss: 1.8586644459796209

Epoch: 5| Step: 5
Training loss: 1.3615838289260864
Validation loss: 1.8833222619948848

Epoch: 5| Step: 6
Training loss: 1.9838511943817139
Validation loss: 1.9059697453693678

Epoch: 5| Step: 7
Training loss: 1.8739986419677734
Validation loss: 1.8963239987691243

Epoch: 5| Step: 8
Training loss: 1.9430500268936157
Validation loss: 1.83209817512061

Epoch: 5| Step: 9
Training loss: 1.7131836414337158
Validation loss: 1.8749191479016376

Epoch: 5| Step: 10
Training loss: 1.9179819822311401
Validation loss: 1.8756345292573333

Epoch: 292| Step: 0
Training loss: 1.70244562625885
Validation loss: 1.8930234229692848

Epoch: 5| Step: 1
Training loss: 0.980765700340271
Validation loss: 1.9515735026328795

Epoch: 5| Step: 2
Training loss: 1.4111908674240112
Validation loss: 1.9074939348364388

Epoch: 5| Step: 3
Training loss: 1.9184001684188843
Validation loss: 1.879699855722407

Epoch: 5| Step: 4
Training loss: 1.4338394403457642
Validation loss: 1.8769900414251512

Epoch: 5| Step: 5
Training loss: 1.4963290691375732
Validation loss: 1.8773618641720022

Epoch: 5| Step: 6
Training loss: 1.5036455392837524
Validation loss: 1.8745999695152364

Epoch: 5| Step: 7
Training loss: 2.317391872406006
Validation loss: 1.9042091933629846

Epoch: 5| Step: 8
Training loss: 1.736424207687378
Validation loss: 1.889671637165931

Epoch: 5| Step: 9
Training loss: 1.3309686183929443
Validation loss: 1.8949248406194872

Epoch: 5| Step: 10
Training loss: 2.0391101837158203
Validation loss: 1.8707854824681436

Epoch: 293| Step: 0
Training loss: 1.6410646438598633
Validation loss: 1.9046412642284105

Epoch: 5| Step: 1
Training loss: 2.102168083190918
Validation loss: 1.9158198269464637

Epoch: 5| Step: 2
Training loss: 2.0794875621795654
Validation loss: 1.9144832793102469

Epoch: 5| Step: 3
Training loss: 1.581976294517517
Validation loss: 1.9042852617079211

Epoch: 5| Step: 4
Training loss: 1.6163088083267212
Validation loss: 1.872806490108531

Epoch: 5| Step: 5
Training loss: 1.3536427021026611
Validation loss: 1.893550037055887

Epoch: 5| Step: 6
Training loss: 1.372768759727478
Validation loss: 1.928932753942346

Epoch: 5| Step: 7
Training loss: 1.2203601598739624
Validation loss: 1.8578920364379883

Epoch: 5| Step: 8
Training loss: 1.4529664516448975
Validation loss: 1.9060294012869559

Epoch: 5| Step: 9
Training loss: 1.7322784662246704
Validation loss: 1.8756161146266486

Epoch: 5| Step: 10
Training loss: 1.5381245613098145
Validation loss: 1.8697201487838582

Epoch: 294| Step: 0
Training loss: 1.9505077600479126
Validation loss: 1.878559043330531

Epoch: 5| Step: 1
Training loss: 0.8656045198440552
Validation loss: 1.8791733070086407

Epoch: 5| Step: 2
Training loss: 1.6438019275665283
Validation loss: 1.8914751198983961

Epoch: 5| Step: 3
Training loss: 1.6086410284042358
Validation loss: 1.8253701169003722

Epoch: 5| Step: 4
Training loss: 1.7707269191741943
Validation loss: 1.8653925759817964

Epoch: 5| Step: 5
Training loss: 1.5234959125518799
Validation loss: 1.8671550314913514

Epoch: 5| Step: 6
Training loss: 1.4886215925216675
Validation loss: 1.8824358614542152

Epoch: 5| Step: 7
Training loss: 1.92135488986969
Validation loss: 1.8315748527485838

Epoch: 5| Step: 8
Training loss: 1.7435791492462158
Validation loss: 1.8758548446880874

Epoch: 5| Step: 9
Training loss: 1.7592862844467163
Validation loss: 1.869810442770681

Epoch: 5| Step: 10
Training loss: 1.7619675397872925
Validation loss: 1.8589389721552532

Epoch: 295| Step: 0
Training loss: 1.7234302759170532
Validation loss: 1.858304540316264

Epoch: 5| Step: 1
Training loss: 1.5290782451629639
Validation loss: 1.8417581742809666

Epoch: 5| Step: 2
Training loss: 1.225935935974121
Validation loss: 1.8469262943472913

Epoch: 5| Step: 3
Training loss: 1.844416856765747
Validation loss: 1.8660246300440964

Epoch: 5| Step: 4
Training loss: 1.398287057876587
Validation loss: 1.8891560851886708

Epoch: 5| Step: 5
Training loss: 0.9458824396133423
Validation loss: 1.873269183661348

Epoch: 5| Step: 6
Training loss: 1.939340353012085
Validation loss: 1.8345932345236502

Epoch: 5| Step: 7
Training loss: 1.5840989351272583
Validation loss: 1.86471127951017

Epoch: 5| Step: 8
Training loss: 1.685389518737793
Validation loss: 1.8692022549208773

Epoch: 5| Step: 9
Training loss: 1.7019126415252686
Validation loss: 1.8391433582510999

Epoch: 5| Step: 10
Training loss: 2.051980495452881
Validation loss: 1.8954160187834053

Epoch: 296| Step: 0
Training loss: 1.2867000102996826
Validation loss: 1.8605250440618044

Epoch: 5| Step: 1
Training loss: 1.6654131412506104
Validation loss: 1.847402741832118

Epoch: 5| Step: 2
Training loss: 1.827612280845642
Validation loss: 1.9017584323883057

Epoch: 5| Step: 3
Training loss: 1.5949881076812744
Validation loss: 1.8803084460637902

Epoch: 5| Step: 4
Training loss: 2.316941738128662
Validation loss: 1.8622561321463635

Epoch: 5| Step: 5
Training loss: 2.001466989517212
Validation loss: 1.8872571683699084

Epoch: 5| Step: 6
Training loss: 1.4485303163528442
Validation loss: 1.9621006481109127

Epoch: 5| Step: 7
Training loss: 1.3101117610931396
Validation loss: 1.8965818881988525

Epoch: 5| Step: 8
Training loss: 1.5314065217971802
Validation loss: 1.9164554021691764

Epoch: 5| Step: 9
Training loss: 1.1540393829345703
Validation loss: 1.8924742590996526

Epoch: 5| Step: 10
Training loss: 1.6488014459609985
Validation loss: 1.9387377449261245

Epoch: 297| Step: 0
Training loss: 2.0915446281433105
Validation loss: 1.8988748750379008

Epoch: 5| Step: 1
Training loss: 1.8010122776031494
Validation loss: 1.8624085713458318

Epoch: 5| Step: 2
Training loss: 1.3867149353027344
Validation loss: 1.8491008858526907

Epoch: 5| Step: 3
Training loss: 1.4270905256271362
Validation loss: 1.8791033606375418

Epoch: 5| Step: 4
Training loss: 1.4255859851837158
Validation loss: 1.8423639676904167

Epoch: 5| Step: 5
Training loss: 2.009641170501709
Validation loss: 1.8447156029362832

Epoch: 5| Step: 6
Training loss: 1.5223835706710815
Validation loss: 1.80667967437416

Epoch: 5| Step: 7
Training loss: 1.6023356914520264
Validation loss: 1.8470185020918488

Epoch: 5| Step: 8
Training loss: 1.5911668539047241
Validation loss: 1.8576488520509453

Epoch: 5| Step: 9
Training loss: 1.7158968448638916
Validation loss: 1.8956173440461517

Epoch: 5| Step: 10
Training loss: 1.5849801301956177
Validation loss: 1.8494823901884017

Epoch: 298| Step: 0
Training loss: 1.8181602954864502
Validation loss: 1.8736957606448923

Epoch: 5| Step: 1
Training loss: 1.7645801305770874
Validation loss: 1.8478566356884536

Epoch: 5| Step: 2
Training loss: 1.7135995626449585
Validation loss: 1.8937620347545994

Epoch: 5| Step: 3
Training loss: 1.2122246026992798
Validation loss: 1.9016299401560137

Epoch: 5| Step: 4
Training loss: 1.4064998626708984
Validation loss: 1.854630567694223

Epoch: 5| Step: 5
Training loss: 1.3790597915649414
Validation loss: 1.884202063724559

Epoch: 5| Step: 6
Training loss: 1.7197567224502563
Validation loss: 1.9096881702382078

Epoch: 5| Step: 7
Training loss: 1.7273130416870117
Validation loss: 1.90036210449793

Epoch: 5| Step: 8
Training loss: 1.4293015003204346
Validation loss: 1.8592442979094803

Epoch: 5| Step: 9
Training loss: 1.6700245141983032
Validation loss: 1.9019114637887606

Epoch: 5| Step: 10
Training loss: 1.840759515762329
Validation loss: 1.8520492379383375

Epoch: 299| Step: 0
Training loss: 1.1861835718154907
Validation loss: 1.8645654673217444

Epoch: 5| Step: 1
Training loss: 1.7394440174102783
Validation loss: 1.8622444131041085

Epoch: 5| Step: 2
Training loss: 2.0192689895629883
Validation loss: 1.9244338081729027

Epoch: 5| Step: 3
Training loss: 1.3247588872909546
Validation loss: 1.8401593315985896

Epoch: 5| Step: 4
Training loss: 1.9550273418426514
Validation loss: 1.8578299886436873

Epoch: 5| Step: 5
Training loss: 1.7339613437652588
Validation loss: 1.8782641797937372

Epoch: 5| Step: 6
Training loss: 1.4949994087219238
Validation loss: 1.8441228123121365

Epoch: 5| Step: 7
Training loss: 1.3531155586242676
Validation loss: 1.8655098830499957

Epoch: 5| Step: 8
Training loss: 1.4930702447891235
Validation loss: 1.8700779996892458

Epoch: 5| Step: 9
Training loss: 1.1798804998397827
Validation loss: 1.8530608812967937

Epoch: 5| Step: 10
Training loss: 2.1035842895507812
Validation loss: 1.8602640423723447

Epoch: 300| Step: 0
Training loss: 1.9378836154937744
Validation loss: 1.9023019908576884

Epoch: 5| Step: 1
Training loss: 1.6949713230133057
Validation loss: 1.834232404667844

Epoch: 5| Step: 2
Training loss: 1.6486022472381592
Validation loss: 1.8192893382041686

Epoch: 5| Step: 3
Training loss: 1.0472095012664795
Validation loss: 1.855741980255291

Epoch: 5| Step: 4
Training loss: 1.0524909496307373
Validation loss: 1.881126328181195

Epoch: 5| Step: 5
Training loss: 1.5343120098114014
Validation loss: 1.8761036895936536

Epoch: 5| Step: 6
Training loss: 1.5396983623504639
Validation loss: 1.8875277401298605

Epoch: 5| Step: 7
Training loss: 1.783453345298767
Validation loss: 1.895433086220936

Epoch: 5| Step: 8
Training loss: 1.8292529582977295
Validation loss: 1.883733864753477

Epoch: 5| Step: 9
Training loss: 1.8856265544891357
Validation loss: 1.8381990168684272

Epoch: 5| Step: 10
Training loss: 1.5845588445663452
Validation loss: 1.8505885037042762

Epoch: 301| Step: 0
Training loss: 1.469384789466858
Validation loss: 1.8582975069681804

Epoch: 5| Step: 1
Training loss: 1.5057474374771118
Validation loss: 1.8370250335303686

Epoch: 5| Step: 2
Training loss: 1.8711391687393188
Validation loss: 1.8673784284181492

Epoch: 5| Step: 3
Training loss: 1.6974977254867554
Validation loss: 1.8737764653339182

Epoch: 5| Step: 4
Training loss: 2.077301025390625
Validation loss: 1.8806688965007823

Epoch: 5| Step: 5
Training loss: 1.757785439491272
Validation loss: 1.8693599675291328

Epoch: 5| Step: 6
Training loss: 1.5454576015472412
Validation loss: 1.8253704360736314

Epoch: 5| Step: 7
Training loss: 1.2375373840332031
Validation loss: 1.825029339841617

Epoch: 5| Step: 8
Training loss: 1.6611162424087524
Validation loss: 1.8539330164591472

Epoch: 5| Step: 9
Training loss: 1.3771196603775024
Validation loss: 1.8523073119501914

Epoch: 5| Step: 10
Training loss: 1.2068458795547485
Validation loss: 1.8262716659935572

Epoch: 302| Step: 0
Training loss: 2.027778148651123
Validation loss: 1.8584979400839856

Epoch: 5| Step: 1
Training loss: 2.0610902309417725
Validation loss: 1.901372653181835

Epoch: 5| Step: 2
Training loss: 1.2879137992858887
Validation loss: 1.836012517252276

Epoch: 5| Step: 3
Training loss: 1.3922239542007446
Validation loss: 1.8189589772173154

Epoch: 5| Step: 4
Training loss: 1.5690412521362305
Validation loss: 1.8724265201117403

Epoch: 5| Step: 5
Training loss: 1.1156742572784424
Validation loss: 1.890174013312145

Epoch: 5| Step: 6
Training loss: 1.8772188425064087
Validation loss: 1.8734447212629421

Epoch: 5| Step: 7
Training loss: 1.5700819492340088
Validation loss: 1.888633802372922

Epoch: 5| Step: 8
Training loss: 1.8203773498535156
Validation loss: 1.9185073426974717

Epoch: 5| Step: 9
Training loss: 1.5414941310882568
Validation loss: 1.9072984034015286

Epoch: 5| Step: 10
Training loss: 1.5811333656311035
Validation loss: 1.8942341804504395

Epoch: 303| Step: 0
Training loss: 1.3228192329406738
Validation loss: 1.8682221584422614

Epoch: 5| Step: 1
Training loss: 1.826708436012268
Validation loss: 1.8916985950162333

Epoch: 5| Step: 2
Training loss: 1.5521247386932373
Validation loss: 1.8886455976834862

Epoch: 5| Step: 3
Training loss: 1.4194834232330322
Validation loss: 1.843943444631433

Epoch: 5| Step: 4
Training loss: 2.0508201122283936
Validation loss: 1.8657169329222811

Epoch: 5| Step: 5
Training loss: 1.3660385608673096
Validation loss: 1.8505755714190903

Epoch: 5| Step: 6
Training loss: 1.8480507135391235
Validation loss: 1.891527993704683

Epoch: 5| Step: 7
Training loss: 1.2710751295089722
Validation loss: 1.8338053508471417

Epoch: 5| Step: 8
Training loss: 1.8011436462402344
Validation loss: 1.8798222669991114

Epoch: 5| Step: 9
Training loss: 1.903235673904419
Validation loss: 1.8752387057068527

Epoch: 5| Step: 10
Training loss: 1.543969988822937
Validation loss: 1.8484433671479583

Epoch: 304| Step: 0
Training loss: 1.953739881515503
Validation loss: 1.858396525024086

Epoch: 5| Step: 1
Training loss: 1.7071897983551025
Validation loss: 1.878528437306804

Epoch: 5| Step: 2
Training loss: 1.287277102470398
Validation loss: 1.8697396068162815

Epoch: 5| Step: 3
Training loss: 1.2492729425430298
Validation loss: 1.8408728004783712

Epoch: 5| Step: 4
Training loss: 1.4699592590332031
Validation loss: 1.8546506794550086

Epoch: 5| Step: 5
Training loss: 1.44290292263031
Validation loss: 1.8706933285600396

Epoch: 5| Step: 6
Training loss: 1.169166088104248
Validation loss: 1.8449122187911824

Epoch: 5| Step: 7
Training loss: 1.5294504165649414
Validation loss: 1.8641668955485027

Epoch: 5| Step: 8
Training loss: 2.0878255367279053
Validation loss: 1.8916201694037325

Epoch: 5| Step: 9
Training loss: 1.4821628332138062
Validation loss: 1.9056418326593214

Epoch: 5| Step: 10
Training loss: 1.9730366468429565
Validation loss: 1.8962623662846063

Epoch: 305| Step: 0
Training loss: 1.9996318817138672
Validation loss: 1.8497250387745519

Epoch: 5| Step: 1
Training loss: 1.6867347955703735
Validation loss: 1.9506040849993307

Epoch: 5| Step: 2
Training loss: 1.229305624961853
Validation loss: 1.953545844042173

Epoch: 5| Step: 3
Training loss: 1.101496696472168
Validation loss: 1.9078606764475505

Epoch: 5| Step: 4
Training loss: 1.4542709589004517
Validation loss: 1.9091035384003834

Epoch: 5| Step: 5
Training loss: 1.2961921691894531
Validation loss: 1.8807547630802277

Epoch: 5| Step: 6
Training loss: 1.6242090463638306
Validation loss: 1.878375562288428

Epoch: 5| Step: 7
Training loss: 1.492851734161377
Validation loss: 1.8773498022428123

Epoch: 5| Step: 8
Training loss: 2.2385997772216797
Validation loss: 1.8746087910026632

Epoch: 5| Step: 9
Training loss: 2.0791308879852295
Validation loss: 1.901252277435795

Epoch: 5| Step: 10
Training loss: 1.2994509935379028
Validation loss: 1.8421419141113118

Epoch: 306| Step: 0
Training loss: 1.668623685836792
Validation loss: 1.8373580812126078

Epoch: 5| Step: 1
Training loss: 1.3110761642456055
Validation loss: 1.8431172640092912

Epoch: 5| Step: 2
Training loss: 1.8365850448608398
Validation loss: 1.8747208990076536

Epoch: 5| Step: 3
Training loss: 1.1311867237091064
Validation loss: 1.8083631377066336

Epoch: 5| Step: 4
Training loss: 1.6704814434051514
Validation loss: 1.8541917493266444

Epoch: 5| Step: 5
Training loss: 1.2759273052215576
Validation loss: 1.8938780869207075

Epoch: 5| Step: 6
Training loss: 2.642430305480957
Validation loss: 1.8350887772857503

Epoch: 5| Step: 7
Training loss: 1.2800300121307373
Validation loss: 1.8643206857865857

Epoch: 5| Step: 8
Training loss: 1.419708490371704
Validation loss: 1.8796458757051857

Epoch: 5| Step: 9
Training loss: 1.8303226232528687
Validation loss: 1.8492025547130133

Epoch: 5| Step: 10
Training loss: 1.3087502717971802
Validation loss: 1.8690170626486502

Epoch: 307| Step: 0
Training loss: 1.5003092288970947
Validation loss: 1.8718749618017545

Epoch: 5| Step: 1
Training loss: 1.764263391494751
Validation loss: 1.8739781584790958

Epoch: 5| Step: 2
Training loss: 2.181645631790161
Validation loss: 1.8394848736383582

Epoch: 5| Step: 3
Training loss: 1.6808280944824219
Validation loss: 1.85780450477395

Epoch: 5| Step: 4
Training loss: 1.3581287860870361
Validation loss: 1.8529743302252986

Epoch: 5| Step: 5
Training loss: 1.1349900960922241
Validation loss: 1.8777691395052019

Epoch: 5| Step: 6
Training loss: 1.4962880611419678
Validation loss: 1.8438542581373645

Epoch: 5| Step: 7
Training loss: 1.4685001373291016
Validation loss: 1.8565063694471955

Epoch: 5| Step: 8
Training loss: 2.1298298835754395
Validation loss: 1.8557376092480076

Epoch: 5| Step: 9
Training loss: 1.299530267715454
Validation loss: 1.8614243474057925

Epoch: 5| Step: 10
Training loss: 1.3066905736923218
Validation loss: 1.8674456009300806

Epoch: 308| Step: 0
Training loss: 2.2327725887298584
Validation loss: 1.8773387939699235

Epoch: 5| Step: 1
Training loss: 1.427694320678711
Validation loss: 1.8862981565536991

Epoch: 5| Step: 2
Training loss: 1.5833699703216553
Validation loss: 1.8389428892443258

Epoch: 5| Step: 3
Training loss: 1.7560789585113525
Validation loss: 1.8946541342684018

Epoch: 5| Step: 4
Training loss: 1.3296804428100586
Validation loss: 1.8926384243913876

Epoch: 5| Step: 5
Training loss: 1.7250617742538452
Validation loss: 1.846384217662196

Epoch: 5| Step: 6
Training loss: 1.4367517232894897
Validation loss: 1.8832044428394688

Epoch: 5| Step: 7
Training loss: 1.6490428447723389
Validation loss: 1.86971834141721

Epoch: 5| Step: 8
Training loss: 1.305162787437439
Validation loss: 1.8856172254008632

Epoch: 5| Step: 9
Training loss: 1.2903368473052979
Validation loss: 1.8658304393932383

Epoch: 5| Step: 10
Training loss: 1.6799719333648682
Validation loss: 1.8435881753121652

Epoch: 309| Step: 0
Training loss: 1.714072823524475
Validation loss: 1.8762944885479507

Epoch: 5| Step: 1
Training loss: 1.3796327114105225
Validation loss: 1.8351480550663446

Epoch: 5| Step: 2
Training loss: 1.7478790283203125
Validation loss: 1.8083889497223722

Epoch: 5| Step: 3
Training loss: 1.7308437824249268
Validation loss: 1.8437536813879525

Epoch: 5| Step: 4
Training loss: 1.8574234247207642
Validation loss: 1.8853724156656573

Epoch: 5| Step: 5
Training loss: 2.1459879875183105
Validation loss: 1.83986194415759

Epoch: 5| Step: 6
Training loss: 1.2175583839416504
Validation loss: 1.8653195186327862

Epoch: 5| Step: 7
Training loss: 1.8947250843048096
Validation loss: 1.8135915751098304

Epoch: 5| Step: 8
Training loss: 1.2399977445602417
Validation loss: 1.8430876885690997

Epoch: 5| Step: 9
Training loss: 1.0654456615447998
Validation loss: 1.8614299502424014

Epoch: 5| Step: 10
Training loss: 0.952285885810852
Validation loss: 1.8505980378837996

Epoch: 310| Step: 0
Training loss: 1.9853363037109375
Validation loss: 1.855930733424361

Epoch: 5| Step: 1
Training loss: 2.039761781692505
Validation loss: 1.8608288534225956

Epoch: 5| Step: 2
Training loss: 1.797483205795288
Validation loss: 1.867625472366169

Epoch: 5| Step: 3
Training loss: 1.3493225574493408
Validation loss: 1.841465228347368

Epoch: 5| Step: 4
Training loss: 1.8066647052764893
Validation loss: 1.8383452161665885

Epoch: 5| Step: 5
Training loss: 1.2265827655792236
Validation loss: 1.842299775410724

Epoch: 5| Step: 6
Training loss: 1.5242772102355957
Validation loss: 1.8793042718723256

Epoch: 5| Step: 7
Training loss: 1.3104298114776611
Validation loss: 1.869419643955846

Epoch: 5| Step: 8
Training loss: 1.087009072303772
Validation loss: 1.8786552490726594

Epoch: 5| Step: 9
Training loss: 1.9737666845321655
Validation loss: 1.8695397312923143

Epoch: 5| Step: 10
Training loss: 1.4872047901153564
Validation loss: 1.8784348118689753

Epoch: 311| Step: 0
Training loss: 2.159681558609009
Validation loss: 1.8373012081269295

Epoch: 5| Step: 1
Training loss: 1.0730174779891968
Validation loss: 1.8716920421969505

Epoch: 5| Step: 2
Training loss: 1.4963358640670776
Validation loss: 1.8194925477427821

Epoch: 5| Step: 3
Training loss: 1.3394992351531982
Validation loss: 1.8801337480545044

Epoch: 5| Step: 4
Training loss: 1.315683364868164
Validation loss: 1.8696355230064803

Epoch: 5| Step: 5
Training loss: 1.8075031042099
Validation loss: 1.8496046079102384

Epoch: 5| Step: 6
Training loss: 1.112492322921753
Validation loss: 1.8274639216802453

Epoch: 5| Step: 7
Training loss: 1.6517959833145142
Validation loss: 1.8133602065424765

Epoch: 5| Step: 8
Training loss: 2.2007768154144287
Validation loss: 1.8522816960529616

Epoch: 5| Step: 9
Training loss: 1.600301742553711
Validation loss: 1.8700785226719354

Epoch: 5| Step: 10
Training loss: 1.5844817161560059
Validation loss: 1.873049512986214

Epoch: 312| Step: 0
Training loss: 0.9798930287361145
Validation loss: 1.8756186526308778

Epoch: 5| Step: 1
Training loss: 1.7427558898925781
Validation loss: 1.862314470352665

Epoch: 5| Step: 2
Training loss: 1.3968098163604736
Validation loss: 1.874281785821402

Epoch: 5| Step: 3
Training loss: 0.9859112501144409
Validation loss: 1.8285457395738172

Epoch: 5| Step: 4
Training loss: 1.982897162437439
Validation loss: 1.798479043027406

Epoch: 5| Step: 5
Training loss: 1.3811206817626953
Validation loss: 1.85956710128374

Epoch: 5| Step: 6
Training loss: 1.3799660205841064
Validation loss: 1.8275867175030451

Epoch: 5| Step: 7
Training loss: 1.9019763469696045
Validation loss: 1.8541606369838919

Epoch: 5| Step: 8
Training loss: 2.1726250648498535
Validation loss: 1.8563784296794603

Epoch: 5| Step: 9
Training loss: 1.4074018001556396
Validation loss: 1.8596646708826865

Epoch: 5| Step: 10
Training loss: 1.3954163789749146
Validation loss: 1.8755302403562812

Epoch: 313| Step: 0
Training loss: 1.397167444229126
Validation loss: 1.86433212026473

Epoch: 5| Step: 1
Training loss: 1.484226942062378
Validation loss: 1.886947444690171

Epoch: 5| Step: 2
Training loss: 1.422417402267456
Validation loss: 1.9129219324358049

Epoch: 5| Step: 3
Training loss: 1.8440303802490234
Validation loss: 1.8379829750266126

Epoch: 5| Step: 4
Training loss: 1.98214590549469
Validation loss: 1.8888019015712123

Epoch: 5| Step: 5
Training loss: 1.5457613468170166
Validation loss: 1.8737706420242146

Epoch: 5| Step: 6
Training loss: 1.7036784887313843
Validation loss: 1.8465645877263879

Epoch: 5| Step: 7
Training loss: 1.2271640300750732
Validation loss: 1.864689475746565

Epoch: 5| Step: 8
Training loss: 1.7800270318984985
Validation loss: 1.839293349173761

Epoch: 5| Step: 9
Training loss: 1.1442630290985107
Validation loss: 1.9044477939605713

Epoch: 5| Step: 10
Training loss: 1.627666711807251
Validation loss: 1.854582607105214

Epoch: 314| Step: 0
Training loss: 1.660424828529358
Validation loss: 1.84909394479567

Epoch: 5| Step: 1
Training loss: 1.6420866250991821
Validation loss: 1.858739887514422

Epoch: 5| Step: 2
Training loss: 1.3657463788986206
Validation loss: 1.8908663924022386

Epoch: 5| Step: 3
Training loss: 1.3375965356826782
Validation loss: 1.8603522418647684

Epoch: 5| Step: 4
Training loss: 1.1408827304840088
Validation loss: 1.8402223202490038

Epoch: 5| Step: 5
Training loss: 1.3092801570892334
Validation loss: 1.7951257241669523

Epoch: 5| Step: 6
Training loss: 1.98260498046875
Validation loss: 1.8604810724976242

Epoch: 5| Step: 7
Training loss: 1.6606543064117432
Validation loss: 1.8877554298729025

Epoch: 5| Step: 8
Training loss: 1.4079777002334595
Validation loss: 1.8443896719204482

Epoch: 5| Step: 9
Training loss: 1.8226089477539062
Validation loss: 1.8720083890422698

Epoch: 5| Step: 10
Training loss: 1.934773564338684
Validation loss: 1.848976965873472

Epoch: 315| Step: 0
Training loss: 1.4008558988571167
Validation loss: 1.899877716136235

Epoch: 5| Step: 1
Training loss: 1.362967848777771
Validation loss: 1.853278321604575

Epoch: 5| Step: 2
Training loss: 1.8201541900634766
Validation loss: 1.9205571989859305

Epoch: 5| Step: 3
Training loss: 1.410367488861084
Validation loss: 1.8508759954924225

Epoch: 5| Step: 4
Training loss: 1.2809937000274658
Validation loss: 1.8860932396304222

Epoch: 5| Step: 5
Training loss: 1.5101547241210938
Validation loss: 1.8877683608762679

Epoch: 5| Step: 6
Training loss: 2.2911133766174316
Validation loss: 1.8867162094321301

Epoch: 5| Step: 7
Training loss: 1.4230139255523682
Validation loss: 1.8374575466238043

Epoch: 5| Step: 8
Training loss: 1.9268535375595093
Validation loss: 1.8328812045435752

Epoch: 5| Step: 9
Training loss: 1.0382068157196045
Validation loss: 1.842803697432241

Epoch: 5| Step: 10
Training loss: 1.5809624195098877
Validation loss: 1.8569859561099802

Epoch: 316| Step: 0
Training loss: 1.7825965881347656
Validation loss: 1.8160529957022717

Epoch: 5| Step: 1
Training loss: 0.8894521594047546
Validation loss: 1.873020246464719

Epoch: 5| Step: 2
Training loss: 1.483066201210022
Validation loss: 1.8310859587884718

Epoch: 5| Step: 3
Training loss: 1.7039098739624023
Validation loss: 1.8580755161982712

Epoch: 5| Step: 4
Training loss: 1.3176603317260742
Validation loss: 1.826068433382178

Epoch: 5| Step: 5
Training loss: 1.4697774648666382
Validation loss: 1.8321889113354426

Epoch: 5| Step: 6
Training loss: 1.4080545902252197
Validation loss: 1.820719022904673

Epoch: 5| Step: 7
Training loss: 1.8412058353424072
Validation loss: 1.8202739530994045

Epoch: 5| Step: 8
Training loss: 1.5768146514892578
Validation loss: 1.8122565182306434

Epoch: 5| Step: 9
Training loss: 1.7591291666030884
Validation loss: 1.8184798789280716

Epoch: 5| Step: 10
Training loss: 1.6712114810943604
Validation loss: 1.827481169854441

Epoch: 317| Step: 0
Training loss: 1.2899997234344482
Validation loss: 1.8421320953676779

Epoch: 5| Step: 1
Training loss: 1.3779971599578857
Validation loss: 1.875600955819571

Epoch: 5| Step: 2
Training loss: 1.4714306592941284
Validation loss: 1.8570946621638473

Epoch: 5| Step: 3
Training loss: 0.9098695516586304
Validation loss: 1.8815717056233396

Epoch: 5| Step: 4
Training loss: 1.7442359924316406
Validation loss: 1.8900429869210849

Epoch: 5| Step: 5
Training loss: 1.307448148727417
Validation loss: 1.89645504823295

Epoch: 5| Step: 6
Training loss: 1.7392997741699219
Validation loss: 1.8708777196945683

Epoch: 5| Step: 7
Training loss: 1.971700668334961
Validation loss: 1.874117887148293

Epoch: 5| Step: 8
Training loss: 1.7034038305282593
Validation loss: 1.8707946372288529

Epoch: 5| Step: 9
Training loss: 1.9666273593902588
Validation loss: 1.8308526879997664

Epoch: 5| Step: 10
Training loss: 1.5386940240859985
Validation loss: 1.8621271810223978

Epoch: 318| Step: 0
Training loss: 1.478804349899292
Validation loss: 1.8610461834938294

Epoch: 5| Step: 1
Training loss: 1.661156415939331
Validation loss: 1.913456888609035

Epoch: 5| Step: 2
Training loss: 1.6522724628448486
Validation loss: 1.8628883169543358

Epoch: 5| Step: 3
Training loss: 1.4798108339309692
Validation loss: 1.8240771562822404

Epoch: 5| Step: 4
Training loss: 2.175842523574829
Validation loss: 1.8439439189049505

Epoch: 5| Step: 5
Training loss: 0.983333945274353
Validation loss: 1.882634093684535

Epoch: 5| Step: 6
Training loss: 1.6579996347427368
Validation loss: 1.8594785044270177

Epoch: 5| Step: 7
Training loss: 1.278026819229126
Validation loss: 1.8563560221784858

Epoch: 5| Step: 8
Training loss: 1.2552860975265503
Validation loss: 1.8444082531877743

Epoch: 5| Step: 9
Training loss: 1.9756269454956055
Validation loss: 1.8800771723511398

Epoch: 5| Step: 10
Training loss: 1.4487589597702026
Validation loss: 1.8690522332345285

Epoch: 319| Step: 0
Training loss: 1.3382998704910278
Validation loss: 1.8858983555147726

Epoch: 5| Step: 1
Training loss: 1.5179387331008911
Validation loss: 1.8801071105464813

Epoch: 5| Step: 2
Training loss: 1.5530281066894531
Validation loss: 1.8304791040317987

Epoch: 5| Step: 3
Training loss: 1.430355429649353
Validation loss: 1.8675236240510018

Epoch: 5| Step: 4
Training loss: 1.7092831134796143
Validation loss: 1.8844677940491708

Epoch: 5| Step: 5
Training loss: 1.4109398126602173
Validation loss: 1.899728705806117

Epoch: 5| Step: 6
Training loss: 2.0940520763397217
Validation loss: 1.8834816050785843

Epoch: 5| Step: 7
Training loss: 1.2389293909072876
Validation loss: 1.8378439757131761

Epoch: 5| Step: 8
Training loss: 1.4323116540908813
Validation loss: 1.902293215515793

Epoch: 5| Step: 9
Training loss: 1.654598593711853
Validation loss: 1.8466037499007357

Epoch: 5| Step: 10
Training loss: 1.8880404233932495
Validation loss: 1.8515406962363952

Epoch: 320| Step: 0
Training loss: 1.6725130081176758
Validation loss: 1.830269525128026

Epoch: 5| Step: 1
Training loss: 1.998191475868225
Validation loss: 1.884841085762106

Epoch: 5| Step: 2
Training loss: 1.8466873168945312
Validation loss: 1.8208013042326896

Epoch: 5| Step: 3
Training loss: 0.8752153515815735
Validation loss: 1.836914962337863

Epoch: 5| Step: 4
Training loss: 1.5906881093978882
Validation loss: 1.8858241009455856

Epoch: 5| Step: 5
Training loss: 1.1370000839233398
Validation loss: 1.8421219651417067

Epoch: 5| Step: 6
Training loss: 1.5603021383285522
Validation loss: 1.8756369211340462

Epoch: 5| Step: 7
Training loss: 1.6489776372909546
Validation loss: 1.8142286449350336

Epoch: 5| Step: 8
Training loss: 1.5543053150177002
Validation loss: 1.8317061496037308

Epoch: 5| Step: 9
Training loss: 1.5243895053863525
Validation loss: 1.7794693810965425

Epoch: 5| Step: 10
Training loss: 1.7508107423782349
Validation loss: 1.8187805850018737

Epoch: 321| Step: 0
Training loss: 1.6901655197143555
Validation loss: 1.8407168439639512

Epoch: 5| Step: 1
Training loss: 1.5600838661193848
Validation loss: 1.857790857233027

Epoch: 5| Step: 2
Training loss: 2.2374913692474365
Validation loss: 1.8608515454876808

Epoch: 5| Step: 3
Training loss: 1.1936452388763428
Validation loss: 1.8654824431224535

Epoch: 5| Step: 4
Training loss: 1.6055234670639038
Validation loss: 1.8176662152813328

Epoch: 5| Step: 5
Training loss: 1.1883025169372559
Validation loss: 1.8420853896807599

Epoch: 5| Step: 6
Training loss: 1.834682822227478
Validation loss: 1.8533879082690004

Epoch: 5| Step: 7
Training loss: 1.6080856323242188
Validation loss: 1.8628788904477191

Epoch: 5| Step: 8
Training loss: 1.1000032424926758
Validation loss: 1.8982812384123444

Epoch: 5| Step: 9
Training loss: 1.2562110424041748
Validation loss: 1.8621383790046937

Epoch: 5| Step: 10
Training loss: 1.3807264566421509
Validation loss: 1.8655621813189598

Epoch: 322| Step: 0
Training loss: 1.6959148645401
Validation loss: 1.855211805271846

Epoch: 5| Step: 1
Training loss: 1.5744221210479736
Validation loss: 1.8475166725856003

Epoch: 5| Step: 2
Training loss: 1.7094800472259521
Validation loss: 1.849718306654243

Epoch: 5| Step: 3
Training loss: 1.321053147315979
Validation loss: 1.8564880894076439

Epoch: 5| Step: 4
Training loss: 1.7602516412734985
Validation loss: 1.8176823546809535

Epoch: 5| Step: 5
Training loss: 1.273603916168213
Validation loss: 1.809997199684061

Epoch: 5| Step: 6
Training loss: 1.616490364074707
Validation loss: 1.8422893003750873

Epoch: 5| Step: 7
Training loss: 1.6073238849639893
Validation loss: 1.839957239807293

Epoch: 5| Step: 8
Training loss: 1.4916150569915771
Validation loss: 1.8485220234881166

Epoch: 5| Step: 9
Training loss: 1.4537636041641235
Validation loss: 1.8717257168985182

Epoch: 5| Step: 10
Training loss: 1.6083030700683594
Validation loss: 1.8277079571959793

Epoch: 323| Step: 0
Training loss: 1.605160117149353
Validation loss: 1.8457168071500716

Epoch: 5| Step: 1
Training loss: 1.1078310012817383
Validation loss: 1.8672761430022538

Epoch: 5| Step: 2
Training loss: 1.2336325645446777
Validation loss: 1.8474979964635705

Epoch: 5| Step: 3
Training loss: 1.8664203882217407
Validation loss: 1.852960253274569

Epoch: 5| Step: 4
Training loss: 2.0354714393615723
Validation loss: 1.8488332891976962

Epoch: 5| Step: 5
Training loss: 1.1851861476898193
Validation loss: 1.879241233230919

Epoch: 5| Step: 6
Training loss: 1.4365531206130981
Validation loss: 1.8871528230687624

Epoch: 5| Step: 7
Training loss: 1.4496022462844849
Validation loss: 1.9035281519736014

Epoch: 5| Step: 8
Training loss: 1.580402135848999
Validation loss: 1.8485730386549426

Epoch: 5| Step: 9
Training loss: 1.7412490844726562
Validation loss: 1.8373959910485052

Epoch: 5| Step: 10
Training loss: 1.3883399963378906
Validation loss: 1.8414140209074943

Epoch: 324| Step: 0
Training loss: 1.1131458282470703
Validation loss: 1.828051652959598

Epoch: 5| Step: 1
Training loss: 1.454438328742981
Validation loss: 1.8044968343550158

Epoch: 5| Step: 2
Training loss: 2.0015029907226562
Validation loss: 1.7944444994772635

Epoch: 5| Step: 3
Training loss: 1.672285795211792
Validation loss: 1.8095407280870663

Epoch: 5| Step: 4
Training loss: 1.4830827713012695
Validation loss: 1.8738319950719033

Epoch: 5| Step: 5
Training loss: 1.5361268520355225
Validation loss: 1.8466986789498279

Epoch: 5| Step: 6
Training loss: 1.3534356355667114
Validation loss: 1.8398758583171393

Epoch: 5| Step: 7
Training loss: 1.3866523504257202
Validation loss: 1.8415769082243725

Epoch: 5| Step: 8
Training loss: 1.986959457397461
Validation loss: 1.8277749425621443

Epoch: 5| Step: 9
Training loss: 1.7119252681732178
Validation loss: 1.8261242707570393

Epoch: 5| Step: 10
Training loss: 1.0321195125579834
Validation loss: 1.8353991816120763

Epoch: 325| Step: 0
Training loss: 2.2193214893341064
Validation loss: 1.8673219937150196

Epoch: 5| Step: 1
Training loss: 1.8730275630950928
Validation loss: 1.8633215453035088

Epoch: 5| Step: 2
Training loss: 1.2855688333511353
Validation loss: 1.8216300549045685

Epoch: 5| Step: 3
Training loss: 1.6309572458267212
Validation loss: 1.85681632385459

Epoch: 5| Step: 4
Training loss: 1.0581233501434326
Validation loss: 1.8765473006874003

Epoch: 5| Step: 5
Training loss: 0.8667861223220825
Validation loss: 1.8647310644067743

Epoch: 5| Step: 6
Training loss: 1.5605850219726562
Validation loss: 1.8453943601218603

Epoch: 5| Step: 7
Training loss: 1.5136849880218506
Validation loss: 1.855564175113555

Epoch: 5| Step: 8
Training loss: 1.068709135055542
Validation loss: 1.8689317395610194

Epoch: 5| Step: 9
Training loss: 1.6573368310928345
Validation loss: 1.8518771509970389

Epoch: 5| Step: 10
Training loss: 1.795414924621582
Validation loss: 1.8367369905594857

Epoch: 326| Step: 0
Training loss: 1.5120617151260376
Validation loss: 1.8593312642907585

Epoch: 5| Step: 1
Training loss: 1.1679003238677979
Validation loss: 1.8520915508270264

Epoch: 5| Step: 2
Training loss: 1.5735050439834595
Validation loss: 1.8650393229658886

Epoch: 5| Step: 3
Training loss: 1.1770707368850708
Validation loss: 1.8486226861194899

Epoch: 5| Step: 4
Training loss: 1.3898636102676392
Validation loss: 1.8011638964376142

Epoch: 5| Step: 5
Training loss: 1.9074360132217407
Validation loss: 1.8443862763784264

Epoch: 5| Step: 6
Training loss: 1.641427993774414
Validation loss: 1.8086754891180223

Epoch: 5| Step: 7
Training loss: 1.2333273887634277
Validation loss: 1.8385444725713422

Epoch: 5| Step: 8
Training loss: 1.496690034866333
Validation loss: 1.8494501934256604

Epoch: 5| Step: 9
Training loss: 2.452000379562378
Validation loss: 1.8154035845110494

Epoch: 5| Step: 10
Training loss: 1.311444640159607
Validation loss: 1.836351748435728

Epoch: 327| Step: 0
Training loss: 1.6348768472671509
Validation loss: 1.8182026673388738

Epoch: 5| Step: 1
Training loss: 1.2614963054656982
Validation loss: 1.8324515140184792

Epoch: 5| Step: 2
Training loss: 1.3205270767211914
Validation loss: 1.862374342897887

Epoch: 5| Step: 3
Training loss: 1.3600997924804688
Validation loss: 1.8784455932596678

Epoch: 5| Step: 4
Training loss: 1.4654970169067383
Validation loss: 1.8683441813274095

Epoch: 5| Step: 5
Training loss: 1.990735650062561
Validation loss: 1.8868905446862663

Epoch: 5| Step: 6
Training loss: 0.9435235857963562
Validation loss: 1.8485397728540565

Epoch: 5| Step: 7
Training loss: 1.5142858028411865
Validation loss: 1.847164994926863

Epoch: 5| Step: 8
Training loss: 2.0064971446990967
Validation loss: 1.9030132319337578

Epoch: 5| Step: 9
Training loss: 2.107109546661377
Validation loss: 1.8336574646734423

Epoch: 5| Step: 10
Training loss: 1.0493221282958984
Validation loss: 1.8981809744270899

Epoch: 328| Step: 0
Training loss: 1.171149492263794
Validation loss: 1.8855363681752195

Epoch: 5| Step: 1
Training loss: 1.5312397480010986
Validation loss: 1.8743587258041545

Epoch: 5| Step: 2
Training loss: 2.068469524383545
Validation loss: 1.8364339618272678

Epoch: 5| Step: 3
Training loss: 1.283633828163147
Validation loss: 1.8453481197357178

Epoch: 5| Step: 4
Training loss: 1.3907182216644287
Validation loss: 1.8715189528721634

Epoch: 5| Step: 5
Training loss: 1.505548119544983
Validation loss: 1.801222337189541

Epoch: 5| Step: 6
Training loss: 1.5481706857681274
Validation loss: 1.8139288976628294

Epoch: 5| Step: 7
Training loss: 1.8493410348892212
Validation loss: 1.846198134524848

Epoch: 5| Step: 8
Training loss: 1.414335012435913
Validation loss: 1.8449304642215851

Epoch: 5| Step: 9
Training loss: 1.2506052255630493
Validation loss: 1.8126802944367932

Epoch: 5| Step: 10
Training loss: 1.2498942613601685
Validation loss: 1.8267547520258094

Epoch: 329| Step: 0
Training loss: 1.7133163213729858
Validation loss: 1.819874458415534

Epoch: 5| Step: 1
Training loss: 1.2703371047973633
Validation loss: 1.8597695878756944

Epoch: 5| Step: 2
Training loss: 1.8220571279525757
Validation loss: 1.8620728203045425

Epoch: 5| Step: 3
Training loss: 1.419161081314087
Validation loss: 1.8481552229132703

Epoch: 5| Step: 4
Training loss: 1.3986788988113403
Validation loss: 1.8959194383313578

Epoch: 5| Step: 5
Training loss: 1.9063752889633179
Validation loss: 1.8551801686645837

Epoch: 5| Step: 6
Training loss: 1.886853814125061
Validation loss: 1.8523772198666808

Epoch: 5| Step: 7
Training loss: 0.7407467365264893
Validation loss: 1.8763876832941526

Epoch: 5| Step: 8
Training loss: 1.6042808294296265
Validation loss: 1.8414749676181423

Epoch: 5| Step: 9
Training loss: 1.4034078121185303
Validation loss: 1.8541544483553978

Epoch: 5| Step: 10
Training loss: 1.4777661561965942
Validation loss: 1.816458781560262

Epoch: 330| Step: 0
Training loss: 1.8486995697021484
Validation loss: 1.8360717335054952

Epoch: 5| Step: 1
Training loss: 1.4100611209869385
Validation loss: 1.8733349564254924

Epoch: 5| Step: 2
Training loss: 1.0799920558929443
Validation loss: 1.8712664086331603

Epoch: 5| Step: 3
Training loss: 1.3983044624328613
Validation loss: 1.8854624353429323

Epoch: 5| Step: 4
Training loss: 1.400572657585144
Validation loss: 1.854121869610202

Epoch: 5| Step: 5
Training loss: 1.1198574304580688
Validation loss: 1.8456533057715303

Epoch: 5| Step: 6
Training loss: 1.4986804723739624
Validation loss: 1.823786872689442

Epoch: 5| Step: 7
Training loss: 0.9663079380989075
Validation loss: 1.8229902892984369

Epoch: 5| Step: 8
Training loss: 1.782671332359314
Validation loss: 1.828031566835219

Epoch: 5| Step: 9
Training loss: 1.4192124605178833
Validation loss: 1.819348358338879

Epoch: 5| Step: 10
Training loss: 2.6183218955993652
Validation loss: 1.8269905198004939

Epoch: 331| Step: 0
Training loss: 1.5405552387237549
Validation loss: 1.8429743461711432

Epoch: 5| Step: 1
Training loss: 1.6447370052337646
Validation loss: 1.8299937350775606

Epoch: 5| Step: 2
Training loss: 1.3088963031768799
Validation loss: 1.7982735531304472

Epoch: 5| Step: 3
Training loss: 1.4939779043197632
Validation loss: 1.8845204704551286

Epoch: 5| Step: 4
Training loss: 2.157583475112915
Validation loss: 1.8709744561103083

Epoch: 5| Step: 5
Training loss: 1.3951444625854492
Validation loss: 1.834634660392679

Epoch: 5| Step: 6
Training loss: 0.9823484420776367
Validation loss: 1.884454825873016

Epoch: 5| Step: 7
Training loss: 1.3286044597625732
Validation loss: 1.8676457815272833

Epoch: 5| Step: 8
Training loss: 1.7895625829696655
Validation loss: 1.8595772904734458

Epoch: 5| Step: 9
Training loss: 1.525089144706726
Validation loss: 1.867399823281073

Epoch: 5| Step: 10
Training loss: 1.4223967790603638
Validation loss: 1.8717620244590185

Epoch: 332| Step: 0
Training loss: 1.207236886024475
Validation loss: 1.8844787830947547

Epoch: 5| Step: 1
Training loss: 1.4784910678863525
Validation loss: 1.8147753310459915

Epoch: 5| Step: 2
Training loss: 1.7905477285385132
Validation loss: 1.8485749972763883

Epoch: 5| Step: 3
Training loss: 1.5132038593292236
Validation loss: 1.8498288123838362

Epoch: 5| Step: 4
Training loss: 1.1478725671768188
Validation loss: 1.8445874183408675

Epoch: 5| Step: 5
Training loss: 1.4294216632843018
Validation loss: 1.8802419003619943

Epoch: 5| Step: 6
Training loss: 1.1729648113250732
Validation loss: 1.8740828114171182

Epoch: 5| Step: 7
Training loss: 1.9368813037872314
Validation loss: 1.8384807596924484

Epoch: 5| Step: 8
Training loss: 1.4535915851593018
Validation loss: 1.8651397407695811

Epoch: 5| Step: 9
Training loss: 1.9845879077911377
Validation loss: 1.8259126037679694

Epoch: 5| Step: 10
Training loss: 1.4819387197494507
Validation loss: 1.8047113059669413

Epoch: 333| Step: 0
Training loss: 1.4551141262054443
Validation loss: 1.8333828910704582

Epoch: 5| Step: 1
Training loss: 1.4446983337402344
Validation loss: 1.8228736667222873

Epoch: 5| Step: 2
Training loss: 1.425923228263855
Validation loss: 1.8723972920448548

Epoch: 5| Step: 3
Training loss: 1.2579071521759033
Validation loss: 1.8164437317079114

Epoch: 5| Step: 4
Training loss: 1.4863454103469849
Validation loss: 1.8427951617907452

Epoch: 5| Step: 5
Training loss: 1.9319798946380615
Validation loss: 1.819051832281133

Epoch: 5| Step: 6
Training loss: 1.2516984939575195
Validation loss: 1.851289455608655

Epoch: 5| Step: 7
Training loss: 1.5641034841537476
Validation loss: 1.9120864099071873

Epoch: 5| Step: 8
Training loss: 1.3869425058364868
Validation loss: 1.8296328859944497

Epoch: 5| Step: 9
Training loss: 1.8182322978973389
Validation loss: 1.8522810013063493

Epoch: 5| Step: 10
Training loss: 1.455600380897522
Validation loss: 1.8516829834189465

Epoch: 334| Step: 0
Training loss: 1.6826775074005127
Validation loss: 1.8661533683858893

Epoch: 5| Step: 1
Training loss: 1.4250489473342896
Validation loss: 1.8667713172974125

Epoch: 5| Step: 2
Training loss: 1.3523356914520264
Validation loss: 1.8549153112596082

Epoch: 5| Step: 3
Training loss: 1.0897619724273682
Validation loss: 1.8757042872008456

Epoch: 5| Step: 4
Training loss: 1.8199838399887085
Validation loss: 1.83843990166982

Epoch: 5| Step: 5
Training loss: 1.9503787755966187
Validation loss: 1.8604847359400924

Epoch: 5| Step: 6
Training loss: 1.5692476034164429
Validation loss: 1.8385578458027174

Epoch: 5| Step: 7
Training loss: 1.2108795642852783
Validation loss: 1.876886671589267

Epoch: 5| Step: 8
Training loss: 1.5651191473007202
Validation loss: 1.8374475471435054

Epoch: 5| Step: 9
Training loss: 1.9362132549285889
Validation loss: 1.8226262369463522

Epoch: 5| Step: 10
Training loss: 0.6480594277381897
Validation loss: 1.8266272980679747

Epoch: 335| Step: 0
Training loss: 1.5397030115127563
Validation loss: 1.8295558062932824

Epoch: 5| Step: 1
Training loss: 1.5835230350494385
Validation loss: 1.8535048974457609

Epoch: 5| Step: 2
Training loss: 1.6510915756225586
Validation loss: 1.7973063222823604

Epoch: 5| Step: 3
Training loss: 1.358248233795166
Validation loss: 1.833806933895234

Epoch: 5| Step: 4
Training loss: 1.3532315492630005
Validation loss: 1.815845102392217

Epoch: 5| Step: 5
Training loss: 1.3851969242095947
Validation loss: 1.8385742351573

Epoch: 5| Step: 6
Training loss: 1.6048624515533447
Validation loss: 1.8425097068150837

Epoch: 5| Step: 7
Training loss: 1.753161072731018
Validation loss: 1.8532894375503703

Epoch: 5| Step: 8
Training loss: 1.7208713293075562
Validation loss: 1.8234717640825497

Epoch: 5| Step: 9
Training loss: 1.461789846420288
Validation loss: 1.8436382509046985

Epoch: 5| Step: 10
Training loss: 0.8657203912734985
Validation loss: 1.871831488865678

Epoch: 336| Step: 0
Training loss: 1.6747360229492188
Validation loss: 1.856366192140887

Epoch: 5| Step: 1
Training loss: 1.7925279140472412
Validation loss: 1.824777888995345

Epoch: 5| Step: 2
Training loss: 1.2186845541000366
Validation loss: 1.8387051218299455

Epoch: 5| Step: 3
Training loss: 1.289820909500122
Validation loss: 1.84116607071251

Epoch: 5| Step: 4
Training loss: 1.5407801866531372
Validation loss: 1.88961075967358

Epoch: 5| Step: 5
Training loss: 1.3304177522659302
Validation loss: 1.8145101749768822

Epoch: 5| Step: 6
Training loss: 1.4924776554107666
Validation loss: 1.8484724439600462

Epoch: 5| Step: 7
Training loss: 1.4544652700424194
Validation loss: 1.7696216221778625

Epoch: 5| Step: 8
Training loss: 1.985076904296875
Validation loss: 1.8620937088484406

Epoch: 5| Step: 9
Training loss: 1.0536073446273804
Validation loss: 1.7892658428479267

Epoch: 5| Step: 10
Training loss: 1.6251840591430664
Validation loss: 1.8320207685552619

Epoch: 337| Step: 0
Training loss: 1.6076608896255493
Validation loss: 1.8531395696824597

Epoch: 5| Step: 1
Training loss: 1.5768625736236572
Validation loss: 1.8291760010104026

Epoch: 5| Step: 2
Training loss: 1.6437098979949951
Validation loss: 1.7935212760843255

Epoch: 5| Step: 3
Training loss: 1.3984867334365845
Validation loss: 1.8496626179705384

Epoch: 5| Step: 4
Training loss: 1.3081274032592773
Validation loss: 1.872206352090323

Epoch: 5| Step: 5
Training loss: 1.7094457149505615
Validation loss: 1.834473709906301

Epoch: 5| Step: 6
Training loss: 0.9689136743545532
Validation loss: 1.8508612058495963

Epoch: 5| Step: 7
Training loss: 1.4470504522323608
Validation loss: 1.8740766804705384

Epoch: 5| Step: 8
Training loss: 1.5975093841552734
Validation loss: 1.8614478777813654

Epoch: 5| Step: 9
Training loss: 1.4977773427963257
Validation loss: 1.8208404676888579

Epoch: 5| Step: 10
Training loss: 2.038863182067871
Validation loss: 1.860571220356931

Epoch: 338| Step: 0
Training loss: 2.025588274002075
Validation loss: 1.863630123035882

Epoch: 5| Step: 1
Training loss: 1.2465757131576538
Validation loss: 1.8843489244420042

Epoch: 5| Step: 2
Training loss: 1.638522744178772
Validation loss: 1.8598743356684202

Epoch: 5| Step: 3
Training loss: 1.1538264751434326
Validation loss: 1.8672639375091882

Epoch: 5| Step: 4
Training loss: 1.7160522937774658
Validation loss: 1.8737823078709264

Epoch: 5| Step: 5
Training loss: 1.1176540851593018
Validation loss: 1.9121709639026272

Epoch: 5| Step: 6
Training loss: 1.6112810373306274
Validation loss: 1.9000431645301081

Epoch: 5| Step: 7
Training loss: 1.5842126607894897
Validation loss: 1.8585559642443092

Epoch: 5| Step: 8
Training loss: 1.4158644676208496
Validation loss: 1.8906447695147606

Epoch: 5| Step: 9
Training loss: 1.3108570575714111
Validation loss: 1.891075514977978

Epoch: 5| Step: 10
Training loss: 1.3505874872207642
Validation loss: 1.8637893943376438

Epoch: 339| Step: 0
Training loss: 1.6934369802474976
Validation loss: 1.8160491335776545

Epoch: 5| Step: 1
Training loss: 1.8845937252044678
Validation loss: 1.8739645250381962

Epoch: 5| Step: 2
Training loss: 1.4495891332626343
Validation loss: 1.858903613141788

Epoch: 5| Step: 3
Training loss: 1.3589107990264893
Validation loss: 1.814038767609545

Epoch: 5| Step: 4
Training loss: 1.1152576208114624
Validation loss: 1.8266888972251647

Epoch: 5| Step: 5
Training loss: 1.3571580648422241
Validation loss: 1.840956211090088

Epoch: 5| Step: 6
Training loss: 0.988425076007843
Validation loss: 1.7993914094022525

Epoch: 5| Step: 7
Training loss: 1.5043957233428955
Validation loss: 1.8230466227377615

Epoch: 5| Step: 8
Training loss: 1.7633346319198608
Validation loss: 1.8025993813750565

Epoch: 5| Step: 9
Training loss: 1.6552810668945312
Validation loss: 1.7972112003193106

Epoch: 5| Step: 10
Training loss: 1.3623560667037964
Validation loss: 1.84116070501266

Epoch: 340| Step: 0
Training loss: 1.416658639907837
Validation loss: 1.8366480104384884

Epoch: 5| Step: 1
Training loss: 1.3728646039962769
Validation loss: 1.8385683426292994

Epoch: 5| Step: 2
Training loss: 1.762477159500122
Validation loss: 1.836217559793944

Epoch: 5| Step: 3
Training loss: 1.4387811422348022
Validation loss: 1.8713301791939685

Epoch: 5| Step: 4
Training loss: 1.6408103704452515
Validation loss: 1.8718910422376407

Epoch: 5| Step: 5
Training loss: 1.6504827737808228
Validation loss: 1.8902934315384075

Epoch: 5| Step: 6
Training loss: 1.6935386657714844
Validation loss: 1.8793834165860248

Epoch: 5| Step: 7
Training loss: 1.2195767164230347
Validation loss: 1.8659861767163841

Epoch: 5| Step: 8
Training loss: 1.4754440784454346
Validation loss: 1.9124852489399653

Epoch: 5| Step: 9
Training loss: 1.1085107326507568
Validation loss: 1.8747255199698991

Epoch: 5| Step: 10
Training loss: 1.4414170980453491
Validation loss: 1.8793364109531525

Epoch: 341| Step: 0
Training loss: 1.2667131423950195
Validation loss: 1.8675767042303597

Epoch: 5| Step: 1
Training loss: 1.3577892780303955
Validation loss: 1.9039736114522463

Epoch: 5| Step: 2
Training loss: 0.6814413070678711
Validation loss: 1.8013907670974731

Epoch: 5| Step: 3
Training loss: 1.182800054550171
Validation loss: 1.849210705808414

Epoch: 5| Step: 4
Training loss: 1.9556195735931396
Validation loss: 1.828353786981234

Epoch: 5| Step: 5
Training loss: 1.558104395866394
Validation loss: 1.8385836514093543

Epoch: 5| Step: 6
Training loss: 1.5286190509796143
Validation loss: 1.823555923277332

Epoch: 5| Step: 7
Training loss: 1.757328748703003
Validation loss: 1.8098742961883545

Epoch: 5| Step: 8
Training loss: 1.7306522130966187
Validation loss: 1.7947078033160138

Epoch: 5| Step: 9
Training loss: 1.0602833032608032
Validation loss: 1.8292763361366846

Epoch: 5| Step: 10
Training loss: 1.8946044445037842
Validation loss: 1.8618456573896511

Epoch: 342| Step: 0
Training loss: 2.068425178527832
Validation loss: 1.831956471166303

Epoch: 5| Step: 1
Training loss: 0.9905522465705872
Validation loss: 1.8518228697520431

Epoch: 5| Step: 2
Training loss: 1.433910846710205
Validation loss: 1.8333082276005899

Epoch: 5| Step: 3
Training loss: 1.5728305578231812
Validation loss: 1.863461676464286

Epoch: 5| Step: 4
Training loss: 1.3259814977645874
Validation loss: 1.902433540231438

Epoch: 5| Step: 5
Training loss: 1.424267053604126
Validation loss: 1.864121485781926

Epoch: 5| Step: 6
Training loss: 1.3803209066390991
Validation loss: 1.9158645547846311

Epoch: 5| Step: 7
Training loss: 1.17537522315979
Validation loss: 1.9109694906460342

Epoch: 5| Step: 8
Training loss: 1.2021198272705078
Validation loss: 1.8655653051150742

Epoch: 5| Step: 9
Training loss: 1.8583412170410156
Validation loss: 1.8511735598246257

Epoch: 5| Step: 10
Training loss: 1.7943482398986816
Validation loss: 1.8373330126526535

Epoch: 343| Step: 0
Training loss: 1.7335325479507446
Validation loss: 1.8603155843673214

Epoch: 5| Step: 1
Training loss: 2.2443747520446777
Validation loss: 1.8079899229029173

Epoch: 5| Step: 2
Training loss: 1.704424262046814
Validation loss: 1.8356476945261802

Epoch: 5| Step: 3
Training loss: 1.6860936880111694
Validation loss: 1.8562455279852754

Epoch: 5| Step: 4
Training loss: 1.1155269145965576
Validation loss: 1.8475004498676588

Epoch: 5| Step: 5
Training loss: 1.425477147102356
Validation loss: 1.8599349708967312

Epoch: 5| Step: 6
Training loss: 1.1471563577651978
Validation loss: 1.7722763528106034

Epoch: 5| Step: 7
Training loss: 1.0634254217147827
Validation loss: 1.852400227259564

Epoch: 5| Step: 8
Training loss: 1.2300865650177002
Validation loss: 1.8516533297877158

Epoch: 5| Step: 9
Training loss: 1.3560574054718018
Validation loss: 1.8746769838435675

Epoch: 5| Step: 10
Training loss: 0.9824239015579224
Validation loss: 1.8548276475680772

Epoch: 344| Step: 0
Training loss: 1.389736533164978
Validation loss: 1.8779061763517317

Epoch: 5| Step: 1
Training loss: 1.0764957666397095
Validation loss: 1.8278345164432321

Epoch: 5| Step: 2
Training loss: 1.8189901113510132
Validation loss: 1.8574473883516045

Epoch: 5| Step: 3
Training loss: 1.2655632495880127
Validation loss: 1.814705277001986

Epoch: 5| Step: 4
Training loss: 1.848102331161499
Validation loss: 1.7973397880472162

Epoch: 5| Step: 5
Training loss: 1.5983705520629883
Validation loss: 1.8203626576290335

Epoch: 5| Step: 6
Training loss: 1.5001875162124634
Validation loss: 1.820572929997598

Epoch: 5| Step: 7
Training loss: 2.003990650177002
Validation loss: 1.8644313350800545

Epoch: 5| Step: 8
Training loss: 1.3969638347625732
Validation loss: 1.7971093141904442

Epoch: 5| Step: 9
Training loss: 1.0425987243652344
Validation loss: 1.7924498768262966

Epoch: 5| Step: 10
Training loss: 1.0988636016845703
Validation loss: 1.8465165643281833

Epoch: 345| Step: 0
Training loss: 1.4008891582489014
Validation loss: 1.8577684228138258

Epoch: 5| Step: 1
Training loss: 1.4788641929626465
Validation loss: 1.8027414532117947

Epoch: 5| Step: 2
Training loss: 1.2547707557678223
Validation loss: 1.7716307499075448

Epoch: 5| Step: 3
Training loss: 1.586277961730957
Validation loss: 1.805006791186589

Epoch: 5| Step: 4
Training loss: 1.5565452575683594
Validation loss: 1.8218886262627059

Epoch: 5| Step: 5
Training loss: 0.923963725566864
Validation loss: 1.7990606664329447

Epoch: 5| Step: 6
Training loss: 1.5917710065841675
Validation loss: 1.8143903004225863

Epoch: 5| Step: 7
Training loss: 1.3286162614822388
Validation loss: 1.8247068979406869

Epoch: 5| Step: 8
Training loss: 1.6074244976043701
Validation loss: 1.858414956318435

Epoch: 5| Step: 9
Training loss: 1.3740160465240479
Validation loss: 1.8007651689232036

Epoch: 5| Step: 10
Training loss: 1.6920865774154663
Validation loss: 1.8247618931595997

Epoch: 346| Step: 0
Training loss: 1.517855167388916
Validation loss: 1.8400873727695917

Epoch: 5| Step: 1
Training loss: 1.625244140625
Validation loss: 1.827265966323114

Epoch: 5| Step: 2
Training loss: 1.4304332733154297
Validation loss: 1.8303079835830196

Epoch: 5| Step: 3
Training loss: 1.1762962341308594
Validation loss: 1.792526323308227

Epoch: 5| Step: 4
Training loss: 1.0977160930633545
Validation loss: 1.862172939444101

Epoch: 5| Step: 5
Training loss: 1.8324295282363892
Validation loss: 1.8645296173710977

Epoch: 5| Step: 6
Training loss: 1.2160696983337402
Validation loss: 1.8496900950708697

Epoch: 5| Step: 7
Training loss: 1.3831623792648315
Validation loss: 1.8866808465732041

Epoch: 5| Step: 8
Training loss: 1.682990312576294
Validation loss: 1.9087130792679325

Epoch: 5| Step: 9
Training loss: 1.7315998077392578
Validation loss: 1.8508180136321692

Epoch: 5| Step: 10
Training loss: 0.9261987209320068
Validation loss: 1.8271124145036102

Epoch: 347| Step: 0
Training loss: 1.472245693206787
Validation loss: 1.8410360146594305

Epoch: 5| Step: 1
Training loss: 1.9075924158096313
Validation loss: 1.8140662216371106

Epoch: 5| Step: 2
Training loss: 1.4235212802886963
Validation loss: 1.8173807154419601

Epoch: 5| Step: 3
Training loss: 1.3346176147460938
Validation loss: 1.8464467115299676

Epoch: 5| Step: 4
Training loss: 0.9029281735420227
Validation loss: 1.8802427437997633

Epoch: 5| Step: 5
Training loss: 1.442988395690918
Validation loss: 1.8289105917817803

Epoch: 5| Step: 6
Training loss: 1.2098342180252075
Validation loss: 1.8565297344679474

Epoch: 5| Step: 7
Training loss: 1.0366472005844116
Validation loss: 1.8476237532913045

Epoch: 5| Step: 8
Training loss: 1.4592608213424683
Validation loss: 1.8222713444822578

Epoch: 5| Step: 9
Training loss: 2.273017406463623
Validation loss: 1.8658476721855901

Epoch: 5| Step: 10
Training loss: 1.3290338516235352
Validation loss: 1.7699116288974721

Epoch: 348| Step: 0
Training loss: 1.284083604812622
Validation loss: 1.8385992268080353

Epoch: 5| Step: 1
Training loss: 1.3043421506881714
Validation loss: 1.851259942977659

Epoch: 5| Step: 2
Training loss: 1.2859587669372559
Validation loss: 1.8663816170025898

Epoch: 5| Step: 3
Training loss: 1.9851738214492798
Validation loss: 1.8078164259592693

Epoch: 5| Step: 4
Training loss: 1.0745726823806763
Validation loss: 1.8345320365762199

Epoch: 5| Step: 5
Training loss: 1.7329460382461548
Validation loss: 1.7768394690687939

Epoch: 5| Step: 6
Training loss: 1.4968845844268799
Validation loss: 1.8735260963439941

Epoch: 5| Step: 7
Training loss: 0.9852469563484192
Validation loss: 1.8085399058557325

Epoch: 5| Step: 8
Training loss: 1.3078184127807617
Validation loss: 1.871002717684674

Epoch: 5| Step: 9
Training loss: 1.4437878131866455
Validation loss: 1.8669486289383264

Epoch: 5| Step: 10
Training loss: 1.4426443576812744
Validation loss: 1.7891818810534734

Epoch: 349| Step: 0
Training loss: 1.3325488567352295
Validation loss: 1.8146941046560965

Epoch: 5| Step: 1
Training loss: 1.5011687278747559
Validation loss: 1.7808351965360745

Epoch: 5| Step: 2
Training loss: 1.916709542274475
Validation loss: 1.862803973177428

Epoch: 5| Step: 3
Training loss: 1.2570656538009644
Validation loss: 1.8477276320098548

Epoch: 5| Step: 4
Training loss: 1.271640419960022
Validation loss: 1.8544141682245399

Epoch: 5| Step: 5
Training loss: 2.161062479019165
Validation loss: 1.836854603982741

Epoch: 5| Step: 6
Training loss: 1.8525950908660889
Validation loss: 1.7920476749379148

Epoch: 5| Step: 7
Training loss: 1.5321855545043945
Validation loss: 1.8189029501330467

Epoch: 5| Step: 8
Training loss: 1.3716076612472534
Validation loss: 1.8238127244416105

Epoch: 5| Step: 9
Training loss: 0.9458862543106079
Validation loss: 1.8282448373815066

Epoch: 5| Step: 10
Training loss: 0.9386844635009766
Validation loss: 1.8434305755040978

Epoch: 350| Step: 0
Training loss: 1.0772138833999634
Validation loss: 1.8721239643712198

Epoch: 5| Step: 1
Training loss: 1.3632347583770752
Validation loss: 1.8446861018416703

Epoch: 5| Step: 2
Training loss: 1.3250477313995361
Validation loss: 1.8910548866436045

Epoch: 5| Step: 3
Training loss: 1.7355047464370728
Validation loss: 1.8725846967389506

Epoch: 5| Step: 4
Training loss: 1.7689472436904907
Validation loss: 1.8904065752542147

Epoch: 5| Step: 5
Training loss: 1.2715344429016113
Validation loss: 1.9098336235169442

Epoch: 5| Step: 6
Training loss: 1.3114534616470337
Validation loss: 1.9020567363308323

Epoch: 5| Step: 7
Training loss: 1.5109387636184692
Validation loss: 1.8745695775555027

Epoch: 5| Step: 8
Training loss: 1.141575574874878
Validation loss: 1.881154937128867

Epoch: 5| Step: 9
Training loss: 1.743172287940979
Validation loss: 1.8160615954347836

Epoch: 5| Step: 10
Training loss: 1.7909952402114868
Validation loss: 1.8350780446042296

Epoch: 351| Step: 0
Training loss: 1.3309370279312134
Validation loss: 1.8456517650235085

Epoch: 5| Step: 1
Training loss: 1.2565248012542725
Validation loss: 1.8633430298938547

Epoch: 5| Step: 2
Training loss: 1.4809415340423584
Validation loss: 1.8189100655176307

Epoch: 5| Step: 3
Training loss: 1.5729172229766846
Validation loss: 1.8268533804083382

Epoch: 5| Step: 4
Training loss: 1.1826223134994507
Validation loss: 1.8645571277987572

Epoch: 5| Step: 5
Training loss: 1.6004650592803955
Validation loss: 1.858638245572326

Epoch: 5| Step: 6
Training loss: 1.4490965604782104
Validation loss: 1.8339958216554375

Epoch: 5| Step: 7
Training loss: 1.3674920797348022
Validation loss: 1.8441439790110434

Epoch: 5| Step: 8
Training loss: 1.0901453495025635
Validation loss: 1.8549225714898878

Epoch: 5| Step: 9
Training loss: 1.2320482730865479
Validation loss: 1.8848172785133444

Epoch: 5| Step: 10
Training loss: 2.1205153465270996
Validation loss: 1.831557950665874

Epoch: 352| Step: 0
Training loss: 1.4436613321304321
Validation loss: 1.7909303608761038

Epoch: 5| Step: 1
Training loss: 1.6733710765838623
Validation loss: 1.8385270628877866

Epoch: 5| Step: 2
Training loss: 0.930631160736084
Validation loss: 1.8073214625799527

Epoch: 5| Step: 3
Training loss: 1.7773946523666382
Validation loss: 1.7803395396919661

Epoch: 5| Step: 4
Training loss: 1.4200830459594727
Validation loss: 1.8285277915257279

Epoch: 5| Step: 5
Training loss: 1.0093075037002563
Validation loss: 1.8366883993148804

Epoch: 5| Step: 6
Training loss: 1.9389123916625977
Validation loss: 1.8477229546475153

Epoch: 5| Step: 7
Training loss: 1.7099870443344116
Validation loss: 1.857453852571467

Epoch: 5| Step: 8
Training loss: 1.1060593128204346
Validation loss: 1.8233426578583256

Epoch: 5| Step: 9
Training loss: 0.8067702054977417
Validation loss: 1.84999853949393

Epoch: 5| Step: 10
Training loss: 1.8628990650177002
Validation loss: 1.836312133778808

Epoch: 353| Step: 0
Training loss: 1.3614414930343628
Validation loss: 1.8405592877377746

Epoch: 5| Step: 1
Training loss: 1.5451281070709229
Validation loss: 1.8618715424691477

Epoch: 5| Step: 2
Training loss: 1.557372808456421
Validation loss: 1.8379492041885213

Epoch: 5| Step: 3
Training loss: 1.3976114988327026
Validation loss: 1.8943749755941413

Epoch: 5| Step: 4
Training loss: 1.1878564357757568
Validation loss: 1.8453018178222

Epoch: 5| Step: 5
Training loss: 1.495467185974121
Validation loss: 1.7923948508436962

Epoch: 5| Step: 6
Training loss: 1.6008551120758057
Validation loss: 1.8797137442455496

Epoch: 5| Step: 7
Training loss: 1.6697616577148438
Validation loss: 1.858506142452199

Epoch: 5| Step: 8
Training loss: 0.6166190505027771
Validation loss: 1.9049829398432085

Epoch: 5| Step: 9
Training loss: 1.3352327346801758
Validation loss: 1.8171036217802314

Epoch: 5| Step: 10
Training loss: 1.721669316291809
Validation loss: 1.8523184714778778

Epoch: 354| Step: 0
Training loss: 1.3833043575286865
Validation loss: 1.8134585195972073

Epoch: 5| Step: 1
Training loss: 1.3479125499725342
Validation loss: 1.8459764347281507

Epoch: 5| Step: 2
Training loss: 1.1397773027420044
Validation loss: 1.8316423085428053

Epoch: 5| Step: 3
Training loss: 1.6777231693267822
Validation loss: 1.8311767808852657

Epoch: 5| Step: 4
Training loss: 1.4915193319320679
Validation loss: 1.7983667978676416

Epoch: 5| Step: 5
Training loss: 1.2521617412567139
Validation loss: 1.825196796847928

Epoch: 5| Step: 6
Training loss: 1.3119714260101318
Validation loss: 1.8374008927294003

Epoch: 5| Step: 7
Training loss: 1.4962317943572998
Validation loss: 1.8092986858019264

Epoch: 5| Step: 8
Training loss: 1.3756093978881836
Validation loss: 1.77248243875401

Epoch: 5| Step: 9
Training loss: 1.2440941333770752
Validation loss: 1.811917148610597

Epoch: 5| Step: 10
Training loss: 1.7974108457565308
Validation loss: 1.8476565320004699

Epoch: 355| Step: 0
Training loss: 1.4388030767440796
Validation loss: 1.7962242582792878

Epoch: 5| Step: 1
Training loss: 1.9327434301376343
Validation loss: 1.8240158365618797

Epoch: 5| Step: 2
Training loss: 1.1480567455291748
Validation loss: 1.8069509254988803

Epoch: 5| Step: 3
Training loss: 1.4509992599487305
Validation loss: 1.8395807102162351

Epoch: 5| Step: 4
Training loss: 1.3898308277130127
Validation loss: 1.8799802539169148

Epoch: 5| Step: 5
Training loss: 1.3126693964004517
Validation loss: 1.8474895710586219

Epoch: 5| Step: 6
Training loss: 0.97056645154953
Validation loss: 1.7881458907999017

Epoch: 5| Step: 7
Training loss: 1.354544997215271
Validation loss: 1.8099176140241726

Epoch: 5| Step: 8
Training loss: 1.5081640481948853
Validation loss: 1.8281512580892092

Epoch: 5| Step: 9
Training loss: 1.193564534187317
Validation loss: 1.8116730746402536

Epoch: 5| Step: 10
Training loss: 2.019045352935791
Validation loss: 1.8379703849874518

Epoch: 356| Step: 0
Training loss: 1.837384819984436
Validation loss: 1.8103614071364045

Epoch: 5| Step: 1
Training loss: 1.788365364074707
Validation loss: 1.7870887697383921

Epoch: 5| Step: 2
Training loss: 1.0980836153030396
Validation loss: 1.811428887869722

Epoch: 5| Step: 3
Training loss: 1.9907219409942627
Validation loss: 1.8022196600514073

Epoch: 5| Step: 4
Training loss: 1.40544855594635
Validation loss: 1.8235558053498626

Epoch: 5| Step: 5
Training loss: 1.1062164306640625
Validation loss: 1.7878490917144283

Epoch: 5| Step: 6
Training loss: 1.3594404458999634
Validation loss: 1.8317654696843957

Epoch: 5| Step: 7
Training loss: 1.3460451364517212
Validation loss: 1.8253918745184456

Epoch: 5| Step: 8
Training loss: 1.2190120220184326
Validation loss: 1.8160303715736634

Epoch: 5| Step: 9
Training loss: 1.6391042470932007
Validation loss: 1.8728096472319735

Epoch: 5| Step: 10
Training loss: 0.7176749110221863
Validation loss: 1.8036127385272775

Epoch: 357| Step: 0
Training loss: 1.32508385181427
Validation loss: 1.8490979568932646

Epoch: 5| Step: 1
Training loss: 1.0425924062728882
Validation loss: 1.8626042181445706

Epoch: 5| Step: 2
Training loss: 1.425837755203247
Validation loss: 1.8579744113388883

Epoch: 5| Step: 3
Training loss: 1.3940261602401733
Validation loss: 1.8902348472226052

Epoch: 5| Step: 4
Training loss: 2.1820297241210938
Validation loss: 1.8344644218362787

Epoch: 5| Step: 5
Training loss: 1.316571593284607
Validation loss: 1.8904395334182247

Epoch: 5| Step: 6
Training loss: 1.405601143836975
Validation loss: 1.8870843636092318

Epoch: 5| Step: 7
Training loss: 1.5087220668792725
Validation loss: 1.94409349144146

Epoch: 5| Step: 8
Training loss: 0.8362619280815125
Validation loss: 1.8550010291478967

Epoch: 5| Step: 9
Training loss: 1.8872976303100586
Validation loss: 1.8602661330212829

Epoch: 5| Step: 10
Training loss: 1.0924503803253174
Validation loss: 1.8411602358664236

Epoch: 358| Step: 0
Training loss: 1.1375916004180908
Validation loss: 1.8249959676496443

Epoch: 5| Step: 1
Training loss: 1.13173508644104
Validation loss: 1.828249110970446

Epoch: 5| Step: 2
Training loss: 1.723023772239685
Validation loss: 1.825894586501583

Epoch: 5| Step: 3
Training loss: 1.2836761474609375
Validation loss: 1.7959286653867332

Epoch: 5| Step: 4
Training loss: 1.7579253911972046
Validation loss: 1.8191555571812454

Epoch: 5| Step: 5
Training loss: 1.0319240093231201
Validation loss: 1.822831125669582

Epoch: 5| Step: 6
Training loss: 1.6090819835662842
Validation loss: 1.8511504242497105

Epoch: 5| Step: 7
Training loss: 1.159650444984436
Validation loss: 1.820845119414791

Epoch: 5| Step: 8
Training loss: 1.4918596744537354
Validation loss: 1.7546320371730353

Epoch: 5| Step: 9
Training loss: 1.6535406112670898
Validation loss: 1.816067805854223

Epoch: 5| Step: 10
Training loss: 1.4658259153366089
Validation loss: 1.8240970719245173

Epoch: 359| Step: 0
Training loss: 1.2169437408447266
Validation loss: 1.8207617293121994

Epoch: 5| Step: 1
Training loss: 1.334991693496704
Validation loss: 1.8526285361218195

Epoch: 5| Step: 2
Training loss: 1.389208436012268
Validation loss: 1.826672725780036

Epoch: 5| Step: 3
Training loss: 2.0583438873291016
Validation loss: 1.8083815561827792

Epoch: 5| Step: 4
Training loss: 1.2395942211151123
Validation loss: 1.8616228898366292

Epoch: 5| Step: 5
Training loss: 1.12978196144104
Validation loss: 1.831953187142649

Epoch: 5| Step: 6
Training loss: 1.1637852191925049
Validation loss: 1.815185905784689

Epoch: 5| Step: 7
Training loss: 1.2792203426361084
Validation loss: 1.8659067025748632

Epoch: 5| Step: 8
Training loss: 1.335573434829712
Validation loss: 1.829770790633335

Epoch: 5| Step: 9
Training loss: 1.5188480615615845
Validation loss: 1.8660566012064617

Epoch: 5| Step: 10
Training loss: 1.6126197576522827
Validation loss: 1.8669898997070968

Epoch: 360| Step: 0
Training loss: 1.0340241193771362
Validation loss: 1.855152137817875

Epoch: 5| Step: 1
Training loss: 1.1928493976593018
Validation loss: 1.8994608643234416

Epoch: 5| Step: 2
Training loss: 1.5286638736724854
Validation loss: 1.864169825789749

Epoch: 5| Step: 3
Training loss: 1.216632604598999
Validation loss: 1.8604948392478369

Epoch: 5| Step: 4
Training loss: 1.363740086555481
Validation loss: 1.8682420958754837

Epoch: 5| Step: 5
Training loss: 2.248584747314453
Validation loss: 1.8532408040056947

Epoch: 5| Step: 6
Training loss: 1.8215587139129639
Validation loss: 1.877558180080947

Epoch: 5| Step: 7
Training loss: 1.5319621562957764
Validation loss: 1.871209054864863

Epoch: 5| Step: 8
Training loss: 1.244750738143921
Validation loss: 1.8919310185217089

Epoch: 5| Step: 9
Training loss: 1.031186580657959
Validation loss: 1.8872381589745963

Epoch: 5| Step: 10
Training loss: 1.058496356010437
Validation loss: 1.8162940240675403

Epoch: 361| Step: 0
Training loss: 1.8821094036102295
Validation loss: 1.8431510233109998

Epoch: 5| Step: 1
Training loss: 1.607672095298767
Validation loss: 1.867858297081404

Epoch: 5| Step: 2
Training loss: 0.8877959251403809
Validation loss: 1.9068539962973645

Epoch: 5| Step: 3
Training loss: 1.389785647392273
Validation loss: 1.859187364578247

Epoch: 5| Step: 4
Training loss: 1.5895036458969116
Validation loss: 1.8477326670000631

Epoch: 5| Step: 5
Training loss: 1.386134147644043
Validation loss: 1.808590353176158

Epoch: 5| Step: 6
Training loss: 1.3526599407196045
Validation loss: 1.812567203275619

Epoch: 5| Step: 7
Training loss: 1.3844650983810425
Validation loss: 1.858433400430987

Epoch: 5| Step: 8
Training loss: 0.9722736477851868
Validation loss: 1.8573851559751777

Epoch: 5| Step: 9
Training loss: 1.307051420211792
Validation loss: 1.8614309231440227

Epoch: 5| Step: 10
Training loss: 1.7232277393341064
Validation loss: 1.8630086401457429

Epoch: 362| Step: 0
Training loss: 1.7399368286132812
Validation loss: 1.8676645294312508

Epoch: 5| Step: 1
Training loss: 1.2727277278900146
Validation loss: 1.8864478565031482

Epoch: 5| Step: 2
Training loss: 1.4215929508209229
Validation loss: 1.8394741448022986

Epoch: 5| Step: 3
Training loss: 1.4681017398834229
Validation loss: 1.8699803416446974

Epoch: 5| Step: 4
Training loss: 1.533179521560669
Validation loss: 1.8578765776849562

Epoch: 5| Step: 5
Training loss: 1.3361690044403076
Validation loss: 1.8256416564346643

Epoch: 5| Step: 6
Training loss: 1.1026781797409058
Validation loss: 1.859157290509952

Epoch: 5| Step: 7
Training loss: 1.0996136665344238
Validation loss: 1.8156658757117488

Epoch: 5| Step: 8
Training loss: 0.9511417150497437
Validation loss: 1.8463451529061923

Epoch: 5| Step: 9
Training loss: 1.6643444299697876
Validation loss: 1.8143371753795172

Epoch: 5| Step: 10
Training loss: 1.4839706420898438
Validation loss: 1.8549119451994538

Epoch: 363| Step: 0
Training loss: 1.2532683610916138
Validation loss: 1.87257799794597

Epoch: 5| Step: 1
Training loss: 0.9870999455451965
Validation loss: 1.7957759582868187

Epoch: 5| Step: 2
Training loss: 1.4954164028167725
Validation loss: 1.8310615119113718

Epoch: 5| Step: 3
Training loss: 1.829622507095337
Validation loss: 1.8370418676766016

Epoch: 5| Step: 4
Training loss: 1.5416959524154663
Validation loss: 1.835132674504352

Epoch: 5| Step: 5
Training loss: 1.213598370552063
Validation loss: 1.8401598840631463

Epoch: 5| Step: 6
Training loss: 1.7454391717910767
Validation loss: 1.8776434903503747

Epoch: 5| Step: 7
Training loss: 0.7874094247817993
Validation loss: 1.82253017733174

Epoch: 5| Step: 8
Training loss: 1.179443120956421
Validation loss: 1.9023616903571672

Epoch: 5| Step: 9
Training loss: 1.6225979328155518
Validation loss: 1.9038038715239494

Epoch: 5| Step: 10
Training loss: 1.5364408493041992
Validation loss: 1.8498723865837179

Epoch: 364| Step: 0
Training loss: 1.5954859256744385
Validation loss: 1.8272444509690808

Epoch: 5| Step: 1
Training loss: 1.9878584146499634
Validation loss: 1.8327069949078303

Epoch: 5| Step: 2
Training loss: 1.4051674604415894
Validation loss: 1.860819749934699

Epoch: 5| Step: 3
Training loss: 1.473768949508667
Validation loss: 1.8501669142835884

Epoch: 5| Step: 4
Training loss: 1.5535216331481934
Validation loss: 1.8504745421871063

Epoch: 5| Step: 5
Training loss: 0.8989493250846863
Validation loss: 1.9337560848523212

Epoch: 5| Step: 6
Training loss: 1.1795412302017212
Validation loss: 1.8632185933410481

Epoch: 5| Step: 7
Training loss: 1.215977430343628
Validation loss: 1.8312466298380206

Epoch: 5| Step: 8
Training loss: 1.280074954032898
Validation loss: 1.8869957564979472

Epoch: 5| Step: 9
Training loss: 1.159935712814331
Validation loss: 1.824100302111718

Epoch: 5| Step: 10
Training loss: 1.5851205587387085
Validation loss: 1.8393339880051152

Epoch: 365| Step: 0
Training loss: 1.6961971521377563
Validation loss: 1.8015048632057764

Epoch: 5| Step: 1
Training loss: 1.5983057022094727
Validation loss: 1.8382710551702848

Epoch: 5| Step: 2
Training loss: 1.5187537670135498
Validation loss: 1.8302245575894591

Epoch: 5| Step: 3
Training loss: 1.6727920770645142
Validation loss: 1.8876717154697706

Epoch: 5| Step: 4
Training loss: 0.9776527285575867
Validation loss: 1.8861085061104066

Epoch: 5| Step: 5
Training loss: 1.5623738765716553
Validation loss: 1.864848252265684

Epoch: 5| Step: 6
Training loss: 1.0541245937347412
Validation loss: 1.8400612928534066

Epoch: 5| Step: 7
Training loss: 1.109603762626648
Validation loss: 1.8276616386187974

Epoch: 5| Step: 8
Training loss: 1.5396581888198853
Validation loss: 1.8506693224753104

Epoch: 5| Step: 9
Training loss: 0.8982492685317993
Validation loss: 1.8095310400891047

Epoch: 5| Step: 10
Training loss: 1.1602134704589844
Validation loss: 1.8924060713860296

Epoch: 366| Step: 0
Training loss: 1.1732540130615234
Validation loss: 1.8388500098259217

Epoch: 5| Step: 1
Training loss: 1.050301194190979
Validation loss: 1.8508093651904856

Epoch: 5| Step: 2
Training loss: 1.9223133325576782
Validation loss: 1.8263135199905725

Epoch: 5| Step: 3
Training loss: 1.3600002527236938
Validation loss: 1.7545396858646023

Epoch: 5| Step: 4
Training loss: 1.5801494121551514
Validation loss: 1.8190593975846485

Epoch: 5| Step: 5
Training loss: 1.0071887969970703
Validation loss: 1.8299015337421047

Epoch: 5| Step: 6
Training loss: 1.1360183954238892
Validation loss: 1.8629244194235852

Epoch: 5| Step: 7
Training loss: 1.8453330993652344
Validation loss: 1.8832529731976089

Epoch: 5| Step: 8
Training loss: 1.318541407585144
Validation loss: 1.8236628091463478

Epoch: 5| Step: 9
Training loss: 0.9411218762397766
Validation loss: 1.7787634236838228

Epoch: 5| Step: 10
Training loss: 1.4569807052612305
Validation loss: 1.8574424277069748

Epoch: 367| Step: 0
Training loss: 1.217623233795166
Validation loss: 1.8565509678215109

Epoch: 5| Step: 1
Training loss: 1.8137699365615845
Validation loss: 1.8336539806858185

Epoch: 5| Step: 2
Training loss: 1.9187848567962646
Validation loss: 1.8411913187273088

Epoch: 5| Step: 3
Training loss: 1.2241421937942505
Validation loss: 1.8105942433880222

Epoch: 5| Step: 4
Training loss: 1.5897095203399658
Validation loss: 1.8753458735763386

Epoch: 5| Step: 5
Training loss: 0.8842952847480774
Validation loss: 1.8823635078245593

Epoch: 5| Step: 6
Training loss: 1.098251223564148
Validation loss: 1.9104456004276071

Epoch: 5| Step: 7
Training loss: 1.513674020767212
Validation loss: 1.8848586326004357

Epoch: 5| Step: 8
Training loss: 1.3360813856124878
Validation loss: 1.940966188266713

Epoch: 5| Step: 9
Training loss: 1.3782365322113037
Validation loss: 1.8570414743115824

Epoch: 5| Step: 10
Training loss: 1.1320006847381592
Validation loss: 1.8131740708504953

Epoch: 368| Step: 0
Training loss: 1.3330726623535156
Validation loss: 1.8565905440238215

Epoch: 5| Step: 1
Training loss: 1.5089499950408936
Validation loss: 1.8640409413204397

Epoch: 5| Step: 2
Training loss: 1.210054636001587
Validation loss: 1.808635675778953

Epoch: 5| Step: 3
Training loss: 1.3270635604858398
Validation loss: 1.8139875781151555

Epoch: 5| Step: 4
Training loss: 1.271206021308899
Validation loss: 1.8035261041374617

Epoch: 5| Step: 5
Training loss: 1.5520048141479492
Validation loss: 1.8227298003371044

Epoch: 5| Step: 6
Training loss: 1.1623989343643188
Validation loss: 1.8277682271054996

Epoch: 5| Step: 7
Training loss: 1.4836533069610596
Validation loss: 1.8121092652761808

Epoch: 5| Step: 8
Training loss: 1.3602514266967773
Validation loss: 1.8570523787570257

Epoch: 5| Step: 9
Training loss: 1.2949556112289429
Validation loss: 1.8188335946811143

Epoch: 5| Step: 10
Training loss: 1.6156251430511475
Validation loss: 1.83610289583924

Epoch: 369| Step: 0
Training loss: 1.8685142993927002
Validation loss: 1.860018519945042

Epoch: 5| Step: 1
Training loss: 1.002020239830017
Validation loss: 1.824286751849677

Epoch: 5| Step: 2
Training loss: 1.2005614042282104
Validation loss: 1.8551300661538237

Epoch: 5| Step: 3
Training loss: 1.1266692876815796
Validation loss: 1.8266756380757978

Epoch: 5| Step: 4
Training loss: 0.6505856513977051
Validation loss: 1.8736836243701238

Epoch: 5| Step: 5
Training loss: 1.4896143674850464
Validation loss: 1.85990156409561

Epoch: 5| Step: 6
Training loss: 1.6118056774139404
Validation loss: 1.8612386936782508

Epoch: 5| Step: 7
Training loss: 1.5954535007476807
Validation loss: 1.860290442743609

Epoch: 5| Step: 8
Training loss: 1.8743648529052734
Validation loss: 1.854828284632775

Epoch: 5| Step: 9
Training loss: 1.14840567111969
Validation loss: 1.8808643176991453

Epoch: 5| Step: 10
Training loss: 1.0360867977142334
Validation loss: 1.8879868035675378

Epoch: 370| Step: 0
Training loss: 1.7893493175506592
Validation loss: 1.897345910790146

Epoch: 5| Step: 1
Training loss: 1.281684398651123
Validation loss: 1.9251061408750472

Epoch: 5| Step: 2
Training loss: 1.1856492757797241
Validation loss: 1.866442673308875

Epoch: 5| Step: 3
Training loss: 1.0059858560562134
Validation loss: 1.9197797365086053

Epoch: 5| Step: 4
Training loss: 1.7045135498046875
Validation loss: 1.8305700914834135

Epoch: 5| Step: 5
Training loss: 1.331374168395996
Validation loss: 1.8431353735667404

Epoch: 5| Step: 6
Training loss: 1.274471640586853
Validation loss: 1.824971765600225

Epoch: 5| Step: 7
Training loss: 0.9223699569702148
Validation loss: 1.843384006971954

Epoch: 5| Step: 8
Training loss: 1.0808382034301758
Validation loss: 1.7986988508573143

Epoch: 5| Step: 9
Training loss: 1.302715539932251
Validation loss: 1.8387695089463265

Epoch: 5| Step: 10
Training loss: 2.053818464279175
Validation loss: 1.8579635812390236

Epoch: 371| Step: 0
Training loss: 1.6237894296646118
Validation loss: 1.86578280438659

Epoch: 5| Step: 1
Training loss: 1.4891908168792725
Validation loss: 1.8243400460930281

Epoch: 5| Step: 2
Training loss: 1.5820977687835693
Validation loss: 1.8011488760671308

Epoch: 5| Step: 3
Training loss: 1.5803864002227783
Validation loss: 1.8170282097272976

Epoch: 5| Step: 4
Training loss: 1.3331336975097656
Validation loss: 1.8220015052826173

Epoch: 5| Step: 5
Training loss: 1.271138310432434
Validation loss: 1.8830430392296083

Epoch: 5| Step: 6
Training loss: 1.3770002126693726
Validation loss: 1.838785466327462

Epoch: 5| Step: 7
Training loss: 1.1538612842559814
Validation loss: 1.849910964248001

Epoch: 5| Step: 8
Training loss: 1.1105096340179443
Validation loss: 1.865313651741192

Epoch: 5| Step: 9
Training loss: 1.0203222036361694
Validation loss: 1.8755927701150217

Epoch: 5| Step: 10
Training loss: 1.6673669815063477
Validation loss: 1.829778399518741

Epoch: 372| Step: 0
Training loss: 1.146828532218933
Validation loss: 1.8123252904543312

Epoch: 5| Step: 1
Training loss: 1.5081901550292969
Validation loss: 1.8158317265972015

Epoch: 5| Step: 2
Training loss: 1.1006019115447998
Validation loss: 1.8196701183114001

Epoch: 5| Step: 3
Training loss: 1.492417335510254
Validation loss: 1.8071302649795369

Epoch: 5| Step: 4
Training loss: 1.5777051448822021
Validation loss: 1.8542024063807663

Epoch: 5| Step: 5
Training loss: 1.5290402173995972
Validation loss: 1.8579145157209007

Epoch: 5| Step: 6
Training loss: 1.4167579412460327
Validation loss: 1.8558062532896638

Epoch: 5| Step: 7
Training loss: 1.4207350015640259
Validation loss: 1.8177997745493406

Epoch: 5| Step: 8
Training loss: 1.5876717567443848
Validation loss: 1.7836361059578516

Epoch: 5| Step: 9
Training loss: 1.2280309200286865
Validation loss: 1.8111777767058341

Epoch: 5| Step: 10
Training loss: 1.018797516822815
Validation loss: 1.8263955795636742

Epoch: 373| Step: 0
Training loss: 1.1465963125228882
Validation loss: 1.8151352649093957

Epoch: 5| Step: 1
Training loss: 0.5587363243103027
Validation loss: 1.8518396051981116

Epoch: 5| Step: 2
Training loss: 1.9667892456054688
Validation loss: 1.828216778334751

Epoch: 5| Step: 3
Training loss: 1.3368242979049683
Validation loss: 1.8938100248254754

Epoch: 5| Step: 4
Training loss: 1.4022572040557861
Validation loss: 1.8545545326766146

Epoch: 5| Step: 5
Training loss: 1.2940795421600342
Validation loss: 1.8900230187241749

Epoch: 5| Step: 6
Training loss: 1.5658519268035889
Validation loss: 1.8716916589326755

Epoch: 5| Step: 7
Training loss: 1.249392032623291
Validation loss: 1.847219910672916

Epoch: 5| Step: 8
Training loss: 1.2564738988876343
Validation loss: 1.9273670745152298

Epoch: 5| Step: 9
Training loss: 1.3734112977981567
Validation loss: 1.8467758137692687

Epoch: 5| Step: 10
Training loss: 1.7971094846725464
Validation loss: 1.8228196347913435

Epoch: 374| Step: 0
Training loss: 1.3385690450668335
Validation loss: 1.8269063067692581

Epoch: 5| Step: 1
Training loss: 1.733407974243164
Validation loss: 1.8031160549450946

Epoch: 5| Step: 2
Training loss: 1.2470003366470337
Validation loss: 1.8200237276733562

Epoch: 5| Step: 3
Training loss: 1.2149560451507568
Validation loss: 1.7907950416687997

Epoch: 5| Step: 4
Training loss: 0.8709875345230103
Validation loss: 1.852716709977837

Epoch: 5| Step: 5
Training loss: 1.2721182107925415
Validation loss: 1.7995141142158098

Epoch: 5| Step: 6
Training loss: 1.148118257522583
Validation loss: 1.8192618982766264

Epoch: 5| Step: 7
Training loss: 1.4489223957061768
Validation loss: 1.8417392135948263

Epoch: 5| Step: 8
Training loss: 1.337501883506775
Validation loss: 1.8087102149122505

Epoch: 5| Step: 9
Training loss: 1.470762014389038
Validation loss: 1.8470353734108709

Epoch: 5| Step: 10
Training loss: 1.757203459739685
Validation loss: 1.8711870895918978

Epoch: 375| Step: 0
Training loss: 1.1226375102996826
Validation loss: 1.8479078405646867

Epoch: 5| Step: 1
Training loss: 1.0623891353607178
Validation loss: 1.8369614129425378

Epoch: 5| Step: 2
Training loss: 1.6566635370254517
Validation loss: 1.7830720780998148

Epoch: 5| Step: 3
Training loss: 0.9577947854995728
Validation loss: 1.7630763425621936

Epoch: 5| Step: 4
Training loss: 1.414674162864685
Validation loss: 1.875375755371586

Epoch: 5| Step: 5
Training loss: 1.2936869859695435
Validation loss: 1.8161986489449777

Epoch: 5| Step: 6
Training loss: 1.383535385131836
Validation loss: 1.8431900111577844

Epoch: 5| Step: 7
Training loss: 1.3269734382629395
Validation loss: 1.8947993670740435

Epoch: 5| Step: 8
Training loss: 1.3376033306121826
Validation loss: 1.9145688472255584

Epoch: 5| Step: 9
Training loss: 1.321276307106018
Validation loss: 1.8446028437665714

Epoch: 5| Step: 10
Training loss: 1.6437151432037354
Validation loss: 1.8332643611456758

Epoch: 376| Step: 0
Training loss: 0.9606958627700806
Validation loss: 1.8056351318154285

Epoch: 5| Step: 1
Training loss: 1.010140061378479
Validation loss: 1.8120339314142864

Epoch: 5| Step: 2
Training loss: 2.0663886070251465
Validation loss: 1.8426007006758003

Epoch: 5| Step: 3
Training loss: 0.9685564041137695
Validation loss: 1.8725725104731898

Epoch: 5| Step: 4
Training loss: 1.21623957157135
Validation loss: 1.8297858981675998

Epoch: 5| Step: 5
Training loss: 1.5070399045944214
Validation loss: 1.8388110001881917

Epoch: 5| Step: 6
Training loss: 2.0539443492889404
Validation loss: 1.850569563527261

Epoch: 5| Step: 7
Training loss: 1.3254241943359375
Validation loss: 1.8062560968501593

Epoch: 5| Step: 8
Training loss: 0.8947769999504089
Validation loss: 1.834756826841703

Epoch: 5| Step: 9
Training loss: 1.3427438735961914
Validation loss: 1.8586435394902383

Epoch: 5| Step: 10
Training loss: 1.138207197189331
Validation loss: 1.829035610281011

Epoch: 377| Step: 0
Training loss: 1.4924237728118896
Validation loss: 1.8883735992575204

Epoch: 5| Step: 1
Training loss: 1.8783235549926758
Validation loss: 1.8642567562800583

Epoch: 5| Step: 2
Training loss: 0.9990107417106628
Validation loss: 1.873866306838169

Epoch: 5| Step: 3
Training loss: 1.5208028554916382
Validation loss: 1.8829285073023971

Epoch: 5| Step: 4
Training loss: 1.300797462463379
Validation loss: 1.8865937199643863

Epoch: 5| Step: 5
Training loss: 1.262669563293457
Validation loss: 1.860851913370112

Epoch: 5| Step: 6
Training loss: 1.4477876424789429
Validation loss: 1.8886639636049989

Epoch: 5| Step: 7
Training loss: 1.0830490589141846
Validation loss: 1.9079607481597571

Epoch: 5| Step: 8
Training loss: 1.0283526182174683
Validation loss: 1.928567381315334

Epoch: 5| Step: 9
Training loss: 1.329537272453308
Validation loss: 1.8577419660424674

Epoch: 5| Step: 10
Training loss: 1.3662205934524536
Validation loss: 1.8765283630740257

Epoch: 378| Step: 0
Training loss: 1.0593128204345703
Validation loss: 1.8763073195693314

Epoch: 5| Step: 1
Training loss: 1.0056368112564087
Validation loss: 1.8273832131457586

Epoch: 5| Step: 2
Training loss: 1.484979271888733
Validation loss: 1.8605369931908065

Epoch: 5| Step: 3
Training loss: 1.6737711429595947
Validation loss: 1.8749289333179433

Epoch: 5| Step: 4
Training loss: 1.2699131965637207
Validation loss: 1.8134770335689667

Epoch: 5| Step: 5
Training loss: 1.4587860107421875
Validation loss: 1.8536001046498616

Epoch: 5| Step: 6
Training loss: 1.3312909603118896
Validation loss: 1.8358647028605144

Epoch: 5| Step: 7
Training loss: 1.4360630512237549
Validation loss: 1.8408813117652811

Epoch: 5| Step: 8
Training loss: 1.4695030450820923
Validation loss: 1.8478901706716067

Epoch: 5| Step: 9
Training loss: 1.1276136636734009
Validation loss: 1.8135202623182727

Epoch: 5| Step: 10
Training loss: 1.329126000404358
Validation loss: 1.8075558626523582

Epoch: 379| Step: 0
Training loss: 1.9774081707000732
Validation loss: 1.8629920521090109

Epoch: 5| Step: 1
Training loss: 1.3808164596557617
Validation loss: 1.8657825851953158

Epoch: 5| Step: 2
Training loss: 1.2891724109649658
Validation loss: 1.8524928733866701

Epoch: 5| Step: 3
Training loss: 1.4549479484558105
Validation loss: 1.7886374573553763

Epoch: 5| Step: 4
Training loss: 2.085404634475708
Validation loss: 1.8116169450103596

Epoch: 5| Step: 5
Training loss: 0.5553314089775085
Validation loss: 1.804943044980367

Epoch: 5| Step: 6
Training loss: 1.0041224956512451
Validation loss: 1.7996384661684754

Epoch: 5| Step: 7
Training loss: 0.7757643461227417
Validation loss: 1.8419038711055633

Epoch: 5| Step: 8
Training loss: 1.116484522819519
Validation loss: 1.8540145376677155

Epoch: 5| Step: 9
Training loss: 1.362000823020935
Validation loss: 1.8450321587183143

Epoch: 5| Step: 10
Training loss: 1.7175158262252808
Validation loss: 1.8331646598795408

Epoch: 380| Step: 0
Training loss: 1.1907329559326172
Validation loss: 1.8462368442166237

Epoch: 5| Step: 1
Training loss: 1.3622304201126099
Validation loss: 1.8700558523977957

Epoch: 5| Step: 2
Training loss: 1.8362197875976562
Validation loss: 1.8552556166084864

Epoch: 5| Step: 3
Training loss: 1.6617698669433594
Validation loss: 1.8718551974142752

Epoch: 5| Step: 4
Training loss: 1.6707136631011963
Validation loss: 1.852234919865926

Epoch: 5| Step: 5
Training loss: 0.9650930166244507
Validation loss: 1.8827788009438464

Epoch: 5| Step: 6
Training loss: 1.551077127456665
Validation loss: 1.8714725484130204

Epoch: 5| Step: 7
Training loss: 1.2329589128494263
Validation loss: 1.7954927887967838

Epoch: 5| Step: 8
Training loss: 0.7034443616867065
Validation loss: 1.8363581113917853

Epoch: 5| Step: 9
Training loss: 1.529870629310608
Validation loss: 1.7816453787588304

Epoch: 5| Step: 10
Training loss: 1.4468852281570435
Validation loss: 1.7813562757225447

Epoch: 381| Step: 0
Training loss: 1.5570837259292603
Validation loss: 1.8084617776255454

Epoch: 5| Step: 1
Training loss: 1.7446664571762085
Validation loss: 1.8055268346622426

Epoch: 5| Step: 2
Training loss: 0.9940946698188782
Validation loss: 1.7517788358913955

Epoch: 5| Step: 3
Training loss: 0.9122998118400574
Validation loss: 1.7965332808033112

Epoch: 5| Step: 4
Training loss: 1.4046491384506226
Validation loss: 1.86042651566126

Epoch: 5| Step: 5
Training loss: 0.9878110885620117
Validation loss: 1.8388232620813514

Epoch: 5| Step: 6
Training loss: 1.3801320791244507
Validation loss: 1.8223024670795729

Epoch: 5| Step: 7
Training loss: 1.6100060939788818
Validation loss: 1.864610142605279

Epoch: 5| Step: 8
Training loss: 1.543790578842163
Validation loss: 1.8629791249511063

Epoch: 5| Step: 9
Training loss: 1.4784886837005615
Validation loss: 1.8261850277582805

Epoch: 5| Step: 10
Training loss: 1.1562128067016602
Validation loss: 1.8622729022015807

Epoch: 382| Step: 0
Training loss: 1.5415875911712646
Validation loss: 1.8248124968621038

Epoch: 5| Step: 1
Training loss: 1.314637541770935
Validation loss: 1.8966751175542031

Epoch: 5| Step: 2
Training loss: 1.307146430015564
Validation loss: 1.8698449186099473

Epoch: 5| Step: 3
Training loss: 0.6015503406524658
Validation loss: 1.835058617335494

Epoch: 5| Step: 4
Training loss: 1.5609365701675415
Validation loss: 1.8388927085425264

Epoch: 5| Step: 5
Training loss: 1.2156518697738647
Validation loss: 1.8343859590509886

Epoch: 5| Step: 6
Training loss: 1.637425422668457
Validation loss: 1.853712680519268

Epoch: 5| Step: 7
Training loss: 1.3332233428955078
Validation loss: 1.8172250627189555

Epoch: 5| Step: 8
Training loss: 1.2467029094696045
Validation loss: 1.8292137563869517

Epoch: 5| Step: 9
Training loss: 1.0824145078659058
Validation loss: 1.8633870450399255

Epoch: 5| Step: 10
Training loss: 1.0839711427688599
Validation loss: 1.7899137876367057

Epoch: 383| Step: 0
Training loss: 0.8405748605728149
Validation loss: 1.8664035258754608

Epoch: 5| Step: 1
Training loss: 1.1025844812393188
Validation loss: 1.8427838561355427

Epoch: 5| Step: 2
Training loss: 1.0414817333221436
Validation loss: 1.7945752259223693

Epoch: 5| Step: 3
Training loss: 1.4838225841522217
Validation loss: 1.8025882449201358

Epoch: 5| Step: 4
Training loss: 1.6870266199111938
Validation loss: 1.7789804640636648

Epoch: 5| Step: 5
Training loss: 1.28139328956604
Validation loss: 1.831320337710842

Epoch: 5| Step: 6
Training loss: 1.7246010303497314
Validation loss: 1.8441972296725038

Epoch: 5| Step: 7
Training loss: 1.9352344274520874
Validation loss: 1.8355956487758185

Epoch: 5| Step: 8
Training loss: 1.095726728439331
Validation loss: 1.7977344835958173

Epoch: 5| Step: 9
Training loss: 1.2024786472320557
Validation loss: 1.8307570629222418

Epoch: 5| Step: 10
Training loss: 0.9305335879325867
Validation loss: 1.80674627647605

Epoch: 384| Step: 0
Training loss: 1.3716720342636108
Validation loss: 1.8176044161601732

Epoch: 5| Step: 1
Training loss: 1.1522125005722046
Validation loss: 1.8580307896419237

Epoch: 5| Step: 2
Training loss: 1.2194265127182007
Validation loss: 1.8715152138022966

Epoch: 5| Step: 3
Training loss: 1.4092233180999756
Validation loss: 1.8317879938310193

Epoch: 5| Step: 4
Training loss: 0.9318097829818726
Validation loss: 1.8388351073829077

Epoch: 5| Step: 5
Training loss: 1.5087672472000122
Validation loss: 1.7953927081118348

Epoch: 5| Step: 6
Training loss: 1.6597414016723633
Validation loss: 1.7967453720749065

Epoch: 5| Step: 7
Training loss: 0.8714199066162109
Validation loss: 1.8366917000021985

Epoch: 5| Step: 8
Training loss: 1.6884820461273193
Validation loss: 1.8292853793790262

Epoch: 5| Step: 9
Training loss: 0.7020451426506042
Validation loss: 1.817678274646882

Epoch: 5| Step: 10
Training loss: 1.8422373533248901
Validation loss: 1.7873814695624894

Epoch: 385| Step: 0
Training loss: 0.9447018504142761
Validation loss: 1.8108319236386208

Epoch: 5| Step: 1
Training loss: 1.511045217514038
Validation loss: 1.8324130465907436

Epoch: 5| Step: 2
Training loss: 1.192217469215393
Validation loss: 1.80427752002593

Epoch: 5| Step: 3
Training loss: 1.3143186569213867
Validation loss: 1.8459047937905917

Epoch: 5| Step: 4
Training loss: 1.0675714015960693
Validation loss: 1.7578532336860575

Epoch: 5| Step: 5
Training loss: 1.0179702043533325
Validation loss: 1.837168239778088

Epoch: 5| Step: 6
Training loss: 1.2687547206878662
Validation loss: 1.8333098221850652

Epoch: 5| Step: 7
Training loss: 1.1751207113265991
Validation loss: 1.829562843486827

Epoch: 5| Step: 8
Training loss: 1.2334587574005127
Validation loss: 1.868961113755421

Epoch: 5| Step: 9
Training loss: 1.7406272888183594
Validation loss: 1.8326780847323838

Epoch: 5| Step: 10
Training loss: 1.6607983112335205
Validation loss: 1.818887883617032

Epoch: 386| Step: 0
Training loss: 1.4448890686035156
Validation loss: 1.8329668160407775

Epoch: 5| Step: 1
Training loss: 1.2439275979995728
Validation loss: 1.8635455216130903

Epoch: 5| Step: 2
Training loss: 1.3729972839355469
Validation loss: 1.8376125956094393

Epoch: 5| Step: 3
Training loss: 1.5493872165679932
Validation loss: 1.8531434817980694

Epoch: 5| Step: 4
Training loss: 0.9183864593505859
Validation loss: 1.878986556042907

Epoch: 5| Step: 5
Training loss: 1.748549461364746
Validation loss: 1.8279579685580345

Epoch: 5| Step: 6
Training loss: 1.0564442873001099
Validation loss: 1.8591446991889709

Epoch: 5| Step: 7
Training loss: 1.2326279878616333
Validation loss: 1.8298364582882132

Epoch: 5| Step: 8
Training loss: 1.5373899936676025
Validation loss: 1.831233166238313

Epoch: 5| Step: 9
Training loss: 0.8764604330062866
Validation loss: 1.8601592381795247

Epoch: 5| Step: 10
Training loss: 1.4627139568328857
Validation loss: 1.8478414358631257

Epoch: 387| Step: 0
Training loss: 1.667925477027893
Validation loss: 1.8231377755441973

Epoch: 5| Step: 1
Training loss: 0.9992218017578125
Validation loss: 1.848589357509408

Epoch: 5| Step: 2
Training loss: 0.9051744341850281
Validation loss: 1.8316594657077585

Epoch: 5| Step: 3
Training loss: 1.4104715585708618
Validation loss: 1.8286782323673207

Epoch: 5| Step: 4
Training loss: 0.9132448434829712
Validation loss: 1.84883923428033

Epoch: 5| Step: 5
Training loss: 0.9815065264701843
Validation loss: 1.8236478426123177

Epoch: 5| Step: 6
Training loss: 1.755750298500061
Validation loss: 1.8111843537258845

Epoch: 5| Step: 7
Training loss: 2.3035168647766113
Validation loss: 1.806608364146243

Epoch: 5| Step: 8
Training loss: 0.8651026487350464
Validation loss: 1.837130190223776

Epoch: 5| Step: 9
Training loss: 1.4141861200332642
Validation loss: 1.9073019899347776

Epoch: 5| Step: 10
Training loss: 1.3874685764312744
Validation loss: 1.822325583427183

Epoch: 388| Step: 0
Training loss: 1.8273388147354126
Validation loss: 1.9414433484436364

Epoch: 5| Step: 1
Training loss: 1.0679471492767334
Validation loss: 1.862175742785136

Epoch: 5| Step: 2
Training loss: 1.2391016483306885
Validation loss: 1.8757539333835724

Epoch: 5| Step: 3
Training loss: 1.4127857685089111
Validation loss: 1.8598408763126661

Epoch: 5| Step: 4
Training loss: 1.7148621082305908
Validation loss: 1.8226522373896774

Epoch: 5| Step: 5
Training loss: 1.2807352542877197
Validation loss: 1.8378466329266947

Epoch: 5| Step: 6
Training loss: 1.3507835865020752
Validation loss: 1.7936056224248742

Epoch: 5| Step: 7
Training loss: 1.5755535364151
Validation loss: 1.8377442667561192

Epoch: 5| Step: 8
Training loss: 1.1674973964691162
Validation loss: 1.824615506715672

Epoch: 5| Step: 9
Training loss: 0.5981056094169617
Validation loss: 1.8631378989065848

Epoch: 5| Step: 10
Training loss: 1.2025465965270996
Validation loss: 1.8320800809450046

Epoch: 389| Step: 0
Training loss: 1.048407793045044
Validation loss: 1.8364302765938543

Epoch: 5| Step: 1
Training loss: 1.0558356046676636
Validation loss: 1.8420592277280745

Epoch: 5| Step: 2
Training loss: 1.6739362478256226
Validation loss: 1.8745430566931283

Epoch: 5| Step: 3
Training loss: 1.118329405784607
Validation loss: 1.7930712981890606

Epoch: 5| Step: 4
Training loss: 1.1745812892913818
Validation loss: 1.8724035383552633

Epoch: 5| Step: 5
Training loss: 1.3675676584243774
Validation loss: 1.8418319020220029

Epoch: 5| Step: 6
Training loss: 1.1545350551605225
Validation loss: 1.8409661939067226

Epoch: 5| Step: 7
Training loss: 1.4906084537506104
Validation loss: 1.8100866335694508

Epoch: 5| Step: 8
Training loss: 1.5451265573501587
Validation loss: 1.9053295889208395

Epoch: 5| Step: 9
Training loss: 1.3224834203720093
Validation loss: 1.851186583119054

Epoch: 5| Step: 10
Training loss: 1.2857484817504883
Validation loss: 1.8730451535153132

Epoch: 390| Step: 0
Training loss: 1.3778297901153564
Validation loss: 1.9257954166781517

Epoch: 5| Step: 1
Training loss: 1.2952630519866943
Validation loss: 1.909200737553258

Epoch: 5| Step: 2
Training loss: 1.8601373434066772
Validation loss: 1.882082511019963

Epoch: 5| Step: 3
Training loss: 1.017721176147461
Validation loss: 1.8656324442996775

Epoch: 5| Step: 4
Training loss: 1.1894596815109253
Validation loss: 1.8523530498627694

Epoch: 5| Step: 5
Training loss: 1.0076611042022705
Validation loss: 1.903667188459827

Epoch: 5| Step: 6
Training loss: 1.4826076030731201
Validation loss: 1.844886725948703

Epoch: 5| Step: 7
Training loss: 1.7445974349975586
Validation loss: 1.829329357352308

Epoch: 5| Step: 8
Training loss: 0.6363142728805542
Validation loss: 1.8238338988314393

Epoch: 5| Step: 9
Training loss: 0.949255108833313
Validation loss: 1.8260449414612145

Epoch: 5| Step: 10
Training loss: 1.3359287977218628
Validation loss: 1.8280234849581154

Epoch: 391| Step: 0
Training loss: 1.3492151498794556
Validation loss: 1.8555564534279607

Epoch: 5| Step: 1
Training loss: 1.123042345046997
Validation loss: 1.879415137793428

Epoch: 5| Step: 2
Training loss: 1.2206331491470337
Validation loss: 1.8392082311773812

Epoch: 5| Step: 3
Training loss: 1.4900767803192139
Validation loss: 1.8910397996184647

Epoch: 5| Step: 4
Training loss: 1.4738576412200928
Validation loss: 1.7988618522562005

Epoch: 5| Step: 5
Training loss: 0.9901334047317505
Validation loss: 1.8862052630352717

Epoch: 5| Step: 6
Training loss: 1.6703335046768188
Validation loss: 1.8330867290496826

Epoch: 5| Step: 7
Training loss: 1.1925694942474365
Validation loss: 1.8201800007973947

Epoch: 5| Step: 8
Training loss: 1.0823509693145752
Validation loss: 1.830036763221987

Epoch: 5| Step: 9
Training loss: 1.309018850326538
Validation loss: 1.8103150475409724

Epoch: 5| Step: 10
Training loss: 1.0921430587768555
Validation loss: 1.808864280741702

Epoch: 392| Step: 0
Training loss: 1.7195285558700562
Validation loss: 1.824922380908843

Epoch: 5| Step: 1
Training loss: 1.320418119430542
Validation loss: 1.8279321757696008

Epoch: 5| Step: 2
Training loss: 1.230271577835083
Validation loss: 1.8561534035590388

Epoch: 5| Step: 3
Training loss: 1.4916718006134033
Validation loss: 1.813412130519908

Epoch: 5| Step: 4
Training loss: 1.4278029203414917
Validation loss: 1.8864177426984232

Epoch: 5| Step: 5
Training loss: 0.775077223777771
Validation loss: 1.8389990047741962

Epoch: 5| Step: 6
Training loss: 1.5451750755310059
Validation loss: 1.8323688417352655

Epoch: 5| Step: 7
Training loss: 1.2148357629776
Validation loss: 1.8800781567891438

Epoch: 5| Step: 8
Training loss: 0.8666451573371887
Validation loss: 1.8334710803083194

Epoch: 5| Step: 9
Training loss: 1.4830652475357056
Validation loss: 1.8894999745071575

Epoch: 5| Step: 10
Training loss: 1.5088586807250977
Validation loss: 1.8412271597052132

Epoch: 393| Step: 0
Training loss: 1.696152925491333
Validation loss: 1.8601809393975042

Epoch: 5| Step: 1
Training loss: 1.0579192638397217
Validation loss: 1.8895390700268488

Epoch: 5| Step: 2
Training loss: 1.1490248441696167
Validation loss: 1.8924529257641043

Epoch: 5| Step: 3
Training loss: 0.7973021268844604
Validation loss: 1.8338216556015836

Epoch: 5| Step: 4
Training loss: 1.2221441268920898
Validation loss: 1.8662337641562186

Epoch: 5| Step: 5
Training loss: 1.2326459884643555
Validation loss: 1.830771743610341

Epoch: 5| Step: 6
Training loss: 1.9323679208755493
Validation loss: 1.8430317640304565

Epoch: 5| Step: 7
Training loss: 1.1140015125274658
Validation loss: 1.847343380733203

Epoch: 5| Step: 8
Training loss: 1.055325984954834
Validation loss: 1.8039373787500526

Epoch: 5| Step: 9
Training loss: 1.4207961559295654
Validation loss: 1.8303801231486823

Epoch: 5| Step: 10
Training loss: 1.0378663539886475
Validation loss: 1.7992152347359607

Epoch: 394| Step: 0
Training loss: 1.3912580013275146
Validation loss: 1.8255372034606112

Epoch: 5| Step: 1
Training loss: 1.7018258571624756
Validation loss: 1.85388151291878

Epoch: 5| Step: 2
Training loss: 1.2845227718353271
Validation loss: 1.8058347650753555

Epoch: 5| Step: 3
Training loss: 1.2633470296859741
Validation loss: 1.8469408763352262

Epoch: 5| Step: 4
Training loss: 1.2034260034561157
Validation loss: 1.8412635916022844

Epoch: 5| Step: 5
Training loss: 1.2772303819656372
Validation loss: 1.8260423406477897

Epoch: 5| Step: 6
Training loss: 0.8053566217422485
Validation loss: 1.8203637599945068

Epoch: 5| Step: 7
Training loss: 1.288252592086792
Validation loss: 1.8492058477094095

Epoch: 5| Step: 8
Training loss: 1.2415549755096436
Validation loss: 1.8016870701184837

Epoch: 5| Step: 9
Training loss: 1.1717051267623901
Validation loss: 1.910406735635573

Epoch: 5| Step: 10
Training loss: 1.1506547927856445
Validation loss: 1.820572837706535

Epoch: 395| Step: 0
Training loss: 1.1385254859924316
Validation loss: 1.868911338108842

Epoch: 5| Step: 1
Training loss: 1.182081937789917
Validation loss: 1.84900660796832

Epoch: 5| Step: 2
Training loss: 1.15493905544281
Validation loss: 1.826482360081006

Epoch: 5| Step: 3
Training loss: 1.2482085227966309
Validation loss: 1.84580260451122

Epoch: 5| Step: 4
Training loss: 1.3719961643218994
Validation loss: 1.7944104697114678

Epoch: 5| Step: 5
Training loss: 1.569214105606079
Validation loss: 1.8487736601983347

Epoch: 5| Step: 6
Training loss: 1.0815931558609009
Validation loss: 1.7862297193978423

Epoch: 5| Step: 7
Training loss: 1.368035912513733
Validation loss: 1.778866183373236

Epoch: 5| Step: 8
Training loss: 0.9294561147689819
Validation loss: 1.8021407793926936

Epoch: 5| Step: 9
Training loss: 1.31577467918396
Validation loss: 1.8246217748170257

Epoch: 5| Step: 10
Training loss: 1.645097255706787
Validation loss: 1.8452530227681643

Epoch: 396| Step: 0
Training loss: 0.9412334561347961
Validation loss: 1.8398302165410851

Epoch: 5| Step: 1
Training loss: 1.159521222114563
Validation loss: 1.8944724400838215

Epoch: 5| Step: 2
Training loss: 1.3618080615997314
Validation loss: 1.8407282701102636

Epoch: 5| Step: 3
Training loss: 1.0891910791397095
Validation loss: 1.8553261949170021

Epoch: 5| Step: 4
Training loss: 1.3927942514419556
Validation loss: 1.8052531570516608

Epoch: 5| Step: 5
Training loss: 1.4816334247589111
Validation loss: 1.8234059285092097

Epoch: 5| Step: 6
Training loss: 1.5639817714691162
Validation loss: 1.8948756597375358

Epoch: 5| Step: 7
Training loss: 1.144425392150879
Validation loss: 1.8031881150378977

Epoch: 5| Step: 8
Training loss: 1.0507705211639404
Validation loss: 1.8415649706317532

Epoch: 5| Step: 9
Training loss: 1.333099126815796
Validation loss: 1.87176424969909

Epoch: 5| Step: 10
Training loss: 1.260994553565979
Validation loss: 1.9064777679340814

Epoch: 397| Step: 0
Training loss: 0.9062369465827942
Validation loss: 1.8295194641236336

Epoch: 5| Step: 1
Training loss: 1.1699340343475342
Validation loss: 1.8107834041759532

Epoch: 5| Step: 2
Training loss: 1.4642258882522583
Validation loss: 1.8973311967747186

Epoch: 5| Step: 3
Training loss: 1.154844045639038
Validation loss: 1.8904710738889632

Epoch: 5| Step: 4
Training loss: 1.27497398853302
Validation loss: 1.8456337657026065

Epoch: 5| Step: 5
Training loss: 0.9738591313362122
Validation loss: 1.8083052404465214

Epoch: 5| Step: 6
Training loss: 1.8014240264892578
Validation loss: 1.8391548625884517

Epoch: 5| Step: 7
Training loss: 1.523411750793457
Validation loss: 1.8373732618106309

Epoch: 5| Step: 8
Training loss: 0.834819495677948
Validation loss: 1.8297838523823728

Epoch: 5| Step: 9
Training loss: 1.4023730754852295
Validation loss: 1.8508849156800138

Epoch: 5| Step: 10
Training loss: 1.3781477212905884
Validation loss: 1.8534211804789882

Epoch: 398| Step: 0
Training loss: 1.485681176185608
Validation loss: 1.821323134565866

Epoch: 5| Step: 1
Training loss: 1.044105887413025
Validation loss: 1.7947856662093953

Epoch: 5| Step: 2
Training loss: 1.3958574533462524
Validation loss: 1.8072745646199873

Epoch: 5| Step: 3
Training loss: 1.1219079494476318
Validation loss: 1.82714214376224

Epoch: 5| Step: 4
Training loss: 1.3242878913879395
Validation loss: 1.8039568431915776

Epoch: 5| Step: 5
Training loss: 1.2943778038024902
Validation loss: 1.811658561870616

Epoch: 5| Step: 6
Training loss: 1.0215259790420532
Validation loss: 1.8508568963696879

Epoch: 5| Step: 7
Training loss: 1.4612194299697876
Validation loss: 1.8560389895592966

Epoch: 5| Step: 8
Training loss: 1.5036523342132568
Validation loss: 1.8333480652942453

Epoch: 5| Step: 9
Training loss: 1.2659891843795776
Validation loss: 1.8323353631522066

Epoch: 5| Step: 10
Training loss: 0.953275203704834
Validation loss: 1.8280185063680012

Epoch: 399| Step: 0
Training loss: 1.2451918125152588
Validation loss: 1.8821929142039309

Epoch: 5| Step: 1
Training loss: 1.3009883165359497
Validation loss: 1.919643307244906

Epoch: 5| Step: 2
Training loss: 1.8520030975341797
Validation loss: 1.968604544157623

Epoch: 5| Step: 3
Training loss: 1.6149146556854248
Validation loss: 1.8752616784905876

Epoch: 5| Step: 4
Training loss: 1.5594087839126587
Validation loss: 1.8942557919409968

Epoch: 5| Step: 5
Training loss: 1.4028152227401733
Validation loss: 1.878998887154364

Epoch: 5| Step: 6
Training loss: 1.368765115737915
Validation loss: 1.8909930234314294

Epoch: 5| Step: 7
Training loss: 0.5070613622665405
Validation loss: 1.8755863187133626

Epoch: 5| Step: 8
Training loss: 1.2254326343536377
Validation loss: 1.8027430170325822

Epoch: 5| Step: 9
Training loss: 1.134222149848938
Validation loss: 1.8415501425343175

Epoch: 5| Step: 10
Training loss: 0.874771237373352
Validation loss: 1.7865047454833984

Epoch: 400| Step: 0
Training loss: 0.9658516049385071
Validation loss: 1.797680906070176

Epoch: 5| Step: 1
Training loss: 0.9029468297958374
Validation loss: 1.8239352010911511

Epoch: 5| Step: 2
Training loss: 1.0370763540267944
Validation loss: 1.7824848159666984

Epoch: 5| Step: 3
Training loss: 1.47775399684906
Validation loss: 1.858362159421367

Epoch: 5| Step: 4
Training loss: 1.3444478511810303
Validation loss: 1.787408640307765

Epoch: 5| Step: 5
Training loss: 1.430250644683838
Validation loss: 1.7852424998437204

Epoch: 5| Step: 6
Training loss: 1.486627459526062
Validation loss: 1.852231679424163

Epoch: 5| Step: 7
Training loss: 1.4950158596038818
Validation loss: 1.8292696296527822

Epoch: 5| Step: 8
Training loss: 1.2963935136795044
Validation loss: 1.8695945534654843

Epoch: 5| Step: 9
Training loss: 1.3657104969024658
Validation loss: 1.872468340781427

Epoch: 5| Step: 10
Training loss: 0.9795585870742798
Validation loss: 1.8405034388265302

Testing loss: 2.477409760157267
