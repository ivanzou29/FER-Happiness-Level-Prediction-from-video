Epoch: 1| Step: 0
Training loss: 7.573489189147949
Validation loss: 7.089655455722604

Epoch: 5| Step: 1
Training loss: 7.132058620452881
Validation loss: 7.0840615662195345

Epoch: 5| Step: 2
Training loss: 7.038883209228516
Validation loss: 7.077887227458339

Epoch: 5| Step: 3
Training loss: 6.398310661315918
Validation loss: 7.07150746417302

Epoch: 5| Step: 4
Training loss: 6.871189117431641
Validation loss: 7.0652078505485285

Epoch: 5| Step: 5
Training loss: 6.2677321434021
Validation loss: 7.0593122051608175

Epoch: 5| Step: 6
Training loss: 5.258334159851074
Validation loss: 7.053833253922001

Epoch: 5| Step: 7
Training loss: 7.354203701019287
Validation loss: 7.046854024292321

Epoch: 5| Step: 8
Training loss: 7.4056596755981445
Validation loss: 7.042066727915118

Epoch: 5| Step: 9
Training loss: 6.98052453994751
Validation loss: 7.0350920102929555

Epoch: 5| Step: 10
Training loss: 7.175924777984619
Validation loss: 7.030430921944239

Epoch: 2| Step: 0
Training loss: 6.8184404373168945
Validation loss: 7.023444211611184

Epoch: 5| Step: 1
Training loss: 6.944149017333984
Validation loss: 7.016234797816122

Epoch: 5| Step: 2
Training loss: 6.852964878082275
Validation loss: 7.01044387202109

Epoch: 5| Step: 3
Training loss: 7.133525848388672
Validation loss: 7.00695142951063

Epoch: 5| Step: 4
Training loss: 7.17899227142334
Validation loss: 6.997963095224032

Epoch: 5| Step: 5
Training loss: 6.987727165222168
Validation loss: 6.994530236849221

Epoch: 5| Step: 6
Training loss: 5.764199733734131
Validation loss: 6.985372999662994

Epoch: 5| Step: 7
Training loss: 7.446533203125
Validation loss: 6.980267406791769

Epoch: 5| Step: 8
Training loss: 6.976295471191406
Validation loss: 6.9756400046810025

Epoch: 5| Step: 9
Training loss: 6.481535911560059
Validation loss: 6.969503536019274

Epoch: 5| Step: 10
Training loss: 5.954189777374268
Validation loss: 6.964470996651598

Epoch: 3| Step: 0
Training loss: 6.059903144836426
Validation loss: 6.958364532839868

Epoch: 5| Step: 1
Training loss: 7.49048376083374
Validation loss: 6.953263375066942

Epoch: 5| Step: 2
Training loss: 7.05447244644165
Validation loss: 6.945999042962187

Epoch: 5| Step: 3
Training loss: 7.238628387451172
Validation loss: 6.941602963273243

Epoch: 5| Step: 4
Training loss: 5.842957496643066
Validation loss: 6.935482117437547

Epoch: 5| Step: 5
Training loss: 7.075173854827881
Validation loss: 6.929637975590204

Epoch: 5| Step: 6
Training loss: 5.935283660888672
Validation loss: 6.9241831020642355

Epoch: 5| Step: 7
Training loss: 7.416511535644531
Validation loss: 6.918822975568874

Epoch: 5| Step: 8
Training loss: 5.593113422393799
Validation loss: 6.910820043215188

Epoch: 5| Step: 9
Training loss: 7.486586093902588
Validation loss: 6.904644996889176

Epoch: 5| Step: 10
Training loss: 6.759228706359863
Validation loss: 6.899722012140417

Epoch: 4| Step: 0
Training loss: 6.819425106048584
Validation loss: 6.895522758524905

Epoch: 5| Step: 1
Training loss: 7.108580112457275
Validation loss: 6.88682049064226

Epoch: 5| Step: 2
Training loss: 6.356660842895508
Validation loss: 6.881633148398451

Epoch: 5| Step: 3
Training loss: 6.288522243499756
Validation loss: 6.877121248552876

Epoch: 5| Step: 4
Training loss: 7.4850263595581055
Validation loss: 6.869217052254625

Epoch: 5| Step: 5
Training loss: 5.948426246643066
Validation loss: 6.864611615416824

Epoch: 5| Step: 6
Training loss: 6.633917331695557
Validation loss: 6.859791042984173

Epoch: 5| Step: 7
Training loss: 7.055551052093506
Validation loss: 6.852731894421321

Epoch: 5| Step: 8
Training loss: 7.0171799659729
Validation loss: 6.845972009884414

Epoch: 5| Step: 9
Training loss: 6.358639717102051
Validation loss: 6.8410411855225925

Epoch: 5| Step: 10
Training loss: 6.056303024291992
Validation loss: 6.834115997437508

Epoch: 5| Step: 0
Training loss: 6.2548418045043945
Validation loss: 6.830141718669604

Epoch: 5| Step: 1
Training loss: 5.910037517547607
Validation loss: 6.8234800164417555

Epoch: 5| Step: 2
Training loss: 6.56695556640625
Validation loss: 6.816446817049417

Epoch: 5| Step: 3
Training loss: 6.631497383117676
Validation loss: 6.807921255788496

Epoch: 5| Step: 4
Training loss: 5.525806427001953
Validation loss: 6.805293754864764

Epoch: 5| Step: 5
Training loss: 7.051907539367676
Validation loss: 6.798138208286737

Epoch: 5| Step: 6
Training loss: 7.749661445617676
Validation loss: 6.7921902236118115

Epoch: 5| Step: 7
Training loss: 5.7133402824401855
Validation loss: 6.786287502575946

Epoch: 5| Step: 8
Training loss: 6.893333435058594
Validation loss: 6.780435695443102

Epoch: 5| Step: 9
Training loss: 6.786505699157715
Validation loss: 6.77433491265902

Epoch: 5| Step: 10
Training loss: 7.512775421142578
Validation loss: 6.765948757048576

Epoch: 6| Step: 0
Training loss: 5.683100700378418
Validation loss: 6.760361281774378

Epoch: 5| Step: 1
Training loss: 7.091313362121582
Validation loss: 6.754233242363058

Epoch: 5| Step: 2
Training loss: 6.398669242858887
Validation loss: 6.746738603038173

Epoch: 5| Step: 3
Training loss: 7.132330417633057
Validation loss: 6.739571520077285

Epoch: 5| Step: 4
Training loss: 6.257757186889648
Validation loss: 6.731785692194457

Epoch: 5| Step: 5
Training loss: 6.548922538757324
Validation loss: 6.724727820324642

Epoch: 5| Step: 6
Training loss: 6.1057820320129395
Validation loss: 6.718287770466138

Epoch: 5| Step: 7
Training loss: 5.425530433654785
Validation loss: 6.711331003455705

Epoch: 5| Step: 8
Training loss: 6.912083625793457
Validation loss: 6.707079195207165

Epoch: 5| Step: 9
Training loss: 6.725031852722168
Validation loss: 6.70012116688554

Epoch: 5| Step: 10
Training loss: 7.508549690246582
Validation loss: 6.692251405408306

Epoch: 7| Step: 0
Training loss: 6.621234893798828
Validation loss: 6.683477345333304

Epoch: 5| Step: 1
Training loss: 6.503384590148926
Validation loss: 6.675183014203143

Epoch: 5| Step: 2
Training loss: 5.6456708908081055
Validation loss: 6.6697836486242155

Epoch: 5| Step: 3
Training loss: 6.696937561035156
Validation loss: 6.661330669156967

Epoch: 5| Step: 4
Training loss: 6.4882330894470215
Validation loss: 6.654328756434943

Epoch: 5| Step: 5
Training loss: 7.411571502685547
Validation loss: 6.646460702342372

Epoch: 5| Step: 6
Training loss: 6.4790849685668945
Validation loss: 6.6385526810922935

Epoch: 5| Step: 7
Training loss: 6.066287040710449
Validation loss: 6.631946481684203

Epoch: 5| Step: 8
Training loss: 6.664858341217041
Validation loss: 6.623790561511952

Epoch: 5| Step: 9
Training loss: 6.733075141906738
Validation loss: 6.61755334690053

Epoch: 5| Step: 10
Training loss: 5.290055751800537
Validation loss: 6.60863124170611

Epoch: 8| Step: 0
Training loss: 5.789045333862305
Validation loss: 6.600819756907802

Epoch: 5| Step: 1
Training loss: 6.626991271972656
Validation loss: 6.591756307950583

Epoch: 5| Step: 2
Training loss: 7.320880889892578
Validation loss: 6.584396664814283

Epoch: 5| Step: 3
Training loss: 6.594435214996338
Validation loss: 6.574835033826931

Epoch: 5| Step: 4
Training loss: 6.755640983581543
Validation loss: 6.567469350753292

Epoch: 5| Step: 5
Training loss: 5.132178783416748
Validation loss: 6.561137076347105

Epoch: 5| Step: 6
Training loss: 5.958224296569824
Validation loss: 6.550307576374341

Epoch: 5| Step: 7
Training loss: 6.1548943519592285
Validation loss: 6.540953959188154

Epoch: 5| Step: 8
Training loss: 5.901172637939453
Validation loss: 6.536266962687175

Epoch: 5| Step: 9
Training loss: 6.544483184814453
Validation loss: 6.52455827754031

Epoch: 5| Step: 10
Training loss: 7.135648727416992
Validation loss: 6.516175680263068

Epoch: 9| Step: 0
Training loss: 6.891500949859619
Validation loss: 6.505514114133773

Epoch: 5| Step: 1
Training loss: 6.693243980407715
Validation loss: 6.496856161343154

Epoch: 5| Step: 2
Training loss: 6.89141321182251
Validation loss: 6.490711294194703

Epoch: 5| Step: 3
Training loss: 6.049878120422363
Validation loss: 6.481722283106978

Epoch: 5| Step: 4
Training loss: 4.935248374938965
Validation loss: 6.470272089845391

Epoch: 5| Step: 5
Training loss: 5.771163463592529
Validation loss: 6.4595966390384145

Epoch: 5| Step: 6
Training loss: 4.960320472717285
Validation loss: 6.4517152745236634

Epoch: 5| Step: 7
Training loss: 6.781869411468506
Validation loss: 6.442230706573815

Epoch: 5| Step: 8
Training loss: 6.516504764556885
Validation loss: 6.430478588227303

Epoch: 5| Step: 9
Training loss: 7.071702003479004
Validation loss: 6.419812489581364

Epoch: 5| Step: 10
Training loss: 6.081923961639404
Validation loss: 6.411168477868521

Epoch: 10| Step: 0
Training loss: 6.1439595222473145
Validation loss: 6.399156349961475

Epoch: 5| Step: 1
Training loss: 6.234708309173584
Validation loss: 6.389955166847475

Epoch: 5| Step: 2
Training loss: 6.294354438781738
Validation loss: 6.378891750048566

Epoch: 5| Step: 3
Training loss: 5.631129264831543
Validation loss: 6.366123184081046

Epoch: 5| Step: 4
Training loss: 6.351815223693848
Validation loss: 6.352057867152716

Epoch: 5| Step: 5
Training loss: 6.185678958892822
Validation loss: 6.347842021655011

Epoch: 5| Step: 6
Training loss: 5.793339729309082
Validation loss: 6.335863605622323

Epoch: 5| Step: 7
Training loss: 5.244910717010498
Validation loss: 6.320909161721507

Epoch: 5| Step: 8
Training loss: 6.450304985046387
Validation loss: 6.309182710545038

Epoch: 5| Step: 9
Training loss: 5.937506675720215
Validation loss: 6.298673773324618

Epoch: 5| Step: 10
Training loss: 7.26177978515625
Validation loss: 6.286936067765759

Epoch: 11| Step: 0
Training loss: 5.7513556480407715
Validation loss: 6.2734806511991765

Epoch: 5| Step: 1
Training loss: 7.140157222747803
Validation loss: 6.262753773761052

Epoch: 5| Step: 2
Training loss: 5.430975437164307
Validation loss: 6.245539860058856

Epoch: 5| Step: 3
Training loss: 6.866847038269043
Validation loss: 6.236788575367261

Epoch: 5| Step: 4
Training loss: 5.9937744140625
Validation loss: 6.222680035457816

Epoch: 5| Step: 5
Training loss: 4.8958539962768555
Validation loss: 6.207176264896188

Epoch: 5| Step: 6
Training loss: 4.414092063903809
Validation loss: 6.196244188534316

Epoch: 5| Step: 7
Training loss: 7.046938896179199
Validation loss: 6.18455050581245

Epoch: 5| Step: 8
Training loss: 5.702358722686768
Validation loss: 6.172672584492673

Epoch: 5| Step: 9
Training loss: 7.303343296051025
Validation loss: 6.151701522129838

Epoch: 5| Step: 10
Training loss: 5.20728874206543
Validation loss: 6.1404512672014135

Epoch: 12| Step: 0
Training loss: 5.132446765899658
Validation loss: 6.127330508283389

Epoch: 5| Step: 1
Training loss: 4.645012378692627
Validation loss: 6.1124711344319005

Epoch: 5| Step: 2
Training loss: 5.953902244567871
Validation loss: 6.100735751531458

Epoch: 5| Step: 3
Training loss: 5.801150798797607
Validation loss: 6.0858174959818525

Epoch: 5| Step: 4
Training loss: 6.104001045227051
Validation loss: 6.070377744654174

Epoch: 5| Step: 5
Training loss: 7.964799404144287
Validation loss: 6.0523095028374785

Epoch: 5| Step: 6
Training loss: 5.69663667678833
Validation loss: 6.042383147824195

Epoch: 5| Step: 7
Training loss: 5.876984596252441
Validation loss: 6.02599036821755

Epoch: 5| Step: 8
Training loss: 5.008833885192871
Validation loss: 6.013316754371889

Epoch: 5| Step: 9
Training loss: 6.380650520324707
Validation loss: 5.993075160570042

Epoch: 5| Step: 10
Training loss: 5.508979797363281
Validation loss: 5.980332866791756

Epoch: 13| Step: 0
Training loss: 6.1426568031311035
Validation loss: 5.966071128845215

Epoch: 5| Step: 1
Training loss: 6.371569633483887
Validation loss: 5.948071782306958

Epoch: 5| Step: 2
Training loss: 5.99174690246582
Validation loss: 5.930593664928149

Epoch: 5| Step: 3
Training loss: 4.201915264129639
Validation loss: 5.914482285899501

Epoch: 5| Step: 4
Training loss: 6.044167995452881
Validation loss: 5.898705733719693

Epoch: 5| Step: 5
Training loss: 4.01242208480835
Validation loss: 5.878871702378796

Epoch: 5| Step: 6
Training loss: 6.343234539031982
Validation loss: 5.864625992313508

Epoch: 5| Step: 7
Training loss: 5.65015172958374
Validation loss: 5.851530664710588

Epoch: 5| Step: 8
Training loss: 6.105066776275635
Validation loss: 5.8317048216378815

Epoch: 5| Step: 9
Training loss: 5.494721412658691
Validation loss: 5.813193998029155

Epoch: 5| Step: 10
Training loss: 5.824110507965088
Validation loss: 5.797241990284253

Epoch: 14| Step: 0
Training loss: 5.927523612976074
Validation loss: 5.776897927766205

Epoch: 5| Step: 1
Training loss: 5.793408393859863
Validation loss: 5.752216113510952

Epoch: 5| Step: 2
Training loss: 4.754342079162598
Validation loss: 5.737067786596155

Epoch: 5| Step: 3
Training loss: 5.789512634277344
Validation loss: 5.719791858426986

Epoch: 5| Step: 4
Training loss: 5.480884075164795
Validation loss: 5.704082909450736

Epoch: 5| Step: 5
Training loss: 5.867989540100098
Validation loss: 5.683042762100055

Epoch: 5| Step: 6
Training loss: 4.579348564147949
Validation loss: 5.660974538454446

Epoch: 5| Step: 7
Training loss: 5.03237247467041
Validation loss: 5.645989684648411

Epoch: 5| Step: 8
Training loss: 7.074376106262207
Validation loss: 5.623088944342829

Epoch: 5| Step: 9
Training loss: 6.0417046546936035
Validation loss: 5.602008911871141

Epoch: 5| Step: 10
Training loss: 3.230207681655884
Validation loss: 5.584104045744865

Epoch: 15| Step: 0
Training loss: 4.563343048095703
Validation loss: 5.562577283510598

Epoch: 5| Step: 1
Training loss: 4.687619209289551
Validation loss: 5.540425033979519

Epoch: 5| Step: 2
Training loss: 4.74021053314209
Validation loss: 5.521476232877341

Epoch: 5| Step: 3
Training loss: 5.428752899169922
Validation loss: 5.5040163019652

Epoch: 5| Step: 4
Training loss: 5.963314056396484
Validation loss: 5.479009371931835

Epoch: 5| Step: 5
Training loss: 4.911459922790527
Validation loss: 5.458785041686027

Epoch: 5| Step: 6
Training loss: 6.279735088348389
Validation loss: 5.4397290855325675

Epoch: 5| Step: 7
Training loss: 4.901806354522705
Validation loss: 5.407134973874656

Epoch: 5| Step: 8
Training loss: 4.711874485015869
Validation loss: 5.387657027090749

Epoch: 5| Step: 9
Training loss: 5.758622646331787
Validation loss: 5.364550728951731

Epoch: 5| Step: 10
Training loss: 5.456305503845215
Validation loss: 5.344808737436931

Epoch: 16| Step: 0
Training loss: 5.3735175132751465
Validation loss: 5.316790678167856

Epoch: 5| Step: 1
Training loss: 4.211468696594238
Validation loss: 5.292378948580835

Epoch: 5| Step: 2
Training loss: 4.140463829040527
Validation loss: 5.264676268382739

Epoch: 5| Step: 3
Training loss: 5.276094436645508
Validation loss: 5.242554977375974

Epoch: 5| Step: 4
Training loss: 5.9640302658081055
Validation loss: 5.221721039023451

Epoch: 5| Step: 5
Training loss: 4.606241703033447
Validation loss: 5.195283992316133

Epoch: 5| Step: 6
Training loss: 5.4626007080078125
Validation loss: 5.161638895670573

Epoch: 5| Step: 7
Training loss: 5.682243824005127
Validation loss: 5.14208298344766

Epoch: 5| Step: 8
Training loss: 4.350896835327148
Validation loss: 5.108697537452944

Epoch: 5| Step: 9
Training loss: 5.9135589599609375
Validation loss: 5.0890016299422065

Epoch: 5| Step: 10
Training loss: 3.2026968002319336
Validation loss: 5.0650193460526

Epoch: 17| Step: 0
Training loss: 5.353568077087402
Validation loss: 5.039744674518544

Epoch: 5| Step: 1
Training loss: 4.9662933349609375
Validation loss: 5.002948458476733

Epoch: 5| Step: 2
Training loss: 4.539689540863037
Validation loss: 4.9852632809710755

Epoch: 5| Step: 3
Training loss: 4.700331687927246
Validation loss: 4.959372182046214

Epoch: 5| Step: 4
Training loss: 5.328784942626953
Validation loss: 4.923427289532077

Epoch: 5| Step: 5
Training loss: 5.068571090698242
Validation loss: 4.905140240987142

Epoch: 5| Step: 6
Training loss: 4.417457103729248
Validation loss: 4.872778513098276

Epoch: 5| Step: 7
Training loss: 4.470128536224365
Validation loss: 4.849072922942459

Epoch: 5| Step: 8
Training loss: 3.762728452682495
Validation loss: 4.813245019605083

Epoch: 5| Step: 9
Training loss: 3.9441566467285156
Validation loss: 4.788461244234475

Epoch: 5| Step: 10
Training loss: 4.516022682189941
Validation loss: 4.764132161294261

Epoch: 18| Step: 0
Training loss: 4.542124271392822
Validation loss: 4.737159539294499

Epoch: 5| Step: 1
Training loss: 4.661561965942383
Validation loss: 4.708492637962423

Epoch: 5| Step: 2
Training loss: 4.8193817138671875
Validation loss: 4.67218671306487

Epoch: 5| Step: 3
Training loss: 4.424211025238037
Validation loss: 4.641516208648682

Epoch: 5| Step: 4
Training loss: 4.4556684494018555
Validation loss: 4.612694873604723

Epoch: 5| Step: 5
Training loss: 4.019268035888672
Validation loss: 4.589391972429009

Epoch: 5| Step: 6
Training loss: 4.404706001281738
Validation loss: 4.558285492722706

Epoch: 5| Step: 7
Training loss: 4.098662853240967
Validation loss: 4.526458365942842

Epoch: 5| Step: 8
Training loss: 4.005251407623291
Validation loss: 4.487466883915727

Epoch: 5| Step: 9
Training loss: 3.822007417678833
Validation loss: 4.468935115363008

Epoch: 5| Step: 10
Training loss: 4.337298393249512
Validation loss: 4.4334364039923555

Epoch: 19| Step: 0
Training loss: 5.501507759094238
Validation loss: 4.397297202899892

Epoch: 5| Step: 1
Training loss: 4.550083637237549
Validation loss: 4.361709553708312

Epoch: 5| Step: 2
Training loss: 3.093092441558838
Validation loss: 4.3370215508245655

Epoch: 5| Step: 3
Training loss: 3.7680938243865967
Validation loss: 4.302418885692473

Epoch: 5| Step: 4
Training loss: 4.211720943450928
Validation loss: 4.270729418723814

Epoch: 5| Step: 5
Training loss: 3.4825069904327393
Validation loss: 4.236069412641628

Epoch: 5| Step: 6
Training loss: 4.422120094299316
Validation loss: 4.192888911052417

Epoch: 5| Step: 7
Training loss: 4.032676696777344
Validation loss: 4.166485283964423

Epoch: 5| Step: 8
Training loss: 4.024016857147217
Validation loss: 4.1353611766651115

Epoch: 5| Step: 9
Training loss: 3.6088600158691406
Validation loss: 4.098348673953805

Epoch: 5| Step: 10
Training loss: 3.1786060333251953
Validation loss: 4.070751108149047

Epoch: 20| Step: 0
Training loss: 3.1367156505584717
Validation loss: 4.027254499414916

Epoch: 5| Step: 1
Training loss: 3.174960136413574
Validation loss: 4.007387238164102

Epoch: 5| Step: 2
Training loss: 3.925844669342041
Validation loss: 3.971724602483934

Epoch: 5| Step: 3
Training loss: 4.088970184326172
Validation loss: 3.927547711198048

Epoch: 5| Step: 4
Training loss: 3.2981152534484863
Validation loss: 3.8986492618437736

Epoch: 5| Step: 5
Training loss: 3.6465983390808105
Validation loss: 3.8694251070740404

Epoch: 5| Step: 6
Training loss: 3.7778849601745605
Validation loss: 3.8229761508203324

Epoch: 5| Step: 7
Training loss: 3.2680487632751465
Validation loss: 3.7955010937106226

Epoch: 5| Step: 8
Training loss: 4.021511077880859
Validation loss: 3.7704478438182543

Epoch: 5| Step: 9
Training loss: 4.2764153480529785
Validation loss: 3.7329607009887695

Epoch: 5| Step: 10
Training loss: 3.5549328327178955
Validation loss: 3.7065010173346407

Epoch: 21| Step: 0
Training loss: 3.0709662437438965
Validation loss: 3.6583474477132163

Epoch: 5| Step: 1
Training loss: 4.287230491638184
Validation loss: 3.6489630463302776

Epoch: 5| Step: 2
Training loss: 3.430593490600586
Validation loss: 3.611128355867119

Epoch: 5| Step: 3
Training loss: 4.213330268859863
Validation loss: 3.5854683024908907

Epoch: 5| Step: 4
Training loss: 3.170464515686035
Validation loss: 3.541494236197523

Epoch: 5| Step: 5
Training loss: 2.7548604011535645
Validation loss: 3.515965225876019

Epoch: 5| Step: 6
Training loss: 2.5429725646972656
Validation loss: 3.498579340596353

Epoch: 5| Step: 7
Training loss: 3.243227481842041
Validation loss: 3.4479198122537262

Epoch: 5| Step: 8
Training loss: 3.0047965049743652
Validation loss: 3.408323562273415

Epoch: 5| Step: 9
Training loss: 3.155611753463745
Validation loss: 3.388946766494423

Epoch: 5| Step: 10
Training loss: 4.1454758644104
Validation loss: 3.3607509623291674

Epoch: 22| Step: 0
Training loss: 2.981672763824463
Validation loss: 3.3384772680139028

Epoch: 5| Step: 1
Training loss: 3.5506224632263184
Validation loss: 3.2995812226367254

Epoch: 5| Step: 2
Training loss: 3.547473192214966
Validation loss: 3.2794638936237623

Epoch: 5| Step: 3
Training loss: 3.43194317817688
Validation loss: 3.239537646693568

Epoch: 5| Step: 4
Training loss: 2.9787070751190186
Validation loss: 3.213294444545623

Epoch: 5| Step: 5
Training loss: 2.92779278755188
Validation loss: 3.188668771456647

Epoch: 5| Step: 6
Training loss: 3.2490153312683105
Validation loss: 3.1570516273539555

Epoch: 5| Step: 7
Training loss: 2.7059688568115234
Validation loss: 3.1207133288024576

Epoch: 5| Step: 8
Training loss: 2.3407368659973145
Validation loss: 3.1022411443853892

Epoch: 5| Step: 9
Training loss: 3.03422474861145
Validation loss: 3.0666643111936507

Epoch: 5| Step: 10
Training loss: 3.351209878921509
Validation loss: 3.0529612930872108

Epoch: 23| Step: 0
Training loss: 3.7721495628356934
Validation loss: 3.0092796330810874

Epoch: 5| Step: 1
Training loss: 3.1894583702087402
Validation loss: 2.9827554687376945

Epoch: 5| Step: 2
Training loss: 3.448690891265869
Validation loss: 2.96762849438575

Epoch: 5| Step: 3
Training loss: 2.2943544387817383
Validation loss: 2.9313866220494753

Epoch: 5| Step: 4
Training loss: 3.024548053741455
Validation loss: 2.927980084573069

Epoch: 5| Step: 5
Training loss: 2.579756498336792
Validation loss: 2.9045968619726037

Epoch: 5| Step: 6
Training loss: 3.2692489624023438
Validation loss: 2.8692660408635295

Epoch: 5| Step: 7
Training loss: 2.6725013256073
Validation loss: 2.866294421175475

Epoch: 5| Step: 8
Training loss: 2.160545825958252
Validation loss: 2.8449134775387344

Epoch: 5| Step: 9
Training loss: 2.9047694206237793
Validation loss: 2.798026043881652

Epoch: 5| Step: 10
Training loss: 2.3998732566833496
Validation loss: 2.781346364687848

Epoch: 24| Step: 0
Training loss: 2.4754090309143066
Validation loss: 2.7632177670796714

Epoch: 5| Step: 1
Training loss: 3.037781238555908
Validation loss: 2.7367117225482898

Epoch: 5| Step: 2
Training loss: 2.7176451683044434
Validation loss: 2.725424289703369

Epoch: 5| Step: 3
Training loss: 2.855426549911499
Validation loss: 2.7008625256117953

Epoch: 5| Step: 4
Training loss: 3.126406192779541
Validation loss: 2.6767587225924254

Epoch: 5| Step: 5
Training loss: 2.2086548805236816
Validation loss: 2.6529345307298886

Epoch: 5| Step: 6
Training loss: 2.938037157058716
Validation loss: 2.6420706087543118

Epoch: 5| Step: 7
Training loss: 2.611625909805298
Validation loss: 2.628026147042551

Epoch: 5| Step: 8
Training loss: 3.2242321968078613
Validation loss: 2.599962026842179

Epoch: 5| Step: 9
Training loss: 1.907585859298706
Validation loss: 2.586386639584777

Epoch: 5| Step: 10
Training loss: 2.798849105834961
Validation loss: 2.5754377124130086

Epoch: 25| Step: 0
Training loss: 1.9061836004257202
Validation loss: 2.542913185652866

Epoch: 5| Step: 1
Training loss: 2.948237657546997
Validation loss: 2.5410545103011595

Epoch: 5| Step: 2
Training loss: 1.9750030040740967
Validation loss: 2.527463689927132

Epoch: 5| Step: 3
Training loss: 3.3155548572540283
Validation loss: 2.5209353790488294

Epoch: 5| Step: 4
Training loss: 2.3108129501342773
Validation loss: 2.510448512210641

Epoch: 5| Step: 5
Training loss: 2.5196733474731445
Validation loss: 2.4939478802424606

Epoch: 5| Step: 6
Training loss: 4.099137306213379
Validation loss: 2.509589869488952

Epoch: 5| Step: 7
Training loss: 2.4012250900268555
Validation loss: 2.4809502683660036

Epoch: 5| Step: 8
Training loss: 2.260801315307617
Validation loss: 2.4557518933409

Epoch: 5| Step: 9
Training loss: 2.5749144554138184
Validation loss: 2.4564712201395342

Epoch: 5| Step: 10
Training loss: 2.2504937648773193
Validation loss: 2.433709841902538

Epoch: 26| Step: 0
Training loss: 2.897644281387329
Validation loss: 2.428537248283304

Epoch: 5| Step: 1
Training loss: 2.6383068561553955
Validation loss: 2.4261876306226178

Epoch: 5| Step: 2
Training loss: 3.0490918159484863
Validation loss: 2.4115393264319307

Epoch: 5| Step: 3
Training loss: 1.8711864948272705
Validation loss: 2.4266021482406126

Epoch: 5| Step: 4
Training loss: 2.48982310295105
Validation loss: 2.412487422266314

Epoch: 5| Step: 5
Training loss: 2.584502696990967
Validation loss: 2.4124085108439126

Epoch: 5| Step: 6
Training loss: 3.0981218814849854
Validation loss: 2.397839148839315

Epoch: 5| Step: 7
Training loss: 2.3630752563476562
Validation loss: 2.379862931466872

Epoch: 5| Step: 8
Training loss: 1.868159532546997
Validation loss: 2.407526341817712

Epoch: 5| Step: 9
Training loss: 2.619084596633911
Validation loss: 2.3681206985186507

Epoch: 5| Step: 10
Training loss: 2.649834632873535
Validation loss: 2.3704463153757076

Epoch: 27| Step: 0
Training loss: 2.447697162628174
Validation loss: 2.3649225311894573

Epoch: 5| Step: 1
Training loss: 2.4330148696899414
Validation loss: 2.362294558555849

Epoch: 5| Step: 2
Training loss: 2.8824963569641113
Validation loss: 2.328846405911189

Epoch: 5| Step: 3
Training loss: 2.010132312774658
Validation loss: 2.353464500878447

Epoch: 5| Step: 4
Training loss: 2.8635237216949463
Validation loss: 2.3773452492170435

Epoch: 5| Step: 5
Training loss: 2.1371748447418213
Validation loss: 2.328036282652168

Epoch: 5| Step: 6
Training loss: 2.0971598625183105
Validation loss: 2.3480940095839964

Epoch: 5| Step: 7
Training loss: 2.6256542205810547
Validation loss: 2.329545969604164

Epoch: 5| Step: 8
Training loss: 2.715388774871826
Validation loss: 2.345365496091945

Epoch: 5| Step: 9
Training loss: 2.968606472015381
Validation loss: 2.3135009427224436

Epoch: 5| Step: 10
Training loss: 2.2707176208496094
Validation loss: 2.333401095482611

Epoch: 28| Step: 0
Training loss: 2.8371167182922363
Validation loss: 2.320344060979864

Epoch: 5| Step: 1
Training loss: 2.71687388420105
Validation loss: 2.3179885238729496

Epoch: 5| Step: 2
Training loss: 2.7455310821533203
Validation loss: 2.3090961466553392

Epoch: 5| Step: 3
Training loss: 2.1145031452178955
Validation loss: 2.30443436356001

Epoch: 5| Step: 4
Training loss: 2.5332608222961426
Validation loss: 2.320131327516289

Epoch: 5| Step: 5
Training loss: 2.7822046279907227
Validation loss: 2.329232461990849

Epoch: 5| Step: 6
Training loss: 2.382404088973999
Validation loss: 2.294578798355595

Epoch: 5| Step: 7
Training loss: 2.1100730895996094
Validation loss: 2.306266725704234

Epoch: 5| Step: 8
Training loss: 2.085218906402588
Validation loss: 2.3129671773602887

Epoch: 5| Step: 9
Training loss: 2.444427251815796
Validation loss: 2.3081699417483423

Epoch: 5| Step: 10
Training loss: 2.9989356994628906
Validation loss: 2.3268232948036602

Epoch: 29| Step: 0
Training loss: 2.9154622554779053
Validation loss: 2.3210090360333844

Epoch: 5| Step: 1
Training loss: 1.7102982997894287
Validation loss: 2.3144273296479256

Epoch: 5| Step: 2
Training loss: 2.23868989944458
Validation loss: 2.3208287121147237

Epoch: 5| Step: 3
Training loss: 2.3050930500030518
Validation loss: 2.295713318291531

Epoch: 5| Step: 4
Training loss: 3.4937236309051514
Validation loss: 2.3236316801399313

Epoch: 5| Step: 5
Training loss: 3.4217216968536377
Validation loss: 2.314361290265155

Epoch: 5| Step: 6
Training loss: 2.186588764190674
Validation loss: 2.3117702622567453

Epoch: 5| Step: 7
Training loss: 2.0593409538269043
Validation loss: 2.315441801983823

Epoch: 5| Step: 8
Training loss: 2.4546308517456055
Validation loss: 2.303607709946171

Epoch: 5| Step: 9
Training loss: 2.1064248085021973
Validation loss: 2.3048473891391548

Epoch: 5| Step: 10
Training loss: 2.5458526611328125
Validation loss: 2.3107572012050177

Epoch: 30| Step: 0
Training loss: 2.048118829727173
Validation loss: 2.292433577199136

Epoch: 5| Step: 1
Training loss: 2.2137515544891357
Validation loss: 2.3361172035176265

Epoch: 5| Step: 2
Training loss: 1.9333778619766235
Validation loss: 2.303499657620666

Epoch: 5| Step: 3
Training loss: 3.0051136016845703
Validation loss: 2.297569159538515

Epoch: 5| Step: 4
Training loss: 3.1053760051727295
Validation loss: 2.343256304340978

Epoch: 5| Step: 5
Training loss: 2.9963583946228027
Validation loss: 2.318486955858046

Epoch: 5| Step: 6
Training loss: 2.792665958404541
Validation loss: 2.292130062657018

Epoch: 5| Step: 7
Training loss: 2.218348979949951
Validation loss: 2.309116627580376

Epoch: 5| Step: 8
Training loss: 2.387974262237549
Validation loss: 2.2862254727271294

Epoch: 5| Step: 9
Training loss: 2.592132568359375
Validation loss: 2.3030540430417625

Epoch: 5| Step: 10
Training loss: 2.0656216144561768
Validation loss: 2.302509161733812

Epoch: 31| Step: 0
Training loss: 2.9267730712890625
Validation loss: 2.2969705648319696

Epoch: 5| Step: 1
Training loss: 2.6720852851867676
Validation loss: 2.297311011181083

Epoch: 5| Step: 2
Training loss: 2.6045467853546143
Validation loss: 2.296182897783095

Epoch: 5| Step: 3
Training loss: 2.3904058933258057
Validation loss: 2.3000135473025742

Epoch: 5| Step: 4
Training loss: 1.8388038873672485
Validation loss: 2.2804141031798495

Epoch: 5| Step: 5
Training loss: 2.691377878189087
Validation loss: 2.2821059944809123

Epoch: 5| Step: 6
Training loss: 2.557718276977539
Validation loss: 2.299250687322309

Epoch: 5| Step: 7
Training loss: 2.762577533721924
Validation loss: 2.299471648790503

Epoch: 5| Step: 8
Training loss: 2.841304302215576
Validation loss: 2.3056415896261893

Epoch: 5| Step: 9
Training loss: 2.089970827102661
Validation loss: 2.2857878079978367

Epoch: 5| Step: 10
Training loss: 2.0565171241760254
Validation loss: 2.2996553092874508

Epoch: 32| Step: 0
Training loss: 2.443531036376953
Validation loss: 2.274897362596245

Epoch: 5| Step: 1
Training loss: 2.493969678878784
Validation loss: 2.2789750522182834

Epoch: 5| Step: 2
Training loss: 2.735377550125122
Validation loss: 2.2840857736526

Epoch: 5| Step: 3
Training loss: 2.9125685691833496
Validation loss: 2.2807889984500025

Epoch: 5| Step: 4
Training loss: 2.447526454925537
Validation loss: 2.286306869599127

Epoch: 5| Step: 5
Training loss: 2.6681065559387207
Validation loss: 2.278678127514419

Epoch: 5| Step: 6
Training loss: 2.679872512817383
Validation loss: 2.312081754848521

Epoch: 5| Step: 7
Training loss: 2.411194086074829
Validation loss: 2.2511422916125228

Epoch: 5| Step: 8
Training loss: 1.900241494178772
Validation loss: 2.292956398379418

Epoch: 5| Step: 9
Training loss: 2.4165573120117188
Validation loss: 2.3007714774018977

Epoch: 5| Step: 10
Training loss: 2.1718502044677734
Validation loss: 2.2824304642215854

Epoch: 33| Step: 0
Training loss: 2.1244685649871826
Validation loss: 2.295433308488579

Epoch: 5| Step: 1
Training loss: 2.2581515312194824
Validation loss: 2.298627902102727

Epoch: 5| Step: 2
Training loss: 3.273530960083008
Validation loss: 2.275639272505237

Epoch: 5| Step: 3
Training loss: 2.860736131668091
Validation loss: 2.2929602694767777

Epoch: 5| Step: 4
Training loss: 2.0829997062683105
Validation loss: 2.2872879376975437

Epoch: 5| Step: 5
Training loss: 2.6283669471740723
Validation loss: 2.2626246867641324

Epoch: 5| Step: 6
Training loss: 1.9932502508163452
Validation loss: 2.3060085811922626

Epoch: 5| Step: 7
Training loss: 2.5488269329071045
Validation loss: 2.2889883928401495

Epoch: 5| Step: 8
Training loss: 2.231076717376709
Validation loss: 2.2884738445281982

Epoch: 5| Step: 9
Training loss: 2.4855940341949463
Validation loss: 2.2818694576140373

Epoch: 5| Step: 10
Training loss: 2.8032679557800293
Validation loss: 2.3152584337419078

Epoch: 34| Step: 0
Training loss: 2.1764042377471924
Validation loss: 2.2852451262935514

Epoch: 5| Step: 1
Training loss: 2.44520902633667
Validation loss: 2.287563734157111

Epoch: 5| Step: 2
Training loss: 3.2451870441436768
Validation loss: 2.272797676824754

Epoch: 5| Step: 3
Training loss: 2.548382520675659
Validation loss: 2.2807129095959406

Epoch: 5| Step: 4
Training loss: 2.649747371673584
Validation loss: 2.284023595112626

Epoch: 5| Step: 5
Training loss: 1.9328476190567017
Validation loss: 2.281935279087354

Epoch: 5| Step: 6
Training loss: 1.9010608196258545
Validation loss: 2.3121521652385755

Epoch: 5| Step: 7
Training loss: 2.8747398853302
Validation loss: 2.287584694482947

Epoch: 5| Step: 8
Training loss: 2.921117067337036
Validation loss: 2.3022524759333622

Epoch: 5| Step: 9
Training loss: 1.7625172138214111
Validation loss: 2.2795157201828493

Epoch: 5| Step: 10
Training loss: 2.749406337738037
Validation loss: 2.27801416766259

Epoch: 35| Step: 0
Training loss: 2.224409818649292
Validation loss: 2.2773328596545803

Epoch: 5| Step: 1
Training loss: 3.0856826305389404
Validation loss: 2.295897958099201

Epoch: 5| Step: 2
Training loss: 1.8274509906768799
Validation loss: 2.2645987515808432

Epoch: 5| Step: 3
Training loss: 2.7380757331848145
Validation loss: 2.268273122849003

Epoch: 5| Step: 4
Training loss: 2.488600730895996
Validation loss: 2.2903511857473724

Epoch: 5| Step: 5
Training loss: 3.238687038421631
Validation loss: 2.2874014300684773

Epoch: 5| Step: 6
Training loss: 2.493542194366455
Validation loss: 2.2833016059731923

Epoch: 5| Step: 7
Training loss: 2.159710168838501
Validation loss: 2.2909975833790277

Epoch: 5| Step: 8
Training loss: 2.7890124320983887
Validation loss: 2.2823348711895686

Epoch: 5| Step: 9
Training loss: 1.8425124883651733
Validation loss: 2.289317193851676

Epoch: 5| Step: 10
Training loss: 2.3000941276550293
Validation loss: 2.2934036690701722

Epoch: 36| Step: 0
Training loss: 2.7799441814422607
Validation loss: 2.284342204370806

Epoch: 5| Step: 1
Training loss: 2.607272148132324
Validation loss: 2.281007541123257

Epoch: 5| Step: 2
Training loss: 2.2562191486358643
Validation loss: 2.281202124011132

Epoch: 5| Step: 3
Training loss: 2.7606513500213623
Validation loss: 2.2884905312650945

Epoch: 5| Step: 4
Training loss: 2.432654857635498
Validation loss: 2.2792167791756253

Epoch: 5| Step: 5
Training loss: 2.729799747467041
Validation loss: 2.27756061989774

Epoch: 5| Step: 6
Training loss: 2.568448066711426
Validation loss: 2.2707452056228474

Epoch: 5| Step: 7
Training loss: 2.4672932624816895
Validation loss: 2.301262414583596

Epoch: 5| Step: 8
Training loss: 1.8681970834732056
Validation loss: 2.2664007294562554

Epoch: 5| Step: 9
Training loss: 2.0956783294677734
Validation loss: 2.257160609768283

Epoch: 5| Step: 10
Training loss: 2.130293369293213
Validation loss: 2.294158116463692

Epoch: 37| Step: 0
Training loss: 2.3521196842193604
Validation loss: 2.304861380207923

Epoch: 5| Step: 1
Training loss: 2.348651170730591
Validation loss: 2.250475888611168

Epoch: 5| Step: 2
Training loss: 2.060253858566284
Validation loss: 2.304565093850577

Epoch: 5| Step: 3
Training loss: 2.275585174560547
Validation loss: 2.266614657576366

Epoch: 5| Step: 4
Training loss: 2.2426416873931885
Validation loss: 2.248018972335323

Epoch: 5| Step: 5
Training loss: 2.4878134727478027
Validation loss: 2.264409439538115

Epoch: 5| Step: 6
Training loss: 2.639768362045288
Validation loss: 2.284804000649401

Epoch: 5| Step: 7
Training loss: 2.677003860473633
Validation loss: 2.2806942360375517

Epoch: 5| Step: 8
Training loss: 2.472961664199829
Validation loss: 2.2458172254664923

Epoch: 5| Step: 9
Training loss: 2.5383243560791016
Validation loss: 2.2831134539778515

Epoch: 5| Step: 10
Training loss: 2.925424575805664
Validation loss: 2.2846012756388676

Epoch: 38| Step: 0
Training loss: 2.483792543411255
Validation loss: 2.2538123874254126

Epoch: 5| Step: 1
Training loss: 2.354973077774048
Validation loss: 2.242612384980725

Epoch: 5| Step: 2
Training loss: 2.490198850631714
Validation loss: 2.263564581512123

Epoch: 5| Step: 3
Training loss: 2.5394160747528076
Validation loss: 2.2508500250436927

Epoch: 5| Step: 4
Training loss: 2.2836437225341797
Validation loss: 2.2620673461626937

Epoch: 5| Step: 5
Training loss: 2.227163076400757
Validation loss: 2.240577005570935

Epoch: 5| Step: 6
Training loss: 2.1727728843688965
Validation loss: 2.2586192443806636

Epoch: 5| Step: 7
Training loss: 2.039480686187744
Validation loss: 2.256364168659333

Epoch: 5| Step: 8
Training loss: 2.880260944366455
Validation loss: 2.2640598281737296

Epoch: 5| Step: 9
Training loss: 2.7693774700164795
Validation loss: 2.22438714068423

Epoch: 5| Step: 10
Training loss: 2.752228021621704
Validation loss: 2.2548217593982653

Epoch: 39| Step: 0
Training loss: 2.600151538848877
Validation loss: 2.257063473424604

Epoch: 5| Step: 1
Training loss: 2.069359302520752
Validation loss: 2.2298653023217314

Epoch: 5| Step: 2
Training loss: 2.371854066848755
Validation loss: 2.2845890316911923

Epoch: 5| Step: 3
Training loss: 2.233586549758911
Validation loss: 2.2650183631527807

Epoch: 5| Step: 4
Training loss: 2.7407631874084473
Validation loss: 2.2634756283093522

Epoch: 5| Step: 5
Training loss: 1.9169976711273193
Validation loss: 2.2451384375172276

Epoch: 5| Step: 6
Training loss: 2.166799783706665
Validation loss: 2.244754388768186

Epoch: 5| Step: 7
Training loss: 2.4722518920898438
Validation loss: 2.2326560533174904

Epoch: 5| Step: 8
Training loss: 2.2486486434936523
Validation loss: 2.239992226323774

Epoch: 5| Step: 9
Training loss: 2.9366917610168457
Validation loss: 2.2484891389005925

Epoch: 5| Step: 10
Training loss: 3.1578474044799805
Validation loss: 2.2449649328826577

Epoch: 40| Step: 0
Training loss: 2.0410666465759277
Validation loss: 2.2591504653294883

Epoch: 5| Step: 1
Training loss: 2.3336405754089355
Validation loss: 2.2596097787221274

Epoch: 5| Step: 2
Training loss: 1.921046257019043
Validation loss: 2.24370313203463

Epoch: 5| Step: 3
Training loss: 2.2074837684631348
Validation loss: 2.25421634668945

Epoch: 5| Step: 4
Training loss: 1.9712741374969482
Validation loss: 2.2353638884841756

Epoch: 5| Step: 5
Training loss: 3.198185443878174
Validation loss: 2.234283765157064

Epoch: 5| Step: 6
Training loss: 2.541985034942627
Validation loss: 2.2324497853555987

Epoch: 5| Step: 7
Training loss: 2.421586513519287
Validation loss: 2.2428309327812603

Epoch: 5| Step: 8
Training loss: 3.0027003288269043
Validation loss: 2.235757686758554

Epoch: 5| Step: 9
Training loss: 2.157587766647339
Validation loss: 2.230459295293336

Epoch: 5| Step: 10
Training loss: 2.925194501876831
Validation loss: 2.2385181829493535

Epoch: 41| Step: 0
Training loss: 1.973710298538208
Validation loss: 2.2429857971847698

Epoch: 5| Step: 1
Training loss: 2.5355610847473145
Validation loss: 2.2251087965503817

Epoch: 5| Step: 2
Training loss: 2.648799180984497
Validation loss: 2.2274639055293095

Epoch: 5| Step: 3
Training loss: 2.0955705642700195
Validation loss: 2.2301508893248854

Epoch: 5| Step: 4
Training loss: 2.775433301925659
Validation loss: 2.258578613240232

Epoch: 5| Step: 5
Training loss: 2.1916165351867676
Validation loss: 2.2479598650368313

Epoch: 5| Step: 6
Training loss: 2.5570156574249268
Validation loss: 2.238773094710483

Epoch: 5| Step: 7
Training loss: 3.159686326980591
Validation loss: 2.230131777383948

Epoch: 5| Step: 8
Training loss: 2.2425942420959473
Validation loss: 2.239388737627255

Epoch: 5| Step: 9
Training loss: 1.8372809886932373
Validation loss: 2.2437357902526855

Epoch: 5| Step: 10
Training loss: 2.5053646564483643
Validation loss: 2.2295854476190384

Epoch: 42| Step: 0
Training loss: 2.227393627166748
Validation loss: 2.2388484862542923

Epoch: 5| Step: 1
Training loss: 2.6154634952545166
Validation loss: 2.2518761978354505

Epoch: 5| Step: 2
Training loss: 2.08172607421875
Validation loss: 2.221936684782787

Epoch: 5| Step: 3
Training loss: 2.105477809906006
Validation loss: 2.233458995819092

Epoch: 5| Step: 4
Training loss: 2.842158079147339
Validation loss: 2.2357604580540813

Epoch: 5| Step: 5
Training loss: 2.0395679473876953
Validation loss: 2.210337063317658

Epoch: 5| Step: 6
Training loss: 2.453944683074951
Validation loss: 2.243866735889066

Epoch: 5| Step: 7
Training loss: 2.017719030380249
Validation loss: 2.2262076575268983

Epoch: 5| Step: 8
Training loss: 2.3902266025543213
Validation loss: 2.2224262350349018

Epoch: 5| Step: 9
Training loss: 2.3220348358154297
Validation loss: 2.251096148644724

Epoch: 5| Step: 10
Training loss: 3.409247875213623
Validation loss: 2.2424115545006207

Epoch: 43| Step: 0
Training loss: 2.429434299468994
Validation loss: 2.231529047412257

Epoch: 5| Step: 1
Training loss: 1.9372354745864868
Validation loss: 2.2341298698097147

Epoch: 5| Step: 2
Training loss: 2.463463544845581
Validation loss: 2.2191106837282897

Epoch: 5| Step: 3
Training loss: 2.7778093814849854
Validation loss: 2.2078466646132933

Epoch: 5| Step: 4
Training loss: 2.343890428543091
Validation loss: 2.2124361017698884

Epoch: 5| Step: 5
Training loss: 2.596554756164551
Validation loss: 2.2048557381476126

Epoch: 5| Step: 6
Training loss: 2.0728416442871094
Validation loss: 2.2179693457900838

Epoch: 5| Step: 7
Training loss: 2.6843032836914062
Validation loss: 2.210917636912356

Epoch: 5| Step: 8
Training loss: 2.563171625137329
Validation loss: 2.2205281180720173

Epoch: 5| Step: 9
Training loss: 2.2867400646209717
Validation loss: 2.224607603524321

Epoch: 5| Step: 10
Training loss: 2.4394583702087402
Validation loss: 2.235424554476174

Epoch: 44| Step: 0
Training loss: 2.119874954223633
Validation loss: 2.199889841900077

Epoch: 5| Step: 1
Training loss: 2.6981801986694336
Validation loss: 2.20866387121139

Epoch: 5| Step: 2
Training loss: 2.8729262351989746
Validation loss: 2.197400072569488

Epoch: 5| Step: 3
Training loss: 2.8069496154785156
Validation loss: 2.20710148349885

Epoch: 5| Step: 4
Training loss: 1.9243381023406982
Validation loss: 2.198961247680008

Epoch: 5| Step: 5
Training loss: 1.83356511592865
Validation loss: 2.230046997788132

Epoch: 5| Step: 6
Training loss: 2.362135410308838
Validation loss: 2.201236669735242

Epoch: 5| Step: 7
Training loss: 1.79096257686615
Validation loss: 2.216822143523924

Epoch: 5| Step: 8
Training loss: 1.7346893548965454
Validation loss: 2.2175595632163425

Epoch: 5| Step: 9
Training loss: 3.4386775493621826
Validation loss: 2.185594576661305

Epoch: 5| Step: 10
Training loss: 2.6312928199768066
Validation loss: 2.23872104255102

Epoch: 45| Step: 0
Training loss: 2.534090518951416
Validation loss: 2.2081813555891796

Epoch: 5| Step: 1
Training loss: 1.9445089101791382
Validation loss: 2.216851924055366

Epoch: 5| Step: 2
Training loss: 1.9986671209335327
Validation loss: 2.2042200975520636

Epoch: 5| Step: 3
Training loss: 2.6331112384796143
Validation loss: 2.221691882738503

Epoch: 5| Step: 4
Training loss: 1.7543437480926514
Validation loss: 2.214223769403273

Epoch: 5| Step: 5
Training loss: 3.1032803058624268
Validation loss: 2.1946914452378468

Epoch: 5| Step: 6
Training loss: 2.570040464401245
Validation loss: 2.1782530302642495

Epoch: 5| Step: 7
Training loss: 1.9405256509780884
Validation loss: 2.1817626081487185

Epoch: 5| Step: 8
Training loss: 2.9522085189819336
Validation loss: 2.1999052186166086

Epoch: 5| Step: 9
Training loss: 2.3147096633911133
Validation loss: 2.1908199274411766

Epoch: 5| Step: 10
Training loss: 2.631807565689087
Validation loss: 2.2385481378083587

Epoch: 46| Step: 0
Training loss: 1.990033745765686
Validation loss: 2.1985310559631674

Epoch: 5| Step: 1
Training loss: 2.5601248741149902
Validation loss: 2.1900327218476163

Epoch: 5| Step: 2
Training loss: 2.144270181655884
Validation loss: 2.1988987589395173

Epoch: 5| Step: 3
Training loss: 2.1561472415924072
Validation loss: 2.187871192091255

Epoch: 5| Step: 4
Training loss: 2.5827746391296387
Validation loss: 2.198247722400132

Epoch: 5| Step: 5
Training loss: 2.420888662338257
Validation loss: 2.238924285416962

Epoch: 5| Step: 6
Training loss: 2.5439438819885254
Validation loss: 2.2010325821497108

Epoch: 5| Step: 7
Training loss: 2.3369216918945312
Validation loss: 2.2007960196464293

Epoch: 5| Step: 8
Training loss: 2.3749356269836426
Validation loss: 2.2315944240939234

Epoch: 5| Step: 9
Training loss: 2.587543249130249
Validation loss: 2.215889992252473

Epoch: 5| Step: 10
Training loss: 2.601205587387085
Validation loss: 2.2114265657240346

Epoch: 47| Step: 0
Training loss: 2.370690107345581
Validation loss: 2.2244239314909904

Epoch: 5| Step: 1
Training loss: 2.018049716949463
Validation loss: 2.2026749964683288

Epoch: 5| Step: 2
Training loss: 2.6851842403411865
Validation loss: 2.2299814519061836

Epoch: 5| Step: 3
Training loss: 1.9413944482803345
Validation loss: 2.2275956625579507

Epoch: 5| Step: 4
Training loss: 2.7540667057037354
Validation loss: 2.2231632355720765

Epoch: 5| Step: 5
Training loss: 2.607973337173462
Validation loss: 2.2075165240995345

Epoch: 5| Step: 6
Training loss: 2.593477725982666
Validation loss: 2.1850063954630206

Epoch: 5| Step: 7
Training loss: 2.5309250354766846
Validation loss: 2.2218511566039054

Epoch: 5| Step: 8
Training loss: 2.3637309074401855
Validation loss: 2.1831667320702666

Epoch: 5| Step: 9
Training loss: 2.0361104011535645
Validation loss: 2.220912261675763

Epoch: 5| Step: 10
Training loss: 2.011810302734375
Validation loss: 2.1915761950195476

Epoch: 48| Step: 0
Training loss: 2.667469024658203
Validation loss: 2.1945955189325477

Epoch: 5| Step: 1
Training loss: 2.7027809619903564
Validation loss: 2.2058326223845124

Epoch: 5| Step: 2
Training loss: 1.9300010204315186
Validation loss: 2.155782489366429

Epoch: 5| Step: 3
Training loss: 2.9869561195373535
Validation loss: 2.166244856772884

Epoch: 5| Step: 4
Training loss: 1.9784832000732422
Validation loss: 2.1875133078585387

Epoch: 5| Step: 5
Training loss: 2.30938982963562
Validation loss: 2.1906494632844002

Epoch: 5| Step: 6
Training loss: 2.9039275646209717
Validation loss: 2.177035036907401

Epoch: 5| Step: 7
Training loss: 2.351933240890503
Validation loss: 2.230921781191262

Epoch: 5| Step: 8
Training loss: 2.3135764598846436
Validation loss: 2.1827598169285762

Epoch: 5| Step: 9
Training loss: 1.8708690404891968
Validation loss: 2.210332138563997

Epoch: 5| Step: 10
Training loss: 1.8058247566223145
Validation loss: 2.1978057020454

Epoch: 49| Step: 0
Training loss: 2.3375678062438965
Validation loss: 2.1743588268115954

Epoch: 5| Step: 1
Training loss: 2.635443687438965
Validation loss: 2.158093995945428

Epoch: 5| Step: 2
Training loss: 2.0030407905578613
Validation loss: 2.1810850122923493

Epoch: 5| Step: 3
Training loss: 2.773594856262207
Validation loss: 2.1911623452299382

Epoch: 5| Step: 4
Training loss: 2.046602487564087
Validation loss: 2.207715972777336

Epoch: 5| Step: 5
Training loss: 2.5423481464385986
Validation loss: 2.19133787257697

Epoch: 5| Step: 6
Training loss: 2.5197510719299316
Validation loss: 2.1809912702088714

Epoch: 5| Step: 7
Training loss: 1.8354161977767944
Validation loss: 2.1823396836557696

Epoch: 5| Step: 8
Training loss: 2.5553460121154785
Validation loss: 2.1913882891337075

Epoch: 5| Step: 9
Training loss: 2.0837104320526123
Validation loss: 2.195509333764353

Epoch: 5| Step: 10
Training loss: 2.3114678859710693
Validation loss: 2.1898929995875203

Epoch: 50| Step: 0
Training loss: 2.6717731952667236
Validation loss: 2.224003038098735

Epoch: 5| Step: 1
Training loss: 2.5396504402160645
Validation loss: 2.1777861631044777

Epoch: 5| Step: 2
Training loss: 2.9195876121520996
Validation loss: 2.18174655975834

Epoch: 5| Step: 3
Training loss: 2.1319756507873535
Validation loss: 2.2108328816711262

Epoch: 5| Step: 4
Training loss: 2.177116870880127
Validation loss: 2.181082240996822

Epoch: 5| Step: 5
Training loss: 1.568993330001831
Validation loss: 2.1758959959912043

Epoch: 5| Step: 6
Training loss: 2.4648842811584473
Validation loss: 2.205790545350762

Epoch: 5| Step: 7
Training loss: 2.731387138366699
Validation loss: 2.2157861468612507

Epoch: 5| Step: 8
Training loss: 2.250927448272705
Validation loss: 2.180922222393815

Epoch: 5| Step: 9
Training loss: 1.7971004247665405
Validation loss: 2.2257178932107906

Epoch: 5| Step: 10
Training loss: 2.3610310554504395
Validation loss: 2.176839820800289

Epoch: 51| Step: 0
Training loss: 2.384384870529175
Validation loss: 2.1937751347018826

Epoch: 5| Step: 1
Training loss: 2.410571575164795
Validation loss: 2.1944391881265948

Epoch: 5| Step: 2
Training loss: 2.7165274620056152
Validation loss: 2.1815825687941683

Epoch: 5| Step: 3
Training loss: 1.7576444149017334
Validation loss: 2.17294248970606

Epoch: 5| Step: 4
Training loss: 1.8775503635406494
Validation loss: 2.1818083024794057

Epoch: 5| Step: 5
Training loss: 2.311586618423462
Validation loss: 2.162925176723029

Epoch: 5| Step: 6
Training loss: 1.9466445446014404
Validation loss: 2.183206417227304

Epoch: 5| Step: 7
Training loss: 2.5214622020721436
Validation loss: 2.150003788291767

Epoch: 5| Step: 8
Training loss: 2.3497047424316406
Validation loss: 2.1698024683101202

Epoch: 5| Step: 9
Training loss: 2.571416139602661
Validation loss: 2.1531065112801007

Epoch: 5| Step: 10
Training loss: 2.703165054321289
Validation loss: 2.167452094375446

Epoch: 52| Step: 0
Training loss: 2.1239023208618164
Validation loss: 2.2133063936746247

Epoch: 5| Step: 1
Training loss: 2.903278350830078
Validation loss: 2.1786365957670313

Epoch: 5| Step: 2
Training loss: 3.096259117126465
Validation loss: 2.155714019652336

Epoch: 5| Step: 3
Training loss: 1.8822110891342163
Validation loss: 2.166814893804571

Epoch: 5| Step: 4
Training loss: 2.1527903079986572
Validation loss: 2.191260168629308

Epoch: 5| Step: 5
Training loss: 1.9783287048339844
Validation loss: 2.1595823354618524

Epoch: 5| Step: 6
Training loss: 2.6853737831115723
Validation loss: 2.167873397950203

Epoch: 5| Step: 7
Training loss: 1.7547271251678467
Validation loss: 2.200242342487458

Epoch: 5| Step: 8
Training loss: 2.4356846809387207
Validation loss: 2.1463218248018654

Epoch: 5| Step: 9
Training loss: 2.383131504058838
Validation loss: 2.149444974878783

Epoch: 5| Step: 10
Training loss: 2.5013489723205566
Validation loss: 2.1945768928015106

Epoch: 53| Step: 0
Training loss: 1.4156206846237183
Validation loss: 2.191159168879191

Epoch: 5| Step: 1
Training loss: 2.661125659942627
Validation loss: 2.17679016564482

Epoch: 5| Step: 2
Training loss: 2.9269580841064453
Validation loss: 2.170656893842964

Epoch: 5| Step: 3
Training loss: 3.0564162731170654
Validation loss: 2.187757399774367

Epoch: 5| Step: 4
Training loss: 2.5734927654266357
Validation loss: 2.1870341582964827

Epoch: 5| Step: 5
Training loss: 2.123314380645752
Validation loss: 2.175699536518384

Epoch: 5| Step: 6
Training loss: 2.573345899581909
Validation loss: 2.213999166283556

Epoch: 5| Step: 7
Training loss: 2.351292848587036
Validation loss: 2.1958872938668854

Epoch: 5| Step: 8
Training loss: 2.2792725563049316
Validation loss: 2.1927037982530493

Epoch: 5| Step: 9
Training loss: 1.8093807697296143
Validation loss: 2.194210285781532

Epoch: 5| Step: 10
Training loss: 1.6507692337036133
Validation loss: 2.170688133085928

Epoch: 54| Step: 0
Training loss: 2.1087300777435303
Validation loss: 2.2148936897195797

Epoch: 5| Step: 1
Training loss: 2.5655674934387207
Validation loss: 2.233705569339055

Epoch: 5| Step: 2
Training loss: 2.398686170578003
Validation loss: 2.218081863977576

Epoch: 5| Step: 3
Training loss: 2.4230122566223145
Validation loss: 2.1922266714034544

Epoch: 5| Step: 4
Training loss: 2.2059175968170166
Validation loss: 2.180611479666925

Epoch: 5| Step: 5
Training loss: 3.110229015350342
Validation loss: 2.2349698107729674

Epoch: 5| Step: 6
Training loss: 1.7346923351287842
Validation loss: 2.200923776113859

Epoch: 5| Step: 7
Training loss: 2.576592206954956
Validation loss: 2.1640292982901297

Epoch: 5| Step: 8
Training loss: 2.0506722927093506
Validation loss: 2.186199172850578

Epoch: 5| Step: 9
Training loss: 2.2872672080993652
Validation loss: 2.183168611218852

Epoch: 5| Step: 10
Training loss: 1.7915419340133667
Validation loss: 2.1923636518498903

Epoch: 55| Step: 0
Training loss: 2.862264633178711
Validation loss: 2.186658807980117

Epoch: 5| Step: 1
Training loss: 2.1687216758728027
Validation loss: 2.207073219360844

Epoch: 5| Step: 2
Training loss: 2.5641562938690186
Validation loss: 2.1719108114960375

Epoch: 5| Step: 3
Training loss: 2.9153318405151367
Validation loss: 2.1851737024963542

Epoch: 5| Step: 4
Training loss: 1.660881757736206
Validation loss: 2.192038251507667

Epoch: 5| Step: 5
Training loss: 2.157973289489746
Validation loss: 2.19649145167361

Epoch: 5| Step: 6
Training loss: 2.3791942596435547
Validation loss: 2.1964912312005156

Epoch: 5| Step: 7
Training loss: 2.2171521186828613
Validation loss: 2.193195676290861

Epoch: 5| Step: 8
Training loss: 2.176231861114502
Validation loss: 2.233596319793373

Epoch: 5| Step: 9
Training loss: 2.1877474784851074
Validation loss: 2.1971028363832863

Epoch: 5| Step: 10
Training loss: 1.864659070968628
Validation loss: 2.1963303089141846

Epoch: 56| Step: 0
Training loss: 2.8790788650512695
Validation loss: 2.1868339225810063

Epoch: 5| Step: 1
Training loss: 2.2408909797668457
Validation loss: 2.201289200013684

Epoch: 5| Step: 2
Training loss: 1.8782075643539429
Validation loss: 2.2003144192439255

Epoch: 5| Step: 3
Training loss: 3.0851099491119385
Validation loss: 2.178833592322565

Epoch: 5| Step: 4
Training loss: 2.2410037517547607
Validation loss: 2.177634600670107

Epoch: 5| Step: 5
Training loss: 2.462468147277832
Validation loss: 2.189250692244499

Epoch: 5| Step: 6
Training loss: 2.010556697845459
Validation loss: 2.1848833612216416

Epoch: 5| Step: 7
Training loss: 2.3294410705566406
Validation loss: 2.2189425755572576

Epoch: 5| Step: 8
Training loss: 1.859757661819458
Validation loss: 2.1882529412546465

Epoch: 5| Step: 9
Training loss: 1.8884334564208984
Validation loss: 2.1824999547773793

Epoch: 5| Step: 10
Training loss: 2.2853660583496094
Validation loss: 2.208167524747951

Epoch: 57| Step: 0
Training loss: 2.8962671756744385
Validation loss: 2.1903691907082834

Epoch: 5| Step: 1
Training loss: 2.4385533332824707
Validation loss: 2.1629376437074397

Epoch: 5| Step: 2
Training loss: 2.0231335163116455
Validation loss: 2.15398040381811

Epoch: 5| Step: 3
Training loss: 2.067866802215576
Validation loss: 2.1575615713673253

Epoch: 5| Step: 4
Training loss: 2.3735873699188232
Validation loss: 2.170970424529045

Epoch: 5| Step: 5
Training loss: 2.726454257965088
Validation loss: 2.164816200092275

Epoch: 5| Step: 6
Training loss: 1.897804617881775
Validation loss: 2.1615691774634906

Epoch: 5| Step: 7
Training loss: 2.716803789138794
Validation loss: 2.190736997512079

Epoch: 5| Step: 8
Training loss: 1.7600109577178955
Validation loss: 2.1683816448334725

Epoch: 5| Step: 9
Training loss: 1.920975685119629
Validation loss: 2.1705411044500207

Epoch: 5| Step: 10
Training loss: 2.2637295722961426
Validation loss: 2.1432041288704

Epoch: 58| Step: 0
Training loss: 1.5366880893707275
Validation loss: 2.156009269017045

Epoch: 5| Step: 1
Training loss: 2.1111397743225098
Validation loss: 2.172344156490859

Epoch: 5| Step: 2
Training loss: 2.3403496742248535
Validation loss: 2.1813786029815674

Epoch: 5| Step: 3
Training loss: 2.5113449096679688
Validation loss: 2.174582846703068

Epoch: 5| Step: 4
Training loss: 2.752584457397461
Validation loss: 2.1552140635828816

Epoch: 5| Step: 5
Training loss: 2.5204501152038574
Validation loss: 2.18525969084873

Epoch: 5| Step: 6
Training loss: 2.4170479774475098
Validation loss: 2.198569877173311

Epoch: 5| Step: 7
Training loss: 2.219743251800537
Validation loss: 2.18051468172381

Epoch: 5| Step: 8
Training loss: 1.7225754261016846
Validation loss: 2.1606829986777356

Epoch: 5| Step: 9
Training loss: 2.2741236686706543
Validation loss: 2.1846578172458115

Epoch: 5| Step: 10
Training loss: 2.630864381790161
Validation loss: 2.2034043112108783

Epoch: 59| Step: 0
Training loss: 3.0212302207946777
Validation loss: 2.172981087879468

Epoch: 5| Step: 1
Training loss: 2.6577560901641846
Validation loss: 2.192869145383117

Epoch: 5| Step: 2
Training loss: 1.9051014184951782
Validation loss: 2.167854478282313

Epoch: 5| Step: 3
Training loss: 2.20192289352417
Validation loss: 2.203500178552443

Epoch: 5| Step: 4
Training loss: 2.2543113231658936
Validation loss: 2.173514304622527

Epoch: 5| Step: 5
Training loss: 2.648853063583374
Validation loss: 2.1609827805590887

Epoch: 5| Step: 6
Training loss: 2.633993148803711
Validation loss: 2.1878328041363786

Epoch: 5| Step: 7
Training loss: 1.3693324327468872
Validation loss: 2.167958080127675

Epoch: 5| Step: 8
Training loss: 2.1293115615844727
Validation loss: 2.174617308442311

Epoch: 5| Step: 9
Training loss: 1.9143216609954834
Validation loss: 2.1888503515592186

Epoch: 5| Step: 10
Training loss: 2.474161386489868
Validation loss: 2.1683066224539154

Epoch: 60| Step: 0
Training loss: 2.104001998901367
Validation loss: 2.1603978269843647

Epoch: 5| Step: 1
Training loss: 2.531407594680786
Validation loss: 2.1690005897193827

Epoch: 5| Step: 2
Training loss: 2.3276658058166504
Validation loss: 2.178545162241946

Epoch: 5| Step: 3
Training loss: 2.706958770751953
Validation loss: 2.1719875874057895

Epoch: 5| Step: 4
Training loss: 2.1533329486846924
Validation loss: 2.177101860764206

Epoch: 5| Step: 5
Training loss: 2.364166259765625
Validation loss: 2.1692995396993493

Epoch: 5| Step: 6
Training loss: 2.482649803161621
Validation loss: 2.156582634936097

Epoch: 5| Step: 7
Training loss: 2.107924222946167
Validation loss: 2.1949491475218084

Epoch: 5| Step: 8
Training loss: 2.2360291481018066
Validation loss: 2.2022462198811192

Epoch: 5| Step: 9
Training loss: 2.062887668609619
Validation loss: 2.1796200608694427

Epoch: 5| Step: 10
Training loss: 2.0181140899658203
Validation loss: 2.186354580745902

Epoch: 61| Step: 0
Training loss: 2.042940855026245
Validation loss: 2.1578528881073

Epoch: 5| Step: 1
Training loss: 3.27485728263855
Validation loss: 2.1506387520861883

Epoch: 5| Step: 2
Training loss: 2.0907139778137207
Validation loss: 2.1688929552673013

Epoch: 5| Step: 3
Training loss: 2.6138336658477783
Validation loss: 2.163932749020156

Epoch: 5| Step: 4
Training loss: 1.9605960845947266
Validation loss: 2.1710631129562215

Epoch: 5| Step: 5
Training loss: 2.4692282676696777
Validation loss: 2.163784611609674

Epoch: 5| Step: 6
Training loss: 2.3658981323242188
Validation loss: 2.186357823751306

Epoch: 5| Step: 7
Training loss: 1.9945542812347412
Validation loss: 2.1738556623458862

Epoch: 5| Step: 8
Training loss: 2.398944139480591
Validation loss: 2.171020810322095

Epoch: 5| Step: 9
Training loss: 1.5454280376434326
Validation loss: 2.175559480985006

Epoch: 5| Step: 10
Training loss: 2.247913122177124
Validation loss: 2.1450314701244397

Epoch: 62| Step: 0
Training loss: 2.115636110305786
Validation loss: 2.16855574551449

Epoch: 5| Step: 1
Training loss: 2.1222429275512695
Validation loss: 2.187870563999299

Epoch: 5| Step: 2
Training loss: 1.6777347326278687
Validation loss: 2.1690560207572034

Epoch: 5| Step: 3
Training loss: 2.8472952842712402
Validation loss: 2.19260303179423

Epoch: 5| Step: 4
Training loss: 1.98922860622406
Validation loss: 2.1649549699598745

Epoch: 5| Step: 5
Training loss: 2.8464252948760986
Validation loss: 2.1798165562332317

Epoch: 5| Step: 6
Training loss: 2.114675998687744
Validation loss: 2.1746496013415757

Epoch: 5| Step: 7
Training loss: 2.9544999599456787
Validation loss: 2.1664506414885163

Epoch: 5| Step: 8
Training loss: 1.8484452962875366
Validation loss: 2.166414363409883

Epoch: 5| Step: 9
Training loss: 2.2706451416015625
Validation loss: 2.157757277129799

Epoch: 5| Step: 10
Training loss: 2.06601881980896
Validation loss: 2.152648533544233

Epoch: 63| Step: 0
Training loss: 1.8791687488555908
Validation loss: 2.1648059839843423

Epoch: 5| Step: 1
Training loss: 2.3332390785217285
Validation loss: 2.1850705851790724

Epoch: 5| Step: 2
Training loss: 2.284592390060425
Validation loss: 2.1945031714695755

Epoch: 5| Step: 3
Training loss: 2.4455184936523438
Validation loss: 2.1763351886503157

Epoch: 5| Step: 4
Training loss: 2.2065796852111816
Validation loss: 2.1540110482964465

Epoch: 5| Step: 5
Training loss: 2.389444351196289
Validation loss: 2.183278847766179

Epoch: 5| Step: 6
Training loss: 2.010099411010742
Validation loss: 2.1908203760782876

Epoch: 5| Step: 7
Training loss: 2.0246405601501465
Validation loss: 2.1793517579314527

Epoch: 5| Step: 8
Training loss: 2.264317750930786
Validation loss: 2.174858134279969

Epoch: 5| Step: 9
Training loss: 2.6690471172332764
Validation loss: 2.1490865932997836

Epoch: 5| Step: 10
Training loss: 2.214099645614624
Validation loss: 2.176956399794548

Epoch: 64| Step: 0
Training loss: 2.703826665878296
Validation loss: 2.1550439814085602

Epoch: 5| Step: 1
Training loss: 3.26839017868042
Validation loss: 2.191848576709788

Epoch: 5| Step: 2
Training loss: 2.1323580741882324
Validation loss: 2.1679261320380756

Epoch: 5| Step: 3
Training loss: 1.9354474544525146
Validation loss: 2.1633447472767164

Epoch: 5| Step: 4
Training loss: 2.475553274154663
Validation loss: 2.1781980401726178

Epoch: 5| Step: 5
Training loss: 2.2504544258117676
Validation loss: 2.19394709474297

Epoch: 5| Step: 6
Training loss: 2.260603666305542
Validation loss: 2.1726430308434272

Epoch: 5| Step: 7
Training loss: 2.132167339324951
Validation loss: 2.16970766744306

Epoch: 5| Step: 8
Training loss: 1.9762260913848877
Validation loss: 2.1602326362363753

Epoch: 5| Step: 9
Training loss: 1.5236387252807617
Validation loss: 2.1541950651394424

Epoch: 5| Step: 10
Training loss: 2.214853525161743
Validation loss: 2.1915372904910835

Epoch: 65| Step: 0
Training loss: 2.3586182594299316
Validation loss: 2.1623790648675736

Epoch: 5| Step: 1
Training loss: 1.8036819696426392
Validation loss: 2.1754379067369687

Epoch: 5| Step: 2
Training loss: 1.712040662765503
Validation loss: 2.164494836202232

Epoch: 5| Step: 3
Training loss: 2.8594093322753906
Validation loss: 2.164000988006592

Epoch: 5| Step: 4
Training loss: 2.8616456985473633
Validation loss: 2.166954917292441

Epoch: 5| Step: 5
Training loss: 2.28210186958313
Validation loss: 2.167888384993358

Epoch: 5| Step: 6
Training loss: 2.068467617034912
Validation loss: 2.145568219564294

Epoch: 5| Step: 7
Training loss: 2.6791980266571045
Validation loss: 2.1892789410006617

Epoch: 5| Step: 8
Training loss: 1.9469947814941406
Validation loss: 2.1428918992319415

Epoch: 5| Step: 9
Training loss: 2.314378261566162
Validation loss: 2.157850270630211

Epoch: 5| Step: 10
Training loss: 1.8498402833938599
Validation loss: 2.145921440534694

Epoch: 66| Step: 0
Training loss: 1.926459550857544
Validation loss: 2.1972694371336248

Epoch: 5| Step: 1
Training loss: 2.7654707431793213
Validation loss: 2.193021857610313

Epoch: 5| Step: 2
Training loss: 2.9155218601226807
Validation loss: 2.15187269385143

Epoch: 5| Step: 3
Training loss: 2.2004106044769287
Validation loss: 2.1690450304297992

Epoch: 5| Step: 4
Training loss: 1.9733400344848633
Validation loss: 2.182599200997301

Epoch: 5| Step: 5
Training loss: 2.834965467453003
Validation loss: 2.1540836903356735

Epoch: 5| Step: 6
Training loss: 1.8955034017562866
Validation loss: 2.154826892319546

Epoch: 5| Step: 7
Training loss: 2.1497013568878174
Validation loss: 2.1730887146406275

Epoch: 5| Step: 8
Training loss: 2.216627836227417
Validation loss: 2.19595181685622

Epoch: 5| Step: 9
Training loss: 2.3973159790039062
Validation loss: 2.159057032677435

Epoch: 5| Step: 10
Training loss: 1.624839425086975
Validation loss: 2.219992140287994

Epoch: 67| Step: 0
Training loss: 2.364502429962158
Validation loss: 2.1857271553367696

Epoch: 5| Step: 1
Training loss: 2.2181694507598877
Validation loss: 2.176306960403278

Epoch: 5| Step: 2
Training loss: 2.2846665382385254
Validation loss: 2.19004165228977

Epoch: 5| Step: 3
Training loss: 2.513280153274536
Validation loss: 2.149904686917541

Epoch: 5| Step: 4
Training loss: 3.0848238468170166
Validation loss: 2.162677034254997

Epoch: 5| Step: 5
Training loss: 2.0437071323394775
Validation loss: 2.2066983586998394

Epoch: 5| Step: 6
Training loss: 1.6643438339233398
Validation loss: 2.199995199839274

Epoch: 5| Step: 7
Training loss: 2.2106454372406006
Validation loss: 2.2060500139831216

Epoch: 5| Step: 8
Training loss: 1.7893253564834595
Validation loss: 2.200646323542441

Epoch: 5| Step: 9
Training loss: 2.603908061981201
Validation loss: 2.2129096228589296

Epoch: 5| Step: 10
Training loss: 2.2316675186157227
Validation loss: 2.175534135551863

Epoch: 68| Step: 0
Training loss: 1.875637412071228
Validation loss: 2.2034800309006886

Epoch: 5| Step: 1
Training loss: 2.2825474739074707
Validation loss: 2.20269743088753

Epoch: 5| Step: 2
Training loss: 2.2507925033569336
Validation loss: 2.212502062961619

Epoch: 5| Step: 3
Training loss: 1.789459228515625
Validation loss: 2.208615505567161

Epoch: 5| Step: 4
Training loss: 1.9975273609161377
Validation loss: 2.1949278039316975

Epoch: 5| Step: 5
Training loss: 1.952200174331665
Validation loss: 2.167891234479925

Epoch: 5| Step: 6
Training loss: 2.1544785499572754
Validation loss: 2.1988596403470604

Epoch: 5| Step: 7
Training loss: 3.029402494430542
Validation loss: 2.222388479017442

Epoch: 5| Step: 8
Training loss: 3.587271213531494
Validation loss: 2.1681180077214397

Epoch: 5| Step: 9
Training loss: 1.8717275857925415
Validation loss: 2.18480097862982

Epoch: 5| Step: 10
Training loss: 2.1277401447296143
Validation loss: 2.1843803428834483

Epoch: 69| Step: 0
Training loss: 1.9871383905410767
Validation loss: 2.19238176397098

Epoch: 5| Step: 1
Training loss: 2.71103572845459
Validation loss: 2.1927047826910533

Epoch: 5| Step: 2
Training loss: 2.1649162769317627
Validation loss: 2.166149200931672

Epoch: 5| Step: 3
Training loss: 2.014741897583008
Validation loss: 2.197274331123598

Epoch: 5| Step: 4
Training loss: 2.269656181335449
Validation loss: 2.1821813275737147

Epoch: 5| Step: 5
Training loss: 2.3430638313293457
Validation loss: 2.203245565455447

Epoch: 5| Step: 6
Training loss: 2.1736996173858643
Validation loss: 2.148136390152798

Epoch: 5| Step: 7
Training loss: 2.683664321899414
Validation loss: 2.166026787091327

Epoch: 5| Step: 8
Training loss: 2.126237392425537
Validation loss: 2.1536963729448217

Epoch: 5| Step: 9
Training loss: 2.1034884452819824
Validation loss: 2.1831311718110116

Epoch: 5| Step: 10
Training loss: 2.1726326942443848
Validation loss: 2.173768078127215

Epoch: 70| Step: 0
Training loss: 2.345240592956543
Validation loss: 2.146785372047014

Epoch: 5| Step: 1
Training loss: 2.482926607131958
Validation loss: 2.155997876198061

Epoch: 5| Step: 2
Training loss: 1.7602665424346924
Validation loss: 2.153337317128335

Epoch: 5| Step: 3
Training loss: 1.9381558895111084
Validation loss: 2.174722912491009

Epoch: 5| Step: 4
Training loss: 2.8958194255828857
Validation loss: 2.1369308181988296

Epoch: 5| Step: 5
Training loss: 1.9311691522598267
Validation loss: 2.1422696972406037

Epoch: 5| Step: 6
Training loss: 2.2861990928649902
Validation loss: 2.148863207909369

Epoch: 5| Step: 7
Training loss: 2.2775259017944336
Validation loss: 2.131328571227289

Epoch: 5| Step: 8
Training loss: 2.0281729698181152
Validation loss: 2.1635737137127946

Epoch: 5| Step: 9
Training loss: 2.342881679534912
Validation loss: 2.139176445622598

Epoch: 5| Step: 10
Training loss: 2.4597697257995605
Validation loss: 2.1500873437491794

Epoch: 71| Step: 0
Training loss: 1.8228509426116943
Validation loss: 2.152020210860878

Epoch: 5| Step: 1
Training loss: 2.292618751525879
Validation loss: 2.1605050845812728

Epoch: 5| Step: 2
Training loss: 2.310807228088379
Validation loss: 2.1476222597142702

Epoch: 5| Step: 3
Training loss: 2.565779685974121
Validation loss: 2.1915868777100758

Epoch: 5| Step: 4
Training loss: 2.8476176261901855
Validation loss: 2.1126057499198505

Epoch: 5| Step: 5
Training loss: 1.9738662242889404
Validation loss: 2.1275753795459704

Epoch: 5| Step: 6
Training loss: 2.0613577365875244
Validation loss: 2.1686194289115166

Epoch: 5| Step: 7
Training loss: 1.9183257818222046
Validation loss: 2.16899279368821

Epoch: 5| Step: 8
Training loss: 2.5170392990112305
Validation loss: 2.1810798734746952

Epoch: 5| Step: 9
Training loss: 2.207158088684082
Validation loss: 2.1393967059350785

Epoch: 5| Step: 10
Training loss: 2.0373735427856445
Validation loss: 2.123168929930656

Epoch: 72| Step: 0
Training loss: 2.241300582885742
Validation loss: 2.1995860325392855

Epoch: 5| Step: 1
Training loss: 2.375675678253174
Validation loss: 2.1790001943547237

Epoch: 5| Step: 2
Training loss: 1.5162657499313354
Validation loss: 2.1637997678531113

Epoch: 5| Step: 3
Training loss: 2.7366135120391846
Validation loss: 2.180074435408397

Epoch: 5| Step: 4
Training loss: 2.1883113384246826
Validation loss: 2.1851146169888076

Epoch: 5| Step: 5
Training loss: 2.3375706672668457
Validation loss: 2.184632367985223

Epoch: 5| Step: 6
Training loss: 3.042558193206787
Validation loss: 2.1459873901900424

Epoch: 5| Step: 7
Training loss: 1.8466472625732422
Validation loss: 2.201140219165433

Epoch: 5| Step: 8
Training loss: 2.1877951622009277
Validation loss: 2.152753808165109

Epoch: 5| Step: 9
Training loss: 2.13006854057312
Validation loss: 2.1956714096889702

Epoch: 5| Step: 10
Training loss: 1.8811129331588745
Validation loss: 2.1645394332947268

Epoch: 73| Step: 0
Training loss: 1.9479392766952515
Validation loss: 2.18171723170947

Epoch: 5| Step: 1
Training loss: 2.6873838901519775
Validation loss: 2.144843914175546

Epoch: 5| Step: 2
Training loss: 1.4692167043685913
Validation loss: 2.157860981520786

Epoch: 5| Step: 3
Training loss: 2.5696492195129395
Validation loss: 2.1701868054687337

Epoch: 5| Step: 4
Training loss: 2.718031644821167
Validation loss: 2.1944173741084274

Epoch: 5| Step: 5
Training loss: 2.163797378540039
Validation loss: 2.1985922885197464

Epoch: 5| Step: 6
Training loss: 1.9128462076187134
Validation loss: 2.173200494499617

Epoch: 5| Step: 7
Training loss: 1.8924728631973267
Validation loss: 2.1788229083502166

Epoch: 5| Step: 8
Training loss: 2.121964931488037
Validation loss: 2.2004963223652174

Epoch: 5| Step: 9
Training loss: 2.325253963470459
Validation loss: 2.1713393580529

Epoch: 5| Step: 10
Training loss: 2.977358341217041
Validation loss: 2.2074856681208455

Epoch: 74| Step: 0
Training loss: 2.6834378242492676
Validation loss: 2.1902401703660206

Epoch: 5| Step: 1
Training loss: 2.2409462928771973
Validation loss: 2.180233314473142

Epoch: 5| Step: 2
Training loss: 1.8292373418807983
Validation loss: 2.178803143962737

Epoch: 5| Step: 3
Training loss: 1.8312585353851318
Validation loss: 2.178678831746501

Epoch: 5| Step: 4
Training loss: 2.6190004348754883
Validation loss: 2.183641182479038

Epoch: 5| Step: 5
Training loss: 2.522894859313965
Validation loss: 2.185876633531304

Epoch: 5| Step: 6
Training loss: 2.484503984451294
Validation loss: 2.1862590107866513

Epoch: 5| Step: 7
Training loss: 2.3094065189361572
Validation loss: 2.1707880650797198

Epoch: 5| Step: 8
Training loss: 1.5217841863632202
Validation loss: 2.156943928810858

Epoch: 5| Step: 9
Training loss: 1.7966620922088623
Validation loss: 2.1170346044724986

Epoch: 5| Step: 10
Training loss: 2.6528656482696533
Validation loss: 2.1814376948982157

Epoch: 75| Step: 0
Training loss: 1.9156646728515625
Validation loss: 2.142780183463968

Epoch: 5| Step: 1
Training loss: 2.7818338871002197
Validation loss: 2.1868142979119414

Epoch: 5| Step: 2
Training loss: 2.5024120807647705
Validation loss: 2.2028305120365594

Epoch: 5| Step: 3
Training loss: 2.284214973449707
Validation loss: 2.1607472409484205

Epoch: 5| Step: 4
Training loss: 2.440486431121826
Validation loss: 2.149870102123548

Epoch: 5| Step: 5
Training loss: 2.171269178390503
Validation loss: 2.1589606602986655

Epoch: 5| Step: 6
Training loss: 1.8366447687149048
Validation loss: 2.1495126370460755

Epoch: 5| Step: 7
Training loss: 2.695284605026245
Validation loss: 2.1723076617845924

Epoch: 5| Step: 8
Training loss: 2.2332701683044434
Validation loss: 2.1707784257909304

Epoch: 5| Step: 9
Training loss: 1.4172338247299194
Validation loss: 2.1653115569904284

Epoch: 5| Step: 10
Training loss: 2.1577870845794678
Validation loss: 2.199029889158023

Epoch: 76| Step: 0
Training loss: 1.5664680004119873
Validation loss: 2.192988418763684

Epoch: 5| Step: 1
Training loss: 2.2713119983673096
Validation loss: 2.185229685998732

Epoch: 5| Step: 2
Training loss: 2.019047260284424
Validation loss: 2.195825502436648

Epoch: 5| Step: 3
Training loss: 1.8876268863677979
Validation loss: 2.189171030957212

Epoch: 5| Step: 4
Training loss: 1.8518911600112915
Validation loss: 2.1753128831104567

Epoch: 5| Step: 5
Training loss: 2.31245493888855
Validation loss: 2.174623120215631

Epoch: 5| Step: 6
Training loss: 2.246656894683838
Validation loss: 2.15160442936805

Epoch: 5| Step: 7
Training loss: 3.230398178100586
Validation loss: 2.1961476392643426

Epoch: 5| Step: 8
Training loss: 2.413270950317383
Validation loss: 2.2066848252409246

Epoch: 5| Step: 9
Training loss: 2.4199700355529785
Validation loss: 2.2170251646349506

Epoch: 5| Step: 10
Training loss: 2.5945277214050293
Validation loss: 2.1769334603381414

Epoch: 77| Step: 0
Training loss: 2.6757500171661377
Validation loss: 2.1706852675766073

Epoch: 5| Step: 1
Training loss: 2.2615318298339844
Validation loss: 2.184727043233892

Epoch: 5| Step: 2
Training loss: 1.9503101110458374
Validation loss: 2.1828504185522757

Epoch: 5| Step: 3
Training loss: 1.958164930343628
Validation loss: 2.2324268894810833

Epoch: 5| Step: 4
Training loss: 2.0784554481506348
Validation loss: 2.2009546372198288

Epoch: 5| Step: 5
Training loss: 2.0549635887145996
Validation loss: 2.1559910312775643

Epoch: 5| Step: 6
Training loss: 2.6222994327545166
Validation loss: 2.189467132732432

Epoch: 5| Step: 7
Training loss: 2.8008038997650146
Validation loss: 2.2033619983221895

Epoch: 5| Step: 8
Training loss: 2.39904522895813
Validation loss: 2.2121384374557005

Epoch: 5| Step: 9
Training loss: 1.7134212255477905
Validation loss: 2.2095210911125265

Epoch: 5| Step: 10
Training loss: 2.0000479221343994
Validation loss: 2.191601070024634

Epoch: 78| Step: 0
Training loss: 1.9772663116455078
Validation loss: 2.156573636557466

Epoch: 5| Step: 1
Training loss: 1.963409423828125
Validation loss: 2.162610153998098

Epoch: 5| Step: 2
Training loss: 2.3165736198425293
Validation loss: 2.1828725696891866

Epoch: 5| Step: 3
Training loss: 2.587838649749756
Validation loss: 2.1656029916578725

Epoch: 5| Step: 4
Training loss: 1.7234058380126953
Validation loss: 2.171676935688142

Epoch: 5| Step: 5
Training loss: 2.521648645401001
Validation loss: 2.1796165832909207

Epoch: 5| Step: 6
Training loss: 1.838655710220337
Validation loss: 2.1604085455658617

Epoch: 5| Step: 7
Training loss: 2.3597404956817627
Validation loss: 2.1839487219369538

Epoch: 5| Step: 8
Training loss: 2.7241313457489014
Validation loss: 2.1655894351261917

Epoch: 5| Step: 9
Training loss: 2.3306753635406494
Validation loss: 2.160633925468691

Epoch: 5| Step: 10
Training loss: 2.2408807277679443
Validation loss: 2.177736823276807

Epoch: 79| Step: 0
Training loss: 2.1349425315856934
Validation loss: 2.1514428328442317

Epoch: 5| Step: 1
Training loss: 2.1204440593719482
Validation loss: 2.2004011113156556

Epoch: 5| Step: 2
Training loss: 2.1771137714385986
Validation loss: 2.1752123781429824

Epoch: 5| Step: 3
Training loss: 2.0599637031555176
Validation loss: 2.17692429788651

Epoch: 5| Step: 4
Training loss: 2.281647205352783
Validation loss: 2.194015077365342

Epoch: 5| Step: 5
Training loss: 1.8575077056884766
Validation loss: 2.2069774007284515

Epoch: 5| Step: 6
Training loss: 2.2290797233581543
Validation loss: 2.132309498325471

Epoch: 5| Step: 7
Training loss: 2.384066104888916
Validation loss: 2.17747022515984

Epoch: 5| Step: 8
Training loss: 2.635819911956787
Validation loss: 2.1448315061548704

Epoch: 5| Step: 9
Training loss: 1.8751976490020752
Validation loss: 2.1180229904831096

Epoch: 5| Step: 10
Training loss: 2.6997923851013184
Validation loss: 2.1835473122135287

Epoch: 80| Step: 0
Training loss: 2.350882053375244
Validation loss: 2.194321245275518

Epoch: 5| Step: 1
Training loss: 1.7542768716812134
Validation loss: 2.1300126019344536

Epoch: 5| Step: 2
Training loss: 2.3985512256622314
Validation loss: 2.168290215153848

Epoch: 5| Step: 3
Training loss: 2.1539430618286133
Validation loss: 2.154763526813958

Epoch: 5| Step: 4
Training loss: 2.450920820236206
Validation loss: 2.1099712720481296

Epoch: 5| Step: 5
Training loss: 1.9990113973617554
Validation loss: 2.1533019529875888

Epoch: 5| Step: 6
Training loss: 1.941706895828247
Validation loss: 2.154929892991179

Epoch: 5| Step: 7
Training loss: 2.1740520000457764
Validation loss: 2.1325488013605916

Epoch: 5| Step: 8
Training loss: 2.1203887462615967
Validation loss: 2.1603332129857873

Epoch: 5| Step: 9
Training loss: 2.2777087688446045
Validation loss: 2.1304494411714616

Epoch: 5| Step: 10
Training loss: 2.7911593914031982
Validation loss: 2.1654969569175475

Epoch: 81| Step: 0
Training loss: 2.149296998977661
Validation loss: 2.1671685057301677

Epoch: 5| Step: 1
Training loss: 2.1026291847229004
Validation loss: 2.130498105479825

Epoch: 5| Step: 2
Training loss: 1.871605634689331
Validation loss: 2.1202842471420125

Epoch: 5| Step: 3
Training loss: 2.1603763103485107
Validation loss: 2.1478680115874096

Epoch: 5| Step: 4
Training loss: 2.4496045112609863
Validation loss: 2.167034359388454

Epoch: 5| Step: 5
Training loss: 2.7658543586730957
Validation loss: 2.1848209647722143

Epoch: 5| Step: 6
Training loss: 1.7872419357299805
Validation loss: 2.1616489579600673

Epoch: 5| Step: 7
Training loss: 2.3032751083374023
Validation loss: 2.163930041815645

Epoch: 5| Step: 8
Training loss: 1.9774366617202759
Validation loss: 2.1859005907530427

Epoch: 5| Step: 9
Training loss: 2.447772264480591
Validation loss: 2.163189576518151

Epoch: 5| Step: 10
Training loss: 2.108002185821533
Validation loss: 2.1554938080490276

Epoch: 82| Step: 0
Training loss: 1.467540979385376
Validation loss: 2.1430027548984816

Epoch: 5| Step: 1
Training loss: 2.5819246768951416
Validation loss: 2.168369944377612

Epoch: 5| Step: 2
Training loss: 1.8331502676010132
Validation loss: 2.173275475860924

Epoch: 5| Step: 3
Training loss: 2.3175601959228516
Validation loss: 2.154147167359629

Epoch: 5| Step: 4
Training loss: 2.3755626678466797
Validation loss: 2.1616095214761715

Epoch: 5| Step: 5
Training loss: 3.1218910217285156
Validation loss: 2.1737655862685172

Epoch: 5| Step: 6
Training loss: 2.1741268634796143
Validation loss: 2.117067893346151

Epoch: 5| Step: 7
Training loss: 2.224083662033081
Validation loss: 2.169374358269476

Epoch: 5| Step: 8
Training loss: 1.9617668390274048
Validation loss: 2.165822095768426

Epoch: 5| Step: 9
Training loss: 2.1743040084838867
Validation loss: 2.1595608982988583

Epoch: 5| Step: 10
Training loss: 1.9710803031921387
Validation loss: 2.202152065051499

Epoch: 83| Step: 0
Training loss: 1.9703340530395508
Validation loss: 2.1753491252981205

Epoch: 5| Step: 1
Training loss: 2.387061357498169
Validation loss: 2.161386412958945

Epoch: 5| Step: 2
Training loss: 2.179978132247925
Validation loss: 2.1136934065049693

Epoch: 5| Step: 3
Training loss: 2.286292314529419
Validation loss: 2.198060019041902

Epoch: 5| Step: 4
Training loss: 2.2801690101623535
Validation loss: 2.2018628197331584

Epoch: 5| Step: 5
Training loss: 1.4292867183685303
Validation loss: 2.177630675736294

Epoch: 5| Step: 6
Training loss: 2.198544502258301
Validation loss: 2.1923274993896484

Epoch: 5| Step: 7
Training loss: 2.090136766433716
Validation loss: 2.1691670494694866

Epoch: 5| Step: 8
Training loss: 2.062904119491577
Validation loss: 2.1630052546019196

Epoch: 5| Step: 9
Training loss: 3.022216320037842
Validation loss: 2.164106786891978

Epoch: 5| Step: 10
Training loss: 2.27239727973938
Validation loss: 2.165221018175925

Epoch: 84| Step: 0
Training loss: 1.853773832321167
Validation loss: 2.1200842844542636

Epoch: 5| Step: 1
Training loss: 2.250182628631592
Validation loss: 2.1281560813227007

Epoch: 5| Step: 2
Training loss: 2.4250285625457764
Validation loss: 2.1501885626905706

Epoch: 5| Step: 3
Training loss: 2.1839940547943115
Validation loss: 2.145510228731299

Epoch: 5| Step: 4
Training loss: 1.732619285583496
Validation loss: 2.1624081673160678

Epoch: 5| Step: 5
Training loss: 2.3608062267303467
Validation loss: 2.1206728630168463

Epoch: 5| Step: 6
Training loss: 1.9942182302474976
Validation loss: 2.092095036660471

Epoch: 5| Step: 7
Training loss: 2.4346203804016113
Validation loss: 2.1521296680614515

Epoch: 5| Step: 8
Training loss: 2.311293363571167
Validation loss: 2.116323468505695

Epoch: 5| Step: 9
Training loss: 1.76800537109375
Validation loss: 2.131747740571217

Epoch: 5| Step: 10
Training loss: 3.153292417526245
Validation loss: 2.1452529686753468

Epoch: 85| Step: 0
Training loss: 1.7964956760406494
Validation loss: 2.1889366565212125

Epoch: 5| Step: 1
Training loss: 2.6986546516418457
Validation loss: 2.1553731438934163

Epoch: 5| Step: 2
Training loss: 1.7677295207977295
Validation loss: 2.1561020023079327

Epoch: 5| Step: 3
Training loss: 2.283393621444702
Validation loss: 2.138165913602357

Epoch: 5| Step: 4
Training loss: 2.1446337699890137
Validation loss: 2.115210385732753

Epoch: 5| Step: 5
Training loss: 2.1305088996887207
Validation loss: 2.1491097224655973

Epoch: 5| Step: 6
Training loss: 2.578542947769165
Validation loss: 2.1508381366729736

Epoch: 5| Step: 7
Training loss: 2.2120747566223145
Validation loss: 2.1474709151893534

Epoch: 5| Step: 8
Training loss: 2.0561506748199463
Validation loss: 2.105085022987858

Epoch: 5| Step: 9
Training loss: 2.0419766902923584
Validation loss: 2.1504228038172566

Epoch: 5| Step: 10
Training loss: 2.7134602069854736
Validation loss: 2.146898017134718

Epoch: 86| Step: 0
Training loss: 2.378037929534912
Validation loss: 2.1288001691141436

Epoch: 5| Step: 1
Training loss: 2.3562862873077393
Validation loss: 2.1237036515307683

Epoch: 5| Step: 2
Training loss: 2.260913848876953
Validation loss: 2.157397216366183

Epoch: 5| Step: 3
Training loss: 3.0573534965515137
Validation loss: 2.1541616634656022

Epoch: 5| Step: 4
Training loss: 1.6945079565048218
Validation loss: 2.1435119695560907

Epoch: 5| Step: 5
Training loss: 1.4214046001434326
Validation loss: 2.125431106936547

Epoch: 5| Step: 6
Training loss: 2.0252647399902344
Validation loss: 2.1626707353899555

Epoch: 5| Step: 7
Training loss: 2.0374197959899902
Validation loss: 2.1844726454827095

Epoch: 5| Step: 8
Training loss: 2.0645804405212402
Validation loss: 2.1370281198973298

Epoch: 5| Step: 9
Training loss: 2.7810652256011963
Validation loss: 2.173219370585616

Epoch: 5| Step: 10
Training loss: 2.020843744277954
Validation loss: 2.1195013061646493

Epoch: 87| Step: 0
Training loss: 2.190387725830078
Validation loss: 2.177078047106343

Epoch: 5| Step: 1
Training loss: 2.5809972286224365
Validation loss: 2.163331259963333

Epoch: 5| Step: 2
Training loss: 1.551471471786499
Validation loss: 2.163570806544314

Epoch: 5| Step: 3
Training loss: 1.985955834388733
Validation loss: 2.1704290605360463

Epoch: 5| Step: 4
Training loss: 1.9533863067626953
Validation loss: 2.1575729872590754

Epoch: 5| Step: 5
Training loss: 2.7516238689422607
Validation loss: 2.1714845344584477

Epoch: 5| Step: 6
Training loss: 2.8901195526123047
Validation loss: 2.1139624669987667

Epoch: 5| Step: 7
Training loss: 2.385857105255127
Validation loss: 2.143684280815945

Epoch: 5| Step: 8
Training loss: 1.8065201044082642
Validation loss: 2.163132054831392

Epoch: 5| Step: 9
Training loss: 2.087266206741333
Validation loss: 2.193177410351333

Epoch: 5| Step: 10
Training loss: 2.1062867641448975
Validation loss: 2.1877076215641473

Epoch: 88| Step: 0
Training loss: 2.4892354011535645
Validation loss: 2.160409738940577

Epoch: 5| Step: 1
Training loss: 2.7064125537872314
Validation loss: 2.1500645709294144

Epoch: 5| Step: 2
Training loss: 1.6897739171981812
Validation loss: 2.166082056619788

Epoch: 5| Step: 3
Training loss: 2.0799033641815186
Validation loss: 2.171584816389186

Epoch: 5| Step: 4
Training loss: 1.706701636314392
Validation loss: 2.15621345145728

Epoch: 5| Step: 5
Training loss: 2.225930690765381
Validation loss: 2.1442481702373875

Epoch: 5| Step: 6
Training loss: 2.2040538787841797
Validation loss: 2.1676927305036977

Epoch: 5| Step: 7
Training loss: 1.9895111322402954
Validation loss: 2.170619185252856

Epoch: 5| Step: 8
Training loss: 1.7892366647720337
Validation loss: 2.1533560483686385

Epoch: 5| Step: 9
Training loss: 2.4145681858062744
Validation loss: 2.1731963183290217

Epoch: 5| Step: 10
Training loss: 2.888383626937866
Validation loss: 2.128510623849848

Epoch: 89| Step: 0
Training loss: 2.0463297367095947
Validation loss: 2.143323411223709

Epoch: 5| Step: 1
Training loss: 1.7022836208343506
Validation loss: 2.150831219970539

Epoch: 5| Step: 2
Training loss: 2.8831450939178467
Validation loss: 2.1502791130414574

Epoch: 5| Step: 3
Training loss: 2.61991810798645
Validation loss: 2.1410883088265695

Epoch: 5| Step: 4
Training loss: 1.8112081289291382
Validation loss: 2.1759436335614932

Epoch: 5| Step: 5
Training loss: 1.791386604309082
Validation loss: 2.1749704396852882

Epoch: 5| Step: 6
Training loss: 1.979270339012146
Validation loss: 2.1642433699741157

Epoch: 5| Step: 7
Training loss: 2.3851318359375
Validation loss: 2.1377200465048514

Epoch: 5| Step: 8
Training loss: 3.161827325820923
Validation loss: 2.168188779584823

Epoch: 5| Step: 9
Training loss: 1.945474624633789
Validation loss: 2.1493840768773067

Epoch: 5| Step: 10
Training loss: 1.4670782089233398
Validation loss: 2.1456118488824494

Epoch: 90| Step: 0
Training loss: 1.879094123840332
Validation loss: 2.1688217398940877

Epoch: 5| Step: 1
Training loss: 1.7220208644866943
Validation loss: 2.096414375048812

Epoch: 5| Step: 2
Training loss: 1.9139792919158936
Validation loss: 2.132268818475867

Epoch: 5| Step: 3
Training loss: 2.1128196716308594
Validation loss: 2.153083365450623

Epoch: 5| Step: 4
Training loss: 2.090256452560425
Validation loss: 2.1318381935037594

Epoch: 5| Step: 5
Training loss: 1.7299400568008423
Validation loss: 2.143331250836772

Epoch: 5| Step: 6
Training loss: 2.9812819957733154
Validation loss: 2.1196156189005864

Epoch: 5| Step: 7
Training loss: 2.535407066345215
Validation loss: 2.1352463037736955

Epoch: 5| Step: 8
Training loss: 2.256859540939331
Validation loss: 2.147479864858812

Epoch: 5| Step: 9
Training loss: 2.3448376655578613
Validation loss: 2.120357459591281

Epoch: 5| Step: 10
Training loss: 2.1824848651885986
Validation loss: 2.1591628264355403

Epoch: 91| Step: 0
Training loss: 2.5154032707214355
Validation loss: 2.148129875941943

Epoch: 5| Step: 1
Training loss: 2.233379364013672
Validation loss: 2.164714974741782

Epoch: 5| Step: 2
Training loss: 1.7566678524017334
Validation loss: 2.1121573935272875

Epoch: 5| Step: 3
Training loss: 2.520979881286621
Validation loss: 2.1786986704795592

Epoch: 5| Step: 4
Training loss: 1.8849732875823975
Validation loss: 2.1490717511023245

Epoch: 5| Step: 5
Training loss: 2.133673906326294
Validation loss: 2.1355379909597416

Epoch: 5| Step: 6
Training loss: 2.185713291168213
Validation loss: 2.1419899694381224

Epoch: 5| Step: 7
Training loss: 1.5967479944229126
Validation loss: 2.1854441294106106

Epoch: 5| Step: 8
Training loss: 2.732590675354004
Validation loss: 2.1287077998602264

Epoch: 5| Step: 9
Training loss: 2.255645275115967
Validation loss: 2.181395851155763

Epoch: 5| Step: 10
Training loss: 2.3553218841552734
Validation loss: 2.1535082735041136

Epoch: 92| Step: 0
Training loss: 2.613970994949341
Validation loss: 2.1701935542527067

Epoch: 5| Step: 1
Training loss: 1.9443213939666748
Validation loss: 2.150449977126173

Epoch: 5| Step: 2
Training loss: 2.673851490020752
Validation loss: 2.14998266261111

Epoch: 5| Step: 3
Training loss: 2.27724027633667
Validation loss: 2.2007390555515083

Epoch: 5| Step: 4
Training loss: 2.574496030807495
Validation loss: 2.1254191962621545

Epoch: 5| Step: 5
Training loss: 1.6787803173065186
Validation loss: 2.1220442697566044

Epoch: 5| Step: 6
Training loss: 1.9933182001113892
Validation loss: 2.156539373500373

Epoch: 5| Step: 7
Training loss: 2.271143674850464
Validation loss: 2.161884915444159

Epoch: 5| Step: 8
Training loss: 2.4103240966796875
Validation loss: 2.1730829490128385

Epoch: 5| Step: 9
Training loss: 1.6032416820526123
Validation loss: 2.165102697187854

Epoch: 5| Step: 10
Training loss: 1.7053160667419434
Validation loss: 2.1523688147144933

Epoch: 93| Step: 0
Training loss: 2.186418294906616
Validation loss: 2.146141449610392

Epoch: 5| Step: 1
Training loss: 2.467067241668701
Validation loss: 2.133377936578566

Epoch: 5| Step: 2
Training loss: 2.662022590637207
Validation loss: 2.1659887606097805

Epoch: 5| Step: 3
Training loss: 1.8616917133331299
Validation loss: 2.1298299861210648

Epoch: 5| Step: 4
Training loss: 2.5398058891296387
Validation loss: 2.1523144898876065

Epoch: 5| Step: 5
Training loss: 1.422838568687439
Validation loss: 2.192796951981001

Epoch: 5| Step: 6
Training loss: 2.3438096046447754
Validation loss: 2.1703958254988476

Epoch: 5| Step: 7
Training loss: 1.8237149715423584
Validation loss: 2.1270642101123767

Epoch: 5| Step: 8
Training loss: 2.162407398223877
Validation loss: 2.131497403626801

Epoch: 5| Step: 9
Training loss: 1.9375789165496826
Validation loss: 2.1177759247441448

Epoch: 5| Step: 10
Training loss: 2.667551040649414
Validation loss: 2.11529460260945

Epoch: 94| Step: 0
Training loss: 1.9132314920425415
Validation loss: 2.118753197372601

Epoch: 5| Step: 1
Training loss: 1.9703483581542969
Validation loss: 2.1285070411620604

Epoch: 5| Step: 2
Training loss: 1.9352428913116455
Validation loss: 2.141256381106633

Epoch: 5| Step: 3
Training loss: 2.4102396965026855
Validation loss: 2.1415181518882833

Epoch: 5| Step: 4
Training loss: 2.153611421585083
Validation loss: 2.1412836505520727

Epoch: 5| Step: 5
Training loss: 2.097686767578125
Validation loss: 2.1403488959035566

Epoch: 5| Step: 6
Training loss: 2.5192911624908447
Validation loss: 2.1264084949288318

Epoch: 5| Step: 7
Training loss: 2.0223405361175537
Validation loss: 2.1241396934755388

Epoch: 5| Step: 8
Training loss: 2.249136447906494
Validation loss: 2.1291255540745233

Epoch: 5| Step: 9
Training loss: 2.239596366882324
Validation loss: 2.1517990148195656

Epoch: 5| Step: 10
Training loss: 2.284254312515259
Validation loss: 2.138265632813977

Epoch: 95| Step: 0
Training loss: 2.8756070137023926
Validation loss: 2.133118485891691

Epoch: 5| Step: 1
Training loss: 2.2666146755218506
Validation loss: 2.125912353556643

Epoch: 5| Step: 2
Training loss: 1.7570909261703491
Validation loss: 2.1318411160540838

Epoch: 5| Step: 3
Training loss: 2.8635401725769043
Validation loss: 2.1717698189520065

Epoch: 5| Step: 4
Training loss: 1.7331892251968384
Validation loss: 2.0955454047008226

Epoch: 5| Step: 5
Training loss: 2.236607789993286
Validation loss: 2.120667075598112

Epoch: 5| Step: 6
Training loss: 1.8093643188476562
Validation loss: 2.1195760593619397

Epoch: 5| Step: 7
Training loss: 2.0579822063446045
Validation loss: 2.1234249607209237

Epoch: 5| Step: 8
Training loss: 2.156022071838379
Validation loss: 2.1441685358683267

Epoch: 5| Step: 9
Training loss: 2.3218767642974854
Validation loss: 2.146903286698044

Epoch: 5| Step: 10
Training loss: 1.803417682647705
Validation loss: 2.120687230940788

Epoch: 96| Step: 0
Training loss: 2.483560085296631
Validation loss: 2.135014618596723

Epoch: 5| Step: 1
Training loss: 2.5518946647644043
Validation loss: 2.1483566145743094

Epoch: 5| Step: 2
Training loss: 1.6624294519424438
Validation loss: 2.153077346022411

Epoch: 5| Step: 3
Training loss: 2.0570425987243652
Validation loss: 2.1548800827354513

Epoch: 5| Step: 4
Training loss: 2.336792230606079
Validation loss: 2.1451969979911722

Epoch: 5| Step: 5
Training loss: 2.3965020179748535
Validation loss: 2.13510319494432

Epoch: 5| Step: 6
Training loss: 1.9466882944107056
Validation loss: 2.1292817464438816

Epoch: 5| Step: 7
Training loss: 2.462664842605591
Validation loss: 2.1240122292631414

Epoch: 5| Step: 8
Training loss: 2.320935010910034
Validation loss: 2.111694032146085

Epoch: 5| Step: 9
Training loss: 1.8099949359893799
Validation loss: 2.1433371343920307

Epoch: 5| Step: 10
Training loss: 1.7711942195892334
Validation loss: 2.1158343720179733

Epoch: 97| Step: 0
Training loss: 2.845574140548706
Validation loss: 2.1407443195260982

Epoch: 5| Step: 1
Training loss: 2.3028740882873535
Validation loss: 2.133449141697217

Epoch: 5| Step: 2
Training loss: 2.417123317718506
Validation loss: 2.133598917274065

Epoch: 5| Step: 3
Training loss: 2.3623557090759277
Validation loss: 2.137811571039179

Epoch: 5| Step: 4
Training loss: 1.8142898082733154
Validation loss: 2.165265594759295

Epoch: 5| Step: 5
Training loss: 1.6222642660140991
Validation loss: 2.1422354303380495

Epoch: 5| Step: 6
Training loss: 2.429413318634033
Validation loss: 2.100010056649485

Epoch: 5| Step: 7
Training loss: 1.6818866729736328
Validation loss: 2.1472271821832143

Epoch: 5| Step: 8
Training loss: 2.2160892486572266
Validation loss: 2.1371670153833207

Epoch: 5| Step: 9
Training loss: 1.8348979949951172
Validation loss: 2.129052549280146

Epoch: 5| Step: 10
Training loss: 2.4543309211730957
Validation loss: 2.1510031325842744

Epoch: 98| Step: 0
Training loss: 2.838526725769043
Validation loss: 2.1550882554823354

Epoch: 5| Step: 1
Training loss: 1.8265628814697266
Validation loss: 2.1040943284188547

Epoch: 5| Step: 2
Training loss: 2.1985654830932617
Validation loss: 2.1333462666439753

Epoch: 5| Step: 3
Training loss: 1.7895053625106812
Validation loss: 2.120034579307802

Epoch: 5| Step: 4
Training loss: 2.36169695854187
Validation loss: 2.1253381108724945

Epoch: 5| Step: 5
Training loss: 2.231691837310791
Validation loss: 2.169226574641402

Epoch: 5| Step: 6
Training loss: 2.096468448638916
Validation loss: 2.175810824158371

Epoch: 5| Step: 7
Training loss: 2.407196283340454
Validation loss: 2.1299003580565095

Epoch: 5| Step: 8
Training loss: 2.4422519207000732
Validation loss: 2.122726043065389

Epoch: 5| Step: 9
Training loss: 1.5957915782928467
Validation loss: 2.171710919308406

Epoch: 5| Step: 10
Training loss: 1.9467132091522217
Validation loss: 2.12768078619434

Epoch: 99| Step: 0
Training loss: 1.6614364385604858
Validation loss: 2.1457593851192023

Epoch: 5| Step: 1
Training loss: 1.6072553396224976
Validation loss: 2.134942167548723

Epoch: 5| Step: 2
Training loss: 2.4058101177215576
Validation loss: 2.1041708172008557

Epoch: 5| Step: 3
Training loss: 2.7493698596954346
Validation loss: 2.15207867212193

Epoch: 5| Step: 4
Training loss: 1.602954626083374
Validation loss: 2.140067920889906

Epoch: 5| Step: 5
Training loss: 2.3669707775115967
Validation loss: 2.0593138715272308

Epoch: 5| Step: 6
Training loss: 2.065800428390503
Validation loss: 2.1217661391022387

Epoch: 5| Step: 7
Training loss: 1.8989349603652954
Validation loss: 2.1027665535608926

Epoch: 5| Step: 8
Training loss: 2.8490970134735107
Validation loss: 2.1265991234010264

Epoch: 5| Step: 9
Training loss: 2.4695236682891846
Validation loss: 2.1271970092609362

Epoch: 5| Step: 10
Training loss: 2.178377866744995
Validation loss: 2.140030360990955

Epoch: 100| Step: 0
Training loss: 1.8933242559432983
Validation loss: 2.140535253350453

Epoch: 5| Step: 1
Training loss: 2.2482314109802246
Validation loss: 2.1127803889654015

Epoch: 5| Step: 2
Training loss: 2.432425022125244
Validation loss: 2.1437223239611556

Epoch: 5| Step: 3
Training loss: 1.8003389835357666
Validation loss: 2.1052585442860923

Epoch: 5| Step: 4
Training loss: 2.2327218055725098
Validation loss: 2.1027143181011243

Epoch: 5| Step: 5
Training loss: 2.098315477371216
Validation loss: 2.107201824906052

Epoch: 5| Step: 6
Training loss: 2.16886568069458
Validation loss: 2.1225893369285007

Epoch: 5| Step: 7
Training loss: 2.475534200668335
Validation loss: 2.1205237783411497

Epoch: 5| Step: 8
Training loss: 2.622281074523926
Validation loss: 2.081223410944785

Epoch: 5| Step: 9
Training loss: 1.980749487876892
Validation loss: 2.123588249247561

Epoch: 5| Step: 10
Training loss: 1.9807487726211548
Validation loss: 2.0967871681336434

Testing loss: 2.0504964457617865
