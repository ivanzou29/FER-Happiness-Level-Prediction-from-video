Epoch: 1| Step: 0
Training loss: 4.8469367027282715
Validation loss: 5.167049331049765

Epoch: 5| Step: 1
Training loss: 5.71326208114624
Validation loss: 5.163435659100933

Epoch: 5| Step: 2
Training loss: 4.342904090881348
Validation loss: 5.160031159718831

Epoch: 5| Step: 3
Training loss: 4.705301284790039
Validation loss: 5.1552896807270665

Epoch: 5| Step: 4
Training loss: 5.198849678039551
Validation loss: 5.151228345850463

Epoch: 5| Step: 5
Training loss: 5.7816362380981445
Validation loss: 5.1458057588146575

Epoch: 5| Step: 6
Training loss: 5.613284111022949
Validation loss: 5.142506055934454

Epoch: 5| Step: 7
Training loss: 3.9484429359436035
Validation loss: 5.138045700647497

Epoch: 5| Step: 8
Training loss: 4.833010673522949
Validation loss: 5.134340327273133

Epoch: 5| Step: 9
Training loss: 4.760365962982178
Validation loss: 5.129858601477839

Epoch: 5| Step: 10
Training loss: 4.583611488342285
Validation loss: 5.125857137864636

Epoch: 2| Step: 0
Training loss: 5.456714630126953
Validation loss: 5.1211136233422065

Epoch: 5| Step: 1
Training loss: 3.532731533050537
Validation loss: 5.11679938531691

Epoch: 5| Step: 2
Training loss: 4.718705654144287
Validation loss: 5.112930579852033

Epoch: 5| Step: 3
Training loss: 4.693709850311279
Validation loss: 5.110062163363221

Epoch: 5| Step: 4
Training loss: 4.911682605743408
Validation loss: 5.104762790023639

Epoch: 5| Step: 5
Training loss: 4.9521684646606445
Validation loss: 5.100959634268156

Epoch: 5| Step: 6
Training loss: 5.564302921295166
Validation loss: 5.0970040393132034

Epoch: 5| Step: 7
Training loss: 6.087831974029541
Validation loss: 5.092490034718668

Epoch: 5| Step: 8
Training loss: 4.283974647521973
Validation loss: 5.089244422092233

Epoch: 5| Step: 9
Training loss: 5.681177616119385
Validation loss: 5.084231658648419

Epoch: 5| Step: 10
Training loss: 3.8227651119232178
Validation loss: 5.080032517833095

Epoch: 3| Step: 0
Training loss: 4.714956760406494
Validation loss: 5.074730273216002

Epoch: 5| Step: 1
Training loss: 4.4088239669799805
Validation loss: 5.07146087256811

Epoch: 5| Step: 2
Training loss: 5.764621734619141
Validation loss: 5.067323700074227

Epoch: 5| Step: 3
Training loss: 4.273961067199707
Validation loss: 5.061902230785739

Epoch: 5| Step: 4
Training loss: 4.896048545837402
Validation loss: 5.057177687204012

Epoch: 5| Step: 5
Training loss: 5.9070048332214355
Validation loss: 5.052758360421786

Epoch: 5| Step: 6
Training loss: 5.883946418762207
Validation loss: 5.048236513650545

Epoch: 5| Step: 7
Training loss: 4.0288615226745605
Validation loss: 5.045148957160212

Epoch: 5| Step: 8
Training loss: 4.831031799316406
Validation loss: 5.0390590339578605

Epoch: 5| Step: 9
Training loss: 4.639939308166504
Validation loss: 5.0344642875015095

Epoch: 5| Step: 10
Training loss: 3.8299291133880615
Validation loss: 5.029597523391888

Epoch: 4| Step: 0
Training loss: 5.261425971984863
Validation loss: 5.024870236714681

Epoch: 5| Step: 1
Training loss: 4.838871955871582
Validation loss: 5.01901295364544

Epoch: 5| Step: 2
Training loss: 4.91938591003418
Validation loss: 5.015319193563154

Epoch: 5| Step: 3
Training loss: 5.158761024475098
Validation loss: 5.00949630942396

Epoch: 5| Step: 4
Training loss: 3.857037305831909
Validation loss: 5.004770642967634

Epoch: 5| Step: 5
Training loss: 5.272884845733643
Validation loss: 5.0000113210370465

Epoch: 5| Step: 6
Training loss: 4.222970485687256
Validation loss: 4.994413796291556

Epoch: 5| Step: 7
Training loss: 4.002153396606445
Validation loss: 4.990829693373813

Epoch: 5| Step: 8
Training loss: 4.3711652755737305
Validation loss: 4.983587726469962

Epoch: 5| Step: 9
Training loss: 5.047739505767822
Validation loss: 4.980894411763837

Epoch: 5| Step: 10
Training loss: 5.9519362449646
Validation loss: 4.975352241146949

Epoch: 5| Step: 0
Training loss: 4.950606346130371
Validation loss: 4.968638271413823

Epoch: 5| Step: 1
Training loss: 5.502842903137207
Validation loss: 4.964645308832968

Epoch: 5| Step: 2
Training loss: 5.396119117736816
Validation loss: 4.9598582175470165

Epoch: 5| Step: 3
Training loss: 4.919812202453613
Validation loss: 4.953124761581421

Epoch: 5| Step: 4
Training loss: 3.5258407592773438
Validation loss: 4.948816355838571

Epoch: 5| Step: 5
Training loss: 5.496359348297119
Validation loss: 4.94243594138853

Epoch: 5| Step: 6
Training loss: 3.9792370796203613
Validation loss: 4.937587117636076

Epoch: 5| Step: 7
Training loss: 4.6020073890686035
Validation loss: 4.933318717505342

Epoch: 5| Step: 8
Training loss: 5.518667221069336
Validation loss: 4.927015535293087

Epoch: 5| Step: 9
Training loss: 4.1292619705200195
Validation loss: 4.9212282780678045

Epoch: 5| Step: 10
Training loss: 3.9441895484924316
Validation loss: 4.913698216920258

Epoch: 6| Step: 0
Training loss: 3.905552625656128
Validation loss: 4.90916637707782

Epoch: 5| Step: 1
Training loss: 5.8491010665893555
Validation loss: 4.902874367211455

Epoch: 5| Step: 2
Training loss: 5.386467933654785
Validation loss: 4.899321330490933

Epoch: 5| Step: 3
Training loss: 3.41349720954895
Validation loss: 4.890765841289233

Epoch: 5| Step: 4
Training loss: 5.252972602844238
Validation loss: 4.885455675022577

Epoch: 5| Step: 5
Training loss: 4.156528949737549
Validation loss: 4.878599587307181

Epoch: 5| Step: 6
Training loss: 3.9294610023498535
Validation loss: 4.872181989813364

Epoch: 5| Step: 7
Training loss: 4.7798027992248535
Validation loss: 4.866422335306804

Epoch: 5| Step: 8
Training loss: 4.442063331604004
Validation loss: 4.860453215978479

Epoch: 5| Step: 9
Training loss: 4.724917411804199
Validation loss: 4.854381192115046

Epoch: 5| Step: 10
Training loss: 5.678553104400635
Validation loss: 4.848346253877045

Epoch: 7| Step: 0
Training loss: 4.316819190979004
Validation loss: 4.840422004781743

Epoch: 5| Step: 1
Training loss: 4.111530780792236
Validation loss: 4.83309450457173

Epoch: 5| Step: 2
Training loss: 4.517086505889893
Validation loss: 4.8285552096623245

Epoch: 5| Step: 3
Training loss: 4.035185813903809
Validation loss: 4.820925287021104

Epoch: 5| Step: 4
Training loss: 3.9250435829162598
Validation loss: 4.812728404998779

Epoch: 5| Step: 5
Training loss: 5.243752956390381
Validation loss: 4.805498153932633

Epoch: 5| Step: 6
Training loss: 4.802455902099609
Validation loss: 4.796972500380649

Epoch: 5| Step: 7
Training loss: 4.979575157165527
Validation loss: 4.792830385187621

Epoch: 5| Step: 8
Training loss: 5.690647602081299
Validation loss: 4.786559422810872

Epoch: 5| Step: 9
Training loss: 4.023234844207764
Validation loss: 4.7784683166011686

Epoch: 5| Step: 10
Training loss: 4.923962116241455
Validation loss: 4.7704367483815835

Epoch: 8| Step: 0
Training loss: 4.184253692626953
Validation loss: 4.762431108823386

Epoch: 5| Step: 1
Training loss: 4.039431095123291
Validation loss: 4.7540713176932385

Epoch: 5| Step: 2
Training loss: 3.900848388671875
Validation loss: 4.747931557316934

Epoch: 5| Step: 3
Training loss: 5.64461088180542
Validation loss: 4.740928619138656

Epoch: 5| Step: 4
Training loss: 3.7613823413848877
Validation loss: 4.731876880891861

Epoch: 5| Step: 5
Training loss: 4.016253471374512
Validation loss: 4.724614261299052

Epoch: 5| Step: 6
Training loss: 5.214862823486328
Validation loss: 4.716099503219769

Epoch: 5| Step: 7
Training loss: 4.755858421325684
Validation loss: 4.708811944530856

Epoch: 5| Step: 8
Training loss: 4.715062141418457
Validation loss: 4.7009110758381505

Epoch: 5| Step: 9
Training loss: 5.182250022888184
Validation loss: 4.693278497265231

Epoch: 5| Step: 10
Training loss: 4.1549248695373535
Validation loss: 4.685700924165787

Epoch: 9| Step: 0
Training loss: 4.049960136413574
Validation loss: 4.678160257236932

Epoch: 5| Step: 1
Training loss: 4.475203514099121
Validation loss: 4.667944226213681

Epoch: 5| Step: 2
Training loss: 3.8304314613342285
Validation loss: 4.66002365337905

Epoch: 5| Step: 3
Training loss: 4.500538349151611
Validation loss: 4.65320683551091

Epoch: 5| Step: 4
Training loss: 4.174220561981201
Validation loss: 4.641441522106048

Epoch: 5| Step: 5
Training loss: 4.702242851257324
Validation loss: 4.635688058791622

Epoch: 5| Step: 6
Training loss: 5.859346866607666
Validation loss: 4.625402245470273

Epoch: 5| Step: 7
Training loss: 3.530088424682617
Validation loss: 4.617100961746708

Epoch: 5| Step: 8
Training loss: 3.4212708473205566
Validation loss: 4.6091424419033915

Epoch: 5| Step: 9
Training loss: 4.731756687164307
Validation loss: 4.599424469855524

Epoch: 5| Step: 10
Training loss: 5.505573272705078
Validation loss: 4.591031069396644

Epoch: 10| Step: 0
Training loss: 4.093903541564941
Validation loss: 4.582600347457394

Epoch: 5| Step: 1
Training loss: 4.681532859802246
Validation loss: 4.5738239339602895

Epoch: 5| Step: 2
Training loss: 4.845057487487793
Validation loss: 4.563344673443866

Epoch: 5| Step: 3
Training loss: 4.336719036102295
Validation loss: 4.553604377213345

Epoch: 5| Step: 4
Training loss: 5.294259071350098
Validation loss: 4.546243682984383

Epoch: 5| Step: 5
Training loss: 3.0378801822662354
Validation loss: 4.536177286537745

Epoch: 5| Step: 6
Training loss: 4.749777317047119
Validation loss: 4.523731036852765

Epoch: 5| Step: 7
Training loss: 3.631086826324463
Validation loss: 4.5169090250486965

Epoch: 5| Step: 8
Training loss: 4.165276527404785
Validation loss: 4.5064796478517595

Epoch: 5| Step: 9
Training loss: 4.063525676727295
Validation loss: 4.499390243202128

Epoch: 5| Step: 10
Training loss: 4.679645538330078
Validation loss: 4.485186684516169

Epoch: 11| Step: 0
Training loss: 5.445740699768066
Validation loss: 4.476485560017247

Epoch: 5| Step: 1
Training loss: 4.1717400550842285
Validation loss: 4.466840913218837

Epoch: 5| Step: 2
Training loss: 5.326296806335449
Validation loss: 4.457264490025018

Epoch: 5| Step: 3
Training loss: 4.106294631958008
Validation loss: 4.447921547838437

Epoch: 5| Step: 4
Training loss: 5.558396816253662
Validation loss: 4.433569123668056

Epoch: 5| Step: 5
Training loss: 2.6941113471984863
Validation loss: 4.4233954644972275

Epoch: 5| Step: 6
Training loss: 3.74479341506958
Validation loss: 4.412158561009233

Epoch: 5| Step: 7
Training loss: 4.464237213134766
Validation loss: 4.402903136386667

Epoch: 5| Step: 8
Training loss: 3.260282516479492
Validation loss: 4.391723494375905

Epoch: 5| Step: 9
Training loss: 3.8018107414245605
Validation loss: 4.379056422941146

Epoch: 5| Step: 10
Training loss: 3.717855453491211
Validation loss: 4.3691794231373775

Epoch: 12| Step: 0
Training loss: 3.7415053844451904
Validation loss: 4.353727440680227

Epoch: 5| Step: 1
Training loss: 4.08783483505249
Validation loss: 4.3461754322052

Epoch: 5| Step: 2
Training loss: 4.225322723388672
Validation loss: 4.3321489775052635

Epoch: 5| Step: 3
Training loss: 4.865322589874268
Validation loss: 4.325491407866119

Epoch: 5| Step: 4
Training loss: 4.525212287902832
Validation loss: 4.312757512574555

Epoch: 5| Step: 5
Training loss: 3.696840286254883
Validation loss: 4.300907437519361

Epoch: 5| Step: 6
Training loss: 4.76067590713501
Validation loss: 4.2861978623174855

Epoch: 5| Step: 7
Training loss: 4.088391304016113
Validation loss: 4.274275579760151

Epoch: 5| Step: 8
Training loss: 3.434481143951416
Validation loss: 4.264179450209423

Epoch: 5| Step: 9
Training loss: 3.9085490703582764
Validation loss: 4.251092467256772

Epoch: 5| Step: 10
Training loss: 3.6363773345947266
Validation loss: 4.235898212719989

Epoch: 13| Step: 0
Training loss: 4.885021686553955
Validation loss: 4.227962781024235

Epoch: 5| Step: 1
Training loss: 5.275753974914551
Validation loss: 4.212521286420925

Epoch: 5| Step: 2
Training loss: 3.4745349884033203
Validation loss: 4.202037647206296

Epoch: 5| Step: 3
Training loss: 3.5800411701202393
Validation loss: 4.186600426191925

Epoch: 5| Step: 4
Training loss: 4.673759937286377
Validation loss: 4.17432988074518

Epoch: 5| Step: 5
Training loss: 3.121859550476074
Validation loss: 4.16371044804973

Epoch: 5| Step: 6
Training loss: 3.8883273601531982
Validation loss: 4.147067044370917

Epoch: 5| Step: 7
Training loss: 3.371441602706909
Validation loss: 4.1363325119018555

Epoch: 5| Step: 8
Training loss: 3.8055901527404785
Validation loss: 4.118862613554923

Epoch: 5| Step: 9
Training loss: 3.6683859825134277
Validation loss: 4.110141556750062

Epoch: 5| Step: 10
Training loss: 3.938933849334717
Validation loss: 4.097069663386191

Epoch: 14| Step: 0
Training loss: 4.410587310791016
Validation loss: 4.08118293105915

Epoch: 5| Step: 1
Training loss: 4.296346187591553
Validation loss: 4.068565509652578

Epoch: 5| Step: 2
Training loss: 2.9896209239959717
Validation loss: 4.0542282647984

Epoch: 5| Step: 3
Training loss: 2.4824650287628174
Validation loss: 4.044352162268854

Epoch: 5| Step: 4
Training loss: 4.222448348999023
Validation loss: 4.031345913487096

Epoch: 5| Step: 5
Training loss: 3.3106276988983154
Validation loss: 4.009872777487642

Epoch: 5| Step: 6
Training loss: 4.415060997009277
Validation loss: 3.9987613744633173

Epoch: 5| Step: 7
Training loss: 4.140474796295166
Validation loss: 3.985299438558599

Epoch: 5| Step: 8
Training loss: 4.0946502685546875
Validation loss: 3.968162680184969

Epoch: 5| Step: 9
Training loss: 3.2434191703796387
Validation loss: 3.9563751938522502

Epoch: 5| Step: 10
Training loss: 4.737329959869385
Validation loss: 3.938964110548778

Epoch: 15| Step: 0
Training loss: 4.04608678817749
Validation loss: 3.927841878706409

Epoch: 5| Step: 1
Training loss: 3.9924263954162598
Validation loss: 3.912034329547677

Epoch: 5| Step: 2
Training loss: 3.0470924377441406
Validation loss: 3.895477851231893

Epoch: 5| Step: 3
Training loss: 4.248240947723389
Validation loss: 3.8841609185741794

Epoch: 5| Step: 4
Training loss: 4.494500160217285
Validation loss: 3.870509034843855

Epoch: 5| Step: 5
Training loss: 4.174082279205322
Validation loss: 3.862904143589799

Epoch: 5| Step: 6
Training loss: 4.068938255310059
Validation loss: 3.845793854805731

Epoch: 5| Step: 7
Training loss: 3.8490092754364014
Validation loss: 3.8252004654176774

Epoch: 5| Step: 8
Training loss: 2.9510247707366943
Validation loss: 3.815410383286015

Epoch: 5| Step: 9
Training loss: 2.9847710132598877
Validation loss: 3.7999234840434086

Epoch: 5| Step: 10
Training loss: 2.818584442138672
Validation loss: 3.7838763165217575

Epoch: 16| Step: 0
Training loss: 3.689876079559326
Validation loss: 3.769618767564015

Epoch: 5| Step: 1
Training loss: 4.196871280670166
Validation loss: 3.756076387179795

Epoch: 5| Step: 2
Training loss: 4.118489742279053
Validation loss: 3.7389902350723103

Epoch: 5| Step: 3
Training loss: 3.8611807823181152
Validation loss: 3.7209381339370564

Epoch: 5| Step: 4
Training loss: 3.0238728523254395
Validation loss: 3.7125945219429592

Epoch: 5| Step: 5
Training loss: 3.137002468109131
Validation loss: 3.692797286536104

Epoch: 5| Step: 6
Training loss: 3.813683271408081
Validation loss: 3.6795360631840204

Epoch: 5| Step: 7
Training loss: 4.470138072967529
Validation loss: 3.6653744123315297

Epoch: 5| Step: 8
Training loss: 2.9141581058502197
Validation loss: 3.6493287394123692

Epoch: 5| Step: 9
Training loss: 2.4561145305633545
Validation loss: 3.6292421792143132

Epoch: 5| Step: 10
Training loss: 3.6327011585235596
Validation loss: 3.6228290834734516

Epoch: 17| Step: 0
Training loss: 3.4386844635009766
Validation loss: 3.6053050871818297

Epoch: 5| Step: 1
Training loss: 3.3388009071350098
Validation loss: 3.5862692658619215

Epoch: 5| Step: 2
Training loss: 2.8012566566467285
Validation loss: 3.572500777500932

Epoch: 5| Step: 3
Training loss: 3.3996798992156982
Validation loss: 3.5600031678394606

Epoch: 5| Step: 4
Training loss: 3.832284450531006
Validation loss: 3.536742279606481

Epoch: 5| Step: 5
Training loss: 3.2825629711151123
Validation loss: 3.522391355165871

Epoch: 5| Step: 6
Training loss: 4.245322227478027
Validation loss: 3.5091686684598207

Epoch: 5| Step: 7
Training loss: 3.489609479904175
Validation loss: 3.4893928215067875

Epoch: 5| Step: 8
Training loss: 3.938464641571045
Validation loss: 3.476516677487281

Epoch: 5| Step: 9
Training loss: 2.4566636085510254
Validation loss: 3.457449372096728

Epoch: 5| Step: 10
Training loss: 3.4120888710021973
Validation loss: 3.4450402567463536

Epoch: 18| Step: 0
Training loss: 3.071418046951294
Validation loss: 3.4264423206288326

Epoch: 5| Step: 1
Training loss: 2.9472436904907227
Validation loss: 3.397231255808184

Epoch: 5| Step: 2
Training loss: 2.92850923538208
Validation loss: 3.38637347631557

Epoch: 5| Step: 3
Training loss: 4.432065963745117
Validation loss: 3.365587285769883

Epoch: 5| Step: 4
Training loss: 3.9316916465759277
Validation loss: 3.3407622973124185

Epoch: 5| Step: 5
Training loss: 4.248222351074219
Validation loss: 3.3238972592097458

Epoch: 5| Step: 6
Training loss: 3.576747179031372
Validation loss: 3.310200463059128

Epoch: 5| Step: 7
Training loss: 2.3734872341156006
Validation loss: 3.291686696390952

Epoch: 5| Step: 8
Training loss: 2.1687753200531006
Validation loss: 3.2660899213565293

Epoch: 5| Step: 9
Training loss: 3.0338261127471924
Validation loss: 3.2447173621064875

Epoch: 5| Step: 10
Training loss: 3.170161008834839
Validation loss: 3.2196014670915503

Epoch: 19| Step: 0
Training loss: 3.4521610736846924
Validation loss: 3.21159109761638

Epoch: 5| Step: 1
Training loss: 2.645503520965576
Validation loss: 3.190637006554552

Epoch: 5| Step: 2
Training loss: 3.515233278274536
Validation loss: 3.168251427271033

Epoch: 5| Step: 3
Training loss: 3.0241570472717285
Validation loss: 3.148148908410021

Epoch: 5| Step: 4
Training loss: 3.382740020751953
Validation loss: 3.127338832424533

Epoch: 5| Step: 5
Training loss: 3.364222288131714
Validation loss: 3.1073107283602477

Epoch: 5| Step: 6
Training loss: 2.8953068256378174
Validation loss: 3.0902718728588474

Epoch: 5| Step: 7
Training loss: 2.521575927734375
Validation loss: 3.0636516591554046

Epoch: 5| Step: 8
Training loss: 3.1960320472717285
Validation loss: 3.048180751903083

Epoch: 5| Step: 9
Training loss: 3.2506637573242188
Validation loss: 3.03402256196545

Epoch: 5| Step: 10
Training loss: 2.6846866607666016
Validation loss: 3.0165535352563344

Epoch: 20| Step: 0
Training loss: 3.1592135429382324
Validation loss: 2.999585936146398

Epoch: 5| Step: 1
Training loss: 2.6130785942077637
Validation loss: 2.9766689936319985

Epoch: 5| Step: 2
Training loss: 3.2648937702178955
Validation loss: 2.963705401266775

Epoch: 5| Step: 3
Training loss: 3.0854482650756836
Validation loss: 2.936328762321062

Epoch: 5| Step: 4
Training loss: 2.2846617698669434
Validation loss: 2.9176674606979534

Epoch: 5| Step: 5
Training loss: 3.09622859954834
Validation loss: 2.9045714947485153

Epoch: 5| Step: 6
Training loss: 3.588843822479248
Validation loss: 2.889613882187874

Epoch: 5| Step: 7
Training loss: 2.5684216022491455
Validation loss: 2.8699443160846667

Epoch: 5| Step: 8
Training loss: 2.9747633934020996
Validation loss: 2.8475704449479298

Epoch: 5| Step: 9
Training loss: 2.96882700920105
Validation loss: 2.8289313111253964

Epoch: 5| Step: 10
Training loss: 2.744384527206421
Validation loss: 2.8082696724963445

Epoch: 21| Step: 0
Training loss: 2.559993028640747
Validation loss: 2.801544666290283

Epoch: 5| Step: 1
Training loss: 3.1008098125457764
Validation loss: 2.780473270723897

Epoch: 5| Step: 2
Training loss: 2.7944347858428955
Validation loss: 2.7608239522544284

Epoch: 5| Step: 3
Training loss: 2.5952420234680176
Validation loss: 2.7365480956210884

Epoch: 5| Step: 4
Training loss: 2.660353899002075
Validation loss: 2.719724003986646

Epoch: 5| Step: 5
Training loss: 2.1906516551971436
Validation loss: 2.6977413879927767

Epoch: 5| Step: 6
Training loss: 2.525707244873047
Validation loss: 2.6919806593207904

Epoch: 5| Step: 7
Training loss: 3.7883543968200684
Validation loss: 2.6701788133190525

Epoch: 5| Step: 8
Training loss: 2.8565852642059326
Validation loss: 2.6691458866160405

Epoch: 5| Step: 9
Training loss: 2.9998703002929688
Validation loss: 2.6411349978498233

Epoch: 5| Step: 10
Training loss: 2.885519027709961
Validation loss: 2.632735372871481

Epoch: 22| Step: 0
Training loss: 3.295280933380127
Validation loss: 2.619955562776135

Epoch: 5| Step: 1
Training loss: 3.7354025840759277
Validation loss: 2.5928932825724282

Epoch: 5| Step: 2
Training loss: 2.1393604278564453
Validation loss: 2.584507173107516

Epoch: 5| Step: 3
Training loss: 3.2421977519989014
Validation loss: 2.5701513367314495

Epoch: 5| Step: 4
Training loss: 2.941699504852295
Validation loss: 2.5548611199983986

Epoch: 5| Step: 5
Training loss: 2.0959129333496094
Validation loss: 2.5404708923832064

Epoch: 5| Step: 6
Training loss: 2.305772066116333
Validation loss: 2.5266991097440004

Epoch: 5| Step: 7
Training loss: 2.508932590484619
Validation loss: 2.50654359017649

Epoch: 5| Step: 8
Training loss: 2.1496119499206543
Validation loss: 2.4916055945939917

Epoch: 5| Step: 9
Training loss: 2.3305203914642334
Validation loss: 2.482738002654045

Epoch: 5| Step: 10
Training loss: 3.034827947616577
Validation loss: 2.477100977333643

Epoch: 23| Step: 0
Training loss: 2.5351638793945312
Validation loss: 2.4502954431759414

Epoch: 5| Step: 1
Training loss: 3.442791700363159
Validation loss: 2.426416625258743

Epoch: 5| Step: 2
Training loss: 2.590261459350586
Validation loss: 2.4210126143629833

Epoch: 5| Step: 3
Training loss: 3.0084023475646973
Validation loss: 2.413763142401172

Epoch: 5| Step: 4
Training loss: 2.2424888610839844
Validation loss: 2.4106820526943413

Epoch: 5| Step: 5
Training loss: 2.3952651023864746
Validation loss: 2.3951742982351654

Epoch: 5| Step: 6
Training loss: 2.4829680919647217
Validation loss: 2.3851436350935247

Epoch: 5| Step: 7
Training loss: 2.9573092460632324
Validation loss: 2.371592334521714

Epoch: 5| Step: 8
Training loss: 2.37577748298645
Validation loss: 2.3695213640889814

Epoch: 5| Step: 9
Training loss: 2.2808732986450195
Validation loss: 2.3515575393553703

Epoch: 5| Step: 10
Training loss: 2.2701711654663086
Validation loss: 2.3466688458637526

Epoch: 24| Step: 0
Training loss: 2.9045474529266357
Validation loss: 2.328615996145433

Epoch: 5| Step: 1
Training loss: 2.801633358001709
Validation loss: 2.326064884021718

Epoch: 5| Step: 2
Training loss: 2.4551708698272705
Validation loss: 2.3088006588720504

Epoch: 5| Step: 3
Training loss: 2.1145455837249756
Validation loss: 2.3008175332059144

Epoch: 5| Step: 4
Training loss: 2.41644287109375
Validation loss: 2.291575916351811

Epoch: 5| Step: 5
Training loss: 2.6526005268096924
Validation loss: 2.2757851180209907

Epoch: 5| Step: 6
Training loss: 1.7888046503067017
Validation loss: 2.2712794503858014

Epoch: 5| Step: 7
Training loss: 3.3633029460906982
Validation loss: 2.2659439194586968

Epoch: 5| Step: 8
Training loss: 2.5905184745788574
Validation loss: 2.2449067818221224

Epoch: 5| Step: 9
Training loss: 2.2896251678466797
Validation loss: 2.2332892135907243

Epoch: 5| Step: 10
Training loss: 2.595698595046997
Validation loss: 2.2446015573317006

Epoch: 25| Step: 0
Training loss: 2.0139832496643066
Validation loss: 2.242538188093452

Epoch: 5| Step: 1
Training loss: 2.675037384033203
Validation loss: 2.2437512002965456

Epoch: 5| Step: 2
Training loss: 2.185629367828369
Validation loss: 2.2432899193097184

Epoch: 5| Step: 3
Training loss: 2.771486759185791
Validation loss: 2.2255458139604136

Epoch: 5| Step: 4
Training loss: 1.7205994129180908
Validation loss: 2.2279039749535183

Epoch: 5| Step: 5
Training loss: 2.8286337852478027
Validation loss: 2.2145689636148433

Epoch: 5| Step: 6
Training loss: 2.642981767654419
Validation loss: 2.202470202599802

Epoch: 5| Step: 7
Training loss: 2.840501308441162
Validation loss: 2.223968598150438

Epoch: 5| Step: 8
Training loss: 2.0733015537261963
Validation loss: 2.2070144376447125

Epoch: 5| Step: 9
Training loss: 2.5239596366882324
Validation loss: 2.2094932038296937

Epoch: 5| Step: 10
Training loss: 3.3050954341888428
Validation loss: 2.2033457012586695

Epoch: 26| Step: 0
Training loss: 2.2576518058776855
Validation loss: 2.187747255448372

Epoch: 5| Step: 1
Training loss: 2.3147521018981934
Validation loss: 2.1771807004046697

Epoch: 5| Step: 2
Training loss: 2.5525248050689697
Validation loss: 2.1933647253180064

Epoch: 5| Step: 3
Training loss: 1.9695699214935303
Validation loss: 2.1878764398636354

Epoch: 5| Step: 4
Training loss: 2.2327523231506348
Validation loss: 2.1938972114234843

Epoch: 5| Step: 5
Training loss: 3.1975784301757812
Validation loss: 2.17497589254892

Epoch: 5| Step: 6
Training loss: 2.2351174354553223
Validation loss: 2.1802676236757668

Epoch: 5| Step: 7
Training loss: 2.3370745182037354
Validation loss: 2.183455067296182

Epoch: 5| Step: 8
Training loss: 2.2841556072235107
Validation loss: 2.1630021782331568

Epoch: 5| Step: 9
Training loss: 3.0548160076141357
Validation loss: 2.17493296951376

Epoch: 5| Step: 10
Training loss: 2.9043383598327637
Validation loss: 2.165401715104298

Epoch: 27| Step: 0
Training loss: 1.6202571392059326
Validation loss: 2.1716024260367117

Epoch: 5| Step: 1
Training loss: 2.4352824687957764
Validation loss: 2.156314610153116

Epoch: 5| Step: 2
Training loss: 2.420414686203003
Validation loss: 2.174544266475144

Epoch: 5| Step: 3
Training loss: 2.7372074127197266
Validation loss: 2.147887663174701

Epoch: 5| Step: 4
Training loss: 2.5175271034240723
Validation loss: 2.1658348191169

Epoch: 5| Step: 5
Training loss: 2.7093398571014404
Validation loss: 2.163754350395613

Epoch: 5| Step: 6
Training loss: 2.276853322982788
Validation loss: 2.164954782814108

Epoch: 5| Step: 7
Training loss: 2.8419077396392822
Validation loss: 2.154800763694189

Epoch: 5| Step: 8
Training loss: 2.672894239425659
Validation loss: 2.155116033810441

Epoch: 5| Step: 9
Training loss: 2.324789047241211
Validation loss: 2.1454022187058643

Epoch: 5| Step: 10
Training loss: 2.6449151039123535
Validation loss: 2.1578214604367494

Epoch: 28| Step: 0
Training loss: 1.9714568853378296
Validation loss: 2.1464366336022653

Epoch: 5| Step: 1
Training loss: 2.2943918704986572
Validation loss: 2.139384541460263

Epoch: 5| Step: 2
Training loss: 2.991910934448242
Validation loss: 2.139365662810623

Epoch: 5| Step: 3
Training loss: 2.2233822345733643
Validation loss: 2.1442051305565784

Epoch: 5| Step: 4
Training loss: 2.6628661155700684
Validation loss: 2.143760622188609

Epoch: 5| Step: 5
Training loss: 2.346130609512329
Validation loss: 2.147251846969769

Epoch: 5| Step: 6
Training loss: 2.8744304180145264
Validation loss: 2.143951646743282

Epoch: 5| Step: 7
Training loss: 1.7787425518035889
Validation loss: 2.1504077167921167

Epoch: 5| Step: 8
Training loss: 2.6815359592437744
Validation loss: 2.1421514531617523

Epoch: 5| Step: 9
Training loss: 2.6807663440704346
Validation loss: 2.118488052839874

Epoch: 5| Step: 10
Training loss: 2.585961103439331
Validation loss: 2.1301092870773806

Epoch: 29| Step: 0
Training loss: 2.1896414756774902
Validation loss: 2.1233896183711227

Epoch: 5| Step: 1
Training loss: 2.6554927825927734
Validation loss: 2.132233096707252

Epoch: 5| Step: 2
Training loss: 2.4422547817230225
Validation loss: 2.1314139263604277

Epoch: 5| Step: 3
Training loss: 2.5443475246429443
Validation loss: 2.121610141569568

Epoch: 5| Step: 4
Training loss: 1.8370879888534546
Validation loss: 2.126017124422135

Epoch: 5| Step: 5
Training loss: 2.482347011566162
Validation loss: 2.121057810321931

Epoch: 5| Step: 6
Training loss: 2.6835739612579346
Validation loss: 2.1174071450387277

Epoch: 5| Step: 7
Training loss: 2.302642345428467
Validation loss: 2.1304774771454515

Epoch: 5| Step: 8
Training loss: 2.890463352203369
Validation loss: 2.1274572290400022

Epoch: 5| Step: 9
Training loss: 2.6751911640167236
Validation loss: 2.116713721265075

Epoch: 5| Step: 10
Training loss: 2.266862154006958
Validation loss: 2.128209352493286

Epoch: 30| Step: 0
Training loss: 2.518594741821289
Validation loss: 2.1302853694526096

Epoch: 5| Step: 1
Training loss: 2.6652424335479736
Validation loss: 2.121089509738389

Epoch: 5| Step: 2
Training loss: 2.714931011199951
Validation loss: 2.11615946215968

Epoch: 5| Step: 3
Training loss: 2.268920660018921
Validation loss: 2.124190484323809

Epoch: 5| Step: 4
Training loss: 2.3548808097839355
Validation loss: 2.119282263581471

Epoch: 5| Step: 5
Training loss: 2.146367073059082
Validation loss: 2.118528063579272

Epoch: 5| Step: 6
Training loss: 2.0311992168426514
Validation loss: 2.1108670875590336

Epoch: 5| Step: 7
Training loss: 2.8843472003936768
Validation loss: 2.1087246402617423

Epoch: 5| Step: 8
Training loss: 2.4089741706848145
Validation loss: 2.10907482588163

Epoch: 5| Step: 9
Training loss: 2.6617636680603027
Validation loss: 2.1123707422646145

Epoch: 5| Step: 10
Training loss: 2.1433427333831787
Validation loss: 2.129007952187651

Epoch: 31| Step: 0
Training loss: 2.8542227745056152
Validation loss: 2.141613850029566

Epoch: 5| Step: 1
Training loss: 2.983135223388672
Validation loss: 2.116863250732422

Epoch: 5| Step: 2
Training loss: 2.5932559967041016
Validation loss: 2.111770068445513

Epoch: 5| Step: 3
Training loss: 2.332606315612793
Validation loss: 2.1223072339129705

Epoch: 5| Step: 4
Training loss: 2.657667875289917
Validation loss: 2.1178053245749524

Epoch: 5| Step: 5
Training loss: 2.511032819747925
Validation loss: 2.1101033764500774

Epoch: 5| Step: 6
Training loss: 2.615215301513672
Validation loss: 2.1274074892843924

Epoch: 5| Step: 7
Training loss: 2.3301568031311035
Validation loss: 2.1217079226688673

Epoch: 5| Step: 8
Training loss: 2.1099894046783447
Validation loss: 2.1121070179887997

Epoch: 5| Step: 9
Training loss: 1.394588828086853
Validation loss: 2.1184862185549993

Epoch: 5| Step: 10
Training loss: 2.392883539199829
Validation loss: 2.107433198600687

Epoch: 32| Step: 0
Training loss: 2.4287056922912598
Validation loss: 2.1161193296473515

Epoch: 5| Step: 1
Training loss: 2.046257495880127
Validation loss: 2.104384852993873

Epoch: 5| Step: 2
Training loss: 2.1192941665649414
Validation loss: 2.1136786348076275

Epoch: 5| Step: 3
Training loss: 2.5112216472625732
Validation loss: 2.0980981011544504

Epoch: 5| Step: 4
Training loss: 2.6262307167053223
Validation loss: 2.0994428434679584

Epoch: 5| Step: 5
Training loss: 2.3445777893066406
Validation loss: 2.101869213965631

Epoch: 5| Step: 6
Training loss: 2.2493045330047607
Validation loss: 2.1177026943493913

Epoch: 5| Step: 7
Training loss: 2.902712821960449
Validation loss: 2.1163513173339186

Epoch: 5| Step: 8
Training loss: 2.061533212661743
Validation loss: 2.10237878881475

Epoch: 5| Step: 9
Training loss: 2.7656826972961426
Validation loss: 2.1124956018181256

Epoch: 5| Step: 10
Training loss: 2.841940402984619
Validation loss: 2.1106211318764636

Epoch: 33| Step: 0
Training loss: 2.431431293487549
Validation loss: 2.1082010012800976

Epoch: 5| Step: 1
Training loss: 2.7818799018859863
Validation loss: 2.118853735667403

Epoch: 5| Step: 2
Training loss: 2.2107784748077393
Validation loss: 2.0922378416984313

Epoch: 5| Step: 3
Training loss: 2.3662924766540527
Validation loss: 2.1159728342486965

Epoch: 5| Step: 4
Training loss: 2.7420287132263184
Validation loss: 2.1059906764697005

Epoch: 5| Step: 5
Training loss: 2.3751490116119385
Validation loss: 2.1105325888561945

Epoch: 5| Step: 6
Training loss: 2.0154881477355957
Validation loss: 2.1130844008538032

Epoch: 5| Step: 7
Training loss: 2.5755138397216797
Validation loss: 2.10611274550038

Epoch: 5| Step: 8
Training loss: 2.6945626735687256
Validation loss: 2.1170900560194448

Epoch: 5| Step: 9
Training loss: 2.0730538368225098
Validation loss: 2.103243233055197

Epoch: 5| Step: 10
Training loss: 2.48146390914917
Validation loss: 2.1096058455846642

Epoch: 34| Step: 0
Training loss: 1.675061821937561
Validation loss: 2.098361530611592

Epoch: 5| Step: 1
Training loss: 2.5154337882995605
Validation loss: 2.0998420856332265

Epoch: 5| Step: 2
Training loss: 2.086611270904541
Validation loss: 2.107301394144694

Epoch: 5| Step: 3
Training loss: 2.1861348152160645
Validation loss: 2.09580433881411

Epoch: 5| Step: 4
Training loss: 2.0296099185943604
Validation loss: 2.0886872712002007

Epoch: 5| Step: 5
Training loss: 2.4581987857818604
Validation loss: 2.10804013283022

Epoch: 5| Step: 6
Training loss: 2.627962350845337
Validation loss: 2.1015443776243474

Epoch: 5| Step: 7
Training loss: 2.9923274517059326
Validation loss: 2.091701179422358

Epoch: 5| Step: 8
Training loss: 2.097890853881836
Validation loss: 2.081306463928633

Epoch: 5| Step: 9
Training loss: 2.686567544937134
Validation loss: 2.0848400746622393

Epoch: 5| Step: 10
Training loss: 3.48160457611084
Validation loss: 2.0840631390130646

Epoch: 35| Step: 0
Training loss: 2.8419032096862793
Validation loss: 2.08472546967127

Epoch: 5| Step: 1
Training loss: 1.7403968572616577
Validation loss: 2.0743244207033547

Epoch: 5| Step: 2
Training loss: 2.6499521732330322
Validation loss: 2.0948044664116314

Epoch: 5| Step: 3
Training loss: 2.5600197315216064
Validation loss: 2.0832305723621

Epoch: 5| Step: 4
Training loss: 1.9143069982528687
Validation loss: 2.0817216352749894

Epoch: 5| Step: 5
Training loss: 2.361182689666748
Validation loss: 2.0970987068709506

Epoch: 5| Step: 6
Training loss: 2.825965404510498
Validation loss: 2.0922721560283373

Epoch: 5| Step: 7
Training loss: 2.1914114952087402
Validation loss: 2.0833024927364883

Epoch: 5| Step: 8
Training loss: 2.585322380065918
Validation loss: 2.0977578060601347

Epoch: 5| Step: 9
Training loss: 2.584989070892334
Validation loss: 2.100411608654966

Epoch: 5| Step: 10
Training loss: 2.4017889499664307
Validation loss: 2.1080455651847263

Epoch: 36| Step: 0
Training loss: 2.643695116043091
Validation loss: 2.092785321256166

Epoch: 5| Step: 1
Training loss: 2.2902560234069824
Validation loss: 2.095331290716766

Epoch: 5| Step: 2
Training loss: 2.7391154766082764
Validation loss: 2.111593936079292

Epoch: 5| Step: 3
Training loss: 2.140901803970337
Validation loss: 2.090936601802867

Epoch: 5| Step: 4
Training loss: 2.478562116622925
Validation loss: 2.094996952241467

Epoch: 5| Step: 5
Training loss: 2.7929885387420654
Validation loss: 2.097049154261107

Epoch: 5| Step: 6
Training loss: 2.143812894821167
Validation loss: 2.0884675133612847

Epoch: 5| Step: 7
Training loss: 2.6014270782470703
Validation loss: 2.1006397944624706

Epoch: 5| Step: 8
Training loss: 2.0295205116271973
Validation loss: 2.0978650662206833

Epoch: 5| Step: 9
Training loss: 2.3173489570617676
Validation loss: 2.091117464086061

Epoch: 5| Step: 10
Training loss: 2.2941970825195312
Validation loss: 2.0899755800923994

Epoch: 37| Step: 0
Training loss: 2.710428237915039
Validation loss: 2.091497728901525

Epoch: 5| Step: 1
Training loss: 1.9737869501113892
Validation loss: 2.07172147176599

Epoch: 5| Step: 2
Training loss: 2.3052613735198975
Validation loss: 2.0993264900740756

Epoch: 5| Step: 3
Training loss: 1.967560052871704
Validation loss: 2.095729112625122

Epoch: 5| Step: 4
Training loss: 2.8180859088897705
Validation loss: 2.0824492439146964

Epoch: 5| Step: 5
Training loss: 2.7183613777160645
Validation loss: 2.0742258769209667

Epoch: 5| Step: 6
Training loss: 2.3249759674072266
Validation loss: 2.0735709923569874

Epoch: 5| Step: 7
Training loss: 2.5911059379577637
Validation loss: 2.0868282113023984

Epoch: 5| Step: 8
Training loss: 2.055494546890259
Validation loss: 2.0889064086380826

Epoch: 5| Step: 9
Training loss: 2.6992135047912598
Validation loss: 2.088503909367387

Epoch: 5| Step: 10
Training loss: 2.339404582977295
Validation loss: 2.1023228681215675

Epoch: 38| Step: 0
Training loss: 2.5740745067596436
Validation loss: 2.089378365906336

Epoch: 5| Step: 1
Training loss: 2.1154980659484863
Validation loss: 2.087751132185741

Epoch: 5| Step: 2
Training loss: 2.042922258377075
Validation loss: 2.110555091211873

Epoch: 5| Step: 3
Training loss: 2.020132303237915
Validation loss: 2.1040404317199544

Epoch: 5| Step: 4
Training loss: 2.173785448074341
Validation loss: 2.1014447314764864

Epoch: 5| Step: 5
Training loss: 2.760042905807495
Validation loss: 2.088788147895567

Epoch: 5| Step: 6
Training loss: 2.814990520477295
Validation loss: 2.091448882574676

Epoch: 5| Step: 7
Training loss: 2.701343059539795
Validation loss: 2.084133081538703

Epoch: 5| Step: 8
Training loss: 1.7438075542449951
Validation loss: 2.098622175955003

Epoch: 5| Step: 9
Training loss: 2.792642116546631
Validation loss: 2.0823789463248303

Epoch: 5| Step: 10
Training loss: 2.669691562652588
Validation loss: 2.0879840312465543

Epoch: 39| Step: 0
Training loss: 2.2815675735473633
Validation loss: 2.0730578130291355

Epoch: 5| Step: 1
Training loss: 2.213984966278076
Validation loss: 2.083270767683624

Epoch: 5| Step: 2
Training loss: 2.2373383045196533
Validation loss: 2.0995599108357585

Epoch: 5| Step: 3
Training loss: 2.443645477294922
Validation loss: 2.0672240026535524

Epoch: 5| Step: 4
Training loss: 2.2319142818450928
Validation loss: 2.08446402447198

Epoch: 5| Step: 5
Training loss: 2.5869781970977783
Validation loss: 2.08212947845459

Epoch: 5| Step: 6
Training loss: 2.738720655441284
Validation loss: 2.0820315960914857

Epoch: 5| Step: 7
Training loss: 2.4335386753082275
Validation loss: 2.071570424623387

Epoch: 5| Step: 8
Training loss: 2.6482386589050293
Validation loss: 2.0881158228843444

Epoch: 5| Step: 9
Training loss: 2.739715576171875
Validation loss: 2.0791283269082346

Epoch: 5| Step: 10
Training loss: 1.6499013900756836
Validation loss: 2.0747105139558033

Epoch: 40| Step: 0
Training loss: 2.6877262592315674
Validation loss: 2.0766579271644674

Epoch: 5| Step: 1
Training loss: 2.5696542263031006
Validation loss: 2.076985166918847

Epoch: 5| Step: 2
Training loss: 2.381425380706787
Validation loss: 2.0756799572257587

Epoch: 5| Step: 3
Training loss: 2.3581814765930176
Validation loss: 2.0740244362943914

Epoch: 5| Step: 4
Training loss: 2.033263921737671
Validation loss: 2.081287384033203

Epoch: 5| Step: 5
Training loss: 2.5109241008758545
Validation loss: 2.085907200331329

Epoch: 5| Step: 6
Training loss: 2.9193012714385986
Validation loss: 2.063674129465575

Epoch: 5| Step: 7
Training loss: 1.723689317703247
Validation loss: 2.0774083009330173

Epoch: 5| Step: 8
Training loss: 2.6904873847961426
Validation loss: 2.0778991637691373

Epoch: 5| Step: 9
Training loss: 2.281888008117676
Validation loss: 2.085984917097194

Epoch: 5| Step: 10
Training loss: 2.090883255004883
Validation loss: 2.0866034825642905

Epoch: 41| Step: 0
Training loss: 2.3769240379333496
Validation loss: 2.077935775121053

Epoch: 5| Step: 1
Training loss: 2.6015219688415527
Validation loss: 2.072121433032456

Epoch: 5| Step: 2
Training loss: 2.1734795570373535
Validation loss: 2.0819710198269097

Epoch: 5| Step: 3
Training loss: 1.8547122478485107
Validation loss: 2.0750726628047165

Epoch: 5| Step: 4
Training loss: 2.5389018058776855
Validation loss: 2.0830814723045594

Epoch: 5| Step: 5
Training loss: 2.3041770458221436
Validation loss: 2.0867154598236084

Epoch: 5| Step: 6
Training loss: 2.324960231781006
Validation loss: 2.0725311156242125

Epoch: 5| Step: 7
Training loss: 2.887287139892578
Validation loss: 2.0597760305609754

Epoch: 5| Step: 8
Training loss: 1.9347273111343384
Validation loss: 2.083482362890756

Epoch: 5| Step: 9
Training loss: 2.49926495552063
Validation loss: 2.0686119987118627

Epoch: 5| Step: 10
Training loss: 2.7577853202819824
Validation loss: 2.078846387965705

Epoch: 42| Step: 0
Training loss: 2.768634080886841
Validation loss: 2.0746267175161712

Epoch: 5| Step: 1
Training loss: 2.616482734680176
Validation loss: 2.078692284963464

Epoch: 5| Step: 2
Training loss: 2.410933256149292
Validation loss: 2.0749691186412687

Epoch: 5| Step: 3
Training loss: 2.8666176795959473
Validation loss: 2.078176342031007

Epoch: 5| Step: 4
Training loss: 2.1116137504577637
Validation loss: 2.0743062432094286

Epoch: 5| Step: 5
Training loss: 2.0976510047912598
Validation loss: 2.0805513064066568

Epoch: 5| Step: 6
Training loss: 2.5165762901306152
Validation loss: 2.080783203083982

Epoch: 5| Step: 7
Training loss: 1.735673189163208
Validation loss: 2.0844064630487913

Epoch: 5| Step: 8
Training loss: 2.370954990386963
Validation loss: 2.092783410062072

Epoch: 5| Step: 9
Training loss: 2.625547170639038
Validation loss: 2.0797078827376008

Epoch: 5| Step: 10
Training loss: 1.9449119567871094
Validation loss: 2.08602976029919

Epoch: 43| Step: 0
Training loss: 2.8420448303222656
Validation loss: 2.0690334548232374

Epoch: 5| Step: 1
Training loss: 2.0647988319396973
Validation loss: 2.077759585072917

Epoch: 5| Step: 2
Training loss: 1.936231255531311
Validation loss: 2.068900257028559

Epoch: 5| Step: 3
Training loss: 2.8792576789855957
Validation loss: 2.0724640161760393

Epoch: 5| Step: 4
Training loss: 1.937485933303833
Validation loss: 2.0637888754567792

Epoch: 5| Step: 5
Training loss: 1.983268141746521
Validation loss: 2.05668907268073

Epoch: 5| Step: 6
Training loss: 2.1564841270446777
Validation loss: 2.0705705150481193

Epoch: 5| Step: 7
Training loss: 2.810426712036133
Validation loss: 2.077073299756614

Epoch: 5| Step: 8
Training loss: 1.9339462518692017
Validation loss: 2.0727705147958573

Epoch: 5| Step: 9
Training loss: 2.6505842208862305
Validation loss: 2.0738033376714236

Epoch: 5| Step: 10
Training loss: 2.973320484161377
Validation loss: 2.062824603049986

Epoch: 44| Step: 0
Training loss: 1.8067430257797241
Validation loss: 2.069748150405063

Epoch: 5| Step: 1
Training loss: 2.664780855178833
Validation loss: 2.055215774043914

Epoch: 5| Step: 2
Training loss: 2.8374252319335938
Validation loss: 2.054693588646509

Epoch: 5| Step: 3
Training loss: 2.6045963764190674
Validation loss: 2.059755826509127

Epoch: 5| Step: 4
Training loss: 2.38254714012146
Validation loss: 2.050145310740317

Epoch: 5| Step: 5
Training loss: 2.524022340774536
Validation loss: 2.052943960312874

Epoch: 5| Step: 6
Training loss: 2.2614405155181885
Validation loss: 2.0670251871949885

Epoch: 5| Step: 7
Training loss: 2.7919650077819824
Validation loss: 2.0419052313732844

Epoch: 5| Step: 8
Training loss: 2.5558536052703857
Validation loss: 2.0627196219659623

Epoch: 5| Step: 9
Training loss: 2.0636603832244873
Validation loss: 2.06077310603152

Epoch: 5| Step: 10
Training loss: 1.3961371183395386
Validation loss: 2.052046629690355

Epoch: 45| Step: 0
Training loss: 2.965134859085083
Validation loss: 2.0612393450993363

Epoch: 5| Step: 1
Training loss: 2.4775679111480713
Validation loss: 2.059745516828311

Epoch: 5| Step: 2
Training loss: 1.5972884893417358
Validation loss: 2.052444258043843

Epoch: 5| Step: 3
Training loss: 2.012129306793213
Validation loss: 2.068535754757543

Epoch: 5| Step: 4
Training loss: 2.5263218879699707
Validation loss: 2.059989825371773

Epoch: 5| Step: 5
Training loss: 2.839725971221924
Validation loss: 2.0610972706989577

Epoch: 5| Step: 6
Training loss: 2.6797399520874023
Validation loss: 2.0575914562389417

Epoch: 5| Step: 7
Training loss: 2.411956310272217
Validation loss: 2.0558645045885475

Epoch: 5| Step: 8
Training loss: 1.8753963708877563
Validation loss: 2.0656110676386024

Epoch: 5| Step: 9
Training loss: 2.387688159942627
Validation loss: 2.054184562416487

Epoch: 5| Step: 10
Training loss: 2.212076425552368
Validation loss: 2.064799988141624

Epoch: 46| Step: 0
Training loss: 2.4790711402893066
Validation loss: 2.047107809333391

Epoch: 5| Step: 1
Training loss: 2.3733279705047607
Validation loss: 2.0621486530509046

Epoch: 5| Step: 2
Training loss: 1.8154428005218506
Validation loss: 2.0530834069816013

Epoch: 5| Step: 3
Training loss: 2.8241639137268066
Validation loss: 2.05079343370212

Epoch: 5| Step: 4
Training loss: 2.0177981853485107
Validation loss: 2.0426590660566926

Epoch: 5| Step: 5
Training loss: 2.393958568572998
Validation loss: 2.061511539643811

Epoch: 5| Step: 6
Training loss: 2.2875101566314697
Validation loss: 2.037105615421008

Epoch: 5| Step: 7
Training loss: 2.694370985031128
Validation loss: 2.038300329639066

Epoch: 5| Step: 8
Training loss: 2.3903133869171143
Validation loss: 2.046713998240809

Epoch: 5| Step: 9
Training loss: 2.514143466949463
Validation loss: 2.0567313804421374

Epoch: 5| Step: 10
Training loss: 2.0836493968963623
Validation loss: 2.044857922420707

Epoch: 47| Step: 0
Training loss: 2.776108503341675
Validation loss: 2.0425265463449622

Epoch: 5| Step: 1
Training loss: 1.8722587823867798
Validation loss: 2.0388136371489494

Epoch: 5| Step: 2
Training loss: 1.87661874294281
Validation loss: 2.047762711842855

Epoch: 5| Step: 3
Training loss: 2.7223596572875977
Validation loss: 2.0390288752894246

Epoch: 5| Step: 4
Training loss: 2.770264148712158
Validation loss: 2.043482998365997

Epoch: 5| Step: 5
Training loss: 2.1153435707092285
Validation loss: 2.0482195218404136

Epoch: 5| Step: 6
Training loss: 2.158128023147583
Validation loss: 2.0531894853038173

Epoch: 5| Step: 7
Training loss: 2.213223695755005
Validation loss: 2.0490770237420195

Epoch: 5| Step: 8
Training loss: 2.475151538848877
Validation loss: 2.0666419459927465

Epoch: 5| Step: 9
Training loss: 2.4870684146881104
Validation loss: 2.056067205244495

Epoch: 5| Step: 10
Training loss: 2.470318078994751
Validation loss: 2.061969716061828

Epoch: 48| Step: 0
Training loss: 2.374969482421875
Validation loss: 2.0483209715094617

Epoch: 5| Step: 1
Training loss: 2.360414981842041
Validation loss: 2.043683044372066

Epoch: 5| Step: 2
Training loss: 1.8358274698257446
Validation loss: 2.0489261252905733

Epoch: 5| Step: 3
Training loss: 2.816561222076416
Validation loss: 2.042368422272385

Epoch: 5| Step: 4
Training loss: 2.7077293395996094
Validation loss: 2.049374206091768

Epoch: 5| Step: 5
Training loss: 2.6731550693511963
Validation loss: 2.044568879629976

Epoch: 5| Step: 6
Training loss: 1.9430497884750366
Validation loss: 2.045556273511661

Epoch: 5| Step: 7
Training loss: 2.7174313068389893
Validation loss: 2.0462983654391382

Epoch: 5| Step: 8
Training loss: 1.7466545104980469
Validation loss: 2.0387338669069353

Epoch: 5| Step: 9
Training loss: 2.340344190597534
Validation loss: 2.0455591409437117

Epoch: 5| Step: 10
Training loss: 2.3758866786956787
Validation loss: 2.038657062797136

Epoch: 49| Step: 0
Training loss: 2.68540620803833
Validation loss: 2.0368940317502586

Epoch: 5| Step: 1
Training loss: 2.069692611694336
Validation loss: 2.03228243448401

Epoch: 5| Step: 2
Training loss: 1.9594783782958984
Validation loss: 2.04270907755821

Epoch: 5| Step: 3
Training loss: 2.2996296882629395
Validation loss: 2.0424828349903064

Epoch: 5| Step: 4
Training loss: 2.524080991744995
Validation loss: 2.052961052104991

Epoch: 5| Step: 5
Training loss: 2.3399555683135986
Validation loss: 2.0554521827287573

Epoch: 5| Step: 6
Training loss: 2.453988552093506
Validation loss: 2.04708226906356

Epoch: 5| Step: 7
Training loss: 2.4236626625061035
Validation loss: 2.032980433074377

Epoch: 5| Step: 8
Training loss: 2.6562511920928955
Validation loss: 2.030850987280569

Epoch: 5| Step: 9
Training loss: 2.3549108505249023
Validation loss: 2.0552226676735827

Epoch: 5| Step: 10
Training loss: 1.9403332471847534
Validation loss: 2.0443708691545712

Epoch: 50| Step: 0
Training loss: 2.4435548782348633
Validation loss: 2.0368614401868594

Epoch: 5| Step: 1
Training loss: 2.1642818450927734
Validation loss: 2.057312289873759

Epoch: 5| Step: 2
Training loss: 3.246539354324341
Validation loss: 2.0400924016070623

Epoch: 5| Step: 3
Training loss: 2.1153452396392822
Validation loss: 2.0408238275076753

Epoch: 5| Step: 4
Training loss: 2.220487356185913
Validation loss: 2.0438281977048485

Epoch: 5| Step: 5
Training loss: 2.230829954147339
Validation loss: 2.046254457965974

Epoch: 5| Step: 6
Training loss: 1.998502492904663
Validation loss: 2.0438935628501316

Epoch: 5| Step: 7
Training loss: 1.8947452306747437
Validation loss: 2.0411457861623457

Epoch: 5| Step: 8
Training loss: 2.5359296798706055
Validation loss: 2.043071428934733

Epoch: 5| Step: 9
Training loss: 2.434451103210449
Validation loss: 2.054613621004166

Epoch: 5| Step: 10
Training loss: 2.500497817993164
Validation loss: 2.02971932067666

Epoch: 51| Step: 0
Training loss: 2.1507935523986816
Validation loss: 2.0327832365548737

Epoch: 5| Step: 1
Training loss: 2.5323338508605957
Validation loss: 2.026292625293937

Epoch: 5| Step: 2
Training loss: 2.5109424591064453
Validation loss: 2.032369844375118

Epoch: 5| Step: 3
Training loss: 2.6451306343078613
Validation loss: 2.027934279493106

Epoch: 5| Step: 4
Training loss: 2.048194408416748
Validation loss: 2.0401432591099895

Epoch: 5| Step: 5
Training loss: 2.0626025199890137
Validation loss: 2.0279430689350253

Epoch: 5| Step: 6
Training loss: 2.287595748901367
Validation loss: 2.049944967351934

Epoch: 5| Step: 7
Training loss: 1.9934982061386108
Validation loss: 2.025534588803527

Epoch: 5| Step: 8
Training loss: 2.904752254486084
Validation loss: 2.0348682172836794

Epoch: 5| Step: 9
Training loss: 2.0550174713134766
Validation loss: 2.0408016327888734

Epoch: 5| Step: 10
Training loss: 2.478562355041504
Validation loss: 2.040729050995201

Epoch: 52| Step: 0
Training loss: 3.225592851638794
Validation loss: 2.02463238598198

Epoch: 5| Step: 1
Training loss: 2.1681106090545654
Validation loss: 2.03561137055838

Epoch: 5| Step: 2
Training loss: 2.239731788635254
Validation loss: 2.0307885959584224

Epoch: 5| Step: 3
Training loss: 3.0367798805236816
Validation loss: 2.0266475318580546

Epoch: 5| Step: 4
Training loss: 1.7645890712738037
Validation loss: 2.042086362838745

Epoch: 5| Step: 5
Training loss: 2.2682621479034424
Validation loss: 2.0260461607287006

Epoch: 5| Step: 6
Training loss: 2.525510787963867
Validation loss: 2.0301885527949177

Epoch: 5| Step: 7
Training loss: 2.2604572772979736
Validation loss: 2.045192482650921

Epoch: 5| Step: 8
Training loss: 1.7541958093643188
Validation loss: 2.0325379371643066

Epoch: 5| Step: 9
Training loss: 1.7862190008163452
Validation loss: 2.034224940884498

Epoch: 5| Step: 10
Training loss: 2.622887372970581
Validation loss: 2.041885765649939

Epoch: 53| Step: 0
Training loss: 2.0775258541107178
Validation loss: 2.0330667393181914

Epoch: 5| Step: 1
Training loss: 2.5538063049316406
Validation loss: 2.0279104594261415

Epoch: 5| Step: 2
Training loss: 2.0098252296447754
Validation loss: 2.0368028622801586

Epoch: 5| Step: 3
Training loss: 2.007827043533325
Validation loss: 2.0297305148134948

Epoch: 5| Step: 4
Training loss: 2.7090566158294678
Validation loss: 2.0357814886236705

Epoch: 5| Step: 5
Training loss: 2.201475143432617
Validation loss: 2.0097340486382924

Epoch: 5| Step: 6
Training loss: 2.613347291946411
Validation loss: 2.0299480256213935

Epoch: 5| Step: 7
Training loss: 2.438774585723877
Validation loss: 2.01496906434336

Epoch: 5| Step: 8
Training loss: 1.8932254314422607
Validation loss: 2.0368672417056177

Epoch: 5| Step: 9
Training loss: 2.6645495891571045
Validation loss: 2.012512174985742

Epoch: 5| Step: 10
Training loss: 2.362260580062866
Validation loss: 2.0114235480626426

Epoch: 54| Step: 0
Training loss: 2.7372803688049316
Validation loss: 2.024884025255839

Epoch: 5| Step: 1
Training loss: 2.5008139610290527
Validation loss: 2.02094167535023

Epoch: 5| Step: 2
Training loss: 2.138026237487793
Validation loss: 2.0354305057115454

Epoch: 5| Step: 3
Training loss: 2.7063307762145996
Validation loss: 2.014297245651163

Epoch: 5| Step: 4
Training loss: 2.524073362350464
Validation loss: 2.015543732591855

Epoch: 5| Step: 5
Training loss: 1.7282578945159912
Validation loss: 2.028548744417006

Epoch: 5| Step: 6
Training loss: 2.183755397796631
Validation loss: 2.0254237818461593

Epoch: 5| Step: 7
Training loss: 2.3346962928771973
Validation loss: 2.017346878205576

Epoch: 5| Step: 8
Training loss: 2.372687816619873
Validation loss: 2.0240184286589264

Epoch: 5| Step: 9
Training loss: 1.9092075824737549
Validation loss: 2.0204823363211846

Epoch: 5| Step: 10
Training loss: 2.5351991653442383
Validation loss: 2.026714112168999

Epoch: 55| Step: 0
Training loss: 2.2333312034606934
Validation loss: 2.0338984971405356

Epoch: 5| Step: 1
Training loss: 2.613680601119995
Validation loss: 2.0373311247876895

Epoch: 5| Step: 2
Training loss: 1.7946542501449585
Validation loss: 2.031431510884275

Epoch: 5| Step: 3
Training loss: 2.2133097648620605
Validation loss: 2.0217621454628567

Epoch: 5| Step: 4
Training loss: 2.422868251800537
Validation loss: 2.001213394185548

Epoch: 5| Step: 5
Training loss: 2.1420810222625732
Validation loss: 2.0170929252460437

Epoch: 5| Step: 6
Training loss: 2.52459979057312
Validation loss: 2.014358465389539

Epoch: 5| Step: 7
Training loss: 2.6625189781188965
Validation loss: 2.013283730835043

Epoch: 5| Step: 8
Training loss: 2.963209867477417
Validation loss: 2.0211782814354025

Epoch: 5| Step: 9
Training loss: 1.9192396402359009
Validation loss: 2.0184543030236357

Epoch: 5| Step: 10
Training loss: 2.012781858444214
Validation loss: 2.017940082857686

Epoch: 56| Step: 0
Training loss: 2.671131134033203
Validation loss: 2.014896228749265

Epoch: 5| Step: 1
Training loss: 2.5361294746398926
Validation loss: 2.01014014597862

Epoch: 5| Step: 2
Training loss: 2.1969285011291504
Validation loss: 2.0194070390475694

Epoch: 5| Step: 3
Training loss: 2.4219462871551514
Validation loss: 2.0162148526919785

Epoch: 5| Step: 4
Training loss: 2.343447208404541
Validation loss: 2.0138950129990936

Epoch: 5| Step: 5
Training loss: 2.0196480751037598
Validation loss: 2.0112491807629986

Epoch: 5| Step: 6
Training loss: 2.797254800796509
Validation loss: 2.014016589810771

Epoch: 5| Step: 7
Training loss: 2.4613921642303467
Validation loss: 2.0119873682657876

Epoch: 5| Step: 8
Training loss: 2.05820894241333
Validation loss: 2.0234554377935265

Epoch: 5| Step: 9
Training loss: 1.9193317890167236
Validation loss: 2.015690172872236

Epoch: 5| Step: 10
Training loss: 2.1176109313964844
Validation loss: 2.0028453091139435

Epoch: 57| Step: 0
Training loss: 2.4892406463623047
Validation loss: 2.0094008420103338

Epoch: 5| Step: 1
Training loss: 2.0932607650756836
Validation loss: 2.015483840819328

Epoch: 5| Step: 2
Training loss: 2.277578353881836
Validation loss: 2.0177160232297835

Epoch: 5| Step: 3
Training loss: 1.6539262533187866
Validation loss: 2.0237291551405385

Epoch: 5| Step: 4
Training loss: 2.857086658477783
Validation loss: 2.023522061686362

Epoch: 5| Step: 5
Training loss: 2.1329779624938965
Validation loss: 2.011022303694038

Epoch: 5| Step: 6
Training loss: 2.2500221729278564
Validation loss: 2.021695352369739

Epoch: 5| Step: 7
Training loss: 2.747448682785034
Validation loss: 2.009475008133919

Epoch: 5| Step: 8
Training loss: 2.3068580627441406
Validation loss: 2.018078419470018

Epoch: 5| Step: 9
Training loss: 2.340853691101074
Validation loss: 2.0225830744671565

Epoch: 5| Step: 10
Training loss: 2.2418298721313477
Validation loss: 2.023356286428308

Epoch: 58| Step: 0
Training loss: 1.4591931104660034
Validation loss: 2.0089324956299155

Epoch: 5| Step: 1
Training loss: 1.6152807474136353
Validation loss: 2.012044027287473

Epoch: 5| Step: 2
Training loss: 2.712925672531128
Validation loss: 2.0042314285873086

Epoch: 5| Step: 3
Training loss: 3.0295119285583496
Validation loss: 2.013151787942456

Epoch: 5| Step: 4
Training loss: 2.392152786254883
Validation loss: 2.0041477013659734

Epoch: 5| Step: 5
Training loss: 2.546607255935669
Validation loss: 1.999712400538947

Epoch: 5| Step: 6
Training loss: 2.3707566261291504
Validation loss: 1.9890985988801526

Epoch: 5| Step: 7
Training loss: 2.557061195373535
Validation loss: 2.016757890742312

Epoch: 5| Step: 8
Training loss: 1.9199247360229492
Validation loss: 2.0056741852914133

Epoch: 5| Step: 9
Training loss: 2.3357882499694824
Validation loss: 2.02181363362138

Epoch: 5| Step: 10
Training loss: 2.4910311698913574
Validation loss: 2.01107810261429

Epoch: 59| Step: 0
Training loss: 2.146238327026367
Validation loss: 2.0026263780491327

Epoch: 5| Step: 1
Training loss: 2.4780006408691406
Validation loss: 1.9957419826138405

Epoch: 5| Step: 2
Training loss: 2.147726535797119
Validation loss: 2.0049421351443053

Epoch: 5| Step: 3
Training loss: 2.232783079147339
Validation loss: 1.9991243782863821

Epoch: 5| Step: 4
Training loss: 2.257953405380249
Validation loss: 2.0174099514561314

Epoch: 5| Step: 5
Training loss: 2.4926133155822754
Validation loss: 2.012908012636246

Epoch: 5| Step: 6
Training loss: 2.1586403846740723
Validation loss: 1.9920763764330136

Epoch: 5| Step: 7
Training loss: 2.290803909301758
Validation loss: 2.00382831276104

Epoch: 5| Step: 8
Training loss: 2.239825487136841
Validation loss: 2.0066770738170994

Epoch: 5| Step: 9
Training loss: 2.1274290084838867
Validation loss: 2.0098327949482906

Epoch: 5| Step: 10
Training loss: 2.864821672439575
Validation loss: 2.007264937123945

Epoch: 60| Step: 0
Training loss: 2.18829083442688
Validation loss: 2.0059859932109876

Epoch: 5| Step: 1
Training loss: 1.7435659170150757
Validation loss: 2.0261548693462084

Epoch: 5| Step: 2
Training loss: 2.3550338745117188
Validation loss: 2.0251741857938867

Epoch: 5| Step: 3
Training loss: 2.324641466140747
Validation loss: 1.9899957551751086

Epoch: 5| Step: 4
Training loss: 2.5645930767059326
Validation loss: 2.0092539082291307

Epoch: 5| Step: 5
Training loss: 2.199317455291748
Validation loss: 2.008786948778296

Epoch: 5| Step: 6
Training loss: 3.4360973834991455
Validation loss: 2.004144476306054

Epoch: 5| Step: 7
Training loss: 2.2949087619781494
Validation loss: 2.0023572573097805

Epoch: 5| Step: 8
Training loss: 2.383762836456299
Validation loss: 2.0004449095777286

Epoch: 5| Step: 9
Training loss: 1.6999679803848267
Validation loss: 1.9988444979472826

Epoch: 5| Step: 10
Training loss: 2.1050055027008057
Validation loss: 2.000707548151734

Epoch: 61| Step: 0
Training loss: 2.4738659858703613
Validation loss: 1.984201902984291

Epoch: 5| Step: 1
Training loss: 2.193866014480591
Validation loss: 1.9921973546346028

Epoch: 5| Step: 2
Training loss: 1.9145656824111938
Validation loss: 2.0049616854677916

Epoch: 5| Step: 3
Training loss: 2.699728488922119
Validation loss: 1.9989648506205568

Epoch: 5| Step: 4
Training loss: 2.235793113708496
Validation loss: 1.9963816699161325

Epoch: 5| Step: 5
Training loss: 2.3659067153930664
Validation loss: 2.0064121830847954

Epoch: 5| Step: 6
Training loss: 2.1711103916168213
Validation loss: 2.0010475753456034

Epoch: 5| Step: 7
Training loss: 2.671743631362915
Validation loss: 1.9908977759781705

Epoch: 5| Step: 8
Training loss: 2.1060023307800293
Validation loss: 1.9947790932911698

Epoch: 5| Step: 9
Training loss: 1.9734718799591064
Validation loss: 2.005531954508956

Epoch: 5| Step: 10
Training loss: 2.521780014038086
Validation loss: 2.006774817743609

Epoch: 62| Step: 0
Training loss: 1.9370660781860352
Validation loss: 1.9873927152285011

Epoch: 5| Step: 1
Training loss: 2.0566940307617188
Validation loss: 1.9936880962823027

Epoch: 5| Step: 2
Training loss: 2.272367238998413
Validation loss: 1.9894620346766647

Epoch: 5| Step: 3
Training loss: 2.2616801261901855
Validation loss: 1.9787836485011603

Epoch: 5| Step: 4
Training loss: 2.637199640274048
Validation loss: 1.9726553527257775

Epoch: 5| Step: 5
Training loss: 2.705571174621582
Validation loss: 1.9931083340798654

Epoch: 5| Step: 6
Training loss: 2.07940411567688
Validation loss: 1.9898612345418623

Epoch: 5| Step: 7
Training loss: 2.309847354888916
Validation loss: 1.9880276162137267

Epoch: 5| Step: 8
Training loss: 2.3971588611602783
Validation loss: 1.9978643796777213

Epoch: 5| Step: 9
Training loss: 2.3195900917053223
Validation loss: 1.989892513521256

Epoch: 5| Step: 10
Training loss: 2.258476734161377
Validation loss: 2.004535298193655

Epoch: 63| Step: 0
Training loss: 2.0394721031188965
Validation loss: 1.9923608764525382

Epoch: 5| Step: 1
Training loss: 2.488675832748413
Validation loss: 1.994671885685254

Epoch: 5| Step: 2
Training loss: 2.3225667476654053
Validation loss: 1.9897203368525351

Epoch: 5| Step: 3
Training loss: 1.7588624954223633
Validation loss: 1.9847983698691092

Epoch: 5| Step: 4
Training loss: 2.019721508026123
Validation loss: 1.9985836039307296

Epoch: 5| Step: 5
Training loss: 2.244863986968994
Validation loss: 1.9794656461285007

Epoch: 5| Step: 6
Training loss: 2.734384536743164
Validation loss: 1.9821580789422477

Epoch: 5| Step: 7
Training loss: 2.4110023975372314
Validation loss: 1.9914222635248655

Epoch: 5| Step: 8
Training loss: 2.240935802459717
Validation loss: 1.981721721669679

Epoch: 5| Step: 9
Training loss: 2.5202386379241943
Validation loss: 1.971996743191955

Epoch: 5| Step: 10
Training loss: 2.4402201175689697
Validation loss: 1.9920839237910446

Epoch: 64| Step: 0
Training loss: 2.390873432159424
Validation loss: 1.9845443592276624

Epoch: 5| Step: 1
Training loss: 2.0777816772460938
Validation loss: 1.973774899718582

Epoch: 5| Step: 2
Training loss: 2.317988872528076
Validation loss: 1.9939205133786766

Epoch: 5| Step: 3
Training loss: 2.4692797660827637
Validation loss: 1.9684323726161834

Epoch: 5| Step: 4
Training loss: 2.372692584991455
Validation loss: 1.9683188789634294

Epoch: 5| Step: 5
Training loss: 2.2252135276794434
Validation loss: 1.966711982603996

Epoch: 5| Step: 6
Training loss: 2.53460431098938
Validation loss: 1.9635350242737801

Epoch: 5| Step: 7
Training loss: 2.0976078510284424
Validation loss: 1.9809302155689528

Epoch: 5| Step: 8
Training loss: 2.214254856109619
Validation loss: 1.9799949866469189

Epoch: 5| Step: 9
Training loss: 2.1952872276306152
Validation loss: 1.9813632747178436

Epoch: 5| Step: 10
Training loss: 2.27980899810791
Validation loss: 1.974461035061908

Epoch: 65| Step: 0
Training loss: 2.4118270874023438
Validation loss: 1.9735836469998924

Epoch: 5| Step: 1
Training loss: 2.634476900100708
Validation loss: 1.977339930431817

Epoch: 5| Step: 2
Training loss: 2.411256790161133
Validation loss: 1.9850290821444603

Epoch: 5| Step: 3
Training loss: 2.5223193168640137
Validation loss: 1.9672305545499247

Epoch: 5| Step: 4
Training loss: 2.5560197830200195
Validation loss: 1.9725901452443932

Epoch: 5| Step: 5
Training loss: 1.7153873443603516
Validation loss: 1.974105313260068

Epoch: 5| Step: 6
Training loss: 2.3200771808624268
Validation loss: 1.9785444557025869

Epoch: 5| Step: 7
Training loss: 1.8610420227050781
Validation loss: 1.972251348598029

Epoch: 5| Step: 8
Training loss: 1.935297966003418
Validation loss: 1.971049121631089

Epoch: 5| Step: 9
Training loss: 2.429466724395752
Validation loss: 1.9852110416658464

Epoch: 5| Step: 10
Training loss: 2.319237232208252
Validation loss: 1.978121554979714

Epoch: 66| Step: 0
Training loss: 2.38618803024292
Validation loss: 1.9786058292594007

Epoch: 5| Step: 1
Training loss: 2.0563228130340576
Validation loss: 1.964343656775772

Epoch: 5| Step: 2
Training loss: 2.156524658203125
Validation loss: 1.9812624505771104

Epoch: 5| Step: 3
Training loss: 1.8887836933135986
Validation loss: 1.9834170162036855

Epoch: 5| Step: 4
Training loss: 1.978960633277893
Validation loss: 1.9778294358202206

Epoch: 5| Step: 5
Training loss: 2.696845769882202
Validation loss: 1.980575523068828

Epoch: 5| Step: 6
Training loss: 2.0754032135009766
Validation loss: 1.9794433116912842

Epoch: 5| Step: 7
Training loss: 2.3962507247924805
Validation loss: 1.9770764894382928

Epoch: 5| Step: 8
Training loss: 1.8648045063018799
Validation loss: 1.9811170613893898

Epoch: 5| Step: 9
Training loss: 2.602954387664795
Validation loss: 1.9801819324493408

Epoch: 5| Step: 10
Training loss: 2.9767069816589355
Validation loss: 1.9793156872513473

Epoch: 67| Step: 0
Training loss: 1.8912265300750732
Validation loss: 1.9590800564776185

Epoch: 5| Step: 1
Training loss: 3.008219003677368
Validation loss: 1.9573429323011828

Epoch: 5| Step: 2
Training loss: 1.675264596939087
Validation loss: 1.9664454152507167

Epoch: 5| Step: 3
Training loss: 2.24796199798584
Validation loss: 1.9635513841464955

Epoch: 5| Step: 4
Training loss: 2.128098726272583
Validation loss: 1.975413817231373

Epoch: 5| Step: 5
Training loss: 2.402775287628174
Validation loss: 1.9752676563878213

Epoch: 5| Step: 6
Training loss: 2.265393018722534
Validation loss: 1.962395110437947

Epoch: 5| Step: 7
Training loss: 2.492661714553833
Validation loss: 1.9665289412262619

Epoch: 5| Step: 8
Training loss: 2.1727864742279053
Validation loss: 1.9812180226848972

Epoch: 5| Step: 9
Training loss: 2.8037302494049072
Validation loss: 1.9675314195694462

Epoch: 5| Step: 10
Training loss: 1.8052475452423096
Validation loss: 1.9772055225987588

Epoch: 68| Step: 0
Training loss: 2.2645695209503174
Validation loss: 1.9682067414765716

Epoch: 5| Step: 1
Training loss: 2.346644878387451
Validation loss: 1.9822692512184061

Epoch: 5| Step: 2
Training loss: 2.15828275680542
Validation loss: 1.960534554655834

Epoch: 5| Step: 3
Training loss: 1.9180774688720703
Validation loss: 1.9671832835802467

Epoch: 5| Step: 4
Training loss: 2.113551378250122
Validation loss: 1.973504791977585

Epoch: 5| Step: 5
Training loss: 2.4604411125183105
Validation loss: 1.959628032099816

Epoch: 5| Step: 6
Training loss: 2.412191390991211
Validation loss: 1.9469397093660088

Epoch: 5| Step: 7
Training loss: 2.1729929447174072
Validation loss: 1.9726727624093332

Epoch: 5| Step: 8
Training loss: 2.8969566822052
Validation loss: 1.9458529103186823

Epoch: 5| Step: 9
Training loss: 2.0966644287109375
Validation loss: 1.9623291774462628

Epoch: 5| Step: 10
Training loss: 2.054426908493042
Validation loss: 1.941406507645884

Epoch: 69| Step: 0
Training loss: 1.778240442276001
Validation loss: 1.9648397045750772

Epoch: 5| Step: 1
Training loss: 2.5039262771606445
Validation loss: 1.9594883149670017

Epoch: 5| Step: 2
Training loss: 2.0138792991638184
Validation loss: 1.9429295665474349

Epoch: 5| Step: 3
Training loss: 2.477698564529419
Validation loss: 1.978116435389365

Epoch: 5| Step: 4
Training loss: 2.5287883281707764
Validation loss: 1.9559199028117682

Epoch: 5| Step: 5
Training loss: 2.4150307178497314
Validation loss: 1.961366807260821

Epoch: 5| Step: 6
Training loss: 2.29896879196167
Validation loss: 1.966475817465013

Epoch: 5| Step: 7
Training loss: 2.126429319381714
Validation loss: 1.9658929404392038

Epoch: 5| Step: 8
Training loss: 2.2159910202026367
Validation loss: 1.9600509776864001

Epoch: 5| Step: 9
Training loss: 2.0654616355895996
Validation loss: 1.9637737389533751

Epoch: 5| Step: 10
Training loss: 2.5609607696533203
Validation loss: 1.9431768078957834

Epoch: 70| Step: 0
Training loss: 2.195822238922119
Validation loss: 1.9609494927108928

Epoch: 5| Step: 1
Training loss: 2.184248208999634
Validation loss: 1.9657280727099347

Epoch: 5| Step: 2
Training loss: 3.0128121376037598
Validation loss: 1.952154024954765

Epoch: 5| Step: 3
Training loss: 2.0589046478271484
Validation loss: 1.9564479935553767

Epoch: 5| Step: 4
Training loss: 1.675315260887146
Validation loss: 1.9640857417096373

Epoch: 5| Step: 5
Training loss: 2.262540578842163
Validation loss: 1.9612745033797396

Epoch: 5| Step: 6
Training loss: 2.136782169342041
Validation loss: 1.9763079817577074

Epoch: 5| Step: 7
Training loss: 1.9881242513656616
Validation loss: 1.9384852391417309

Epoch: 5| Step: 8
Training loss: 2.2901368141174316
Validation loss: 1.9683449242704658

Epoch: 5| Step: 9
Training loss: 2.778010845184326
Validation loss: 1.9752997429140153

Epoch: 5| Step: 10
Training loss: 2.38466739654541
Validation loss: 1.9693622666020547

Epoch: 71| Step: 0
Training loss: 2.8351473808288574
Validation loss: 1.9803674605584913

Epoch: 5| Step: 1
Training loss: 2.5017685890197754
Validation loss: 1.9631397172968874

Epoch: 5| Step: 2
Training loss: 3.2753586769104004
Validation loss: 1.956872211989536

Epoch: 5| Step: 3
Training loss: 2.6562671661376953
Validation loss: 1.9700030216606714

Epoch: 5| Step: 4
Training loss: 1.8168442249298096
Validation loss: 1.979485842489427

Epoch: 5| Step: 5
Training loss: 1.731652855873108
Validation loss: 1.965707484111991

Epoch: 5| Step: 6
Training loss: 2.104501724243164
Validation loss: 1.9674016493622974

Epoch: 5| Step: 7
Training loss: 1.804731011390686
Validation loss: 1.9718684150326637

Epoch: 5| Step: 8
Training loss: 2.3397083282470703
Validation loss: 1.9748877504820466

Epoch: 5| Step: 9
Training loss: 2.1529831886291504
Validation loss: 1.9756407225003807

Epoch: 5| Step: 10
Training loss: 1.6368919610977173
Validation loss: 1.9675301915855818

Epoch: 72| Step: 0
Training loss: 2.5145323276519775
Validation loss: 1.9487690925598145

Epoch: 5| Step: 1
Training loss: 2.3663268089294434
Validation loss: 1.9703686634699504

Epoch: 5| Step: 2
Training loss: 2.4155468940734863
Validation loss: 1.9664799167263893

Epoch: 5| Step: 3
Training loss: 1.9058315753936768
Validation loss: 1.9752201393086424

Epoch: 5| Step: 4
Training loss: 1.7887332439422607
Validation loss: 1.9812130389675018

Epoch: 5| Step: 5
Training loss: 2.2277495861053467
Validation loss: 1.9593041955783803

Epoch: 5| Step: 6
Training loss: 3.052394390106201
Validation loss: 1.9553720566534227

Epoch: 5| Step: 7
Training loss: 1.9561065435409546
Validation loss: 1.9723514869648924

Epoch: 5| Step: 8
Training loss: 2.6171793937683105
Validation loss: 1.9577303676195041

Epoch: 5| Step: 9
Training loss: 2.152777671813965
Validation loss: 1.959080921706333

Epoch: 5| Step: 10
Training loss: 1.7559608221054077
Validation loss: 1.9748524773505427

Epoch: 73| Step: 0
Training loss: 2.1227080821990967
Validation loss: 1.956005116944672

Epoch: 5| Step: 1
Training loss: 2.125093698501587
Validation loss: 1.9711508212550994

Epoch: 5| Step: 2
Training loss: 2.173060894012451
Validation loss: 1.975642773412889

Epoch: 5| Step: 3
Training loss: 2.1511008739471436
Validation loss: 1.9468107825966292

Epoch: 5| Step: 4
Training loss: 2.791107654571533
Validation loss: 1.9648742342507968

Epoch: 5| Step: 5
Training loss: 2.1766979694366455
Validation loss: 1.9632387289436914

Epoch: 5| Step: 6
Training loss: 2.104829788208008
Validation loss: 1.9536960009605653

Epoch: 5| Step: 7
Training loss: 2.4840903282165527
Validation loss: 1.9724518675957956

Epoch: 5| Step: 8
Training loss: 2.5272889137268066
Validation loss: 1.9784974282787693

Epoch: 5| Step: 9
Training loss: 2.217874050140381
Validation loss: 1.9732671386452132

Epoch: 5| Step: 10
Training loss: 1.9658712148666382
Validation loss: 1.9483451394624607

Epoch: 74| Step: 0
Training loss: 1.9918476343154907
Validation loss: 1.9670849128436017

Epoch: 5| Step: 1
Training loss: 2.7605979442596436
Validation loss: 1.9641055419880857

Epoch: 5| Step: 2
Training loss: 2.217005729675293
Validation loss: 1.9699926632706837

Epoch: 5| Step: 3
Training loss: 2.1978752613067627
Validation loss: 1.9703745060069586

Epoch: 5| Step: 4
Training loss: 2.4709866046905518
Validation loss: 1.9495493878600418

Epoch: 5| Step: 5
Training loss: 2.269317626953125
Validation loss: 1.9480056352512811

Epoch: 5| Step: 6
Training loss: 1.764411211013794
Validation loss: 1.9510373466758317

Epoch: 5| Step: 7
Training loss: 2.4649600982666016
Validation loss: 1.9413472708835398

Epoch: 5| Step: 8
Training loss: 2.235717296600342
Validation loss: 1.9616120887059036

Epoch: 5| Step: 9
Training loss: 2.272773504257202
Validation loss: 1.9584043282334522

Epoch: 5| Step: 10
Training loss: 2.144942045211792
Validation loss: 1.9324880107756583

Epoch: 75| Step: 0
Training loss: 2.0452656745910645
Validation loss: 1.9566978049534622

Epoch: 5| Step: 1
Training loss: 2.7753841876983643
Validation loss: 1.9647986376157371

Epoch: 5| Step: 2
Training loss: 2.4303646087646484
Validation loss: 1.9363464206777594

Epoch: 5| Step: 3
Training loss: 1.7577266693115234
Validation loss: 1.9565121948078115

Epoch: 5| Step: 4
Training loss: 2.5798733234405518
Validation loss: 1.9440380975764284

Epoch: 5| Step: 5
Training loss: 2.7012736797332764
Validation loss: 1.9519884406879384

Epoch: 5| Step: 6
Training loss: 2.5104687213897705
Validation loss: 1.950657036996657

Epoch: 5| Step: 7
Training loss: 1.5650068521499634
Validation loss: 1.954134879573699

Epoch: 5| Step: 8
Training loss: 2.0277411937713623
Validation loss: 1.9470908372632918

Epoch: 5| Step: 9
Training loss: 2.317772626876831
Validation loss: 1.9367708890668807

Epoch: 5| Step: 10
Training loss: 1.9829119443893433
Validation loss: 1.9541625566379999

Epoch: 76| Step: 0
Training loss: 2.014601469039917
Validation loss: 1.974466787871494

Epoch: 5| Step: 1
Training loss: 2.501678705215454
Validation loss: 1.9386270071870537

Epoch: 5| Step: 2
Training loss: 2.749068021774292
Validation loss: 1.949187736357412

Epoch: 5| Step: 3
Training loss: 1.9608707427978516
Validation loss: 1.9466396275387015

Epoch: 5| Step: 4
Training loss: 1.9632947444915771
Validation loss: 1.9673954107428109

Epoch: 5| Step: 5
Training loss: 2.3234028816223145
Validation loss: 1.9433601005102998

Epoch: 5| Step: 6
Training loss: 1.8643808364868164
Validation loss: 1.9421752639996108

Epoch: 5| Step: 7
Training loss: 2.935906171798706
Validation loss: 1.9505278102813228

Epoch: 5| Step: 8
Training loss: 1.785470724105835
Validation loss: 1.9526092967679423

Epoch: 5| Step: 9
Training loss: 2.611398458480835
Validation loss: 1.9473365506818217

Epoch: 5| Step: 10
Training loss: 2.048065185546875
Validation loss: 1.9504672147894417

Epoch: 77| Step: 0
Training loss: 2.4319496154785156
Validation loss: 1.9511321103701027

Epoch: 5| Step: 1
Training loss: 2.413067102432251
Validation loss: 1.9574071925173524

Epoch: 5| Step: 2
Training loss: 2.0144381523132324
Validation loss: 1.965948885486972

Epoch: 5| Step: 3
Training loss: 2.3733575344085693
Validation loss: 1.9577530378936439

Epoch: 5| Step: 4
Training loss: 2.113607168197632
Validation loss: 1.9581064319097867

Epoch: 5| Step: 5
Training loss: 2.478269100189209
Validation loss: 1.9641939440081198

Epoch: 5| Step: 6
Training loss: 1.9135490655899048
Validation loss: 1.9630809868535688

Epoch: 5| Step: 7
Training loss: 2.4396746158599854
Validation loss: 1.9698977624216387

Epoch: 5| Step: 8
Training loss: 1.8738266229629517
Validation loss: 1.9686675263989357

Epoch: 5| Step: 9
Training loss: 2.351656436920166
Validation loss: 1.969427239510321

Epoch: 5| Step: 10
Training loss: 2.4148051738739014
Validation loss: 1.9632527418034051

Epoch: 78| Step: 0
Training loss: 2.9996049404144287
Validation loss: 1.962007467464734

Epoch: 5| Step: 1
Training loss: 2.0962533950805664
Validation loss: 1.9796360154305734

Epoch: 5| Step: 2
Training loss: 2.3164546489715576
Validation loss: 1.9663168538001277

Epoch: 5| Step: 3
Training loss: 2.157722234725952
Validation loss: 1.9463782579668107

Epoch: 5| Step: 4
Training loss: 1.7745487689971924
Validation loss: 1.9675052447985577

Epoch: 5| Step: 5
Training loss: 2.6399166584014893
Validation loss: 1.955971715270832

Epoch: 5| Step: 6
Training loss: 2.483166217803955
Validation loss: 1.9565637214209444

Epoch: 5| Step: 7
Training loss: 2.024688243865967
Validation loss: 1.9635964209033596

Epoch: 5| Step: 8
Training loss: 1.8259334564208984
Validation loss: 1.9398571060549827

Epoch: 5| Step: 9
Training loss: 2.241349458694458
Validation loss: 1.955807247469502

Epoch: 5| Step: 10
Training loss: 2.285104513168335
Validation loss: 1.9533366516072264

Epoch: 79| Step: 0
Training loss: 2.3235394954681396
Validation loss: 1.9539238099128968

Epoch: 5| Step: 1
Training loss: 2.3283419609069824
Validation loss: 1.9564206882189679

Epoch: 5| Step: 2
Training loss: 2.059582233428955
Validation loss: 1.9599157328246741

Epoch: 5| Step: 3
Training loss: 2.258466958999634
Validation loss: 1.965510586256622

Epoch: 5| Step: 4
Training loss: 2.408102035522461
Validation loss: 1.9586246013641357

Epoch: 5| Step: 5
Training loss: 2.2967123985290527
Validation loss: 1.9664084860073623

Epoch: 5| Step: 6
Training loss: 2.0142252445220947
Validation loss: 1.959225502065433

Epoch: 5| Step: 7
Training loss: 2.631258487701416
Validation loss: 1.9717521423934607

Epoch: 5| Step: 8
Training loss: 1.7161972522735596
Validation loss: 1.9721479018529255

Epoch: 5| Step: 9
Training loss: 2.393542766571045
Validation loss: 1.9646327098210652

Epoch: 5| Step: 10
Training loss: 2.351308822631836
Validation loss: 1.9682854362713393

Epoch: 80| Step: 0
Training loss: 2.97428297996521
Validation loss: 1.9611641181412565

Epoch: 5| Step: 1
Training loss: 2.141472578048706
Validation loss: 1.975607588726987

Epoch: 5| Step: 2
Training loss: 2.4303536415100098
Validation loss: 1.9716038383463377

Epoch: 5| Step: 3
Training loss: 2.3292899131774902
Validation loss: 1.9828471881087109

Epoch: 5| Step: 4
Training loss: 1.9840524196624756
Validation loss: 1.9721074591400802

Epoch: 5| Step: 5
Training loss: 2.792001962661743
Validation loss: 1.966081614135414

Epoch: 5| Step: 6
Training loss: 2.3635337352752686
Validation loss: 1.9618299250961633

Epoch: 5| Step: 7
Training loss: 1.4173578023910522
Validation loss: 1.9580112887967018

Epoch: 5| Step: 8
Training loss: 1.7251415252685547
Validation loss: 1.9501846169912687

Epoch: 5| Step: 9
Training loss: 1.8734334707260132
Validation loss: 1.953407895180487

Epoch: 5| Step: 10
Training loss: 2.8976473808288574
Validation loss: 1.964518859822263

Epoch: 81| Step: 0
Training loss: 1.9199186563491821
Validation loss: 1.9627534984260477

Epoch: 5| Step: 1
Training loss: 2.3851630687713623
Validation loss: 1.9612660741293302

Epoch: 5| Step: 2
Training loss: 2.1476376056671143
Validation loss: 1.9662143761111843

Epoch: 5| Step: 3
Training loss: 2.7123589515686035
Validation loss: 1.9488242903063375

Epoch: 5| Step: 4
Training loss: 2.9896438121795654
Validation loss: 1.961157161702392

Epoch: 5| Step: 5
Training loss: 2.4221768379211426
Validation loss: 1.9741793563289027

Epoch: 5| Step: 6
Training loss: 2.105604648590088
Validation loss: 1.9669599174171366

Epoch: 5| Step: 7
Training loss: 1.5539531707763672
Validation loss: 1.9695084364183488

Epoch: 5| Step: 8
Training loss: 2.0958354473114014
Validation loss: 1.9534371283746534

Epoch: 5| Step: 9
Training loss: 1.9497039318084717
Validation loss: 1.9607084566547024

Epoch: 5| Step: 10
Training loss: 2.5171501636505127
Validation loss: 1.966445578041897

Epoch: 82| Step: 0
Training loss: 2.0998170375823975
Validation loss: 1.9679899190061836

Epoch: 5| Step: 1
Training loss: 2.6735622882843018
Validation loss: 1.980261186117767

Epoch: 5| Step: 2
Training loss: 1.6443322896957397
Validation loss: 1.9681181318016463

Epoch: 5| Step: 3
Training loss: 2.526872158050537
Validation loss: 1.9758159204195904

Epoch: 5| Step: 4
Training loss: 3.226311445236206
Validation loss: 1.945423892749253

Epoch: 5| Step: 5
Training loss: 1.8684501647949219
Validation loss: 1.9527951863504225

Epoch: 5| Step: 6
Training loss: 2.4890644550323486
Validation loss: 1.976359159715714

Epoch: 5| Step: 7
Training loss: 2.0488128662109375
Validation loss: 1.9723860884225497

Epoch: 5| Step: 8
Training loss: 1.9889640808105469
Validation loss: 1.963799048495549

Epoch: 5| Step: 9
Training loss: 2.141895294189453
Validation loss: 1.9749863070826377

Epoch: 5| Step: 10
Training loss: 1.8596460819244385
Validation loss: 1.9646633286629953

Epoch: 83| Step: 0
Training loss: 2.5421042442321777
Validation loss: 1.958295581161335

Epoch: 5| Step: 1
Training loss: 1.3690125942230225
Validation loss: 1.955311595752675

Epoch: 5| Step: 2
Training loss: 2.813302993774414
Validation loss: 1.9680371681849163

Epoch: 5| Step: 3
Training loss: 2.589900255203247
Validation loss: 1.9552628865806005

Epoch: 5| Step: 4
Training loss: 2.330509901046753
Validation loss: 1.9539947740493282

Epoch: 5| Step: 5
Training loss: 2.6784937381744385
Validation loss: 1.9710272665946715

Epoch: 5| Step: 6
Training loss: 1.7343776226043701
Validation loss: 1.968598614456833

Epoch: 5| Step: 7
Training loss: 2.3620822429656982
Validation loss: 1.9831816496387604

Epoch: 5| Step: 8
Training loss: 1.691040277481079
Validation loss: 1.9644649592779015

Epoch: 5| Step: 9
Training loss: 2.0361762046813965
Validation loss: 1.9667306330896193

Epoch: 5| Step: 10
Training loss: 2.3152403831481934
Validation loss: 1.9598073638895506

Epoch: 84| Step: 0
Training loss: 2.3831074237823486
Validation loss: 1.961156678456132

Epoch: 5| Step: 1
Training loss: 2.117220401763916
Validation loss: 1.9712378722365185

Epoch: 5| Step: 2
Training loss: 2.046562671661377
Validation loss: 1.9591247163793093

Epoch: 5| Step: 3
Training loss: 2.690598249435425
Validation loss: 1.9721080372410436

Epoch: 5| Step: 4
Training loss: 2.6085166931152344
Validation loss: 1.9754641350879465

Epoch: 5| Step: 5
Training loss: 2.0580506324768066
Validation loss: 1.962892287520952

Epoch: 5| Step: 6
Training loss: 1.981473684310913
Validation loss: 1.964666989541823

Epoch: 5| Step: 7
Training loss: 2.0811142921447754
Validation loss: 1.9790830394273162

Epoch: 5| Step: 8
Training loss: 1.8867161273956299
Validation loss: 1.9729687936844365

Epoch: 5| Step: 9
Training loss: 2.5826947689056396
Validation loss: 1.9810643426833614

Epoch: 5| Step: 10
Training loss: 2.210636854171753
Validation loss: 1.9557015883025302

Epoch: 85| Step: 0
Training loss: 2.4754436016082764
Validation loss: 1.9613632476457985

Epoch: 5| Step: 1
Training loss: 1.8155133724212646
Validation loss: 1.9513208827664774

Epoch: 5| Step: 2
Training loss: 2.5310139656066895
Validation loss: 1.9616368983381538

Epoch: 5| Step: 3
Training loss: 1.700512170791626
Validation loss: 1.9630366371523948

Epoch: 5| Step: 4
Training loss: 2.3036892414093018
Validation loss: 1.9517019474378197

Epoch: 5| Step: 5
Training loss: 2.418898820877075
Validation loss: 1.9566198715599634

Epoch: 5| Step: 6
Training loss: 1.8105041980743408
Validation loss: 1.9665261596761725

Epoch: 5| Step: 7
Training loss: 2.2596144676208496
Validation loss: 1.9530786801409978

Epoch: 5| Step: 8
Training loss: 1.8332479000091553
Validation loss: 1.9488141408530615

Epoch: 5| Step: 9
Training loss: 3.114521026611328
Validation loss: 1.9538511307008806

Epoch: 5| Step: 10
Training loss: 2.3462467193603516
Validation loss: 1.9500314112632506

Epoch: 86| Step: 0
Training loss: 2.8894283771514893
Validation loss: 1.9418839357232536

Epoch: 5| Step: 1
Training loss: 1.941244125366211
Validation loss: 1.9754452961747364

Epoch: 5| Step: 2
Training loss: 2.233741283416748
Validation loss: 1.9497620162143503

Epoch: 5| Step: 3
Training loss: 1.867039680480957
Validation loss: 1.9355985221042429

Epoch: 5| Step: 4
Training loss: 2.6691935062408447
Validation loss: 1.9553759315962433

Epoch: 5| Step: 5
Training loss: 2.5540051460266113
Validation loss: 1.9399883593282392

Epoch: 5| Step: 6
Training loss: 2.2909648418426514
Validation loss: 1.959770018054593

Epoch: 5| Step: 7
Training loss: 2.354001522064209
Validation loss: 1.977819009493756

Epoch: 5| Step: 8
Training loss: 2.0701141357421875
Validation loss: 1.9611423746232064

Epoch: 5| Step: 9
Training loss: 1.4864780902862549
Validation loss: 1.9661567339333155

Epoch: 5| Step: 10
Training loss: 2.024688243865967
Validation loss: 1.9613531904835855

Epoch: 87| Step: 0
Training loss: 2.214942693710327
Validation loss: 1.9393952482490129

Epoch: 5| Step: 1
Training loss: 2.0691487789154053
Validation loss: 1.9542309084246237

Epoch: 5| Step: 2
Training loss: 1.6956040859222412
Validation loss: 1.9479988031489874

Epoch: 5| Step: 3
Training loss: 2.9616141319274902
Validation loss: 1.9590529113687494

Epoch: 5| Step: 4
Training loss: 2.537226438522339
Validation loss: 1.9312751741819485

Epoch: 5| Step: 5
Training loss: 1.9281126260757446
Validation loss: 1.9468630488200853

Epoch: 5| Step: 6
Training loss: 2.0292277336120605
Validation loss: 1.9610370769295642

Epoch: 5| Step: 7
Training loss: 2.796616315841675
Validation loss: 1.9348228029025498

Epoch: 5| Step: 8
Training loss: 2.116804599761963
Validation loss: 1.942387806471958

Epoch: 5| Step: 9
Training loss: 2.0118846893310547
Validation loss: 1.9541644588593514

Epoch: 5| Step: 10
Training loss: 2.1103169918060303
Validation loss: 1.951263968662549

Epoch: 88| Step: 0
Training loss: 2.251591444015503
Validation loss: 1.933160792114914

Epoch: 5| Step: 1
Training loss: 2.38059139251709
Validation loss: 1.9351423760896087

Epoch: 5| Step: 2
Training loss: 1.9428856372833252
Validation loss: 1.9501444011606195

Epoch: 5| Step: 3
Training loss: 2.284574270248413
Validation loss: 1.935649751335062

Epoch: 5| Step: 4
Training loss: 2.960191249847412
Validation loss: 1.9501792666732625

Epoch: 5| Step: 5
Training loss: 1.7424967288970947
Validation loss: 1.9477876053061536

Epoch: 5| Step: 6
Training loss: 1.8431117534637451
Validation loss: 1.9532232182000273

Epoch: 5| Step: 7
Training loss: 1.9798856973648071
Validation loss: 1.9555026908074655

Epoch: 5| Step: 8
Training loss: 2.366511583328247
Validation loss: 1.9628156167204662

Epoch: 5| Step: 9
Training loss: 2.4236927032470703
Validation loss: 1.9371291488729498

Epoch: 5| Step: 10
Training loss: 2.314631700515747
Validation loss: 1.9503545876472228

Epoch: 89| Step: 0
Training loss: 2.2576613426208496
Validation loss: 1.954770662451303

Epoch: 5| Step: 1
Training loss: 2.430035352706909
Validation loss: 1.9477461820007653

Epoch: 5| Step: 2
Training loss: 2.4994475841522217
Validation loss: 1.950444242005707

Epoch: 5| Step: 3
Training loss: 2.44350528717041
Validation loss: 1.9441199841037873

Epoch: 5| Step: 4
Training loss: 1.9280738830566406
Validation loss: 1.9383429711864841

Epoch: 5| Step: 5
Training loss: 2.100982189178467
Validation loss: 1.9380124897085211

Epoch: 5| Step: 6
Training loss: 2.7307326793670654
Validation loss: 1.9317047121704265

Epoch: 5| Step: 7
Training loss: 1.7082713842391968
Validation loss: 1.966325149741224

Epoch: 5| Step: 8
Training loss: 1.7226765155792236
Validation loss: 1.9340710793772051

Epoch: 5| Step: 9
Training loss: 2.2588844299316406
Validation loss: 1.9346515645263016

Epoch: 5| Step: 10
Training loss: 2.3639895915985107
Validation loss: 1.9469664173741494

Epoch: 90| Step: 0
Training loss: 2.8925185203552246
Validation loss: 1.948515768974058

Epoch: 5| Step: 1
Training loss: 2.6010115146636963
Validation loss: 1.95138979470858

Epoch: 5| Step: 2
Training loss: 1.5421741008758545
Validation loss: 1.9234402615536925

Epoch: 5| Step: 3
Training loss: 2.1593985557556152
Validation loss: 1.9417147213412869

Epoch: 5| Step: 4
Training loss: 1.4716334342956543
Validation loss: 1.9198847342562932

Epoch: 5| Step: 5
Training loss: 1.6647613048553467
Validation loss: 1.953653758571994

Epoch: 5| Step: 6
Training loss: 1.7439676523208618
Validation loss: 1.9512736656332528

Epoch: 5| Step: 7
Training loss: 2.4439196586608887
Validation loss: 1.9360186143587994

Epoch: 5| Step: 8
Training loss: 2.8547637462615967
Validation loss: 1.944300886123411

Epoch: 5| Step: 9
Training loss: 2.392127752304077
Validation loss: 1.9433836296040525

Epoch: 5| Step: 10
Training loss: 2.6213817596435547
Validation loss: 1.9304760156139251

Epoch: 91| Step: 0
Training loss: 2.2673091888427734
Validation loss: 1.9308367634332309

Epoch: 5| Step: 1
Training loss: 2.1198811531066895
Validation loss: 1.9387583296786073

Epoch: 5| Step: 2
Training loss: 2.1119980812072754
Validation loss: 1.932105355365302

Epoch: 5| Step: 3
Training loss: 2.1691136360168457
Validation loss: 1.9525581226553967

Epoch: 5| Step: 4
Training loss: 2.533287286758423
Validation loss: 1.9600454248407835

Epoch: 5| Step: 5
Training loss: 2.3351738452911377
Validation loss: 1.9475108115903792

Epoch: 5| Step: 6
Training loss: 2.135779857635498
Validation loss: 1.9495886807800622

Epoch: 5| Step: 7
Training loss: 2.26289701461792
Validation loss: 1.9633094456888014

Epoch: 5| Step: 8
Training loss: 1.9451345205307007
Validation loss: 1.9426699171784103

Epoch: 5| Step: 9
Training loss: 2.238917589187622
Validation loss: 1.9475228068649129

Epoch: 5| Step: 10
Training loss: 2.2763476371765137
Validation loss: 1.948683641290152

Epoch: 92| Step: 0
Training loss: 1.8104887008666992
Validation loss: 1.949859489676773

Epoch: 5| Step: 1
Training loss: 1.7524055242538452
Validation loss: 1.945684798302189

Epoch: 5| Step: 2
Training loss: 2.4136838912963867
Validation loss: 1.948073096172784

Epoch: 5| Step: 3
Training loss: 2.6153907775878906
Validation loss: 1.9493599809626097

Epoch: 5| Step: 4
Training loss: 2.228584051132202
Validation loss: 1.9521013985397995

Epoch: 5| Step: 5
Training loss: 2.2563841342926025
Validation loss: 1.9603721493033952

Epoch: 5| Step: 6
Training loss: 2.490220069885254
Validation loss: 1.9727382352275233

Epoch: 5| Step: 7
Training loss: 1.5284137725830078
Validation loss: 1.9562623423914756

Epoch: 5| Step: 8
Training loss: 2.494328260421753
Validation loss: 1.9441751433957009

Epoch: 5| Step: 9
Training loss: 2.3363752365112305
Validation loss: 1.9610833839703632

Epoch: 5| Step: 10
Training loss: 2.4871344566345215
Validation loss: 1.963374601897373

Epoch: 93| Step: 0
Training loss: 2.266153573989868
Validation loss: 1.9572697454883206

Epoch: 5| Step: 1
Training loss: 2.963921308517456
Validation loss: 1.9566729876302904

Epoch: 5| Step: 2
Training loss: 2.1007838249206543
Validation loss: 1.9476818602572206

Epoch: 5| Step: 3
Training loss: 1.6962013244628906
Validation loss: 1.9521500500299598

Epoch: 5| Step: 4
Training loss: 2.2089922428131104
Validation loss: 1.9598161417950866

Epoch: 5| Step: 5
Training loss: 2.6791539192199707
Validation loss: 1.9487932279545774

Epoch: 5| Step: 6
Training loss: 2.2151806354522705
Validation loss: 1.9782308455436461

Epoch: 5| Step: 7
Training loss: 1.9185035228729248
Validation loss: 1.9669241418120682

Epoch: 5| Step: 8
Training loss: 2.249286651611328
Validation loss: 1.9487266771255

Epoch: 5| Step: 9
Training loss: 1.8762630224227905
Validation loss: 1.970335554051143

Epoch: 5| Step: 10
Training loss: 2.170092821121216
Validation loss: 1.959230294791601

Epoch: 94| Step: 0
Training loss: 1.7735694646835327
Validation loss: 1.953057958233741

Epoch: 5| Step: 1
Training loss: 1.8184131383895874
Validation loss: 1.9551928722730247

Epoch: 5| Step: 2
Training loss: 2.9119935035705566
Validation loss: 1.9633417937063402

Epoch: 5| Step: 3
Training loss: 1.8188121318817139
Validation loss: 1.9622128189250987

Epoch: 5| Step: 4
Training loss: 2.3868796825408936
Validation loss: 1.9626603921254475

Epoch: 5| Step: 5
Training loss: 2.3904387950897217
Validation loss: 1.9715548638374574

Epoch: 5| Step: 6
Training loss: 1.934217095375061
Validation loss: 1.966249164714608

Epoch: 5| Step: 7
Training loss: 3.23078989982605
Validation loss: 1.9643748550004856

Epoch: 5| Step: 8
Training loss: 2.0443625450134277
Validation loss: 1.9537117045412782

Epoch: 5| Step: 9
Training loss: 2.3066911697387695
Validation loss: 1.9673406975243681

Epoch: 5| Step: 10
Training loss: 1.5310144424438477
Validation loss: 1.970725308182419

Epoch: 95| Step: 0
Training loss: 2.3587896823883057
Validation loss: 1.9555851336448424

Epoch: 5| Step: 1
Training loss: 2.1585538387298584
Validation loss: 1.9783469989735594

Epoch: 5| Step: 2
Training loss: 1.7134323120117188
Validation loss: 1.9599510969654206

Epoch: 5| Step: 3
Training loss: 1.9839187860488892
Validation loss: 1.9521133220323952

Epoch: 5| Step: 4
Training loss: 2.3311710357666016
Validation loss: 1.9661761932475592

Epoch: 5| Step: 5
Training loss: 2.2305848598480225
Validation loss: 1.9659462744189846

Epoch: 5| Step: 6
Training loss: 2.599788188934326
Validation loss: 1.9656024299642092

Epoch: 5| Step: 7
Training loss: 2.181058406829834
Validation loss: 1.9622198894459715

Epoch: 5| Step: 8
Training loss: 1.987058401107788
Validation loss: 1.9615935587113904

Epoch: 5| Step: 9
Training loss: 3.185067653656006
Validation loss: 1.9490646828887284

Epoch: 5| Step: 10
Training loss: 1.4309319257736206
Validation loss: 1.9555851336448424

Epoch: 96| Step: 0
Training loss: 1.83905827999115
Validation loss: 1.968239781677082

Epoch: 5| Step: 1
Training loss: 2.1795921325683594
Validation loss: 1.9508665710367181

Epoch: 5| Step: 2
Training loss: 2.811307191848755
Validation loss: 1.9599119373547134

Epoch: 5| Step: 3
Training loss: 2.183488368988037
Validation loss: 1.9757823892818984

Epoch: 5| Step: 4
Training loss: 2.3986575603485107
Validation loss: 1.9429364460770802

Epoch: 5| Step: 5
Training loss: 2.3036530017852783
Validation loss: 1.9549801657276769

Epoch: 5| Step: 6
Training loss: 2.1059725284576416
Validation loss: 1.9533033242789648

Epoch: 5| Step: 7
Training loss: 2.077444076538086
Validation loss: 1.9646876371035011

Epoch: 5| Step: 8
Training loss: 2.8373026847839355
Validation loss: 1.9585519900885962

Epoch: 5| Step: 9
Training loss: 1.9591630697250366
Validation loss: 1.9595217012589978

Epoch: 5| Step: 10
Training loss: 1.5376813411712646
Validation loss: 1.961900262422459

Epoch: 97| Step: 0
Training loss: 1.6877902746200562
Validation loss: 1.956471179121284

Epoch: 5| Step: 1
Training loss: 2.519462823867798
Validation loss: 1.941148219570037

Epoch: 5| Step: 2
Training loss: 2.8760464191436768
Validation loss: 1.945500345640285

Epoch: 5| Step: 3
Training loss: 2.847869396209717
Validation loss: 1.9445412082056845

Epoch: 5| Step: 4
Training loss: 2.031214952468872
Validation loss: 1.9657280060552782

Epoch: 5| Step: 5
Training loss: 1.9517786502838135
Validation loss: 1.9485656446026218

Epoch: 5| Step: 6
Training loss: 1.9019346237182617
Validation loss: 1.96557205723178

Epoch: 5| Step: 7
Training loss: 2.894880771636963
Validation loss: 1.9487008625461208

Epoch: 5| Step: 8
Training loss: 1.9973329305648804
Validation loss: 1.9638208227772866

Epoch: 5| Step: 9
Training loss: 1.8752800226211548
Validation loss: 1.9461419159366238

Epoch: 5| Step: 10
Training loss: 1.460699439048767
Validation loss: 1.9327968179538686

Epoch: 98| Step: 0
Training loss: 2.062699556350708
Validation loss: 1.9570319652557373

Epoch: 5| Step: 1
Training loss: 2.5618579387664795
Validation loss: 1.9422718991515457

Epoch: 5| Step: 2
Training loss: 2.0467183589935303
Validation loss: 1.936528290471723

Epoch: 5| Step: 3
Training loss: 2.163822650909424
Validation loss: 1.954556393366988

Epoch: 5| Step: 4
Training loss: 2.607236862182617
Validation loss: 1.962612481527431

Epoch: 5| Step: 5
Training loss: 3.312086582183838
Validation loss: 1.9511617998923025

Epoch: 5| Step: 6
Training loss: 1.3416374921798706
Validation loss: 1.956327639600282

Epoch: 5| Step: 7
Training loss: 1.480491280555725
Validation loss: 1.966676527454007

Epoch: 5| Step: 8
Training loss: 2.047524929046631
Validation loss: 1.9432271116523332

Epoch: 5| Step: 9
Training loss: 2.9428749084472656
Validation loss: 1.9749509365327897

Epoch: 5| Step: 10
Training loss: 1.643890619277954
Validation loss: 1.959799740904121

Epoch: 99| Step: 0
Training loss: 2.678745746612549
Validation loss: 1.966583712126619

Epoch: 5| Step: 1
Training loss: 2.834001302719116
Validation loss: 1.9592033124739123

Epoch: 5| Step: 2
Training loss: 2.0495011806488037
Validation loss: 1.9857918818791707

Epoch: 5| Step: 3
Training loss: 2.0518195629119873
Validation loss: 1.9776122903311124

Epoch: 5| Step: 4
Training loss: 2.2917118072509766
Validation loss: 1.9545277421192457

Epoch: 5| Step: 5
Training loss: 2.2900335788726807
Validation loss: 1.9661693214088358

Epoch: 5| Step: 6
Training loss: 1.7398532629013062
Validation loss: 1.9706288512035082

Epoch: 5| Step: 7
Training loss: 1.898343801498413
Validation loss: 1.9739317586345058

Epoch: 5| Step: 8
Training loss: 2.3171751499176025
Validation loss: 1.961360312277271

Epoch: 5| Step: 9
Training loss: 1.8730032444000244
Validation loss: 1.9751565200026318

Epoch: 5| Step: 10
Training loss: 2.2897541522979736
Validation loss: 1.9755831405680666

Epoch: 100| Step: 0
Training loss: 2.552689790725708
Validation loss: 1.9742174379287227

Epoch: 5| Step: 1
Training loss: 2.3103373050689697
Validation loss: 1.9620450773546774

Epoch: 5| Step: 2
Training loss: 1.6720974445343018
Validation loss: 1.966418186823527

Epoch: 5| Step: 3
Training loss: 1.5816062688827515
Validation loss: 1.9641361839027816

Epoch: 5| Step: 4
Training loss: 2.420729637145996
Validation loss: 1.9573984428118634

Epoch: 5| Step: 5
Training loss: 2.259235382080078
Validation loss: 1.9479729488331785

Epoch: 5| Step: 6
Training loss: 2.823129177093506
Validation loss: 1.9571205646761003

Epoch: 5| Step: 7
Training loss: 1.8274396657943726
Validation loss: 1.9780251877282256

Epoch: 5| Step: 8
Training loss: 2.1739726066589355
Validation loss: 1.9619998611429685

Epoch: 5| Step: 9
Training loss: 2.279284715652466
Validation loss: 1.9735026846649826

Epoch: 5| Step: 10
Training loss: 2.212195634841919
Validation loss: 1.9654561370931647

Epoch: 101| Step: 0
Training loss: 2.2744081020355225
Validation loss: 1.961809882553675

Epoch: 5| Step: 1
Training loss: 2.898128032684326
Validation loss: 1.950940050104613

Epoch: 5| Step: 2
Training loss: 2.3107168674468994
Validation loss: 1.973909479315563

Epoch: 5| Step: 3
Training loss: 2.2611544132232666
Validation loss: 1.9684604047447123

Epoch: 5| Step: 4
Training loss: 2.204040050506592
Validation loss: 1.9634067781509892

Epoch: 5| Step: 5
Training loss: 2.6057076454162598
Validation loss: 1.9767211842280563

Epoch: 5| Step: 6
Training loss: 1.8870594501495361
Validation loss: 1.9661672986963743

Epoch: 5| Step: 7
Training loss: 2.1366448402404785
Validation loss: 1.961057214326756

Epoch: 5| Step: 8
Training loss: 1.9893932342529297
Validation loss: 1.9682577194706086

Epoch: 5| Step: 9
Training loss: 1.8017208576202393
Validation loss: 1.9708375289875975

Epoch: 5| Step: 10
Training loss: 1.847988247871399
Validation loss: 1.9657030541409728

Epoch: 102| Step: 0
Training loss: 1.822324514389038
Validation loss: 1.9842795505318591

Epoch: 5| Step: 1
Training loss: 2.1594886779785156
Validation loss: 1.9602268754795034

Epoch: 5| Step: 2
Training loss: 2.6316540241241455
Validation loss: 1.9847918415582309

Epoch: 5| Step: 3
Training loss: 1.8963149785995483
Validation loss: 1.9806271060820548

Epoch: 5| Step: 4
Training loss: 2.073075771331787
Validation loss: 1.9686847835458734

Epoch: 5| Step: 5
Training loss: 2.455245018005371
Validation loss: 1.977201948883713

Epoch: 5| Step: 6
Training loss: 2.586308240890503
Validation loss: 1.9713223570136613

Epoch: 5| Step: 7
Training loss: 2.102414608001709
Validation loss: 1.9748168363366077

Epoch: 5| Step: 8
Training loss: 2.3024234771728516
Validation loss: 1.9921880358008928

Epoch: 5| Step: 9
Training loss: 1.9756065607070923
Validation loss: 1.9667356450070617

Epoch: 5| Step: 10
Training loss: 2.1829018592834473
Validation loss: 1.9561222612216909

Epoch: 103| Step: 0
Training loss: 2.398561954498291
Validation loss: 1.9782683926243936

Epoch: 5| Step: 1
Training loss: 2.064903736114502
Validation loss: 1.9478659706730996

Epoch: 5| Step: 2
Training loss: 2.248582124710083
Validation loss: 1.9603849867338776

Epoch: 5| Step: 3
Training loss: 2.4161393642425537
Validation loss: 1.9575067976469636

Epoch: 5| Step: 4
Training loss: 1.435302495956421
Validation loss: 1.974041570899307

Epoch: 5| Step: 5
Training loss: 2.201207399368286
Validation loss: 1.964833491591997

Epoch: 5| Step: 6
Training loss: 2.1476542949676514
Validation loss: 1.96007368897879

Epoch: 5| Step: 7
Training loss: 2.3020951747894287
Validation loss: 1.945428058665286

Epoch: 5| Step: 8
Training loss: 2.471787929534912
Validation loss: 1.9369708312455045

Epoch: 5| Step: 9
Training loss: 2.287740707397461
Validation loss: 1.9391382330207414

Epoch: 5| Step: 10
Training loss: 2.275498867034912
Validation loss: 1.9359240403739355

Epoch: 104| Step: 0
Training loss: 2.444406032562256
Validation loss: 1.9451621322221653

Epoch: 5| Step: 1
Training loss: 3.061915159225464
Validation loss: 1.94415016969045

Epoch: 5| Step: 2
Training loss: 2.2022643089294434
Validation loss: 1.9283692811125068

Epoch: 5| Step: 3
Training loss: 2.1028685569763184
Validation loss: 1.9408125736380135

Epoch: 5| Step: 4
Training loss: 2.27311372756958
Validation loss: 1.9519433577855427

Epoch: 5| Step: 5
Training loss: 1.6930773258209229
Validation loss: 1.9613356218543103

Epoch: 5| Step: 6
Training loss: 1.9552440643310547
Validation loss: 1.9452586802103187

Epoch: 5| Step: 7
Training loss: 2.1324353218078613
Validation loss: 1.957207764348676

Epoch: 5| Step: 8
Training loss: 2.2161622047424316
Validation loss: 1.9597810852912165

Epoch: 5| Step: 9
Training loss: 1.7675892114639282
Validation loss: 1.9524045080266974

Epoch: 5| Step: 10
Training loss: 2.3387577533721924
Validation loss: 1.9608184009469964

Epoch: 105| Step: 0
Training loss: 3.220289707183838
Validation loss: 1.9324670837771507

Epoch: 5| Step: 1
Training loss: 1.9661586284637451
Validation loss: 1.9533348378314768

Epoch: 5| Step: 2
Training loss: 2.2193655967712402
Validation loss: 1.9384586400883173

Epoch: 5| Step: 3
Training loss: 1.5340707302093506
Validation loss: 1.9571516360006025

Epoch: 5| Step: 4
Training loss: 2.1803205013275146
Validation loss: 1.9553583539942259

Epoch: 5| Step: 5
Training loss: 2.4036712646484375
Validation loss: 1.9481567887849705

Epoch: 5| Step: 6
Training loss: 2.2789387702941895
Validation loss: 1.951196277013389

Epoch: 5| Step: 7
Training loss: 2.1433770656585693
Validation loss: 1.966658652469676

Epoch: 5| Step: 8
Training loss: 1.7527672052383423
Validation loss: 1.9434505444701

Epoch: 5| Step: 9
Training loss: 2.2297210693359375
Validation loss: 1.9627297283500753

Epoch: 5| Step: 10
Training loss: 2.238252878189087
Validation loss: 1.933801092127318

Epoch: 106| Step: 0
Training loss: 2.5362510681152344
Validation loss: 1.953519413548131

Epoch: 5| Step: 1
Training loss: 2.229609727859497
Validation loss: 1.9595371625756706

Epoch: 5| Step: 2
Training loss: 2.063016414642334
Validation loss: 1.9529252424035022

Epoch: 5| Step: 3
Training loss: 2.2024357318878174
Validation loss: 1.95249040408801

Epoch: 5| Step: 4
Training loss: 3.054718494415283
Validation loss: 1.9400743745988416

Epoch: 5| Step: 5
Training loss: 1.4786345958709717
Validation loss: 1.94357547965101

Epoch: 5| Step: 6
Training loss: 1.9927676916122437
Validation loss: 1.9495862222486926

Epoch: 5| Step: 7
Training loss: 2.1729063987731934
Validation loss: 1.9458790030530704

Epoch: 5| Step: 8
Training loss: 2.0086562633514404
Validation loss: 1.9395178056532336

Epoch: 5| Step: 9
Training loss: 2.1185920238494873
Validation loss: 1.950867711856801

Epoch: 5| Step: 10
Training loss: 2.1422879695892334
Validation loss: 1.961840219395135

Epoch: 107| Step: 0
Training loss: 2.5359325408935547
Validation loss: 1.9459169744163431

Epoch: 5| Step: 1
Training loss: 2.125704765319824
Validation loss: 1.9482464687798613

Epoch: 5| Step: 2
Training loss: 1.9291661977767944
Validation loss: 1.9563358829867454

Epoch: 5| Step: 3
Training loss: 1.708433747291565
Validation loss: 1.961878832950387

Epoch: 5| Step: 4
Training loss: 2.1484591960906982
Validation loss: 1.953873142119377

Epoch: 5| Step: 5
Training loss: 2.4112887382507324
Validation loss: 1.949819198218725

Epoch: 5| Step: 6
Training loss: 2.02911376953125
Validation loss: 1.9711081622749247

Epoch: 5| Step: 7
Training loss: 2.190119743347168
Validation loss: 1.949435023851292

Epoch: 5| Step: 8
Training loss: 2.6413440704345703
Validation loss: 1.9571913032121555

Epoch: 5| Step: 9
Training loss: 2.3176581859588623
Validation loss: 1.947551041521052

Epoch: 5| Step: 10
Training loss: 2.0066094398498535
Validation loss: 1.9651984617274294

Epoch: 108| Step: 0
Training loss: 2.2831203937530518
Validation loss: 1.9627104689998012

Epoch: 5| Step: 1
Training loss: 2.2146859169006348
Validation loss: 1.958636140310636

Epoch: 5| Step: 2
Training loss: 2.3350741863250732
Validation loss: 1.9651178249748804

Epoch: 5| Step: 3
Training loss: 2.4875597953796387
Validation loss: 1.9541436433792114

Epoch: 5| Step: 4
Training loss: 1.968886137008667
Validation loss: 1.969031031413745

Epoch: 5| Step: 5
Training loss: 1.4530020952224731
Validation loss: 1.983784996053224

Epoch: 5| Step: 6
Training loss: 2.3410849571228027
Validation loss: 1.964183856082219

Epoch: 5| Step: 7
Training loss: 2.3592612743377686
Validation loss: 1.962054552570466

Epoch: 5| Step: 8
Training loss: 2.2416491508483887
Validation loss: 1.9822290302604757

Epoch: 5| Step: 9
Training loss: 1.8633325099945068
Validation loss: 1.959878049870973

Epoch: 5| Step: 10
Training loss: 2.6806023120880127
Validation loss: 1.9929010893708916

Epoch: 109| Step: 0
Training loss: 1.7970962524414062
Validation loss: 1.97507474243

Epoch: 5| Step: 1
Training loss: 2.2759292125701904
Validation loss: 1.9586899588184972

Epoch: 5| Step: 2
Training loss: 2.2969906330108643
Validation loss: 1.973585577421291

Epoch: 5| Step: 3
Training loss: 2.1861865520477295
Validation loss: 1.98138734345795

Epoch: 5| Step: 4
Training loss: 2.331880569458008
Validation loss: 1.989723959276753

Epoch: 5| Step: 5
Training loss: 2.5443248748779297
Validation loss: 1.9952792506064139

Epoch: 5| Step: 6
Training loss: 1.8354084491729736
Validation loss: 1.989181500609203

Epoch: 5| Step: 7
Training loss: 1.9202806949615479
Validation loss: 2.0079126101668163

Epoch: 5| Step: 8
Training loss: 2.63981294631958
Validation loss: 1.9826301618288922

Epoch: 5| Step: 9
Training loss: 2.13708758354187
Validation loss: 1.9921776184471705

Epoch: 5| Step: 10
Training loss: 2.048525333404541
Validation loss: 2.002153476079305

Epoch: 110| Step: 0
Training loss: 2.0821681022644043
Validation loss: 1.980613762332547

Epoch: 5| Step: 1
Training loss: 2.3573691844940186
Validation loss: 1.9747697204671881

Epoch: 5| Step: 2
Training loss: 1.9001801013946533
Validation loss: 1.9812005489103255

Epoch: 5| Step: 3
Training loss: 2.1875624656677246
Validation loss: 1.9870327377832064

Epoch: 5| Step: 4
Training loss: 3.255890369415283
Validation loss: 1.9848294591390958

Epoch: 5| Step: 5
Training loss: 2.101738929748535
Validation loss: 1.9720602061158867

Epoch: 5| Step: 6
Training loss: 1.653563141822815
Validation loss: 1.9712809644719607

Epoch: 5| Step: 7
Training loss: 2.335165500640869
Validation loss: 1.9690584034048102

Epoch: 5| Step: 8
Training loss: 1.9814567565917969
Validation loss: 1.973706860696116

Epoch: 5| Step: 9
Training loss: 2.135982036590576
Validation loss: 1.9713313784650577

Epoch: 5| Step: 10
Training loss: 2.21555757522583
Validation loss: 1.9585933050801676

Epoch: 111| Step: 0
Training loss: 2.0334746837615967
Validation loss: 1.9622810707297376

Epoch: 5| Step: 1
Training loss: 2.266040325164795
Validation loss: 1.9640660849950646

Epoch: 5| Step: 2
Training loss: 1.9819600582122803
Validation loss: 1.9443778222607029

Epoch: 5| Step: 3
Training loss: 2.0710628032684326
Validation loss: 1.9690133602388444

Epoch: 5| Step: 4
Training loss: 3.0404887199401855
Validation loss: 1.968796278840752

Epoch: 5| Step: 5
Training loss: 2.7035868167877197
Validation loss: 1.966242600512761

Epoch: 5| Step: 6
Training loss: 1.935124397277832
Validation loss: 1.9560119926288564

Epoch: 5| Step: 7
Training loss: 2.37898325920105
Validation loss: 1.964136726112776

Epoch: 5| Step: 8
Training loss: 2.088839292526245
Validation loss: 1.960607106967639

Epoch: 5| Step: 9
Training loss: 1.5623606443405151
Validation loss: 1.957287323090338

Epoch: 5| Step: 10
Training loss: 1.952697992324829
Validation loss: 1.963611041345904

Epoch: 112| Step: 0
Training loss: 2.18613338470459
Validation loss: 1.9632915194316576

Epoch: 5| Step: 1
Training loss: 2.0811333656311035
Validation loss: 1.938720614679398

Epoch: 5| Step: 2
Training loss: 2.556553363800049
Validation loss: 1.9407045174670476

Epoch: 5| Step: 3
Training loss: 1.8232157230377197
Validation loss: 1.9542522122783046

Epoch: 5| Step: 4
Training loss: 1.9463984966278076
Validation loss: 1.9538005782711891

Epoch: 5| Step: 5
Training loss: 1.9223434925079346
Validation loss: 1.9689379392131683

Epoch: 5| Step: 6
Training loss: 2.4060592651367188
Validation loss: 1.9600994279307704

Epoch: 5| Step: 7
Training loss: 2.2166800498962402
Validation loss: 1.950596914496473

Epoch: 5| Step: 8
Training loss: 2.550508737564087
Validation loss: 1.966340894340187

Epoch: 5| Step: 9
Training loss: 2.5211596488952637
Validation loss: 1.961726374523614

Epoch: 5| Step: 10
Training loss: 1.705207109451294
Validation loss: 1.953188120677907

Epoch: 113| Step: 0
Training loss: 2.403963565826416
Validation loss: 1.9606835739586943

Epoch: 5| Step: 1
Training loss: 3.0359044075012207
Validation loss: 1.9276667102690666

Epoch: 5| Step: 2
Training loss: 2.003513813018799
Validation loss: 1.9443259521197247

Epoch: 5| Step: 3
Training loss: 1.9310239553451538
Validation loss: 1.9538937102081955

Epoch: 5| Step: 4
Training loss: 1.5462459325790405
Validation loss: 1.9436019338587278

Epoch: 5| Step: 5
Training loss: 2.011190176010132
Validation loss: 1.9559908989937074

Epoch: 5| Step: 6
Training loss: 1.809069037437439
Validation loss: 1.9495388038696781

Epoch: 5| Step: 7
Training loss: 2.2019760608673096
Validation loss: 1.9573759263561619

Epoch: 5| Step: 8
Training loss: 2.4458210468292236
Validation loss: 1.9708503741090015

Epoch: 5| Step: 9
Training loss: 2.858922243118286
Validation loss: 1.962372919564606

Epoch: 5| Step: 10
Training loss: 1.674522042274475
Validation loss: 1.9495424557757635

Epoch: 114| Step: 0
Training loss: 2.2127861976623535
Validation loss: 1.947874105104836

Epoch: 5| Step: 1
Training loss: 2.3105578422546387
Validation loss: 1.9557049223171767

Epoch: 5| Step: 2
Training loss: 2.395502805709839
Validation loss: 1.941500440720589

Epoch: 5| Step: 3
Training loss: 2.1738057136535645
Validation loss: 1.9426022345019924

Epoch: 5| Step: 4
Training loss: 2.5694923400878906
Validation loss: 1.9594303125976233

Epoch: 5| Step: 5
Training loss: 2.257711172103882
Validation loss: 1.9575269042804677

Epoch: 5| Step: 6
Training loss: 1.9497915506362915
Validation loss: 1.9417194320309548

Epoch: 5| Step: 7
Training loss: 2.3084654808044434
Validation loss: 1.9410488156862156

Epoch: 5| Step: 8
Training loss: 1.8768904209136963
Validation loss: 1.9551945155666721

Epoch: 5| Step: 9
Training loss: 2.45601224899292
Validation loss: 1.9509220072018203

Epoch: 5| Step: 10
Training loss: 1.3245915174484253
Validation loss: 1.9489101748312674

Epoch: 115| Step: 0
Training loss: 2.637773275375366
Validation loss: 1.9574534123943699

Epoch: 5| Step: 1
Training loss: 1.9642086029052734
Validation loss: 1.9739556568925098

Epoch: 5| Step: 2
Training loss: 2.114224910736084
Validation loss: 1.9590508617380613

Epoch: 5| Step: 3
Training loss: 2.3942863941192627
Validation loss: 1.9502270093528173

Epoch: 5| Step: 4
Training loss: 2.352224349975586
Validation loss: 1.9562537042043542

Epoch: 5| Step: 5
Training loss: 2.094041347503662
Validation loss: 1.9397635024080995

Epoch: 5| Step: 6
Training loss: 2.3178749084472656
Validation loss: 1.953860693080451

Epoch: 5| Step: 7
Training loss: 1.944537878036499
Validation loss: 1.9661303463802542

Epoch: 5| Step: 8
Training loss: 2.938570976257324
Validation loss: 1.9514439464897237

Epoch: 5| Step: 9
Training loss: 1.6029495000839233
Validation loss: 1.9683786130720569

Epoch: 5| Step: 10
Training loss: 1.5070233345031738
Validation loss: 1.9632345245730491

Epoch: 116| Step: 0
Training loss: 2.538745164871216
Validation loss: 1.964430275783744

Epoch: 5| Step: 1
Training loss: 1.716135025024414
Validation loss: 1.9404887358347576

Epoch: 5| Step: 2
Training loss: 1.6223671436309814
Validation loss: 1.9518773683937647

Epoch: 5| Step: 3
Training loss: 2.379669666290283
Validation loss: 1.9669206744881087

Epoch: 5| Step: 4
Training loss: 1.8934738636016846
Validation loss: 1.9641082889290267

Epoch: 5| Step: 5
Training loss: 1.6781232357025146
Validation loss: 1.9627718284565916

Epoch: 5| Step: 6
Training loss: 2.590867280960083
Validation loss: 1.9633004691011162

Epoch: 5| Step: 7
Training loss: 2.3114218711853027
Validation loss: 1.9502787154207948

Epoch: 5| Step: 8
Training loss: 2.1680660247802734
Validation loss: 1.9522499371600408

Epoch: 5| Step: 9
Training loss: 2.3708744049072266
Validation loss: 1.9579653009291618

Epoch: 5| Step: 10
Training loss: 2.595503330230713
Validation loss: 1.9586047613492577

Epoch: 117| Step: 0
Training loss: 2.1119070053100586
Validation loss: 1.9692240094625821

Epoch: 5| Step: 1
Training loss: 2.193920135498047
Validation loss: 1.9760846835310741

Epoch: 5| Step: 2
Training loss: 3.0788683891296387
Validation loss: 1.9545350664405412

Epoch: 5| Step: 3
Training loss: 1.6582870483398438
Validation loss: 1.963093884529606

Epoch: 5| Step: 4
Training loss: 2.3092453479766846
Validation loss: 1.9442761662185832

Epoch: 5| Step: 5
Training loss: 2.010631561279297
Validation loss: 1.9719153296562932

Epoch: 5| Step: 6
Training loss: 1.4349005222320557
Validation loss: 1.9651425166796612

Epoch: 5| Step: 7
Training loss: 2.311589479446411
Validation loss: 1.969125945080993

Epoch: 5| Step: 8
Training loss: 1.9780696630477905
Validation loss: 1.9881080594114078

Epoch: 5| Step: 9
Training loss: 2.0905652046203613
Validation loss: 1.9564826565404092

Epoch: 5| Step: 10
Training loss: 2.790558338165283
Validation loss: 1.9840539040104035

Epoch: 118| Step: 0
Training loss: 2.2927989959716797
Validation loss: 1.9640607628771054

Epoch: 5| Step: 1
Training loss: 2.217001438140869
Validation loss: 1.9754182677115164

Epoch: 5| Step: 2
Training loss: 2.4688477516174316
Validation loss: 1.9666963649052445

Epoch: 5| Step: 3
Training loss: 1.9478013515472412
Validation loss: 1.9726544605788363

Epoch: 5| Step: 4
Training loss: 2.153968334197998
Validation loss: 1.9710566036162838

Epoch: 5| Step: 5
Training loss: 2.365906000137329
Validation loss: 1.954942410992038

Epoch: 5| Step: 6
Training loss: 2.1540560722351074
Validation loss: 1.9648483222530735

Epoch: 5| Step: 7
Training loss: 1.9699866771697998
Validation loss: 1.9661725644142396

Epoch: 5| Step: 8
Training loss: 1.9272212982177734
Validation loss: 1.963915773617324

Epoch: 5| Step: 9
Training loss: 2.536201000213623
Validation loss: 1.9624839008495372

Epoch: 5| Step: 10
Training loss: 1.677445888519287
Validation loss: 1.9697692535256828

Epoch: 119| Step: 0
Training loss: 2.1720004081726074
Validation loss: 1.9779196477705432

Epoch: 5| Step: 1
Training loss: 2.4509084224700928
Validation loss: 1.980084244922925

Epoch: 5| Step: 2
Training loss: 2.0538101196289062
Validation loss: 1.9691350793325773

Epoch: 5| Step: 3
Training loss: 2.6474897861480713
Validation loss: 1.962142095770887

Epoch: 5| Step: 4
Training loss: 2.400378704071045
Validation loss: 1.9730989817650086

Epoch: 5| Step: 5
Training loss: 1.8009427785873413
Validation loss: 1.9591664627034178

Epoch: 5| Step: 6
Training loss: 1.6395864486694336
Validation loss: 1.9712208253081127

Epoch: 5| Step: 7
Training loss: 2.213059663772583
Validation loss: 1.9548835895394767

Epoch: 5| Step: 8
Training loss: 2.5738792419433594
Validation loss: 1.9664506566139959

Epoch: 5| Step: 9
Training loss: 1.689587950706482
Validation loss: 1.9614446419541554

Epoch: 5| Step: 10
Training loss: 1.9466410875320435
Validation loss: 1.9517933835265457

Epoch: 120| Step: 0
Training loss: 1.4284075498580933
Validation loss: 1.981377697760059

Epoch: 5| Step: 1
Training loss: 2.4144232273101807
Validation loss: 1.9604071494071715

Epoch: 5| Step: 2
Training loss: 2.2011055946350098
Validation loss: 1.955800489712787

Epoch: 5| Step: 3
Training loss: 2.3225414752960205
Validation loss: 1.9617236404008762

Epoch: 5| Step: 4
Training loss: 2.0471320152282715
Validation loss: 1.9709725085125174

Epoch: 5| Step: 5
Training loss: 1.8449417352676392
Validation loss: 1.9743869689203077

Epoch: 5| Step: 6
Training loss: 2.2456533908843994
Validation loss: 1.9725044260742843

Epoch: 5| Step: 7
Training loss: 2.325671672821045
Validation loss: 1.9629581769307454

Epoch: 5| Step: 8
Training loss: 2.363011121749878
Validation loss: 1.9890171584262644

Epoch: 5| Step: 9
Training loss: 2.219766139984131
Validation loss: 1.9691268603007

Epoch: 5| Step: 10
Training loss: 2.527086019515991
Validation loss: 1.9907509729426394

Epoch: 121| Step: 0
Training loss: 2.0119669437408447
Validation loss: 1.9771529166929183

Epoch: 5| Step: 1
Training loss: 2.816166639328003
Validation loss: 1.9693530644139936

Epoch: 5| Step: 2
Training loss: 2.4715824127197266
Validation loss: 1.9810802603280673

Epoch: 5| Step: 3
Training loss: 1.5751193761825562
Validation loss: 1.968359854913527

Epoch: 5| Step: 4
Training loss: 1.5699799060821533
Validation loss: 1.9496695521057292

Epoch: 5| Step: 5
Training loss: 1.954951524734497
Validation loss: 1.9621694280255226

Epoch: 5| Step: 6
Training loss: 2.3529856204986572
Validation loss: 1.9806615934577039

Epoch: 5| Step: 7
Training loss: 1.9400644302368164
Validation loss: 1.9761403350419895

Epoch: 5| Step: 8
Training loss: 1.9825931787490845
Validation loss: 1.9477256908211658

Epoch: 5| Step: 9
Training loss: 2.5225770473480225
Validation loss: 1.9662773327160907

Epoch: 5| Step: 10
Training loss: 2.8186533451080322
Validation loss: 1.9745156611165693

Epoch: 122| Step: 0
Training loss: 2.2522335052490234
Validation loss: 1.970642448753439

Epoch: 5| Step: 1
Training loss: 2.3943138122558594
Validation loss: 1.9482995297319146

Epoch: 5| Step: 2
Training loss: 2.6472437381744385
Validation loss: 1.9573837864783503

Epoch: 5| Step: 3
Training loss: 2.0813817977905273
Validation loss: 1.9568291556450628

Epoch: 5| Step: 4
Training loss: 1.7839399576187134
Validation loss: 1.974293895947036

Epoch: 5| Step: 5
Training loss: 2.701895236968994
Validation loss: 1.96571107064524

Epoch: 5| Step: 6
Training loss: 2.189096450805664
Validation loss: 1.972229822989433

Epoch: 5| Step: 7
Training loss: 2.4145445823669434
Validation loss: 1.9712853559883692

Epoch: 5| Step: 8
Training loss: 1.856126070022583
Validation loss: 1.9873043465357956

Epoch: 5| Step: 9
Training loss: 1.772425889968872
Validation loss: 1.9736245421953098

Epoch: 5| Step: 10
Training loss: 1.4095563888549805
Validation loss: 1.9476709763209026

Epoch: 123| Step: 0
Training loss: 2.5001165866851807
Validation loss: 1.9816056784763132

Epoch: 5| Step: 1
Training loss: 2.7362568378448486
Validation loss: 1.9677624343543925

Epoch: 5| Step: 2
Training loss: 1.2323552370071411
Validation loss: 1.961108535848638

Epoch: 5| Step: 3
Training loss: 1.6368831396102905
Validation loss: 1.9708373187690653

Epoch: 5| Step: 4
Training loss: 1.8502298593521118
Validation loss: 1.9668201951570408

Epoch: 5| Step: 5
Training loss: 2.1548163890838623
Validation loss: 1.9530492918465727

Epoch: 5| Step: 6
Training loss: 1.861031174659729
Validation loss: 1.9554459741038661

Epoch: 5| Step: 7
Training loss: 3.0660266876220703
Validation loss: 1.9599270154071111

Epoch: 5| Step: 8
Training loss: 2.3519182205200195
Validation loss: 1.961505166945919

Epoch: 5| Step: 9
Training loss: 1.8772666454315186
Validation loss: 1.9665322483226817

Epoch: 5| Step: 10
Training loss: 2.5036814212799072
Validation loss: 1.9664121212497834

Epoch: 124| Step: 0
Training loss: 2.325840473175049
Validation loss: 1.9723044556956137

Epoch: 5| Step: 1
Training loss: 2.0076584815979004
Validation loss: 1.9507809364667503

Epoch: 5| Step: 2
Training loss: 1.9064356088638306
Validation loss: 1.9510422445112658

Epoch: 5| Step: 3
Training loss: 1.6358896493911743
Validation loss: 1.9592043276756042

Epoch: 5| Step: 4
Training loss: 2.8981146812438965
Validation loss: 1.9574844093732937

Epoch: 5| Step: 5
Training loss: 2.0403685569763184
Validation loss: 1.9673336834035895

Epoch: 5| Step: 6
Training loss: 1.9704554080963135
Validation loss: 1.9694987176566996

Epoch: 5| Step: 7
Training loss: 2.2071533203125
Validation loss: 1.965541539653655

Epoch: 5| Step: 8
Training loss: 2.5910534858703613
Validation loss: 1.9565252373295445

Epoch: 5| Step: 9
Training loss: 2.2769343852996826
Validation loss: 1.9502600649351716

Epoch: 5| Step: 10
Training loss: 1.8656198978424072
Validation loss: 1.932465161046674

Epoch: 125| Step: 0
Training loss: 3.223970413208008
Validation loss: 1.9713809708113312

Epoch: 5| Step: 1
Training loss: 1.3843824863433838
Validation loss: 1.957503649496263

Epoch: 5| Step: 2
Training loss: 2.115576982498169
Validation loss: 1.960685460798202

Epoch: 5| Step: 3
Training loss: 1.9522956609725952
Validation loss: 1.9620780701278357

Epoch: 5| Step: 4
Training loss: 2.4828152656555176
Validation loss: 1.9652349346427507

Epoch: 5| Step: 5
Training loss: 1.6632006168365479
Validation loss: 1.9572731500030847

Epoch: 5| Step: 6
Training loss: 2.2367494106292725
Validation loss: 1.9496105742710892

Epoch: 5| Step: 7
Training loss: 2.2450077533721924
Validation loss: 1.959574161037322

Epoch: 5| Step: 8
Training loss: 2.4567413330078125
Validation loss: 1.9532981867431312

Epoch: 5| Step: 9
Training loss: 1.705299735069275
Validation loss: 1.9590237550838019

Epoch: 5| Step: 10
Training loss: 2.207751512527466
Validation loss: 1.9490487088439286

Epoch: 126| Step: 0
Training loss: 2.0285866260528564
Validation loss: 1.961732138869583

Epoch: 5| Step: 1
Training loss: 2.281062602996826
Validation loss: 1.9756362361292685

Epoch: 5| Step: 2
Training loss: 1.3200427293777466
Validation loss: 1.9700917390085035

Epoch: 5| Step: 3
Training loss: 2.438371181488037
Validation loss: 1.9765433201225855

Epoch: 5| Step: 4
Training loss: 2.624751567840576
Validation loss: 1.9595217115135604

Epoch: 5| Step: 5
Training loss: 2.5455963611602783
Validation loss: 1.9601794237731605

Epoch: 5| Step: 6
Training loss: 2.723179340362549
Validation loss: 1.9570320831832064

Epoch: 5| Step: 7
Training loss: 1.933509111404419
Validation loss: 1.9440821768135153

Epoch: 5| Step: 8
Training loss: 2.4977123737335205
Validation loss: 1.9743988360128095

Epoch: 5| Step: 9
Training loss: 1.4402191638946533
Validation loss: 1.9546480973561604

Epoch: 5| Step: 10
Training loss: 1.6528979539871216
Validation loss: 1.946847036320676

Epoch: 127| Step: 0
Training loss: 2.7690892219543457
Validation loss: 1.9661688958444903

Epoch: 5| Step: 1
Training loss: 1.8710769414901733
Validation loss: 1.969544638869583

Epoch: 5| Step: 2
Training loss: 2.5491490364074707
Validation loss: 1.9785892937773017

Epoch: 5| Step: 3
Training loss: 1.6357944011688232
Validation loss: 1.9601904269187682

Epoch: 5| Step: 4
Training loss: 2.2965087890625
Validation loss: 1.9556731280460153

Epoch: 5| Step: 5
Training loss: 2.161301374435425
Validation loss: 1.9803939814208655

Epoch: 5| Step: 6
Training loss: 1.7309634685516357
Validation loss: 1.9681954050576815

Epoch: 5| Step: 7
Training loss: 2.639740467071533
Validation loss: 1.9664078322790002

Epoch: 5| Step: 8
Training loss: 2.2199041843414307
Validation loss: 1.9657961271142448

Epoch: 5| Step: 9
Training loss: 1.8490406274795532
Validation loss: 1.982990054674046

Epoch: 5| Step: 10
Training loss: 1.9944307804107666
Validation loss: 1.9643083528805805

Epoch: 128| Step: 0
Training loss: 2.514392137527466
Validation loss: 1.9505064718184932

Epoch: 5| Step: 1
Training loss: 1.7259308099746704
Validation loss: 1.9702138977666055

Epoch: 5| Step: 2
Training loss: 2.1848361492156982
Validation loss: 1.953633564774708

Epoch: 5| Step: 3
Training loss: 1.894988775253296
Validation loss: 1.9624459217953425

Epoch: 5| Step: 4
Training loss: 2.7373509407043457
Validation loss: 1.963902238876589

Epoch: 5| Step: 5
Training loss: 1.6505485773086548
Validation loss: 1.9556010487259075

Epoch: 5| Step: 6
Training loss: 2.4975733757019043
Validation loss: 1.9741327070420789

Epoch: 5| Step: 7
Training loss: 2.7277958393096924
Validation loss: 1.9630572462594638

Epoch: 5| Step: 8
Training loss: 1.873337745666504
Validation loss: 1.981452145884114

Epoch: 5| Step: 9
Training loss: 1.9927400350570679
Validation loss: 1.9621966141526417

Epoch: 5| Step: 10
Training loss: 1.7776598930358887
Validation loss: 1.9598787125720774

Epoch: 129| Step: 0
Training loss: 2.0177416801452637
Validation loss: 1.9826410137197024

Epoch: 5| Step: 1
Training loss: 2.1192774772644043
Validation loss: 1.9580870161774337

Epoch: 5| Step: 2
Training loss: 1.9155937433242798
Validation loss: 1.9645599165270407

Epoch: 5| Step: 3
Training loss: 2.4880549907684326
Validation loss: 1.9687862755149923

Epoch: 5| Step: 4
Training loss: 2.175480365753174
Validation loss: 1.9705488297247118

Epoch: 5| Step: 5
Training loss: 1.9290508031845093
Validation loss: 1.9581334642184678

Epoch: 5| Step: 6
Training loss: 2.807351589202881
Validation loss: 1.9573939666953137

Epoch: 5| Step: 7
Training loss: 2.5102086067199707
Validation loss: 1.9723957200204172

Epoch: 5| Step: 8
Training loss: 2.0428364276885986
Validation loss: 1.9559047760501984

Epoch: 5| Step: 9
Training loss: 1.5162595510482788
Validation loss: 1.9768040154569892

Epoch: 5| Step: 10
Training loss: 2.167872190475464
Validation loss: 1.9809289158031504

Epoch: 130| Step: 0
Training loss: 1.949231505393982
Validation loss: 1.9611256340498566

Epoch: 5| Step: 1
Training loss: 2.655311107635498
Validation loss: 1.9564879504583215

Epoch: 5| Step: 2
Training loss: 1.710065484046936
Validation loss: 1.9551958499416229

Epoch: 5| Step: 3
Training loss: 1.6371361017227173
Validation loss: 1.956977326382873

Epoch: 5| Step: 4
Training loss: 1.571589469909668
Validation loss: 1.9707020328890892

Epoch: 5| Step: 5
Training loss: 2.9944918155670166
Validation loss: 1.9582709676475936

Epoch: 5| Step: 6
Training loss: 2.100623607635498
Validation loss: 1.9783994023517897

Epoch: 5| Step: 7
Training loss: 2.396015167236328
Validation loss: 1.9540721229327622

Epoch: 5| Step: 8
Training loss: 1.9124805927276611
Validation loss: 1.9670304970074726

Epoch: 5| Step: 9
Training loss: 2.0731098651885986
Validation loss: 1.9577169059425272

Epoch: 5| Step: 10
Training loss: 2.682110071182251
Validation loss: 1.9382503032684326

Epoch: 131| Step: 0
Training loss: 2.0483806133270264
Validation loss: 1.9575068502015964

Epoch: 5| Step: 1
Training loss: 2.669203281402588
Validation loss: 1.9560176531473796

Epoch: 5| Step: 2
Training loss: 2.1867241859436035
Validation loss: 1.9586347687628962

Epoch: 5| Step: 3
Training loss: 1.4648774862289429
Validation loss: 1.9693272139436455

Epoch: 5| Step: 4
Training loss: 1.9377567768096924
Validation loss: 1.954241926952075

Epoch: 5| Step: 5
Training loss: 2.3275339603424072
Validation loss: 1.9405280479820826

Epoch: 5| Step: 6
Training loss: 2.068819761276245
Validation loss: 1.956010813354164

Epoch: 5| Step: 7
Training loss: 2.2077927589416504
Validation loss: 1.9521877432382235

Epoch: 5| Step: 8
Training loss: 2.0299620628356934
Validation loss: 1.9669027866855744

Epoch: 5| Step: 9
Training loss: 2.2184834480285645
Validation loss: 1.9409133029240433

Epoch: 5| Step: 10
Training loss: 2.5226082801818848
Validation loss: 1.9513857992746497

Epoch: 132| Step: 0
Training loss: 2.9382851123809814
Validation loss: 1.9601135920452815

Epoch: 5| Step: 1
Training loss: 2.0005862712860107
Validation loss: 1.953559519142233

Epoch: 5| Step: 2
Training loss: 2.2373805046081543
Validation loss: 1.9627026281049174

Epoch: 5| Step: 3
Training loss: 2.0814056396484375
Validation loss: 1.9458992224867626

Epoch: 5| Step: 4
Training loss: 2.4330782890319824
Validation loss: 1.9696883565636092

Epoch: 5| Step: 5
Training loss: 1.9968631267547607
Validation loss: 1.9484168150091683

Epoch: 5| Step: 6
Training loss: 2.0276710987091064
Validation loss: 1.9688040133445495

Epoch: 5| Step: 7
Training loss: 1.895850419998169
Validation loss: 1.9762650561589066

Epoch: 5| Step: 8
Training loss: 1.8040237426757812
Validation loss: 1.9651572447951122

Epoch: 5| Step: 9
Training loss: 1.8449138402938843
Validation loss: 1.972104908317648

Epoch: 5| Step: 10
Training loss: 2.450221300125122
Validation loss: 1.9514921288336478

Epoch: 133| Step: 0
Training loss: 2.3471121788024902
Validation loss: 1.9716106794213737

Epoch: 5| Step: 1
Training loss: 1.8250949382781982
Validation loss: 1.9665260302123202

Epoch: 5| Step: 2
Training loss: 1.9180046319961548
Validation loss: 1.9734880296132897

Epoch: 5| Step: 3
Training loss: 2.657041311264038
Validation loss: 1.9773620200413529

Epoch: 5| Step: 4
Training loss: 2.2838668823242188
Validation loss: 1.959326292878838

Epoch: 5| Step: 5
Training loss: 2.3573899269104004
Validation loss: 1.9644125969179216

Epoch: 5| Step: 6
Training loss: 2.2944509983062744
Validation loss: 1.9738262673859954

Epoch: 5| Step: 7
Training loss: 2.1698243618011475
Validation loss: 1.9664620417420582

Epoch: 5| Step: 8
Training loss: 1.9859437942504883
Validation loss: 1.9483935230521745

Epoch: 5| Step: 9
Training loss: 1.921154260635376
Validation loss: 1.9753973227675243

Epoch: 5| Step: 10
Training loss: 1.7464016675949097
Validation loss: 1.9655354010161532

Epoch: 134| Step: 0
Training loss: 2.1669249534606934
Validation loss: 1.9533649862453502

Epoch: 5| Step: 1
Training loss: 2.207418203353882
Validation loss: 1.961923522333945

Epoch: 5| Step: 2
Training loss: 2.252960205078125
Validation loss: 1.9592203542750368

Epoch: 5| Step: 3
Training loss: 1.9306560754776
Validation loss: 1.9628418722460348

Epoch: 5| Step: 4
Training loss: 2.2304625511169434
Validation loss: 1.9469239275942567

Epoch: 5| Step: 5
Training loss: 1.9333750009536743
Validation loss: 1.9499613597828855

Epoch: 5| Step: 6
Training loss: 1.7536332607269287
Validation loss: 1.945515416001761

Epoch: 5| Step: 7
Training loss: 2.437220573425293
Validation loss: 1.9525683708088373

Epoch: 5| Step: 8
Training loss: 2.1146774291992188
Validation loss: 1.9629217347791117

Epoch: 5| Step: 9
Training loss: 2.6381475925445557
Validation loss: 1.968990663046478

Epoch: 5| Step: 10
Training loss: 1.8405574560165405
Validation loss: 1.9517352311841902

Epoch: 135| Step: 0
Training loss: 2.26605224609375
Validation loss: 1.9775002438534972

Epoch: 5| Step: 1
Training loss: 1.9929587841033936
Validation loss: 1.9556396648448

Epoch: 5| Step: 2
Training loss: 2.6452629566192627
Validation loss: 1.9414111850082234

Epoch: 5| Step: 3
Training loss: 2.221831798553467
Validation loss: 1.9563086237958682

Epoch: 5| Step: 4
Training loss: 1.6435739994049072
Validation loss: 1.9423731450111634

Epoch: 5| Step: 5
Training loss: 1.3796567916870117
Validation loss: 1.9456581031122515

Epoch: 5| Step: 6
Training loss: 2.3676846027374268
Validation loss: 1.9687649716613114

Epoch: 5| Step: 7
Training loss: 2.8852057456970215
Validation loss: 1.954274030141933

Epoch: 5| Step: 8
Training loss: 2.029254674911499
Validation loss: 1.9539352450319516

Epoch: 5| Step: 9
Training loss: 1.9080429077148438
Validation loss: 1.9604235310708322

Epoch: 5| Step: 10
Training loss: 2.199079751968384
Validation loss: 1.9557101341985887

Epoch: 136| Step: 0
Training loss: 2.8703646659851074
Validation loss: 1.9565637457755305

Epoch: 5| Step: 1
Training loss: 2.285235643386841
Validation loss: 1.9811510591096775

Epoch: 5| Step: 2
Training loss: 2.225583553314209
Validation loss: 1.9593126158560477

Epoch: 5| Step: 3
Training loss: 1.8535200357437134
Validation loss: 1.957823468792823

Epoch: 5| Step: 4
Training loss: 2.329102039337158
Validation loss: 1.9526569433109735

Epoch: 5| Step: 5
Training loss: 2.235715866088867
Validation loss: 1.9704607763598043

Epoch: 5| Step: 6
Training loss: 1.9984050989151
Validation loss: 1.9630546826188282

Epoch: 5| Step: 7
Training loss: 1.9738566875457764
Validation loss: 1.9628717143048522

Epoch: 5| Step: 8
Training loss: 2.3105335235595703
Validation loss: 1.9589207467212473

Epoch: 5| Step: 9
Training loss: 1.730780839920044
Validation loss: 1.9718048290539814

Epoch: 5| Step: 10
Training loss: 1.4923887252807617
Validation loss: 1.9745140614048127

Epoch: 137| Step: 0
Training loss: 2.1216092109680176
Validation loss: 1.9588673781323176

Epoch: 5| Step: 1
Training loss: 1.8063007593154907
Validation loss: 1.9665239613543275

Epoch: 5| Step: 2
Training loss: 2.7225000858306885
Validation loss: 1.9693271601071922

Epoch: 5| Step: 3
Training loss: 2.122500419616699
Validation loss: 1.9643660488949026

Epoch: 5| Step: 4
Training loss: 2.130938768386841
Validation loss: 1.9564532567096014

Epoch: 5| Step: 5
Training loss: 2.3456931114196777
Validation loss: 1.962605672497903

Epoch: 5| Step: 6
Training loss: 1.7290785312652588
Validation loss: 1.9603307990617649

Epoch: 5| Step: 7
Training loss: 2.036053419113159
Validation loss: 1.9494617549321984

Epoch: 5| Step: 8
Training loss: 2.235867738723755
Validation loss: 1.9564991535678986

Epoch: 5| Step: 9
Training loss: 2.02712345123291
Validation loss: 1.96819386559148

Epoch: 5| Step: 10
Training loss: 2.1442337036132812
Validation loss: 1.9582646431461457

Epoch: 138| Step: 0
Training loss: 2.4641635417938232
Validation loss: 1.968772203691544

Epoch: 5| Step: 1
Training loss: 2.1416568756103516
Validation loss: 1.9624103410269624

Epoch: 5| Step: 2
Training loss: 2.8012919425964355
Validation loss: 1.9516912480836273

Epoch: 5| Step: 3
Training loss: 1.903192162513733
Validation loss: 1.9478639838516072

Epoch: 5| Step: 4
Training loss: 1.879594087600708
Validation loss: 1.9492887335438882

Epoch: 5| Step: 5
Training loss: 1.628495216369629
Validation loss: 1.9744798111659225

Epoch: 5| Step: 6
Training loss: 2.132686138153076
Validation loss: 1.9618801327161892

Epoch: 5| Step: 7
Training loss: 2.1457598209381104
Validation loss: 1.9609567901139617

Epoch: 5| Step: 8
Training loss: 1.992884874343872
Validation loss: 1.950886631524691

Epoch: 5| Step: 9
Training loss: 2.054798126220703
Validation loss: 1.9592140079826437

Epoch: 5| Step: 10
Training loss: 2.414046049118042
Validation loss: 1.963436677891721

Epoch: 139| Step: 0
Training loss: 2.8762309551239014
Validation loss: 1.92846550608194

Epoch: 5| Step: 1
Training loss: 2.2359702587127686
Validation loss: 1.9432301495664863

Epoch: 5| Step: 2
Training loss: 1.9102392196655273
Validation loss: 1.9636540438539238

Epoch: 5| Step: 3
Training loss: 1.8866996765136719
Validation loss: 1.9507729673898349

Epoch: 5| Step: 4
Training loss: 2.123654365539551
Validation loss: 1.9477291350723596

Epoch: 5| Step: 5
Training loss: 1.8537952899932861
Validation loss: 1.956016932764361

Epoch: 5| Step: 6
Training loss: 1.7073805332183838
Validation loss: 1.9502861320331533

Epoch: 5| Step: 7
Training loss: 2.175628900527954
Validation loss: 1.9654346384027952

Epoch: 5| Step: 8
Training loss: 1.9879401922225952
Validation loss: 1.957602236860542

Epoch: 5| Step: 9
Training loss: 2.433579683303833
Validation loss: 1.9531505953881048

Epoch: 5| Step: 10
Training loss: 2.0923259258270264
Validation loss: 1.9685022190052976

Epoch: 140| Step: 0
Training loss: 2.6994800567626953
Validation loss: 1.950502654557587

Epoch: 5| Step: 1
Training loss: 1.9846370220184326
Validation loss: 1.9583612616344164

Epoch: 5| Step: 2
Training loss: 1.853569746017456
Validation loss: 1.937395441916681

Epoch: 5| Step: 3
Training loss: 1.9755992889404297
Validation loss: 1.9655736723253805

Epoch: 5| Step: 4
Training loss: 1.7446197271347046
Validation loss: 1.9662714953063636

Epoch: 5| Step: 5
Training loss: 2.2956483364105225
Validation loss: 1.954779996666857

Epoch: 5| Step: 6
Training loss: 2.2153513431549072
Validation loss: 1.9512660644387687

Epoch: 5| Step: 7
Training loss: 2.1279027462005615
Validation loss: 1.9549669373419978

Epoch: 5| Step: 8
Training loss: 2.301164388656616
Validation loss: 1.9561596865295081

Epoch: 5| Step: 9
Training loss: 1.792388916015625
Validation loss: 1.9692402911442581

Epoch: 5| Step: 10
Training loss: 2.3821518421173096
Validation loss: 1.9555114725584626

Epoch: 141| Step: 0
Training loss: 2.2896413803100586
Validation loss: 1.9832392738711448

Epoch: 5| Step: 1
Training loss: 1.772970199584961
Validation loss: 1.9523147588135095

Epoch: 5| Step: 2
Training loss: 2.103301525115967
Validation loss: 1.9590729077657063

Epoch: 5| Step: 3
Training loss: 1.8163906335830688
Validation loss: 1.9542548938464093

Epoch: 5| Step: 4
Training loss: 1.9079914093017578
Validation loss: 1.9709089981612338

Epoch: 5| Step: 5
Training loss: 1.7791045904159546
Validation loss: 1.9676036091261013

Epoch: 5| Step: 6
Training loss: 2.245021343231201
Validation loss: 1.953923665067201

Epoch: 5| Step: 7
Training loss: 2.66801118850708
Validation loss: 1.9590326098985569

Epoch: 5| Step: 8
Training loss: 2.3303284645080566
Validation loss: 1.9667388649397

Epoch: 5| Step: 9
Training loss: 1.8773244619369507
Validation loss: 1.9709402233041742

Epoch: 5| Step: 10
Training loss: 2.7547430992126465
Validation loss: 1.9755485211649249

Epoch: 142| Step: 0
Training loss: 2.628382682800293
Validation loss: 1.965178487121418

Epoch: 5| Step: 1
Training loss: 2.2579293251037598
Validation loss: 1.9572726654750046

Epoch: 5| Step: 2
Training loss: 1.935032606124878
Validation loss: 1.9459706685876335

Epoch: 5| Step: 3
Training loss: 1.9031823873519897
Validation loss: 1.9447948650647235

Epoch: 5| Step: 4
Training loss: 1.8200565576553345
Validation loss: 1.9968813644942416

Epoch: 5| Step: 5
Training loss: 2.0890307426452637
Validation loss: 1.9408077398935955

Epoch: 5| Step: 6
Training loss: 2.322863817214966
Validation loss: 1.952682920681533

Epoch: 5| Step: 7
Training loss: 1.6100313663482666
Validation loss: 1.9556157576140536

Epoch: 5| Step: 8
Training loss: 2.2475826740264893
Validation loss: 1.927470471269341

Epoch: 5| Step: 9
Training loss: 2.16784930229187
Validation loss: 1.952477019320252

Epoch: 5| Step: 10
Training loss: 2.4295194149017334
Validation loss: 1.970115912857876

Epoch: 143| Step: 0
Training loss: 1.8712358474731445
Validation loss: 1.9582473642082625

Epoch: 5| Step: 1
Training loss: 1.9138813018798828
Validation loss: 1.9420589439330562

Epoch: 5| Step: 2
Training loss: 2.1157524585723877
Validation loss: 1.963777575441586

Epoch: 5| Step: 3
Training loss: 1.6701456308364868
Validation loss: 1.9571954024735319

Epoch: 5| Step: 4
Training loss: 2.3092267513275146
Validation loss: 1.9566472063782394

Epoch: 5| Step: 5
Training loss: 2.3232786655426025
Validation loss: 1.9621308824067474

Epoch: 5| Step: 6
Training loss: 2.301499605178833
Validation loss: 1.9653702435954925

Epoch: 5| Step: 7
Training loss: 2.6736090183258057
Validation loss: 1.9563905474960164

Epoch: 5| Step: 8
Training loss: 2.3723816871643066
Validation loss: 1.9503340926221622

Epoch: 5| Step: 9
Training loss: 1.839839220046997
Validation loss: 1.9639195601145427

Epoch: 5| Step: 10
Training loss: 2.0266129970550537
Validation loss: 1.9596574024487567

Epoch: 144| Step: 0
Training loss: 1.7830978631973267
Validation loss: 1.9508755694153488

Epoch: 5| Step: 1
Training loss: 1.785763144493103
Validation loss: 1.9803972039171445

Epoch: 5| Step: 2
Training loss: 1.9559005498886108
Validation loss: 1.9620822885985016

Epoch: 5| Step: 3
Training loss: 1.667028784751892
Validation loss: 1.9454476115524129

Epoch: 5| Step: 4
Training loss: 1.6506826877593994
Validation loss: 1.9655794764077792

Epoch: 5| Step: 5
Training loss: 2.577767848968506
Validation loss: 1.9646607675860006

Epoch: 5| Step: 6
Training loss: 2.8588554859161377
Validation loss: 1.919571938053254

Epoch: 5| Step: 7
Training loss: 2.31502103805542
Validation loss: 1.9650285423442881

Epoch: 5| Step: 8
Training loss: 2.4460983276367188
Validation loss: 1.9417963732955277

Epoch: 5| Step: 9
Training loss: 2.2673122882843018
Validation loss: 1.9372516780771234

Epoch: 5| Step: 10
Training loss: 2.057655096054077
Validation loss: 1.9565443608068651

Epoch: 145| Step: 0
Training loss: 2.103577136993408
Validation loss: 1.966902143211775

Epoch: 5| Step: 1
Training loss: 2.5294442176818848
Validation loss: 1.9551645965986355

Epoch: 5| Step: 2
Training loss: 2.1378180980682373
Validation loss: 1.925429154467839

Epoch: 5| Step: 3
Training loss: 2.189260959625244
Validation loss: 1.9472332205823673

Epoch: 5| Step: 4
Training loss: 1.9553306102752686
Validation loss: 1.9665880741611603

Epoch: 5| Step: 5
Training loss: 2.1764512062072754
Validation loss: 1.9668123234984696

Epoch: 5| Step: 6
Training loss: 1.8945268392562866
Validation loss: 1.9556595984325613

Epoch: 5| Step: 7
Training loss: 2.2878425121307373
Validation loss: 1.9612742752157233

Epoch: 5| Step: 8
Training loss: 1.655224084854126
Validation loss: 1.9649298075706727

Epoch: 5| Step: 9
Training loss: 1.976552963256836
Validation loss: 1.9643267200839134

Epoch: 5| Step: 10
Training loss: 2.4040887355804443
Validation loss: 1.961764383059676

Epoch: 146| Step: 0
Training loss: 1.9863208532333374
Validation loss: 1.9675148815237067

Epoch: 5| Step: 1
Training loss: 2.0737295150756836
Validation loss: 1.9622395551332863

Epoch: 5| Step: 2
Training loss: 2.1848785877227783
Validation loss: 1.9607279864690637

Epoch: 5| Step: 3
Training loss: 1.7440274953842163
Validation loss: 1.9497491313565163

Epoch: 5| Step: 4
Training loss: 2.3349032402038574
Validation loss: 1.9468190106012488

Epoch: 5| Step: 5
Training loss: 2.1086249351501465
Validation loss: 1.9641367927674325

Epoch: 5| Step: 6
Training loss: 1.924996018409729
Validation loss: 1.95322633558704

Epoch: 5| Step: 7
Training loss: 1.7714531421661377
Validation loss: 1.9496934413909912

Epoch: 5| Step: 8
Training loss: 1.7360824346542358
Validation loss: 1.9525182375343897

Epoch: 5| Step: 9
Training loss: 2.919811725616455
Validation loss: 1.9458694740008282

Epoch: 5| Step: 10
Training loss: 2.586610794067383
Validation loss: 1.9492625780003046

Epoch: 147| Step: 0
Training loss: 2.067871570587158
Validation loss: 1.9491909216809016

Epoch: 5| Step: 1
Training loss: 2.265160083770752
Validation loss: 1.953295789739137

Epoch: 5| Step: 2
Training loss: 2.9769623279571533
Validation loss: 1.9666533418880996

Epoch: 5| Step: 3
Training loss: 1.619574785232544
Validation loss: 1.948658929076246

Epoch: 5| Step: 4
Training loss: 2.0593924522399902
Validation loss: 1.949299625171128

Epoch: 5| Step: 5
Training loss: 2.305509567260742
Validation loss: 1.9823068123991772

Epoch: 5| Step: 6
Training loss: 2.494394302368164
Validation loss: 1.9631312739464544

Epoch: 5| Step: 7
Training loss: 2.117990016937256
Validation loss: 1.9701786182260002

Epoch: 5| Step: 8
Training loss: 1.4069169759750366
Validation loss: 1.9726802302945046

Epoch: 5| Step: 9
Training loss: 1.8241240978240967
Validation loss: 1.9704708001946891

Epoch: 5| Step: 10
Training loss: 2.0990896224975586
Validation loss: 1.956855494488952

Epoch: 148| Step: 0
Training loss: 2.329070568084717
Validation loss: 1.9579691361355525

Epoch: 5| Step: 1
Training loss: 1.8435661792755127
Validation loss: 1.9619564753706737

Epoch: 5| Step: 2
Training loss: 1.8692238330841064
Validation loss: 1.9640015427784254

Epoch: 5| Step: 3
Training loss: 1.9611371755599976
Validation loss: 1.9495451706711964

Epoch: 5| Step: 4
Training loss: 2.1568801403045654
Validation loss: 1.9547665683172082

Epoch: 5| Step: 5
Training loss: 1.9863548278808594
Validation loss: 1.9670847974797732

Epoch: 5| Step: 6
Training loss: 1.4478133916854858
Validation loss: 1.9504360229738298

Epoch: 5| Step: 7
Training loss: 2.96126127243042
Validation loss: 1.94574833813534

Epoch: 5| Step: 8
Training loss: 2.1248087882995605
Validation loss: 1.9671792522553475

Epoch: 5| Step: 9
Training loss: 2.081944227218628
Validation loss: 1.9599939507822837

Epoch: 5| Step: 10
Training loss: 2.6604719161987305
Validation loss: 1.961931465774454

Epoch: 149| Step: 0
Training loss: 2.5557684898376465
Validation loss: 1.9413343783347838

Epoch: 5| Step: 1
Training loss: 2.5229790210723877
Validation loss: 1.9473437622029295

Epoch: 5| Step: 2
Training loss: 1.5327963829040527
Validation loss: 1.9480868347229496

Epoch: 5| Step: 3
Training loss: 2.7047832012176514
Validation loss: 1.9570779056959255

Epoch: 5| Step: 4
Training loss: 2.066838502883911
Validation loss: 1.94621907254701

Epoch: 5| Step: 5
Training loss: 1.8961158990859985
Validation loss: 1.9541888121635682

Epoch: 5| Step: 6
Training loss: 2.0425777435302734
Validation loss: 1.9594698618817072

Epoch: 5| Step: 7
Training loss: 1.5191274881362915
Validation loss: 1.9449992897689983

Epoch: 5| Step: 8
Training loss: 2.245767116546631
Validation loss: 1.9478897099853845

Epoch: 5| Step: 9
Training loss: 2.1529698371887207
Validation loss: 1.9707044170748802

Epoch: 5| Step: 10
Training loss: 1.8848464488983154
Validation loss: 1.9523666084453624

Epoch: 150| Step: 0
Training loss: 2.087334394454956
Validation loss: 1.9518159922733103

Epoch: 5| Step: 1
Training loss: 2.1591036319732666
Validation loss: 1.9764877173208422

Epoch: 5| Step: 2
Training loss: 2.1512224674224854
Validation loss: 1.9558353424072266

Epoch: 5| Step: 3
Training loss: 1.665203332901001
Validation loss: 1.9689059103688886

Epoch: 5| Step: 4
Training loss: 2.1154372692108154
Validation loss: 1.9736637864061581

Epoch: 5| Step: 5
Training loss: 2.03596568107605
Validation loss: 1.9538275349524714

Epoch: 5| Step: 6
Training loss: 2.0254900455474854
Validation loss: 1.951753798351493

Epoch: 5| Step: 7
Training loss: 2.0716068744659424
Validation loss: 1.9630832806710274

Epoch: 5| Step: 8
Training loss: 2.044372081756592
Validation loss: 1.9527527683524675

Epoch: 5| Step: 9
Training loss: 2.9875309467315674
Validation loss: 1.9484679058033934

Epoch: 5| Step: 10
Training loss: 1.6234140396118164
Validation loss: 1.9637906884634366

Epoch: 151| Step: 0
Training loss: 1.802380919456482
Validation loss: 1.9714270971154655

Epoch: 5| Step: 1
Training loss: 2.4077773094177246
Validation loss: 1.9629934910804994

Epoch: 5| Step: 2
Training loss: 2.930202007293701
Validation loss: 1.9507948519081197

Epoch: 5| Step: 3
Training loss: 1.9670175313949585
Validation loss: 1.9821849894779984

Epoch: 5| Step: 4
Training loss: 1.6221981048583984
Validation loss: 1.969495819460961

Epoch: 5| Step: 5
Training loss: 2.531036376953125
Validation loss: 1.9403338252857167

Epoch: 5| Step: 6
Training loss: 1.8206297159194946
Validation loss: 1.9467333388584915

Epoch: 5| Step: 7
Training loss: 1.8517287969589233
Validation loss: 1.9483317611038045

Epoch: 5| Step: 8
Training loss: 1.5818415880203247
Validation loss: 1.9668062553610852

Epoch: 5| Step: 9
Training loss: 2.2555246353149414
Validation loss: 1.9527034285247966

Epoch: 5| Step: 10
Training loss: 2.4465551376342773
Validation loss: 1.9628052660214004

Epoch: 152| Step: 0
Training loss: 2.3006908893585205
Validation loss: 1.9698367913564045

Epoch: 5| Step: 1
Training loss: 1.9956029653549194
Validation loss: 1.9584597156893822

Epoch: 5| Step: 2
Training loss: 1.817182183265686
Validation loss: 1.951915483320913

Epoch: 5| Step: 3
Training loss: 2.369011402130127
Validation loss: 1.9571432823775916

Epoch: 5| Step: 4
Training loss: 2.128626585006714
Validation loss: 1.9606395594535335

Epoch: 5| Step: 5
Training loss: 1.6036903858184814
Validation loss: 1.958815909201099

Epoch: 5| Step: 6
Training loss: 1.9041706323623657
Validation loss: 1.9700464356330134

Epoch: 5| Step: 7
Training loss: 1.9923175573349
Validation loss: 1.9618978423456992

Epoch: 5| Step: 8
Training loss: 2.237213611602783
Validation loss: 1.9637109835942586

Epoch: 5| Step: 9
Training loss: 2.736710548400879
Validation loss: 1.976334661565801

Epoch: 5| Step: 10
Training loss: 1.9374185800552368
Validation loss: 1.9842739092406405

Epoch: 153| Step: 0
Training loss: 2.4623587131500244
Validation loss: 1.9467623720886886

Epoch: 5| Step: 1
Training loss: 2.3979945182800293
Validation loss: 1.9635400720821914

Epoch: 5| Step: 2
Training loss: 1.9595441818237305
Validation loss: 1.967216089207639

Epoch: 5| Step: 3
Training loss: 2.2543892860412598
Validation loss: 1.9530941414576706

Epoch: 5| Step: 4
Training loss: 2.213085174560547
Validation loss: 1.9695327769043625

Epoch: 5| Step: 5
Training loss: 1.3735015392303467
Validation loss: 1.9625238064796693

Epoch: 5| Step: 6
Training loss: 2.105665683746338
Validation loss: 1.9678263664245605

Epoch: 5| Step: 7
Training loss: 1.8489809036254883
Validation loss: 1.9771585900296447

Epoch: 5| Step: 8
Training loss: 2.0665764808654785
Validation loss: 1.9584222762815413

Epoch: 5| Step: 9
Training loss: 2.230264186859131
Validation loss: 1.9597782345228298

Epoch: 5| Step: 10
Training loss: 2.287567377090454
Validation loss: 1.9497745152442687

Epoch: 154| Step: 0
Training loss: 2.1918163299560547
Validation loss: 1.9614751146685692

Epoch: 5| Step: 1
Training loss: 1.429392695426941
Validation loss: 1.953494966671031

Epoch: 5| Step: 2
Training loss: 1.875867486000061
Validation loss: 1.9661683113344255

Epoch: 5| Step: 3
Training loss: 2.170212507247925
Validation loss: 1.9861212033097462

Epoch: 5| Step: 4
Training loss: 2.533238410949707
Validation loss: 1.9548762972636888

Epoch: 5| Step: 5
Training loss: 2.2696309089660645
Validation loss: 1.9659303234469505

Epoch: 5| Step: 6
Training loss: 2.083289384841919
Validation loss: 1.9744210755953224

Epoch: 5| Step: 7
Training loss: 2.3792645931243896
Validation loss: 1.9346116127506379

Epoch: 5| Step: 8
Training loss: 2.0500025749206543
Validation loss: 1.9488172787491993

Epoch: 5| Step: 9
Training loss: 1.8767592906951904
Validation loss: 1.961405123433759

Epoch: 5| Step: 10
Training loss: 2.2351911067962646
Validation loss: 1.9760401723205403

Epoch: 155| Step: 0
Training loss: 2.0491867065429688
Validation loss: 1.9819269667389572

Epoch: 5| Step: 1
Training loss: 1.420157790184021
Validation loss: 1.9469199488239903

Epoch: 5| Step: 2
Training loss: 1.8687183856964111
Validation loss: 1.939669983361357

Epoch: 5| Step: 3
Training loss: 2.0422720909118652
Validation loss: 1.949321363561897

Epoch: 5| Step: 4
Training loss: 2.3638978004455566
Validation loss: 1.9716132533165716

Epoch: 5| Step: 5
Training loss: 2.445568084716797
Validation loss: 1.9503119837853216

Epoch: 5| Step: 6
Training loss: 1.7994121313095093
Validation loss: 1.961232945483218

Epoch: 5| Step: 7
Training loss: 1.6704025268554688
Validation loss: 1.9510481203756025

Epoch: 5| Step: 8
Training loss: 2.914638042449951
Validation loss: 1.9511491816530946

Epoch: 5| Step: 9
Training loss: 2.0932536125183105
Validation loss: 1.9534735474535214

Epoch: 5| Step: 10
Training loss: 2.578571319580078
Validation loss: 1.9458003326128888

Epoch: 156| Step: 0
Training loss: 1.3340840339660645
Validation loss: 1.940630651289417

Epoch: 5| Step: 1
Training loss: 2.289618968963623
Validation loss: 1.9714603488163283

Epoch: 5| Step: 2
Training loss: 2.400477170944214
Validation loss: 1.9470081662618985

Epoch: 5| Step: 3
Training loss: 2.384046792984009
Validation loss: 1.9584123857559697

Epoch: 5| Step: 4
Training loss: 2.1494040489196777
Validation loss: 1.9330382500925372

Epoch: 5| Step: 5
Training loss: 1.4256861209869385
Validation loss: 1.9293377450717393

Epoch: 5| Step: 6
Training loss: 2.536818027496338
Validation loss: 1.9687477888599518

Epoch: 5| Step: 7
Training loss: 2.1119601726531982
Validation loss: 1.9559301022560365

Epoch: 5| Step: 8
Training loss: 1.4748731851577759
Validation loss: 1.9588466741705453

Epoch: 5| Step: 9
Training loss: 2.430321455001831
Validation loss: 1.949492036655385

Epoch: 5| Step: 10
Training loss: 2.42820143699646
Validation loss: 1.9361010392506917

Epoch: 157| Step: 0
Training loss: 1.8100868463516235
Validation loss: 1.9466367511339084

Epoch: 5| Step: 1
Training loss: 2.0113840103149414
Validation loss: 1.9419761896133423

Epoch: 5| Step: 2
Training loss: 2.4451472759246826
Validation loss: 1.9476357211348831

Epoch: 5| Step: 3
Training loss: 2.4260106086730957
Validation loss: 1.9627664243021319

Epoch: 5| Step: 4
Training loss: 1.2746626138687134
Validation loss: 1.9518491004102974

Epoch: 5| Step: 5
Training loss: 2.1784656047821045
Validation loss: 1.9633002076097714

Epoch: 5| Step: 6
Training loss: 2.3915138244628906
Validation loss: 1.9629148744767713

Epoch: 5| Step: 7
Training loss: 1.560519814491272
Validation loss: 1.9786403666260421

Epoch: 5| Step: 8
Training loss: 2.41192889213562
Validation loss: 1.964664477174

Epoch: 5| Step: 9
Training loss: 2.716149091720581
Validation loss: 1.94889566334345

Epoch: 5| Step: 10
Training loss: 1.7294236421585083
Validation loss: 1.9532531474226265

Epoch: 158| Step: 0
Training loss: 3.1119446754455566
Validation loss: 1.9547970602589269

Epoch: 5| Step: 1
Training loss: 1.9933669567108154
Validation loss: 1.9572163576720862

Epoch: 5| Step: 2
Training loss: 1.841794729232788
Validation loss: 1.9813119326868365

Epoch: 5| Step: 3
Training loss: 2.079744338989258
Validation loss: 1.973086295589324

Epoch: 5| Step: 4
Training loss: 2.200345516204834
Validation loss: 1.9571071286355295

Epoch: 5| Step: 5
Training loss: 1.9946073293685913
Validation loss: 1.9884616431369577

Epoch: 5| Step: 6
Training loss: 1.8246322870254517
Validation loss: 1.9428985785412531

Epoch: 5| Step: 7
Training loss: 1.5220187902450562
Validation loss: 1.9743503383410874

Epoch: 5| Step: 8
Training loss: 2.6330361366271973
Validation loss: 1.9441646452872985

Epoch: 5| Step: 9
Training loss: 2.2401063442230225
Validation loss: 1.9697710083376976

Epoch: 5| Step: 10
Training loss: 1.5858205556869507
Validation loss: 1.9644463203286613

Epoch: 159| Step: 0
Training loss: 1.711096167564392
Validation loss: 1.9286180926907448

Epoch: 5| Step: 1
Training loss: 2.4946465492248535
Validation loss: 1.9661312846727268

Epoch: 5| Step: 2
Training loss: 2.1949596405029297
Validation loss: 1.9434938315422303

Epoch: 5| Step: 3
Training loss: 1.5464465618133545
Validation loss: 1.9536820278372815

Epoch: 5| Step: 4
Training loss: 2.1543033123016357
Validation loss: 1.9362569265468146

Epoch: 5| Step: 5
Training loss: 2.74243426322937
Validation loss: 1.9326643802786385

Epoch: 5| Step: 6
Training loss: 2.191909074783325
Validation loss: 1.9509527580712431

Epoch: 5| Step: 7
Training loss: 1.63748300075531
Validation loss: 1.950218008410546

Epoch: 5| Step: 8
Training loss: 2.0760064125061035
Validation loss: 1.9324057602113294

Epoch: 5| Step: 9
Training loss: 2.704310417175293
Validation loss: 1.9492415100015619

Epoch: 5| Step: 10
Training loss: 1.3653446435928345
Validation loss: 1.940950878204838

Epoch: 160| Step: 0
Training loss: 1.9894298315048218
Validation loss: 1.9539648819995183

Epoch: 5| Step: 1
Training loss: 2.191093921661377
Validation loss: 1.9355067745331795

Epoch: 5| Step: 2
Training loss: 1.9870895147323608
Validation loss: 1.9579687297985118

Epoch: 5| Step: 3
Training loss: 2.2832348346710205
Validation loss: 1.962970854133688

Epoch: 5| Step: 4
Training loss: 2.88700532913208
Validation loss: 1.9700314088534283

Epoch: 5| Step: 5
Training loss: 2.2753853797912598
Validation loss: 1.946828285853068

Epoch: 5| Step: 6
Training loss: 1.2936445474624634
Validation loss: 1.9594815174738567

Epoch: 5| Step: 7
Training loss: 1.8978382349014282
Validation loss: 1.9498251715014059

Epoch: 5| Step: 8
Training loss: 2.581799030303955
Validation loss: 1.953852674012543

Epoch: 5| Step: 9
Training loss: 1.9043550491333008
Validation loss: 1.9668192632736698

Epoch: 5| Step: 10
Training loss: 1.5479459762573242
Validation loss: 1.934641384309338

Epoch: 161| Step: 0
Training loss: 1.909425973892212
Validation loss: 1.971245922068114

Epoch: 5| Step: 1
Training loss: 2.182333469390869
Validation loss: 1.9372671086301085

Epoch: 5| Step: 2
Training loss: 2.03078031539917
Validation loss: 1.9264540031392088

Epoch: 5| Step: 3
Training loss: 1.4803903102874756
Validation loss: 1.9343762961767053

Epoch: 5| Step: 4
Training loss: 1.815617322921753
Validation loss: 1.9588274237930134

Epoch: 5| Step: 5
Training loss: 2.5815913677215576
Validation loss: 1.959331456051078

Epoch: 5| Step: 6
Training loss: 1.727500319480896
Validation loss: 1.9419017184165217

Epoch: 5| Step: 7
Training loss: 2.784529209136963
Validation loss: 1.94978363795947

Epoch: 5| Step: 8
Training loss: 2.017876386642456
Validation loss: 1.9527678156411776

Epoch: 5| Step: 9
Training loss: 2.0369057655334473
Validation loss: 1.9308836408840713

Epoch: 5| Step: 10
Training loss: 2.4189155101776123
Validation loss: 1.9460644773257676

Epoch: 162| Step: 0
Training loss: 2.3802497386932373
Validation loss: 1.9495979970501316

Epoch: 5| Step: 1
Training loss: 1.7930011749267578
Validation loss: 1.9496150401330763

Epoch: 5| Step: 2
Training loss: 2.6534900665283203
Validation loss: 1.9424750933083155

Epoch: 5| Step: 3
Training loss: 2.772977590560913
Validation loss: 1.9574063093431535

Epoch: 5| Step: 4
Training loss: 2.2953550815582275
Validation loss: 1.9438608615629134

Epoch: 5| Step: 5
Training loss: 1.836116075515747
Validation loss: 1.9595280321695472

Epoch: 5| Step: 6
Training loss: 1.8814713954925537
Validation loss: 1.9651065834106938

Epoch: 5| Step: 7
Training loss: 1.6093368530273438
Validation loss: 1.967302458260649

Epoch: 5| Step: 8
Training loss: 2.160484790802002
Validation loss: 1.9508620372382544

Epoch: 5| Step: 9
Training loss: 1.753525733947754
Validation loss: 1.962555318750361

Epoch: 5| Step: 10
Training loss: 1.7355031967163086
Validation loss: 1.9666758262982933

Epoch: 163| Step: 0
Training loss: 2.4659576416015625
Validation loss: 1.9776092178078108

Epoch: 5| Step: 1
Training loss: 2.1143012046813965
Validation loss: 1.9536831968574113

Epoch: 5| Step: 2
Training loss: 1.6448034048080444
Validation loss: 1.9560652061175274

Epoch: 5| Step: 3
Training loss: 1.6382001638412476
Validation loss: 1.937639844033026

Epoch: 5| Step: 4
Training loss: 1.8370678424835205
Validation loss: 1.9446094074556906

Epoch: 5| Step: 5
Training loss: 2.344482660293579
Validation loss: 1.941976055022209

Epoch: 5| Step: 6
Training loss: 2.170011043548584
Validation loss: 1.944717199571671

Epoch: 5| Step: 7
Training loss: 1.7026870250701904
Validation loss: 1.953016117054929

Epoch: 5| Step: 8
Training loss: 2.4379706382751465
Validation loss: 1.952615886606196

Epoch: 5| Step: 9
Training loss: 2.292205333709717
Validation loss: 1.9251192615878197

Epoch: 5| Step: 10
Training loss: 2.454733371734619
Validation loss: 1.943702079916513

Epoch: 164| Step: 0
Training loss: 1.8828544616699219
Validation loss: 1.9419983663866598

Epoch: 5| Step: 1
Training loss: 1.9799220561981201
Validation loss: 1.9663577131045762

Epoch: 5| Step: 2
Training loss: 2.2681069374084473
Validation loss: 1.9312878577939925

Epoch: 5| Step: 3
Training loss: 2.0071635246276855
Validation loss: 1.9455438788219164

Epoch: 5| Step: 4
Training loss: 2.00727915763855
Validation loss: 1.9590929451809134

Epoch: 5| Step: 5
Training loss: 1.365264654159546
Validation loss: 1.9463583641154791

Epoch: 5| Step: 6
Training loss: 1.6923496723175049
Validation loss: 1.952817791251726

Epoch: 5| Step: 7
Training loss: 2.024681568145752
Validation loss: 1.9568194240652106

Epoch: 5| Step: 8
Training loss: 2.9333128929138184
Validation loss: 1.9482250700714767

Epoch: 5| Step: 9
Training loss: 2.087218999862671
Validation loss: 1.9286248786475069

Epoch: 5| Step: 10
Training loss: 2.6412200927734375
Validation loss: 1.9359897516107047

Epoch: 165| Step: 0
Training loss: 1.7029186487197876
Validation loss: 1.949409105444467

Epoch: 5| Step: 1
Training loss: 2.2054004669189453
Validation loss: 1.959280990785168

Epoch: 5| Step: 2
Training loss: 2.255007028579712
Validation loss: 1.954814544288061

Epoch: 5| Step: 3
Training loss: 2.7964065074920654
Validation loss: 1.9746409628980903

Epoch: 5| Step: 4
Training loss: 2.410320281982422
Validation loss: 1.9584671117926156

Epoch: 5| Step: 5
Training loss: 2.0396080017089844
Validation loss: 1.966008109431113

Epoch: 5| Step: 6
Training loss: 2.1387133598327637
Validation loss: 1.9763725111561437

Epoch: 5| Step: 7
Training loss: 1.9668395519256592
Validation loss: 1.952071189880371

Epoch: 5| Step: 8
Training loss: 1.3513859510421753
Validation loss: 1.9412357243158485

Epoch: 5| Step: 9
Training loss: 1.940294861793518
Validation loss: 1.9544071651274157

Epoch: 5| Step: 10
Training loss: 1.9114680290222168
Validation loss: 1.9474787314732869

Epoch: 166| Step: 0
Training loss: 2.4629621505737305
Validation loss: 1.9497018039867442

Epoch: 5| Step: 1
Training loss: 2.1360695362091064
Validation loss: 1.9422539139306674

Epoch: 5| Step: 2
Training loss: 2.3889055252075195
Validation loss: 1.9596892582472933

Epoch: 5| Step: 3
Training loss: 1.8274198770523071
Validation loss: 1.9449135154806159

Epoch: 5| Step: 4
Training loss: 1.5659539699554443
Validation loss: 1.9552229822322886

Epoch: 5| Step: 5
Training loss: 2.2541491985321045
Validation loss: 1.9687122824371501

Epoch: 5| Step: 6
Training loss: 2.466463565826416
Validation loss: 1.939849094677997

Epoch: 5| Step: 7
Training loss: 2.5027687549591064
Validation loss: 1.958226192382074

Epoch: 5| Step: 8
Training loss: 1.7013094425201416
Validation loss: 1.9326659338448637

Epoch: 5| Step: 9
Training loss: 1.4820541143417358
Validation loss: 1.9622623894804267

Epoch: 5| Step: 10
Training loss: 1.9471346139907837
Validation loss: 1.9655960990536598

Epoch: 167| Step: 0
Training loss: 1.8045785427093506
Validation loss: 1.9517498221448673

Epoch: 5| Step: 1
Training loss: 2.400479793548584
Validation loss: 1.9463612136020456

Epoch: 5| Step: 2
Training loss: 2.1733174324035645
Validation loss: 1.9666104649984708

Epoch: 5| Step: 3
Training loss: 1.8005489110946655
Validation loss: 1.9612207758811213

Epoch: 5| Step: 4
Training loss: 2.238402843475342
Validation loss: 1.9702910018223587

Epoch: 5| Step: 5
Training loss: 1.9449275732040405
Validation loss: 1.9347098450506888

Epoch: 5| Step: 6
Training loss: 2.29485821723938
Validation loss: 1.9500700978822605

Epoch: 5| Step: 7
Training loss: 1.3922855854034424
Validation loss: 1.9557456137031637

Epoch: 5| Step: 8
Training loss: 2.130462169647217
Validation loss: 1.9486791036462272

Epoch: 5| Step: 9
Training loss: 2.232926845550537
Validation loss: 1.9400206048001525

Epoch: 5| Step: 10
Training loss: 2.401106834411621
Validation loss: 1.9521468634246497

Epoch: 168| Step: 0
Training loss: 2.4525485038757324
Validation loss: 1.9657845804768224

Epoch: 5| Step: 1
Training loss: 2.669142246246338
Validation loss: 1.9426851413583244

Epoch: 5| Step: 2
Training loss: 2.738129138946533
Validation loss: 1.9451117387381933

Epoch: 5| Step: 3
Training loss: 1.836096167564392
Validation loss: 1.9384537422528831

Epoch: 5| Step: 4
Training loss: 1.4054243564605713
Validation loss: 1.9433144907797537

Epoch: 5| Step: 5
Training loss: 1.9567890167236328
Validation loss: 1.9558569051886117

Epoch: 5| Step: 6
Training loss: 2.0587713718414307
Validation loss: 1.9381443813282957

Epoch: 5| Step: 7
Training loss: 1.8933355808258057
Validation loss: 1.98073669146466

Epoch: 5| Step: 8
Training loss: 2.065761089324951
Validation loss: 1.9624581119065643

Epoch: 5| Step: 9
Training loss: 1.6858726739883423
Validation loss: 1.946072369493464

Epoch: 5| Step: 10
Training loss: 2.1984243392944336
Validation loss: 1.9394016035141484

Epoch: 169| Step: 0
Training loss: 2.258044719696045
Validation loss: 1.9664762455929992

Epoch: 5| Step: 1
Training loss: 2.6497817039489746
Validation loss: 1.961355201659664

Epoch: 5| Step: 2
Training loss: 2.6215338706970215
Validation loss: 1.970422980605915

Epoch: 5| Step: 3
Training loss: 2.0213489532470703
Validation loss: 1.949070849726277

Epoch: 5| Step: 4
Training loss: 1.9057064056396484
Validation loss: 1.9631153921927176

Epoch: 5| Step: 5
Training loss: 1.9707664251327515
Validation loss: 1.9431872444768106

Epoch: 5| Step: 6
Training loss: 1.805976152420044
Validation loss: 1.9446632862091064

Epoch: 5| Step: 7
Training loss: 2.1456825733184814
Validation loss: 1.9447499885353992

Epoch: 5| Step: 8
Training loss: 1.6715551614761353
Validation loss: 1.9576339798588906

Epoch: 5| Step: 9
Training loss: 1.6134535074234009
Validation loss: 1.9333004490021737

Epoch: 5| Step: 10
Training loss: 1.9877119064331055
Validation loss: 1.9202889575753161

Epoch: 170| Step: 0
Training loss: 2.180718183517456
Validation loss: 1.9599477911508212

Epoch: 5| Step: 1
Training loss: 1.7837409973144531
Validation loss: 1.9549944887879074

Epoch: 5| Step: 2
Training loss: 2.071300745010376
Validation loss: 1.9543797239180534

Epoch: 5| Step: 3
Training loss: 1.9014663696289062
Validation loss: 1.9572925772718204

Epoch: 5| Step: 4
Training loss: 2.0213115215301514
Validation loss: 1.941604652712422

Epoch: 5| Step: 5
Training loss: 0.6434348821640015
Validation loss: 1.9480937155344153

Epoch: 5| Step: 6
Training loss: 2.708296775817871
Validation loss: 1.9828998273418796

Epoch: 5| Step: 7
Training loss: 1.9001544713974
Validation loss: 1.9477514195185837

Epoch: 5| Step: 8
Training loss: 2.2227540016174316
Validation loss: 1.970281825270704

Epoch: 5| Step: 9
Training loss: 2.8659865856170654
Validation loss: 1.9500791911155946

Epoch: 5| Step: 10
Training loss: 2.4699864387512207
Validation loss: 1.9701418440829042

Epoch: 171| Step: 0
Training loss: 1.6086063385009766
Validation loss: 1.9304734942733601

Epoch: 5| Step: 1
Training loss: 2.2406156063079834
Validation loss: 1.9300813136562225

Epoch: 5| Step: 2
Training loss: 2.203490972518921
Validation loss: 1.9646091897000548

Epoch: 5| Step: 3
Training loss: 1.9231159687042236
Validation loss: 1.9475887539566203

Epoch: 5| Step: 4
Training loss: 2.3222789764404297
Validation loss: 1.942192469873736

Epoch: 5| Step: 5
Training loss: 2.4349398612976074
Validation loss: 1.966933455518497

Epoch: 5| Step: 6
Training loss: 1.955479383468628
Validation loss: 1.9320137064944032

Epoch: 5| Step: 7
Training loss: 1.270166039466858
Validation loss: 1.9559400850726711

Epoch: 5| Step: 8
Training loss: 2.0910398960113525
Validation loss: 1.9684051980254471

Epoch: 5| Step: 9
Training loss: 2.3709495067596436
Validation loss: 1.9447833043272778

Epoch: 5| Step: 10
Training loss: 2.455677032470703
Validation loss: 1.9606576324791036

Epoch: 172| Step: 0
Training loss: 2.0655152797698975
Validation loss: 1.9533834124124179

Epoch: 5| Step: 1
Training loss: 1.8393932580947876
Validation loss: 1.9448569077317432

Epoch: 5| Step: 2
Training loss: 2.1892993450164795
Validation loss: 1.9623231823726366

Epoch: 5| Step: 3
Training loss: 1.8903884887695312
Validation loss: 1.9472436661361365

Epoch: 5| Step: 4
Training loss: 2.2363619804382324
Validation loss: 1.9387747177513697

Epoch: 5| Step: 5
Training loss: 1.7674356698989868
Validation loss: 1.9350297758656163

Epoch: 5| Step: 6
Training loss: 1.842969536781311
Validation loss: 1.9430956302150604

Epoch: 5| Step: 7
Training loss: 1.7266743183135986
Validation loss: 1.9638700895411993

Epoch: 5| Step: 8
Training loss: 2.9342169761657715
Validation loss: 1.9517026203934864

Epoch: 5| Step: 9
Training loss: 1.790069580078125
Validation loss: 1.9277251356391496

Epoch: 5| Step: 10
Training loss: 2.2898709774017334
Validation loss: 1.971164370095858

Epoch: 173| Step: 0
Training loss: 1.83688223361969
Validation loss: 1.9471194218563777

Epoch: 5| Step: 1
Training loss: 2.0417513847351074
Validation loss: 1.9607162167949062

Epoch: 5| Step: 2
Training loss: 2.7879271507263184
Validation loss: 1.9633575318962015

Epoch: 5| Step: 3
Training loss: 1.6946239471435547
Validation loss: 1.9801486717757357

Epoch: 5| Step: 4
Training loss: 1.471709966659546
Validation loss: 1.977882614699743

Epoch: 5| Step: 5
Training loss: 1.7639544010162354
Validation loss: 1.9361099658473846

Epoch: 5| Step: 6
Training loss: 2.0030343532562256
Validation loss: 1.9548927686547721

Epoch: 5| Step: 7
Training loss: 2.773092269897461
Validation loss: 1.961333086413722

Epoch: 5| Step: 8
Training loss: 1.7430918216705322
Validation loss: 1.9514364632227088

Epoch: 5| Step: 9
Training loss: 2.2772128582000732
Validation loss: 1.9428816533857776

Epoch: 5| Step: 10
Training loss: 2.008439302444458
Validation loss: 1.9473964296361452

Epoch: 174| Step: 0
Training loss: 1.8539199829101562
Validation loss: 1.9640197574451406

Epoch: 5| Step: 1
Training loss: 1.912703514099121
Validation loss: 1.9495888371621408

Epoch: 5| Step: 2
Training loss: 1.7803125381469727
Validation loss: 1.948917491461641

Epoch: 5| Step: 3
Training loss: 1.7896732091903687
Validation loss: 1.9491202882541123

Epoch: 5| Step: 4
Training loss: 2.15073823928833
Validation loss: 1.927221308472336

Epoch: 5| Step: 5
Training loss: 2.20467472076416
Validation loss: 1.9518685289608535

Epoch: 5| Step: 6
Training loss: 2.4274678230285645
Validation loss: 1.9227807521820068

Epoch: 5| Step: 7
Training loss: 2.14098858833313
Validation loss: 1.9382113461853356

Epoch: 5| Step: 8
Training loss: 2.4743950366973877
Validation loss: 1.9352527792735765

Epoch: 5| Step: 9
Training loss: 2.282705783843994
Validation loss: 1.9466514638675156

Epoch: 5| Step: 10
Training loss: 1.533948302268982
Validation loss: 1.9447148461495676

Epoch: 175| Step: 0
Training loss: 2.090023994445801
Validation loss: 1.9517227526633971

Epoch: 5| Step: 1
Training loss: 2.8439974784851074
Validation loss: 1.9492489061047953

Epoch: 5| Step: 2
Training loss: 2.1755471229553223
Validation loss: 1.9606167821473972

Epoch: 5| Step: 3
Training loss: 1.6450563669204712
Validation loss: 1.9448318404536094

Epoch: 5| Step: 4
Training loss: 1.9212862253189087
Validation loss: 1.9449575126812022

Epoch: 5| Step: 5
Training loss: 1.8918851613998413
Validation loss: 1.966489217614615

Epoch: 5| Step: 6
Training loss: 1.6725389957427979
Validation loss: 1.9528657723498601

Epoch: 5| Step: 7
Training loss: 2.3026864528656006
Validation loss: 1.9548787045222458

Epoch: 5| Step: 8
Training loss: 2.189326524734497
Validation loss: 1.9666343196745841

Epoch: 5| Step: 9
Training loss: 1.6712818145751953
Validation loss: 1.9547397218724734

Epoch: 5| Step: 10
Training loss: 2.27986741065979
Validation loss: 1.970090086742114

Epoch: 176| Step: 0
Training loss: 2.1314759254455566
Validation loss: 1.9435053974069574

Epoch: 5| Step: 1
Training loss: 2.802748441696167
Validation loss: 1.9652260259915424

Epoch: 5| Step: 2
Training loss: 2.261855363845825
Validation loss: 1.9496569095119354

Epoch: 5| Step: 3
Training loss: 1.4387025833129883
Validation loss: 1.9763210537613078

Epoch: 5| Step: 4
Training loss: 1.5817979574203491
Validation loss: 1.942620970869577

Epoch: 5| Step: 5
Training loss: 1.9424766302108765
Validation loss: 1.9743265785196775

Epoch: 5| Step: 6
Training loss: 1.802956223487854
Validation loss: 1.9383575647108016

Epoch: 5| Step: 7
Training loss: 2.039912462234497
Validation loss: 1.935523320269841

Epoch: 5| Step: 8
Training loss: 2.234238624572754
Validation loss: 1.9632602994159987

Epoch: 5| Step: 9
Training loss: 2.116757869720459
Validation loss: 1.9443014283334055

Epoch: 5| Step: 10
Training loss: 2.1868748664855957
Validation loss: 1.9489179529169554

Epoch: 177| Step: 0
Training loss: 1.9247162342071533
Validation loss: 1.9356697990048317

Epoch: 5| Step: 1
Training loss: 2.166498899459839
Validation loss: 1.941041031191426

Epoch: 5| Step: 2
Training loss: 1.2722896337509155
Validation loss: 1.9385596680384811

Epoch: 5| Step: 3
Training loss: 1.8945211172103882
Validation loss: 1.9317308959140573

Epoch: 5| Step: 4
Training loss: 1.965410828590393
Validation loss: 1.9513206353751562

Epoch: 5| Step: 5
Training loss: 2.6642487049102783
Validation loss: 1.9223983390356905

Epoch: 5| Step: 6
Training loss: 2.3655357360839844
Validation loss: 1.935961038835587

Epoch: 5| Step: 7
Training loss: 2.046970844268799
Validation loss: 1.946273353792006

Epoch: 5| Step: 8
Training loss: 2.228522777557373
Validation loss: 1.9591252265437957

Epoch: 5| Step: 9
Training loss: 1.5885592699050903
Validation loss: 1.9587063840640488

Epoch: 5| Step: 10
Training loss: 2.5023677349090576
Validation loss: 1.9547519094200545

Epoch: 178| Step: 0
Training loss: 2.2270214557647705
Validation loss: 1.9470950941885672

Epoch: 5| Step: 1
Training loss: 2.0398099422454834
Validation loss: 1.9398398501898653

Epoch: 5| Step: 2
Training loss: 2.0360782146453857
Validation loss: 1.9705843412747948

Epoch: 5| Step: 3
Training loss: 1.9203838109970093
Validation loss: 1.9323109401169645

Epoch: 5| Step: 4
Training loss: 2.2245609760284424
Validation loss: 1.9349040177560621

Epoch: 5| Step: 5
Training loss: 2.3389177322387695
Validation loss: 1.9451783498128254

Epoch: 5| Step: 6
Training loss: 1.7130320072174072
Validation loss: 1.9410649371403519

Epoch: 5| Step: 7
Training loss: 1.5598139762878418
Validation loss: 1.945568088562258

Epoch: 5| Step: 8
Training loss: 2.2851502895355225
Validation loss: 1.9636286868843982

Epoch: 5| Step: 9
Training loss: 2.3185126781463623
Validation loss: 1.9384199906420965

Epoch: 5| Step: 10
Training loss: 1.793840765953064
Validation loss: 1.9244105815887451

Epoch: 179| Step: 0
Training loss: 1.9797191619873047
Validation loss: 1.9712961630154682

Epoch: 5| Step: 1
Training loss: 2.3236916065216064
Validation loss: 1.943321781773721

Epoch: 5| Step: 2
Training loss: 1.8325105905532837
Validation loss: 1.9478568133487497

Epoch: 5| Step: 3
Training loss: 1.6012709140777588
Validation loss: 1.9407645848489576

Epoch: 5| Step: 4
Training loss: 2.3774662017822266
Validation loss: 1.955226021428262

Epoch: 5| Step: 5
Training loss: 1.5105135440826416
Validation loss: 1.9357121349662862

Epoch: 5| Step: 6
Training loss: 1.4673340320587158
Validation loss: 1.9575006987458916

Epoch: 5| Step: 7
Training loss: 2.2667059898376465
Validation loss: 1.932209719893753

Epoch: 5| Step: 8
Training loss: 2.5169897079467773
Validation loss: 1.9282418028000863

Epoch: 5| Step: 9
Training loss: 2.1804890632629395
Validation loss: 1.943579932694794

Epoch: 5| Step: 10
Training loss: 2.5457968711853027
Validation loss: 1.9496889575835197

Epoch: 180| Step: 0
Training loss: 2.6594176292419434
Validation loss: 1.9444314843864852

Epoch: 5| Step: 1
Training loss: 2.494168281555176
Validation loss: 1.9449136641717726

Epoch: 5| Step: 2
Training loss: 1.6731408834457397
Validation loss: 1.9715638519615255

Epoch: 5| Step: 3
Training loss: 2.2461934089660645
Validation loss: 1.9453320400689238

Epoch: 5| Step: 4
Training loss: 1.8003482818603516
Validation loss: 1.9499868987708964

Epoch: 5| Step: 5
Training loss: 2.0421645641326904
Validation loss: 1.9612885213667346

Epoch: 5| Step: 6
Training loss: 2.0005903244018555
Validation loss: 1.9480796937019593

Epoch: 5| Step: 7
Training loss: 1.4640545845031738
Validation loss: 1.9709026839143486

Epoch: 5| Step: 8
Training loss: 1.7745481729507446
Validation loss: 1.9446978620303574

Epoch: 5| Step: 9
Training loss: 1.99456787109375
Validation loss: 1.9510009698970343

Epoch: 5| Step: 10
Training loss: 2.1855480670928955
Validation loss: 1.9530005442198886

Epoch: 181| Step: 0
Training loss: 1.5239548683166504
Validation loss: 1.946773898216986

Epoch: 5| Step: 1
Training loss: 2.1409261226654053
Validation loss: 1.9500748367719754

Epoch: 5| Step: 2
Training loss: 1.88162362575531
Validation loss: 1.955873861107775

Epoch: 5| Step: 3
Training loss: 2.3403067588806152
Validation loss: 1.9411775912007978

Epoch: 5| Step: 4
Training loss: 2.2825610637664795
Validation loss: 1.946183185423574

Epoch: 5| Step: 5
Training loss: 2.6786751747131348
Validation loss: 1.9663303026589014

Epoch: 5| Step: 6
Training loss: 1.443170428276062
Validation loss: 1.9476494250759002

Epoch: 5| Step: 7
Training loss: 2.6356053352355957
Validation loss: 1.957957988144249

Epoch: 5| Step: 8
Training loss: 1.7116581201553345
Validation loss: 1.9508816465254752

Epoch: 5| Step: 9
Training loss: 1.7075608968734741
Validation loss: 1.9587002467083674

Epoch: 5| Step: 10
Training loss: 1.91597318649292
Validation loss: 1.9473144751723095

Epoch: 182| Step: 0
Training loss: 2.115752935409546
Validation loss: 1.942606838800574

Epoch: 5| Step: 1
Training loss: 2.8320364952087402
Validation loss: 1.9483653178779028

Epoch: 5| Step: 2
Training loss: 2.042036771774292
Validation loss: 1.9311671500564904

Epoch: 5| Step: 3
Training loss: 2.2281532287597656
Validation loss: 1.9433898310507498

Epoch: 5| Step: 4
Training loss: 1.6345010995864868
Validation loss: 1.9268202576585995

Epoch: 5| Step: 5
Training loss: 2.1500766277313232
Validation loss: 1.944079949009803

Epoch: 5| Step: 6
Training loss: 1.7412694692611694
Validation loss: 1.948191850416122

Epoch: 5| Step: 7
Training loss: 1.617639183998108
Validation loss: 1.9524789138506817

Epoch: 5| Step: 8
Training loss: 2.068988084793091
Validation loss: 1.9477077197003108

Epoch: 5| Step: 9
Training loss: 2.070782423019409
Validation loss: 1.960454883113984

Epoch: 5| Step: 10
Training loss: 1.7984570264816284
Validation loss: 1.931795863695042

Epoch: 183| Step: 0
Training loss: 1.8930137157440186
Validation loss: 1.953700368122388

Epoch: 5| Step: 1
Training loss: 2.0823159217834473
Validation loss: 1.9419093183291856

Epoch: 5| Step: 2
Training loss: 2.2322776317596436
Validation loss: 1.9605124432553527

Epoch: 5| Step: 3
Training loss: 2.486898422241211
Validation loss: 1.9420009531000608

Epoch: 5| Step: 4
Training loss: 1.80615234375
Validation loss: 1.916754912304622

Epoch: 5| Step: 5
Training loss: 2.103325128555298
Validation loss: 1.9317469494317168

Epoch: 5| Step: 6
Training loss: 2.1598868370056152
Validation loss: 1.9366916661621423

Epoch: 5| Step: 7
Training loss: 1.933005690574646
Validation loss: 1.9448988232561337

Epoch: 5| Step: 8
Training loss: 2.2376396656036377
Validation loss: 1.9372954727500997

Epoch: 5| Step: 9
Training loss: 1.6499135494232178
Validation loss: 1.9463440320825065

Epoch: 5| Step: 10
Training loss: 1.8775159120559692
Validation loss: 1.954599577893493

Epoch: 184| Step: 0
Training loss: 2.422788143157959
Validation loss: 1.939876018031951

Epoch: 5| Step: 1
Training loss: 2.8199477195739746
Validation loss: 1.9305893849301081

Epoch: 5| Step: 2
Training loss: 1.436846375465393
Validation loss: 1.9469147138698126

Epoch: 5| Step: 3
Training loss: 1.7952505350112915
Validation loss: 1.9497965997265232

Epoch: 5| Step: 4
Training loss: 2.1818668842315674
Validation loss: 1.9466692786062918

Epoch: 5| Step: 5
Training loss: 2.1314663887023926
Validation loss: 1.9586830292978594

Epoch: 5| Step: 6
Training loss: 2.273207187652588
Validation loss: 1.9322833912346953

Epoch: 5| Step: 7
Training loss: 2.2174575328826904
Validation loss: 1.9610641464110343

Epoch: 5| Step: 8
Training loss: 1.8713051080703735
Validation loss: 1.9484008589098532

Epoch: 5| Step: 9
Training loss: 1.7534677982330322
Validation loss: 1.936666932157291

Epoch: 5| Step: 10
Training loss: 1.3535678386688232
Validation loss: 1.9727057564643122

Epoch: 185| Step: 0
Training loss: 1.9838597774505615
Validation loss: 1.9547161594513924

Epoch: 5| Step: 1
Training loss: 1.571070671081543
Validation loss: 1.9409569591604254

Epoch: 5| Step: 2
Training loss: 1.7597029209136963
Validation loss: 1.9448167944467196

Epoch: 5| Step: 3
Training loss: 2.22649884223938
Validation loss: 1.9488652162654425

Epoch: 5| Step: 4
Training loss: 2.4034759998321533
Validation loss: 1.9671965106841056

Epoch: 5| Step: 5
Training loss: 1.896773338317871
Validation loss: 1.9556307767027168

Epoch: 5| Step: 6
Training loss: 1.774977684020996
Validation loss: 1.9720936077897266

Epoch: 5| Step: 7
Training loss: 2.6138875484466553
Validation loss: 1.9340518982179704

Epoch: 5| Step: 8
Training loss: 2.313586711883545
Validation loss: 1.945429297544623

Epoch: 5| Step: 9
Training loss: 1.8410784006118774
Validation loss: 1.94798872804129

Epoch: 5| Step: 10
Training loss: 1.8271608352661133
Validation loss: 1.9555366885277532

Epoch: 186| Step: 0
Training loss: 2.420257329940796
Validation loss: 1.9361785483616654

Epoch: 5| Step: 1
Training loss: 1.4550583362579346
Validation loss: 1.9588724977226668

Epoch: 5| Step: 2
Training loss: 1.566833734512329
Validation loss: 1.9455607232227121

Epoch: 5| Step: 3
Training loss: 1.9755375385284424
Validation loss: 1.9367058264311923

Epoch: 5| Step: 4
Training loss: 2.158775806427002
Validation loss: 1.9576335312217794

Epoch: 5| Step: 5
Training loss: 2.7392067909240723
Validation loss: 1.9345755756542247

Epoch: 5| Step: 6
Training loss: 2.2743120193481445
Validation loss: 1.9316914491755988

Epoch: 5| Step: 7
Training loss: 1.3097162246704102
Validation loss: 1.9401287622349237

Epoch: 5| Step: 8
Training loss: 2.231724977493286
Validation loss: 1.9292649325504099

Epoch: 5| Step: 9
Training loss: 2.1030454635620117
Validation loss: 1.9579182350507347

Epoch: 5| Step: 10
Training loss: 2.018028497695923
Validation loss: 1.9183633455666163

Epoch: 187| Step: 0
Training loss: 3.2504448890686035
Validation loss: 1.9436592914724862

Epoch: 5| Step: 1
Training loss: 2.1914687156677246
Validation loss: 1.970742226928793

Epoch: 5| Step: 2
Training loss: 1.4688167572021484
Validation loss: 1.940526448270326

Epoch: 5| Step: 3
Training loss: 1.8163702487945557
Validation loss: 1.9607951794901202

Epoch: 5| Step: 4
Training loss: 1.5876424312591553
Validation loss: 1.9304023788821312

Epoch: 5| Step: 5
Training loss: 2.167348623275757
Validation loss: 1.955714774388139

Epoch: 5| Step: 6
Training loss: 1.793895959854126
Validation loss: 1.940306161039619

Epoch: 5| Step: 7
Training loss: 2.137563705444336
Validation loss: 1.92422192840166

Epoch: 5| Step: 8
Training loss: 2.0641233921051025
Validation loss: 1.9378251734600271

Epoch: 5| Step: 9
Training loss: 1.9054067134857178
Validation loss: 1.9347512132378035

Epoch: 5| Step: 10
Training loss: 2.0457217693328857
Validation loss: 1.901938989598264

Epoch: 188| Step: 0
Training loss: 2.152315139770508
Validation loss: 1.945878424952107

Epoch: 5| Step: 1
Training loss: 1.883984923362732
Validation loss: 1.9491874184659732

Epoch: 5| Step: 2
Training loss: 2.14728045463562
Validation loss: 1.935188506239204

Epoch: 5| Step: 3
Training loss: 2.194368839263916
Validation loss: 1.9331478995661582

Epoch: 5| Step: 4
Training loss: 2.265166997909546
Validation loss: 1.9340878827597505

Epoch: 5| Step: 5
Training loss: 1.9774748086929321
Validation loss: 1.9387288529385802

Epoch: 5| Step: 6
Training loss: 1.904088020324707
Validation loss: 1.921223068750033

Epoch: 5| Step: 7
Training loss: 2.0266072750091553
Validation loss: 1.9325813298584313

Epoch: 5| Step: 8
Training loss: 1.7002146244049072
Validation loss: 1.9407252855198358

Epoch: 5| Step: 9
Training loss: 2.2174205780029297
Validation loss: 1.9351938860390776

Epoch: 5| Step: 10
Training loss: 1.7450488805770874
Validation loss: 1.9226720974009524

Epoch: 189| Step: 0
Training loss: 1.7693986892700195
Validation loss: 1.9404335791064846

Epoch: 5| Step: 1
Training loss: 2.276231050491333
Validation loss: 1.9374409580743441

Epoch: 5| Step: 2
Training loss: 2.2771363258361816
Validation loss: 1.9630304946694324

Epoch: 5| Step: 3
Training loss: 1.821279525756836
Validation loss: 1.9325933353875273

Epoch: 5| Step: 4
Training loss: 1.7300516366958618
Validation loss: 1.9659737438283942

Epoch: 5| Step: 5
Training loss: 2.2991247177124023
Validation loss: 1.9636500138108448

Epoch: 5| Step: 6
Training loss: 2.1164538860321045
Validation loss: 1.9506509073318974

Epoch: 5| Step: 7
Training loss: 2.3446593284606934
Validation loss: 1.9652082497073757

Epoch: 5| Step: 8
Training loss: 1.9121789932250977
Validation loss: 1.9652695040549002

Epoch: 5| Step: 9
Training loss: 2.399805784225464
Validation loss: 1.9228210795310237

Epoch: 5| Step: 10
Training loss: 1.2942230701446533
Validation loss: 1.943396524716449

Epoch: 190| Step: 0
Training loss: 2.5714001655578613
Validation loss: 1.9454466630053777

Epoch: 5| Step: 1
Training loss: 2.1390721797943115
Validation loss: 1.927116742698095

Epoch: 5| Step: 2
Training loss: 1.7931010723114014
Validation loss: 1.9449897978895454

Epoch: 5| Step: 3
Training loss: 2.0565476417541504
Validation loss: 1.914002804345982

Epoch: 5| Step: 4
Training loss: 1.972898244857788
Validation loss: 1.939622220172677

Epoch: 5| Step: 5
Training loss: 2.0190351009368896
Validation loss: 1.932338910718118

Epoch: 5| Step: 6
Training loss: 1.7232778072357178
Validation loss: 1.9415565806050454

Epoch: 5| Step: 7
Training loss: 2.169678211212158
Validation loss: 1.9349259150925504

Epoch: 5| Step: 8
Training loss: 1.1177788972854614
Validation loss: 1.9408495682542042

Epoch: 5| Step: 9
Training loss: 2.517871379852295
Validation loss: 1.9503509485593407

Epoch: 5| Step: 10
Training loss: 2.092923164367676
Validation loss: 1.94027340796686

Epoch: 191| Step: 0
Training loss: 1.0988004207611084
Validation loss: 1.933547104558637

Epoch: 5| Step: 1
Training loss: 2.4140896797180176
Validation loss: 1.9124475166361818

Epoch: 5| Step: 2
Training loss: 1.9930822849273682
Validation loss: 1.9427758827004382

Epoch: 5| Step: 3
Training loss: 1.8593971729278564
Validation loss: 1.9441739410482428

Epoch: 5| Step: 4
Training loss: 2.0216684341430664
Validation loss: 1.951405591862176

Epoch: 5| Step: 5
Training loss: 2.033609628677368
Validation loss: 1.9415979334103164

Epoch: 5| Step: 6
Training loss: 2.3982338905334473
Validation loss: 1.9607412738184775

Epoch: 5| Step: 7
Training loss: 2.016857624053955
Validation loss: 1.9441521270300752

Epoch: 5| Step: 8
Training loss: 2.4513111114501953
Validation loss: 1.9362065484446864

Epoch: 5| Step: 9
Training loss: 1.9567235708236694
Validation loss: 1.9406268942740657

Epoch: 5| Step: 10
Training loss: 1.9837628602981567
Validation loss: 1.94742497064734

Epoch: 192| Step: 0
Training loss: 2.2186498641967773
Validation loss: 1.9571086745108328

Epoch: 5| Step: 1
Training loss: 2.380420207977295
Validation loss: 1.9586658836692892

Epoch: 5| Step: 2
Training loss: 1.5944668054580688
Validation loss: 1.93851758844109

Epoch: 5| Step: 3
Training loss: 1.6394907236099243
Validation loss: 1.9416676977629304

Epoch: 5| Step: 4
Training loss: 1.8918787240982056
Validation loss: 1.9106154390560683

Epoch: 5| Step: 5
Training loss: 1.8157364130020142
Validation loss: 1.944822601092759

Epoch: 5| Step: 6
Training loss: 2.136676549911499
Validation loss: 1.9439035448976743

Epoch: 5| Step: 7
Training loss: 2.159036159515381
Validation loss: 1.9570678600700953

Epoch: 5| Step: 8
Training loss: 2.130164384841919
Validation loss: 1.930120155375491

Epoch: 5| Step: 9
Training loss: 1.7507450580596924
Validation loss: 1.96340355437289

Epoch: 5| Step: 10
Training loss: 2.4434595108032227
Validation loss: 1.9325148572203934

Epoch: 193| Step: 0
Training loss: 1.6646215915679932
Validation loss: 1.9120379737628403

Epoch: 5| Step: 1
Training loss: 1.9425569772720337
Validation loss: 1.9589928324504564

Epoch: 5| Step: 2
Training loss: 1.8465713262557983
Validation loss: 1.9324579815710745

Epoch: 5| Step: 3
Training loss: 1.5484867095947266
Validation loss: 1.960094258349429

Epoch: 5| Step: 4
Training loss: 1.7620055675506592
Validation loss: 1.9437637700829455

Epoch: 5| Step: 5
Training loss: 2.127800703048706
Validation loss: 1.9400889668413388

Epoch: 5| Step: 6
Training loss: 2.1624457836151123
Validation loss: 1.928301247217322

Epoch: 5| Step: 7
Training loss: 2.3363547325134277
Validation loss: 1.9489274281327442

Epoch: 5| Step: 8
Training loss: 2.201571464538574
Validation loss: 1.9634487295663485

Epoch: 5| Step: 9
Training loss: 1.89224112033844
Validation loss: 1.9285709806667861

Epoch: 5| Step: 10
Training loss: 2.623478412628174
Validation loss: 1.9408944883654196

Epoch: 194| Step: 0
Training loss: 1.8247648477554321
Validation loss: 1.9353487248061805

Epoch: 5| Step: 1
Training loss: 2.586310863494873
Validation loss: 1.932284644854966

Epoch: 5| Step: 2
Training loss: 1.7478443384170532
Validation loss: 1.9412971863182642

Epoch: 5| Step: 3
Training loss: 2.110044240951538
Validation loss: 1.9194165250306487

Epoch: 5| Step: 4
Training loss: 2.094686508178711
Validation loss: 1.958730500231507

Epoch: 5| Step: 5
Training loss: 1.9959112405776978
Validation loss: 1.9423391780545634

Epoch: 5| Step: 6
Training loss: 1.4596880674362183
Validation loss: 1.9650044005404237

Epoch: 5| Step: 7
Training loss: 1.5978200435638428
Validation loss: 1.9387724707203526

Epoch: 5| Step: 8
Training loss: 2.7414488792419434
Validation loss: 1.9494281071488575

Epoch: 5| Step: 9
Training loss: 1.6853981018066406
Validation loss: 1.939582661915851

Epoch: 5| Step: 10
Training loss: 2.314286947250366
Validation loss: 1.943053025071339

Epoch: 195| Step: 0
Training loss: 2.3010833263397217
Validation loss: 1.9418015890224005

Epoch: 5| Step: 1
Training loss: 1.9763389825820923
Validation loss: 1.9224915863365255

Epoch: 5| Step: 2
Training loss: 1.6896473169326782
Validation loss: 1.9323267834160918

Epoch: 5| Step: 3
Training loss: 1.662487268447876
Validation loss: 1.9501324853589457

Epoch: 5| Step: 4
Training loss: 2.1495537757873535
Validation loss: 1.953312115002704

Epoch: 5| Step: 5
Training loss: 1.866398811340332
Validation loss: 1.9146218094774472

Epoch: 5| Step: 6
Training loss: 2.114337682723999
Validation loss: 1.9465101047228741

Epoch: 5| Step: 7
Training loss: 1.5801507234573364
Validation loss: 1.9284204744523572

Epoch: 5| Step: 8
Training loss: 2.774620532989502
Validation loss: 1.949184303642601

Epoch: 5| Step: 9
Training loss: 1.7698482275009155
Validation loss: 1.9403731771694717

Epoch: 5| Step: 10
Training loss: 1.9238957166671753
Validation loss: 1.9203390113769039

Epoch: 196| Step: 0
Training loss: 1.5719053745269775
Validation loss: 1.9488833360774542

Epoch: 5| Step: 1
Training loss: 1.958734154701233
Validation loss: 1.960567388483273

Epoch: 5| Step: 2
Training loss: 2.735273838043213
Validation loss: 1.9260833583852297

Epoch: 5| Step: 3
Training loss: 2.054966926574707
Validation loss: 1.9232441097177484

Epoch: 5| Step: 4
Training loss: 1.325613260269165
Validation loss: 1.9228490065502863

Epoch: 5| Step: 5
Training loss: 2.0347557067871094
Validation loss: 1.9311290043656544

Epoch: 5| Step: 6
Training loss: 1.875896692276001
Validation loss: 1.9265788960200485

Epoch: 5| Step: 7
Training loss: 1.8831260204315186
Validation loss: 1.9500223372572212

Epoch: 5| Step: 8
Training loss: 1.970899224281311
Validation loss: 1.92566987006895

Epoch: 5| Step: 9
Training loss: 2.3926875591278076
Validation loss: 1.9209877649943035

Epoch: 5| Step: 10
Training loss: 2.2705202102661133
Validation loss: 1.9337022355807725

Epoch: 197| Step: 0
Training loss: 2.1597084999084473
Validation loss: 1.9387339866289528

Epoch: 5| Step: 1
Training loss: 2.2263381481170654
Validation loss: 1.934063603801112

Epoch: 5| Step: 2
Training loss: 2.2703194618225098
Validation loss: 1.9255944246886878

Epoch: 5| Step: 3
Training loss: 2.1800649166107178
Validation loss: 1.9292984880426878

Epoch: 5| Step: 4
Training loss: 1.750915765762329
Validation loss: 1.9597812301369124

Epoch: 5| Step: 5
Training loss: 1.9135162830352783
Validation loss: 1.9347959897851432

Epoch: 5| Step: 6
Training loss: 1.6407455205917358
Validation loss: 1.9564601811029578

Epoch: 5| Step: 7
Training loss: 2.0611822605133057
Validation loss: 1.9607504003791398

Epoch: 5| Step: 8
Training loss: 2.1437828540802
Validation loss: 1.9394482669009958

Epoch: 5| Step: 9
Training loss: 1.5017167329788208
Validation loss: 1.9415319901640697

Epoch: 5| Step: 10
Training loss: 2.0247108936309814
Validation loss: 1.9354313188983547

Epoch: 198| Step: 0
Training loss: 1.8944154977798462
Validation loss: 1.95132871853408

Epoch: 5| Step: 1
Training loss: 1.5393792390823364
Validation loss: 1.9479366028180687

Epoch: 5| Step: 2
Training loss: 1.4341578483581543
Validation loss: 1.956328124128362

Epoch: 5| Step: 3
Training loss: 1.8159751892089844
Validation loss: 1.9459546868519118

Epoch: 5| Step: 4
Training loss: 1.729183554649353
Validation loss: 1.9476171091038694

Epoch: 5| Step: 5
Training loss: 2.6709048748016357
Validation loss: 1.9458290607698503

Epoch: 5| Step: 6
Training loss: 2.1290926933288574
Validation loss: 1.923441397246494

Epoch: 5| Step: 7
Training loss: 2.2046446800231934
Validation loss: 1.9162518683300223

Epoch: 5| Step: 8
Training loss: 1.296248197555542
Validation loss: 1.930838902791341

Epoch: 5| Step: 9
Training loss: 2.231104850769043
Validation loss: 1.9202525590055732

Epoch: 5| Step: 10
Training loss: 3.0631885528564453
Validation loss: 1.9537173060960666

Epoch: 199| Step: 0
Training loss: 1.9210147857666016
Validation loss: 1.9444117417899511

Epoch: 5| Step: 1
Training loss: 1.8001213073730469
Validation loss: 1.9228304970648982

Epoch: 5| Step: 2
Training loss: 2.307121753692627
Validation loss: 1.9520284155363679

Epoch: 5| Step: 3
Training loss: 2.335082530975342
Validation loss: 1.939468006933889

Epoch: 5| Step: 4
Training loss: 2.403738260269165
Validation loss: 1.9672665583190097

Epoch: 5| Step: 5
Training loss: 1.779341459274292
Validation loss: 1.9210210179769864

Epoch: 5| Step: 6
Training loss: 1.6495888233184814
Validation loss: 1.9530645724265807

Epoch: 5| Step: 7
Training loss: 1.8751001358032227
Validation loss: 1.9386301232922463

Epoch: 5| Step: 8
Training loss: 1.2755722999572754
Validation loss: 1.9137014381347164

Epoch: 5| Step: 9
Training loss: 2.2644639015197754
Validation loss: 1.9402528488507835

Epoch: 5| Step: 10
Training loss: 2.4423255920410156
Validation loss: 1.941243121700902

Epoch: 200| Step: 0
Training loss: 1.9321496486663818
Validation loss: 1.9448235393852316

Epoch: 5| Step: 1
Training loss: 2.421262264251709
Validation loss: 1.9355240329619376

Epoch: 5| Step: 2
Training loss: 1.747870683670044
Validation loss: 1.908280671283763

Epoch: 5| Step: 3
Training loss: 1.5878795385360718
Validation loss: 1.9464508551423267

Epoch: 5| Step: 4
Training loss: 2.344412326812744
Validation loss: 1.9272776047388713

Epoch: 5| Step: 5
Training loss: 1.9378677606582642
Validation loss: 1.968636143592096

Epoch: 5| Step: 6
Training loss: 1.8939403295516968
Validation loss: 1.9149742793011408

Epoch: 5| Step: 7
Training loss: 2.0527377128601074
Validation loss: 1.9120907245143768

Epoch: 5| Step: 8
Training loss: 2.05004620552063
Validation loss: 1.937137597350664

Epoch: 5| Step: 9
Training loss: 1.8944965600967407
Validation loss: 1.9322868906041628

Epoch: 5| Step: 10
Training loss: 2.000307559967041
Validation loss: 1.9177214932698075

Epoch: 201| Step: 0
Training loss: 1.7433736324310303
Validation loss: 1.9078941550306094

Epoch: 5| Step: 1
Training loss: 2.842928409576416
Validation loss: 1.932385862514537

Epoch: 5| Step: 2
Training loss: 1.640951156616211
Validation loss: 1.9252296955354753

Epoch: 5| Step: 3
Training loss: 1.5152021646499634
Validation loss: 1.9475766125545706

Epoch: 5| Step: 4
Training loss: 1.5830775499343872
Validation loss: 1.9153185723930277

Epoch: 5| Step: 5
Training loss: 1.8888555765151978
Validation loss: 1.9278896188223233

Epoch: 5| Step: 6
Training loss: 1.658707618713379
Validation loss: 1.9355768247317242

Epoch: 5| Step: 7
Training loss: 2.5104193687438965
Validation loss: 1.9445680392685758

Epoch: 5| Step: 8
Training loss: 1.9168927669525146
Validation loss: 1.9309002378935456

Epoch: 5| Step: 9
Training loss: 2.820181131362915
Validation loss: 1.939885868821093

Epoch: 5| Step: 10
Training loss: 1.7698887586593628
Validation loss: 1.9312354287793558

Epoch: 202| Step: 0
Training loss: 1.982013463973999
Validation loss: 1.9238882577547463

Epoch: 5| Step: 1
Training loss: 2.165689468383789
Validation loss: 1.9406609073761971

Epoch: 5| Step: 2
Training loss: 1.7063837051391602
Validation loss: 1.9373197529905586

Epoch: 5| Step: 3
Training loss: 2.197445869445801
Validation loss: 1.936096881025581

Epoch: 5| Step: 4
Training loss: 2.4409210681915283
Validation loss: 1.9416143291740007

Epoch: 5| Step: 5
Training loss: 1.875653862953186
Validation loss: 1.9372846977685088

Epoch: 5| Step: 6
Training loss: 1.9427837133407593
Validation loss: 1.9140379915955246

Epoch: 5| Step: 7
Training loss: 1.3818789720535278
Validation loss: 1.9277469970846688

Epoch: 5| Step: 8
Training loss: 2.1108551025390625
Validation loss: 1.9408213118071198

Epoch: 5| Step: 9
Training loss: 1.9865375757217407
Validation loss: 1.9183758433147142

Epoch: 5| Step: 10
Training loss: 2.2306718826293945
Validation loss: 1.9402984188448997

Epoch: 203| Step: 0
Training loss: 2.0955421924591064
Validation loss: 1.9596860511328584

Epoch: 5| Step: 1
Training loss: 2.565800905227661
Validation loss: 1.9436508891403035

Epoch: 5| Step: 2
Training loss: 1.4526664018630981
Validation loss: 1.9242070926133024

Epoch: 5| Step: 3
Training loss: 1.9814599752426147
Validation loss: 1.9347277918169576

Epoch: 5| Step: 4
Training loss: 2.381333827972412
Validation loss: 1.9386455717907156

Epoch: 5| Step: 5
Training loss: 1.7202327251434326
Validation loss: 1.9314172985733196

Epoch: 5| Step: 6
Training loss: 2.0955581665039062
Validation loss: 1.9213131076546126

Epoch: 5| Step: 7
Training loss: 1.5716865062713623
Validation loss: 1.941706334390948

Epoch: 5| Step: 8
Training loss: 1.888684630393982
Validation loss: 1.9391090921176377

Epoch: 5| Step: 9
Training loss: 2.059994697570801
Validation loss: 1.9434927919859528

Epoch: 5| Step: 10
Training loss: 2.0646426677703857
Validation loss: 1.9571661436429588

Epoch: 204| Step: 0
Training loss: 1.99224853515625
Validation loss: 1.920501470565796

Epoch: 5| Step: 1
Training loss: 2.6288163661956787
Validation loss: 1.9540242674530193

Epoch: 5| Step: 2
Training loss: 2.4651451110839844
Validation loss: 1.9445880074654855

Epoch: 5| Step: 3
Training loss: 2.2235748767852783
Validation loss: 1.9550951578283822

Epoch: 5| Step: 4
Training loss: 1.5268213748931885
Validation loss: 1.9556755827319237

Epoch: 5| Step: 5
Training loss: 1.8742053508758545
Validation loss: 1.9372064272562664

Epoch: 5| Step: 6
Training loss: 1.9116767644882202
Validation loss: 1.9434127448707499

Epoch: 5| Step: 7
Training loss: 2.1100172996520996
Validation loss: 1.9227249545435752

Epoch: 5| Step: 8
Training loss: 1.8562723398208618
Validation loss: 1.944026271502177

Epoch: 5| Step: 9
Training loss: 1.4302427768707275
Validation loss: 1.9294261573463358

Epoch: 5| Step: 10
Training loss: 1.7813918590545654
Validation loss: 1.9175938124297767

Epoch: 205| Step: 0
Training loss: 2.434762716293335
Validation loss: 1.945133400219743

Epoch: 5| Step: 1
Training loss: 1.893437147140503
Validation loss: 1.9291966012729111

Epoch: 5| Step: 2
Training loss: 1.4890817403793335
Validation loss: 1.9304645522948234

Epoch: 5| Step: 3
Training loss: 2.168795347213745
Validation loss: 1.9289764332514938

Epoch: 5| Step: 4
Training loss: 2.5508511066436768
Validation loss: 1.9514942822917816

Epoch: 5| Step: 5
Training loss: 1.5489585399627686
Validation loss: 1.9535026729747813

Epoch: 5| Step: 6
Training loss: 1.7596609592437744
Validation loss: 1.9223240229391283

Epoch: 5| Step: 7
Training loss: 2.0638835430145264
Validation loss: 1.9383725414993942

Epoch: 5| Step: 8
Training loss: 2.252946376800537
Validation loss: 1.9126077608395649

Epoch: 5| Step: 9
Training loss: 2.046253204345703
Validation loss: 1.9565783700635355

Epoch: 5| Step: 10
Training loss: 1.3804521560668945
Validation loss: 1.9432726906191917

Epoch: 206| Step: 0
Training loss: 2.162240743637085
Validation loss: 1.9415372174273255

Epoch: 5| Step: 1
Training loss: 1.5594944953918457
Validation loss: 1.9333268160461097

Epoch: 5| Step: 2
Training loss: 1.7147786617279053
Validation loss: 1.9420043486420826

Epoch: 5| Step: 3
Training loss: 2.3228037357330322
Validation loss: 1.9418739913612284

Epoch: 5| Step: 4
Training loss: 1.4813387393951416
Validation loss: 1.9539820442917526

Epoch: 5| Step: 5
Training loss: 2.0624868869781494
Validation loss: 1.9373548799945461

Epoch: 5| Step: 6
Training loss: 2.2381489276885986
Validation loss: 1.953586406605218

Epoch: 5| Step: 7
Training loss: 1.4198988676071167
Validation loss: 1.9497032319345782

Epoch: 5| Step: 8
Training loss: 2.131883144378662
Validation loss: 1.9422155644304009

Epoch: 5| Step: 9
Training loss: 2.4236981868743896
Validation loss: 1.9445389650201286

Epoch: 5| Step: 10
Training loss: 2.125065803527832
Validation loss: 1.9636564241942538

Epoch: 207| Step: 0
Training loss: 1.8350566625595093
Validation loss: 1.9183548445342689

Epoch: 5| Step: 1
Training loss: 1.5993191003799438
Validation loss: 1.9430295575049616

Epoch: 5| Step: 2
Training loss: 2.3774189949035645
Validation loss: 1.9244961559131581

Epoch: 5| Step: 3
Training loss: 1.6798746585845947
Validation loss: 1.9439378194911505

Epoch: 5| Step: 4
Training loss: 1.7663249969482422
Validation loss: 1.936696183296942

Epoch: 5| Step: 5
Training loss: 2.036623239517212
Validation loss: 1.9297738844348538

Epoch: 5| Step: 6
Training loss: 1.9965152740478516
Validation loss: 1.9195959093750163

Epoch: 5| Step: 7
Training loss: 1.8117729425430298
Validation loss: 1.9187041559526998

Epoch: 5| Step: 8
Training loss: 2.0057106018066406
Validation loss: 1.9229670660470122

Epoch: 5| Step: 9
Training loss: 2.1791129112243652
Validation loss: 1.9304265668315272

Epoch: 5| Step: 10
Training loss: 2.321284055709839
Validation loss: 1.9230715203028854

Epoch: 208| Step: 0
Training loss: 1.488112449645996
Validation loss: 1.9304300251827444

Epoch: 5| Step: 1
Training loss: 1.7745897769927979
Validation loss: 1.9264641487470238

Epoch: 5| Step: 2
Training loss: 1.7353252172470093
Validation loss: 1.9359895849740634

Epoch: 5| Step: 3
Training loss: 2.2284018993377686
Validation loss: 1.929325012750523

Epoch: 5| Step: 4
Training loss: 2.3478899002075195
Validation loss: 1.9269122026299919

Epoch: 5| Step: 5
Training loss: 1.988181471824646
Validation loss: 1.918996085402786

Epoch: 5| Step: 6
Training loss: 2.3275468349456787
Validation loss: 1.9459750293403544

Epoch: 5| Step: 7
Training loss: 2.18497896194458
Validation loss: 1.921872228704473

Epoch: 5| Step: 8
Training loss: 1.8351541757583618
Validation loss: 1.9485849180529196

Epoch: 5| Step: 9
Training loss: 1.9823246002197266
Validation loss: 1.9533812717724872

Epoch: 5| Step: 10
Training loss: 1.748016119003296
Validation loss: 1.9240138261548934

Epoch: 209| Step: 0
Training loss: 1.6906144618988037
Validation loss: 1.9354180930763163

Epoch: 5| Step: 1
Training loss: 1.6739267110824585
Validation loss: 1.9466969236250846

Epoch: 5| Step: 2
Training loss: 1.5772231817245483
Validation loss: 1.904952984984203

Epoch: 5| Step: 3
Training loss: 2.323363780975342
Validation loss: 1.9418197857436312

Epoch: 5| Step: 4
Training loss: 2.401869297027588
Validation loss: 1.9338308803496822

Epoch: 5| Step: 5
Training loss: 1.7479509115219116
Validation loss: 1.9193964132698633

Epoch: 5| Step: 6
Training loss: 2.3960742950439453
Validation loss: 1.950277627155345

Epoch: 5| Step: 7
Training loss: 1.8053690195083618
Validation loss: 1.9596573024667718

Epoch: 5| Step: 8
Training loss: 1.7744171619415283
Validation loss: 1.9349229617785382

Epoch: 5| Step: 9
Training loss: 2.20619535446167
Validation loss: 1.9359684144296954

Epoch: 5| Step: 10
Training loss: 1.935237169265747
Validation loss: 1.9429453111463977

Epoch: 210| Step: 0
Training loss: 1.8792188167572021
Validation loss: 1.9086780522459297

Epoch: 5| Step: 1
Training loss: 1.9387906789779663
Validation loss: 1.9286315902586906

Epoch: 5| Step: 2
Training loss: 1.7553317546844482
Validation loss: 1.9490548436359694

Epoch: 5| Step: 3
Training loss: 2.1661739349365234
Validation loss: 1.921014924203196

Epoch: 5| Step: 4
Training loss: 1.5889941453933716
Validation loss: 1.9348925044459682

Epoch: 5| Step: 5
Training loss: 2.4599342346191406
Validation loss: 1.9311096975880284

Epoch: 5| Step: 6
Training loss: 2.3576247692108154
Validation loss: 1.9307238491632606

Epoch: 5| Step: 7
Training loss: 2.0028042793273926
Validation loss: 1.9385469805809759

Epoch: 5| Step: 8
Training loss: 2.6223018169403076
Validation loss: 1.9276814512027207

Epoch: 5| Step: 9
Training loss: 1.365992784500122
Validation loss: 1.9303891517782723

Epoch: 5| Step: 10
Training loss: 1.375057578086853
Validation loss: 1.9498817971957627

Epoch: 211| Step: 0
Training loss: 1.5861793756484985
Validation loss: 1.9412133462967411

Epoch: 5| Step: 1
Training loss: 1.8457950353622437
Validation loss: 1.9573830776317145

Epoch: 5| Step: 2
Training loss: 1.6327394247055054
Validation loss: 1.92447425857667

Epoch: 5| Step: 3
Training loss: 2.0921061038970947
Validation loss: 1.9347122933274956

Epoch: 5| Step: 4
Training loss: 1.7335411310195923
Validation loss: 1.919798953558809

Epoch: 5| Step: 5
Training loss: 2.7101008892059326
Validation loss: 1.9220525205776255

Epoch: 5| Step: 6
Training loss: 1.9171825647354126
Validation loss: 1.936810367850847

Epoch: 5| Step: 7
Training loss: 1.5327013731002808
Validation loss: 1.9367581003455705

Epoch: 5| Step: 8
Training loss: 2.0412042140960693
Validation loss: 1.9286477296583113

Epoch: 5| Step: 9
Training loss: 2.036076068878174
Validation loss: 1.9450552437895088

Epoch: 5| Step: 10
Training loss: 2.46283221244812
Validation loss: 1.9221351121061592

Epoch: 212| Step: 0
Training loss: 1.929419755935669
Validation loss: 1.9150482582789596

Epoch: 5| Step: 1
Training loss: 2.402899980545044
Validation loss: 1.9450409066292547

Epoch: 5| Step: 2
Training loss: 1.8741973638534546
Validation loss: 1.9337142795644782

Epoch: 5| Step: 3
Training loss: 1.791038155555725
Validation loss: 1.9235183936293407

Epoch: 5| Step: 4
Training loss: 2.2681403160095215
Validation loss: 1.922953644106465

Epoch: 5| Step: 5
Training loss: 2.0356669425964355
Validation loss: 1.970685435879615

Epoch: 5| Step: 6
Training loss: 1.9990171194076538
Validation loss: 1.9240523346008793

Epoch: 5| Step: 7
Training loss: 2.4701132774353027
Validation loss: 1.9375194349596578

Epoch: 5| Step: 8
Training loss: 1.6964054107666016
Validation loss: 1.9395859472213253

Epoch: 5| Step: 9
Training loss: 1.4500871896743774
Validation loss: 1.9395261541489632

Epoch: 5| Step: 10
Training loss: 1.4460265636444092
Validation loss: 1.9247125066736692

Epoch: 213| Step: 0
Training loss: 1.4972656965255737
Validation loss: 1.923726556121662

Epoch: 5| Step: 1
Training loss: 1.6532806158065796
Validation loss: 1.9323212792796474

Epoch: 5| Step: 2
Training loss: 1.7555423974990845
Validation loss: 1.9354415260335451

Epoch: 5| Step: 3
Training loss: 2.433131694793701
Validation loss: 1.905824101099404

Epoch: 5| Step: 4
Training loss: 1.9959309101104736
Validation loss: 1.9505684452672158

Epoch: 5| Step: 5
Training loss: 1.8544994592666626
Validation loss: 1.938551566934073

Epoch: 5| Step: 6
Training loss: 2.2504310607910156
Validation loss: 1.922443474492719

Epoch: 5| Step: 7
Training loss: 1.6983085870742798
Validation loss: 1.900328907915341

Epoch: 5| Step: 8
Training loss: 1.547121286392212
Validation loss: 1.8920086635056363

Epoch: 5| Step: 9
Training loss: 2.3599941730499268
Validation loss: 1.9302361024323331

Epoch: 5| Step: 10
Training loss: 2.7068119049072266
Validation loss: 1.9352777850243352

Epoch: 214| Step: 0
Training loss: 2.1142592430114746
Validation loss: 1.9261179611247072

Epoch: 5| Step: 1
Training loss: 2.0197339057922363
Validation loss: 1.9294579362356534

Epoch: 5| Step: 2
Training loss: 1.9183924198150635
Validation loss: 1.9223746509962185

Epoch: 5| Step: 3
Training loss: 1.941878080368042
Validation loss: 1.9047926651534213

Epoch: 5| Step: 4
Training loss: 2.3360276222229004
Validation loss: 1.9212920024830809

Epoch: 5| Step: 5
Training loss: 1.922637939453125
Validation loss: 1.91110727735745

Epoch: 5| Step: 6
Training loss: 2.131462574005127
Validation loss: 1.9132286630651003

Epoch: 5| Step: 7
Training loss: 2.2901461124420166
Validation loss: 1.9267484705935243

Epoch: 5| Step: 8
Training loss: 1.402921199798584
Validation loss: 1.9201419750849407

Epoch: 5| Step: 9
Training loss: 1.8353675603866577
Validation loss: 1.9191373599472867

Epoch: 5| Step: 10
Training loss: 1.5804904699325562
Validation loss: 1.9239542151010165

Epoch: 215| Step: 0
Training loss: 2.028757095336914
Validation loss: 1.9054274200111307

Epoch: 5| Step: 1
Training loss: 2.2739381790161133
Validation loss: 1.9206782053875666

Epoch: 5| Step: 2
Training loss: 2.042060136795044
Validation loss: 1.9105656877640755

Epoch: 5| Step: 3
Training loss: 1.5133962631225586
Validation loss: 1.8946651335685485

Epoch: 5| Step: 4
Training loss: 2.773723602294922
Validation loss: 1.9346728401799356

Epoch: 5| Step: 5
Training loss: 1.4304592609405518
Validation loss: 1.9217032360774216

Epoch: 5| Step: 6
Training loss: 1.4773838520050049
Validation loss: 1.9147535959879558

Epoch: 5| Step: 7
Training loss: 2.416533946990967
Validation loss: 1.9468785524368286

Epoch: 5| Step: 8
Training loss: 1.7837117910385132
Validation loss: 1.9262834800186979

Epoch: 5| Step: 9
Training loss: 1.6150001287460327
Validation loss: 1.943180581574799

Epoch: 5| Step: 10
Training loss: 2.1448283195495605
Validation loss: 1.9527621307680685

Epoch: 216| Step: 0
Training loss: 2.032820224761963
Validation loss: 1.9178245464960735

Epoch: 5| Step: 1
Training loss: 2.408848762512207
Validation loss: 1.941472299637333

Epoch: 5| Step: 2
Training loss: 2.1583709716796875
Validation loss: 1.9209030699986283

Epoch: 5| Step: 3
Training loss: 1.2489618062973022
Validation loss: 1.910896760161205

Epoch: 5| Step: 4
Training loss: 1.9172557592391968
Validation loss: 1.9372523484691497

Epoch: 5| Step: 5
Training loss: 1.3414767980575562
Validation loss: 1.9109320614927559

Epoch: 5| Step: 6
Training loss: 2.010129451751709
Validation loss: 1.9640972447651688

Epoch: 5| Step: 7
Training loss: 1.8610508441925049
Validation loss: 1.9316942179074852

Epoch: 5| Step: 8
Training loss: 2.1746721267700195
Validation loss: 1.9137911386387323

Epoch: 5| Step: 9
Training loss: 1.9534600973129272
Validation loss: 1.9117450624383905

Epoch: 5| Step: 10
Training loss: 2.1652655601501465
Validation loss: 1.935589486552823

Epoch: 217| Step: 0
Training loss: 2.3966920375823975
Validation loss: 1.9274637609399774

Epoch: 5| Step: 1
Training loss: 2.4510254859924316
Validation loss: 1.9506940649401756

Epoch: 5| Step: 2
Training loss: 2.5699944496154785
Validation loss: 1.949165444220266

Epoch: 5| Step: 3
Training loss: 2.0231821537017822
Validation loss: 1.9190810495807278

Epoch: 5| Step: 4
Training loss: 2.061840534210205
Validation loss: 1.9213630948015439

Epoch: 5| Step: 5
Training loss: 1.2863388061523438
Validation loss: 1.968777766791723

Epoch: 5| Step: 6
Training loss: 1.6786420345306396
Validation loss: 1.943546882239721

Epoch: 5| Step: 7
Training loss: 2.30916166305542
Validation loss: 1.9308202215420303

Epoch: 5| Step: 8
Training loss: 1.5325264930725098
Validation loss: 1.9252262871752504

Epoch: 5| Step: 9
Training loss: 1.4185038805007935
Validation loss: 1.9423790131845782

Epoch: 5| Step: 10
Training loss: 1.567165493965149
Validation loss: 1.9391600867753387

Epoch: 218| Step: 0
Training loss: 2.363093852996826
Validation loss: 1.9307187475183958

Epoch: 5| Step: 1
Training loss: 1.5653228759765625
Validation loss: 1.9189513127009075

Epoch: 5| Step: 2
Training loss: 2.3070530891418457
Validation loss: 1.93918231866693

Epoch: 5| Step: 3
Training loss: 2.261944055557251
Validation loss: 1.9190634463423042

Epoch: 5| Step: 4
Training loss: 1.7303314208984375
Validation loss: 1.9455278304315382

Epoch: 5| Step: 5
Training loss: 1.847768783569336
Validation loss: 1.91789964706667

Epoch: 5| Step: 6
Training loss: 1.694801926612854
Validation loss: 1.9539387661923644

Epoch: 5| Step: 7
Training loss: 1.6818243265151978
Validation loss: 1.8907048202330066

Epoch: 5| Step: 8
Training loss: 2.39762544631958
Validation loss: 1.9213751721125778

Epoch: 5| Step: 9
Training loss: 1.662295937538147
Validation loss: 1.920445449890629

Epoch: 5| Step: 10
Training loss: 1.6759686470031738
Validation loss: 1.9279289335332892

Epoch: 219| Step: 0
Training loss: 1.716909408569336
Validation loss: 1.911299987505841

Epoch: 5| Step: 1
Training loss: 1.4368422031402588
Validation loss: 1.9242945448044808

Epoch: 5| Step: 2
Training loss: 2.3335444927215576
Validation loss: 1.9353547134707052

Epoch: 5| Step: 3
Training loss: 2.3111743927001953
Validation loss: 1.9181303593420214

Epoch: 5| Step: 4
Training loss: 2.626366376876831
Validation loss: 1.9294483892379268

Epoch: 5| Step: 5
Training loss: 2.203476667404175
Validation loss: 1.9205628800135788

Epoch: 5| Step: 6
Training loss: 1.7066246271133423
Validation loss: 1.922205707078339

Epoch: 5| Step: 7
Training loss: 1.5385611057281494
Validation loss: 1.9235679052209342

Epoch: 5| Step: 8
Training loss: 1.5320934057235718
Validation loss: 1.903493740225351

Epoch: 5| Step: 9
Training loss: 2.084690809249878
Validation loss: 1.949515591385544

Epoch: 5| Step: 10
Training loss: 1.8112274408340454
Validation loss: 1.9115327430027786

Epoch: 220| Step: 0
Training loss: 2.2767493724823
Validation loss: 1.9391222820487073

Epoch: 5| Step: 1
Training loss: 2.0700173377990723
Validation loss: 1.919711906422851

Epoch: 5| Step: 2
Training loss: 1.5909717082977295
Validation loss: 1.9220336970462595

Epoch: 5| Step: 3
Training loss: 1.7685909271240234
Validation loss: 1.9265420424040927

Epoch: 5| Step: 4
Training loss: 1.6013765335083008
Validation loss: 1.9149399008802188

Epoch: 5| Step: 5
Training loss: 2.1045093536376953
Validation loss: 1.9150743023041756

Epoch: 5| Step: 6
Training loss: 2.6506428718566895
Validation loss: 1.8967461855180803

Epoch: 5| Step: 7
Training loss: 1.9769477844238281
Validation loss: 1.9249375763759817

Epoch: 5| Step: 8
Training loss: 1.677433729171753
Validation loss: 1.9390830570651638

Epoch: 5| Step: 9
Training loss: 1.7194032669067383
Validation loss: 1.922659848325996

Epoch: 5| Step: 10
Training loss: 1.6653214693069458
Validation loss: 1.9196944211118965

Epoch: 221| Step: 0
Training loss: 1.4831339120864868
Validation loss: 1.937303650763727

Epoch: 5| Step: 1
Training loss: 2.0095324516296387
Validation loss: 1.9241056647351993

Epoch: 5| Step: 2
Training loss: 2.0721633434295654
Validation loss: 1.9546331846585838

Epoch: 5| Step: 3
Training loss: 1.2669862508773804
Validation loss: 1.927727726198012

Epoch: 5| Step: 4
Training loss: 2.0525569915771484
Validation loss: 1.914460507772302

Epoch: 5| Step: 5
Training loss: 1.6344425678253174
Validation loss: 1.9343926919403898

Epoch: 5| Step: 6
Training loss: 2.2122740745544434
Validation loss: 1.9217467077316777

Epoch: 5| Step: 7
Training loss: 2.1722187995910645
Validation loss: 1.9133130965694305

Epoch: 5| Step: 8
Training loss: 1.6884227991104126
Validation loss: 1.9373952457981725

Epoch: 5| Step: 9
Training loss: 2.124704122543335
Validation loss: 1.915459511100605

Epoch: 5| Step: 10
Training loss: 2.433697462081909
Validation loss: 1.9418546999654462

Epoch: 222| Step: 0
Training loss: 2.1395516395568848
Validation loss: 1.9110950680189236

Epoch: 5| Step: 1
Training loss: 2.3610711097717285
Validation loss: 1.9327455169411116

Epoch: 5| Step: 2
Training loss: 1.7375223636627197
Validation loss: 1.9392205156305784

Epoch: 5| Step: 3
Training loss: 2.2049670219421387
Validation loss: 1.9426151885781238

Epoch: 5| Step: 4
Training loss: 1.3474284410476685
Validation loss: 1.9511180372648342

Epoch: 5| Step: 5
Training loss: 1.6536626815795898
Validation loss: 1.9613153319205008

Epoch: 5| Step: 6
Training loss: 2.486008882522583
Validation loss: 1.937496849285659

Epoch: 5| Step: 7
Training loss: 1.426905632019043
Validation loss: 1.9828136826074252

Epoch: 5| Step: 8
Training loss: 1.9605607986450195
Validation loss: 1.9262110315343386

Epoch: 5| Step: 9
Training loss: 1.8319613933563232
Validation loss: 1.9220614792198263

Epoch: 5| Step: 10
Training loss: 2.1728458404541016
Validation loss: 1.9309574493797876

Epoch: 223| Step: 0
Training loss: 2.3115904331207275
Validation loss: 1.9086463861568

Epoch: 5| Step: 1
Training loss: 1.1489222049713135
Validation loss: 1.9374597418692805

Epoch: 5| Step: 2
Training loss: 2.1336748600006104
Validation loss: 1.9100868394297938

Epoch: 5| Step: 3
Training loss: 1.8901405334472656
Validation loss: 1.9143936659700127

Epoch: 5| Step: 4
Training loss: 2.156182050704956
Validation loss: 1.9135775925010763

Epoch: 5| Step: 5
Training loss: 1.683582067489624
Validation loss: 1.9066892247046194

Epoch: 5| Step: 6
Training loss: 1.7364749908447266
Validation loss: 1.9115833441416423

Epoch: 5| Step: 7
Training loss: 2.2392163276672363
Validation loss: 1.9204343211266302

Epoch: 5| Step: 8
Training loss: 2.0446784496307373
Validation loss: 1.8988649742577666

Epoch: 5| Step: 9
Training loss: 1.446956753730774
Validation loss: 1.902166074322116

Epoch: 5| Step: 10
Training loss: 2.2978246212005615
Validation loss: 1.9238266175793064

Epoch: 224| Step: 0
Training loss: 2.1852290630340576
Validation loss: 1.898505873577569

Epoch: 5| Step: 1
Training loss: 2.1967825889587402
Validation loss: 1.9241836481196906

Epoch: 5| Step: 2
Training loss: 1.8878132104873657
Validation loss: 1.9040295898273427

Epoch: 5| Step: 3
Training loss: 2.1633663177490234
Validation loss: 1.9168497413717291

Epoch: 5| Step: 4
Training loss: 1.4941823482513428
Validation loss: 1.9148769929844847

Epoch: 5| Step: 5
Training loss: 1.4454689025878906
Validation loss: 1.9190482388260544

Epoch: 5| Step: 6
Training loss: 2.2259902954101562
Validation loss: 1.9194119168866066

Epoch: 5| Step: 7
Training loss: 1.9981193542480469
Validation loss: 1.9531091413190287

Epoch: 5| Step: 8
Training loss: 1.7056162357330322
Validation loss: 1.926666889139401

Epoch: 5| Step: 9
Training loss: 2.0092403888702393
Validation loss: 1.9128668462076495

Epoch: 5| Step: 10
Training loss: 1.7213133573532104
Validation loss: 1.9230946033231673

Epoch: 225| Step: 0
Training loss: 1.9633209705352783
Validation loss: 1.9394952327974382

Epoch: 5| Step: 1
Training loss: 2.1183505058288574
Validation loss: 1.9263564399493638

Epoch: 5| Step: 2
Training loss: 1.9767189025878906
Validation loss: 1.912687732327369

Epoch: 5| Step: 3
Training loss: 1.968515396118164
Validation loss: 1.9176145548461585

Epoch: 5| Step: 4
Training loss: 1.9015700817108154
Validation loss: 1.933374035742975

Epoch: 5| Step: 5
Training loss: 1.9420356750488281
Validation loss: 1.927663880009805

Epoch: 5| Step: 6
Training loss: 2.381974697113037
Validation loss: 1.9649080627708024

Epoch: 5| Step: 7
Training loss: 1.3555150032043457
Validation loss: 1.922509281866012

Epoch: 5| Step: 8
Training loss: 1.7484471797943115
Validation loss: 1.9247960813583866

Epoch: 5| Step: 9
Training loss: 1.6587213277816772
Validation loss: 1.917834315248715

Epoch: 5| Step: 10
Training loss: 1.8722033500671387
Validation loss: 1.9173678672441872

Epoch: 226| Step: 0
Training loss: 2.423567295074463
Validation loss: 1.9248723291581677

Epoch: 5| Step: 1
Training loss: 2.076406955718994
Validation loss: 1.9201300836378528

Epoch: 5| Step: 2
Training loss: 1.5643062591552734
Validation loss: 1.9053487521345898

Epoch: 5| Step: 3
Training loss: 2.1406469345092773
Validation loss: 1.9007233727362849

Epoch: 5| Step: 4
Training loss: 1.55312180519104
Validation loss: 1.9251440904473747

Epoch: 5| Step: 5
Training loss: 1.9079148769378662
Validation loss: 1.9229825004454582

Epoch: 5| Step: 6
Training loss: 2.204739570617676
Validation loss: 1.938181971990934

Epoch: 5| Step: 7
Training loss: 1.8069576025009155
Validation loss: 1.9255251102550055

Epoch: 5| Step: 8
Training loss: 2.236142158508301
Validation loss: 1.913187740951456

Epoch: 5| Step: 9
Training loss: 1.3345205783843994
Validation loss: 1.9229410732946088

Epoch: 5| Step: 10
Training loss: 1.6779083013534546
Validation loss: 1.9038269724897159

Epoch: 227| Step: 0
Training loss: 1.5263054370880127
Validation loss: 1.9368509400275447

Epoch: 5| Step: 1
Training loss: 2.186753988265991
Validation loss: 1.9313545662869689

Epoch: 5| Step: 2
Training loss: 1.4366592168807983
Validation loss: 1.9273846944173176

Epoch: 5| Step: 3
Training loss: 1.9142024517059326
Validation loss: 1.933250501591672

Epoch: 5| Step: 4
Training loss: 1.9696667194366455
Validation loss: 1.9184546342460058

Epoch: 5| Step: 5
Training loss: 1.8530781269073486
Validation loss: 1.9062626618210987

Epoch: 5| Step: 6
Training loss: 2.085437059402466
Validation loss: 1.8993882389478787

Epoch: 5| Step: 7
Training loss: 1.3734607696533203
Validation loss: 1.9241155860244588

Epoch: 5| Step: 8
Training loss: 2.177353620529175
Validation loss: 1.9358673057248514

Epoch: 5| Step: 9
Training loss: 1.679090142250061
Validation loss: 1.9243922451490998

Epoch: 5| Step: 10
Training loss: 2.9137015342712402
Validation loss: 1.9263460033683366

Epoch: 228| Step: 0
Training loss: 1.7497437000274658
Validation loss: 1.9261615609609952

Epoch: 5| Step: 1
Training loss: 2.219726085662842
Validation loss: 1.9347651671337824

Epoch: 5| Step: 2
Training loss: 2.334263324737549
Validation loss: 1.9244688159676009

Epoch: 5| Step: 3
Training loss: 1.6270173788070679
Validation loss: 1.922948847534836

Epoch: 5| Step: 4
Training loss: 1.2595036029815674
Validation loss: 1.91341963378332

Epoch: 5| Step: 5
Training loss: 1.8106296062469482
Validation loss: 1.9302789447128132

Epoch: 5| Step: 6
Training loss: 2.270803213119507
Validation loss: 1.923876699580941

Epoch: 5| Step: 7
Training loss: 1.5453585386276245
Validation loss: 1.926842135767783

Epoch: 5| Step: 8
Training loss: 1.977075219154358
Validation loss: 1.9048625102607153

Epoch: 5| Step: 9
Training loss: 2.094975233078003
Validation loss: 1.9114601253181376

Epoch: 5| Step: 10
Training loss: 1.9391533136367798
Validation loss: 1.9262072706735263

Epoch: 229| Step: 0
Training loss: 1.702856421470642
Validation loss: 1.899659933582429

Epoch: 5| Step: 1
Training loss: 1.644620656967163
Validation loss: 1.915271077104794

Epoch: 5| Step: 2
Training loss: 1.7747313976287842
Validation loss: 1.9061624260358914

Epoch: 5| Step: 3
Training loss: 1.6702169179916382
Validation loss: 1.9051476447812972

Epoch: 5| Step: 4
Training loss: 1.969164252281189
Validation loss: 1.9102707133498242

Epoch: 5| Step: 5
Training loss: 1.6409103870391846
Validation loss: 1.891869205300526

Epoch: 5| Step: 6
Training loss: 2.1996045112609863
Validation loss: 1.9444121737633981

Epoch: 5| Step: 7
Training loss: 1.7618262767791748
Validation loss: 1.8962820934992966

Epoch: 5| Step: 8
Training loss: 3.0683674812316895
Validation loss: 1.8999652734366796

Epoch: 5| Step: 9
Training loss: 2.0792346000671387
Validation loss: 1.8855135120371336

Epoch: 5| Step: 10
Training loss: 1.5817070007324219
Validation loss: 1.908719342242005

Epoch: 230| Step: 0
Training loss: 1.9314491748809814
Validation loss: 1.8850421520971483

Epoch: 5| Step: 1
Training loss: 2.0873749256134033
Validation loss: 1.915351349820373

Epoch: 5| Step: 2
Training loss: 1.6865265369415283
Validation loss: 1.929043318635674

Epoch: 5| Step: 3
Training loss: 1.8291038274765015
Validation loss: 1.9212238468149656

Epoch: 5| Step: 4
Training loss: 1.4694002866744995
Validation loss: 1.8975564843864852

Epoch: 5| Step: 5
Training loss: 2.97880482673645
Validation loss: 1.9335960354856265

Epoch: 5| Step: 6
Training loss: 1.830021619796753
Validation loss: 1.9158845614361506

Epoch: 5| Step: 7
Training loss: 1.7876834869384766
Validation loss: 1.9076943679522442

Epoch: 5| Step: 8
Training loss: 1.5406053066253662
Validation loss: 1.888338468408072

Epoch: 5| Step: 9
Training loss: 2.060007095336914
Validation loss: 1.9227509447323379

Epoch: 5| Step: 10
Training loss: 1.678977131843567
Validation loss: 1.911906232116043

Epoch: 231| Step: 0
Training loss: 1.83087158203125
Validation loss: 1.8858709873691681

Epoch: 5| Step: 1
Training loss: 1.8449227809906006
Validation loss: 1.9035319974345546

Epoch: 5| Step: 2
Training loss: 1.567073106765747
Validation loss: 1.9250511815471034

Epoch: 5| Step: 3
Training loss: 1.767939805984497
Validation loss: 1.9092943886274933

Epoch: 5| Step: 4
Training loss: 2.062012195587158
Validation loss: 1.9210986911609609

Epoch: 5| Step: 5
Training loss: 1.9846866130828857
Validation loss: 1.914677095669572

Epoch: 5| Step: 6
Training loss: 1.7463805675506592
Validation loss: 1.9418782546956053

Epoch: 5| Step: 7
Training loss: 1.9790443181991577
Validation loss: 1.891493164083009

Epoch: 5| Step: 8
Training loss: 2.365840435028076
Validation loss: 1.9234692306928738

Epoch: 5| Step: 9
Training loss: 1.5757968425750732
Validation loss: 1.8989283782179638

Epoch: 5| Step: 10
Training loss: 2.047656297683716
Validation loss: 1.901825729236808

Epoch: 232| Step: 0
Training loss: 1.9335434436798096
Validation loss: 1.9471804147125573

Epoch: 5| Step: 1
Training loss: 2.448308229446411
Validation loss: 1.9463832301478232

Epoch: 5| Step: 2
Training loss: 1.7665786743164062
Validation loss: 1.9092139813207811

Epoch: 5| Step: 3
Training loss: 1.9621078968048096
Validation loss: 1.9432483949968893

Epoch: 5| Step: 4
Training loss: 1.7241872549057007
Validation loss: 1.937845455702915

Epoch: 5| Step: 5
Training loss: 2.1978354454040527
Validation loss: 1.942030095284985

Epoch: 5| Step: 6
Training loss: 2.0736308097839355
Validation loss: 1.9373866665747859

Epoch: 5| Step: 7
Training loss: 1.6940873861312866
Validation loss: 1.90760584415928

Epoch: 5| Step: 8
Training loss: 1.5974633693695068
Validation loss: 1.921698304914659

Epoch: 5| Step: 9
Training loss: 1.6690336465835571
Validation loss: 1.919077648911425

Epoch: 5| Step: 10
Training loss: 1.6995939016342163
Validation loss: 1.9130281120218255

Epoch: 233| Step: 0
Training loss: 2.208561420440674
Validation loss: 1.8947048366710704

Epoch: 5| Step: 1
Training loss: 2.0631356239318848
Validation loss: 1.9338719101362332

Epoch: 5| Step: 2
Training loss: 2.202579975128174
Validation loss: 1.904676470705258

Epoch: 5| Step: 3
Training loss: 2.420577049255371
Validation loss: 1.944817066192627

Epoch: 5| Step: 4
Training loss: 1.6770846843719482
Validation loss: 1.9140443289151756

Epoch: 5| Step: 5
Training loss: 1.5759356021881104
Validation loss: 1.9160013301398164

Epoch: 5| Step: 6
Training loss: 2.050140142440796
Validation loss: 1.906942859772713

Epoch: 5| Step: 7
Training loss: 1.7332384586334229
Validation loss: 1.9235324475073046

Epoch: 5| Step: 8
Training loss: 1.8307006359100342
Validation loss: 1.9294244089434225

Epoch: 5| Step: 9
Training loss: 1.215399980545044
Validation loss: 1.9379221213761197

Epoch: 5| Step: 10
Training loss: 1.8359748125076294
Validation loss: 1.947676525321058

Epoch: 234| Step: 0
Training loss: 1.6664526462554932
Validation loss: 1.9180042359136766

Epoch: 5| Step: 1
Training loss: 1.9167906045913696
Validation loss: 1.9325903666916715

Epoch: 5| Step: 2
Training loss: 2.333585262298584
Validation loss: 1.9375184620580366

Epoch: 5| Step: 3
Training loss: 2.5582172870635986
Validation loss: 1.953724935490598

Epoch: 5| Step: 4
Training loss: 1.330481767654419
Validation loss: 1.925815422047851

Epoch: 5| Step: 5
Training loss: 1.2425533533096313
Validation loss: 1.9336508179223666

Epoch: 5| Step: 6
Training loss: 1.833783745765686
Validation loss: 1.9349753536203855

Epoch: 5| Step: 7
Training loss: 1.572628140449524
Validation loss: 1.933958294571087

Epoch: 5| Step: 8
Training loss: 2.5179152488708496
Validation loss: 1.9384190882405927

Epoch: 5| Step: 9
Training loss: 1.9670121669769287
Validation loss: 1.9229385019630514

Epoch: 5| Step: 10
Training loss: 1.780076265335083
Validation loss: 1.8852871284689954

Epoch: 235| Step: 0
Training loss: 1.6596561670303345
Validation loss: 1.9315534509638304

Epoch: 5| Step: 1
Training loss: 0.9042354822158813
Validation loss: 1.8908955486871863

Epoch: 5| Step: 2
Training loss: 2.4117305278778076
Validation loss: 1.9121304147986955

Epoch: 5| Step: 3
Training loss: 2.3800132274627686
Validation loss: 1.8994387977866716

Epoch: 5| Step: 4
Training loss: 2.3148226737976074
Validation loss: 1.9364727004881828

Epoch: 5| Step: 5
Training loss: 1.5355195999145508
Validation loss: 1.916845134509507

Epoch: 5| Step: 6
Training loss: 2.080552816390991
Validation loss: 1.9094213375481226

Epoch: 5| Step: 7
Training loss: 1.9791128635406494
Validation loss: 1.8796636404529694

Epoch: 5| Step: 8
Training loss: 1.9281280040740967
Validation loss: 1.9140928676051479

Epoch: 5| Step: 9
Training loss: 1.5084975957870483
Validation loss: 1.9262741663122689

Epoch: 5| Step: 10
Training loss: 1.89138662815094
Validation loss: 1.8777930249450028

Epoch: 236| Step: 0
Training loss: 1.8209359645843506
Validation loss: 1.897939694825039

Epoch: 5| Step: 1
Training loss: 2.57654070854187
Validation loss: 1.9127451463412213

Epoch: 5| Step: 2
Training loss: 2.1482315063476562
Validation loss: 1.9115331801035071

Epoch: 5| Step: 3
Training loss: 1.6356843709945679
Validation loss: 1.8906148351648802

Epoch: 5| Step: 4
Training loss: 1.6786525249481201
Validation loss: 1.9102485628538235

Epoch: 5| Step: 5
Training loss: 1.5284688472747803
Validation loss: 1.8854892523058

Epoch: 5| Step: 6
Training loss: 1.7958158254623413
Validation loss: 1.9044593431616341

Epoch: 5| Step: 7
Training loss: 2.1379058361053467
Validation loss: 1.910573092840051

Epoch: 5| Step: 8
Training loss: 2.0152509212493896
Validation loss: 1.8991689848643478

Epoch: 5| Step: 9
Training loss: 1.389267921447754
Validation loss: 1.9300857000453497

Epoch: 5| Step: 10
Training loss: 1.8584558963775635
Validation loss: 1.9254498943205802

Epoch: 237| Step: 0
Training loss: 1.4042350053787231
Validation loss: 1.925867857471589

Epoch: 5| Step: 1
Training loss: 2.1040008068084717
Validation loss: 1.9071197561038438

Epoch: 5| Step: 2
Training loss: 1.8211898803710938
Validation loss: 1.914940091871446

Epoch: 5| Step: 3
Training loss: 1.922208547592163
Validation loss: 1.9167795437638477

Epoch: 5| Step: 4
Training loss: 1.6189165115356445
Validation loss: 1.920041758527038

Epoch: 5| Step: 5
Training loss: 1.7251203060150146
Validation loss: 1.9092952525743874

Epoch: 5| Step: 6
Training loss: 1.9304218292236328
Validation loss: 1.9230827913489392

Epoch: 5| Step: 7
Training loss: 2.551837682723999
Validation loss: 1.885888522671115

Epoch: 5| Step: 8
Training loss: 2.3169751167297363
Validation loss: 1.8931012127989082

Epoch: 5| Step: 9
Training loss: 1.6257950067520142
Validation loss: 1.9015061163133191

Epoch: 5| Step: 10
Training loss: 1.70380437374115
Validation loss: 1.9100149100826633

Epoch: 238| Step: 0
Training loss: 2.254833936691284
Validation loss: 1.887533458330298

Epoch: 5| Step: 1
Training loss: 1.4962501525878906
Validation loss: 1.9197056190941924

Epoch: 5| Step: 2
Training loss: 1.7997074127197266
Validation loss: 1.8980541716339767

Epoch: 5| Step: 3
Training loss: 2.25773549079895
Validation loss: 1.8988739854546004

Epoch: 5| Step: 4
Training loss: 1.0814520120620728
Validation loss: 1.8741889025575371

Epoch: 5| Step: 5
Training loss: 2.1274161338806152
Validation loss: 1.920185125002297

Epoch: 5| Step: 6
Training loss: 1.9638134241104126
Validation loss: 1.9289613410990725

Epoch: 5| Step: 7
Training loss: 1.9228166341781616
Validation loss: 1.9234196985921552

Epoch: 5| Step: 8
Training loss: 1.839453101158142
Validation loss: 1.9272394385389102

Epoch: 5| Step: 9
Training loss: 1.8556684255599976
Validation loss: 1.9401213276770808

Epoch: 5| Step: 10
Training loss: 1.8728268146514893
Validation loss: 1.9493779418289021

Epoch: 239| Step: 0
Training loss: 1.3641375303268433
Validation loss: 1.8959855418051443

Epoch: 5| Step: 1
Training loss: 1.7267513275146484
Validation loss: 1.9321589534000685

Epoch: 5| Step: 2
Training loss: 1.9547433853149414
Validation loss: 1.9483217475234822

Epoch: 5| Step: 3
Training loss: 2.5779776573181152
Validation loss: 1.927638215403403

Epoch: 5| Step: 4
Training loss: 2.293569564819336
Validation loss: 1.9030230519592122

Epoch: 5| Step: 5
Training loss: 1.8754212856292725
Validation loss: 1.909556004308885

Epoch: 5| Step: 6
Training loss: 1.8869909048080444
Validation loss: 1.9260249227605841

Epoch: 5| Step: 7
Training loss: 1.416536808013916
Validation loss: 1.9074232116822274

Epoch: 5| Step: 8
Training loss: 1.9165265560150146
Validation loss: 1.8977138124486452

Epoch: 5| Step: 9
Training loss: 1.8645626306533813
Validation loss: 1.9196408640953802

Epoch: 5| Step: 10
Training loss: 1.6945223808288574
Validation loss: 1.8900933778414162

Epoch: 240| Step: 0
Training loss: 1.3663299083709717
Validation loss: 1.9114818393543203

Epoch: 5| Step: 1
Training loss: 1.9498831033706665
Validation loss: 1.8856592562890822

Epoch: 5| Step: 2
Training loss: 1.9867883920669556
Validation loss: 1.895121669256559

Epoch: 5| Step: 3
Training loss: 1.5608054399490356
Validation loss: 1.88960232785953

Epoch: 5| Step: 4
Training loss: 2.4476675987243652
Validation loss: 1.9014891578305153

Epoch: 5| Step: 5
Training loss: 1.52824866771698
Validation loss: 1.9186531779586629

Epoch: 5| Step: 6
Training loss: 1.532164216041565
Validation loss: 1.8853129879120858

Epoch: 5| Step: 7
Training loss: 2.243921995162964
Validation loss: 1.9208738034771335

Epoch: 5| Step: 8
Training loss: 1.8374626636505127
Validation loss: 1.9125901396556566

Epoch: 5| Step: 9
Training loss: 1.8075039386749268
Validation loss: 1.8918254913822297

Epoch: 5| Step: 10
Training loss: 2.204632520675659
Validation loss: 1.874772338457005

Epoch: 241| Step: 0
Training loss: 2.0557632446289062
Validation loss: 1.8920694986979167

Epoch: 5| Step: 1
Training loss: 1.7450840473175049
Validation loss: 1.930399461459088

Epoch: 5| Step: 2
Training loss: 1.5591744184494019
Validation loss: 1.9066553282481369

Epoch: 5| Step: 3
Training loss: 2.350508213043213
Validation loss: 1.9085461670352566

Epoch: 5| Step: 4
Training loss: 1.6627346277236938
Validation loss: 1.9229819774627686

Epoch: 5| Step: 5
Training loss: 2.415015697479248
Validation loss: 1.9314424248151882

Epoch: 5| Step: 6
Training loss: 2.136695623397827
Validation loss: 1.8990292574769707

Epoch: 5| Step: 7
Training loss: 1.2498219013214111
Validation loss: 1.9344112642349736

Epoch: 5| Step: 8
Training loss: 2.091411828994751
Validation loss: 1.9272375363175587

Epoch: 5| Step: 9
Training loss: 1.6112836599349976
Validation loss: 1.922101960387281

Epoch: 5| Step: 10
Training loss: 1.648188591003418
Validation loss: 1.9098864704050043

Epoch: 242| Step: 0
Training loss: 2.5111899375915527
Validation loss: 1.9106731260976484

Epoch: 5| Step: 1
Training loss: 1.9247710704803467
Validation loss: 1.8730197029729043

Epoch: 5| Step: 2
Training loss: 1.5982025861740112
Validation loss: 1.9119447187710834

Epoch: 5| Step: 3
Training loss: 1.9673506021499634
Validation loss: 1.9124897526156517

Epoch: 5| Step: 4
Training loss: 2.1273927688598633
Validation loss: 1.895440077268949

Epoch: 5| Step: 5
Training loss: 1.8203620910644531
Validation loss: 1.9031102298408427

Epoch: 5| Step: 6
Training loss: 1.550477147102356
Validation loss: 1.906617933704007

Epoch: 5| Step: 7
Training loss: 2.118680477142334
Validation loss: 1.8951402402693225

Epoch: 5| Step: 8
Training loss: 1.8827416896820068
Validation loss: 1.8915703963207942

Epoch: 5| Step: 9
Training loss: 1.7681678533554077
Validation loss: 1.91066772707047

Epoch: 5| Step: 10
Training loss: 0.9706141352653503
Validation loss: 1.8967517986092517

Epoch: 243| Step: 0
Training loss: 2.6386373043060303
Validation loss: 1.9375961442147531

Epoch: 5| Step: 1
Training loss: 2.2326436042785645
Validation loss: 1.862857203329763

Epoch: 5| Step: 2
Training loss: 2.0514464378356934
Validation loss: 1.9107965320669196

Epoch: 5| Step: 3
Training loss: 1.6668026447296143
Validation loss: 1.9134903479647893

Epoch: 5| Step: 4
Training loss: 1.6184914112091064
Validation loss: 1.913219739032048

Epoch: 5| Step: 5
Training loss: 1.72517991065979
Validation loss: 1.9048192770250383

Epoch: 5| Step: 6
Training loss: 1.4280688762664795
Validation loss: 1.9377852665480746

Epoch: 5| Step: 7
Training loss: 1.6639366149902344
Validation loss: 1.8942177757140128

Epoch: 5| Step: 8
Training loss: 2.4587459564208984
Validation loss: 1.8835677293039137

Epoch: 5| Step: 9
Training loss: 1.2746152877807617
Validation loss: 1.8840778412357453

Epoch: 5| Step: 10
Training loss: 1.5070884227752686
Validation loss: 1.9115540776201474

Epoch: 244| Step: 0
Training loss: 1.4574501514434814
Validation loss: 1.8902251861428703

Epoch: 5| Step: 1
Training loss: 1.8396356105804443
Validation loss: 1.8955838680267334

Epoch: 5| Step: 2
Training loss: 1.3405916690826416
Validation loss: 1.918659738315049

Epoch: 5| Step: 3
Training loss: 1.4084646701812744
Validation loss: 1.8976195935280091

Epoch: 5| Step: 4
Training loss: 2.248124361038208
Validation loss: 1.8855333994793635

Epoch: 5| Step: 5
Training loss: 2.2916786670684814
Validation loss: 1.8668736193769722

Epoch: 5| Step: 6
Training loss: 2.1903984546661377
Validation loss: 1.9043321583860664

Epoch: 5| Step: 7
Training loss: 1.9959224462509155
Validation loss: 1.887583181422244

Epoch: 5| Step: 8
Training loss: 2.271446943283081
Validation loss: 1.9163017452404063

Epoch: 5| Step: 9
Training loss: 1.440185308456421
Validation loss: 1.928658668712903

Epoch: 5| Step: 10
Training loss: 1.4813106060028076
Validation loss: 1.9032737490951375

Epoch: 245| Step: 0
Training loss: 1.4725195169448853
Validation loss: 1.875383727012142

Epoch: 5| Step: 1
Training loss: 1.4265185594558716
Validation loss: 1.9211771103643602

Epoch: 5| Step: 2
Training loss: 1.7975517511367798
Validation loss: 1.9280066797810216

Epoch: 5| Step: 3
Training loss: 2.0004425048828125
Validation loss: 1.9267246800084268

Epoch: 5| Step: 4
Training loss: 1.3325594663619995
Validation loss: 1.9166291682950911

Epoch: 5| Step: 5
Training loss: 2.2038803100585938
Validation loss: 1.9156304841400476

Epoch: 5| Step: 6
Training loss: 2.113760471343994
Validation loss: 1.9674965489295222

Epoch: 5| Step: 7
Training loss: 2.012261152267456
Validation loss: 1.918029151937013

Epoch: 5| Step: 8
Training loss: 2.2557687759399414
Validation loss: 1.9199396384659635

Epoch: 5| Step: 9
Training loss: 1.7056457996368408
Validation loss: 1.9171947740739392

Epoch: 5| Step: 10
Training loss: 2.0373518466949463
Validation loss: 1.878001106682644

Epoch: 246| Step: 0
Training loss: 1.5521763563156128
Validation loss: 1.922620447733069

Epoch: 5| Step: 1
Training loss: 2.0425102710723877
Validation loss: 1.9167172485782253

Epoch: 5| Step: 2
Training loss: 1.7105634212493896
Validation loss: 1.8895701259695075

Epoch: 5| Step: 3
Training loss: 2.264765977859497
Validation loss: 1.8766001757755075

Epoch: 5| Step: 4
Training loss: 1.9738575220108032
Validation loss: 1.8758459937187932

Epoch: 5| Step: 5
Training loss: 2.250808000564575
Validation loss: 1.8547434140277166

Epoch: 5| Step: 6
Training loss: 1.918127417564392
Validation loss: 1.8882373148395168

Epoch: 5| Step: 7
Training loss: 2.099099636077881
Validation loss: 1.8691950639088948

Epoch: 5| Step: 8
Training loss: 1.128541350364685
Validation loss: 1.8833303079810193

Epoch: 5| Step: 9
Training loss: 1.8325283527374268
Validation loss: 1.9170389636870353

Epoch: 5| Step: 10
Training loss: 1.079777717590332
Validation loss: 1.850228771086662

Epoch: 247| Step: 0
Training loss: 1.8217792510986328
Validation loss: 1.8763327034570838

Epoch: 5| Step: 1
Training loss: 1.521723747253418
Validation loss: 1.8842382020847772

Epoch: 5| Step: 2
Training loss: 1.560165524482727
Validation loss: 1.885854644160117

Epoch: 5| Step: 3
Training loss: 1.708568811416626
Validation loss: 1.8884395322492045

Epoch: 5| Step: 4
Training loss: 1.7924654483795166
Validation loss: 1.9130104652015112

Epoch: 5| Step: 5
Training loss: 2.3213562965393066
Validation loss: 1.9074279569810437

Epoch: 5| Step: 6
Training loss: 1.6100146770477295
Validation loss: 1.9206927386663293

Epoch: 5| Step: 7
Training loss: 2.2069571018218994
Validation loss: 1.9098609160351496

Epoch: 5| Step: 8
Training loss: 2.3727259635925293
Validation loss: 1.9121985858486545

Epoch: 5| Step: 9
Training loss: 1.7946078777313232
Validation loss: 1.9249234917343303

Epoch: 5| Step: 10
Training loss: 1.3071527481079102
Validation loss: 1.8976532490022722

Epoch: 248| Step: 0
Training loss: 1.5464489459991455
Validation loss: 1.8992852703217538

Epoch: 5| Step: 1
Training loss: 2.0296730995178223
Validation loss: 1.892930644814686

Epoch: 5| Step: 2
Training loss: 1.3035866022109985
Validation loss: 1.9159507072100075

Epoch: 5| Step: 3
Training loss: 2.058433771133423
Validation loss: 1.90759559664675

Epoch: 5| Step: 4
Training loss: 1.7536567449569702
Validation loss: 1.930389642715454

Epoch: 5| Step: 5
Training loss: 2.2003610134124756
Validation loss: 1.8760495724216584

Epoch: 5| Step: 6
Training loss: 1.244278073310852
Validation loss: 1.9025165098969654

Epoch: 5| Step: 7
Training loss: 1.9091317653656006
Validation loss: 1.8867218366233252

Epoch: 5| Step: 8
Training loss: 2.2484183311462402
Validation loss: 1.912172479014243

Epoch: 5| Step: 9
Training loss: 1.3942047357559204
Validation loss: 1.894659544831963

Epoch: 5| Step: 10
Training loss: 2.44176983833313
Validation loss: 1.9067088352736605

Epoch: 249| Step: 0
Training loss: 1.8044353723526
Validation loss: 1.9080929909982989

Epoch: 5| Step: 1
Training loss: 1.954464316368103
Validation loss: 1.8772124833958124

Epoch: 5| Step: 2
Training loss: 1.379143476486206
Validation loss: 1.8810939763181953

Epoch: 5| Step: 3
Training loss: 1.4345676898956299
Validation loss: 1.8816332522258963

Epoch: 5| Step: 4
Training loss: 1.842272400856018
Validation loss: 1.8711737766060779

Epoch: 5| Step: 5
Training loss: 2.0518765449523926
Validation loss: 1.8727964380735993

Epoch: 5| Step: 6
Training loss: 2.204388380050659
Validation loss: 1.919378322939719

Epoch: 5| Step: 7
Training loss: 1.6528091430664062
Validation loss: 1.8853817550084924

Epoch: 5| Step: 8
Training loss: 1.9297231435775757
Validation loss: 1.9055660822058236

Epoch: 5| Step: 9
Training loss: 1.7376409769058228
Validation loss: 1.942326722606536

Epoch: 5| Step: 10
Training loss: 1.9628820419311523
Validation loss: 1.9368038792763986

Epoch: 250| Step: 0
Training loss: 2.5056052207946777
Validation loss: 1.942192114809508

Epoch: 5| Step: 1
Training loss: 1.4531505107879639
Validation loss: 1.8775611026312715

Epoch: 5| Step: 2
Training loss: 1.502700686454773
Validation loss: 1.9038255753055695

Epoch: 5| Step: 3
Training loss: 2.0396037101745605
Validation loss: 1.9221929478388962

Epoch: 5| Step: 4
Training loss: 1.3722550868988037
Validation loss: 1.8838598510270477

Epoch: 5| Step: 5
Training loss: 1.9431110620498657
Validation loss: 1.9046946853719733

Epoch: 5| Step: 6
Training loss: 1.9363658428192139
Validation loss: 1.88377199890793

Epoch: 5| Step: 7
Training loss: 1.5963172912597656
Validation loss: 1.8791769076419134

Epoch: 5| Step: 8
Training loss: 1.6971187591552734
Validation loss: 1.8637030278482745

Epoch: 5| Step: 9
Training loss: 1.550459861755371
Validation loss: 1.8840080640649284

Epoch: 5| Step: 10
Training loss: 2.3657617568969727
Validation loss: 1.8986429834878573

Epoch: 251| Step: 0
Training loss: 1.942726731300354
Validation loss: 1.8621244366450975

Epoch: 5| Step: 1
Training loss: 1.7574365139007568
Validation loss: 1.869511644045512

Epoch: 5| Step: 2
Training loss: 1.8785184621810913
Validation loss: 1.8936599262299076

Epoch: 5| Step: 3
Training loss: 2.290416717529297
Validation loss: 1.9017616369391

Epoch: 5| Step: 4
Training loss: 1.9641004800796509
Validation loss: 1.8840063259165774

Epoch: 5| Step: 5
Training loss: 1.4542465209960938
Validation loss: 1.8817163372552523

Epoch: 5| Step: 6
Training loss: 2.069883108139038
Validation loss: 1.902891541040072

Epoch: 5| Step: 7
Training loss: 1.1941354274749756
Validation loss: 1.8978484548548216

Epoch: 5| Step: 8
Training loss: 1.9353851079940796
Validation loss: 1.8600736497550883

Epoch: 5| Step: 9
Training loss: 1.785943627357483
Validation loss: 1.8822753326867216

Epoch: 5| Step: 10
Training loss: 1.643162727355957
Validation loss: 1.878832188985681

Epoch: 252| Step: 0
Training loss: 2.1312015056610107
Validation loss: 1.8986415286217966

Epoch: 5| Step: 1
Training loss: 1.495530366897583
Validation loss: 1.8821020049433554

Epoch: 5| Step: 2
Training loss: 1.3019133806228638
Validation loss: 1.9008798330060896

Epoch: 5| Step: 3
Training loss: 1.7432012557983398
Validation loss: 1.9134790205186414

Epoch: 5| Step: 4
Training loss: 1.9580166339874268
Validation loss: 1.8754981769028531

Epoch: 5| Step: 5
Training loss: 1.864801049232483
Validation loss: 1.9544629396930817

Epoch: 5| Step: 6
Training loss: 2.4665133953094482
Validation loss: 1.9293447707289009

Epoch: 5| Step: 7
Training loss: 1.5631011724472046
Validation loss: 1.9133407454336844

Epoch: 5| Step: 8
Training loss: 2.0412237644195557
Validation loss: 1.9091580273002706

Epoch: 5| Step: 9
Training loss: 1.5226703882217407
Validation loss: 1.9066363470528715

Epoch: 5| Step: 10
Training loss: 1.6388025283813477
Validation loss: 1.8989716268354846

Epoch: 253| Step: 0
Training loss: 1.826930284500122
Validation loss: 1.8941168349276307

Epoch: 5| Step: 1
Training loss: 2.1127610206604004
Validation loss: 1.9048843204334218

Epoch: 5| Step: 2
Training loss: 1.9716873168945312
Validation loss: 1.8765819380360265

Epoch: 5| Step: 3
Training loss: 1.6714038848876953
Validation loss: 1.9006929025855115

Epoch: 5| Step: 4
Training loss: 1.5900113582611084
Validation loss: 1.9096888867757653

Epoch: 5| Step: 5
Training loss: 1.906827688217163
Validation loss: 1.9206193031803254

Epoch: 5| Step: 6
Training loss: 1.4476791620254517
Validation loss: 1.8917513867860198

Epoch: 5| Step: 7
Training loss: 1.2775558233261108
Validation loss: 1.8755187437098513

Epoch: 5| Step: 8
Training loss: 2.162010431289673
Validation loss: 1.9055450629162531

Epoch: 5| Step: 9
Training loss: 1.5290372371673584
Validation loss: 1.8949130222361574

Epoch: 5| Step: 10
Training loss: 2.3447203636169434
Validation loss: 1.8737377633330643

Epoch: 254| Step: 0
Training loss: 2.543703317642212
Validation loss: 1.9165259356139808

Epoch: 5| Step: 1
Training loss: 1.7386152744293213
Validation loss: 1.8650943386939265

Epoch: 5| Step: 2
Training loss: 1.8790919780731201
Validation loss: 1.8766812073287142

Epoch: 5| Step: 3
Training loss: 2.1240386962890625
Validation loss: 1.9116304087382492

Epoch: 5| Step: 4
Training loss: 1.267667531967163
Validation loss: 1.8904539692786433

Epoch: 5| Step: 5
Training loss: 1.962183952331543
Validation loss: 1.8645533592470231

Epoch: 5| Step: 6
Training loss: 1.993827223777771
Validation loss: 1.8683509185749998

Epoch: 5| Step: 7
Training loss: 1.7735650539398193
Validation loss: 1.9362880927260204

Epoch: 5| Step: 8
Training loss: 1.2852171659469604
Validation loss: 1.8972536825364636

Epoch: 5| Step: 9
Training loss: 1.4459404945373535
Validation loss: 1.9083842308290544

Epoch: 5| Step: 10
Training loss: 2.015199661254883
Validation loss: 1.8821822981680594

Epoch: 255| Step: 0
Training loss: 1.4966793060302734
Validation loss: 1.9026601519635928

Epoch: 5| Step: 1
Training loss: 1.761741042137146
Validation loss: 1.8815042370109147

Epoch: 5| Step: 2
Training loss: 1.9871402978897095
Validation loss: 1.8519175360279698

Epoch: 5| Step: 3
Training loss: 1.9898784160614014
Validation loss: 1.8836989915499123

Epoch: 5| Step: 4
Training loss: 1.7280237674713135
Validation loss: 1.869100739878993

Epoch: 5| Step: 5
Training loss: 2.2580814361572266
Validation loss: 1.8778544010654572

Epoch: 5| Step: 6
Training loss: 1.390674352645874
Validation loss: 1.903828364546581

Epoch: 5| Step: 7
Training loss: 2.5519680976867676
Validation loss: 1.8653246074594476

Epoch: 5| Step: 8
Training loss: 1.463793396949768
Validation loss: 1.8802557055668165

Epoch: 5| Step: 9
Training loss: 1.508002519607544
Validation loss: 1.8911699005352554

Epoch: 5| Step: 10
Training loss: 1.884913682937622
Validation loss: 1.8822127144823793

Epoch: 256| Step: 0
Training loss: 2.1497905254364014
Validation loss: 1.8783650193163144

Epoch: 5| Step: 1
Training loss: 1.3163206577301025
Validation loss: 1.884007333427347

Epoch: 5| Step: 2
Training loss: 2.5360772609710693
Validation loss: 1.8739410202990296

Epoch: 5| Step: 3
Training loss: 1.516741156578064
Validation loss: 1.9234237850353282

Epoch: 5| Step: 4
Training loss: 1.9389336109161377
Validation loss: 1.9017437363183627

Epoch: 5| Step: 5
Training loss: 1.5479354858398438
Validation loss: 1.8844656726365447

Epoch: 5| Step: 6
Training loss: 1.4291810989379883
Validation loss: 1.906181477731274

Epoch: 5| Step: 7
Training loss: 1.8076616525650024
Validation loss: 1.9317826481275662

Epoch: 5| Step: 8
Training loss: 1.8003623485565186
Validation loss: 1.8933956430804344

Epoch: 5| Step: 9
Training loss: 1.8526763916015625
Validation loss: 1.8879221241961244

Epoch: 5| Step: 10
Training loss: 1.7617489099502563
Validation loss: 1.9067537015484226

Epoch: 257| Step: 0
Training loss: 1.4389811754226685
Validation loss: 1.9343867507032169

Epoch: 5| Step: 1
Training loss: 1.8910586833953857
Validation loss: 1.9073053047221193

Epoch: 5| Step: 2
Training loss: 1.8021125793457031
Validation loss: 1.904610396713339

Epoch: 5| Step: 3
Training loss: 1.6190977096557617
Validation loss: 1.9112850184081702

Epoch: 5| Step: 4
Training loss: 0.9576178789138794
Validation loss: 1.8729271465732205

Epoch: 5| Step: 5
Training loss: 2.3722331523895264
Validation loss: 1.8984285298214163

Epoch: 5| Step: 6
Training loss: 1.9657237529754639
Validation loss: 1.8771127372659662

Epoch: 5| Step: 7
Training loss: 2.261019229888916
Validation loss: 1.8932278310098956

Epoch: 5| Step: 8
Training loss: 1.8450847864151
Validation loss: 1.906289304456403

Epoch: 5| Step: 9
Training loss: 1.8874914646148682
Validation loss: 1.8909487621758574

Epoch: 5| Step: 10
Training loss: 1.7757965326309204
Validation loss: 1.8939788520977061

Epoch: 258| Step: 0
Training loss: 2.0025582313537598
Validation loss: 1.9087860763713878

Epoch: 5| Step: 1
Training loss: 2.0875110626220703
Validation loss: 1.8661342308085451

Epoch: 5| Step: 2
Training loss: 1.9592243432998657
Validation loss: 1.8428719915369505

Epoch: 5| Step: 3
Training loss: 1.5889486074447632
Validation loss: 1.9147518783487298

Epoch: 5| Step: 4
Training loss: 1.8420441150665283
Validation loss: 1.9020046380258375

Epoch: 5| Step: 5
Training loss: 1.681321144104004
Validation loss: 1.9288281394589333

Epoch: 5| Step: 6
Training loss: 1.9377601146697998
Validation loss: 1.897034897599169

Epoch: 5| Step: 7
Training loss: 1.6229450702667236
Validation loss: 1.8778068621953328

Epoch: 5| Step: 8
Training loss: 1.8155444860458374
Validation loss: 1.891736880425484

Epoch: 5| Step: 9
Training loss: 1.4604361057281494
Validation loss: 1.8901593582604521

Epoch: 5| Step: 10
Training loss: 1.7275522947311401
Validation loss: 1.88964420236567

Epoch: 259| Step: 0
Training loss: 1.4131453037261963
Validation loss: 1.8861565051540252

Epoch: 5| Step: 1
Training loss: 1.896074891090393
Validation loss: 1.8920677246585969

Epoch: 5| Step: 2
Training loss: 1.8191360235214233
Validation loss: 1.8694259223117624

Epoch: 5| Step: 3
Training loss: 1.9342906475067139
Validation loss: 1.8988506883703253

Epoch: 5| Step: 4
Training loss: 1.0794620513916016
Validation loss: 1.9212030262075446

Epoch: 5| Step: 5
Training loss: 1.50352942943573
Validation loss: 1.937302012597361

Epoch: 5| Step: 6
Training loss: 1.4246671199798584
Validation loss: 1.8989807251961

Epoch: 5| Step: 7
Training loss: 2.1477580070495605
Validation loss: 1.9142153686092747

Epoch: 5| Step: 8
Training loss: 2.252262592315674
Validation loss: 1.8621888506797053

Epoch: 5| Step: 9
Training loss: 1.825356125831604
Validation loss: 1.8996358750968851

Epoch: 5| Step: 10
Training loss: 2.422919273376465
Validation loss: 1.9171300780388616

Epoch: 260| Step: 0
Training loss: 1.8307456970214844
Validation loss: 1.8676937754436205

Epoch: 5| Step: 1
Training loss: 1.8493869304656982
Validation loss: 1.8878576435068601

Epoch: 5| Step: 2
Training loss: 1.897499680519104
Validation loss: 1.915858898111569

Epoch: 5| Step: 3
Training loss: 1.3373732566833496
Validation loss: 1.8832705392632434

Epoch: 5| Step: 4
Training loss: 1.0924209356307983
Validation loss: 1.8683278509365615

Epoch: 5| Step: 5
Training loss: 2.1271705627441406
Validation loss: 1.8740188293559576

Epoch: 5| Step: 6
Training loss: 2.0318799018859863
Validation loss: 1.8975291482863887

Epoch: 5| Step: 7
Training loss: 2.006988286972046
Validation loss: 1.8954733187152493

Epoch: 5| Step: 8
Training loss: 1.4463765621185303
Validation loss: 1.875025007032579

Epoch: 5| Step: 9
Training loss: 1.7848107814788818
Validation loss: 1.8998910496311803

Epoch: 5| Step: 10
Training loss: 2.1895406246185303
Validation loss: 1.8991547912679694

Epoch: 261| Step: 0
Training loss: 1.514849305152893
Validation loss: 1.900405676134171

Epoch: 5| Step: 1
Training loss: 1.9552948474884033
Validation loss: 1.8813871798976776

Epoch: 5| Step: 2
Training loss: 2.226881980895996
Validation loss: 1.8801396918553177

Epoch: 5| Step: 3
Training loss: 1.4231215715408325
Validation loss: 1.8954313967817573

Epoch: 5| Step: 4
Training loss: 1.7588762044906616
Validation loss: 1.8780623456483245

Epoch: 5| Step: 5
Training loss: 2.4804155826568604
Validation loss: 1.8592822808091358

Epoch: 5| Step: 6
Training loss: 1.6990426778793335
Validation loss: 1.849462491209789

Epoch: 5| Step: 7
Training loss: 1.2392103672027588
Validation loss: 1.881779364360276

Epoch: 5| Step: 8
Training loss: 2.3813376426696777
Validation loss: 1.8783436141988283

Epoch: 5| Step: 9
Training loss: 1.27980637550354
Validation loss: 1.895645567165908

Epoch: 5| Step: 10
Training loss: 1.5857527256011963
Validation loss: 1.8625834706009075

Epoch: 262| Step: 0
Training loss: 1.2599900960922241
Validation loss: 1.8587438073209537

Epoch: 5| Step: 1
Training loss: 2.3269054889678955
Validation loss: 1.8721306080459266

Epoch: 5| Step: 2
Training loss: 1.5393292903900146
Validation loss: 1.8554613205694384

Epoch: 5| Step: 3
Training loss: 1.922903060913086
Validation loss: 1.8591386272061257

Epoch: 5| Step: 4
Training loss: 1.6064541339874268
Validation loss: 1.8575524873630975

Epoch: 5| Step: 5
Training loss: 1.5309293270111084
Validation loss: 1.8602926526018368

Epoch: 5| Step: 6
Training loss: 1.995527982711792
Validation loss: 1.9065182824288645

Epoch: 5| Step: 7
Training loss: 1.8366451263427734
Validation loss: 1.9078090767706595

Epoch: 5| Step: 8
Training loss: 2.10337233543396
Validation loss: 1.9377522699294552

Epoch: 5| Step: 9
Training loss: 2.0127925872802734
Validation loss: 1.8894948062076364

Epoch: 5| Step: 10
Training loss: 1.4403529167175293
Validation loss: 1.9330352134602045

Epoch: 263| Step: 0
Training loss: 1.6425750255584717
Validation loss: 1.8712709219224992

Epoch: 5| Step: 1
Training loss: 1.5564916133880615
Validation loss: 1.9162478677688106

Epoch: 5| Step: 2
Training loss: 1.9840368032455444
Validation loss: 1.9169182495404316

Epoch: 5| Step: 3
Training loss: 1.6995019912719727
Validation loss: 1.9203500952771915

Epoch: 5| Step: 4
Training loss: 1.171948790550232
Validation loss: 1.8921750873647711

Epoch: 5| Step: 5
Training loss: 1.4773857593536377
Validation loss: 1.8796098591178976

Epoch: 5| Step: 6
Training loss: 2.0435681343078613
Validation loss: 1.8992193193845852

Epoch: 5| Step: 7
Training loss: 2.2950825691223145
Validation loss: 1.8671821073819233

Epoch: 5| Step: 8
Training loss: 1.8878158330917358
Validation loss: 1.8918430830842705

Epoch: 5| Step: 9
Training loss: 1.6610357761383057
Validation loss: 1.8625419075771044

Epoch: 5| Step: 10
Training loss: 1.807794451713562
Validation loss: 1.8594601974692395

Epoch: 264| Step: 0
Training loss: 1.9861838817596436
Validation loss: 1.894851251315045

Epoch: 5| Step: 1
Training loss: 2.574836015701294
Validation loss: 1.8656182007123066

Epoch: 5| Step: 2
Training loss: 1.6518843173980713
Validation loss: 1.8563531009099816

Epoch: 5| Step: 3
Training loss: 1.1516157388687134
Validation loss: 1.8858845144189813

Epoch: 5| Step: 4
Training loss: 1.5679121017456055
Validation loss: 1.8735534375713718

Epoch: 5| Step: 5
Training loss: 1.5768383741378784
Validation loss: 1.8660676748521867

Epoch: 5| Step: 6
Training loss: 2.359328508377075
Validation loss: 1.8915964493187525

Epoch: 5| Step: 7
Training loss: 1.824379563331604
Validation loss: 1.8742142800361878

Epoch: 5| Step: 8
Training loss: 2.019050359725952
Validation loss: 1.8761595782413278

Epoch: 5| Step: 9
Training loss: 1.1799784898757935
Validation loss: 1.8793985766749228

Epoch: 5| Step: 10
Training loss: 1.4445648193359375
Validation loss: 1.886440820591424

Epoch: 265| Step: 0
Training loss: 2.9752488136291504
Validation loss: 1.8605564627596127

Epoch: 5| Step: 1
Training loss: 1.7255350351333618
Validation loss: 1.9008591405807003

Epoch: 5| Step: 2
Training loss: 1.0586649179458618
Validation loss: 1.9117158100169191

Epoch: 5| Step: 3
Training loss: 2.084963321685791
Validation loss: 1.8728787975926553

Epoch: 5| Step: 4
Training loss: 1.991868019104004
Validation loss: 1.8652959408298615

Epoch: 5| Step: 5
Training loss: 1.3691930770874023
Validation loss: 1.8526019716775546

Epoch: 5| Step: 6
Training loss: 1.548007607460022
Validation loss: 1.881092909843691

Epoch: 5| Step: 7
Training loss: 1.7745895385742188
Validation loss: 1.8803506871705413

Epoch: 5| Step: 8
Training loss: 1.445236325263977
Validation loss: 1.885537890977757

Epoch: 5| Step: 9
Training loss: 1.2876155376434326
Validation loss: 1.8813734669839182

Epoch: 5| Step: 10
Training loss: 1.7988330125808716
Validation loss: 1.8942318770193285

Epoch: 266| Step: 0
Training loss: 1.7214429378509521
Validation loss: 1.9111825291828444

Epoch: 5| Step: 1
Training loss: 2.254725217819214
Validation loss: 1.8953527224961149

Epoch: 5| Step: 2
Training loss: 2.337947368621826
Validation loss: 1.8673145142934655

Epoch: 5| Step: 3
Training loss: 1.3702220916748047
Validation loss: 1.8974877185718988

Epoch: 5| Step: 4
Training loss: 1.6219289302825928
Validation loss: 1.8609554613790205

Epoch: 5| Step: 5
Training loss: 1.9349892139434814
Validation loss: 1.8923176232204642

Epoch: 5| Step: 6
Training loss: 1.9472520351409912
Validation loss: 1.8736344152881252

Epoch: 5| Step: 7
Training loss: 1.3886913061141968
Validation loss: 1.9282832376418575

Epoch: 5| Step: 8
Training loss: 1.3170185089111328
Validation loss: 1.872435824845427

Epoch: 5| Step: 9
Training loss: 1.2964692115783691
Validation loss: 1.8770827926615232

Epoch: 5| Step: 10
Training loss: 2.120192766189575
Validation loss: 1.8912503603966004

Epoch: 267| Step: 0
Training loss: 1.752370834350586
Validation loss: 1.9280713629978958

Epoch: 5| Step: 1
Training loss: 2.4334192276000977
Validation loss: 1.917607448434317

Epoch: 5| Step: 2
Training loss: 1.6704511642456055
Validation loss: 1.8715314172929334

Epoch: 5| Step: 3
Training loss: 1.4172405004501343
Validation loss: 1.8860877098575715

Epoch: 5| Step: 4
Training loss: 1.9734563827514648
Validation loss: 1.877246086315442

Epoch: 5| Step: 5
Training loss: 1.6422719955444336
Validation loss: 1.87248477115426

Epoch: 5| Step: 6
Training loss: 1.5043565034866333
Validation loss: 1.8765913376244165

Epoch: 5| Step: 7
Training loss: 1.3296902179718018
Validation loss: 1.8751920859018962

Epoch: 5| Step: 8
Training loss: 1.448440670967102
Validation loss: 1.8904514235834922

Epoch: 5| Step: 9
Training loss: 2.084789276123047
Validation loss: 1.8985543135673768

Epoch: 5| Step: 10
Training loss: 1.9512165784835815
Validation loss: 1.8903007097141717

Epoch: 268| Step: 0
Training loss: 1.7477900981903076
Validation loss: 1.8685187165455153

Epoch: 5| Step: 1
Training loss: 1.9347059726715088
Validation loss: 1.8766808407281035

Epoch: 5| Step: 2
Training loss: 1.5555561780929565
Validation loss: 1.8850222056911838

Epoch: 5| Step: 3
Training loss: 1.5423245429992676
Validation loss: 1.8770957339194514

Epoch: 5| Step: 4
Training loss: 1.3101770877838135
Validation loss: 1.8808788702052126

Epoch: 5| Step: 5
Training loss: 1.4102675914764404
Validation loss: 1.879069503917489

Epoch: 5| Step: 6
Training loss: 1.7962278127670288
Validation loss: 1.9177870314608338

Epoch: 5| Step: 7
Training loss: 2.4038825035095215
Validation loss: 1.8879032493919454

Epoch: 5| Step: 8
Training loss: 1.780402421951294
Validation loss: 1.8802154961452688

Epoch: 5| Step: 9
Training loss: 1.7293697595596313
Validation loss: 1.8674497783824962

Epoch: 5| Step: 10
Training loss: 1.9861154556274414
Validation loss: 1.900185304303323

Epoch: 269| Step: 0
Training loss: 2.000214099884033
Validation loss: 1.8661663878348567

Epoch: 5| Step: 1
Training loss: 1.9363759756088257
Validation loss: 1.9104763871879988

Epoch: 5| Step: 2
Training loss: 1.7576900720596313
Validation loss: 1.8838289540301087

Epoch: 5| Step: 3
Training loss: 1.6082630157470703
Validation loss: 1.8651082118352253

Epoch: 5| Step: 4
Training loss: 1.3173073530197144
Validation loss: 1.867770004016097

Epoch: 5| Step: 5
Training loss: 1.5126163959503174
Validation loss: 1.8848646058831164

Epoch: 5| Step: 6
Training loss: 2.171889066696167
Validation loss: 1.867560814785701

Epoch: 5| Step: 7
Training loss: 2.354754686355591
Validation loss: 1.8749374010229622

Epoch: 5| Step: 8
Training loss: 1.4804476499557495
Validation loss: 1.8559483815264959

Epoch: 5| Step: 9
Training loss: 1.172715187072754
Validation loss: 1.872065818437966

Epoch: 5| Step: 10
Training loss: 1.7950725555419922
Validation loss: 1.8757728722787672

Epoch: 270| Step: 0
Training loss: 1.688044786453247
Validation loss: 1.884145608512304

Epoch: 5| Step: 1
Training loss: 2.0049984455108643
Validation loss: 1.8423646778188727

Epoch: 5| Step: 2
Training loss: 1.9382034540176392
Validation loss: 1.8880769168176958

Epoch: 5| Step: 3
Training loss: 1.3736464977264404
Validation loss: 1.8520831895130936

Epoch: 5| Step: 4
Training loss: 1.919122338294983
Validation loss: 1.8719373620966429

Epoch: 5| Step: 5
Training loss: 1.5012972354888916
Validation loss: 1.8827386927861038

Epoch: 5| Step: 6
Training loss: 1.4330799579620361
Validation loss: 1.8294610836172616

Epoch: 5| Step: 7
Training loss: 1.4451353549957275
Validation loss: 1.8447546087285525

Epoch: 5| Step: 8
Training loss: 1.3833866119384766
Validation loss: 1.895930851659467

Epoch: 5| Step: 9
Training loss: 2.0459706783294678
Validation loss: 1.87851849679024

Epoch: 5| Step: 10
Training loss: 1.944074034690857
Validation loss: 1.850106946883663

Epoch: 271| Step: 0
Training loss: 2.1661646366119385
Validation loss: 1.8642067319603377

Epoch: 5| Step: 1
Training loss: 1.6741663217544556
Validation loss: 1.8861064936525078

Epoch: 5| Step: 2
Training loss: 1.8070201873779297
Validation loss: 1.9141298545304166

Epoch: 5| Step: 3
Training loss: 1.8325464725494385
Validation loss: 1.871746588778752

Epoch: 5| Step: 4
Training loss: 1.3099076747894287
Validation loss: 1.8663220828579319

Epoch: 5| Step: 5
Training loss: 2.003762722015381
Validation loss: 1.8596124392683788

Epoch: 5| Step: 6
Training loss: 1.6561447381973267
Validation loss: 1.878940281047616

Epoch: 5| Step: 7
Training loss: 1.3672422170639038
Validation loss: 1.9044375432434903

Epoch: 5| Step: 8
Training loss: 1.6565014123916626
Validation loss: 1.898747403134582

Epoch: 5| Step: 9
Training loss: 1.5827057361602783
Validation loss: 1.9143353380182737

Epoch: 5| Step: 10
Training loss: 2.209136724472046
Validation loss: 1.8759858582609443

Epoch: 272| Step: 0
Training loss: 1.5379064083099365
Validation loss: 1.8996123472849529

Epoch: 5| Step: 1
Training loss: 1.5477497577667236
Validation loss: 1.900593541001761

Epoch: 5| Step: 2
Training loss: 1.692371129989624
Validation loss: 1.9135203015419744

Epoch: 5| Step: 3
Training loss: 2.1598758697509766
Validation loss: 1.8831256256308606

Epoch: 5| Step: 4
Training loss: 1.630974531173706
Validation loss: 1.8497745426752235

Epoch: 5| Step: 5
Training loss: 1.0035709142684937
Validation loss: 1.8394998183814428

Epoch: 5| Step: 6
Training loss: 1.7830874919891357
Validation loss: 1.8864400341946592

Epoch: 5| Step: 7
Training loss: 1.5817883014678955
Validation loss: 1.8890395484944826

Epoch: 5| Step: 8
Training loss: 1.8239202499389648
Validation loss: 1.8878293345051427

Epoch: 5| Step: 9
Training loss: 1.9622137546539307
Validation loss: 1.879652189952071

Epoch: 5| Step: 10
Training loss: 2.2594478130340576
Validation loss: 1.8392479727345128

Epoch: 273| Step: 0
Training loss: 1.417326807975769
Validation loss: 1.8701203189870363

Epoch: 5| Step: 1
Training loss: 1.4974396228790283
Validation loss: 1.8391087106479111

Epoch: 5| Step: 2
Training loss: 1.8359390497207642
Validation loss: 1.860861168112806

Epoch: 5| Step: 3
Training loss: 1.809812307357788
Validation loss: 1.863970664239699

Epoch: 5| Step: 4
Training loss: 2.136484384536743
Validation loss: 1.85181975108321

Epoch: 5| Step: 5
Training loss: 1.7616136074066162
Validation loss: 1.8637237702646563

Epoch: 5| Step: 6
Training loss: 1.5104459524154663
Validation loss: 1.9002598113911127

Epoch: 5| Step: 7
Training loss: 1.9300448894500732
Validation loss: 1.836142219522948

Epoch: 5| Step: 8
Training loss: 1.739900827407837
Validation loss: 1.8799622122959425

Epoch: 5| Step: 9
Training loss: 1.4014238119125366
Validation loss: 1.8866919202189292

Epoch: 5| Step: 10
Training loss: 1.875869631767273
Validation loss: 1.8671035817874375

Epoch: 274| Step: 0
Training loss: 1.9124799966812134
Validation loss: 1.8710259724688787

Epoch: 5| Step: 1
Training loss: 1.3711494207382202
Validation loss: 1.8735021314313334

Epoch: 5| Step: 2
Training loss: 1.3400821685791016
Validation loss: 1.8630298529901812

Epoch: 5| Step: 3
Training loss: 2.027294158935547
Validation loss: 1.9128151670578988

Epoch: 5| Step: 4
Training loss: 1.811807632446289
Validation loss: 1.8888348610170427

Epoch: 5| Step: 5
Training loss: 1.2916293144226074
Validation loss: 1.877077647434768

Epoch: 5| Step: 6
Training loss: 1.683922529220581
Validation loss: 1.873253531353448

Epoch: 5| Step: 7
Training loss: 2.033618211746216
Validation loss: 1.8822811534327846

Epoch: 5| Step: 8
Training loss: 2.0230300426483154
Validation loss: 1.8794056882140457

Epoch: 5| Step: 9
Training loss: 1.9107154607772827
Validation loss: 1.8633244165810205

Epoch: 5| Step: 10
Training loss: 1.3405416011810303
Validation loss: 1.86917156557883

Epoch: 275| Step: 0
Training loss: 1.7735910415649414
Validation loss: 1.8601051120347873

Epoch: 5| Step: 1
Training loss: 1.872519850730896
Validation loss: 1.857637104167733

Epoch: 5| Step: 2
Training loss: 1.3838484287261963
Validation loss: 1.8779398497714792

Epoch: 5| Step: 3
Training loss: 1.6454474925994873
Validation loss: 1.8797059289870723

Epoch: 5| Step: 4
Training loss: 1.580151915550232
Validation loss: 1.8910618494915705

Epoch: 5| Step: 5
Training loss: 1.9870197772979736
Validation loss: 1.8767514203184394

Epoch: 5| Step: 6
Training loss: 1.6134898662567139
Validation loss: 1.8889851159946893

Epoch: 5| Step: 7
Training loss: 1.7534806728363037
Validation loss: 1.8789568562661447

Epoch: 5| Step: 8
Training loss: 1.5163770914077759
Validation loss: 1.8769672301507765

Epoch: 5| Step: 9
Training loss: 1.6799814701080322
Validation loss: 1.8775523580530638

Epoch: 5| Step: 10
Training loss: 2.1495447158813477
Validation loss: 1.8826430228448683

Epoch: 276| Step: 0
Training loss: 2.0293407440185547
Validation loss: 1.8587399785236647

Epoch: 5| Step: 1
Training loss: 2.1858198642730713
Validation loss: 1.8492488668810936

Epoch: 5| Step: 2
Training loss: 1.3535950183868408
Validation loss: 1.8847753206888835

Epoch: 5| Step: 3
Training loss: 1.391446828842163
Validation loss: 1.8350270294374036

Epoch: 5| Step: 4
Training loss: 1.4453394412994385
Validation loss: 1.8750644627437796

Epoch: 5| Step: 5
Training loss: 1.425135850906372
Validation loss: 1.8382590034956574

Epoch: 5| Step: 6
Training loss: 2.5072808265686035
Validation loss: 1.860415631724942

Epoch: 5| Step: 7
Training loss: 1.5080868005752563
Validation loss: 1.8523111035746913

Epoch: 5| Step: 8
Training loss: 1.5186834335327148
Validation loss: 1.8587949352879678

Epoch: 5| Step: 9
Training loss: 1.2965359687805176
Validation loss: 1.849648529483426

Epoch: 5| Step: 10
Training loss: 2.024441719055176
Validation loss: 1.827232938940807

Epoch: 277| Step: 0
Training loss: 1.2578245401382446
Validation loss: 1.8473580152757707

Epoch: 5| Step: 1
Training loss: 2.0428762435913086
Validation loss: 1.8663712957853913

Epoch: 5| Step: 2
Training loss: 2.036050796508789
Validation loss: 1.8998707468791673

Epoch: 5| Step: 3
Training loss: 1.7575044631958008
Validation loss: 1.855230531384868

Epoch: 5| Step: 4
Training loss: 2.5276341438293457
Validation loss: 1.850061531989805

Epoch: 5| Step: 5
Training loss: 2.110936164855957
Validation loss: 1.8514878557574364

Epoch: 5| Step: 6
Training loss: 1.8044008016586304
Validation loss: 1.8392543036450621

Epoch: 5| Step: 7
Training loss: 0.8862922787666321
Validation loss: 1.866551765831568

Epoch: 5| Step: 8
Training loss: 1.0092309713363647
Validation loss: 1.9069741131157003

Epoch: 5| Step: 9
Training loss: 1.7662826776504517
Validation loss: 1.8498132100669287

Epoch: 5| Step: 10
Training loss: 1.6535629034042358
Validation loss: 1.891068991794381

Epoch: 278| Step: 0
Training loss: 1.8327109813690186
Validation loss: 1.8692048236887941

Epoch: 5| Step: 1
Training loss: 2.066519021987915
Validation loss: 1.905293732561091

Epoch: 5| Step: 2
Training loss: 1.3884222507476807
Validation loss: 1.876841930932896

Epoch: 5| Step: 3
Training loss: 2.0975520610809326
Validation loss: 1.8966639093173447

Epoch: 5| Step: 4
Training loss: 1.3503198623657227
Validation loss: 1.8763051430384319

Epoch: 5| Step: 5
Training loss: 2.156795024871826
Validation loss: 1.8685638596934657

Epoch: 5| Step: 6
Training loss: 1.4999537467956543
Validation loss: 1.887712404292117

Epoch: 5| Step: 7
Training loss: 1.7182490825653076
Validation loss: 1.904161419919742

Epoch: 5| Step: 8
Training loss: 1.4089082479476929
Validation loss: 1.8663596619841873

Epoch: 5| Step: 9
Training loss: 1.5009435415267944
Validation loss: 1.8890347467955722

Epoch: 5| Step: 10
Training loss: 1.6569414138793945
Validation loss: 1.8555728017642934

Epoch: 279| Step: 0
Training loss: 2.009641170501709
Validation loss: 1.8778556418675247

Epoch: 5| Step: 1
Training loss: 1.398707628250122
Validation loss: 1.880166502409084

Epoch: 5| Step: 2
Training loss: 1.7674278020858765
Validation loss: 1.8414540752287833

Epoch: 5| Step: 3
Training loss: 1.4040074348449707
Validation loss: 1.8525750239690144

Epoch: 5| Step: 4
Training loss: 1.5212652683258057
Validation loss: 1.8718307325916905

Epoch: 5| Step: 5
Training loss: 1.8196725845336914
Validation loss: 1.8715312891109015

Epoch: 5| Step: 6
Training loss: 1.4885575771331787
Validation loss: 1.8732810379356466

Epoch: 5| Step: 7
Training loss: 1.7551028728485107
Validation loss: 1.8611537230912076

Epoch: 5| Step: 8
Training loss: 1.771466851234436
Validation loss: 1.8806978656399636

Epoch: 5| Step: 9
Training loss: 2.2085447311401367
Validation loss: 1.8447802810258762

Epoch: 5| Step: 10
Training loss: 1.6884835958480835
Validation loss: 1.8330841064453125

Epoch: 280| Step: 0
Training loss: 1.8987808227539062
Validation loss: 1.8858181097174203

Epoch: 5| Step: 1
Training loss: 1.52339768409729
Validation loss: 1.8505005259667673

Epoch: 5| Step: 2
Training loss: 2.020692825317383
Validation loss: 1.8156823137755036

Epoch: 5| Step: 3
Training loss: 2.256025552749634
Validation loss: 1.8051372830585768

Epoch: 5| Step: 4
Training loss: 1.5571643114089966
Validation loss: 1.8692560452286915

Epoch: 5| Step: 5
Training loss: 1.7580798864364624
Validation loss: 1.870374782111055

Epoch: 5| Step: 6
Training loss: 1.463829755783081
Validation loss: 1.8492536211526522

Epoch: 5| Step: 7
Training loss: 1.2016382217407227
Validation loss: 1.8851292094876688

Epoch: 5| Step: 8
Training loss: 1.7217128276824951
Validation loss: 1.848877522253221

Epoch: 5| Step: 9
Training loss: 1.3610014915466309
Validation loss: 1.9004837082278343

Epoch: 5| Step: 10
Training loss: 1.7935431003570557
Validation loss: 1.88341022435055

Epoch: 281| Step: 0
Training loss: 2.212658643722534
Validation loss: 1.866325936009807

Epoch: 5| Step: 1
Training loss: 2.0493216514587402
Validation loss: 1.896171627506133

Epoch: 5| Step: 2
Training loss: 1.1965386867523193
Validation loss: 1.8741720261112336

Epoch: 5| Step: 3
Training loss: 1.5626882314682007
Validation loss: 1.8656128939761911

Epoch: 5| Step: 4
Training loss: 0.9552481770515442
Validation loss: 1.8806662264690603

Epoch: 5| Step: 5
Training loss: 1.1802798509597778
Validation loss: 1.8953541606985114

Epoch: 5| Step: 6
Training loss: 1.896936058998108
Validation loss: 1.8431604164902882

Epoch: 5| Step: 7
Training loss: 1.4098105430603027
Validation loss: 1.8760205994370163

Epoch: 5| Step: 8
Training loss: 1.5686626434326172
Validation loss: 1.8663899014073033

Epoch: 5| Step: 9
Training loss: 2.7130446434020996
Validation loss: 1.8511635718807098

Epoch: 5| Step: 10
Training loss: 2.009340763092041
Validation loss: 1.8716412974942116

Epoch: 282| Step: 0
Training loss: 2.262930154800415
Validation loss: 1.8592173040554087

Epoch: 5| Step: 1
Training loss: 1.8389008045196533
Validation loss: 1.8746949882917507

Epoch: 5| Step: 2
Training loss: 1.5256202220916748
Validation loss: 1.8932433218084357

Epoch: 5| Step: 3
Training loss: 1.0194966793060303
Validation loss: 1.8822481375868603

Epoch: 5| Step: 4
Training loss: 1.6027179956436157
Validation loss: 1.8798682779394171

Epoch: 5| Step: 5
Training loss: 1.9032623767852783
Validation loss: 1.8471650795270038

Epoch: 5| Step: 6
Training loss: 2.111323833465576
Validation loss: 1.831057387013589

Epoch: 5| Step: 7
Training loss: 1.2308636903762817
Validation loss: 1.8703342817162956

Epoch: 5| Step: 8
Training loss: 1.6106605529785156
Validation loss: 1.832056914606402

Epoch: 5| Step: 9
Training loss: 2.0197830200195312
Validation loss: 1.8589533221337102

Epoch: 5| Step: 10
Training loss: 1.6742511987686157
Validation loss: 1.864167075003347

Epoch: 283| Step: 0
Training loss: 1.9782384634017944
Validation loss: 1.880276882520286

Epoch: 5| Step: 1
Training loss: 1.372478723526001
Validation loss: 1.8337553867729761

Epoch: 5| Step: 2
Training loss: 1.3875534534454346
Validation loss: 1.8337932914815924

Epoch: 5| Step: 3
Training loss: 1.2372853755950928
Validation loss: 1.8568679209678405

Epoch: 5| Step: 4
Training loss: 1.7925199270248413
Validation loss: 1.821785516636346

Epoch: 5| Step: 5
Training loss: 1.5786107778549194
Validation loss: 1.8879343514801354

Epoch: 5| Step: 6
Training loss: 2.140779972076416
Validation loss: 1.8656740086053007

Epoch: 5| Step: 7
Training loss: 1.7046411037445068
Validation loss: 1.8609300710821663

Epoch: 5| Step: 8
Training loss: 1.754686713218689
Validation loss: 1.8583033443779073

Epoch: 5| Step: 9
Training loss: 2.1155972480773926
Validation loss: 1.8351250002461095

Epoch: 5| Step: 10
Training loss: 1.6894149780273438
Validation loss: 1.8458037607131466

Epoch: 284| Step: 0
Training loss: 1.7186214923858643
Validation loss: 1.8532286485036213

Epoch: 5| Step: 1
Training loss: 1.597686529159546
Validation loss: 1.850650518171249

Epoch: 5| Step: 2
Training loss: 1.7927474975585938
Validation loss: 1.899278716374469

Epoch: 5| Step: 3
Training loss: 1.7134618759155273
Validation loss: 1.8892933219991705

Epoch: 5| Step: 4
Training loss: 2.1044201850891113
Validation loss: 1.8653419363883235

Epoch: 5| Step: 5
Training loss: 1.5497591495513916
Validation loss: 1.8636768351319015

Epoch: 5| Step: 6
Training loss: 1.409101128578186
Validation loss: 1.903943387410974

Epoch: 5| Step: 7
Training loss: 1.263560175895691
Validation loss: 1.8685899524278538

Epoch: 5| Step: 8
Training loss: 1.7671358585357666
Validation loss: 1.8535972205541467

Epoch: 5| Step: 9
Training loss: 1.706197738647461
Validation loss: 1.8940311426757483

Epoch: 5| Step: 10
Training loss: 1.6813936233520508
Validation loss: 1.8791507405619468

Epoch: 285| Step: 0
Training loss: 2.031742572784424
Validation loss: 1.9087063625294676

Epoch: 5| Step: 1
Training loss: 1.9671192169189453
Validation loss: 1.8891803269745202

Epoch: 5| Step: 2
Training loss: 1.8595737218856812
Validation loss: 1.863748090241545

Epoch: 5| Step: 3
Training loss: 1.6084924936294556
Validation loss: 1.8506713041695215

Epoch: 5| Step: 4
Training loss: 1.7817051410675049
Validation loss: 1.9227353642063756

Epoch: 5| Step: 5
Training loss: 1.1221964359283447
Validation loss: 1.8807437458345968

Epoch: 5| Step: 6
Training loss: 1.913538932800293
Validation loss: 1.8774831602650304

Epoch: 5| Step: 7
Training loss: 1.2901238203048706
Validation loss: 1.851055932301347

Epoch: 5| Step: 8
Training loss: 1.31405770778656
Validation loss: 1.8225017568116546

Epoch: 5| Step: 9
Training loss: 1.9657970666885376
Validation loss: 1.840673928619713

Epoch: 5| Step: 10
Training loss: 1.8032982349395752
Validation loss: 1.8633346557617188

Epoch: 286| Step: 0
Training loss: 2.2315375804901123
Validation loss: 1.8379428643052296

Epoch: 5| Step: 1
Training loss: 1.5829435586929321
Validation loss: 1.876717669989473

Epoch: 5| Step: 2
Training loss: 1.4949861764907837
Validation loss: 1.8391126689090525

Epoch: 5| Step: 3
Training loss: 1.9700024127960205
Validation loss: 1.8567567358734787

Epoch: 5| Step: 4
Training loss: 1.4596993923187256
Validation loss: 1.9145948707416494

Epoch: 5| Step: 5
Training loss: 1.4877132177352905
Validation loss: 1.8517002892750565

Epoch: 5| Step: 6
Training loss: 2.008333683013916
Validation loss: 1.865025402397238

Epoch: 5| Step: 7
Training loss: 1.7495830059051514
Validation loss: 1.8332502201039305

Epoch: 5| Step: 8
Training loss: 1.4022133350372314
Validation loss: 1.837545669207009

Epoch: 5| Step: 9
Training loss: 1.9053592681884766
Validation loss: 1.859930060243094

Epoch: 5| Step: 10
Training loss: 1.1691293716430664
Validation loss: 1.8595855415508311

Epoch: 287| Step: 0
Training loss: 1.6966495513916016
Validation loss: 1.854420317116604

Epoch: 5| Step: 1
Training loss: 1.9635093212127686
Validation loss: 1.8319104115168254

Epoch: 5| Step: 2
Training loss: 1.565171718597412
Validation loss: 1.8879967671568676

Epoch: 5| Step: 3
Training loss: 1.9809234142303467
Validation loss: 1.893032097047375

Epoch: 5| Step: 4
Training loss: 1.7210134267807007
Validation loss: 1.8599506475592171

Epoch: 5| Step: 5
Training loss: 1.636548638343811
Validation loss: 1.896268751031609

Epoch: 5| Step: 6
Training loss: 1.7916367053985596
Validation loss: 1.8654164575761365

Epoch: 5| Step: 7
Training loss: 1.4425384998321533
Validation loss: 1.893691741010194

Epoch: 5| Step: 8
Training loss: 1.3532899618148804
Validation loss: 1.8482221403429586

Epoch: 5| Step: 9
Training loss: 1.347169041633606
Validation loss: 1.8481692511548278

Epoch: 5| Step: 10
Training loss: 1.7365089654922485
Validation loss: 1.831227699915568

Epoch: 288| Step: 0
Training loss: 1.6136327981948853
Validation loss: 1.8692240189480525

Epoch: 5| Step: 1
Training loss: 1.7841838598251343
Validation loss: 1.840208948299449

Epoch: 5| Step: 2
Training loss: 2.0200648307800293
Validation loss: 1.8736787431983537

Epoch: 5| Step: 3
Training loss: 1.5283663272857666
Validation loss: 1.8729768953015726

Epoch: 5| Step: 4
Training loss: 1.7228456735610962
Validation loss: 1.8699847113701604

Epoch: 5| Step: 5
Training loss: 1.630920648574829
Validation loss: 1.82962143036627

Epoch: 5| Step: 6
Training loss: 1.494317650794983
Validation loss: 1.8263600423771849

Epoch: 5| Step: 7
Training loss: 1.5597808361053467
Validation loss: 1.875154133765928

Epoch: 5| Step: 8
Training loss: 1.568947434425354
Validation loss: 1.808935647369713

Epoch: 5| Step: 9
Training loss: 1.5280141830444336
Validation loss: 1.8367960735033917

Epoch: 5| Step: 10
Training loss: 1.8310091495513916
Validation loss: 1.8489668164201962

Epoch: 289| Step: 0
Training loss: 1.652570366859436
Validation loss: 1.8807801072315504

Epoch: 5| Step: 1
Training loss: 1.8155429363250732
Validation loss: 1.8878411169975036

Epoch: 5| Step: 2
Training loss: 2.2008156776428223
Validation loss: 1.8461663966537805

Epoch: 5| Step: 3
Training loss: 1.5454843044281006
Validation loss: 1.8638450586667625

Epoch: 5| Step: 4
Training loss: 0.9697168469429016
Validation loss: 1.8809584930378904

Epoch: 5| Step: 5
Training loss: 1.5590587854385376
Validation loss: 1.8712301074817617

Epoch: 5| Step: 6
Training loss: 2.3602492809295654
Validation loss: 1.8937906501113728

Epoch: 5| Step: 7
Training loss: 1.5155470371246338
Validation loss: 1.8438778205584454

Epoch: 5| Step: 8
Training loss: 1.4824951887130737
Validation loss: 1.8417561015775126

Epoch: 5| Step: 9
Training loss: 1.3859809637069702
Validation loss: 1.8724824690049695

Epoch: 5| Step: 10
Training loss: 1.9751319885253906
Validation loss: 1.8617603432747625

Epoch: 290| Step: 0
Training loss: 2.007611036300659
Validation loss: 1.8610348791204474

Epoch: 5| Step: 1
Training loss: 1.6899207830429077
Validation loss: 1.8543334648173342

Epoch: 5| Step: 2
Training loss: 1.8379634618759155
Validation loss: 1.8639641397742814

Epoch: 5| Step: 3
Training loss: 1.153869390487671
Validation loss: 1.8756398539389334

Epoch: 5| Step: 4
Training loss: 1.3686243295669556
Validation loss: 1.8713980925980436

Epoch: 5| Step: 5
Training loss: 1.802146553993225
Validation loss: 1.8461937724903066

Epoch: 5| Step: 6
Training loss: 1.5726521015167236
Validation loss: 1.8340928733989756

Epoch: 5| Step: 7
Training loss: 1.7737003564834595
Validation loss: 1.836705465470591

Epoch: 5| Step: 8
Training loss: 2.275463581085205
Validation loss: 1.8567206680133779

Epoch: 5| Step: 9
Training loss: 1.3308428525924683
Validation loss: 1.855208840421451

Epoch: 5| Step: 10
Training loss: 1.4516712427139282
Validation loss: 1.8628595054790538

Epoch: 291| Step: 0
Training loss: 1.7125136852264404
Validation loss: 1.8649673320913827

Epoch: 5| Step: 1
Training loss: 1.314247965812683
Validation loss: 1.8567458070734495

Epoch: 5| Step: 2
Training loss: 1.7739626169204712
Validation loss: 1.814153209809334

Epoch: 5| Step: 3
Training loss: 1.2487714290618896
Validation loss: 1.8491156101226807

Epoch: 5| Step: 4
Training loss: 1.439551830291748
Validation loss: 1.8280965820435555

Epoch: 5| Step: 5
Training loss: 1.5601614713668823
Validation loss: 1.8350933341569797

Epoch: 5| Step: 6
Training loss: 1.734363317489624
Validation loss: 1.8284016245154924

Epoch: 5| Step: 7
Training loss: 1.687896728515625
Validation loss: 1.849579043285821

Epoch: 5| Step: 8
Training loss: 1.9265530109405518
Validation loss: 1.8446878387082009

Epoch: 5| Step: 9
Training loss: 1.6106159687042236
Validation loss: 1.840465566163422

Epoch: 5| Step: 10
Training loss: 1.9059405326843262
Validation loss: 1.8652602549522155

Epoch: 292| Step: 0
Training loss: 2.1715824604034424
Validation loss: 1.83071986193298

Epoch: 5| Step: 1
Training loss: 2.157839775085449
Validation loss: 1.8719146097860029

Epoch: 5| Step: 2
Training loss: 1.1743768453598022
Validation loss: 1.828844170416555

Epoch: 5| Step: 3
Training loss: 1.6574089527130127
Validation loss: 1.8768009498555174

Epoch: 5| Step: 4
Training loss: 1.8851171731948853
Validation loss: 1.8627851906643118

Epoch: 5| Step: 5
Training loss: 1.9999372959136963
Validation loss: 1.8088206706508514

Epoch: 5| Step: 6
Training loss: 1.4428932666778564
Validation loss: 1.901517225850013

Epoch: 5| Step: 7
Training loss: 1.4755456447601318
Validation loss: 1.8434291731926702

Epoch: 5| Step: 8
Training loss: 1.442445158958435
Validation loss: 1.854550592360958

Epoch: 5| Step: 9
Training loss: 1.112785816192627
Validation loss: 1.8780448180372997

Epoch: 5| Step: 10
Training loss: 1.818338394165039
Validation loss: 1.8533045450846355

Epoch: 293| Step: 0
Training loss: 1.9281708002090454
Validation loss: 1.8271693568075857

Epoch: 5| Step: 1
Training loss: 1.9926159381866455
Validation loss: 1.8686849494134226

Epoch: 5| Step: 2
Training loss: 1.3646280765533447
Validation loss: 1.8555974678326679

Epoch: 5| Step: 3
Training loss: 1.3440738916397095
Validation loss: 1.86564730059716

Epoch: 5| Step: 4
Training loss: 2.0718629360198975
Validation loss: 1.851846024554263

Epoch: 5| Step: 5
Training loss: 1.8387151956558228
Validation loss: 1.8456297023321993

Epoch: 5| Step: 6
Training loss: 1.4137407541275024
Validation loss: 1.871632650334348

Epoch: 5| Step: 7
Training loss: 1.2243766784667969
Validation loss: 1.8630542883308985

Epoch: 5| Step: 8
Training loss: 1.3124449253082275
Validation loss: 1.857200216221553

Epoch: 5| Step: 9
Training loss: 1.900029182434082
Validation loss: 1.8240617295747161

Epoch: 5| Step: 10
Training loss: 1.7821558713912964
Validation loss: 1.8540544714978946

Epoch: 294| Step: 0
Training loss: 1.5983577966690063
Validation loss: 1.8534700152694539

Epoch: 5| Step: 1
Training loss: 1.5670140981674194
Validation loss: 1.8378405160801385

Epoch: 5| Step: 2
Training loss: 1.7889198064804077
Validation loss: 1.872069053752448

Epoch: 5| Step: 3
Training loss: 1.9660437107086182
Validation loss: 1.8823646435173609

Epoch: 5| Step: 4
Training loss: 1.6491329669952393
Validation loss: 1.8947253714325607

Epoch: 5| Step: 5
Training loss: 1.517323613166809
Validation loss: 1.8680446865738078

Epoch: 5| Step: 6
Training loss: 1.2792226076126099
Validation loss: 1.8975722238581667

Epoch: 5| Step: 7
Training loss: 2.08919095993042
Validation loss: 1.8535996970310007

Epoch: 5| Step: 8
Training loss: 1.3854100704193115
Validation loss: 1.8821726486247072

Epoch: 5| Step: 9
Training loss: 1.9958105087280273
Validation loss: 1.86766432434

Epoch: 5| Step: 10
Training loss: 1.4204999208450317
Validation loss: 1.8434498310089111

Epoch: 295| Step: 0
Training loss: 1.8510043621063232
Validation loss: 1.8728917644869896

Epoch: 5| Step: 1
Training loss: 1.3929351568222046
Validation loss: 1.8255259388236589

Epoch: 5| Step: 2
Training loss: 1.6305326223373413
Validation loss: 1.8395219836183774

Epoch: 5| Step: 3
Training loss: 1.729742407798767
Validation loss: 1.8168393642671647

Epoch: 5| Step: 4
Training loss: 1.7374727725982666
Validation loss: 1.846463926376835

Epoch: 5| Step: 5
Training loss: 2.4876747131347656
Validation loss: 1.842014071761921

Epoch: 5| Step: 6
Training loss: 1.6488983631134033
Validation loss: 1.8445696394930604

Epoch: 5| Step: 7
Training loss: 1.4337178468704224
Validation loss: 1.8284679881988033

Epoch: 5| Step: 8
Training loss: 1.1938626766204834
Validation loss: 1.8161234881288262

Epoch: 5| Step: 9
Training loss: 1.8169448375701904
Validation loss: 1.8397056569335282

Epoch: 5| Step: 10
Training loss: 1.5254666805267334
Validation loss: 1.8062400971689532

Epoch: 296| Step: 0
Training loss: 1.6991329193115234
Validation loss: 1.8545963636008642

Epoch: 5| Step: 1
Training loss: 1.309391736984253
Validation loss: 1.8488863065678587

Epoch: 5| Step: 2
Training loss: 1.5770807266235352
Validation loss: 1.831621116207492

Epoch: 5| Step: 3
Training loss: 1.8202495574951172
Validation loss: 1.8579975187137563

Epoch: 5| Step: 4
Training loss: 2.2342047691345215
Validation loss: 1.8782860450847174

Epoch: 5| Step: 5
Training loss: 1.734919786453247
Validation loss: 1.8940042757218885

Epoch: 5| Step: 6
Training loss: 1.4524005651474
Validation loss: 1.8466248730177521

Epoch: 5| Step: 7
Training loss: 1.518285870552063
Validation loss: 1.8519346739656182

Epoch: 5| Step: 8
Training loss: 1.6938831806182861
Validation loss: 1.840881937293596

Epoch: 5| Step: 9
Training loss: 1.3743422031402588
Validation loss: 1.8977265293880174

Epoch: 5| Step: 10
Training loss: 1.3173755407333374
Validation loss: 1.872580433404574

Epoch: 297| Step: 0
Training loss: 2.143721103668213
Validation loss: 1.830604471186156

Epoch: 5| Step: 1
Training loss: 1.2893530130386353
Validation loss: 1.8449527858405985

Epoch: 5| Step: 2
Training loss: 1.8478221893310547
Validation loss: 1.8512004754876579

Epoch: 5| Step: 3
Training loss: 1.5059003829956055
Validation loss: 1.8030803690674484

Epoch: 5| Step: 4
Training loss: 1.4878857135772705
Validation loss: 1.8118134839560396

Epoch: 5| Step: 5
Training loss: 1.638838529586792
Validation loss: 1.8255251569132651

Epoch: 5| Step: 6
Training loss: 1.9012548923492432
Validation loss: 1.8517412498433103

Epoch: 5| Step: 7
Training loss: 1.3070909976959229
Validation loss: 1.8422906501318819

Epoch: 5| Step: 8
Training loss: 1.3444302082061768
Validation loss: 1.87433381747174

Epoch: 5| Step: 9
Training loss: 1.6398712396621704
Validation loss: 1.8461127050461308

Epoch: 5| Step: 10
Training loss: 1.8805862665176392
Validation loss: 1.8567361626573788

Epoch: 298| Step: 0
Training loss: 1.1344711780548096
Validation loss: 1.8281685267725298

Epoch: 5| Step: 1
Training loss: 1.797677993774414
Validation loss: 1.8081336969970374

Epoch: 5| Step: 2
Training loss: 1.4761663675308228
Validation loss: 1.870557713252242

Epoch: 5| Step: 3
Training loss: 2.159280776977539
Validation loss: 1.8956912281692668

Epoch: 5| Step: 4
Training loss: 1.4697020053863525
Validation loss: 1.8543029267300841

Epoch: 5| Step: 5
Training loss: 1.1558892726898193
Validation loss: 1.8484068609053088

Epoch: 5| Step: 6
Training loss: 2.024043083190918
Validation loss: 1.8675556618680236

Epoch: 5| Step: 7
Training loss: 1.4126628637313843
Validation loss: 1.8636317829931937

Epoch: 5| Step: 8
Training loss: 2.16963267326355
Validation loss: 1.8268637118800994

Epoch: 5| Step: 9
Training loss: 1.3855617046356201
Validation loss: 1.8590116603400118

Epoch: 5| Step: 10
Training loss: 1.3348934650421143
Validation loss: 1.8663812683474632

Epoch: 299| Step: 0
Training loss: 1.519794225692749
Validation loss: 1.864941849503466

Epoch: 5| Step: 1
Training loss: 1.5512253046035767
Validation loss: 1.8619966045502694

Epoch: 5| Step: 2
Training loss: 2.133525848388672
Validation loss: 1.8113752154893772

Epoch: 5| Step: 3
Training loss: 1.420410394668579
Validation loss: 1.8186998956946916

Epoch: 5| Step: 4
Training loss: 2.058403730392456
Validation loss: 1.8251253545925181

Epoch: 5| Step: 5
Training loss: 1.5602459907531738
Validation loss: 1.8365169058563888

Epoch: 5| Step: 6
Training loss: 1.159542441368103
Validation loss: 1.8684035911354968

Epoch: 5| Step: 7
Training loss: 1.5394033193588257
Validation loss: 1.8413902213496547

Epoch: 5| Step: 8
Training loss: 1.7170226573944092
Validation loss: 1.7942732713555778

Epoch: 5| Step: 9
Training loss: 2.130521297454834
Validation loss: 1.8770887864533292

Epoch: 5| Step: 10
Training loss: 1.0651049613952637
Validation loss: 1.8247229835038543

Epoch: 300| Step: 0
Training loss: 1.5917989015579224
Validation loss: 1.863475485514569

Epoch: 5| Step: 1
Training loss: 1.3538575172424316
Validation loss: 1.809565645392223

Epoch: 5| Step: 2
Training loss: 1.715620994567871
Validation loss: 1.8823181531762565

Epoch: 5| Step: 3
Training loss: 1.7039625644683838
Validation loss: 1.8496835270235616

Epoch: 5| Step: 4
Training loss: 1.3297027349472046
Validation loss: 1.8245332599968038

Epoch: 5| Step: 5
Training loss: 1.8265984058380127
Validation loss: 1.86128907562584

Epoch: 5| Step: 6
Training loss: 1.919647455215454
Validation loss: 1.8440503984369256

Epoch: 5| Step: 7
Training loss: 1.2685792446136475
Validation loss: 1.8770453147990729

Epoch: 5| Step: 8
Training loss: 1.7610151767730713
Validation loss: 1.8699797584164528

Epoch: 5| Step: 9
Training loss: 1.5250910520553589
Validation loss: 1.8578300347892187

Epoch: 5| Step: 10
Training loss: 1.8136746883392334
Validation loss: 1.8279337036994197

Epoch: 301| Step: 0
Training loss: 1.5240800380706787
Validation loss: 1.865627449045899

Epoch: 5| Step: 1
Training loss: 1.7712618112564087
Validation loss: 1.8321013822350452

Epoch: 5| Step: 2
Training loss: 1.4528343677520752
Validation loss: 1.8613538613883398

Epoch: 5| Step: 3
Training loss: 2.166391372680664
Validation loss: 1.8284469554501195

Epoch: 5| Step: 4
Training loss: 1.8354361057281494
Validation loss: 1.8240537912614885

Epoch: 5| Step: 5
Training loss: 1.4865925312042236
Validation loss: 1.8103507411095403

Epoch: 5| Step: 6
Training loss: 1.4742485284805298
Validation loss: 1.8615433836496005

Epoch: 5| Step: 7
Training loss: 1.889634132385254
Validation loss: 1.8272505908884027

Epoch: 5| Step: 8
Training loss: 1.6552517414093018
Validation loss: 1.8701391143183554

Epoch: 5| Step: 9
Training loss: 1.2444360256195068
Validation loss: 1.8163952109634236

Epoch: 5| Step: 10
Training loss: 1.3287882804870605
Validation loss: 1.82287795312943

Epoch: 302| Step: 0
Training loss: 1.8743864297866821
Validation loss: 1.8525384203080209

Epoch: 5| Step: 1
Training loss: 1.4865435361862183
Validation loss: 1.819377339014443

Epoch: 5| Step: 2
Training loss: 1.8057657480239868
Validation loss: 1.8384766130037205

Epoch: 5| Step: 3
Training loss: 1.7974541187286377
Validation loss: 1.8464638161402878

Epoch: 5| Step: 4
Training loss: 2.2820181846618652
Validation loss: 1.8332746413446241

Epoch: 5| Step: 5
Training loss: 1.0436190366744995
Validation loss: 1.8412305488381335

Epoch: 5| Step: 6
Training loss: 1.2654002904891968
Validation loss: 1.8723431646182973

Epoch: 5| Step: 7
Training loss: 1.528188705444336
Validation loss: 1.888990948277135

Epoch: 5| Step: 8
Training loss: 1.314033031463623
Validation loss: 1.8219548553548834

Epoch: 5| Step: 9
Training loss: 1.3733361959457397
Validation loss: 1.8505143362988707

Epoch: 5| Step: 10
Training loss: 1.6166049242019653
Validation loss: 1.8442091852106073

Epoch: 303| Step: 0
Training loss: 1.2894392013549805
Validation loss: 1.8096123997883131

Epoch: 5| Step: 1
Training loss: 1.4501583576202393
Validation loss: 1.8133964769301876

Epoch: 5| Step: 2
Training loss: 1.2532302141189575
Validation loss: 1.8301127905486732

Epoch: 5| Step: 3
Training loss: 1.5907540321350098
Validation loss: 1.8205218020305838

Epoch: 5| Step: 4
Training loss: 1.8044860363006592
Validation loss: 1.8570419050032092

Epoch: 5| Step: 5
Training loss: 1.7958805561065674
Validation loss: 1.8194524959851337

Epoch: 5| Step: 6
Training loss: 2.2649173736572266
Validation loss: 1.8476309596851308

Epoch: 5| Step: 7
Training loss: 1.618675947189331
Validation loss: 1.8227162386781426

Epoch: 5| Step: 8
Training loss: 1.2797958850860596
Validation loss: 1.8768254403145082

Epoch: 5| Step: 9
Training loss: 1.6794731616973877
Validation loss: 1.8469401328794417

Epoch: 5| Step: 10
Training loss: 1.6390275955200195
Validation loss: 1.8249462599395423

Epoch: 304| Step: 0
Training loss: 1.0452455282211304
Validation loss: 1.8586796509322299

Epoch: 5| Step: 1
Training loss: 0.9885269403457642
Validation loss: 1.8634674933648878

Epoch: 5| Step: 2
Training loss: 1.5137523412704468
Validation loss: 1.8395579245782667

Epoch: 5| Step: 3
Training loss: 1.6793451309204102
Validation loss: 1.85023239351088

Epoch: 5| Step: 4
Training loss: 2.203037738800049
Validation loss: 1.848554749642649

Epoch: 5| Step: 5
Training loss: 1.5654399394989014
Validation loss: 1.8418782654628958

Epoch: 5| Step: 6
Training loss: 1.9229320287704468
Validation loss: 1.8225887385747765

Epoch: 5| Step: 7
Training loss: 1.5548419952392578
Validation loss: 1.8347993191852365

Epoch: 5| Step: 8
Training loss: 1.944908857345581
Validation loss: 1.8543166268256404

Epoch: 5| Step: 9
Training loss: 1.1746728420257568
Validation loss: 1.827973625993216

Epoch: 5| Step: 10
Training loss: 2.0872414112091064
Validation loss: 1.8446544972799157

Epoch: 305| Step: 0
Training loss: 1.3343862295150757
Validation loss: 1.8124264978593396

Epoch: 5| Step: 1
Training loss: 1.3559019565582275
Validation loss: 1.8525777068189395

Epoch: 5| Step: 2
Training loss: 1.4167684316635132
Validation loss: 1.8255936497001237

Epoch: 5| Step: 3
Training loss: 1.788270354270935
Validation loss: 1.8565028534140637

Epoch: 5| Step: 4
Training loss: 1.852927803993225
Validation loss: 1.7811399570075415

Epoch: 5| Step: 5
Training loss: 1.9997886419296265
Validation loss: 1.8545635502825502

Epoch: 5| Step: 6
Training loss: 1.8271009922027588
Validation loss: 1.8387787393344346

Epoch: 5| Step: 7
Training loss: 1.0107676982879639
Validation loss: 1.811029129130866

Epoch: 5| Step: 8
Training loss: 1.6889480352401733
Validation loss: 1.83919479257317

Epoch: 5| Step: 9
Training loss: 1.7665739059448242
Validation loss: 1.784109491173939

Epoch: 5| Step: 10
Training loss: 1.4099931716918945
Validation loss: 1.848734212178056

Epoch: 306| Step: 0
Training loss: 1.184037446975708
Validation loss: 1.7859914789917648

Epoch: 5| Step: 1
Training loss: 1.9246540069580078
Validation loss: 1.864364884232962

Epoch: 5| Step: 2
Training loss: 1.6776397228240967
Validation loss: 1.8148961541473225

Epoch: 5| Step: 3
Training loss: 1.4414703845977783
Validation loss: 1.8347022725689797

Epoch: 5| Step: 4
Training loss: 2.0414395332336426
Validation loss: 1.8741325870636971

Epoch: 5| Step: 5
Training loss: 1.194534420967102
Validation loss: 1.8162803496083906

Epoch: 5| Step: 6
Training loss: 1.5298610925674438
Validation loss: 1.8141813175652617

Epoch: 5| Step: 7
Training loss: 1.6471641063690186
Validation loss: 1.8450550892019784

Epoch: 5| Step: 8
Training loss: 1.8744306564331055
Validation loss: 1.7999877519504999

Epoch: 5| Step: 9
Training loss: 1.8011248111724854
Validation loss: 1.8595660219910324

Epoch: 5| Step: 10
Training loss: 1.4794448614120483
Validation loss: 1.8289131067132438

Epoch: 307| Step: 0
Training loss: 1.6620845794677734
Validation loss: 1.835633703457412

Epoch: 5| Step: 1
Training loss: 1.5659326314926147
Validation loss: 1.846224614368972

Epoch: 5| Step: 2
Training loss: 1.6912806034088135
Validation loss: 1.792426589996584

Epoch: 5| Step: 3
Training loss: 1.6149671077728271
Validation loss: 1.8135122765776932

Epoch: 5| Step: 4
Training loss: 1.5929560661315918
Validation loss: 1.8491102726228776

Epoch: 5| Step: 5
Training loss: 1.807708740234375
Validation loss: 1.8766339901954896

Epoch: 5| Step: 6
Training loss: 1.922075629234314
Validation loss: 1.8413474931511828

Epoch: 5| Step: 7
Training loss: 1.1888188123703003
Validation loss: 1.8687131584331553

Epoch: 5| Step: 8
Training loss: 1.4045703411102295
Validation loss: 1.8776214020226591

Epoch: 5| Step: 9
Training loss: 1.4660193920135498
Validation loss: 1.8963028230974752

Epoch: 5| Step: 10
Training loss: 1.6173250675201416
Validation loss: 1.8937996766900504

Epoch: 308| Step: 0
Training loss: 1.921295166015625
Validation loss: 1.8801132273930374

Epoch: 5| Step: 1
Training loss: 1.8491405248641968
Validation loss: 1.868493918449648

Epoch: 5| Step: 2
Training loss: 1.499780535697937
Validation loss: 1.8807375161878523

Epoch: 5| Step: 3
Training loss: 2.0086302757263184
Validation loss: 1.870598860966262

Epoch: 5| Step: 4
Training loss: 1.1107311248779297
Validation loss: 1.8531614260006977

Epoch: 5| Step: 5
Training loss: 1.2635362148284912
Validation loss: 1.841666930465288

Epoch: 5| Step: 6
Training loss: 1.2292816638946533
Validation loss: 1.8962309411776963

Epoch: 5| Step: 7
Training loss: 1.594396948814392
Validation loss: 1.865660567437449

Epoch: 5| Step: 8
Training loss: 1.1945503950119019
Validation loss: 1.8422766629085745

Epoch: 5| Step: 9
Training loss: 1.5065467357635498
Validation loss: 1.83535139278699

Epoch: 5| Step: 10
Training loss: 2.1027004718780518
Validation loss: 1.7652626652871408

Epoch: 309| Step: 0
Training loss: 1.1874310970306396
Validation loss: 1.8509015549895584

Epoch: 5| Step: 1
Training loss: 1.6394574642181396
Validation loss: 1.8209236052728468

Epoch: 5| Step: 2
Training loss: 1.6911262273788452
Validation loss: 1.8163455070987824

Epoch: 5| Step: 3
Training loss: 2.1754775047302246
Validation loss: 1.827692219006118

Epoch: 5| Step: 4
Training loss: 2.1210134029388428
Validation loss: 1.8166612245703255

Epoch: 5| Step: 5
Training loss: 1.5938162803649902
Validation loss: 1.8375742461091729

Epoch: 5| Step: 6
Training loss: 1.2644649744033813
Validation loss: 1.8595780557201755

Epoch: 5| Step: 7
Training loss: 1.1210196018218994
Validation loss: 1.7987731477265716

Epoch: 5| Step: 8
Training loss: 1.7802164554595947
Validation loss: 1.8621166124138782

Epoch: 5| Step: 9
Training loss: 1.0612455606460571
Validation loss: 1.798342288181346

Epoch: 5| Step: 10
Training loss: 1.58601713180542
Validation loss: 1.8151230119889783

Epoch: 310| Step: 0
Training loss: 1.0844310522079468
Validation loss: 1.8515585699389059

Epoch: 5| Step: 1
Training loss: 1.7452112436294556
Validation loss: 1.8536602758592176

Epoch: 5| Step: 2
Training loss: 2.1166718006134033
Validation loss: 1.836819189851002

Epoch: 5| Step: 3
Training loss: 1.2211410999298096
Validation loss: 1.8319157682439333

Epoch: 5| Step: 4
Training loss: 1.2125009298324585
Validation loss: 1.8123445767228321

Epoch: 5| Step: 5
Training loss: 1.7559095621109009
Validation loss: 1.8333464527642855

Epoch: 5| Step: 6
Training loss: 2.018601417541504
Validation loss: 1.8486528063333163

Epoch: 5| Step: 7
Training loss: 1.3800277709960938
Validation loss: 1.836491395068425

Epoch: 5| Step: 8
Training loss: 1.7618286609649658
Validation loss: 1.8087627631361767

Epoch: 5| Step: 9
Training loss: 1.5442626476287842
Validation loss: 1.8083426478088542

Epoch: 5| Step: 10
Training loss: 1.5340805053710938
Validation loss: 1.7760999254001084

Epoch: 311| Step: 0
Training loss: 2.3285648822784424
Validation loss: 1.8289049774087884

Epoch: 5| Step: 1
Training loss: 1.6443713903427124
Validation loss: 1.892150681505921

Epoch: 5| Step: 2
Training loss: 1.769148588180542
Validation loss: 1.8452159512427546

Epoch: 5| Step: 3
Training loss: 1.1881248950958252
Validation loss: 1.8153528167355446

Epoch: 5| Step: 4
Training loss: 1.8160803318023682
Validation loss: 1.8233802062208935

Epoch: 5| Step: 5
Training loss: 1.390959620475769
Validation loss: 1.846506203374555

Epoch: 5| Step: 6
Training loss: 1.4911534786224365
Validation loss: 1.8420172660581526

Epoch: 5| Step: 7
Training loss: 1.4377275705337524
Validation loss: 1.8134072954936693

Epoch: 5| Step: 8
Training loss: 1.3334242105484009
Validation loss: 1.8423150918817008

Epoch: 5| Step: 9
Training loss: 1.4195821285247803
Validation loss: 1.8206867864055019

Epoch: 5| Step: 10
Training loss: 1.5677452087402344
Validation loss: 1.810700103800784

Epoch: 312| Step: 0
Training loss: 1.239290475845337
Validation loss: 1.833331872058171

Epoch: 5| Step: 1
Training loss: 2.112273693084717
Validation loss: 1.8692294166934105

Epoch: 5| Step: 2
Training loss: 1.512915849685669
Validation loss: 1.8098220902104531

Epoch: 5| Step: 3
Training loss: 1.348819613456726
Validation loss: 1.8778968318816154

Epoch: 5| Step: 4
Training loss: 1.9228070974349976
Validation loss: 1.8504467420680548

Epoch: 5| Step: 5
Training loss: 1.7440881729125977
Validation loss: 1.8355922468246952

Epoch: 5| Step: 6
Training loss: 1.573201060295105
Validation loss: 1.831681974472538

Epoch: 5| Step: 7
Training loss: 1.5264045000076294
Validation loss: 1.858117239449614

Epoch: 5| Step: 8
Training loss: 1.5727980136871338
Validation loss: 1.8216160651176208

Epoch: 5| Step: 9
Training loss: 1.3466840982437134
Validation loss: 1.8505409507341282

Epoch: 5| Step: 10
Training loss: 1.409572720527649
Validation loss: 1.8531971259783673

Epoch: 313| Step: 0
Training loss: 1.258674144744873
Validation loss: 1.849048376083374

Epoch: 5| Step: 1
Training loss: 1.5761216878890991
Validation loss: 1.8614135314059514

Epoch: 5| Step: 2
Training loss: 1.4265496730804443
Validation loss: 1.8148170260972873

Epoch: 5| Step: 3
Training loss: 1.5135314464569092
Validation loss: 1.8515674350082234

Epoch: 5| Step: 4
Training loss: 1.8171465396881104
Validation loss: 1.8075538040489278

Epoch: 5| Step: 5
Training loss: 1.1669727563858032
Validation loss: 1.8256716779483262

Epoch: 5| Step: 6
Training loss: 1.604770302772522
Validation loss: 1.822918781670191

Epoch: 5| Step: 7
Training loss: 1.360724925994873
Validation loss: 1.8397768928158669

Epoch: 5| Step: 8
Training loss: 2.2105698585510254
Validation loss: 1.8335425482001355

Epoch: 5| Step: 9
Training loss: 1.4897434711456299
Validation loss: 1.8449699558237547

Epoch: 5| Step: 10
Training loss: 1.6801550388336182
Validation loss: 1.826886365490575

Epoch: 314| Step: 0
Training loss: 1.3564749956130981
Validation loss: 1.8606243518091017

Epoch: 5| Step: 1
Training loss: 1.0118415355682373
Validation loss: 1.792133979899909

Epoch: 5| Step: 2
Training loss: 1.6755759716033936
Validation loss: 1.820340512901224

Epoch: 5| Step: 3
Training loss: 1.2491873502731323
Validation loss: 1.826631244792733

Epoch: 5| Step: 4
Training loss: 2.2118210792541504
Validation loss: 1.8264823280354983

Epoch: 5| Step: 5
Training loss: 1.6526609659194946
Validation loss: 1.8349832604008336

Epoch: 5| Step: 6
Training loss: 1.7686840295791626
Validation loss: 1.8390111897581367

Epoch: 5| Step: 7
Training loss: 1.18528413772583
Validation loss: 1.8468679702410133

Epoch: 5| Step: 8
Training loss: 1.4122406244277954
Validation loss: 1.8507352913579633

Epoch: 5| Step: 9
Training loss: 1.7816340923309326
Validation loss: 1.8716983743893203

Epoch: 5| Step: 10
Training loss: 2.0915513038635254
Validation loss: 1.8602882457035843

Epoch: 315| Step: 0
Training loss: 1.258279800415039
Validation loss: 1.876303243380721

Epoch: 5| Step: 1
Training loss: 1.5927011966705322
Validation loss: 1.816567858060201

Epoch: 5| Step: 2
Training loss: 1.4065310955047607
Validation loss: 1.8665034488965107

Epoch: 5| Step: 3
Training loss: 1.4360953569412231
Validation loss: 1.7914087708278368

Epoch: 5| Step: 4
Training loss: 1.6835979223251343
Validation loss: 1.8322919517435052

Epoch: 5| Step: 5
Training loss: 1.4564179182052612
Validation loss: 1.8720119525027532

Epoch: 5| Step: 6
Training loss: 1.4754596948623657
Validation loss: 1.8203413281389462

Epoch: 5| Step: 7
Training loss: 1.8723433017730713
Validation loss: 1.8079497993633311

Epoch: 5| Step: 8
Training loss: 1.679474115371704
Validation loss: 1.8606423434390817

Epoch: 5| Step: 9
Training loss: 1.6200765371322632
Validation loss: 1.8331559729832474

Epoch: 5| Step: 10
Training loss: 1.462402105331421
Validation loss: 1.8386171479378977

Epoch: 316| Step: 0
Training loss: 1.3840034008026123
Validation loss: 1.832130220628554

Epoch: 5| Step: 1
Training loss: 2.3630459308624268
Validation loss: 1.8351154635029454

Epoch: 5| Step: 2
Training loss: 1.666926383972168
Validation loss: 1.8445624048991869

Epoch: 5| Step: 3
Training loss: 1.6903671026229858
Validation loss: 1.8097893499558972

Epoch: 5| Step: 4
Training loss: 1.4983782768249512
Validation loss: 1.7898825746710583

Epoch: 5| Step: 5
Training loss: 1.7610530853271484
Validation loss: 1.8048512628001552

Epoch: 5| Step: 6
Training loss: 1.3890392780303955
Validation loss: 1.8258554012544694

Epoch: 5| Step: 7
Training loss: 1.275713324546814
Validation loss: 1.8059748372723978

Epoch: 5| Step: 8
Training loss: 1.8884658813476562
Validation loss: 1.818350463785151

Epoch: 5| Step: 9
Training loss: 1.4741779565811157
Validation loss: 1.8406168696700886

Epoch: 5| Step: 10
Training loss: 0.5960645079612732
Validation loss: 1.8310693451153335

Epoch: 317| Step: 0
Training loss: 1.5455119609832764
Validation loss: 1.8406231557169268

Epoch: 5| Step: 1
Training loss: 1.9881922006607056
Validation loss: 1.8960675334417691

Epoch: 5| Step: 2
Training loss: 1.2722607851028442
Validation loss: 1.865036661906909

Epoch: 5| Step: 3
Training loss: 2.1474175453186035
Validation loss: 1.8521377117403093

Epoch: 5| Step: 4
Training loss: 0.8229330778121948
Validation loss: 1.8470220053067772

Epoch: 5| Step: 5
Training loss: 1.8204584121704102
Validation loss: 1.8606601171596076

Epoch: 5| Step: 6
Training loss: 1.8380893468856812
Validation loss: 1.8229852132899786

Epoch: 5| Step: 7
Training loss: 1.782741904258728
Validation loss: 1.834549080940985

Epoch: 5| Step: 8
Training loss: 0.997027575969696
Validation loss: 1.808638640629348

Epoch: 5| Step: 9
Training loss: 1.7433891296386719
Validation loss: 1.7932873336217736

Epoch: 5| Step: 10
Training loss: 1.0715919733047485
Validation loss: 1.8571139458687074

Epoch: 318| Step: 0
Training loss: 1.0633890628814697
Validation loss: 1.7877989994582308

Epoch: 5| Step: 1
Training loss: 1.4968284368515015
Validation loss: 1.797502136999561

Epoch: 5| Step: 2
Training loss: 1.6201000213623047
Validation loss: 1.8599605329575077

Epoch: 5| Step: 3
Training loss: 2.027923822402954
Validation loss: 1.7916952589506745

Epoch: 5| Step: 4
Training loss: 1.9116780757904053
Validation loss: 1.8096768368956864

Epoch: 5| Step: 5
Training loss: 1.3257547616958618
Validation loss: 1.827961370509158

Epoch: 5| Step: 6
Training loss: 1.0697381496429443
Validation loss: 1.8133170758524249

Epoch: 5| Step: 7
Training loss: 1.9338271617889404
Validation loss: 1.8213788155586488

Epoch: 5| Step: 8
Training loss: 1.3574278354644775
Validation loss: 1.8136189970918881

Epoch: 5| Step: 9
Training loss: 1.894342064857483
Validation loss: 1.815066001748526

Epoch: 5| Step: 10
Training loss: 1.6891803741455078
Validation loss: 1.8427347380627868

Epoch: 319| Step: 0
Training loss: 2.3601057529449463
Validation loss: 1.7911189422812512

Epoch: 5| Step: 1
Training loss: 1.3388324975967407
Validation loss: 1.8637304357303086

Epoch: 5| Step: 2
Training loss: 1.5148388147354126
Validation loss: 1.845783923261909

Epoch: 5| Step: 3
Training loss: 1.5425517559051514
Validation loss: 1.9111600281089864

Epoch: 5| Step: 4
Training loss: 1.5483601093292236
Validation loss: 1.84158411974548

Epoch: 5| Step: 5
Training loss: 1.359618067741394
Validation loss: 1.8299065507868284

Epoch: 5| Step: 6
Training loss: 1.4861400127410889
Validation loss: 1.8724021142528904

Epoch: 5| Step: 7
Training loss: 1.8532453775405884
Validation loss: 1.83032819532579

Epoch: 5| Step: 8
Training loss: 1.6923131942749023
Validation loss: 1.8316356033407233

Epoch: 5| Step: 9
Training loss: 1.1943506002426147
Validation loss: 1.7885727126111266

Epoch: 5| Step: 10
Training loss: 1.3002550601959229
Validation loss: 1.7808443910332137

Epoch: 320| Step: 0
Training loss: 1.6776021718978882
Validation loss: 1.8081643248117099

Epoch: 5| Step: 1
Training loss: 1.1002180576324463
Validation loss: 1.7867878803642847

Epoch: 5| Step: 2
Training loss: 1.7893149852752686
Validation loss: 1.8504362977961057

Epoch: 5| Step: 3
Training loss: 1.9518409967422485
Validation loss: 1.8113971756350609

Epoch: 5| Step: 4
Training loss: 1.3685617446899414
Validation loss: 1.8403431497594362

Epoch: 5| Step: 5
Training loss: 1.738512635231018
Validation loss: 1.8073673735382736

Epoch: 5| Step: 6
Training loss: 1.1599732637405396
Validation loss: 1.8379606662258026

Epoch: 5| Step: 7
Training loss: 1.4274309873580933
Validation loss: 1.8127462146102742

Epoch: 5| Step: 8
Training loss: 1.6431926488876343
Validation loss: 1.7903774579366047

Epoch: 5| Step: 9
Training loss: 1.2957966327667236
Validation loss: 1.8049852514779696

Epoch: 5| Step: 10
Training loss: 1.7261576652526855
Validation loss: 1.8023659272860455

Epoch: 321| Step: 0
Training loss: 1.7133958339691162
Validation loss: 1.8176315497326594

Epoch: 5| Step: 1
Training loss: 1.3366600275039673
Validation loss: 1.8020017249609834

Epoch: 5| Step: 2
Training loss: 1.7849111557006836
Validation loss: 1.7955562350570515

Epoch: 5| Step: 3
Training loss: 2.085965633392334
Validation loss: 1.8366341103789627

Epoch: 5| Step: 4
Training loss: 1.3702129125595093
Validation loss: 1.7914555649603567

Epoch: 5| Step: 5
Training loss: 1.40743887424469
Validation loss: 1.832049544139575

Epoch: 5| Step: 6
Training loss: 1.3839740753173828
Validation loss: 1.821873672546879

Epoch: 5| Step: 7
Training loss: 1.1345192193984985
Validation loss: 1.7899027550092308

Epoch: 5| Step: 8
Training loss: 1.5258183479309082
Validation loss: 1.8202431317298644

Epoch: 5| Step: 9
Training loss: 1.3998676538467407
Validation loss: 1.8211489082664571

Epoch: 5| Step: 10
Training loss: 1.1744050979614258
Validation loss: 1.8185259347320886

Epoch: 322| Step: 0
Training loss: 2.0254082679748535
Validation loss: 1.832761203089068

Epoch: 5| Step: 1
Training loss: 1.6876789331436157
Validation loss: 1.8409590080220213

Epoch: 5| Step: 2
Training loss: 1.456348180770874
Validation loss: 1.8038490049300655

Epoch: 5| Step: 3
Training loss: 1.3814764022827148
Validation loss: 1.8466692534826135

Epoch: 5| Step: 4
Training loss: 1.305727243423462
Validation loss: 1.7951359325839626

Epoch: 5| Step: 5
Training loss: 1.3236500024795532
Validation loss: 1.796746156548941

Epoch: 5| Step: 6
Training loss: 2.120164632797241
Validation loss: 1.7787860593488138

Epoch: 5| Step: 7
Training loss: 1.5604625940322876
Validation loss: 1.8284235872248167

Epoch: 5| Step: 8
Training loss: 1.753228783607483
Validation loss: 1.8340116649545648

Epoch: 5| Step: 9
Training loss: 1.054311990737915
Validation loss: 1.8048243650826075

Epoch: 5| Step: 10
Training loss: 1.212417483329773
Validation loss: 1.8241142457531345

Epoch: 323| Step: 0
Training loss: 1.5609614849090576
Validation loss: 1.7808348286536433

Epoch: 5| Step: 1
Training loss: 1.3814139366149902
Validation loss: 1.8295663684927008

Epoch: 5| Step: 2
Training loss: 1.1685585975646973
Validation loss: 1.8257547475958382

Epoch: 5| Step: 3
Training loss: 1.28592050075531
Validation loss: 1.830373905038321

Epoch: 5| Step: 4
Training loss: 1.299588918685913
Validation loss: 1.825387434292865

Epoch: 5| Step: 5
Training loss: 1.524486780166626
Validation loss: 1.831078093539002

Epoch: 5| Step: 6
Training loss: 1.5839704275131226
Validation loss: 1.7799550666603992

Epoch: 5| Step: 7
Training loss: 1.806217908859253
Validation loss: 1.8300487482419578

Epoch: 5| Step: 8
Training loss: 1.3790539503097534
Validation loss: 1.827377030926366

Epoch: 5| Step: 9
Training loss: 1.8394100666046143
Validation loss: 1.8096986970593851

Epoch: 5| Step: 10
Training loss: 1.9059399366378784
Validation loss: 1.817620926005866

Epoch: 324| Step: 0
Training loss: 1.3562769889831543
Validation loss: 1.8190416930824198

Epoch: 5| Step: 1
Training loss: 1.6733314990997314
Validation loss: 1.81711398401568

Epoch: 5| Step: 2
Training loss: 1.538347840309143
Validation loss: 1.8442509699893255

Epoch: 5| Step: 3
Training loss: 1.1411311626434326
Validation loss: 1.8645651609666887

Epoch: 5| Step: 4
Training loss: 1.544039249420166
Validation loss: 1.8337970549060452

Epoch: 5| Step: 5
Training loss: 1.8471992015838623
Validation loss: 1.9059221898355792

Epoch: 5| Step: 6
Training loss: 1.2631404399871826
Validation loss: 1.8632533729717295

Epoch: 5| Step: 7
Training loss: 1.943128228187561
Validation loss: 1.809426434578434

Epoch: 5| Step: 8
Training loss: 1.5734078884124756
Validation loss: 1.8558413777300107

Epoch: 5| Step: 9
Training loss: 1.6835222244262695
Validation loss: 1.8438102058185044

Epoch: 5| Step: 10
Training loss: 0.9761382937431335
Validation loss: 1.8414379204473188

Epoch: 325| Step: 0
Training loss: 1.1341121196746826
Validation loss: 1.8042706430599253

Epoch: 5| Step: 1
Training loss: 1.5459693670272827
Validation loss: 1.8332497689031786

Epoch: 5| Step: 2
Training loss: 1.5783319473266602
Validation loss: 1.7896969613208566

Epoch: 5| Step: 3
Training loss: 1.3440431356430054
Validation loss: 1.839426189340571

Epoch: 5| Step: 4
Training loss: 1.230105996131897
Validation loss: 1.8093817310948526

Epoch: 5| Step: 5
Training loss: 1.9327564239501953
Validation loss: 1.8189615549579743

Epoch: 5| Step: 6
Training loss: 1.9937702417373657
Validation loss: 1.8224851687749226

Epoch: 5| Step: 7
Training loss: 1.5223389863967896
Validation loss: 1.8042314975492415

Epoch: 5| Step: 8
Training loss: 1.2413666248321533
Validation loss: 1.8383055092186056

Epoch: 5| Step: 9
Training loss: 1.3431645631790161
Validation loss: 1.8047370679916874

Epoch: 5| Step: 10
Training loss: 1.945165753364563
Validation loss: 1.8293662583956154

Epoch: 326| Step: 0
Training loss: 1.4522147178649902
Validation loss: 1.8317063341858566

Epoch: 5| Step: 1
Training loss: 1.6715911626815796
Validation loss: 1.8725115611989012

Epoch: 5| Step: 2
Training loss: 1.8857002258300781
Validation loss: 1.8275609195873301

Epoch: 5| Step: 3
Training loss: 1.4837695360183716
Validation loss: 1.8381239932070497

Epoch: 5| Step: 4
Training loss: 1.8136526346206665
Validation loss: 1.7983740657888434

Epoch: 5| Step: 5
Training loss: 1.5674817562103271
Validation loss: 1.8207511645491405

Epoch: 5| Step: 6
Training loss: 1.2280229330062866
Validation loss: 1.8206110462065666

Epoch: 5| Step: 7
Training loss: 1.7472511529922485
Validation loss: 1.825068740434544

Epoch: 5| Step: 8
Training loss: 1.0947399139404297
Validation loss: 1.8124720306806668

Epoch: 5| Step: 9
Training loss: 1.4390760660171509
Validation loss: 1.8146305878957112

Epoch: 5| Step: 10
Training loss: 1.5364911556243896
Validation loss: 1.827933680626654

Epoch: 327| Step: 0
Training loss: 1.5211139917373657
Validation loss: 1.7549568953052643

Epoch: 5| Step: 1
Training loss: 1.2743499279022217
Validation loss: 1.801035883606121

Epoch: 5| Step: 2
Training loss: 1.5930652618408203
Validation loss: 1.7964288009110319

Epoch: 5| Step: 3
Training loss: 1.3737986087799072
Validation loss: 1.8229548661939559

Epoch: 5| Step: 4
Training loss: 1.3491710424423218
Validation loss: 1.8201028429051882

Epoch: 5| Step: 5
Training loss: 1.9336506128311157
Validation loss: 1.8489191609044229

Epoch: 5| Step: 6
Training loss: 1.330422282218933
Validation loss: 1.776416600391429

Epoch: 5| Step: 7
Training loss: 1.5317658185958862
Validation loss: 1.8273467979123514

Epoch: 5| Step: 8
Training loss: 1.6945216655731201
Validation loss: 1.803746086294933

Epoch: 5| Step: 9
Training loss: 1.0859529972076416
Validation loss: 1.8241791930249942

Epoch: 5| Step: 10
Training loss: 1.8371754884719849
Validation loss: 1.7956231153139504

Epoch: 328| Step: 0
Training loss: 1.9892040491104126
Validation loss: 1.8247259214360227

Epoch: 5| Step: 1
Training loss: 2.2367124557495117
Validation loss: 1.827229630562567

Epoch: 5| Step: 2
Training loss: 0.9077436327934265
Validation loss: 1.8372395525696457

Epoch: 5| Step: 3
Training loss: 1.480961561203003
Validation loss: 1.8109286164724698

Epoch: 5| Step: 4
Training loss: 1.277421236038208
Validation loss: 1.8315769254520375

Epoch: 5| Step: 5
Training loss: 1.5669708251953125
Validation loss: 1.807601337791771

Epoch: 5| Step: 6
Training loss: 1.5617446899414062
Validation loss: 1.9044299561490294

Epoch: 5| Step: 7
Training loss: 1.455912709236145
Validation loss: 1.8364947278012511

Epoch: 5| Step: 8
Training loss: 1.3307464122772217
Validation loss: 1.8265323369733748

Epoch: 5| Step: 9
Training loss: 1.3233764171600342
Validation loss: 1.8100123277274511

Epoch: 5| Step: 10
Training loss: 1.4060180187225342
Validation loss: 1.8327757312405495

Epoch: 329| Step: 0
Training loss: 1.4053620100021362
Validation loss: 1.840776087135397

Epoch: 5| Step: 1
Training loss: 1.5374256372451782
Validation loss: 1.848862180145838

Epoch: 5| Step: 2
Training loss: 1.6520042419433594
Validation loss: 1.892519356102072

Epoch: 5| Step: 3
Training loss: 1.2605934143066406
Validation loss: 1.82005871752257

Epoch: 5| Step: 4
Training loss: 1.5979646444320679
Validation loss: 1.861225196110305

Epoch: 5| Step: 5
Training loss: 1.9298479557037354
Validation loss: 1.8130344293450797

Epoch: 5| Step: 6
Training loss: 1.334602952003479
Validation loss: 1.858312693975305

Epoch: 5| Step: 7
Training loss: 1.5773251056671143
Validation loss: 1.8475878520678448

Epoch: 5| Step: 8
Training loss: 1.1563884019851685
Validation loss: 1.7596320529137888

Epoch: 5| Step: 9
Training loss: 1.5201842784881592
Validation loss: 1.8328934997640631

Epoch: 5| Step: 10
Training loss: 1.5196311473846436
Validation loss: 1.8116028103777158

Epoch: 330| Step: 0
Training loss: 1.7799714803695679
Validation loss: 1.7777907489448466

Epoch: 5| Step: 1
Training loss: 1.3245409727096558
Validation loss: 1.7944199603091004

Epoch: 5| Step: 2
Training loss: 2.1521592140197754
Validation loss: 1.7927959734393704

Epoch: 5| Step: 3
Training loss: 0.8694320917129517
Validation loss: 1.8053001537117908

Epoch: 5| Step: 4
Training loss: 1.8883453607559204
Validation loss: 1.7927498202170096

Epoch: 5| Step: 5
Training loss: 1.5335419178009033
Validation loss: 1.7964690423780871

Epoch: 5| Step: 6
Training loss: 1.790466547012329
Validation loss: 1.8405104157745198

Epoch: 5| Step: 7
Training loss: 1.4059644937515259
Validation loss: 1.8186037117435085

Epoch: 5| Step: 8
Training loss: 1.4922921657562256
Validation loss: 1.8264246230484338

Epoch: 5| Step: 9
Training loss: 1.1588122844696045
Validation loss: 1.7744034439004877

Epoch: 5| Step: 10
Training loss: 1.099159836769104
Validation loss: 1.8322252842687792

Epoch: 331| Step: 0
Training loss: 1.17720365524292
Validation loss: 1.8372406421169158

Epoch: 5| Step: 1
Training loss: 1.1732820272445679
Validation loss: 1.849384129688304

Epoch: 5| Step: 2
Training loss: 1.0759004354476929
Validation loss: 1.856801930294242

Epoch: 5| Step: 3
Training loss: 1.5160638093948364
Validation loss: 1.9035246013313212

Epoch: 5| Step: 4
Training loss: 1.3539572954177856
Validation loss: 1.857125073350886

Epoch: 5| Step: 5
Training loss: 1.4700580835342407
Validation loss: 1.849936290453839

Epoch: 5| Step: 6
Training loss: 1.9310925006866455
Validation loss: 1.8492161381629206

Epoch: 5| Step: 7
Training loss: 1.9941718578338623
Validation loss: 1.810287752459126

Epoch: 5| Step: 8
Training loss: 1.684562087059021
Validation loss: 1.818169669438434

Epoch: 5| Step: 9
Training loss: 1.659491777420044
Validation loss: 1.834128596449411

Epoch: 5| Step: 10
Training loss: 1.4089763164520264
Validation loss: 1.865290585384574

Epoch: 332| Step: 0
Training loss: 1.3329477310180664
Validation loss: 1.797414848881383

Epoch: 5| Step: 1
Training loss: 1.8670520782470703
Validation loss: 1.8339037356838104

Epoch: 5| Step: 2
Training loss: 1.5533536672592163
Validation loss: 1.8176541174611738

Epoch: 5| Step: 3
Training loss: 1.5080639123916626
Validation loss: 1.806399300534238

Epoch: 5| Step: 4
Training loss: 1.3854763507843018
Validation loss: 1.8300687420752741

Epoch: 5| Step: 5
Training loss: 1.7256786823272705
Validation loss: 1.8083779914404756

Epoch: 5| Step: 6
Training loss: 1.9022260904312134
Validation loss: 1.8123528342093191

Epoch: 5| Step: 7
Training loss: 1.5964149236679077
Validation loss: 1.8539751857839606

Epoch: 5| Step: 8
Training loss: 1.4447190761566162
Validation loss: 1.8292878084285285

Epoch: 5| Step: 9
Training loss: 0.6255217790603638
Validation loss: 1.798884985267475

Epoch: 5| Step: 10
Training loss: 1.1666536331176758
Validation loss: 1.7781820707423712

Epoch: 333| Step: 0
Training loss: 1.1854209899902344
Validation loss: 1.835949533729143

Epoch: 5| Step: 1
Training loss: 1.6919853687286377
Validation loss: 1.8330956518009145

Epoch: 5| Step: 2
Training loss: 1.6093518733978271
Validation loss: 1.7693388308248212

Epoch: 5| Step: 3
Training loss: 1.2187309265136719
Validation loss: 1.7894560034557054

Epoch: 5| Step: 4
Training loss: 1.4310979843139648
Validation loss: 1.8544983389557048

Epoch: 5| Step: 5
Training loss: 1.6638721227645874
Validation loss: 1.8021486984786166

Epoch: 5| Step: 6
Training loss: 1.521510124206543
Validation loss: 1.7870570844219578

Epoch: 5| Step: 7
Training loss: 2.116572856903076
Validation loss: 1.799551499146287

Epoch: 5| Step: 8
Training loss: 1.1872708797454834
Validation loss: 1.7985352880211287

Epoch: 5| Step: 9
Training loss: 1.3638620376586914
Validation loss: 1.8141267889289445

Epoch: 5| Step: 10
Training loss: 1.11696195602417
Validation loss: 1.8177009180027952

Epoch: 334| Step: 0
Training loss: 1.5913121700286865
Validation loss: 1.7903088126131284

Epoch: 5| Step: 1
Training loss: 1.2409064769744873
Validation loss: 1.8350960541796941

Epoch: 5| Step: 2
Training loss: 1.9095414876937866
Validation loss: 1.8315143700568908

Epoch: 5| Step: 3
Training loss: 1.0856283903121948
Validation loss: 1.8338995043949415

Epoch: 5| Step: 4
Training loss: 1.6285383701324463
Validation loss: 1.8047317125463997

Epoch: 5| Step: 5
Training loss: 2.182556390762329
Validation loss: 1.806961759444206

Epoch: 5| Step: 6
Training loss: 1.2778639793395996
Validation loss: 1.8369275293042582

Epoch: 5| Step: 7
Training loss: 0.9425451159477234
Validation loss: 1.8175687431007304

Epoch: 5| Step: 8
Training loss: 1.5750490427017212
Validation loss: 1.8826208576079337

Epoch: 5| Step: 9
Training loss: 1.2839761972427368
Validation loss: 1.8093678092443815

Epoch: 5| Step: 10
Training loss: 1.4521702527999878
Validation loss: 1.8200811442508493

Epoch: 335| Step: 0
Training loss: 1.079622507095337
Validation loss: 1.8242930109782884

Epoch: 5| Step: 1
Training loss: 1.6439316272735596
Validation loss: 1.8112879363439416

Epoch: 5| Step: 2
Training loss: 1.8489372730255127
Validation loss: 1.7993807946482012

Epoch: 5| Step: 3
Training loss: 1.652433156967163
Validation loss: 1.776211138694517

Epoch: 5| Step: 4
Training loss: 1.545111060142517
Validation loss: 1.8316925161628312

Epoch: 5| Step: 5
Training loss: 1.4318221807479858
Validation loss: 1.8078115281238352

Epoch: 5| Step: 6
Training loss: 1.7841860055923462
Validation loss: 1.8382143538485292

Epoch: 5| Step: 7
Training loss: 0.9699982404708862
Validation loss: 1.7990486724402315

Epoch: 5| Step: 8
Training loss: 1.1222779750823975
Validation loss: 1.8224586773944158

Epoch: 5| Step: 9
Training loss: 1.8595308065414429
Validation loss: 1.7891233826196322

Epoch: 5| Step: 10
Training loss: 1.16802978515625
Validation loss: 1.7901547980564896

Epoch: 336| Step: 0
Training loss: 1.182119607925415
Validation loss: 1.7719661599846297

Epoch: 5| Step: 1
Training loss: 1.6980187892913818
Validation loss: 1.7744969988381991

Epoch: 5| Step: 2
Training loss: 1.3648757934570312
Validation loss: 1.8158584871599752

Epoch: 5| Step: 3
Training loss: 1.2222130298614502
Validation loss: 1.77772097433767

Epoch: 5| Step: 4
Training loss: 1.6463415622711182
Validation loss: 1.8120656269852833

Epoch: 5| Step: 5
Training loss: 1.7108478546142578
Validation loss: 1.8137783940120409

Epoch: 5| Step: 6
Training loss: 1.6717844009399414
Validation loss: 1.8408072289600168

Epoch: 5| Step: 7
Training loss: 1.3371977806091309
Validation loss: 1.824840752027368

Epoch: 5| Step: 8
Training loss: 1.5439107418060303
Validation loss: 1.816255687385477

Epoch: 5| Step: 9
Training loss: 1.055346131324768
Validation loss: 1.773036144113028

Epoch: 5| Step: 10
Training loss: 1.8605064153671265
Validation loss: 1.8215913388036913

Epoch: 337| Step: 0
Training loss: 1.9594335556030273
Validation loss: 1.7904052926648049

Epoch: 5| Step: 1
Training loss: 1.6228911876678467
Validation loss: 1.8496473937906244

Epoch: 5| Step: 2
Training loss: 1.7453744411468506
Validation loss: 1.7899394073793966

Epoch: 5| Step: 3
Training loss: 1.0458914041519165
Validation loss: 1.810946895230201

Epoch: 5| Step: 4
Training loss: 1.3129240274429321
Validation loss: 1.796527567730155

Epoch: 5| Step: 5
Training loss: 1.3317731618881226
Validation loss: 1.839774481711849

Epoch: 5| Step: 6
Training loss: 1.2023985385894775
Validation loss: 1.8233412863105856

Epoch: 5| Step: 7
Training loss: 1.471620798110962
Validation loss: 1.8380777259026804

Epoch: 5| Step: 8
Training loss: 1.9781911373138428
Validation loss: 1.7967492893177976

Epoch: 5| Step: 9
Training loss: 1.0586011409759521
Validation loss: 1.8307388636373705

Epoch: 5| Step: 10
Training loss: 1.4206212759017944
Validation loss: 1.8221402309274162

Epoch: 338| Step: 0
Training loss: 1.1456495523452759
Validation loss: 1.7616374646463702

Epoch: 5| Step: 1
Training loss: 1.297922968864441
Validation loss: 1.775543930710003

Epoch: 5| Step: 2
Training loss: 1.3245065212249756
Validation loss: 1.8299194920447566

Epoch: 5| Step: 3
Training loss: 1.1932666301727295
Validation loss: 1.7853595774660829

Epoch: 5| Step: 4
Training loss: 1.7429462671279907
Validation loss: 1.7993096305478005

Epoch: 5| Step: 5
Training loss: 1.5770083665847778
Validation loss: 1.8127176876991027

Epoch: 5| Step: 6
Training loss: 1.5543360710144043
Validation loss: 1.7624213695526123

Epoch: 5| Step: 7
Training loss: 1.8364521265029907
Validation loss: 1.8370616974369172

Epoch: 5| Step: 8
Training loss: 1.3274908065795898
Validation loss: 1.8083014488220215

Epoch: 5| Step: 9
Training loss: 1.4902222156524658
Validation loss: 1.8231294462757726

Epoch: 5| Step: 10
Training loss: 1.547804832458496
Validation loss: 1.839491355803705

Epoch: 339| Step: 0
Training loss: 1.978645920753479
Validation loss: 1.798579687713295

Epoch: 5| Step: 1
Training loss: 1.3563987016677856
Validation loss: 1.7874267972925657

Epoch: 5| Step: 2
Training loss: 1.5452852249145508
Validation loss: 1.8451181150251819

Epoch: 5| Step: 3
Training loss: 0.9817983508110046
Validation loss: 1.8231235883569206

Epoch: 5| Step: 4
Training loss: 1.2312901020050049
Validation loss: 1.7981742851195797

Epoch: 5| Step: 5
Training loss: 2.191641092300415
Validation loss: 1.7937363296426752

Epoch: 5| Step: 6
Training loss: 1.1914100646972656
Validation loss: 1.8146520712042367

Epoch: 5| Step: 7
Training loss: 1.7342517375946045
Validation loss: 1.8035041465554187

Epoch: 5| Step: 8
Training loss: 1.7207673788070679
Validation loss: 1.765159664615508

Epoch: 5| Step: 9
Training loss: 0.9247010946273804
Validation loss: 1.7982438841173727

Epoch: 5| Step: 10
Training loss: 1.0626081228256226
Validation loss: 1.8212760750965407

Epoch: 340| Step: 0
Training loss: 1.958629846572876
Validation loss: 1.7845606521893573

Epoch: 5| Step: 1
Training loss: 1.5552911758422852
Validation loss: 1.8268677778141473

Epoch: 5| Step: 2
Training loss: 1.9279708862304688
Validation loss: 1.8251773606064499

Epoch: 5| Step: 3
Training loss: 0.7969692945480347
Validation loss: 1.7963779908354565

Epoch: 5| Step: 4
Training loss: 1.4499647617340088
Validation loss: 1.7834009175659509

Epoch: 5| Step: 5
Training loss: 1.3220243453979492
Validation loss: 1.7934891716126473

Epoch: 5| Step: 6
Training loss: 1.114020824432373
Validation loss: 1.8087543428585093

Epoch: 5| Step: 7
Training loss: 1.5951985120773315
Validation loss: 1.7984813054402669

Epoch: 5| Step: 8
Training loss: 1.2855207920074463
Validation loss: 1.7958806599340131

Epoch: 5| Step: 9
Training loss: 1.452739953994751
Validation loss: 1.7788244767855572

Epoch: 5| Step: 10
Training loss: 1.0685036182403564
Validation loss: 1.8304825444375314

Epoch: 341| Step: 0
Training loss: 1.7678178548812866
Validation loss: 1.8343658319083593

Epoch: 5| Step: 1
Training loss: 1.6748558282852173
Validation loss: 1.8151838394903368

Epoch: 5| Step: 2
Training loss: 1.3740408420562744
Validation loss: 1.8067111033265308

Epoch: 5| Step: 3
Training loss: 1.2468159198760986
Validation loss: 1.8209704122235697

Epoch: 5| Step: 4
Training loss: 1.2964845895767212
Validation loss: 1.810979905948844

Epoch: 5| Step: 5
Training loss: 1.2742036581039429
Validation loss: 1.8532817684194094

Epoch: 5| Step: 6
Training loss: 1.7300498485565186
Validation loss: 1.8006923147427139

Epoch: 5| Step: 7
Training loss: 1.6853224039077759
Validation loss: 1.767352049068738

Epoch: 5| Step: 8
Training loss: 1.1537789106369019
Validation loss: 1.78899081548055

Epoch: 5| Step: 9
Training loss: 1.333606481552124
Validation loss: 1.8402643460099415

Epoch: 5| Step: 10
Training loss: 1.5436419248580933
Validation loss: 1.7885690504504788

Epoch: 342| Step: 0
Training loss: 1.7453587055206299
Validation loss: 1.828221264705863

Epoch: 5| Step: 1
Training loss: 1.2715933322906494
Validation loss: 1.8419986065997873

Epoch: 5| Step: 2
Training loss: 1.3062539100646973
Validation loss: 1.75166791741566

Epoch: 5| Step: 3
Training loss: 1.1889442205429077
Validation loss: 1.834057725885863

Epoch: 5| Step: 4
Training loss: 1.5822389125823975
Validation loss: 1.829788977100003

Epoch: 5| Step: 5
Training loss: 1.1415951251983643
Validation loss: 1.7859095142733665

Epoch: 5| Step: 6
Training loss: 2.1525564193725586
Validation loss: 1.8160459802996727

Epoch: 5| Step: 7
Training loss: 1.2785775661468506
Validation loss: 1.8052974875255297

Epoch: 5| Step: 8
Training loss: 1.3513015508651733
Validation loss: 1.7953241435430383

Epoch: 5| Step: 9
Training loss: 1.54830002784729
Validation loss: 1.811514856994793

Epoch: 5| Step: 10
Training loss: 1.3477354049682617
Validation loss: 1.8191230784180343

Epoch: 343| Step: 0
Training loss: 1.6403621435165405
Validation loss: 1.7920563682433097

Epoch: 5| Step: 1
Training loss: 1.5572001934051514
Validation loss: 1.839290108731998

Epoch: 5| Step: 2
Training loss: 1.3789769411087036
Validation loss: 1.8325322853621615

Epoch: 5| Step: 3
Training loss: 1.1331285238265991
Validation loss: 1.8502692740450624

Epoch: 5| Step: 4
Training loss: 2.1829962730407715
Validation loss: 1.8175748368745208

Epoch: 5| Step: 5
Training loss: 1.2623192071914673
Validation loss: 1.7985378593526862

Epoch: 5| Step: 6
Training loss: 1.1888936758041382
Validation loss: 1.8430507272802374

Epoch: 5| Step: 7
Training loss: 1.2566219568252563
Validation loss: 1.8368724482033842

Epoch: 5| Step: 8
Training loss: 1.0677412748336792
Validation loss: 1.8554443979776034

Epoch: 5| Step: 9
Training loss: 1.929080605506897
Validation loss: 1.85087493670884

Epoch: 5| Step: 10
Training loss: 1.2090272903442383
Validation loss: 1.801085848962107

Epoch: 344| Step: 0
Training loss: 1.8581936359405518
Validation loss: 1.8161363435047928

Epoch: 5| Step: 1
Training loss: 1.2412251234054565
Validation loss: 1.7850470376271073

Epoch: 5| Step: 2
Training loss: 0.7038397789001465
Validation loss: 1.7491939375477452

Epoch: 5| Step: 3
Training loss: 1.8062999248504639
Validation loss: 1.809776900916971

Epoch: 5| Step: 4
Training loss: 1.4768588542938232
Validation loss: 1.8300862850681427

Epoch: 5| Step: 5
Training loss: 1.7667115926742554
Validation loss: 1.8360373217572448

Epoch: 5| Step: 6
Training loss: 1.1870766878128052
Validation loss: 1.8250015884317377

Epoch: 5| Step: 7
Training loss: 1.6090295314788818
Validation loss: 1.8416075347572245

Epoch: 5| Step: 8
Training loss: 1.2754065990447998
Validation loss: 1.797153628000649

Epoch: 5| Step: 9
Training loss: 1.3318531513214111
Validation loss: 1.8181300932361233

Epoch: 5| Step: 10
Training loss: 1.083478331565857
Validation loss: 1.7844625890895884

Epoch: 345| Step: 0
Training loss: 1.0192286968231201
Validation loss: 1.8214054825485393

Epoch: 5| Step: 1
Training loss: 1.0843197107315063
Validation loss: 1.8167853099043652

Epoch: 5| Step: 2
Training loss: 1.1081304550170898
Validation loss: 1.841868664628716

Epoch: 5| Step: 3
Training loss: 1.9112040996551514
Validation loss: 1.7544956309821016

Epoch: 5| Step: 4
Training loss: 1.5551501512527466
Validation loss: 1.8066867884769235

Epoch: 5| Step: 5
Training loss: 1.2324535846710205
Validation loss: 1.7616622024966824

Epoch: 5| Step: 6
Training loss: 1.476989984512329
Validation loss: 1.7764167221643592

Epoch: 5| Step: 7
Training loss: 1.374930739402771
Validation loss: 1.8184660301413587

Epoch: 5| Step: 8
Training loss: 1.4991388320922852
Validation loss: 1.8233605853972896

Epoch: 5| Step: 9
Training loss: 1.9365031719207764
Validation loss: 1.837531123110043

Epoch: 5| Step: 10
Training loss: 1.621036171913147
Validation loss: 1.7929554972597348

Epoch: 346| Step: 0
Training loss: 1.4414011240005493
Validation loss: 1.8032148358642415

Epoch: 5| Step: 1
Training loss: 1.182865023612976
Validation loss: 1.8123719243593113

Epoch: 5| Step: 2
Training loss: 1.348309874534607
Validation loss: 1.8801470700130667

Epoch: 5| Step: 3
Training loss: 1.4788017272949219
Validation loss: 1.8255967299143474

Epoch: 5| Step: 4
Training loss: 1.3187077045440674
Validation loss: 1.8094324399066228

Epoch: 5| Step: 5
Training loss: 1.6107518672943115
Validation loss: 1.7854047001049083

Epoch: 5| Step: 6
Training loss: 1.172867774963379
Validation loss: 1.8441045258634834

Epoch: 5| Step: 7
Training loss: 1.506150484085083
Validation loss: 1.8331069587379374

Epoch: 5| Step: 8
Training loss: 1.5970571041107178
Validation loss: 1.8229566286968928

Epoch: 5| Step: 9
Training loss: 1.4486448764801025
Validation loss: 1.7901594638824463

Epoch: 5| Step: 10
Training loss: 1.4008883237838745
Validation loss: 1.801411985710103

Epoch: 347| Step: 0
Training loss: 1.3687613010406494
Validation loss: 1.8110067100935086

Epoch: 5| Step: 1
Training loss: 1.5186073780059814
Validation loss: 1.8008790259720178

Epoch: 5| Step: 2
Training loss: 1.8749183416366577
Validation loss: 1.7736237254194034

Epoch: 5| Step: 3
Training loss: 1.2147576808929443
Validation loss: 1.8362148679712766

Epoch: 5| Step: 4
Training loss: 1.6935679912567139
Validation loss: 1.779048223649302

Epoch: 5| Step: 5
Training loss: 1.7840566635131836
Validation loss: 1.804599456889655

Epoch: 5| Step: 6
Training loss: 1.7139676809310913
Validation loss: 1.7870164609724475

Epoch: 5| Step: 7
Training loss: 1.1394238471984863
Validation loss: 1.8428221261629494

Epoch: 5| Step: 8
Training loss: 0.8336173295974731
Validation loss: 1.780811422614641

Epoch: 5| Step: 9
Training loss: 1.536007046699524
Validation loss: 1.8198529892070319

Epoch: 5| Step: 10
Training loss: 1.0597258806228638
Validation loss: 1.8420509407597203

Epoch: 348| Step: 0
Training loss: 1.6909414529800415
Validation loss: 1.8126100147924116

Epoch: 5| Step: 1
Training loss: 1.446767807006836
Validation loss: 1.758859226780553

Epoch: 5| Step: 2
Training loss: 1.5597693920135498
Validation loss: 1.8098753780447028

Epoch: 5| Step: 3
Training loss: 1.3964635133743286
Validation loss: 1.757356212985131

Epoch: 5| Step: 4
Training loss: 1.2649996280670166
Validation loss: 1.812094307714893

Epoch: 5| Step: 5
Training loss: 1.1677236557006836
Validation loss: 1.8105257403466009

Epoch: 5| Step: 6
Training loss: 1.2759467363357544
Validation loss: 1.8241384990753666

Epoch: 5| Step: 7
Training loss: 1.2641578912734985
Validation loss: 1.8621550913779967

Epoch: 5| Step: 8
Training loss: 1.7767797708511353
Validation loss: 1.8523192905610608

Epoch: 5| Step: 9
Training loss: 1.4267218112945557
Validation loss: 1.8492700797255321

Epoch: 5| Step: 10
Training loss: 1.0087426900863647
Validation loss: 1.8413334687550862

Epoch: 349| Step: 0
Training loss: 1.8661006689071655
Validation loss: 1.7858247551866757

Epoch: 5| Step: 1
Training loss: 1.3685907125473022
Validation loss: 1.7599806349764588

Epoch: 5| Step: 2
Training loss: 1.3278475999832153
Validation loss: 1.813947957049134

Epoch: 5| Step: 3
Training loss: 1.9541631937026978
Validation loss: 1.7650694539470058

Epoch: 5| Step: 4
Training loss: 1.4009506702423096
Validation loss: 1.8156266891828148

Epoch: 5| Step: 5
Training loss: 1.1281381845474243
Validation loss: 1.7741837552798692

Epoch: 5| Step: 6
Training loss: 1.457856297492981
Validation loss: 1.8277359918881488

Epoch: 5| Step: 7
Training loss: 0.9265438914299011
Validation loss: 1.8226708801843787

Epoch: 5| Step: 8
Training loss: 1.016160249710083
Validation loss: 1.8303969957495247

Epoch: 5| Step: 9
Training loss: 1.3721764087677002
Validation loss: 1.8137859247064079

Epoch: 5| Step: 10
Training loss: 1.3698670864105225
Validation loss: 1.865280742286354

Epoch: 350| Step: 0
Training loss: 1.7027599811553955
Validation loss: 1.8398362513511413

Epoch: 5| Step: 1
Training loss: 1.529503345489502
Validation loss: 1.8063969817212833

Epoch: 5| Step: 2
Training loss: 1.304000735282898
Validation loss: 1.8259084750247259

Epoch: 5| Step: 3
Training loss: 0.9772943258285522
Validation loss: 1.8054837270449566

Epoch: 5| Step: 4
Training loss: 0.8898757100105286
Validation loss: 1.8217192785714262

Epoch: 5| Step: 5
Training loss: 1.4066271781921387
Validation loss: 1.8048469046110749

Epoch: 5| Step: 6
Training loss: 1.111834168434143
Validation loss: 1.8322172946827386

Epoch: 5| Step: 7
Training loss: 1.6293437480926514
Validation loss: 1.8316154556889688

Epoch: 5| Step: 8
Training loss: 1.4753086566925049
Validation loss: 1.7969000236962431

Epoch: 5| Step: 9
Training loss: 2.1634018421173096
Validation loss: 1.7940476273977628

Epoch: 5| Step: 10
Training loss: 1.744593620300293
Validation loss: 1.798129125307965

Epoch: 351| Step: 0
Training loss: 1.2804181575775146
Validation loss: 1.7908498010327738

Epoch: 5| Step: 1
Training loss: 1.3032578229904175
Validation loss: 1.796382652815952

Epoch: 5| Step: 2
Training loss: 1.2945994138717651
Validation loss: 1.8137007092916837

Epoch: 5| Step: 3
Training loss: 1.2419159412384033
Validation loss: 1.7786647042920511

Epoch: 5| Step: 4
Training loss: 1.8636367321014404
Validation loss: 1.8264869720705095

Epoch: 5| Step: 5
Training loss: 1.4710910320281982
Validation loss: 1.818960911484175

Epoch: 5| Step: 6
Training loss: 1.3046491146087646
Validation loss: 1.8019488537183372

Epoch: 5| Step: 7
Training loss: 1.021988034248352
Validation loss: 1.7960885224803802

Epoch: 5| Step: 8
Training loss: 1.8325607776641846
Validation loss: 1.8003423931778118

Epoch: 5| Step: 9
Training loss: 1.3794467449188232
Validation loss: 1.8240658493452175

Epoch: 5| Step: 10
Training loss: 1.1461305618286133
Validation loss: 1.8253547735111688

Epoch: 352| Step: 0
Training loss: 1.582096815109253
Validation loss: 1.8382974875870572

Epoch: 5| Step: 1
Training loss: 0.9223273992538452
Validation loss: 1.7876941978290517

Epoch: 5| Step: 2
Training loss: 1.1665279865264893
Validation loss: 1.800137089144799

Epoch: 5| Step: 3
Training loss: 1.2152382135391235
Validation loss: 1.842926756028206

Epoch: 5| Step: 4
Training loss: 1.4488343000411987
Validation loss: 1.7943800585244292

Epoch: 5| Step: 5
Training loss: 1.1740516424179077
Validation loss: 1.7969661835701234

Epoch: 5| Step: 6
Training loss: 1.6011215448379517
Validation loss: 1.7967754025613107

Epoch: 5| Step: 7
Training loss: 1.9503028392791748
Validation loss: 1.7879079964853102

Epoch: 5| Step: 8
Training loss: 1.0665802955627441
Validation loss: 1.8106297780108709

Epoch: 5| Step: 9
Training loss: 1.7150815725326538
Validation loss: 1.809517780939738

Epoch: 5| Step: 10
Training loss: 1.5744619369506836
Validation loss: 1.8163622502357728

Epoch: 353| Step: 0
Training loss: 1.7121398448944092
Validation loss: 1.8331173773734801

Epoch: 5| Step: 1
Training loss: 1.58529794216156
Validation loss: 1.785849445609636

Epoch: 5| Step: 2
Training loss: 1.3301684856414795
Validation loss: 1.8254985527325702

Epoch: 5| Step: 3
Training loss: 1.4408748149871826
Validation loss: 1.7587909134485389

Epoch: 5| Step: 4
Training loss: 1.360818862915039
Validation loss: 1.810275852039296

Epoch: 5| Step: 5
Training loss: 0.914497971534729
Validation loss: 1.848317958975351

Epoch: 5| Step: 6
Training loss: 1.1485302448272705
Validation loss: 1.881335284120293

Epoch: 5| Step: 7
Training loss: 1.273339033126831
Validation loss: 1.8059018478598645

Epoch: 5| Step: 8
Training loss: 1.1639833450317383
Validation loss: 1.8334036424595823

Epoch: 5| Step: 9
Training loss: 1.9903342723846436
Validation loss: 1.8196134310896679

Epoch: 5| Step: 10
Training loss: 1.292510986328125
Validation loss: 1.8654273171578684

Epoch: 354| Step: 0
Training loss: 1.3475309610366821
Validation loss: 1.845890724530784

Epoch: 5| Step: 1
Training loss: 1.0802273750305176
Validation loss: 1.7699729088814027

Epoch: 5| Step: 2
Training loss: 1.0033496618270874
Validation loss: 1.798393996812964

Epoch: 5| Step: 3
Training loss: 1.7713323831558228
Validation loss: 1.8237221087178876

Epoch: 5| Step: 4
Training loss: 1.831364631652832
Validation loss: 1.8297072200364963

Epoch: 5| Step: 5
Training loss: 1.493405818939209
Validation loss: 1.7865712360669208

Epoch: 5| Step: 6
Training loss: 1.589731216430664
Validation loss: 1.8282179217184744

Epoch: 5| Step: 7
Training loss: 1.0270369052886963
Validation loss: 1.8240337987099924

Epoch: 5| Step: 8
Training loss: 2.0348803997039795
Validation loss: 1.7819556754122499

Epoch: 5| Step: 9
Training loss: 1.0408096313476562
Validation loss: 1.8290036673186927

Epoch: 5| Step: 10
Training loss: 1.1562952995300293
Validation loss: 1.804254856160892

Epoch: 355| Step: 0
Training loss: 1.3740789890289307
Validation loss: 1.8018777293543662

Epoch: 5| Step: 1
Training loss: 0.9481622576713562
Validation loss: 1.8078949553992159

Epoch: 5| Step: 2
Training loss: 1.4039337635040283
Validation loss: 1.7725755258273053

Epoch: 5| Step: 3
Training loss: 1.3344959020614624
Validation loss: 1.7640715722114808

Epoch: 5| Step: 4
Training loss: 1.4654299020767212
Validation loss: 1.8234370267519386

Epoch: 5| Step: 5
Training loss: 1.5229156017303467
Validation loss: 1.7719483901095647

Epoch: 5| Step: 6
Training loss: 1.1125247478485107
Validation loss: 1.8053193143619004

Epoch: 5| Step: 7
Training loss: 1.5204918384552002
Validation loss: 1.836710742724839

Epoch: 5| Step: 8
Training loss: 1.3704231977462769
Validation loss: 1.766408271687005

Epoch: 5| Step: 9
Training loss: 1.7498050928115845
Validation loss: 1.8274432125911917

Epoch: 5| Step: 10
Training loss: 1.4362882375717163
Validation loss: 1.8792430380339264

Epoch: 356| Step: 0
Training loss: 1.8514200448989868
Validation loss: 1.8868283815281366

Epoch: 5| Step: 1
Training loss: 1.499836802482605
Validation loss: 1.7969811949678647

Epoch: 5| Step: 2
Training loss: 1.2220789194107056
Validation loss: 1.8348669775070683

Epoch: 5| Step: 3
Training loss: 1.4034063816070557
Validation loss: 1.840945101553394

Epoch: 5| Step: 4
Training loss: 0.9464620351791382
Validation loss: 1.7708053793958438

Epoch: 5| Step: 5
Training loss: 1.1527035236358643
Validation loss: 1.768657845835532

Epoch: 5| Step: 6
Training loss: 1.3200489282608032
Validation loss: 1.8283055828463646

Epoch: 5| Step: 7
Training loss: 1.718865156173706
Validation loss: 1.7896603768871677

Epoch: 5| Step: 8
Training loss: 0.8365095257759094
Validation loss: 1.7737553504205519

Epoch: 5| Step: 9
Training loss: 1.8475652933120728
Validation loss: 1.8143597533625941

Epoch: 5| Step: 10
Training loss: 1.6528120040893555
Validation loss: 1.819446402211343

Epoch: 357| Step: 0
Training loss: 1.5790300369262695
Validation loss: 1.7884684108918714

Epoch: 5| Step: 1
Training loss: 1.638559103012085
Validation loss: 1.7963782279722151

Epoch: 5| Step: 2
Training loss: 0.9190536737442017
Validation loss: 1.8305179149873796

Epoch: 5| Step: 3
Training loss: 1.81658935546875
Validation loss: 1.8325814559895506

Epoch: 5| Step: 4
Training loss: 1.5628652572631836
Validation loss: 1.7806235795379968

Epoch: 5| Step: 5
Training loss: 1.318744421005249
Validation loss: 1.7760765347429501

Epoch: 5| Step: 6
Training loss: 1.4286177158355713
Validation loss: 1.7942640473765712

Epoch: 5| Step: 7
Training loss: 1.3952159881591797
Validation loss: 1.8180606672840733

Epoch: 5| Step: 8
Training loss: 1.326345682144165
Validation loss: 1.8288765979069534

Epoch: 5| Step: 9
Training loss: 0.9293811917304993
Validation loss: 1.8613373515426472

Epoch: 5| Step: 10
Training loss: 1.161522626876831
Validation loss: 1.8396935873134161

Epoch: 358| Step: 0
Training loss: 1.3495545387268066
Validation loss: 1.773902831539031

Epoch: 5| Step: 1
Training loss: 1.4761879444122314
Validation loss: 1.818683801158782

Epoch: 5| Step: 2
Training loss: 1.6877775192260742
Validation loss: 1.8377583795978176

Epoch: 5| Step: 3
Training loss: 1.0537588596343994
Validation loss: 1.7846369538255917

Epoch: 5| Step: 4
Training loss: 2.1453187465667725
Validation loss: 1.7812599187256188

Epoch: 5| Step: 5
Training loss: 0.6027067303657532
Validation loss: 1.774182923378483

Epoch: 5| Step: 6
Training loss: 1.4477869272232056
Validation loss: 1.7849438113550986

Epoch: 5| Step: 7
Training loss: 1.1960811614990234
Validation loss: 1.8641506523214362

Epoch: 5| Step: 8
Training loss: 1.387250542640686
Validation loss: 1.8585490372873121

Epoch: 5| Step: 9
Training loss: 1.5557610988616943
Validation loss: 1.8449130250561623

Epoch: 5| Step: 10
Training loss: 1.1340749263763428
Validation loss: 1.8755935750981814

Epoch: 359| Step: 0
Training loss: 1.2148902416229248
Validation loss: 1.8583111378454393

Epoch: 5| Step: 1
Training loss: 1.226908802986145
Validation loss: 1.8161292793930217

Epoch: 5| Step: 2
Training loss: 1.1908037662506104
Validation loss: 1.8129955081529514

Epoch: 5| Step: 3
Training loss: 1.6021747589111328
Validation loss: 1.7758984219643377

Epoch: 5| Step: 4
Training loss: 1.624353051185608
Validation loss: 1.8292406118044289

Epoch: 5| Step: 5
Training loss: 1.8157047033309937
Validation loss: 1.8232350541699318

Epoch: 5| Step: 6
Training loss: 1.2181856632232666
Validation loss: 1.7818585647049772

Epoch: 5| Step: 7
Training loss: 1.1522563695907593
Validation loss: 1.7673512722856255

Epoch: 5| Step: 8
Training loss: 1.6474195718765259
Validation loss: 1.8510691055687525

Epoch: 5| Step: 9
Training loss: 1.3960673809051514
Validation loss: 1.8357049290851881

Epoch: 5| Step: 10
Training loss: 1.5542173385620117
Validation loss: 1.8149731877029582

Epoch: 360| Step: 0
Training loss: 1.6396293640136719
Validation loss: 1.7597376044078539

Epoch: 5| Step: 1
Training loss: 1.3913483619689941
Validation loss: 1.8068607699486516

Epoch: 5| Step: 2
Training loss: 0.9151220321655273
Validation loss: 1.819383071314904

Epoch: 5| Step: 3
Training loss: 1.4279447793960571
Validation loss: 1.7506727275028025

Epoch: 5| Step: 4
Training loss: 1.2968946695327759
Validation loss: 1.8007496018563547

Epoch: 5| Step: 5
Training loss: 1.4336559772491455
Validation loss: 1.8538622215229978

Epoch: 5| Step: 6
Training loss: 1.571246862411499
Validation loss: 1.761892694298939

Epoch: 5| Step: 7
Training loss: 1.553968071937561
Validation loss: 1.8459813825545772

Epoch: 5| Step: 8
Training loss: 1.6461706161499023
Validation loss: 1.8242700612673195

Epoch: 5| Step: 9
Training loss: 0.8560221791267395
Validation loss: 1.8261685115034862

Epoch: 5| Step: 10
Training loss: 1.4121768474578857
Validation loss: 1.8208135122893958

Epoch: 361| Step: 0
Training loss: 1.1234633922576904
Validation loss: 1.8445188588993524

Epoch: 5| Step: 1
Training loss: 1.392221212387085
Validation loss: 1.8515005457785823

Epoch: 5| Step: 2
Training loss: 1.4653929471969604
Validation loss: 1.7400591757989698

Epoch: 5| Step: 3
Training loss: 1.0216906070709229
Validation loss: 1.7964555294282976

Epoch: 5| Step: 4
Training loss: 1.042003870010376
Validation loss: 1.802724749811234

Epoch: 5| Step: 5
Training loss: 1.348850131034851
Validation loss: 1.8134036897331156

Epoch: 5| Step: 6
Training loss: 2.184776782989502
Validation loss: 1.799432933971446

Epoch: 5| Step: 7
Training loss: 1.8506866693496704
Validation loss: 1.8423414589256368

Epoch: 5| Step: 8
Training loss: 1.4155499935150146
Validation loss: 1.8179918873694636

Epoch: 5| Step: 9
Training loss: 1.1980223655700684
Validation loss: 1.8145667711893718

Epoch: 5| Step: 10
Training loss: 1.10469388961792
Validation loss: 1.8177877164656115

Epoch: 362| Step: 0
Training loss: 1.2403085231781006
Validation loss: 1.7858389872376637

Epoch: 5| Step: 1
Training loss: 1.1885929107666016
Validation loss: 1.7890586327481013

Epoch: 5| Step: 2
Training loss: 1.952527642250061
Validation loss: 1.8110323593180666

Epoch: 5| Step: 3
Training loss: 1.3924105167388916
Validation loss: 1.8071673416322278

Epoch: 5| Step: 4
Training loss: 0.8078948259353638
Validation loss: 1.7625227666670276

Epoch: 5| Step: 5
Training loss: 1.8520469665527344
Validation loss: 1.782073317035552

Epoch: 5| Step: 6
Training loss: 1.5528838634490967
Validation loss: 1.819327929968475

Epoch: 5| Step: 7
Training loss: 0.7344730496406555
Validation loss: 1.7740838450770224

Epoch: 5| Step: 8
Training loss: 1.4132544994354248
Validation loss: 1.8245486213314919

Epoch: 5| Step: 9
Training loss: 1.1541359424591064
Validation loss: 1.8040835780482138

Epoch: 5| Step: 10
Training loss: 1.6724337339401245
Validation loss: 1.8435917990182036

Epoch: 363| Step: 0
Training loss: 1.2875932455062866
Validation loss: 1.872229019800822

Epoch: 5| Step: 1
Training loss: 1.5707852840423584
Validation loss: 1.808285690123035

Epoch: 5| Step: 2
Training loss: 1.243829369544983
Validation loss: 1.8627240606533584

Epoch: 5| Step: 3
Training loss: 1.5174682140350342
Validation loss: 1.7619097309727823

Epoch: 5| Step: 4
Training loss: 0.8615592122077942
Validation loss: 1.7716657615477038

Epoch: 5| Step: 5
Training loss: 1.6565347909927368
Validation loss: 1.8119477033615112

Epoch: 5| Step: 6
Training loss: 1.490131139755249
Validation loss: 1.8313785676033265

Epoch: 5| Step: 7
Training loss: 1.6606452465057373
Validation loss: 1.7802940260979436

Epoch: 5| Step: 8
Training loss: 1.0953998565673828
Validation loss: 1.8415388702064432

Epoch: 5| Step: 9
Training loss: 1.1790841817855835
Validation loss: 1.8005523681640625

Epoch: 5| Step: 10
Training loss: 1.6516683101654053
Validation loss: 1.7678761354056738

Epoch: 364| Step: 0
Training loss: 1.0926358699798584
Validation loss: 1.836947832056271

Epoch: 5| Step: 1
Training loss: 1.8907626867294312
Validation loss: 1.7748012299178748

Epoch: 5| Step: 2
Training loss: 1.3792365789413452
Validation loss: 1.808596275186026

Epoch: 5| Step: 3
Training loss: 1.2241883277893066
Validation loss: 1.8401034608963998

Epoch: 5| Step: 4
Training loss: 1.6998335123062134
Validation loss: 1.8216256967154882

Epoch: 5| Step: 5
Training loss: 1.434915542602539
Validation loss: 1.822326237155545

Epoch: 5| Step: 6
Training loss: 1.3565140962600708
Validation loss: 1.7973018653931156

Epoch: 5| Step: 7
Training loss: 1.4056164026260376
Validation loss: 1.8030557529900664

Epoch: 5| Step: 8
Training loss: 1.252960443496704
Validation loss: 1.8247046727006153

Epoch: 5| Step: 9
Training loss: 1.2571369409561157
Validation loss: 1.812243821800396

Epoch: 5| Step: 10
Training loss: 1.0336202383041382
Validation loss: 1.813707979776526

Epoch: 365| Step: 0
Training loss: 1.13778555393219
Validation loss: 1.8505131083150064

Epoch: 5| Step: 1
Training loss: 1.6948721408843994
Validation loss: 1.8104075936860935

Epoch: 5| Step: 2
Training loss: 1.3190370798110962
Validation loss: 1.7788148003239785

Epoch: 5| Step: 3
Training loss: 1.3027255535125732
Validation loss: 1.7792133938881658

Epoch: 5| Step: 4
Training loss: 1.5478687286376953
Validation loss: 1.7567178831305554

Epoch: 5| Step: 5
Training loss: 1.287013292312622
Validation loss: 1.792412378454721

Epoch: 5| Step: 6
Training loss: 1.005003571510315
Validation loss: 1.8638443536655878

Epoch: 5| Step: 7
Training loss: 1.5693998336791992
Validation loss: 1.78688169294788

Epoch: 5| Step: 8
Training loss: 1.3964234590530396
Validation loss: 1.7843614970484087

Epoch: 5| Step: 9
Training loss: 1.1710388660430908
Validation loss: 1.817547744320285

Epoch: 5| Step: 10
Training loss: 1.8620901107788086
Validation loss: 1.841507973209504

Epoch: 366| Step: 0
Training loss: 1.799088478088379
Validation loss: 1.7769860054856987

Epoch: 5| Step: 1
Training loss: 1.5490777492523193
Validation loss: 1.841234068716726

Epoch: 5| Step: 2
Training loss: 0.9253526926040649
Validation loss: 1.8526420900898595

Epoch: 5| Step: 3
Training loss: 0.9641316533088684
Validation loss: 1.7869020341545023

Epoch: 5| Step: 4
Training loss: 1.8530337810516357
Validation loss: 1.8276390080810876

Epoch: 5| Step: 5
Training loss: 1.4934860467910767
Validation loss: 1.8170297671389837

Epoch: 5| Step: 6
Training loss: 1.621199369430542
Validation loss: 1.8486099986619846

Epoch: 5| Step: 7
Training loss: 1.6651687622070312
Validation loss: 1.8355647735698248

Epoch: 5| Step: 8
Training loss: 0.7210379242897034
Validation loss: 1.817883651743653

Epoch: 5| Step: 9
Training loss: 1.1505438089370728
Validation loss: 1.8539470562370874

Epoch: 5| Step: 10
Training loss: 1.1208921670913696
Validation loss: 1.7674629547262704

Epoch: 367| Step: 0
Training loss: 1.4616509675979614
Validation loss: 1.8624442149234075

Epoch: 5| Step: 1
Training loss: 1.5439456701278687
Validation loss: 1.7870453942206599

Epoch: 5| Step: 2
Training loss: 0.9707671999931335
Validation loss: 1.8212200262213265

Epoch: 5| Step: 3
Training loss: 1.2008174657821655
Validation loss: 1.826684703109085

Epoch: 5| Step: 4
Training loss: 1.2061702013015747
Validation loss: 1.8523506015859625

Epoch: 5| Step: 5
Training loss: 1.1424895524978638
Validation loss: 1.830987572669983

Epoch: 5| Step: 6
Training loss: 1.5559625625610352
Validation loss: 1.8041871978390602

Epoch: 5| Step: 7
Training loss: 1.2568330764770508
Validation loss: 1.8418898774731545

Epoch: 5| Step: 8
Training loss: 1.9955848455429077
Validation loss: 1.8265990967391639

Epoch: 5| Step: 9
Training loss: 1.127668023109436
Validation loss: 1.7898507118225098

Epoch: 5| Step: 10
Training loss: 1.8894706964492798
Validation loss: 1.7720934575603855

Epoch: 368| Step: 0
Training loss: 1.2458274364471436
Validation loss: 1.7971851389895204

Epoch: 5| Step: 1
Training loss: 1.2605458498001099
Validation loss: 1.7484759515331638

Epoch: 5| Step: 2
Training loss: 1.5511846542358398
Validation loss: 1.831499235604399

Epoch: 5| Step: 3
Training loss: 1.4445979595184326
Validation loss: 1.8206895602646695

Epoch: 5| Step: 4
Training loss: 1.2820640802383423
Validation loss: 1.8481017440877936

Epoch: 5| Step: 5
Training loss: 1.5330673456192017
Validation loss: 1.8717930214379424

Epoch: 5| Step: 6
Training loss: 1.2648475170135498
Validation loss: 1.8294479770045127

Epoch: 5| Step: 7
Training loss: 1.663100004196167
Validation loss: 1.896971833321356

Epoch: 5| Step: 8
Training loss: 1.66144597530365
Validation loss: 1.8776125766897713

Epoch: 5| Step: 9
Training loss: 1.161926031112671
Validation loss: 1.8483286583295433

Epoch: 5| Step: 10
Training loss: 1.223789930343628
Validation loss: 1.8173090424588931

Epoch: 369| Step: 0
Training loss: 1.4855235815048218
Validation loss: 1.802368370435571

Epoch: 5| Step: 1
Training loss: 1.1399599313735962
Validation loss: 1.813864246491463

Epoch: 5| Step: 2
Training loss: 1.0513007640838623
Validation loss: 1.793944699789888

Epoch: 5| Step: 3
Training loss: 1.1765130758285522
Validation loss: 1.810195420377998

Epoch: 5| Step: 4
Training loss: 1.8091033697128296
Validation loss: 1.7412985717096636

Epoch: 5| Step: 5
Training loss: 1.4819358587265015
Validation loss: 1.837826495529503

Epoch: 5| Step: 6
Training loss: 2.1216084957122803
Validation loss: 1.853970346912261

Epoch: 5| Step: 7
Training loss: 1.1313480138778687
Validation loss: 1.8170503083095755

Epoch: 5| Step: 8
Training loss: 1.6318556070327759
Validation loss: 1.7998852037614392

Epoch: 5| Step: 9
Training loss: 1.2709767818450928
Validation loss: 1.8016358344785628

Epoch: 5| Step: 10
Training loss: 1.169245719909668
Validation loss: 1.8667576697564894

Epoch: 370| Step: 0
Training loss: 1.236851453781128
Validation loss: 1.8433047020307152

Epoch: 5| Step: 1
Training loss: 0.8301785588264465
Validation loss: 1.7935394804964784

Epoch: 5| Step: 2
Training loss: 1.0604150295257568
Validation loss: 1.7519765400117444

Epoch: 5| Step: 3
Training loss: 0.7914476990699768
Validation loss: 1.79563231109291

Epoch: 5| Step: 4
Training loss: 1.9807544946670532
Validation loss: 1.8267781913921397

Epoch: 5| Step: 5
Training loss: 1.771660566329956
Validation loss: 1.8283314063984861

Epoch: 5| Step: 6
Training loss: 1.5247987508773804
Validation loss: 1.8231162742901874

Epoch: 5| Step: 7
Training loss: 1.2004314661026
Validation loss: 1.7631310878261444

Epoch: 5| Step: 8
Training loss: 1.7331746816635132
Validation loss: 1.780227000995349

Epoch: 5| Step: 9
Training loss: 0.9664467573165894
Validation loss: 1.7667829567386257

Epoch: 5| Step: 10
Training loss: 1.485467791557312
Validation loss: 1.8227273212966097

Epoch: 371| Step: 0
Training loss: 1.4016515016555786
Validation loss: 1.8204170683378815

Epoch: 5| Step: 1
Training loss: 1.4321614503860474
Validation loss: 1.83781438104568

Epoch: 5| Step: 2
Training loss: 1.5651651620864868
Validation loss: 1.837281306584676

Epoch: 5| Step: 3
Training loss: 1.6398522853851318
Validation loss: 1.7529084541464364

Epoch: 5| Step: 4
Training loss: 1.3260242938995361
Validation loss: 1.801857066410844

Epoch: 5| Step: 5
Training loss: 0.8833438158035278
Validation loss: 1.8138445295313352

Epoch: 5| Step: 6
Training loss: 1.7462158203125
Validation loss: 1.860835535551912

Epoch: 5| Step: 7
Training loss: 1.366931676864624
Validation loss: 1.8310737558590469

Epoch: 5| Step: 8
Training loss: 0.9173094034194946
Validation loss: 1.7983290738956903

Epoch: 5| Step: 9
Training loss: 1.251590609550476
Validation loss: 1.809275088771697

Epoch: 5| Step: 10
Training loss: 1.3629193305969238
Validation loss: 1.7999821080956409

Epoch: 372| Step: 0
Training loss: 1.623366355895996
Validation loss: 1.7943377430720995

Epoch: 5| Step: 1
Training loss: 2.188483238220215
Validation loss: 1.8457978553669427

Epoch: 5| Step: 2
Training loss: 1.7799949645996094
Validation loss: 1.8146066742558633

Epoch: 5| Step: 3
Training loss: 1.0792171955108643
Validation loss: 1.797577073497157

Epoch: 5| Step: 4
Training loss: 0.9461892247200012
Validation loss: 1.851970721316594

Epoch: 5| Step: 5
Training loss: 1.2893322706222534
Validation loss: 1.794952202868718

Epoch: 5| Step: 6
Training loss: 1.4223244190216064
Validation loss: 1.781856789383837

Epoch: 5| Step: 7
Training loss: 0.8884432911872864
Validation loss: 1.7732942745249758

Epoch: 5| Step: 8
Training loss: 1.180098533630371
Validation loss: 1.8356902176334011

Epoch: 5| Step: 9
Training loss: 1.1165608167648315
Validation loss: 1.841593312960799

Epoch: 5| Step: 10
Training loss: 1.2665903568267822
Validation loss: 1.8237573382675007

Epoch: 373| Step: 0
Training loss: 1.2633635997772217
Validation loss: 1.84377509163272

Epoch: 5| Step: 1
Training loss: 1.4573694467544556
Validation loss: 1.7745343075003674

Epoch: 5| Step: 2
Training loss: 1.7078535556793213
Validation loss: 1.805365849566716

Epoch: 5| Step: 3
Training loss: 1.3302195072174072
Validation loss: 1.822922815558731

Epoch: 5| Step: 4
Training loss: 1.2002367973327637
Validation loss: 1.8201514623498405

Epoch: 5| Step: 5
Training loss: 1.4569391012191772
Validation loss: 1.8062890806505758

Epoch: 5| Step: 6
Training loss: 1.5521209239959717
Validation loss: 1.8002958887366838

Epoch: 5| Step: 7
Training loss: 1.0744125843048096
Validation loss: 1.805515544388884

Epoch: 5| Step: 8
Training loss: 0.970933735370636
Validation loss: 1.7796110504417009

Epoch: 5| Step: 9
Training loss: 1.6045992374420166
Validation loss: 1.8600474531932543

Epoch: 5| Step: 10
Training loss: 1.1512929201126099
Validation loss: 1.7709630381676458

Epoch: 374| Step: 0
Training loss: 1.6112594604492188
Validation loss: 1.7813503460217548

Epoch: 5| Step: 1
Training loss: 1.2942733764648438
Validation loss: 1.8057867647499166

Epoch: 5| Step: 2
Training loss: 1.2081780433654785
Validation loss: 1.7730997070189445

Epoch: 5| Step: 3
Training loss: 1.183311939239502
Validation loss: 1.8147459440333868

Epoch: 5| Step: 4
Training loss: 1.0240048170089722
Validation loss: 1.7880033113623177

Epoch: 5| Step: 5
Training loss: 1.7484534978866577
Validation loss: 1.80039055244897

Epoch: 5| Step: 6
Training loss: 1.6190906763076782
Validation loss: 1.8653458292766283

Epoch: 5| Step: 7
Training loss: 0.8972846269607544
Validation loss: 1.7819979319008448

Epoch: 5| Step: 8
Training loss: 1.4320381879806519
Validation loss: 1.8146184593118646

Epoch: 5| Step: 9
Training loss: 1.2021703720092773
Validation loss: 1.763104777182302

Epoch: 5| Step: 10
Training loss: 1.657712459564209
Validation loss: 1.821784673198577

Epoch: 375| Step: 0
Training loss: 1.5378385782241821
Validation loss: 1.8161201092504686

Epoch: 5| Step: 1
Training loss: 1.301740288734436
Validation loss: 1.8237728918752363

Epoch: 5| Step: 2
Training loss: 1.0901262760162354
Validation loss: 1.8825605261710383

Epoch: 5| Step: 3
Training loss: 1.165901780128479
Validation loss: 1.7750768174407303

Epoch: 5| Step: 4
Training loss: 1.5293257236480713
Validation loss: 1.850168356331446

Epoch: 5| Step: 5
Training loss: 1.6906591653823853
Validation loss: 1.8635974289268575

Epoch: 5| Step: 6
Training loss: 0.6215220093727112
Validation loss: 1.852972033203289

Epoch: 5| Step: 7
Training loss: 1.2011444568634033
Validation loss: 1.8226071403872581

Epoch: 5| Step: 8
Training loss: 1.7734521627426147
Validation loss: 1.8929505578933223

Epoch: 5| Step: 9
Training loss: 1.7433990240097046
Validation loss: 1.7642414698036768

Epoch: 5| Step: 10
Training loss: 1.177215576171875
Validation loss: 1.8104764159007738

Epoch: 376| Step: 0
Training loss: 2.21077561378479
Validation loss: 1.7768517066073675

Epoch: 5| Step: 1
Training loss: 1.0979676246643066
Validation loss: 1.7390352064563381

Epoch: 5| Step: 2
Training loss: 1.0296729803085327
Validation loss: 1.8130309915029874

Epoch: 5| Step: 3
Training loss: 1.3301258087158203
Validation loss: 1.7644217309131418

Epoch: 5| Step: 4
Training loss: 1.9414926767349243
Validation loss: 1.7939622607282413

Epoch: 5| Step: 5
Training loss: 1.0693615674972534
Validation loss: 1.766020183922142

Epoch: 5| Step: 6
Training loss: 1.2556813955307007
Validation loss: 1.8231146399692824

Epoch: 5| Step: 7
Training loss: 1.606532335281372
Validation loss: 1.8129347511517104

Epoch: 5| Step: 8
Training loss: 0.837010383605957
Validation loss: 1.8068416938986829

Epoch: 5| Step: 9
Training loss: 1.248265027999878
Validation loss: 1.8172003915232997

Epoch: 5| Step: 10
Training loss: 1.2008063793182373
Validation loss: 1.856568851778584

Epoch: 377| Step: 0
Training loss: 1.2643612623214722
Validation loss: 1.825781040294196

Epoch: 5| Step: 1
Training loss: 1.3500663042068481
Validation loss: 1.8353737861879411

Epoch: 5| Step: 2
Training loss: 1.2829393148422241
Validation loss: 1.8634242421837264

Epoch: 5| Step: 3
Training loss: 0.834682285785675
Validation loss: 1.7975875639146375

Epoch: 5| Step: 4
Training loss: 1.8555011749267578
Validation loss: 1.8440155393333846

Epoch: 5| Step: 5
Training loss: 1.8329557180404663
Validation loss: 1.8613667052279237

Epoch: 5| Step: 6
Training loss: 1.2582809925079346
Validation loss: 1.8693945689867901

Epoch: 5| Step: 7
Training loss: 0.9468223452568054
Validation loss: 1.8274704141001548

Epoch: 5| Step: 8
Training loss: 1.11772620677948
Validation loss: 1.774744987487793

Epoch: 5| Step: 9
Training loss: 1.4137365818023682
Validation loss: 1.7806007451908563

Epoch: 5| Step: 10
Training loss: 1.2033239603042603
Validation loss: 1.780781252409822

Epoch: 378| Step: 0
Training loss: 1.2252395153045654
Validation loss: 1.833687945078778

Epoch: 5| Step: 1
Training loss: 1.1809628009796143
Validation loss: 1.8344908478439494

Epoch: 5| Step: 2
Training loss: 1.380306601524353
Validation loss: 1.7936800526034447

Epoch: 5| Step: 3
Training loss: 1.308393120765686
Validation loss: 1.8246594846889537

Epoch: 5| Step: 4
Training loss: 1.7638781070709229
Validation loss: 1.8158065093460904

Epoch: 5| Step: 5
Training loss: 0.8139852285385132
Validation loss: 1.8116592284171813

Epoch: 5| Step: 6
Training loss: 1.6550133228302002
Validation loss: 1.8706960344827304

Epoch: 5| Step: 7
Training loss: 1.348448395729065
Validation loss: 1.7830626016022058

Epoch: 5| Step: 8
Training loss: 0.9633978009223938
Validation loss: 1.7481000833613898

Epoch: 5| Step: 9
Training loss: 1.3193475008010864
Validation loss: 1.8035863753288024

Epoch: 5| Step: 10
Training loss: 1.849387288093567
Validation loss: 1.7783079736976213

Epoch: 379| Step: 0
Training loss: 1.4022669792175293
Validation loss: 1.806508961544242

Epoch: 5| Step: 1
Training loss: 1.5661102533340454
Validation loss: 1.8399696478279688

Epoch: 5| Step: 2
Training loss: 1.3046774864196777
Validation loss: 1.810002960184569

Epoch: 5| Step: 3
Training loss: 1.0564672946929932
Validation loss: 1.7973161256441506

Epoch: 5| Step: 4
Training loss: 1.0261008739471436
Validation loss: 1.8197444561989076

Epoch: 5| Step: 5
Training loss: 1.4919263124465942
Validation loss: 1.7945523902934084

Epoch: 5| Step: 6
Training loss: 1.6068851947784424
Validation loss: 1.7819191102058656

Epoch: 5| Step: 7
Training loss: 1.4911620616912842
Validation loss: 1.7970561776109921

Epoch: 5| Step: 8
Training loss: 0.9501597285270691
Validation loss: 1.8264385038806545

Epoch: 5| Step: 9
Training loss: 1.2728123664855957
Validation loss: 1.8098933542928388

Epoch: 5| Step: 10
Training loss: 1.046734094619751
Validation loss: 1.839229319685249

Epoch: 380| Step: 0
Training loss: 0.924429714679718
Validation loss: 1.8390477767554663

Epoch: 5| Step: 1
Training loss: 1.5372529029846191
Validation loss: 1.8436902748641146

Epoch: 5| Step: 2
Training loss: 1.5309253931045532
Validation loss: 1.7727950388385403

Epoch: 5| Step: 3
Training loss: 1.1224290132522583
Validation loss: 1.7629425397483252

Epoch: 5| Step: 4
Training loss: 1.7521898746490479
Validation loss: 1.7830670033731768

Epoch: 5| Step: 5
Training loss: 1.1755895614624023
Validation loss: 1.8231959727502638

Epoch: 5| Step: 6
Training loss: 1.0100845098495483
Validation loss: 1.8192214530001405

Epoch: 5| Step: 7
Training loss: 1.1756019592285156
Validation loss: 1.8474282731292069

Epoch: 5| Step: 8
Training loss: 1.2890002727508545
Validation loss: 1.8182743659583471

Epoch: 5| Step: 9
Training loss: 1.4811221361160278
Validation loss: 1.791520869860085

Epoch: 5| Step: 10
Training loss: 1.9825960397720337
Validation loss: 1.8107267797634166

Epoch: 381| Step: 0
Training loss: 1.4111425876617432
Validation loss: 1.823125591842077

Epoch: 5| Step: 1
Training loss: 2.213123321533203
Validation loss: 1.8202211600477978

Epoch: 5| Step: 2
Training loss: 1.4686248302459717
Validation loss: 1.7938615468240553

Epoch: 5| Step: 3
Training loss: 0.9376506805419922
Validation loss: 1.8300023271191506

Epoch: 5| Step: 4
Training loss: 1.0678999423980713
Validation loss: 1.809697966421804

Epoch: 5| Step: 5
Training loss: 0.8898183107376099
Validation loss: 1.8250382395200833

Epoch: 5| Step: 6
Training loss: 0.6510924100875854
Validation loss: 1.8387832359601093

Epoch: 5| Step: 7
Training loss: 1.308688759803772
Validation loss: 1.8230296822004421

Epoch: 5| Step: 8
Training loss: 1.66796875
Validation loss: 1.7949736656681183

Epoch: 5| Step: 9
Training loss: 1.2385308742523193
Validation loss: 1.84876799327071

Epoch: 5| Step: 10
Training loss: 1.806420922279358
Validation loss: 1.824393085254136

Epoch: 382| Step: 0
Training loss: 1.596673607826233
Validation loss: 1.793065640234178

Epoch: 5| Step: 1
Training loss: 1.7502174377441406
Validation loss: 1.852811832581797

Epoch: 5| Step: 2
Training loss: 1.3909738063812256
Validation loss: 1.8068532123360583

Epoch: 5| Step: 3
Training loss: 1.0927581787109375
Validation loss: 1.814097830044326

Epoch: 5| Step: 4
Training loss: 0.9208796620368958
Validation loss: 1.8057415536654893

Epoch: 5| Step: 5
Training loss: 0.9335481524467468
Validation loss: 1.7880104023923156

Epoch: 5| Step: 6
Training loss: 1.5484991073608398
Validation loss: 1.8057969334304973

Epoch: 5| Step: 7
Training loss: 1.0535707473754883
Validation loss: 1.8021343190182921

Epoch: 5| Step: 8
Training loss: 1.2736088037490845
Validation loss: 1.8079086939493816

Epoch: 5| Step: 9
Training loss: 1.0705063343048096
Validation loss: 1.8025732373678556

Epoch: 5| Step: 10
Training loss: 1.4996223449707031
Validation loss: 1.7644284130424581

Epoch: 383| Step: 0
Training loss: 0.9691509008407593
Validation loss: 1.8373220479616554

Epoch: 5| Step: 1
Training loss: 1.252541422843933
Validation loss: 1.8525554339090984

Epoch: 5| Step: 2
Training loss: 1.1201149225234985
Validation loss: 1.838990706269459

Epoch: 5| Step: 3
Training loss: 1.2916479110717773
Validation loss: 1.8177115955660421

Epoch: 5| Step: 4
Training loss: 1.4419819116592407
Validation loss: 1.8217369997373192

Epoch: 5| Step: 5
Training loss: 1.5943377017974854
Validation loss: 1.7959862120689885

Epoch: 5| Step: 6
Training loss: 1.182445764541626
Validation loss: 1.8463133586350309

Epoch: 5| Step: 7
Training loss: 1.0595027208328247
Validation loss: 1.8076848701764179

Epoch: 5| Step: 8
Training loss: 1.1942161321640015
Validation loss: 1.8263008947013526

Epoch: 5| Step: 9
Training loss: 2.0179436206817627
Validation loss: 1.77523636305204

Epoch: 5| Step: 10
Training loss: 1.2110419273376465
Validation loss: 1.81098477045695

Epoch: 384| Step: 0
Training loss: 1.3072090148925781
Validation loss: 1.8205324757483698

Epoch: 5| Step: 1
Training loss: 1.5777660608291626
Validation loss: 1.8297175963719685

Epoch: 5| Step: 2
Training loss: 1.260662317276001
Validation loss: 1.8075065907611643

Epoch: 5| Step: 3
Training loss: 1.0024032592773438
Validation loss: 1.7660698736867597

Epoch: 5| Step: 4
Training loss: 0.8458510637283325
Validation loss: 1.8323001041207263

Epoch: 5| Step: 5
Training loss: 0.70099937915802
Validation loss: 1.7922103866454093

Epoch: 5| Step: 6
Training loss: 1.8137935400009155
Validation loss: 1.7960665251619072

Epoch: 5| Step: 7
Training loss: 1.6990514993667603
Validation loss: 1.8266913378110496

Epoch: 5| Step: 8
Training loss: 1.6481530666351318
Validation loss: 1.773320399945782

Epoch: 5| Step: 9
Training loss: 1.386406421661377
Validation loss: 1.8270366114954795

Epoch: 5| Step: 10
Training loss: 1.3921815156936646
Validation loss: 1.7798980820563532

Epoch: 385| Step: 0
Training loss: 1.1237726211547852
Validation loss: 1.8772309595538723

Epoch: 5| Step: 1
Training loss: 1.0947496891021729
Validation loss: 1.834672054936809

Epoch: 5| Step: 2
Training loss: 1.1956253051757812
Validation loss: 1.805337077827864

Epoch: 5| Step: 3
Training loss: 1.7185252904891968
Validation loss: 1.797132940702541

Epoch: 5| Step: 4
Training loss: 0.8798421621322632
Validation loss: 1.8109314441680908

Epoch: 5| Step: 5
Training loss: 1.122633934020996
Validation loss: 1.8247627442882908

Epoch: 5| Step: 6
Training loss: 1.5026304721832275
Validation loss: 1.7846149475343767

Epoch: 5| Step: 7
Training loss: 1.327742576599121
Validation loss: 1.7445825684455134

Epoch: 5| Step: 8
Training loss: 1.595842719078064
Validation loss: 1.8102264763206564

Epoch: 5| Step: 9
Training loss: 1.0441670417785645
Validation loss: 1.8130951825008597

Epoch: 5| Step: 10
Training loss: 1.98309326171875
Validation loss: 1.834688300727516

Epoch: 386| Step: 0
Training loss: 1.027752161026001
Validation loss: 1.8037337974835468

Epoch: 5| Step: 1
Training loss: 1.4097744226455688
Validation loss: 1.878157554134246

Epoch: 5| Step: 2
Training loss: 1.4465070962905884
Validation loss: 1.7985530617416545

Epoch: 5| Step: 3
Training loss: 1.1093618869781494
Validation loss: 1.826984864409252

Epoch: 5| Step: 4
Training loss: 1.4818509817123413
Validation loss: 1.8698999087015789

Epoch: 5| Step: 5
Training loss: 1.1422077417373657
Validation loss: 1.8190601128403858

Epoch: 5| Step: 6
Training loss: 1.3816413879394531
Validation loss: 1.8029568836253176

Epoch: 5| Step: 7
Training loss: 1.3711249828338623
Validation loss: 1.8108529429281912

Epoch: 5| Step: 8
Training loss: 1.484880805015564
Validation loss: 1.773588708651963

Epoch: 5| Step: 9
Training loss: 1.1546558141708374
Validation loss: 1.7904486451097714

Epoch: 5| Step: 10
Training loss: 0.9994444847106934
Validation loss: 1.7703522469407769

Epoch: 387| Step: 0
Training loss: 1.4768297672271729
Validation loss: 1.8169060509691957

Epoch: 5| Step: 1
Training loss: 1.3908454179763794
Validation loss: 1.7671235658789193

Epoch: 5| Step: 2
Training loss: 1.3911839723587036
Validation loss: 1.8222790841133363

Epoch: 5| Step: 3
Training loss: 1.6240125894546509
Validation loss: 1.79274873323338

Epoch: 5| Step: 4
Training loss: 1.7688205242156982
Validation loss: 1.7906924780978952

Epoch: 5| Step: 5
Training loss: 0.8230891227722168
Validation loss: 1.816975987085732

Epoch: 5| Step: 6
Training loss: 1.2052056789398193
Validation loss: 1.7941432409389044

Epoch: 5| Step: 7
Training loss: 1.1746633052825928
Validation loss: 1.7645268542792207

Epoch: 5| Step: 8
Training loss: 0.9389740228652954
Validation loss: 1.8192506938852289

Epoch: 5| Step: 9
Training loss: 1.0592031478881836
Validation loss: 1.8177884419759114

Epoch: 5| Step: 10
Training loss: 1.6166326999664307
Validation loss: 1.7822968370171004

Epoch: 388| Step: 0
Training loss: 0.9259637594223022
Validation loss: 1.7795956019432313

Epoch: 5| Step: 1
Training loss: 1.7185745239257812
Validation loss: 1.827502659572068

Epoch: 5| Step: 2
Training loss: 0.9036374092102051
Validation loss: 1.7603751741429812

Epoch: 5| Step: 3
Training loss: 1.2569105625152588
Validation loss: 1.811787405321675

Epoch: 5| Step: 4
Training loss: 1.228318691253662
Validation loss: 1.7704591033279256

Epoch: 5| Step: 5
Training loss: 1.3310606479644775
Validation loss: 1.790727461538007

Epoch: 5| Step: 6
Training loss: 1.009839415550232
Validation loss: 1.8271069898400256

Epoch: 5| Step: 7
Training loss: 1.892433762550354
Validation loss: 1.7980563486776044

Epoch: 5| Step: 8
Training loss: 1.0978162288665771
Validation loss: 1.7664206527894544

Epoch: 5| Step: 9
Training loss: 1.0513923168182373
Validation loss: 1.7440443654214182

Epoch: 5| Step: 10
Training loss: 1.6706980466842651
Validation loss: 1.8263743333919074

Epoch: 389| Step: 0
Training loss: 1.0338733196258545
Validation loss: 1.8316189653129988

Epoch: 5| Step: 1
Training loss: 1.2268797159194946
Validation loss: 1.8589481435796267

Epoch: 5| Step: 2
Training loss: 1.4153419733047485
Validation loss: 1.769579836117324

Epoch: 5| Step: 3
Training loss: 1.4193990230560303
Validation loss: 1.8540250357761179

Epoch: 5| Step: 4
Training loss: 1.330399990081787
Validation loss: 1.7614346781084615

Epoch: 5| Step: 5
Training loss: 1.4981451034545898
Validation loss: 1.8062207134821082

Epoch: 5| Step: 6
Training loss: 1.39565908908844
Validation loss: 1.8055585174150364

Epoch: 5| Step: 7
Training loss: 1.3744661808013916
Validation loss: 1.8225533564885457

Epoch: 5| Step: 8
Training loss: 1.2257859706878662
Validation loss: 1.7941123131782777

Epoch: 5| Step: 9
Training loss: 1.1068060398101807
Validation loss: 1.797634264474274

Epoch: 5| Step: 10
Training loss: 1.4295259714126587
Validation loss: 1.857492978854846

Epoch: 390| Step: 0
Training loss: 1.3455795049667358
Validation loss: 1.8130008469345749

Epoch: 5| Step: 1
Training loss: 1.4127495288848877
Validation loss: 1.7691066393288233

Epoch: 5| Step: 2
Training loss: 0.9727951884269714
Validation loss: 1.7676271776999197

Epoch: 5| Step: 3
Training loss: 1.1493074893951416
Validation loss: 1.7708849407011462

Epoch: 5| Step: 4
Training loss: 1.9718425273895264
Validation loss: 1.7391338489388908

Epoch: 5| Step: 5
Training loss: 1.4440237283706665
Validation loss: 1.8460202460647912

Epoch: 5| Step: 6
Training loss: 1.1398390531539917
Validation loss: 1.876664379591583

Epoch: 5| Step: 7
Training loss: 1.5313619375228882
Validation loss: 1.7772446370893908

Epoch: 5| Step: 8
Training loss: 1.0839638710021973
Validation loss: 1.7977819917022542

Epoch: 5| Step: 9
Training loss: 1.1015841960906982
Validation loss: 1.8232054902661232

Epoch: 5| Step: 10
Training loss: 1.2922667264938354
Validation loss: 1.7906644959603586

Epoch: 391| Step: 0
Training loss: 1.6328999996185303
Validation loss: 1.7927169222985544

Epoch: 5| Step: 1
Training loss: 1.5318598747253418
Validation loss: 1.7946248387777677

Epoch: 5| Step: 2
Training loss: 1.4987764358520508
Validation loss: 1.785064064046388

Epoch: 5| Step: 3
Training loss: 1.1268970966339111
Validation loss: 1.841318142029547

Epoch: 5| Step: 4
Training loss: 1.194152593612671
Validation loss: 1.8097083184026903

Epoch: 5| Step: 5
Training loss: 1.5769374370574951
Validation loss: 1.778941495444185

Epoch: 5| Step: 6
Training loss: 0.9803676605224609
Validation loss: 1.865568728857143

Epoch: 5| Step: 7
Training loss: 1.105918288230896
Validation loss: 1.795790828684325

Epoch: 5| Step: 8
Training loss: 1.062074065208435
Validation loss: 1.8326122812045518

Epoch: 5| Step: 9
Training loss: 1.0812156200408936
Validation loss: 1.8564022869192145

Epoch: 5| Step: 10
Training loss: 1.4451656341552734
Validation loss: 1.7707576931163829

Epoch: 392| Step: 0
Training loss: 1.0004040002822876
Validation loss: 1.8211568273523802

Epoch: 5| Step: 1
Training loss: 1.239445447921753
Validation loss: 1.7441531509481452

Epoch: 5| Step: 2
Training loss: 1.2926695346832275
Validation loss: 1.773288587088226

Epoch: 5| Step: 3
Training loss: 1.0884732007980347
Validation loss: 1.796720512451664

Epoch: 5| Step: 4
Training loss: 1.2189903259277344
Validation loss: 1.8136422172669442

Epoch: 5| Step: 5
Training loss: 1.4581009149551392
Validation loss: 1.787934886511936

Epoch: 5| Step: 6
Training loss: 1.321791410446167
Validation loss: 1.7527501634372178

Epoch: 5| Step: 7
Training loss: 1.2959411144256592
Validation loss: 1.8042804130943872

Epoch: 5| Step: 8
Training loss: 1.370800495147705
Validation loss: 1.7565384718679613

Epoch: 5| Step: 9
Training loss: 1.3755055665969849
Validation loss: 1.7536203938145791

Epoch: 5| Step: 10
Training loss: 1.148735523223877
Validation loss: 1.801926218053346

Epoch: 393| Step: 0
Training loss: 1.3239662647247314
Validation loss: 1.8465552073653027

Epoch: 5| Step: 1
Training loss: 0.9410222768783569
Validation loss: 1.8504147132237752

Epoch: 5| Step: 2
Training loss: 0.9737554788589478
Validation loss: 1.7665519765628281

Epoch: 5| Step: 3
Training loss: 1.0347564220428467
Validation loss: 1.8101659974744242

Epoch: 5| Step: 4
Training loss: 1.286435604095459
Validation loss: 1.8184343871249948

Epoch: 5| Step: 5
Training loss: 1.203505039215088
Validation loss: 1.8260209380939443

Epoch: 5| Step: 6
Training loss: 1.530623197555542
Validation loss: 1.8535741003610755

Epoch: 5| Step: 7
Training loss: 1.2546803951263428
Validation loss: 1.8255482078880392

Epoch: 5| Step: 8
Training loss: 1.1453744173049927
Validation loss: 1.819934674488601

Epoch: 5| Step: 9
Training loss: 1.6296859979629517
Validation loss: 1.8368754130537792

Epoch: 5| Step: 10
Training loss: 1.568320631980896
Validation loss: 1.8117517181622085

Epoch: 394| Step: 0
Training loss: 1.0240288972854614
Validation loss: 1.8334009083368445

Epoch: 5| Step: 1
Training loss: 0.9624687433242798
Validation loss: 1.7601619766604515

Epoch: 5| Step: 2
Training loss: 1.5197418928146362
Validation loss: 1.847998385788292

Epoch: 5| Step: 3
Training loss: 1.557159185409546
Validation loss: 1.8087171149510208

Epoch: 5| Step: 4
Training loss: 0.9504225850105286
Validation loss: 1.789422078799176

Epoch: 5| Step: 5
Training loss: 1.9260528087615967
Validation loss: 1.8011017409704064

Epoch: 5| Step: 6
Training loss: 1.2448431253433228
Validation loss: 1.7332775438985517

Epoch: 5| Step: 7
Training loss: 1.7888944149017334
Validation loss: 1.7690453260175643

Epoch: 5| Step: 8
Training loss: 1.117727279663086
Validation loss: 1.7942856281034407

Epoch: 5| Step: 9
Training loss: 0.9170804023742676
Validation loss: 1.7429645702403078

Epoch: 5| Step: 10
Training loss: 0.9288080930709839
Validation loss: 1.7909693243683025

Epoch: 395| Step: 0
Training loss: 1.2509338855743408
Validation loss: 1.8524397509072417

Epoch: 5| Step: 1
Training loss: 1.2893493175506592
Validation loss: 1.8081217696589809

Epoch: 5| Step: 2
Training loss: 1.2240298986434937
Validation loss: 1.7669310262126308

Epoch: 5| Step: 3
Training loss: 1.1594949960708618
Validation loss: 1.8443948312472271

Epoch: 5| Step: 4
Training loss: 1.5492087602615356
Validation loss: 1.7705305494287962

Epoch: 5| Step: 5
Training loss: 1.225690484046936
Validation loss: 1.7943039286521174

Epoch: 5| Step: 6
Training loss: 0.8407605290412903
Validation loss: 1.7827342530732513

Epoch: 5| Step: 7
Training loss: 1.1528007984161377
Validation loss: 1.7998725791131296

Epoch: 5| Step: 8
Training loss: 1.021160364151001
Validation loss: 1.8410438696543376

Epoch: 5| Step: 9
Training loss: 1.628990888595581
Validation loss: 1.7244725176083144

Epoch: 5| Step: 10
Training loss: 1.5895215272903442
Validation loss: 1.826827500456123

Epoch: 396| Step: 0
Training loss: 1.4342904090881348
Validation loss: 1.7729271304222844

Epoch: 5| Step: 1
Training loss: 1.7650830745697021
Validation loss: 1.7354642216877272

Epoch: 5| Step: 2
Training loss: 1.1111969947814941
Validation loss: 1.7898097627906389

Epoch: 5| Step: 3
Training loss: 1.0139750242233276
Validation loss: 1.7924783127282256

Epoch: 5| Step: 4
Training loss: 1.3678576946258545
Validation loss: 1.8097045190872685

Epoch: 5| Step: 5
Training loss: 1.5380702018737793
Validation loss: 1.799410557234159

Epoch: 5| Step: 6
Training loss: 0.6975136399269104
Validation loss: 1.840630280074253

Epoch: 5| Step: 7
Training loss: 1.3121416568756104
Validation loss: 1.810959126359673

Epoch: 5| Step: 8
Training loss: 0.8257488012313843
Validation loss: 1.831985983797299

Epoch: 5| Step: 9
Training loss: 1.3671607971191406
Validation loss: 1.8451304679275842

Epoch: 5| Step: 10
Training loss: 1.7552499771118164
Validation loss: 1.8007433991278372

Epoch: 397| Step: 0
Training loss: 1.2208588123321533
Validation loss: 1.8496118373768304

Epoch: 5| Step: 1
Training loss: 0.8410247564315796
Validation loss: 1.7686752273190407

Epoch: 5| Step: 2
Training loss: 1.4574263095855713
Validation loss: 1.8300663783986082

Epoch: 5| Step: 3
Training loss: 1.0544029474258423
Validation loss: 1.8058851559956868

Epoch: 5| Step: 4
Training loss: 1.5991891622543335
Validation loss: 1.8216497936556417

Epoch: 5| Step: 5
Training loss: 1.2654058933258057
Validation loss: 1.7748584644768828

Epoch: 5| Step: 6
Training loss: 1.528423547744751
Validation loss: 1.8096595605214436

Epoch: 5| Step: 7
Training loss: 0.9355707168579102
Validation loss: 1.7597217329086796

Epoch: 5| Step: 8
Training loss: 1.2628796100616455
Validation loss: 1.8237431741529895

Epoch: 5| Step: 9
Training loss: 1.1807911396026611
Validation loss: 1.809295169768795

Epoch: 5| Step: 10
Training loss: 1.5416728258132935
Validation loss: 1.8223498931495092

Epoch: 398| Step: 0
Training loss: 1.3203461170196533
Validation loss: 1.7740645139448104

Epoch: 5| Step: 1
Training loss: 1.6648375988006592
Validation loss: 1.8168182629410938

Epoch: 5| Step: 2
Training loss: 0.7490646839141846
Validation loss: 1.7938290078152892

Epoch: 5| Step: 3
Training loss: 0.5872155427932739
Validation loss: 1.8202611836053992

Epoch: 5| Step: 4
Training loss: 1.2841081619262695
Validation loss: 1.7982252387590305

Epoch: 5| Step: 5
Training loss: 1.4420197010040283
Validation loss: 1.7315806291436637

Epoch: 5| Step: 6
Training loss: 1.1853187084197998
Validation loss: 1.814247856857956

Epoch: 5| Step: 7
Training loss: 1.2289918661117554
Validation loss: 1.772657141890577

Epoch: 5| Step: 8
Training loss: 1.5270628929138184
Validation loss: 1.8067969327331872

Epoch: 5| Step: 9
Training loss: 1.432222604751587
Validation loss: 1.8206219544974707

Epoch: 5| Step: 10
Training loss: 1.4099606275558472
Validation loss: 1.780130963171682

Epoch: 399| Step: 0
Training loss: 0.5949967503547668
Validation loss: 1.753511728778962

Epoch: 5| Step: 1
Training loss: 1.6820087432861328
Validation loss: 1.7894099886699388

Epoch: 5| Step: 2
Training loss: 1.2371529340744019
Validation loss: 1.7993569515084709

Epoch: 5| Step: 3
Training loss: 1.2249091863632202
Validation loss: 1.8214782976335095

Epoch: 5| Step: 4
Training loss: 1.2434555292129517
Validation loss: 1.8030326302333544

Epoch: 5| Step: 5
Training loss: 0.9534305334091187
Validation loss: 1.7957587088308027

Epoch: 5| Step: 6
Training loss: 1.1864879131317139
Validation loss: 1.794722416067636

Epoch: 5| Step: 7
Training loss: 1.733938217163086
Validation loss: 1.8312992447166032

Epoch: 5| Step: 8
Training loss: 1.489758849143982
Validation loss: 1.8614375873278546

Epoch: 5| Step: 9
Training loss: 1.1229066848754883
Validation loss: 1.7848295960375058

Epoch: 5| Step: 10
Training loss: 1.4497606754302979
Validation loss: 1.8438967940627888

Epoch: 400| Step: 0
Training loss: 1.3323224782943726
Validation loss: 1.8198076935224636

Epoch: 5| Step: 1
Training loss: 1.2184278964996338
Validation loss: 1.7714687034647951

Epoch: 5| Step: 2
Training loss: 1.2549127340316772
Validation loss: 1.8243082236218195

Epoch: 5| Step: 3
Training loss: 1.4135202169418335
Validation loss: 1.8570012661718553

Epoch: 5| Step: 4
Training loss: 0.8795483708381653
Validation loss: 1.788159361449621

Epoch: 5| Step: 5
Training loss: 1.3239479064941406
Validation loss: 1.8032087933632635

Epoch: 5| Step: 6
Training loss: 1.3726409673690796
Validation loss: 1.7976210399340558

Epoch: 5| Step: 7
Training loss: 1.4906855821609497
Validation loss: 1.7968453591869724

Epoch: 5| Step: 8
Training loss: 1.2451252937316895
Validation loss: 1.8591348740362352

Epoch: 5| Step: 9
Training loss: 1.3991620540618896
Validation loss: 1.8131803850973807

Epoch: 5| Step: 10
Training loss: 1.262467622756958
Validation loss: 1.8032631104992283

Epoch: 401| Step: 0
Training loss: 1.0287178754806519
Validation loss: 1.825525568377587

Epoch: 5| Step: 1
Training loss: 1.3466440439224243
Validation loss: 1.7884319008037608

Epoch: 5| Step: 2
Training loss: 1.270904541015625
Validation loss: 1.755431487996091

Epoch: 5| Step: 3
Training loss: 1.2422631978988647
Validation loss: 1.802251410740678

Epoch: 5| Step: 4
Training loss: 1.6495201587677002
Validation loss: 1.7749892562948248

Epoch: 5| Step: 5
Training loss: 1.1191918849945068
Validation loss: 1.7685624989130164

Epoch: 5| Step: 6
Training loss: 0.8762483596801758
Validation loss: 1.7856031848538307

Epoch: 5| Step: 7
Training loss: 1.330708622932434
Validation loss: 1.7481940068224424

Epoch: 5| Step: 8
Training loss: 1.9357681274414062
Validation loss: 1.7276819944381714

Epoch: 5| Step: 9
Training loss: 0.9779623746871948
Validation loss: 1.8381975338023195

Epoch: 5| Step: 10
Training loss: 0.9909441471099854
Validation loss: 1.7368786040172781

Epoch: 402| Step: 0
Training loss: 0.866923987865448
Validation loss: 1.76593771929382

Epoch: 5| Step: 1
Training loss: 1.334082841873169
Validation loss: 1.8435182186865038

Epoch: 5| Step: 2
Training loss: 0.774655818939209
Validation loss: 1.8148776010800434

Epoch: 5| Step: 3
Training loss: 1.560821294784546
Validation loss: 1.8026945937064387

Epoch: 5| Step: 4
Training loss: 1.3855222463607788
Validation loss: 1.787512222925822

Epoch: 5| Step: 5
Training loss: 1.5031547546386719
Validation loss: 1.815304237027322

Epoch: 5| Step: 6
Training loss: 1.3646217584609985
Validation loss: 1.7642369385688537

Epoch: 5| Step: 7
Training loss: 1.6889327764511108
Validation loss: 1.8552691987765733

Epoch: 5| Step: 8
Training loss: 1.181277871131897
Validation loss: 1.8262460193326395

Epoch: 5| Step: 9
Training loss: 1.0935096740722656
Validation loss: 1.7838415997002715

Epoch: 5| Step: 10
Training loss: 0.8397743701934814
Validation loss: 1.820071155025113

Epoch: 403| Step: 0
Training loss: 1.0341284275054932
Validation loss: 1.7962205256185224

Epoch: 5| Step: 1
Training loss: 1.5030039548873901
Validation loss: 1.876186442631547

Epoch: 5| Step: 2
Training loss: 1.055795431137085
Validation loss: 1.838314374287923

Epoch: 5| Step: 3
Training loss: 1.4801545143127441
Validation loss: 1.8387835999970794

Epoch: 5| Step: 4
Training loss: 0.7979105114936829
Validation loss: 1.8039206548403668

Epoch: 5| Step: 5
Training loss: 1.1852643489837646
Validation loss: 1.8067558503920031

Epoch: 5| Step: 6
Training loss: 1.5872513055801392
Validation loss: 1.8251748059385566

Epoch: 5| Step: 7
Training loss: 1.0523335933685303
Validation loss: 1.7645149615503126

Epoch: 5| Step: 8
Training loss: 1.9539467096328735
Validation loss: 1.7682634758692917

Epoch: 5| Step: 9
Training loss: 0.9396697282791138
Validation loss: 1.7775015074719664

Epoch: 5| Step: 10
Training loss: 1.2046741247177124
Validation loss: 1.8357713991595852

Epoch: 404| Step: 0
Training loss: 0.9902349710464478
Validation loss: 1.735831432445075

Epoch: 5| Step: 1
Training loss: 1.5863678455352783
Validation loss: 1.82170735379701

Epoch: 5| Step: 2
Training loss: 1.6803995370864868
Validation loss: 1.8561894470645535

Epoch: 5| Step: 3
Training loss: 1.1370913982391357
Validation loss: 1.776965392533169

Epoch: 5| Step: 4
Training loss: 1.2950600385665894
Validation loss: 1.8022293044674782

Epoch: 5| Step: 5
Training loss: 0.9161972999572754
Validation loss: 1.812208624296291

Epoch: 5| Step: 6
Training loss: 0.9178125262260437
Validation loss: 1.8335723274497575

Epoch: 5| Step: 7
Training loss: 1.3339382410049438
Validation loss: 1.753353153505633

Epoch: 5| Step: 8
Training loss: 1.4285361766815186
Validation loss: 1.811449340594712

Epoch: 5| Step: 9
Training loss: 1.0753570795059204
Validation loss: 1.7868394415865663

Epoch: 5| Step: 10
Training loss: 1.386646032333374
Validation loss: 1.8069644756214593

Epoch: 405| Step: 0
Training loss: 1.1876811981201172
Validation loss: 1.7646080511872486

Epoch: 5| Step: 1
Training loss: 0.7976356148719788
Validation loss: 1.814549711442763

Epoch: 5| Step: 2
Training loss: 1.3982090950012207
Validation loss: 1.855370831745927

Epoch: 5| Step: 3
Training loss: 1.059958815574646
Validation loss: 1.8484457000609367

Epoch: 5| Step: 4
Training loss: 1.6361815929412842
Validation loss: 1.8054909642024706

Epoch: 5| Step: 5
Training loss: 1.5053659677505493
Validation loss: 1.801403845510175

Epoch: 5| Step: 6
Training loss: 1.1844408512115479
Validation loss: 1.8412852056564823

Epoch: 5| Step: 7
Training loss: 1.394242525100708
Validation loss: 1.8825907053485993

Epoch: 5| Step: 8
Training loss: 1.0461448431015015
Validation loss: 1.8853187843035626

Epoch: 5| Step: 9
Training loss: 1.764695405960083
Validation loss: 1.8139599189963391

Epoch: 5| Step: 10
Training loss: 1.0646759271621704
Validation loss: 1.812412449108657

Epoch: 406| Step: 0
Training loss: 1.202427864074707
Validation loss: 1.833403988551068

Epoch: 5| Step: 1
Training loss: 0.9823137521743774
Validation loss: 1.7841267995936896

Epoch: 5| Step: 2
Training loss: 1.456551432609558
Validation loss: 1.7826659820413078

Epoch: 5| Step: 3
Training loss: 1.2535126209259033
Validation loss: 1.824130960690078

Epoch: 5| Step: 4
Training loss: 0.9714568853378296
Validation loss: 1.795662195451798

Epoch: 5| Step: 5
Training loss: 1.4231274127960205
Validation loss: 1.7900993452277234

Epoch: 5| Step: 6
Training loss: 1.2735121250152588
Validation loss: 1.7987267458310692

Epoch: 5| Step: 7
Training loss: 0.9194436073303223
Validation loss: 1.790435819215672

Epoch: 5| Step: 8
Training loss: 1.721933126449585
Validation loss: 1.810600564044009

Epoch: 5| Step: 9
Training loss: 1.5142362117767334
Validation loss: 1.7518528078192024

Epoch: 5| Step: 10
Training loss: 1.0453333854675293
Validation loss: 1.7762549577220794

Epoch: 407| Step: 0
Training loss: 1.3393580913543701
Validation loss: 1.763106010293448

Epoch: 5| Step: 1
Training loss: 1.2380506992340088
Validation loss: 1.8418510062720186

Epoch: 5| Step: 2
Training loss: 1.531212568283081
Validation loss: 1.77378709085526

Epoch: 5| Step: 3
Training loss: 1.2932547330856323
Validation loss: 1.833199784319888

Epoch: 5| Step: 4
Training loss: 1.2916301488876343
Validation loss: 1.8408750641730525

Epoch: 5| Step: 5
Training loss: 0.9806379079818726
Validation loss: 1.8121223654798282

Epoch: 5| Step: 6
Training loss: 1.4072290658950806
Validation loss: 1.8393149132369666

Epoch: 5| Step: 7
Training loss: 1.3156297206878662
Validation loss: 1.8409344970539052

Epoch: 5| Step: 8
Training loss: 0.9826453924179077
Validation loss: 1.8126040915007233

Epoch: 5| Step: 9
Training loss: 1.438328504562378
Validation loss: 1.8547561809580813

Epoch: 5| Step: 10
Training loss: 0.6869851350784302
Validation loss: 1.7881380217049712

Epoch: 408| Step: 0
Training loss: 1.7003037929534912
Validation loss: 1.7869557296076128

Epoch: 5| Step: 1
Training loss: 0.8416183590888977
Validation loss: 1.7524317426066245

Epoch: 5| Step: 2
Training loss: 1.6864455938339233
Validation loss: 1.7551270954070552

Epoch: 5| Step: 3
Training loss: 1.1454708576202393
Validation loss: 1.8294205883497834

Epoch: 5| Step: 4
Training loss: 0.7837998270988464
Validation loss: 1.823526684955884

Epoch: 5| Step: 5
Training loss: 1.5573073625564575
Validation loss: 1.8612302759642243

Epoch: 5| Step: 6
Training loss: 1.4952224493026733
Validation loss: 1.7907394324579546

Epoch: 5| Step: 7
Training loss: 0.7873017191886902
Validation loss: 1.7900093242686281

Epoch: 5| Step: 8
Training loss: 1.1966054439544678
Validation loss: 1.8022119383658133

Epoch: 5| Step: 9
Training loss: 1.4514950513839722
Validation loss: 1.8017493755586687

Epoch: 5| Step: 10
Training loss: 0.9273068308830261
Validation loss: 1.7964038695058515

Epoch: 409| Step: 0
Training loss: 1.3947298526763916
Validation loss: 1.788155876180177

Epoch: 5| Step: 1
Training loss: 1.2521650791168213
Validation loss: 1.8132099079829391

Epoch: 5| Step: 2
Training loss: 1.1098549365997314
Validation loss: 1.826250937677199

Epoch: 5| Step: 3
Training loss: 1.1449358463287354
Validation loss: 1.7785566699120305

Epoch: 5| Step: 4
Training loss: 1.6386276483535767
Validation loss: 1.7627599303440382

Epoch: 5| Step: 5
Training loss: 1.1708800792694092
Validation loss: 1.7443932564027849

Epoch: 5| Step: 6
Training loss: 1.0424731969833374
Validation loss: 1.7670839243037726

Epoch: 5| Step: 7
Training loss: 1.6533253192901611
Validation loss: 1.8160247777097969

Epoch: 5| Step: 8
Training loss: 0.9508541226387024
Validation loss: 1.839391916028915

Epoch: 5| Step: 9
Training loss: 1.1865217685699463
Validation loss: 1.784206223744218

Epoch: 5| Step: 10
Training loss: 1.1350892782211304
Validation loss: 1.7316628463806645

Epoch: 410| Step: 0
Training loss: 1.2772705554962158
Validation loss: 1.7795550528392996

Epoch: 5| Step: 1
Training loss: 1.2198046445846558
Validation loss: 1.8155485404435026

Epoch: 5| Step: 2
Training loss: 1.1004230976104736
Validation loss: 1.7829717871963338

Epoch: 5| Step: 3
Training loss: 1.6796600818634033
Validation loss: 1.839588047355734

Epoch: 5| Step: 4
Training loss: 0.9896261096000671
Validation loss: 1.803810461874931

Epoch: 5| Step: 5
Training loss: 0.9428746104240417
Validation loss: 1.8372078941714378

Epoch: 5| Step: 6
Training loss: 1.0449790954589844
Validation loss: 1.8063756112129457

Epoch: 5| Step: 7
Training loss: 1.2299716472625732
Validation loss: 1.745644418142175

Epoch: 5| Step: 8
Training loss: 1.1701768636703491
Validation loss: 1.825232716016872

Epoch: 5| Step: 9
Training loss: 1.6937814950942993
Validation loss: 1.803732769463652

Epoch: 5| Step: 10
Training loss: 1.5183604955673218
Validation loss: 1.7431675426421627

Epoch: 411| Step: 0
Training loss: 1.068052053451538
Validation loss: 1.7647655804951985

Epoch: 5| Step: 1
Training loss: 1.1162598133087158
Validation loss: 1.808122468251054

Epoch: 5| Step: 2
Training loss: 1.4995996952056885
Validation loss: 1.7601704405200096

Epoch: 5| Step: 3
Training loss: 1.2187464237213135
Validation loss: 1.8028466009324597

Epoch: 5| Step: 4
Training loss: 1.5499846935272217
Validation loss: 1.764874146830651

Epoch: 5| Step: 5
Training loss: 1.2188678979873657
Validation loss: 1.7570356643328102

Epoch: 5| Step: 6
Training loss: 1.199904203414917
Validation loss: 1.7549343929495862

Epoch: 5| Step: 7
Training loss: 1.2176172733306885
Validation loss: 1.796084314264277

Epoch: 5| Step: 8
Training loss: 1.0840122699737549
Validation loss: 1.8069884097704323

Epoch: 5| Step: 9
Training loss: 1.3881345987319946
Validation loss: 1.7684899132738832

Epoch: 5| Step: 10
Training loss: 0.9050623774528503
Validation loss: 1.7720212577491679

Epoch: 412| Step: 0
Training loss: 1.3015433549880981
Validation loss: 1.8181267630669378

Epoch: 5| Step: 1
Training loss: 1.6366298198699951
Validation loss: 1.828128864688258

Epoch: 5| Step: 2
Training loss: 0.8582663536071777
Validation loss: 1.7990497363510953

Epoch: 5| Step: 3
Training loss: 1.2044854164123535
Validation loss: 1.8385609170441986

Epoch: 5| Step: 4
Training loss: 1.130356788635254
Validation loss: 1.7949971998891523

Epoch: 5| Step: 5
Training loss: 0.8305765390396118
Validation loss: 1.8084758315035092

Epoch: 5| Step: 6
Training loss: 1.6558196544647217
Validation loss: 1.8060434236321399

Epoch: 5| Step: 7
Training loss: 1.3085577487945557
Validation loss: 1.791400304404638

Epoch: 5| Step: 8
Training loss: 1.2740830183029175
Validation loss: 1.8204016044575682

Epoch: 5| Step: 9
Training loss: 1.0059133768081665
Validation loss: 1.784672280793549

Epoch: 5| Step: 10
Training loss: 1.43096125125885
Validation loss: 1.804167801334012

Epoch: 413| Step: 0
Training loss: 1.2725833654403687
Validation loss: 1.766870298693257

Epoch: 5| Step: 1
Training loss: 0.9213764071464539
Validation loss: 1.8055409359675583

Epoch: 5| Step: 2
Training loss: 0.768467366695404
Validation loss: 1.74732240041097

Epoch: 5| Step: 3
Training loss: 1.3088997602462769
Validation loss: 1.8495013444654402

Epoch: 5| Step: 4
Training loss: 0.8097931146621704
Validation loss: 1.8260087326008787

Epoch: 5| Step: 5
Training loss: 1.7959091663360596
Validation loss: 1.8018339039177023

Epoch: 5| Step: 6
Training loss: 1.0020471811294556
Validation loss: 1.8107044901899112

Epoch: 5| Step: 7
Training loss: 1.5130103826522827
Validation loss: 1.8382471992123512

Epoch: 5| Step: 8
Training loss: 1.8821855783462524
Validation loss: 1.7668255042004328

Epoch: 5| Step: 9
Training loss: 1.4075603485107422
Validation loss: 1.82348128544387

Epoch: 5| Step: 10
Training loss: 1.2611922025680542
Validation loss: 1.7659133506077591

Epoch: 414| Step: 0
Training loss: 1.1781424283981323
Validation loss: 1.831857148037162

Epoch: 5| Step: 1
Training loss: 1.365234613418579
Validation loss: 1.8195352503048476

Epoch: 5| Step: 2
Training loss: 1.198387622833252
Validation loss: 1.8053149689910233

Epoch: 5| Step: 3
Training loss: 0.8730291128158569
Validation loss: 1.7831665149299047

Epoch: 5| Step: 4
Training loss: 0.9703969955444336
Validation loss: 1.7844531728375344

Epoch: 5| Step: 5
Training loss: 0.8335175514221191
Validation loss: 1.8061019041204964

Epoch: 5| Step: 6
Training loss: 1.4116852283477783
Validation loss: 1.7701926692839591

Epoch: 5| Step: 7
Training loss: 1.6882011890411377
Validation loss: 1.7958009037920224

Epoch: 5| Step: 8
Training loss: 1.2801518440246582
Validation loss: 1.8283775211662374

Epoch: 5| Step: 9
Training loss: 1.0714150667190552
Validation loss: 1.8335142802166682

Epoch: 5| Step: 10
Training loss: 1.4819328784942627
Validation loss: 1.7714701801218011

Epoch: 415| Step: 0
Training loss: 1.193712830543518
Validation loss: 1.8004364608436503

Epoch: 5| Step: 1
Training loss: 1.7110793590545654
Validation loss: 1.8596351210789015

Epoch: 5| Step: 2
Training loss: 0.8092902898788452
Validation loss: 1.790069656987344

Epoch: 5| Step: 3
Training loss: 1.6567211151123047
Validation loss: 1.7836147662132018

Epoch: 5| Step: 4
Training loss: 1.3578238487243652
Validation loss: 1.8792895270932106

Epoch: 5| Step: 5
Training loss: 0.7749561071395874
Validation loss: 1.81782026444712

Epoch: 5| Step: 6
Training loss: 1.187432050704956
Validation loss: 1.8334258012874152

Epoch: 5| Step: 7
Training loss: 1.3297855854034424
Validation loss: 1.7700375895346365

Epoch: 5| Step: 8
Training loss: 0.9074012637138367
Validation loss: 1.816913986718783

Epoch: 5| Step: 9
Training loss: 1.0791592597961426
Validation loss: 1.7969681332188268

Epoch: 5| Step: 10
Training loss: 1.4078714847564697
Validation loss: 1.7855972423348376

Epoch: 416| Step: 0
Training loss: 1.5467609167099
Validation loss: 1.8481880054678967

Epoch: 5| Step: 1
Training loss: 1.1718231439590454
Validation loss: 1.7881081219642394

Epoch: 5| Step: 2
Training loss: 1.7391353845596313
Validation loss: 1.8195111879738428

Epoch: 5| Step: 3
Training loss: 1.0879042148590088
Validation loss: 1.8300574312927902

Epoch: 5| Step: 4
Training loss: 1.1192880868911743
Validation loss: 1.7759619605156682

Epoch: 5| Step: 5
Training loss: 1.1022627353668213
Validation loss: 1.7614879800427345

Epoch: 5| Step: 6
Training loss: 1.0552728176116943
Validation loss: 1.7774132195339407

Epoch: 5| Step: 7
Training loss: 1.314190149307251
Validation loss: 1.8219621078942412

Epoch: 5| Step: 8
Training loss: 0.9856743812561035
Validation loss: 1.768052835618296

Epoch: 5| Step: 9
Training loss: 1.4130266904830933
Validation loss: 1.7432643085397699

Epoch: 5| Step: 10
Training loss: 1.239060640335083
Validation loss: 1.7419785222699564

Epoch: 417| Step: 0
Training loss: 1.2859165668487549
Validation loss: 1.8124508280907907

Epoch: 5| Step: 1
Training loss: 1.0819039344787598
Validation loss: 1.7813762823740642

Epoch: 5| Step: 2
Training loss: 1.441868543624878
Validation loss: 1.7733701967423963

Epoch: 5| Step: 3
Training loss: 1.2540514469146729
Validation loss: 1.8215086831841418

Epoch: 5| Step: 4
Training loss: 0.6423386931419373
Validation loss: 1.7634934417663082

Epoch: 5| Step: 5
Training loss: 0.7624426484107971
Validation loss: 1.7802084876644997

Epoch: 5| Step: 6
Training loss: 1.6891403198242188
Validation loss: 1.7919325546551776

Epoch: 5| Step: 7
Training loss: 1.384220838546753
Validation loss: 1.8449050277791998

Epoch: 5| Step: 8
Training loss: 1.4172577857971191
Validation loss: 1.7875854943388252

Epoch: 5| Step: 9
Training loss: 1.038811445236206
Validation loss: 1.8131206471432921

Epoch: 5| Step: 10
Training loss: 1.4703688621520996
Validation loss: 1.8209635211575417

Epoch: 418| Step: 0
Training loss: 1.0562994480133057
Validation loss: 1.8783383741173694

Epoch: 5| Step: 1
Training loss: 1.0375783443450928
Validation loss: 1.865566070361804

Epoch: 5| Step: 2
Training loss: 1.4157698154449463
Validation loss: 1.7715278440906155

Epoch: 5| Step: 3
Training loss: 1.0239441394805908
Validation loss: 1.8254807021028252

Epoch: 5| Step: 4
Training loss: 1.0370676517486572
Validation loss: 1.8144632539441508

Epoch: 5| Step: 5
Training loss: 1.7861976623535156
Validation loss: 1.8073501612550469

Epoch: 5| Step: 6
Training loss: 0.7283667325973511
Validation loss: 1.8063635595383183

Epoch: 5| Step: 7
Training loss: 1.259930968284607
Validation loss: 1.8462890937764158

Epoch: 5| Step: 8
Training loss: 0.9817706942558289
Validation loss: 1.8177696107536234

Epoch: 5| Step: 9
Training loss: 1.6090961694717407
Validation loss: 1.7665037391006306

Epoch: 5| Step: 10
Training loss: 1.2404252290725708
Validation loss: 1.784983750312559

Epoch: 419| Step: 0
Training loss: 1.19448983669281
Validation loss: 1.7769619572547175

Epoch: 5| Step: 1
Training loss: 1.3534135818481445
Validation loss: 1.7819673527953446

Epoch: 5| Step: 2
Training loss: 0.6780441403388977
Validation loss: 1.8416933398092947

Epoch: 5| Step: 3
Training loss: 0.7489196062088013
Validation loss: 1.7716171574848953

Epoch: 5| Step: 4
Training loss: 1.5099385976791382
Validation loss: 1.852061689540904

Epoch: 5| Step: 5
Training loss: 1.4148750305175781
Validation loss: 1.8311243364887853

Epoch: 5| Step: 6
Training loss: 1.4676573276519775
Validation loss: 1.8166338846247683

Epoch: 5| Step: 7
Training loss: 1.4754273891448975
Validation loss: 1.8176527638589182

Epoch: 5| Step: 8
Training loss: 1.1202137470245361
Validation loss: 1.8062545484112156

Epoch: 5| Step: 9
Training loss: 1.2492786645889282
Validation loss: 1.8278607976052068

Epoch: 5| Step: 10
Training loss: 1.3234529495239258
Validation loss: 1.8302545778213009

Epoch: 420| Step: 0
Training loss: 1.4157692193984985
Validation loss: 1.780677395482217

Epoch: 5| Step: 1
Training loss: 1.4298502206802368
Validation loss: 1.8103627838114256

Epoch: 5| Step: 2
Training loss: 1.3282477855682373
Validation loss: 1.8443240939929921

Epoch: 5| Step: 3
Training loss: 1.2898420095443726
Validation loss: 1.8568667763022966

Epoch: 5| Step: 4
Training loss: 1.348185658454895
Validation loss: 1.8372779725700297

Epoch: 5| Step: 5
Training loss: 1.177785873413086
Validation loss: 1.847091902968704

Epoch: 5| Step: 6
Training loss: 1.2462836503982544
Validation loss: 1.8066050006497292

Epoch: 5| Step: 7
Training loss: 1.4102303981781006
Validation loss: 1.8180761529553322

Epoch: 5| Step: 8
Training loss: 1.0835720300674438
Validation loss: 1.8482086863569034

Epoch: 5| Step: 9
Training loss: 1.0566160678863525
Validation loss: 1.8214762851756106

Epoch: 5| Step: 10
Training loss: 0.8733657598495483
Validation loss: 1.7884717231155725

Epoch: 421| Step: 0
Training loss: 1.8128448724746704
Validation loss: 1.805873324794154

Epoch: 5| Step: 1
Training loss: 1.4261382818222046
Validation loss: 1.7573766067463865

Epoch: 5| Step: 2
Training loss: 0.9876290559768677
Validation loss: 1.8028168678283691

Epoch: 5| Step: 3
Training loss: 1.5264976024627686
Validation loss: 1.811939412547696

Epoch: 5| Step: 4
Training loss: 0.9669971466064453
Validation loss: 1.835710604985555

Epoch: 5| Step: 5
Training loss: 1.161429762840271
Validation loss: 1.8139307191295009

Epoch: 5| Step: 6
Training loss: 1.043103575706482
Validation loss: 1.7930108949702273

Epoch: 5| Step: 7
Training loss: 1.382367491722107
Validation loss: 1.779295713670792

Epoch: 5| Step: 8
Training loss: 0.7676757574081421
Validation loss: 1.8206253718304377

Epoch: 5| Step: 9
Training loss: 1.2386003732681274
Validation loss: 1.7533762493441183

Epoch: 5| Step: 10
Training loss: 1.068681240081787
Validation loss: 1.786331662567713

Epoch: 422| Step: 0
Training loss: 1.1314947605133057
Validation loss: 1.8020528119097474

Epoch: 5| Step: 1
Training loss: 0.577423095703125
Validation loss: 1.7870061589825539

Epoch: 5| Step: 2
Training loss: 1.2885448932647705
Validation loss: 1.7632617501802341

Epoch: 5| Step: 3
Training loss: 1.1912333965301514
Validation loss: 1.7984821129870672

Epoch: 5| Step: 4
Training loss: 0.7759990692138672
Validation loss: 1.8028279158376879

Epoch: 5| Step: 5
Training loss: 0.8878406286239624
Validation loss: 1.8034414181145288

Epoch: 5| Step: 6
Training loss: 1.5250725746154785
Validation loss: 1.7748222107528357

Epoch: 5| Step: 7
Training loss: 1.3219765424728394
Validation loss: 1.8141736804798085

Epoch: 5| Step: 8
Training loss: 1.0963687896728516
Validation loss: 1.7772741176748788

Epoch: 5| Step: 9
Training loss: 1.8819921016693115
Validation loss: 1.7745205228046705

Epoch: 5| Step: 10
Training loss: 1.4348913431167603
Validation loss: 1.8138512834425895

Epoch: 423| Step: 0
Training loss: 1.2618409395217896
Validation loss: 1.8542153732751006

Epoch: 5| Step: 1
Training loss: 0.9236059188842773
Validation loss: 1.7809365039230676

Epoch: 5| Step: 2
Training loss: 1.4134379625320435
Validation loss: 1.8101131916046143

Epoch: 5| Step: 3
Training loss: 0.9666204452514648
Validation loss: 1.7856162645483529

Epoch: 5| Step: 4
Training loss: 0.9997800588607788
Validation loss: 1.8050349886699388

Epoch: 5| Step: 5
Training loss: 1.2498265504837036
Validation loss: 1.868330256913298

Epoch: 5| Step: 6
Training loss: 1.3073688745498657
Validation loss: 1.9112358349625782

Epoch: 5| Step: 7
Training loss: 1.1341880559921265
Validation loss: 1.808108739955451

Epoch: 5| Step: 8
Training loss: 1.5015764236450195
Validation loss: 1.8147728943055677

Epoch: 5| Step: 9
Training loss: 1.2921898365020752
Validation loss: 1.8120169460132558

Epoch: 5| Step: 10
Training loss: 1.358205795288086
Validation loss: 1.7679711631549302

Epoch: 424| Step: 0
Training loss: 1.4980436563491821
Validation loss: 1.8071204077812932

Epoch: 5| Step: 1
Training loss: 1.0404714345932007
Validation loss: 1.746891128119602

Epoch: 5| Step: 2
Training loss: 1.2299654483795166
Validation loss: 1.7349401648326586

Epoch: 5| Step: 3
Training loss: 1.4504823684692383
Validation loss: 1.7186848399459675

Epoch: 5| Step: 4
Training loss: 1.1302343606948853
Validation loss: 1.7911065034968878

Epoch: 5| Step: 5
Training loss: 0.9175878763198853
Validation loss: 1.760178901815927

Epoch: 5| Step: 6
Training loss: 1.4718658924102783
Validation loss: 1.7856534475921302

Epoch: 5| Step: 7
Training loss: 1.0473779439926147
Validation loss: 1.7583833394512054

Epoch: 5| Step: 8
Training loss: 1.3533915281295776
Validation loss: 1.7826887933156823

Epoch: 5| Step: 9
Training loss: 1.3671655654907227
Validation loss: 1.781095197123866

Epoch: 5| Step: 10
Training loss: 1.0947790145874023
Validation loss: 1.8050950778427945

Epoch: 425| Step: 0
Training loss: 1.2519934177398682
Validation loss: 1.8406062792706233

Epoch: 5| Step: 1
Training loss: 1.3722220659255981
Validation loss: 1.7748892025281024

Epoch: 5| Step: 2
Training loss: 1.7035062313079834
Validation loss: 1.8494354217283187

Epoch: 5| Step: 3
Training loss: 1.229925513267517
Validation loss: 1.7803872246896066

Epoch: 5| Step: 4
Training loss: 1.2998183965682983
Validation loss: 1.8399921450563657

Epoch: 5| Step: 5
Training loss: 1.2863361835479736
Validation loss: 1.7841946976159209

Epoch: 5| Step: 6
Training loss: 1.235555648803711
Validation loss: 1.8105987477046188

Epoch: 5| Step: 7
Training loss: 1.1322526931762695
Validation loss: 1.8481444184498121

Epoch: 5| Step: 8
Training loss: 1.1222114562988281
Validation loss: 1.8018392183447396

Epoch: 5| Step: 9
Training loss: 1.015766978263855
Validation loss: 1.8319598808083484

Epoch: 5| Step: 10
Training loss: 1.069052815437317
Validation loss: 1.8096060035049275

Epoch: 426| Step: 0
Training loss: 0.9939292669296265
Validation loss: 1.7879773314281175

Epoch: 5| Step: 1
Training loss: 1.5604573488235474
Validation loss: 1.8292141037602578

Epoch: 5| Step: 2
Training loss: 1.0828602313995361
Validation loss: 1.7702940817802184

Epoch: 5| Step: 3
Training loss: 1.0722084045410156
Validation loss: 1.8313155212709982

Epoch: 5| Step: 4
Training loss: 1.5563997030258179
Validation loss: 1.7816449916490944

Epoch: 5| Step: 5
Training loss: 0.9830650091171265
Validation loss: 1.8107059155741045

Epoch: 5| Step: 6
Training loss: 0.9292155504226685
Validation loss: 1.8075500662608812

Epoch: 5| Step: 7
Training loss: 1.6541839838027954
Validation loss: 1.8091980398342173

Epoch: 5| Step: 8
Training loss: 1.1744842529296875
Validation loss: 1.7554509562830771

Epoch: 5| Step: 9
Training loss: 1.400587558746338
Validation loss: 1.7571617659702097

Epoch: 5| Step: 10
Training loss: 1.1860911846160889
Validation loss: 1.7918826662084109

Epoch: 427| Step: 0
Training loss: 1.164743423461914
Validation loss: 1.7872186386457054

Epoch: 5| Step: 1
Training loss: 1.3758379220962524
Validation loss: 1.8276765884891633

Epoch: 5| Step: 2
Training loss: 1.1181178092956543
Validation loss: 1.8375317191564908

Epoch: 5| Step: 3
Training loss: 1.0841586589813232
Validation loss: 1.720390373660672

Epoch: 5| Step: 4
Training loss: 1.1542339324951172
Validation loss: 1.726216112413714

Epoch: 5| Step: 5
Training loss: 1.0786197185516357
Validation loss: 1.7813590944454234

Epoch: 5| Step: 6
Training loss: 1.1430028676986694
Validation loss: 1.7484115323712748

Epoch: 5| Step: 7
Training loss: 1.1597316265106201
Validation loss: 1.8152597309440694

Epoch: 5| Step: 8
Training loss: 0.985203742980957
Validation loss: 1.8015336067445817

Epoch: 5| Step: 9
Training loss: 1.2601035833358765
Validation loss: 1.827533321995889

Epoch: 5| Step: 10
Training loss: 1.612563133239746
Validation loss: 1.784769214609618

Epoch: 428| Step: 0
Training loss: 1.083661437034607
Validation loss: 1.7945280921074651

Epoch: 5| Step: 1
Training loss: 0.9819093942642212
Validation loss: 1.7881811998223747

Epoch: 5| Step: 2
Training loss: 1.2149251699447632
Validation loss: 1.8345696977389756

Epoch: 5| Step: 3
Training loss: 1.0725364685058594
Validation loss: 1.7492678588436497

Epoch: 5| Step: 4
Training loss: 1.3421828746795654
Validation loss: 1.782057403236307

Epoch: 5| Step: 5
Training loss: 1.6138076782226562
Validation loss: 1.8119445552108109

Epoch: 5| Step: 6
Training loss: 1.2700237035751343
Validation loss: 1.7934131109586327

Epoch: 5| Step: 7
Training loss: 0.9337489008903503
Validation loss: 1.8005912047560497

Epoch: 5| Step: 8
Training loss: 1.1965258121490479
Validation loss: 1.900405651779585

Epoch: 5| Step: 9
Training loss: 1.4754799604415894
Validation loss: 1.8353184115502141

Epoch: 5| Step: 10
Training loss: 1.2196027040481567
Validation loss: 1.7840810616811116

Epoch: 429| Step: 0
Training loss: 1.184792399406433
Validation loss: 1.8501062290642851

Epoch: 5| Step: 1
Training loss: 1.2500417232513428
Validation loss: 1.818632811628362

Epoch: 5| Step: 2
Training loss: 1.141579031944275
Validation loss: 1.8263818602408133

Epoch: 5| Step: 3
Training loss: 1.1830041408538818
Validation loss: 1.8052368792154456

Epoch: 5| Step: 4
Training loss: 1.51211678981781
Validation loss: 1.8029550429313415

Epoch: 5| Step: 5
Training loss: 1.2011326551437378
Validation loss: 1.8157549635056527

Epoch: 5| Step: 6
Training loss: 0.8643986582756042
Validation loss: 1.711847537307329

Epoch: 5| Step: 7
Training loss: 1.214005470275879
Validation loss: 1.7798457043145293

Epoch: 5| Step: 8
Training loss: 1.1989206075668335
Validation loss: 1.809907018497426

Epoch: 5| Step: 9
Training loss: 1.1580513715744019
Validation loss: 1.7169405029666038

Epoch: 5| Step: 10
Training loss: 1.0520058870315552
Validation loss: 1.81260129456879

Epoch: 430| Step: 0
Training loss: 1.1790460348129272
Validation loss: 1.7721814070978472

Epoch: 5| Step: 1
Training loss: 0.9689983129501343
Validation loss: 1.7865370729918122

Epoch: 5| Step: 2
Training loss: 0.6981768012046814
Validation loss: 1.7788372411522815

Epoch: 5| Step: 3
Training loss: 0.9697771072387695
Validation loss: 1.8746777811358053

Epoch: 5| Step: 4
Training loss: 0.9346917867660522
Validation loss: 1.8804126875374907

Epoch: 5| Step: 5
Training loss: 1.6076686382293701
Validation loss: 1.821883386181247

Epoch: 5| Step: 6
Training loss: 0.9651296734809875
Validation loss: 1.7976941139467302

Epoch: 5| Step: 7
Training loss: 0.8569141626358032
Validation loss: 1.7858669296387704

Epoch: 5| Step: 8
Training loss: 1.6216161251068115
Validation loss: 1.7894245629669518

Epoch: 5| Step: 9
Training loss: 1.5229867696762085
Validation loss: 1.796662410100301

Epoch: 5| Step: 10
Training loss: 1.7292264699935913
Validation loss: 1.8458583354949951

Epoch: 431| Step: 0
Training loss: 0.8343914151191711
Validation loss: 1.8177282207755632

Epoch: 5| Step: 1
Training loss: 1.1174638271331787
Validation loss: 1.8300587566949988

Epoch: 5| Step: 2
Training loss: 1.1290318965911865
Validation loss: 1.7693274328785558

Epoch: 5| Step: 3
Training loss: 1.1992112398147583
Validation loss: 1.8766705169472644

Epoch: 5| Step: 4
Training loss: 1.5608328580856323
Validation loss: 1.7729390321239349

Epoch: 5| Step: 5
Training loss: 1.4400463104248047
Validation loss: 1.8321667768621956

Epoch: 5| Step: 6
Training loss: 1.1474778652191162
Validation loss: 1.7755189531592912

Epoch: 5| Step: 7
Training loss: 1.3071537017822266
Validation loss: 1.7765721069869174

Epoch: 5| Step: 8
Training loss: 1.1737339496612549
Validation loss: 1.8088074268833283

Epoch: 5| Step: 9
Training loss: 1.0002630949020386
Validation loss: 1.7474004722410632

Epoch: 5| Step: 10
Training loss: 1.268729329109192
Validation loss: 1.8354553484147595

Epoch: 432| Step: 0
Training loss: 1.786348581314087
Validation loss: 1.7656001980586717

Epoch: 5| Step: 1
Training loss: 1.0959570407867432
Validation loss: 1.883336781173624

Epoch: 5| Step: 2
Training loss: 0.9320321083068848
Validation loss: 1.7911315489840764

Epoch: 5| Step: 3
Training loss: 1.2165629863739014
Validation loss: 1.7981797431104927

Epoch: 5| Step: 4
Training loss: 1.1898033618927002
Validation loss: 1.8194511084146396

Epoch: 5| Step: 5
Training loss: 1.112669825553894
Validation loss: 1.7886503640041556

Epoch: 5| Step: 6
Training loss: 1.0630404949188232
Validation loss: 1.7793180237534225

Epoch: 5| Step: 7
Training loss: 1.9254887104034424
Validation loss: 1.7871999548327537

Epoch: 5| Step: 8
Training loss: 0.575855016708374
Validation loss: 1.8126045119377874

Epoch: 5| Step: 9
Training loss: 1.3972829580307007
Validation loss: 1.7944694180642404

Epoch: 5| Step: 10
Training loss: 0.6873052716255188
Validation loss: 1.825967760496242

Epoch: 433| Step: 0
Training loss: 0.7362282276153564
Validation loss: 1.8300556457170876

Epoch: 5| Step: 1
Training loss: 1.2046204805374146
Validation loss: 1.7942769578708115

Epoch: 5| Step: 2
Training loss: 1.4324718713760376
Validation loss: 1.7935464882081555

Epoch: 5| Step: 3
Training loss: 1.319823145866394
Validation loss: 1.8997994699785787

Epoch: 5| Step: 4
Training loss: 1.4944058656692505
Validation loss: 1.77588112508097

Epoch: 5| Step: 5
Training loss: 0.8224096298217773
Validation loss: 1.8226603102940384

Epoch: 5| Step: 6
Training loss: 1.4599897861480713
Validation loss: 1.7760519801929433

Epoch: 5| Step: 7
Training loss: 1.1674293279647827
Validation loss: 1.8237098455429077

Epoch: 5| Step: 8
Training loss: 0.9907630085945129
Validation loss: 1.7393700538143035

Epoch: 5| Step: 9
Training loss: 1.0106966495513916
Validation loss: 1.7720471505195863

Epoch: 5| Step: 10
Training loss: 1.5839498043060303
Validation loss: 1.7624571195212744

Epoch: 434| Step: 0
Training loss: 1.47197687625885
Validation loss: 1.8144437395116335

Epoch: 5| Step: 1
Training loss: 1.5663294792175293
Validation loss: 1.8008964651374406

Epoch: 5| Step: 2
Training loss: 1.047359824180603
Validation loss: 1.7782357559409192

Epoch: 5| Step: 3
Training loss: 0.9826951026916504
Validation loss: 1.74006865614204

Epoch: 5| Step: 4
Training loss: 1.0728912353515625
Validation loss: 1.791343153163951

Epoch: 5| Step: 5
Training loss: 0.9297334551811218
Validation loss: 1.7852924485360422

Epoch: 5| Step: 6
Training loss: 0.7935857772827148
Validation loss: 1.7894363505865938

Epoch: 5| Step: 7
Training loss: 1.1701993942260742
Validation loss: 1.7799952491637199

Epoch: 5| Step: 8
Training loss: 1.0589438676834106
Validation loss: 1.7587793232292257

Epoch: 5| Step: 9
Training loss: 1.4796900749206543
Validation loss: 1.7375945352738904

Epoch: 5| Step: 10
Training loss: 1.6570231914520264
Validation loss: 1.7315634386513823

Epoch: 435| Step: 0
Training loss: 1.3851085901260376
Validation loss: 1.8052261772976126

Epoch: 5| Step: 1
Training loss: 0.8362165689468384
Validation loss: 1.8234266542619275

Epoch: 5| Step: 2
Training loss: 1.6749794483184814
Validation loss: 1.77098556487791

Epoch: 5| Step: 3
Training loss: 0.915555477142334
Validation loss: 1.7874714200214674

Epoch: 5| Step: 4
Training loss: 1.3875268697738647
Validation loss: 1.8193521832907071

Epoch: 5| Step: 5
Training loss: 1.1924149990081787
Validation loss: 1.7383902816362278

Epoch: 5| Step: 6
Training loss: 0.7968815565109253
Validation loss: 1.7866551235157957

Epoch: 5| Step: 7
Training loss: 1.0153626203536987
Validation loss: 1.7697636940146004

Epoch: 5| Step: 8
Training loss: 0.9329839944839478
Validation loss: 1.8206537718413978

Epoch: 5| Step: 9
Training loss: 1.6486186981201172
Validation loss: 1.7931229170932566

Epoch: 5| Step: 10
Training loss: 1.567836880683899
Validation loss: 1.8149153558156823

Epoch: 436| Step: 0
Training loss: 0.697930634021759
Validation loss: 1.8115973818686701

Epoch: 5| Step: 1
Training loss: 1.1826000213623047
Validation loss: 1.733452780272371

Epoch: 5| Step: 2
Training loss: 1.9981460571289062
Validation loss: 1.8427045191487958

Epoch: 5| Step: 3
Training loss: 1.3667482137680054
Validation loss: 1.7595753233919862

Epoch: 5| Step: 4
Training loss: 0.9165646433830261
Validation loss: 1.7775329184788529

Epoch: 5| Step: 5
Training loss: 1.5203025341033936
Validation loss: 1.8073262347969958

Epoch: 5| Step: 6
Training loss: 0.9000188708305359
Validation loss: 1.7570036060066634

Epoch: 5| Step: 7
Training loss: 1.4228184223175049
Validation loss: 1.7904740123338596

Epoch: 5| Step: 8
Training loss: 0.661652684211731
Validation loss: 1.7906444675178939

Epoch: 5| Step: 9
Training loss: 0.8805039525032043
Validation loss: 1.7833780768097087

Epoch: 5| Step: 10
Training loss: 1.4194200038909912
Validation loss: 1.8208080812167096

Epoch: 437| Step: 0
Training loss: 1.0357024669647217
Validation loss: 1.7866512331911313

Epoch: 5| Step: 1
Training loss: 1.2240034341812134
Validation loss: 1.7294290091401787

Epoch: 5| Step: 2
Training loss: 1.4421387910842896
Validation loss: 1.8086774759395148

Epoch: 5| Step: 3
Training loss: 0.9588757753372192
Validation loss: 1.8758999134904595

Epoch: 5| Step: 4
Training loss: 1.3834234476089478
Validation loss: 1.8401994179653864

Epoch: 5| Step: 5
Training loss: 1.4316823482513428
Validation loss: 1.7854896668464906

Epoch: 5| Step: 6
Training loss: 1.057215690612793
Validation loss: 1.7840387795561103

Epoch: 5| Step: 7
Training loss: 1.162372350692749
Validation loss: 1.8208228490685905

Epoch: 5| Step: 8
Training loss: 0.6968529224395752
Validation loss: 1.7437877244846796

Epoch: 5| Step: 9
Training loss: 1.5131632089614868
Validation loss: 1.7795357922072053

Epoch: 5| Step: 10
Training loss: 1.4770729541778564
Validation loss: 1.7387401788465437

Epoch: 438| Step: 0
Training loss: 1.3325586318969727
Validation loss: 1.7422298385250954

Epoch: 5| Step: 1
Training loss: 0.9520742297172546
Validation loss: 1.7781004149426696

Epoch: 5| Step: 2
Training loss: 1.0500023365020752
Validation loss: 1.7074014550896102

Epoch: 5| Step: 3
Training loss: 1.4088033437728882
Validation loss: 1.7664626080502746

Epoch: 5| Step: 4
Training loss: 1.3800688982009888
Validation loss: 1.784599829745549

Epoch: 5| Step: 5
Training loss: 1.1348549127578735
Validation loss: 1.7885527636415215

Epoch: 5| Step: 6
Training loss: 1.2238959074020386
Validation loss: 1.8114274381309428

Epoch: 5| Step: 7
Training loss: 1.3766109943389893
Validation loss: 1.7649502267119705

Epoch: 5| Step: 8
Training loss: 0.8654130697250366
Validation loss: 1.8280777149302985

Epoch: 5| Step: 9
Training loss: 1.3521771430969238
Validation loss: 1.7891354804397912

Epoch: 5| Step: 10
Training loss: 1.281931757926941
Validation loss: 1.7646892968044485

Epoch: 439| Step: 0
Training loss: 0.8531205058097839
Validation loss: 1.7802912753115419

Epoch: 5| Step: 1
Training loss: 2.3531603813171387
Validation loss: 1.81931019982984

Epoch: 5| Step: 2
Training loss: 1.0733896493911743
Validation loss: 1.8400416502388575

Epoch: 5| Step: 3
Training loss: 1.1107165813446045
Validation loss: 1.7816988947570964

Epoch: 5| Step: 4
Training loss: 0.7363389730453491
Validation loss: 1.7922111659921625

Epoch: 5| Step: 5
Training loss: 0.897335410118103
Validation loss: 1.7900482454607565

Epoch: 5| Step: 6
Training loss: 1.1384482383728027
Validation loss: 1.8209242692557714

Epoch: 5| Step: 7
Training loss: 1.3120931386947632
Validation loss: 1.7435936274067048

Epoch: 5| Step: 8
Training loss: 1.2231075763702393
Validation loss: 1.72851356767839

Epoch: 5| Step: 9
Training loss: 0.9615002870559692
Validation loss: 1.791099904685892

Epoch: 5| Step: 10
Training loss: 1.3356759548187256
Validation loss: 1.7752354375777706

Epoch: 440| Step: 0
Training loss: 1.1322318315505981
Validation loss: 1.8159137438702326

Epoch: 5| Step: 1
Training loss: 1.1930174827575684
Validation loss: 1.7514085667107695

Epoch: 5| Step: 2
Training loss: 1.0078495740890503
Validation loss: 1.817764587299798

Epoch: 5| Step: 3
Training loss: 0.9996057748794556
Validation loss: 1.743047994952048

Epoch: 5| Step: 4
Training loss: 1.1740983724594116
Validation loss: 1.8133605141793527

Epoch: 5| Step: 5
Training loss: 0.9877856373786926
Validation loss: 1.7625970609726445

Epoch: 5| Step: 6
Training loss: 1.4927483797073364
Validation loss: 1.739768374350763

Epoch: 5| Step: 7
Training loss: 1.085975170135498
Validation loss: 1.7811316751664685

Epoch: 5| Step: 8
Training loss: 0.9908877611160278
Validation loss: 1.7549300603969122

Epoch: 5| Step: 9
Training loss: 1.3806387186050415
Validation loss: 1.7546082529970395

Epoch: 5| Step: 10
Training loss: 1.4705129861831665
Validation loss: 1.8078148467566377

Epoch: 441| Step: 0
Training loss: 1.4047352075576782
Validation loss: 1.7551287822825934

Epoch: 5| Step: 1
Training loss: 1.2014563083648682
Validation loss: 1.7772094536853094

Epoch: 5| Step: 2
Training loss: 1.3832769393920898
Validation loss: 1.7937367462342786

Epoch: 5| Step: 3
Training loss: 1.411424160003662
Validation loss: 1.7503136947590818

Epoch: 5| Step: 4
Training loss: 0.8511580228805542
Validation loss: 1.8141582473631828

Epoch: 5| Step: 5
Training loss: 0.6938004493713379
Validation loss: 1.7988585246506559

Epoch: 5| Step: 6
Training loss: 1.887060523033142
Validation loss: 1.8079624791299143

Epoch: 5| Step: 7
Training loss: 0.9238373041152954
Validation loss: 1.7983931341478903

Epoch: 5| Step: 8
Training loss: 1.0501762628555298
Validation loss: 1.7287407587933283

Epoch: 5| Step: 9
Training loss: 1.1200522184371948
Validation loss: 1.806363146792176

Epoch: 5| Step: 10
Training loss: 0.9436055421829224
Validation loss: 1.8188623779563493

Epoch: 442| Step: 0
Training loss: 0.9675871729850769
Validation loss: 1.7887151754030617

Epoch: 5| Step: 1
Training loss: 1.1560028791427612
Validation loss: 1.7844843402985604

Epoch: 5| Step: 2
Training loss: 1.010151743888855
Validation loss: 1.8038581109816028

Epoch: 5| Step: 3
Training loss: 1.1682853698730469
Validation loss: 1.7893356110460015

Epoch: 5| Step: 4
Training loss: 1.156266689300537
Validation loss: 1.7615183271387571

Epoch: 5| Step: 5
Training loss: 0.6458078026771545
Validation loss: 1.8034708576817666

Epoch: 5| Step: 6
Training loss: 1.5089346170425415
Validation loss: 1.7802053689956665

Epoch: 5| Step: 7
Training loss: 1.654374122619629
Validation loss: 1.8442831782884495

Epoch: 5| Step: 8
Training loss: 0.8967658877372742
Validation loss: 1.7245445918011408

Epoch: 5| Step: 9
Training loss: 1.3433701992034912
Validation loss: 1.7491016118757186

Epoch: 5| Step: 10
Training loss: 1.5535520315170288
Validation loss: 1.7415389117374216

Epoch: 443| Step: 0
Training loss: 0.9126520156860352
Validation loss: 1.839703477838988

Epoch: 5| Step: 1
Training loss: 1.4089189767837524
Validation loss: 1.792393704896332

Epoch: 5| Step: 2
Training loss: 1.445349931716919
Validation loss: 1.8387240799524451

Epoch: 5| Step: 3
Training loss: 1.2274799346923828
Validation loss: 1.7602465332195323

Epoch: 5| Step: 4
Training loss: 1.5196356773376465
Validation loss: 1.7646832889126194

Epoch: 5| Step: 5
Training loss: 0.9284928441047668
Validation loss: 1.7671034848818215

Epoch: 5| Step: 6
Training loss: 0.9806812405586243
Validation loss: 1.7646403261410293

Epoch: 5| Step: 7
Training loss: 1.1795414686203003
Validation loss: 1.8222954555224347

Epoch: 5| Step: 8
Training loss: 0.974513828754425
Validation loss: 1.7596418293573524

Epoch: 5| Step: 9
Training loss: 1.2910007238388062
Validation loss: 1.7186167868234778

Epoch: 5| Step: 10
Training loss: 1.0268888473510742
Validation loss: 1.7785495506819857

Epoch: 444| Step: 0
Training loss: 1.5577366352081299
Validation loss: 1.7891963117866105

Epoch: 5| Step: 1
Training loss: 1.3388433456420898
Validation loss: 1.7565488892216836

Epoch: 5| Step: 2
Training loss: 0.6446918845176697
Validation loss: 1.7123092553948844

Epoch: 5| Step: 3
Training loss: 1.4294679164886475
Validation loss: 1.7700039007330453

Epoch: 5| Step: 4
Training loss: 0.8209860920906067
Validation loss: 1.7241708283783288

Epoch: 5| Step: 5
Training loss: 1.2713509798049927
Validation loss: 1.798978893346684

Epoch: 5| Step: 6
Training loss: 1.2169859409332275
Validation loss: 1.7470815502187258

Epoch: 5| Step: 7
Training loss: 1.2244364023208618
Validation loss: 1.857926704550302

Epoch: 5| Step: 8
Training loss: 1.2152382135391235
Validation loss: 1.7592189440163233

Epoch: 5| Step: 9
Training loss: 1.1597952842712402
Validation loss: 1.7286666029243059

Epoch: 5| Step: 10
Training loss: 0.940592348575592
Validation loss: 1.724183686317936

Epoch: 445| Step: 0
Training loss: 1.3395318984985352
Validation loss: 1.770971159781179

Epoch: 5| Step: 1
Training loss: 1.0196588039398193
Validation loss: 1.7631907757892404

Epoch: 5| Step: 2
Training loss: 1.1765683889389038
Validation loss: 1.7697701915617912

Epoch: 5| Step: 3
Training loss: 1.0879684686660767
Validation loss: 1.7263956710856447

Epoch: 5| Step: 4
Training loss: 1.7654693126678467
Validation loss: 1.7795475618813628

Epoch: 5| Step: 5
Training loss: 1.3332080841064453
Validation loss: 1.7372074486106954

Epoch: 5| Step: 6
Training loss: 1.1032021045684814
Validation loss: 1.806181275716392

Epoch: 5| Step: 7
Training loss: 1.079131007194519
Validation loss: 1.7558721201394194

Epoch: 5| Step: 8
Training loss: 0.8048204183578491
Validation loss: 1.8047698114507942

Epoch: 5| Step: 9
Training loss: 0.9671086072921753
Validation loss: 1.80113983667025

Epoch: 5| Step: 10
Training loss: 1.1890815496444702
Validation loss: 1.801448086256622

Epoch: 446| Step: 0
Training loss: 1.7287943363189697
Validation loss: 1.8068575461705525

Epoch: 5| Step: 1
Training loss: 1.2147157192230225
Validation loss: 1.8018190207019928

Epoch: 5| Step: 2
Training loss: 1.3121726512908936
Validation loss: 1.8812787276442333

Epoch: 5| Step: 3
Training loss: 0.7898398041725159
Validation loss: 1.7935414109178769

Epoch: 5| Step: 4
Training loss: 1.1617926359176636
Validation loss: 1.808341936398578

Epoch: 5| Step: 5
Training loss: 1.171588659286499
Validation loss: 1.8217680441435946

Epoch: 5| Step: 6
Training loss: 1.1280487775802612
Validation loss: 1.8189422565121804

Epoch: 5| Step: 7
Training loss: 1.170451045036316
Validation loss: 1.770969824124408

Epoch: 5| Step: 8
Training loss: 1.3371284008026123
Validation loss: 1.784655833757052

Epoch: 5| Step: 9
Training loss: 0.9470640420913696
Validation loss: 1.7427425025611796

Epoch: 5| Step: 10
Training loss: 0.84781414270401
Validation loss: 1.7559188360808997

Epoch: 447| Step: 0
Training loss: 0.7924407124519348
Validation loss: 1.7707682758249261

Epoch: 5| Step: 1
Training loss: 1.156788945198059
Validation loss: 1.741060435131032

Epoch: 5| Step: 2
Training loss: 1.0999376773834229
Validation loss: 1.7751264828507618

Epoch: 5| Step: 3
Training loss: 1.4030437469482422
Validation loss: 1.8022108616367463

Epoch: 5| Step: 4
Training loss: 1.1292855739593506
Validation loss: 1.750861733190475

Epoch: 5| Step: 5
Training loss: 1.367571234703064
Validation loss: 1.8060893525359452

Epoch: 5| Step: 6
Training loss: 1.4033873081207275
Validation loss: 1.771404957258573

Epoch: 5| Step: 7
Training loss: 1.1112072467803955
Validation loss: 1.767013334458874

Epoch: 5| Step: 8
Training loss: 0.9578289985656738
Validation loss: 1.772850190439532

Epoch: 5| Step: 9
Training loss: 0.8740518689155579
Validation loss: 1.743869189293154

Epoch: 5| Step: 10
Training loss: 1.4329551458358765
Validation loss: 1.8143195183046403

Epoch: 448| Step: 0
Training loss: 1.134256362915039
Validation loss: 1.7812654613166727

Epoch: 5| Step: 1
Training loss: 0.942906379699707
Validation loss: 1.7956785719881776

Epoch: 5| Step: 2
Training loss: 1.5067343711853027
Validation loss: 1.7700077385030768

Epoch: 5| Step: 3
Training loss: 1.0762081146240234
Validation loss: 1.750589475836805

Epoch: 5| Step: 4
Training loss: 1.1916186809539795
Validation loss: 1.8147004060847785

Epoch: 5| Step: 5
Training loss: 1.027459979057312
Validation loss: 1.8413684778316046

Epoch: 5| Step: 6
Training loss: 1.2024999856948853
Validation loss: 1.7687615989356913

Epoch: 5| Step: 7
Training loss: 1.266509771347046
Validation loss: 1.7912948951926282

Epoch: 5| Step: 8
Training loss: 1.2149384021759033
Validation loss: 1.8111875569948586

Epoch: 5| Step: 9
Training loss: 1.216395378112793
Validation loss: 1.765225492497926

Epoch: 5| Step: 10
Training loss: 0.8831789493560791
Validation loss: 1.8030550467070712

Epoch: 449| Step: 0
Training loss: 0.9315899014472961
Validation loss: 1.799704695260653

Epoch: 5| Step: 1
Training loss: 0.902391791343689
Validation loss: 1.8017523814273138

Epoch: 5| Step: 2
Training loss: 1.5806713104248047
Validation loss: 1.7635155967486802

Epoch: 5| Step: 3
Training loss: 1.0412864685058594
Validation loss: 1.753888104551582

Epoch: 5| Step: 4
Training loss: 0.7730918526649475
Validation loss: 1.801944737793297

Epoch: 5| Step: 5
Training loss: 1.2613861560821533
Validation loss: 1.7330107714540215

Epoch: 5| Step: 6
Training loss: 1.3660218715667725
Validation loss: 1.817527885078102

Epoch: 5| Step: 7
Training loss: 1.5482332706451416
Validation loss: 1.75687365634467

Epoch: 5| Step: 8
Training loss: 1.1658403873443604
Validation loss: 1.773322787336124

Epoch: 5| Step: 9
Training loss: 1.095126986503601
Validation loss: 1.7976939550010107

Epoch: 5| Step: 10
Training loss: 1.0792372226715088
Validation loss: 1.7658906162426036

Epoch: 450| Step: 0
Training loss: 1.2297505140304565
Validation loss: 1.7125763995673067

Epoch: 5| Step: 1
Training loss: 1.2152392864227295
Validation loss: 1.7784097297217256

Epoch: 5| Step: 2
Training loss: 0.8440324664115906
Validation loss: 1.757851941611177

Epoch: 5| Step: 3
Training loss: 1.1903197765350342
Validation loss: 1.7940395750025266

Epoch: 5| Step: 4
Training loss: 0.7573608160018921
Validation loss: 1.8084628094909012

Epoch: 5| Step: 5
Training loss: 0.6270249485969543
Validation loss: 1.7964309838510328

Epoch: 5| Step: 6
Training loss: 1.045969009399414
Validation loss: 1.762834483577359

Epoch: 5| Step: 7
Training loss: 1.4991521835327148
Validation loss: 1.7912902396212342

Epoch: 5| Step: 8
Training loss: 1.3570215702056885
Validation loss: 1.7785209250706497

Epoch: 5| Step: 9
Training loss: 1.7204811573028564
Validation loss: 1.7390196861759308

Epoch: 5| Step: 10
Training loss: 1.2785266637802124
Validation loss: 1.7959614287140548

Epoch: 451| Step: 0
Training loss: 1.8370676040649414
Validation loss: 1.7711980688956477

Epoch: 5| Step: 1
Training loss: 1.1701164245605469
Validation loss: 1.7383722105333883

Epoch: 5| Step: 2
Training loss: 0.8367586135864258
Validation loss: 1.7473658079742103

Epoch: 5| Step: 3
Training loss: 0.995661735534668
Validation loss: 1.8055642574064192

Epoch: 5| Step: 4
Training loss: 1.0682504177093506
Validation loss: 1.7628799843531784

Epoch: 5| Step: 5
Training loss: 0.9078761339187622
Validation loss: 1.7747271163489229

Epoch: 5| Step: 6
Training loss: 1.3341166973114014
Validation loss: 1.7666001589067521

Epoch: 5| Step: 7
Training loss: 0.8188160061836243
Validation loss: 1.8122812189081663

Epoch: 5| Step: 8
Training loss: 1.1777417659759521
Validation loss: 1.8560398791425972

Epoch: 5| Step: 9
Training loss: 0.841131329536438
Validation loss: 1.7447322145585091

Epoch: 5| Step: 10
Training loss: 1.469247579574585
Validation loss: 1.7433884336102394

Epoch: 452| Step: 0
Training loss: 1.1279125213623047
Validation loss: 1.7303379607456986

Epoch: 5| Step: 1
Training loss: 1.3825585842132568
Validation loss: 1.7763543680150022

Epoch: 5| Step: 2
Training loss: 1.101036787033081
Validation loss: 1.7759478553648917

Epoch: 5| Step: 3
Training loss: 1.3761205673217773
Validation loss: 1.7868006396037277

Epoch: 5| Step: 4
Training loss: 1.1392672061920166
Validation loss: 1.7606758584258377

Epoch: 5| Step: 5
Training loss: 1.2475090026855469
Validation loss: 1.7679882164924376

Epoch: 5| Step: 6
Training loss: 1.1359156370162964
Validation loss: 1.7474439887590305

Epoch: 5| Step: 7
Training loss: 1.0050303936004639
Validation loss: 1.783516828731824

Epoch: 5| Step: 8
Training loss: 1.1156753301620483
Validation loss: 1.7450604105508456

Epoch: 5| Step: 9
Training loss: 1.0380407571792603
Validation loss: 1.8024922288874143

Epoch: 5| Step: 10
Training loss: 1.0608738660812378
Validation loss: 1.7305735195836713

Epoch: 453| Step: 0
Training loss: 1.2511425018310547
Validation loss: 1.7170295074421873

Epoch: 5| Step: 1
Training loss: 0.8540997505187988
Validation loss: 1.7545747346775507

Epoch: 5| Step: 2
Training loss: 1.3183372020721436
Validation loss: 1.7687828386983564

Epoch: 5| Step: 3
Training loss: 1.2710222005844116
Validation loss: 1.779326231248917

Epoch: 5| Step: 4
Training loss: 1.0712687969207764
Validation loss: 1.7620343533895348

Epoch: 5| Step: 5
Training loss: 0.9619334936141968
Validation loss: 1.7905883250697967

Epoch: 5| Step: 6
Training loss: 0.9318952560424805
Validation loss: 1.7608861756581131

Epoch: 5| Step: 7
Training loss: 1.3019739389419556
Validation loss: 1.7794545299263411

Epoch: 5| Step: 8
Training loss: 1.6360561847686768
Validation loss: 1.739383792364469

Epoch: 5| Step: 9
Training loss: 0.6305957436561584
Validation loss: 1.794541323056785

Epoch: 5| Step: 10
Training loss: 1.1976412534713745
Validation loss: 1.77781448312985

Epoch: 454| Step: 0
Training loss: 1.1255040168762207
Validation loss: 1.819266135974597

Epoch: 5| Step: 1
Training loss: 0.9208528399467468
Validation loss: 1.800607273655553

Epoch: 5| Step: 2
Training loss: 1.0284608602523804
Validation loss: 1.7542633433495798

Epoch: 5| Step: 3
Training loss: 1.0444854497909546
Validation loss: 1.7604246331799416

Epoch: 5| Step: 4
Training loss: 1.1142723560333252
Validation loss: 1.732659484750481

Epoch: 5| Step: 5
Training loss: 0.9833160638809204
Validation loss: 1.7308238885735954

Epoch: 5| Step: 6
Training loss: 1.296026587486267
Validation loss: 1.7222043211742113

Epoch: 5| Step: 7
Training loss: 1.210714340209961
Validation loss: 1.725329513190895

Epoch: 5| Step: 8
Training loss: 0.8739937543869019
Validation loss: 1.7576274512916483

Epoch: 5| Step: 9
Training loss: 1.3825428485870361
Validation loss: 1.7699897109821279

Epoch: 5| Step: 10
Training loss: 1.7173012495040894
Validation loss: 1.7441665293068014

Epoch: 455| Step: 0
Training loss: 1.0669171810150146
Validation loss: 1.7874164042934295

Epoch: 5| Step: 1
Training loss: 1.393892526626587
Validation loss: 1.7783224377580868

Epoch: 5| Step: 2
Training loss: 1.0634963512420654
Validation loss: 1.7197266855547506

Epoch: 5| Step: 3
Training loss: 0.9828587770462036
Validation loss: 1.7893853123470018

Epoch: 5| Step: 4
Training loss: 1.356076717376709
Validation loss: 1.7659001478584864

Epoch: 5| Step: 5
Training loss: 1.2420300245285034
Validation loss: 1.7545084517489198

Epoch: 5| Step: 6
Training loss: 1.3838655948638916
Validation loss: 1.8182122912458194

Epoch: 5| Step: 7
Training loss: 0.8829919695854187
Validation loss: 1.8137896548035324

Epoch: 5| Step: 8
Training loss: 1.0500538349151611
Validation loss: 1.752391484475905

Epoch: 5| Step: 9
Training loss: 0.9389246702194214
Validation loss: 1.7737246431330198

Epoch: 5| Step: 10
Training loss: 0.9650558233261108
Validation loss: 1.8307169816827262

Epoch: 456| Step: 0
Training loss: 1.0403645038604736
Validation loss: 1.735345760981242

Epoch: 5| Step: 1
Training loss: 1.1209938526153564
Validation loss: 1.7926377429757068

Epoch: 5| Step: 2
Training loss: 1.0100877285003662
Validation loss: 1.7761295149403233

Epoch: 5| Step: 3
Training loss: 0.9892569780349731
Validation loss: 1.7596473937393518

Epoch: 5| Step: 4
Training loss: 1.3329885005950928
Validation loss: 1.8078298299543318

Epoch: 5| Step: 5
Training loss: 0.8450732231140137
Validation loss: 1.7968962859081965

Epoch: 5| Step: 6
Training loss: 1.1712133884429932
Validation loss: 1.761236003650132

Epoch: 5| Step: 7
Training loss: 1.4088634252548218
Validation loss: 1.7968659093303065

Epoch: 5| Step: 8
Training loss: 1.2865594625473022
Validation loss: 1.7413655596394693

Epoch: 5| Step: 9
Training loss: 1.2352626323699951
Validation loss: 1.763528682852304

Epoch: 5| Step: 10
Training loss: 1.4185845851898193
Validation loss: 1.7418447053560646

Epoch: 457| Step: 0
Training loss: 1.232216715812683
Validation loss: 1.7353175724706342

Epoch: 5| Step: 1
Training loss: 1.019598126411438
Validation loss: 1.7887243788729432

Epoch: 5| Step: 2
Training loss: 0.7956938147544861
Validation loss: 1.8194964778038762

Epoch: 5| Step: 3
Training loss: 1.4095518589019775
Validation loss: 1.760390632896013

Epoch: 5| Step: 4
Training loss: 0.9708393216133118
Validation loss: 1.7969293773815196

Epoch: 5| Step: 5
Training loss: 1.2440180778503418
Validation loss: 1.7590463110195693

Epoch: 5| Step: 6
Training loss: 1.612768530845642
Validation loss: 1.7812841797387728

Epoch: 5| Step: 7
Training loss: 1.4097061157226562
Validation loss: 1.8368887503941853

Epoch: 5| Step: 8
Training loss: 0.9967001080513
Validation loss: 1.7944320119837278

Epoch: 5| Step: 9
Training loss: 0.8854429125785828
Validation loss: 1.7775787871371034

Epoch: 5| Step: 10
Training loss: 1.0837574005126953
Validation loss: 1.806027397032707

Epoch: 458| Step: 0
Training loss: 0.984056830406189
Validation loss: 1.765010582503452

Epoch: 5| Step: 1
Training loss: 1.178800106048584
Validation loss: 1.7778639139667634

Epoch: 5| Step: 2
Training loss: 1.135904312133789
Validation loss: 1.813227976522138

Epoch: 5| Step: 3
Training loss: 1.5937190055847168
Validation loss: 1.7898854388985583

Epoch: 5| Step: 4
Training loss: 0.8265191316604614
Validation loss: 1.7739085176939606

Epoch: 5| Step: 5
Training loss: 1.6880779266357422
Validation loss: 1.816436964978454

Epoch: 5| Step: 6
Training loss: 0.9148966073989868
Validation loss: 1.792102990611907

Epoch: 5| Step: 7
Training loss: 0.9477590322494507
Validation loss: 1.738992767949258

Epoch: 5| Step: 8
Training loss: 1.0394090414047241
Validation loss: 1.771585141458819

Epoch: 5| Step: 9
Training loss: 0.8251792192459106
Validation loss: 1.8048928027511926

Epoch: 5| Step: 10
Training loss: 1.2994718551635742
Validation loss: 1.802095813135947

Epoch: 459| Step: 0
Training loss: 1.59955894947052
Validation loss: 1.7806220182808496

Epoch: 5| Step: 1
Training loss: 1.2946927547454834
Validation loss: 1.7673349547129806

Epoch: 5| Step: 2
Training loss: 0.9621542692184448
Validation loss: 1.7903674007743917

Epoch: 5| Step: 3
Training loss: 1.2016866207122803
Validation loss: 1.7859489911346025

Epoch: 5| Step: 4
Training loss: 1.0101722478866577
Validation loss: 1.7010584877383323

Epoch: 5| Step: 5
Training loss: 1.2115380764007568
Validation loss: 1.7870356421316824

Epoch: 5| Step: 6
Training loss: 1.0680081844329834
Validation loss: 1.7464748210804437

Epoch: 5| Step: 7
Training loss: 0.7694154381752014
Validation loss: 1.7551381690527803

Epoch: 5| Step: 8
Training loss: 1.2700825929641724
Validation loss: 1.7803602372446368

Epoch: 5| Step: 9
Training loss: 1.1615490913391113
Validation loss: 1.7484375212782173

Epoch: 5| Step: 10
Training loss: 0.6990482211112976
Validation loss: 1.8270941267731369

Epoch: 460| Step: 0
Training loss: 1.170727014541626
Validation loss: 1.810484915651301

Epoch: 5| Step: 1
Training loss: 1.214856505393982
Validation loss: 1.8468965753432243

Epoch: 5| Step: 2
Training loss: 1.0556151866912842
Validation loss: 1.7869582983755297

Epoch: 5| Step: 3
Training loss: 1.2567675113677979
Validation loss: 1.7919915132625128

Epoch: 5| Step: 4
Training loss: 0.5594242811203003
Validation loss: 1.7792494438027824

Epoch: 5| Step: 5
Training loss: 1.2006293535232544
Validation loss: 1.7524731441210675

Epoch: 5| Step: 6
Training loss: 1.25858473777771
Validation loss: 1.8220355536348076

Epoch: 5| Step: 7
Training loss: 0.7979721426963806
Validation loss: 1.7512998298932148

Epoch: 5| Step: 8
Training loss: 0.8362678289413452
Validation loss: 1.7771755828652331

Epoch: 5| Step: 9
Training loss: 1.1040682792663574
Validation loss: 1.7409390826379099

Epoch: 5| Step: 10
Training loss: 1.9662104845046997
Validation loss: 1.7846366256795905

Epoch: 461| Step: 0
Training loss: 0.6838877201080322
Validation loss: 1.7500979413268387

Epoch: 5| Step: 1
Training loss: 1.1291439533233643
Validation loss: 1.74896538770327

Epoch: 5| Step: 2
Training loss: 1.1793140172958374
Validation loss: 1.7369362532451589

Epoch: 5| Step: 3
Training loss: 0.711203396320343
Validation loss: 1.7785139160771524

Epoch: 5| Step: 4
Training loss: 0.9981053471565247
Validation loss: 1.7029029271935905

Epoch: 5| Step: 5
Training loss: 1.3420034646987915
Validation loss: 1.7427967209969797

Epoch: 5| Step: 6
Training loss: 1.8550630807876587
Validation loss: 1.7836338063722015

Epoch: 5| Step: 7
Training loss: 1.1742088794708252
Validation loss: 1.8002980652675833

Epoch: 5| Step: 8
Training loss: 1.5154056549072266
Validation loss: 1.7804037922172136

Epoch: 5| Step: 9
Training loss: 0.8984540104866028
Validation loss: 1.7657003312982538

Epoch: 5| Step: 10
Training loss: 0.6176463961601257
Validation loss: 1.7917752983749553

Epoch: 462| Step: 0
Training loss: 1.2084230184555054
Validation loss: 1.8006404446017357

Epoch: 5| Step: 1
Training loss: 1.1218513250350952
Validation loss: 1.7251410330495527

Epoch: 5| Step: 2
Training loss: 0.8010318875312805
Validation loss: 1.8233392802617883

Epoch: 5| Step: 3
Training loss: 1.9958255290985107
Validation loss: 1.8100875269982122

Epoch: 5| Step: 4
Training loss: 1.1742819547653198
Validation loss: 1.8291474183400471

Epoch: 5| Step: 5
Training loss: 1.3251590728759766
Validation loss: 1.7395542090938938

Epoch: 5| Step: 6
Training loss: 0.8128490447998047
Validation loss: 1.8058184795482184

Epoch: 5| Step: 7
Training loss: 1.1455049514770508
Validation loss: 1.8004196933520737

Epoch: 5| Step: 8
Training loss: 0.9984022378921509
Validation loss: 1.7450664735609485

Epoch: 5| Step: 9
Training loss: 0.941012978553772
Validation loss: 1.7321203395884524

Epoch: 5| Step: 10
Training loss: 0.7700209617614746
Validation loss: 1.7893202407385713

Epoch: 463| Step: 0
Training loss: 1.0884859561920166
Validation loss: 1.772611564205539

Epoch: 5| Step: 1
Training loss: 1.6863733530044556
Validation loss: 1.800901484745805

Epoch: 5| Step: 2
Training loss: 0.7453063130378723
Validation loss: 1.8032999577060822

Epoch: 5| Step: 3
Training loss: 1.0090094804763794
Validation loss: 1.744869550069173

Epoch: 5| Step: 4
Training loss: 0.9851852655410767
Validation loss: 1.748193262725748

Epoch: 5| Step: 5
Training loss: 0.7925158739089966
Validation loss: 1.78584276476214

Epoch: 5| Step: 6
Training loss: 1.0817821025848389
Validation loss: 1.8000162070797336

Epoch: 5| Step: 7
Training loss: 1.6591440439224243
Validation loss: 1.7613284011040964

Epoch: 5| Step: 8
Training loss: 1.070065975189209
Validation loss: 1.7373457698411838

Epoch: 5| Step: 9
Training loss: 1.2918643951416016
Validation loss: 1.8064534523153817

Epoch: 5| Step: 10
Training loss: 1.0012942552566528
Validation loss: 1.754604922827854

Epoch: 464| Step: 0
Training loss: 0.9966257810592651
Validation loss: 1.7136026095318537

Epoch: 5| Step: 1
Training loss: 1.7229769229888916
Validation loss: 1.7696433426231466

Epoch: 5| Step: 2
Training loss: 0.8834869265556335
Validation loss: 1.75827536659856

Epoch: 5| Step: 3
Training loss: 1.0454955101013184
Validation loss: 1.788940063086889

Epoch: 5| Step: 4
Training loss: 0.8461783528327942
Validation loss: 1.789362294699556

Epoch: 5| Step: 5
Training loss: 1.2855396270751953
Validation loss: 1.7759435907486947

Epoch: 5| Step: 6
Training loss: 1.4288761615753174
Validation loss: 1.7481134809473509

Epoch: 5| Step: 7
Training loss: 0.7691870927810669
Validation loss: 1.7476566273679015

Epoch: 5| Step: 8
Training loss: 1.562086582183838
Validation loss: 1.7681139399928432

Epoch: 5| Step: 9
Training loss: 1.3219149112701416
Validation loss: 1.7427339823015275

Epoch: 5| Step: 10
Training loss: 0.7483804225921631
Validation loss: 1.7619094733268983

Epoch: 465| Step: 0
Training loss: 1.1882439851760864
Validation loss: 1.792360310913414

Epoch: 5| Step: 1
Training loss: 0.670696496963501
Validation loss: 1.747862954293528

Epoch: 5| Step: 2
Training loss: 0.8304895162582397
Validation loss: 1.7540203755901707

Epoch: 5| Step: 3
Training loss: 1.5101864337921143
Validation loss: 1.772945301507109

Epoch: 5| Step: 4
Training loss: 0.8159712553024292
Validation loss: 1.8025460384225334

Epoch: 5| Step: 5
Training loss: 1.2425196170806885
Validation loss: 1.7629096956663235

Epoch: 5| Step: 6
Training loss: 1.3280514478683472
Validation loss: 1.7281648548700477

Epoch: 5| Step: 7
Training loss: 1.2058298587799072
Validation loss: 1.8199984873494794

Epoch: 5| Step: 8
Training loss: 1.2656505107879639
Validation loss: 1.7638825703692693

Epoch: 5| Step: 9
Training loss: 1.2272613048553467
Validation loss: 1.7784962551568144

Epoch: 5| Step: 10
Training loss: 1.3152191638946533
Validation loss: 1.7748991071536977

Epoch: 466| Step: 0
Training loss: 1.2261979579925537
Validation loss: 1.7527998121835853

Epoch: 5| Step: 1
Training loss: 1.0785318613052368
Validation loss: 1.7685887980204757

Epoch: 5| Step: 2
Training loss: 0.9808185696601868
Validation loss: 1.7956250970081618

Epoch: 5| Step: 3
Training loss: 1.5221525430679321
Validation loss: 1.7612893312208113

Epoch: 5| Step: 4
Training loss: 1.3447452783584595
Validation loss: 1.7610854884629608

Epoch: 5| Step: 5
Training loss: 0.7534273266792297
Validation loss: 1.7517418951116583

Epoch: 5| Step: 6
Training loss: 1.1331181526184082
Validation loss: 1.7516009564040809

Epoch: 5| Step: 7
Training loss: 1.131859540939331
Validation loss: 1.761827895718236

Epoch: 5| Step: 8
Training loss: 0.9823943972587585
Validation loss: 1.7534801793354813

Epoch: 5| Step: 9
Training loss: 1.237733006477356
Validation loss: 1.7864741202323668

Epoch: 5| Step: 10
Training loss: 1.2091304063796997
Validation loss: 1.730829010727585

Epoch: 467| Step: 0
Training loss: 1.0875072479248047
Validation loss: 1.7554628669574697

Epoch: 5| Step: 1
Training loss: 0.9839679002761841
Validation loss: 1.8373723824818928

Epoch: 5| Step: 2
Training loss: 0.9008702039718628
Validation loss: 1.7676612715567313

Epoch: 5| Step: 3
Training loss: 1.226530909538269
Validation loss: 1.7579697139801518

Epoch: 5| Step: 4
Training loss: 1.7052924633026123
Validation loss: 1.7674689779999435

Epoch: 5| Step: 5
Training loss: 1.185248851776123
Validation loss: 1.8264740385035032

Epoch: 5| Step: 6
Training loss: 1.2401736974716187
Validation loss: 1.8433012936704902

Epoch: 5| Step: 7
Training loss: 1.0679851770401
Validation loss: 1.8077420239807458

Epoch: 5| Step: 8
Training loss: 0.9333851933479309
Validation loss: 1.8338429427916003

Epoch: 5| Step: 9
Training loss: 0.9021139144897461
Validation loss: 1.7590553222164031

Epoch: 5| Step: 10
Training loss: 1.2368413209915161
Validation loss: 1.7531484403917867

Epoch: 468| Step: 0
Training loss: 0.9968295097351074
Validation loss: 1.810890861736831

Epoch: 5| Step: 1
Training loss: 1.15985107421875
Validation loss: 1.8428411381219023

Epoch: 5| Step: 2
Training loss: 1.3079828023910522
Validation loss: 1.805146259646262

Epoch: 5| Step: 3
Training loss: 1.2251718044281006
Validation loss: 1.7975336582429948

Epoch: 5| Step: 4
Training loss: 1.206284523010254
Validation loss: 1.768979400716802

Epoch: 5| Step: 5
Training loss: 1.1368753910064697
Validation loss: 1.8038102478109381

Epoch: 5| Step: 6
Training loss: 1.326215386390686
Validation loss: 1.750586719923122

Epoch: 5| Step: 7
Training loss: 1.4761135578155518
Validation loss: 1.7341573443464053

Epoch: 5| Step: 8
Training loss: 0.7641423344612122
Validation loss: 1.7507408395890267

Epoch: 5| Step: 9
Training loss: 0.9028469920158386
Validation loss: 1.740807355091136

Epoch: 5| Step: 10
Training loss: 0.7488046884536743
Validation loss: 1.8147634793353338

Epoch: 469| Step: 0
Training loss: 1.09915292263031
Validation loss: 1.7758563615942513

Epoch: 5| Step: 1
Training loss: 1.3780131340026855
Validation loss: 1.8054927292690481

Epoch: 5| Step: 2
Training loss: 0.9503194689750671
Validation loss: 1.7816965426168134

Epoch: 5| Step: 3
Training loss: 0.7949350476264954
Validation loss: 1.742743061434838

Epoch: 5| Step: 4
Training loss: 0.9814985394477844
Validation loss: 1.7991177510189753

Epoch: 5| Step: 5
Training loss: 1.4721778631210327
Validation loss: 1.8247617765139508

Epoch: 5| Step: 6
Training loss: 0.921887218952179
Validation loss: 1.7646991706663562

Epoch: 5| Step: 7
Training loss: 1.2764861583709717
Validation loss: 1.7450767665781

Epoch: 5| Step: 8
Training loss: 1.4163148403167725
Validation loss: 1.7764964962518344

Epoch: 5| Step: 9
Training loss: 1.2567218542099
Validation loss: 1.7414251578751432

Epoch: 5| Step: 10
Training loss: 0.8496785163879395
Validation loss: 1.7365252869103545

Epoch: 470| Step: 0
Training loss: 0.9888145327568054
Validation loss: 1.7593490257058093

Epoch: 5| Step: 1
Training loss: 1.5435174703598022
Validation loss: 1.755748805820301

Epoch: 5| Step: 2
Training loss: 0.8263975977897644
Validation loss: 1.7461422399808002

Epoch: 5| Step: 3
Training loss: 1.0046685934066772
Validation loss: 1.7208524557851976

Epoch: 5| Step: 4
Training loss: 1.2853891849517822
Validation loss: 1.7377727300890031

Epoch: 5| Step: 5
Training loss: 0.559674859046936
Validation loss: 1.7597174849561465

Epoch: 5| Step: 6
Training loss: 0.7115853428840637
Validation loss: 1.7083010135158416

Epoch: 5| Step: 7
Training loss: 0.8157231211662292
Validation loss: 1.8080480534543273

Epoch: 5| Step: 8
Training loss: 1.6235402822494507
Validation loss: 1.7668032902543263

Epoch: 5| Step: 9
Training loss: 1.411837100982666
Validation loss: 1.7497402480853501

Epoch: 5| Step: 10
Training loss: 1.5181612968444824
Validation loss: 1.8106234278730167

Epoch: 471| Step: 0
Training loss: 1.1042125225067139
Validation loss: 1.7921645897690968

Epoch: 5| Step: 1
Training loss: 1.0188522338867188
Validation loss: 1.7802930685781664

Epoch: 5| Step: 2
Training loss: 1.4418320655822754
Validation loss: 1.7780314171186058

Epoch: 5| Step: 3
Training loss: 1.0267127752304077
Validation loss: 1.7145971380254275

Epoch: 5| Step: 4
Training loss: 1.1835845708847046
Validation loss: 1.7442325981714393

Epoch: 5| Step: 5
Training loss: 1.1897937059402466
Validation loss: 1.7893705329587382

Epoch: 5| Step: 6
Training loss: 1.0820856094360352
Validation loss: 1.7516638707089167

Epoch: 5| Step: 7
Training loss: 0.669049084186554
Validation loss: 1.8061468421771962

Epoch: 5| Step: 8
Training loss: 0.882541298866272
Validation loss: 1.7573029501463777

Epoch: 5| Step: 9
Training loss: 1.0055230855941772
Validation loss: 1.7784570673460602

Epoch: 5| Step: 10
Training loss: 1.5308785438537598
Validation loss: 1.7920963700099657

Epoch: 472| Step: 0
Training loss: 0.8843868374824524
Validation loss: 1.7392404874165852

Epoch: 5| Step: 1
Training loss: 0.7577909231185913
Validation loss: 1.7717477685661727

Epoch: 5| Step: 2
Training loss: 1.3971717357635498
Validation loss: 1.7830770143898584

Epoch: 5| Step: 3
Training loss: 0.8008729815483093
Validation loss: 1.727245597429173

Epoch: 5| Step: 4
Training loss: 1.1192811727523804
Validation loss: 1.7592697092281875

Epoch: 5| Step: 5
Training loss: 1.5200161933898926
Validation loss: 1.764879486894095

Epoch: 5| Step: 6
Training loss: 1.071701169013977
Validation loss: 1.7298652125943093

Epoch: 5| Step: 7
Training loss: 1.0390114784240723
Validation loss: 1.7618205713969406

Epoch: 5| Step: 8
Training loss: 0.9897263646125793
Validation loss: 1.7818370660146077

Epoch: 5| Step: 9
Training loss: 1.3316987752914429
Validation loss: 1.7505578879387147

Epoch: 5| Step: 10
Training loss: 0.9417191743850708
Validation loss: 1.829721208541624

Epoch: 473| Step: 0
Training loss: 1.23604416847229
Validation loss: 1.8092011149211595

Epoch: 5| Step: 1
Training loss: 1.4328880310058594
Validation loss: 1.8394391331621396

Epoch: 5| Step: 2
Training loss: 1.1202894449234009
Validation loss: 1.7701765785935104

Epoch: 5| Step: 3
Training loss: 1.588564157485962
Validation loss: 1.7806018860109392

Epoch: 5| Step: 4
Training loss: 0.8463941812515259
Validation loss: 1.733651323985028

Epoch: 5| Step: 5
Training loss: 0.9513174295425415
Validation loss: 1.791147626856322

Epoch: 5| Step: 6
Training loss: 0.6426142454147339
Validation loss: 1.6767950416893087

Epoch: 5| Step: 7
Training loss: 1.0379374027252197
Validation loss: 1.7884001885690997

Epoch: 5| Step: 8
Training loss: 1.2827726602554321
Validation loss: 1.7557427652420536

Epoch: 5| Step: 9
Training loss: 0.8321644067764282
Validation loss: 1.8140068067017423

Epoch: 5| Step: 10
Training loss: 0.7927417159080505
Validation loss: 1.8165153047089935

Epoch: 474| Step: 0
Training loss: 0.9788745045661926
Validation loss: 1.7537125964318552

Epoch: 5| Step: 1
Training loss: 1.1261205673217773
Validation loss: 1.7466359490989356

Epoch: 5| Step: 2
Training loss: 0.736096203327179
Validation loss: 1.7898168204933085

Epoch: 5| Step: 3
Training loss: 1.892587423324585
Validation loss: 1.7587577976206297

Epoch: 5| Step: 4
Training loss: 1.5074443817138672
Validation loss: 1.8120438078398347

Epoch: 5| Step: 5
Training loss: 1.3586235046386719
Validation loss: 1.7945177670448058

Epoch: 5| Step: 6
Training loss: 0.9800499081611633
Validation loss: 1.8197960135757283

Epoch: 5| Step: 7
Training loss: 0.8774183392524719
Validation loss: 1.7812743802224436

Epoch: 5| Step: 8
Training loss: 0.6403476595878601
Validation loss: 1.8210272237818728

Epoch: 5| Step: 9
Training loss: 0.8786450624465942
Validation loss: 1.720642424398853

Epoch: 5| Step: 10
Training loss: 1.1852794885635376
Validation loss: 1.7123700944326257

Epoch: 475| Step: 0
Training loss: 1.2615104913711548
Validation loss: 1.8087570731357863

Epoch: 5| Step: 1
Training loss: 1.2955042123794556
Validation loss: 1.7551405545203917

Epoch: 5| Step: 2
Training loss: 0.9857913851737976
Validation loss: 1.7747588260199434

Epoch: 5| Step: 3
Training loss: 1.3719549179077148
Validation loss: 1.7519991115857196

Epoch: 5| Step: 4
Training loss: 1.1562062501907349
Validation loss: 1.7718759993071198

Epoch: 5| Step: 5
Training loss: 1.0357953310012817
Validation loss: 1.7360338587914743

Epoch: 5| Step: 6
Training loss: 0.7822575569152832
Validation loss: 1.722331577731717

Epoch: 5| Step: 7
Training loss: 1.0623143911361694
Validation loss: 1.8186607258294218

Epoch: 5| Step: 8
Training loss: 0.9379218220710754
Validation loss: 1.7586946102880663

Epoch: 5| Step: 9
Training loss: 0.9056908488273621
Validation loss: 1.828604503344464

Epoch: 5| Step: 10
Training loss: 1.3594456911087036
Validation loss: 1.770494532841508

Epoch: 476| Step: 0
Training loss: 0.9377080202102661
Validation loss: 1.8275558999789658

Epoch: 5| Step: 1
Training loss: 1.2819827795028687
Validation loss: 1.816432540134717

Epoch: 5| Step: 2
Training loss: 1.1114709377288818
Validation loss: 1.8077846316881077

Epoch: 5| Step: 3
Training loss: 1.3626272678375244
Validation loss: 1.8237529031692012

Epoch: 5| Step: 4
Training loss: 1.1595538854599
Validation loss: 1.7909537361514183

Epoch: 5| Step: 5
Training loss: 1.5246336460113525
Validation loss: 1.7981302161370554

Epoch: 5| Step: 6
Training loss: 1.0555284023284912
Validation loss: 1.758027550994709

Epoch: 5| Step: 7
Training loss: 0.9676579236984253
Validation loss: 1.8724126187703942

Epoch: 5| Step: 8
Training loss: 0.6883417367935181
Validation loss: 1.7921462930658811

Epoch: 5| Step: 9
Training loss: 1.3461157083511353
Validation loss: 1.6932262220690328

Epoch: 5| Step: 10
Training loss: 0.9357771873474121
Validation loss: 1.7571293115615845

Epoch: 477| Step: 0
Training loss: 1.3038263320922852
Validation loss: 1.71191753110578

Epoch: 5| Step: 1
Training loss: 0.83311527967453
Validation loss: 1.8053234572051673

Epoch: 5| Step: 2
Training loss: 0.9401003122329712
Validation loss: 1.7482375508995467

Epoch: 5| Step: 3
Training loss: 1.1445006132125854
Validation loss: 1.7826478455656318

Epoch: 5| Step: 4
Training loss: 0.9680892825126648
Validation loss: 1.753586446085284

Epoch: 5| Step: 5
Training loss: 1.0661617517471313
Validation loss: 1.7248673144207205

Epoch: 5| Step: 6
Training loss: 1.0219403505325317
Validation loss: 1.8268822880201443

Epoch: 5| Step: 7
Training loss: 1.480924129486084
Validation loss: 1.793657959148448

Epoch: 5| Step: 8
Training loss: 0.8636035919189453
Validation loss: 1.76878232853387

Epoch: 5| Step: 9
Training loss: 1.4883949756622314
Validation loss: 1.749256585233955

Epoch: 5| Step: 10
Training loss: 0.826808512210846
Validation loss: 1.7638498749784244

Epoch: 478| Step: 0
Training loss: 1.1212093830108643
Validation loss: 1.772848463827564

Epoch: 5| Step: 1
Training loss: 1.1075643301010132
Validation loss: 1.808257406757724

Epoch: 5| Step: 2
Training loss: 1.270461916923523
Validation loss: 1.7373904566611014

Epoch: 5| Step: 3
Training loss: 0.7068265080451965
Validation loss: 1.815317121885156

Epoch: 5| Step: 4
Training loss: 1.0511693954467773
Validation loss: 1.7039421578889251

Epoch: 5| Step: 5
Training loss: 1.2869675159454346
Validation loss: 1.8498890951115599

Epoch: 5| Step: 6
Training loss: 1.215256929397583
Validation loss: 1.8273804136501846

Epoch: 5| Step: 7
Training loss: 0.6788328289985657
Validation loss: 1.8089802188258017

Epoch: 5| Step: 8
Training loss: 1.165057897567749
Validation loss: 1.8507104919802757

Epoch: 5| Step: 9
Training loss: 1.174914002418518
Validation loss: 1.7795369984001241

Epoch: 5| Step: 10
Training loss: 1.4828245639801025
Validation loss: 1.7683627592620028

Epoch: 479| Step: 0
Training loss: 0.9785741567611694
Validation loss: 1.7986385296749812

Epoch: 5| Step: 1
Training loss: 1.1857903003692627
Validation loss: 1.8135829997319046

Epoch: 5| Step: 2
Training loss: 0.8455203771591187
Validation loss: 1.783357379257038

Epoch: 5| Step: 3
Training loss: 1.0917601585388184
Validation loss: 1.7643820342197214

Epoch: 5| Step: 4
Training loss: 0.8779765963554382
Validation loss: 1.7885267888346026

Epoch: 5| Step: 5
Training loss: 1.199175238609314
Validation loss: 1.823908777647121

Epoch: 5| Step: 6
Training loss: 1.5418990850448608
Validation loss: 1.7650318261115783

Epoch: 5| Step: 7
Training loss: 0.8414703607559204
Validation loss: 1.7398880271501438

Epoch: 5| Step: 8
Training loss: 1.3742449283599854
Validation loss: 1.7602422224578036

Epoch: 5| Step: 9
Training loss: 1.0552846193313599
Validation loss: 1.8152221710451188

Epoch: 5| Step: 10
Training loss: 0.8358913064002991
Validation loss: 1.7544708662135626

Epoch: 480| Step: 0
Training loss: 1.1441452503204346
Validation loss: 1.7723901207729051

Epoch: 5| Step: 1
Training loss: 0.9987457394599915
Validation loss: 1.7901626325422717

Epoch: 5| Step: 2
Training loss: 1.5398012399673462
Validation loss: 1.7526922225952148

Epoch: 5| Step: 3
Training loss: 0.4527546465396881
Validation loss: 1.8005532269836755

Epoch: 5| Step: 4
Training loss: 1.073107361793518
Validation loss: 1.7317240045916649

Epoch: 5| Step: 5
Training loss: 1.1436477899551392
Validation loss: 1.738174606395024

Epoch: 5| Step: 6
Training loss: 1.282568335533142
Validation loss: 1.7739543632794452

Epoch: 5| Step: 7
Training loss: 0.903918445110321
Validation loss: 1.7532345710262176

Epoch: 5| Step: 8
Training loss: 1.139060378074646
Validation loss: 1.7204884341968003

Epoch: 5| Step: 9
Training loss: 0.9205312728881836
Validation loss: 1.727259607725246

Epoch: 5| Step: 10
Training loss: 1.4860209226608276
Validation loss: 1.7322857251731298

Epoch: 481| Step: 0
Training loss: 1.2112748622894287
Validation loss: 1.751207185047929

Epoch: 5| Step: 1
Training loss: 0.6147744655609131
Validation loss: 1.786923462344754

Epoch: 5| Step: 2
Training loss: 1.2136785984039307
Validation loss: 1.7778013867716635

Epoch: 5| Step: 3
Training loss: 1.1289020776748657
Validation loss: 1.7601066584228187

Epoch: 5| Step: 4
Training loss: 0.9319098591804504
Validation loss: 1.7495430566931283

Epoch: 5| Step: 5
Training loss: 0.9424136877059937
Validation loss: 1.776154843709802

Epoch: 5| Step: 6
Training loss: 1.1518253087997437
Validation loss: 1.7854341781267555

Epoch: 5| Step: 7
Training loss: 1.372193455696106
Validation loss: 1.7482873047551801

Epoch: 5| Step: 8
Training loss: 1.158529281616211
Validation loss: 1.7923202258284374

Epoch: 5| Step: 9
Training loss: 0.8071694374084473
Validation loss: 1.7584297503194501

Epoch: 5| Step: 10
Training loss: 1.6112744808197021
Validation loss: 1.7729935376874861

Epoch: 482| Step: 0
Training loss: 1.2506873607635498
Validation loss: 1.81795883435075

Epoch: 5| Step: 1
Training loss: 1.0814225673675537
Validation loss: 1.799195469066661

Epoch: 5| Step: 2
Training loss: 0.9665981531143188
Validation loss: 1.737424494117819

Epoch: 5| Step: 3
Training loss: 0.958325207233429
Validation loss: 1.7660267955513411

Epoch: 5| Step: 4
Training loss: 0.9043729901313782
Validation loss: 1.7410578599540136

Epoch: 5| Step: 5
Training loss: 0.875143826007843
Validation loss: 1.8184845114267

Epoch: 5| Step: 6
Training loss: 1.1022700071334839
Validation loss: 1.737063568125489

Epoch: 5| Step: 7
Training loss: 1.0078226327896118
Validation loss: 1.737422365014271

Epoch: 5| Step: 8
Training loss: 1.2259069681167603
Validation loss: 1.7707584904086204

Epoch: 5| Step: 9
Training loss: 0.9317852854728699
Validation loss: 1.7157140444683772

Epoch: 5| Step: 10
Training loss: 1.5648430585861206
Validation loss: 1.7679205568887855

Epoch: 483| Step: 0
Training loss: 1.1554163694381714
Validation loss: 1.778917202385523

Epoch: 5| Step: 1
Training loss: 1.1255706548690796
Validation loss: 1.7897387448177542

Epoch: 5| Step: 2
Training loss: 1.188590407371521
Validation loss: 1.7290882378496149

Epoch: 5| Step: 3
Training loss: 1.3167545795440674
Validation loss: 1.750477119158673

Epoch: 5| Step: 4
Training loss: 1.100180983543396
Validation loss: 1.7731084246789255

Epoch: 5| Step: 5
Training loss: 1.1959959268569946
Validation loss: 1.7978153536396642

Epoch: 5| Step: 6
Training loss: 1.4317530393600464
Validation loss: 1.7773816354813115

Epoch: 5| Step: 7
Training loss: 1.155927300453186
Validation loss: 1.7851655329427412

Epoch: 5| Step: 8
Training loss: 0.8152381777763367
Validation loss: 1.7496657089520526

Epoch: 5| Step: 9
Training loss: 0.7225375175476074
Validation loss: 1.7588874781003563

Epoch: 5| Step: 10
Training loss: 1.0574952363967896
Validation loss: 1.788859434025262

Epoch: 484| Step: 0
Training loss: 1.2107203006744385
Validation loss: 1.8144329555573002

Epoch: 5| Step: 1
Training loss: 1.2009625434875488
Validation loss: 1.770653022232876

Epoch: 5| Step: 2
Training loss: 1.0786710977554321
Validation loss: 1.7859538934564079

Epoch: 5| Step: 3
Training loss: 0.9920501708984375
Validation loss: 1.734780857639928

Epoch: 5| Step: 4
Training loss: 1.2333781719207764
Validation loss: 1.7747152672019055

Epoch: 5| Step: 5
Training loss: 1.1630207300186157
Validation loss: 1.8146364958055559

Epoch: 5| Step: 6
Training loss: 1.2550908327102661
Validation loss: 1.7778674966545516

Epoch: 5| Step: 7
Training loss: 0.8490581512451172
Validation loss: 1.7145536996984994

Epoch: 5| Step: 8
Training loss: 1.0199706554412842
Validation loss: 1.7432010199434014

Epoch: 5| Step: 9
Training loss: 1.041786789894104
Validation loss: 1.8019531926801127

Epoch: 5| Step: 10
Training loss: 0.7094182372093201
Validation loss: 1.7814448059246104

Epoch: 485| Step: 0
Training loss: 0.9707772135734558
Validation loss: 1.758700829680248

Epoch: 5| Step: 1
Training loss: 1.2346563339233398
Validation loss: 1.7461817097920243

Epoch: 5| Step: 2
Training loss: 1.0448304414749146
Validation loss: 1.7323205586402648

Epoch: 5| Step: 3
Training loss: 0.8747345209121704
Validation loss: 1.7924297586564095

Epoch: 5| Step: 4
Training loss: 1.4025163650512695
Validation loss: 1.761790285828293

Epoch: 5| Step: 5
Training loss: 0.7288109064102173
Validation loss: 1.7694691278601204

Epoch: 5| Step: 6
Training loss: 1.6741063594818115
Validation loss: 1.7412783894487607

Epoch: 5| Step: 7
Training loss: 0.9302018284797668
Validation loss: 1.7498139104535502

Epoch: 5| Step: 8
Training loss: 0.7666446566581726
Validation loss: 1.7174831821072487

Epoch: 5| Step: 9
Training loss: 1.124511480331421
Validation loss: 1.8158192339763846

Epoch: 5| Step: 10
Training loss: 1.5202969312667847
Validation loss: 1.7392494319587626

Epoch: 486| Step: 0
Training loss: 1.0465922355651855
Validation loss: 1.73065786592422

Epoch: 5| Step: 1
Training loss: 0.8002580404281616
Validation loss: 1.750097474744243

Epoch: 5| Step: 2
Training loss: 0.9281044006347656
Validation loss: 1.7332873062420917

Epoch: 5| Step: 3
Training loss: 1.6813358068466187
Validation loss: 1.8017437291401688

Epoch: 5| Step: 4
Training loss: 1.489560842514038
Validation loss: 1.8789370867513842

Epoch: 5| Step: 5
Training loss: 1.9596569538116455
Validation loss: 1.7834915486715173

Epoch: 5| Step: 6
Training loss: 1.104681372642517
Validation loss: 1.8964458370721469

Epoch: 5| Step: 7
Training loss: 0.9324101209640503
Validation loss: 1.8398015063296083

Epoch: 5| Step: 8
Training loss: 0.7316157817840576
Validation loss: 1.8548976785393172

Epoch: 5| Step: 9
Training loss: 0.7854217290878296
Validation loss: 1.7811014344615321

Epoch: 5| Step: 10
Training loss: 1.109425663948059
Validation loss: 1.7852450583570747

Epoch: 487| Step: 0
Training loss: 1.140162706375122
Validation loss: 1.809994759098176

Epoch: 5| Step: 1
Training loss: 1.1002912521362305
Validation loss: 1.6918070418860323

Epoch: 5| Step: 2
Training loss: 0.7243719696998596
Validation loss: 1.7933612536358576

Epoch: 5| Step: 3
Training loss: 0.7750388979911804
Validation loss: 1.7240665369136359

Epoch: 5| Step: 4
Training loss: 1.1097427606582642
Validation loss: 1.741065667521569

Epoch: 5| Step: 5
Training loss: 1.4207451343536377
Validation loss: 1.7671138855718798

Epoch: 5| Step: 6
Training loss: 1.279104232788086
Validation loss: 1.7899185303718812

Epoch: 5| Step: 7
Training loss: 1.1750094890594482
Validation loss: 1.7383122495425645

Epoch: 5| Step: 8
Training loss: 0.6455938220024109
Validation loss: 1.7391771526746853

Epoch: 5| Step: 9
Training loss: 0.9144048690795898
Validation loss: 1.7422580244720622

Epoch: 5| Step: 10
Training loss: 1.948271632194519
Validation loss: 1.7090363887048536

Epoch: 488| Step: 0
Training loss: 1.1462059020996094
Validation loss: 1.7937043354075441

Epoch: 5| Step: 1
Training loss: 0.8755243420600891
Validation loss: 1.7211691333401589

Epoch: 5| Step: 2
Training loss: 0.8367208242416382
Validation loss: 1.7193921842882711

Epoch: 5| Step: 3
Training loss: 0.7869167327880859
Validation loss: 1.752684042658857

Epoch: 5| Step: 4
Training loss: 1.4981313943862915
Validation loss: 1.7309600153276998

Epoch: 5| Step: 5
Training loss: 1.0751699209213257
Validation loss: 1.7210964310553767

Epoch: 5| Step: 6
Training loss: 0.7013769745826721
Validation loss: 1.8046395009563816

Epoch: 5| Step: 7
Training loss: 1.245636224746704
Validation loss: 1.7454235066649735

Epoch: 5| Step: 8
Training loss: 1.4078502655029297
Validation loss: 1.7755971813714633

Epoch: 5| Step: 9
Training loss: 0.7655656933784485
Validation loss: 1.7437460717334543

Epoch: 5| Step: 10
Training loss: 1.6698817014694214
Validation loss: 1.7614507969989572

Epoch: 489| Step: 0
Training loss: 0.9479725956916809
Validation loss: 1.777006144164711

Epoch: 5| Step: 1
Training loss: 0.9597095251083374
Validation loss: 1.7130673059853174

Epoch: 5| Step: 2
Training loss: 1.0471214056015015
Validation loss: 1.7510351468158025

Epoch: 5| Step: 3
Training loss: 0.9955185055732727
Validation loss: 1.760663822133054

Epoch: 5| Step: 4
Training loss: 0.9228376150131226
Validation loss: 1.729919777121595

Epoch: 5| Step: 5
Training loss: 1.1677223443984985
Validation loss: 1.6824956632429553

Epoch: 5| Step: 6
Training loss: 1.171902060508728
Validation loss: 1.7502037491849674

Epoch: 5| Step: 7
Training loss: 1.0911954641342163
Validation loss: 1.7330409096133323

Epoch: 5| Step: 8
Training loss: 0.96197509765625
Validation loss: 1.7408199964031097

Epoch: 5| Step: 9
Training loss: 1.2001957893371582
Validation loss: 1.7457507771830405

Epoch: 5| Step: 10
Training loss: 1.3447037935256958
Validation loss: 1.7400535396350327

Epoch: 490| Step: 0
Training loss: 0.6825874447822571
Validation loss: 1.7894115576180079

Epoch: 5| Step: 1
Training loss: 1.0788943767547607
Validation loss: 1.726538182586752

Epoch: 5| Step: 2
Training loss: 0.975021243095398
Validation loss: 1.7393490460611158

Epoch: 5| Step: 3
Training loss: 0.9251114130020142
Validation loss: 1.8018673120006439

Epoch: 5| Step: 4
Training loss: 1.1973527669906616
Validation loss: 1.759610955433179

Epoch: 5| Step: 5
Training loss: 1.0347158908843994
Validation loss: 1.801894757055467

Epoch: 5| Step: 6
Training loss: 1.498081922531128
Validation loss: 1.782470844125235

Epoch: 5| Step: 7
Training loss: 1.0542857646942139
Validation loss: 1.764460700814442

Epoch: 5| Step: 8
Training loss: 1.1904634237289429
Validation loss: 1.7591060156463294

Epoch: 5| Step: 9
Training loss: 1.2456843852996826
Validation loss: 1.742769866861323

Epoch: 5| Step: 10
Training loss: 0.8337177634239197
Validation loss: 1.7948289737906507

Epoch: 491| Step: 0
Training loss: 1.2223117351531982
Validation loss: 1.8048342697082027

Epoch: 5| Step: 1
Training loss: 1.1681779623031616
Validation loss: 1.74059094408507

Epoch: 5| Step: 2
Training loss: 1.3089827299118042
Validation loss: 1.77107790464996

Epoch: 5| Step: 3
Training loss: 0.6670058369636536
Validation loss: 1.725479572050033

Epoch: 5| Step: 4
Training loss: 0.3726268410682678
Validation loss: 1.7439705376983972

Epoch: 5| Step: 5
Training loss: 1.2924764156341553
Validation loss: 1.7746967730983612

Epoch: 5| Step: 6
Training loss: 1.2059824466705322
Validation loss: 1.7105080030297721

Epoch: 5| Step: 7
Training loss: 1.0787163972854614
Validation loss: 1.7370628650470445

Epoch: 5| Step: 8
Training loss: 1.3176990747451782
Validation loss: 1.715467055638631

Epoch: 5| Step: 9
Training loss: 1.096047282218933
Validation loss: 1.745932295758237

Epoch: 5| Step: 10
Training loss: 1.2380000352859497
Validation loss: 1.7705809582946122

Epoch: 492| Step: 0
Training loss: 1.1510193347930908
Validation loss: 1.7052069876783638

Epoch: 5| Step: 1
Training loss: 0.889423668384552
Validation loss: 1.7871502573772142

Epoch: 5| Step: 2
Training loss: 0.8545647859573364
Validation loss: 1.7779595569897724

Epoch: 5| Step: 3
Training loss: 0.9036736488342285
Validation loss: 1.8066987811878163

Epoch: 5| Step: 4
Training loss: 1.2410342693328857
Validation loss: 1.7619862915367208

Epoch: 5| Step: 5
Training loss: 1.3874878883361816
Validation loss: 1.7568367553013626

Epoch: 5| Step: 6
Training loss: 0.8651270866394043
Validation loss: 1.8128831155838505

Epoch: 5| Step: 7
Training loss: 1.0972105264663696
Validation loss: 1.812870704999534

Epoch: 5| Step: 8
Training loss: 1.4911553859710693
Validation loss: 1.7756421848009991

Epoch: 5| Step: 9
Training loss: 1.0396426916122437
Validation loss: 1.758542695353108

Epoch: 5| Step: 10
Training loss: 0.9015349745750427
Validation loss: 1.7696733192730976

Epoch: 493| Step: 0
Training loss: 0.8908259272575378
Validation loss: 1.7135902925204205

Epoch: 5| Step: 1
Training loss: 0.9603202939033508
Validation loss: 1.810918265773404

Epoch: 5| Step: 2
Training loss: 0.6372123956680298
Validation loss: 1.8038895745431223

Epoch: 5| Step: 3
Training loss: 0.9943340420722961
Validation loss: 1.7201591037934827

Epoch: 5| Step: 4
Training loss: 0.9807316064834595
Validation loss: 1.7877820794300368

Epoch: 5| Step: 5
Training loss: 1.558616042137146
Validation loss: 1.7662829301690544

Epoch: 5| Step: 6
Training loss: 1.3961117267608643
Validation loss: 1.766678605028378

Epoch: 5| Step: 7
Training loss: 1.1850285530090332
Validation loss: 1.736802726663569

Epoch: 5| Step: 8
Training loss: 1.2544816732406616
Validation loss: 1.7619331216299405

Epoch: 5| Step: 9
Training loss: 0.8968650698661804
Validation loss: 1.7248415036868023

Epoch: 5| Step: 10
Training loss: 1.3524665832519531
Validation loss: 1.7582384963189401

Epoch: 494| Step: 0
Training loss: 1.0469285249710083
Validation loss: 1.7079943533866637

Epoch: 5| Step: 1
Training loss: 1.0725466012954712
Validation loss: 1.7874865762649044

Epoch: 5| Step: 2
Training loss: 0.8369916677474976
Validation loss: 1.7583727759699668

Epoch: 5| Step: 3
Training loss: 1.316122055053711
Validation loss: 1.7913760190368981

Epoch: 5| Step: 4
Training loss: 0.8345090746879578
Validation loss: 1.7832466466452486

Epoch: 5| Step: 5
Training loss: 0.7157397866249084
Validation loss: 1.75773540876245

Epoch: 5| Step: 6
Training loss: 0.9783210754394531
Validation loss: 1.812192665633335

Epoch: 5| Step: 7
Training loss: 1.1448360681533813
Validation loss: 1.7669626666653542

Epoch: 5| Step: 8
Training loss: 0.9818887710571289
Validation loss: 1.8305302102078673

Epoch: 5| Step: 9
Training loss: 1.3326975107192993
Validation loss: 1.7407006127859956

Epoch: 5| Step: 10
Training loss: 1.821088433265686
Validation loss: 1.8207870939726472

Epoch: 495| Step: 0
Training loss: 0.7273787260055542
Validation loss: 1.749403360069439

Epoch: 5| Step: 1
Training loss: 1.2113434076309204
Validation loss: 1.746747556553092

Epoch: 5| Step: 2
Training loss: 1.07668137550354
Validation loss: 1.7745924636881838

Epoch: 5| Step: 3
Training loss: 1.0512938499450684
Validation loss: 1.7068375964318552

Epoch: 5| Step: 4
Training loss: 1.2455248832702637
Validation loss: 1.701006499669885

Epoch: 5| Step: 5
Training loss: 1.1499103307724
Validation loss: 1.7631859151265954

Epoch: 5| Step: 6
Training loss: 0.6027811169624329
Validation loss: 1.763407341895565

Epoch: 5| Step: 7
Training loss: 1.3357317447662354
Validation loss: 1.780456535277828

Epoch: 5| Step: 8
Training loss: 1.0452221632003784
Validation loss: 1.7573917155624719

Epoch: 5| Step: 9
Training loss: 1.1317769289016724
Validation loss: 1.731848996172669

Epoch: 5| Step: 10
Training loss: 1.2601224184036255
Validation loss: 1.684193931600099

Epoch: 496| Step: 0
Training loss: 1.2222239971160889
Validation loss: 1.6985908580082718

Epoch: 5| Step: 1
Training loss: 1.302893042564392
Validation loss: 1.787064298506706

Epoch: 5| Step: 2
Training loss: 0.8698252439498901
Validation loss: 1.7104449297792168

Epoch: 5| Step: 3
Training loss: 1.0221847295761108
Validation loss: 1.7698626543885918

Epoch: 5| Step: 4
Training loss: 0.7375566363334656
Validation loss: 1.7427503114105554

Epoch: 5| Step: 5
Training loss: 1.6071538925170898
Validation loss: 1.7438906777289607

Epoch: 5| Step: 6
Training loss: 0.9587022662162781
Validation loss: 1.7952464703590638

Epoch: 5| Step: 7
Training loss: 0.8790149688720703
Validation loss: 1.7991804448507165

Epoch: 5| Step: 8
Training loss: 1.5122826099395752
Validation loss: 1.7479333031562068

Epoch: 5| Step: 9
Training loss: 0.8192836046218872
Validation loss: 1.7118019570586502

Epoch: 5| Step: 10
Training loss: 0.7976442575454712
Validation loss: 1.8224950503277522

Epoch: 497| Step: 0
Training loss: 1.1618396043777466
Validation loss: 1.771701479470858

Epoch: 5| Step: 1
Training loss: 0.8097242116928101
Validation loss: 1.6867028846535632

Epoch: 5| Step: 2
Training loss: 1.132951259613037
Validation loss: 1.7201189917902793

Epoch: 5| Step: 3
Training loss: 1.0669869184494019
Validation loss: 1.770292374395555

Epoch: 5| Step: 4
Training loss: 1.0776022672653198
Validation loss: 1.681606218379031

Epoch: 5| Step: 5
Training loss: 1.0777523517608643
Validation loss: 1.7666974349688458

Epoch: 5| Step: 6
Training loss: 0.8991653323173523
Validation loss: 1.7453185435264342

Epoch: 5| Step: 7
Training loss: 1.6669399738311768
Validation loss: 1.770096363559846

Epoch: 5| Step: 8
Training loss: 0.9063597917556763
Validation loss: 1.818039478794221

Epoch: 5| Step: 9
Training loss: 1.1256898641586304
Validation loss: 1.762355955698157

Epoch: 5| Step: 10
Training loss: 0.9276778101921082
Validation loss: 1.7523145867932228

Epoch: 498| Step: 0
Training loss: 1.6599664688110352
Validation loss: 1.8016992743297289

Epoch: 5| Step: 1
Training loss: 0.8937742114067078
Validation loss: 1.7325750140733616

Epoch: 5| Step: 2
Training loss: 0.7090451717376709
Validation loss: 1.7319057487672376

Epoch: 5| Step: 3
Training loss: 1.3054698705673218
Validation loss: 1.7136651277542114

Epoch: 5| Step: 4
Training loss: 0.9535967707633972
Validation loss: 1.735011669897264

Epoch: 5| Step: 5
Training loss: 1.0140657424926758
Validation loss: 1.709892621604345

Epoch: 5| Step: 6
Training loss: 1.1480002403259277
Validation loss: 1.722551220206804

Epoch: 5| Step: 7
Training loss: 0.79351806640625
Validation loss: 1.7560191615935294

Epoch: 5| Step: 8
Training loss: 0.8785830736160278
Validation loss: 1.74287413525325

Epoch: 5| Step: 9
Training loss: 1.2672154903411865
Validation loss: 1.7268499507698962

Epoch: 5| Step: 10
Training loss: 0.9671093225479126
Validation loss: 1.8054301943830264

Epoch: 499| Step: 0
Training loss: 0.9438775777816772
Validation loss: 1.703692529791145

Epoch: 5| Step: 1
Training loss: 1.0700323581695557
Validation loss: 1.7251471165687806

Epoch: 5| Step: 2
Training loss: 0.9895132780075073
Validation loss: 1.7874267062833231

Epoch: 5| Step: 3
Training loss: 1.3058332204818726
Validation loss: 1.7989454089954335

Epoch: 5| Step: 4
Training loss: 1.2621771097183228
Validation loss: 1.801092988701277

Epoch: 5| Step: 5
Training loss: 1.2074706554412842
Validation loss: 1.7957761582507883

Epoch: 5| Step: 6
Training loss: 1.0874037742614746
Validation loss: 1.7883247829252673

Epoch: 5| Step: 7
Training loss: 1.0988366603851318
Validation loss: 1.8114070815424765

Epoch: 5| Step: 8
Training loss: 0.956619143486023
Validation loss: 1.7525399000413957

Epoch: 5| Step: 9
Training loss: 1.0609023571014404
Validation loss: 1.752685135410678

Epoch: 5| Step: 10
Training loss: 0.9373246431350708
Validation loss: 1.759048423459453

Epoch: 500| Step: 0
Training loss: 1.123375654220581
Validation loss: 1.7925894875680246

Epoch: 5| Step: 1
Training loss: 1.1495308876037598
Validation loss: 1.7988153990878855

Epoch: 5| Step: 2
Training loss: 0.9828135371208191
Validation loss: 1.780516860305622

Epoch: 5| Step: 3
Training loss: 1.2360765933990479
Validation loss: 1.7336196591777187

Epoch: 5| Step: 4
Training loss: 1.114213228225708
Validation loss: 1.7660351312288673

Epoch: 5| Step: 5
Training loss: 1.0513007640838623
Validation loss: 1.7194251078431324

Epoch: 5| Step: 6
Training loss: 1.0121476650238037
Validation loss: 1.6716483587859778

Epoch: 5| Step: 7
Training loss: 1.0586097240447998
Validation loss: 1.746573373835574

Epoch: 5| Step: 8
Training loss: 1.2509500980377197
Validation loss: 1.7263437624900573

Epoch: 5| Step: 9
Training loss: 0.7414926886558533
Validation loss: 1.7629334721513974

Epoch: 5| Step: 10
Training loss: 0.9056373834609985
Validation loss: 1.7004230535158547

Epoch: 501| Step: 0
Training loss: 1.1494674682617188
Validation loss: 1.7732692469832718

Epoch: 5| Step: 1
Training loss: 0.866993248462677
Validation loss: 1.7703568345756941

Epoch: 5| Step: 2
Training loss: 0.8722101449966431
Validation loss: 1.7742429753785491

Epoch: 5| Step: 3
Training loss: 1.2592389583587646
Validation loss: 1.8539382296223794

Epoch: 5| Step: 4
Training loss: 1.1589882373809814
Validation loss: 1.7817769294144006

Epoch: 5| Step: 5
Training loss: 1.1119991540908813
Validation loss: 1.763398588344615

Epoch: 5| Step: 6
Training loss: 0.932706356048584
Validation loss: 1.8045254394572268

Epoch: 5| Step: 7
Training loss: 1.257312297821045
Validation loss: 1.8168370108450613

Epoch: 5| Step: 8
Training loss: 0.8508745431900024
Validation loss: 1.7132713153798094

Epoch: 5| Step: 9
Training loss: 1.3898409605026245
Validation loss: 1.7441238062356108

Epoch: 5| Step: 10
Training loss: 0.9996251463890076
Validation loss: 1.8120842569617814

Epoch: 502| Step: 0
Training loss: 1.4975569248199463
Validation loss: 1.7545636892318726

Epoch: 5| Step: 1
Training loss: 1.1046631336212158
Validation loss: 1.706057616459426

Epoch: 5| Step: 2
Training loss: 0.8179248571395874
Validation loss: 1.731209014051704

Epoch: 5| Step: 3
Training loss: 0.8028081655502319
Validation loss: 1.738159562951775

Epoch: 5| Step: 4
Training loss: 1.2843458652496338
Validation loss: 1.7597653891450615

Epoch: 5| Step: 5
Training loss: 0.9014420509338379
Validation loss: 1.776586219828616

Epoch: 5| Step: 6
Training loss: 0.8437888026237488
Validation loss: 1.7000785271326702

Epoch: 5| Step: 7
Training loss: 1.06756591796875
Validation loss: 1.729689803174747

Epoch: 5| Step: 8
Training loss: 1.1835927963256836
Validation loss: 1.7547790670907626

Epoch: 5| Step: 9
Training loss: 0.8703020811080933
Validation loss: 1.7190043900602607

Epoch: 5| Step: 10
Training loss: 1.0414787530899048
Validation loss: 1.8016452494487967

Epoch: 503| Step: 0
Training loss: 1.0856373310089111
Validation loss: 1.7527504403104064

Epoch: 5| Step: 1
Training loss: 1.0091438293457031
Validation loss: 1.7493297810195594

Epoch: 5| Step: 2
Training loss: 1.1840249300003052
Validation loss: 1.7889113349299277

Epoch: 5| Step: 3
Training loss: 0.5492653250694275
Validation loss: 1.8342078116632277

Epoch: 5| Step: 4
Training loss: 0.9504300951957703
Validation loss: 1.7767462153588571

Epoch: 5| Step: 5
Training loss: 1.4696975946426392
Validation loss: 1.8233354450553976

Epoch: 5| Step: 6
Training loss: 0.9775092005729675
Validation loss: 1.8023486047662713

Epoch: 5| Step: 7
Training loss: 1.5649735927581787
Validation loss: 1.8464660388167187

Epoch: 5| Step: 8
Training loss: 1.5803403854370117
Validation loss: 1.823102387048865

Epoch: 5| Step: 9
Training loss: 0.7200732231140137
Validation loss: 1.7652120628664572

Epoch: 5| Step: 10
Training loss: 1.027334213256836
Validation loss: 1.7457912762959797

Epoch: 504| Step: 0
Training loss: 1.1378271579742432
Validation loss: 1.7205587497321508

Epoch: 5| Step: 1
Training loss: 1.0103946924209595
Validation loss: 1.7103762998375842

Epoch: 5| Step: 2
Training loss: 1.1915782690048218
Validation loss: 1.7341402089723976

Epoch: 5| Step: 3
Training loss: 0.8209949731826782
Validation loss: 1.7505175785351825

Epoch: 5| Step: 4
Training loss: 1.2720937728881836
Validation loss: 1.7356213420949957

Epoch: 5| Step: 5
Training loss: 0.9778106808662415
Validation loss: 1.7776980938449982

Epoch: 5| Step: 6
Training loss: 0.49348869919776917
Validation loss: 1.7490106885151198

Epoch: 5| Step: 7
Training loss: 1.4573408365249634
Validation loss: 1.7287222339260964

Epoch: 5| Step: 8
Training loss: 1.0960537195205688
Validation loss: 1.7309191611505323

Epoch: 5| Step: 9
Training loss: 1.1711721420288086
Validation loss: 1.7014112164897304

Epoch: 5| Step: 10
Training loss: 1.0183539390563965
Validation loss: 1.7340675066876154

Epoch: 505| Step: 0
Training loss: 1.0222113132476807
Validation loss: 1.782573840951407

Epoch: 5| Step: 1
Training loss: 0.790890097618103
Validation loss: 1.7346046240099016

Epoch: 5| Step: 2
Training loss: 0.9245845675468445
Validation loss: 1.6793865388439548

Epoch: 5| Step: 3
Training loss: 0.9236171841621399
Validation loss: 1.7483412527268933

Epoch: 5| Step: 4
Training loss: 1.3572787046432495
Validation loss: 1.7557592058694491

Epoch: 5| Step: 5
Training loss: 0.9616875648498535
Validation loss: 1.7694146479329755

Epoch: 5| Step: 6
Training loss: 1.1780641078948975
Validation loss: 1.769369061275195

Epoch: 5| Step: 7
Training loss: 1.0447133779525757
Validation loss: 1.8060936081794001

Epoch: 5| Step: 8
Training loss: 1.2915236949920654
Validation loss: 1.786727992437219

Epoch: 5| Step: 9
Training loss: 0.9294238090515137
Validation loss: 1.7242338824015793

Epoch: 5| Step: 10
Training loss: 1.3490750789642334
Validation loss: 1.7021818250738165

Epoch: 506| Step: 0
Training loss: 1.4033138751983643
Validation loss: 1.7359329180050922

Epoch: 5| Step: 1
Training loss: 1.0154980421066284
Validation loss: 1.7735236049980245

Epoch: 5| Step: 2
Training loss: 0.7470517158508301
Validation loss: 1.8261575365579257

Epoch: 5| Step: 3
Training loss: 1.0540074110031128
Validation loss: 1.7178921840524162

Epoch: 5| Step: 4
Training loss: 0.9588590860366821
Validation loss: 1.7635762576133973

Epoch: 5| Step: 5
Training loss: 1.1569061279296875
Validation loss: 1.7309157034402252

Epoch: 5| Step: 6
Training loss: 0.9074304699897766
Validation loss: 1.774744228650165

Epoch: 5| Step: 7
Training loss: 0.49141162633895874
Validation loss: 1.7280165828684324

Epoch: 5| Step: 8
Training loss: 0.922166645526886
Validation loss: 1.7432951722093808

Epoch: 5| Step: 9
Training loss: 1.2451554536819458
Validation loss: 1.7344691753387451

Epoch: 5| Step: 10
Training loss: 1.3896262645721436
Validation loss: 1.801463835982866

Epoch: 507| Step: 0
Training loss: 1.135768175125122
Validation loss: 1.7940014267480502

Epoch: 5| Step: 1
Training loss: 1.4108238220214844
Validation loss: 1.7851025199377408

Epoch: 5| Step: 2
Training loss: 0.9788605570793152
Validation loss: 1.8086352066327167

Epoch: 5| Step: 3
Training loss: 1.000392198562622
Validation loss: 1.7547749447566208

Epoch: 5| Step: 4
Training loss: 0.7880144119262695
Validation loss: 1.711479466448548

Epoch: 5| Step: 5
Training loss: 1.1667730808258057
Validation loss: 1.7771390227861301

Epoch: 5| Step: 6
Training loss: 0.8217021822929382
Validation loss: 1.767775515074371

Epoch: 5| Step: 7
Training loss: 1.2512937784194946
Validation loss: 1.7844270608758415

Epoch: 5| Step: 8
Training loss: 1.2020206451416016
Validation loss: 1.7013254973196215

Epoch: 5| Step: 9
Training loss: 1.0357041358947754
Validation loss: 1.691418892593794

Epoch: 5| Step: 10
Training loss: 0.8022669553756714
Validation loss: 1.7687805327036048

Epoch: 508| Step: 0
Training loss: 0.9026566743850708
Validation loss: 1.7693824588611562

Epoch: 5| Step: 1
Training loss: 1.0024690628051758
Validation loss: 1.7346189816792805

Epoch: 5| Step: 2
Training loss: 0.7784131765365601
Validation loss: 1.778476543323968

Epoch: 5| Step: 3
Training loss: 0.948037326335907
Validation loss: 1.755267225286012

Epoch: 5| Step: 4
Training loss: 0.7671975493431091
Validation loss: 1.724724482464534

Epoch: 5| Step: 5
Training loss: 1.4032847881317139
Validation loss: 1.7514969841126473

Epoch: 5| Step: 6
Training loss: 1.2049506902694702
Validation loss: 1.7463679031659198

Epoch: 5| Step: 7
Training loss: 1.0628750324249268
Validation loss: 1.7607991874858897

Epoch: 5| Step: 8
Training loss: 1.1025768518447876
Validation loss: 1.7909660031718593

Epoch: 5| Step: 9
Training loss: 0.7947713136672974
Validation loss: 1.7162209518494145

Epoch: 5| Step: 10
Training loss: 1.3169398307800293
Validation loss: 1.7290336278177076

Epoch: 509| Step: 0
Training loss: 1.5941565036773682
Validation loss: 1.7436900856674358

Epoch: 5| Step: 1
Training loss: 0.9485219717025757
Validation loss: 1.7310796899180259

Epoch: 5| Step: 2
Training loss: 1.0036038160324097
Validation loss: 1.751133559852518

Epoch: 5| Step: 3
Training loss: 0.5530713796615601
Validation loss: 1.7375966887320242

Epoch: 5| Step: 4
Training loss: 0.8911170959472656
Validation loss: 1.792874615679505

Epoch: 5| Step: 5
Training loss: 1.2298709154129028
Validation loss: 1.705710268789722

Epoch: 5| Step: 6
Training loss: 1.264756441116333
Validation loss: 1.728509526098928

Epoch: 5| Step: 7
Training loss: 1.0241931676864624
Validation loss: 1.7778715087521462

Epoch: 5| Step: 8
Training loss: 1.5897767543792725
Validation loss: 1.7644150398110832

Epoch: 5| Step: 9
Training loss: 0.5748361349105835
Validation loss: 1.709968751476657

Epoch: 5| Step: 10
Training loss: 0.8351479172706604
Validation loss: 1.6890506911021408

Epoch: 510| Step: 0
Training loss: 0.6139619946479797
Validation loss: 1.7374075869078278

Epoch: 5| Step: 1
Training loss: 0.987645149230957
Validation loss: 1.795084721298628

Epoch: 5| Step: 2
Training loss: 0.9813340306282043
Validation loss: 1.7605848927651682

Epoch: 5| Step: 3
Training loss: 0.7281596660614014
Validation loss: 1.787247815439778

Epoch: 5| Step: 4
Training loss: 0.9250568151473999
Validation loss: 1.6975924673900809

Epoch: 5| Step: 5
Training loss: 0.953154444694519
Validation loss: 1.7781314439671014

Epoch: 5| Step: 6
Training loss: 1.686018705368042
Validation loss: 1.7464448277668287

Epoch: 5| Step: 7
Training loss: 1.024645447731018
Validation loss: 1.764425613546884

Epoch: 5| Step: 8
Training loss: 1.2046664953231812
Validation loss: 1.692399537691506

Epoch: 5| Step: 9
Training loss: 0.7407243847846985
Validation loss: 1.726800121286864

Epoch: 5| Step: 10
Training loss: 1.5944854021072388
Validation loss: 1.754274905368846

Epoch: 511| Step: 0
Training loss: 0.8458158373832703
Validation loss: 1.771444025860038

Epoch: 5| Step: 1
Training loss: 1.427037239074707
Validation loss: 1.754391812509106

Epoch: 5| Step: 2
Training loss: 1.484533667564392
Validation loss: 1.7449049308735838

Epoch: 5| Step: 3
Training loss: 0.9429135322570801
Validation loss: 1.7380618151798044

Epoch: 5| Step: 4
Training loss: 0.8531185984611511
Validation loss: 1.7160887513109433

Epoch: 5| Step: 5
Training loss: 0.7735377550125122
Validation loss: 1.7449849279977943

Epoch: 5| Step: 6
Training loss: 1.3345991373062134
Validation loss: 1.771712669762232

Epoch: 5| Step: 7
Training loss: 1.0425077676773071
Validation loss: 1.7496628710018691

Epoch: 5| Step: 8
Training loss: 1.0447885990142822
Validation loss: 1.7318620938126759

Epoch: 5| Step: 9
Training loss: 0.9359089732170105
Validation loss: 1.710152519005601

Epoch: 5| Step: 10
Training loss: 1.099786400794983
Validation loss: 1.7529881846520208

Epoch: 512| Step: 0
Training loss: 0.8823486566543579
Validation loss: 1.6773194427131324

Epoch: 5| Step: 1
Training loss: 1.1718406677246094
Validation loss: 1.6909710412384362

Epoch: 5| Step: 2
Training loss: 0.7670833468437195
Validation loss: 1.6864250718906362

Epoch: 5| Step: 3
Training loss: 0.8865925073623657
Validation loss: 1.7173674555235012

Epoch: 5| Step: 4
Training loss: 1.0823557376861572
Validation loss: 1.762205958366394

Epoch: 5| Step: 5
Training loss: 0.879119873046875
Validation loss: 1.757537518778155

Epoch: 5| Step: 6
Training loss: 1.0503708124160767
Validation loss: 1.7800455747112152

Epoch: 5| Step: 7
Training loss: 1.0053633451461792
Validation loss: 1.7748445362173102

Epoch: 5| Step: 8
Training loss: 0.995293915271759
Validation loss: 1.7712079555757585

Epoch: 5| Step: 9
Training loss: 1.3808618783950806
Validation loss: 1.7043326195850168

Epoch: 5| Step: 10
Training loss: 1.2042624950408936
Validation loss: 1.7046649750842844

Epoch: 513| Step: 0
Training loss: 1.151837944984436
Validation loss: 1.723281979560852

Epoch: 5| Step: 1
Training loss: 0.9660569429397583
Validation loss: 1.7913535871813375

Epoch: 5| Step: 2
Training loss: 0.993250846862793
Validation loss: 1.7694044907887776

Epoch: 5| Step: 3
Training loss: 1.0858780145645142
Validation loss: 1.8058181116657872

Epoch: 5| Step: 4
Training loss: 1.3545515537261963
Validation loss: 1.8024218864338373

Epoch: 5| Step: 5
Training loss: 0.8260909914970398
Validation loss: 1.7366197147677023

Epoch: 5| Step: 6
Training loss: 0.6196204423904419
Validation loss: 1.712847707092121

Epoch: 5| Step: 7
Training loss: 1.206483244895935
Validation loss: 1.7089106305952995

Epoch: 5| Step: 8
Training loss: 1.0982115268707275
Validation loss: 1.769672086161952

Epoch: 5| Step: 9
Training loss: 1.536029577255249
Validation loss: 1.7734732961141935

Epoch: 5| Step: 10
Training loss: 0.8294976949691772
Validation loss: 1.7207108748856412

Epoch: 514| Step: 0
Training loss: 0.8178022503852844
Validation loss: 1.7456746639743927

Epoch: 5| Step: 1
Training loss: 0.8271700143814087
Validation loss: 1.8109808967959495

Epoch: 5| Step: 2
Training loss: 1.4364728927612305
Validation loss: 1.7561618897222704

Epoch: 5| Step: 3
Training loss: 0.6500765085220337
Validation loss: 1.7497757404081282

Epoch: 5| Step: 4
Training loss: 1.7565559148788452
Validation loss: 1.754624161669003

Epoch: 5| Step: 5
Training loss: 1.0898005962371826
Validation loss: 1.7152499075858825

Epoch: 5| Step: 6
Training loss: 0.8346524238586426
Validation loss: 1.7342750487789031

Epoch: 5| Step: 7
Training loss: 0.8378971219062805
Validation loss: 1.7943761502542803

Epoch: 5| Step: 8
Training loss: 1.3205747604370117
Validation loss: 1.6709980144295642

Epoch: 5| Step: 9
Training loss: 0.8528947830200195
Validation loss: 1.789030744183448

Epoch: 5| Step: 10
Training loss: 0.8558490872383118
Validation loss: 1.7232463436741983

Epoch: 515| Step: 0
Training loss: 1.2330410480499268
Validation loss: 1.7397242464045042

Epoch: 5| Step: 1
Training loss: 0.7803398370742798
Validation loss: 1.7111374690968504

Epoch: 5| Step: 2
Training loss: 1.1006885766983032
Validation loss: 1.7507531822368663

Epoch: 5| Step: 3
Training loss: 0.91096031665802
Validation loss: 1.6834669625887306

Epoch: 5| Step: 4
Training loss: 1.2537742853164673
Validation loss: 1.708072473925929

Epoch: 5| Step: 5
Training loss: 1.0663793087005615
Validation loss: 1.750795700216806

Epoch: 5| Step: 6
Training loss: 0.6466249227523804
Validation loss: 1.703167611552823

Epoch: 5| Step: 7
Training loss: 1.1029629707336426
Validation loss: 1.6988419883994645

Epoch: 5| Step: 8
Training loss: 0.8188450932502747
Validation loss: 1.714296551160915

Epoch: 5| Step: 9
Training loss: 1.5484591722488403
Validation loss: 1.7338801019935197

Epoch: 5| Step: 10
Training loss: 0.5970892906188965
Validation loss: 1.7600668502110306

Epoch: 516| Step: 0
Training loss: 1.0516210794448853
Validation loss: 1.7507592811379382

Epoch: 5| Step: 1
Training loss: 1.097133994102478
Validation loss: 1.785834402166387

Epoch: 5| Step: 2
Training loss: 1.2137577533721924
Validation loss: 1.742318034172058

Epoch: 5| Step: 3
Training loss: 1.0480719804763794
Validation loss: 1.7141324038146644

Epoch: 5| Step: 4
Training loss: 0.9343559145927429
Validation loss: 1.696903855569901

Epoch: 5| Step: 5
Training loss: 0.5226209163665771
Validation loss: 1.7415165298728532

Epoch: 5| Step: 6
Training loss: 1.360863447189331
Validation loss: 1.6985356987163585

Epoch: 5| Step: 7
Training loss: 0.9769191741943359
Validation loss: 1.753742964037003

Epoch: 5| Step: 8
Training loss: 0.9032315015792847
Validation loss: 1.7322206061373475

Epoch: 5| Step: 9
Training loss: 0.8718051910400391
Validation loss: 1.6838431928747444

Epoch: 5| Step: 10
Training loss: 1.0957697629928589
Validation loss: 1.7235374540411017

Epoch: 517| Step: 0
Training loss: 0.7631855010986328
Validation loss: 1.7112076064591766

Epoch: 5| Step: 1
Training loss: 1.6345821619033813
Validation loss: 1.7366191225667154

Epoch: 5| Step: 2
Training loss: 1.0177454948425293
Validation loss: 1.7174705741226033

Epoch: 5| Step: 3
Training loss: 1.1882764101028442
Validation loss: 1.734266637473978

Epoch: 5| Step: 4
Training loss: 1.126096487045288
Validation loss: 1.7177436890140656

Epoch: 5| Step: 5
Training loss: 0.8588859438896179
Validation loss: 1.7517541057320052

Epoch: 5| Step: 6
Training loss: 1.1197996139526367
Validation loss: 1.7427539312711327

Epoch: 5| Step: 7
Training loss: 0.7446907758712769
Validation loss: 1.6945655204916512

Epoch: 5| Step: 8
Training loss: 1.2174122333526611
Validation loss: 1.7184492849534558

Epoch: 5| Step: 9
Training loss: 0.9052486419677734
Validation loss: 1.7430272121583261

Epoch: 5| Step: 10
Training loss: 0.9308204054832458
Validation loss: 1.7268352534181328

Epoch: 518| Step: 0
Training loss: 1.1110363006591797
Validation loss: 1.760418914979504

Epoch: 5| Step: 1
Training loss: 1.0504295825958252
Validation loss: 1.7509146300695275

Epoch: 5| Step: 2
Training loss: 0.82850182056427
Validation loss: 1.7746142213062575

Epoch: 5| Step: 3
Training loss: 0.7557997703552246
Validation loss: 1.7410641536917737

Epoch: 5| Step: 4
Training loss: 1.4159739017486572
Validation loss: 1.7452598823014127

Epoch: 5| Step: 5
Training loss: 0.7543747425079346
Validation loss: 1.7594791945590769

Epoch: 5| Step: 6
Training loss: 1.2935885190963745
Validation loss: 1.7433933468275173

Epoch: 5| Step: 7
Training loss: 1.1631803512573242
Validation loss: 1.7342288647928545

Epoch: 5| Step: 8
Training loss: 0.7598658800125122
Validation loss: 1.7950172411498202

Epoch: 5| Step: 9
Training loss: 1.1162317991256714
Validation loss: 1.76514656184822

Epoch: 5| Step: 10
Training loss: 1.203839659690857
Validation loss: 1.7455353980423303

Epoch: 519| Step: 0
Training loss: 0.7621070146560669
Validation loss: 1.7403862912167785

Epoch: 5| Step: 1
Training loss: 0.8303723335266113
Validation loss: 1.7815881877817132

Epoch: 5| Step: 2
Training loss: 1.0474724769592285
Validation loss: 1.7684525700025662

Epoch: 5| Step: 3
Training loss: 1.3062379360198975
Validation loss: 1.7276475826899211

Epoch: 5| Step: 4
Training loss: 1.085561990737915
Validation loss: 1.70652183025114

Epoch: 5| Step: 5
Training loss: 0.5638946890830994
Validation loss: 1.7190636486135504

Epoch: 5| Step: 6
Training loss: 1.2670347690582275
Validation loss: 1.677278059785084

Epoch: 5| Step: 7
Training loss: 1.0980160236358643
Validation loss: 1.7367956125608055

Epoch: 5| Step: 8
Training loss: 0.8020336031913757
Validation loss: 1.755485116794545

Epoch: 5| Step: 9
Training loss: 1.1860339641571045
Validation loss: 1.7795202334721882

Epoch: 5| Step: 10
Training loss: 1.4765841960906982
Validation loss: 1.7475608061718684

Epoch: 520| Step: 0
Training loss: 0.9621278643608093
Validation loss: 1.6702632481052029

Epoch: 5| Step: 1
Training loss: 1.159057378768921
Validation loss: 1.7864442307461974

Epoch: 5| Step: 2
Training loss: 0.9831595420837402
Validation loss: 1.7494594948266142

Epoch: 5| Step: 3
Training loss: 0.8539690971374512
Validation loss: 1.7663801998220465

Epoch: 5| Step: 4
Training loss: 0.8137885332107544
Validation loss: 1.786366364007355

Epoch: 5| Step: 5
Training loss: 1.1715234518051147
Validation loss: 1.8032089228271155

Epoch: 5| Step: 6
Training loss: 0.8930456042289734
Validation loss: 1.7551396098188174

Epoch: 5| Step: 7
Training loss: 1.44570791721344
Validation loss: 1.7719250366251955

Epoch: 5| Step: 8
Training loss: 1.3901121616363525
Validation loss: 1.7576141690695157

Epoch: 5| Step: 9
Training loss: 0.7866120338439941
Validation loss: 1.7846380356819398

Epoch: 5| Step: 10
Training loss: 0.6715371608734131
Validation loss: 1.784191152100922

Epoch: 521| Step: 0
Training loss: 1.0491466522216797
Validation loss: 1.727241152076311

Epoch: 5| Step: 1
Training loss: 0.9870845675468445
Validation loss: 1.7804467165341942

Epoch: 5| Step: 2
Training loss: 0.9624977111816406
Validation loss: 1.7217649811057634

Epoch: 5| Step: 3
Training loss: 0.7445514798164368
Validation loss: 1.7089501247611096

Epoch: 5| Step: 4
Training loss: 1.1974595785140991
Validation loss: 1.6956273125063988

Epoch: 5| Step: 5
Training loss: 1.1679809093475342
Validation loss: 1.6829419174501974

Epoch: 5| Step: 6
Training loss: 0.9222022891044617
Validation loss: 1.705284700598768

Epoch: 5| Step: 7
Training loss: 1.046319603919983
Validation loss: 1.7174008302791144

Epoch: 5| Step: 8
Training loss: 1.1935737133026123
Validation loss: 1.731036506673341

Epoch: 5| Step: 9
Training loss: 1.0787408351898193
Validation loss: 1.7660755867599158

Epoch: 5| Step: 10
Training loss: 0.987414538860321
Validation loss: 1.7326699226133284

Epoch: 522| Step: 0
Training loss: 1.0425034761428833
Validation loss: 1.7872813196592434

Epoch: 5| Step: 1
Training loss: 1.0251518487930298
Validation loss: 1.74820738966747

Epoch: 5| Step: 2
Training loss: 1.005298137664795
Validation loss: 1.8396496670220488

Epoch: 5| Step: 3
Training loss: 0.45792800188064575
Validation loss: 1.763742869900119

Epoch: 5| Step: 4
Training loss: 0.7143093943595886
Validation loss: 1.7991304269400976

Epoch: 5| Step: 5
Training loss: 1.341470718383789
Validation loss: 1.8405942583596835

Epoch: 5| Step: 6
Training loss: 1.476938009262085
Validation loss: 1.7728388117205711

Epoch: 5| Step: 7
Training loss: 0.9896309971809387
Validation loss: 1.7425097086096322

Epoch: 5| Step: 8
Training loss: 1.063899278640747
Validation loss: 1.7027829270209036

Epoch: 5| Step: 9
Training loss: 1.2020304203033447
Validation loss: 1.7530446232006114

Epoch: 5| Step: 10
Training loss: 0.88094562292099
Validation loss: 1.7990846569820116

Epoch: 523| Step: 0
Training loss: 1.6149728298187256
Validation loss: 1.740488011349914

Epoch: 5| Step: 1
Training loss: 0.8826351165771484
Validation loss: 1.7769421069852767

Epoch: 5| Step: 2
Training loss: 1.0131347179412842
Validation loss: 1.741441729248211

Epoch: 5| Step: 3
Training loss: 0.7147046327590942
Validation loss: 1.7453843162905784

Epoch: 5| Step: 4
Training loss: 1.3321222066879272
Validation loss: 1.7803644672516854

Epoch: 5| Step: 5
Training loss: 0.7604303359985352
Validation loss: 1.7264070831319338

Epoch: 5| Step: 6
Training loss: 0.7353318929672241
Validation loss: 1.7717306485740087

Epoch: 5| Step: 7
Training loss: 0.8397372961044312
Validation loss: 1.668102938641784

Epoch: 5| Step: 8
Training loss: 1.0881590843200684
Validation loss: 1.77694579093687

Epoch: 5| Step: 9
Training loss: 1.0953171253204346
Validation loss: 1.7211753860596688

Epoch: 5| Step: 10
Training loss: 1.073858380317688
Validation loss: 1.679201542690236

Epoch: 524| Step: 0
Training loss: 1.1679213047027588
Validation loss: 1.767931725389214

Epoch: 5| Step: 1
Training loss: 0.6301947832107544
Validation loss: 1.7473275251286005

Epoch: 5| Step: 2
Training loss: 1.19490647315979
Validation loss: 1.7499591022409418

Epoch: 5| Step: 3
Training loss: 1.2701107263565063
Validation loss: 1.7034077080347205

Epoch: 5| Step: 4
Training loss: 1.086917757987976
Validation loss: 1.6754492764831872

Epoch: 5| Step: 5
Training loss: 1.438555121421814
Validation loss: 1.7083277433149275

Epoch: 5| Step: 6
Training loss: 0.8188421130180359
Validation loss: 1.7269595848616732

Epoch: 5| Step: 7
Training loss: 0.8355865478515625
Validation loss: 1.722518782461843

Epoch: 5| Step: 8
Training loss: 0.8640700578689575
Validation loss: 1.6827087017797655

Epoch: 5| Step: 9
Training loss: 1.0353851318359375
Validation loss: 1.7135721137446742

Epoch: 5| Step: 10
Training loss: 1.0413942337036133
Validation loss: 1.7385546622737762

Epoch: 525| Step: 0
Training loss: 1.114992618560791
Validation loss: 1.7992247253335931

Epoch: 5| Step: 1
Training loss: 1.0971527099609375
Validation loss: 1.7193566150562738

Epoch: 5| Step: 2
Training loss: 0.8033465147018433
Validation loss: 1.7639649901338803

Epoch: 5| Step: 3
Training loss: 0.7992218136787415
Validation loss: 1.6762887649638678

Epoch: 5| Step: 4
Training loss: 1.1935691833496094
Validation loss: 1.707555736905785

Epoch: 5| Step: 5
Training loss: 0.8007866740226746
Validation loss: 1.6748241250232985

Epoch: 5| Step: 6
Training loss: 0.9758567810058594
Validation loss: 1.7544347496442898

Epoch: 5| Step: 7
Training loss: 1.2086422443389893
Validation loss: 1.7207143768187492

Epoch: 5| Step: 8
Training loss: 1.064839243888855
Validation loss: 1.7543095939902849

Epoch: 5| Step: 9
Training loss: 1.1488523483276367
Validation loss: 1.747119516454717

Epoch: 5| Step: 10
Training loss: 1.325011134147644
Validation loss: 1.74379547180668

Epoch: 526| Step: 0
Training loss: 0.8765091896057129
Validation loss: 1.7417549061518844

Epoch: 5| Step: 1
Training loss: 0.8995523452758789
Validation loss: 1.7459321073306504

Epoch: 5| Step: 2
Training loss: 0.9554352760314941
Validation loss: 1.7600753845707062

Epoch: 5| Step: 3
Training loss: 0.976065456867218
Validation loss: 1.7282666096123316

Epoch: 5| Step: 4
Training loss: 0.7975196838378906
Validation loss: 1.7592926268936486

Epoch: 5| Step: 5
Training loss: 1.6921123266220093
Validation loss: 1.7969880821884319

Epoch: 5| Step: 6
Training loss: 0.6796520352363586
Validation loss: 1.7609885931015015

Epoch: 5| Step: 7
Training loss: 0.677075982093811
Validation loss: 1.7814832297704553

Epoch: 5| Step: 8
Training loss: 1.510627031326294
Validation loss: 1.7806056378990092

Epoch: 5| Step: 9
Training loss: 0.7088673710823059
Validation loss: 1.7945382415607412

Epoch: 5| Step: 10
Training loss: 1.2657997608184814
Validation loss: 1.7325393173002428

Epoch: 527| Step: 0
Training loss: 1.0377994775772095
Validation loss: 1.7732831521700787

Epoch: 5| Step: 1
Training loss: 0.7506664991378784
Validation loss: 1.7295126543250134

Epoch: 5| Step: 2
Training loss: 1.4735751152038574
Validation loss: 1.7295555888965566

Epoch: 5| Step: 3
Training loss: 0.7584699392318726
Validation loss: 1.6871440461886826

Epoch: 5| Step: 4
Training loss: 1.1676689386367798
Validation loss: 1.6944176650816394

Epoch: 5| Step: 5
Training loss: 0.6720758676528931
Validation loss: 1.7676670038571922

Epoch: 5| Step: 6
Training loss: 0.8679670095443726
Validation loss: 1.7058118620226461

Epoch: 5| Step: 7
Training loss: 1.1534395217895508
Validation loss: 1.6892290602448166

Epoch: 5| Step: 8
Training loss: 0.9780198931694031
Validation loss: 1.7566656809981152

Epoch: 5| Step: 9
Training loss: 1.1266570091247559
Validation loss: 1.7677233231964933

Epoch: 5| Step: 10
Training loss: 1.1181856393814087
Validation loss: 1.826052070945822

Epoch: 528| Step: 0
Training loss: 1.1019294261932373
Validation loss: 1.7909556409364105

Epoch: 5| Step: 1
Training loss: 0.8548682928085327
Validation loss: 1.7668983654309345

Epoch: 5| Step: 2
Training loss: 1.2174291610717773
Validation loss: 1.7851578804754442

Epoch: 5| Step: 3
Training loss: 1.062249779701233
Validation loss: 1.7936258649313321

Epoch: 5| Step: 4
Training loss: 0.807262122631073
Validation loss: 1.7764163555637482

Epoch: 5| Step: 5
Training loss: 0.33799758553504944
Validation loss: 1.7313746008821713

Epoch: 5| Step: 6
Training loss: 1.1538511514663696
Validation loss: 1.6908445076275898

Epoch: 5| Step: 7
Training loss: 0.9879485368728638
Validation loss: 1.7466422486048874

Epoch: 5| Step: 8
Training loss: 0.8776095509529114
Validation loss: 1.7067779097505795

Epoch: 5| Step: 9
Training loss: 1.358612298965454
Validation loss: 1.6970591160558886

Epoch: 5| Step: 10
Training loss: 1.5310826301574707
Validation loss: 1.738767267555319

Epoch: 529| Step: 0
Training loss: 0.8258916735649109
Validation loss: 1.7506987023097214

Epoch: 5| Step: 1
Training loss: 1.118945837020874
Validation loss: 1.7939964340579124

Epoch: 5| Step: 2
Training loss: 0.7043460011482239
Validation loss: 1.6936964937435683

Epoch: 5| Step: 3
Training loss: 0.8881181478500366
Validation loss: 1.723083270493374

Epoch: 5| Step: 4
Training loss: 1.296584129333496
Validation loss: 1.7653632843366234

Epoch: 5| Step: 5
Training loss: 1.5216543674468994
Validation loss: 1.731206573465819

Epoch: 5| Step: 6
Training loss: 0.9275824427604675
Validation loss: 1.7373286883036296

Epoch: 5| Step: 7
Training loss: 1.1624224185943604
Validation loss: 1.717770758495536

Epoch: 5| Step: 8
Training loss: 0.9613077044487
Validation loss: 1.7683614607780211

Epoch: 5| Step: 9
Training loss: 0.9190536737442017
Validation loss: 1.7456597640950193

Epoch: 5| Step: 10
Training loss: 1.0785373449325562
Validation loss: 1.7560583032587522

Epoch: 530| Step: 0
Training loss: 0.7078479528427124
Validation loss: 1.7754589139774282

Epoch: 5| Step: 1
Training loss: 0.8299872279167175
Validation loss: 1.766674300675751

Epoch: 5| Step: 2
Training loss: 1.218935251235962
Validation loss: 1.668376322715513

Epoch: 5| Step: 3
Training loss: 1.0423619747161865
Validation loss: 1.7299238417738227

Epoch: 5| Step: 4
Training loss: 0.836016058921814
Validation loss: 1.7036708606186735

Epoch: 5| Step: 5
Training loss: 0.9967409372329712
Validation loss: 1.7173201601992372

Epoch: 5| Step: 6
Training loss: 0.6669110655784607
Validation loss: 1.685603735267475

Epoch: 5| Step: 7
Training loss: 1.0579261779785156
Validation loss: 1.8054813569591892

Epoch: 5| Step: 8
Training loss: 1.0277931690216064
Validation loss: 1.728919139472387

Epoch: 5| Step: 9
Training loss: 1.2319438457489014
Validation loss: 1.6931601288498088

Epoch: 5| Step: 10
Training loss: 1.463007926940918
Validation loss: 1.7512308448873541

Epoch: 531| Step: 0
Training loss: 0.8633753657341003
Validation loss: 1.707165172023158

Epoch: 5| Step: 1
Training loss: 0.8170603513717651
Validation loss: 1.7478719270357521

Epoch: 5| Step: 2
Training loss: 0.9369694590568542
Validation loss: 1.8002855175284929

Epoch: 5| Step: 3
Training loss: 1.27497398853302
Validation loss: 1.8224071661631267

Epoch: 5| Step: 4
Training loss: 0.9779692888259888
Validation loss: 1.6885567172881095

Epoch: 5| Step: 5
Training loss: 1.080370306968689
Validation loss: 1.7114842373837706

Epoch: 5| Step: 6
Training loss: 1.2686080932617188
Validation loss: 1.7322906960723221

Epoch: 5| Step: 7
Training loss: 1.4374977350234985
Validation loss: 1.742113660740596

Epoch: 5| Step: 8
Training loss: 0.6816186904907227
Validation loss: 1.7197137391695412

Epoch: 5| Step: 9
Training loss: 1.0401782989501953
Validation loss: 1.7532037419657553

Epoch: 5| Step: 10
Training loss: 0.6794324517250061
Validation loss: 1.755286180844871

Epoch: 532| Step: 0
Training loss: 1.0967851877212524
Validation loss: 1.7503287330750497

Epoch: 5| Step: 1
Training loss: 1.2577009201049805
Validation loss: 1.6399975899727113

Epoch: 5| Step: 2
Training loss: 1.0729855298995972
Validation loss: 1.79027130270517

Epoch: 5| Step: 3
Training loss: 1.231086015701294
Validation loss: 1.769843037410449

Epoch: 5| Step: 4
Training loss: 1.1527988910675049
Validation loss: 1.776027858898204

Epoch: 5| Step: 5
Training loss: 1.1066893339157104
Validation loss: 1.7710345547686341

Epoch: 5| Step: 6
Training loss: 0.8350416421890259
Validation loss: 1.781496004391742

Epoch: 5| Step: 7
Training loss: 0.9259177446365356
Validation loss: 1.7209419345342984

Epoch: 5| Step: 8
Training loss: 0.917233943939209
Validation loss: 1.721699865915442

Epoch: 5| Step: 9
Training loss: 1.0654315948486328
Validation loss: 1.7293395521820232

Epoch: 5| Step: 10
Training loss: 0.5795295834541321
Validation loss: 1.6902420225963797

Epoch: 533| Step: 0
Training loss: 1.289487600326538
Validation loss: 1.738724535511386

Epoch: 5| Step: 1
Training loss: 1.219477891921997
Validation loss: 1.7237824009310814

Epoch: 5| Step: 2
Training loss: 1.0733200311660767
Validation loss: 1.7305006378440446

Epoch: 5| Step: 3
Training loss: 1.1373291015625
Validation loss: 1.7262267604950936

Epoch: 5| Step: 4
Training loss: 1.2178536653518677
Validation loss: 1.705585564336469

Epoch: 5| Step: 5
Training loss: 0.6865100264549255
Validation loss: 1.6900568726242229

Epoch: 5| Step: 6
Training loss: 0.9854095578193665
Validation loss: 1.731303479081841

Epoch: 5| Step: 7
Training loss: 0.6629608869552612
Validation loss: 1.7231822706037951

Epoch: 5| Step: 8
Training loss: 1.0473648309707642
Validation loss: 1.7196266830608409

Epoch: 5| Step: 9
Training loss: 0.7790235280990601
Validation loss: 1.7328034549631097

Epoch: 5| Step: 10
Training loss: 1.1109451055526733
Validation loss: 1.6936065022663405

Epoch: 534| Step: 0
Training loss: 1.0477206707000732
Validation loss: 1.6984754172704553

Epoch: 5| Step: 1
Training loss: 0.5674328804016113
Validation loss: 1.7911748898926603

Epoch: 5| Step: 2
Training loss: 1.3367468118667603
Validation loss: 1.7616755629098544

Epoch: 5| Step: 3
Training loss: 0.6774595379829407
Validation loss: 1.7358059690844627

Epoch: 5| Step: 4
Training loss: 0.6212387084960938
Validation loss: 1.7607754545827066

Epoch: 5| Step: 5
Training loss: 1.5441908836364746
Validation loss: 1.7340807414823962

Epoch: 5| Step: 6
Training loss: 1.220392107963562
Validation loss: 1.7962091379268195

Epoch: 5| Step: 7
Training loss: 0.9903122782707214
Validation loss: 1.710128063796669

Epoch: 5| Step: 8
Training loss: 0.8938156366348267
Validation loss: 1.7610969851093907

Epoch: 5| Step: 9
Training loss: 1.0934467315673828
Validation loss: 1.7027103170271842

Epoch: 5| Step: 10
Training loss: 0.8947198390960693
Validation loss: 1.6756396985823108

Epoch: 535| Step: 0
Training loss: 0.8325098156929016
Validation loss: 1.7158740310258762

Epoch: 5| Step: 1
Training loss: 1.0968624353408813
Validation loss: 1.7010303389641546

Epoch: 5| Step: 2
Training loss: 0.9299473762512207
Validation loss: 1.750476324430076

Epoch: 5| Step: 3
Training loss: 0.9003175497055054
Validation loss: 1.750416487775823

Epoch: 5| Step: 4
Training loss: 1.0796821117401123
Validation loss: 1.6830762086376068

Epoch: 5| Step: 5
Training loss: 1.2243565320968628
Validation loss: 1.7011989226905249

Epoch: 5| Step: 6
Training loss: 1.230696678161621
Validation loss: 1.7583739847265265

Epoch: 5| Step: 7
Training loss: 1.0847864151000977
Validation loss: 1.78106342592547

Epoch: 5| Step: 8
Training loss: 0.7795024514198303
Validation loss: 1.762315175866568

Epoch: 5| Step: 9
Training loss: 0.9352492094039917
Validation loss: 1.7145586244521602

Epoch: 5| Step: 10
Training loss: 0.5846219062805176
Validation loss: 1.7061929151576052

Epoch: 536| Step: 0
Training loss: 1.346581220626831
Validation loss: 1.7028147200102448

Epoch: 5| Step: 1
Training loss: 1.0457526445388794
Validation loss: 1.70363792937289

Epoch: 5| Step: 2
Training loss: 0.8044258952140808
Validation loss: 1.717359863301759

Epoch: 5| Step: 3
Training loss: 0.6934313178062439
Validation loss: 1.719197614218599

Epoch: 5| Step: 4
Training loss: 0.9427547454833984
Validation loss: 1.7056264826046523

Epoch: 5| Step: 5
Training loss: 1.0026938915252686
Validation loss: 1.7616133459152714

Epoch: 5| Step: 6
Training loss: 1.0454895496368408
Validation loss: 1.704527489600643

Epoch: 5| Step: 7
Training loss: 1.0618048906326294
Validation loss: 1.7816925869193128

Epoch: 5| Step: 8
Training loss: 1.2488311529159546
Validation loss: 1.7700734933217366

Epoch: 5| Step: 9
Training loss: 0.8464815020561218
Validation loss: 1.7499149153309483

Epoch: 5| Step: 10
Training loss: 0.8798598051071167
Validation loss: 1.72455713441295

Epoch: 537| Step: 0
Training loss: 1.4188718795776367
Validation loss: 1.7548342930373324

Epoch: 5| Step: 1
Training loss: 1.3082494735717773
Validation loss: 1.7319908911182034

Epoch: 5| Step: 2
Training loss: 0.9683036804199219
Validation loss: 1.7419470920357654

Epoch: 5| Step: 3
Training loss: 1.0800230503082275
Validation loss: 1.7256038752935265

Epoch: 5| Step: 4
Training loss: 1.4378983974456787
Validation loss: 1.7413052807572067

Epoch: 5| Step: 5
Training loss: 0.7075238227844238
Validation loss: 1.780852463937575

Epoch: 5| Step: 6
Training loss: 0.5819156169891357
Validation loss: 1.741393361040341

Epoch: 5| Step: 7
Training loss: 1.239886999130249
Validation loss: 1.715988072015906

Epoch: 5| Step: 8
Training loss: 0.8082523345947266
Validation loss: 1.7475680343566402

Epoch: 5| Step: 9
Training loss: 0.5852652788162231
Validation loss: 1.7528314718636133

Epoch: 5| Step: 10
Training loss: 0.5681772828102112
Validation loss: 1.7099885812369726

Epoch: 538| Step: 0
Training loss: 0.5904510021209717
Validation loss: 1.687725523466705

Epoch: 5| Step: 1
Training loss: 0.8535664677619934
Validation loss: 1.6954374633809572

Epoch: 5| Step: 2
Training loss: 0.9142757654190063
Validation loss: 1.739423313448506

Epoch: 5| Step: 3
Training loss: 0.775558352470398
Validation loss: 1.7667833989666355

Epoch: 5| Step: 4
Training loss: 0.6631885766983032
Validation loss: 1.723961914739301

Epoch: 5| Step: 5
Training loss: 0.6999293565750122
Validation loss: 1.7429566870453537

Epoch: 5| Step: 6
Training loss: 1.0365898609161377
Validation loss: 1.788456057989469

Epoch: 5| Step: 7
Training loss: 0.8825389742851257
Validation loss: 1.710770747994864

Epoch: 5| Step: 8
Training loss: 1.744852066040039
Validation loss: 1.7608226165976575

Epoch: 5| Step: 9
Training loss: 1.1890943050384521
Validation loss: 1.7513570734249648

Epoch: 5| Step: 10
Training loss: 1.169929027557373
Validation loss: 1.7694677396487164

Epoch: 539| Step: 0
Training loss: 0.8878906965255737
Validation loss: 1.7392776576421594

Epoch: 5| Step: 1
Training loss: 1.4415992498397827
Validation loss: 1.7829797729369132

Epoch: 5| Step: 2
Training loss: 1.0418113470077515
Validation loss: 1.7384705005153533

Epoch: 5| Step: 3
Training loss: 0.8747841715812683
Validation loss: 1.761013529633963

Epoch: 5| Step: 4
Training loss: 1.2935068607330322
Validation loss: 1.680315790637847

Epoch: 5| Step: 5
Training loss: 0.636810302734375
Validation loss: 1.7102079494025118

Epoch: 5| Step: 6
Training loss: 0.998744010925293
Validation loss: 1.7466044195236698

Epoch: 5| Step: 7
Training loss: 1.034703254699707
Validation loss: 1.7112237791861258

Epoch: 5| Step: 8
Training loss: 0.6185778975486755
Validation loss: 1.7415517171223958

Epoch: 5| Step: 9
Training loss: 1.020052194595337
Validation loss: 1.7158161030020764

Epoch: 5| Step: 10
Training loss: 1.216295599937439
Validation loss: 1.7574063219049925

Epoch: 540| Step: 0
Training loss: 1.1857813596725464
Validation loss: 1.7792923437651766

Epoch: 5| Step: 1
Training loss: 0.8350197672843933
Validation loss: 1.728143568961851

Epoch: 5| Step: 2
Training loss: 0.5613569021224976
Validation loss: 1.7327550841915993

Epoch: 5| Step: 3
Training loss: 1.0807921886444092
Validation loss: 1.7627657844174294

Epoch: 5| Step: 4
Training loss: 1.2154518365859985
Validation loss: 1.7373632025975052

Epoch: 5| Step: 5
Training loss: 0.9893401265144348
Validation loss: 1.7038032970120829

Epoch: 5| Step: 6
Training loss: 1.3107330799102783
Validation loss: 1.7528155375552434

Epoch: 5| Step: 7
Training loss: 0.881648063659668
Validation loss: 1.7583581927002117

Epoch: 5| Step: 8
Training loss: 0.661131739616394
Validation loss: 1.7174719264430385

Epoch: 5| Step: 9
Training loss: 1.234850525856018
Validation loss: 1.7593975579866798

Epoch: 5| Step: 10
Training loss: 1.3367187976837158
Validation loss: 1.7495460176980624

Epoch: 541| Step: 0
Training loss: 1.8365478515625
Validation loss: 1.760275056285243

Epoch: 5| Step: 1
Training loss: 0.6886819005012512
Validation loss: 1.7865277650535747

Epoch: 5| Step: 2
Training loss: 0.9569019079208374
Validation loss: 1.7927467297482234

Epoch: 5| Step: 3
Training loss: 0.8447405099868774
Validation loss: 1.7934734231682234

Epoch: 5| Step: 4
Training loss: 0.684127151966095
Validation loss: 1.7452124164950462

Epoch: 5| Step: 5
Training loss: 0.9188166856765747
Validation loss: 1.732036800794704

Epoch: 5| Step: 6
Training loss: 1.0130720138549805
Validation loss: 1.7149784821335987

Epoch: 5| Step: 7
Training loss: 1.0031960010528564
Validation loss: 1.6821339232947237

Epoch: 5| Step: 8
Training loss: 0.9020277857780457
Validation loss: 1.7160972920797204

Epoch: 5| Step: 9
Training loss: 1.3036553859710693
Validation loss: 1.7329229859895603

Epoch: 5| Step: 10
Training loss: 1.042560338973999
Validation loss: 1.736765802547496

Epoch: 542| Step: 0
Training loss: 1.181786298751831
Validation loss: 1.7008763179984143

Epoch: 5| Step: 1
Training loss: 0.9330630302429199
Validation loss: 1.7530452910289969

Epoch: 5| Step: 2
Training loss: 0.6004047989845276
Validation loss: 1.7079441893485285

Epoch: 5| Step: 3
Training loss: 0.829321563243866
Validation loss: 1.7252900997797649

Epoch: 5| Step: 4
Training loss: 1.2074825763702393
Validation loss: 1.7457766814898419

Epoch: 5| Step: 5
Training loss: 1.3056278228759766
Validation loss: 1.6748935766117548

Epoch: 5| Step: 6
Training loss: 1.075014352798462
Validation loss: 1.723961268701861

Epoch: 5| Step: 7
Training loss: 1.2131346464157104
Validation loss: 1.7425982721390263

Epoch: 5| Step: 8
Training loss: 1.2282832860946655
Validation loss: 1.747139141123782

Epoch: 5| Step: 9
Training loss: 0.8893595933914185
Validation loss: 1.7511486981504707

Epoch: 5| Step: 10
Training loss: 0.840110719203949
Validation loss: 1.774373459559615

Epoch: 543| Step: 0
Training loss: 1.447604775428772
Validation loss: 1.769186915889863

Epoch: 5| Step: 1
Training loss: 1.189963698387146
Validation loss: 1.7606520652770996

Epoch: 5| Step: 2
Training loss: 0.9178141355514526
Validation loss: 1.7739885519909602

Epoch: 5| Step: 3
Training loss: 1.5214130878448486
Validation loss: 1.7584348942643853

Epoch: 5| Step: 4
Training loss: 0.8088777661323547
Validation loss: 1.7075509819933163

Epoch: 5| Step: 5
Training loss: 0.8777597546577454
Validation loss: 1.7796954198550152

Epoch: 5| Step: 6
Training loss: 1.000641107559204
Validation loss: 1.7576671800305765

Epoch: 5| Step: 7
Training loss: 0.6934992671012878
Validation loss: 1.7025837500890095

Epoch: 5| Step: 8
Training loss: 0.8819997906684875
Validation loss: 1.7190835681012882

Epoch: 5| Step: 9
Training loss: 0.8633516430854797
Validation loss: 1.705561416123503

Epoch: 5| Step: 10
Training loss: 0.5165084600448608
Validation loss: 1.7539677145660564

Epoch: 544| Step: 0
Training loss: 0.8224247097969055
Validation loss: 1.710952716488992

Epoch: 5| Step: 1
Training loss: 0.8532564043998718
Validation loss: 1.6607954271378056

Epoch: 5| Step: 2
Training loss: 0.9303536415100098
Validation loss: 1.718623850935249

Epoch: 5| Step: 3
Training loss: 1.0604102611541748
Validation loss: 1.6702256151424941

Epoch: 5| Step: 4
Training loss: 1.0679051876068115
Validation loss: 1.6962607791346889

Epoch: 5| Step: 5
Training loss: 0.6475702524185181
Validation loss: 1.7186886456704908

Epoch: 5| Step: 6
Training loss: 1.4570586681365967
Validation loss: 1.718903910729193

Epoch: 5| Step: 7
Training loss: 1.047710657119751
Validation loss: 1.753927335944227

Epoch: 5| Step: 8
Training loss: 0.8531641960144043
Validation loss: 1.7365920261670185

Epoch: 5| Step: 9
Training loss: 1.3935749530792236
Validation loss: 1.7150951777735064

Epoch: 5| Step: 10
Training loss: 0.628041684627533
Validation loss: 1.7225815865301317

Epoch: 545| Step: 0
Training loss: 0.8543112874031067
Validation loss: 1.7319049771114061

Epoch: 5| Step: 1
Training loss: 0.9643205404281616
Validation loss: 1.7073171164399834

Epoch: 5| Step: 2
Training loss: 1.1382232904434204
Validation loss: 1.654345126562221

Epoch: 5| Step: 3
Training loss: 1.658057451248169
Validation loss: 1.7096645178333405

Epoch: 5| Step: 4
Training loss: 0.7850605249404907
Validation loss: 1.698202822798042

Epoch: 5| Step: 5
Training loss: 0.9270873069763184
Validation loss: 1.6960274916823193

Epoch: 5| Step: 6
Training loss: 0.70772385597229
Validation loss: 1.7729502083152853

Epoch: 5| Step: 7
Training loss: 1.0215564966201782
Validation loss: 1.7369237663925334

Epoch: 5| Step: 8
Training loss: 0.8151222467422485
Validation loss: 1.7229688449572491

Epoch: 5| Step: 9
Training loss: 0.8005939722061157
Validation loss: 1.7580025977985834

Epoch: 5| Step: 10
Training loss: 1.0496492385864258
Validation loss: 1.7526964295294978

Epoch: 546| Step: 0
Training loss: 0.9595922231674194
Validation loss: 1.6816631799103112

Epoch: 5| Step: 1
Training loss: 0.9202785491943359
Validation loss: 1.7327716991465578

Epoch: 5| Step: 2
Training loss: 0.7470162510871887
Validation loss: 1.709767556959583

Epoch: 5| Step: 3
Training loss: 0.9460998773574829
Validation loss: 1.7498995104143698

Epoch: 5| Step: 4
Training loss: 0.7578092217445374
Validation loss: 1.812176481370003

Epoch: 5| Step: 5
Training loss: 1.05666184425354
Validation loss: 1.699491072726506

Epoch: 5| Step: 6
Training loss: 1.080444097518921
Validation loss: 1.671934881517964

Epoch: 5| Step: 7
Training loss: 1.0902270078659058
Validation loss: 1.7519492000661872

Epoch: 5| Step: 8
Training loss: 1.0454702377319336
Validation loss: 1.70654760765773

Epoch: 5| Step: 9
Training loss: 0.9017490148544312
Validation loss: 1.7152772667587444

Epoch: 5| Step: 10
Training loss: 0.8940723538398743
Validation loss: 1.7683117543497393

Epoch: 547| Step: 0
Training loss: 0.8535602688789368
Validation loss: 1.7634687590342697

Epoch: 5| Step: 1
Training loss: 0.610795795917511
Validation loss: 1.743740967524949

Epoch: 5| Step: 2
Training loss: 0.7748060822486877
Validation loss: 1.7209020660769554

Epoch: 5| Step: 3
Training loss: 0.9690387845039368
Validation loss: 1.6919309810925556

Epoch: 5| Step: 4
Training loss: 1.17495596408844
Validation loss: 1.7081173235370266

Epoch: 5| Step: 5
Training loss: 0.9902350306510925
Validation loss: 1.7389384790133404

Epoch: 5| Step: 6
Training loss: 1.7766205072402954
Validation loss: 1.769932686641652

Epoch: 5| Step: 7
Training loss: 0.8451153039932251
Validation loss: 1.8254277193418114

Epoch: 5| Step: 8
Training loss: 0.8588663935661316
Validation loss: 1.6945222385468022

Epoch: 5| Step: 9
Training loss: 1.0596405267715454
Validation loss: 1.747830916476506

Epoch: 5| Step: 10
Training loss: 0.9282801151275635
Validation loss: 1.7013376861490228

Epoch: 548| Step: 0
Training loss: 0.9569056630134583
Validation loss: 1.6896500972009474

Epoch: 5| Step: 1
Training loss: 0.6010643243789673
Validation loss: 1.7687770910160516

Epoch: 5| Step: 2
Training loss: 1.0228922367095947
Validation loss: 1.7530863925974856

Epoch: 5| Step: 3
Training loss: 0.7456080317497253
Validation loss: 1.7408401299548406

Epoch: 5| Step: 4
Training loss: 1.4557908773422241
Validation loss: 1.7530864438702982

Epoch: 5| Step: 5
Training loss: 0.6412707567214966
Validation loss: 1.710344886267057

Epoch: 5| Step: 6
Training loss: 0.8645482063293457
Validation loss: 1.7193604028353127

Epoch: 5| Step: 7
Training loss: 1.1846933364868164
Validation loss: 1.750351837886277

Epoch: 5| Step: 8
Training loss: 1.0005722045898438
Validation loss: 1.7122428519751436

Epoch: 5| Step: 9
Training loss: 1.167008876800537
Validation loss: 1.7431935661582536

Epoch: 5| Step: 10
Training loss: 1.084749460220337
Validation loss: 1.7596109426149757

Epoch: 549| Step: 0
Training loss: 1.404658555984497
Validation loss: 1.7061107671389015

Epoch: 5| Step: 1
Training loss: 0.9248613119125366
Validation loss: 1.749707677031076

Epoch: 5| Step: 2
Training loss: 0.7732213139533997
Validation loss: 1.7737901608149211

Epoch: 5| Step: 3
Training loss: 0.9022678136825562
Validation loss: 1.7274426798666678

Epoch: 5| Step: 4
Training loss: 1.1909828186035156
Validation loss: 1.7402597986241823

Epoch: 5| Step: 5
Training loss: 0.7538874745368958
Validation loss: 1.7258081679703088

Epoch: 5| Step: 6
Training loss: 0.7933710217475891
Validation loss: 1.7396199959580616

Epoch: 5| Step: 7
Training loss: 1.1613337993621826
Validation loss: 1.7934298989593342

Epoch: 5| Step: 8
Training loss: 1.0835144519805908
Validation loss: 1.6986078613547868

Epoch: 5| Step: 9
Training loss: 0.8559303283691406
Validation loss: 1.6992487048590055

Epoch: 5| Step: 10
Training loss: 0.8041386604309082
Validation loss: 1.7149832248687744

Epoch: 550| Step: 0
Training loss: 0.5867880582809448
Validation loss: 1.7611388416700466

Epoch: 5| Step: 1
Training loss: 1.2527706623077393
Validation loss: 1.7288001404013684

Epoch: 5| Step: 2
Training loss: 0.8155704736709595
Validation loss: 1.7484624244833504

Epoch: 5| Step: 3
Training loss: 1.3487040996551514
Validation loss: 1.7706466105676466

Epoch: 5| Step: 4
Training loss: 1.0929319858551025
Validation loss: 1.697577025300713

Epoch: 5| Step: 5
Training loss: 0.9637752771377563
Validation loss: 1.7126186393922376

Epoch: 5| Step: 6
Training loss: 1.0825365781784058
Validation loss: 1.740075442098802

Epoch: 5| Step: 7
Training loss: 0.6507929563522339
Validation loss: 1.736056145801339

Epoch: 5| Step: 8
Training loss: 0.9339668154716492
Validation loss: 1.7066597477082284

Epoch: 5| Step: 9
Training loss: 1.0371983051300049
Validation loss: 1.8056433969928372

Epoch: 5| Step: 10
Training loss: 1.3738075494766235
Validation loss: 1.7307026309351767

Epoch: 551| Step: 0
Training loss: 0.7110418081283569
Validation loss: 1.7221392162384526

Epoch: 5| Step: 1
Training loss: 1.2127548456192017
Validation loss: 1.7970339277739167

Epoch: 5| Step: 2
Training loss: 1.4368422031402588
Validation loss: 1.6977990570888724

Epoch: 5| Step: 3
Training loss: 0.7657930850982666
Validation loss: 1.7897280185453353

Epoch: 5| Step: 4
Training loss: 0.7293572425842285
Validation loss: 1.7423259853034891

Epoch: 5| Step: 5
Training loss: 0.8857227563858032
Validation loss: 1.7629587688753683

Epoch: 5| Step: 6
Training loss: 0.8125206828117371
Validation loss: 1.7865640104457896

Epoch: 5| Step: 7
Training loss: 1.186145305633545
Validation loss: 1.665463206588581

Epoch: 5| Step: 8
Training loss: 1.145134687423706
Validation loss: 1.7027125294490526

Epoch: 5| Step: 9
Training loss: 0.9892219305038452
Validation loss: 1.7086047228946482

Epoch: 5| Step: 10
Training loss: 1.0407025814056396
Validation loss: 1.7392305763818885

Epoch: 552| Step: 0
Training loss: 1.0071101188659668
Validation loss: 1.7122440056134296

Epoch: 5| Step: 1
Training loss: 0.7215410470962524
Validation loss: 1.6782455469972344

Epoch: 5| Step: 2
Training loss: 1.0654672384262085
Validation loss: 1.7229926842515186

Epoch: 5| Step: 3
Training loss: 0.8272750973701477
Validation loss: 1.7262378790045296

Epoch: 5| Step: 4
Training loss: 0.8709651231765747
Validation loss: 1.674144511581749

Epoch: 5| Step: 5
Training loss: 0.9291325807571411
Validation loss: 1.715385462648125

Epoch: 5| Step: 6
Training loss: 0.6554263234138489
Validation loss: 1.7334715448400027

Epoch: 5| Step: 7
Training loss: 1.1840064525604248
Validation loss: 1.7406178341116956

Epoch: 5| Step: 8
Training loss: 1.5843372344970703
Validation loss: 1.7111018832011888

Epoch: 5| Step: 9
Training loss: 1.0651719570159912
Validation loss: 1.7388166842922088

Epoch: 5| Step: 10
Training loss: 0.9024261236190796
Validation loss: 1.708072070152529

Epoch: 553| Step: 0
Training loss: 0.6736523509025574
Validation loss: 1.7469439480894355

Epoch: 5| Step: 1
Training loss: 1.365984320640564
Validation loss: 1.733765572629949

Epoch: 5| Step: 2
Training loss: 1.2656086683273315
Validation loss: 1.785734143308414

Epoch: 5| Step: 3
Training loss: 1.055890679359436
Validation loss: 1.7384100498691681

Epoch: 5| Step: 4
Training loss: 0.6429458260536194
Validation loss: 1.764848425824155

Epoch: 5| Step: 5
Training loss: 1.4426062107086182
Validation loss: 1.7436840880301692

Epoch: 5| Step: 6
Training loss: 1.1580915451049805
Validation loss: 1.7177221031599148

Epoch: 5| Step: 7
Training loss: 0.7828488349914551
Validation loss: 1.7559252605643323

Epoch: 5| Step: 8
Training loss: 0.8645650744438171
Validation loss: 1.7679384088003507

Epoch: 5| Step: 9
Training loss: 0.7125334739685059
Validation loss: 1.7437746550447197

Epoch: 5| Step: 10
Training loss: 0.7616620063781738
Validation loss: 1.7249803799454884

Epoch: 554| Step: 0
Training loss: 0.9380594491958618
Validation loss: 1.7332472673026464

Epoch: 5| Step: 1
Training loss: 0.9853132963180542
Validation loss: 1.78530635628649

Epoch: 5| Step: 2
Training loss: 1.0997756719589233
Validation loss: 1.7413633164539133

Epoch: 5| Step: 3
Training loss: 0.8468678593635559
Validation loss: 1.7215657285464707

Epoch: 5| Step: 4
Training loss: 0.9308907389640808
Validation loss: 1.7199226105084984

Epoch: 5| Step: 5
Training loss: 0.7583398222923279
Validation loss: 1.7161644761280348

Epoch: 5| Step: 6
Training loss: 1.0656496286392212
Validation loss: 1.6960178036843576

Epoch: 5| Step: 7
Training loss: 0.9533942937850952
Validation loss: 1.7367643412723337

Epoch: 5| Step: 8
Training loss: 0.8972377777099609
Validation loss: 1.7942306636482157

Epoch: 5| Step: 9
Training loss: 1.2408429384231567
Validation loss: 1.7088005055663407

Epoch: 5| Step: 10
Training loss: 0.9313190579414368
Validation loss: 1.7751313800452857

Epoch: 555| Step: 0
Training loss: 0.7528475522994995
Validation loss: 1.7747156261115946

Epoch: 5| Step: 1
Training loss: 0.9067769050598145
Validation loss: 1.7280104057763213

Epoch: 5| Step: 2
Training loss: 0.8914705514907837
Validation loss: 1.7353028084642144

Epoch: 5| Step: 3
Training loss: 1.0098272562026978
Validation loss: 1.7559008034326697

Epoch: 5| Step: 4
Training loss: 0.7032747268676758
Validation loss: 1.7341166016876057

Epoch: 5| Step: 5
Training loss: 1.0917627811431885
Validation loss: 1.735903686092746

Epoch: 5| Step: 6
Training loss: 1.3975279331207275
Validation loss: 1.7568991376507668

Epoch: 5| Step: 7
Training loss: 1.473816156387329
Validation loss: 1.8138234128234207

Epoch: 5| Step: 8
Training loss: 0.7169778347015381
Validation loss: 1.7357370840605868

Epoch: 5| Step: 9
Training loss: 0.7854770421981812
Validation loss: 1.7501371022193664

Epoch: 5| Step: 10
Training loss: 1.1413823366165161
Validation loss: 1.756632794616043

Epoch: 556| Step: 0
Training loss: 1.2934263944625854
Validation loss: 1.734337326019041

Epoch: 5| Step: 1
Training loss: 0.8791557550430298
Validation loss: 1.765739094826483

Epoch: 5| Step: 2
Training loss: 1.0188499689102173
Validation loss: 1.7256710119144891

Epoch: 5| Step: 3
Training loss: 1.4056318998336792
Validation loss: 1.7786495262576687

Epoch: 5| Step: 4
Training loss: 1.1658896207809448
Validation loss: 1.6824892054321945

Epoch: 5| Step: 5
Training loss: 0.8111651539802551
Validation loss: 1.7280432229400964

Epoch: 5| Step: 6
Training loss: 0.7445039749145508
Validation loss: 1.7061435522571686

Epoch: 5| Step: 7
Training loss: 0.5328298211097717
Validation loss: 1.6968453161178096

Epoch: 5| Step: 8
Training loss: 1.1108782291412354
Validation loss: 1.736237669503817

Epoch: 5| Step: 9
Training loss: 1.03211510181427
Validation loss: 1.677768712402672

Epoch: 5| Step: 10
Training loss: 0.6949331164360046
Validation loss: 1.6773786211526522

Epoch: 557| Step: 0
Training loss: 1.231217622756958
Validation loss: 1.6914408604303997

Epoch: 5| Step: 1
Training loss: 0.7306499481201172
Validation loss: 1.688055048706711

Epoch: 5| Step: 2
Training loss: 1.316169261932373
Validation loss: 1.683932073654667

Epoch: 5| Step: 3
Training loss: 0.6864616870880127
Validation loss: 1.7406716244195097

Epoch: 5| Step: 4
Training loss: 1.0127274990081787
Validation loss: 1.709646677458158

Epoch: 5| Step: 5
Training loss: 0.6991446614265442
Validation loss: 1.7557823350352626

Epoch: 5| Step: 6
Training loss: 1.149674415588379
Validation loss: 1.7197021771502752

Epoch: 5| Step: 7
Training loss: 1.3001654148101807
Validation loss: 1.7515921669621621

Epoch: 5| Step: 8
Training loss: 0.9023518562316895
Validation loss: 1.7433026849582631

Epoch: 5| Step: 9
Training loss: 0.6413966417312622
Validation loss: 1.744915699446073

Epoch: 5| Step: 10
Training loss: 0.6844246983528137
Validation loss: 1.7344289979627054

Epoch: 558| Step: 0
Training loss: 1.080047369003296
Validation loss: 1.7983045795912385

Epoch: 5| Step: 1
Training loss: 0.8063830137252808
Validation loss: 1.7489175758054178

Epoch: 5| Step: 2
Training loss: 1.4309743642807007
Validation loss: 1.7610804970546434

Epoch: 5| Step: 3
Training loss: 1.0222995281219482
Validation loss: 1.781376592574581

Epoch: 5| Step: 4
Training loss: 0.9272893667221069
Validation loss: 1.7435278597698416

Epoch: 5| Step: 5
Training loss: 1.3765969276428223
Validation loss: 1.711112194163825

Epoch: 5| Step: 6
Training loss: 0.7428380250930786
Validation loss: 1.7336643536885579

Epoch: 5| Step: 7
Training loss: 0.5336377620697021
Validation loss: 1.7037623325983684

Epoch: 5| Step: 8
Training loss: 0.8245620727539062
Validation loss: 1.742335772001615

Epoch: 5| Step: 9
Training loss: 1.013379454612732
Validation loss: 1.6895104672319146

Epoch: 5| Step: 10
Training loss: 0.7656534910202026
Validation loss: 1.7067000571117605

Epoch: 559| Step: 0
Training loss: 0.8298307657241821
Validation loss: 1.7149245867165186

Epoch: 5| Step: 1
Training loss: 1.1691734790802002
Validation loss: 1.6862505892271638

Epoch: 5| Step: 2
Training loss: 0.753606379032135
Validation loss: 1.7033939438481485

Epoch: 5| Step: 3
Training loss: 0.8766325116157532
Validation loss: 1.7891371685971496

Epoch: 5| Step: 4
Training loss: 1.2404857873916626
Validation loss: 1.7277110045956028

Epoch: 5| Step: 5
Training loss: 0.8485797643661499
Validation loss: 1.6974805414035756

Epoch: 5| Step: 6
Training loss: 1.1233497858047485
Validation loss: 1.7344571070004535

Epoch: 5| Step: 7
Training loss: 0.9345673322677612
Validation loss: 1.7102881490543325

Epoch: 5| Step: 8
Training loss: 1.0591713190078735
Validation loss: 1.700717382533576

Epoch: 5| Step: 9
Training loss: 1.1083095073699951
Validation loss: 1.7421458459669543

Epoch: 5| Step: 10
Training loss: 0.775033712387085
Validation loss: 1.7382670294853948

Epoch: 560| Step: 0
Training loss: 0.7541043758392334
Validation loss: 1.7035856323857461

Epoch: 5| Step: 1
Training loss: 0.8388651609420776
Validation loss: 1.7573913322981967

Epoch: 5| Step: 2
Training loss: 0.7378982305526733
Validation loss: 1.7288429224362938

Epoch: 5| Step: 3
Training loss: 0.7383925914764404
Validation loss: 1.714025584600305

Epoch: 5| Step: 4
Training loss: 1.3585968017578125
Validation loss: 1.7278505474008539

Epoch: 5| Step: 5
Training loss: 1.4315588474273682
Validation loss: 1.7342528117600309

Epoch: 5| Step: 6
Training loss: 0.9623112678527832
Validation loss: 1.7355314480361117

Epoch: 5| Step: 7
Training loss: 0.6098025441169739
Validation loss: 1.7779390735010947

Epoch: 5| Step: 8
Training loss: 1.2578375339508057
Validation loss: 1.7107134442175589

Epoch: 5| Step: 9
Training loss: 1.2782095670700073
Validation loss: 1.7328029358258812

Epoch: 5| Step: 10
Training loss: 0.6888084411621094
Validation loss: 1.7398541614573488

Epoch: 561| Step: 0
Training loss: 0.8345156908035278
Validation loss: 1.7015469426749854

Epoch: 5| Step: 1
Training loss: 0.6944807767868042
Validation loss: 1.7502956967200003

Epoch: 5| Step: 2
Training loss: 0.793117880821228
Validation loss: 1.7523428470857683

Epoch: 5| Step: 3
Training loss: 0.9082139134407043
Validation loss: 1.700452632801507

Epoch: 5| Step: 4
Training loss: 0.8251420855522156
Validation loss: 1.729086555460448

Epoch: 5| Step: 5
Training loss: 0.9136261940002441
Validation loss: 1.7147706990600915

Epoch: 5| Step: 6
Training loss: 0.960292637348175
Validation loss: 1.7213620396070584

Epoch: 5| Step: 7
Training loss: 1.2522671222686768
Validation loss: 1.7214752025501703

Epoch: 5| Step: 8
Training loss: 1.0246366262435913
Validation loss: 1.7085698573820052

Epoch: 5| Step: 9
Training loss: 1.8886654376983643
Validation loss: 1.752556465005362

Epoch: 5| Step: 10
Training loss: 0.5691605806350708
Validation loss: 1.7463987386354836

Epoch: 562| Step: 0
Training loss: 1.2803388833999634
Validation loss: 1.7245209537526613

Epoch: 5| Step: 1
Training loss: 1.10964834690094
Validation loss: 1.7197809116814726

Epoch: 5| Step: 2
Training loss: 0.8629355430603027
Validation loss: 1.727481140885302

Epoch: 5| Step: 3
Training loss: 0.7628992199897766
Validation loss: 1.6772777213845202

Epoch: 5| Step: 4
Training loss: 0.655471920967102
Validation loss: 1.7402837430277178

Epoch: 5| Step: 5
Training loss: 1.317007303237915
Validation loss: 1.7613085457073745

Epoch: 5| Step: 6
Training loss: 0.8575051426887512
Validation loss: 1.7420089296115342

Epoch: 5| Step: 7
Training loss: 1.3378328084945679
Validation loss: 1.7911946222346316

Epoch: 5| Step: 8
Training loss: 0.8126189112663269
Validation loss: 1.7668773692141297

Epoch: 5| Step: 9
Training loss: 0.8853546380996704
Validation loss: 1.7589125466603104

Epoch: 5| Step: 10
Training loss: 0.7943031191825867
Validation loss: 1.7552059171020344

Epoch: 563| Step: 0
Training loss: 0.719219982624054
Validation loss: 1.7834231392029793

Epoch: 5| Step: 1
Training loss: 1.0420855283737183
Validation loss: 1.7535868601132465

Epoch: 5| Step: 2
Training loss: 1.1575276851654053
Validation loss: 1.7080014969712944

Epoch: 5| Step: 3
Training loss: 0.8530054092407227
Validation loss: 1.6899217213353803

Epoch: 5| Step: 4
Training loss: 1.051300287246704
Validation loss: 1.6646671243893203

Epoch: 5| Step: 5
Training loss: 1.026188611984253
Validation loss: 1.7312624025088486

Epoch: 5| Step: 6
Training loss: 0.5920920372009277
Validation loss: 1.7570126043852938

Epoch: 5| Step: 7
Training loss: 1.2297534942626953
Validation loss: 1.6953818951883624

Epoch: 5| Step: 8
Training loss: 0.9226974248886108
Validation loss: 1.6854618057127921

Epoch: 5| Step: 9
Training loss: 0.7430703043937683
Validation loss: 1.6949035634276688

Epoch: 5| Step: 10
Training loss: 0.6783921718597412
Validation loss: 1.7036849837149344

Epoch: 564| Step: 0
Training loss: 1.2576783895492554
Validation loss: 1.7585852633240402

Epoch: 5| Step: 1
Training loss: 1.0168688297271729
Validation loss: 1.730517691181552

Epoch: 5| Step: 2
Training loss: 0.8822935223579407
Validation loss: 1.711549162864685

Epoch: 5| Step: 3
Training loss: 1.131209373474121
Validation loss: 1.6770778368878108

Epoch: 5| Step: 4
Training loss: 0.8795417547225952
Validation loss: 1.8025209596080165

Epoch: 5| Step: 5
Training loss: 0.6638333201408386
Validation loss: 1.7184003014718332

Epoch: 5| Step: 6
Training loss: 1.112141728401184
Validation loss: 1.7658971842899118

Epoch: 5| Step: 7
Training loss: 0.7489079236984253
Validation loss: 1.719009291741156

Epoch: 5| Step: 8
Training loss: 0.7541165947914124
Validation loss: 1.7097464825517388

Epoch: 5| Step: 9
Training loss: 1.0143563747406006
Validation loss: 1.7751151643773562

Epoch: 5| Step: 10
Training loss: 1.1321167945861816
Validation loss: 1.776609092630366

Epoch: 565| Step: 0
Training loss: 0.9894685745239258
Validation loss: 1.7726696075931672

Epoch: 5| Step: 1
Training loss: 1.1311894655227661
Validation loss: 1.6968627347741077

Epoch: 5| Step: 2
Training loss: 0.8151968121528625
Validation loss: 1.7161370477368754

Epoch: 5| Step: 3
Training loss: 1.0605647563934326
Validation loss: 1.7763008135621265

Epoch: 5| Step: 4
Training loss: 0.9463468790054321
Validation loss: 1.748897724254157

Epoch: 5| Step: 5
Training loss: 0.9460910558700562
Validation loss: 1.7134034223453973

Epoch: 5| Step: 6
Training loss: 0.904334545135498
Validation loss: 1.7058885482049757

Epoch: 5| Step: 7
Training loss: 0.6786361932754517
Validation loss: 1.7060438894456433

Epoch: 5| Step: 8
Training loss: 1.4145857095718384
Validation loss: 1.7252950706789572

Epoch: 5| Step: 9
Training loss: 0.8535777926445007
Validation loss: 1.704679177653405

Epoch: 5| Step: 10
Training loss: 0.6334478855133057
Validation loss: 1.7473410201329056

Epoch: 566| Step: 0
Training loss: 0.9071331024169922
Validation loss: 1.6824366943810576

Epoch: 5| Step: 1
Training loss: 0.7608065009117126
Validation loss: 1.782307182588885

Epoch: 5| Step: 2
Training loss: 1.2242313623428345
Validation loss: 1.7361900088607625

Epoch: 5| Step: 3
Training loss: 0.929991602897644
Validation loss: 1.748669066736775

Epoch: 5| Step: 4
Training loss: 0.8482621312141418
Validation loss: 1.7284054217800018

Epoch: 5| Step: 5
Training loss: 1.1828153133392334
Validation loss: 1.753023447528962

Epoch: 5| Step: 6
Training loss: 1.1276761293411255
Validation loss: 1.7775627566922096

Epoch: 5| Step: 7
Training loss: 0.8141453862190247
Validation loss: 1.763402420987365

Epoch: 5| Step: 8
Training loss: 0.729809582233429
Validation loss: 1.7722395658493042

Epoch: 5| Step: 9
Training loss: 0.7143955230712891
Validation loss: 1.7470006327475271

Epoch: 5| Step: 10
Training loss: 1.1013448238372803
Validation loss: 1.7949062662739907

Epoch: 567| Step: 0
Training loss: 1.0500833988189697
Validation loss: 1.7126497401986072

Epoch: 5| Step: 1
Training loss: 1.1333072185516357
Validation loss: 1.6964378254387968

Epoch: 5| Step: 2
Training loss: 0.8709508776664734
Validation loss: 1.6954328872824227

Epoch: 5| Step: 3
Training loss: 0.988625168800354
Validation loss: 1.7822198149978474

Epoch: 5| Step: 4
Training loss: 0.942320704460144
Validation loss: 1.6579172547145555

Epoch: 5| Step: 5
Training loss: 0.5291844606399536
Validation loss: 1.7130487740680735

Epoch: 5| Step: 6
Training loss: 1.0127366781234741
Validation loss: 1.7353723202982256

Epoch: 5| Step: 7
Training loss: 0.5973362922668457
Validation loss: 1.721284140822708

Epoch: 5| Step: 8
Training loss: 1.0870038270950317
Validation loss: 1.7232852212844356

Epoch: 5| Step: 9
Training loss: 1.0843194723129272
Validation loss: 1.7867219101998113

Epoch: 5| Step: 10
Training loss: 1.0085296630859375
Validation loss: 1.7210314953198997

Epoch: 568| Step: 0
Training loss: 1.2548805475234985
Validation loss: 1.7297048927635275

Epoch: 5| Step: 1
Training loss: 0.983203113079071
Validation loss: 1.7072607086550804

Epoch: 5| Step: 2
Training loss: 1.0726615190505981
Validation loss: 1.7778715459249352

Epoch: 5| Step: 3
Training loss: 1.2640130519866943
Validation loss: 1.717138821078885

Epoch: 5| Step: 4
Training loss: 1.3269872665405273
Validation loss: 1.7153578035293087

Epoch: 5| Step: 5
Training loss: 0.6755456924438477
Validation loss: 1.6713517571008334

Epoch: 5| Step: 6
Training loss: 0.6331223249435425
Validation loss: 1.675103920762257

Epoch: 5| Step: 7
Training loss: 0.7845948338508606
Validation loss: 1.7879123239107029

Epoch: 5| Step: 8
Training loss: 0.5923080444335938
Validation loss: 1.748711573180332

Epoch: 5| Step: 9
Training loss: 0.9413713216781616
Validation loss: 1.7437396267408967

Epoch: 5| Step: 10
Training loss: 1.0143194198608398
Validation loss: 1.7501933151675808

Epoch: 569| Step: 0
Training loss: 1.0778024196624756
Validation loss: 1.7903928782350274

Epoch: 5| Step: 1
Training loss: 1.143186330795288
Validation loss: 1.7097566743050852

Epoch: 5| Step: 2
Training loss: 0.6859127283096313
Validation loss: 1.7344926223959973

Epoch: 5| Step: 3
Training loss: 0.9126283526420593
Validation loss: 1.7463504947641844

Epoch: 5| Step: 4
Training loss: 1.1364516019821167
Validation loss: 1.8043681421587545

Epoch: 5| Step: 5
Training loss: 0.7909131050109863
Validation loss: 1.756308360766339

Epoch: 5| Step: 6
Training loss: 0.6966843605041504
Validation loss: 1.7374260323022002

Epoch: 5| Step: 7
Training loss: 0.7258164286613464
Validation loss: 1.7730776520185574

Epoch: 5| Step: 8
Training loss: 0.8000253438949585
Validation loss: 1.7531792899613738

Epoch: 5| Step: 9
Training loss: 0.8386430740356445
Validation loss: 1.7383620200618621

Epoch: 5| Step: 10
Training loss: 1.3837499618530273
Validation loss: 1.7322747822730773

Epoch: 570| Step: 0
Training loss: 0.6533220410346985
Validation loss: 1.745628914525432

Epoch: 5| Step: 1
Training loss: 1.152231216430664
Validation loss: 1.7292963894464637

Epoch: 5| Step: 2
Training loss: 0.5908524394035339
Validation loss: 1.7856228736139113

Epoch: 5| Step: 3
Training loss: 1.4851576089859009
Validation loss: 1.7221695351344284

Epoch: 5| Step: 4
Training loss: 1.0831339359283447
Validation loss: 1.7589020498337284

Epoch: 5| Step: 5
Training loss: 1.0571753978729248
Validation loss: 1.7895730464689192

Epoch: 5| Step: 6
Training loss: 0.7386959791183472
Validation loss: 1.7536506781014063

Epoch: 5| Step: 7
Training loss: 0.8971713781356812
Validation loss: 1.680803466868657

Epoch: 5| Step: 8
Training loss: 1.1031891107559204
Validation loss: 1.7430578239502446

Epoch: 5| Step: 9
Training loss: 1.1061477661132812
Validation loss: 1.7086033769833144

Epoch: 5| Step: 10
Training loss: 0.3803340196609497
Validation loss: 1.7491034999970467

Epoch: 571| Step: 0
Training loss: 0.658535361289978
Validation loss: 1.7100809081908195

Epoch: 5| Step: 1
Training loss: 1.0979702472686768
Validation loss: 1.7112932121881874

Epoch: 5| Step: 2
Training loss: 0.8736569285392761
Validation loss: 1.6879542232841573

Epoch: 5| Step: 3
Training loss: 0.6539981365203857
Validation loss: 1.7241108776420675

Epoch: 5| Step: 4
Training loss: 0.7018401026725769
Validation loss: 1.6985585099907332

Epoch: 5| Step: 5
Training loss: 1.296181321144104
Validation loss: 1.7184003911992556

Epoch: 5| Step: 6
Training loss: 1.9178088903427124
Validation loss: 1.68016343732034

Epoch: 5| Step: 7
Training loss: 1.0225956439971924
Validation loss: 1.705566378049953

Epoch: 5| Step: 8
Training loss: 0.49757060408592224
Validation loss: 1.7005239071384552

Epoch: 5| Step: 9
Training loss: 0.7994929552078247
Validation loss: 1.7384250446032452

Epoch: 5| Step: 10
Training loss: 1.028606653213501
Validation loss: 1.7187835170376686

Epoch: 572| Step: 0
Training loss: 0.972695529460907
Validation loss: 1.7713720567764775

Epoch: 5| Step: 1
Training loss: 0.5809520483016968
Validation loss: 1.6995114088058472

Epoch: 5| Step: 2
Training loss: 1.1435637474060059
Validation loss: 1.761521291989152

Epoch: 5| Step: 3
Training loss: 1.2157166004180908
Validation loss: 1.7727879836995115

Epoch: 5| Step: 4
Training loss: 0.9510751962661743
Validation loss: 1.7546531436263875

Epoch: 5| Step: 5
Training loss: 0.6989533305168152
Validation loss: 1.7630051425708237

Epoch: 5| Step: 6
Training loss: 0.9752155542373657
Validation loss: 1.7157792429770193

Epoch: 5| Step: 7
Training loss: 1.4957026243209839
Validation loss: 1.7521337668100994

Epoch: 5| Step: 8
Training loss: 0.8751994967460632
Validation loss: 1.7675478894223449

Epoch: 5| Step: 9
Training loss: 0.5995475053787231
Validation loss: 1.768791844767909

Epoch: 5| Step: 10
Training loss: 1.010347843170166
Validation loss: 1.7679985761642456

Epoch: 573| Step: 0
Training loss: 0.8157486915588379
Validation loss: 1.7140864403017106

Epoch: 5| Step: 1
Training loss: 1.20017409324646
Validation loss: 1.7056374114046815

Epoch: 5| Step: 2
Training loss: 1.2531604766845703
Validation loss: 1.8244651927742908

Epoch: 5| Step: 3
Training loss: 0.6937005519866943
Validation loss: 1.8029130171704035

Epoch: 5| Step: 4
Training loss: 0.7790848612785339
Validation loss: 1.7410406989435996

Epoch: 5| Step: 5
Training loss: 0.6533166766166687
Validation loss: 1.6938569532927645

Epoch: 5| Step: 6
Training loss: 0.9198972582817078
Validation loss: 1.773155730257752

Epoch: 5| Step: 7
Training loss: 1.3068983554840088
Validation loss: 1.7014861286327403

Epoch: 5| Step: 8
Training loss: 0.7945907711982727
Validation loss: 1.7067192216073312

Epoch: 5| Step: 9
Training loss: 1.3968931436538696
Validation loss: 1.7642679842569495

Epoch: 5| Step: 10
Training loss: 0.8036781549453735
Validation loss: 1.7004925679135066

Epoch: 574| Step: 0
Training loss: 0.7760332822799683
Validation loss: 1.688766726883509

Epoch: 5| Step: 1
Training loss: 0.9269658327102661
Validation loss: 1.695641674021239

Epoch: 5| Step: 2
Training loss: 1.0877487659454346
Validation loss: 1.670212822575723

Epoch: 5| Step: 3
Training loss: 0.6359125971794128
Validation loss: 1.7383927004311674

Epoch: 5| Step: 4
Training loss: 0.968278706073761
Validation loss: 1.7167483555373324

Epoch: 5| Step: 5
Training loss: 0.5375863909721375
Validation loss: 1.752188418501167

Epoch: 5| Step: 6
Training loss: 1.066044569015503
Validation loss: 1.7475627917115406

Epoch: 5| Step: 7
Training loss: 1.3719139099121094
Validation loss: 1.76978680651675

Epoch: 5| Step: 8
Training loss: 0.8704532384872437
Validation loss: 1.7217320396054177

Epoch: 5| Step: 9
Training loss: 1.206662893295288
Validation loss: 1.799752361030989

Epoch: 5| Step: 10
Training loss: 0.8188586831092834
Validation loss: 1.7518789370854695

Epoch: 575| Step: 0
Training loss: 1.0309631824493408
Validation loss: 1.7430097005700553

Epoch: 5| Step: 1
Training loss: 0.7856895923614502
Validation loss: 1.6872386291462889

Epoch: 5| Step: 2
Training loss: 0.8184517025947571
Validation loss: 1.6998077028541154

Epoch: 5| Step: 3
Training loss: 1.3209526538848877
Validation loss: 1.7283787188991424

Epoch: 5| Step: 4
Training loss: 0.9628502726554871
Validation loss: 1.722940283436929

Epoch: 5| Step: 5
Training loss: 0.730783998966217
Validation loss: 1.6753951817430475

Epoch: 5| Step: 6
Training loss: 1.0476804971694946
Validation loss: 1.6690551978285595

Epoch: 5| Step: 7
Training loss: 1.101744532585144
Validation loss: 1.732713290440139

Epoch: 5| Step: 8
Training loss: 1.1424375772476196
Validation loss: 1.6883928455332273

Epoch: 5| Step: 9
Training loss: 0.8173320889472961
Validation loss: 1.765326343556886

Epoch: 5| Step: 10
Training loss: 0.691390335559845
Validation loss: 1.719102713369554

Epoch: 576| Step: 0
Training loss: 1.4384052753448486
Validation loss: 1.692223310470581

Epoch: 5| Step: 1
Training loss: 1.033847689628601
Validation loss: 1.70245191871479

Epoch: 5| Step: 2
Training loss: 0.8436613082885742
Validation loss: 1.7828897737687635

Epoch: 5| Step: 3
Training loss: 1.0716546773910522
Validation loss: 1.7394430996269308

Epoch: 5| Step: 4
Training loss: 0.825688362121582
Validation loss: 1.6846007929053357

Epoch: 5| Step: 5
Training loss: 0.9085149765014648
Validation loss: 1.783648665233325

Epoch: 5| Step: 6
Training loss: 0.9697650671005249
Validation loss: 1.7128794859814387

Epoch: 5| Step: 7
Training loss: 1.1937766075134277
Validation loss: 1.697065568739368

Epoch: 5| Step: 8
Training loss: 0.6858294606208801
Validation loss: 1.7321434482451408

Epoch: 5| Step: 9
Training loss: 0.8495996594429016
Validation loss: 1.7127285093389533

Epoch: 5| Step: 10
Training loss: 0.7424557209014893
Validation loss: 1.6934655045950284

Epoch: 577| Step: 0
Training loss: 1.2649965286254883
Validation loss: 1.7134366266189083

Epoch: 5| Step: 1
Training loss: 0.7464746236801147
Validation loss: 1.7447938431975663

Epoch: 5| Step: 2
Training loss: 0.46742668747901917
Validation loss: 1.7204454816797727

Epoch: 5| Step: 3
Training loss: 0.9767966270446777
Validation loss: 1.708919676401282

Epoch: 5| Step: 4
Training loss: 1.2014752626419067
Validation loss: 1.6849679357262068

Epoch: 5| Step: 5
Training loss: 0.8562344312667847
Validation loss: 1.7640144453253797

Epoch: 5| Step: 6
Training loss: 0.9927017092704773
Validation loss: 1.7374887158793788

Epoch: 5| Step: 7
Training loss: 0.6287004947662354
Validation loss: 1.7190054257710774

Epoch: 5| Step: 8
Training loss: 0.9743318557739258
Validation loss: 1.687354121156918

Epoch: 5| Step: 9
Training loss: 1.2275924682617188
Validation loss: 1.7070809666828444

Epoch: 5| Step: 10
Training loss: 1.045538306236267
Validation loss: 1.7413648841201619

Epoch: 578| Step: 0
Training loss: 1.4597597122192383
Validation loss: 1.7508254358845372

Epoch: 5| Step: 1
Training loss: 0.6728540658950806
Validation loss: 1.7565781916341474

Epoch: 5| Step: 2
Training loss: 0.9108765721321106
Validation loss: 1.7356360471376808

Epoch: 5| Step: 3
Training loss: 1.0447633266448975
Validation loss: 1.7720162227589598

Epoch: 5| Step: 4
Training loss: 0.7866147756576538
Validation loss: 1.7587661640618437

Epoch: 5| Step: 5
Training loss: 0.8862262964248657
Validation loss: 1.733538317423995

Epoch: 5| Step: 6
Training loss: 0.6756370663642883
Validation loss: 1.705973150909588

Epoch: 5| Step: 7
Training loss: 1.1294853687286377
Validation loss: 1.7124863645081878

Epoch: 5| Step: 8
Training loss: 0.9362965822219849
Validation loss: 1.7550262558844782

Epoch: 5| Step: 9
Training loss: 0.8868740200996399
Validation loss: 1.716361814929593

Epoch: 5| Step: 10
Training loss: 0.987851619720459
Validation loss: 1.7615338474191644

Epoch: 579| Step: 0
Training loss: 0.7742791175842285
Validation loss: 1.7153172505799161

Epoch: 5| Step: 1
Training loss: 1.3122584819793701
Validation loss: 1.750525382257277

Epoch: 5| Step: 2
Training loss: 0.6802988052368164
Validation loss: 1.7108165487166374

Epoch: 5| Step: 3
Training loss: 0.8097108602523804
Validation loss: 1.7395557818874237

Epoch: 5| Step: 4
Training loss: 0.9668542742729187
Validation loss: 1.7127422427618375

Epoch: 5| Step: 5
Training loss: 0.8409518003463745
Validation loss: 1.7055996079598703

Epoch: 5| Step: 6
Training loss: 1.126251459121704
Validation loss: 1.7438033293652278

Epoch: 5| Step: 7
Training loss: 1.0938549041748047
Validation loss: 1.7254928465812438

Epoch: 5| Step: 8
Training loss: 0.8258703351020813
Validation loss: 1.7091541854284142

Epoch: 5| Step: 9
Training loss: 0.8369001150131226
Validation loss: 1.7468797827279696

Epoch: 5| Step: 10
Training loss: 1.2966334819793701
Validation loss: 1.690552834541567

Epoch: 580| Step: 0
Training loss: 0.9279373288154602
Validation loss: 1.7154602786546111

Epoch: 5| Step: 1
Training loss: 1.0668281316757202
Validation loss: 1.6741484480519448

Epoch: 5| Step: 2
Training loss: 1.1058112382888794
Validation loss: 1.7503354382771317

Epoch: 5| Step: 3
Training loss: 0.8042097091674805
Validation loss: 1.7072854452235724

Epoch: 5| Step: 4
Training loss: 1.0147368907928467
Validation loss: 1.7079874828297605

Epoch: 5| Step: 5
Training loss: 1.0461091995239258
Validation loss: 1.7315970838710826

Epoch: 5| Step: 6
Training loss: 1.1997592449188232
Validation loss: 1.757210760988215

Epoch: 5| Step: 7
Training loss: 0.6709697842597961
Validation loss: 1.7766497019798524

Epoch: 5| Step: 8
Training loss: 0.6088176965713501
Validation loss: 1.716345779357418

Epoch: 5| Step: 9
Training loss: 1.1710658073425293
Validation loss: 1.7931728837310628

Epoch: 5| Step: 10
Training loss: 0.5891912579536438
Validation loss: 1.7468895655806347

Epoch: 581| Step: 0
Training loss: 0.6676142811775208
Validation loss: 1.6945899968506188

Epoch: 5| Step: 1
Training loss: 1.4877108335494995
Validation loss: 1.6878626205587899

Epoch: 5| Step: 2
Training loss: 0.4366903305053711
Validation loss: 1.7028075238709808

Epoch: 5| Step: 3
Training loss: 0.9215280413627625
Validation loss: 1.7284349985020135

Epoch: 5| Step: 4
Training loss: 0.8724601864814758
Validation loss: 1.720954978337852

Epoch: 5| Step: 5
Training loss: 1.1750184297561646
Validation loss: 1.7169915373607347

Epoch: 5| Step: 6
Training loss: 1.000950574874878
Validation loss: 1.6886923069595008

Epoch: 5| Step: 7
Training loss: 0.7799680829048157
Validation loss: 1.6963450536932996

Epoch: 5| Step: 8
Training loss: 0.7905580401420593
Validation loss: 1.7181358106674687

Epoch: 5| Step: 9
Training loss: 0.7547646760940552
Validation loss: 1.7805425672120945

Epoch: 5| Step: 10
Training loss: 1.248437762260437
Validation loss: 1.7229803390400384

Epoch: 582| Step: 0
Training loss: 0.8867419958114624
Validation loss: 1.68433476391659

Epoch: 5| Step: 1
Training loss: 1.103351354598999
Validation loss: 1.6882690460451188

Epoch: 5| Step: 2
Training loss: 0.8059355020523071
Validation loss: 1.7100896745599725

Epoch: 5| Step: 3
Training loss: 1.0422052145004272
Validation loss: 1.6793714236187678

Epoch: 5| Step: 4
Training loss: 1.0154197216033936
Validation loss: 1.6964082461531445

Epoch: 5| Step: 5
Training loss: 1.0972537994384766
Validation loss: 1.7553270452766008

Epoch: 5| Step: 6
Training loss: 1.1102696657180786
Validation loss: 1.760500459260838

Epoch: 5| Step: 7
Training loss: 0.5063043832778931
Validation loss: 1.7849768925738592

Epoch: 5| Step: 8
Training loss: 1.0333821773529053
Validation loss: 1.706722536394673

Epoch: 5| Step: 9
Training loss: 0.8074127435684204
Validation loss: 1.7410630538899412

Epoch: 5| Step: 10
Training loss: 0.965551495552063
Validation loss: 1.7694483444254885

Epoch: 583| Step: 0
Training loss: 1.1549561023712158
Validation loss: 1.7287384592076784

Epoch: 5| Step: 1
Training loss: 0.9758026003837585
Validation loss: 1.736932211024787

Epoch: 5| Step: 2
Training loss: 0.8663867115974426
Validation loss: 1.7670696230344876

Epoch: 5| Step: 3
Training loss: 0.4224484860897064
Validation loss: 1.7506712072639055

Epoch: 5| Step: 4
Training loss: 0.72362220287323
Validation loss: 1.7818677912476242

Epoch: 5| Step: 5
Training loss: 1.1529291868209839
Validation loss: 1.7455679806329871

Epoch: 5| Step: 6
Training loss: 0.8476606607437134
Validation loss: 1.7081983038174209

Epoch: 5| Step: 7
Training loss: 1.7575805187225342
Validation loss: 1.665781040345469

Epoch: 5| Step: 8
Training loss: 0.6760314702987671
Validation loss: 1.6678844498049827

Epoch: 5| Step: 9
Training loss: 0.8865848779678345
Validation loss: 1.698006785044106

Epoch: 5| Step: 10
Training loss: 0.8195971250534058
Validation loss: 1.6976119087588402

Epoch: 584| Step: 0
Training loss: 1.064712643623352
Validation loss: 1.7154054949360509

Epoch: 5| Step: 1
Training loss: 1.2226994037628174
Validation loss: 1.722847330954767

Epoch: 5| Step: 2
Training loss: 0.7067408561706543
Validation loss: 1.7323303440565705

Epoch: 5| Step: 3
Training loss: 0.77367103099823
Validation loss: 1.6591190227898218

Epoch: 5| Step: 4
Training loss: 1.2158724069595337
Validation loss: 1.7376350100322435

Epoch: 5| Step: 5
Training loss: 1.109838843345642
Validation loss: 1.729433189156235

Epoch: 5| Step: 6
Training loss: 0.7617419958114624
Validation loss: 1.7740915693262571

Epoch: 5| Step: 7
Training loss: 0.9109107255935669
Validation loss: 1.70654938297887

Epoch: 5| Step: 8
Training loss: 1.1128126382827759
Validation loss: 1.7622252382257932

Epoch: 5| Step: 9
Training loss: 0.7324545979499817
Validation loss: 1.7457079848935526

Epoch: 5| Step: 10
Training loss: 0.5627071261405945
Validation loss: 1.779753984943513

Epoch: 585| Step: 0
Training loss: 0.8540487289428711
Validation loss: 1.6821152638363581

Epoch: 5| Step: 1
Training loss: 1.2678593397140503
Validation loss: 1.7545871093708982

Epoch: 5| Step: 2
Training loss: 0.8541901707649231
Validation loss: 1.7615954106853855

Epoch: 5| Step: 3
Training loss: 1.1019210815429688
Validation loss: 1.6931599583677066

Epoch: 5| Step: 4
Training loss: 0.8337180018424988
Validation loss: 1.7077267144315986

Epoch: 5| Step: 5
Training loss: 1.0753448009490967
Validation loss: 1.7489480677471365

Epoch: 5| Step: 6
Training loss: 0.7646694183349609
Validation loss: 1.745050694352837

Epoch: 5| Step: 7
Training loss: 0.9758104085922241
Validation loss: 1.7098554962424821

Epoch: 5| Step: 8
Training loss: 0.8016036748886108
Validation loss: 1.6968443419343682

Epoch: 5| Step: 9
Training loss: 0.6165820956230164
Validation loss: 1.7402182727731683

Epoch: 5| Step: 10
Training loss: 0.9458365440368652
Validation loss: 1.6760060710291709

Epoch: 586| Step: 0
Training loss: 1.0219686031341553
Validation loss: 1.7522481410734114

Epoch: 5| Step: 1
Training loss: 0.9898244142532349
Validation loss: 1.7369972800695768

Epoch: 5| Step: 2
Training loss: 0.6989765763282776
Validation loss: 1.7580701087110786

Epoch: 5| Step: 3
Training loss: 1.1422364711761475
Validation loss: 1.6652862154027468

Epoch: 5| Step: 4
Training loss: 1.083929181098938
Validation loss: 1.7568747048736901

Epoch: 5| Step: 5
Training loss: 1.0489157438278198
Validation loss: 1.7069717081644202

Epoch: 5| Step: 6
Training loss: 1.2122762203216553
Validation loss: 1.7494094858887375

Epoch: 5| Step: 7
Training loss: 0.8978098034858704
Validation loss: 1.700673318678333

Epoch: 5| Step: 8
Training loss: 0.5854951739311218
Validation loss: 1.7474141300365489

Epoch: 5| Step: 9
Training loss: 0.5329146385192871
Validation loss: 1.7050065712262226

Epoch: 5| Step: 10
Training loss: 0.7490682005882263
Validation loss: 1.7169873406810146

Epoch: 587| Step: 0
Training loss: 0.6940609812736511
Validation loss: 1.6889823546973608

Epoch: 5| Step: 1
Training loss: 1.4175679683685303
Validation loss: 1.7359856815748318

Epoch: 5| Step: 2
Training loss: 0.8539766073226929
Validation loss: 1.7452643878998295

Epoch: 5| Step: 3
Training loss: 0.8685017824172974
Validation loss: 1.6995203661662277

Epoch: 5| Step: 4
Training loss: 1.1744401454925537
Validation loss: 1.7211143137306295

Epoch: 5| Step: 5
Training loss: 0.6634862422943115
Validation loss: 1.722724494113717

Epoch: 5| Step: 6
Training loss: 1.1914331912994385
Validation loss: 1.67908731455444

Epoch: 5| Step: 7
Training loss: 0.9168733358383179
Validation loss: 1.6640584635478195

Epoch: 5| Step: 8
Training loss: 0.9467336535453796
Validation loss: 1.6617060117824103

Epoch: 5| Step: 9
Training loss: 0.6228683590888977
Validation loss: 1.7569989388988865

Epoch: 5| Step: 10
Training loss: 1.1448041200637817
Validation loss: 1.794899009889172

Epoch: 588| Step: 0
Training loss: 0.6918545961380005
Validation loss: 1.768031406146224

Epoch: 5| Step: 1
Training loss: 0.937508761882782
Validation loss: 1.7578676772373978

Epoch: 5| Step: 2
Training loss: 1.099156141281128
Validation loss: 1.7257946332295735

Epoch: 5| Step: 3
Training loss: 1.3361786603927612
Validation loss: 1.7018579923978416

Epoch: 5| Step: 4
Training loss: 0.7097480893135071
Validation loss: 1.736411012629027

Epoch: 5| Step: 5
Training loss: 0.6613801717758179
Validation loss: 1.721093762305475

Epoch: 5| Step: 6
Training loss: 1.0150290727615356
Validation loss: 1.73162716691212

Epoch: 5| Step: 7
Training loss: 0.8948265314102173
Validation loss: 1.697431638676633

Epoch: 5| Step: 8
Training loss: 0.6992984414100647
Validation loss: 1.7255708697021648

Epoch: 5| Step: 9
Training loss: 1.0595635175704956
Validation loss: 1.6834237242257724

Epoch: 5| Step: 10
Training loss: 0.8608667850494385
Validation loss: 1.6441659978640977

Epoch: 589| Step: 0
Training loss: 1.1125943660736084
Validation loss: 1.700173916355256

Epoch: 5| Step: 1
Training loss: 0.8521488308906555
Validation loss: 1.7410478784191994

Epoch: 5| Step: 2
Training loss: 1.237131118774414
Validation loss: 1.6808571738581504

Epoch: 5| Step: 3
Training loss: 0.887710452079773
Validation loss: 1.6961414108994186

Epoch: 5| Step: 4
Training loss: 0.8129006624221802
Validation loss: 1.6699186601946432

Epoch: 5| Step: 5
Training loss: 1.0873997211456299
Validation loss: 1.750082096745891

Epoch: 5| Step: 6
Training loss: 0.6577135324478149
Validation loss: 1.7580334371136082

Epoch: 5| Step: 7
Training loss: 0.4569074213504791
Validation loss: 1.7800466655403056

Epoch: 5| Step: 8
Training loss: 1.232778787612915
Validation loss: 1.7235653323511924

Epoch: 5| Step: 9
Training loss: 0.7654293775558472
Validation loss: 1.7419632070808

Epoch: 5| Step: 10
Training loss: 1.1149879693984985
Validation loss: 1.766909287821862

Epoch: 590| Step: 0
Training loss: 0.9937251806259155
Validation loss: 1.6928364217922252

Epoch: 5| Step: 1
Training loss: 0.9461328387260437
Validation loss: 1.6962532112675328

Epoch: 5| Step: 2
Training loss: 0.5354542136192322
Validation loss: 1.663724107127036

Epoch: 5| Step: 3
Training loss: 1.2053821086883545
Validation loss: 1.7076703130557973

Epoch: 5| Step: 4
Training loss: 0.9542858004570007
Validation loss: 1.7211954593658447

Epoch: 5| Step: 5
Training loss: 1.0907459259033203
Validation loss: 1.728667357916473

Epoch: 5| Step: 6
Training loss: 0.8114832043647766
Validation loss: 1.7518618170933058

Epoch: 5| Step: 7
Training loss: 0.8027125597000122
Validation loss: 1.6834983133500623

Epoch: 5| Step: 8
Training loss: 0.9793428182601929
Validation loss: 1.711480176577004

Epoch: 5| Step: 9
Training loss: 0.7086788415908813
Validation loss: 1.7200191937467104

Epoch: 5| Step: 10
Training loss: 1.2179991006851196
Validation loss: 1.7333432089897893

Epoch: 591| Step: 0
Training loss: 0.8067245483398438
Validation loss: 1.7148767350822367

Epoch: 5| Step: 1
Training loss: 1.0490169525146484
Validation loss: 1.7752673997673938

Epoch: 5| Step: 2
Training loss: 1.063320517539978
Validation loss: 1.7240254853361396

Epoch: 5| Step: 3
Training loss: 0.7557107210159302
Validation loss: 1.749936608858006

Epoch: 5| Step: 4
Training loss: 1.4466198682785034
Validation loss: 1.7420294323275167

Epoch: 5| Step: 5
Training loss: 0.8089505434036255
Validation loss: 1.7515405115260874

Epoch: 5| Step: 6
Training loss: 0.6334768533706665
Validation loss: 1.7275483467245614

Epoch: 5| Step: 7
Training loss: 1.0471407175064087
Validation loss: 1.7382024821414743

Epoch: 5| Step: 8
Training loss: 0.6057536005973816
Validation loss: 1.7486826194229947

Epoch: 5| Step: 9
Training loss: 0.6553071141242981
Validation loss: 1.730403833491828

Epoch: 5| Step: 10
Training loss: 1.1239352226257324
Validation loss: 1.709466379175904

Epoch: 592| Step: 0
Training loss: 0.8499536514282227
Validation loss: 1.680049466830428

Epoch: 5| Step: 1
Training loss: 0.9483839869499207
Validation loss: 1.691040954282207

Epoch: 5| Step: 2
Training loss: 1.200554609298706
Validation loss: 1.678774772151824

Epoch: 5| Step: 3
Training loss: 0.9843165278434753
Validation loss: 1.6730834412318405

Epoch: 5| Step: 4
Training loss: 0.9165012240409851
Validation loss: 1.6438151200612385

Epoch: 5| Step: 5
Training loss: 0.8916341066360474
Validation loss: 1.7031746820736957

Epoch: 5| Step: 6
Training loss: 1.319477915763855
Validation loss: 1.7127454614126554

Epoch: 5| Step: 7
Training loss: 0.7167186737060547
Validation loss: 1.715743677590483

Epoch: 5| Step: 8
Training loss: 0.8114582896232605
Validation loss: 1.6817806933515815

Epoch: 5| Step: 9
Training loss: 0.5609675645828247
Validation loss: 1.7185600624289563

Epoch: 5| Step: 10
Training loss: 0.49811631441116333
Validation loss: 1.7312461304408249

Epoch: 593| Step: 0
Training loss: 1.1028962135314941
Validation loss: 1.7170333093212498

Epoch: 5| Step: 1
Training loss: 0.6755551099777222
Validation loss: 1.743307863512347

Epoch: 5| Step: 2
Training loss: 0.7307814955711365
Validation loss: 1.7233860479888095

Epoch: 5| Step: 3
Training loss: 0.8182626962661743
Validation loss: 1.693184132217079

Epoch: 5| Step: 4
Training loss: 0.6279023885726929
Validation loss: 1.7087558648919547

Epoch: 5| Step: 5
Training loss: 0.7730118632316589
Validation loss: 1.7564031795788837

Epoch: 5| Step: 6
Training loss: 1.2883069515228271
Validation loss: 1.7486539604843303

Epoch: 5| Step: 7
Training loss: 1.146449089050293
Validation loss: 1.7216487866576

Epoch: 5| Step: 8
Training loss: 1.126882791519165
Validation loss: 1.7368725384435346

Epoch: 5| Step: 9
Training loss: 1.1754980087280273
Validation loss: 1.694774225193967

Epoch: 5| Step: 10
Training loss: 0.696835994720459
Validation loss: 1.6998406815272507

Epoch: 594| Step: 0
Training loss: 0.8518081903457642
Validation loss: 1.8223329923486198

Epoch: 5| Step: 1
Training loss: 1.2321903705596924
Validation loss: 1.7270271150014733

Epoch: 5| Step: 2
Training loss: 0.7843196988105774
Validation loss: 1.7446214152920632

Epoch: 5| Step: 3
Training loss: 0.5155604481697083
Validation loss: 1.6736560790769515

Epoch: 5| Step: 4
Training loss: 0.7755089998245239
Validation loss: 1.73091858689503

Epoch: 5| Step: 5
Training loss: 1.1384565830230713
Validation loss: 1.7237833879327262

Epoch: 5| Step: 6
Training loss: 0.9496740102767944
Validation loss: 1.6693367112067439

Epoch: 5| Step: 7
Training loss: 0.9230824708938599
Validation loss: 1.7258097894730107

Epoch: 5| Step: 8
Training loss: 1.2985883951187134
Validation loss: 1.6850195084848711

Epoch: 5| Step: 9
Training loss: 0.8535739183425903
Validation loss: 1.680821341852988

Epoch: 5| Step: 10
Training loss: 0.7558833360671997
Validation loss: 1.6717521477771062

Epoch: 595| Step: 0
Training loss: 0.8014340400695801
Validation loss: 1.7439721771465835

Epoch: 5| Step: 1
Training loss: 0.6603256464004517
Validation loss: 1.6783705654964651

Epoch: 5| Step: 2
Training loss: 1.2768915891647339
Validation loss: 1.76496797479609

Epoch: 5| Step: 3
Training loss: 0.8870061635971069
Validation loss: 1.7832925370944444

Epoch: 5| Step: 4
Training loss: 0.8179346323013306
Validation loss: 1.7299611183904833

Epoch: 5| Step: 5
Training loss: 0.8000295758247375
Validation loss: 1.796299252458798

Epoch: 5| Step: 6
Training loss: 0.7547677159309387
Validation loss: 1.7367458420415078

Epoch: 5| Step: 7
Training loss: 0.8763065338134766
Validation loss: 1.7278158331430087

Epoch: 5| Step: 8
Training loss: 0.6483055949211121
Validation loss: 1.8219618874211465

Epoch: 5| Step: 9
Training loss: 1.2865334749221802
Validation loss: 1.7572668085816086

Epoch: 5| Step: 10
Training loss: 0.9928662776947021
Validation loss: 1.769230447789674

Epoch: 596| Step: 0
Training loss: 0.8239259719848633
Validation loss: 1.7048672911941365

Epoch: 5| Step: 1
Training loss: 0.9435089230537415
Validation loss: 1.713488140413838

Epoch: 5| Step: 2
Training loss: 1.2609368562698364
Validation loss: 1.7082974769735848

Epoch: 5| Step: 3
Training loss: 0.6282958984375
Validation loss: 1.6922055047045472

Epoch: 5| Step: 4
Training loss: 0.9221355319023132
Validation loss: 1.712394001663372

Epoch: 5| Step: 5
Training loss: 0.9320372343063354
Validation loss: 1.6954100439625401

Epoch: 5| Step: 6
Training loss: 0.9007787704467773
Validation loss: 1.686066650575207

Epoch: 5| Step: 7
Training loss: 0.9279733896255493
Validation loss: 1.722751288003819

Epoch: 5| Step: 8
Training loss: 1.2048228979110718
Validation loss: 1.7209838116040794

Epoch: 5| Step: 9
Training loss: 0.8077439069747925
Validation loss: 1.6459140328950779

Epoch: 5| Step: 10
Training loss: 0.4040330946445465
Validation loss: 1.7357382312897713

Epoch: 597| Step: 0
Training loss: 0.8050119280815125
Validation loss: 1.7641902457001388

Epoch: 5| Step: 1
Training loss: 1.2957744598388672
Validation loss: 1.699439476895076

Epoch: 5| Step: 2
Training loss: 0.8766632080078125
Validation loss: 1.6997359760345951

Epoch: 5| Step: 3
Training loss: 1.0411392450332642
Validation loss: 1.6994253512351745

Epoch: 5| Step: 4
Training loss: 0.9629127383232117
Validation loss: 1.690619658398372

Epoch: 5| Step: 5
Training loss: 1.2158111333847046
Validation loss: 1.7210693192738358

Epoch: 5| Step: 6
Training loss: 0.7838194966316223
Validation loss: 1.7189942957252584

Epoch: 5| Step: 7
Training loss: 0.7639241218566895
Validation loss: 1.7539059795359129

Epoch: 5| Step: 8
Training loss: 1.1103074550628662
Validation loss: 1.74837452109142

Epoch: 5| Step: 9
Training loss: 0.9137610197067261
Validation loss: 1.7303287457394343

Epoch: 5| Step: 10
Training loss: 0.42236900329589844
Validation loss: 1.7140452323421356

Epoch: 598| Step: 0
Training loss: 0.8404991030693054
Validation loss: 1.7460062619178527

Epoch: 5| Step: 1
Training loss: 1.2703074216842651
Validation loss: 1.7707187642333329

Epoch: 5| Step: 2
Training loss: 1.1744403839111328
Validation loss: 1.7472175090543685

Epoch: 5| Step: 3
Training loss: 0.7920117974281311
Validation loss: 1.7020668868095643

Epoch: 5| Step: 4
Training loss: 0.6861516833305359
Validation loss: 1.7602356435150228

Epoch: 5| Step: 5
Training loss: 0.8356385231018066
Validation loss: 1.7615419536508539

Epoch: 5| Step: 6
Training loss: 0.7421883940696716
Validation loss: 1.7521229251738517

Epoch: 5| Step: 7
Training loss: 0.8608972430229187
Validation loss: 1.7006036978895946

Epoch: 5| Step: 8
Training loss: 0.8297788500785828
Validation loss: 1.7629063834426224

Epoch: 5| Step: 9
Training loss: 0.5557637214660645
Validation loss: 1.7109377230367353

Epoch: 5| Step: 10
Training loss: 1.2688194513320923
Validation loss: 1.7021612018667243

Epoch: 599| Step: 0
Training loss: 0.9894072413444519
Validation loss: 1.7231454233969412

Epoch: 5| Step: 1
Training loss: 1.0412172079086304
Validation loss: 1.7664440883103238

Epoch: 5| Step: 2
Training loss: 1.3977508544921875
Validation loss: 1.7195081364723943

Epoch: 5| Step: 3
Training loss: 1.1206761598587036
Validation loss: 1.6825260885300175

Epoch: 5| Step: 4
Training loss: 0.7790499925613403
Validation loss: 1.7647482054207915

Epoch: 5| Step: 5
Training loss: 0.6272549033164978
Validation loss: 1.686980926862327

Epoch: 5| Step: 6
Training loss: 0.6225738525390625
Validation loss: 1.6978772404373332

Epoch: 5| Step: 7
Training loss: 0.5722683072090149
Validation loss: 1.7080430638405584

Epoch: 5| Step: 8
Training loss: 1.060752272605896
Validation loss: 1.6993895410209574

Epoch: 5| Step: 9
Training loss: 0.9715306162834167
Validation loss: 1.7432341511531542

Epoch: 5| Step: 10
Training loss: 1.020624041557312
Validation loss: 1.6850091411221413

Epoch: 600| Step: 0
Training loss: 0.8018868565559387
Validation loss: 1.6880523171476138

Epoch: 5| Step: 1
Training loss: 0.6584912538528442
Validation loss: 1.7572766529616488

Epoch: 5| Step: 2
Training loss: 0.9275115132331848
Validation loss: 1.7285244567419893

Epoch: 5| Step: 3
Training loss: 1.3480721712112427
Validation loss: 1.688636883612602

Epoch: 5| Step: 4
Training loss: 0.6157985925674438
Validation loss: 1.6835374985971758

Epoch: 5| Step: 5
Training loss: 0.7766603231430054
Validation loss: 1.7285913510989117

Epoch: 5| Step: 6
Training loss: 1.159332275390625
Validation loss: 1.7500541876721125

Epoch: 5| Step: 7
Training loss: 0.7460500001907349
Validation loss: 1.730868140856425

Epoch: 5| Step: 8
Training loss: 1.2885210514068604
Validation loss: 1.7287078378021077

Epoch: 5| Step: 9
Training loss: 0.6825193762779236
Validation loss: 1.7636799273952362

Epoch: 5| Step: 10
Training loss: 0.9116238951683044
Validation loss: 1.717802111820508

Testing loss: 2.283736652798123
