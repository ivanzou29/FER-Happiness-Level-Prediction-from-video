Epoch: 1| Step: 0
Training loss: 5.112025260925293
Validation loss: 5.029885507399036

Epoch: 5| Step: 1
Training loss: 5.092794418334961
Validation loss: 5.022132371061591

Epoch: 5| Step: 2
Training loss: 3.7505264282226562
Validation loss: 5.018699661377938

Epoch: 5| Step: 3
Training loss: 4.547074317932129
Validation loss: 5.01128960681218

Epoch: 5| Step: 4
Training loss: 5.969552516937256
Validation loss: 5.0069529420586045

Epoch: 5| Step: 5
Training loss: 4.860600471496582
Validation loss: 5.001792574441561

Epoch: 5| Step: 6
Training loss: 4.772352695465088
Validation loss: 4.9981151396228425

Epoch: 5| Step: 7
Training loss: 5.787174701690674
Validation loss: 4.994563118104012

Epoch: 5| Step: 8
Training loss: 4.133481502532959
Validation loss: 4.9893260335409515

Epoch: 5| Step: 9
Training loss: 4.079100608825684
Validation loss: 4.984183490917247

Epoch: 5| Step: 10
Training loss: 4.675435543060303
Validation loss: 4.978890075478502

Epoch: 2| Step: 0
Training loss: 3.750347852706909
Validation loss: 4.975569207181213

Epoch: 5| Step: 1
Training loss: 5.193656921386719
Validation loss: 4.969888071860036

Epoch: 5| Step: 2
Training loss: 5.250685214996338
Validation loss: 4.9659271240234375

Epoch: 5| Step: 3
Training loss: 4.4357733726501465
Validation loss: 4.961679802146009

Epoch: 5| Step: 4
Training loss: 5.093614101409912
Validation loss: 4.956776562557425

Epoch: 5| Step: 5
Training loss: 5.806743621826172
Validation loss: 4.952581944004182

Epoch: 5| Step: 6
Training loss: 3.8917179107666016
Validation loss: 4.948520768073298

Epoch: 5| Step: 7
Training loss: 5.611108779907227
Validation loss: 4.943776715186335

Epoch: 5| Step: 8
Training loss: 3.406259536743164
Validation loss: 4.938480084942233

Epoch: 5| Step: 9
Training loss: 4.9861016273498535
Validation loss: 4.9325913408751125

Epoch: 5| Step: 10
Training loss: 4.806609153747559
Validation loss: 4.927087219812536

Epoch: 3| Step: 0
Training loss: 5.7203369140625
Validation loss: 4.926327110618673

Epoch: 5| Step: 1
Training loss: 4.260729789733887
Validation loss: 4.920215488761984

Epoch: 5| Step: 2
Training loss: 4.79604959487915
Validation loss: 4.914805735311201

Epoch: 5| Step: 3
Training loss: 3.8788414001464844
Validation loss: 4.909765499894337

Epoch: 5| Step: 4
Training loss: 4.461562156677246
Validation loss: 4.906554780980592

Epoch: 5| Step: 5
Training loss: 4.668957233428955
Validation loss: 4.901103060732606

Epoch: 5| Step: 6
Training loss: 5.429207801818848
Validation loss: 4.895300967718965

Epoch: 5| Step: 7
Training loss: 4.355423927307129
Validation loss: 4.892521817197082

Epoch: 5| Step: 8
Training loss: 5.359869956970215
Validation loss: 4.885764727028468

Epoch: 5| Step: 9
Training loss: 4.504230499267578
Validation loss: 4.88255367484144

Epoch: 5| Step: 10
Training loss: 4.1513991355896
Validation loss: 4.875868638356526

Epoch: 4| Step: 0
Training loss: 5.397139072418213
Validation loss: 4.871554928441202

Epoch: 5| Step: 1
Training loss: 5.120800971984863
Validation loss: 4.8674514062942995

Epoch: 5| Step: 2
Training loss: 4.346144199371338
Validation loss: 4.8620525739526235

Epoch: 5| Step: 3
Training loss: 4.021164894104004
Validation loss: 4.857411543528239

Epoch: 5| Step: 4
Training loss: 5.469834327697754
Validation loss: 4.852847327468216

Epoch: 5| Step: 5
Training loss: 4.367234706878662
Validation loss: 4.847819928200014

Epoch: 5| Step: 6
Training loss: 4.552532196044922
Validation loss: 4.840202131578999

Epoch: 5| Step: 7
Training loss: 3.965918779373169
Validation loss: 4.836506351347892

Epoch: 5| Step: 8
Training loss: 4.760008335113525
Validation loss: 4.831860152623987

Epoch: 5| Step: 9
Training loss: 3.800846576690674
Validation loss: 4.825669509108349

Epoch: 5| Step: 10
Training loss: 5.341884613037109
Validation loss: 4.820111043991581

Epoch: 5| Step: 0
Training loss: 4.828444480895996
Validation loss: 4.814852622247511

Epoch: 5| Step: 1
Training loss: 3.3005504608154297
Validation loss: 4.810418021294378

Epoch: 5| Step: 2
Training loss: 3.6632981300354004
Validation loss: 4.80473348914936

Epoch: 5| Step: 3
Training loss: 3.8640358448028564
Validation loss: 4.800765011900214

Epoch: 5| Step: 4
Training loss: 6.4937896728515625
Validation loss: 4.793132761473297

Epoch: 5| Step: 5
Training loss: 4.8684515953063965
Validation loss: 4.78933439459852

Epoch: 5| Step: 6
Training loss: 4.863020420074463
Validation loss: 4.782409580804968

Epoch: 5| Step: 7
Training loss: 4.805037021636963
Validation loss: 4.776470491963048

Epoch: 5| Step: 8
Training loss: 4.347575664520264
Validation loss: 4.771862522248299

Epoch: 5| Step: 9
Training loss: 4.28976583480835
Validation loss: 4.765374737401163

Epoch: 5| Step: 10
Training loss: 5.131785869598389
Validation loss: 4.762019152282386

Epoch: 6| Step: 0
Training loss: 4.717155933380127
Validation loss: 4.752749837854857

Epoch: 5| Step: 1
Training loss: 4.982964515686035
Validation loss: 4.747610502345587

Epoch: 5| Step: 2
Training loss: 4.052321434020996
Validation loss: 4.74124159351472

Epoch: 5| Step: 3
Training loss: 3.4242451190948486
Validation loss: 4.733820187148227

Epoch: 5| Step: 4
Training loss: 3.6361446380615234
Validation loss: 4.730595245156237

Epoch: 5| Step: 5
Training loss: 5.482516288757324
Validation loss: 4.7245031326047835

Epoch: 5| Step: 6
Training loss: 5.281800746917725
Validation loss: 4.719788223184565

Epoch: 5| Step: 7
Training loss: 5.389700889587402
Validation loss: 4.714129104409166

Epoch: 5| Step: 8
Training loss: 4.1144490242004395
Validation loss: 4.706122880340905

Epoch: 5| Step: 9
Training loss: 3.507155656814575
Validation loss: 4.702630853140226

Epoch: 5| Step: 10
Training loss: 5.156796455383301
Validation loss: 4.694236099079091

Epoch: 7| Step: 0
Training loss: 4.706263542175293
Validation loss: 4.6872837415305515

Epoch: 5| Step: 1
Training loss: 4.131928443908691
Validation loss: 4.681942419339252

Epoch: 5| Step: 2
Training loss: 3.3935375213623047
Validation loss: 4.673092206319173

Epoch: 5| Step: 3
Training loss: 4.8690900802612305
Validation loss: 4.669618906513337

Epoch: 5| Step: 4
Training loss: 3.966352939605713
Validation loss: 4.65986821984732

Epoch: 5| Step: 5
Training loss: 3.9651882648468018
Validation loss: 4.65726242270521

Epoch: 5| Step: 6
Training loss: 4.208877086639404
Validation loss: 4.650043215802921

Epoch: 5| Step: 7
Training loss: 5.127431392669678
Validation loss: 4.640422615953671

Epoch: 5| Step: 8
Training loss: 4.951696872711182
Validation loss: 4.634147105678435

Epoch: 5| Step: 9
Training loss: 5.471407890319824
Validation loss: 4.630267086849417

Epoch: 5| Step: 10
Training loss: 4.020519733428955
Validation loss: 4.620542997954994

Epoch: 8| Step: 0
Training loss: 4.0223565101623535
Validation loss: 4.616550753193517

Epoch: 5| Step: 1
Training loss: 4.9491071701049805
Validation loss: 4.6092622818485385

Epoch: 5| Step: 2
Training loss: 4.1949687004089355
Validation loss: 4.601576235986525

Epoch: 5| Step: 3
Training loss: 4.255034923553467
Validation loss: 4.594132136273128

Epoch: 5| Step: 4
Training loss: 4.27229118347168
Validation loss: 4.585718770180979

Epoch: 5| Step: 5
Training loss: 4.888416290283203
Validation loss: 4.577962019110239

Epoch: 5| Step: 6
Training loss: 4.354576110839844
Validation loss: 4.568427537077216

Epoch: 5| Step: 7
Training loss: 5.163499355316162
Validation loss: 4.564647997579267

Epoch: 5| Step: 8
Training loss: 3.723844528198242
Validation loss: 4.55765433978009

Epoch: 5| Step: 9
Training loss: 3.9044623374938965
Validation loss: 4.548259289033951

Epoch: 5| Step: 10
Training loss: 4.3198699951171875
Validation loss: 4.541089016904113

Epoch: 9| Step: 0
Training loss: 3.379074811935425
Validation loss: 4.533730230023784

Epoch: 5| Step: 1
Training loss: 4.483493804931641
Validation loss: 4.524234453837077

Epoch: 5| Step: 2
Training loss: 4.261623382568359
Validation loss: 4.516302816329464

Epoch: 5| Step: 3
Training loss: 4.994114398956299
Validation loss: 4.510214503093432

Epoch: 5| Step: 4
Training loss: 5.33560037612915
Validation loss: 4.502743505662488

Epoch: 5| Step: 5
Training loss: 4.1750102043151855
Validation loss: 4.495552432152532

Epoch: 5| Step: 6
Training loss: 4.264101982116699
Validation loss: 4.485304683767339

Epoch: 5| Step: 7
Training loss: 3.5497848987579346
Validation loss: 4.476637671070714

Epoch: 5| Step: 8
Training loss: 3.4025044441223145
Validation loss: 4.4694200843893075

Epoch: 5| Step: 9
Training loss: 4.985835552215576
Validation loss: 4.462208322299424

Epoch: 5| Step: 10
Training loss: 4.272783279418945
Validation loss: 4.450812447455622

Epoch: 10| Step: 0
Training loss: 4.011651992797852
Validation loss: 4.439897696177165

Epoch: 5| Step: 1
Training loss: 4.116563320159912
Validation loss: 4.432391961415608

Epoch: 5| Step: 2
Training loss: 4.449170112609863
Validation loss: 4.42418077940582

Epoch: 5| Step: 3
Training loss: 3.778529405593872
Validation loss: 4.4129737884767595

Epoch: 5| Step: 4
Training loss: 4.356057167053223
Validation loss: 4.408400422783308

Epoch: 5| Step: 5
Training loss: 4.831879615783691
Validation loss: 4.397291337290118

Epoch: 5| Step: 6
Training loss: 4.586803436279297
Validation loss: 4.388235820237027

Epoch: 5| Step: 7
Training loss: 3.442038059234619
Validation loss: 4.378536378183672

Epoch: 5| Step: 8
Training loss: 4.399717807769775
Validation loss: 4.368950105482532

Epoch: 5| Step: 9
Training loss: 3.7896716594696045
Validation loss: 4.3566449021780365

Epoch: 5| Step: 10
Training loss: 4.334837436676025
Validation loss: 4.347746643968808

Epoch: 11| Step: 0
Training loss: 5.149967193603516
Validation loss: 4.338059115153487

Epoch: 5| Step: 1
Training loss: 3.382544994354248
Validation loss: 4.330213577516617

Epoch: 5| Step: 2
Training loss: 5.231800556182861
Validation loss: 4.3211331162401425

Epoch: 5| Step: 3
Training loss: 4.931033134460449
Validation loss: 4.3068222973936345

Epoch: 5| Step: 4
Training loss: 3.3561809062957764
Validation loss: 4.297159676910729

Epoch: 5| Step: 5
Training loss: 3.264617919921875
Validation loss: 4.2885823249816895

Epoch: 5| Step: 6
Training loss: 4.487896919250488
Validation loss: 4.274382442556401

Epoch: 5| Step: 7
Training loss: 4.5838623046875
Validation loss: 4.266444021655667

Epoch: 5| Step: 8
Training loss: 3.153822422027588
Validation loss: 4.257344056201237

Epoch: 5| Step: 9
Training loss: 3.3579506874084473
Validation loss: 4.245771418335617

Epoch: 5| Step: 10
Training loss: 4.076252460479736
Validation loss: 4.232473865632088

Epoch: 12| Step: 0
Training loss: 3.171855926513672
Validation loss: 4.22683540467293

Epoch: 5| Step: 1
Training loss: 2.9404892921447754
Validation loss: 4.2140481600197415

Epoch: 5| Step: 2
Training loss: 3.42228627204895
Validation loss: 4.202273748254263

Epoch: 5| Step: 3
Training loss: 4.146676063537598
Validation loss: 4.189993678882558

Epoch: 5| Step: 4
Training loss: 4.0985517501831055
Validation loss: 4.1797283977590585

Epoch: 5| Step: 5
Training loss: 3.8646183013916016
Validation loss: 4.164623732207923

Epoch: 5| Step: 6
Training loss: 4.483216285705566
Validation loss: 4.155371619809058

Epoch: 5| Step: 7
Training loss: 4.2118377685546875
Validation loss: 4.140439171944895

Epoch: 5| Step: 8
Training loss: 4.140701770782471
Validation loss: 4.132678565158639

Epoch: 5| Step: 9
Training loss: 4.390707492828369
Validation loss: 4.1177124566929315

Epoch: 5| Step: 10
Training loss: 5.004879951477051
Validation loss: 4.107967712545908

Epoch: 13| Step: 0
Training loss: 3.716383695602417
Validation loss: 4.097447961889287

Epoch: 5| Step: 1
Training loss: 4.04203987121582
Validation loss: 4.081125331181352

Epoch: 5| Step: 2
Training loss: 3.753464460372925
Validation loss: 4.067053723078902

Epoch: 5| Step: 3
Training loss: 3.324127197265625
Validation loss: 4.055076640139344

Epoch: 5| Step: 4
Training loss: 3.8610291481018066
Validation loss: 4.048749239214005

Epoch: 5| Step: 5
Training loss: 4.003549098968506
Validation loss: 4.032060418077695

Epoch: 5| Step: 6
Training loss: 3.3081181049346924
Validation loss: 4.014105407140589

Epoch: 5| Step: 7
Training loss: 4.191638946533203
Validation loss: 4.001624866198468

Epoch: 5| Step: 8
Training loss: 3.966866970062256
Validation loss: 3.9891257311708186

Epoch: 5| Step: 9
Training loss: 4.363374710083008
Validation loss: 3.9748983895906838

Epoch: 5| Step: 10
Training loss: 3.932840347290039
Validation loss: 3.9646058005671345

Epoch: 14| Step: 0
Training loss: 4.228848457336426
Validation loss: 3.947874028195617

Epoch: 5| Step: 1
Training loss: 4.117194175720215
Validation loss: 3.9349871655946136

Epoch: 5| Step: 2
Training loss: 3.3468899726867676
Validation loss: 3.92646602917743

Epoch: 5| Step: 3
Training loss: 4.079803943634033
Validation loss: 3.911802368779336

Epoch: 5| Step: 4
Training loss: 4.607659816741943
Validation loss: 3.8974115976723294

Epoch: 5| Step: 5
Training loss: 3.5979514122009277
Validation loss: 3.8764860501853367

Epoch: 5| Step: 6
Training loss: 3.1629161834716797
Validation loss: 3.868895317918511

Epoch: 5| Step: 7
Training loss: 3.3180477619171143
Validation loss: 3.8507793795677925

Epoch: 5| Step: 8
Training loss: 3.3572869300842285
Validation loss: 3.8371041333803566

Epoch: 5| Step: 9
Training loss: 3.5325751304626465
Validation loss: 3.8252325237438245

Epoch: 5| Step: 10
Training loss: 3.6994779109954834
Validation loss: 3.814089652030699

Epoch: 15| Step: 0
Training loss: 3.5342679023742676
Validation loss: 3.799551087041055

Epoch: 5| Step: 1
Training loss: 3.3766911029815674
Validation loss: 3.782378178770824

Epoch: 5| Step: 2
Training loss: 3.9005424976348877
Validation loss: 3.767513480237735

Epoch: 5| Step: 3
Training loss: 4.009562969207764
Validation loss: 3.7570010769751763

Epoch: 5| Step: 4
Training loss: 3.1992480754852295
Validation loss: 3.7414789328011135

Epoch: 5| Step: 5
Training loss: 3.2937920093536377
Validation loss: 3.7270540627100135

Epoch: 5| Step: 6
Training loss: 3.4110865592956543
Validation loss: 3.712723890940348

Epoch: 5| Step: 7
Training loss: 3.6257522106170654
Validation loss: 3.695953784450408

Epoch: 5| Step: 8
Training loss: 4.772027015686035
Validation loss: 3.6801998897265364

Epoch: 5| Step: 9
Training loss: 3.5102622509002686
Validation loss: 3.6580514472018004

Epoch: 5| Step: 10
Training loss: 2.7677536010742188
Validation loss: 3.6480404843566236

Epoch: 16| Step: 0
Training loss: 3.793395519256592
Validation loss: 3.6334517848107124

Epoch: 5| Step: 1
Training loss: 3.2585246562957764
Validation loss: 3.6202798863892913

Epoch: 5| Step: 2
Training loss: 2.9982409477233887
Validation loss: 3.6023732974965084

Epoch: 5| Step: 3
Training loss: 2.9734768867492676
Validation loss: 3.5806713258066485

Epoch: 5| Step: 4
Training loss: 4.171483993530273
Validation loss: 3.5682150676686275

Epoch: 5| Step: 5
Training loss: 3.5592377185821533
Validation loss: 3.558659415091238

Epoch: 5| Step: 6
Training loss: 3.524054765701294
Validation loss: 3.5341816512487267

Epoch: 5| Step: 7
Training loss: 3.025372266769409
Validation loss: 3.5193018913269043

Epoch: 5| Step: 8
Training loss: 3.5950608253479004
Validation loss: 3.4984371354503017

Epoch: 5| Step: 9
Training loss: 3.695262908935547
Validation loss: 3.4894893246312297

Epoch: 5| Step: 10
Training loss: 3.2802181243896484
Validation loss: 3.4669524828592935

Epoch: 17| Step: 0
Training loss: 3.9166622161865234
Validation loss: 3.4508049436794814

Epoch: 5| Step: 1
Training loss: 3.1562774181365967
Validation loss: 3.433864470451109

Epoch: 5| Step: 2
Training loss: 3.122724771499634
Validation loss: 3.4131880626883557

Epoch: 5| Step: 3
Training loss: 3.244171142578125
Validation loss: 3.393201228111021

Epoch: 5| Step: 4
Training loss: 3.852487087249756
Validation loss: 3.37752608073655

Epoch: 5| Step: 5
Training loss: 2.526811361312866
Validation loss: 3.3558486020693215

Epoch: 5| Step: 6
Training loss: 3.694868564605713
Validation loss: 3.340100642173521

Epoch: 5| Step: 7
Training loss: 3.551236629486084
Validation loss: 3.3193685188088367

Epoch: 5| Step: 8
Training loss: 2.5995187759399414
Validation loss: 3.3048508936359036

Epoch: 5| Step: 9
Training loss: 3.2407402992248535
Validation loss: 3.278596770378851

Epoch: 5| Step: 10
Training loss: 3.16705322265625
Validation loss: 3.2642989132993963

Epoch: 18| Step: 0
Training loss: 4.166569709777832
Validation loss: 3.245962219853555

Epoch: 5| Step: 1
Training loss: 2.7662863731384277
Validation loss: 3.225593092621014

Epoch: 5| Step: 2
Training loss: 3.183178663253784
Validation loss: 3.201160584726641

Epoch: 5| Step: 3
Training loss: 2.928307294845581
Validation loss: 3.1845805209170104

Epoch: 5| Step: 4
Training loss: 3.3791861534118652
Validation loss: 3.1555714991784867

Epoch: 5| Step: 5
Training loss: 3.124720335006714
Validation loss: 3.1386920431608796

Epoch: 5| Step: 6
Training loss: 2.51682710647583
Validation loss: 3.1201393809369815

Epoch: 5| Step: 7
Training loss: 3.918818950653076
Validation loss: 3.0995957287408973

Epoch: 5| Step: 8
Training loss: 2.580230236053467
Validation loss: 3.071876954006892

Epoch: 5| Step: 9
Training loss: 2.0806820392608643
Validation loss: 3.0608154804475847

Epoch: 5| Step: 10
Training loss: 3.5473852157592773
Validation loss: 3.0322041742263304

Epoch: 19| Step: 0
Training loss: 3.2727744579315186
Validation loss: 3.0114097287577968

Epoch: 5| Step: 1
Training loss: 2.94226336479187
Validation loss: 2.9903861579074653

Epoch: 5| Step: 2
Training loss: 3.15616512298584
Validation loss: 2.967142476830431

Epoch: 5| Step: 3
Training loss: 2.549849033355713
Validation loss: 2.94787428199604

Epoch: 5| Step: 4
Training loss: 3.632970094680786
Validation loss: 2.93079444413544

Epoch: 5| Step: 5
Training loss: 2.699209213256836
Validation loss: 2.9108590848984255

Epoch: 5| Step: 6
Training loss: 2.5464494228363037
Validation loss: 2.8990263451812086

Epoch: 5| Step: 7
Training loss: 2.79661226272583
Validation loss: 2.8777881027549825

Epoch: 5| Step: 8
Training loss: 2.9877333641052246
Validation loss: 2.844412560104042

Epoch: 5| Step: 9
Training loss: 2.6333765983581543
Validation loss: 2.8395898367768977

Epoch: 5| Step: 10
Training loss: 3.062166213989258
Validation loss: 2.81849758086666

Epoch: 20| Step: 0
Training loss: 2.637620210647583
Validation loss: 2.802957816790509

Epoch: 5| Step: 1
Training loss: 2.884065628051758
Validation loss: 2.770026142879199

Epoch: 5| Step: 2
Training loss: 3.3233635425567627
Validation loss: 2.758198297151955

Epoch: 5| Step: 3
Training loss: 2.1237194538116455
Validation loss: 2.7379142956067155

Epoch: 5| Step: 4
Training loss: 2.189535617828369
Validation loss: 2.7253727989812053

Epoch: 5| Step: 5
Training loss: 3.3482232093811035
Validation loss: 2.7033889703853156

Epoch: 5| Step: 6
Training loss: 2.4581010341644287
Validation loss: 2.6821525199438936

Epoch: 5| Step: 7
Training loss: 3.575855255126953
Validation loss: 2.6762195838394987

Epoch: 5| Step: 8
Training loss: 2.8774240016937256
Validation loss: 2.6463029615340696

Epoch: 5| Step: 9
Training loss: 2.1806564331054688
Validation loss: 2.6240936120351157

Epoch: 5| Step: 10
Training loss: 3.110905170440674
Validation loss: 2.6191714707241265

Epoch: 21| Step: 0
Training loss: 2.9077858924865723
Validation loss: 2.6008013012588664

Epoch: 5| Step: 1
Training loss: 2.3304855823516846
Validation loss: 2.565457623492005

Epoch: 5| Step: 2
Training loss: 3.0193259716033936
Validation loss: 2.5576867006158315

Epoch: 5| Step: 3
Training loss: 2.591738224029541
Validation loss: 2.535517361856276

Epoch: 5| Step: 4
Training loss: 2.9363598823547363
Validation loss: 2.5217320124308267

Epoch: 5| Step: 5
Training loss: 2.342033863067627
Validation loss: 2.512834108004006

Epoch: 5| Step: 6
Training loss: 2.3147294521331787
Validation loss: 2.479843803631362

Epoch: 5| Step: 7
Training loss: 3.022648811340332
Validation loss: 2.4636308147061254

Epoch: 5| Step: 8
Training loss: 2.748878002166748
Validation loss: 2.4344181014645483

Epoch: 5| Step: 9
Training loss: 2.4934866428375244
Validation loss: 2.436981601099814

Epoch: 5| Step: 10
Training loss: 2.5334365367889404
Validation loss: 2.4101034005482993

Epoch: 22| Step: 0
Training loss: 2.4459309577941895
Validation loss: 2.4000771302048878

Epoch: 5| Step: 1
Training loss: 2.263301372528076
Validation loss: 2.383429078645604

Epoch: 5| Step: 2
Training loss: 3.23834490776062
Validation loss: 2.3839818328939457

Epoch: 5| Step: 3
Training loss: 2.5363571643829346
Validation loss: 2.361694557692415

Epoch: 5| Step: 4
Training loss: 2.1212377548217773
Validation loss: 2.344699398163826

Epoch: 5| Step: 5
Training loss: 2.666886568069458
Validation loss: 2.3517227019033125

Epoch: 5| Step: 6
Training loss: 2.4770724773406982
Validation loss: 2.3372086991545973

Epoch: 5| Step: 7
Training loss: 2.8230748176574707
Validation loss: 2.3344183070685274

Epoch: 5| Step: 8
Training loss: 2.354016065597534
Validation loss: 2.322987828203427

Epoch: 5| Step: 9
Training loss: 2.526693105697632
Validation loss: 2.2983158403827297

Epoch: 5| Step: 10
Training loss: 2.301754951477051
Validation loss: 2.301542771759854

Epoch: 23| Step: 0
Training loss: 2.2802376747131348
Validation loss: 2.2947510955154256

Epoch: 5| Step: 1
Training loss: 2.8289856910705566
Validation loss: 2.283202176452965

Epoch: 5| Step: 2
Training loss: 2.425189733505249
Validation loss: 2.2631850627160843

Epoch: 5| Step: 3
Training loss: 2.2707936763763428
Validation loss: 2.266221784776257

Epoch: 5| Step: 4
Training loss: 2.515063762664795
Validation loss: 2.2360952977211244

Epoch: 5| Step: 5
Training loss: 2.7656643390655518
Validation loss: 2.255498898926602

Epoch: 5| Step: 6
Training loss: 2.101620674133301
Validation loss: 2.2370143987799205

Epoch: 5| Step: 7
Training loss: 2.3342480659484863
Validation loss: 2.248730772285051

Epoch: 5| Step: 8
Training loss: 2.4146921634674072
Validation loss: 2.242837139355239

Epoch: 5| Step: 9
Training loss: 2.7798259258270264
Validation loss: 2.207663966763404

Epoch: 5| Step: 10
Training loss: 2.360844373703003
Validation loss: 2.223564565822642

Epoch: 24| Step: 0
Training loss: 2.3836982250213623
Validation loss: 2.2156054742874636

Epoch: 5| Step: 1
Training loss: 2.5691683292388916
Validation loss: 2.210257835285638

Epoch: 5| Step: 2
Training loss: 2.199686288833618
Validation loss: 2.195482307864774

Epoch: 5| Step: 3
Training loss: 3.0429701805114746
Validation loss: 2.1980555108798447

Epoch: 5| Step: 4
Training loss: 2.3872084617614746
Validation loss: 2.189568168373518

Epoch: 5| Step: 5
Training loss: 2.186767101287842
Validation loss: 2.181741729859383

Epoch: 5| Step: 6
Training loss: 1.971353530883789
Validation loss: 2.1890429322437575

Epoch: 5| Step: 7
Training loss: 2.591726303100586
Validation loss: 2.180027938658191

Epoch: 5| Step: 8
Training loss: 2.498884677886963
Validation loss: 2.1887535664343063

Epoch: 5| Step: 9
Training loss: 2.375314235687256
Validation loss: 2.1574698289235434

Epoch: 5| Step: 10
Training loss: 2.5420591831207275
Validation loss: 2.1615143386266564

Epoch: 25| Step: 0
Training loss: 2.3831801414489746
Validation loss: 2.1650815471526115

Epoch: 5| Step: 1
Training loss: 2.1750686168670654
Validation loss: 2.1654870305010068

Epoch: 5| Step: 2
Training loss: 3.4145569801330566
Validation loss: 2.152639194201398

Epoch: 5| Step: 3
Training loss: 2.6619317531585693
Validation loss: 2.1593914608801565

Epoch: 5| Step: 4
Training loss: 2.4750466346740723
Validation loss: 2.1572502569485734

Epoch: 5| Step: 5
Training loss: 1.954030990600586
Validation loss: 2.1488548286499514

Epoch: 5| Step: 6
Training loss: 2.05133318901062
Validation loss: 2.1633400122324624

Epoch: 5| Step: 7
Training loss: 2.4234883785247803
Validation loss: 2.170714662921044

Epoch: 5| Step: 8
Training loss: 2.0682132244110107
Validation loss: 2.1498124868639055

Epoch: 5| Step: 9
Training loss: 2.885982036590576
Validation loss: 2.1578373960269395

Epoch: 5| Step: 10
Training loss: 2.0301191806793213
Validation loss: 2.154419811823035

Epoch: 26| Step: 0
Training loss: 3.2178986072540283
Validation loss: 2.1625603078514017

Epoch: 5| Step: 1
Training loss: 2.55334734916687
Validation loss: 2.132330911133879

Epoch: 5| Step: 2
Training loss: 2.328155517578125
Validation loss: 2.1668972610145487

Epoch: 5| Step: 3
Training loss: 2.197103261947632
Validation loss: 2.1514494367825088

Epoch: 5| Step: 4
Training loss: 2.302774429321289
Validation loss: 2.157038099022322

Epoch: 5| Step: 5
Training loss: 2.711949110031128
Validation loss: 2.1443873579784105

Epoch: 5| Step: 6
Training loss: 2.500175952911377
Validation loss: 2.155343850453695

Epoch: 5| Step: 7
Training loss: 1.9727271795272827
Validation loss: 2.15781666386512

Epoch: 5| Step: 8
Training loss: 2.3441433906555176
Validation loss: 2.1521637375636766

Epoch: 5| Step: 9
Training loss: 2.3203587532043457
Validation loss: 2.15251580361397

Epoch: 5| Step: 10
Training loss: 1.984344720840454
Validation loss: 2.128299800298547

Epoch: 27| Step: 0
Training loss: 2.259634017944336
Validation loss: 2.145155986150106

Epoch: 5| Step: 1
Training loss: 2.403258800506592
Validation loss: 2.1522236254907425

Epoch: 5| Step: 2
Training loss: 3.060840129852295
Validation loss: 2.128942815206384

Epoch: 5| Step: 3
Training loss: 2.6098647117614746
Validation loss: 2.141849770340868

Epoch: 5| Step: 4
Training loss: 2.626293420791626
Validation loss: 2.140772177327064

Epoch: 5| Step: 5
Training loss: 2.1508612632751465
Validation loss: 2.136057871644215

Epoch: 5| Step: 6
Training loss: 2.031160354614258
Validation loss: 2.1342667277141283

Epoch: 5| Step: 7
Training loss: 3.0295097827911377
Validation loss: 2.1494884234602734

Epoch: 5| Step: 8
Training loss: 2.172032117843628
Validation loss: 2.1403806747928744

Epoch: 5| Step: 9
Training loss: 1.5673249959945679
Validation loss: 2.1384131370052213

Epoch: 5| Step: 10
Training loss: 2.666975975036621
Validation loss: 2.1172648168379262

Epoch: 28| Step: 0
Training loss: 1.630393624305725
Validation loss: 2.13278357700635

Epoch: 5| Step: 1
Training loss: 2.8981432914733887
Validation loss: 2.1281261879910707

Epoch: 5| Step: 2
Training loss: 2.8229165077209473
Validation loss: 2.1384750284174436

Epoch: 5| Step: 3
Training loss: 2.278761625289917
Validation loss: 2.136553810488793

Epoch: 5| Step: 4
Training loss: 1.9706093072891235
Validation loss: 2.1283034278500463

Epoch: 5| Step: 5
Training loss: 2.389214515686035
Validation loss: 2.1190264994098293

Epoch: 5| Step: 6
Training loss: 3.3692116737365723
Validation loss: 2.121054446825417

Epoch: 5| Step: 7
Training loss: 1.8698718547821045
Validation loss: 2.130370129821121

Epoch: 5| Step: 8
Training loss: 2.8123106956481934
Validation loss: 2.131171913557155

Epoch: 5| Step: 9
Training loss: 2.412262201309204
Validation loss: 2.132151952353857

Epoch: 5| Step: 10
Training loss: 1.8664047718048096
Validation loss: 2.132706665223645

Epoch: 29| Step: 0
Training loss: 2.2246172428131104
Validation loss: 2.1327923344027613

Epoch: 5| Step: 1
Training loss: 2.226205348968506
Validation loss: 2.117060278051643

Epoch: 5| Step: 2
Training loss: 2.541930913925171
Validation loss: 2.1489792626391173

Epoch: 5| Step: 3
Training loss: 1.7559101581573486
Validation loss: 2.1284631926526307

Epoch: 5| Step: 4
Training loss: 2.657827377319336
Validation loss: 2.1287187094329507

Epoch: 5| Step: 5
Training loss: 1.7824665307998657
Validation loss: 2.1433429512926327

Epoch: 5| Step: 6
Training loss: 3.326411724090576
Validation loss: 2.119995455588064

Epoch: 5| Step: 7
Training loss: 2.189652919769287
Validation loss: 2.144015960795905

Epoch: 5| Step: 8
Training loss: 2.858469247817993
Validation loss: 2.137151692503242

Epoch: 5| Step: 9
Training loss: 2.1919071674346924
Validation loss: 2.128201251388878

Epoch: 5| Step: 10
Training loss: 2.737658739089966
Validation loss: 2.131236560883061

Epoch: 30| Step: 0
Training loss: 2.4029324054718018
Validation loss: 2.126905192611038

Epoch: 5| Step: 1
Training loss: 2.5015981197357178
Validation loss: 2.144889147050919

Epoch: 5| Step: 2
Training loss: 2.443694829940796
Validation loss: 2.133661652124056

Epoch: 5| Step: 3
Training loss: 2.2394258975982666
Validation loss: 2.1273991318159204

Epoch: 5| Step: 4
Training loss: 2.8966064453125
Validation loss: 2.129085381825765

Epoch: 5| Step: 5
Training loss: 2.920175790786743
Validation loss: 2.142648927627071

Epoch: 5| Step: 6
Training loss: 2.4103894233703613
Validation loss: 2.1224699892023557

Epoch: 5| Step: 7
Training loss: 2.0390806198120117
Validation loss: 2.1273650712864374

Epoch: 5| Step: 8
Training loss: 2.240802526473999
Validation loss: 2.1285828621156755

Epoch: 5| Step: 9
Training loss: 1.7613893747329712
Validation loss: 2.1354051610474944

Epoch: 5| Step: 10
Training loss: 2.5815205574035645
Validation loss: 2.1297632519916823

Epoch: 31| Step: 0
Training loss: 1.950635313987732
Validation loss: 2.1371567659480597

Epoch: 5| Step: 1
Training loss: 2.6269328594207764
Validation loss: 2.1348507686327864

Epoch: 5| Step: 2
Training loss: 2.2726387977600098
Validation loss: 2.146247125441028

Epoch: 5| Step: 3
Training loss: 2.5538361072540283
Validation loss: 2.1161050488871913

Epoch: 5| Step: 4
Training loss: 2.283385753631592
Validation loss: 2.1271745363871255

Epoch: 5| Step: 5
Training loss: 2.11480975151062
Validation loss: 2.129247506459554

Epoch: 5| Step: 6
Training loss: 2.4457879066467285
Validation loss: 2.126594656257219

Epoch: 5| Step: 7
Training loss: 2.6409194469451904
Validation loss: 2.122328132711431

Epoch: 5| Step: 8
Training loss: 2.157296657562256
Validation loss: 2.134122503701077

Epoch: 5| Step: 9
Training loss: 2.2785775661468506
Validation loss: 2.1237005623438026

Epoch: 5| Step: 10
Training loss: 3.167534351348877
Validation loss: 2.114445629940238

Epoch: 32| Step: 0
Training loss: 2.304783582687378
Validation loss: 2.120330536237327

Epoch: 5| Step: 1
Training loss: 1.997978925704956
Validation loss: 2.1175001039299914

Epoch: 5| Step: 2
Training loss: 2.511486530303955
Validation loss: 2.1300414608370875

Epoch: 5| Step: 3
Training loss: 2.2517948150634766
Validation loss: 2.130575926073136

Epoch: 5| Step: 4
Training loss: 1.8586483001708984
Validation loss: 2.1176190837737052

Epoch: 5| Step: 5
Training loss: 2.6500966548919678
Validation loss: 2.127377462643449

Epoch: 5| Step: 6
Training loss: 2.856327772140503
Validation loss: 2.1175162728114794

Epoch: 5| Step: 7
Training loss: 2.832298517227173
Validation loss: 2.110482795264131

Epoch: 5| Step: 8
Training loss: 2.051091194152832
Validation loss: 2.12955020576395

Epoch: 5| Step: 9
Training loss: 2.609532117843628
Validation loss: 2.1202752282542567

Epoch: 5| Step: 10
Training loss: 2.3193159103393555
Validation loss: 2.126773226645685

Epoch: 33| Step: 0
Training loss: 2.036187171936035
Validation loss: 2.13366352358172

Epoch: 5| Step: 1
Training loss: 2.481868028640747
Validation loss: 2.1331599386789466

Epoch: 5| Step: 2
Training loss: 2.198434829711914
Validation loss: 2.116745255326712

Epoch: 5| Step: 3
Training loss: 2.9576783180236816
Validation loss: 2.140158107203822

Epoch: 5| Step: 4
Training loss: 2.7089500427246094
Validation loss: 2.133265459409324

Epoch: 5| Step: 5
Training loss: 2.149066209793091
Validation loss: 2.123269240061442

Epoch: 5| Step: 6
Training loss: 2.2851474285125732
Validation loss: 2.1144306018788326

Epoch: 5| Step: 7
Training loss: 2.484480619430542
Validation loss: 2.1342817634664555

Epoch: 5| Step: 8
Training loss: 2.2329671382904053
Validation loss: 2.1218096056292133

Epoch: 5| Step: 9
Training loss: 2.3965821266174316
Validation loss: 2.129338925884616

Epoch: 5| Step: 10
Training loss: 2.357365846633911
Validation loss: 2.1193383842386226

Epoch: 34| Step: 0
Training loss: 2.129497766494751
Validation loss: 2.1156541455176567

Epoch: 5| Step: 1
Training loss: 2.639930486679077
Validation loss: 2.132164652629565

Epoch: 5| Step: 2
Training loss: 2.155163526535034
Validation loss: 2.1110931109356623

Epoch: 5| Step: 3
Training loss: 1.6684772968292236
Validation loss: 2.110684597364036

Epoch: 5| Step: 4
Training loss: 3.2052001953125
Validation loss: 2.1270921127770537

Epoch: 5| Step: 5
Training loss: 2.581810235977173
Validation loss: 2.1236695320375505

Epoch: 5| Step: 6
Training loss: 2.4434871673583984
Validation loss: 2.123523227630123

Epoch: 5| Step: 7
Training loss: 2.3782119750976562
Validation loss: 2.1193402274962394

Epoch: 5| Step: 8
Training loss: 2.130092144012451
Validation loss: 2.111001758165257

Epoch: 5| Step: 9
Training loss: 2.1269631385803223
Validation loss: 2.1317298194413543

Epoch: 5| Step: 10
Training loss: 2.574028968811035
Validation loss: 2.11909225679213

Epoch: 35| Step: 0
Training loss: 2.4045767784118652
Validation loss: 2.1208932681750228

Epoch: 5| Step: 1
Training loss: 2.5935168266296387
Validation loss: 2.116205665373033

Epoch: 5| Step: 2
Training loss: 2.701571464538574
Validation loss: 2.1290620193686536

Epoch: 5| Step: 3
Training loss: 2.6139214038848877
Validation loss: 2.125609479924684

Epoch: 5| Step: 4
Training loss: 2.355919599533081
Validation loss: 2.1270942213714763

Epoch: 5| Step: 5
Training loss: 2.403472900390625
Validation loss: 2.1203876592779674

Epoch: 5| Step: 6
Training loss: 1.852800726890564
Validation loss: 2.137278505550918

Epoch: 5| Step: 7
Training loss: 2.517540693283081
Validation loss: 2.1192980325350197

Epoch: 5| Step: 8
Training loss: 1.488642930984497
Validation loss: 2.115313353077058

Epoch: 5| Step: 9
Training loss: 2.5766093730926514
Validation loss: 2.114519780681979

Epoch: 5| Step: 10
Training loss: 2.6457865238189697
Validation loss: 2.138132174809774

Epoch: 36| Step: 0
Training loss: 2.1099276542663574
Validation loss: 2.1184978062106716

Epoch: 5| Step: 1
Training loss: 1.5151132345199585
Validation loss: 2.111082528227119

Epoch: 5| Step: 2
Training loss: 1.855542778968811
Validation loss: 2.129385843071886

Epoch: 5| Step: 3
Training loss: 2.1728174686431885
Validation loss: 2.1077062814466414

Epoch: 5| Step: 4
Training loss: 2.754417896270752
Validation loss: 2.1251926960483676

Epoch: 5| Step: 5
Training loss: 2.1267313957214355
Validation loss: 2.1239509121064217

Epoch: 5| Step: 6
Training loss: 2.679386615753174
Validation loss: 2.1238612103205856

Epoch: 5| Step: 7
Training loss: 2.6184940338134766
Validation loss: 2.1081769620218584

Epoch: 5| Step: 8
Training loss: 2.898646831512451
Validation loss: 2.108313334885464

Epoch: 5| Step: 9
Training loss: 2.8158481121063232
Validation loss: 2.101663999660041

Epoch: 5| Step: 10
Training loss: 2.5286457538604736
Validation loss: 2.1068565922398723

Epoch: 37| Step: 0
Training loss: 2.7347347736358643
Validation loss: 2.116690287026026

Epoch: 5| Step: 1
Training loss: 2.2015297412872314
Validation loss: 2.1048535480294177

Epoch: 5| Step: 2
Training loss: 2.114597797393799
Validation loss: 2.1185516721458844

Epoch: 5| Step: 3
Training loss: 2.6678481101989746
Validation loss: 2.1039070749795563

Epoch: 5| Step: 4
Training loss: 2.210216522216797
Validation loss: 2.104688180390225

Epoch: 5| Step: 5
Training loss: 2.0781517028808594
Validation loss: 2.0984466844989407

Epoch: 5| Step: 6
Training loss: 2.3946986198425293
Validation loss: 2.106625267254409

Epoch: 5| Step: 7
Training loss: 2.636564254760742
Validation loss: 2.0936007320239978

Epoch: 5| Step: 8
Training loss: 2.443856716156006
Validation loss: 2.100984063199771

Epoch: 5| Step: 9
Training loss: 2.4807446002960205
Validation loss: 2.114601348036079

Epoch: 5| Step: 10
Training loss: 1.9881871938705444
Validation loss: 2.119014770753922

Epoch: 38| Step: 0
Training loss: 2.1504218578338623
Validation loss: 2.1156830249294156

Epoch: 5| Step: 1
Training loss: 2.4865596294403076
Validation loss: 2.1082406044006348

Epoch: 5| Step: 2
Training loss: 2.2443978786468506
Validation loss: 2.1038299350328344

Epoch: 5| Step: 3
Training loss: 2.3652515411376953
Validation loss: 2.130263743862029

Epoch: 5| Step: 4
Training loss: 2.3178601264953613
Validation loss: 2.11121872163588

Epoch: 5| Step: 5
Training loss: 2.6770501136779785
Validation loss: 2.1062242369497977

Epoch: 5| Step: 6
Training loss: 2.234884023666382
Validation loss: 2.106094850006924

Epoch: 5| Step: 7
Training loss: 2.420076847076416
Validation loss: 2.100558738554678

Epoch: 5| Step: 8
Training loss: 2.6017918586730957
Validation loss: 2.1104921833161385

Epoch: 5| Step: 9
Training loss: 2.1858527660369873
Validation loss: 2.1087913333728747

Epoch: 5| Step: 10
Training loss: 2.189586877822876
Validation loss: 2.1099641425635225

Epoch: 39| Step: 0
Training loss: 2.007996082305908
Validation loss: 2.101274544192899

Epoch: 5| Step: 1
Training loss: 2.2520804405212402
Validation loss: 2.124274048753964

Epoch: 5| Step: 2
Training loss: 2.348242998123169
Validation loss: 2.0898300037589124

Epoch: 5| Step: 3
Training loss: 2.5968515872955322
Validation loss: 2.1106922113767235

Epoch: 5| Step: 4
Training loss: 1.9737892150878906
Validation loss: 2.099486379213231

Epoch: 5| Step: 5
Training loss: 2.341543674468994
Validation loss: 2.1143146227764826

Epoch: 5| Step: 6
Training loss: 2.789726972579956
Validation loss: 2.094815722075842

Epoch: 5| Step: 7
Training loss: 3.070664167404175
Validation loss: 2.1169406060249574

Epoch: 5| Step: 8
Training loss: 1.6916834115982056
Validation loss: 2.0989195172504713

Epoch: 5| Step: 9
Training loss: 2.3254125118255615
Validation loss: 2.105050940667429

Epoch: 5| Step: 10
Training loss: 2.5134077072143555
Validation loss: 2.1182868378136748

Epoch: 40| Step: 0
Training loss: 2.11313533782959
Validation loss: 2.104646485338929

Epoch: 5| Step: 1
Training loss: 2.2908780574798584
Validation loss: 2.1106160122861146

Epoch: 5| Step: 2
Training loss: 2.0561652183532715
Validation loss: 2.105528002144188

Epoch: 5| Step: 3
Training loss: 2.1343626976013184
Validation loss: 2.120094055770546

Epoch: 5| Step: 4
Training loss: 2.5345005989074707
Validation loss: 2.1136141746274886

Epoch: 5| Step: 5
Training loss: 2.8128509521484375
Validation loss: 2.0931656488808255

Epoch: 5| Step: 6
Training loss: 2.0144600868225098
Validation loss: 2.0982565033820366

Epoch: 5| Step: 7
Training loss: 2.4195568561553955
Validation loss: 2.107254283402556

Epoch: 5| Step: 8
Training loss: 2.3184218406677246
Validation loss: 2.120990401955061

Epoch: 5| Step: 9
Training loss: 3.0727756023406982
Validation loss: 2.0926779495772494

Epoch: 5| Step: 10
Training loss: 2.05676007270813
Validation loss: 2.101583501344086

Epoch: 41| Step: 0
Training loss: 2.763847827911377
Validation loss: 2.096293833947951

Epoch: 5| Step: 1
Training loss: 2.554757595062256
Validation loss: 2.089126770214368

Epoch: 5| Step: 2
Training loss: 2.7996950149536133
Validation loss: 2.0864482541238107

Epoch: 5| Step: 3
Training loss: 2.442531108856201
Validation loss: 2.0916563310930805

Epoch: 5| Step: 4
Training loss: 2.0375537872314453
Validation loss: 2.1099663498581096

Epoch: 5| Step: 5
Training loss: 1.9650596380233765
Validation loss: 2.090464695807426

Epoch: 5| Step: 6
Training loss: 2.136284589767456
Validation loss: 2.0999429482285694

Epoch: 5| Step: 7
Training loss: 1.9005876779556274
Validation loss: 2.0867650675517257

Epoch: 5| Step: 8
Training loss: 2.369194269180298
Validation loss: 2.106007965662146

Epoch: 5| Step: 9
Training loss: 2.190915584564209
Validation loss: 2.088592827961009

Epoch: 5| Step: 10
Training loss: 2.6749136447906494
Validation loss: 2.092673340151387

Epoch: 42| Step: 0
Training loss: 2.2875189781188965
Validation loss: 2.0926518850429083

Epoch: 5| Step: 1
Training loss: 2.2167577743530273
Validation loss: 2.096626122792562

Epoch: 5| Step: 2
Training loss: 2.598529577255249
Validation loss: 2.104446808497111

Epoch: 5| Step: 3
Training loss: 2.690826416015625
Validation loss: 2.1054024414349626

Epoch: 5| Step: 4
Training loss: 2.248185396194458
Validation loss: 2.1012390531519407

Epoch: 5| Step: 5
Training loss: 2.3290398120880127
Validation loss: 2.095141613355247

Epoch: 5| Step: 6
Training loss: 2.0313773155212402
Validation loss: 2.0846974567700456

Epoch: 5| Step: 7
Training loss: 2.469818115234375
Validation loss: 2.0827173673978416

Epoch: 5| Step: 8
Training loss: 2.1422832012176514
Validation loss: 2.0945863159753944

Epoch: 5| Step: 9
Training loss: 2.471909284591675
Validation loss: 2.0882607352349067

Epoch: 5| Step: 10
Training loss: 2.22771954536438
Validation loss: 2.10683512431319

Epoch: 43| Step: 0
Training loss: 2.6349120140075684
Validation loss: 2.1003727797539002

Epoch: 5| Step: 1
Training loss: 2.6030797958374023
Validation loss: 2.1045706246488836

Epoch: 5| Step: 2
Training loss: 2.1675057411193848
Validation loss: 2.0819651388352916

Epoch: 5| Step: 3
Training loss: 2.2576801776885986
Validation loss: 2.0867625282656763

Epoch: 5| Step: 4
Training loss: 1.9442332983016968
Validation loss: 2.08940823360156

Epoch: 5| Step: 5
Training loss: 1.6184860467910767
Validation loss: 2.099242453934044

Epoch: 5| Step: 6
Training loss: 2.0676651000976562
Validation loss: 2.1012848167009253

Epoch: 5| Step: 7
Training loss: 2.331939458847046
Validation loss: 2.1005573067613827

Epoch: 5| Step: 8
Training loss: 3.0427069664001465
Validation loss: 2.105998026427402

Epoch: 5| Step: 9
Training loss: 3.0068259239196777
Validation loss: 2.095255982491278

Epoch: 5| Step: 10
Training loss: 2.048309087753296
Validation loss: 2.0829943277502574

Epoch: 44| Step: 0
Training loss: 1.789642572402954
Validation loss: 2.0962226467747844

Epoch: 5| Step: 1
Training loss: 1.9970102310180664
Validation loss: 2.090651136572643

Epoch: 5| Step: 2
Training loss: 2.2260875701904297
Validation loss: 2.1136731998894804

Epoch: 5| Step: 3
Training loss: 1.5284498929977417
Validation loss: 2.083313975282895

Epoch: 5| Step: 4
Training loss: 2.781008243560791
Validation loss: 2.1042823227502967

Epoch: 5| Step: 5
Training loss: 3.064641237258911
Validation loss: 2.105948148235198

Epoch: 5| Step: 6
Training loss: 1.6836200952529907
Validation loss: 2.1100647987857943

Epoch: 5| Step: 7
Training loss: 2.50343656539917
Validation loss: 2.1022041933510893

Epoch: 5| Step: 8
Training loss: 2.5724685192108154
Validation loss: 2.0971038328704013

Epoch: 5| Step: 9
Training loss: 2.731917142868042
Validation loss: 2.1010060823091896

Epoch: 5| Step: 10
Training loss: 2.8587892055511475
Validation loss: 2.0832082584340084

Epoch: 45| Step: 0
Training loss: 1.9786758422851562
Validation loss: 2.09641291633729

Epoch: 5| Step: 1
Training loss: 3.1531639099121094
Validation loss: 2.0971034572970484

Epoch: 5| Step: 2
Training loss: 2.518184185028076
Validation loss: 2.0922438867630495

Epoch: 5| Step: 3
Training loss: 2.5574564933776855
Validation loss: 2.074615384942742

Epoch: 5| Step: 4
Training loss: 1.682508111000061
Validation loss: 2.0953493579741447

Epoch: 5| Step: 5
Training loss: 2.2154979705810547
Validation loss: 2.0740181553748345

Epoch: 5| Step: 6
Training loss: 2.3402676582336426
Validation loss: 2.0791958557662142

Epoch: 5| Step: 7
Training loss: 2.656200408935547
Validation loss: 2.0933940705432685

Epoch: 5| Step: 8
Training loss: 2.484772205352783
Validation loss: 2.0871453515944944

Epoch: 5| Step: 9
Training loss: 1.7727108001708984
Validation loss: 2.1034157006971297

Epoch: 5| Step: 10
Training loss: 2.391296625137329
Validation loss: 2.089428376126033

Epoch: 46| Step: 0
Training loss: 2.2383627891540527
Validation loss: 2.1038013030123968

Epoch: 5| Step: 1
Training loss: 1.9264488220214844
Validation loss: 2.0783699443263393

Epoch: 5| Step: 2
Training loss: 2.386028289794922
Validation loss: 2.098149771331459

Epoch: 5| Step: 3
Training loss: 1.6639578342437744
Validation loss: 2.096777626263198

Epoch: 5| Step: 4
Training loss: 2.234170436859131
Validation loss: 2.072918959843215

Epoch: 5| Step: 5
Training loss: 2.3504104614257812
Validation loss: 2.0791958762753393

Epoch: 5| Step: 6
Training loss: 2.8373732566833496
Validation loss: 2.080483539130098

Epoch: 5| Step: 7
Training loss: 2.530803680419922
Validation loss: 2.088778729079872

Epoch: 5| Step: 8
Training loss: 2.563685894012451
Validation loss: 2.074995187021071

Epoch: 5| Step: 9
Training loss: 2.2615151405334473
Validation loss: 2.091824693064536

Epoch: 5| Step: 10
Training loss: 2.6186416149139404
Validation loss: 2.101123809814453

Epoch: 47| Step: 0
Training loss: 3.2531485557556152
Validation loss: 2.092777082996984

Epoch: 5| Step: 1
Training loss: 2.2104885578155518
Validation loss: 2.099013599016333

Epoch: 5| Step: 2
Training loss: 2.9379446506500244
Validation loss: 2.0760591248030305

Epoch: 5| Step: 3
Training loss: 1.8025157451629639
Validation loss: 2.0888493907067085

Epoch: 5| Step: 4
Training loss: 2.5284907817840576
Validation loss: 2.1029080754967144

Epoch: 5| Step: 5
Training loss: 1.9209611415863037
Validation loss: 2.114190488733271

Epoch: 5| Step: 6
Training loss: 1.6319042444229126
Validation loss: 2.0870947530192714

Epoch: 5| Step: 7
Training loss: 2.3746790885925293
Validation loss: 2.0896929963942497

Epoch: 5| Step: 8
Training loss: 2.0286169052124023
Validation loss: 2.0814031708625054

Epoch: 5| Step: 9
Training loss: 2.5597968101501465
Validation loss: 2.098286441577378

Epoch: 5| Step: 10
Training loss: 2.288443088531494
Validation loss: 2.1030719972425893

Epoch: 48| Step: 0
Training loss: 2.3591911792755127
Validation loss: 2.1046386675168107

Epoch: 5| Step: 1
Training loss: 1.8564621210098267
Validation loss: 2.0772647780756794

Epoch: 5| Step: 2
Training loss: 2.0638651847839355
Validation loss: 2.1002270662656395

Epoch: 5| Step: 3
Training loss: 2.6262001991271973
Validation loss: 2.0930402483991397

Epoch: 5| Step: 4
Training loss: 2.716447353363037
Validation loss: 2.087326888115175

Epoch: 5| Step: 5
Training loss: 2.594723701477051
Validation loss: 2.0904865649438675

Epoch: 5| Step: 6
Training loss: 2.4888756275177
Validation loss: 2.0938605134205153

Epoch: 5| Step: 7
Training loss: 2.3634562492370605
Validation loss: 2.0983139596959597

Epoch: 5| Step: 8
Training loss: 1.9023067951202393
Validation loss: 2.095333776166362

Epoch: 5| Step: 9
Training loss: 2.7373759746551514
Validation loss: 2.0921275641328547

Epoch: 5| Step: 10
Training loss: 1.6372627019882202
Validation loss: 2.1149037140671925

Epoch: 49| Step: 0
Training loss: 2.38311767578125
Validation loss: 2.0751750430753155

Epoch: 5| Step: 1
Training loss: 2.3385701179504395
Validation loss: 2.092599673937726

Epoch: 5| Step: 2
Training loss: 2.510704517364502
Validation loss: 2.0826379970837663

Epoch: 5| Step: 3
Training loss: 1.9994299411773682
Validation loss: 2.086131001031527

Epoch: 5| Step: 4
Training loss: 2.1163535118103027
Validation loss: 2.0760409088544947

Epoch: 5| Step: 5
Training loss: 2.2886855602264404
Validation loss: 2.0817662336493052

Epoch: 5| Step: 6
Training loss: 1.9843254089355469
Validation loss: 2.0957144460370465

Epoch: 5| Step: 7
Training loss: 2.109060049057007
Validation loss: 2.088984327931558

Epoch: 5| Step: 8
Training loss: 3.2376389503479004
Validation loss: 2.0855730977109683

Epoch: 5| Step: 9
Training loss: 2.4139063358306885
Validation loss: 2.102726959413098

Epoch: 5| Step: 10
Training loss: 1.9619569778442383
Validation loss: 2.0757150906388477

Epoch: 50| Step: 0
Training loss: 1.9225099086761475
Validation loss: 2.09122557281166

Epoch: 5| Step: 1
Training loss: 2.3767781257629395
Validation loss: 2.0773691297859274

Epoch: 5| Step: 2
Training loss: 2.2716522216796875
Validation loss: 2.0814347459423925

Epoch: 5| Step: 3
Training loss: 2.814429521560669
Validation loss: 2.0895958177505003

Epoch: 5| Step: 4
Training loss: 2.5355005264282227
Validation loss: 2.097886498256396

Epoch: 5| Step: 5
Training loss: 2.413073778152466
Validation loss: 2.0838890126956406

Epoch: 5| Step: 6
Training loss: 1.774539589881897
Validation loss: 2.0986064428924234

Epoch: 5| Step: 7
Training loss: 1.9756755828857422
Validation loss: 2.082616372775006

Epoch: 5| Step: 8
Training loss: 2.4133248329162598
Validation loss: 2.076440400974725

Epoch: 5| Step: 9
Training loss: 2.560882568359375
Validation loss: 2.1080779939569454

Epoch: 5| Step: 10
Training loss: 2.252328872680664
Validation loss: 2.083554703702209

Epoch: 51| Step: 0
Training loss: 2.1566457748413086
Validation loss: 2.085387606774607

Epoch: 5| Step: 1
Training loss: 2.2722389698028564
Validation loss: 2.1009149397573164

Epoch: 5| Step: 2
Training loss: 2.039214611053467
Validation loss: 2.095131266501642

Epoch: 5| Step: 3
Training loss: 3.039501428604126
Validation loss: 2.0958365368586716

Epoch: 5| Step: 4
Training loss: 2.730937957763672
Validation loss: 2.100392782559959

Epoch: 5| Step: 5
Training loss: 2.2834584712982178
Validation loss: 2.0705888989151164

Epoch: 5| Step: 6
Training loss: 2.063058853149414
Validation loss: 2.0965278789561284

Epoch: 5| Step: 7
Training loss: 2.314279556274414
Validation loss: 2.0824361462746896

Epoch: 5| Step: 8
Training loss: 2.376685619354248
Validation loss: 2.102980867508919

Epoch: 5| Step: 9
Training loss: 1.8897864818572998
Validation loss: 2.0857684073909635

Epoch: 5| Step: 10
Training loss: 2.1058998107910156
Validation loss: 2.0876026563746954

Epoch: 52| Step: 0
Training loss: 2.56439208984375
Validation loss: 2.079052056035688

Epoch: 5| Step: 1
Training loss: 2.1494882106781006
Validation loss: 2.0845091419835247

Epoch: 5| Step: 2
Training loss: 2.5430305004119873
Validation loss: 2.0871948965134157

Epoch: 5| Step: 3
Training loss: 2.419708728790283
Validation loss: 2.0921291253900014

Epoch: 5| Step: 4
Training loss: 2.0387978553771973
Validation loss: 2.090497250198036

Epoch: 5| Step: 5
Training loss: 2.6459801197052
Validation loss: 2.0909557727075394

Epoch: 5| Step: 6
Training loss: 2.467071533203125
Validation loss: 2.0897762185783795

Epoch: 5| Step: 7
Training loss: 2.3472602367401123
Validation loss: 2.0979132126736384

Epoch: 5| Step: 8
Training loss: 1.7790378332138062
Validation loss: 2.096562990578272

Epoch: 5| Step: 9
Training loss: 1.796085000038147
Validation loss: 2.073735829322569

Epoch: 5| Step: 10
Training loss: 2.451345443725586
Validation loss: 2.0815932904520342

Epoch: 53| Step: 0
Training loss: 2.3282954692840576
Validation loss: 2.080113640395544

Epoch: 5| Step: 1
Training loss: 2.596520185470581
Validation loss: 2.085359437491304

Epoch: 5| Step: 2
Training loss: 2.471482515335083
Validation loss: 2.0675536509483092

Epoch: 5| Step: 3
Training loss: 1.8204342126846313
Validation loss: 2.0825027470947592

Epoch: 5| Step: 4
Training loss: 1.8905547857284546
Validation loss: 2.0825327647629606

Epoch: 5| Step: 5
Training loss: 3.090000629425049
Validation loss: 2.0767296488567064

Epoch: 5| Step: 6
Training loss: 2.0711631774902344
Validation loss: 2.0858087411490818

Epoch: 5| Step: 7
Training loss: 1.9699987173080444
Validation loss: 2.084622065226237

Epoch: 5| Step: 8
Training loss: 2.1177666187286377
Validation loss: 2.086002130662241

Epoch: 5| Step: 9
Training loss: 2.123443126678467
Validation loss: 2.082536656369445

Epoch: 5| Step: 10
Training loss: 2.9101505279541016
Validation loss: 2.084472269140264

Epoch: 54| Step: 0
Training loss: 2.0635757446289062
Validation loss: 2.0758998855467765

Epoch: 5| Step: 1
Training loss: 2.282668113708496
Validation loss: 2.083932797114054

Epoch: 5| Step: 2
Training loss: 1.84780752658844
Validation loss: 2.0772516599265476

Epoch: 5| Step: 3
Training loss: 2.6363959312438965
Validation loss: 2.0827274937783518

Epoch: 5| Step: 4
Training loss: 2.1925666332244873
Validation loss: 2.0675065696880384

Epoch: 5| Step: 5
Training loss: 3.067939043045044
Validation loss: 2.0748341903891614

Epoch: 5| Step: 6
Training loss: 2.111074209213257
Validation loss: 2.0784192162175334

Epoch: 5| Step: 7
Training loss: 2.879915714263916
Validation loss: 2.0583829277305195

Epoch: 5| Step: 8
Training loss: 2.359276533126831
Validation loss: 2.081289745146228

Epoch: 5| Step: 9
Training loss: 2.0373520851135254
Validation loss: 2.0878394752420406

Epoch: 5| Step: 10
Training loss: 1.6870455741882324
Validation loss: 2.085700359395755

Epoch: 55| Step: 0
Training loss: 2.7500405311584473
Validation loss: 2.0699373368294007

Epoch: 5| Step: 1
Training loss: 2.580402374267578
Validation loss: 2.09180853315579

Epoch: 5| Step: 2
Training loss: 2.4964165687561035
Validation loss: 2.089756178599532

Epoch: 5| Step: 3
Training loss: 2.2865350246429443
Validation loss: 2.0759971526361283

Epoch: 5| Step: 4
Training loss: 1.942186951637268
Validation loss: 2.069529405204199

Epoch: 5| Step: 5
Training loss: 2.0981287956237793
Validation loss: 2.0720117758679133

Epoch: 5| Step: 6
Training loss: 1.851946234703064
Validation loss: 2.0971650051814255

Epoch: 5| Step: 7
Training loss: 2.0675625801086426
Validation loss: 2.091485272171677

Epoch: 5| Step: 8
Training loss: 2.2501232624053955
Validation loss: 2.084729798378483

Epoch: 5| Step: 9
Training loss: 2.451995849609375
Validation loss: 2.069207363231208

Epoch: 5| Step: 10
Training loss: 2.441483974456787
Validation loss: 2.0777288508671585

Epoch: 56| Step: 0
Training loss: 2.1219143867492676
Validation loss: 2.084319440267419

Epoch: 5| Step: 1
Training loss: 1.5225903987884521
Validation loss: 2.080084018809821

Epoch: 5| Step: 2
Training loss: 2.3295273780822754
Validation loss: 2.0837451668195826

Epoch: 5| Step: 3
Training loss: 3.0432345867156982
Validation loss: 2.0766603690321728

Epoch: 5| Step: 4
Training loss: 2.2039260864257812
Validation loss: 2.0685528170677925

Epoch: 5| Step: 5
Training loss: 1.9991672039031982
Validation loss: 2.0858168755808184

Epoch: 5| Step: 6
Training loss: 2.2373480796813965
Validation loss: 2.0841141528980707

Epoch: 5| Step: 7
Training loss: 2.7029004096984863
Validation loss: 2.0825324417442403

Epoch: 5| Step: 8
Training loss: 2.6632611751556396
Validation loss: 2.0718575549382034

Epoch: 5| Step: 9
Training loss: 1.6553688049316406
Validation loss: 2.0808725433964885

Epoch: 5| Step: 10
Training loss: 2.7892954349517822
Validation loss: 2.084676586171632

Epoch: 57| Step: 0
Training loss: 2.238940477371216
Validation loss: 2.0805458432884625

Epoch: 5| Step: 1
Training loss: 2.1364316940307617
Validation loss: 2.097040186646164

Epoch: 5| Step: 2
Training loss: 2.155073881149292
Validation loss: 2.0753979772649784

Epoch: 5| Step: 3
Training loss: 2.368922472000122
Validation loss: 2.071823086789859

Epoch: 5| Step: 4
Training loss: 2.3831491470336914
Validation loss: 2.0695734870049263

Epoch: 5| Step: 5
Training loss: 1.7721723318099976
Validation loss: 2.078012679212837

Epoch: 5| Step: 6
Training loss: 2.7855725288391113
Validation loss: 2.06918849227249

Epoch: 5| Step: 7
Training loss: 2.1409802436828613
Validation loss: 2.057415836600847

Epoch: 5| Step: 8
Training loss: 2.20982027053833
Validation loss: 2.069065611849549

Epoch: 5| Step: 9
Training loss: 2.3497474193573
Validation loss: 2.065410690922891

Epoch: 5| Step: 10
Training loss: 2.665287733078003
Validation loss: 2.069475027822679

Epoch: 58| Step: 0
Training loss: 1.6871658563613892
Validation loss: 2.080961594017603

Epoch: 5| Step: 1
Training loss: 2.7709743976593018
Validation loss: 2.088260157133943

Epoch: 5| Step: 2
Training loss: 2.427405834197998
Validation loss: 2.070659573360156

Epoch: 5| Step: 3
Training loss: 2.540400981903076
Validation loss: 2.087502118079893

Epoch: 5| Step: 4
Training loss: 2.2906956672668457
Validation loss: 2.0727215672052033

Epoch: 5| Step: 5
Training loss: 2.9005465507507324
Validation loss: 2.079484421719787

Epoch: 5| Step: 6
Training loss: 2.3375256061553955
Validation loss: 2.0698278745015464

Epoch: 5| Step: 7
Training loss: 1.8780431747436523
Validation loss: 2.089549390218591

Epoch: 5| Step: 8
Training loss: 1.9200594425201416
Validation loss: 2.0728998030385664

Epoch: 5| Step: 9
Training loss: 1.9803558588027954
Validation loss: 2.0817444862857943

Epoch: 5| Step: 10
Training loss: 2.474579334259033
Validation loss: 2.088123808624924

Epoch: 59| Step: 0
Training loss: 2.377514600753784
Validation loss: 2.0793471977274907

Epoch: 5| Step: 1
Training loss: 2.2667665481567383
Validation loss: 2.082566217709613

Epoch: 5| Step: 2
Training loss: 2.0297389030456543
Validation loss: 2.076854805792532

Epoch: 5| Step: 3
Training loss: 1.8261725902557373
Validation loss: 2.0836464333277878

Epoch: 5| Step: 4
Training loss: 2.604832172393799
Validation loss: 2.0647374096737114

Epoch: 5| Step: 5
Training loss: 1.9895111322402954
Validation loss: 2.0764752177781958

Epoch: 5| Step: 6
Training loss: 2.696962594985962
Validation loss: 2.05330704873608

Epoch: 5| Step: 7
Training loss: 2.2288553714752197
Validation loss: 2.0651150467575237

Epoch: 5| Step: 8
Training loss: 2.209620952606201
Validation loss: 2.077387143206853

Epoch: 5| Step: 9
Training loss: 2.634500503540039
Validation loss: 2.0572160238860757

Epoch: 5| Step: 10
Training loss: 2.151784658432007
Validation loss: 2.0922699051518596

Epoch: 60| Step: 0
Training loss: 2.193270444869995
Validation loss: 2.0621592742140575

Epoch: 5| Step: 1
Training loss: 2.4908366203308105
Validation loss: 2.068490811573562

Epoch: 5| Step: 2
Training loss: 2.4985251426696777
Validation loss: 2.0831277626816944

Epoch: 5| Step: 3
Training loss: 2.1519103050231934
Validation loss: 2.077652769704019

Epoch: 5| Step: 4
Training loss: 1.937330961227417
Validation loss: 2.06599755953717

Epoch: 5| Step: 5
Training loss: 3.021782159805298
Validation loss: 2.073181383071407

Epoch: 5| Step: 6
Training loss: 1.6794023513793945
Validation loss: 2.0840731051660355

Epoch: 5| Step: 7
Training loss: 2.4846415519714355
Validation loss: 2.059515890254769

Epoch: 5| Step: 8
Training loss: 2.0501818656921387
Validation loss: 2.066271125629384

Epoch: 5| Step: 9
Training loss: 2.3356051445007324
Validation loss: 2.0854174501152447

Epoch: 5| Step: 10
Training loss: 2.1770431995391846
Validation loss: 2.080597000737344

Epoch: 61| Step: 0
Training loss: 1.5643471479415894
Validation loss: 2.059360393913843

Epoch: 5| Step: 1
Training loss: 2.1431756019592285
Validation loss: 2.0771080011962564

Epoch: 5| Step: 2
Training loss: 2.6820261478424072
Validation loss: 2.072663552017622

Epoch: 5| Step: 3
Training loss: 2.969303846359253
Validation loss: 2.0790983169309554

Epoch: 5| Step: 4
Training loss: 1.8393151760101318
Validation loss: 2.0814177297776744

Epoch: 5| Step: 5
Training loss: 2.1571011543273926
Validation loss: 2.0689524540337185

Epoch: 5| Step: 6
Training loss: 2.2201855182647705
Validation loss: 2.0571723343223653

Epoch: 5| Step: 7
Training loss: 2.2419028282165527
Validation loss: 2.0786658192193634

Epoch: 5| Step: 8
Training loss: 2.215177059173584
Validation loss: 2.0522828960931427

Epoch: 5| Step: 9
Training loss: 2.4765377044677734
Validation loss: 2.0868471348157493

Epoch: 5| Step: 10
Training loss: 2.451497793197632
Validation loss: 2.0806316303950485

Epoch: 62| Step: 0
Training loss: 1.927501916885376
Validation loss: 2.080451828177257

Epoch: 5| Step: 1
Training loss: 2.032740354537964
Validation loss: 2.0718442342614614

Epoch: 5| Step: 2
Training loss: 2.5290918350219727
Validation loss: 2.0611636664277766

Epoch: 5| Step: 3
Training loss: 2.9697489738464355
Validation loss: 2.0588890890921316

Epoch: 5| Step: 4
Training loss: 2.083671808242798
Validation loss: 2.0591275768895305

Epoch: 5| Step: 5
Training loss: 2.399461507797241
Validation loss: 2.066372622725784

Epoch: 5| Step: 6
Training loss: 3.224384307861328
Validation loss: 2.0598563417311637

Epoch: 5| Step: 7
Training loss: 2.5040431022644043
Validation loss: 2.047657144966946

Epoch: 5| Step: 8
Training loss: 2.0522751808166504
Validation loss: 2.0700879673804007

Epoch: 5| Step: 9
Training loss: 1.8110507726669312
Validation loss: 2.0887855945094937

Epoch: 5| Step: 10
Training loss: 1.5176239013671875
Validation loss: 2.0625214307538924

Epoch: 63| Step: 0
Training loss: 2.648160457611084
Validation loss: 2.083095112154561

Epoch: 5| Step: 1
Training loss: 2.459892749786377
Validation loss: 2.0629220726669475

Epoch: 5| Step: 2
Training loss: 1.6629409790039062
Validation loss: 2.0674108715467554

Epoch: 5| Step: 3
Training loss: 2.324293613433838
Validation loss: 2.0657959612466956

Epoch: 5| Step: 4
Training loss: 2.037121534347534
Validation loss: 2.05664312711326

Epoch: 5| Step: 5
Training loss: 2.1083786487579346
Validation loss: 2.0748150835755053

Epoch: 5| Step: 6
Training loss: 2.8195877075195312
Validation loss: 2.05810708127996

Epoch: 5| Step: 7
Training loss: 2.376901149749756
Validation loss: 2.0684457978894635

Epoch: 5| Step: 8
Training loss: 1.837885856628418
Validation loss: 2.0574533554815475

Epoch: 5| Step: 9
Training loss: 2.0843396186828613
Validation loss: 2.079082588995657

Epoch: 5| Step: 10
Training loss: 2.692082405090332
Validation loss: 2.0690378604396695

Epoch: 64| Step: 0
Training loss: 2.256380796432495
Validation loss: 2.0552961903233684

Epoch: 5| Step: 1
Training loss: 2.656113624572754
Validation loss: 2.0692895009953487

Epoch: 5| Step: 2
Training loss: 2.091165065765381
Validation loss: 2.061409569555713

Epoch: 5| Step: 3
Training loss: 1.9296610355377197
Validation loss: 2.0694407442564606

Epoch: 5| Step: 4
Training loss: 2.070000171661377
Validation loss: 2.0597773059721916

Epoch: 5| Step: 5
Training loss: 1.8494646549224854
Validation loss: 2.092872304301108

Epoch: 5| Step: 6
Training loss: 2.222832202911377
Validation loss: 2.0849731276112218

Epoch: 5| Step: 7
Training loss: 2.855686664581299
Validation loss: 2.071926647616971

Epoch: 5| Step: 8
Training loss: 1.7738265991210938
Validation loss: 2.063239138613465

Epoch: 5| Step: 9
Training loss: 2.8120415210723877
Validation loss: 2.0756448494490756

Epoch: 5| Step: 10
Training loss: 2.2917656898498535
Validation loss: 2.0735578472896288

Epoch: 65| Step: 0
Training loss: 2.26517915725708
Validation loss: 2.051480702174607

Epoch: 5| Step: 1
Training loss: 2.812471628189087
Validation loss: 2.070333444943992

Epoch: 5| Step: 2
Training loss: 2.0352115631103516
Validation loss: 2.079592051044587

Epoch: 5| Step: 3
Training loss: 3.001497745513916
Validation loss: 2.0771202707803376

Epoch: 5| Step: 4
Training loss: 2.075639486312866
Validation loss: 2.0672348263443157

Epoch: 5| Step: 5
Training loss: 2.092555284500122
Validation loss: 2.054135109788628

Epoch: 5| Step: 6
Training loss: 2.63374662399292
Validation loss: 2.0618759227055374

Epoch: 5| Step: 7
Training loss: 1.8580347299575806
Validation loss: 2.087874294609152

Epoch: 5| Step: 8
Training loss: 2.4007487297058105
Validation loss: 2.0659462175061627

Epoch: 5| Step: 9
Training loss: 1.6003189086914062
Validation loss: 2.0768601356014127

Epoch: 5| Step: 10
Training loss: 1.9734522104263306
Validation loss: 2.081494326232582

Epoch: 66| Step: 0
Training loss: 2.7507119178771973
Validation loss: 2.076592778646818

Epoch: 5| Step: 1
Training loss: 2.364910364151001
Validation loss: 2.0663091021199382

Epoch: 5| Step: 2
Training loss: 2.5814762115478516
Validation loss: 2.085956173558389

Epoch: 5| Step: 3
Training loss: 2.535726547241211
Validation loss: 2.0904717855556036

Epoch: 5| Step: 4
Training loss: 1.6046737432479858
Validation loss: 2.0830899707732664

Epoch: 5| Step: 5
Training loss: 2.0139517784118652
Validation loss: 2.06918066675945

Epoch: 5| Step: 6
Training loss: 2.1025633811950684
Validation loss: 2.0910970228974537

Epoch: 5| Step: 7
Training loss: 2.5115160942077637
Validation loss: 2.0760991086242018

Epoch: 5| Step: 8
Training loss: 2.0100409984588623
Validation loss: 2.0810327363270584

Epoch: 5| Step: 9
Training loss: 1.979791283607483
Validation loss: 2.0702071202698575

Epoch: 5| Step: 10
Training loss: 2.3187437057495117
Validation loss: 2.065854519926092

Epoch: 67| Step: 0
Training loss: 2.5137059688568115
Validation loss: 2.076618286871141

Epoch: 5| Step: 1
Training loss: 2.0724265575408936
Validation loss: 2.05849890939651

Epoch: 5| Step: 2
Training loss: 2.3594553470611572
Validation loss: 2.0735235573143087

Epoch: 5| Step: 3
Training loss: 2.0648956298828125
Validation loss: 2.063541932772565

Epoch: 5| Step: 4
Training loss: 2.567139148712158
Validation loss: 2.0799051830845494

Epoch: 5| Step: 5
Training loss: 1.7228975296020508
Validation loss: 2.075764348430018

Epoch: 5| Step: 6
Training loss: 2.343228340148926
Validation loss: 2.074054406535241

Epoch: 5| Step: 7
Training loss: 2.7282373905181885
Validation loss: 2.0746630878858667

Epoch: 5| Step: 8
Training loss: 2.8578152656555176
Validation loss: 2.086335748754522

Epoch: 5| Step: 9
Training loss: 1.6752941608428955
Validation loss: 2.0670822974174254

Epoch: 5| Step: 10
Training loss: 1.8915883302688599
Validation loss: 2.1076938503532

Epoch: 68| Step: 0
Training loss: 2.5846166610717773
Validation loss: 2.0884198014454176

Epoch: 5| Step: 1
Training loss: 1.7163372039794922
Validation loss: 2.0865886493395736

Epoch: 5| Step: 2
Training loss: 1.4935455322265625
Validation loss: 2.0642977504320044

Epoch: 5| Step: 3
Training loss: 2.330650806427002
Validation loss: 2.0728999004569104

Epoch: 5| Step: 4
Training loss: 2.3274364471435547
Validation loss: 2.0658261904152493

Epoch: 5| Step: 5
Training loss: 1.9970645904541016
Validation loss: 2.073455887456094

Epoch: 5| Step: 6
Training loss: 2.032560110092163
Validation loss: 2.0783157963906564

Epoch: 5| Step: 7
Training loss: 2.925389289855957
Validation loss: 2.06872360937057

Epoch: 5| Step: 8
Training loss: 2.058055877685547
Validation loss: 2.072369711373442

Epoch: 5| Step: 9
Training loss: 2.828026294708252
Validation loss: 2.07677694289915

Epoch: 5| Step: 10
Training loss: 2.380467653274536
Validation loss: 2.078693782129595

Epoch: 69| Step: 0
Training loss: 1.9088293313980103
Validation loss: 2.083171077953872

Epoch: 5| Step: 1
Training loss: 2.359790563583374
Validation loss: 2.073862939752558

Epoch: 5| Step: 2
Training loss: 2.0323734283447266
Validation loss: 2.069949746131897

Epoch: 5| Step: 3
Training loss: 2.534388303756714
Validation loss: 2.061851662974204

Epoch: 5| Step: 4
Training loss: 1.8939831256866455
Validation loss: 2.052974893200782

Epoch: 5| Step: 5
Training loss: 2.3335399627685547
Validation loss: 2.0515588150229505

Epoch: 5| Step: 6
Training loss: 2.3307032585144043
Validation loss: 2.0603811766511653

Epoch: 5| Step: 7
Training loss: 2.614398717880249
Validation loss: 2.043525747073594

Epoch: 5| Step: 8
Training loss: 2.1123108863830566
Validation loss: 2.0642767824152464

Epoch: 5| Step: 9
Training loss: 2.4551644325256348
Validation loss: 2.068263530731201

Epoch: 5| Step: 10
Training loss: 2.2366929054260254
Validation loss: 2.0425301341600317

Epoch: 70| Step: 0
Training loss: 2.459033250808716
Validation loss: 2.0719614439113165

Epoch: 5| Step: 1
Training loss: 2.4586751461029053
Validation loss: 2.067140348495976

Epoch: 5| Step: 2
Training loss: 2.4468908309936523
Validation loss: 2.0801066044838197

Epoch: 5| Step: 3
Training loss: 1.8318455219268799
Validation loss: 2.059661070505778

Epoch: 5| Step: 4
Training loss: 1.9405120611190796
Validation loss: 2.0614169361770793

Epoch: 5| Step: 5
Training loss: 1.8667333126068115
Validation loss: 2.0601764417463735

Epoch: 5| Step: 6
Training loss: 2.0761468410491943
Validation loss: 2.0692707953914518

Epoch: 5| Step: 7
Training loss: 1.9819371700286865
Validation loss: 2.076773084619994

Epoch: 5| Step: 8
Training loss: 2.927830934524536
Validation loss: 2.0690715338594172

Epoch: 5| Step: 9
Training loss: 1.9250469207763672
Validation loss: 2.066811097565518

Epoch: 5| Step: 10
Training loss: 2.8428754806518555
Validation loss: 2.073088333170901

Epoch: 71| Step: 0
Training loss: 1.6218631267547607
Validation loss: 2.0527956998476418

Epoch: 5| Step: 1
Training loss: 1.8211711645126343
Validation loss: 2.08070110249263

Epoch: 5| Step: 2
Training loss: 2.757814884185791
Validation loss: 2.050452028551409

Epoch: 5| Step: 3
Training loss: 2.3062374591827393
Validation loss: 2.0565882690491213

Epoch: 5| Step: 4
Training loss: 2.1157352924346924
Validation loss: 2.0606462801656416

Epoch: 5| Step: 5
Training loss: 2.377859592437744
Validation loss: 2.0597599757614957

Epoch: 5| Step: 6
Training loss: 1.9757416248321533
Validation loss: 2.0724108731874855

Epoch: 5| Step: 7
Training loss: 1.7877225875854492
Validation loss: 2.0438011692416285

Epoch: 5| Step: 8
Training loss: 2.6952872276306152
Validation loss: 2.0475237292628132

Epoch: 5| Step: 9
Training loss: 2.401461124420166
Validation loss: 2.064353432706607

Epoch: 5| Step: 10
Training loss: 2.8086905479431152
Validation loss: 2.0511999130249023

Epoch: 72| Step: 0
Training loss: 2.9352469444274902
Validation loss: 2.054099811020718

Epoch: 5| Step: 1
Training loss: 2.0154480934143066
Validation loss: 2.069791055494739

Epoch: 5| Step: 2
Training loss: 2.58868670463562
Validation loss: 2.0466318412493636

Epoch: 5| Step: 3
Training loss: 2.010309934616089
Validation loss: 2.046011911925449

Epoch: 5| Step: 4
Training loss: 2.1824746131896973
Validation loss: 2.0691485251149824

Epoch: 5| Step: 5
Training loss: 2.6993191242218018
Validation loss: 2.0593689026371127

Epoch: 5| Step: 6
Training loss: 2.356948137283325
Validation loss: 2.063571696640343

Epoch: 5| Step: 7
Training loss: 1.8158735036849976
Validation loss: 2.0604307420792116

Epoch: 5| Step: 8
Training loss: 2.098517417907715
Validation loss: 2.042911019376529

Epoch: 5| Step: 9
Training loss: 1.7862590551376343
Validation loss: 2.077352698131274

Epoch: 5| Step: 10
Training loss: 2.0721800327301025
Validation loss: 2.0487276200325257

Epoch: 73| Step: 0
Training loss: 2.3670098781585693
Validation loss: 2.075053720064061

Epoch: 5| Step: 1
Training loss: 2.240170955657959
Validation loss: 2.0506407419840493

Epoch: 5| Step: 2
Training loss: 1.788818120956421
Validation loss: 2.0547938987772953

Epoch: 5| Step: 3
Training loss: 2.8287265300750732
Validation loss: 2.0758650995069936

Epoch: 5| Step: 4
Training loss: 1.7015221118927002
Validation loss: 2.0661428692520305

Epoch: 5| Step: 5
Training loss: 2.2167649269104004
Validation loss: 2.066857918616264

Epoch: 5| Step: 6
Training loss: 2.652966022491455
Validation loss: 2.047321088852421

Epoch: 5| Step: 7
Training loss: 2.702596664428711
Validation loss: 2.0751744137015393

Epoch: 5| Step: 8
Training loss: 2.0061516761779785
Validation loss: 2.0732744124627884

Epoch: 5| Step: 9
Training loss: 2.2218003273010254
Validation loss: 2.059230896734422

Epoch: 5| Step: 10
Training loss: 1.776850700378418
Validation loss: 2.0642991206979238

Epoch: 74| Step: 0
Training loss: 1.8597776889801025
Validation loss: 2.088613630622946

Epoch: 5| Step: 1
Training loss: 2.4535038471221924
Validation loss: 2.0526525666636806

Epoch: 5| Step: 2
Training loss: 2.9443862438201904
Validation loss: 2.046124558294973

Epoch: 5| Step: 3
Training loss: 2.6927082538604736
Validation loss: 2.0545891023451284

Epoch: 5| Step: 4
Training loss: 2.1077332496643066
Validation loss: 2.0683307916887346

Epoch: 5| Step: 5
Training loss: 1.6143566370010376
Validation loss: 2.0658796423224994

Epoch: 5| Step: 6
Training loss: 2.102696180343628
Validation loss: 2.0510803563620454

Epoch: 5| Step: 7
Training loss: 1.4250876903533936
Validation loss: 2.072162666628438

Epoch: 5| Step: 8
Training loss: 2.765199661254883
Validation loss: 2.0510254726615003

Epoch: 5| Step: 9
Training loss: 2.61484694480896
Validation loss: 2.0689740603969944

Epoch: 5| Step: 10
Training loss: 1.7631539106369019
Validation loss: 2.052444839990267

Epoch: 75| Step: 0
Training loss: 2.6287388801574707
Validation loss: 2.066029382008378

Epoch: 5| Step: 1
Training loss: 2.222611665725708
Validation loss: 2.0737757810982327

Epoch: 5| Step: 2
Training loss: 2.6595585346221924
Validation loss: 2.0627140127202517

Epoch: 5| Step: 3
Training loss: 2.0975327491760254
Validation loss: 2.0466645943221224

Epoch: 5| Step: 4
Training loss: 2.33441424369812
Validation loss: 2.070805634221723

Epoch: 5| Step: 5
Training loss: 1.8992102146148682
Validation loss: 2.0622561798300794

Epoch: 5| Step: 6
Training loss: 2.7873165607452393
Validation loss: 2.0654534088668

Epoch: 5| Step: 7
Training loss: 1.8047984838485718
Validation loss: 2.0611349895436275

Epoch: 5| Step: 8
Training loss: 2.1650681495666504
Validation loss: 2.0534374072987545

Epoch: 5| Step: 9
Training loss: 1.775790810585022
Validation loss: 2.0599133301806707

Epoch: 5| Step: 10
Training loss: 2.1065211296081543
Validation loss: 2.0723189769252652

Epoch: 76| Step: 0
Training loss: 2.5255236625671387
Validation loss: 2.0491328341986543

Epoch: 5| Step: 1
Training loss: 1.9793674945831299
Validation loss: 2.059340428280574

Epoch: 5| Step: 2
Training loss: 2.153465747833252
Validation loss: 2.070535675171883

Epoch: 5| Step: 3
Training loss: 1.9908558130264282
Validation loss: 2.0703051282513525

Epoch: 5| Step: 4
Training loss: 2.1393978595733643
Validation loss: 2.0856260279173493

Epoch: 5| Step: 5
Training loss: 1.594207763671875
Validation loss: 2.0733297896641556

Epoch: 5| Step: 6
Training loss: 2.8026795387268066
Validation loss: 2.0619782504215034

Epoch: 5| Step: 7
Training loss: 2.2452309131622314
Validation loss: 2.0804436078635593

Epoch: 5| Step: 8
Training loss: 2.6267333030700684
Validation loss: 2.066295544306437

Epoch: 5| Step: 9
Training loss: 2.0594658851623535
Validation loss: 2.0622059081190374

Epoch: 5| Step: 10
Training loss: 2.452441930770874
Validation loss: 2.0643817801629343

Epoch: 77| Step: 0
Training loss: 1.8657925128936768
Validation loss: 2.050902197437902

Epoch: 5| Step: 1
Training loss: 2.190145492553711
Validation loss: 2.060931800514139

Epoch: 5| Step: 2
Training loss: 2.3743488788604736
Validation loss: 2.0535399042150027

Epoch: 5| Step: 3
Training loss: 2.54168701171875
Validation loss: 2.067608070629899

Epoch: 5| Step: 4
Training loss: 2.246309757232666
Validation loss: 2.0525686766511653

Epoch: 5| Step: 5
Training loss: 2.425767421722412
Validation loss: 2.0755040876327024

Epoch: 5| Step: 6
Training loss: 1.5232964754104614
Validation loss: 2.069458939695871

Epoch: 5| Step: 7
Training loss: 2.4839377403259277
Validation loss: 2.068276248952394

Epoch: 5| Step: 8
Training loss: 2.52398419380188
Validation loss: 2.0644204872910694

Epoch: 5| Step: 9
Training loss: 1.8034032583236694
Validation loss: 2.0891182281637706

Epoch: 5| Step: 10
Training loss: 2.582207202911377
Validation loss: 2.0637092551877423

Epoch: 78| Step: 0
Training loss: 2.4353222846984863
Validation loss: 2.0780347239586616

Epoch: 5| Step: 1
Training loss: 2.5221216678619385
Validation loss: 2.0516340860756497

Epoch: 5| Step: 2
Training loss: 2.1777076721191406
Validation loss: 2.054857357855766

Epoch: 5| Step: 3
Training loss: 2.168282985687256
Validation loss: 2.073185054204797

Epoch: 5| Step: 4
Training loss: 2.8252620697021484
Validation loss: 2.093599238703328

Epoch: 5| Step: 5
Training loss: 1.7983615398406982
Validation loss: 2.0747624622878207

Epoch: 5| Step: 6
Training loss: 1.6390453577041626
Validation loss: 2.0558486510348577

Epoch: 5| Step: 7
Training loss: 2.583435535430908
Validation loss: 2.052197126932042

Epoch: 5| Step: 8
Training loss: 2.43182110786438
Validation loss: 2.0858264917968423

Epoch: 5| Step: 9
Training loss: 2.076143264770508
Validation loss: 2.048864846588463

Epoch: 5| Step: 10
Training loss: 1.6560903787612915
Validation loss: 2.048637547800618

Epoch: 79| Step: 0
Training loss: 2.3139700889587402
Validation loss: 2.0502357034273047

Epoch: 5| Step: 1
Training loss: 2.2207190990448
Validation loss: 2.0700717651715843

Epoch: 5| Step: 2
Training loss: 2.929682731628418
Validation loss: 2.056005726578415

Epoch: 5| Step: 3
Training loss: 2.0889134407043457
Validation loss: 2.060385670713199

Epoch: 5| Step: 4
Training loss: 2.0411975383758545
Validation loss: 2.066369278456575

Epoch: 5| Step: 5
Training loss: 1.787510633468628
Validation loss: 2.052873642213883

Epoch: 5| Step: 6
Training loss: 2.003612995147705
Validation loss: 2.0541332870401363

Epoch: 5| Step: 7
Training loss: 2.4315171241760254
Validation loss: 2.0571769873301187

Epoch: 5| Step: 8
Training loss: 2.092155933380127
Validation loss: 2.077687786471459

Epoch: 5| Step: 9
Training loss: 2.597322940826416
Validation loss: 2.0766777197519937

Epoch: 5| Step: 10
Training loss: 1.8512985706329346
Validation loss: 2.0484946902080248

Epoch: 80| Step: 0
Training loss: 2.169659376144409
Validation loss: 2.063313299609769

Epoch: 5| Step: 1
Training loss: 2.2501397132873535
Validation loss: 2.0542922583959435

Epoch: 5| Step: 2
Training loss: 1.8759071826934814
Validation loss: 2.0530203132219214

Epoch: 5| Step: 3
Training loss: 2.041038990020752
Validation loss: 2.0465192076980427

Epoch: 5| Step: 4
Training loss: 2.5433735847473145
Validation loss: 2.034296384421728

Epoch: 5| Step: 5
Training loss: 1.552260398864746
Validation loss: 2.045223174556609

Epoch: 5| Step: 6
Training loss: 2.6459648609161377
Validation loss: 2.0704655403731973

Epoch: 5| Step: 7
Training loss: 2.3296515941619873
Validation loss: 2.0479811340249996

Epoch: 5| Step: 8
Training loss: 2.1190011501312256
Validation loss: 2.0557817310415287

Epoch: 5| Step: 9
Training loss: 2.4351487159729004
Validation loss: 2.0462661814946

Epoch: 5| Step: 10
Training loss: 2.4200844764709473
Validation loss: 2.0687378632125033

Epoch: 81| Step: 0
Training loss: 2.3179492950439453
Validation loss: 2.0467732362849738

Epoch: 5| Step: 1
Training loss: 2.047653913497925
Validation loss: 2.0487047215943694

Epoch: 5| Step: 2
Training loss: 2.2143940925598145
Validation loss: 2.0556608861492527

Epoch: 5| Step: 3
Training loss: 2.179020643234253
Validation loss: 2.0594383183346

Epoch: 5| Step: 4
Training loss: 2.5617268085479736
Validation loss: 2.063710084525488

Epoch: 5| Step: 5
Training loss: 2.509284496307373
Validation loss: 2.040055025008417

Epoch: 5| Step: 6
Training loss: 2.1666557788848877
Validation loss: 2.0533890416545253

Epoch: 5| Step: 7
Training loss: 2.120643377304077
Validation loss: 2.058438253659074

Epoch: 5| Step: 8
Training loss: 2.3203775882720947
Validation loss: 2.0627969605948335

Epoch: 5| Step: 9
Training loss: 1.7723652124404907
Validation loss: 2.06033351344447

Epoch: 5| Step: 10
Training loss: 2.1980977058410645
Validation loss: 2.0682582983406643

Epoch: 82| Step: 0
Training loss: 2.212671995162964
Validation loss: 2.069692401475804

Epoch: 5| Step: 1
Training loss: 1.7983167171478271
Validation loss: 2.0652612101647163

Epoch: 5| Step: 2
Training loss: 2.2644872665405273
Validation loss: 2.0678361923463884

Epoch: 5| Step: 3
Training loss: 2.7851836681365967
Validation loss: 2.0653912175086235

Epoch: 5| Step: 4
Training loss: 2.287181854248047
Validation loss: 2.0519932739196287

Epoch: 5| Step: 5
Training loss: 2.1373143196105957
Validation loss: 2.0598258023620932

Epoch: 5| Step: 6
Training loss: 1.699425458908081
Validation loss: 2.062227802891885

Epoch: 5| Step: 7
Training loss: 2.099964141845703
Validation loss: 2.0630775728533344

Epoch: 5| Step: 8
Training loss: 2.1453633308410645
Validation loss: 2.061389446258545

Epoch: 5| Step: 9
Training loss: 2.991729736328125
Validation loss: 2.0536754285135577

Epoch: 5| Step: 10
Training loss: 1.768336296081543
Validation loss: 2.045115445249824

Epoch: 83| Step: 0
Training loss: 2.1805965900421143
Validation loss: 2.054179222353043

Epoch: 5| Step: 1
Training loss: 2.695138931274414
Validation loss: 2.0474022408967376

Epoch: 5| Step: 2
Training loss: 2.516767740249634
Validation loss: 2.0749742279770556

Epoch: 5| Step: 3
Training loss: 2.0149295330047607
Validation loss: 2.0518002997162523

Epoch: 5| Step: 4
Training loss: 1.7937358617782593
Validation loss: 2.0687820219224498

Epoch: 5| Step: 5
Training loss: 1.843998670578003
Validation loss: 2.0692972342173257

Epoch: 5| Step: 6
Training loss: 2.1526684761047363
Validation loss: 2.0586866512093493

Epoch: 5| Step: 7
Training loss: 2.1325316429138184
Validation loss: 2.04641483676049

Epoch: 5| Step: 8
Training loss: 2.058612108230591
Validation loss: 2.052679172126196

Epoch: 5| Step: 9
Training loss: 2.259028434753418
Validation loss: 2.0625537672350482

Epoch: 5| Step: 10
Training loss: 2.7260961532592773
Validation loss: 2.0709309693305724

Epoch: 84| Step: 0
Training loss: 2.404402256011963
Validation loss: 2.062190031492582

Epoch: 5| Step: 1
Training loss: 2.6940367221832275
Validation loss: 2.0510633273791243

Epoch: 5| Step: 2
Training loss: 1.8868777751922607
Validation loss: 2.053784503731676

Epoch: 5| Step: 3
Training loss: 2.24124813079834
Validation loss: 2.05054634873585

Epoch: 5| Step: 4
Training loss: 2.4443535804748535
Validation loss: 2.0559661260215183

Epoch: 5| Step: 5
Training loss: 1.7276995182037354
Validation loss: 2.0655201814507924

Epoch: 5| Step: 6
Training loss: 2.035616397857666
Validation loss: 2.057339754155887

Epoch: 5| Step: 7
Training loss: 2.43005108833313
Validation loss: 2.0500301648211736

Epoch: 5| Step: 8
Training loss: 2.583345890045166
Validation loss: 2.0550220499756517

Epoch: 5| Step: 9
Training loss: 2.073845386505127
Validation loss: 2.0513031303241687

Epoch: 5| Step: 10
Training loss: 1.8604211807250977
Validation loss: 2.0719979398994037

Epoch: 85| Step: 0
Training loss: 1.996311902999878
Validation loss: 2.0495680480874996

Epoch: 5| Step: 1
Training loss: 2.7262532711029053
Validation loss: 2.0527259508768716

Epoch: 5| Step: 2
Training loss: 1.6509815454483032
Validation loss: 2.0551230420348463

Epoch: 5| Step: 3
Training loss: 1.737636923789978
Validation loss: 2.0552037749239194

Epoch: 5| Step: 4
Training loss: 2.089536190032959
Validation loss: 2.074016991481986

Epoch: 5| Step: 5
Training loss: 2.5076053142547607
Validation loss: 2.0607580113154587

Epoch: 5| Step: 6
Training loss: 2.3678081035614014
Validation loss: 2.0623441344948223

Epoch: 5| Step: 7
Training loss: 1.8640708923339844
Validation loss: 2.0569802291931643

Epoch: 5| Step: 8
Training loss: 2.811119556427002
Validation loss: 2.0503117615176785

Epoch: 5| Step: 9
Training loss: 2.374929189682007
Validation loss: 2.064652253222722

Epoch: 5| Step: 10
Training loss: 2.033221483230591
Validation loss: 2.063172055828956

Epoch: 86| Step: 0
Training loss: 2.6989681720733643
Validation loss: 2.0762073865500827

Epoch: 5| Step: 1
Training loss: 1.7107833623886108
Validation loss: 2.0671891320136284

Epoch: 5| Step: 2
Training loss: 2.208193302154541
Validation loss: 2.041911058528449

Epoch: 5| Step: 3
Training loss: 2.235339641571045
Validation loss: 2.0552405541942966

Epoch: 5| Step: 4
Training loss: 2.409107208251953
Validation loss: 2.0389577214435866

Epoch: 5| Step: 5
Training loss: 2.2030155658721924
Validation loss: 2.0627957492746334

Epoch: 5| Step: 6
Training loss: 2.038970470428467
Validation loss: 2.0477164278748217

Epoch: 5| Step: 7
Training loss: 1.9982635974884033
Validation loss: 2.0723541987839567

Epoch: 5| Step: 8
Training loss: 2.1518287658691406
Validation loss: 2.0648515865366948

Epoch: 5| Step: 9
Training loss: 2.7777347564697266
Validation loss: 2.079863973843154

Epoch: 5| Step: 10
Training loss: 1.8182964324951172
Validation loss: 2.07252638570724

Epoch: 87| Step: 0
Training loss: 2.0239107608795166
Validation loss: 2.0486816026831187

Epoch: 5| Step: 1
Training loss: 2.8570735454559326
Validation loss: 2.0506861491869857

Epoch: 5| Step: 2
Training loss: 2.2437796592712402
Validation loss: 2.061089200358237

Epoch: 5| Step: 3
Training loss: 2.1011123657226562
Validation loss: 2.0598368272986463

Epoch: 5| Step: 4
Training loss: 2.0527496337890625
Validation loss: 2.0651304157831336

Epoch: 5| Step: 5
Training loss: 1.5914342403411865
Validation loss: 2.0544593513652845

Epoch: 5| Step: 6
Training loss: 1.801926851272583
Validation loss: 2.0495144551800144

Epoch: 5| Step: 7
Training loss: 2.5062966346740723
Validation loss: 2.055771727715769

Epoch: 5| Step: 8
Training loss: 2.9168858528137207
Validation loss: 2.0354542911693616

Epoch: 5| Step: 9
Training loss: 2.140692710876465
Validation loss: 2.039156110055985

Epoch: 5| Step: 10
Training loss: 1.9064887762069702
Validation loss: 2.040115248772406

Epoch: 88| Step: 0
Training loss: 2.625828742980957
Validation loss: 2.0447182219515563

Epoch: 5| Step: 1
Training loss: 2.7383100986480713
Validation loss: 2.0345097600772815

Epoch: 5| Step: 2
Training loss: 1.6223739385604858
Validation loss: 2.043339531908753

Epoch: 5| Step: 3
Training loss: 2.11098575592041
Validation loss: 2.0435520218264673

Epoch: 5| Step: 4
Training loss: 2.0141491889953613
Validation loss: 2.057193033156856

Epoch: 5| Step: 5
Training loss: 2.3172335624694824
Validation loss: 2.048753915294524

Epoch: 5| Step: 6
Training loss: 1.9243011474609375
Validation loss: 2.0516473990614696

Epoch: 5| Step: 7
Training loss: 2.193647861480713
Validation loss: 2.049953793966642

Epoch: 5| Step: 8
Training loss: 2.541590452194214
Validation loss: 2.063452677060199

Epoch: 5| Step: 9
Training loss: 1.9493181705474854
Validation loss: 2.035239258120137

Epoch: 5| Step: 10
Training loss: 1.8966962099075317
Validation loss: 2.065875143133184

Epoch: 89| Step: 0
Training loss: 1.8753983974456787
Validation loss: 2.044935744295838

Epoch: 5| Step: 1
Training loss: 2.1042628288269043
Validation loss: 2.0439307151302213

Epoch: 5| Step: 2
Training loss: 2.216200351715088
Validation loss: 2.04513483278213

Epoch: 5| Step: 3
Training loss: 2.3338828086853027
Validation loss: 2.0550766350120626

Epoch: 5| Step: 4
Training loss: 1.7137645483016968
Validation loss: 2.0580129649049494

Epoch: 5| Step: 5
Training loss: 2.6642582416534424
Validation loss: 2.041383299776303

Epoch: 5| Step: 6
Training loss: 2.5886173248291016
Validation loss: 2.0658330942994807

Epoch: 5| Step: 7
Training loss: 2.221109628677368
Validation loss: 2.0529983812762844

Epoch: 5| Step: 8
Training loss: 2.01214599609375
Validation loss: 2.064096062414108

Epoch: 5| Step: 9
Training loss: 1.8553396463394165
Validation loss: 2.039409170868576

Epoch: 5| Step: 10
Training loss: 2.626647472381592
Validation loss: 2.070330819775981

Epoch: 90| Step: 0
Training loss: 2.4531784057617188
Validation loss: 2.0516358165330786

Epoch: 5| Step: 1
Training loss: 2.4671573638916016
Validation loss: 2.0655133262757333

Epoch: 5| Step: 2
Training loss: 2.158186435699463
Validation loss: 2.045426543040942

Epoch: 5| Step: 3
Training loss: 2.2645556926727295
Validation loss: 2.05453460959978

Epoch: 5| Step: 4
Training loss: 2.890998363494873
Validation loss: 2.0601707504641626

Epoch: 5| Step: 5
Training loss: 2.281045913696289
Validation loss: 2.070652759203347

Epoch: 5| Step: 6
Training loss: 1.9055845737457275
Validation loss: 2.069454954516503

Epoch: 5| Step: 7
Training loss: 2.043048858642578
Validation loss: 2.0521710880341066

Epoch: 5| Step: 8
Training loss: 1.5282814502716064
Validation loss: 2.074427884112122

Epoch: 5| Step: 9
Training loss: 2.129765033721924
Validation loss: 2.0452437221363025

Epoch: 5| Step: 10
Training loss: 1.9105924367904663
Validation loss: 2.0694532971228323

Epoch: 91| Step: 0
Training loss: 2.3273508548736572
Validation loss: 2.046757341713034

Epoch: 5| Step: 1
Training loss: 1.7837053537368774
Validation loss: 2.076844125665644

Epoch: 5| Step: 2
Training loss: 2.539222240447998
Validation loss: 2.0474968430816487

Epoch: 5| Step: 3
Training loss: 2.842376232147217
Validation loss: 2.0603361232306368

Epoch: 5| Step: 4
Training loss: 2.177049160003662
Validation loss: 2.0500732852566625

Epoch: 5| Step: 5
Training loss: 2.09185791015625
Validation loss: 2.044752387590306

Epoch: 5| Step: 6
Training loss: 2.473442792892456
Validation loss: 2.05148027020116

Epoch: 5| Step: 7
Training loss: 1.866155982017517
Validation loss: 2.0578365684837423

Epoch: 5| Step: 8
Training loss: 2.074091911315918
Validation loss: 2.044310790236278

Epoch: 5| Step: 9
Training loss: 1.7414363622665405
Validation loss: 2.0485174361095635

Epoch: 5| Step: 10
Training loss: 1.9727951288223267
Validation loss: 2.0544981879572712

Epoch: 92| Step: 0
Training loss: 2.326786994934082
Validation loss: 2.0515472376218407

Epoch: 5| Step: 1
Training loss: 1.9589354991912842
Validation loss: 2.0700957723843154

Epoch: 5| Step: 2
Training loss: 2.537104845046997
Validation loss: 2.073160966237386

Epoch: 5| Step: 3
Training loss: 2.1014163494110107
Validation loss: 2.036882483831016

Epoch: 5| Step: 4
Training loss: 2.5638139247894287
Validation loss: 2.0632378311567408

Epoch: 5| Step: 5
Training loss: 2.3152122497558594
Validation loss: 2.0484376312584005

Epoch: 5| Step: 6
Training loss: 2.058145761489868
Validation loss: 2.057060715972736

Epoch: 5| Step: 7
Training loss: 2.7486488819122314
Validation loss: 2.049257988570839

Epoch: 5| Step: 8
Training loss: 1.8631038665771484
Validation loss: 2.0404908016163814

Epoch: 5| Step: 9
Training loss: 2.065516948699951
Validation loss: 2.0516188785594

Epoch: 5| Step: 10
Training loss: 1.2500104904174805
Validation loss: 2.0532549940129763

Epoch: 93| Step: 0
Training loss: 2.8209280967712402
Validation loss: 2.0620383908671718

Epoch: 5| Step: 1
Training loss: 2.078662872314453
Validation loss: 2.046277271803989

Epoch: 5| Step: 2
Training loss: 1.825089454650879
Validation loss: 2.065335101978753

Epoch: 5| Step: 3
Training loss: 2.34466552734375
Validation loss: 2.053553628665145

Epoch: 5| Step: 4
Training loss: 2.1988022327423096
Validation loss: 2.049138157598434

Epoch: 5| Step: 5
Training loss: 2.097219944000244
Validation loss: 2.0424325991702337

Epoch: 5| Step: 6
Training loss: 2.246638059616089
Validation loss: 2.0485338869915215

Epoch: 5| Step: 7
Training loss: 2.0536611080169678
Validation loss: 2.0507924774641633

Epoch: 5| Step: 8
Training loss: 1.9384028911590576
Validation loss: 2.059142651096467

Epoch: 5| Step: 9
Training loss: 2.168652057647705
Validation loss: 2.0632470064265753

Epoch: 5| Step: 10
Training loss: 2.066132068634033
Validation loss: 2.0411280970419607

Epoch: 94| Step: 0
Training loss: 2.1823813915252686
Validation loss: 2.057606550955003

Epoch: 5| Step: 1
Training loss: 2.0395007133483887
Validation loss: 2.06790917663164

Epoch: 5| Step: 2
Training loss: 2.4543521404266357
Validation loss: 2.057208581637311

Epoch: 5| Step: 3
Training loss: 2.2393436431884766
Validation loss: 2.044224462201518

Epoch: 5| Step: 4
Training loss: 2.2115366458892822
Validation loss: 2.053515946993264

Epoch: 5| Step: 5
Training loss: 1.8423480987548828
Validation loss: 2.074381496316643

Epoch: 5| Step: 6
Training loss: 2.2185511589050293
Validation loss: 2.0544824138764413

Epoch: 5| Step: 7
Training loss: 2.219874143600464
Validation loss: 2.0545891561815814

Epoch: 5| Step: 8
Training loss: 2.206665277481079
Validation loss: 2.048816127161826

Epoch: 5| Step: 9
Training loss: 1.8219163417816162
Validation loss: 2.047641702877578

Epoch: 5| Step: 10
Training loss: 2.4081833362579346
Validation loss: 2.050402970724208

Epoch: 95| Step: 0
Training loss: 1.6260395050048828
Validation loss: 2.0408968835748653

Epoch: 5| Step: 1
Training loss: 1.8434131145477295
Validation loss: 2.0466159107864543

Epoch: 5| Step: 2
Training loss: 2.432884693145752
Validation loss: 2.0481826336153093

Epoch: 5| Step: 3
Training loss: 2.226752996444702
Validation loss: 2.056813468215286

Epoch: 5| Step: 4
Training loss: 1.8007497787475586
Validation loss: 2.045767484172698

Epoch: 5| Step: 5
Training loss: 1.4841718673706055
Validation loss: 2.0344331392677883

Epoch: 5| Step: 6
Training loss: 3.1401333808898926
Validation loss: 2.061231602904617

Epoch: 5| Step: 7
Training loss: 2.286149263381958
Validation loss: 2.0479312199418263

Epoch: 5| Step: 8
Training loss: 1.9884077310562134
Validation loss: 2.0488904137765207

Epoch: 5| Step: 9
Training loss: 2.558446168899536
Validation loss: 2.0663767630054104

Epoch: 5| Step: 10
Training loss: 2.778580904006958
Validation loss: 2.0434608382563435

Epoch: 96| Step: 0
Training loss: 2.232867479324341
Validation loss: 2.045024089915778

Epoch: 5| Step: 1
Training loss: 2.113577127456665
Validation loss: 2.055270928208546

Epoch: 5| Step: 2
Training loss: 2.0687503814697266
Validation loss: 2.040625040249158

Epoch: 5| Step: 3
Training loss: 1.8524211645126343
Validation loss: 2.042302511071646

Epoch: 5| Step: 4
Training loss: 3.335442304611206
Validation loss: 2.062401190880806

Epoch: 5| Step: 5
Training loss: 2.5158896446228027
Validation loss: 2.0485670489649617

Epoch: 5| Step: 6
Training loss: 2.076901435852051
Validation loss: 2.076972620461577

Epoch: 5| Step: 7
Training loss: 2.2493252754211426
Validation loss: 2.0569372497579104

Epoch: 5| Step: 8
Training loss: 1.9539839029312134
Validation loss: 2.0432192099991666

Epoch: 5| Step: 9
Training loss: 1.3884999752044678
Validation loss: 2.0466184282815583

Epoch: 5| Step: 10
Training loss: 2.0654828548431396
Validation loss: 2.056220252026794

Epoch: 97| Step: 0
Training loss: 2.1227638721466064
Validation loss: 2.0658799409866333

Epoch: 5| Step: 1
Training loss: 1.326791524887085
Validation loss: 2.048487796578356

Epoch: 5| Step: 2
Training loss: 1.6154301166534424
Validation loss: 2.0626946290334067

Epoch: 5| Step: 3
Training loss: 1.959172010421753
Validation loss: 2.0332975490118868

Epoch: 5| Step: 4
Training loss: 2.672497510910034
Validation loss: 2.053319528538694

Epoch: 5| Step: 5
Training loss: 2.50579571723938
Validation loss: 2.0540709136634745

Epoch: 5| Step: 6
Training loss: 2.0760273933410645
Validation loss: 2.058297698215772

Epoch: 5| Step: 7
Training loss: 2.2927119731903076
Validation loss: 2.048574898832588

Epoch: 5| Step: 8
Training loss: 2.169964075088501
Validation loss: 2.072639721696095

Epoch: 5| Step: 9
Training loss: 2.6461334228515625
Validation loss: 2.059419026938818

Epoch: 5| Step: 10
Training loss: 2.415255308151245
Validation loss: 2.065840003310993

Epoch: 98| Step: 0
Training loss: 2.452275514602661
Validation loss: 2.052288132329141

Epoch: 5| Step: 1
Training loss: 2.115170955657959
Validation loss: 2.051541846285584

Epoch: 5| Step: 2
Training loss: 3.0370213985443115
Validation loss: 2.0483350689693163

Epoch: 5| Step: 3
Training loss: 1.92473566532135
Validation loss: 2.052739930409257

Epoch: 5| Step: 4
Training loss: 2.189063787460327
Validation loss: 2.0604178597850185

Epoch: 5| Step: 5
Training loss: 1.527937889099121
Validation loss: 2.062090648117886

Epoch: 5| Step: 6
Training loss: 2.237020969390869
Validation loss: 2.0718764335878435

Epoch: 5| Step: 7
Training loss: 2.1739821434020996
Validation loss: 2.042808376332765

Epoch: 5| Step: 8
Training loss: 2.042720079421997
Validation loss: 2.037389078447896

Epoch: 5| Step: 9
Training loss: 1.6622165441513062
Validation loss: 2.041578633810884

Epoch: 5| Step: 10
Training loss: 2.5016605854034424
Validation loss: 2.049189231728995

Epoch: 99| Step: 0
Training loss: 2.076319932937622
Validation loss: 2.045068774172055

Epoch: 5| Step: 1
Training loss: 1.863157868385315
Validation loss: 2.050741841716151

Epoch: 5| Step: 2
Training loss: 2.1684489250183105
Validation loss: 2.03184183566801

Epoch: 5| Step: 3
Training loss: 2.1470088958740234
Validation loss: 2.0572602607870616

Epoch: 5| Step: 4
Training loss: 2.4665160179138184
Validation loss: 2.05947660246203

Epoch: 5| Step: 5
Training loss: 2.423981189727783
Validation loss: 2.042667426088805

Epoch: 5| Step: 6
Training loss: 2.8654427528381348
Validation loss: 2.027332875036424

Epoch: 5| Step: 7
Training loss: 1.9161593914031982
Validation loss: 2.0634116818827968

Epoch: 5| Step: 8
Training loss: 1.7316166162490845
Validation loss: 2.053252773900186

Epoch: 5| Step: 9
Training loss: 1.98480224609375
Validation loss: 2.051529117809829

Epoch: 5| Step: 10
Training loss: 2.0510079860687256
Validation loss: 2.0570295421026086

Epoch: 100| Step: 0
Training loss: 2.0721399784088135
Validation loss: 2.046586867301695

Epoch: 5| Step: 1
Training loss: 2.0780956745147705
Validation loss: 2.0579434133345083

Epoch: 5| Step: 2
Training loss: 2.2570126056671143
Validation loss: 2.064315488261561

Epoch: 5| Step: 3
Training loss: 2.6941909790039062
Validation loss: 2.074751921879348

Epoch: 5| Step: 4
Training loss: 1.4518009424209595
Validation loss: 2.0465061356944423

Epoch: 5| Step: 5
Training loss: 2.0687649250030518
Validation loss: 2.064525032556185

Epoch: 5| Step: 6
Training loss: 2.266289710998535
Validation loss: 2.066187491980932

Epoch: 5| Step: 7
Training loss: 2.2446742057800293
Validation loss: 2.0567017550109536

Epoch: 5| Step: 8
Training loss: 2.484163999557495
Validation loss: 2.05417122251244

Epoch: 5| Step: 9
Training loss: 2.1428165435791016
Validation loss: 2.0493591652121594

Epoch: 5| Step: 10
Training loss: 1.828900933265686
Validation loss: 2.049990043845228

Epoch: 101| Step: 0
Training loss: 1.9163246154785156
Validation loss: 2.077553310701924

Epoch: 5| Step: 1
Training loss: 1.5453613996505737
Validation loss: 2.066378874163474

Epoch: 5| Step: 2
Training loss: 2.2402613162994385
Validation loss: 2.065025579544806

Epoch: 5| Step: 3
Training loss: 1.7834501266479492
Validation loss: 2.05748495235238

Epoch: 5| Step: 4
Training loss: 2.076698064804077
Validation loss: 2.0701434714819795

Epoch: 5| Step: 5
Training loss: 2.697711944580078
Validation loss: 2.039299075321485

Epoch: 5| Step: 6
Training loss: 2.3374950885772705
Validation loss: 2.0450430762383247

Epoch: 5| Step: 7
Training loss: 1.9967060089111328
Validation loss: 2.0604270171093684

Epoch: 5| Step: 8
Training loss: 2.855130672454834
Validation loss: 2.047763709099062

Epoch: 5| Step: 9
Training loss: 1.9733257293701172
Validation loss: 2.0737402131480556

Epoch: 5| Step: 10
Training loss: 2.2291619777679443
Validation loss: 2.0487244039453487

Epoch: 102| Step: 0
Training loss: 2.242626905441284
Validation loss: 2.0595662414386706

Epoch: 5| Step: 1
Training loss: 2.2930688858032227
Validation loss: 2.0548259622307232

Epoch: 5| Step: 2
Training loss: 2.1278185844421387
Validation loss: 2.0426905949910483

Epoch: 5| Step: 3
Training loss: 1.625927209854126
Validation loss: 2.0706422803222493

Epoch: 5| Step: 4
Training loss: 2.0546460151672363
Validation loss: 2.058547609595842

Epoch: 5| Step: 5
Training loss: 2.1894869804382324
Validation loss: 2.070818148633485

Epoch: 5| Step: 6
Training loss: 2.0109105110168457
Validation loss: 2.035042053909712

Epoch: 5| Step: 7
Training loss: 2.1371772289276123
Validation loss: 2.0393539705584125

Epoch: 5| Step: 8
Training loss: 2.5241119861602783
Validation loss: 2.038468837738037

Epoch: 5| Step: 9
Training loss: 2.0096921920776367
Validation loss: 2.0518280741988972

Epoch: 5| Step: 10
Training loss: 2.419834852218628
Validation loss: 2.0515063885719544

Epoch: 103| Step: 0
Training loss: 1.447185754776001
Validation loss: 2.076956290070729

Epoch: 5| Step: 1
Training loss: 2.2338900566101074
Validation loss: 2.071741000298531

Epoch: 5| Step: 2
Training loss: 2.452888250350952
Validation loss: 2.0559785942877493

Epoch: 5| Step: 3
Training loss: 2.1572957038879395
Validation loss: 2.0421766657983103

Epoch: 5| Step: 4
Training loss: 1.8055537939071655
Validation loss: 2.073284431170392

Epoch: 5| Step: 5
Training loss: 2.345186233520508
Validation loss: 2.0587945394618536

Epoch: 5| Step: 6
Training loss: 2.2185263633728027
Validation loss: 2.052078390634188

Epoch: 5| Step: 7
Training loss: 1.9433984756469727
Validation loss: 2.07140883322685

Epoch: 5| Step: 8
Training loss: 2.9440433979034424
Validation loss: 2.0532604545675297

Epoch: 5| Step: 9
Training loss: 2.03289532661438
Validation loss: 2.0456286912323325

Epoch: 5| Step: 10
Training loss: 2.0218505859375
Validation loss: 2.0684871955584456

Epoch: 104| Step: 0
Training loss: 2.471999406814575
Validation loss: 2.0703175285811066

Epoch: 5| Step: 1
Training loss: 2.491271495819092
Validation loss: 2.0542607999617055

Epoch: 5| Step: 2
Training loss: 1.5975511074066162
Validation loss: 2.0540628023045038

Epoch: 5| Step: 3
Training loss: 2.145174264907837
Validation loss: 2.0285799208507744

Epoch: 5| Step: 4
Training loss: 2.933664321899414
Validation loss: 2.0366293794365338

Epoch: 5| Step: 5
Training loss: 2.593728542327881
Validation loss: 2.0455723231838596

Epoch: 5| Step: 6
Training loss: 1.9836927652359009
Validation loss: 2.0412777957095893

Epoch: 5| Step: 7
Training loss: 2.007416248321533
Validation loss: 2.0671656336835635

Epoch: 5| Step: 8
Training loss: 1.5168673992156982
Validation loss: 2.0493129684079077

Epoch: 5| Step: 9
Training loss: 2.0435702800750732
Validation loss: 2.030698154562263

Epoch: 5| Step: 10
Training loss: 1.762316107749939
Validation loss: 2.0433368195769606

Epoch: 105| Step: 0
Training loss: 2.6983392238616943
Validation loss: 2.054544145061124

Epoch: 5| Step: 1
Training loss: 2.709688425064087
Validation loss: 2.0414663630147136

Epoch: 5| Step: 2
Training loss: 2.600527286529541
Validation loss: 2.0654375348039853

Epoch: 5| Step: 3
Training loss: 1.505066156387329
Validation loss: 2.059010383903339

Epoch: 5| Step: 4
Training loss: 2.139237880706787
Validation loss: 2.046410660589895

Epoch: 5| Step: 5
Training loss: 2.0929694175720215
Validation loss: 2.045812281229163

Epoch: 5| Step: 6
Training loss: 2.49898099899292
Validation loss: 2.0450533154190227

Epoch: 5| Step: 7
Training loss: 1.9391196966171265
Validation loss: 2.0673274699077813

Epoch: 5| Step: 8
Training loss: 2.031693696975708
Validation loss: 2.056535518297585

Epoch: 5| Step: 9
Training loss: 1.4581259489059448
Validation loss: 2.054242718604303

Epoch: 5| Step: 10
Training loss: 1.760742425918579
Validation loss: 2.051631808280945

Epoch: 106| Step: 0
Training loss: 2.238285541534424
Validation loss: 2.0407527723620014

Epoch: 5| Step: 1
Training loss: 2.0418052673339844
Validation loss: 2.0521162568881945

Epoch: 5| Step: 2
Training loss: 2.7608251571655273
Validation loss: 2.0554668646986767

Epoch: 5| Step: 3
Training loss: 2.3533267974853516
Validation loss: 2.044804101349205

Epoch: 5| Step: 4
Training loss: 2.228938341140747
Validation loss: 2.056155261173043

Epoch: 5| Step: 5
Training loss: 1.95772385597229
Validation loss: 2.0382862655065392

Epoch: 5| Step: 6
Training loss: 1.7582212686538696
Validation loss: 2.0613005904741186

Epoch: 5| Step: 7
Training loss: 1.4152519702911377
Validation loss: 2.0350575395809707

Epoch: 5| Step: 8
Training loss: 2.229060411453247
Validation loss: 2.048200576536117

Epoch: 5| Step: 9
Training loss: 2.0497708320617676
Validation loss: 2.0505187485807683

Epoch: 5| Step: 10
Training loss: 2.5397520065307617
Validation loss: 2.0482322374979653

Epoch: 107| Step: 0
Training loss: 2.1971371173858643
Validation loss: 2.0315929292350687

Epoch: 5| Step: 1
Training loss: 1.7131407260894775
Validation loss: 2.068118933708437

Epoch: 5| Step: 2
Training loss: 2.07861590385437
Validation loss: 2.0525690214608305

Epoch: 5| Step: 3
Training loss: 2.1513257026672363
Validation loss: 2.0587533481659426

Epoch: 5| Step: 4
Training loss: 1.911380410194397
Validation loss: 2.066870561210058

Epoch: 5| Step: 5
Training loss: 2.2466518878936768
Validation loss: 2.043326540659833

Epoch: 5| Step: 6
Training loss: 1.9197025299072266
Validation loss: 2.0605812713664067

Epoch: 5| Step: 7
Training loss: 2.1661784648895264
Validation loss: 2.094842428802162

Epoch: 5| Step: 8
Training loss: 2.4797205924987793
Validation loss: 2.0695605995834514

Epoch: 5| Step: 9
Training loss: 1.803479552268982
Validation loss: 2.064367607075681

Epoch: 5| Step: 10
Training loss: 3.098468065261841
Validation loss: 2.051023466612703

Epoch: 108| Step: 0
Training loss: 2.8120789527893066
Validation loss: 2.051478821744201

Epoch: 5| Step: 1
Training loss: 1.9387474060058594
Validation loss: 2.0573860470966627

Epoch: 5| Step: 2
Training loss: 1.738472580909729
Validation loss: 2.052831252415975

Epoch: 5| Step: 3
Training loss: 1.8320634365081787
Validation loss: 2.055835284212584

Epoch: 5| Step: 4
Training loss: 1.869126319885254
Validation loss: 2.058350298994331

Epoch: 5| Step: 5
Training loss: 1.9740116596221924
Validation loss: 2.052364783902322

Epoch: 5| Step: 6
Training loss: 2.081134796142578
Validation loss: 2.0552891198024956

Epoch: 5| Step: 7
Training loss: 2.621215343475342
Validation loss: 2.056184768676758

Epoch: 5| Step: 8
Training loss: 1.8346580266952515
Validation loss: 2.0411911549106723

Epoch: 5| Step: 9
Training loss: 2.2134616374969482
Validation loss: 2.0611848984995196

Epoch: 5| Step: 10
Training loss: 2.7592849731445312
Validation loss: 2.0700631372390257

Epoch: 109| Step: 0
Training loss: 2.4658031463623047
Validation loss: 2.0461951891581216

Epoch: 5| Step: 1
Training loss: 1.3718504905700684
Validation loss: 2.0341330510313793

Epoch: 5| Step: 2
Training loss: 2.954540491104126
Validation loss: 2.0521572456564954

Epoch: 5| Step: 3
Training loss: 2.2533984184265137
Validation loss: 2.0577122639584284

Epoch: 5| Step: 4
Training loss: 2.0122933387756348
Validation loss: 2.0797486894874164

Epoch: 5| Step: 5
Training loss: 2.079925537109375
Validation loss: 2.0607428191810526

Epoch: 5| Step: 6
Training loss: 2.5116820335388184
Validation loss: 2.0562150657817884

Epoch: 5| Step: 7
Training loss: 2.342574119567871
Validation loss: 2.048542937924785

Epoch: 5| Step: 8
Training loss: 2.1408276557922363
Validation loss: 2.0529708195758123

Epoch: 5| Step: 9
Training loss: 1.6115509271621704
Validation loss: 2.061539198762627

Epoch: 5| Step: 10
Training loss: 1.6638484001159668
Validation loss: 2.061328313683951

Epoch: 110| Step: 0
Training loss: 2.3617148399353027
Validation loss: 2.0601596114456013

Epoch: 5| Step: 1
Training loss: 1.6351356506347656
Validation loss: 2.039982198387064

Epoch: 5| Step: 2
Training loss: 2.3332180976867676
Validation loss: 2.064252663684148

Epoch: 5| Step: 3
Training loss: 2.2051939964294434
Validation loss: 2.047447289189985

Epoch: 5| Step: 4
Training loss: 2.2137348651885986
Validation loss: 2.054787971640146

Epoch: 5| Step: 5
Training loss: 1.7965819835662842
Validation loss: 2.028346327043349

Epoch: 5| Step: 6
Training loss: 1.8406912088394165
Validation loss: 2.0522382900279057

Epoch: 5| Step: 7
Training loss: 2.115210771560669
Validation loss: 2.042408517611924

Epoch: 5| Step: 8
Training loss: 2.7616443634033203
Validation loss: 2.0244286393606536

Epoch: 5| Step: 9
Training loss: 2.3212132453918457
Validation loss: 2.0489784568868656

Epoch: 5| Step: 10
Training loss: 1.9312779903411865
Validation loss: 2.031970506073326

Epoch: 111| Step: 0
Training loss: 1.9871633052825928
Validation loss: 2.0478446996340187

Epoch: 5| Step: 1
Training loss: 2.872014045715332
Validation loss: 2.0401137759608607

Epoch: 5| Step: 2
Training loss: 2.032266616821289
Validation loss: 2.0277434497751217

Epoch: 5| Step: 3
Training loss: 1.9396120309829712
Validation loss: 2.0619143414241012

Epoch: 5| Step: 4
Training loss: 1.4140397310256958
Validation loss: 2.0291134798398582

Epoch: 5| Step: 5
Training loss: 2.2784321308135986
Validation loss: 2.0409153571692844

Epoch: 5| Step: 6
Training loss: 2.2673823833465576
Validation loss: 2.046601955608655

Epoch: 5| Step: 7
Training loss: 2.01406192779541
Validation loss: 2.043849318258224

Epoch: 5| Step: 8
Training loss: 1.9861961603164673
Validation loss: 2.039671431305588

Epoch: 5| Step: 9
Training loss: 1.6633208990097046
Validation loss: 2.0354131267916773

Epoch: 5| Step: 10
Training loss: 3.0000925064086914
Validation loss: 2.071150505414573

Epoch: 112| Step: 0
Training loss: 1.7119020223617554
Validation loss: 2.0529098510742188

Epoch: 5| Step: 1
Training loss: 2.731062412261963
Validation loss: 2.0553908232719666

Epoch: 5| Step: 2
Training loss: 2.3075945377349854
Validation loss: 2.052137626114712

Epoch: 5| Step: 3
Training loss: 1.921892523765564
Validation loss: 2.049764689578805

Epoch: 5| Step: 4
Training loss: 2.214369058609009
Validation loss: 2.043889179024645

Epoch: 5| Step: 5
Training loss: 2.151726245880127
Validation loss: 2.0464185937758415

Epoch: 5| Step: 6
Training loss: 1.3190996646881104
Validation loss: 2.0567666023008284

Epoch: 5| Step: 7
Training loss: 2.3088319301605225
Validation loss: 2.056192195543679

Epoch: 5| Step: 8
Training loss: 2.5024843215942383
Validation loss: 2.050632538334016

Epoch: 5| Step: 9
Training loss: 1.8297828435897827
Validation loss: 2.0420780271612187

Epoch: 5| Step: 10
Training loss: 2.5790226459503174
Validation loss: 2.066781037597246

Epoch: 113| Step: 0
Training loss: 1.589146375656128
Validation loss: 2.044760291294385

Epoch: 5| Step: 1
Training loss: 2.6645443439483643
Validation loss: 2.0539744156663136

Epoch: 5| Step: 2
Training loss: 1.9026740789413452
Validation loss: 2.0380152399821947

Epoch: 5| Step: 3
Training loss: 1.8553978204727173
Validation loss: 2.0426744632823493

Epoch: 5| Step: 4
Training loss: 2.0258116722106934
Validation loss: 2.0482557358280307

Epoch: 5| Step: 5
Training loss: 1.8116075992584229
Validation loss: 2.044306021864696

Epoch: 5| Step: 6
Training loss: 2.499701738357544
Validation loss: 2.0449003429823023

Epoch: 5| Step: 7
Training loss: 2.3422691822052
Validation loss: 2.061728363396019

Epoch: 5| Step: 8
Training loss: 2.297586679458618
Validation loss: 2.05184442253523

Epoch: 5| Step: 9
Training loss: 1.9754126071929932
Validation loss: 2.0585350528840096

Epoch: 5| Step: 10
Training loss: 2.4569857120513916
Validation loss: 2.028264263624786

Epoch: 114| Step: 0
Training loss: 1.8813183307647705
Validation loss: 2.038868320885525

Epoch: 5| Step: 1
Training loss: 2.4074490070343018
Validation loss: 2.046506389494865

Epoch: 5| Step: 2
Training loss: 2.0604913234710693
Validation loss: 2.0422775745391846

Epoch: 5| Step: 3
Training loss: 1.6764638423919678
Validation loss: 2.0636629981379353

Epoch: 5| Step: 4
Training loss: 2.011260986328125
Validation loss: 2.067910555870302

Epoch: 5| Step: 5
Training loss: 1.516784429550171
Validation loss: 2.0510597152094685

Epoch: 5| Step: 6
Training loss: 1.9758142232894897
Validation loss: 2.0362488838934127

Epoch: 5| Step: 7
Training loss: 2.10573410987854
Validation loss: 2.0215852863045147

Epoch: 5| Step: 8
Training loss: 2.7572197914123535
Validation loss: 2.0499650227126254

Epoch: 5| Step: 9
Training loss: 2.0268471240997314
Validation loss: 2.0574412691977715

Epoch: 5| Step: 10
Training loss: 3.077404499053955
Validation loss: 2.037513558582593

Epoch: 115| Step: 0
Training loss: 2.1143088340759277
Validation loss: 2.0584217450952016

Epoch: 5| Step: 1
Training loss: 2.226663827896118
Validation loss: 2.05020954403826

Epoch: 5| Step: 2
Training loss: 2.801298141479492
Validation loss: 2.062109283221665

Epoch: 5| Step: 3
Training loss: 2.444805145263672
Validation loss: 2.0533197182481007

Epoch: 5| Step: 4
Training loss: 2.247049331665039
Validation loss: 2.0491031767219625

Epoch: 5| Step: 5
Training loss: 2.715754747390747
Validation loss: 2.034019152323405

Epoch: 5| Step: 6
Training loss: 1.6460367441177368
Validation loss: 2.0538478948736705

Epoch: 5| Step: 7
Training loss: 1.6331573724746704
Validation loss: 2.0573490101804017

Epoch: 5| Step: 8
Training loss: 1.6201975345611572
Validation loss: 2.0450527565453642

Epoch: 5| Step: 9
Training loss: 1.6031450033187866
Validation loss: 2.0458788794855916

Epoch: 5| Step: 10
Training loss: 2.091087818145752
Validation loss: 2.047082495945756

Epoch: 116| Step: 0
Training loss: 2.414444923400879
Validation loss: 2.055940802379321

Epoch: 5| Step: 1
Training loss: 2.151890516281128
Validation loss: 2.036853390355264

Epoch: 5| Step: 2
Training loss: 2.726015090942383
Validation loss: 2.058407137470861

Epoch: 5| Step: 3
Training loss: 1.7749525308609009
Validation loss: 2.0401988414026078

Epoch: 5| Step: 4
Training loss: 2.28045654296875
Validation loss: 2.061551401692052

Epoch: 5| Step: 5
Training loss: 2.2764434814453125
Validation loss: 2.0626261183010635

Epoch: 5| Step: 6
Training loss: 1.8828084468841553
Validation loss: 2.0574172709577825

Epoch: 5| Step: 7
Training loss: 1.7477772235870361
Validation loss: 2.048609031144009

Epoch: 5| Step: 8
Training loss: 1.747488260269165
Validation loss: 2.0600520410845355

Epoch: 5| Step: 9
Training loss: 2.261147975921631
Validation loss: 2.056499091527795

Epoch: 5| Step: 10
Training loss: 1.9531779289245605
Validation loss: 2.07051206404163

Epoch: 117| Step: 0
Training loss: 2.13557767868042
Validation loss: 2.05040680977606

Epoch: 5| Step: 1
Training loss: 1.803666114807129
Validation loss: 2.051936125242582

Epoch: 5| Step: 2
Training loss: 2.1779403686523438
Validation loss: 2.06314597078549

Epoch: 5| Step: 3
Training loss: 1.8748722076416016
Validation loss: 2.036931586521928

Epoch: 5| Step: 4
Training loss: 1.9560215473175049
Validation loss: 2.049419303094187

Epoch: 5| Step: 5
Training loss: 2.197937488555908
Validation loss: 2.0499962709283315

Epoch: 5| Step: 6
Training loss: 2.8601155281066895
Validation loss: 2.0684373506935696

Epoch: 5| Step: 7
Training loss: 2.3203377723693848
Validation loss: 2.0693073939251643

Epoch: 5| Step: 8
Training loss: 2.123818874359131
Validation loss: 2.0630929828971944

Epoch: 5| Step: 9
Training loss: 1.7704393863677979
Validation loss: 2.03799008810392

Epoch: 5| Step: 10
Training loss: 2.0368869304656982
Validation loss: 2.070042843459755

Epoch: 118| Step: 0
Training loss: 1.9106471538543701
Validation loss: 2.0751909671291227

Epoch: 5| Step: 1
Training loss: 3.0884456634521484
Validation loss: 2.0422970171897643

Epoch: 5| Step: 2
Training loss: 1.7809343338012695
Validation loss: 2.0570333619271555

Epoch: 5| Step: 3
Training loss: 2.174309730529785
Validation loss: 2.0503802914773264

Epoch: 5| Step: 4
Training loss: 2.298124074935913
Validation loss: 2.0589805072353733

Epoch: 5| Step: 5
Training loss: 1.3925788402557373
Validation loss: 2.071195048670615

Epoch: 5| Step: 6
Training loss: 1.8151601552963257
Validation loss: 2.039147825651271

Epoch: 5| Step: 7
Training loss: 1.976583480834961
Validation loss: 2.0526210569566294

Epoch: 5| Step: 8
Training loss: 2.126723527908325
Validation loss: 2.056732000843171

Epoch: 5| Step: 9
Training loss: 2.4982943534851074
Validation loss: 2.043277750733078

Epoch: 5| Step: 10
Training loss: 2.086034059524536
Validation loss: 2.0272758904323784

Epoch: 119| Step: 0
Training loss: 1.8092674016952515
Validation loss: 2.052398109948763

Epoch: 5| Step: 1
Training loss: 2.0055768489837646
Validation loss: 2.047258982094385

Epoch: 5| Step: 2
Training loss: 2.505019426345825
Validation loss: 2.024061423476024

Epoch: 5| Step: 3
Training loss: 1.695220947265625
Validation loss: 2.0451919071135984

Epoch: 5| Step: 4
Training loss: 2.213660717010498
Validation loss: 2.0562174268948135

Epoch: 5| Step: 5
Training loss: 2.148888349533081
Validation loss: 2.0495608032390638

Epoch: 5| Step: 6
Training loss: 2.3953635692596436
Validation loss: 2.046819558707617

Epoch: 5| Step: 7
Training loss: 2.3809356689453125
Validation loss: 2.0631771241464922

Epoch: 5| Step: 8
Training loss: 1.8693681955337524
Validation loss: 2.0453451897508357

Epoch: 5| Step: 9
Training loss: 2.2578682899475098
Validation loss: 2.0486570455694713

Epoch: 5| Step: 10
Training loss: 1.7214624881744385
Validation loss: 2.029680290529805

Epoch: 120| Step: 0
Training loss: 2.1808485984802246
Validation loss: 2.054086051961427

Epoch: 5| Step: 1
Training loss: 2.6586036682128906
Validation loss: 2.0524655388247584

Epoch: 5| Step: 2
Training loss: 2.090261697769165
Validation loss: 2.0559320783102386

Epoch: 5| Step: 3
Training loss: 2.090503215789795
Validation loss: 2.0472970111395723

Epoch: 5| Step: 4
Training loss: 1.8515737056732178
Validation loss: 2.038832131252494

Epoch: 5| Step: 5
Training loss: 1.327348232269287
Validation loss: 2.067202842363747

Epoch: 5| Step: 6
Training loss: 1.9486039876937866
Validation loss: 2.047903385213626

Epoch: 5| Step: 7
Training loss: 2.041956663131714
Validation loss: 2.0684151367474626

Epoch: 5| Step: 8
Training loss: 2.5766091346740723
Validation loss: 2.043143364690965

Epoch: 5| Step: 9
Training loss: 2.2380030155181885
Validation loss: 2.0497737725575766

Epoch: 5| Step: 10
Training loss: 1.9546223878860474
Validation loss: 2.0515672314551567

Epoch: 121| Step: 0
Training loss: 2.0605521202087402
Validation loss: 2.06311918586813

Epoch: 5| Step: 1
Training loss: 1.6569362878799438
Validation loss: 2.0434324536272275

Epoch: 5| Step: 2
Training loss: 2.200753688812256
Validation loss: 2.051710054438601

Epoch: 5| Step: 3
Training loss: 1.8250077962875366
Validation loss: 2.046142690925188

Epoch: 5| Step: 4
Training loss: 2.2918715476989746
Validation loss: 2.0609299136746313

Epoch: 5| Step: 5
Training loss: 2.990349531173706
Validation loss: 2.0529502232869468

Epoch: 5| Step: 6
Training loss: 1.6161152124404907
Validation loss: 2.054921198916692

Epoch: 5| Step: 7
Training loss: 2.509089231491089
Validation loss: 2.059681584758143

Epoch: 5| Step: 8
Training loss: 2.4252851009368896
Validation loss: 2.054701523114276

Epoch: 5| Step: 9
Training loss: 2.034925937652588
Validation loss: 2.0645371406309065

Epoch: 5| Step: 10
Training loss: 1.4444379806518555
Validation loss: 2.0596661900961273

Epoch: 122| Step: 0
Training loss: 2.3272361755371094
Validation loss: 2.041956176039993

Epoch: 5| Step: 1
Training loss: 1.950063943862915
Validation loss: 2.0742610769887126

Epoch: 5| Step: 2
Training loss: 2.4734582901000977
Validation loss: 2.061084683223437

Epoch: 5| Step: 3
Training loss: 1.6808898448944092
Validation loss: 2.0589466415425783

Epoch: 5| Step: 4
Training loss: 2.495335102081299
Validation loss: 2.044134339978618

Epoch: 5| Step: 5
Training loss: 2.4763376712799072
Validation loss: 2.035737351704669

Epoch: 5| Step: 6
Training loss: 1.6720468997955322
Validation loss: 2.0550001718664683

Epoch: 5| Step: 7
Training loss: 2.32149076461792
Validation loss: 2.072461179507676

Epoch: 5| Step: 8
Training loss: 1.504015326499939
Validation loss: 2.0541777533869587

Epoch: 5| Step: 9
Training loss: 2.0109355449676514
Validation loss: 2.045536697551768

Epoch: 5| Step: 10
Training loss: 2.1060872077941895
Validation loss: 2.0460129783999537

Epoch: 123| Step: 0
Training loss: 1.460258960723877
Validation loss: 2.041125568010474

Epoch: 5| Step: 1
Training loss: 2.1245150566101074
Validation loss: 2.0465747079541607

Epoch: 5| Step: 2
Training loss: 1.6100581884384155
Validation loss: 2.0515222857075353

Epoch: 5| Step: 3
Training loss: 2.4207420349121094
Validation loss: 2.0440409491139073

Epoch: 5| Step: 4
Training loss: 1.942419409751892
Validation loss: 2.0434382500187045

Epoch: 5| Step: 5
Training loss: 2.266740083694458
Validation loss: 2.0508693354104155

Epoch: 5| Step: 6
Training loss: 2.2648684978485107
Validation loss: 2.0529972763471704

Epoch: 5| Step: 7
Training loss: 2.32586669921875
Validation loss: 2.049704420951105

Epoch: 5| Step: 8
Training loss: 2.087125062942505
Validation loss: 2.053211312140188

Epoch: 5| Step: 9
Training loss: 2.3906290531158447
Validation loss: 2.0446935212740334

Epoch: 5| Step: 10
Training loss: 2.0505013465881348
Validation loss: 2.054969428687967

Epoch: 124| Step: 0
Training loss: 2.427983045578003
Validation loss: 2.0407139690973426

Epoch: 5| Step: 1
Training loss: 1.8012081384658813
Validation loss: 2.060325073939498

Epoch: 5| Step: 2
Training loss: 2.180562973022461
Validation loss: 2.0663898580817768

Epoch: 5| Step: 3
Training loss: 2.1535401344299316
Validation loss: 2.0645423191849903

Epoch: 5| Step: 4
Training loss: 2.3887853622436523
Validation loss: 2.0538820605124197

Epoch: 5| Step: 5
Training loss: 1.924164056777954
Validation loss: 2.0589917141904115

Epoch: 5| Step: 6
Training loss: 2.0820302963256836
Validation loss: 2.016014693885721

Epoch: 5| Step: 7
Training loss: 2.4098048210144043
Validation loss: 2.0513453893764044

Epoch: 5| Step: 8
Training loss: 1.7479088306427002
Validation loss: 2.0513958854060017

Epoch: 5| Step: 9
Training loss: 2.1975114345550537
Validation loss: 2.0702644458381076

Epoch: 5| Step: 10
Training loss: 1.6509790420532227
Validation loss: 2.081773174706326

Epoch: 125| Step: 0
Training loss: 1.9165401458740234
Validation loss: 2.05163933128439

Epoch: 5| Step: 1
Training loss: 2.5425639152526855
Validation loss: 2.0507998889492405

Epoch: 5| Step: 2
Training loss: 1.879238486289978
Validation loss: 2.0556266794922533

Epoch: 5| Step: 3
Training loss: 1.8479416370391846
Validation loss: 2.046930559219853

Epoch: 5| Step: 4
Training loss: 2.6208689212799072
Validation loss: 2.0707556534838933

Epoch: 5| Step: 5
Training loss: 2.169525623321533
Validation loss: 2.042844085283177

Epoch: 5| Step: 6
Training loss: 1.6551622152328491
Validation loss: 2.0523269612302064

Epoch: 5| Step: 7
Training loss: 2.2604708671569824
Validation loss: 2.041615686108989

Epoch: 5| Step: 8
Training loss: 1.9856675863265991
Validation loss: 2.0433077209739277

Epoch: 5| Step: 9
Training loss: 2.0730419158935547
Validation loss: 2.038609976409584

Epoch: 5| Step: 10
Training loss: 1.8951184749603271
Validation loss: 2.036533401858422

Epoch: 126| Step: 0
Training loss: 2.2880868911743164
Validation loss: 2.0562987686485372

Epoch: 5| Step: 1
Training loss: 2.015416383743286
Validation loss: 2.054023006910919

Epoch: 5| Step: 2
Training loss: 1.8247318267822266
Validation loss: 2.061272380172565

Epoch: 5| Step: 3
Training loss: 2.2994437217712402
Validation loss: 2.0442268156236216

Epoch: 5| Step: 4
Training loss: 2.0173850059509277
Validation loss: 2.0427535810778217

Epoch: 5| Step: 5
Training loss: 1.7806580066680908
Validation loss: 2.0413116485841813

Epoch: 5| Step: 6
Training loss: 2.061586856842041
Validation loss: 2.0510576373787335

Epoch: 5| Step: 7
Training loss: 2.6448428630828857
Validation loss: 2.041040623059837

Epoch: 5| Step: 8
Training loss: 1.6762886047363281
Validation loss: 2.0498557680396625

Epoch: 5| Step: 9
Training loss: 2.419161558151245
Validation loss: 2.032359923085859

Epoch: 5| Step: 10
Training loss: 1.773695707321167
Validation loss: 2.0403579435040875

Epoch: 127| Step: 0
Training loss: 2.086742877960205
Validation loss: 2.0660020638537664

Epoch: 5| Step: 1
Training loss: 2.1640608310699463
Validation loss: 2.0509211171057915

Epoch: 5| Step: 2
Training loss: 2.555143356323242
Validation loss: 2.0657898174819125

Epoch: 5| Step: 3
Training loss: 2.2458503246307373
Validation loss: 2.059564931418306

Epoch: 5| Step: 4
Training loss: 2.2709391117095947
Validation loss: 2.0760459746083906

Epoch: 5| Step: 5
Training loss: 2.321394920349121
Validation loss: 2.0718842937100317

Epoch: 5| Step: 6
Training loss: 2.370241403579712
Validation loss: 2.041222987636443

Epoch: 5| Step: 7
Training loss: 1.4772922992706299
Validation loss: 2.046366162197564

Epoch: 5| Step: 8
Training loss: 1.8987877368927002
Validation loss: 2.047553329057591

Epoch: 5| Step: 9
Training loss: 1.8011283874511719
Validation loss: 2.0615442747710855

Epoch: 5| Step: 10
Training loss: 1.7862095832824707
Validation loss: 2.0676367859686575

Epoch: 128| Step: 0
Training loss: 2.6671836376190186
Validation loss: 2.0461440560638264

Epoch: 5| Step: 1
Training loss: 1.8291311264038086
Validation loss: 2.0647663916310957

Epoch: 5| Step: 2
Training loss: 2.055258274078369
Validation loss: 2.029437723980155

Epoch: 5| Step: 3
Training loss: 2.0274806022644043
Validation loss: 2.048341765198656

Epoch: 5| Step: 4
Training loss: 2.380006790161133
Validation loss: 2.047929742003

Epoch: 5| Step: 5
Training loss: 2.2327895164489746
Validation loss: 2.0694234384003507

Epoch: 5| Step: 6
Training loss: 2.3618264198303223
Validation loss: 2.05930144299743

Epoch: 5| Step: 7
Training loss: 1.9272544384002686
Validation loss: 2.054684841504661

Epoch: 5| Step: 8
Training loss: 1.8444925546646118
Validation loss: 2.0628511418578444

Epoch: 5| Step: 9
Training loss: 1.8075145483016968
Validation loss: 2.0751932718420543

Epoch: 5| Step: 10
Training loss: 1.6461951732635498
Validation loss: 2.041861440545769

Epoch: 129| Step: 0
Training loss: 2.157585382461548
Validation loss: 2.049303206064368

Epoch: 5| Step: 1
Training loss: 1.908225655555725
Validation loss: 2.0453372463103263

Epoch: 5| Step: 2
Training loss: 2.05234432220459
Validation loss: 2.0456676201153825

Epoch: 5| Step: 3
Training loss: 2.290956974029541
Validation loss: 2.0673405816478114

Epoch: 5| Step: 4
Training loss: 1.788478136062622
Validation loss: 2.067323141200568

Epoch: 5| Step: 5
Training loss: 1.7862266302108765
Validation loss: 2.0499583828833794

Epoch: 5| Step: 6
Training loss: 2.12459135055542
Validation loss: 2.056015299212548

Epoch: 5| Step: 7
Training loss: 1.9502322673797607
Validation loss: 2.049778881893363

Epoch: 5| Step: 8
Training loss: 2.44287109375
Validation loss: 2.0626086419628513

Epoch: 5| Step: 9
Training loss: 2.3570613861083984
Validation loss: 2.0609143369941303

Epoch: 5| Step: 10
Training loss: 1.9522244930267334
Validation loss: 2.064317241791756

Epoch: 130| Step: 0
Training loss: 2.142029047012329
Validation loss: 2.0345742548665693

Epoch: 5| Step: 1
Training loss: 2.0608134269714355
Validation loss: 2.0491834943012526

Epoch: 5| Step: 2
Training loss: 2.3645143508911133
Validation loss: 2.0587754570027834

Epoch: 5| Step: 3
Training loss: 1.4977772235870361
Validation loss: 2.0559649928923576

Epoch: 5| Step: 4
Training loss: 1.4838167428970337
Validation loss: 2.044924323276807

Epoch: 5| Step: 5
Training loss: 2.2945492267608643
Validation loss: 2.062247658288607

Epoch: 5| Step: 6
Training loss: 2.3597493171691895
Validation loss: 2.0705668977511826

Epoch: 5| Step: 7
Training loss: 2.165006637573242
Validation loss: 2.0398335700394004

Epoch: 5| Step: 8
Training loss: 2.2993834018707275
Validation loss: 2.070684814965853

Epoch: 5| Step: 9
Training loss: 2.053658962249756
Validation loss: 2.0489578093251875

Epoch: 5| Step: 10
Training loss: 2.0696003437042236
Validation loss: 2.0585866512790805

Epoch: 131| Step: 0
Training loss: 1.8486568927764893
Validation loss: 2.0831607567366732

Epoch: 5| Step: 1
Training loss: 2.225446939468384
Validation loss: 2.074453851228119

Epoch: 5| Step: 2
Training loss: 1.6730759143829346
Validation loss: 2.0582745023953017

Epoch: 5| Step: 3
Training loss: 2.5654404163360596
Validation loss: 2.0673291298650924

Epoch: 5| Step: 4
Training loss: 1.6432859897613525
Validation loss: 2.0613922611359627

Epoch: 5| Step: 5
Training loss: 2.211515426635742
Validation loss: 2.0576934096633748

Epoch: 5| Step: 6
Training loss: 2.562073230743408
Validation loss: 2.0497007728904806

Epoch: 5| Step: 7
Training loss: 1.7442373037338257
Validation loss: 2.0642625554915397

Epoch: 5| Step: 8
Training loss: 2.5401012897491455
Validation loss: 2.0507963062614523

Epoch: 5| Step: 9
Training loss: 1.8792812824249268
Validation loss: 2.0590534479387346

Epoch: 5| Step: 10
Training loss: 1.7982829809188843
Validation loss: 2.0476089613412016

Epoch: 132| Step: 0
Training loss: 2.0233564376831055
Validation loss: 2.050931853632773

Epoch: 5| Step: 1
Training loss: 2.2176051139831543
Validation loss: 2.0590616246705413

Epoch: 5| Step: 2
Training loss: 2.2242698669433594
Validation loss: 2.0712999528454197

Epoch: 5| Step: 3
Training loss: 2.1134002208709717
Validation loss: 2.0515439177072174

Epoch: 5| Step: 4
Training loss: 1.8762414455413818
Validation loss: 2.0426702960844962

Epoch: 5| Step: 5
Training loss: 2.581890106201172
Validation loss: 2.063934820954518

Epoch: 5| Step: 6
Training loss: 1.9855139255523682
Validation loss: 2.03542431195577

Epoch: 5| Step: 7
Training loss: 1.6087077856063843
Validation loss: 2.034603540615369

Epoch: 5| Step: 8
Training loss: 2.1942191123962402
Validation loss: 2.0408600850771834

Epoch: 5| Step: 9
Training loss: 1.9209651947021484
Validation loss: 2.039836804072062

Epoch: 5| Step: 10
Training loss: 1.8751795291900635
Validation loss: 2.047155249503351

Epoch: 133| Step: 0
Training loss: 1.4645578861236572
Validation loss: 2.0707196958603395

Epoch: 5| Step: 1
Training loss: 2.7783427238464355
Validation loss: 2.0733699555038125

Epoch: 5| Step: 2
Training loss: 2.61307430267334
Validation loss: 2.0634029296136673

Epoch: 5| Step: 3
Training loss: 1.6430000066757202
Validation loss: 2.043910091923129

Epoch: 5| Step: 4
Training loss: 1.5984470844268799
Validation loss: 2.06530491511027

Epoch: 5| Step: 5
Training loss: 1.8275455236434937
Validation loss: 2.0576145238773798

Epoch: 5| Step: 6
Training loss: 1.6034517288208008
Validation loss: 2.0606964595856203

Epoch: 5| Step: 7
Training loss: 2.108185291290283
Validation loss: 2.054534835200156

Epoch: 5| Step: 8
Training loss: 2.5407485961914062
Validation loss: 2.0551279103884132

Epoch: 5| Step: 9
Training loss: 2.518359661102295
Validation loss: 2.0503980241796023

Epoch: 5| Step: 10
Training loss: 1.8567153215408325
Validation loss: 2.050688862800598

Epoch: 134| Step: 0
Training loss: 2.2763442993164062
Validation loss: 2.0594372313509703

Epoch: 5| Step: 1
Training loss: 3.073498487472534
Validation loss: 2.058364825863992

Epoch: 5| Step: 2
Training loss: 1.5568370819091797
Validation loss: 2.049643103794385

Epoch: 5| Step: 3
Training loss: 1.8086532354354858
Validation loss: 2.057052525140906

Epoch: 5| Step: 4
Training loss: 1.84201979637146
Validation loss: 2.0682318069601573

Epoch: 5| Step: 5
Training loss: 1.5256766080856323
Validation loss: 2.0560922789317306

Epoch: 5| Step: 6
Training loss: 1.8009382486343384
Validation loss: 2.0501452440856607

Epoch: 5| Step: 7
Training loss: 2.4541125297546387
Validation loss: 2.0695844568232054

Epoch: 5| Step: 8
Training loss: 1.7760041952133179
Validation loss: 2.0500703268153693

Epoch: 5| Step: 9
Training loss: 2.456833600997925
Validation loss: 2.0613850521784958

Epoch: 5| Step: 10
Training loss: 1.7507891654968262
Validation loss: 2.070531436192092

Epoch: 135| Step: 0
Training loss: 2.225583791732788
Validation loss: 2.044565595606322

Epoch: 5| Step: 1
Training loss: 2.163038730621338
Validation loss: 2.053724270994945

Epoch: 5| Step: 2
Training loss: 1.9495699405670166
Validation loss: 2.0631848471139067

Epoch: 5| Step: 3
Training loss: 1.8059762716293335
Validation loss: 2.0765037177711405

Epoch: 5| Step: 4
Training loss: 1.7523200511932373
Validation loss: 2.0456325225932623

Epoch: 5| Step: 5
Training loss: 1.8469451665878296
Validation loss: 2.0632027041527534

Epoch: 5| Step: 6
Training loss: 1.6448253393173218
Validation loss: 2.0510866257452194

Epoch: 5| Step: 7
Training loss: 2.053678274154663
Validation loss: 2.0287750972214567

Epoch: 5| Step: 8
Training loss: 2.847740650177002
Validation loss: 2.0664032864314255

Epoch: 5| Step: 9
Training loss: 2.1893150806427
Validation loss: 2.0552113748365834

Epoch: 5| Step: 10
Training loss: 2.0404152870178223
Validation loss: 2.04585777303224

Epoch: 136| Step: 0
Training loss: 2.476217269897461
Validation loss: 2.0442762682514806

Epoch: 5| Step: 1
Training loss: 2.4313483238220215
Validation loss: 2.044034416957568

Epoch: 5| Step: 2
Training loss: 2.664799213409424
Validation loss: 2.0569272861685803

Epoch: 5| Step: 3
Training loss: 1.7834465503692627
Validation loss: 2.0426666967330442

Epoch: 5| Step: 4
Training loss: 1.9879751205444336
Validation loss: 2.059719298475532

Epoch: 5| Step: 5
Training loss: 2.315791606903076
Validation loss: 2.042129571719836

Epoch: 5| Step: 6
Training loss: 1.5204401016235352
Validation loss: 2.0581056328230005

Epoch: 5| Step: 7
Training loss: 1.5393718481063843
Validation loss: 2.047868815801477

Epoch: 5| Step: 8
Training loss: 2.1132218837738037
Validation loss: 2.059947039491387

Epoch: 5| Step: 9
Training loss: 1.9719631671905518
Validation loss: 2.0591150791414323

Epoch: 5| Step: 10
Training loss: 1.6646108627319336
Validation loss: 2.0666904231553436

Epoch: 137| Step: 0
Training loss: 2.0294370651245117
Validation loss: 2.07599111013515

Epoch: 5| Step: 1
Training loss: 1.9770078659057617
Validation loss: 2.042317158432417

Epoch: 5| Step: 2
Training loss: 2.2269644737243652
Validation loss: 2.051623450812473

Epoch: 5| Step: 3
Training loss: 2.237881660461426
Validation loss: 2.0375289045354372

Epoch: 5| Step: 4
Training loss: 2.1284093856811523
Validation loss: 2.034497868630194

Epoch: 5| Step: 5
Training loss: 1.5199897289276123
Validation loss: 2.047267347253779

Epoch: 5| Step: 6
Training loss: 2.145554542541504
Validation loss: 2.040359015105873

Epoch: 5| Step: 7
Training loss: 2.515132427215576
Validation loss: 2.058677355448405

Epoch: 5| Step: 8
Training loss: 2.3228957653045654
Validation loss: 2.0377234925505934

Epoch: 5| Step: 9
Training loss: 1.7014862298965454
Validation loss: 2.030453707582207

Epoch: 5| Step: 10
Training loss: 1.618834376335144
Validation loss: 2.044855933035574

Epoch: 138| Step: 0
Training loss: 1.8996670246124268
Validation loss: 2.043728833557457

Epoch: 5| Step: 1
Training loss: 1.631983757019043
Validation loss: 2.0496182185347362

Epoch: 5| Step: 2
Training loss: 2.150022029876709
Validation loss: 2.037354237289839

Epoch: 5| Step: 3
Training loss: 2.078477621078491
Validation loss: 2.06587157710906

Epoch: 5| Step: 4
Training loss: 2.024312734603882
Validation loss: 2.0522697317984795

Epoch: 5| Step: 5
Training loss: 1.5806853771209717
Validation loss: 2.046890713835275

Epoch: 5| Step: 6
Training loss: 2.601966381072998
Validation loss: 2.0527783478460004

Epoch: 5| Step: 7
Training loss: 2.367741823196411
Validation loss: 2.075846022175204

Epoch: 5| Step: 8
Training loss: 1.9741789102554321
Validation loss: 2.0631335499466106

Epoch: 5| Step: 9
Training loss: 2.168250560760498
Validation loss: 2.0729342506777857

Epoch: 5| Step: 10
Training loss: 1.8945956230163574
Validation loss: 2.0819160604989655

Epoch: 139| Step: 0
Training loss: 2.084315538406372
Validation loss: 2.069351157834453

Epoch: 5| Step: 1
Training loss: 2.1822829246520996
Validation loss: 2.076070252285209

Epoch: 5| Step: 2
Training loss: 1.8432121276855469
Validation loss: 2.0589605992840183

Epoch: 5| Step: 3
Training loss: 2.058201313018799
Validation loss: 2.0643731804304224

Epoch: 5| Step: 4
Training loss: 2.089205503463745
Validation loss: 2.073034478772071

Epoch: 5| Step: 5
Training loss: 2.413693428039551
Validation loss: 2.0764311808411793

Epoch: 5| Step: 6
Training loss: 2.13006591796875
Validation loss: 2.0563606882608063

Epoch: 5| Step: 7
Training loss: 1.6511762142181396
Validation loss: 2.0587604789323706

Epoch: 5| Step: 8
Training loss: 2.2894959449768066
Validation loss: 2.051208813985189

Epoch: 5| Step: 9
Training loss: 2.049767017364502
Validation loss: 2.0449838997215353

Epoch: 5| Step: 10
Training loss: 1.4617308378219604
Validation loss: 2.051477637342227

Epoch: 140| Step: 0
Training loss: 2.647275924682617
Validation loss: 2.0622165100548857

Epoch: 5| Step: 1
Training loss: 1.5634839534759521
Validation loss: 2.0543764880908433

Epoch: 5| Step: 2
Training loss: 2.3811323642730713
Validation loss: 2.0534432652176067

Epoch: 5| Step: 3
Training loss: 1.8357810974121094
Validation loss: 2.068885794249914

Epoch: 5| Step: 4
Training loss: 2.360182285308838
Validation loss: 2.031768678337015

Epoch: 5| Step: 5
Training loss: 1.8235210180282593
Validation loss: 2.0635432722747966

Epoch: 5| Step: 6
Training loss: 1.3313627243041992
Validation loss: 2.0649012058011946

Epoch: 5| Step: 7
Training loss: 1.844050645828247
Validation loss: 2.0613854213427474

Epoch: 5| Step: 8
Training loss: 1.9220203161239624
Validation loss: 2.0490504400704497

Epoch: 5| Step: 9
Training loss: 2.1676087379455566
Validation loss: 2.051859358305572

Epoch: 5| Step: 10
Training loss: 2.6719815731048584
Validation loss: 2.0392442236664476

Epoch: 141| Step: 0
Training loss: 2.063570261001587
Validation loss: 2.0438688621726087

Epoch: 5| Step: 1
Training loss: 2.292823314666748
Validation loss: 2.043773279395155

Epoch: 5| Step: 2
Training loss: 2.0915870666503906
Validation loss: 2.060683609336935

Epoch: 5| Step: 3
Training loss: 2.332443952560425
Validation loss: 2.0418520307028167

Epoch: 5| Step: 4
Training loss: 2.163302183151245
Validation loss: 2.029368387755527

Epoch: 5| Step: 5
Training loss: 2.3644707202911377
Validation loss: 2.072068137507285

Epoch: 5| Step: 6
Training loss: 1.8727811574935913
Validation loss: 2.067482722702847

Epoch: 5| Step: 7
Training loss: 2.19653058052063
Validation loss: 2.0782888653457805

Epoch: 5| Step: 8
Training loss: 1.9821093082427979
Validation loss: 2.056939169924746

Epoch: 5| Step: 9
Training loss: 1.4566972255706787
Validation loss: 2.0560757960042646

Epoch: 5| Step: 10
Training loss: 1.4560155868530273
Validation loss: 2.061442853302084

Epoch: 142| Step: 0
Training loss: 2.02622652053833
Validation loss: 2.0560501954888784

Epoch: 5| Step: 1
Training loss: 2.551551580429077
Validation loss: 2.0832868545286116

Epoch: 5| Step: 2
Training loss: 1.8340438604354858
Validation loss: 2.0829113119391987

Epoch: 5| Step: 3
Training loss: 1.3348101377487183
Validation loss: 2.0391174208733345

Epoch: 5| Step: 4
Training loss: 1.4475014209747314
Validation loss: 2.0592318145177697

Epoch: 5| Step: 5
Training loss: 2.534785747528076
Validation loss: 2.071962861604588

Epoch: 5| Step: 6
Training loss: 2.8687756061553955
Validation loss: 2.064195586789039

Epoch: 5| Step: 7
Training loss: 2.377051591873169
Validation loss: 2.0342755061323925

Epoch: 5| Step: 8
Training loss: 2.019606113433838
Validation loss: 2.062072274505451

Epoch: 5| Step: 9
Training loss: 1.882524847984314
Validation loss: 2.040143962829344

Epoch: 5| Step: 10
Training loss: 1.6512560844421387
Validation loss: 2.0799207559195896

Epoch: 143| Step: 0
Training loss: 2.3026528358459473
Validation loss: 2.0537256809972946

Epoch: 5| Step: 1
Training loss: 2.1269919872283936
Validation loss: 2.0529882895049227

Epoch: 5| Step: 2
Training loss: 1.5992425680160522
Validation loss: 2.069177585263406

Epoch: 5| Step: 3
Training loss: 1.9886735677719116
Validation loss: 2.049618572317144

Epoch: 5| Step: 4
Training loss: 2.0417516231536865
Validation loss: 2.0498341539854645

Epoch: 5| Step: 5
Training loss: 1.4677813053131104
Validation loss: 2.015532524354996

Epoch: 5| Step: 6
Training loss: 1.7444069385528564
Validation loss: 2.0572508483804683

Epoch: 5| Step: 7
Training loss: 2.749462127685547
Validation loss: 2.068377261520714

Epoch: 5| Step: 8
Training loss: 2.524332284927368
Validation loss: 2.0639104996958086

Epoch: 5| Step: 9
Training loss: 1.908544898033142
Validation loss: 2.0614656350945912

Epoch: 5| Step: 10
Training loss: 1.9767465591430664
Validation loss: 2.0602029420996226

Epoch: 144| Step: 0
Training loss: 2.347916841506958
Validation loss: 2.040237348566773

Epoch: 5| Step: 1
Training loss: 2.4294724464416504
Validation loss: 2.065945057458775

Epoch: 5| Step: 2
Training loss: 1.783167839050293
Validation loss: 2.053325354412038

Epoch: 5| Step: 3
Training loss: 2.372786283493042
Validation loss: 2.045181543596329

Epoch: 5| Step: 4
Training loss: 2.6933608055114746
Validation loss: 2.0615947823370657

Epoch: 5| Step: 5
Training loss: 1.5704103708267212
Validation loss: 2.0299687359922673

Epoch: 5| Step: 6
Training loss: 1.8038508892059326
Validation loss: 2.039398880415065

Epoch: 5| Step: 7
Training loss: 1.8168808221817017
Validation loss: 2.031613688315115

Epoch: 5| Step: 8
Training loss: 2.2986834049224854
Validation loss: 2.0545641811945106

Epoch: 5| Step: 9
Training loss: 1.7961432933807373
Validation loss: 2.059145171155212

Epoch: 5| Step: 10
Training loss: 1.239333152770996
Validation loss: 2.026116890292014

Epoch: 145| Step: 0
Training loss: 2.3009655475616455
Validation loss: 2.0588568846384683

Epoch: 5| Step: 1
Training loss: 3.004026174545288
Validation loss: 2.0564174318826325

Epoch: 5| Step: 2
Training loss: 2.1359353065490723
Validation loss: 2.035336293200011

Epoch: 5| Step: 3
Training loss: 1.8920167684555054
Validation loss: 2.047684233675721

Epoch: 5| Step: 4
Training loss: 2.2606379985809326
Validation loss: 2.0604666612481557

Epoch: 5| Step: 5
Training loss: 1.9736669063568115
Validation loss: 2.044556217808877

Epoch: 5| Step: 6
Training loss: 1.6584928035736084
Validation loss: 2.020701157149448

Epoch: 5| Step: 7
Training loss: 1.2676225900650024
Validation loss: 2.03176688378857

Epoch: 5| Step: 8
Training loss: 2.2104783058166504
Validation loss: 2.0277547297939176

Epoch: 5| Step: 9
Training loss: 2.0506372451782227
Validation loss: 2.0760724723979993

Epoch: 5| Step: 10
Training loss: 1.3863857984542847
Validation loss: 2.01744322622976

Epoch: 146| Step: 0
Training loss: 2.159186601638794
Validation loss: 2.0584846337636313

Epoch: 5| Step: 1
Training loss: 1.7493507862091064
Validation loss: 2.0431807323168685

Epoch: 5| Step: 2
Training loss: 1.7114856243133545
Validation loss: 2.060994709691694

Epoch: 5| Step: 3
Training loss: 2.002305030822754
Validation loss: 2.0495706706918697

Epoch: 5| Step: 4
Training loss: 1.801717758178711
Validation loss: 2.0549094318061747

Epoch: 5| Step: 5
Training loss: 1.773565649986267
Validation loss: 2.049357214281636

Epoch: 5| Step: 6
Training loss: 2.6318061351776123
Validation loss: 2.0487786416084535

Epoch: 5| Step: 7
Training loss: 2.0513808727264404
Validation loss: 2.059990616254909

Epoch: 5| Step: 8
Training loss: 1.8684488534927368
Validation loss: 2.0515876047072874

Epoch: 5| Step: 9
Training loss: 2.262911319732666
Validation loss: 2.0335014968790035

Epoch: 5| Step: 10
Training loss: 2.1266028881073
Validation loss: 2.051839474708803

Epoch: 147| Step: 0
Training loss: 1.5787140130996704
Validation loss: 2.0566196057104293

Epoch: 5| Step: 1
Training loss: 1.5964024066925049
Validation loss: 2.0531288910937566

Epoch: 5| Step: 2
Training loss: 1.7095359563827515
Validation loss: 2.055736721202891

Epoch: 5| Step: 3
Training loss: 2.464576005935669
Validation loss: 2.0330680826658845

Epoch: 5| Step: 4
Training loss: 2.176715850830078
Validation loss: 2.0465923124744045

Epoch: 5| Step: 5
Training loss: 2.234278440475464
Validation loss: 2.0510072913221133

Epoch: 5| Step: 6
Training loss: 1.5465145111083984
Validation loss: 2.0292557285678003

Epoch: 5| Step: 7
Training loss: 1.828940749168396
Validation loss: 2.0448489137875137

Epoch: 5| Step: 8
Training loss: 1.8882131576538086
Validation loss: 2.0507922172546387

Epoch: 5| Step: 9
Training loss: 2.725637435913086
Validation loss: 2.037587069695996

Epoch: 5| Step: 10
Training loss: 2.482851982116699
Validation loss: 2.022310624840439

Epoch: 148| Step: 0
Training loss: 1.9682152271270752
Validation loss: 2.0551710308239026

Epoch: 5| Step: 1
Training loss: 2.173081636428833
Validation loss: 2.059410359269829

Epoch: 5| Step: 2
Training loss: 1.727870225906372
Validation loss: 2.0432534653653383

Epoch: 5| Step: 3
Training loss: 2.095977306365967
Validation loss: 2.060462009522223

Epoch: 5| Step: 4
Training loss: 0.9984356760978699
Validation loss: 2.038259329334382

Epoch: 5| Step: 5
Training loss: 2.596917152404785
Validation loss: 2.0399328226684244

Epoch: 5| Step: 6
Training loss: 2.2871999740600586
Validation loss: 2.0607893364403838

Epoch: 5| Step: 7
Training loss: 1.4225571155548096
Validation loss: 2.0452850941688783

Epoch: 5| Step: 8
Training loss: 2.1008353233337402
Validation loss: 2.01027980542952

Epoch: 5| Step: 9
Training loss: 2.0600171089172363
Validation loss: 2.031287980336015

Epoch: 5| Step: 10
Training loss: 2.6842386722564697
Validation loss: 2.063617842171782

Epoch: 149| Step: 0
Training loss: 2.4172754287719727
Validation loss: 2.0561055944811915

Epoch: 5| Step: 1
Training loss: 1.555086374282837
Validation loss: 2.0307085590977825

Epoch: 5| Step: 2
Training loss: 2.647545576095581
Validation loss: 2.0658997361378004

Epoch: 5| Step: 3
Training loss: 1.7657737731933594
Validation loss: 2.035618273160791

Epoch: 5| Step: 4
Training loss: 2.019956111907959
Validation loss: 2.0104636902450235

Epoch: 5| Step: 5
Training loss: 1.772531509399414
Validation loss: 2.0637041830247447

Epoch: 5| Step: 6
Training loss: 2.0785717964172363
Validation loss: 2.019756394047891

Epoch: 5| Step: 7
Training loss: 1.5712625980377197
Validation loss: 2.04490585993695

Epoch: 5| Step: 8
Training loss: 1.9906269311904907
Validation loss: 2.0526157245841077

Epoch: 5| Step: 9
Training loss: 2.6283059120178223
Validation loss: 2.0404186197506484

Epoch: 5| Step: 10
Training loss: 1.5609471797943115
Validation loss: 2.032031689920733

Epoch: 150| Step: 0
Training loss: 1.4465080499649048
Validation loss: 2.067616073034143

Epoch: 5| Step: 1
Training loss: 1.5483640432357788
Validation loss: 2.050778033912823

Epoch: 5| Step: 2
Training loss: 2.236489772796631
Validation loss: 2.0584790552816083

Epoch: 5| Step: 3
Training loss: 2.0819783210754395
Validation loss: 2.0193935414796234

Epoch: 5| Step: 4
Training loss: 2.1904969215393066
Validation loss: 2.0475236420990317

Epoch: 5| Step: 5
Training loss: 2.6208558082580566
Validation loss: 2.0463427856404293

Epoch: 5| Step: 6
Training loss: 2.285492420196533
Validation loss: 2.0123992978885608

Epoch: 5| Step: 7
Training loss: 2.0790507793426514
Validation loss: 2.048379482761506

Epoch: 5| Step: 8
Training loss: 1.6206767559051514
Validation loss: 2.030498976348549

Epoch: 5| Step: 9
Training loss: 1.7975116968154907
Validation loss: 2.0783594936452885

Epoch: 5| Step: 10
Training loss: 2.208228588104248
Validation loss: 2.0320313566474506

Epoch: 151| Step: 0
Training loss: 2.0405449867248535
Validation loss: 2.051228428399691

Epoch: 5| Step: 1
Training loss: 2.7148499488830566
Validation loss: 2.016152012732721

Epoch: 5| Step: 2
Training loss: 1.562330961227417
Validation loss: 2.052998096712174

Epoch: 5| Step: 3
Training loss: 2.0323245525360107
Validation loss: 2.0318583083409134

Epoch: 5| Step: 4
Training loss: 1.7882858514785767
Validation loss: 2.0284097899672804

Epoch: 5| Step: 5
Training loss: 1.792196273803711
Validation loss: 2.0406990333270003

Epoch: 5| Step: 6
Training loss: 1.8583444356918335
Validation loss: 2.022224695451798

Epoch: 5| Step: 7
Training loss: 2.140575885772705
Validation loss: 2.048992165955164

Epoch: 5| Step: 8
Training loss: 2.7515714168548584
Validation loss: 2.042864917426981

Epoch: 5| Step: 9
Training loss: 1.9017051458358765
Validation loss: 2.003594163925417

Epoch: 5| Step: 10
Training loss: 1.296372652053833
Validation loss: 2.0220009126970844

Epoch: 152| Step: 0
Training loss: 2.3590750694274902
Validation loss: 2.0278671005720734

Epoch: 5| Step: 1
Training loss: 1.7047847509384155
Validation loss: 2.038483460744222

Epoch: 5| Step: 2
Training loss: 2.3716795444488525
Validation loss: 2.046008361283169

Epoch: 5| Step: 3
Training loss: 1.7725553512573242
Validation loss: 2.0229803836473854

Epoch: 5| Step: 4
Training loss: 1.063579797744751
Validation loss: 2.016898875595421

Epoch: 5| Step: 5
Training loss: 2.0982017517089844
Validation loss: 2.0520808889019873

Epoch: 5| Step: 6
Training loss: 2.4512524604797363
Validation loss: 2.0377255896086335

Epoch: 5| Step: 7
Training loss: 2.040128469467163
Validation loss: 2.043937620296273

Epoch: 5| Step: 8
Training loss: 2.254004955291748
Validation loss: 2.0512574052297943

Epoch: 5| Step: 9
Training loss: 1.7919889688491821
Validation loss: 2.0560407792368243

Epoch: 5| Step: 10
Training loss: 2.24843430519104
Validation loss: 2.0300921547797417

Epoch: 153| Step: 0
Training loss: 2.3502731323242188
Validation loss: 2.0544587155824066

Epoch: 5| Step: 1
Training loss: 2.1739304065704346
Validation loss: 2.0487241091266757

Epoch: 5| Step: 2
Training loss: 1.7085880041122437
Validation loss: 2.041206404726992

Epoch: 5| Step: 3
Training loss: 1.9294980764389038
Validation loss: 2.051718314488729

Epoch: 5| Step: 4
Training loss: 1.8595173358917236
Validation loss: 2.046435333067371

Epoch: 5| Step: 5
Training loss: 2.08701229095459
Validation loss: 2.059105557780112

Epoch: 5| Step: 6
Training loss: 1.8065458536148071
Validation loss: 2.0479544375532415

Epoch: 5| Step: 7
Training loss: 2.1835169792175293
Validation loss: 2.0591471067038913

Epoch: 5| Step: 8
Training loss: 2.197521209716797
Validation loss: 2.0329893353164836

Epoch: 5| Step: 9
Training loss: 1.8616230487823486
Validation loss: 2.0421921847968973

Epoch: 5| Step: 10
Training loss: 1.6378573179244995
Validation loss: 2.0564811357887844

Epoch: 154| Step: 0
Training loss: 1.133130669593811
Validation loss: 2.0759422509900984

Epoch: 5| Step: 1
Training loss: 1.7545467615127563
Validation loss: 2.024749578968171

Epoch: 5| Step: 2
Training loss: 2.012333631515503
Validation loss: 2.0547160384475545

Epoch: 5| Step: 3
Training loss: 2.1340625286102295
Validation loss: 2.044423923697523

Epoch: 5| Step: 4
Training loss: 2.051199197769165
Validation loss: 2.030990921041017

Epoch: 5| Step: 5
Training loss: 2.134639024734497
Validation loss: 2.054257292901316

Epoch: 5| Step: 6
Training loss: 1.7494661808013916
Validation loss: 2.043387466861356

Epoch: 5| Step: 7
Training loss: 2.352355718612671
Validation loss: 2.029621834396034

Epoch: 5| Step: 8
Training loss: 2.27689790725708
Validation loss: 2.0487913995660763

Epoch: 5| Step: 9
Training loss: 1.89303719997406
Validation loss: 2.0339212802148636

Epoch: 5| Step: 10
Training loss: 2.425004005432129
Validation loss: 2.032764903960689

Epoch: 155| Step: 0
Training loss: 1.9482399225234985
Validation loss: 2.0322317487450055

Epoch: 5| Step: 1
Training loss: 1.8928028345108032
Validation loss: 2.0217446986065117

Epoch: 5| Step: 2
Training loss: 1.7238075733184814
Validation loss: 2.018329446033765

Epoch: 5| Step: 3
Training loss: 2.0088725090026855
Validation loss: 2.0455900417861117

Epoch: 5| Step: 4
Training loss: 1.395005464553833
Validation loss: 2.0458794152864845

Epoch: 5| Step: 5
Training loss: 2.740173816680908
Validation loss: 2.051282590435397

Epoch: 5| Step: 6
Training loss: 2.639103651046753
Validation loss: 2.033804411529213

Epoch: 5| Step: 7
Training loss: 1.5830661058425903
Validation loss: 2.043367769128533

Epoch: 5| Step: 8
Training loss: 1.7083619832992554
Validation loss: 2.050888890861183

Epoch: 5| Step: 9
Training loss: 2.1781370639801025
Validation loss: 2.0416874295921734

Epoch: 5| Step: 10
Training loss: 1.9710339307785034
Validation loss: 2.024517020871562

Epoch: 156| Step: 0
Training loss: 2.0556788444519043
Validation loss: 2.060485978280344

Epoch: 5| Step: 1
Training loss: 1.3417401313781738
Validation loss: 2.0305293824083064

Epoch: 5| Step: 2
Training loss: 1.6978057622909546
Validation loss: 2.018830987714952

Epoch: 5| Step: 3
Training loss: 2.549773931503296
Validation loss: 2.0356814169114634

Epoch: 5| Step: 4
Training loss: 1.4425617456436157
Validation loss: 2.0427979448790192

Epoch: 5| Step: 5
Training loss: 2.161923885345459
Validation loss: 2.0220249570826048

Epoch: 5| Step: 6
Training loss: 2.199282646179199
Validation loss: 2.0447658492672827

Epoch: 5| Step: 7
Training loss: 1.8669919967651367
Validation loss: 2.037001230383432

Epoch: 5| Step: 8
Training loss: 2.1891746520996094
Validation loss: 2.0307468701434392

Epoch: 5| Step: 9
Training loss: 2.4067282676696777
Validation loss: 2.0265905344358055

Epoch: 5| Step: 10
Training loss: 1.919916033744812
Validation loss: 2.002860507657451

Epoch: 157| Step: 0
Training loss: 1.9600341320037842
Validation loss: 2.037302904231574

Epoch: 5| Step: 1
Training loss: 1.838611364364624
Validation loss: 2.0372024505369124

Epoch: 5| Step: 2
Training loss: 1.5882415771484375
Validation loss: 2.055673696661508

Epoch: 5| Step: 3
Training loss: 1.5215733051300049
Validation loss: 2.0211361979925506

Epoch: 5| Step: 4
Training loss: 2.316521167755127
Validation loss: 2.021662853097403

Epoch: 5| Step: 5
Training loss: 1.8309032917022705
Validation loss: 2.0255809214807328

Epoch: 5| Step: 6
Training loss: 1.9021583795547485
Validation loss: 2.007055446665774

Epoch: 5| Step: 7
Training loss: 2.658013105392456
Validation loss: 2.0412359276125507

Epoch: 5| Step: 8
Training loss: 2.2150776386260986
Validation loss: 2.0240097917536253

Epoch: 5| Step: 9
Training loss: 1.9282019138336182
Validation loss: 2.003157441334058

Epoch: 5| Step: 10
Training loss: 1.9957590103149414
Validation loss: 2.0335238505435247

Epoch: 158| Step: 0
Training loss: 2.4252512454986572
Validation loss: 2.045066331022529

Epoch: 5| Step: 1
Training loss: 1.8743873834609985
Validation loss: 2.040764542036159

Epoch: 5| Step: 2
Training loss: 1.9058936834335327
Validation loss: 2.021905315819607

Epoch: 5| Step: 3
Training loss: 1.8396419286727905
Validation loss: 2.040051434629707

Epoch: 5| Step: 4
Training loss: 2.2192788124084473
Validation loss: 2.0273555017286733

Epoch: 5| Step: 5
Training loss: 1.8668384552001953
Validation loss: 2.0132821477869505

Epoch: 5| Step: 6
Training loss: 1.9995378255844116
Validation loss: 2.009972705635973

Epoch: 5| Step: 7
Training loss: 1.839238166809082
Validation loss: 2.031462933427544

Epoch: 5| Step: 8
Training loss: 2.004594087600708
Validation loss: 2.068926880436559

Epoch: 5| Step: 9
Training loss: 1.6374940872192383
Validation loss: 2.0238444036053074

Epoch: 5| Step: 10
Training loss: 2.180215358734131
Validation loss: 2.0344907417092273

Epoch: 159| Step: 0
Training loss: 2.123553514480591
Validation loss: 2.016360036788448

Epoch: 5| Step: 1
Training loss: 2.274219036102295
Validation loss: 2.01678039181617

Epoch: 5| Step: 2
Training loss: 1.7314939498901367
Validation loss: 2.035166081561837

Epoch: 5| Step: 3
Training loss: 2.105156421661377
Validation loss: 2.0370882788012104

Epoch: 5| Step: 4
Training loss: 2.2173242568969727
Validation loss: 2.0259146536550214

Epoch: 5| Step: 5
Training loss: 2.1669249534606934
Validation loss: 2.0040563280864427

Epoch: 5| Step: 6
Training loss: 2.0011754035949707
Validation loss: 2.0266890782181934

Epoch: 5| Step: 7
Training loss: 2.1930224895477295
Validation loss: 2.0397794528674056

Epoch: 5| Step: 8
Training loss: 2.5064773559570312
Validation loss: 2.039388951434884

Epoch: 5| Step: 9
Training loss: 0.7208293080329895
Validation loss: 2.0220994680158553

Epoch: 5| Step: 10
Training loss: 1.6504896879196167
Validation loss: 2.013328775282829

Epoch: 160| Step: 0
Training loss: 2.3677098751068115
Validation loss: 2.016111268792101

Epoch: 5| Step: 1
Training loss: 2.030972957611084
Validation loss: 2.0244135728446384

Epoch: 5| Step: 2
Training loss: 1.991103172302246
Validation loss: 2.0304545548654374

Epoch: 5| Step: 3
Training loss: 1.562647819519043
Validation loss: 2.0269733526373424

Epoch: 5| Step: 4
Training loss: 2.7613322734832764
Validation loss: 2.0365951099703388

Epoch: 5| Step: 5
Training loss: 1.9223054647445679
Validation loss: 2.048108544400943

Epoch: 5| Step: 6
Training loss: 1.7961244583129883
Validation loss: 2.046515855737912

Epoch: 5| Step: 7
Training loss: 2.343140125274658
Validation loss: 2.0319013159762145

Epoch: 5| Step: 8
Training loss: 1.0786316394805908
Validation loss: 2.05957007023596

Epoch: 5| Step: 9
Training loss: 2.175128221511841
Validation loss: 2.023263362146193

Epoch: 5| Step: 10
Training loss: 1.64016854763031
Validation loss: 2.0620063889411187

Epoch: 161| Step: 0
Training loss: 2.2196779251098633
Validation loss: 2.0178100729501374

Epoch: 5| Step: 1
Training loss: 1.762290358543396
Validation loss: 2.0364695941248248

Epoch: 5| Step: 2
Training loss: 1.987627387046814
Validation loss: 2.0464087352957776

Epoch: 5| Step: 3
Training loss: 2.068321704864502
Validation loss: 2.0411430110213575

Epoch: 5| Step: 4
Training loss: 1.3888626098632812
Validation loss: 2.0544020488697994

Epoch: 5| Step: 5
Training loss: 2.3468668460845947
Validation loss: 2.0338965141645042

Epoch: 5| Step: 6
Training loss: 1.4147086143493652
Validation loss: 2.0177600499122375

Epoch: 5| Step: 7
Training loss: 2.2504050731658936
Validation loss: 2.0402631234097224

Epoch: 5| Step: 8
Training loss: 2.028419017791748
Validation loss: 1.9968680720175467

Epoch: 5| Step: 9
Training loss: 1.8944618701934814
Validation loss: 2.0367675237758185

Epoch: 5| Step: 10
Training loss: 2.37880802154541
Validation loss: 2.0180574245350336

Epoch: 162| Step: 0
Training loss: 1.8488537073135376
Validation loss: 2.0143464047421693

Epoch: 5| Step: 1
Training loss: 1.3345553874969482
Validation loss: 2.0254437692703737

Epoch: 5| Step: 2
Training loss: 2.303530216217041
Validation loss: 2.0056077587989067

Epoch: 5| Step: 3
Training loss: 2.1184072494506836
Validation loss: 2.041248584306368

Epoch: 5| Step: 4
Training loss: 2.198617458343506
Validation loss: 2.0012368861065117

Epoch: 5| Step: 5
Training loss: 3.1669435501098633
Validation loss: 2.017087185254661

Epoch: 5| Step: 6
Training loss: 1.6553313732147217
Validation loss: 2.0284458821819675

Epoch: 5| Step: 7
Training loss: 1.717821717262268
Validation loss: 2.0021088584776847

Epoch: 5| Step: 8
Training loss: 1.9350868463516235
Validation loss: 2.0351264322957685

Epoch: 5| Step: 9
Training loss: 1.6688601970672607
Validation loss: 2.0227108642619145

Epoch: 5| Step: 10
Training loss: 1.4668526649475098
Validation loss: 2.028317548895395

Epoch: 163| Step: 0
Training loss: 1.246801733970642
Validation loss: 2.028749588997133

Epoch: 5| Step: 1
Training loss: 1.5122253894805908
Validation loss: 2.02969329972421

Epoch: 5| Step: 2
Training loss: 2.301703929901123
Validation loss: 2.0405885429792505

Epoch: 5| Step: 3
Training loss: 1.9949111938476562
Validation loss: 2.00700060782894

Epoch: 5| Step: 4
Training loss: 2.5706844329833984
Validation loss: 2.006725339479344

Epoch: 5| Step: 5
Training loss: 2.5627048015594482
Validation loss: 2.0191462783403296

Epoch: 5| Step: 6
Training loss: 2.038931369781494
Validation loss: 2.011952507880426

Epoch: 5| Step: 7
Training loss: 1.7619348764419556
Validation loss: 2.028680573227585

Epoch: 5| Step: 8
Training loss: 1.55721116065979
Validation loss: 2.0167991115200903

Epoch: 5| Step: 9
Training loss: 2.345970630645752
Validation loss: 2.0193593155953193

Epoch: 5| Step: 10
Training loss: 1.6292388439178467
Validation loss: 2.000645201693299

Epoch: 164| Step: 0
Training loss: 1.9942872524261475
Validation loss: 1.9794124762217205

Epoch: 5| Step: 1
Training loss: 1.7997545003890991
Validation loss: 2.0305630571098736

Epoch: 5| Step: 2
Training loss: 1.2606016397476196
Validation loss: 2.0195845916707027

Epoch: 5| Step: 3
Training loss: 2.197375774383545
Validation loss: 2.0085970227436354

Epoch: 5| Step: 4
Training loss: 1.6573512554168701
Validation loss: 2.032601064251315

Epoch: 5| Step: 5
Training loss: 2.4243052005767822
Validation loss: 2.0277827503860637

Epoch: 5| Step: 6
Training loss: 2.2574455738067627
Validation loss: 2.060282499559464

Epoch: 5| Step: 7
Training loss: 1.9629666805267334
Validation loss: 2.021850928183525

Epoch: 5| Step: 8
Training loss: 2.2682929039001465
Validation loss: 2.032339508815478

Epoch: 5| Step: 9
Training loss: 1.9647538661956787
Validation loss: 2.025717435344573

Epoch: 5| Step: 10
Training loss: 1.6834107637405396
Validation loss: 2.0406886441733247

Epoch: 165| Step: 0
Training loss: 2.474438190460205
Validation loss: 2.0430422124042305

Epoch: 5| Step: 1
Training loss: 1.8953897953033447
Validation loss: 2.0375778264896844

Epoch: 5| Step: 2
Training loss: 1.8912498950958252
Validation loss: 2.02734274248923

Epoch: 5| Step: 3
Training loss: 1.6346790790557861
Validation loss: 2.0250559647878013

Epoch: 5| Step: 4
Training loss: 1.2078521251678467
Validation loss: 2.044703096471807

Epoch: 5| Step: 5
Training loss: 1.7129045724868774
Validation loss: 2.038256391402214

Epoch: 5| Step: 6
Training loss: 2.5472073554992676
Validation loss: 2.0179800794970606

Epoch: 5| Step: 7
Training loss: 1.6294845342636108
Validation loss: 2.0266657926703013

Epoch: 5| Step: 8
Training loss: 1.7573459148406982
Validation loss: 2.003411736539615

Epoch: 5| Step: 9
Training loss: 2.675013303756714
Validation loss: 2.02150244738466

Epoch: 5| Step: 10
Training loss: 1.9773213863372803
Validation loss: 2.0053894173714424

Epoch: 166| Step: 0
Training loss: 1.5248503684997559
Validation loss: 2.000345186520648

Epoch: 5| Step: 1
Training loss: 2.0308470726013184
Validation loss: 2.0068217451854418

Epoch: 5| Step: 2
Training loss: 2.07250714302063
Validation loss: 2.0027923737802813

Epoch: 5| Step: 3
Training loss: 1.8113113641738892
Validation loss: 1.9961791858878186

Epoch: 5| Step: 4
Training loss: 2.081442356109619
Validation loss: 2.042930139008389

Epoch: 5| Step: 5
Training loss: 2.0512211322784424
Validation loss: 1.992963226892615

Epoch: 5| Step: 6
Training loss: 2.3017330169677734
Validation loss: 2.0046621086776897

Epoch: 5| Step: 7
Training loss: 2.146467924118042
Validation loss: 2.0145047787697083

Epoch: 5| Step: 8
Training loss: 1.9053910970687866
Validation loss: 2.0197670831475207

Epoch: 5| Step: 9
Training loss: 2.0282654762268066
Validation loss: 2.036973158518473

Epoch: 5| Step: 10
Training loss: 1.3563224077224731
Validation loss: 1.9993398304908507

Epoch: 167| Step: 0
Training loss: 1.952705979347229
Validation loss: 1.9796475518134333

Epoch: 5| Step: 1
Training loss: 1.2558951377868652
Validation loss: 1.9956443950694094

Epoch: 5| Step: 2
Training loss: 2.063514232635498
Validation loss: 2.0460986321972263

Epoch: 5| Step: 3
Training loss: 1.6409680843353271
Validation loss: 2.0400041739145913

Epoch: 5| Step: 4
Training loss: 2.3595898151397705
Validation loss: 2.005322537114543

Epoch: 5| Step: 5
Training loss: 1.6423065662384033
Validation loss: 2.0151081969661098

Epoch: 5| Step: 6
Training loss: 2.1908178329467773
Validation loss: 2.0093148011033253

Epoch: 5| Step: 7
Training loss: 1.85211181640625
Validation loss: 2.014016238592004

Epoch: 5| Step: 8
Training loss: 2.528792142868042
Validation loss: 2.0202870830412833

Epoch: 5| Step: 9
Training loss: 2.442927598953247
Validation loss: 2.0059666133696035

Epoch: 5| Step: 10
Training loss: 1.3294988870620728
Validation loss: 2.019812164768096

Epoch: 168| Step: 0
Training loss: 1.8982950448989868
Validation loss: 2.0231505068399573

Epoch: 5| Step: 1
Training loss: 1.7929275035858154
Validation loss: 1.9951970449057959

Epoch: 5| Step: 2
Training loss: 1.7891651391983032
Validation loss: 2.0137699893725816

Epoch: 5| Step: 3
Training loss: 1.6907424926757812
Validation loss: 1.999067138600093

Epoch: 5| Step: 4
Training loss: 2.1373159885406494
Validation loss: 2.007000013064313

Epoch: 5| Step: 5
Training loss: 2.095982074737549
Validation loss: 2.0032806306756954

Epoch: 5| Step: 6
Training loss: 2.7531538009643555
Validation loss: 2.0000993231291413

Epoch: 5| Step: 7
Training loss: 1.7632296085357666
Validation loss: 2.01826431674342

Epoch: 5| Step: 8
Training loss: 1.8134667873382568
Validation loss: 1.9823137790926042

Epoch: 5| Step: 9
Training loss: 1.8593482971191406
Validation loss: 2.0054946830195766

Epoch: 5| Step: 10
Training loss: 1.6437757015228271
Validation loss: 2.0309379613527687

Epoch: 169| Step: 0
Training loss: 2.080899953842163
Validation loss: 2.004889980439217

Epoch: 5| Step: 1
Training loss: 2.129363536834717
Validation loss: 2.0160039112132084

Epoch: 5| Step: 2
Training loss: 1.61179518699646
Validation loss: 2.015285672680024

Epoch: 5| Step: 3
Training loss: 1.3299098014831543
Validation loss: 2.0008736156648204

Epoch: 5| Step: 4
Training loss: 2.177906036376953
Validation loss: 2.0070315663532545

Epoch: 5| Step: 5
Training loss: 1.2528358697891235
Validation loss: 2.02081960503773

Epoch: 5| Step: 6
Training loss: 2.2547802925109863
Validation loss: 2.0469031603105607

Epoch: 5| Step: 7
Training loss: 2.0897629261016846
Validation loss: 2.022737403069773

Epoch: 5| Step: 8
Training loss: 2.465585231781006
Validation loss: 2.012966227787797

Epoch: 5| Step: 9
Training loss: 1.7539803981781006
Validation loss: 2.0135570405631937

Epoch: 5| Step: 10
Training loss: 2.167015314102173
Validation loss: 2.016173724205263

Epoch: 170| Step: 0
Training loss: 1.7415153980255127
Validation loss: 2.0056439086955082

Epoch: 5| Step: 1
Training loss: 2.1763546466827393
Validation loss: 2.029715903343693

Epoch: 5| Step: 2
Training loss: 2.249396324157715
Validation loss: 2.0236900301389795

Epoch: 5| Step: 3
Training loss: 2.28261137008667
Validation loss: 1.969747071625084

Epoch: 5| Step: 4
Training loss: 1.376875638961792
Validation loss: 2.0138951937357583

Epoch: 5| Step: 5
Training loss: 2.1484413146972656
Validation loss: 2.016315970369565

Epoch: 5| Step: 6
Training loss: 1.7265348434448242
Validation loss: 1.9958559261855258

Epoch: 5| Step: 7
Training loss: 1.7473258972167969
Validation loss: 2.0056333452142696

Epoch: 5| Step: 8
Training loss: 1.6186304092407227
Validation loss: 2.000179970136253

Epoch: 5| Step: 9
Training loss: 2.3354313373565674
Validation loss: 2.004966879403719

Epoch: 5| Step: 10
Training loss: 1.6979621648788452
Validation loss: 2.0180249444900022

Epoch: 171| Step: 0
Training loss: 1.7251430749893188
Validation loss: 1.968383494243827

Epoch: 5| Step: 1
Training loss: 1.54056715965271
Validation loss: 2.0209910818325576

Epoch: 5| Step: 2
Training loss: 1.9728978872299194
Validation loss: 1.983355801592591

Epoch: 5| Step: 3
Training loss: 2.0244674682617188
Validation loss: 2.000030686778407

Epoch: 5| Step: 4
Training loss: 1.8875175714492798
Validation loss: 2.00249747819798

Epoch: 5| Step: 5
Training loss: 2.3201394081115723
Validation loss: 2.0090928846789944

Epoch: 5| Step: 6
Training loss: 2.007723808288574
Validation loss: 1.9811587782316311

Epoch: 5| Step: 7
Training loss: 1.624316930770874
Validation loss: 1.9939277248997842

Epoch: 5| Step: 8
Training loss: 1.7927042245864868
Validation loss: 1.9953572404000066

Epoch: 5| Step: 9
Training loss: 2.351947784423828
Validation loss: 2.020463543553506

Epoch: 5| Step: 10
Training loss: 1.8185871839523315
Validation loss: 2.00563560506349

Epoch: 172| Step: 0
Training loss: 2.1451826095581055
Validation loss: 2.0219128747140207

Epoch: 5| Step: 1
Training loss: 2.4675850868225098
Validation loss: 2.035970000810521

Epoch: 5| Step: 2
Training loss: 1.55198073387146
Validation loss: 2.0463698910128687

Epoch: 5| Step: 3
Training loss: 1.538886308670044
Validation loss: 1.9961697183629519

Epoch: 5| Step: 4
Training loss: 1.9138495922088623
Validation loss: 2.0013701749104325

Epoch: 5| Step: 5
Training loss: 1.9827629327774048
Validation loss: 2.001463402983963

Epoch: 5| Step: 6
Training loss: 1.3577523231506348
Validation loss: 1.9997888944482292

Epoch: 5| Step: 7
Training loss: 2.6247785091400146
Validation loss: 2.017468188398628

Epoch: 5| Step: 8
Training loss: 1.6287628412246704
Validation loss: 1.9864778800677227

Epoch: 5| Step: 9
Training loss: 1.520260214805603
Validation loss: 2.002174304377648

Epoch: 5| Step: 10
Training loss: 2.619020938873291
Validation loss: 2.014323310185504

Epoch: 173| Step: 0
Training loss: 1.9988775253295898
Validation loss: 1.9880670770522086

Epoch: 5| Step: 1
Training loss: 1.6346728801727295
Validation loss: 1.9642251140327864

Epoch: 5| Step: 2
Training loss: 1.9889049530029297
Validation loss: 2.020219364473897

Epoch: 5| Step: 3
Training loss: 1.217699646949768
Validation loss: 2.0059778933883994

Epoch: 5| Step: 4
Training loss: 1.7196086645126343
Validation loss: 2.010647666069769

Epoch: 5| Step: 5
Training loss: 2.6096699237823486
Validation loss: 2.0384418502930672

Epoch: 5| Step: 6
Training loss: 2.164433717727661
Validation loss: 2.029417924983527

Epoch: 5| Step: 7
Training loss: 1.4916918277740479
Validation loss: 2.0058431804821057

Epoch: 5| Step: 8
Training loss: 2.5201478004455566
Validation loss: 1.9847252650927472

Epoch: 5| Step: 9
Training loss: 1.8200550079345703
Validation loss: 2.0260908219122116

Epoch: 5| Step: 10
Training loss: 2.152921676635742
Validation loss: 1.993647022913861

Epoch: 174| Step: 0
Training loss: 2.4047322273254395
Validation loss: 2.023923594464538

Epoch: 5| Step: 1
Training loss: 1.438899040222168
Validation loss: 1.9941222385693622

Epoch: 5| Step: 2
Training loss: 1.6516392230987549
Validation loss: 1.985717119709138

Epoch: 5| Step: 3
Training loss: 1.5745179653167725
Validation loss: 2.032448512251659

Epoch: 5| Step: 4
Training loss: 2.3233115673065186
Validation loss: 2.015590529288015

Epoch: 5| Step: 5
Training loss: 2.0755443572998047
Validation loss: 2.023088373163695

Epoch: 5| Step: 6
Training loss: 1.7048728466033936
Validation loss: 1.9834482951830792

Epoch: 5| Step: 7
Training loss: 1.6392322778701782
Validation loss: 2.01506410619264

Epoch: 5| Step: 8
Training loss: 2.3346869945526123
Validation loss: 1.9977900315356512

Epoch: 5| Step: 9
Training loss: 1.9336252212524414
Validation loss: 2.000655097346152

Epoch: 5| Step: 10
Training loss: 1.8588972091674805
Validation loss: 1.9966007509539205

Epoch: 175| Step: 0
Training loss: 1.5434709787368774
Validation loss: 2.029386667795079

Epoch: 5| Step: 1
Training loss: 1.8747262954711914
Validation loss: 1.9885086039061188

Epoch: 5| Step: 2
Training loss: 2.027202606201172
Validation loss: 2.000125044135637

Epoch: 5| Step: 3
Training loss: 2.1293463706970215
Validation loss: 1.9864770673936414

Epoch: 5| Step: 4
Training loss: 2.451810359954834
Validation loss: 1.992616961079259

Epoch: 5| Step: 5
Training loss: 1.633178472518921
Validation loss: 2.0096807787495274

Epoch: 5| Step: 6
Training loss: 1.9257543087005615
Validation loss: 1.9867523075431905

Epoch: 5| Step: 7
Training loss: 1.8253265619277954
Validation loss: 1.9799146562494256

Epoch: 5| Step: 8
Training loss: 1.66067373752594
Validation loss: 2.0102482431678363

Epoch: 5| Step: 9
Training loss: 1.7363487482070923
Validation loss: 2.0159319985297417

Epoch: 5| Step: 10
Training loss: 2.2801194190979004
Validation loss: 1.984131609239886

Epoch: 176| Step: 0
Training loss: 2.0770742893218994
Validation loss: 2.0033085077039656

Epoch: 5| Step: 1
Training loss: 2.179438591003418
Validation loss: 1.9958321881550614

Epoch: 5| Step: 2
Training loss: 2.2308239936828613
Validation loss: 1.9850983312053065

Epoch: 5| Step: 3
Training loss: 1.671212911605835
Validation loss: 2.008202924523302

Epoch: 5| Step: 4
Training loss: 2.3432469367980957
Validation loss: 1.9555557030503468

Epoch: 5| Step: 5
Training loss: 1.418433427810669
Validation loss: 1.9636705101177256

Epoch: 5| Step: 6
Training loss: 2.260920286178589
Validation loss: 1.9865650553857126

Epoch: 5| Step: 7
Training loss: 1.7895572185516357
Validation loss: 1.9857997689195859

Epoch: 5| Step: 8
Training loss: 1.7950313091278076
Validation loss: 1.982465435099858

Epoch: 5| Step: 9
Training loss: 1.9408252239227295
Validation loss: 2.0101571877797446

Epoch: 5| Step: 10
Training loss: 1.1557105779647827
Validation loss: 2.009042716795398

Epoch: 177| Step: 0
Training loss: 2.208643913269043
Validation loss: 2.0019356409708657

Epoch: 5| Step: 1
Training loss: 1.7114986181259155
Validation loss: 1.997526607205791

Epoch: 5| Step: 2
Training loss: 1.8127349615097046
Validation loss: 2.02043237481066

Epoch: 5| Step: 3
Training loss: 1.698036551475525
Validation loss: 2.012600588542159

Epoch: 5| Step: 4
Training loss: 1.6085236072540283
Validation loss: 2.0193862761220625

Epoch: 5| Step: 5
Training loss: 2.620138645172119
Validation loss: 2.032974978928925

Epoch: 5| Step: 6
Training loss: 2.268293857574463
Validation loss: 1.9955276263657438

Epoch: 5| Step: 7
Training loss: 1.5270684957504272
Validation loss: 2.0081728799368745

Epoch: 5| Step: 8
Training loss: 2.19415020942688
Validation loss: 2.006292458503477

Epoch: 5| Step: 9
Training loss: 1.3711745738983154
Validation loss: 1.9887015922095186

Epoch: 5| Step: 10
Training loss: 1.8613317012786865
Validation loss: 2.0077901296718146

Epoch: 178| Step: 0
Training loss: 1.9528398513793945
Validation loss: 1.978173412302489

Epoch: 5| Step: 1
Training loss: 1.6061776876449585
Validation loss: 1.9813642758195118

Epoch: 5| Step: 2
Training loss: 1.7249504327774048
Validation loss: 2.0029380347139094

Epoch: 5| Step: 3
Training loss: 1.5511354207992554
Validation loss: 1.979617900745843

Epoch: 5| Step: 4
Training loss: 1.6013950109481812
Validation loss: 1.9713582492643786

Epoch: 5| Step: 5
Training loss: 1.5860817432403564
Validation loss: 2.0122787183330906

Epoch: 5| Step: 6
Training loss: 1.6219898462295532
Validation loss: 2.002749437926918

Epoch: 5| Step: 7
Training loss: 2.1817803382873535
Validation loss: 2.001987723894017

Epoch: 5| Step: 8
Training loss: 2.3635127544403076
Validation loss: 1.990740785034754

Epoch: 5| Step: 9
Training loss: 2.2655606269836426
Validation loss: 1.9921332046549807

Epoch: 5| Step: 10
Training loss: 2.374321460723877
Validation loss: 2.0004552884768416

Epoch: 179| Step: 0
Training loss: 1.353860855102539
Validation loss: 1.9898011556235693

Epoch: 5| Step: 1
Training loss: 1.5185105800628662
Validation loss: 2.010652588259789

Epoch: 5| Step: 2
Training loss: 2.6513378620147705
Validation loss: 2.0015591857253865

Epoch: 5| Step: 3
Training loss: 2.5533499717712402
Validation loss: 1.9722071847608011

Epoch: 5| Step: 4
Training loss: 1.772817850112915
Validation loss: 1.9767344664501887

Epoch: 5| Step: 5
Training loss: 1.7799930572509766
Validation loss: 2.001270996626987

Epoch: 5| Step: 6
Training loss: 1.5292034149169922
Validation loss: 2.0025680782974407

Epoch: 5| Step: 7
Training loss: 2.2114529609680176
Validation loss: 1.980790316417653

Epoch: 5| Step: 8
Training loss: 2.133288621902466
Validation loss: 2.0121045163882676

Epoch: 5| Step: 9
Training loss: 1.6872764825820923
Validation loss: 2.0358734412859847

Epoch: 5| Step: 10
Training loss: 1.7476083040237427
Validation loss: 1.9947275500143729

Epoch: 180| Step: 0
Training loss: 1.6202293634414673
Validation loss: 1.9756986377059773

Epoch: 5| Step: 1
Training loss: 2.4064033031463623
Validation loss: 1.996653942651646

Epoch: 5| Step: 2
Training loss: 2.7006630897521973
Validation loss: 1.9853634603561894

Epoch: 5| Step: 3
Training loss: 2.12127685546875
Validation loss: 1.9633711884098668

Epoch: 5| Step: 4
Training loss: 1.5485700368881226
Validation loss: 2.013182686221215

Epoch: 5| Step: 5
Training loss: 1.6934703588485718
Validation loss: 1.9600239056412891

Epoch: 5| Step: 6
Training loss: 1.47018301486969
Validation loss: 1.9764588276545207

Epoch: 5| Step: 7
Training loss: 1.8237991333007812
Validation loss: 1.99278474110429

Epoch: 5| Step: 8
Training loss: 2.097926139831543
Validation loss: 1.9716249512087913

Epoch: 5| Step: 9
Training loss: 1.4977571964263916
Validation loss: 1.9488305378985662

Epoch: 5| Step: 10
Training loss: 1.8701163530349731
Validation loss: 2.000966812974663

Epoch: 181| Step: 0
Training loss: 2.1177754402160645
Validation loss: 1.9926172969161824

Epoch: 5| Step: 1
Training loss: 2.1124470233917236
Validation loss: 2.0124691506867767

Epoch: 5| Step: 2
Training loss: 1.6654800176620483
Validation loss: 1.9553765404608943

Epoch: 5| Step: 3
Training loss: 2.149649143218994
Validation loss: 1.9985897105227235

Epoch: 5| Step: 4
Training loss: 2.2397537231445312
Validation loss: 1.9847266392041278

Epoch: 5| Step: 5
Training loss: 2.0899112224578857
Validation loss: 1.9955162591831659

Epoch: 5| Step: 6
Training loss: 1.1765964031219482
Validation loss: 1.9842931660272742

Epoch: 5| Step: 7
Training loss: 1.4815183877944946
Validation loss: 2.0039421230234127

Epoch: 5| Step: 8
Training loss: 2.009322166442871
Validation loss: 1.9927692669694141

Epoch: 5| Step: 9
Training loss: 2.0899224281311035
Validation loss: 1.984518475429986

Epoch: 5| Step: 10
Training loss: 1.5836873054504395
Validation loss: 2.012812255531229

Epoch: 182| Step: 0
Training loss: 0.9614772796630859
Validation loss: 1.9950575879825059

Epoch: 5| Step: 1
Training loss: 1.6607856750488281
Validation loss: 1.9907786384705575

Epoch: 5| Step: 2
Training loss: 2.043919086456299
Validation loss: 1.9967222598291212

Epoch: 5| Step: 3
Training loss: 2.0948638916015625
Validation loss: 1.996071961618239

Epoch: 5| Step: 4
Training loss: 1.9117320775985718
Validation loss: 2.009824272124998

Epoch: 5| Step: 5
Training loss: 1.7131668329238892
Validation loss: 1.995271844248618

Epoch: 5| Step: 6
Training loss: 1.9920552968978882
Validation loss: 1.9961371626905215

Epoch: 5| Step: 7
Training loss: 2.225482225418091
Validation loss: 1.9449085855996737

Epoch: 5| Step: 8
Training loss: 1.6372865438461304
Validation loss: 1.9849105022286857

Epoch: 5| Step: 9
Training loss: 2.362450122833252
Validation loss: 1.9799238046010335

Epoch: 5| Step: 10
Training loss: 2.1997945308685303
Validation loss: 1.9659637328117125

Epoch: 183| Step: 0
Training loss: 1.708094835281372
Validation loss: 2.0007182064876763

Epoch: 5| Step: 1
Training loss: 2.0289101600646973
Validation loss: 1.9822109463394328

Epoch: 5| Step: 2
Training loss: 1.5961987972259521
Validation loss: 1.9637270627483245

Epoch: 5| Step: 3
Training loss: 2.778740406036377
Validation loss: 1.9794886189122354

Epoch: 5| Step: 4
Training loss: 1.7119172811508179
Validation loss: 1.950861744983222

Epoch: 5| Step: 5
Training loss: 1.8626912832260132
Validation loss: 1.9857626897032543

Epoch: 5| Step: 6
Training loss: 2.1477510929107666
Validation loss: 1.9915158697353896

Epoch: 5| Step: 7
Training loss: 1.8181155920028687
Validation loss: 1.995575520300096

Epoch: 5| Step: 8
Training loss: 1.7043746709823608
Validation loss: 1.9951810888064805

Epoch: 5| Step: 9
Training loss: 1.7077980041503906
Validation loss: 1.9899027488564933

Epoch: 5| Step: 10
Training loss: 1.7885068655014038
Validation loss: 1.9913301775532384

Epoch: 184| Step: 0
Training loss: 1.606013536453247
Validation loss: 1.9788208033448906

Epoch: 5| Step: 1
Training loss: 1.7691218852996826
Validation loss: 1.9944135245456491

Epoch: 5| Step: 2
Training loss: 2.1725172996520996
Validation loss: 1.9955470497890184

Epoch: 5| Step: 3
Training loss: 1.825608491897583
Validation loss: 1.9666244137671687

Epoch: 5| Step: 4
Training loss: 1.6051307916641235
Validation loss: 1.9789806732567408

Epoch: 5| Step: 5
Training loss: 1.6957155466079712
Validation loss: 1.970707331934283

Epoch: 5| Step: 6
Training loss: 1.5995290279388428
Validation loss: 1.9563685386411604

Epoch: 5| Step: 7
Training loss: 2.2110133171081543
Validation loss: 1.9651758722079697

Epoch: 5| Step: 8
Training loss: 2.017378330230713
Validation loss: 1.9778547748442619

Epoch: 5| Step: 9
Training loss: 1.8550136089324951
Validation loss: 1.9791178703308105

Epoch: 5| Step: 10
Training loss: 2.4063720703125
Validation loss: 1.9712697562351023

Epoch: 185| Step: 0
Training loss: 1.9419183731079102
Validation loss: 2.005122482135732

Epoch: 5| Step: 1
Training loss: 2.438594341278076
Validation loss: 1.9342740184517317

Epoch: 5| Step: 2
Training loss: 2.010937452316284
Validation loss: 1.9680207314029816

Epoch: 5| Step: 3
Training loss: 2.050894260406494
Validation loss: 1.9779445381574734

Epoch: 5| Step: 4
Training loss: 1.432902216911316
Validation loss: 1.9920436746330672

Epoch: 5| Step: 5
Training loss: 1.8052383661270142
Validation loss: 1.9423104909158522

Epoch: 5| Step: 6
Training loss: 1.259175181388855
Validation loss: 1.9727005715011268

Epoch: 5| Step: 7
Training loss: 1.8050578832626343
Validation loss: 1.9673199422897831

Epoch: 5| Step: 8
Training loss: 2.2850964069366455
Validation loss: 1.9486647523859495

Epoch: 5| Step: 9
Training loss: 2.250310182571411
Validation loss: 1.9645444500830866

Epoch: 5| Step: 10
Training loss: 1.2114758491516113
Validation loss: 1.9660636276327155

Epoch: 186| Step: 0
Training loss: 2.1028409004211426
Validation loss: 1.963481718494046

Epoch: 5| Step: 1
Training loss: 1.2720439434051514
Validation loss: 2.0091947893942557

Epoch: 5| Step: 2
Training loss: 1.4740720987319946
Validation loss: 1.9751908138234129

Epoch: 5| Step: 3
Training loss: 2.17545747756958
Validation loss: 1.9754427940614763

Epoch: 5| Step: 4
Training loss: 2.465662717819214
Validation loss: 1.961880809517317

Epoch: 5| Step: 5
Training loss: 2.348376750946045
Validation loss: 1.982184963841592

Epoch: 5| Step: 6
Training loss: 1.2061305046081543
Validation loss: 1.9499414351678663

Epoch: 5| Step: 7
Training loss: 2.051544666290283
Validation loss: 1.9580615438440794

Epoch: 5| Step: 8
Training loss: 1.9821163415908813
Validation loss: 1.9402384847723029

Epoch: 5| Step: 9
Training loss: 2.0604121685028076
Validation loss: 1.986676259707379

Epoch: 5| Step: 10
Training loss: 1.411242127418518
Validation loss: 1.9832831839079499

Epoch: 187| Step: 0
Training loss: 2.0875351428985596
Validation loss: 1.9722124274059007

Epoch: 5| Step: 1
Training loss: 1.7901952266693115
Validation loss: 1.9853643371212868

Epoch: 5| Step: 2
Training loss: 1.4416000843048096
Validation loss: 1.9228752274667062

Epoch: 5| Step: 3
Training loss: 1.4109236001968384
Validation loss: 1.9473706740205006

Epoch: 5| Step: 4
Training loss: 1.7654091119766235
Validation loss: 1.9478703544985863

Epoch: 5| Step: 5
Training loss: 2.599498748779297
Validation loss: 1.9915070444025018

Epoch: 5| Step: 6
Training loss: 2.696376085281372
Validation loss: 1.9695820090591267

Epoch: 5| Step: 7
Training loss: 1.8538506031036377
Validation loss: 1.970787130376344

Epoch: 5| Step: 8
Training loss: 1.3637694120407104
Validation loss: 1.9702254059494182

Epoch: 5| Step: 9
Training loss: 1.7834205627441406
Validation loss: 1.94833589881979

Epoch: 5| Step: 10
Training loss: 1.9396636486053467
Validation loss: 1.982840952052865

Epoch: 188| Step: 0
Training loss: 2.203294038772583
Validation loss: 1.9649560323325537

Epoch: 5| Step: 1
Training loss: 2.192209243774414
Validation loss: 1.95507009695935

Epoch: 5| Step: 2
Training loss: 1.6529414653778076
Validation loss: 1.976752681116904

Epoch: 5| Step: 3
Training loss: 1.4498169422149658
Validation loss: 1.9899653542426325

Epoch: 5| Step: 4
Training loss: 1.4444975852966309
Validation loss: 1.9479798001627768

Epoch: 5| Step: 5
Training loss: 1.715004324913025
Validation loss: 1.9706899889053837

Epoch: 5| Step: 6
Training loss: 2.0444555282592773
Validation loss: 1.9843173385948263

Epoch: 5| Step: 7
Training loss: 1.7417409420013428
Validation loss: 1.9806630893420147

Epoch: 5| Step: 8
Training loss: 1.9281946420669556
Validation loss: 1.98496215574203

Epoch: 5| Step: 9
Training loss: 1.979479193687439
Validation loss: 1.983642662725141

Epoch: 5| Step: 10
Training loss: 2.0888941287994385
Validation loss: 1.9641806746041903

Epoch: 189| Step: 0
Training loss: 1.0886032581329346
Validation loss: 1.9358292677069222

Epoch: 5| Step: 1
Training loss: 1.8441110849380493
Validation loss: 1.9688060437479327

Epoch: 5| Step: 2
Training loss: 2.1791980266571045
Validation loss: 2.0013029447165867

Epoch: 5| Step: 3
Training loss: 1.1855106353759766
Validation loss: 1.9650323890870618

Epoch: 5| Step: 4
Training loss: 2.279715061187744
Validation loss: 1.967459681213543

Epoch: 5| Step: 5
Training loss: 1.9069569110870361
Validation loss: 1.9798903875453497

Epoch: 5| Step: 6
Training loss: 2.0784568786621094
Validation loss: 1.9736617777937202

Epoch: 5| Step: 7
Training loss: 2.06791353225708
Validation loss: 1.9498304577283962

Epoch: 5| Step: 8
Training loss: 1.8361527919769287
Validation loss: 1.983398514409219

Epoch: 5| Step: 9
Training loss: 1.9435093402862549
Validation loss: 1.986966461263677

Epoch: 5| Step: 10
Training loss: 2.0028035640716553
Validation loss: 1.9651673557937785

Epoch: 190| Step: 0
Training loss: 2.2080676555633545
Validation loss: 1.9762398965897099

Epoch: 5| Step: 1
Training loss: 1.6988589763641357
Validation loss: 1.9648865474167692

Epoch: 5| Step: 2
Training loss: 2.958078384399414
Validation loss: 1.9787055292437155

Epoch: 5| Step: 3
Training loss: 2.2497832775115967
Validation loss: 1.9631515164529123

Epoch: 5| Step: 4
Training loss: 1.8792362213134766
Validation loss: 1.9732832254902009

Epoch: 5| Step: 5
Training loss: 1.2789589166641235
Validation loss: 1.9602999200103104

Epoch: 5| Step: 6
Training loss: 1.4509243965148926
Validation loss: 1.974714333011258

Epoch: 5| Step: 7
Training loss: 1.8294605016708374
Validation loss: 1.96398623271655

Epoch: 5| Step: 8
Training loss: 2.1125636100769043
Validation loss: 1.9447861871411722

Epoch: 5| Step: 9
Training loss: 1.7113864421844482
Validation loss: 1.9695980087403329

Epoch: 5| Step: 10
Training loss: 1.0952500104904175
Validation loss: 1.946009656434418

Epoch: 191| Step: 0
Training loss: 1.9684150218963623
Validation loss: 1.9845220952905633

Epoch: 5| Step: 1
Training loss: 1.6682147979736328
Validation loss: 1.972919443602203

Epoch: 5| Step: 2
Training loss: 1.7629899978637695
Validation loss: 1.957800926700715

Epoch: 5| Step: 3
Training loss: 1.9189863204956055
Validation loss: 1.9518867743912565

Epoch: 5| Step: 4
Training loss: 2.3704447746276855
Validation loss: 1.9534736781991937

Epoch: 5| Step: 5
Training loss: 1.8929252624511719
Validation loss: 1.957645905915127

Epoch: 5| Step: 6
Training loss: 1.2815876007080078
Validation loss: 1.9565644648767286

Epoch: 5| Step: 7
Training loss: 2.1056017875671387
Validation loss: 1.9691960221977645

Epoch: 5| Step: 8
Training loss: 1.5846164226531982
Validation loss: 1.9686452778436805

Epoch: 5| Step: 9
Training loss: 1.8030240535736084
Validation loss: 1.9463953459134666

Epoch: 5| Step: 10
Training loss: 2.290093421936035
Validation loss: 1.9637196038358955

Epoch: 192| Step: 0
Training loss: 2.2144739627838135
Validation loss: 1.9670731559876473

Epoch: 5| Step: 1
Training loss: 1.4663772583007812
Validation loss: 1.9534592474660566

Epoch: 5| Step: 2
Training loss: 1.5770080089569092
Validation loss: 1.9522480246841267

Epoch: 5| Step: 3
Training loss: 1.6723823547363281
Validation loss: 1.959276190368078

Epoch: 5| Step: 4
Training loss: 2.5065462589263916
Validation loss: 1.9682919389458113

Epoch: 5| Step: 5
Training loss: 1.7136328220367432
Validation loss: 1.9595649293673936

Epoch: 5| Step: 6
Training loss: 2.5026650428771973
Validation loss: 1.9608057686077651

Epoch: 5| Step: 7
Training loss: 1.338801622390747
Validation loss: 1.940850265564457

Epoch: 5| Step: 8
Training loss: 2.1476094722747803
Validation loss: 1.9652048080198226

Epoch: 5| Step: 9
Training loss: 1.8332901000976562
Validation loss: 1.9820408205832205

Epoch: 5| Step: 10
Training loss: 1.3838447332382202
Validation loss: 1.993932745789969

Epoch: 193| Step: 0
Training loss: 1.7597553730010986
Validation loss: 1.9868313368930612

Epoch: 5| Step: 1
Training loss: 2.4114108085632324
Validation loss: 1.9629111571978497

Epoch: 5| Step: 2
Training loss: 2.602916717529297
Validation loss: 1.9895001829311412

Epoch: 5| Step: 3
Training loss: 1.940029501914978
Validation loss: 1.984114113674369

Epoch: 5| Step: 4
Training loss: 1.6855151653289795
Validation loss: 1.9680144812471123

Epoch: 5| Step: 5
Training loss: 1.8071244955062866
Validation loss: 1.9687856512684976

Epoch: 5| Step: 6
Training loss: 1.7163293361663818
Validation loss: 1.9648476031518751

Epoch: 5| Step: 7
Training loss: 1.734161376953125
Validation loss: 1.9873960197612803

Epoch: 5| Step: 8
Training loss: 1.381778597831726
Validation loss: 1.9831847734348749

Epoch: 5| Step: 9
Training loss: 2.0312135219573975
Validation loss: 1.9499633401952765

Epoch: 5| Step: 10
Training loss: 1.2673853635787964
Validation loss: 1.98124954008287

Epoch: 194| Step: 0
Training loss: 2.266633987426758
Validation loss: 1.9471401322272517

Epoch: 5| Step: 1
Training loss: 1.7803306579589844
Validation loss: 1.980446489908362

Epoch: 5| Step: 2
Training loss: 2.1349847316741943
Validation loss: 1.9653864804134573

Epoch: 5| Step: 3
Training loss: 1.6088435649871826
Validation loss: 1.9699093590500534

Epoch: 5| Step: 4
Training loss: 1.8514759540557861
Validation loss: 1.9768115192331293

Epoch: 5| Step: 5
Training loss: 1.7736164331436157
Validation loss: 1.9583291981809883

Epoch: 5| Step: 6
Training loss: 1.702757477760315
Validation loss: 1.971369645928824

Epoch: 5| Step: 7
Training loss: 1.6598217487335205
Validation loss: 1.9776181649136286

Epoch: 5| Step: 8
Training loss: 1.5658223628997803
Validation loss: 1.9649177623051468

Epoch: 5| Step: 9
Training loss: 1.8215017318725586
Validation loss: 1.985800402138823

Epoch: 5| Step: 10
Training loss: 2.089158773422241
Validation loss: 1.9798860062835038

Epoch: 195| Step: 0
Training loss: 2.349928140640259
Validation loss: 1.9495822383511452

Epoch: 5| Step: 1
Training loss: 2.0082345008850098
Validation loss: 1.9795206413474133

Epoch: 5| Step: 2
Training loss: 1.4729478359222412
Validation loss: 1.9403667129496092

Epoch: 5| Step: 3
Training loss: 1.5964481830596924
Validation loss: 1.9309961475351805

Epoch: 5| Step: 4
Training loss: 1.8021777868270874
Validation loss: 1.9454197755423925

Epoch: 5| Step: 5
Training loss: 2.135364294052124
Validation loss: 1.975431126932944

Epoch: 5| Step: 6
Training loss: 1.2554877996444702
Validation loss: 1.9550826036801903

Epoch: 5| Step: 7
Training loss: 1.6525481939315796
Validation loss: 1.945021576778863

Epoch: 5| Step: 8
Training loss: 2.063699722290039
Validation loss: 1.9375542222812612

Epoch: 5| Step: 9
Training loss: 1.6616138219833374
Validation loss: 1.9303930421029367

Epoch: 5| Step: 10
Training loss: 2.6957759857177734
Validation loss: 1.9441408188112321

Epoch: 196| Step: 0
Training loss: 1.3167574405670166
Validation loss: 1.937478994810453

Epoch: 5| Step: 1
Training loss: 1.8905376195907593
Validation loss: 1.9496650580436952

Epoch: 5| Step: 2
Training loss: 1.2656147480010986
Validation loss: 1.9430265888091056

Epoch: 5| Step: 3
Training loss: 2.112595796585083
Validation loss: 1.991082945177632

Epoch: 5| Step: 4
Training loss: 1.845597505569458
Validation loss: 1.9634229854870868

Epoch: 5| Step: 5
Training loss: 1.4481890201568604
Validation loss: 1.9468509881727156

Epoch: 5| Step: 6
Training loss: 2.5527729988098145
Validation loss: 1.9850399571080362

Epoch: 5| Step: 7
Training loss: 1.5650742053985596
Validation loss: 1.9655599081388084

Epoch: 5| Step: 8
Training loss: 2.0609829425811768
Validation loss: 1.9972141045396046

Epoch: 5| Step: 9
Training loss: 1.6973488330841064
Validation loss: 1.9691168082657682

Epoch: 5| Step: 10
Training loss: 2.5138156414031982
Validation loss: 1.938463557151056

Epoch: 197| Step: 0
Training loss: 1.8471260070800781
Validation loss: 1.966202384682112

Epoch: 5| Step: 1
Training loss: 2.01098895072937
Validation loss: 1.969085180631248

Epoch: 5| Step: 2
Training loss: 1.6927242279052734
Validation loss: 1.9477981905783377

Epoch: 5| Step: 3
Training loss: 2.046891689300537
Validation loss: 1.9357124220940374

Epoch: 5| Step: 4
Training loss: 1.2238069772720337
Validation loss: 1.9506161315466768

Epoch: 5| Step: 5
Training loss: 1.454254388809204
Validation loss: 1.9537671586518646

Epoch: 5| Step: 6
Training loss: 1.7680397033691406
Validation loss: 1.9378501394743561

Epoch: 5| Step: 7
Training loss: 2.2602295875549316
Validation loss: 1.9449881815141248

Epoch: 5| Step: 8
Training loss: 2.0118789672851562
Validation loss: 1.935351981911608

Epoch: 5| Step: 9
Training loss: 2.1572659015655518
Validation loss: 1.952616681334793

Epoch: 5| Step: 10
Training loss: 1.83674955368042
Validation loss: 1.9431862074841735

Epoch: 198| Step: 0
Training loss: 1.1155074834823608
Validation loss: 1.9203172217133224

Epoch: 5| Step: 1
Training loss: 2.1349892616271973
Validation loss: 1.9662571055914766

Epoch: 5| Step: 2
Training loss: 1.8353979587554932
Validation loss: 1.9195892375002626

Epoch: 5| Step: 3
Training loss: 1.8038909435272217
Validation loss: 1.9698368144291702

Epoch: 5| Step: 4
Training loss: 2.67944073677063
Validation loss: 1.9582202357630576

Epoch: 5| Step: 5
Training loss: 1.4330822229385376
Validation loss: 1.9604395871521325

Epoch: 5| Step: 6
Training loss: 2.2692713737487793
Validation loss: 1.9411297639211018

Epoch: 5| Step: 7
Training loss: 1.7464349269866943
Validation loss: 1.9535981403884066

Epoch: 5| Step: 8
Training loss: 2.1279702186584473
Validation loss: 1.9435485537334154

Epoch: 5| Step: 9
Training loss: 1.870867133140564
Validation loss: 1.9681255637958486

Epoch: 5| Step: 10
Training loss: 1.200995683670044
Validation loss: 1.9848184483025664

Epoch: 199| Step: 0
Training loss: 1.7701858282089233
Validation loss: 1.981131092194588

Epoch: 5| Step: 1
Training loss: 1.9453099966049194
Validation loss: 1.9468554501892419

Epoch: 5| Step: 2
Training loss: 1.7063884735107422
Validation loss: 1.94621475537618

Epoch: 5| Step: 3
Training loss: 1.6742093563079834
Validation loss: 1.9681469855769989

Epoch: 5| Step: 4
Training loss: 2.3868069648742676
Validation loss: 1.9491771780034548

Epoch: 5| Step: 5
Training loss: 2.078143835067749
Validation loss: 1.9554906673328851

Epoch: 5| Step: 6
Training loss: 1.5014359951019287
Validation loss: 1.9508081815576042

Epoch: 5| Step: 7
Training loss: 1.5995491743087769
Validation loss: 1.9989521990540207

Epoch: 5| Step: 8
Training loss: 1.6875356435775757
Validation loss: 1.9604282597059846

Epoch: 5| Step: 9
Training loss: 1.6044574975967407
Validation loss: 1.9476194766259962

Epoch: 5| Step: 10
Training loss: 2.217240333557129
Validation loss: 1.9789624829446115

Epoch: 200| Step: 0
Training loss: 1.806846261024475
Validation loss: 1.98236975490406

Epoch: 5| Step: 1
Training loss: 2.06520414352417
Validation loss: 1.9768543294681016

Epoch: 5| Step: 2
Training loss: 2.3444559574127197
Validation loss: 1.961227297782898

Epoch: 5| Step: 3
Training loss: 1.1008182764053345
Validation loss: 1.9527586788259528

Epoch: 5| Step: 4
Training loss: 1.6391308307647705
Validation loss: 1.940052406762236

Epoch: 5| Step: 5
Training loss: 2.2232842445373535
Validation loss: 1.9825029283441522

Epoch: 5| Step: 6
Training loss: 2.0163965225219727
Validation loss: 1.9543242531438028

Epoch: 5| Step: 7
Training loss: 1.7763627767562866
Validation loss: 1.944387323112898

Epoch: 5| Step: 8
Training loss: 1.7774661779403687
Validation loss: 1.9638212496234524

Epoch: 5| Step: 9
Training loss: 1.6996796131134033
Validation loss: 1.9365417329213952

Epoch: 5| Step: 10
Training loss: 1.7667180299758911
Validation loss: 1.9376404311067315

Epoch: 201| Step: 0
Training loss: 2.2945830821990967
Validation loss: 1.9645254137695476

Epoch: 5| Step: 1
Training loss: 2.1186931133270264
Validation loss: 1.9514524449584305

Epoch: 5| Step: 2
Training loss: 1.446507215499878
Validation loss: 1.9659243322187854

Epoch: 5| Step: 3
Training loss: 1.8405824899673462
Validation loss: 1.956429131569401

Epoch: 5| Step: 4
Training loss: 1.7286503314971924
Validation loss: 1.9734403138519616

Epoch: 5| Step: 5
Training loss: 2.1661105155944824
Validation loss: 1.9658462257795437

Epoch: 5| Step: 6
Training loss: 1.884931206703186
Validation loss: 1.9536435296458583

Epoch: 5| Step: 7
Training loss: 1.3410475254058838
Validation loss: 1.9775729756201468

Epoch: 5| Step: 8
Training loss: 1.7312885522842407
Validation loss: 1.9886934039413289

Epoch: 5| Step: 9
Training loss: 2.140939235687256
Validation loss: 1.9414708870713429

Epoch: 5| Step: 10
Training loss: 1.4661422967910767
Validation loss: 1.9869380151071856

Epoch: 202| Step: 0
Training loss: 1.436353087425232
Validation loss: 1.9898332959862166

Epoch: 5| Step: 1
Training loss: 1.9023325443267822
Validation loss: 1.982073683892527

Epoch: 5| Step: 2
Training loss: 1.542599081993103
Validation loss: 1.9645764225272722

Epoch: 5| Step: 3
Training loss: 1.7025959491729736
Validation loss: 1.9887583512131886

Epoch: 5| Step: 4
Training loss: 2.321206569671631
Validation loss: 1.985440206784074

Epoch: 5| Step: 5
Training loss: 1.8262943029403687
Validation loss: 1.9644443091525827

Epoch: 5| Step: 6
Training loss: 1.3978008031845093
Validation loss: 1.9730602490004672

Epoch: 5| Step: 7
Training loss: 2.0645346641540527
Validation loss: 1.934721282733384

Epoch: 5| Step: 8
Training loss: 2.1748690605163574
Validation loss: 1.9329034256678757

Epoch: 5| Step: 9
Training loss: 1.932366132736206
Validation loss: 1.9351928605828235

Epoch: 5| Step: 10
Training loss: 1.8014432191848755
Validation loss: 1.95180251777813

Epoch: 203| Step: 0
Training loss: 2.256277561187744
Validation loss: 1.950270975789716

Epoch: 5| Step: 1
Training loss: 2.1788647174835205
Validation loss: 1.9757737985221289

Epoch: 5| Step: 2
Training loss: 1.6934783458709717
Validation loss: 1.940633980176782

Epoch: 5| Step: 3
Training loss: 1.4709528684616089
Validation loss: 1.9671306930562502

Epoch: 5| Step: 4
Training loss: 2.824120044708252
Validation loss: 1.9700024884234193

Epoch: 5| Step: 5
Training loss: 1.9201343059539795
Validation loss: 1.9534964330734745

Epoch: 5| Step: 6
Training loss: 1.3218586444854736
Validation loss: 1.9499112688085085

Epoch: 5| Step: 7
Training loss: 1.6130282878875732
Validation loss: 1.9416229647974814

Epoch: 5| Step: 8
Training loss: 1.4304527044296265
Validation loss: 1.9563538130893503

Epoch: 5| Step: 9
Training loss: 1.2660917043685913
Validation loss: 1.955423419193555

Epoch: 5| Step: 10
Training loss: 1.877475380897522
Validation loss: 1.9482920195466729

Epoch: 204| Step: 0
Training loss: 1.9168941974639893
Validation loss: 1.9471365931213542

Epoch: 5| Step: 1
Training loss: 1.8952033519744873
Validation loss: 1.9649963122542187

Epoch: 5| Step: 2
Training loss: 1.7745018005371094
Validation loss: 1.9873055129922845

Epoch: 5| Step: 3
Training loss: 1.6045491695404053
Validation loss: 1.9686529239018757

Epoch: 5| Step: 4
Training loss: 1.7403188943862915
Validation loss: 1.972624550583542

Epoch: 5| Step: 5
Training loss: 1.8379911184310913
Validation loss: 1.9534814844849289

Epoch: 5| Step: 6
Training loss: 1.2534444332122803
Validation loss: 1.937914832945793

Epoch: 5| Step: 7
Training loss: 2.291760206222534
Validation loss: 1.9585446029581048

Epoch: 5| Step: 8
Training loss: 2.1260313987731934
Validation loss: 1.934156067909733

Epoch: 5| Step: 9
Training loss: 1.6832082271575928
Validation loss: 1.9662722477348902

Epoch: 5| Step: 10
Training loss: 1.8219826221466064
Validation loss: 1.9398318618856452

Epoch: 205| Step: 0
Training loss: 1.9758914709091187
Validation loss: 1.9111855312060284

Epoch: 5| Step: 1
Training loss: 1.1113742589950562
Validation loss: 1.9534839058435092

Epoch: 5| Step: 2
Training loss: 1.448118805885315
Validation loss: 1.9448743507426272

Epoch: 5| Step: 3
Training loss: 1.8131545782089233
Validation loss: 1.9582760141741844

Epoch: 5| Step: 4
Training loss: 2.0581912994384766
Validation loss: 1.9777272516681301

Epoch: 5| Step: 5
Training loss: 1.8882675170898438
Validation loss: 1.9636437905732023

Epoch: 5| Step: 6
Training loss: 1.8208491802215576
Validation loss: 1.969970695434078

Epoch: 5| Step: 7
Training loss: 2.1840908527374268
Validation loss: 1.937977949778239

Epoch: 5| Step: 8
Training loss: 2.104231834411621
Validation loss: 1.9600186091597362

Epoch: 5| Step: 9
Training loss: 1.6401996612548828
Validation loss: 1.9279583192640735

Epoch: 5| Step: 10
Training loss: 1.6125383377075195
Validation loss: 1.9600910486713532

Epoch: 206| Step: 0
Training loss: 2.2616782188415527
Validation loss: 1.950754024649179

Epoch: 5| Step: 1
Training loss: 1.3955295085906982
Validation loss: 1.9619392784692908

Epoch: 5| Step: 2
Training loss: 1.9644867181777954
Validation loss: 1.9655971475826797

Epoch: 5| Step: 3
Training loss: 1.3562536239624023
Validation loss: 1.9221012361588017

Epoch: 5| Step: 4
Training loss: 2.0811667442321777
Validation loss: 1.9327284495035808

Epoch: 5| Step: 5
Training loss: 2.212803363800049
Validation loss: 1.9419384605141097

Epoch: 5| Step: 6
Training loss: 2.1392858028411865
Validation loss: 1.9296300936770696

Epoch: 5| Step: 7
Training loss: 1.803529977798462
Validation loss: 1.9123278958823091

Epoch: 5| Step: 8
Training loss: 1.2697789669036865
Validation loss: 1.9403174692584622

Epoch: 5| Step: 9
Training loss: 2.154874324798584
Validation loss: 1.969863054572895

Epoch: 5| Step: 10
Training loss: 1.2794227600097656
Validation loss: 1.954588613202495

Epoch: 207| Step: 0
Training loss: 1.4447386264801025
Validation loss: 1.9377017559543732

Epoch: 5| Step: 1
Training loss: 1.761094331741333
Validation loss: 1.9527741106607581

Epoch: 5| Step: 2
Training loss: 1.8123016357421875
Validation loss: 1.9561506778963151

Epoch: 5| Step: 3
Training loss: 1.6013660430908203
Validation loss: 1.9342667466850691

Epoch: 5| Step: 4
Training loss: 2.249199151992798
Validation loss: 1.9882411238967732

Epoch: 5| Step: 5
Training loss: 1.5334484577178955
Validation loss: 1.9583172029064548

Epoch: 5| Step: 6
Training loss: 1.6754372119903564
Validation loss: 1.963772855779176

Epoch: 5| Step: 7
Training loss: 2.0532305240631104
Validation loss: 1.9540266913752402

Epoch: 5| Step: 8
Training loss: 1.8105396032333374
Validation loss: 1.927493610689717

Epoch: 5| Step: 9
Training loss: 2.180894374847412
Validation loss: 1.949453515391196

Epoch: 5| Step: 10
Training loss: 1.748530387878418
Validation loss: 1.9159510545833136

Epoch: 208| Step: 0
Training loss: 1.3704473972320557
Validation loss: 1.9519321546759656

Epoch: 5| Step: 1
Training loss: 1.5839176177978516
Validation loss: 1.9630481081624185

Epoch: 5| Step: 2
Training loss: 2.1933560371398926
Validation loss: 1.9355892199341969

Epoch: 5| Step: 3
Training loss: 2.310255289077759
Validation loss: 1.9633708730820687

Epoch: 5| Step: 4
Training loss: 1.918686866760254
Validation loss: 1.9575803741332023

Epoch: 5| Step: 5
Training loss: 2.3010048866271973
Validation loss: 1.9724342515391688

Epoch: 5| Step: 6
Training loss: 2.1315159797668457
Validation loss: 2.003949060234972

Epoch: 5| Step: 7
Training loss: 1.3098787069320679
Validation loss: 1.9671633705016105

Epoch: 5| Step: 8
Training loss: 1.7087684869766235
Validation loss: 1.9597893709777503

Epoch: 5| Step: 9
Training loss: 1.8954013586044312
Validation loss: 1.966489758542789

Epoch: 5| Step: 10
Training loss: 1.0645992755889893
Validation loss: 1.9075009310117332

Epoch: 209| Step: 0
Training loss: 1.7390896081924438
Validation loss: 1.9454176733570714

Epoch: 5| Step: 1
Training loss: 1.669811487197876
Validation loss: 1.9398488101138864

Epoch: 5| Step: 2
Training loss: 1.7588697671890259
Validation loss: 1.9732705777691257

Epoch: 5| Step: 3
Training loss: 1.9022645950317383
Validation loss: 1.9265239777103547

Epoch: 5| Step: 4
Training loss: 1.4802632331848145
Validation loss: 1.9725335515955442

Epoch: 5| Step: 5
Training loss: 2.0213208198547363
Validation loss: 1.9307730890089465

Epoch: 5| Step: 6
Training loss: 1.885856032371521
Validation loss: 1.9580319722493489

Epoch: 5| Step: 7
Training loss: 1.789162039756775
Validation loss: 1.9416499355787873

Epoch: 5| Step: 8
Training loss: 2.138491630554199
Validation loss: 1.9713084928451046

Epoch: 5| Step: 9
Training loss: 1.595219612121582
Validation loss: 1.9324603952387327

Epoch: 5| Step: 10
Training loss: 1.6929301023483276
Validation loss: 1.9380535797406269

Epoch: 210| Step: 0
Training loss: 1.6234766244888306
Validation loss: 1.9042038186903922

Epoch: 5| Step: 1
Training loss: 2.04599928855896
Validation loss: 1.966134177741184

Epoch: 5| Step: 2
Training loss: 1.4193528890609741
Validation loss: 1.9454727557397657

Epoch: 5| Step: 3
Training loss: 2.087071180343628
Validation loss: 1.938599557004949

Epoch: 5| Step: 4
Training loss: 1.6392099857330322
Validation loss: 1.929949043899454

Epoch: 5| Step: 5
Training loss: 2.101473569869995
Validation loss: 1.9391994501954766

Epoch: 5| Step: 6
Training loss: 1.9040664434432983
Validation loss: 1.9810715029316563

Epoch: 5| Step: 7
Training loss: 1.7596855163574219
Validation loss: 1.960284713775881

Epoch: 5| Step: 8
Training loss: 1.5546472072601318
Validation loss: 1.9341759989338536

Epoch: 5| Step: 9
Training loss: 1.8967081308364868
Validation loss: 1.9505702475065827

Epoch: 5| Step: 10
Training loss: 1.7496452331542969
Validation loss: 1.963826294868223

Epoch: 211| Step: 0
Training loss: 1.3636592626571655
Validation loss: 1.942253581939205

Epoch: 5| Step: 1
Training loss: 3.0454766750335693
Validation loss: 1.9180336818900159

Epoch: 5| Step: 2
Training loss: 2.163349151611328
Validation loss: 1.9612092971801758

Epoch: 5| Step: 3
Training loss: 1.4599370956420898
Validation loss: 1.9417740029673423

Epoch: 5| Step: 4
Training loss: 1.7051849365234375
Validation loss: 1.9790182626375588

Epoch: 5| Step: 5
Training loss: 1.606740951538086
Validation loss: 1.961223042139443

Epoch: 5| Step: 6
Training loss: 1.122589349746704
Validation loss: 1.9470314825734785

Epoch: 5| Step: 7
Training loss: 2.5305590629577637
Validation loss: 1.9779290896590038

Epoch: 5| Step: 8
Training loss: 2.036294460296631
Validation loss: 1.9640395500326668

Epoch: 5| Step: 9
Training loss: 1.237777590751648
Validation loss: 1.9490448095465218

Epoch: 5| Step: 10
Training loss: 1.4243731498718262
Validation loss: 1.9526856483951691

Epoch: 212| Step: 0
Training loss: 1.476428747177124
Validation loss: 1.930456881882042

Epoch: 5| Step: 1
Training loss: 2.083069324493408
Validation loss: 1.920402830646884

Epoch: 5| Step: 2
Training loss: 2.3304290771484375
Validation loss: 1.9250679323750157

Epoch: 5| Step: 3
Training loss: 1.3786674737930298
Validation loss: 1.9352618725069108

Epoch: 5| Step: 4
Training loss: 1.699120283126831
Validation loss: 1.9301588048217118

Epoch: 5| Step: 5
Training loss: 1.9324884414672852
Validation loss: 1.9522047119755899

Epoch: 5| Step: 6
Training loss: 1.972312569618225
Validation loss: 1.946147705918999

Epoch: 5| Step: 7
Training loss: 1.602331519126892
Validation loss: 1.9318301959704327

Epoch: 5| Step: 8
Training loss: 1.4596731662750244
Validation loss: 1.9138987371998448

Epoch: 5| Step: 9
Training loss: 2.106694221496582
Validation loss: 1.9263184378224034

Epoch: 5| Step: 10
Training loss: 1.740217685699463
Validation loss: 1.915181653473967

Epoch: 213| Step: 0
Training loss: 2.022264003753662
Validation loss: 1.9661096795912711

Epoch: 5| Step: 1
Training loss: 2.1413686275482178
Validation loss: 1.9403338547675841

Epoch: 5| Step: 2
Training loss: 1.944903016090393
Validation loss: 1.9341079727295907

Epoch: 5| Step: 3
Training loss: 1.8334506750106812
Validation loss: 1.9655391221405358

Epoch: 5| Step: 4
Training loss: 1.2285115718841553
Validation loss: 1.9575801177691388

Epoch: 5| Step: 5
Training loss: 1.5264190435409546
Validation loss: 1.9449797522637151

Epoch: 5| Step: 6
Training loss: 1.6256088018417358
Validation loss: 1.9532681972749772

Epoch: 5| Step: 7
Training loss: 1.7306963205337524
Validation loss: 1.9497650797649095

Epoch: 5| Step: 8
Training loss: 1.8733097314834595
Validation loss: 1.931093938889042

Epoch: 5| Step: 9
Training loss: 1.4224936962127686
Validation loss: 1.9308579250048565

Epoch: 5| Step: 10
Training loss: 2.473471164703369
Validation loss: 1.975863750262927

Epoch: 214| Step: 0
Training loss: 1.7037546634674072
Validation loss: 1.9467432652750323

Epoch: 5| Step: 1
Training loss: 2.351121187210083
Validation loss: 1.938925843085012

Epoch: 5| Step: 2
Training loss: 1.5753228664398193
Validation loss: 1.9622087504274102

Epoch: 5| Step: 3
Training loss: 1.4744001626968384
Validation loss: 1.9148258637356501

Epoch: 5| Step: 4
Training loss: 1.702344536781311
Validation loss: 1.9614656702164681

Epoch: 5| Step: 5
Training loss: 1.526369333267212
Validation loss: 1.9505360869951145

Epoch: 5| Step: 6
Training loss: 1.219665765762329
Validation loss: 1.9051703906828357

Epoch: 5| Step: 7
Training loss: 1.6419891119003296
Validation loss: 1.9400337690948157

Epoch: 5| Step: 8
Training loss: 2.054328203201294
Validation loss: 1.905557668337258

Epoch: 5| Step: 9
Training loss: 2.529003620147705
Validation loss: 1.9491863917278986

Epoch: 5| Step: 10
Training loss: 1.9255801439285278
Validation loss: 1.9508155597153531

Epoch: 215| Step: 0
Training loss: 1.7558939456939697
Validation loss: 1.925609778332454

Epoch: 5| Step: 1
Training loss: 1.6347888708114624
Validation loss: 1.9247305329127977

Epoch: 5| Step: 2
Training loss: 1.463998794555664
Validation loss: 1.9188481812836022

Epoch: 5| Step: 3
Training loss: 1.969154715538025
Validation loss: 1.9574283271707513

Epoch: 5| Step: 4
Training loss: 1.677420973777771
Validation loss: 1.9469016418662122

Epoch: 5| Step: 5
Training loss: 2.1257619857788086
Validation loss: 1.957051396369934

Epoch: 5| Step: 6
Training loss: 1.844312310218811
Validation loss: 1.9264518958266064

Epoch: 5| Step: 7
Training loss: 1.348078966140747
Validation loss: 1.9272335255017845

Epoch: 5| Step: 8
Training loss: 1.2500202655792236
Validation loss: 1.9317620185113722

Epoch: 5| Step: 9
Training loss: 2.308331251144409
Validation loss: 1.965943483896153

Epoch: 5| Step: 10
Training loss: 2.4037511348724365
Validation loss: 1.9326068970464891

Epoch: 216| Step: 0
Training loss: 1.4035972356796265
Validation loss: 1.9535353734929075

Epoch: 5| Step: 1
Training loss: 1.2843140363693237
Validation loss: 1.9683345825441423

Epoch: 5| Step: 2
Training loss: 1.3907092809677124
Validation loss: 1.9051419560627272

Epoch: 5| Step: 3
Training loss: 1.6304771900177002
Validation loss: 1.9349257548650105

Epoch: 5| Step: 4
Training loss: 1.734750747680664
Validation loss: 1.9147276327174196

Epoch: 5| Step: 5
Training loss: 2.0723297595977783
Validation loss: 1.9844707289049703

Epoch: 5| Step: 6
Training loss: 1.542981743812561
Validation loss: 1.9312281775218185

Epoch: 5| Step: 7
Training loss: 2.232138156890869
Validation loss: 1.9731607373042772

Epoch: 5| Step: 8
Training loss: 2.064937114715576
Validation loss: 1.927200476328532

Epoch: 5| Step: 9
Training loss: 1.9062350988388062
Validation loss: 1.9266470632245463

Epoch: 5| Step: 10
Training loss: 2.10660719871521
Validation loss: 1.9431015752976941

Epoch: 217| Step: 0
Training loss: 1.4180132150650024
Validation loss: 1.9286452365177933

Epoch: 5| Step: 1
Training loss: 2.004108428955078
Validation loss: 1.9317117711549163

Epoch: 5| Step: 2
Training loss: 1.8845272064208984
Validation loss: 1.939106470795088

Epoch: 5| Step: 3
Training loss: 1.7753627300262451
Validation loss: 1.9145697829543904

Epoch: 5| Step: 4
Training loss: 1.7102714776992798
Validation loss: 1.9613671482250254

Epoch: 5| Step: 5
Training loss: 1.614392876625061
Validation loss: 1.9184376629449988

Epoch: 5| Step: 6
Training loss: 1.9729934930801392
Validation loss: 1.9651274219635995

Epoch: 5| Step: 7
Training loss: 2.0528037548065186
Validation loss: 1.9522136975360174

Epoch: 5| Step: 8
Training loss: 2.252256155014038
Validation loss: 1.9314452730199343

Epoch: 5| Step: 9
Training loss: 0.9596460461616516
Validation loss: 1.9539553785836825

Epoch: 5| Step: 10
Training loss: 1.8758273124694824
Validation loss: 1.918978601373652

Epoch: 218| Step: 0
Training loss: 1.6876718997955322
Validation loss: 1.9644203826945315

Epoch: 5| Step: 1
Training loss: 1.8793773651123047
Validation loss: 1.9250929394075948

Epoch: 5| Step: 2
Training loss: 1.878774881362915
Validation loss: 1.9267427434203446

Epoch: 5| Step: 3
Training loss: 1.722177505493164
Validation loss: 1.9707328991223407

Epoch: 5| Step: 4
Training loss: 1.6651216745376587
Validation loss: 1.9809663808473976

Epoch: 5| Step: 5
Training loss: 1.8569574356079102
Validation loss: 1.960865214306821

Epoch: 5| Step: 6
Training loss: 2.0008347034454346
Validation loss: 1.9310518862098776

Epoch: 5| Step: 7
Training loss: 1.4924875497817993
Validation loss: 1.9243286796795425

Epoch: 5| Step: 8
Training loss: 1.7541139125823975
Validation loss: 1.9446605469590874

Epoch: 5| Step: 9
Training loss: 2.2150707244873047
Validation loss: 1.9198490637604908

Epoch: 5| Step: 10
Training loss: 1.2909283638000488
Validation loss: 1.924954770713724

Epoch: 219| Step: 0
Training loss: 1.9593359231948853
Validation loss: 1.9264136514356058

Epoch: 5| Step: 1
Training loss: 1.5226337909698486
Validation loss: 1.9484100405887892

Epoch: 5| Step: 2
Training loss: 2.0071969032287598
Validation loss: 1.8607815529710503

Epoch: 5| Step: 3
Training loss: 2.1348319053649902
Validation loss: 1.9098961930121146

Epoch: 5| Step: 4
Training loss: 1.613705039024353
Validation loss: 1.955569166009144

Epoch: 5| Step: 5
Training loss: 2.134120464324951
Validation loss: 1.9443282183780466

Epoch: 5| Step: 6
Training loss: 1.4083789587020874
Validation loss: 1.9807735450806156

Epoch: 5| Step: 7
Training loss: 1.5763065814971924
Validation loss: 1.937447319748581

Epoch: 5| Step: 8
Training loss: 1.6847463846206665
Validation loss: 1.9722370652742283

Epoch: 5| Step: 9
Training loss: 1.5696808099746704
Validation loss: 1.9209919860286098

Epoch: 5| Step: 10
Training loss: 1.7193100452423096
Validation loss: 1.9386251152202647

Epoch: 220| Step: 0
Training loss: 2.3616819381713867
Validation loss: 1.9624009017021424

Epoch: 5| Step: 1
Training loss: 0.8954218029975891
Validation loss: 1.9344451350550498

Epoch: 5| Step: 2
Training loss: 2.173490047454834
Validation loss: 1.9369380345908545

Epoch: 5| Step: 3
Training loss: 2.3458187580108643
Validation loss: 1.98753567664854

Epoch: 5| Step: 4
Training loss: 1.9349607229232788
Validation loss: 1.9701072298070437

Epoch: 5| Step: 5
Training loss: 1.8557918071746826
Validation loss: 1.9629606816076464

Epoch: 5| Step: 6
Training loss: 1.8732064962387085
Validation loss: 1.9464532098462504

Epoch: 5| Step: 7
Training loss: 1.928180456161499
Validation loss: 1.9511257179321781

Epoch: 5| Step: 8
Training loss: 1.0713775157928467
Validation loss: 1.9684405326843262

Epoch: 5| Step: 9
Training loss: 1.6644904613494873
Validation loss: 1.9447838260281471

Epoch: 5| Step: 10
Training loss: 1.2788437604904175
Validation loss: 1.9650864011497908

Epoch: 221| Step: 0
Training loss: 1.5478662252426147
Validation loss: 1.9242263942636468

Epoch: 5| Step: 1
Training loss: 1.663700819015503
Validation loss: 1.9643618599061043

Epoch: 5| Step: 2
Training loss: 1.9667901992797852
Validation loss: 1.9513990750876806

Epoch: 5| Step: 3
Training loss: 1.4691441059112549
Validation loss: 1.9361990241594211

Epoch: 5| Step: 4
Training loss: 1.3978978395462036
Validation loss: 1.9161149301836569

Epoch: 5| Step: 5
Training loss: 1.785120964050293
Validation loss: 1.931419918614049

Epoch: 5| Step: 6
Training loss: 1.9941987991333008
Validation loss: 1.9008006806014686

Epoch: 5| Step: 7
Training loss: 2.1290440559387207
Validation loss: 1.9219254896204958

Epoch: 5| Step: 8
Training loss: 1.9755580425262451
Validation loss: 1.9361521813177294

Epoch: 5| Step: 9
Training loss: 2.1795871257781982
Validation loss: 1.9255985367682673

Epoch: 5| Step: 10
Training loss: 1.2991907596588135
Validation loss: 1.928154419827205

Epoch: 222| Step: 0
Training loss: 1.7707535028457642
Validation loss: 1.9181135457049134

Epoch: 5| Step: 1
Training loss: 1.7515857219696045
Validation loss: 1.91807169939882

Epoch: 5| Step: 2
Training loss: 2.088228702545166
Validation loss: 1.9233217931562854

Epoch: 5| Step: 3
Training loss: 1.6295557022094727
Validation loss: 1.9433789022507206

Epoch: 5| Step: 4
Training loss: 1.7138487100601196
Validation loss: 1.9314895470937092

Epoch: 5| Step: 5
Training loss: 1.7926483154296875
Validation loss: 1.9339658124472505

Epoch: 5| Step: 6
Training loss: 2.231566905975342
Validation loss: 1.92389892249979

Epoch: 5| Step: 7
Training loss: 1.7129390239715576
Validation loss: 1.9401484522768246

Epoch: 5| Step: 8
Training loss: 1.66941237449646
Validation loss: 1.930979169825072

Epoch: 5| Step: 9
Training loss: 1.3781248331069946
Validation loss: 1.9232760462709653

Epoch: 5| Step: 10
Training loss: 1.4113950729370117
Validation loss: 1.9455389361227713

Epoch: 223| Step: 0
Training loss: 1.6683921813964844
Validation loss: 1.94169629773786

Epoch: 5| Step: 1
Training loss: 1.5229499340057373
Validation loss: 1.9978793257026262

Epoch: 5| Step: 2
Training loss: 1.6002649068832397
Validation loss: 1.9735100615409114

Epoch: 5| Step: 3
Training loss: 1.8606055974960327
Validation loss: 1.9513809052846764

Epoch: 5| Step: 4
Training loss: 2.359790325164795
Validation loss: 1.9630060221559258

Epoch: 5| Step: 5
Training loss: 2.372861623764038
Validation loss: 1.970343497491652

Epoch: 5| Step: 6
Training loss: 2.063436985015869
Validation loss: 1.9621086684606408

Epoch: 5| Step: 7
Training loss: 1.0715930461883545
Validation loss: 1.9546201126549834

Epoch: 5| Step: 8
Training loss: 2.1727049350738525
Validation loss: 1.9627484647176598

Epoch: 5| Step: 9
Training loss: 1.5138397216796875
Validation loss: 1.9647280426435574

Epoch: 5| Step: 10
Training loss: 1.0985664129257202
Validation loss: 1.9288676836157357

Epoch: 224| Step: 0
Training loss: 1.9037634134292603
Validation loss: 1.9425586269747825

Epoch: 5| Step: 1
Training loss: 1.8857742547988892
Validation loss: 1.9357106403637958

Epoch: 5| Step: 2
Training loss: 2.1958775520324707
Validation loss: 1.945940879083449

Epoch: 5| Step: 3
Training loss: 1.3271236419677734
Validation loss: 1.9304192143101846

Epoch: 5| Step: 4
Training loss: 1.732998251914978
Validation loss: 1.9033529014997586

Epoch: 5| Step: 5
Training loss: 1.9599940776824951
Validation loss: 1.9235201945868872

Epoch: 5| Step: 6
Training loss: 1.3484283685684204
Validation loss: 1.9245347156319568

Epoch: 5| Step: 7
Training loss: 1.6420329809188843
Validation loss: 1.8907334176442956

Epoch: 5| Step: 8
Training loss: 1.8523178100585938
Validation loss: 1.9252594888851207

Epoch: 5| Step: 9
Training loss: 1.2117784023284912
Validation loss: 1.9236474024352206

Epoch: 5| Step: 10
Training loss: 1.997712254524231
Validation loss: 1.9299546095632738

Epoch: 225| Step: 0
Training loss: 1.2511199712753296
Validation loss: 1.9228156279492121

Epoch: 5| Step: 1
Training loss: 1.799043893814087
Validation loss: 1.9245006833025204

Epoch: 5| Step: 2
Training loss: 1.4036357402801514
Validation loss: 1.921485677842171

Epoch: 5| Step: 3
Training loss: 1.969719648361206
Validation loss: 1.945938443624845

Epoch: 5| Step: 4
Training loss: 2.0433292388916016
Validation loss: 1.8944615958839335

Epoch: 5| Step: 5
Training loss: 2.1495399475097656
Validation loss: 1.9133043430184806

Epoch: 5| Step: 6
Training loss: 1.9140304327011108
Validation loss: 1.904915846804137

Epoch: 5| Step: 7
Training loss: 1.823669672012329
Validation loss: 1.9384258524064095

Epoch: 5| Step: 8
Training loss: 1.4643839597702026
Validation loss: 1.917308562545366

Epoch: 5| Step: 9
Training loss: 1.6650975942611694
Validation loss: 1.9404564083263438

Epoch: 5| Step: 10
Training loss: 2.0070955753326416
Validation loss: 1.92448458620297

Epoch: 226| Step: 0
Training loss: 1.8651793003082275
Validation loss: 1.9472822873823104

Epoch: 5| Step: 1
Training loss: 2.625582456588745
Validation loss: 1.932212677053226

Epoch: 5| Step: 2
Training loss: 1.3625751733779907
Validation loss: 1.9447503115541191

Epoch: 5| Step: 3
Training loss: 1.64533269405365
Validation loss: 1.9245364665985107

Epoch: 5| Step: 4
Training loss: 1.0807380676269531
Validation loss: 1.9343342242702362

Epoch: 5| Step: 5
Training loss: 1.784799337387085
Validation loss: 1.952943782652578

Epoch: 5| Step: 6
Training loss: 1.4740939140319824
Validation loss: 1.9347873144252326

Epoch: 5| Step: 7
Training loss: 1.9722321033477783
Validation loss: 1.9622705367303663

Epoch: 5| Step: 8
Training loss: 1.6962928771972656
Validation loss: 1.9261951561897033

Epoch: 5| Step: 9
Training loss: 1.8770049810409546
Validation loss: 1.915601380409733

Epoch: 5| Step: 10
Training loss: 1.872576355934143
Validation loss: 1.9194485295203425

Epoch: 227| Step: 0
Training loss: 1.516897201538086
Validation loss: 1.9327456387140418

Epoch: 5| Step: 1
Training loss: 1.46808660030365
Validation loss: 1.9214320746801232

Epoch: 5| Step: 2
Training loss: 2.070446491241455
Validation loss: 1.925758219534351

Epoch: 5| Step: 3
Training loss: 2.7655141353607178
Validation loss: 1.9162507005917129

Epoch: 5| Step: 4
Training loss: 2.1027278900146484
Validation loss: 1.892274074656989

Epoch: 5| Step: 5
Training loss: 1.518580675125122
Validation loss: 1.9512942260311497

Epoch: 5| Step: 6
Training loss: 1.2520923614501953
Validation loss: 1.8983528383316532

Epoch: 5| Step: 7
Training loss: 1.7061898708343506
Validation loss: 1.9146407342726184

Epoch: 5| Step: 8
Training loss: 1.418291449546814
Validation loss: 1.9092593564782092

Epoch: 5| Step: 9
Training loss: 1.740643858909607
Validation loss: 1.9381955862045288

Epoch: 5| Step: 10
Training loss: 1.5999524593353271
Validation loss: 1.9492429161584506

Epoch: 228| Step: 0
Training loss: 1.323965311050415
Validation loss: 1.9664310921904862

Epoch: 5| Step: 1
Training loss: 1.5656248331069946
Validation loss: 1.9285090020907822

Epoch: 5| Step: 2
Training loss: 1.7450430393218994
Validation loss: 1.9448871215184529

Epoch: 5| Step: 3
Training loss: 1.9554932117462158
Validation loss: 1.9534113022588915

Epoch: 5| Step: 4
Training loss: 1.9436604976654053
Validation loss: 1.9049627281004382

Epoch: 5| Step: 5
Training loss: 1.571656584739685
Validation loss: 1.9107804964947444

Epoch: 5| Step: 6
Training loss: 1.4655673503875732
Validation loss: 1.9399628690494004

Epoch: 5| Step: 7
Training loss: 1.7284024953842163
Validation loss: 1.9311191253764655

Epoch: 5| Step: 8
Training loss: 1.5544064044952393
Validation loss: 1.9156304328672347

Epoch: 5| Step: 9
Training loss: 1.935379981994629
Validation loss: 1.930965168501741

Epoch: 5| Step: 10
Training loss: 2.336763381958008
Validation loss: 1.9554997746662428

Epoch: 229| Step: 0
Training loss: 1.4409842491149902
Validation loss: 1.9186201172490274

Epoch: 5| Step: 1
Training loss: 1.4007765054702759
Validation loss: 1.974248670762585

Epoch: 5| Step: 2
Training loss: 1.781101942062378
Validation loss: 1.9401301748009139

Epoch: 5| Step: 3
Training loss: 2.2831926345825195
Validation loss: 1.97390821672255

Epoch: 5| Step: 4
Training loss: 2.057385206222534
Validation loss: 1.9326348509839786

Epoch: 5| Step: 5
Training loss: 1.4570212364196777
Validation loss: 1.9370368334554857

Epoch: 5| Step: 6
Training loss: 2.1906638145446777
Validation loss: 1.9370735563257688

Epoch: 5| Step: 7
Training loss: 1.934417724609375
Validation loss: 1.9200181217603787

Epoch: 5| Step: 8
Training loss: 1.9806495904922485
Validation loss: 1.9098932589254072

Epoch: 5| Step: 9
Training loss: 1.581815481185913
Validation loss: 1.9242370231177217

Epoch: 5| Step: 10
Training loss: 1.484625220298767
Validation loss: 1.922600289826752

Epoch: 230| Step: 0
Training loss: 1.9856303930282593
Validation loss: 1.9465456149911369

Epoch: 5| Step: 1
Training loss: 2.163168430328369
Validation loss: 1.9380287918993222

Epoch: 5| Step: 2
Training loss: 1.5328586101531982
Validation loss: 1.8855634491930726

Epoch: 5| Step: 3
Training loss: 1.6229909658432007
Validation loss: 1.9532687164122058

Epoch: 5| Step: 4
Training loss: 1.7131969928741455
Validation loss: 1.9017089105421496

Epoch: 5| Step: 5
Training loss: 1.9430946111679077
Validation loss: 1.9298143732932307

Epoch: 5| Step: 6
Training loss: 1.2334885597229004
Validation loss: 1.895640580884872

Epoch: 5| Step: 7
Training loss: 1.7344783544540405
Validation loss: 1.915389108401473

Epoch: 5| Step: 8
Training loss: 1.432274341583252
Validation loss: 1.9016308989576114

Epoch: 5| Step: 9
Training loss: 2.2783870697021484
Validation loss: 1.917763312657674

Epoch: 5| Step: 10
Training loss: 1.4845962524414062
Validation loss: 1.9253712892532349

Epoch: 231| Step: 0
Training loss: 1.6823034286499023
Validation loss: 1.911808039552422

Epoch: 5| Step: 1
Training loss: 1.9998477697372437
Validation loss: 1.8938541053443827

Epoch: 5| Step: 2
Training loss: 2.154479503631592
Validation loss: 1.929685793897157

Epoch: 5| Step: 3
Training loss: 1.787377953529358
Validation loss: 1.9102296816405429

Epoch: 5| Step: 4
Training loss: 2.1209800243377686
Validation loss: 1.9474664375346193

Epoch: 5| Step: 5
Training loss: 1.5983893871307373
Validation loss: 1.9475408497677054

Epoch: 5| Step: 6
Training loss: 1.2725088596343994
Validation loss: 1.8969509217046923

Epoch: 5| Step: 7
Training loss: 1.702331304550171
Validation loss: 1.9094454447428386

Epoch: 5| Step: 8
Training loss: 1.131960153579712
Validation loss: 1.9403741462256319

Epoch: 5| Step: 9
Training loss: 1.4188226461410522
Validation loss: 1.913280003814287

Epoch: 5| Step: 10
Training loss: 1.9708361625671387
Validation loss: 1.9405883435280091

Epoch: 232| Step: 0
Training loss: 1.692935585975647
Validation loss: 1.9363429777083858

Epoch: 5| Step: 1
Training loss: 1.6832081079483032
Validation loss: 1.9269818823824647

Epoch: 5| Step: 2
Training loss: 2.506119728088379
Validation loss: 1.9507636972652969

Epoch: 5| Step: 3
Training loss: 1.8062645196914673
Validation loss: 1.950903493870971

Epoch: 5| Step: 4
Training loss: 2.16790771484375
Validation loss: 1.9308309465326288

Epoch: 5| Step: 5
Training loss: 1.510455846786499
Validation loss: 1.929498957049462

Epoch: 5| Step: 6
Training loss: 1.443566083908081
Validation loss: 1.8912921400480374

Epoch: 5| Step: 7
Training loss: 1.798916220664978
Validation loss: 1.8972297208283537

Epoch: 5| Step: 8
Training loss: 1.2611944675445557
Validation loss: 1.9480252958113147

Epoch: 5| Step: 9
Training loss: 1.1314834356307983
Validation loss: 1.9628235396518503

Epoch: 5| Step: 10
Training loss: 1.7934550046920776
Validation loss: 1.966560653460923

Epoch: 233| Step: 0
Training loss: 1.034340262413025
Validation loss: 1.9228441176875946

Epoch: 5| Step: 1
Training loss: 2.0950849056243896
Validation loss: 1.9285828208410611

Epoch: 5| Step: 2
Training loss: 1.4657313823699951
Validation loss: 1.9371347119731288

Epoch: 5| Step: 3
Training loss: 1.8538312911987305
Validation loss: 1.9235500853548768

Epoch: 5| Step: 4
Training loss: 1.6634470224380493
Validation loss: 1.9665274440601308

Epoch: 5| Step: 5
Training loss: 2.010255813598633
Validation loss: 1.9269915114166916

Epoch: 5| Step: 6
Training loss: 1.2579474449157715
Validation loss: 1.9420678871934132

Epoch: 5| Step: 7
Training loss: 1.7281852960586548
Validation loss: 1.935162687814364

Epoch: 5| Step: 8
Training loss: 1.5827082395553589
Validation loss: 1.9262308728310369

Epoch: 5| Step: 9
Training loss: 1.7514396905899048
Validation loss: 1.9140091826838832

Epoch: 5| Step: 10
Training loss: 2.628084182739258
Validation loss: 1.9276436708306754

Epoch: 234| Step: 0
Training loss: 1.5715785026550293
Validation loss: 1.9349716248050812

Epoch: 5| Step: 1
Training loss: 2.0081329345703125
Validation loss: 1.9054055906111194

Epoch: 5| Step: 2
Training loss: 1.5041598081588745
Validation loss: 1.9411808713789909

Epoch: 5| Step: 3
Training loss: 1.5577303171157837
Validation loss: 1.9243898648087696

Epoch: 5| Step: 4
Training loss: 1.4656388759613037
Validation loss: 1.9121324528930008

Epoch: 5| Step: 5
Training loss: 1.7871296405792236
Validation loss: 1.9343619115890995

Epoch: 5| Step: 6
Training loss: 1.7240276336669922
Validation loss: 1.952581872222244

Epoch: 5| Step: 7
Training loss: 1.4263370037078857
Validation loss: 1.932874301428436

Epoch: 5| Step: 8
Training loss: 1.6088688373565674
Validation loss: 1.942617130535905

Epoch: 5| Step: 9
Training loss: 1.8451271057128906
Validation loss: 1.9058315215572235

Epoch: 5| Step: 10
Training loss: 2.4101436138153076
Validation loss: 1.9348506927490234

Epoch: 235| Step: 0
Training loss: 2.1577565670013428
Validation loss: 1.92529510682629

Epoch: 5| Step: 1
Training loss: 1.4794061183929443
Validation loss: 1.9577491488507999

Epoch: 5| Step: 2
Training loss: 2.0996880531311035
Validation loss: 1.950051946024741

Epoch: 5| Step: 3
Training loss: 1.4985682964324951
Validation loss: 1.9209998000052668

Epoch: 5| Step: 4
Training loss: 1.5400302410125732
Validation loss: 1.9036609254857546

Epoch: 5| Step: 5
Training loss: 1.8295215368270874
Validation loss: 1.9478309244237921

Epoch: 5| Step: 6
Training loss: 1.843804955482483
Validation loss: 1.9381831051200948

Epoch: 5| Step: 7
Training loss: 1.405037760734558
Validation loss: 1.9379834231509958

Epoch: 5| Step: 8
Training loss: 1.8750931024551392
Validation loss: 1.9405027961218229

Epoch: 5| Step: 9
Training loss: 1.612451195716858
Validation loss: 1.9316899725185928

Epoch: 5| Step: 10
Training loss: 1.5783309936523438
Validation loss: 1.947077335849885

Epoch: 236| Step: 0
Training loss: 1.2639468908309937
Validation loss: 1.91420478077345

Epoch: 5| Step: 1
Training loss: 1.5917553901672363
Validation loss: 1.9105440134643226

Epoch: 5| Step: 2
Training loss: 1.9341838359832764
Validation loss: 1.92746776406483

Epoch: 5| Step: 3
Training loss: 1.2585729360580444
Validation loss: 1.9153013229370117

Epoch: 5| Step: 4
Training loss: 1.7443397045135498
Validation loss: 1.9038670370655675

Epoch: 5| Step: 5
Training loss: 1.9927345514297485
Validation loss: 1.9054303630705802

Epoch: 5| Step: 6
Training loss: 2.194547653198242
Validation loss: 1.9061952816542758

Epoch: 5| Step: 7
Training loss: 1.3661483526229858
Validation loss: 1.881897613566409

Epoch: 5| Step: 8
Training loss: 1.556605577468872
Validation loss: 1.9235854430865216

Epoch: 5| Step: 9
Training loss: 2.295454978942871
Validation loss: 1.901388418289923

Epoch: 5| Step: 10
Training loss: 1.540663719177246
Validation loss: 1.909836648612894

Epoch: 237| Step: 0
Training loss: 1.2195861339569092
Validation loss: 1.9551357056504937

Epoch: 5| Step: 1
Training loss: 1.6758654117584229
Validation loss: 1.9058759853404055

Epoch: 5| Step: 2
Training loss: 1.8351331949234009
Validation loss: 1.9364518375806912

Epoch: 5| Step: 3
Training loss: 1.8221038579940796
Validation loss: 1.9084449557847873

Epoch: 5| Step: 4
Training loss: 1.8530027866363525
Validation loss: 1.9026238213303268

Epoch: 5| Step: 5
Training loss: 2.559391498565674
Validation loss: 1.8967791616275747

Epoch: 5| Step: 6
Training loss: 1.9997875690460205
Validation loss: 1.8841715910101449

Epoch: 5| Step: 7
Training loss: 1.3289825916290283
Validation loss: 1.9350408040067202

Epoch: 5| Step: 8
Training loss: 1.6280624866485596
Validation loss: 1.9160274946561424

Epoch: 5| Step: 9
Training loss: 1.410186529159546
Validation loss: 1.9110340931082284

Epoch: 5| Step: 10
Training loss: 1.3303916454315186
Validation loss: 1.926666066210757

Epoch: 238| Step: 0
Training loss: 1.5046885013580322
Validation loss: 1.9204681842557845

Epoch: 5| Step: 1
Training loss: 1.7351281642913818
Validation loss: 1.8826357664600495

Epoch: 5| Step: 2
Training loss: 1.5552985668182373
Validation loss: 1.8582607776887956

Epoch: 5| Step: 3
Training loss: 2.2696938514709473
Validation loss: 1.926503607021865

Epoch: 5| Step: 4
Training loss: 1.2335373163223267
Validation loss: 1.9230575484614219

Epoch: 5| Step: 5
Training loss: 1.8049055337905884
Validation loss: 1.8985620339711506

Epoch: 5| Step: 6
Training loss: 1.4708669185638428
Validation loss: 1.9177395707817488

Epoch: 5| Step: 7
Training loss: 2.0928544998168945
Validation loss: 1.8918422934829549

Epoch: 5| Step: 8
Training loss: 1.6528480052947998
Validation loss: 1.955325666294303

Epoch: 5| Step: 9
Training loss: 1.3817112445831299
Validation loss: 1.9434670991795038

Epoch: 5| Step: 10
Training loss: 1.9701566696166992
Validation loss: 1.902803099283608

Epoch: 239| Step: 0
Training loss: 2.3405022621154785
Validation loss: 1.9277552520075152

Epoch: 5| Step: 1
Training loss: 1.4243923425674438
Validation loss: 1.9056017693652902

Epoch: 5| Step: 2
Training loss: 1.4340636730194092
Validation loss: 1.9511493175260481

Epoch: 5| Step: 3
Training loss: 1.4427685737609863
Validation loss: 1.889995587769375

Epoch: 5| Step: 4
Training loss: 2.2365119457244873
Validation loss: 1.881211821750928

Epoch: 5| Step: 5
Training loss: 1.7974939346313477
Validation loss: 1.937868063167859

Epoch: 5| Step: 6
Training loss: 1.7744957208633423
Validation loss: 1.9290855840970111

Epoch: 5| Step: 7
Training loss: 1.6579151153564453
Validation loss: 1.8979332254778953

Epoch: 5| Step: 8
Training loss: 1.8071315288543701
Validation loss: 1.9079498539688766

Epoch: 5| Step: 9
Training loss: 1.700788140296936
Validation loss: 1.9097203195735972

Epoch: 5| Step: 10
Training loss: 1.2746034860610962
Validation loss: 1.9157635883618427

Epoch: 240| Step: 0
Training loss: 1.9707355499267578
Validation loss: 1.954958951601418

Epoch: 5| Step: 1
Training loss: 1.8752940893173218
Validation loss: 1.9240848902733094

Epoch: 5| Step: 2
Training loss: 1.5772327184677124
Validation loss: 1.912533942089286

Epoch: 5| Step: 3
Training loss: 1.9746475219726562
Validation loss: 1.926733459195783

Epoch: 5| Step: 4
Training loss: 1.9186567068099976
Validation loss: 1.9251420318439443

Epoch: 5| Step: 5
Training loss: 1.5161113739013672
Validation loss: 1.93633355504723

Epoch: 5| Step: 6
Training loss: 1.2132707834243774
Validation loss: 1.9232681925578783

Epoch: 5| Step: 7
Training loss: 1.758582353591919
Validation loss: 1.9354388765109483

Epoch: 5| Step: 8
Training loss: 1.5706994533538818
Validation loss: 1.9260223834745345

Epoch: 5| Step: 9
Training loss: 1.7306535243988037
Validation loss: 1.938486401752759

Epoch: 5| Step: 10
Training loss: 1.7727643251419067
Validation loss: 1.8877150858602216

Epoch: 241| Step: 0
Training loss: 2.1318583488464355
Validation loss: 1.9217235478021766

Epoch: 5| Step: 1
Training loss: 1.725523591041565
Validation loss: 1.9091045023292623

Epoch: 5| Step: 2
Training loss: 1.3109005689620972
Validation loss: 1.955775014815792

Epoch: 5| Step: 3
Training loss: 1.952617883682251
Validation loss: 1.901414543069819

Epoch: 5| Step: 4
Training loss: 2.0524306297302246
Validation loss: 1.936886477214034

Epoch: 5| Step: 5
Training loss: 2.024249315261841
Validation loss: 1.9114647885804534

Epoch: 5| Step: 6
Training loss: 1.6946388483047485
Validation loss: 1.8813241912472634

Epoch: 5| Step: 7
Training loss: 1.3250545263290405
Validation loss: 1.9342836513314197

Epoch: 5| Step: 8
Training loss: 1.7197265625
Validation loss: 1.9091334535229592

Epoch: 5| Step: 9
Training loss: 0.7855384349822998
Validation loss: 1.9066442622933337

Epoch: 5| Step: 10
Training loss: 2.225105047225952
Validation loss: 1.8960472435079596

Epoch: 242| Step: 0
Training loss: 1.7610687017440796
Validation loss: 1.8947617289840535

Epoch: 5| Step: 1
Training loss: 2.0501022338867188
Validation loss: 1.9191969992012106

Epoch: 5| Step: 2
Training loss: 1.5452759265899658
Validation loss: 1.9057098396362797

Epoch: 5| Step: 3
Training loss: 1.4833225011825562
Validation loss: 1.9139639536539714

Epoch: 5| Step: 4
Training loss: 1.9822132587432861
Validation loss: 1.8897035852555306

Epoch: 5| Step: 5
Training loss: 1.692207932472229
Validation loss: 1.9189324032875799

Epoch: 5| Step: 6
Training loss: 1.6132934093475342
Validation loss: 1.8816216581611223

Epoch: 5| Step: 7
Training loss: 1.8555669784545898
Validation loss: 1.9278998016029276

Epoch: 5| Step: 8
Training loss: 1.489640474319458
Validation loss: 1.9326662607090448

Epoch: 5| Step: 9
Training loss: 2.0927538871765137
Validation loss: 1.9348082055327713

Epoch: 5| Step: 10
Training loss: 0.8978103995323181
Validation loss: 1.9220684933406051

Epoch: 243| Step: 0
Training loss: 1.1783862113952637
Validation loss: 1.9293718338012695

Epoch: 5| Step: 1
Training loss: 1.8067200183868408
Validation loss: 1.9248611311758719

Epoch: 5| Step: 2
Training loss: 2.149868965148926
Validation loss: 1.931892063028069

Epoch: 5| Step: 3
Training loss: 1.1623307466506958
Validation loss: 1.909301786012547

Epoch: 5| Step: 4
Training loss: 1.7910715341567993
Validation loss: 1.937571894737982

Epoch: 5| Step: 5
Training loss: 2.21083927154541
Validation loss: 1.9283690350030058

Epoch: 5| Step: 6
Training loss: 1.4682680368423462
Validation loss: 1.9268947429554437

Epoch: 5| Step: 7
Training loss: 1.8611873388290405
Validation loss: 1.884216054793327

Epoch: 5| Step: 8
Training loss: 1.1461886167526245
Validation loss: 1.8966353349788214

Epoch: 5| Step: 9
Training loss: 2.191495418548584
Validation loss: 1.925780196343699

Epoch: 5| Step: 10
Training loss: 1.523723840713501
Validation loss: 1.9312016874231317

Epoch: 244| Step: 0
Training loss: 1.3430507183074951
Validation loss: 1.9385951462612356

Epoch: 5| Step: 1
Training loss: 1.4666025638580322
Validation loss: 1.942963638613301

Epoch: 5| Step: 2
Training loss: 1.5228787660598755
Validation loss: 1.9295598537691179

Epoch: 5| Step: 3
Training loss: 1.6217275857925415
Validation loss: 1.88148453158717

Epoch: 5| Step: 4
Training loss: 2.256060838699341
Validation loss: 1.912425628272436

Epoch: 5| Step: 5
Training loss: 1.78175950050354
Validation loss: 1.9060043032451341

Epoch: 5| Step: 6
Training loss: 2.250640869140625
Validation loss: 1.9025173238528672

Epoch: 5| Step: 7
Training loss: 1.4378163814544678
Validation loss: 1.9232936264366232

Epoch: 5| Step: 8
Training loss: 2.240546464920044
Validation loss: 1.9152058068142142

Epoch: 5| Step: 9
Training loss: 1.3844720125198364
Validation loss: 1.9309072853416525

Epoch: 5| Step: 10
Training loss: 1.5445125102996826
Validation loss: 1.9331547598684988

Epoch: 245| Step: 0
Training loss: 2.0259604454040527
Validation loss: 1.9125024144367506

Epoch: 5| Step: 1
Training loss: 1.9297821521759033
Validation loss: 1.8902242363140147

Epoch: 5| Step: 2
Training loss: 1.8088324069976807
Validation loss: 1.8895421835684008

Epoch: 5| Step: 3
Training loss: 1.7883164882659912
Validation loss: 1.9162235388191797

Epoch: 5| Step: 4
Training loss: 1.8065379858016968
Validation loss: 1.9146734065906976

Epoch: 5| Step: 5
Training loss: 1.4722318649291992
Validation loss: 1.9423127276923067

Epoch: 5| Step: 6
Training loss: 1.3682198524475098
Validation loss: 1.9124839293059481

Epoch: 5| Step: 7
Training loss: 1.777195930480957
Validation loss: 1.9192506587633522

Epoch: 5| Step: 8
Training loss: 1.9914274215698242
Validation loss: 1.9590032741587649

Epoch: 5| Step: 9
Training loss: 1.552663803100586
Validation loss: 1.9307078225638277

Epoch: 5| Step: 10
Training loss: 1.2789771556854248
Validation loss: 1.8976693461018224

Epoch: 246| Step: 0
Training loss: 1.5603865385055542
Validation loss: 1.952059317660588

Epoch: 5| Step: 1
Training loss: 1.7466446161270142
Validation loss: 1.9335622326020272

Epoch: 5| Step: 2
Training loss: 1.6701768636703491
Validation loss: 1.9345388732930666

Epoch: 5| Step: 3
Training loss: 1.5218818187713623
Validation loss: 1.8874410237035444

Epoch: 5| Step: 4
Training loss: 1.8898918628692627
Validation loss: 1.9403220299751527

Epoch: 5| Step: 5
Training loss: 1.6722352504730225
Validation loss: 1.9269526850792669

Epoch: 5| Step: 6
Training loss: 1.9033374786376953
Validation loss: 1.864737650399567

Epoch: 5| Step: 7
Training loss: 1.5690271854400635
Validation loss: 1.9298572642828828

Epoch: 5| Step: 8
Training loss: 1.6961383819580078
Validation loss: 1.895771723921581

Epoch: 5| Step: 9
Training loss: 1.6545593738555908
Validation loss: 1.9378907321601786

Epoch: 5| Step: 10
Training loss: 1.4847326278686523
Validation loss: 1.8946419415935394

Epoch: 247| Step: 0
Training loss: 1.3436894416809082
Validation loss: 1.8730133143804406

Epoch: 5| Step: 1
Training loss: 0.819421112537384
Validation loss: 1.9325153263666297

Epoch: 5| Step: 2
Training loss: 1.968538522720337
Validation loss: 1.8892294950382684

Epoch: 5| Step: 3
Training loss: 1.434993028640747
Validation loss: 1.9388161679749847

Epoch: 5| Step: 4
Training loss: 1.961643934249878
Validation loss: 1.895567645308792

Epoch: 5| Step: 5
Training loss: 1.57939875125885
Validation loss: 1.8836712773128221

Epoch: 5| Step: 6
Training loss: 1.474472999572754
Validation loss: 1.9293888051022765

Epoch: 5| Step: 7
Training loss: 1.9188963174819946
Validation loss: 1.9004926963519024

Epoch: 5| Step: 8
Training loss: 2.2221643924713135
Validation loss: 1.9261221308862009

Epoch: 5| Step: 9
Training loss: 1.7356655597686768
Validation loss: 1.906912648549644

Epoch: 5| Step: 10
Training loss: 1.8644914627075195
Validation loss: 1.898808261399628

Epoch: 248| Step: 0
Training loss: 1.4435203075408936
Validation loss: 1.8862317223702707

Epoch: 5| Step: 1
Training loss: 1.947680115699768
Validation loss: 1.937681596766236

Epoch: 5| Step: 2
Training loss: 1.7430832386016846
Validation loss: 1.9688732982963644

Epoch: 5| Step: 3
Training loss: 1.1640653610229492
Validation loss: 1.9225635861837735

Epoch: 5| Step: 4
Training loss: 1.1940295696258545
Validation loss: 1.9398255014932284

Epoch: 5| Step: 5
Training loss: 1.995383858680725
Validation loss: 1.8944794965046707

Epoch: 5| Step: 6
Training loss: 1.4500850439071655
Validation loss: 1.8923051280360068

Epoch: 5| Step: 7
Training loss: 1.3408877849578857
Validation loss: 1.9066412346337431

Epoch: 5| Step: 8
Training loss: 2.553091049194336
Validation loss: 1.938475485770933

Epoch: 5| Step: 9
Training loss: 2.5913023948669434
Validation loss: 1.9084460940412296

Epoch: 5| Step: 10
Training loss: 1.1294509172439575
Validation loss: 1.9329343060011506

Epoch: 249| Step: 0
Training loss: 1.6877756118774414
Validation loss: 1.9265136129112654

Epoch: 5| Step: 1
Training loss: 1.4018182754516602
Validation loss: 1.8909771186049267

Epoch: 5| Step: 2
Training loss: 1.885765790939331
Validation loss: 1.8829008148562523

Epoch: 5| Step: 3
Training loss: 1.1807410717010498
Validation loss: 1.8914022855861212

Epoch: 5| Step: 4
Training loss: 1.6364707946777344
Validation loss: 1.8645175541600874

Epoch: 5| Step: 5
Training loss: 1.8779714107513428
Validation loss: 1.8778320345827328

Epoch: 5| Step: 6
Training loss: 1.4974192380905151
Validation loss: 1.837442800562869

Epoch: 5| Step: 7
Training loss: 1.8779960870742798
Validation loss: 1.9014882759381366

Epoch: 5| Step: 8
Training loss: 2.2887117862701416
Validation loss: 1.8841957123048845

Epoch: 5| Step: 9
Training loss: 1.3739125728607178
Validation loss: 1.900555162019627

Epoch: 5| Step: 10
Training loss: 1.5446804761886597
Validation loss: 1.8696182133049093

Epoch: 250| Step: 0
Training loss: 1.3932279348373413
Validation loss: 1.892681191044469

Epoch: 5| Step: 1
Training loss: 1.3201547861099243
Validation loss: 1.8607034901136994

Epoch: 5| Step: 2
Training loss: 2.207310438156128
Validation loss: 1.886962939334172

Epoch: 5| Step: 3
Training loss: 1.7610313892364502
Validation loss: 1.9038572695947462

Epoch: 5| Step: 4
Training loss: 1.6900537014007568
Validation loss: 1.9010445225623347

Epoch: 5| Step: 5
Training loss: 1.8393852710723877
Validation loss: 1.8675878278670772

Epoch: 5| Step: 6
Training loss: 1.642888069152832
Validation loss: 1.8961772828973749

Epoch: 5| Step: 7
Training loss: 1.7358388900756836
Validation loss: 1.9665237088357248

Epoch: 5| Step: 8
Training loss: 2.216998338699341
Validation loss: 1.9658797428172121

Epoch: 5| Step: 9
Training loss: 1.2051193714141846
Validation loss: 1.9378327118453158

Epoch: 5| Step: 10
Training loss: 1.1778929233551025
Validation loss: 1.931304072821012

Testing loss: 2.2482311063342624
