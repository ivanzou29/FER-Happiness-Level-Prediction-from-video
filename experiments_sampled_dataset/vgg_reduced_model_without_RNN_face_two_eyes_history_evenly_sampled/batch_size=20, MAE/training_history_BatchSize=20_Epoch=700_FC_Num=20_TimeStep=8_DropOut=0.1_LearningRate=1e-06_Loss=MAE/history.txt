Epoch: 1| Step: 0
Training loss: 5.716886520385742
Validation loss: 5.63748308407363

Epoch: 5| Step: 1
Training loss: 5.894145965576172
Validation loss: 5.631181829719133

Epoch: 5| Step: 2
Training loss: 4.941153049468994
Validation loss: 5.627047097811135

Epoch: 5| Step: 3
Training loss: 4.236793518066406
Validation loss: 5.620262274178126

Epoch: 5| Step: 4
Training loss: 4.378232479095459
Validation loss: 5.614221480584914

Epoch: 5| Step: 5
Training loss: 5.532024383544922
Validation loss: 5.61008640514907

Epoch: 5| Step: 6
Training loss: 6.922495365142822
Validation loss: 5.603702652838923

Epoch: 5| Step: 7
Training loss: 5.163519859313965
Validation loss: 5.598536716994419

Epoch: 5| Step: 8
Training loss: 5.075225830078125
Validation loss: 5.591722170511882

Epoch: 5| Step: 9
Training loss: 6.083744525909424
Validation loss: 5.5867776306726595

Epoch: 5| Step: 10
Training loss: 5.52198600769043
Validation loss: 5.579355973069386

Epoch: 2| Step: 0
Training loss: 5.617563247680664
Validation loss: 5.573454708181401

Epoch: 5| Step: 1
Training loss: 4.538849830627441
Validation loss: 5.568544946691041

Epoch: 5| Step: 2
Training loss: 5.237224578857422
Validation loss: 5.562572407466109

Epoch: 5| Step: 3
Training loss: 5.9494428634643555
Validation loss: 5.55699489449942

Epoch: 5| Step: 4
Training loss: 6.123355865478516
Validation loss: 5.551779987991497

Epoch: 5| Step: 5
Training loss: 4.100031852722168
Validation loss: 5.547094944984682

Epoch: 5| Step: 6
Training loss: 5.632220268249512
Validation loss: 5.540540254244241

Epoch: 5| Step: 7
Training loss: 5.939856052398682
Validation loss: 5.5330004281895135

Epoch: 5| Step: 8
Training loss: 4.455461502075195
Validation loss: 5.527763417972031

Epoch: 5| Step: 9
Training loss: 5.968274116516113
Validation loss: 5.520327137362573

Epoch: 5| Step: 10
Training loss: 5.158263206481934
Validation loss: 5.515537728545486

Epoch: 3| Step: 0
Training loss: 5.950923919677734
Validation loss: 5.5089945588060605

Epoch: 5| Step: 1
Training loss: 4.862666130065918
Validation loss: 5.507050565494004

Epoch: 5| Step: 2
Training loss: 4.909951210021973
Validation loss: 5.497204047377392

Epoch: 5| Step: 3
Training loss: 4.755162239074707
Validation loss: 5.492260973940613

Epoch: 5| Step: 4
Training loss: 5.4200568199157715
Validation loss: 5.485592575483425

Epoch: 5| Step: 5
Training loss: 4.882960796356201
Validation loss: 5.478142902415286

Epoch: 5| Step: 6
Training loss: 4.916574954986572
Validation loss: 5.474341720663091

Epoch: 5| Step: 7
Training loss: 4.84616231918335
Validation loss: 5.466953021223827

Epoch: 5| Step: 8
Training loss: 5.816195487976074
Validation loss: 5.461390972137451

Epoch: 5| Step: 9
Training loss: 5.587969779968262
Validation loss: 5.452839625779019

Epoch: 5| Step: 10
Training loss: 6.19996976852417
Validation loss: 5.448346763528804

Epoch: 4| Step: 0
Training loss: 5.798637390136719
Validation loss: 5.442873395899291

Epoch: 5| Step: 1
Training loss: 4.670257568359375
Validation loss: 5.434767200100806

Epoch: 5| Step: 2
Training loss: 5.809506416320801
Validation loss: 5.43075805582026

Epoch: 5| Step: 3
Training loss: 6.068040370941162
Validation loss: 5.422601915174915

Epoch: 5| Step: 4
Training loss: 4.708127975463867
Validation loss: 5.417019115981235

Epoch: 5| Step: 5
Training loss: 4.955204010009766
Validation loss: 5.411803522417622

Epoch: 5| Step: 6
Training loss: 5.528903007507324
Validation loss: 5.404089558509089

Epoch: 5| Step: 7
Training loss: 4.8438615798950195
Validation loss: 5.395689451566306

Epoch: 5| Step: 8
Training loss: 4.78143310546875
Validation loss: 5.389735257753762

Epoch: 5| Step: 9
Training loss: 4.8568010330200195
Validation loss: 5.383953150882516

Epoch: 5| Step: 10
Training loss: 5.199793815612793
Validation loss: 5.375262727019607

Epoch: 5| Step: 0
Training loss: 4.726496696472168
Validation loss: 5.371564285729521

Epoch: 5| Step: 1
Training loss: 5.377431392669678
Validation loss: 5.365192920930924

Epoch: 5| Step: 2
Training loss: 5.025619983673096
Validation loss: 5.35756714113297

Epoch: 5| Step: 3
Training loss: 4.5568084716796875
Validation loss: 5.350176016489665

Epoch: 5| Step: 4
Training loss: 4.503942012786865
Validation loss: 5.343074516583514

Epoch: 5| Step: 5
Training loss: 5.968700408935547
Validation loss: 5.336381835322226

Epoch: 5| Step: 6
Training loss: 6.256712436676025
Validation loss: 5.328446829190818

Epoch: 5| Step: 7
Training loss: 4.9173150062561035
Validation loss: 5.322822150363717

Epoch: 5| Step: 8
Training loss: 4.898024559020996
Validation loss: 5.313663821066579

Epoch: 5| Step: 9
Training loss: 4.35770845413208
Validation loss: 5.308209496159708

Epoch: 5| Step: 10
Training loss: 5.94757604598999
Validation loss: 5.300823652616111

Epoch: 6| Step: 0
Training loss: 4.5145583152771
Validation loss: 5.293422375955889

Epoch: 5| Step: 1
Training loss: 5.81119966506958
Validation loss: 5.287230322437901

Epoch: 5| Step: 2
Training loss: 4.092223167419434
Validation loss: 5.280208961938017

Epoch: 5| Step: 3
Training loss: 4.961008548736572
Validation loss: 5.27242914835612

Epoch: 5| Step: 4
Training loss: 5.293081760406494
Validation loss: 5.265783873937464

Epoch: 5| Step: 5
Training loss: 4.850290775299072
Validation loss: 5.2560195205032185

Epoch: 5| Step: 6
Training loss: 5.198172092437744
Validation loss: 5.247939089293121

Epoch: 5| Step: 7
Training loss: 5.237523078918457
Validation loss: 5.242615843331942

Epoch: 5| Step: 8
Training loss: 6.055667877197266
Validation loss: 5.236019944631925

Epoch: 5| Step: 9
Training loss: 4.815235137939453
Validation loss: 5.227408983374155

Epoch: 5| Step: 10
Training loss: 4.607123374938965
Validation loss: 5.220043971974363

Epoch: 7| Step: 0
Training loss: 3.9497573375701904
Validation loss: 5.210236585268411

Epoch: 5| Step: 1
Training loss: 5.340453147888184
Validation loss: 5.205368385520033

Epoch: 5| Step: 2
Training loss: 5.872258186340332
Validation loss: 5.196889554300616

Epoch: 5| Step: 3
Training loss: 4.985594272613525
Validation loss: 5.189074418878042

Epoch: 5| Step: 4
Training loss: 5.8828125
Validation loss: 5.181787188335131

Epoch: 5| Step: 5
Training loss: 3.580565929412842
Validation loss: 5.173774862802157

Epoch: 5| Step: 6
Training loss: 5.2024827003479
Validation loss: 5.1643659786511495

Epoch: 5| Step: 7
Training loss: 5.00784969329834
Validation loss: 5.157363968510782

Epoch: 5| Step: 8
Training loss: 4.5749945640563965
Validation loss: 5.14611949715563

Epoch: 5| Step: 9
Training loss: 4.795582294464111
Validation loss: 5.1370588066757366

Epoch: 5| Step: 10
Training loss: 5.455192565917969
Validation loss: 5.129607928696499

Epoch: 8| Step: 0
Training loss: 5.766393184661865
Validation loss: 5.121347827296103

Epoch: 5| Step: 1
Training loss: 4.71412992477417
Validation loss: 5.113291366125948

Epoch: 5| Step: 2
Training loss: 4.382360935211182
Validation loss: 5.103788409181821

Epoch: 5| Step: 3
Training loss: 4.344090461730957
Validation loss: 5.097134062038955

Epoch: 5| Step: 4
Training loss: 5.423833847045898
Validation loss: 5.0888524978391585

Epoch: 5| Step: 5
Training loss: 5.086986541748047
Validation loss: 5.078418259979577

Epoch: 5| Step: 6
Training loss: 4.2955322265625
Validation loss: 5.068870903343282

Epoch: 5| Step: 7
Training loss: 4.899633884429932
Validation loss: 5.060687372761388

Epoch: 5| Step: 8
Training loss: 4.798569202423096
Validation loss: 5.052375619129468

Epoch: 5| Step: 9
Training loss: 4.052487373352051
Validation loss: 5.041068912834249

Epoch: 5| Step: 10
Training loss: 5.875054836273193
Validation loss: 5.031990425561064

Epoch: 9| Step: 0
Training loss: 6.875888824462891
Validation loss: 5.023694648537584

Epoch: 5| Step: 1
Training loss: 4.0367045402526855
Validation loss: 5.010509639657954

Epoch: 5| Step: 2
Training loss: 4.320176124572754
Validation loss: 5.002102939031458

Epoch: 5| Step: 3
Training loss: 4.92388391494751
Validation loss: 4.995669959693827

Epoch: 5| Step: 4
Training loss: 5.818401336669922
Validation loss: 4.985033107060258

Epoch: 5| Step: 5
Training loss: 4.357032299041748
Validation loss: 4.973394542612056

Epoch: 5| Step: 6
Training loss: 5.538690090179443
Validation loss: 4.96083927154541

Epoch: 5| Step: 7
Training loss: 3.7648117542266846
Validation loss: 4.952705962683565

Epoch: 5| Step: 8
Training loss: 4.043756008148193
Validation loss: 4.9414517187303115

Epoch: 5| Step: 9
Training loss: 4.60230016708374
Validation loss: 4.933228595282442

Epoch: 5| Step: 10
Training loss: 3.9318201541900635
Validation loss: 4.9242665383123585

Epoch: 10| Step: 0
Training loss: 4.1199846267700195
Validation loss: 4.914638124486451

Epoch: 5| Step: 1
Training loss: 5.250182151794434
Validation loss: 4.9008636577155

Epoch: 5| Step: 2
Training loss: 4.747908592224121
Validation loss: 4.888851452899235

Epoch: 5| Step: 3
Training loss: 5.011074542999268
Validation loss: 4.880954773195328

Epoch: 5| Step: 4
Training loss: 4.6099748611450195
Validation loss: 4.870194614574474

Epoch: 5| Step: 5
Training loss: 4.489438533782959
Validation loss: 4.857674547421035

Epoch: 5| Step: 6
Training loss: 4.64397668838501
Validation loss: 4.846902903690133

Epoch: 5| Step: 7
Training loss: 4.807363986968994
Validation loss: 4.837114749416228

Epoch: 5| Step: 8
Training loss: 4.719460487365723
Validation loss: 4.820768674214681

Epoch: 5| Step: 9
Training loss: 4.796019077301025
Validation loss: 4.8100699814417025

Epoch: 5| Step: 10
Training loss: 3.713491439819336
Validation loss: 4.800934689019316

Epoch: 11| Step: 0
Training loss: 4.709916114807129
Validation loss: 4.786480519079393

Epoch: 5| Step: 1
Training loss: 4.463747501373291
Validation loss: 4.773497766064059

Epoch: 5| Step: 2
Training loss: 4.321498870849609
Validation loss: 4.7637256140350015

Epoch: 5| Step: 3
Training loss: 3.879340648651123
Validation loss: 4.750374394078409

Epoch: 5| Step: 4
Training loss: 4.341833591461182
Validation loss: 4.740149951750232

Epoch: 5| Step: 5
Training loss: 4.832427978515625
Validation loss: 4.727803543049802

Epoch: 5| Step: 6
Training loss: 4.5566205978393555
Validation loss: 4.716975591515982

Epoch: 5| Step: 7
Training loss: 3.5660972595214844
Validation loss: 4.697961556014194

Epoch: 5| Step: 8
Training loss: 5.3550872802734375
Validation loss: 4.683579224412159

Epoch: 5| Step: 9
Training loss: 5.013370037078857
Validation loss: 4.669891116439655

Epoch: 5| Step: 10
Training loss: 4.466732025146484
Validation loss: 4.655221851923132

Epoch: 12| Step: 0
Training loss: 4.755467891693115
Validation loss: 4.640654927940779

Epoch: 5| Step: 1
Training loss: 5.036028861999512
Validation loss: 4.628151165541782

Epoch: 5| Step: 2
Training loss: 3.8642029762268066
Validation loss: 4.612463743455948

Epoch: 5| Step: 3
Training loss: 4.066985607147217
Validation loss: 4.595607014112575

Epoch: 5| Step: 4
Training loss: 4.4170355796813965
Validation loss: 4.583639203861195

Epoch: 5| Step: 5
Training loss: 5.002560138702393
Validation loss: 4.567668314903013

Epoch: 5| Step: 6
Training loss: 4.888765811920166
Validation loss: 4.547109293681319

Epoch: 5| Step: 7
Training loss: 3.223402738571167
Validation loss: 4.5324930067985285

Epoch: 5| Step: 8
Training loss: 3.837811231613159
Validation loss: 4.516966173725743

Epoch: 5| Step: 9
Training loss: 4.516139984130859
Validation loss: 4.505384747700025

Epoch: 5| Step: 10
Training loss: 4.116695880889893
Validation loss: 4.48296328513853

Epoch: 13| Step: 0
Training loss: 4.460611820220947
Validation loss: 4.471149377925421

Epoch: 5| Step: 1
Training loss: 4.11197566986084
Validation loss: 4.453431293528567

Epoch: 5| Step: 2
Training loss: 4.463193416595459
Validation loss: 4.435646985166816

Epoch: 5| Step: 3
Training loss: 4.506012916564941
Validation loss: 4.4137687990742345

Epoch: 5| Step: 4
Training loss: 3.7985267639160156
Validation loss: 4.406278353865429

Epoch: 5| Step: 5
Training loss: 4.074345588684082
Validation loss: 4.38017745940916

Epoch: 5| Step: 6
Training loss: 3.4089560508728027
Validation loss: 4.367788750638244

Epoch: 5| Step: 7
Training loss: 3.9246666431427
Validation loss: 4.355483019223777

Epoch: 5| Step: 8
Training loss: 2.9026570320129395
Validation loss: 4.329867414248887

Epoch: 5| Step: 9
Training loss: 4.817584037780762
Validation loss: 4.313618713809598

Epoch: 5| Step: 10
Training loss: 5.5133748054504395
Validation loss: 4.297259887059529

Epoch: 14| Step: 0
Training loss: 4.627610683441162
Validation loss: 4.275593506392612

Epoch: 5| Step: 1
Training loss: 3.852574110031128
Validation loss: 4.262794822774907

Epoch: 5| Step: 2
Training loss: 3.2898716926574707
Validation loss: 4.242299720805178

Epoch: 5| Step: 3
Training loss: 2.723008632659912
Validation loss: 4.223444092658259

Epoch: 5| Step: 4
Training loss: 3.7360587120056152
Validation loss: 4.1994677359058015

Epoch: 5| Step: 5
Training loss: 4.491210460662842
Validation loss: 4.183343892456383

Epoch: 5| Step: 6
Training loss: 4.603280067443848
Validation loss: 4.17282977668188

Epoch: 5| Step: 7
Training loss: 4.437642574310303
Validation loss: 4.147423928783786

Epoch: 5| Step: 8
Training loss: 4.244879722595215
Validation loss: 4.1302799665799705

Epoch: 5| Step: 9
Training loss: 4.345153331756592
Validation loss: 4.115950730539137

Epoch: 5| Step: 10
Training loss: 3.360020637512207
Validation loss: 4.095653972318096

Epoch: 15| Step: 0
Training loss: 3.8653392791748047
Validation loss: 4.071955301428354

Epoch: 5| Step: 1
Training loss: 4.994719982147217
Validation loss: 4.054867436808925

Epoch: 5| Step: 2
Training loss: 4.970320224761963
Validation loss: 4.035636363490935

Epoch: 5| Step: 3
Training loss: 3.214106798171997
Validation loss: 4.013619584421957

Epoch: 5| Step: 4
Training loss: 2.9981768131256104
Validation loss: 3.997445103942707

Epoch: 5| Step: 5
Training loss: 3.231558322906494
Validation loss: 3.9750258127848306

Epoch: 5| Step: 6
Training loss: 3.4364166259765625
Validation loss: 3.9575045749705327

Epoch: 5| Step: 7
Training loss: 4.481095314025879
Validation loss: 3.933830563740064

Epoch: 5| Step: 8
Training loss: 3.6071457862854004
Validation loss: 3.9185193148992394

Epoch: 5| Step: 9
Training loss: 3.2849831581115723
Validation loss: 3.8974658904537076

Epoch: 5| Step: 10
Training loss: 3.7600815296173096
Validation loss: 3.8728597292336087

Epoch: 16| Step: 0
Training loss: 3.5546810626983643
Validation loss: 3.854863735937303

Epoch: 5| Step: 1
Training loss: 3.791114091873169
Validation loss: 3.844632053887972

Epoch: 5| Step: 2
Training loss: 4.272110939025879
Validation loss: 3.816233840039981

Epoch: 5| Step: 3
Training loss: 3.641953945159912
Validation loss: 3.7910637804256972

Epoch: 5| Step: 4
Training loss: 3.3490116596221924
Validation loss: 3.7771220489214827

Epoch: 5| Step: 5
Training loss: 3.526336669921875
Validation loss: 3.7585650541449107

Epoch: 5| Step: 6
Training loss: 3.6031155586242676
Validation loss: 3.743033537300684

Epoch: 5| Step: 7
Training loss: 3.9241039752960205
Validation loss: 3.71724090268535

Epoch: 5| Step: 8
Training loss: 3.4143993854522705
Validation loss: 3.693950319802889

Epoch: 5| Step: 9
Training loss: 3.449627637863159
Validation loss: 3.678281517438991

Epoch: 5| Step: 10
Training loss: 3.2239084243774414
Validation loss: 3.6579733228170745

Epoch: 17| Step: 0
Training loss: 2.221701145172119
Validation loss: 3.6406304656818347

Epoch: 5| Step: 1
Training loss: 3.6216888427734375
Validation loss: 3.621655628245364

Epoch: 5| Step: 2
Training loss: 3.72139310836792
Validation loss: 3.5950239704501246

Epoch: 5| Step: 3
Training loss: 3.0962843894958496
Validation loss: 3.5873146980039534

Epoch: 5| Step: 4
Training loss: 3.8405890464782715
Validation loss: 3.5626968799098844

Epoch: 5| Step: 5
Training loss: 3.999316453933716
Validation loss: 3.5388619412658033

Epoch: 5| Step: 6
Training loss: 2.944552183151245
Validation loss: 3.5243844627052225

Epoch: 5| Step: 7
Training loss: 3.5424132347106934
Validation loss: 3.5056163623768795

Epoch: 5| Step: 8
Training loss: 3.8180270195007324
Validation loss: 3.486465782247564

Epoch: 5| Step: 9
Training loss: 3.468111515045166
Validation loss: 3.4563073291573474

Epoch: 5| Step: 10
Training loss: 3.3986704349517822
Validation loss: 3.440738780524141

Epoch: 18| Step: 0
Training loss: 3.35783052444458
Validation loss: 3.4214105426624255

Epoch: 5| Step: 1
Training loss: 2.1705830097198486
Validation loss: 3.391537202301846

Epoch: 5| Step: 2
Training loss: 2.686966896057129
Validation loss: 3.384328193562005

Epoch: 5| Step: 3
Training loss: 2.629089832305908
Validation loss: 3.355752355308943

Epoch: 5| Step: 4
Training loss: 3.41925311088562
Validation loss: 3.3291232790998233

Epoch: 5| Step: 5
Training loss: 3.0385489463806152
Validation loss: 3.307769606190343

Epoch: 5| Step: 6
Training loss: 3.5835235118865967
Validation loss: 3.2946701921442503

Epoch: 5| Step: 7
Training loss: 3.3853423595428467
Validation loss: 3.271260651209021

Epoch: 5| Step: 8
Training loss: 3.7935473918914795
Validation loss: 3.247171301995554

Epoch: 5| Step: 9
Training loss: 2.8946051597595215
Validation loss: 3.2249792750163744

Epoch: 5| Step: 10
Training loss: 4.763033866882324
Validation loss: 3.199259217067431

Epoch: 19| Step: 0
Training loss: 3.4352333545684814
Validation loss: 3.185675774851153

Epoch: 5| Step: 1
Training loss: 3.1448299884796143
Validation loss: 3.161354567414971

Epoch: 5| Step: 2
Training loss: 2.983048915863037
Validation loss: 3.142551496464719

Epoch: 5| Step: 3
Training loss: 1.7713321447372437
Validation loss: 3.1157897903073217

Epoch: 5| Step: 4
Training loss: 3.3299365043640137
Validation loss: 3.0986851671690583

Epoch: 5| Step: 5
Training loss: 3.207681179046631
Validation loss: 3.069861391539215

Epoch: 5| Step: 6
Training loss: 2.9472222328186035
Validation loss: 3.06342137757168

Epoch: 5| Step: 7
Training loss: 3.8866779804229736
Validation loss: 3.041640768768967

Epoch: 5| Step: 8
Training loss: 2.5829224586486816
Validation loss: 3.0168091558641

Epoch: 5| Step: 9
Training loss: 3.3696448802948
Validation loss: 2.9976231692939677

Epoch: 5| Step: 10
Training loss: 2.874483108520508
Validation loss: 2.969186741818664

Epoch: 20| Step: 0
Training loss: 3.114339828491211
Validation loss: 2.9592445896517847

Epoch: 5| Step: 1
Training loss: 1.8780086040496826
Validation loss: 2.929303361523536

Epoch: 5| Step: 2
Training loss: 2.725283145904541
Validation loss: 2.9137645101034515

Epoch: 5| Step: 3
Training loss: 3.200876235961914
Validation loss: 2.8900960004457863

Epoch: 5| Step: 4
Training loss: 3.262742280960083
Validation loss: 2.8791034478013233

Epoch: 5| Step: 5
Training loss: 2.7036776542663574
Validation loss: 2.858800047187395

Epoch: 5| Step: 6
Training loss: 3.5165977478027344
Validation loss: 2.8248362823199202

Epoch: 5| Step: 7
Training loss: 3.0509681701660156
Validation loss: 2.8064190649217173

Epoch: 5| Step: 8
Training loss: 2.9832346439361572
Validation loss: 2.797507729581607

Epoch: 5| Step: 9
Training loss: 2.4647035598754883
Validation loss: 2.7722144665256625

Epoch: 5| Step: 10
Training loss: 3.020139217376709
Validation loss: 2.7524229531647055

Epoch: 21| Step: 0
Training loss: 3.125453472137451
Validation loss: 2.7337793432256228

Epoch: 5| Step: 1
Training loss: 2.530272960662842
Validation loss: 2.709635385902979

Epoch: 5| Step: 2
Training loss: 2.720463991165161
Validation loss: 2.698214848836263

Epoch: 5| Step: 3
Training loss: 2.6408097743988037
Validation loss: 2.6683570159378873

Epoch: 5| Step: 4
Training loss: 2.809260368347168
Validation loss: 2.6463510451778287

Epoch: 5| Step: 5
Training loss: 2.6936981678009033
Validation loss: 2.6340029342200166

Epoch: 5| Step: 6
Training loss: 2.59395170211792
Validation loss: 2.617273199942804

Epoch: 5| Step: 7
Training loss: 2.435206651687622
Validation loss: 2.591006309755387

Epoch: 5| Step: 8
Training loss: 2.2500076293945312
Validation loss: 2.592912043294599

Epoch: 5| Step: 9
Training loss: 3.172145128250122
Validation loss: 2.56867128802884

Epoch: 5| Step: 10
Training loss: 3.5283257961273193
Validation loss: 2.5493560016796155

Epoch: 22| Step: 0
Training loss: 2.535362482070923
Validation loss: 2.523083563773863

Epoch: 5| Step: 1
Training loss: 2.643279552459717
Validation loss: 2.50996159994474

Epoch: 5| Step: 2
Training loss: 3.408504009246826
Validation loss: 2.5041715355329615

Epoch: 5| Step: 3
Training loss: 2.352288246154785
Validation loss: 2.4835550118518133

Epoch: 5| Step: 4
Training loss: 2.708395004272461
Validation loss: 2.459609898187781

Epoch: 5| Step: 5
Training loss: 2.2548623085021973
Validation loss: 2.452043035978912

Epoch: 5| Step: 6
Training loss: 2.76770281791687
Validation loss: 2.4406445308398177

Epoch: 5| Step: 7
Training loss: 3.2385811805725098
Validation loss: 2.427164166204391

Epoch: 5| Step: 8
Training loss: 2.440629720687866
Validation loss: 2.4039955318615003

Epoch: 5| Step: 9
Training loss: 2.1740665435791016
Validation loss: 2.399972613139819

Epoch: 5| Step: 10
Training loss: 2.381377935409546
Validation loss: 2.386316607075353

Epoch: 23| Step: 0
Training loss: 2.978304624557495
Validation loss: 2.376371552867274

Epoch: 5| Step: 1
Training loss: 2.284529685974121
Validation loss: 2.3591055870056152

Epoch: 5| Step: 2
Training loss: 2.1150975227355957
Validation loss: 2.348978632239885

Epoch: 5| Step: 3
Training loss: 2.6400306224823
Validation loss: 2.3321927875600834

Epoch: 5| Step: 4
Training loss: 2.7818427085876465
Validation loss: 2.30984523219447

Epoch: 5| Step: 5
Training loss: 2.9756085872650146
Validation loss: 2.317183494567871

Epoch: 5| Step: 6
Training loss: 2.769353151321411
Validation loss: 2.3000867648791243

Epoch: 5| Step: 7
Training loss: 1.975415825843811
Validation loss: 2.299554983774821

Epoch: 5| Step: 8
Training loss: 2.6962084770202637
Validation loss: 2.2947431533567366

Epoch: 5| Step: 9
Training loss: 2.0377306938171387
Validation loss: 2.275446007328649

Epoch: 5| Step: 10
Training loss: 2.862363815307617
Validation loss: 2.2793839259814193

Epoch: 24| Step: 0
Training loss: 3.034224033355713
Validation loss: 2.2733318856967393

Epoch: 5| Step: 1
Training loss: 2.138406991958618
Validation loss: 2.243663339204686

Epoch: 5| Step: 2
Training loss: 2.823273181915283
Validation loss: 2.248458421358498

Epoch: 5| Step: 3
Training loss: 2.491950035095215
Validation loss: 2.238467388255622

Epoch: 5| Step: 4
Training loss: 1.835314154624939
Validation loss: 2.232237326201572

Epoch: 5| Step: 5
Training loss: 2.662532329559326
Validation loss: 2.2303288341850362

Epoch: 5| Step: 6
Training loss: 3.080277442932129
Validation loss: 2.2155359868080384

Epoch: 5| Step: 7
Training loss: 2.5661063194274902
Validation loss: 2.212332402506182

Epoch: 5| Step: 8
Training loss: 2.409608840942383
Validation loss: 2.2057833492114978

Epoch: 5| Step: 9
Training loss: 2.050370693206787
Validation loss: 2.2047609949624665

Epoch: 5| Step: 10
Training loss: 2.476034641265869
Validation loss: 2.2092810241124963

Epoch: 25| Step: 0
Training loss: 1.8302381038665771
Validation loss: 2.2123334151442333

Epoch: 5| Step: 1
Training loss: 2.428481340408325
Validation loss: 2.1760894739499657

Epoch: 5| Step: 2
Training loss: 2.4861812591552734
Validation loss: 2.1879609951408963

Epoch: 5| Step: 3
Training loss: 3.2016372680664062
Validation loss: 2.181189170447729

Epoch: 5| Step: 4
Training loss: 2.5729312896728516
Validation loss: 2.1741983813624226

Epoch: 5| Step: 5
Training loss: 2.489793300628662
Validation loss: 2.166995161323137

Epoch: 5| Step: 6
Training loss: 1.8429445028305054
Validation loss: 2.1866496045102357

Epoch: 5| Step: 7
Training loss: 2.5575156211853027
Validation loss: 2.1657182247407976

Epoch: 5| Step: 8
Training loss: 2.1688766479492188
Validation loss: 2.155832376531375

Epoch: 5| Step: 9
Training loss: 3.4548239707946777
Validation loss: 2.1563241199780534

Epoch: 5| Step: 10
Training loss: 2.093332290649414
Validation loss: 2.1652987798055015

Epoch: 26| Step: 0
Training loss: 2.6823747158050537
Validation loss: 2.1431108866968462

Epoch: 5| Step: 1
Training loss: 2.4177050590515137
Validation loss: 2.145990694722822

Epoch: 5| Step: 2
Training loss: 2.3451027870178223
Validation loss: 2.1523930359912176

Epoch: 5| Step: 3
Training loss: 2.7841925621032715
Validation loss: 2.1469204425811768

Epoch: 5| Step: 4
Training loss: 2.1881625652313232
Validation loss: 2.139059733319026

Epoch: 5| Step: 5
Training loss: 2.5145633220672607
Validation loss: 2.1533410087708504

Epoch: 5| Step: 6
Training loss: 2.3037524223327637
Validation loss: 2.1489176519455446

Epoch: 5| Step: 7
Training loss: 2.6864819526672363
Validation loss: 2.133363534045476

Epoch: 5| Step: 8
Training loss: 2.2649834156036377
Validation loss: 2.139453862303047

Epoch: 5| Step: 9
Training loss: 2.6631762981414795
Validation loss: 2.1479927237315843

Epoch: 5| Step: 10
Training loss: 2.2673168182373047
Validation loss: 2.1491219958951397

Epoch: 27| Step: 0
Training loss: 2.61806058883667
Validation loss: 2.144634122489601

Epoch: 5| Step: 1
Training loss: 2.2838802337646484
Validation loss: 2.1463276775934363

Epoch: 5| Step: 2
Training loss: 2.638331890106201
Validation loss: 2.14727028723686

Epoch: 5| Step: 3
Training loss: 2.6086268424987793
Validation loss: 2.139303466325165

Epoch: 5| Step: 4
Training loss: 3.3368968963623047
Validation loss: 2.1327712100039244

Epoch: 5| Step: 5
Training loss: 2.142979860305786
Validation loss: 2.1235618681036015

Epoch: 5| Step: 6
Training loss: 2.5172507762908936
Validation loss: 2.1414218025822795

Epoch: 5| Step: 7
Training loss: 2.195528268814087
Validation loss: 2.131793050355809

Epoch: 5| Step: 8
Training loss: 2.3861336708068848
Validation loss: 2.137472560328822

Epoch: 5| Step: 9
Training loss: 1.9582805633544922
Validation loss: 2.1291376083127913

Epoch: 5| Step: 10
Training loss: 2.3016819953918457
Validation loss: 2.137429925703233

Epoch: 28| Step: 0
Training loss: 2.3087306022644043
Validation loss: 2.151094816064322

Epoch: 5| Step: 1
Training loss: 1.9607059955596924
Validation loss: 2.1371651772529847

Epoch: 5| Step: 2
Training loss: 2.3475985527038574
Validation loss: 2.1412683071628695

Epoch: 5| Step: 3
Training loss: 2.309922218322754
Validation loss: 2.14454480396804

Epoch: 5| Step: 4
Training loss: 2.9801769256591797
Validation loss: 2.141154130299886

Epoch: 5| Step: 5
Training loss: 2.600562572479248
Validation loss: 2.140040338680308

Epoch: 5| Step: 6
Training loss: 1.9446628093719482
Validation loss: 2.1388617792437152

Epoch: 5| Step: 7
Training loss: 2.241617202758789
Validation loss: 2.1370247384553314

Epoch: 5| Step: 8
Training loss: 2.8461291790008545
Validation loss: 2.1365303621497205

Epoch: 5| Step: 9
Training loss: 2.360581874847412
Validation loss: 2.1539334174125426

Epoch: 5| Step: 10
Training loss: 3.1723499298095703
Validation loss: 2.150861829839727

Epoch: 29| Step: 0
Training loss: 2.733668804168701
Validation loss: 2.144304249876289

Epoch: 5| Step: 1
Training loss: 2.5137250423431396
Validation loss: 2.15190452401356

Epoch: 5| Step: 2
Training loss: 2.3981196880340576
Validation loss: 2.1456745004141204

Epoch: 5| Step: 3
Training loss: 2.493926763534546
Validation loss: 2.140377195932532

Epoch: 5| Step: 4
Training loss: 2.3342628479003906
Validation loss: 2.1345271307935

Epoch: 5| Step: 5
Training loss: 2.421328544616699
Validation loss: 2.14047654726172

Epoch: 5| Step: 6
Training loss: 3.0303492546081543
Validation loss: 2.1475674542047645

Epoch: 5| Step: 7
Training loss: 2.0709831714630127
Validation loss: 2.125783369105349

Epoch: 5| Step: 8
Training loss: 1.9184024333953857
Validation loss: 2.1495442351987286

Epoch: 5| Step: 9
Training loss: 2.753117799758911
Validation loss: 2.143542755034662

Epoch: 5| Step: 10
Training loss: 2.257007122039795
Validation loss: 2.1239428904748734

Epoch: 30| Step: 0
Training loss: 2.3229851722717285
Validation loss: 2.154275031499965

Epoch: 5| Step: 1
Training loss: 2.488276481628418
Validation loss: 2.1361244199096516

Epoch: 5| Step: 2
Training loss: 2.373002290725708
Validation loss: 2.1379449649523665

Epoch: 5| Step: 3
Training loss: 2.5776724815368652
Validation loss: 2.1474487448251374

Epoch: 5| Step: 4
Training loss: 2.2701218128204346
Validation loss: 2.1384203305808445

Epoch: 5| Step: 5
Training loss: 2.8784613609313965
Validation loss: 2.1294078596176638

Epoch: 5| Step: 6
Training loss: 2.219503164291382
Validation loss: 2.1247827442743445

Epoch: 5| Step: 7
Training loss: 3.2466330528259277
Validation loss: 2.1204803169414563

Epoch: 5| Step: 8
Training loss: 2.268019676208496
Validation loss: 2.1310397399369108

Epoch: 5| Step: 9
Training loss: 2.103734254837036
Validation loss: 2.1334205365950063

Epoch: 5| Step: 10
Training loss: 2.1884193420410156
Validation loss: 2.135019712550666

Epoch: 31| Step: 0
Training loss: 2.16676926612854
Validation loss: 2.136576493581136

Epoch: 5| Step: 1
Training loss: 2.0873818397521973
Validation loss: 2.1460839048508675

Epoch: 5| Step: 2
Training loss: 2.394632339477539
Validation loss: 2.1448901776344544

Epoch: 5| Step: 3
Training loss: 2.3842110633850098
Validation loss: 2.1235242620591195

Epoch: 5| Step: 4
Training loss: 2.7563557624816895
Validation loss: 2.137756537365657

Epoch: 5| Step: 5
Training loss: 2.646149158477783
Validation loss: 2.1251532057280182

Epoch: 5| Step: 6
Training loss: 2.4066004753112793
Validation loss: 2.133060338676617

Epoch: 5| Step: 7
Training loss: 2.2392210960388184
Validation loss: 2.141277805451424

Epoch: 5| Step: 8
Training loss: 2.354377269744873
Validation loss: 2.138459649137271

Epoch: 5| Step: 9
Training loss: 3.0178582668304443
Validation loss: 2.1303048082577285

Epoch: 5| Step: 10
Training loss: 2.410374879837036
Validation loss: 2.1383302416852725

Epoch: 32| Step: 0
Training loss: 2.2549996376037598
Validation loss: 2.1298159783886326

Epoch: 5| Step: 1
Training loss: 2.190885543823242
Validation loss: 2.132920506179974

Epoch: 5| Step: 2
Training loss: 2.3143765926361084
Validation loss: 2.1262626750494844

Epoch: 5| Step: 3
Training loss: 2.5863022804260254
Validation loss: 2.132147007091071

Epoch: 5| Step: 4
Training loss: 3.032409191131592
Validation loss: 2.132486735620806

Epoch: 5| Step: 5
Training loss: 2.017570972442627
Validation loss: 2.1226921466089066

Epoch: 5| Step: 6
Training loss: 1.9061524868011475
Validation loss: 2.1202527220531175

Epoch: 5| Step: 7
Training loss: 2.8250598907470703
Validation loss: 2.1348618474057925

Epoch: 5| Step: 8
Training loss: 2.454972267150879
Validation loss: 2.1354211684196227

Epoch: 5| Step: 9
Training loss: 2.782888889312744
Validation loss: 2.1335182830851567

Epoch: 5| Step: 10
Training loss: 2.3649401664733887
Validation loss: 2.1242683215807845

Epoch: 33| Step: 0
Training loss: 2.2835278511047363
Validation loss: 2.125988256546759

Epoch: 5| Step: 1
Training loss: 2.6028170585632324
Validation loss: 2.137900657551263

Epoch: 5| Step: 2
Training loss: 2.7501020431518555
Validation loss: 2.126544141000317

Epoch: 5| Step: 3
Training loss: 2.6850292682647705
Validation loss: 2.1222531334046395

Epoch: 5| Step: 4
Training loss: 2.393213987350464
Validation loss: 2.1182400000992643

Epoch: 5| Step: 5
Training loss: 2.4032633304595947
Validation loss: 2.1275779995867

Epoch: 5| Step: 6
Training loss: 2.5529863834381104
Validation loss: 2.134213298879644

Epoch: 5| Step: 7
Training loss: 1.9531962871551514
Validation loss: 2.1088852356838923

Epoch: 5| Step: 8
Training loss: 2.218235731124878
Validation loss: 2.1316182305735927

Epoch: 5| Step: 9
Training loss: 2.265119791030884
Validation loss: 2.1168340713747087

Epoch: 5| Step: 10
Training loss: 2.695671319961548
Validation loss: 2.1276693318479802

Epoch: 34| Step: 0
Training loss: 2.9519808292388916
Validation loss: 2.1133478098018195

Epoch: 5| Step: 1
Training loss: 2.9755730628967285
Validation loss: 2.1263275172120784

Epoch: 5| Step: 2
Training loss: 2.7499442100524902
Validation loss: 2.1186224734911354

Epoch: 5| Step: 3
Training loss: 2.3279430866241455
Validation loss: 2.1335087207055863

Epoch: 5| Step: 4
Training loss: 2.114931583404541
Validation loss: 2.1156486131811656

Epoch: 5| Step: 5
Training loss: 1.9662364721298218
Validation loss: 2.1148983816946707

Epoch: 5| Step: 6
Training loss: 2.145723581314087
Validation loss: 2.111860946942401

Epoch: 5| Step: 7
Training loss: 2.901256561279297
Validation loss: 2.124248316211085

Epoch: 5| Step: 8
Training loss: 2.0558385848999023
Validation loss: 2.126217613938034

Epoch: 5| Step: 9
Training loss: 2.1597647666931152
Validation loss: 2.137117729392103

Epoch: 5| Step: 10
Training loss: 2.3331966400146484
Validation loss: 2.132189219997775

Epoch: 35| Step: 0
Training loss: 2.802882671356201
Validation loss: 2.1157702656202417

Epoch: 5| Step: 1
Training loss: 2.3564274311065674
Validation loss: 2.122998845192694

Epoch: 5| Step: 2
Training loss: 2.423649549484253
Validation loss: 2.130862174495574

Epoch: 5| Step: 3
Training loss: 2.74507999420166
Validation loss: 2.1191192186006935

Epoch: 5| Step: 4
Training loss: 2.194093942642212
Validation loss: 2.126665087156398

Epoch: 5| Step: 5
Training loss: 1.9463202953338623
Validation loss: 2.1344915692524244

Epoch: 5| Step: 6
Training loss: 2.2477505207061768
Validation loss: 2.145110040582636

Epoch: 5| Step: 7
Training loss: 2.0732641220092773
Validation loss: 2.125521413741573

Epoch: 5| Step: 8
Training loss: 2.486260414123535
Validation loss: 2.1277538986616236

Epoch: 5| Step: 9
Training loss: 2.4570202827453613
Validation loss: 2.133795207546603

Epoch: 5| Step: 10
Training loss: 2.8566477298736572
Validation loss: 2.120989432898901

Epoch: 36| Step: 0
Training loss: 2.778923988342285
Validation loss: 2.1352311616302817

Epoch: 5| Step: 1
Training loss: 1.8903827667236328
Validation loss: 2.1185047498313327

Epoch: 5| Step: 2
Training loss: 2.1217808723449707
Validation loss: 2.1195823351542153

Epoch: 5| Step: 3
Training loss: 2.17213773727417
Validation loss: 2.1218787534262544

Epoch: 5| Step: 4
Training loss: 1.861065149307251
Validation loss: 2.1261695174760717

Epoch: 5| Step: 5
Training loss: 3.2638614177703857
Validation loss: 2.1328983537612425

Epoch: 5| Step: 6
Training loss: 2.5918631553649902
Validation loss: 2.1279477022027455

Epoch: 5| Step: 7
Training loss: 2.397782325744629
Validation loss: 2.110471355017795

Epoch: 5| Step: 8
Training loss: 1.889739990234375
Validation loss: 2.1180631576045865

Epoch: 5| Step: 9
Training loss: 3.386831283569336
Validation loss: 2.1290487268919587

Epoch: 5| Step: 10
Training loss: 2.146350145339966
Validation loss: 2.1289557692825154

Epoch: 37| Step: 0
Training loss: 2.229511260986328
Validation loss: 2.1279094347389798

Epoch: 5| Step: 1
Training loss: 2.0468883514404297
Validation loss: 2.1268565129208308

Epoch: 5| Step: 2
Training loss: 2.3746252059936523
Validation loss: 2.132040983887129

Epoch: 5| Step: 3
Training loss: 2.7505669593811035
Validation loss: 2.1165591491165983

Epoch: 5| Step: 4
Training loss: 2.6179745197296143
Validation loss: 2.106084051952567

Epoch: 5| Step: 5
Training loss: 2.576528310775757
Validation loss: 2.108368196795064

Epoch: 5| Step: 6
Training loss: 2.180436849594116
Validation loss: 2.1048556245783323

Epoch: 5| Step: 7
Training loss: 2.9254209995269775
Validation loss: 2.1171020897485877

Epoch: 5| Step: 8
Training loss: 1.9210532903671265
Validation loss: 2.100057389146538

Epoch: 5| Step: 9
Training loss: 2.1788618564605713
Validation loss: 2.1054236247975338

Epoch: 5| Step: 10
Training loss: 2.7578232288360596
Validation loss: 2.1217917793540546

Epoch: 38| Step: 0
Training loss: 2.693686008453369
Validation loss: 2.101822885133887

Epoch: 5| Step: 1
Training loss: 2.8941779136657715
Validation loss: 2.1205200456803843

Epoch: 5| Step: 2
Training loss: 2.0269625186920166
Validation loss: 2.117117944584098

Epoch: 5| Step: 3
Training loss: 2.6426033973693848
Validation loss: 2.108724759471032

Epoch: 5| Step: 4
Training loss: 1.6680669784545898
Validation loss: 2.1157445138500584

Epoch: 5| Step: 5
Training loss: 2.435864210128784
Validation loss: 2.1026823982115714

Epoch: 5| Step: 6
Training loss: 2.8328232765197754
Validation loss: 2.107546301298244

Epoch: 5| Step: 7
Training loss: 2.5761420726776123
Validation loss: 2.1212489886950423

Epoch: 5| Step: 8
Training loss: 2.577415704727173
Validation loss: 2.1013649381617063

Epoch: 5| Step: 9
Training loss: 2.311537742614746
Validation loss: 2.110615445721534

Epoch: 5| Step: 10
Training loss: 1.7125513553619385
Validation loss: 2.0994492782059537

Epoch: 39| Step: 0
Training loss: 2.100330352783203
Validation loss: 2.110493811227942

Epoch: 5| Step: 1
Training loss: 2.9674007892608643
Validation loss: 2.1085803713849796

Epoch: 5| Step: 2
Training loss: 1.8640903234481812
Validation loss: 2.1060947551522204

Epoch: 5| Step: 3
Training loss: 2.5944695472717285
Validation loss: 2.100766840801444

Epoch: 5| Step: 4
Training loss: 2.7944445610046387
Validation loss: 2.113983485006517

Epoch: 5| Step: 5
Training loss: 2.7031781673431396
Validation loss: 2.1063572232441237

Epoch: 5| Step: 6
Training loss: 2.1301817893981934
Validation loss: 2.108973262130573

Epoch: 5| Step: 7
Training loss: 2.021878480911255
Validation loss: 2.1217559652943767

Epoch: 5| Step: 8
Training loss: 1.9178078174591064
Validation loss: 2.1078982532665296

Epoch: 5| Step: 9
Training loss: 2.4131808280944824
Validation loss: 2.1167643172766573

Epoch: 5| Step: 10
Training loss: 2.9642789363861084
Validation loss: 2.0946473754862303

Epoch: 40| Step: 0
Training loss: 2.3684892654418945
Validation loss: 2.101748961274342

Epoch: 5| Step: 1
Training loss: 2.4000861644744873
Validation loss: 2.1193886033950315

Epoch: 5| Step: 2
Training loss: 2.225719928741455
Validation loss: 2.105225964259076

Epoch: 5| Step: 3
Training loss: 2.717471122741699
Validation loss: 2.1215804238473215

Epoch: 5| Step: 4
Training loss: 2.5775036811828613
Validation loss: 2.109613205796929

Epoch: 5| Step: 5
Training loss: 2.379328727722168
Validation loss: 2.114805826576807

Epoch: 5| Step: 6
Training loss: 2.6589131355285645
Validation loss: 2.1087133781884306

Epoch: 5| Step: 7
Training loss: 2.7138752937316895
Validation loss: 2.116174392802741

Epoch: 5| Step: 8
Training loss: 1.9094222784042358
Validation loss: 2.117271548958235

Epoch: 5| Step: 9
Training loss: 2.489145040512085
Validation loss: 2.096636704219285

Epoch: 5| Step: 10
Training loss: 1.8231704235076904
Validation loss: 2.104716993147327

Epoch: 41| Step: 0
Training loss: 2.8710873126983643
Validation loss: 2.1155919285230738

Epoch: 5| Step: 1
Training loss: 2.58998966217041
Validation loss: 2.1131454949737876

Epoch: 5| Step: 2
Training loss: 2.005946397781372
Validation loss: 2.0985741076930875

Epoch: 5| Step: 3
Training loss: 1.955934762954712
Validation loss: 2.117805423275117

Epoch: 5| Step: 4
Training loss: 2.5272984504699707
Validation loss: 2.1043639593226935

Epoch: 5| Step: 5
Training loss: 1.7129099369049072
Validation loss: 2.1150078004406345

Epoch: 5| Step: 6
Training loss: 2.48594331741333
Validation loss: 2.1055314079407723

Epoch: 5| Step: 7
Training loss: 2.4666237831115723
Validation loss: 2.1037676501017746

Epoch: 5| Step: 8
Training loss: 2.548325777053833
Validation loss: 2.097351228037188

Epoch: 5| Step: 9
Training loss: 2.6593775749206543
Validation loss: 2.1116544303073677

Epoch: 5| Step: 10
Training loss: 2.5569443702697754
Validation loss: 2.1047957225512435

Epoch: 42| Step: 0
Training loss: 2.8168888092041016
Validation loss: 2.095470669449017

Epoch: 5| Step: 1
Training loss: 2.3736367225646973
Validation loss: 2.0995179325021724

Epoch: 5| Step: 2
Training loss: 2.497960329055786
Validation loss: 2.1031042632236274

Epoch: 5| Step: 3
Training loss: 2.284137725830078
Validation loss: 2.0970268403330157

Epoch: 5| Step: 4
Training loss: 2.4104535579681396
Validation loss: 2.0973100226412535

Epoch: 5| Step: 5
Training loss: 2.2411246299743652
Validation loss: 2.095572239609175

Epoch: 5| Step: 6
Training loss: 1.9938465356826782
Validation loss: 2.1124061794691187

Epoch: 5| Step: 7
Training loss: 2.775693893432617
Validation loss: 2.0894842737464496

Epoch: 5| Step: 8
Training loss: 2.3350977897644043
Validation loss: 2.095089635541362

Epoch: 5| Step: 9
Training loss: 2.344146728515625
Validation loss: 2.0979814593509962

Epoch: 5| Step: 10
Training loss: 2.2989602088928223
Validation loss: 2.101945436129006

Epoch: 43| Step: 0
Training loss: 2.4462599754333496
Validation loss: 2.0996506419233096

Epoch: 5| Step: 1
Training loss: 2.1625702381134033
Validation loss: 2.0948678408899615

Epoch: 5| Step: 2
Training loss: 1.7782337665557861
Validation loss: 2.1077548393639187

Epoch: 5| Step: 3
Training loss: 2.485569477081299
Validation loss: 2.096612920043289

Epoch: 5| Step: 4
Training loss: 1.721643090248108
Validation loss: 2.1082402454909457

Epoch: 5| Step: 5
Training loss: 2.7506604194641113
Validation loss: 2.0730539521863385

Epoch: 5| Step: 6
Training loss: 2.9563894271850586
Validation loss: 2.105947358633882

Epoch: 5| Step: 7
Training loss: 1.6777375936508179
Validation loss: 2.0813918293163343

Epoch: 5| Step: 8
Training loss: 2.7166552543640137
Validation loss: 2.0933810280215357

Epoch: 5| Step: 9
Training loss: 2.394855260848999
Validation loss: 2.088800230333882

Epoch: 5| Step: 10
Training loss: 3.2685389518737793
Validation loss: 2.096953567638192

Epoch: 44| Step: 0
Training loss: 2.7921090126037598
Validation loss: 2.0775488140762493

Epoch: 5| Step: 1
Training loss: 2.3427751064300537
Validation loss: 2.087342507095747

Epoch: 5| Step: 2
Training loss: 1.6952037811279297
Validation loss: 2.0766817318495883

Epoch: 5| Step: 3
Training loss: 2.4439148902893066
Validation loss: 2.0939825657875306

Epoch: 5| Step: 4
Training loss: 2.1664719581604004
Validation loss: 2.0978512046157674

Epoch: 5| Step: 5
Training loss: 1.9865596294403076
Validation loss: 2.0775346602163007

Epoch: 5| Step: 6
Training loss: 2.4359376430511475
Validation loss: 2.090353418422002

Epoch: 5| Step: 7
Training loss: 2.626608371734619
Validation loss: 2.0931985865357103

Epoch: 5| Step: 8
Training loss: 2.7504639625549316
Validation loss: 2.079284550041281

Epoch: 5| Step: 9
Training loss: 2.869295597076416
Validation loss: 2.0905700370829594

Epoch: 5| Step: 10
Training loss: 1.9572125673294067
Validation loss: 2.0835575698524393

Epoch: 45| Step: 0
Training loss: 2.5005898475646973
Validation loss: 2.089310969075849

Epoch: 5| Step: 1
Training loss: 2.1546382904052734
Validation loss: 2.0946921456244683

Epoch: 5| Step: 2
Training loss: 1.9742558002471924
Validation loss: 2.0810584496426325

Epoch: 5| Step: 3
Training loss: 2.5454859733581543
Validation loss: 2.0832063895399853

Epoch: 5| Step: 4
Training loss: 1.9905071258544922
Validation loss: 2.0806447575169225

Epoch: 5| Step: 5
Training loss: 2.2316412925720215
Validation loss: 2.10246733824412

Epoch: 5| Step: 6
Training loss: 2.787895917892456
Validation loss: 2.100351789946197

Epoch: 5| Step: 7
Training loss: 2.804903984069824
Validation loss: 2.087498257237096

Epoch: 5| Step: 8
Training loss: 2.7768094539642334
Validation loss: 2.1025334878634383

Epoch: 5| Step: 9
Training loss: 2.3101649284362793
Validation loss: 2.0990086678535707

Epoch: 5| Step: 10
Training loss: 2.0927608013153076
Validation loss: 2.100142163615073

Epoch: 46| Step: 0
Training loss: 2.2086169719696045
Validation loss: 2.0843818033895185

Epoch: 5| Step: 1
Training loss: 1.9599781036376953
Validation loss: 2.093447300695604

Epoch: 5| Step: 2
Training loss: 3.2283082008361816
Validation loss: 2.0906639945122505

Epoch: 5| Step: 3
Training loss: 2.1997148990631104
Validation loss: 2.091841889965919

Epoch: 5| Step: 4
Training loss: 3.0368690490722656
Validation loss: 2.079707504600607

Epoch: 5| Step: 5
Training loss: 2.4922006130218506
Validation loss: 2.088195464944327

Epoch: 5| Step: 6
Training loss: 1.7789312601089478
Validation loss: 2.08090575023364

Epoch: 5| Step: 7
Training loss: 1.7189964056015015
Validation loss: 2.0709112075067337

Epoch: 5| Step: 8
Training loss: 2.5724406242370605
Validation loss: 2.0674266046093357

Epoch: 5| Step: 9
Training loss: 2.379915714263916
Validation loss: 2.0587036853195517

Epoch: 5| Step: 10
Training loss: 2.424529790878296
Validation loss: 2.0750765915839904

Epoch: 47| Step: 0
Training loss: 2.654785633087158
Validation loss: 2.0787897648349887

Epoch: 5| Step: 1
Training loss: 2.5017476081848145
Validation loss: 2.0804835775847077

Epoch: 5| Step: 2
Training loss: 2.196176528930664
Validation loss: 2.091554799387532

Epoch: 5| Step: 3
Training loss: 2.597890615463257
Validation loss: 2.075257552567349

Epoch: 5| Step: 4
Training loss: 2.4876227378845215
Validation loss: 2.094239543843013

Epoch: 5| Step: 5
Training loss: 2.053640127182007
Validation loss: 2.08806541914581

Epoch: 5| Step: 6
Training loss: 2.285731315612793
Validation loss: 2.070305685843191

Epoch: 5| Step: 7
Training loss: 2.7689502239227295
Validation loss: 2.086648469330162

Epoch: 5| Step: 8
Training loss: 2.2944130897521973
Validation loss: 2.073684130945513

Epoch: 5| Step: 9
Training loss: 1.9043121337890625
Validation loss: 2.090909996340352

Epoch: 5| Step: 10
Training loss: 2.3434550762176514
Validation loss: 2.094641175321353

Epoch: 48| Step: 0
Training loss: 2.60563325881958
Validation loss: 2.0882681569745465

Epoch: 5| Step: 1
Training loss: 2.158736228942871
Validation loss: 2.0773040774048015

Epoch: 5| Step: 2
Training loss: 2.363670825958252
Validation loss: 2.080323082144542

Epoch: 5| Step: 3
Training loss: 1.9058529138565063
Validation loss: 2.075116442095849

Epoch: 5| Step: 4
Training loss: 2.3285555839538574
Validation loss: 2.072173700537733

Epoch: 5| Step: 5
Training loss: 2.3935952186584473
Validation loss: 2.0789939639388875

Epoch: 5| Step: 6
Training loss: 2.369249105453491
Validation loss: 2.0674443539752754

Epoch: 5| Step: 7
Training loss: 2.5399436950683594
Validation loss: 2.074546753719289

Epoch: 5| Step: 8
Training loss: 2.7078909873962402
Validation loss: 2.0613695524072133

Epoch: 5| Step: 9
Training loss: 2.342984437942505
Validation loss: 2.058582039289577

Epoch: 5| Step: 10
Training loss: 2.161025285720825
Validation loss: 2.062090148207962

Epoch: 49| Step: 0
Training loss: 2.080064296722412
Validation loss: 2.059900922159995

Epoch: 5| Step: 1
Training loss: 2.9872899055480957
Validation loss: 2.0718327017240625

Epoch: 5| Step: 2
Training loss: 2.4493956565856934
Validation loss: 2.061853861296049

Epoch: 5| Step: 3
Training loss: 2.1271655559539795
Validation loss: 2.062645011050727

Epoch: 5| Step: 4
Training loss: 2.0162510871887207
Validation loss: 2.060791023315922

Epoch: 5| Step: 5
Training loss: 2.80128812789917
Validation loss: 2.077919570348596

Epoch: 5| Step: 6
Training loss: 1.7181440591812134
Validation loss: 2.052841462114806

Epoch: 5| Step: 7
Training loss: 2.51417875289917
Validation loss: 2.064524548028105

Epoch: 5| Step: 8
Training loss: 2.4023380279541016
Validation loss: 2.071058398933821

Epoch: 5| Step: 9
Training loss: 2.611227512359619
Validation loss: 2.062438705916046

Epoch: 5| Step: 10
Training loss: 2.302825450897217
Validation loss: 2.0802937553774927

Epoch: 50| Step: 0
Training loss: 1.9045295715332031
Validation loss: 2.062905051374948

Epoch: 5| Step: 1
Training loss: 2.7434792518615723
Validation loss: 2.0544140697807394

Epoch: 5| Step: 2
Training loss: 2.340282917022705
Validation loss: 2.068520301131792

Epoch: 5| Step: 3
Training loss: 2.269904375076294
Validation loss: 2.045245470539216

Epoch: 5| Step: 4
Training loss: 2.6513402462005615
Validation loss: 2.056968104454779

Epoch: 5| Step: 5
Training loss: 2.3318228721618652
Validation loss: 2.0562818870749524

Epoch: 5| Step: 6
Training loss: 2.1420135498046875
Validation loss: 2.0525553252107356

Epoch: 5| Step: 7
Training loss: 2.26290225982666
Validation loss: 2.046967714063583

Epoch: 5| Step: 8
Training loss: 2.6531221866607666
Validation loss: 2.0536352844648462

Epoch: 5| Step: 9
Training loss: 1.8296791315078735
Validation loss: 2.0518896451560398

Epoch: 5| Step: 10
Training loss: 2.8323421478271484
Validation loss: 2.057942021277643

Epoch: 51| Step: 0
Training loss: 1.9329866170883179
Validation loss: 2.052053174664897

Epoch: 5| Step: 1
Training loss: 2.1282241344451904
Validation loss: 2.0677680661601405

Epoch: 5| Step: 2
Training loss: 2.6537275314331055
Validation loss: 2.0583562107496363

Epoch: 5| Step: 3
Training loss: 2.1354188919067383
Validation loss: 2.0634421379335466

Epoch: 5| Step: 4
Training loss: 3.5912327766418457
Validation loss: 2.0401301255790134

Epoch: 5| Step: 5
Training loss: 2.3092315196990967
Validation loss: 2.0541129727517404

Epoch: 5| Step: 6
Training loss: 2.2457807064056396
Validation loss: 2.061191483210492

Epoch: 5| Step: 7
Training loss: 2.3200478553771973
Validation loss: 2.0572406758544264

Epoch: 5| Step: 8
Training loss: 1.9847431182861328
Validation loss: 2.0711040753190235

Epoch: 5| Step: 9
Training loss: 2.5023186206817627
Validation loss: 2.052687519340105

Epoch: 5| Step: 10
Training loss: 1.9538769721984863
Validation loss: 2.048187425059657

Epoch: 52| Step: 0
Training loss: 2.3689541816711426
Validation loss: 2.0542932043793383

Epoch: 5| Step: 1
Training loss: 1.8979740142822266
Validation loss: 2.0673446039999686

Epoch: 5| Step: 2
Training loss: 2.176663875579834
Validation loss: 2.0704739683417865

Epoch: 5| Step: 3
Training loss: 2.62626576423645
Validation loss: 2.0535859600190194

Epoch: 5| Step: 4
Training loss: 2.352142810821533
Validation loss: 2.058164054347623

Epoch: 5| Step: 5
Training loss: 2.367657423019409
Validation loss: 2.0479252466591458

Epoch: 5| Step: 6
Training loss: 2.5624682903289795
Validation loss: 2.0641821763848744

Epoch: 5| Step: 7
Training loss: 2.3794777393341064
Validation loss: 2.0501622512776363

Epoch: 5| Step: 8
Training loss: 2.2296464443206787
Validation loss: 2.0576427777608237

Epoch: 5| Step: 9
Training loss: 2.678924798965454
Validation loss: 2.046707090511117

Epoch: 5| Step: 10
Training loss: 2.156485080718994
Validation loss: 2.0469469408835135

Epoch: 53| Step: 0
Training loss: 2.708979368209839
Validation loss: 2.0507568338865876

Epoch: 5| Step: 1
Training loss: 2.2449300289154053
Validation loss: 2.0465270498747468

Epoch: 5| Step: 2
Training loss: 2.0093910694122314
Validation loss: 2.0428483588721162

Epoch: 5| Step: 3
Training loss: 2.540285110473633
Validation loss: 2.0433940989996797

Epoch: 5| Step: 4
Training loss: 2.2947399616241455
Validation loss: 2.0524816359243085

Epoch: 5| Step: 5
Training loss: 1.5217069387435913
Validation loss: 2.0400400443743636

Epoch: 5| Step: 6
Training loss: 2.723045825958252
Validation loss: 2.0514352526716007

Epoch: 5| Step: 7
Training loss: 2.633307695388794
Validation loss: 2.039949247913976

Epoch: 5| Step: 8
Training loss: 2.840439796447754
Validation loss: 2.0534588559981315

Epoch: 5| Step: 9
Training loss: 2.5367560386657715
Validation loss: 2.0596028117723364

Epoch: 5| Step: 10
Training loss: 1.6316455602645874
Validation loss: 2.0388224637636574

Epoch: 54| Step: 0
Training loss: 2.9103481769561768
Validation loss: 2.037223183980552

Epoch: 5| Step: 1
Training loss: 2.4756863117218018
Validation loss: 2.0524792876294864

Epoch: 5| Step: 2
Training loss: 2.3625478744506836
Validation loss: 2.026139638757193

Epoch: 5| Step: 3
Training loss: 2.334049940109253
Validation loss: 2.041371037883143

Epoch: 5| Step: 4
Training loss: 2.735027313232422
Validation loss: 2.0345418594216786

Epoch: 5| Step: 5
Training loss: 1.9960803985595703
Validation loss: 2.043775135470975

Epoch: 5| Step: 6
Training loss: 1.953706979751587
Validation loss: 2.0305069825982534

Epoch: 5| Step: 7
Training loss: 3.1281471252441406
Validation loss: 2.0384870588138537

Epoch: 5| Step: 8
Training loss: 2.3661582469940186
Validation loss: 2.0428168055831746

Epoch: 5| Step: 9
Training loss: 1.2997081279754639
Validation loss: 2.028785490220593

Epoch: 5| Step: 10
Training loss: 2.118790864944458
Validation loss: 2.0441268182569936

Epoch: 55| Step: 0
Training loss: 1.9458034038543701
Validation loss: 2.043366342462519

Epoch: 5| Step: 1
Training loss: 1.9596328735351562
Validation loss: 2.036182194627741

Epoch: 5| Step: 2
Training loss: 2.0030999183654785
Validation loss: 2.038124712564612

Epoch: 5| Step: 3
Training loss: 2.5557408332824707
Validation loss: 2.0297303430495726

Epoch: 5| Step: 4
Training loss: 2.21083664894104
Validation loss: 2.037940755967171

Epoch: 5| Step: 5
Training loss: 2.4269657135009766
Validation loss: 2.0327966136317097

Epoch: 5| Step: 6
Training loss: 2.939272403717041
Validation loss: 2.0225590082906906

Epoch: 5| Step: 7
Training loss: 2.65244722366333
Validation loss: 2.034060525637801

Epoch: 5| Step: 8
Training loss: 2.2920544147491455
Validation loss: 2.034858421612811

Epoch: 5| Step: 9
Training loss: 2.4649415016174316
Validation loss: 2.0387172365701325

Epoch: 5| Step: 10
Training loss: 2.0714309215545654
Validation loss: 2.021681193382509

Epoch: 56| Step: 0
Training loss: 2.570298433303833
Validation loss: 2.028470318804505

Epoch: 5| Step: 1
Training loss: 2.263059139251709
Validation loss: 2.03163509086896

Epoch: 5| Step: 2
Training loss: 2.3076798915863037
Validation loss: 2.036701499774892

Epoch: 5| Step: 3
Training loss: 2.4764950275421143
Validation loss: 2.0295865856191164

Epoch: 5| Step: 4
Training loss: 2.1660983562469482
Validation loss: 2.0369864099769184

Epoch: 5| Step: 5
Training loss: 1.9995170831680298
Validation loss: 2.0392589107636483

Epoch: 5| Step: 6
Training loss: 1.7026121616363525
Validation loss: 2.039949027440881

Epoch: 5| Step: 7
Training loss: 2.397193431854248
Validation loss: 2.0358425250617405

Epoch: 5| Step: 8
Training loss: 2.9120261669158936
Validation loss: 2.0511132286440943

Epoch: 5| Step: 9
Training loss: 2.3666415214538574
Validation loss: 2.0440716974196897

Epoch: 5| Step: 10
Training loss: 2.5364491939544678
Validation loss: 2.0517240134618615

Epoch: 57| Step: 0
Training loss: 2.2557671070098877
Validation loss: 2.045477787653605

Epoch: 5| Step: 1
Training loss: 2.15916109085083
Validation loss: 2.052110369487475

Epoch: 5| Step: 2
Training loss: 2.4933159351348877
Validation loss: 2.039476825344947

Epoch: 5| Step: 3
Training loss: 2.0660572052001953
Validation loss: 2.046701349237914

Epoch: 5| Step: 4
Training loss: 2.8113808631896973
Validation loss: 2.028352036271044

Epoch: 5| Step: 5
Training loss: 2.137195110321045
Validation loss: 2.0361924171447754

Epoch: 5| Step: 6
Training loss: 2.2239930629730225
Validation loss: 2.0428779176486436

Epoch: 5| Step: 7
Training loss: 2.4782490730285645
Validation loss: 2.03325940075741

Epoch: 5| Step: 8
Training loss: 2.3716330528259277
Validation loss: 2.036605997752118

Epoch: 5| Step: 9
Training loss: 2.1939456462860107
Validation loss: 2.034835303983381

Epoch: 5| Step: 10
Training loss: 2.3862552642822266
Validation loss: 2.029546199306365

Epoch: 58| Step: 0
Training loss: 2.195288896560669
Validation loss: 2.0318179284372637

Epoch: 5| Step: 1
Training loss: 2.5488345623016357
Validation loss: 2.0402159485765683

Epoch: 5| Step: 2
Training loss: 2.7979488372802734
Validation loss: 2.011215994434972

Epoch: 5| Step: 3
Training loss: 1.9162801504135132
Validation loss: 2.0285253447871052

Epoch: 5| Step: 4
Training loss: 2.146648406982422
Validation loss: 2.045805203017368

Epoch: 5| Step: 5
Training loss: 2.5859436988830566
Validation loss: 2.0323357223182597

Epoch: 5| Step: 6
Training loss: 2.2590854167938232
Validation loss: 2.0204505151317966

Epoch: 5| Step: 7
Training loss: 1.9894263744354248
Validation loss: 2.019840266114922

Epoch: 5| Step: 8
Training loss: 2.3431670665740967
Validation loss: 2.0219697465178785

Epoch: 5| Step: 9
Training loss: 2.0367722511291504
Validation loss: 2.0314277192597747

Epoch: 5| Step: 10
Training loss: 2.87648606300354
Validation loss: 2.029651816173266

Epoch: 59| Step: 0
Training loss: 2.366266965866089
Validation loss: 2.0142148963866697

Epoch: 5| Step: 1
Training loss: 1.8173038959503174
Validation loss: 2.049800524147608

Epoch: 5| Step: 2
Training loss: 2.0435597896575928
Validation loss: 2.0264434250452186

Epoch: 5| Step: 3
Training loss: 2.600506544113159
Validation loss: 2.0262409640896704

Epoch: 5| Step: 4
Training loss: 2.158533811569214
Validation loss: 2.0226840280717417

Epoch: 5| Step: 5
Training loss: 2.8415157794952393
Validation loss: 2.0156389039049865

Epoch: 5| Step: 6
Training loss: 2.5168251991271973
Validation loss: 2.0214152182302167

Epoch: 5| Step: 7
Training loss: 2.11376953125
Validation loss: 2.017290767802987

Epoch: 5| Step: 8
Training loss: 2.4699456691741943
Validation loss: 2.015383743470715

Epoch: 5| Step: 9
Training loss: 2.255411386489868
Validation loss: 2.0245319489509828

Epoch: 5| Step: 10
Training loss: 2.277045726776123
Validation loss: 2.014645820022911

Epoch: 60| Step: 0
Training loss: 1.909717321395874
Validation loss: 2.006252077318007

Epoch: 5| Step: 1
Training loss: 2.9743576049804688
Validation loss: 2.0117380465230634

Epoch: 5| Step: 2
Training loss: 2.8010175228118896
Validation loss: 2.0099665669984716

Epoch: 5| Step: 3
Training loss: 1.9883289337158203
Validation loss: 2.0066585592044297

Epoch: 5| Step: 4
Training loss: 2.4875895977020264
Validation loss: 2.018725468266395

Epoch: 5| Step: 5
Training loss: 2.4141364097595215
Validation loss: 2.013939913883004

Epoch: 5| Step: 6
Training loss: 2.974163770675659
Validation loss: 2.016950847000204

Epoch: 5| Step: 7
Training loss: 2.0143051147460938
Validation loss: 2.0238201874558643

Epoch: 5| Step: 8
Training loss: 1.8621752262115479
Validation loss: 2.0005357880746164

Epoch: 5| Step: 9
Training loss: 2.0636887550354004
Validation loss: 2.006090615385322

Epoch: 5| Step: 10
Training loss: 1.8634892702102661
Validation loss: 2.0105712747061126

Epoch: 61| Step: 0
Training loss: 2.41162371635437
Validation loss: 1.9988331846011582

Epoch: 5| Step: 1
Training loss: 2.4833693504333496
Validation loss: 2.0233093846228813

Epoch: 5| Step: 2
Training loss: 2.3931007385253906
Validation loss: 2.009894076214042

Epoch: 5| Step: 3
Training loss: 1.9361982345581055
Validation loss: 2.008035009907138

Epoch: 5| Step: 4
Training loss: 1.8836345672607422
Validation loss: 2.0061921022271596

Epoch: 5| Step: 5
Training loss: 2.582925796508789
Validation loss: 2.011352480098765

Epoch: 5| Step: 6
Training loss: 2.690781831741333
Validation loss: 2.020031670088409

Epoch: 5| Step: 7
Training loss: 2.3754000663757324
Validation loss: 2.013550768616379

Epoch: 5| Step: 8
Training loss: 1.9952312707901
Validation loss: 2.009960412979126

Epoch: 5| Step: 9
Training loss: 2.044827938079834
Validation loss: 2.004822410562987

Epoch: 5| Step: 10
Training loss: 2.5429818630218506
Validation loss: 2.016161339257353

Epoch: 62| Step: 0
Training loss: 2.3995585441589355
Validation loss: 2.002314849566388

Epoch: 5| Step: 1
Training loss: 1.7490475177764893
Validation loss: 2.0212459589845393

Epoch: 5| Step: 2
Training loss: 1.830609917640686
Validation loss: 2.002827541802519

Epoch: 5| Step: 3
Training loss: 2.216948986053467
Validation loss: 1.9930089353233256

Epoch: 5| Step: 4
Training loss: 2.4776034355163574
Validation loss: 2.00168921742388

Epoch: 5| Step: 5
Training loss: 2.4874660968780518
Validation loss: 2.0051454100557553

Epoch: 5| Step: 6
Training loss: 2.835758924484253
Validation loss: 1.996460069892227

Epoch: 5| Step: 7
Training loss: 2.173490047454834
Validation loss: 1.9990597796696488

Epoch: 5| Step: 8
Training loss: 2.048677921295166
Validation loss: 1.9956686689007668

Epoch: 5| Step: 9
Training loss: 2.587339162826538
Validation loss: 1.9917620215364682

Epoch: 5| Step: 10
Training loss: 2.593773365020752
Validation loss: 1.9946387903664702

Epoch: 63| Step: 0
Training loss: 3.0947723388671875
Validation loss: 2.009340786164807

Epoch: 5| Step: 1
Training loss: 2.6795601844787598
Validation loss: 1.9996833083450154

Epoch: 5| Step: 2
Training loss: 1.9104745388031006
Validation loss: 2.0099720647258144

Epoch: 5| Step: 3
Training loss: 1.8978404998779297
Validation loss: 2.001539562338142

Epoch: 5| Step: 4
Training loss: 2.8132660388946533
Validation loss: 1.9875700178966726

Epoch: 5| Step: 5
Training loss: 2.0360910892486572
Validation loss: 2.01588955233174

Epoch: 5| Step: 6
Training loss: 2.792356491088867
Validation loss: 2.00249489661186

Epoch: 5| Step: 7
Training loss: 2.2189345359802246
Validation loss: 1.9886459496713453

Epoch: 5| Step: 8
Training loss: 2.439758777618408
Validation loss: 1.991237171234623

Epoch: 5| Step: 9
Training loss: 1.4801061153411865
Validation loss: 1.998817164410827

Epoch: 5| Step: 10
Training loss: 2.0924320220947266
Validation loss: 2.0133601785987936

Epoch: 64| Step: 0
Training loss: 2.9291839599609375
Validation loss: 1.9884142978217012

Epoch: 5| Step: 1
Training loss: 1.9908561706542969
Validation loss: 2.0062255231283044

Epoch: 5| Step: 2
Training loss: 2.1391971111297607
Validation loss: 1.992026311095043

Epoch: 5| Step: 3
Training loss: 2.721625328063965
Validation loss: 2.005133717290817

Epoch: 5| Step: 4
Training loss: 2.410892963409424
Validation loss: 2.0104448603045557

Epoch: 5| Step: 5
Training loss: 1.9937671422958374
Validation loss: 2.00701000741733

Epoch: 5| Step: 6
Training loss: 2.1396923065185547
Validation loss: 1.9889779270336192

Epoch: 5| Step: 7
Training loss: 1.9667112827301025
Validation loss: 1.9938074619539323

Epoch: 5| Step: 8
Training loss: 2.3626232147216797
Validation loss: 1.9816719344867173

Epoch: 5| Step: 9
Training loss: 2.1894400119781494
Validation loss: 2.0112792368858092

Epoch: 5| Step: 10
Training loss: 2.530301809310913
Validation loss: 1.9811170883076166

Epoch: 65| Step: 0
Training loss: 2.4849560260772705
Validation loss: 1.9930993613376413

Epoch: 5| Step: 1
Training loss: 2.2599141597747803
Validation loss: 2.0009762420449206

Epoch: 5| Step: 2
Training loss: 2.9705312252044678
Validation loss: 1.991418997446696

Epoch: 5| Step: 3
Training loss: 2.3042538166046143
Validation loss: 1.9885581795887282

Epoch: 5| Step: 4
Training loss: 1.7594867944717407
Validation loss: 1.999585202945176

Epoch: 5| Step: 5
Training loss: 2.585564136505127
Validation loss: 2.0161777337392173

Epoch: 5| Step: 6
Training loss: 2.462855100631714
Validation loss: 1.9973321691636117

Epoch: 5| Step: 7
Training loss: 1.6842111349105835
Validation loss: 2.002222366230462

Epoch: 5| Step: 8
Training loss: 2.3715341091156006
Validation loss: 1.9871144961285334

Epoch: 5| Step: 9
Training loss: 2.593536615371704
Validation loss: 2.0126079654180877

Epoch: 5| Step: 10
Training loss: 1.6802332401275635
Validation loss: 1.9839329616997832

Epoch: 66| Step: 0
Training loss: 2.398770570755005
Validation loss: 2.0027100975795458

Epoch: 5| Step: 1
Training loss: 2.1241323947906494
Validation loss: 1.9900107499091857

Epoch: 5| Step: 2
Training loss: 2.4572768211364746
Validation loss: 1.9978566759376115

Epoch: 5| Step: 3
Training loss: 1.8337122201919556
Validation loss: 2.0185710076362855

Epoch: 5| Step: 4
Training loss: 2.4065024852752686
Validation loss: 2.0018125413566508

Epoch: 5| Step: 5
Training loss: 2.7978405952453613
Validation loss: 1.999015251795451

Epoch: 5| Step: 6
Training loss: 3.1216530799865723
Validation loss: 2.004664123699229

Epoch: 5| Step: 7
Training loss: 2.337493896484375
Validation loss: 2.0046555393485614

Epoch: 5| Step: 8
Training loss: 2.1084704399108887
Validation loss: 1.993916037262127

Epoch: 5| Step: 9
Training loss: 1.7522445917129517
Validation loss: 2.002362479445755

Epoch: 5| Step: 10
Training loss: 1.9201453924179077
Validation loss: 2.0158140095331336

Epoch: 67| Step: 0
Training loss: 2.5929388999938965
Validation loss: 2.002598850957809

Epoch: 5| Step: 1
Training loss: 2.252262592315674
Validation loss: 2.006532553703554

Epoch: 5| Step: 2
Training loss: 1.7907568216323853
Validation loss: 2.016086491205359

Epoch: 5| Step: 3
Training loss: 2.0711686611175537
Validation loss: 2.011606691986002

Epoch: 5| Step: 4
Training loss: 2.64745831489563
Validation loss: 1.9968122859154978

Epoch: 5| Step: 5
Training loss: 1.525891900062561
Validation loss: 2.000132512020808

Epoch: 5| Step: 6
Training loss: 2.5671546459198
Validation loss: 1.999920787349824

Epoch: 5| Step: 7
Training loss: 2.8017737865448
Validation loss: 2.016327263206564

Epoch: 5| Step: 8
Training loss: 2.285400390625
Validation loss: 2.007473652080823

Epoch: 5| Step: 9
Training loss: 2.5757670402526855
Validation loss: 2.0032509847353865

Epoch: 5| Step: 10
Training loss: 2.0470950603485107
Validation loss: 2.0030143209683

Epoch: 68| Step: 0
Training loss: 2.2323896884918213
Validation loss: 1.9981585446224417

Epoch: 5| Step: 1
Training loss: 2.219339370727539
Validation loss: 2.0061919612269246

Epoch: 5| Step: 2
Training loss: 2.860582113265991
Validation loss: 2.0026022695725962

Epoch: 5| Step: 3
Training loss: 2.1637322902679443
Validation loss: 2.0096766025789323

Epoch: 5| Step: 4
Training loss: 2.477797269821167
Validation loss: 1.9985099159261233

Epoch: 5| Step: 5
Training loss: 2.2125537395477295
Validation loss: 2.009744559564898

Epoch: 5| Step: 6
Training loss: 2.0395798683166504
Validation loss: 2.010758594800067

Epoch: 5| Step: 7
Training loss: 2.096512794494629
Validation loss: 2.007958786461943

Epoch: 5| Step: 8
Training loss: 2.1065258979797363
Validation loss: 2.0218853040408065

Epoch: 5| Step: 9
Training loss: 2.6916022300720215
Validation loss: 2.0132840192446144

Epoch: 5| Step: 10
Training loss: 2.037055492401123
Validation loss: 1.9936179960927656

Epoch: 69| Step: 0
Training loss: 2.4713070392608643
Validation loss: 2.0246462847596858

Epoch: 5| Step: 1
Training loss: 2.3976523876190186
Validation loss: 2.011176839951546

Epoch: 5| Step: 2
Training loss: 1.6311849355697632
Validation loss: 2.0287519501101587

Epoch: 5| Step: 3
Training loss: 1.7623533010482788
Validation loss: 2.0285942874928957

Epoch: 5| Step: 4
Training loss: 2.2849535942077637
Validation loss: 2.010495469134341

Epoch: 5| Step: 5
Training loss: 2.451538562774658
Validation loss: 2.0153656159677813

Epoch: 5| Step: 6
Training loss: 2.788419485092163
Validation loss: 2.020981181052423

Epoch: 5| Step: 7
Training loss: 2.160382032394409
Validation loss: 2.007599038462485

Epoch: 5| Step: 8
Training loss: 2.5884206295013428
Validation loss: 2.02353653600139

Epoch: 5| Step: 9
Training loss: 2.548927068710327
Validation loss: 2.0093229227168585

Epoch: 5| Step: 10
Training loss: 2.035069465637207
Validation loss: 2.010606622183195

Epoch: 70| Step: 0
Training loss: 2.269864320755005
Validation loss: 2.0235464547270086

Epoch: 5| Step: 1
Training loss: 2.516493320465088
Validation loss: 1.9952080929151146

Epoch: 5| Step: 2
Training loss: 2.1284329891204834
Validation loss: 2.0230973664150445

Epoch: 5| Step: 3
Training loss: 3.0140576362609863
Validation loss: 2.0025282444492465

Epoch: 5| Step: 4
Training loss: 2.429863452911377
Validation loss: 2.014893129307737

Epoch: 5| Step: 5
Training loss: 1.8203580379486084
Validation loss: 2.0302205316482054

Epoch: 5| Step: 6
Training loss: 2.0657248497009277
Validation loss: 2.0178604420795234

Epoch: 5| Step: 7
Training loss: 2.2185981273651123
Validation loss: 2.0275113659520305

Epoch: 5| Step: 8
Training loss: 2.351991891860962
Validation loss: 2.033672672446056

Epoch: 5| Step: 9
Training loss: 2.5282704830169678
Validation loss: 2.022375411884759

Epoch: 5| Step: 10
Training loss: 1.8158488273620605
Validation loss: 2.0390442084240656

Epoch: 71| Step: 0
Training loss: 1.2564516067504883
Validation loss: 2.035687727312888

Epoch: 5| Step: 1
Training loss: 2.7884764671325684
Validation loss: 2.0317082097453456

Epoch: 5| Step: 2
Training loss: 2.595170497894287
Validation loss: 2.0085423338797783

Epoch: 5| Step: 3
Training loss: 2.220506429672241
Validation loss: 2.030749636311685

Epoch: 5| Step: 4
Training loss: 2.355365037918091
Validation loss: 2.011960862785257

Epoch: 5| Step: 5
Training loss: 1.9981060028076172
Validation loss: 2.0162387586409047

Epoch: 5| Step: 6
Training loss: 3.32647967338562
Validation loss: 2.020021119425374

Epoch: 5| Step: 7
Training loss: 1.9205570220947266
Validation loss: 2.020595201881983

Epoch: 5| Step: 8
Training loss: 2.251750946044922
Validation loss: 2.022238403238276

Epoch: 5| Step: 9
Training loss: 2.2135233879089355
Validation loss: 2.017082478410454

Epoch: 5| Step: 10
Training loss: 2.1643848419189453
Validation loss: 2.011151998273788

Epoch: 72| Step: 0
Training loss: 2.7181715965270996
Validation loss: 2.0114609041521625

Epoch: 5| Step: 1
Training loss: 1.6846405267715454
Validation loss: 2.0115354599491244

Epoch: 5| Step: 2
Training loss: 2.23022723197937
Validation loss: 1.9988009852747763

Epoch: 5| Step: 3
Training loss: 2.3840532302856445
Validation loss: 1.998879078895815

Epoch: 5| Step: 4
Training loss: 2.432389736175537
Validation loss: 2.013147133652882

Epoch: 5| Step: 5
Training loss: 2.2730517387390137
Validation loss: 2.014596854486773

Epoch: 5| Step: 6
Training loss: 2.4411909580230713
Validation loss: 2.017628950457419

Epoch: 5| Step: 7
Training loss: 2.043811082839966
Validation loss: 1.9992159669117262

Epoch: 5| Step: 8
Training loss: 2.6138460636138916
Validation loss: 2.000608346795523

Epoch: 5| Step: 9
Training loss: 2.172921657562256
Validation loss: 2.0202253172474522

Epoch: 5| Step: 10
Training loss: 2.088611364364624
Validation loss: 2.0021657969361994

Epoch: 73| Step: 0
Training loss: 2.3348259925842285
Validation loss: 2.008831649698237

Epoch: 5| Step: 1
Training loss: 2.341608762741089
Validation loss: 1.9841440441787883

Epoch: 5| Step: 2
Training loss: 2.478492498397827
Validation loss: 2.004303277179759

Epoch: 5| Step: 3
Training loss: 2.7650437355041504
Validation loss: 1.9930371238339333

Epoch: 5| Step: 4
Training loss: 2.1078286170959473
Validation loss: 2.000315458543839

Epoch: 5| Step: 5
Training loss: 2.259260654449463
Validation loss: 1.9955316358996975

Epoch: 5| Step: 6
Training loss: 1.931449294090271
Validation loss: 2.0104983686119

Epoch: 5| Step: 7
Training loss: 1.9718888998031616
Validation loss: 2.0198867397923626

Epoch: 5| Step: 8
Training loss: 1.8905874490737915
Validation loss: 1.9998739329717492

Epoch: 5| Step: 9
Training loss: 2.6780037879943848
Validation loss: 2.0149565730043637

Epoch: 5| Step: 10
Training loss: 2.2183589935302734
Validation loss: 2.0155068033485004

Epoch: 74| Step: 0
Training loss: 2.636901378631592
Validation loss: 2.0238034225279287

Epoch: 5| Step: 1
Training loss: 2.3994460105895996
Validation loss: 2.0055364562619116

Epoch: 5| Step: 2
Training loss: 2.135584592819214
Validation loss: 2.011437480167676

Epoch: 5| Step: 3
Training loss: 2.3056507110595703
Validation loss: 1.9993039997675086

Epoch: 5| Step: 4
Training loss: 1.9872026443481445
Validation loss: 2.0366795934656614

Epoch: 5| Step: 5
Training loss: 2.230684757232666
Validation loss: 2.000424092815768

Epoch: 5| Step: 6
Training loss: 2.5607857704162598
Validation loss: 2.02495006592043

Epoch: 5| Step: 7
Training loss: 2.4308485984802246
Validation loss: 2.0000237675123316

Epoch: 5| Step: 8
Training loss: 2.430145740509033
Validation loss: 2.017857579774754

Epoch: 5| Step: 9
Training loss: 2.1167373657226562
Validation loss: 2.017201066017151

Epoch: 5| Step: 10
Training loss: 1.6460458040237427
Validation loss: 2.0100146160330823

Epoch: 75| Step: 0
Training loss: 2.944779872894287
Validation loss: 2.01170854414663

Epoch: 5| Step: 1
Training loss: 2.2020835876464844
Validation loss: 2.021455685297648

Epoch: 5| Step: 2
Training loss: 2.774752140045166
Validation loss: 2.006113935542363

Epoch: 5| Step: 3
Training loss: 2.01887845993042
Validation loss: 2.008543743882128

Epoch: 5| Step: 4
Training loss: 2.7196226119995117
Validation loss: 1.99819762732393

Epoch: 5| Step: 5
Training loss: 1.6114590167999268
Validation loss: 2.000347750161284

Epoch: 5| Step: 6
Training loss: 1.6463696956634521
Validation loss: 2.0098631971625873

Epoch: 5| Step: 7
Training loss: 2.3353331089019775
Validation loss: 2.002474086259001

Epoch: 5| Step: 8
Training loss: 2.4043872356414795
Validation loss: 2.0083577914904525

Epoch: 5| Step: 9
Training loss: 2.3810229301452637
Validation loss: 1.9900648491356963

Epoch: 5| Step: 10
Training loss: 1.9939374923706055
Validation loss: 2.0111502485890544

Epoch: 76| Step: 0
Training loss: 2.085937976837158
Validation loss: 1.9866804204961306

Epoch: 5| Step: 1
Training loss: 1.9453045129776
Validation loss: 2.0110582049174974

Epoch: 5| Step: 2
Training loss: 2.1174559593200684
Validation loss: 2.001489762336977

Epoch: 5| Step: 3
Training loss: 2.3667283058166504
Validation loss: 1.9878037668043567

Epoch: 5| Step: 4
Training loss: 2.683310031890869
Validation loss: 1.994073998543524

Epoch: 5| Step: 5
Training loss: 2.275705337524414
Validation loss: 2.0055729522499988

Epoch: 5| Step: 6
Training loss: 2.0471689701080322
Validation loss: 1.9902200006669568

Epoch: 5| Step: 7
Training loss: 2.3980820178985596
Validation loss: 1.998880224843179

Epoch: 5| Step: 8
Training loss: 1.8772084712982178
Validation loss: 2.0050282785969396

Epoch: 5| Step: 9
Training loss: 2.4824986457824707
Validation loss: 2.0015391188283123

Epoch: 5| Step: 10
Training loss: 2.6331324577331543
Validation loss: 1.980674196315068

Epoch: 77| Step: 0
Training loss: 2.6650490760803223
Validation loss: 2.0176509388031496

Epoch: 5| Step: 1
Training loss: 2.5959064960479736
Validation loss: 2.0184864626135877

Epoch: 5| Step: 2
Training loss: 1.990439772605896
Validation loss: 2.0010795618898127

Epoch: 5| Step: 3
Training loss: 1.901399850845337
Validation loss: 2.001506616992335

Epoch: 5| Step: 4
Training loss: 1.9748637676239014
Validation loss: 1.9958301603153188

Epoch: 5| Step: 5
Training loss: 2.57907772064209
Validation loss: 1.9984562794367473

Epoch: 5| Step: 6
Training loss: 2.449288845062256
Validation loss: 2.0091387264190184

Epoch: 5| Step: 7
Training loss: 2.4209463596343994
Validation loss: 1.9873494358472927

Epoch: 5| Step: 8
Training loss: 2.148876667022705
Validation loss: 2.00983690702787

Epoch: 5| Step: 9
Training loss: 1.987341284751892
Validation loss: 2.000595631137971

Epoch: 5| Step: 10
Training loss: 2.2470462322235107
Validation loss: 1.9904001694853588

Epoch: 78| Step: 0
Training loss: 2.561032772064209
Validation loss: 2.002238114674886

Epoch: 5| Step: 1
Training loss: 2.0641469955444336
Validation loss: 2.0001121003140687

Epoch: 5| Step: 2
Training loss: 2.121441602706909
Validation loss: 2.010204775359041

Epoch: 5| Step: 3
Training loss: 2.0545592308044434
Validation loss: 2.008360985786684

Epoch: 5| Step: 4
Training loss: 2.42667818069458
Validation loss: 2.0249024591138287

Epoch: 5| Step: 5
Training loss: 2.2480838298797607
Validation loss: 1.9957082784304054

Epoch: 5| Step: 6
Training loss: 2.138540267944336
Validation loss: 2.0074956609356787

Epoch: 5| Step: 7
Training loss: 2.360436201095581
Validation loss: 2.026762544467885

Epoch: 5| Step: 8
Training loss: 2.140254497528076
Validation loss: 2.0250487455757717

Epoch: 5| Step: 9
Training loss: 2.665890693664551
Validation loss: 2.0340595629907425

Epoch: 5| Step: 10
Training loss: 2.1841933727264404
Validation loss: 2.0258596456179054

Epoch: 79| Step: 0
Training loss: 1.885282278060913
Validation loss: 2.0085985763098604

Epoch: 5| Step: 1
Training loss: 1.7091245651245117
Validation loss: 2.0107731101333455

Epoch: 5| Step: 2
Training loss: 2.6850197315216064
Validation loss: 2.0275679198644494

Epoch: 5| Step: 3
Training loss: 2.3757331371307373
Validation loss: 2.0174756947384087

Epoch: 5| Step: 4
Training loss: 2.4230620861053467
Validation loss: 2.0193189997826853

Epoch: 5| Step: 5
Training loss: 1.9840824604034424
Validation loss: 2.0020270552686465

Epoch: 5| Step: 6
Training loss: 2.1403846740722656
Validation loss: 2.034593815444618

Epoch: 5| Step: 7
Training loss: 2.768336772918701
Validation loss: 2.021445806308459

Epoch: 5| Step: 8
Training loss: 2.062720775604248
Validation loss: 2.0173607564741567

Epoch: 5| Step: 9
Training loss: 2.763664722442627
Validation loss: 2.003870535922307

Epoch: 5| Step: 10
Training loss: 2.152942419052124
Validation loss: 1.9951924021526048

Epoch: 80| Step: 0
Training loss: 2.7507731914520264
Validation loss: 1.9951918073879775

Epoch: 5| Step: 1
Training loss: 2.616266965866089
Validation loss: 1.9933955874494327

Epoch: 5| Step: 2
Training loss: 1.9898649454116821
Validation loss: 2.019332972905969

Epoch: 5| Step: 3
Training loss: 2.045132637023926
Validation loss: 2.0165208757564588

Epoch: 5| Step: 4
Training loss: 1.9010493755340576
Validation loss: 2.0098072867239676

Epoch: 5| Step: 5
Training loss: 2.4374759197235107
Validation loss: 1.9995979391118532

Epoch: 5| Step: 6
Training loss: 2.552063465118408
Validation loss: 1.9987905602301321

Epoch: 5| Step: 7
Training loss: 2.258998394012451
Validation loss: 1.9980132605439873

Epoch: 5| Step: 8
Training loss: 2.2839088439941406
Validation loss: 2.0069434540246123

Epoch: 5| Step: 9
Training loss: 2.0456650257110596
Validation loss: 2.0195993300407165

Epoch: 5| Step: 10
Training loss: 1.9221837520599365
Validation loss: 1.9999079768375685

Epoch: 81| Step: 0
Training loss: 1.4965795278549194
Validation loss: 2.0107980851204164

Epoch: 5| Step: 1
Training loss: 2.007389545440674
Validation loss: 1.9978587396683232

Epoch: 5| Step: 2
Training loss: 2.890819549560547
Validation loss: 1.997589139528172

Epoch: 5| Step: 3
Training loss: 1.663063645362854
Validation loss: 2.012097635576802

Epoch: 5| Step: 4
Training loss: 1.635107398033142
Validation loss: 2.0073085600329983

Epoch: 5| Step: 5
Training loss: 2.333575963973999
Validation loss: 2.000495281270755

Epoch: 5| Step: 6
Training loss: 2.485905170440674
Validation loss: 2.007701317469279

Epoch: 5| Step: 7
Training loss: 2.387519359588623
Validation loss: 2.000671486700735

Epoch: 5| Step: 8
Training loss: 3.033475160598755
Validation loss: 2.0053792358726583

Epoch: 5| Step: 9
Training loss: 2.7615485191345215
Validation loss: 2.01069208627106

Epoch: 5| Step: 10
Training loss: 2.083599328994751
Validation loss: 2.0158888563033073

Epoch: 82| Step: 0
Training loss: 2.3551459312438965
Validation loss: 1.9861346906231296

Epoch: 5| Step: 1
Training loss: 2.302150011062622
Validation loss: 2.0040051424375145

Epoch: 5| Step: 2
Training loss: 1.5297250747680664
Validation loss: 2.000708249307448

Epoch: 5| Step: 3
Training loss: 2.5864665508270264
Validation loss: 1.9914548820064915

Epoch: 5| Step: 4
Training loss: 2.3517017364501953
Validation loss: 1.999371502989082

Epoch: 5| Step: 5
Training loss: 2.2803008556365967
Validation loss: 1.9946773359852452

Epoch: 5| Step: 6
Training loss: 2.296416997909546
Validation loss: 1.9968479141112296

Epoch: 5| Step: 7
Training loss: 2.050429582595825
Validation loss: 1.9805699407413442

Epoch: 5| Step: 8
Training loss: 2.527250289916992
Validation loss: 2.0105157718863538

Epoch: 5| Step: 9
Training loss: 2.164034605026245
Validation loss: 1.985114679541639

Epoch: 5| Step: 10
Training loss: 2.427919626235962
Validation loss: 1.9830061633099791

Epoch: 83| Step: 0
Training loss: 2.693232774734497
Validation loss: 1.9755519692615797

Epoch: 5| Step: 1
Training loss: 2.171926975250244
Validation loss: 2.0053597047764766

Epoch: 5| Step: 2
Training loss: 1.8799606561660767
Validation loss: 1.9947427421487787

Epoch: 5| Step: 3
Training loss: 1.9518626928329468
Validation loss: 1.9941731242723362

Epoch: 5| Step: 4
Training loss: 1.610700011253357
Validation loss: 1.9916359545082174

Epoch: 5| Step: 5
Training loss: 2.1566355228424072
Validation loss: 1.9873535863814815

Epoch: 5| Step: 6
Training loss: 2.9615931510925293
Validation loss: 1.9985517019866614

Epoch: 5| Step: 7
Training loss: 2.0472898483276367
Validation loss: 1.9803983575554305

Epoch: 5| Step: 8
Training loss: 2.6034598350524902
Validation loss: 1.9746979603203394

Epoch: 5| Step: 9
Training loss: 2.3675339221954346
Validation loss: 1.994109485739021

Epoch: 5| Step: 10
Training loss: 2.196439743041992
Validation loss: 1.9771936529426164

Epoch: 84| Step: 0
Training loss: 2.382638931274414
Validation loss: 1.9953628957912486

Epoch: 5| Step: 1
Training loss: 2.1854636669158936
Validation loss: 1.9738307332479825

Epoch: 5| Step: 2
Training loss: 1.6540281772613525
Validation loss: 1.991130526347827

Epoch: 5| Step: 3
Training loss: 1.8980028629302979
Validation loss: 1.9945919321429344

Epoch: 5| Step: 4
Training loss: 2.618687868118286
Validation loss: 1.9981204027770667

Epoch: 5| Step: 5
Training loss: 1.8294391632080078
Validation loss: 1.9985983730644308

Epoch: 5| Step: 6
Training loss: 2.343597173690796
Validation loss: 2.022419286030595

Epoch: 5| Step: 7
Training loss: 2.2784929275512695
Validation loss: 2.0077627089715775

Epoch: 5| Step: 8
Training loss: 2.6967289447784424
Validation loss: 2.012921407658567

Epoch: 5| Step: 9
Training loss: 2.3029396533966064
Validation loss: 2.0327515345747753

Epoch: 5| Step: 10
Training loss: 2.5221667289733887
Validation loss: 2.025110908733901

Epoch: 85| Step: 0
Training loss: 2.2061023712158203
Validation loss: 2.02657260048774

Epoch: 5| Step: 1
Training loss: 1.8886219263076782
Validation loss: 2.0196823355972127

Epoch: 5| Step: 2
Training loss: 2.334624767303467
Validation loss: 2.008957746208355

Epoch: 5| Step: 3
Training loss: 1.895622968673706
Validation loss: 2.0226662389693724

Epoch: 5| Step: 4
Training loss: 2.626433849334717
Validation loss: 2.0090474492760113

Epoch: 5| Step: 5
Training loss: 1.9685083627700806
Validation loss: 2.019109986161673

Epoch: 5| Step: 6
Training loss: 2.7077438831329346
Validation loss: 1.9961089293162029

Epoch: 5| Step: 7
Training loss: 2.8524129390716553
Validation loss: 2.004786829794607

Epoch: 5| Step: 8
Training loss: 2.4548869132995605
Validation loss: 1.9989546396399056

Epoch: 5| Step: 9
Training loss: 1.2742059230804443
Validation loss: 1.999087493906739

Epoch: 5| Step: 10
Training loss: 2.6577534675598145
Validation loss: 2.01686429977417

Epoch: 86| Step: 0
Training loss: 2.4896132946014404
Validation loss: 2.0188877172367548

Epoch: 5| Step: 1
Training loss: 1.8815624713897705
Validation loss: 1.982879343853202

Epoch: 5| Step: 2
Training loss: 3.072178840637207
Validation loss: 1.9954829164730605

Epoch: 5| Step: 3
Training loss: 2.178044319152832
Validation loss: 1.9960475224320606

Epoch: 5| Step: 4
Training loss: 1.6728490591049194
Validation loss: 2.0014982005601287

Epoch: 5| Step: 5
Training loss: 1.672739028930664
Validation loss: 1.994748386003638

Epoch: 5| Step: 6
Training loss: 2.307098865509033
Validation loss: 2.0118921931071947

Epoch: 5| Step: 7
Training loss: 2.769721031188965
Validation loss: 2.0128258069356284

Epoch: 5| Step: 8
Training loss: 2.329343318939209
Validation loss: 2.0058081611510246

Epoch: 5| Step: 9
Training loss: 1.9329391717910767
Validation loss: 2.0199635003202703

Epoch: 5| Step: 10
Training loss: 2.2434983253479004
Validation loss: 2.0134236453681864

Epoch: 87| Step: 0
Training loss: 2.0550315380096436
Validation loss: 1.999801674196797

Epoch: 5| Step: 1
Training loss: 2.669072389602661
Validation loss: 2.006630487339471

Epoch: 5| Step: 2
Training loss: 2.1602625846862793
Validation loss: 1.989733761356723

Epoch: 5| Step: 3
Training loss: 1.9235397577285767
Validation loss: 1.9963966864411549

Epoch: 5| Step: 4
Training loss: 2.891385316848755
Validation loss: 2.0059925894583426

Epoch: 5| Step: 5
Training loss: 1.9196847677230835
Validation loss: 2.011565705781342

Epoch: 5| Step: 6
Training loss: 1.3388679027557373
Validation loss: 2.005091195465416

Epoch: 5| Step: 7
Training loss: 2.1581695079803467
Validation loss: 2.0205585469481764

Epoch: 5| Step: 8
Training loss: 2.1756205558776855
Validation loss: 2.0039389799999934

Epoch: 5| Step: 9
Training loss: 2.952117443084717
Validation loss: 1.9897831973209177

Epoch: 5| Step: 10
Training loss: 2.487818479537964
Validation loss: 2.0121648055250927

Epoch: 88| Step: 0
Training loss: 2.214775800704956
Validation loss: 2.0195158207288353

Epoch: 5| Step: 1
Training loss: 2.6099581718444824
Validation loss: 2.00342643901866

Epoch: 5| Step: 2
Training loss: 2.676427125930786
Validation loss: 2.0033748226781047

Epoch: 5| Step: 3
Training loss: 2.236630916595459
Validation loss: 2.0175451604268884

Epoch: 5| Step: 4
Training loss: 2.4966368675231934
Validation loss: 2.007852690194243

Epoch: 5| Step: 5
Training loss: 1.9650089740753174
Validation loss: 1.9966651021793325

Epoch: 5| Step: 6
Training loss: 1.6694278717041016
Validation loss: 2.013782012847162

Epoch: 5| Step: 7
Training loss: 1.9007847309112549
Validation loss: 2.0072760351242556

Epoch: 5| Step: 8
Training loss: 1.99993097782135
Validation loss: 2.0189045834284958

Epoch: 5| Step: 9
Training loss: 2.3423991203308105
Validation loss: 2.0257495244344077

Epoch: 5| Step: 10
Training loss: 2.4976799488067627
Validation loss: 2.012445536992883

Epoch: 89| Step: 0
Training loss: 1.9809892177581787
Validation loss: 2.0137897511964202

Epoch: 5| Step: 1
Training loss: 2.033435106277466
Validation loss: 2.0181455599364413

Epoch: 5| Step: 2
Training loss: 2.0746614933013916
Validation loss: 2.0042777548554125

Epoch: 5| Step: 3
Training loss: 2.397581100463867
Validation loss: 2.0068908224823656

Epoch: 5| Step: 4
Training loss: 2.538173198699951
Validation loss: 2.01473904168734

Epoch: 5| Step: 5
Training loss: 2.2840218544006348
Validation loss: 2.0018772412371892

Epoch: 5| Step: 6
Training loss: 1.7968738079071045
Validation loss: 2.0086292079699937

Epoch: 5| Step: 7
Training loss: 2.3522145748138428
Validation loss: 1.9998494245672738

Epoch: 5| Step: 8
Training loss: 2.3472719192504883
Validation loss: 1.9966819235073623

Epoch: 5| Step: 9
Training loss: 1.9177923202514648
Validation loss: 1.992865426566011

Epoch: 5| Step: 10
Training loss: 2.945789098739624
Validation loss: 1.9898776213328044

Epoch: 90| Step: 0
Training loss: 2.499453544616699
Validation loss: 1.993439156522033

Epoch: 5| Step: 1
Training loss: 2.3134665489196777
Validation loss: 1.9943817379654094

Epoch: 5| Step: 2
Training loss: 1.7826484441757202
Validation loss: 2.0161393919298725

Epoch: 5| Step: 3
Training loss: 1.8169634342193604
Validation loss: 2.0082347790400186

Epoch: 5| Step: 4
Training loss: 2.5708413124084473
Validation loss: 1.9912746490970734

Epoch: 5| Step: 5
Training loss: 2.1410021781921387
Validation loss: 2.0174355583806194

Epoch: 5| Step: 6
Training loss: 2.1363677978515625
Validation loss: 2.0156807694383847

Epoch: 5| Step: 7
Training loss: 2.6209325790405273
Validation loss: 2.0095876288670365

Epoch: 5| Step: 8
Training loss: 2.102968215942383
Validation loss: 2.0028883487947526

Epoch: 5| Step: 9
Training loss: 2.18493390083313
Validation loss: 1.986530980756206

Epoch: 5| Step: 10
Training loss: 2.569962978363037
Validation loss: 2.0021441546819543

Epoch: 91| Step: 0
Training loss: 2.004934310913086
Validation loss: 2.0163167676618023

Epoch: 5| Step: 1
Training loss: 2.1724438667297363
Validation loss: 2.017512065108104

Epoch: 5| Step: 2
Training loss: 1.7228736877441406
Validation loss: 2.011887804154427

Epoch: 5| Step: 3
Training loss: 2.2722930908203125
Validation loss: 2.0097317464890017

Epoch: 5| Step: 4
Training loss: 2.2134432792663574
Validation loss: 1.9946168135571223

Epoch: 5| Step: 5
Training loss: 2.7074427604675293
Validation loss: 2.0113685515619095

Epoch: 5| Step: 6
Training loss: 2.3218610286712646
Validation loss: 2.034534454345703

Epoch: 5| Step: 7
Training loss: 2.025218963623047
Validation loss: 2.007350911376297

Epoch: 5| Step: 8
Training loss: 2.207514762878418
Validation loss: 2.025691509246826

Epoch: 5| Step: 9
Training loss: 2.5687637329101562
Validation loss: 2.0415960050398305

Epoch: 5| Step: 10
Training loss: 2.3248465061187744
Validation loss: 2.0303708737896335

Epoch: 92| Step: 0
Training loss: 2.127035617828369
Validation loss: 2.01277151671789

Epoch: 5| Step: 1
Training loss: 2.092555046081543
Validation loss: 2.018767237663269

Epoch: 5| Step: 2
Training loss: 2.2441468238830566
Validation loss: 2.0292864256007697

Epoch: 5| Step: 3
Training loss: 2.790599822998047
Validation loss: 2.0250813422664518

Epoch: 5| Step: 4
Training loss: 1.583775281906128
Validation loss: 2.037337080124886

Epoch: 5| Step: 5
Training loss: 2.3036787509918213
Validation loss: 2.017517717935706

Epoch: 5| Step: 6
Training loss: 2.738842487335205
Validation loss: 2.026178244621523

Epoch: 5| Step: 7
Training loss: 2.4124014377593994
Validation loss: 2.023438531865356

Epoch: 5| Step: 8
Training loss: 1.9044721126556396
Validation loss: 2.0340337061112925

Epoch: 5| Step: 9
Training loss: 2.2902865409851074
Validation loss: 2.0140380808102187

Epoch: 5| Step: 10
Training loss: 1.9979619979858398
Validation loss: 2.0290334814338276

Epoch: 93| Step: 0
Training loss: 2.206239938735962
Validation loss: 2.006908961521682

Epoch: 5| Step: 1
Training loss: 2.253242254257202
Validation loss: 2.021446210081859

Epoch: 5| Step: 2
Training loss: 2.1695396900177
Validation loss: 2.0264836075485393

Epoch: 5| Step: 3
Training loss: 2.8231966495513916
Validation loss: 2.008363918591571

Epoch: 5| Step: 4
Training loss: 2.150383472442627
Validation loss: 2.008037510738578

Epoch: 5| Step: 5
Training loss: 2.644152879714966
Validation loss: 2.0169926740789927

Epoch: 5| Step: 6
Training loss: 2.397813558578491
Validation loss: 1.998612908906834

Epoch: 5| Step: 7
Training loss: 1.469120979309082
Validation loss: 2.0222277115750056

Epoch: 5| Step: 8
Training loss: 1.9183038473129272
Validation loss: 1.9982791228960919

Epoch: 5| Step: 9
Training loss: 2.2357449531555176
Validation loss: 2.016957390692926

Epoch: 5| Step: 10
Training loss: 2.169603109359741
Validation loss: 2.0045506800374677

Epoch: 94| Step: 0
Training loss: 2.362095355987549
Validation loss: 2.0099813963777278

Epoch: 5| Step: 1
Training loss: 2.4316112995147705
Validation loss: 1.997053418108212

Epoch: 5| Step: 2
Training loss: 2.0751538276672363
Validation loss: 2.014573509975146

Epoch: 5| Step: 3
Training loss: 2.8721957206726074
Validation loss: 2.004823842356282

Epoch: 5| Step: 4
Training loss: 1.9350054264068604
Validation loss: 2.0187194308926983

Epoch: 5| Step: 5
Training loss: 1.6897268295288086
Validation loss: 2.00602807793566

Epoch: 5| Step: 6
Training loss: 2.391448497772217
Validation loss: 2.0343094410434848

Epoch: 5| Step: 7
Training loss: 1.7945728302001953
Validation loss: 2.0187716048250914

Epoch: 5| Step: 8
Training loss: 2.553417682647705
Validation loss: 2.0236826763358167

Epoch: 5| Step: 9
Training loss: 2.146249771118164
Validation loss: 2.0116387515939693

Epoch: 5| Step: 10
Training loss: 2.1885907649993896
Validation loss: 2.026165839164488

Epoch: 95| Step: 0
Training loss: 2.490079402923584
Validation loss: 2.0081232055541007

Epoch: 5| Step: 1
Training loss: 1.8940789699554443
Validation loss: 2.024295050610778

Epoch: 5| Step: 2
Training loss: 1.7914758920669556
Validation loss: 1.9955951680419266

Epoch: 5| Step: 3
Training loss: 2.322938919067383
Validation loss: 2.013082331226718

Epoch: 5| Step: 4
Training loss: 2.268867015838623
Validation loss: 2.0051695915960495

Epoch: 5| Step: 5
Training loss: 2.3619813919067383
Validation loss: 1.999651252582509

Epoch: 5| Step: 6
Training loss: 2.4544758796691895
Validation loss: 1.9852282590763544

Epoch: 5| Step: 7
Training loss: 2.327965259552002
Validation loss: 1.9988369685347362

Epoch: 5| Step: 8
Training loss: 2.2088851928710938
Validation loss: 1.9980355642175163

Epoch: 5| Step: 9
Training loss: 2.168722629547119
Validation loss: 2.010035120030885

Epoch: 5| Step: 10
Training loss: 2.322835922241211
Validation loss: 2.0005881581255185

Epoch: 96| Step: 0
Training loss: 1.9585838317871094
Validation loss: 2.0089500347773233

Epoch: 5| Step: 1
Training loss: 2.6864418983459473
Validation loss: 2.0059313979200137

Epoch: 5| Step: 2
Training loss: 2.078336715698242
Validation loss: 2.0030081477216495

Epoch: 5| Step: 3
Training loss: 1.9801372289657593
Validation loss: 2.0048998619920466

Epoch: 5| Step: 4
Training loss: 2.0090746879577637
Validation loss: 1.9927653843356716

Epoch: 5| Step: 5
Training loss: 1.9581773281097412
Validation loss: 2.008305488094207

Epoch: 5| Step: 6
Training loss: 2.5240111351013184
Validation loss: 2.0047679011539747

Epoch: 5| Step: 7
Training loss: 1.94719660282135
Validation loss: 2.0281064202708583

Epoch: 5| Step: 8
Training loss: 2.4059531688690186
Validation loss: 2.012979345936929

Epoch: 5| Step: 9
Training loss: 2.6386232376098633
Validation loss: 2.0152035195340394

Epoch: 5| Step: 10
Training loss: 2.2213046550750732
Validation loss: 1.983844469952327

Epoch: 97| Step: 0
Training loss: 2.458840847015381
Validation loss: 2.00376921315347

Epoch: 5| Step: 1
Training loss: 1.9968602657318115
Validation loss: 2.0245210355327976

Epoch: 5| Step: 2
Training loss: 1.7765470743179321
Validation loss: 2.0103847288316294

Epoch: 5| Step: 3
Training loss: 2.2175517082214355
Validation loss: 2.0007028836075977

Epoch: 5| Step: 4
Training loss: 2.2926831245422363
Validation loss: 1.988732651997638

Epoch: 5| Step: 5
Training loss: 2.0450093746185303
Validation loss: 2.0123667127342633

Epoch: 5| Step: 6
Training loss: 2.2721385955810547
Validation loss: 2.0263326937152493

Epoch: 5| Step: 7
Training loss: 2.2573771476745605
Validation loss: 2.0056898619538996

Epoch: 5| Step: 8
Training loss: 2.963822603225708
Validation loss: 2.00738997485048

Epoch: 5| Step: 9
Training loss: 2.413337469100952
Validation loss: 2.011630960690078

Epoch: 5| Step: 10
Training loss: 1.7077889442443848
Validation loss: 2.0210689395986576

Epoch: 98| Step: 0
Training loss: 2.651639938354492
Validation loss: 2.008833674974339

Epoch: 5| Step: 1
Training loss: 2.204434633255005
Validation loss: 2.0226817643770607

Epoch: 5| Step: 2
Training loss: 2.692537784576416
Validation loss: 2.021665161655795

Epoch: 5| Step: 3
Training loss: 2.432644844055176
Validation loss: 2.0211474651931436

Epoch: 5| Step: 4
Training loss: 1.9069557189941406
Validation loss: 2.029496410841583

Epoch: 5| Step: 5
Training loss: 1.55596125125885
Validation loss: 2.026457372532096

Epoch: 5| Step: 6
Training loss: 2.0325114727020264
Validation loss: 2.020232090386011

Epoch: 5| Step: 7
Training loss: 2.0844550132751465
Validation loss: 2.015898842965403

Epoch: 5| Step: 8
Training loss: 2.4300403594970703
Validation loss: 2.0157485187694593

Epoch: 5| Step: 9
Training loss: 2.481412410736084
Validation loss: 2.025687966295468

Epoch: 5| Step: 10
Training loss: 1.9988484382629395
Validation loss: 2.0173132060676493

Epoch: 99| Step: 0
Training loss: 1.7376604080200195
Validation loss: 2.002269773073094

Epoch: 5| Step: 1
Training loss: 2.1688876152038574
Validation loss: 2.0333778012183403

Epoch: 5| Step: 2
Training loss: 2.292360782623291
Validation loss: 2.0221146409229567

Epoch: 5| Step: 3
Training loss: 2.2854819297790527
Validation loss: 2.019704016306067

Epoch: 5| Step: 4
Training loss: 2.396130323410034
Validation loss: 2.0179271441633984

Epoch: 5| Step: 5
Training loss: 2.452704906463623
Validation loss: 2.040558958566317

Epoch: 5| Step: 6
Training loss: 2.6699092388153076
Validation loss: 2.023450082348239

Epoch: 5| Step: 7
Training loss: 2.718517541885376
Validation loss: 1.9849380754655408

Epoch: 5| Step: 8
Training loss: 1.9451448917388916
Validation loss: 2.0109351232487667

Epoch: 5| Step: 9
Training loss: 1.926445722579956
Validation loss: 2.0257518958019953

Epoch: 5| Step: 10
Training loss: 1.846142292022705
Validation loss: 2.0334045463992703

Epoch: 100| Step: 0
Training loss: 1.7453641891479492
Validation loss: 2.0166561859910206

Epoch: 5| Step: 1
Training loss: 2.1088993549346924
Validation loss: 2.005438289334697

Epoch: 5| Step: 2
Training loss: 1.5735009908676147
Validation loss: 2.016116455037107

Epoch: 5| Step: 3
Training loss: 2.025068759918213
Validation loss: 2.000474129953692

Epoch: 5| Step: 4
Training loss: 1.917542815208435
Validation loss: 2.021064882637352

Epoch: 5| Step: 5
Training loss: 2.723090887069702
Validation loss: 2.020593444506327

Epoch: 5| Step: 6
Training loss: 2.7295703887939453
Validation loss: 2.02348498118821

Epoch: 5| Step: 7
Training loss: 2.1700072288513184
Validation loss: 1.986611823881826

Epoch: 5| Step: 8
Training loss: 2.347412586212158
Validation loss: 1.9984316031138103

Epoch: 5| Step: 9
Training loss: 2.384927749633789
Validation loss: 1.9976968598622147

Epoch: 5| Step: 10
Training loss: 2.5929203033447266
Validation loss: 2.009146523732011

Epoch: 101| Step: 0
Training loss: 2.469512462615967
Validation loss: 1.9863184267474758

Epoch: 5| Step: 1
Training loss: 1.9183181524276733
Validation loss: 1.996908890303745

Epoch: 5| Step: 2
Training loss: 1.6229177713394165
Validation loss: 1.9858391105487783

Epoch: 5| Step: 3
Training loss: 2.2802813053131104
Validation loss: 1.9976024345685077

Epoch: 5| Step: 4
Training loss: 2.808566093444824
Validation loss: 2.0007154390376103

Epoch: 5| Step: 5
Training loss: 2.553528308868408
Validation loss: 2.0152575251876668

Epoch: 5| Step: 6
Training loss: 2.1731526851654053
Validation loss: 1.9853863998125958

Epoch: 5| Step: 7
Training loss: 1.969583511352539
Validation loss: 1.987200306307885

Epoch: 5| Step: 8
Training loss: 2.7349209785461426
Validation loss: 1.996421888310422

Epoch: 5| Step: 9
Training loss: 1.5811004638671875
Validation loss: 2.002630069691648

Epoch: 5| Step: 10
Training loss: 2.299811363220215
Validation loss: 1.9887021151922082

Epoch: 102| Step: 0
Training loss: 2.072716474533081
Validation loss: 1.9683022114538378

Epoch: 5| Step: 1
Training loss: 2.587545871734619
Validation loss: 1.989165436836981

Epoch: 5| Step: 2
Training loss: 2.1481964588165283
Validation loss: 1.979861879861483

Epoch: 5| Step: 3
Training loss: 2.8393712043762207
Validation loss: 1.9926747429755427

Epoch: 5| Step: 4
Training loss: 1.9789375066757202
Validation loss: 1.9824449964748916

Epoch: 5| Step: 5
Training loss: 2.2289602756500244
Validation loss: 2.019449567282072

Epoch: 5| Step: 6
Training loss: 2.249965190887451
Validation loss: 1.9754112817907845

Epoch: 5| Step: 7
Training loss: 1.83061945438385
Validation loss: 1.982276120493489

Epoch: 5| Step: 8
Training loss: 2.3194987773895264
Validation loss: 1.9908247429837462

Epoch: 5| Step: 9
Training loss: 2.0867180824279785
Validation loss: 1.9698325498129732

Epoch: 5| Step: 10
Training loss: 2.033712863922119
Validation loss: 2.017673951323314

Epoch: 103| Step: 0
Training loss: 1.4988892078399658
Validation loss: 1.9784673644650368

Epoch: 5| Step: 1
Training loss: 2.5074234008789062
Validation loss: 2.0014168895700926

Epoch: 5| Step: 2
Training loss: 2.001429796218872
Validation loss: 1.995694007924808

Epoch: 5| Step: 3
Training loss: 1.5273568630218506
Validation loss: 2.004349950821169

Epoch: 5| Step: 4
Training loss: 2.7561111450195312
Validation loss: 1.9951826000726351

Epoch: 5| Step: 5
Training loss: 2.314201831817627
Validation loss: 1.9936282839826358

Epoch: 5| Step: 6
Training loss: 2.2393696308135986
Validation loss: 2.009812870333272

Epoch: 5| Step: 7
Training loss: 2.491109848022461
Validation loss: 2.0126951535542807

Epoch: 5| Step: 8
Training loss: 2.2540621757507324
Validation loss: 1.9805607846988145

Epoch: 5| Step: 9
Training loss: 2.4234912395477295
Validation loss: 2.0105019615542505

Epoch: 5| Step: 10
Training loss: 2.27152943611145
Validation loss: 2.0064690907796225

Epoch: 104| Step: 0
Training loss: 1.9181381464004517
Validation loss: 2.0118423097877094

Epoch: 5| Step: 1
Training loss: 2.6321120262145996
Validation loss: 1.9970051011731547

Epoch: 5| Step: 2
Training loss: 2.2978317737579346
Validation loss: 2.0091629848685315

Epoch: 5| Step: 3
Training loss: 2.3429930210113525
Validation loss: 1.990761882515364

Epoch: 5| Step: 4
Training loss: 2.509035587310791
Validation loss: 1.9929333976520005

Epoch: 5| Step: 5
Training loss: 2.8133082389831543
Validation loss: 1.9937111511025378

Epoch: 5| Step: 6
Training loss: 1.4028983116149902
Validation loss: 2.017344344046808

Epoch: 5| Step: 7
Training loss: 2.276186227798462
Validation loss: 2.020834994572465

Epoch: 5| Step: 8
Training loss: 2.0743377208709717
Validation loss: 2.0090672200725925

Epoch: 5| Step: 9
Training loss: 1.9449551105499268
Validation loss: 2.0226192525638047

Epoch: 5| Step: 10
Training loss: 1.9020015001296997
Validation loss: 2.004323177440192

Epoch: 105| Step: 0
Training loss: 2.4898505210876465
Validation loss: 2.0248335151262182

Epoch: 5| Step: 1
Training loss: 2.033993721008301
Validation loss: 2.0253099549201226

Epoch: 5| Step: 2
Training loss: 1.9819484949111938
Validation loss: 2.019237495237781

Epoch: 5| Step: 3
Training loss: 2.145315647125244
Validation loss: 2.011348932020126

Epoch: 5| Step: 4
Training loss: 2.7462563514709473
Validation loss: 2.02502848768747

Epoch: 5| Step: 5
Training loss: 2.9607605934143066
Validation loss: 2.0210717570397163

Epoch: 5| Step: 6
Training loss: 1.663679838180542
Validation loss: 2.038712327198316

Epoch: 5| Step: 7
Training loss: 2.0891828536987305
Validation loss: 2.0256396826877388

Epoch: 5| Step: 8
Training loss: 2.0959889888763428
Validation loss: 2.018226187716248

Epoch: 5| Step: 9
Training loss: 1.9046367406845093
Validation loss: 2.0271535817012993

Epoch: 5| Step: 10
Training loss: 2.069091558456421
Validation loss: 2.006688529445279

Epoch: 106| Step: 0
Training loss: 1.858351469039917
Validation loss: 1.9999848501656645

Epoch: 5| Step: 1
Training loss: 2.8440096378326416
Validation loss: 2.012938064913596

Epoch: 5| Step: 2
Training loss: 2.259542942047119
Validation loss: 2.0087907147663895

Epoch: 5| Step: 3
Training loss: 2.1833443641662598
Validation loss: 2.0134354842606412

Epoch: 5| Step: 4
Training loss: 2.0950958728790283
Validation loss: 2.0082465435868952

Epoch: 5| Step: 5
Training loss: 1.549225091934204
Validation loss: 2.011866746410247

Epoch: 5| Step: 6
Training loss: 2.2504138946533203
Validation loss: 2.014599900091848

Epoch: 5| Step: 7
Training loss: 2.3950424194335938
Validation loss: 2.0214700083578787

Epoch: 5| Step: 8
Training loss: 2.6972036361694336
Validation loss: 2.018188658580985

Epoch: 5| Step: 9
Training loss: 1.8547680377960205
Validation loss: 2.01834003643323

Epoch: 5| Step: 10
Training loss: 2.0926923751831055
Validation loss: 2.007181639312416

Epoch: 107| Step: 0
Training loss: 2.5141983032226562
Validation loss: 2.0092517791255826

Epoch: 5| Step: 1
Training loss: 1.9044561386108398
Validation loss: 2.024408814727619

Epoch: 5| Step: 2
Training loss: 2.7828240394592285
Validation loss: 2.0012236128571215

Epoch: 5| Step: 3
Training loss: 2.1063127517700195
Validation loss: 1.9903872525820168

Epoch: 5| Step: 4
Training loss: 2.0312557220458984
Validation loss: 2.008036208409135

Epoch: 5| Step: 5
Training loss: 2.587480068206787
Validation loss: 2.0043737862699773

Epoch: 5| Step: 6
Training loss: 1.445041298866272
Validation loss: 2.0115163428809053

Epoch: 5| Step: 7
Training loss: 2.065511703491211
Validation loss: 1.9863865234518563

Epoch: 5| Step: 8
Training loss: 1.4727699756622314
Validation loss: 2.012809318880881

Epoch: 5| Step: 9
Training loss: 2.7672009468078613
Validation loss: 2.021425098501226

Epoch: 5| Step: 10
Training loss: 2.5163707733154297
Validation loss: 1.9976845556689846

Epoch: 108| Step: 0
Training loss: 1.5776448249816895
Validation loss: 2.002527145929234

Epoch: 5| Step: 1
Training loss: 2.4431304931640625
Validation loss: 1.9912756694260465

Epoch: 5| Step: 2
Training loss: 2.874182939529419
Validation loss: 1.986318124237881

Epoch: 5| Step: 3
Training loss: 1.6066051721572876
Validation loss: 2.0125738741249166

Epoch: 5| Step: 4
Training loss: 2.411825656890869
Validation loss: 1.9932628703373734

Epoch: 5| Step: 5
Training loss: 2.535257577896118
Validation loss: 1.9921051789355535

Epoch: 5| Step: 6
Training loss: 2.193934679031372
Validation loss: 2.014442245165507

Epoch: 5| Step: 7
Training loss: 2.1420369148254395
Validation loss: 2.009151371576453

Epoch: 5| Step: 8
Training loss: 1.735943078994751
Validation loss: 2.014966905757945

Epoch: 5| Step: 9
Training loss: 2.3385276794433594
Validation loss: 2.024708438945073

Epoch: 5| Step: 10
Training loss: 2.3326377868652344
Validation loss: 2.013015539415421

Epoch: 109| Step: 0
Training loss: 2.081935405731201
Validation loss: 1.9986238197613788

Epoch: 5| Step: 1
Training loss: 2.493065357208252
Validation loss: 2.0027912124510734

Epoch: 5| Step: 2
Training loss: 2.4563164710998535
Validation loss: 2.0100725902024137

Epoch: 5| Step: 3
Training loss: 2.7077698707580566
Validation loss: 2.0168787830619404

Epoch: 5| Step: 4
Training loss: 2.2266221046447754
Validation loss: 1.9856410231641544

Epoch: 5| Step: 5
Training loss: 2.899688482284546
Validation loss: 2.0036041851966613

Epoch: 5| Step: 6
Training loss: 1.6740257740020752
Validation loss: 2.0268429325472925

Epoch: 5| Step: 7
Training loss: 1.4765983819961548
Validation loss: 2.005116807517185

Epoch: 5| Step: 8
Training loss: 2.353532552719116
Validation loss: 1.9966139575486541

Epoch: 5| Step: 9
Training loss: 1.959132432937622
Validation loss: 2.009838306775657

Epoch: 5| Step: 10
Training loss: 1.613593578338623
Validation loss: 2.0047291799258162

Epoch: 110| Step: 0
Training loss: 2.120496988296509
Validation loss: 2.01741619776654

Epoch: 5| Step: 1
Training loss: 2.169877529144287
Validation loss: 2.0015542353353193

Epoch: 5| Step: 2
Training loss: 2.0902960300445557
Validation loss: 2.0000899325134935

Epoch: 5| Step: 3
Training loss: 2.2743191719055176
Validation loss: 2.015264731581493

Epoch: 5| Step: 4
Training loss: 1.8363946676254272
Validation loss: 2.0147415540551625

Epoch: 5| Step: 5
Training loss: 1.8768246173858643
Validation loss: 2.00230836355558

Epoch: 5| Step: 6
Training loss: 2.082947254180908
Validation loss: 1.9913884580776255

Epoch: 5| Step: 7
Training loss: 3.1216444969177246
Validation loss: 2.0233072619284354

Epoch: 5| Step: 8
Training loss: 2.3947575092315674
Validation loss: 2.0102874066240046

Epoch: 5| Step: 9
Training loss: 1.8463020324707031
Validation loss: 1.992001433526316

Epoch: 5| Step: 10
Training loss: 2.427191734313965
Validation loss: 2.005705466834448

Epoch: 111| Step: 0
Training loss: 2.5956528186798096
Validation loss: 2.0256852693455194

Epoch: 5| Step: 1
Training loss: 1.4347470998764038
Validation loss: 2.0235280913691365

Epoch: 5| Step: 2
Training loss: 2.608600616455078
Validation loss: 2.0317766666412354

Epoch: 5| Step: 3
Training loss: 1.91704523563385
Validation loss: 2.0012507630932714

Epoch: 5| Step: 4
Training loss: 2.843341827392578
Validation loss: 2.0034999680775467

Epoch: 5| Step: 5
Training loss: 2.762305736541748
Validation loss: 2.024634289485152

Epoch: 5| Step: 6
Training loss: 2.264779806137085
Validation loss: 2.021220494342107

Epoch: 5| Step: 7
Training loss: 2.0195913314819336
Validation loss: 2.0224505880827546

Epoch: 5| Step: 8
Training loss: 1.8565009832382202
Validation loss: 2.0067653040732107

Epoch: 5| Step: 9
Training loss: 1.6403299570083618
Validation loss: 1.994657092196967

Epoch: 5| Step: 10
Training loss: 2.1366219520568848
Validation loss: 1.99949562293227

Epoch: 112| Step: 0
Training loss: 1.518419861793518
Validation loss: 1.9927388750096804

Epoch: 5| Step: 1
Training loss: 2.385103702545166
Validation loss: 2.0034650679557555

Epoch: 5| Step: 2
Training loss: 2.5403618812561035
Validation loss: 2.0193165476604173

Epoch: 5| Step: 3
Training loss: 2.121201992034912
Validation loss: 1.98472075821251

Epoch: 5| Step: 4
Training loss: 2.0394692420959473
Validation loss: 1.98967194813554

Epoch: 5| Step: 5
Training loss: 2.8162364959716797
Validation loss: 2.008208497878044

Epoch: 5| Step: 6
Training loss: 2.523299217224121
Validation loss: 1.9926085843834827

Epoch: 5| Step: 7
Training loss: 2.3357536792755127
Validation loss: 1.9968534567022835

Epoch: 5| Step: 8
Training loss: 1.5883033275604248
Validation loss: 2.0085247703777847

Epoch: 5| Step: 9
Training loss: 2.2607874870300293
Validation loss: 2.010179283798382

Epoch: 5| Step: 10
Training loss: 1.8657673597335815
Validation loss: 2.0023137959100867

Epoch: 113| Step: 0
Training loss: 2.093599319458008
Validation loss: 2.014044266875072

Epoch: 5| Step: 1
Training loss: 2.2385311126708984
Validation loss: 1.998061659515545

Epoch: 5| Step: 2
Training loss: 1.5930315256118774
Validation loss: 1.9862869478041125

Epoch: 5| Step: 3
Training loss: 2.74289870262146
Validation loss: 1.9897114743468582

Epoch: 5| Step: 4
Training loss: 2.45894718170166
Validation loss: 2.017249684179983

Epoch: 5| Step: 5
Training loss: 1.8557240962982178
Validation loss: 2.014627787374681

Epoch: 5| Step: 6
Training loss: 1.5754401683807373
Validation loss: 2.0089337338683424

Epoch: 5| Step: 7
Training loss: 2.07033109664917
Validation loss: 2.0061179027762464

Epoch: 5| Step: 8
Training loss: 2.0849547386169434
Validation loss: 2.0120468242194063

Epoch: 5| Step: 9
Training loss: 2.50089430809021
Validation loss: 1.9818369650071668

Epoch: 5| Step: 10
Training loss: 2.9273533821105957
Validation loss: 2.002887951430454

Epoch: 114| Step: 0
Training loss: 3.10858154296875
Validation loss: 1.997639923967341

Epoch: 5| Step: 1
Training loss: 2.187929630279541
Validation loss: 2.022813299650787

Epoch: 5| Step: 2
Training loss: 2.391223430633545
Validation loss: 1.9967836923496698

Epoch: 5| Step: 3
Training loss: 2.220918655395508
Validation loss: 2.0043299685242357

Epoch: 5| Step: 4
Training loss: 2.444995403289795
Validation loss: 2.0179695185794624

Epoch: 5| Step: 5
Training loss: 2.172921895980835
Validation loss: 2.007841375566298

Epoch: 5| Step: 6
Training loss: 1.9272940158843994
Validation loss: 2.0264348676127772

Epoch: 5| Step: 7
Training loss: 2.0264904499053955
Validation loss: 1.9983039197101389

Epoch: 5| Step: 8
Training loss: 2.2609944343566895
Validation loss: 2.0087863322227233

Epoch: 5| Step: 9
Training loss: 1.5930324792861938
Validation loss: 2.0076018841035905

Epoch: 5| Step: 10
Training loss: 1.6926884651184082
Validation loss: 2.0237675636045394

Epoch: 115| Step: 0
Training loss: 2.8027451038360596
Validation loss: 2.0250472650733045

Epoch: 5| Step: 1
Training loss: 1.874834418296814
Validation loss: 2.0079439468281244

Epoch: 5| Step: 2
Training loss: 2.1648635864257812
Validation loss: 2.011313009005721

Epoch: 5| Step: 3
Training loss: 2.6575546264648438
Validation loss: 2.0174219249397196

Epoch: 5| Step: 4
Training loss: 2.3507704734802246
Validation loss: 1.9977587705017419

Epoch: 5| Step: 5
Training loss: 1.494551658630371
Validation loss: 2.009812952369772

Epoch: 5| Step: 6
Training loss: 2.1729254722595215
Validation loss: 2.024931159070743

Epoch: 5| Step: 7
Training loss: 1.8948001861572266
Validation loss: 2.0121512259206464

Epoch: 5| Step: 8
Training loss: 1.8528999090194702
Validation loss: 2.000352164750458

Epoch: 5| Step: 9
Training loss: 2.723456621170044
Validation loss: 2.0218737586852042

Epoch: 5| Step: 10
Training loss: 1.9821553230285645
Validation loss: 2.0203187029848815

Epoch: 116| Step: 0
Training loss: 1.7277171611785889
Validation loss: 2.015138861953571

Epoch: 5| Step: 1
Training loss: 2.190382480621338
Validation loss: 2.0275701322863178

Epoch: 5| Step: 2
Training loss: 2.3714725971221924
Validation loss: 2.0055208270267775

Epoch: 5| Step: 3
Training loss: 2.1593029499053955
Validation loss: 2.0396907919196674

Epoch: 5| Step: 4
Training loss: 1.7390110492706299
Validation loss: 2.0011634031931558

Epoch: 5| Step: 5
Training loss: 1.6426522731781006
Validation loss: 2.025886312607796

Epoch: 5| Step: 6
Training loss: 2.9347662925720215
Validation loss: 2.0219768901025095

Epoch: 5| Step: 7
Training loss: 2.618668794631958
Validation loss: 2.005722430444533

Epoch: 5| Step: 8
Training loss: 2.185103416442871
Validation loss: 1.9930052834172403

Epoch: 5| Step: 9
Training loss: 2.3715622425079346
Validation loss: 2.0134194756066925

Epoch: 5| Step: 10
Training loss: 2.146810531616211
Validation loss: 2.008085132927023

Epoch: 117| Step: 0
Training loss: 2.807312488555908
Validation loss: 2.009337035558557

Epoch: 5| Step: 1
Training loss: 1.9826223850250244
Validation loss: 1.9991953142227665

Epoch: 5| Step: 2
Training loss: 2.15509295463562
Validation loss: 2.023255794279037

Epoch: 5| Step: 3
Training loss: 2.1397945880889893
Validation loss: 1.9984285164904851

Epoch: 5| Step: 4
Training loss: 2.478015422821045
Validation loss: 1.9944803894207042

Epoch: 5| Step: 5
Training loss: 2.1570708751678467
Validation loss: 2.009648107713269

Epoch: 5| Step: 6
Training loss: 2.34745192527771
Validation loss: 2.0183715717766875

Epoch: 5| Step: 7
Training loss: 1.9077510833740234
Validation loss: 2.0147736764723256

Epoch: 5| Step: 8
Training loss: 2.0051889419555664
Validation loss: 2.0177401188881166

Epoch: 5| Step: 9
Training loss: 1.7868306636810303
Validation loss: 2.0124849760404198

Epoch: 5| Step: 10
Training loss: 2.1518213748931885
Validation loss: 1.9972969947322723

Epoch: 118| Step: 0
Training loss: 1.999383568763733
Validation loss: 2.011080813664262

Epoch: 5| Step: 1
Training loss: 2.001683235168457
Validation loss: 1.9949177131857923

Epoch: 5| Step: 2
Training loss: 2.3217709064483643
Validation loss: 1.980851355419364

Epoch: 5| Step: 3
Training loss: 2.3045034408569336
Validation loss: 2.001345270423479

Epoch: 5| Step: 4
Training loss: 2.0789570808410645
Validation loss: 2.022153474951303

Epoch: 5| Step: 5
Training loss: 2.270900011062622
Validation loss: 1.9995783477701166

Epoch: 5| Step: 6
Training loss: 2.2599332332611084
Validation loss: 2.0117186871908044

Epoch: 5| Step: 7
Training loss: 1.9645583629608154
Validation loss: 2.004072659759111

Epoch: 5| Step: 8
Training loss: 1.7412912845611572
Validation loss: 2.0135322822037565

Epoch: 5| Step: 9
Training loss: 2.778380870819092
Validation loss: 2.016078310628091

Epoch: 5| Step: 10
Training loss: 2.32413911819458
Validation loss: 2.029511956758397

Epoch: 119| Step: 0
Training loss: 2.2276999950408936
Validation loss: 2.011026091473077

Epoch: 5| Step: 1
Training loss: 2.3325469493865967
Validation loss: 2.015832652327835

Epoch: 5| Step: 2
Training loss: 2.4910051822662354
Validation loss: 2.0162518408990677

Epoch: 5| Step: 3
Training loss: 2.120028018951416
Validation loss: 2.0353540951205837

Epoch: 5| Step: 4
Training loss: 1.905413031578064
Validation loss: 2.028894688493462

Epoch: 5| Step: 5
Training loss: 1.858983039855957
Validation loss: 2.0124239678023965

Epoch: 5| Step: 6
Training loss: 2.001322031021118
Validation loss: 2.014998717974591

Epoch: 5| Step: 7
Training loss: 2.467447280883789
Validation loss: 2.0233794719942155

Epoch: 5| Step: 8
Training loss: 2.332348346710205
Validation loss: 2.01723623916667

Epoch: 5| Step: 9
Training loss: 1.683117151260376
Validation loss: 2.01624809798374

Epoch: 5| Step: 10
Training loss: 2.4407460689544678
Validation loss: 2.008703201047836

Epoch: 120| Step: 0
Training loss: 2.6097071170806885
Validation loss: 2.0285204328516477

Epoch: 5| Step: 1
Training loss: 2.3493924140930176
Validation loss: 2.0257183326187955

Epoch: 5| Step: 2
Training loss: 2.4804844856262207
Validation loss: 2.010647737851707

Epoch: 5| Step: 3
Training loss: 2.327373743057251
Validation loss: 2.0165196285452893

Epoch: 5| Step: 4
Training loss: 2.6465039253234863
Validation loss: 2.011020883437126

Epoch: 5| Step: 5
Training loss: 1.9071388244628906
Validation loss: 1.995862392969029

Epoch: 5| Step: 6
Training loss: 2.081953763961792
Validation loss: 2.03271665880757

Epoch: 5| Step: 7
Training loss: 1.8581622838974
Validation loss: 2.035925167863087

Epoch: 5| Step: 8
Training loss: 1.6785249710083008
Validation loss: 2.01205886051219

Epoch: 5| Step: 9
Training loss: 1.5593934059143066
Validation loss: 1.9997050659630888

Epoch: 5| Step: 10
Training loss: 2.4483296871185303
Validation loss: 2.011303319725939

Epoch: 121| Step: 0
Training loss: 2.031243324279785
Validation loss: 1.9878321078515822

Epoch: 5| Step: 1
Training loss: 2.5087409019470215
Validation loss: 1.9802060793804865

Epoch: 5| Step: 2
Training loss: 2.2044429779052734
Validation loss: 2.0098746553544076

Epoch: 5| Step: 3
Training loss: 2.51475191116333
Validation loss: 1.9945664457095567

Epoch: 5| Step: 4
Training loss: 1.687207818031311
Validation loss: 2.016813849890104

Epoch: 5| Step: 5
Training loss: 2.295665740966797
Validation loss: 1.983359258661988

Epoch: 5| Step: 6
Training loss: 2.195857048034668
Validation loss: 1.9961435307738602

Epoch: 5| Step: 7
Training loss: 1.7200641632080078
Validation loss: 1.996557512590962

Epoch: 5| Step: 8
Training loss: 1.6471582651138306
Validation loss: 2.0166719139263196

Epoch: 5| Step: 9
Training loss: 2.915191173553467
Validation loss: 2.0045119075364966

Epoch: 5| Step: 10
Training loss: 2.227351188659668
Validation loss: 2.0090277400068057

Epoch: 122| Step: 0
Training loss: 2.372941493988037
Validation loss: 1.9980734086805774

Epoch: 5| Step: 1
Training loss: 2.834169387817383
Validation loss: 1.9912148316701253

Epoch: 5| Step: 2
Training loss: 2.1746411323547363
Validation loss: 1.9942378600438435

Epoch: 5| Step: 3
Training loss: 1.9969993829727173
Validation loss: 1.9939700018975042

Epoch: 5| Step: 4
Training loss: 2.402945041656494
Validation loss: 1.9924789705584127

Epoch: 5| Step: 5
Training loss: 1.919836401939392
Validation loss: 2.002583661387044

Epoch: 5| Step: 6
Training loss: 1.9259326457977295
Validation loss: 2.0080505801785375

Epoch: 5| Step: 7
Training loss: 1.8670387268066406
Validation loss: 1.9851372165064658

Epoch: 5| Step: 8
Training loss: 2.058856248855591
Validation loss: 2.00821046034495

Epoch: 5| Step: 9
Training loss: 2.743624210357666
Validation loss: 1.992262457006721

Epoch: 5| Step: 10
Training loss: 1.6762515306472778
Validation loss: 1.9957175818822717

Epoch: 123| Step: 0
Training loss: 2.0964951515197754
Validation loss: 1.9862244282999346

Epoch: 5| Step: 1
Training loss: 2.7593834400177
Validation loss: 2.01401287253185

Epoch: 5| Step: 2
Training loss: 1.8006868362426758
Validation loss: 1.9919717773314445

Epoch: 5| Step: 3
Training loss: 2.0305233001708984
Validation loss: 1.9739510167029597

Epoch: 5| Step: 4
Training loss: 2.408947706222534
Validation loss: 1.998132941543415

Epoch: 5| Step: 5
Training loss: 2.138430118560791
Validation loss: 2.012008059409357

Epoch: 5| Step: 6
Training loss: 2.06997013092041
Validation loss: 2.0128986309933405

Epoch: 5| Step: 7
Training loss: 2.558568000793457
Validation loss: 2.0118964474688292

Epoch: 5| Step: 8
Training loss: 1.7861888408660889
Validation loss: 1.9891219959464124

Epoch: 5| Step: 9
Training loss: 2.2490997314453125
Validation loss: 1.9910402067245976

Epoch: 5| Step: 10
Training loss: 2.0861382484436035
Validation loss: 2.01137763069522

Epoch: 124| Step: 0
Training loss: 2.6583240032196045
Validation loss: 2.007019450587611

Epoch: 5| Step: 1
Training loss: 1.8224906921386719
Validation loss: 2.009943921078918

Epoch: 5| Step: 2
Training loss: 1.702021598815918
Validation loss: 1.9995032125903713

Epoch: 5| Step: 3
Training loss: 2.583822727203369
Validation loss: 2.006383060127176

Epoch: 5| Step: 4
Training loss: 1.8582713603973389
Validation loss: 2.0148289395916845

Epoch: 5| Step: 5
Training loss: 2.1134533882141113
Validation loss: 2.0132615181707565

Epoch: 5| Step: 6
Training loss: 2.172022581100464
Validation loss: 2.0242624769928637

Epoch: 5| Step: 7
Training loss: 2.1268787384033203
Validation loss: 2.0138643505752727

Epoch: 5| Step: 8
Training loss: 2.220630645751953
Validation loss: 2.0251434285153627

Epoch: 5| Step: 9
Training loss: 2.4623303413391113
Validation loss: 2.019094326162851

Epoch: 5| Step: 10
Training loss: 2.1196846961975098
Validation loss: 2.015182420771609

Epoch: 125| Step: 0
Training loss: 1.7023948431015015
Validation loss: 1.9963199528314735

Epoch: 5| Step: 1
Training loss: 2.4362006187438965
Validation loss: 2.0215476161690167

Epoch: 5| Step: 2
Training loss: 2.7933316230773926
Validation loss: 2.012828903813516

Epoch: 5| Step: 3
Training loss: 2.492706775665283
Validation loss: 2.0218437769079722

Epoch: 5| Step: 4
Training loss: 2.4811010360717773
Validation loss: 2.005542907663571

Epoch: 5| Step: 5
Training loss: 2.2007172107696533
Validation loss: 2.027147287963539

Epoch: 5| Step: 6
Training loss: 2.3351287841796875
Validation loss: 2.0112717113187237

Epoch: 5| Step: 7
Training loss: 1.5663533210754395
Validation loss: 2.0502947120256323

Epoch: 5| Step: 8
Training loss: 1.6155391931533813
Validation loss: 2.0402716154693277

Epoch: 5| Step: 9
Training loss: 2.0883877277374268
Validation loss: 2.0385797075046006

Epoch: 5| Step: 10
Training loss: 2.1050074100494385
Validation loss: 2.025110767733666

Epoch: 126| Step: 0
Training loss: 2.2253477573394775
Validation loss: 2.0198110970117713

Epoch: 5| Step: 1
Training loss: 2.806128978729248
Validation loss: 2.0143057633471746

Epoch: 5| Step: 2
Training loss: 2.4001972675323486
Validation loss: 2.022168585049209

Epoch: 5| Step: 3
Training loss: 2.1550159454345703
Validation loss: 2.0281156750135523

Epoch: 5| Step: 4
Training loss: 1.6677722930908203
Validation loss: 2.0157827574719667

Epoch: 5| Step: 5
Training loss: 1.8322193622589111
Validation loss: 2.0039363356046778

Epoch: 5| Step: 6
Training loss: 2.2575008869171143
Validation loss: 2.0249272110641643

Epoch: 5| Step: 7
Training loss: 1.9716532230377197
Validation loss: 2.023859795703683

Epoch: 5| Step: 8
Training loss: 1.961024522781372
Validation loss: 2.02564864261176

Epoch: 5| Step: 9
Training loss: 2.1398396492004395
Validation loss: 2.019475502352561

Epoch: 5| Step: 10
Training loss: 2.464837074279785
Validation loss: 2.029618567036044

Epoch: 127| Step: 0
Training loss: 2.4808828830718994
Validation loss: 2.0246114064288396

Epoch: 5| Step: 1
Training loss: 1.658752202987671
Validation loss: 2.0209350842301563

Epoch: 5| Step: 2
Training loss: 2.1190590858459473
Validation loss: 2.026272560960503

Epoch: 5| Step: 3
Training loss: 1.605027437210083
Validation loss: 1.9915141008233512

Epoch: 5| Step: 4
Training loss: 1.9356882572174072
Validation loss: 2.0287119496253228

Epoch: 5| Step: 5
Training loss: 1.9579178094863892
Validation loss: 2.011037454810194

Epoch: 5| Step: 6
Training loss: 2.318955183029175
Validation loss: 2.0202657714966805

Epoch: 5| Step: 7
Training loss: 2.292055606842041
Validation loss: 1.9984511688191404

Epoch: 5| Step: 8
Training loss: 2.812704086303711
Validation loss: 2.0334878942017913

Epoch: 5| Step: 9
Training loss: 2.402301788330078
Validation loss: 2.0149381968282882

Epoch: 5| Step: 10
Training loss: 2.252962827682495
Validation loss: 2.0152559459850354

Epoch: 128| Step: 0
Training loss: 2.4945425987243652
Validation loss: 2.011015861265121

Epoch: 5| Step: 1
Training loss: 1.7739289999008179
Validation loss: 2.00187542874326

Epoch: 5| Step: 2
Training loss: 1.9201552867889404
Validation loss: 2.0353205716738136

Epoch: 5| Step: 3
Training loss: 2.192208766937256
Validation loss: 2.020751977479586

Epoch: 5| Step: 4
Training loss: 2.631563663482666
Validation loss: 2.014607867886943

Epoch: 5| Step: 5
Training loss: 2.349884510040283
Validation loss: 2.0071462046715522

Epoch: 5| Step: 6
Training loss: 2.2020316123962402
Validation loss: 2.015723530964185

Epoch: 5| Step: 7
Training loss: 2.2262606620788574
Validation loss: 2.0069172151627077

Epoch: 5| Step: 8
Training loss: 1.6667215824127197
Validation loss: 2.003329748748451

Epoch: 5| Step: 9
Training loss: 2.4322903156280518
Validation loss: 2.0015857245332453

Epoch: 5| Step: 10
Training loss: 1.9070948362350464
Validation loss: 1.9959307486011135

Epoch: 129| Step: 0
Training loss: 2.4577243328094482
Validation loss: 1.9948654661896408

Epoch: 5| Step: 1
Training loss: 2.4215831756591797
Validation loss: 1.973677565974574

Epoch: 5| Step: 2
Training loss: 2.0695037841796875
Validation loss: 2.0105206722854287

Epoch: 5| Step: 3
Training loss: 2.1549932956695557
Validation loss: 1.9877210201755646

Epoch: 5| Step: 4
Training loss: 2.1421725749969482
Validation loss: 2.001376319957036

Epoch: 5| Step: 5
Training loss: 1.7658687829971313
Validation loss: 1.9981448317086825

Epoch: 5| Step: 6
Training loss: 1.9515407085418701
Validation loss: 1.9798704347302836

Epoch: 5| Step: 7
Training loss: 2.231703281402588
Validation loss: 1.9926906926657564

Epoch: 5| Step: 8
Training loss: 2.3879590034484863
Validation loss: 2.0199210746313936

Epoch: 5| Step: 9
Training loss: 1.699317216873169
Validation loss: 1.9872960634129022

Epoch: 5| Step: 10
Training loss: 2.603604793548584
Validation loss: 2.0087584167398433

Epoch: 130| Step: 0
Training loss: 2.331559181213379
Validation loss: 1.9932538899042274

Epoch: 5| Step: 1
Training loss: 2.0271191596984863
Validation loss: 1.9817840565917313

Epoch: 5| Step: 2
Training loss: 2.083911418914795
Validation loss: 2.002331973404013

Epoch: 5| Step: 3
Training loss: 2.067371368408203
Validation loss: 2.0088065106381654

Epoch: 5| Step: 4
Training loss: 1.8380584716796875
Validation loss: 2.0040835808682185

Epoch: 5| Step: 5
Training loss: 1.887885332107544
Validation loss: 1.9975672537280666

Epoch: 5| Step: 6
Training loss: 2.8403677940368652
Validation loss: 1.9890824902442195

Epoch: 5| Step: 7
Training loss: 2.455289125442505
Validation loss: 2.0134654147650606

Epoch: 5| Step: 8
Training loss: 1.9581464529037476
Validation loss: 2.000377792184071

Epoch: 5| Step: 9
Training loss: 2.507192611694336
Validation loss: 1.9987367929950837

Epoch: 5| Step: 10
Training loss: 1.7339820861816406
Validation loss: 1.9681580861409504

Epoch: 131| Step: 0
Training loss: 2.5511810779571533
Validation loss: 1.9794108547190183

Epoch: 5| Step: 1
Training loss: 1.775503396987915
Validation loss: 2.012022090214555

Epoch: 5| Step: 2
Training loss: 2.204218864440918
Validation loss: 1.9953325204951788

Epoch: 5| Step: 3
Training loss: 2.5465269088745117
Validation loss: 2.0061660197473343

Epoch: 5| Step: 4
Training loss: 2.0599610805511475
Validation loss: 2.009121923036473

Epoch: 5| Step: 5
Training loss: 2.1980032920837402
Validation loss: 1.9971918162479196

Epoch: 5| Step: 6
Training loss: 2.345032215118408
Validation loss: 1.9912262898619457

Epoch: 5| Step: 7
Training loss: 1.379894495010376
Validation loss: 2.006634622491816

Epoch: 5| Step: 8
Training loss: 2.211510181427002
Validation loss: 2.0154437352252264

Epoch: 5| Step: 9
Training loss: 1.8680721521377563
Validation loss: 2.0219503987220024

Epoch: 5| Step: 10
Training loss: 2.6994285583496094
Validation loss: 2.0190510801089707

Epoch: 132| Step: 0
Training loss: 2.0639901161193848
Validation loss: 2.0022705947199175

Epoch: 5| Step: 1
Training loss: 1.9373422861099243
Validation loss: 2.012590221179429

Epoch: 5| Step: 2
Training loss: 2.1071114540100098
Validation loss: 2.032087533704696

Epoch: 5| Step: 3
Training loss: 2.798316717147827
Validation loss: 2.0006292814849527

Epoch: 5| Step: 4
Training loss: 2.009488105773926
Validation loss: 2.0183982169756325

Epoch: 5| Step: 5
Training loss: 1.948455810546875
Validation loss: 2.0104989774765505

Epoch: 5| Step: 6
Training loss: 2.1325550079345703
Validation loss: 1.9933999123111847

Epoch: 5| Step: 7
Training loss: 2.119663715362549
Validation loss: 2.0192175475499963

Epoch: 5| Step: 8
Training loss: 1.7131378650665283
Validation loss: 2.0374427546737013

Epoch: 5| Step: 9
Training loss: 2.6616921424865723
Validation loss: 2.0169563960003596

Epoch: 5| Step: 10
Training loss: 2.2502665519714355
Validation loss: 2.0174139776537494

Epoch: 133| Step: 0
Training loss: 2.831662654876709
Validation loss: 2.0022447314313663

Epoch: 5| Step: 1
Training loss: 1.5903240442276
Validation loss: 2.020298227187126

Epoch: 5| Step: 2
Training loss: 2.531129837036133
Validation loss: 2.001756488635976

Epoch: 5| Step: 3
Training loss: 1.2475756406784058
Validation loss: 2.0388338206916727

Epoch: 5| Step: 4
Training loss: 1.7601172924041748
Validation loss: 1.9910226175861974

Epoch: 5| Step: 5
Training loss: 2.791593074798584
Validation loss: 2.0256581691003617

Epoch: 5| Step: 6
Training loss: 1.7733793258666992
Validation loss: 2.0156407420353224

Epoch: 5| Step: 7
Training loss: 2.1143922805786133
Validation loss: 2.016154243100074

Epoch: 5| Step: 8
Training loss: 1.9593921899795532
Validation loss: 2.0049625404419436

Epoch: 5| Step: 9
Training loss: 2.669126033782959
Validation loss: 2.038397640310308

Epoch: 5| Step: 10
Training loss: 2.460322618484497
Validation loss: 2.000319113013565

Epoch: 134| Step: 0
Training loss: 2.906187057495117
Validation loss: 2.010926940107858

Epoch: 5| Step: 1
Training loss: 2.1633434295654297
Validation loss: 2.019808533371136

Epoch: 5| Step: 2
Training loss: 1.8895877599716187
Validation loss: 2.0110210628919702

Epoch: 5| Step: 3
Training loss: 1.8172330856323242
Validation loss: 2.0024019133660103

Epoch: 5| Step: 4
Training loss: 2.3289706707000732
Validation loss: 2.0305724067072712

Epoch: 5| Step: 5
Training loss: 2.7136330604553223
Validation loss: 2.014042995309317

Epoch: 5| Step: 6
Training loss: 1.604879379272461
Validation loss: 2.0035820558506954

Epoch: 5| Step: 7
Training loss: 1.9058024883270264
Validation loss: 2.0164984374917965

Epoch: 5| Step: 8
Training loss: 1.6516315937042236
Validation loss: 2.004465050594781

Epoch: 5| Step: 9
Training loss: 2.837404727935791
Validation loss: 2.010412746860135

Epoch: 5| Step: 10
Training loss: 1.956359624862671
Validation loss: 2.020052134349782

Epoch: 135| Step: 0
Training loss: 2.9193434715270996
Validation loss: 2.015986801475607

Epoch: 5| Step: 1
Training loss: 2.1368637084960938
Validation loss: 2.046361736072007

Epoch: 5| Step: 2
Training loss: 2.808624267578125
Validation loss: 1.9997808753803212

Epoch: 5| Step: 3
Training loss: 1.7254436016082764
Validation loss: 2.019669494321269

Epoch: 5| Step: 4
Training loss: 2.1043829917907715
Validation loss: 2.0048396215643933

Epoch: 5| Step: 5
Training loss: 1.9975935220718384
Validation loss: 2.0150800264009865

Epoch: 5| Step: 6
Training loss: 2.544536590576172
Validation loss: 1.9966401566741288

Epoch: 5| Step: 7
Training loss: 1.9594110250473022
Validation loss: 2.0077630524994223

Epoch: 5| Step: 8
Training loss: 2.2058534622192383
Validation loss: 2.0245823244894705

Epoch: 5| Step: 9
Training loss: 1.332449197769165
Validation loss: 2.0088119737563597

Epoch: 5| Step: 10
Training loss: 1.7805004119873047
Validation loss: 2.0108920092223794

Epoch: 136| Step: 0
Training loss: 1.8756879568099976
Validation loss: 2.0235122455063688

Epoch: 5| Step: 1
Training loss: 2.2885308265686035
Validation loss: 2.0187039849578694

Epoch: 5| Step: 2
Training loss: 2.5651333332061768
Validation loss: 1.9940911646812194

Epoch: 5| Step: 3
Training loss: 2.2367172241210938
Validation loss: 1.9990392525990803

Epoch: 5| Step: 4
Training loss: 1.967171311378479
Validation loss: 1.985350262734198

Epoch: 5| Step: 5
Training loss: 1.9546489715576172
Validation loss: 2.0061527721343504

Epoch: 5| Step: 6
Training loss: 2.1085305213928223
Validation loss: 1.9957225886724328

Epoch: 5| Step: 7
Training loss: 1.8527567386627197
Validation loss: 1.981971913768399

Epoch: 5| Step: 8
Training loss: 2.03606915473938
Validation loss: 1.9980538314388645

Epoch: 5| Step: 9
Training loss: 2.8768532276153564
Validation loss: 1.9941023447180306

Epoch: 5| Step: 10
Training loss: 1.6466214656829834
Validation loss: 1.9987903192479124

Epoch: 137| Step: 0
Training loss: 1.9732691049575806
Validation loss: 2.0112029583223405

Epoch: 5| Step: 1
Training loss: 2.556230306625366
Validation loss: 1.9833336850648284

Epoch: 5| Step: 2
Training loss: 2.079257011413574
Validation loss: 1.9930288663474462

Epoch: 5| Step: 3
Training loss: 1.9032433032989502
Validation loss: 2.0131841731327835

Epoch: 5| Step: 4
Training loss: 1.9853355884552002
Validation loss: 1.9772514822662517

Epoch: 5| Step: 5
Training loss: 2.41129732131958
Validation loss: 1.9709888235215218

Epoch: 5| Step: 6
Training loss: 2.078052282333374
Validation loss: 1.9862894781174198

Epoch: 5| Step: 7
Training loss: 1.8340036869049072
Validation loss: 1.9703158024818666

Epoch: 5| Step: 8
Training loss: 2.8022308349609375
Validation loss: 1.994412778526224

Epoch: 5| Step: 9
Training loss: 2.1069889068603516
Validation loss: 1.9945897222847067

Epoch: 5| Step: 10
Training loss: 1.697661280632019
Validation loss: 1.9860087479314497

Epoch: 138| Step: 0
Training loss: 2.576383352279663
Validation loss: 1.9796087946943057

Epoch: 5| Step: 1
Training loss: 2.7410998344421387
Validation loss: 2.0129423026115663

Epoch: 5| Step: 2
Training loss: 2.5267446041107178
Validation loss: 2.013338376117009

Epoch: 5| Step: 3
Training loss: 1.6727443933486938
Validation loss: 1.995660969006118

Epoch: 5| Step: 4
Training loss: 1.9496043920516968
Validation loss: 2.028632310128981

Epoch: 5| Step: 5
Training loss: 1.6761058568954468
Validation loss: 2.012201888586885

Epoch: 5| Step: 6
Training loss: 2.158298969268799
Validation loss: 2.01568296904205

Epoch: 5| Step: 7
Training loss: 1.7211071252822876
Validation loss: 2.0306467022947086

Epoch: 5| Step: 8
Training loss: 2.231367826461792
Validation loss: 2.0290230525437223

Epoch: 5| Step: 9
Training loss: 2.705202102661133
Validation loss: 2.016215508983981

Epoch: 5| Step: 10
Training loss: 1.5764186382293701
Validation loss: 2.013955854600476

Epoch: 139| Step: 0
Training loss: 1.6124681234359741
Validation loss: 2.003409185717183

Epoch: 5| Step: 1
Training loss: 2.7780566215515137
Validation loss: 1.9903235589304278

Epoch: 5| Step: 2
Training loss: 2.0709900856018066
Validation loss: 2.004294054482573

Epoch: 5| Step: 3
Training loss: 2.599090099334717
Validation loss: 2.0208026927004576

Epoch: 5| Step: 4
Training loss: 1.6670162677764893
Validation loss: 2.0198871884294736

Epoch: 5| Step: 5
Training loss: 1.869842290878296
Validation loss: 2.0222932279750867

Epoch: 5| Step: 6
Training loss: 2.125091791152954
Validation loss: 2.02437585912725

Epoch: 5| Step: 7
Training loss: 2.069939136505127
Validation loss: 2.0210502634766283

Epoch: 5| Step: 8
Training loss: 2.371872663497925
Validation loss: 2.02124120343116

Epoch: 5| Step: 9
Training loss: 2.411775588989258
Validation loss: 2.007527917943975

Epoch: 5| Step: 10
Training loss: 1.815216064453125
Validation loss: 1.991669492055011

Epoch: 140| Step: 0
Training loss: 1.8496812582015991
Validation loss: 2.0009112614457325

Epoch: 5| Step: 1
Training loss: 2.4006242752075195
Validation loss: 2.022275919555336

Epoch: 5| Step: 2
Training loss: 2.741518974304199
Validation loss: 1.9980265863480107

Epoch: 5| Step: 3
Training loss: 1.620290756225586
Validation loss: 2.0161749047617756

Epoch: 5| Step: 4
Training loss: 2.2083916664123535
Validation loss: 2.0181255391848985

Epoch: 5| Step: 5
Training loss: 2.274996519088745
Validation loss: 1.9992501492141395

Epoch: 5| Step: 6
Training loss: 2.1859424114227295
Validation loss: 1.99616115836687

Epoch: 5| Step: 7
Training loss: 1.9925689697265625
Validation loss: 2.012318713690645

Epoch: 5| Step: 8
Training loss: 2.543673038482666
Validation loss: 1.989065782998198

Epoch: 5| Step: 9
Training loss: 2.21856689453125
Validation loss: 1.9955596282917967

Epoch: 5| Step: 10
Training loss: 1.523081660270691
Validation loss: 2.0053431244306665

Epoch: 141| Step: 0
Training loss: 1.6361488103866577
Validation loss: 1.9769316527151293

Epoch: 5| Step: 1
Training loss: 2.5799760818481445
Validation loss: 1.995533707321331

Epoch: 5| Step: 2
Training loss: 1.9389508962631226
Validation loss: 2.0129330799143803

Epoch: 5| Step: 3
Training loss: 2.2806243896484375
Validation loss: 2.0093732880007837

Epoch: 5| Step: 4
Training loss: 2.646718978881836
Validation loss: 2.0099522221472954

Epoch: 5| Step: 5
Training loss: 1.3877360820770264
Validation loss: 2.0035506140801216

Epoch: 5| Step: 6
Training loss: 2.0920708179473877
Validation loss: 2.0113323170651674

Epoch: 5| Step: 7
Training loss: 2.8797013759613037
Validation loss: 2.030343541534998

Epoch: 5| Step: 8
Training loss: 1.6342718601226807
Validation loss: 2.027924350512925

Epoch: 5| Step: 9
Training loss: 2.262014865875244
Validation loss: 2.015185036966878

Epoch: 5| Step: 10
Training loss: 2.3778786659240723
Validation loss: 2.016435388595827

Epoch: 142| Step: 0
Training loss: 1.747222661972046
Validation loss: 2.017854008623349

Epoch: 5| Step: 1
Training loss: 2.6158177852630615
Validation loss: 2.0111691810751475

Epoch: 5| Step: 2
Training loss: 2.005775213241577
Validation loss: 2.0084826382257606

Epoch: 5| Step: 3
Training loss: 2.167663335800171
Validation loss: 2.0013339852774017

Epoch: 5| Step: 4
Training loss: 2.1562559604644775
Validation loss: 2.0009695791429087

Epoch: 5| Step: 5
Training loss: 1.611056923866272
Validation loss: 1.9985912666525891

Epoch: 5| Step: 6
Training loss: 1.8696781396865845
Validation loss: 2.021305643102174

Epoch: 5| Step: 7
Training loss: 2.0485339164733887
Validation loss: 1.9897430917268157

Epoch: 5| Step: 8
Training loss: 2.94278621673584
Validation loss: 1.991482796207551

Epoch: 5| Step: 9
Training loss: 2.3191978931427
Validation loss: 1.9978935526263328

Epoch: 5| Step: 10
Training loss: 1.9253547191619873
Validation loss: 2.0107897968702417

Epoch: 143| Step: 0
Training loss: 2.4583077430725098
Validation loss: 1.9882179639672721

Epoch: 5| Step: 1
Training loss: 2.7359566688537598
Validation loss: 1.9850283617614417

Epoch: 5| Step: 2
Training loss: 1.7246700525283813
Validation loss: 2.0001996640236146

Epoch: 5| Step: 3
Training loss: 2.3986852169036865
Validation loss: 2.017830071910735

Epoch: 5| Step: 4
Training loss: 2.8848636150360107
Validation loss: 1.9851653704079248

Epoch: 5| Step: 5
Training loss: 2.063624858856201
Validation loss: 1.9950823553146855

Epoch: 5| Step: 6
Training loss: 1.5992989540100098
Validation loss: 1.9948419870868805

Epoch: 5| Step: 7
Training loss: 1.5602585077285767
Validation loss: 2.0080620486249208

Epoch: 5| Step: 8
Training loss: 1.923575758934021
Validation loss: 2.0051170997722174

Epoch: 5| Step: 9
Training loss: 2.1773459911346436
Validation loss: 1.995163058721891

Epoch: 5| Step: 10
Training loss: 1.9268206357955933
Validation loss: 1.9863335958091162

Epoch: 144| Step: 0
Training loss: 1.9344314336776733
Validation loss: 2.023482056074245

Epoch: 5| Step: 1
Training loss: 2.406137704849243
Validation loss: 2.005414192394544

Epoch: 5| Step: 2
Training loss: 2.0369811058044434
Validation loss: 1.9903479186437463

Epoch: 5| Step: 3
Training loss: 1.6455882787704468
Validation loss: 2.007622282992127

Epoch: 5| Step: 4
Training loss: 1.629725694656372
Validation loss: 1.9811080143015871

Epoch: 5| Step: 5
Training loss: 2.663163661956787
Validation loss: 2.01253257771974

Epoch: 5| Step: 6
Training loss: 2.438436985015869
Validation loss: 1.9938598781503656

Epoch: 5| Step: 7
Training loss: 1.7730915546417236
Validation loss: 1.9878924098066104

Epoch: 5| Step: 8
Training loss: 2.3772289752960205
Validation loss: 2.015857465805546

Epoch: 5| Step: 9
Training loss: 2.374673366546631
Validation loss: 2.007414428136682

Epoch: 5| Step: 10
Training loss: 2.090916633605957
Validation loss: 2.0039638139868297

Epoch: 145| Step: 0
Training loss: 1.2666957378387451
Validation loss: 2.014704788884809

Epoch: 5| Step: 1
Training loss: 2.1392102241516113
Validation loss: 2.0059471540553595

Epoch: 5| Step: 2
Training loss: 2.6697068214416504
Validation loss: 2.0072399083004204

Epoch: 5| Step: 3
Training loss: 2.287022590637207
Validation loss: 2.0066621444558583

Epoch: 5| Step: 4
Training loss: 1.8410829305648804
Validation loss: 2.0255333198014127

Epoch: 5| Step: 5
Training loss: 1.798227310180664
Validation loss: 1.9911531786764822

Epoch: 5| Step: 6
Training loss: 1.8362147808074951
Validation loss: 2.0132452646891275

Epoch: 5| Step: 7
Training loss: 2.5271739959716797
Validation loss: 2.0229730426624255

Epoch: 5| Step: 8
Training loss: 1.7251383066177368
Validation loss: 1.9936634545685143

Epoch: 5| Step: 9
Training loss: 2.7358651161193848
Validation loss: 1.9992467331629928

Epoch: 5| Step: 10
Training loss: 2.5395236015319824
Validation loss: 2.011033296585083

Epoch: 146| Step: 0
Training loss: 2.123037576675415
Validation loss: 2.0036816161165953

Epoch: 5| Step: 1
Training loss: 2.1762619018554688
Validation loss: 2.02229981781334

Epoch: 5| Step: 2
Training loss: 2.3716042041778564
Validation loss: 1.9908466057110858

Epoch: 5| Step: 3
Training loss: 1.7377992868423462
Validation loss: 2.000823382408388

Epoch: 5| Step: 4
Training loss: 2.6277146339416504
Validation loss: 2.0017378791686027

Epoch: 5| Step: 5
Training loss: 1.8145815134048462
Validation loss: 2.0106228910466677

Epoch: 5| Step: 6
Training loss: 1.9417511224746704
Validation loss: 2.0074471184002456

Epoch: 5| Step: 7
Training loss: 1.7203458547592163
Validation loss: 1.9988886822936356

Epoch: 5| Step: 8
Training loss: 2.1273434162139893
Validation loss: 2.001911278693907

Epoch: 5| Step: 9
Training loss: 2.145948886871338
Validation loss: 2.0103851800323813

Epoch: 5| Step: 10
Training loss: 2.870473861694336
Validation loss: 2.015929675871326

Epoch: 147| Step: 0
Training loss: 2.41749906539917
Validation loss: 1.9969613180365613

Epoch: 5| Step: 1
Training loss: 1.6492841243743896
Validation loss: 2.0070331647831905

Epoch: 5| Step: 2
Training loss: 1.5731210708618164
Validation loss: 2.0311253199013333

Epoch: 5| Step: 3
Training loss: 1.972398042678833
Validation loss: 1.997459493657594

Epoch: 5| Step: 4
Training loss: 2.4490163326263428
Validation loss: 1.997278041737054

Epoch: 5| Step: 5
Training loss: 2.5324463844299316
Validation loss: 1.999585513145693

Epoch: 5| Step: 6
Training loss: 2.424097776412964
Validation loss: 2.0052101535181843

Epoch: 5| Step: 7
Training loss: 1.8215376138687134
Validation loss: 2.003241676156239

Epoch: 5| Step: 8
Training loss: 2.6026649475097656
Validation loss: 2.0039207781514814

Epoch: 5| Step: 9
Training loss: 2.0328071117401123
Validation loss: 2.0178488839057183

Epoch: 5| Step: 10
Training loss: 1.9638643264770508
Validation loss: 1.99144943042468

Epoch: 148| Step: 0
Training loss: 1.6621787548065186
Validation loss: 2.0191533411702802

Epoch: 5| Step: 1
Training loss: 2.0520687103271484
Validation loss: 2.0005895078823133

Epoch: 5| Step: 2
Training loss: 1.878469705581665
Validation loss: 2.002256349850726

Epoch: 5| Step: 3
Training loss: 2.1264185905456543
Validation loss: 1.9990561726272746

Epoch: 5| Step: 4
Training loss: 1.8061294555664062
Validation loss: 2.0072765093977734

Epoch: 5| Step: 5
Training loss: 2.259395122528076
Validation loss: 1.9982605723924534

Epoch: 5| Step: 6
Training loss: 2.6869800090789795
Validation loss: 2.030052650359369

Epoch: 5| Step: 7
Training loss: 2.043835401535034
Validation loss: 2.003127508265998

Epoch: 5| Step: 8
Training loss: 1.8483245372772217
Validation loss: 2.0043875427656275

Epoch: 5| Step: 9
Training loss: 2.4884133338928223
Validation loss: 2.0001959185446463

Epoch: 5| Step: 10
Training loss: 2.5669403076171875
Validation loss: 2.010203702475435

Epoch: 149| Step: 0
Training loss: 1.5296571254730225
Validation loss: 2.032087181204109

Epoch: 5| Step: 1
Training loss: 2.4482181072235107
Validation loss: 2.027204200785647

Epoch: 5| Step: 2
Training loss: 1.6298179626464844
Validation loss: 2.0063319462601856

Epoch: 5| Step: 3
Training loss: 1.564281702041626
Validation loss: 1.997810527842532

Epoch: 5| Step: 4
Training loss: 1.9933154582977295
Validation loss: 2.018736077893165

Epoch: 5| Step: 5
Training loss: 2.5460383892059326
Validation loss: 2.0084889716999506

Epoch: 5| Step: 6
Training loss: 1.8991864919662476
Validation loss: 2.0083336368683846

Epoch: 5| Step: 7
Training loss: 2.7728142738342285
Validation loss: 2.008201563230125

Epoch: 5| Step: 8
Training loss: 1.954949975013733
Validation loss: 1.9934588273366292

Epoch: 5| Step: 9
Training loss: 3.013319253921509
Validation loss: 1.9866453011830647

Epoch: 5| Step: 10
Training loss: 2.125598192214966
Validation loss: 2.00245040206499

Epoch: 150| Step: 0
Training loss: 1.8737112283706665
Validation loss: 1.9872004447444793

Epoch: 5| Step: 1
Training loss: 2.357893705368042
Validation loss: 2.000047306860647

Epoch: 5| Step: 2
Training loss: 2.247837543487549
Validation loss: 1.9897462501320788

Epoch: 5| Step: 3
Training loss: 2.3469181060791016
Validation loss: 2.0117266793404855

Epoch: 5| Step: 4
Training loss: 2.6716668605804443
Validation loss: 1.9897199523064397

Epoch: 5| Step: 5
Training loss: 2.066885471343994
Validation loss: 1.997027950902139

Epoch: 5| Step: 6
Training loss: 1.9070888757705688
Validation loss: 2.0050807076115764

Epoch: 5| Step: 7
Training loss: 2.2026400566101074
Validation loss: 2.001071491549092

Epoch: 5| Step: 8
Training loss: 1.774540901184082
Validation loss: 1.9992130725614485

Epoch: 5| Step: 9
Training loss: 2.093222141265869
Validation loss: 2.004821995253204

Epoch: 5| Step: 10
Training loss: 1.7432284355163574
Validation loss: 1.9982729240130352

Epoch: 151| Step: 0
Training loss: 1.5660130977630615
Validation loss: 2.0058192783786404

Epoch: 5| Step: 1
Training loss: 2.2948737144470215
Validation loss: 2.0022051295926495

Epoch: 5| Step: 2
Training loss: 2.2915382385253906
Validation loss: 1.9874525582918556

Epoch: 5| Step: 3
Training loss: 1.9570674896240234
Validation loss: 2.0034881637942408

Epoch: 5| Step: 4
Training loss: 2.199817180633545
Validation loss: 2.000461583496422

Epoch: 5| Step: 5
Training loss: 2.220808744430542
Validation loss: 1.982406359846874

Epoch: 5| Step: 6
Training loss: 2.0153841972351074
Validation loss: 1.9755047316192298

Epoch: 5| Step: 7
Training loss: 2.5388882160186768
Validation loss: 1.9969821796622327

Epoch: 5| Step: 8
Training loss: 1.959653615951538
Validation loss: 1.9805578672757713

Epoch: 5| Step: 9
Training loss: 2.671992540359497
Validation loss: 2.0018703232529345

Epoch: 5| Step: 10
Training loss: 1.7339458465576172
Validation loss: 2.0046912008716213

Epoch: 152| Step: 0
Training loss: 2.370258331298828
Validation loss: 2.0012114176186184

Epoch: 5| Step: 1
Training loss: 2.004340648651123
Validation loss: 1.977806224617907

Epoch: 5| Step: 2
Training loss: 2.58447265625
Validation loss: 2.005086701403382

Epoch: 5| Step: 3
Training loss: 1.9282855987548828
Validation loss: 1.9897623241588633

Epoch: 5| Step: 4
Training loss: 2.209240674972534
Validation loss: 2.0266140814750426

Epoch: 5| Step: 5
Training loss: 1.9404035806655884
Validation loss: 1.9983957403449601

Epoch: 5| Step: 6
Training loss: 2.124953031539917
Validation loss: 2.000717182313242

Epoch: 5| Step: 7
Training loss: 2.0267958641052246
Validation loss: 2.0083277148585164

Epoch: 5| Step: 8
Training loss: 2.047797679901123
Validation loss: 1.993200646933689

Epoch: 5| Step: 9
Training loss: 1.7826147079467773
Validation loss: 2.0138795337369366

Epoch: 5| Step: 10
Training loss: 2.158803939819336
Validation loss: 2.031141516982868

Epoch: 153| Step: 0
Training loss: 1.6395385265350342
Validation loss: 2.0074265439023256

Epoch: 5| Step: 1
Training loss: 1.7356256246566772
Validation loss: 2.0234903840608496

Epoch: 5| Step: 2
Training loss: 2.285783290863037
Validation loss: 2.0398018757502236

Epoch: 5| Step: 3
Training loss: 2.0831246376037598
Validation loss: 2.015278052258235

Epoch: 5| Step: 4
Training loss: 2.224902391433716
Validation loss: 2.019154812700005

Epoch: 5| Step: 5
Training loss: 2.130751132965088
Validation loss: 2.0002360587478965

Epoch: 5| Step: 6
Training loss: 1.7513145208358765
Validation loss: 2.0173602450278496

Epoch: 5| Step: 7
Training loss: 2.3565471172332764
Validation loss: 2.001623938160558

Epoch: 5| Step: 8
Training loss: 2.1198108196258545
Validation loss: 2.0057665481362292

Epoch: 5| Step: 9
Training loss: 2.1163582801818848
Validation loss: 2.0131195309341594

Epoch: 5| Step: 10
Training loss: 2.8350794315338135
Validation loss: 1.9928543772748721

Epoch: 154| Step: 0
Training loss: 1.9053722620010376
Validation loss: 2.0224192629578295

Epoch: 5| Step: 1
Training loss: 2.189887046813965
Validation loss: 2.0200233203108593

Epoch: 5| Step: 2
Training loss: 2.388726234436035
Validation loss: 2.0091775642928256

Epoch: 5| Step: 3
Training loss: 2.270176410675049
Validation loss: 1.9961422502353627

Epoch: 5| Step: 4
Training loss: 2.0938029289245605
Validation loss: 2.0184997294538762

Epoch: 5| Step: 5
Training loss: 1.9515399932861328
Validation loss: 2.0079478525346324

Epoch: 5| Step: 6
Training loss: 2.2190709114074707
Validation loss: 2.0175689215301187

Epoch: 5| Step: 7
Training loss: 1.8805633783340454
Validation loss: 2.010870402859103

Epoch: 5| Step: 8
Training loss: 2.096360921859741
Validation loss: 2.0042490215711695

Epoch: 5| Step: 9
Training loss: 1.5731887817382812
Validation loss: 1.9953870722042617

Epoch: 5| Step: 10
Training loss: 2.7439098358154297
Validation loss: 1.9837702576832106

Epoch: 155| Step: 0
Training loss: 2.058932065963745
Validation loss: 1.98784549261934

Epoch: 5| Step: 1
Training loss: 2.705430030822754
Validation loss: 1.9976225758111605

Epoch: 5| Step: 2
Training loss: 2.067965269088745
Validation loss: 1.9935869504046697

Epoch: 5| Step: 3
Training loss: 1.7233680486679077
Validation loss: 1.9718216119274017

Epoch: 5| Step: 4
Training loss: 1.9183038473129272
Validation loss: 1.9828137479802614

Epoch: 5| Step: 5
Training loss: 1.477435827255249
Validation loss: 2.0062695703198834

Epoch: 5| Step: 6
Training loss: 2.798292636871338
Validation loss: 1.9943551299392537

Epoch: 5| Step: 7
Training loss: 1.754478096961975
Validation loss: 2.0050227667695735

Epoch: 5| Step: 8
Training loss: 2.0967628955841064
Validation loss: 1.9798237803161784

Epoch: 5| Step: 9
Training loss: 2.9002857208251953
Validation loss: 1.9769239579477618

Epoch: 5| Step: 10
Training loss: 1.640559196472168
Validation loss: 2.000273977556536

Epoch: 156| Step: 0
Training loss: 2.321619987487793
Validation loss: 1.978810803864592

Epoch: 5| Step: 1
Training loss: 2.001194477081299
Validation loss: 2.0002173082802885

Epoch: 5| Step: 2
Training loss: 1.8735271692276
Validation loss: 1.9875518141254302

Epoch: 5| Step: 3
Training loss: 1.6934082508087158
Validation loss: 2.0114368520757204

Epoch: 5| Step: 4
Training loss: 1.9731467962265015
Validation loss: 1.9823875440064298

Epoch: 5| Step: 5
Training loss: 1.7682472467422485
Validation loss: 1.9955126559862526

Epoch: 5| Step: 6
Training loss: 2.321507215499878
Validation loss: 2.0053182712165256

Epoch: 5| Step: 7
Training loss: 2.3903863430023193
Validation loss: 1.992433124972928

Epoch: 5| Step: 8
Training loss: 2.5553994178771973
Validation loss: 1.9876473898528724

Epoch: 5| Step: 9
Training loss: 1.9414256811141968
Validation loss: 1.98888901997638

Epoch: 5| Step: 10
Training loss: 2.40541672706604
Validation loss: 1.994200930800489

Epoch: 157| Step: 0
Training loss: 2.382533311843872
Validation loss: 1.9882763188372377

Epoch: 5| Step: 1
Training loss: 2.201399087905884
Validation loss: 2.0030057353358113

Epoch: 5| Step: 2
Training loss: 2.30991268157959
Validation loss: 1.9779954443695724

Epoch: 5| Step: 3
Training loss: 1.7231340408325195
Validation loss: 1.963730888981973

Epoch: 5| Step: 4
Training loss: 1.637237787246704
Validation loss: 1.996419975834508

Epoch: 5| Step: 5
Training loss: 2.6317038536071777
Validation loss: 1.993595928274175

Epoch: 5| Step: 6
Training loss: 2.149824619293213
Validation loss: 1.9849732024695284

Epoch: 5| Step: 7
Training loss: 2.1454524993896484
Validation loss: 1.9984848653116534

Epoch: 5| Step: 8
Training loss: 2.204118251800537
Validation loss: 1.9976247472147788

Epoch: 5| Step: 9
Training loss: 1.9925258159637451
Validation loss: 2.025098967295821

Epoch: 5| Step: 10
Training loss: 1.874005675315857
Validation loss: 1.994925598944387

Epoch: 158| Step: 0
Training loss: 1.9163557291030884
Validation loss: 1.9864989044845744

Epoch: 5| Step: 1
Training loss: 2.1207852363586426
Validation loss: 1.9826426211223807

Epoch: 5| Step: 2
Training loss: 2.003366231918335
Validation loss: 2.025790173520324

Epoch: 5| Step: 3
Training loss: 2.1165432929992676
Validation loss: 1.989705007563355

Epoch: 5| Step: 4
Training loss: 2.103356122970581
Validation loss: 2.0001398465966664

Epoch: 5| Step: 5
Training loss: 2.026580572128296
Validation loss: 1.996882132304612

Epoch: 5| Step: 6
Training loss: 2.208233594894409
Validation loss: 1.9919760611749464

Epoch: 5| Step: 7
Training loss: 2.4129061698913574
Validation loss: 2.014741434845873

Epoch: 5| Step: 8
Training loss: 1.9810097217559814
Validation loss: 1.9834334670856435

Epoch: 5| Step: 9
Training loss: 1.8149116039276123
Validation loss: 1.9887840914469894

Epoch: 5| Step: 10
Training loss: 2.534083843231201
Validation loss: 2.0054587036050777

Epoch: 159| Step: 0
Training loss: 2.10894513130188
Validation loss: 1.993194510859828

Epoch: 5| Step: 1
Training loss: 2.175287961959839
Validation loss: 2.0020570960096133

Epoch: 5| Step: 2
Training loss: 2.14298939704895
Validation loss: 1.999609552403932

Epoch: 5| Step: 3
Training loss: 1.9438403844833374
Validation loss: 1.9911738493109261

Epoch: 5| Step: 4
Training loss: 1.7147470712661743
Validation loss: 1.992592542402206

Epoch: 5| Step: 5
Training loss: 2.6860759258270264
Validation loss: 2.0086211837748045

Epoch: 5| Step: 6
Training loss: 1.8493512868881226
Validation loss: 2.0175581914122387

Epoch: 5| Step: 7
Training loss: 1.9559816122055054
Validation loss: 1.9973892473405408

Epoch: 5| Step: 8
Training loss: 2.0870070457458496
Validation loss: 1.9899601551794237

Epoch: 5| Step: 9
Training loss: 2.605834484100342
Validation loss: 2.0026608000519457

Epoch: 5| Step: 10
Training loss: 2.008988380432129
Validation loss: 1.9851368088876047

Epoch: 160| Step: 0
Training loss: 2.0892879962921143
Validation loss: 1.979027517380253

Epoch: 5| Step: 1
Training loss: 2.929011821746826
Validation loss: 2.0089941870781685

Epoch: 5| Step: 2
Training loss: 1.7060363292694092
Validation loss: 1.995626256030093

Epoch: 5| Step: 3
Training loss: 1.8175170421600342
Validation loss: 1.9865273198773783

Epoch: 5| Step: 4
Training loss: 1.8171241283416748
Validation loss: 2.005062936454691

Epoch: 5| Step: 5
Training loss: 1.791346788406372
Validation loss: 1.9952318412001415

Epoch: 5| Step: 6
Training loss: 2.313246965408325
Validation loss: 1.9958943090131205

Epoch: 5| Step: 7
Training loss: 2.282543659210205
Validation loss: 2.0126051659225137

Epoch: 5| Step: 8
Training loss: 1.8314367532730103
Validation loss: 2.0197693891422723

Epoch: 5| Step: 9
Training loss: 1.9072414636611938
Validation loss: 2.0177367797461887

Epoch: 5| Step: 10
Training loss: 2.8623530864715576
Validation loss: 2.0223566075806976

Epoch: 161| Step: 0
Training loss: 1.6276592016220093
Validation loss: 2.004318949996784

Epoch: 5| Step: 1
Training loss: 1.6111671924591064
Validation loss: 1.9908301791837137

Epoch: 5| Step: 2
Training loss: 2.561631679534912
Validation loss: 2.014433148086712

Epoch: 5| Step: 3
Training loss: 1.8948562145233154
Validation loss: 2.0099126638904696

Epoch: 5| Step: 4
Training loss: 1.7860103845596313
Validation loss: 2.001020643018907

Epoch: 5| Step: 5
Training loss: 1.754532814025879
Validation loss: 2.035352853036696

Epoch: 5| Step: 6
Training loss: 2.409369468688965
Validation loss: 2.001291423715571

Epoch: 5| Step: 7
Training loss: 2.367182970046997
Validation loss: 2.0020712806332495

Epoch: 5| Step: 8
Training loss: 2.0153822898864746
Validation loss: 1.989005168279012

Epoch: 5| Step: 9
Training loss: 2.44704008102417
Validation loss: 2.004284898440043

Epoch: 5| Step: 10
Training loss: 2.806980609893799
Validation loss: 2.0137535500270065

Epoch: 162| Step: 0
Training loss: 2.232347011566162
Validation loss: 1.9923583974120438

Epoch: 5| Step: 1
Training loss: 1.6810331344604492
Validation loss: 2.0136136649757304

Epoch: 5| Step: 2
Training loss: 2.2268240451812744
Validation loss: 2.0098961527629564

Epoch: 5| Step: 3
Training loss: 2.2001760005950928
Validation loss: 1.9900912982161327

Epoch: 5| Step: 4
Training loss: 2.084737777709961
Validation loss: 1.9996630696840183

Epoch: 5| Step: 5
Training loss: 1.9846203327178955
Validation loss: 1.9964689593161307

Epoch: 5| Step: 6
Training loss: 1.8302913904190063
Validation loss: 1.9903645746169552

Epoch: 5| Step: 7
Training loss: 2.26711106300354
Validation loss: 1.9896503263904202

Epoch: 5| Step: 8
Training loss: 2.207399368286133
Validation loss: 1.9989675898705759

Epoch: 5| Step: 9
Training loss: 2.0553011894226074
Validation loss: 1.9839131037394206

Epoch: 5| Step: 10
Training loss: 2.230421304702759
Validation loss: 1.9879409638784264

Epoch: 163| Step: 0
Training loss: 1.5760542154312134
Validation loss: 1.9825514683159449

Epoch: 5| Step: 1
Training loss: 2.4136548042297363
Validation loss: 1.9925876304667482

Epoch: 5| Step: 2
Training loss: 2.419300079345703
Validation loss: 2.0055544389191495

Epoch: 5| Step: 3
Training loss: 1.8235231637954712
Validation loss: 1.9760309406506118

Epoch: 5| Step: 4
Training loss: 1.9672906398773193
Validation loss: 1.9679911623718918

Epoch: 5| Step: 5
Training loss: 2.013448715209961
Validation loss: 1.9755432195560907

Epoch: 5| Step: 6
Training loss: 1.9790318012237549
Validation loss: 1.9826752908768193

Epoch: 5| Step: 7
Training loss: 2.1679306030273438
Validation loss: 1.9858766640386274

Epoch: 5| Step: 8
Training loss: 2.1973190307617188
Validation loss: 1.993313418921604

Epoch: 5| Step: 9
Training loss: 2.062622547149658
Validation loss: 1.9777186160446496

Epoch: 5| Step: 10
Training loss: 2.4748611450195312
Validation loss: 1.9937468113437775

Epoch: 164| Step: 0
Training loss: 2.714322805404663
Validation loss: 1.994270299070625

Epoch: 5| Step: 1
Training loss: 1.5259019136428833
Validation loss: 2.004661008875857

Epoch: 5| Step: 2
Training loss: 2.1448898315429688
Validation loss: 1.9876956247514295

Epoch: 5| Step: 3
Training loss: 1.9423134326934814
Validation loss: 1.9916961603267218

Epoch: 5| Step: 4
Training loss: 2.6982789039611816
Validation loss: 2.0014555120980866

Epoch: 5| Step: 5
Training loss: 2.004443645477295
Validation loss: 2.005260717484259

Epoch: 5| Step: 6
Training loss: 2.6280176639556885
Validation loss: 2.005100738617682

Epoch: 5| Step: 7
Training loss: 2.617901563644409
Validation loss: 1.9996885343264508

Epoch: 5| Step: 8
Training loss: 1.5698553323745728
Validation loss: 2.0203867407255274

Epoch: 5| Step: 9
Training loss: 1.5115783214569092
Validation loss: 1.9969382670617872

Epoch: 5| Step: 10
Training loss: 1.6717661619186401
Validation loss: 1.9881125803916686

Epoch: 165| Step: 0
Training loss: 1.6459020376205444
Validation loss: 1.9940822393663469

Epoch: 5| Step: 1
Training loss: 2.0942089557647705
Validation loss: 1.99648868396718

Epoch: 5| Step: 2
Training loss: 1.7491967678070068
Validation loss: 1.9976992376389042

Epoch: 5| Step: 3
Training loss: 2.116856336593628
Validation loss: 2.0006119499924364

Epoch: 5| Step: 4
Training loss: 1.966168999671936
Validation loss: 2.0069743369215276

Epoch: 5| Step: 5
Training loss: 2.073699712753296
Validation loss: 1.9969569701020435

Epoch: 5| Step: 6
Training loss: 2.036501169204712
Validation loss: 2.01295926109437

Epoch: 5| Step: 7
Training loss: 2.1831860542297363
Validation loss: 2.006865325794425

Epoch: 5| Step: 8
Training loss: 2.3724331855773926
Validation loss: 2.0037253082439466

Epoch: 5| Step: 9
Training loss: 2.7698376178741455
Validation loss: 1.9932291135993054

Epoch: 5| Step: 10
Training loss: 1.975139856338501
Validation loss: 1.9954202880141556

Epoch: 166| Step: 0
Training loss: 1.594881296157837
Validation loss: 1.984058524972649

Epoch: 5| Step: 1
Training loss: 2.481356382369995
Validation loss: 2.0040764065199

Epoch: 5| Step: 2
Training loss: 2.9587974548339844
Validation loss: 2.011815917107367

Epoch: 5| Step: 3
Training loss: 2.0909993648529053
Validation loss: 1.9900436952549925

Epoch: 5| Step: 4
Training loss: 1.6914989948272705
Validation loss: 1.9947909462836482

Epoch: 5| Step: 5
Training loss: 2.5831589698791504
Validation loss: 1.9876764435921945

Epoch: 5| Step: 6
Training loss: 2.2278223037719727
Validation loss: 1.9982953866322835

Epoch: 5| Step: 7
Training loss: 1.6574037075042725
Validation loss: 1.9859872505229006

Epoch: 5| Step: 8
Training loss: 1.7564160823822021
Validation loss: 1.988072197924378

Epoch: 5| Step: 9
Training loss: 2.164799451828003
Validation loss: 1.9961164023286553

Epoch: 5| Step: 10
Training loss: 1.925409197807312
Validation loss: 1.9921374244074668

Epoch: 167| Step: 0
Training loss: 2.0469675064086914
Validation loss: 1.9661982700388918

Epoch: 5| Step: 1
Training loss: 2.053126335144043
Validation loss: 1.9924102688348422

Epoch: 5| Step: 2
Training loss: 1.8909218311309814
Validation loss: 1.9896728390006608

Epoch: 5| Step: 3
Training loss: 1.5584006309509277
Validation loss: 2.009953562931348

Epoch: 5| Step: 4
Training loss: 1.7004258632659912
Validation loss: 1.9847270058047386

Epoch: 5| Step: 5
Training loss: 1.982924222946167
Validation loss: 2.012665228177142

Epoch: 5| Step: 6
Training loss: 1.9015579223632812
Validation loss: 2.0197866142437024

Epoch: 5| Step: 7
Training loss: 2.198673725128174
Validation loss: 2.0011172679162796

Epoch: 5| Step: 8
Training loss: 2.4036366939544678
Validation loss: 1.996859622258012

Epoch: 5| Step: 9
Training loss: 2.1694176197052
Validation loss: 2.01402065959028

Epoch: 5| Step: 10
Training loss: 3.339519739151001
Validation loss: 2.008887138417972

Epoch: 168| Step: 0
Training loss: 1.9987128973007202
Validation loss: 2.0318266781427528

Epoch: 5| Step: 1
Training loss: 2.6861934661865234
Validation loss: 2.0037421462356404

Epoch: 5| Step: 2
Training loss: 2.239041805267334
Validation loss: 2.0130870201254405

Epoch: 5| Step: 3
Training loss: 1.9677461385726929
Validation loss: 1.9993131109463271

Epoch: 5| Step: 4
Training loss: 2.0850133895874023
Validation loss: 1.9907508319424045

Epoch: 5| Step: 5
Training loss: 2.164644241333008
Validation loss: 2.0079634125514696

Epoch: 5| Step: 6
Training loss: 2.0790326595306396
Validation loss: 2.0045908830499135

Epoch: 5| Step: 7
Training loss: 1.695224404335022
Validation loss: 2.0005034067297496

Epoch: 5| Step: 8
Training loss: 2.1335134506225586
Validation loss: 2.0058526569797146

Epoch: 5| Step: 9
Training loss: 1.9518197774887085
Validation loss: 1.988972395978948

Epoch: 5| Step: 10
Training loss: 1.7592438459396362
Validation loss: 1.9984442303257604

Epoch: 169| Step: 0
Training loss: 2.266775608062744
Validation loss: 2.0054237483650126

Epoch: 5| Step: 1
Training loss: 1.9183800220489502
Validation loss: 1.9842497289821666

Epoch: 5| Step: 2
Training loss: 2.021523952484131
Validation loss: 2.022742866187967

Epoch: 5| Step: 3
Training loss: 2.1882262229919434
Validation loss: 2.0032664806612077

Epoch: 5| Step: 4
Training loss: 2.2037155628204346
Validation loss: 2.0068696032288256

Epoch: 5| Step: 5
Training loss: 2.5317835807800293
Validation loss: 1.9822537206834363

Epoch: 5| Step: 6
Training loss: 1.8477096557617188
Validation loss: 2.002810976838553

Epoch: 5| Step: 7
Training loss: 2.658557415008545
Validation loss: 1.9909256235245736

Epoch: 5| Step: 8
Training loss: 1.6838061809539795
Validation loss: 1.9979769786198933

Epoch: 5| Step: 9
Training loss: 1.8416074514389038
Validation loss: 2.0077479859834075

Epoch: 5| Step: 10
Training loss: 1.5841710567474365
Validation loss: 2.0135769433872674

Epoch: 170| Step: 0
Training loss: 1.8224159479141235
Validation loss: 1.9990159157783753

Epoch: 5| Step: 1
Training loss: 2.027850389480591
Validation loss: 1.9853702181129045

Epoch: 5| Step: 2
Training loss: 2.2846572399139404
Validation loss: 2.0007195241989626

Epoch: 5| Step: 3
Training loss: 1.7937463521957397
Validation loss: 2.000655820292811

Epoch: 5| Step: 4
Training loss: 1.5852208137512207
Validation loss: 1.9623434005245086

Epoch: 5| Step: 5
Training loss: 2.3104240894317627
Validation loss: 1.9883318678025277

Epoch: 5| Step: 6
Training loss: 2.361030101776123
Validation loss: 1.984188905326269

Epoch: 5| Step: 7
Training loss: 2.3569841384887695
Validation loss: 1.9897493265008415

Epoch: 5| Step: 8
Training loss: 2.1745214462280273
Validation loss: 2.000875401240523

Epoch: 5| Step: 9
Training loss: 2.158726930618286
Validation loss: 2.0031087078073972

Epoch: 5| Step: 10
Training loss: 1.8591512441635132
Validation loss: 1.9841385349150626

Epoch: 171| Step: 0
Training loss: 1.7102909088134766
Validation loss: 1.9913036592545048

Epoch: 5| Step: 1
Training loss: 2.0099194049835205
Validation loss: 1.9836054745540823

Epoch: 5| Step: 2
Training loss: 2.842599391937256
Validation loss: 1.978150644610005

Epoch: 5| Step: 3
Training loss: 2.2261767387390137
Validation loss: 1.9620567573014127

Epoch: 5| Step: 4
Training loss: 1.8831920623779297
Validation loss: 1.99345011736757

Epoch: 5| Step: 5
Training loss: 2.4948487281799316
Validation loss: 1.9861024477148568

Epoch: 5| Step: 6
Training loss: 1.9557098150253296
Validation loss: 1.976712671659326

Epoch: 5| Step: 7
Training loss: 1.426976203918457
Validation loss: 1.982816170620662

Epoch: 5| Step: 8
Training loss: 2.414612293243408
Validation loss: 1.975012179343931

Epoch: 5| Step: 9
Training loss: 1.874312162399292
Validation loss: 1.98973040170567

Epoch: 5| Step: 10
Training loss: 2.1631052494049072
Validation loss: 1.9861606397936422

Epoch: 172| Step: 0
Training loss: 1.9464569091796875
Validation loss: 1.9854332426542878

Epoch: 5| Step: 1
Training loss: 2.181109666824341
Validation loss: 1.9703047390907042

Epoch: 5| Step: 2
Training loss: 2.299891710281372
Validation loss: 1.9758082923068796

Epoch: 5| Step: 3
Training loss: 2.0163979530334473
Validation loss: 1.9862178115434543

Epoch: 5| Step: 4
Training loss: 2.1479809284210205
Validation loss: 1.9810185778525569

Epoch: 5| Step: 5
Training loss: 1.9733946323394775
Validation loss: 2.0085856401792137

Epoch: 5| Step: 6
Training loss: 1.8336986303329468
Validation loss: 1.998562866641629

Epoch: 5| Step: 7
Training loss: 2.2878830432891846
Validation loss: 1.99370644041287

Epoch: 5| Step: 8
Training loss: 2.072221040725708
Validation loss: 1.992748786044377

Epoch: 5| Step: 9
Training loss: 2.242088794708252
Validation loss: 2.007782547704635

Epoch: 5| Step: 10
Training loss: 1.9248217344284058
Validation loss: 2.005911829651043

Epoch: 173| Step: 0
Training loss: 2.7387096881866455
Validation loss: 2.0029628097370105

Epoch: 5| Step: 1
Training loss: 1.8761581182479858
Validation loss: 2.003655932282889

Epoch: 5| Step: 2
Training loss: 2.4299206733703613
Validation loss: 1.986061091064125

Epoch: 5| Step: 3
Training loss: 1.7270103693008423
Validation loss: 1.9914266832413212

Epoch: 5| Step: 4
Training loss: 2.3151965141296387
Validation loss: 2.014438852187126

Epoch: 5| Step: 5
Training loss: 1.8697932958602905
Validation loss: 2.0096011700168734

Epoch: 5| Step: 6
Training loss: 1.7822355031967163
Validation loss: 1.9922067811412196

Epoch: 5| Step: 7
Training loss: 1.9748785495758057
Validation loss: 2.0076774461295015

Epoch: 5| Step: 8
Training loss: 1.5623222589492798
Validation loss: 1.9979415401335685

Epoch: 5| Step: 9
Training loss: 2.2336297035217285
Validation loss: 1.9921879345370876

Epoch: 5| Step: 10
Training loss: 2.3250210285186768
Validation loss: 1.950960031119726

Epoch: 174| Step: 0
Training loss: 2.583484649658203
Validation loss: 2.006556289170378

Epoch: 5| Step: 1
Training loss: 1.756299614906311
Validation loss: 1.9898983522128033

Epoch: 5| Step: 2
Training loss: 2.0000863075256348
Validation loss: 1.983055289073657

Epoch: 5| Step: 3
Training loss: 1.811527967453003
Validation loss: 1.9901218952671174

Epoch: 5| Step: 4
Training loss: 1.6258472204208374
Validation loss: 2.003755569458008

Epoch: 5| Step: 5
Training loss: 2.1837334632873535
Validation loss: 1.9873912513896983

Epoch: 5| Step: 6
Training loss: 1.8852564096450806
Validation loss: 2.014924354450677

Epoch: 5| Step: 7
Training loss: 2.311345338821411
Validation loss: 2.0006534604616064

Epoch: 5| Step: 8
Training loss: 2.1929495334625244
Validation loss: 1.9869617672376736

Epoch: 5| Step: 9
Training loss: 2.3571677207946777
Validation loss: 2.0060049064697756

Epoch: 5| Step: 10
Training loss: 2.1315464973449707
Validation loss: 2.0130166020444644

Epoch: 175| Step: 0
Training loss: 2.1976640224456787
Validation loss: 1.9873769988295853

Epoch: 5| Step: 1
Training loss: 2.1239676475524902
Validation loss: 2.0098235350783153

Epoch: 5| Step: 2
Training loss: 1.542833685874939
Validation loss: 2.003676255544027

Epoch: 5| Step: 3
Training loss: 2.249624490737915
Validation loss: 1.9712631433240828

Epoch: 5| Step: 4
Training loss: 2.000275135040283
Validation loss: 1.9973172641569568

Epoch: 5| Step: 5
Training loss: 2.545788288116455
Validation loss: 1.9966749132320445

Epoch: 5| Step: 6
Training loss: 2.3802521228790283
Validation loss: 1.9982950354135165

Epoch: 5| Step: 7
Training loss: 1.8764146566390991
Validation loss: 1.9892019379523493

Epoch: 5| Step: 8
Training loss: 1.8449491262435913
Validation loss: 1.9801283241600118

Epoch: 5| Step: 9
Training loss: 1.886290192604065
Validation loss: 1.974927354884404

Epoch: 5| Step: 10
Training loss: 2.1095778942108154
Validation loss: 2.0077149252737723

Epoch: 176| Step: 0
Training loss: 2.6213552951812744
Validation loss: 1.9650442830977901

Epoch: 5| Step: 1
Training loss: 2.0872488021850586
Validation loss: 1.9765740991920553

Epoch: 5| Step: 2
Training loss: 2.700852632522583
Validation loss: 1.9868682020453996

Epoch: 5| Step: 3
Training loss: 1.489314079284668
Validation loss: 1.9725181030970749

Epoch: 5| Step: 4
Training loss: 2.732238531112671
Validation loss: 1.9718026755958475

Epoch: 5| Step: 5
Training loss: 1.9033056497573853
Validation loss: 1.9931439186937066

Epoch: 5| Step: 6
Training loss: 2.3619484901428223
Validation loss: 1.980451108306967

Epoch: 5| Step: 7
Training loss: 1.6003376245498657
Validation loss: 1.992316779269967

Epoch: 5| Step: 8
Training loss: 1.3804376125335693
Validation loss: 1.9773334969756424

Epoch: 5| Step: 9
Training loss: 1.908255934715271
Validation loss: 1.9910822145400509

Epoch: 5| Step: 10
Training loss: 1.8794845342636108
Validation loss: 1.9801046335568993

Epoch: 177| Step: 0
Training loss: 2.1933815479278564
Validation loss: 1.97017684290486

Epoch: 5| Step: 1
Training loss: 1.6710994243621826
Validation loss: 1.970316570292237

Epoch: 5| Step: 2
Training loss: 2.1949095726013184
Validation loss: 1.976798911248484

Epoch: 5| Step: 3
Training loss: 2.285848379135132
Validation loss: 1.9875826117812947

Epoch: 5| Step: 4
Training loss: 1.4392436742782593
Validation loss: 1.9861538512732393

Epoch: 5| Step: 5
Training loss: 2.2091667652130127
Validation loss: 1.9798259555652578

Epoch: 5| Step: 6
Training loss: 2.2038068771362305
Validation loss: 1.986453406272396

Epoch: 5| Step: 7
Training loss: 2.0116450786590576
Validation loss: 1.979250087532946

Epoch: 5| Step: 8
Training loss: 1.9230432510375977
Validation loss: 1.9938505849530619

Epoch: 5| Step: 9
Training loss: 2.157384157180786
Validation loss: 1.9831327622936619

Epoch: 5| Step: 10
Training loss: 2.360954523086548
Validation loss: 1.9683661999240998

Epoch: 178| Step: 0
Training loss: 1.8534904718399048
Validation loss: 1.9795592036298526

Epoch: 5| Step: 1
Training loss: 2.348181962966919
Validation loss: 1.9797005050925798

Epoch: 5| Step: 2
Training loss: 2.4211268424987793
Validation loss: 1.9946805482269616

Epoch: 5| Step: 3
Training loss: 2.085674285888672
Validation loss: 1.975943785841747

Epoch: 5| Step: 4
Training loss: 2.0421929359436035
Validation loss: 1.9562677401368336

Epoch: 5| Step: 5
Training loss: 2.4905173778533936
Validation loss: 1.991845174502301

Epoch: 5| Step: 6
Training loss: 2.0960562229156494
Validation loss: 1.9884533087412517

Epoch: 5| Step: 7
Training loss: 1.4435584545135498
Validation loss: 1.9874994139517508

Epoch: 5| Step: 8
Training loss: 2.694450855255127
Validation loss: 1.9779342002766107

Epoch: 5| Step: 9
Training loss: 1.6750218868255615
Validation loss: 1.9746992408588369

Epoch: 5| Step: 10
Training loss: 1.6149457693099976
Validation loss: 1.9791119278118174

Epoch: 179| Step: 0
Training loss: 2.2476117610931396
Validation loss: 1.979033003571213

Epoch: 5| Step: 1
Training loss: 2.030022382736206
Validation loss: 1.9513187357174453

Epoch: 5| Step: 2
Training loss: 2.1631951332092285
Validation loss: 1.9630527521974297

Epoch: 5| Step: 3
Training loss: 1.9987163543701172
Validation loss: 1.976149418020761

Epoch: 5| Step: 4
Training loss: 2.7095563411712646
Validation loss: 1.9937906547259259

Epoch: 5| Step: 5
Training loss: 2.1545872688293457
Validation loss: 1.9874158110669864

Epoch: 5| Step: 6
Training loss: 2.1257565021514893
Validation loss: 1.9847438668691983

Epoch: 5| Step: 7
Training loss: 1.7917778491973877
Validation loss: 1.9794045596994378

Epoch: 5| Step: 8
Training loss: 1.9520610570907593
Validation loss: 1.9898614498876757

Epoch: 5| Step: 9
Training loss: 1.953078031539917
Validation loss: 1.967134875635947

Epoch: 5| Step: 10
Training loss: 1.455571174621582
Validation loss: 1.9554191712410218

Epoch: 180| Step: 0
Training loss: 1.5041162967681885
Validation loss: 1.9642862799347087

Epoch: 5| Step: 1
Training loss: 2.1755433082580566
Validation loss: 1.9697125406675442

Epoch: 5| Step: 2
Training loss: 2.3513808250427246
Validation loss: 1.9728265116291661

Epoch: 5| Step: 3
Training loss: 2.561675548553467
Validation loss: 1.967611853794385

Epoch: 5| Step: 4
Training loss: 2.4624838829040527
Validation loss: 1.9662546086054977

Epoch: 5| Step: 5
Training loss: 1.41568922996521
Validation loss: 1.9939910660507858

Epoch: 5| Step: 6
Training loss: 1.7869117259979248
Validation loss: 1.955727595154957

Epoch: 5| Step: 7
Training loss: 1.896462082862854
Validation loss: 1.9825884065320414

Epoch: 5| Step: 8
Training loss: 2.1775195598602295
Validation loss: 2.0039925844438615

Epoch: 5| Step: 9
Training loss: 2.0441203117370605
Validation loss: 1.9797931384014826

Epoch: 5| Step: 10
Training loss: 2.3945701122283936
Validation loss: 2.022309554520474

Epoch: 181| Step: 0
Training loss: 2.280818462371826
Validation loss: 1.996424526296636

Epoch: 5| Step: 1
Training loss: 2.3127951622009277
Validation loss: 1.9938378795500724

Epoch: 5| Step: 2
Training loss: 2.0060763359069824
Validation loss: 2.0005917728588147

Epoch: 5| Step: 3
Training loss: 2.2911019325256348
Validation loss: 1.9903920594082083

Epoch: 5| Step: 4
Training loss: 1.6226551532745361
Validation loss: 2.00327141182397

Epoch: 5| Step: 5
Training loss: 1.4815342426300049
Validation loss: 1.9661751113912111

Epoch: 5| Step: 6
Training loss: 1.8094031810760498
Validation loss: 1.9743136116253432

Epoch: 5| Step: 7
Training loss: 1.9377368688583374
Validation loss: 1.992140317475924

Epoch: 5| Step: 8
Training loss: 2.220752477645874
Validation loss: 1.989180298261745

Epoch: 5| Step: 9
Training loss: 2.4612464904785156
Validation loss: 1.9673365931357107

Epoch: 5| Step: 10
Training loss: 2.3502445220947266
Validation loss: 1.9778307676315308

Epoch: 182| Step: 0
Training loss: 2.150803804397583
Validation loss: 1.9596638423140331

Epoch: 5| Step: 1
Training loss: 2.450605869293213
Validation loss: 1.9831698248463292

Epoch: 5| Step: 2
Training loss: 2.001006841659546
Validation loss: 1.962535378753498

Epoch: 5| Step: 3
Training loss: 1.9094173908233643
Validation loss: 1.9609425901084818

Epoch: 5| Step: 4
Training loss: 2.3544676303863525
Validation loss: 1.9766920099976242

Epoch: 5| Step: 5
Training loss: 1.8629124164581299
Validation loss: 1.9720120699174943

Epoch: 5| Step: 6
Training loss: 1.9000314474105835
Validation loss: 1.9920695840671498

Epoch: 5| Step: 7
Training loss: 1.598970651626587
Validation loss: 1.985464156314891

Epoch: 5| Step: 8
Training loss: 2.1215720176696777
Validation loss: 1.9667772849400837

Epoch: 5| Step: 9
Training loss: 2.166267156600952
Validation loss: 1.997658424479987

Epoch: 5| Step: 10
Training loss: 2.2110047340393066
Validation loss: 1.964349599294765

Epoch: 183| Step: 0
Training loss: 2.0617072582244873
Validation loss: 1.975228404486051

Epoch: 5| Step: 1
Training loss: 1.8415638208389282
Validation loss: 1.969656950684004

Epoch: 5| Step: 2
Training loss: 1.6605641841888428
Validation loss: 1.996508526545699

Epoch: 5| Step: 3
Training loss: 1.819286584854126
Validation loss: 1.992894084222855

Epoch: 5| Step: 4
Training loss: 2.6558690071105957
Validation loss: 1.975789987912742

Epoch: 5| Step: 5
Training loss: 2.3078763484954834
Validation loss: 1.9968050833671325

Epoch: 5| Step: 6
Training loss: 1.9807970523834229
Validation loss: 1.976660781009223

Epoch: 5| Step: 7
Training loss: 2.085641384124756
Validation loss: 1.9718978148634716

Epoch: 5| Step: 8
Training loss: 1.9224634170532227
Validation loss: 1.9866542841798516

Epoch: 5| Step: 9
Training loss: 2.3218178749084473
Validation loss: 1.9813959444722822

Epoch: 5| Step: 10
Training loss: 2.0597243309020996
Validation loss: 1.9681779492285945

Epoch: 184| Step: 0
Training loss: 2.317868709564209
Validation loss: 1.981489263555055

Epoch: 5| Step: 1
Training loss: 2.044304370880127
Validation loss: 1.9913805197643977

Epoch: 5| Step: 2
Training loss: 2.0220041275024414
Validation loss: 1.9978770530352028

Epoch: 5| Step: 3
Training loss: 1.3764349222183228
Validation loss: 1.9970575583878385

Epoch: 5| Step: 4
Training loss: 2.0129551887512207
Validation loss: 1.9916053895027406

Epoch: 5| Step: 5
Training loss: 2.6028523445129395
Validation loss: 1.9836106479808848

Epoch: 5| Step: 6
Training loss: 1.8546512126922607
Validation loss: 1.9826697380312028

Epoch: 5| Step: 7
Training loss: 2.1047775745391846
Validation loss: 1.986820218383625

Epoch: 5| Step: 8
Training loss: 2.147008180618286
Validation loss: 1.995240601160193

Epoch: 5| Step: 9
Training loss: 1.712874174118042
Validation loss: 1.9659759357411375

Epoch: 5| Step: 10
Training loss: 2.5266432762145996
Validation loss: 1.9957686111491213

Epoch: 185| Step: 0
Training loss: 1.537401795387268
Validation loss: 1.9977823559955885

Epoch: 5| Step: 1
Training loss: 1.7299680709838867
Validation loss: 1.9985572291958718

Epoch: 5| Step: 2
Training loss: 2.2929763793945312
Validation loss: 1.9703075731954267

Epoch: 5| Step: 3
Training loss: 2.1330294609069824
Validation loss: 1.9798654202492005

Epoch: 5| Step: 4
Training loss: 2.3536107540130615
Validation loss: 1.980753408965244

Epoch: 5| Step: 5
Training loss: 2.2671103477478027
Validation loss: 2.006177930421727

Epoch: 5| Step: 6
Training loss: 2.262714147567749
Validation loss: 1.9989073045792118

Epoch: 5| Step: 7
Training loss: 2.0294337272644043
Validation loss: 1.9907394545052641

Epoch: 5| Step: 8
Training loss: 1.6451270580291748
Validation loss: 1.990737561256655

Epoch: 5| Step: 9
Training loss: 2.3803281784057617
Validation loss: 1.966922918955485

Epoch: 5| Step: 10
Training loss: 1.9342793226242065
Validation loss: 1.9902137159019389

Epoch: 186| Step: 0
Training loss: 2.241666793823242
Validation loss: 1.9919112138850714

Epoch: 5| Step: 1
Training loss: 2.665332317352295
Validation loss: 1.9716395819058983

Epoch: 5| Step: 2
Training loss: 1.2487741708755493
Validation loss: 1.9821922804719658

Epoch: 5| Step: 3
Training loss: 2.4274544715881348
Validation loss: 1.9696093707956293

Epoch: 5| Step: 4
Training loss: 1.8622949123382568
Validation loss: 1.979889556925784

Epoch: 5| Step: 5
Training loss: 1.4789862632751465
Validation loss: 1.977777519533711

Epoch: 5| Step: 6
Training loss: 1.9343135356903076
Validation loss: 1.979276373822202

Epoch: 5| Step: 7
Training loss: 1.8365118503570557
Validation loss: 1.9749872223023446

Epoch: 5| Step: 8
Training loss: 2.344447612762451
Validation loss: 1.970295916321457

Epoch: 5| Step: 9
Training loss: 2.2233424186706543
Validation loss: 1.9801007739959224

Epoch: 5| Step: 10
Training loss: 2.2981185913085938
Validation loss: 1.941878995587749

Epoch: 187| Step: 0
Training loss: 1.7731002569198608
Validation loss: 1.9613520047997917

Epoch: 5| Step: 1
Training loss: 2.039987564086914
Validation loss: 1.9802695935772312

Epoch: 5| Step: 2
Training loss: 1.8229764699935913
Validation loss: 1.9648154807347122

Epoch: 5| Step: 3
Training loss: 2.247098207473755
Validation loss: 1.9746847947438557

Epoch: 5| Step: 4
Training loss: 2.1315436363220215
Validation loss: 1.977160269214261

Epoch: 5| Step: 5
Training loss: 1.7827774286270142
Validation loss: 1.9673395144042147

Epoch: 5| Step: 6
Training loss: 2.174171209335327
Validation loss: 1.9856241082632413

Epoch: 5| Step: 7
Training loss: 1.7566982507705688
Validation loss: 1.9985079893501856

Epoch: 5| Step: 8
Training loss: 2.2056870460510254
Validation loss: 1.9668258056845715

Epoch: 5| Step: 9
Training loss: 2.374166250228882
Validation loss: 1.9687354667212373

Epoch: 5| Step: 10
Training loss: 2.2532711029052734
Validation loss: 1.9970052139733427

Epoch: 188| Step: 0
Training loss: 2.092935085296631
Validation loss: 1.9745653854903353

Epoch: 5| Step: 1
Training loss: 1.7707712650299072
Validation loss: 1.9674178272165277

Epoch: 5| Step: 2
Training loss: 2.27687406539917
Validation loss: 1.9860548511628182

Epoch: 5| Step: 3
Training loss: 1.9744764566421509
Validation loss: 1.981002059034122

Epoch: 5| Step: 4
Training loss: 2.390869140625
Validation loss: 1.9785608066025602

Epoch: 5| Step: 5
Training loss: 2.0570690631866455
Validation loss: 2.011399394722395

Epoch: 5| Step: 6
Training loss: 2.036233425140381
Validation loss: 1.9957739742853309

Epoch: 5| Step: 7
Training loss: 1.6371796131134033
Validation loss: 1.9743097110461163

Epoch: 5| Step: 8
Training loss: 1.8956348896026611
Validation loss: 1.9915180360117266

Epoch: 5| Step: 9
Training loss: 2.0995278358459473
Validation loss: 2.0054985066895843

Epoch: 5| Step: 10
Training loss: 2.3118298053741455
Validation loss: 1.9876157955456806

Epoch: 189| Step: 0
Training loss: 2.091531276702881
Validation loss: 1.9862428326760568

Epoch: 5| Step: 1
Training loss: 1.7270361185073853
Validation loss: 1.9882240897865706

Epoch: 5| Step: 2
Training loss: 2.0104432106018066
Validation loss: 1.9867621788414576

Epoch: 5| Step: 3
Training loss: 2.028785228729248
Validation loss: 1.9921052532811319

Epoch: 5| Step: 4
Training loss: 1.8630825281143188
Validation loss: 2.0135251347736647

Epoch: 5| Step: 5
Training loss: 2.109562397003174
Validation loss: 2.0080992816596903

Epoch: 5| Step: 6
Training loss: 1.7122987508773804
Validation loss: 1.9937731335240025

Epoch: 5| Step: 7
Training loss: 1.9690841436386108
Validation loss: 1.9933961924686228

Epoch: 5| Step: 8
Training loss: 2.540459156036377
Validation loss: 1.981024351171268

Epoch: 5| Step: 9
Training loss: 2.139967441558838
Validation loss: 1.969865115739966

Epoch: 5| Step: 10
Training loss: 2.1238458156585693
Validation loss: 1.9828675164971301

Epoch: 190| Step: 0
Training loss: 2.5572025775909424
Validation loss: 1.9949921138824955

Epoch: 5| Step: 1
Training loss: 2.220120906829834
Validation loss: 1.9808613869451708

Epoch: 5| Step: 2
Training loss: 1.8259327411651611
Validation loss: 1.9764299725973478

Epoch: 5| Step: 3
Training loss: 2.2062833309173584
Validation loss: 2.016456283548827

Epoch: 5| Step: 4
Training loss: 1.650787115097046
Validation loss: 1.950104813421926

Epoch: 5| Step: 5
Training loss: 1.544744849205017
Validation loss: 1.974021247638169

Epoch: 5| Step: 6
Training loss: 2.688931703567505
Validation loss: 1.9684482953881706

Epoch: 5| Step: 7
Training loss: 2.4002881050109863
Validation loss: 1.988424567766087

Epoch: 5| Step: 8
Training loss: 1.927438735961914
Validation loss: 1.9662179331625662

Epoch: 5| Step: 9
Training loss: 1.5496301651000977
Validation loss: 1.9866195263401154

Epoch: 5| Step: 10
Training loss: 2.066592216491699
Validation loss: 1.9584852136591429

Epoch: 191| Step: 0
Training loss: 2.2427303791046143
Validation loss: 1.979192349218553

Epoch: 5| Step: 1
Training loss: 1.444652795791626
Validation loss: 1.9952854302621656

Epoch: 5| Step: 2
Training loss: 1.6805299520492554
Validation loss: 1.9884873000524377

Epoch: 5| Step: 3
Training loss: 2.151747226715088
Validation loss: 1.994459987968527

Epoch: 5| Step: 4
Training loss: 2.6587259769439697
Validation loss: 1.9667041532454952

Epoch: 5| Step: 5
Training loss: 1.685164451599121
Validation loss: 1.970013205723096

Epoch: 5| Step: 6
Training loss: 2.331206798553467
Validation loss: 1.9830137401498773

Epoch: 5| Step: 7
Training loss: 1.83246648311615
Validation loss: 1.9705778296275804

Epoch: 5| Step: 8
Training loss: 1.9429900646209717
Validation loss: 1.976182073675176

Epoch: 5| Step: 9
Training loss: 2.0717251300811768
Validation loss: 1.9755195789439703

Epoch: 5| Step: 10
Training loss: 2.426903486251831
Validation loss: 1.9825117459861181

Epoch: 192| Step: 0
Training loss: 1.7777483463287354
Validation loss: 1.9821974308260026

Epoch: 5| Step: 1
Training loss: 2.477353811264038
Validation loss: 1.9734730566701582

Epoch: 5| Step: 2
Training loss: 1.361295223236084
Validation loss: 1.9793437770617905

Epoch: 5| Step: 3
Training loss: 2.2820096015930176
Validation loss: 1.9524450173941992

Epoch: 5| Step: 4
Training loss: 2.4380276203155518
Validation loss: 1.9499979967712073

Epoch: 5| Step: 5
Training loss: 2.0456383228302
Validation loss: 1.9746789009340349

Epoch: 5| Step: 6
Training loss: 2.2321012020111084
Validation loss: 1.9593446998186008

Epoch: 5| Step: 7
Training loss: 2.1785635948181152
Validation loss: 1.9544699909866496

Epoch: 5| Step: 8
Training loss: 1.668900728225708
Validation loss: 1.9598972771757392

Epoch: 5| Step: 9
Training loss: 2.0823147296905518
Validation loss: 1.9723305394572597

Epoch: 5| Step: 10
Training loss: 1.7760238647460938
Validation loss: 1.9689724919616536

Epoch: 193| Step: 0
Training loss: 2.1554818153381348
Validation loss: 1.9797954264507498

Epoch: 5| Step: 1
Training loss: 2.1323564052581787
Validation loss: 1.968303257419217

Epoch: 5| Step: 2
Training loss: 2.071415424346924
Validation loss: 1.9540837477612238

Epoch: 5| Step: 3
Training loss: 1.5344128608703613
Validation loss: 1.9673075073508806

Epoch: 5| Step: 4
Training loss: 1.6945078372955322
Validation loss: 1.9636463298592517

Epoch: 5| Step: 5
Training loss: 1.8884601593017578
Validation loss: 1.975380370693822

Epoch: 5| Step: 6
Training loss: 2.4882073402404785
Validation loss: 1.9546995509055354

Epoch: 5| Step: 7
Training loss: 2.422990560531616
Validation loss: 1.9685785744779853

Epoch: 5| Step: 8
Training loss: 1.7762556076049805
Validation loss: 1.9685625465967322

Epoch: 5| Step: 9
Training loss: 1.6416337490081787
Validation loss: 1.946391046688121

Epoch: 5| Step: 10
Training loss: 2.7166805267333984
Validation loss: 1.9759750379029142

Epoch: 194| Step: 0
Training loss: 1.8968727588653564
Validation loss: 1.972213586171468

Epoch: 5| Step: 1
Training loss: 2.2098464965820312
Validation loss: 1.9750974691042336

Epoch: 5| Step: 2
Training loss: 2.111583948135376
Validation loss: 1.985471357581436

Epoch: 5| Step: 3
Training loss: 1.6109821796417236
Validation loss: 1.9470999676694152

Epoch: 5| Step: 4
Training loss: 2.214679479598999
Validation loss: 1.9719334161409767

Epoch: 5| Step: 5
Training loss: 1.8705146312713623
Validation loss: 1.9600888631677116

Epoch: 5| Step: 6
Training loss: 2.2483270168304443
Validation loss: 1.9469922434899114

Epoch: 5| Step: 7
Training loss: 2.539808988571167
Validation loss: 1.9673890849595428

Epoch: 5| Step: 8
Training loss: 2.289586305618286
Validation loss: 1.9829093435759186

Epoch: 5| Step: 9
Training loss: 1.883838415145874
Validation loss: 1.9667476941180486

Epoch: 5| Step: 10
Training loss: 1.5220715999603271
Validation loss: 1.9715345482672415

Epoch: 195| Step: 0
Training loss: 1.5932328701019287
Validation loss: 1.9772692636776996

Epoch: 5| Step: 1
Training loss: 1.9904439449310303
Validation loss: 1.9831282913043935

Epoch: 5| Step: 2
Training loss: 2.0086283683776855
Validation loss: 1.988126700924289

Epoch: 5| Step: 3
Training loss: 2.4933536052703857
Validation loss: 1.9840598388384747

Epoch: 5| Step: 4
Training loss: 1.7632620334625244
Validation loss: 1.9556198555936095

Epoch: 5| Step: 5
Training loss: 2.4949045181274414
Validation loss: 1.9829000606331775

Epoch: 5| Step: 6
Training loss: 2.1828553676605225
Validation loss: 1.9763967426874305

Epoch: 5| Step: 7
Training loss: 1.9856398105621338
Validation loss: 1.987936690289487

Epoch: 5| Step: 8
Training loss: 2.063913345336914
Validation loss: 1.9871634360282653

Epoch: 5| Step: 9
Training loss: 1.6052637100219727
Validation loss: 1.9739178508840582

Epoch: 5| Step: 10
Training loss: 2.167107582092285
Validation loss: 1.9847645298127206

Epoch: 196| Step: 0
Training loss: 2.6704788208007812
Validation loss: 1.9550110986155849

Epoch: 5| Step: 1
Training loss: 1.78366219997406
Validation loss: 1.9842293570118565

Epoch: 5| Step: 2
Training loss: 1.9127693176269531
Validation loss: 1.977430446173555

Epoch: 5| Step: 3
Training loss: 2.0108160972595215
Validation loss: 1.9782637498712028

Epoch: 5| Step: 4
Training loss: 1.6139198541641235
Validation loss: 1.98518035745108

Epoch: 5| Step: 5
Training loss: 2.5114071369171143
Validation loss: 1.978206056420521

Epoch: 5| Step: 6
Training loss: 1.685636281967163
Validation loss: 1.9775306178677468

Epoch: 5| Step: 7
Training loss: 1.919865369796753
Validation loss: 1.9805517965747463

Epoch: 5| Step: 8
Training loss: 2.107760190963745
Validation loss: 1.9912648508625646

Epoch: 5| Step: 9
Training loss: 2.358147144317627
Validation loss: 1.978018556871722

Epoch: 5| Step: 10
Training loss: 1.6250840425491333
Validation loss: 1.9816335888319119

Epoch: 197| Step: 0
Training loss: 2.715750217437744
Validation loss: 1.9859290276804278

Epoch: 5| Step: 1
Training loss: 1.9518632888793945
Validation loss: 1.9877250912368938

Epoch: 5| Step: 2
Training loss: 1.6505111455917358
Validation loss: 1.9732893077276086

Epoch: 5| Step: 3
Training loss: 1.5939775705337524
Validation loss: 1.9669847155130038

Epoch: 5| Step: 4
Training loss: 2.1622250080108643
Validation loss: 1.9898611640417447

Epoch: 5| Step: 5
Training loss: 1.6716111898422241
Validation loss: 2.0009669232112106

Epoch: 5| Step: 6
Training loss: 1.9337879419326782
Validation loss: 1.9585191126792663

Epoch: 5| Step: 7
Training loss: 2.2724039554595947
Validation loss: 1.9668194517012565

Epoch: 5| Step: 8
Training loss: 1.7425296306610107
Validation loss: 1.9596887045009161

Epoch: 5| Step: 9
Training loss: 2.246673583984375
Validation loss: 1.9710016865884104

Epoch: 5| Step: 10
Training loss: 2.3042562007904053
Validation loss: 1.9636561588574482

Epoch: 198| Step: 0
Training loss: 2.11309552192688
Validation loss: 1.992981667159706

Epoch: 5| Step: 1
Training loss: 1.8150746822357178
Validation loss: 1.9644310679487003

Epoch: 5| Step: 2
Training loss: 2.0347447395324707
Validation loss: 1.9522602583772393

Epoch: 5| Step: 3
Training loss: 1.6080678701400757
Validation loss: 1.9539645692353607

Epoch: 5| Step: 4
Training loss: 1.922909140586853
Validation loss: 1.9640079044526624

Epoch: 5| Step: 5
Training loss: 2.002676010131836
Validation loss: 1.967900272338621

Epoch: 5| Step: 6
Training loss: 2.5217368602752686
Validation loss: 1.9617312210862354

Epoch: 5| Step: 7
Training loss: 2.1193647384643555
Validation loss: 1.9852813751466813

Epoch: 5| Step: 8
Training loss: 2.045053005218506
Validation loss: 1.9700473534163607

Epoch: 5| Step: 9
Training loss: 1.962776780128479
Validation loss: 1.999310738296919

Epoch: 5| Step: 10
Training loss: 2.001307725906372
Validation loss: 1.9733700393348612

Epoch: 199| Step: 0
Training loss: 2.0079283714294434
Validation loss: 1.9648206721069992

Epoch: 5| Step: 1
Training loss: 2.3677217960357666
Validation loss: 1.9646222796491397

Epoch: 5| Step: 2
Training loss: 1.8687255382537842
Validation loss: 1.9974960588639783

Epoch: 5| Step: 3
Training loss: 1.2065616846084595
Validation loss: 1.9776324969466015

Epoch: 5| Step: 4
Training loss: 1.5317169427871704
Validation loss: 1.981960456858399

Epoch: 5| Step: 5
Training loss: 2.5121848583221436
Validation loss: 1.9650250224656955

Epoch: 5| Step: 6
Training loss: 2.4929893016815186
Validation loss: 1.9661323357653875

Epoch: 5| Step: 7
Training loss: 1.6176121234893799
Validation loss: 1.986021916071574

Epoch: 5| Step: 8
Training loss: 2.524810791015625
Validation loss: 1.9769629406672653

Epoch: 5| Step: 9
Training loss: 2.0148000717163086
Validation loss: 1.960407236570953

Epoch: 5| Step: 10
Training loss: 1.889531135559082
Validation loss: 1.9576175840952064

Epoch: 200| Step: 0
Training loss: 1.738115668296814
Validation loss: 1.9608853042766612

Epoch: 5| Step: 1
Training loss: 1.9134540557861328
Validation loss: 1.985912533216579

Epoch: 5| Step: 2
Training loss: 2.3356575965881348
Validation loss: 1.9919423851915585

Epoch: 5| Step: 3
Training loss: 2.0903217792510986
Validation loss: 1.967151423936249

Epoch: 5| Step: 4
Training loss: 2.2521371841430664
Validation loss: 1.9769496751087967

Epoch: 5| Step: 5
Training loss: 1.7694625854492188
Validation loss: 1.9695153082570722

Epoch: 5| Step: 6
Training loss: 2.197772979736328
Validation loss: 1.9901008144501717

Epoch: 5| Step: 7
Training loss: 1.9608932733535767
Validation loss: 1.9625389255503172

Epoch: 5| Step: 8
Training loss: 1.9850490093231201
Validation loss: 1.971144796699606

Epoch: 5| Step: 9
Training loss: 2.455591917037964
Validation loss: 1.9530726658400668

Epoch: 5| Step: 10
Training loss: 1.346933126449585
Validation loss: 1.981967915770828

Epoch: 201| Step: 0
Training loss: 2.416236162185669
Validation loss: 1.9914136112377208

Epoch: 5| Step: 1
Training loss: 1.7590992450714111
Validation loss: 1.9959195301096926

Epoch: 5| Step: 2
Training loss: 2.327169895172119
Validation loss: 1.9570496466852003

Epoch: 5| Step: 3
Training loss: 2.122870922088623
Validation loss: 1.952314107648788

Epoch: 5| Step: 4
Training loss: 1.6181347370147705
Validation loss: 1.9698456307893157

Epoch: 5| Step: 5
Training loss: 2.364966630935669
Validation loss: 1.9625669217878772

Epoch: 5| Step: 6
Training loss: 2.3928604125976562
Validation loss: 1.968101720656118

Epoch: 5| Step: 7
Training loss: 1.9161533117294312
Validation loss: 1.9787797351037302

Epoch: 5| Step: 8
Training loss: 1.9243052005767822
Validation loss: 1.9820293559822986

Epoch: 5| Step: 9
Training loss: 1.4851152896881104
Validation loss: 1.9843744411263415

Epoch: 5| Step: 10
Training loss: 1.815835952758789
Validation loss: 1.9714995494452856

Epoch: 202| Step: 0
Training loss: 2.219587564468384
Validation loss: 1.9309482189916796

Epoch: 5| Step: 1
Training loss: 1.9143422842025757
Validation loss: 1.9651703014168689

Epoch: 5| Step: 2
Training loss: 1.2288978099822998
Validation loss: 1.976082694145941

Epoch: 5| Step: 3
Training loss: 2.366741895675659
Validation loss: 1.93254501845247

Epoch: 5| Step: 4
Training loss: 1.8108272552490234
Validation loss: 1.9563251554325063

Epoch: 5| Step: 5
Training loss: 2.1220192909240723
Validation loss: 1.9635119027988885

Epoch: 5| Step: 6
Training loss: 1.7820762395858765
Validation loss: 1.9513805656022922

Epoch: 5| Step: 7
Training loss: 1.6125377416610718
Validation loss: 1.945222987923571

Epoch: 5| Step: 8
Training loss: 1.9656280279159546
Validation loss: 1.947685598045267

Epoch: 5| Step: 9
Training loss: 3.0153417587280273
Validation loss: 1.9642746986881379

Epoch: 5| Step: 10
Training loss: 2.110375165939331
Validation loss: 1.960627204628401

Epoch: 203| Step: 0
Training loss: 1.6403789520263672
Validation loss: 1.9637481845835203

Epoch: 5| Step: 1
Training loss: 1.66818106174469
Validation loss: 1.9786016761615712

Epoch: 5| Step: 2
Training loss: 2.3686025142669678
Validation loss: 1.9533842712320306

Epoch: 5| Step: 3
Training loss: 2.2501184940338135
Validation loss: 1.9652231624049525

Epoch: 5| Step: 4
Training loss: 1.8519216775894165
Validation loss: 1.983786133027846

Epoch: 5| Step: 5
Training loss: 2.260627269744873
Validation loss: 1.985655919198067

Epoch: 5| Step: 6
Training loss: 2.194152355194092
Validation loss: 1.9862750191842355

Epoch: 5| Step: 7
Training loss: 2.320009469985962
Validation loss: 1.9809097910440097

Epoch: 5| Step: 8
Training loss: 1.286712646484375
Validation loss: 1.9775595767523653

Epoch: 5| Step: 9
Training loss: 1.9689756631851196
Validation loss: 1.9684357373945174

Epoch: 5| Step: 10
Training loss: 2.3554208278656006
Validation loss: 1.9910965619548675

Epoch: 204| Step: 0
Training loss: 1.9711172580718994
Validation loss: 2.0107599150749946

Epoch: 5| Step: 1
Training loss: 1.9846248626708984
Validation loss: 1.9644280479800316

Epoch: 5| Step: 2
Training loss: 1.5976383686065674
Validation loss: 1.9723152909227597

Epoch: 5| Step: 3
Training loss: 2.1692862510681152
Validation loss: 1.9864855966260355

Epoch: 5| Step: 4
Training loss: 1.8668687343597412
Validation loss: 1.9892502753965315

Epoch: 5| Step: 5
Training loss: 2.312534809112549
Validation loss: 1.976883437043877

Epoch: 5| Step: 6
Training loss: 2.1698825359344482
Validation loss: 1.9682983506110407

Epoch: 5| Step: 7
Training loss: 1.996254563331604
Validation loss: 1.9766048641615017

Epoch: 5| Step: 8
Training loss: 1.871124267578125
Validation loss: 1.9602770882268106

Epoch: 5| Step: 9
Training loss: 2.101907253265381
Validation loss: 1.9726533966679727

Epoch: 5| Step: 10
Training loss: 2.1836092472076416
Validation loss: 1.9700725975856985

Epoch: 205| Step: 0
Training loss: 2.1128859519958496
Validation loss: 1.9640164144577519

Epoch: 5| Step: 1
Training loss: 1.4892202615737915
Validation loss: 1.9575126683840187

Epoch: 5| Step: 2
Training loss: 1.9961254596710205
Validation loss: 1.9440675935437601

Epoch: 5| Step: 3
Training loss: 1.9111143350601196
Validation loss: 1.9770084042702951

Epoch: 5| Step: 4
Training loss: 1.5589252710342407
Validation loss: 1.9426834634555283

Epoch: 5| Step: 5
Training loss: 2.207639217376709
Validation loss: 1.9492953797822357

Epoch: 5| Step: 6
Training loss: 2.504310131072998
Validation loss: 1.945627990589347

Epoch: 5| Step: 7
Training loss: 2.2466769218444824
Validation loss: 1.96380022264296

Epoch: 5| Step: 8
Training loss: 2.057239532470703
Validation loss: 1.9563546385816348

Epoch: 5| Step: 9
Training loss: 1.7620868682861328
Validation loss: 1.9682436553380822

Epoch: 5| Step: 10
Training loss: 2.2942540645599365
Validation loss: 1.966497157209663

Epoch: 206| Step: 0
Training loss: 1.4954898357391357
Validation loss: 1.972531057173206

Epoch: 5| Step: 1
Training loss: 2.347628355026245
Validation loss: 1.9769687011677732

Epoch: 5| Step: 2
Training loss: 2.504236936569214
Validation loss: 1.9395623899275256

Epoch: 5| Step: 3
Training loss: 2.2493090629577637
Validation loss: 1.9571974495405793

Epoch: 5| Step: 4
Training loss: 2.7153491973876953
Validation loss: 1.9501241778814664

Epoch: 5| Step: 5
Training loss: 1.6187413930892944
Validation loss: 1.9504801880928777

Epoch: 5| Step: 6
Training loss: 1.97456955909729
Validation loss: 1.9880369632474837

Epoch: 5| Step: 7
Training loss: 2.0040676593780518
Validation loss: 1.9589718695609801

Epoch: 5| Step: 8
Training loss: 1.7088619470596313
Validation loss: 1.978611538487096

Epoch: 5| Step: 9
Training loss: 1.3351218700408936
Validation loss: 1.965925210265703

Epoch: 5| Step: 10
Training loss: 2.1755707263946533
Validation loss: 1.9516443680691462

Epoch: 207| Step: 0
Training loss: 2.5511088371276855
Validation loss: 1.9572219412813905

Epoch: 5| Step: 1
Training loss: 2.656052589416504
Validation loss: 1.9804583390553792

Epoch: 5| Step: 2
Training loss: 1.6656395196914673
Validation loss: 1.9629750623497912

Epoch: 5| Step: 3
Training loss: 1.9404910802841187
Validation loss: 1.9739223987825456

Epoch: 5| Step: 4
Training loss: 2.1613247394561768
Validation loss: 1.9512353456148537

Epoch: 5| Step: 5
Training loss: 2.5027260780334473
Validation loss: 1.9669458532846102

Epoch: 5| Step: 6
Training loss: 1.8140556812286377
Validation loss: 1.948156387575211

Epoch: 5| Step: 7
Training loss: 1.329147458076477
Validation loss: 1.9630382535278157

Epoch: 5| Step: 8
Training loss: 1.9321584701538086
Validation loss: 1.9417062190271193

Epoch: 5| Step: 9
Training loss: 1.2311903238296509
Validation loss: 1.9436761922733758

Epoch: 5| Step: 10
Training loss: 2.2853145599365234
Validation loss: 1.940465195204622

Epoch: 208| Step: 0
Training loss: 1.7339651584625244
Validation loss: 1.9539655216278569

Epoch: 5| Step: 1
Training loss: 1.9098243713378906
Validation loss: 1.959735729361093

Epoch: 5| Step: 2
Training loss: 2.1617705821990967
Validation loss: 1.9498505823073848

Epoch: 5| Step: 3
Training loss: 2.0027153491973877
Validation loss: 1.9488341782682685

Epoch: 5| Step: 4
Training loss: 2.2322072982788086
Validation loss: 1.9584346336703147

Epoch: 5| Step: 5
Training loss: 2.460340976715088
Validation loss: 1.9562088802296629

Epoch: 5| Step: 6
Training loss: 1.7822822332382202
Validation loss: 1.9512573262696624

Epoch: 5| Step: 7
Training loss: 1.334855318069458
Validation loss: 1.9821542552722398

Epoch: 5| Step: 8
Training loss: 2.2044217586517334
Validation loss: 1.9399099875521917

Epoch: 5| Step: 9
Training loss: 1.4468648433685303
Validation loss: 1.9693575994942778

Epoch: 5| Step: 10
Training loss: 2.899413585662842
Validation loss: 1.9865669358161189

Epoch: 209| Step: 0
Training loss: 2.4542465209960938
Validation loss: 1.9337458866898731

Epoch: 5| Step: 1
Training loss: 1.8966491222381592
Validation loss: 1.958488961701752

Epoch: 5| Step: 2
Training loss: 2.0333876609802246
Validation loss: 1.936480350391839

Epoch: 5| Step: 3
Training loss: 1.829899549484253
Validation loss: 1.9419330794324157

Epoch: 5| Step: 4
Training loss: 2.079773187637329
Validation loss: 1.9588292196232786

Epoch: 5| Step: 5
Training loss: 1.5225757360458374
Validation loss: 1.9521426423903434

Epoch: 5| Step: 6
Training loss: 1.880353331565857
Validation loss: 1.9578536736067904

Epoch: 5| Step: 7
Training loss: 2.078927516937256
Validation loss: 1.959063546631926

Epoch: 5| Step: 8
Training loss: 2.3043341636657715
Validation loss: 1.9498178074436803

Epoch: 5| Step: 9
Training loss: 1.5497188568115234
Validation loss: 1.9490056653176584

Epoch: 5| Step: 10
Training loss: 2.4724793434143066
Validation loss: 1.9584160799621253

Epoch: 210| Step: 0
Training loss: 2.0498738288879395
Validation loss: 1.96133755612117

Epoch: 5| Step: 1
Training loss: 1.8983185291290283
Validation loss: 1.955355926226544

Epoch: 5| Step: 2
Training loss: 2.304067850112915
Validation loss: 1.991701364517212

Epoch: 5| Step: 3
Training loss: 1.5511966943740845
Validation loss: 1.960716910259698

Epoch: 5| Step: 4
Training loss: 1.1543323993682861
Validation loss: 1.9922797551719091

Epoch: 5| Step: 5
Training loss: 2.4212677478790283
Validation loss: 1.9434046822209512

Epoch: 5| Step: 6
Training loss: 2.4064784049987793
Validation loss: 1.95547773761134

Epoch: 5| Step: 7
Training loss: 2.2158408164978027
Validation loss: 1.9412666905310847

Epoch: 5| Step: 8
Training loss: 2.145012140274048
Validation loss: 1.9574182148902648

Epoch: 5| Step: 9
Training loss: 1.5715625286102295
Validation loss: 1.9608997888462518

Epoch: 5| Step: 10
Training loss: 2.02663254737854
Validation loss: 1.9596056066533571

Epoch: 211| Step: 0
Training loss: 1.993906021118164
Validation loss: 1.9622656235130884

Epoch: 5| Step: 1
Training loss: 1.9364726543426514
Validation loss: 1.9906147859429801

Epoch: 5| Step: 2
Training loss: 2.2053656578063965
Validation loss: 1.996458117679883

Epoch: 5| Step: 3
Training loss: 1.7725032567977905
Validation loss: 1.9623795747756958

Epoch: 5| Step: 4
Training loss: 1.9659221172332764
Validation loss: 1.9838700576495099

Epoch: 5| Step: 5
Training loss: 2.4191081523895264
Validation loss: 1.9779615479130899

Epoch: 5| Step: 6
Training loss: 2.265773296356201
Validation loss: 2.005964472729673

Epoch: 5| Step: 7
Training loss: 2.1859145164489746
Validation loss: 1.9712926392914147

Epoch: 5| Step: 8
Training loss: 1.2754465341567993
Validation loss: 1.9899329703341249

Epoch: 5| Step: 9
Training loss: 2.0633158683776855
Validation loss: 1.9925640372819797

Epoch: 5| Step: 10
Training loss: 1.7999473810195923
Validation loss: 1.9920686060382473

Epoch: 212| Step: 0
Training loss: 2.190462827682495
Validation loss: 1.9739832519203104

Epoch: 5| Step: 1
Training loss: 1.9456361532211304
Validation loss: 1.9693171157631824

Epoch: 5| Step: 2
Training loss: 1.4689794778823853
Validation loss: 1.9608876256532566

Epoch: 5| Step: 3
Training loss: 2.278669834136963
Validation loss: 1.9686730318172003

Epoch: 5| Step: 4
Training loss: 1.1365392208099365
Validation loss: 1.9574934128792054

Epoch: 5| Step: 5
Training loss: 2.0624148845672607
Validation loss: 1.9478130071393904

Epoch: 5| Step: 6
Training loss: 1.9216680526733398
Validation loss: 1.935460603365334

Epoch: 5| Step: 7
Training loss: 1.6718286275863647
Validation loss: 1.981140931447347

Epoch: 5| Step: 8
Training loss: 2.346693992614746
Validation loss: 1.9588149350176576

Epoch: 5| Step: 9
Training loss: 2.479602575302124
Validation loss: 1.953260919099213

Epoch: 5| Step: 10
Training loss: 2.2800445556640625
Validation loss: 1.9558174353773876

Epoch: 213| Step: 0
Training loss: 2.032848358154297
Validation loss: 1.942376095761535

Epoch: 5| Step: 1
Training loss: 2.123772382736206
Validation loss: 1.9330129751595118

Epoch: 5| Step: 2
Training loss: 1.4541727304458618
Validation loss: 1.9339080933601625

Epoch: 5| Step: 3
Training loss: 2.213378667831421
Validation loss: 1.946103403645177

Epoch: 5| Step: 4
Training loss: 1.8778722286224365
Validation loss: 1.9674224904788438

Epoch: 5| Step: 5
Training loss: 2.6350035667419434
Validation loss: 1.9525693770377868

Epoch: 5| Step: 6
Training loss: 1.6995985507965088
Validation loss: 1.9459953256832656

Epoch: 5| Step: 7
Training loss: 2.0529441833496094
Validation loss: 1.9282872523030927

Epoch: 5| Step: 8
Training loss: 2.243914842605591
Validation loss: 1.950968655206824

Epoch: 5| Step: 9
Training loss: 1.7626157999038696
Validation loss: 1.9570277506305325

Epoch: 5| Step: 10
Training loss: 1.6746182441711426
Validation loss: 1.9679739923887356

Epoch: 214| Step: 0
Training loss: 2.424943685531616
Validation loss: 1.9353656422707342

Epoch: 5| Step: 1
Training loss: 1.8231956958770752
Validation loss: 1.9311008504641953

Epoch: 5| Step: 2
Training loss: 1.4997351169586182
Validation loss: 1.9348761676460184

Epoch: 5| Step: 3
Training loss: 2.4089438915252686
Validation loss: 1.978320316601825

Epoch: 5| Step: 4
Training loss: 2.063123941421509
Validation loss: 1.9756536432491836

Epoch: 5| Step: 5
Training loss: 1.8119239807128906
Validation loss: 1.9322316056938582

Epoch: 5| Step: 6
Training loss: 1.728020429611206
Validation loss: 1.9654200192420714

Epoch: 5| Step: 7
Training loss: 2.109523057937622
Validation loss: 1.954881860363868

Epoch: 5| Step: 8
Training loss: 1.851792573928833
Validation loss: 1.9664014872684275

Epoch: 5| Step: 9
Training loss: 2.0205516815185547
Validation loss: 1.967802002865781

Epoch: 5| Step: 10
Training loss: 1.8033983707427979
Validation loss: 1.984202109357362

Epoch: 215| Step: 0
Training loss: 2.127657413482666
Validation loss: 1.9556559452446558

Epoch: 5| Step: 1
Training loss: 1.7364485263824463
Validation loss: 1.9694599746375956

Epoch: 5| Step: 2
Training loss: 2.5682482719421387
Validation loss: 1.9511144917498353

Epoch: 5| Step: 3
Training loss: 2.443756103515625
Validation loss: 1.926324054759036

Epoch: 5| Step: 4
Training loss: 1.900377631187439
Validation loss: 1.967657078978836

Epoch: 5| Step: 5
Training loss: 2.2157816886901855
Validation loss: 1.951391702057213

Epoch: 5| Step: 6
Training loss: 1.4732229709625244
Validation loss: 1.9511329973897626

Epoch: 5| Step: 7
Training loss: 1.9802051782608032
Validation loss: 1.9569993134467834

Epoch: 5| Step: 8
Training loss: 2.0724546909332275
Validation loss: 1.9517382857620076

Epoch: 5| Step: 9
Training loss: 1.3841770887374878
Validation loss: 1.963926576798962

Epoch: 5| Step: 10
Training loss: 1.8426473140716553
Validation loss: 1.9665722116347282

Epoch: 216| Step: 0
Training loss: 1.8374955654144287
Validation loss: 1.9571835725538191

Epoch: 5| Step: 1
Training loss: 2.005591630935669
Validation loss: 1.9593621043748752

Epoch: 5| Step: 2
Training loss: 1.9670288562774658
Validation loss: 1.9656622538002588

Epoch: 5| Step: 3
Training loss: 1.4310375452041626
Validation loss: 1.921004105639714

Epoch: 5| Step: 4
Training loss: 2.324301242828369
Validation loss: 1.9470427420831495

Epoch: 5| Step: 5
Training loss: 2.291104793548584
Validation loss: 1.952532773376793

Epoch: 5| Step: 6
Training loss: 1.8416900634765625
Validation loss: 1.9387503926471998

Epoch: 5| Step: 7
Training loss: 2.068563938140869
Validation loss: 1.9562000843786425

Epoch: 5| Step: 8
Training loss: 1.9891340732574463
Validation loss: 1.951816221719147

Epoch: 5| Step: 9
Training loss: 2.031322717666626
Validation loss: 1.9391261159732778

Epoch: 5| Step: 10
Training loss: 1.7858695983886719
Validation loss: 1.9529563534644343

Epoch: 217| Step: 0
Training loss: 2.590580701828003
Validation loss: 1.9566331063547442

Epoch: 5| Step: 1
Training loss: 2.195225954055786
Validation loss: 1.9727727392668366

Epoch: 5| Step: 2
Training loss: 1.939795732498169
Validation loss: 1.9685303113793815

Epoch: 5| Step: 3
Training loss: 1.8766504526138306
Validation loss: 1.9594142103707919

Epoch: 5| Step: 4
Training loss: 2.0338351726531982
Validation loss: 1.990283759691382

Epoch: 5| Step: 5
Training loss: 1.6205803155899048
Validation loss: 1.9471427625225437

Epoch: 5| Step: 6
Training loss: 1.917907953262329
Validation loss: 1.9691835423951507

Epoch: 5| Step: 7
Training loss: 1.6668792963027954
Validation loss: 1.95094088585146

Epoch: 5| Step: 8
Training loss: 2.2666678428649902
Validation loss: 1.972027773498207

Epoch: 5| Step: 9
Training loss: 1.8194900751113892
Validation loss: 1.9564779394416398

Epoch: 5| Step: 10
Training loss: 1.8021764755249023
Validation loss: 1.9609778132489932

Epoch: 218| Step: 0
Training loss: 2.053938388824463
Validation loss: 1.9548416035149687

Epoch: 5| Step: 1
Training loss: 1.4591875076293945
Validation loss: 1.9628388458682644

Epoch: 5| Step: 2
Training loss: 2.8622143268585205
Validation loss: 1.9738018076906922

Epoch: 5| Step: 3
Training loss: 1.3355506658554077
Validation loss: 1.9541043440500896

Epoch: 5| Step: 4
Training loss: 2.273455858230591
Validation loss: 1.9551438054730814

Epoch: 5| Step: 5
Training loss: 2.0447564125061035
Validation loss: 1.9610990965238182

Epoch: 5| Step: 6
Training loss: 2.0681827068328857
Validation loss: 1.9448295857316704

Epoch: 5| Step: 7
Training loss: 1.8186413049697876
Validation loss: 1.94784943262736

Epoch: 5| Step: 8
Training loss: 1.5673097372055054
Validation loss: 1.9547024798649613

Epoch: 5| Step: 9
Training loss: 2.115522623062134
Validation loss: 1.9954517977212065

Epoch: 5| Step: 10
Training loss: 2.0024967193603516
Validation loss: 1.9559980912875103

Epoch: 219| Step: 0
Training loss: 2.258388042449951
Validation loss: 1.9527619269586378

Epoch: 5| Step: 1
Training loss: 2.0129554271698
Validation loss: 1.94024105482204

Epoch: 5| Step: 2
Training loss: 1.8115510940551758
Validation loss: 1.9331481713120655

Epoch: 5| Step: 3
Training loss: 2.1431758403778076
Validation loss: 1.9463374614715576

Epoch: 5| Step: 4
Training loss: 1.5605732202529907
Validation loss: 1.9648146578060683

Epoch: 5| Step: 5
Training loss: 2.308539628982544
Validation loss: 1.9367481431653422

Epoch: 5| Step: 6
Training loss: 2.0976531505584717
Validation loss: 1.9519301793908561

Epoch: 5| Step: 7
Training loss: 1.6160167455673218
Validation loss: 1.9356731753195486

Epoch: 5| Step: 8
Training loss: 1.5066572427749634
Validation loss: 1.9590697955059748

Epoch: 5| Step: 9
Training loss: 2.3471431732177734
Validation loss: 1.9545539604720248

Epoch: 5| Step: 10
Training loss: 1.9039340019226074
Validation loss: 1.9492478575757755

Epoch: 220| Step: 0
Training loss: 1.704403281211853
Validation loss: 1.9414040785963818

Epoch: 5| Step: 1
Training loss: 1.4465396404266357
Validation loss: 1.9197410434804938

Epoch: 5| Step: 2
Training loss: 2.596785068511963
Validation loss: 1.9611672060464018

Epoch: 5| Step: 3
Training loss: 1.9616005420684814
Validation loss: 1.9495341752165107

Epoch: 5| Step: 4
Training loss: 2.3125033378601074
Validation loss: 1.9480037637936172

Epoch: 5| Step: 5
Training loss: 1.8102182149887085
Validation loss: 1.9549184691521428

Epoch: 5| Step: 6
Training loss: 2.087297201156616
Validation loss: 1.9561913782550442

Epoch: 5| Step: 7
Training loss: 1.6826385259628296
Validation loss: 1.9512946092954246

Epoch: 5| Step: 8
Training loss: 2.2762608528137207
Validation loss: 1.9374869036418136

Epoch: 5| Step: 9
Training loss: 1.952863335609436
Validation loss: 1.9397525351534608

Epoch: 5| Step: 10
Training loss: 1.7183459997177124
Validation loss: 1.9571418249478905

Epoch: 221| Step: 0
Training loss: 1.8069298267364502
Validation loss: 1.95280413217442

Epoch: 5| Step: 1
Training loss: 2.2068495750427246
Validation loss: 1.9412810059003933

Epoch: 5| Step: 2
Training loss: 2.1918227672576904
Validation loss: 1.9429602212803339

Epoch: 5| Step: 3
Training loss: 1.8479621410369873
Validation loss: 1.963634475584953

Epoch: 5| Step: 4
Training loss: 1.8632224798202515
Validation loss: 1.9470094019366848

Epoch: 5| Step: 5
Training loss: 0.9898006319999695
Validation loss: 1.9503773502124253

Epoch: 5| Step: 6
Training loss: 1.5486725568771362
Validation loss: 1.966013967349965

Epoch: 5| Step: 7
Training loss: 1.6644830703735352
Validation loss: 1.9582331718937043

Epoch: 5| Step: 8
Training loss: 2.37419056892395
Validation loss: 1.9499445576821604

Epoch: 5| Step: 9
Training loss: 2.747692584991455
Validation loss: 1.9144599130076747

Epoch: 5| Step: 10
Training loss: 2.2139668464660645
Validation loss: 1.9511193818943475

Epoch: 222| Step: 0
Training loss: 2.6853554248809814
Validation loss: 1.9598977706765617

Epoch: 5| Step: 1
Training loss: 1.9113985300064087
Validation loss: 1.9441321447331419

Epoch: 5| Step: 2
Training loss: 1.4538488388061523
Validation loss: 1.930280496997218

Epoch: 5| Step: 3
Training loss: 1.6689866781234741
Validation loss: 1.9418199728893977

Epoch: 5| Step: 4
Training loss: 2.2905008792877197
Validation loss: 1.938436855552017

Epoch: 5| Step: 5
Training loss: 2.1621108055114746
Validation loss: 1.9015258871099001

Epoch: 5| Step: 6
Training loss: 2.1762022972106934
Validation loss: 1.933009906481671

Epoch: 5| Step: 7
Training loss: 1.8412864208221436
Validation loss: 1.9188410492353543

Epoch: 5| Step: 8
Training loss: 1.5945117473602295
Validation loss: 1.9422689227647678

Epoch: 5| Step: 9
Training loss: 1.712749719619751
Validation loss: 1.916374933335089

Epoch: 5| Step: 10
Training loss: 2.088468551635742
Validation loss: 1.9589037767020605

Epoch: 223| Step: 0
Training loss: 1.5101468563079834
Validation loss: 1.939233333833756

Epoch: 5| Step: 1
Training loss: 1.8690071105957031
Validation loss: 1.9512782712136545

Epoch: 5| Step: 2
Training loss: 1.8781006336212158
Validation loss: 1.938412690675387

Epoch: 5| Step: 3
Training loss: 2.160717725753784
Validation loss: 1.9483941524259505

Epoch: 5| Step: 4
Training loss: 1.7257553339004517
Validation loss: 1.9627618764036445

Epoch: 5| Step: 5
Training loss: 1.7682279348373413
Validation loss: 1.9376507677057737

Epoch: 5| Step: 6
Training loss: 2.0324485301971436
Validation loss: 1.966384965886352

Epoch: 5| Step: 7
Training loss: 2.2680153846740723
Validation loss: 1.9370539201203214

Epoch: 5| Step: 8
Training loss: 2.0949206352233887
Validation loss: 1.9423817537164176

Epoch: 5| Step: 9
Training loss: 2.1409802436828613
Validation loss: 1.9754987685911116

Epoch: 5| Step: 10
Training loss: 2.1635162830352783
Validation loss: 1.9591829033308132

Epoch: 224| Step: 0
Training loss: 1.723907470703125
Validation loss: 1.9579960671804284

Epoch: 5| Step: 1
Training loss: 3.043334722518921
Validation loss: 1.974616640357561

Epoch: 5| Step: 2
Training loss: 1.418134093284607
Validation loss: 1.9453649649056055

Epoch: 5| Step: 3
Training loss: 1.6052192449569702
Validation loss: 1.9578213396892752

Epoch: 5| Step: 4
Training loss: 1.7777462005615234
Validation loss: 1.9297728615422403

Epoch: 5| Step: 5
Training loss: 1.6555283069610596
Validation loss: 1.9512602911200574

Epoch: 5| Step: 6
Training loss: 2.066009998321533
Validation loss: 1.932277512806718

Epoch: 5| Step: 7
Training loss: 1.681136131286621
Validation loss: 1.9728902309171614

Epoch: 5| Step: 8
Training loss: 2.3073842525482178
Validation loss: 1.9616531454106814

Epoch: 5| Step: 9
Training loss: 1.7139469385147095
Validation loss: 1.9413749748660671

Epoch: 5| Step: 10
Training loss: 2.385748863220215
Validation loss: 1.9525844307355984

Epoch: 225| Step: 0
Training loss: 2.033846378326416
Validation loss: 1.9531349341074626

Epoch: 5| Step: 1
Training loss: 2.1181752681732178
Validation loss: 1.9351465445692821

Epoch: 5| Step: 2
Training loss: 2.1620802879333496
Validation loss: 1.9399203100512106

Epoch: 5| Step: 3
Training loss: 1.817772626876831
Validation loss: 1.9456346829732258

Epoch: 5| Step: 4
Training loss: 1.8691800832748413
Validation loss: 1.9296692443150345

Epoch: 5| Step: 5
Training loss: 1.478564739227295
Validation loss: 1.9572640003696564

Epoch: 5| Step: 6
Training loss: 2.0058512687683105
Validation loss: 1.9345512390136719

Epoch: 5| Step: 7
Training loss: 1.5278713703155518
Validation loss: 1.9334804473384735

Epoch: 5| Step: 8
Training loss: 1.8337007761001587
Validation loss: 1.9570657130210631

Epoch: 5| Step: 9
Training loss: 2.1167163848876953
Validation loss: 1.914420852097132

Epoch: 5| Step: 10
Training loss: 2.619286060333252
Validation loss: 1.9308736580674366

Epoch: 226| Step: 0
Training loss: 1.3713757991790771
Validation loss: 1.923603448816525

Epoch: 5| Step: 1
Training loss: 2.084900379180908
Validation loss: 1.920337515492593

Epoch: 5| Step: 2
Training loss: 1.7117372751235962
Validation loss: 1.9441848365209435

Epoch: 5| Step: 3
Training loss: 2.2062344551086426
Validation loss: 1.9474245835376043

Epoch: 5| Step: 4
Training loss: 2.480652332305908
Validation loss: 1.930276919436711

Epoch: 5| Step: 5
Training loss: 2.2626073360443115
Validation loss: 1.9361860393196024

Epoch: 5| Step: 6
Training loss: 2.271296262741089
Validation loss: 1.9358481155928744

Epoch: 5| Step: 7
Training loss: 1.8783302307128906
Validation loss: 1.940577624946512

Epoch: 5| Step: 8
Training loss: 1.6194565296173096
Validation loss: 1.9318951560604958

Epoch: 5| Step: 9
Training loss: 2.263840436935425
Validation loss: 1.9471151418583368

Epoch: 5| Step: 10
Training loss: 0.9441318511962891
Validation loss: 1.9318983298476025

Epoch: 227| Step: 0
Training loss: 2.277153491973877
Validation loss: 1.906616351937735

Epoch: 5| Step: 1
Training loss: 1.6183192729949951
Validation loss: 1.9275251665422994

Epoch: 5| Step: 2
Training loss: 2.220820903778076
Validation loss: 1.9272820308644285

Epoch: 5| Step: 3
Training loss: 2.0096523761749268
Validation loss: 1.9421054663196686

Epoch: 5| Step: 4
Training loss: 2.2174148559570312
Validation loss: 1.9282778847602107

Epoch: 5| Step: 5
Training loss: 2.505054473876953
Validation loss: 1.9385494057850172

Epoch: 5| Step: 6
Training loss: 1.8008571863174438
Validation loss: 1.9466771643648866

Epoch: 5| Step: 7
Training loss: 1.687329888343811
Validation loss: 1.9250190129844091

Epoch: 5| Step: 8
Training loss: 1.8158836364746094
Validation loss: 1.9168704299516575

Epoch: 5| Step: 9
Training loss: 1.5214951038360596
Validation loss: 1.9232988306271133

Epoch: 5| Step: 10
Training loss: 1.7084009647369385
Validation loss: 1.9563788342219528

Epoch: 228| Step: 0
Training loss: 1.8332748413085938
Validation loss: 1.9424192700334775

Epoch: 5| Step: 1
Training loss: 1.5506560802459717
Validation loss: 1.9274198137303835

Epoch: 5| Step: 2
Training loss: 1.8481887578964233
Validation loss: 1.9487221599907003

Epoch: 5| Step: 3
Training loss: 1.9572433233261108
Validation loss: 1.932683462737709

Epoch: 5| Step: 4
Training loss: 3.2856926918029785
Validation loss: 1.920952639272136

Epoch: 5| Step: 5
Training loss: 1.8224856853485107
Validation loss: 1.9453568535466348

Epoch: 5| Step: 6
Training loss: 2.470820903778076
Validation loss: 1.9374644551225888

Epoch: 5| Step: 7
Training loss: 1.48171067237854
Validation loss: 1.9418562586589525

Epoch: 5| Step: 8
Training loss: 1.2458140850067139
Validation loss: 1.9183943463910011

Epoch: 5| Step: 9
Training loss: 1.7959940433502197
Validation loss: 1.9240385281142367

Epoch: 5| Step: 10
Training loss: 1.9384770393371582
Validation loss: 1.9169184418134793

Epoch: 229| Step: 0
Training loss: 2.0817012786865234
Validation loss: 1.9326397501012331

Epoch: 5| Step: 1
Training loss: 1.837733507156372
Validation loss: 1.9549004647039598

Epoch: 5| Step: 2
Training loss: 1.3710529804229736
Validation loss: 1.9270031567542785

Epoch: 5| Step: 3
Training loss: 1.553325891494751
Validation loss: 1.9118376162744337

Epoch: 5| Step: 4
Training loss: 2.5607059001922607
Validation loss: 1.9295068248625724

Epoch: 5| Step: 5
Training loss: 1.651800513267517
Validation loss: 1.9340939508971347

Epoch: 5| Step: 6
Training loss: 2.3377833366394043
Validation loss: 1.9283401171366374

Epoch: 5| Step: 7
Training loss: 2.2490427494049072
Validation loss: 1.93586818633541

Epoch: 5| Step: 8
Training loss: 1.740149736404419
Validation loss: 1.9178211894086612

Epoch: 5| Step: 9
Training loss: 2.0567729473114014
Validation loss: 1.947352990027397

Epoch: 5| Step: 10
Training loss: 1.7931013107299805
Validation loss: 1.9474297954190163

Epoch: 230| Step: 0
Training loss: 2.475541591644287
Validation loss: 1.9369308012788014

Epoch: 5| Step: 1
Training loss: 1.7749555110931396
Validation loss: 1.9128865490677536

Epoch: 5| Step: 2
Training loss: 1.8154525756835938
Validation loss: 1.9218328127297022

Epoch: 5| Step: 3
Training loss: 2.0888094902038574
Validation loss: 1.9399013980742423

Epoch: 5| Step: 4
Training loss: 1.3059755563735962
Validation loss: 1.9363408742412445

Epoch: 5| Step: 5
Training loss: 2.6088037490844727
Validation loss: 1.9560705923265027

Epoch: 5| Step: 6
Training loss: 2.137439012527466
Validation loss: 1.9369022846221924

Epoch: 5| Step: 7
Training loss: 1.8940006494522095
Validation loss: 1.9261672509613859

Epoch: 5| Step: 8
Training loss: 1.3663139343261719
Validation loss: 1.9256539011514315

Epoch: 5| Step: 9
Training loss: 2.126112461090088
Validation loss: 1.9229156855613954

Epoch: 5| Step: 10
Training loss: 1.4490973949432373
Validation loss: 1.924521662855661

Epoch: 231| Step: 0
Training loss: 1.6026585102081299
Validation loss: 1.9356186210468251

Epoch: 5| Step: 1
Training loss: 1.7383559942245483
Validation loss: 1.9114474775970622

Epoch: 5| Step: 2
Training loss: 1.6663926839828491
Validation loss: 1.930823585038544

Epoch: 5| Step: 3
Training loss: 1.6627016067504883
Validation loss: 1.9434151072655954

Epoch: 5| Step: 4
Training loss: 1.3006079196929932
Validation loss: 1.9417408691939486

Epoch: 5| Step: 5
Training loss: 2.3324429988861084
Validation loss: 1.9329739078398673

Epoch: 5| Step: 6
Training loss: 2.8656527996063232
Validation loss: 1.9385572697526665

Epoch: 5| Step: 7
Training loss: 2.333859920501709
Validation loss: 1.905246348791225

Epoch: 5| Step: 8
Training loss: 1.819253921508789
Validation loss: 1.949062599930712

Epoch: 5| Step: 9
Training loss: 2.2608542442321777
Validation loss: 1.9145926813925467

Epoch: 5| Step: 10
Training loss: 1.5557729005813599
Validation loss: 1.9435400591101697

Epoch: 232| Step: 0
Training loss: 2.304218292236328
Validation loss: 1.9222712619330293

Epoch: 5| Step: 1
Training loss: 1.8256118297576904
Validation loss: 1.925027253807232

Epoch: 5| Step: 2
Training loss: 1.60041081905365
Validation loss: 1.9101167225068616

Epoch: 5| Step: 3
Training loss: 2.114255666732788
Validation loss: 1.9056585757963118

Epoch: 5| Step: 4
Training loss: 1.9073171615600586
Validation loss: 1.9061508294074767

Epoch: 5| Step: 5
Training loss: 1.3460214138031006
Validation loss: 1.9023629234683128

Epoch: 5| Step: 6
Training loss: 2.6167149543762207
Validation loss: 1.9025217871512137

Epoch: 5| Step: 7
Training loss: 1.8955307006835938
Validation loss: 1.931918119871488

Epoch: 5| Step: 8
Training loss: 1.6237856149673462
Validation loss: 1.9274169168164652

Epoch: 5| Step: 9
Training loss: 1.8821156024932861
Validation loss: 1.9559713794339089

Epoch: 5| Step: 10
Training loss: 2.2236318588256836
Validation loss: 1.9364401525066746

Epoch: 233| Step: 0
Training loss: 2.0309531688690186
Validation loss: 1.934768784430719

Epoch: 5| Step: 1
Training loss: 1.9300596714019775
Validation loss: 1.9596356217579176

Epoch: 5| Step: 2
Training loss: 1.7740287780761719
Validation loss: 1.9524910014162782

Epoch: 5| Step: 3
Training loss: 1.2252086400985718
Validation loss: 1.941570863928846

Epoch: 5| Step: 4
Training loss: 2.2985386848449707
Validation loss: 1.947861227937924

Epoch: 5| Step: 5
Training loss: 1.7608200311660767
Validation loss: 1.958866383439751

Epoch: 5| Step: 6
Training loss: 2.263319492340088
Validation loss: 1.926835593356881

Epoch: 5| Step: 7
Training loss: 2.1340770721435547
Validation loss: 1.9266658598376858

Epoch: 5| Step: 8
Training loss: 2.0617425441741943
Validation loss: 1.94915569725857

Epoch: 5| Step: 9
Training loss: 1.7790100574493408
Validation loss: 1.9263736009597778

Epoch: 5| Step: 10
Training loss: 1.9721384048461914
Validation loss: 1.9169850605790333

Epoch: 234| Step: 0
Training loss: 1.562753438949585
Validation loss: 1.899649473928636

Epoch: 5| Step: 1
Training loss: 1.003206729888916
Validation loss: 1.921345615899691

Epoch: 5| Step: 2
Training loss: 1.386311411857605
Validation loss: 1.9002845953869563

Epoch: 5| Step: 3
Training loss: 2.418548583984375
Validation loss: 1.923586712088636

Epoch: 5| Step: 4
Training loss: 2.0413708686828613
Validation loss: 1.9040036252749863

Epoch: 5| Step: 5
Training loss: 1.7355180978775024
Validation loss: 1.9289517633376583

Epoch: 5| Step: 6
Training loss: 2.2141647338867188
Validation loss: 1.9090235976762668

Epoch: 5| Step: 7
Training loss: 1.9703419208526611
Validation loss: 1.9170873806040774

Epoch: 5| Step: 8
Training loss: 2.3988420963287354
Validation loss: 1.9129488621988604

Epoch: 5| Step: 9
Training loss: 1.788988709449768
Validation loss: 1.919076402982076

Epoch: 5| Step: 10
Training loss: 2.590273380279541
Validation loss: 1.902174977846043

Epoch: 235| Step: 0
Training loss: 1.738135576248169
Validation loss: 1.915225266128458

Epoch: 5| Step: 1
Training loss: 2.299487590789795
Validation loss: 1.9095393316720122

Epoch: 5| Step: 2
Training loss: 1.905334711074829
Validation loss: 1.9010446827898744

Epoch: 5| Step: 3
Training loss: 2.1703062057495117
Validation loss: 1.9187968956526888

Epoch: 5| Step: 4
Training loss: 1.7786566019058228
Validation loss: 1.9340013893701697

Epoch: 5| Step: 5
Training loss: 2.165491819381714
Validation loss: 1.9639673220214022

Epoch: 5| Step: 6
Training loss: 1.8170400857925415
Validation loss: 1.9404058597421134

Epoch: 5| Step: 7
Training loss: 1.5546081066131592
Validation loss: 1.917721603506355

Epoch: 5| Step: 8
Training loss: 1.966239333152771
Validation loss: 1.933765176803835

Epoch: 5| Step: 9
Training loss: 2.0605103969573975
Validation loss: 1.9519722436064033

Epoch: 5| Step: 10
Training loss: 1.6782938241958618
Validation loss: 1.9506951301328597

Epoch: 236| Step: 0
Training loss: 2.3325724601745605
Validation loss: 1.9398242478729577

Epoch: 5| Step: 1
Training loss: 1.5767673254013062
Validation loss: 1.9347363646312425

Epoch: 5| Step: 2
Training loss: 1.2881003618240356
Validation loss: 1.9204553352889193

Epoch: 5| Step: 3
Training loss: 2.6160762310028076
Validation loss: 1.9109276110126125

Epoch: 5| Step: 4
Training loss: 1.4764553308486938
Validation loss: 1.9109374861563406

Epoch: 5| Step: 5
Training loss: 1.534130334854126
Validation loss: 1.9296907481326853

Epoch: 5| Step: 6
Training loss: 2.14853835105896
Validation loss: 1.9115852053447435

Epoch: 5| Step: 7
Training loss: 2.2898268699645996
Validation loss: 1.9308027170037712

Epoch: 5| Step: 8
Training loss: 2.1200013160705566
Validation loss: 1.8976784367715158

Epoch: 5| Step: 9
Training loss: 2.1211495399475098
Validation loss: 1.9232212933160926

Epoch: 5| Step: 10
Training loss: 1.6124497652053833
Validation loss: 1.9267479886290848

Epoch: 237| Step: 0
Training loss: 1.4699348211288452
Validation loss: 1.9163274316377537

Epoch: 5| Step: 1
Training loss: 2.0778677463531494
Validation loss: 1.9221566953966696

Epoch: 5| Step: 2
Training loss: 1.3313229084014893
Validation loss: 1.9297271031205372

Epoch: 5| Step: 3
Training loss: 1.7534679174423218
Validation loss: 1.9174300906478718

Epoch: 5| Step: 4
Training loss: 2.499708652496338
Validation loss: 1.9113482352226012

Epoch: 5| Step: 5
Training loss: 1.7925949096679688
Validation loss: 1.9299124325475385

Epoch: 5| Step: 6
Training loss: 2.2314467430114746
Validation loss: 1.9278165858278993

Epoch: 5| Step: 7
Training loss: 2.049067974090576
Validation loss: 1.933523811319823

Epoch: 5| Step: 8
Training loss: 2.0926880836486816
Validation loss: 1.9179695857468473

Epoch: 5| Step: 9
Training loss: 1.8569339513778687
Validation loss: 1.9208038135241436

Epoch: 5| Step: 10
Training loss: 1.9227399826049805
Validation loss: 1.9062000474622172

Epoch: 238| Step: 0
Training loss: 2.4580230712890625
Validation loss: 1.9141135510577951

Epoch: 5| Step: 1
Training loss: 1.6953824758529663
Validation loss: 1.9376055604668074

Epoch: 5| Step: 2
Training loss: 1.2342267036437988
Validation loss: 1.8968244073211507

Epoch: 5| Step: 3
Training loss: 2.313308000564575
Validation loss: 1.9419995033612816

Epoch: 5| Step: 4
Training loss: 1.8193142414093018
Validation loss: 1.9105794814325148

Epoch: 5| Step: 5
Training loss: 2.394423007965088
Validation loss: 1.9091148978920394

Epoch: 5| Step: 6
Training loss: 1.8541686534881592
Validation loss: 1.92505003816338

Epoch: 5| Step: 7
Training loss: 1.8642829656600952
Validation loss: 1.9196679207586473

Epoch: 5| Step: 8
Training loss: 1.8211724758148193
Validation loss: 1.9268212228692987

Epoch: 5| Step: 9
Training loss: 1.816200613975525
Validation loss: 1.9136876085753083

Epoch: 5| Step: 10
Training loss: 1.6257028579711914
Validation loss: 1.8948610636495775

Epoch: 239| Step: 0
Training loss: 2.071674346923828
Validation loss: 1.923698361201953

Epoch: 5| Step: 1
Training loss: 1.8035030364990234
Validation loss: 1.9378759784083213

Epoch: 5| Step: 2
Training loss: 1.9203979969024658
Validation loss: 1.906043303910122

Epoch: 5| Step: 3
Training loss: 1.5600366592407227
Validation loss: 1.9128773622615363

Epoch: 5| Step: 4
Training loss: 1.9110164642333984
Validation loss: 1.920266415483208

Epoch: 5| Step: 5
Training loss: 2.251521348953247
Validation loss: 1.9400177040407736

Epoch: 5| Step: 6
Training loss: 2.0639913082122803
Validation loss: 1.9083874058979813

Epoch: 5| Step: 7
Training loss: 1.5526609420776367
Validation loss: 1.9386526717934558

Epoch: 5| Step: 8
Training loss: 1.8620052337646484
Validation loss: 1.9360672248307096

Epoch: 5| Step: 9
Training loss: 2.006833553314209
Validation loss: 1.935338835562429

Epoch: 5| Step: 10
Training loss: 1.9099982976913452
Validation loss: 1.9099548965372064

Epoch: 240| Step: 0
Training loss: 2.035335063934326
Validation loss: 1.926513748784219

Epoch: 5| Step: 1
Training loss: 1.5574547052383423
Validation loss: 1.9314139081585793

Epoch: 5| Step: 2
Training loss: 1.8984298706054688
Validation loss: 1.9136626233336747

Epoch: 5| Step: 3
Training loss: 2.1918587684631348
Validation loss: 1.9270247541448122

Epoch: 5| Step: 4
Training loss: 1.5547688007354736
Validation loss: 1.9324708254106584

Epoch: 5| Step: 5
Training loss: 1.7582371234893799
Validation loss: 1.9138070537197975

Epoch: 5| Step: 6
Training loss: 2.119978189468384
Validation loss: 1.9354159344909012

Epoch: 5| Step: 7
Training loss: 1.899206519126892
Validation loss: 1.928756586966976

Epoch: 5| Step: 8
Training loss: 1.5520305633544922
Validation loss: 1.9445648218995781

Epoch: 5| Step: 9
Training loss: 2.254103899002075
Validation loss: 1.922265975706039

Epoch: 5| Step: 10
Training loss: 1.7819852828979492
Validation loss: 1.9308660620002336

Epoch: 241| Step: 0
Training loss: 2.319190502166748
Validation loss: 1.9345633035065026

Epoch: 5| Step: 1
Training loss: 1.8518714904785156
Validation loss: 1.9244094689687092

Epoch: 5| Step: 2
Training loss: 2.1119446754455566
Validation loss: 1.9205997195295108

Epoch: 5| Step: 3
Training loss: 1.602168321609497
Validation loss: 1.909655322310745

Epoch: 5| Step: 4
Training loss: 1.3590290546417236
Validation loss: 1.9406571413881035

Epoch: 5| Step: 5
Training loss: 1.3493773937225342
Validation loss: 1.8989905272760699

Epoch: 5| Step: 6
Training loss: 1.9404090642929077
Validation loss: 1.9355874869131273

Epoch: 5| Step: 7
Training loss: 2.5672106742858887
Validation loss: 1.8852872220418786

Epoch: 5| Step: 8
Training loss: 1.6736781597137451
Validation loss: 1.9048923254013062

Epoch: 5| Step: 9
Training loss: 2.48726487159729
Validation loss: 1.897508159760506

Epoch: 5| Step: 10
Training loss: 1.5769118070602417
Validation loss: 1.8806735930904266

Epoch: 242| Step: 0
Training loss: 1.7447580099105835
Validation loss: 1.9098654690609183

Epoch: 5| Step: 1
Training loss: 1.8324205875396729
Validation loss: 1.8911627300323979

Epoch: 5| Step: 2
Training loss: 1.925138235092163
Validation loss: 1.9073061520053494

Epoch: 5| Step: 3
Training loss: 2.0604500770568848
Validation loss: 1.9021389176768642

Epoch: 5| Step: 4
Training loss: 2.0744900703430176
Validation loss: 1.9088987329954743

Epoch: 5| Step: 5
Training loss: 2.1765685081481934
Validation loss: 1.9126211955983152

Epoch: 5| Step: 6
Training loss: 1.219364047050476
Validation loss: 1.9266275718647947

Epoch: 5| Step: 7
Training loss: 1.9157682657241821
Validation loss: 1.9277419274853123

Epoch: 5| Step: 8
Training loss: 1.5295696258544922
Validation loss: 1.9244716090540732

Epoch: 5| Step: 9
Training loss: 2.028940200805664
Validation loss: 1.8984590115085724

Epoch: 5| Step: 10
Training loss: 2.5462698936462402
Validation loss: 1.9179690230277278

Epoch: 243| Step: 0
Training loss: 1.6872714757919312
Validation loss: 1.9411606455361972

Epoch: 5| Step: 1
Training loss: 2.4227752685546875
Validation loss: 1.9081842566049227

Epoch: 5| Step: 2
Training loss: 1.3312666416168213
Validation loss: 1.9126067648651779

Epoch: 5| Step: 3
Training loss: 1.944042444229126
Validation loss: 1.9140831770435456

Epoch: 5| Step: 4
Training loss: 1.8949683904647827
Validation loss: 1.9111147208880352

Epoch: 5| Step: 5
Training loss: 2.285482406616211
Validation loss: 1.93098069519125

Epoch: 5| Step: 6
Training loss: 1.931281328201294
Validation loss: 1.894887924194336

Epoch: 5| Step: 7
Training loss: 1.7749544382095337
Validation loss: 1.9047915602243075

Epoch: 5| Step: 8
Training loss: 1.3378074169158936
Validation loss: 1.9380152661313292

Epoch: 5| Step: 9
Training loss: 2.026837110519409
Validation loss: 1.8820123159757225

Epoch: 5| Step: 10
Training loss: 2.146646022796631
Validation loss: 1.8994586493379326

Epoch: 244| Step: 0
Training loss: 1.8959766626358032
Validation loss: 1.912011274727442

Epoch: 5| Step: 1
Training loss: 1.8649928569793701
Validation loss: 1.8862107530716927

Epoch: 5| Step: 2
Training loss: 1.9317302703857422
Validation loss: 1.9108088375419698

Epoch: 5| Step: 3
Training loss: 1.742371916770935
Validation loss: 1.9142604438207482

Epoch: 5| Step: 4
Training loss: 1.7716211080551147
Validation loss: 1.8855666319529216

Epoch: 5| Step: 5
Training loss: 1.8675224781036377
Validation loss: 1.8996409523871638

Epoch: 5| Step: 6
Training loss: 2.1947786808013916
Validation loss: 1.8901267718243342

Epoch: 5| Step: 7
Training loss: 1.5698784589767456
Validation loss: 1.8817661782746673

Epoch: 5| Step: 8
Training loss: 2.106558322906494
Validation loss: 1.883965922940162

Epoch: 5| Step: 9
Training loss: 2.246687650680542
Validation loss: 1.9224965264720302

Epoch: 5| Step: 10
Training loss: 1.7952215671539307
Validation loss: 1.8897642384293258

Epoch: 245| Step: 0
Training loss: 2.404268264770508
Validation loss: 1.892902389649422

Epoch: 5| Step: 1
Training loss: 2.108243227005005
Validation loss: 1.8857265672376078

Epoch: 5| Step: 2
Training loss: 1.126490592956543
Validation loss: 1.9310657337147703

Epoch: 5| Step: 3
Training loss: 2.0184824466705322
Validation loss: 1.9287019878305414

Epoch: 5| Step: 4
Training loss: 2.5819649696350098
Validation loss: 1.9137654483959239

Epoch: 5| Step: 5
Training loss: 1.4062252044677734
Validation loss: 1.9282095316917665

Epoch: 5| Step: 6
Training loss: 1.7155215740203857
Validation loss: 1.9235660311996297

Epoch: 5| Step: 7
Training loss: 1.721631407737732
Validation loss: 1.9395172608795987

Epoch: 5| Step: 8
Training loss: 1.5762975215911865
Validation loss: 1.9555641605008034

Epoch: 5| Step: 9
Training loss: 1.8121668100357056
Validation loss: 1.9344688743673346

Epoch: 5| Step: 10
Training loss: 2.1384644508361816
Validation loss: 1.9230866175825878

Epoch: 246| Step: 0
Training loss: 1.9308820962905884
Validation loss: 1.9511284764095018

Epoch: 5| Step: 1
Training loss: 2.0045838356018066
Validation loss: 1.9524718164115824

Epoch: 5| Step: 2
Training loss: 1.7827234268188477
Validation loss: 1.9521971825630433

Epoch: 5| Step: 3
Training loss: 1.7575256824493408
Validation loss: 1.9186087475028089

Epoch: 5| Step: 4
Training loss: 1.6589524745941162
Validation loss: 1.9096365026248399

Epoch: 5| Step: 5
Training loss: 1.2275673151016235
Validation loss: 1.921789889694542

Epoch: 5| Step: 6
Training loss: 2.254772901535034
Validation loss: 1.9323105222435408

Epoch: 5| Step: 7
Training loss: 2.265808582305908
Validation loss: 1.886999939077644

Epoch: 5| Step: 8
Training loss: 1.9365625381469727
Validation loss: 1.9044434549987956

Epoch: 5| Step: 9
Training loss: 1.698840856552124
Validation loss: 1.9132846273401731

Epoch: 5| Step: 10
Training loss: 2.206850290298462
Validation loss: 1.9076920170937814

Epoch: 247| Step: 0
Training loss: 2.2248082160949707
Validation loss: 1.9104054025424424

Epoch: 5| Step: 1
Training loss: 1.7318881750106812
Validation loss: 1.904769338587279

Epoch: 5| Step: 2
Training loss: 2.0757813453674316
Validation loss: 1.9172613056757117

Epoch: 5| Step: 3
Training loss: 2.046027421951294
Validation loss: 1.8871307783229376

Epoch: 5| Step: 4
Training loss: 1.9153730869293213
Validation loss: 1.9336273183104813

Epoch: 5| Step: 5
Training loss: 1.6107810735702515
Validation loss: 1.8907657579709125

Epoch: 5| Step: 6
Training loss: 2.5922293663024902
Validation loss: 1.8957685629526775

Epoch: 5| Step: 7
Training loss: 1.585556149482727
Validation loss: 1.8944186010668356

Epoch: 5| Step: 8
Training loss: 1.5491597652435303
Validation loss: 1.9139240903239096

Epoch: 5| Step: 9
Training loss: 1.8551533222198486
Validation loss: 1.9114546980909122

Epoch: 5| Step: 10
Training loss: 1.4185004234313965
Validation loss: 1.883272026174812

Epoch: 248| Step: 0
Training loss: 1.6680530309677124
Validation loss: 1.9001791913022277

Epoch: 5| Step: 1
Training loss: 1.7024548053741455
Validation loss: 1.9033266164923226

Epoch: 5| Step: 2
Training loss: 2.431429386138916
Validation loss: 1.9002612995845016

Epoch: 5| Step: 3
Training loss: 1.90670907497406
Validation loss: 1.9072431492549118

Epoch: 5| Step: 4
Training loss: 2.054363965988159
Validation loss: 1.9030577059715026

Epoch: 5| Step: 5
Training loss: 1.080560326576233
Validation loss: 1.9141620384749545

Epoch: 5| Step: 6
Training loss: 1.1878927946090698
Validation loss: 1.9072082991241126

Epoch: 5| Step: 7
Training loss: 1.980004906654358
Validation loss: 1.9415010995762323

Epoch: 5| Step: 8
Training loss: 2.2652790546417236
Validation loss: 1.8960116601759387

Epoch: 5| Step: 9
Training loss: 2.0329673290252686
Validation loss: 1.9104611463444208

Epoch: 5| Step: 10
Training loss: 2.1893770694732666
Validation loss: 1.904539931205011

Epoch: 249| Step: 0
Training loss: 1.9627869129180908
Validation loss: 1.93188593592695

Epoch: 5| Step: 1
Training loss: 2.0569863319396973
Validation loss: 1.8924840983524118

Epoch: 5| Step: 2
Training loss: 1.4118731021881104
Validation loss: 1.9141494176721061

Epoch: 5| Step: 3
Training loss: 1.8605902194976807
Validation loss: 1.9002988979380617

Epoch: 5| Step: 4
Training loss: 1.540537714958191
Validation loss: 1.9060687839343984

Epoch: 5| Step: 5
Training loss: 2.0951151847839355
Validation loss: 1.8857112597393733

Epoch: 5| Step: 6
Training loss: 1.6090574264526367
Validation loss: 1.888444044256723

Epoch: 5| Step: 7
Training loss: 1.9110521078109741
Validation loss: 1.9341466837031867

Epoch: 5| Step: 8
Training loss: 2.6378328800201416
Validation loss: 1.9041110315630514

Epoch: 5| Step: 9
Training loss: 1.7683089971542358
Validation loss: 1.916096301488979

Epoch: 5| Step: 10
Training loss: 1.7062108516693115
Validation loss: 1.8961096591846918

Epoch: 250| Step: 0
Training loss: 1.9275420904159546
Validation loss: 1.9018770597314323

Epoch: 5| Step: 1
Training loss: 1.567352533340454
Validation loss: 1.8780778044013566

Epoch: 5| Step: 2
Training loss: 1.65007746219635
Validation loss: 1.8722127611919115

Epoch: 5| Step: 3
Training loss: 1.9877475500106812
Validation loss: 1.9042496181303454

Epoch: 5| Step: 4
Training loss: 2.250673770904541
Validation loss: 1.9153725242102018

Epoch: 5| Step: 5
Training loss: 2.1976065635681152
Validation loss: 1.9159998201554822

Epoch: 5| Step: 6
Training loss: 1.9331308603286743
Validation loss: 1.9016024322919949

Epoch: 5| Step: 7
Training loss: 2.000009775161743
Validation loss: 1.9047697436424993

Epoch: 5| Step: 8
Training loss: 1.3733476400375366
Validation loss: 1.9213571753553165

Epoch: 5| Step: 9
Training loss: 1.8255243301391602
Validation loss: 1.9037012207892634

Epoch: 5| Step: 10
Training loss: 1.8492236137390137
Validation loss: 1.9212211921650877

Epoch: 251| Step: 0
Training loss: 1.8613269329071045
Validation loss: 1.926548961670168

Epoch: 5| Step: 1
Training loss: 1.8249397277832031
Validation loss: 1.8699442302027056

Epoch: 5| Step: 2
Training loss: 2.1699206829071045
Validation loss: 1.9149791361183248

Epoch: 5| Step: 3
Training loss: 1.2177070379257202
Validation loss: 1.8981937413574548

Epoch: 5| Step: 4
Training loss: 1.7996046543121338
Validation loss: 1.9019928093879455

Epoch: 5| Step: 5
Training loss: 2.0307281017303467
Validation loss: 1.9065364945319392

Epoch: 5| Step: 6
Training loss: 1.9150310754776
Validation loss: 1.8992867495424004

Epoch: 5| Step: 7
Training loss: 2.0644383430480957
Validation loss: 1.8890305680613364

Epoch: 5| Step: 8
Training loss: 2.1865944862365723
Validation loss: 1.891345352254888

Epoch: 5| Step: 9
Training loss: 1.7971853017807007
Validation loss: 1.880306011887007

Epoch: 5| Step: 10
Training loss: 1.6598223447799683
Validation loss: 1.9068900282664965

Epoch: 252| Step: 0
Training loss: 1.9612758159637451
Validation loss: 1.9008104711450555

Epoch: 5| Step: 1
Training loss: 1.4959094524383545
Validation loss: 1.889087998738853

Epoch: 5| Step: 2
Training loss: 1.9554697275161743
Validation loss: 1.89887587998503

Epoch: 5| Step: 3
Training loss: 1.6909706592559814
Validation loss: 1.9043354360006188

Epoch: 5| Step: 4
Training loss: 1.7156566381454468
Validation loss: 1.9173258414832495

Epoch: 5| Step: 5
Training loss: 2.124554395675659
Validation loss: 1.9227159484740226

Epoch: 5| Step: 6
Training loss: 1.7552486658096313
Validation loss: 1.8846695089852938

Epoch: 5| Step: 7
Training loss: 2.4540321826934814
Validation loss: 1.9058914722934845

Epoch: 5| Step: 8
Training loss: 1.927350640296936
Validation loss: 1.9167112432500368

Epoch: 5| Step: 9
Training loss: 1.6355279684066772
Validation loss: 1.8867149968301096

Epoch: 5| Step: 10
Training loss: 2.026987075805664
Validation loss: 1.9024722806869014

Epoch: 253| Step: 0
Training loss: 1.8947227001190186
Validation loss: 1.8917015034665343

Epoch: 5| Step: 1
Training loss: 2.2349658012390137
Validation loss: 1.9171771028990388

Epoch: 5| Step: 2
Training loss: 1.7545198202133179
Validation loss: 1.9110871002238283

Epoch: 5| Step: 3
Training loss: 1.6243444681167603
Validation loss: 1.889936540716438

Epoch: 5| Step: 4
Training loss: 1.5955581665039062
Validation loss: 1.9201915315402451

Epoch: 5| Step: 5
Training loss: 1.411708116531372
Validation loss: 1.8923237349397393

Epoch: 5| Step: 6
Training loss: 1.6135025024414062
Validation loss: 1.9181861826168594

Epoch: 5| Step: 7
Training loss: 1.8035863637924194
Validation loss: 1.8853458794214393

Epoch: 5| Step: 8
Training loss: 2.1429762840270996
Validation loss: 1.9140816427046252

Epoch: 5| Step: 9
Training loss: 2.3302032947540283
Validation loss: 1.8993257066254974

Epoch: 5| Step: 10
Training loss: 2.170978307723999
Validation loss: 1.9130641888546687

Epoch: 254| Step: 0
Training loss: 1.4585219621658325
Validation loss: 1.9168839352105254

Epoch: 5| Step: 1
Training loss: 2.4696052074432373
Validation loss: 1.929704373882663

Epoch: 5| Step: 2
Training loss: 2.131842613220215
Validation loss: 1.9066922741551553

Epoch: 5| Step: 3
Training loss: 1.7585541009902954
Validation loss: 1.913956739569223

Epoch: 5| Step: 4
Training loss: 1.1297471523284912
Validation loss: 1.913869910342719

Epoch: 5| Step: 5
Training loss: 1.823860764503479
Validation loss: 1.9304838231814805

Epoch: 5| Step: 6
Training loss: 2.2076234817504883
Validation loss: 1.9185753535198908

Epoch: 5| Step: 7
Training loss: 1.6221774816513062
Validation loss: 1.8876788975090109

Epoch: 5| Step: 8
Training loss: 2.0171563625335693
Validation loss: 1.8882628051183556

Epoch: 5| Step: 9
Training loss: 2.1269235610961914
Validation loss: 1.9183844327926636

Epoch: 5| Step: 10
Training loss: 1.8055630922317505
Validation loss: 1.889784751399871

Epoch: 255| Step: 0
Training loss: 2.201076030731201
Validation loss: 1.916442527565905

Epoch: 5| Step: 1
Training loss: 1.7377287149429321
Validation loss: 1.8861798753020584

Epoch: 5| Step: 2
Training loss: 2.1880245208740234
Validation loss: 1.9375337926290368

Epoch: 5| Step: 3
Training loss: 2.008450984954834
Validation loss: 1.8946533228761406

Epoch: 5| Step: 4
Training loss: 2.269509792327881
Validation loss: 1.913266275518684

Epoch: 5| Step: 5
Training loss: 1.3027760982513428
Validation loss: 1.890248308899582

Epoch: 5| Step: 6
Training loss: 2.1026406288146973
Validation loss: 1.9319954610640002

Epoch: 5| Step: 7
Training loss: 1.2273519039154053
Validation loss: 1.9263098060443837

Epoch: 5| Step: 8
Training loss: 1.4204204082489014
Validation loss: 1.9013359931207472

Epoch: 5| Step: 9
Training loss: 1.7647819519042969
Validation loss: 1.8910186957287531

Epoch: 5| Step: 10
Training loss: 2.291043758392334
Validation loss: 1.8808064576118224

Epoch: 256| Step: 0
Training loss: 1.6342270374298096
Validation loss: 1.8952388532700077

Epoch: 5| Step: 1
Training loss: 1.597242832183838
Validation loss: 1.9219695714212233

Epoch: 5| Step: 2
Training loss: 1.714827299118042
Validation loss: 1.899003210888114

Epoch: 5| Step: 3
Training loss: 1.6066023111343384
Validation loss: 1.8903059215955837

Epoch: 5| Step: 4
Training loss: 1.584398865699768
Validation loss: 1.8785817725684053

Epoch: 5| Step: 5
Training loss: 1.6146084070205688
Validation loss: 1.8917392697385562

Epoch: 5| Step: 6
Training loss: 2.4005627632141113
Validation loss: 1.8809379095672278

Epoch: 5| Step: 7
Training loss: 1.8958232402801514
Validation loss: 1.8669561532235914

Epoch: 5| Step: 8
Training loss: 1.7301158905029297
Validation loss: 1.9006008909594627

Epoch: 5| Step: 9
Training loss: 2.1800553798675537
Validation loss: 1.9031216380416707

Epoch: 5| Step: 10
Training loss: 2.4885966777801514
Validation loss: 1.8702438877474876

Epoch: 257| Step: 0
Training loss: 1.9638240337371826
Validation loss: 1.9178939378389748

Epoch: 5| Step: 1
Training loss: 1.3393495082855225
Validation loss: 1.8946738743012952

Epoch: 5| Step: 2
Training loss: 1.472046971321106
Validation loss: 1.891336259021554

Epoch: 5| Step: 3
Training loss: 1.7993366718292236
Validation loss: 1.9133441076483777

Epoch: 5| Step: 4
Training loss: 1.9509029388427734
Validation loss: 1.9015909741001744

Epoch: 5| Step: 5
Training loss: 2.1053547859191895
Validation loss: 1.9082059783320273

Epoch: 5| Step: 6
Training loss: 1.9560505151748657
Validation loss: 1.9195457991733347

Epoch: 5| Step: 7
Training loss: 2.0918731689453125
Validation loss: 1.9521407978509062

Epoch: 5| Step: 8
Training loss: 1.9777511358261108
Validation loss: 1.907786774378951

Epoch: 5| Step: 9
Training loss: 2.04542875289917
Validation loss: 1.916849144043461

Epoch: 5| Step: 10
Training loss: 1.4776850938796997
Validation loss: 1.926768010662448

Epoch: 258| Step: 0
Training loss: 1.639661431312561
Validation loss: 1.9056094308053293

Epoch: 5| Step: 1
Training loss: 1.5427625179290771
Validation loss: 1.8912604278133762

Epoch: 5| Step: 2
Training loss: 2.0082924365997314
Validation loss: 1.9129638056601248

Epoch: 5| Step: 3
Training loss: 2.123291492462158
Validation loss: 1.907390329145616

Epoch: 5| Step: 4
Training loss: 1.5426852703094482
Validation loss: 1.9069466308880878

Epoch: 5| Step: 5
Training loss: 1.9526739120483398
Validation loss: 1.8646249181480818

Epoch: 5| Step: 6
Training loss: 1.0837254524230957
Validation loss: 1.8751990384952997

Epoch: 5| Step: 7
Training loss: 1.936189889907837
Validation loss: 1.8739171348592287

Epoch: 5| Step: 8
Training loss: 1.9992157220840454
Validation loss: 1.8788169019965715

Epoch: 5| Step: 9
Training loss: 2.4608154296875
Validation loss: 1.867033875116738

Epoch: 5| Step: 10
Training loss: 2.0571279525756836
Validation loss: 1.8822964352946128

Epoch: 259| Step: 0
Training loss: 1.8314993381500244
Validation loss: 1.8810282804632699

Epoch: 5| Step: 1
Training loss: 2.1202526092529297
Validation loss: 1.9065268860068372

Epoch: 5| Step: 2
Training loss: 1.4550853967666626
Validation loss: 1.8579931130973242

Epoch: 5| Step: 3
Training loss: 1.1799395084381104
Validation loss: 1.8618972019482685

Epoch: 5| Step: 4
Training loss: 1.5122771263122559
Validation loss: 1.8881150368721253

Epoch: 5| Step: 5
Training loss: 1.688828706741333
Validation loss: 1.8844409219680294

Epoch: 5| Step: 6
Training loss: 1.5055662393569946
Validation loss: 1.8954749491906935

Epoch: 5| Step: 7
Training loss: 2.0491511821746826
Validation loss: 1.9090702328630673

Epoch: 5| Step: 8
Training loss: 2.396601676940918
Validation loss: 1.8910524691304853

Epoch: 5| Step: 9
Training loss: 2.0885872840881348
Validation loss: 1.8716498895358014

Epoch: 5| Step: 10
Training loss: 2.6081981658935547
Validation loss: 1.881339059722039

Epoch: 260| Step: 0
Training loss: 1.4079464673995972
Validation loss: 1.8801268146884056

Epoch: 5| Step: 1
Training loss: 1.700404405593872
Validation loss: 1.880057942482733

Epoch: 5| Step: 2
Training loss: 2.293715715408325
Validation loss: 1.8955758579315678

Epoch: 5| Step: 3
Training loss: 1.9701534509658813
Validation loss: 1.9088866403025966

Epoch: 5| Step: 4
Training loss: 2.5698180198669434
Validation loss: 1.8663859098188338

Epoch: 5| Step: 5
Training loss: 1.3986371755599976
Validation loss: 1.8938438264272546

Epoch: 5| Step: 6
Training loss: 1.7814080715179443
Validation loss: 1.8946489518688572

Epoch: 5| Step: 7
Training loss: 2.3958895206451416
Validation loss: 1.901398907425583

Epoch: 5| Step: 8
Training loss: 1.459828495979309
Validation loss: 1.904793885446364

Epoch: 5| Step: 9
Training loss: 1.4972710609436035
Validation loss: 1.8959991098732076

Epoch: 5| Step: 10
Training loss: 1.691545844078064
Validation loss: 1.8986725781553535

Epoch: 261| Step: 0
Training loss: 2.053544521331787
Validation loss: 1.8842885314777333

Epoch: 5| Step: 1
Training loss: 2.036691427230835
Validation loss: 1.8710772683543544

Epoch: 5| Step: 2
Training loss: 1.1221431493759155
Validation loss: 1.9177459850106189

Epoch: 5| Step: 3
Training loss: 1.8252484798431396
Validation loss: 1.905273163190452

Epoch: 5| Step: 4
Training loss: 1.872123122215271
Validation loss: 1.8642922011754846

Epoch: 5| Step: 5
Training loss: 1.945924162864685
Validation loss: 1.9095872063790598

Epoch: 5| Step: 6
Training loss: 1.2357816696166992
Validation loss: 1.914036690547902

Epoch: 5| Step: 7
Training loss: 1.2369941473007202
Validation loss: 1.8999881667475547

Epoch: 5| Step: 8
Training loss: 2.5788216590881348
Validation loss: 1.9042581870991697

Epoch: 5| Step: 9
Training loss: 2.2078282833099365
Validation loss: 1.9139084995433848

Epoch: 5| Step: 10
Training loss: 2.090329885482788
Validation loss: 1.885374653723932

Epoch: 262| Step: 0
Training loss: 1.3111748695373535
Validation loss: 1.9101119707989436

Epoch: 5| Step: 1
Training loss: 1.7171123027801514
Validation loss: 1.868043025334676

Epoch: 5| Step: 2
Training loss: 1.8584682941436768
Validation loss: 1.8756192909773959

Epoch: 5| Step: 3
Training loss: 2.1693432331085205
Validation loss: 1.900445907346664

Epoch: 5| Step: 4
Training loss: 2.344851016998291
Validation loss: 1.8968565399928758

Epoch: 5| Step: 5
Training loss: 2.090395927429199
Validation loss: 1.9109986700037473

Epoch: 5| Step: 6
Training loss: 1.5567165613174438
Validation loss: 1.8799927619195753

Epoch: 5| Step: 7
Training loss: 2.0084691047668457
Validation loss: 1.9125825410248132

Epoch: 5| Step: 8
Training loss: 1.7942426204681396
Validation loss: 1.885618858439948

Epoch: 5| Step: 9
Training loss: 1.5078599452972412
Validation loss: 1.9200637058545185

Epoch: 5| Step: 10
Training loss: 1.8481130599975586
Validation loss: 1.9092524359303136

Epoch: 263| Step: 0
Training loss: 1.3710575103759766
Validation loss: 1.8918647509749218

Epoch: 5| Step: 1
Training loss: 1.9439570903778076
Validation loss: 1.8852545856147684

Epoch: 5| Step: 2
Training loss: 2.2879626750946045
Validation loss: 1.8907097026865969

Epoch: 5| Step: 3
Training loss: 1.4073041677474976
Validation loss: 1.894646438219214

Epoch: 5| Step: 4
Training loss: 1.5771691799163818
Validation loss: 1.8954449917680474

Epoch: 5| Step: 5
Training loss: 2.47236704826355
Validation loss: 1.904279496080132

Epoch: 5| Step: 6
Training loss: 1.659123182296753
Validation loss: 1.8944093924696728

Epoch: 5| Step: 7
Training loss: 2.0478615760803223
Validation loss: 1.8856021973394579

Epoch: 5| Step: 8
Training loss: 2.2309176921844482
Validation loss: 1.84625163385945

Epoch: 5| Step: 9
Training loss: 1.6237146854400635
Validation loss: 1.877785926224083

Epoch: 5| Step: 10
Training loss: 1.4953958988189697
Validation loss: 1.8758795889475013

Epoch: 264| Step: 0
Training loss: 1.3570985794067383
Validation loss: 1.889373828006047

Epoch: 5| Step: 1
Training loss: 1.942342758178711
Validation loss: 1.8989657407165856

Epoch: 5| Step: 2
Training loss: 1.6089494228363037
Validation loss: 1.9008421128795994

Epoch: 5| Step: 3
Training loss: 1.4771476984024048
Validation loss: 1.8731264157961773

Epoch: 5| Step: 4
Training loss: 2.2723209857940674
Validation loss: 1.8794749757295013

Epoch: 5| Step: 5
Training loss: 1.7193816900253296
Validation loss: 1.8605365906992266

Epoch: 5| Step: 6
Training loss: 2.019446849822998
Validation loss: 1.880322539678184

Epoch: 5| Step: 7
Training loss: 1.7495555877685547
Validation loss: 1.8539497442142938

Epoch: 5| Step: 8
Training loss: 1.2908904552459717
Validation loss: 1.899501380100045

Epoch: 5| Step: 9
Training loss: 1.960423469543457
Validation loss: 1.887220457036008

Epoch: 5| Step: 10
Training loss: 2.8218464851379395
Validation loss: 1.8758260819219774

Epoch: 265| Step: 0
Training loss: 1.6687605381011963
Validation loss: 1.8895981914253646

Epoch: 5| Step: 1
Training loss: 1.6597411632537842
Validation loss: 1.9015061227224206

Epoch: 5| Step: 2
Training loss: 1.5231130123138428
Validation loss: 1.8734761361152894

Epoch: 5| Step: 3
Training loss: 1.6996183395385742
Validation loss: 1.895560150505394

Epoch: 5| Step: 4
Training loss: 2.030038356781006
Validation loss: 1.90983118677652

Epoch: 5| Step: 5
Training loss: 1.7391865253448486
Validation loss: 1.9468688234206168

Epoch: 5| Step: 6
Training loss: 2.0899038314819336
Validation loss: 1.908384930702948

Epoch: 5| Step: 7
Training loss: 2.0977141857147217
Validation loss: 1.934007260107225

Epoch: 5| Step: 8
Training loss: 1.711787462234497
Validation loss: 1.924716672589702

Epoch: 5| Step: 9
Training loss: 1.830099105834961
Validation loss: 1.8929967457248318

Epoch: 5| Step: 10
Training loss: 2.10345721244812
Validation loss: 1.8602137334885136

Epoch: 266| Step: 0
Training loss: 1.4657682180404663
Validation loss: 1.9199741578871203

Epoch: 5| Step: 1
Training loss: 1.8279221057891846
Validation loss: 1.8963738167157738

Epoch: 5| Step: 2
Training loss: 1.416290283203125
Validation loss: 1.876437787086733

Epoch: 5| Step: 3
Training loss: 1.5285133123397827
Validation loss: 1.897724384902626

Epoch: 5| Step: 4
Training loss: 2.0411019325256348
Validation loss: 1.890826004807667

Epoch: 5| Step: 5
Training loss: 1.437864065170288
Validation loss: 1.8785822250509774

Epoch: 5| Step: 6
Training loss: 1.6046158075332642
Validation loss: 1.8712086844187912

Epoch: 5| Step: 7
Training loss: 1.9839515686035156
Validation loss: 1.8558323755059192

Epoch: 5| Step: 8
Training loss: 2.3785619735717773
Validation loss: 1.8939654929663545

Epoch: 5| Step: 9
Training loss: 2.3268539905548096
Validation loss: 1.8577079721676406

Epoch: 5| Step: 10
Training loss: 1.842617392539978
Validation loss: 1.863730658767044

Epoch: 267| Step: 0
Training loss: 1.3800960779190063
Validation loss: 1.8632488814733361

Epoch: 5| Step: 1
Training loss: 1.9062656164169312
Validation loss: 1.878719546461618

Epoch: 5| Step: 2
Training loss: 1.7131048440933228
Validation loss: 1.8881798354528283

Epoch: 5| Step: 3
Training loss: 1.4964611530303955
Validation loss: 1.8950597316988054

Epoch: 5| Step: 4
Training loss: 1.550135850906372
Validation loss: 1.8963710390111452

Epoch: 5| Step: 5
Training loss: 1.605159044265747
Validation loss: 1.8948571515339676

Epoch: 5| Step: 6
Training loss: 1.6578248739242554
Validation loss: 1.8792550897085538

Epoch: 5| Step: 7
Training loss: 2.2824277877807617
Validation loss: 1.8822189556655062

Epoch: 5| Step: 8
Training loss: 2.3286147117614746
Validation loss: 1.8663520812988281

Epoch: 5| Step: 9
Training loss: 1.9778486490249634
Validation loss: 1.917378394834457

Epoch: 5| Step: 10
Training loss: 2.026257276535034
Validation loss: 1.907094431179826

Epoch: 268| Step: 0
Training loss: 1.6076393127441406
Validation loss: 1.8858240958183043

Epoch: 5| Step: 1
Training loss: 1.9613456726074219
Validation loss: 1.9036113703122703

Epoch: 5| Step: 2
Training loss: 2.1114449501037598
Validation loss: 1.8707443437268656

Epoch: 5| Step: 3
Training loss: 1.406872034072876
Validation loss: 1.898975165941382

Epoch: 5| Step: 4
Training loss: 2.0737643241882324
Validation loss: 1.8696750902360486

Epoch: 5| Step: 5
Training loss: 1.5394834280014038
Validation loss: 1.9029657430546258

Epoch: 5| Step: 6
Training loss: 1.8469696044921875
Validation loss: 1.8489602291455833

Epoch: 5| Step: 7
Training loss: 1.9648361206054688
Validation loss: 1.876000286430441

Epoch: 5| Step: 8
Training loss: 1.5278081893920898
Validation loss: 1.8812089735461819

Epoch: 5| Step: 9
Training loss: 2.1119723320007324
Validation loss: 1.8915813661390735

Epoch: 5| Step: 10
Training loss: 1.987255334854126
Validation loss: 1.8891506412977814

Epoch: 269| Step: 0
Training loss: 1.6635850667953491
Validation loss: 1.8937875698971491

Epoch: 5| Step: 1
Training loss: 1.8945589065551758
Validation loss: 1.8944463063311834

Epoch: 5| Step: 2
Training loss: 2.0987658500671387
Validation loss: 1.8829968308889737

Epoch: 5| Step: 3
Training loss: 1.9336131811141968
Validation loss: 1.883277876402742

Epoch: 5| Step: 4
Training loss: 1.4211652278900146
Validation loss: 1.8824782256157166

Epoch: 5| Step: 5
Training loss: 2.227231502532959
Validation loss: 1.9042219884933964

Epoch: 5| Step: 6
Training loss: 1.304396390914917
Validation loss: 1.877988310270412

Epoch: 5| Step: 7
Training loss: 1.949608564376831
Validation loss: 1.9205747471060803

Epoch: 5| Step: 8
Training loss: 2.157285213470459
Validation loss: 1.8767961430293258

Epoch: 5| Step: 9
Training loss: 2.1755194664001465
Validation loss: 1.9091663527232345

Epoch: 5| Step: 10
Training loss: 1.1966577768325806
Validation loss: 1.900902630180441

Epoch: 270| Step: 0
Training loss: 1.610858678817749
Validation loss: 1.936017317156638

Epoch: 5| Step: 1
Training loss: 1.7066357135772705
Validation loss: 1.890894425812588

Epoch: 5| Step: 2
Training loss: 1.735791563987732
Validation loss: 1.8702964141804685

Epoch: 5| Step: 3
Training loss: 1.864295244216919
Validation loss: 1.8794090927288096

Epoch: 5| Step: 4
Training loss: 1.5871732234954834
Validation loss: 1.8712525611282678

Epoch: 5| Step: 5
Training loss: 2.6639187335968018
Validation loss: 1.844917123035718

Epoch: 5| Step: 6
Training loss: 1.5069921016693115
Validation loss: 1.8693069052952591

Epoch: 5| Step: 7
Training loss: 1.6261358261108398
Validation loss: 1.8869033205893733

Epoch: 5| Step: 8
Training loss: 1.4535386562347412
Validation loss: 1.8470334904168242

Epoch: 5| Step: 9
Training loss: 1.9918025732040405
Validation loss: 1.870391191974763

Epoch: 5| Step: 10
Training loss: 2.4415056705474854
Validation loss: 1.8457054245856501

Epoch: 271| Step: 0
Training loss: 2.218323230743408
Validation loss: 1.8716474553590179

Epoch: 5| Step: 1
Training loss: 1.4201332330703735
Validation loss: 1.9032902461226269

Epoch: 5| Step: 2
Training loss: 1.6078367233276367
Validation loss: 1.857060590097981

Epoch: 5| Step: 3
Training loss: 1.8388175964355469
Validation loss: 1.8817401509131155

Epoch: 5| Step: 4
Training loss: 1.6609208583831787
Validation loss: 1.858980606960994

Epoch: 5| Step: 5
Training loss: 1.903127670288086
Validation loss: 1.8677142871323453

Epoch: 5| Step: 6
Training loss: 2.3071625232696533
Validation loss: 1.8878539864734938

Epoch: 5| Step: 7
Training loss: 1.5299978256225586
Validation loss: 1.8802647424000565

Epoch: 5| Step: 8
Training loss: 1.8778988122940063
Validation loss: 1.909785388618387

Epoch: 5| Step: 9
Training loss: 2.0561490058898926
Validation loss: 1.8793059805388093

Epoch: 5| Step: 10
Training loss: 1.4085767269134521
Validation loss: 1.8847611078652002

Epoch: 272| Step: 0
Training loss: 1.782537817955017
Validation loss: 1.9029595095624205

Epoch: 5| Step: 1
Training loss: 1.7425823211669922
Validation loss: 1.9219188818367579

Epoch: 5| Step: 2
Training loss: 1.672014594078064
Validation loss: 1.9087152455442695

Epoch: 5| Step: 3
Training loss: 1.764731764793396
Validation loss: 1.8769357742801789

Epoch: 5| Step: 4
Training loss: 1.6823333501815796
Validation loss: 1.8982276634503437

Epoch: 5| Step: 5
Training loss: 1.9999282360076904
Validation loss: 1.8824184376706359

Epoch: 5| Step: 6
Training loss: 1.6124836206436157
Validation loss: 1.8945370643369612

Epoch: 5| Step: 7
Training loss: 2.5899245738983154
Validation loss: 1.9065846115030267

Epoch: 5| Step: 8
Training loss: 2.0332398414611816
Validation loss: 1.9005528419248519

Epoch: 5| Step: 9
Training loss: 1.4945318698883057
Validation loss: 1.9008916962531306

Epoch: 5| Step: 10
Training loss: 1.6159543991088867
Validation loss: 1.8855536830040716

Epoch: 273| Step: 0
Training loss: 1.3987843990325928
Validation loss: 1.8607140920495475

Epoch: 5| Step: 1
Training loss: 1.8555419445037842
Validation loss: 1.868651948949342

Epoch: 5| Step: 2
Training loss: 1.7554746866226196
Validation loss: 1.8607548334265267

Epoch: 5| Step: 3
Training loss: 2.0633397102355957
Validation loss: 1.8864101889312908

Epoch: 5| Step: 4
Training loss: 1.4172227382659912
Validation loss: 1.8749379457965973

Epoch: 5| Step: 5
Training loss: 2.2524971961975098
Validation loss: 1.8603623990089662

Epoch: 5| Step: 6
Training loss: 2.1178383827209473
Validation loss: 1.8626692371983682

Epoch: 5| Step: 7
Training loss: 1.9822075366973877
Validation loss: 1.8763306525445753

Epoch: 5| Step: 8
Training loss: 1.8978326320648193
Validation loss: 1.870390502355432

Epoch: 5| Step: 9
Training loss: 1.5876442193984985
Validation loss: 1.8345149999023767

Epoch: 5| Step: 10
Training loss: 1.167893886566162
Validation loss: 1.864507471361468

Epoch: 274| Step: 0
Training loss: 2.184274196624756
Validation loss: 1.8907406919745988

Epoch: 5| Step: 1
Training loss: 2.048973798751831
Validation loss: 1.8575946541242703

Epoch: 5| Step: 2
Training loss: 1.9780439138412476
Validation loss: 1.858353212315549

Epoch: 5| Step: 3
Training loss: 1.7490803003311157
Validation loss: 1.8627947325347571

Epoch: 5| Step: 4
Training loss: 1.6773052215576172
Validation loss: 1.8533383671955397

Epoch: 5| Step: 5
Training loss: 2.1196041107177734
Validation loss: 1.884234538642309

Epoch: 5| Step: 6
Training loss: 1.576095700263977
Validation loss: 1.8372217057853617

Epoch: 5| Step: 7
Training loss: 1.3247058391571045
Validation loss: 1.8904078929655013

Epoch: 5| Step: 8
Training loss: 1.7781301736831665
Validation loss: 1.8856625249308925

Epoch: 5| Step: 9
Training loss: 1.866084098815918
Validation loss: 1.8910284414086291

Epoch: 5| Step: 10
Training loss: 1.4905896186828613
Validation loss: 1.8535209189179123

Epoch: 275| Step: 0
Training loss: 1.6561521291732788
Validation loss: 1.898923256063974

Epoch: 5| Step: 1
Training loss: 1.9829012155532837
Validation loss: 1.9252383298771356

Epoch: 5| Step: 2
Training loss: 2.1228058338165283
Validation loss: 1.9051995226131972

Epoch: 5| Step: 3
Training loss: 2.038578748703003
Validation loss: 1.8888022168990104

Epoch: 5| Step: 4
Training loss: 2.148940086364746
Validation loss: 1.8979272509133944

Epoch: 5| Step: 5
Training loss: 2.011064052581787
Validation loss: 1.9203383384212371

Epoch: 5| Step: 6
Training loss: 1.6951795816421509
Validation loss: 1.8960892090233423

Epoch: 5| Step: 7
Training loss: 1.396388053894043
Validation loss: 1.8889295593384774

Epoch: 5| Step: 8
Training loss: 1.6660187244415283
Validation loss: 1.8828379441333074

Epoch: 5| Step: 9
Training loss: 1.666459083557129
Validation loss: 1.855338788801624

Epoch: 5| Step: 10
Training loss: 1.5059716701507568
Validation loss: 1.871186367927059

Epoch: 276| Step: 0
Training loss: 2.103825807571411
Validation loss: 1.859135586728332

Epoch: 5| Step: 1
Training loss: 1.5938974618911743
Validation loss: 1.8528252442677815

Epoch: 5| Step: 2
Training loss: 1.351951241493225
Validation loss: 1.8537250590580765

Epoch: 5| Step: 3
Training loss: 1.6685768365859985
Validation loss: 1.8645457836889452

Epoch: 5| Step: 4
Training loss: 2.280688762664795
Validation loss: 1.8273554155903478

Epoch: 5| Step: 5
Training loss: 2.0523014068603516
Validation loss: 1.8664103861778014

Epoch: 5| Step: 6
Training loss: 1.6188690662384033
Validation loss: 1.8501052625717656

Epoch: 5| Step: 7
Training loss: 1.6492332220077515
Validation loss: 1.8332774100765106

Epoch: 5| Step: 8
Training loss: 1.8629987239837646
Validation loss: 1.8375277442316855

Epoch: 5| Step: 9
Training loss: 1.9162200689315796
Validation loss: 1.866419546065792

Epoch: 5| Step: 10
Training loss: 1.786339282989502
Validation loss: 1.8700482922215615

Epoch: 277| Step: 0
Training loss: 1.748049020767212
Validation loss: 1.8617354503241919

Epoch: 5| Step: 1
Training loss: 2.0517354011535645
Validation loss: 1.8994051500033307

Epoch: 5| Step: 2
Training loss: 1.2900382280349731
Validation loss: 1.8948990914129442

Epoch: 5| Step: 3
Training loss: 1.6911541223526
Validation loss: 1.875422639231528

Epoch: 5| Step: 4
Training loss: 1.8032773733139038
Validation loss: 1.9057115547118648

Epoch: 5| Step: 5
Training loss: 1.9637749195098877
Validation loss: 1.9039680009247155

Epoch: 5| Step: 6
Training loss: 1.2601394653320312
Validation loss: 1.8897533224474998

Epoch: 5| Step: 7
Training loss: 1.6829640865325928
Validation loss: 1.9087211419177312

Epoch: 5| Step: 8
Training loss: 2.420337677001953
Validation loss: 1.900086328547488

Epoch: 5| Step: 9
Training loss: 1.9728819131851196
Validation loss: 1.876372197622894

Epoch: 5| Step: 10
Training loss: 1.8249549865722656
Validation loss: 1.897685613683475

Epoch: 278| Step: 0
Training loss: 1.969688057899475
Validation loss: 1.9009392479414582

Epoch: 5| Step: 1
Training loss: 1.1784675121307373
Validation loss: 1.8869057457934144

Epoch: 5| Step: 2
Training loss: 1.8897651433944702
Validation loss: 1.859094953024259

Epoch: 5| Step: 3
Training loss: 1.9163596630096436
Validation loss: 1.8864855125386228

Epoch: 5| Step: 4
Training loss: 1.7754004001617432
Validation loss: 1.9008465108051096

Epoch: 5| Step: 5
Training loss: 1.8821525573730469
Validation loss: 1.8852555021162956

Epoch: 5| Step: 6
Training loss: 1.8483803272247314
Validation loss: 1.8584359409988567

Epoch: 5| Step: 7
Training loss: 2.108081102371216
Validation loss: 1.9239140966887116

Epoch: 5| Step: 8
Training loss: 1.761157751083374
Validation loss: 1.8836624955618253

Epoch: 5| Step: 9
Training loss: 1.358973741531372
Validation loss: 1.8644967232981036

Epoch: 5| Step: 10
Training loss: 1.9887865781784058
Validation loss: 1.8816566954376877

Epoch: 279| Step: 0
Training loss: 2.0454676151275635
Validation loss: 1.8483906510055705

Epoch: 5| Step: 1
Training loss: 1.8626092672348022
Validation loss: 1.8596878667031564

Epoch: 5| Step: 2
Training loss: 2.2707760334014893
Validation loss: 1.86626947182481

Epoch: 5| Step: 3
Training loss: 1.5098475217819214
Validation loss: 1.8861632706016622

Epoch: 5| Step: 4
Training loss: 1.8839133977890015
Validation loss: 1.8607481154062415

Epoch: 5| Step: 5
Training loss: 1.5132471323013306
Validation loss: 1.882209582995343

Epoch: 5| Step: 6
Training loss: 1.9946444034576416
Validation loss: 1.869015041218009

Epoch: 5| Step: 7
Training loss: 1.6145471334457397
Validation loss: 1.8829065471567132

Epoch: 5| Step: 8
Training loss: 1.9282684326171875
Validation loss: 1.8883028209850352

Epoch: 5| Step: 9
Training loss: 1.5091581344604492
Validation loss: 1.870842554235971

Epoch: 5| Step: 10
Training loss: 1.4229599237442017
Validation loss: 1.8885671861710087

Epoch: 280| Step: 0
Training loss: 1.7445707321166992
Validation loss: 1.8629231940033615

Epoch: 5| Step: 1
Training loss: 1.82456374168396
Validation loss: 1.8542255150374545

Epoch: 5| Step: 2
Training loss: 2.255708694458008
Validation loss: 1.8466867605845134

Epoch: 5| Step: 3
Training loss: 2.14158296585083
Validation loss: 1.851395873613255

Epoch: 5| Step: 4
Training loss: 2.1335787773132324
Validation loss: 1.862669675580917

Epoch: 5| Step: 5
Training loss: 1.6142685413360596
Validation loss: 1.8954186849696661

Epoch: 5| Step: 6
Training loss: 1.391340970993042
Validation loss: 1.8512824889152282

Epoch: 5| Step: 7
Training loss: 1.919451117515564
Validation loss: 1.8663427445196337

Epoch: 5| Step: 8
Training loss: 2.0757453441619873
Validation loss: 1.8707708261346305

Epoch: 5| Step: 9
Training loss: 1.1685603857040405
Validation loss: 1.8650119163656746

Epoch: 5| Step: 10
Training loss: 1.0956015586853027
Validation loss: 1.87508947490364

Epoch: 281| Step: 0
Training loss: 1.7371177673339844
Validation loss: 1.905078488011514

Epoch: 5| Step: 1
Training loss: 1.7005863189697266
Validation loss: 1.8838658717370802

Epoch: 5| Step: 2
Training loss: 1.9470964670181274
Validation loss: 1.8484076710157498

Epoch: 5| Step: 3
Training loss: 1.902101755142212
Validation loss: 1.877461943575131

Epoch: 5| Step: 4
Training loss: 2.5145740509033203
Validation loss: 1.8609736606638918

Epoch: 5| Step: 5
Training loss: 1.6818777322769165
Validation loss: 1.8825398491274925

Epoch: 5| Step: 6
Training loss: 1.0249814987182617
Validation loss: 1.9021620545335995

Epoch: 5| Step: 7
Training loss: 2.0281147956848145
Validation loss: 1.873527919092486

Epoch: 5| Step: 8
Training loss: 2.372335195541382
Validation loss: 1.879187942833029

Epoch: 5| Step: 9
Training loss: 1.395929217338562
Validation loss: 1.8764268659776258

Epoch: 5| Step: 10
Training loss: 1.2422564029693604
Validation loss: 1.8563182546246437

Epoch: 282| Step: 0
Training loss: 1.6666399240493774
Validation loss: 1.8711565092045774

Epoch: 5| Step: 1
Training loss: 1.9121357202529907
Validation loss: 1.8764279427066926

Epoch: 5| Step: 2
Training loss: 1.5291621685028076
Validation loss: 1.865311045800486

Epoch: 5| Step: 3
Training loss: 1.9800384044647217
Validation loss: 1.8591632150834607

Epoch: 5| Step: 4
Training loss: 1.272155523300171
Validation loss: 1.8613026193393174

Epoch: 5| Step: 5
Training loss: 2.7375946044921875
Validation loss: 1.8872456730052989

Epoch: 5| Step: 6
Training loss: 1.619712471961975
Validation loss: 1.8845194731989214

Epoch: 5| Step: 7
Training loss: 1.5246570110321045
Validation loss: 1.8452005053079257

Epoch: 5| Step: 8
Training loss: 1.65907883644104
Validation loss: 1.8651126610335482

Epoch: 5| Step: 9
Training loss: 1.7116763591766357
Validation loss: 1.8761110190422303

Epoch: 5| Step: 10
Training loss: 2.1874213218688965
Validation loss: 1.8793683590427521

Epoch: 283| Step: 0
Training loss: 2.1093084812164307
Validation loss: 1.8711124517584359

Epoch: 5| Step: 1
Training loss: 1.4696060419082642
Validation loss: 1.858384648958842

Epoch: 5| Step: 2
Training loss: 2.057497978210449
Validation loss: 1.8679186067273539

Epoch: 5| Step: 3
Training loss: 2.0605552196502686
Validation loss: 1.8712221704503542

Epoch: 5| Step: 4
Training loss: 1.8733148574829102
Validation loss: 1.8545177572516984

Epoch: 5| Step: 5
Training loss: 1.9038894176483154
Validation loss: 1.8976677707446519

Epoch: 5| Step: 6
Training loss: 1.572932481765747
Validation loss: 1.8858119595435359

Epoch: 5| Step: 7
Training loss: 1.6198179721832275
Validation loss: 1.8943801208208966

Epoch: 5| Step: 8
Training loss: 1.6298706531524658
Validation loss: 1.8706138210911905

Epoch: 5| Step: 9
Training loss: 1.421979546546936
Validation loss: 1.8446553035448956

Epoch: 5| Step: 10
Training loss: 1.96377432346344
Validation loss: 1.8727920183571436

Epoch: 284| Step: 0
Training loss: 1.698328971862793
Validation loss: 1.8644440507376066

Epoch: 5| Step: 1
Training loss: 2.0673468112945557
Validation loss: 1.8406078533459735

Epoch: 5| Step: 2
Training loss: 1.3107465505599976
Validation loss: 1.8596612830315866

Epoch: 5| Step: 3
Training loss: 1.5746562480926514
Validation loss: 1.8381729331067813

Epoch: 5| Step: 4
Training loss: 2.4627599716186523
Validation loss: 1.8280841637683172

Epoch: 5| Step: 5
Training loss: 1.215611457824707
Validation loss: 1.8682763563689364

Epoch: 5| Step: 6
Training loss: 1.2819560766220093
Validation loss: 1.8345602455959524

Epoch: 5| Step: 7
Training loss: 1.647212266921997
Validation loss: 1.8457184594164613

Epoch: 5| Step: 8
Training loss: 1.831855058670044
Validation loss: 1.825614256243552

Epoch: 5| Step: 9
Training loss: 1.8094335794448853
Validation loss: 1.8541713324926232

Epoch: 5| Step: 10
Training loss: 2.8405232429504395
Validation loss: 1.8658927653425483

Epoch: 285| Step: 0
Training loss: 2.060070037841797
Validation loss: 1.846316929786436

Epoch: 5| Step: 1
Training loss: 1.7222633361816406
Validation loss: 1.864972344008825

Epoch: 5| Step: 2
Training loss: 1.6399867534637451
Validation loss: 1.896618781551238

Epoch: 5| Step: 3
Training loss: 1.6645065546035767
Validation loss: 1.8739471563728907

Epoch: 5| Step: 4
Training loss: 1.643691062927246
Validation loss: 1.901935682501844

Epoch: 5| Step: 5
Training loss: 2.065784454345703
Validation loss: 1.934708095365955

Epoch: 5| Step: 6
Training loss: 2.03322434425354
Validation loss: 1.9061875471504786

Epoch: 5| Step: 7
Training loss: 1.8063433170318604
Validation loss: 1.891814834328108

Epoch: 5| Step: 8
Training loss: 1.5733082294464111
Validation loss: 1.9097674328793761

Epoch: 5| Step: 9
Training loss: 1.9220783710479736
Validation loss: 1.921709104250836

Epoch: 5| Step: 10
Training loss: 1.58339524269104
Validation loss: 1.887090072836927

Epoch: 286| Step: 0
Training loss: 2.1879849433898926
Validation loss: 1.9331182138894194

Epoch: 5| Step: 1
Training loss: 2.3413233757019043
Validation loss: 1.8948973827464606

Epoch: 5| Step: 2
Training loss: 1.535842776298523
Validation loss: 1.8669884794501848

Epoch: 5| Step: 3
Training loss: 1.6839481592178345
Validation loss: 1.8992338770179338

Epoch: 5| Step: 4
Training loss: 1.1730470657348633
Validation loss: 1.8553643547078615

Epoch: 5| Step: 5
Training loss: 1.693554162979126
Validation loss: 1.8620142372705604

Epoch: 5| Step: 6
Training loss: 2.6139984130859375
Validation loss: 1.8529843412419802

Epoch: 5| Step: 7
Training loss: 1.2897156476974487
Validation loss: 1.8729766363738685

Epoch: 5| Step: 8
Training loss: 1.7734063863754272
Validation loss: 1.870636591347315

Epoch: 5| Step: 9
Training loss: 1.2438024282455444
Validation loss: 1.8489190275951097

Epoch: 5| Step: 10
Training loss: 1.5806604623794556
Validation loss: 1.8342390714153167

Epoch: 287| Step: 0
Training loss: 1.7480827569961548
Validation loss: 1.8473513395555559

Epoch: 5| Step: 1
Training loss: 2.280799388885498
Validation loss: 1.8443106989706717

Epoch: 5| Step: 2
Training loss: 1.3486030101776123
Validation loss: 1.8323698992370276

Epoch: 5| Step: 3
Training loss: 1.061797857284546
Validation loss: 1.8449511553651543

Epoch: 5| Step: 4
Training loss: 2.411619186401367
Validation loss: 1.85987776325595

Epoch: 5| Step: 5
Training loss: 1.2882819175720215
Validation loss: 1.857272595487615

Epoch: 5| Step: 6
Training loss: 2.1640610694885254
Validation loss: 1.853178011473789

Epoch: 5| Step: 7
Training loss: 1.5430489778518677
Validation loss: 1.81573566954623

Epoch: 5| Step: 8
Training loss: 1.7197086811065674
Validation loss: 1.8551412115814865

Epoch: 5| Step: 9
Training loss: 2.0051372051239014
Validation loss: 1.9010323760330037

Epoch: 5| Step: 10
Training loss: 1.8528611660003662
Validation loss: 1.8612238437898698

Epoch: 288| Step: 0
Training loss: 2.113987922668457
Validation loss: 1.870642920976044

Epoch: 5| Step: 1
Training loss: 2.0534470081329346
Validation loss: 1.8506060364425823

Epoch: 5| Step: 2
Training loss: 1.3054981231689453
Validation loss: 1.8601136117853143

Epoch: 5| Step: 3
Training loss: 1.9311920404434204
Validation loss: 1.8836142209268385

Epoch: 5| Step: 4
Training loss: 1.57183039188385
Validation loss: 1.8596428094371673

Epoch: 5| Step: 5
Training loss: 1.3552725315093994
Validation loss: 1.8562761788727136

Epoch: 5| Step: 6
Training loss: 1.3737878799438477
Validation loss: 1.8809221572773431

Epoch: 5| Step: 7
Training loss: 1.8221359252929688
Validation loss: 1.8822268183513353

Epoch: 5| Step: 8
Training loss: 2.0894951820373535
Validation loss: 1.860199386073697

Epoch: 5| Step: 9
Training loss: 2.0727100372314453
Validation loss: 1.8478883671504196

Epoch: 5| Step: 10
Training loss: 1.746768832206726
Validation loss: 1.842051657297278

Epoch: 289| Step: 0
Training loss: 1.7333686351776123
Validation loss: 1.8192249472423265

Epoch: 5| Step: 1
Training loss: 1.8546245098114014
Validation loss: 1.8521579670649704

Epoch: 5| Step: 2
Training loss: 1.3255418539047241
Validation loss: 1.8590975807559105

Epoch: 5| Step: 3
Training loss: 2.3943870067596436
Validation loss: 1.856716799479659

Epoch: 5| Step: 4
Training loss: 1.5606014728546143
Validation loss: 1.849485271720476

Epoch: 5| Step: 5
Training loss: 1.6353566646575928
Validation loss: 1.8670975213409753

Epoch: 5| Step: 6
Training loss: 2.0491137504577637
Validation loss: 1.8518715712331957

Epoch: 5| Step: 7
Training loss: 1.4076013565063477
Validation loss: 1.8408068277502572

Epoch: 5| Step: 8
Training loss: 1.8560466766357422
Validation loss: 1.8532592750364734

Epoch: 5| Step: 9
Training loss: 1.4553409814834595
Validation loss: 1.8742333073769846

Epoch: 5| Step: 10
Training loss: 2.159874200820923
Validation loss: 1.8454469711549821

Epoch: 290| Step: 0
Training loss: 1.4838848114013672
Validation loss: 1.864899258459768

Epoch: 5| Step: 1
Training loss: 1.2623538970947266
Validation loss: 1.8452077988655335

Epoch: 5| Step: 2
Training loss: 1.6548351049423218
Validation loss: 1.8620396044946486

Epoch: 5| Step: 3
Training loss: 2.392063617706299
Validation loss: 1.865219868639464

Epoch: 5| Step: 4
Training loss: 2.212968111038208
Validation loss: 1.8575974305470784

Epoch: 5| Step: 5
Training loss: 2.1422553062438965
Validation loss: 1.8307987964281471

Epoch: 5| Step: 6
Training loss: 1.6595662832260132
Validation loss: 1.8368969694260628

Epoch: 5| Step: 7
Training loss: 1.7204490900039673
Validation loss: 1.8703797094283565

Epoch: 5| Step: 8
Training loss: 1.6949939727783203
Validation loss: 1.8584834567962154

Epoch: 5| Step: 9
Training loss: 1.6556813716888428
Validation loss: 1.8790513841054772

Epoch: 5| Step: 10
Training loss: 1.4376201629638672
Validation loss: 1.8729384419738606

Epoch: 291| Step: 0
Training loss: 1.873722791671753
Validation loss: 1.866129200304708

Epoch: 5| Step: 1
Training loss: 1.6313531398773193
Validation loss: 1.881580202810226

Epoch: 5| Step: 2
Training loss: 2.11539626121521
Validation loss: 1.864891138128055

Epoch: 5| Step: 3
Training loss: 1.5176541805267334
Validation loss: 1.8761716696523851

Epoch: 5| Step: 4
Training loss: 1.7791004180908203
Validation loss: 1.84042868691106

Epoch: 5| Step: 5
Training loss: 2.055793046951294
Validation loss: 1.8751655150485296

Epoch: 5| Step: 6
Training loss: 1.7819626331329346
Validation loss: 1.8597393522980392

Epoch: 5| Step: 7
Training loss: 2.214158773422241
Validation loss: 1.8572057088216145

Epoch: 5| Step: 8
Training loss: 1.094922423362732
Validation loss: 1.8582210835590158

Epoch: 5| Step: 9
Training loss: 1.9167702198028564
Validation loss: 1.849758654512385

Epoch: 5| Step: 10
Training loss: 1.5158641338348389
Validation loss: 1.822849101917718

Epoch: 292| Step: 0
Training loss: 1.3983519077301025
Validation loss: 1.8625461619387391

Epoch: 5| Step: 1
Training loss: 1.9419498443603516
Validation loss: 1.8563428848020491

Epoch: 5| Step: 2
Training loss: 1.932012915611267
Validation loss: 1.8573466488110122

Epoch: 5| Step: 3
Training loss: 1.4861361980438232
Validation loss: 1.8753712177276611

Epoch: 5| Step: 4
Training loss: 2.0374398231506348
Validation loss: 1.9010743338574645

Epoch: 5| Step: 5
Training loss: 1.4054994583129883
Validation loss: 1.8859373728434246

Epoch: 5| Step: 6
Training loss: 1.7065393924713135
Validation loss: 1.8501783096662132

Epoch: 5| Step: 7
Training loss: 1.7975105047225952
Validation loss: 1.8734295919377317

Epoch: 5| Step: 8
Training loss: 2.0683987140655518
Validation loss: 1.837993311625655

Epoch: 5| Step: 9
Training loss: 1.789855718612671
Validation loss: 1.879581666761829

Epoch: 5| Step: 10
Training loss: 1.6432697772979736
Validation loss: 1.8843274603607834

Epoch: 293| Step: 0
Training loss: 1.6768420934677124
Validation loss: 1.84269929188554

Epoch: 5| Step: 1
Training loss: 1.8390834331512451
Validation loss: 1.8354963974286151

Epoch: 5| Step: 2
Training loss: 1.4039976596832275
Validation loss: 1.8581772312041251

Epoch: 5| Step: 3
Training loss: 2.3534507751464844
Validation loss: 1.8217436857120965

Epoch: 5| Step: 4
Training loss: 1.1484676599502563
Validation loss: 1.7976607347047457

Epoch: 5| Step: 5
Training loss: 1.9800117015838623
Validation loss: 1.861150360876514

Epoch: 5| Step: 6
Training loss: 1.6107304096221924
Validation loss: 1.825986789118859

Epoch: 5| Step: 7
Training loss: 1.7657569646835327
Validation loss: 1.8666720621047481

Epoch: 5| Step: 8
Training loss: 2.4038681983947754
Validation loss: 1.8596157489284393

Epoch: 5| Step: 9
Training loss: 1.8326667547225952
Validation loss: 1.850942934713056

Epoch: 5| Step: 10
Training loss: 0.8208450675010681
Validation loss: 1.8525447640367734

Epoch: 294| Step: 0
Training loss: 1.509386658668518
Validation loss: 1.8656113980918803

Epoch: 5| Step: 1
Training loss: 2.0210137367248535
Validation loss: 1.8570576739567581

Epoch: 5| Step: 2
Training loss: 1.991804838180542
Validation loss: 1.8709722500975414

Epoch: 5| Step: 3
Training loss: 1.7401866912841797
Validation loss: 1.8689530036782707

Epoch: 5| Step: 4
Training loss: 1.2358496189117432
Validation loss: 1.8488701774228005

Epoch: 5| Step: 5
Training loss: 1.1749467849731445
Validation loss: 1.8835885165840067

Epoch: 5| Step: 6
Training loss: 1.8648483753204346
Validation loss: 1.8567047836960002

Epoch: 5| Step: 7
Training loss: 1.4322491884231567
Validation loss: 1.88390044243105

Epoch: 5| Step: 8
Training loss: 1.6246757507324219
Validation loss: 1.8712328428863196

Epoch: 5| Step: 9
Training loss: 2.4851632118225098
Validation loss: 1.8715234956433695

Epoch: 5| Step: 10
Training loss: 1.986570954322815
Validation loss: 1.892955526228874

Epoch: 295| Step: 0
Training loss: 1.6808383464813232
Validation loss: 1.8845259040914557

Epoch: 5| Step: 1
Training loss: 2.461608648300171
Validation loss: 1.9016501339532996

Epoch: 5| Step: 2
Training loss: 1.459575891494751
Validation loss: 1.8845661711949173

Epoch: 5| Step: 3
Training loss: 2.117199420928955
Validation loss: 1.8968653601984824

Epoch: 5| Step: 4
Training loss: 1.7120370864868164
Validation loss: 1.8485340399126853

Epoch: 5| Step: 5
Training loss: 1.4423197507858276
Validation loss: 1.8794055972048032

Epoch: 5| Step: 6
Training loss: 1.130489706993103
Validation loss: 1.8419549798452726

Epoch: 5| Step: 7
Training loss: 1.3950588703155518
Validation loss: 1.8214284271322272

Epoch: 5| Step: 8
Training loss: 1.4722304344177246
Validation loss: 1.8631615818187754

Epoch: 5| Step: 9
Training loss: 2.454134464263916
Validation loss: 1.8365845398236347

Epoch: 5| Step: 10
Training loss: 1.7345882654190063
Validation loss: 1.821364491216598

Epoch: 296| Step: 0
Training loss: 2.228668212890625
Validation loss: 1.8416056709904824

Epoch: 5| Step: 1
Training loss: 2.318140983581543
Validation loss: 1.8441387786660144

Epoch: 5| Step: 2
Training loss: 1.5258902311325073
Validation loss: 1.8423392554765106

Epoch: 5| Step: 3
Training loss: 1.3608567714691162
Validation loss: 1.8792199191226755

Epoch: 5| Step: 4
Training loss: 1.6659443378448486
Validation loss: 1.8796599744468607

Epoch: 5| Step: 5
Training loss: 1.8925940990447998
Validation loss: 1.8610073725382488

Epoch: 5| Step: 6
Training loss: 1.92742919921875
Validation loss: 1.8555203137859222

Epoch: 5| Step: 7
Training loss: 1.6491258144378662
Validation loss: 1.8444461694327734

Epoch: 5| Step: 8
Training loss: 1.9362280368804932
Validation loss: 1.8603734303546209

Epoch: 5| Step: 9
Training loss: 1.488279104232788
Validation loss: 1.8413259662607664

Epoch: 5| Step: 10
Training loss: 1.1369856595993042
Validation loss: 1.840117254564839

Epoch: 297| Step: 0
Training loss: 2.0997185707092285
Validation loss: 1.8504030409679617

Epoch: 5| Step: 1
Training loss: 1.5305182933807373
Validation loss: 1.862595332566128

Epoch: 5| Step: 2
Training loss: 2.0210232734680176
Validation loss: 1.8626155622543827

Epoch: 5| Step: 3
Training loss: 1.4808193445205688
Validation loss: 1.8442220418683943

Epoch: 5| Step: 4
Training loss: 1.3101980686187744
Validation loss: 1.8627043539477932

Epoch: 5| Step: 5
Training loss: 2.0592234134674072
Validation loss: 1.8594579978655743

Epoch: 5| Step: 6
Training loss: 1.4737306833267212
Validation loss: 1.8108593366479362

Epoch: 5| Step: 7
Training loss: 1.7382466793060303
Validation loss: 1.8517380888744066

Epoch: 5| Step: 8
Training loss: 2.133694648742676
Validation loss: 1.8701743874498593

Epoch: 5| Step: 9
Training loss: 1.5123710632324219
Validation loss: 1.8114830499054284

Epoch: 5| Step: 10
Training loss: 1.5601816177368164
Validation loss: 1.8664116859436035

Epoch: 298| Step: 0
Training loss: 1.6443344354629517
Validation loss: 1.8543893662832116

Epoch: 5| Step: 1
Training loss: 1.1553304195404053
Validation loss: 1.8493440023032568

Epoch: 5| Step: 2
Training loss: 1.9172252416610718
Validation loss: 1.8439319056849326

Epoch: 5| Step: 3
Training loss: 2.000845432281494
Validation loss: 1.8644338282205726

Epoch: 5| Step: 4
Training loss: 1.956682562828064
Validation loss: 1.8455225652264011

Epoch: 5| Step: 5
Training loss: 2.3592169284820557
Validation loss: 1.8766898083430466

Epoch: 5| Step: 6
Training loss: 1.8293815851211548
Validation loss: 1.8492235919480682

Epoch: 5| Step: 7
Training loss: 1.7212915420532227
Validation loss: 1.8398901147227134

Epoch: 5| Step: 8
Training loss: 1.4812225103378296
Validation loss: 1.869552553340953

Epoch: 5| Step: 9
Training loss: 1.574440360069275
Validation loss: 1.8813306016306723

Epoch: 5| Step: 10
Training loss: 1.3161945343017578
Validation loss: 1.8412808461855816

Epoch: 299| Step: 0
Training loss: 1.8701575994491577
Validation loss: 1.8797769238871913

Epoch: 5| Step: 1
Training loss: 2.2653045654296875
Validation loss: 1.8395848684413458

Epoch: 5| Step: 2
Training loss: 1.7879221439361572
Validation loss: 1.8553562510398127

Epoch: 5| Step: 3
Training loss: 1.1558196544647217
Validation loss: 1.8246041946513678

Epoch: 5| Step: 4
Training loss: 1.32318115234375
Validation loss: 1.8601760351529686

Epoch: 5| Step: 5
Training loss: 1.782415747642517
Validation loss: 1.855904556089832

Epoch: 5| Step: 6
Training loss: 2.0226387977600098
Validation loss: 1.8397809100407425

Epoch: 5| Step: 7
Training loss: 1.7750250101089478
Validation loss: 1.8292154214715446

Epoch: 5| Step: 8
Training loss: 1.941461205482483
Validation loss: 1.81416699065957

Epoch: 5| Step: 9
Training loss: 1.408672571182251
Validation loss: 1.8289044646806614

Epoch: 5| Step: 10
Training loss: 1.6638994216918945
Validation loss: 1.817942403977917

Epoch: 300| Step: 0
Training loss: 1.2688844203948975
Validation loss: 1.8709280849784933

Epoch: 5| Step: 1
Training loss: 2.4992377758026123
Validation loss: 1.8367369136502665

Epoch: 5| Step: 2
Training loss: 1.7176250219345093
Validation loss: 1.7968673885509532

Epoch: 5| Step: 3
Training loss: 1.5549507141113281
Validation loss: 1.844906742854785

Epoch: 5| Step: 4
Training loss: 1.4609367847442627
Validation loss: 1.8865770319456696

Epoch: 5| Step: 5
Training loss: 2.376970052719116
Validation loss: 1.848311234545964

Epoch: 5| Step: 6
Training loss: 1.6426706314086914
Validation loss: 1.8701935916818597

Epoch: 5| Step: 7
Training loss: 1.8243157863616943
Validation loss: 1.8638739432058027

Epoch: 5| Step: 8
Training loss: 1.8201892375946045
Validation loss: 1.8796521450883599

Epoch: 5| Step: 9
Training loss: 1.4560412168502808
Validation loss: 1.8598228103371077

Epoch: 5| Step: 10
Training loss: 1.1329679489135742
Validation loss: 1.832693188421188

Epoch: 301| Step: 0
Training loss: 1.5060831308364868
Validation loss: 1.855023693012935

Epoch: 5| Step: 1
Training loss: 1.5945322513580322
Validation loss: 1.849940114123847

Epoch: 5| Step: 2
Training loss: 1.0999852418899536
Validation loss: 1.8467035716579807

Epoch: 5| Step: 3
Training loss: 1.6166353225708008
Validation loss: 1.8508712809572938

Epoch: 5| Step: 4
Training loss: 1.662859320640564
Validation loss: 1.8559412033327165

Epoch: 5| Step: 5
Training loss: 2.303605556488037
Validation loss: 1.8249395444828977

Epoch: 5| Step: 6
Training loss: 1.7852528095245361
Validation loss: 1.8444452631858088

Epoch: 5| Step: 7
Training loss: 1.6838163137435913
Validation loss: 1.8564155793959094

Epoch: 5| Step: 8
Training loss: 1.7993028163909912
Validation loss: 1.8134051010172854

Epoch: 5| Step: 9
Training loss: 1.807621955871582
Validation loss: 1.8224963180480465

Epoch: 5| Step: 10
Training loss: 1.808030128479004
Validation loss: 1.8423428445734003

Epoch: 302| Step: 0
Training loss: 1.8254215717315674
Validation loss: 1.861672096354987

Epoch: 5| Step: 1
Training loss: 1.687583565711975
Validation loss: 1.8485501863623177

Epoch: 5| Step: 2
Training loss: 1.0451222658157349
Validation loss: 1.8392063674106394

Epoch: 5| Step: 3
Training loss: 1.5991533994674683
Validation loss: 1.8516384427265455

Epoch: 5| Step: 4
Training loss: 2.112658739089966
Validation loss: 1.8147214753653413

Epoch: 5| Step: 5
Training loss: 1.5691871643066406
Validation loss: 1.835524812821419

Epoch: 5| Step: 6
Training loss: 1.7503089904785156
Validation loss: 1.8463791647265035

Epoch: 5| Step: 7
Training loss: 1.8189895153045654
Validation loss: 1.8745619199609245

Epoch: 5| Step: 8
Training loss: 1.6095302104949951
Validation loss: 1.8542659769776046

Epoch: 5| Step: 9
Training loss: 1.7472484111785889
Validation loss: 1.8469117969594977

Epoch: 5| Step: 10
Training loss: 1.9978395700454712
Validation loss: 1.840754424372027

Epoch: 303| Step: 0
Training loss: 2.0171494483947754
Validation loss: 1.8488596306052258

Epoch: 5| Step: 1
Training loss: 1.74789297580719
Validation loss: 1.8455730087013655

Epoch: 5| Step: 2
Training loss: 1.1075140237808228
Validation loss: 1.8568825824286348

Epoch: 5| Step: 3
Training loss: 1.283402442932129
Validation loss: 1.838374989007109

Epoch: 5| Step: 4
Training loss: 1.8132644891738892
Validation loss: 1.8401969196975871

Epoch: 5| Step: 5
Training loss: 2.0065560340881348
Validation loss: 1.8374805501712266

Epoch: 5| Step: 6
Training loss: 1.7422412633895874
Validation loss: 1.8348912013474332

Epoch: 5| Step: 7
Training loss: 1.999500036239624
Validation loss: 1.833340899918669

Epoch: 5| Step: 8
Training loss: 2.080273389816284
Validation loss: 1.8458062961537351

Epoch: 5| Step: 9
Training loss: 1.8531363010406494
Validation loss: 1.8142680173279138

Epoch: 5| Step: 10
Training loss: 0.9852694272994995
Validation loss: 1.8302158437749392

Epoch: 304| Step: 0
Training loss: 1.7146133184432983
Validation loss: 1.8816710646434496

Epoch: 5| Step: 1
Training loss: 1.6923549175262451
Validation loss: 1.857088932427027

Epoch: 5| Step: 2
Training loss: 1.6105762720108032
Validation loss: 1.8507466290586738

Epoch: 5| Step: 3
Training loss: 1.936671495437622
Validation loss: 1.841019461231847

Epoch: 5| Step: 4
Training loss: 2.0054984092712402
Validation loss: 1.861942773224205

Epoch: 5| Step: 5
Training loss: 1.9839988946914673
Validation loss: 1.8801592203878588

Epoch: 5| Step: 6
Training loss: 1.0870188474655151
Validation loss: 1.843578625750798

Epoch: 5| Step: 7
Training loss: 1.9124796390533447
Validation loss: 1.874883226169053

Epoch: 5| Step: 8
Training loss: 1.5960334539413452
Validation loss: 1.8395192443683583

Epoch: 5| Step: 9
Training loss: 1.0635242462158203
Validation loss: 1.8586009920284312

Epoch: 5| Step: 10
Training loss: 1.7846271991729736
Validation loss: 1.8665370671979842

Epoch: 305| Step: 0
Training loss: 1.656214714050293
Validation loss: 1.8181579010460966

Epoch: 5| Step: 1
Training loss: 1.706080675125122
Validation loss: 1.82775790204284

Epoch: 5| Step: 2
Training loss: 1.6051690578460693
Validation loss: 1.8420451251409387

Epoch: 5| Step: 3
Training loss: 1.9568541049957275
Validation loss: 1.8137404226487683

Epoch: 5| Step: 4
Training loss: 1.9559274911880493
Validation loss: 1.8533585584291847

Epoch: 5| Step: 5
Training loss: 1.4352260828018188
Validation loss: 1.8147130653422365

Epoch: 5| Step: 6
Training loss: 1.5334362983703613
Validation loss: 1.8317736143706946

Epoch: 5| Step: 7
Training loss: 1.8426969051361084
Validation loss: 1.8354263972210627

Epoch: 5| Step: 8
Training loss: 1.546771764755249
Validation loss: 1.8290755569293935

Epoch: 5| Step: 9
Training loss: 1.7904380559921265
Validation loss: 1.8494056168422903

Epoch: 5| Step: 10
Training loss: 1.6850460767745972
Validation loss: 1.8533105952765352

Epoch: 306| Step: 0
Training loss: 2.0794100761413574
Validation loss: 1.8419761375714374

Epoch: 5| Step: 1
Training loss: 1.4725592136383057
Validation loss: 1.8426156146551973

Epoch: 5| Step: 2
Training loss: 1.4913617372512817
Validation loss: 1.8654290245425316

Epoch: 5| Step: 3
Training loss: 2.2526042461395264
Validation loss: 1.8487642452281008

Epoch: 5| Step: 4
Training loss: 1.4785393476486206
Validation loss: 1.8765840991850822

Epoch: 5| Step: 5
Training loss: 1.5524780750274658
Validation loss: 1.8442293533714869

Epoch: 5| Step: 6
Training loss: 1.8813053369522095
Validation loss: 1.8533720918880996

Epoch: 5| Step: 7
Training loss: 1.713810682296753
Validation loss: 1.8831610910354122

Epoch: 5| Step: 8
Training loss: 1.9082252979278564
Validation loss: 1.9042178507774108

Epoch: 5| Step: 9
Training loss: 1.5537246465682983
Validation loss: 1.879871024880358

Epoch: 5| Step: 10
Training loss: 1.253340482711792
Validation loss: 1.8258140599855812

Epoch: 307| Step: 0
Training loss: 1.5639607906341553
Validation loss: 1.8461932764258435

Epoch: 5| Step: 1
Training loss: 1.716296911239624
Validation loss: 1.8563974339474913

Epoch: 5| Step: 2
Training loss: 1.4777003526687622
Validation loss: 1.8097213737426265

Epoch: 5| Step: 3
Training loss: 0.938768744468689
Validation loss: 1.790475332608787

Epoch: 5| Step: 4
Training loss: 1.8990662097930908
Validation loss: 1.8132709200664232

Epoch: 5| Step: 5
Training loss: 1.7196305990219116
Validation loss: 1.845336675643921

Epoch: 5| Step: 6
Training loss: 1.3471543788909912
Validation loss: 1.8247539727918562

Epoch: 5| Step: 7
Training loss: 2.382845401763916
Validation loss: 1.852045730877948

Epoch: 5| Step: 8
Training loss: 1.3928582668304443
Validation loss: 1.8405300635163502

Epoch: 5| Step: 9
Training loss: 1.8964297771453857
Validation loss: 1.863627528631559

Epoch: 5| Step: 10
Training loss: 2.603682041168213
Validation loss: 1.8649601500521424

Epoch: 308| Step: 0
Training loss: 1.208839774131775
Validation loss: 1.825955290948191

Epoch: 5| Step: 1
Training loss: 1.9430019855499268
Validation loss: 1.8400333414795578

Epoch: 5| Step: 2
Training loss: 1.9519128799438477
Validation loss: 1.8586539529984998

Epoch: 5| Step: 3
Training loss: 1.4181829690933228
Validation loss: 1.8390659260493454

Epoch: 5| Step: 4
Training loss: 2.0164268016815186
Validation loss: 1.8475983514580676

Epoch: 5| Step: 5
Training loss: 2.0185203552246094
Validation loss: 1.8807436753344793

Epoch: 5| Step: 6
Training loss: 1.344813585281372
Validation loss: 1.8512086752922303

Epoch: 5| Step: 7
Training loss: 2.046809434890747
Validation loss: 1.889445738125873

Epoch: 5| Step: 8
Training loss: 1.5904731750488281
Validation loss: 1.8030556312171362

Epoch: 5| Step: 9
Training loss: 1.5094058513641357
Validation loss: 1.8346363934137488

Epoch: 5| Step: 10
Training loss: 1.2952258586883545
Validation loss: 1.8473722075903287

Epoch: 309| Step: 0
Training loss: 2.040809154510498
Validation loss: 1.8714553028024652

Epoch: 5| Step: 1
Training loss: 1.6779706478118896
Validation loss: 1.8733648882117322

Epoch: 5| Step: 2
Training loss: 1.5309785604476929
Validation loss: 1.8873416159742622

Epoch: 5| Step: 3
Training loss: 1.9997618198394775
Validation loss: 1.8425129780205347

Epoch: 5| Step: 4
Training loss: 1.1197335720062256
Validation loss: 1.8905006275382092

Epoch: 5| Step: 5
Training loss: 2.049043655395508
Validation loss: 1.8421424229939778

Epoch: 5| Step: 6
Training loss: 1.1954386234283447
Validation loss: 1.8510836337202339

Epoch: 5| Step: 7
Training loss: 1.5851030349731445
Validation loss: 1.8293839372614378

Epoch: 5| Step: 8
Training loss: 1.4467427730560303
Validation loss: 1.8872374385915778

Epoch: 5| Step: 9
Training loss: 2.1046764850616455
Validation loss: 1.8336676525813278

Epoch: 5| Step: 10
Training loss: 1.6597310304641724
Validation loss: 1.854072916892267

Epoch: 310| Step: 0
Training loss: 1.7026021480560303
Validation loss: 1.8599398046411493

Epoch: 5| Step: 1
Training loss: 1.2532145977020264
Validation loss: 1.844679178730134

Epoch: 5| Step: 2
Training loss: 1.8304386138916016
Validation loss: 1.8209271302787207

Epoch: 5| Step: 3
Training loss: 2.0773253440856934
Validation loss: 1.8385852447120092

Epoch: 5| Step: 4
Training loss: 1.452677845954895
Validation loss: 1.8380276259555612

Epoch: 5| Step: 5
Training loss: 1.5903164148330688
Validation loss: 1.8159200978535477

Epoch: 5| Step: 6
Training loss: 1.9768626689910889
Validation loss: 1.844218345098598

Epoch: 5| Step: 7
Training loss: 1.3701488971710205
Validation loss: 1.8586372124251498

Epoch: 5| Step: 8
Training loss: 1.8533656597137451
Validation loss: 1.8567840655644734

Epoch: 5| Step: 9
Training loss: 1.9040868282318115
Validation loss: 1.8210611356201993

Epoch: 5| Step: 10
Training loss: 1.5238150358200073
Validation loss: 1.8653311447430683

Epoch: 311| Step: 0
Training loss: 2.1748948097229004
Validation loss: 1.862545592810518

Epoch: 5| Step: 1
Training loss: 1.3212405443191528
Validation loss: 1.8560950589436356

Epoch: 5| Step: 2
Training loss: 1.9723984003067017
Validation loss: 1.853320344801872

Epoch: 5| Step: 3
Training loss: 1.3849059343338013
Validation loss: 1.8304116674648818

Epoch: 5| Step: 4
Training loss: 0.9328548312187195
Validation loss: 1.84759384329601

Epoch: 5| Step: 5
Training loss: 2.0095207691192627
Validation loss: 1.8208443016134284

Epoch: 5| Step: 6
Training loss: 2.0007271766662598
Validation loss: 1.8425077853664276

Epoch: 5| Step: 7
Training loss: 1.7935184240341187
Validation loss: 1.8372001468494374

Epoch: 5| Step: 8
Training loss: 1.4726049900054932
Validation loss: 1.8571158224536526

Epoch: 5| Step: 9
Training loss: 1.5768002271652222
Validation loss: 1.8632338790483371

Epoch: 5| Step: 10
Training loss: 1.8131414651870728
Validation loss: 1.831304116915631

Epoch: 312| Step: 0
Training loss: 2.4364731311798096
Validation loss: 1.8418919142856394

Epoch: 5| Step: 1
Training loss: 1.4919785261154175
Validation loss: 1.852749950142317

Epoch: 5| Step: 2
Training loss: 1.7039369344711304
Validation loss: 1.8575727516605007

Epoch: 5| Step: 3
Training loss: 1.521286964416504
Validation loss: 1.8543342698004939

Epoch: 5| Step: 4
Training loss: 1.7680648565292358
Validation loss: 1.8576542305689987

Epoch: 5| Step: 5
Training loss: 1.3949791193008423
Validation loss: 1.8265328586742442

Epoch: 5| Step: 6
Training loss: 1.4601547718048096
Validation loss: 1.8775230517951391

Epoch: 5| Step: 7
Training loss: 1.3631333112716675
Validation loss: 1.8537550049443399

Epoch: 5| Step: 8
Training loss: 1.4924038648605347
Validation loss: 1.826784167238461

Epoch: 5| Step: 9
Training loss: 2.254892587661743
Validation loss: 1.8501663900190783

Epoch: 5| Step: 10
Training loss: 1.560578465461731
Validation loss: 1.7966580237111738

Epoch: 313| Step: 0
Training loss: 1.2731691598892212
Validation loss: 1.8527747482381842

Epoch: 5| Step: 1
Training loss: 1.5176045894622803
Validation loss: 1.8212641387857416

Epoch: 5| Step: 2
Training loss: 1.9780353307724
Validation loss: 1.8367010137086273

Epoch: 5| Step: 3
Training loss: 2.0453782081604004
Validation loss: 1.9099658407190794

Epoch: 5| Step: 4
Training loss: 1.5734997987747192
Validation loss: 1.8398732613491755

Epoch: 5| Step: 5
Training loss: 1.8697971105575562
Validation loss: 1.821081643463463

Epoch: 5| Step: 6
Training loss: 1.1826238632202148
Validation loss: 1.8456386314925326

Epoch: 5| Step: 7
Training loss: 1.5582735538482666
Validation loss: 1.8287717655140867

Epoch: 5| Step: 8
Training loss: 1.5671977996826172
Validation loss: 1.8356293529592536

Epoch: 5| Step: 9
Training loss: 1.9996974468231201
Validation loss: 1.8569432548297349

Epoch: 5| Step: 10
Training loss: 1.8117762804031372
Validation loss: 1.8658480157134354

Epoch: 314| Step: 0
Training loss: 1.358231782913208
Validation loss: 1.8432884549581876

Epoch: 5| Step: 1
Training loss: 1.4657588005065918
Validation loss: 1.8368296725775606

Epoch: 5| Step: 2
Training loss: 2.4670581817626953
Validation loss: 1.8490476736458399

Epoch: 5| Step: 3
Training loss: 1.5406825542449951
Validation loss: 1.817102309196226

Epoch: 5| Step: 4
Training loss: 1.5144917964935303
Validation loss: 1.8135622162972727

Epoch: 5| Step: 5
Training loss: 1.3233829736709595
Validation loss: 1.8470540559420021

Epoch: 5| Step: 6
Training loss: 1.7600352764129639
Validation loss: 1.8688793772010392

Epoch: 5| Step: 7
Training loss: 1.5663244724273682
Validation loss: 1.8585708589964016

Epoch: 5| Step: 8
Training loss: 1.926417350769043
Validation loss: 1.8444130061775126

Epoch: 5| Step: 9
Training loss: 1.7683312892913818
Validation loss: 1.8601378676711873

Epoch: 5| Step: 10
Training loss: 1.615828275680542
Validation loss: 1.8591608552522556

Epoch: 315| Step: 0
Training loss: 2.366769790649414
Validation loss: 1.8240977833347936

Epoch: 5| Step: 1
Training loss: 1.4737846851348877
Validation loss: 1.8413164410539853

Epoch: 5| Step: 2
Training loss: 1.2346080541610718
Validation loss: 1.8474273886731876

Epoch: 5| Step: 3
Training loss: 1.8074537515640259
Validation loss: 1.8242100143945346

Epoch: 5| Step: 4
Training loss: 1.675912857055664
Validation loss: 1.8557773354232951

Epoch: 5| Step: 5
Training loss: 1.493585228919983
Validation loss: 1.875313498640573

Epoch: 5| Step: 6
Training loss: 1.636322021484375
Validation loss: 1.8307971608254217

Epoch: 5| Step: 7
Training loss: 1.6496388912200928
Validation loss: 1.8580788066310268

Epoch: 5| Step: 8
Training loss: 1.8210903406143188
Validation loss: 1.8651714235223749

Epoch: 5| Step: 9
Training loss: 1.8495168685913086
Validation loss: 1.8585409592556696

Epoch: 5| Step: 10
Training loss: 1.458567500114441
Validation loss: 1.8413596576259983

Epoch: 316| Step: 0
Training loss: 1.7289988994598389
Validation loss: 1.8632469933520082

Epoch: 5| Step: 1
Training loss: 1.3799265623092651
Validation loss: 1.8625268602883944

Epoch: 5| Step: 2
Training loss: 1.879150152206421
Validation loss: 1.8266247882637927

Epoch: 5| Step: 3
Training loss: 1.453096628189087
Validation loss: 1.8407883157012284

Epoch: 5| Step: 4
Training loss: 1.6693031787872314
Validation loss: 1.836535599923903

Epoch: 5| Step: 5
Training loss: 1.8255081176757812
Validation loss: 1.8302038843913744

Epoch: 5| Step: 6
Training loss: 1.6709626913070679
Validation loss: 1.837332401224362

Epoch: 5| Step: 7
Training loss: 1.8108994960784912
Validation loss: 1.8379053479881697

Epoch: 5| Step: 8
Training loss: 1.6908963918685913
Validation loss: 1.8671844441403624

Epoch: 5| Step: 9
Training loss: 1.6728988885879517
Validation loss: 1.8555482818234352

Epoch: 5| Step: 10
Training loss: 1.527234673500061
Validation loss: 1.8422818901718303

Epoch: 317| Step: 0
Training loss: 2.218390941619873
Validation loss: 1.8504098807611773

Epoch: 5| Step: 1
Training loss: 1.2974575757980347
Validation loss: 1.83356608498481

Epoch: 5| Step: 2
Training loss: 1.379340410232544
Validation loss: 1.84027769232309

Epoch: 5| Step: 3
Training loss: 1.934708595275879
Validation loss: 1.8189749845894434

Epoch: 5| Step: 4
Training loss: 1.923994779586792
Validation loss: 1.8673802216847737

Epoch: 5| Step: 5
Training loss: 1.5000317096710205
Validation loss: 1.8247953717426588

Epoch: 5| Step: 6
Training loss: 1.5904722213745117
Validation loss: 1.8688106703501877

Epoch: 5| Step: 7
Training loss: 1.2050445079803467
Validation loss: 1.8188748551953224

Epoch: 5| Step: 8
Training loss: 1.5880827903747559
Validation loss: 1.8760506568416473

Epoch: 5| Step: 9
Training loss: 2.2609550952911377
Validation loss: 1.854285951583616

Epoch: 5| Step: 10
Training loss: 1.2482762336730957
Validation loss: 1.8462369698350147

Epoch: 318| Step: 0
Training loss: 1.8717578649520874
Validation loss: 1.8421378597136466

Epoch: 5| Step: 1
Training loss: 2.128753662109375
Validation loss: 1.8753337424288514

Epoch: 5| Step: 2
Training loss: 1.199751615524292
Validation loss: 1.8334622229299238

Epoch: 5| Step: 3
Training loss: 1.5541349649429321
Validation loss: 1.839235662132181

Epoch: 5| Step: 4
Training loss: 1.3858973979949951
Validation loss: 1.837085699522367

Epoch: 5| Step: 5
Training loss: 1.4376330375671387
Validation loss: 1.8218930164972942

Epoch: 5| Step: 6
Training loss: 1.491978406906128
Validation loss: 1.8233980594142791

Epoch: 5| Step: 7
Training loss: 1.4656574726104736
Validation loss: 1.8017591853295603

Epoch: 5| Step: 8
Training loss: 1.6503582000732422
Validation loss: 1.8339985121962845

Epoch: 5| Step: 9
Training loss: 2.031632661819458
Validation loss: 1.870898885111655

Epoch: 5| Step: 10
Training loss: 2.0661261081695557
Validation loss: 1.8582800716482184

Epoch: 319| Step: 0
Training loss: 2.590240478515625
Validation loss: 1.8670929708788473

Epoch: 5| Step: 1
Training loss: 2.2186598777770996
Validation loss: 1.8203416973031976

Epoch: 5| Step: 2
Training loss: 1.5388120412826538
Validation loss: 1.8345773040607412

Epoch: 5| Step: 3
Training loss: 1.1810623407363892
Validation loss: 1.8794739989824192

Epoch: 5| Step: 4
Training loss: 1.2510814666748047
Validation loss: 1.8528887302644792

Epoch: 5| Step: 5
Training loss: 1.3768658638000488
Validation loss: 1.8337432133254183

Epoch: 5| Step: 6
Training loss: 1.8917127847671509
Validation loss: 1.8715000370497346

Epoch: 5| Step: 7
Training loss: 1.3657596111297607
Validation loss: 1.8691982479505642

Epoch: 5| Step: 8
Training loss: 1.5053361654281616
Validation loss: 1.874391814713837

Epoch: 5| Step: 9
Training loss: 2.0557544231414795
Validation loss: 1.8635953164869739

Epoch: 5| Step: 10
Training loss: 1.2342538833618164
Validation loss: 1.8615938348154868

Epoch: 320| Step: 0
Training loss: 1.5634281635284424
Validation loss: 1.8312801609757126

Epoch: 5| Step: 1
Training loss: 1.109515905380249
Validation loss: 1.8507062876096336

Epoch: 5| Step: 2
Training loss: 1.8917567729949951
Validation loss: 1.8492799523056194

Epoch: 5| Step: 3
Training loss: 1.8057429790496826
Validation loss: 1.8355017464648011

Epoch: 5| Step: 4
Training loss: 1.990308165550232
Validation loss: 1.864316140451739

Epoch: 5| Step: 5
Training loss: 1.4751099348068237
Validation loss: 1.8300887743632

Epoch: 5| Step: 6
Training loss: 1.7600961923599243
Validation loss: 1.8348593096579275

Epoch: 5| Step: 7
Training loss: 2.2667715549468994
Validation loss: 1.802196438594531

Epoch: 5| Step: 8
Training loss: 1.4776725769042969
Validation loss: 1.8476745672123407

Epoch: 5| Step: 9
Training loss: 1.5441936254501343
Validation loss: 1.8223231325867355

Epoch: 5| Step: 10
Training loss: 1.528219223022461
Validation loss: 1.7844408327533352

Epoch: 321| Step: 0
Training loss: 1.5496032238006592
Validation loss: 1.8121362911757601

Epoch: 5| Step: 1
Training loss: 1.741748571395874
Validation loss: 1.8101437091827393

Epoch: 5| Step: 2
Training loss: 1.3079169988632202
Validation loss: 1.8351861110297583

Epoch: 5| Step: 3
Training loss: 1.6936454772949219
Validation loss: 1.8301856620337373

Epoch: 5| Step: 4
Training loss: 2.038140058517456
Validation loss: 1.8527755570668045

Epoch: 5| Step: 5
Training loss: 1.5731923580169678
Validation loss: 1.8339285568524433

Epoch: 5| Step: 6
Training loss: 1.9203191995620728
Validation loss: 1.845878008873232

Epoch: 5| Step: 7
Training loss: 1.2413123846054077
Validation loss: 1.8833355557534002

Epoch: 5| Step: 8
Training loss: 1.527867317199707
Validation loss: 1.8175387074870448

Epoch: 5| Step: 9
Training loss: 1.6385647058486938
Validation loss: 1.8198008665474512

Epoch: 5| Step: 10
Training loss: 1.74834144115448
Validation loss: 1.817431326835386

Epoch: 322| Step: 0
Training loss: 1.8588091135025024
Validation loss: 1.8586506817930488

Epoch: 5| Step: 1
Training loss: 1.9519962072372437
Validation loss: 1.8726387818654378

Epoch: 5| Step: 2
Training loss: 1.4843858480453491
Validation loss: 1.8472385662858204

Epoch: 5| Step: 3
Training loss: 1.5456736087799072
Validation loss: 1.8706867412854267

Epoch: 5| Step: 4
Training loss: 2.1503238677978516
Validation loss: 1.8312004727701987

Epoch: 5| Step: 5
Training loss: 1.0370314121246338
Validation loss: 1.8551236685886179

Epoch: 5| Step: 6
Training loss: 1.9453680515289307
Validation loss: 1.8586228124557003

Epoch: 5| Step: 7
Training loss: 1.0978310108184814
Validation loss: 1.8202763295942737

Epoch: 5| Step: 8
Training loss: 1.9097970724105835
Validation loss: 1.8540013554275676

Epoch: 5| Step: 9
Training loss: 1.4641201496124268
Validation loss: 1.8602941651498117

Epoch: 5| Step: 10
Training loss: 1.5889109373092651
Validation loss: 1.8453192236602947

Epoch: 323| Step: 0
Training loss: 1.3784539699554443
Validation loss: 1.826362274026358

Epoch: 5| Step: 1
Training loss: 2.0400078296661377
Validation loss: 1.8274951340049825

Epoch: 5| Step: 2
Training loss: 1.063188910484314
Validation loss: 1.8295778145072281

Epoch: 5| Step: 3
Training loss: 1.5907487869262695
Validation loss: 1.8337964832141835

Epoch: 5| Step: 4
Training loss: 1.5234191417694092
Validation loss: 1.8085570053387714

Epoch: 5| Step: 5
Training loss: 1.3094680309295654
Validation loss: 1.8410420340876426

Epoch: 5| Step: 6
Training loss: 1.8115968704223633
Validation loss: 1.7991606343177058

Epoch: 5| Step: 7
Training loss: 1.894727349281311
Validation loss: 1.8546662356263848

Epoch: 5| Step: 8
Training loss: 1.954140067100525
Validation loss: 1.8273551643535655

Epoch: 5| Step: 9
Training loss: 1.6120967864990234
Validation loss: 1.8474022239767096

Epoch: 5| Step: 10
Training loss: 1.9200190305709839
Validation loss: 1.8470528305217784

Epoch: 324| Step: 0
Training loss: 1.8818347454071045
Validation loss: 1.8296886913238033

Epoch: 5| Step: 1
Training loss: 1.9435955286026
Validation loss: 1.8585534749492523

Epoch: 5| Step: 2
Training loss: 1.6385486125946045
Validation loss: 1.8372293364617132

Epoch: 5| Step: 3
Training loss: 1.6707470417022705
Validation loss: 1.8438948033958353

Epoch: 5| Step: 4
Training loss: 1.383819580078125
Validation loss: 1.8599954420520413

Epoch: 5| Step: 5
Training loss: 1.3278405666351318
Validation loss: 1.8617923413553545

Epoch: 5| Step: 6
Training loss: 2.1857547760009766
Validation loss: 1.8725855312039774

Epoch: 5| Step: 7
Training loss: 1.772155523300171
Validation loss: 1.8235834901050856

Epoch: 5| Step: 8
Training loss: 1.4897257089614868
Validation loss: 1.874630589638987

Epoch: 5| Step: 9
Training loss: 1.2723630666732788
Validation loss: 1.8788166815234768

Epoch: 5| Step: 10
Training loss: 1.433356523513794
Validation loss: 1.860706434454969

Epoch: 325| Step: 0
Training loss: 1.6811294555664062
Validation loss: 1.8345748442475514

Epoch: 5| Step: 1
Training loss: 1.743200659751892
Validation loss: 1.8649212339872956

Epoch: 5| Step: 2
Training loss: 1.5248699188232422
Validation loss: 1.8221832411263579

Epoch: 5| Step: 3
Training loss: 1.4507626295089722
Validation loss: 1.7975895238179032

Epoch: 5| Step: 4
Training loss: 1.6684255599975586
Validation loss: 1.8100741999123686

Epoch: 5| Step: 5
Training loss: 1.2816038131713867
Validation loss: 1.849985150880711

Epoch: 5| Step: 6
Training loss: 1.5434355735778809
Validation loss: 1.818401898107221

Epoch: 5| Step: 7
Training loss: 1.943830132484436
Validation loss: 1.7830846822389992

Epoch: 5| Step: 8
Training loss: 1.443289041519165
Validation loss: 1.8276112630803099

Epoch: 5| Step: 9
Training loss: 2.0374109745025635
Validation loss: 1.866448320368285

Epoch: 5| Step: 10
Training loss: 1.488059401512146
Validation loss: 1.8182209666057298

Epoch: 326| Step: 0
Training loss: 1.6345598697662354
Validation loss: 1.7897258240689513

Epoch: 5| Step: 1
Training loss: 1.034867763519287
Validation loss: 1.8263467409277474

Epoch: 5| Step: 2
Training loss: 1.519330382347107
Validation loss: 1.8287630542632072

Epoch: 5| Step: 3
Training loss: 1.7753121852874756
Validation loss: 1.8053833797413816

Epoch: 5| Step: 4
Training loss: 2.3208110332489014
Validation loss: 1.7939203708402571

Epoch: 5| Step: 5
Training loss: 1.6753135919570923
Validation loss: 1.7985311810688307

Epoch: 5| Step: 6
Training loss: 1.8173147439956665
Validation loss: 1.83536954592633

Epoch: 5| Step: 7
Training loss: 2.3044471740722656
Validation loss: 1.8325385406453123

Epoch: 5| Step: 8
Training loss: 0.9420730471611023
Validation loss: 1.8414235384233537

Epoch: 5| Step: 9
Training loss: 1.6122652292251587
Validation loss: 1.8232644578462005

Epoch: 5| Step: 10
Training loss: 1.2632322311401367
Validation loss: 1.8630578671732256

Epoch: 327| Step: 0
Training loss: 1.4568241834640503
Validation loss: 1.8552630024571573

Epoch: 5| Step: 1
Training loss: 1.638746976852417
Validation loss: 1.8308234650601622

Epoch: 5| Step: 2
Training loss: 1.3350427150726318
Validation loss: 1.8219913641611736

Epoch: 5| Step: 3
Training loss: 1.7126556634902954
Validation loss: 1.8284404739256828

Epoch: 5| Step: 4
Training loss: 1.8684085607528687
Validation loss: 1.8410483201344807

Epoch: 5| Step: 5
Training loss: 1.4310117959976196
Validation loss: 1.811210334941905

Epoch: 5| Step: 6
Training loss: 1.7807918787002563
Validation loss: 1.8200715062438801

Epoch: 5| Step: 7
Training loss: 1.4726067781448364
Validation loss: 1.8510455034112419

Epoch: 5| Step: 8
Training loss: 1.648861289024353
Validation loss: 1.8519877156903666

Epoch: 5| Step: 9
Training loss: 2.0462048053741455
Validation loss: 1.85101185306426

Epoch: 5| Step: 10
Training loss: 1.385827660560608
Validation loss: 1.8522571825212049

Epoch: 328| Step: 0
Training loss: 1.7332541942596436
Validation loss: 1.833391579248572

Epoch: 5| Step: 1
Training loss: 1.608655571937561
Validation loss: 1.8312976283411826

Epoch: 5| Step: 2
Training loss: 1.2240006923675537
Validation loss: 1.8784631042070286

Epoch: 5| Step: 3
Training loss: 1.8363544940948486
Validation loss: 1.8451880947236092

Epoch: 5| Step: 4
Training loss: 1.971199631690979
Validation loss: 1.8439468645280408

Epoch: 5| Step: 5
Training loss: 1.1785480976104736
Validation loss: 1.8462096593713249

Epoch: 5| Step: 6
Training loss: 2.127671003341675
Validation loss: 1.8420973118915354

Epoch: 5| Step: 7
Training loss: 1.6769100427627563
Validation loss: 1.809879772124752

Epoch: 5| Step: 8
Training loss: 1.9318574666976929
Validation loss: 1.856314673218676

Epoch: 5| Step: 9
Training loss: 1.3730754852294922
Validation loss: 1.826421223660951

Epoch: 5| Step: 10
Training loss: 0.8666344285011292
Validation loss: 1.8453092754528087

Epoch: 329| Step: 0
Training loss: 1.8780925273895264
Validation loss: 1.8178953893723027

Epoch: 5| Step: 1
Training loss: 1.6309106349945068
Validation loss: 1.8160747276839388

Epoch: 5| Step: 2
Training loss: 1.8085100650787354
Validation loss: 1.8265695264262538

Epoch: 5| Step: 3
Training loss: 1.4975632429122925
Validation loss: 1.8772917998734342

Epoch: 5| Step: 4
Training loss: 1.6602046489715576
Validation loss: 1.8324617801174041

Epoch: 5| Step: 5
Training loss: 1.6881412267684937
Validation loss: 1.813478187848163

Epoch: 5| Step: 6
Training loss: 1.8936790227890015
Validation loss: 1.8473693273400749

Epoch: 5| Step: 7
Training loss: 1.5144354104995728
Validation loss: 1.8061163745900637

Epoch: 5| Step: 8
Training loss: 1.457367181777954
Validation loss: 1.8136089053205264

Epoch: 5| Step: 9
Training loss: 1.3249191045761108
Validation loss: 1.813464714634803

Epoch: 5| Step: 10
Training loss: 1.1726582050323486
Validation loss: 1.845347007115682

Epoch: 330| Step: 0
Training loss: 1.3608629703521729
Validation loss: 1.850070163767825

Epoch: 5| Step: 1
Training loss: 1.919567346572876
Validation loss: 1.7958988194824548

Epoch: 5| Step: 2
Training loss: 1.5002737045288086
Validation loss: 1.8332401962690457

Epoch: 5| Step: 3
Training loss: 1.5781704187393188
Validation loss: 1.8384149048918037

Epoch: 5| Step: 4
Training loss: 1.8256492614746094
Validation loss: 1.8319731694395824

Epoch: 5| Step: 5
Training loss: 1.6772880554199219
Validation loss: 1.8404101133346558

Epoch: 5| Step: 6
Training loss: 1.1262905597686768
Validation loss: 1.7939402954552763

Epoch: 5| Step: 7
Training loss: 2.1429667472839355
Validation loss: 1.8557450117603425

Epoch: 5| Step: 8
Training loss: 1.5223426818847656
Validation loss: 1.8133753743222965

Epoch: 5| Step: 9
Training loss: 1.4228324890136719
Validation loss: 1.8074770307028165

Epoch: 5| Step: 10
Training loss: 1.7884674072265625
Validation loss: 1.839489636882659

Epoch: 331| Step: 0
Training loss: 1.8396718502044678
Validation loss: 1.8304914966706307

Epoch: 5| Step: 1
Training loss: 1.5004621744155884
Validation loss: 1.8487741203718289

Epoch: 5| Step: 2
Training loss: 2.196455240249634
Validation loss: 1.8541249767426522

Epoch: 5| Step: 3
Training loss: 1.7174062728881836
Validation loss: 1.8462739657330256

Epoch: 5| Step: 4
Training loss: 1.5871341228485107
Validation loss: 1.8168159787372877

Epoch: 5| Step: 5
Training loss: 1.2511322498321533
Validation loss: 1.820653869259742

Epoch: 5| Step: 6
Training loss: 1.9618017673492432
Validation loss: 1.836987708204536

Epoch: 5| Step: 7
Training loss: 1.4461867809295654
Validation loss: 1.7795244545064948

Epoch: 5| Step: 8
Training loss: 1.7077062129974365
Validation loss: 1.8451659051320886

Epoch: 5| Step: 9
Training loss: 1.807851791381836
Validation loss: 1.8133762869783627

Epoch: 5| Step: 10
Training loss: 1.039903163909912
Validation loss: 1.8303297027464835

Epoch: 332| Step: 0
Training loss: 1.7171249389648438
Validation loss: 1.8005857993197698

Epoch: 5| Step: 1
Training loss: 1.4598664045333862
Validation loss: 1.8235383072207052

Epoch: 5| Step: 2
Training loss: 1.921514868736267
Validation loss: 1.843098335368659

Epoch: 5| Step: 3
Training loss: 1.8934825658798218
Validation loss: 1.8356440618473997

Epoch: 5| Step: 4
Training loss: 1.5871926546096802
Validation loss: 1.8427432557587982

Epoch: 5| Step: 5
Training loss: 1.097352385520935
Validation loss: 1.8377597255091513

Epoch: 5| Step: 6
Training loss: 1.1849873065948486
Validation loss: 1.8262755858000888

Epoch: 5| Step: 7
Training loss: 1.8671658039093018
Validation loss: 1.8346497166541316

Epoch: 5| Step: 8
Training loss: 1.314104437828064
Validation loss: 1.8308882944045528

Epoch: 5| Step: 9
Training loss: 1.779547095298767
Validation loss: 1.8456801252980386

Epoch: 5| Step: 10
Training loss: 2.022547721862793
Validation loss: 1.8120973199926398

Epoch: 333| Step: 0
Training loss: 2.234611988067627
Validation loss: 1.8390058996856853

Epoch: 5| Step: 1
Training loss: 1.3501982688903809
Validation loss: 1.851921676307596

Epoch: 5| Step: 2
Training loss: 1.7852342128753662
Validation loss: 1.8240829129372873

Epoch: 5| Step: 3
Training loss: 1.3901852369308472
Validation loss: 1.8419503447830037

Epoch: 5| Step: 4
Training loss: 1.355862021446228
Validation loss: 1.8455114774806525

Epoch: 5| Step: 5
Training loss: 1.633988618850708
Validation loss: 1.7852526403242541

Epoch: 5| Step: 6
Training loss: 1.405754804611206
Validation loss: 1.8179759825429609

Epoch: 5| Step: 7
Training loss: 1.417112946510315
Validation loss: 1.8167077777206257

Epoch: 5| Step: 8
Training loss: 1.4930460453033447
Validation loss: 1.8150483587736725

Epoch: 5| Step: 9
Training loss: 1.7497117519378662
Validation loss: 1.8468965112522084

Epoch: 5| Step: 10
Training loss: 1.76947820186615
Validation loss: 1.8424600990869666

Epoch: 334| Step: 0
Training loss: 1.8964046239852905
Validation loss: 1.8232605136850828

Epoch: 5| Step: 1
Training loss: 1.7302354574203491
Validation loss: 1.8475424564012917

Epoch: 5| Step: 2
Training loss: 1.2449076175689697
Validation loss: 1.8704234303966645

Epoch: 5| Step: 3
Training loss: 1.6057367324829102
Validation loss: 1.856248999154696

Epoch: 5| Step: 4
Training loss: 1.699505090713501
Validation loss: 1.8938202883607598

Epoch: 5| Step: 5
Training loss: 1.559950590133667
Validation loss: 1.8599122660134428

Epoch: 5| Step: 6
Training loss: 1.8834031820297241
Validation loss: 1.8645226365776473

Epoch: 5| Step: 7
Training loss: 1.450980305671692
Validation loss: 1.8510948881026237

Epoch: 5| Step: 8
Training loss: 1.585985541343689
Validation loss: 1.8730133195077219

Epoch: 5| Step: 9
Training loss: 1.624694585800171
Validation loss: 1.8583056952363701

Epoch: 5| Step: 10
Training loss: 1.549140214920044
Validation loss: 1.8685036910477506

Epoch: 335| Step: 0
Training loss: 2.2063679695129395
Validation loss: 1.8342257225385277

Epoch: 5| Step: 1
Training loss: 1.3691751956939697
Validation loss: 1.8422396490650792

Epoch: 5| Step: 2
Training loss: 1.0273799896240234
Validation loss: 1.859052958027009

Epoch: 5| Step: 3
Training loss: 1.4904972314834595
Validation loss: 1.8098047535906556

Epoch: 5| Step: 4
Training loss: 1.877305269241333
Validation loss: 1.8064057211722098

Epoch: 5| Step: 5
Training loss: 1.0990777015686035
Validation loss: 1.799469247941048

Epoch: 5| Step: 6
Training loss: 2.1326775550842285
Validation loss: 1.8181399863253358

Epoch: 5| Step: 7
Training loss: 1.6042331457138062
Validation loss: 1.8441721393216042

Epoch: 5| Step: 8
Training loss: 1.5120290517807007
Validation loss: 1.8180464108784993

Epoch: 5| Step: 9
Training loss: 1.3865118026733398
Validation loss: 1.8344965532261839

Epoch: 5| Step: 10
Training loss: 1.9764879941940308
Validation loss: 1.7889142984985023

Epoch: 336| Step: 0
Training loss: 1.7772899866104126
Validation loss: 1.802748304541393

Epoch: 5| Step: 1
Training loss: 1.8128750324249268
Validation loss: 1.8478249888266287

Epoch: 5| Step: 2
Training loss: 1.2724260091781616
Validation loss: 1.823127504317991

Epoch: 5| Step: 3
Training loss: 1.8130594491958618
Validation loss: 1.814317487901257

Epoch: 5| Step: 4
Training loss: 1.345083236694336
Validation loss: 1.8352527797863047

Epoch: 5| Step: 5
Training loss: 0.9696826934814453
Validation loss: 1.848093307146462

Epoch: 5| Step: 6
Training loss: 1.7167530059814453
Validation loss: 1.837998108197284

Epoch: 5| Step: 7
Training loss: 1.3589344024658203
Validation loss: 1.8590608027673536

Epoch: 5| Step: 8
Training loss: 1.7707138061523438
Validation loss: 1.834528725634339

Epoch: 5| Step: 9
Training loss: 1.6713368892669678
Validation loss: 1.8266219528772498

Epoch: 5| Step: 10
Training loss: 2.069589376449585
Validation loss: 1.842959616773872

Epoch: 337| Step: 0
Training loss: 1.6914695501327515
Validation loss: 1.8453593215634745

Epoch: 5| Step: 1
Training loss: 1.7055448293685913
Validation loss: 1.8602888507227744

Epoch: 5| Step: 2
Training loss: 1.4408951997756958
Validation loss: 1.8391176628810104

Epoch: 5| Step: 3
Training loss: 1.387632966041565
Validation loss: 1.854056360901043

Epoch: 5| Step: 4
Training loss: 1.6885004043579102
Validation loss: 1.8183192181330856

Epoch: 5| Step: 5
Training loss: 1.9837344884872437
Validation loss: 1.8159645436912455

Epoch: 5| Step: 6
Training loss: 1.674647569656372
Validation loss: 1.8099334137414091

Epoch: 5| Step: 7
Training loss: 1.8424034118652344
Validation loss: 1.8162146422170824

Epoch: 5| Step: 8
Training loss: 1.2239456176757812
Validation loss: 1.8024303374751922

Epoch: 5| Step: 9
Training loss: 1.4917852878570557
Validation loss: 1.8111091019004903

Epoch: 5| Step: 10
Training loss: 1.3546411991119385
Validation loss: 1.8330029659373785

Epoch: 338| Step: 0
Training loss: 1.781043291091919
Validation loss: 1.8400779962539673

Epoch: 5| Step: 1
Training loss: 1.5479800701141357
Validation loss: 1.8207059098828224

Epoch: 5| Step: 2
Training loss: 1.419650912284851
Validation loss: 1.8562108034728675

Epoch: 5| Step: 3
Training loss: 1.5202417373657227
Validation loss: 1.8597056135054557

Epoch: 5| Step: 4
Training loss: 1.435590147972107
Validation loss: 1.8833307809727167

Epoch: 5| Step: 5
Training loss: 1.2937839031219482
Validation loss: 1.886167808245587

Epoch: 5| Step: 6
Training loss: 1.0501469373703003
Validation loss: 1.89804966603556

Epoch: 5| Step: 7
Training loss: 1.4768844842910767
Validation loss: 1.906146377645513

Epoch: 5| Step: 8
Training loss: 2.19173264503479
Validation loss: 1.8994129216799172

Epoch: 5| Step: 9
Training loss: 2.0964531898498535
Validation loss: 1.8697266142855409

Epoch: 5| Step: 10
Training loss: 1.7316771745681763
Validation loss: 1.843127432689872

Epoch: 339| Step: 0
Training loss: 2.122847080230713
Validation loss: 1.8407329346544

Epoch: 5| Step: 1
Training loss: 1.634293794631958
Validation loss: 1.842994427168241

Epoch: 5| Step: 2
Training loss: 1.2769691944122314
Validation loss: 1.7924596699335242

Epoch: 5| Step: 3
Training loss: 1.518554925918579
Validation loss: 1.8174261482813026

Epoch: 5| Step: 4
Training loss: 1.3802945613861084
Validation loss: 1.7945804262673983

Epoch: 5| Step: 5
Training loss: 1.1615869998931885
Validation loss: 1.8072024237725042

Epoch: 5| Step: 6
Training loss: 2.05883526802063
Validation loss: 1.800119202624085

Epoch: 5| Step: 7
Training loss: 2.193347215652466
Validation loss: 1.819400696344273

Epoch: 5| Step: 8
Training loss: 1.4582183361053467
Validation loss: 1.8083196224704865

Epoch: 5| Step: 9
Training loss: 1.4075686931610107
Validation loss: 1.8257256912928757

Epoch: 5| Step: 10
Training loss: 1.397765040397644
Validation loss: 1.8007768302835443

Epoch: 340| Step: 0
Training loss: 1.675472617149353
Validation loss: 1.8303437412426036

Epoch: 5| Step: 1
Training loss: 1.7368351221084595
Validation loss: 1.8042988251614314

Epoch: 5| Step: 2
Training loss: 1.446244239807129
Validation loss: 1.8192647234086068

Epoch: 5| Step: 3
Training loss: 1.9797779321670532
Validation loss: 1.8184900476086525

Epoch: 5| Step: 4
Training loss: 1.4738630056381226
Validation loss: 1.8543770133808095

Epoch: 5| Step: 5
Training loss: 1.5821455717086792
Validation loss: 1.8208362505000124

Epoch: 5| Step: 6
Training loss: 1.703552007675171
Validation loss: 1.868584276527487

Epoch: 5| Step: 7
Training loss: 1.4510180950164795
Validation loss: 1.8341897277421848

Epoch: 5| Step: 8
Training loss: 1.334588646888733
Validation loss: 1.8117290632699126

Epoch: 5| Step: 9
Training loss: 1.279329776763916
Validation loss: 1.8023315398923812

Epoch: 5| Step: 10
Training loss: 1.6911635398864746
Validation loss: 1.8000082367209977

Epoch: 341| Step: 0
Training loss: 1.5575578212738037
Validation loss: 1.81910849771192

Epoch: 5| Step: 1
Training loss: 1.5770971775054932
Validation loss: 1.821939626047688

Epoch: 5| Step: 2
Training loss: 1.4422457218170166
Validation loss: 1.8889438298440748

Epoch: 5| Step: 3
Training loss: 2.121081590652466
Validation loss: 1.8246015733288181

Epoch: 5| Step: 4
Training loss: 1.2532597780227661
Validation loss: 1.8715013406609977

Epoch: 5| Step: 5
Training loss: 2.279405117034912
Validation loss: 1.8295325733000232

Epoch: 5| Step: 6
Training loss: 1.5146710872650146
Validation loss: 1.8352036194134784

Epoch: 5| Step: 7
Training loss: 1.0892212390899658
Validation loss: 1.865540664683106

Epoch: 5| Step: 8
Training loss: 1.926112413406372
Validation loss: 1.7960523789928806

Epoch: 5| Step: 9
Training loss: 1.1280696392059326
Validation loss: 1.8549089829126995

Epoch: 5| Step: 10
Training loss: 1.6494871377944946
Validation loss: 1.845146845745784

Epoch: 342| Step: 0
Training loss: 1.5563571453094482
Validation loss: 1.7987822127598587

Epoch: 5| Step: 1
Training loss: 1.2249902486801147
Validation loss: 1.8363278168503956

Epoch: 5| Step: 2
Training loss: 1.8181072473526
Validation loss: 1.840693530216012

Epoch: 5| Step: 3
Training loss: 1.2975046634674072
Validation loss: 1.8340443885454567

Epoch: 5| Step: 4
Training loss: 1.494875431060791
Validation loss: 1.8093164915679603

Epoch: 5| Step: 5
Training loss: 2.0082130432128906
Validation loss: 1.8309977785233529

Epoch: 5| Step: 6
Training loss: 1.8770091533660889
Validation loss: 1.7730243462388233

Epoch: 5| Step: 7
Training loss: 1.5449711084365845
Validation loss: 1.8173835815921906

Epoch: 5| Step: 8
Training loss: 1.242889404296875
Validation loss: 1.8328958262679398

Epoch: 5| Step: 9
Training loss: 1.690774917602539
Validation loss: 1.8066042148938743

Epoch: 5| Step: 10
Training loss: 1.518889307975769
Validation loss: 1.7995462494511758

Epoch: 343| Step: 0
Training loss: 1.266851782798767
Validation loss: 1.8193680701717254

Epoch: 5| Step: 1
Training loss: 1.6110742092132568
Validation loss: 1.8141567322515673

Epoch: 5| Step: 2
Training loss: 1.71219801902771
Validation loss: 1.8394498517436366

Epoch: 5| Step: 3
Training loss: 1.471757173538208
Validation loss: 1.7972874308145175

Epoch: 5| Step: 4
Training loss: 1.6196954250335693
Validation loss: 1.7756012024418

Epoch: 5| Step: 5
Training loss: 1.6777961254119873
Validation loss: 1.8132026580072218

Epoch: 5| Step: 6
Training loss: 1.3868579864501953
Validation loss: 1.8279152736868909

Epoch: 5| Step: 7
Training loss: 2.2733500003814697
Validation loss: 1.8437658163809008

Epoch: 5| Step: 8
Training loss: 1.4344314336776733
Validation loss: 1.8407840472395702

Epoch: 5| Step: 9
Training loss: 1.2267810106277466
Validation loss: 1.8503067416529502

Epoch: 5| Step: 10
Training loss: 1.8451226949691772
Validation loss: 1.8462357790239396

Epoch: 344| Step: 0
Training loss: 1.2815091609954834
Validation loss: 1.8157301654097855

Epoch: 5| Step: 1
Training loss: 1.4649107456207275
Validation loss: 1.8535241401323708

Epoch: 5| Step: 2
Training loss: 1.537843942642212
Validation loss: 1.8194341531363867

Epoch: 5| Step: 3
Training loss: 1.4194309711456299
Validation loss: 1.8501183563663113

Epoch: 5| Step: 4
Training loss: 1.7150928974151611
Validation loss: 1.8189332536471787

Epoch: 5| Step: 5
Training loss: 1.9975240230560303
Validation loss: 1.814130102434466

Epoch: 5| Step: 6
Training loss: 1.416603446006775
Validation loss: 1.8190051996579735

Epoch: 5| Step: 7
Training loss: 2.0281052589416504
Validation loss: 1.843988242969718

Epoch: 5| Step: 8
Training loss: 1.3638290166854858
Validation loss: 1.8045774454711585

Epoch: 5| Step: 9
Training loss: 1.8133151531219482
Validation loss: 1.8461607284443353

Epoch: 5| Step: 10
Training loss: 1.0875722169876099
Validation loss: 1.8489982479362077

Epoch: 345| Step: 0
Training loss: 1.7393267154693604
Validation loss: 1.8011901019721903

Epoch: 5| Step: 1
Training loss: 1.1470879316329956
Validation loss: 1.8568543900725663

Epoch: 5| Step: 2
Training loss: 1.5982582569122314
Validation loss: 1.8050090394994265

Epoch: 5| Step: 3
Training loss: 1.1389636993408203
Validation loss: 1.8130738991563038

Epoch: 5| Step: 4
Training loss: 1.5966589450836182
Validation loss: 1.8124639000943912

Epoch: 5| Step: 5
Training loss: 1.4193520545959473
Validation loss: 1.8028190289774249

Epoch: 5| Step: 6
Training loss: 1.93173348903656
Validation loss: 1.8007317140538206

Epoch: 5| Step: 7
Training loss: 1.2647424936294556
Validation loss: 1.8448746294103644

Epoch: 5| Step: 8
Training loss: 1.6600608825683594
Validation loss: 1.8403127206269132

Epoch: 5| Step: 9
Training loss: 1.5780515670776367
Validation loss: 1.8463376158027238

Epoch: 5| Step: 10
Training loss: 2.0630619525909424
Validation loss: 1.8329097250456452

Epoch: 346| Step: 0
Training loss: 1.9135448932647705
Validation loss: 1.8291104839694114

Epoch: 5| Step: 1
Training loss: 1.4501869678497314
Validation loss: 1.840255118185474

Epoch: 5| Step: 2
Training loss: 1.7043018341064453
Validation loss: 1.8394399112270725

Epoch: 5| Step: 3
Training loss: 1.8544689416885376
Validation loss: 1.8557456052431496

Epoch: 5| Step: 4
Training loss: 1.334050178527832
Validation loss: 1.8661451185903242

Epoch: 5| Step: 5
Training loss: 2.218653440475464
Validation loss: 1.8229839289060203

Epoch: 5| Step: 6
Training loss: 1.6636549234390259
Validation loss: 1.7936300936565603

Epoch: 5| Step: 7
Training loss: 1.2783149480819702
Validation loss: 1.8564873985064927

Epoch: 5| Step: 8
Training loss: 1.382880449295044
Validation loss: 1.8530294279898367

Epoch: 5| Step: 9
Training loss: 1.1867433786392212
Validation loss: 1.8369628960086453

Epoch: 5| Step: 10
Training loss: 1.260787010192871
Validation loss: 1.829624827190112

Epoch: 347| Step: 0
Training loss: 1.2998627424240112
Validation loss: 1.809438064534177

Epoch: 5| Step: 1
Training loss: 1.2913774251937866
Validation loss: 1.8669412648806007

Epoch: 5| Step: 2
Training loss: 1.6222785711288452
Validation loss: 1.8425605758543937

Epoch: 5| Step: 3
Training loss: 1.5365865230560303
Validation loss: 1.8286088666608256

Epoch: 5| Step: 4
Training loss: 1.6702091693878174
Validation loss: 1.8064388472546813

Epoch: 5| Step: 5
Training loss: 2.476417064666748
Validation loss: 1.824898322423299

Epoch: 5| Step: 6
Training loss: 1.2439072132110596
Validation loss: 1.7930476486041982

Epoch: 5| Step: 7
Training loss: 2.0042147636413574
Validation loss: 1.818999316102715

Epoch: 5| Step: 8
Training loss: 1.5600529909133911
Validation loss: 1.7796659328604256

Epoch: 5| Step: 9
Training loss: 1.2489800453186035
Validation loss: 1.8046755944528887

Epoch: 5| Step: 10
Training loss: 1.3922308683395386
Validation loss: 1.7797274589538574

Epoch: 348| Step: 0
Training loss: 2.034182071685791
Validation loss: 1.82733658564988

Epoch: 5| Step: 1
Training loss: 1.3340356349945068
Validation loss: 1.8444208355360134

Epoch: 5| Step: 2
Training loss: 2.5173346996307373
Validation loss: 1.8135183383059759

Epoch: 5| Step: 3
Training loss: 1.3545141220092773
Validation loss: 1.8394416416845014

Epoch: 5| Step: 4
Training loss: 1.1888409852981567
Validation loss: 1.8583835401842672

Epoch: 5| Step: 5
Training loss: 1.600481629371643
Validation loss: 1.832555006909114

Epoch: 5| Step: 6
Training loss: 1.481350064277649
Validation loss: 1.8344500000758837

Epoch: 5| Step: 7
Training loss: 1.3605117797851562
Validation loss: 1.8255396504555979

Epoch: 5| Step: 8
Training loss: 1.7140960693359375
Validation loss: 1.8066512576995357

Epoch: 5| Step: 9
Training loss: 1.9789104461669922
Validation loss: 1.8123472018908429

Epoch: 5| Step: 10
Training loss: 0.7918447256088257
Validation loss: 1.7835832590697913

Epoch: 349| Step: 0
Training loss: 1.4845876693725586
Validation loss: 1.8054678158093524

Epoch: 5| Step: 1
Training loss: 1.8913787603378296
Validation loss: 1.8415196723835443

Epoch: 5| Step: 2
Training loss: 1.4029842615127563
Validation loss: 1.8482993392534153

Epoch: 5| Step: 3
Training loss: 1.8946056365966797
Validation loss: 1.7956084589804373

Epoch: 5| Step: 4
Training loss: 1.4725573062896729
Validation loss: 1.8164817287075905

Epoch: 5| Step: 5
Training loss: 1.5054610967636108
Validation loss: 1.8090109748225058

Epoch: 5| Step: 6
Training loss: 1.7221943140029907
Validation loss: 1.8096671950432561

Epoch: 5| Step: 7
Training loss: 1.4228140115737915
Validation loss: 1.824094928720946

Epoch: 5| Step: 8
Training loss: 1.3135626316070557
Validation loss: 1.8181936151237899

Epoch: 5| Step: 9
Training loss: 1.8035564422607422
Validation loss: 1.8325282924918718

Epoch: 5| Step: 10
Training loss: 1.087130069732666
Validation loss: 1.8696987039299422

Epoch: 350| Step: 0
Training loss: 1.105218768119812
Validation loss: 1.7769082771834506

Epoch: 5| Step: 1
Training loss: 1.183692216873169
Validation loss: 1.8184595313123477

Epoch: 5| Step: 2
Training loss: 2.115978717803955
Validation loss: 1.8393843097071494

Epoch: 5| Step: 3
Training loss: 1.5415681600570679
Validation loss: 1.824029698166796

Epoch: 5| Step: 4
Training loss: 2.1808724403381348
Validation loss: 1.8368334488202167

Epoch: 5| Step: 5
Training loss: 1.6945266723632812
Validation loss: 1.8011583423101774

Epoch: 5| Step: 6
Training loss: 1.7654054164886475
Validation loss: 1.8257725290072861

Epoch: 5| Step: 7
Training loss: 1.1845786571502686
Validation loss: 1.8094487754247521

Epoch: 5| Step: 8
Training loss: 1.2041733264923096
Validation loss: 1.8199119721689532

Epoch: 5| Step: 9
Training loss: 1.792527437210083
Validation loss: 1.835560384617057

Epoch: 5| Step: 10
Training loss: 1.5764532089233398
Validation loss: 1.8321783318314502

Epoch: 351| Step: 0
Training loss: 1.362714171409607
Validation loss: 1.7992240690415906

Epoch: 5| Step: 1
Training loss: 1.8970849514007568
Validation loss: 1.8215232203083653

Epoch: 5| Step: 2
Training loss: 1.3242542743682861
Validation loss: 1.79431914770475

Epoch: 5| Step: 3
Training loss: 1.6239897012710571
Validation loss: 1.8003180860191264

Epoch: 5| Step: 4
Training loss: 1.7840715646743774
Validation loss: 1.8348435368589175

Epoch: 5| Step: 5
Training loss: 1.3765857219696045
Validation loss: 1.7912833152278778

Epoch: 5| Step: 6
Training loss: 1.1904737949371338
Validation loss: 1.8414929682208645

Epoch: 5| Step: 7
Training loss: 1.7337520122528076
Validation loss: 1.817089291029079

Epoch: 5| Step: 8
Training loss: 1.6717102527618408
Validation loss: 1.787665327390035

Epoch: 5| Step: 9
Training loss: 1.9169092178344727
Validation loss: 1.829217141674411

Epoch: 5| Step: 10
Training loss: 1.2550290822982788
Validation loss: 1.82519285140499

Epoch: 352| Step: 0
Training loss: 1.2216743230819702
Validation loss: 1.8179392583908573

Epoch: 5| Step: 1
Training loss: 1.5037437677383423
Validation loss: 1.8201428369809223

Epoch: 5| Step: 2
Training loss: 1.3268470764160156
Validation loss: 1.8223596747203539

Epoch: 5| Step: 3
Training loss: 1.4140715599060059
Validation loss: 1.8310310020241687

Epoch: 5| Step: 4
Training loss: 1.6231749057769775
Validation loss: 1.845339702021691

Epoch: 5| Step: 5
Training loss: 1.3026999235153198
Validation loss: 1.8228212556531351

Epoch: 5| Step: 6
Training loss: 1.4392855167388916
Validation loss: 1.8100245050204697

Epoch: 5| Step: 7
Training loss: 1.9307422637939453
Validation loss: 1.834158533362932

Epoch: 5| Step: 8
Training loss: 1.7358137369155884
Validation loss: 1.8521022360811952

Epoch: 5| Step: 9
Training loss: 1.8033987283706665
Validation loss: 1.8172623303628737

Epoch: 5| Step: 10
Training loss: 1.6383662223815918
Validation loss: 1.818245272482595

Epoch: 353| Step: 0
Training loss: 1.5687720775604248
Validation loss: 1.8089492244105185

Epoch: 5| Step: 1
Training loss: 1.4082224369049072
Validation loss: 1.8193573644084315

Epoch: 5| Step: 2
Training loss: 1.208184003829956
Validation loss: 1.8119101908899122

Epoch: 5| Step: 3
Training loss: 1.9964282512664795
Validation loss: 1.8321697250489266

Epoch: 5| Step: 4
Training loss: 1.2699649333953857
Validation loss: 1.8303136466651835

Epoch: 5| Step: 5
Training loss: 1.6795037984848022
Validation loss: 1.8014022163165513

Epoch: 5| Step: 6
Training loss: 1.180020809173584
Validation loss: 1.7845436065427718

Epoch: 5| Step: 7
Training loss: 1.766217589378357
Validation loss: 1.822604343455325

Epoch: 5| Step: 8
Training loss: 1.5227152109146118
Validation loss: 1.797474593244573

Epoch: 5| Step: 9
Training loss: 1.7642666101455688
Validation loss: 1.8005184973439863

Epoch: 5| Step: 10
Training loss: 1.6282731294631958
Validation loss: 1.8131341190748318

Epoch: 354| Step: 0
Training loss: 1.0503007173538208
Validation loss: 1.7968964281902517

Epoch: 5| Step: 1
Training loss: 1.5279039144515991
Validation loss: 1.7864728845575804

Epoch: 5| Step: 2
Training loss: 1.7142750024795532
Validation loss: 1.7720544363862725

Epoch: 5| Step: 3
Training loss: 1.0930330753326416
Validation loss: 1.8535643674994027

Epoch: 5| Step: 4
Training loss: 1.8782432079315186
Validation loss: 1.7819891847589964

Epoch: 5| Step: 5
Training loss: 1.77325439453125
Validation loss: 1.8336049279858988

Epoch: 5| Step: 6
Training loss: 2.00024676322937
Validation loss: 1.7828988900748632

Epoch: 5| Step: 7
Training loss: 1.558042287826538
Validation loss: 1.8271887212671258

Epoch: 5| Step: 8
Training loss: 1.5802350044250488
Validation loss: 1.8231535765432543

Epoch: 5| Step: 9
Training loss: 1.1465407609939575
Validation loss: 1.810865448367211

Epoch: 5| Step: 10
Training loss: 1.5365400314331055
Validation loss: 1.842756748199463

Epoch: 355| Step: 0
Training loss: 1.2934882640838623
Validation loss: 1.8019466028418591

Epoch: 5| Step: 1
Training loss: 1.5420242547988892
Validation loss: 1.7883337646402337

Epoch: 5| Step: 2
Training loss: 1.0566346645355225
Validation loss: 1.8446568353201753

Epoch: 5| Step: 3
Training loss: 1.8545868396759033
Validation loss: 1.8538019554589384

Epoch: 5| Step: 4
Training loss: 2.035810947418213
Validation loss: 1.8085432411521993

Epoch: 5| Step: 5
Training loss: 1.687605619430542
Validation loss: 1.790817605551853

Epoch: 5| Step: 6
Training loss: 1.4975603818893433
Validation loss: 1.7896386564418834

Epoch: 5| Step: 7
Training loss: 1.6195749044418335
Validation loss: 1.833317450297776

Epoch: 5| Step: 8
Training loss: 1.6324701309204102
Validation loss: 1.777193933404902

Epoch: 5| Step: 9
Training loss: 1.1374447345733643
Validation loss: 1.7943907194240118

Epoch: 5| Step: 10
Training loss: 1.5869760513305664
Validation loss: 1.8322675176846084

Epoch: 356| Step: 0
Training loss: 1.2336134910583496
Validation loss: 1.80059608720964

Epoch: 5| Step: 1
Training loss: 1.2508536577224731
Validation loss: 1.804558179711783

Epoch: 5| Step: 2
Training loss: 1.4490869045257568
Validation loss: 1.8331511712843371

Epoch: 5| Step: 3
Training loss: 2.164846658706665
Validation loss: 1.8325188198397238

Epoch: 5| Step: 4
Training loss: 1.8374216556549072
Validation loss: 1.8548261811656337

Epoch: 5| Step: 5
Training loss: 1.5452468395233154
Validation loss: 1.8583653844812864

Epoch: 5| Step: 6
Training loss: 1.5275049209594727
Validation loss: 1.7957494002516552

Epoch: 5| Step: 7
Training loss: 1.7553962469100952
Validation loss: 1.826877688848844

Epoch: 5| Step: 8
Training loss: 1.8957370519638062
Validation loss: 1.8304534048162482

Epoch: 5| Step: 9
Training loss: 1.1600762605667114
Validation loss: 1.8765789847220145

Epoch: 5| Step: 10
Training loss: 0.9863799810409546
Validation loss: 1.8343052094982517

Epoch: 357| Step: 0
Training loss: 1.170100212097168
Validation loss: 1.8198706052636588

Epoch: 5| Step: 1
Training loss: 1.216994285583496
Validation loss: 1.858752433971692

Epoch: 5| Step: 2
Training loss: 1.8732879161834717
Validation loss: 1.7838853610459195

Epoch: 5| Step: 3
Training loss: 1.3803430795669556
Validation loss: 1.8378226731413154

Epoch: 5| Step: 4
Training loss: 1.6699756383895874
Validation loss: 1.8067777041466004

Epoch: 5| Step: 5
Training loss: 1.497104287147522
Validation loss: 1.7800691435413976

Epoch: 5| Step: 6
Training loss: 2.1306004524230957
Validation loss: 1.7863618776362429

Epoch: 5| Step: 7
Training loss: 1.6806297302246094
Validation loss: 1.786117503719945

Epoch: 5| Step: 8
Training loss: 1.3622852563858032
Validation loss: 1.751477244079754

Epoch: 5| Step: 9
Training loss: 0.9752625226974487
Validation loss: 1.834830133504765

Epoch: 5| Step: 10
Training loss: 1.675502896308899
Validation loss: 1.7898339340763707

Epoch: 358| Step: 0
Training loss: 1.4340860843658447
Validation loss: 1.787071084463468

Epoch: 5| Step: 1
Training loss: 1.2891499996185303
Validation loss: 1.83689131018936

Epoch: 5| Step: 2
Training loss: 1.5245873928070068
Validation loss: 1.81238648199266

Epoch: 5| Step: 3
Training loss: 1.8228238821029663
Validation loss: 1.8233428680768577

Epoch: 5| Step: 4
Training loss: 1.7890040874481201
Validation loss: 1.8302500363319152

Epoch: 5| Step: 5
Training loss: 1.4677960872650146
Validation loss: 1.8604873752081266

Epoch: 5| Step: 6
Training loss: 1.3582655191421509
Validation loss: 1.8476617900274133

Epoch: 5| Step: 7
Training loss: 1.3854329586029053
Validation loss: 1.7746523708425543

Epoch: 5| Step: 8
Training loss: 1.4286785125732422
Validation loss: 1.827672948119461

Epoch: 5| Step: 9
Training loss: 1.7273041009902954
Validation loss: 1.8276241453745032

Epoch: 5| Step: 10
Training loss: 1.7072527408599854
Validation loss: 1.8262084017517746

Epoch: 359| Step: 0
Training loss: 0.9343298077583313
Validation loss: 1.8430904752464705

Epoch: 5| Step: 1
Training loss: 1.5216000080108643
Validation loss: 1.826908362809048

Epoch: 5| Step: 2
Training loss: 1.6365444660186768
Validation loss: 1.8772847985708585

Epoch: 5| Step: 3
Training loss: 1.8227113485336304
Validation loss: 1.8369188283079414

Epoch: 5| Step: 4
Training loss: 1.493618369102478
Validation loss: 1.8264486379520868

Epoch: 5| Step: 5
Training loss: 1.8341381549835205
Validation loss: 1.8598706286440614

Epoch: 5| Step: 6
Training loss: 1.1536850929260254
Validation loss: 1.8066157987040858

Epoch: 5| Step: 7
Training loss: 1.5461660623550415
Validation loss: 1.8053360344261251

Epoch: 5| Step: 8
Training loss: 1.3436682224273682
Validation loss: 1.807119249015726

Epoch: 5| Step: 9
Training loss: 1.310509204864502
Validation loss: 1.8344281950304586

Epoch: 5| Step: 10
Training loss: 2.367002487182617
Validation loss: 1.8046036304966095

Epoch: 360| Step: 0
Training loss: 1.8353652954101562
Validation loss: 1.7998055117104643

Epoch: 5| Step: 1
Training loss: 0.8469291925430298
Validation loss: 1.814184122188117

Epoch: 5| Step: 2
Training loss: 1.6418691873550415
Validation loss: 1.8115110140974804

Epoch: 5| Step: 3
Training loss: 1.5390493869781494
Validation loss: 1.8174843121600408

Epoch: 5| Step: 4
Training loss: 1.9297844171524048
Validation loss: 1.8248012040251045

Epoch: 5| Step: 5
Training loss: 1.5597083568572998
Validation loss: 1.770754878238965

Epoch: 5| Step: 6
Training loss: 0.9685994386672974
Validation loss: 1.814290032591871

Epoch: 5| Step: 7
Training loss: 1.4104512929916382
Validation loss: 1.822440206363637

Epoch: 5| Step: 8
Training loss: 1.7421470880508423
Validation loss: 1.7932283827053603

Epoch: 5| Step: 9
Training loss: 1.430237889289856
Validation loss: 1.7868220754849014

Epoch: 5| Step: 10
Training loss: 1.8967992067337036
Validation loss: 1.812546448041034

Epoch: 361| Step: 0
Training loss: 1.117978811264038
Validation loss: 1.8424722494617585

Epoch: 5| Step: 1
Training loss: 1.4405653476715088
Validation loss: 1.8219159546718802

Epoch: 5| Step: 2
Training loss: 1.5526158809661865
Validation loss: 1.80258136410867

Epoch: 5| Step: 3
Training loss: 1.847436547279358
Validation loss: 1.8542013552881056

Epoch: 5| Step: 4
Training loss: 1.5111335515975952
Validation loss: 1.808249960663498

Epoch: 5| Step: 5
Training loss: 1.6671969890594482
Validation loss: 1.8626335705480268

Epoch: 5| Step: 6
Training loss: 1.3718461990356445
Validation loss: 1.8110885363753124

Epoch: 5| Step: 7
Training loss: 1.527316689491272
Validation loss: 1.8034342886299215

Epoch: 5| Step: 8
Training loss: 1.0639320611953735
Validation loss: 1.8307973518166492

Epoch: 5| Step: 9
Training loss: 1.80362069606781
Validation loss: 1.8219533556251115

Epoch: 5| Step: 10
Training loss: 1.591639518737793
Validation loss: 1.864218872080567

Epoch: 362| Step: 0
Training loss: 1.3961759805679321
Validation loss: 1.8470612110630158

Epoch: 5| Step: 1
Training loss: 1.5820338726043701
Validation loss: 1.8042061867252472

Epoch: 5| Step: 2
Training loss: 1.4948170185089111
Validation loss: 1.8323024383155249

Epoch: 5| Step: 3
Training loss: 2.042600154876709
Validation loss: 1.7896070057345974

Epoch: 5| Step: 4
Training loss: 1.5659193992614746
Validation loss: 1.8194944576550556

Epoch: 5| Step: 5
Training loss: 1.5319693088531494
Validation loss: 1.8457857011466898

Epoch: 5| Step: 6
Training loss: 1.2716271877288818
Validation loss: 1.8081037639289774

Epoch: 5| Step: 7
Training loss: 1.2726328372955322
Validation loss: 1.8355413188216507

Epoch: 5| Step: 8
Training loss: 1.4764316082000732
Validation loss: 1.7870138255498742

Epoch: 5| Step: 9
Training loss: 1.9361801147460938
Validation loss: 1.789928961825627

Epoch: 5| Step: 10
Training loss: 1.4368051290512085
Validation loss: 1.7903810393425725

Epoch: 363| Step: 0
Training loss: 1.569709062576294
Validation loss: 1.7932744154366114

Epoch: 5| Step: 1
Training loss: 1.5582468509674072
Validation loss: 1.7758846462413829

Epoch: 5| Step: 2
Training loss: 1.8805805444717407
Validation loss: 1.8562406263043802

Epoch: 5| Step: 3
Training loss: 1.462473750114441
Validation loss: 1.8543265352966964

Epoch: 5| Step: 4
Training loss: 1.322016954421997
Validation loss: 1.8156188636697748

Epoch: 5| Step: 5
Training loss: 1.5104793310165405
Validation loss: 1.8462214867273967

Epoch: 5| Step: 6
Training loss: 1.4530651569366455
Validation loss: 1.7575905169210126

Epoch: 5| Step: 7
Training loss: 1.265094518661499
Validation loss: 1.8159258416903916

Epoch: 5| Step: 8
Training loss: 1.3160796165466309
Validation loss: 1.8296369685921618

Epoch: 5| Step: 9
Training loss: 1.4464318752288818
Validation loss: 1.8497941609351867

Epoch: 5| Step: 10
Training loss: 2.173691511154175
Validation loss: 1.8310081343497

Epoch: 364| Step: 0
Training loss: 1.0017238855361938
Validation loss: 1.8262581338164627

Epoch: 5| Step: 1
Training loss: 1.401609182357788
Validation loss: 1.8265912084169285

Epoch: 5| Step: 2
Training loss: 1.9107344150543213
Validation loss: 1.8331642291879142

Epoch: 5| Step: 3
Training loss: 1.0769742727279663
Validation loss: 1.8666678436340824

Epoch: 5| Step: 4
Training loss: 1.2407602071762085
Validation loss: 1.89173178134426

Epoch: 5| Step: 5
Training loss: 1.2167762517929077
Validation loss: 1.8756147007788382

Epoch: 5| Step: 6
Training loss: 1.8993752002716064
Validation loss: 1.863360280631691

Epoch: 5| Step: 7
Training loss: 2.108313798904419
Validation loss: 1.8723873041009391

Epoch: 5| Step: 8
Training loss: 1.369300127029419
Validation loss: 1.816550524004044

Epoch: 5| Step: 9
Training loss: 2.0779452323913574
Validation loss: 1.8162787716875795

Epoch: 5| Step: 10
Training loss: 1.1761878728866577
Validation loss: 1.7720849501189364

Epoch: 365| Step: 0
Training loss: 1.6538101434707642
Validation loss: 1.7668762847941408

Epoch: 5| Step: 1
Training loss: 1.4712278842926025
Validation loss: 1.8124528443941506

Epoch: 5| Step: 2
Training loss: 1.1195347309112549
Validation loss: 1.844838575650287

Epoch: 5| Step: 3
Training loss: 1.245917558670044
Validation loss: 1.8001127422496837

Epoch: 5| Step: 4
Training loss: 1.1328494548797607
Validation loss: 1.8139324957324612

Epoch: 5| Step: 5
Training loss: 1.8020846843719482
Validation loss: 1.7828931462380193

Epoch: 5| Step: 6
Training loss: 1.7076146602630615
Validation loss: 1.8222507456297516

Epoch: 5| Step: 7
Training loss: 1.5186772346496582
Validation loss: 1.7756833440514022

Epoch: 5| Step: 8
Training loss: 1.8370895385742188
Validation loss: 1.8320508580054007

Epoch: 5| Step: 9
Training loss: 1.7150561809539795
Validation loss: 1.7545976972067228

Epoch: 5| Step: 10
Training loss: 1.2743901014328003
Validation loss: 1.7854305223752094

Epoch: 366| Step: 0
Training loss: 1.0409247875213623
Validation loss: 1.7911515312810098

Epoch: 5| Step: 1
Training loss: 1.458112359046936
Validation loss: 1.7771703620110788

Epoch: 5| Step: 2
Training loss: 1.365673542022705
Validation loss: 1.8280610922844178

Epoch: 5| Step: 3
Training loss: 1.2346259355545044
Validation loss: 1.7918632158669092

Epoch: 5| Step: 4
Training loss: 1.8663301467895508
Validation loss: 1.8268249855246594

Epoch: 5| Step: 5
Training loss: 1.0613563060760498
Validation loss: 1.8177447216485136

Epoch: 5| Step: 6
Training loss: 1.2631494998931885
Validation loss: 1.798227160207687

Epoch: 5| Step: 7
Training loss: 1.9845565557479858
Validation loss: 1.8140699889070244

Epoch: 5| Step: 8
Training loss: 1.6906465291976929
Validation loss: 1.847918072054463

Epoch: 5| Step: 9
Training loss: 1.804534673690796
Validation loss: 1.8186678694140526

Epoch: 5| Step: 10
Training loss: 1.3441507816314697
Validation loss: 1.7522113143756826

Epoch: 367| Step: 0
Training loss: 1.9339075088500977
Validation loss: 1.8407145084873322

Epoch: 5| Step: 1
Training loss: 0.975601077079773
Validation loss: 1.8117566185612832

Epoch: 5| Step: 2
Training loss: 1.6927982568740845
Validation loss: 1.789130832559319

Epoch: 5| Step: 3
Training loss: 1.2231906652450562
Validation loss: 1.7985355290033485

Epoch: 5| Step: 4
Training loss: 1.3773486614227295
Validation loss: 1.8174258406444261

Epoch: 5| Step: 5
Training loss: 1.5561436414718628
Validation loss: 1.8009207210233134

Epoch: 5| Step: 6
Training loss: 1.4003589153289795
Validation loss: 1.8053628988163446

Epoch: 5| Step: 7
Training loss: 1.3703923225402832
Validation loss: 1.8274498972841489

Epoch: 5| Step: 8
Training loss: 1.3975415229797363
Validation loss: 1.8152371080972816

Epoch: 5| Step: 9
Training loss: 2.202683210372925
Validation loss: 1.804388548738213

Epoch: 5| Step: 10
Training loss: 1.417046308517456
Validation loss: 1.8445668797339163

Epoch: 368| Step: 0
Training loss: 1.2410669326782227
Validation loss: 1.7747953373898742

Epoch: 5| Step: 1
Training loss: 1.615944504737854
Validation loss: 1.8247806026089577

Epoch: 5| Step: 2
Training loss: 1.2420542240142822
Validation loss: 1.8033759568327217

Epoch: 5| Step: 3
Training loss: 1.935032606124878
Validation loss: 1.8212802205034482

Epoch: 5| Step: 4
Training loss: 1.0018826723098755
Validation loss: 1.8510734188941218

Epoch: 5| Step: 5
Training loss: 1.0982967615127563
Validation loss: 1.7813820531291347

Epoch: 5| Step: 6
Training loss: 1.101254940032959
Validation loss: 1.849104291649275

Epoch: 5| Step: 7
Training loss: 1.9646072387695312
Validation loss: 1.8276181528645177

Epoch: 5| Step: 8
Training loss: 1.5920588970184326
Validation loss: 1.8412752305307696

Epoch: 5| Step: 9
Training loss: 1.5359117984771729
Validation loss: 1.8276046104328607

Epoch: 5| Step: 10
Training loss: 2.290335178375244
Validation loss: 1.817067987175398

Epoch: 369| Step: 0
Training loss: 1.835505723953247
Validation loss: 1.8176150693688342

Epoch: 5| Step: 1
Training loss: 1.6793311834335327
Validation loss: 1.8264422109050136

Epoch: 5| Step: 2
Training loss: 1.6703052520751953
Validation loss: 1.8481584261822444

Epoch: 5| Step: 3
Training loss: 1.395064115524292
Validation loss: 1.7880433374835598

Epoch: 5| Step: 4
Training loss: 1.0536468029022217
Validation loss: 1.8209797541300456

Epoch: 5| Step: 5
Training loss: 1.3626264333724976
Validation loss: 1.8187675110755428

Epoch: 5| Step: 6
Training loss: 1.503709316253662
Validation loss: 1.782431214086471

Epoch: 5| Step: 7
Training loss: 1.537434697151184
Validation loss: 1.8330929586964269

Epoch: 5| Step: 8
Training loss: 1.4451652765274048
Validation loss: 1.814170745111281

Epoch: 5| Step: 9
Training loss: 1.478521466255188
Validation loss: 1.8282232681910198

Epoch: 5| Step: 10
Training loss: 1.6312497854232788
Validation loss: 1.82539757990068

Epoch: 370| Step: 0
Training loss: 1.2997543811798096
Validation loss: 1.8020991958597654

Epoch: 5| Step: 1
Training loss: 1.9554628133773804
Validation loss: 1.7908915024931713

Epoch: 5| Step: 2
Training loss: 1.56659734249115
Validation loss: 1.847755321892359

Epoch: 5| Step: 3
Training loss: 1.3115746974945068
Validation loss: 1.7750814730121243

Epoch: 5| Step: 4
Training loss: 1.3053611516952515
Validation loss: 1.8009259482865692

Epoch: 5| Step: 5
Training loss: 1.4273213148117065
Validation loss: 1.8141257506544872

Epoch: 5| Step: 6
Training loss: 1.7108867168426514
Validation loss: 1.8071656534748692

Epoch: 5| Step: 7
Training loss: 1.109541893005371
Validation loss: 1.7795327184020833

Epoch: 5| Step: 8
Training loss: 1.4180601835250854
Validation loss: 1.789437742643459

Epoch: 5| Step: 9
Training loss: 1.5345408916473389
Validation loss: 1.7877889371687365

Epoch: 5| Step: 10
Training loss: 2.061868667602539
Validation loss: 1.802862782632151

Epoch: 371| Step: 0
Training loss: 1.183645486831665
Validation loss: 1.8161769079905685

Epoch: 5| Step: 1
Training loss: 1.0641504526138306
Validation loss: 1.8063080900458879

Epoch: 5| Step: 2
Training loss: 1.5801527500152588
Validation loss: 1.794281090459516

Epoch: 5| Step: 3
Training loss: 1.272918462753296
Validation loss: 1.8347125476406467

Epoch: 5| Step: 4
Training loss: 2.4995689392089844
Validation loss: 1.8378315817925237

Epoch: 5| Step: 5
Training loss: 1.667340874671936
Validation loss: 1.8379827071261663

Epoch: 5| Step: 6
Training loss: 1.4381392002105713
Validation loss: 1.8239574714373517

Epoch: 5| Step: 7
Training loss: 1.3993412256240845
Validation loss: 1.8380303139327674

Epoch: 5| Step: 8
Training loss: 2.0880520343780518
Validation loss: 1.8213565234215028

Epoch: 5| Step: 9
Training loss: 1.3036507368087769
Validation loss: 1.8537666874547158

Epoch: 5| Step: 10
Training loss: 0.990899920463562
Validation loss: 1.7887090829110914

Epoch: 372| Step: 0
Training loss: 1.0750787258148193
Validation loss: 1.8491458713367421

Epoch: 5| Step: 1
Training loss: 1.348120093345642
Validation loss: 1.8224293519091863

Epoch: 5| Step: 2
Training loss: 1.8535505533218384
Validation loss: 1.7960164854603429

Epoch: 5| Step: 3
Training loss: 1.2062033414840698
Validation loss: 1.8026865656657884

Epoch: 5| Step: 4
Training loss: 1.6792205572128296
Validation loss: 1.8246939259190713

Epoch: 5| Step: 5
Training loss: 1.661852478981018
Validation loss: 1.7589970557920394

Epoch: 5| Step: 6
Training loss: 1.4283006191253662
Validation loss: 1.7234915712828278

Epoch: 5| Step: 7
Training loss: 1.3893651962280273
Validation loss: 1.7994132208567795

Epoch: 5| Step: 8
Training loss: 1.1566084623336792
Validation loss: 1.7916736820692658

Epoch: 5| Step: 9
Training loss: 1.6302478313446045
Validation loss: 1.7975758301314486

Epoch: 5| Step: 10
Training loss: 1.9783508777618408
Validation loss: 1.8207309015335575

Epoch: 373| Step: 0
Training loss: 0.7714516520500183
Validation loss: 1.7715294489296534

Epoch: 5| Step: 1
Training loss: 1.1324846744537354
Validation loss: 1.7917612803879606

Epoch: 5| Step: 2
Training loss: 2.0556132793426514
Validation loss: 1.8503264099039056

Epoch: 5| Step: 3
Training loss: 1.0858840942382812
Validation loss: 1.806595738216113

Epoch: 5| Step: 4
Training loss: 1.7512832880020142
Validation loss: 1.8108489064760105

Epoch: 5| Step: 5
Training loss: 1.4717836380004883
Validation loss: 1.820446196422782

Epoch: 5| Step: 6
Training loss: 1.6221860647201538
Validation loss: 1.7810355130062308

Epoch: 5| Step: 7
Training loss: 1.6020870208740234
Validation loss: 1.8047795385442755

Epoch: 5| Step: 8
Training loss: 1.7393617630004883
Validation loss: 1.809424373411363

Epoch: 5| Step: 9
Training loss: 1.7314506769180298
Validation loss: 1.8248293169083134

Epoch: 5| Step: 10
Training loss: 1.2810087203979492
Validation loss: 1.8116670731575257

Epoch: 374| Step: 0
Training loss: 1.1604012250900269
Validation loss: 1.7917637158465642

Epoch: 5| Step: 1
Training loss: 1.767309546470642
Validation loss: 1.8558039639585762

Epoch: 5| Step: 2
Training loss: 1.6693687438964844
Validation loss: 1.8340413096130534

Epoch: 5| Step: 3
Training loss: 1.36301851272583
Validation loss: 1.8159865487006404

Epoch: 5| Step: 4
Training loss: 1.404047966003418
Validation loss: 1.803703285032703

Epoch: 5| Step: 5
Training loss: 1.8173996210098267
Validation loss: 1.7947344010876072

Epoch: 5| Step: 6
Training loss: 1.5648548603057861
Validation loss: 1.8035947750973444

Epoch: 5| Step: 7
Training loss: 1.8319947719573975
Validation loss: 1.8163731110993253

Epoch: 5| Step: 8
Training loss: 1.2228126525878906
Validation loss: 1.8249027652125205

Epoch: 5| Step: 9
Training loss: 1.4465901851654053
Validation loss: 1.7781757282954391

Epoch: 5| Step: 10
Training loss: 1.0598602294921875
Validation loss: 1.7829100496025496

Epoch: 375| Step: 0
Training loss: 1.645564317703247
Validation loss: 1.8046537906892839

Epoch: 5| Step: 1
Training loss: 1.4787086248397827
Validation loss: 1.847663894776375

Epoch: 5| Step: 2
Training loss: 1.6008319854736328
Validation loss: 1.7589500270864016

Epoch: 5| Step: 3
Training loss: 1.2410860061645508
Validation loss: 1.761397566846622

Epoch: 5| Step: 4
Training loss: 1.6795339584350586
Validation loss: 1.7982271845622728

Epoch: 5| Step: 5
Training loss: 1.3552625179290771
Validation loss: 1.8040964680333291

Epoch: 5| Step: 6
Training loss: 1.9143764972686768
Validation loss: 1.7996678557447208

Epoch: 5| Step: 7
Training loss: 1.5759427547454834
Validation loss: 1.7559498202416204

Epoch: 5| Step: 8
Training loss: 0.8446000218391418
Validation loss: 1.827411787484282

Epoch: 5| Step: 9
Training loss: 1.2683968544006348
Validation loss: 1.8024794850298154

Epoch: 5| Step: 10
Training loss: 1.3638598918914795
Validation loss: 1.765086648284748

Epoch: 376| Step: 0
Training loss: 1.35687255859375
Validation loss: 1.8323714117850027

Epoch: 5| Step: 1
Training loss: 1.5167194604873657
Validation loss: 1.7975799332382858

Epoch: 5| Step: 2
Training loss: 1.7746937274932861
Validation loss: 1.8247914173269784

Epoch: 5| Step: 3
Training loss: 0.6955054998397827
Validation loss: 1.8042439363336051

Epoch: 5| Step: 4
Training loss: 1.1006319522857666
Validation loss: 1.8340804038509246

Epoch: 5| Step: 5
Training loss: 2.2135844230651855
Validation loss: 1.8119161096952294

Epoch: 5| Step: 6
Training loss: 1.626251459121704
Validation loss: 1.8665509172665176

Epoch: 5| Step: 7
Training loss: 1.5782912969589233
Validation loss: 1.8344684672612015

Epoch: 5| Step: 8
Training loss: 1.1987165212631226
Validation loss: 1.8579237114998601

Epoch: 5| Step: 9
Training loss: 1.295676827430725
Validation loss: 1.7999374456303094

Epoch: 5| Step: 10
Training loss: 2.031190872192383
Validation loss: 1.8424481781580115

Epoch: 377| Step: 0
Training loss: 1.1390714645385742
Validation loss: 1.808432238076323

Epoch: 5| Step: 1
Training loss: 2.0484681129455566
Validation loss: 1.7895221710205078

Epoch: 5| Step: 2
Training loss: 1.4327642917633057
Validation loss: 1.8339048354856429

Epoch: 5| Step: 3
Training loss: 0.7415342926979065
Validation loss: 1.7612448225739181

Epoch: 5| Step: 4
Training loss: 1.5551458597183228
Validation loss: 1.8081850082643571

Epoch: 5| Step: 5
Training loss: 1.672394037246704
Validation loss: 1.784267084572905

Epoch: 5| Step: 6
Training loss: 0.8622443079948425
Validation loss: 1.7958004769458566

Epoch: 5| Step: 7
Training loss: 1.9335181713104248
Validation loss: 1.8130552204706336

Epoch: 5| Step: 8
Training loss: 1.195148229598999
Validation loss: 1.7689971975100938

Epoch: 5| Step: 9
Training loss: 1.6758182048797607
Validation loss: 1.800931187086208

Epoch: 5| Step: 10
Training loss: 2.0465140342712402
Validation loss: 1.8135787402429888

Epoch: 378| Step: 0
Training loss: 1.5514709949493408
Validation loss: 1.770786387946016

Epoch: 5| Step: 1
Training loss: 1.414679765701294
Validation loss: 1.7894386834995721

Epoch: 5| Step: 2
Training loss: 0.8688094019889832
Validation loss: 1.8313545873088222

Epoch: 5| Step: 3
Training loss: 2.0171103477478027
Validation loss: 1.793720035142796

Epoch: 5| Step: 4
Training loss: 0.9029911160469055
Validation loss: 1.8089171263479418

Epoch: 5| Step: 5
Training loss: 1.193917989730835
Validation loss: 1.8439113555415985

Epoch: 5| Step: 6
Training loss: 1.1661112308502197
Validation loss: 1.8124042762223112

Epoch: 5| Step: 7
Training loss: 1.2625802755355835
Validation loss: 1.8094582378223378

Epoch: 5| Step: 8
Training loss: 2.299802780151367
Validation loss: 1.8281002595860472

Epoch: 5| Step: 9
Training loss: 1.725128173828125
Validation loss: 1.8274315428990189

Epoch: 5| Step: 10
Training loss: 2.1547961235046387
Validation loss: 1.8512657496236986

Epoch: 379| Step: 0
Training loss: 1.1598012447357178
Validation loss: 1.8487757636654762

Epoch: 5| Step: 1
Training loss: 1.1007492542266846
Validation loss: 1.7929762268579135

Epoch: 5| Step: 2
Training loss: 1.181083083152771
Validation loss: 1.8137180548842236

Epoch: 5| Step: 3
Training loss: 1.48533296585083
Validation loss: 1.7910470488250896

Epoch: 5| Step: 4
Training loss: 1.3908411264419556
Validation loss: 1.812456803937112

Epoch: 5| Step: 5
Training loss: 2.244981050491333
Validation loss: 1.7562152442111765

Epoch: 5| Step: 6
Training loss: 0.8283230662345886
Validation loss: 1.7905502678245626

Epoch: 5| Step: 7
Training loss: 1.248716950416565
Validation loss: 1.7998551976296209

Epoch: 5| Step: 8
Training loss: 1.8400688171386719
Validation loss: 1.8044104922202326

Epoch: 5| Step: 9
Training loss: 1.7950900793075562
Validation loss: 1.791295523284584

Epoch: 5| Step: 10
Training loss: 1.793798565864563
Validation loss: 1.807131540390753

Epoch: 380| Step: 0
Training loss: 1.270121455192566
Validation loss: 1.8000078457658009

Epoch: 5| Step: 1
Training loss: 1.3243051767349243
Validation loss: 1.802949341394568

Epoch: 5| Step: 2
Training loss: 1.3457123041152954
Validation loss: 1.8239154764401015

Epoch: 5| Step: 3
Training loss: 1.2796061038970947
Validation loss: 1.8581128658786896

Epoch: 5| Step: 4
Training loss: 1.5080782175064087
Validation loss: 1.8393396741600447

Epoch: 5| Step: 5
Training loss: 1.3965847492218018
Validation loss: 1.8389035527424147

Epoch: 5| Step: 6
Training loss: 1.4175338745117188
Validation loss: 1.854429587241142

Epoch: 5| Step: 7
Training loss: 2.1790008544921875
Validation loss: 1.8275412346727105

Epoch: 5| Step: 8
Training loss: 1.636471152305603
Validation loss: 1.835094977450627

Epoch: 5| Step: 9
Training loss: 1.7290055751800537
Validation loss: 1.8056358098983765

Epoch: 5| Step: 10
Training loss: 1.1801695823669434
Validation loss: 1.8133577864657167

Epoch: 381| Step: 0
Training loss: 1.3344618082046509
Validation loss: 1.796794517065889

Epoch: 5| Step: 1
Training loss: 1.3587639331817627
Validation loss: 1.7709347112204439

Epoch: 5| Step: 2
Training loss: 1.4188560247421265
Validation loss: 1.8307186454854987

Epoch: 5| Step: 3
Training loss: 1.0344610214233398
Validation loss: 1.8091714651353898

Epoch: 5| Step: 4
Training loss: 1.348302960395813
Validation loss: 1.7695612779227636

Epoch: 5| Step: 5
Training loss: 1.419166088104248
Validation loss: 1.7700049390075028

Epoch: 5| Step: 6
Training loss: 1.9005693197250366
Validation loss: 1.7964023031214231

Epoch: 5| Step: 7
Training loss: 1.6270278692245483
Validation loss: 1.7911580442100443

Epoch: 5| Step: 8
Training loss: 1.8374671936035156
Validation loss: 1.7850459775617045

Epoch: 5| Step: 9
Training loss: 1.6123464107513428
Validation loss: 1.8025048804539505

Epoch: 5| Step: 10
Training loss: 1.0705037117004395
Validation loss: 1.8178893776350125

Epoch: 382| Step: 0
Training loss: 1.4464702606201172
Validation loss: 1.8206604270524875

Epoch: 5| Step: 1
Training loss: 1.57173752784729
Validation loss: 1.830143932373293

Epoch: 5| Step: 2
Training loss: 0.7013729810714722
Validation loss: 1.8510409811491608

Epoch: 5| Step: 3
Training loss: 1.8509219884872437
Validation loss: 1.8380516344501125

Epoch: 5| Step: 4
Training loss: 1.481241226196289
Validation loss: 1.8154660488969536

Epoch: 5| Step: 5
Training loss: 1.4674723148345947
Validation loss: 1.8344976850735244

Epoch: 5| Step: 6
Training loss: 1.695813536643982
Validation loss: 1.8139520922014791

Epoch: 5| Step: 7
Training loss: 1.2142765522003174
Validation loss: 1.8000759360610799

Epoch: 5| Step: 8
Training loss: 1.7380043268203735
Validation loss: 1.7425272926207511

Epoch: 5| Step: 9
Training loss: 1.5538417100906372
Validation loss: 1.8100346249918784

Epoch: 5| Step: 10
Training loss: 1.902330994606018
Validation loss: 1.7773533200704923

Epoch: 383| Step: 0
Training loss: 1.6442782878875732
Validation loss: 1.815212909893323

Epoch: 5| Step: 1
Training loss: 1.3662160634994507
Validation loss: 1.7764455785033524

Epoch: 5| Step: 2
Training loss: 1.1913002729415894
Validation loss: 1.7765729042791552

Epoch: 5| Step: 3
Training loss: 1.773130178451538
Validation loss: 1.8261770445813414

Epoch: 5| Step: 4
Training loss: 1.2739558219909668
Validation loss: 1.8296072367698915

Epoch: 5| Step: 5
Training loss: 1.8431951999664307
Validation loss: 1.816108847177157

Epoch: 5| Step: 6
Training loss: 1.656097173690796
Validation loss: 1.8201745261428177

Epoch: 5| Step: 7
Training loss: 1.229617714881897
Validation loss: 1.7777938137772262

Epoch: 5| Step: 8
Training loss: 1.3185480833053589
Validation loss: 1.7817714355325187

Epoch: 5| Step: 9
Training loss: 1.1949602365493774
Validation loss: 1.8008711786680325

Epoch: 5| Step: 10
Training loss: 1.6732916831970215
Validation loss: 1.7714769865876885

Epoch: 384| Step: 0
Training loss: 1.9645283222198486
Validation loss: 1.8049599047630065

Epoch: 5| Step: 1
Training loss: 0.8513164520263672
Validation loss: 1.7948758038141395

Epoch: 5| Step: 2
Training loss: 1.5611673593521118
Validation loss: 1.781489364562496

Epoch: 5| Step: 3
Training loss: 1.9057010412216187
Validation loss: 1.845392539937009

Epoch: 5| Step: 4
Training loss: 1.2628757953643799
Validation loss: 1.8247447449673888

Epoch: 5| Step: 5
Training loss: 1.5931751728057861
Validation loss: 1.7874770010671308

Epoch: 5| Step: 6
Training loss: 1.7788808345794678
Validation loss: 1.7923671430157078

Epoch: 5| Step: 7
Training loss: 1.3387582302093506
Validation loss: 1.8395804897431405

Epoch: 5| Step: 8
Training loss: 0.9544944763183594
Validation loss: 1.7888028211491083

Epoch: 5| Step: 9
Training loss: 0.9647148847579956
Validation loss: 1.7651944186097832

Epoch: 5| Step: 10
Training loss: 1.6014974117279053
Validation loss: 1.7982474270687308

Epoch: 385| Step: 0
Training loss: 1.784221887588501
Validation loss: 1.7610972299370715

Epoch: 5| Step: 1
Training loss: 1.3698265552520752
Validation loss: 1.777561015980218

Epoch: 5| Step: 2
Training loss: 1.1446154117584229
Validation loss: 1.8073816376347696

Epoch: 5| Step: 3
Training loss: 1.4507094621658325
Validation loss: 1.8395955101136239

Epoch: 5| Step: 4
Training loss: 1.9878795146942139
Validation loss: 1.7568389523413874

Epoch: 5| Step: 5
Training loss: 1.1858748197555542
Validation loss: 1.8199956186356083

Epoch: 5| Step: 6
Training loss: 1.3482564687728882
Validation loss: 1.798674334761917

Epoch: 5| Step: 7
Training loss: 1.2188411951065063
Validation loss: 1.8201859830528178

Epoch: 5| Step: 8
Training loss: 1.8172900676727295
Validation loss: 1.7764346266305575

Epoch: 5| Step: 9
Training loss: 1.2180454730987549
Validation loss: 1.8142718922707342

Epoch: 5| Step: 10
Training loss: 1.2934353351593018
Validation loss: 1.7876139507498792

Epoch: 386| Step: 0
Training loss: 1.216198205947876
Validation loss: 1.8273296868929298

Epoch: 5| Step: 1
Training loss: 1.2371517419815063
Validation loss: 1.7823087220550866

Epoch: 5| Step: 2
Training loss: 1.8712831735610962
Validation loss: 1.814737440437399

Epoch: 5| Step: 3
Training loss: 1.3632373809814453
Validation loss: 1.7634621435596096

Epoch: 5| Step: 4
Training loss: 1.140794277191162
Validation loss: 1.7597268383990052

Epoch: 5| Step: 5
Training loss: 1.677080512046814
Validation loss: 1.7864271274176977

Epoch: 5| Step: 6
Training loss: 1.1940364837646484
Validation loss: 1.7952691957514773

Epoch: 5| Step: 7
Training loss: 1.4533441066741943
Validation loss: 1.7892771203030822

Epoch: 5| Step: 8
Training loss: 1.2383848428726196
Validation loss: 1.7853779446694158

Epoch: 5| Step: 9
Training loss: 1.5222963094711304
Validation loss: 1.8316760627172326

Epoch: 5| Step: 10
Training loss: 1.7376604080200195
Validation loss: 1.8237929305722635

Epoch: 387| Step: 0
Training loss: 1.0403294563293457
Validation loss: 1.8670883486347813

Epoch: 5| Step: 1
Training loss: 0.9569371938705444
Validation loss: 1.8066241330997919

Epoch: 5| Step: 2
Training loss: 1.696380853652954
Validation loss: 1.8637473826767297

Epoch: 5| Step: 3
Training loss: 1.3596237897872925
Validation loss: 1.780042702151883

Epoch: 5| Step: 4
Training loss: 1.2424886226654053
Validation loss: 1.8050760248655915

Epoch: 5| Step: 5
Training loss: 1.6336380243301392
Validation loss: 1.8433654192955262

Epoch: 5| Step: 6
Training loss: 2.163944721221924
Validation loss: 1.8195055223280383

Epoch: 5| Step: 7
Training loss: 1.57148277759552
Validation loss: 1.7873882247555641

Epoch: 5| Step: 8
Training loss: 1.620308518409729
Validation loss: 1.8114977011116602

Epoch: 5| Step: 9
Training loss: 1.3611031770706177
Validation loss: 1.7914084465272966

Epoch: 5| Step: 10
Training loss: 1.0042296648025513
Validation loss: 1.844519163972588

Epoch: 388| Step: 0
Training loss: 1.636263132095337
Validation loss: 1.8174817427512138

Epoch: 5| Step: 1
Training loss: 1.2251754999160767
Validation loss: 1.805387076511178

Epoch: 5| Step: 2
Training loss: 1.4342750310897827
Validation loss: 1.7724570023116244

Epoch: 5| Step: 3
Training loss: 1.9383690357208252
Validation loss: 1.8329930343935568

Epoch: 5| Step: 4
Training loss: 1.3561443090438843
Validation loss: 1.7830516189657233

Epoch: 5| Step: 5
Training loss: 1.653927206993103
Validation loss: 1.800480604171753

Epoch: 5| Step: 6
Training loss: 1.1966336965560913
Validation loss: 1.8259903679611862

Epoch: 5| Step: 7
Training loss: 1.23090398311615
Validation loss: 1.7970081388309438

Epoch: 5| Step: 8
Training loss: 1.9142402410507202
Validation loss: 1.7936500695443922

Epoch: 5| Step: 9
Training loss: 1.4642083644866943
Validation loss: 1.7748783224372453

Epoch: 5| Step: 10
Training loss: 1.1404519081115723
Validation loss: 1.8089708269283336

Epoch: 389| Step: 0
Training loss: 1.0471559762954712
Validation loss: 1.7931633175060313

Epoch: 5| Step: 1
Training loss: 1.2446284294128418
Validation loss: 1.8035847730534051

Epoch: 5| Step: 2
Training loss: 1.7100279331207275
Validation loss: 1.8205299377441406

Epoch: 5| Step: 3
Training loss: 1.4349735975265503
Validation loss: 1.8189842136957313

Epoch: 5| Step: 4
Training loss: 1.3751052618026733
Validation loss: 1.8570167659431376

Epoch: 5| Step: 5
Training loss: 1.3404711484909058
Validation loss: 1.8088882917998939

Epoch: 5| Step: 6
Training loss: 1.6232887506484985
Validation loss: 1.7999031133549188

Epoch: 5| Step: 7
Training loss: 1.4987561702728271
Validation loss: 1.8137087386141542

Epoch: 5| Step: 8
Training loss: 1.7234846353530884
Validation loss: 1.7966307978476248

Epoch: 5| Step: 9
Training loss: 1.4693284034729004
Validation loss: 1.781994447913221

Epoch: 5| Step: 10
Training loss: 1.3712018728256226
Validation loss: 1.7769782825182843

Epoch: 390| Step: 0
Training loss: 1.3592183589935303
Validation loss: 1.8483704072172924

Epoch: 5| Step: 1
Training loss: 1.2875401973724365
Validation loss: 1.7675982521426292

Epoch: 5| Step: 2
Training loss: 1.5641947984695435
Validation loss: 1.7801760345376947

Epoch: 5| Step: 3
Training loss: 1.8447058200836182
Validation loss: 1.7705454980173418

Epoch: 5| Step: 4
Training loss: 0.9277505874633789
Validation loss: 1.8029916401832335

Epoch: 5| Step: 5
Training loss: 1.2508275508880615
Validation loss: 1.7808853285287016

Epoch: 5| Step: 6
Training loss: 1.7470051050186157
Validation loss: 1.78306479736041

Epoch: 5| Step: 7
Training loss: 1.776662826538086
Validation loss: 1.8129173799227642

Epoch: 5| Step: 8
Training loss: 1.2681362628936768
Validation loss: 1.8323954266886557

Epoch: 5| Step: 9
Training loss: 1.3633599281311035
Validation loss: 1.7960775552257415

Epoch: 5| Step: 10
Training loss: 1.6516789197921753
Validation loss: 1.791650108111802

Epoch: 391| Step: 0
Training loss: 1.3969922065734863
Validation loss: 1.8255001908989363

Epoch: 5| Step: 1
Training loss: 1.008664846420288
Validation loss: 1.8209486712691605

Epoch: 5| Step: 2
Training loss: 1.600992202758789
Validation loss: 1.7968717723764398

Epoch: 5| Step: 3
Training loss: 1.8161453008651733
Validation loss: 1.8045442194067023

Epoch: 5| Step: 4
Training loss: 1.413959264755249
Validation loss: 1.8401455392119705

Epoch: 5| Step: 5
Training loss: 1.329056978225708
Validation loss: 1.8054063909797258

Epoch: 5| Step: 6
Training loss: 1.709119200706482
Validation loss: 1.7957817405782721

Epoch: 5| Step: 7
Training loss: 1.079453706741333
Validation loss: 1.8046070427022955

Epoch: 5| Step: 8
Training loss: 1.5490260124206543
Validation loss: 1.8495116285098496

Epoch: 5| Step: 9
Training loss: 1.2573521137237549
Validation loss: 1.8177240792141165

Epoch: 5| Step: 10
Training loss: 1.8828516006469727
Validation loss: 1.8419692490690498

Epoch: 392| Step: 0
Training loss: 1.4328495264053345
Validation loss: 1.8260306965920232

Epoch: 5| Step: 1
Training loss: 1.6132663488388062
Validation loss: 1.8148089147383166

Epoch: 5| Step: 2
Training loss: 1.2064802646636963
Validation loss: 1.7553182481437601

Epoch: 5| Step: 3
Training loss: 0.8286730051040649
Validation loss: 1.8171898421420847

Epoch: 5| Step: 4
Training loss: 1.4436919689178467
Validation loss: 1.7881578207015991

Epoch: 5| Step: 5
Training loss: 1.2433449029922485
Validation loss: 1.8227984482242214

Epoch: 5| Step: 6
Training loss: 1.272781491279602
Validation loss: 1.8178282027603478

Epoch: 5| Step: 7
Training loss: 1.3655033111572266
Validation loss: 1.7914266688849336

Epoch: 5| Step: 8
Training loss: 1.9636342525482178
Validation loss: 1.8238917294368948

Epoch: 5| Step: 9
Training loss: 1.695688009262085
Validation loss: 1.8218374124137304

Epoch: 5| Step: 10
Training loss: 1.3157614469528198
Validation loss: 1.8391620369367703

Epoch: 393| Step: 0
Training loss: 1.0175378322601318
Validation loss: 1.7773967353246545

Epoch: 5| Step: 1
Training loss: 1.7195026874542236
Validation loss: 1.8051735540871978

Epoch: 5| Step: 2
Training loss: 1.0139960050582886
Validation loss: 1.7823849570366643

Epoch: 5| Step: 3
Training loss: 1.4534575939178467
Validation loss: 1.7649922806729552

Epoch: 5| Step: 4
Training loss: 2.087292432785034
Validation loss: 1.8148893643450994

Epoch: 5| Step: 5
Training loss: 1.0096248388290405
Validation loss: 1.786868122316176

Epoch: 5| Step: 6
Training loss: 1.4418833255767822
Validation loss: 1.819512797940162

Epoch: 5| Step: 7
Training loss: 1.2644095420837402
Validation loss: 1.8014913464105258

Epoch: 5| Step: 8
Training loss: 1.549157977104187
Validation loss: 1.7385516012868574

Epoch: 5| Step: 9
Training loss: 1.5938246250152588
Validation loss: 1.7737254686253046

Epoch: 5| Step: 10
Training loss: 1.4120724201202393
Validation loss: 1.762601988289946

Epoch: 394| Step: 0
Training loss: 1.3630685806274414
Validation loss: 1.809255708930313

Epoch: 5| Step: 1
Training loss: 0.9524981379508972
Validation loss: 1.7621813166526057

Epoch: 5| Step: 2
Training loss: 2.130789041519165
Validation loss: 1.782092091857746

Epoch: 5| Step: 3
Training loss: 1.7771689891815186
Validation loss: 1.771240411266204

Epoch: 5| Step: 4
Training loss: 1.570197343826294
Validation loss: 1.7419687881264636

Epoch: 5| Step: 5
Training loss: 1.526993751525879
Validation loss: 1.814662148875575

Epoch: 5| Step: 6
Training loss: 1.0520952939987183
Validation loss: 1.8404173363921463

Epoch: 5| Step: 7
Training loss: 1.260005235671997
Validation loss: 1.7740172891206638

Epoch: 5| Step: 8
Training loss: 0.7285102009773254
Validation loss: 1.841981021306848

Epoch: 5| Step: 9
Training loss: 1.1602156162261963
Validation loss: 1.8242316733124435

Epoch: 5| Step: 10
Training loss: 2.020146369934082
Validation loss: 1.788025253562517

Epoch: 395| Step: 0
Training loss: 1.0615594387054443
Validation loss: 1.8033507177906651

Epoch: 5| Step: 1
Training loss: 1.8290382623672485
Validation loss: 1.7905097930662093

Epoch: 5| Step: 2
Training loss: 1.3522512912750244
Validation loss: 1.8182533146232687

Epoch: 5| Step: 3
Training loss: 1.2808220386505127
Validation loss: 1.8004129343135382

Epoch: 5| Step: 4
Training loss: 1.1399753093719482
Validation loss: 1.7882241010665894

Epoch: 5| Step: 5
Training loss: 1.474120855331421
Validation loss: 1.8266733513083508

Epoch: 5| Step: 6
Training loss: 1.365006923675537
Validation loss: 1.801867244064167

Epoch: 5| Step: 7
Training loss: 2.1418261528015137
Validation loss: 1.795698740149057

Epoch: 5| Step: 8
Training loss: 1.586606740951538
Validation loss: 1.77940910221428

Epoch: 5| Step: 9
Training loss: 1.1400346755981445
Validation loss: 1.800927100643035

Epoch: 5| Step: 10
Training loss: 1.265525460243225
Validation loss: 1.757767472215878

Epoch: 396| Step: 0
Training loss: 1.6364421844482422
Validation loss: 1.8383238354036886

Epoch: 5| Step: 1
Training loss: 1.4247446060180664
Validation loss: 1.793512963479565

Epoch: 5| Step: 2
Training loss: 1.5129159688949585
Validation loss: 1.765341099872384

Epoch: 5| Step: 3
Training loss: 1.1114273071289062
Validation loss: 1.8112721866176975

Epoch: 5| Step: 4
Training loss: 1.3801074028015137
Validation loss: 1.7893088863741966

Epoch: 5| Step: 5
Training loss: 1.3896188735961914
Validation loss: 1.8187521606363275

Epoch: 5| Step: 6
Training loss: 1.6796739101409912
Validation loss: 1.7853117309590822

Epoch: 5| Step: 7
Training loss: 1.4180258512496948
Validation loss: 1.814013760576966

Epoch: 5| Step: 8
Training loss: 1.544621467590332
Validation loss: 1.8243615934925694

Epoch: 5| Step: 9
Training loss: 1.4996817111968994
Validation loss: 1.7891731185297812

Epoch: 5| Step: 10
Training loss: 1.0872101783752441
Validation loss: 1.7495682162623252

Epoch: 397| Step: 0
Training loss: 1.0051501989364624
Validation loss: 1.7952656797183457

Epoch: 5| Step: 1
Training loss: 1.7012214660644531
Validation loss: 1.7641257919291014

Epoch: 5| Step: 2
Training loss: 1.6340243816375732
Validation loss: 1.7967218737448416

Epoch: 5| Step: 3
Training loss: 1.6849275827407837
Validation loss: 1.81279892306174

Epoch: 5| Step: 4
Training loss: 1.0835767984390259
Validation loss: 1.7541788893361245

Epoch: 5| Step: 5
Training loss: 1.6205737590789795
Validation loss: 1.7814357306367608

Epoch: 5| Step: 6
Training loss: 0.7388045787811279
Validation loss: 1.7910496714294597

Epoch: 5| Step: 7
Training loss: 1.1066319942474365
Validation loss: 1.8069382213777112

Epoch: 5| Step: 8
Training loss: 1.737575888633728
Validation loss: 1.783137567581669

Epoch: 5| Step: 9
Training loss: 2.12103271484375
Validation loss: 1.7719516587513748

Epoch: 5| Step: 10
Training loss: 1.2457164525985718
Validation loss: 1.8392320499625257

Epoch: 398| Step: 0
Training loss: 1.0901832580566406
Validation loss: 1.7361487137374056

Epoch: 5| Step: 1
Training loss: 1.0043991804122925
Validation loss: 1.7858444618922409

Epoch: 5| Step: 2
Training loss: 1.2666542530059814
Validation loss: 1.826553503672282

Epoch: 5| Step: 3
Training loss: 1.5296663045883179
Validation loss: 1.7818805915053173

Epoch: 5| Step: 4
Training loss: 1.8550316095352173
Validation loss: 1.8247606433847898

Epoch: 5| Step: 5
Training loss: 2.001276969909668
Validation loss: 1.7848798869758524

Epoch: 5| Step: 6
Training loss: 1.1172590255737305
Validation loss: 1.7712383577900548

Epoch: 5| Step: 7
Training loss: 1.5318853855133057
Validation loss: 1.842876447144375

Epoch: 5| Step: 8
Training loss: 1.6595340967178345
Validation loss: 1.8015757004419963

Epoch: 5| Step: 9
Training loss: 1.1324217319488525
Validation loss: 1.7818220353895617

Epoch: 5| Step: 10
Training loss: 0.9921850562095642
Validation loss: 1.7796157636950094

Epoch: 399| Step: 0
Training loss: 1.570805549621582
Validation loss: 1.7379286955761653

Epoch: 5| Step: 1
Training loss: 1.286010503768921
Validation loss: 1.8226703828380955

Epoch: 5| Step: 2
Training loss: 1.2224745750427246
Validation loss: 1.7953162013843496

Epoch: 5| Step: 3
Training loss: 1.3718971014022827
Validation loss: 1.820852566790837

Epoch: 5| Step: 4
Training loss: 1.5825729370117188
Validation loss: 1.8381806419741722

Epoch: 5| Step: 5
Training loss: 1.7361360788345337
Validation loss: 1.8318833035807456

Epoch: 5| Step: 6
Training loss: 1.9315874576568604
Validation loss: 1.7922622208954186

Epoch: 5| Step: 7
Training loss: 1.2045668363571167
Validation loss: 1.7759770372862458

Epoch: 5| Step: 8
Training loss: 1.21575129032135
Validation loss: 1.763504735885128

Epoch: 5| Step: 9
Training loss: 0.8983443975448608
Validation loss: 1.838068578832893

Epoch: 5| Step: 10
Training loss: 1.5424995422363281
Validation loss: 1.7913643865175144

Epoch: 400| Step: 0
Training loss: 0.7889383435249329
Validation loss: 1.7996078793720534

Epoch: 5| Step: 1
Training loss: 1.206923484802246
Validation loss: 1.772958573474679

Epoch: 5| Step: 2
Training loss: 1.4978523254394531
Validation loss: 1.7738334876234814

Epoch: 5| Step: 3
Training loss: 1.1149146556854248
Validation loss: 1.820983152876618

Epoch: 5| Step: 4
Training loss: 1.383904218673706
Validation loss: 1.7715924260436848

Epoch: 5| Step: 5
Training loss: 1.6730406284332275
Validation loss: 1.7752151309802968

Epoch: 5| Step: 6
Training loss: 1.4558966159820557
Validation loss: 1.7719147564262472

Epoch: 5| Step: 7
Training loss: 1.1432253122329712
Validation loss: 1.8019616180850613

Epoch: 5| Step: 8
Training loss: 2.096909284591675
Validation loss: 1.8427724684438398

Epoch: 5| Step: 9
Training loss: 1.6577966213226318
Validation loss: 1.8164925972620647

Epoch: 5| Step: 10
Training loss: 1.5581789016723633
Validation loss: 1.825715595676053

Epoch: 401| Step: 0
Training loss: 1.0863286256790161
Validation loss: 1.8406484024499052

Epoch: 5| Step: 1
Training loss: 1.5670381784439087
Validation loss: 1.8107932959833453

Epoch: 5| Step: 2
Training loss: 1.3957570791244507
Validation loss: 1.7927245991204375

Epoch: 5| Step: 3
Training loss: 1.6071693897247314
Validation loss: 1.8435093818172332

Epoch: 5| Step: 4
Training loss: 1.2698332071304321
Validation loss: 1.815015266018529

Epoch: 5| Step: 5
Training loss: 1.2782504558563232
Validation loss: 1.828317755012102

Epoch: 5| Step: 6
Training loss: 1.6174920797348022
Validation loss: 1.7792272619021836

Epoch: 5| Step: 7
Training loss: 1.508040189743042
Validation loss: 1.7918950537199616

Epoch: 5| Step: 8
Training loss: 0.8413833379745483
Validation loss: 1.7862631659353934

Epoch: 5| Step: 9
Training loss: 1.4792648553848267
Validation loss: 1.7443392443400558

Epoch: 5| Step: 10
Training loss: 1.6366989612579346
Validation loss: 1.7799197012378323

Epoch: 402| Step: 0
Training loss: 1.245074987411499
Validation loss: 1.7934253959245579

Epoch: 5| Step: 1
Training loss: 1.2762948274612427
Validation loss: 1.8053279717763264

Epoch: 5| Step: 2
Training loss: 1.2548784017562866
Validation loss: 1.7850021521250408

Epoch: 5| Step: 3
Training loss: 1.1733639240264893
Validation loss: 1.7849316981530958

Epoch: 5| Step: 4
Training loss: 1.7413724660873413
Validation loss: 1.8178702285212855

Epoch: 5| Step: 5
Training loss: 1.4724124670028687
Validation loss: 1.7932844777261057

Epoch: 5| Step: 6
Training loss: 1.2586946487426758
Validation loss: 1.8198747429796445

Epoch: 5| Step: 7
Training loss: 1.1646244525909424
Validation loss: 1.828761269969325

Epoch: 5| Step: 8
Training loss: 1.4337667226791382
Validation loss: 1.8109934432532198

Epoch: 5| Step: 9
Training loss: 1.489776372909546
Validation loss: 1.8340136927943076

Epoch: 5| Step: 10
Training loss: 1.8448455333709717
Validation loss: 1.8107488796275149

Epoch: 403| Step: 0
Training loss: 1.407861351966858
Validation loss: 1.799374234291815

Epoch: 5| Step: 1
Training loss: 1.2273831367492676
Validation loss: 1.8176962355131745

Epoch: 5| Step: 2
Training loss: 1.663404107093811
Validation loss: 1.8121671471544492

Epoch: 5| Step: 3
Training loss: 0.9736689329147339
Validation loss: 1.7772054967059885

Epoch: 5| Step: 4
Training loss: 1.2668935060501099
Validation loss: 1.7863132210188015

Epoch: 5| Step: 5
Training loss: 1.547143578529358
Validation loss: 1.8389411331504903

Epoch: 5| Step: 6
Training loss: 1.0784941911697388
Validation loss: 1.7887082112732755

Epoch: 5| Step: 7
Training loss: 1.6229422092437744
Validation loss: 1.8223620166060746

Epoch: 5| Step: 8
Training loss: 1.3505405187606812
Validation loss: 1.8074246068154611

Epoch: 5| Step: 9
Training loss: 1.3359291553497314
Validation loss: 1.8853534011430637

Epoch: 5| Step: 10
Training loss: 1.6449416875839233
Validation loss: 1.7860297695282967

Epoch: 404| Step: 0
Training loss: 1.3172060251235962
Validation loss: 1.8474729112399522

Epoch: 5| Step: 1
Training loss: 0.9539041519165039
Validation loss: 1.7728418919347948

Epoch: 5| Step: 2
Training loss: 1.5784399509429932
Validation loss: 1.7738895646987423

Epoch: 5| Step: 3
Training loss: 1.3774913549423218
Validation loss: 1.8181188580810383

Epoch: 5| Step: 4
Training loss: 1.4687434434890747
Validation loss: 1.7861165731183943

Epoch: 5| Step: 5
Training loss: 1.544473648071289
Validation loss: 1.7674350584706953

Epoch: 5| Step: 6
Training loss: 1.5482969284057617
Validation loss: 1.8003746694134128

Epoch: 5| Step: 7
Training loss: 0.8266159296035767
Validation loss: 1.7715307461318148

Epoch: 5| Step: 8
Training loss: 1.5183436870574951
Validation loss: 1.7869067140804824

Epoch: 5| Step: 9
Training loss: 1.2745978832244873
Validation loss: 1.7836182117462158

Epoch: 5| Step: 10
Training loss: 1.6619843244552612
Validation loss: 1.766399783472861

Epoch: 405| Step: 0
Training loss: 1.4987943172454834
Validation loss: 1.7622125148773193

Epoch: 5| Step: 1
Training loss: 1.0061476230621338
Validation loss: 1.8100522628394506

Epoch: 5| Step: 2
Training loss: 1.0750778913497925
Validation loss: 1.7657546932979296

Epoch: 5| Step: 3
Training loss: 1.3695316314697266
Validation loss: 1.800615777251541

Epoch: 5| Step: 4
Training loss: 0.8624534606933594
Validation loss: 1.7877595091378817

Epoch: 5| Step: 5
Training loss: 1.635711669921875
Validation loss: 1.8161028815853981

Epoch: 5| Step: 6
Training loss: 1.2717994451522827
Validation loss: 1.826400492780952

Epoch: 5| Step: 7
Training loss: 1.5976414680480957
Validation loss: 1.8066548070599955

Epoch: 5| Step: 8
Training loss: 1.96733820438385
Validation loss: 1.7820336690513037

Epoch: 5| Step: 9
Training loss: 1.4910725355148315
Validation loss: 1.8027476597857732

Epoch: 5| Step: 10
Training loss: 1.366033911705017
Validation loss: 1.837587777004447

Epoch: 406| Step: 0
Training loss: 1.204304575920105
Validation loss: 1.797379792377513

Epoch: 5| Step: 1
Training loss: 1.6315826177597046
Validation loss: 1.778446223146172

Epoch: 5| Step: 2
Training loss: 2.0589611530303955
Validation loss: 1.7889393375765892

Epoch: 5| Step: 3
Training loss: 0.7171740531921387
Validation loss: 1.7837939646936232

Epoch: 5| Step: 4
Training loss: 1.496305227279663
Validation loss: 1.771019163952079

Epoch: 5| Step: 5
Training loss: 1.7053884267807007
Validation loss: 1.8265356504788963

Epoch: 5| Step: 6
Training loss: 1.077588677406311
Validation loss: 1.7706288560744254

Epoch: 5| Step: 7
Training loss: 1.2677322626113892
Validation loss: 1.7861916954799364

Epoch: 5| Step: 8
Training loss: 0.9390201568603516
Validation loss: 1.7879717965279855

Epoch: 5| Step: 9
Training loss: 1.504188060760498
Validation loss: 1.7476599703552902

Epoch: 5| Step: 10
Training loss: 1.7778087854385376
Validation loss: 1.7981184900447886

Epoch: 407| Step: 0
Training loss: 1.1136547327041626
Validation loss: 1.7686258182730725

Epoch: 5| Step: 1
Training loss: 1.5073940753936768
Validation loss: 1.797435781007172

Epoch: 5| Step: 2
Training loss: 1.2377623319625854
Validation loss: 1.819278718322836

Epoch: 5| Step: 3
Training loss: 1.6403955221176147
Validation loss: 1.8389518799320344

Epoch: 5| Step: 4
Training loss: 1.1005016565322876
Validation loss: 1.822226337207261

Epoch: 5| Step: 5
Training loss: 1.3541443347930908
Validation loss: 1.7944684002989082

Epoch: 5| Step: 6
Training loss: 1.629315733909607
Validation loss: 1.8132301017802248

Epoch: 5| Step: 7
Training loss: 1.1651179790496826
Validation loss: 1.8025355441595918

Epoch: 5| Step: 8
Training loss: 1.1198437213897705
Validation loss: 1.8158363783231346

Epoch: 5| Step: 9
Training loss: 1.796741247177124
Validation loss: 1.8204433802635438

Epoch: 5| Step: 10
Training loss: 1.6534909009933472
Validation loss: 1.8070603327084613

Epoch: 408| Step: 0
Training loss: 1.3092256784439087
Validation loss: 1.8721699791569864

Epoch: 5| Step: 1
Training loss: 1.4910227060317993
Validation loss: 1.7886967094995643

Epoch: 5| Step: 2
Training loss: 1.2493820190429688
Validation loss: 1.7785861017883464

Epoch: 5| Step: 3
Training loss: 1.4372460842132568
Validation loss: 1.8335249411162509

Epoch: 5| Step: 4
Training loss: 1.6709579229354858
Validation loss: 1.779150718001909

Epoch: 5| Step: 5
Training loss: 1.1974997520446777
Validation loss: 1.8344359154342322

Epoch: 5| Step: 6
Training loss: 1.3140895366668701
Validation loss: 1.8330662596610285

Epoch: 5| Step: 7
Training loss: 1.4166486263275146
Validation loss: 1.8300877207068986

Epoch: 5| Step: 8
Training loss: 1.4631649255752563
Validation loss: 1.8109468311391852

Epoch: 5| Step: 9
Training loss: 1.4119486808776855
Validation loss: 1.815820005632216

Epoch: 5| Step: 10
Training loss: 1.185120940208435
Validation loss: 1.8346459878388273

Epoch: 409| Step: 0
Training loss: 1.6781501770019531
Validation loss: 1.7940975158445296

Epoch: 5| Step: 1
Training loss: 0.9660342931747437
Validation loss: 1.7903281732272076

Epoch: 5| Step: 2
Training loss: 1.5384148359298706
Validation loss: 1.766325121284813

Epoch: 5| Step: 3
Training loss: 1.5953134298324585
Validation loss: 1.8490701170377835

Epoch: 5| Step: 4
Training loss: 1.4456486701965332
Validation loss: 1.8516439865994196

Epoch: 5| Step: 5
Training loss: 1.2747681140899658
Validation loss: 1.779393816506991

Epoch: 5| Step: 6
Training loss: 1.476907730102539
Validation loss: 1.7935642503922986

Epoch: 5| Step: 7
Training loss: 1.225738525390625
Validation loss: 1.794304757989863

Epoch: 5| Step: 8
Training loss: 1.3825404644012451
Validation loss: 1.833283939669209

Epoch: 5| Step: 9
Training loss: 1.44425368309021
Validation loss: 1.7937434745091263

Epoch: 5| Step: 10
Training loss: 1.1044820547103882
Validation loss: 1.7876947336299445

Epoch: 410| Step: 0
Training loss: 1.171271562576294
Validation loss: 1.8125818455091087

Epoch: 5| Step: 1
Training loss: 1.253313422203064
Validation loss: 1.8062278301485124

Epoch: 5| Step: 2
Training loss: 1.80426824092865
Validation loss: 1.8294554551442463

Epoch: 5| Step: 3
Training loss: 1.5230827331542969
Validation loss: 1.7821250884763655

Epoch: 5| Step: 4
Training loss: 1.363206148147583
Validation loss: 1.7615793687041088

Epoch: 5| Step: 5
Training loss: 0.9325364232063293
Validation loss: 1.8141290808236727

Epoch: 5| Step: 6
Training loss: 1.1038079261779785
Validation loss: 1.791793418186967

Epoch: 5| Step: 7
Training loss: 1.3722277879714966
Validation loss: 1.838407415215687

Epoch: 5| Step: 8
Training loss: 1.222530484199524
Validation loss: 1.8183052975644347

Epoch: 5| Step: 9
Training loss: 1.8947490453720093
Validation loss: 1.8213226128649969

Epoch: 5| Step: 10
Training loss: 1.6057190895080566
Validation loss: 1.819959645630211

Epoch: 411| Step: 0
Training loss: 1.3975303173065186
Validation loss: 1.8323785220423052

Epoch: 5| Step: 1
Training loss: 1.3879282474517822
Validation loss: 1.8132525041539183

Epoch: 5| Step: 2
Training loss: 1.0694783926010132
Validation loss: 1.8056894527968539

Epoch: 5| Step: 3
Training loss: 1.5612632036209106
Validation loss: 1.8003178078641173

Epoch: 5| Step: 4
Training loss: 1.207838773727417
Validation loss: 1.7780838807423909

Epoch: 5| Step: 5
Training loss: 1.012373924255371
Validation loss: 1.8286728743583924

Epoch: 5| Step: 6
Training loss: 1.8042805194854736
Validation loss: 1.8463175655693136

Epoch: 5| Step: 7
Training loss: 1.0240384340286255
Validation loss: 1.7975222038966354

Epoch: 5| Step: 8
Training loss: 1.3522412776947021
Validation loss: 1.7731666270122732

Epoch: 5| Step: 9
Training loss: 1.8036720752716064
Validation loss: 1.8029476622099518

Epoch: 5| Step: 10
Training loss: 1.5061918497085571
Validation loss: 1.8293914743649062

Epoch: 412| Step: 0
Training loss: 1.6156593561172485
Validation loss: 1.796352755638861

Epoch: 5| Step: 1
Training loss: 1.6672645807266235
Validation loss: 1.8045321254320041

Epoch: 5| Step: 2
Training loss: 0.9448404312133789
Validation loss: 1.814177393913269

Epoch: 5| Step: 3
Training loss: 1.7444337606430054
Validation loss: 1.7673559278570197

Epoch: 5| Step: 4
Training loss: 0.7957769632339478
Validation loss: 1.8558118625353741

Epoch: 5| Step: 5
Training loss: 1.143478274345398
Validation loss: 1.7926341320878716

Epoch: 5| Step: 6
Training loss: 1.569519281387329
Validation loss: 1.7660437886432936

Epoch: 5| Step: 7
Training loss: 1.526935338973999
Validation loss: 1.750033918247428

Epoch: 5| Step: 8
Training loss: 1.6460607051849365
Validation loss: 1.8118646426867413

Epoch: 5| Step: 9
Training loss: 1.4801350831985474
Validation loss: 1.8107385968649259

Epoch: 5| Step: 10
Training loss: 0.7792479991912842
Validation loss: 1.7889363176079207

Epoch: 413| Step: 0
Training loss: 1.8045740127563477
Validation loss: 1.860430371376776

Epoch: 5| Step: 1
Training loss: 1.2469708919525146
Validation loss: 1.8211851607086837

Epoch: 5| Step: 2
Training loss: 0.924557089805603
Validation loss: 1.7803534615424372

Epoch: 5| Step: 3
Training loss: 1.4026178121566772
Validation loss: 1.797362466012278

Epoch: 5| Step: 4
Training loss: 2.10953688621521
Validation loss: 1.7985509313562864

Epoch: 5| Step: 5
Training loss: 1.1061474084854126
Validation loss: 1.7878780980263986

Epoch: 5| Step: 6
Training loss: 1.4289295673370361
Validation loss: 1.7915695944140035

Epoch: 5| Step: 7
Training loss: 1.1143099069595337
Validation loss: 1.8191471151126328

Epoch: 5| Step: 8
Training loss: 1.1311166286468506
Validation loss: 1.7944590583924325

Epoch: 5| Step: 9
Training loss: 1.3331775665283203
Validation loss: 1.8141129029694425

Epoch: 5| Step: 10
Training loss: 1.6032116413116455
Validation loss: 1.8320131994062854

Epoch: 414| Step: 0
Training loss: 1.3977454900741577
Validation loss: 1.824009196732634

Epoch: 5| Step: 1
Training loss: 1.521806240081787
Validation loss: 1.7770330982823526

Epoch: 5| Step: 2
Training loss: 1.549705147743225
Validation loss: 1.7847707861213273

Epoch: 5| Step: 3
Training loss: 1.2223162651062012
Validation loss: 1.7954277710248066

Epoch: 5| Step: 4
Training loss: 1.1883131265640259
Validation loss: 1.7528598846927765

Epoch: 5| Step: 5
Training loss: 1.5844533443450928
Validation loss: 1.7890262052577028

Epoch: 5| Step: 6
Training loss: 1.0364573001861572
Validation loss: 1.8068029457522976

Epoch: 5| Step: 7
Training loss: 1.4875046014785767
Validation loss: 1.8167352907119259

Epoch: 5| Step: 8
Training loss: 1.0438427925109863
Validation loss: 1.8171339368307462

Epoch: 5| Step: 9
Training loss: 1.4312324523925781
Validation loss: 1.8134315577886437

Epoch: 5| Step: 10
Training loss: 1.8491209745407104
Validation loss: 1.8281651478941723

Epoch: 415| Step: 0
Training loss: 1.4025633335113525
Validation loss: 1.7747390911143313

Epoch: 5| Step: 1
Training loss: 1.5021867752075195
Validation loss: 1.807056188583374

Epoch: 5| Step: 2
Training loss: 1.2785011529922485
Validation loss: 1.767660605010166

Epoch: 5| Step: 3
Training loss: 1.5065288543701172
Validation loss: 1.7966916740581553

Epoch: 5| Step: 4
Training loss: 1.5029277801513672
Validation loss: 1.8160884085521902

Epoch: 5| Step: 5
Training loss: 1.393404245376587
Validation loss: 1.7931112794465915

Epoch: 5| Step: 6
Training loss: 1.2343939542770386
Validation loss: 1.7769362413755028

Epoch: 5| Step: 7
Training loss: 1.4326956272125244
Validation loss: 1.799270450427968

Epoch: 5| Step: 8
Training loss: 1.2674299478530884
Validation loss: 1.7898601896019393

Epoch: 5| Step: 9
Training loss: 1.0342023372650146
Validation loss: 1.7564748833256383

Epoch: 5| Step: 10
Training loss: 1.2623815536499023
Validation loss: 1.7970955102674422

Epoch: 416| Step: 0
Training loss: 1.3513524532318115
Validation loss: 1.7739946880648214

Epoch: 5| Step: 1
Training loss: 1.685197114944458
Validation loss: 1.7893589735031128

Epoch: 5| Step: 2
Training loss: 1.1818673610687256
Validation loss: 1.7855346202850342

Epoch: 5| Step: 3
Training loss: 0.6411685347557068
Validation loss: 1.8184327322949645

Epoch: 5| Step: 4
Training loss: 1.0167795419692993
Validation loss: 1.8110347588857014

Epoch: 5| Step: 5
Training loss: 1.2429378032684326
Validation loss: 1.8611969793996503

Epoch: 5| Step: 6
Training loss: 1.7313886880874634
Validation loss: 1.8135796951991257

Epoch: 5| Step: 7
Training loss: 1.4752159118652344
Validation loss: 1.8539274110588977

Epoch: 5| Step: 8
Training loss: 1.5343692302703857
Validation loss: 1.8152285801467074

Epoch: 5| Step: 9
Training loss: 1.5344386100769043
Validation loss: 1.8309186735460836

Epoch: 5| Step: 10
Training loss: 1.2953168153762817
Validation loss: 1.7865507166872743

Epoch: 417| Step: 0
Training loss: 1.204364538192749
Validation loss: 1.7360765792990243

Epoch: 5| Step: 1
Training loss: 1.0039702653884888
Validation loss: 1.7925886966848885

Epoch: 5| Step: 2
Training loss: 1.2879316806793213
Validation loss: 1.8272100443481116

Epoch: 5| Step: 3
Training loss: 1.2057164907455444
Validation loss: 1.788955165493873

Epoch: 5| Step: 4
Training loss: 1.6175577640533447
Validation loss: 1.7926811659207909

Epoch: 5| Step: 5
Training loss: 1.7038753032684326
Validation loss: 1.8076726621197117

Epoch: 5| Step: 6
Training loss: 1.3399690389633179
Validation loss: 1.7912291224284838

Epoch: 5| Step: 7
Training loss: 1.486838936805725
Validation loss: 1.8179512331562657

Epoch: 5| Step: 8
Training loss: 1.2326873540878296
Validation loss: 1.8059268010559903

Epoch: 5| Step: 9
Training loss: 1.5219241380691528
Validation loss: 1.7997367215412918

Epoch: 5| Step: 10
Training loss: 1.312037467956543
Validation loss: 1.7878375950679983

Epoch: 418| Step: 0
Training loss: 1.7092291116714478
Validation loss: 1.7981868046586231

Epoch: 5| Step: 1
Training loss: 1.5089893341064453
Validation loss: 1.79666522882318

Epoch: 5| Step: 2
Training loss: 1.3122727870941162
Validation loss: 1.7839922610149588

Epoch: 5| Step: 3
Training loss: 0.8318315744400024
Validation loss: 1.8218985578065277

Epoch: 5| Step: 4
Training loss: 1.174706220626831
Validation loss: 1.808962166950267

Epoch: 5| Step: 5
Training loss: 1.4452595710754395
Validation loss: 1.8544837826041765

Epoch: 5| Step: 6
Training loss: 1.1285969018936157
Validation loss: 1.8129277742037209

Epoch: 5| Step: 7
Training loss: 1.3096319437026978
Validation loss: 1.7703914270606091

Epoch: 5| Step: 8
Training loss: 1.1563928127288818
Validation loss: 1.7837040808893019

Epoch: 5| Step: 9
Training loss: 1.6127687692642212
Validation loss: 1.7900419632593791

Epoch: 5| Step: 10
Training loss: 1.5370045900344849
Validation loss: 1.8424072214352187

Epoch: 419| Step: 0
Training loss: 1.1256738901138306
Validation loss: 1.7649447969211045

Epoch: 5| Step: 1
Training loss: 1.5086686611175537
Validation loss: 1.8184532324473064

Epoch: 5| Step: 2
Training loss: 0.9455547332763672
Validation loss: 1.809225897635183

Epoch: 5| Step: 3
Training loss: 1.6858930587768555
Validation loss: 1.7852580688333

Epoch: 5| Step: 4
Training loss: 1.5380752086639404
Validation loss: 1.7959301176891531

Epoch: 5| Step: 5
Training loss: 1.0482683181762695
Validation loss: 1.8424475962115872

Epoch: 5| Step: 6
Training loss: 1.3470178842544556
Validation loss: 1.8437794434126986

Epoch: 5| Step: 7
Training loss: 1.0189834833145142
Validation loss: 1.8107037339159238

Epoch: 5| Step: 8
Training loss: 1.542855978012085
Validation loss: 1.784903851888513

Epoch: 5| Step: 9
Training loss: 1.292372226715088
Validation loss: 1.7765756614746586

Epoch: 5| Step: 10
Training loss: 1.5373506546020508
Validation loss: 1.7794565077750915

Epoch: 420| Step: 0
Training loss: 1.513745903968811
Validation loss: 1.8156558903314735

Epoch: 5| Step: 1
Training loss: 1.0979034900665283
Validation loss: 1.8464278969713437

Epoch: 5| Step: 2
Training loss: 1.2439535856246948
Validation loss: 1.7531488813379759

Epoch: 5| Step: 3
Training loss: 1.352299451828003
Validation loss: 1.7829799754645235

Epoch: 5| Step: 4
Training loss: 1.2766813039779663
Validation loss: 1.804085116232595

Epoch: 5| Step: 5
Training loss: 1.5112154483795166
Validation loss: 1.7843505259483092

Epoch: 5| Step: 6
Training loss: 0.9972052574157715
Validation loss: 1.8008613842789845

Epoch: 5| Step: 7
Training loss: 1.5972172021865845
Validation loss: 1.8084230422973633

Epoch: 5| Step: 8
Training loss: 1.5209746360778809
Validation loss: 1.792886221280662

Epoch: 5| Step: 9
Training loss: 1.4856836795806885
Validation loss: 1.766687132978952

Epoch: 5| Step: 10
Training loss: 1.493779182434082
Validation loss: 1.8049016896114554

Epoch: 421| Step: 0
Training loss: 1.3416244983673096
Validation loss: 1.7504882658681562

Epoch: 5| Step: 1
Training loss: 1.4119031429290771
Validation loss: 1.8253205412177629

Epoch: 5| Step: 2
Training loss: 1.5040688514709473
Validation loss: 1.7925885338937082

Epoch: 5| Step: 3
Training loss: 1.0967860221862793
Validation loss: 1.827397543896911

Epoch: 5| Step: 4
Training loss: 0.7950664162635803
Validation loss: 1.7954422645671393

Epoch: 5| Step: 5
Training loss: 1.6627222299575806
Validation loss: 1.840435245985626

Epoch: 5| Step: 6
Training loss: 1.749853491783142
Validation loss: 1.8024598116515784

Epoch: 5| Step: 7
Training loss: 1.4989837408065796
Validation loss: 1.8120729179792507

Epoch: 5| Step: 8
Training loss: 1.241835117340088
Validation loss: 1.821147762319093

Epoch: 5| Step: 9
Training loss: 1.2401902675628662
Validation loss: 1.7420047867682673

Epoch: 5| Step: 10
Training loss: 1.2573331594467163
Validation loss: 1.819456656773885

Epoch: 422| Step: 0
Training loss: 1.0785483121871948
Validation loss: 1.7770386152370001

Epoch: 5| Step: 1
Training loss: 1.0452702045440674
Validation loss: 1.7870082342496483

Epoch: 5| Step: 2
Training loss: 1.6629806756973267
Validation loss: 1.7732163526678597

Epoch: 5| Step: 3
Training loss: 1.1364786624908447
Validation loss: 1.7718860833875594

Epoch: 5| Step: 4
Training loss: 1.3166553974151611
Validation loss: 1.8240774677645775

Epoch: 5| Step: 5
Training loss: 1.2116951942443848
Validation loss: 1.8219758643898913

Epoch: 5| Step: 6
Training loss: 0.9594663381576538
Validation loss: 1.7820514350809076

Epoch: 5| Step: 7
Training loss: 1.0698528289794922
Validation loss: 1.7660199826763523

Epoch: 5| Step: 8
Training loss: 1.6243442296981812
Validation loss: 1.8175616815526

Epoch: 5| Step: 9
Training loss: 1.3964288234710693
Validation loss: 1.832279871868831

Epoch: 5| Step: 10
Training loss: 2.084047317504883
Validation loss: 1.806117219309653

Epoch: 423| Step: 0
Training loss: 1.2916203737258911
Validation loss: 1.8031916592710762

Epoch: 5| Step: 1
Training loss: 1.1756112575531006
Validation loss: 1.8464132278196272

Epoch: 5| Step: 2
Training loss: 1.20367431640625
Validation loss: 1.754713475063283

Epoch: 5| Step: 3
Training loss: 1.3789314031600952
Validation loss: 1.7801528451263264

Epoch: 5| Step: 4
Training loss: 1.2998446226119995
Validation loss: 1.7646844669054913

Epoch: 5| Step: 5
Training loss: 1.4331648349761963
Validation loss: 1.7964874236814437

Epoch: 5| Step: 6
Training loss: 1.020937204360962
Validation loss: 1.7989757419914327

Epoch: 5| Step: 7
Training loss: 1.5126618146896362
Validation loss: 1.7977024021969046

Epoch: 5| Step: 8
Training loss: 1.7038567066192627
Validation loss: 1.7612543516261603

Epoch: 5| Step: 9
Training loss: 1.6228246688842773
Validation loss: 1.803887794094701

Epoch: 5| Step: 10
Training loss: 1.3089265823364258
Validation loss: 1.7689435687116397

Epoch: 424| Step: 0
Training loss: 0.9851062893867493
Validation loss: 1.839779201374259

Epoch: 5| Step: 1
Training loss: 1.3791205883026123
Validation loss: 1.8206247296384586

Epoch: 5| Step: 2
Training loss: 1.3445053100585938
Validation loss: 1.829819433150753

Epoch: 5| Step: 3
Training loss: 1.0364590883255005
Validation loss: 1.7928199332247499

Epoch: 5| Step: 4
Training loss: 1.1596615314483643
Validation loss: 1.7713238039324362

Epoch: 5| Step: 5
Training loss: 1.5482805967330933
Validation loss: 1.836453942842381

Epoch: 5| Step: 6
Training loss: 1.7860500812530518
Validation loss: 1.864207208797496

Epoch: 5| Step: 7
Training loss: 1.5328117609024048
Validation loss: 1.8549315698685185

Epoch: 5| Step: 8
Training loss: 1.3691880702972412
Validation loss: 1.861679942377152

Epoch: 5| Step: 9
Training loss: 1.2795437574386597
Validation loss: 1.8260723288341234

Epoch: 5| Step: 10
Training loss: 1.322663426399231
Validation loss: 1.7964137215768137

Epoch: 425| Step: 0
Training loss: 1.00750732421875
Validation loss: 1.8232205144820675

Epoch: 5| Step: 1
Training loss: 1.6989866495132446
Validation loss: 1.7963475899029804

Epoch: 5| Step: 2
Training loss: 1.266395926475525
Validation loss: 1.80969440039768

Epoch: 5| Step: 3
Training loss: 1.1051064729690552
Validation loss: 1.7625196569709367

Epoch: 5| Step: 4
Training loss: 1.2251540422439575
Validation loss: 1.799907729189883

Epoch: 5| Step: 5
Training loss: 1.6934341192245483
Validation loss: 1.788453878894929

Epoch: 5| Step: 6
Training loss: 1.951162338256836
Validation loss: 1.823804909183133

Epoch: 5| Step: 7
Training loss: 1.0085537433624268
Validation loss: 1.7824818036889518

Epoch: 5| Step: 8
Training loss: 1.234533429145813
Validation loss: 1.8150501546039377

Epoch: 5| Step: 9
Training loss: 1.2994714975357056
Validation loss: 1.824850910453386

Epoch: 5| Step: 10
Training loss: 1.019525408744812
Validation loss: 1.7658163847461823

Epoch: 426| Step: 0
Training loss: 0.9322481155395508
Validation loss: 1.8023619767158263

Epoch: 5| Step: 1
Training loss: 1.3063042163848877
Validation loss: 1.8099655464131346

Epoch: 5| Step: 2
Training loss: 1.1379766464233398
Validation loss: 1.7466970759053384

Epoch: 5| Step: 3
Training loss: 1.5868804454803467
Validation loss: 1.798773370763307

Epoch: 5| Step: 4
Training loss: 1.5474637746810913
Validation loss: 1.8177618749680058

Epoch: 5| Step: 5
Training loss: 0.9400316476821899
Validation loss: 1.7838301863721622

Epoch: 5| Step: 6
Training loss: 1.6058824062347412
Validation loss: 1.7906974784789547

Epoch: 5| Step: 7
Training loss: 1.1934692859649658
Validation loss: 1.801996100333429

Epoch: 5| Step: 8
Training loss: 1.3361585140228271
Validation loss: 1.790531232792844

Epoch: 5| Step: 9
Training loss: 1.2451379299163818
Validation loss: 1.7920394687242405

Epoch: 5| Step: 10
Training loss: 1.7335362434387207
Validation loss: 1.813660462697347

Epoch: 427| Step: 0
Training loss: 1.7122318744659424
Validation loss: 1.8030390201076385

Epoch: 5| Step: 1
Training loss: 1.4339675903320312
Validation loss: 1.7787432311683573

Epoch: 5| Step: 2
Training loss: 1.4181650876998901
Validation loss: 1.7935075272795975

Epoch: 5| Step: 3
Training loss: 1.4393483400344849
Validation loss: 1.79472311722335

Epoch: 5| Step: 4
Training loss: 1.5504776239395142
Validation loss: 1.8034748774702831

Epoch: 5| Step: 5
Training loss: 1.0817209482192993
Validation loss: 1.7857686255567817

Epoch: 5| Step: 6
Training loss: 1.0314385890960693
Validation loss: 1.8031552709558958

Epoch: 5| Step: 7
Training loss: 1.270775318145752
Validation loss: 1.76685090731549

Epoch: 5| Step: 8
Training loss: 1.2388523817062378
Validation loss: 1.8055918844797278

Epoch: 5| Step: 9
Training loss: 0.826882004737854
Validation loss: 1.781467536444305

Epoch: 5| Step: 10
Training loss: 1.1627767086029053
Validation loss: 1.8295915434437413

Epoch: 428| Step: 0
Training loss: 1.097292423248291
Validation loss: 1.8429439260113625

Epoch: 5| Step: 1
Training loss: 1.6097828149795532
Validation loss: 1.8067916131788684

Epoch: 5| Step: 2
Training loss: 0.8654731512069702
Validation loss: 1.765785114739531

Epoch: 5| Step: 3
Training loss: 1.6917461156845093
Validation loss: 1.7437211935238173

Epoch: 5| Step: 4
Training loss: 1.0158791542053223
Validation loss: 1.8141604341486448

Epoch: 5| Step: 5
Training loss: 0.7844502329826355
Validation loss: 1.7882728922751643

Epoch: 5| Step: 6
Training loss: 1.2346525192260742
Validation loss: 1.7850242212254515

Epoch: 5| Step: 7
Training loss: 1.1108275651931763
Validation loss: 1.803631341585549

Epoch: 5| Step: 8
Training loss: 2.2249653339385986
Validation loss: 1.809550069993542

Epoch: 5| Step: 9
Training loss: 1.4826794862747192
Validation loss: 1.8172256010834889

Epoch: 5| Step: 10
Training loss: 1.2760831117630005
Validation loss: 1.8339190739457325

Epoch: 429| Step: 0
Training loss: 0.9485836029052734
Validation loss: 1.8339607279787782

Epoch: 5| Step: 1
Training loss: 1.0776540040969849
Validation loss: 1.8236338118071198

Epoch: 5| Step: 2
Training loss: 1.293912649154663
Validation loss: 1.8183633204429381

Epoch: 5| Step: 3
Training loss: 1.2542998790740967
Validation loss: 1.8042604000337663

Epoch: 5| Step: 4
Training loss: 1.1094509363174438
Validation loss: 1.8458905681487052

Epoch: 5| Step: 5
Training loss: 1.1134159564971924
Validation loss: 1.7493394382538334

Epoch: 5| Step: 6
Training loss: 1.0276134014129639
Validation loss: 1.7988504671281385

Epoch: 5| Step: 7
Training loss: 1.0001603364944458
Validation loss: 1.806739161091466

Epoch: 5| Step: 8
Training loss: 2.183887004852295
Validation loss: 1.8467848416297667

Epoch: 5| Step: 9
Training loss: 1.8396075963974
Validation loss: 1.7963131191909953

Epoch: 5| Step: 10
Training loss: 1.5222549438476562
Validation loss: 1.8024674859098209

Epoch: 430| Step: 0
Training loss: 1.1690601110458374
Validation loss: 1.819268589378685

Epoch: 5| Step: 1
Training loss: 1.1510273218154907
Validation loss: 1.8194518294385684

Epoch: 5| Step: 2
Training loss: 1.3189985752105713
Validation loss: 1.8046179804750668

Epoch: 5| Step: 3
Training loss: 1.2710261344909668
Validation loss: 1.7961865163618518

Epoch: 5| Step: 4
Training loss: 1.948265790939331
Validation loss: 1.7829762786947272

Epoch: 5| Step: 5
Training loss: 1.5184334516525269
Validation loss: 1.8450428631997877

Epoch: 5| Step: 6
Training loss: 1.428043246269226
Validation loss: 1.8245111139871741

Epoch: 5| Step: 7
Training loss: 1.4980289936065674
Validation loss: 1.8147804865273096

Epoch: 5| Step: 8
Training loss: 1.4738117456436157
Validation loss: 1.7975560131893362

Epoch: 5| Step: 9
Training loss: 1.1114579439163208
Validation loss: 1.830714225769043

Epoch: 5| Step: 10
Training loss: 0.7229056358337402
Validation loss: 1.8025203417706233

Epoch: 431| Step: 0
Training loss: 1.2913062572479248
Validation loss: 1.857184935641545

Epoch: 5| Step: 1
Training loss: 1.9416850805282593
Validation loss: 1.8083391330575431

Epoch: 5| Step: 2
Training loss: 1.0968751907348633
Validation loss: 1.816976821550759

Epoch: 5| Step: 3
Training loss: 1.0456435680389404
Validation loss: 1.7737475710530435

Epoch: 5| Step: 4
Training loss: 1.6306145191192627
Validation loss: 1.8042182460907967

Epoch: 5| Step: 5
Training loss: 1.378587007522583
Validation loss: 1.7687812748775686

Epoch: 5| Step: 6
Training loss: 1.038236379623413
Validation loss: 1.7995605443113594

Epoch: 5| Step: 7
Training loss: 1.2983478307724
Validation loss: 1.8282897856927687

Epoch: 5| Step: 8
Training loss: 1.2746660709381104
Validation loss: 1.7890468105193107

Epoch: 5| Step: 9
Training loss: 1.438503623008728
Validation loss: 1.784489434252503

Epoch: 5| Step: 10
Training loss: 0.8039840459823608
Validation loss: 1.8040030643504152

Epoch: 432| Step: 0
Training loss: 1.008529543876648
Validation loss: 1.721181429842467

Epoch: 5| Step: 1
Training loss: 0.964411735534668
Validation loss: 1.822418705109627

Epoch: 5| Step: 2
Training loss: 1.5623042583465576
Validation loss: 1.770823291552964

Epoch: 5| Step: 3
Training loss: 1.6151460409164429
Validation loss: 1.8278914933563561

Epoch: 5| Step: 4
Training loss: 1.668029546737671
Validation loss: 1.8421000447324527

Epoch: 5| Step: 5
Training loss: 1.0230872631072998
Validation loss: 1.811503905121998

Epoch: 5| Step: 6
Training loss: 1.8339115381240845
Validation loss: 1.8411856774360902

Epoch: 5| Step: 7
Training loss: 1.5573537349700928
Validation loss: 1.7555003858381701

Epoch: 5| Step: 8
Training loss: 0.7323457598686218
Validation loss: 1.747936092397218

Epoch: 5| Step: 9
Training loss: 0.962117075920105
Validation loss: 1.7522248119436286

Epoch: 5| Step: 10
Training loss: 1.6758794784545898
Validation loss: 1.820814489036478

Epoch: 433| Step: 0
Training loss: 0.8422943353652954
Validation loss: 1.7812441946357809

Epoch: 5| Step: 1
Training loss: 1.2436186075210571
Validation loss: 1.7731571735874299

Epoch: 5| Step: 2
Training loss: 1.9057254791259766
Validation loss: 1.814594994309128

Epoch: 5| Step: 3
Training loss: 1.2953932285308838
Validation loss: 1.789862318705487

Epoch: 5| Step: 4
Training loss: 1.174547553062439
Validation loss: 1.7671993663234096

Epoch: 5| Step: 5
Training loss: 1.1128509044647217
Validation loss: 1.8125717345104422

Epoch: 5| Step: 6
Training loss: 1.5637311935424805
Validation loss: 1.8289594804086993

Epoch: 5| Step: 7
Training loss: 1.7089664936065674
Validation loss: 1.7939532777314544

Epoch: 5| Step: 8
Training loss: 1.171078085899353
Validation loss: 1.760626862126012

Epoch: 5| Step: 9
Training loss: 1.3004957437515259
Validation loss: 1.7969345636265253

Epoch: 5| Step: 10
Training loss: 1.014054298400879
Validation loss: 1.794962361294736

Epoch: 434| Step: 0
Training loss: 1.115902304649353
Validation loss: 1.78099343469066

Epoch: 5| Step: 1
Training loss: 1.1763249635696411
Validation loss: 1.8081195995371828

Epoch: 5| Step: 2
Training loss: 1.190138339996338
Validation loss: 1.7964839243119763

Epoch: 5| Step: 3
Training loss: 1.6959850788116455
Validation loss: 1.776510730866463

Epoch: 5| Step: 4
Training loss: 1.2943494319915771
Validation loss: 1.8472745367275771

Epoch: 5| Step: 5
Training loss: 1.3652122020721436
Validation loss: 1.7827871307249992

Epoch: 5| Step: 6
Training loss: 1.8229128122329712
Validation loss: 1.8232391265130812

Epoch: 5| Step: 7
Training loss: 1.6524375677108765
Validation loss: 1.7681463264649915

Epoch: 5| Step: 8
Training loss: 0.6051949262619019
Validation loss: 1.8188497609989618

Epoch: 5| Step: 9
Training loss: 0.8726853132247925
Validation loss: 1.7996306855191466

Epoch: 5| Step: 10
Training loss: 1.5137749910354614
Validation loss: 1.8155624174302625

Epoch: 435| Step: 0
Training loss: 1.1033846139907837
Validation loss: 1.732072199544599

Epoch: 5| Step: 1
Training loss: 1.3433191776275635
Validation loss: 1.8132932468127179

Epoch: 5| Step: 2
Training loss: 1.4502838850021362
Validation loss: 1.7861806474706179

Epoch: 5| Step: 3
Training loss: 0.9912439584732056
Validation loss: 1.7974738536342498

Epoch: 5| Step: 4
Training loss: 1.6084797382354736
Validation loss: 1.826043657077256

Epoch: 5| Step: 5
Training loss: 1.5937646627426147
Validation loss: 1.8277110271556403

Epoch: 5| Step: 6
Training loss: 1.2258193492889404
Validation loss: 1.8099431132757535

Epoch: 5| Step: 7
Training loss: 1.2667897939682007
Validation loss: 1.8162017791501937

Epoch: 5| Step: 8
Training loss: 1.458668828010559
Validation loss: 1.8335053369563112

Epoch: 5| Step: 9
Training loss: 1.2250862121582031
Validation loss: 1.7937444025470364

Epoch: 5| Step: 10
Training loss: 1.2483539581298828
Validation loss: 1.777426585074394

Epoch: 436| Step: 0
Training loss: 1.6226694583892822
Validation loss: 1.818296855495822

Epoch: 5| Step: 1
Training loss: 1.0614230632781982
Validation loss: 1.858276682515298

Epoch: 5| Step: 2
Training loss: 1.3005602359771729
Validation loss: 1.7528170539486794

Epoch: 5| Step: 3
Training loss: 1.0535327196121216
Validation loss: 1.838566860845012

Epoch: 5| Step: 4
Training loss: 1.1470215320587158
Validation loss: 1.7977434999199324

Epoch: 5| Step: 5
Training loss: 1.6984941959381104
Validation loss: 1.8133904267382879

Epoch: 5| Step: 6
Training loss: 1.580909252166748
Validation loss: 1.7719913759539205

Epoch: 5| Step: 7
Training loss: 1.2377642393112183
Validation loss: 1.810048016168738

Epoch: 5| Step: 8
Training loss: 1.101045846939087
Validation loss: 1.8128950031854774

Epoch: 5| Step: 9
Training loss: 1.2250455617904663
Validation loss: 1.765038239058628

Epoch: 5| Step: 10
Training loss: 1.2973629236221313
Validation loss: 1.7681147475396433

Epoch: 437| Step: 0
Training loss: 1.5152559280395508
Validation loss: 1.7329116777707172

Epoch: 5| Step: 1
Training loss: 1.3310216665267944
Validation loss: 1.7982349395751953

Epoch: 5| Step: 2
Training loss: 0.971428394317627
Validation loss: 1.7758513637768325

Epoch: 5| Step: 3
Training loss: 1.6355739831924438
Validation loss: 1.7816270653919508

Epoch: 5| Step: 4
Training loss: 1.4065946340560913
Validation loss: 1.7939172124349942

Epoch: 5| Step: 5
Training loss: 1.1205757856369019
Validation loss: 1.7855368891069967

Epoch: 5| Step: 6
Training loss: 1.6241604089736938
Validation loss: 1.763196559362514

Epoch: 5| Step: 7
Training loss: 1.3516327142715454
Validation loss: 1.7871362445175007

Epoch: 5| Step: 8
Training loss: 1.4687856435775757
Validation loss: 1.821522387125159

Epoch: 5| Step: 9
Training loss: 0.7261155247688293
Validation loss: 1.8029281759774813

Epoch: 5| Step: 10
Training loss: 1.0949152708053589
Validation loss: 1.838546379919975

Epoch: 438| Step: 0
Training loss: 1.6668806076049805
Validation loss: 1.8074453658955072

Epoch: 5| Step: 1
Training loss: 1.562991738319397
Validation loss: 1.7759410283898796

Epoch: 5| Step: 2
Training loss: 1.0747591257095337
Validation loss: 1.8359091461345713

Epoch: 5| Step: 3
Training loss: 1.0280654430389404
Validation loss: 1.8474231766116234

Epoch: 5| Step: 4
Training loss: 1.1770896911621094
Validation loss: 1.8130879812343146

Epoch: 5| Step: 5
Training loss: 0.8542041778564453
Validation loss: 1.8504784004662627

Epoch: 5| Step: 6
Training loss: 1.6841634511947632
Validation loss: 1.8256353691060057

Epoch: 5| Step: 7
Training loss: 1.3517271280288696
Validation loss: 1.7544517183816561

Epoch: 5| Step: 8
Training loss: 0.9317167401313782
Validation loss: 1.7768825074677825

Epoch: 5| Step: 9
Training loss: 1.316110610961914
Validation loss: 1.81471925140709

Epoch: 5| Step: 10
Training loss: 1.3845144510269165
Validation loss: 1.7823313795110232

Epoch: 439| Step: 0
Training loss: 1.0149812698364258
Validation loss: 1.7702021573179512

Epoch: 5| Step: 1
Training loss: 1.6763837337493896
Validation loss: 1.7992495311203824

Epoch: 5| Step: 2
Training loss: 1.1863502264022827
Validation loss: 1.8245686241375503

Epoch: 5| Step: 3
Training loss: 1.2019588947296143
Validation loss: 1.773371168362197

Epoch: 5| Step: 4
Training loss: 0.858028769493103
Validation loss: 1.8175899905543174

Epoch: 5| Step: 5
Training loss: 1.0285496711730957
Validation loss: 1.7644455637983096

Epoch: 5| Step: 6
Training loss: 1.4951671361923218
Validation loss: 1.7812963198590022

Epoch: 5| Step: 7
Training loss: 1.2329250574111938
Validation loss: 1.8053337194586312

Epoch: 5| Step: 8
Training loss: 1.4520282745361328
Validation loss: 1.77440950434695

Epoch: 5| Step: 9
Training loss: 1.3729193210601807
Validation loss: 1.7828942114307034

Epoch: 5| Step: 10
Training loss: 1.460892677307129
Validation loss: 1.7596755079043809

Epoch: 440| Step: 0
Training loss: 1.211057424545288
Validation loss: 1.7876914701154154

Epoch: 5| Step: 1
Training loss: 1.2912700176239014
Validation loss: 1.8322497362731605

Epoch: 5| Step: 2
Training loss: 1.7757952213287354
Validation loss: 1.8041229401865313

Epoch: 5| Step: 3
Training loss: 0.9630638360977173
Validation loss: 1.8157257546660721

Epoch: 5| Step: 4
Training loss: 1.1988133192062378
Validation loss: 1.8492388084370603

Epoch: 5| Step: 5
Training loss: 1.1876295804977417
Validation loss: 1.817981994280251

Epoch: 5| Step: 6
Training loss: 1.1472960710525513
Validation loss: 1.8237791087037774

Epoch: 5| Step: 7
Training loss: 1.5041561126708984
Validation loss: 1.7777536607557727

Epoch: 5| Step: 8
Training loss: 0.7317045331001282
Validation loss: 1.7993842017266057

Epoch: 5| Step: 9
Training loss: 1.5547701120376587
Validation loss: 1.7902586306295087

Epoch: 5| Step: 10
Training loss: 1.6100726127624512
Validation loss: 1.7519963223447081

Epoch: 441| Step: 0
Training loss: 1.284272313117981
Validation loss: 1.8453948113226122

Epoch: 5| Step: 1
Training loss: 1.166189193725586
Validation loss: 1.7992021870869461

Epoch: 5| Step: 2
Training loss: 1.2463538646697998
Validation loss: 1.8393222414037234

Epoch: 5| Step: 3
Training loss: 0.8453992605209351
Validation loss: 1.8861990103157618

Epoch: 5| Step: 4
Training loss: 1.400022268295288
Validation loss: 1.8009885741818337

Epoch: 5| Step: 5
Training loss: 1.9615089893341064
Validation loss: 1.8379620082916752

Epoch: 5| Step: 6
Training loss: 0.9369695782661438
Validation loss: 1.8080935862756544

Epoch: 5| Step: 7
Training loss: 1.0403625965118408
Validation loss: 1.797171672185262

Epoch: 5| Step: 8
Training loss: 1.3951233625411987
Validation loss: 1.7795005331757248

Epoch: 5| Step: 9
Training loss: 1.8319175243377686
Validation loss: 1.7950535679376254

Epoch: 5| Step: 10
Training loss: 1.232544183731079
Validation loss: 1.8220953056889195

Epoch: 442| Step: 0
Training loss: 1.1196491718292236
Validation loss: 1.829605794722034

Epoch: 5| Step: 1
Training loss: 1.2035462856292725
Validation loss: 1.8281269329850391

Epoch: 5| Step: 2
Training loss: 1.256441354751587
Validation loss: 1.8064609355823968

Epoch: 5| Step: 3
Training loss: 1.1806942224502563
Validation loss: 1.8446277187716575

Epoch: 5| Step: 4
Training loss: 1.1091164350509644
Validation loss: 1.7967974729435419

Epoch: 5| Step: 5
Training loss: 1.1833577156066895
Validation loss: 1.790213664372762

Epoch: 5| Step: 6
Training loss: 1.614619493484497
Validation loss: 1.8339475739386775

Epoch: 5| Step: 7
Training loss: 1.6904054880142212
Validation loss: 1.826694555180047

Epoch: 5| Step: 8
Training loss: 1.820180892944336
Validation loss: 1.759503496590481

Epoch: 5| Step: 9
Training loss: 1.135877013206482
Validation loss: 1.7675085683022775

Epoch: 5| Step: 10
Training loss: 0.9412123560905457
Validation loss: 1.7826498631508119

Epoch: 443| Step: 0
Training loss: 1.1912524700164795
Validation loss: 1.7849909220972369

Epoch: 5| Step: 1
Training loss: 1.1285836696624756
Validation loss: 1.8399161792570544

Epoch: 5| Step: 2
Training loss: 0.9743798971176147
Validation loss: 1.8496449621774818

Epoch: 5| Step: 3
Training loss: 1.766180396080017
Validation loss: 1.8511512228237685

Epoch: 5| Step: 4
Training loss: 1.340411901473999
Validation loss: 1.8447590899723831

Epoch: 5| Step: 5
Training loss: 1.1474534273147583
Validation loss: 1.810501592133635

Epoch: 5| Step: 6
Training loss: 1.4467189311981201
Validation loss: 1.8181609953603437

Epoch: 5| Step: 7
Training loss: 1.109970211982727
Validation loss: 1.8138587577368623

Epoch: 5| Step: 8
Training loss: 1.7570421695709229
Validation loss: 1.8675614262139926

Epoch: 5| Step: 9
Training loss: 0.9434040188789368
Validation loss: 1.8475621989978257

Epoch: 5| Step: 10
Training loss: 1.651381492614746
Validation loss: 1.7639343136100358

Epoch: 444| Step: 0
Training loss: 0.7956579923629761
Validation loss: 1.8097643089550797

Epoch: 5| Step: 1
Training loss: 1.3319737911224365
Validation loss: 1.8217355128257506

Epoch: 5| Step: 2
Training loss: 1.1745296716690063
Validation loss: 1.7686401336423812

Epoch: 5| Step: 3
Training loss: 1.2263939380645752
Validation loss: 1.8038396002143942

Epoch: 5| Step: 4
Training loss: 1.4193638563156128
Validation loss: 1.7734599677465295

Epoch: 5| Step: 5
Training loss: 1.2314671277999878
Validation loss: 1.815514091522463

Epoch: 5| Step: 6
Training loss: 0.9871265292167664
Validation loss: 1.795466649916864

Epoch: 5| Step: 7
Training loss: 1.7626609802246094
Validation loss: 1.7809212182157783

Epoch: 5| Step: 8
Training loss: 1.2597520351409912
Validation loss: 1.8580519050680182

Epoch: 5| Step: 9
Training loss: 1.928636908531189
Validation loss: 1.8053617785053868

Epoch: 5| Step: 10
Training loss: 1.0720088481903076
Validation loss: 1.7815901810123074

Epoch: 445| Step: 0
Training loss: 1.3280692100524902
Validation loss: 1.7646572564237861

Epoch: 5| Step: 1
Training loss: 0.9309539794921875
Validation loss: 1.749885465509148

Epoch: 5| Step: 2
Training loss: 0.8353394269943237
Validation loss: 1.8508452279593355

Epoch: 5| Step: 3
Training loss: 1.0369949340820312
Validation loss: 1.785545245293648

Epoch: 5| Step: 4
Training loss: 1.356589913368225
Validation loss: 1.7887754927399337

Epoch: 5| Step: 5
Training loss: 1.9435093402862549
Validation loss: 1.8031556555019912

Epoch: 5| Step: 6
Training loss: 0.8207294344902039
Validation loss: 1.7714834161984023

Epoch: 5| Step: 7
Training loss: 1.556307077407837
Validation loss: 1.816207698596421

Epoch: 5| Step: 8
Training loss: 1.0069029331207275
Validation loss: 1.8217938125774424

Epoch: 5| Step: 9
Training loss: 1.211069941520691
Validation loss: 1.770113609170401

Epoch: 5| Step: 10
Training loss: 1.5979363918304443
Validation loss: 1.8266535958936136

Epoch: 446| Step: 0
Training loss: 1.5320268869400024
Validation loss: 1.8406934263885661

Epoch: 5| Step: 1
Training loss: 1.7815592288970947
Validation loss: 1.8171648402367868

Epoch: 5| Step: 2
Training loss: 0.6970181465148926
Validation loss: 1.7797260463878672

Epoch: 5| Step: 3
Training loss: 1.7163053750991821
Validation loss: 1.7514791821920743

Epoch: 5| Step: 4
Training loss: 1.1574105024337769
Validation loss: 1.8150181231960174

Epoch: 5| Step: 5
Training loss: 1.2964388132095337
Validation loss: 1.7830354629024383

Epoch: 5| Step: 6
Training loss: 1.1811977624893188
Validation loss: 1.8041898127525084

Epoch: 5| Step: 7
Training loss: 1.1307202577590942
Validation loss: 1.7939466045748802

Epoch: 5| Step: 8
Training loss: 1.1022812128067017
Validation loss: 1.808568682721866

Epoch: 5| Step: 9
Training loss: 1.313326120376587
Validation loss: 1.7952952256766699

Epoch: 5| Step: 10
Training loss: 1.338704228401184
Validation loss: 1.8389137714139876

Epoch: 447| Step: 0
Training loss: 1.3695493936538696
Validation loss: 1.7516613967957035

Epoch: 5| Step: 1
Training loss: 1.8149166107177734
Validation loss: 1.7605459843912432

Epoch: 5| Step: 2
Training loss: 1.2329775094985962
Validation loss: 1.8222823527551466

Epoch: 5| Step: 3
Training loss: 0.9936019778251648
Validation loss: 1.794659504326441

Epoch: 5| Step: 4
Training loss: 0.911350429058075
Validation loss: 1.8269008257055794

Epoch: 5| Step: 5
Training loss: 0.9666614532470703
Validation loss: 1.8199981502307359

Epoch: 5| Step: 6
Training loss: 1.2846211194992065
Validation loss: 1.7612951609396166

Epoch: 5| Step: 7
Training loss: 1.3446769714355469
Validation loss: 1.7420789259736256

Epoch: 5| Step: 8
Training loss: 1.5147290229797363
Validation loss: 1.8429069608770392

Epoch: 5| Step: 9
Training loss: 1.0793262720108032
Validation loss: 1.8058307017049482

Epoch: 5| Step: 10
Training loss: 1.5068844556808472
Validation loss: 1.7857656273790585

Epoch: 448| Step: 0
Training loss: 1.7921310663223267
Validation loss: 1.7697989286914948

Epoch: 5| Step: 1
Training loss: 1.7575451135635376
Validation loss: 1.8760250332534953

Epoch: 5| Step: 2
Training loss: 1.3424590826034546
Validation loss: 1.8574738015410721

Epoch: 5| Step: 3
Training loss: 1.3056814670562744
Validation loss: 1.8005896229897775

Epoch: 5| Step: 4
Training loss: 0.8656076192855835
Validation loss: 1.8222912511517924

Epoch: 5| Step: 5
Training loss: 1.0407768487930298
Validation loss: 1.7978122452253937

Epoch: 5| Step: 6
Training loss: 1.1267423629760742
Validation loss: 1.776389753946694

Epoch: 5| Step: 7
Training loss: 1.0157536268234253
Validation loss: 1.7507643033099431

Epoch: 5| Step: 8
Training loss: 0.8208196759223938
Validation loss: 1.8150393847496278

Epoch: 5| Step: 9
Training loss: 1.1511765718460083
Validation loss: 1.790024652275988

Epoch: 5| Step: 10
Training loss: 1.6273671388626099
Validation loss: 1.824195396515631

Epoch: 449| Step: 0
Training loss: 1.1087929010391235
Validation loss: 1.8066200056383688

Epoch: 5| Step: 1
Training loss: 1.0075987577438354
Validation loss: 1.7697128685571815

Epoch: 5| Step: 2
Training loss: 0.9739490747451782
Validation loss: 1.798958005443696

Epoch: 5| Step: 3
Training loss: 1.0946506261825562
Validation loss: 1.824737556519047

Epoch: 5| Step: 4
Training loss: 1.6043899059295654
Validation loss: 1.7452203394264303

Epoch: 5| Step: 5
Training loss: 1.4636173248291016
Validation loss: 1.853192380679551

Epoch: 5| Step: 6
Training loss: 1.4387295246124268
Validation loss: 1.776902792274311

Epoch: 5| Step: 7
Training loss: 1.394197940826416
Validation loss: 1.760012936848466

Epoch: 5| Step: 8
Training loss: 0.9588411450386047
Validation loss: 1.8278195819547098

Epoch: 5| Step: 9
Training loss: 1.212311863899231
Validation loss: 1.793440225303814

Epoch: 5| Step: 10
Training loss: 1.549216866493225
Validation loss: 1.8645862635745798

Epoch: 450| Step: 0
Training loss: 1.4310781955718994
Validation loss: 1.798598325380715

Epoch: 5| Step: 1
Training loss: 0.9296375513076782
Validation loss: 1.7603079567673385

Epoch: 5| Step: 2
Training loss: 1.0464448928833008
Validation loss: 1.7957529483302948

Epoch: 5| Step: 3
Training loss: 1.3150722980499268
Validation loss: 1.768740637328035

Epoch: 5| Step: 4
Training loss: 1.1015424728393555
Validation loss: 1.8032916399740404

Epoch: 5| Step: 5
Training loss: 1.3121337890625
Validation loss: 1.7662386535316386

Epoch: 5| Step: 6
Training loss: 0.669047474861145
Validation loss: 1.7867209629345966

Epoch: 5| Step: 7
Training loss: 1.689369559288025
Validation loss: 1.8200517546746038

Epoch: 5| Step: 8
Training loss: 1.482958436012268
Validation loss: 1.8240163223717802

Epoch: 5| Step: 9
Training loss: 1.4233601093292236
Validation loss: 1.8160201221384027

Epoch: 5| Step: 10
Training loss: 1.6303156614303589
Validation loss: 1.8945930388665968

Epoch: 451| Step: 0
Training loss: 1.0920519828796387
Validation loss: 1.7926838218524892

Epoch: 5| Step: 1
Training loss: 1.7777408361434937
Validation loss: 1.8088306714129705

Epoch: 5| Step: 2
Training loss: 1.2337820529937744
Validation loss: 1.8568154060712425

Epoch: 5| Step: 3
Training loss: 0.8640421032905579
Validation loss: 1.838845258118004

Epoch: 5| Step: 4
Training loss: 0.9323856234550476
Validation loss: 1.7934850813240133

Epoch: 5| Step: 5
Training loss: 2.337613344192505
Validation loss: 1.790647965605541

Epoch: 5| Step: 6
Training loss: 1.1541991233825684
Validation loss: 1.8321883986073155

Epoch: 5| Step: 7
Training loss: 1.1283400058746338
Validation loss: 1.8250212746281778

Epoch: 5| Step: 8
Training loss: 1.2696031332015991
Validation loss: 1.8286117610111032

Epoch: 5| Step: 9
Training loss: 1.013810157775879
Validation loss: 1.8236479111897048

Epoch: 5| Step: 10
Training loss: 0.7102488279342651
Validation loss: 1.77863940628626

Epoch: 452| Step: 0
Training loss: 1.0397123098373413
Validation loss: 1.7950526693815827

Epoch: 5| Step: 1
Training loss: 1.408127784729004
Validation loss: 1.8176874947804276

Epoch: 5| Step: 2
Training loss: 1.6069895029067993
Validation loss: 1.8106686338301627

Epoch: 5| Step: 3
Training loss: 1.0215529203414917
Validation loss: 1.8091637319134128

Epoch: 5| Step: 4
Training loss: 1.3155103921890259
Validation loss: 1.8120916684468586

Epoch: 5| Step: 5
Training loss: 1.3983110189437866
Validation loss: 1.8119014629753687

Epoch: 5| Step: 6
Training loss: 0.8624283075332642
Validation loss: 1.7432752334943382

Epoch: 5| Step: 7
Training loss: 1.8877830505371094
Validation loss: 1.756196839835054

Epoch: 5| Step: 8
Training loss: 0.8501169085502625
Validation loss: 1.8210421249430666

Epoch: 5| Step: 9
Training loss: 1.2635904550552368
Validation loss: 1.7778874648514615

Epoch: 5| Step: 10
Training loss: 1.2582676410675049
Validation loss: 1.7610571666430401

Epoch: 453| Step: 0
Training loss: 1.0333598852157593
Validation loss: 1.8335188050423898

Epoch: 5| Step: 1
Training loss: 1.034377098083496
Validation loss: 1.749026321595715

Epoch: 5| Step: 2
Training loss: 1.1904423236846924
Validation loss: 1.7334573371436006

Epoch: 5| Step: 3
Training loss: 1.7832378149032593
Validation loss: 1.8192567863771993

Epoch: 5| Step: 4
Training loss: 1.8931188583374023
Validation loss: 1.7539244223666448

Epoch: 5| Step: 5
Training loss: 1.4600000381469727
Validation loss: 1.8351964758288475

Epoch: 5| Step: 6
Training loss: 0.7991619110107422
Validation loss: 1.7931406831228605

Epoch: 5| Step: 7
Training loss: 1.07529616355896
Validation loss: 1.8240018211385256

Epoch: 5| Step: 8
Training loss: 1.2085380554199219
Validation loss: 1.7650757758848128

Epoch: 5| Step: 9
Training loss: 1.0068119764328003
Validation loss: 1.8299353225256807

Epoch: 5| Step: 10
Training loss: 1.4249452352523804
Validation loss: 1.837324353956407

Epoch: 454| Step: 0
Training loss: 0.9200319051742554
Validation loss: 1.8057559638895013

Epoch: 5| Step: 1
Training loss: 1.4312045574188232
Validation loss: 1.8097446733905422

Epoch: 5| Step: 2
Training loss: 1.1874208450317383
Validation loss: 1.8156879281484952

Epoch: 5| Step: 3
Training loss: 1.5537798404693604
Validation loss: 1.781736045755366

Epoch: 5| Step: 4
Training loss: 1.55998957157135
Validation loss: 1.7494530536795174

Epoch: 5| Step: 5
Training loss: 1.0438783168792725
Validation loss: 1.8507081077944847

Epoch: 5| Step: 6
Training loss: 1.2302477359771729
Validation loss: 1.826788148572368

Epoch: 5| Step: 7
Training loss: 1.158675193786621
Validation loss: 1.7620567224359

Epoch: 5| Step: 8
Training loss: 0.9734612703323364
Validation loss: 1.7819206355720438

Epoch: 5| Step: 9
Training loss: 1.3741239309310913
Validation loss: 1.8650706403998918

Epoch: 5| Step: 10
Training loss: 1.4202167987823486
Validation loss: 1.775649978268531

Epoch: 455| Step: 0
Training loss: 1.208134651184082
Validation loss: 1.7628177750495173

Epoch: 5| Step: 1
Training loss: 1.1082149744033813
Validation loss: 1.8272519547452208

Epoch: 5| Step: 2
Training loss: 1.5867165327072144
Validation loss: 1.7919201773981894

Epoch: 5| Step: 3
Training loss: 1.3480082750320435
Validation loss: 1.8048906864658478

Epoch: 5| Step: 4
Training loss: 1.3827074766159058
Validation loss: 1.7855174285109325

Epoch: 5| Step: 5
Training loss: 1.0990530252456665
Validation loss: 1.7414227224165393

Epoch: 5| Step: 6
Training loss: 1.0904321670532227
Validation loss: 1.7936738793567946

Epoch: 5| Step: 7
Training loss: 1.3523874282836914
Validation loss: 1.784913811632382

Epoch: 5| Step: 8
Training loss: 1.0893054008483887
Validation loss: 1.811163854855363

Epoch: 5| Step: 9
Training loss: 1.3378053903579712
Validation loss: 1.7782954567222184

Epoch: 5| Step: 10
Training loss: 1.2482768297195435
Validation loss: 1.8160040122206493

Epoch: 456| Step: 0
Training loss: 0.9914706945419312
Validation loss: 1.794487169993821

Epoch: 5| Step: 1
Training loss: 1.110586404800415
Validation loss: 1.7923078203714022

Epoch: 5| Step: 2
Training loss: 1.090970516204834
Validation loss: 1.7760835988547212

Epoch: 5| Step: 3
Training loss: 1.2447354793548584
Validation loss: 1.803684329473844

Epoch: 5| Step: 4
Training loss: 1.5937138795852661
Validation loss: 1.7712948130023094

Epoch: 5| Step: 5
Training loss: 1.0935463905334473
Validation loss: 1.8107852243608045

Epoch: 5| Step: 6
Training loss: 1.2326761484146118
Validation loss: 1.8064069555651756

Epoch: 5| Step: 7
Training loss: 1.1305080652236938
Validation loss: 1.7925012130891123

Epoch: 5| Step: 8
Training loss: 1.4254820346832275
Validation loss: 1.7408019752912625

Epoch: 5| Step: 9
Training loss: 1.2089895009994507
Validation loss: 1.814014709124001

Epoch: 5| Step: 10
Training loss: 1.4171003103256226
Validation loss: 1.781531249323199

Epoch: 457| Step: 0
Training loss: 1.1745606660842896
Validation loss: 1.830245546115342

Epoch: 5| Step: 1
Training loss: 1.1843899488449097
Validation loss: 1.8049744764963787

Epoch: 5| Step: 2
Training loss: 1.472312092781067
Validation loss: 1.8184965759195306

Epoch: 5| Step: 3
Training loss: 1.3654283285140991
Validation loss: 1.835543700443801

Epoch: 5| Step: 4
Training loss: 1.1780250072479248
Validation loss: 1.782316429640657

Epoch: 5| Step: 5
Training loss: 1.0299336910247803
Validation loss: 1.7546683242244105

Epoch: 5| Step: 6
Training loss: 1.7324268817901611
Validation loss: 1.802476990607477

Epoch: 5| Step: 7
Training loss: 1.5197901725769043
Validation loss: 1.793096956386361

Epoch: 5| Step: 8
Training loss: 0.9955814480781555
Validation loss: 1.7745560920366676

Epoch: 5| Step: 9
Training loss: 0.8624625205993652
Validation loss: 1.788782436360595

Epoch: 5| Step: 10
Training loss: 1.2246599197387695
Validation loss: 1.806061121725267

Epoch: 458| Step: 0
Training loss: 1.024529218673706
Validation loss: 1.7689600490754651

Epoch: 5| Step: 1
Training loss: 1.3536558151245117
Validation loss: 1.7477161038306452

Epoch: 5| Step: 2
Training loss: 1.0728622674942017
Validation loss: 1.799697651658007

Epoch: 5| Step: 3
Training loss: 0.9598865509033203
Validation loss: 1.8083480340178295

Epoch: 5| Step: 4
Training loss: 1.260679841041565
Validation loss: 1.776205849903886

Epoch: 5| Step: 5
Training loss: 1.3595075607299805
Validation loss: 1.7913289672584944

Epoch: 5| Step: 6
Training loss: 0.9154184460639954
Validation loss: 1.7761654405183689

Epoch: 5| Step: 7
Training loss: 1.125807523727417
Validation loss: 1.7345933811638945

Epoch: 5| Step: 8
Training loss: 1.301483392715454
Validation loss: 1.8211423530373523

Epoch: 5| Step: 9
Training loss: 1.097447395324707
Validation loss: 1.8445923366854269

Epoch: 5| Step: 10
Training loss: 2.0600736141204834
Validation loss: 1.7485502817297494

Epoch: 459| Step: 0
Training loss: 1.0988972187042236
Validation loss: 1.8284476059739307

Epoch: 5| Step: 1
Training loss: 1.3054412603378296
Validation loss: 1.796382991216516

Epoch: 5| Step: 2
Training loss: 1.1761059761047363
Validation loss: 1.83019729070766

Epoch: 5| Step: 3
Training loss: 0.6666498184204102
Validation loss: 1.8271892762953235

Epoch: 5| Step: 4
Training loss: 1.3558636903762817
Validation loss: 1.8352869877251246

Epoch: 5| Step: 5
Training loss: 1.9629738330841064
Validation loss: 1.8122370089254072

Epoch: 5| Step: 6
Training loss: 1.3840906620025635
Validation loss: 1.7952643068887855

Epoch: 5| Step: 7
Training loss: 0.9820636510848999
Validation loss: 1.815470636531871

Epoch: 5| Step: 8
Training loss: 0.6937554478645325
Validation loss: 1.8124085626294535

Epoch: 5| Step: 9
Training loss: 1.3909209966659546
Validation loss: 1.8026981635760235

Epoch: 5| Step: 10
Training loss: 1.5966155529022217
Validation loss: 1.7974616955685359

Epoch: 460| Step: 0
Training loss: 1.1193299293518066
Validation loss: 1.796380542939709

Epoch: 5| Step: 1
Training loss: 1.2995855808258057
Validation loss: 1.7859287236326484

Epoch: 5| Step: 2
Training loss: 1.203995704650879
Validation loss: 1.7981407360364032

Epoch: 5| Step: 3
Training loss: 1.4637199640274048
Validation loss: 1.8257910641290809

Epoch: 5| Step: 4
Training loss: 1.3258049488067627
Validation loss: 1.8068565578870877

Epoch: 5| Step: 5
Training loss: 1.0544384717941284
Validation loss: 1.7900990516908708

Epoch: 5| Step: 6
Training loss: 1.136448860168457
Validation loss: 1.7997841681203535

Epoch: 5| Step: 7
Training loss: 1.4393203258514404
Validation loss: 1.793157039150115

Epoch: 5| Step: 8
Training loss: 1.7518463134765625
Validation loss: 1.829377035940847

Epoch: 5| Step: 9
Training loss: 1.0218299627304077
Validation loss: 1.808103105073334

Epoch: 5| Step: 10
Training loss: 0.6512537598609924
Validation loss: 1.8300973164137972

Epoch: 461| Step: 0
Training loss: 1.4767065048217773
Validation loss: 1.8102142631366689

Epoch: 5| Step: 1
Training loss: 1.0249505043029785
Validation loss: 1.8092055166921308

Epoch: 5| Step: 2
Training loss: 1.5248676538467407
Validation loss: 1.792845558094722

Epoch: 5| Step: 3
Training loss: 1.4185134172439575
Validation loss: 1.792376761795372

Epoch: 5| Step: 4
Training loss: 0.7210148572921753
Validation loss: 1.7627682942216114

Epoch: 5| Step: 5
Training loss: 0.9030790328979492
Validation loss: 1.8095467757153254

Epoch: 5| Step: 6
Training loss: 1.536773443222046
Validation loss: 1.809807550522589

Epoch: 5| Step: 7
Training loss: 1.4033408164978027
Validation loss: 1.767969701879768

Epoch: 5| Step: 8
Training loss: 1.4448530673980713
Validation loss: 1.7960009408253494

Epoch: 5| Step: 9
Training loss: 1.1815013885498047
Validation loss: 1.7927933277622345

Epoch: 5| Step: 10
Training loss: 0.7686259746551514
Validation loss: 1.773689809665885

Epoch: 462| Step: 0
Training loss: 1.1478750705718994
Validation loss: 1.8038934892223728

Epoch: 5| Step: 1
Training loss: 0.9392790794372559
Validation loss: 1.8466462768534178

Epoch: 5| Step: 2
Training loss: 1.090672492980957
Validation loss: 1.7715404213115733

Epoch: 5| Step: 3
Training loss: 1.234728217124939
Validation loss: 1.840361697699434

Epoch: 5| Step: 4
Training loss: 1.0451183319091797
Validation loss: 1.8264621419291343

Epoch: 5| Step: 5
Training loss: 1.3813244104385376
Validation loss: 1.7871287163867746

Epoch: 5| Step: 6
Training loss: 1.2762365341186523
Validation loss: 1.8041454438240296

Epoch: 5| Step: 7
Training loss: 1.6312179565429688
Validation loss: 1.7822937926938456

Epoch: 5| Step: 8
Training loss: 1.090199589729309
Validation loss: 1.818376879538259

Epoch: 5| Step: 9
Training loss: 1.2895970344543457
Validation loss: 1.8294065165263351

Epoch: 5| Step: 10
Training loss: 1.147559404373169
Validation loss: 1.7660799334126134

Epoch: 463| Step: 0
Training loss: 1.0476043224334717
Validation loss: 1.8383335605744393

Epoch: 5| Step: 1
Training loss: 0.8836797475814819
Validation loss: 1.8353757691639725

Epoch: 5| Step: 2
Training loss: 1.2862884998321533
Validation loss: 1.847834280742112

Epoch: 5| Step: 3
Training loss: 1.5478451251983643
Validation loss: 1.8162019445050148

Epoch: 5| Step: 4
Training loss: 1.928026556968689
Validation loss: 1.8278723506517307

Epoch: 5| Step: 5
Training loss: 0.6838648915290833
Validation loss: 1.800695998694307

Epoch: 5| Step: 6
Training loss: 1.1733306646347046
Validation loss: 1.7324321487898469

Epoch: 5| Step: 7
Training loss: 1.171716332435608
Validation loss: 1.8300313206129177

Epoch: 5| Step: 8
Training loss: 1.3386720418930054
Validation loss: 1.8301208480711906

Epoch: 5| Step: 9
Training loss: 1.2293004989624023
Validation loss: 1.7675284467717653

Epoch: 5| Step: 10
Training loss: 1.041825294494629
Validation loss: 1.764636339679841

Epoch: 464| Step: 0
Training loss: 1.263227939605713
Validation loss: 1.7994750674052904

Epoch: 5| Step: 1
Training loss: 1.404928207397461
Validation loss: 1.7933901920113513

Epoch: 5| Step: 2
Training loss: 0.9832422137260437
Validation loss: 1.7758604634192683

Epoch: 5| Step: 3
Training loss: 0.8637590408325195
Validation loss: 1.777291924722733

Epoch: 5| Step: 4
Training loss: 0.9175718426704407
Validation loss: 1.796480958179761

Epoch: 5| Step: 5
Training loss: 1.382738471031189
Validation loss: 1.7771255803364578

Epoch: 5| Step: 6
Training loss: 1.5152353048324585
Validation loss: 1.8058301325767272

Epoch: 5| Step: 7
Training loss: 1.3885985612869263
Validation loss: 1.7897626443575787

Epoch: 5| Step: 8
Training loss: 0.80218505859375
Validation loss: 1.7354611581371677

Epoch: 5| Step: 9
Training loss: 1.405725359916687
Validation loss: 1.7329461420736005

Epoch: 5| Step: 10
Training loss: 1.653242826461792
Validation loss: 1.8079482842517156

Epoch: 465| Step: 0
Training loss: 0.8833867907524109
Validation loss: 1.7551381562345771

Epoch: 5| Step: 1
Training loss: 0.8653370141983032
Validation loss: 1.7676373476623206

Epoch: 5| Step: 2
Training loss: 1.6640392541885376
Validation loss: 1.8260094452929754

Epoch: 5| Step: 3
Training loss: 1.2582485675811768
Validation loss: 1.8211797911633727

Epoch: 5| Step: 4
Training loss: 1.499488353729248
Validation loss: 1.8076519914852676

Epoch: 5| Step: 5
Training loss: 1.7695776224136353
Validation loss: 1.826784533839072

Epoch: 5| Step: 6
Training loss: 1.1380635499954224
Validation loss: 1.8132963154905586

Epoch: 5| Step: 7
Training loss: 0.9185335040092468
Validation loss: 1.819182913790467

Epoch: 5| Step: 8
Training loss: 1.126824140548706
Validation loss: 1.8025323319178757

Epoch: 5| Step: 9
Training loss: 1.146113395690918
Validation loss: 1.7834299610507103

Epoch: 5| Step: 10
Training loss: 1.377423644065857
Validation loss: 1.78344270747195

Epoch: 466| Step: 0
Training loss: 1.5390069484710693
Validation loss: 1.785906227686072

Epoch: 5| Step: 1
Training loss: 1.4346154928207397
Validation loss: 1.7654101899875108

Epoch: 5| Step: 2
Training loss: 0.8216539621353149
Validation loss: 1.7707340435315204

Epoch: 5| Step: 3
Training loss: 1.6149928569793701
Validation loss: 1.792684382007968

Epoch: 5| Step: 4
Training loss: 1.3326385021209717
Validation loss: 1.8018558384269796

Epoch: 5| Step: 5
Training loss: 0.7164908051490784
Validation loss: 1.7751218106157036

Epoch: 5| Step: 6
Training loss: 0.9874182939529419
Validation loss: 1.820000930499005

Epoch: 5| Step: 7
Training loss: 1.2820775508880615
Validation loss: 1.7823122714155464

Epoch: 5| Step: 8
Training loss: 0.9419019818305969
Validation loss: 1.7657047446056078

Epoch: 5| Step: 9
Training loss: 1.1979176998138428
Validation loss: 1.8161395365192043

Epoch: 5| Step: 10
Training loss: 1.317327618598938
Validation loss: 1.8028580552788191

Epoch: 467| Step: 0
Training loss: 1.2921055555343628
Validation loss: 1.8067948408024286

Epoch: 5| Step: 1
Training loss: 0.8652509450912476
Validation loss: 1.7713595641556608

Epoch: 5| Step: 2
Training loss: 0.975681483745575
Validation loss: 1.812369599137255

Epoch: 5| Step: 3
Training loss: 1.3134366273880005
Validation loss: 1.8240545782991635

Epoch: 5| Step: 4
Training loss: 1.287758469581604
Validation loss: 1.7695178972777499

Epoch: 5| Step: 5
Training loss: 1.325709342956543
Validation loss: 1.876195010318551

Epoch: 5| Step: 6
Training loss: 0.9508858919143677
Validation loss: 1.7774078051249187

Epoch: 5| Step: 7
Training loss: 0.8679195642471313
Validation loss: 1.8041556637774232

Epoch: 5| Step: 8
Training loss: 2.0193886756896973
Validation loss: 1.8511961634441088

Epoch: 5| Step: 9
Training loss: 1.4394404888153076
Validation loss: 1.7719340862766388

Epoch: 5| Step: 10
Training loss: 1.273787498474121
Validation loss: 1.761762426745507

Epoch: 468| Step: 0
Training loss: 1.1125714778900146
Validation loss: 1.8358881947814778

Epoch: 5| Step: 1
Training loss: 1.3784235715866089
Validation loss: 1.7918038079815526

Epoch: 5| Step: 2
Training loss: 1.5298478603363037
Validation loss: 1.810734748840332

Epoch: 5| Step: 3
Training loss: 0.9918216466903687
Validation loss: 1.7924567627650436

Epoch: 5| Step: 4
Training loss: 1.055216670036316
Validation loss: 1.818911143528518

Epoch: 5| Step: 5
Training loss: 1.4751150608062744
Validation loss: 1.7976634489592684

Epoch: 5| Step: 6
Training loss: 1.5329054594039917
Validation loss: 1.775426806942109

Epoch: 5| Step: 7
Training loss: 1.337559461593628
Validation loss: 1.77928408756051

Epoch: 5| Step: 8
Training loss: 0.7376734614372253
Validation loss: 1.7730529603137766

Epoch: 5| Step: 9
Training loss: 0.9469801783561707
Validation loss: 1.7563738464027323

Epoch: 5| Step: 10
Training loss: 1.460845708847046
Validation loss: 1.8171792491789787

Epoch: 469| Step: 0
Training loss: 1.053124189376831
Validation loss: 1.7623411301643617

Epoch: 5| Step: 1
Training loss: 1.2267985343933105
Validation loss: 1.724207241048095

Epoch: 5| Step: 2
Training loss: 1.3161699771881104
Validation loss: 1.794260645425448

Epoch: 5| Step: 3
Training loss: 0.6287428140640259
Validation loss: 1.8133810938045543

Epoch: 5| Step: 4
Training loss: 1.32163405418396
Validation loss: 1.8239120027070403

Epoch: 5| Step: 5
Training loss: 0.7818045616149902
Validation loss: 1.7978855179202171

Epoch: 5| Step: 6
Training loss: 1.4068114757537842
Validation loss: 1.8301270110632784

Epoch: 5| Step: 7
Training loss: 1.1267379522323608
Validation loss: 1.8169963616196827

Epoch: 5| Step: 8
Training loss: 1.7645171880722046
Validation loss: 1.7547395062702957

Epoch: 5| Step: 9
Training loss: 1.2867552042007446
Validation loss: 1.7335174814347298

Epoch: 5| Step: 10
Training loss: 1.5615664720535278
Validation loss: 1.7954456658773525

Epoch: 470| Step: 0
Training loss: 1.2990275621414185
Validation loss: 1.8303055417153142

Epoch: 5| Step: 1
Training loss: 1.3763105869293213
Validation loss: 1.8362292487134215

Epoch: 5| Step: 2
Training loss: 1.0567805767059326
Validation loss: 1.8323704196560768

Epoch: 5| Step: 3
Training loss: 1.3563271760940552
Validation loss: 1.81995338906524

Epoch: 5| Step: 4
Training loss: 1.405120611190796
Validation loss: 1.8038314414280716

Epoch: 5| Step: 5
Training loss: 1.6110031604766846
Validation loss: 1.8140943857931322

Epoch: 5| Step: 6
Training loss: 1.3670774698257446
Validation loss: 1.7787162514143093

Epoch: 5| Step: 7
Training loss: 1.0759141445159912
Validation loss: 1.799877030875093

Epoch: 5| Step: 8
Training loss: 1.0712919235229492
Validation loss: 1.8120673394972278

Epoch: 5| Step: 9
Training loss: 0.7920096516609192
Validation loss: 1.7593285178625455

Epoch: 5| Step: 10
Training loss: 0.8122472763061523
Validation loss: 1.7548436887802616

Epoch: 471| Step: 0
Training loss: 1.9135154485702515
Validation loss: 1.7994334877178233

Epoch: 5| Step: 1
Training loss: 0.7791916728019714
Validation loss: 1.8091763245162142

Epoch: 5| Step: 2
Training loss: 1.3929773569107056
Validation loss: 1.796465091807868

Epoch: 5| Step: 3
Training loss: 1.1753380298614502
Validation loss: 1.7798748003539218

Epoch: 5| Step: 4
Training loss: 1.0738896131515503
Validation loss: 1.7748711583434895

Epoch: 5| Step: 5
Training loss: 1.4297058582305908
Validation loss: 1.8167744003316408

Epoch: 5| Step: 6
Training loss: 1.0433118343353271
Validation loss: 1.805005572175467

Epoch: 5| Step: 7
Training loss: 0.8562799692153931
Validation loss: 1.8326643948913903

Epoch: 5| Step: 8
Training loss: 1.9784084558486938
Validation loss: 1.8174111612381474

Epoch: 5| Step: 9
Training loss: 0.7025696039199829
Validation loss: 1.7871364790906188

Epoch: 5| Step: 10
Training loss: 1.0746111869812012
Validation loss: 1.7968477061999741

Epoch: 472| Step: 0
Training loss: 1.126542091369629
Validation loss: 1.796130254704465

Epoch: 5| Step: 1
Training loss: 1.311376929283142
Validation loss: 1.7840228888296312

Epoch: 5| Step: 2
Training loss: 0.9056116342544556
Validation loss: 1.785790099892565

Epoch: 5| Step: 3
Training loss: 1.2431105375289917
Validation loss: 1.7884788000455467

Epoch: 5| Step: 4
Training loss: 1.1723331212997437
Validation loss: 1.7945021583187966

Epoch: 5| Step: 5
Training loss: 1.2533602714538574
Validation loss: 1.809410431051767

Epoch: 5| Step: 6
Training loss: 0.9738744497299194
Validation loss: 1.842957619697817

Epoch: 5| Step: 7
Training loss: 1.3113311529159546
Validation loss: 1.8079138263579337

Epoch: 5| Step: 8
Training loss: 1.2550523281097412
Validation loss: 1.8192517603597333

Epoch: 5| Step: 9
Training loss: 1.0034480094909668
Validation loss: 1.7941519919262137

Epoch: 5| Step: 10
Training loss: 1.8424144983291626
Validation loss: 1.8473438793613064

Epoch: 473| Step: 0
Training loss: 1.4728038311004639
Validation loss: 1.7857328678971978

Epoch: 5| Step: 1
Training loss: 0.9848675727844238
Validation loss: 1.8031017062484578

Epoch: 5| Step: 2
Training loss: 1.1260440349578857
Validation loss: 1.7641931618413618

Epoch: 5| Step: 3
Training loss: 1.2626068592071533
Validation loss: 1.821096876616119

Epoch: 5| Step: 4
Training loss: 1.1773619651794434
Validation loss: 1.7644373614300963

Epoch: 5| Step: 5
Training loss: 1.1861560344696045
Validation loss: 1.8105382470674412

Epoch: 5| Step: 6
Training loss: 1.1832005977630615
Validation loss: 1.8072050284313899

Epoch: 5| Step: 7
Training loss: 1.3920334577560425
Validation loss: 1.8087350604354695

Epoch: 5| Step: 8
Training loss: 1.075587511062622
Validation loss: 1.8415723577622445

Epoch: 5| Step: 9
Training loss: 1.2659882307052612
Validation loss: 1.8189207135990102

Epoch: 5| Step: 10
Training loss: 1.2663559913635254
Validation loss: 1.7699348221543014

Epoch: 474| Step: 0
Training loss: 1.0836617946624756
Validation loss: 1.82634779971133

Epoch: 5| Step: 1
Training loss: 0.9063215255737305
Validation loss: 1.8238307583716609

Epoch: 5| Step: 2
Training loss: 1.109419822692871
Validation loss: 1.7760197475392332

Epoch: 5| Step: 3
Training loss: 1.8665215969085693
Validation loss: 1.8445373914575065

Epoch: 5| Step: 4
Training loss: 1.559023380279541
Validation loss: 1.8190048497210267

Epoch: 5| Step: 5
Training loss: 1.3028839826583862
Validation loss: 1.7969262689672492

Epoch: 5| Step: 6
Training loss: 0.6466895341873169
Validation loss: 1.8212334789255613

Epoch: 5| Step: 7
Training loss: 1.021775245666504
Validation loss: 1.8032569423798592

Epoch: 5| Step: 8
Training loss: 0.9305598139762878
Validation loss: 1.8311730418153989

Epoch: 5| Step: 9
Training loss: 1.4229440689086914
Validation loss: 1.7433476268604238

Epoch: 5| Step: 10
Training loss: 1.7337876558303833
Validation loss: 1.8037897335585726

Epoch: 475| Step: 0
Training loss: 1.2132624387741089
Validation loss: 1.8163975861764723

Epoch: 5| Step: 1
Training loss: 1.0401923656463623
Validation loss: 1.7483935561231387

Epoch: 5| Step: 2
Training loss: 1.2466702461242676
Validation loss: 1.739883586283653

Epoch: 5| Step: 3
Training loss: 0.9425204992294312
Validation loss: 1.8130487690689743

Epoch: 5| Step: 4
Training loss: 1.2491899728775024
Validation loss: 1.7579303274872482

Epoch: 5| Step: 5
Training loss: 1.3096163272857666
Validation loss: 1.7922080755233765

Epoch: 5| Step: 6
Training loss: 0.9705265760421753
Validation loss: 1.792795834361866

Epoch: 5| Step: 7
Training loss: 1.4791382551193237
Validation loss: 1.800300769908454

Epoch: 5| Step: 8
Training loss: 1.3469089269638062
Validation loss: 1.781910216936501

Epoch: 5| Step: 9
Training loss: 1.1801010370254517
Validation loss: 1.8027804795131888

Epoch: 5| Step: 10
Training loss: 1.0984041690826416
Validation loss: 1.7953519103347615

Epoch: 476| Step: 0
Training loss: 1.457593321800232
Validation loss: 1.7498025394255114

Epoch: 5| Step: 1
Training loss: 1.2880553007125854
Validation loss: 1.7371473145741287

Epoch: 5| Step: 2
Training loss: 1.2170416116714478
Validation loss: 1.7189101083304292

Epoch: 5| Step: 3
Training loss: 1.043323278427124
Validation loss: 1.8347089418800928

Epoch: 5| Step: 4
Training loss: 0.997942328453064
Validation loss: 1.819170316060384

Epoch: 5| Step: 5
Training loss: 0.7970608472824097
Validation loss: 1.79776640348537

Epoch: 5| Step: 6
Training loss: 0.9712662696838379
Validation loss: 1.7937942589482954

Epoch: 5| Step: 7
Training loss: 1.0542360544204712
Validation loss: 1.8273425820053264

Epoch: 5| Step: 8
Training loss: 1.476149320602417
Validation loss: 1.7906541721795195

Epoch: 5| Step: 9
Training loss: 1.7007843255996704
Validation loss: 1.8431734269665134

Epoch: 5| Step: 10
Training loss: 1.4579529762268066
Validation loss: 1.7761538823445637

Epoch: 477| Step: 0
Training loss: 1.497899055480957
Validation loss: 1.8236090957477529

Epoch: 5| Step: 1
Training loss: 1.204404592514038
Validation loss: 1.8109722727088517

Epoch: 5| Step: 2
Training loss: 0.9643864631652832
Validation loss: 1.825313700142727

Epoch: 5| Step: 3
Training loss: 0.8819858431816101
Validation loss: 1.7467288253127888

Epoch: 5| Step: 4
Training loss: 1.1466087102890015
Validation loss: 1.7726597747495096

Epoch: 5| Step: 5
Training loss: 0.8681067228317261
Validation loss: 1.8026232181056854

Epoch: 5| Step: 6
Training loss: 1.0178886651992798
Validation loss: 1.7554499744087138

Epoch: 5| Step: 7
Training loss: 1.2325971126556396
Validation loss: 1.765287709492509

Epoch: 5| Step: 8
Training loss: 1.1026432514190674
Validation loss: 1.7506848650593911

Epoch: 5| Step: 9
Training loss: 1.7088079452514648
Validation loss: 1.755963360109637

Epoch: 5| Step: 10
Training loss: 1.6812028884887695
Validation loss: 1.775969245100534

Epoch: 478| Step: 0
Training loss: 1.2338714599609375
Validation loss: 1.756220535565448

Epoch: 5| Step: 1
Training loss: 1.1017863750457764
Validation loss: 1.7920383727678688

Epoch: 5| Step: 2
Training loss: 1.2522382736206055
Validation loss: 1.856741133556571

Epoch: 5| Step: 3
Training loss: 1.540234923362732
Validation loss: 1.826650619506836

Epoch: 5| Step: 4
Training loss: 0.6689199209213257
Validation loss: 1.8145975118042321

Epoch: 5| Step: 5
Training loss: 1.0148918628692627
Validation loss: 1.8265625315327798

Epoch: 5| Step: 6
Training loss: 1.8016046285629272
Validation loss: 1.759317800562869

Epoch: 5| Step: 7
Training loss: 1.2503702640533447
Validation loss: 1.7825934322931434

Epoch: 5| Step: 8
Training loss: 1.1609323024749756
Validation loss: 1.8282413559575235

Epoch: 5| Step: 9
Training loss: 1.515549898147583
Validation loss: 1.7794113338634532

Epoch: 5| Step: 10
Training loss: 0.9154279828071594
Validation loss: 1.7612582175962386

Epoch: 479| Step: 0
Training loss: 1.4593961238861084
Validation loss: 1.768371159030545

Epoch: 5| Step: 1
Training loss: 1.283407211303711
Validation loss: 1.790131176671674

Epoch: 5| Step: 2
Training loss: 1.4038636684417725
Validation loss: 1.7665334747683616

Epoch: 5| Step: 3
Training loss: 1.1525192260742188
Validation loss: 1.776715587544185

Epoch: 5| Step: 4
Training loss: 0.914700984954834
Validation loss: 1.7761403796493367

Epoch: 5| Step: 5
Training loss: 1.2862187623977661
Validation loss: 1.7907089905072284

Epoch: 5| Step: 6
Training loss: 1.1230729818344116
Validation loss: 1.8153081247883458

Epoch: 5| Step: 7
Training loss: 1.373688817024231
Validation loss: 1.7445298657622388

Epoch: 5| Step: 8
Training loss: 1.0131027698516846
Validation loss: 1.7306752550986506

Epoch: 5| Step: 9
Training loss: 0.8974051475524902
Validation loss: 1.748837327444425

Epoch: 5| Step: 10
Training loss: 0.9284536242485046
Validation loss: 1.773544301268875

Epoch: 480| Step: 0
Training loss: 2.058255434036255
Validation loss: 1.7830964698586413

Epoch: 5| Step: 1
Training loss: 1.3540101051330566
Validation loss: 1.7759749581736903

Epoch: 5| Step: 2
Training loss: 0.8447470664978027
Validation loss: 1.7806889228923346

Epoch: 5| Step: 3
Training loss: 1.2372100353240967
Validation loss: 1.748847589697889

Epoch: 5| Step: 4
Training loss: 1.140560507774353
Validation loss: 1.7989193906066239

Epoch: 5| Step: 5
Training loss: 1.4410958290100098
Validation loss: 1.7896178896709154

Epoch: 5| Step: 6
Training loss: 1.2337315082550049
Validation loss: 1.7692572967980498

Epoch: 5| Step: 7
Training loss: 0.9564889669418335
Validation loss: 1.7864887381112704

Epoch: 5| Step: 8
Training loss: 1.08681321144104
Validation loss: 1.7822724593582975

Epoch: 5| Step: 9
Training loss: 0.7466365098953247
Validation loss: 1.7890138151825115

Epoch: 5| Step: 10
Training loss: 1.4181241989135742
Validation loss: 1.829996173099805

Epoch: 481| Step: 0
Training loss: 1.289424180984497
Validation loss: 1.7596987960159138

Epoch: 5| Step: 1
Training loss: 0.9874477386474609
Validation loss: 1.704676164093838

Epoch: 5| Step: 2
Training loss: 1.3838179111480713
Validation loss: 1.790776442455989

Epoch: 5| Step: 3
Training loss: 1.1050050258636475
Validation loss: 1.8004506364945443

Epoch: 5| Step: 4
Training loss: 1.671738624572754
Validation loss: 1.7660127583370413

Epoch: 5| Step: 5
Training loss: 1.238621473312378
Validation loss: 1.7505882106801516

Epoch: 5| Step: 6
Training loss: 1.3666349649429321
Validation loss: 1.7264585482176913

Epoch: 5| Step: 7
Training loss: 0.9700201153755188
Validation loss: 1.7721355922760502

Epoch: 5| Step: 8
Training loss: 0.930465042591095
Validation loss: 1.7986019452412922

Epoch: 5| Step: 9
Training loss: 1.044309139251709
Validation loss: 1.7842224131348312

Epoch: 5| Step: 10
Training loss: 1.2878512144088745
Validation loss: 1.8179913233685236

Epoch: 482| Step: 0
Training loss: 1.0772478580474854
Validation loss: 1.7818230467457925

Epoch: 5| Step: 1
Training loss: 1.5420265197753906
Validation loss: 1.7608950061182822

Epoch: 5| Step: 2
Training loss: 1.4409934282302856
Validation loss: 1.7720313379841466

Epoch: 5| Step: 3
Training loss: 1.4524527788162231
Validation loss: 1.7811078307449177

Epoch: 5| Step: 4
Training loss: 1.3344039916992188
Validation loss: 1.7844117738867318

Epoch: 5| Step: 5
Training loss: 1.0427939891815186
Validation loss: 1.7712426249698927

Epoch: 5| Step: 6
Training loss: 1.0148385763168335
Validation loss: 1.7822672923405964

Epoch: 5| Step: 7
Training loss: 0.7770348787307739
Validation loss: 1.771618805905824

Epoch: 5| Step: 8
Training loss: 0.7775977849960327
Validation loss: 1.8049005308458883

Epoch: 5| Step: 9
Training loss: 1.3459688425064087
Validation loss: 1.8076674425473778

Epoch: 5| Step: 10
Training loss: 1.2880604267120361
Validation loss: 1.7443777515042214

Epoch: 483| Step: 0
Training loss: 0.6808688044548035
Validation loss: 1.787488692550249

Epoch: 5| Step: 1
Training loss: 0.9858392477035522
Validation loss: 1.7882014551470358

Epoch: 5| Step: 2
Training loss: 1.3360744714736938
Validation loss: 1.7901197287344164

Epoch: 5| Step: 3
Training loss: 0.7976217865943909
Validation loss: 1.8152724671107467

Epoch: 5| Step: 4
Training loss: 1.4546598196029663
Validation loss: 1.7526606539244294

Epoch: 5| Step: 5
Training loss: 1.3831490278244019
Validation loss: 1.7596270730418544

Epoch: 5| Step: 6
Training loss: 1.5197372436523438
Validation loss: 1.737657784133829

Epoch: 5| Step: 7
Training loss: 1.4102814197540283
Validation loss: 1.8354920994850896

Epoch: 5| Step: 8
Training loss: 1.3866121768951416
Validation loss: 1.8307438999093988

Epoch: 5| Step: 9
Training loss: 1.2320234775543213
Validation loss: 1.8002216598039031

Epoch: 5| Step: 10
Training loss: 1.0127217769622803
Validation loss: 1.8125797676783737

Epoch: 484| Step: 0
Training loss: 1.2229974269866943
Validation loss: 1.761279454795263

Epoch: 5| Step: 1
Training loss: 1.131938099861145
Validation loss: 1.8305054428756877

Epoch: 5| Step: 2
Training loss: 1.140825867652893
Validation loss: 1.795323871797131

Epoch: 5| Step: 3
Training loss: 1.1060802936553955
Validation loss: 1.831775212800631

Epoch: 5| Step: 4
Training loss: 1.3249140977859497
Validation loss: 1.7905669494341778

Epoch: 5| Step: 5
Training loss: 1.7272746562957764
Validation loss: 1.7619771649760585

Epoch: 5| Step: 6
Training loss: 1.1081019639968872
Validation loss: 1.7398661157136321

Epoch: 5| Step: 7
Training loss: 1.3014395236968994
Validation loss: 1.7980994434766873

Epoch: 5| Step: 8
Training loss: 1.1042554378509521
Validation loss: 1.7701806278638943

Epoch: 5| Step: 9
Training loss: 1.064764380455017
Validation loss: 1.7602446899619153

Epoch: 5| Step: 10
Training loss: 1.2824351787567139
Validation loss: 1.7607409710525184

Epoch: 485| Step: 0
Training loss: 0.9987619519233704
Validation loss: 1.781199268115464

Epoch: 5| Step: 1
Training loss: 1.315956950187683
Validation loss: 1.7675587605404597

Epoch: 5| Step: 2
Training loss: 1.2048375606536865
Validation loss: 1.793581752366917

Epoch: 5| Step: 3
Training loss: 1.2015868425369263
Validation loss: 1.8122337633563625

Epoch: 5| Step: 4
Training loss: 1.0415422916412354
Validation loss: 1.8624448660881288

Epoch: 5| Step: 5
Training loss: 1.1681472063064575
Validation loss: 1.7842668730725524

Epoch: 5| Step: 6
Training loss: 1.9823726415634155
Validation loss: 1.8235202066359981

Epoch: 5| Step: 7
Training loss: 1.0702108144760132
Validation loss: 1.7333249058774722

Epoch: 5| Step: 8
Training loss: 1.1435277462005615
Validation loss: 1.8579657526426419

Epoch: 5| Step: 9
Training loss: 1.1422268152236938
Validation loss: 1.7989040164537327

Epoch: 5| Step: 10
Training loss: 1.2885925769805908
Validation loss: 1.8049116698644494

Epoch: 486| Step: 0
Training loss: 1.2156198024749756
Validation loss: 1.8185131139652704

Epoch: 5| Step: 1
Training loss: 0.6426092386245728
Validation loss: 1.7717306267830633

Epoch: 5| Step: 2
Training loss: 1.1665849685668945
Validation loss: 1.80106012411015

Epoch: 5| Step: 3
Training loss: 1.2587072849273682
Validation loss: 1.833732492180281

Epoch: 5| Step: 4
Training loss: 0.9427298307418823
Validation loss: 1.7690142149566321

Epoch: 5| Step: 5
Training loss: 1.7426906824111938
Validation loss: 1.7559529786468835

Epoch: 5| Step: 6
Training loss: 1.1713200807571411
Validation loss: 1.7830824531534666

Epoch: 5| Step: 7
Training loss: 1.1156585216522217
Validation loss: 1.7543822719204811

Epoch: 5| Step: 8
Training loss: 0.8477972149848938
Validation loss: 1.8026443168681154

Epoch: 5| Step: 9
Training loss: 1.330535888671875
Validation loss: 1.7892896026693366

Epoch: 5| Step: 10
Training loss: 1.6389439105987549
Validation loss: 1.7530974098431167

Epoch: 487| Step: 0
Training loss: 1.2920873165130615
Validation loss: 1.8063324830865348

Epoch: 5| Step: 1
Training loss: 1.5151288509368896
Validation loss: 1.77773787642038

Epoch: 5| Step: 2
Training loss: 0.8481483459472656
Validation loss: 1.8150185013330111

Epoch: 5| Step: 3
Training loss: 0.9717645645141602
Validation loss: 1.8569783972155662

Epoch: 5| Step: 4
Training loss: 0.8503816723823547
Validation loss: 1.8216792255319574

Epoch: 5| Step: 5
Training loss: 1.6539325714111328
Validation loss: 1.7655279674837667

Epoch: 5| Step: 6
Training loss: 1.1978555917739868
Validation loss: 1.811602097685619

Epoch: 5| Step: 7
Training loss: 1.6446129083633423
Validation loss: 1.8290976644844137

Epoch: 5| Step: 8
Training loss: 0.7132599949836731
Validation loss: 1.807737668355306

Epoch: 5| Step: 9
Training loss: 1.0655202865600586
Validation loss: 1.8129476936914588

Epoch: 5| Step: 10
Training loss: 1.2493321895599365
Validation loss: 1.8006041280684932

Epoch: 488| Step: 0
Training loss: 0.9021592140197754
Validation loss: 1.7609720973558323

Epoch: 5| Step: 1
Training loss: 1.3314329385757446
Validation loss: 1.7355027762792443

Epoch: 5| Step: 2
Training loss: 1.5967586040496826
Validation loss: 1.79604672872892

Epoch: 5| Step: 3
Training loss: 1.4296029806137085
Validation loss: 1.7836135036201888

Epoch: 5| Step: 4
Training loss: 0.9359410405158997
Validation loss: 1.7416420918638988

Epoch: 5| Step: 5
Training loss: 1.2532134056091309
Validation loss: 1.8154075825086204

Epoch: 5| Step: 6
Training loss: 1.2490198612213135
Validation loss: 1.8014880559777702

Epoch: 5| Step: 7
Training loss: 1.4187521934509277
Validation loss: 1.776780742470936

Epoch: 5| Step: 8
Training loss: 0.9566406011581421
Validation loss: 1.747513714657035

Epoch: 5| Step: 9
Training loss: 1.0462251901626587
Validation loss: 1.7201658192501272

Epoch: 5| Step: 10
Training loss: 0.9970588684082031
Validation loss: 1.7696855504025695

Epoch: 489| Step: 0
Training loss: 1.0900710821151733
Validation loss: 1.7881066388981317

Epoch: 5| Step: 1
Training loss: 1.1010438203811646
Validation loss: 1.7653476115195983

Epoch: 5| Step: 2
Training loss: 1.7703430652618408
Validation loss: 1.7391256670798025

Epoch: 5| Step: 3
Training loss: 0.8716886639595032
Validation loss: 1.8023160631938646

Epoch: 5| Step: 4
Training loss: 1.0930335521697998
Validation loss: 1.7716090243349794

Epoch: 5| Step: 5
Training loss: 1.3621095418930054
Validation loss: 1.7899864078849874

Epoch: 5| Step: 6
Training loss: 1.0369470119476318
Validation loss: 1.7789440219120314

Epoch: 5| Step: 7
Training loss: 1.1798274517059326
Validation loss: 1.7681233985449678

Epoch: 5| Step: 8
Training loss: 0.9465247988700867
Validation loss: 1.8353081749331566

Epoch: 5| Step: 9
Training loss: 1.3225891590118408
Validation loss: 1.8030669689178467

Epoch: 5| Step: 10
Training loss: 1.3622932434082031
Validation loss: 1.7314418682488062

Epoch: 490| Step: 0
Training loss: 1.266141414642334
Validation loss: 1.7549581822528635

Epoch: 5| Step: 1
Training loss: 0.8289895057678223
Validation loss: 1.7540053013832337

Epoch: 5| Step: 2
Training loss: 1.2059932947158813
Validation loss: 1.768596464587796

Epoch: 5| Step: 3
Training loss: 1.0465271472930908
Validation loss: 1.7549001157924693

Epoch: 5| Step: 4
Training loss: 0.9472982287406921
Validation loss: 1.7926221547588226

Epoch: 5| Step: 5
Training loss: 0.8390942811965942
Validation loss: 1.7643131184321579

Epoch: 5| Step: 6
Training loss: 1.077283263206482
Validation loss: 1.747245124591294

Epoch: 5| Step: 7
Training loss: 1.1033076047897339
Validation loss: 1.8046020102757279

Epoch: 5| Step: 8
Training loss: 1.1288610696792603
Validation loss: 1.7579553434925694

Epoch: 5| Step: 9
Training loss: 1.6583369970321655
Validation loss: 1.7540118079031668

Epoch: 5| Step: 10
Training loss: 1.5369675159454346
Validation loss: 1.7470744976433374

Epoch: 491| Step: 0
Training loss: 1.3832075595855713
Validation loss: 1.7778292394453479

Epoch: 5| Step: 1
Training loss: 0.845650315284729
Validation loss: 1.8242748988571988

Epoch: 5| Step: 2
Training loss: 1.1518871784210205
Validation loss: 1.7942554668713642

Epoch: 5| Step: 3
Training loss: 0.8081125020980835
Validation loss: 1.7950137686985794

Epoch: 5| Step: 4
Training loss: 0.9403759241104126
Validation loss: 1.7563197933217531

Epoch: 5| Step: 5
Training loss: 1.3351095914840698
Validation loss: 1.758191979059609

Epoch: 5| Step: 6
Training loss: 1.432632565498352
Validation loss: 1.7365553173967587

Epoch: 5| Step: 7
Training loss: 1.3616033792495728
Validation loss: 1.7853065280504123

Epoch: 5| Step: 8
Training loss: 0.886806309223175
Validation loss: 1.7860993890352146

Epoch: 5| Step: 9
Training loss: 2.1127681732177734
Validation loss: 1.8180581626071726

Epoch: 5| Step: 10
Training loss: 0.9113106727600098
Validation loss: 1.7915232066185243

Epoch: 492| Step: 0
Training loss: 1.0627435445785522
Validation loss: 1.7625647039823635

Epoch: 5| Step: 1
Training loss: 1.21623957157135
Validation loss: 1.7109726500767533

Epoch: 5| Step: 2
Training loss: 1.2631579637527466
Validation loss: 1.8090986000594271

Epoch: 5| Step: 3
Training loss: 1.043071985244751
Validation loss: 1.7983345703412128

Epoch: 5| Step: 4
Training loss: 1.1299184560775757
Validation loss: 1.8025049573631697

Epoch: 5| Step: 5
Training loss: 1.7087128162384033
Validation loss: 1.8027528562853414

Epoch: 5| Step: 6
Training loss: 0.8317801356315613
Validation loss: 1.75618238090187

Epoch: 5| Step: 7
Training loss: 1.1513481140136719
Validation loss: 1.781687823675012

Epoch: 5| Step: 8
Training loss: 1.1175323724746704
Validation loss: 1.7564541844911472

Epoch: 5| Step: 9
Training loss: 1.4142439365386963
Validation loss: 1.766028711872716

Epoch: 5| Step: 10
Training loss: 0.7425568103790283
Validation loss: 1.8098233694671302

Epoch: 493| Step: 0
Training loss: 1.2522923946380615
Validation loss: 1.8014149255650018

Epoch: 5| Step: 1
Training loss: 1.150876522064209
Validation loss: 1.783867597579956

Epoch: 5| Step: 2
Training loss: 1.1473954916000366
Validation loss: 1.7671270037210116

Epoch: 5| Step: 3
Training loss: 1.0370219945907593
Validation loss: 1.7335492052057737

Epoch: 5| Step: 4
Training loss: 0.9434655904769897
Validation loss: 1.792490279802712

Epoch: 5| Step: 5
Training loss: 1.5660561323165894
Validation loss: 1.7943009432925974

Epoch: 5| Step: 6
Training loss: 1.3905830383300781
Validation loss: 1.793482586901675

Epoch: 5| Step: 7
Training loss: 1.6190458536148071
Validation loss: 1.7888673659293883

Epoch: 5| Step: 8
Training loss: 0.9182940721511841
Validation loss: 1.7987104308220647

Epoch: 5| Step: 9
Training loss: 0.7334649562835693
Validation loss: 1.7837986664105487

Epoch: 5| Step: 10
Training loss: 1.11751389503479
Validation loss: 1.7961348807939919

Epoch: 494| Step: 0
Training loss: 1.7799956798553467
Validation loss: 1.8542646208117086

Epoch: 5| Step: 1
Training loss: 0.7846168279647827
Validation loss: 1.80892655926366

Epoch: 5| Step: 2
Training loss: 1.4715123176574707
Validation loss: 1.746141949007588

Epoch: 5| Step: 3
Training loss: 1.4634027481079102
Validation loss: 1.7473858569258003

Epoch: 5| Step: 4
Training loss: 1.2516065835952759
Validation loss: 1.806216629602576

Epoch: 5| Step: 5
Training loss: 1.2089362144470215
Validation loss: 1.7554315495234665

Epoch: 5| Step: 6
Training loss: 0.7796861529350281
Validation loss: 1.7951723837083386

Epoch: 5| Step: 7
Training loss: 1.0032469034194946
Validation loss: 1.7685312365972867

Epoch: 5| Step: 8
Training loss: 0.9936796426773071
Validation loss: 1.8240904654225996

Epoch: 5| Step: 9
Training loss: 1.2945382595062256
Validation loss: 1.7892754001002158

Epoch: 5| Step: 10
Training loss: 1.1893310546875
Validation loss: 1.7863289771541473

Epoch: 495| Step: 0
Training loss: 0.8075577616691589
Validation loss: 1.7357939353553198

Epoch: 5| Step: 1
Training loss: 1.2839986085891724
Validation loss: 1.7448851831497685

Epoch: 5| Step: 2
Training loss: 1.1846075057983398
Validation loss: 1.824679748986357

Epoch: 5| Step: 3
Training loss: 1.3550397157669067
Validation loss: 1.8111032016815678

Epoch: 5| Step: 4
Training loss: 1.0357599258422852
Validation loss: 1.7627243406029158

Epoch: 5| Step: 5
Training loss: 0.7593764662742615
Validation loss: 1.782242186607853

Epoch: 5| Step: 6
Training loss: 0.9383138418197632
Validation loss: 1.7911629664000643

Epoch: 5| Step: 7
Training loss: 1.297394037246704
Validation loss: 1.8060431390680292

Epoch: 5| Step: 8
Training loss: 1.6331548690795898
Validation loss: 1.75545447744349

Epoch: 5| Step: 9
Training loss: 0.8681036233901978
Validation loss: 1.7930621966238944

Epoch: 5| Step: 10
Training loss: 2.062365770339966
Validation loss: 1.7290982725799724

Epoch: 496| Step: 0
Training loss: 1.4447803497314453
Validation loss: 1.7931625714866064

Epoch: 5| Step: 1
Training loss: 1.7326290607452393
Validation loss: 1.756187306937351

Epoch: 5| Step: 2
Training loss: 1.160088300704956
Validation loss: 1.7710425853729248

Epoch: 5| Step: 3
Training loss: 0.8550901412963867
Validation loss: 1.817963142548838

Epoch: 5| Step: 4
Training loss: 0.804188072681427
Validation loss: 1.8253266426824755

Epoch: 5| Step: 5
Training loss: 1.3359060287475586
Validation loss: 1.8131903320230462

Epoch: 5| Step: 6
Training loss: 0.7633637189865112
Validation loss: 1.7077559027620541

Epoch: 5| Step: 7
Training loss: 1.2358585596084595
Validation loss: 1.736401622013379

Epoch: 5| Step: 8
Training loss: 1.1628053188323975
Validation loss: 1.8048473032571937

Epoch: 5| Step: 9
Training loss: 0.969150185585022
Validation loss: 1.7493826791804323

Epoch: 5| Step: 10
Training loss: 1.36439847946167
Validation loss: 1.7464458468139812

Epoch: 497| Step: 0
Training loss: 1.3203182220458984
Validation loss: 1.778790891811412

Epoch: 5| Step: 1
Training loss: 1.308641791343689
Validation loss: 1.7683928423030402

Epoch: 5| Step: 2
Training loss: 1.3101140260696411
Validation loss: 1.7493343878817815

Epoch: 5| Step: 3
Training loss: 1.4748709201812744
Validation loss: 1.798151675090995

Epoch: 5| Step: 4
Training loss: 1.1017723083496094
Validation loss: 1.7539889799651278

Epoch: 5| Step: 5
Training loss: 1.2842687368392944
Validation loss: 1.7555098302902714

Epoch: 5| Step: 6
Training loss: 0.9585800170898438
Validation loss: 1.7899336443152478

Epoch: 5| Step: 7
Training loss: 1.0758631229400635
Validation loss: 1.754373670906149

Epoch: 5| Step: 8
Training loss: 1.3732569217681885
Validation loss: 1.819036950347244

Epoch: 5| Step: 9
Training loss: 0.689752995967865
Validation loss: 1.7870857971970753

Epoch: 5| Step: 10
Training loss: 0.8406091928482056
Validation loss: 1.7188694528354111

Epoch: 498| Step: 0
Training loss: 0.935529887676239
Validation loss: 1.783869686947074

Epoch: 5| Step: 1
Training loss: 0.8729091882705688
Validation loss: 1.755624412208475

Epoch: 5| Step: 2
Training loss: 0.9848442077636719
Validation loss: 1.7890795943557576

Epoch: 5| Step: 3
Training loss: 0.9643204808235168
Validation loss: 1.7991646912790114

Epoch: 5| Step: 4
Training loss: 0.9766484498977661
Validation loss: 1.7495259187554801

Epoch: 5| Step: 5
Training loss: 1.790287733078003
Validation loss: 1.7979838848114014

Epoch: 5| Step: 6
Training loss: 1.3857421875
Validation loss: 1.8014718717144382

Epoch: 5| Step: 7
Training loss: 1.3769031763076782
Validation loss: 1.8269396789612309

Epoch: 5| Step: 8
Training loss: 1.085078477859497
Validation loss: 1.7520311647845852

Epoch: 5| Step: 9
Training loss: 1.0914876461029053
Validation loss: 1.7932624996349376

Epoch: 5| Step: 10
Training loss: 1.353220820426941
Validation loss: 1.808932436409817

Epoch: 499| Step: 0
Training loss: 1.6285717487335205
Validation loss: 1.775479567948208

Epoch: 5| Step: 1
Training loss: 1.0870459079742432
Validation loss: 1.7833124976004324

Epoch: 5| Step: 2
Training loss: 1.0714890956878662
Validation loss: 1.7846390944655224

Epoch: 5| Step: 3
Training loss: 0.6931106448173523
Validation loss: 1.8608284047854844

Epoch: 5| Step: 4
Training loss: 1.1580030918121338
Validation loss: 1.7912401973560292

Epoch: 5| Step: 5
Training loss: 1.6221004724502563
Validation loss: 1.8568880558013916

Epoch: 5| Step: 6
Training loss: 0.9064925909042358
Validation loss: 1.8090391479512697

Epoch: 5| Step: 7
Training loss: 0.8487797975540161
Validation loss: 1.742432080289369

Epoch: 5| Step: 8
Training loss: 1.3206416368484497
Validation loss: 1.743931067887173

Epoch: 5| Step: 9
Training loss: 0.99652498960495
Validation loss: 1.8102416441004763

Epoch: 5| Step: 10
Training loss: 1.3927454948425293
Validation loss: 1.84243377049764

Epoch: 500| Step: 0
Training loss: 1.1182606220245361
Validation loss: 1.7739066641817811

Epoch: 5| Step: 1
Training loss: 0.8012620210647583
Validation loss: 1.837193319874425

Epoch: 5| Step: 2
Training loss: 0.9759511947631836
Validation loss: 1.8056569919791272

Epoch: 5| Step: 3
Training loss: 1.3544375896453857
Validation loss: 1.804982352000411

Epoch: 5| Step: 4
Training loss: 1.5266598463058472
Validation loss: 1.7875840599818895

Epoch: 5| Step: 5
Training loss: 1.4948457479476929
Validation loss: 1.7580673527973953

Epoch: 5| Step: 6
Training loss: 1.3556302785873413
Validation loss: 1.8114326974397064

Epoch: 5| Step: 7
Training loss: 1.1868600845336914
Validation loss: 1.7850815506391629

Epoch: 5| Step: 8
Training loss: 0.9322730898857117
Validation loss: 1.8136677331821893

Epoch: 5| Step: 9
Training loss: 0.9838607907295227
Validation loss: 1.8037565497941868

Epoch: 5| Step: 10
Training loss: 1.1292314529418945
Validation loss: 1.8486840699308662

Epoch: 501| Step: 0
Training loss: 1.4055945873260498
Validation loss: 1.8092960849885018

Epoch: 5| Step: 1
Training loss: 0.8764160871505737
Validation loss: 1.7639340072549798

Epoch: 5| Step: 2
Training loss: 1.2255408763885498
Validation loss: 1.7639756894880725

Epoch: 5| Step: 3
Training loss: 1.1360458135604858
Validation loss: 1.7934613791845178

Epoch: 5| Step: 4
Training loss: 1.0188398361206055
Validation loss: 1.7799526427381782

Epoch: 5| Step: 5
Training loss: 1.2111289501190186
Validation loss: 1.809525917935115

Epoch: 5| Step: 6
Training loss: 0.7585217356681824
Validation loss: 1.785199986991062

Epoch: 5| Step: 7
Training loss: 0.9120392799377441
Validation loss: 1.7716145464169082

Epoch: 5| Step: 8
Training loss: 1.6911461353302002
Validation loss: 1.8441042848812637

Epoch: 5| Step: 9
Training loss: 1.204453706741333
Validation loss: 1.7924771308898926

Epoch: 5| Step: 10
Training loss: 1.3762730360031128
Validation loss: 1.768281252153458

Epoch: 502| Step: 0
Training loss: 1.0493853092193604
Validation loss: 1.7740387775564705

Epoch: 5| Step: 1
Training loss: 1.3138920068740845
Validation loss: 1.8073142959225563

Epoch: 5| Step: 2
Training loss: 0.985451340675354
Validation loss: 1.7941006229769798

Epoch: 5| Step: 3
Training loss: 0.9606664776802063
Validation loss: 1.7915418160858976

Epoch: 5| Step: 4
Training loss: 1.2500358819961548
Validation loss: 1.7526313310028405

Epoch: 5| Step: 5
Training loss: 0.9789613485336304
Validation loss: 1.8296165081762499

Epoch: 5| Step: 6
Training loss: 1.033881425857544
Validation loss: 1.7549726399042274

Epoch: 5| Step: 7
Training loss: 1.3752381801605225
Validation loss: 1.7981313261934506

Epoch: 5| Step: 8
Training loss: 1.135213851928711
Validation loss: 1.810348605596891

Epoch: 5| Step: 9
Training loss: 1.1380786895751953
Validation loss: 1.7910374185090423

Epoch: 5| Step: 10
Training loss: 1.376220464706421
Validation loss: 1.8283522129058838

Epoch: 503| Step: 0
Training loss: 0.8626109957695007
Validation loss: 1.7863692750212967

Epoch: 5| Step: 1
Training loss: 1.5437085628509521
Validation loss: 1.75261515314861

Epoch: 5| Step: 2
Training loss: 1.1910486221313477
Validation loss: 1.8139905416837303

Epoch: 5| Step: 3
Training loss: 1.3134288787841797
Validation loss: 1.7822310591256747

Epoch: 5| Step: 4
Training loss: 0.9641801714897156
Validation loss: 1.785480268539921

Epoch: 5| Step: 5
Training loss: 1.0516780614852905
Validation loss: 1.768061311014237

Epoch: 5| Step: 6
Training loss: 1.1099283695220947
Validation loss: 1.8212615277177544

Epoch: 5| Step: 7
Training loss: 0.791538417339325
Validation loss: 1.7219125532334851

Epoch: 5| Step: 8
Training loss: 1.1750924587249756
Validation loss: 1.8012974851874894

Epoch: 5| Step: 9
Training loss: 1.2298071384429932
Validation loss: 1.7430703947621007

Epoch: 5| Step: 10
Training loss: 1.6797157526016235
Validation loss: 1.8375192637084632

Epoch: 504| Step: 0
Training loss: 0.7097232937812805
Validation loss: 1.805418719527542

Epoch: 5| Step: 1
Training loss: 0.8621964454650879
Validation loss: 1.7981978385679183

Epoch: 5| Step: 2
Training loss: 1.379023551940918
Validation loss: 1.8698457159021848

Epoch: 5| Step: 3
Training loss: 1.273604154586792
Validation loss: 1.807812508716378

Epoch: 5| Step: 4
Training loss: 1.3016395568847656
Validation loss: 1.8045603998245732

Epoch: 5| Step: 5
Training loss: 1.296558141708374
Validation loss: 1.832162675037179

Epoch: 5| Step: 6
Training loss: 1.0191859006881714
Validation loss: 1.8146962222232614

Epoch: 5| Step: 7
Training loss: 1.5760457515716553
Validation loss: 1.8122203003975652

Epoch: 5| Step: 8
Training loss: 1.4744699001312256
Validation loss: 1.79786685205275

Epoch: 5| Step: 9
Training loss: 1.2986730337142944
Validation loss: 1.730977076356129

Epoch: 5| Step: 10
Training loss: 0.5583608746528625
Validation loss: 1.761349053793056

Epoch: 505| Step: 0
Training loss: 1.2338242530822754
Validation loss: 1.7804672307865594

Epoch: 5| Step: 1
Training loss: 1.1481598615646362
Validation loss: 1.74508838499746

Epoch: 5| Step: 2
Training loss: 0.9568330645561218
Validation loss: 1.8335284366402576

Epoch: 5| Step: 3
Training loss: 1.6226837635040283
Validation loss: 1.755181506115903

Epoch: 5| Step: 4
Training loss: 1.3083131313323975
Validation loss: 1.8103346170917634

Epoch: 5| Step: 5
Training loss: 0.852031409740448
Validation loss: 1.7866374549045358

Epoch: 5| Step: 6
Training loss: 1.119362473487854
Validation loss: 1.7770344698300926

Epoch: 5| Step: 7
Training loss: 1.2547036409378052
Validation loss: 1.7587577130204888

Epoch: 5| Step: 8
Training loss: 0.9670519828796387
Validation loss: 1.8029607585681382

Epoch: 5| Step: 9
Training loss: 0.9786345362663269
Validation loss: 1.8114731363070908

Epoch: 5| Step: 10
Training loss: 1.2638570070266724
Validation loss: 1.7776960685688963

Epoch: 506| Step: 0
Training loss: 0.8685197830200195
Validation loss: 1.8026252228726622

Epoch: 5| Step: 1
Training loss: 0.9045801162719727
Validation loss: 1.7622349416055987

Epoch: 5| Step: 2
Training loss: 1.326036810874939
Validation loss: 1.7367001836017897

Epoch: 5| Step: 3
Training loss: 1.945227861404419
Validation loss: 1.7584244115378267

Epoch: 5| Step: 4
Training loss: 0.7877928614616394
Validation loss: 1.834347669796277

Epoch: 5| Step: 5
Training loss: 1.5147587060928345
Validation loss: 1.8019676734042425

Epoch: 5| Step: 6
Training loss: 1.2436779737472534
Validation loss: 1.8304043482708674

Epoch: 5| Step: 7
Training loss: 0.993090033531189
Validation loss: 1.7715424876059256

Epoch: 5| Step: 8
Training loss: 0.9717229604721069
Validation loss: 1.7598318361466931

Epoch: 5| Step: 9
Training loss: 1.2887332439422607
Validation loss: 1.783105545146491

Epoch: 5| Step: 10
Training loss: 0.7950615286827087
Validation loss: 1.817673513966222

Epoch: 507| Step: 0
Training loss: 1.3472230434417725
Validation loss: 1.760203629411677

Epoch: 5| Step: 1
Training loss: 1.3418182134628296
Validation loss: 1.7680596946388163

Epoch: 5| Step: 2
Training loss: 1.0344563722610474
Validation loss: 1.804249112324048

Epoch: 5| Step: 3
Training loss: 0.8487638235092163
Validation loss: 1.7571552979048861

Epoch: 5| Step: 4
Training loss: 0.8861272931098938
Validation loss: 1.7684262644860052

Epoch: 5| Step: 5
Training loss: 1.3700757026672363
Validation loss: 1.7792095791909002

Epoch: 5| Step: 6
Training loss: 1.2231383323669434
Validation loss: 1.8030960457299345

Epoch: 5| Step: 7
Training loss: 1.2872570753097534
Validation loss: 1.8080192688972718

Epoch: 5| Step: 8
Training loss: 0.6663128137588501
Validation loss: 1.818841931640461

Epoch: 5| Step: 9
Training loss: 1.6256301403045654
Validation loss: 1.795182494707005

Epoch: 5| Step: 10
Training loss: 0.9079859852790833
Validation loss: 1.7756475722917946

Epoch: 508| Step: 0
Training loss: 1.3735078573226929
Validation loss: 1.7580170285317205

Epoch: 5| Step: 1
Training loss: 0.8830476999282837
Validation loss: 1.658437939100368

Epoch: 5| Step: 2
Training loss: 1.3424489498138428
Validation loss: 1.7215622830134567

Epoch: 5| Step: 3
Training loss: 1.0070053339004517
Validation loss: 1.7680913671370475

Epoch: 5| Step: 4
Training loss: 1.263023853302002
Validation loss: 1.8042108140965945

Epoch: 5| Step: 5
Training loss: 1.3491086959838867
Validation loss: 1.8437410298214163

Epoch: 5| Step: 6
Training loss: 1.0935332775115967
Validation loss: 1.7770539291443364

Epoch: 5| Step: 7
Training loss: 1.5853054523468018
Validation loss: 1.8053797880808513

Epoch: 5| Step: 8
Training loss: 0.8768313527107239
Validation loss: 1.829667027278613

Epoch: 5| Step: 9
Training loss: 1.1829748153686523
Validation loss: 1.820448451144721

Epoch: 5| Step: 10
Training loss: 0.7897191047668457
Validation loss: 1.7488600092549478

Epoch: 509| Step: 0
Training loss: 1.0439051389694214
Validation loss: 1.7891206882333244

Epoch: 5| Step: 1
Training loss: 1.1994916200637817
Validation loss: 1.8209419199215469

Epoch: 5| Step: 2
Training loss: 1.3093090057373047
Validation loss: 1.7779909974785262

Epoch: 5| Step: 3
Training loss: 1.3090102672576904
Validation loss: 1.7776573986135504

Epoch: 5| Step: 4
Training loss: 0.9790929555892944
Validation loss: 1.7945011661898704

Epoch: 5| Step: 5
Training loss: 1.0060652494430542
Validation loss: 1.789858728326777

Epoch: 5| Step: 6
Training loss: 1.4617468118667603
Validation loss: 1.8084928835591962

Epoch: 5| Step: 7
Training loss: 1.19786536693573
Validation loss: 1.7561476717713058

Epoch: 5| Step: 8
Training loss: 1.1004037857055664
Validation loss: 1.7754004296436106

Epoch: 5| Step: 9
Training loss: 1.2198903560638428
Validation loss: 1.7815981167618946

Epoch: 5| Step: 10
Training loss: 1.049164056777954
Validation loss: 1.776338420888429

Epoch: 510| Step: 0
Training loss: 1.3171484470367432
Validation loss: 1.8000102440516155

Epoch: 5| Step: 1
Training loss: 1.0882480144500732
Validation loss: 1.7840932735832788

Epoch: 5| Step: 2
Training loss: 1.0264568328857422
Validation loss: 1.7741634666278798

Epoch: 5| Step: 3
Training loss: 1.10560142993927
Validation loss: 1.7652127896585772

Epoch: 5| Step: 4
Training loss: 1.1250628232955933
Validation loss: 1.7041712166160665

Epoch: 5| Step: 5
Training loss: 0.9850289225578308
Validation loss: 1.8294710420793103

Epoch: 5| Step: 6
Training loss: 0.8996762037277222
Validation loss: 1.7531322074192826

Epoch: 5| Step: 7
Training loss: 1.1771175861358643
Validation loss: 1.8269935115691154

Epoch: 5| Step: 8
Training loss: 1.0111913681030273
Validation loss: 1.8169286725341633

Epoch: 5| Step: 9
Training loss: 1.394775152206421
Validation loss: 1.8271185185319634

Epoch: 5| Step: 10
Training loss: 1.444186806678772
Validation loss: 1.8174592641092115

Epoch: 511| Step: 0
Training loss: 1.113931655883789
Validation loss: 1.776386837805471

Epoch: 5| Step: 1
Training loss: 1.4252300262451172
Validation loss: 1.8441158199823031

Epoch: 5| Step: 2
Training loss: 1.5024540424346924
Validation loss: 1.7929875132858113

Epoch: 5| Step: 3
Training loss: 0.8418945074081421
Validation loss: 1.749262031688485

Epoch: 5| Step: 4
Training loss: 0.9085663557052612
Validation loss: 1.8023636469277002

Epoch: 5| Step: 5
Training loss: 0.8231961131095886
Validation loss: 1.7915977290881577

Epoch: 5| Step: 6
Training loss: 1.0164037942886353
Validation loss: 1.8035184337246803

Epoch: 5| Step: 7
Training loss: 1.236147403717041
Validation loss: 1.7597011712289625

Epoch: 5| Step: 8
Training loss: 1.545731782913208
Validation loss: 1.7853848523991083

Epoch: 5| Step: 9
Training loss: 1.0926679372787476
Validation loss: 1.7690660902248916

Epoch: 5| Step: 10
Training loss: 1.2677327394485474
Validation loss: 1.7528136507157357

Epoch: 512| Step: 0
Training loss: 1.121887445449829
Validation loss: 1.7993565759351176

Epoch: 5| Step: 1
Training loss: 0.7372649908065796
Validation loss: 1.8022656645826114

Epoch: 5| Step: 2
Training loss: 0.9857576489448547
Validation loss: 1.7451718263728644

Epoch: 5| Step: 3
Training loss: 1.1545151472091675
Validation loss: 1.699826983995335

Epoch: 5| Step: 4
Training loss: 1.6319061517715454
Validation loss: 1.7930572173928703

Epoch: 5| Step: 5
Training loss: 1.233860731124878
Validation loss: 1.786949985770769

Epoch: 5| Step: 6
Training loss: 1.1862189769744873
Validation loss: 1.7837636169566904

Epoch: 5| Step: 7
Training loss: 0.8154577016830444
Validation loss: 1.7382068454578359

Epoch: 5| Step: 8
Training loss: 0.9483499526977539
Validation loss: 1.802620671128714

Epoch: 5| Step: 9
Training loss: 0.9127507209777832
Validation loss: 1.8178743316281227

Epoch: 5| Step: 10
Training loss: 1.8057998418807983
Validation loss: 1.7786212775015062

Epoch: 513| Step: 0
Training loss: 0.8834272623062134
Validation loss: 1.784276226515411

Epoch: 5| Step: 1
Training loss: 1.2659989595413208
Validation loss: 1.7594654047360985

Epoch: 5| Step: 2
Training loss: 1.0087732076644897
Validation loss: 1.755096867520322

Epoch: 5| Step: 3
Training loss: 1.2528377771377563
Validation loss: 1.8001672388404928

Epoch: 5| Step: 4
Training loss: 1.3236992359161377
Validation loss: 1.7915616766099007

Epoch: 5| Step: 5
Training loss: 0.9941374659538269
Validation loss: 1.7808480057665097

Epoch: 5| Step: 6
Training loss: 1.0744949579238892
Validation loss: 1.8044788568250594

Epoch: 5| Step: 7
Training loss: 1.3838787078857422
Validation loss: 1.8130237261454265

Epoch: 5| Step: 8
Training loss: 1.0071589946746826
Validation loss: 1.7343138328162573

Epoch: 5| Step: 9
Training loss: 0.978195309638977
Validation loss: 1.785325957882789

Epoch: 5| Step: 10
Training loss: 1.320679783821106
Validation loss: 1.7631131987417898

Epoch: 514| Step: 0
Training loss: 0.949607253074646
Validation loss: 1.810805425849012

Epoch: 5| Step: 1
Training loss: 1.2425141334533691
Validation loss: 1.7738150127472416

Epoch: 5| Step: 2
Training loss: 0.9964185953140259
Validation loss: 1.8299514811526063

Epoch: 5| Step: 3
Training loss: 1.2244415283203125
Validation loss: 1.8690149937906573

Epoch: 5| Step: 4
Training loss: 0.9545500874519348
Validation loss: 1.857963103120045

Epoch: 5| Step: 5
Training loss: 0.8872871398925781
Validation loss: 1.8518929071323846

Epoch: 5| Step: 6
Training loss: 0.8883716464042664
Validation loss: 1.764253484305515

Epoch: 5| Step: 7
Training loss: 1.8081382513046265
Validation loss: 1.7353678826362855

Epoch: 5| Step: 8
Training loss: 0.9154282808303833
Validation loss: 1.8480375761626868

Epoch: 5| Step: 9
Training loss: 0.8527622222900391
Validation loss: 1.7689006367037374

Epoch: 5| Step: 10
Training loss: 1.7151199579238892
Validation loss: 1.7464950533323391

Epoch: 515| Step: 0
Training loss: 1.030759334564209
Validation loss: 1.7587885074718024

Epoch: 5| Step: 1
Training loss: 1.2722045183181763
Validation loss: 1.7913510350770847

Epoch: 5| Step: 2
Training loss: 1.0539281368255615
Validation loss: 1.7780377044472644

Epoch: 5| Step: 3
Training loss: 1.3286100625991821
Validation loss: 1.7729541024854105

Epoch: 5| Step: 4
Training loss: 1.156432867050171
Validation loss: 1.8192996850577734

Epoch: 5| Step: 5
Training loss: 0.9892266392707825
Validation loss: 1.8213717732378232

Epoch: 5| Step: 6
Training loss: 1.0480068922042847
Validation loss: 1.820649444416005

Epoch: 5| Step: 7
Training loss: 1.5724493265151978
Validation loss: 1.7762724379057526

Epoch: 5| Step: 8
Training loss: 1.304057240486145
Validation loss: 1.810080816668849

Epoch: 5| Step: 9
Training loss: 0.9170407056808472
Validation loss: 1.7880325983929377

Epoch: 5| Step: 10
Training loss: 1.079222321510315
Validation loss: 1.7903718204908474

Epoch: 516| Step: 0
Training loss: 0.9904597997665405
Validation loss: 1.8077073366411271

Epoch: 5| Step: 1
Training loss: 0.9274198412895203
Validation loss: 1.7767795388416578

Epoch: 5| Step: 2
Training loss: 1.3248487710952759
Validation loss: 1.7836721045996553

Epoch: 5| Step: 3
Training loss: 1.1629700660705566
Validation loss: 1.7911474140741492

Epoch: 5| Step: 4
Training loss: 1.3282510042190552
Validation loss: 1.8106615197273992

Epoch: 5| Step: 5
Training loss: 1.0344021320343018
Validation loss: 1.7909037848954559

Epoch: 5| Step: 6
Training loss: 0.961281955242157
Validation loss: 1.810825196645593

Epoch: 5| Step: 7
Training loss: 1.2050896883010864
Validation loss: 1.8263167386413903

Epoch: 5| Step: 8
Training loss: 1.2931536436080933
Validation loss: 1.7929713956771358

Epoch: 5| Step: 9
Training loss: 0.9079893827438354
Validation loss: 1.8091927651436097

Epoch: 5| Step: 10
Training loss: 1.0400716066360474
Validation loss: 1.7219017782518942

Epoch: 517| Step: 0
Training loss: 1.040103554725647
Validation loss: 1.8012384624891384

Epoch: 5| Step: 1
Training loss: 0.9534710049629211
Validation loss: 1.7974375396646478

Epoch: 5| Step: 2
Training loss: 0.9200827479362488
Validation loss: 1.8172810295576691

Epoch: 5| Step: 3
Training loss: 1.5774067640304565
Validation loss: 1.8330829271706202

Epoch: 5| Step: 4
Training loss: 1.4009253978729248
Validation loss: 1.8827128935885686

Epoch: 5| Step: 5
Training loss: 1.0807843208312988
Validation loss: 1.7977623760059316

Epoch: 5| Step: 6
Training loss: 0.9717099070549011
Validation loss: 1.7437032845712477

Epoch: 5| Step: 7
Training loss: 1.1589748859405518
Validation loss: 1.7854412704385736

Epoch: 5| Step: 8
Training loss: 1.3434616327285767
Validation loss: 1.7340733812701317

Epoch: 5| Step: 9
Training loss: 0.9533200263977051
Validation loss: 1.7768764547122422

Epoch: 5| Step: 10
Training loss: 1.6135430335998535
Validation loss: 1.7734846222785212

Epoch: 518| Step: 0
Training loss: 0.8169977068901062
Validation loss: 1.8239416768473964

Epoch: 5| Step: 1
Training loss: 1.4022849798202515
Validation loss: 1.7816405488598732

Epoch: 5| Step: 2
Training loss: 0.9253295660018921
Validation loss: 1.777305362045124

Epoch: 5| Step: 3
Training loss: 1.1869447231292725
Validation loss: 1.7774368742460847

Epoch: 5| Step: 4
Training loss: 1.1945282220840454
Validation loss: 1.7934464511050974

Epoch: 5| Step: 5
Training loss: 1.265499234199524
Validation loss: 1.7865958905989123

Epoch: 5| Step: 6
Training loss: 1.291015863418579
Validation loss: 1.7934332804013324

Epoch: 5| Step: 7
Training loss: 1.011564016342163
Validation loss: 1.7836855893493981

Epoch: 5| Step: 8
Training loss: 0.9252578616142273
Validation loss: 1.7632033222465104

Epoch: 5| Step: 9
Training loss: 1.0346475839614868
Validation loss: 1.7580979921484505

Epoch: 5| Step: 10
Training loss: 1.2494821548461914
Validation loss: 1.8094667093728178

Epoch: 519| Step: 0
Training loss: 1.0632606744766235
Validation loss: 1.8083975802185714

Epoch: 5| Step: 1
Training loss: 1.189569115638733
Validation loss: 1.7406159306085238

Epoch: 5| Step: 2
Training loss: 1.2185046672821045
Validation loss: 1.7948334793890677

Epoch: 5| Step: 3
Training loss: 1.080843210220337
Validation loss: 1.7719611160216793

Epoch: 5| Step: 4
Training loss: 1.1042311191558838
Validation loss: 1.8048901814286427

Epoch: 5| Step: 5
Training loss: 1.2837107181549072
Validation loss: 1.80261065113929

Epoch: 5| Step: 6
Training loss: 0.938625156879425
Validation loss: 1.7592898158616916

Epoch: 5| Step: 7
Training loss: 1.0975573062896729
Validation loss: 1.8101934861111384

Epoch: 5| Step: 8
Training loss: 1.2220633029937744
Validation loss: 1.7825182278951008

Epoch: 5| Step: 9
Training loss: 0.7874287366867065
Validation loss: 1.8032045761744182

Epoch: 5| Step: 10
Training loss: 1.241373896598816
Validation loss: 1.7880477854000625

Epoch: 520| Step: 0
Training loss: 0.9097613096237183
Validation loss: 1.8268117263752928

Epoch: 5| Step: 1
Training loss: 1.167091965675354
Validation loss: 1.8736358970724127

Epoch: 5| Step: 2
Training loss: 0.910687267780304
Validation loss: 1.713686413662408

Epoch: 5| Step: 3
Training loss: 1.0554559230804443
Validation loss: 1.7626512870993665

Epoch: 5| Step: 4
Training loss: 0.9239122271537781
Validation loss: 1.7979867599343742

Epoch: 5| Step: 5
Training loss: 1.4018123149871826
Validation loss: 1.7866657485244095

Epoch: 5| Step: 6
Training loss: 0.9923149347305298
Validation loss: 1.7520473349478938

Epoch: 5| Step: 7
Training loss: 1.5253400802612305
Validation loss: 1.7923354923084218

Epoch: 5| Step: 8
Training loss: 1.226074457168579
Validation loss: 1.727207040274015

Epoch: 5| Step: 9
Training loss: 1.2385435104370117
Validation loss: 1.7719700567183956

Epoch: 5| Step: 10
Training loss: 0.829110860824585
Validation loss: 1.7437702327646234

Epoch: 521| Step: 0
Training loss: 1.3355604410171509
Validation loss: 1.8021669926181916

Epoch: 5| Step: 1
Training loss: 1.0056078433990479
Validation loss: 1.7756934627409904

Epoch: 5| Step: 2
Training loss: 0.9442845582962036
Validation loss: 1.7593885083352365

Epoch: 5| Step: 3
Training loss: 0.7952365279197693
Validation loss: 1.7821120664637575

Epoch: 5| Step: 4
Training loss: 1.3868622779846191
Validation loss: 1.802169986950454

Epoch: 5| Step: 5
Training loss: 1.1542437076568604
Validation loss: 1.7621881795185868

Epoch: 5| Step: 6
Training loss: 1.535191535949707
Validation loss: 1.7807285734402236

Epoch: 5| Step: 7
Training loss: 1.1113626956939697
Validation loss: 1.7264429971735964

Epoch: 5| Step: 8
Training loss: 0.8172652125358582
Validation loss: 1.762840796542424

Epoch: 5| Step: 9
Training loss: 1.299851655960083
Validation loss: 1.7647341617973902

Epoch: 5| Step: 10
Training loss: 0.8050039410591125
Validation loss: 1.7856080685892413

Epoch: 522| Step: 0
Training loss: 0.8790170550346375
Validation loss: 1.8065051071105465

Epoch: 5| Step: 1
Training loss: 1.0163713693618774
Validation loss: 1.8271509396132601

Epoch: 5| Step: 2
Training loss: 1.0299532413482666
Validation loss: 1.786057476074465

Epoch: 5| Step: 3
Training loss: 1.6740531921386719
Validation loss: 1.7911010429423342

Epoch: 5| Step: 4
Training loss: 0.9628537893295288
Validation loss: 1.7173425587274695

Epoch: 5| Step: 5
Training loss: 1.217909336090088
Validation loss: 1.7653216623490857

Epoch: 5| Step: 6
Training loss: 0.9511715173721313
Validation loss: 1.7735867090122674

Epoch: 5| Step: 7
Training loss: 1.0765421390533447
Validation loss: 1.7684211166956092

Epoch: 5| Step: 8
Training loss: 1.310166835784912
Validation loss: 1.8244318654460292

Epoch: 5| Step: 9
Training loss: 1.0190856456756592
Validation loss: 1.8088659996627479

Epoch: 5| Step: 10
Training loss: 1.1762131452560425
Validation loss: 1.7873690769236574

Epoch: 523| Step: 0
Training loss: 0.8988335728645325
Validation loss: 1.7397902011871338

Epoch: 5| Step: 1
Training loss: 1.2856179475784302
Validation loss: 1.7548086309945712

Epoch: 5| Step: 2
Training loss: 0.8988552093505859
Validation loss: 1.8243496982000207

Epoch: 5| Step: 3
Training loss: 1.3223903179168701
Validation loss: 1.7612635345869168

Epoch: 5| Step: 4
Training loss: 0.940475344657898
Validation loss: 1.7972236487173265

Epoch: 5| Step: 5
Training loss: 1.5615345239639282
Validation loss: 1.7747408779718543

Epoch: 5| Step: 6
Training loss: 0.7409161329269409
Validation loss: 1.8194124929366573

Epoch: 5| Step: 7
Training loss: 1.1516931056976318
Validation loss: 1.772729496802053

Epoch: 5| Step: 8
Training loss: 1.4889729022979736
Validation loss: 1.8193150874107116

Epoch: 5| Step: 9
Training loss: 1.026781678199768
Validation loss: 1.773621336106331

Epoch: 5| Step: 10
Training loss: 1.0772910118103027
Validation loss: 1.8014857999740108

Epoch: 524| Step: 0
Training loss: 1.0104398727416992
Validation loss: 1.7634760436191355

Epoch: 5| Step: 1
Training loss: 1.5519448518753052
Validation loss: 1.82576346781946

Epoch: 5| Step: 2
Training loss: 1.097199559211731
Validation loss: 1.7966370121125252

Epoch: 5| Step: 3
Training loss: 0.9049535989761353
Validation loss: 1.7566784081920501

Epoch: 5| Step: 4
Training loss: 0.9349872469902039
Validation loss: 1.767997500716999

Epoch: 5| Step: 5
Training loss: 1.1269145011901855
Validation loss: 1.7681216706511795

Epoch: 5| Step: 6
Training loss: 1.0054254531860352
Validation loss: 1.7854327296697965

Epoch: 5| Step: 7
Training loss: 1.0434625148773193
Validation loss: 1.7531118508308166

Epoch: 5| Step: 8
Training loss: 0.8927978277206421
Validation loss: 1.7904306611707133

Epoch: 5| Step: 9
Training loss: 1.3900829553604126
Validation loss: 1.786507571897199

Epoch: 5| Step: 10
Training loss: 1.6174410581588745
Validation loss: 1.8071395299767936

Epoch: 525| Step: 0
Training loss: 1.2245534658432007
Validation loss: 1.7925137166054017

Epoch: 5| Step: 1
Training loss: 0.9254739880561829
Validation loss: 1.7327325190267255

Epoch: 5| Step: 2
Training loss: 1.541658639907837
Validation loss: 1.8155190316579675

Epoch: 5| Step: 3
Training loss: 0.5251665115356445
Validation loss: 1.786975856750242

Epoch: 5| Step: 4
Training loss: 1.4397649765014648
Validation loss: 1.740196599755236

Epoch: 5| Step: 5
Training loss: 1.2818418741226196
Validation loss: 1.721873297486254

Epoch: 5| Step: 6
Training loss: 0.8503228425979614
Validation loss: 1.7422364155451457

Epoch: 5| Step: 7
Training loss: 0.7270370125770569
Validation loss: 1.7750522551998016

Epoch: 5| Step: 8
Training loss: 1.0864245891571045
Validation loss: 1.814879294364683

Epoch: 5| Step: 9
Training loss: 1.2901182174682617
Validation loss: 1.827187757338247

Epoch: 5| Step: 10
Training loss: 1.2901074886322021
Validation loss: 1.7699854720023371

Epoch: 526| Step: 0
Training loss: 0.8403097987174988
Validation loss: 1.7547729810078938

Epoch: 5| Step: 1
Training loss: 1.3346177339553833
Validation loss: 1.8307858795248053

Epoch: 5| Step: 2
Training loss: 1.1448559761047363
Validation loss: 1.8053106249019664

Epoch: 5| Step: 3
Training loss: 1.1443684101104736
Validation loss: 1.8152789582488358

Epoch: 5| Step: 4
Training loss: 0.9591941833496094
Validation loss: 1.796056257781162

Epoch: 5| Step: 5
Training loss: 1.0608294010162354
Validation loss: 1.694957595999523

Epoch: 5| Step: 6
Training loss: 1.0746097564697266
Validation loss: 1.7734279042931014

Epoch: 5| Step: 7
Training loss: 1.1712877750396729
Validation loss: 1.783426982100292

Epoch: 5| Step: 8
Training loss: 1.1267141103744507
Validation loss: 1.742411655764426

Epoch: 5| Step: 9
Training loss: 1.1686424016952515
Validation loss: 1.7535198414197533

Epoch: 5| Step: 10
Training loss: 1.506844401359558
Validation loss: 1.8290865934023293

Epoch: 527| Step: 0
Training loss: 1.4146231412887573
Validation loss: 1.7779142459233601

Epoch: 5| Step: 1
Training loss: 1.663106918334961
Validation loss: 1.7919728384223035

Epoch: 5| Step: 2
Training loss: 0.9005796313285828
Validation loss: 1.8234877137727634

Epoch: 5| Step: 3
Training loss: 1.280907392501831
Validation loss: 1.7236006503464074

Epoch: 5| Step: 4
Training loss: 1.31875479221344
Validation loss: 1.811211109161377

Epoch: 5| Step: 5
Training loss: 0.918617844581604
Validation loss: 1.8110306096333328

Epoch: 5| Step: 6
Training loss: 0.935346245765686
Validation loss: 1.7717129261262956

Epoch: 5| Step: 7
Training loss: 1.4804556369781494
Validation loss: 1.7939902967022312

Epoch: 5| Step: 8
Training loss: 0.7371482849121094
Validation loss: 1.7881252906655754

Epoch: 5| Step: 9
Training loss: 0.8133252859115601
Validation loss: 1.8323075284240067

Epoch: 5| Step: 10
Training loss: 0.8604683876037598
Validation loss: 1.790338502135328

Epoch: 528| Step: 0
Training loss: 1.580990195274353
Validation loss: 1.8503731322544876

Epoch: 5| Step: 1
Training loss: 1.5295826196670532
Validation loss: 1.7802988098513695

Epoch: 5| Step: 2
Training loss: 1.207193374633789
Validation loss: 1.7611240366453766

Epoch: 5| Step: 3
Training loss: 0.7496346235275269
Validation loss: 1.818648240899527

Epoch: 5| Step: 4
Training loss: 1.635685682296753
Validation loss: 1.7144905303114204

Epoch: 5| Step: 5
Training loss: 1.5517860651016235
Validation loss: 1.7706428048431233

Epoch: 5| Step: 6
Training loss: 1.0029103755950928
Validation loss: 1.7755282322565715

Epoch: 5| Step: 7
Training loss: 0.9325269460678101
Validation loss: 1.7664891917218444

Epoch: 5| Step: 8
Training loss: 0.8816010355949402
Validation loss: 1.7477441346773537

Epoch: 5| Step: 9
Training loss: 0.5331683158874512
Validation loss: 1.8128199859332013

Epoch: 5| Step: 10
Training loss: 1.0157896280288696
Validation loss: 1.7964290342023295

Epoch: 529| Step: 0
Training loss: 1.2768865823745728
Validation loss: 1.724251979140825

Epoch: 5| Step: 1
Training loss: 0.8917727470397949
Validation loss: 1.7942005998344832

Epoch: 5| Step: 2
Training loss: 1.320269227027893
Validation loss: 1.7981375917311637

Epoch: 5| Step: 3
Training loss: 1.3073465824127197
Validation loss: 1.7910664927574895

Epoch: 5| Step: 4
Training loss: 0.6675904393196106
Validation loss: 1.801055060919895

Epoch: 5| Step: 5
Training loss: 1.3654028177261353
Validation loss: 1.7955698531161073

Epoch: 5| Step: 6
Training loss: 0.8663384318351746
Validation loss: 1.797770087436963

Epoch: 5| Step: 7
Training loss: 1.2225698232650757
Validation loss: 1.8149423753061602

Epoch: 5| Step: 8
Training loss: 1.6023820638656616
Validation loss: 1.8115047498415875

Epoch: 5| Step: 9
Training loss: 0.7117403745651245
Validation loss: 1.8047369551914993

Epoch: 5| Step: 10
Training loss: 1.09685218334198
Validation loss: 1.811300983992956

Epoch: 530| Step: 0
Training loss: 1.029512643814087
Validation loss: 1.8000583879409298

Epoch: 5| Step: 1
Training loss: 0.9771696925163269
Validation loss: 1.7458695878264725

Epoch: 5| Step: 2
Training loss: 0.8398340344429016
Validation loss: 1.7483089162457375

Epoch: 5| Step: 3
Training loss: 1.2386057376861572
Validation loss: 1.8239755066492225

Epoch: 5| Step: 4
Training loss: 0.8990350961685181
Validation loss: 1.7519398145778204

Epoch: 5| Step: 5
Training loss: 0.780585765838623
Validation loss: 1.7559355689633278

Epoch: 5| Step: 6
Training loss: 1.1779515743255615
Validation loss: 1.7548192098576536

Epoch: 5| Step: 7
Training loss: 1.2491718530654907
Validation loss: 1.7867040557246054

Epoch: 5| Step: 8
Training loss: 1.1802451610565186
Validation loss: 1.7495895867706628

Epoch: 5| Step: 9
Training loss: 1.9786103963851929
Validation loss: 1.7839857891041746

Epoch: 5| Step: 10
Training loss: 0.5780965089797974
Validation loss: 1.7998275359471638

Epoch: 531| Step: 0
Training loss: 0.7024179697036743
Validation loss: 1.7901516537512503

Epoch: 5| Step: 1
Training loss: 1.0060330629348755
Validation loss: 1.802869458352366

Epoch: 5| Step: 2
Training loss: 1.9270702600479126
Validation loss: 1.7626699119485834

Epoch: 5| Step: 3
Training loss: 1.5513484477996826
Validation loss: 1.7760431151236258

Epoch: 5| Step: 4
Training loss: 0.7757581472396851
Validation loss: 1.7823358133275022

Epoch: 5| Step: 5
Training loss: 0.8418956995010376
Validation loss: 1.7092947921445292

Epoch: 5| Step: 6
Training loss: 1.043811559677124
Validation loss: 1.7934931080828431

Epoch: 5| Step: 7
Training loss: 1.5093820095062256
Validation loss: 1.8315167286062752

Epoch: 5| Step: 8
Training loss: 0.8692065477371216
Validation loss: 1.8404045861254457

Epoch: 5| Step: 9
Training loss: 1.091524362564087
Validation loss: 1.8181998909160655

Epoch: 5| Step: 10
Training loss: 1.0389152765274048
Validation loss: 1.8275445353600286

Epoch: 532| Step: 0
Training loss: 1.3060531616210938
Validation loss: 1.7605767173151816

Epoch: 5| Step: 1
Training loss: 1.2697944641113281
Validation loss: 1.7709287084558958

Epoch: 5| Step: 2
Training loss: 0.9370452165603638
Validation loss: 1.803650071544032

Epoch: 5| Step: 3
Training loss: 1.7551969289779663
Validation loss: 1.7275028997851956

Epoch: 5| Step: 4
Training loss: 0.8863919377326965
Validation loss: 1.7520693848209996

Epoch: 5| Step: 5
Training loss: 1.0326125621795654
Validation loss: 1.7514679880552395

Epoch: 5| Step: 6
Training loss: 0.9536654353141785
Validation loss: 1.7781674977271789

Epoch: 5| Step: 7
Training loss: 1.0998141765594482
Validation loss: 1.7099968656416862

Epoch: 5| Step: 8
Training loss: 0.9178746342658997
Validation loss: 1.7813840899416196

Epoch: 5| Step: 9
Training loss: 1.1839125156402588
Validation loss: 1.777244899862556

Epoch: 5| Step: 10
Training loss: 1.1806843280792236
Validation loss: 1.7507447927228865

Epoch: 533| Step: 0
Training loss: 0.8919521570205688
Validation loss: 1.7158908023629138

Epoch: 5| Step: 1
Training loss: 1.4695360660552979
Validation loss: 1.7702005088970225

Epoch: 5| Step: 2
Training loss: 0.6064903736114502
Validation loss: 1.7543134330421366

Epoch: 5| Step: 3
Training loss: 1.446210503578186
Validation loss: 1.7956731011790614

Epoch: 5| Step: 4
Training loss: 1.3006207942962646
Validation loss: 1.7908481474845641

Epoch: 5| Step: 5
Training loss: 0.8971160650253296
Validation loss: 1.8103336531628844

Epoch: 5| Step: 6
Training loss: 0.7348962426185608
Validation loss: 1.7791426591975714

Epoch: 5| Step: 7
Training loss: 1.3425889015197754
Validation loss: 1.8208253050363192

Epoch: 5| Step: 8
Training loss: 1.1805522441864014
Validation loss: 1.7646869254368607

Epoch: 5| Step: 9
Training loss: 0.8525211215019226
Validation loss: 1.7418230964291481

Epoch: 5| Step: 10
Training loss: 1.343539834022522
Validation loss: 1.7931278790197065

Epoch: 534| Step: 0
Training loss: 1.5675159692764282
Validation loss: 1.7862197506812312

Epoch: 5| Step: 1
Training loss: 1.0576865673065186
Validation loss: 1.8190575415088284

Epoch: 5| Step: 2
Training loss: 0.8365612030029297
Validation loss: 1.7808025319089171

Epoch: 5| Step: 3
Training loss: 1.1332519054412842
Validation loss: 1.7724511533655145

Epoch: 5| Step: 4
Training loss: 1.1012133359909058
Validation loss: 1.8128268718719482

Epoch: 5| Step: 5
Training loss: 1.2650467157363892
Validation loss: 1.7610799932992587

Epoch: 5| Step: 6
Training loss: 0.8042968511581421
Validation loss: 1.7997406900569957

Epoch: 5| Step: 7
Training loss: 1.128581166267395
Validation loss: 1.7352389750942108

Epoch: 5| Step: 8
Training loss: 0.6047869324684143
Validation loss: 1.788165659032842

Epoch: 5| Step: 9
Training loss: 1.5171667337417603
Validation loss: 1.8212629325928227

Epoch: 5| Step: 10
Training loss: 1.0364218950271606
Validation loss: 1.754122180323447

Epoch: 535| Step: 0
Training loss: 1.2099969387054443
Validation loss: 1.7943930728461153

Epoch: 5| Step: 1
Training loss: 1.255799412727356
Validation loss: 1.7817894758716706

Epoch: 5| Step: 2
Training loss: 1.1402161121368408
Validation loss: 1.7442579359136603

Epoch: 5| Step: 3
Training loss: 1.6796001195907593
Validation loss: 1.804469568755037

Epoch: 5| Step: 4
Training loss: 0.7975692749023438
Validation loss: 1.792364957512066

Epoch: 5| Step: 5
Training loss: 1.7329826354980469
Validation loss: 1.7903472146680277

Epoch: 5| Step: 6
Training loss: 0.6883341073989868
Validation loss: 1.810744982893749

Epoch: 5| Step: 7
Training loss: 0.9404020309448242
Validation loss: 1.8108262938837851

Epoch: 5| Step: 8
Training loss: 0.8299310803413391
Validation loss: 1.7712794888404109

Epoch: 5| Step: 9
Training loss: 0.9212421178817749
Validation loss: 1.7880274326570573

Epoch: 5| Step: 10
Training loss: 0.7915675044059753
Validation loss: 1.732477718783963

Epoch: 536| Step: 0
Training loss: 1.4693351984024048
Validation loss: 1.7337317248826385

Epoch: 5| Step: 1
Training loss: 1.0087482929229736
Validation loss: 1.7679227231651224

Epoch: 5| Step: 2
Training loss: 0.9146507978439331
Validation loss: 1.7555695438897738

Epoch: 5| Step: 3
Training loss: 1.349769949913025
Validation loss: 1.7655341317576747

Epoch: 5| Step: 4
Training loss: 1.0198605060577393
Validation loss: 1.8423632626892419

Epoch: 5| Step: 5
Training loss: 0.7877486348152161
Validation loss: 1.7878448476073563

Epoch: 5| Step: 6
Training loss: 0.884268581867218
Validation loss: 1.800474751380182

Epoch: 5| Step: 7
Training loss: 1.0017437934875488
Validation loss: 1.8256917115180724

Epoch: 5| Step: 8
Training loss: 0.8196770548820496
Validation loss: 1.7468352010173183

Epoch: 5| Step: 9
Training loss: 1.5359278917312622
Validation loss: 1.7469121243364067

Epoch: 5| Step: 10
Training loss: 1.298375129699707
Validation loss: 1.7336056796453332

Epoch: 537| Step: 0
Training loss: 0.8018988370895386
Validation loss: 1.7990557224519792

Epoch: 5| Step: 1
Training loss: 1.0926330089569092
Validation loss: 1.7963429753498366

Epoch: 5| Step: 2
Training loss: 0.9079324007034302
Validation loss: 1.781596981069093

Epoch: 5| Step: 3
Training loss: 0.906481146812439
Validation loss: 1.8250164472928612

Epoch: 5| Step: 4
Training loss: 1.6150147914886475
Validation loss: 1.9157007868571947

Epoch: 5| Step: 5
Training loss: 1.1517844200134277
Validation loss: 1.8444232274127264

Epoch: 5| Step: 6
Training loss: 1.0027529001235962
Validation loss: 1.841235887619757

Epoch: 5| Step: 7
Training loss: 1.6040165424346924
Validation loss: 1.8616249484400595

Epoch: 5| Step: 8
Training loss: 0.9980899691581726
Validation loss: 1.844984995421543

Epoch: 5| Step: 9
Training loss: 1.0823895931243896
Validation loss: 1.840115204934151

Epoch: 5| Step: 10
Training loss: 0.6955653429031372
Validation loss: 1.791471278795632

Epoch: 538| Step: 0
Training loss: 1.0436737537384033
Validation loss: 1.7643246419968144

Epoch: 5| Step: 1
Training loss: 1.8551006317138672
Validation loss: 1.7724038016411565

Epoch: 5| Step: 2
Training loss: 0.9065071940422058
Validation loss: 1.7775722806171705

Epoch: 5| Step: 3
Training loss: 0.6999026536941528
Validation loss: 1.737473057162377

Epoch: 5| Step: 4
Training loss: 1.659338355064392
Validation loss: 1.7825977571548954

Epoch: 5| Step: 5
Training loss: 0.8445676565170288
Validation loss: 1.8355811052424933

Epoch: 5| Step: 6
Training loss: 1.1603723764419556
Validation loss: 1.773261740643491

Epoch: 5| Step: 7
Training loss: 0.7894052267074585
Validation loss: 1.7177799799109017

Epoch: 5| Step: 8
Training loss: 1.1071504354476929
Validation loss: 1.710886142587149

Epoch: 5| Step: 9
Training loss: 1.0789034366607666
Validation loss: 1.7419350724066458

Epoch: 5| Step: 10
Training loss: 1.0362199544906616
Validation loss: 1.7465590520571637

Epoch: 539| Step: 0
Training loss: 1.0793390274047852
Validation loss: 1.782815033389676

Epoch: 5| Step: 1
Training loss: 1.0626505613327026
Validation loss: 1.7957882060799548

Epoch: 5| Step: 2
Training loss: 1.0945820808410645
Validation loss: 1.8074066497946297

Epoch: 5| Step: 3
Training loss: 0.9462966918945312
Validation loss: 1.8478056256489088

Epoch: 5| Step: 4
Training loss: 1.2237217426300049
Validation loss: 1.812293065491543

Epoch: 5| Step: 5
Training loss: 0.7389433979988098
Validation loss: 1.7595757002471595

Epoch: 5| Step: 6
Training loss: 1.0449522733688354
Validation loss: 1.7427620093027751

Epoch: 5| Step: 7
Training loss: 1.3006877899169922
Validation loss: 1.7853436341849707

Epoch: 5| Step: 8
Training loss: 1.6026954650878906
Validation loss: 1.7713000646201513

Epoch: 5| Step: 9
Training loss: 0.8777309656143188
Validation loss: 1.7509887218475342

Epoch: 5| Step: 10
Training loss: 1.0559568405151367
Validation loss: 1.8055004176273142

Epoch: 540| Step: 0
Training loss: 0.8401807546615601
Validation loss: 1.8091908475404144

Epoch: 5| Step: 1
Training loss: 1.249782681465149
Validation loss: 1.8112088044484456

Epoch: 5| Step: 2
Training loss: 1.1931993961334229
Validation loss: 1.7715870462438112

Epoch: 5| Step: 3
Training loss: 1.071596384048462
Validation loss: 1.7376831103396673

Epoch: 5| Step: 4
Training loss: 0.9822871088981628
Validation loss: 1.7650908308644448

Epoch: 5| Step: 5
Training loss: 0.8749328851699829
Validation loss: 1.7462806304295857

Epoch: 5| Step: 6
Training loss: 1.02374267578125
Validation loss: 1.7245342859657862

Epoch: 5| Step: 7
Training loss: 1.1734868288040161
Validation loss: 1.7583968267645886

Epoch: 5| Step: 8
Training loss: 1.0652729272842407
Validation loss: 1.7304254424187444

Epoch: 5| Step: 9
Training loss: 1.2162933349609375
Validation loss: 1.783555289750458

Epoch: 5| Step: 10
Training loss: 1.187897801399231
Validation loss: 1.737156888490082

Epoch: 541| Step: 0
Training loss: 0.7791651487350464
Validation loss: 1.8001110258922781

Epoch: 5| Step: 1
Training loss: 0.8980660438537598
Validation loss: 1.7869535338494085

Epoch: 5| Step: 2
Training loss: 0.9449728727340698
Validation loss: 1.7157743528325071

Epoch: 5| Step: 3
Training loss: 1.3709527254104614
Validation loss: 1.7783402960787538

Epoch: 5| Step: 4
Training loss: 1.049391508102417
Validation loss: 1.8135829676863968

Epoch: 5| Step: 5
Training loss: 0.8921451568603516
Validation loss: 1.731522298628284

Epoch: 5| Step: 6
Training loss: 0.8698965907096863
Validation loss: 1.697733288170189

Epoch: 5| Step: 7
Training loss: 1.3011165857315063
Validation loss: 1.7572074231281076

Epoch: 5| Step: 8
Training loss: 1.5051400661468506
Validation loss: 1.7585705954541442

Epoch: 5| Step: 9
Training loss: 0.9332567453384399
Validation loss: 1.7535206015392015

Epoch: 5| Step: 10
Training loss: 1.282750129699707
Validation loss: 1.8076750181054557

Epoch: 542| Step: 0
Training loss: 0.6244584321975708
Validation loss: 1.7509366030334144

Epoch: 5| Step: 1
Training loss: 0.8258380889892578
Validation loss: 1.7673817321818361

Epoch: 5| Step: 2
Training loss: 1.0095669031143188
Validation loss: 1.7952548124456917

Epoch: 5| Step: 3
Training loss: 0.9802969694137573
Validation loss: 1.7424408966495144

Epoch: 5| Step: 4
Training loss: 1.1144535541534424
Validation loss: 1.7242006178825133

Epoch: 5| Step: 5
Training loss: 1.2856242656707764
Validation loss: 1.7585305295964724

Epoch: 5| Step: 6
Training loss: 1.532589316368103
Validation loss: 1.7864774657833962

Epoch: 5| Step: 7
Training loss: 2.0052216053009033
Validation loss: 1.7513614546868108

Epoch: 5| Step: 8
Training loss: 1.1535168886184692
Validation loss: 1.7626002450143137

Epoch: 5| Step: 9
Training loss: 0.7878022193908691
Validation loss: 1.793602789601972

Epoch: 5| Step: 10
Training loss: 0.8839437365531921
Validation loss: 1.8049964225420387

Epoch: 543| Step: 0
Training loss: 1.2150793075561523
Validation loss: 1.8216543248904649

Epoch: 5| Step: 1
Training loss: 1.2605092525482178
Validation loss: 1.7676951654495732

Epoch: 5| Step: 2
Training loss: 0.9689818620681763
Validation loss: 1.7984333397239767

Epoch: 5| Step: 3
Training loss: 1.2456032037734985
Validation loss: 1.7823555290058095

Epoch: 5| Step: 4
Training loss: 1.0031981468200684
Validation loss: 1.7781405641186623

Epoch: 5| Step: 5
Training loss: 1.2211534976959229
Validation loss: 1.8094748835409842

Epoch: 5| Step: 6
Training loss: 0.688897430896759
Validation loss: 1.801301852349312

Epoch: 5| Step: 7
Training loss: 0.8511177897453308
Validation loss: 1.7976068591558805

Epoch: 5| Step: 8
Training loss: 1.1667343378067017
Validation loss: 1.7718574282943562

Epoch: 5| Step: 9
Training loss: 0.9826221466064453
Validation loss: 1.7481590932415378

Epoch: 5| Step: 10
Training loss: 1.0247540473937988
Validation loss: 1.828031438653187

Epoch: 544| Step: 0
Training loss: 1.136020541191101
Validation loss: 1.7424342196474794

Epoch: 5| Step: 1
Training loss: 0.6211877465248108
Validation loss: 1.7623728359899213

Epoch: 5| Step: 2
Training loss: 1.1181246042251587
Validation loss: 1.7752847453599334

Epoch: 5| Step: 3
Training loss: 1.2046611309051514
Validation loss: 1.791991856790358

Epoch: 5| Step: 4
Training loss: 0.8712078332901001
Validation loss: 1.7181078131480882

Epoch: 5| Step: 5
Training loss: 0.9599621891975403
Validation loss: 1.764834193773167

Epoch: 5| Step: 6
Training loss: 1.5934169292449951
Validation loss: 1.7249829051315144

Epoch: 5| Step: 7
Training loss: 0.95489102602005
Validation loss: 1.814606999838224

Epoch: 5| Step: 8
Training loss: 0.7671871185302734
Validation loss: 1.7919202453346663

Epoch: 5| Step: 9
Training loss: 1.260315179824829
Validation loss: 1.817146799897635

Epoch: 5| Step: 10
Training loss: 1.273471713066101
Validation loss: 1.822003408144879

Epoch: 545| Step: 0
Training loss: 0.872353732585907
Validation loss: 1.7773528047787246

Epoch: 5| Step: 1
Training loss: 1.031590461730957
Validation loss: 1.7934932272921327

Epoch: 5| Step: 2
Training loss: 1.1848716735839844
Validation loss: 1.7350357604283158

Epoch: 5| Step: 3
Training loss: 0.993313193321228
Validation loss: 1.8157007425062117

Epoch: 5| Step: 4
Training loss: 0.9249065518379211
Validation loss: 1.7545416508951495

Epoch: 5| Step: 5
Training loss: 0.9123290777206421
Validation loss: 1.7988765060260732

Epoch: 5| Step: 6
Training loss: 1.0812478065490723
Validation loss: 1.790989500220104

Epoch: 5| Step: 7
Training loss: 0.7952064275741577
Validation loss: 1.7909224648629465

Epoch: 5| Step: 8
Training loss: 0.9705867767333984
Validation loss: 1.7804267585918467

Epoch: 5| Step: 9
Training loss: 1.5226948261260986
Validation loss: 1.728097964358586

Epoch: 5| Step: 10
Training loss: 1.518905520439148
Validation loss: 1.7492549086129794

Epoch: 546| Step: 0
Training loss: 1.4344055652618408
Validation loss: 1.773879220408778

Epoch: 5| Step: 1
Training loss: 0.8824432492256165
Validation loss: 1.7570142105061521

Epoch: 5| Step: 2
Training loss: 1.3111728429794312
Validation loss: 1.771887046034618

Epoch: 5| Step: 3
Training loss: 1.5055183172225952
Validation loss: 1.7374199872375817

Epoch: 5| Step: 4
Training loss: 0.9706656336784363
Validation loss: 1.8148931354604743

Epoch: 5| Step: 5
Training loss: 1.125989317893982
Validation loss: 1.755844077756328

Epoch: 5| Step: 6
Training loss: 0.8809114694595337
Validation loss: 1.7506100964802567

Epoch: 5| Step: 7
Training loss: 0.9461044073104858
Validation loss: 1.7739627912480345

Epoch: 5| Step: 8
Training loss: 0.8752595782279968
Validation loss: 1.7986006903392013

Epoch: 5| Step: 9
Training loss: 0.8260149955749512
Validation loss: 1.767806447962279

Epoch: 5| Step: 10
Training loss: 0.7769033312797546
Validation loss: 1.7316564693245837

Epoch: 547| Step: 0
Training loss: 1.0722332000732422
Validation loss: 1.7697324175988474

Epoch: 5| Step: 1
Training loss: 1.0481096506118774
Validation loss: 1.72985557458734

Epoch: 5| Step: 2
Training loss: 1.0369583368301392
Validation loss: 1.7387114109531525

Epoch: 5| Step: 3
Training loss: 0.9371933937072754
Validation loss: 1.748784529265537

Epoch: 5| Step: 4
Training loss: 1.3692985773086548
Validation loss: 1.7791494528452556

Epoch: 5| Step: 5
Training loss: 0.8278578519821167
Validation loss: 1.729427945229315

Epoch: 5| Step: 6
Training loss: 1.4167379140853882
Validation loss: 1.789499698146697

Epoch: 5| Step: 7
Training loss: 0.7314017415046692
Validation loss: 1.769632653523517

Epoch: 5| Step: 8
Training loss: 1.1848790645599365
Validation loss: 1.785899046928652

Epoch: 5| Step: 9
Training loss: 0.9124557375907898
Validation loss: 1.789101815992786

Epoch: 5| Step: 10
Training loss: 1.1492968797683716
Validation loss: 1.777283186553627

Epoch: 548| Step: 0
Training loss: 1.0910184383392334
Validation loss: 1.8095375004635061

Epoch: 5| Step: 1
Training loss: 0.9273541569709778
Validation loss: 1.8245467960193593

Epoch: 5| Step: 2
Training loss: 0.8709725141525269
Validation loss: 1.7730280327540573

Epoch: 5| Step: 3
Training loss: 1.181689739227295
Validation loss: 1.7629882404881139

Epoch: 5| Step: 4
Training loss: 1.0595808029174805
Validation loss: 1.8293964503913798

Epoch: 5| Step: 5
Training loss: 1.3009932041168213
Validation loss: 1.8288820738433509

Epoch: 5| Step: 6
Training loss: 1.5138276815414429
Validation loss: 1.8054495908880746

Epoch: 5| Step: 7
Training loss: 0.9501761198043823
Validation loss: 1.7235659232703588

Epoch: 5| Step: 8
Training loss: 1.1081353425979614
Validation loss: 1.829952903973159

Epoch: 5| Step: 9
Training loss: 0.9537667036056519
Validation loss: 1.8207495879101496

Epoch: 5| Step: 10
Training loss: 0.7627245783805847
Validation loss: 1.7712942733559558

Epoch: 549| Step: 0
Training loss: 0.9154504537582397
Validation loss: 1.8121288976361674

Epoch: 5| Step: 1
Training loss: 1.3265177011489868
Validation loss: 1.74885731486864

Epoch: 5| Step: 2
Training loss: 1.8231360912322998
Validation loss: 1.7484496767802904

Epoch: 5| Step: 3
Training loss: 0.8103755712509155
Validation loss: 1.767899069734799

Epoch: 5| Step: 4
Training loss: 0.980628490447998
Validation loss: 1.7823860517112158

Epoch: 5| Step: 5
Training loss: 1.1239506006240845
Validation loss: 1.8073742581952004

Epoch: 5| Step: 6
Training loss: 1.055908441543579
Validation loss: 1.740827771925157

Epoch: 5| Step: 7
Training loss: 1.1238667964935303
Validation loss: 1.8039572623468214

Epoch: 5| Step: 8
Training loss: 1.068436861038208
Validation loss: 1.7257145463779409

Epoch: 5| Step: 9
Training loss: 0.9169608354568481
Validation loss: 1.7787853787022252

Epoch: 5| Step: 10
Training loss: 0.8500635027885437
Validation loss: 1.748209576452932

Epoch: 550| Step: 0
Training loss: 1.6694681644439697
Validation loss: 1.7746632432424894

Epoch: 5| Step: 1
Training loss: 0.7993730306625366
Validation loss: 1.7338690514205604

Epoch: 5| Step: 2
Training loss: 1.3214552402496338
Validation loss: 1.8023134790441042

Epoch: 5| Step: 3
Training loss: 0.6342798471450806
Validation loss: 1.808863542413199

Epoch: 5| Step: 4
Training loss: 1.3000050783157349
Validation loss: 1.7899263622940227

Epoch: 5| Step: 5
Training loss: 0.6791579127311707
Validation loss: 1.790190327552057

Epoch: 5| Step: 6
Training loss: 0.8347543478012085
Validation loss: 1.7872171312250116

Epoch: 5| Step: 7
Training loss: 1.0452100038528442
Validation loss: 1.7404880369863203

Epoch: 5| Step: 8
Training loss: 0.8589568138122559
Validation loss: 1.732279102007548

Epoch: 5| Step: 9
Training loss: 1.4684219360351562
Validation loss: 1.7533294423933952

Epoch: 5| Step: 10
Training loss: 1.011404275894165
Validation loss: 1.7724617732468473

Epoch: 551| Step: 0
Training loss: 0.8888424038887024
Validation loss: 1.8046219336089266

Epoch: 5| Step: 1
Training loss: 1.017946481704712
Validation loss: 1.7567835905218636

Epoch: 5| Step: 2
Training loss: 1.460326075553894
Validation loss: 1.7158790044887091

Epoch: 5| Step: 3
Training loss: 0.8800357580184937
Validation loss: 1.732234521578717

Epoch: 5| Step: 4
Training loss: 1.0510506629943848
Validation loss: 1.7906454750286636

Epoch: 5| Step: 5
Training loss: 1.2499432563781738
Validation loss: 1.7497005090918591

Epoch: 5| Step: 6
Training loss: 0.6768840551376343
Validation loss: 1.7923159932577482

Epoch: 5| Step: 7
Training loss: 1.2898105382919312
Validation loss: 1.7632217804590862

Epoch: 5| Step: 8
Training loss: 1.1695032119750977
Validation loss: 1.6950629103568293

Epoch: 5| Step: 9
Training loss: 1.0821164846420288
Validation loss: 1.7715191302760955

Epoch: 5| Step: 10
Training loss: 1.0045547485351562
Validation loss: 1.8287161229759135

Epoch: 552| Step: 0
Training loss: 0.971021294593811
Validation loss: 1.7961359844412854

Epoch: 5| Step: 1
Training loss: 0.708861231803894
Validation loss: 1.7399407291925082

Epoch: 5| Step: 2
Training loss: 0.7898291349411011
Validation loss: 1.7965699524007819

Epoch: 5| Step: 3
Training loss: 0.6739156246185303
Validation loss: 1.8064542380712365

Epoch: 5| Step: 4
Training loss: 1.4063440561294556
Validation loss: 1.7609453688385666

Epoch: 5| Step: 5
Training loss: 1.2019997835159302
Validation loss: 1.8079016759831419

Epoch: 5| Step: 6
Training loss: 1.2618399858474731
Validation loss: 1.8460722507969025

Epoch: 5| Step: 7
Training loss: 0.950508713722229
Validation loss: 1.783633187252988

Epoch: 5| Step: 8
Training loss: 0.9957060813903809
Validation loss: 1.7685853691511257

Epoch: 5| Step: 9
Training loss: 1.6347167491912842
Validation loss: 1.7813980425557783

Epoch: 5| Step: 10
Training loss: 0.5955688953399658
Validation loss: 1.7628004422751806

Epoch: 553| Step: 0
Training loss: 1.631529450416565
Validation loss: 1.7523918703038206

Epoch: 5| Step: 1
Training loss: 0.9396525621414185
Validation loss: 1.8214387047675349

Epoch: 5| Step: 2
Training loss: 0.5242214798927307
Validation loss: 1.740309428143245

Epoch: 5| Step: 3
Training loss: 1.0033681392669678
Validation loss: 1.7571291462067635

Epoch: 5| Step: 4
Training loss: 1.2898645401000977
Validation loss: 1.742727033553585

Epoch: 5| Step: 5
Training loss: 0.579104483127594
Validation loss: 1.7490655465792584

Epoch: 5| Step: 6
Training loss: 1.356695532798767
Validation loss: 1.7682738175956152

Epoch: 5| Step: 7
Training loss: 1.3272078037261963
Validation loss: 1.7641162731314217

Epoch: 5| Step: 8
Training loss: 0.9048044085502625
Validation loss: 1.7687683272105392

Epoch: 5| Step: 9
Training loss: 1.1881320476531982
Validation loss: 1.779820837000365

Epoch: 5| Step: 10
Training loss: 0.9750034213066101
Validation loss: 1.7650472464100007

Epoch: 554| Step: 0
Training loss: 1.4028345346450806
Validation loss: 1.7795135026337

Epoch: 5| Step: 1
Training loss: 1.28336501121521
Validation loss: 1.7854018980456936

Epoch: 5| Step: 2
Training loss: 0.9466851949691772
Validation loss: 1.8292178453937653

Epoch: 5| Step: 3
Training loss: 0.8958951830863953
Validation loss: 1.7686570100886847

Epoch: 5| Step: 4
Training loss: 1.0007843971252441
Validation loss: 1.7475618111189974

Epoch: 5| Step: 5
Training loss: 1.0260379314422607
Validation loss: 1.7361385245477

Epoch: 5| Step: 6
Training loss: 0.8492571115493774
Validation loss: 1.745639407506553

Epoch: 5| Step: 7
Training loss: 1.009114384651184
Validation loss: 1.7601983598483506

Epoch: 5| Step: 8
Training loss: 1.3013883829116821
Validation loss: 1.777538727688533

Epoch: 5| Step: 9
Training loss: 1.0577970743179321
Validation loss: 1.7456005414326985

Epoch: 5| Step: 10
Training loss: 0.9585975408554077
Validation loss: 1.7805846006639543

Epoch: 555| Step: 0
Training loss: 1.4177210330963135
Validation loss: 1.763286671330852

Epoch: 5| Step: 1
Training loss: 1.463169813156128
Validation loss: 1.7928923458181403

Epoch: 5| Step: 2
Training loss: 0.8880883455276489
Validation loss: 1.692497831518932

Epoch: 5| Step: 3
Training loss: 1.2146059274673462
Validation loss: 1.788022752731077

Epoch: 5| Step: 4
Training loss: 1.2077200412750244
Validation loss: 1.7590254570848198

Epoch: 5| Step: 5
Training loss: 0.5928485989570618
Validation loss: 1.796601221125613

Epoch: 5| Step: 6
Training loss: 0.5961689949035645
Validation loss: 1.8017230085147324

Epoch: 5| Step: 7
Training loss: 0.9436159133911133
Validation loss: 1.763030198312575

Epoch: 5| Step: 8
Training loss: 0.7597070932388306
Validation loss: 1.7681432975235807

Epoch: 5| Step: 9
Training loss: 1.0744681358337402
Validation loss: 1.7396914766680809

Epoch: 5| Step: 10
Training loss: 1.5057235956192017
Validation loss: 1.7378952810841222

Epoch: 556| Step: 0
Training loss: 1.6201874017715454
Validation loss: 1.7668360048724758

Epoch: 5| Step: 1
Training loss: 0.777682900428772
Validation loss: 1.7368758609217982

Epoch: 5| Step: 2
Training loss: 0.872056782245636
Validation loss: 1.7727315874509915

Epoch: 5| Step: 3
Training loss: 0.6871703863143921
Validation loss: 1.806849282274964

Epoch: 5| Step: 4
Training loss: 1.156790018081665
Validation loss: 1.801513264256139

Epoch: 5| Step: 5
Training loss: 1.0714128017425537
Validation loss: 1.7992145233256842

Epoch: 5| Step: 6
Training loss: 1.1581438779830933
Validation loss: 1.754374365652761

Epoch: 5| Step: 7
Training loss: 1.052621603012085
Validation loss: 1.8285120917904762

Epoch: 5| Step: 8
Training loss: 1.213670015335083
Validation loss: 1.7744428060388053

Epoch: 5| Step: 9
Training loss: 0.6812838912010193
Validation loss: 1.770882378342331

Epoch: 5| Step: 10
Training loss: 1.4778802394866943
Validation loss: 1.827870189502675

Epoch: 557| Step: 0
Training loss: 0.9268407821655273
Validation loss: 1.7822245923421716

Epoch: 5| Step: 1
Training loss: 1.0237371921539307
Validation loss: 1.7542407358846357

Epoch: 5| Step: 2
Training loss: 1.2989227771759033
Validation loss: 1.799217580467142

Epoch: 5| Step: 3
Training loss: 0.7877209186553955
Validation loss: 1.7457276723718131

Epoch: 5| Step: 4
Training loss: 1.2373015880584717
Validation loss: 1.6874573461471065

Epoch: 5| Step: 5
Training loss: 1.432269811630249
Validation loss: 1.7912591375330442

Epoch: 5| Step: 6
Training loss: 0.7302111983299255
Validation loss: 1.7601649094653387

Epoch: 5| Step: 7
Training loss: 1.0255868434906006
Validation loss: 1.7435759011135306

Epoch: 5| Step: 8
Training loss: 1.108760118484497
Validation loss: 1.7480293486707954

Epoch: 5| Step: 9
Training loss: 1.2186832427978516
Validation loss: 1.7436611504964932

Epoch: 5| Step: 10
Training loss: 1.0439882278442383
Validation loss: 1.7580641726011872

Epoch: 558| Step: 0
Training loss: 1.2436542510986328
Validation loss: 1.763160474838749

Epoch: 5| Step: 1
Training loss: 0.9040759801864624
Validation loss: 1.7446451417861446

Epoch: 5| Step: 2
Training loss: 1.1454813480377197
Validation loss: 1.7894976985070012

Epoch: 5| Step: 3
Training loss: 0.7510048151016235
Validation loss: 1.7428739404165616

Epoch: 5| Step: 4
Training loss: 0.9329339861869812
Validation loss: 1.7793386508059759

Epoch: 5| Step: 5
Training loss: 0.9076727032661438
Validation loss: 1.827634060254661

Epoch: 5| Step: 6
Training loss: 1.340710997581482
Validation loss: 1.7145414839508712

Epoch: 5| Step: 7
Training loss: 1.0138890743255615
Validation loss: 1.7722906310071227

Epoch: 5| Step: 8
Training loss: 1.2388118505477905
Validation loss: 1.7788236295023272

Epoch: 5| Step: 9
Training loss: 0.9397388696670532
Validation loss: 1.815255868819452

Epoch: 5| Step: 10
Training loss: 1.0375800132751465
Validation loss: 1.791300997939161

Epoch: 559| Step: 0
Training loss: 1.0597524642944336
Validation loss: 1.8211960177267752

Epoch: 5| Step: 1
Training loss: 1.2021909952163696
Validation loss: 1.7660558556997648

Epoch: 5| Step: 2
Training loss: 1.2417863607406616
Validation loss: 1.7962547989301785

Epoch: 5| Step: 3
Training loss: 0.9005451202392578
Validation loss: 1.797363752959877

Epoch: 5| Step: 4
Training loss: 0.7777026891708374
Validation loss: 1.7598948145425448

Epoch: 5| Step: 5
Training loss: 1.1456598043441772
Validation loss: 1.7510094129911034

Epoch: 5| Step: 6
Training loss: 1.0068614482879639
Validation loss: 1.7465945956527547

Epoch: 5| Step: 7
Training loss: 1.4875351190567017
Validation loss: 1.7333468596140544

Epoch: 5| Step: 8
Training loss: 0.9721872210502625
Validation loss: 1.7514038034664687

Epoch: 5| Step: 9
Training loss: 0.9537037014961243
Validation loss: 1.6916664684972456

Epoch: 5| Step: 10
Training loss: 1.3422290086746216
Validation loss: 1.7665322724209036

Epoch: 560| Step: 0
Training loss: 0.8771230578422546
Validation loss: 1.8266335815511725

Epoch: 5| Step: 1
Training loss: 0.9562276005744934
Validation loss: 1.7380881309509277

Epoch: 5| Step: 2
Training loss: 1.0505750179290771
Validation loss: 1.7894214186617123

Epoch: 5| Step: 3
Training loss: 0.9607244729995728
Validation loss: 1.799174375431512

Epoch: 5| Step: 4
Training loss: 0.610352098941803
Validation loss: 1.7150143795115973

Epoch: 5| Step: 5
Training loss: 1.1312341690063477
Validation loss: 1.789132074643207

Epoch: 5| Step: 6
Training loss: 1.27963125705719
Validation loss: 1.7803362313137259

Epoch: 5| Step: 7
Training loss: 1.0961096286773682
Validation loss: 1.7780479077369935

Epoch: 5| Step: 8
Training loss: 1.2727038860321045
Validation loss: 1.730637522153957

Epoch: 5| Step: 9
Training loss: 0.8173543810844421
Validation loss: 1.7966980523960565

Epoch: 5| Step: 10
Training loss: 1.424652099609375
Validation loss: 1.8349332835084649

Epoch: 561| Step: 0
Training loss: 1.0941911935806274
Validation loss: 1.8062082990523307

Epoch: 5| Step: 1
Training loss: 0.7983044385910034
Validation loss: 1.8455649242606214

Epoch: 5| Step: 2
Training loss: 1.0602247714996338
Validation loss: 1.8048093472757647

Epoch: 5| Step: 3
Training loss: 0.951621413230896
Validation loss: 1.755949511322924

Epoch: 5| Step: 4
Training loss: 0.7520450353622437
Validation loss: 1.7636001366440968

Epoch: 5| Step: 5
Training loss: 0.6881610751152039
Validation loss: 1.7840497891108196

Epoch: 5| Step: 6
Training loss: 1.1876108646392822
Validation loss: 1.7275236152833509

Epoch: 5| Step: 7
Training loss: 1.0030232667922974
Validation loss: 1.7343959180257653

Epoch: 5| Step: 8
Training loss: 1.8339439630508423
Validation loss: 1.7843199545337307

Epoch: 5| Step: 9
Training loss: 1.2079318761825562
Validation loss: 1.7862351350886847

Epoch: 5| Step: 10
Training loss: 0.9026983380317688
Validation loss: 1.7541882491880847

Epoch: 562| Step: 0
Training loss: 1.096181869506836
Validation loss: 1.8454704310304375

Epoch: 5| Step: 1
Training loss: 1.2344471216201782
Validation loss: 1.7923085279362176

Epoch: 5| Step: 2
Training loss: 1.267324686050415
Validation loss: 1.7946816311087659

Epoch: 5| Step: 3
Training loss: 1.093625783920288
Validation loss: 1.7853579482724589

Epoch: 5| Step: 4
Training loss: 0.7466924786567688
Validation loss: 1.7635027811091433

Epoch: 5| Step: 5
Training loss: 1.3093326091766357
Validation loss: 1.7413316619011663

Epoch: 5| Step: 6
Training loss: 0.6207723021507263
Validation loss: 1.7870007356007893

Epoch: 5| Step: 7
Training loss: 1.0084959268569946
Validation loss: 1.7508264523680492

Epoch: 5| Step: 8
Training loss: 0.926779568195343
Validation loss: 1.82295391508328

Epoch: 5| Step: 9
Training loss: 1.1920546293258667
Validation loss: 1.8039556959623932

Epoch: 5| Step: 10
Training loss: 1.007861614227295
Validation loss: 1.824471236557089

Epoch: 563| Step: 0
Training loss: 1.1455166339874268
Validation loss: 1.737170551412849

Epoch: 5| Step: 1
Training loss: 0.7042078971862793
Validation loss: 1.8028584270067112

Epoch: 5| Step: 2
Training loss: 0.993636429309845
Validation loss: 1.7752437822280391

Epoch: 5| Step: 3
Training loss: 0.9831594228744507
Validation loss: 1.7838926007670741

Epoch: 5| Step: 4
Training loss: 1.024593710899353
Validation loss: 1.7922945701947777

Epoch: 5| Step: 5
Training loss: 0.6818385124206543
Validation loss: 1.7419448206501622

Epoch: 5| Step: 6
Training loss: 0.987321674823761
Validation loss: 1.7298110902950328

Epoch: 5| Step: 7
Training loss: 1.0898644924163818
Validation loss: 1.831773465679538

Epoch: 5| Step: 8
Training loss: 1.4271800518035889
Validation loss: 1.7751355709568146

Epoch: 5| Step: 9
Training loss: 1.2786973714828491
Validation loss: 1.7218455858128046

Epoch: 5| Step: 10
Training loss: 1.2043884992599487
Validation loss: 1.7667123925301336

Epoch: 564| Step: 0
Training loss: 0.9818808436393738
Validation loss: 1.7835612104785057

Epoch: 5| Step: 1
Training loss: 1.415810227394104
Validation loss: 1.6915492268018826

Epoch: 5| Step: 2
Training loss: 0.8000475168228149
Validation loss: 1.743393200700001

Epoch: 5| Step: 3
Training loss: 1.147206425666809
Validation loss: 1.7786024847338278

Epoch: 5| Step: 4
Training loss: 1.2348846197128296
Validation loss: 1.7606574835315827

Epoch: 5| Step: 5
Training loss: 1.0479137897491455
Validation loss: 1.8148979807412753

Epoch: 5| Step: 6
Training loss: 0.5733794569969177
Validation loss: 1.7533791347216534

Epoch: 5| Step: 7
Training loss: 0.6987581849098206
Validation loss: 1.781213216884162

Epoch: 5| Step: 8
Training loss: 0.9711999893188477
Validation loss: 1.7874343318323935

Epoch: 5| Step: 9
Training loss: 1.1929069757461548
Validation loss: 1.7713054405745638

Epoch: 5| Step: 10
Training loss: 1.184368371963501
Validation loss: 1.7422238408878286

Epoch: 565| Step: 0
Training loss: 1.25312077999115
Validation loss: 1.8095474371346094

Epoch: 5| Step: 1
Training loss: 0.8003109693527222
Validation loss: 1.7330558043654247

Epoch: 5| Step: 2
Training loss: 0.8163771629333496
Validation loss: 1.8390457783975909

Epoch: 5| Step: 3
Training loss: 1.094733715057373
Validation loss: 1.765701473400157

Epoch: 5| Step: 4
Training loss: 0.9909189343452454
Validation loss: 1.8096775431786813

Epoch: 5| Step: 5
Training loss: 1.114522933959961
Validation loss: 1.7743197487246605

Epoch: 5| Step: 6
Training loss: 1.1356512308120728
Validation loss: 1.7351592048521964

Epoch: 5| Step: 7
Training loss: 0.9827211499214172
Validation loss: 1.8346633218949842

Epoch: 5| Step: 8
Training loss: 0.663804292678833
Validation loss: 1.7589118480682373

Epoch: 5| Step: 9
Training loss: 1.2589188814163208
Validation loss: 1.7554010921908962

Epoch: 5| Step: 10
Training loss: 1.0404881238937378
Validation loss: 1.748923082505503

Epoch: 566| Step: 0
Training loss: 1.1657723188400269
Validation loss: 1.7335363870025964

Epoch: 5| Step: 1
Training loss: 1.1451301574707031
Validation loss: 1.81115593576944

Epoch: 5| Step: 2
Training loss: 0.7089406251907349
Validation loss: 1.769439156337451

Epoch: 5| Step: 3
Training loss: 0.9342802166938782
Validation loss: 1.7456361375829226

Epoch: 5| Step: 4
Training loss: 1.0871526002883911
Validation loss: 1.7036041149529078

Epoch: 5| Step: 5
Training loss: 1.2857472896575928
Validation loss: 1.7404378934573101

Epoch: 5| Step: 6
Training loss: 0.825247585773468
Validation loss: 1.764455992688415

Epoch: 5| Step: 7
Training loss: 1.0898736715316772
Validation loss: 1.7878961857929025

Epoch: 5| Step: 8
Training loss: 0.9575983285903931
Validation loss: 1.7608434154141335

Epoch: 5| Step: 9
Training loss: 0.7753394246101379
Validation loss: 1.7639309872863114

Epoch: 5| Step: 10
Training loss: 1.3712366819381714
Validation loss: 1.7578864456504903

Epoch: 567| Step: 0
Training loss: 1.3092074394226074
Validation loss: 1.8229708543387793

Epoch: 5| Step: 1
Training loss: 1.3904348611831665
Validation loss: 1.7965130575241581

Epoch: 5| Step: 2
Training loss: 0.8626931309700012
Validation loss: 1.7714238500082364

Epoch: 5| Step: 3
Training loss: 0.9440679550170898
Validation loss: 1.8196233421243646

Epoch: 5| Step: 4
Training loss: 0.8113049268722534
Validation loss: 1.7665472428003948

Epoch: 5| Step: 5
Training loss: 1.0311065912246704
Validation loss: 1.8113248514872726

Epoch: 5| Step: 6
Training loss: 1.1594167947769165
Validation loss: 1.731145889528336

Epoch: 5| Step: 7
Training loss: 1.163851022720337
Validation loss: 1.7712544138713548

Epoch: 5| Step: 8
Training loss: 0.8361202478408813
Validation loss: 1.6818165368931268

Epoch: 5| Step: 9
Training loss: 1.1114243268966675
Validation loss: 1.7822589105175388

Epoch: 5| Step: 10
Training loss: 0.722506582736969
Validation loss: 1.7629733623996857

Epoch: 568| Step: 0
Training loss: 0.851736843585968
Validation loss: 1.7585191072956208

Epoch: 5| Step: 1
Training loss: 1.1886482238769531
Validation loss: 1.7649425268173218

Epoch: 5| Step: 2
Training loss: 1.0670826435089111
Validation loss: 1.735676578296128

Epoch: 5| Step: 3
Training loss: 1.310961127281189
Validation loss: 1.7482100186809417

Epoch: 5| Step: 4
Training loss: 1.0114974975585938
Validation loss: 1.8007107716734692

Epoch: 5| Step: 5
Training loss: 0.6523565649986267
Validation loss: 1.7352577409436625

Epoch: 5| Step: 6
Training loss: 0.8771837949752808
Validation loss: 1.720681510945802

Epoch: 5| Step: 7
Training loss: 0.8059277534484863
Validation loss: 1.7578534887683006

Epoch: 5| Step: 8
Training loss: 0.9776245951652527
Validation loss: 1.7830936062720515

Epoch: 5| Step: 9
Training loss: 1.2965301275253296
Validation loss: 1.7499182929274857

Epoch: 5| Step: 10
Training loss: 1.0463342666625977
Validation loss: 1.7374977552762596

Epoch: 569| Step: 0
Training loss: 0.5930436849594116
Validation loss: 1.7617523567650908

Epoch: 5| Step: 1
Training loss: 0.9573947787284851
Validation loss: 1.7359557151794434

Epoch: 5| Step: 2
Training loss: 1.0092923641204834
Validation loss: 1.7992062055936424

Epoch: 5| Step: 3
Training loss: 0.7968761324882507
Validation loss: 1.7729534513206893

Epoch: 5| Step: 4
Training loss: 1.3624974489212036
Validation loss: 1.727858079377041

Epoch: 5| Step: 5
Training loss: 1.1475074291229248
Validation loss: 1.7330689942964943

Epoch: 5| Step: 6
Training loss: 1.2291944026947021
Validation loss: 1.717845905211664

Epoch: 5| Step: 7
Training loss: 1.2058804035186768
Validation loss: 1.8072904540646462

Epoch: 5| Step: 8
Training loss: 0.6977430582046509
Validation loss: 1.7394855330067296

Epoch: 5| Step: 9
Training loss: 1.1459449529647827
Validation loss: 1.8050788961431032

Epoch: 5| Step: 10
Training loss: 1.0530238151550293
Validation loss: 1.7526025900276758

Epoch: 570| Step: 0
Training loss: 0.5541342496871948
Validation loss: 1.7401160796483357

Epoch: 5| Step: 1
Training loss: 1.145193338394165
Validation loss: 1.7704087995713758

Epoch: 5| Step: 2
Training loss: 0.8931854367256165
Validation loss: 1.7802303157826906

Epoch: 5| Step: 3
Training loss: 0.9733062982559204
Validation loss: 1.7965284944862447

Epoch: 5| Step: 4
Training loss: 0.777109682559967
Validation loss: 1.8037187694221415

Epoch: 5| Step: 5
Training loss: 1.0965286493301392
Validation loss: 1.7954086090928765

Epoch: 5| Step: 6
Training loss: 1.0483616590499878
Validation loss: 1.7584396664814284

Epoch: 5| Step: 7
Training loss: 1.2410584688186646
Validation loss: 1.8100363759584324

Epoch: 5| Step: 8
Training loss: 1.162801742553711
Validation loss: 1.7545257358140842

Epoch: 5| Step: 9
Training loss: 1.2174891233444214
Validation loss: 1.7664735471048663

Epoch: 5| Step: 10
Training loss: 1.053943395614624
Validation loss: 1.7864413697232482

Epoch: 571| Step: 0
Training loss: 1.169275164604187
Validation loss: 1.7904084132563682

Epoch: 5| Step: 1
Training loss: 1.2723678350448608
Validation loss: 1.8673338928530294

Epoch: 5| Step: 2
Training loss: 0.9094201922416687
Validation loss: 1.7648518598207863

Epoch: 5| Step: 3
Training loss: 1.0356230735778809
Validation loss: 1.765884445559594

Epoch: 5| Step: 4
Training loss: 0.8463122248649597
Validation loss: 1.7827953177113687

Epoch: 5| Step: 5
Training loss: 0.8335675001144409
Validation loss: 1.7697520038133026

Epoch: 5| Step: 6
Training loss: 1.1747846603393555
Validation loss: 1.7535458674994848

Epoch: 5| Step: 7
Training loss: 1.2307841777801514
Validation loss: 1.7511872553056287

Epoch: 5| Step: 8
Training loss: 0.8844143748283386
Validation loss: 1.779845167231816

Epoch: 5| Step: 9
Training loss: 1.188843011856079
Validation loss: 1.767030108359552

Epoch: 5| Step: 10
Training loss: 1.0172457695007324
Validation loss: 1.7324720980018697

Epoch: 572| Step: 0
Training loss: 1.2213624715805054
Validation loss: 1.7818718084725

Epoch: 5| Step: 1
Training loss: 0.8889982104301453
Validation loss: 1.7665182569975495

Epoch: 5| Step: 2
Training loss: 0.994724452495575
Validation loss: 1.7355113926754202

Epoch: 5| Step: 3
Training loss: 0.767596423625946
Validation loss: 1.7925638383434666

Epoch: 5| Step: 4
Training loss: 1.2243112325668335
Validation loss: 1.7869384948925306

Epoch: 5| Step: 5
Training loss: 1.0447978973388672
Validation loss: 1.778298383118004

Epoch: 5| Step: 6
Training loss: 0.9401509165763855
Validation loss: 1.7799692435931134

Epoch: 5| Step: 7
Training loss: 0.897129237651825
Validation loss: 1.7585099127984816

Epoch: 5| Step: 8
Training loss: 1.1858009099960327
Validation loss: 1.7699993797527847

Epoch: 5| Step: 9
Training loss: 0.5749344229698181
Validation loss: 1.7529972061034171

Epoch: 5| Step: 10
Training loss: 1.403570294380188
Validation loss: 1.7631587700177265

Epoch: 573| Step: 0
Training loss: 0.951429009437561
Validation loss: 1.7671326411667692

Epoch: 5| Step: 1
Training loss: 1.2250031232833862
Validation loss: 1.7170449995225476

Epoch: 5| Step: 2
Training loss: 0.7780750393867493
Validation loss: 1.8567107672332435

Epoch: 5| Step: 3
Training loss: 1.221356987953186
Validation loss: 1.7690360533293856

Epoch: 5| Step: 4
Training loss: 1.0941840410232544
Validation loss: 1.800745193676282

Epoch: 5| Step: 5
Training loss: 0.745522677898407
Validation loss: 1.8115320359506915

Epoch: 5| Step: 6
Training loss: 0.7537514567375183
Validation loss: 1.7260645679248277

Epoch: 5| Step: 7
Training loss: 1.4480488300323486
Validation loss: 1.800099095990581

Epoch: 5| Step: 8
Training loss: 1.0359009504318237
Validation loss: 1.7553866883759857

Epoch: 5| Step: 9
Training loss: 0.9603792428970337
Validation loss: 1.7395354368353402

Epoch: 5| Step: 10
Training loss: 0.948828399181366
Validation loss: 1.8008848954272527

Epoch: 574| Step: 0
Training loss: 0.9624778628349304
Validation loss: 1.8664233107720651

Epoch: 5| Step: 1
Training loss: 1.0051906108856201
Validation loss: 1.729361852010091

Epoch: 5| Step: 2
Training loss: 1.2690880298614502
Validation loss: 1.8045300206830424

Epoch: 5| Step: 3
Training loss: 0.9112933278083801
Validation loss: 1.7855010250563264

Epoch: 5| Step: 4
Training loss: 0.837731659412384
Validation loss: 1.743904495751986

Epoch: 5| Step: 5
Training loss: 0.8707395792007446
Validation loss: 1.7724092750139133

Epoch: 5| Step: 6
Training loss: 1.0467517375946045
Validation loss: 1.782853643099467

Epoch: 5| Step: 7
Training loss: 0.5060020685195923
Validation loss: 1.7770015078206216

Epoch: 5| Step: 8
Training loss: 1.12735915184021
Validation loss: 1.767900796346767

Epoch: 5| Step: 9
Training loss: 1.332054615020752
Validation loss: 1.7154188822674494

Epoch: 5| Step: 10
Training loss: 1.0828381776809692
Validation loss: 1.7274834558527956

Epoch: 575| Step: 0
Training loss: 0.8377917408943176
Validation loss: 1.7574425282016877

Epoch: 5| Step: 1
Training loss: 1.0283839702606201
Validation loss: 1.746280945757384

Epoch: 5| Step: 2
Training loss: 1.4143428802490234
Validation loss: 1.7679852888148317

Epoch: 5| Step: 3
Training loss: 1.2342851161956787
Validation loss: 1.7940226472834104

Epoch: 5| Step: 4
Training loss: 0.6699213981628418
Validation loss: 1.7700672316294845

Epoch: 5| Step: 5
Training loss: 1.2244904041290283
Validation loss: 1.795322802758986

Epoch: 5| Step: 6
Training loss: 1.1579526662826538
Validation loss: 1.870328898070961

Epoch: 5| Step: 7
Training loss: 1.1688083410263062
Validation loss: 1.725138214326674

Epoch: 5| Step: 8
Training loss: 0.821491539478302
Validation loss: 1.7124358172057776

Epoch: 5| Step: 9
Training loss: 0.791330099105835
Validation loss: 1.7372399940285632

Epoch: 5| Step: 10
Training loss: 0.9432568550109863
Validation loss: 1.7327009119013304

Epoch: 576| Step: 0
Training loss: 1.134364366531372
Validation loss: 1.7851031698206419

Epoch: 5| Step: 1
Training loss: 0.6858586072921753
Validation loss: 1.7888046169793734

Epoch: 5| Step: 2
Training loss: 0.8669217824935913
Validation loss: 1.7695388922127344

Epoch: 5| Step: 3
Training loss: 0.8772838711738586
Validation loss: 1.7671950940162904

Epoch: 5| Step: 4
Training loss: 0.5076242685317993
Validation loss: 1.7956560004142024

Epoch: 5| Step: 5
Training loss: 0.9940549731254578
Validation loss: 1.7163828611373901

Epoch: 5| Step: 6
Training loss: 1.224906086921692
Validation loss: 1.7891268678890762

Epoch: 5| Step: 7
Training loss: 1.1407188177108765
Validation loss: 1.7466131410291117

Epoch: 5| Step: 8
Training loss: 1.200641393661499
Validation loss: 1.803805169238839

Epoch: 5| Step: 9
Training loss: 1.2374522686004639
Validation loss: 1.7318369996163152

Epoch: 5| Step: 10
Training loss: 1.1983399391174316
Validation loss: 1.7104190062451106

Epoch: 577| Step: 0
Training loss: 1.2483993768692017
Validation loss: 1.8462753757353751

Epoch: 5| Step: 1
Training loss: 1.1300404071807861
Validation loss: 1.747785980983447

Epoch: 5| Step: 2
Training loss: 0.9245355725288391
Validation loss: 1.737415575212048

Epoch: 5| Step: 3
Training loss: 0.5931498408317566
Validation loss: 1.7973917350974133

Epoch: 5| Step: 4
Training loss: 1.1373379230499268
Validation loss: 1.748339162077955

Epoch: 5| Step: 5
Training loss: 0.8790278434753418
Validation loss: 1.7809120532005065

Epoch: 5| Step: 6
Training loss: 0.5707610845565796
Validation loss: 1.7688928804089945

Epoch: 5| Step: 7
Training loss: 1.7340424060821533
Validation loss: 1.799610089230281

Epoch: 5| Step: 8
Training loss: 0.7929880619049072
Validation loss: 1.666514140303417

Epoch: 5| Step: 9
Training loss: 1.0939793586730957
Validation loss: 1.7641551725326046

Epoch: 5| Step: 10
Training loss: 0.8493766784667969
Validation loss: 1.7789212760104929

Epoch: 578| Step: 0
Training loss: 1.0101035833358765
Validation loss: 1.8171138686518515

Epoch: 5| Step: 1
Training loss: 1.0055747032165527
Validation loss: 1.776977623662641

Epoch: 5| Step: 2
Training loss: 1.0874519348144531
Validation loss: 1.8006370631597375

Epoch: 5| Step: 3
Training loss: 0.6892803907394409
Validation loss: 1.7686821491487565

Epoch: 5| Step: 4
Training loss: 1.3921654224395752
Validation loss: 1.7408819660063712

Epoch: 5| Step: 5
Training loss: 1.3011399507522583
Validation loss: 1.7414569880372734

Epoch: 5| Step: 6
Training loss: 0.7497774958610535
Validation loss: 1.7319911449186263

Epoch: 5| Step: 7
Training loss: 1.0760738849639893
Validation loss: 1.751562326185165

Epoch: 5| Step: 8
Training loss: 0.5804580450057983
Validation loss: 1.7736182571739278

Epoch: 5| Step: 9
Training loss: 1.268467664718628
Validation loss: 1.7643796500339304

Epoch: 5| Step: 10
Training loss: 0.5754379034042358
Validation loss: 1.7650509342070548

Epoch: 579| Step: 0
Training loss: 1.190558671951294
Validation loss: 1.7666943714182863

Epoch: 5| Step: 1
Training loss: 1.1103771924972534
Validation loss: 1.7262544221775507

Epoch: 5| Step: 2
Training loss: 0.9445871114730835
Validation loss: 1.7511065941984936

Epoch: 5| Step: 3
Training loss: 0.6622965931892395
Validation loss: 1.7760330118158811

Epoch: 5| Step: 4
Training loss: 0.7151921987533569
Validation loss: 1.7898609279304423

Epoch: 5| Step: 5
Training loss: 0.7979866862297058
Validation loss: 1.7931899793686406

Epoch: 5| Step: 6
Training loss: 0.5804225206375122
Validation loss: 1.7667701269990654

Epoch: 5| Step: 7
Training loss: 1.3706403970718384
Validation loss: 1.761641985626631

Epoch: 5| Step: 8
Training loss: 0.9889861941337585
Validation loss: 1.759424441604204

Epoch: 5| Step: 9
Training loss: 1.148128628730774
Validation loss: 1.7339957414134857

Epoch: 5| Step: 10
Training loss: 1.4863038063049316
Validation loss: 1.7379438864287509

Epoch: 580| Step: 0
Training loss: 1.1811716556549072
Validation loss: 1.7020006756628714

Epoch: 5| Step: 1
Training loss: 0.9940388798713684
Validation loss: 1.7387929026798536

Epoch: 5| Step: 2
Training loss: 0.8108512759208679
Validation loss: 1.7552189839783536

Epoch: 5| Step: 3
Training loss: 1.272911787033081
Validation loss: 1.8087487836037912

Epoch: 5| Step: 4
Training loss: 1.029153823852539
Validation loss: 1.791766389723747

Epoch: 5| Step: 5
Training loss: 1.1751645803451538
Validation loss: 1.775308915363845

Epoch: 5| Step: 6
Training loss: 1.0493261814117432
Validation loss: 1.767774994655322

Epoch: 5| Step: 7
Training loss: 0.6620934009552002
Validation loss: 1.7673996046025267

Epoch: 5| Step: 8
Training loss: 0.860289454460144
Validation loss: 1.7953978584658714

Epoch: 5| Step: 9
Training loss: 0.9447256326675415
Validation loss: 1.7591394506474978

Epoch: 5| Step: 10
Training loss: 0.9863303899765015
Validation loss: 1.7769854799393685

Epoch: 581| Step: 0
Training loss: 1.105578064918518
Validation loss: 1.7357915793695757

Epoch: 5| Step: 1
Training loss: 1.001267910003662
Validation loss: 1.7413714829311575

Epoch: 5| Step: 2
Training loss: 0.9187809228897095
Validation loss: 1.7701383918844245

Epoch: 5| Step: 3
Training loss: 0.899697482585907
Validation loss: 1.7564580735339914

Epoch: 5| Step: 4
Training loss: 1.2908049821853638
Validation loss: 1.7776904003594511

Epoch: 5| Step: 5
Training loss: 0.7606304883956909
Validation loss: 1.735602314754199

Epoch: 5| Step: 6
Training loss: 1.2323083877563477
Validation loss: 1.7302224802714523

Epoch: 5| Step: 7
Training loss: 0.8975321650505066
Validation loss: 1.783820390701294

Epoch: 5| Step: 8
Training loss: 0.7735499739646912
Validation loss: 1.7777535312919206

Epoch: 5| Step: 9
Training loss: 0.9787331819534302
Validation loss: 1.753356683638788

Epoch: 5| Step: 10
Training loss: 1.0200774669647217
Validation loss: 1.7758379873409067

Epoch: 582| Step: 0
Training loss: 1.3036625385284424
Validation loss: 1.784355003346679

Epoch: 5| Step: 1
Training loss: 0.9454953074455261
Validation loss: 1.7772248047654347

Epoch: 5| Step: 2
Training loss: 0.7538946866989136
Validation loss: 1.7419769097399969

Epoch: 5| Step: 3
Training loss: 0.8368984460830688
Validation loss: 1.7531169345301967

Epoch: 5| Step: 4
Training loss: 0.9558904767036438
Validation loss: 1.7613570677336825

Epoch: 5| Step: 5
Training loss: 1.0831191539764404
Validation loss: 1.7359155365215835

Epoch: 5| Step: 6
Training loss: 1.1208118200302124
Validation loss: 1.7755896711862216

Epoch: 5| Step: 7
Training loss: 0.67920982837677
Validation loss: 1.8255028673397597

Epoch: 5| Step: 8
Training loss: 1.2313929796218872
Validation loss: 1.7440803755996048

Epoch: 5| Step: 9
Training loss: 1.0593862533569336
Validation loss: 1.7890034350015784

Epoch: 5| Step: 10
Training loss: 1.3765227794647217
Validation loss: 1.8241688794987176

Epoch: 583| Step: 0
Training loss: 0.941201388835907
Validation loss: 1.8114458053342757

Epoch: 5| Step: 1
Training loss: 0.7777628898620605
Validation loss: 1.7401883563687723

Epoch: 5| Step: 2
Training loss: 0.7905228734016418
Validation loss: 1.8307632964144471

Epoch: 5| Step: 3
Training loss: 0.8554466962814331
Validation loss: 1.7388692389252365

Epoch: 5| Step: 4
Training loss: 0.9858708381652832
Validation loss: 1.7463324621159544

Epoch: 5| Step: 5
Training loss: 1.5299897193908691
Validation loss: 1.8199819877583494

Epoch: 5| Step: 6
Training loss: 1.5506991147994995
Validation loss: 1.8620624798600391

Epoch: 5| Step: 7
Training loss: 0.7990622520446777
Validation loss: 1.8656663151197537

Epoch: 5| Step: 8
Training loss: 1.0852458477020264
Validation loss: 1.8717909448890275

Epoch: 5| Step: 9
Training loss: 1.1141517162322998
Validation loss: 1.8403224034975934

Epoch: 5| Step: 10
Training loss: 1.4296159744262695
Validation loss: 1.8133087927295315

Epoch: 584| Step: 0
Training loss: 0.8654471635818481
Validation loss: 1.8039104073278365

Epoch: 5| Step: 1
Training loss: 0.9084073901176453
Validation loss: 1.7492604037766815

Epoch: 5| Step: 2
Training loss: 0.935886025428772
Validation loss: 1.758616239793839

Epoch: 5| Step: 3
Training loss: 0.8556039929389954
Validation loss: 1.7705638985480032

Epoch: 5| Step: 4
Training loss: 1.1062531471252441
Validation loss: 1.819100514534981

Epoch: 5| Step: 5
Training loss: 1.1776647567749023
Validation loss: 1.821367625267275

Epoch: 5| Step: 6
Training loss: 1.3467881679534912
Validation loss: 1.8330103569133307

Epoch: 5| Step: 7
Training loss: 1.6395725011825562
Validation loss: 1.7992056415927025

Epoch: 5| Step: 8
Training loss: 1.1648386716842651
Validation loss: 1.8169791237000497

Epoch: 5| Step: 9
Training loss: 0.5937899947166443
Validation loss: 1.8093704844033847

Epoch: 5| Step: 10
Training loss: 1.0778166055679321
Validation loss: 1.7893684846098705

Epoch: 585| Step: 0
Training loss: 1.250885248184204
Validation loss: 1.7701376715014059

Epoch: 5| Step: 1
Training loss: 1.1404119729995728
Validation loss: 1.7634325642739572

Epoch: 5| Step: 2
Training loss: 1.2976739406585693
Validation loss: 1.780787432065574

Epoch: 5| Step: 3
Training loss: 1.0737512111663818
Validation loss: 1.7926806916472733

Epoch: 5| Step: 4
Training loss: 0.900309681892395
Validation loss: 1.786103936933702

Epoch: 5| Step: 5
Training loss: 0.7443132400512695
Validation loss: 1.8648159080936062

Epoch: 5| Step: 6
Training loss: 0.6273571848869324
Validation loss: 1.8244515413879066

Epoch: 5| Step: 7
Training loss: 1.1772382259368896
Validation loss: 1.8049594253622077

Epoch: 5| Step: 8
Training loss: 0.8813220262527466
Validation loss: 1.869635574279293

Epoch: 5| Step: 9
Training loss: 1.2718424797058105
Validation loss: 1.8421028173098

Epoch: 5| Step: 10
Training loss: 1.117286205291748
Validation loss: 1.8233602508421867

Epoch: 586| Step: 0
Training loss: 1.0204098224639893
Validation loss: 1.8005838471074258

Epoch: 5| Step: 1
Training loss: 0.9540138244628906
Validation loss: 1.7598554088223366

Epoch: 5| Step: 2
Training loss: 0.9350954294204712
Validation loss: 1.746292955131941

Epoch: 5| Step: 3
Training loss: 1.4538072347640991
Validation loss: 1.6979065210588518

Epoch: 5| Step: 4
Training loss: 1.1201251745224
Validation loss: 1.7376352830599713

Epoch: 5| Step: 5
Training loss: 0.8706955909729004
Validation loss: 1.7616541501014464

Epoch: 5| Step: 6
Training loss: 1.0835607051849365
Validation loss: 1.7702415668836204

Epoch: 5| Step: 7
Training loss: 0.8730023503303528
Validation loss: 1.751757102627908

Epoch: 5| Step: 8
Training loss: 0.7522932291030884
Validation loss: 1.788312453095631

Epoch: 5| Step: 9
Training loss: 1.0709350109100342
Validation loss: 1.733974528569047

Epoch: 5| Step: 10
Training loss: 1.1148977279663086
Validation loss: 1.7661363796521259

Epoch: 587| Step: 0
Training loss: 1.1420637369155884
Validation loss: 1.7482350013589347

Epoch: 5| Step: 1
Training loss: 1.1756465435028076
Validation loss: 1.7567037459342711

Epoch: 5| Step: 2
Training loss: 0.9769774675369263
Validation loss: 1.7235795221021097

Epoch: 5| Step: 3
Training loss: 0.7751114964485168
Validation loss: 1.7835332603864773

Epoch: 5| Step: 4
Training loss: 1.0244886875152588
Validation loss: 1.800001476400642

Epoch: 5| Step: 5
Training loss: 1.1337476968765259
Validation loss: 1.7187078588752336

Epoch: 5| Step: 6
Training loss: 1.162457823753357
Validation loss: 1.8151962705837783

Epoch: 5| Step: 7
Training loss: 1.1933882236480713
Validation loss: 1.7547080888543078

Epoch: 5| Step: 8
Training loss: 0.5859413743019104
Validation loss: 1.8100886216727636

Epoch: 5| Step: 9
Training loss: 0.75083988904953
Validation loss: 1.7822674525681363

Epoch: 5| Step: 10
Training loss: 1.0354645252227783
Validation loss: 1.7849707013817244

Epoch: 588| Step: 0
Training loss: 1.000762701034546
Validation loss: 1.73405251836264

Epoch: 5| Step: 1
Training loss: 0.9822608232498169
Validation loss: 1.790511090268371

Epoch: 5| Step: 2
Training loss: 1.1667537689208984
Validation loss: 1.7845986991800287

Epoch: 5| Step: 3
Training loss: 0.9620859026908875
Validation loss: 1.7693658323698147

Epoch: 5| Step: 4
Training loss: 0.6738532781600952
Validation loss: 1.7478604739712131

Epoch: 5| Step: 5
Training loss: 1.3399934768676758
Validation loss: 1.7844636594095538

Epoch: 5| Step: 6
Training loss: 1.2679479122161865
Validation loss: 1.7881077438272455

Epoch: 5| Step: 7
Training loss: 0.9666540026664734
Validation loss: 1.729325758513584

Epoch: 5| Step: 8
Training loss: 0.963427722454071
Validation loss: 1.7662750059558499

Epoch: 5| Step: 9
Training loss: 0.7544492483139038
Validation loss: 1.7579927598276446

Epoch: 5| Step: 10
Training loss: 0.876761257648468
Validation loss: 1.729889892762707

Epoch: 589| Step: 0
Training loss: 0.942626953125
Validation loss: 1.788314337371498

Epoch: 5| Step: 1
Training loss: 1.0455424785614014
Validation loss: 1.7400979925227422

Epoch: 5| Step: 2
Training loss: 0.7614269256591797
Validation loss: 1.8068309548080608

Epoch: 5| Step: 3
Training loss: 0.9937721490859985
Validation loss: 1.8717010251937374

Epoch: 5| Step: 4
Training loss: 0.6065969467163086
Validation loss: 1.7351570103758125

Epoch: 5| Step: 5
Training loss: 0.7937272787094116
Validation loss: 1.779923027561557

Epoch: 5| Step: 6
Training loss: 1.1681663990020752
Validation loss: 1.7979130104023924

Epoch: 5| Step: 7
Training loss: 1.455932378768921
Validation loss: 1.7839211802328787

Epoch: 5| Step: 8
Training loss: 1.057727575302124
Validation loss: 1.7935647631204257

Epoch: 5| Step: 9
Training loss: 1.0163328647613525
Validation loss: 1.7659913557831959

Epoch: 5| Step: 10
Training loss: 1.1255089044570923
Validation loss: 1.7370446253848333

Epoch: 590| Step: 0
Training loss: 0.6617389917373657
Validation loss: 1.7688587045156827

Epoch: 5| Step: 1
Training loss: 0.9550685882568359
Validation loss: 1.7208208114870134

Epoch: 5| Step: 2
Training loss: 0.9658058881759644
Validation loss: 1.818750762170361

Epoch: 5| Step: 3
Training loss: 1.3804668188095093
Validation loss: 1.8329193002434188

Epoch: 5| Step: 4
Training loss: 0.7662531137466431
Validation loss: 1.7959145115267845

Epoch: 5| Step: 5
Training loss: 1.0335357189178467
Validation loss: 1.752557695552867

Epoch: 5| Step: 6
Training loss: 0.8497141003608704
Validation loss: 1.7731673294498074

Epoch: 5| Step: 7
Training loss: 1.1891119480133057
Validation loss: 1.792493079298286

Epoch: 5| Step: 8
Training loss: 1.111711859703064
Validation loss: 1.7891596824892106

Epoch: 5| Step: 9
Training loss: 0.3506479263305664
Validation loss: 1.7793160433410316

Epoch: 5| Step: 10
Training loss: 1.4467819929122925
Validation loss: 1.7575267732784312

Epoch: 591| Step: 0
Training loss: 0.7033089995384216
Validation loss: 1.7399264061322777

Epoch: 5| Step: 1
Training loss: 1.0331213474273682
Validation loss: 1.7195808272207938

Epoch: 5| Step: 2
Training loss: 1.0435863733291626
Validation loss: 1.6912230304492417

Epoch: 5| Step: 3
Training loss: 0.8578512072563171
Validation loss: 1.8002323463398924

Epoch: 5| Step: 4
Training loss: 0.9518001675605774
Validation loss: 1.7564917366991761

Epoch: 5| Step: 5
Training loss: 0.7119863629341125
Validation loss: 1.76119739009488

Epoch: 5| Step: 6
Training loss: 0.9735544919967651
Validation loss: 1.7461061208478865

Epoch: 5| Step: 7
Training loss: 1.2942129373550415
Validation loss: 1.779538336620536

Epoch: 5| Step: 8
Training loss: 0.9935895800590515
Validation loss: 1.7750751651743406

Epoch: 5| Step: 9
Training loss: 1.1238434314727783
Validation loss: 1.764761709397839

Epoch: 5| Step: 10
Training loss: 0.9676429629325867
Validation loss: 1.7667878532922396

Epoch: 592| Step: 0
Training loss: 0.9735342264175415
Validation loss: 1.7551553556996007

Epoch: 5| Step: 1
Training loss: 0.6512543559074402
Validation loss: 1.7789422222363052

Epoch: 5| Step: 2
Training loss: 1.0359516143798828
Validation loss: 1.7590224153252059

Epoch: 5| Step: 3
Training loss: 1.0611374378204346
Validation loss: 1.7786192022344118

Epoch: 5| Step: 4
Training loss: 0.9181955456733704
Validation loss: 1.7496563298727876

Epoch: 5| Step: 5
Training loss: 1.1003776788711548
Validation loss: 1.7258523471893803

Epoch: 5| Step: 6
Training loss: 1.1036993265151978
Validation loss: 1.7375694808139597

Epoch: 5| Step: 7
Training loss: 1.1830308437347412
Validation loss: 1.7862566248063119

Epoch: 5| Step: 8
Training loss: 0.723981499671936
Validation loss: 1.724267118720598

Epoch: 5| Step: 9
Training loss: 1.0941318273544312
Validation loss: 1.7564606999838224

Epoch: 5| Step: 10
Training loss: 0.8157426714897156
Validation loss: 1.762372834708101

Epoch: 593| Step: 0
Training loss: 0.6313737630844116
Validation loss: 1.773277416024157

Epoch: 5| Step: 1
Training loss: 0.8283015489578247
Validation loss: 1.7619301208885767

Epoch: 5| Step: 2
Training loss: 1.3945643901824951
Validation loss: 1.804936831997287

Epoch: 5| Step: 3
Training loss: 0.6531244516372681
Validation loss: 1.7480261428381807

Epoch: 5| Step: 4
Training loss: 0.9370377659797668
Validation loss: 1.8213052493269726

Epoch: 5| Step: 5
Training loss: 1.3023895025253296
Validation loss: 1.847640270827919

Epoch: 5| Step: 6
Training loss: 1.193795919418335
Validation loss: 1.8045559929263206

Epoch: 5| Step: 7
Training loss: 0.9546353220939636
Validation loss: 1.8677467889683221

Epoch: 5| Step: 8
Training loss: 1.0661566257476807
Validation loss: 1.8146333873912852

Epoch: 5| Step: 9
Training loss: 0.9532221555709839
Validation loss: 1.8353206034629577

Epoch: 5| Step: 10
Training loss: 1.1834343671798706
Validation loss: 1.7512272327176985

Epoch: 594| Step: 0
Training loss: 1.3414509296417236
Validation loss: 1.8219958582232076

Epoch: 5| Step: 1
Training loss: 0.9601051211357117
Validation loss: 1.766995758138677

Epoch: 5| Step: 2
Training loss: 0.9383169412612915
Validation loss: 1.7840282519658406

Epoch: 5| Step: 3
Training loss: 1.2152751684188843
Validation loss: 1.7283051654856691

Epoch: 5| Step: 4
Training loss: 1.042291283607483
Validation loss: 1.7593746659576253

Epoch: 5| Step: 5
Training loss: 0.9761446118354797
Validation loss: 1.7303311773525771

Epoch: 5| Step: 6
Training loss: 1.1405540704727173
Validation loss: 1.8263751486296296

Epoch: 5| Step: 7
Training loss: 0.7603249549865723
Validation loss: 1.7494409968776088

Epoch: 5| Step: 8
Training loss: 1.0350699424743652
Validation loss: 1.796950646626052

Epoch: 5| Step: 9
Training loss: 0.9567478895187378
Validation loss: 1.743999909329158

Epoch: 5| Step: 10
Training loss: 0.7299761176109314
Validation loss: 1.7628626131242322

Epoch: 595| Step: 0
Training loss: 0.5934022068977356
Validation loss: 1.7474832278425976

Epoch: 5| Step: 1
Training loss: 0.8650598526000977
Validation loss: 1.8168696267630464

Epoch: 5| Step: 2
Training loss: 0.9606316685676575
Validation loss: 1.8315788827916628

Epoch: 5| Step: 3
Training loss: 1.0385501384735107
Validation loss: 1.763504006529367

Epoch: 5| Step: 4
Training loss: 0.9969046711921692
Validation loss: 1.7780971514281405

Epoch: 5| Step: 5
Training loss: 1.012629508972168
Validation loss: 1.881682062661776

Epoch: 5| Step: 6
Training loss: 0.9651854634284973
Validation loss: 1.7890634690561602

Epoch: 5| Step: 7
Training loss: 0.8737907409667969
Validation loss: 1.8281844546717982

Epoch: 5| Step: 8
Training loss: 1.4233976602554321
Validation loss: 1.771965375510595

Epoch: 5| Step: 9
Training loss: 0.9957411885261536
Validation loss: 1.8334476178692234

Epoch: 5| Step: 10
Training loss: 1.2001230716705322
Validation loss: 1.7580544205122097

Epoch: 596| Step: 0
Training loss: 0.7807396054267883
Validation loss: 1.8101890292218936

Epoch: 5| Step: 1
Training loss: 0.9766216278076172
Validation loss: 1.7730090041314401

Epoch: 5| Step: 2
Training loss: 1.331475019454956
Validation loss: 1.7155447249771447

Epoch: 5| Step: 3
Training loss: 0.9526078104972839
Validation loss: 1.7602077132912093

Epoch: 5| Step: 4
Training loss: 1.1150085926055908
Validation loss: 1.7546965050440964

Epoch: 5| Step: 5
Training loss: 0.7756463289260864
Validation loss: 1.7573370292622557

Epoch: 5| Step: 6
Training loss: 0.8202016949653625
Validation loss: 1.7787539561589558

Epoch: 5| Step: 7
Training loss: 1.6219069957733154
Validation loss: 1.8163610632701586

Epoch: 5| Step: 8
Training loss: 0.9215984344482422
Validation loss: 1.70147906836643

Epoch: 5| Step: 9
Training loss: 0.9804286956787109
Validation loss: 1.7453064559608378

Epoch: 5| Step: 10
Training loss: 0.8098410964012146
Validation loss: 1.773895658472533

Epoch: 597| Step: 0
Training loss: 1.2018554210662842
Validation loss: 1.7260090074231547

Epoch: 5| Step: 1
Training loss: 0.8296219706535339
Validation loss: 1.7798388984895521

Epoch: 5| Step: 2
Training loss: 0.9094351530075073
Validation loss: 1.7589796422630228

Epoch: 5| Step: 3
Training loss: 1.0702269077301025
Validation loss: 1.7849469530966975

Epoch: 5| Step: 4
Training loss: 1.090628981590271
Validation loss: 1.7637164900379796

Epoch: 5| Step: 5
Training loss: 1.0751662254333496
Validation loss: 1.7558821003924134

Epoch: 5| Step: 6
Training loss: 0.8937172889709473
Validation loss: 1.7468320913212274

Epoch: 5| Step: 7
Training loss: 0.7459427118301392
Validation loss: 1.712989080336786

Epoch: 5| Step: 8
Training loss: 0.9329107999801636
Validation loss: 1.7840524104333693

Epoch: 5| Step: 9
Training loss: 0.6307061314582825
Validation loss: 1.805719405092219

Epoch: 5| Step: 10
Training loss: 1.4522669315338135
Validation loss: 1.7398665489688996

Epoch: 598| Step: 0
Training loss: 0.9915758371353149
Validation loss: 1.7431965374177503

Epoch: 5| Step: 1
Training loss: 0.8911267518997192
Validation loss: 1.735258069089664

Epoch: 5| Step: 2
Training loss: 1.2950769662857056
Validation loss: 1.799341642728416

Epoch: 5| Step: 3
Training loss: 0.8488003611564636
Validation loss: 1.7786820139936221

Epoch: 5| Step: 4
Training loss: 1.4465563297271729
Validation loss: 1.797203185737774

Epoch: 5| Step: 5
Training loss: 0.7630736231803894
Validation loss: 1.758989546888618

Epoch: 5| Step: 6
Training loss: 1.0620641708374023
Validation loss: 1.773474499743472

Epoch: 5| Step: 7
Training loss: 0.6796925663948059
Validation loss: 1.7909337282180786

Epoch: 5| Step: 8
Training loss: 1.1204100847244263
Validation loss: 1.8089144178616103

Epoch: 5| Step: 9
Training loss: 1.1913527250289917
Validation loss: 1.7518134758036623

Epoch: 5| Step: 10
Training loss: 0.705365777015686
Validation loss: 1.754703224346202

Epoch: 599| Step: 0
Training loss: 1.1279932260513306
Validation loss: 1.725045669463373

Epoch: 5| Step: 1
Training loss: 0.8222516775131226
Validation loss: 1.7709600874172744

Epoch: 5| Step: 2
Training loss: 0.9329155683517456
Validation loss: 1.763959123242286

Epoch: 5| Step: 3
Training loss: 1.3596705198287964
Validation loss: 1.685362700493105

Epoch: 5| Step: 4
Training loss: 1.2353521585464478
Validation loss: 1.7523984870603007

Epoch: 5| Step: 5
Training loss: 0.692567765712738
Validation loss: 1.756865995545541

Epoch: 5| Step: 6
Training loss: 0.943952739238739
Validation loss: 1.771280256650781

Epoch: 5| Step: 7
Training loss: 1.0715644359588623
Validation loss: 1.7691062958009782

Epoch: 5| Step: 8
Training loss: 1.0093961954116821
Validation loss: 1.7611988949519333

Epoch: 5| Step: 9
Training loss: 0.6875219345092773
Validation loss: 1.7704581701627342

Epoch: 5| Step: 10
Training loss: 0.8347156643867493
Validation loss: 1.7359612654614192

Epoch: 600| Step: 0
Training loss: 1.240654706954956
Validation loss: 1.7959138654893445

Epoch: 5| Step: 1
Training loss: 0.7955021262168884
Validation loss: 1.7875703868045603

Epoch: 5| Step: 2
Training loss: 1.023777961730957
Validation loss: 1.8202970566288117

Epoch: 5| Step: 3
Training loss: 0.7507331371307373
Validation loss: 1.8069460033088602

Epoch: 5| Step: 4
Training loss: 1.3526579141616821
Validation loss: 1.7891581904503606

Epoch: 5| Step: 5
Training loss: 1.0068234205245972
Validation loss: 1.8235096393092987

Epoch: 5| Step: 6
Training loss: 0.9172994494438171
Validation loss: 1.788135584964547

Epoch: 5| Step: 7
Training loss: 0.8260807991027832
Validation loss: 1.7078411604768486

Epoch: 5| Step: 8
Training loss: 1.0925483703613281
Validation loss: 1.7788462292763494

Epoch: 5| Step: 9
Training loss: 0.9054959416389465
Validation loss: 1.7386608726234847

Epoch: 5| Step: 10
Training loss: 0.9679997563362122
Validation loss: 1.7561803210166194

Epoch: 601| Step: 0
Training loss: 0.845345675945282
Validation loss: 1.7628191209608508

Epoch: 5| Step: 1
Training loss: 1.0533795356750488
Validation loss: 1.7547077081536735

Epoch: 5| Step: 2
Training loss: 0.9237055778503418
Validation loss: 1.748739980882214

Epoch: 5| Step: 3
Training loss: 1.3524187803268433
Validation loss: 1.7299682786387782

Epoch: 5| Step: 4
Training loss: 0.8439364433288574
Validation loss: 1.7903412221580424

Epoch: 5| Step: 5
Training loss: 1.0664567947387695
Validation loss: 1.7386697710201304

Epoch: 5| Step: 6
Training loss: 1.2273069620132446
Validation loss: 1.7333325262992614

Epoch: 5| Step: 7
Training loss: 0.7185759544372559
Validation loss: 1.7327474458243257

Epoch: 5| Step: 8
Training loss: 0.8965269327163696
Validation loss: 1.7631629513156029

Epoch: 5| Step: 9
Training loss: 0.6607503890991211
Validation loss: 1.7239493862275155

Epoch: 5| Step: 10
Training loss: 0.9234237670898438
Validation loss: 1.7687032363748039

Epoch: 602| Step: 0
Training loss: 0.810101330280304
Validation loss: 1.7372316237418883

Epoch: 5| Step: 1
Training loss: 1.2687300443649292
Validation loss: 1.7485235403942805

Epoch: 5| Step: 2
Training loss: 0.8284961581230164
Validation loss: 1.729466962557967

Epoch: 5| Step: 3
Training loss: 1.1769211292266846
Validation loss: 1.7026063524266726

Epoch: 5| Step: 4
Training loss: 0.9588893055915833
Validation loss: 1.7225399940244612

Epoch: 5| Step: 5
Training loss: 0.8375128507614136
Validation loss: 1.7198496300687072

Epoch: 5| Step: 6
Training loss: 0.9035075306892395
Validation loss: 1.7496071669363207

Epoch: 5| Step: 7
Training loss: 1.1178617477416992
Validation loss: 1.773170328909351

Epoch: 5| Step: 8
Training loss: 1.0767093896865845
Validation loss: 1.7606996233745287

Epoch: 5| Step: 9
Training loss: 0.7054237127304077
Validation loss: 1.7969482310356633

Epoch: 5| Step: 10
Training loss: 1.300360083580017
Validation loss: 1.7807304166978406

Epoch: 603| Step: 0
Training loss: 1.0595983266830444
Validation loss: 1.7393628012749456

Epoch: 5| Step: 1
Training loss: 1.0198462009429932
Validation loss: 1.7799358329465311

Epoch: 5| Step: 2
Training loss: 0.6918715238571167
Validation loss: 1.7991148425686745

Epoch: 5| Step: 3
Training loss: 0.8943158984184265
Validation loss: 1.7395154365929224

Epoch: 5| Step: 4
Training loss: 1.0341449975967407
Validation loss: 1.7340298403975785

Epoch: 5| Step: 5
Training loss: 1.0697977542877197
Validation loss: 1.7994207848784745

Epoch: 5| Step: 6
Training loss: 0.6896209716796875
Validation loss: 1.7217457884101457

Epoch: 5| Step: 7
Training loss: 0.959080696105957
Validation loss: 1.73665161542995

Epoch: 5| Step: 8
Training loss: 1.0697107315063477
Validation loss: 1.7318988897467171

Epoch: 5| Step: 9
Training loss: 1.371691107749939
Validation loss: 1.7763398757544897

Epoch: 5| Step: 10
Training loss: 1.068245530128479
Validation loss: 1.7744286521788566

Epoch: 604| Step: 0
Training loss: 0.9175683856010437
Validation loss: 1.8165445545668244

Epoch: 5| Step: 1
Training loss: 1.0701510906219482
Validation loss: 1.7073553685219056

Epoch: 5| Step: 2
Training loss: 1.1525781154632568
Validation loss: 1.750250175435056

Epoch: 5| Step: 3
Training loss: 0.33280831575393677
Validation loss: 1.7287050588156587

Epoch: 5| Step: 4
Training loss: 1.0485273599624634
Validation loss: 1.7501046862653507

Epoch: 5| Step: 5
Training loss: 0.9585195779800415
Validation loss: 1.7806833110829836

Epoch: 5| Step: 6
Training loss: 0.7296256422996521
Validation loss: 1.7926520506540935

Epoch: 5| Step: 7
Training loss: 1.15354323387146
Validation loss: 1.765793869572301

Epoch: 5| Step: 8
Training loss: 1.1669915914535522
Validation loss: 1.7618945990839312

Epoch: 5| Step: 9
Training loss: 0.8954358100891113
Validation loss: 1.7442626196851012

Epoch: 5| Step: 10
Training loss: 1.4486006498336792
Validation loss: 1.7034734654170212

Epoch: 605| Step: 0
Training loss: 0.9281147718429565
Validation loss: 1.726266525124991

Epoch: 5| Step: 1
Training loss: 0.7983561158180237
Validation loss: 1.7732475265379875

Epoch: 5| Step: 2
Training loss: 0.7159768342971802
Validation loss: 1.7292783542345929

Epoch: 5| Step: 3
Training loss: 0.8225307464599609
Validation loss: 1.6983676110544512

Epoch: 5| Step: 4
Training loss: 1.2394376993179321
Validation loss: 1.807065338216802

Epoch: 5| Step: 5
Training loss: 1.2952888011932373
Validation loss: 1.7846117558017853

Epoch: 5| Step: 6
Training loss: 0.8272671699523926
Validation loss: 1.7584292299004012

Epoch: 5| Step: 7
Training loss: 1.0151386260986328
Validation loss: 1.7999028621181365

Epoch: 5| Step: 8
Training loss: 0.9956304430961609
Validation loss: 1.7899878730056107

Epoch: 5| Step: 9
Training loss: 0.7662650346755981
Validation loss: 1.7385945063765331

Epoch: 5| Step: 10
Training loss: 1.1100307703018188
Validation loss: 1.7861521897777435

Epoch: 606| Step: 0
Training loss: 0.9315900802612305
Validation loss: 1.7745559215545654

Epoch: 5| Step: 1
Training loss: 0.945651650428772
Validation loss: 1.804129514642941

Epoch: 5| Step: 2
Training loss: 0.8688252568244934
Validation loss: 1.7888173339187459

Epoch: 5| Step: 3
Training loss: 0.9292821884155273
Validation loss: 1.7927820938889698

Epoch: 5| Step: 4
Training loss: 1.1633405685424805
Validation loss: 1.8013127119310441

Epoch: 5| Step: 5
Training loss: 1.0474302768707275
Validation loss: 1.7984178553345382

Epoch: 5| Step: 6
Training loss: 0.5736784338951111
Validation loss: 1.7263856933962913

Epoch: 5| Step: 7
Training loss: 1.3747459650039673
Validation loss: 1.775421873215706

Epoch: 5| Step: 8
Training loss: 0.7399774193763733
Validation loss: 1.710626817518665

Epoch: 5| Step: 9
Training loss: 0.9022272229194641
Validation loss: 1.775956852461702

Epoch: 5| Step: 10
Training loss: 1.030806064605713
Validation loss: 1.732936812985328

Epoch: 607| Step: 0
Training loss: 1.2410409450531006
Validation loss: 1.7707502765040244

Epoch: 5| Step: 1
Training loss: 1.0456234216690063
Validation loss: 1.7906279743358653

Epoch: 5| Step: 2
Training loss: 1.0880281925201416
Validation loss: 1.7740960633882912

Epoch: 5| Step: 3
Training loss: 0.929719090461731
Validation loss: 1.789888362730703

Epoch: 5| Step: 4
Training loss: 0.7309396862983704
Validation loss: 1.8162290857684227

Epoch: 5| Step: 5
Training loss: 1.0796558856964111
Validation loss: 1.8093723289428219

Epoch: 5| Step: 6
Training loss: 1.1105836629867554
Validation loss: 1.778636355553904

Epoch: 5| Step: 7
Training loss: 0.9388567805290222
Validation loss: 1.7554527905679518

Epoch: 5| Step: 8
Training loss: 1.1532589197158813
Validation loss: 1.732674635866637

Epoch: 5| Step: 9
Training loss: 0.638034999370575
Validation loss: 1.7567840378771546

Epoch: 5| Step: 10
Training loss: 0.7812057733535767
Validation loss: 1.7680450793235534

Epoch: 608| Step: 0
Training loss: 1.047688603401184
Validation loss: 1.742094547517838

Epoch: 5| Step: 1
Training loss: 0.7626063823699951
Validation loss: 1.778022930186282

Epoch: 5| Step: 2
Training loss: 1.1207740306854248
Validation loss: 1.77669951223558

Epoch: 5| Step: 3
Training loss: 0.7501913905143738
Validation loss: 1.7481651947062502

Epoch: 5| Step: 4
Training loss: 1.0979225635528564
Validation loss: 1.743568967747432

Epoch: 5| Step: 5
Training loss: 0.7823168635368347
Validation loss: 1.7359594786038963

Epoch: 5| Step: 6
Training loss: 0.7649308443069458
Validation loss: 1.7929719096870833

Epoch: 5| Step: 7
Training loss: 0.972679615020752
Validation loss: 1.7604667127773326

Epoch: 5| Step: 8
Training loss: 1.0915861129760742
Validation loss: 1.7201466547545565

Epoch: 5| Step: 9
Training loss: 0.9535444378852844
Validation loss: 1.7590442562616

Epoch: 5| Step: 10
Training loss: 1.2523902654647827
Validation loss: 1.7783987470852431

Epoch: 609| Step: 0
Training loss: 0.9768575429916382
Validation loss: 1.7789236140507523

Epoch: 5| Step: 1
Training loss: 1.0394736528396606
Validation loss: 1.8085881766452585

Epoch: 5| Step: 2
Training loss: 0.420485258102417
Validation loss: 1.7429397862444642

Epoch: 5| Step: 3
Training loss: 0.7049986124038696
Validation loss: 1.7027748989802536

Epoch: 5| Step: 4
Training loss: 0.7213698625564575
Validation loss: 1.776865347739189

Epoch: 5| Step: 5
Training loss: 0.6138526797294617
Validation loss: 1.7800134035848802

Epoch: 5| Step: 6
Training loss: 1.0212159156799316
Validation loss: 1.7355699705821213

Epoch: 5| Step: 7
Training loss: 1.639116644859314
Validation loss: 1.7673398986939461

Epoch: 5| Step: 8
Training loss: 1.0889772176742554
Validation loss: 1.779378088571692

Epoch: 5| Step: 9
Training loss: 1.2295186519622803
Validation loss: 1.7943746428335867

Epoch: 5| Step: 10
Training loss: 0.9430873990058899
Validation loss: 1.8010974686632875

Epoch: 610| Step: 0
Training loss: 1.0098140239715576
Validation loss: 1.757995351668327

Epoch: 5| Step: 1
Training loss: 1.2845280170440674
Validation loss: 1.7797006163545834

Epoch: 5| Step: 2
Training loss: 1.0442547798156738
Validation loss: 1.7389229907784411

Epoch: 5| Step: 3
Training loss: 0.8505825996398926
Validation loss: 1.774017503184657

Epoch: 5| Step: 4
Training loss: 1.0749006271362305
Validation loss: 1.8370368557591592

Epoch: 5| Step: 5
Training loss: 0.4161190092563629
Validation loss: 1.8123577769084642

Epoch: 5| Step: 6
Training loss: 0.6015098094940186
Validation loss: 1.8897087035640594

Epoch: 5| Step: 7
Training loss: 0.8446194529533386
Validation loss: 1.8161386251449585

Epoch: 5| Step: 8
Training loss: 0.9670486450195312
Validation loss: 1.8264234835101711

Epoch: 5| Step: 9
Training loss: 1.3557039499282837
Validation loss: 1.8421054578596545

Epoch: 5| Step: 10
Training loss: 0.9411196708679199
Validation loss: 1.7823720888424945

Epoch: 611| Step: 0
Training loss: 1.4111624956130981
Validation loss: 1.706423968397161

Epoch: 5| Step: 1
Training loss: 0.8065948486328125
Validation loss: 1.774878248091667

Epoch: 5| Step: 2
Training loss: 1.1415611505508423
Validation loss: 1.726317810755904

Epoch: 5| Step: 3
Training loss: 0.6976290345191956
Validation loss: 1.6789710342243154

Epoch: 5| Step: 4
Training loss: 1.129028081893921
Validation loss: 1.7322687410539197

Epoch: 5| Step: 5
Training loss: 0.9106475710868835
Validation loss: 1.6934373148026005

Epoch: 5| Step: 6
Training loss: 0.9348229169845581
Validation loss: 1.7523774152160974

Epoch: 5| Step: 7
Training loss: 0.9414957165718079
Validation loss: 1.783739536039291

Epoch: 5| Step: 8
Training loss: 0.5802384614944458
Validation loss: 1.79879242374051

Epoch: 5| Step: 9
Training loss: 0.6891719102859497
Validation loss: 1.740730094653304

Epoch: 5| Step: 10
Training loss: 1.1309194564819336
Validation loss: 1.8011647168026175

Epoch: 612| Step: 0
Training loss: 0.6671923398971558
Validation loss: 1.7940052645180815

Epoch: 5| Step: 1
Training loss: 1.1832797527313232
Validation loss: 1.760926910625991

Epoch: 5| Step: 2
Training loss: 1.0363099575042725
Validation loss: 1.6861650238754928

Epoch: 5| Step: 3
Training loss: 0.664817214012146
Validation loss: 1.7331529868546354

Epoch: 5| Step: 4
Training loss: 0.8551667928695679
Validation loss: 1.7995660638296476

Epoch: 5| Step: 5
Training loss: 1.0430347919464111
Validation loss: 1.7668479796378844

Epoch: 5| Step: 6
Training loss: 0.9904338717460632
Validation loss: 1.7648176121455368

Epoch: 5| Step: 7
Training loss: 0.9068180322647095
Validation loss: 1.7630820287171232

Epoch: 5| Step: 8
Training loss: 0.9731817245483398
Validation loss: 1.768940000123875

Epoch: 5| Step: 9
Training loss: 0.8806179165840149
Validation loss: 1.8137335943919357

Epoch: 5| Step: 10
Training loss: 0.7888835668563843
Validation loss: 1.7461271221919725

Epoch: 613| Step: 0
Training loss: 1.3040621280670166
Validation loss: 1.8471735805593512

Epoch: 5| Step: 1
Training loss: 0.9140195846557617
Validation loss: 1.7984122460888279

Epoch: 5| Step: 2
Training loss: 1.090486764907837
Validation loss: 1.7588310151971795

Epoch: 5| Step: 3
Training loss: 1.01383376121521
Validation loss: 1.7771640605823968

Epoch: 5| Step: 4
Training loss: 1.0351556539535522
Validation loss: 1.6769261231986425

Epoch: 5| Step: 5
Training loss: 1.2922332286834717
Validation loss: 1.7214174398811914

Epoch: 5| Step: 6
Training loss: 0.6709875464439392
Validation loss: 1.7684351833917762

Epoch: 5| Step: 7
Training loss: 0.7252374887466431
Validation loss: 1.785351453288909

Epoch: 5| Step: 8
Training loss: 0.822101891040802
Validation loss: 1.7356705345133299

Epoch: 5| Step: 9
Training loss: 1.024895191192627
Validation loss: 1.7788831880015712

Epoch: 5| Step: 10
Training loss: 0.5865908265113831
Validation loss: 1.7217086643301032

Epoch: 614| Step: 0
Training loss: 0.9070261120796204
Validation loss: 1.7491925057544504

Epoch: 5| Step: 1
Training loss: 0.6475074887275696
Validation loss: 1.8521586054114885

Epoch: 5| Step: 2
Training loss: 0.9549404382705688
Validation loss: 1.7883465930979738

Epoch: 5| Step: 3
Training loss: 1.2404937744140625
Validation loss: 1.7551733845023698

Epoch: 5| Step: 4
Training loss: 0.8812496066093445
Validation loss: 1.816057752537471

Epoch: 5| Step: 5
Training loss: 1.1402794122695923
Validation loss: 1.7948885271626134

Epoch: 5| Step: 6
Training loss: 1.2207499742507935
Validation loss: 1.8071035877350838

Epoch: 5| Step: 7
Training loss: 0.6240444183349609
Validation loss: 1.7435267509952668

Epoch: 5| Step: 8
Training loss: 1.0435137748718262
Validation loss: 1.7742602056072605

Epoch: 5| Step: 9
Training loss: 0.6120506525039673
Validation loss: 1.7675573838654386

Epoch: 5| Step: 10
Training loss: 1.1264113187789917
Validation loss: 1.8152943298380861

Epoch: 615| Step: 0
Training loss: 0.8175679445266724
Validation loss: 1.778857397776778

Epoch: 5| Step: 1
Training loss: 0.40262699127197266
Validation loss: 1.7920942793610275

Epoch: 5| Step: 2
Training loss: 0.8752033114433289
Validation loss: 1.7325040896733601

Epoch: 5| Step: 3
Training loss: 1.163782000541687
Validation loss: 1.7827087102397796

Epoch: 5| Step: 4
Training loss: 0.7823351621627808
Validation loss: 1.7657327357158865

Epoch: 5| Step: 5
Training loss: 1.0666248798370361
Validation loss: 1.7801038154991724

Epoch: 5| Step: 6
Training loss: 0.9430118799209595
Validation loss: 1.7779816786448162

Epoch: 5| Step: 7
Training loss: 0.8179557919502258
Validation loss: 1.7319019879064252

Epoch: 5| Step: 8
Training loss: 1.2066051959991455
Validation loss: 1.7040901812173987

Epoch: 5| Step: 9
Training loss: 1.0559608936309814
Validation loss: 1.6962674894640524

Epoch: 5| Step: 10
Training loss: 1.368989109992981
Validation loss: 1.7653794403999084

Epoch: 616| Step: 0
Training loss: 0.76715487241745
Validation loss: 1.744152089600922

Epoch: 5| Step: 1
Training loss: 1.1654446125030518
Validation loss: 1.7456198687194495

Epoch: 5| Step: 2
Training loss: 0.776276171207428
Validation loss: 1.784470937585318

Epoch: 5| Step: 3
Training loss: 1.1991991996765137
Validation loss: 1.7993407300723496

Epoch: 5| Step: 4
Training loss: 0.9444723129272461
Validation loss: 1.7657468857303742

Epoch: 5| Step: 5
Training loss: 1.0550477504730225
Validation loss: 1.7545634738860592

Epoch: 5| Step: 6
Training loss: 0.6777346730232239
Validation loss: 1.7119103452210784

Epoch: 5| Step: 7
Training loss: 1.0448219776153564
Validation loss: 1.7655687998699885

Epoch: 5| Step: 8
Training loss: 0.6796414256095886
Validation loss: 1.7100839473867928

Epoch: 5| Step: 9
Training loss: 0.8251965641975403
Validation loss: 1.7073561017231276

Epoch: 5| Step: 10
Training loss: 0.9842320680618286
Validation loss: 1.8131946491938766

Epoch: 617| Step: 0
Training loss: 0.7542873024940491
Validation loss: 1.7645996847460348

Epoch: 5| Step: 1
Training loss: 0.748957633972168
Validation loss: 1.817164539009012

Epoch: 5| Step: 2
Training loss: 0.797732949256897
Validation loss: 1.7702905285742976

Epoch: 5| Step: 3
Training loss: 1.219745397567749
Validation loss: 1.7830370215959446

Epoch: 5| Step: 4
Training loss: 0.6620548963546753
Validation loss: 1.8141370204187208

Epoch: 5| Step: 5
Training loss: 1.2680528163909912
Validation loss: 1.754593655627261

Epoch: 5| Step: 6
Training loss: 0.8516902923583984
Validation loss: 1.7707678733333465

Epoch: 5| Step: 7
Training loss: 0.728732705116272
Validation loss: 1.7669586712314236

Epoch: 5| Step: 8
Training loss: 0.9039376378059387
Validation loss: 1.80462868367472

Epoch: 5| Step: 9
Training loss: 1.294025182723999
Validation loss: 1.7078394992377168

Epoch: 5| Step: 10
Training loss: 0.9699830412864685
Validation loss: 1.8040138213865218

Epoch: 618| Step: 0
Training loss: 0.854468047618866
Validation loss: 1.760986376834172

Epoch: 5| Step: 1
Training loss: 1.0682454109191895
Validation loss: 1.76455734878458

Epoch: 5| Step: 2
Training loss: 0.8421877026557922
Validation loss: 1.7363322268250168

Epoch: 5| Step: 3
Training loss: 0.9054096937179565
Validation loss: 1.7296179661186792

Epoch: 5| Step: 4
Training loss: 0.9895874857902527
Validation loss: 1.7580335858047649

Epoch: 5| Step: 5
Training loss: 1.0564393997192383
Validation loss: 1.7467424382445633

Epoch: 5| Step: 6
Training loss: 1.1312259435653687
Validation loss: 1.7424852027687976

Epoch: 5| Step: 7
Training loss: 0.7604999542236328
Validation loss: 1.7840957641601562

Epoch: 5| Step: 8
Training loss: 0.9745556116104126
Validation loss: 1.699373314457555

Epoch: 5| Step: 9
Training loss: 0.832685112953186
Validation loss: 1.7484670582637991

Epoch: 5| Step: 10
Training loss: 0.7703419923782349
Validation loss: 1.7562870953672676

Epoch: 619| Step: 0
Training loss: 0.9516566395759583
Validation loss: 1.7556416834554365

Epoch: 5| Step: 1
Training loss: 1.1209770441055298
Validation loss: 1.797627220871628

Epoch: 5| Step: 2
Training loss: 0.9501470327377319
Validation loss: 1.7828623171775573

Epoch: 5| Step: 3
Training loss: 0.8971655964851379
Validation loss: 1.7609158203166018

Epoch: 5| Step: 4
Training loss: 0.6489371061325073
Validation loss: 1.7658471292065037

Epoch: 5| Step: 5
Training loss: 0.5012658834457397
Validation loss: 1.7642992927182106

Epoch: 5| Step: 6
Training loss: 0.5122016668319702
Validation loss: 1.819712818309825

Epoch: 5| Step: 7
Training loss: 0.9504432678222656
Validation loss: 1.7559190462994319

Epoch: 5| Step: 8
Training loss: 0.8745215535163879
Validation loss: 1.7300476540801346

Epoch: 5| Step: 9
Training loss: 1.5209747552871704
Validation loss: 1.8313090596147763

Epoch: 5| Step: 10
Training loss: 1.3399020433425903
Validation loss: 1.7217506080545404

Epoch: 620| Step: 0
Training loss: 1.0796667337417603
Validation loss: 1.7679438693549043

Epoch: 5| Step: 1
Training loss: 0.7547324895858765
Validation loss: 1.762624015090286

Epoch: 5| Step: 2
Training loss: 0.7617751359939575
Validation loss: 1.773443175900367

Epoch: 5| Step: 3
Training loss: 0.8229940533638
Validation loss: 1.8003553459721227

Epoch: 5| Step: 4
Training loss: 0.8446237444877625
Validation loss: 1.7566361183761268

Epoch: 5| Step: 5
Training loss: 0.9176355600357056
Validation loss: 1.8083651937464231

Epoch: 5| Step: 6
Training loss: 1.1693357229232788
Validation loss: 1.7550329239137712

Epoch: 5| Step: 7
Training loss: 1.2482634782791138
Validation loss: 1.820126510435535

Epoch: 5| Step: 8
Training loss: 0.8990604281425476
Validation loss: 1.6619506279627483

Epoch: 5| Step: 9
Training loss: 1.0083286762237549
Validation loss: 1.7836272870340655

Epoch: 5| Step: 10
Training loss: 1.1166435480117798
Validation loss: 1.8142352040095995

Epoch: 621| Step: 0
Training loss: 0.7373842000961304
Validation loss: 1.7440077412512995

Epoch: 5| Step: 1
Training loss: 0.9804881811141968
Validation loss: 1.7823045958754837

Epoch: 5| Step: 2
Training loss: 1.252534031867981
Validation loss: 1.7425663061039423

Epoch: 5| Step: 3
Training loss: 0.883265495300293
Validation loss: 1.739975021731469

Epoch: 5| Step: 4
Training loss: 0.51970374584198
Validation loss: 1.7514098857038765

Epoch: 5| Step: 5
Training loss: 1.3677749633789062
Validation loss: 1.7098666724338327

Epoch: 5| Step: 6
Training loss: 0.8434319496154785
Validation loss: 1.765151326374341

Epoch: 5| Step: 7
Training loss: 0.8453944325447083
Validation loss: 1.7882401481751473

Epoch: 5| Step: 8
Training loss: 0.9393007159233093
Validation loss: 1.7172167211450555

Epoch: 5| Step: 9
Training loss: 0.9401220083236694
Validation loss: 1.6945563875218874

Epoch: 5| Step: 10
Training loss: 0.8212847709655762
Validation loss: 1.795658432027345

Epoch: 622| Step: 0
Training loss: 0.8879901170730591
Validation loss: 1.7312990798745105

Epoch: 5| Step: 1
Training loss: 1.390210747718811
Validation loss: 1.7459195634370208

Epoch: 5| Step: 2
Training loss: 1.1434684991836548
Validation loss: 1.7812252775315316

Epoch: 5| Step: 3
Training loss: 0.7905064821243286
Validation loss: 1.7217848403479463

Epoch: 5| Step: 4
Training loss: 1.275789499282837
Validation loss: 1.7633297328026063

Epoch: 5| Step: 5
Training loss: 0.9231807589530945
Validation loss: 1.7609534366156465

Epoch: 5| Step: 6
Training loss: 0.6287800073623657
Validation loss: 1.7319094122097056

Epoch: 5| Step: 7
Training loss: 0.8359634280204773
Validation loss: 1.7712676063660653

Epoch: 5| Step: 8
Training loss: 0.8180509805679321
Validation loss: 1.7964921189892677

Epoch: 5| Step: 9
Training loss: 0.9655826687812805
Validation loss: 1.7910477666444675

Epoch: 5| Step: 10
Training loss: 0.8052549362182617
Validation loss: 1.7806798745227117

Epoch: 623| Step: 0
Training loss: 1.207254409790039
Validation loss: 1.7482402196494482

Epoch: 5| Step: 1
Training loss: 0.6566521525382996
Validation loss: 1.7956690865178262

Epoch: 5| Step: 2
Training loss: 1.056997299194336
Validation loss: 1.7830507678370322

Epoch: 5| Step: 3
Training loss: 0.7809962034225464
Validation loss: 1.812350829442342

Epoch: 5| Step: 4
Training loss: 0.7929642796516418
Validation loss: 1.7711952565818705

Epoch: 5| Step: 5
Training loss: 0.7234452366828918
Validation loss: 1.7514841210457586

Epoch: 5| Step: 6
Training loss: 1.0193862915039062
Validation loss: 1.6994382476293912

Epoch: 5| Step: 7
Training loss: 1.0759583711624146
Validation loss: 1.7355565640234178

Epoch: 5| Step: 8
Training loss: 1.1073328256607056
Validation loss: 1.787986461834241

Epoch: 5| Step: 9
Training loss: 1.127647876739502
Validation loss: 1.738021719840265

Epoch: 5| Step: 10
Training loss: 0.7928805351257324
Validation loss: 1.7454365248321204

Epoch: 624| Step: 0
Training loss: 0.6888982057571411
Validation loss: 1.7372895774020944

Epoch: 5| Step: 1
Training loss: 1.1756523847579956
Validation loss: 1.69168480109143

Epoch: 5| Step: 2
Training loss: 0.6690975427627563
Validation loss: 1.743081030025277

Epoch: 5| Step: 3
Training loss: 1.069823980331421
Validation loss: 1.7644111699955438

Epoch: 5| Step: 4
Training loss: 0.5362564921379089
Validation loss: 1.7636137130439922

Epoch: 5| Step: 5
Training loss: 1.6831214427947998
Validation loss: 1.7192021582716255

Epoch: 5| Step: 6
Training loss: 1.1206743717193604
Validation loss: 1.7710162298653715

Epoch: 5| Step: 7
Training loss: 0.84625244140625
Validation loss: 1.7405448652082873

Epoch: 5| Step: 8
Training loss: 0.6629904508590698
Validation loss: 1.775739017353263

Epoch: 5| Step: 9
Training loss: 0.7538703083992004
Validation loss: 1.814965058398503

Epoch: 5| Step: 10
Training loss: 0.8593814969062805
Validation loss: 1.791525576704292

Epoch: 625| Step: 0
Training loss: 1.2242357730865479
Validation loss: 1.764956763995591

Epoch: 5| Step: 1
Training loss: 0.9674524068832397
Validation loss: 1.8487400752241894

Epoch: 5| Step: 2
Training loss: 0.8104785680770874
Validation loss: 1.781383252912952

Epoch: 5| Step: 3
Training loss: 0.7560669183731079
Validation loss: 1.746137930500892

Epoch: 5| Step: 4
Training loss: 0.7318002581596375
Validation loss: 1.7884347143993582

Epoch: 5| Step: 5
Training loss: 0.9604288935661316
Validation loss: 1.7469584788045576

Epoch: 5| Step: 6
Training loss: 0.8686362504959106
Validation loss: 1.787587317087317

Epoch: 5| Step: 7
Training loss: 0.9991649389266968
Validation loss: 1.708431807897424

Epoch: 5| Step: 8
Training loss: 1.3906269073486328
Validation loss: 1.8010125365308536

Epoch: 5| Step: 9
Training loss: 1.1029646396636963
Validation loss: 1.8118646965231946

Epoch: 5| Step: 10
Training loss: 0.4651579260826111
Validation loss: 1.7247299263554234

Epoch: 626| Step: 0
Training loss: 1.1056537628173828
Validation loss: 1.7599308042116062

Epoch: 5| Step: 1
Training loss: 0.8739110827445984
Validation loss: 1.721102758120465

Epoch: 5| Step: 2
Training loss: 0.6975905299186707
Validation loss: 1.7501031493627897

Epoch: 5| Step: 3
Training loss: 0.7914573550224304
Validation loss: 1.7545162887983425

Epoch: 5| Step: 4
Training loss: 0.6849442720413208
Validation loss: 1.7675524450117541

Epoch: 5| Step: 5
Training loss: 0.9560865163803101
Validation loss: 1.7448946916928856

Epoch: 5| Step: 6
Training loss: 1.177330732345581
Validation loss: 1.813047036688815

Epoch: 5| Step: 7
Training loss: 1.0303484201431274
Validation loss: 1.7922055106009207

Epoch: 5| Step: 8
Training loss: 0.712022066116333
Validation loss: 1.684936087618592

Epoch: 5| Step: 9
Training loss: 0.8864097595214844
Validation loss: 1.8084502181699198

Epoch: 5| Step: 10
Training loss: 0.8169127106666565
Validation loss: 1.8157299334003079

Epoch: 627| Step: 0
Training loss: 0.7502241134643555
Validation loss: 1.791442512184061

Epoch: 5| Step: 1
Training loss: 0.8272467851638794
Validation loss: 1.7585094744159329

Epoch: 5| Step: 2
Training loss: 0.6796526908874512
Validation loss: 1.7560664479450514

Epoch: 5| Step: 3
Training loss: 1.0589640140533447
Validation loss: 1.796684161309273

Epoch: 5| Step: 4
Training loss: 0.8378610610961914
Validation loss: 1.8023184140523274

Epoch: 5| Step: 5
Training loss: 0.9942423701286316
Validation loss: 1.7270805220450125

Epoch: 5| Step: 6
Training loss: 0.9963006973266602
Validation loss: 1.7917293886984549

Epoch: 5| Step: 7
Training loss: 0.8042634725570679
Validation loss: 1.7450765589232087

Epoch: 5| Step: 8
Training loss: 1.1205447912216187
Validation loss: 1.77774711449941

Epoch: 5| Step: 9
Training loss: 1.3679578304290771
Validation loss: 1.7315795639509797

Epoch: 5| Step: 10
Training loss: 0.7126064300537109
Validation loss: 1.7484225508987263

Epoch: 628| Step: 0
Training loss: 0.8493638038635254
Validation loss: 1.7666254069215508

Epoch: 5| Step: 1
Training loss: 1.0000401735305786
Validation loss: 1.7361617665137015

Epoch: 5| Step: 2
Training loss: 1.1479240655899048
Validation loss: 1.772427394825925

Epoch: 5| Step: 3
Training loss: 0.7541932463645935
Validation loss: 1.756144601811645

Epoch: 5| Step: 4
Training loss: 0.7209546566009521
Validation loss: 1.6901742014833676

Epoch: 5| Step: 5
Training loss: 0.7566407322883606
Validation loss: 1.6948854897611885

Epoch: 5| Step: 6
Training loss: 0.6418360471725464
Validation loss: 1.800461769104004

Epoch: 5| Step: 7
Training loss: 0.8554671406745911
Validation loss: 1.7199434182977165

Epoch: 5| Step: 8
Training loss: 1.416929841041565
Validation loss: 1.8096589593477146

Epoch: 5| Step: 9
Training loss: 0.8895075917243958
Validation loss: 1.7598756333833099

Epoch: 5| Step: 10
Training loss: 0.995223879814148
Validation loss: 1.711145277946226

Epoch: 629| Step: 0
Training loss: 1.2750247716903687
Validation loss: 1.7550172575058476

Epoch: 5| Step: 1
Training loss: 0.9635364413261414
Validation loss: 1.768775482331553

Epoch: 5| Step: 2
Training loss: 1.0349524021148682
Validation loss: 1.72900951293207

Epoch: 5| Step: 3
Training loss: 0.931396484375
Validation loss: 1.7531585744632188

Epoch: 5| Step: 4
Training loss: 1.0243284702301025
Validation loss: 1.6828002955323906

Epoch: 5| Step: 5
Training loss: 1.1224524974822998
Validation loss: 1.7784297632914718

Epoch: 5| Step: 6
Training loss: 0.6355973482131958
Validation loss: 1.7288206995174449

Epoch: 5| Step: 7
Training loss: 0.6236389875411987
Validation loss: 1.7199575542121806

Epoch: 5| Step: 8
Training loss: 1.0268784761428833
Validation loss: 1.7305519632113877

Epoch: 5| Step: 9
Training loss: 0.664976954460144
Validation loss: 1.7498443434315343

Epoch: 5| Step: 10
Training loss: 0.6955283880233765
Validation loss: 1.8060225158609369

Epoch: 630| Step: 0
Training loss: 1.0221614837646484
Validation loss: 1.746614166485366

Epoch: 5| Step: 1
Training loss: 0.8974357843399048
Validation loss: 1.7718968493964082

Epoch: 5| Step: 2
Training loss: 0.8436084985733032
Validation loss: 1.7752722027481243

Epoch: 5| Step: 3
Training loss: 1.11165452003479
Validation loss: 1.7621663001275831

Epoch: 5| Step: 4
Training loss: 1.0554852485656738
Validation loss: 1.7722277705387404

Epoch: 5| Step: 5
Training loss: 0.8447458148002625
Validation loss: 1.822693440221971

Epoch: 5| Step: 6
Training loss: 0.9308061599731445
Validation loss: 1.7635987484326927

Epoch: 5| Step: 7
Training loss: 1.0461878776550293
Validation loss: 1.8058361289321736

Epoch: 5| Step: 8
Training loss: 0.6544655561447144
Validation loss: 1.7610516650702364

Epoch: 5| Step: 9
Training loss: 0.9181915521621704
Validation loss: 1.7636556881730274

Epoch: 5| Step: 10
Training loss: 0.7097219824790955
Validation loss: 1.7530431401345037

Epoch: 631| Step: 0
Training loss: 1.1939200162887573
Validation loss: 1.7386183777163107

Epoch: 5| Step: 1
Training loss: 1.3908250331878662
Validation loss: 1.7777934035947245

Epoch: 5| Step: 2
Training loss: 0.7921086549758911
Validation loss: 1.7680782118151266

Epoch: 5| Step: 3
Training loss: 0.6464312672615051
Validation loss: 1.7256460843547698

Epoch: 5| Step: 4
Training loss: 1.314049482345581
Validation loss: 1.7362450604797692

Epoch: 5| Step: 5
Training loss: 0.5859311819076538
Validation loss: 1.6874404402189358

Epoch: 5| Step: 6
Training loss: 0.9750339388847351
Validation loss: 1.7676183331397273

Epoch: 5| Step: 7
Training loss: 0.973246693611145
Validation loss: 1.7729880886693155

Epoch: 5| Step: 8
Training loss: 0.8460267782211304
Validation loss: 1.7057859218248757

Epoch: 5| Step: 9
Training loss: 0.72002112865448
Validation loss: 1.7975228409613333

Epoch: 5| Step: 10
Training loss: 1.1415393352508545
Validation loss: 1.7259723986348798

Epoch: 632| Step: 0
Training loss: 1.1063592433929443
Validation loss: 1.7872559652533582

Epoch: 5| Step: 1
Training loss: 1.1197078227996826
Validation loss: 1.7430235391022058

Epoch: 5| Step: 2
Training loss: 1.416251301765442
Validation loss: 1.7912524169491184

Epoch: 5| Step: 3
Training loss: 0.7640947699546814
Validation loss: 1.7146483429016606

Epoch: 5| Step: 4
Training loss: 0.5157925486564636
Validation loss: 1.6970952300615207

Epoch: 5| Step: 5
Training loss: 0.9186522364616394
Validation loss: 1.7895271316651375

Epoch: 5| Step: 6
Training loss: 0.8154587745666504
Validation loss: 1.7726661594965125

Epoch: 5| Step: 7
Training loss: 1.094801425933838
Validation loss: 1.7892719314944359

Epoch: 5| Step: 8
Training loss: 0.7978626489639282
Validation loss: 1.7276959457705099

Epoch: 5| Step: 9
Training loss: 0.5874481201171875
Validation loss: 1.7921592522692937

Epoch: 5| Step: 10
Training loss: 0.9853031039237976
Validation loss: 1.793291518765111

Epoch: 633| Step: 0
Training loss: 0.9036469459533691
Validation loss: 1.7790271236050514

Epoch: 5| Step: 1
Training loss: 0.6643568277359009
Validation loss: 1.7950887487780662

Epoch: 5| Step: 2
Training loss: 0.9265602231025696
Validation loss: 1.7785309117327455

Epoch: 5| Step: 3
Training loss: 0.819672703742981
Validation loss: 1.7800702401386794

Epoch: 5| Step: 4
Training loss: 0.8566163182258606
Validation loss: 1.8052650625987718

Epoch: 5| Step: 5
Training loss: 0.9537668228149414
Validation loss: 1.7059123516082764

Epoch: 5| Step: 6
Training loss: 0.7105253338813782
Validation loss: 1.7688842973401468

Epoch: 5| Step: 7
Training loss: 1.2401525974273682
Validation loss: 1.7524976807255899

Epoch: 5| Step: 8
Training loss: 0.6369562745094299
Validation loss: 1.7723790804545085

Epoch: 5| Step: 9
Training loss: 1.0153076648712158
Validation loss: 1.7381939657272831

Epoch: 5| Step: 10
Training loss: 1.4841158390045166
Validation loss: 1.7336063051736483

Epoch: 634| Step: 0
Training loss: 0.8165456652641296
Validation loss: 1.7727512941565564

Epoch: 5| Step: 1
Training loss: 0.8532139658927917
Validation loss: 1.765010315884826

Epoch: 5| Step: 2
Training loss: 0.9667213559150696
Validation loss: 1.7729127817256476

Epoch: 5| Step: 3
Training loss: 0.8942289352416992
Validation loss: 1.7638938657699093

Epoch: 5| Step: 4
Training loss: 1.17976713180542
Validation loss: 1.8007612074575117

Epoch: 5| Step: 5
Training loss: 0.9067180752754211
Validation loss: 1.7737257480621338

Epoch: 5| Step: 6
Training loss: 1.1407891511917114
Validation loss: 1.8006576799577283

Epoch: 5| Step: 7
Training loss: 1.1687707901000977
Validation loss: 1.8116394063477874

Epoch: 5| Step: 8
Training loss: 0.5006108283996582
Validation loss: 1.8381516856531943

Epoch: 5| Step: 9
Training loss: 1.315363883972168
Validation loss: 1.8285158705967728

Epoch: 5| Step: 10
Training loss: 0.5418564081192017
Validation loss: 1.8517555959763066

Epoch: 635| Step: 0
Training loss: 0.9958702325820923
Validation loss: 1.7454379130435247

Epoch: 5| Step: 1
Training loss: 0.9591196179389954
Validation loss: 1.7913581607162312

Epoch: 5| Step: 2
Training loss: 0.9051889181137085
Validation loss: 1.7381799041583974

Epoch: 5| Step: 3
Training loss: 0.7743297219276428
Validation loss: 1.7462715679599392

Epoch: 5| Step: 4
Training loss: 0.5187913775444031
Validation loss: 1.779961935935482

Epoch: 5| Step: 5
Training loss: 0.8777559399604797
Validation loss: 1.740991666752805

Epoch: 5| Step: 6
Training loss: 0.6661537885665894
Validation loss: 1.7234186344249274

Epoch: 5| Step: 7
Training loss: 1.0861589908599854
Validation loss: 1.7867389520009358

Epoch: 5| Step: 8
Training loss: 1.139890432357788
Validation loss: 1.7693067750623148

Epoch: 5| Step: 9
Training loss: 0.902993381023407
Validation loss: 1.7642190584572413

Epoch: 5| Step: 10
Training loss: 1.1631650924682617
Validation loss: 1.6997862182637697

Epoch: 636| Step: 0
Training loss: 0.7143347859382629
Validation loss: 1.7342796825593518

Epoch: 5| Step: 1
Training loss: 0.5808548927307129
Validation loss: 1.7659312909649265

Epoch: 5| Step: 2
Training loss: 0.7368136048316956
Validation loss: 1.7413349997612737

Epoch: 5| Step: 3
Training loss: 1.1926219463348389
Validation loss: 1.7888169416817286

Epoch: 5| Step: 4
Training loss: 0.872036337852478
Validation loss: 1.8263050138309438

Epoch: 5| Step: 5
Training loss: 0.9202386736869812
Validation loss: 1.8164977117251324

Epoch: 5| Step: 6
Training loss: 0.9662108421325684
Validation loss: 1.788480197870603

Epoch: 5| Step: 7
Training loss: 1.5345646142959595
Validation loss: 1.750275545222785

Epoch: 5| Step: 8
Training loss: 0.8955492973327637
Validation loss: 1.7911423739566599

Epoch: 5| Step: 9
Training loss: 0.8448604345321655
Validation loss: 1.776018234991258

Epoch: 5| Step: 10
Training loss: 0.6464431881904602
Validation loss: 1.7598490843208887

Epoch: 637| Step: 0
Training loss: 0.5209858417510986
Validation loss: 1.7295851502367245

Epoch: 5| Step: 1
Training loss: 0.8700310587882996
Validation loss: 1.7421358375139133

Epoch: 5| Step: 2
Training loss: 1.0260908603668213
Validation loss: 1.8199828363233996

Epoch: 5| Step: 3
Training loss: 1.1435390710830688
Validation loss: 1.803889436106528

Epoch: 5| Step: 4
Training loss: 0.9732437133789062
Validation loss: 1.7858867260717577

Epoch: 5| Step: 5
Training loss: 1.4239107370376587
Validation loss: 1.801527689861995

Epoch: 5| Step: 6
Training loss: 1.0650055408477783
Validation loss: 1.7201419709831156

Epoch: 5| Step: 7
Training loss: 0.9273780584335327
Validation loss: 1.7526776047163113

Epoch: 5| Step: 8
Training loss: 0.7230309247970581
Validation loss: 1.8075811927036574

Epoch: 5| Step: 9
Training loss: 0.7227828502655029
Validation loss: 1.7211396514728505

Epoch: 5| Step: 10
Training loss: 0.7324279546737671
Validation loss: 1.7604396573958858

Epoch: 638| Step: 0
Training loss: 1.008381962776184
Validation loss: 1.7098198513830862

Epoch: 5| Step: 1
Training loss: 0.9952434301376343
Validation loss: 1.7844347543613885

Epoch: 5| Step: 2
Training loss: 1.2269656658172607
Validation loss: 1.7639729066561627

Epoch: 5| Step: 3
Training loss: 1.0490881204605103
Validation loss: 1.744327377247554

Epoch: 5| Step: 4
Training loss: 0.7337173223495483
Validation loss: 1.8025019886673137

Epoch: 5| Step: 5
Training loss: 0.7962855100631714
Validation loss: 1.7466138255211614

Epoch: 5| Step: 6
Training loss: 0.7344719171524048
Validation loss: 1.725253423055013

Epoch: 5| Step: 7
Training loss: 0.9905787706375122
Validation loss: 1.7858363812969578

Epoch: 5| Step: 8
Training loss: 1.1300127506256104
Validation loss: 1.7608226858159548

Epoch: 5| Step: 9
Training loss: 0.8350809216499329
Validation loss: 1.7167615659775273

Epoch: 5| Step: 10
Training loss: 0.5327003002166748
Validation loss: 1.7470781392948602

Epoch: 639| Step: 0
Training loss: 0.8085641860961914
Validation loss: 1.703924818705487

Epoch: 5| Step: 1
Training loss: 0.6362197995185852
Validation loss: 1.743160334966516

Epoch: 5| Step: 2
Training loss: 1.0283902883529663
Validation loss: 1.773764007834978

Epoch: 5| Step: 3
Training loss: 1.2208747863769531
Validation loss: 1.7534858206266999

Epoch: 5| Step: 4
Training loss: 0.6851550936698914
Validation loss: 1.743721724838339

Epoch: 5| Step: 5
Training loss: 0.9705684781074524
Validation loss: 1.7433672066657775

Epoch: 5| Step: 6
Training loss: 0.9910320043563843
Validation loss: 1.7492057751583796

Epoch: 5| Step: 7
Training loss: 0.517440676689148
Validation loss: 1.779819046297381

Epoch: 5| Step: 8
Training loss: 0.946480929851532
Validation loss: 1.7602120983985163

Epoch: 5| Step: 9
Training loss: 1.253971815109253
Validation loss: 1.791171532805248

Epoch: 5| Step: 10
Training loss: 0.771747350692749
Validation loss: 1.746942222759288

Epoch: 640| Step: 0
Training loss: 0.9236066937446594
Validation loss: 1.744480908557933

Epoch: 5| Step: 1
Training loss: 1.2910455465316772
Validation loss: 1.7725223943751345

Epoch: 5| Step: 2
Training loss: 0.9020929336547852
Validation loss: 1.7647038711014615

Epoch: 5| Step: 3
Training loss: 0.8479207754135132
Validation loss: 1.7419083708076066

Epoch: 5| Step: 4
Training loss: 0.8946981430053711
Validation loss: 1.7779578137141403

Epoch: 5| Step: 5
Training loss: 0.7008817791938782
Validation loss: 1.7643730191774265

Epoch: 5| Step: 6
Training loss: 0.8109463453292847
Validation loss: 1.8173772686271257

Epoch: 5| Step: 7
Training loss: 0.6703695058822632
Validation loss: 1.7564328883283882

Epoch: 5| Step: 8
Training loss: 0.9259681701660156
Validation loss: 1.7951514221006823

Epoch: 5| Step: 9
Training loss: 0.834479033946991
Validation loss: 1.72511685791836

Epoch: 5| Step: 10
Training loss: 1.068469524383545
Validation loss: 1.7910050128095893

Epoch: 641| Step: 0
Training loss: 0.6153489351272583
Validation loss: 1.8222858136700046

Epoch: 5| Step: 1
Training loss: 0.8221659660339355
Validation loss: 1.7823368605747019

Epoch: 5| Step: 2
Training loss: 1.1709901094436646
Validation loss: 1.8236192810919978

Epoch: 5| Step: 3
Training loss: 1.0765010118484497
Validation loss: 1.7807475136172386

Epoch: 5| Step: 4
Training loss: 1.0035336017608643
Validation loss: 1.7670464118321736

Epoch: 5| Step: 5
Training loss: 0.5620614886283875
Validation loss: 1.714372710515094

Epoch: 5| Step: 6
Training loss: 0.7543178796768188
Validation loss: 1.6995371259668821

Epoch: 5| Step: 7
Training loss: 1.0030921697616577
Validation loss: 1.7448278447633148

Epoch: 5| Step: 8
Training loss: 0.9347634315490723
Validation loss: 1.7153032531020462

Epoch: 5| Step: 9
Training loss: 1.202986478805542
Validation loss: 1.7611018944812078

Epoch: 5| Step: 10
Training loss: 0.923407256603241
Validation loss: 1.7401837328428864

Epoch: 642| Step: 0
Training loss: 1.6508785486221313
Validation loss: 1.7477229910512124

Epoch: 5| Step: 1
Training loss: 0.6741225123405457
Validation loss: 1.7630420782232796

Epoch: 5| Step: 2
Training loss: 1.0946578979492188
Validation loss: 1.7646353962600871

Epoch: 5| Step: 3
Training loss: 0.9033046960830688
Validation loss: 1.764214664377192

Epoch: 5| Step: 4
Training loss: 1.0057101249694824
Validation loss: 1.7935773403413835

Epoch: 5| Step: 5
Training loss: 0.8421250581741333
Validation loss: 1.786591237591159

Epoch: 5| Step: 6
Training loss: 0.9778850674629211
Validation loss: 1.7492009747412898

Epoch: 5| Step: 7
Training loss: 0.8026798367500305
Validation loss: 1.8193958574725735

Epoch: 5| Step: 8
Training loss: 0.6871274709701538
Validation loss: 1.7220750188314786

Epoch: 5| Step: 9
Training loss: 0.7293521761894226
Validation loss: 1.7343393166859944

Epoch: 5| Step: 10
Training loss: 0.775854766368866
Validation loss: 1.7236594461625623

Epoch: 643| Step: 0
Training loss: 0.7347083687782288
Validation loss: 1.78579605010248

Epoch: 5| Step: 1
Training loss: 0.8404812812805176
Validation loss: 1.7397631957966795

Epoch: 5| Step: 2
Training loss: 0.7197175025939941
Validation loss: 1.7433018825387443

Epoch: 5| Step: 3
Training loss: 0.9892742037773132
Validation loss: 1.7512091289284408

Epoch: 5| Step: 4
Training loss: 0.7592005133628845
Validation loss: 1.7729712391412387

Epoch: 5| Step: 5
Training loss: 1.0600839853286743
Validation loss: 1.6902888269834622

Epoch: 5| Step: 6
Training loss: 0.7776229977607727
Validation loss: 1.8087903107366254

Epoch: 5| Step: 7
Training loss: 1.071732759475708
Validation loss: 1.7097824735026206

Epoch: 5| Step: 8
Training loss: 1.0274982452392578
Validation loss: 1.7567809653538529

Epoch: 5| Step: 9
Training loss: 0.7918586730957031
Validation loss: 1.748883847267397

Epoch: 5| Step: 10
Training loss: 1.0300593376159668
Validation loss: 1.7462146218105028

Epoch: 644| Step: 0
Training loss: 0.7585042119026184
Validation loss: 1.7897195495584959

Epoch: 5| Step: 1
Training loss: 0.7911969423294067
Validation loss: 1.7512250100412676

Epoch: 5| Step: 2
Training loss: 0.7746663093566895
Validation loss: 1.7935502170234598

Epoch: 5| Step: 3
Training loss: 0.8172498941421509
Validation loss: 1.7682155755258375

Epoch: 5| Step: 4
Training loss: 0.5653336048126221
Validation loss: 1.7606339685378536

Epoch: 5| Step: 5
Training loss: 1.3299789428710938
Validation loss: 1.822354628193763

Epoch: 5| Step: 6
Training loss: 0.9535813331604004
Validation loss: 1.7852999202666744

Epoch: 5| Step: 7
Training loss: 0.964389443397522
Validation loss: 1.8161688363680275

Epoch: 5| Step: 8
Training loss: 0.9974552989006042
Validation loss: 1.7634528119076964

Epoch: 5| Step: 9
Training loss: 0.96165931224823
Validation loss: 1.7155775844409902

Epoch: 5| Step: 10
Training loss: 1.0040674209594727
Validation loss: 1.8135915558825257

Epoch: 645| Step: 0
Training loss: 0.9848591685295105
Validation loss: 1.7677595948660245

Epoch: 5| Step: 1
Training loss: 1.0136715173721313
Validation loss: 1.8118632070479854

Epoch: 5| Step: 2
Training loss: 1.2354016304016113
Validation loss: 1.7750030332995999

Epoch: 5| Step: 3
Training loss: 0.8403250575065613
Validation loss: 1.8708659384840278

Epoch: 5| Step: 4
Training loss: 1.0025373697280884
Validation loss: 1.7475150169864777

Epoch: 5| Step: 5
Training loss: 0.8337151408195496
Validation loss: 1.798807074946742

Epoch: 5| Step: 6
Training loss: 0.9172639846801758
Validation loss: 1.7259762338412705

Epoch: 5| Step: 7
Training loss: 0.8176653981208801
Validation loss: 1.767553642231931

Epoch: 5| Step: 8
Training loss: 0.744706928730011
Validation loss: 1.77713789222061

Epoch: 5| Step: 9
Training loss: 0.7501630783081055
Validation loss: 1.7253758625317646

Epoch: 5| Step: 10
Training loss: 0.37837672233581543
Validation loss: 1.776724652577472

Epoch: 646| Step: 0
Training loss: 0.928134560585022
Validation loss: 1.7431983063297887

Epoch: 5| Step: 1
Training loss: 0.832532525062561
Validation loss: 1.7836369916956911

Epoch: 5| Step: 2
Training loss: 0.9297075271606445
Validation loss: 1.7570234934488933

Epoch: 5| Step: 3
Training loss: 1.2147029638290405
Validation loss: 1.76785502190231

Epoch: 5| Step: 4
Training loss: 0.9432021379470825
Validation loss: 1.7491343431575324

Epoch: 5| Step: 5
Training loss: 0.900218665599823
Validation loss: 1.7526392141977947

Epoch: 5| Step: 6
Training loss: 0.5337879657745361
Validation loss: 1.6954579122604863

Epoch: 5| Step: 7
Training loss: 0.5539718866348267
Validation loss: 1.687723111080867

Epoch: 5| Step: 8
Training loss: 1.1886144876480103
Validation loss: 1.7489296800346785

Epoch: 5| Step: 9
Training loss: 0.7166382074356079
Validation loss: 1.7491685639145553

Epoch: 5| Step: 10
Training loss: 0.775995135307312
Validation loss: 1.7680274312214186

Epoch: 647| Step: 0
Training loss: 0.6461519002914429
Validation loss: 1.7173798584168958

Epoch: 5| Step: 1
Training loss: 1.0584160089492798
Validation loss: 1.7208349807288057

Epoch: 5| Step: 2
Training loss: 0.9188264608383179
Validation loss: 1.7602130225909653

Epoch: 5| Step: 3
Training loss: 0.7497247457504272
Validation loss: 1.7202877203623455

Epoch: 5| Step: 4
Training loss: 1.0955113172531128
Validation loss: 1.7692355673800233

Epoch: 5| Step: 5
Training loss: 0.6615859270095825
Validation loss: 1.751122317006511

Epoch: 5| Step: 6
Training loss: 0.7761180996894836
Validation loss: 1.740794804788405

Epoch: 5| Step: 7
Training loss: 1.3308045864105225
Validation loss: 1.749402048767254

Epoch: 5| Step: 8
Training loss: 0.5717445611953735
Validation loss: 1.7893969012844948

Epoch: 5| Step: 9
Training loss: 0.969447135925293
Validation loss: 1.8400293575820101

Epoch: 5| Step: 10
Training loss: 0.7077985405921936
Validation loss: 1.7580391777459012

Epoch: 648| Step: 0
Training loss: 1.0995312929153442
Validation loss: 1.786344325670632

Epoch: 5| Step: 1
Training loss: 0.6782517433166504
Validation loss: 1.780096520659744

Epoch: 5| Step: 2
Training loss: 0.9551835060119629
Validation loss: 1.7507038552273986

Epoch: 5| Step: 3
Training loss: 0.6978775858879089
Validation loss: 1.727119436828039

Epoch: 5| Step: 4
Training loss: 0.7210054397583008
Validation loss: 1.7147533060401998

Epoch: 5| Step: 5
Training loss: 0.4492829442024231
Validation loss: 1.7535727575261106

Epoch: 5| Step: 6
Training loss: 0.9989506602287292
Validation loss: 1.7903772784817604

Epoch: 5| Step: 7
Training loss: 1.2010811567306519
Validation loss: 1.7427121939197663

Epoch: 5| Step: 8
Training loss: 0.8852856755256653
Validation loss: 1.7948763332059305

Epoch: 5| Step: 9
Training loss: 0.8958069682121277
Validation loss: 1.7828557722030147

Epoch: 5| Step: 10
Training loss: 1.0978180170059204
Validation loss: 1.8082361182858866

Epoch: 649| Step: 0
Training loss: 0.5079023241996765
Validation loss: 1.7291603447288595

Epoch: 5| Step: 1
Training loss: 1.0801994800567627
Validation loss: 1.7484236789006058

Epoch: 5| Step: 2
Training loss: 0.8077957034111023
Validation loss: 1.7394558511754519

Epoch: 5| Step: 3
Training loss: 0.9569091796875
Validation loss: 1.7516424297004618

Epoch: 5| Step: 4
Training loss: 0.7962201833724976
Validation loss: 1.7574199886732205

Epoch: 5| Step: 5
Training loss: 0.9408923387527466
Validation loss: 1.7426602955787414

Epoch: 5| Step: 6
Training loss: 0.5827683210372925
Validation loss: 1.7546510747683945

Epoch: 5| Step: 7
Training loss: 0.9568164944648743
Validation loss: 1.7954402008364279

Epoch: 5| Step: 8
Training loss: 0.7427631616592407
Validation loss: 1.7817425471480175

Epoch: 5| Step: 9
Training loss: 1.3823626041412354
Validation loss: 1.7846401840127923

Epoch: 5| Step: 10
Training loss: 0.885934591293335
Validation loss: 1.772166480300247

Epoch: 650| Step: 0
Training loss: 0.7809767723083496
Validation loss: 1.7659643055290304

Epoch: 5| Step: 1
Training loss: 1.5385730266571045
Validation loss: 1.8155791631308935

Epoch: 5| Step: 2
Training loss: 0.7534807920455933
Validation loss: 1.75993025431069

Epoch: 5| Step: 3
Training loss: 0.9054335355758667
Validation loss: 1.7401104486116798

Epoch: 5| Step: 4
Training loss: 1.017486810684204
Validation loss: 1.783397420760124

Epoch: 5| Step: 5
Training loss: 0.8845523595809937
Validation loss: 1.7403801474519955

Epoch: 5| Step: 6
Training loss: 0.9091312289237976
Validation loss: 1.7769273122151692

Epoch: 5| Step: 7
Training loss: 0.6733517646789551
Validation loss: 1.7345940951378114

Epoch: 5| Step: 8
Training loss: 0.5057571530342102
Validation loss: 1.7942792728383055

Epoch: 5| Step: 9
Training loss: 0.9991733431816101
Validation loss: 1.7590756249684159

Epoch: 5| Step: 10
Training loss: 0.902328372001648
Validation loss: 1.6962510821639851

Epoch: 651| Step: 0
Training loss: 0.821315586566925
Validation loss: 1.791890880113007

Epoch: 5| Step: 1
Training loss: 0.794283390045166
Validation loss: 1.714608710299256

Epoch: 5| Step: 2
Training loss: 0.891089141368866
Validation loss: 1.7378500584633119

Epoch: 5| Step: 3
Training loss: 0.809402585029602
Validation loss: 1.7097602736565374

Epoch: 5| Step: 4
Training loss: 0.9163053631782532
Validation loss: 1.7491962614879812

Epoch: 5| Step: 5
Training loss: 1.0307809114456177
Validation loss: 1.7470894628955471

Epoch: 5| Step: 6
Training loss: 0.8103523254394531
Validation loss: 1.7745396629456551

Epoch: 5| Step: 7
Training loss: 0.6198597550392151
Validation loss: 1.7175733799575477

Epoch: 5| Step: 8
Training loss: 0.9753276705741882
Validation loss: 1.7605591371495237

Epoch: 5| Step: 9
Training loss: 1.0807536840438843
Validation loss: 1.7621480880245086

Epoch: 5| Step: 10
Training loss: 0.6029199361801147
Validation loss: 1.7772579654570548

Epoch: 652| Step: 0
Training loss: 0.8849223256111145
Validation loss: 1.8101319792450115

Epoch: 5| Step: 1
Training loss: 0.6495444774627686
Validation loss: 1.7674046998382897

Epoch: 5| Step: 2
Training loss: 1.0470205545425415
Validation loss: 1.7947790366347118

Epoch: 5| Step: 3
Training loss: 0.970779538154602
Validation loss: 1.8137722233290314

Epoch: 5| Step: 4
Training loss: 0.9470376968383789
Validation loss: 1.749316870525319

Epoch: 5| Step: 5
Training loss: 0.7181210517883301
Validation loss: 1.8033381713333951

Epoch: 5| Step: 6
Training loss: 0.7640283703804016
Validation loss: 1.728732716652655

Epoch: 5| Step: 7
Training loss: 0.9693512916564941
Validation loss: 1.7717797089648504

Epoch: 5| Step: 8
Training loss: 1.1775318384170532
Validation loss: 1.803510776130102

Epoch: 5| Step: 9
Training loss: 0.6219892501831055
Validation loss: 1.7880424607184626

Epoch: 5| Step: 10
Training loss: 0.5154793858528137
Validation loss: 1.7041680620562645

Epoch: 653| Step: 0
Training loss: 0.5626741051673889
Validation loss: 1.7225480054014473

Epoch: 5| Step: 1
Training loss: 0.7718454003334045
Validation loss: 1.723026055161671

Epoch: 5| Step: 2
Training loss: 0.7487766742706299
Validation loss: 1.708547314008077

Epoch: 5| Step: 3
Training loss: 0.7946423888206482
Validation loss: 1.7653231543879355

Epoch: 5| Step: 4
Training loss: 0.6667864918708801
Validation loss: 1.7626944639349496

Epoch: 5| Step: 5
Training loss: 0.6746112108230591
Validation loss: 1.739089265946419

Epoch: 5| Step: 6
Training loss: 0.8484281301498413
Validation loss: 1.6777645644321237

Epoch: 5| Step: 7
Training loss: 1.785780668258667
Validation loss: 1.698325398147747

Epoch: 5| Step: 8
Training loss: 1.0143266916275024
Validation loss: 1.7431501086040209

Epoch: 5| Step: 9
Training loss: 0.990456759929657
Validation loss: 1.7741618361524356

Epoch: 5| Step: 10
Training loss: 0.83962482213974
Validation loss: 1.7800275151447584

Epoch: 654| Step: 0
Training loss: 0.9612895846366882
Validation loss: 1.7825836468768377

Epoch: 5| Step: 1
Training loss: 0.9957768321037292
Validation loss: 1.749130633569533

Epoch: 5| Step: 2
Training loss: 1.0927151441574097
Validation loss: 1.8239125385079333

Epoch: 5| Step: 3
Training loss: 0.693480908870697
Validation loss: 1.7966097785580544

Epoch: 5| Step: 4
Training loss: 0.803094744682312
Validation loss: 1.7242585561608756

Epoch: 5| Step: 5
Training loss: 0.9396163821220398
Validation loss: 1.7767785800400602

Epoch: 5| Step: 6
Training loss: 1.2663336992263794
Validation loss: 1.7475883371086531

Epoch: 5| Step: 7
Training loss: 0.7455474734306335
Validation loss: 1.725452551277735

Epoch: 5| Step: 8
Training loss: 0.5345125198364258
Validation loss: 1.7469363545858732

Epoch: 5| Step: 9
Training loss: 0.6536142826080322
Validation loss: 1.7645587639142108

Epoch: 5| Step: 10
Training loss: 0.9908082485198975
Validation loss: 1.7484998087729178

Epoch: 655| Step: 0
Training loss: 0.8476530909538269
Validation loss: 1.6863217482002832

Epoch: 5| Step: 1
Training loss: 1.3535728454589844
Validation loss: 1.779502616133741

Epoch: 5| Step: 2
Training loss: 0.9347317814826965
Validation loss: 1.7079098993732083

Epoch: 5| Step: 3
Training loss: 0.6142686009407043
Validation loss: 1.6814453922292238

Epoch: 5| Step: 4
Training loss: 0.5070228576660156
Validation loss: 1.7446182825232064

Epoch: 5| Step: 5
Training loss: 0.7947608828544617
Validation loss: 1.842100106259828

Epoch: 5| Step: 6
Training loss: 0.8718292117118835
Validation loss: 1.7572895557649675

Epoch: 5| Step: 7
Training loss: 0.5688637495040894
Validation loss: 1.7586086821812454

Epoch: 5| Step: 8
Training loss: 0.9668993949890137
Validation loss: 1.7064328526937833

Epoch: 5| Step: 9
Training loss: 1.236275315284729
Validation loss: 1.772864830109381

Epoch: 5| Step: 10
Training loss: 1.22712242603302
Validation loss: 1.732489275675948

Epoch: 656| Step: 0
Training loss: 0.7125592827796936
Validation loss: 1.6934617680888022

Epoch: 5| Step: 1
Training loss: 0.7554522752761841
Validation loss: 1.7564695932531869

Epoch: 5| Step: 2
Training loss: 1.115774393081665
Validation loss: 1.6839560308764059

Epoch: 5| Step: 3
Training loss: 1.0235884189605713
Validation loss: 1.6782068860146306

Epoch: 5| Step: 4
Training loss: 0.5287966132164001
Validation loss: 1.7616350855878604

Epoch: 5| Step: 5
Training loss: 0.9720104336738586
Validation loss: 1.764911069664904

Epoch: 5| Step: 6
Training loss: 0.7159726023674011
Validation loss: 1.7517085024105605

Epoch: 5| Step: 7
Training loss: 0.4706496298313141
Validation loss: 1.7019098958661478

Epoch: 5| Step: 8
Training loss: 1.348118543624878
Validation loss: 1.7419527538361088

Epoch: 5| Step: 9
Training loss: 1.0908498764038086
Validation loss: 1.7687694385487547

Epoch: 5| Step: 10
Training loss: 1.0770331621170044
Validation loss: 1.7505513237368675

Epoch: 657| Step: 0
Training loss: 0.7286064028739929
Validation loss: 1.7747833292971376

Epoch: 5| Step: 1
Training loss: 1.0858829021453857
Validation loss: 1.7344605973971787

Epoch: 5| Step: 2
Training loss: 0.8065759539604187
Validation loss: 1.7018883330847627

Epoch: 5| Step: 3
Training loss: 0.8375523686408997
Validation loss: 1.781566600645742

Epoch: 5| Step: 4
Training loss: 0.9095064401626587
Validation loss: 1.684459847788657

Epoch: 5| Step: 5
Training loss: 0.5733330249786377
Validation loss: 1.7956947049786967

Epoch: 5| Step: 6
Training loss: 0.9499473571777344
Validation loss: 1.7396304145936043

Epoch: 5| Step: 7
Training loss: 0.772762656211853
Validation loss: 1.7727442761903167

Epoch: 5| Step: 8
Training loss: 0.9227026700973511
Validation loss: 1.7864021383306032

Epoch: 5| Step: 9
Training loss: 0.9231599569320679
Validation loss: 1.766946574693085

Epoch: 5| Step: 10
Training loss: 0.774589478969574
Validation loss: 1.7302495587256648

Epoch: 658| Step: 0
Training loss: 0.7488831877708435
Validation loss: 1.7887245339732016

Epoch: 5| Step: 1
Training loss: 1.0151606798171997
Validation loss: 1.7810501475487985

Epoch: 5| Step: 2
Training loss: 0.7916265726089478
Validation loss: 1.7807566824779715

Epoch: 5| Step: 3
Training loss: 1.3234646320343018
Validation loss: 1.7166832390651907

Epoch: 5| Step: 4
Training loss: 0.9717547297477722
Validation loss: 1.745808236060604

Epoch: 5| Step: 5
Training loss: 0.6952216625213623
Validation loss: 1.7305756012598674

Epoch: 5| Step: 6
Training loss: 0.5763651728630066
Validation loss: 1.7820952387266262

Epoch: 5| Step: 7
Training loss: 0.8308836221694946
Validation loss: 1.781031923909341

Epoch: 5| Step: 8
Training loss: 0.8154772520065308
Validation loss: 1.766393861462993

Epoch: 5| Step: 9
Training loss: 0.9426169395446777
Validation loss: 1.7500398671755226

Epoch: 5| Step: 10
Training loss: 0.48797568678855896
Validation loss: 1.7401340610237532

Epoch: 659| Step: 0
Training loss: 0.6960239410400391
Validation loss: 1.7434077865333968

Epoch: 5| Step: 1
Training loss: 0.7373629808425903
Validation loss: 1.7788029486133206

Epoch: 5| Step: 2
Training loss: 1.4115138053894043
Validation loss: 1.769852957417888

Epoch: 5| Step: 3
Training loss: 0.7014752626419067
Validation loss: 1.7640898355873682

Epoch: 5| Step: 4
Training loss: 0.7931637763977051
Validation loss: 1.7580646109837357

Epoch: 5| Step: 5
Training loss: 0.47923746705055237
Validation loss: 1.7694802989241898

Epoch: 5| Step: 6
Training loss: 0.5104053020477295
Validation loss: 1.708068088818622

Epoch: 5| Step: 7
Training loss: 1.087793231010437
Validation loss: 1.7384491402615783

Epoch: 5| Step: 8
Training loss: 0.9962928891181946
Validation loss: 1.7903612198368195

Epoch: 5| Step: 9
Training loss: 1.0256963968276978
Validation loss: 1.7469882888178672

Epoch: 5| Step: 10
Training loss: 1.094791054725647
Validation loss: 1.6978123239291611

Epoch: 660| Step: 0
Training loss: 0.708044171333313
Validation loss: 1.7886748865086546

Epoch: 5| Step: 1
Training loss: 0.8640154004096985
Validation loss: 1.740603067541635

Epoch: 5| Step: 2
Training loss: 1.3164169788360596
Validation loss: 1.7662208849383938

Epoch: 5| Step: 3
Training loss: 0.6995301246643066
Validation loss: 1.7490668412177794

Epoch: 5| Step: 4
Training loss: 1.2359962463378906
Validation loss: 1.7305158774058025

Epoch: 5| Step: 5
Training loss: 0.546629786491394
Validation loss: 1.7430912551059519

Epoch: 5| Step: 6
Training loss: 0.9713059663772583
Validation loss: 1.7884564220264394

Epoch: 5| Step: 7
Training loss: 0.6535749435424805
Validation loss: 1.7647559309518466

Epoch: 5| Step: 8
Training loss: 0.5498291254043579
Validation loss: 1.7511544253236504

Epoch: 5| Step: 9
Training loss: 0.7428295612335205
Validation loss: 1.7082504880043767

Epoch: 5| Step: 10
Training loss: 1.1350432634353638
Validation loss: 1.7502121925354004

Epoch: 661| Step: 0
Training loss: 0.6526957750320435
Validation loss: 1.6827281508394467

Epoch: 5| Step: 1
Training loss: 0.7859090566635132
Validation loss: 1.8174073785863898

Epoch: 5| Step: 2
Training loss: 0.5470556616783142
Validation loss: 1.780495894852505

Epoch: 5| Step: 3
Training loss: 1.0550596714019775
Validation loss: 1.7508825345705914

Epoch: 5| Step: 4
Training loss: 0.7106816172599792
Validation loss: 1.7741882621601064

Epoch: 5| Step: 5
Training loss: 0.991980254650116
Validation loss: 1.7901867679370347

Epoch: 5| Step: 6
Training loss: 0.7013309001922607
Validation loss: 1.7747121190512052

Epoch: 5| Step: 7
Training loss: 0.888637363910675
Validation loss: 1.7716131069326913

Epoch: 5| Step: 8
Training loss: 0.6555098295211792
Validation loss: 1.7761232071025397

Epoch: 5| Step: 9
Training loss: 1.167635202407837
Validation loss: 1.731494749746015

Epoch: 5| Step: 10
Training loss: 1.350537657737732
Validation loss: 1.7713723028859785

Epoch: 662| Step: 0
Training loss: 0.9855941534042358
Validation loss: 1.7934321280448668

Epoch: 5| Step: 1
Training loss: 0.893255889415741
Validation loss: 1.756927095433717

Epoch: 5| Step: 2
Training loss: 1.017564296722412
Validation loss: 1.812723975027761

Epoch: 5| Step: 3
Training loss: 1.0407428741455078
Validation loss: 1.8154775814343524

Epoch: 5| Step: 4
Training loss: 0.6833445429801941
Validation loss: 1.7530812166070426

Epoch: 5| Step: 5
Training loss: 0.861594557762146
Validation loss: 1.7282797546796902

Epoch: 5| Step: 6
Training loss: 0.5623811483383179
Validation loss: 1.738497652033324

Epoch: 5| Step: 7
Training loss: 0.7707512974739075
Validation loss: 1.7153524942295526

Epoch: 5| Step: 8
Training loss: 0.6491366028785706
Validation loss: 1.769599578713858

Epoch: 5| Step: 9
Training loss: 0.9075824022293091
Validation loss: 1.8026825048590218

Epoch: 5| Step: 10
Training loss: 0.7732091546058655
Validation loss: 1.7476263930720668

Epoch: 663| Step: 0
Training loss: 0.6704949140548706
Validation loss: 1.7843927106549662

Epoch: 5| Step: 1
Training loss: 0.6552248597145081
Validation loss: 1.7261931024571902

Epoch: 5| Step: 2
Training loss: 0.6575828790664673
Validation loss: 1.7243555463770384

Epoch: 5| Step: 3
Training loss: 0.6935610175132751
Validation loss: 1.7817804903112433

Epoch: 5| Step: 4
Training loss: 0.9724701046943665
Validation loss: 1.7575025609744492

Epoch: 5| Step: 5
Training loss: 0.7264646291732788
Validation loss: 1.7522394298225321

Epoch: 5| Step: 6
Training loss: 1.1336880922317505
Validation loss: 1.75520997406334

Epoch: 5| Step: 7
Training loss: 1.1065573692321777
Validation loss: 1.725645447290072

Epoch: 5| Step: 8
Training loss: 1.064406394958496
Validation loss: 1.7649294932683308

Epoch: 5| Step: 9
Training loss: 0.9780284762382507
Validation loss: 1.7343568878789102

Epoch: 5| Step: 10
Training loss: 0.703452467918396
Validation loss: 1.7638236130437543

Epoch: 664| Step: 0
Training loss: 0.9746990203857422
Validation loss: 1.7399655683066255

Epoch: 5| Step: 1
Training loss: 1.0057352781295776
Validation loss: 1.781466794270341

Epoch: 5| Step: 2
Training loss: 0.7668678760528564
Validation loss: 1.7338111913332375

Epoch: 5| Step: 3
Training loss: 0.7351940870285034
Validation loss: 1.7610876175665087

Epoch: 5| Step: 4
Training loss: 0.6381990313529968
Validation loss: 1.7908550795688425

Epoch: 5| Step: 5
Training loss: 1.1072323322296143
Validation loss: 1.7734642720991565

Epoch: 5| Step: 6
Training loss: 0.8129521608352661
Validation loss: 1.7561024901687459

Epoch: 5| Step: 7
Training loss: 0.5184866189956665
Validation loss: 1.7492409444624377

Epoch: 5| Step: 8
Training loss: 0.639686644077301
Validation loss: 1.7278497257540304

Epoch: 5| Step: 9
Training loss: 1.0625430345535278
Validation loss: 1.740083686767086

Epoch: 5| Step: 10
Training loss: 1.0095099210739136
Validation loss: 1.6945602534919657

Epoch: 665| Step: 0
Training loss: 0.9723720550537109
Validation loss: 1.7297623003682783

Epoch: 5| Step: 1
Training loss: 0.6999300122261047
Validation loss: 1.7810205656995055

Epoch: 5| Step: 2
Training loss: 0.633354663848877
Validation loss: 1.7362375105580976

Epoch: 5| Step: 3
Training loss: 0.7845695614814758
Validation loss: 1.7381102654241747

Epoch: 5| Step: 4
Training loss: 0.9380086064338684
Validation loss: 1.8076508173378565

Epoch: 5| Step: 5
Training loss: 0.5539321303367615
Validation loss: 1.756749701756303

Epoch: 5| Step: 6
Training loss: 0.7243520617485046
Validation loss: 1.8058027951948104

Epoch: 5| Step: 7
Training loss: 1.0962574481964111
Validation loss: 1.7781617269721082

Epoch: 5| Step: 8
Training loss: 0.8003045916557312
Validation loss: 1.768825877097345

Epoch: 5| Step: 9
Training loss: 1.125653624534607
Validation loss: 1.8364111313255884

Epoch: 5| Step: 10
Training loss: 1.2566075325012207
Validation loss: 1.762843919056718

Epoch: 666| Step: 0
Training loss: 0.4877558648586273
Validation loss: 1.7532167639783633

Epoch: 5| Step: 1
Training loss: 1.3162600994110107
Validation loss: 1.6842229417575303

Epoch: 5| Step: 2
Training loss: 1.0006769895553589
Validation loss: 1.7258615775774884

Epoch: 5| Step: 3
Training loss: 0.9544700384140015
Validation loss: 1.7284953376298309

Epoch: 5| Step: 4
Training loss: 0.7453823089599609
Validation loss: 1.7871346665966896

Epoch: 5| Step: 5
Training loss: 0.8862003087997437
Validation loss: 1.737458852029616

Epoch: 5| Step: 6
Training loss: 0.7580457925796509
Validation loss: 1.7484970374773907

Epoch: 5| Step: 7
Training loss: 1.0249522924423218
Validation loss: 1.742436949924756

Epoch: 5| Step: 8
Training loss: 0.6389370560646057
Validation loss: 1.762048671322484

Epoch: 5| Step: 9
Training loss: 0.7909141182899475
Validation loss: 1.7990484545307774

Epoch: 5| Step: 10
Training loss: 0.69222491979599
Validation loss: 1.779677237874718

Epoch: 667| Step: 0
Training loss: 0.5819452404975891
Validation loss: 1.7737449087122434

Epoch: 5| Step: 1
Training loss: 0.7533366084098816
Validation loss: 1.842359854329017

Epoch: 5| Step: 2
Training loss: 0.5724694728851318
Validation loss: 1.7825328560285671

Epoch: 5| Step: 3
Training loss: 0.8101728558540344
Validation loss: 1.76544943804382

Epoch: 5| Step: 4
Training loss: 0.6970717310905457
Validation loss: 1.7671677143343034

Epoch: 5| Step: 5
Training loss: 0.9379153251647949
Validation loss: 1.7698429425557454

Epoch: 5| Step: 6
Training loss: 0.8461869359016418
Validation loss: 1.7544691139651882

Epoch: 5| Step: 7
Training loss: 1.0456112623214722
Validation loss: 1.7584982661790745

Epoch: 5| Step: 8
Training loss: 0.853668212890625
Validation loss: 1.7916789311234669

Epoch: 5| Step: 9
Training loss: 1.3484399318695068
Validation loss: 1.783445781277072

Epoch: 5| Step: 10
Training loss: 0.9906541109085083
Validation loss: 1.7725386311930995

Epoch: 668| Step: 0
Training loss: 0.8368304371833801
Validation loss: 1.7012899389830969

Epoch: 5| Step: 1
Training loss: 1.2906091213226318
Validation loss: 1.780352903950599

Epoch: 5| Step: 2
Training loss: 0.7779451608657837
Validation loss: 1.7494129032217047

Epoch: 5| Step: 3
Training loss: 1.0619566440582275
Validation loss: 1.6933568485321537

Epoch: 5| Step: 4
Training loss: 0.8129615783691406
Validation loss: 1.7394138228508733

Epoch: 5| Step: 5
Training loss: 0.6393669843673706
Validation loss: 1.7469176502637966

Epoch: 5| Step: 6
Training loss: 0.8030007481575012
Validation loss: 1.7513805358640608

Epoch: 5| Step: 7
Training loss: 0.79931640625
Validation loss: 1.7658894228678879

Epoch: 5| Step: 8
Training loss: 0.837986946105957
Validation loss: 1.8296067842873194

Epoch: 5| Step: 9
Training loss: 0.7309499979019165
Validation loss: 1.8267945115284254

Epoch: 5| Step: 10
Training loss: 0.7270937561988831
Validation loss: 1.8029817137666928

Epoch: 669| Step: 0
Training loss: 0.8589423298835754
Validation loss: 1.7784836599903722

Epoch: 5| Step: 1
Training loss: 1.1995818614959717
Validation loss: 1.811365460836759

Epoch: 5| Step: 2
Training loss: 0.9491336941719055
Validation loss: 1.7034089398640457

Epoch: 5| Step: 3
Training loss: 1.0218279361724854
Validation loss: 1.787359704253494

Epoch: 5| Step: 4
Training loss: 0.7402225732803345
Validation loss: 1.7070298092339629

Epoch: 5| Step: 5
Training loss: 0.8760181665420532
Validation loss: 1.689880765894408

Epoch: 5| Step: 6
Training loss: 0.5482136011123657
Validation loss: 1.8323926656476912

Epoch: 5| Step: 7
Training loss: 0.6631595492362976
Validation loss: 1.7396501059173255

Epoch: 5| Step: 8
Training loss: 1.000840663909912
Validation loss: 1.724444789271201

Epoch: 5| Step: 9
Training loss: 0.6524264216423035
Validation loss: 1.8085603919080508

Epoch: 5| Step: 10
Training loss: 1.1338835954666138
Validation loss: 1.7431619398055538

Epoch: 670| Step: 0
Training loss: 0.6112815141677856
Validation loss: 1.7905015330160818

Epoch: 5| Step: 1
Training loss: 0.9741004705429077
Validation loss: 1.7687055962060088

Epoch: 5| Step: 2
Training loss: 1.0382649898529053
Validation loss: 1.7623091205473869

Epoch: 5| Step: 3
Training loss: 1.0403764247894287
Validation loss: 1.7843539714813232

Epoch: 5| Step: 4
Training loss: 0.9445293545722961
Validation loss: 1.7621047381431825

Epoch: 5| Step: 5
Training loss: 0.6273727416992188
Validation loss: 1.9039213195923836

Epoch: 5| Step: 6
Training loss: 1.0359363555908203
Validation loss: 1.7770340532384894

Epoch: 5| Step: 7
Training loss: 1.0110005140304565
Validation loss: 1.787214688075486

Epoch: 5| Step: 8
Training loss: 0.6767863631248474
Validation loss: 1.7588355938593547

Epoch: 5| Step: 9
Training loss: 0.7035254836082458
Validation loss: 1.7985521542128695

Epoch: 5| Step: 10
Training loss: 0.6406049132347107
Validation loss: 1.7319766847036218

Epoch: 671| Step: 0
Training loss: 0.6728722453117371
Validation loss: 1.7453103309036584

Epoch: 5| Step: 1
Training loss: 1.043592929840088
Validation loss: 1.797680700978925

Epoch: 5| Step: 2
Training loss: 0.663406491279602
Validation loss: 1.7044516583924652

Epoch: 5| Step: 3
Training loss: 0.8738929629325867
Validation loss: 1.7539927728714482

Epoch: 5| Step: 4
Training loss: 1.1649283170700073
Validation loss: 1.7511845737375238

Epoch: 5| Step: 5
Training loss: 0.9526129961013794
Validation loss: 1.7490881309714368

Epoch: 5| Step: 6
Training loss: 0.8979039192199707
Validation loss: 1.7145203941611833

Epoch: 5| Step: 7
Training loss: 0.5520976781845093
Validation loss: 1.7804425890727709

Epoch: 5| Step: 8
Training loss: 0.9831491708755493
Validation loss: 1.7619349841148622

Epoch: 5| Step: 9
Training loss: 1.0296709537506104
Validation loss: 1.7242048119985929

Epoch: 5| Step: 10
Training loss: 0.5475552678108215
Validation loss: 1.7283233814342047

Epoch: 672| Step: 0
Training loss: 0.5942106246948242
Validation loss: 1.728396725910966

Epoch: 5| Step: 1
Training loss: 0.4192446768283844
Validation loss: 1.7598145302905832

Epoch: 5| Step: 2
Training loss: 0.5367719531059265
Validation loss: 1.7400528000247093

Epoch: 5| Step: 3
Training loss: 1.324631929397583
Validation loss: 1.752930219455432

Epoch: 5| Step: 4
Training loss: 1.2116379737854004
Validation loss: 1.7926579239547893

Epoch: 5| Step: 5
Training loss: 1.093322515487671
Validation loss: 1.75556105695745

Epoch: 5| Step: 6
Training loss: 0.8007707595825195
Validation loss: 1.7299560090546966

Epoch: 5| Step: 7
Training loss: 0.9298572540283203
Validation loss: 1.7425439357757568

Epoch: 5| Step: 8
Training loss: 0.6569474339485168
Validation loss: 1.743231855412965

Epoch: 5| Step: 9
Training loss: 0.8712247610092163
Validation loss: 1.7977018561414493

Epoch: 5| Step: 10
Training loss: 0.715799868106842
Validation loss: 1.744294781838694

Epoch: 673| Step: 0
Training loss: 0.9418988227844238
Validation loss: 1.7384496145350958

Epoch: 5| Step: 1
Training loss: 1.4655563831329346
Validation loss: 1.7758528686338855

Epoch: 5| Step: 2
Training loss: 0.6672663688659668
Validation loss: 1.6707277426155664

Epoch: 5| Step: 3
Training loss: 0.5425049662590027
Validation loss: 1.7542037079411168

Epoch: 5| Step: 4
Training loss: 0.6596226692199707
Validation loss: 1.7840049856452531

Epoch: 5| Step: 5
Training loss: 0.7686349153518677
Validation loss: 1.7310849158994612

Epoch: 5| Step: 6
Training loss: 1.0782790184020996
Validation loss: 1.7848401915642522

Epoch: 5| Step: 7
Training loss: 0.5133140683174133
Validation loss: 1.759094847145901

Epoch: 5| Step: 8
Training loss: 0.9711921811103821
Validation loss: 1.7654714686896211

Epoch: 5| Step: 9
Training loss: 0.7873319387435913
Validation loss: 1.752939626734744

Epoch: 5| Step: 10
Training loss: 0.6068437099456787
Validation loss: 1.769182051381757

Epoch: 674| Step: 0
Training loss: 0.7654709219932556
Validation loss: 1.7253121688801756

Epoch: 5| Step: 1
Training loss: 1.2634764909744263
Validation loss: 1.790840341198829

Epoch: 5| Step: 2
Training loss: 0.5562914609909058
Validation loss: 1.7346024346607987

Epoch: 5| Step: 3
Training loss: 0.9706304669380188
Validation loss: 1.7390332093802832

Epoch: 5| Step: 4
Training loss: 0.9606917500495911
Validation loss: 1.7862113060489777

Epoch: 5| Step: 5
Training loss: 0.9928687810897827
Validation loss: 1.7576321273721673

Epoch: 5| Step: 6
Training loss: 0.7372987270355225
Validation loss: 1.7233592143622778

Epoch: 5| Step: 7
Training loss: 0.7859864234924316
Validation loss: 1.808373458923832

Epoch: 5| Step: 8
Training loss: 0.8344650268554688
Validation loss: 1.763034059155372

Epoch: 5| Step: 9
Training loss: 0.8248437643051147
Validation loss: 1.7613097954821844

Epoch: 5| Step: 10
Training loss: 0.6839499473571777
Validation loss: 1.7424087332141014

Epoch: 675| Step: 0
Training loss: 0.7038992047309875
Validation loss: 1.7899494812052736

Epoch: 5| Step: 1
Training loss: 0.5576133728027344
Validation loss: 1.7702144551020798

Epoch: 5| Step: 2
Training loss: 0.6911746263504028
Validation loss: 1.750529553300591

Epoch: 5| Step: 3
Training loss: 0.9946260452270508
Validation loss: 1.7752991543021253

Epoch: 5| Step: 4
Training loss: 1.1210994720458984
Validation loss: 1.796811685767225

Epoch: 5| Step: 5
Training loss: 0.923815906047821
Validation loss: 1.7185764569108204

Epoch: 5| Step: 6
Training loss: 0.35247382521629333
Validation loss: 1.732829963007281

Epoch: 5| Step: 7
Training loss: 0.9742500185966492
Validation loss: 1.737684255005211

Epoch: 5| Step: 8
Training loss: 0.8260642290115356
Validation loss: 1.732371171315511

Epoch: 5| Step: 9
Training loss: 0.7434700131416321
Validation loss: 1.7738921949940343

Epoch: 5| Step: 10
Training loss: 1.1197091341018677
Validation loss: 1.775910767175818

Epoch: 676| Step: 0
Training loss: 0.7837570905685425
Validation loss: 1.7919802127345916

Epoch: 5| Step: 1
Training loss: 0.8461798429489136
Validation loss: 1.7181869270980998

Epoch: 5| Step: 2
Training loss: 1.116687297821045
Validation loss: 1.7452219211927025

Epoch: 5| Step: 3
Training loss: 0.8672140836715698
Validation loss: 1.6961879396951327

Epoch: 5| Step: 4
Training loss: 0.7610028386116028
Validation loss: 1.7336876700001378

Epoch: 5| Step: 5
Training loss: 0.6733861565589905
Validation loss: 1.7445138154491302

Epoch: 5| Step: 6
Training loss: 0.8897367715835571
Validation loss: 1.7309707262182747

Epoch: 5| Step: 7
Training loss: 1.139284372329712
Validation loss: 1.7068616779901649

Epoch: 5| Step: 8
Training loss: 0.6223775744438171
Validation loss: 1.7138636221167862

Epoch: 5| Step: 9
Training loss: 0.8790394067764282
Validation loss: 1.7603426005250664

Epoch: 5| Step: 10
Training loss: 0.5412238836288452
Validation loss: 1.7615943108835528

Epoch: 677| Step: 0
Training loss: 0.8765101432800293
Validation loss: 1.763535907191615

Epoch: 5| Step: 1
Training loss: 0.7666915059089661
Validation loss: 1.7491288928575413

Epoch: 5| Step: 2
Training loss: 0.424846887588501
Validation loss: 1.7889613977042578

Epoch: 5| Step: 3
Training loss: 1.0263670682907104
Validation loss: 1.72418850211687

Epoch: 5| Step: 4
Training loss: 0.5509790182113647
Validation loss: 1.731749689707192

Epoch: 5| Step: 5
Training loss: 1.0124340057373047
Validation loss: 1.7679473623152702

Epoch: 5| Step: 6
Training loss: 0.8888416290283203
Validation loss: 1.7078013189377323

Epoch: 5| Step: 7
Training loss: 0.8923152685165405
Validation loss: 1.7281484309063162

Epoch: 5| Step: 8
Training loss: 1.2920057773590088
Validation loss: 1.7587862655680666

Epoch: 5| Step: 9
Training loss: 0.7827629446983337
Validation loss: 1.7738262799478346

Epoch: 5| Step: 10
Training loss: 0.5164148211479187
Validation loss: 1.740218900865124

Epoch: 678| Step: 0
Training loss: 0.9052976369857788
Validation loss: 1.7035605727985341

Epoch: 5| Step: 1
Training loss: 0.7376691699028015
Validation loss: 1.7791134900944208

Epoch: 5| Step: 2
Training loss: 1.6524394750595093
Validation loss: 1.7822875258743123

Epoch: 5| Step: 3
Training loss: 0.9453447461128235
Validation loss: 1.719083636037765

Epoch: 5| Step: 4
Training loss: 0.5458416938781738
Validation loss: 1.7340536579009025

Epoch: 5| Step: 5
Training loss: 0.9911915063858032
Validation loss: 1.7410186670159782

Epoch: 5| Step: 6
Training loss: 0.6659596562385559
Validation loss: 1.7506518184497792

Epoch: 5| Step: 7
Training loss: 0.6138831377029419
Validation loss: 1.734773543573195

Epoch: 5| Step: 8
Training loss: 0.7830277681350708
Validation loss: 1.7635004751143917

Epoch: 5| Step: 9
Training loss: 0.5305353999137878
Validation loss: 1.747362930287597

Epoch: 5| Step: 10
Training loss: 0.6345672607421875
Validation loss: 1.7227502804930492

Epoch: 679| Step: 0
Training loss: 1.0364868640899658
Validation loss: 1.7307739360358125

Epoch: 5| Step: 1
Training loss: 0.7671977281570435
Validation loss: 1.7759653009394163

Epoch: 5| Step: 2
Training loss: 0.9891362190246582
Validation loss: 1.724644737858926

Epoch: 5| Step: 3
Training loss: 0.6879643201828003
Validation loss: 1.7481264119507165

Epoch: 5| Step: 4
Training loss: 0.8285285830497742
Validation loss: 1.7359963668290006

Epoch: 5| Step: 5
Training loss: 0.9079998135566711
Validation loss: 1.7541902526732414

Epoch: 5| Step: 6
Training loss: 0.8114811182022095
Validation loss: 1.7563190319204842

Epoch: 5| Step: 7
Training loss: 0.8656989336013794
Validation loss: 1.7635395373067548

Epoch: 5| Step: 8
Training loss: 0.7771930694580078
Validation loss: 1.8022512344903843

Epoch: 5| Step: 9
Training loss: 0.7057399153709412
Validation loss: 1.7982443673636324

Epoch: 5| Step: 10
Training loss: 0.873855710029602
Validation loss: 1.796871199402758

Epoch: 680| Step: 0
Training loss: 0.8198751211166382
Validation loss: 1.723843365587214

Epoch: 5| Step: 1
Training loss: 0.6350910067558289
Validation loss: 1.7239130286760227

Epoch: 5| Step: 2
Training loss: 1.1244897842407227
Validation loss: 1.7724608836635467

Epoch: 5| Step: 3
Training loss: 0.5277713537216187
Validation loss: 1.7391592597448697

Epoch: 5| Step: 4
Training loss: 1.0887259244918823
Validation loss: 1.714335310843683

Epoch: 5| Step: 5
Training loss: 0.8088697195053101
Validation loss: 1.7621660386362383

Epoch: 5| Step: 6
Training loss: 1.159919261932373
Validation loss: 1.7958049389623827

Epoch: 5| Step: 7
Training loss: 0.7298412322998047
Validation loss: 1.8027015091270528

Epoch: 5| Step: 8
Training loss: 0.8598140478134155
Validation loss: 1.7494349261765838

Epoch: 5| Step: 9
Training loss: 0.6603981852531433
Validation loss: 1.8149118179916053

Epoch: 5| Step: 10
Training loss: 0.6920667290687561
Validation loss: 1.7497480902620541

Epoch: 681| Step: 0
Training loss: 0.8616119623184204
Validation loss: 1.7988054034530476

Epoch: 5| Step: 1
Training loss: 1.0383577346801758
Validation loss: 1.6919883963882283

Epoch: 5| Step: 2
Training loss: 0.9153637886047363
Validation loss: 1.721948613402664

Epoch: 5| Step: 3
Training loss: 0.578726589679718
Validation loss: 1.7453041563751877

Epoch: 5| Step: 4
Training loss: 0.9531537294387817
Validation loss: 1.7558863675722511

Epoch: 5| Step: 5
Training loss: 0.4047018885612488
Validation loss: 1.740336407897293

Epoch: 5| Step: 6
Training loss: 0.7125455737113953
Validation loss: 1.7405953548287834

Epoch: 5| Step: 7
Training loss: 1.0218772888183594
Validation loss: 1.7802609730792303

Epoch: 5| Step: 8
Training loss: 0.8460363149642944
Validation loss: 1.708361570553113

Epoch: 5| Step: 9
Training loss: 0.9330803751945496
Validation loss: 1.7643215605007705

Epoch: 5| Step: 10
Training loss: 0.5699126720428467
Validation loss: 1.8024827818716727

Epoch: 682| Step: 0
Training loss: 1.07351815700531
Validation loss: 1.7130989977108535

Epoch: 5| Step: 1
Training loss: 0.8656355738639832
Validation loss: 1.7504407193071099

Epoch: 5| Step: 2
Training loss: 0.7245761156082153
Validation loss: 1.7507537770014938

Epoch: 5| Step: 3
Training loss: 0.9300419688224792
Validation loss: 1.73647698151168

Epoch: 5| Step: 4
Training loss: 0.4021584391593933
Validation loss: 1.7728110141651605

Epoch: 5| Step: 5
Training loss: 0.6333269476890564
Validation loss: 1.7913537820180256

Epoch: 5| Step: 6
Training loss: 0.6704573035240173
Validation loss: 1.7771181060421852

Epoch: 5| Step: 7
Training loss: 0.93946772813797
Validation loss: 1.7548586873597996

Epoch: 5| Step: 8
Training loss: 0.7997428178787231
Validation loss: 1.7590202259761032

Epoch: 5| Step: 9
Training loss: 0.9182088971138
Validation loss: 1.7412403924490816

Epoch: 5| Step: 10
Training loss: 0.7061107754707336
Validation loss: 1.7269503762645106

Epoch: 683| Step: 0
Training loss: 0.9712575078010559
Validation loss: 1.7822594796457598

Epoch: 5| Step: 1
Training loss: 0.9386606216430664
Validation loss: 1.7523773421523392

Epoch: 5| Step: 2
Training loss: 0.8371755480766296
Validation loss: 1.7021601046285322

Epoch: 5| Step: 3
Training loss: 0.5685232877731323
Validation loss: 1.721188146580932

Epoch: 5| Step: 4
Training loss: 0.637551486492157
Validation loss: 1.8061971959247385

Epoch: 5| Step: 5
Training loss: 1.1688753366470337
Validation loss: 1.7179332394753732

Epoch: 5| Step: 6
Training loss: 0.7231429219245911
Validation loss: 1.7363362927590646

Epoch: 5| Step: 7
Training loss: 0.682679295539856
Validation loss: 1.7183648027399534

Epoch: 5| Step: 8
Training loss: 0.8820730447769165
Validation loss: 1.753642802597374

Epoch: 5| Step: 9
Training loss: 1.0272860527038574
Validation loss: 1.7637153389633342

Epoch: 5| Step: 10
Training loss: 0.5272303223609924
Validation loss: 1.7308000396656733

Epoch: 684| Step: 0
Training loss: 0.7130447030067444
Validation loss: 1.7434030245709162

Epoch: 5| Step: 1
Training loss: 1.0178526639938354
Validation loss: 1.6981285643833939

Epoch: 5| Step: 2
Training loss: 0.7222645282745361
Validation loss: 1.7289610408967542

Epoch: 5| Step: 3
Training loss: 0.6791827082633972
Validation loss: 1.7598257141728555

Epoch: 5| Step: 4
Training loss: 1.2572101354599
Validation loss: 1.7636075224927676

Epoch: 5| Step: 5
Training loss: 0.7195786833763123
Validation loss: 1.826691060937861

Epoch: 5| Step: 6
Training loss: 0.836288332939148
Validation loss: 1.7303846715598978

Epoch: 5| Step: 7
Training loss: 0.8322202563285828
Validation loss: 1.738457973285388

Epoch: 5| Step: 8
Training loss: 1.0003554821014404
Validation loss: 1.7715606484361874

Epoch: 5| Step: 9
Training loss: 0.7319172620773315
Validation loss: 1.7621484700069632

Epoch: 5| Step: 10
Training loss: 0.8229027986526489
Validation loss: 1.7412552910466348

Epoch: 685| Step: 0
Training loss: 0.8736101388931274
Validation loss: 1.7344900292734946

Epoch: 5| Step: 1
Training loss: 0.5986760854721069
Validation loss: 1.7479722384483583

Epoch: 5| Step: 2
Training loss: 0.6845620274543762
Validation loss: 1.7131589074288645

Epoch: 5| Step: 3
Training loss: 1.034610390663147
Validation loss: 1.7611599532506799

Epoch: 5| Step: 4
Training loss: 0.892569899559021
Validation loss: 1.7718639501961329

Epoch: 5| Step: 5
Training loss: 0.91917484998703
Validation loss: 1.7381943554006598

Epoch: 5| Step: 6
Training loss: 0.7713227868080139
Validation loss: 1.744308429379617

Epoch: 5| Step: 7
Training loss: 0.6413713693618774
Validation loss: 1.7250263806312316

Epoch: 5| Step: 8
Training loss: 0.9268268346786499
Validation loss: 1.7655117434840049

Epoch: 5| Step: 9
Training loss: 0.8303686380386353
Validation loss: 1.747719664727488

Epoch: 5| Step: 10
Training loss: 0.8616999983787537
Validation loss: 1.7406016652302077

Epoch: 686| Step: 0
Training loss: 1.1851565837860107
Validation loss: 1.7690857712940504

Epoch: 5| Step: 1
Training loss: 0.7059428095817566
Validation loss: 1.690090863935409

Epoch: 5| Step: 2
Training loss: 0.5292651653289795
Validation loss: 1.7579441275647891

Epoch: 5| Step: 3
Training loss: 0.539687991142273
Validation loss: 1.7979692553961149

Epoch: 5| Step: 4
Training loss: 0.5655517578125
Validation loss: 1.7991759033613308

Epoch: 5| Step: 5
Training loss: 0.7175675630569458
Validation loss: 1.7864906787872314

Epoch: 5| Step: 6
Training loss: 0.7424672245979309
Validation loss: 1.7483528993463004

Epoch: 5| Step: 7
Training loss: 1.2101507186889648
Validation loss: 1.7241372805769726

Epoch: 5| Step: 8
Training loss: 0.9174572229385376
Validation loss: 1.7820754525482014

Epoch: 5| Step: 9
Training loss: 1.1067206859588623
Validation loss: 1.737922691529797

Epoch: 5| Step: 10
Training loss: 0.8750284314155579
Validation loss: 1.7498598457664571

Epoch: 687| Step: 0
Training loss: 0.8660802841186523
Validation loss: 1.768891110215136

Epoch: 5| Step: 1
Training loss: 0.5668596029281616
Validation loss: 1.7370971056722826

Epoch: 5| Step: 2
Training loss: 0.7718271613121033
Validation loss: 1.7389914425470496

Epoch: 5| Step: 3
Training loss: 0.6700313091278076
Validation loss: 1.772755838209583

Epoch: 5| Step: 4
Training loss: 0.926937460899353
Validation loss: 1.8382861870591358

Epoch: 5| Step: 5
Training loss: 0.8128083944320679
Validation loss: 1.7784400806632092

Epoch: 5| Step: 6
Training loss: 1.0813524723052979
Validation loss: 1.7686835527420044

Epoch: 5| Step: 7
Training loss: 0.768012523651123
Validation loss: 1.7503688668691983

Epoch: 5| Step: 8
Training loss: 0.7466748356819153
Validation loss: 1.7871486756109423

Epoch: 5| Step: 9
Training loss: 0.746066689491272
Validation loss: 1.7427880840916787

Epoch: 5| Step: 10
Training loss: 0.6340904235839844
Validation loss: 1.7206411759058635

Epoch: 688| Step: 0
Training loss: 0.9151291847229004
Validation loss: 1.702585207518711

Epoch: 5| Step: 1
Training loss: 0.8496575355529785
Validation loss: 1.7593484860594555

Epoch: 5| Step: 2
Training loss: 1.2032874822616577
Validation loss: 1.7796317146670433

Epoch: 5| Step: 3
Training loss: 0.8127816915512085
Validation loss: 1.710969009707051

Epoch: 5| Step: 4
Training loss: 0.7850230932235718
Validation loss: 1.7196098245600218

Epoch: 5| Step: 5
Training loss: 0.6415296792984009
Validation loss: 1.6897753618096794

Epoch: 5| Step: 6
Training loss: 0.8089512586593628
Validation loss: 1.7264155482733121

Epoch: 5| Step: 7
Training loss: 1.0667576789855957
Validation loss: 1.758742343994879

Epoch: 5| Step: 8
Training loss: 0.4414800703525543
Validation loss: 1.7110848221727597

Epoch: 5| Step: 9
Training loss: 0.7347107529640198
Validation loss: 1.6945796333333498

Epoch: 5| Step: 10
Training loss: 0.7563864588737488
Validation loss: 1.76509944341516

Epoch: 689| Step: 0
Training loss: 0.6666649580001831
Validation loss: 1.8254005344965125

Epoch: 5| Step: 1
Training loss: 0.7365096211433411
Validation loss: 1.7811163266499836

Epoch: 5| Step: 2
Training loss: 0.49935832619667053
Validation loss: 1.8117262419833933

Epoch: 5| Step: 3
Training loss: 0.7409151196479797
Validation loss: 1.8330945020080895

Epoch: 5| Step: 4
Training loss: 0.6383196711540222
Validation loss: 1.7433398436474543

Epoch: 5| Step: 5
Training loss: 0.9773606061935425
Validation loss: 1.822866944856541

Epoch: 5| Step: 6
Training loss: 1.0819686651229858
Validation loss: 1.7022492244679441

Epoch: 5| Step: 7
Training loss: 1.313531756401062
Validation loss: 1.7980416846531693

Epoch: 5| Step: 8
Training loss: 0.7904494404792786
Validation loss: 1.7348179394199001

Epoch: 5| Step: 9
Training loss: 0.6678018569946289
Validation loss: 1.755729917557009

Epoch: 5| Step: 10
Training loss: 0.6970100402832031
Validation loss: 1.775356928507487

Epoch: 690| Step: 0
Training loss: 0.8130601048469543
Validation loss: 1.7500299843408729

Epoch: 5| Step: 1
Training loss: 0.7547308206558228
Validation loss: 1.7113184134165447

Epoch: 5| Step: 2
Training loss: 0.8815776705741882
Validation loss: 1.7332980453327138

Epoch: 5| Step: 3
Training loss: 0.614319920539856
Validation loss: 1.7395588069833734

Epoch: 5| Step: 4
Training loss: 0.7323074340820312
Validation loss: 1.7121543474094842

Epoch: 5| Step: 5
Training loss: 0.8468648791313171
Validation loss: 1.772040892672795

Epoch: 5| Step: 6
Training loss: 0.970088005065918
Validation loss: 1.7694675460938485

Epoch: 5| Step: 7
Training loss: 0.8744243383407593
Validation loss: 1.765653952475517

Epoch: 5| Step: 8
Training loss: 0.7432292699813843
Validation loss: 1.8014219063584522

Epoch: 5| Step: 9
Training loss: 0.8263023495674133
Validation loss: 1.778667913970127

Epoch: 5| Step: 10
Training loss: 0.8322502374649048
Validation loss: 1.755437042123528

Epoch: 691| Step: 0
Training loss: 0.5724256038665771
Validation loss: 1.792978952007909

Epoch: 5| Step: 1
Training loss: 0.599513053894043
Validation loss: 1.78993405577957

Epoch: 5| Step: 2
Training loss: 0.650184690952301
Validation loss: 1.7663198312123616

Epoch: 5| Step: 3
Training loss: 0.4474433362483978
Validation loss: 1.761348670528781

Epoch: 5| Step: 4
Training loss: 1.0718085765838623
Validation loss: 1.7506225609010266

Epoch: 5| Step: 5
Training loss: 0.7685017585754395
Validation loss: 1.7397739976964972

Epoch: 5| Step: 6
Training loss: 1.2312920093536377
Validation loss: 1.7786894908515356

Epoch: 5| Step: 7
Training loss: 0.8311691284179688
Validation loss: 1.7491943426029657

Epoch: 5| Step: 8
Training loss: 0.9095016717910767
Validation loss: 1.708039435007239

Epoch: 5| Step: 9
Training loss: 0.9341033697128296
Validation loss: 1.7806911122414373

Epoch: 5| Step: 10
Training loss: 0.5404862761497498
Validation loss: 1.6941658950621081

Epoch: 692| Step: 0
Training loss: 0.6761684417724609
Validation loss: 1.776255976769232

Epoch: 5| Step: 1
Training loss: 1.2703460454940796
Validation loss: 1.804413696771027

Epoch: 5| Step: 2
Training loss: 0.6654235124588013
Validation loss: 1.8043009555467995

Epoch: 5| Step: 3
Training loss: 0.6535965800285339
Validation loss: 1.7660304487392466

Epoch: 5| Step: 4
Training loss: 0.8082521557807922
Validation loss: 1.7187603622354486

Epoch: 5| Step: 5
Training loss: 0.8865979313850403
Validation loss: 1.6755361390370194

Epoch: 5| Step: 6
Training loss: 1.2036157846450806
Validation loss: 1.7608634759021062

Epoch: 5| Step: 7
Training loss: 0.5358520746231079
Validation loss: 1.7676392242472658

Epoch: 5| Step: 8
Training loss: 0.8657742738723755
Validation loss: 1.7944150560645646

Epoch: 5| Step: 9
Training loss: 0.795576274394989
Validation loss: 1.775393198895198

Epoch: 5| Step: 10
Training loss: 0.5281549096107483
Validation loss: 1.763537778649279

Epoch: 693| Step: 0
Training loss: 1.0704764127731323
Validation loss: 1.8204825744833997

Epoch: 5| Step: 1
Training loss: 1.047553300857544
Validation loss: 1.7875923008047125

Epoch: 5| Step: 2
Training loss: 0.8065788149833679
Validation loss: 1.8511728625143729

Epoch: 5| Step: 3
Training loss: 1.2942357063293457
Validation loss: 1.771074773162924

Epoch: 5| Step: 4
Training loss: 0.8424445986747742
Validation loss: 1.841643617999169

Epoch: 5| Step: 5
Training loss: 0.550169050693512
Validation loss: 1.7577240185071064

Epoch: 5| Step: 6
Training loss: 0.8043972253799438
Validation loss: 1.761871289181453

Epoch: 5| Step: 7
Training loss: 0.6495221853256226
Validation loss: 1.7456749331566594

Epoch: 5| Step: 8
Training loss: 1.0590367317199707
Validation loss: 1.6953493318250101

Epoch: 5| Step: 9
Training loss: 0.4152103364467621
Validation loss: 1.7058689145631687

Epoch: 5| Step: 10
Training loss: 0.5751489400863647
Validation loss: 1.719603616704223

Epoch: 694| Step: 0
Training loss: 0.9800592660903931
Validation loss: 1.748034897670951

Epoch: 5| Step: 1
Training loss: 0.5450550317764282
Validation loss: 1.7847820058945687

Epoch: 5| Step: 2
Training loss: 0.7115170359611511
Validation loss: 1.7762125615150697

Epoch: 5| Step: 3
Training loss: 0.5880843997001648
Validation loss: 1.7581836997821767

Epoch: 5| Step: 4
Training loss: 0.8405765295028687
Validation loss: 1.6906615021408244

Epoch: 5| Step: 5
Training loss: 0.988854706287384
Validation loss: 1.8041179846691828

Epoch: 5| Step: 6
Training loss: 0.6011096835136414
Validation loss: 1.6910912708569599

Epoch: 5| Step: 7
Training loss: 1.191341519355774
Validation loss: 1.7632174491882324

Epoch: 5| Step: 8
Training loss: 0.735767662525177
Validation loss: 1.765857300450725

Epoch: 5| Step: 9
Training loss: 1.0296366214752197
Validation loss: 1.732645861564144

Epoch: 5| Step: 10
Training loss: 0.4775432050228119
Validation loss: 1.754221514988971

Epoch: 695| Step: 0
Training loss: 0.8072578310966492
Validation loss: 1.758569057269763

Epoch: 5| Step: 1
Training loss: 0.7908177375793457
Validation loss: 1.7048921021082069

Epoch: 5| Step: 2
Training loss: 0.48463305830955505
Validation loss: 1.8025882346655733

Epoch: 5| Step: 3
Training loss: 0.9001197814941406
Validation loss: 1.7473237540132256

Epoch: 5| Step: 4
Training loss: 0.7888083457946777
Validation loss: 1.789882247165967

Epoch: 5| Step: 5
Training loss: 1.0865209102630615
Validation loss: 1.768899906066156

Epoch: 5| Step: 6
Training loss: 0.643842339515686
Validation loss: 1.8140557401923723

Epoch: 5| Step: 7
Training loss: 0.5045989155769348
Validation loss: 1.7673856622429305

Epoch: 5| Step: 8
Training loss: 0.8917881846427917
Validation loss: 1.8108661854138939

Epoch: 5| Step: 9
Training loss: 1.130839228630066
Validation loss: 1.7108879807174846

Epoch: 5| Step: 10
Training loss: 0.5501503944396973
Validation loss: 1.7463408106116838

Epoch: 696| Step: 0
Training loss: 0.5229463577270508
Validation loss: 1.7542988959179129

Epoch: 5| Step: 1
Training loss: 0.3251028060913086
Validation loss: 1.6934031312183668

Epoch: 5| Step: 2
Training loss: 0.5763365626335144
Validation loss: 1.758283188266139

Epoch: 5| Step: 3
Training loss: 0.4509045481681824
Validation loss: 1.6778422799161685

Epoch: 5| Step: 4
Training loss: 0.9047037363052368
Validation loss: 1.7374660545779812

Epoch: 5| Step: 5
Training loss: 0.613268256187439
Validation loss: 1.79934165939208

Epoch: 5| Step: 6
Training loss: 0.9428657293319702
Validation loss: 1.7426871561234998

Epoch: 5| Step: 7
Training loss: 0.8312692642211914
Validation loss: 1.716057820986676

Epoch: 5| Step: 8
Training loss: 0.8275243639945984
Validation loss: 1.7388314649622927

Epoch: 5| Step: 9
Training loss: 1.1494638919830322
Validation loss: 1.7772667689989972

Epoch: 5| Step: 10
Training loss: 1.1964657306671143
Validation loss: 1.8555698305047967

Epoch: 697| Step: 0
Training loss: 0.8187739253044128
Validation loss: 1.8415257700027958

Epoch: 5| Step: 1
Training loss: 0.763422429561615
Validation loss: 1.7644836620617939

Epoch: 5| Step: 2
Training loss: 0.6992241144180298
Validation loss: 1.7887369099483694

Epoch: 5| Step: 3
Training loss: 1.0689564943313599
Validation loss: 1.8033653587423346

Epoch: 5| Step: 4
Training loss: 0.8095817565917969
Validation loss: 1.8395222028096516

Epoch: 5| Step: 5
Training loss: 0.7105289101600647
Validation loss: 1.7925119451297227

Epoch: 5| Step: 6
Training loss: 0.9677382707595825
Validation loss: 1.7869910911847187

Epoch: 5| Step: 7
Training loss: 0.8575448989868164
Validation loss: 1.7731481264996272

Epoch: 5| Step: 8
Training loss: 0.6168409585952759
Validation loss: 1.8175875166411042

Epoch: 5| Step: 9
Training loss: 0.7114256620407104
Validation loss: 1.7696162705780358

Epoch: 5| Step: 10
Training loss: 0.617171585559845
Validation loss: 1.7633588032055927

Epoch: 698| Step: 0
Training loss: 0.6724432706832886
Validation loss: 1.713591089812658

Epoch: 5| Step: 1
Training loss: 0.8429546356201172
Validation loss: 1.7320376775598014

Epoch: 5| Step: 2
Training loss: 0.7927308082580566
Validation loss: 1.7304226454868112

Epoch: 5| Step: 3
Training loss: 0.5394585728645325
Validation loss: 1.743038700472924

Epoch: 5| Step: 4
Training loss: 0.5960808992385864
Validation loss: 1.7309932144739295

Epoch: 5| Step: 5
Training loss: 0.9522018432617188
Validation loss: 1.724773269827648

Epoch: 5| Step: 6
Training loss: 0.7485209703445435
Validation loss: 1.7849613287115609

Epoch: 5| Step: 7
Training loss: 0.4550681710243225
Validation loss: 1.8043569390491774

Epoch: 5| Step: 8
Training loss: 1.0378834009170532
Validation loss: 1.6923671653193813

Epoch: 5| Step: 9
Training loss: 1.1407480239868164
Validation loss: 1.7465198860373548

Epoch: 5| Step: 10
Training loss: 0.8553450703620911
Validation loss: 1.768432194186795

Epoch: 699| Step: 0
Training loss: 1.1505372524261475
Validation loss: 1.7870837962755592

Epoch: 5| Step: 1
Training loss: 0.929262638092041
Validation loss: 1.7513009873769616

Epoch: 5| Step: 2
Training loss: 0.833094596862793
Validation loss: 1.7475497684171122

Epoch: 5| Step: 3
Training loss: 0.6108702421188354
Validation loss: 1.7652216496006135

Epoch: 5| Step: 4
Training loss: 0.8404723405838013
Validation loss: 1.751234809557597

Epoch: 5| Step: 5
Training loss: 0.41095131635665894
Validation loss: 1.8143757645801832

Epoch: 5| Step: 6
Training loss: 0.493114173412323
Validation loss: 1.7258504744498961

Epoch: 5| Step: 7
Training loss: 0.5085785388946533
Validation loss: 1.7639425108509679

Epoch: 5| Step: 8
Training loss: 0.8739389181137085
Validation loss: 1.7215205187438636

Epoch: 5| Step: 9
Training loss: 0.8506889343261719
Validation loss: 1.746684035947246

Epoch: 5| Step: 10
Training loss: 0.7819005250930786
Validation loss: 1.7137007982500139

Epoch: 700| Step: 0
Training loss: 0.4884265065193176
Validation loss: 1.740426189155989

Epoch: 5| Step: 1
Training loss: 0.7853623032569885
Validation loss: 1.7032543343882407

Epoch: 5| Step: 2
Training loss: 1.0110175609588623
Validation loss: 1.7443142757620862

Epoch: 5| Step: 3
Training loss: 0.44672703742980957
Validation loss: 1.7830776322272517

Epoch: 5| Step: 4
Training loss: 0.7941937446594238
Validation loss: 1.7093329916718185

Epoch: 5| Step: 5
Training loss: 1.0704345703125
Validation loss: 1.678705152644906

Epoch: 5| Step: 6
Training loss: 0.8251402974128723
Validation loss: 1.7659617367611136

Epoch: 5| Step: 7
Training loss: 0.7027431726455688
Validation loss: 1.8279752615959413

Epoch: 5| Step: 8
Training loss: 0.7923797369003296
Validation loss: 1.7462213295762257

Epoch: 5| Step: 9
Training loss: 0.6933056712150574
Validation loss: 1.820818631879745

Epoch: 5| Step: 10
Training loss: 1.0464805364608765
Validation loss: 1.8454030867545836

Testing loss: 2.2953555054134793
