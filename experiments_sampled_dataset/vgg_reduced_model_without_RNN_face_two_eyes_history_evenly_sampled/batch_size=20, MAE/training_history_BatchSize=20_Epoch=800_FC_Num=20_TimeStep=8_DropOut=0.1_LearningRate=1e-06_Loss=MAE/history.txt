Epoch: 1| Step: 0
Training loss: 5.472876071929932
Validation loss: 5.5530225846075245

Epoch: 5| Step: 1
Training loss: 5.198535919189453
Validation loss: 5.547594490871634

Epoch: 5| Step: 2
Training loss: 5.067744255065918
Validation loss: 5.537755443203833

Epoch: 5| Step: 3
Training loss: 4.3587822914123535
Validation loss: 5.5338359545635925

Epoch: 5| Step: 4
Training loss: 5.436291694641113
Validation loss: 5.526748882826938

Epoch: 5| Step: 5
Training loss: 5.3939337730407715
Validation loss: 5.521492573522752

Epoch: 5| Step: 6
Training loss: 5.607030391693115
Validation loss: 5.5119315526818715

Epoch: 5| Step: 7
Training loss: 6.122506618499756
Validation loss: 5.506470100854033

Epoch: 5| Step: 8
Training loss: 5.510585784912109
Validation loss: 5.498612506415254

Epoch: 5| Step: 9
Training loss: 5.564154148101807
Validation loss: 5.494656588441583

Epoch: 5| Step: 10
Training loss: 4.653625965118408
Validation loss: 5.484812464765323

Epoch: 2| Step: 0
Training loss: 4.522285461425781
Validation loss: 5.477649283665483

Epoch: 5| Step: 1
Training loss: 5.488384246826172
Validation loss: 5.473951672994962

Epoch: 5| Step: 2
Training loss: 4.2279767990112305
Validation loss: 5.4662712415059405

Epoch: 5| Step: 3
Training loss: 6.1628546714782715
Validation loss: 5.460996858535275

Epoch: 5| Step: 4
Training loss: 6.3549323081970215
Validation loss: 5.454802969450592

Epoch: 5| Step: 5
Training loss: 4.374510288238525
Validation loss: 5.449682892009776

Epoch: 5| Step: 6
Training loss: 5.239185810089111
Validation loss: 5.4400558728043755

Epoch: 5| Step: 7
Training loss: 5.429433345794678
Validation loss: 5.433016730893042

Epoch: 5| Step: 8
Training loss: 4.87572717666626
Validation loss: 5.428083173690304

Epoch: 5| Step: 9
Training loss: 5.982173919677734
Validation loss: 5.42292732320806

Epoch: 5| Step: 10
Training loss: 4.971468448638916
Validation loss: 5.415212410752491

Epoch: 3| Step: 0
Training loss: 4.126565933227539
Validation loss: 5.410534453648393

Epoch: 5| Step: 1
Training loss: 6.724229335784912
Validation loss: 5.406204767124628

Epoch: 5| Step: 2
Training loss: 4.342677593231201
Validation loss: 5.399768711418234

Epoch: 5| Step: 3
Training loss: 5.867369174957275
Validation loss: 5.394539412631784

Epoch: 5| Step: 4
Training loss: 5.09560489654541
Validation loss: 5.387489288083969

Epoch: 5| Step: 5
Training loss: 6.405114650726318
Validation loss: 5.382006440111386

Epoch: 5| Step: 6
Training loss: 4.983305931091309
Validation loss: 5.373283334957656

Epoch: 5| Step: 7
Training loss: 4.571581840515137
Validation loss: 5.372215973433628

Epoch: 5| Step: 8
Training loss: 6.009619235992432
Validation loss: 5.362510132533248

Epoch: 5| Step: 9
Training loss: 3.5771865844726562
Validation loss: 5.35878667523784

Epoch: 5| Step: 10
Training loss: 5.211670398712158
Validation loss: 5.351293204933085

Epoch: 4| Step: 0
Training loss: 5.83349084854126
Validation loss: 5.345443074421216

Epoch: 5| Step: 1
Training loss: 5.022935390472412
Validation loss: 5.339550218274517

Epoch: 5| Step: 2
Training loss: 5.002163410186768
Validation loss: 5.3321208236038045

Epoch: 5| Step: 3
Training loss: 5.893213748931885
Validation loss: 5.325957031660183

Epoch: 5| Step: 4
Training loss: 5.1161065101623535
Validation loss: 5.3218856626941315

Epoch: 5| Step: 5
Training loss: 5.701742172241211
Validation loss: 5.316018068662253

Epoch: 5| Step: 6
Training loss: 4.4707746505737305
Validation loss: 5.308045053994784

Epoch: 5| Step: 7
Training loss: 4.218743801116943
Validation loss: 5.302407936383319

Epoch: 5| Step: 8
Training loss: 5.04023551940918
Validation loss: 5.294805865133962

Epoch: 5| Step: 9
Training loss: 4.652420997619629
Validation loss: 5.28583275887274

Epoch: 5| Step: 10
Training loss: 5.21840763092041
Validation loss: 5.280099581646663

Epoch: 5| Step: 0
Training loss: 5.833765983581543
Validation loss: 5.274414047118156

Epoch: 5| Step: 1
Training loss: 4.433316707611084
Validation loss: 5.268162727355957

Epoch: 5| Step: 2
Training loss: 4.312569618225098
Validation loss: 5.261452551810972

Epoch: 5| Step: 3
Training loss: 5.169386863708496
Validation loss: 5.251941562980734

Epoch: 5| Step: 4
Training loss: 5.15623664855957
Validation loss: 5.245354175567627

Epoch: 5| Step: 5
Training loss: 3.937868595123291
Validation loss: 5.237446287626861

Epoch: 5| Step: 6
Training loss: 6.386274337768555
Validation loss: 5.231563491206015

Epoch: 5| Step: 7
Training loss: 4.926783561706543
Validation loss: 5.222470519363239

Epoch: 5| Step: 8
Training loss: 5.362527370452881
Validation loss: 5.2170066166949525

Epoch: 5| Step: 9
Training loss: 4.474390506744385
Validation loss: 5.207690028734104

Epoch: 5| Step: 10
Training loss: 5.3568525314331055
Validation loss: 5.201745756210819

Epoch: 6| Step: 0
Training loss: 4.383913993835449
Validation loss: 5.193838519434775

Epoch: 5| Step: 1
Training loss: 4.4794020652771
Validation loss: 5.187327277275823

Epoch: 5| Step: 2
Training loss: 4.453676700592041
Validation loss: 5.176742933129751

Epoch: 5| Step: 3
Training loss: 5.121002674102783
Validation loss: 5.168640116209625

Epoch: 5| Step: 4
Training loss: 5.478479385375977
Validation loss: 5.1614228833106255

Epoch: 5| Step: 5
Training loss: 5.116632461547852
Validation loss: 5.153082919377153

Epoch: 5| Step: 6
Training loss: 4.080998420715332
Validation loss: 5.145976825426984

Epoch: 5| Step: 7
Training loss: 4.82618522644043
Validation loss: 5.13472645257109

Epoch: 5| Step: 8
Training loss: 5.796505928039551
Validation loss: 5.127064140894079

Epoch: 5| Step: 9
Training loss: 6.198370456695557
Validation loss: 5.117110577962732

Epoch: 5| Step: 10
Training loss: 4.313931941986084
Validation loss: 5.110052252328524

Epoch: 7| Step: 0
Training loss: 4.36577844619751
Validation loss: 5.097310712260585

Epoch: 5| Step: 1
Training loss: 3.4064273834228516
Validation loss: 5.091405063547114

Epoch: 5| Step: 2
Training loss: 4.8633222579956055
Validation loss: 5.081732267974525

Epoch: 5| Step: 3
Training loss: 4.286959171295166
Validation loss: 5.075546059557187

Epoch: 5| Step: 4
Training loss: 4.318299293518066
Validation loss: 5.063917226688837

Epoch: 5| Step: 5
Training loss: 6.484165191650391
Validation loss: 5.053497340089532

Epoch: 5| Step: 6
Training loss: 5.295324802398682
Validation loss: 5.045285737642678

Epoch: 5| Step: 7
Training loss: 5.077000617980957
Validation loss: 5.033532475912443

Epoch: 5| Step: 8
Training loss: 5.285883903503418
Validation loss: 5.022720429205125

Epoch: 5| Step: 9
Training loss: 4.62257194519043
Validation loss: 5.013942057086576

Epoch: 5| Step: 10
Training loss: 5.298034191131592
Validation loss: 5.004792357003817

Epoch: 8| Step: 0
Training loss: 5.706076622009277
Validation loss: 4.9919295618611

Epoch: 5| Step: 1
Training loss: 4.467113494873047
Validation loss: 4.983236435920961

Epoch: 5| Step: 2
Training loss: 5.178836822509766
Validation loss: 4.973178730216078

Epoch: 5| Step: 3
Training loss: 3.885753631591797
Validation loss: 4.96464325792046

Epoch: 5| Step: 4
Training loss: 5.448006629943848
Validation loss: 4.9508888490738405

Epoch: 5| Step: 5
Training loss: 4.256819725036621
Validation loss: 4.939819961465815

Epoch: 5| Step: 6
Training loss: 5.406075477600098
Validation loss: 4.927708364302112

Epoch: 5| Step: 7
Training loss: 5.1511311531066895
Validation loss: 4.9184809295080045

Epoch: 5| Step: 8
Training loss: 3.4270224571228027
Validation loss: 4.906087675402241

Epoch: 5| Step: 9
Training loss: 4.1572489738464355
Validation loss: 4.896444371951524

Epoch: 5| Step: 10
Training loss: 4.927523612976074
Validation loss: 4.886974683371923

Epoch: 9| Step: 0
Training loss: 3.709871768951416
Validation loss: 4.8743171384257655

Epoch: 5| Step: 1
Training loss: 5.818772315979004
Validation loss: 4.8604769911817325

Epoch: 5| Step: 2
Training loss: 5.014853477478027
Validation loss: 4.850533762285786

Epoch: 5| Step: 3
Training loss: 4.764647006988525
Validation loss: 4.838955602338237

Epoch: 5| Step: 4
Training loss: 4.29810905456543
Validation loss: 4.829199980663997

Epoch: 5| Step: 5
Training loss: 4.2838134765625
Validation loss: 4.814284791228592

Epoch: 5| Step: 6
Training loss: 4.490227222442627
Validation loss: 4.804342531388806

Epoch: 5| Step: 7
Training loss: 4.118420600891113
Validation loss: 4.7913343983311805

Epoch: 5| Step: 8
Training loss: 5.712947845458984
Validation loss: 4.781063469507361

Epoch: 5| Step: 9
Training loss: 4.098043441772461
Validation loss: 4.767594178517659

Epoch: 5| Step: 10
Training loss: 4.185950756072998
Validation loss: 4.755094974271713

Epoch: 10| Step: 0
Training loss: 5.181532382965088
Validation loss: 4.740411943004977

Epoch: 5| Step: 1
Training loss: 4.478093147277832
Validation loss: 4.724322990704608

Epoch: 5| Step: 2
Training loss: 4.176022529602051
Validation loss: 4.714918454488118

Epoch: 5| Step: 3
Training loss: 4.2506422996521
Validation loss: 4.696778856297975

Epoch: 5| Step: 4
Training loss: 5.025147438049316
Validation loss: 4.688883222559447

Epoch: 5| Step: 5
Training loss: 3.396925449371338
Validation loss: 4.674551881769652

Epoch: 5| Step: 6
Training loss: 6.099050045013428
Validation loss: 4.659078418567616

Epoch: 5| Step: 7
Training loss: 3.1878719329833984
Validation loss: 4.645620428105836

Epoch: 5| Step: 8
Training loss: 4.667231559753418
Validation loss: 4.632207224445958

Epoch: 5| Step: 9
Training loss: 5.276883602142334
Validation loss: 4.61586719430903

Epoch: 5| Step: 10
Training loss: 3.003150463104248
Validation loss: 4.599042595073741

Epoch: 11| Step: 0
Training loss: 4.681177139282227
Validation loss: 4.587947445531046

Epoch: 5| Step: 1
Training loss: 4.381392478942871
Validation loss: 4.574944783282536

Epoch: 5| Step: 2
Training loss: 4.000601291656494
Validation loss: 4.560443719228108

Epoch: 5| Step: 3
Training loss: 3.5409584045410156
Validation loss: 4.545576767254901

Epoch: 5| Step: 4
Training loss: 4.174131870269775
Validation loss: 4.52729868888855

Epoch: 5| Step: 5
Training loss: 5.782970905303955
Validation loss: 4.514021817074027

Epoch: 5| Step: 6
Training loss: 4.372735023498535
Validation loss: 4.4963035122040775

Epoch: 5| Step: 7
Training loss: 4.358754634857178
Validation loss: 4.483438758439915

Epoch: 5| Step: 8
Training loss: 4.628831386566162
Validation loss: 4.467667625796411

Epoch: 5| Step: 9
Training loss: 3.792576551437378
Validation loss: 4.446747846500848

Epoch: 5| Step: 10
Training loss: 3.3330676555633545
Validation loss: 4.436059367272161

Epoch: 12| Step: 0
Training loss: 3.519695997238159
Validation loss: 4.416684286568755

Epoch: 5| Step: 1
Training loss: 3.1244218349456787
Validation loss: 4.40246303619877

Epoch: 5| Step: 2
Training loss: 4.297905445098877
Validation loss: 4.388115882873535

Epoch: 5| Step: 3
Training loss: 4.855650424957275
Validation loss: 4.371840518007996

Epoch: 5| Step: 4
Training loss: 3.290804386138916
Validation loss: 4.356646225016604

Epoch: 5| Step: 5
Training loss: 5.159766674041748
Validation loss: 4.336781040314706

Epoch: 5| Step: 6
Training loss: 3.700155735015869
Validation loss: 4.321561505717616

Epoch: 5| Step: 7
Training loss: 4.548128604888916
Validation loss: 4.307251171399188

Epoch: 5| Step: 8
Training loss: 3.5528793334960938
Validation loss: 4.285732961470081

Epoch: 5| Step: 9
Training loss: 4.510666847229004
Validation loss: 4.270716580011511

Epoch: 5| Step: 10
Training loss: 4.909336566925049
Validation loss: 4.253630140776275

Epoch: 13| Step: 0
Training loss: 3.579606294631958
Validation loss: 4.237680635144634

Epoch: 5| Step: 1
Training loss: 2.290788173675537
Validation loss: 4.220438593177385

Epoch: 5| Step: 2
Training loss: 4.93282413482666
Validation loss: 4.206860619206583

Epoch: 5| Step: 3
Training loss: 3.922088623046875
Validation loss: 4.189724814507269

Epoch: 5| Step: 4
Training loss: 4.917522430419922
Validation loss: 4.164817123002903

Epoch: 5| Step: 5
Training loss: 4.326677322387695
Validation loss: 4.15171258167554

Epoch: 5| Step: 6
Training loss: 4.534572601318359
Validation loss: 4.130406538645427

Epoch: 5| Step: 7
Training loss: 4.087587833404541
Validation loss: 4.110919132027575

Epoch: 5| Step: 8
Training loss: 4.176785945892334
Validation loss: 4.094334274209956

Epoch: 5| Step: 9
Training loss: 3.9561843872070312
Validation loss: 4.0760536655302975

Epoch: 5| Step: 10
Training loss: 2.603618621826172
Validation loss: 4.06004705736714

Epoch: 14| Step: 0
Training loss: 3.0069098472595215
Validation loss: 4.044921521217592

Epoch: 5| Step: 1
Training loss: 4.735911846160889
Validation loss: 4.025283895513063

Epoch: 5| Step: 2
Training loss: 3.7335598468780518
Validation loss: 4.0030346378203365

Epoch: 5| Step: 3
Training loss: 3.183192014694214
Validation loss: 3.9941553556790916

Epoch: 5| Step: 4
Training loss: 4.361466884613037
Validation loss: 3.9726354332380396

Epoch: 5| Step: 5
Training loss: 2.9367682933807373
Validation loss: 3.9508732313750894

Epoch: 5| Step: 6
Training loss: 4.332579135894775
Validation loss: 3.9261136003719863

Epoch: 5| Step: 7
Training loss: 3.337099075317383
Validation loss: 3.914998536468834

Epoch: 5| Step: 8
Training loss: 4.015534400939941
Validation loss: 3.9002786323588383

Epoch: 5| Step: 9
Training loss: 3.742108106613159
Validation loss: 3.881049874008343

Epoch: 5| Step: 10
Training loss: 4.278076171875
Validation loss: 3.864317688890683

Epoch: 15| Step: 0
Training loss: 3.598618984222412
Validation loss: 3.848415959265924

Epoch: 5| Step: 1
Training loss: 3.492187023162842
Validation loss: 3.829016411176292

Epoch: 5| Step: 2
Training loss: 3.5390357971191406
Validation loss: 3.8004189306689846

Epoch: 5| Step: 3
Training loss: 4.138554573059082
Validation loss: 3.7788808679067962

Epoch: 5| Step: 4
Training loss: 3.3790695667266846
Validation loss: 3.7594135525406047

Epoch: 5| Step: 5
Training loss: 4.136195182800293
Validation loss: 3.743943391307708

Epoch: 5| Step: 6
Training loss: 3.8391666412353516
Validation loss: 3.7217289452911704

Epoch: 5| Step: 7
Training loss: 3.3711514472961426
Validation loss: 3.7027296814867245

Epoch: 5| Step: 8
Training loss: 3.2396278381347656
Validation loss: 3.678517592850552

Epoch: 5| Step: 9
Training loss: 3.7250633239746094
Validation loss: 3.657901007642028

Epoch: 5| Step: 10
Training loss: 3.081556558609009
Validation loss: 3.643176258251231

Epoch: 16| Step: 0
Training loss: 4.6795477867126465
Validation loss: 3.6188109151778685

Epoch: 5| Step: 1
Training loss: 2.8980135917663574
Validation loss: 3.5967912520131757

Epoch: 5| Step: 2
Training loss: 2.761824131011963
Validation loss: 3.5771759710004254

Epoch: 5| Step: 3
Training loss: 3.1967382431030273
Validation loss: 3.5604148449436313

Epoch: 5| Step: 4
Training loss: 3.293112277984619
Validation loss: 3.537534293308053

Epoch: 5| Step: 5
Training loss: 3.896610736846924
Validation loss: 3.5080346240792224

Epoch: 5| Step: 6
Training loss: 3.2493674755096436
Validation loss: 3.488144438753846

Epoch: 5| Step: 7
Training loss: 3.4860024452209473
Validation loss: 3.4803667786300823

Epoch: 5| Step: 8
Training loss: 3.4361014366149902
Validation loss: 3.454845823267455

Epoch: 5| Step: 9
Training loss: 3.1874184608459473
Validation loss: 3.4316964149475098

Epoch: 5| Step: 10
Training loss: 3.308586597442627
Validation loss: 3.4142864391367924

Epoch: 17| Step: 0
Training loss: 3.6277053356170654
Validation loss: 3.3914636001792005

Epoch: 5| Step: 1
Training loss: 3.2559237480163574
Validation loss: 3.370434038100704

Epoch: 5| Step: 2
Training loss: 4.718687534332275
Validation loss: 3.344549253422727

Epoch: 5| Step: 3
Training loss: 2.983527898788452
Validation loss: 3.3148462490368913

Epoch: 5| Step: 4
Training loss: 3.0868210792541504
Validation loss: 3.3001724212400374

Epoch: 5| Step: 5
Training loss: 2.527435779571533
Validation loss: 3.2777864958650325

Epoch: 5| Step: 6
Training loss: 2.692140817642212
Validation loss: 3.256788794712354

Epoch: 5| Step: 7
Training loss: 2.1137003898620605
Validation loss: 3.2291933516020417

Epoch: 5| Step: 8
Training loss: 3.2925400733947754
Validation loss: 3.2028482293569915

Epoch: 5| Step: 9
Training loss: 3.146278142929077
Validation loss: 3.1782005115221907

Epoch: 5| Step: 10
Training loss: 3.886845350265503
Validation loss: 3.1709989886130057

Epoch: 18| Step: 0
Training loss: 3.3884875774383545
Validation loss: 3.144879038615893

Epoch: 5| Step: 1
Training loss: 3.908097743988037
Validation loss: 3.125473427516158

Epoch: 5| Step: 2
Training loss: 2.9636709690093994
Validation loss: 3.0920160432015695

Epoch: 5| Step: 3
Training loss: 2.716395854949951
Validation loss: 3.0800345995092906

Epoch: 5| Step: 4
Training loss: 3.387753963470459
Validation loss: 3.050290323072864

Epoch: 5| Step: 5
Training loss: 2.6097192764282227
Validation loss: 3.033983302372758

Epoch: 5| Step: 6
Training loss: 3.1442925930023193
Validation loss: 3.0214365810476322

Epoch: 5| Step: 7
Training loss: 2.875290870666504
Validation loss: 2.985831001753448

Epoch: 5| Step: 8
Training loss: 3.2657809257507324
Validation loss: 2.9681929337081088

Epoch: 5| Step: 9
Training loss: 2.1904664039611816
Validation loss: 2.939336322969006

Epoch: 5| Step: 10
Training loss: 2.9712305068969727
Validation loss: 2.918321132659912

Epoch: 19| Step: 0
Training loss: 3.5467090606689453
Validation loss: 2.896942571927142

Epoch: 5| Step: 1
Training loss: 2.292382001876831
Validation loss: 2.8805958942700456

Epoch: 5| Step: 2
Training loss: 3.419248104095459
Validation loss: 2.8649914623588644

Epoch: 5| Step: 3
Training loss: 3.1823439598083496
Validation loss: 2.8443970834055254

Epoch: 5| Step: 4
Training loss: 3.0253889560699463
Validation loss: 2.820384051210137

Epoch: 5| Step: 5
Training loss: 3.0250868797302246
Validation loss: 2.8056896886517926

Epoch: 5| Step: 6
Training loss: 3.0248923301696777
Validation loss: 2.780646606158185

Epoch: 5| Step: 7
Training loss: 3.3950982093811035
Validation loss: 2.7572850463210896

Epoch: 5| Step: 8
Training loss: 2.597581148147583
Validation loss: 2.744915741746144

Epoch: 5| Step: 9
Training loss: 2.061584949493408
Validation loss: 2.712652406384868

Epoch: 5| Step: 10
Training loss: 2.1680166721343994
Validation loss: 2.693819212657149

Epoch: 20| Step: 0
Training loss: 2.969856023788452
Validation loss: 2.6837773015422206

Epoch: 5| Step: 1
Training loss: 2.9266695976257324
Validation loss: 2.6567200614560034

Epoch: 5| Step: 2
Training loss: 3.1868484020233154
Validation loss: 2.6573826215600453

Epoch: 5| Step: 3
Training loss: 2.8535866737365723
Validation loss: 2.633611473985898

Epoch: 5| Step: 4
Training loss: 2.1914191246032715
Validation loss: 2.61563963531166

Epoch: 5| Step: 5
Training loss: 2.9845170974731445
Validation loss: 2.5960668056241927

Epoch: 5| Step: 6
Training loss: 2.8517649173736572
Validation loss: 2.5753052747377785

Epoch: 5| Step: 7
Training loss: 2.4989736080169678
Validation loss: 2.5551424590490197

Epoch: 5| Step: 8
Training loss: 2.787696123123169
Validation loss: 2.5378161963596138

Epoch: 5| Step: 9
Training loss: 2.6361241340637207
Validation loss: 2.5255839465766825

Epoch: 5| Step: 10
Training loss: 2.206658363342285
Validation loss: 2.508720629958696

Epoch: 21| Step: 0
Training loss: 3.121778726577759
Validation loss: 2.4954892537927114

Epoch: 5| Step: 1
Training loss: 1.983859658241272
Validation loss: 2.4813608097773727

Epoch: 5| Step: 2
Training loss: 2.8620030879974365
Validation loss: 2.4585857442630235

Epoch: 5| Step: 3
Training loss: 2.1116294860839844
Validation loss: 2.4449705693029586

Epoch: 5| Step: 4
Training loss: 3.2583937644958496
Validation loss: 2.423441763847105

Epoch: 5| Step: 5
Training loss: 3.0960559844970703
Validation loss: 2.4060631285431566

Epoch: 5| Step: 6
Training loss: 1.92768132686615
Validation loss: 2.394330011901035

Epoch: 5| Step: 7
Training loss: 2.3906142711639404
Validation loss: 2.3805595418458343

Epoch: 5| Step: 8
Training loss: 2.349837303161621
Validation loss: 2.3614705788191928

Epoch: 5| Step: 9
Training loss: 2.808131694793701
Validation loss: 2.344917804964127

Epoch: 5| Step: 10
Training loss: 2.984096050262451
Validation loss: 2.3353458399413736

Epoch: 22| Step: 0
Training loss: 2.6773428916931152
Validation loss: 2.331608774841473

Epoch: 5| Step: 1
Training loss: 2.351809024810791
Validation loss: 2.3065785925875426

Epoch: 5| Step: 2
Training loss: 3.2409281730651855
Validation loss: 2.298207329165551

Epoch: 5| Step: 3
Training loss: 2.006530523300171
Validation loss: 2.294288181489514

Epoch: 5| Step: 4
Training loss: 2.282322645187378
Validation loss: 2.284931572534705

Epoch: 5| Step: 5
Training loss: 1.9819562435150146
Validation loss: 2.2727277868537494

Epoch: 5| Step: 6
Training loss: 2.1563289165496826
Validation loss: 2.2478820200889342

Epoch: 5| Step: 7
Training loss: 2.8289787769317627
Validation loss: 2.272106685946065

Epoch: 5| Step: 8
Training loss: 2.811450719833374
Validation loss: 2.2524202382692726

Epoch: 5| Step: 9
Training loss: 3.30830454826355
Validation loss: 2.2425259467094176

Epoch: 5| Step: 10
Training loss: 1.8205900192260742
Validation loss: 2.2363071980014926

Epoch: 23| Step: 0
Training loss: 2.207289457321167
Validation loss: 2.2283269461765083

Epoch: 5| Step: 1
Training loss: 2.475309371948242
Validation loss: 2.2270253114802863

Epoch: 5| Step: 2
Training loss: 2.2579619884490967
Validation loss: 2.2111404583018315

Epoch: 5| Step: 3
Training loss: 2.6589763164520264
Validation loss: 2.20194048266257

Epoch: 5| Step: 4
Training loss: 2.1531271934509277
Validation loss: 2.189181020182948

Epoch: 5| Step: 5
Training loss: 2.5871267318725586
Validation loss: 2.190364988901282

Epoch: 5| Step: 6
Training loss: 2.810920238494873
Validation loss: 2.1971152867040327

Epoch: 5| Step: 7
Training loss: 2.463695526123047
Validation loss: 2.1996698276970976

Epoch: 5| Step: 8
Training loss: 2.686722993850708
Validation loss: 2.1773429762932563

Epoch: 5| Step: 9
Training loss: 2.22511625289917
Validation loss: 2.1651506218858945

Epoch: 5| Step: 10
Training loss: 2.600011110305786
Validation loss: 2.18007186407684

Epoch: 24| Step: 0
Training loss: 1.9300187826156616
Validation loss: 2.1629276429453204

Epoch: 5| Step: 1
Training loss: 2.3908183574676514
Validation loss: 2.1682212596298545

Epoch: 5| Step: 2
Training loss: 3.099022626876831
Validation loss: 2.159478477252427

Epoch: 5| Step: 3
Training loss: 2.6435658931732178
Validation loss: 2.15846727484016

Epoch: 5| Step: 4
Training loss: 2.402681589126587
Validation loss: 2.1530353535888014

Epoch: 5| Step: 5
Training loss: 2.6890900135040283
Validation loss: 2.1583861971414215

Epoch: 5| Step: 6
Training loss: 2.4342007637023926
Validation loss: 2.1531548730788694

Epoch: 5| Step: 7
Training loss: 2.7482805252075195
Validation loss: 2.14408181687837

Epoch: 5| Step: 8
Training loss: 2.32182240486145
Validation loss: 2.1369015657773582

Epoch: 5| Step: 9
Training loss: 2.070591449737549
Validation loss: 2.1382580521286174

Epoch: 5| Step: 10
Training loss: 2.1019210815429688
Validation loss: 2.1211895865778767

Epoch: 25| Step: 0
Training loss: 2.228070020675659
Validation loss: 2.135812185143912

Epoch: 5| Step: 1
Training loss: 2.0403246879577637
Validation loss: 2.1419809069684757

Epoch: 5| Step: 2
Training loss: 3.1561827659606934
Validation loss: 2.141079197647751

Epoch: 5| Step: 3
Training loss: 2.495058536529541
Validation loss: 2.126978323023806

Epoch: 5| Step: 4
Training loss: 2.546201229095459
Validation loss: 2.1240296953467914

Epoch: 5| Step: 5
Training loss: 2.101567029953003
Validation loss: 2.1175147923090125

Epoch: 5| Step: 6
Training loss: 2.66339111328125
Validation loss: 2.1263954203615905

Epoch: 5| Step: 7
Training loss: 2.4728684425354004
Validation loss: 2.1415127605520268

Epoch: 5| Step: 8
Training loss: 2.5038249492645264
Validation loss: 2.140812871276691

Epoch: 5| Step: 9
Training loss: 2.3150031566619873
Validation loss: 2.1325253773761053

Epoch: 5| Step: 10
Training loss: 2.3251378536224365
Validation loss: 2.1275208304005284

Epoch: 26| Step: 0
Training loss: 2.4644083976745605
Validation loss: 2.121433106801843

Epoch: 5| Step: 1
Training loss: 2.1810059547424316
Validation loss: 2.1220713071925665

Epoch: 5| Step: 2
Training loss: 3.3685708045959473
Validation loss: 2.128089289511404

Epoch: 5| Step: 3
Training loss: 2.726672410964966
Validation loss: 2.1206878615963842

Epoch: 5| Step: 4
Training loss: 2.5332024097442627
Validation loss: 2.1069829079412643

Epoch: 5| Step: 5
Training loss: 1.6135727167129517
Validation loss: 2.103093821515319

Epoch: 5| Step: 6
Training loss: 2.5893120765686035
Validation loss: 2.1160986884947746

Epoch: 5| Step: 7
Training loss: 1.8329389095306396
Validation loss: 2.1225471163308747

Epoch: 5| Step: 8
Training loss: 2.7549924850463867
Validation loss: 2.116895601313601

Epoch: 5| Step: 9
Training loss: 2.141618490219116
Validation loss: 2.1129779238854685

Epoch: 5| Step: 10
Training loss: 2.5898303985595703
Validation loss: 2.1182895116908576

Epoch: 27| Step: 0
Training loss: 3.0658116340637207
Validation loss: 2.1219682975481917

Epoch: 5| Step: 1
Training loss: 2.7622504234313965
Validation loss: 2.112164689648536

Epoch: 5| Step: 2
Training loss: 2.3277153968811035
Validation loss: 2.11823292445111

Epoch: 5| Step: 3
Training loss: 2.9269461631774902
Validation loss: 2.1196050567011677

Epoch: 5| Step: 4
Training loss: 2.9407334327697754
Validation loss: 2.112396652980517

Epoch: 5| Step: 5
Training loss: 2.0555834770202637
Validation loss: 2.1107049065251506

Epoch: 5| Step: 6
Training loss: 2.763324737548828
Validation loss: 2.12538900426639

Epoch: 5| Step: 7
Training loss: 1.7363536357879639
Validation loss: 2.110236326853434

Epoch: 5| Step: 8
Training loss: 1.6413118839263916
Validation loss: 2.136913004741874

Epoch: 5| Step: 9
Training loss: 2.3651530742645264
Validation loss: 2.1138253365793536

Epoch: 5| Step: 10
Training loss: 2.143744468688965
Validation loss: 2.100864792382845

Epoch: 28| Step: 0
Training loss: 2.7392475605010986
Validation loss: 2.10919544517353

Epoch: 5| Step: 1
Training loss: 2.134291172027588
Validation loss: 2.115491533792147

Epoch: 5| Step: 2
Training loss: 2.7350687980651855
Validation loss: 2.1092117307006673

Epoch: 5| Step: 3
Training loss: 2.55568265914917
Validation loss: 2.1182424945216023

Epoch: 5| Step: 4
Training loss: 2.532966375350952
Validation loss: 2.1092396884836178

Epoch: 5| Step: 5
Training loss: 2.4304754734039307
Validation loss: 2.1052381095065864

Epoch: 5| Step: 6
Training loss: 2.4603590965270996
Validation loss: 2.1035595119640393

Epoch: 5| Step: 7
Training loss: 1.7337801456451416
Validation loss: 2.124549259421646

Epoch: 5| Step: 8
Training loss: 2.2299580574035645
Validation loss: 2.1105465671067596

Epoch: 5| Step: 9
Training loss: 2.5223422050476074
Validation loss: 2.100488929338353

Epoch: 5| Step: 10
Training loss: 2.6545491218566895
Validation loss: 2.1075404049247823

Epoch: 29| Step: 0
Training loss: 2.591306686401367
Validation loss: 2.0969462240895917

Epoch: 5| Step: 1
Training loss: 3.2440237998962402
Validation loss: 2.1005277966940277

Epoch: 5| Step: 2
Training loss: 2.017256259918213
Validation loss: 2.121894515970702

Epoch: 5| Step: 3
Training loss: 2.3682186603546143
Validation loss: 2.112585275403915

Epoch: 5| Step: 4
Training loss: 2.256063938140869
Validation loss: 2.111822687169557

Epoch: 5| Step: 5
Training loss: 2.3840994834899902
Validation loss: 2.1154248586264988

Epoch: 5| Step: 6
Training loss: 2.6273205280303955
Validation loss: 2.1065520060959684

Epoch: 5| Step: 7
Training loss: 2.5552377700805664
Validation loss: 2.1057115780409945

Epoch: 5| Step: 8
Training loss: 2.0183334350585938
Validation loss: 2.1117677816780667

Epoch: 5| Step: 9
Training loss: 2.465122699737549
Validation loss: 2.1067619926186016

Epoch: 5| Step: 10
Training loss: 2.008902072906494
Validation loss: 2.1166009236407537

Epoch: 30| Step: 0
Training loss: 2.1703968048095703
Validation loss: 2.1164483793320192

Epoch: 5| Step: 1
Training loss: 2.3608736991882324
Validation loss: 2.094182816884851

Epoch: 5| Step: 2
Training loss: 2.4696168899536133
Validation loss: 2.1017884977402224

Epoch: 5| Step: 3
Training loss: 2.0137271881103516
Validation loss: 2.11362551617366

Epoch: 5| Step: 4
Training loss: 2.473970890045166
Validation loss: 2.1039517066812

Epoch: 5| Step: 5
Training loss: 1.9123790264129639
Validation loss: 2.1262211902167207

Epoch: 5| Step: 6
Training loss: 2.7057242393493652
Validation loss: 2.123238298200792

Epoch: 5| Step: 7
Training loss: 2.5757064819335938
Validation loss: 2.1014875212023334

Epoch: 5| Step: 8
Training loss: 2.8155274391174316
Validation loss: 2.1237614282997708

Epoch: 5| Step: 9
Training loss: 2.2128381729125977
Validation loss: 2.108230153719584

Epoch: 5| Step: 10
Training loss: 2.9159297943115234
Validation loss: 2.109656035259206

Epoch: 31| Step: 0
Training loss: 2.2712128162384033
Validation loss: 2.1035861212720155

Epoch: 5| Step: 1
Training loss: 1.9018386602401733
Validation loss: 2.1098868718711277

Epoch: 5| Step: 2
Training loss: 2.1104795932769775
Validation loss: 2.111897781331052

Epoch: 5| Step: 3
Training loss: 2.012432813644409
Validation loss: 2.0993045812012046

Epoch: 5| Step: 4
Training loss: 2.4588778018951416
Validation loss: 2.108241855457265

Epoch: 5| Step: 5
Training loss: 3.092498540878296
Validation loss: 2.1038075608591877

Epoch: 5| Step: 6
Training loss: 2.764875650405884
Validation loss: 2.112854403834189

Epoch: 5| Step: 7
Training loss: 2.2276949882507324
Validation loss: 2.1106073138534382

Epoch: 5| Step: 8
Training loss: 3.1301748752593994
Validation loss: 2.0866933586776897

Epoch: 5| Step: 9
Training loss: 2.405019760131836
Validation loss: 2.09995239011703

Epoch: 5| Step: 10
Training loss: 2.0901598930358887
Validation loss: 2.0990353553525862

Epoch: 32| Step: 0
Training loss: 2.563760280609131
Validation loss: 2.0886567164492864

Epoch: 5| Step: 1
Training loss: 2.5775704383850098
Validation loss: 2.092485764975189

Epoch: 5| Step: 2
Training loss: 3.2112507820129395
Validation loss: 2.0966562353154665

Epoch: 5| Step: 3
Training loss: 2.8276257514953613
Validation loss: 2.0945340920520086

Epoch: 5| Step: 4
Training loss: 2.2927048206329346
Validation loss: 2.0810726804118

Epoch: 5| Step: 5
Training loss: 2.419119358062744
Validation loss: 2.100112545874811

Epoch: 5| Step: 6
Training loss: 1.6370117664337158
Validation loss: 2.0877403290041032

Epoch: 5| Step: 7
Training loss: 2.1540071964263916
Validation loss: 2.077944263335197

Epoch: 5| Step: 8
Training loss: 2.20729660987854
Validation loss: 2.1020286531858545

Epoch: 5| Step: 9
Training loss: 2.3346104621887207
Validation loss: 2.0851694230110414

Epoch: 5| Step: 10
Training loss: 2.284623384475708
Validation loss: 2.0930998863712436

Epoch: 33| Step: 0
Training loss: 2.1124682426452637
Validation loss: 2.094711975384784

Epoch: 5| Step: 1
Training loss: 2.6023306846618652
Validation loss: 2.093155599409534

Epoch: 5| Step: 2
Training loss: 2.828598737716675
Validation loss: 2.0961467437846686

Epoch: 5| Step: 3
Training loss: 1.6900088787078857
Validation loss: 2.091779294834342

Epoch: 5| Step: 4
Training loss: 2.519617795944214
Validation loss: 2.0933135940182592

Epoch: 5| Step: 5
Training loss: 2.278440237045288
Validation loss: 2.0832130998693486

Epoch: 5| Step: 6
Training loss: 2.0896692276000977
Validation loss: 2.08855535650766

Epoch: 5| Step: 7
Training loss: 2.535360097885132
Validation loss: 2.1050749363437777

Epoch: 5| Step: 8
Training loss: 3.1244895458221436
Validation loss: 2.09150396239373

Epoch: 5| Step: 9
Training loss: 2.397490978240967
Validation loss: 2.1180400515115387

Epoch: 5| Step: 10
Training loss: 2.170915126800537
Validation loss: 2.10396647196944

Epoch: 34| Step: 0
Training loss: 2.5295920372009277
Validation loss: 2.090870754693144

Epoch: 5| Step: 1
Training loss: 1.492826223373413
Validation loss: 2.1031307661405174

Epoch: 5| Step: 2
Training loss: 2.967400074005127
Validation loss: 2.106080021909488

Epoch: 5| Step: 3
Training loss: 2.2413811683654785
Validation loss: 2.109265996563819

Epoch: 5| Step: 4
Training loss: 2.645829677581787
Validation loss: 2.111078408456618

Epoch: 5| Step: 5
Training loss: 2.2406086921691895
Validation loss: 2.103216287910297

Epoch: 5| Step: 6
Training loss: 2.3560261726379395
Validation loss: 2.1105555872763357

Epoch: 5| Step: 7
Training loss: 2.4308056831359863
Validation loss: 2.104277108305244

Epoch: 5| Step: 8
Training loss: 2.398623466491699
Validation loss: 2.11669526561614

Epoch: 5| Step: 9
Training loss: 3.049715042114258
Validation loss: 2.1045874485405545

Epoch: 5| Step: 10
Training loss: 1.8681432008743286
Validation loss: 2.101140478605865

Epoch: 35| Step: 0
Training loss: 2.887943744659424
Validation loss: 2.102399214621513

Epoch: 5| Step: 1
Training loss: 2.6167168617248535
Validation loss: 2.1031548579533896

Epoch: 5| Step: 2
Training loss: 2.282496929168701
Validation loss: 2.1012894825268815

Epoch: 5| Step: 3
Training loss: 2.7819087505340576
Validation loss: 2.102149845451437

Epoch: 5| Step: 4
Training loss: 2.5997982025146484
Validation loss: 2.1053999829035934

Epoch: 5| Step: 5
Training loss: 2.285764217376709
Validation loss: 2.1046176725818264

Epoch: 5| Step: 6
Training loss: 1.824314832687378
Validation loss: 2.101983244701098

Epoch: 5| Step: 7
Training loss: 2.5950896739959717
Validation loss: 2.1025859027780514

Epoch: 5| Step: 8
Training loss: 2.1220130920410156
Validation loss: 2.092688695076973

Epoch: 5| Step: 9
Training loss: 1.8389002084732056
Validation loss: 2.08933767964763

Epoch: 5| Step: 10
Training loss: 2.3194260597229004
Validation loss: 2.0915382382690266

Epoch: 36| Step: 0
Training loss: 2.0255849361419678
Validation loss: 2.0889627164410007

Epoch: 5| Step: 1
Training loss: 2.8724377155303955
Validation loss: 2.0882085907843804

Epoch: 5| Step: 2
Training loss: 2.754034996032715
Validation loss: 2.08262731952052

Epoch: 5| Step: 3
Training loss: 2.547790288925171
Validation loss: 2.090620254957548

Epoch: 5| Step: 4
Training loss: 1.911441445350647
Validation loss: 2.0800370964952695

Epoch: 5| Step: 5
Training loss: 1.7155901193618774
Validation loss: 2.0889995867206204

Epoch: 5| Step: 6
Training loss: 2.71661114692688
Validation loss: 2.080443779627482

Epoch: 5| Step: 7
Training loss: 2.4408721923828125
Validation loss: 2.08477880108741

Epoch: 5| Step: 8
Training loss: 1.992871642112732
Validation loss: 2.0823471956355597

Epoch: 5| Step: 9
Training loss: 2.2028069496154785
Validation loss: 2.069767807119636

Epoch: 5| Step: 10
Training loss: 3.1224615573883057
Validation loss: 2.0885740992843465

Epoch: 37| Step: 0
Training loss: 2.7524914741516113
Validation loss: 2.0795273178367206

Epoch: 5| Step: 1
Training loss: 2.1068553924560547
Validation loss: 2.091728369394938

Epoch: 5| Step: 2
Training loss: 2.4284305572509766
Validation loss: 2.075108612737348

Epoch: 5| Step: 3
Training loss: 2.6700642108917236
Validation loss: 2.0803444180437314

Epoch: 5| Step: 4
Training loss: 2.957545757293701
Validation loss: 2.0800420981581493

Epoch: 5| Step: 5
Training loss: 1.8487262725830078
Validation loss: 2.0814059011397825

Epoch: 5| Step: 6
Training loss: 1.7985937595367432
Validation loss: 2.061359174789921

Epoch: 5| Step: 7
Training loss: 2.4196887016296387
Validation loss: 2.061079985351973

Epoch: 5| Step: 8
Training loss: 2.770537853240967
Validation loss: 2.0740970898700017

Epoch: 5| Step: 9
Training loss: 2.658586025238037
Validation loss: 2.072667228278293

Epoch: 5| Step: 10
Training loss: 1.6683697700500488
Validation loss: 2.0682978527520293

Epoch: 38| Step: 0
Training loss: 2.192962169647217
Validation loss: 2.0725840701851794

Epoch: 5| Step: 1
Training loss: 2.638420343399048
Validation loss: 2.0679119812544955

Epoch: 5| Step: 2
Training loss: 2.4956841468811035
Validation loss: 2.0606678121833393

Epoch: 5| Step: 3
Training loss: 1.8110764026641846
Validation loss: 2.055259399516608

Epoch: 5| Step: 4
Training loss: 2.2532413005828857
Validation loss: 2.0670221108262257

Epoch: 5| Step: 5
Training loss: 2.8711791038513184
Validation loss: 2.043506342877624

Epoch: 5| Step: 6
Training loss: 2.439568281173706
Validation loss: 2.0512772785720004

Epoch: 5| Step: 7
Training loss: 2.297639846801758
Validation loss: 2.0726064892225367

Epoch: 5| Step: 8
Training loss: 1.9435737133026123
Validation loss: 2.057322194499354

Epoch: 5| Step: 9
Training loss: 2.5673940181732178
Validation loss: 2.060093625899284

Epoch: 5| Step: 10
Training loss: 2.534536600112915
Validation loss: 2.059963862101237

Epoch: 39| Step: 0
Training loss: 2.276613473892212
Validation loss: 2.077219024781258

Epoch: 5| Step: 1
Training loss: 2.0367391109466553
Validation loss: 2.0806561182903986

Epoch: 5| Step: 2
Training loss: 2.0769901275634766
Validation loss: 2.05659310279354

Epoch: 5| Step: 3
Training loss: 1.9425439834594727
Validation loss: 2.0601794065967685

Epoch: 5| Step: 4
Training loss: 2.5506818294525146
Validation loss: 2.0503370428598053

Epoch: 5| Step: 5
Training loss: 2.3120365142822266
Validation loss: 2.051684561596122

Epoch: 5| Step: 6
Training loss: 2.254854917526245
Validation loss: 2.0647969540729316

Epoch: 5| Step: 7
Training loss: 2.1773312091827393
Validation loss: 2.070540451234387

Epoch: 5| Step: 8
Training loss: 2.5553696155548096
Validation loss: 2.051644589311333

Epoch: 5| Step: 9
Training loss: 3.014644145965576
Validation loss: 2.060609266322146

Epoch: 5| Step: 10
Training loss: 2.8279025554656982
Validation loss: 2.0556568586698143

Epoch: 40| Step: 0
Training loss: 2.137728452682495
Validation loss: 2.0589798752979567

Epoch: 5| Step: 1
Training loss: 1.718714952468872
Validation loss: 2.056355227706253

Epoch: 5| Step: 2
Training loss: 2.1567044258117676
Validation loss: 2.0728618521844187

Epoch: 5| Step: 3
Training loss: 3.249871015548706
Validation loss: 2.0667777394735687

Epoch: 5| Step: 4
Training loss: 2.4416985511779785
Validation loss: 2.0602382049765637

Epoch: 5| Step: 5
Training loss: 1.985643744468689
Validation loss: 2.0653603807572396

Epoch: 5| Step: 6
Training loss: 2.5412917137145996
Validation loss: 2.062028727223796

Epoch: 5| Step: 7
Training loss: 2.5926432609558105
Validation loss: 2.063909517821445

Epoch: 5| Step: 8
Training loss: 2.612300395965576
Validation loss: 2.0733253750749814

Epoch: 5| Step: 9
Training loss: 1.8639262914657593
Validation loss: 2.0749906109225367

Epoch: 5| Step: 10
Training loss: 2.6376662254333496
Validation loss: 2.0631274459182576

Epoch: 41| Step: 0
Training loss: 2.4052023887634277
Validation loss: 2.0611538399932203

Epoch: 5| Step: 1
Training loss: 2.4150540828704834
Validation loss: 2.073625845293845

Epoch: 5| Step: 2
Training loss: 1.7059059143066406
Validation loss: 2.0884732815527145

Epoch: 5| Step: 3
Training loss: 2.379241704940796
Validation loss: 2.0700587329044136

Epoch: 5| Step: 4
Training loss: 2.495918035507202
Validation loss: 2.073361381407707

Epoch: 5| Step: 5
Training loss: 1.9850232601165771
Validation loss: 2.054744358985655

Epoch: 5| Step: 6
Training loss: 2.7835633754730225
Validation loss: 2.0660017895442184

Epoch: 5| Step: 7
Training loss: 1.9150956869125366
Validation loss: 2.0501728596225863

Epoch: 5| Step: 8
Training loss: 2.9756388664245605
Validation loss: 2.0655071863564114

Epoch: 5| Step: 9
Training loss: 2.5785629749298096
Validation loss: 2.0632921918745963

Epoch: 5| Step: 10
Training loss: 2.2693819999694824
Validation loss: 2.0596593938848025

Epoch: 42| Step: 0
Training loss: 2.0164389610290527
Validation loss: 2.052999714369415

Epoch: 5| Step: 1
Training loss: 2.3203532695770264
Validation loss: 2.068551299392536

Epoch: 5| Step: 2
Training loss: 3.2497799396514893
Validation loss: 2.0598202572073987

Epoch: 5| Step: 3
Training loss: 2.1370859146118164
Validation loss: 2.05713532047887

Epoch: 5| Step: 4
Training loss: 2.6521365642547607
Validation loss: 2.059725128194337

Epoch: 5| Step: 5
Training loss: 2.0101571083068848
Validation loss: 2.059673511853782

Epoch: 5| Step: 6
Training loss: 2.3901360034942627
Validation loss: 2.0567064746733634

Epoch: 5| Step: 7
Training loss: 1.7989555597305298
Validation loss: 2.056043742805399

Epoch: 5| Step: 8
Training loss: 2.047793388366699
Validation loss: 2.0507896997595347

Epoch: 5| Step: 9
Training loss: 2.7501792907714844
Validation loss: 2.058059823128485

Epoch: 5| Step: 10
Training loss: 2.4354329109191895
Validation loss: 2.046608781301847

Epoch: 43| Step: 0
Training loss: 1.6621806621551514
Validation loss: 2.0535010317320466

Epoch: 5| Step: 1
Training loss: 2.1000053882598877
Validation loss: 2.0404977080642537

Epoch: 5| Step: 2
Training loss: 2.411027193069458
Validation loss: 2.0519478218529814

Epoch: 5| Step: 3
Training loss: 2.3227787017822266
Validation loss: 2.0449642532615253

Epoch: 5| Step: 4
Training loss: 2.3596770763397217
Validation loss: 2.0401910710078415

Epoch: 5| Step: 5
Training loss: 2.596339464187622
Validation loss: 2.035680817019555

Epoch: 5| Step: 6
Training loss: 2.7611701488494873
Validation loss: 2.0481535773123465

Epoch: 5| Step: 7
Training loss: 3.232691526412964
Validation loss: 2.0305688842650382

Epoch: 5| Step: 8
Training loss: 1.877103567123413
Validation loss: 2.0350157535204323

Epoch: 5| Step: 9
Training loss: 2.1495707035064697
Validation loss: 2.0288901072676464

Epoch: 5| Step: 10
Training loss: 2.2149534225463867
Validation loss: 2.028020066599692

Epoch: 44| Step: 0
Training loss: 2.1447503566741943
Validation loss: 2.0416678895232496

Epoch: 5| Step: 1
Training loss: 2.3114750385284424
Validation loss: 2.032318668980752

Epoch: 5| Step: 2
Training loss: 1.7757259607315063
Validation loss: 2.030980307568786

Epoch: 5| Step: 3
Training loss: 2.733893871307373
Validation loss: 2.0342087232938377

Epoch: 5| Step: 4
Training loss: 1.9370853900909424
Validation loss: 2.0277091405724965

Epoch: 5| Step: 5
Training loss: 2.674102306365967
Validation loss: 2.0377480060823503

Epoch: 5| Step: 6
Training loss: 2.785853862762451
Validation loss: 2.04236315783634

Epoch: 5| Step: 7
Training loss: 2.063823699951172
Validation loss: 2.0244137458903815

Epoch: 5| Step: 8
Training loss: 3.021763324737549
Validation loss: 2.0367897300310034

Epoch: 5| Step: 9
Training loss: 2.0215868949890137
Validation loss: 2.029058684584915

Epoch: 5| Step: 10
Training loss: 2.0703177452087402
Validation loss: 2.0309824366723337

Epoch: 45| Step: 0
Training loss: 2.6788198947906494
Validation loss: 2.031135415518156

Epoch: 5| Step: 1
Training loss: 1.6869055032730103
Validation loss: 2.025635932081489

Epoch: 5| Step: 2
Training loss: 2.496256113052368
Validation loss: 2.0363911300577144

Epoch: 5| Step: 3
Training loss: 2.296513319015503
Validation loss: 2.0295249287800123

Epoch: 5| Step: 4
Training loss: 2.174898624420166
Validation loss: 2.0334057449012675

Epoch: 5| Step: 5
Training loss: 2.133615732192993
Validation loss: 2.026148191062353

Epoch: 5| Step: 6
Training loss: 2.050978183746338
Validation loss: 2.039990771201349

Epoch: 5| Step: 7
Training loss: 2.730971574783325
Validation loss: 2.032219618879339

Epoch: 5| Step: 8
Training loss: 2.064732074737549
Validation loss: 2.0328288680763653

Epoch: 5| Step: 9
Training loss: 2.33642315864563
Validation loss: 2.027619651568833

Epoch: 5| Step: 10
Training loss: 3.052011013031006
Validation loss: 2.021067101468322

Epoch: 46| Step: 0
Training loss: 2.984147310256958
Validation loss: 2.0261993292839295

Epoch: 5| Step: 1
Training loss: 2.2586162090301514
Validation loss: 2.0077355446354037

Epoch: 5| Step: 2
Training loss: 1.999842643737793
Validation loss: 2.025928181986655

Epoch: 5| Step: 3
Training loss: 2.754453659057617
Validation loss: 2.0145434974342264

Epoch: 5| Step: 4
Training loss: 1.7807830572128296
Validation loss: 2.0103690162781747

Epoch: 5| Step: 5
Training loss: 2.6373369693756104
Validation loss: 2.0177835097876926

Epoch: 5| Step: 6
Training loss: 2.235008716583252
Validation loss: 2.0291814381076443

Epoch: 5| Step: 7
Training loss: 2.0861029624938965
Validation loss: 2.029120801597513

Epoch: 5| Step: 8
Training loss: 2.254157543182373
Validation loss: 2.039885946499404

Epoch: 5| Step: 9
Training loss: 2.2701029777526855
Validation loss: 2.0255293820493963

Epoch: 5| Step: 10
Training loss: 2.2847177982330322
Validation loss: 2.0295457455419723

Epoch: 47| Step: 0
Training loss: 2.6777923107147217
Validation loss: 2.0416379487642677

Epoch: 5| Step: 1
Training loss: 1.9033479690551758
Validation loss: 2.0168853985366

Epoch: 5| Step: 2
Training loss: 2.250479221343994
Validation loss: 2.02837267485998

Epoch: 5| Step: 3
Training loss: 2.155226945877075
Validation loss: 2.0241410270813973

Epoch: 5| Step: 4
Training loss: 2.299988269805908
Validation loss: 2.0374919214556293

Epoch: 5| Step: 5
Training loss: 1.925249695777893
Validation loss: 2.0300248066584268

Epoch: 5| Step: 6
Training loss: 2.5483195781707764
Validation loss: 2.032958084537137

Epoch: 5| Step: 7
Training loss: 2.362673759460449
Validation loss: 2.0294163060444657

Epoch: 5| Step: 8
Training loss: 2.349433183670044
Validation loss: 2.030700655393703

Epoch: 5| Step: 9
Training loss: 2.776557445526123
Validation loss: 2.024278515128679

Epoch: 5| Step: 10
Training loss: 2.0985267162323
Validation loss: 2.03328126476657

Epoch: 48| Step: 0
Training loss: 2.9057319164276123
Validation loss: 2.0139407086116012

Epoch: 5| Step: 1
Training loss: 1.721975564956665
Validation loss: 2.002337030185166

Epoch: 5| Step: 2
Training loss: 2.2557787895202637
Validation loss: 2.0255184019765546

Epoch: 5| Step: 3
Training loss: 2.0829105377197266
Validation loss: 2.0386115556122153

Epoch: 5| Step: 4
Training loss: 2.0824875831604004
Validation loss: 2.035973838580552

Epoch: 5| Step: 5
Training loss: 2.890414237976074
Validation loss: 2.0230049317882908

Epoch: 5| Step: 6
Training loss: 2.5007119178771973
Validation loss: 2.0469453232262724

Epoch: 5| Step: 7
Training loss: 2.1438896656036377
Validation loss: 2.029317545634444

Epoch: 5| Step: 8
Training loss: 1.7130390405654907
Validation loss: 2.0353887273419287

Epoch: 5| Step: 9
Training loss: 2.355243682861328
Validation loss: 2.0244355163266583

Epoch: 5| Step: 10
Training loss: 2.8058736324310303
Validation loss: 2.033980466986215

Epoch: 49| Step: 0
Training loss: 2.213108539581299
Validation loss: 2.0197438988634335

Epoch: 5| Step: 1
Training loss: 2.5961668491363525
Validation loss: 2.0213809731186076

Epoch: 5| Step: 2
Training loss: 1.9876039028167725
Validation loss: 2.0431710686734927

Epoch: 5| Step: 3
Training loss: 1.8748385906219482
Validation loss: 2.0408229891971876

Epoch: 5| Step: 4
Training loss: 2.2781076431274414
Validation loss: 2.034468722599809

Epoch: 5| Step: 5
Training loss: 2.6251277923583984
Validation loss: 2.0374893116694626

Epoch: 5| Step: 6
Training loss: 3.2253661155700684
Validation loss: 2.037109869782643

Epoch: 5| Step: 7
Training loss: 2.438880443572998
Validation loss: 2.0409605503082275

Epoch: 5| Step: 8
Training loss: 2.089900016784668
Validation loss: 2.044601094338202

Epoch: 5| Step: 9
Training loss: 2.1538748741149902
Validation loss: 2.0529229871688353

Epoch: 5| Step: 10
Training loss: 1.8019335269927979
Validation loss: 2.0573197795498754

Epoch: 50| Step: 0
Training loss: 1.878846526145935
Validation loss: 2.0534833579935055

Epoch: 5| Step: 1
Training loss: 2.815171957015991
Validation loss: 2.0320403563079013

Epoch: 5| Step: 2
Training loss: 2.384178876876831
Validation loss: 2.0376368645698792

Epoch: 5| Step: 3
Training loss: 2.0614266395568848
Validation loss: 2.0409656160621235

Epoch: 5| Step: 4
Training loss: 1.8258936405181885
Validation loss: 2.0389296239422214

Epoch: 5| Step: 5
Training loss: 1.794690489768982
Validation loss: 2.026876844385619

Epoch: 5| Step: 6
Training loss: 2.6001999378204346
Validation loss: 2.03168608039938

Epoch: 5| Step: 7
Training loss: 2.528177261352539
Validation loss: 2.032023015842643

Epoch: 5| Step: 8
Training loss: 2.1420557498931885
Validation loss: 2.0393384182324974

Epoch: 5| Step: 9
Training loss: 2.8505921363830566
Validation loss: 2.014299782373572

Epoch: 5| Step: 10
Training loss: 2.5376744270324707
Validation loss: 2.0253401238431215

Epoch: 51| Step: 0
Training loss: 3.2059197425842285
Validation loss: 2.030008004557702

Epoch: 5| Step: 1
Training loss: 1.944799780845642
Validation loss: 1.996796888689841

Epoch: 5| Step: 2
Training loss: 2.038968801498413
Validation loss: 2.0269271301966842

Epoch: 5| Step: 3
Training loss: 1.3985973596572876
Validation loss: 2.018578629339895

Epoch: 5| Step: 4
Training loss: 2.31002140045166
Validation loss: 2.0218713873176166

Epoch: 5| Step: 5
Training loss: 2.499917507171631
Validation loss: 2.014131498593156

Epoch: 5| Step: 6
Training loss: 2.908151149749756
Validation loss: 2.028367051514246

Epoch: 5| Step: 7
Training loss: 1.7954990863800049
Validation loss: 2.0086297245435816

Epoch: 5| Step: 8
Training loss: 2.0857996940612793
Validation loss: 2.016260375258743

Epoch: 5| Step: 9
Training loss: 2.0390608310699463
Validation loss: 2.027280035839286

Epoch: 5| Step: 10
Training loss: 3.2924513816833496
Validation loss: 2.0179307153148036

Epoch: 52| Step: 0
Training loss: 2.2682528495788574
Validation loss: 2.0134608066210182

Epoch: 5| Step: 1
Training loss: 2.5938730239868164
Validation loss: 2.022164906224897

Epoch: 5| Step: 2
Training loss: 2.0594944953918457
Validation loss: 2.016204826293453

Epoch: 5| Step: 3
Training loss: 2.6489765644073486
Validation loss: 2.0224295175203713

Epoch: 5| Step: 4
Training loss: 1.940521240234375
Validation loss: 2.033387686616631

Epoch: 5| Step: 5
Training loss: 1.937029242515564
Validation loss: 2.0163355027475665

Epoch: 5| Step: 6
Training loss: 2.324897289276123
Validation loss: 2.018549842219199

Epoch: 5| Step: 7
Training loss: 2.555905818939209
Validation loss: 2.0179359912872314

Epoch: 5| Step: 8
Training loss: 2.1766395568847656
Validation loss: 2.030073727330854

Epoch: 5| Step: 9
Training loss: 2.472255229949951
Validation loss: 2.004408492836901

Epoch: 5| Step: 10
Training loss: 2.2610714435577393
Validation loss: 2.010358404087764

Epoch: 53| Step: 0
Training loss: 2.487757682800293
Validation loss: 2.0186348063971407

Epoch: 5| Step: 1
Training loss: 1.7429533004760742
Validation loss: 2.03373138366207

Epoch: 5| Step: 2
Training loss: 2.382723331451416
Validation loss: 2.02414761435601

Epoch: 5| Step: 3
Training loss: 1.7721586227416992
Validation loss: 2.0302050472587667

Epoch: 5| Step: 4
Training loss: 2.838468074798584
Validation loss: 2.0267755677623134

Epoch: 5| Step: 5
Training loss: 2.293761730194092
Validation loss: 2.0230146608045025

Epoch: 5| Step: 6
Training loss: 2.3291513919830322
Validation loss: 2.0404317276452177

Epoch: 5| Step: 7
Training loss: 2.905806541442871
Validation loss: 2.040463691116661

Epoch: 5| Step: 8
Training loss: 2.6608827114105225
Validation loss: 2.019664336276311

Epoch: 5| Step: 9
Training loss: 2.13053560256958
Validation loss: 2.0245514351834535

Epoch: 5| Step: 10
Training loss: 1.695770025253296
Validation loss: 2.0176869438540552

Epoch: 54| Step: 0
Training loss: 2.2518985271453857
Validation loss: 2.026997725168864

Epoch: 5| Step: 1
Training loss: 2.4120233058929443
Validation loss: 2.0435554148048483

Epoch: 5| Step: 2
Training loss: 2.911569833755493
Validation loss: 2.034142146828354

Epoch: 5| Step: 3
Training loss: 2.0050244331359863
Validation loss: 2.025636124354537

Epoch: 5| Step: 4
Training loss: 2.5889687538146973
Validation loss: 2.014282940536417

Epoch: 5| Step: 5
Training loss: 1.7995564937591553
Validation loss: 2.0305003684054137

Epoch: 5| Step: 6
Training loss: 2.489605188369751
Validation loss: 2.0296352012183076

Epoch: 5| Step: 7
Training loss: 2.143515110015869
Validation loss: 2.020040809467275

Epoch: 5| Step: 8
Training loss: 2.3228530883789062
Validation loss: 2.012889363432443

Epoch: 5| Step: 9
Training loss: 2.631636381149292
Validation loss: 2.0420781066340785

Epoch: 5| Step: 10
Training loss: 1.6154571771621704
Validation loss: 2.0417194033181794

Epoch: 55| Step: 0
Training loss: 1.7012096643447876
Validation loss: 2.0188553551191926

Epoch: 5| Step: 1
Training loss: 1.683355689048767
Validation loss: 2.0116520658616097

Epoch: 5| Step: 2
Training loss: 2.0407214164733887
Validation loss: 2.027314968006585

Epoch: 5| Step: 3
Training loss: 2.4747424125671387
Validation loss: 2.023921214124208

Epoch: 5| Step: 4
Training loss: 1.913870096206665
Validation loss: 2.0195281890130814

Epoch: 5| Step: 5
Training loss: 2.301424503326416
Validation loss: 2.004127220440936

Epoch: 5| Step: 6
Training loss: 2.9499449729919434
Validation loss: 2.025556489985476

Epoch: 5| Step: 7
Training loss: 2.690725803375244
Validation loss: 2.006202410626155

Epoch: 5| Step: 8
Training loss: 2.563363790512085
Validation loss: 2.020817078569884

Epoch: 5| Step: 9
Training loss: 3.1806516647338867
Validation loss: 2.0360940476899505

Epoch: 5| Step: 10
Training loss: 1.6055994033813477
Validation loss: 2.023941973204254

Epoch: 56| Step: 0
Training loss: 1.7693212032318115
Validation loss: 2.0230459859294276

Epoch: 5| Step: 1
Training loss: 2.305210590362549
Validation loss: 2.017179766008931

Epoch: 5| Step: 2
Training loss: 2.810904026031494
Validation loss: 2.0176121137475453

Epoch: 5| Step: 3
Training loss: 2.1128411293029785
Validation loss: 2.029404722234254

Epoch: 5| Step: 4
Training loss: 2.951686143875122
Validation loss: 2.0346147244976414

Epoch: 5| Step: 5
Training loss: 2.0233311653137207
Validation loss: 2.03809368354018

Epoch: 5| Step: 6
Training loss: 2.090519428253174
Validation loss: 2.0446503598202943

Epoch: 5| Step: 7
Training loss: 2.2797513008117676
Validation loss: 2.021090558780137

Epoch: 5| Step: 8
Training loss: 2.3453147411346436
Validation loss: 2.029841584544028

Epoch: 5| Step: 9
Training loss: 2.17314076423645
Validation loss: 2.032859633045812

Epoch: 5| Step: 10
Training loss: 2.1670873165130615
Validation loss: 2.0309220539626254

Epoch: 57| Step: 0
Training loss: 1.8769174814224243
Validation loss: 2.049195111438792

Epoch: 5| Step: 1
Training loss: 2.413404941558838
Validation loss: 2.03762891984755

Epoch: 5| Step: 2
Training loss: 2.517190456390381
Validation loss: 2.024317827276004

Epoch: 5| Step: 3
Training loss: 2.3290133476257324
Validation loss: 2.0358789313224053

Epoch: 5| Step: 4
Training loss: 2.6689517498016357
Validation loss: 2.0249604922468945

Epoch: 5| Step: 5
Training loss: 2.4437808990478516
Validation loss: 2.023248108484412

Epoch: 5| Step: 6
Training loss: 1.9765228033065796
Validation loss: 2.0234988043385167

Epoch: 5| Step: 7
Training loss: 1.9874775409698486
Validation loss: 2.043186454362767

Epoch: 5| Step: 8
Training loss: 2.3614728450775146
Validation loss: 2.034940163294474

Epoch: 5| Step: 9
Training loss: 2.4334921836853027
Validation loss: 2.0297913346239316

Epoch: 5| Step: 10
Training loss: 2.1069560050964355
Validation loss: 2.0254367025949622

Epoch: 58| Step: 0
Training loss: 2.6633033752441406
Validation loss: 2.0180291744970504

Epoch: 5| Step: 1
Training loss: 1.8549678325653076
Validation loss: 2.017688925548266

Epoch: 5| Step: 2
Training loss: 2.0939323902130127
Validation loss: 2.0192405946793093

Epoch: 5| Step: 3
Training loss: 2.415794849395752
Validation loss: 2.0251843544744674

Epoch: 5| Step: 4
Training loss: 2.4581987857818604
Validation loss: 2.0338974716842815

Epoch: 5| Step: 5
Training loss: 1.952649712562561
Validation loss: 2.039152076167445

Epoch: 5| Step: 6
Training loss: 2.752586841583252
Validation loss: 2.0442728675821775

Epoch: 5| Step: 7
Training loss: 1.5679657459259033
Validation loss: 2.025721429496683

Epoch: 5| Step: 8
Training loss: 2.225959062576294
Validation loss: 2.018667418469665

Epoch: 5| Step: 9
Training loss: 2.785999298095703
Validation loss: 2.018245586784937

Epoch: 5| Step: 10
Training loss: 2.3044376373291016
Validation loss: 2.027192379838677

Epoch: 59| Step: 0
Training loss: 2.644580364227295
Validation loss: 2.0191003955820555

Epoch: 5| Step: 1
Training loss: 2.2407662868499756
Validation loss: 2.0144964520649244

Epoch: 5| Step: 2
Training loss: 1.7218555212020874
Validation loss: 2.013524991209789

Epoch: 5| Step: 3
Training loss: 2.1797821521759033
Validation loss: 2.0141610830060896

Epoch: 5| Step: 4
Training loss: 1.8132766485214233
Validation loss: 2.022730863222512

Epoch: 5| Step: 5
Training loss: 2.422870635986328
Validation loss: 2.0218467058673983

Epoch: 5| Step: 6
Training loss: 2.56062388420105
Validation loss: 2.0294163573172783

Epoch: 5| Step: 7
Training loss: 2.661844253540039
Validation loss: 2.022585940617387

Epoch: 5| Step: 8
Training loss: 1.92194402217865
Validation loss: 2.022753139977814

Epoch: 5| Step: 9
Training loss: 2.6492409706115723
Validation loss: 2.025555802929786

Epoch: 5| Step: 10
Training loss: 2.1989307403564453
Validation loss: 2.028956397887199

Epoch: 60| Step: 0
Training loss: 2.5861010551452637
Validation loss: 2.0160478058681695

Epoch: 5| Step: 1
Training loss: 2.0174968242645264
Validation loss: 2.0114710484781573

Epoch: 5| Step: 2
Training loss: 2.30898118019104
Validation loss: 2.002155616719236

Epoch: 5| Step: 3
Training loss: 1.6336917877197266
Validation loss: 2.027782501712922

Epoch: 5| Step: 4
Training loss: 3.057664394378662
Validation loss: 2.0220133258450415

Epoch: 5| Step: 5
Training loss: 2.4968433380126953
Validation loss: 2.0200818994993806

Epoch: 5| Step: 6
Training loss: 1.5551618337631226
Validation loss: 2.026730498959941

Epoch: 5| Step: 7
Training loss: 2.0291686058044434
Validation loss: 2.0236431911427486

Epoch: 5| Step: 8
Training loss: 2.4780356884002686
Validation loss: 2.0193042319308043

Epoch: 5| Step: 9
Training loss: 1.6738554239273071
Validation loss: 2.0104519961982645

Epoch: 5| Step: 10
Training loss: 3.150052547454834
Validation loss: 2.0242733083745486

Epoch: 61| Step: 0
Training loss: 1.8095338344573975
Validation loss: 2.0131148087081088

Epoch: 5| Step: 1
Training loss: 2.8205673694610596
Validation loss: 2.007783479588006

Epoch: 5| Step: 2
Training loss: 2.709784507751465
Validation loss: 2.0254964290126676

Epoch: 5| Step: 3
Training loss: 2.222707748413086
Validation loss: 2.010649411909042

Epoch: 5| Step: 4
Training loss: 2.053915023803711
Validation loss: 1.9987226506715179

Epoch: 5| Step: 5
Training loss: 2.177405834197998
Validation loss: 2.028535735222601

Epoch: 5| Step: 6
Training loss: 2.042158842086792
Validation loss: 2.0193491917784496

Epoch: 5| Step: 7
Training loss: 2.304258346557617
Validation loss: 2.0232590475390033

Epoch: 5| Step: 8
Training loss: 2.6929283142089844
Validation loss: 2.0192765753756285

Epoch: 5| Step: 9
Training loss: 2.125864028930664
Validation loss: 2.0300269639620216

Epoch: 5| Step: 10
Training loss: 1.9862762689590454
Validation loss: 2.0177847505897604

Epoch: 62| Step: 0
Training loss: 1.9851324558258057
Validation loss: 2.004945606313726

Epoch: 5| Step: 1
Training loss: 2.724483013153076
Validation loss: 2.004436339101484

Epoch: 5| Step: 2
Training loss: 2.106018543243408
Validation loss: 2.0024814477530857

Epoch: 5| Step: 3
Training loss: 2.7718253135681152
Validation loss: 2.015085369028071

Epoch: 5| Step: 4
Training loss: 2.068093776702881
Validation loss: 2.0106666152195265

Epoch: 5| Step: 5
Training loss: 2.2452280521392822
Validation loss: 2.023393827099954

Epoch: 5| Step: 6
Training loss: 1.7020946741104126
Validation loss: 2.0154366877771195

Epoch: 5| Step: 7
Training loss: 2.6940360069274902
Validation loss: 2.025758374121881

Epoch: 5| Step: 8
Training loss: 2.251962184906006
Validation loss: 2.0073914027983144

Epoch: 5| Step: 9
Training loss: 2.2295498847961426
Validation loss: 2.0269154451226674

Epoch: 5| Step: 10
Training loss: 2.041435718536377
Validation loss: 2.0157899497657694

Epoch: 63| Step: 0
Training loss: 2.993574857711792
Validation loss: 2.012213090414642

Epoch: 5| Step: 1
Training loss: 2.228318452835083
Validation loss: 2.0252313895892073

Epoch: 5| Step: 2
Training loss: 2.2346413135528564
Validation loss: 2.009076526088099

Epoch: 5| Step: 3
Training loss: 3.143780469894409
Validation loss: 2.027891674349385

Epoch: 5| Step: 4
Training loss: 1.55330491065979
Validation loss: 2.0219321122733493

Epoch: 5| Step: 5
Training loss: 2.6085920333862305
Validation loss: 2.0255453253305085

Epoch: 5| Step: 6
Training loss: 1.7320384979248047
Validation loss: 2.023258997548011

Epoch: 5| Step: 7
Training loss: 2.1159262657165527
Validation loss: 2.0199575821558633

Epoch: 5| Step: 8
Training loss: 2.3944966793060303
Validation loss: 2.0171109399487896

Epoch: 5| Step: 9
Training loss: 2.054548978805542
Validation loss: 2.0355075328580794

Epoch: 5| Step: 10
Training loss: 1.7714651823043823
Validation loss: 2.0272403840095765

Epoch: 64| Step: 0
Training loss: 2.0013234615325928
Validation loss: 2.0154279560171147

Epoch: 5| Step: 1
Training loss: 2.0539302825927734
Validation loss: 2.027123720415177

Epoch: 5| Step: 2
Training loss: 1.7590715885162354
Validation loss: 2.0335858944923646

Epoch: 5| Step: 3
Training loss: 2.1823947429656982
Validation loss: 2.031091208099037

Epoch: 5| Step: 4
Training loss: 2.3533692359924316
Validation loss: 2.013004426033266

Epoch: 5| Step: 5
Training loss: 2.100484609603882
Validation loss: 2.027765513748251

Epoch: 5| Step: 6
Training loss: 2.30881929397583
Validation loss: 2.02414951016826

Epoch: 5| Step: 7
Training loss: 2.1602892875671387
Validation loss: 2.0290647219586115

Epoch: 5| Step: 8
Training loss: 2.5808143615722656
Validation loss: 2.0142708875799693

Epoch: 5| Step: 9
Training loss: 2.7355265617370605
Validation loss: 2.020925352650304

Epoch: 5| Step: 10
Training loss: 2.66259765625
Validation loss: 2.016429211503716

Epoch: 65| Step: 0
Training loss: 2.3897082805633545
Validation loss: 2.0246867774635233

Epoch: 5| Step: 1
Training loss: 1.7880384922027588
Validation loss: 2.017411160212691

Epoch: 5| Step: 2
Training loss: 2.753434181213379
Validation loss: 2.023150582467356

Epoch: 5| Step: 3
Training loss: 1.6284099817276
Validation loss: 2.0193949553274337

Epoch: 5| Step: 4
Training loss: 1.9761629104614258
Validation loss: 2.0198360848170456

Epoch: 5| Step: 5
Training loss: 3.1105449199676514
Validation loss: 2.0178258777946554

Epoch: 5| Step: 6
Training loss: 1.8439241647720337
Validation loss: 2.0001917039194415

Epoch: 5| Step: 7
Training loss: 2.208752393722534
Validation loss: 2.020685339486727

Epoch: 5| Step: 8
Training loss: 2.2498135566711426
Validation loss: 2.0169396220996814

Epoch: 5| Step: 9
Training loss: 2.178622007369995
Validation loss: 2.0248107858883437

Epoch: 5| Step: 10
Training loss: 2.8701677322387695
Validation loss: 2.0151197500126337

Epoch: 66| Step: 0
Training loss: 2.4002606868743896
Validation loss: 2.0212765919264926

Epoch: 5| Step: 1
Training loss: 1.9276206493377686
Validation loss: 2.0096145394027873

Epoch: 5| Step: 2
Training loss: 2.1891775131225586
Validation loss: 2.001774308502033

Epoch: 5| Step: 3
Training loss: 2.8349406719207764
Validation loss: 2.022068977355957

Epoch: 5| Step: 4
Training loss: 1.81015145778656
Validation loss: 2.0118199022867347

Epoch: 5| Step: 5
Training loss: 1.613430380821228
Validation loss: 2.02122575236905

Epoch: 5| Step: 6
Training loss: 2.44350528717041
Validation loss: 2.0311215590405207

Epoch: 5| Step: 7
Training loss: 1.7863590717315674
Validation loss: 2.0139928504984868

Epoch: 5| Step: 8
Training loss: 2.6481761932373047
Validation loss: 2.005110006178579

Epoch: 5| Step: 9
Training loss: 2.6420304775238037
Validation loss: 2.011252513495825

Epoch: 5| Step: 10
Training loss: 2.5424368381500244
Validation loss: 2.008694005268876

Epoch: 67| Step: 0
Training loss: 2.281978130340576
Validation loss: 2.0071758044663297

Epoch: 5| Step: 1
Training loss: 1.555433988571167
Validation loss: 2.017678338994262

Epoch: 5| Step: 2
Training loss: 1.692824125289917
Validation loss: 2.0049552340661325

Epoch: 5| Step: 3
Training loss: 2.119494915008545
Validation loss: 2.0132637434108283

Epoch: 5| Step: 4
Training loss: 2.1314427852630615
Validation loss: 2.0212621509387927

Epoch: 5| Step: 5
Training loss: 2.73327898979187
Validation loss: 1.9937286030861638

Epoch: 5| Step: 6
Training loss: 2.5373756885528564
Validation loss: 2.0287391857434343

Epoch: 5| Step: 7
Training loss: 2.0664238929748535
Validation loss: 2.02952080388223

Epoch: 5| Step: 8
Training loss: 2.821392059326172
Validation loss: 2.024644841430008

Epoch: 5| Step: 9
Training loss: 2.649653196334839
Validation loss: 2.004034388449884

Epoch: 5| Step: 10
Training loss: 2.334308385848999
Validation loss: 2.0043675809778194

Epoch: 68| Step: 0
Training loss: 1.9511373043060303
Validation loss: 2.022433873145811

Epoch: 5| Step: 1
Training loss: 1.8983474969863892
Validation loss: 2.015713398174573

Epoch: 5| Step: 2
Training loss: 2.669752359390259
Validation loss: 2.010584312100564

Epoch: 5| Step: 3
Training loss: 3.157886505126953
Validation loss: 2.006691144358727

Epoch: 5| Step: 4
Training loss: 2.0642542839050293
Validation loss: 2.0154901114843224

Epoch: 5| Step: 5
Training loss: 2.308927059173584
Validation loss: 2.033194698313231

Epoch: 5| Step: 6
Training loss: 2.402423858642578
Validation loss: 2.0162306293364494

Epoch: 5| Step: 7
Training loss: 2.275848150253296
Validation loss: 2.0210823153936737

Epoch: 5| Step: 8
Training loss: 1.9906530380249023
Validation loss: 2.025924644162578

Epoch: 5| Step: 9
Training loss: 2.1096205711364746
Validation loss: 2.016035670875221

Epoch: 5| Step: 10
Training loss: 1.8189070224761963
Validation loss: 2.0286875540210354

Epoch: 69| Step: 0
Training loss: 1.728219985961914
Validation loss: 2.0249058072284987

Epoch: 5| Step: 1
Training loss: 2.83651065826416
Validation loss: 2.0288533446609334

Epoch: 5| Step: 2
Training loss: 2.1980316638946533
Validation loss: 2.021894157573741

Epoch: 5| Step: 3
Training loss: 2.237034320831299
Validation loss: 2.029795100612025

Epoch: 5| Step: 4
Training loss: 1.9364649057388306
Validation loss: 2.0159454871249456

Epoch: 5| Step: 5
Training loss: 1.932399034500122
Validation loss: 2.0235764057405534

Epoch: 5| Step: 6
Training loss: 2.7761387825012207
Validation loss: 2.028651665615779

Epoch: 5| Step: 7
Training loss: 2.7143049240112305
Validation loss: 2.0280422151729627

Epoch: 5| Step: 8
Training loss: 2.4018635749816895
Validation loss: 2.0318743246857838

Epoch: 5| Step: 9
Training loss: 1.8422256708145142
Validation loss: 2.043384328965218

Epoch: 5| Step: 10
Training loss: 2.233258008956909
Validation loss: 2.0328889559674006

Epoch: 70| Step: 0
Training loss: 1.5323398113250732
Validation loss: 2.0255058503920034

Epoch: 5| Step: 1
Training loss: 1.9057937860488892
Validation loss: 2.0244557190966863

Epoch: 5| Step: 2
Training loss: 2.533846616744995
Validation loss: 2.019585418444808

Epoch: 5| Step: 3
Training loss: 2.28523588180542
Validation loss: 2.0268593552292034

Epoch: 5| Step: 4
Training loss: 1.8549245595932007
Validation loss: 2.0228521182972896

Epoch: 5| Step: 5
Training loss: 2.433776378631592
Validation loss: 2.04025206001856

Epoch: 5| Step: 6
Training loss: 2.980053424835205
Validation loss: 2.024580599159323

Epoch: 5| Step: 7
Training loss: 2.102576494216919
Validation loss: 2.024716986122952

Epoch: 5| Step: 8
Training loss: 2.38006329536438
Validation loss: 2.0206775434555544

Epoch: 5| Step: 9
Training loss: 2.838351249694824
Validation loss: 2.023327394198346

Epoch: 5| Step: 10
Training loss: 1.7717735767364502
Validation loss: 2.0273115596463605

Epoch: 71| Step: 0
Training loss: 3.358724594116211
Validation loss: 2.032929928072037

Epoch: 5| Step: 1
Training loss: 2.2586188316345215
Validation loss: 2.0271917056011897

Epoch: 5| Step: 2
Training loss: 2.3793742656707764
Validation loss: 2.01157074077155

Epoch: 5| Step: 3
Training loss: 2.016324996948242
Validation loss: 2.0184377880506617

Epoch: 5| Step: 4
Training loss: 2.5247483253479004
Validation loss: 2.0247888308699413

Epoch: 5| Step: 5
Training loss: 2.4576282501220703
Validation loss: 2.017075423271425

Epoch: 5| Step: 6
Training loss: 1.5559003353118896
Validation loss: 2.014171669560094

Epoch: 5| Step: 7
Training loss: 2.005234718322754
Validation loss: 2.021348435391662

Epoch: 5| Step: 8
Training loss: 1.9896339178085327
Validation loss: 1.999677937517884

Epoch: 5| Step: 9
Training loss: 2.246063709259033
Validation loss: 2.024449761195849

Epoch: 5| Step: 10
Training loss: 1.7718263864517212
Validation loss: 2.0035201170111216

Epoch: 72| Step: 0
Training loss: 1.9459835290908813
Validation loss: 2.0142283696000294

Epoch: 5| Step: 1
Training loss: 2.139052629470825
Validation loss: 2.0119315757546374

Epoch: 5| Step: 2
Training loss: 2.876671075820923
Validation loss: 2.0298199345988612

Epoch: 5| Step: 3
Training loss: 2.3825459480285645
Validation loss: 2.0065670500519457

Epoch: 5| Step: 4
Training loss: 2.4782676696777344
Validation loss: 2.0230695201504614

Epoch: 5| Step: 5
Training loss: 1.7484276294708252
Validation loss: 2.0298088532622143

Epoch: 5| Step: 6
Training loss: 1.6714410781860352
Validation loss: 2.0189429508742465

Epoch: 5| Step: 7
Training loss: 2.4153835773468018
Validation loss: 2.023329047746556

Epoch: 5| Step: 8
Training loss: 2.147550106048584
Validation loss: 2.025798752743711

Epoch: 5| Step: 9
Training loss: 2.4412503242492676
Validation loss: 2.0153967475378387

Epoch: 5| Step: 10
Training loss: 2.5013866424560547
Validation loss: 2.021870736152895

Epoch: 73| Step: 0
Training loss: 2.2958614826202393
Validation loss: 2.028822907837488

Epoch: 5| Step: 1
Training loss: 1.9700708389282227
Validation loss: 2.031398473247405

Epoch: 5| Step: 2
Training loss: 2.667154312133789
Validation loss: 2.018671001157453

Epoch: 5| Step: 3
Training loss: 2.0756592750549316
Validation loss: 2.025210495918028

Epoch: 5| Step: 4
Training loss: 2.269118070602417
Validation loss: 2.018285080950747

Epoch: 5| Step: 5
Training loss: 2.0537219047546387
Validation loss: 2.0183567231701267

Epoch: 5| Step: 6
Training loss: 2.3122928142547607
Validation loss: 2.016950111235342

Epoch: 5| Step: 7
Training loss: 2.7328782081604004
Validation loss: 2.021797549340033

Epoch: 5| Step: 8
Training loss: 2.2820401191711426
Validation loss: 2.024837804097001

Epoch: 5| Step: 9
Training loss: 2.024506092071533
Validation loss: 2.024843758152377

Epoch: 5| Step: 10
Training loss: 1.8998585939407349
Validation loss: 2.016628974227495

Epoch: 74| Step: 0
Training loss: 2.4952235221862793
Validation loss: 2.01314821550923

Epoch: 5| Step: 1
Training loss: 2.07491397857666
Validation loss: 2.0150890017068512

Epoch: 5| Step: 2
Training loss: 2.695817708969116
Validation loss: 2.0204840808786373

Epoch: 5| Step: 3
Training loss: 1.6980270147323608
Validation loss: 2.0147905119003786

Epoch: 5| Step: 4
Training loss: 2.043900966644287
Validation loss: 2.0236620903015137

Epoch: 5| Step: 5
Training loss: 2.317770481109619
Validation loss: 2.010231266739548

Epoch: 5| Step: 6
Training loss: 1.9385474920272827
Validation loss: 1.9988831922572146

Epoch: 5| Step: 7
Training loss: 3.1761558055877686
Validation loss: 2.031339050621115

Epoch: 5| Step: 8
Training loss: 2.4714627265930176
Validation loss: 2.015468107756748

Epoch: 5| Step: 9
Training loss: 1.818067193031311
Validation loss: 2.0136013172006093

Epoch: 5| Step: 10
Training loss: 1.8875114917755127
Validation loss: 2.01746492872956

Epoch: 75| Step: 0
Training loss: 2.138181686401367
Validation loss: 2.015750531227358

Epoch: 5| Step: 1
Training loss: 1.6542415618896484
Validation loss: 2.009873681170966

Epoch: 5| Step: 2
Training loss: 2.6431221961975098
Validation loss: 2.003855134851189

Epoch: 5| Step: 3
Training loss: 2.395580291748047
Validation loss: 2.0186024686341644

Epoch: 5| Step: 4
Training loss: 2.0274486541748047
Validation loss: 2.024924910196694

Epoch: 5| Step: 5
Training loss: 2.4259467124938965
Validation loss: 2.0226398206526235

Epoch: 5| Step: 6
Training loss: 2.4005074501037598
Validation loss: 2.0137015478585356

Epoch: 5| Step: 7
Training loss: 1.7463443279266357
Validation loss: 2.012479628286054

Epoch: 5| Step: 8
Training loss: 2.7499687671661377
Validation loss: 2.007484056616342

Epoch: 5| Step: 9
Training loss: 2.335639476776123
Validation loss: 2.008634792861118

Epoch: 5| Step: 10
Training loss: 2.128368854522705
Validation loss: 2.0260002151612313

Epoch: 76| Step: 0
Training loss: 1.6054506301879883
Validation loss: 2.012797799161685

Epoch: 5| Step: 1
Training loss: 3.01608943939209
Validation loss: 2.0100662118645123

Epoch: 5| Step: 2
Training loss: 2.4344170093536377
Validation loss: 2.022779744158509

Epoch: 5| Step: 3
Training loss: 1.9671903848648071
Validation loss: 2.0083529910733624

Epoch: 5| Step: 4
Training loss: 2.128596782684326
Validation loss: 2.0152254412251134

Epoch: 5| Step: 5
Training loss: 2.1794509887695312
Validation loss: 2.0262663851502123

Epoch: 5| Step: 6
Training loss: 2.2044482231140137
Validation loss: 2.027884414119105

Epoch: 5| Step: 7
Training loss: 2.321376323699951
Validation loss: 2.01354536702556

Epoch: 5| Step: 8
Training loss: 2.002241611480713
Validation loss: 1.9972925391248477

Epoch: 5| Step: 9
Training loss: 2.125019073486328
Validation loss: 2.0105742049473587

Epoch: 5| Step: 10
Training loss: 2.630746603012085
Validation loss: 2.0131220599656463

Epoch: 77| Step: 0
Training loss: 2.00347900390625
Validation loss: 2.0281347843908493

Epoch: 5| Step: 1
Training loss: 1.5377804040908813
Validation loss: 2.014581113733271

Epoch: 5| Step: 2
Training loss: 2.5470175743103027
Validation loss: 2.03012498476172

Epoch: 5| Step: 3
Training loss: 2.126225709915161
Validation loss: 2.0230810975515716

Epoch: 5| Step: 4
Training loss: 2.515532970428467
Validation loss: 2.026760451255306

Epoch: 5| Step: 5
Training loss: 2.7152416706085205
Validation loss: 2.0358161708360076

Epoch: 5| Step: 6
Training loss: 2.1197245121002197
Validation loss: 2.0057917461600354

Epoch: 5| Step: 7
Training loss: 2.484476327896118
Validation loss: 2.0185961313145135

Epoch: 5| Step: 8
Training loss: 2.013875722885132
Validation loss: 2.0213965164717806

Epoch: 5| Step: 9
Training loss: 1.9433252811431885
Validation loss: 2.023619700503606

Epoch: 5| Step: 10
Training loss: 2.6282670497894287
Validation loss: 2.016641878312634

Epoch: 78| Step: 0
Training loss: 2.7215142250061035
Validation loss: 2.0407427100725073

Epoch: 5| Step: 1
Training loss: 2.1294426918029785
Validation loss: 2.019536772081929

Epoch: 5| Step: 2
Training loss: 2.0504817962646484
Validation loss: 2.0256774438324796

Epoch: 5| Step: 3
Training loss: 2.328740119934082
Validation loss: 2.038754206831737

Epoch: 5| Step: 4
Training loss: 2.564995050430298
Validation loss: 2.038506466855285

Epoch: 5| Step: 5
Training loss: 1.2440179586410522
Validation loss: 2.0207219777568692

Epoch: 5| Step: 6
Training loss: 2.0850536823272705
Validation loss: 2.0326134081809752

Epoch: 5| Step: 7
Training loss: 2.6115386486053467
Validation loss: 2.018695628771218

Epoch: 5| Step: 8
Training loss: 2.182215452194214
Validation loss: 2.0212169924089984

Epoch: 5| Step: 9
Training loss: 2.347071886062622
Validation loss: 2.0180711566760974

Epoch: 5| Step: 10
Training loss: 2.1141390800476074
Validation loss: 2.0319668451944985

Epoch: 79| Step: 0
Training loss: 2.885871410369873
Validation loss: 2.0142253752677672

Epoch: 5| Step: 1
Training loss: 1.7350867986679077
Validation loss: 2.04116726434359

Epoch: 5| Step: 2
Training loss: 1.4888412952423096
Validation loss: 2.0282124755203084

Epoch: 5| Step: 3
Training loss: 2.3230345249176025
Validation loss: 2.0325566466136644

Epoch: 5| Step: 4
Training loss: 2.2786271572113037
Validation loss: 2.0244719213055027

Epoch: 5| Step: 5
Training loss: 1.7986714839935303
Validation loss: 2.0283067892956477

Epoch: 5| Step: 6
Training loss: 2.639298677444458
Validation loss: 2.03290642205105

Epoch: 5| Step: 7
Training loss: 2.8014159202575684
Validation loss: 2.0168225457591396

Epoch: 5| Step: 8
Training loss: 1.8643348217010498
Validation loss: 2.024481209375525

Epoch: 5| Step: 9
Training loss: 2.455577850341797
Validation loss: 2.043559464075232

Epoch: 5| Step: 10
Training loss: 2.2533726692199707
Validation loss: 2.0437174304839103

Epoch: 80| Step: 0
Training loss: 2.694507122039795
Validation loss: 2.0227407665662867

Epoch: 5| Step: 1
Training loss: 1.879195213317871
Validation loss: 2.0241094340560255

Epoch: 5| Step: 2
Training loss: 2.6054201126098633
Validation loss: 2.0283906652081396

Epoch: 5| Step: 3
Training loss: 2.036339282989502
Validation loss: 2.023535318272088

Epoch: 5| Step: 4
Training loss: 1.6222684383392334
Validation loss: 2.0156874246494745

Epoch: 5| Step: 5
Training loss: 2.6612515449523926
Validation loss: 2.021383531631962

Epoch: 5| Step: 6
Training loss: 1.7311378717422485
Validation loss: 2.025761899127755

Epoch: 5| Step: 7
Training loss: 2.4518790245056152
Validation loss: 2.0040016046134372

Epoch: 5| Step: 8
Training loss: 2.298698902130127
Validation loss: 2.0156472344552316

Epoch: 5| Step: 9
Training loss: 2.626203775405884
Validation loss: 2.0154745886402745

Epoch: 5| Step: 10
Training loss: 1.7778830528259277
Validation loss: 2.013471093229068

Epoch: 81| Step: 0
Training loss: 2.257885217666626
Validation loss: 2.004916266728473

Epoch: 5| Step: 1
Training loss: 1.5301600694656372
Validation loss: 2.0235659627504248

Epoch: 5| Step: 2
Training loss: 2.2086846828460693
Validation loss: 2.005777476936258

Epoch: 5| Step: 3
Training loss: 2.2887632846832275
Validation loss: 2.0240557283483525

Epoch: 5| Step: 4
Training loss: 1.8085542917251587
Validation loss: 2.0242855074585124

Epoch: 5| Step: 5
Training loss: 2.520843029022217
Validation loss: 2.025839823548512

Epoch: 5| Step: 6
Training loss: 2.5439510345458984
Validation loss: 2.021118938281972

Epoch: 5| Step: 7
Training loss: 2.115539789199829
Validation loss: 2.021179155636859

Epoch: 5| Step: 8
Training loss: 2.471407651901245
Validation loss: 2.0231107640010055

Epoch: 5| Step: 9
Training loss: 2.1236307621002197
Validation loss: 2.0292593074101273

Epoch: 5| Step: 10
Training loss: 2.5456409454345703
Validation loss: 2.013311828336408

Epoch: 82| Step: 0
Training loss: 2.297794818878174
Validation loss: 2.0177571465892177

Epoch: 5| Step: 1
Training loss: 2.006277084350586
Validation loss: 2.0161310934251353

Epoch: 5| Step: 2
Training loss: 2.3956151008605957
Validation loss: 2.0311936639970347

Epoch: 5| Step: 3
Training loss: 2.4628074169158936
Validation loss: 2.016251580689543

Epoch: 5| Step: 4
Training loss: 1.6670935153961182
Validation loss: 2.0251877218164425

Epoch: 5| Step: 5
Training loss: 1.8323752880096436
Validation loss: 2.0208228365067513

Epoch: 5| Step: 6
Training loss: 1.9546873569488525
Validation loss: 2.0191438326271633

Epoch: 5| Step: 7
Training loss: 2.315269947052002
Validation loss: 2.026067510727913

Epoch: 5| Step: 8
Training loss: 2.1659395694732666
Validation loss: 2.0140977264732443

Epoch: 5| Step: 9
Training loss: 2.7227835655212402
Validation loss: 2.0063643622142013

Epoch: 5| Step: 10
Training loss: 2.6730093955993652
Validation loss: 2.0194437016722975

Epoch: 83| Step: 0
Training loss: 2.1637682914733887
Validation loss: 2.0436988710075297

Epoch: 5| Step: 1
Training loss: 1.7070915699005127
Validation loss: 2.017412175414383

Epoch: 5| Step: 2
Training loss: 2.2442500591278076
Validation loss: 2.008309507882723

Epoch: 5| Step: 3
Training loss: 2.071524143218994
Validation loss: 2.01032680080783

Epoch: 5| Step: 4
Training loss: 2.1167731285095215
Validation loss: 2.0422872766371696

Epoch: 5| Step: 5
Training loss: 2.29646372795105
Validation loss: 2.0351829221171718

Epoch: 5| Step: 6
Training loss: 2.800360918045044
Validation loss: 2.0189296173793014

Epoch: 5| Step: 7
Training loss: 2.371206045150757
Validation loss: 2.0148107210795083

Epoch: 5| Step: 8
Training loss: 2.3976643085479736
Validation loss: 2.0242167621530514

Epoch: 5| Step: 9
Training loss: 2.0179293155670166
Validation loss: 2.016849396049335

Epoch: 5| Step: 10
Training loss: 2.2270095348358154
Validation loss: 2.022938387368315

Epoch: 84| Step: 0
Training loss: 2.161006450653076
Validation loss: 2.0110552234034382

Epoch: 5| Step: 1
Training loss: 2.6159329414367676
Validation loss: 2.0251355248112834

Epoch: 5| Step: 2
Training loss: 2.2382595539093018
Validation loss: 2.0128530904810917

Epoch: 5| Step: 3
Training loss: 2.2953343391418457
Validation loss: 2.0096443801797848

Epoch: 5| Step: 4
Training loss: 1.7330894470214844
Validation loss: 2.0113166301481185

Epoch: 5| Step: 5
Training loss: 2.6453070640563965
Validation loss: 2.0139124829282045

Epoch: 5| Step: 6
Training loss: 2.104310989379883
Validation loss: 2.017318367958069

Epoch: 5| Step: 7
Training loss: 2.2152531147003174
Validation loss: 2.023860490450295

Epoch: 5| Step: 8
Training loss: 2.1078641414642334
Validation loss: 2.0185935856193624

Epoch: 5| Step: 9
Training loss: 1.862511396408081
Validation loss: 2.0083860505011772

Epoch: 5| Step: 10
Training loss: 2.278660774230957
Validation loss: 2.0128988117300053

Epoch: 85| Step: 0
Training loss: 1.8753993511199951
Validation loss: 2.0299739837646484

Epoch: 5| Step: 1
Training loss: 2.6469814777374268
Validation loss: 2.019990321128599

Epoch: 5| Step: 2
Training loss: 2.2857048511505127
Validation loss: 2.0300738055218934

Epoch: 5| Step: 3
Training loss: 1.9937078952789307
Validation loss: 2.0149090341342393

Epoch: 5| Step: 4
Training loss: 2.0268616676330566
Validation loss: 2.021033478039567

Epoch: 5| Step: 5
Training loss: 2.041855573654175
Validation loss: 2.0117691204112065

Epoch: 5| Step: 6
Training loss: 1.895249605178833
Validation loss: 2.009021835942422

Epoch: 5| Step: 7
Training loss: 2.2739551067352295
Validation loss: 2.0218785732023177

Epoch: 5| Step: 8
Training loss: 2.706366539001465
Validation loss: 2.0089674329244964

Epoch: 5| Step: 9
Training loss: 2.3006930351257324
Validation loss: 2.006399582791072

Epoch: 5| Step: 10
Training loss: 2.275114059448242
Validation loss: 2.0217174624884002

Epoch: 86| Step: 0
Training loss: 2.310988664627075
Validation loss: 2.024497605139209

Epoch: 5| Step: 1
Training loss: 2.4969723224639893
Validation loss: 2.020034332429209

Epoch: 5| Step: 2
Training loss: 2.1838111877441406
Validation loss: 2.0246090350612516

Epoch: 5| Step: 3
Training loss: 1.6577396392822266
Validation loss: 2.014659332972701

Epoch: 5| Step: 4
Training loss: 2.433495283126831
Validation loss: 2.0171001444580736

Epoch: 5| Step: 5
Training loss: 2.343461513519287
Validation loss: 2.0090885546899613

Epoch: 5| Step: 6
Training loss: 2.1734211444854736
Validation loss: 2.015796426803835

Epoch: 5| Step: 7
Training loss: 1.884479284286499
Validation loss: 2.0292979901836765

Epoch: 5| Step: 8
Training loss: 2.5073294639587402
Validation loss: 2.0343642029710995

Epoch: 5| Step: 9
Training loss: 2.3058886528015137
Validation loss: 2.026079862348495

Epoch: 5| Step: 10
Training loss: 1.9093468189239502
Validation loss: 2.025453213722475

Epoch: 87| Step: 0
Training loss: 2.4625489711761475
Validation loss: 2.020236207592872

Epoch: 5| Step: 1
Training loss: 2.5851287841796875
Validation loss: 2.0256033866636214

Epoch: 5| Step: 2
Training loss: 2.129817485809326
Validation loss: 2.031137656140071

Epoch: 5| Step: 3
Training loss: 2.3261616230010986
Validation loss: 2.0214840622358423

Epoch: 5| Step: 4
Training loss: 2.213500499725342
Validation loss: 2.0301768690027218

Epoch: 5| Step: 5
Training loss: 2.230867862701416
Validation loss: 2.0188524197506648

Epoch: 5| Step: 6
Training loss: 2.2849621772766113
Validation loss: 2.009699611253636

Epoch: 5| Step: 7
Training loss: 1.8761478662490845
Validation loss: 2.0176853364513767

Epoch: 5| Step: 8
Training loss: 2.212031602859497
Validation loss: 2.0155678641411567

Epoch: 5| Step: 9
Training loss: 1.8897987604141235
Validation loss: 2.0303688638953754

Epoch: 5| Step: 10
Training loss: 2.018998622894287
Validation loss: 2.0260929728067048

Epoch: 88| Step: 0
Training loss: 2.9669883251190186
Validation loss: 2.030016981145387

Epoch: 5| Step: 1
Training loss: 2.6398227214813232
Validation loss: 2.01877232520811

Epoch: 5| Step: 2
Training loss: 1.9083096981048584
Validation loss: 2.011654605147659

Epoch: 5| Step: 3
Training loss: 2.464521884918213
Validation loss: 2.0248704161695255

Epoch: 5| Step: 4
Training loss: 3.1157119274139404
Validation loss: 2.0216408455243675

Epoch: 5| Step: 5
Training loss: 1.6260273456573486
Validation loss: 2.0102255536663916

Epoch: 5| Step: 6
Training loss: 1.9112449884414673
Validation loss: 2.022621326549079

Epoch: 5| Step: 7
Training loss: 1.9618489742279053
Validation loss: 2.0376447682739585

Epoch: 5| Step: 8
Training loss: 1.38703191280365
Validation loss: 2.029049796442832

Epoch: 5| Step: 9
Training loss: 2.070913791656494
Validation loss: 2.041699299248316

Epoch: 5| Step: 10
Training loss: 2.1249592304229736
Validation loss: 2.017807901546519

Epoch: 89| Step: 0
Training loss: 2.40335750579834
Validation loss: 2.020795911870977

Epoch: 5| Step: 1
Training loss: 2.2883358001708984
Validation loss: 2.028308765862578

Epoch: 5| Step: 2
Training loss: 1.9697134494781494
Validation loss: 2.0374497777672222

Epoch: 5| Step: 3
Training loss: 1.7820380926132202
Validation loss: 2.042968596181562

Epoch: 5| Step: 4
Training loss: 2.325392484664917
Validation loss: 2.028043734130039

Epoch: 5| Step: 5
Training loss: 2.8840904235839844
Validation loss: 2.0202932357788086

Epoch: 5| Step: 6
Training loss: 1.6961148977279663
Validation loss: 2.033984148374168

Epoch: 5| Step: 7
Training loss: 2.2049310207366943
Validation loss: 2.034663197814777

Epoch: 5| Step: 8
Training loss: 1.9315952062606812
Validation loss: 2.0202373996857674

Epoch: 5| Step: 9
Training loss: 2.6405208110809326
Validation loss: 2.0072364345673592

Epoch: 5| Step: 10
Training loss: 2.02630352973938
Validation loss: 2.0052444191389185

Epoch: 90| Step: 0
Training loss: 1.8044334650039673
Validation loss: 2.0065869387759956

Epoch: 5| Step: 1
Training loss: 2.9675984382629395
Validation loss: 2.032599736285466

Epoch: 5| Step: 2
Training loss: 1.620162010192871
Validation loss: 2.0175553752530004

Epoch: 5| Step: 3
Training loss: 2.457368850708008
Validation loss: 2.034984148958678

Epoch: 5| Step: 4
Training loss: 2.906968355178833
Validation loss: 2.012133836746216

Epoch: 5| Step: 5
Training loss: 2.3255972862243652
Validation loss: 2.012449283753672

Epoch: 5| Step: 6
Training loss: 2.24714994430542
Validation loss: 1.9981525175033077

Epoch: 5| Step: 7
Training loss: 2.0283713340759277
Validation loss: 2.011681431083269

Epoch: 5| Step: 8
Training loss: 1.930295705795288
Validation loss: 2.0295492551660024

Epoch: 5| Step: 9
Training loss: 1.8150310516357422
Validation loss: 2.0141296207263903

Epoch: 5| Step: 10
Training loss: 1.958593487739563
Validation loss: 2.03083102421094

Epoch: 91| Step: 0
Training loss: 2.2272543907165527
Validation loss: 2.026308185310774

Epoch: 5| Step: 1
Training loss: 2.330087423324585
Validation loss: 2.007420139928018

Epoch: 5| Step: 2
Training loss: 2.684009075164795
Validation loss: 2.0162961201001237

Epoch: 5| Step: 3
Training loss: 2.063264846801758
Validation loss: 2.0363700569316907

Epoch: 5| Step: 4
Training loss: 1.8214800357818604
Validation loss: 2.030638038471181

Epoch: 5| Step: 5
Training loss: 2.0932514667510986
Validation loss: 2.0243188181231098

Epoch: 5| Step: 6
Training loss: 1.8099920749664307
Validation loss: 2.0165971838017946

Epoch: 5| Step: 7
Training loss: 2.5335311889648438
Validation loss: 2.034588408726518

Epoch: 5| Step: 8
Training loss: 2.476057767868042
Validation loss: 2.021521237588698

Epoch: 5| Step: 9
Training loss: 2.1360878944396973
Validation loss: 2.024191133437618

Epoch: 5| Step: 10
Training loss: 2.1050970554351807
Validation loss: 2.0149003305742816

Epoch: 92| Step: 0
Training loss: 2.243649959564209
Validation loss: 2.01478337728849

Epoch: 5| Step: 1
Training loss: 2.1296863555908203
Validation loss: 2.040160617520732

Epoch: 5| Step: 2
Training loss: 1.9971733093261719
Validation loss: 2.035128019189322

Epoch: 5| Step: 3
Training loss: 2.1920042037963867
Validation loss: 2.025334459479137

Epoch: 5| Step: 4
Training loss: 1.8280296325683594
Validation loss: 2.0190342331445343

Epoch: 5| Step: 5
Training loss: 1.9125442504882812
Validation loss: 2.022526982010052

Epoch: 5| Step: 6
Training loss: 2.4848597049713135
Validation loss: 2.0290044200035835

Epoch: 5| Step: 7
Training loss: 2.7588696479797363
Validation loss: 2.0138096399204706

Epoch: 5| Step: 8
Training loss: 2.384713649749756
Validation loss: 2.0315515713025163

Epoch: 5| Step: 9
Training loss: 2.116914987564087
Validation loss: 2.016946529829374

Epoch: 5| Step: 10
Training loss: 2.0528900623321533
Validation loss: 2.0248532346499863

Epoch: 93| Step: 0
Training loss: 1.7203582525253296
Validation loss: 2.0216040111357167

Epoch: 5| Step: 1
Training loss: 1.373308539390564
Validation loss: 2.021282404981634

Epoch: 5| Step: 2
Training loss: 2.616804599761963
Validation loss: 2.0107803421635784

Epoch: 5| Step: 3
Training loss: 2.248060464859009
Validation loss: 2.0485829743005897

Epoch: 5| Step: 4
Training loss: 2.2577693462371826
Validation loss: 2.0375501494253836

Epoch: 5| Step: 5
Training loss: 2.434873580932617
Validation loss: 2.0406149343777726

Epoch: 5| Step: 6
Training loss: 2.1989731788635254
Validation loss: 2.0170500586109776

Epoch: 5| Step: 7
Training loss: 2.4645893573760986
Validation loss: 2.0027107782261346

Epoch: 5| Step: 8
Training loss: 2.7448573112487793
Validation loss: 2.0055268246640443

Epoch: 5| Step: 9
Training loss: 1.534896969795227
Validation loss: 2.015202781205536

Epoch: 5| Step: 10
Training loss: 2.5086798667907715
Validation loss: 1.9963040595413537

Epoch: 94| Step: 0
Training loss: 2.259838581085205
Validation loss: 2.0124716912546465

Epoch: 5| Step: 1
Training loss: 2.088015079498291
Validation loss: 2.022911961360644

Epoch: 5| Step: 2
Training loss: 2.060082197189331
Validation loss: 2.027803051856256

Epoch: 5| Step: 3
Training loss: 1.906987190246582
Validation loss: 2.0159912814376173

Epoch: 5| Step: 4
Training loss: 2.508035182952881
Validation loss: 2.0053555991059993

Epoch: 5| Step: 5
Training loss: 1.6525065898895264
Validation loss: 2.0154723018728276

Epoch: 5| Step: 6
Training loss: 2.4456117153167725
Validation loss: 2.02776401786394

Epoch: 5| Step: 7
Training loss: 1.6686174869537354
Validation loss: 2.020548548749698

Epoch: 5| Step: 8
Training loss: 2.3466696739196777
Validation loss: 2.020428522940605

Epoch: 5| Step: 9
Training loss: 2.387608766555786
Validation loss: 2.025766829008697

Epoch: 5| Step: 10
Training loss: 2.7697534561157227
Validation loss: 2.02666530429676

Epoch: 95| Step: 0
Training loss: 2.6569876670837402
Validation loss: 2.0332287588427143

Epoch: 5| Step: 1
Training loss: 2.6789908409118652
Validation loss: 2.0257142743756695

Epoch: 5| Step: 2
Training loss: 2.17510986328125
Validation loss: 2.035532454008697

Epoch: 5| Step: 3
Training loss: 1.848048210144043
Validation loss: 2.0110535160187752

Epoch: 5| Step: 4
Training loss: 1.6313947439193726
Validation loss: 2.027893166388235

Epoch: 5| Step: 5
Training loss: 2.2207207679748535
Validation loss: 2.0194070185384443

Epoch: 5| Step: 6
Training loss: 1.6684672832489014
Validation loss: 2.041590775212934

Epoch: 5| Step: 7
Training loss: 2.0381293296813965
Validation loss: 2.0244696729926654

Epoch: 5| Step: 8
Training loss: 2.375059127807617
Validation loss: 2.0164534994350967

Epoch: 5| Step: 9
Training loss: 2.500941514968872
Validation loss: 2.0171537565928634

Epoch: 5| Step: 10
Training loss: 2.3077855110168457
Validation loss: 2.027028542692943

Epoch: 96| Step: 0
Training loss: 2.666883945465088
Validation loss: 2.0208525901199668

Epoch: 5| Step: 1
Training loss: 1.855987548828125
Validation loss: 2.0238881982782835

Epoch: 5| Step: 2
Training loss: 1.8450372219085693
Validation loss: 2.0102692137482348

Epoch: 5| Step: 3
Training loss: 2.4891066551208496
Validation loss: 2.0197250817411687

Epoch: 5| Step: 4
Training loss: 2.0558266639709473
Validation loss: 2.026125900207027

Epoch: 5| Step: 5
Training loss: 2.188246250152588
Validation loss: 2.0040109439562728

Epoch: 5| Step: 6
Training loss: 1.816952109336853
Validation loss: 2.0191263947435605

Epoch: 5| Step: 7
Training loss: 3.0607151985168457
Validation loss: 2.0334056833738923

Epoch: 5| Step: 8
Training loss: 2.044009208679199
Validation loss: 2.0157950206469466

Epoch: 5| Step: 9
Training loss: 2.323192834854126
Validation loss: 2.0105952037278043

Epoch: 5| Step: 10
Training loss: 1.663618564605713
Validation loss: 2.004770557085673

Epoch: 97| Step: 0
Training loss: 2.073904514312744
Validation loss: 2.023510049748164

Epoch: 5| Step: 1
Training loss: 1.6947853565216064
Validation loss: 2.0074744532185216

Epoch: 5| Step: 2
Training loss: 1.7671016454696655
Validation loss: 2.005108820494785

Epoch: 5| Step: 3
Training loss: 2.5528488159179688
Validation loss: 2.021602617797031

Epoch: 5| Step: 4
Training loss: 2.3573899269104004
Validation loss: 2.0116503828315326

Epoch: 5| Step: 5
Training loss: 1.995032548904419
Validation loss: 2.0174942221692813

Epoch: 5| Step: 6
Training loss: 1.9897037744522095
Validation loss: 2.0116499470126246

Epoch: 5| Step: 7
Training loss: 2.241213321685791
Validation loss: 2.012618923699984

Epoch: 5| Step: 8
Training loss: 2.626094341278076
Validation loss: 2.036662450400732

Epoch: 5| Step: 9
Training loss: 2.3024895191192627
Validation loss: 2.0146944753585325

Epoch: 5| Step: 10
Training loss: 2.280365467071533
Validation loss: 2.021979888280233

Epoch: 98| Step: 0
Training loss: 2.544620990753174
Validation loss: 2.0259548079582954

Epoch: 5| Step: 1
Training loss: 1.6559932231903076
Validation loss: 2.0386920846918577

Epoch: 5| Step: 2
Training loss: 1.5643212795257568
Validation loss: 2.0147880969509

Epoch: 5| Step: 3
Training loss: 1.9460980892181396
Validation loss: 2.0238462596811275

Epoch: 5| Step: 4
Training loss: 2.3036041259765625
Validation loss: 2.021373910288657

Epoch: 5| Step: 5
Training loss: 2.236778736114502
Validation loss: 2.0267541972539758

Epoch: 5| Step: 6
Training loss: 2.168851375579834
Validation loss: 2.0037884045672674

Epoch: 5| Step: 7
Training loss: 1.6324806213378906
Validation loss: 2.0048476290959183

Epoch: 5| Step: 8
Training loss: 1.9417979717254639
Validation loss: 2.0265596284661243

Epoch: 5| Step: 9
Training loss: 2.7713756561279297
Validation loss: 2.0299566817539993

Epoch: 5| Step: 10
Training loss: 3.2796900272369385
Validation loss: 2.0159045662931216

Epoch: 99| Step: 0
Training loss: 1.864834189414978
Validation loss: 2.022097441457933

Epoch: 5| Step: 1
Training loss: 3.146918296813965
Validation loss: 2.0168392145505516

Epoch: 5| Step: 2
Training loss: 2.4251976013183594
Validation loss: 2.01229678943593

Epoch: 5| Step: 3
Training loss: 1.7789461612701416
Validation loss: 2.0353562588332803

Epoch: 5| Step: 4
Training loss: 2.167963743209839
Validation loss: 2.009589672088623

Epoch: 5| Step: 5
Training loss: 1.8301918506622314
Validation loss: 2.022421749689246

Epoch: 5| Step: 6
Training loss: 2.0328001976013184
Validation loss: 2.012530626789216

Epoch: 5| Step: 7
Training loss: 1.9631268978118896
Validation loss: 2.0365863756466935

Epoch: 5| Step: 8
Training loss: 2.1613259315490723
Validation loss: 2.028580152860252

Epoch: 5| Step: 9
Training loss: 2.2142574787139893
Validation loss: 2.0323436619133077

Epoch: 5| Step: 10
Training loss: 2.3623428344726562
Validation loss: 2.0452259176520893

Epoch: 100| Step: 0
Training loss: 2.003000020980835
Validation loss: 2.0329104162031606

Epoch: 5| Step: 1
Training loss: 2.3720130920410156
Validation loss: 2.0339629034842215

Epoch: 5| Step: 2
Training loss: 2.362729549407959
Validation loss: 2.001082702349591

Epoch: 5| Step: 3
Training loss: 1.8342841863632202
Validation loss: 2.0268196969903927

Epoch: 5| Step: 4
Training loss: 2.4629979133605957
Validation loss: 2.037785171180643

Epoch: 5| Step: 5
Training loss: 2.0858826637268066
Validation loss: 2.02531119444037

Epoch: 5| Step: 6
Training loss: 1.8425216674804688
Validation loss: 2.015455465162954

Epoch: 5| Step: 7
Training loss: 1.8822200298309326
Validation loss: 2.02495563414789

Epoch: 5| Step: 8
Training loss: 2.288515567779541
Validation loss: 2.0168826567229403

Epoch: 5| Step: 9
Training loss: 2.442857265472412
Validation loss: 2.0287011695164505

Epoch: 5| Step: 10
Training loss: 2.2899417877197266
Validation loss: 2.017581885860812

Epoch: 101| Step: 0
Training loss: 1.893739938735962
Validation loss: 2.020334777011666

Epoch: 5| Step: 1
Training loss: 2.015233039855957
Validation loss: 2.01255734761556

Epoch: 5| Step: 2
Training loss: 2.203901529312134
Validation loss: 2.0238339490787958

Epoch: 5| Step: 3
Training loss: 2.124739170074463
Validation loss: 2.027616362417898

Epoch: 5| Step: 4
Training loss: 2.512697696685791
Validation loss: 2.029271255257309

Epoch: 5| Step: 5
Training loss: 1.9567043781280518
Validation loss: 2.030485604398994

Epoch: 5| Step: 6
Training loss: 3.1087849140167236
Validation loss: 2.0330377471062446

Epoch: 5| Step: 7
Training loss: 2.1804277896881104
Validation loss: 2.0233396163550754

Epoch: 5| Step: 8
Training loss: 1.8085758686065674
Validation loss: 2.0158627084506455

Epoch: 5| Step: 9
Training loss: 1.9564399719238281
Validation loss: 2.036574879000264

Epoch: 5| Step: 10
Training loss: 2.1947569847106934
Validation loss: 2.030614164567763

Epoch: 102| Step: 0
Training loss: 2.3988940715789795
Validation loss: 2.022857389142436

Epoch: 5| Step: 1
Training loss: 2.3356773853302
Validation loss: 2.0310568168599117

Epoch: 5| Step: 2
Training loss: 1.4706491231918335
Validation loss: 2.041086591700072

Epoch: 5| Step: 3
Training loss: 2.1644468307495117
Validation loss: 2.0324655860982914

Epoch: 5| Step: 4
Training loss: 2.1347155570983887
Validation loss: 2.008574539615262

Epoch: 5| Step: 5
Training loss: 1.3236238956451416
Validation loss: 2.0036287025738786

Epoch: 5| Step: 6
Training loss: 2.1667799949645996
Validation loss: 2.022026261975688

Epoch: 5| Step: 7
Training loss: 2.718606472015381
Validation loss: 2.007180844583819

Epoch: 5| Step: 8
Training loss: 2.251732349395752
Validation loss: 2.0295856101538545

Epoch: 5| Step: 9
Training loss: 2.2499749660491943
Validation loss: 2.0237951509414183

Epoch: 5| Step: 10
Training loss: 2.643294095993042
Validation loss: 2.006573134852994

Epoch: 103| Step: 0
Training loss: 2.4289329051971436
Validation loss: 2.001514668105751

Epoch: 5| Step: 1
Training loss: 2.6988205909729004
Validation loss: 2.02537057604841

Epoch: 5| Step: 2
Training loss: 2.02912974357605
Validation loss: 2.007920024215534

Epoch: 5| Step: 3
Training loss: 2.3426012992858887
Validation loss: 2.030726892973787

Epoch: 5| Step: 4
Training loss: 1.8391940593719482
Validation loss: 2.0282568662397322

Epoch: 5| Step: 5
Training loss: 2.359180450439453
Validation loss: 2.010824300909555

Epoch: 5| Step: 6
Training loss: 2.216508388519287
Validation loss: 2.029356063053172

Epoch: 5| Step: 7
Training loss: 2.0044612884521484
Validation loss: 2.017965437263571

Epoch: 5| Step: 8
Training loss: 1.5145900249481201
Validation loss: 2.0149409694056355

Epoch: 5| Step: 9
Training loss: 2.11112904548645
Validation loss: 2.0244719777055966

Epoch: 5| Step: 10
Training loss: 2.2221310138702393
Validation loss: 2.0318509173649613

Epoch: 104| Step: 0
Training loss: 2.629000186920166
Validation loss: 2.0214065223611812

Epoch: 5| Step: 1
Training loss: 2.3854053020477295
Validation loss: 2.023771632102228

Epoch: 5| Step: 2
Training loss: 1.8938703536987305
Validation loss: 2.0087693660489974

Epoch: 5| Step: 3
Training loss: 1.7722549438476562
Validation loss: 2.0279983922999394

Epoch: 5| Step: 4
Training loss: 2.1951069831848145
Validation loss: 2.0211369940029678

Epoch: 5| Step: 5
Training loss: 2.077598810195923
Validation loss: 2.0175247397474063

Epoch: 5| Step: 6
Training loss: 1.9433292150497437
Validation loss: 2.0127498539545203

Epoch: 5| Step: 7
Training loss: 2.168952465057373
Validation loss: 2.009739519447409

Epoch: 5| Step: 8
Training loss: 2.248793840408325
Validation loss: 2.0035321866312334

Epoch: 5| Step: 9
Training loss: 2.693744659423828
Validation loss: 2.0426149650286605

Epoch: 5| Step: 10
Training loss: 1.841592788696289
Validation loss: 2.0161294680769726

Epoch: 105| Step: 0
Training loss: 2.4277055263519287
Validation loss: 2.0106951472579793

Epoch: 5| Step: 1
Training loss: 1.8280305862426758
Validation loss: 2.0367879175370738

Epoch: 5| Step: 2
Training loss: 2.039391040802002
Validation loss: 2.015597240899199

Epoch: 5| Step: 3
Training loss: 2.1478493213653564
Validation loss: 2.0232174088878017

Epoch: 5| Step: 4
Training loss: 2.1997885704040527
Validation loss: 2.009642590758621

Epoch: 5| Step: 5
Training loss: 2.4776508808135986
Validation loss: 2.00351773154351

Epoch: 5| Step: 6
Training loss: 1.766300916671753
Validation loss: 2.0096308364663074

Epoch: 5| Step: 7
Training loss: 2.107665538787842
Validation loss: 2.0255029791144916

Epoch: 5| Step: 8
Training loss: 2.1016087532043457
Validation loss: 2.0146460148595993

Epoch: 5| Step: 9
Training loss: 2.613069772720337
Validation loss: 2.0359061469313917

Epoch: 5| Step: 10
Training loss: 2.115171432495117
Validation loss: 2.032569428925873

Epoch: 106| Step: 0
Training loss: 2.2767632007598877
Validation loss: 2.011728112415601

Epoch: 5| Step: 1
Training loss: 1.7937991619110107
Validation loss: 2.0211362428562616

Epoch: 5| Step: 2
Training loss: 1.9725139141082764
Validation loss: 2.026864267164661

Epoch: 5| Step: 3
Training loss: 2.3083462715148926
Validation loss: 2.0269563377544446

Epoch: 5| Step: 4
Training loss: 2.114762544631958
Validation loss: 2.035709583631126

Epoch: 5| Step: 5
Training loss: 1.861846923828125
Validation loss: 2.0318984267532185

Epoch: 5| Step: 6
Training loss: 2.457787036895752
Validation loss: 2.026649193097186

Epoch: 5| Step: 7
Training loss: 2.3319485187530518
Validation loss: 2.027261403299147

Epoch: 5| Step: 8
Training loss: 2.528864860534668
Validation loss: 2.02867401799848

Epoch: 5| Step: 9
Training loss: 1.9002786874771118
Validation loss: 2.020026960680562

Epoch: 5| Step: 10
Training loss: 2.2494349479675293
Validation loss: 2.015668229390216

Epoch: 107| Step: 0
Training loss: 1.6401870250701904
Validation loss: 2.021288715383058

Epoch: 5| Step: 1
Training loss: 1.5409821271896362
Validation loss: 2.017833932753532

Epoch: 5| Step: 2
Training loss: 2.6556248664855957
Validation loss: 2.035933938077701

Epoch: 5| Step: 3
Training loss: 2.335202217102051
Validation loss: 2.0152684360422115

Epoch: 5| Step: 4
Training loss: 2.716944932937622
Validation loss: 2.0216958650978665

Epoch: 5| Step: 5
Training loss: 2.365025043487549
Validation loss: 2.0308683354367494

Epoch: 5| Step: 6
Training loss: 2.0850508213043213
Validation loss: 2.030115323681985

Epoch: 5| Step: 7
Training loss: 1.6311900615692139
Validation loss: 2.0418785502833705

Epoch: 5| Step: 8
Training loss: 2.163667678833008
Validation loss: 2.040285236092024

Epoch: 5| Step: 9
Training loss: 2.1899237632751465
Validation loss: 2.0267273661910847

Epoch: 5| Step: 10
Training loss: 2.4719669818878174
Validation loss: 2.031124808455026

Epoch: 108| Step: 0
Training loss: 2.1555569171905518
Validation loss: 2.040980936378561

Epoch: 5| Step: 1
Training loss: 2.2061548233032227
Validation loss: 2.015523441376225

Epoch: 5| Step: 2
Training loss: 2.842236280441284
Validation loss: 2.0277728393513668

Epoch: 5| Step: 3
Training loss: 2.0900232791900635
Validation loss: 2.0284716224157684

Epoch: 5| Step: 4
Training loss: 1.7447223663330078
Validation loss: 2.017380601616316

Epoch: 5| Step: 5
Training loss: 2.1087021827697754
Validation loss: 2.025994557206349

Epoch: 5| Step: 6
Training loss: 1.686811089515686
Validation loss: 2.0179150078886297

Epoch: 5| Step: 7
Training loss: 1.9920837879180908
Validation loss: 2.028082024666571

Epoch: 5| Step: 8
Training loss: 2.8295750617980957
Validation loss: 2.0049594294640327

Epoch: 5| Step: 9
Training loss: 2.363051652908325
Validation loss: 2.015665554231213

Epoch: 5| Step: 10
Training loss: 1.63726806640625
Validation loss: 2.015416524743521

Epoch: 109| Step: 0
Training loss: 2.67453670501709
Validation loss: 2.0241767796137

Epoch: 5| Step: 1
Training loss: 1.331918716430664
Validation loss: 2.0189591992285942

Epoch: 5| Step: 2
Training loss: 2.4544918537139893
Validation loss: 2.0156589323474514

Epoch: 5| Step: 3
Training loss: 1.6964502334594727
Validation loss: 2.020624347912368

Epoch: 5| Step: 4
Training loss: 2.6886096000671387
Validation loss: 2.0258667161387782

Epoch: 5| Step: 5
Training loss: 2.0199806690216064
Validation loss: 2.0263609706714587

Epoch: 5| Step: 6
Training loss: 2.216073989868164
Validation loss: 2.0289076810242026

Epoch: 5| Step: 7
Training loss: 1.9986059665679932
Validation loss: 2.0356376042930027

Epoch: 5| Step: 8
Training loss: 2.5875515937805176
Validation loss: 2.0004690706088977

Epoch: 5| Step: 9
Training loss: 1.6238987445831299
Validation loss: 2.0238439113863054

Epoch: 5| Step: 10
Training loss: 2.403475761413574
Validation loss: 2.011464253548653

Epoch: 110| Step: 0
Training loss: 2.5478546619415283
Validation loss: 2.026686191558838

Epoch: 5| Step: 1
Training loss: 1.93212890625
Validation loss: 2.005561928595266

Epoch: 5| Step: 2
Training loss: 1.9560744762420654
Validation loss: 2.017005119272458

Epoch: 5| Step: 3
Training loss: 2.4534249305725098
Validation loss: 2.0205520968283377

Epoch: 5| Step: 4
Training loss: 3.069232225418091
Validation loss: 2.027503011047199

Epoch: 5| Step: 5
Training loss: 2.135831594467163
Validation loss: 2.0049072978317097

Epoch: 5| Step: 6
Training loss: 1.4555456638336182
Validation loss: 1.9918154119163431

Epoch: 5| Step: 7
Training loss: 1.9711596965789795
Validation loss: 2.017097960236252

Epoch: 5| Step: 8
Training loss: 1.652345895767212
Validation loss: 2.0152666184210006

Epoch: 5| Step: 9
Training loss: 1.8711344003677368
Validation loss: 2.013126891146424

Epoch: 5| Step: 10
Training loss: 2.7299392223358154
Validation loss: 2.0398369014904065

Epoch: 111| Step: 0
Training loss: 1.6648277044296265
Validation loss: 2.0108952599187053

Epoch: 5| Step: 1
Training loss: 2.5565438270568848
Validation loss: 2.0099249475745746

Epoch: 5| Step: 2
Training loss: 1.9257545471191406
Validation loss: 2.0192223082306566

Epoch: 5| Step: 3
Training loss: 2.1564443111419678
Validation loss: 2.0202204527393466

Epoch: 5| Step: 4
Training loss: 1.571677565574646
Validation loss: 2.0284320333952546

Epoch: 5| Step: 5
Training loss: 2.526167392730713
Validation loss: 2.0216377550555813

Epoch: 5| Step: 6
Training loss: 2.514749526977539
Validation loss: 2.024281512024582

Epoch: 5| Step: 7
Training loss: 1.9537372589111328
Validation loss: 2.035053568501626

Epoch: 5| Step: 8
Training loss: 2.049253463745117
Validation loss: 2.023208133635982

Epoch: 5| Step: 9
Training loss: 2.111323118209839
Validation loss: 2.034235441556541

Epoch: 5| Step: 10
Training loss: 2.8376853466033936
Validation loss: 2.0248766663253948

Epoch: 112| Step: 0
Training loss: 2.1343212127685547
Validation loss: 2.0392694934721916

Epoch: 5| Step: 1
Training loss: 1.930996298789978
Validation loss: 2.025992644730435

Epoch: 5| Step: 2
Training loss: 2.171966314315796
Validation loss: 2.011887437553816

Epoch: 5| Step: 3
Training loss: 2.2321407794952393
Validation loss: 2.023941074648211

Epoch: 5| Step: 4
Training loss: 2.288052797317505
Validation loss: 2.024275633596605

Epoch: 5| Step: 5
Training loss: 2.286431074142456
Validation loss: 2.0120786646360993

Epoch: 5| Step: 6
Training loss: 1.7293792963027954
Validation loss: 2.030620330123491

Epoch: 5| Step: 7
Training loss: 2.233914852142334
Validation loss: 2.0348253198849258

Epoch: 5| Step: 8
Training loss: 1.895367980003357
Validation loss: 2.0212970356787405

Epoch: 5| Step: 9
Training loss: 2.3935492038726807
Validation loss: 2.0084232540540796

Epoch: 5| Step: 10
Training loss: 2.4964656829833984
Validation loss: 2.014822688153995

Epoch: 113| Step: 0
Training loss: 1.8020036220550537
Validation loss: 2.0088606611374886

Epoch: 5| Step: 1
Training loss: 2.425436496734619
Validation loss: 2.0181146308939946

Epoch: 5| Step: 2
Training loss: 2.256834030151367
Validation loss: 2.023651592193111

Epoch: 5| Step: 3
Training loss: 2.140868663787842
Validation loss: 2.0158735834142214

Epoch: 5| Step: 4
Training loss: 1.8228180408477783
Validation loss: 2.030579932274357

Epoch: 5| Step: 5
Training loss: 1.996019721031189
Validation loss: 2.0300333012816725

Epoch: 5| Step: 6
Training loss: 1.8394038677215576
Validation loss: 2.0232292400893344

Epoch: 5| Step: 7
Training loss: 2.057380199432373
Validation loss: 2.0406787305749874

Epoch: 5| Step: 8
Training loss: 2.028728723526001
Validation loss: 2.009271611449539

Epoch: 5| Step: 9
Training loss: 2.740774393081665
Validation loss: 2.0273895238035466

Epoch: 5| Step: 10
Training loss: 2.5733351707458496
Validation loss: 2.019323008034819

Epoch: 114| Step: 0
Training loss: 2.1551904678344727
Validation loss: 2.008814432287729

Epoch: 5| Step: 1
Training loss: 2.0912375450134277
Validation loss: 2.0255937525021133

Epoch: 5| Step: 2
Training loss: 1.4446519613265991
Validation loss: 2.0085267251537693

Epoch: 5| Step: 3
Training loss: 2.560605764389038
Validation loss: 2.0218565822929464

Epoch: 5| Step: 4
Training loss: 2.2052695751190186
Validation loss: 2.0296151996940694

Epoch: 5| Step: 5
Training loss: 2.458334445953369
Validation loss: 2.036131840880199

Epoch: 5| Step: 6
Training loss: 2.3504936695098877
Validation loss: 2.040849539541429

Epoch: 5| Step: 7
Training loss: 2.0375399589538574
Validation loss: 2.0311576089551373

Epoch: 5| Step: 8
Training loss: 2.0344581604003906
Validation loss: 2.035950569696324

Epoch: 5| Step: 9
Training loss: 2.0509696006774902
Validation loss: 2.041936989753477

Epoch: 5| Step: 10
Training loss: 2.293783664703369
Validation loss: 2.029727174389747

Epoch: 115| Step: 0
Training loss: 1.7779619693756104
Validation loss: 2.0341777929695706

Epoch: 5| Step: 1
Training loss: 2.4366674423217773
Validation loss: 2.0310462546604935

Epoch: 5| Step: 2
Training loss: 2.736758232116699
Validation loss: 2.0193621073999712

Epoch: 5| Step: 3
Training loss: 2.038285732269287
Validation loss: 2.027802485291676

Epoch: 5| Step: 4
Training loss: 2.2187323570251465
Validation loss: 2.036826810529155

Epoch: 5| Step: 5
Training loss: 1.7842832803726196
Validation loss: 2.0402147270018056

Epoch: 5| Step: 6
Training loss: 2.4971022605895996
Validation loss: 2.000309310933595

Epoch: 5| Step: 7
Training loss: 1.9052963256835938
Validation loss: 2.001848416943704

Epoch: 5| Step: 8
Training loss: 2.4084103107452393
Validation loss: 2.0208595106678624

Epoch: 5| Step: 9
Training loss: 1.4947468042373657
Validation loss: 2.0078456863280265

Epoch: 5| Step: 10
Training loss: 2.5413546562194824
Validation loss: 1.9949778946497108

Epoch: 116| Step: 0
Training loss: 2.2901432514190674
Validation loss: 2.023883455543108

Epoch: 5| Step: 1
Training loss: 2.071993827819824
Validation loss: 2.0098420240545787

Epoch: 5| Step: 2
Training loss: 1.787282943725586
Validation loss: 2.0146914374443794

Epoch: 5| Step: 3
Training loss: 2.2476911544799805
Validation loss: 2.026487191518148

Epoch: 5| Step: 4
Training loss: 2.2840213775634766
Validation loss: 2.0340002224009526

Epoch: 5| Step: 5
Training loss: 1.6583654880523682
Validation loss: 2.034161485651488

Epoch: 5| Step: 6
Training loss: 1.9582494497299194
Validation loss: 2.027374750824385

Epoch: 5| Step: 7
Training loss: 2.456029176712036
Validation loss: 2.0182425834799327

Epoch: 5| Step: 8
Training loss: 2.1765992641448975
Validation loss: 2.0115436789810017

Epoch: 5| Step: 9
Training loss: 2.2015957832336426
Validation loss: 2.0337970923351985

Epoch: 5| Step: 10
Training loss: 2.417102336883545
Validation loss: 2.0168191284261723

Epoch: 117| Step: 0
Training loss: 2.205726146697998
Validation loss: 2.0308659435600362

Epoch: 5| Step: 1
Training loss: 2.1068062782287598
Validation loss: 2.013637219705889

Epoch: 5| Step: 2
Training loss: 1.8432636260986328
Validation loss: 2.0252442001014628

Epoch: 5| Step: 3
Training loss: 2.2302587032318115
Validation loss: 2.023212698198134

Epoch: 5| Step: 4
Training loss: 2.660789966583252
Validation loss: 2.0274082050528577

Epoch: 5| Step: 5
Training loss: 2.021895170211792
Validation loss: 2.0314819607683408

Epoch: 5| Step: 6
Training loss: 2.1718881130218506
Validation loss: 2.015888975512597

Epoch: 5| Step: 7
Training loss: 1.7909847497940063
Validation loss: 2.0454627416467153

Epoch: 5| Step: 8
Training loss: 2.7307186126708984
Validation loss: 2.0189732018337456

Epoch: 5| Step: 9
Training loss: 1.5484062433242798
Validation loss: 2.027978398466623

Epoch: 5| Step: 10
Training loss: 2.186892509460449
Validation loss: 2.022816632383613

Epoch: 118| Step: 0
Training loss: 2.2409491539001465
Validation loss: 2.021931920000302

Epoch: 5| Step: 1
Training loss: 2.3132481575012207
Validation loss: 2.0225705280098865

Epoch: 5| Step: 2
Training loss: 2.289712905883789
Validation loss: 2.0164196568150676

Epoch: 5| Step: 3
Training loss: 1.9198757410049438
Validation loss: 2.0306007862091064

Epoch: 5| Step: 4
Training loss: 2.236154317855835
Validation loss: 2.035189149200275

Epoch: 5| Step: 5
Training loss: 2.2711751461029053
Validation loss: 2.0148904874760616

Epoch: 5| Step: 6
Training loss: 1.7791324853897095
Validation loss: 2.0073071269578833

Epoch: 5| Step: 7
Training loss: 1.6183913946151733
Validation loss: 2.0262271319666216

Epoch: 5| Step: 8
Training loss: 2.421914577484131
Validation loss: 2.020607145883704

Epoch: 5| Step: 9
Training loss: 1.9296772480010986
Validation loss: 2.016104555899097

Epoch: 5| Step: 10
Training loss: 2.445033073425293
Validation loss: 2.0171729467248403

Epoch: 119| Step: 0
Training loss: 1.9915755987167358
Validation loss: 2.0102038255301853

Epoch: 5| Step: 1
Training loss: 1.8940483331680298
Validation loss: 2.0224534080874537

Epoch: 5| Step: 2
Training loss: 2.4710516929626465
Validation loss: 2.0261627025501703

Epoch: 5| Step: 3
Training loss: 2.4556400775909424
Validation loss: 2.0077423511012906

Epoch: 5| Step: 4
Training loss: 1.9890435934066772
Validation loss: 2.012992407685967

Epoch: 5| Step: 5
Training loss: 2.1815593242645264
Validation loss: 2.0313644511725313

Epoch: 5| Step: 6
Training loss: 1.9136615991592407
Validation loss: 2.01932406169112

Epoch: 5| Step: 7
Training loss: 2.2427163124084473
Validation loss: 2.042495381447577

Epoch: 5| Step: 8
Training loss: 1.9826141595840454
Validation loss: 2.012342640148696

Epoch: 5| Step: 9
Training loss: 2.150263786315918
Validation loss: 2.0102896062276696

Epoch: 5| Step: 10
Training loss: 2.068502426147461
Validation loss: 2.02626137323277

Epoch: 120| Step: 0
Training loss: 2.170466899871826
Validation loss: 2.0170997829847437

Epoch: 5| Step: 1
Training loss: 2.0002191066741943
Validation loss: 2.032563961962218

Epoch: 5| Step: 2
Training loss: 1.6671558618545532
Validation loss: 2.0185675544123494

Epoch: 5| Step: 3
Training loss: 1.8983043432235718
Validation loss: 2.003761967023214

Epoch: 5| Step: 4
Training loss: 2.182774305343628
Validation loss: 2.0170269063723985

Epoch: 5| Step: 5
Training loss: 2.6073315143585205
Validation loss: 2.0018454264569026

Epoch: 5| Step: 6
Training loss: 1.7267379760742188
Validation loss: 2.001387314129901

Epoch: 5| Step: 7
Training loss: 2.631796360015869
Validation loss: 2.0081196344026955

Epoch: 5| Step: 8
Training loss: 1.5115394592285156
Validation loss: 2.024194804571008

Epoch: 5| Step: 9
Training loss: 2.3408875465393066
Validation loss: 2.0123458831541

Epoch: 5| Step: 10
Training loss: 2.862811326980591
Validation loss: 2.004350939104634

Epoch: 121| Step: 0
Training loss: 2.3403685092926025
Validation loss: 2.014873006010568

Epoch: 5| Step: 1
Training loss: 2.069112777709961
Validation loss: 2.0156641519197853

Epoch: 5| Step: 2
Training loss: 1.892913818359375
Validation loss: 2.0283464513799196

Epoch: 5| Step: 3
Training loss: 2.140150547027588
Validation loss: 2.0179127390666673

Epoch: 5| Step: 4
Training loss: 2.3073558807373047
Validation loss: 2.0326413992912538

Epoch: 5| Step: 5
Training loss: 2.329732656478882
Validation loss: 2.0204721061132287

Epoch: 5| Step: 6
Training loss: 2.5924620628356934
Validation loss: 2.0354986575341996

Epoch: 5| Step: 7
Training loss: 2.0387191772460938
Validation loss: 2.029660758151803

Epoch: 5| Step: 8
Training loss: 1.7733055353164673
Validation loss: 2.023940893911546

Epoch: 5| Step: 9
Training loss: 1.1845682859420776
Validation loss: 2.026155669202087

Epoch: 5| Step: 10
Training loss: 2.9223790168762207
Validation loss: 2.0215905404859975

Epoch: 122| Step: 0
Training loss: 1.887170433998108
Validation loss: 2.0227458938475578

Epoch: 5| Step: 1
Training loss: 1.8314504623413086
Validation loss: 2.0104073760330037

Epoch: 5| Step: 2
Training loss: 1.9813201427459717
Validation loss: 2.010483972487911

Epoch: 5| Step: 3
Training loss: 2.143366813659668
Validation loss: 2.023668053329632

Epoch: 5| Step: 4
Training loss: 2.288008689880371
Validation loss: 2.0031461408061366

Epoch: 5| Step: 5
Training loss: 1.9169113636016846
Validation loss: 2.0330912656681512

Epoch: 5| Step: 6
Training loss: 2.6024723052978516
Validation loss: 2.0190651339869343

Epoch: 5| Step: 7
Training loss: 2.410240650177002
Validation loss: 2.021440593145227

Epoch: 5| Step: 8
Training loss: 1.9277757406234741
Validation loss: 2.0016539750560636

Epoch: 5| Step: 9
Training loss: 2.0794548988342285
Validation loss: 2.0116756167463077

Epoch: 5| Step: 10
Training loss: 2.208559274673462
Validation loss: 2.023422195065406

Epoch: 123| Step: 0
Training loss: 2.227919816970825
Validation loss: 2.0043082762789983

Epoch: 5| Step: 1
Training loss: 2.1730856895446777
Validation loss: 2.0085869014904065

Epoch: 5| Step: 2
Training loss: 1.5694279670715332
Validation loss: 2.0116280458306752

Epoch: 5| Step: 3
Training loss: 2.1728432178497314
Validation loss: 2.026945194890422

Epoch: 5| Step: 4
Training loss: 2.2900288105010986
Validation loss: 2.0210711776569323

Epoch: 5| Step: 5
Training loss: 2.3110103607177734
Validation loss: 2.0211157427039197

Epoch: 5| Step: 6
Training loss: 2.3434576988220215
Validation loss: 2.04191755735746

Epoch: 5| Step: 7
Training loss: 2.1712708473205566
Validation loss: 2.0243172184113534

Epoch: 5| Step: 8
Training loss: 2.499335527420044
Validation loss: 2.018045243396554

Epoch: 5| Step: 9
Training loss: 1.8262494802474976
Validation loss: 2.02668014905786

Epoch: 5| Step: 10
Training loss: 1.7663804292678833
Validation loss: 2.0362660756675144

Epoch: 124| Step: 0
Training loss: 2.2598958015441895
Validation loss: 2.020867350280926

Epoch: 5| Step: 1
Training loss: 1.7243740558624268
Validation loss: 2.0312461019844137

Epoch: 5| Step: 2
Training loss: 2.227376937866211
Validation loss: 2.029662755227858

Epoch: 5| Step: 3
Training loss: 1.6801345348358154
Validation loss: 2.0078720841356503

Epoch: 5| Step: 4
Training loss: 1.682189702987671
Validation loss: 2.041256676438034

Epoch: 5| Step: 5
Training loss: 2.315155267715454
Validation loss: 2.0217827417517222

Epoch: 5| Step: 6
Training loss: 2.2128243446350098
Validation loss: 2.0235152026658416

Epoch: 5| Step: 7
Training loss: 1.7352190017700195
Validation loss: 2.03764404789094

Epoch: 5| Step: 8
Training loss: 2.4059906005859375
Validation loss: 2.0255590818261586

Epoch: 5| Step: 9
Training loss: 2.7225594520568848
Validation loss: 2.0258849436236965

Epoch: 5| Step: 10
Training loss: 2.396667242050171
Validation loss: 2.0269445911530526

Epoch: 125| Step: 0
Training loss: 1.8100717067718506
Validation loss: 2.0161706106637114

Epoch: 5| Step: 1
Training loss: 2.001260757446289
Validation loss: 2.0362456844699

Epoch: 5| Step: 2
Training loss: 2.321700096130371
Validation loss: 2.0317680989542315

Epoch: 5| Step: 3
Training loss: 1.9307396411895752
Validation loss: 2.030153043808476

Epoch: 5| Step: 4
Training loss: 1.8437058925628662
Validation loss: 2.010366956392924

Epoch: 5| Step: 5
Training loss: 1.8293583393096924
Validation loss: 2.0240230919212423

Epoch: 5| Step: 6
Training loss: 2.3250465393066406
Validation loss: 2.0369629577923845

Epoch: 5| Step: 7
Training loss: 2.669663429260254
Validation loss: 2.022802795133283

Epoch: 5| Step: 8
Training loss: 2.3399813175201416
Validation loss: 2.0195844686159523

Epoch: 5| Step: 9
Training loss: 1.8563588857650757
Validation loss: 2.024723881034441

Epoch: 5| Step: 10
Training loss: 2.4213178157806396
Validation loss: 2.0218261262421966

Epoch: 126| Step: 0
Training loss: 1.875004529953003
Validation loss: 2.0376137789859565

Epoch: 5| Step: 1
Training loss: 2.6149802207946777
Validation loss: 2.0063136264842045

Epoch: 5| Step: 2
Training loss: 1.8790756464004517
Validation loss: 2.0006516543767785

Epoch: 5| Step: 3
Training loss: 2.029778003692627
Validation loss: 2.0340604218103553

Epoch: 5| Step: 4
Training loss: 2.8352456092834473
Validation loss: 2.0124888907196703

Epoch: 5| Step: 5
Training loss: 1.809170126914978
Validation loss: 2.023743209018502

Epoch: 5| Step: 6
Training loss: 2.4552364349365234
Validation loss: 1.9911504522446664

Epoch: 5| Step: 7
Training loss: 2.24107027053833
Validation loss: 2.007755475659524

Epoch: 5| Step: 8
Training loss: 1.9736213684082031
Validation loss: 2.033881405348419

Epoch: 5| Step: 9
Training loss: 1.3858288526535034
Validation loss: 2.030293136514643

Epoch: 5| Step: 10
Training loss: 2.115236282348633
Validation loss: 2.012733156963061

Epoch: 127| Step: 0
Training loss: 2.3589179515838623
Validation loss: 2.0232082105452016

Epoch: 5| Step: 1
Training loss: 2.079157590866089
Validation loss: 2.017952788260675

Epoch: 5| Step: 2
Training loss: 1.8983951807022095
Validation loss: 2.027299319544146

Epoch: 5| Step: 3
Training loss: 2.022648334503174
Validation loss: 2.0120503364070768

Epoch: 5| Step: 4
Training loss: 2.3285574913024902
Validation loss: 2.0077800212367887

Epoch: 5| Step: 5
Training loss: 1.9387092590332031
Validation loss: 2.02823228989878

Epoch: 5| Step: 6
Training loss: 1.9318459033966064
Validation loss: 2.0138488072220997

Epoch: 5| Step: 7
Training loss: 1.9029918909072876
Validation loss: 2.0100333947007374

Epoch: 5| Step: 8
Training loss: 1.966291069984436
Validation loss: 2.0046308989165933

Epoch: 5| Step: 9
Training loss: 2.5423219203948975
Validation loss: 2.02291827688935

Epoch: 5| Step: 10
Training loss: 2.2063257694244385
Validation loss: 2.0205741787469513

Epoch: 128| Step: 0
Training loss: 2.4050395488739014
Validation loss: 2.0191871184174732

Epoch: 5| Step: 1
Training loss: 1.9347692728042603
Validation loss: 2.0231826869390344

Epoch: 5| Step: 2
Training loss: 1.662510633468628
Validation loss: 2.0151543642884944

Epoch: 5| Step: 3
Training loss: 2.3731112480163574
Validation loss: 2.0246906665063675

Epoch: 5| Step: 4
Training loss: 2.5817458629608154
Validation loss: 2.036651902301337

Epoch: 5| Step: 5
Training loss: 1.731081247329712
Validation loss: 2.023279356700118

Epoch: 5| Step: 6
Training loss: 2.4437458515167236
Validation loss: 2.0273137733500493

Epoch: 5| Step: 7
Training loss: 1.7553720474243164
Validation loss: 2.02452019722231

Epoch: 5| Step: 8
Training loss: 1.716482400894165
Validation loss: 2.0236822405169086

Epoch: 5| Step: 9
Training loss: 2.8639144897460938
Validation loss: 2.014049771011517

Epoch: 5| Step: 10
Training loss: 1.7737623453140259
Validation loss: 2.0141014950249785

Epoch: 129| Step: 0
Training loss: 1.7501599788665771
Validation loss: 2.0165633296453827

Epoch: 5| Step: 1
Training loss: 2.293949604034424
Validation loss: 2.0132631204461537

Epoch: 5| Step: 2
Training loss: 2.1460373401641846
Validation loss: 2.0073074422856814

Epoch: 5| Step: 3
Training loss: 1.8769296407699585
Validation loss: 2.0069579052668747

Epoch: 5| Step: 4
Training loss: 1.6162267923355103
Validation loss: 2.0118084056403047

Epoch: 5| Step: 5
Training loss: 2.0280489921569824
Validation loss: 2.035513459995229

Epoch: 5| Step: 6
Training loss: 2.4545395374298096
Validation loss: 2.010785928336523

Epoch: 5| Step: 7
Training loss: 2.012873411178589
Validation loss: 2.037100230493853

Epoch: 5| Step: 8
Training loss: 2.701913356781006
Validation loss: 2.04518231268852

Epoch: 5| Step: 9
Training loss: 2.0182108879089355
Validation loss: 2.01579309791647

Epoch: 5| Step: 10
Training loss: 2.367919921875
Validation loss: 2.0152619936132945

Epoch: 130| Step: 0
Training loss: 1.6342957019805908
Validation loss: 2.0224345268741732

Epoch: 5| Step: 1
Training loss: 2.3973612785339355
Validation loss: 1.998612347469535

Epoch: 5| Step: 2
Training loss: 2.750183582305908
Validation loss: 2.0193595758048435

Epoch: 5| Step: 3
Training loss: 2.044485569000244
Validation loss: 2.030233754906603

Epoch: 5| Step: 4
Training loss: 1.924941062927246
Validation loss: 2.0132275012231644

Epoch: 5| Step: 5
Training loss: 1.9688555002212524
Validation loss: 2.01925463573907

Epoch: 5| Step: 6
Training loss: 1.8053929805755615
Validation loss: 2.017026488498975

Epoch: 5| Step: 7
Training loss: 2.1735291481018066
Validation loss: 2.0170227840382564

Epoch: 5| Step: 8
Training loss: 2.8440730571746826
Validation loss: 2.0135816707405993

Epoch: 5| Step: 9
Training loss: 1.8112741708755493
Validation loss: 2.0221167456719185

Epoch: 5| Step: 10
Training loss: 1.6973156929016113
Validation loss: 2.0225538387093493

Epoch: 131| Step: 0
Training loss: 2.3073410987854004
Validation loss: 2.0346033983333136

Epoch: 5| Step: 1
Training loss: 1.6238758563995361
Validation loss: 2.0261606144648727

Epoch: 5| Step: 2
Training loss: 2.0162272453308105
Validation loss: 2.011424858083007

Epoch: 5| Step: 3
Training loss: 2.5904929637908936
Validation loss: 2.0234820509469635

Epoch: 5| Step: 4
Training loss: 2.418018341064453
Validation loss: 2.0209825167091946

Epoch: 5| Step: 5
Training loss: 2.74684476852417
Validation loss: 2.0182880432375017

Epoch: 5| Step: 6
Training loss: 2.3458313941955566
Validation loss: 2.0093977246233212

Epoch: 5| Step: 7
Training loss: 1.7170250415802002
Validation loss: 2.0095810659470095

Epoch: 5| Step: 8
Training loss: 1.8164809942245483
Validation loss: 2.0092215384206464

Epoch: 5| Step: 9
Training loss: 1.4268659353256226
Validation loss: 1.9988905127330492

Epoch: 5| Step: 10
Training loss: 2.0623905658721924
Validation loss: 2.011360353039157

Epoch: 132| Step: 0
Training loss: 2.1151723861694336
Validation loss: 2.023792582173501

Epoch: 5| Step: 1
Training loss: 2.5995731353759766
Validation loss: 2.021241521322599

Epoch: 5| Step: 2
Training loss: 1.9634921550750732
Validation loss: 2.0166777000632337

Epoch: 5| Step: 3
Training loss: 2.2012104988098145
Validation loss: 2.007898962625893

Epoch: 5| Step: 4
Training loss: 1.7614402770996094
Validation loss: 2.032300820914648

Epoch: 5| Step: 5
Training loss: 1.8809826374053955
Validation loss: 2.0273238792214343

Epoch: 5| Step: 6
Training loss: 2.3337464332580566
Validation loss: 2.022606554851737

Epoch: 5| Step: 7
Training loss: 1.9429957866668701
Validation loss: 2.0277974579923894

Epoch: 5| Step: 8
Training loss: 2.2520766258239746
Validation loss: 2.038304389164012

Epoch: 5| Step: 9
Training loss: 1.7361934185028076
Validation loss: 2.042913449707852

Epoch: 5| Step: 10
Training loss: 2.34639048576355
Validation loss: 2.018560404418617

Epoch: 133| Step: 0
Training loss: 2.508105516433716
Validation loss: 2.025053765184136

Epoch: 5| Step: 1
Training loss: 2.1529006958007812
Validation loss: 2.028198545978915

Epoch: 5| Step: 2
Training loss: 2.0894503593444824
Validation loss: 2.0348869805694907

Epoch: 5| Step: 3
Training loss: 1.9279565811157227
Validation loss: 2.019261380677582

Epoch: 5| Step: 4
Training loss: 1.8634684085845947
Validation loss: 2.023121395418721

Epoch: 5| Step: 5
Training loss: 2.1022229194641113
Validation loss: 2.0445267987507645

Epoch: 5| Step: 6
Training loss: 1.8698219060897827
Validation loss: 2.0075694591768327

Epoch: 5| Step: 7
Training loss: 2.2198967933654785
Validation loss: 2.01726423540423

Epoch: 5| Step: 8
Training loss: 1.9824669361114502
Validation loss: 2.032671042667922

Epoch: 5| Step: 9
Training loss: 2.5988173484802246
Validation loss: 2.029831647872925

Epoch: 5| Step: 10
Training loss: 1.8242840766906738
Validation loss: 2.0224093583322342

Epoch: 134| Step: 0
Training loss: 2.0182483196258545
Validation loss: 2.021348686628444

Epoch: 5| Step: 1
Training loss: 1.827684760093689
Validation loss: 2.021364022326726

Epoch: 5| Step: 2
Training loss: 2.54362154006958
Validation loss: 2.009386590732041

Epoch: 5| Step: 3
Training loss: 1.988126516342163
Validation loss: 1.9845906329411331

Epoch: 5| Step: 4
Training loss: 2.6286063194274902
Validation loss: 2.02052709620486

Epoch: 5| Step: 5
Training loss: 2.666651725769043
Validation loss: 2.011761978108396

Epoch: 5| Step: 6
Training loss: 2.246690034866333
Validation loss: 2.015853161452919

Epoch: 5| Step: 7
Training loss: 1.9919614791870117
Validation loss: 1.9926301651103522

Epoch: 5| Step: 8
Training loss: 1.5053056478500366
Validation loss: 2.0069201736040014

Epoch: 5| Step: 9
Training loss: 1.6538680791854858
Validation loss: 2.034609945871497

Epoch: 5| Step: 10
Training loss: 2.1107234954833984
Validation loss: 2.0148038479589645

Epoch: 135| Step: 0
Training loss: 2.15590238571167
Validation loss: 2.0192005044670513

Epoch: 5| Step: 1
Training loss: 1.553083062171936
Validation loss: 2.0206715573546705

Epoch: 5| Step: 2
Training loss: 2.587510824203491
Validation loss: 1.9985813453633299

Epoch: 5| Step: 3
Training loss: 2.1805317401885986
Validation loss: 2.015227625446935

Epoch: 5| Step: 4
Training loss: 1.6226966381072998
Validation loss: 2.0030477457149054

Epoch: 5| Step: 5
Training loss: 2.491800546646118
Validation loss: 2.0044466090458695

Epoch: 5| Step: 6
Training loss: 2.0976219177246094
Validation loss: 1.9913954555347402

Epoch: 5| Step: 7
Training loss: 2.5534563064575195
Validation loss: 2.0139882513271865

Epoch: 5| Step: 8
Training loss: 2.3058230876922607
Validation loss: 2.004944650075769

Epoch: 5| Step: 9
Training loss: 1.8879379034042358
Validation loss: 2.0111512394361597

Epoch: 5| Step: 10
Training loss: 1.5511767864227295
Validation loss: 2.019511612512732

Epoch: 136| Step: 0
Training loss: 2.427067279815674
Validation loss: 2.0334931894015242

Epoch: 5| Step: 1
Training loss: 2.2881360054016113
Validation loss: 2.029681796668678

Epoch: 5| Step: 2
Training loss: 1.5156052112579346
Validation loss: 2.0149770705930647

Epoch: 5| Step: 3
Training loss: 1.9149563312530518
Validation loss: 2.0154794890393495

Epoch: 5| Step: 4
Training loss: 2.1728549003601074
Validation loss: 2.0187541361778014

Epoch: 5| Step: 5
Training loss: 2.2581334114074707
Validation loss: 2.0114703139951153

Epoch: 5| Step: 6
Training loss: 2.1721127033233643
Validation loss: 2.027366607419906

Epoch: 5| Step: 7
Training loss: 1.9962927103042603
Validation loss: 2.031287024098058

Epoch: 5| Step: 8
Training loss: 2.0891802310943604
Validation loss: 2.037222763543488

Epoch: 5| Step: 9
Training loss: 1.9065895080566406
Validation loss: 2.0292575256798857

Epoch: 5| Step: 10
Training loss: 2.14431095123291
Validation loss: 2.0361916480525846

Epoch: 137| Step: 0
Training loss: 2.674783229827881
Validation loss: 2.0248604077164845

Epoch: 5| Step: 1
Training loss: 2.081590175628662
Validation loss: 2.0222889710498113

Epoch: 5| Step: 2
Training loss: 2.04740834236145
Validation loss: 2.016620733404672

Epoch: 5| Step: 3
Training loss: 1.9632200002670288
Validation loss: 2.016776816819304

Epoch: 5| Step: 4
Training loss: 2.068598508834839
Validation loss: 2.0166282910172657

Epoch: 5| Step: 5
Training loss: 2.5537734031677246
Validation loss: 2.013832123048844

Epoch: 5| Step: 6
Training loss: 1.776259183883667
Validation loss: 1.9935776597710066

Epoch: 5| Step: 7
Training loss: 1.4025614261627197
Validation loss: 2.0218867191704373

Epoch: 5| Step: 8
Training loss: 1.935523271560669
Validation loss: 1.9942115237635951

Epoch: 5| Step: 9
Training loss: 1.993232011795044
Validation loss: 2.0132124398344304

Epoch: 5| Step: 10
Training loss: 2.5907230377197266
Validation loss: 1.992459935526694

Epoch: 138| Step: 0
Training loss: 2.194262742996216
Validation loss: 2.0270834789481214

Epoch: 5| Step: 1
Training loss: 1.453249216079712
Validation loss: 2.037319980641847

Epoch: 5| Step: 2
Training loss: 1.5318481922149658
Validation loss: 2.013528177815099

Epoch: 5| Step: 3
Training loss: 2.456753730773926
Validation loss: 2.0229601539591306

Epoch: 5| Step: 4
Training loss: 3.2803711891174316
Validation loss: 2.0130696065964235

Epoch: 5| Step: 5
Training loss: 1.798011064529419
Validation loss: 1.9996855028213993

Epoch: 5| Step: 6
Training loss: 2.292320966720581
Validation loss: 2.0181559183264293

Epoch: 5| Step: 7
Training loss: 2.0117337703704834
Validation loss: 2.036078546636848

Epoch: 5| Step: 8
Training loss: 1.7658014297485352
Validation loss: 2.023452485761335

Epoch: 5| Step: 9
Training loss: 2.547612190246582
Validation loss: 2.0309113815266597

Epoch: 5| Step: 10
Training loss: 1.6015558242797852
Validation loss: 2.017879988557549

Epoch: 139| Step: 0
Training loss: 1.710367202758789
Validation loss: 2.016145278048772

Epoch: 5| Step: 1
Training loss: 2.0487449169158936
Validation loss: 2.030888001124064

Epoch: 5| Step: 2
Training loss: 1.8170655965805054
Validation loss: 2.0214126930441907

Epoch: 5| Step: 3
Training loss: 2.8915274143218994
Validation loss: 2.008360662767964

Epoch: 5| Step: 4
Training loss: 2.672480344772339
Validation loss: 2.0149413924063406

Epoch: 5| Step: 5
Training loss: 2.12660813331604
Validation loss: 2.003557397473243

Epoch: 5| Step: 6
Training loss: 1.9269307851791382
Validation loss: 2.0132029556458995

Epoch: 5| Step: 7
Training loss: 1.864375352859497
Validation loss: 2.022668270654576

Epoch: 5| Step: 8
Training loss: 1.9641954898834229
Validation loss: 2.0251406943926247

Epoch: 5| Step: 9
Training loss: 1.7976487874984741
Validation loss: 2.0233573016299995

Epoch: 5| Step: 10
Training loss: 2.213355541229248
Validation loss: 2.0451247166561823

Epoch: 140| Step: 0
Training loss: 2.242313861846924
Validation loss: 2.0176709146909815

Epoch: 5| Step: 1
Training loss: 1.422073245048523
Validation loss: 2.015303111845447

Epoch: 5| Step: 2
Training loss: 2.2073090076446533
Validation loss: 2.0131006753572853

Epoch: 5| Step: 3
Training loss: 3.0116324424743652
Validation loss: 2.0211477728300196

Epoch: 5| Step: 4
Training loss: 1.3084633350372314
Validation loss: 2.014078219731649

Epoch: 5| Step: 5
Training loss: 2.324363946914673
Validation loss: 2.0141163077405704

Epoch: 5| Step: 6
Training loss: 2.3003034591674805
Validation loss: 2.0343068748392086

Epoch: 5| Step: 7
Training loss: 1.2993844747543335
Validation loss: 2.017003752851999

Epoch: 5| Step: 8
Training loss: 2.728976249694824
Validation loss: 2.0230120228182886

Epoch: 5| Step: 9
Training loss: 2.0495445728302
Validation loss: 2.0207702088099655

Epoch: 5| Step: 10
Training loss: 1.9886062145233154
Validation loss: 2.0078203473039853

Epoch: 141| Step: 0
Training loss: 1.4443213939666748
Validation loss: 2.017741730136256

Epoch: 5| Step: 1
Training loss: 2.3106377124786377
Validation loss: 2.0075325965881348

Epoch: 5| Step: 2
Training loss: 2.693624973297119
Validation loss: 2.0156184947618874

Epoch: 5| Step: 3
Training loss: 1.5309224128723145
Validation loss: 2.0071242368349465

Epoch: 5| Step: 4
Training loss: 1.9432106018066406
Validation loss: 2.0130001191169984

Epoch: 5| Step: 5
Training loss: 2.7155327796936035
Validation loss: 2.0127953624212616

Epoch: 5| Step: 6
Training loss: 2.2073256969451904
Validation loss: 2.0072033430940364

Epoch: 5| Step: 7
Training loss: 1.686266303062439
Validation loss: 2.005609699474868

Epoch: 5| Step: 8
Training loss: 1.8922901153564453
Validation loss: 2.0112483014342604

Epoch: 5| Step: 9
Training loss: 2.072374105453491
Validation loss: 2.023047572822981

Epoch: 5| Step: 10
Training loss: 2.507431983947754
Validation loss: 2.0069658435801023

Epoch: 142| Step: 0
Training loss: 2.545210599899292
Validation loss: 1.9973827062114593

Epoch: 5| Step: 1
Training loss: 1.906521201133728
Validation loss: 2.021205868772281

Epoch: 5| Step: 2
Training loss: 2.031857967376709
Validation loss: 2.026682516579987

Epoch: 5| Step: 3
Training loss: 1.5913946628570557
Validation loss: 2.034658511479696

Epoch: 5| Step: 4
Training loss: 2.1008968353271484
Validation loss: 2.020571759952012

Epoch: 5| Step: 5
Training loss: 1.6164867877960205
Validation loss: 2.008897803163016

Epoch: 5| Step: 6
Training loss: 2.748075008392334
Validation loss: 2.0212943605197373

Epoch: 5| Step: 7
Training loss: 2.5854125022888184
Validation loss: 1.9975352761565999

Epoch: 5| Step: 8
Training loss: 2.104163408279419
Validation loss: 2.017172449378557

Epoch: 5| Step: 9
Training loss: 2.0783286094665527
Validation loss: 2.011976424083915

Epoch: 5| Step: 10
Training loss: 1.4470701217651367
Validation loss: 2.0151202499225573

Epoch: 143| Step: 0
Training loss: 2.115539789199829
Validation loss: 1.9980643756927983

Epoch: 5| Step: 1
Training loss: 2.857081174850464
Validation loss: 2.031750750798051

Epoch: 5| Step: 2
Training loss: 1.4718083143234253
Validation loss: 2.038200368163406

Epoch: 5| Step: 3
Training loss: 1.9521198272705078
Validation loss: 2.0169005957982873

Epoch: 5| Step: 4
Training loss: 1.8575313091278076
Validation loss: 2.020808768528764

Epoch: 5| Step: 5
Training loss: 2.1327860355377197
Validation loss: 2.0027243065577682

Epoch: 5| Step: 6
Training loss: 2.6036486625671387
Validation loss: 2.019652059001307

Epoch: 5| Step: 7
Training loss: 1.4132412672042847
Validation loss: 2.0146773066571964

Epoch: 5| Step: 8
Training loss: 2.4549455642700195
Validation loss: 2.022929449235239

Epoch: 5| Step: 9
Training loss: 1.754868745803833
Validation loss: 2.026271606004366

Epoch: 5| Step: 10
Training loss: 2.27282977104187
Validation loss: 2.0019905964533486

Epoch: 144| Step: 0
Training loss: 2.053952693939209
Validation loss: 2.0288720195011427

Epoch: 5| Step: 1
Training loss: 2.210756540298462
Validation loss: 2.0236929949893745

Epoch: 5| Step: 2
Training loss: 2.0159621238708496
Validation loss: 2.037999130064441

Epoch: 5| Step: 3
Training loss: 2.0664989948272705
Validation loss: 2.0018158164075626

Epoch: 5| Step: 4
Training loss: 1.8157516717910767
Validation loss: 2.0232991710785897

Epoch: 5| Step: 5
Training loss: 2.3876280784606934
Validation loss: 2.004937292427145

Epoch: 5| Step: 6
Training loss: 2.2204527854919434
Validation loss: 2.0034677713148055

Epoch: 5| Step: 7
Training loss: 2.06286358833313
Validation loss: 2.0117207496396956

Epoch: 5| Step: 8
Training loss: 2.4627771377563477
Validation loss: 2.0174643288376513

Epoch: 5| Step: 9
Training loss: 2.0345165729522705
Validation loss: 1.998459246850783

Epoch: 5| Step: 10
Training loss: 1.6142945289611816
Validation loss: 2.007363796234131

Epoch: 145| Step: 0
Training loss: 2.2093589305877686
Validation loss: 2.025724659683884

Epoch: 5| Step: 1
Training loss: 2.7827906608581543
Validation loss: 2.0213249421888784

Epoch: 5| Step: 2
Training loss: 2.5441696643829346
Validation loss: 2.025254426463958

Epoch: 5| Step: 3
Training loss: 1.046750783920288
Validation loss: 2.0177154823016097

Epoch: 5| Step: 4
Training loss: 1.3047418594360352
Validation loss: 2.013528996898282

Epoch: 5| Step: 5
Training loss: 2.0381951332092285
Validation loss: 2.0045452938284924

Epoch: 5| Step: 6
Training loss: 2.035160541534424
Validation loss: 2.016741975661247

Epoch: 5| Step: 7
Training loss: 2.860813856124878
Validation loss: 2.0276460827037854

Epoch: 5| Step: 8
Training loss: 2.396003007888794
Validation loss: 2.0153706996671614

Epoch: 5| Step: 9
Training loss: 1.7307087182998657
Validation loss: 2.0001799983362996

Epoch: 5| Step: 10
Training loss: 1.7403297424316406
Validation loss: 2.026143880300624

Epoch: 146| Step: 0
Training loss: 2.385617733001709
Validation loss: 2.018255420910415

Epoch: 5| Step: 1
Training loss: 1.3070584535598755
Validation loss: 2.0023254374022126

Epoch: 5| Step: 2
Training loss: 1.8275495767593384
Validation loss: 2.010468262498097

Epoch: 5| Step: 3
Training loss: 2.1322789192199707
Validation loss: 2.0336615475275184

Epoch: 5| Step: 4
Training loss: 1.996382474899292
Validation loss: 2.0021137550312984

Epoch: 5| Step: 5
Training loss: 2.9622740745544434
Validation loss: 2.0075013406815065

Epoch: 5| Step: 6
Training loss: 2.050386428833008
Validation loss: 2.009466061028101

Epoch: 5| Step: 7
Training loss: 1.8499596118927002
Validation loss: 2.0021831925197313

Epoch: 5| Step: 8
Training loss: 2.0303211212158203
Validation loss: 2.014351080822688

Epoch: 5| Step: 9
Training loss: 1.9199720621109009
Validation loss: 2.034540964711097

Epoch: 5| Step: 10
Training loss: 2.44637393951416
Validation loss: 2.007189493025503

Epoch: 147| Step: 0
Training loss: 1.7139637470245361
Validation loss: 2.0207605220938243

Epoch: 5| Step: 1
Training loss: 1.8473865985870361
Validation loss: 2.024526132050381

Epoch: 5| Step: 2
Training loss: 2.4439592361450195
Validation loss: 2.016331595759238

Epoch: 5| Step: 3
Training loss: 2.1808853149414062
Validation loss: 2.0123460959362727

Epoch: 5| Step: 4
Training loss: 2.2184231281280518
Validation loss: 2.0101707814842142

Epoch: 5| Step: 5
Training loss: 1.8549741506576538
Validation loss: 2.028022079057591

Epoch: 5| Step: 6
Training loss: 2.551482677459717
Validation loss: 2.00459450034685

Epoch: 5| Step: 7
Training loss: 2.2721502780914307
Validation loss: 2.0140052867192093

Epoch: 5| Step: 8
Training loss: 1.6154487133026123
Validation loss: 2.0213421006356516

Epoch: 5| Step: 9
Training loss: 1.996350884437561
Validation loss: 2.006871819496155

Epoch: 5| Step: 10
Training loss: 2.0252676010131836
Validation loss: 2.0238333927687777

Epoch: 148| Step: 0
Training loss: 2.193249225616455
Validation loss: 2.044731047845656

Epoch: 5| Step: 1
Training loss: 2.0221238136291504
Validation loss: 2.022933557469358

Epoch: 5| Step: 2
Training loss: 2.3274331092834473
Validation loss: 2.019911922434325

Epoch: 5| Step: 3
Training loss: 1.9854652881622314
Validation loss: 2.02790807395853

Epoch: 5| Step: 4
Training loss: 1.9432560205459595
Validation loss: 2.0328744560159664

Epoch: 5| Step: 5
Training loss: 1.648193359375
Validation loss: 2.033076896462389

Epoch: 5| Step: 6
Training loss: 2.5398576259613037
Validation loss: 1.9995063645865327

Epoch: 5| Step: 7
Training loss: 2.039344072341919
Validation loss: 2.0137237348864154

Epoch: 5| Step: 8
Training loss: 2.2221570014953613
Validation loss: 2.0187871507419053

Epoch: 5| Step: 9
Training loss: 1.2508351802825928
Validation loss: 2.017793789986641

Epoch: 5| Step: 10
Training loss: 2.518284559249878
Validation loss: 2.0083849442902433

Epoch: 149| Step: 0
Training loss: 2.0007271766662598
Validation loss: 2.022851288959544

Epoch: 5| Step: 1
Training loss: 2.302366256713867
Validation loss: 2.012363585092688

Epoch: 5| Step: 2
Training loss: 1.7715730667114258
Validation loss: 1.99999269875147

Epoch: 5| Step: 3
Training loss: 1.9089444875717163
Validation loss: 2.0058997933582594

Epoch: 5| Step: 4
Training loss: 2.1984753608703613
Validation loss: 2.014031074380362

Epoch: 5| Step: 5
Training loss: 2.3370158672332764
Validation loss: 2.0462243979977024

Epoch: 5| Step: 6
Training loss: 2.3062334060668945
Validation loss: 2.0048722169732534

Epoch: 5| Step: 7
Training loss: 1.6797622442245483
Validation loss: 2.007943340527114

Epoch: 5| Step: 8
Training loss: 2.3826072216033936
Validation loss: 2.033151013876802

Epoch: 5| Step: 9
Training loss: 1.4296801090240479
Validation loss: 2.0190480857767086

Epoch: 5| Step: 10
Training loss: 2.36674427986145
Validation loss: 2.0156329498496106

Epoch: 150| Step: 0
Training loss: 1.8495174646377563
Validation loss: 2.0220110980413293

Epoch: 5| Step: 1
Training loss: 2.374048948287964
Validation loss: 2.008142307240476

Epoch: 5| Step: 2
Training loss: 1.7978403568267822
Validation loss: 2.00960236723705

Epoch: 5| Step: 3
Training loss: 2.5444579124450684
Validation loss: 2.004558604250672

Epoch: 5| Step: 4
Training loss: 2.338977098464966
Validation loss: 2.013949047493678

Epoch: 5| Step: 5
Training loss: 1.9053446054458618
Validation loss: 2.025956775552483

Epoch: 5| Step: 6
Training loss: 2.085561990737915
Validation loss: 2.0248593643147457

Epoch: 5| Step: 7
Training loss: 2.132326364517212
Validation loss: 2.0058487846005346

Epoch: 5| Step: 8
Training loss: 1.8118444681167603
Validation loss: 2.046485447114514

Epoch: 5| Step: 9
Training loss: 1.6892497539520264
Validation loss: 2.0235217899404545

Epoch: 5| Step: 10
Training loss: 2.085671901702881
Validation loss: 2.009485895915698

Epoch: 151| Step: 0
Training loss: 2.4550700187683105
Validation loss: 2.0113790330066474

Epoch: 5| Step: 1
Training loss: 2.2025904655456543
Validation loss: 1.9932382901509602

Epoch: 5| Step: 2
Training loss: 1.8625072240829468
Validation loss: 2.008139665408801

Epoch: 5| Step: 3
Training loss: 1.4969083070755005
Validation loss: 2.0154909985039824

Epoch: 5| Step: 4
Training loss: 1.8301889896392822
Validation loss: 2.020577915253178

Epoch: 5| Step: 5
Training loss: 2.0695223808288574
Validation loss: 2.0122919979915825

Epoch: 5| Step: 6
Training loss: 2.3558642864227295
Validation loss: 2.0095468926173385

Epoch: 5| Step: 7
Training loss: 2.0324974060058594
Validation loss: 2.01743378690494

Epoch: 5| Step: 8
Training loss: 1.9033167362213135
Validation loss: 2.0151080380203905

Epoch: 5| Step: 9
Training loss: 2.291316509246826
Validation loss: 2.010517324170759

Epoch: 5| Step: 10
Training loss: 2.0859622955322266
Validation loss: 2.00765626020329

Epoch: 152| Step: 0
Training loss: 1.9330365657806396
Validation loss: 2.0203010215554187

Epoch: 5| Step: 1
Training loss: 1.8251432180404663
Validation loss: 2.00756743133709

Epoch: 5| Step: 2
Training loss: 3.057004451751709
Validation loss: 2.0249012131844797

Epoch: 5| Step: 3
Training loss: 2.1253037452697754
Validation loss: 2.014724785281766

Epoch: 5| Step: 4
Training loss: 1.5166447162628174
Validation loss: 2.003030252713029

Epoch: 5| Step: 5
Training loss: 1.807948350906372
Validation loss: 2.0060472103857223

Epoch: 5| Step: 6
Training loss: 1.6907758712768555
Validation loss: 2.0208804709936983

Epoch: 5| Step: 7
Training loss: 2.2333483695983887
Validation loss: 2.0095115015583653

Epoch: 5| Step: 8
Training loss: 2.082066774368286
Validation loss: 2.050426544681672

Epoch: 5| Step: 9
Training loss: 2.52203631401062
Validation loss: 2.008809712625319

Epoch: 5| Step: 10
Training loss: 1.7353419065475464
Validation loss: 2.0026466115828483

Epoch: 153| Step: 0
Training loss: 1.797751784324646
Validation loss: 2.0047378347766016

Epoch: 5| Step: 1
Training loss: 2.6330819129943848
Validation loss: 2.0047971676754694

Epoch: 5| Step: 2
Training loss: 2.610170364379883
Validation loss: 2.0081966282219015

Epoch: 5| Step: 3
Training loss: 1.9455013275146484
Validation loss: 1.9953655696684314

Epoch: 5| Step: 4
Training loss: 2.190974712371826
Validation loss: 2.019349754497569

Epoch: 5| Step: 5
Training loss: 1.5941991806030273
Validation loss: 2.0228560611765873

Epoch: 5| Step: 6
Training loss: 2.0503249168395996
Validation loss: 2.009106606565496

Epoch: 5| Step: 7
Training loss: 2.270754337310791
Validation loss: 2.0065352096352527

Epoch: 5| Step: 8
Training loss: 1.7270135879516602
Validation loss: 2.009105304876963

Epoch: 5| Step: 9
Training loss: 1.5100815296173096
Validation loss: 2.0313887057765836

Epoch: 5| Step: 10
Training loss: 2.2495310306549072
Validation loss: 2.0162944409155075

Epoch: 154| Step: 0
Training loss: 1.4712393283843994
Validation loss: 2.0193039127575454

Epoch: 5| Step: 1
Training loss: 1.888392448425293
Validation loss: 1.9974233617064774

Epoch: 5| Step: 2
Training loss: 2.2558486461639404
Validation loss: 2.0197237448025773

Epoch: 5| Step: 3
Training loss: 1.8770802021026611
Validation loss: 2.0203811494253014

Epoch: 5| Step: 4
Training loss: 2.579571008682251
Validation loss: 2.023463297915715

Epoch: 5| Step: 5
Training loss: 2.228515863418579
Validation loss: 2.0090149320581907

Epoch: 5| Step: 6
Training loss: 1.8835678100585938
Validation loss: 2.019810761174848

Epoch: 5| Step: 7
Training loss: 2.9665420055389404
Validation loss: 2.0306331316630044

Epoch: 5| Step: 8
Training loss: 1.7449085712432861
Validation loss: 2.031427034767725

Epoch: 5| Step: 9
Training loss: 2.2560715675354004
Validation loss: 2.015940821298989

Epoch: 5| Step: 10
Training loss: 1.5602214336395264
Validation loss: 2.0183572461528163

Epoch: 155| Step: 0
Training loss: 1.6592261791229248
Validation loss: 2.011871378908875

Epoch: 5| Step: 1
Training loss: 2.182244062423706
Validation loss: 2.0279344102387786

Epoch: 5| Step: 2
Training loss: 2.2941927909851074
Validation loss: 2.0110123900957007

Epoch: 5| Step: 3
Training loss: 2.1517436504364014
Validation loss: 2.0237403826047013

Epoch: 5| Step: 4
Training loss: 1.8167810440063477
Validation loss: 2.006945768992106

Epoch: 5| Step: 5
Training loss: 2.114387035369873
Validation loss: 2.0023865879222913

Epoch: 5| Step: 6
Training loss: 2.072415828704834
Validation loss: 2.007556502537061

Epoch: 5| Step: 7
Training loss: 1.9094436168670654
Validation loss: 2.02338505816716

Epoch: 5| Step: 8
Training loss: 1.92609441280365
Validation loss: 2.0316966438806183

Epoch: 5| Step: 9
Training loss: 2.266840934753418
Validation loss: 2.005430329230524

Epoch: 5| Step: 10
Training loss: 2.1465933322906494
Validation loss: 1.9970333063474266

Epoch: 156| Step: 0
Training loss: 2.0288405418395996
Validation loss: 2.0009597680901967

Epoch: 5| Step: 1
Training loss: 2.456454038619995
Validation loss: 1.993847982857817

Epoch: 5| Step: 2
Training loss: 2.3978946208953857
Validation loss: 2.005220229907702

Epoch: 5| Step: 3
Training loss: 1.695648431777954
Validation loss: 2.0096410307832944

Epoch: 5| Step: 4
Training loss: 1.9765431880950928
Validation loss: 2.0208250232922134

Epoch: 5| Step: 5
Training loss: 1.6557724475860596
Validation loss: 2.000305450090798

Epoch: 5| Step: 6
Training loss: 2.269490957260132
Validation loss: 2.0153611321603098

Epoch: 5| Step: 7
Training loss: 2.114557981491089
Validation loss: 2.0181242214736117

Epoch: 5| Step: 8
Training loss: 2.9465880393981934
Validation loss: 2.0072266760692803

Epoch: 5| Step: 9
Training loss: 1.751713752746582
Validation loss: 1.9906941588206957

Epoch: 5| Step: 10
Training loss: 1.0820093154907227
Validation loss: 2.0105556749528453

Epoch: 157| Step: 0
Training loss: 1.826934576034546
Validation loss: 2.0182937268287904

Epoch: 5| Step: 1
Training loss: 1.6150562763214111
Validation loss: 2.0043937788214734

Epoch: 5| Step: 2
Training loss: 1.6703541278839111
Validation loss: 2.0267909957516577

Epoch: 5| Step: 3
Training loss: 2.1210081577301025
Validation loss: 2.0124607419454925

Epoch: 5| Step: 4
Training loss: 1.8530473709106445
Validation loss: 2.007399566711918

Epoch: 5| Step: 5
Training loss: 2.6381044387817383
Validation loss: 2.0228086581794162

Epoch: 5| Step: 6
Training loss: 2.0334219932556152
Validation loss: 2.0148069089458835

Epoch: 5| Step: 7
Training loss: 1.9795444011688232
Validation loss: 1.9950676835993284

Epoch: 5| Step: 8
Training loss: 2.373251438140869
Validation loss: 2.0102853134114254

Epoch: 5| Step: 9
Training loss: 2.20988392829895
Validation loss: 2.009201012631898

Epoch: 5| Step: 10
Training loss: 2.3198282718658447
Validation loss: 2.0160924721789617

Epoch: 158| Step: 0
Training loss: 1.8977304697036743
Validation loss: 2.0037301689065914

Epoch: 5| Step: 1
Training loss: 1.8200891017913818
Validation loss: 2.011891072796237

Epoch: 5| Step: 2
Training loss: 2.0299265384674072
Validation loss: 2.0291959906137116

Epoch: 5| Step: 3
Training loss: 1.7924381494522095
Validation loss: 2.0059171850963304

Epoch: 5| Step: 4
Training loss: 1.8398479223251343
Validation loss: 2.037671184027067

Epoch: 5| Step: 5
Training loss: 2.032912492752075
Validation loss: 2.0235870807401595

Epoch: 5| Step: 6
Training loss: 2.6708273887634277
Validation loss: 2.0292679802063973

Epoch: 5| Step: 7
Training loss: 1.932542085647583
Validation loss: 2.004875870161159

Epoch: 5| Step: 8
Training loss: 2.2369775772094727
Validation loss: 2.020425535017444

Epoch: 5| Step: 9
Training loss: 2.223602771759033
Validation loss: 2.0243880697475967

Epoch: 5| Step: 10
Training loss: 1.8713611364364624
Validation loss: 2.00653475587086

Epoch: 159| Step: 0
Training loss: 1.4830352067947388
Validation loss: 2.0116723122135287

Epoch: 5| Step: 1
Training loss: 1.721662163734436
Validation loss: 2.031449349977637

Epoch: 5| Step: 2
Training loss: 2.1640937328338623
Validation loss: 2.013478176568144

Epoch: 5| Step: 3
Training loss: 1.8680309057235718
Validation loss: 1.9998188121344453

Epoch: 5| Step: 4
Training loss: 1.8934814929962158
Validation loss: 1.9913118718772806

Epoch: 5| Step: 5
Training loss: 2.4947383403778076
Validation loss: 2.021644482048609

Epoch: 5| Step: 6
Training loss: 1.7787683010101318
Validation loss: 2.0072564617280038

Epoch: 5| Step: 7
Training loss: 1.9800803661346436
Validation loss: 1.973982871219676

Epoch: 5| Step: 8
Training loss: 2.2137036323547363
Validation loss: 2.03367611669725

Epoch: 5| Step: 9
Training loss: 2.7923271656036377
Validation loss: 2.034810664833233

Epoch: 5| Step: 10
Training loss: 2.041168689727783
Validation loss: 2.0151136382933585

Epoch: 160| Step: 0
Training loss: 1.8539785146713257
Validation loss: 2.012594087149507

Epoch: 5| Step: 1
Training loss: 1.6613041162490845
Validation loss: 2.026704047315864

Epoch: 5| Step: 2
Training loss: 1.9449679851531982
Validation loss: 2.0155206726443384

Epoch: 5| Step: 3
Training loss: 2.452167510986328
Validation loss: 2.017966083301011

Epoch: 5| Step: 4
Training loss: 2.5878212451934814
Validation loss: 2.018851154594011

Epoch: 5| Step: 5
Training loss: 1.6278743743896484
Validation loss: 2.016229485952726

Epoch: 5| Step: 6
Training loss: 1.693170189857483
Validation loss: 2.012187703963249

Epoch: 5| Step: 7
Training loss: 1.4785560369491577
Validation loss: 1.9860331576357606

Epoch: 5| Step: 8
Training loss: 2.430103302001953
Validation loss: 2.013806096969112

Epoch: 5| Step: 9
Training loss: 2.1820404529571533
Validation loss: 2.003643863944597

Epoch: 5| Step: 10
Training loss: 2.5542609691619873
Validation loss: 2.0100148390698176

Epoch: 161| Step: 0
Training loss: 1.7857706546783447
Validation loss: 2.0020333836155553

Epoch: 5| Step: 1
Training loss: 2.087658405303955
Validation loss: 1.9986470540364583

Epoch: 5| Step: 2
Training loss: 1.8614755868911743
Validation loss: 2.0139732719749532

Epoch: 5| Step: 3
Training loss: 1.7018013000488281
Validation loss: 2.002195360840008

Epoch: 5| Step: 4
Training loss: 2.3759446144104004
Validation loss: 2.014648296499765

Epoch: 5| Step: 5
Training loss: 1.6277990341186523
Validation loss: 2.0144075988441386

Epoch: 5| Step: 6
Training loss: 2.467019557952881
Validation loss: 2.0106923375078427

Epoch: 5| Step: 7
Training loss: 2.600637912750244
Validation loss: 2.0090164189697592

Epoch: 5| Step: 8
Training loss: 2.2667083740234375
Validation loss: 2.023751098622558

Epoch: 5| Step: 9
Training loss: 1.861417531967163
Validation loss: 2.016785906207177

Epoch: 5| Step: 10
Training loss: 1.8210841417312622
Validation loss: 1.9969726301008655

Epoch: 162| Step: 0
Training loss: 1.655090093612671
Validation loss: 2.0094771808193577

Epoch: 5| Step: 1
Training loss: 2.0295214653015137
Validation loss: 2.009715300734325

Epoch: 5| Step: 2
Training loss: 1.8034679889678955
Validation loss: 2.006151448013962

Epoch: 5| Step: 3
Training loss: 1.9575248956680298
Validation loss: 2.003291919667234

Epoch: 5| Step: 4
Training loss: 1.1997956037521362
Validation loss: 2.003688040600028

Epoch: 5| Step: 5
Training loss: 2.8701913356781006
Validation loss: 2.0147648088393675

Epoch: 5| Step: 6
Training loss: 2.2196011543273926
Validation loss: 2.0311301062183995

Epoch: 5| Step: 7
Training loss: 1.7700984477996826
Validation loss: 2.0126081307729087

Epoch: 5| Step: 8
Training loss: 2.1935677528381348
Validation loss: 2.021965447292533

Epoch: 5| Step: 9
Training loss: 2.3896567821502686
Validation loss: 2.015617694906009

Epoch: 5| Step: 10
Training loss: 2.5097036361694336
Validation loss: 2.025157848993937

Epoch: 163| Step: 0
Training loss: 2.0353386402130127
Validation loss: 2.029441023385653

Epoch: 5| Step: 1
Training loss: 1.2541778087615967
Validation loss: 2.012659436912947

Epoch: 5| Step: 2
Training loss: 2.1582400798797607
Validation loss: 2.037904611197851

Epoch: 5| Step: 3
Training loss: 2.572754383087158
Validation loss: 2.036076775161169

Epoch: 5| Step: 4
Training loss: 1.9587395191192627
Validation loss: 2.0138027052725516

Epoch: 5| Step: 5
Training loss: 1.933534860610962
Validation loss: 2.010327331481441

Epoch: 5| Step: 6
Training loss: 1.8579893112182617
Validation loss: 2.0266418880031956

Epoch: 5| Step: 7
Training loss: 2.2762951850891113
Validation loss: 1.9952248514339488

Epoch: 5| Step: 8
Training loss: 1.8626388311386108
Validation loss: 2.013227708878056

Epoch: 5| Step: 9
Training loss: 2.1386806964874268
Validation loss: 2.017552565502864

Epoch: 5| Step: 10
Training loss: 2.349966049194336
Validation loss: 2.0061896026775403

Epoch: 164| Step: 0
Training loss: 2.2819344997406006
Validation loss: 2.0161323239726405

Epoch: 5| Step: 1
Training loss: 2.1436121463775635
Validation loss: 2.019657811810893

Epoch: 5| Step: 2
Training loss: 2.107880115509033
Validation loss: 2.0055443368932253

Epoch: 5| Step: 3
Training loss: 1.945452094078064
Validation loss: 2.004858475859447

Epoch: 5| Step: 4
Training loss: 1.6857662200927734
Validation loss: 2.0032596882953437

Epoch: 5| Step: 5
Training loss: 1.807607650756836
Validation loss: 2.0242794534211517

Epoch: 5| Step: 6
Training loss: 2.6253838539123535
Validation loss: 2.0180560517054733

Epoch: 5| Step: 7
Training loss: 1.5373613834381104
Validation loss: 1.9867097126540316

Epoch: 5| Step: 8
Training loss: 2.1815576553344727
Validation loss: 2.0077175812054704

Epoch: 5| Step: 9
Training loss: 2.196732997894287
Validation loss: 2.018601740560224

Epoch: 5| Step: 10
Training loss: 1.7421990633010864
Validation loss: 2.0204409296794603

Epoch: 165| Step: 0
Training loss: 1.9855148792266846
Validation loss: 2.009317046852522

Epoch: 5| Step: 1
Training loss: 1.8110415935516357
Validation loss: 2.0180251213812057

Epoch: 5| Step: 2
Training loss: 1.66781485080719
Validation loss: 2.0000780320936635

Epoch: 5| Step: 3
Training loss: 2.0494236946105957
Validation loss: 2.003024515285287

Epoch: 5| Step: 4
Training loss: 1.5976381301879883
Validation loss: 2.000843342914376

Epoch: 5| Step: 5
Training loss: 2.4502787590026855
Validation loss: 2.0165800971369587

Epoch: 5| Step: 6
Training loss: 1.5790296792984009
Validation loss: 2.0040031415159985

Epoch: 5| Step: 7
Training loss: 1.927117109298706
Validation loss: 2.007864227858923

Epoch: 5| Step: 8
Training loss: 2.49076771736145
Validation loss: 2.008651130942888

Epoch: 5| Step: 9
Training loss: 2.8560876846313477
Validation loss: 2.0266606589799285

Epoch: 5| Step: 10
Training loss: 1.702907919883728
Validation loss: 2.004221327843205

Epoch: 166| Step: 0
Training loss: 2.1047523021698
Validation loss: 2.0254063606262207

Epoch: 5| Step: 1
Training loss: 1.7932875156402588
Validation loss: 2.041804398259809

Epoch: 5| Step: 2
Training loss: 2.206470012664795
Validation loss: 1.9963414105035926

Epoch: 5| Step: 3
Training loss: 2.789626121520996
Validation loss: 2.0155864966812955

Epoch: 5| Step: 4
Training loss: 2.2737252712249756
Validation loss: 2.0255839670858076

Epoch: 5| Step: 5
Training loss: 1.9275999069213867
Validation loss: 2.0182810470622075

Epoch: 5| Step: 6
Training loss: 1.985207200050354
Validation loss: 2.022129733075378

Epoch: 5| Step: 7
Training loss: 1.755021333694458
Validation loss: 2.031610817037603

Epoch: 5| Step: 8
Training loss: 1.8989365100860596
Validation loss: 2.024101067614812

Epoch: 5| Step: 9
Training loss: 1.8078632354736328
Validation loss: 2.0418867731607087

Epoch: 5| Step: 10
Training loss: 1.6850132942199707
Validation loss: 2.0354925586331274

Epoch: 167| Step: 0
Training loss: 1.9452072381973267
Validation loss: 2.0305124252073226

Epoch: 5| Step: 1
Training loss: 1.2213695049285889
Validation loss: 2.0295006562304754

Epoch: 5| Step: 2
Training loss: 1.9482078552246094
Validation loss: 2.040277361869812

Epoch: 5| Step: 3
Training loss: 1.8300132751464844
Validation loss: 2.0219629682520384

Epoch: 5| Step: 4
Training loss: 1.847630262374878
Validation loss: 2.0123499593427105

Epoch: 5| Step: 5
Training loss: 2.397967576980591
Validation loss: 2.0186860894644134

Epoch: 5| Step: 6
Training loss: 2.107391834259033
Validation loss: 2.0062464924268824

Epoch: 5| Step: 7
Training loss: 2.3990495204925537
Validation loss: 2.0118938671645297

Epoch: 5| Step: 8
Training loss: 2.4187541007995605
Validation loss: 2.0082429993537163

Epoch: 5| Step: 9
Training loss: 1.9539579153060913
Validation loss: 1.9887405877472253

Epoch: 5| Step: 10
Training loss: 2.125985622406006
Validation loss: 2.0160698403594313

Epoch: 168| Step: 0
Training loss: 2.0015435218811035
Validation loss: 2.0047362248102822

Epoch: 5| Step: 1
Training loss: 1.650684118270874
Validation loss: 2.020333764373615

Epoch: 5| Step: 2
Training loss: 1.2486363649368286
Validation loss: 2.0313414245523433

Epoch: 5| Step: 3
Training loss: 2.1449692249298096
Validation loss: 2.0098252552811817

Epoch: 5| Step: 4
Training loss: 2.303496837615967
Validation loss: 2.01118867628036

Epoch: 5| Step: 5
Training loss: 2.0629563331604004
Validation loss: 2.0174031090992752

Epoch: 5| Step: 6
Training loss: 2.2121193408966064
Validation loss: 2.020356999930515

Epoch: 5| Step: 7
Training loss: 2.4407553672790527
Validation loss: 1.996552796774013

Epoch: 5| Step: 8
Training loss: 2.3541388511657715
Validation loss: 2.03643822926347

Epoch: 5| Step: 9
Training loss: 1.9536739587783813
Validation loss: 2.014335575924125

Epoch: 5| Step: 10
Training loss: 2.035564422607422
Validation loss: 2.0050315882570002

Epoch: 169| Step: 0
Training loss: 2.2795820236206055
Validation loss: 2.0134283701578775

Epoch: 5| Step: 1
Training loss: 2.0991244316101074
Validation loss: 2.025320314591931

Epoch: 5| Step: 2
Training loss: 1.5227904319763184
Validation loss: 2.0125216194378432

Epoch: 5| Step: 3
Training loss: 2.193887233734131
Validation loss: 2.031911765375445

Epoch: 5| Step: 4
Training loss: 1.6453365087509155
Validation loss: 2.024743224984856

Epoch: 5| Step: 5
Training loss: 2.8348946571350098
Validation loss: 2.0048462690845614

Epoch: 5| Step: 6
Training loss: 2.1980605125427246
Validation loss: 2.0190094876033005

Epoch: 5| Step: 7
Training loss: 1.8751764297485352
Validation loss: 2.006374309139867

Epoch: 5| Step: 8
Training loss: 1.772300362586975
Validation loss: 2.028317964205178

Epoch: 5| Step: 9
Training loss: 1.9558223485946655
Validation loss: 1.9976799693158878

Epoch: 5| Step: 10
Training loss: 1.8468761444091797
Validation loss: 2.0017201644118114

Epoch: 170| Step: 0
Training loss: 2.103076457977295
Validation loss: 1.9985456902493712

Epoch: 5| Step: 1
Training loss: 2.1743059158325195
Validation loss: 1.999762333849425

Epoch: 5| Step: 2
Training loss: 2.2052524089813232
Validation loss: 2.0072113801074285

Epoch: 5| Step: 3
Training loss: 1.9916718006134033
Validation loss: 2.0119518515884236

Epoch: 5| Step: 4
Training loss: 2.0822556018829346
Validation loss: 2.0141515090901363

Epoch: 5| Step: 5
Training loss: 2.1128056049346924
Validation loss: 2.0114056653873895

Epoch: 5| Step: 6
Training loss: 1.8769502639770508
Validation loss: 2.025319596772553

Epoch: 5| Step: 7
Training loss: 1.631395697593689
Validation loss: 2.029316266377767

Epoch: 5| Step: 8
Training loss: 2.041142702102661
Validation loss: 2.011964587755101

Epoch: 5| Step: 9
Training loss: 1.551318645477295
Validation loss: 2.0166693682311685

Epoch: 5| Step: 10
Training loss: 2.2943339347839355
Validation loss: 1.9982032557969451

Epoch: 171| Step: 0
Training loss: 1.4976197481155396
Validation loss: 2.02209484705361

Epoch: 5| Step: 1
Training loss: 2.2735328674316406
Validation loss: 2.0103460499035415

Epoch: 5| Step: 2
Training loss: 1.2753576040267944
Validation loss: 2.0193909650207846

Epoch: 5| Step: 3
Training loss: 2.6308650970458984
Validation loss: 2.0081100169048516

Epoch: 5| Step: 4
Training loss: 1.6066166162490845
Validation loss: 2.0154854046401156

Epoch: 5| Step: 5
Training loss: 2.355764627456665
Validation loss: 2.0098035348358976

Epoch: 5| Step: 6
Training loss: 2.477288246154785
Validation loss: 2.014782763296558

Epoch: 5| Step: 7
Training loss: 1.8188979625701904
Validation loss: 2.0101906214990923

Epoch: 5| Step: 8
Training loss: 2.3968605995178223
Validation loss: 2.0175592271230554

Epoch: 5| Step: 9
Training loss: 1.8576204776763916
Validation loss: 2.005527275864796

Epoch: 5| Step: 10
Training loss: 1.7130454778671265
Validation loss: 1.9896194140116374

Epoch: 172| Step: 0
Training loss: 1.5861461162567139
Validation loss: 1.9958406109963693

Epoch: 5| Step: 1
Training loss: 2.246593713760376
Validation loss: 2.000598281942388

Epoch: 5| Step: 2
Training loss: 2.217597484588623
Validation loss: 2.019713968359014

Epoch: 5| Step: 3
Training loss: 2.032958507537842
Validation loss: 1.99768143059105

Epoch: 5| Step: 4
Training loss: 1.7092288732528687
Validation loss: 2.0146795190790647

Epoch: 5| Step: 5
Training loss: 2.6122422218322754
Validation loss: 1.9980029341995076

Epoch: 5| Step: 6
Training loss: 2.7955517768859863
Validation loss: 2.0007738182621617

Epoch: 5| Step: 7
Training loss: 1.695599913597107
Validation loss: 1.999526020019285

Epoch: 5| Step: 8
Training loss: 1.1639763116836548
Validation loss: 1.995086669921875

Epoch: 5| Step: 9
Training loss: 2.1459262371063232
Validation loss: 2.0041777446705806

Epoch: 5| Step: 10
Training loss: 1.96412992477417
Validation loss: 1.995148310097315

Epoch: 173| Step: 0
Training loss: 1.996538519859314
Validation loss: 2.0020616426262805

Epoch: 5| Step: 1
Training loss: 2.23317813873291
Validation loss: 2.0184976926413913

Epoch: 5| Step: 2
Training loss: 1.7808864116668701
Validation loss: 2.013127939675444

Epoch: 5| Step: 3
Training loss: 2.1809451580047607
Validation loss: 2.008685088926746

Epoch: 5| Step: 4
Training loss: 2.3695034980773926
Validation loss: 1.9974410405722998

Epoch: 5| Step: 5
Training loss: 1.8582302331924438
Validation loss: 2.0010504107321463

Epoch: 5| Step: 6
Training loss: 1.624260663986206
Validation loss: 2.020665531517357

Epoch: 5| Step: 7
Training loss: 1.5899066925048828
Validation loss: 2.0192704508381505

Epoch: 5| Step: 8
Training loss: 1.9712865352630615
Validation loss: 2.0001557847504974

Epoch: 5| Step: 9
Training loss: 2.216073513031006
Validation loss: 2.0267949232491116

Epoch: 5| Step: 10
Training loss: 2.2594754695892334
Validation loss: 2.008649810667961

Epoch: 174| Step: 0
Training loss: 1.3440548181533813
Validation loss: 2.0010022732519333

Epoch: 5| Step: 1
Training loss: 1.9544503688812256
Validation loss: 1.994798493641679

Epoch: 5| Step: 2
Training loss: 1.9146846532821655
Validation loss: 2.00347202567644

Epoch: 5| Step: 3
Training loss: 2.0566980838775635
Validation loss: 2.014317920131068

Epoch: 5| Step: 4
Training loss: 2.503931760787964
Validation loss: 1.9958076297595937

Epoch: 5| Step: 5
Training loss: 2.480764389038086
Validation loss: 1.988918883826143

Epoch: 5| Step: 6
Training loss: 2.2096235752105713
Validation loss: 2.002428079164156

Epoch: 5| Step: 7
Training loss: 1.407130479812622
Validation loss: 2.0147259619928177

Epoch: 5| Step: 8
Training loss: 2.0112557411193848
Validation loss: 2.007509531513337

Epoch: 5| Step: 9
Training loss: 2.177504777908325
Validation loss: 2.0141685624276437

Epoch: 5| Step: 10
Training loss: 2.0630106925964355
Validation loss: 2.029554574720321

Epoch: 175| Step: 0
Training loss: 2.084726095199585
Validation loss: 1.9941791629278531

Epoch: 5| Step: 1
Training loss: 1.9754173755645752
Validation loss: 2.009883503760061

Epoch: 5| Step: 2
Training loss: 2.691725015640259
Validation loss: 1.9859265153126051

Epoch: 5| Step: 3
Training loss: 1.705434799194336
Validation loss: 2.028600891431173

Epoch: 5| Step: 4
Training loss: 1.310118317604065
Validation loss: 1.9915379593449254

Epoch: 5| Step: 5
Training loss: 1.683301568031311
Validation loss: 1.9972795132667787

Epoch: 5| Step: 6
Training loss: 2.078000545501709
Validation loss: 2.035799223889587

Epoch: 5| Step: 7
Training loss: 1.9536521434783936
Validation loss: 2.036522670458722

Epoch: 5| Step: 8
Training loss: 2.1015079021453857
Validation loss: 2.016121093944837

Epoch: 5| Step: 9
Training loss: 2.4299755096435547
Validation loss: 2.020958153150415

Epoch: 5| Step: 10
Training loss: 2.082839250564575
Validation loss: 2.0218246521488314

Epoch: 176| Step: 0
Training loss: 2.234727621078491
Validation loss: 2.023458050143334

Epoch: 5| Step: 1
Training loss: 1.8732563257217407
Validation loss: 2.0183936895862704

Epoch: 5| Step: 2
Training loss: 1.6173698902130127
Validation loss: 2.015314536709939

Epoch: 5| Step: 3
Training loss: 2.4731154441833496
Validation loss: 2.0160168729802614

Epoch: 5| Step: 4
Training loss: 1.4671738147735596
Validation loss: 2.0091490348180137

Epoch: 5| Step: 5
Training loss: 2.612450122833252
Validation loss: 2.046590324371092

Epoch: 5| Step: 6
Training loss: 1.9267669916152954
Validation loss: 2.0174945426243607

Epoch: 5| Step: 7
Training loss: 1.1146851778030396
Validation loss: 2.0093741468203965

Epoch: 5| Step: 8
Training loss: 2.1993792057037354
Validation loss: 2.0191015825476697

Epoch: 5| Step: 9
Training loss: 2.3807501792907715
Validation loss: 2.0332181504977647

Epoch: 5| Step: 10
Training loss: 2.0294954776763916
Validation loss: 2.0128201489807456

Epoch: 177| Step: 0
Training loss: 2.1692614555358887
Validation loss: 2.0084440015977427

Epoch: 5| Step: 1
Training loss: 1.8690385818481445
Validation loss: 2.0025997277229064

Epoch: 5| Step: 2
Training loss: 2.4671225547790527
Validation loss: 2.010444438585671

Epoch: 5| Step: 3
Training loss: 1.6994739770889282
Validation loss: 2.0136102989155757

Epoch: 5| Step: 4
Training loss: 1.9291763305664062
Validation loss: 2.018034879879285

Epoch: 5| Step: 5
Training loss: 2.0317792892456055
Validation loss: 1.9896657671979678

Epoch: 5| Step: 6
Training loss: 1.4857456684112549
Validation loss: 2.004113269108598

Epoch: 5| Step: 7
Training loss: 1.6905930042266846
Validation loss: 1.9867580834255423

Epoch: 5| Step: 8
Training loss: 2.274470806121826
Validation loss: 1.9909529814156153

Epoch: 5| Step: 9
Training loss: 1.969830870628357
Validation loss: 2.012605022358638

Epoch: 5| Step: 10
Training loss: 2.5245468616485596
Validation loss: 2.0005210548318844

Epoch: 178| Step: 0
Training loss: 1.7707767486572266
Validation loss: 1.9865652886770104

Epoch: 5| Step: 1
Training loss: 1.6764888763427734
Validation loss: 2.01595478416771

Epoch: 5| Step: 2
Training loss: 1.6596348285675049
Validation loss: 1.996152872680336

Epoch: 5| Step: 3
Training loss: 2.458252191543579
Validation loss: 2.005371824387581

Epoch: 5| Step: 4
Training loss: 1.5671266317367554
Validation loss: 2.005978871417302

Epoch: 5| Step: 5
Training loss: 2.365055799484253
Validation loss: 1.996247835056756

Epoch: 5| Step: 6
Training loss: 2.1570472717285156
Validation loss: 2.024352599215764

Epoch: 5| Step: 7
Training loss: 2.8291430473327637
Validation loss: 2.0133209177242812

Epoch: 5| Step: 8
Training loss: 1.8244049549102783
Validation loss: 2.0281524248020624

Epoch: 5| Step: 9
Training loss: 2.092071533203125
Validation loss: 1.9964060962841075

Epoch: 5| Step: 10
Training loss: 1.5957518815994263
Validation loss: 2.01424176590417

Epoch: 179| Step: 0
Training loss: 1.8773269653320312
Validation loss: 2.022129915093863

Epoch: 5| Step: 1
Training loss: 2.4033195972442627
Validation loss: 2.000138682703818

Epoch: 5| Step: 2
Training loss: 1.8887970447540283
Validation loss: 2.0053564797165575

Epoch: 5| Step: 3
Training loss: 1.8068122863769531
Validation loss: 2.021071514775676

Epoch: 5| Step: 4
Training loss: 2.2823829650878906
Validation loss: 2.0169780382546048

Epoch: 5| Step: 5
Training loss: 1.851980209350586
Validation loss: 2.0161214849000335

Epoch: 5| Step: 6
Training loss: 1.8969275951385498
Validation loss: 2.029342738530969

Epoch: 5| Step: 7
Training loss: 1.930694341659546
Validation loss: 2.0160850927393925

Epoch: 5| Step: 8
Training loss: 1.8424303531646729
Validation loss: 2.0281982960239535

Epoch: 5| Step: 9
Training loss: 1.9879169464111328
Validation loss: 2.0062385169408654

Epoch: 5| Step: 10
Training loss: 2.3133420944213867
Validation loss: 2.0273943921571136

Epoch: 180| Step: 0
Training loss: 2.0467190742492676
Validation loss: 2.0160171857444187

Epoch: 5| Step: 1
Training loss: 1.7882035970687866
Validation loss: 2.0092670661146923

Epoch: 5| Step: 2
Training loss: 2.3229687213897705
Validation loss: 2.0198880344308834

Epoch: 5| Step: 3
Training loss: 2.140725612640381
Validation loss: 2.005179282157652

Epoch: 5| Step: 4
Training loss: 2.635279893875122
Validation loss: 2.0088747957701325

Epoch: 5| Step: 5
Training loss: 2.2083535194396973
Validation loss: 1.9825673949333928

Epoch: 5| Step: 6
Training loss: 2.140133857727051
Validation loss: 2.0158802565707954

Epoch: 5| Step: 7
Training loss: 1.4287339448928833
Validation loss: 2.011075476164459

Epoch: 5| Step: 8
Training loss: 1.5122092962265015
Validation loss: 2.008618673970622

Epoch: 5| Step: 9
Training loss: 1.886944055557251
Validation loss: 1.9915269138992473

Epoch: 5| Step: 10
Training loss: 1.872450590133667
Validation loss: 1.995679557964366

Epoch: 181| Step: 0
Training loss: 2.4903934001922607
Validation loss: 2.010766234449161

Epoch: 5| Step: 1
Training loss: 2.183349847793579
Validation loss: 2.005403390494726

Epoch: 5| Step: 2
Training loss: 1.714141607284546
Validation loss: 1.9949486742737472

Epoch: 5| Step: 3
Training loss: 2.6150341033935547
Validation loss: 2.0194354903313423

Epoch: 5| Step: 4
Training loss: 1.8288236856460571
Validation loss: 2.0157248384209088

Epoch: 5| Step: 5
Training loss: 1.878061294555664
Validation loss: 2.0109981388174076

Epoch: 5| Step: 6
Training loss: 1.8118352890014648
Validation loss: 1.9971509159252208

Epoch: 5| Step: 7
Training loss: 1.7418549060821533
Validation loss: 1.9995550314585369

Epoch: 5| Step: 8
Training loss: 1.8066768646240234
Validation loss: 2.005871211328814

Epoch: 5| Step: 9
Training loss: 1.7002134323120117
Validation loss: 1.9992216120484054

Epoch: 5| Step: 10
Training loss: 2.0295090675354004
Validation loss: 1.9978733037107734

Epoch: 182| Step: 0
Training loss: 2.006923198699951
Validation loss: 1.9938592718493553

Epoch: 5| Step: 1
Training loss: 1.8397305011749268
Validation loss: 2.0047393768064437

Epoch: 5| Step: 2
Training loss: 1.8565927743911743
Validation loss: 2.0062119768511866

Epoch: 5| Step: 3
Training loss: 2.270540237426758
Validation loss: 2.010730387062155

Epoch: 5| Step: 4
Training loss: 1.8431291580200195
Validation loss: 2.039653880621797

Epoch: 5| Step: 5
Training loss: 2.488265037536621
Validation loss: 1.9966662763267435

Epoch: 5| Step: 6
Training loss: 2.0350728034973145
Validation loss: 2.01103183274628

Epoch: 5| Step: 7
Training loss: 1.8754539489746094
Validation loss: 2.0160140222118748

Epoch: 5| Step: 8
Training loss: 2.210904598236084
Validation loss: 2.0005218457150202

Epoch: 5| Step: 9
Training loss: 1.649605393409729
Validation loss: 2.028544338800574

Epoch: 5| Step: 10
Training loss: 1.5245565176010132
Validation loss: 1.9990292492733206

Epoch: 183| Step: 0
Training loss: 2.216275691986084
Validation loss: 2.0243608272203835

Epoch: 5| Step: 1
Training loss: 2.2524375915527344
Validation loss: 2.0158371899717595

Epoch: 5| Step: 2
Training loss: 2.2747511863708496
Validation loss: 2.0104054635570896

Epoch: 5| Step: 3
Training loss: 1.401557445526123
Validation loss: 2.013321412506924

Epoch: 5| Step: 4
Training loss: 1.9400304555892944
Validation loss: 2.0069341287818006

Epoch: 5| Step: 5
Training loss: 2.054445743560791
Validation loss: 2.0254214476513606

Epoch: 5| Step: 6
Training loss: 1.6780389547348022
Validation loss: 1.9843045537189772

Epoch: 5| Step: 7
Training loss: 2.1196885108947754
Validation loss: 2.0002997780358918

Epoch: 5| Step: 8
Training loss: 2.5582714080810547
Validation loss: 2.0147810597573557

Epoch: 5| Step: 9
Training loss: 1.413665533065796
Validation loss: 1.9993439053976407

Epoch: 5| Step: 10
Training loss: 1.9882705211639404
Validation loss: 2.009929049399591

Epoch: 184| Step: 0
Training loss: 2.572683811187744
Validation loss: 2.0111931805969565

Epoch: 5| Step: 1
Training loss: 1.7261943817138672
Validation loss: 1.9929166455422678

Epoch: 5| Step: 2
Training loss: 2.0592434406280518
Validation loss: 2.0021870405443254

Epoch: 5| Step: 3
Training loss: 1.7203242778778076
Validation loss: 1.9979329263010333

Epoch: 5| Step: 4
Training loss: 2.130115032196045
Validation loss: 2.001396034353523

Epoch: 5| Step: 5
Training loss: 2.247293472290039
Validation loss: 2.002371567551808

Epoch: 5| Step: 6
Training loss: 1.8975093364715576
Validation loss: 1.994125925084596

Epoch: 5| Step: 7
Training loss: 1.645615577697754
Validation loss: 2.0131137140335573

Epoch: 5| Step: 8
Training loss: 1.7139068841934204
Validation loss: 1.9996671151089411

Epoch: 5| Step: 9
Training loss: 2.0581917762756348
Validation loss: 1.9948857240779425

Epoch: 5| Step: 10
Training loss: 2.1248981952667236
Validation loss: 2.027168499526157

Epoch: 185| Step: 0
Training loss: 1.7495720386505127
Validation loss: 2.0062008750054146

Epoch: 5| Step: 1
Training loss: 1.3156269788742065
Validation loss: 2.0224840384657665

Epoch: 5| Step: 2
Training loss: 1.368035078048706
Validation loss: 2.000316410936335

Epoch: 5| Step: 3
Training loss: 2.3375136852264404
Validation loss: 1.9814945818275533

Epoch: 5| Step: 4
Training loss: 2.8401501178741455
Validation loss: 2.0074859819104596

Epoch: 5| Step: 5
Training loss: 1.223344087600708
Validation loss: 1.9841178104441652

Epoch: 5| Step: 6
Training loss: 2.560842990875244
Validation loss: 2.0070079039501887

Epoch: 5| Step: 7
Training loss: 2.0589075088500977
Validation loss: 1.9823715135615358

Epoch: 5| Step: 8
Training loss: 2.3063788414001465
Validation loss: 2.0077486781663794

Epoch: 5| Step: 9
Training loss: 2.2038016319274902
Validation loss: 1.9918187690037552

Epoch: 5| Step: 10
Training loss: 1.7175796031951904
Validation loss: 2.022183479801301

Epoch: 186| Step: 0
Training loss: 2.5470213890075684
Validation loss: 2.023771979475534

Epoch: 5| Step: 1
Training loss: 1.6720235347747803
Validation loss: 1.9943648628009263

Epoch: 5| Step: 2
Training loss: 2.510775089263916
Validation loss: 2.007716751867725

Epoch: 5| Step: 3
Training loss: 2.088317632675171
Validation loss: 1.998623142960251

Epoch: 5| Step: 4
Training loss: 1.327883243560791
Validation loss: 2.010919822159634

Epoch: 5| Step: 5
Training loss: 1.7334887981414795
Validation loss: 2.0129668661343154

Epoch: 5| Step: 6
Training loss: 1.9628280401229858
Validation loss: 2.0275227997892644

Epoch: 5| Step: 7
Training loss: 2.0486698150634766
Validation loss: 2.0180715642949587

Epoch: 5| Step: 8
Training loss: 2.350992441177368
Validation loss: 2.01696208471893

Epoch: 5| Step: 9
Training loss: 2.1763503551483154
Validation loss: 1.994811863027593

Epoch: 5| Step: 10
Training loss: 1.4235191345214844
Validation loss: 2.005804451563025

Epoch: 187| Step: 0
Training loss: 2.161776542663574
Validation loss: 2.0218788244391

Epoch: 5| Step: 1
Training loss: 2.055685520172119
Validation loss: 2.011346418370483

Epoch: 5| Step: 2
Training loss: 2.0093770027160645
Validation loss: 1.9885861283989363

Epoch: 5| Step: 3
Training loss: 1.5880011320114136
Validation loss: 2.0143633170794417

Epoch: 5| Step: 4
Training loss: 2.4956836700439453
Validation loss: 2.0112655547357376

Epoch: 5| Step: 5
Training loss: 1.5155540704727173
Validation loss: 1.9823822462430565

Epoch: 5| Step: 6
Training loss: 1.9840352535247803
Validation loss: 1.996778198467788

Epoch: 5| Step: 7
Training loss: 2.1671853065490723
Validation loss: 1.991733717662032

Epoch: 5| Step: 8
Training loss: 2.0722405910491943
Validation loss: 2.0116203497814875

Epoch: 5| Step: 9
Training loss: 1.9223703145980835
Validation loss: 1.9839043386520878

Epoch: 5| Step: 10
Training loss: 1.8554975986480713
Validation loss: 2.0063900921934392

Epoch: 188| Step: 0
Training loss: 1.9462220668792725
Validation loss: 1.9904587986648723

Epoch: 5| Step: 1
Training loss: 1.7680606842041016
Validation loss: 2.007838224851957

Epoch: 5| Step: 2
Training loss: 2.150005578994751
Validation loss: 1.9955087707888695

Epoch: 5| Step: 3
Training loss: 1.5268751382827759
Validation loss: 2.017924212640332

Epoch: 5| Step: 4
Training loss: 1.9880573749542236
Validation loss: 1.9899582375762284

Epoch: 5| Step: 5
Training loss: 1.7552725076675415
Validation loss: 1.9978259109681653

Epoch: 5| Step: 6
Training loss: 2.3402445316314697
Validation loss: 2.0275610576393786

Epoch: 5| Step: 7
Training loss: 2.5548315048217773
Validation loss: 1.9975464779843566

Epoch: 5| Step: 8
Training loss: 2.0484726428985596
Validation loss: 1.9959000848954724

Epoch: 5| Step: 9
Training loss: 2.2785134315490723
Validation loss: 2.0015488414354223

Epoch: 5| Step: 10
Training loss: 1.362829566001892
Validation loss: 2.0056025981903076

Epoch: 189| Step: 0
Training loss: 1.9506088495254517
Validation loss: 1.988810746900497

Epoch: 5| Step: 1
Training loss: 1.4498692750930786
Validation loss: 1.9951523221949095

Epoch: 5| Step: 2
Training loss: 2.1454646587371826
Validation loss: 2.0149993614483903

Epoch: 5| Step: 3
Training loss: 1.7420011758804321
Validation loss: 1.992503914781796

Epoch: 5| Step: 4
Training loss: 1.505234956741333
Validation loss: 1.9786523055004817

Epoch: 5| Step: 5
Training loss: 2.1023974418640137
Validation loss: 1.9986746106096493

Epoch: 5| Step: 6
Training loss: 2.069504976272583
Validation loss: 1.9988074328309746

Epoch: 5| Step: 7
Training loss: 2.2348694801330566
Validation loss: 1.9871308329284831

Epoch: 5| Step: 8
Training loss: 1.5272283554077148
Validation loss: 2.0073418335248063

Epoch: 5| Step: 9
Training loss: 1.8855794668197632
Validation loss: 2.026254810312743

Epoch: 5| Step: 10
Training loss: 3.0762510299682617
Validation loss: 2.022569303871483

Epoch: 190| Step: 0
Training loss: 1.5857179164886475
Validation loss: 2.026029570128328

Epoch: 5| Step: 1
Training loss: 1.5032625198364258
Validation loss: 2.017870003177274

Epoch: 5| Step: 2
Training loss: 2.514460325241089
Validation loss: 1.9934145917174637

Epoch: 5| Step: 3
Training loss: 2.0041422843933105
Validation loss: 1.9825418661999445

Epoch: 5| Step: 4
Training loss: 2.283712387084961
Validation loss: 2.009224493016479

Epoch: 5| Step: 5
Training loss: 1.9515600204467773
Validation loss: 2.000946698650237

Epoch: 5| Step: 6
Training loss: 1.9451789855957031
Validation loss: 2.00860349593624

Epoch: 5| Step: 7
Training loss: 2.5485880374908447
Validation loss: 1.981893411246679

Epoch: 5| Step: 8
Training loss: 1.6453237533569336
Validation loss: 2.0038709384138866

Epoch: 5| Step: 9
Training loss: 2.3348851203918457
Validation loss: 2.01295446067728

Epoch: 5| Step: 10
Training loss: 1.1801363229751587
Validation loss: 2.013147954017885

Epoch: 191| Step: 0
Training loss: 2.13857364654541
Validation loss: 1.9893064601446993

Epoch: 5| Step: 1
Training loss: 1.7443573474884033
Validation loss: 1.9824066982474378

Epoch: 5| Step: 2
Training loss: 2.3045718669891357
Validation loss: 2.015809602634881

Epoch: 5| Step: 3
Training loss: 1.6214059591293335
Validation loss: 2.005190182757634

Epoch: 5| Step: 4
Training loss: 1.7798397541046143
Validation loss: 2.0005976102685414

Epoch: 5| Step: 5
Training loss: 2.3416037559509277
Validation loss: 1.997828697645536

Epoch: 5| Step: 6
Training loss: 1.91498601436615
Validation loss: 2.0153824424230926

Epoch: 5| Step: 7
Training loss: 1.9361827373504639
Validation loss: 2.0163469545302855

Epoch: 5| Step: 8
Training loss: 2.1540417671203613
Validation loss: 2.004517621891473

Epoch: 5| Step: 9
Training loss: 1.632279396057129
Validation loss: 1.9963302048303748

Epoch: 5| Step: 10
Training loss: 1.9836894273757935
Validation loss: 2.0071586716559624

Epoch: 192| Step: 0
Training loss: 2.55422306060791
Validation loss: 1.9851236074201521

Epoch: 5| Step: 1
Training loss: 2.1261186599731445
Validation loss: 2.003944529000149

Epoch: 5| Step: 2
Training loss: 1.9499439001083374
Validation loss: 1.9821374775261007

Epoch: 5| Step: 3
Training loss: 1.642319917678833
Validation loss: 2.023678651420019

Epoch: 5| Step: 4
Training loss: 1.970965027809143
Validation loss: 1.9780475401109265

Epoch: 5| Step: 5
Training loss: 1.800519585609436
Validation loss: 2.002278402287473

Epoch: 5| Step: 6
Training loss: 2.1126668453216553
Validation loss: 2.000938779564314

Epoch: 5| Step: 7
Training loss: 2.0292983055114746
Validation loss: 2.0042128768018497

Epoch: 5| Step: 8
Training loss: 2.1558003425598145
Validation loss: 1.997586856606186

Epoch: 5| Step: 9
Training loss: 1.8515222072601318
Validation loss: 2.008467969074044

Epoch: 5| Step: 10
Training loss: 1.1466645002365112
Validation loss: 2.000072625375563

Epoch: 193| Step: 0
Training loss: 0.9779245257377625
Validation loss: 1.9985836962217927

Epoch: 5| Step: 1
Training loss: 1.558268666267395
Validation loss: 2.012189428011576

Epoch: 5| Step: 2
Training loss: 1.687347412109375
Validation loss: 2.007612474503056

Epoch: 5| Step: 3
Training loss: 1.8949272632598877
Validation loss: 1.9900789568501134

Epoch: 5| Step: 4
Training loss: 2.0949907302856445
Validation loss: 1.9865823868782289

Epoch: 5| Step: 5
Training loss: 2.331373453140259
Validation loss: 1.9836938573468117

Epoch: 5| Step: 6
Training loss: 1.9229110479354858
Validation loss: 1.991367889988807

Epoch: 5| Step: 7
Training loss: 2.3896303176879883
Validation loss: 2.0164212103812926

Epoch: 5| Step: 8
Training loss: 1.9420747756958008
Validation loss: 2.000868171773931

Epoch: 5| Step: 9
Training loss: 2.237900972366333
Validation loss: 1.9983469401636431

Epoch: 5| Step: 10
Training loss: 2.410539388656616
Validation loss: 1.995489497338572

Epoch: 194| Step: 0
Training loss: 1.4557174444198608
Validation loss: 1.992654259486865

Epoch: 5| Step: 1
Training loss: 2.2712104320526123
Validation loss: 2.00189055678665

Epoch: 5| Step: 2
Training loss: 2.178028106689453
Validation loss: 1.9959344351163475

Epoch: 5| Step: 3
Training loss: 2.7896761894226074
Validation loss: 2.0296902092554236

Epoch: 5| Step: 4
Training loss: 1.8135566711425781
Validation loss: 2.012782158390168

Epoch: 5| Step: 5
Training loss: 1.9679086208343506
Validation loss: 2.0269686611749793

Epoch: 5| Step: 6
Training loss: 2.4006316661834717
Validation loss: 1.989370479378649

Epoch: 5| Step: 7
Training loss: 1.908782720565796
Validation loss: 1.9939161269895491

Epoch: 5| Step: 8
Training loss: 1.304523229598999
Validation loss: 2.0060156160785305

Epoch: 5| Step: 9
Training loss: 2.40175461769104
Validation loss: 2.02393251849759

Epoch: 5| Step: 10
Training loss: 1.0878682136535645
Validation loss: 1.9787636277496174

Epoch: 195| Step: 0
Training loss: 2.0585579872131348
Validation loss: 2.0287720029072096

Epoch: 5| Step: 1
Training loss: 2.2371718883514404
Validation loss: 2.017716948704053

Epoch: 5| Step: 2
Training loss: 1.6541502475738525
Validation loss: 2.0101611639863703

Epoch: 5| Step: 3
Training loss: 1.6385005712509155
Validation loss: 1.99489813850772

Epoch: 5| Step: 4
Training loss: 2.3112480640411377
Validation loss: 2.0125744112076296

Epoch: 5| Step: 5
Training loss: 1.9062544107437134
Validation loss: 2.0038593033308625

Epoch: 5| Step: 6
Training loss: 2.2212953567504883
Validation loss: 2.0063308977311656

Epoch: 5| Step: 7
Training loss: 1.812241792678833
Validation loss: 2.0005560882629885

Epoch: 5| Step: 8
Training loss: 1.7417278289794922
Validation loss: 1.9992092347914172

Epoch: 5| Step: 9
Training loss: 1.4483200311660767
Validation loss: 2.0164223281286096

Epoch: 5| Step: 10
Training loss: 2.596921920776367
Validation loss: 1.9817679979467904

Epoch: 196| Step: 0
Training loss: 1.2486567497253418
Validation loss: 1.9772319601428123

Epoch: 5| Step: 1
Training loss: 1.6487400531768799
Validation loss: 2.0017029828922723

Epoch: 5| Step: 2
Training loss: 1.4242384433746338
Validation loss: 2.002210360701366

Epoch: 5| Step: 3
Training loss: 1.8807872533798218
Validation loss: 1.9985558320117254

Epoch: 5| Step: 4
Training loss: 2.350074291229248
Validation loss: 1.966120332799932

Epoch: 5| Step: 5
Training loss: 2.4951701164245605
Validation loss: 2.0097614078111548

Epoch: 5| Step: 6
Training loss: 1.6144860982894897
Validation loss: 2.0004176785868983

Epoch: 5| Step: 7
Training loss: 1.9227997064590454
Validation loss: 2.0056025494811354

Epoch: 5| Step: 8
Training loss: 2.1160473823547363
Validation loss: 2.0099541705141784

Epoch: 5| Step: 9
Training loss: 2.1487202644348145
Validation loss: 1.9938573555279804

Epoch: 5| Step: 10
Training loss: 2.643723726272583
Validation loss: 1.9733204431431268

Epoch: 197| Step: 0
Training loss: 2.629456043243408
Validation loss: 2.0069181162823915

Epoch: 5| Step: 1
Training loss: 1.9725669622421265
Validation loss: 2.016982800217085

Epoch: 5| Step: 2
Training loss: 1.9413515329360962
Validation loss: 2.029763998523835

Epoch: 5| Step: 3
Training loss: 2.1376209259033203
Validation loss: 1.9829625032281364

Epoch: 5| Step: 4
Training loss: 1.8417679071426392
Validation loss: 1.9962536981028896

Epoch: 5| Step: 5
Training loss: 1.7398669719696045
Validation loss: 2.0144129542894262

Epoch: 5| Step: 6
Training loss: 2.011101484298706
Validation loss: 1.9864464165062032

Epoch: 5| Step: 7
Training loss: 1.5357162952423096
Validation loss: 1.9846096231091408

Epoch: 5| Step: 8
Training loss: 1.455222487449646
Validation loss: 1.9766841883300452

Epoch: 5| Step: 9
Training loss: 1.9728587865829468
Validation loss: 1.9619819592404109

Epoch: 5| Step: 10
Training loss: 2.261772871017456
Validation loss: 1.982302108118611

Epoch: 198| Step: 0
Training loss: 2.116299867630005
Validation loss: 2.013321001042602

Epoch: 5| Step: 1
Training loss: 2.0174803733825684
Validation loss: 1.993301127546577

Epoch: 5| Step: 2
Training loss: 1.4839940071105957
Validation loss: 2.0058963080888152

Epoch: 5| Step: 3
Training loss: 1.7878143787384033
Validation loss: 1.994550612664992

Epoch: 5| Step: 4
Training loss: 1.6602779626846313
Validation loss: 2.024904909954276

Epoch: 5| Step: 5
Training loss: 2.238186836242676
Validation loss: 2.036970084713351

Epoch: 5| Step: 6
Training loss: 1.9135223627090454
Validation loss: 2.024226926988171

Epoch: 5| Step: 7
Training loss: 2.344107151031494
Validation loss: 1.9912681156589138

Epoch: 5| Step: 8
Training loss: 1.879604697227478
Validation loss: 2.0294840130754697

Epoch: 5| Step: 9
Training loss: 2.059415578842163
Validation loss: 2.007761416896697

Epoch: 5| Step: 10
Training loss: 2.0015757083892822
Validation loss: 1.9761920282917638

Epoch: 199| Step: 0
Training loss: 1.7217140197753906
Validation loss: 1.9917465563743346

Epoch: 5| Step: 1
Training loss: 1.8635101318359375
Validation loss: 2.017171741813742

Epoch: 5| Step: 2
Training loss: 2.3640315532684326
Validation loss: 2.0111627450553318

Epoch: 5| Step: 3
Training loss: 1.837825059890747
Validation loss: 2.002204656600952

Epoch: 5| Step: 4
Training loss: 1.7163254022598267
Validation loss: 2.0111839873816377

Epoch: 5| Step: 5
Training loss: 2.1268811225891113
Validation loss: 2.0058636767889864

Epoch: 5| Step: 6
Training loss: 2.1800379753112793
Validation loss: 2.0033038098325013

Epoch: 5| Step: 7
Training loss: 1.71115243434906
Validation loss: 1.9886136003719863

Epoch: 5| Step: 8
Training loss: 1.9457826614379883
Validation loss: 1.9968786085805585

Epoch: 5| Step: 9
Training loss: 2.4108572006225586
Validation loss: 1.9985831501663371

Epoch: 5| Step: 10
Training loss: 1.5401079654693604
Validation loss: 2.0032212016403035

Epoch: 200| Step: 0
Training loss: 2.022374391555786
Validation loss: 1.9896046576961395

Epoch: 5| Step: 1
Training loss: 2.4876153469085693
Validation loss: 1.9903392253383514

Epoch: 5| Step: 2
Training loss: 1.7827930450439453
Validation loss: 2.006567132088446

Epoch: 5| Step: 3
Training loss: 1.9357128143310547
Validation loss: 1.9761871240472282

Epoch: 5| Step: 4
Training loss: 1.7246288061141968
Validation loss: 1.9986944378063243

Epoch: 5| Step: 5
Training loss: 2.345653772354126
Validation loss: 1.9776181277408396

Epoch: 5| Step: 6
Training loss: 1.5543749332427979
Validation loss: 1.9802386581256826

Epoch: 5| Step: 7
Training loss: 1.7440954446792603
Validation loss: 1.9880483458119054

Epoch: 5| Step: 8
Training loss: 2.280470371246338
Validation loss: 1.959627066889117

Epoch: 5| Step: 9
Training loss: 1.9687793254852295
Validation loss: 1.9980842605713875

Epoch: 5| Step: 10
Training loss: 1.507385492324829
Validation loss: 1.9947936342608543

Epoch: 201| Step: 0
Training loss: 2.232210159301758
Validation loss: 1.9848384523904452

Epoch: 5| Step: 1
Training loss: 2.0054662227630615
Validation loss: 1.9886314561290126

Epoch: 5| Step: 2
Training loss: 1.7385286092758179
Validation loss: 2.002070276967941

Epoch: 5| Step: 3
Training loss: 2.1218624114990234
Validation loss: 1.9927529801604569

Epoch: 5| Step: 4
Training loss: 1.2659640312194824
Validation loss: 1.9818957518505793

Epoch: 5| Step: 5
Training loss: 1.816751480102539
Validation loss: 1.9944446548338859

Epoch: 5| Step: 6
Training loss: 2.284921169281006
Validation loss: 2.0031003182934177

Epoch: 5| Step: 7
Training loss: 2.0164802074432373
Validation loss: 2.002734658538654

Epoch: 5| Step: 8
Training loss: 2.10851788520813
Validation loss: 2.0146012049849316

Epoch: 5| Step: 9
Training loss: 1.8730995655059814
Validation loss: 1.9918579773236347

Epoch: 5| Step: 10
Training loss: 1.7932876348495483
Validation loss: 1.9766052512712375

Epoch: 202| Step: 0
Training loss: 2.162904739379883
Validation loss: 1.9880659362321258

Epoch: 5| Step: 1
Training loss: 2.1753926277160645
Validation loss: 1.9944632604557981

Epoch: 5| Step: 2
Training loss: 1.859561562538147
Validation loss: 1.9945708526078092

Epoch: 5| Step: 3
Training loss: 1.9815781116485596
Validation loss: 1.9983040530194518

Epoch: 5| Step: 4
Training loss: 1.1321032047271729
Validation loss: 2.012621291222111

Epoch: 5| Step: 5
Training loss: 2.2351956367492676
Validation loss: 2.0196286016894924

Epoch: 5| Step: 6
Training loss: 1.3697079420089722
Validation loss: 1.9761934382941133

Epoch: 5| Step: 7
Training loss: 1.5834029912948608
Validation loss: 2.001717452080019

Epoch: 5| Step: 8
Training loss: 2.159615993499756
Validation loss: 2.003217015215146

Epoch: 5| Step: 9
Training loss: 2.2264046669006348
Validation loss: 1.9854057578630344

Epoch: 5| Step: 10
Training loss: 2.201900005340576
Validation loss: 1.9982928409371326

Epoch: 203| Step: 0
Training loss: 1.7119085788726807
Validation loss: 1.9906350874131726

Epoch: 5| Step: 1
Training loss: 2.132624387741089
Validation loss: 1.9777464379546463

Epoch: 5| Step: 2
Training loss: 2.0182299613952637
Validation loss: 2.002102387848721

Epoch: 5| Step: 3
Training loss: 1.6183977127075195
Validation loss: 1.9786106540310768

Epoch: 5| Step: 4
Training loss: 2.540571928024292
Validation loss: 1.9933563765659128

Epoch: 5| Step: 5
Training loss: 1.8009252548217773
Validation loss: 1.9678363466775546

Epoch: 5| Step: 6
Training loss: 2.20489239692688
Validation loss: 2.0058666941940144

Epoch: 5| Step: 7
Training loss: 2.184807538986206
Validation loss: 1.9898693036007624

Epoch: 5| Step: 8
Training loss: 1.7677345275878906
Validation loss: 1.9950121243794758

Epoch: 5| Step: 9
Training loss: 1.5519119501113892
Validation loss: 1.9978551787714804

Epoch: 5| Step: 10
Training loss: 1.72713041305542
Validation loss: 2.001379853935652

Epoch: 204| Step: 0
Training loss: 1.4291785955429077
Validation loss: 1.9856415692196097

Epoch: 5| Step: 1
Training loss: 1.7670018672943115
Validation loss: 1.9916870850388722

Epoch: 5| Step: 2
Training loss: 2.126518726348877
Validation loss: 2.008658943637725

Epoch: 5| Step: 3
Training loss: 1.7439661026000977
Validation loss: 1.9827230181745303

Epoch: 5| Step: 4
Training loss: 2.272014856338501
Validation loss: 2.0045929185805784

Epoch: 5| Step: 5
Training loss: 2.100672483444214
Validation loss: 2.0007828051044094

Epoch: 5| Step: 6
Training loss: 2.842808485031128
Validation loss: 1.9800058782741587

Epoch: 5| Step: 7
Training loss: 1.8161077499389648
Validation loss: 1.9672930612358996

Epoch: 5| Step: 8
Training loss: 1.6037019491195679
Validation loss: 2.0060546449435654

Epoch: 5| Step: 9
Training loss: 1.6156361103057861
Validation loss: 1.988807821786532

Epoch: 5| Step: 10
Training loss: 1.8869224786758423
Validation loss: 1.9986411730448406

Epoch: 205| Step: 0
Training loss: 1.7288764715194702
Validation loss: 1.9925014998323174

Epoch: 5| Step: 1
Training loss: 1.723780870437622
Validation loss: 1.9883141171547674

Epoch: 5| Step: 2
Training loss: 2.0140280723571777
Validation loss: 1.9829253663298905

Epoch: 5| Step: 3
Training loss: 2.0973517894744873
Validation loss: 2.0187896759279313

Epoch: 5| Step: 4
Training loss: 2.182710647583008
Validation loss: 1.9916118575680641

Epoch: 5| Step: 5
Training loss: 1.9732692241668701
Validation loss: 1.9905980684423958

Epoch: 5| Step: 6
Training loss: 1.6995525360107422
Validation loss: 1.9843218993115168

Epoch: 5| Step: 7
Training loss: 1.8490921258926392
Validation loss: 2.0036906837135233

Epoch: 5| Step: 8
Training loss: 2.248056411743164
Validation loss: 1.9916717083223405

Epoch: 5| Step: 9
Training loss: 1.482250452041626
Validation loss: 1.9987952747652609

Epoch: 5| Step: 10
Training loss: 2.327869176864624
Validation loss: 1.9745428767255557

Epoch: 206| Step: 0
Training loss: 1.9756635427474976
Validation loss: 2.0147057425591255

Epoch: 5| Step: 1
Training loss: 2.001697301864624
Validation loss: 2.012553330390684

Epoch: 5| Step: 2
Training loss: 1.9131715297698975
Validation loss: 1.9855744300350067

Epoch: 5| Step: 3
Training loss: 1.9832706451416016
Validation loss: 1.982224295216222

Epoch: 5| Step: 4
Training loss: 1.9934335947036743
Validation loss: 1.9919587527551958

Epoch: 5| Step: 5
Training loss: 1.8133461475372314
Validation loss: 1.980428684142328

Epoch: 5| Step: 6
Training loss: 2.1991829872131348
Validation loss: 1.9915917740073255

Epoch: 5| Step: 7
Training loss: 1.2433229684829712
Validation loss: 1.9992783787429973

Epoch: 5| Step: 8
Training loss: 2.3375067710876465
Validation loss: 1.9661864939556326

Epoch: 5| Step: 9
Training loss: 1.4266424179077148
Validation loss: 1.9993286914722894

Epoch: 5| Step: 10
Training loss: 2.321089506149292
Validation loss: 1.9690470849314043

Epoch: 207| Step: 0
Training loss: 1.6218640804290771
Validation loss: 1.9886866654119184

Epoch: 5| Step: 1
Training loss: 1.628655195236206
Validation loss: 1.9737919415197065

Epoch: 5| Step: 2
Training loss: 2.1901917457580566
Validation loss: 1.9941145194474088

Epoch: 5| Step: 3
Training loss: 1.9716154336929321
Validation loss: 1.988791024813088

Epoch: 5| Step: 4
Training loss: 2.416801929473877
Validation loss: 1.9719479878743489

Epoch: 5| Step: 5
Training loss: 1.2545324563980103
Validation loss: 1.999478925940811

Epoch: 5| Step: 6
Training loss: 2.350925922393799
Validation loss: 1.983450916505629

Epoch: 5| Step: 7
Training loss: 2.3237245082855225
Validation loss: 1.9977183495798418

Epoch: 5| Step: 8
Training loss: 2.0432581901550293
Validation loss: 2.0153917894568494

Epoch: 5| Step: 9
Training loss: 1.495444416999817
Validation loss: 1.988483425109617

Epoch: 5| Step: 10
Training loss: 1.8743184804916382
Validation loss: 1.9983337271598078

Epoch: 208| Step: 0
Training loss: 1.6445777416229248
Validation loss: 1.9918096232157882

Epoch: 5| Step: 1
Training loss: 1.7532974481582642
Validation loss: 1.97724659468538

Epoch: 5| Step: 2
Training loss: 2.2576985359191895
Validation loss: 1.9920747357030069

Epoch: 5| Step: 3
Training loss: 2.0458931922912598
Validation loss: 1.9908019804185437

Epoch: 5| Step: 4
Training loss: 1.9736087322235107
Validation loss: 1.9900853108334284

Epoch: 5| Step: 5
Training loss: 1.4478398561477661
Validation loss: 1.9756429785041398

Epoch: 5| Step: 6
Training loss: 2.0192291736602783
Validation loss: 2.011207539548156

Epoch: 5| Step: 7
Training loss: 1.9204246997833252
Validation loss: 1.983288154807142

Epoch: 5| Step: 8
Training loss: 1.8537845611572266
Validation loss: 1.9932899077733357

Epoch: 5| Step: 9
Training loss: 1.9893070459365845
Validation loss: 2.009675884759554

Epoch: 5| Step: 10
Training loss: 2.1494667530059814
Validation loss: 1.9857640010054394

Epoch: 209| Step: 0
Training loss: 2.8905515670776367
Validation loss: 2.0063863390235492

Epoch: 5| Step: 1
Training loss: 1.1390987634658813
Validation loss: 1.9981750903591033

Epoch: 5| Step: 2
Training loss: 1.6697471141815186
Validation loss: 2.013709645117483

Epoch: 5| Step: 3
Training loss: 2.491072654724121
Validation loss: 2.011245976212204

Epoch: 5| Step: 4
Training loss: 1.8102195262908936
Validation loss: 1.988057783854905

Epoch: 5| Step: 5
Training loss: 1.9158904552459717
Validation loss: 1.9759629208554503

Epoch: 5| Step: 6
Training loss: 2.024761915206909
Validation loss: 1.9746854433449366

Epoch: 5| Step: 7
Training loss: 1.5199604034423828
Validation loss: 1.9940248253524944

Epoch: 5| Step: 8
Training loss: 1.8627277612686157
Validation loss: 1.9659588183126142

Epoch: 5| Step: 9
Training loss: 2.070014238357544
Validation loss: 1.9914098580678303

Epoch: 5| Step: 10
Training loss: 1.731134057044983
Validation loss: 2.0167022341041156

Epoch: 210| Step: 0
Training loss: 1.987817406654358
Validation loss: 2.0115033490683443

Epoch: 5| Step: 1
Training loss: 1.7382371425628662
Validation loss: 1.9929950327001593

Epoch: 5| Step: 2
Training loss: 1.876343011856079
Validation loss: 1.997138628395655

Epoch: 5| Step: 3
Training loss: 1.294701337814331
Validation loss: 2.0210875183023433

Epoch: 5| Step: 4
Training loss: 2.3431010246276855
Validation loss: 1.978893922221276

Epoch: 5| Step: 5
Training loss: 2.068276882171631
Validation loss: 2.001551274330385

Epoch: 5| Step: 6
Training loss: 1.8363621234893799
Validation loss: 1.9937705673197264

Epoch: 5| Step: 7
Training loss: 2.5128509998321533
Validation loss: 1.9832104303503548

Epoch: 5| Step: 8
Training loss: 1.271607756614685
Validation loss: 1.9919207185827277

Epoch: 5| Step: 9
Training loss: 1.7628018856048584
Validation loss: 1.9835929409150155

Epoch: 5| Step: 10
Training loss: 2.5470480918884277
Validation loss: 1.9911049207051594

Epoch: 211| Step: 0
Training loss: 1.358386754989624
Validation loss: 2.004903836916852

Epoch: 5| Step: 1
Training loss: 2.029064655303955
Validation loss: 2.0025911561904417

Epoch: 5| Step: 2
Training loss: 2.1899638175964355
Validation loss: 2.0155694010437175

Epoch: 5| Step: 3
Training loss: 1.5780797004699707
Validation loss: 1.9827519014317503

Epoch: 5| Step: 4
Training loss: 2.0134940147399902
Validation loss: 1.989614120093725

Epoch: 5| Step: 5
Training loss: 2.4557385444641113
Validation loss: 2.006230822173498

Epoch: 5| Step: 6
Training loss: 1.713132619857788
Validation loss: 2.021548822361936

Epoch: 5| Step: 7
Training loss: 2.618807792663574
Validation loss: 2.0214533434119275

Epoch: 5| Step: 8
Training loss: 1.673474907875061
Validation loss: 1.9939670332016484

Epoch: 5| Step: 9
Training loss: 1.7837152481079102
Validation loss: 1.986043289143552

Epoch: 5| Step: 10
Training loss: 1.4018808603286743
Validation loss: 1.9973373643813594

Epoch: 212| Step: 0
Training loss: 1.2626187801361084
Validation loss: 1.9971675718984296

Epoch: 5| Step: 1
Training loss: 1.8021882772445679
Validation loss: 2.0028635699261903

Epoch: 5| Step: 2
Training loss: 1.8656774759292603
Validation loss: 2.004241863886515

Epoch: 5| Step: 3
Training loss: 2.1392905712127686
Validation loss: 1.9994429144808041

Epoch: 5| Step: 4
Training loss: 2.041699171066284
Validation loss: 2.0317743516737417

Epoch: 5| Step: 5
Training loss: 1.1399471759796143
Validation loss: 1.99881072198191

Epoch: 5| Step: 6
Training loss: 1.9775686264038086
Validation loss: 1.9822625242253786

Epoch: 5| Step: 7
Training loss: 1.800256371498108
Validation loss: 1.9794387189290856

Epoch: 5| Step: 8
Training loss: 1.946218490600586
Validation loss: 1.9853117312154462

Epoch: 5| Step: 9
Training loss: 2.3678536415100098
Validation loss: 1.995201236458235

Epoch: 5| Step: 10
Training loss: 2.7305474281311035
Validation loss: 1.9919363016723304

Epoch: 213| Step: 0
Training loss: 1.3084344863891602
Validation loss: 1.993057584249845

Epoch: 5| Step: 1
Training loss: 1.9091488122940063
Validation loss: 1.9814145821397022

Epoch: 5| Step: 2
Training loss: 1.8648664951324463
Validation loss: 1.994414492319989

Epoch: 5| Step: 3
Training loss: 1.6742655038833618
Validation loss: 1.9855210755461006

Epoch: 5| Step: 4
Training loss: 2.6090900897979736
Validation loss: 1.9963881123450495

Epoch: 5| Step: 5
Training loss: 2.291740894317627
Validation loss: 2.0043848919612106

Epoch: 5| Step: 6
Training loss: 1.574946641921997
Validation loss: 1.9858367750721593

Epoch: 5| Step: 7
Training loss: 1.892656922340393
Validation loss: 2.0217255494927846

Epoch: 5| Step: 8
Training loss: 2.00434947013855
Validation loss: 1.9941281592974098

Epoch: 5| Step: 9
Training loss: 1.8207155466079712
Validation loss: 2.028378995515967

Epoch: 5| Step: 10
Training loss: 2.011641502380371
Validation loss: 1.9933182116477721

Epoch: 214| Step: 0
Training loss: 1.7292324304580688
Validation loss: 1.9771330600143762

Epoch: 5| Step: 1
Training loss: 1.977838158607483
Validation loss: 2.005053525329918

Epoch: 5| Step: 2
Training loss: 1.7545160055160522
Validation loss: 2.0101402087878157

Epoch: 5| Step: 3
Training loss: 2.265702724456787
Validation loss: 2.0054496219081264

Epoch: 5| Step: 4
Training loss: 1.630806565284729
Validation loss: 1.9952444017574351

Epoch: 5| Step: 5
Training loss: 2.291375160217285
Validation loss: 1.9793784259467997

Epoch: 5| Step: 6
Training loss: 1.9327253103256226
Validation loss: 1.9603355699969875

Epoch: 5| Step: 7
Training loss: 1.3682559728622437
Validation loss: 1.9565731530548425

Epoch: 5| Step: 8
Training loss: 1.9573379755020142
Validation loss: 1.9709950544500863

Epoch: 5| Step: 9
Training loss: 2.2551562786102295
Validation loss: 2.02786692496269

Epoch: 5| Step: 10
Training loss: 1.7074757814407349
Validation loss: 1.9933577583682152

Epoch: 215| Step: 0
Training loss: 1.6644306182861328
Validation loss: 1.9937986430301462

Epoch: 5| Step: 1
Training loss: 1.864331841468811
Validation loss: 1.9965106159128168

Epoch: 5| Step: 2
Training loss: 2.7585158348083496
Validation loss: 1.9774386011144167

Epoch: 5| Step: 3
Training loss: 1.8033173084259033
Validation loss: 1.97450178669345

Epoch: 5| Step: 4
Training loss: 2.0491652488708496
Validation loss: 1.9814020305551507

Epoch: 5| Step: 5
Training loss: 1.3818426132202148
Validation loss: 1.9771371323575255

Epoch: 5| Step: 6
Training loss: 1.4055520296096802
Validation loss: 1.9718917582624702

Epoch: 5| Step: 7
Training loss: 2.356989622116089
Validation loss: 1.9881548317529822

Epoch: 5| Step: 8
Training loss: 1.7076528072357178
Validation loss: 1.988342946575534

Epoch: 5| Step: 9
Training loss: 2.1107001304626465
Validation loss: 1.966891255429996

Epoch: 5| Step: 10
Training loss: 1.624105453491211
Validation loss: 2.0086990889682563

Epoch: 216| Step: 0
Training loss: 1.7117286920547485
Validation loss: 1.9703341196942072

Epoch: 5| Step: 1
Training loss: 1.8007333278656006
Validation loss: 2.0120857325933312

Epoch: 5| Step: 2
Training loss: 1.563309669494629
Validation loss: 1.9714251320849183

Epoch: 5| Step: 3
Training loss: 2.1493937969207764
Validation loss: 1.9828278326219129

Epoch: 5| Step: 4
Training loss: 1.8285667896270752
Validation loss: 1.993279787801927

Epoch: 5| Step: 5
Training loss: 2.1769983768463135
Validation loss: 2.000481608093426

Epoch: 5| Step: 6
Training loss: 1.8051011562347412
Validation loss: 2.0330580101218274

Epoch: 5| Step: 7
Training loss: 2.1983115673065186
Validation loss: 2.012602818909512

Epoch: 5| Step: 8
Training loss: 2.0530693531036377
Validation loss: 1.9953321718400525

Epoch: 5| Step: 9
Training loss: 2.117356538772583
Validation loss: 2.024152865973852

Epoch: 5| Step: 10
Training loss: 1.4084104299545288
Validation loss: 2.0533499820258028

Epoch: 217| Step: 0
Training loss: 1.8974792957305908
Validation loss: 2.015856924877372

Epoch: 5| Step: 1
Training loss: 2.570936441421509
Validation loss: 2.018299400165517

Epoch: 5| Step: 2
Training loss: 1.5560706853866577
Validation loss: 2.017943633499966

Epoch: 5| Step: 3
Training loss: 2.2836520671844482
Validation loss: 2.038383965851158

Epoch: 5| Step: 4
Training loss: 2.4242684841156006
Validation loss: 2.0353565856974614

Epoch: 5| Step: 5
Training loss: 1.733849287033081
Validation loss: 2.0059548911227973

Epoch: 5| Step: 6
Training loss: 2.232923984527588
Validation loss: 2.0102696598217054

Epoch: 5| Step: 7
Training loss: 1.7959964275360107
Validation loss: 2.0019092816178516

Epoch: 5| Step: 8
Training loss: 1.161240816116333
Validation loss: 2.0033463021760345

Epoch: 5| Step: 9
Training loss: 1.1948343515396118
Validation loss: 1.980278798328933

Epoch: 5| Step: 10
Training loss: 2.0272364616394043
Validation loss: 1.9948656584626885

Epoch: 218| Step: 0
Training loss: 1.5517923831939697
Validation loss: 1.9903688405149726

Epoch: 5| Step: 1
Training loss: 2.054659605026245
Validation loss: 1.98307656088183

Epoch: 5| Step: 2
Training loss: 2.500957489013672
Validation loss: 2.007590093920308

Epoch: 5| Step: 3
Training loss: 1.8548095226287842
Validation loss: 2.0030845237034622

Epoch: 5| Step: 4
Training loss: 2.2440896034240723
Validation loss: 2.018741789684501

Epoch: 5| Step: 5
Training loss: 2.0585274696350098
Validation loss: 2.0081034091211136

Epoch: 5| Step: 6
Training loss: 1.6486656665802002
Validation loss: 1.9943018626141291

Epoch: 5| Step: 7
Training loss: 1.716576337814331
Validation loss: 2.0257908733942176

Epoch: 5| Step: 8
Training loss: 1.659594178199768
Validation loss: 1.9917359967385568

Epoch: 5| Step: 9
Training loss: 1.5390437841415405
Validation loss: 1.9951477422509143

Epoch: 5| Step: 10
Training loss: 2.0778043270111084
Validation loss: 1.9936927954355876

Epoch: 219| Step: 0
Training loss: 1.6300404071807861
Validation loss: 1.9672098428972307

Epoch: 5| Step: 1
Training loss: 2.1457836627960205
Validation loss: 1.9664875384299987

Epoch: 5| Step: 2
Training loss: 1.3961349725723267
Validation loss: 1.9770073865049629

Epoch: 5| Step: 3
Training loss: 1.380609393119812
Validation loss: 1.9931895066333074

Epoch: 5| Step: 4
Training loss: 1.875802755355835
Validation loss: 1.9896786738467473

Epoch: 5| Step: 5
Training loss: 2.270878553390503
Validation loss: 1.9769455540564753

Epoch: 5| Step: 6
Training loss: 2.448361396789551
Validation loss: 1.9661132776609032

Epoch: 5| Step: 7
Training loss: 1.5352758169174194
Validation loss: 1.996532601694907

Epoch: 5| Step: 8
Training loss: 2.1437785625457764
Validation loss: 1.9896509967824465

Epoch: 5| Step: 9
Training loss: 2.236584424972534
Validation loss: 1.9704859987381966

Epoch: 5| Step: 10
Training loss: 1.5906833410263062
Validation loss: 1.9558784923245829

Epoch: 220| Step: 0
Training loss: 2.207564115524292
Validation loss: 1.9778562130466584

Epoch: 5| Step: 1
Training loss: 2.027797222137451
Validation loss: 1.9673780625866306

Epoch: 5| Step: 2
Training loss: 2.046299695968628
Validation loss: 1.9833723883475027

Epoch: 5| Step: 3
Training loss: 1.9553825855255127
Validation loss: 1.9763531992512364

Epoch: 5| Step: 4
Training loss: 1.3731467723846436
Validation loss: 1.9899206084589804

Epoch: 5| Step: 5
Training loss: 1.6051852703094482
Validation loss: 1.965855549740535

Epoch: 5| Step: 6
Training loss: 2.456699848175049
Validation loss: 1.9865650720493768

Epoch: 5| Step: 7
Training loss: 1.8197479248046875
Validation loss: 1.9723450317177722

Epoch: 5| Step: 8
Training loss: 2.0540690422058105
Validation loss: 1.9609096357899327

Epoch: 5| Step: 9
Training loss: 1.5736443996429443
Validation loss: 1.994736966266427

Epoch: 5| Step: 10
Training loss: 1.6560029983520508
Validation loss: 1.981416117760443

Epoch: 221| Step: 0
Training loss: 2.0837771892547607
Validation loss: 1.991684720080386

Epoch: 5| Step: 1
Training loss: 2.264622211456299
Validation loss: 2.0118497097364036

Epoch: 5| Step: 2
Training loss: 1.9406535625457764
Validation loss: 1.978189395320031

Epoch: 5| Step: 3
Training loss: 1.7206014394760132
Validation loss: 1.9955497352025842

Epoch: 5| Step: 4
Training loss: 1.928123116493225
Validation loss: 1.989757312241421

Epoch: 5| Step: 5
Training loss: 1.8695558309555054
Validation loss: 2.006594898880169

Epoch: 5| Step: 6
Training loss: 1.7351930141448975
Validation loss: 2.0166821159342283

Epoch: 5| Step: 7
Training loss: 1.2547438144683838
Validation loss: 2.0116917805005143

Epoch: 5| Step: 8
Training loss: 1.9772344827651978
Validation loss: 2.011302178905856

Epoch: 5| Step: 9
Training loss: 1.6734575033187866
Validation loss: 1.9786780982889154

Epoch: 5| Step: 10
Training loss: 2.1946499347686768
Validation loss: 1.9802699729960451

Epoch: 222| Step: 0
Training loss: 2.4976513385772705
Validation loss: 1.9993370579135032

Epoch: 5| Step: 1
Training loss: 2.0671889781951904
Validation loss: 2.014344543539068

Epoch: 5| Step: 2
Training loss: 1.718029260635376
Validation loss: 2.035734268926805

Epoch: 5| Step: 3
Training loss: 2.0059289932250977
Validation loss: 2.0023414768198484

Epoch: 5| Step: 4
Training loss: 2.0635504722595215
Validation loss: 1.9972087106397074

Epoch: 5| Step: 5
Training loss: 1.7125200033187866
Validation loss: 2.0038131693358063

Epoch: 5| Step: 6
Training loss: 1.6668422222137451
Validation loss: 1.9777711078684816

Epoch: 5| Step: 7
Training loss: 1.3337714672088623
Validation loss: 1.9817268540782313

Epoch: 5| Step: 8
Training loss: 1.6042592525482178
Validation loss: 1.9890178672729

Epoch: 5| Step: 9
Training loss: 2.143402338027954
Validation loss: 2.016744816175071

Epoch: 5| Step: 10
Training loss: 1.9465197324752808
Validation loss: 1.9841419253298032

Epoch: 223| Step: 0
Training loss: 1.4678055047988892
Validation loss: 1.9788060213929863

Epoch: 5| Step: 1
Training loss: 2.2955079078674316
Validation loss: 1.958454344862251

Epoch: 5| Step: 2
Training loss: 1.844818353652954
Validation loss: 1.9892105851122128

Epoch: 5| Step: 3
Training loss: 1.2152700424194336
Validation loss: 1.9953509748622935

Epoch: 5| Step: 4
Training loss: 1.6836299896240234
Validation loss: 2.003170137764305

Epoch: 5| Step: 5
Training loss: 1.876448631286621
Validation loss: 1.9917928685424149

Epoch: 5| Step: 6
Training loss: 2.09816312789917
Validation loss: 1.9834533429914905

Epoch: 5| Step: 7
Training loss: 1.9626100063323975
Validation loss: 1.9604305605734549

Epoch: 5| Step: 8
Training loss: 1.7223386764526367
Validation loss: 1.9709600556281306

Epoch: 5| Step: 9
Training loss: 2.7250969409942627
Validation loss: 1.9720843697106967

Epoch: 5| Step: 10
Training loss: 1.742039442062378
Validation loss: 1.9788234054401357

Epoch: 224| Step: 0
Training loss: 1.5557551383972168
Validation loss: 1.9826078389280586

Epoch: 5| Step: 1
Training loss: 1.953545331954956
Validation loss: 1.97808236845078

Epoch: 5| Step: 2
Training loss: 1.3905179500579834
Validation loss: 2.0032522934739307

Epoch: 5| Step: 3
Training loss: 2.4909868240356445
Validation loss: 1.9660625739764142

Epoch: 5| Step: 4
Training loss: 2.147489547729492
Validation loss: 1.9645678356129637

Epoch: 5| Step: 5
Training loss: 2.1378931999206543
Validation loss: 1.993647877888013

Epoch: 5| Step: 6
Training loss: 1.8004614114761353
Validation loss: 1.9904048609477218

Epoch: 5| Step: 7
Training loss: 1.871380090713501
Validation loss: 1.9881875771348194

Epoch: 5| Step: 8
Training loss: 1.9707410335540771
Validation loss: 1.9952650736736994

Epoch: 5| Step: 9
Training loss: 1.6358928680419922
Validation loss: 1.9850261224213468

Epoch: 5| Step: 10
Training loss: 1.5769175291061401
Validation loss: 1.9845517463581537

Epoch: 225| Step: 0
Training loss: 1.17374849319458
Validation loss: 2.0084821729249853

Epoch: 5| Step: 1
Training loss: 2.1506905555725098
Validation loss: 1.9802381889794463

Epoch: 5| Step: 2
Training loss: 2.0085690021514893
Validation loss: 1.9910315621283747

Epoch: 5| Step: 3
Training loss: 2.3180184364318848
Validation loss: 1.959045579356532

Epoch: 5| Step: 4
Training loss: 2.0271644592285156
Validation loss: 1.976949240571709

Epoch: 5| Step: 5
Training loss: 2.0714211463928223
Validation loss: 1.9922786502427952

Epoch: 5| Step: 6
Training loss: 1.8652398586273193
Validation loss: 1.9857404949844524

Epoch: 5| Step: 7
Training loss: 1.9652115106582642
Validation loss: 1.9866730782293505

Epoch: 5| Step: 8
Training loss: 1.5746533870697021
Validation loss: 2.0096275447517313

Epoch: 5| Step: 9
Training loss: 1.506656289100647
Validation loss: 1.9736568081763484

Epoch: 5| Step: 10
Training loss: 1.7692724466323853
Validation loss: 1.9461555480957031

Epoch: 226| Step: 0
Training loss: 1.7844374179840088
Validation loss: 1.9873116516297864

Epoch: 5| Step: 1
Training loss: 1.4689719676971436
Validation loss: 1.950559998071322

Epoch: 5| Step: 2
Training loss: 2.007540464401245
Validation loss: 1.9727098236801803

Epoch: 5| Step: 3
Training loss: 1.82217538356781
Validation loss: 1.9919228066680252

Epoch: 5| Step: 4
Training loss: 1.5913152694702148
Validation loss: 1.9982612248389953

Epoch: 5| Step: 5
Training loss: 1.583059549331665
Validation loss: 1.9717498748533187

Epoch: 5| Step: 6
Training loss: 2.1298699378967285
Validation loss: 1.961531154571041

Epoch: 5| Step: 7
Training loss: 2.1828713417053223
Validation loss: 1.9750328038328437

Epoch: 5| Step: 8
Training loss: 1.9472358226776123
Validation loss: 2.0074997896789224

Epoch: 5| Step: 9
Training loss: 2.3016648292541504
Validation loss: 2.0140815755372405

Epoch: 5| Step: 10
Training loss: 1.8217414617538452
Validation loss: 1.9902789054378387

Epoch: 227| Step: 0
Training loss: 1.3408100605010986
Validation loss: 2.0116243349608554

Epoch: 5| Step: 1
Training loss: 2.1502299308776855
Validation loss: 1.9882305950246832

Epoch: 5| Step: 2
Training loss: 1.8562065362930298
Validation loss: 1.9901243332893617

Epoch: 5| Step: 3
Training loss: 2.280541181564331
Validation loss: 1.97116865393936

Epoch: 5| Step: 4
Training loss: 2.634486436843872
Validation loss: 1.971101717282367

Epoch: 5| Step: 5
Training loss: 1.5784714221954346
Validation loss: 1.9557003500641033

Epoch: 5| Step: 6
Training loss: 1.5133278369903564
Validation loss: 1.9867721193580217

Epoch: 5| Step: 7
Training loss: 1.770124077796936
Validation loss: 1.984373930961855

Epoch: 5| Step: 8
Training loss: 1.2819130420684814
Validation loss: 1.9761663854763072

Epoch: 5| Step: 9
Training loss: 2.0958786010742188
Validation loss: 1.966486850092488

Epoch: 5| Step: 10
Training loss: 2.001349687576294
Validation loss: 1.9908896466737152

Epoch: 228| Step: 0
Training loss: 1.6522057056427002
Validation loss: 1.9907865601201211

Epoch: 5| Step: 1
Training loss: 2.07453989982605
Validation loss: 1.9823127164635608

Epoch: 5| Step: 2
Training loss: 1.8293405771255493
Validation loss: 1.9731966000731274

Epoch: 5| Step: 3
Training loss: 1.960181474685669
Validation loss: 1.9947532043662122

Epoch: 5| Step: 4
Training loss: 1.7193756103515625
Validation loss: 1.9779056297835482

Epoch: 5| Step: 5
Training loss: 1.5524280071258545
Validation loss: 1.990452604909097

Epoch: 5| Step: 6
Training loss: 2.42537260055542
Validation loss: 1.9617770615444388

Epoch: 5| Step: 7
Training loss: 2.179906129837036
Validation loss: 1.976593607215471

Epoch: 5| Step: 8
Training loss: 1.253957748413086
Validation loss: 1.9663387293456702

Epoch: 5| Step: 9
Training loss: 1.993295669555664
Validation loss: 2.0167187490770893

Epoch: 5| Step: 10
Training loss: 1.7157832384109497
Validation loss: 1.9940106291924753

Epoch: 229| Step: 0
Training loss: 1.0400183200836182
Validation loss: 1.9877768024321525

Epoch: 5| Step: 1
Training loss: 2.2883477210998535
Validation loss: 1.9834515933067567

Epoch: 5| Step: 2
Training loss: 1.5942230224609375
Validation loss: 1.9640553997408958

Epoch: 5| Step: 3
Training loss: 1.862783670425415
Validation loss: 1.973787348757508

Epoch: 5| Step: 4
Training loss: 1.7473112344741821
Validation loss: 1.9849266672647128

Epoch: 5| Step: 5
Training loss: 1.6613438129425049
Validation loss: 1.9456049050054243

Epoch: 5| Step: 6
Training loss: 1.6588973999023438
Validation loss: 2.011011090329898

Epoch: 5| Step: 7
Training loss: 2.370952606201172
Validation loss: 1.9416943275800316

Epoch: 5| Step: 8
Training loss: 1.5241856575012207
Validation loss: 1.9815471351787608

Epoch: 5| Step: 9
Training loss: 2.352088212966919
Validation loss: 2.017278745610227

Epoch: 5| Step: 10
Training loss: 2.397369861602783
Validation loss: 1.9552356068805983

Epoch: 230| Step: 0
Training loss: 2.18782114982605
Validation loss: 1.9946225099666144

Epoch: 5| Step: 1
Training loss: 1.917258620262146
Validation loss: 1.9756199390657487

Epoch: 5| Step: 2
Training loss: 2.0997166633605957
Validation loss: 1.989769184461204

Epoch: 5| Step: 3
Training loss: 2.129992723464966
Validation loss: 1.9846331919393232

Epoch: 5| Step: 4
Training loss: 1.6224756240844727
Validation loss: 1.9934154633552796

Epoch: 5| Step: 5
Training loss: 1.7481517791748047
Validation loss: 1.9951189717938822

Epoch: 5| Step: 6
Training loss: 1.5464065074920654
Validation loss: 1.981440831256169

Epoch: 5| Step: 7
Training loss: 2.054025411605835
Validation loss: 1.963891343403888

Epoch: 5| Step: 8
Training loss: 1.5878703594207764
Validation loss: 1.9538841170649375

Epoch: 5| Step: 9
Training loss: 1.628483772277832
Validation loss: 1.9954912354869228

Epoch: 5| Step: 10
Training loss: 2.227971315383911
Validation loss: 1.9695582582104592

Epoch: 231| Step: 0
Training loss: 1.7994734048843384
Validation loss: 1.9864798732983169

Epoch: 5| Step: 1
Training loss: 1.6507365703582764
Validation loss: 2.0220353705908662

Epoch: 5| Step: 2
Training loss: 1.8914668560028076
Validation loss: 1.9883170115050448

Epoch: 5| Step: 3
Training loss: 2.194794178009033
Validation loss: 1.9759093497389106

Epoch: 5| Step: 4
Training loss: 1.5642110109329224
Validation loss: 1.9731547512033933

Epoch: 5| Step: 5
Training loss: 2.0941426753997803
Validation loss: 1.980003922216354

Epoch: 5| Step: 6
Training loss: 1.9712731838226318
Validation loss: 1.976737795337554

Epoch: 5| Step: 7
Training loss: 2.1396820545196533
Validation loss: 1.9576671392686906

Epoch: 5| Step: 8
Training loss: 1.9766887426376343
Validation loss: 1.9703685980971142

Epoch: 5| Step: 9
Training loss: 1.3477213382720947
Validation loss: 1.9676884220492454

Epoch: 5| Step: 10
Training loss: 1.8039438724517822
Validation loss: 1.958636260801746

Epoch: 232| Step: 0
Training loss: 1.8932701349258423
Validation loss: 1.9495599167321318

Epoch: 5| Step: 1
Training loss: 1.623659372329712
Validation loss: 1.988016459249681

Epoch: 5| Step: 2
Training loss: 1.834678292274475
Validation loss: 1.989697999851678

Epoch: 5| Step: 3
Training loss: 2.4705088138580322
Validation loss: 1.987516724935142

Epoch: 5| Step: 4
Training loss: 2.050095796585083
Validation loss: 1.9923229499529767

Epoch: 5| Step: 5
Training loss: 2.128837823867798
Validation loss: 1.9725805226192679

Epoch: 5| Step: 6
Training loss: 1.9088966846466064
Validation loss: 1.9625298207806003

Epoch: 5| Step: 7
Training loss: 1.3357815742492676
Validation loss: 2.003059337216039

Epoch: 5| Step: 8
Training loss: 2.123683214187622
Validation loss: 1.9821408128225675

Epoch: 5| Step: 9
Training loss: 1.1533339023590088
Validation loss: 1.985592467810518

Epoch: 5| Step: 10
Training loss: 1.7323216199874878
Validation loss: 1.9833117428646292

Epoch: 233| Step: 0
Training loss: 1.8178869485855103
Validation loss: 1.9829729974910777

Epoch: 5| Step: 1
Training loss: 2.1152477264404297
Validation loss: 1.9581606106091571

Epoch: 5| Step: 2
Training loss: 1.9684727191925049
Validation loss: 1.9874724495795466

Epoch: 5| Step: 3
Training loss: 1.913818359375
Validation loss: 1.9752594553014284

Epoch: 5| Step: 4
Training loss: 1.7447706460952759
Validation loss: 2.000793831322783

Epoch: 5| Step: 5
Training loss: 1.8435380458831787
Validation loss: 2.0026572647915093

Epoch: 5| Step: 6
Training loss: 1.6390966176986694
Validation loss: 2.0026475921753915

Epoch: 5| Step: 7
Training loss: 2.1504461765289307
Validation loss: 2.0036594380614576

Epoch: 5| Step: 8
Training loss: 1.3015283346176147
Validation loss: 2.009177630947482

Epoch: 5| Step: 9
Training loss: 1.7745463848114014
Validation loss: 2.0153641213652906

Epoch: 5| Step: 10
Training loss: 2.0501720905303955
Validation loss: 1.9964699258086502

Epoch: 234| Step: 0
Training loss: 1.6582839488983154
Validation loss: 2.0156076018528273

Epoch: 5| Step: 1
Training loss: 1.1678892374038696
Validation loss: 1.9878406165748514

Epoch: 5| Step: 2
Training loss: 2.0936787128448486
Validation loss: 1.9744267591866114

Epoch: 5| Step: 3
Training loss: 2.0074961185455322
Validation loss: 2.0192557560500277

Epoch: 5| Step: 4
Training loss: 1.5017831325531006
Validation loss: 1.9912818708727438

Epoch: 5| Step: 5
Training loss: 2.6842339038848877
Validation loss: 1.9682045880184378

Epoch: 5| Step: 6
Training loss: 2.1415200233459473
Validation loss: 1.95814299327071

Epoch: 5| Step: 7
Training loss: 1.7059316635131836
Validation loss: 1.954274639006584

Epoch: 5| Step: 8
Training loss: 1.807722806930542
Validation loss: 2.004271561099637

Epoch: 5| Step: 9
Training loss: 2.0460047721862793
Validation loss: 1.9760066104191605

Epoch: 5| Step: 10
Training loss: 1.5590789318084717
Validation loss: 1.9917659451884608

Epoch: 235| Step: 0
Training loss: 2.2723631858825684
Validation loss: 1.9474455925726122

Epoch: 5| Step: 1
Training loss: 1.5632820129394531
Validation loss: 1.962180463216638

Epoch: 5| Step: 2
Training loss: 1.1618496179580688
Validation loss: 1.9699672229828373

Epoch: 5| Step: 3
Training loss: 1.7680305242538452
Validation loss: 1.9553301744563605

Epoch: 5| Step: 4
Training loss: 2.405872344970703
Validation loss: 1.9936111409177062

Epoch: 5| Step: 5
Training loss: 2.3134379386901855
Validation loss: 2.0007787186612367

Epoch: 5| Step: 6
Training loss: 1.6164610385894775
Validation loss: 1.972710358199253

Epoch: 5| Step: 7
Training loss: 1.7944424152374268
Validation loss: 1.9631477120102092

Epoch: 5| Step: 8
Training loss: 1.526208519935608
Validation loss: 1.9838763847145984

Epoch: 5| Step: 9
Training loss: 1.573434829711914
Validation loss: 1.9932210970950384

Epoch: 5| Step: 10
Training loss: 2.2741825580596924
Validation loss: 1.9554537944896246

Epoch: 236| Step: 0
Training loss: 2.343588352203369
Validation loss: 1.9894924215091172

Epoch: 5| Step: 1
Training loss: 1.8778812885284424
Validation loss: 1.940935049005734

Epoch: 5| Step: 2
Training loss: 1.5790085792541504
Validation loss: 1.9738322252868323

Epoch: 5| Step: 3
Training loss: 2.410295009613037
Validation loss: 1.982090852593863

Epoch: 5| Step: 4
Training loss: 1.4901174306869507
Validation loss: 2.0025832140317528

Epoch: 5| Step: 5
Training loss: 1.7286781072616577
Validation loss: 2.0096703037138908

Epoch: 5| Step: 6
Training loss: 1.775583267211914
Validation loss: 1.9695208636663293

Epoch: 5| Step: 7
Training loss: 1.8813377618789673
Validation loss: 1.998720972768722

Epoch: 5| Step: 8
Training loss: 1.7678909301757812
Validation loss: 2.0031368540179346

Epoch: 5| Step: 9
Training loss: 1.6548583507537842
Validation loss: 1.9733592412805046

Epoch: 5| Step: 10
Training loss: 1.9461308717727661
Validation loss: 1.9681280095090148

Epoch: 237| Step: 0
Training loss: 2.357879638671875
Validation loss: 1.968112450773998

Epoch: 5| Step: 1
Training loss: 1.6539968252182007
Validation loss: 1.9750890347265428

Epoch: 5| Step: 2
Training loss: 1.7952426671981812
Validation loss: 1.9622556688965007

Epoch: 5| Step: 3
Training loss: 2.2088770866394043
Validation loss: 1.9561235584238523

Epoch: 5| Step: 4
Training loss: 1.724646806716919
Validation loss: 1.9633806443983508

Epoch: 5| Step: 5
Training loss: 1.9407126903533936
Validation loss: 1.9738132082005984

Epoch: 5| Step: 6
Training loss: 1.6756731271743774
Validation loss: 1.9751463397856681

Epoch: 5| Step: 7
Training loss: 1.6409428119659424
Validation loss: 1.970699232111695

Epoch: 5| Step: 8
Training loss: 1.7784039974212646
Validation loss: 1.9693859084959953

Epoch: 5| Step: 9
Training loss: 1.7998695373535156
Validation loss: 1.9593017357651905

Epoch: 5| Step: 10
Training loss: 1.7246296405792236
Validation loss: 1.9285266553201983

Epoch: 238| Step: 0
Training loss: 1.8730369806289673
Validation loss: 1.9696221684896817

Epoch: 5| Step: 1
Training loss: 1.5538890361785889
Validation loss: 1.961517249384234

Epoch: 5| Step: 2
Training loss: 1.8815906047821045
Validation loss: 1.947976577666498

Epoch: 5| Step: 3
Training loss: 2.0278000831604004
Validation loss: 1.9855805943089146

Epoch: 5| Step: 4
Training loss: 1.4941561222076416
Validation loss: 1.9572657064724994

Epoch: 5| Step: 5
Training loss: 1.8330862522125244
Validation loss: 1.9320076178478938

Epoch: 5| Step: 6
Training loss: 1.8601531982421875
Validation loss: 1.9611671329826437

Epoch: 5| Step: 7
Training loss: 1.9808756113052368
Validation loss: 1.9780566948716358

Epoch: 5| Step: 8
Training loss: 2.059112787246704
Validation loss: 1.9687885879188456

Epoch: 5| Step: 9
Training loss: 1.9949672222137451
Validation loss: 1.9477893062817153

Epoch: 5| Step: 10
Training loss: 1.6010092496871948
Validation loss: 2.001499327280188

Epoch: 239| Step: 0
Training loss: 1.3781949281692505
Validation loss: 1.9752457295694659

Epoch: 5| Step: 1
Training loss: 1.4945027828216553
Validation loss: 1.9394738058890066

Epoch: 5| Step: 2
Training loss: 1.554558515548706
Validation loss: 1.9906459713494906

Epoch: 5| Step: 3
Training loss: 1.9561278820037842
Validation loss: 1.9686984785141484

Epoch: 5| Step: 4
Training loss: 1.89043390750885
Validation loss: 1.9813268902481243

Epoch: 5| Step: 5
Training loss: 1.5635578632354736
Validation loss: 1.9901543022483907

Epoch: 5| Step: 6
Training loss: 2.357633113861084
Validation loss: 1.9672739633949854

Epoch: 5| Step: 7
Training loss: 1.9092788696289062
Validation loss: 1.9524002664832658

Epoch: 5| Step: 8
Training loss: 2.0228326320648193
Validation loss: 1.9703934628476378

Epoch: 5| Step: 9
Training loss: 2.1503491401672363
Validation loss: 1.9883564364525579

Epoch: 5| Step: 10
Training loss: 1.943476676940918
Validation loss: 1.9612794306970411

Epoch: 240| Step: 0
Training loss: 1.957379698753357
Validation loss: 1.9275557482114403

Epoch: 5| Step: 1
Training loss: 1.7780643701553345
Validation loss: 1.9670524007530623

Epoch: 5| Step: 2
Training loss: 1.776089072227478
Validation loss: 1.9703662856932609

Epoch: 5| Step: 3
Training loss: 2.388589859008789
Validation loss: 1.9624964075703775

Epoch: 5| Step: 4
Training loss: 1.392683506011963
Validation loss: 2.0007273215119556

Epoch: 5| Step: 5
Training loss: 1.5487124919891357
Validation loss: 1.9619142022184146

Epoch: 5| Step: 6
Training loss: 1.9841492176055908
Validation loss: 1.9592521523916593

Epoch: 5| Step: 7
Training loss: 1.6831496953964233
Validation loss: 1.9507929791686356

Epoch: 5| Step: 8
Training loss: 2.1152515411376953
Validation loss: 1.9894803134343957

Epoch: 5| Step: 9
Training loss: 1.7570703029632568
Validation loss: 1.9834777232139342

Epoch: 5| Step: 10
Training loss: 1.743046760559082
Validation loss: 1.968522084656582

Epoch: 241| Step: 0
Training loss: 2.0948433876037598
Validation loss: 1.9732648249595397

Epoch: 5| Step: 1
Training loss: 1.5364551544189453
Validation loss: 1.9605171898359894

Epoch: 5| Step: 2
Training loss: 1.7285306453704834
Validation loss: 1.9571149297939834

Epoch: 5| Step: 3
Training loss: 1.6596778631210327
Validation loss: 1.963763980455296

Epoch: 5| Step: 4
Training loss: 1.7277686595916748
Validation loss: 1.9818567178582633

Epoch: 5| Step: 5
Training loss: 1.9885870218276978
Validation loss: 1.9625246063355477

Epoch: 5| Step: 6
Training loss: 2.134462594985962
Validation loss: 1.9713542115303777

Epoch: 5| Step: 7
Training loss: 2.2036099433898926
Validation loss: 1.9512533269902712

Epoch: 5| Step: 8
Training loss: 1.29714834690094
Validation loss: 1.9614055207980576

Epoch: 5| Step: 9
Training loss: 1.6091283559799194
Validation loss: 1.983202918883293

Epoch: 5| Step: 10
Training loss: 1.829915165901184
Validation loss: 1.9845764329356532

Epoch: 242| Step: 0
Training loss: 1.5755199193954468
Validation loss: 1.9529944953098093

Epoch: 5| Step: 1
Training loss: 1.5699684619903564
Validation loss: 1.969395088893111

Epoch: 5| Step: 2
Training loss: 1.237805962562561
Validation loss: 1.9393541838533135

Epoch: 5| Step: 3
Training loss: 1.8196830749511719
Validation loss: 1.9669437075173983

Epoch: 5| Step: 4
Training loss: 2.2839436531066895
Validation loss: 1.9643993967322892

Epoch: 5| Step: 5
Training loss: 2.023571014404297
Validation loss: 1.9664489902475828

Epoch: 5| Step: 6
Training loss: 2.155348062515259
Validation loss: 1.985963982920493

Epoch: 5| Step: 7
Training loss: 1.8907562494277954
Validation loss: 1.9481998425658031

Epoch: 5| Step: 8
Training loss: 1.776036024093628
Validation loss: 1.948102621621983

Epoch: 5| Step: 9
Training loss: 2.391909122467041
Validation loss: 1.9704348989712295

Epoch: 5| Step: 10
Training loss: 1.449278473854065
Validation loss: 1.9867658294657224

Epoch: 243| Step: 0
Training loss: 1.5351722240447998
Validation loss: 1.951866865158081

Epoch: 5| Step: 1
Training loss: 2.053961992263794
Validation loss: 1.9676618858050274

Epoch: 5| Step: 2
Training loss: 1.7720587253570557
Validation loss: 1.9540586856103712

Epoch: 5| Step: 3
Training loss: 2.398698329925537
Validation loss: 1.979832157011955

Epoch: 5| Step: 4
Training loss: 1.9726722240447998
Validation loss: 1.9334708913680045

Epoch: 5| Step: 5
Training loss: 1.587430715560913
Validation loss: 1.9694274958743845

Epoch: 5| Step: 6
Training loss: 2.1094117164611816
Validation loss: 2.004061419476745

Epoch: 5| Step: 7
Training loss: 2.1170554161071777
Validation loss: 1.9546485408659904

Epoch: 5| Step: 8
Training loss: 1.4031695127487183
Validation loss: 1.9431034044552875

Epoch: 5| Step: 9
Training loss: 1.3930933475494385
Validation loss: 1.9747559870443037

Epoch: 5| Step: 10
Training loss: 1.6558068990707397
Validation loss: 1.9589998645167197

Epoch: 244| Step: 0
Training loss: 1.7635223865509033
Validation loss: 1.9781024635479014

Epoch: 5| Step: 1
Training loss: 2.0565104484558105
Validation loss: 1.9552233642147434

Epoch: 5| Step: 2
Training loss: 1.4359052181243896
Validation loss: 1.9534639543102634

Epoch: 5| Step: 3
Training loss: 2.3907525539398193
Validation loss: 1.9365771085985246

Epoch: 5| Step: 4
Training loss: 1.9997808933258057
Validation loss: 1.9547071226181523

Epoch: 5| Step: 5
Training loss: 2.0579216480255127
Validation loss: 1.968893866385183

Epoch: 5| Step: 6
Training loss: 1.5184072256088257
Validation loss: 1.9633215358180385

Epoch: 5| Step: 7
Training loss: 1.4271458387374878
Validation loss: 1.9817944867636568

Epoch: 5| Step: 8
Training loss: 1.5945699214935303
Validation loss: 1.9493087799318376

Epoch: 5| Step: 9
Training loss: 1.927901268005371
Validation loss: 1.9694688845706243

Epoch: 5| Step: 10
Training loss: 1.9099019765853882
Validation loss: 1.9582119064946328

Epoch: 245| Step: 0
Training loss: 1.9320061206817627
Validation loss: 1.9726883801080848

Epoch: 5| Step: 1
Training loss: 1.5630815029144287
Validation loss: 1.9741048248865272

Epoch: 5| Step: 2
Training loss: 1.771587610244751
Validation loss: 1.9699636966951433

Epoch: 5| Step: 3
Training loss: 1.432027816772461
Validation loss: 1.9484662291824177

Epoch: 5| Step: 4
Training loss: 2.276557683944702
Validation loss: 1.9357484732904742

Epoch: 5| Step: 5
Training loss: 1.4955925941467285
Validation loss: 1.9439388346928421

Epoch: 5| Step: 6
Training loss: 1.972905158996582
Validation loss: 1.9296301898135935

Epoch: 5| Step: 7
Training loss: 1.797652006149292
Validation loss: 1.9626810448144072

Epoch: 5| Step: 8
Training loss: 2.612071990966797
Validation loss: 1.943886012159368

Epoch: 5| Step: 9
Training loss: 1.0177428722381592
Validation loss: 1.9731882618319603

Epoch: 5| Step: 10
Training loss: 2.3388350009918213
Validation loss: 1.9440194047907347

Epoch: 246| Step: 0
Training loss: 1.6506843566894531
Validation loss: 1.9382672694421583

Epoch: 5| Step: 1
Training loss: 1.765972375869751
Validation loss: 1.9321457057870843

Epoch: 5| Step: 2
Training loss: 1.17937171459198
Validation loss: 1.9759647025856921

Epoch: 5| Step: 3
Training loss: 2.405125141143799
Validation loss: 1.9493699330155567

Epoch: 5| Step: 4
Training loss: 1.6176408529281616
Validation loss: 1.9521101918271793

Epoch: 5| Step: 5
Training loss: 2.1607770919799805
Validation loss: 1.9757446230098765

Epoch: 5| Step: 6
Training loss: 2.4613165855407715
Validation loss: 1.9732958757749168

Epoch: 5| Step: 7
Training loss: 2.1847548484802246
Validation loss: 1.9911224893344346

Epoch: 5| Step: 8
Training loss: 1.5501658916473389
Validation loss: 2.001614611635926

Epoch: 5| Step: 9
Training loss: 1.9909570217132568
Validation loss: 1.9904540687478998

Epoch: 5| Step: 10
Training loss: 0.9163877367973328
Validation loss: 1.97007429727944

Epoch: 247| Step: 0
Training loss: 1.8846845626831055
Validation loss: 1.9866631902674192

Epoch: 5| Step: 1
Training loss: 1.9416320323944092
Validation loss: 1.9426389009721818

Epoch: 5| Step: 2
Training loss: 1.3154417276382446
Validation loss: 1.9393224818732149

Epoch: 5| Step: 3
Training loss: 2.3108878135681152
Validation loss: 1.9426698377055507

Epoch: 5| Step: 4
Training loss: 2.1886234283447266
Validation loss: 1.9534014142969602

Epoch: 5| Step: 5
Training loss: 2.2920565605163574
Validation loss: 1.9827662488465667

Epoch: 5| Step: 6
Training loss: 1.3036589622497559
Validation loss: 1.954012276023947

Epoch: 5| Step: 7
Training loss: 1.6859676837921143
Validation loss: 1.9620584672497166

Epoch: 5| Step: 8
Training loss: 1.6644299030303955
Validation loss: 1.9616896208896433

Epoch: 5| Step: 9
Training loss: 1.5545413494110107
Validation loss: 1.949797304727698

Epoch: 5| Step: 10
Training loss: 1.7689481973648071
Validation loss: 1.9472612283563102

Epoch: 248| Step: 0
Training loss: 2.355116367340088
Validation loss: 1.9750724633534749

Epoch: 5| Step: 1
Training loss: 2.2220144271850586
Validation loss: 1.9668163125232985

Epoch: 5| Step: 2
Training loss: 1.314478874206543
Validation loss: 1.9667019972237207

Epoch: 5| Step: 3
Training loss: 1.1372456550598145
Validation loss: 1.9319425564940258

Epoch: 5| Step: 4
Training loss: 1.937598466873169
Validation loss: 1.945804698492891

Epoch: 5| Step: 5
Training loss: 2.4422359466552734
Validation loss: 1.9573745099447106

Epoch: 5| Step: 6
Training loss: 1.961103081703186
Validation loss: 1.9486188234821442

Epoch: 5| Step: 7
Training loss: 1.8910003900527954
Validation loss: 1.960378223849881

Epoch: 5| Step: 8
Training loss: 1.2484793663024902
Validation loss: 1.9633419488065986

Epoch: 5| Step: 9
Training loss: 1.5736567974090576
Validation loss: 1.9532202007949993

Epoch: 5| Step: 10
Training loss: 1.6275955438613892
Validation loss: 1.988949386022424

Epoch: 249| Step: 0
Training loss: 1.4901748895645142
Validation loss: 1.9591492529838317

Epoch: 5| Step: 1
Training loss: 1.6647497415542603
Validation loss: 1.9457369517254572

Epoch: 5| Step: 2
Training loss: 2.1174521446228027
Validation loss: 1.9431097020385086

Epoch: 5| Step: 3
Training loss: 1.7515170574188232
Validation loss: 1.9210714114609586

Epoch: 5| Step: 4
Training loss: 2.5581164360046387
Validation loss: 1.9396846038039013

Epoch: 5| Step: 5
Training loss: 1.8328920602798462
Validation loss: 1.9634549489585302

Epoch: 5| Step: 6
Training loss: 1.3722928762435913
Validation loss: 1.9854017278199554

Epoch: 5| Step: 7
Training loss: 1.8317816257476807
Validation loss: 1.9568716197885492

Epoch: 5| Step: 8
Training loss: 1.6505918502807617
Validation loss: 1.9571980225142611

Epoch: 5| Step: 9
Training loss: 1.808655023574829
Validation loss: 1.9606147376439904

Epoch: 5| Step: 10
Training loss: 1.567111611366272
Validation loss: 1.9154554656756821

Epoch: 250| Step: 0
Training loss: 1.6047731637954712
Validation loss: 1.957245554975284

Epoch: 5| Step: 1
Training loss: 2.098565101623535
Validation loss: 1.9666020049843738

Epoch: 5| Step: 2
Training loss: 1.4599337577819824
Validation loss: 1.9932913293120682

Epoch: 5| Step: 3
Training loss: 1.776862382888794
Validation loss: 1.9413927267956477

Epoch: 5| Step: 4
Training loss: 1.1923675537109375
Validation loss: 1.9513807476207774

Epoch: 5| Step: 5
Training loss: 2.720742702484131
Validation loss: 1.9654663916557067

Epoch: 5| Step: 6
Training loss: 1.7193971872329712
Validation loss: 1.9203476034184939

Epoch: 5| Step: 7
Training loss: 1.6536738872528076
Validation loss: 1.9674060472878077

Epoch: 5| Step: 8
Training loss: 1.7114349603652954
Validation loss: 1.9818930292642245

Epoch: 5| Step: 9
Training loss: 1.6353765726089478
Validation loss: 1.9580445879249162

Epoch: 5| Step: 10
Training loss: 1.9690697193145752
Validation loss: 1.9826539639503724

Epoch: 251| Step: 0
Training loss: 1.0736323595046997
Validation loss: 1.963525003002536

Epoch: 5| Step: 1
Training loss: 2.0671730041503906
Validation loss: 1.9678363479593748

Epoch: 5| Step: 2
Training loss: 1.879386305809021
Validation loss: 1.9683204543205999

Epoch: 5| Step: 3
Training loss: 1.2501897811889648
Validation loss: 1.9670757298828454

Epoch: 5| Step: 4
Training loss: 2.266709327697754
Validation loss: 1.938666662862224

Epoch: 5| Step: 5
Training loss: 1.5508182048797607
Validation loss: 1.9440363927554059

Epoch: 5| Step: 6
Training loss: 1.7568973302841187
Validation loss: 1.951843233518703

Epoch: 5| Step: 7
Training loss: 1.7379066944122314
Validation loss: 1.930308203543386

Epoch: 5| Step: 8
Training loss: 1.8979790210723877
Validation loss: 1.9346949336349324

Epoch: 5| Step: 9
Training loss: 1.4242531061172485
Validation loss: 1.9639940723296134

Epoch: 5| Step: 10
Training loss: 2.715949535369873
Validation loss: 1.9710478757017402

Epoch: 252| Step: 0
Training loss: 1.5126253366470337
Validation loss: 1.9459745973669074

Epoch: 5| Step: 1
Training loss: 1.9204912185668945
Validation loss: 1.9498429631674161

Epoch: 5| Step: 2
Training loss: 2.496805191040039
Validation loss: 1.9336216501010361

Epoch: 5| Step: 3
Training loss: 1.549086093902588
Validation loss: 1.9352777901516165

Epoch: 5| Step: 4
Training loss: 1.596217393875122
Validation loss: 1.9486701591040498

Epoch: 5| Step: 5
Training loss: 1.4655840396881104
Validation loss: 1.938438977605553

Epoch: 5| Step: 6
Training loss: 1.7010772228240967
Validation loss: 1.9426233204462195

Epoch: 5| Step: 7
Training loss: 1.7034250497817993
Validation loss: 1.95714371947832

Epoch: 5| Step: 8
Training loss: 1.8818979263305664
Validation loss: 1.9265234560094855

Epoch: 5| Step: 9
Training loss: 1.736620306968689
Validation loss: 1.950494412452944

Epoch: 5| Step: 10
Training loss: 2.1489689350128174
Validation loss: 1.957739100661329

Epoch: 253| Step: 0
Training loss: 1.2109310626983643
Validation loss: 1.9527738555785148

Epoch: 5| Step: 1
Training loss: 1.961126685142517
Validation loss: 1.9543625539348972

Epoch: 5| Step: 2
Training loss: 2.0454914569854736
Validation loss: 1.952246819773028

Epoch: 5| Step: 3
Training loss: 1.5439298152923584
Validation loss: 1.9586833286029037

Epoch: 5| Step: 4
Training loss: 1.9984887838363647
Validation loss: 1.9595844412362704

Epoch: 5| Step: 5
Training loss: 2.0745818614959717
Validation loss: 1.9750090465750745

Epoch: 5| Step: 6
Training loss: 1.8879497051239014
Validation loss: 1.9362449120449763

Epoch: 5| Step: 7
Training loss: 1.4335148334503174
Validation loss: 1.930226702843943

Epoch: 5| Step: 8
Training loss: 1.627798080444336
Validation loss: 1.9814530649492819

Epoch: 5| Step: 9
Training loss: 1.6628385782241821
Validation loss: 1.9646894444701493

Epoch: 5| Step: 10
Training loss: 2.443138599395752
Validation loss: 1.9367617432789137

Epoch: 254| Step: 0
Training loss: 1.5302226543426514
Validation loss: 1.9787227107632546

Epoch: 5| Step: 1
Training loss: 1.4185658693313599
Validation loss: 1.9771448694249636

Epoch: 5| Step: 2
Training loss: 2.001533031463623
Validation loss: 1.946012443111789

Epoch: 5| Step: 3
Training loss: 2.269623041152954
Validation loss: 1.9571081899827527

Epoch: 5| Step: 4
Training loss: 2.0352752208709717
Validation loss: 1.9481957215134815

Epoch: 5| Step: 5
Training loss: 1.269998550415039
Validation loss: 1.9565334166249921

Epoch: 5| Step: 6
Training loss: 1.3613135814666748
Validation loss: 1.956462232015466

Epoch: 5| Step: 7
Training loss: 2.223498582839966
Validation loss: 1.9573536534463205

Epoch: 5| Step: 8
Training loss: 1.2670800685882568
Validation loss: 1.9298667471895936

Epoch: 5| Step: 9
Training loss: 2.0507054328918457
Validation loss: 1.9284455135304441

Epoch: 5| Step: 10
Training loss: 2.0431463718414307
Validation loss: 1.9476233477233558

Epoch: 255| Step: 0
Training loss: 1.4765926599502563
Validation loss: 1.9406603087661087

Epoch: 5| Step: 1
Training loss: 1.3606083393096924
Validation loss: 1.945785375051601

Epoch: 5| Step: 2
Training loss: 2.3339104652404785
Validation loss: 1.9826502364168885

Epoch: 5| Step: 3
Training loss: 1.6443488597869873
Validation loss: 1.969059621134112

Epoch: 5| Step: 4
Training loss: 1.0731645822525024
Validation loss: 1.9663467612317813

Epoch: 5| Step: 5
Training loss: 2.0117242336273193
Validation loss: 1.9686621209626556

Epoch: 5| Step: 6
Training loss: 1.74942147731781
Validation loss: 1.9462479891315583

Epoch: 5| Step: 7
Training loss: 1.7523107528686523
Validation loss: 1.954612560169671

Epoch: 5| Step: 8
Training loss: 2.1589982509613037
Validation loss: 1.9334600330680929

Epoch: 5| Step: 9
Training loss: 2.557964563369751
Validation loss: 1.9380274229152228

Epoch: 5| Step: 10
Training loss: 1.2121856212615967
Validation loss: 1.948848469282991

Epoch: 256| Step: 0
Training loss: 2.051553964614868
Validation loss: 1.9485990667855868

Epoch: 5| Step: 1
Training loss: 2.2004666328430176
Validation loss: 1.9445113802468905

Epoch: 5| Step: 2
Training loss: 1.592207908630371
Validation loss: 1.9501803523750716

Epoch: 5| Step: 3
Training loss: 1.8719203472137451
Validation loss: 1.9684619660018592

Epoch: 5| Step: 4
Training loss: 1.176253080368042
Validation loss: 1.938054960261109

Epoch: 5| Step: 5
Training loss: 1.9567409753799438
Validation loss: 1.9652837373877083

Epoch: 5| Step: 6
Training loss: 1.8295791149139404
Validation loss: 1.971259432454263

Epoch: 5| Step: 7
Training loss: 1.945322036743164
Validation loss: 1.9225828391249462

Epoch: 5| Step: 8
Training loss: 1.787758231163025
Validation loss: 1.9469907591419835

Epoch: 5| Step: 9
Training loss: 1.5767042636871338
Validation loss: 1.9357052208274923

Epoch: 5| Step: 10
Training loss: 1.4562146663665771
Validation loss: 1.9479459460063646

Epoch: 257| Step: 0
Training loss: 2.215264320373535
Validation loss: 1.943516828680551

Epoch: 5| Step: 1
Training loss: 1.2840454578399658
Validation loss: 1.9272877836740145

Epoch: 5| Step: 2
Training loss: 2.205470561981201
Validation loss: 1.9430086561428603

Epoch: 5| Step: 3
Training loss: 1.69939386844635
Validation loss: 1.948275237955073

Epoch: 5| Step: 4
Training loss: 1.350017786026001
Validation loss: 1.9320012228463286

Epoch: 5| Step: 5
Training loss: 1.590590238571167
Validation loss: 1.9295927555330339

Epoch: 5| Step: 6
Training loss: 1.8167142868041992
Validation loss: 1.9461053468847787

Epoch: 5| Step: 7
Training loss: 2.040262222290039
Validation loss: 1.9386108459964875

Epoch: 5| Step: 8
Training loss: 1.5348424911499023
Validation loss: 1.9227320276280886

Epoch: 5| Step: 9
Training loss: 2.004993438720703
Validation loss: 1.9250652764433174

Epoch: 5| Step: 10
Training loss: 1.5429433584213257
Validation loss: 1.9319523534467142

Epoch: 258| Step: 0
Training loss: 1.723325490951538
Validation loss: 1.964080543928249

Epoch: 5| Step: 1
Training loss: 1.7611777782440186
Validation loss: 1.9499221437720842

Epoch: 5| Step: 2
Training loss: 1.7746925354003906
Validation loss: 1.9521557131121237

Epoch: 5| Step: 3
Training loss: 2.0283029079437256
Validation loss: 1.9291779853964364

Epoch: 5| Step: 4
Training loss: 1.4105368852615356
Validation loss: 1.9293396126839422

Epoch: 5| Step: 5
Training loss: 1.5232115983963013
Validation loss: 1.933834591219502

Epoch: 5| Step: 6
Training loss: 1.5330328941345215
Validation loss: 1.909640960795905

Epoch: 5| Step: 7
Training loss: 2.331413984298706
Validation loss: 1.9338493603532032

Epoch: 5| Step: 8
Training loss: 1.6765375137329102
Validation loss: 1.960590293330531

Epoch: 5| Step: 9
Training loss: 2.2947094440460205
Validation loss: 1.9361373634748562

Epoch: 5| Step: 10
Training loss: 1.2533283233642578
Validation loss: 1.9464224179585774

Epoch: 259| Step: 0
Training loss: 1.661059021949768
Validation loss: 1.9754048906346804

Epoch: 5| Step: 1
Training loss: 1.571118950843811
Validation loss: 1.9564068612232004

Epoch: 5| Step: 2
Training loss: 2.074486494064331
Validation loss: 1.9470151624371927

Epoch: 5| Step: 3
Training loss: 2.3321280479431152
Validation loss: 1.9318821532751924

Epoch: 5| Step: 4
Training loss: 1.3125048875808716
Validation loss: 1.9393434332263084

Epoch: 5| Step: 5
Training loss: 1.547644853591919
Validation loss: 1.9435744606038576

Epoch: 5| Step: 6
Training loss: 1.872185468673706
Validation loss: 1.9511915381236742

Epoch: 5| Step: 7
Training loss: 1.3481123447418213
Validation loss: 1.9611550582352506

Epoch: 5| Step: 8
Training loss: 1.5999106168746948
Validation loss: 1.9572614316017396

Epoch: 5| Step: 9
Training loss: 2.005577564239502
Validation loss: 1.9247516303934076

Epoch: 5| Step: 10
Training loss: 1.975915551185608
Validation loss: 1.955451875604609

Epoch: 260| Step: 0
Training loss: 1.8323091268539429
Validation loss: 1.9173130181527906

Epoch: 5| Step: 1
Training loss: 1.9312565326690674
Validation loss: 1.934300507268598

Epoch: 5| Step: 2
Training loss: 1.6628131866455078
Validation loss: 1.9401878861970798

Epoch: 5| Step: 3
Training loss: 1.7009837627410889
Validation loss: 1.9379481038739603

Epoch: 5| Step: 4
Training loss: 2.1321754455566406
Validation loss: 1.9567945349601008

Epoch: 5| Step: 5
Training loss: 1.1672433614730835
Validation loss: 1.935503275163712

Epoch: 5| Step: 6
Training loss: 2.5347065925598145
Validation loss: 1.9287616514390515

Epoch: 5| Step: 7
Training loss: 1.2516816854476929
Validation loss: 1.9359003036252913

Epoch: 5| Step: 8
Training loss: 1.7778146266937256
Validation loss: 1.9180949323920793

Epoch: 5| Step: 9
Training loss: 1.364362359046936
Validation loss: 1.9446730741890528

Epoch: 5| Step: 10
Training loss: 2.209648609161377
Validation loss: 1.9267312172920472

Epoch: 261| Step: 0
Training loss: 2.368582010269165
Validation loss: 1.9470219548030565

Epoch: 5| Step: 1
Training loss: 2.648820638656616
Validation loss: 1.9455745784185265

Epoch: 5| Step: 2
Training loss: 1.6355054378509521
Validation loss: 1.9474447337529992

Epoch: 5| Step: 3
Training loss: 1.8870662450790405
Validation loss: 1.9276696802467428

Epoch: 5| Step: 4
Training loss: 1.2094752788543701
Validation loss: 1.9452067818692935

Epoch: 5| Step: 5
Training loss: 1.3117308616638184
Validation loss: 1.9519503680608605

Epoch: 5| Step: 6
Training loss: 1.127903699874878
Validation loss: 1.9451174761659356

Epoch: 5| Step: 7
Training loss: 1.8101418018341064
Validation loss: 1.9818696719343945

Epoch: 5| Step: 8
Training loss: 1.6135820150375366
Validation loss: 1.9734655093121272

Epoch: 5| Step: 9
Training loss: 1.5997555255889893
Validation loss: 1.9500314061359694

Epoch: 5| Step: 10
Training loss: 1.9037197828292847
Validation loss: 1.9590089846682806

Epoch: 262| Step: 0
Training loss: 1.2480559349060059
Validation loss: 1.942204915067201

Epoch: 5| Step: 1
Training loss: 1.6085706949234009
Validation loss: 1.939931099132825

Epoch: 5| Step: 2
Training loss: 1.7571923732757568
Validation loss: 1.9114127441119122

Epoch: 5| Step: 3
Training loss: 1.9008508920669556
Validation loss: 1.9411094637327297

Epoch: 5| Step: 4
Training loss: 2.072969436645508
Validation loss: 1.9348045292721

Epoch: 5| Step: 5
Training loss: 1.5759810209274292
Validation loss: 1.9208215795537478

Epoch: 5| Step: 6
Training loss: 2.1039352416992188
Validation loss: 1.9288172362953104

Epoch: 5| Step: 7
Training loss: 1.7782857418060303
Validation loss: 1.9467632437265048

Epoch: 5| Step: 8
Training loss: 1.3452770709991455
Validation loss: 1.9435785573015931

Epoch: 5| Step: 9
Training loss: 2.169858694076538
Validation loss: 1.9461182714790426

Epoch: 5| Step: 10
Training loss: 1.7945131063461304
Validation loss: 1.9362704112965574

Epoch: 263| Step: 0
Training loss: 1.8491809368133545
Validation loss: 1.9492099541489796

Epoch: 5| Step: 1
Training loss: 1.7111060619354248
Validation loss: 1.9124315605368665

Epoch: 5| Step: 2
Training loss: 1.840821623802185
Validation loss: 1.9364894820797829

Epoch: 5| Step: 3
Training loss: 1.3819541931152344
Validation loss: 1.903324596343502

Epoch: 5| Step: 4
Training loss: 1.7545276880264282
Validation loss: 1.9525832437699842

Epoch: 5| Step: 5
Training loss: 1.8911664485931396
Validation loss: 1.9480145797934583

Epoch: 5| Step: 6
Training loss: 1.726993203163147
Validation loss: 1.9543492524854598

Epoch: 5| Step: 7
Training loss: 1.5328773260116577
Validation loss: 1.9626825868442495

Epoch: 5| Step: 8
Training loss: 1.586836814880371
Validation loss: 1.9586802797932779

Epoch: 5| Step: 9
Training loss: 2.3040738105773926
Validation loss: 1.9418696818813201

Epoch: 5| Step: 10
Training loss: 1.617311716079712
Validation loss: 1.953728602778527

Epoch: 264| Step: 0
Training loss: 1.8064546585083008
Validation loss: 1.914094304525724

Epoch: 5| Step: 1
Training loss: 2.484562873840332
Validation loss: 1.9347765766164309

Epoch: 5| Step: 2
Training loss: 1.5322697162628174
Validation loss: 1.9675133766666535

Epoch: 5| Step: 3
Training loss: 1.7013168334960938
Validation loss: 1.9434500061055666

Epoch: 5| Step: 4
Training loss: 1.4006309509277344
Validation loss: 1.9386760368142077

Epoch: 5| Step: 5
Training loss: 1.2801533937454224
Validation loss: 1.9156711960351596

Epoch: 5| Step: 6
Training loss: 1.8462152481079102
Validation loss: 1.918304612559657

Epoch: 5| Step: 7
Training loss: 2.090902805328369
Validation loss: 1.931834231140793

Epoch: 5| Step: 8
Training loss: 1.238446593284607
Validation loss: 1.9565238824454687

Epoch: 5| Step: 9
Training loss: 1.7976014614105225
Validation loss: 1.9137285447889758

Epoch: 5| Step: 10
Training loss: 2.037499189376831
Validation loss: 1.9422895831446494

Epoch: 265| Step: 0
Training loss: 2.0060977935791016
Validation loss: 1.91148341086603

Epoch: 5| Step: 1
Training loss: 1.1890342235565186
Validation loss: 1.9133040161542996

Epoch: 5| Step: 2
Training loss: 1.83999502658844
Validation loss: 1.9227728638597714

Epoch: 5| Step: 3
Training loss: 2.0653789043426514
Validation loss: 1.9322897605998541

Epoch: 5| Step: 4
Training loss: 1.4496365785598755
Validation loss: 1.9378257925792406

Epoch: 5| Step: 5
Training loss: 2.2404818534851074
Validation loss: 1.9221447462676673

Epoch: 5| Step: 6
Training loss: 1.5420483350753784
Validation loss: 1.9179942889880108

Epoch: 5| Step: 7
Training loss: 2.1261730194091797
Validation loss: 1.9063568474144064

Epoch: 5| Step: 8
Training loss: 1.2306444644927979
Validation loss: 1.9259858169863302

Epoch: 5| Step: 9
Training loss: 1.8471252918243408
Validation loss: 1.9324883735308083

Epoch: 5| Step: 10
Training loss: 1.849233865737915
Validation loss: 1.9253062343084684

Epoch: 266| Step: 0
Training loss: 1.4172327518463135
Validation loss: 1.9298746701209777

Epoch: 5| Step: 1
Training loss: 2.040848970413208
Validation loss: 1.987089123777164

Epoch: 5| Step: 2
Training loss: 1.597985029220581
Validation loss: 1.9249700051482006

Epoch: 5| Step: 3
Training loss: 1.9751274585723877
Validation loss: 1.9432549220259472

Epoch: 5| Step: 4
Training loss: 2.0993735790252686
Validation loss: 1.9271978703878259

Epoch: 5| Step: 5
Training loss: 1.6466690301895142
Validation loss: 1.9651164777817265

Epoch: 5| Step: 6
Training loss: 1.8529475927352905
Validation loss: 1.9228609864429762

Epoch: 5| Step: 7
Training loss: 1.6234381198883057
Validation loss: 1.9782779075766121

Epoch: 5| Step: 8
Training loss: 1.7423988580703735
Validation loss: 1.9443863489294564

Epoch: 5| Step: 9
Training loss: 1.299522042274475
Validation loss: 1.9282374587110294

Epoch: 5| Step: 10
Training loss: 1.945953130722046
Validation loss: 1.95120785825996

Epoch: 267| Step: 0
Training loss: 1.459890604019165
Validation loss: 1.9262816752156904

Epoch: 5| Step: 1
Training loss: 1.7008644342422485
Validation loss: 1.9172592880905315

Epoch: 5| Step: 2
Training loss: 1.473393201828003
Validation loss: 1.9288682758167226

Epoch: 5| Step: 3
Training loss: 1.368696928024292
Validation loss: 1.9192752953498595

Epoch: 5| Step: 4
Training loss: 2.0462098121643066
Validation loss: 1.918474301215141

Epoch: 5| Step: 5
Training loss: 1.937368392944336
Validation loss: 1.9211702551893008

Epoch: 5| Step: 6
Training loss: 1.5673412084579468
Validation loss: 1.922239634298509

Epoch: 5| Step: 7
Training loss: 1.629492163658142
Validation loss: 1.8795060252630582

Epoch: 5| Step: 8
Training loss: 2.018200397491455
Validation loss: 1.9324607567120624

Epoch: 5| Step: 9
Training loss: 1.912878394126892
Validation loss: 1.9318505640952819

Epoch: 5| Step: 10
Training loss: 2.0829591751098633
Validation loss: 1.9177240671650055

Epoch: 268| Step: 0
Training loss: 1.263686180114746
Validation loss: 1.9273955950172998

Epoch: 5| Step: 1
Training loss: 1.7845007181167603
Validation loss: 1.9222217298323108

Epoch: 5| Step: 2
Training loss: 2.1342780590057373
Validation loss: 1.9208708873359106

Epoch: 5| Step: 3
Training loss: 1.8898260593414307
Validation loss: 1.936552583530385

Epoch: 5| Step: 4
Training loss: 1.0397241115570068
Validation loss: 1.9675111078446912

Epoch: 5| Step: 5
Training loss: 1.7225592136383057
Validation loss: 1.949690475258776

Epoch: 5| Step: 6
Training loss: 1.7314237356185913
Validation loss: 1.9526533234503962

Epoch: 5| Step: 7
Training loss: 1.5314582586288452
Validation loss: 1.9709378109183362

Epoch: 5| Step: 8
Training loss: 1.3261797428131104
Validation loss: 1.9420351251479118

Epoch: 5| Step: 9
Training loss: 2.1588587760925293
Validation loss: 1.9282355026532245

Epoch: 5| Step: 10
Training loss: 2.4718129634857178
Validation loss: 1.9479371834826726

Epoch: 269| Step: 0
Training loss: 1.36612069606781
Validation loss: 1.91019364582595

Epoch: 5| Step: 1
Training loss: 1.9384605884552002
Validation loss: 1.9415252798347062

Epoch: 5| Step: 2
Training loss: 1.7457637786865234
Validation loss: 1.9559678236643474

Epoch: 5| Step: 3
Training loss: 1.3066259622573853
Validation loss: 1.9088622549528718

Epoch: 5| Step: 4
Training loss: 1.8309574127197266
Validation loss: 1.9189123889451385

Epoch: 5| Step: 5
Training loss: 2.266542911529541
Validation loss: 1.936258287839992

Epoch: 5| Step: 6
Training loss: 1.6457881927490234
Validation loss: 1.88394312256126

Epoch: 5| Step: 7
Training loss: 1.9716176986694336
Validation loss: 1.896839899401511

Epoch: 5| Step: 8
Training loss: 1.287541389465332
Validation loss: 1.9284488949724423

Epoch: 5| Step: 9
Training loss: 2.115894317626953
Validation loss: 1.946528596262778

Epoch: 5| Step: 10
Training loss: 1.3945200443267822
Validation loss: 1.9284605069827008

Epoch: 270| Step: 0
Training loss: 1.6116527318954468
Validation loss: 1.9420624753480316

Epoch: 5| Step: 1
Training loss: 1.5243853330612183
Validation loss: 1.9322164917504916

Epoch: 5| Step: 2
Training loss: 1.7971620559692383
Validation loss: 1.9122865981953119

Epoch: 5| Step: 3
Training loss: 1.7252403497695923
Validation loss: 1.936745100123908

Epoch: 5| Step: 4
Training loss: 2.3250510692596436
Validation loss: 1.9233190705699306

Epoch: 5| Step: 5
Training loss: 1.5876742601394653
Validation loss: 1.9421161272192513

Epoch: 5| Step: 6
Training loss: 1.495661973953247
Validation loss: 1.9406521281888407

Epoch: 5| Step: 7
Training loss: 1.5977156162261963
Validation loss: 1.9442626019959808

Epoch: 5| Step: 8
Training loss: 1.7962825298309326
Validation loss: 1.9253270626068115

Epoch: 5| Step: 9
Training loss: 1.7682892084121704
Validation loss: 1.8974722700734292

Epoch: 5| Step: 10
Training loss: 1.6969014406204224
Validation loss: 1.8842914207007295

Epoch: 271| Step: 0
Training loss: 1.8228247165679932
Validation loss: 1.9190193273687874

Epoch: 5| Step: 1
Training loss: 1.537627935409546
Validation loss: 1.945584854772014

Epoch: 5| Step: 2
Training loss: 2.006988048553467
Validation loss: 1.9063392518669047

Epoch: 5| Step: 3
Training loss: 1.7715187072753906
Validation loss: 1.9273549459313835

Epoch: 5| Step: 4
Training loss: 1.5589183568954468
Validation loss: 1.9433780075401388

Epoch: 5| Step: 5
Training loss: 1.8638445138931274
Validation loss: 1.9303719920496787

Epoch: 5| Step: 6
Training loss: 1.8289703130722046
Validation loss: 1.9286127295545352

Epoch: 5| Step: 7
Training loss: 1.2943317890167236
Validation loss: 1.9406148387539772

Epoch: 5| Step: 8
Training loss: 1.7994130849838257
Validation loss: 1.8973332669145317

Epoch: 5| Step: 9
Training loss: 1.6343212127685547
Validation loss: 1.9841839574998426

Epoch: 5| Step: 10
Training loss: 1.6527681350708008
Validation loss: 1.9443441616591586

Epoch: 272| Step: 0
Training loss: 1.6214252710342407
Validation loss: 1.9503537249821488

Epoch: 5| Step: 1
Training loss: 2.1618142127990723
Validation loss: 1.911115474598382

Epoch: 5| Step: 2
Training loss: 1.4438389539718628
Validation loss: 1.925184912579034

Epoch: 5| Step: 3
Training loss: 1.7059946060180664
Validation loss: 1.9295656296514696

Epoch: 5| Step: 4
Training loss: 1.9364662170410156
Validation loss: 1.9354074770404446

Epoch: 5| Step: 5
Training loss: 1.3229100704193115
Validation loss: 1.9526471643037693

Epoch: 5| Step: 6
Training loss: 1.7530149221420288
Validation loss: 1.8958864596582228

Epoch: 5| Step: 7
Training loss: 2.032705068588257
Validation loss: 1.879827650644446

Epoch: 5| Step: 8
Training loss: 1.6207462549209595
Validation loss: 1.9097271427031486

Epoch: 5| Step: 9
Training loss: 1.739532709121704
Validation loss: 1.9138355383308985

Epoch: 5| Step: 10
Training loss: 1.5174305438995361
Validation loss: 1.9272439710555538

Epoch: 273| Step: 0
Training loss: 1.0915733575820923
Validation loss: 1.906509978796846

Epoch: 5| Step: 1
Training loss: 1.5562422275543213
Validation loss: 1.9139921716464463

Epoch: 5| Step: 2
Training loss: 1.7545477151870728
Validation loss: 1.8915809662111345

Epoch: 5| Step: 3
Training loss: 1.9563525915145874
Validation loss: 1.9305973001705703

Epoch: 5| Step: 4
Training loss: 1.5389975309371948
Validation loss: 1.895531145475244

Epoch: 5| Step: 5
Training loss: 2.0168120861053467
Validation loss: 1.892722357985794

Epoch: 5| Step: 6
Training loss: 1.9416621923446655
Validation loss: 1.9184790503594182

Epoch: 5| Step: 7
Training loss: 1.076846718788147
Validation loss: 1.917856434340118

Epoch: 5| Step: 8
Training loss: 1.614659070968628
Validation loss: 1.9250510815651185

Epoch: 5| Step: 9
Training loss: 2.372868776321411
Validation loss: 1.9416517070544663

Epoch: 5| Step: 10
Training loss: 2.094099760055542
Validation loss: 1.874796543070065

Epoch: 274| Step: 0
Training loss: 1.5469684600830078
Validation loss: 1.9324935418303295

Epoch: 5| Step: 1
Training loss: 1.7861541509628296
Validation loss: 1.9467067910778908

Epoch: 5| Step: 2
Training loss: 2.0939860343933105
Validation loss: 1.914264827646235

Epoch: 5| Step: 3
Training loss: 1.9297025203704834
Validation loss: 1.930281380171417

Epoch: 5| Step: 4
Training loss: 1.8938980102539062
Validation loss: 1.9359609721809306

Epoch: 5| Step: 5
Training loss: 1.4372130632400513
Validation loss: 1.9321686683162567

Epoch: 5| Step: 6
Training loss: 1.8826687335968018
Validation loss: 1.9224740164254301

Epoch: 5| Step: 7
Training loss: 1.6421178579330444
Validation loss: 1.9577698297398065

Epoch: 5| Step: 8
Training loss: 1.0506908893585205
Validation loss: 1.9748188936582176

Epoch: 5| Step: 9
Training loss: 1.7669479846954346
Validation loss: 1.9632764426610803

Epoch: 5| Step: 10
Training loss: 1.951292872428894
Validation loss: 1.9560142063325452

Epoch: 275| Step: 0
Training loss: 1.5354783535003662
Validation loss: 1.9392449932713662

Epoch: 5| Step: 1
Training loss: 2.479435443878174
Validation loss: 1.9473595978111349

Epoch: 5| Step: 2
Training loss: 2.2363834381103516
Validation loss: 1.9313411187100153

Epoch: 5| Step: 3
Training loss: 1.8003085851669312
Validation loss: 1.910351825016801

Epoch: 5| Step: 4
Training loss: 1.2849884033203125
Validation loss: 1.9382834498600294

Epoch: 5| Step: 5
Training loss: 1.5543396472930908
Validation loss: 1.9093902777600031

Epoch: 5| Step: 6
Training loss: 1.7934091091156006
Validation loss: 1.9259981057977165

Epoch: 5| Step: 7
Training loss: 1.3246924877166748
Validation loss: 1.926485417991556

Epoch: 5| Step: 8
Training loss: 1.5370365381240845
Validation loss: 1.9041640194513465

Epoch: 5| Step: 9
Training loss: 1.9871097803115845
Validation loss: 1.9002538496448147

Epoch: 5| Step: 10
Training loss: 1.439526915550232
Validation loss: 1.9388352837613834

Epoch: 276| Step: 0
Training loss: 2.0804800987243652
Validation loss: 1.8951886533409037

Epoch: 5| Step: 1
Training loss: 1.2307287454605103
Validation loss: 1.9257581823615617

Epoch: 5| Step: 2
Training loss: 2.610166311264038
Validation loss: 1.9159612553094023

Epoch: 5| Step: 3
Training loss: 1.7078006267547607
Validation loss: 1.9130197237896662

Epoch: 5| Step: 4
Training loss: 1.5366724729537964
Validation loss: 1.891139030456543

Epoch: 5| Step: 5
Training loss: 2.02172589302063
Validation loss: 1.904967963054616

Epoch: 5| Step: 6
Training loss: 1.4002686738967896
Validation loss: 1.9166437451557448

Epoch: 5| Step: 7
Training loss: 1.875573754310608
Validation loss: 1.918253912720629

Epoch: 5| Step: 8
Training loss: 1.3566659688949585
Validation loss: 1.9362421651040354

Epoch: 5| Step: 9
Training loss: 1.1852617263793945
Validation loss: 1.921096073683872

Epoch: 5| Step: 10
Training loss: 1.917626976966858
Validation loss: 1.926119412145307

Epoch: 277| Step: 0
Training loss: 1.3296420574188232
Validation loss: 1.9392639539575065

Epoch: 5| Step: 1
Training loss: 2.384331464767456
Validation loss: 1.9426168267444899

Epoch: 5| Step: 2
Training loss: 1.068446397781372
Validation loss: 1.9564970090825071

Epoch: 5| Step: 3
Training loss: 2.4059269428253174
Validation loss: 1.9454554844928045

Epoch: 5| Step: 4
Training loss: 1.7207565307617188
Validation loss: 1.9611769645444808

Epoch: 5| Step: 5
Training loss: 1.6286678314208984
Validation loss: 1.9520611275908768

Epoch: 5| Step: 6
Training loss: 1.3404649496078491
Validation loss: 1.9483612865530036

Epoch: 5| Step: 7
Training loss: 1.7139759063720703
Validation loss: 1.9445398981853197

Epoch: 5| Step: 8
Training loss: 1.4377492666244507
Validation loss: 1.9197731133430236

Epoch: 5| Step: 9
Training loss: 1.9517977237701416
Validation loss: 1.9257686099698466

Epoch: 5| Step: 10
Training loss: 2.013573169708252
Validation loss: 1.9297706004111999

Epoch: 278| Step: 0
Training loss: 2.0908217430114746
Validation loss: 1.8948803511998986

Epoch: 5| Step: 1
Training loss: 1.3725868463516235
Validation loss: 1.9053070865651613

Epoch: 5| Step: 2
Training loss: 1.868652105331421
Validation loss: 1.9375685171414447

Epoch: 5| Step: 3
Training loss: 1.8656221628189087
Validation loss: 1.9294351352158414

Epoch: 5| Step: 4
Training loss: 1.5774887800216675
Validation loss: 1.9136231496769895

Epoch: 5| Step: 5
Training loss: 1.6861047744750977
Validation loss: 1.9509560959313506

Epoch: 5| Step: 6
Training loss: 2.1864638328552246
Validation loss: 1.8783603265721311

Epoch: 5| Step: 7
Training loss: 1.3690307140350342
Validation loss: 1.917237586872552

Epoch: 5| Step: 8
Training loss: 1.5777587890625
Validation loss: 1.9233037066716019

Epoch: 5| Step: 9
Training loss: 1.2169057130813599
Validation loss: 1.949702614097185

Epoch: 5| Step: 10
Training loss: 1.948546051979065
Validation loss: 1.9271247502296203

Epoch: 279| Step: 0
Training loss: 2.1134066581726074
Validation loss: 1.9517586179958877

Epoch: 5| Step: 1
Training loss: 1.5922733545303345
Validation loss: 1.8963100628186298

Epoch: 5| Step: 2
Training loss: 1.7674287557601929
Validation loss: 1.910984282852501

Epoch: 5| Step: 3
Training loss: 1.4588326215744019
Validation loss: 1.896601087303572

Epoch: 5| Step: 4
Training loss: 1.638986587524414
Validation loss: 1.9421371234360563

Epoch: 5| Step: 5
Training loss: 1.666243553161621
Validation loss: 1.886932590956329

Epoch: 5| Step: 6
Training loss: 1.1038811206817627
Validation loss: 1.8714189324327695

Epoch: 5| Step: 7
Training loss: 1.916805624961853
Validation loss: 1.875762060124387

Epoch: 5| Step: 8
Training loss: 2.314901351928711
Validation loss: 1.9615145729434105

Epoch: 5| Step: 9
Training loss: 1.7714793682098389
Validation loss: 1.9273637571642477

Epoch: 5| Step: 10
Training loss: 1.3474528789520264
Validation loss: 1.9319799792382024

Epoch: 280| Step: 0
Training loss: 2.084075450897217
Validation loss: 1.9000859158013457

Epoch: 5| Step: 1
Training loss: 1.5385738611221313
Validation loss: 1.9054375938189927

Epoch: 5| Step: 2
Training loss: 1.4391368627548218
Validation loss: 1.9110055559424943

Epoch: 5| Step: 3
Training loss: 2.1472017765045166
Validation loss: 1.9345316117809666

Epoch: 5| Step: 4
Training loss: 1.3645555973052979
Validation loss: 1.9385042869916527

Epoch: 5| Step: 5
Training loss: 1.641908884048462
Validation loss: 1.8965906270088688

Epoch: 5| Step: 6
Training loss: 2.1712851524353027
Validation loss: 1.9114886650475122

Epoch: 5| Step: 7
Training loss: 1.5193144083023071
Validation loss: 1.9132697992427374

Epoch: 5| Step: 8
Training loss: 0.9775692224502563
Validation loss: 1.9257728515132781

Epoch: 5| Step: 9
Training loss: 2.1525955200195312
Validation loss: 1.965513511370587

Epoch: 5| Step: 10
Training loss: 1.9325085878372192
Validation loss: 1.9371583718125538

Epoch: 281| Step: 0
Training loss: 1.4267724752426147
Validation loss: 1.9219729438904793

Epoch: 5| Step: 1
Training loss: 1.3219488859176636
Validation loss: 1.9078288847400295

Epoch: 5| Step: 2
Training loss: 1.814265251159668
Validation loss: 1.8987339068484563

Epoch: 5| Step: 3
Training loss: 1.3180480003356934
Validation loss: 1.9345185884865381

Epoch: 5| Step: 4
Training loss: 1.8485549688339233
Validation loss: 1.9641847418200584

Epoch: 5| Step: 5
Training loss: 2.412595272064209
Validation loss: 1.9262747662041777

Epoch: 5| Step: 6
Training loss: 1.725446343421936
Validation loss: 1.9258195943729852

Epoch: 5| Step: 7
Training loss: 1.6086578369140625
Validation loss: 1.9596527917410738

Epoch: 5| Step: 8
Training loss: 1.6707712411880493
Validation loss: 1.921377751135057

Epoch: 5| Step: 9
Training loss: 1.854872465133667
Validation loss: 1.9296288926114318

Epoch: 5| Step: 10
Training loss: 1.7876176834106445
Validation loss: 1.9154086587249592

Epoch: 282| Step: 0
Training loss: 2.0798861980438232
Validation loss: 1.9317057940267748

Epoch: 5| Step: 1
Training loss: 1.6469428539276123
Validation loss: 1.9270670619062198

Epoch: 5| Step: 2
Training loss: 2.0437023639678955
Validation loss: 1.9586751512301865

Epoch: 5| Step: 3
Training loss: 1.476567268371582
Validation loss: 1.9223379499168807

Epoch: 5| Step: 4
Training loss: 1.7947953939437866
Validation loss: 1.9304129538997528

Epoch: 5| Step: 5
Training loss: 1.9309566020965576
Validation loss: 1.9215729108420752

Epoch: 5| Step: 6
Training loss: 1.3417497873306274
Validation loss: 1.910635809744558

Epoch: 5| Step: 7
Training loss: 1.1576710939407349
Validation loss: 1.9112510322242655

Epoch: 5| Step: 8
Training loss: 1.8436195850372314
Validation loss: 1.9392407030187628

Epoch: 5| Step: 9
Training loss: 1.81368088722229
Validation loss: 1.9096325071909095

Epoch: 5| Step: 10
Training loss: 1.7562810182571411
Validation loss: 1.9236600834836242

Epoch: 283| Step: 0
Training loss: 1.2043110132217407
Validation loss: 1.8871219875991985

Epoch: 5| Step: 1
Training loss: 1.6993739604949951
Validation loss: 1.9327401832867694

Epoch: 5| Step: 2
Training loss: 1.2454359531402588
Validation loss: 1.9106440082673104

Epoch: 5| Step: 3
Training loss: 1.8408935070037842
Validation loss: 1.8969096470904607

Epoch: 5| Step: 4
Training loss: 2.168368339538574
Validation loss: 1.8957849907618698

Epoch: 5| Step: 5
Training loss: 1.8183701038360596
Validation loss: 1.913595704622166

Epoch: 5| Step: 6
Training loss: 2.478527069091797
Validation loss: 1.8717211446454447

Epoch: 5| Step: 7
Training loss: 1.7852556705474854
Validation loss: 1.916238566880585

Epoch: 5| Step: 8
Training loss: 1.8435386419296265
Validation loss: 1.9380144611481698

Epoch: 5| Step: 9
Training loss: 1.3606247901916504
Validation loss: 1.919462296270555

Epoch: 5| Step: 10
Training loss: 1.009040355682373
Validation loss: 1.9451611452205206

Epoch: 284| Step: 0
Training loss: 2.052199602127075
Validation loss: 1.9542584252613846

Epoch: 5| Step: 1
Training loss: 1.5401906967163086
Validation loss: 1.8987415400884484

Epoch: 5| Step: 2
Training loss: 1.1518017053604126
Validation loss: 1.918843419962032

Epoch: 5| Step: 3
Training loss: 1.7802488803863525
Validation loss: 1.9303584585907638

Epoch: 5| Step: 4
Training loss: 1.419963002204895
Validation loss: 1.942958047313075

Epoch: 5| Step: 5
Training loss: 1.6880786418914795
Validation loss: 1.9325833166799238

Epoch: 5| Step: 6
Training loss: 1.8254636526107788
Validation loss: 1.9012815465209305

Epoch: 5| Step: 7
Training loss: 1.710022211074829
Validation loss: 1.8866885144223449

Epoch: 5| Step: 8
Training loss: 1.8629944324493408
Validation loss: 1.8795092298138527

Epoch: 5| Step: 9
Training loss: 1.5620861053466797
Validation loss: 1.9123051358807472

Epoch: 5| Step: 10
Training loss: 1.8799140453338623
Validation loss: 1.9248654637285458

Epoch: 285| Step: 0
Training loss: 1.6754318475723267
Validation loss: 1.9309392641949397

Epoch: 5| Step: 1
Training loss: 1.2898304462432861
Validation loss: 1.9405788888213455

Epoch: 5| Step: 2
Training loss: 1.774125337600708
Validation loss: 1.8988050927398026

Epoch: 5| Step: 3
Training loss: 1.5969610214233398
Validation loss: 1.882331666126046

Epoch: 5| Step: 4
Training loss: 2.1755359172821045
Validation loss: 1.9179748565919938

Epoch: 5| Step: 5
Training loss: 2.173786163330078
Validation loss: 1.9481985133181337

Epoch: 5| Step: 6
Training loss: 1.8789031505584717
Validation loss: 1.9118316006916825

Epoch: 5| Step: 7
Training loss: 1.1783106327056885
Validation loss: 1.88550978578547

Epoch: 5| Step: 8
Training loss: 1.396009087562561
Validation loss: 1.9642087387782272

Epoch: 5| Step: 9
Training loss: 1.8122928142547607
Validation loss: 1.91018440774692

Epoch: 5| Step: 10
Training loss: 1.8167668581008911
Validation loss: 1.9390452215748448

Epoch: 286| Step: 0
Training loss: 1.347609043121338
Validation loss: 1.891682622253254

Epoch: 5| Step: 1
Training loss: 2.1505725383758545
Validation loss: 1.9120504189563055

Epoch: 5| Step: 2
Training loss: 1.051210641860962
Validation loss: 1.9178752553078435

Epoch: 5| Step: 3
Training loss: 1.568730115890503
Validation loss: 1.9135383457265875

Epoch: 5| Step: 4
Training loss: 1.0583269596099854
Validation loss: 1.9377549002247472

Epoch: 5| Step: 5
Training loss: 2.009822368621826
Validation loss: 1.9134659946605723

Epoch: 5| Step: 6
Training loss: 2.4665627479553223
Validation loss: 1.8943104590139082

Epoch: 5| Step: 7
Training loss: 1.5455182790756226
Validation loss: 1.907142908342423

Epoch: 5| Step: 8
Training loss: 2.1680595874786377
Validation loss: 1.8782156641765306

Epoch: 5| Step: 9
Training loss: 1.511663556098938
Validation loss: 1.8987543839280323

Epoch: 5| Step: 10
Training loss: 1.6257225275039673
Validation loss: 1.9347967588773338

Epoch: 287| Step: 0
Training loss: 2.017535448074341
Validation loss: 1.9038544700991722

Epoch: 5| Step: 1
Training loss: 1.8296148777008057
Validation loss: 1.9302138000406244

Epoch: 5| Step: 2
Training loss: 1.4486875534057617
Validation loss: 1.9206922874655774

Epoch: 5| Step: 3
Training loss: 2.3132548332214355
Validation loss: 1.9248732559142574

Epoch: 5| Step: 4
Training loss: 1.4940125942230225
Validation loss: 1.9519081474632345

Epoch: 5| Step: 5
Training loss: 1.248340368270874
Validation loss: 1.9007330658615276

Epoch: 5| Step: 6
Training loss: 1.4855197668075562
Validation loss: 1.9474656581878662

Epoch: 5| Step: 7
Training loss: 1.7229175567626953
Validation loss: 1.8962946284201838

Epoch: 5| Step: 8
Training loss: 1.240812063217163
Validation loss: 1.9370848337809246

Epoch: 5| Step: 9
Training loss: 1.9590412378311157
Validation loss: 1.9352536509113927

Epoch: 5| Step: 10
Training loss: 1.7046794891357422
Validation loss: 1.9039616302777362

Epoch: 288| Step: 0
Training loss: 1.8257224559783936
Validation loss: 1.9299276644183743

Epoch: 5| Step: 1
Training loss: 1.071357011795044
Validation loss: 1.9478416981235627

Epoch: 5| Step: 2
Training loss: 1.473975419998169
Validation loss: 1.945947531730898

Epoch: 5| Step: 3
Training loss: 1.7286087274551392
Validation loss: 1.9096925463727725

Epoch: 5| Step: 4
Training loss: 0.9611603021621704
Validation loss: 1.9076641016109015

Epoch: 5| Step: 5
Training loss: 1.505353569984436
Validation loss: 1.9297345479329426

Epoch: 5| Step: 6
Training loss: 2.010651111602783
Validation loss: 1.9153137835123206

Epoch: 5| Step: 7
Training loss: 1.5583970546722412
Validation loss: 1.9095857579221007

Epoch: 5| Step: 8
Training loss: 1.8901138305664062
Validation loss: 1.9445884535389562

Epoch: 5| Step: 9
Training loss: 2.672712802886963
Validation loss: 1.9213532696488083

Epoch: 5| Step: 10
Training loss: 1.760338306427002
Validation loss: 1.8944758369076637

Epoch: 289| Step: 0
Training loss: 1.5801060199737549
Validation loss: 1.9009021892342517

Epoch: 5| Step: 1
Training loss: 1.6946073770523071
Validation loss: 1.9504314468752952

Epoch: 5| Step: 2
Training loss: 1.8937137126922607
Validation loss: 1.9303229342224777

Epoch: 5| Step: 3
Training loss: 1.9427406787872314
Validation loss: 1.8999860799440773

Epoch: 5| Step: 4
Training loss: 1.4635322093963623
Validation loss: 1.8988749263107136

Epoch: 5| Step: 5
Training loss: 1.5472484827041626
Validation loss: 1.910045471242679

Epoch: 5| Step: 6
Training loss: 1.7529399394989014
Validation loss: 1.8897882225692912

Epoch: 5| Step: 7
Training loss: 1.6890405416488647
Validation loss: 1.9038977123075915

Epoch: 5| Step: 8
Training loss: 1.9415833950042725
Validation loss: 1.9241287323736376

Epoch: 5| Step: 9
Training loss: 1.474445104598999
Validation loss: 1.88605208294366

Epoch: 5| Step: 10
Training loss: 1.3107497692108154
Validation loss: 1.8979862607935423

Epoch: 290| Step: 0
Training loss: 2.1826701164245605
Validation loss: 1.9413223728056876

Epoch: 5| Step: 1
Training loss: 1.7005774974822998
Validation loss: 1.8967312330840735

Epoch: 5| Step: 2
Training loss: 1.557142972946167
Validation loss: 1.9058997618254794

Epoch: 5| Step: 3
Training loss: 1.8166229724884033
Validation loss: 1.9283917283499112

Epoch: 5| Step: 4
Training loss: 1.5407406091690063
Validation loss: 1.9312258074360509

Epoch: 5| Step: 5
Training loss: 1.7457174062728882
Validation loss: 1.9585818359928746

Epoch: 5| Step: 6
Training loss: 1.1611251831054688
Validation loss: 1.887582807130711

Epoch: 5| Step: 7
Training loss: 1.8184175491333008
Validation loss: 1.937569281106354

Epoch: 5| Step: 8
Training loss: 1.9924466609954834
Validation loss: 1.8836883857686033

Epoch: 5| Step: 9
Training loss: 1.6646549701690674
Validation loss: 1.8876224410149358

Epoch: 5| Step: 10
Training loss: 1.3412765264511108
Validation loss: 1.9278636773427327

Epoch: 291| Step: 0
Training loss: 1.503962755203247
Validation loss: 1.9057913223902385

Epoch: 5| Step: 1
Training loss: 1.5103623867034912
Validation loss: 1.911874827518258

Epoch: 5| Step: 2
Training loss: 1.0529892444610596
Validation loss: 1.8898899093750985

Epoch: 5| Step: 3
Training loss: 1.5344644784927368
Validation loss: 1.8868951541121288

Epoch: 5| Step: 4
Training loss: 2.005058765411377
Validation loss: 1.9388267814472158

Epoch: 5| Step: 5
Training loss: 2.0508739948272705
Validation loss: 1.9247102237516833

Epoch: 5| Step: 6
Training loss: 2.055074691772461
Validation loss: 1.8792327373258528

Epoch: 5| Step: 7
Training loss: 1.8477853536605835
Validation loss: 1.8736201806734967

Epoch: 5| Step: 8
Training loss: 1.7608025074005127
Validation loss: 1.8916942880999656

Epoch: 5| Step: 9
Training loss: 1.8056466579437256
Validation loss: 1.8950457752391856

Epoch: 5| Step: 10
Training loss: 1.2893699407577515
Validation loss: 1.9101641549858996

Epoch: 292| Step: 0
Training loss: 1.9987154006958008
Validation loss: 1.941885317525556

Epoch: 5| Step: 1
Training loss: 1.2652783393859863
Validation loss: 1.936387377400552

Epoch: 5| Step: 2
Training loss: 1.0302060842514038
Validation loss: 1.937138638188762

Epoch: 5| Step: 3
Training loss: 2.043118953704834
Validation loss: 1.9319387046239709

Epoch: 5| Step: 4
Training loss: 1.6225630044937134
Validation loss: 1.9530280187565794

Epoch: 5| Step: 5
Training loss: 1.9013324975967407
Validation loss: 1.9214985793636692

Epoch: 5| Step: 6
Training loss: 1.9908015727996826
Validation loss: 1.9434895797442364

Epoch: 5| Step: 7
Training loss: 1.780093789100647
Validation loss: 1.951971903924019

Epoch: 5| Step: 8
Training loss: 1.6833059787750244
Validation loss: 1.9240644542119836

Epoch: 5| Step: 9
Training loss: 1.356654405593872
Validation loss: 1.9121115989582513

Epoch: 5| Step: 10
Training loss: 1.772919774055481
Validation loss: 1.8964479123392413

Epoch: 293| Step: 0
Training loss: 1.7163738012313843
Validation loss: 1.935922622680664

Epoch: 5| Step: 1
Training loss: 1.7639195919036865
Validation loss: 1.9052378131497292

Epoch: 5| Step: 2
Training loss: 2.161614418029785
Validation loss: 1.9541569038103985

Epoch: 5| Step: 3
Training loss: 2.110384941101074
Validation loss: 1.9307369032213766

Epoch: 5| Step: 4
Training loss: 1.6732181310653687
Validation loss: 1.9332109689712524

Epoch: 5| Step: 5
Training loss: 1.40556800365448
Validation loss: 1.9115029432440316

Epoch: 5| Step: 6
Training loss: 1.9053456783294678
Validation loss: 1.8950967006785895

Epoch: 5| Step: 7
Training loss: 1.0953199863433838
Validation loss: 1.9108157696262482

Epoch: 5| Step: 8
Training loss: 1.7135388851165771
Validation loss: 1.889738098267586

Epoch: 5| Step: 9
Training loss: 1.1341493129730225
Validation loss: 1.9196323451175485

Epoch: 5| Step: 10
Training loss: 1.450977087020874
Validation loss: 1.8985580577645251

Epoch: 294| Step: 0
Training loss: 1.5387861728668213
Validation loss: 1.9021661640495382

Epoch: 5| Step: 1
Training loss: 2.070552110671997
Validation loss: 1.9150274517715618

Epoch: 5| Step: 2
Training loss: 1.5528759956359863
Validation loss: 1.9307445236431655

Epoch: 5| Step: 3
Training loss: 1.0711400508880615
Validation loss: 1.9221217068292762

Epoch: 5| Step: 4
Training loss: 2.1339499950408936
Validation loss: 1.9354762659277966

Epoch: 5| Step: 5
Training loss: 2.1097412109375
Validation loss: 1.924718867066086

Epoch: 5| Step: 6
Training loss: 1.2297422885894775
Validation loss: 1.9356102674238143

Epoch: 5| Step: 7
Training loss: 1.6965736150741577
Validation loss: 1.9081622298045824

Epoch: 5| Step: 8
Training loss: 2.0157370567321777
Validation loss: 1.9115798037539247

Epoch: 5| Step: 9
Training loss: 1.7967236042022705
Validation loss: 1.9095362027486165

Epoch: 5| Step: 10
Training loss: 0.9985659122467041
Validation loss: 1.917866429974956

Epoch: 295| Step: 0
Training loss: 1.7857192754745483
Validation loss: 1.943019082469325

Epoch: 5| Step: 1
Training loss: 1.1925286054611206
Validation loss: 1.9022561016903128

Epoch: 5| Step: 2
Training loss: 1.5466808080673218
Validation loss: 1.8679022737728652

Epoch: 5| Step: 3
Training loss: 1.169128656387329
Validation loss: 1.8911057351737894

Epoch: 5| Step: 4
Training loss: 1.3664121627807617
Validation loss: 1.8907376925150554

Epoch: 5| Step: 5
Training loss: 1.8162578344345093
Validation loss: 1.8839040520370647

Epoch: 5| Step: 6
Training loss: 1.8885676860809326
Validation loss: 1.9087235350762644

Epoch: 5| Step: 7
Training loss: 1.9205700159072876
Validation loss: 1.9349481367295789

Epoch: 5| Step: 8
Training loss: 1.4868710041046143
Validation loss: 1.8666491816120763

Epoch: 5| Step: 9
Training loss: 1.9200502634048462
Validation loss: 1.9110458512460031

Epoch: 5| Step: 10
Training loss: 1.861242413520813
Validation loss: 1.8876075770265313

Epoch: 296| Step: 0
Training loss: 1.2696162462234497
Validation loss: 1.9613561399521366

Epoch: 5| Step: 1
Training loss: 2.121922016143799
Validation loss: 1.906608812270626

Epoch: 5| Step: 2
Training loss: 1.6088460683822632
Validation loss: 1.917145703428535

Epoch: 5| Step: 3
Training loss: 1.5199452638626099
Validation loss: 1.8705147338169876

Epoch: 5| Step: 4
Training loss: 1.6312980651855469
Validation loss: 1.953081469382009

Epoch: 5| Step: 5
Training loss: 1.4701324701309204
Validation loss: 1.9205142016051917

Epoch: 5| Step: 6
Training loss: 1.3840415477752686
Validation loss: 1.9257839597681516

Epoch: 5| Step: 7
Training loss: 1.5073201656341553
Validation loss: 1.902287039705502

Epoch: 5| Step: 8
Training loss: 2.0589537620544434
Validation loss: 1.9283062834893503

Epoch: 5| Step: 9
Training loss: 1.9339109659194946
Validation loss: 1.9038362400506132

Epoch: 5| Step: 10
Training loss: 1.7243443727493286
Validation loss: 1.9165618419647217

Epoch: 297| Step: 0
Training loss: 1.172562837600708
Validation loss: 1.8939180938146447

Epoch: 5| Step: 1
Training loss: 1.818193793296814
Validation loss: 1.8942018144874162

Epoch: 5| Step: 2
Training loss: 1.4639921188354492
Validation loss: 1.901498822755711

Epoch: 5| Step: 3
Training loss: 1.8569742441177368
Validation loss: 1.8813283161450458

Epoch: 5| Step: 4
Training loss: 1.2694693803787231
Validation loss: 1.8817445475568053

Epoch: 5| Step: 5
Training loss: 1.839739441871643
Validation loss: 1.8853425454067927

Epoch: 5| Step: 6
Training loss: 1.6982707977294922
Validation loss: 1.8668397152295677

Epoch: 5| Step: 7
Training loss: 1.667954444885254
Validation loss: 1.9126056855724705

Epoch: 5| Step: 8
Training loss: 1.9948288202285767
Validation loss: 1.908004468487155

Epoch: 5| Step: 9
Training loss: 2.0065791606903076
Validation loss: 1.9112002772669638

Epoch: 5| Step: 10
Training loss: 1.6190462112426758
Validation loss: 1.9095665882992487

Epoch: 298| Step: 0
Training loss: 1.68710458278656
Validation loss: 1.904205173574468

Epoch: 5| Step: 1
Training loss: 1.4280894994735718
Validation loss: 1.9181871042456677

Epoch: 5| Step: 2
Training loss: 1.7755346298217773
Validation loss: 1.9234830076976488

Epoch: 5| Step: 3
Training loss: 1.8405317068099976
Validation loss: 1.9089184653374456

Epoch: 5| Step: 4
Training loss: 1.8569778203964233
Validation loss: 1.9265741186757241

Epoch: 5| Step: 5
Training loss: 1.244626522064209
Validation loss: 1.9200532513280069

Epoch: 5| Step: 6
Training loss: 2.01157808303833
Validation loss: 1.9567834895144227

Epoch: 5| Step: 7
Training loss: 1.267417311668396
Validation loss: 1.9383122946626397

Epoch: 5| Step: 8
Training loss: 1.3718061447143555
Validation loss: 1.9190290653577415

Epoch: 5| Step: 9
Training loss: 1.643202543258667
Validation loss: 1.9169485030635711

Epoch: 5| Step: 10
Training loss: 2.1610379219055176
Validation loss: 1.9129700532523535

Epoch: 299| Step: 0
Training loss: 1.7644615173339844
Validation loss: 1.9502312521780691

Epoch: 5| Step: 1
Training loss: 1.7355701923370361
Validation loss: 1.9065387761721047

Epoch: 5| Step: 2
Training loss: 1.4108428955078125
Validation loss: 1.9022444089253743

Epoch: 5| Step: 3
Training loss: 2.0430216789245605
Validation loss: 1.907247877890064

Epoch: 5| Step: 4
Training loss: 1.2049939632415771
Validation loss: 1.9277358567842873

Epoch: 5| Step: 5
Training loss: 1.8208249807357788
Validation loss: 1.8871350890846663

Epoch: 5| Step: 6
Training loss: 1.4671094417572021
Validation loss: 1.923564895506828

Epoch: 5| Step: 7
Training loss: 1.5984569787979126
Validation loss: 1.9277880832713137

Epoch: 5| Step: 8
Training loss: 1.5505973100662231
Validation loss: 1.899851324737713

Epoch: 5| Step: 9
Training loss: 1.7130296230316162
Validation loss: 1.9262299537658691

Epoch: 5| Step: 10
Training loss: 1.9915295839309692
Validation loss: 1.9242909454530286

Epoch: 300| Step: 0
Training loss: 1.733492136001587
Validation loss: 1.9088208175474597

Epoch: 5| Step: 1
Training loss: 1.7840073108673096
Validation loss: 1.9171571846931212

Epoch: 5| Step: 2
Training loss: 2.609111785888672
Validation loss: 1.9103847703626078

Epoch: 5| Step: 3
Training loss: 1.4485785961151123
Validation loss: 1.9010641549223213

Epoch: 5| Step: 4
Training loss: 1.413252353668213
Validation loss: 1.8821349297800372

Epoch: 5| Step: 5
Training loss: 1.658328652381897
Validation loss: 1.918179754287966

Epoch: 5| Step: 6
Training loss: 1.5780020952224731
Validation loss: 1.8807252812129196

Epoch: 5| Step: 7
Training loss: 1.4629833698272705
Validation loss: 1.9074808038691038

Epoch: 5| Step: 8
Training loss: 1.2396795749664307
Validation loss: 1.9321060770301408

Epoch: 5| Step: 9
Training loss: 1.8258222341537476
Validation loss: 1.9285235815150763

Epoch: 5| Step: 10
Training loss: 1.4663348197937012
Validation loss: 1.9257000979556833

Epoch: 301| Step: 0
Training loss: 1.3982700109481812
Validation loss: 1.9193991461107809

Epoch: 5| Step: 1
Training loss: 1.3580151796340942
Validation loss: 1.9303884352407148

Epoch: 5| Step: 2
Training loss: 1.4242074489593506
Validation loss: 1.9158601414772771

Epoch: 5| Step: 3
Training loss: 2.00376033782959
Validation loss: 1.92521757207891

Epoch: 5| Step: 4
Training loss: 1.5471889972686768
Validation loss: 1.9420696637963737

Epoch: 5| Step: 5
Training loss: 2.033254623413086
Validation loss: 1.9300648563651628

Epoch: 5| Step: 6
Training loss: 1.4846481084823608
Validation loss: 1.9394343450505247

Epoch: 5| Step: 7
Training loss: 1.865450143814087
Validation loss: 1.9318097252999582

Epoch: 5| Step: 8
Training loss: 1.5868291854858398
Validation loss: 1.9178121089935303

Epoch: 5| Step: 9
Training loss: 1.8446521759033203
Validation loss: 1.8961841393542547

Epoch: 5| Step: 10
Training loss: 1.5038572549819946
Validation loss: 1.8981077260868524

Epoch: 302| Step: 0
Training loss: 0.8757209777832031
Validation loss: 1.9213215189595376

Epoch: 5| Step: 1
Training loss: 1.3089791536331177
Validation loss: 1.86612109855939

Epoch: 5| Step: 2
Training loss: 1.6239534616470337
Validation loss: 1.9110473548212359

Epoch: 5| Step: 3
Training loss: 1.5678884983062744
Validation loss: 1.9197107002299318

Epoch: 5| Step: 4
Training loss: 2.222177028656006
Validation loss: 1.9333795450067008

Epoch: 5| Step: 5
Training loss: 1.460142970085144
Validation loss: 1.914446086011907

Epoch: 5| Step: 6
Training loss: 1.5602004528045654
Validation loss: 1.8902584250255297

Epoch: 5| Step: 7
Training loss: 2.196129322052002
Validation loss: 1.9360030146055325

Epoch: 5| Step: 8
Training loss: 1.7944316864013672
Validation loss: 1.9048515635152017

Epoch: 5| Step: 9
Training loss: 1.6499837636947632
Validation loss: 1.9215847343526862

Epoch: 5| Step: 10
Training loss: 1.9076024293899536
Validation loss: 1.9198366211306663

Epoch: 303| Step: 0
Training loss: 2.112104892730713
Validation loss: 1.9202366093153596

Epoch: 5| Step: 1
Training loss: 1.6042248010635376
Validation loss: 1.9240653412316435

Epoch: 5| Step: 2
Training loss: 1.4385154247283936
Validation loss: 1.9552276134490967

Epoch: 5| Step: 3
Training loss: 1.6088926792144775
Validation loss: 1.9510187846358105

Epoch: 5| Step: 4
Training loss: 1.4997103214263916
Validation loss: 1.972697663050826

Epoch: 5| Step: 5
Training loss: 1.5638617277145386
Validation loss: 1.9435277715806039

Epoch: 5| Step: 6
Training loss: 1.5175164937973022
Validation loss: 1.9574134170368154

Epoch: 5| Step: 7
Training loss: 2.179574489593506
Validation loss: 1.9322774128247333

Epoch: 5| Step: 8
Training loss: 2.2794418334960938
Validation loss: 1.993843586214127

Epoch: 5| Step: 9
Training loss: 1.1194982528686523
Validation loss: 1.952663593394782

Epoch: 5| Step: 10
Training loss: 1.51842200756073
Validation loss: 1.9367234194150535

Epoch: 304| Step: 0
Training loss: 1.6878643035888672
Validation loss: 1.9481345094660276

Epoch: 5| Step: 1
Training loss: 1.6039623022079468
Validation loss: 1.9054893973053142

Epoch: 5| Step: 2
Training loss: 1.4703563451766968
Validation loss: 1.8946521641105734

Epoch: 5| Step: 3
Training loss: 1.7041763067245483
Validation loss: 1.9104138010291642

Epoch: 5| Step: 4
Training loss: 2.044124126434326
Validation loss: 1.9423378270159486

Epoch: 5| Step: 5
Training loss: 1.45558762550354
Validation loss: 1.9154691516712148

Epoch: 5| Step: 6
Training loss: 1.5631284713745117
Validation loss: 1.9104106092965731

Epoch: 5| Step: 7
Training loss: 1.8052361011505127
Validation loss: 1.9237764138047413

Epoch: 5| Step: 8
Training loss: 1.1318918466567993
Validation loss: 1.9353291065462175

Epoch: 5| Step: 9
Training loss: 1.8343613147735596
Validation loss: 1.903125879585102

Epoch: 5| Step: 10
Training loss: 1.6590490341186523
Validation loss: 1.882717086422828

Epoch: 305| Step: 0
Training loss: 1.0994964838027954
Validation loss: 1.915744476420905

Epoch: 5| Step: 1
Training loss: 1.3772815465927124
Validation loss: 1.910392112629388

Epoch: 5| Step: 2
Training loss: 1.6236175298690796
Validation loss: 1.920557645700311

Epoch: 5| Step: 3
Training loss: 1.4886239767074585
Validation loss: 1.8890627199603665

Epoch: 5| Step: 4
Training loss: 2.473724842071533
Validation loss: 1.890449813617173

Epoch: 5| Step: 5
Training loss: 1.9463388919830322
Validation loss: 1.9110113446430494

Epoch: 5| Step: 6
Training loss: 1.5889856815338135
Validation loss: 1.9106298685073853

Epoch: 5| Step: 7
Training loss: 1.7705047130584717
Validation loss: 1.8800448986791796

Epoch: 5| Step: 8
Training loss: 1.4378901720046997
Validation loss: 1.8937769859067854

Epoch: 5| Step: 9
Training loss: 1.6300948858261108
Validation loss: 1.906243872898881

Epoch: 5| Step: 10
Training loss: 1.4859395027160645
Validation loss: 1.9087875235465266

Epoch: 306| Step: 0
Training loss: 1.5137050151824951
Validation loss: 1.8855338686255998

Epoch: 5| Step: 1
Training loss: 1.3428462743759155
Validation loss: 1.9464135503256192

Epoch: 5| Step: 2
Training loss: 1.3261820077896118
Validation loss: 1.9394219280571066

Epoch: 5| Step: 3
Training loss: 1.7795002460479736
Validation loss: 1.9214934020914056

Epoch: 5| Step: 4
Training loss: 1.5910836458206177
Validation loss: 1.900395336971488

Epoch: 5| Step: 5
Training loss: 2.240051746368408
Validation loss: 1.9086579879124959

Epoch: 5| Step: 6
Training loss: 1.2685900926589966
Validation loss: 1.9067988113690448

Epoch: 5| Step: 7
Training loss: 1.635845422744751
Validation loss: 1.9018621406247538

Epoch: 5| Step: 8
Training loss: 1.4373544454574585
Validation loss: 1.888251022625995

Epoch: 5| Step: 9
Training loss: 1.7779254913330078
Validation loss: 1.9108827062832412

Epoch: 5| Step: 10
Training loss: 2.011688470840454
Validation loss: 1.892443162138744

Epoch: 307| Step: 0
Training loss: 1.4767086505889893
Validation loss: 1.8902617808311217

Epoch: 5| Step: 1
Training loss: 1.3868372440338135
Validation loss: 1.9209478760278353

Epoch: 5| Step: 2
Training loss: 1.6852178573608398
Validation loss: 1.9141641842421664

Epoch: 5| Step: 3
Training loss: 1.647324562072754
Validation loss: 1.8546428859874766

Epoch: 5| Step: 4
Training loss: 1.4260435104370117
Validation loss: 1.885759279933027

Epoch: 5| Step: 5
Training loss: 1.5073078870773315
Validation loss: 1.9239715401844313

Epoch: 5| Step: 6
Training loss: 1.8907041549682617
Validation loss: 1.8919429932871172

Epoch: 5| Step: 7
Training loss: 1.5660731792449951
Validation loss: 1.925638307807266

Epoch: 5| Step: 8
Training loss: 2.1380982398986816
Validation loss: 1.9103307172816286

Epoch: 5| Step: 9
Training loss: 1.2620878219604492
Validation loss: 1.926347868416899

Epoch: 5| Step: 10
Training loss: 1.8756589889526367
Validation loss: 1.932532682213732

Epoch: 308| Step: 0
Training loss: 1.439639687538147
Validation loss: 1.9143775560522591

Epoch: 5| Step: 1
Training loss: 1.8184268474578857
Validation loss: 1.8970010588246007

Epoch: 5| Step: 2
Training loss: 1.6916135549545288
Validation loss: 1.914890709743705

Epoch: 5| Step: 3
Training loss: 1.7951266765594482
Validation loss: 1.925539089787391

Epoch: 5| Step: 4
Training loss: 1.5033671855926514
Validation loss: 1.8878041262267737

Epoch: 5| Step: 5
Training loss: 1.7075554132461548
Validation loss: 1.8988108455493886

Epoch: 5| Step: 6
Training loss: 1.3325378894805908
Validation loss: 1.9354384163374543

Epoch: 5| Step: 7
Training loss: 1.4805043935775757
Validation loss: 1.9150699902606267

Epoch: 5| Step: 8
Training loss: 1.137727975845337
Validation loss: 1.8719948927561443

Epoch: 5| Step: 9
Training loss: 2.049696445465088
Validation loss: 1.9039832545864968

Epoch: 5| Step: 10
Training loss: 1.9239048957824707
Validation loss: 1.9127842944155458

Epoch: 309| Step: 0
Training loss: 1.4353386163711548
Validation loss: 1.8762562249296455

Epoch: 5| Step: 1
Training loss: 1.8121674060821533
Validation loss: 1.8956265000886814

Epoch: 5| Step: 2
Training loss: 1.759914755821228
Validation loss: 1.8808453749584895

Epoch: 5| Step: 3
Training loss: 1.341666340827942
Validation loss: 1.907253170526156

Epoch: 5| Step: 4
Training loss: 1.911187767982483
Validation loss: 1.8975790623695619

Epoch: 5| Step: 5
Training loss: 1.6640526056289673
Validation loss: 1.8855046008222847

Epoch: 5| Step: 6
Training loss: 1.256493330001831
Validation loss: 1.887244011766167

Epoch: 5| Step: 7
Training loss: 1.6626842021942139
Validation loss: 1.890794059281708

Epoch: 5| Step: 8
Training loss: 1.6786677837371826
Validation loss: 1.8847670785842403

Epoch: 5| Step: 9
Training loss: 1.5379666090011597
Validation loss: 1.9336804523262927

Epoch: 5| Step: 10
Training loss: 1.8846229314804077
Validation loss: 1.8887622125687138

Epoch: 310| Step: 0
Training loss: 1.3748348951339722
Validation loss: 1.8881924588193175

Epoch: 5| Step: 1
Training loss: 1.551379680633545
Validation loss: 1.908836756983111

Epoch: 5| Step: 2
Training loss: 1.7973304986953735
Validation loss: 1.8864234480806576

Epoch: 5| Step: 3
Training loss: 1.4830814599990845
Validation loss: 1.9175445354113014

Epoch: 5| Step: 4
Training loss: 1.7663230895996094
Validation loss: 1.9215831948864845

Epoch: 5| Step: 5
Training loss: 1.7175776958465576
Validation loss: 1.931265382356541

Epoch: 5| Step: 6
Training loss: 1.4956644773483276
Validation loss: 1.9208653408993956

Epoch: 5| Step: 7
Training loss: 2.1053996086120605
Validation loss: 1.9257872591736496

Epoch: 5| Step: 8
Training loss: 1.2669246196746826
Validation loss: 1.933563974595839

Epoch: 5| Step: 9
Training loss: 1.4360380172729492
Validation loss: 1.9442933669654272

Epoch: 5| Step: 10
Training loss: 1.6975654363632202
Validation loss: 1.9255832805428454

Epoch: 311| Step: 0
Training loss: 1.5302876234054565
Validation loss: 1.884916675988064

Epoch: 5| Step: 1
Training loss: 1.6797382831573486
Validation loss: 1.9239068082583848

Epoch: 5| Step: 2
Training loss: 1.916499376296997
Validation loss: 1.9141452120196434

Epoch: 5| Step: 3
Training loss: 1.538447618484497
Validation loss: 1.939106983523215

Epoch: 5| Step: 4
Training loss: 1.280159592628479
Validation loss: 1.9098455367549774

Epoch: 5| Step: 5
Training loss: 1.4538227319717407
Validation loss: 1.9185682727444557

Epoch: 5| Step: 6
Training loss: 1.5911078453063965
Validation loss: 1.8835314909617107

Epoch: 5| Step: 7
Training loss: 1.730290174484253
Validation loss: 1.9277237512732064

Epoch: 5| Step: 8
Training loss: 1.883587121963501
Validation loss: 1.922816571368966

Epoch: 5| Step: 9
Training loss: 1.2592298984527588
Validation loss: 1.9104549320795203

Epoch: 5| Step: 10
Training loss: 2.3148229122161865
Validation loss: 1.8884175157034269

Epoch: 312| Step: 0
Training loss: 1.3224537372589111
Validation loss: 1.8681140997076546

Epoch: 5| Step: 1
Training loss: 1.6058731079101562
Validation loss: 1.902173649880194

Epoch: 5| Step: 2
Training loss: 1.6330770254135132
Validation loss: 1.8683595657348633

Epoch: 5| Step: 3
Training loss: 1.836891770362854
Validation loss: 1.8659732931403703

Epoch: 5| Step: 4
Training loss: 1.474583625793457
Validation loss: 1.8792098094058294

Epoch: 5| Step: 5
Training loss: 1.1181734800338745
Validation loss: 1.912045778766755

Epoch: 5| Step: 6
Training loss: 2.6231000423431396
Validation loss: 1.8756192794410131

Epoch: 5| Step: 7
Training loss: 1.3500821590423584
Validation loss: 1.8852434876144573

Epoch: 5| Step: 8
Training loss: 1.6346852779388428
Validation loss: 1.9088314169196672

Epoch: 5| Step: 9
Training loss: 1.4010307788848877
Validation loss: 1.9009998870152298

Epoch: 5| Step: 10
Training loss: 1.7882347106933594
Validation loss: 1.9285611042412378

Epoch: 313| Step: 0
Training loss: 1.681402564048767
Validation loss: 1.9442408366869854

Epoch: 5| Step: 1
Training loss: 1.7225894927978516
Validation loss: 1.9079006820596673

Epoch: 5| Step: 2
Training loss: 1.564322829246521
Validation loss: 1.9340857254561556

Epoch: 5| Step: 3
Training loss: 1.6104323863983154
Validation loss: 1.902643383190196

Epoch: 5| Step: 4
Training loss: 1.8968040943145752
Validation loss: 1.9088128741069506

Epoch: 5| Step: 5
Training loss: 1.7455469369888306
Validation loss: 1.9447755852053243

Epoch: 5| Step: 6
Training loss: 1.7842658758163452
Validation loss: 1.9052826525062643

Epoch: 5| Step: 7
Training loss: 1.5863268375396729
Validation loss: 1.8908154900356005

Epoch: 5| Step: 8
Training loss: 2.1343135833740234
Validation loss: 1.9164634417462092

Epoch: 5| Step: 9
Training loss: 1.015014886856079
Validation loss: 1.918319930312454

Epoch: 5| Step: 10
Training loss: 0.9778115749359131
Validation loss: 1.8959860878605996

Epoch: 314| Step: 0
Training loss: 1.4755616188049316
Validation loss: 1.9012330462855678

Epoch: 5| Step: 1
Training loss: 0.8273433446884155
Validation loss: 1.9102255695609636

Epoch: 5| Step: 2
Training loss: 1.7207832336425781
Validation loss: 1.9017104256537654

Epoch: 5| Step: 3
Training loss: 1.487837553024292
Validation loss: 1.868554771587413

Epoch: 5| Step: 4
Training loss: 1.4224588871002197
Validation loss: 1.901086571396038

Epoch: 5| Step: 5
Training loss: 1.548395037651062
Validation loss: 1.878213221027005

Epoch: 5| Step: 6
Training loss: 1.565760850906372
Validation loss: 1.8563248790720457

Epoch: 5| Step: 7
Training loss: 1.8842546939849854
Validation loss: 1.8984765993651522

Epoch: 5| Step: 8
Training loss: 2.0836501121520996
Validation loss: 1.9233157339916434

Epoch: 5| Step: 9
Training loss: 1.858933687210083
Validation loss: 1.9219823011787989

Epoch: 5| Step: 10
Training loss: 1.6574572324752808
Validation loss: 1.9434816606583134

Epoch: 315| Step: 0
Training loss: 1.7022969722747803
Validation loss: 1.9299220808090702

Epoch: 5| Step: 1
Training loss: 1.5732810497283936
Validation loss: 1.8928038881671043

Epoch: 5| Step: 2
Training loss: 1.4696743488311768
Validation loss: 1.9127332395122898

Epoch: 5| Step: 3
Training loss: 2.14203143119812
Validation loss: 1.9045879289668093

Epoch: 5| Step: 4
Training loss: 1.6645389795303345
Validation loss: 1.9372445742289226

Epoch: 5| Step: 5
Training loss: 1.3085191249847412
Validation loss: 1.9410127234715286

Epoch: 5| Step: 6
Training loss: 1.222136378288269
Validation loss: 1.9186802628219768

Epoch: 5| Step: 7
Training loss: 1.0644242763519287
Validation loss: 1.8958353534821542

Epoch: 5| Step: 8
Training loss: 2.1143181324005127
Validation loss: 1.9226291205293389

Epoch: 5| Step: 9
Training loss: 1.8140805959701538
Validation loss: 1.9096040059161443

Epoch: 5| Step: 10
Training loss: 1.470768928527832
Validation loss: 1.9339963056707894

Epoch: 316| Step: 0
Training loss: 1.9270490407943726
Validation loss: 1.8625347255378641

Epoch: 5| Step: 1
Training loss: 1.625199317932129
Validation loss: 1.8939510430059125

Epoch: 5| Step: 2
Training loss: 1.6277110576629639
Validation loss: 1.8808679939598165

Epoch: 5| Step: 3
Training loss: 1.7310221195220947
Validation loss: 1.8595189612398866

Epoch: 5| Step: 4
Training loss: 1.6302410364151
Validation loss: 1.8829140355510097

Epoch: 5| Step: 5
Training loss: 1.4863770008087158
Validation loss: 1.8891649989671604

Epoch: 5| Step: 6
Training loss: 1.5309196710586548
Validation loss: 1.8853490980722571

Epoch: 5| Step: 7
Training loss: 1.6609150171279907
Validation loss: 1.8993441815017371

Epoch: 5| Step: 8
Training loss: 1.7503855228424072
Validation loss: 1.8816108742067892

Epoch: 5| Step: 9
Training loss: 1.3283746242523193
Validation loss: 1.9211901413497103

Epoch: 5| Step: 10
Training loss: 1.408797025680542
Validation loss: 1.9532122996545607

Epoch: 317| Step: 0
Training loss: 1.607526183128357
Validation loss: 1.8921868044842955

Epoch: 5| Step: 1
Training loss: 0.7236475348472595
Validation loss: 1.9315669331499326

Epoch: 5| Step: 2
Training loss: 1.7133111953735352
Validation loss: 1.8925932466342885

Epoch: 5| Step: 3
Training loss: 1.4411067962646484
Validation loss: 1.9144440863722114

Epoch: 5| Step: 4
Training loss: 1.2325313091278076
Validation loss: 1.9417919689609158

Epoch: 5| Step: 5
Training loss: 2.0623178482055664
Validation loss: 1.9231396528982347

Epoch: 5| Step: 6
Training loss: 1.9138339757919312
Validation loss: 1.9003006424955142

Epoch: 5| Step: 7
Training loss: 1.549615740776062
Validation loss: 1.911099536444551

Epoch: 5| Step: 8
Training loss: 2.376925230026245
Validation loss: 1.9205075938214538

Epoch: 5| Step: 9
Training loss: 1.427841305732727
Validation loss: 1.9173981605037567

Epoch: 5| Step: 10
Training loss: 1.4399802684783936
Validation loss: 1.962313340556237

Epoch: 318| Step: 0
Training loss: 1.0316886901855469
Validation loss: 1.904875696346324

Epoch: 5| Step: 1
Training loss: 1.6739848852157593
Validation loss: 1.8925532615312965

Epoch: 5| Step: 2
Training loss: 2.0869193077087402
Validation loss: 1.8990834143853956

Epoch: 5| Step: 3
Training loss: 1.9057708978652954
Validation loss: 1.9157375469002673

Epoch: 5| Step: 4
Training loss: 1.3081064224243164
Validation loss: 1.915922785318026

Epoch: 5| Step: 5
Training loss: 1.5255768299102783
Validation loss: 1.8831290339910856

Epoch: 5| Step: 6
Training loss: 1.2373483180999756
Validation loss: 1.8924686806176299

Epoch: 5| Step: 7
Training loss: 2.3664474487304688
Validation loss: 1.8740656888613136

Epoch: 5| Step: 8
Training loss: 1.4556668996810913
Validation loss: 1.9000743768548454

Epoch: 5| Step: 9
Training loss: 1.676953911781311
Validation loss: 1.8412108664871545

Epoch: 5| Step: 10
Training loss: 1.3715484142303467
Validation loss: 1.8887129804139495

Epoch: 319| Step: 0
Training loss: 1.587761640548706
Validation loss: 1.88802973557544

Epoch: 5| Step: 1
Training loss: 2.2001121044158936
Validation loss: 1.9015146942548855

Epoch: 5| Step: 2
Training loss: 1.8136097192764282
Validation loss: 1.9008738392142839

Epoch: 5| Step: 3
Training loss: 1.222468614578247
Validation loss: 1.8741234451211908

Epoch: 5| Step: 4
Training loss: 1.2700437307357788
Validation loss: 1.9049104029132473

Epoch: 5| Step: 5
Training loss: 1.679534912109375
Validation loss: 1.8962832368830198

Epoch: 5| Step: 6
Training loss: 1.2937312126159668
Validation loss: 1.8798451859463927

Epoch: 5| Step: 7
Training loss: 1.46953547000885
Validation loss: 1.9070460373355496

Epoch: 5| Step: 8
Training loss: 1.4972442388534546
Validation loss: 1.9285188797981507

Epoch: 5| Step: 9
Training loss: 1.4982978105545044
Validation loss: 1.8818235294793242

Epoch: 5| Step: 10
Training loss: 1.8876261711120605
Validation loss: 1.9100592572201964

Epoch: 320| Step: 0
Training loss: 1.4046176671981812
Validation loss: 1.9375001845821258

Epoch: 5| Step: 1
Training loss: 1.7179594039916992
Validation loss: 1.921479079031175

Epoch: 5| Step: 2
Training loss: 1.6516988277435303
Validation loss: 1.9081812391998947

Epoch: 5| Step: 3
Training loss: 1.5568058490753174
Validation loss: 1.9428124812341505

Epoch: 5| Step: 4
Training loss: 1.7260663509368896
Validation loss: 1.9028676812366774

Epoch: 5| Step: 5
Training loss: 1.2499397993087769
Validation loss: 1.9327916470907067

Epoch: 5| Step: 6
Training loss: 1.3650084733963013
Validation loss: 1.8887269189280849

Epoch: 5| Step: 7
Training loss: 1.4931613206863403
Validation loss: 1.8882156725852721

Epoch: 5| Step: 8
Training loss: 1.8881511688232422
Validation loss: 1.906133396651155

Epoch: 5| Step: 9
Training loss: 2.0084145069122314
Validation loss: 1.8784108136289863

Epoch: 5| Step: 10
Training loss: 1.4650248289108276
Validation loss: 1.87690524132021

Epoch: 321| Step: 0
Training loss: 1.2694289684295654
Validation loss: 1.87262693015478

Epoch: 5| Step: 1
Training loss: 2.0470893383026123
Validation loss: 1.8797565044895295

Epoch: 5| Step: 2
Training loss: 1.2167177200317383
Validation loss: 1.90191823820914

Epoch: 5| Step: 3
Training loss: 1.625872015953064
Validation loss: 1.87387861487686

Epoch: 5| Step: 4
Training loss: 1.9238771200180054
Validation loss: 1.919343194653911

Epoch: 5| Step: 5
Training loss: 1.3303872346878052
Validation loss: 1.9098765324520808

Epoch: 5| Step: 6
Training loss: 1.392107605934143
Validation loss: 1.8872017052865797

Epoch: 5| Step: 7
Training loss: 1.4634987115859985
Validation loss: 1.899503871958743

Epoch: 5| Step: 8
Training loss: 1.8744544982910156
Validation loss: 1.8758601296332575

Epoch: 5| Step: 9
Training loss: 1.7219445705413818
Validation loss: 1.8918901476808774

Epoch: 5| Step: 10
Training loss: 1.191313624382019
Validation loss: 1.8852889589084092

Epoch: 322| Step: 0
Training loss: 1.1712709665298462
Validation loss: 1.884815800574518

Epoch: 5| Step: 1
Training loss: 2.0164215564727783
Validation loss: 1.8809897668900029

Epoch: 5| Step: 2
Training loss: 1.7635024785995483
Validation loss: 1.9066902501608736

Epoch: 5| Step: 3
Training loss: 1.9139124155044556
Validation loss: 1.907774556067682

Epoch: 5| Step: 4
Training loss: 1.4702582359313965
Validation loss: 1.9143489624864312

Epoch: 5| Step: 5
Training loss: 1.8243920803070068
Validation loss: 1.9121862752463228

Epoch: 5| Step: 6
Training loss: 1.3293473720550537
Validation loss: 1.8655275555067166

Epoch: 5| Step: 7
Training loss: 1.4560014009475708
Validation loss: 1.9413954416910808

Epoch: 5| Step: 8
Training loss: 1.669466257095337
Validation loss: 1.89720655000338

Epoch: 5| Step: 9
Training loss: 1.5472793579101562
Validation loss: 1.9007018253367434

Epoch: 5| Step: 10
Training loss: 1.254368782043457
Validation loss: 1.9408912812509844

Epoch: 323| Step: 0
Training loss: 1.3079732656478882
Validation loss: 1.9056667179189704

Epoch: 5| Step: 1
Training loss: 1.9192854166030884
Validation loss: 1.9354931000740296

Epoch: 5| Step: 2
Training loss: 1.9358551502227783
Validation loss: 1.8624071100706696

Epoch: 5| Step: 3
Training loss: 2.2549941539764404
Validation loss: 1.9285384403761996

Epoch: 5| Step: 4
Training loss: 1.7884418964385986
Validation loss: 1.9064028365637666

Epoch: 5| Step: 5
Training loss: 1.707598328590393
Validation loss: 1.9429788140840427

Epoch: 5| Step: 6
Training loss: 0.8594338297843933
Validation loss: 1.8626374185726207

Epoch: 5| Step: 7
Training loss: 1.3181880712509155
Validation loss: 1.9108297299313288

Epoch: 5| Step: 8
Training loss: 1.9075769186019897
Validation loss: 1.9108393358927902

Epoch: 5| Step: 9
Training loss: 0.9903379678726196
Validation loss: 1.8996914702077066

Epoch: 5| Step: 10
Training loss: 1.4758743047714233
Validation loss: 1.833236832772532

Epoch: 324| Step: 0
Training loss: 1.4481422901153564
Validation loss: 1.8801750777870097

Epoch: 5| Step: 1
Training loss: 2.294879198074341
Validation loss: 1.8926093219428934

Epoch: 5| Step: 2
Training loss: 1.5160681009292603
Validation loss: 1.8890420903441727

Epoch: 5| Step: 3
Training loss: 0.9810761213302612
Validation loss: 1.9296635261145971

Epoch: 5| Step: 4
Training loss: 1.2351016998291016
Validation loss: 1.8877131451842606

Epoch: 5| Step: 5
Training loss: 1.8464676141738892
Validation loss: 1.8852044356766569

Epoch: 5| Step: 6
Training loss: 1.1953471899032593
Validation loss: 1.8918156559749315

Epoch: 5| Step: 7
Training loss: 2.463967800140381
Validation loss: 1.935771188428325

Epoch: 5| Step: 8
Training loss: 1.303091287612915
Validation loss: 1.937980382673202

Epoch: 5| Step: 9
Training loss: 1.7509056329727173
Validation loss: 1.9192928203972437

Epoch: 5| Step: 10
Training loss: 1.4576642513275146
Validation loss: 1.886290842486966

Epoch: 325| Step: 0
Training loss: 1.1041723489761353
Validation loss: 1.884622968653197

Epoch: 5| Step: 1
Training loss: 2.0258243083953857
Validation loss: 1.8795219570077875

Epoch: 5| Step: 2
Training loss: 1.337809681892395
Validation loss: 1.8868403896208732

Epoch: 5| Step: 3
Training loss: 1.379702091217041
Validation loss: 1.8992690629856561

Epoch: 5| Step: 4
Training loss: 1.765031099319458
Validation loss: 1.929769605718633

Epoch: 5| Step: 5
Training loss: 1.4400814771652222
Validation loss: 1.8551969182106756

Epoch: 5| Step: 6
Training loss: 1.5605517625808716
Validation loss: 1.8999684690147318

Epoch: 5| Step: 7
Training loss: 1.4160716533660889
Validation loss: 1.8980866196335002

Epoch: 5| Step: 8
Training loss: 1.4240381717681885
Validation loss: 1.8398288270478607

Epoch: 5| Step: 9
Training loss: 2.0873923301696777
Validation loss: 1.8708009796757852

Epoch: 5| Step: 10
Training loss: 1.660069227218628
Validation loss: 1.8985651872491325

Epoch: 326| Step: 0
Training loss: 1.1665608882904053
Validation loss: 1.872836059139621

Epoch: 5| Step: 1
Training loss: 1.1297008991241455
Validation loss: 1.8718624320081485

Epoch: 5| Step: 2
Training loss: 1.976538062095642
Validation loss: 1.9152595125218874

Epoch: 5| Step: 3
Training loss: 1.5384178161621094
Validation loss: 1.9459860837587746

Epoch: 5| Step: 4
Training loss: 1.7968868017196655
Validation loss: 1.9196718867107103

Epoch: 5| Step: 5
Training loss: 1.1576015949249268
Validation loss: 1.8999637788341892

Epoch: 5| Step: 6
Training loss: 2.165527582168579
Validation loss: 1.9342441084564372

Epoch: 5| Step: 7
Training loss: 1.3894710540771484
Validation loss: 1.8807286703458397

Epoch: 5| Step: 8
Training loss: 1.3824013471603394
Validation loss: 1.898024664130262

Epoch: 5| Step: 9
Training loss: 2.1073460578918457
Validation loss: 1.8862073421478271

Epoch: 5| Step: 10
Training loss: 1.4260365962982178
Validation loss: 1.872467356343423

Epoch: 327| Step: 0
Training loss: 1.0514577627182007
Validation loss: 1.8827177170784242

Epoch: 5| Step: 1
Training loss: 0.9765167236328125
Validation loss: 1.8891293964078348

Epoch: 5| Step: 2
Training loss: 1.4674866199493408
Validation loss: 1.9277720579537012

Epoch: 5| Step: 3
Training loss: 1.4759808778762817
Validation loss: 1.89962940062246

Epoch: 5| Step: 4
Training loss: 1.2668609619140625
Validation loss: 1.9026586099337506

Epoch: 5| Step: 5
Training loss: 1.5806347131729126
Validation loss: 1.885402512806718

Epoch: 5| Step: 6
Training loss: 1.3061285018920898
Validation loss: 1.8872550341390795

Epoch: 5| Step: 7
Training loss: 2.2250351905822754
Validation loss: 1.8999537434629215

Epoch: 5| Step: 8
Training loss: 1.3779544830322266
Validation loss: 1.9224881818217616

Epoch: 5| Step: 9
Training loss: 2.1467556953430176
Validation loss: 1.915695531393892

Epoch: 5| Step: 10
Training loss: 2.5093016624450684
Validation loss: 1.9336150141172512

Epoch: 328| Step: 0
Training loss: 1.744543433189392
Validation loss: 1.8799718092846613

Epoch: 5| Step: 1
Training loss: 1.3372631072998047
Validation loss: 1.895648846062281

Epoch: 5| Step: 2
Training loss: 1.3175899982452393
Validation loss: 1.9091844327988163

Epoch: 5| Step: 3
Training loss: 1.4531198740005493
Validation loss: 1.923778167334936

Epoch: 5| Step: 4
Training loss: 1.7588106393814087
Validation loss: 1.908192616637035

Epoch: 5| Step: 5
Training loss: 2.3010172843933105
Validation loss: 1.8815345110431794

Epoch: 5| Step: 6
Training loss: 1.237654209136963
Validation loss: 1.8803098419661164

Epoch: 5| Step: 7
Training loss: 1.0741081237792969
Validation loss: 1.9286469721025037

Epoch: 5| Step: 8
Training loss: 1.4756685495376587
Validation loss: 1.9267341013877624

Epoch: 5| Step: 9
Training loss: 1.641645073890686
Validation loss: 1.9044386212543776

Epoch: 5| Step: 10
Training loss: 1.9045863151550293
Validation loss: 1.915390379967228

Epoch: 329| Step: 0
Training loss: 1.0865397453308105
Validation loss: 1.8810031798578077

Epoch: 5| Step: 1
Training loss: 1.7890465259552002
Validation loss: 1.8818130672618907

Epoch: 5| Step: 2
Training loss: 1.560052752494812
Validation loss: 1.9052876400691208

Epoch: 5| Step: 3
Training loss: 2.1588964462280273
Validation loss: 1.9017549791643698

Epoch: 5| Step: 4
Training loss: 1.2005250453948975
Validation loss: 1.8970794126551638

Epoch: 5| Step: 5
Training loss: 1.6888154745101929
Validation loss: 1.9193767245097826

Epoch: 5| Step: 6
Training loss: 2.1773476600646973
Validation loss: 1.8959262678700108

Epoch: 5| Step: 7
Training loss: 1.0191023349761963
Validation loss: 1.8424860226210726

Epoch: 5| Step: 8
Training loss: 1.6623060703277588
Validation loss: 1.9082073921798377

Epoch: 5| Step: 9
Training loss: 1.5960710048675537
Validation loss: 1.922130783398946

Epoch: 5| Step: 10
Training loss: 1.1252774000167847
Validation loss: 1.9420768599356375

Epoch: 330| Step: 0
Training loss: 1.7453601360321045
Validation loss: 1.9076084642000095

Epoch: 5| Step: 1
Training loss: 1.9823347330093384
Validation loss: 1.8927181125969015

Epoch: 5| Step: 2
Training loss: 1.8315188884735107
Validation loss: 1.9062842784389373

Epoch: 5| Step: 3
Training loss: 1.6643680334091187
Validation loss: 1.882851848038294

Epoch: 5| Step: 4
Training loss: 1.5269780158996582
Validation loss: 1.9009659264677314

Epoch: 5| Step: 5
Training loss: 1.1927341222763062
Validation loss: 1.9098343400545017

Epoch: 5| Step: 6
Training loss: 1.6646766662597656
Validation loss: 1.8503332599516837

Epoch: 5| Step: 7
Training loss: 1.2378959655761719
Validation loss: 1.9216388822883688

Epoch: 5| Step: 8
Training loss: 1.6124212741851807
Validation loss: 1.9120070780477216

Epoch: 5| Step: 9
Training loss: 1.2600622177124023
Validation loss: 1.9328870055496052

Epoch: 5| Step: 10
Training loss: 1.5180470943450928
Validation loss: 1.9274835637820664

Epoch: 331| Step: 0
Training loss: 1.8112211227416992
Validation loss: 1.8825431280238654

Epoch: 5| Step: 1
Training loss: 1.4267175197601318
Validation loss: 1.8992759681517077

Epoch: 5| Step: 2
Training loss: 1.4896249771118164
Validation loss: 1.855662335631668

Epoch: 5| Step: 3
Training loss: 1.5146310329437256
Validation loss: 1.8727621929619902

Epoch: 5| Step: 4
Training loss: 1.3594404458999634
Validation loss: 1.8587503869046447

Epoch: 5| Step: 5
Training loss: 1.8955729007720947
Validation loss: 1.8889988442902923

Epoch: 5| Step: 6
Training loss: 1.7559293508529663
Validation loss: 1.9114227051376014

Epoch: 5| Step: 7
Training loss: 1.3111244440078735
Validation loss: 1.8730489130943053

Epoch: 5| Step: 8
Training loss: 0.9981054067611694
Validation loss: 1.8678608235492502

Epoch: 5| Step: 9
Training loss: 1.251159429550171
Validation loss: 1.9098134668924476

Epoch: 5| Step: 10
Training loss: 2.067415475845337
Validation loss: 1.899089309477037

Epoch: 332| Step: 0
Training loss: 1.466017246246338
Validation loss: 1.8980742641674575

Epoch: 5| Step: 1
Training loss: 1.3729946613311768
Validation loss: 1.8796079235692178

Epoch: 5| Step: 2
Training loss: 1.3841283321380615
Validation loss: 1.8628729569014681

Epoch: 5| Step: 3
Training loss: 1.5811612606048584
Validation loss: 1.9104045321864467

Epoch: 5| Step: 4
Training loss: 2.31805419921875
Validation loss: 1.8989176199000368

Epoch: 5| Step: 5
Training loss: 1.4699203968048096
Validation loss: 1.9083680055474723

Epoch: 5| Step: 6
Training loss: 1.3606746196746826
Validation loss: 1.8885893488443026

Epoch: 5| Step: 7
Training loss: 1.3747739791870117
Validation loss: 1.9014561458300518

Epoch: 5| Step: 8
Training loss: 1.5325428247451782
Validation loss: 1.8803232805703276

Epoch: 5| Step: 9
Training loss: 1.528313398361206
Validation loss: 1.9396673710115495

Epoch: 5| Step: 10
Training loss: 1.5819895267486572
Validation loss: 1.9051852918440295

Epoch: 333| Step: 0
Training loss: 1.5647839307785034
Validation loss: 1.9400057638845136

Epoch: 5| Step: 1
Training loss: 1.3674085140228271
Validation loss: 1.9113706324690132

Epoch: 5| Step: 2
Training loss: 1.9562965631484985
Validation loss: 1.8846679297826623

Epoch: 5| Step: 3
Training loss: 1.3929256200790405
Validation loss: 1.8975177913583734

Epoch: 5| Step: 4
Training loss: 1.7776445150375366
Validation loss: 1.9216043756854149

Epoch: 5| Step: 5
Training loss: 1.304158329963684
Validation loss: 1.9270862353745328

Epoch: 5| Step: 6
Training loss: 1.253235101699829
Validation loss: 1.884193366573703

Epoch: 5| Step: 7
Training loss: 2.369915008544922
Validation loss: 1.889516657398593

Epoch: 5| Step: 8
Training loss: 1.1015490293502808
Validation loss: 1.9008889249576035

Epoch: 5| Step: 9
Training loss: 1.8161342144012451
Validation loss: 1.9042724024864934

Epoch: 5| Step: 10
Training loss: 1.3166999816894531
Validation loss: 1.9157840974869267

Epoch: 334| Step: 0
Training loss: 2.094595432281494
Validation loss: 1.916050632794698

Epoch: 5| Step: 1
Training loss: 1.5062134265899658
Validation loss: 1.8981323517778868

Epoch: 5| Step: 2
Training loss: 1.7974956035614014
Validation loss: 1.877787354171917

Epoch: 5| Step: 3
Training loss: 1.3646142482757568
Validation loss: 1.8658690247484433

Epoch: 5| Step: 4
Training loss: 2.123077869415283
Validation loss: 1.8838241151584092

Epoch: 5| Step: 5
Training loss: 1.4416797161102295
Validation loss: 1.913263545241407

Epoch: 5| Step: 6
Training loss: 1.1031213998794556
Validation loss: 1.9039495657849055

Epoch: 5| Step: 7
Training loss: 1.110987901687622
Validation loss: 1.9366065763658094

Epoch: 5| Step: 8
Training loss: 1.172996163368225
Validation loss: 1.900615064046716

Epoch: 5| Step: 9
Training loss: 1.785201072692871
Validation loss: 1.8878011588127381

Epoch: 5| Step: 10
Training loss: 1.3205232620239258
Validation loss: 1.910874015541487

Epoch: 335| Step: 0
Training loss: 1.4399864673614502
Validation loss: 1.9362252091848722

Epoch: 5| Step: 1
Training loss: 1.571800708770752
Validation loss: 1.8681592569556287

Epoch: 5| Step: 2
Training loss: 1.368217945098877
Validation loss: 1.8872356722431798

Epoch: 5| Step: 3
Training loss: 1.7258832454681396
Validation loss: 1.8679538747315765

Epoch: 5| Step: 4
Training loss: 1.8887897729873657
Validation loss: 1.884550324050329

Epoch: 5| Step: 5
Training loss: 1.167860746383667
Validation loss: 1.894327199587258

Epoch: 5| Step: 6
Training loss: 1.7727733850479126
Validation loss: 1.8940035937934794

Epoch: 5| Step: 7
Training loss: 1.0061489343643188
Validation loss: 1.9071683806757773

Epoch: 5| Step: 8
Training loss: 1.4823421239852905
Validation loss: 1.8590375172194613

Epoch: 5| Step: 9
Training loss: 2.039778232574463
Validation loss: 1.90646162597082

Epoch: 5| Step: 10
Training loss: 1.5295878648757935
Validation loss: 1.916041669025216

Epoch: 336| Step: 0
Training loss: 1.3057807683944702
Validation loss: 1.8554907896185433

Epoch: 5| Step: 1
Training loss: 1.8028390407562256
Validation loss: 1.9097271350122267

Epoch: 5| Step: 2
Training loss: 1.6144638061523438
Validation loss: 1.8920472155335128

Epoch: 5| Step: 3
Training loss: 0.552811324596405
Validation loss: 1.8889153798421223

Epoch: 5| Step: 4
Training loss: 2.708559513092041
Validation loss: 1.8927792887533865

Epoch: 5| Step: 5
Training loss: 1.4058781862258911
Validation loss: 1.8963722182858376

Epoch: 5| Step: 6
Training loss: 1.2385605573654175
Validation loss: 1.8634084450301303

Epoch: 5| Step: 7
Training loss: 1.2004845142364502
Validation loss: 1.9391788628793531

Epoch: 5| Step: 8
Training loss: 2.2416183948516846
Validation loss: 1.9039274979663152

Epoch: 5| Step: 9
Training loss: 1.2379142045974731
Validation loss: 1.884321612696494

Epoch: 5| Step: 10
Training loss: 1.6763046979904175
Validation loss: 1.9042805574273551

Epoch: 337| Step: 0
Training loss: 0.7370170950889587
Validation loss: 1.8901294277560325

Epoch: 5| Step: 1
Training loss: 1.7442834377288818
Validation loss: 1.8843737238196916

Epoch: 5| Step: 2
Training loss: 1.2769663333892822
Validation loss: 1.890889629240959

Epoch: 5| Step: 3
Training loss: 2.0881690979003906
Validation loss: 1.9326091838139359

Epoch: 5| Step: 4
Training loss: 1.6730362176895142
Validation loss: 1.9033756666286017

Epoch: 5| Step: 5
Training loss: 1.6085879802703857
Validation loss: 1.891322192325387

Epoch: 5| Step: 6
Training loss: 1.628394365310669
Validation loss: 1.8769594007922756

Epoch: 5| Step: 7
Training loss: 1.5040788650512695
Validation loss: 1.8673788962825653

Epoch: 5| Step: 8
Training loss: 1.8725858926773071
Validation loss: 1.891042399150069

Epoch: 5| Step: 9
Training loss: 1.3425076007843018
Validation loss: 1.8876022805449784

Epoch: 5| Step: 10
Training loss: 1.5040218830108643
Validation loss: 1.8591962604112522

Epoch: 338| Step: 0
Training loss: 1.2789446115493774
Validation loss: 1.8510886674286218

Epoch: 5| Step: 1
Training loss: 1.412712812423706
Validation loss: 1.8862481424885411

Epoch: 5| Step: 2
Training loss: 1.5680739879608154
Validation loss: 1.8859500474827264

Epoch: 5| Step: 3
Training loss: 1.7133392095565796
Validation loss: 1.8995540526605421

Epoch: 5| Step: 4
Training loss: 1.4446303844451904
Validation loss: 1.878329174492949

Epoch: 5| Step: 5
Training loss: 1.266535758972168
Validation loss: 1.8828048308690388

Epoch: 5| Step: 6
Training loss: 1.4307072162628174
Validation loss: 1.8948001079661871

Epoch: 5| Step: 7
Training loss: 1.5075924396514893
Validation loss: 1.8917077074768722

Epoch: 5| Step: 8
Training loss: 2.0406830310821533
Validation loss: 1.8936347576879686

Epoch: 5| Step: 9
Training loss: 1.5934770107269287
Validation loss: 1.910996724200505

Epoch: 5| Step: 10
Training loss: 1.824336051940918
Validation loss: 1.8945493441756054

Epoch: 339| Step: 0
Training loss: 1.565256953239441
Validation loss: 1.9056840763297132

Epoch: 5| Step: 1
Training loss: 1.663177251815796
Validation loss: 1.9140475667932981

Epoch: 5| Step: 2
Training loss: 1.2079291343688965
Validation loss: 1.923635975007088

Epoch: 5| Step: 3
Training loss: 1.5874531269073486
Validation loss: 1.8982643273568922

Epoch: 5| Step: 4
Training loss: 1.4887696504592896
Validation loss: 1.9437220660589074

Epoch: 5| Step: 5
Training loss: 1.9000320434570312
Validation loss: 1.9177217483520508

Epoch: 5| Step: 6
Training loss: 1.4559440612792969
Validation loss: 1.9024274682485929

Epoch: 5| Step: 7
Training loss: 1.1584572792053223
Validation loss: 1.9176638754465247

Epoch: 5| Step: 8
Training loss: 1.5026214122772217
Validation loss: 1.9223579206774313

Epoch: 5| Step: 9
Training loss: 1.972153663635254
Validation loss: 1.9009170173316874

Epoch: 5| Step: 10
Training loss: 1.2467190027236938
Validation loss: 1.951324353935898

Epoch: 340| Step: 0
Training loss: 1.1551101207733154
Validation loss: 1.920799377144024

Epoch: 5| Step: 1
Training loss: 1.8489916324615479
Validation loss: 1.8840474082577614

Epoch: 5| Step: 2
Training loss: 1.4898955821990967
Validation loss: 1.9243413350915397

Epoch: 5| Step: 3
Training loss: 1.5611785650253296
Validation loss: 1.8582961738750499

Epoch: 5| Step: 4
Training loss: 1.424323558807373
Validation loss: 1.8699916831908687

Epoch: 5| Step: 5
Training loss: 1.524049162864685
Validation loss: 1.8955236980991979

Epoch: 5| Step: 6
Training loss: 1.123234510421753
Validation loss: 1.8773826886248846

Epoch: 5| Step: 7
Training loss: 1.6125640869140625
Validation loss: 1.8795992328274636

Epoch: 5| Step: 8
Training loss: 2.123922824859619
Validation loss: 1.883423948800692

Epoch: 5| Step: 9
Training loss: 1.5370557308197021
Validation loss: 1.90645041132486

Epoch: 5| Step: 10
Training loss: 1.3665211200714111
Validation loss: 1.9231999381895988

Epoch: 341| Step: 0
Training loss: 1.3663679361343384
Validation loss: 1.9020669075750536

Epoch: 5| Step: 1
Training loss: 1.3388175964355469
Validation loss: 1.8810216419158443

Epoch: 5| Step: 2
Training loss: 1.5044305324554443
Validation loss: 1.920215642580422

Epoch: 5| Step: 3
Training loss: 1.6296508312225342
Validation loss: 1.913275703307121

Epoch: 5| Step: 4
Training loss: 1.2621524333953857
Validation loss: 1.9374290717545377

Epoch: 5| Step: 5
Training loss: 1.5158007144927979
Validation loss: 1.8821655140128186

Epoch: 5| Step: 6
Training loss: 1.9061371088027954
Validation loss: 1.9141556857734598

Epoch: 5| Step: 7
Training loss: 2.190018892288208
Validation loss: 1.9095438282976869

Epoch: 5| Step: 8
Training loss: 1.0227735042572021
Validation loss: 1.9044254108141827

Epoch: 5| Step: 9
Training loss: 1.4160534143447876
Validation loss: 1.9316909261929092

Epoch: 5| Step: 10
Training loss: 1.4456919431686401
Validation loss: 1.902552636720801

Epoch: 342| Step: 0
Training loss: 2.0130183696746826
Validation loss: 1.9134601649417673

Epoch: 5| Step: 1
Training loss: 1.2831043004989624
Validation loss: 1.925107018921965

Epoch: 5| Step: 2
Training loss: 1.7326513528823853
Validation loss: 1.8977471102950394

Epoch: 5| Step: 3
Training loss: 1.3097693920135498
Validation loss: 1.9334602099592968

Epoch: 5| Step: 4
Training loss: 1.2643762826919556
Validation loss: 1.8699216650378319

Epoch: 5| Step: 5
Training loss: 1.8284502029418945
Validation loss: 1.9647803280943184

Epoch: 5| Step: 6
Training loss: 1.4401066303253174
Validation loss: 1.9093208800080002

Epoch: 5| Step: 7
Training loss: 1.9954582452774048
Validation loss: 1.9362743605849564

Epoch: 5| Step: 8
Training loss: 1.3887135982513428
Validation loss: 1.8895737009663736

Epoch: 5| Step: 9
Training loss: 1.2179598808288574
Validation loss: 1.8789670082830614

Epoch: 5| Step: 10
Training loss: 1.1005830764770508
Validation loss: 1.8674828237102878

Epoch: 343| Step: 0
Training loss: 1.6218734979629517
Validation loss: 1.93016876200194

Epoch: 5| Step: 1
Training loss: 1.783258080482483
Validation loss: 1.8987789128416328

Epoch: 5| Step: 2
Training loss: 1.2901586294174194
Validation loss: 1.918326175341042

Epoch: 5| Step: 3
Training loss: 1.2760268449783325
Validation loss: 1.914274420789493

Epoch: 5| Step: 4
Training loss: 1.1524229049682617
Validation loss: 1.9342458273774834

Epoch: 5| Step: 5
Training loss: 1.4574487209320068
Validation loss: 1.8706232488796275

Epoch: 5| Step: 6
Training loss: 1.8387962579727173
Validation loss: 1.9284396889389201

Epoch: 5| Step: 7
Training loss: 1.2505972385406494
Validation loss: 1.8434489542438137

Epoch: 5| Step: 8
Training loss: 1.6182197332382202
Validation loss: 1.8905466371966946

Epoch: 5| Step: 9
Training loss: 2.026012420654297
Validation loss: 1.867180105819497

Epoch: 5| Step: 10
Training loss: 1.5307661294937134
Validation loss: 1.9003127697975404

Epoch: 344| Step: 0
Training loss: 1.8528048992156982
Validation loss: 1.9054685792615336

Epoch: 5| Step: 1
Training loss: 1.7701027393341064
Validation loss: 1.9015715788769465

Epoch: 5| Step: 2
Training loss: 1.2284774780273438
Validation loss: 1.8612347546444143

Epoch: 5| Step: 3
Training loss: 1.6905574798583984
Validation loss: 1.846383842088843

Epoch: 5| Step: 4
Training loss: 1.3724788427352905
Validation loss: 1.9126720249011953

Epoch: 5| Step: 5
Training loss: 2.2761518955230713
Validation loss: 1.9128626738825152

Epoch: 5| Step: 6
Training loss: 1.2620173692703247
Validation loss: 1.8846641458490843

Epoch: 5| Step: 7
Training loss: 1.8107116222381592
Validation loss: 1.9159914062869163

Epoch: 5| Step: 8
Training loss: 1.4472261667251587
Validation loss: 1.88651858093918

Epoch: 5| Step: 9
Training loss: 1.0569546222686768
Validation loss: 1.9021395252596947

Epoch: 5| Step: 10
Training loss: 1.03647780418396
Validation loss: 1.8956838166841896

Epoch: 345| Step: 0
Training loss: 1.3444640636444092
Validation loss: 1.881027457534626

Epoch: 5| Step: 1
Training loss: 1.387790322303772
Validation loss: 1.9154317020088114

Epoch: 5| Step: 2
Training loss: 1.765713095664978
Validation loss: 1.9208115877643708

Epoch: 5| Step: 3
Training loss: 1.894887924194336
Validation loss: 1.9221105139742616

Epoch: 5| Step: 4
Training loss: 1.5607422590255737
Validation loss: 1.893063272199323

Epoch: 5| Step: 5
Training loss: 0.9543749690055847
Validation loss: 1.8876376587857482

Epoch: 5| Step: 6
Training loss: 1.1542770862579346
Validation loss: 1.8887084735337125

Epoch: 5| Step: 7
Training loss: 1.7310867309570312
Validation loss: 1.9151641168901998

Epoch: 5| Step: 8
Training loss: 1.7409271001815796
Validation loss: 1.8875711220566944

Epoch: 5| Step: 9
Training loss: 1.2772910594940186
Validation loss: 1.8598591358430925

Epoch: 5| Step: 10
Training loss: 1.8639070987701416
Validation loss: 1.911536798682264

Epoch: 346| Step: 0
Training loss: 1.792688012123108
Validation loss: 1.928091610631635

Epoch: 5| Step: 1
Training loss: 1.3852424621582031
Validation loss: 1.8681851292169223

Epoch: 5| Step: 2
Training loss: 1.57503080368042
Validation loss: 1.905324246293755

Epoch: 5| Step: 3
Training loss: 1.8847942352294922
Validation loss: 1.8793847150700067

Epoch: 5| Step: 4
Training loss: 1.357889175415039
Validation loss: 1.8933032943356423

Epoch: 5| Step: 5
Training loss: 1.0752815008163452
Validation loss: 1.8656815482724098

Epoch: 5| Step: 6
Training loss: 1.7594468593597412
Validation loss: 1.8937737275195379

Epoch: 5| Step: 7
Training loss: 1.297659158706665
Validation loss: 1.9222303718648932

Epoch: 5| Step: 8
Training loss: 1.0780041217803955
Validation loss: 1.8873570888273177

Epoch: 5| Step: 9
Training loss: 1.6528937816619873
Validation loss: 1.887637972831726

Epoch: 5| Step: 10
Training loss: 1.8160988092422485
Validation loss: 1.8583077179488314

Epoch: 347| Step: 0
Training loss: 1.0553475618362427
Validation loss: 1.8758844867829354

Epoch: 5| Step: 1
Training loss: 2.205820083618164
Validation loss: 1.8982848172546716

Epoch: 5| Step: 2
Training loss: 1.7914104461669922
Validation loss: 1.8657580242362073

Epoch: 5| Step: 3
Training loss: 1.797156572341919
Validation loss: 1.910966710377765

Epoch: 5| Step: 4
Training loss: 1.1279836893081665
Validation loss: 1.8802058799292451

Epoch: 5| Step: 5
Training loss: 1.717246413230896
Validation loss: 1.9330825805664062

Epoch: 5| Step: 6
Training loss: 1.2910728454589844
Validation loss: 1.9017303143778155

Epoch: 5| Step: 7
Training loss: 1.2846505641937256
Validation loss: 1.8886632483492616

Epoch: 5| Step: 8
Training loss: 1.8280019760131836
Validation loss: 1.889685889726044

Epoch: 5| Step: 9
Training loss: 1.1587655544281006
Validation loss: 1.8954659687575472

Epoch: 5| Step: 10
Training loss: 1.2598832845687866
Validation loss: 1.8569245569167598

Epoch: 348| Step: 0
Training loss: 1.1509158611297607
Validation loss: 1.888391681896743

Epoch: 5| Step: 1
Training loss: 1.6666017770767212
Validation loss: 1.9092997299727572

Epoch: 5| Step: 2
Training loss: 1.8345613479614258
Validation loss: 1.9102529761611775

Epoch: 5| Step: 3
Training loss: 1.598934531211853
Validation loss: 1.9249950403808265

Epoch: 5| Step: 4
Training loss: 1.4566218852996826
Validation loss: 1.9287814414629372

Epoch: 5| Step: 5
Training loss: 2.0153708457946777
Validation loss: 1.9451763655549736

Epoch: 5| Step: 6
Training loss: 1.3176161050796509
Validation loss: 1.9259560377367082

Epoch: 5| Step: 7
Training loss: 1.0985798835754395
Validation loss: 1.934635426408501

Epoch: 5| Step: 8
Training loss: 1.5839670896530151
Validation loss: 1.9079720307421941

Epoch: 5| Step: 9
Training loss: 1.7718585729599
Validation loss: 1.9205594985715804

Epoch: 5| Step: 10
Training loss: 1.0798650979995728
Validation loss: 1.8824293241705945

Epoch: 349| Step: 0
Training loss: 1.5101920366287231
Validation loss: 1.9005440896557224

Epoch: 5| Step: 1
Training loss: 1.6461460590362549
Validation loss: 1.919888105443729

Epoch: 5| Step: 2
Training loss: 1.6892340183258057
Validation loss: 1.8481742233358405

Epoch: 5| Step: 3
Training loss: 1.1276626586914062
Validation loss: 1.9006810316475489

Epoch: 5| Step: 4
Training loss: 1.5769834518432617
Validation loss: 1.9292307105115665

Epoch: 5| Step: 5
Training loss: 1.6085031032562256
Validation loss: 1.901832406238843

Epoch: 5| Step: 6
Training loss: 1.530104637145996
Validation loss: 1.8954768052665136

Epoch: 5| Step: 7
Training loss: 1.3629052639007568
Validation loss: 1.8679435701780422

Epoch: 5| Step: 8
Training loss: 1.4406229257583618
Validation loss: 1.8832153069075717

Epoch: 5| Step: 9
Training loss: 1.6383864879608154
Validation loss: 1.923843087688569

Epoch: 5| Step: 10
Training loss: 1.5687105655670166
Validation loss: 1.91124592673394

Epoch: 350| Step: 0
Training loss: 1.723901391029358
Validation loss: 1.8995702266693115

Epoch: 5| Step: 1
Training loss: 1.3718526363372803
Validation loss: 1.93164877353176

Epoch: 5| Step: 2
Training loss: 0.8352143168449402
Validation loss: 1.95243969527624

Epoch: 5| Step: 3
Training loss: 1.722015619277954
Validation loss: 1.899586107141228

Epoch: 5| Step: 4
Training loss: 1.3305189609527588
Validation loss: 1.9075522448426934

Epoch: 5| Step: 5
Training loss: 1.3226995468139648
Validation loss: 1.9502342183102843

Epoch: 5| Step: 6
Training loss: 1.6807653903961182
Validation loss: 1.8999902061236802

Epoch: 5| Step: 7
Training loss: 2.196500301361084
Validation loss: 1.9135684723495154

Epoch: 5| Step: 8
Training loss: 1.1463638544082642
Validation loss: 1.9721913491525958

Epoch: 5| Step: 9
Training loss: 1.5644258260726929
Validation loss: 1.9027065935955252

Epoch: 5| Step: 10
Training loss: 1.7366654872894287
Validation loss: 1.893724778647064

Epoch: 351| Step: 0
Training loss: 1.7822902202606201
Validation loss: 1.8873668088707873

Epoch: 5| Step: 1
Training loss: 1.247910499572754
Validation loss: 1.926857166392829

Epoch: 5| Step: 2
Training loss: 1.2473658323287964
Validation loss: 1.8871387256089078

Epoch: 5| Step: 3
Training loss: 1.3495588302612305
Validation loss: 1.8681387311668807

Epoch: 5| Step: 4
Training loss: 1.607324242591858
Validation loss: 1.85416655899376

Epoch: 5| Step: 5
Training loss: 1.57887864112854
Validation loss: 1.9070249706186273

Epoch: 5| Step: 6
Training loss: 1.73894464969635
Validation loss: 1.8699264962186095

Epoch: 5| Step: 7
Training loss: 1.8677818775177002
Validation loss: 1.878329715421123

Epoch: 5| Step: 8
Training loss: 1.5671900510787964
Validation loss: 1.8781412480979838

Epoch: 5| Step: 9
Training loss: 1.15602445602417
Validation loss: 1.8778260907819193

Epoch: 5| Step: 10
Training loss: 1.133249044418335
Validation loss: 1.8675692927452825

Epoch: 352| Step: 0
Training loss: 1.8624480962753296
Validation loss: 1.9060102278186428

Epoch: 5| Step: 1
Training loss: 1.1901907920837402
Validation loss: 1.9012295635797645

Epoch: 5| Step: 2
Training loss: 1.7383613586425781
Validation loss: 1.8931915311403171

Epoch: 5| Step: 3
Training loss: 0.8721798658370972
Validation loss: 1.9141243657758158

Epoch: 5| Step: 4
Training loss: 1.4136914014816284
Validation loss: 1.9160897116507254

Epoch: 5| Step: 5
Training loss: 1.8696441650390625
Validation loss: 1.9042222474211006

Epoch: 5| Step: 6
Training loss: 1.1237894296646118
Validation loss: 1.8979438889411189

Epoch: 5| Step: 7
Training loss: 1.0515568256378174
Validation loss: 1.8844684529048141

Epoch: 5| Step: 8
Training loss: 1.2751028537750244
Validation loss: 1.9353225308079873

Epoch: 5| Step: 9
Training loss: 2.3260338306427
Validation loss: 1.8936431600201515

Epoch: 5| Step: 10
Training loss: 1.4725046157836914
Validation loss: 1.9074464741573538

Epoch: 353| Step: 0
Training loss: 1.4496616125106812
Validation loss: 1.9203335956860614

Epoch: 5| Step: 1
Training loss: 1.5731405019760132
Validation loss: 1.8787358140432706

Epoch: 5| Step: 2
Training loss: 1.4061740636825562
Validation loss: 1.9198072982090775

Epoch: 5| Step: 3
Training loss: 1.1732007265090942
Validation loss: 1.9356960763213455

Epoch: 5| Step: 4
Training loss: 1.8374866247177124
Validation loss: 1.8787747416445004

Epoch: 5| Step: 5
Training loss: 0.9272300601005554
Validation loss: 1.9577413323105022

Epoch: 5| Step: 6
Training loss: 1.2706749439239502
Validation loss: 1.911521304038263

Epoch: 5| Step: 7
Training loss: 2.1988673210144043
Validation loss: 1.9119790882192633

Epoch: 5| Step: 8
Training loss: 1.7193390130996704
Validation loss: 1.8875295346783054

Epoch: 5| Step: 9
Training loss: 1.4299132823944092
Validation loss: 1.890979823245797

Epoch: 5| Step: 10
Training loss: 1.3807947635650635
Validation loss: 1.9009483988567064

Epoch: 354| Step: 0
Training loss: 1.684378981590271
Validation loss: 1.8696866881462835

Epoch: 5| Step: 1
Training loss: 1.0547701120376587
Validation loss: 1.8748193030716271

Epoch: 5| Step: 2
Training loss: 1.1762453317642212
Validation loss: 1.882300587110622

Epoch: 5| Step: 3
Training loss: 1.796169638633728
Validation loss: 1.856522975429412

Epoch: 5| Step: 4
Training loss: 1.7112312316894531
Validation loss: 1.8776473870841406

Epoch: 5| Step: 5
Training loss: 1.5693080425262451
Validation loss: 1.8681044027369509

Epoch: 5| Step: 6
Training loss: 1.0696020126342773
Validation loss: 1.8882660327419158

Epoch: 5| Step: 7
Training loss: 2.089005947113037
Validation loss: 1.88126661187859

Epoch: 5| Step: 8
Training loss: 1.113227128982544
Validation loss: 1.909464213155931

Epoch: 5| Step: 9
Training loss: 1.7528988122940063
Validation loss: 1.9105754334439513

Epoch: 5| Step: 10
Training loss: 1.3792681694030762
Validation loss: 1.9295516872918734

Epoch: 355| Step: 0
Training loss: 1.699413537979126
Validation loss: 1.9297906557718914

Epoch: 5| Step: 1
Training loss: 1.7595475912094116
Validation loss: 1.9161941184792468

Epoch: 5| Step: 2
Training loss: 1.5322179794311523
Validation loss: 1.9392558528530983

Epoch: 5| Step: 3
Training loss: 1.3578283786773682
Validation loss: 1.944626885075723

Epoch: 5| Step: 4
Training loss: 1.3950345516204834
Validation loss: 1.8941295941670735

Epoch: 5| Step: 5
Training loss: 1.550601840019226
Validation loss: 1.967441261455577

Epoch: 5| Step: 6
Training loss: 1.234445333480835
Validation loss: 1.969884862181961

Epoch: 5| Step: 7
Training loss: 1.5713175535202026
Validation loss: 1.9588588988909157

Epoch: 5| Step: 8
Training loss: 1.5924499034881592
Validation loss: 1.9391520241255402

Epoch: 5| Step: 9
Training loss: 1.1814007759094238
Validation loss: 1.9307442788154847

Epoch: 5| Step: 10
Training loss: 1.6211923360824585
Validation loss: 1.878504676203574

Epoch: 356| Step: 0
Training loss: 1.7585901021957397
Validation loss: 1.9081271245915403

Epoch: 5| Step: 1
Training loss: 0.8652058839797974
Validation loss: 1.9036911238906205

Epoch: 5| Step: 2
Training loss: 1.4346017837524414
Validation loss: 1.8612403254355154

Epoch: 5| Step: 3
Training loss: 1.1036407947540283
Validation loss: 1.8744171563015188

Epoch: 5| Step: 4
Training loss: 1.1370470523834229
Validation loss: 1.9190091125426754

Epoch: 5| Step: 5
Training loss: 1.3486990928649902
Validation loss: 1.8570620526549637

Epoch: 5| Step: 6
Training loss: 2.034186363220215
Validation loss: 1.8697281550335627

Epoch: 5| Step: 7
Training loss: 1.4604624509811401
Validation loss: 1.8976602105684177

Epoch: 5| Step: 8
Training loss: 1.6880531311035156
Validation loss: 1.8978802260532175

Epoch: 5| Step: 9
Training loss: 1.7584097385406494
Validation loss: 1.893871711146447

Epoch: 5| Step: 10
Training loss: 1.6101106405258179
Validation loss: 1.9163397871037966

Epoch: 357| Step: 0
Training loss: 1.4966942071914673
Validation loss: 1.9034506428626277

Epoch: 5| Step: 1
Training loss: 1.4477382898330688
Validation loss: 1.860433106781334

Epoch: 5| Step: 2
Training loss: 1.2809991836547852
Validation loss: 1.9085428355842509

Epoch: 5| Step: 3
Training loss: 1.2340065240859985
Validation loss: 1.9234375697310253

Epoch: 5| Step: 4
Training loss: 1.3716974258422852
Validation loss: 1.877714095577117

Epoch: 5| Step: 5
Training loss: 1.7678550481796265
Validation loss: 1.8857140233439784

Epoch: 5| Step: 6
Training loss: 1.3197729587554932
Validation loss: 1.9245152268358456

Epoch: 5| Step: 7
Training loss: 1.6966731548309326
Validation loss: 1.9025634616933844

Epoch: 5| Step: 8
Training loss: 1.276136040687561
Validation loss: 1.8638107840732863

Epoch: 5| Step: 9
Training loss: 1.3397194147109985
Validation loss: 1.8718920651302542

Epoch: 5| Step: 10
Training loss: 1.881544589996338
Validation loss: 1.900743528078961

Epoch: 358| Step: 0
Training loss: 1.3957831859588623
Validation loss: 1.8671548417819444

Epoch: 5| Step: 1
Training loss: 1.5148756504058838
Validation loss: 1.9027591456649124

Epoch: 5| Step: 2
Training loss: 1.7156394720077515
Validation loss: 1.9027702616107078

Epoch: 5| Step: 3
Training loss: 0.9354718327522278
Validation loss: 1.9188578410815167

Epoch: 5| Step: 4
Training loss: 1.4608423709869385
Validation loss: 1.91242979931575

Epoch: 5| Step: 5
Training loss: 1.7906566858291626
Validation loss: 1.9222869796137656

Epoch: 5| Step: 6
Training loss: 1.1969349384307861
Validation loss: 1.9163951822506484

Epoch: 5| Step: 7
Training loss: 1.7597415447235107
Validation loss: 1.8726233948943436

Epoch: 5| Step: 8
Training loss: 1.078000783920288
Validation loss: 1.8821053197306972

Epoch: 5| Step: 9
Training loss: 1.4868882894515991
Validation loss: 1.9189081486835275

Epoch: 5| Step: 10
Training loss: 1.8152801990509033
Validation loss: 1.8940193422379032

Epoch: 359| Step: 0
Training loss: 1.6538991928100586
Validation loss: 1.8562375435265162

Epoch: 5| Step: 1
Training loss: 1.3412928581237793
Validation loss: 1.8819965547130955

Epoch: 5| Step: 2
Training loss: 1.515964388847351
Validation loss: 1.867059846078196

Epoch: 5| Step: 3
Training loss: 2.0343480110168457
Validation loss: 1.8559116137925016

Epoch: 5| Step: 4
Training loss: 1.4165102243423462
Validation loss: 1.8753823862280896

Epoch: 5| Step: 5
Training loss: 1.3329846858978271
Validation loss: 1.8548338144056258

Epoch: 5| Step: 6
Training loss: 1.505913496017456
Validation loss: 1.8828325104969803

Epoch: 5| Step: 7
Training loss: 1.761020302772522
Validation loss: 1.8769080715794717

Epoch: 5| Step: 8
Training loss: 1.3024475574493408
Validation loss: 1.831011115863759

Epoch: 5| Step: 9
Training loss: 1.0006319284439087
Validation loss: 1.8794176322157665

Epoch: 5| Step: 10
Training loss: 1.4991816282272339
Validation loss: 1.8758447849622337

Epoch: 360| Step: 0
Training loss: 1.0821424722671509
Validation loss: 1.88242156018493

Epoch: 5| Step: 1
Training loss: 1.2018494606018066
Validation loss: 1.8778874233204832

Epoch: 5| Step: 2
Training loss: 1.5467560291290283
Validation loss: 1.9263580370974798

Epoch: 5| Step: 3
Training loss: 1.798021674156189
Validation loss: 1.88049155025072

Epoch: 5| Step: 4
Training loss: 1.4193081855773926
Validation loss: 1.8797733552994267

Epoch: 5| Step: 5
Training loss: 1.7604649066925049
Validation loss: 1.9246613594793505

Epoch: 5| Step: 6
Training loss: 1.1322553157806396
Validation loss: 1.8664395052899596

Epoch: 5| Step: 7
Training loss: 1.3205060958862305
Validation loss: 1.9147445617183563

Epoch: 5| Step: 8
Training loss: 1.6596355438232422
Validation loss: 1.9025459058823124

Epoch: 5| Step: 9
Training loss: 1.7525488138198853
Validation loss: 1.937050247705111

Epoch: 5| Step: 10
Training loss: 1.702212929725647
Validation loss: 1.932807828790398

Epoch: 361| Step: 0
Training loss: 1.5536912679672241
Validation loss: 1.9179245964173348

Epoch: 5| Step: 1
Training loss: 1.640791893005371
Validation loss: 1.8994043616838352

Epoch: 5| Step: 2
Training loss: 1.2546117305755615
Validation loss: 1.9158876890777259

Epoch: 5| Step: 3
Training loss: 1.7506389617919922
Validation loss: 1.8821142847819994

Epoch: 5| Step: 4
Training loss: 1.3736592531204224
Validation loss: 1.8939176567139164

Epoch: 5| Step: 5
Training loss: 1.660363793373108
Validation loss: 1.8784490208471976

Epoch: 5| Step: 6
Training loss: 2.202543258666992
Validation loss: 1.854425379025039

Epoch: 5| Step: 7
Training loss: 0.8779390454292297
Validation loss: 1.9131334853428665

Epoch: 5| Step: 8
Training loss: 1.2413403987884521
Validation loss: 1.8897087240731845

Epoch: 5| Step: 9
Training loss: 1.3650401830673218
Validation loss: 1.8735627756323865

Epoch: 5| Step: 10
Training loss: 1.2064744234085083
Validation loss: 1.9091074235977665

Epoch: 362| Step: 0
Training loss: 1.9817402362823486
Validation loss: 1.8943761074414818

Epoch: 5| Step: 1
Training loss: 1.752211332321167
Validation loss: 1.9309726479232951

Epoch: 5| Step: 2
Training loss: 1.2105326652526855
Validation loss: 1.9005568130041963

Epoch: 5| Step: 3
Training loss: 1.2152467966079712
Validation loss: 1.9616560474518807

Epoch: 5| Step: 4
Training loss: 1.4584712982177734
Validation loss: 1.864517798987768

Epoch: 5| Step: 5
Training loss: 1.1976420879364014
Validation loss: 1.8762355978770922

Epoch: 5| Step: 6
Training loss: 1.1993780136108398
Validation loss: 1.9256880206446494

Epoch: 5| Step: 7
Training loss: 1.5272643566131592
Validation loss: 1.879082989949052

Epoch: 5| Step: 8
Training loss: 1.3579633235931396
Validation loss: 1.8895302241848362

Epoch: 5| Step: 9
Training loss: 1.1483230590820312
Validation loss: 1.9117397518568142

Epoch: 5| Step: 10
Training loss: 2.1651344299316406
Validation loss: 1.9188413261085429

Epoch: 363| Step: 0
Training loss: 1.1191575527191162
Validation loss: 1.8679304276743243

Epoch: 5| Step: 1
Training loss: 1.5874426364898682
Validation loss: 1.886557061185119

Epoch: 5| Step: 2
Training loss: 1.991236686706543
Validation loss: 1.928275760783944

Epoch: 5| Step: 3
Training loss: 0.9572756886482239
Validation loss: 1.8881050925101004

Epoch: 5| Step: 4
Training loss: 1.0649316310882568
Validation loss: 1.8934793562017462

Epoch: 5| Step: 5
Training loss: 1.0468719005584717
Validation loss: 1.889013328859883

Epoch: 5| Step: 6
Training loss: 1.4081751108169556
Validation loss: 1.8740613588722803

Epoch: 5| Step: 7
Training loss: 1.6505073308944702
Validation loss: 1.9136837849053003

Epoch: 5| Step: 8
Training loss: 2.0588059425354004
Validation loss: 1.9265199220308693

Epoch: 5| Step: 9
Training loss: 1.957633376121521
Validation loss: 1.8863416256443146

Epoch: 5| Step: 10
Training loss: 1.4348137378692627
Validation loss: 1.889345149840078

Epoch: 364| Step: 0
Training loss: 1.173421859741211
Validation loss: 1.9045129745237288

Epoch: 5| Step: 1
Training loss: 1.6833387613296509
Validation loss: 1.887447528941657

Epoch: 5| Step: 2
Training loss: 1.1704695224761963
Validation loss: 1.859753624085457

Epoch: 5| Step: 3
Training loss: 2.3076350688934326
Validation loss: 1.8354914380658058

Epoch: 5| Step: 4
Training loss: 1.414780855178833
Validation loss: 1.8831023977648826

Epoch: 5| Step: 5
Training loss: 1.2074975967407227
Validation loss: 1.908045486737323

Epoch: 5| Step: 6
Training loss: 1.698875069618225
Validation loss: 1.8839151808010635

Epoch: 5| Step: 7
Training loss: 1.314599633216858
Validation loss: 1.8527377984857047

Epoch: 5| Step: 8
Training loss: 1.0836459398269653
Validation loss: 1.898411202174361

Epoch: 5| Step: 9
Training loss: 1.6079998016357422
Validation loss: 1.900935214052918

Epoch: 5| Step: 10
Training loss: 1.2784029245376587
Validation loss: 1.9279813023023709

Epoch: 365| Step: 0
Training loss: 1.618872880935669
Validation loss: 1.8914270683001446

Epoch: 5| Step: 1
Training loss: 1.3762978315353394
Validation loss: 1.9034568340547624

Epoch: 5| Step: 2
Training loss: 0.8845237493515015
Validation loss: 1.9223149207330519

Epoch: 5| Step: 3
Training loss: 1.126455307006836
Validation loss: 1.9114661857645998

Epoch: 5| Step: 4
Training loss: 1.4601075649261475
Validation loss: 1.9088434660306541

Epoch: 5| Step: 5
Training loss: 1.9866691827774048
Validation loss: 1.9115538571470527

Epoch: 5| Step: 6
Training loss: 1.5736792087554932
Validation loss: 1.9146620573536042

Epoch: 5| Step: 7
Training loss: 1.4181808233261108
Validation loss: 1.9135236688839492

Epoch: 5| Step: 8
Training loss: 1.0543266534805298
Validation loss: 1.9413318928851877

Epoch: 5| Step: 9
Training loss: 1.6366243362426758
Validation loss: 1.9185907494637273

Epoch: 5| Step: 10
Training loss: 1.8109140396118164
Validation loss: 1.9185805961649904

Epoch: 366| Step: 0
Training loss: 1.6656697988510132
Validation loss: 1.8932283232288976

Epoch: 5| Step: 1
Training loss: 1.6169116497039795
Validation loss: 1.893996827064022

Epoch: 5| Step: 2
Training loss: 1.4943705797195435
Validation loss: 1.902528432107741

Epoch: 5| Step: 3
Training loss: 1.6165183782577515
Validation loss: 1.8893205722173054

Epoch: 5| Step: 4
Training loss: 1.2794345617294312
Validation loss: 1.8844374315713042

Epoch: 5| Step: 5
Training loss: 1.4780617952346802
Validation loss: 1.9118998896691106

Epoch: 5| Step: 6
Training loss: 0.9508476257324219
Validation loss: 1.877830884789908

Epoch: 5| Step: 7
Training loss: 1.7075573205947876
Validation loss: 1.8643451941910612

Epoch: 5| Step: 8
Training loss: 1.3383959531784058
Validation loss: 1.8816333739988265

Epoch: 5| Step: 9
Training loss: 1.2775379419326782
Validation loss: 1.8767883290526688

Epoch: 5| Step: 10
Training loss: 1.512168049812317
Validation loss: 1.9027440509488505

Epoch: 367| Step: 0
Training loss: 1.6429678201675415
Validation loss: 1.8795674052289737

Epoch: 5| Step: 1
Training loss: 1.6692488193511963
Validation loss: 1.8688371373761086

Epoch: 5| Step: 2
Training loss: 1.321852445602417
Validation loss: 1.8626211753455542

Epoch: 5| Step: 3
Training loss: 1.7660675048828125
Validation loss: 1.8852244666827622

Epoch: 5| Step: 4
Training loss: 1.5136579275131226
Validation loss: 1.9224294244602163

Epoch: 5| Step: 5
Training loss: 1.5978116989135742
Validation loss: 1.858440642074872

Epoch: 5| Step: 6
Training loss: 1.3339087963104248
Validation loss: 1.9075177741307083

Epoch: 5| Step: 7
Training loss: 1.2964471578598022
Validation loss: 1.8823018356036114

Epoch: 5| Step: 8
Training loss: 1.4901775121688843
Validation loss: 1.925353983397125

Epoch: 5| Step: 9
Training loss: 1.3863011598587036
Validation loss: 1.8753137857683244

Epoch: 5| Step: 10
Training loss: 1.0133743286132812
Validation loss: 1.8922656659157044

Epoch: 368| Step: 0
Training loss: 1.2589881420135498
Validation loss: 1.9113061710070538

Epoch: 5| Step: 1
Training loss: 1.3943010568618774
Validation loss: 1.9146969369662705

Epoch: 5| Step: 2
Training loss: 1.7477833032608032
Validation loss: 1.8832878169193064

Epoch: 5| Step: 3
Training loss: 1.3874653577804565
Validation loss: 1.919403354326884

Epoch: 5| Step: 4
Training loss: 1.774518370628357
Validation loss: 1.9130072029688026

Epoch: 5| Step: 5
Training loss: 1.1220345497131348
Validation loss: 1.8939434533478112

Epoch: 5| Step: 6
Training loss: 1.0241683721542358
Validation loss: 1.9014965846974363

Epoch: 5| Step: 7
Training loss: 1.4758888483047485
Validation loss: 1.8888547599956553

Epoch: 5| Step: 8
Training loss: 1.3233559131622314
Validation loss: 1.8855373269768172

Epoch: 5| Step: 9
Training loss: 1.9866310358047485
Validation loss: 1.8831416560757546

Epoch: 5| Step: 10
Training loss: 1.2749296426773071
Validation loss: 1.8720763216736496

Epoch: 369| Step: 0
Training loss: 2.2172060012817383
Validation loss: 1.9030793969349196

Epoch: 5| Step: 1
Training loss: 1.4235026836395264
Validation loss: 1.9359227970082273

Epoch: 5| Step: 2
Training loss: 1.0926542282104492
Validation loss: 1.8759390872011903

Epoch: 5| Step: 3
Training loss: 1.1420189142227173
Validation loss: 1.8870010991250314

Epoch: 5| Step: 4
Training loss: 1.103865385055542
Validation loss: 1.9007202143310218

Epoch: 5| Step: 5
Training loss: 1.4775627851486206
Validation loss: 1.8778956449160011

Epoch: 5| Step: 6
Training loss: 1.7629623413085938
Validation loss: 1.8428483086247598

Epoch: 5| Step: 7
Training loss: 1.3124946355819702
Validation loss: 1.88947073746753

Epoch: 5| Step: 8
Training loss: 1.385195255279541
Validation loss: 1.8972431523825533

Epoch: 5| Step: 9
Training loss: 1.429738998413086
Validation loss: 1.8888713044504966

Epoch: 5| Step: 10
Training loss: 1.508270025253296
Validation loss: 1.8736419652097969

Epoch: 370| Step: 0
Training loss: 0.9675911664962769
Validation loss: 1.8762208697616414

Epoch: 5| Step: 1
Training loss: 1.993024468421936
Validation loss: 1.900051111816078

Epoch: 5| Step: 2
Training loss: 1.742093801498413
Validation loss: 1.898985779413613

Epoch: 5| Step: 3
Training loss: 1.6259772777557373
Validation loss: 1.9366267573448919

Epoch: 5| Step: 4
Training loss: 1.2934200763702393
Validation loss: 1.9058133530360397

Epoch: 5| Step: 5
Training loss: 1.4196630716323853
Validation loss: 1.9268404745286511

Epoch: 5| Step: 6
Training loss: 1.2206740379333496
Validation loss: 1.8899081163508917

Epoch: 5| Step: 7
Training loss: 1.473505973815918
Validation loss: 1.9063614171038392

Epoch: 5| Step: 8
Training loss: 1.6594728231430054
Validation loss: 1.911921324268464

Epoch: 5| Step: 9
Training loss: 1.1410285234451294
Validation loss: 1.9620571098019999

Epoch: 5| Step: 10
Training loss: 1.450452208518982
Validation loss: 1.8899559615760722

Epoch: 371| Step: 0
Training loss: 1.4392783641815186
Validation loss: 1.8979585747564993

Epoch: 5| Step: 1
Training loss: 1.088854193687439
Validation loss: 1.888684089465808

Epoch: 5| Step: 2
Training loss: 1.379737138748169
Validation loss: 1.8724829407148464

Epoch: 5| Step: 3
Training loss: 1.7854578495025635
Validation loss: 1.9084749298710977

Epoch: 5| Step: 4
Training loss: 2.0277099609375
Validation loss: 1.8817395907576366

Epoch: 5| Step: 5
Training loss: 1.3094494342803955
Validation loss: 1.8585341361261183

Epoch: 5| Step: 6
Training loss: 1.3269823789596558
Validation loss: 1.8851182204420849

Epoch: 5| Step: 7
Training loss: 2.07511043548584
Validation loss: 1.8666172168588127

Epoch: 5| Step: 8
Training loss: 1.7744691371917725
Validation loss: 1.9043670867079048

Epoch: 5| Step: 9
Training loss: 0.8044121861457825
Validation loss: 1.9114503334927302

Epoch: 5| Step: 10
Training loss: 0.9124240875244141
Validation loss: 1.887219810998568

Epoch: 372| Step: 0
Training loss: 1.4101722240447998
Validation loss: 1.8922584569582375

Epoch: 5| Step: 1
Training loss: 1.6327975988388062
Validation loss: 1.9526450236638386

Epoch: 5| Step: 2
Training loss: 1.7594293355941772
Validation loss: 1.8970706078314012

Epoch: 5| Step: 3
Training loss: 1.6220299005508423
Validation loss: 1.9065120707276046

Epoch: 5| Step: 4
Training loss: 1.4696558713912964
Validation loss: 1.9256394960547005

Epoch: 5| Step: 5
Training loss: 1.1371269226074219
Validation loss: 1.9386964203209005

Epoch: 5| Step: 6
Training loss: 1.4329136610031128
Validation loss: 1.9343249349183933

Epoch: 5| Step: 7
Training loss: 1.4951181411743164
Validation loss: 1.9125626035915908

Epoch: 5| Step: 8
Training loss: 1.6745059490203857
Validation loss: 1.944469476258883

Epoch: 5| Step: 9
Training loss: 1.235997200012207
Validation loss: 1.9145730592871224

Epoch: 5| Step: 10
Training loss: 1.2495002746582031
Validation loss: 1.924181124215485

Epoch: 373| Step: 0
Training loss: 1.5011576414108276
Validation loss: 1.8674222256547661

Epoch: 5| Step: 1
Training loss: 1.5790106058120728
Validation loss: 1.9004062401351107

Epoch: 5| Step: 2
Training loss: 1.5082483291625977
Validation loss: 1.874036342866959

Epoch: 5| Step: 3
Training loss: 1.5347678661346436
Validation loss: 1.8866536232732958

Epoch: 5| Step: 4
Training loss: 1.638122797012329
Validation loss: 1.8711277425930064

Epoch: 5| Step: 5
Training loss: 1.388959527015686
Validation loss: 1.8936569101067

Epoch: 5| Step: 6
Training loss: 1.2611572742462158
Validation loss: 1.9063421718535885

Epoch: 5| Step: 7
Training loss: 1.639678716659546
Validation loss: 1.908332597824835

Epoch: 5| Step: 8
Training loss: 0.8929111361503601
Validation loss: 1.898519439081992

Epoch: 5| Step: 9
Training loss: 1.4528414011001587
Validation loss: 1.8936149048548874

Epoch: 5| Step: 10
Training loss: 1.5463817119598389
Validation loss: 1.8764568003275062

Epoch: 374| Step: 0
Training loss: 1.1162983179092407
Validation loss: 1.903946998298809

Epoch: 5| Step: 1
Training loss: 1.420408844947815
Validation loss: 1.9185557519235918

Epoch: 5| Step: 2
Training loss: 1.57594633102417
Validation loss: 1.9151169459025066

Epoch: 5| Step: 3
Training loss: 2.1368203163146973
Validation loss: 1.9088699356202157

Epoch: 5| Step: 4
Training loss: 1.9060773849487305
Validation loss: 1.9178839588678012

Epoch: 5| Step: 5
Training loss: 0.9642163515090942
Validation loss: 1.929649228690773

Epoch: 5| Step: 6
Training loss: 1.5554065704345703
Validation loss: 1.9392473364389071

Epoch: 5| Step: 7
Training loss: 1.0270978212356567
Validation loss: 1.9287257450883106

Epoch: 5| Step: 8
Training loss: 1.693861961364746
Validation loss: 1.935069094422043

Epoch: 5| Step: 9
Training loss: 0.9721933603286743
Validation loss: 1.9640055061668478

Epoch: 5| Step: 10
Training loss: 1.6523585319519043
Validation loss: 1.937417814808507

Epoch: 375| Step: 0
Training loss: 1.601194143295288
Validation loss: 1.902160221530545

Epoch: 5| Step: 1
Training loss: 1.5684620141983032
Validation loss: 1.9654798071871522

Epoch: 5| Step: 2
Training loss: 1.492316484451294
Validation loss: 1.9341034863584785

Epoch: 5| Step: 3
Training loss: 1.39872145652771
Validation loss: 1.9041156845708047

Epoch: 5| Step: 4
Training loss: 1.103257656097412
Validation loss: 1.907412890465029

Epoch: 5| Step: 5
Training loss: 1.2856676578521729
Validation loss: 1.9083801264403968

Epoch: 5| Step: 6
Training loss: 1.6862941980361938
Validation loss: 1.9141190205850909

Epoch: 5| Step: 7
Training loss: 1.1851089000701904
Validation loss: 1.8834710928701586

Epoch: 5| Step: 8
Training loss: 1.6091783046722412
Validation loss: 1.893665761075994

Epoch: 5| Step: 9
Training loss: 1.3470919132232666
Validation loss: 1.876760978852549

Epoch: 5| Step: 10
Training loss: 1.6335444450378418
Validation loss: 1.8884577148704118

Epoch: 376| Step: 0
Training loss: 1.6845786571502686
Validation loss: 1.8948278753988204

Epoch: 5| Step: 1
Training loss: 2.071716785430908
Validation loss: 1.9341981603253273

Epoch: 5| Step: 2
Training loss: 1.466742753982544
Validation loss: 1.8693715244211175

Epoch: 5| Step: 3
Training loss: 1.5125181674957275
Validation loss: 1.869781033967131

Epoch: 5| Step: 4
Training loss: 0.761642575263977
Validation loss: 1.8840894442732616

Epoch: 5| Step: 5
Training loss: 0.9670981168746948
Validation loss: 1.916851725629581

Epoch: 5| Step: 6
Training loss: 1.9583022594451904
Validation loss: 1.9212017866872972

Epoch: 5| Step: 7
Training loss: 1.1721551418304443
Validation loss: 1.885602335776052

Epoch: 5| Step: 8
Training loss: 1.2197006940841675
Validation loss: 1.8984415684976885

Epoch: 5| Step: 9
Training loss: 1.8077300786972046
Validation loss: 1.9080981528887184

Epoch: 5| Step: 10
Training loss: 1.1097561120986938
Validation loss: 1.9063334356072128

Epoch: 377| Step: 0
Training loss: 1.9467895030975342
Validation loss: 1.9020985416186753

Epoch: 5| Step: 1
Training loss: 0.9351369142532349
Validation loss: 1.8787577741889543

Epoch: 5| Step: 2
Training loss: 1.0198471546173096
Validation loss: 1.8891997016886228

Epoch: 5| Step: 3
Training loss: 1.5722763538360596
Validation loss: 1.9241203518324002

Epoch: 5| Step: 4
Training loss: 1.8104426860809326
Validation loss: 1.8963683189884308

Epoch: 5| Step: 5
Training loss: 1.3240549564361572
Validation loss: 1.8908322049725441

Epoch: 5| Step: 6
Training loss: 1.3161451816558838
Validation loss: 1.8838664536835046

Epoch: 5| Step: 7
Training loss: 1.3824564218521118
Validation loss: 1.9198793044654272

Epoch: 5| Step: 8
Training loss: 1.349514365196228
Validation loss: 1.9231948467992968

Epoch: 5| Step: 9
Training loss: 1.3245697021484375
Validation loss: 1.9349142530912995

Epoch: 5| Step: 10
Training loss: 1.6647179126739502
Validation loss: 1.9188385573766564

Epoch: 378| Step: 0
Training loss: 1.9164435863494873
Validation loss: 1.9336128683500393

Epoch: 5| Step: 1
Training loss: 1.1183018684387207
Validation loss: 1.9096702144991966

Epoch: 5| Step: 2
Training loss: 1.5950305461883545
Validation loss: 1.9121929907029676

Epoch: 5| Step: 3
Training loss: 1.3125592470169067
Validation loss: 1.8881038183807044

Epoch: 5| Step: 4
Training loss: 0.9144116640090942
Validation loss: 1.8626930482925907

Epoch: 5| Step: 5
Training loss: 1.6608680486679077
Validation loss: 1.8702653710560133

Epoch: 5| Step: 6
Training loss: 1.5960813760757446
Validation loss: 1.8912159704392957

Epoch: 5| Step: 7
Training loss: 1.3075404167175293
Validation loss: 1.8847708496996152

Epoch: 5| Step: 8
Training loss: 1.2267030477523804
Validation loss: 1.9165145556132

Epoch: 5| Step: 9
Training loss: 1.7192468643188477
Validation loss: 1.8991528223919611

Epoch: 5| Step: 10
Training loss: 1.2526873350143433
Validation loss: 1.9049082584278558

Epoch: 379| Step: 0
Training loss: 1.6753116846084595
Validation loss: 1.9374491014788229

Epoch: 5| Step: 1
Training loss: 1.0615050792694092
Validation loss: 1.9324076637145011

Epoch: 5| Step: 2
Training loss: 1.2016481161117554
Validation loss: 1.905028175282222

Epoch: 5| Step: 3
Training loss: 1.6132243871688843
Validation loss: 1.8991091789737824

Epoch: 5| Step: 4
Training loss: 2.1969001293182373
Validation loss: 1.8772186489515408

Epoch: 5| Step: 5
Training loss: 0.9318431615829468
Validation loss: 1.922965459926154

Epoch: 5| Step: 6
Training loss: 1.038354754447937
Validation loss: 1.8841366588428456

Epoch: 5| Step: 7
Training loss: 2.0243210792541504
Validation loss: 1.8973386659417102

Epoch: 5| Step: 8
Training loss: 1.3197895288467407
Validation loss: 1.8988407017082296

Epoch: 5| Step: 9
Training loss: 1.1210992336273193
Validation loss: 1.920953965956165

Epoch: 5| Step: 10
Training loss: 1.5124258995056152
Validation loss: 1.9130420864269297

Epoch: 380| Step: 0
Training loss: 1.369204044342041
Validation loss: 1.883368557499301

Epoch: 5| Step: 1
Training loss: 1.8510364294052124
Validation loss: 1.8744684316778695

Epoch: 5| Step: 2
Training loss: 1.4758626222610474
Validation loss: 1.891823253323955

Epoch: 5| Step: 3
Training loss: 1.4664833545684814
Validation loss: 1.9189205406814493

Epoch: 5| Step: 4
Training loss: 1.421722650527954
Validation loss: 1.8905378182729085

Epoch: 5| Step: 5
Training loss: 1.5798835754394531
Validation loss: 1.9435423497230775

Epoch: 5| Step: 6
Training loss: 1.342063307762146
Validation loss: 1.8643916447957356

Epoch: 5| Step: 7
Training loss: 1.4876062870025635
Validation loss: 1.9066091686166742

Epoch: 5| Step: 8
Training loss: 1.2671996355056763
Validation loss: 1.8919380454606907

Epoch: 5| Step: 9
Training loss: 1.1008553504943848
Validation loss: 1.9162949118562924

Epoch: 5| Step: 10
Training loss: 1.3976774215698242
Validation loss: 1.8788632680011053

Epoch: 381| Step: 0
Training loss: 1.4460606575012207
Validation loss: 1.8681785752696376

Epoch: 5| Step: 1
Training loss: 1.4719852209091187
Validation loss: 1.9166796233064385

Epoch: 5| Step: 2
Training loss: 1.1693522930145264
Validation loss: 1.9115572860164027

Epoch: 5| Step: 3
Training loss: 1.0340384244918823
Validation loss: 1.8470453421274822

Epoch: 5| Step: 4
Training loss: 1.563535213470459
Validation loss: 1.9145781378592215

Epoch: 5| Step: 5
Training loss: 1.5858947038650513
Validation loss: 1.8663890554058937

Epoch: 5| Step: 6
Training loss: 1.197249412536621
Validation loss: 1.884829923670779

Epoch: 5| Step: 7
Training loss: 1.570863962173462
Validation loss: 1.9375095008521952

Epoch: 5| Step: 8
Training loss: 1.949652910232544
Validation loss: 1.9024190646345898

Epoch: 5| Step: 9
Training loss: 1.2129571437835693
Validation loss: 1.899698580465009

Epoch: 5| Step: 10
Training loss: 1.197524070739746
Validation loss: 1.949375888352753

Epoch: 382| Step: 0
Training loss: 1.5867359638214111
Validation loss: 1.915515310020857

Epoch: 5| Step: 1
Training loss: 1.4563720226287842
Validation loss: 1.9062100136151878

Epoch: 5| Step: 2
Training loss: 1.9338783025741577
Validation loss: 1.9231776780979608

Epoch: 5| Step: 3
Training loss: 1.4137741327285767
Validation loss: 1.8985619724437754

Epoch: 5| Step: 4
Training loss: 1.702191710472107
Validation loss: 1.9150261391875565

Epoch: 5| Step: 5
Training loss: 1.273348093032837
Validation loss: 1.9340672903163458

Epoch: 5| Step: 6
Training loss: 0.8718682527542114
Validation loss: 1.9032302005316621

Epoch: 5| Step: 7
Training loss: 0.8642056584358215
Validation loss: 1.918299577569449

Epoch: 5| Step: 8
Training loss: 1.7282359600067139
Validation loss: 1.8904383426071496

Epoch: 5| Step: 9
Training loss: 1.3778502941131592
Validation loss: 1.8776540628043554

Epoch: 5| Step: 10
Training loss: 1.5091997385025024
Validation loss: 1.8787036659897014

Epoch: 383| Step: 0
Training loss: 1.4837751388549805
Validation loss: 1.8776753653762162

Epoch: 5| Step: 1
Training loss: 2.0106263160705566
Validation loss: 1.9109222299309188

Epoch: 5| Step: 2
Training loss: 1.5219340324401855
Validation loss: 1.904338041941325

Epoch: 5| Step: 3
Training loss: 1.6623618602752686
Validation loss: 1.947415146776425

Epoch: 5| Step: 4
Training loss: 0.9321367144584656
Validation loss: 1.919900571146319

Epoch: 5| Step: 5
Training loss: 1.4050331115722656
Validation loss: 1.8610908472409813

Epoch: 5| Step: 6
Training loss: 1.948615312576294
Validation loss: 1.9043680314094789

Epoch: 5| Step: 7
Training loss: 1.1473013162612915
Validation loss: 1.8571589172527354

Epoch: 5| Step: 8
Training loss: 1.4793962240219116
Validation loss: 1.883748213450114

Epoch: 5| Step: 9
Training loss: 1.224768877029419
Validation loss: 1.8385588545953073

Epoch: 5| Step: 10
Training loss: 0.7500161528587341
Validation loss: 1.8924269214753182

Epoch: 384| Step: 0
Training loss: 1.0950411558151245
Validation loss: 1.8865230903830579

Epoch: 5| Step: 1
Training loss: 1.6479257345199585
Validation loss: 1.8769326466386036

Epoch: 5| Step: 2
Training loss: 1.356723666191101
Validation loss: 1.9190722742388326

Epoch: 5| Step: 3
Training loss: 1.1181385517120361
Validation loss: 1.912786522219258

Epoch: 5| Step: 4
Training loss: 1.7092710733413696
Validation loss: 1.8860019214691655

Epoch: 5| Step: 5
Training loss: 1.3409193754196167
Validation loss: 1.8893517678783787

Epoch: 5| Step: 6
Training loss: 1.2834978103637695
Validation loss: 1.8918975501932123

Epoch: 5| Step: 7
Training loss: 1.5259323120117188
Validation loss: 1.8947575938317083

Epoch: 5| Step: 8
Training loss: 1.461846113204956
Validation loss: 1.909815985669372

Epoch: 5| Step: 9
Training loss: 0.9483566284179688
Validation loss: 1.8495287164565055

Epoch: 5| Step: 10
Training loss: 2.1175003051757812
Validation loss: 1.892343895409697

Epoch: 385| Step: 0
Training loss: 1.2158963680267334
Validation loss: 1.9258417673008417

Epoch: 5| Step: 1
Training loss: 1.2381861209869385
Validation loss: 1.9294425620827624

Epoch: 5| Step: 2
Training loss: 1.0758700370788574
Validation loss: 1.8792063984819638

Epoch: 5| Step: 3
Training loss: 1.1674985885620117
Validation loss: 1.8880669429738035

Epoch: 5| Step: 4
Training loss: 1.5390746593475342
Validation loss: 1.9146415174648326

Epoch: 5| Step: 5
Training loss: 1.7577474117279053
Validation loss: 1.8966050788920412

Epoch: 5| Step: 6
Training loss: 1.507374882698059
Validation loss: 1.8493946047239407

Epoch: 5| Step: 7
Training loss: 1.4385181665420532
Validation loss: 1.8939374108468332

Epoch: 5| Step: 8
Training loss: 1.5578649044036865
Validation loss: 1.9135338644827566

Epoch: 5| Step: 9
Training loss: 1.5562107563018799
Validation loss: 1.9231048681402718

Epoch: 5| Step: 10
Training loss: 1.6483126878738403
Validation loss: 1.8938435046903548

Epoch: 386| Step: 0
Training loss: 1.3263052701950073
Validation loss: 1.930352807044983

Epoch: 5| Step: 1
Training loss: 1.9992249011993408
Validation loss: 1.9055775750067927

Epoch: 5| Step: 2
Training loss: 0.8607996702194214
Validation loss: 1.8826804173889982

Epoch: 5| Step: 3
Training loss: 0.9099663496017456
Validation loss: 1.9365545434336509

Epoch: 5| Step: 4
Training loss: 1.3228594064712524
Validation loss: 1.9012926291393977

Epoch: 5| Step: 5
Training loss: 1.2671905755996704
Validation loss: 1.8987896493686143

Epoch: 5| Step: 6
Training loss: 1.1171104907989502
Validation loss: 1.8618668792068318

Epoch: 5| Step: 7
Training loss: 1.3597230911254883
Validation loss: 1.8664051384054205

Epoch: 5| Step: 8
Training loss: 1.7337229251861572
Validation loss: 1.9041932167545441

Epoch: 5| Step: 9
Training loss: 1.8683046102523804
Validation loss: 1.866841749478412

Epoch: 5| Step: 10
Training loss: 1.9360138177871704
Validation loss: 1.888693562117956

Epoch: 387| Step: 0
Training loss: 1.2203117609024048
Validation loss: 1.8767180750446935

Epoch: 5| Step: 1
Training loss: 1.4903968572616577
Validation loss: 1.8270880253084245

Epoch: 5| Step: 2
Training loss: 1.6767940521240234
Validation loss: 1.9079298588537401

Epoch: 5| Step: 3
Training loss: 1.1597702503204346
Validation loss: 1.8820315484077699

Epoch: 5| Step: 4
Training loss: 1.403112530708313
Validation loss: 1.9187746381246915

Epoch: 5| Step: 5
Training loss: 1.5103895664215088
Validation loss: 1.9260896457138883

Epoch: 5| Step: 6
Training loss: 1.5496593713760376
Validation loss: 1.9063411553700764

Epoch: 5| Step: 7
Training loss: 1.1992756128311157
Validation loss: 1.9361965963917394

Epoch: 5| Step: 8
Training loss: 1.370341420173645
Validation loss: 1.9051246719975625

Epoch: 5| Step: 9
Training loss: 1.8231884241104126
Validation loss: 1.939994285183568

Epoch: 5| Step: 10
Training loss: 0.9918285608291626
Validation loss: 1.926393514038414

Epoch: 388| Step: 0
Training loss: 1.5485045909881592
Validation loss: 1.8895321712698987

Epoch: 5| Step: 1
Training loss: 1.518530249595642
Validation loss: 1.9288195320354995

Epoch: 5| Step: 2
Training loss: 1.59943425655365
Validation loss: 1.8871414725498488

Epoch: 5| Step: 3
Training loss: 1.9441827535629272
Validation loss: 1.9239035806348246

Epoch: 5| Step: 4
Training loss: 1.012943983078003
Validation loss: 1.881057805912469

Epoch: 5| Step: 5
Training loss: 1.5147312879562378
Validation loss: 1.903070753620517

Epoch: 5| Step: 6
Training loss: 0.9776632189750671
Validation loss: 1.9048354036064559

Epoch: 5| Step: 7
Training loss: 0.917095959186554
Validation loss: 1.9047057795268234

Epoch: 5| Step: 8
Training loss: 0.8606324195861816
Validation loss: 1.905942883542789

Epoch: 5| Step: 9
Training loss: 1.3929064273834229
Validation loss: 1.8771963324598087

Epoch: 5| Step: 10
Training loss: 2.216418743133545
Validation loss: 1.8965207005059848

Epoch: 389| Step: 0
Training loss: 1.4428359270095825
Validation loss: 1.9018356210442

Epoch: 5| Step: 1
Training loss: 1.4532209634780884
Validation loss: 1.9363609603656236

Epoch: 5| Step: 2
Training loss: 1.3557782173156738
Validation loss: 1.8973078625176543

Epoch: 5| Step: 3
Training loss: 1.9119694232940674
Validation loss: 1.8796847302426574

Epoch: 5| Step: 4
Training loss: 1.2978893518447876
Validation loss: 1.919652840142609

Epoch: 5| Step: 5
Training loss: 1.3087139129638672
Validation loss: 1.8825605043800928

Epoch: 5| Step: 6
Training loss: 1.318084716796875
Validation loss: 1.9409540878829135

Epoch: 5| Step: 7
Training loss: 1.285291314125061
Validation loss: 1.9376755811834847

Epoch: 5| Step: 8
Training loss: 1.3254411220550537
Validation loss: 1.9041278477638

Epoch: 5| Step: 9
Training loss: 1.7650588750839233
Validation loss: 1.9427080679965276

Epoch: 5| Step: 10
Training loss: 0.7388887405395508
Validation loss: 1.8881830989673574

Epoch: 390| Step: 0
Training loss: 1.3928676843643188
Validation loss: 1.9015106975391347

Epoch: 5| Step: 1
Training loss: 1.0864911079406738
Validation loss: 1.9263023996865878

Epoch: 5| Step: 2
Training loss: 1.3777790069580078
Validation loss: 1.89479999837055

Epoch: 5| Step: 3
Training loss: 1.368285894393921
Validation loss: 1.908482816911513

Epoch: 5| Step: 4
Training loss: 1.8834667205810547
Validation loss: 1.9029662519372919

Epoch: 5| Step: 5
Training loss: 1.5079829692840576
Validation loss: 1.8692947613295687

Epoch: 5| Step: 6
Training loss: 1.2766460180282593
Validation loss: 1.9030092364998275

Epoch: 5| Step: 7
Training loss: 1.450881838798523
Validation loss: 1.8582196094656502

Epoch: 5| Step: 8
Training loss: 1.321242094039917
Validation loss: 1.893423859791089

Epoch: 5| Step: 9
Training loss: 1.6690232753753662
Validation loss: 1.8673975518954697

Epoch: 5| Step: 10
Training loss: 0.7518433332443237
Validation loss: 1.8590272870115054

Epoch: 391| Step: 0
Training loss: 1.434926152229309
Validation loss: 1.8836831867053945

Epoch: 5| Step: 1
Training loss: 1.6943422555923462
Validation loss: 1.884831061927221

Epoch: 5| Step: 2
Training loss: 1.605318307876587
Validation loss: 1.9061574320639334

Epoch: 5| Step: 3
Training loss: 1.4037768840789795
Validation loss: 1.8904882656630648

Epoch: 5| Step: 4
Training loss: 1.6874030828475952
Validation loss: 1.891181444609037

Epoch: 5| Step: 5
Training loss: 0.8676424026489258
Validation loss: 1.8988029021088795

Epoch: 5| Step: 6
Training loss: 1.5681653022766113
Validation loss: 1.922361114973663

Epoch: 5| Step: 7
Training loss: 0.8086197972297668
Validation loss: 1.9073196752097017

Epoch: 5| Step: 8
Training loss: 1.610844373703003
Validation loss: 1.9199609987197384

Epoch: 5| Step: 9
Training loss: 1.084551453590393
Validation loss: 1.8856077655669181

Epoch: 5| Step: 10
Training loss: 1.4507495164871216
Validation loss: 1.896741497901178

Epoch: 392| Step: 0
Training loss: 1.3027821779251099
Validation loss: 1.9130381666203982

Epoch: 5| Step: 1
Training loss: 1.0219740867614746
Validation loss: 1.9153700618333713

Epoch: 5| Step: 2
Training loss: 1.1489646434783936
Validation loss: 1.8791524005192581

Epoch: 5| Step: 3
Training loss: 1.6935285329818726
Validation loss: 1.984271490445701

Epoch: 5| Step: 4
Training loss: 1.931044578552246
Validation loss: 1.9089444837262552

Epoch: 5| Step: 5
Training loss: 1.4947556257247925
Validation loss: 1.8999358607876686

Epoch: 5| Step: 6
Training loss: 1.1795225143432617
Validation loss: 1.8888829831154115

Epoch: 5| Step: 7
Training loss: 1.0495203733444214
Validation loss: 1.9085043412382885

Epoch: 5| Step: 8
Training loss: 1.6929298639297485
Validation loss: 1.9147688342678932

Epoch: 5| Step: 9
Training loss: 1.5460212230682373
Validation loss: 1.9183892806371052

Epoch: 5| Step: 10
Training loss: 1.3310651779174805
Validation loss: 1.8925098270498297

Epoch: 393| Step: 0
Training loss: 0.9801334142684937
Validation loss: 1.898490095651278

Epoch: 5| Step: 1
Training loss: 1.3254449367523193
Validation loss: 1.860347100483474

Epoch: 5| Step: 2
Training loss: 1.6666094064712524
Validation loss: 1.8872131455329157

Epoch: 5| Step: 3
Training loss: 1.7359158992767334
Validation loss: 1.8771998484929402

Epoch: 5| Step: 4
Training loss: 1.4638357162475586
Validation loss: 1.9220245858674407

Epoch: 5| Step: 5
Training loss: 1.5118305683135986
Validation loss: 1.8924872362485496

Epoch: 5| Step: 6
Training loss: 1.1652119159698486
Validation loss: 1.8829264679262716

Epoch: 5| Step: 7
Training loss: 1.825082778930664
Validation loss: 1.8696800918989285

Epoch: 5| Step: 8
Training loss: 1.567063331604004
Validation loss: 1.8597128019537976

Epoch: 5| Step: 9
Training loss: 0.9583227038383484
Validation loss: 1.8989830555454377

Epoch: 5| Step: 10
Training loss: 1.1083388328552246
Validation loss: 1.9187760981180335

Epoch: 394| Step: 0
Training loss: 1.1395233869552612
Validation loss: 1.9170181776887627

Epoch: 5| Step: 1
Training loss: 1.4489235877990723
Validation loss: 1.874386848941926

Epoch: 5| Step: 2
Training loss: 1.9150516986846924
Validation loss: 1.8287894661708544

Epoch: 5| Step: 3
Training loss: 1.5003581047058105
Validation loss: 1.8524112265597108

Epoch: 5| Step: 4
Training loss: 1.37346613407135
Validation loss: 1.8957905602711502

Epoch: 5| Step: 5
Training loss: 0.7978392243385315
Validation loss: 1.8692279310636624

Epoch: 5| Step: 6
Training loss: 1.3728272914886475
Validation loss: 1.9497681971519225

Epoch: 5| Step: 7
Training loss: 1.0867871046066284
Validation loss: 1.885045378438888

Epoch: 5| Step: 8
Training loss: 1.554398536682129
Validation loss: 1.8717715381294169

Epoch: 5| Step: 9
Training loss: 1.2880921363830566
Validation loss: 1.8848936070678055

Epoch: 5| Step: 10
Training loss: 1.5350199937820435
Validation loss: 1.8978159235369774

Epoch: 395| Step: 0
Training loss: 1.4709265232086182
Validation loss: 1.8988796229003577

Epoch: 5| Step: 1
Training loss: 1.4257328510284424
Validation loss: 1.865018024239489

Epoch: 5| Step: 2
Training loss: 1.082924246788025
Validation loss: 1.887623216516228

Epoch: 5| Step: 3
Training loss: 1.105011224746704
Validation loss: 1.8839862244103545

Epoch: 5| Step: 4
Training loss: 1.2060765027999878
Validation loss: 1.832341440262333

Epoch: 5| Step: 5
Training loss: 1.513127088546753
Validation loss: 1.8992613143818353

Epoch: 5| Step: 6
Training loss: 1.5386345386505127
Validation loss: 1.8930307075541506

Epoch: 5| Step: 7
Training loss: 1.3353221416473389
Validation loss: 1.9081979105549474

Epoch: 5| Step: 8
Training loss: 1.3459984064102173
Validation loss: 1.8847350112853511

Epoch: 5| Step: 9
Training loss: 1.4905502796173096
Validation loss: 1.9350546149797336

Epoch: 5| Step: 10
Training loss: 1.6749603748321533
Validation loss: 1.8784621069508214

Epoch: 396| Step: 0
Training loss: 0.9213685989379883
Validation loss: 1.9078711796832342

Epoch: 5| Step: 1
Training loss: 1.291555404663086
Validation loss: 1.8458893888740129

Epoch: 5| Step: 2
Training loss: 1.2582365274429321
Validation loss: 1.9319977657769316

Epoch: 5| Step: 3
Training loss: 1.7669124603271484
Validation loss: 1.8653211055263397

Epoch: 5| Step: 4
Training loss: 1.3138601779937744
Validation loss: 1.8698929535445346

Epoch: 5| Step: 5
Training loss: 1.8806126117706299
Validation loss: 1.8796334420481036

Epoch: 5| Step: 6
Training loss: 1.4709384441375732
Validation loss: 1.9188222718495194

Epoch: 5| Step: 7
Training loss: 1.3534395694732666
Validation loss: 1.9006263799564813

Epoch: 5| Step: 8
Training loss: 1.3346697092056274
Validation loss: 1.8897045248298234

Epoch: 5| Step: 9
Training loss: 1.2504678964614868
Validation loss: 1.8768905388411654

Epoch: 5| Step: 10
Training loss: 1.329824447631836
Validation loss: 1.8950582909327682

Epoch: 397| Step: 0
Training loss: 1.6547071933746338
Validation loss: 1.9182837060702744

Epoch: 5| Step: 1
Training loss: 1.6373096704483032
Validation loss: 1.8868849431314776

Epoch: 5| Step: 2
Training loss: 1.2212917804718018
Validation loss: 1.9518241190141248

Epoch: 5| Step: 3
Training loss: 1.2711893320083618
Validation loss: 1.8920744875425934

Epoch: 5| Step: 4
Training loss: 0.6069652438163757
Validation loss: 1.9346512991894957

Epoch: 5| Step: 5
Training loss: 1.1231991052627563
Validation loss: 1.902650430638303

Epoch: 5| Step: 6
Training loss: 1.4588254690170288
Validation loss: 1.9123864801981116

Epoch: 5| Step: 7
Training loss: 1.7975353002548218
Validation loss: 1.8871808398154475

Epoch: 5| Step: 8
Training loss: 1.4008066654205322
Validation loss: 1.9083920871057818

Epoch: 5| Step: 9
Training loss: 1.3856563568115234
Validation loss: 1.8744424158527004

Epoch: 5| Step: 10
Training loss: 1.5107107162475586
Validation loss: 1.8829987869467786

Epoch: 398| Step: 0
Training loss: 1.242297887802124
Validation loss: 1.8927704570113972

Epoch: 5| Step: 1
Training loss: 1.1302883625030518
Validation loss: 1.8747022190401632

Epoch: 5| Step: 2
Training loss: 1.653061866760254
Validation loss: 1.8981624931417487

Epoch: 5| Step: 3
Training loss: 0.8559735417366028
Validation loss: 1.9060577525887439

Epoch: 5| Step: 4
Training loss: 1.2673835754394531
Validation loss: 1.9261801012100712

Epoch: 5| Step: 5
Training loss: 1.3472094535827637
Validation loss: 1.9240590551848054

Epoch: 5| Step: 6
Training loss: 1.235257625579834
Validation loss: 1.8459657097375521

Epoch: 5| Step: 7
Training loss: 1.734716773033142
Validation loss: 1.9056103985796693

Epoch: 5| Step: 8
Training loss: 1.706017255783081
Validation loss: 1.9158285689610306

Epoch: 5| Step: 9
Training loss: 1.4329754114151
Validation loss: 1.8683699664249216

Epoch: 5| Step: 10
Training loss: 1.5865758657455444
Validation loss: 1.8620092612440868

Epoch: 399| Step: 0
Training loss: 1.45650315284729
Validation loss: 1.8759334779554797

Epoch: 5| Step: 1
Training loss: 1.4294451475143433
Validation loss: 1.8452351221474268

Epoch: 5| Step: 2
Training loss: 1.4620494842529297
Validation loss: 1.8875150539541756

Epoch: 5| Step: 3
Training loss: 1.376049280166626
Validation loss: 1.9034824012428202

Epoch: 5| Step: 4
Training loss: 1.227220892906189
Validation loss: 1.9156147882502566

Epoch: 5| Step: 5
Training loss: 1.4665244817733765
Validation loss: 1.9276160706755936

Epoch: 5| Step: 6
Training loss: 1.2781871557235718
Validation loss: 1.924295433105961

Epoch: 5| Step: 7
Training loss: 1.1726410388946533
Validation loss: 1.8868590003700667

Epoch: 5| Step: 8
Training loss: 1.7724977731704712
Validation loss: 1.9193096135252266

Epoch: 5| Step: 9
Training loss: 1.2828543186187744
Validation loss: 1.9056700929518668

Epoch: 5| Step: 10
Training loss: 1.141620397567749
Validation loss: 1.9095386664072673

Epoch: 400| Step: 0
Training loss: 1.413419485092163
Validation loss: 1.884814553363349

Epoch: 5| Step: 1
Training loss: 1.0350452661514282
Validation loss: 1.9261890329340452

Epoch: 5| Step: 2
Training loss: 1.2577731609344482
Validation loss: 1.9187650244723085

Epoch: 5| Step: 3
Training loss: 1.4050530195236206
Validation loss: 1.8900122257970995

Epoch: 5| Step: 4
Training loss: 0.9992586970329285
Validation loss: 1.9156435074344758

Epoch: 5| Step: 5
Training loss: 1.671633005142212
Validation loss: 1.8910192225569038

Epoch: 5| Step: 6
Training loss: 1.4256346225738525
Validation loss: 1.902116483257663

Epoch: 5| Step: 7
Training loss: 1.8980443477630615
Validation loss: 1.8917896452770437

Epoch: 5| Step: 8
Training loss: 1.3685548305511475
Validation loss: 1.9135540275163547

Epoch: 5| Step: 9
Training loss: 2.054468870162964
Validation loss: 1.9109411572897306

Epoch: 5| Step: 10
Training loss: 0.7577098608016968
Validation loss: 1.8914886187481623

Epoch: 401| Step: 0
Training loss: 1.3058180809020996
Validation loss: 1.8843873867424585

Epoch: 5| Step: 1
Training loss: 1.811663031578064
Validation loss: 1.9258458845077022

Epoch: 5| Step: 2
Training loss: 1.8290703296661377
Validation loss: 1.8337451296467935

Epoch: 5| Step: 3
Training loss: 0.7252639532089233
Validation loss: 1.936594242690712

Epoch: 5| Step: 4
Training loss: 0.9921929240226746
Validation loss: 1.8746169100525558

Epoch: 5| Step: 5
Training loss: 1.385331392288208
Validation loss: 1.9032784290211175

Epoch: 5| Step: 6
Training loss: 1.2000582218170166
Validation loss: 1.8881648945552048

Epoch: 5| Step: 7
Training loss: 1.408676266670227
Validation loss: 1.86041517924237

Epoch: 5| Step: 8
Training loss: 1.8393356800079346
Validation loss: 1.8679374212859778

Epoch: 5| Step: 9
Training loss: 1.2050552368164062
Validation loss: 1.9083918063871321

Epoch: 5| Step: 10
Training loss: 1.3833272457122803
Validation loss: 1.9349175319876721

Epoch: 402| Step: 0
Training loss: 1.8474515676498413
Validation loss: 1.8756032900143695

Epoch: 5| Step: 1
Training loss: 1.4892735481262207
Validation loss: 1.8993586212076166

Epoch: 5| Step: 2
Training loss: 1.7176799774169922
Validation loss: 1.9018628981805616

Epoch: 5| Step: 3
Training loss: 1.075606346130371
Validation loss: 1.9025579934479089

Epoch: 5| Step: 4
Training loss: 1.0977214574813843
Validation loss: 1.9064660367145334

Epoch: 5| Step: 5
Training loss: 1.2434132099151611
Validation loss: 1.8583993309287614

Epoch: 5| Step: 6
Training loss: 1.481792688369751
Validation loss: 1.9313569017635879

Epoch: 5| Step: 7
Training loss: 1.3883979320526123
Validation loss: 1.8931738022835023

Epoch: 5| Step: 8
Training loss: 1.903363823890686
Validation loss: 1.8691256405204855

Epoch: 5| Step: 9
Training loss: 1.0645126104354858
Validation loss: 1.8989553092628397

Epoch: 5| Step: 10
Training loss: 0.6462774872779846
Validation loss: 1.906924323369098

Epoch: 403| Step: 0
Training loss: 1.12057626247406
Validation loss: 1.9052158606949674

Epoch: 5| Step: 1
Training loss: 1.2365243434906006
Validation loss: 1.869791889703402

Epoch: 5| Step: 2
Training loss: 1.5607597827911377
Validation loss: 1.9222687367470033

Epoch: 5| Step: 3
Training loss: 1.591931939125061
Validation loss: 1.8909560890607937

Epoch: 5| Step: 4
Training loss: 1.0398147106170654
Validation loss: 1.9074889306099183

Epoch: 5| Step: 5
Training loss: 2.564006805419922
Validation loss: 1.8870520860918107

Epoch: 5| Step: 6
Training loss: 1.3294181823730469
Validation loss: 1.8991740301091184

Epoch: 5| Step: 7
Training loss: 0.900607705116272
Validation loss: 1.9022819611334032

Epoch: 5| Step: 8
Training loss: 1.154903769493103
Validation loss: 1.9410579563469015

Epoch: 5| Step: 9
Training loss: 1.1914598941802979
Validation loss: 1.910640803716516

Epoch: 5| Step: 10
Training loss: 1.2383240461349487
Validation loss: 1.9375380751907185

Epoch: 404| Step: 0
Training loss: 1.2050080299377441
Validation loss: 1.9682148502719017

Epoch: 5| Step: 1
Training loss: 1.369097352027893
Validation loss: 1.8763735153341805

Epoch: 5| Step: 2
Training loss: 1.5074729919433594
Validation loss: 1.9214302057861

Epoch: 5| Step: 3
Training loss: 1.9525692462921143
Validation loss: 1.8742649862843175

Epoch: 5| Step: 4
Training loss: 1.4239963293075562
Validation loss: 1.91364884889254

Epoch: 5| Step: 5
Training loss: 1.556154727935791
Validation loss: 1.8934057066517491

Epoch: 5| Step: 6
Training loss: 1.2855757474899292
Validation loss: 1.907895149723176

Epoch: 5| Step: 7
Training loss: 1.5385849475860596
Validation loss: 1.8965830905463106

Epoch: 5| Step: 8
Training loss: 1.2132432460784912
Validation loss: 1.8731638180312289

Epoch: 5| Step: 9
Training loss: 0.8896015286445618
Validation loss: 1.9003013333966654

Epoch: 5| Step: 10
Training loss: 0.9712894558906555
Validation loss: 1.9024418682180426

Epoch: 405| Step: 0
Training loss: 0.9548673629760742
Validation loss: 1.920597267407243

Epoch: 5| Step: 1
Training loss: 1.5633822679519653
Validation loss: 1.910105884716075

Epoch: 5| Step: 2
Training loss: 1.5261681079864502
Validation loss: 1.8944777673290623

Epoch: 5| Step: 3
Training loss: 1.7045120000839233
Validation loss: 1.9025472184663177

Epoch: 5| Step: 4
Training loss: 1.5178254842758179
Validation loss: 1.927458433694737

Epoch: 5| Step: 5
Training loss: 1.3297970294952393
Validation loss: 1.9047604888998053

Epoch: 5| Step: 6
Training loss: 1.275345802307129
Validation loss: 1.8851870439385856

Epoch: 5| Step: 7
Training loss: 1.377695083618164
Validation loss: 1.9225159639953284

Epoch: 5| Step: 8
Training loss: 0.7532207369804382
Validation loss: 1.8503331240787302

Epoch: 5| Step: 9
Training loss: 1.4573452472686768
Validation loss: 1.9259186611380628

Epoch: 5| Step: 10
Training loss: 1.417006254196167
Validation loss: 1.9083597403700634

Epoch: 406| Step: 0
Training loss: 1.1147323846817017
Validation loss: 1.8932648820261802

Epoch: 5| Step: 1
Training loss: 1.3309252262115479
Validation loss: 1.945217219732141

Epoch: 5| Step: 2
Training loss: 1.2814306020736694
Validation loss: 1.9208220551090855

Epoch: 5| Step: 3
Training loss: 1.7946780920028687
Validation loss: 1.9352426990385978

Epoch: 5| Step: 4
Training loss: 1.3879112005233765
Validation loss: 1.9297770082309682

Epoch: 5| Step: 5
Training loss: 1.3055729866027832
Validation loss: 1.9300209732465847

Epoch: 5| Step: 6
Training loss: 1.5242828130722046
Validation loss: 1.9309077262878418

Epoch: 5| Step: 7
Training loss: 1.3771705627441406
Validation loss: 1.8715723970884919

Epoch: 5| Step: 8
Training loss: 1.379635214805603
Validation loss: 1.9295274672969696

Epoch: 5| Step: 9
Training loss: 1.223292350769043
Validation loss: 1.912933426518594

Epoch: 5| Step: 10
Training loss: 1.0716887712478638
Validation loss: 1.916400582559647

Epoch: 407| Step: 0
Training loss: 1.6055948734283447
Validation loss: 1.865811191579347

Epoch: 5| Step: 1
Training loss: 0.9721226692199707
Validation loss: 1.9079465737906836

Epoch: 5| Step: 2
Training loss: 1.405750036239624
Validation loss: 1.9126516516490648

Epoch: 5| Step: 3
Training loss: 0.8505255579948425
Validation loss: 1.886148747577462

Epoch: 5| Step: 4
Training loss: 1.335520625114441
Validation loss: 1.9124306760808474

Epoch: 5| Step: 5
Training loss: 1.2528512477874756
Validation loss: 1.853684740681802

Epoch: 5| Step: 6
Training loss: 1.9773677587509155
Validation loss: 1.918288533405591

Epoch: 5| Step: 7
Training loss: 1.2089847326278687
Validation loss: 1.851955513800344

Epoch: 5| Step: 8
Training loss: 1.1571000814437866
Validation loss: 1.8646750527043496

Epoch: 5| Step: 9
Training loss: 2.023746967315674
Validation loss: 1.8767164650783743

Epoch: 5| Step: 10
Training loss: 0.9909683465957642
Validation loss: 1.8824809494838919

Epoch: 408| Step: 0
Training loss: 1.0841377973556519
Validation loss: 1.8863992562858007

Epoch: 5| Step: 1
Training loss: 1.1559734344482422
Validation loss: 1.9082973977570892

Epoch: 5| Step: 2
Training loss: 1.2319508790969849
Validation loss: 1.92020595201882

Epoch: 5| Step: 3
Training loss: 1.433308482170105
Validation loss: 1.8871438246901318

Epoch: 5| Step: 4
Training loss: 1.0153992176055908
Validation loss: 1.9242576655521189

Epoch: 5| Step: 5
Training loss: 0.9869807958602905
Validation loss: 1.8992404373743201

Epoch: 5| Step: 6
Training loss: 2.0761375427246094
Validation loss: 1.9303045900919105

Epoch: 5| Step: 7
Training loss: 1.480602502822876
Validation loss: 1.8823504909392326

Epoch: 5| Step: 8
Training loss: 1.894280195236206
Validation loss: 1.871488026393357

Epoch: 5| Step: 9
Training loss: 1.0873116254806519
Validation loss: 1.9171458751924577

Epoch: 5| Step: 10
Training loss: 1.4048103094100952
Validation loss: 1.8941507711205432

Epoch: 409| Step: 0
Training loss: 1.3842896223068237
Validation loss: 1.92753646450658

Epoch: 5| Step: 1
Training loss: 1.779710054397583
Validation loss: 1.9039567747423727

Epoch: 5| Step: 2
Training loss: 1.5447747707366943
Validation loss: 1.9334545417498517

Epoch: 5| Step: 3
Training loss: 1.2686725854873657
Validation loss: 1.932860371887043

Epoch: 5| Step: 4
Training loss: 0.9224506616592407
Validation loss: 1.9278162358909525

Epoch: 5| Step: 5
Training loss: 1.262007713317871
Validation loss: 1.9376270822299424

Epoch: 5| Step: 6
Training loss: 0.9094569087028503
Validation loss: 1.8909677510620446

Epoch: 5| Step: 7
Training loss: 1.2527663707733154
Validation loss: 1.8825849345935288

Epoch: 5| Step: 8
Training loss: 1.6801830530166626
Validation loss: 1.9066885799489997

Epoch: 5| Step: 9
Training loss: 1.836670160293579
Validation loss: 1.8839263428923905

Epoch: 5| Step: 10
Training loss: 1.1113219261169434
Validation loss: 1.8841877445097892

Epoch: 410| Step: 0
Training loss: 1.103347659111023
Validation loss: 1.8881886774493801

Epoch: 5| Step: 1
Training loss: 1.7637441158294678
Validation loss: 1.8792494573900778

Epoch: 5| Step: 2
Training loss: 1.4239866733551025
Validation loss: 1.9068745515679801

Epoch: 5| Step: 3
Training loss: 1.4144532680511475
Validation loss: 1.8828731095919045

Epoch: 5| Step: 4
Training loss: 1.2615540027618408
Validation loss: 1.8704506504920222

Epoch: 5| Step: 5
Training loss: 1.0172312259674072
Validation loss: 1.8855611560165242

Epoch: 5| Step: 6
Training loss: 1.6123498678207397
Validation loss: 1.9032508993661532

Epoch: 5| Step: 7
Training loss: 0.8037430644035339
Validation loss: 1.9204396278627458

Epoch: 5| Step: 8
Training loss: 1.8804686069488525
Validation loss: 1.9153675571564706

Epoch: 5| Step: 9
Training loss: 0.8370596170425415
Validation loss: 1.9348491750737673

Epoch: 5| Step: 10
Training loss: 1.526708722114563
Validation loss: 1.8584303214985838

Epoch: 411| Step: 0
Training loss: 1.3469479084014893
Validation loss: 1.9173499179142777

Epoch: 5| Step: 1
Training loss: 1.240134596824646
Validation loss: 1.9152672393347627

Epoch: 5| Step: 2
Training loss: 1.0161633491516113
Validation loss: 1.8515480192758704

Epoch: 5| Step: 3
Training loss: 1.3481781482696533
Validation loss: 1.921162482230894

Epoch: 5| Step: 4
Training loss: 1.2389494180679321
Validation loss: 1.914355677943076

Epoch: 5| Step: 5
Training loss: 1.3380699157714844
Validation loss: 1.8827916127379223

Epoch: 5| Step: 6
Training loss: 1.7536369562149048
Validation loss: 1.8666258499186525

Epoch: 5| Step: 7
Training loss: 1.3408091068267822
Validation loss: 1.8670429337409236

Epoch: 5| Step: 8
Training loss: 1.7935794591903687
Validation loss: 1.8996859083893478

Epoch: 5| Step: 9
Training loss: 1.2892334461212158
Validation loss: 1.8950377279712307

Epoch: 5| Step: 10
Training loss: 1.4629645347595215
Validation loss: 1.9218872477931361

Epoch: 412| Step: 0
Training loss: 1.0922577381134033
Validation loss: 1.8943995916715233

Epoch: 5| Step: 1
Training loss: 1.4534612894058228
Validation loss: 1.8707846556940386

Epoch: 5| Step: 2
Training loss: 1.269468069076538
Validation loss: 1.897403468367874

Epoch: 5| Step: 3
Training loss: 1.0932810306549072
Validation loss: 1.8770756695860176

Epoch: 5| Step: 4
Training loss: 1.7354838848114014
Validation loss: 1.8740557624447731

Epoch: 5| Step: 5
Training loss: 1.3878371715545654
Validation loss: 1.8517154134729856

Epoch: 5| Step: 6
Training loss: 1.2608155012130737
Validation loss: 1.9075547110649846

Epoch: 5| Step: 7
Training loss: 0.9766660928726196
Validation loss: 1.8845065729592436

Epoch: 5| Step: 8
Training loss: 1.703759789466858
Validation loss: 1.8840075692822855

Epoch: 5| Step: 9
Training loss: 1.7117542028427124
Validation loss: 1.8907776750544065

Epoch: 5| Step: 10
Training loss: 1.0543155670166016
Validation loss: 1.8876059491147277

Epoch: 413| Step: 0
Training loss: 0.95494145154953
Validation loss: 1.8784059773209274

Epoch: 5| Step: 1
Training loss: 1.1913375854492188
Validation loss: 1.8862032659592167

Epoch: 5| Step: 2
Training loss: 1.1437318325042725
Validation loss: 1.9068248425760577

Epoch: 5| Step: 3
Training loss: 1.6551005840301514
Validation loss: 1.8828141484209286

Epoch: 5| Step: 4
Training loss: 1.3944283723831177
Validation loss: 1.8994335615506737

Epoch: 5| Step: 5
Training loss: 1.2752742767333984
Validation loss: 1.8801773927545036

Epoch: 5| Step: 6
Training loss: 1.2953401803970337
Validation loss: 1.8996967359255719

Epoch: 5| Step: 7
Training loss: 0.9226896166801453
Validation loss: 1.8861513189090195

Epoch: 5| Step: 8
Training loss: 1.3293375968933105
Validation loss: 1.910006405204855

Epoch: 5| Step: 9
Training loss: 2.027820110321045
Validation loss: 1.9185420761826217

Epoch: 5| Step: 10
Training loss: 1.5426870584487915
Validation loss: 1.912606728974209

Epoch: 414| Step: 0
Training loss: 1.2785733938217163
Validation loss: 1.891224084361907

Epoch: 5| Step: 1
Training loss: 1.5268042087554932
Validation loss: 1.9518987799203524

Epoch: 5| Step: 2
Training loss: 0.8955694437026978
Validation loss: 1.942069322832169

Epoch: 5| Step: 3
Training loss: 1.5968992710113525
Validation loss: 1.8974142766767932

Epoch: 5| Step: 4
Training loss: 1.0969372987747192
Validation loss: 1.8748699567651237

Epoch: 5| Step: 5
Training loss: 1.0803571939468384
Validation loss: 1.9048544258199713

Epoch: 5| Step: 6
Training loss: 1.4844318628311157
Validation loss: 1.8617266737004763

Epoch: 5| Step: 7
Training loss: 1.3695690631866455
Validation loss: 1.8955942712804323

Epoch: 5| Step: 8
Training loss: 2.2830119132995605
Validation loss: 1.9263542647002845

Epoch: 5| Step: 9
Training loss: 1.186250925064087
Validation loss: 1.8831645814321374

Epoch: 5| Step: 10
Training loss: 1.0848159790039062
Validation loss: 1.8943841906004055

Epoch: 415| Step: 0
Training loss: 1.2439913749694824
Validation loss: 1.8646550434891895

Epoch: 5| Step: 1
Training loss: 1.3034522533416748
Validation loss: 1.8788641024661321

Epoch: 5| Step: 2
Training loss: 1.7350355386734009
Validation loss: 1.8770587111032138

Epoch: 5| Step: 3
Training loss: 1.7281776666641235
Validation loss: 1.8628344638373262

Epoch: 5| Step: 4
Training loss: 0.8179910778999329
Validation loss: 1.8566888224694036

Epoch: 5| Step: 5
Training loss: 0.7410743832588196
Validation loss: 1.9142134151151102

Epoch: 5| Step: 6
Training loss: 1.3076846599578857
Validation loss: 1.9184264072807886

Epoch: 5| Step: 7
Training loss: 1.4457676410675049
Validation loss: 1.884539866960177

Epoch: 5| Step: 8
Training loss: 1.835304856300354
Validation loss: 1.9196891297576248

Epoch: 5| Step: 9
Training loss: 1.166614294052124
Validation loss: 1.9079828723784416

Epoch: 5| Step: 10
Training loss: 1.4182751178741455
Validation loss: 1.9225824340697257

Epoch: 416| Step: 0
Training loss: 1.3202539682388306
Validation loss: 1.9010055116427842

Epoch: 5| Step: 1
Training loss: 1.3587175607681274
Validation loss: 1.9266429331994825

Epoch: 5| Step: 2
Training loss: 1.4643056392669678
Validation loss: 1.926530663685132

Epoch: 5| Step: 3
Training loss: 1.921424150466919
Validation loss: 1.9147671704651208

Epoch: 5| Step: 4
Training loss: 1.3008699417114258
Validation loss: 1.9045954340247697

Epoch: 5| Step: 5
Training loss: 1.5528843402862549
Validation loss: 1.8792753245240899

Epoch: 5| Step: 6
Training loss: 0.8722556829452515
Validation loss: 1.8580204889338503

Epoch: 5| Step: 7
Training loss: 1.3733704090118408
Validation loss: 1.9012883081231067

Epoch: 5| Step: 8
Training loss: 1.36039137840271
Validation loss: 1.9037302963195308

Epoch: 5| Step: 9
Training loss: 1.193061351776123
Validation loss: 1.8876059926966184

Epoch: 5| Step: 10
Training loss: 1.3586138486862183
Validation loss: 1.8537142507491573

Epoch: 417| Step: 0
Training loss: 1.726802110671997
Validation loss: 1.862653273408131

Epoch: 5| Step: 1
Training loss: 1.070617437362671
Validation loss: 1.8878224024208643

Epoch: 5| Step: 2
Training loss: 0.8778012990951538
Validation loss: 1.896627313347273

Epoch: 5| Step: 3
Training loss: 1.2168906927108765
Validation loss: 1.8599187340787662

Epoch: 5| Step: 4
Training loss: 0.9446136355400085
Validation loss: 1.8606141408284504

Epoch: 5| Step: 5
Training loss: 1.1140600442886353
Validation loss: 1.905834840190026

Epoch: 5| Step: 6
Training loss: 1.6142170429229736
Validation loss: 1.905037961980348

Epoch: 5| Step: 7
Training loss: 1.504969596862793
Validation loss: 1.8749323801327777

Epoch: 5| Step: 8
Training loss: 1.2106553316116333
Validation loss: 1.8930247983624857

Epoch: 5| Step: 9
Training loss: 1.9899864196777344
Validation loss: 1.8902282817389375

Epoch: 5| Step: 10
Training loss: 1.394250512123108
Validation loss: 1.9149236935441212

Epoch: 418| Step: 0
Training loss: 1.137554407119751
Validation loss: 1.8929801102607482

Epoch: 5| Step: 1
Training loss: 1.4883579015731812
Validation loss: 1.9071884462910313

Epoch: 5| Step: 2
Training loss: 1.1027871370315552
Validation loss: 1.9040637580297326

Epoch: 5| Step: 3
Training loss: 1.281721591949463
Validation loss: 1.9106177706872263

Epoch: 5| Step: 4
Training loss: 1.3767082691192627
Validation loss: 1.8878513241326937

Epoch: 5| Step: 5
Training loss: 1.6578795909881592
Validation loss: 1.9134293948450396

Epoch: 5| Step: 6
Training loss: 1.2944358587265015
Validation loss: 1.8884791404970231

Epoch: 5| Step: 7
Training loss: 1.4948736429214478
Validation loss: 1.9106357879536127

Epoch: 5| Step: 8
Training loss: 1.3899295330047607
Validation loss: 1.8508063734218638

Epoch: 5| Step: 9
Training loss: 1.2129285335540771
Validation loss: 1.8606276114781697

Epoch: 5| Step: 10
Training loss: 1.0875157117843628
Validation loss: 1.9324117270849084

Epoch: 419| Step: 0
Training loss: 1.2681806087493896
Validation loss: 1.9057616392771404

Epoch: 5| Step: 1
Training loss: 1.2999284267425537
Validation loss: 1.8773901154918056

Epoch: 5| Step: 2
Training loss: 1.4961084127426147
Validation loss: 1.9344103131242978

Epoch: 5| Step: 3
Training loss: 1.4540811777114868
Validation loss: 1.9521827082480154

Epoch: 5| Step: 4
Training loss: 1.7196331024169922
Validation loss: 1.984176084559451

Epoch: 5| Step: 5
Training loss: 0.8863517642021179
Validation loss: 1.9491239798966276

Epoch: 5| Step: 6
Training loss: 1.2175450325012207
Validation loss: 1.95023666145981

Epoch: 5| Step: 7
Training loss: 1.402607798576355
Validation loss: 1.940186788958888

Epoch: 5| Step: 8
Training loss: 1.207282304763794
Validation loss: 1.9211505997565486

Epoch: 5| Step: 9
Training loss: 1.2857542037963867
Validation loss: 1.9104118859896095

Epoch: 5| Step: 10
Training loss: 1.5748512744903564
Validation loss: 1.8828590659685032

Epoch: 420| Step: 0
Training loss: 1.148931860923767
Validation loss: 1.913221513071368

Epoch: 5| Step: 1
Training loss: 2.0194342136383057
Validation loss: 1.9099655792277346

Epoch: 5| Step: 2
Training loss: 1.067474126815796
Validation loss: 1.914203909135634

Epoch: 5| Step: 3
Training loss: 0.885369598865509
Validation loss: 1.8715457839350547

Epoch: 5| Step: 4
Training loss: 1.5679343938827515
Validation loss: 1.8809299084448046

Epoch: 5| Step: 5
Training loss: 1.1740739345550537
Validation loss: 1.8916459724467287

Epoch: 5| Step: 6
Training loss: 1.6334543228149414
Validation loss: 1.8481714699857978

Epoch: 5| Step: 7
Training loss: 1.1832252740859985
Validation loss: 1.8658311341398506

Epoch: 5| Step: 8
Training loss: 1.0400307178497314
Validation loss: 1.8989809661783197

Epoch: 5| Step: 9
Training loss: 1.6581361293792725
Validation loss: 1.9382843625160955

Epoch: 5| Step: 10
Training loss: 1.2191343307495117
Validation loss: 1.922861394061837

Epoch: 421| Step: 0
Training loss: 1.341785192489624
Validation loss: 1.8823559566210675

Epoch: 5| Step: 1
Training loss: 2.1960525512695312
Validation loss: 1.884082906989641

Epoch: 5| Step: 2
Training loss: 0.7165988683700562
Validation loss: 1.8727553531687746

Epoch: 5| Step: 3
Training loss: 0.9482367634773254
Validation loss: 1.946912762939289

Epoch: 5| Step: 4
Training loss: 2.084416627883911
Validation loss: 1.8486898522223196

Epoch: 5| Step: 5
Training loss: 0.798704206943512
Validation loss: 1.904698133468628

Epoch: 5| Step: 6
Training loss: 1.2735726833343506
Validation loss: 1.9049474334204068

Epoch: 5| Step: 7
Training loss: 1.2513456344604492
Validation loss: 1.9099168444192538

Epoch: 5| Step: 8
Training loss: 1.3184624910354614
Validation loss: 1.9502397634649788

Epoch: 5| Step: 9
Training loss: 1.1280333995819092
Validation loss: 1.8964927734867219

Epoch: 5| Step: 10
Training loss: 1.149512767791748
Validation loss: 1.8942421764455817

Epoch: 422| Step: 0
Training loss: 1.4548677206039429
Validation loss: 1.9301093214301652

Epoch: 5| Step: 1
Training loss: 1.250798225402832
Validation loss: 1.9139678221876903

Epoch: 5| Step: 2
Training loss: 1.263001799583435
Validation loss: 1.9435700498601443

Epoch: 5| Step: 3
Training loss: 1.0722624063491821
Validation loss: 1.89203635210632

Epoch: 5| Step: 4
Training loss: 1.5513942241668701
Validation loss: 1.9138951288756503

Epoch: 5| Step: 5
Training loss: 1.6241912841796875
Validation loss: 1.893543033189671

Epoch: 5| Step: 6
Training loss: 1.5157111883163452
Validation loss: 1.9241641195871497

Epoch: 5| Step: 7
Training loss: 1.4524049758911133
Validation loss: 1.8942516273067844

Epoch: 5| Step: 8
Training loss: 0.9767032861709595
Validation loss: 1.8608461926060338

Epoch: 5| Step: 9
Training loss: 1.3422225713729858
Validation loss: 1.8710976236610002

Epoch: 5| Step: 10
Training loss: 0.9487020969390869
Validation loss: 1.8922268421419206

Epoch: 423| Step: 0
Training loss: 1.3951120376586914
Validation loss: 1.840305265559945

Epoch: 5| Step: 1
Training loss: 2.0613625049591064
Validation loss: 1.901830247653428

Epoch: 5| Step: 2
Training loss: 1.7528629302978516
Validation loss: 1.9170864294934016

Epoch: 5| Step: 3
Training loss: 1.2268829345703125
Validation loss: 1.8906600962403

Epoch: 5| Step: 4
Training loss: 0.7715002298355103
Validation loss: 1.8758978471961072

Epoch: 5| Step: 5
Training loss: 0.8226229548454285
Validation loss: 1.9025564193725586

Epoch: 5| Step: 6
Training loss: 1.1674108505249023
Validation loss: 1.9068497252720658

Epoch: 5| Step: 7
Training loss: 1.629035234451294
Validation loss: 1.8596785594058294

Epoch: 5| Step: 8
Training loss: 1.1406383514404297
Validation loss: 1.876240280366713

Epoch: 5| Step: 9
Training loss: 1.2615392208099365
Validation loss: 1.8910207261321366

Epoch: 5| Step: 10
Training loss: 1.2497464418411255
Validation loss: 1.8930200838273572

Epoch: 424| Step: 0
Training loss: 1.429703950881958
Validation loss: 1.8754833513690579

Epoch: 5| Step: 1
Training loss: 1.3355213403701782
Validation loss: 1.868036893106276

Epoch: 5| Step: 2
Training loss: 1.6938447952270508
Validation loss: 1.922825389010932

Epoch: 5| Step: 3
Training loss: 1.5685776472091675
Validation loss: 1.8705608062846686

Epoch: 5| Step: 4
Training loss: 1.6823898553848267
Validation loss: 1.8944281967737342

Epoch: 5| Step: 5
Training loss: 1.4039117097854614
Validation loss: 1.8874607778364612

Epoch: 5| Step: 6
Training loss: 1.635205864906311
Validation loss: 1.9029413128411898

Epoch: 5| Step: 7
Training loss: 1.003953218460083
Validation loss: 1.8806238276984102

Epoch: 5| Step: 8
Training loss: 0.8689979314804077
Validation loss: 1.8972243839694607

Epoch: 5| Step: 9
Training loss: 0.9740990400314331
Validation loss: 1.886346194051927

Epoch: 5| Step: 10
Training loss: 0.9268877506256104
Validation loss: 1.871249116877074

Epoch: 425| Step: 0
Training loss: 1.3270204067230225
Validation loss: 1.8910715579986572

Epoch: 5| Step: 1
Training loss: 1.2253494262695312
Validation loss: 1.8770756542041738

Epoch: 5| Step: 2
Training loss: 1.1816465854644775
Validation loss: 1.923342297154088

Epoch: 5| Step: 3
Training loss: 1.6483796834945679
Validation loss: 1.8705112690566688

Epoch: 5| Step: 4
Training loss: 1.1546480655670166
Validation loss: 1.8944015990021408

Epoch: 5| Step: 5
Training loss: 1.366330862045288
Validation loss: 1.9000962588094896

Epoch: 5| Step: 6
Training loss: 1.1121933460235596
Validation loss: 1.8934930280972553

Epoch: 5| Step: 7
Training loss: 1.3850057125091553
Validation loss: 1.903816960191214

Epoch: 5| Step: 8
Training loss: 1.1647049188613892
Validation loss: 1.933594116600611

Epoch: 5| Step: 9
Training loss: 1.7161247730255127
Validation loss: 1.9222028101644208

Epoch: 5| Step: 10
Training loss: 1.198047399520874
Validation loss: 1.9114416055781867

Epoch: 426| Step: 0
Training loss: 1.2630364894866943
Validation loss: 1.906108581891624

Epoch: 5| Step: 1
Training loss: 1.6464719772338867
Validation loss: 1.8708112650020148

Epoch: 5| Step: 2
Training loss: 1.2234004735946655
Validation loss: 1.886923724605191

Epoch: 5| Step: 3
Training loss: 1.8487269878387451
Validation loss: 1.8940747104665285

Epoch: 5| Step: 4
Training loss: 1.1934115886688232
Validation loss: 1.9439892615041425

Epoch: 5| Step: 5
Training loss: 1.1657254695892334
Validation loss: 1.889364977036753

Epoch: 5| Step: 6
Training loss: 0.8830879926681519
Validation loss: 1.8657357192808581

Epoch: 5| Step: 7
Training loss: 1.4512038230895996
Validation loss: 1.91007907928959

Epoch: 5| Step: 8
Training loss: 1.5760208368301392
Validation loss: 1.8703002596414218

Epoch: 5| Step: 9
Training loss: 0.9735718965530396
Validation loss: 1.9188982107306038

Epoch: 5| Step: 10
Training loss: 1.0905708074569702
Validation loss: 1.8909105229121383

Epoch: 427| Step: 0
Training loss: 1.234602689743042
Validation loss: 1.8862766258178219

Epoch: 5| Step: 1
Training loss: 1.7731492519378662
Validation loss: 1.8549495140711467

Epoch: 5| Step: 2
Training loss: 1.1524063348770142
Validation loss: 1.911842921728729

Epoch: 5| Step: 3
Training loss: 1.4997060298919678
Validation loss: 1.8648267663935179

Epoch: 5| Step: 4
Training loss: 1.6445375680923462
Validation loss: 1.8839867166293565

Epoch: 5| Step: 5
Training loss: 0.4620998799800873
Validation loss: 1.9243496259053547

Epoch: 5| Step: 6
Training loss: 1.6186342239379883
Validation loss: 1.9035424288883005

Epoch: 5| Step: 7
Training loss: 0.9311119318008423
Validation loss: 1.8757738810713573

Epoch: 5| Step: 8
Training loss: 1.2443468570709229
Validation loss: 1.8995399359733827

Epoch: 5| Step: 9
Training loss: 1.7667057514190674
Validation loss: 1.931126506097855

Epoch: 5| Step: 10
Training loss: 1.3263037204742432
Validation loss: 1.8888818948499617

Epoch: 428| Step: 0
Training loss: 1.2033123970031738
Validation loss: 1.8846006111432148

Epoch: 5| Step: 1
Training loss: 0.8451229929924011
Validation loss: 1.8859907247686898

Epoch: 5| Step: 2
Training loss: 1.098210334777832
Validation loss: 1.876706297679614

Epoch: 5| Step: 3
Training loss: 1.8773682117462158
Validation loss: 1.8794554318151167

Epoch: 5| Step: 4
Training loss: 0.781165599822998
Validation loss: 1.9038890318203998

Epoch: 5| Step: 5
Training loss: 1.3086401224136353
Validation loss: 1.9001834546366045

Epoch: 5| Step: 6
Training loss: 1.440811038017273
Validation loss: 1.8735176491481003

Epoch: 5| Step: 7
Training loss: 1.375706434249878
Validation loss: 1.835883294382403

Epoch: 5| Step: 8
Training loss: 1.15206778049469
Validation loss: 1.8357309295285134

Epoch: 5| Step: 9
Training loss: 1.4853790998458862
Validation loss: 1.9211508868842997

Epoch: 5| Step: 10
Training loss: 1.8845782279968262
Validation loss: 1.885446915062525

Epoch: 429| Step: 0
Training loss: 1.46053147315979
Validation loss: 1.908611161734468

Epoch: 5| Step: 1
Training loss: 1.010298728942871
Validation loss: 1.8926428389805618

Epoch: 5| Step: 2
Training loss: 1.3938403129577637
Validation loss: 1.9152737573910785

Epoch: 5| Step: 3
Training loss: 1.476567268371582
Validation loss: 1.9251633677431332

Epoch: 5| Step: 4
Training loss: 0.8981901407241821
Validation loss: 1.901803405054154

Epoch: 5| Step: 5
Training loss: 1.7829548120498657
Validation loss: 1.8902548897650935

Epoch: 5| Step: 6
Training loss: 1.6066124439239502
Validation loss: 1.9057939437127882

Epoch: 5| Step: 7
Training loss: 0.956558346748352
Validation loss: 1.8914705335452993

Epoch: 5| Step: 8
Training loss: 1.485299825668335
Validation loss: 1.8540272533252675

Epoch: 5| Step: 9
Training loss: 1.127396583557129
Validation loss: 1.8596944347504647

Epoch: 5| Step: 10
Training loss: 1.1818695068359375
Validation loss: 1.8929528856790194

Epoch: 430| Step: 0
Training loss: 1.5523779392242432
Validation loss: 1.8846068574536232

Epoch: 5| Step: 1
Training loss: 1.2336835861206055
Validation loss: 1.8687493442207255

Epoch: 5| Step: 2
Training loss: 1.0095980167388916
Validation loss: 1.929839721290014

Epoch: 5| Step: 3
Training loss: 1.3414350748062134
Validation loss: 1.878788068730344

Epoch: 5| Step: 4
Training loss: 1.0042979717254639
Validation loss: 1.8708574976972354

Epoch: 5| Step: 5
Training loss: 0.8148332834243774
Validation loss: 1.8622485629973873

Epoch: 5| Step: 6
Training loss: 1.4272364377975464
Validation loss: 1.9015548485581593

Epoch: 5| Step: 7
Training loss: 1.5505491495132446
Validation loss: 1.9062046145880094

Epoch: 5| Step: 8
Training loss: 1.283691167831421
Validation loss: 1.9070262242388982

Epoch: 5| Step: 9
Training loss: 0.9332824945449829
Validation loss: 1.8547360999609834

Epoch: 5| Step: 10
Training loss: 2.452005386352539
Validation loss: 1.8852673256269066

Epoch: 431| Step: 0
Training loss: 1.331521987915039
Validation loss: 1.8527906966465775

Epoch: 5| Step: 1
Training loss: 1.327683687210083
Validation loss: 1.931591877373316

Epoch: 5| Step: 2
Training loss: 2.0412707328796387
Validation loss: 1.9033834882961806

Epoch: 5| Step: 3
Training loss: 1.298441767692566
Validation loss: 1.9250988280901344

Epoch: 5| Step: 4
Training loss: 1.3642975091934204
Validation loss: 1.9099645268532537

Epoch: 5| Step: 5
Training loss: 1.2193827629089355
Validation loss: 1.8510645153701946

Epoch: 5| Step: 6
Training loss: 0.9601207971572876
Validation loss: 1.856569408088602

Epoch: 5| Step: 7
Training loss: 1.1358164548873901
Validation loss: 1.8419389365821757

Epoch: 5| Step: 8
Training loss: 1.094455599784851
Validation loss: 1.910622396776753

Epoch: 5| Step: 9
Training loss: 1.1488208770751953
Validation loss: 1.8703808681939238

Epoch: 5| Step: 10
Training loss: 1.2833209037780762
Validation loss: 1.8766853296628563

Epoch: 432| Step: 0
Training loss: 1.2662363052368164
Validation loss: 1.9040117943158714

Epoch: 5| Step: 1
Training loss: 1.1856173276901245
Validation loss: 1.869067443314419

Epoch: 5| Step: 2
Training loss: 1.6475921869277954
Validation loss: 1.8451693750196887

Epoch: 5| Step: 3
Training loss: 0.9836867451667786
Validation loss: 1.887110210234119

Epoch: 5| Step: 4
Training loss: 1.0355228185653687
Validation loss: 1.9133998014593636

Epoch: 5| Step: 5
Training loss: 1.6081397533416748
Validation loss: 1.857201442923597

Epoch: 5| Step: 6
Training loss: 1.5788795948028564
Validation loss: 1.8985965521104875

Epoch: 5| Step: 7
Training loss: 1.3923537731170654
Validation loss: 1.9302943803930794

Epoch: 5| Step: 8
Training loss: 1.2479040622711182
Validation loss: 1.8961911175840644

Epoch: 5| Step: 9
Training loss: 1.640580415725708
Validation loss: 1.8473132246284074

Epoch: 5| Step: 10
Training loss: 0.5790233612060547
Validation loss: 1.8558217863882742

Epoch: 433| Step: 0
Training loss: 2.103837490081787
Validation loss: 1.890962089261701

Epoch: 5| Step: 1
Training loss: 1.3937125205993652
Validation loss: 1.8982473663104478

Epoch: 5| Step: 2
Training loss: 1.4953421354293823
Validation loss: 1.9524078997232581

Epoch: 5| Step: 3
Training loss: 1.444819450378418
Validation loss: 1.9054775199582499

Epoch: 5| Step: 4
Training loss: 1.0868616104125977
Validation loss: 1.9292943105902722

Epoch: 5| Step: 5
Training loss: 0.8407715559005737
Validation loss: 1.9010338680718535

Epoch: 5| Step: 6
Training loss: 1.048195481300354
Validation loss: 1.9271816835608533

Epoch: 5| Step: 7
Training loss: 0.7787176370620728
Validation loss: 1.8646330000251852

Epoch: 5| Step: 8
Training loss: 1.2857327461242676
Validation loss: 1.9011676644766202

Epoch: 5| Step: 9
Training loss: 1.2041950225830078
Validation loss: 1.8795710520077777

Epoch: 5| Step: 10
Training loss: 1.5266774892807007
Validation loss: 1.8672320458196825

Epoch: 434| Step: 0
Training loss: 1.1083223819732666
Validation loss: 1.8396386843855663

Epoch: 5| Step: 1
Training loss: 1.3815412521362305
Validation loss: 1.8662446365561536

Epoch: 5| Step: 2
Training loss: 1.81069016456604
Validation loss: 1.9310056445419148

Epoch: 5| Step: 3
Training loss: 1.4918558597564697
Validation loss: 1.9143884553704211

Epoch: 5| Step: 4
Training loss: 1.317899465560913
Validation loss: 1.8980989238267303

Epoch: 5| Step: 5
Training loss: 1.0877997875213623
Validation loss: 1.9127681742432296

Epoch: 5| Step: 6
Training loss: 0.8410261869430542
Validation loss: 1.8412420544573056

Epoch: 5| Step: 7
Training loss: 1.316773533821106
Validation loss: 1.902407071923697

Epoch: 5| Step: 8
Training loss: 0.6110776662826538
Validation loss: 1.9262285501726213

Epoch: 5| Step: 9
Training loss: 1.7097591161727905
Validation loss: 1.8774581134960215

Epoch: 5| Step: 10
Training loss: 1.6052236557006836
Validation loss: 1.9095459317648282

Epoch: 435| Step: 0
Training loss: 1.7568349838256836
Validation loss: 1.8904426290142922

Epoch: 5| Step: 1
Training loss: 1.144673228263855
Validation loss: 1.9360044156351397

Epoch: 5| Step: 2
Training loss: 1.2452877759933472
Validation loss: 1.8675088446627381

Epoch: 5| Step: 3
Training loss: 1.4288625717163086
Validation loss: 1.8889391845272434

Epoch: 5| Step: 4
Training loss: 1.5099284648895264
Validation loss: 1.88298753769167

Epoch: 5| Step: 5
Training loss: 0.9253883361816406
Validation loss: 1.9187731050675916

Epoch: 5| Step: 6
Training loss: 1.5643202066421509
Validation loss: 1.8923218891184816

Epoch: 5| Step: 7
Training loss: 1.4148235321044922
Validation loss: 1.9170954560720792

Epoch: 5| Step: 8
Training loss: 1.300840139389038
Validation loss: 1.9613244354083974

Epoch: 5| Step: 9
Training loss: 1.3011605739593506
Validation loss: 1.934651828581287

Epoch: 5| Step: 10
Training loss: 0.8431310057640076
Validation loss: 1.921137039379407

Epoch: 436| Step: 0
Training loss: 1.3385283946990967
Validation loss: 1.88057541847229

Epoch: 5| Step: 1
Training loss: 1.9305191040039062
Validation loss: 1.836051848626906

Epoch: 5| Step: 2
Training loss: 0.9426911473274231
Validation loss: 1.8803306266825686

Epoch: 5| Step: 3
Training loss: 1.2729580402374268
Validation loss: 1.8874450499011624

Epoch: 5| Step: 4
Training loss: 1.3537505865097046
Validation loss: 1.8773923458591584

Epoch: 5| Step: 5
Training loss: 1.1771568059921265
Validation loss: 1.8561706671150782

Epoch: 5| Step: 6
Training loss: 1.034446120262146
Validation loss: 1.8985053262402933

Epoch: 5| Step: 7
Training loss: 1.081740140914917
Validation loss: 1.8989270207702473

Epoch: 5| Step: 8
Training loss: 1.3964837789535522
Validation loss: 1.8705808167816491

Epoch: 5| Step: 9
Training loss: 1.464233160018921
Validation loss: 1.909077166229166

Epoch: 5| Step: 10
Training loss: 1.2926439046859741
Validation loss: 1.9191064475685038

Epoch: 437| Step: 0
Training loss: 1.1044845581054688
Validation loss: 1.8964185253266366

Epoch: 5| Step: 1
Training loss: 0.9333429336547852
Validation loss: 1.8781817215745167

Epoch: 5| Step: 2
Training loss: 1.3206923007965088
Validation loss: 1.9254736438874276

Epoch: 5| Step: 3
Training loss: 1.3828727006912231
Validation loss: 1.916573001492408

Epoch: 5| Step: 4
Training loss: 1.4102166891098022
Validation loss: 1.8800394919610792

Epoch: 5| Step: 5
Training loss: 1.3262604475021362
Validation loss: 1.878691768133512

Epoch: 5| Step: 6
Training loss: 1.2071224451065063
Validation loss: 1.8486452218024962

Epoch: 5| Step: 7
Training loss: 1.7580139636993408
Validation loss: 1.9421493943019579

Epoch: 5| Step: 8
Training loss: 1.1605823040008545
Validation loss: 1.920221277462539

Epoch: 5| Step: 9
Training loss: 0.9403780102729797
Validation loss: 1.8402091892816688

Epoch: 5| Step: 10
Training loss: 1.7164736986160278
Validation loss: 1.8778715390031055

Epoch: 438| Step: 0
Training loss: 1.6759145259857178
Validation loss: 1.8844113862642677

Epoch: 5| Step: 1
Training loss: 1.5245366096496582
Validation loss: 1.8977107629981091

Epoch: 5| Step: 2
Training loss: 1.2393059730529785
Validation loss: 1.8656493156186995

Epoch: 5| Step: 3
Training loss: 0.6817322969436646
Validation loss: 1.8729394546119116

Epoch: 5| Step: 4
Training loss: 1.191404938697815
Validation loss: 1.8862775987194431

Epoch: 5| Step: 5
Training loss: 1.5645153522491455
Validation loss: 1.904669479657245

Epoch: 5| Step: 6
Training loss: 1.2148160934448242
Validation loss: 1.8762859221427672

Epoch: 5| Step: 7
Training loss: 1.352990746498108
Validation loss: 1.883069722883163

Epoch: 5| Step: 8
Training loss: 1.564658284187317
Validation loss: 1.836562959096765

Epoch: 5| Step: 9
Training loss: 0.6642221212387085
Validation loss: 1.9500413863889632

Epoch: 5| Step: 10
Training loss: 1.6238927841186523
Validation loss: 1.9020245536681144

Epoch: 439| Step: 0
Training loss: 1.4168661832809448
Validation loss: 1.9284938919928767

Epoch: 5| Step: 1
Training loss: 0.9137916564941406
Validation loss: 1.8939763935663367

Epoch: 5| Step: 2
Training loss: 1.7005037069320679
Validation loss: 1.8811560689762075

Epoch: 5| Step: 3
Training loss: 1.1931283473968506
Validation loss: 1.925286131520425

Epoch: 5| Step: 4
Training loss: 1.6227309703826904
Validation loss: 1.9393061181550384

Epoch: 5| Step: 5
Training loss: 1.3208136558532715
Validation loss: 1.8964660167694092

Epoch: 5| Step: 6
Training loss: 0.7620530724525452
Validation loss: 1.9027952840251308

Epoch: 5| Step: 7
Training loss: 1.2598752975463867
Validation loss: 1.8885299864635672

Epoch: 5| Step: 8
Training loss: 1.298024296760559
Validation loss: 1.9375889762755363

Epoch: 5| Step: 9
Training loss: 1.5409679412841797
Validation loss: 1.8850686973141086

Epoch: 5| Step: 10
Training loss: 1.640120506286621
Validation loss: 1.8517292135505266

Epoch: 440| Step: 0
Training loss: 1.2605996131896973
Validation loss: 1.8945491583116594

Epoch: 5| Step: 1
Training loss: 1.481946349143982
Validation loss: 1.902000529791719

Epoch: 5| Step: 2
Training loss: 1.1214494705200195
Validation loss: 1.8843239071548625

Epoch: 5| Step: 3
Training loss: 1.2122676372528076
Validation loss: 1.8997737874266922

Epoch: 5| Step: 4
Training loss: 0.9963736534118652
Validation loss: 1.9028235930268482

Epoch: 5| Step: 5
Training loss: 1.2424356937408447
Validation loss: 1.9086222776802637

Epoch: 5| Step: 6
Training loss: 1.4688727855682373
Validation loss: 1.8723833612216416

Epoch: 5| Step: 7
Training loss: 1.567400574684143
Validation loss: 1.9106624357161983

Epoch: 5| Step: 8
Training loss: 1.4434607028961182
Validation loss: 1.8751514445069015

Epoch: 5| Step: 9
Training loss: 0.9962700009346008
Validation loss: 1.9495799233836513

Epoch: 5| Step: 10
Training loss: 1.4409005641937256
Validation loss: 1.877749281544839

Epoch: 441| Step: 0
Training loss: 1.3130866289138794
Validation loss: 1.9091389743230676

Epoch: 5| Step: 1
Training loss: 1.074447512626648
Validation loss: 1.8861059911789433

Epoch: 5| Step: 2
Training loss: 1.331553339958191
Validation loss: 1.898871019322385

Epoch: 5| Step: 3
Training loss: 1.0477465391159058
Validation loss: 1.8899758118455128

Epoch: 5| Step: 4
Training loss: 1.2902253866195679
Validation loss: 1.8807342167823546

Epoch: 5| Step: 5
Training loss: 1.050879716873169
Validation loss: 1.888074267295099

Epoch: 5| Step: 6
Training loss: 1.1022202968597412
Validation loss: 1.9297613354139431

Epoch: 5| Step: 7
Training loss: 1.484827995300293
Validation loss: 1.9691162109375

Epoch: 5| Step: 8
Training loss: 1.4224385023117065
Validation loss: 1.8794916086299445

Epoch: 5| Step: 9
Training loss: 1.4716414213180542
Validation loss: 1.8771782511024064

Epoch: 5| Step: 10
Training loss: 1.3342463970184326
Validation loss: 1.866542100906372

Epoch: 442| Step: 0
Training loss: 1.5021426677703857
Validation loss: 1.8708567798778575

Epoch: 5| Step: 1
Training loss: 1.235802412033081
Validation loss: 1.8941401358573668

Epoch: 5| Step: 2
Training loss: 1.2514064311981201
Validation loss: 1.8544416235339256

Epoch: 5| Step: 3
Training loss: 1.1396222114562988
Validation loss: 1.8785478261209303

Epoch: 5| Step: 4
Training loss: 1.1306017637252808
Validation loss: 1.8628460591839207

Epoch: 5| Step: 5
Training loss: 2.0839407444000244
Validation loss: 1.9126075185755247

Epoch: 5| Step: 6
Training loss: 1.0996898412704468
Validation loss: 1.9216266665407407

Epoch: 5| Step: 7
Training loss: 0.6713610887527466
Validation loss: 1.9183143851577595

Epoch: 5| Step: 8
Training loss: 0.969805896282196
Validation loss: 1.9030668504776493

Epoch: 5| Step: 9
Training loss: 1.4515241384506226
Validation loss: 1.8905005064061893

Epoch: 5| Step: 10
Training loss: 1.3698698282241821
Validation loss: 1.9075210504634406

Epoch: 443| Step: 0
Training loss: 1.2039133310317993
Validation loss: 1.8429717492031794

Epoch: 5| Step: 1
Training loss: 1.4412941932678223
Validation loss: 1.9307630933741087

Epoch: 5| Step: 2
Training loss: 1.3155107498168945
Validation loss: 1.8730293217525686

Epoch: 5| Step: 3
Training loss: 1.1837257146835327
Validation loss: 1.8965156796158

Epoch: 5| Step: 4
Training loss: 1.5225478410720825
Validation loss: 1.9035938516739876

Epoch: 5| Step: 5
Training loss: 0.9402347803115845
Validation loss: 1.8793829923034997

Epoch: 5| Step: 6
Training loss: 1.1840767860412598
Validation loss: 1.9002404020678612

Epoch: 5| Step: 7
Training loss: 0.9687390327453613
Validation loss: 1.8764979557324482

Epoch: 5| Step: 8
Training loss: 1.1152994632720947
Validation loss: 1.9012805774647703

Epoch: 5| Step: 9
Training loss: 1.422524094581604
Validation loss: 1.894004019357825

Epoch: 5| Step: 10
Training loss: 1.551430106163025
Validation loss: 1.9111427132801344

Epoch: 444| Step: 0
Training loss: 1.1296006441116333
Validation loss: 1.8757181026602303

Epoch: 5| Step: 1
Training loss: 1.7425076961517334
Validation loss: 1.909280728268367

Epoch: 5| Step: 2
Training loss: 1.4994456768035889
Validation loss: 1.8527442050236527

Epoch: 5| Step: 3
Training loss: 1.1352417469024658
Validation loss: 1.9196525568603187

Epoch: 5| Step: 4
Training loss: 1.191027283668518
Validation loss: 1.8830039526826592

Epoch: 5| Step: 5
Training loss: 1.1742371320724487
Validation loss: 1.90547530112728

Epoch: 5| Step: 6
Training loss: 1.6416137218475342
Validation loss: 1.9047781600747058

Epoch: 5| Step: 7
Training loss: 1.2558906078338623
Validation loss: 1.8952943407079226

Epoch: 5| Step: 8
Training loss: 0.9928997159004211
Validation loss: 1.9153287346645067

Epoch: 5| Step: 9
Training loss: 0.7945712804794312
Validation loss: 1.9182840060162287

Epoch: 5| Step: 10
Training loss: 1.6744823455810547
Validation loss: 1.9284905105508783

Epoch: 445| Step: 0
Training loss: 0.802627444267273
Validation loss: 1.8914848796782955

Epoch: 5| Step: 1
Training loss: 1.7408597469329834
Validation loss: 1.8907295837197253

Epoch: 5| Step: 2
Training loss: 1.7019792795181274
Validation loss: 1.9224203914724372

Epoch: 5| Step: 3
Training loss: 1.2210882902145386
Validation loss: 1.8988559425518077

Epoch: 5| Step: 4
Training loss: 1.1641387939453125
Validation loss: 1.9072125957858177

Epoch: 5| Step: 5
Training loss: 1.255362629890442
Validation loss: 1.909517421517321

Epoch: 5| Step: 6
Training loss: 0.9713218808174133
Validation loss: 1.8790976168006979

Epoch: 5| Step: 7
Training loss: 1.1368858814239502
Validation loss: 1.870554010073344

Epoch: 5| Step: 8
Training loss: 1.6722307205200195
Validation loss: 1.89151882484395

Epoch: 5| Step: 9
Training loss: 0.9645830988883972
Validation loss: 1.8786330453811153

Epoch: 5| Step: 10
Training loss: 1.108665943145752
Validation loss: 1.9103224982497513

Epoch: 446| Step: 0
Training loss: 1.9236053228378296
Validation loss: 1.8768318840252456

Epoch: 5| Step: 1
Training loss: 0.9753610491752625
Validation loss: 1.8817126392036356

Epoch: 5| Step: 2
Training loss: 1.4872604608535767
Validation loss: 1.8745513680160686

Epoch: 5| Step: 3
Training loss: 1.2396515607833862
Validation loss: 1.8492295319034207

Epoch: 5| Step: 4
Training loss: 1.2748029232025146
Validation loss: 1.8625246824756745

Epoch: 5| Step: 5
Training loss: 1.1957075595855713
Validation loss: 1.87105312655049

Epoch: 5| Step: 6
Training loss: 1.2701807022094727
Validation loss: 1.9103693346823416

Epoch: 5| Step: 7
Training loss: 0.7788854241371155
Validation loss: 1.8954656765025149

Epoch: 5| Step: 8
Training loss: 0.9542883038520813
Validation loss: 1.8744835597212597

Epoch: 5| Step: 9
Training loss: 1.8518720865249634
Validation loss: 1.918490671342419

Epoch: 5| Step: 10
Training loss: 1.0681488513946533
Validation loss: 1.9217986535000544

Epoch: 447| Step: 0
Training loss: 1.0201770067214966
Validation loss: 1.8960430211918329

Epoch: 5| Step: 1
Training loss: 1.1061677932739258
Validation loss: 1.8973169942055979

Epoch: 5| Step: 2
Training loss: 1.360729694366455
Validation loss: 1.8846992292711813

Epoch: 5| Step: 3
Training loss: 1.3324202299118042
Validation loss: 1.9176655815493675

Epoch: 5| Step: 4
Training loss: 1.3859646320343018
Validation loss: 1.9176898976807952

Epoch: 5| Step: 5
Training loss: 0.7706336975097656
Validation loss: 1.8971267592522405

Epoch: 5| Step: 6
Training loss: 1.0941743850708008
Validation loss: 1.918611543152922

Epoch: 5| Step: 7
Training loss: 1.2551991939544678
Validation loss: 1.8772605888305172

Epoch: 5| Step: 8
Training loss: 1.4878270626068115
Validation loss: 1.8649972613139818

Epoch: 5| Step: 9
Training loss: 1.6140730381011963
Validation loss: 1.8818548622951712

Epoch: 5| Step: 10
Training loss: 1.2840179204940796
Validation loss: 1.907511749575215

Epoch: 448| Step: 0
Training loss: 1.5860143899917603
Validation loss: 1.871021806552846

Epoch: 5| Step: 1
Training loss: 0.9294785261154175
Validation loss: 1.8602723844589726

Epoch: 5| Step: 2
Training loss: 1.4819790124893188
Validation loss: 1.8874799705320788

Epoch: 5| Step: 3
Training loss: 1.406510829925537
Validation loss: 1.9024468134808283

Epoch: 5| Step: 4
Training loss: 1.2862130403518677
Validation loss: 1.8503405253092449

Epoch: 5| Step: 5
Training loss: 1.0240991115570068
Validation loss: 1.8572290815332884

Epoch: 5| Step: 6
Training loss: 1.1427637338638306
Validation loss: 1.9078512678864181

Epoch: 5| Step: 7
Training loss: 1.1389615535736084
Validation loss: 1.934337805676204

Epoch: 5| Step: 8
Training loss: 1.3901135921478271
Validation loss: 1.9407378396680277

Epoch: 5| Step: 9
Training loss: 1.084308385848999
Validation loss: 1.9007013972087572

Epoch: 5| Step: 10
Training loss: 1.9804633855819702
Validation loss: 1.9163191010875087

Epoch: 449| Step: 0
Training loss: 1.1983035802841187
Validation loss: 1.9184312435888475

Epoch: 5| Step: 1
Training loss: 1.3657371997833252
Validation loss: 1.8966020461051696

Epoch: 5| Step: 2
Training loss: 1.354885220527649
Validation loss: 1.9090099437262422

Epoch: 5| Step: 3
Training loss: 0.7612953782081604
Validation loss: 1.9156331759627148

Epoch: 5| Step: 4
Training loss: 1.5917701721191406
Validation loss: 1.922894424007785

Epoch: 5| Step: 5
Training loss: 1.4815037250518799
Validation loss: 1.8796490982014646

Epoch: 5| Step: 6
Training loss: 1.2898200750350952
Validation loss: 1.8658719537078694

Epoch: 5| Step: 7
Training loss: 1.4191597700119019
Validation loss: 1.8695565244202972

Epoch: 5| Step: 8
Training loss: 0.9245079159736633
Validation loss: 1.8961834676804081

Epoch: 5| Step: 9
Training loss: 1.0340092182159424
Validation loss: 1.8471005129557785

Epoch: 5| Step: 10
Training loss: 1.3856297731399536
Validation loss: 1.8870900100277317

Epoch: 450| Step: 0
Training loss: 0.8090301752090454
Validation loss: 1.8687346930144935

Epoch: 5| Step: 1
Training loss: 1.7488120794296265
Validation loss: 1.9163773213663409

Epoch: 5| Step: 2
Training loss: 1.468957781791687
Validation loss: 1.927501037556638

Epoch: 5| Step: 3
Training loss: 1.1388527154922485
Validation loss: 1.9247744134677354

Epoch: 5| Step: 4
Training loss: 0.7933095693588257
Validation loss: 1.915291783630207

Epoch: 5| Step: 5
Training loss: 0.9079774022102356
Validation loss: 1.9164471241735643

Epoch: 5| Step: 6
Training loss: 1.2571780681610107
Validation loss: 1.9400826449035316

Epoch: 5| Step: 7
Training loss: 1.4949266910552979
Validation loss: 1.9141725788834274

Epoch: 5| Step: 8
Training loss: 1.4496898651123047
Validation loss: 1.8796263087180354

Epoch: 5| Step: 9
Training loss: 1.503542423248291
Validation loss: 1.9088606654956777

Epoch: 5| Step: 10
Training loss: 1.4190841913223267
Validation loss: 1.8921068458146946

Epoch: 451| Step: 0
Training loss: 1.1257927417755127
Validation loss: 1.9574903800923338

Epoch: 5| Step: 1
Training loss: 1.2587331533432007
Validation loss: 1.862594791637954

Epoch: 5| Step: 2
Training loss: 1.2201000452041626
Validation loss: 1.8871029551311205

Epoch: 5| Step: 3
Training loss: 1.710959792137146
Validation loss: 1.8668751050067205

Epoch: 5| Step: 4
Training loss: 1.606602668762207
Validation loss: 1.922064786316246

Epoch: 5| Step: 5
Training loss: 1.0851386785507202
Validation loss: 1.904736109959182

Epoch: 5| Step: 6
Training loss: 1.3598358631134033
Validation loss: 1.8971971773332166

Epoch: 5| Step: 7
Training loss: 0.9022709131240845
Validation loss: 1.893523916121452

Epoch: 5| Step: 8
Training loss: 1.2932898998260498
Validation loss: 1.8885254116468533

Epoch: 5| Step: 9
Training loss: 1.3811689615249634
Validation loss: 1.8879299343273204

Epoch: 5| Step: 10
Training loss: 0.8161547183990479
Validation loss: 1.9225746444476548

Epoch: 452| Step: 0
Training loss: 0.9430776834487915
Validation loss: 1.8590086147349367

Epoch: 5| Step: 1
Training loss: 1.024616003036499
Validation loss: 1.8969958853977982

Epoch: 5| Step: 2
Training loss: 1.1200425624847412
Validation loss: 1.8891175152153097

Epoch: 5| Step: 3
Training loss: 1.030556559562683
Validation loss: 1.8872675152235134

Epoch: 5| Step: 4
Training loss: 1.0995104312896729
Validation loss: 1.872807474546535

Epoch: 5| Step: 5
Training loss: 1.169114112854004
Validation loss: 1.906309103453031

Epoch: 5| Step: 6
Training loss: 1.8167283535003662
Validation loss: 1.8962207930062407

Epoch: 5| Step: 7
Training loss: 1.6091973781585693
Validation loss: 1.9137913847482333

Epoch: 5| Step: 8
Training loss: 1.67633056640625
Validation loss: 1.8734499113534087

Epoch: 5| Step: 9
Training loss: 1.4825315475463867
Validation loss: 1.8716140024123653

Epoch: 5| Step: 10
Training loss: 1.0921921730041504
Validation loss: 1.8867665388250863

Epoch: 453| Step: 0
Training loss: 1.4986646175384521
Validation loss: 1.8809414012457735

Epoch: 5| Step: 1
Training loss: 1.1664197444915771
Validation loss: 1.9291227991862963

Epoch: 5| Step: 2
Training loss: 1.3582730293273926
Validation loss: 1.8957878774212253

Epoch: 5| Step: 3
Training loss: 0.857724666595459
Validation loss: 1.8844642741705782

Epoch: 5| Step: 4
Training loss: 1.5420724153518677
Validation loss: 1.8765362231962142

Epoch: 5| Step: 5
Training loss: 1.1509567499160767
Validation loss: 1.8722810488875195

Epoch: 5| Step: 6
Training loss: 1.829988718032837
Validation loss: 1.8848215559477448

Epoch: 5| Step: 7
Training loss: 0.6257071495056152
Validation loss: 1.8566284859052269

Epoch: 5| Step: 8
Training loss: 1.237870454788208
Validation loss: 1.9025362217298118

Epoch: 5| Step: 9
Training loss: 1.4429925680160522
Validation loss: 1.8474175660840926

Epoch: 5| Step: 10
Training loss: 0.9817471504211426
Validation loss: 1.8683095644879084

Epoch: 454| Step: 0
Training loss: 1.0463134050369263
Validation loss: 1.8680998663748465

Epoch: 5| Step: 1
Training loss: 1.822182297706604
Validation loss: 1.8953296856213642

Epoch: 5| Step: 2
Training loss: 0.942448616027832
Validation loss: 1.8862048490073091

Epoch: 5| Step: 3
Training loss: 1.2383253574371338
Validation loss: 1.890239538684968

Epoch: 5| Step: 4
Training loss: 1.4012080430984497
Validation loss: 1.8877110763262677

Epoch: 5| Step: 5
Training loss: 1.3375425338745117
Validation loss: 1.891748748799806

Epoch: 5| Step: 6
Training loss: 1.415273666381836
Validation loss: 1.9116967339669504

Epoch: 5| Step: 7
Training loss: 0.7639714479446411
Validation loss: 1.9112120648866058

Epoch: 5| Step: 8
Training loss: 1.6379457712173462
Validation loss: 1.8740412855661044

Epoch: 5| Step: 9
Training loss: 1.2985060214996338
Validation loss: 1.8859262902249572

Epoch: 5| Step: 10
Training loss: 1.0237892866134644
Validation loss: 1.8682270332049298

Epoch: 455| Step: 0
Training loss: 1.113486647605896
Validation loss: 1.886122106223978

Epoch: 5| Step: 1
Training loss: 1.2008603811264038
Validation loss: 1.87000120839765

Epoch: 5| Step: 2
Training loss: 1.632184624671936
Validation loss: 1.8842133245160502

Epoch: 5| Step: 3
Training loss: 0.8969382047653198
Validation loss: 1.8831808220955633

Epoch: 5| Step: 4
Training loss: 1.2435243129730225
Validation loss: 1.9375175058200795

Epoch: 5| Step: 5
Training loss: 1.0078500509262085
Validation loss: 1.8710567566656298

Epoch: 5| Step: 6
Training loss: 0.9807730913162231
Validation loss: 1.872393100492416

Epoch: 5| Step: 7
Training loss: 1.4888213872909546
Validation loss: 1.9054140096069665

Epoch: 5| Step: 8
Training loss: 1.308351755142212
Validation loss: 1.8783753136152863

Epoch: 5| Step: 9
Training loss: 1.438429594039917
Validation loss: 1.845041440379235

Epoch: 5| Step: 10
Training loss: 1.5421438217163086
Validation loss: 1.8752631833476405

Epoch: 456| Step: 0
Training loss: 1.1663775444030762
Validation loss: 1.888498798493416

Epoch: 5| Step: 1
Training loss: 1.5605673789978027
Validation loss: 1.913910319728236

Epoch: 5| Step: 2
Training loss: 0.6785387396812439
Validation loss: 1.8669712408896415

Epoch: 5| Step: 3
Training loss: 1.8613001108169556
Validation loss: 1.8937044143676758

Epoch: 5| Step: 4
Training loss: 1.3609955310821533
Validation loss: 1.8926475868430188

Epoch: 5| Step: 5
Training loss: 0.6979184150695801
Validation loss: 1.8777543498623757

Epoch: 5| Step: 6
Training loss: 0.7204683423042297
Validation loss: 1.9093815383090769

Epoch: 5| Step: 7
Training loss: 1.8459014892578125
Validation loss: 1.8915165803765739

Epoch: 5| Step: 8
Training loss: 1.247733235359192
Validation loss: 1.8876442627240253

Epoch: 5| Step: 9
Training loss: 1.3611379861831665
Validation loss: 1.849834285756593

Epoch: 5| Step: 10
Training loss: 1.3665966987609863
Validation loss: 1.8654958996721493

Epoch: 457| Step: 0
Training loss: 1.1872551441192627
Validation loss: 1.8738811092991983

Epoch: 5| Step: 1
Training loss: 1.6111596822738647
Validation loss: 1.8740232042087022

Epoch: 5| Step: 2
Training loss: 1.6278831958770752
Validation loss: 1.9296740447321246

Epoch: 5| Step: 3
Training loss: 1.2149245738983154
Validation loss: 1.881227780413884

Epoch: 5| Step: 4
Training loss: 1.2629108428955078
Validation loss: 1.8697195976011214

Epoch: 5| Step: 5
Training loss: 1.1232788562774658
Validation loss: 1.8593839829967869

Epoch: 5| Step: 6
Training loss: 1.548415184020996
Validation loss: 1.891134391548813

Epoch: 5| Step: 7
Training loss: 0.9728242754936218
Validation loss: 1.909222787426364

Epoch: 5| Step: 8
Training loss: 0.9911945462226868
Validation loss: 1.924100479772014

Epoch: 5| Step: 9
Training loss: 0.6522648930549622
Validation loss: 1.8892904327761741

Epoch: 5| Step: 10
Training loss: 1.5124444961547852
Validation loss: 1.8899212345000236

Epoch: 458| Step: 0
Training loss: 1.1400511264801025
Validation loss: 1.902136105363087

Epoch: 5| Step: 1
Training loss: 1.5561658143997192
Validation loss: 1.90410812183093

Epoch: 5| Step: 2
Training loss: 0.8549035787582397
Validation loss: 1.8500952900096934

Epoch: 5| Step: 3
Training loss: 1.1011617183685303
Validation loss: 1.921860538503175

Epoch: 5| Step: 4
Training loss: 1.5870587825775146
Validation loss: 1.8946721464075067

Epoch: 5| Step: 5
Training loss: 1.3996002674102783
Validation loss: 1.918860379085746

Epoch: 5| Step: 6
Training loss: 1.1573172807693481
Validation loss: 1.8957532144361926

Epoch: 5| Step: 7
Training loss: 1.470029354095459
Validation loss: 1.9124754321190618

Epoch: 5| Step: 8
Training loss: 0.9821473360061646
Validation loss: 1.915777167966289

Epoch: 5| Step: 9
Training loss: 1.4436777830123901
Validation loss: 1.8233273349782473

Epoch: 5| Step: 10
Training loss: 1.0226895809173584
Validation loss: 1.8851787121065202

Epoch: 459| Step: 0
Training loss: 1.164796233177185
Validation loss: 1.9294270084750267

Epoch: 5| Step: 1
Training loss: 1.2885247468948364
Validation loss: 1.8666119524227676

Epoch: 5| Step: 2
Training loss: 0.8261324167251587
Validation loss: 1.9027374098377843

Epoch: 5| Step: 3
Training loss: 1.3542718887329102
Validation loss: 1.8677265515891455

Epoch: 5| Step: 4
Training loss: 0.9390525817871094
Validation loss: 1.8529092855350946

Epoch: 5| Step: 5
Training loss: 1.268909215927124
Validation loss: 1.8644400514582151

Epoch: 5| Step: 6
Training loss: 1.1740334033966064
Validation loss: 1.9274602218340802

Epoch: 5| Step: 7
Training loss: 1.2418791055679321
Validation loss: 1.8869499557761735

Epoch: 5| Step: 8
Training loss: 1.598479151725769
Validation loss: 1.8860708641749557

Epoch: 5| Step: 9
Training loss: 1.5413801670074463
Validation loss: 1.9249636332194011

Epoch: 5| Step: 10
Training loss: 1.2638015747070312
Validation loss: 1.8795864799971223

Epoch: 460| Step: 0
Training loss: 1.3871840238571167
Validation loss: 1.8214961303177701

Epoch: 5| Step: 1
Training loss: 1.170945167541504
Validation loss: 1.895829782691053

Epoch: 5| Step: 2
Training loss: 0.8507660031318665
Validation loss: 1.9256474817952802

Epoch: 5| Step: 3
Training loss: 1.3271905183792114
Validation loss: 1.9299629708772064

Epoch: 5| Step: 4
Training loss: 1.3690462112426758
Validation loss: 1.8837233833087388

Epoch: 5| Step: 5
Training loss: 1.3103611469268799
Validation loss: 1.8538973523724465

Epoch: 5| Step: 6
Training loss: 0.8830972909927368
Validation loss: 1.8761079080643193

Epoch: 5| Step: 7
Training loss: 1.6474679708480835
Validation loss: 1.8753249850324405

Epoch: 5| Step: 8
Training loss: 1.3785139322280884
Validation loss: 1.8627763384131975

Epoch: 5| Step: 9
Training loss: 1.5783360004425049
Validation loss: 1.875718601288334

Epoch: 5| Step: 10
Training loss: 1.0142263174057007
Validation loss: 1.8852173461708972

Epoch: 461| Step: 0
Training loss: 1.3062647581100464
Validation loss: 1.884705110262799

Epoch: 5| Step: 1
Training loss: 1.071565866470337
Validation loss: 1.8816234027185748

Epoch: 5| Step: 2
Training loss: 1.4566093683242798
Validation loss: 1.8676522726653724

Epoch: 5| Step: 3
Training loss: 1.4413013458251953
Validation loss: 1.8515299904731013

Epoch: 5| Step: 4
Training loss: 1.3324306011199951
Validation loss: 1.916195354154033

Epoch: 5| Step: 5
Training loss: 1.5778963565826416
Validation loss: 1.9078682455965268

Epoch: 5| Step: 6
Training loss: 1.1631635427474976
Validation loss: 1.8979272906498244

Epoch: 5| Step: 7
Training loss: 0.9866482615470886
Validation loss: 1.8875160037830312

Epoch: 5| Step: 8
Training loss: 1.1706053018569946
Validation loss: 1.9054729323233328

Epoch: 5| Step: 9
Training loss: 1.0098519325256348
Validation loss: 1.9269914934712071

Epoch: 5| Step: 10
Training loss: 0.908094048500061
Validation loss: 1.9049719315703197

Epoch: 462| Step: 0
Training loss: 1.8409092426300049
Validation loss: 1.9019868309779833

Epoch: 5| Step: 1
Training loss: 1.2242870330810547
Validation loss: 1.8999941195211103

Epoch: 5| Step: 2
Training loss: 0.8416095972061157
Validation loss: 1.9387128148027646

Epoch: 5| Step: 3
Training loss: 0.9153969883918762
Validation loss: 1.8711163074739519

Epoch: 5| Step: 4
Training loss: 1.4081426858901978
Validation loss: 1.9165529230589509

Epoch: 5| Step: 5
Training loss: 1.6608768701553345
Validation loss: 1.846749985089866

Epoch: 5| Step: 6
Training loss: 1.2029856443405151
Validation loss: 1.837779361714599

Epoch: 5| Step: 7
Training loss: 0.8509429693222046
Validation loss: 1.8579159872506255

Epoch: 5| Step: 8
Training loss: 1.361413598060608
Validation loss: 1.9087540090724986

Epoch: 5| Step: 9
Training loss: 1.1778603792190552
Validation loss: 1.8806920820666897

Epoch: 5| Step: 10
Training loss: 1.253920078277588
Validation loss: 1.862919108842009

Epoch: 463| Step: 0
Training loss: 0.685466468334198
Validation loss: 1.8390521990355624

Epoch: 5| Step: 1
Training loss: 1.3179279565811157
Validation loss: 1.8920433136724657

Epoch: 5| Step: 2
Training loss: 1.2141553163528442
Validation loss: 1.8909896701894782

Epoch: 5| Step: 3
Training loss: 1.3508996963500977
Validation loss: 1.8827210703203756

Epoch: 5| Step: 4
Training loss: 1.4685399532318115
Validation loss: 1.8803490810496832

Epoch: 5| Step: 5
Training loss: 1.3100883960723877
Validation loss: 1.8983091820952713

Epoch: 5| Step: 6
Training loss: 1.1241965293884277
Validation loss: 1.8949065182798652

Epoch: 5| Step: 7
Training loss: 1.1992425918579102
Validation loss: 1.9033397320778138

Epoch: 5| Step: 8
Training loss: 1.4231432676315308
Validation loss: 1.8782032958922847

Epoch: 5| Step: 9
Training loss: 1.0267647504806519
Validation loss: 1.8819903545482184

Epoch: 5| Step: 10
Training loss: 1.3987656831741333
Validation loss: 1.8773287650077575

Epoch: 464| Step: 0
Training loss: 0.8229527473449707
Validation loss: 1.9410728664808377

Epoch: 5| Step: 1
Training loss: 1.399658203125
Validation loss: 1.937036475827617

Epoch: 5| Step: 2
Training loss: 0.8024196624755859
Validation loss: 1.9211778538201445

Epoch: 5| Step: 3
Training loss: 1.206059217453003
Validation loss: 1.88700423958481

Epoch: 5| Step: 4
Training loss: 1.463561773300171
Validation loss: 1.879281267043083

Epoch: 5| Step: 5
Training loss: 1.1296143531799316
Validation loss: 1.8996146853252123

Epoch: 5| Step: 6
Training loss: 1.180492639541626
Validation loss: 1.8693622107146888

Epoch: 5| Step: 7
Training loss: 1.134962558746338
Validation loss: 1.8819912864315895

Epoch: 5| Step: 8
Training loss: 1.7582495212554932
Validation loss: 1.841002711685755

Epoch: 5| Step: 9
Training loss: 1.430262565612793
Validation loss: 1.8694907388379496

Epoch: 5| Step: 10
Training loss: 1.2850970029830933
Validation loss: 1.8664545923150995

Epoch: 465| Step: 0
Training loss: 1.4178001880645752
Validation loss: 1.8499417638265958

Epoch: 5| Step: 1
Training loss: 1.3227918148040771
Validation loss: 1.8939838922151955

Epoch: 5| Step: 2
Training loss: 1.1675745248794556
Validation loss: 1.903606758322767

Epoch: 5| Step: 3
Training loss: 0.8556066751480103
Validation loss: 1.8891985416412354

Epoch: 5| Step: 4
Training loss: 1.4604815244674683
Validation loss: 1.881903773994856

Epoch: 5| Step: 5
Training loss: 1.4212608337402344
Validation loss: 1.8688182728264922

Epoch: 5| Step: 6
Training loss: 1.2091658115386963
Validation loss: 1.905207182771416

Epoch: 5| Step: 7
Training loss: 1.0847525596618652
Validation loss: 1.8984497298476517

Epoch: 5| Step: 8
Training loss: 0.640348494052887
Validation loss: 1.897335695964034

Epoch: 5| Step: 9
Training loss: 1.5782434940338135
Validation loss: 1.8950600675357285

Epoch: 5| Step: 10
Training loss: 1.1150785684585571
Validation loss: 1.8677430742530412

Epoch: 466| Step: 0
Training loss: 1.7499977350234985
Validation loss: 1.87416708982119

Epoch: 5| Step: 1
Training loss: 1.1885921955108643
Validation loss: 1.858242678385909

Epoch: 5| Step: 2
Training loss: 1.1531065702438354
Validation loss: 1.8802240099958194

Epoch: 5| Step: 3
Training loss: 1.441116213798523
Validation loss: 1.9007509485367806

Epoch: 5| Step: 4
Training loss: 1.219963788986206
Validation loss: 1.8505737038068875

Epoch: 5| Step: 5
Training loss: 0.9012700915336609
Validation loss: 1.9207625850554435

Epoch: 5| Step: 6
Training loss: 1.6208336353302002
Validation loss: 1.8925675743369645

Epoch: 5| Step: 7
Training loss: 0.767406702041626
Validation loss: 1.934434295982443

Epoch: 5| Step: 8
Training loss: 0.6537824869155884
Validation loss: 1.9082092277465328

Epoch: 5| Step: 9
Training loss: 1.5627535581588745
Validation loss: 1.878312651829053

Epoch: 5| Step: 10
Training loss: 1.2945222854614258
Validation loss: 1.886001875323634

Epoch: 467| Step: 0
Training loss: 1.1028468608856201
Validation loss: 1.892112543506007

Epoch: 5| Step: 1
Training loss: 0.9534146189689636
Validation loss: 1.8745100293108212

Epoch: 5| Step: 2
Training loss: 1.4814635515213013
Validation loss: 1.9334763942226287

Epoch: 5| Step: 3
Training loss: 1.2455374002456665
Validation loss: 1.8898269373883483

Epoch: 5| Step: 4
Training loss: 0.9339072108268738
Validation loss: 1.8655080385105585

Epoch: 5| Step: 5
Training loss: 1.3310998678207397
Validation loss: 1.9217778931381881

Epoch: 5| Step: 6
Training loss: 1.6097917556762695
Validation loss: 1.8691324213499665

Epoch: 5| Step: 7
Training loss: 1.1652424335479736
Validation loss: 1.853768645435251

Epoch: 5| Step: 8
Training loss: 0.9283542633056641
Validation loss: 1.875688337510632

Epoch: 5| Step: 9
Training loss: 1.346510648727417
Validation loss: 1.8858971967492053

Epoch: 5| Step: 10
Training loss: 1.538741111755371
Validation loss: 1.892214475139495

Epoch: 468| Step: 0
Training loss: 1.1086591482162476
Validation loss: 1.8746137875382618

Epoch: 5| Step: 1
Training loss: 1.4576890468597412
Validation loss: 1.892363171423635

Epoch: 5| Step: 2
Training loss: 1.7171146869659424
Validation loss: 1.910213157694827

Epoch: 5| Step: 3
Training loss: 1.230110764503479
Validation loss: 1.9229998832107873

Epoch: 5| Step: 4
Training loss: 0.9362717866897583
Validation loss: 1.8860969748548282

Epoch: 5| Step: 5
Training loss: 1.269956350326538
Validation loss: 1.9192390852077033

Epoch: 5| Step: 6
Training loss: 1.59840989112854
Validation loss: 1.8793043705724901

Epoch: 5| Step: 7
Training loss: 1.0906407833099365
Validation loss: 1.910314147190381

Epoch: 5| Step: 8
Training loss: 1.4216523170471191
Validation loss: 1.870258879917924

Epoch: 5| Step: 9
Training loss: 1.0046167373657227
Validation loss: 1.8677523213048135

Epoch: 5| Step: 10
Training loss: 0.596816897392273
Validation loss: 1.8993525863975607

Epoch: 469| Step: 0
Training loss: 1.1464093923568726
Validation loss: 1.8895151961234309

Epoch: 5| Step: 1
Training loss: 1.2392451763153076
Validation loss: 1.9112799975179857

Epoch: 5| Step: 2
Training loss: 1.0296201705932617
Validation loss: 1.9242356054244503

Epoch: 5| Step: 3
Training loss: 0.9436690211296082
Validation loss: 1.8681841742607854

Epoch: 5| Step: 4
Training loss: 1.4003479480743408
Validation loss: 1.8931353412648684

Epoch: 5| Step: 5
Training loss: 0.7364094257354736
Validation loss: 1.8864388978609474

Epoch: 5| Step: 6
Training loss: 1.3517907857894897
Validation loss: 1.8622188683479064

Epoch: 5| Step: 7
Training loss: 1.1995989084243774
Validation loss: 1.8649690933124994

Epoch: 5| Step: 8
Training loss: 1.095780611038208
Validation loss: 1.8574222531369937

Epoch: 5| Step: 9
Training loss: 1.4589247703552246
Validation loss: 1.8829508827578636

Epoch: 5| Step: 10
Training loss: 1.7060282230377197
Validation loss: 1.8613299451848513

Epoch: 470| Step: 0
Training loss: 1.8400297164916992
Validation loss: 1.8705822754931707

Epoch: 5| Step: 1
Training loss: 0.8237787485122681
Validation loss: 1.8447176243669243

Epoch: 5| Step: 2
Training loss: 0.9449312090873718
Validation loss: 1.8487380576390091

Epoch: 5| Step: 3
Training loss: 1.0483920574188232
Validation loss: 1.868967169074602

Epoch: 5| Step: 4
Training loss: 1.1967909336090088
Validation loss: 1.8689737268673476

Epoch: 5| Step: 5
Training loss: 1.2965238094329834
Validation loss: 1.8933553593133086

Epoch: 5| Step: 6
Training loss: 1.212095022201538
Validation loss: 1.8829596324633526

Epoch: 5| Step: 7
Training loss: 1.1016857624053955
Validation loss: 1.8947535714795511

Epoch: 5| Step: 8
Training loss: 1.2666443586349487
Validation loss: 1.907599356866652

Epoch: 5| Step: 9
Training loss: 1.2513419389724731
Validation loss: 1.902804211903644

Epoch: 5| Step: 10
Training loss: 1.555607557296753
Validation loss: 1.8626960528794156

Epoch: 471| Step: 0
Training loss: 1.5176388025283813
Validation loss: 1.8819019435554423

Epoch: 5| Step: 1
Training loss: 1.0776112079620361
Validation loss: 1.8879226843516033

Epoch: 5| Step: 2
Training loss: 1.0147563219070435
Validation loss: 1.8857792192889797

Epoch: 5| Step: 3
Training loss: 1.483964204788208
Validation loss: 1.9052025477091472

Epoch: 5| Step: 4
Training loss: 1.423156976699829
Validation loss: 1.8551861034926547

Epoch: 5| Step: 5
Training loss: 1.3889801502227783
Validation loss: 1.8668204866429812

Epoch: 5| Step: 6
Training loss: 0.9908059239387512
Validation loss: 1.8444748232441563

Epoch: 5| Step: 7
Training loss: 1.365339994430542
Validation loss: 1.9006777501875354

Epoch: 5| Step: 8
Training loss: 1.2371480464935303
Validation loss: 1.9202076876035301

Epoch: 5| Step: 9
Training loss: 1.2360823154449463
Validation loss: 1.889815345887215

Epoch: 5| Step: 10
Training loss: 0.7359869480133057
Validation loss: 1.8654785002431562

Epoch: 472| Step: 0
Training loss: 0.7798346281051636
Validation loss: 1.8599017409868137

Epoch: 5| Step: 1
Training loss: 1.2975976467132568
Validation loss: 1.9234694524477887

Epoch: 5| Step: 2
Training loss: 1.0050253868103027
Validation loss: 1.8557696598832325

Epoch: 5| Step: 3
Training loss: 1.1715757846832275
Validation loss: 1.8970997077162548

Epoch: 5| Step: 4
Training loss: 1.4175536632537842
Validation loss: 1.9121332758216447

Epoch: 5| Step: 5
Training loss: 1.6254408359527588
Validation loss: 1.9575620556390414

Epoch: 5| Step: 6
Training loss: 1.6902555227279663
Validation loss: 1.9303165405027327

Epoch: 5| Step: 7
Training loss: 1.0258777141571045
Validation loss: 1.9462647181685253

Epoch: 5| Step: 8
Training loss: 1.2963948249816895
Validation loss: 1.9018478367918281

Epoch: 5| Step: 9
Training loss: 0.9613073468208313
Validation loss: 1.9211726547569357

Epoch: 5| Step: 10
Training loss: 1.3102476596832275
Validation loss: 1.9130614534501107

Epoch: 473| Step: 0
Training loss: 1.21670401096344
Validation loss: 1.9176953813081146

Epoch: 5| Step: 1
Training loss: 1.1252167224884033
Validation loss: 1.9023171124919769

Epoch: 5| Step: 2
Training loss: 0.8440702557563782
Validation loss: 1.862142534666164

Epoch: 5| Step: 3
Training loss: 1.4476420879364014
Validation loss: 1.8965971316060712

Epoch: 5| Step: 4
Training loss: 1.3975732326507568
Validation loss: 1.8708632094885713

Epoch: 5| Step: 5
Training loss: 1.403667688369751
Validation loss: 1.8887984701382217

Epoch: 5| Step: 6
Training loss: 1.232745885848999
Validation loss: 1.9196387516554965

Epoch: 5| Step: 7
Training loss: 1.0179903507232666
Validation loss: 1.8372128471251457

Epoch: 5| Step: 8
Training loss: 1.0814086198806763
Validation loss: 1.891977281980617

Epoch: 5| Step: 9
Training loss: 1.3118473291397095
Validation loss: 1.896845571456417

Epoch: 5| Step: 10
Training loss: 1.1877702474594116
Validation loss: 1.8554217866671983

Epoch: 474| Step: 0
Training loss: 1.148982286453247
Validation loss: 1.8507522318952827

Epoch: 5| Step: 1
Training loss: 1.7636988162994385
Validation loss: 1.8613455193017119

Epoch: 5| Step: 2
Training loss: 1.2667949199676514
Validation loss: 1.891353649477805

Epoch: 5| Step: 3
Training loss: 1.094832420349121
Validation loss: 1.8915239405888382

Epoch: 5| Step: 4
Training loss: 0.9276310205459595
Validation loss: 1.8788040299569406

Epoch: 5| Step: 5
Training loss: 1.293046236038208
Validation loss: 1.9123412127135901

Epoch: 5| Step: 6
Training loss: 0.9735031127929688
Validation loss: 1.9313143735290856

Epoch: 5| Step: 7
Training loss: 1.8329532146453857
Validation loss: 1.9095469238937541

Epoch: 5| Step: 8
Training loss: 1.2357840538024902
Validation loss: 1.857448935508728

Epoch: 5| Step: 9
Training loss: 1.3464305400848389
Validation loss: 1.9225168971605198

Epoch: 5| Step: 10
Training loss: 0.6792157292366028
Validation loss: 1.9321241276238554

Epoch: 475| Step: 0
Training loss: 1.0403449535369873
Validation loss: 1.884251784252864

Epoch: 5| Step: 1
Training loss: 1.0870994329452515
Validation loss: 1.871129999878586

Epoch: 5| Step: 2
Training loss: 1.567284345626831
Validation loss: 1.874376735379619

Epoch: 5| Step: 3
Training loss: 1.5423015356063843
Validation loss: 1.8998935991717922

Epoch: 5| Step: 4
Training loss: 1.1152719259262085
Validation loss: 1.866831100115212

Epoch: 5| Step: 5
Training loss: 1.0693719387054443
Validation loss: 1.8790812492370605

Epoch: 5| Step: 6
Training loss: 1.1122621297836304
Validation loss: 1.8906574390267814

Epoch: 5| Step: 7
Training loss: 1.3060516119003296
Validation loss: 1.9390058184182772

Epoch: 5| Step: 8
Training loss: 1.5089420080184937
Validation loss: 1.891940378373669

Epoch: 5| Step: 9
Training loss: 1.0473228693008423
Validation loss: 1.8736889810972317

Epoch: 5| Step: 10
Training loss: 0.8548170924186707
Validation loss: 1.942024048938546

Epoch: 476| Step: 0
Training loss: 1.1034324169158936
Validation loss: 1.90540680321314

Epoch: 5| Step: 1
Training loss: 1.237848162651062
Validation loss: 1.8762565953757173

Epoch: 5| Step: 2
Training loss: 1.3989841938018799
Validation loss: 1.9354140989242061

Epoch: 5| Step: 3
Training loss: 1.1737984418869019
Validation loss: 1.9150287335918796

Epoch: 5| Step: 4
Training loss: 1.098406195640564
Validation loss: 1.892692163426389

Epoch: 5| Step: 5
Training loss: 1.337498664855957
Validation loss: 1.9424149297898816

Epoch: 5| Step: 6
Training loss: 1.8469139337539673
Validation loss: 1.8998429403510144

Epoch: 5| Step: 7
Training loss: 1.0945038795471191
Validation loss: 1.8912981030761555

Epoch: 5| Step: 8
Training loss: 0.6774217486381531
Validation loss: 1.9643537998199463

Epoch: 5| Step: 9
Training loss: 1.1807937622070312
Validation loss: 1.8271738688151042

Epoch: 5| Step: 10
Training loss: 1.1430623531341553
Validation loss: 1.879281969480617

Epoch: 477| Step: 0
Training loss: 1.2261102199554443
Validation loss: 1.910581781018165

Epoch: 5| Step: 1
Training loss: 1.5184085369110107
Validation loss: 1.840041906602921

Epoch: 5| Step: 2
Training loss: 1.3921276330947876
Validation loss: 1.934218886078045

Epoch: 5| Step: 3
Training loss: 1.1967226266860962
Validation loss: 1.8698788330119143

Epoch: 5| Step: 4
Training loss: 0.9443396329879761
Validation loss: 1.8613619471109042

Epoch: 5| Step: 5
Training loss: 1.1020267009735107
Validation loss: 1.826917504751554

Epoch: 5| Step: 6
Training loss: 1.1662894487380981
Validation loss: 1.864812538187991

Epoch: 5| Step: 7
Training loss: 1.8785512447357178
Validation loss: 1.8570167659431376

Epoch: 5| Step: 8
Training loss: 1.2423388957977295
Validation loss: 1.8694516151182112

Epoch: 5| Step: 9
Training loss: 0.9393706321716309
Validation loss: 1.934068101708607

Epoch: 5| Step: 10
Training loss: 0.766538143157959
Validation loss: 1.91804753580401

Epoch: 478| Step: 0
Training loss: 1.3008369207382202
Validation loss: 1.868318175756803

Epoch: 5| Step: 1
Training loss: 1.367139458656311
Validation loss: 1.881780352643741

Epoch: 5| Step: 2
Training loss: 0.9625728726387024
Validation loss: 1.8747547800822923

Epoch: 5| Step: 3
Training loss: 1.2703238725662231
Validation loss: 1.896603153597924

Epoch: 5| Step: 4
Training loss: 1.5717194080352783
Validation loss: 1.9110829291805145

Epoch: 5| Step: 5
Training loss: 1.5127660036087036
Validation loss: 1.869151963982531

Epoch: 5| Step: 6
Training loss: 0.722951352596283
Validation loss: 1.8450239755774056

Epoch: 5| Step: 7
Training loss: 0.932738184928894
Validation loss: 1.9499638516415831

Epoch: 5| Step: 8
Training loss: 1.114050030708313
Validation loss: 1.9210127566450386

Epoch: 5| Step: 9
Training loss: 1.2458158731460571
Validation loss: 1.8901775626726047

Epoch: 5| Step: 10
Training loss: 1.1164665222167969
Validation loss: 1.9010314710678593

Epoch: 479| Step: 0
Training loss: 0.8758689165115356
Validation loss: 1.8742143338726414

Epoch: 5| Step: 1
Training loss: 1.485743522644043
Validation loss: 1.9335739048578406

Epoch: 5| Step: 2
Training loss: 1.502988576889038
Validation loss: 1.9383513824914091

Epoch: 5| Step: 3
Training loss: 1.1956417560577393
Validation loss: 1.9055618342532907

Epoch: 5| Step: 4
Training loss: 0.7759376764297485
Validation loss: 1.8867530079298123

Epoch: 5| Step: 5
Training loss: 1.3642337322235107
Validation loss: 1.8959798761593398

Epoch: 5| Step: 6
Training loss: 1.1190166473388672
Validation loss: 1.9020122892113143

Epoch: 5| Step: 7
Training loss: 1.2204430103302002
Validation loss: 1.898260897205722

Epoch: 5| Step: 8
Training loss: 1.6535937786102295
Validation loss: 1.8441704550097067

Epoch: 5| Step: 9
Training loss: 1.0418765544891357
Validation loss: 1.8920960016148065

Epoch: 5| Step: 10
Training loss: 1.2857762575149536
Validation loss: 1.8795618780197636

Epoch: 480| Step: 0
Training loss: 1.277318000793457
Validation loss: 1.8734327708521197

Epoch: 5| Step: 1
Training loss: 0.7762651443481445
Validation loss: 1.8680929522360525

Epoch: 5| Step: 2
Training loss: 1.0692765712738037
Validation loss: 1.8595691637326313

Epoch: 5| Step: 3
Training loss: 0.8698169589042664
Validation loss: 1.8761702634954964

Epoch: 5| Step: 4
Training loss: 1.7217845916748047
Validation loss: 1.8864382005506946

Epoch: 5| Step: 5
Training loss: 1.09456467628479
Validation loss: 1.9344958015667495

Epoch: 5| Step: 6
Training loss: 1.3485124111175537
Validation loss: 1.889981403145739

Epoch: 5| Step: 7
Training loss: 1.3154160976409912
Validation loss: 1.8501485201620287

Epoch: 5| Step: 8
Training loss: 1.4101468324661255
Validation loss: 1.8765018857935423

Epoch: 5| Step: 9
Training loss: 0.9979591369628906
Validation loss: 1.9196924035267164

Epoch: 5| Step: 10
Training loss: 1.2238272428512573
Validation loss: 1.9125163273144794

Epoch: 481| Step: 0
Training loss: 1.0774487257003784
Validation loss: 1.9097063541412354

Epoch: 5| Step: 1
Training loss: 0.7968250513076782
Validation loss: 1.8807577240851618

Epoch: 5| Step: 2
Training loss: 1.362243413925171
Validation loss: 1.8463527361551921

Epoch: 5| Step: 3
Training loss: 1.7983806133270264
Validation loss: 1.886493375224452

Epoch: 5| Step: 4
Training loss: 0.9940694570541382
Validation loss: 1.8672420337635984

Epoch: 5| Step: 5
Training loss: 0.9382774233818054
Validation loss: 1.866891002142301

Epoch: 5| Step: 6
Training loss: 1.7061126232147217
Validation loss: 1.8997823499864148

Epoch: 5| Step: 7
Training loss: 0.9546455144882202
Validation loss: 1.8934294933913856

Epoch: 5| Step: 8
Training loss: 1.1353178024291992
Validation loss: 1.906734497316422

Epoch: 5| Step: 9
Training loss: 1.3544434309005737
Validation loss: 1.8880531518690047

Epoch: 5| Step: 10
Training loss: 0.9843264222145081
Validation loss: 1.8685308553839242

Epoch: 482| Step: 0
Training loss: 1.3047775030136108
Validation loss: 1.9381113513823478

Epoch: 5| Step: 1
Training loss: 1.0488139390945435
Validation loss: 1.880766296899447

Epoch: 5| Step: 2
Training loss: 1.138287901878357
Validation loss: 1.8469850465815554

Epoch: 5| Step: 3
Training loss: 0.8316868543624878
Validation loss: 1.878958054768142

Epoch: 5| Step: 4
Training loss: 1.239300012588501
Validation loss: 1.8989297664293678

Epoch: 5| Step: 5
Training loss: 1.249245524406433
Validation loss: 1.9136079383152786

Epoch: 5| Step: 6
Training loss: 0.5034962892532349
Validation loss: 1.9273814565391951

Epoch: 5| Step: 7
Training loss: 1.3138222694396973
Validation loss: 1.916093300747615

Epoch: 5| Step: 8
Training loss: 1.8064649105072021
Validation loss: 1.9445987286106232

Epoch: 5| Step: 9
Training loss: 1.623464584350586
Validation loss: 1.9127931774303477

Epoch: 5| Step: 10
Training loss: 0.9519891142845154
Validation loss: 1.8865174401190974

Epoch: 483| Step: 0
Training loss: 1.4734433889389038
Validation loss: 1.8667378425598145

Epoch: 5| Step: 1
Training loss: 1.2769330739974976
Validation loss: 1.852840926057549

Epoch: 5| Step: 2
Training loss: 1.0035359859466553
Validation loss: 1.8336661989970873

Epoch: 5| Step: 3
Training loss: 1.3715572357177734
Validation loss: 1.8254715575966785

Epoch: 5| Step: 4
Training loss: 1.399128794670105
Validation loss: 1.8701440954721102

Epoch: 5| Step: 5
Training loss: 0.5821338891983032
Validation loss: 1.8720250078426894

Epoch: 5| Step: 6
Training loss: 1.1343473196029663
Validation loss: 1.8911076643133675

Epoch: 5| Step: 7
Training loss: 1.1165823936462402
Validation loss: 1.8827958811995804

Epoch: 5| Step: 8
Training loss: 1.6838207244873047
Validation loss: 1.9100568435525382

Epoch: 5| Step: 9
Training loss: 0.8170833587646484
Validation loss: 1.8714333862386725

Epoch: 5| Step: 10
Training loss: 1.4042885303497314
Validation loss: 1.9077614122821438

Epoch: 484| Step: 0
Training loss: 1.5039252042770386
Validation loss: 1.8687633134985482

Epoch: 5| Step: 1
Training loss: 0.8490464091300964
Validation loss: 1.8816505901275142

Epoch: 5| Step: 2
Training loss: 0.8004453778266907
Validation loss: 1.850006006097281

Epoch: 5| Step: 3
Training loss: 1.5505659580230713
Validation loss: 1.9080678570655085

Epoch: 5| Step: 4
Training loss: 0.8574050664901733
Validation loss: 1.9134712488420549

Epoch: 5| Step: 5
Training loss: 0.9231735467910767
Validation loss: 1.87141502159898

Epoch: 5| Step: 6
Training loss: 0.7475546598434448
Validation loss: 1.8773083648374003

Epoch: 5| Step: 7
Training loss: 1.4443577527999878
Validation loss: 1.91837094547928

Epoch: 5| Step: 8
Training loss: 1.3499784469604492
Validation loss: 1.8559854568973664

Epoch: 5| Step: 9
Training loss: 1.273535132408142
Validation loss: 1.882651964823405

Epoch: 5| Step: 10
Training loss: 1.7813326120376587
Validation loss: 1.9098641090495612

Epoch: 485| Step: 0
Training loss: 1.0619983673095703
Validation loss: 1.9264894967438073

Epoch: 5| Step: 1
Training loss: 1.351966142654419
Validation loss: 1.864942766004993

Epoch: 5| Step: 2
Training loss: 1.082084059715271
Validation loss: 1.8822595880877586

Epoch: 5| Step: 3
Training loss: 1.1619651317596436
Validation loss: 1.8684126266869165

Epoch: 5| Step: 4
Training loss: 1.1436269283294678
Validation loss: 1.9026019111756356

Epoch: 5| Step: 5
Training loss: 1.3595726490020752
Validation loss: 1.857423520857288

Epoch: 5| Step: 6
Training loss: 0.80317622423172
Validation loss: 1.8734142177848405

Epoch: 5| Step: 7
Training loss: 1.4027433395385742
Validation loss: 1.8367507662824405

Epoch: 5| Step: 8
Training loss: 1.2209089994430542
Validation loss: 1.8818091384826168

Epoch: 5| Step: 9
Training loss: 1.1721245050430298
Validation loss: 1.9021100305741834

Epoch: 5| Step: 10
Training loss: 1.4828710556030273
Validation loss: 1.922604791579708

Epoch: 486| Step: 0
Training loss: 0.9574559926986694
Validation loss: 1.8749927013151106

Epoch: 5| Step: 1
Training loss: 0.8380546569824219
Validation loss: 1.8807480771054503

Epoch: 5| Step: 2
Training loss: 1.2001985311508179
Validation loss: 1.8666794633352628

Epoch: 5| Step: 3
Training loss: 1.0872529745101929
Validation loss: 1.8784927527109783

Epoch: 5| Step: 4
Training loss: 1.1046531200408936
Validation loss: 1.8685693587026289

Epoch: 5| Step: 5
Training loss: 1.3019535541534424
Validation loss: 1.8929241382947533

Epoch: 5| Step: 6
Training loss: 1.0470478534698486
Validation loss: 1.8739851828544372

Epoch: 5| Step: 7
Training loss: 0.6852529644966125
Validation loss: 1.9063133373055408

Epoch: 5| Step: 8
Training loss: 1.171026587486267
Validation loss: 1.8311302020985594

Epoch: 5| Step: 9
Training loss: 1.9922994375228882
Validation loss: 1.8530601429682907

Epoch: 5| Step: 10
Training loss: 1.4558496475219727
Validation loss: 1.8704387680176766

Epoch: 487| Step: 0
Training loss: 1.046804428100586
Validation loss: 1.9114948523941862

Epoch: 5| Step: 1
Training loss: 1.4471372365951538
Validation loss: 1.8662944634755452

Epoch: 5| Step: 2
Training loss: 1.50594961643219
Validation loss: 1.8674826737373107

Epoch: 5| Step: 3
Training loss: 1.0150009393692017
Validation loss: 1.8769829401405909

Epoch: 5| Step: 4
Training loss: 0.9343697428703308
Validation loss: 1.9136026418337257

Epoch: 5| Step: 5
Training loss: 0.9889662861824036
Validation loss: 1.9182513080617434

Epoch: 5| Step: 6
Training loss: 1.1529980897903442
Validation loss: 1.9010865073050223

Epoch: 5| Step: 7
Training loss: 1.3588008880615234
Validation loss: 1.8715823593960013

Epoch: 5| Step: 8
Training loss: 1.2796871662139893
Validation loss: 1.9303908219901464

Epoch: 5| Step: 9
Training loss: 0.9621245265007019
Validation loss: 1.9383766715244581

Epoch: 5| Step: 10
Training loss: 1.44074547290802
Validation loss: 1.8714417488344255

Epoch: 488| Step: 0
Training loss: 0.8650999069213867
Validation loss: 1.8506245177279237

Epoch: 5| Step: 1
Training loss: 1.0945028066635132
Validation loss: 1.910546725796115

Epoch: 5| Step: 2
Training loss: 1.1876559257507324
Validation loss: 1.8667627111557992

Epoch: 5| Step: 3
Training loss: 1.4715319871902466
Validation loss: 1.8861172583795363

Epoch: 5| Step: 4
Training loss: 1.121644377708435
Validation loss: 1.8856110790724396

Epoch: 5| Step: 5
Training loss: 1.4699645042419434
Validation loss: 1.8919045527776082

Epoch: 5| Step: 6
Training loss: 0.9666441082954407
Validation loss: 1.8889914712598246

Epoch: 5| Step: 7
Training loss: 1.7010085582733154
Validation loss: 1.8769090585811163

Epoch: 5| Step: 8
Training loss: 1.1554269790649414
Validation loss: 1.866075195291991

Epoch: 5| Step: 9
Training loss: 1.2846691608428955
Validation loss: 1.8339770763151106

Epoch: 5| Step: 10
Training loss: 0.9699418544769287
Validation loss: 1.8864177221892982

Epoch: 489| Step: 0
Training loss: 1.5988357067108154
Validation loss: 1.897761155200261

Epoch: 5| Step: 1
Training loss: 1.3988502025604248
Validation loss: 1.9263837363130303

Epoch: 5| Step: 2
Training loss: 1.3900858163833618
Validation loss: 1.9114073168846868

Epoch: 5| Step: 3
Training loss: 1.4484727382659912
Validation loss: 1.8724494672590686

Epoch: 5| Step: 4
Training loss: 0.8005776405334473
Validation loss: 1.9279498169499059

Epoch: 5| Step: 5
Training loss: 0.973467230796814
Validation loss: 1.9002599331640428

Epoch: 5| Step: 6
Training loss: 1.023574948310852
Validation loss: 1.9274179358636179

Epoch: 5| Step: 7
Training loss: 0.7136556506156921
Validation loss: 1.870723206509826

Epoch: 5| Step: 8
Training loss: 1.0151851177215576
Validation loss: 1.858945426120553

Epoch: 5| Step: 9
Training loss: 0.8149796724319458
Validation loss: 1.8643641318044355

Epoch: 5| Step: 10
Training loss: 1.6172767877578735
Validation loss: 1.9379223213400891

Epoch: 490| Step: 0
Training loss: 1.2230775356292725
Validation loss: 1.8372188742442797

Epoch: 5| Step: 1
Training loss: 1.477738380432129
Validation loss: 1.8967627017728743

Epoch: 5| Step: 2
Training loss: 1.2075726985931396
Validation loss: 1.933426687794347

Epoch: 5| Step: 3
Training loss: 1.3652970790863037
Validation loss: 1.8868076186026297

Epoch: 5| Step: 4
Training loss: 1.1683385372161865
Validation loss: 1.9363467129327918

Epoch: 5| Step: 5
Training loss: 1.3542560338974
Validation loss: 1.876994832869499

Epoch: 5| Step: 6
Training loss: 1.2391374111175537
Validation loss: 1.8892450383914414

Epoch: 5| Step: 7
Training loss: 0.9068319201469421
Validation loss: 1.9107987034705378

Epoch: 5| Step: 8
Training loss: 0.8984848260879517
Validation loss: 1.8417867409285678

Epoch: 5| Step: 9
Training loss: 1.0584211349487305
Validation loss: 1.9226328019172914

Epoch: 5| Step: 10
Training loss: 0.947023868560791
Validation loss: 1.8634003259802376

Epoch: 491| Step: 0
Training loss: 0.9674471020698547
Validation loss: 1.8962987994634977

Epoch: 5| Step: 1
Training loss: 1.019006371498108
Validation loss: 1.9073878052414104

Epoch: 5| Step: 2
Training loss: 1.1304658651351929
Validation loss: 1.8528588625692552

Epoch: 5| Step: 3
Training loss: 1.1941001415252686
Validation loss: 1.8971702103973718

Epoch: 5| Step: 4
Training loss: 0.9360483288764954
Validation loss: 1.8735834372940885

Epoch: 5| Step: 5
Training loss: 1.9302349090576172
Validation loss: 1.8735258707436182

Epoch: 5| Step: 6
Training loss: 1.15592360496521
Validation loss: 1.8644571688867384

Epoch: 5| Step: 7
Training loss: 1.412800908088684
Validation loss: 1.9064055117227698

Epoch: 5| Step: 8
Training loss: 0.8907390832901001
Validation loss: 1.8783768351360033

Epoch: 5| Step: 9
Training loss: 1.220470905303955
Validation loss: 1.8343575449400051

Epoch: 5| Step: 10
Training loss: 1.0185422897338867
Validation loss: 1.8805626553873862

Epoch: 492| Step: 0
Training loss: 1.4144893884658813
Validation loss: 1.9401357455920147

Epoch: 5| Step: 1
Training loss: 1.106862187385559
Validation loss: 1.884099211744083

Epoch: 5| Step: 2
Training loss: 1.4225890636444092
Validation loss: 1.9050615961833666

Epoch: 5| Step: 3
Training loss: 1.0684325695037842
Validation loss: 1.8963566557053597

Epoch: 5| Step: 4
Training loss: 1.0716209411621094
Validation loss: 1.9136010036673596

Epoch: 5| Step: 5
Training loss: 1.7860500812530518
Validation loss: 1.8529602878837175

Epoch: 5| Step: 6
Training loss: 0.8475130200386047
Validation loss: 1.8667954296194098

Epoch: 5| Step: 7
Training loss: 1.2629460096359253
Validation loss: 1.8611469294435234

Epoch: 5| Step: 8
Training loss: 1.0021287202835083
Validation loss: 1.8664399244452035

Epoch: 5| Step: 9
Training loss: 1.122471570968628
Validation loss: 1.911548670902047

Epoch: 5| Step: 10
Training loss: 1.0118898153305054
Validation loss: 1.9270138894357989

Epoch: 493| Step: 0
Training loss: 0.7960512042045593
Validation loss: 1.9098717833078036

Epoch: 5| Step: 1
Training loss: 0.858819305896759
Validation loss: 1.8741076018220635

Epoch: 5| Step: 2
Training loss: 1.22689950466156
Validation loss: 1.8774375530981249

Epoch: 5| Step: 3
Training loss: 1.45514714717865
Validation loss: 1.881661932955506

Epoch: 5| Step: 4
Training loss: 1.323474645614624
Validation loss: 1.8964490505956835

Epoch: 5| Step: 5
Training loss: 1.318102478981018
Validation loss: 1.8676472056296565

Epoch: 5| Step: 6
Training loss: 1.244265079498291
Validation loss: 1.8905149249620334

Epoch: 5| Step: 7
Training loss: 1.0914318561553955
Validation loss: 1.8705898818149362

Epoch: 5| Step: 8
Training loss: 1.0844985246658325
Validation loss: 1.877137130306613

Epoch: 5| Step: 9
Training loss: 1.0103254318237305
Validation loss: 1.8810668478729904

Epoch: 5| Step: 10
Training loss: 1.259861946105957
Validation loss: 1.8736716047410042

Epoch: 494| Step: 0
Training loss: 1.1522352695465088
Validation loss: 1.8909371681110834

Epoch: 5| Step: 1
Training loss: 0.9987006187438965
Validation loss: 1.8651461601257324

Epoch: 5| Step: 2
Training loss: 1.6093565225601196
Validation loss: 1.91694761091663

Epoch: 5| Step: 3
Training loss: 1.0944328308105469
Validation loss: 1.9277754291411369

Epoch: 5| Step: 4
Training loss: 1.1769832372665405
Validation loss: 1.890822087564776

Epoch: 5| Step: 5
Training loss: 1.3185564279556274
Validation loss: 1.9230652393833283

Epoch: 5| Step: 6
Training loss: 1.6965633630752563
Validation loss: 1.9066276255474295

Epoch: 5| Step: 7
Training loss: 0.9811321496963501
Validation loss: 1.8311088700448312

Epoch: 5| Step: 8
Training loss: 1.082341194152832
Validation loss: 1.8716461812296221

Epoch: 5| Step: 9
Training loss: 0.8102739453315735
Validation loss: 1.872352946189142

Epoch: 5| Step: 10
Training loss: 0.7483049035072327
Validation loss: 1.8708806422448927

Epoch: 495| Step: 0
Training loss: 1.221601128578186
Validation loss: 1.8940791519739295

Epoch: 5| Step: 1
Training loss: 1.0303981304168701
Validation loss: 1.9050005276997883

Epoch: 5| Step: 2
Training loss: 1.0708832740783691
Validation loss: 1.9071952425023562

Epoch: 5| Step: 3
Training loss: 1.0200388431549072
Validation loss: 1.8852459128184984

Epoch: 5| Step: 4
Training loss: 1.456499457359314
Validation loss: 1.8526288834951257

Epoch: 5| Step: 5
Training loss: 1.184935450553894
Validation loss: 1.8567041940586542

Epoch: 5| Step: 6
Training loss: 1.2143406867980957
Validation loss: 1.8842695490006478

Epoch: 5| Step: 7
Training loss: 1.4764381647109985
Validation loss: 1.859621581210885

Epoch: 5| Step: 8
Training loss: 1.2460060119628906
Validation loss: 1.9081828927481046

Epoch: 5| Step: 9
Training loss: 0.9210659265518188
Validation loss: 1.861409443680958

Epoch: 5| Step: 10
Training loss: 1.0131620168685913
Validation loss: 1.952225536428472

Epoch: 496| Step: 0
Training loss: 0.7251977920532227
Validation loss: 1.9150155731426772

Epoch: 5| Step: 1
Training loss: 1.2786802053451538
Validation loss: 1.8828828245080926

Epoch: 5| Step: 2
Training loss: 1.3051618337631226
Validation loss: 1.9105189128588604

Epoch: 5| Step: 3
Training loss: 1.1307063102722168
Validation loss: 1.8683125485656082

Epoch: 5| Step: 4
Training loss: 0.6702872514724731
Validation loss: 1.8679951057639173

Epoch: 5| Step: 5
Training loss: 0.8200976252555847
Validation loss: 1.8891099960573259

Epoch: 5| Step: 6
Training loss: 1.2847177982330322
Validation loss: 1.8864374263312227

Epoch: 5| Step: 7
Training loss: 1.8201757669448853
Validation loss: 1.8447228682938444

Epoch: 5| Step: 8
Training loss: 1.3422834873199463
Validation loss: 1.8624450929703251

Epoch: 5| Step: 9
Training loss: 1.113582730293274
Validation loss: 1.8993816606460079

Epoch: 5| Step: 10
Training loss: 1.428999662399292
Validation loss: 1.8983285580911944

Epoch: 497| Step: 0
Training loss: 1.1925444602966309
Validation loss: 1.9033073327874626

Epoch: 5| Step: 1
Training loss: 0.9845096468925476
Validation loss: 1.862235064147621

Epoch: 5| Step: 2
Training loss: 0.779578685760498
Validation loss: 1.908072594673403

Epoch: 5| Step: 3
Training loss: 1.65805184841156
Validation loss: 1.8457531044560094

Epoch: 5| Step: 4
Training loss: 1.576483964920044
Validation loss: 1.8668986571732389

Epoch: 5| Step: 5
Training loss: 1.0284907817840576
Validation loss: 1.8561774171808714

Epoch: 5| Step: 6
Training loss: 0.7988077402114868
Validation loss: 1.8737490612973449

Epoch: 5| Step: 7
Training loss: 1.3256032466888428
Validation loss: 1.8254941176342707

Epoch: 5| Step: 8
Training loss: 1.1855063438415527
Validation loss: 1.8473635206940353

Epoch: 5| Step: 9
Training loss: 0.8779842257499695
Validation loss: 1.855257841848558

Epoch: 5| Step: 10
Training loss: 1.034170150756836
Validation loss: 1.8869226850489134

Epoch: 498| Step: 0
Training loss: 1.4155207872390747
Validation loss: 1.8623553373480355

Epoch: 5| Step: 1
Training loss: 0.8677033185958862
Validation loss: 1.8448708339404034

Epoch: 5| Step: 2
Training loss: 1.2144404649734497
Validation loss: 1.851623901756861

Epoch: 5| Step: 3
Training loss: 1.0090874433517456
Validation loss: 1.9061923757676156

Epoch: 5| Step: 4
Training loss: 1.2715904712677002
Validation loss: 1.929226356167947

Epoch: 5| Step: 5
Training loss: 1.6593526601791382
Validation loss: 1.9129102127526396

Epoch: 5| Step: 6
Training loss: 0.5690373182296753
Validation loss: 1.9055738077368787

Epoch: 5| Step: 7
Training loss: 1.1398427486419678
Validation loss: 1.917994232587917

Epoch: 5| Step: 8
Training loss: 1.183962106704712
Validation loss: 1.9328027899547289

Epoch: 5| Step: 9
Training loss: 1.4237592220306396
Validation loss: 1.9118958673169535

Epoch: 5| Step: 10
Training loss: 1.114314079284668
Validation loss: 1.9328682294455908

Epoch: 499| Step: 0
Training loss: 1.1854023933410645
Validation loss: 1.9296171716464463

Epoch: 5| Step: 1
Training loss: 1.013607382774353
Validation loss: 1.902801505980953

Epoch: 5| Step: 2
Training loss: 1.2528504133224487
Validation loss: 1.8977923213794667

Epoch: 5| Step: 3
Training loss: 0.8515751957893372
Validation loss: 1.8750996192296345

Epoch: 5| Step: 4
Training loss: 1.3580448627471924
Validation loss: 1.8899602223468084

Epoch: 5| Step: 5
Training loss: 1.647881269454956
Validation loss: 1.8698225559726838

Epoch: 5| Step: 6
Training loss: 1.2823119163513184
Validation loss: 1.8603075319720852

Epoch: 5| Step: 7
Training loss: 1.5540497303009033
Validation loss: 1.8960758383556078

Epoch: 5| Step: 8
Training loss: 1.4138836860656738
Validation loss: 1.885032420517296

Epoch: 5| Step: 9
Training loss: 0.7617391347885132
Validation loss: 1.8671437489089144

Epoch: 5| Step: 10
Training loss: 1.119874358177185
Validation loss: 1.8643389799261605

Epoch: 500| Step: 0
Training loss: 1.1035900115966797
Validation loss: 1.8691018986445602

Epoch: 5| Step: 1
Training loss: 1.3555898666381836
Validation loss: 1.8708018769500077

Epoch: 5| Step: 2
Training loss: 0.8937678337097168
Validation loss: 1.8949163959872337

Epoch: 5| Step: 3
Training loss: 1.4385178089141846
Validation loss: 1.9796001129252936

Epoch: 5| Step: 4
Training loss: 1.2596113681793213
Validation loss: 1.9133333724032167

Epoch: 5| Step: 5
Training loss: 1.2756162881851196
Validation loss: 1.9365369863407587

Epoch: 5| Step: 6
Training loss: 0.8636205792427063
Validation loss: 1.952670261424075

Epoch: 5| Step: 7
Training loss: 1.3688220977783203
Validation loss: 1.8468702134265695

Epoch: 5| Step: 8
Training loss: 1.5088540315628052
Validation loss: 1.8953108428626932

Epoch: 5| Step: 9
Training loss: 1.0490775108337402
Validation loss: 1.9315533022726736

Epoch: 5| Step: 10
Training loss: 0.7772908210754395
Validation loss: 1.9333481378452753

Epoch: 501| Step: 0
Training loss: 1.1018966436386108
Validation loss: 1.8995444415717997

Epoch: 5| Step: 1
Training loss: 1.2791048288345337
Validation loss: 1.861952058730587

Epoch: 5| Step: 2
Training loss: 1.099208950996399
Validation loss: 1.9314963740687217

Epoch: 5| Step: 3
Training loss: 1.0514276027679443
Validation loss: 1.9012438071671354

Epoch: 5| Step: 4
Training loss: 1.0816597938537598
Validation loss: 1.9036075069058327

Epoch: 5| Step: 5
Training loss: 1.0853021144866943
Validation loss: 1.8810122346365323

Epoch: 5| Step: 6
Training loss: 1.109810709953308
Validation loss: 1.8923348983128865

Epoch: 5| Step: 7
Training loss: 1.0608593225479126
Validation loss: 1.9028734750645135

Epoch: 5| Step: 8
Training loss: 1.342813491821289
Validation loss: 1.821203311284383

Epoch: 5| Step: 9
Training loss: 1.109740972518921
Validation loss: 1.8781851850530153

Epoch: 5| Step: 10
Training loss: 1.3535479307174683
Validation loss: 1.8412615214624712

Epoch: 502| Step: 0
Training loss: 0.8400853872299194
Validation loss: 1.883922323103874

Epoch: 5| Step: 1
Training loss: 1.2456645965576172
Validation loss: 1.8690545648656867

Epoch: 5| Step: 2
Training loss: 1.5952383279800415
Validation loss: 1.8329597493653655

Epoch: 5| Step: 3
Training loss: 1.0513629913330078
Validation loss: 1.8743352351650115

Epoch: 5| Step: 4
Training loss: 1.2143020629882812
Validation loss: 1.8663286124506304

Epoch: 5| Step: 5
Training loss: 1.6843430995941162
Validation loss: 1.8451407147992043

Epoch: 5| Step: 6
Training loss: 0.924832820892334
Validation loss: 1.894557660625827

Epoch: 5| Step: 7
Training loss: 1.215128779411316
Validation loss: 1.9120960325323126

Epoch: 5| Step: 8
Training loss: 1.4877878427505493
Validation loss: 1.8793386028658958

Epoch: 5| Step: 9
Training loss: 0.8567215204238892
Validation loss: 1.8562062043015675

Epoch: 5| Step: 10
Training loss: 0.5839375257492065
Validation loss: 1.856668585090227

Epoch: 503| Step: 0
Training loss: 1.0692564249038696
Validation loss: 1.8615265828306957

Epoch: 5| Step: 1
Training loss: 1.269920825958252
Validation loss: 1.8846252938752532

Epoch: 5| Step: 2
Training loss: 1.2506916522979736
Validation loss: 1.8733220766949397

Epoch: 5| Step: 3
Training loss: 1.0387012958526611
Validation loss: 1.8343915324057303

Epoch: 5| Step: 4
Training loss: 1.046691656112671
Validation loss: 1.858601482965613

Epoch: 5| Step: 5
Training loss: 1.0250625610351562
Validation loss: 1.8719186513654646

Epoch: 5| Step: 6
Training loss: 0.9681475758552551
Validation loss: 1.8783570669030631

Epoch: 5| Step: 7
Training loss: 1.2874115705490112
Validation loss: 1.9104067305082917

Epoch: 5| Step: 8
Training loss: 0.6489320993423462
Validation loss: 1.8461195794484948

Epoch: 5| Step: 9
Training loss: 1.5456610918045044
Validation loss: 1.8666561367691203

Epoch: 5| Step: 10
Training loss: 1.5465635061264038
Validation loss: 1.8568442521556732

Epoch: 504| Step: 0
Training loss: 1.046457052230835
Validation loss: 1.8994262628657843

Epoch: 5| Step: 1
Training loss: 1.1827865839004517
Validation loss: 1.8799022628415016

Epoch: 5| Step: 2
Training loss: 0.7895652055740356
Validation loss: 1.849582391400491

Epoch: 5| Step: 3
Training loss: 1.3823515176773071
Validation loss: 1.892788787041941

Epoch: 5| Step: 4
Training loss: 1.174113154411316
Validation loss: 1.8158826123001754

Epoch: 5| Step: 5
Training loss: 1.3250828981399536
Validation loss: 1.8781229571629596

Epoch: 5| Step: 6
Training loss: 1.066842794418335
Validation loss: 1.9050832461285334

Epoch: 5| Step: 7
Training loss: 1.407320499420166
Validation loss: 1.8766889033779022

Epoch: 5| Step: 8
Training loss: 1.466457486152649
Validation loss: 1.82719176302674

Epoch: 5| Step: 9
Training loss: 0.5731126070022583
Validation loss: 1.8648377400572582

Epoch: 5| Step: 10
Training loss: 1.0571660995483398
Validation loss: 1.8598573553946711

Epoch: 505| Step: 0
Training loss: 0.9023798108100891
Validation loss: 1.8924099886289207

Epoch: 5| Step: 1
Training loss: 1.4640097618103027
Validation loss: 1.819833924693446

Epoch: 5| Step: 2
Training loss: 1.2250622510910034
Validation loss: 1.8883900591122207

Epoch: 5| Step: 3
Training loss: 0.8926919102668762
Validation loss: 1.8654664024229972

Epoch: 5| Step: 4
Training loss: 1.0711640119552612
Validation loss: 1.8987298037416191

Epoch: 5| Step: 5
Training loss: 1.4254560470581055
Validation loss: 1.8549259990774176

Epoch: 5| Step: 6
Training loss: 0.891558051109314
Validation loss: 1.8706603204050372

Epoch: 5| Step: 7
Training loss: 1.2047734260559082
Validation loss: 1.8688671537624892

Epoch: 5| Step: 8
Training loss: 1.450150489807129
Validation loss: 1.894330286210583

Epoch: 5| Step: 9
Training loss: 1.2187834978103638
Validation loss: 1.897749339380572

Epoch: 5| Step: 10
Training loss: 0.9069504737854004
Validation loss: 1.8955425267578454

Epoch: 506| Step: 0
Training loss: 0.7561721205711365
Validation loss: 1.8937324080415951

Epoch: 5| Step: 1
Training loss: 0.7856518626213074
Validation loss: 1.9029624551855109

Epoch: 5| Step: 2
Training loss: 1.465595006942749
Validation loss: 1.8775814092287453

Epoch: 5| Step: 3
Training loss: 1.2585474252700806
Validation loss: 1.8747815931996992

Epoch: 5| Step: 4
Training loss: 1.210628867149353
Validation loss: 1.8984896790596746

Epoch: 5| Step: 5
Training loss: 0.958779513835907
Validation loss: 1.885430294980285

Epoch: 5| Step: 6
Training loss: 1.1866374015808105
Validation loss: 1.8918134691894695

Epoch: 5| Step: 7
Training loss: 1.4454923868179321
Validation loss: 1.8912930642404864

Epoch: 5| Step: 8
Training loss: 1.343945860862732
Validation loss: 1.8755349933460195

Epoch: 5| Step: 9
Training loss: 0.9852340817451477
Validation loss: 1.910263947261277

Epoch: 5| Step: 10
Training loss: 1.1136666536331177
Validation loss: 1.8771061781914002

Epoch: 507| Step: 0
Training loss: 1.240976095199585
Validation loss: 1.9291759690930765

Epoch: 5| Step: 1
Training loss: 0.7979322671890259
Validation loss: 1.854422430838308

Epoch: 5| Step: 2
Training loss: 1.425010323524475
Validation loss: 1.912144055930517

Epoch: 5| Step: 3
Training loss: 1.0991190671920776
Validation loss: 1.849956209941577

Epoch: 5| Step: 4
Training loss: 1.640552282333374
Validation loss: 1.8581735331525084

Epoch: 5| Step: 5
Training loss: 0.7145823836326599
Validation loss: 1.8590146290358676

Epoch: 5| Step: 6
Training loss: 1.5092490911483765
Validation loss: 1.8610850649495279

Epoch: 5| Step: 7
Training loss: 1.2041561603546143
Validation loss: 1.8699637177169963

Epoch: 5| Step: 8
Training loss: 0.917066752910614
Validation loss: 1.871228410351661

Epoch: 5| Step: 9
Training loss: 1.1137653589248657
Validation loss: 1.8678862638370965

Epoch: 5| Step: 10
Training loss: 0.9837701320648193
Validation loss: 1.8895060490536433

Epoch: 508| Step: 0
Training loss: 1.3816434144973755
Validation loss: 1.8626047834273307

Epoch: 5| Step: 1
Training loss: 1.1938482522964478
Validation loss: 1.8899632858973678

Epoch: 5| Step: 2
Training loss: 1.2361410856246948
Validation loss: 1.8674559785473732

Epoch: 5| Step: 3
Training loss: 1.5092254877090454
Validation loss: 1.87800855277687

Epoch: 5| Step: 4
Training loss: 0.9532220959663391
Validation loss: 1.9148617226590392

Epoch: 5| Step: 5
Training loss: 1.4605351686477661
Validation loss: 1.9354270299275715

Epoch: 5| Step: 6
Training loss: 0.8620021939277649
Validation loss: 1.8233147372481644

Epoch: 5| Step: 7
Training loss: 1.0512423515319824
Validation loss: 1.8668217671814786

Epoch: 5| Step: 8
Training loss: 1.0333092212677002
Validation loss: 1.8659614209205873

Epoch: 5| Step: 9
Training loss: 0.9487172961235046
Validation loss: 1.8524180150801135

Epoch: 5| Step: 10
Training loss: 1.3704131841659546
Validation loss: 1.9123282285146816

Epoch: 509| Step: 0
Training loss: 0.9446932077407837
Validation loss: 1.8895967378411243

Epoch: 5| Step: 1
Training loss: 1.4420784711837769
Validation loss: 1.8562946345216484

Epoch: 5| Step: 2
Training loss: 1.1958611011505127
Validation loss: 1.8956307467593942

Epoch: 5| Step: 3
Training loss: 0.9599125981330872
Validation loss: 1.8699439648658998

Epoch: 5| Step: 4
Training loss: 1.090298056602478
Validation loss: 1.8540163629798478

Epoch: 5| Step: 5
Training loss: 0.8978562355041504
Validation loss: 1.8476683555110809

Epoch: 5| Step: 6
Training loss: 1.1999528408050537
Validation loss: 1.8806357486273653

Epoch: 5| Step: 7
Training loss: 1.9571592807769775
Validation loss: 1.9227718807035876

Epoch: 5| Step: 8
Training loss: 1.2199060916900635
Validation loss: 1.8138666922046291

Epoch: 5| Step: 9
Training loss: 0.8366454839706421
Validation loss: 1.9141500303822179

Epoch: 5| Step: 10
Training loss: 1.0444722175598145
Validation loss: 1.8686574851312945

Epoch: 510| Step: 0
Training loss: 0.6268407106399536
Validation loss: 1.8862300111401467

Epoch: 5| Step: 1
Training loss: 1.220441222190857
Validation loss: 1.9228972696488904

Epoch: 5| Step: 2
Training loss: 1.1854660511016846
Validation loss: 1.9312122765407767

Epoch: 5| Step: 3
Training loss: 1.71468186378479
Validation loss: 1.8859448612377208

Epoch: 5| Step: 4
Training loss: 1.3718799352645874
Validation loss: 1.8664110681062103

Epoch: 5| Step: 5
Training loss: 0.8953957557678223
Validation loss: 1.8969214295828214

Epoch: 5| Step: 6
Training loss: 1.341684103012085
Validation loss: 1.929556546672698

Epoch: 5| Step: 7
Training loss: 1.2692173719406128
Validation loss: 1.8560256150461012

Epoch: 5| Step: 8
Training loss: 1.1937448978424072
Validation loss: 1.839844390910159

Epoch: 5| Step: 9
Training loss: 0.6557624340057373
Validation loss: 1.881974849649655

Epoch: 5| Step: 10
Training loss: 1.1664776802062988
Validation loss: 1.8211141388903382

Epoch: 511| Step: 0
Training loss: 1.2652835845947266
Validation loss: 1.9145386475388722

Epoch: 5| Step: 1
Training loss: 0.9794999361038208
Validation loss: 1.8750095316158828

Epoch: 5| Step: 2
Training loss: 1.2316831350326538
Validation loss: 1.848108781281338

Epoch: 5| Step: 3
Training loss: 1.1002271175384521
Validation loss: 1.834094734602077

Epoch: 5| Step: 4
Training loss: 1.1656831502914429
Validation loss: 1.8649684677841842

Epoch: 5| Step: 5
Training loss: 0.5048052668571472
Validation loss: 1.8881259041447793

Epoch: 5| Step: 6
Training loss: 1.2485475540161133
Validation loss: 1.9032716622916601

Epoch: 5| Step: 7
Training loss: 1.7088514566421509
Validation loss: 1.8421227508975613

Epoch: 5| Step: 8
Training loss: 1.1312038898468018
Validation loss: 1.9144786827025875

Epoch: 5| Step: 9
Training loss: 0.928005576133728
Validation loss: 1.8785555977975168

Epoch: 5| Step: 10
Training loss: 1.5407501459121704
Validation loss: 1.8748192530806347

Epoch: 512| Step: 0
Training loss: 1.100736379623413
Validation loss: 1.901465077554026

Epoch: 5| Step: 1
Training loss: 1.2812507152557373
Validation loss: 1.8613202533414286

Epoch: 5| Step: 2
Training loss: 1.456413984298706
Validation loss: 1.8852799861661849

Epoch: 5| Step: 3
Training loss: 0.8472185134887695
Validation loss: 1.8863666839497064

Epoch: 5| Step: 4
Training loss: 1.3028013706207275
Validation loss: 1.8900956364088162

Epoch: 5| Step: 5
Training loss: 1.5604679584503174
Validation loss: 1.868757463270618

Epoch: 5| Step: 6
Training loss: 0.8989869952201843
Validation loss: 1.8575952437616163

Epoch: 5| Step: 7
Training loss: 0.5859256982803345
Validation loss: 1.8099953577082644

Epoch: 5| Step: 8
Training loss: 1.1262800693511963
Validation loss: 1.8617840043960079

Epoch: 5| Step: 9
Training loss: 1.5020250082015991
Validation loss: 1.8646384887797858

Epoch: 5| Step: 10
Training loss: 1.391982913017273
Validation loss: 1.852981387927968

Epoch: 513| Step: 0
Training loss: 1.6758390665054321
Validation loss: 1.8747383086912093

Epoch: 5| Step: 1
Training loss: 0.8300182223320007
Validation loss: 1.8930344658513223

Epoch: 5| Step: 2
Training loss: 1.4979307651519775
Validation loss: 1.8874192442945255

Epoch: 5| Step: 3
Training loss: 0.9985252618789673
Validation loss: 1.898926313205432

Epoch: 5| Step: 4
Training loss: 1.0415233373641968
Validation loss: 1.9129541702167963

Epoch: 5| Step: 5
Training loss: 0.974490761756897
Validation loss: 1.8872265610643613

Epoch: 5| Step: 6
Training loss: 1.2256698608398438
Validation loss: 1.9256473331041233

Epoch: 5| Step: 7
Training loss: 0.5915342569351196
Validation loss: 1.8936755221377137

Epoch: 5| Step: 8
Training loss: 0.8429142236709595
Validation loss: 1.8904808669961908

Epoch: 5| Step: 9
Training loss: 1.918127417564392
Validation loss: 1.8822013408907

Epoch: 5| Step: 10
Training loss: 1.099340796470642
Validation loss: 1.8461403154557752

Epoch: 514| Step: 0
Training loss: 0.996069073677063
Validation loss: 1.8685491636235227

Epoch: 5| Step: 1
Training loss: 1.3850290775299072
Validation loss: 1.8739213379480506

Epoch: 5| Step: 2
Training loss: 1.1237802505493164
Validation loss: 1.8374063673839773

Epoch: 5| Step: 3
Training loss: 1.389094591140747
Validation loss: 1.822425865357922

Epoch: 5| Step: 4
Training loss: 1.3064310550689697
Validation loss: 1.8714786703868578

Epoch: 5| Step: 5
Training loss: 1.1451666355133057
Validation loss: 1.7859099218922276

Epoch: 5| Step: 6
Training loss: 1.1217502355575562
Validation loss: 1.8770071178354242

Epoch: 5| Step: 7
Training loss: 0.7900993227958679
Validation loss: 1.856828410138366

Epoch: 5| Step: 8
Training loss: 1.1154720783233643
Validation loss: 1.8814697483534455

Epoch: 5| Step: 9
Training loss: 0.8239166140556335
Validation loss: 1.8795334780088035

Epoch: 5| Step: 10
Training loss: 1.447697639465332
Validation loss: 1.9427842837508007

Epoch: 515| Step: 0
Training loss: 1.3119361400604248
Validation loss: 1.9491031413437219

Epoch: 5| Step: 1
Training loss: 0.7610325217247009
Validation loss: 1.8999004056376796

Epoch: 5| Step: 2
Training loss: 0.9669238924980164
Validation loss: 1.8990185901682863

Epoch: 5| Step: 3
Training loss: 1.4657156467437744
Validation loss: 1.8948102587012834

Epoch: 5| Step: 4
Training loss: 0.9558576345443726
Validation loss: 1.8966907634530017

Epoch: 5| Step: 5
Training loss: 1.0355600118637085
Validation loss: 1.889271487471878

Epoch: 5| Step: 6
Training loss: 1.0293385982513428
Validation loss: 1.8767647781679708

Epoch: 5| Step: 7
Training loss: 1.4047858715057373
Validation loss: 1.8427224466877599

Epoch: 5| Step: 8
Training loss: 1.2039141654968262
Validation loss: 1.8839090113998742

Epoch: 5| Step: 9
Training loss: 1.1535836458206177
Validation loss: 1.8784790961973128

Epoch: 5| Step: 10
Training loss: 0.8662335276603699
Validation loss: 1.8409644275583246

Epoch: 516| Step: 0
Training loss: 0.7968991994857788
Validation loss: 1.7830623901018532

Epoch: 5| Step: 1
Training loss: 0.9754549860954285
Validation loss: 1.848625659942627

Epoch: 5| Step: 2
Training loss: 1.5156761407852173
Validation loss: 1.8373342201273928

Epoch: 5| Step: 3
Training loss: 0.8525249361991882
Validation loss: 1.884378053808725

Epoch: 5| Step: 4
Training loss: 0.8789221048355103
Validation loss: 1.856583938803724

Epoch: 5| Step: 5
Training loss: 0.9916883707046509
Validation loss: 1.8815691278826805

Epoch: 5| Step: 6
Training loss: 1.243884563446045
Validation loss: 1.879287149316521

Epoch: 5| Step: 7
Training loss: 1.1917932033538818
Validation loss: 1.9181709392096407

Epoch: 5| Step: 8
Training loss: 1.1890102624893188
Validation loss: 1.86919197856739

Epoch: 5| Step: 9
Training loss: 1.0132672786712646
Validation loss: 1.9017485328899917

Epoch: 5| Step: 10
Training loss: 1.7018699645996094
Validation loss: 1.854725996653239

Epoch: 517| Step: 0
Training loss: 1.3769031763076782
Validation loss: 1.8607484858523133

Epoch: 5| Step: 1
Training loss: 1.0354530811309814
Validation loss: 1.8591937352252264

Epoch: 5| Step: 2
Training loss: 1.165987253189087
Validation loss: 1.9220001876995128

Epoch: 5| Step: 3
Training loss: 1.2974096536636353
Validation loss: 1.929160483421818

Epoch: 5| Step: 4
Training loss: 1.138577938079834
Validation loss: 1.8977381619074012

Epoch: 5| Step: 5
Training loss: 1.1450589895248413
Validation loss: 1.9277140978843934

Epoch: 5| Step: 6
Training loss: 1.1380102634429932
Validation loss: 1.89198011736716

Epoch: 5| Step: 7
Training loss: 0.9991361498832703
Validation loss: 1.8876780720167263

Epoch: 5| Step: 8
Training loss: 0.9580982327461243
Validation loss: 1.869494383053113

Epoch: 5| Step: 9
Training loss: 1.1776376962661743
Validation loss: 1.8592897615125101

Epoch: 5| Step: 10
Training loss: 1.225082278251648
Validation loss: 1.9118248211440219

Epoch: 518| Step: 0
Training loss: 1.3924305438995361
Validation loss: 1.8446158747519217

Epoch: 5| Step: 1
Training loss: 0.974291980266571
Validation loss: 1.8485393703624766

Epoch: 5| Step: 2
Training loss: 1.1666100025177002
Validation loss: 1.8758922341049358

Epoch: 5| Step: 3
Training loss: 0.8460636138916016
Validation loss: 1.874528936160508

Epoch: 5| Step: 4
Training loss: 0.8900636434555054
Validation loss: 1.8872045214458177

Epoch: 5| Step: 5
Training loss: 1.0381723642349243
Validation loss: 1.8803656780591576

Epoch: 5| Step: 6
Training loss: 0.8466920852661133
Validation loss: 1.9146603409961989

Epoch: 5| Step: 7
Training loss: 1.1339561939239502
Validation loss: 1.8485248601564797

Epoch: 5| Step: 8
Training loss: 1.5130279064178467
Validation loss: 1.8742408778077813

Epoch: 5| Step: 9
Training loss: 0.8912725448608398
Validation loss: 1.84921900046769

Epoch: 5| Step: 10
Training loss: 1.5396462678909302
Validation loss: 1.9195186117643952

Epoch: 519| Step: 0
Training loss: 1.0890485048294067
Validation loss: 1.880345465034567

Epoch: 5| Step: 1
Training loss: 0.9526985287666321
Validation loss: 1.8996460373683641

Epoch: 5| Step: 2
Training loss: 1.930132269859314
Validation loss: 1.808265673216953

Epoch: 5| Step: 3
Training loss: 0.6999586820602417
Validation loss: 1.853521143236468

Epoch: 5| Step: 4
Training loss: 0.8957515954971313
Validation loss: 1.8340024384119178

Epoch: 5| Step: 5
Training loss: 1.6692817211151123
Validation loss: 1.8796176269490232

Epoch: 5| Step: 6
Training loss: 0.9181275367736816
Validation loss: 1.8701612154642742

Epoch: 5| Step: 7
Training loss: 0.9401187896728516
Validation loss: 1.8186888053853025

Epoch: 5| Step: 8
Training loss: 1.043513536453247
Validation loss: 1.8202771922593475

Epoch: 5| Step: 9
Training loss: 0.6617473363876343
Validation loss: 1.8934437664606238

Epoch: 5| Step: 10
Training loss: 1.3927100896835327
Validation loss: 1.8593599437385477

Epoch: 520| Step: 0
Training loss: 1.3070275783538818
Validation loss: 1.881001824973732

Epoch: 5| Step: 1
Training loss: 0.8689400553703308
Validation loss: 1.8546780540097145

Epoch: 5| Step: 2
Training loss: 1.229533314704895
Validation loss: 1.9774636530107068

Epoch: 5| Step: 3
Training loss: 0.9694169759750366
Validation loss: 1.8614197879709222

Epoch: 5| Step: 4
Training loss: 0.9119987487792969
Validation loss: 1.9411590817154094

Epoch: 5| Step: 5
Training loss: 1.3334497213363647
Validation loss: 1.9102466875506985

Epoch: 5| Step: 6
Training loss: 1.087145209312439
Validation loss: 1.880351435753607

Epoch: 5| Step: 7
Training loss: 1.448110580444336
Validation loss: 1.9244271747527584

Epoch: 5| Step: 8
Training loss: 1.0536015033721924
Validation loss: 1.8764957586924236

Epoch: 5| Step: 9
Training loss: 0.8380368947982788
Validation loss: 1.859648698119707

Epoch: 5| Step: 10
Training loss: 1.4147993326187134
Validation loss: 1.867793280591247

Epoch: 521| Step: 0
Training loss: 1.1464937925338745
Validation loss: 1.8836080053801179

Epoch: 5| Step: 1
Training loss: 1.073108434677124
Validation loss: 1.8059011351677678

Epoch: 5| Step: 2
Training loss: 0.5980337262153625
Validation loss: 1.872090744715865

Epoch: 5| Step: 3
Training loss: 1.3506219387054443
Validation loss: 1.8613316782059208

Epoch: 5| Step: 4
Training loss: 1.9096729755401611
Validation loss: 1.8743457973644297

Epoch: 5| Step: 5
Training loss: 1.1032676696777344
Validation loss: 1.8630347431346934

Epoch: 5| Step: 6
Training loss: 0.8451040387153625
Validation loss: 1.861316139980029

Epoch: 5| Step: 7
Training loss: 1.4240014553070068
Validation loss: 1.9222952704275809

Epoch: 5| Step: 8
Training loss: 0.9099262952804565
Validation loss: 1.9003110137037051

Epoch: 5| Step: 9
Training loss: 0.9368874430656433
Validation loss: 1.8018972104595554

Epoch: 5| Step: 10
Training loss: 1.0232959985733032
Validation loss: 1.8016235341307938

Epoch: 522| Step: 0
Training loss: 0.7180126905441284
Validation loss: 1.9258830983151671

Epoch: 5| Step: 1
Training loss: 1.072899580001831
Validation loss: 1.9000490250126008

Epoch: 5| Step: 2
Training loss: 1.2196073532104492
Validation loss: 1.9073271007948025

Epoch: 5| Step: 3
Training loss: 1.9384664297103882
Validation loss: 1.8872622636056715

Epoch: 5| Step: 4
Training loss: 0.8905348777770996
Validation loss: 1.9261046532661683

Epoch: 5| Step: 5
Training loss: 1.1997319459915161
Validation loss: 1.9163243962872414

Epoch: 5| Step: 6
Training loss: 1.2260020971298218
Validation loss: 1.9007654100336053

Epoch: 5| Step: 7
Training loss: 0.9596666097640991
Validation loss: 1.9055662308969805

Epoch: 5| Step: 8
Training loss: 0.8420000076293945
Validation loss: 1.865138114139598

Epoch: 5| Step: 9
Training loss: 1.028196930885315
Validation loss: 1.8922479268043273

Epoch: 5| Step: 10
Training loss: 1.17120361328125
Validation loss: 1.8552033311577254

Epoch: 523| Step: 0
Training loss: 0.9480085372924805
Validation loss: 1.8419008255004883

Epoch: 5| Step: 1
Training loss: 0.9316574335098267
Validation loss: 1.8424222187329364

Epoch: 5| Step: 2
Training loss: 0.9426513910293579
Validation loss: 1.8545704080212502

Epoch: 5| Step: 3
Training loss: 0.7443816065788269
Validation loss: 1.9205676714579265

Epoch: 5| Step: 4
Training loss: 1.2356483936309814
Validation loss: 1.8661630999657415

Epoch: 5| Step: 5
Training loss: 1.2716028690338135
Validation loss: 1.8392469357418757

Epoch: 5| Step: 6
Training loss: 1.1295816898345947
Validation loss: 1.8299547728671823

Epoch: 5| Step: 7
Training loss: 1.4132449626922607
Validation loss: 1.848229476200637

Epoch: 5| Step: 8
Training loss: 1.3405100107192993
Validation loss: 1.8744831046750468

Epoch: 5| Step: 9
Training loss: 1.2433847188949585
Validation loss: 1.9069742643704979

Epoch: 5| Step: 10
Training loss: 1.199656367301941
Validation loss: 1.867425375087287

Epoch: 524| Step: 0
Training loss: 1.3030595779418945
Validation loss: 1.9093132659953127

Epoch: 5| Step: 1
Training loss: 1.0018393993377686
Validation loss: 1.891902651838077

Epoch: 5| Step: 2
Training loss: 1.118544578552246
Validation loss: 1.8962397754833262

Epoch: 5| Step: 3
Training loss: 1.3491933345794678
Validation loss: 1.9175735340323499

Epoch: 5| Step: 4
Training loss: 1.7817909717559814
Validation loss: 1.8563911607188563

Epoch: 5| Step: 5
Training loss: 1.3060497045516968
Validation loss: 1.8665862339799122

Epoch: 5| Step: 6
Training loss: 1.0107181072235107
Validation loss: 1.861306482745755

Epoch: 5| Step: 7
Training loss: 1.151207685470581
Validation loss: 1.8634015308913363

Epoch: 5| Step: 8
Training loss: 0.5916080474853516
Validation loss: 1.8303157514141453

Epoch: 5| Step: 9
Training loss: 0.8661817312240601
Validation loss: 1.8876889059620519

Epoch: 5| Step: 10
Training loss: 0.9398568272590637
Validation loss: 1.892916307654432

Epoch: 525| Step: 0
Training loss: 1.0602052211761475
Validation loss: 1.8604127437837663

Epoch: 5| Step: 1
Training loss: 1.422997236251831
Validation loss: 1.9118805341823126

Epoch: 5| Step: 2
Training loss: 1.1635860204696655
Validation loss: 1.8781294925238496

Epoch: 5| Step: 3
Training loss: 1.0942974090576172
Validation loss: 1.8850761741720221

Epoch: 5| Step: 4
Training loss: 0.9880695343017578
Validation loss: 1.8495739890683083

Epoch: 5| Step: 5
Training loss: 0.6843223571777344
Validation loss: 1.896147676693496

Epoch: 5| Step: 6
Training loss: 1.6060798168182373
Validation loss: 1.9249991588695075

Epoch: 5| Step: 7
Training loss: 1.4022853374481201
Validation loss: 1.891277797760502

Epoch: 5| Step: 8
Training loss: 0.7806159257888794
Validation loss: 1.880418110919255

Epoch: 5| Step: 9
Training loss: 0.8287503123283386
Validation loss: 1.8749437960245277

Epoch: 5| Step: 10
Training loss: 1.131639838218689
Validation loss: 1.8575047318653395

Epoch: 526| Step: 0
Training loss: 0.8233095407485962
Validation loss: 1.9007281885352185

Epoch: 5| Step: 1
Training loss: 0.9371781349182129
Validation loss: 1.8466148658465313

Epoch: 5| Step: 2
Training loss: 1.0700186491012573
Validation loss: 1.8317625548249932

Epoch: 5| Step: 3
Training loss: 1.0825793743133545
Validation loss: 1.8412536754403064

Epoch: 5| Step: 4
Training loss: 1.000915765762329
Validation loss: 1.8681124051411946

Epoch: 5| Step: 5
Training loss: 1.0465679168701172
Validation loss: 1.851180664954647

Epoch: 5| Step: 6
Training loss: 1.1531503200531006
Validation loss: 1.8408438595392371

Epoch: 5| Step: 7
Training loss: 0.9853770136833191
Validation loss: 1.8847289264843028

Epoch: 5| Step: 8
Training loss: 1.1878703832626343
Validation loss: 1.8987694632622503

Epoch: 5| Step: 9
Training loss: 1.5969772338867188
Validation loss: 1.8951409657796223

Epoch: 5| Step: 10
Training loss: 1.2698594331741333
Validation loss: 1.907449463362335

Epoch: 527| Step: 0
Training loss: 0.8436703681945801
Validation loss: 1.90784361029184

Epoch: 5| Step: 1
Training loss: 0.7302716374397278
Validation loss: 1.8606787420088244

Epoch: 5| Step: 2
Training loss: 1.184186339378357
Validation loss: 1.9206493195667063

Epoch: 5| Step: 3
Training loss: 1.010595440864563
Validation loss: 1.862567929811375

Epoch: 5| Step: 4
Training loss: 1.1270751953125
Validation loss: 1.874793037291496

Epoch: 5| Step: 5
Training loss: 1.5181013345718384
Validation loss: 1.9125985509605818

Epoch: 5| Step: 6
Training loss: 0.7991640567779541
Validation loss: 1.8650591450352823

Epoch: 5| Step: 7
Training loss: 1.33560049533844
Validation loss: 1.812211844228929

Epoch: 5| Step: 8
Training loss: 1.2330501079559326
Validation loss: 1.886152793002385

Epoch: 5| Step: 9
Training loss: 1.2012546062469482
Validation loss: 1.830953767222743

Epoch: 5| Step: 10
Training loss: 1.3640058040618896
Validation loss: 1.8221565856728503

Epoch: 528| Step: 0
Training loss: 1.6990251541137695
Validation loss: 1.8721139828364055

Epoch: 5| Step: 1
Training loss: 1.1414077281951904
Validation loss: 1.8319490019993117

Epoch: 5| Step: 2
Training loss: 0.9232708811759949
Validation loss: 1.8582195774201424

Epoch: 5| Step: 3
Training loss: 1.0915528535842896
Validation loss: 1.8495263438070975

Epoch: 5| Step: 4
Training loss: 1.3427133560180664
Validation loss: 1.8567502665263351

Epoch: 5| Step: 5
Training loss: 0.9043153524398804
Validation loss: 1.887437323088287

Epoch: 5| Step: 6
Training loss: 1.1126989126205444
Validation loss: 1.844879509300314

Epoch: 5| Step: 7
Training loss: 1.2911906242370605
Validation loss: 1.8375885742966847

Epoch: 5| Step: 8
Training loss: 0.6923791170120239
Validation loss: 1.8797846173727384

Epoch: 5| Step: 9
Training loss: 0.8940635919570923
Validation loss: 1.8721404383259435

Epoch: 5| Step: 10
Training loss: 1.1663191318511963
Validation loss: 1.8741426929350822

Epoch: 529| Step: 0
Training loss: 1.5896213054656982
Validation loss: 1.9071751589416175

Epoch: 5| Step: 1
Training loss: 1.05245041847229
Validation loss: 1.8871754279700659

Epoch: 5| Step: 2
Training loss: 1.1840474605560303
Validation loss: 1.8703416752558883

Epoch: 5| Step: 3
Training loss: 1.2025439739227295
Validation loss: 1.8783700517428819

Epoch: 5| Step: 4
Training loss: 1.2342960834503174
Validation loss: 1.8700334833514305

Epoch: 5| Step: 5
Training loss: 1.2945843935012817
Validation loss: 1.8704027924486386

Epoch: 5| Step: 6
Training loss: 1.0838758945465088
Validation loss: 1.8585892210724533

Epoch: 5| Step: 7
Training loss: 0.8929218053817749
Validation loss: 1.8569465285988265

Epoch: 5| Step: 8
Training loss: 0.980730414390564
Validation loss: 1.8547005999472834

Epoch: 5| Step: 9
Training loss: 0.800459086894989
Validation loss: 1.859906308112606

Epoch: 5| Step: 10
Training loss: 1.0735669136047363
Validation loss: 1.8583446818013345

Epoch: 530| Step: 0
Training loss: 0.8758047223091125
Validation loss: 1.8597432900500555

Epoch: 5| Step: 1
Training loss: 0.9896354675292969
Validation loss: 1.8710009513362762

Epoch: 5| Step: 2
Training loss: 1.0790674686431885
Validation loss: 1.8652945705639419

Epoch: 5| Step: 3
Training loss: 0.6167165040969849
Validation loss: 1.8515357650736326

Epoch: 5| Step: 4
Training loss: 0.5751816630363464
Validation loss: 1.8853445283828243

Epoch: 5| Step: 5
Training loss: 1.5447231531143188
Validation loss: 1.8465753819352837

Epoch: 5| Step: 6
Training loss: 1.1032856702804565
Validation loss: 1.886779216028029

Epoch: 5| Step: 7
Training loss: 1.6786105632781982
Validation loss: 1.846043791822208

Epoch: 5| Step: 8
Training loss: 1.1808364391326904
Validation loss: 1.9003946191521102

Epoch: 5| Step: 9
Training loss: 1.1887919902801514
Validation loss: 1.8757236734513314

Epoch: 5| Step: 10
Training loss: 1.3814401626586914
Validation loss: 1.8941726966570782

Epoch: 531| Step: 0
Training loss: 0.8831740617752075
Validation loss: 1.840919158791983

Epoch: 5| Step: 1
Training loss: 0.9695517420768738
Validation loss: 1.7880323394652335

Epoch: 5| Step: 2
Training loss: 1.299410104751587
Validation loss: 1.8276010149268693

Epoch: 5| Step: 3
Training loss: 1.2510899305343628
Validation loss: 1.8817681151051675

Epoch: 5| Step: 4
Training loss: 1.0206964015960693
Validation loss: 1.8629911484256867

Epoch: 5| Step: 5
Training loss: 1.126328945159912
Validation loss: 1.8627618282072005

Epoch: 5| Step: 6
Training loss: 1.0723068714141846
Validation loss: 1.8859398903385285

Epoch: 5| Step: 7
Training loss: 0.7933981418609619
Validation loss: 1.9041391982827136

Epoch: 5| Step: 8
Training loss: 1.101835012435913
Validation loss: 1.9617547322345037

Epoch: 5| Step: 9
Training loss: 1.383760690689087
Validation loss: 1.9027191054436468

Epoch: 5| Step: 10
Training loss: 1.5089659690856934
Validation loss: 1.849302791780041

Epoch: 532| Step: 0
Training loss: 1.1963322162628174
Validation loss: 1.8947672510659823

Epoch: 5| Step: 1
Training loss: 1.2102642059326172
Validation loss: 1.8410148197604763

Epoch: 5| Step: 2
Training loss: 0.7710667252540588
Validation loss: 1.897511795002927

Epoch: 5| Step: 3
Training loss: 0.8019158244132996
Validation loss: 1.862401431606662

Epoch: 5| Step: 4
Training loss: 1.310359001159668
Validation loss: 1.8236905221016175

Epoch: 5| Step: 5
Training loss: 1.0073301792144775
Validation loss: 1.8739362544910882

Epoch: 5| Step: 6
Training loss: 1.0509884357452393
Validation loss: 1.8056878530850975

Epoch: 5| Step: 7
Training loss: 1.2907606363296509
Validation loss: 1.8857577295713528

Epoch: 5| Step: 8
Training loss: 0.8850598335266113
Validation loss: 1.8314347843970022

Epoch: 5| Step: 9
Training loss: 1.9383246898651123
Validation loss: 1.8733822325224518

Epoch: 5| Step: 10
Training loss: 0.6794002652168274
Validation loss: 1.8214275465216687

Epoch: 533| Step: 0
Training loss: 1.0325244665145874
Validation loss: 1.860783225746565

Epoch: 5| Step: 1
Training loss: 0.9714801907539368
Validation loss: 1.9017310168153496

Epoch: 5| Step: 2
Training loss: 1.1076197624206543
Validation loss: 1.8569215369480911

Epoch: 5| Step: 3
Training loss: 1.2079306840896606
Validation loss: 1.913438517560241

Epoch: 5| Step: 4
Training loss: 1.732210397720337
Validation loss: 1.9263218192644016

Epoch: 5| Step: 5
Training loss: 1.131447196006775
Validation loss: 1.9364110910764305

Epoch: 5| Step: 6
Training loss: 0.879245400428772
Validation loss: 1.9151331814386512

Epoch: 5| Step: 7
Training loss: 1.0597989559173584
Validation loss: 1.9689589059481056

Epoch: 5| Step: 8
Training loss: 0.9390308260917664
Validation loss: 1.9261237241888558

Epoch: 5| Step: 9
Training loss: 0.7889732122421265
Validation loss: 1.8830576481357697

Epoch: 5| Step: 10
Training loss: 1.2749297618865967
Validation loss: 1.8798474483592535

Epoch: 534| Step: 0
Training loss: 1.0058988332748413
Validation loss: 1.9245493194108367

Epoch: 5| Step: 1
Training loss: 0.7669174075126648
Validation loss: 1.8901874762709423

Epoch: 5| Step: 2
Training loss: 1.0058302879333496
Validation loss: 1.847874367108909

Epoch: 5| Step: 3
Training loss: 1.0677506923675537
Validation loss: 1.8673464918649325

Epoch: 5| Step: 4
Training loss: 0.9815500378608704
Validation loss: 1.8187026105901247

Epoch: 5| Step: 5
Training loss: 1.6336758136749268
Validation loss: 1.8653717605016564

Epoch: 5| Step: 6
Training loss: 1.1093162298202515
Validation loss: 1.888692823789453

Epoch: 5| Step: 7
Training loss: 1.2820669412612915
Validation loss: 1.8224815399416032

Epoch: 5| Step: 8
Training loss: 1.0994760990142822
Validation loss: 1.835986211735715

Epoch: 5| Step: 9
Training loss: 1.0322110652923584
Validation loss: 1.809525848716818

Epoch: 5| Step: 10
Training loss: 0.8437526822090149
Validation loss: 1.8441483359183035

Epoch: 535| Step: 0
Training loss: 1.2041383981704712
Validation loss: 1.8467046086506178

Epoch: 5| Step: 1
Training loss: 0.7682385444641113
Validation loss: 1.8710671547920472

Epoch: 5| Step: 2
Training loss: 1.0956051349639893
Validation loss: 1.892847248302993

Epoch: 5| Step: 3
Training loss: 0.9251275062561035
Validation loss: 1.9394777513319446

Epoch: 5| Step: 4
Training loss: 1.126377820968628
Validation loss: 1.9544166954614783

Epoch: 5| Step: 5
Training loss: 1.6269477605819702
Validation loss: 1.9260395521758704

Epoch: 5| Step: 6
Training loss: 1.120314359664917
Validation loss: 1.8768584933332217

Epoch: 5| Step: 7
Training loss: 0.6388645768165588
Validation loss: 1.9303094956182665

Epoch: 5| Step: 8
Training loss: 1.5907318592071533
Validation loss: 1.8887421059352096

Epoch: 5| Step: 9
Training loss: 1.31801438331604
Validation loss: 1.862616906883896

Epoch: 5| Step: 10
Training loss: 0.8838493824005127
Validation loss: 1.8593270060836629

Epoch: 536| Step: 0
Training loss: 0.8636326789855957
Validation loss: 1.877635096990934

Epoch: 5| Step: 1
Training loss: 1.2028284072875977
Validation loss: 1.8980676102381882

Epoch: 5| Step: 2
Training loss: 1.1960618495941162
Validation loss: 1.850666921625855

Epoch: 5| Step: 3
Training loss: 1.1626884937286377
Validation loss: 1.8341940743948824

Epoch: 5| Step: 4
Training loss: 1.3263511657714844
Validation loss: 1.848331202742874

Epoch: 5| Step: 5
Training loss: 1.511544942855835
Validation loss: 1.8615076182990946

Epoch: 5| Step: 6
Training loss: 1.1878001689910889
Validation loss: 1.829848620199388

Epoch: 5| Step: 7
Training loss: 1.1708829402923584
Validation loss: 1.8454865306936286

Epoch: 5| Step: 8
Training loss: 1.0022519826889038
Validation loss: 1.86681148698253

Epoch: 5| Step: 9
Training loss: 0.61671382188797
Validation loss: 1.7995894801232122

Epoch: 5| Step: 10
Training loss: 1.1955621242523193
Validation loss: 1.870468480612642

Epoch: 537| Step: 0
Training loss: 1.0573804378509521
Validation loss: 1.855700272385792

Epoch: 5| Step: 1
Training loss: 0.8208051919937134
Validation loss: 1.9025198464752526

Epoch: 5| Step: 2
Training loss: 0.909309983253479
Validation loss: 1.897736305831581

Epoch: 5| Step: 3
Training loss: 1.481905460357666
Validation loss: 1.90814806056279

Epoch: 5| Step: 4
Training loss: 1.2393711805343628
Validation loss: 1.9338824338810419

Epoch: 5| Step: 5
Training loss: 1.323137879371643
Validation loss: 1.955047881731423

Epoch: 5| Step: 6
Training loss: 1.3459672927856445
Validation loss: 1.9317301127218431

Epoch: 5| Step: 7
Training loss: 0.5662403106689453
Validation loss: 1.8906986598045594

Epoch: 5| Step: 8
Training loss: 1.3206576108932495
Validation loss: 1.9148525858438143

Epoch: 5| Step: 9
Training loss: 1.2514936923980713
Validation loss: 1.8630416624007686

Epoch: 5| Step: 10
Training loss: 1.0680663585662842
Validation loss: 1.9176646022386448

Epoch: 538| Step: 0
Training loss: 1.3031381368637085
Validation loss: 1.8784463226154287

Epoch: 5| Step: 1
Training loss: 0.6227712631225586
Validation loss: 1.8811703728091331

Epoch: 5| Step: 2
Training loss: 0.7053804993629456
Validation loss: 1.8556661657107774

Epoch: 5| Step: 3
Training loss: 1.2853165864944458
Validation loss: 1.8264183895562285

Epoch: 5| Step: 4
Training loss: 1.0307366847991943
Validation loss: 1.8080102423185944

Epoch: 5| Step: 5
Training loss: 1.3140223026275635
Validation loss: 1.866891675097968

Epoch: 5| Step: 6
Training loss: 1.2476507425308228
Validation loss: 1.8871962088410572

Epoch: 5| Step: 7
Training loss: 0.9470747113227844
Validation loss: 1.8868984637721893

Epoch: 5| Step: 8
Training loss: 1.331778645515442
Validation loss: 1.8611190216515654

Epoch: 5| Step: 9
Training loss: 0.9749120473861694
Validation loss: 1.8955839962087653

Epoch: 5| Step: 10
Training loss: 1.2808126211166382
Validation loss: 1.864226654011716

Epoch: 539| Step: 0
Training loss: 0.7712720036506653
Validation loss: 1.8461967565680062

Epoch: 5| Step: 1
Training loss: 0.7877631783485413
Validation loss: 1.8922518735290856

Epoch: 5| Step: 2
Training loss: 1.7801851034164429
Validation loss: 1.8223022542974001

Epoch: 5| Step: 3
Training loss: 1.2431271076202393
Validation loss: 1.8432456575414187

Epoch: 5| Step: 4
Training loss: 0.8314636945724487
Validation loss: 1.9071174757454985

Epoch: 5| Step: 5
Training loss: 0.919468104839325
Validation loss: 1.8759373772528865

Epoch: 5| Step: 6
Training loss: 0.9915863275527954
Validation loss: 1.8966150104358632

Epoch: 5| Step: 7
Training loss: 0.9176099896430969
Validation loss: 1.9043703976497854

Epoch: 5| Step: 8
Training loss: 1.3961063623428345
Validation loss: 1.9030209907921412

Epoch: 5| Step: 9
Training loss: 1.0668295621871948
Validation loss: 1.8994376685029717

Epoch: 5| Step: 10
Training loss: 1.1844725608825684
Validation loss: 1.878835972919259

Epoch: 540| Step: 0
Training loss: 0.8925375938415527
Validation loss: 1.81345489973663

Epoch: 5| Step: 1
Training loss: 1.244027018547058
Validation loss: 1.8637504193090624

Epoch: 5| Step: 2
Training loss: 1.04547917842865
Validation loss: 1.8873691405019453

Epoch: 5| Step: 3
Training loss: 1.0530242919921875
Validation loss: 1.8509731882361955

Epoch: 5| Step: 4
Training loss: 0.7333537936210632
Validation loss: 1.8498866506802139

Epoch: 5| Step: 5
Training loss: 1.2654597759246826
Validation loss: 1.8418007114882111

Epoch: 5| Step: 6
Training loss: 1.5377393960952759
Validation loss: 1.817957288475447

Epoch: 5| Step: 7
Training loss: 1.0108544826507568
Validation loss: 1.8845100723287111

Epoch: 5| Step: 8
Training loss: 1.0309433937072754
Validation loss: 1.8593978715199295

Epoch: 5| Step: 9
Training loss: 0.9186979532241821
Validation loss: 1.8792231031643447

Epoch: 5| Step: 10
Training loss: 1.202040672302246
Validation loss: 1.8383734790227746

Epoch: 541| Step: 0
Training loss: 0.9601485133171082
Validation loss: 1.8918103992298085

Epoch: 5| Step: 1
Training loss: 0.6829443573951721
Validation loss: 1.866240293748917

Epoch: 5| Step: 2
Training loss: 1.0877020359039307
Validation loss: 1.851682347636069

Epoch: 5| Step: 3
Training loss: 1.2985984086990356
Validation loss: 1.8717780869494203

Epoch: 5| Step: 4
Training loss: 1.0221325159072876
Validation loss: 1.889377522212203

Epoch: 5| Step: 5
Training loss: 1.5293629169464111
Validation loss: 1.8183684400332871

Epoch: 5| Step: 6
Training loss: 1.1025118827819824
Validation loss: 1.866165130369125

Epoch: 5| Step: 7
Training loss: 1.343084692955017
Validation loss: 1.8734579355485979

Epoch: 5| Step: 8
Training loss: 0.9863214492797852
Validation loss: 1.8773893771633026

Epoch: 5| Step: 9
Training loss: 0.8539612889289856
Validation loss: 1.84288441493947

Epoch: 5| Step: 10
Training loss: 1.0866588354110718
Validation loss: 1.8949843068276682

Epoch: 542| Step: 0
Training loss: 1.111676812171936
Validation loss: 1.8245853890654862

Epoch: 5| Step: 1
Training loss: 1.1357853412628174
Validation loss: 1.8774673554205126

Epoch: 5| Step: 2
Training loss: 0.9266964793205261
Validation loss: 1.8757351034431047

Epoch: 5| Step: 3
Training loss: 1.2534377574920654
Validation loss: 1.901318984646951

Epoch: 5| Step: 4
Training loss: 1.2061436176300049
Validation loss: 1.8779674024992092

Epoch: 5| Step: 5
Training loss: 0.7564746737480164
Validation loss: 1.9071963499951106

Epoch: 5| Step: 6
Training loss: 1.2759283781051636
Validation loss: 1.8915415066544727

Epoch: 5| Step: 7
Training loss: 1.1533538103103638
Validation loss: 1.8585801291209396

Epoch: 5| Step: 8
Training loss: 1.0147682428359985
Validation loss: 1.8393121304050568

Epoch: 5| Step: 9
Training loss: 1.10597825050354
Validation loss: 1.905681690862102

Epoch: 5| Step: 10
Training loss: 0.7623754143714905
Validation loss: 1.868642968516196

Epoch: 543| Step: 0
Training loss: 1.5053436756134033
Validation loss: 1.8883909563864432

Epoch: 5| Step: 1
Training loss: 1.124108910560608
Validation loss: 1.8590058716394569

Epoch: 5| Step: 2
Training loss: 1.3930597305297852
Validation loss: 1.8759505492384716

Epoch: 5| Step: 3
Training loss: 1.140070915222168
Validation loss: 1.8894203529563

Epoch: 5| Step: 4
Training loss: 0.6450329422950745
Validation loss: 1.8928770980527323

Epoch: 5| Step: 5
Training loss: 1.1526212692260742
Validation loss: 1.836314542319185

Epoch: 5| Step: 6
Training loss: 1.2042696475982666
Validation loss: 1.8333275766782864

Epoch: 5| Step: 7
Training loss: 0.9214391708374023
Validation loss: 1.8173945206467823

Epoch: 5| Step: 8
Training loss: 0.7464786767959595
Validation loss: 1.8391964435577393

Epoch: 5| Step: 9
Training loss: 0.6804530024528503
Validation loss: 1.8627537783756052

Epoch: 5| Step: 10
Training loss: 1.203370451927185
Validation loss: 1.8958953221638997

Epoch: 544| Step: 0
Training loss: 1.19768488407135
Validation loss: 1.8755867506868096

Epoch: 5| Step: 1
Training loss: 0.7793568968772888
Validation loss: 1.8651107806031422

Epoch: 5| Step: 2
Training loss: 0.7901805639266968
Validation loss: 1.863179809303694

Epoch: 5| Step: 3
Training loss: 0.933635413646698
Validation loss: 1.8233594554726795

Epoch: 5| Step: 4
Training loss: 1.1016690731048584
Validation loss: 1.8755333679978565

Epoch: 5| Step: 5
Training loss: 0.7747344970703125
Validation loss: 1.8827707293213054

Epoch: 5| Step: 6
Training loss: 1.2292227745056152
Validation loss: 1.8976380504587644

Epoch: 5| Step: 7
Training loss: 1.307952642440796
Validation loss: 1.840558595554803

Epoch: 5| Step: 8
Training loss: 1.0120559930801392
Validation loss: 1.8658277526978524

Epoch: 5| Step: 9
Training loss: 1.16389799118042
Validation loss: 1.8522679869846632

Epoch: 5| Step: 10
Training loss: 1.494842529296875
Validation loss: 1.9009207076923822

Epoch: 545| Step: 0
Training loss: 1.1751800775527954
Validation loss: 1.8456840335681874

Epoch: 5| Step: 1
Training loss: 0.9745891690254211
Validation loss: 1.8508912773542507

Epoch: 5| Step: 2
Training loss: 1.300082802772522
Validation loss: 1.8169133214540378

Epoch: 5| Step: 3
Training loss: 1.0896241664886475
Validation loss: 1.8785096996573991

Epoch: 5| Step: 4
Training loss: 1.0952465534210205
Validation loss: 1.8459504958122008

Epoch: 5| Step: 5
Training loss: 0.8851792216300964
Validation loss: 1.8501098822521906

Epoch: 5| Step: 6
Training loss: 1.2205231189727783
Validation loss: 1.8675190159069595

Epoch: 5| Step: 7
Training loss: 1.2689164876937866
Validation loss: 1.8711519587424494

Epoch: 5| Step: 8
Training loss: 0.49041667580604553
Validation loss: 1.856743702324488

Epoch: 5| Step: 9
Training loss: 0.7474908232688904
Validation loss: 1.8607197641044535

Epoch: 5| Step: 10
Training loss: 1.7167984247207642
Validation loss: 1.8491462174282278

Epoch: 546| Step: 0
Training loss: 0.964676558971405
Validation loss: 1.8632545637828049

Epoch: 5| Step: 1
Training loss: 0.9313898086547852
Validation loss: 1.8834925466968166

Epoch: 5| Step: 2
Training loss: 1.2878236770629883
Validation loss: 1.8830822642131517

Epoch: 5| Step: 3
Training loss: 0.8378775715827942
Validation loss: 1.939496903009312

Epoch: 5| Step: 4
Training loss: 1.0866672992706299
Validation loss: 1.9090215416364773

Epoch: 5| Step: 5
Training loss: 1.2888622283935547
Validation loss: 1.8632255818254204

Epoch: 5| Step: 6
Training loss: 1.3909709453582764
Validation loss: 1.8977581442043345

Epoch: 5| Step: 7
Training loss: 0.955453097820282
Validation loss: 1.8657478658101891

Epoch: 5| Step: 8
Training loss: 0.8457866907119751
Validation loss: 1.8881537811730498

Epoch: 5| Step: 9
Training loss: 1.0921297073364258
Validation loss: 1.8620382842197214

Epoch: 5| Step: 10
Training loss: 1.2154039144515991
Validation loss: 1.8368339077118905

Epoch: 547| Step: 0
Training loss: 0.7481532692909241
Validation loss: 1.9069400013134044

Epoch: 5| Step: 1
Training loss: 0.9801343679428101
Validation loss: 1.8823737636689217

Epoch: 5| Step: 2
Training loss: 1.09127938747406
Validation loss: 1.8675380329931937

Epoch: 5| Step: 3
Training loss: 1.901183843612671
Validation loss: 1.8048450177715671

Epoch: 5| Step: 4
Training loss: 1.1491161584854126
Validation loss: 1.8349468041491765

Epoch: 5| Step: 5
Training loss: 0.6993049383163452
Validation loss: 1.8261547857715237

Epoch: 5| Step: 6
Training loss: 0.7912288904190063
Validation loss: 1.8374545958734327

Epoch: 5| Step: 7
Training loss: 1.2183823585510254
Validation loss: 1.8867713187330513

Epoch: 5| Step: 8
Training loss: 0.9415349960327148
Validation loss: 1.8228705903535247

Epoch: 5| Step: 9
Training loss: 0.8523687124252319
Validation loss: 1.825128456597687

Epoch: 5| Step: 10
Training loss: 1.2897588014602661
Validation loss: 1.8801623082930041

Epoch: 548| Step: 0
Training loss: 0.9569371938705444
Validation loss: 1.8553584544889388

Epoch: 5| Step: 1
Training loss: 0.8875967860221863
Validation loss: 1.8517131972056564

Epoch: 5| Step: 2
Training loss: 0.932360053062439
Validation loss: 1.8963286261404715

Epoch: 5| Step: 3
Training loss: 1.1981273889541626
Validation loss: 1.8539372003206642

Epoch: 5| Step: 4
Training loss: 0.9174962043762207
Validation loss: 1.8393113715674287

Epoch: 5| Step: 5
Training loss: 1.4529849290847778
Validation loss: 1.8131262230616745

Epoch: 5| Step: 6
Training loss: 0.9624516367912292
Validation loss: 1.87709294596026

Epoch: 5| Step: 7
Training loss: 1.412135124206543
Validation loss: 1.851942334123837

Epoch: 5| Step: 8
Training loss: 0.6656750440597534
Validation loss: 1.9084611592754241

Epoch: 5| Step: 9
Training loss: 1.4101521968841553
Validation loss: 1.8970518830001994

Epoch: 5| Step: 10
Training loss: 0.7852570414543152
Validation loss: 1.8482642994132092

Epoch: 549| Step: 0
Training loss: 0.834741473197937
Validation loss: 1.878811240196228

Epoch: 5| Step: 1
Training loss: 0.7498804330825806
Validation loss: 1.8257506201344151

Epoch: 5| Step: 2
Training loss: 0.9111590385437012
Validation loss: 1.834551756099988

Epoch: 5| Step: 3
Training loss: 1.4994927644729614
Validation loss: 1.846922762932316

Epoch: 5| Step: 4
Training loss: 1.0258393287658691
Validation loss: 1.8603094316297961

Epoch: 5| Step: 5
Training loss: 0.6993340253829956
Validation loss: 1.8514403963601718

Epoch: 5| Step: 6
Training loss: 1.1864172220230103
Validation loss: 1.9394358486257575

Epoch: 5| Step: 7
Training loss: 1.01887845993042
Validation loss: 1.8826214421179988

Epoch: 5| Step: 8
Training loss: 1.4267778396606445
Validation loss: 1.9205433989083895

Epoch: 5| Step: 9
Training loss: 1.0746452808380127
Validation loss: 1.9079598970310663

Epoch: 5| Step: 10
Training loss: 0.8565320372581482
Validation loss: 1.8758490482966106

Epoch: 550| Step: 0
Training loss: 0.8613443374633789
Validation loss: 1.9072481073359007

Epoch: 5| Step: 1
Training loss: 1.1885885000228882
Validation loss: 1.8972609273848995

Epoch: 5| Step: 2
Training loss: 0.9933887720108032
Validation loss: 1.865673452295283

Epoch: 5| Step: 3
Training loss: 1.2021039724349976
Validation loss: 1.8884392771669614

Epoch: 5| Step: 4
Training loss: 0.8668447732925415
Validation loss: 1.9085312530558596

Epoch: 5| Step: 5
Training loss: 0.7958695292472839
Validation loss: 1.8594986520787722

Epoch: 5| Step: 6
Training loss: 1.1746528148651123
Validation loss: 1.8861562603263444

Epoch: 5| Step: 7
Training loss: 1.1500581502914429
Validation loss: 1.8454010050783876

Epoch: 5| Step: 8
Training loss: 0.9446167945861816
Validation loss: 1.8156737563430623

Epoch: 5| Step: 9
Training loss: 1.3327996730804443
Validation loss: 1.8277001329647597

Epoch: 5| Step: 10
Training loss: 1.4697551727294922
Validation loss: 1.857034497363593

Epoch: 551| Step: 0
Training loss: 0.8052565455436707
Validation loss: 1.8987370972992272

Epoch: 5| Step: 1
Training loss: 0.9540355801582336
Validation loss: 1.8412409418372697

Epoch: 5| Step: 2
Training loss: 0.8666655421257019
Validation loss: 1.8657577306993547

Epoch: 5| Step: 3
Training loss: 1.4391127824783325
Validation loss: 1.8637938191813808

Epoch: 5| Step: 4
Training loss: 0.723612368106842
Validation loss: 1.8747499360833118

Epoch: 5| Step: 5
Training loss: 1.6098079681396484
Validation loss: 1.8695038864689488

Epoch: 5| Step: 6
Training loss: 1.453809380531311
Validation loss: 1.848132384720669

Epoch: 5| Step: 7
Training loss: 1.1059938669204712
Validation loss: 1.8748876061490787

Epoch: 5| Step: 8
Training loss: 0.7566956877708435
Validation loss: 1.8766147398179578

Epoch: 5| Step: 9
Training loss: 1.040286660194397
Validation loss: 1.8510763581081102

Epoch: 5| Step: 10
Training loss: 0.9709687829017639
Validation loss: 1.9125633816565237

Epoch: 552| Step: 0
Training loss: 1.1030488014221191
Validation loss: 1.8640495807893815

Epoch: 5| Step: 1
Training loss: 1.0798757076263428
Validation loss: 1.8798886153005785

Epoch: 5| Step: 2
Training loss: 1.0880869626998901
Validation loss: 1.8674633041504891

Epoch: 5| Step: 3
Training loss: 1.2682554721832275
Validation loss: 1.8654955766534294

Epoch: 5| Step: 4
Training loss: 1.0634182691574097
Validation loss: 1.8839857155276882

Epoch: 5| Step: 5
Training loss: 0.9183866381645203
Validation loss: 1.863572753885741

Epoch: 5| Step: 6
Training loss: 1.186310887336731
Validation loss: 1.8753381890635337

Epoch: 5| Step: 7
Training loss: 1.1035470962524414
Validation loss: 1.8652217541971514

Epoch: 5| Step: 8
Training loss: 0.5887282490730286
Validation loss: 1.8743261932044901

Epoch: 5| Step: 9
Training loss: 1.2245776653289795
Validation loss: 1.8796140045248053

Epoch: 5| Step: 10
Training loss: 0.5373594760894775
Validation loss: 1.9006783385430612

Epoch: 553| Step: 0
Training loss: 1.0540869235992432
Validation loss: 1.8866086582983694

Epoch: 5| Step: 1
Training loss: 1.0444566011428833
Validation loss: 1.8472657831766273

Epoch: 5| Step: 2
Training loss: 1.2605979442596436
Validation loss: 1.8759554739921325

Epoch: 5| Step: 3
Training loss: 0.9751954078674316
Validation loss: 1.8754189411799114

Epoch: 5| Step: 4
Training loss: 1.2096526622772217
Validation loss: 1.8342982312684417

Epoch: 5| Step: 5
Training loss: 1.0551594495773315
Validation loss: 1.8431439656083302

Epoch: 5| Step: 6
Training loss: 1.1809744834899902
Validation loss: 1.8446469114672752

Epoch: 5| Step: 7
Training loss: 0.7510906457901001
Validation loss: 1.8725612701908234

Epoch: 5| Step: 8
Training loss: 1.003005862236023
Validation loss: 1.9168991081176265

Epoch: 5| Step: 9
Training loss: 1.0645816326141357
Validation loss: 1.9237163041227607

Epoch: 5| Step: 10
Training loss: 1.2231135368347168
Validation loss: 1.8797744345921341

Epoch: 554| Step: 0
Training loss: 0.9449855089187622
Validation loss: 1.839807794940087

Epoch: 5| Step: 1
Training loss: 1.7821365594863892
Validation loss: 1.8439859536386305

Epoch: 5| Step: 2
Training loss: 0.8936935663223267
Validation loss: 1.8725162629158265

Epoch: 5| Step: 3
Training loss: 0.8900936841964722
Validation loss: 1.8828130665645804

Epoch: 5| Step: 4
Training loss: 1.1931004524230957
Validation loss: 1.864105538655353

Epoch: 5| Step: 5
Training loss: 1.1235482692718506
Validation loss: 1.9240171294058523

Epoch: 5| Step: 6
Training loss: 1.0102145671844482
Validation loss: 1.920222154227636

Epoch: 5| Step: 7
Training loss: 0.9645429849624634
Validation loss: 1.806375180521319

Epoch: 5| Step: 8
Training loss: 1.095440149307251
Validation loss: 1.8624765590954853

Epoch: 5| Step: 9
Training loss: 0.8929085731506348
Validation loss: 1.820689574364693

Epoch: 5| Step: 10
Training loss: 0.6892487406730652
Validation loss: 1.8597891881901731

Epoch: 555| Step: 0
Training loss: 0.8182443380355835
Validation loss: 1.841846069981975

Epoch: 5| Step: 1
Training loss: 1.6869701147079468
Validation loss: 1.8415071964263916

Epoch: 5| Step: 2
Training loss: 1.3899339437484741
Validation loss: 1.872050945476819

Epoch: 5| Step: 3
Training loss: 0.5634124875068665
Validation loss: 1.855404964057348

Epoch: 5| Step: 4
Training loss: 1.1735076904296875
Validation loss: 1.9009649458751883

Epoch: 5| Step: 5
Training loss: 0.9627119898796082
Validation loss: 1.8515908141289987

Epoch: 5| Step: 6
Training loss: 0.9022663831710815
Validation loss: 1.8857896648427492

Epoch: 5| Step: 7
Training loss: 0.8936206102371216
Validation loss: 1.8775982344022362

Epoch: 5| Step: 8
Training loss: 1.3141577243804932
Validation loss: 1.8966388804938203

Epoch: 5| Step: 9
Training loss: 0.7339107394218445
Validation loss: 1.8393871732937392

Epoch: 5| Step: 10
Training loss: 0.8876672387123108
Validation loss: 1.8639041608379734

Epoch: 556| Step: 0
Training loss: 1.1807658672332764
Validation loss: 1.8805374637726815

Epoch: 5| Step: 1
Training loss: 1.0135314464569092
Validation loss: 1.8857187301881853

Epoch: 5| Step: 2
Training loss: 0.8319908380508423
Validation loss: 1.8634047380057714

Epoch: 5| Step: 3
Training loss: 1.0035350322723389
Validation loss: 1.884644736525833

Epoch: 5| Step: 4
Training loss: 0.8156864047050476
Validation loss: 1.8567562628817815

Epoch: 5| Step: 5
Training loss: 1.649330735206604
Validation loss: 1.8853008939373879

Epoch: 5| Step: 6
Training loss: 0.9363576769828796
Validation loss: 1.8941209277799052

Epoch: 5| Step: 7
Training loss: 1.0867445468902588
Validation loss: 1.8778141493438392

Epoch: 5| Step: 8
Training loss: 0.8721386194229126
Validation loss: 1.869071473357498

Epoch: 5| Step: 9
Training loss: 0.9457987546920776
Validation loss: 1.9008934523469658

Epoch: 5| Step: 10
Training loss: 1.3253544569015503
Validation loss: 1.9183716081803845

Epoch: 557| Step: 0
Training loss: 1.163466215133667
Validation loss: 1.9094428131657262

Epoch: 5| Step: 1
Training loss: 0.9157171249389648
Validation loss: 1.8791578405646867

Epoch: 5| Step: 2
Training loss: 0.8287670016288757
Validation loss: 1.8985187251080748

Epoch: 5| Step: 3
Training loss: 0.8738405108451843
Validation loss: 1.907994193415488

Epoch: 5| Step: 4
Training loss: 1.359866738319397
Validation loss: 1.8564696875951623

Epoch: 5| Step: 5
Training loss: 0.800207793712616
Validation loss: 1.9038667896742463

Epoch: 5| Step: 6
Training loss: 1.5924947261810303
Validation loss: 1.8755910960576867

Epoch: 5| Step: 7
Training loss: 0.8193357586860657
Validation loss: 1.8753871366541872

Epoch: 5| Step: 8
Training loss: 1.0594292879104614
Validation loss: 1.9214426971250964

Epoch: 5| Step: 9
Training loss: 1.270952582359314
Validation loss: 1.8088631527398222

Epoch: 5| Step: 10
Training loss: 0.5345278382301331
Validation loss: 1.8492321237441032

Epoch: 558| Step: 0
Training loss: 1.5467113256454468
Validation loss: 1.8703595143492504

Epoch: 5| Step: 1
Training loss: 1.1113086938858032
Validation loss: 1.9051111423841087

Epoch: 5| Step: 2
Training loss: 1.475319266319275
Validation loss: 1.8299427763108285

Epoch: 5| Step: 3
Training loss: 1.1954842805862427
Validation loss: 1.8495796342049875

Epoch: 5| Step: 4
Training loss: 0.7616804242134094
Validation loss: 1.8411230938408965

Epoch: 5| Step: 5
Training loss: 1.0235862731933594
Validation loss: 1.8547906337245819

Epoch: 5| Step: 6
Training loss: 1.2852165699005127
Validation loss: 1.8983038625409525

Epoch: 5| Step: 7
Training loss: 0.7612913250923157
Validation loss: 1.9051339421221005

Epoch: 5| Step: 8
Training loss: 0.8742898106575012
Validation loss: 1.8642414359636204

Epoch: 5| Step: 9
Training loss: 0.8891104459762573
Validation loss: 1.828765502540014

Epoch: 5| Step: 10
Training loss: 0.8642563819885254
Validation loss: 1.9188876959585375

Epoch: 559| Step: 0
Training loss: 0.8349092602729797
Validation loss: 1.825972298140167

Epoch: 5| Step: 1
Training loss: 0.9507919549942017
Validation loss: 1.871006847709738

Epoch: 5| Step: 2
Training loss: 1.2876094579696655
Validation loss: 1.9009874661763508

Epoch: 5| Step: 3
Training loss: 1.0431989431381226
Validation loss: 1.8305557748322845

Epoch: 5| Step: 4
Training loss: 1.5175399780273438
Validation loss: 1.8257327464319044

Epoch: 5| Step: 5
Training loss: 0.9667857885360718
Validation loss: 1.8703646288123181

Epoch: 5| Step: 6
Training loss: 0.8527522087097168
Validation loss: 1.899257247165967

Epoch: 5| Step: 7
Training loss: 1.308841347694397
Validation loss: 1.8719397129551056

Epoch: 5| Step: 8
Training loss: 0.8149797320365906
Validation loss: 1.884598329503049

Epoch: 5| Step: 9
Training loss: 1.0788390636444092
Validation loss: 1.8716094647684405

Epoch: 5| Step: 10
Training loss: 1.1204135417938232
Validation loss: 1.8571824591646913

Epoch: 560| Step: 0
Training loss: 0.9555785059928894
Validation loss: 1.8920631434327813

Epoch: 5| Step: 1
Training loss: 0.9492290616035461
Validation loss: 1.8439838027441373

Epoch: 5| Step: 2
Training loss: 1.682257890701294
Validation loss: 1.863603083036279

Epoch: 5| Step: 3
Training loss: 1.5034162998199463
Validation loss: 1.8569317107559533

Epoch: 5| Step: 4
Training loss: 0.9190144538879395
Validation loss: 1.9148651220465218

Epoch: 5| Step: 5
Training loss: 0.9647695422172546
Validation loss: 1.862895663066577

Epoch: 5| Step: 6
Training loss: 0.7434558868408203
Validation loss: 1.8708502656670027

Epoch: 5| Step: 7
Training loss: 1.2593882083892822
Validation loss: 1.841509243493439

Epoch: 5| Step: 8
Training loss: 0.829710841178894
Validation loss: 1.860631622293944

Epoch: 5| Step: 9
Training loss: 0.723854124546051
Validation loss: 1.9001169666167228

Epoch: 5| Step: 10
Training loss: 0.9833658933639526
Validation loss: 1.8693447279673752

Epoch: 561| Step: 0
Training loss: 0.7198598980903625
Validation loss: 1.9363387964105094

Epoch: 5| Step: 1
Training loss: 0.9083587527275085
Validation loss: 1.8759317756980978

Epoch: 5| Step: 2
Training loss: 1.2962877750396729
Validation loss: 1.9435413575941516

Epoch: 5| Step: 3
Training loss: 1.1422394514083862
Validation loss: 1.891293825641755

Epoch: 5| Step: 4
Training loss: 1.0160138607025146
Validation loss: 1.8971875085625598

Epoch: 5| Step: 5
Training loss: 1.1632049083709717
Validation loss: 1.9193228778018747

Epoch: 5| Step: 6
Training loss: 0.7871256470680237
Validation loss: 1.9241107997073923

Epoch: 5| Step: 7
Training loss: 0.9575832486152649
Validation loss: 1.8041798850541473

Epoch: 5| Step: 8
Training loss: 1.1419109106063843
Validation loss: 1.9007982284792009

Epoch: 5| Step: 9
Training loss: 1.3549442291259766
Validation loss: 1.8406012647895402

Epoch: 5| Step: 10
Training loss: 0.9065007567405701
Validation loss: 1.875954794627364

Epoch: 562| Step: 0
Training loss: 1.4378024339675903
Validation loss: 1.8998420200040262

Epoch: 5| Step: 1
Training loss: 1.2271407842636108
Validation loss: 1.8772320234647362

Epoch: 5| Step: 2
Training loss: 1.1740782260894775
Validation loss: 1.8297363019758655

Epoch: 5| Step: 3
Training loss: 0.9205824732780457
Validation loss: 1.830306012143371

Epoch: 5| Step: 4
Training loss: 0.9103270769119263
Validation loss: 1.8865563613112255

Epoch: 5| Step: 5
Training loss: 0.9584625363349915
Validation loss: 1.8733070934972456

Epoch: 5| Step: 6
Training loss: 0.8270843625068665
Validation loss: 1.8599759455650084

Epoch: 5| Step: 7
Training loss: 1.0912290811538696
Validation loss: 1.8164487628526584

Epoch: 5| Step: 8
Training loss: 0.9550684094429016
Validation loss: 1.9404666372524795

Epoch: 5| Step: 9
Training loss: 1.0304436683654785
Validation loss: 1.8907846814842635

Epoch: 5| Step: 10
Training loss: 1.0300129652023315
Validation loss: 1.8952813174134941

Epoch: 563| Step: 0
Training loss: 0.8708294034004211
Validation loss: 1.8659518867410638

Epoch: 5| Step: 1
Training loss: 1.3425697088241577
Validation loss: 1.8730349566346856

Epoch: 5| Step: 2
Training loss: 1.17791748046875
Validation loss: 1.8679086610835085

Epoch: 5| Step: 3
Training loss: 1.137271523475647
Validation loss: 1.8843051874509422

Epoch: 5| Step: 4
Training loss: 0.877383828163147
Validation loss: 1.878448251755007

Epoch: 5| Step: 5
Training loss: 1.2966272830963135
Validation loss: 1.8676685133287985

Epoch: 5| Step: 6
Training loss: 0.6937599182128906
Validation loss: 1.9308658902363112

Epoch: 5| Step: 7
Training loss: 1.0313836336135864
Validation loss: 1.8821442486137472

Epoch: 5| Step: 8
Training loss: 0.723097026348114
Validation loss: 1.8346178711101573

Epoch: 5| Step: 9
Training loss: 1.0247093439102173
Validation loss: 1.8557826242139261

Epoch: 5| Step: 10
Training loss: 1.099191665649414
Validation loss: 1.8864021557633595

Epoch: 564| Step: 0
Training loss: 0.8952980041503906
Validation loss: 1.86769639548435

Epoch: 5| Step: 1
Training loss: 0.501982569694519
Validation loss: 1.8301743333057692

Epoch: 5| Step: 2
Training loss: 0.7051776647567749
Validation loss: 1.892075115634549

Epoch: 5| Step: 3
Training loss: 1.143480896949768
Validation loss: 1.8471440563919723

Epoch: 5| Step: 4
Training loss: 1.2246356010437012
Validation loss: 1.8291866228144655

Epoch: 5| Step: 5
Training loss: 0.8616601228713989
Validation loss: 1.931261549713791

Epoch: 5| Step: 6
Training loss: 1.103279709815979
Validation loss: 1.8947069145018054

Epoch: 5| Step: 7
Training loss: 1.4669065475463867
Validation loss: 1.8218641716946837

Epoch: 5| Step: 8
Training loss: 1.0088551044464111
Validation loss: 1.8809547988317346

Epoch: 5| Step: 9
Training loss: 1.3697888851165771
Validation loss: 1.8658939766627487

Epoch: 5| Step: 10
Training loss: 0.9496092796325684
Validation loss: 1.8207523271601687

Epoch: 565| Step: 0
Training loss: 1.1058552265167236
Validation loss: 1.8674030893592424

Epoch: 5| Step: 1
Training loss: 0.5437545776367188
Validation loss: 1.829538845246838

Epoch: 5| Step: 2
Training loss: 0.7532085180282593
Validation loss: 1.8528031379945817

Epoch: 5| Step: 3
Training loss: 0.998553454875946
Validation loss: 1.9166267943638626

Epoch: 5| Step: 4
Training loss: 0.8081056475639343
Validation loss: 1.902239417517057

Epoch: 5| Step: 5
Training loss: 0.7419682145118713
Validation loss: 1.8272436998223747

Epoch: 5| Step: 6
Training loss: 1.178594708442688
Validation loss: 1.8755537438136276

Epoch: 5| Step: 7
Training loss: 1.176329255104065
Validation loss: 1.870992350321944

Epoch: 5| Step: 8
Training loss: 1.0241755247116089
Validation loss: 1.8562179483393186

Epoch: 5| Step: 9
Training loss: 1.380163311958313
Validation loss: 1.84823061830254

Epoch: 5| Step: 10
Training loss: 1.2152440547943115
Validation loss: 1.8781360580075173

Epoch: 566| Step: 0
Training loss: 1.7569725513458252
Validation loss: 1.8368392682844592

Epoch: 5| Step: 1
Training loss: 0.7854877710342407
Validation loss: 1.8461291841281358

Epoch: 5| Step: 2
Training loss: 0.7779088616371155
Validation loss: 1.8352947324834845

Epoch: 5| Step: 3
Training loss: 1.2077467441558838
Validation loss: 1.8227869669596355

Epoch: 5| Step: 4
Training loss: 0.5537226796150208
Validation loss: 1.8246593616342033

Epoch: 5| Step: 5
Training loss: 0.8079978227615356
Validation loss: 1.8371770535745928

Epoch: 5| Step: 6
Training loss: 1.2956522703170776
Validation loss: 1.8344160446556665

Epoch: 5| Step: 7
Training loss: 0.9628978967666626
Validation loss: 1.8663315926828692

Epoch: 5| Step: 8
Training loss: 0.8330825567245483
Validation loss: 1.8791694013021325

Epoch: 5| Step: 9
Training loss: 1.232271432876587
Validation loss: 1.8778718492036224

Epoch: 5| Step: 10
Training loss: 1.350886344909668
Validation loss: 1.8539696637020315

Epoch: 567| Step: 0
Training loss: 1.4591667652130127
Validation loss: 1.8267599639072214

Epoch: 5| Step: 1
Training loss: 1.1684796810150146
Validation loss: 1.8932582178423483

Epoch: 5| Step: 2
Training loss: 1.0316777229309082
Validation loss: 1.821610217453331

Epoch: 5| Step: 3
Training loss: 1.0368452072143555
Validation loss: 1.8518390937518048

Epoch: 5| Step: 4
Training loss: 0.7742506861686707
Validation loss: 1.850280818118844

Epoch: 5| Step: 5
Training loss: 0.9789832830429077
Validation loss: 1.8570537669684297

Epoch: 5| Step: 6
Training loss: 1.3195444345474243
Validation loss: 1.8962176897192513

Epoch: 5| Step: 7
Training loss: 0.6869871020317078
Validation loss: 1.9017193701959425

Epoch: 5| Step: 8
Training loss: 1.187105655670166
Validation loss: 1.9517771044085104

Epoch: 5| Step: 9
Training loss: 0.8554853200912476
Validation loss: 1.84072563340587

Epoch: 5| Step: 10
Training loss: 0.6489368677139282
Validation loss: 1.8885002777140627

Epoch: 568| Step: 0
Training loss: 0.9696658253669739
Validation loss: 1.9320441599815124

Epoch: 5| Step: 1
Training loss: 1.4040272235870361
Validation loss: 1.897158322795745

Epoch: 5| Step: 2
Training loss: 1.0205442905426025
Validation loss: 1.878194175740724

Epoch: 5| Step: 3
Training loss: 1.0129015445709229
Validation loss: 1.8434419606321601

Epoch: 5| Step: 4
Training loss: 0.9523435831069946
Validation loss: 1.894631234548425

Epoch: 5| Step: 5
Training loss: 0.9358583688735962
Validation loss: 1.884299998642296

Epoch: 5| Step: 6
Training loss: 1.133363962173462
Validation loss: 1.9019109536242742

Epoch: 5| Step: 7
Training loss: 1.1822030544281006
Validation loss: 1.84796489438703

Epoch: 5| Step: 8
Training loss: 0.9249836206436157
Validation loss: 1.8670969855400823

Epoch: 5| Step: 9
Training loss: 1.0709474086761475
Validation loss: 1.9361174209143526

Epoch: 5| Step: 10
Training loss: 1.05622136592865
Validation loss: 1.8915897159166233

Epoch: 569| Step: 0
Training loss: 0.6706866025924683
Validation loss: 1.9059413966312204

Epoch: 5| Step: 1
Training loss: 1.2546026706695557
Validation loss: 1.8745335519954722

Epoch: 5| Step: 2
Training loss: 0.9826146364212036
Validation loss: 1.8522284646188059

Epoch: 5| Step: 3
Training loss: 0.9221128225326538
Validation loss: 1.9101405425738263

Epoch: 5| Step: 4
Training loss: 0.5793929100036621
Validation loss: 1.8911819022188905

Epoch: 5| Step: 5
Training loss: 1.059441328048706
Validation loss: 1.839242301961427

Epoch: 5| Step: 6
Training loss: 1.4982963800430298
Validation loss: 1.914063625438239

Epoch: 5| Step: 7
Training loss: 0.526334285736084
Validation loss: 1.8189854121977282

Epoch: 5| Step: 8
Training loss: 1.3236687183380127
Validation loss: 1.8479200101667834

Epoch: 5| Step: 9
Training loss: 1.0684486627578735
Validation loss: 1.8363865498573548

Epoch: 5| Step: 10
Training loss: 1.199472427368164
Validation loss: 1.8938303762866604

Epoch: 570| Step: 0
Training loss: 1.6063735485076904
Validation loss: 1.8643274896888322

Epoch: 5| Step: 1
Training loss: 0.9339682459831238
Validation loss: 1.904707206192837

Epoch: 5| Step: 2
Training loss: 1.1307885646820068
Validation loss: 1.8948216579293693

Epoch: 5| Step: 3
Training loss: 1.145255446434021
Validation loss: 1.8440103889793478

Epoch: 5| Step: 4
Training loss: 1.0732477903366089
Validation loss: 1.8297560496996808

Epoch: 5| Step: 5
Training loss: 0.6364186406135559
Validation loss: 1.8812149955380348

Epoch: 5| Step: 6
Training loss: 0.4586969017982483
Validation loss: 1.8782179547894386

Epoch: 5| Step: 7
Training loss: 0.8979352116584778
Validation loss: 1.8839381958848687

Epoch: 5| Step: 8
Training loss: 1.009878396987915
Validation loss: 1.867162686522289

Epoch: 5| Step: 9
Training loss: 1.30324387550354
Validation loss: 1.8562882408019035

Epoch: 5| Step: 10
Training loss: 1.189412236213684
Validation loss: 1.8757515902160316

Epoch: 571| Step: 0
Training loss: 0.7774468064308167
Validation loss: 1.857299381686795

Epoch: 5| Step: 1
Training loss: 1.306375503540039
Validation loss: 1.840798642045708

Epoch: 5| Step: 2
Training loss: 1.1963478326797485
Validation loss: 1.8636588050473122

Epoch: 5| Step: 3
Training loss: 0.45941510796546936
Validation loss: 1.9080787345927248

Epoch: 5| Step: 4
Training loss: 0.9662426710128784
Validation loss: 1.828870447733069

Epoch: 5| Step: 5
Training loss: 0.8643032312393188
Validation loss: 1.8576741077566659

Epoch: 5| Step: 6
Training loss: 0.9794073104858398
Validation loss: 1.843656962917697

Epoch: 5| Step: 7
Training loss: 1.3989765644073486
Validation loss: 1.8357670768614738

Epoch: 5| Step: 8
Training loss: 1.0084880590438843
Validation loss: 1.8525546366168606

Epoch: 5| Step: 9
Training loss: 1.1319053173065186
Validation loss: 1.8657786897433701

Epoch: 5| Step: 10
Training loss: 0.9627943634986877
Validation loss: 1.8964961318559543

Epoch: 572| Step: 0
Training loss: 0.8642670512199402
Validation loss: 1.8554764178491407

Epoch: 5| Step: 1
Training loss: 1.0911133289337158
Validation loss: 1.942137202908916

Epoch: 5| Step: 2
Training loss: 1.0045968294143677
Validation loss: 1.8872616598683019

Epoch: 5| Step: 3
Training loss: 1.2929062843322754
Validation loss: 1.9175762591823455

Epoch: 5| Step: 4
Training loss: 1.1246010065078735
Validation loss: 1.897797115387455

Epoch: 5| Step: 5
Training loss: 1.0674049854278564
Validation loss: 1.9151738125790831

Epoch: 5| Step: 6
Training loss: 1.2473417520523071
Validation loss: 1.875561027116673

Epoch: 5| Step: 7
Training loss: 0.7521313428878784
Validation loss: 1.8971760965162707

Epoch: 5| Step: 8
Training loss: 1.301491379737854
Validation loss: 1.8635586025894328

Epoch: 5| Step: 9
Training loss: 0.9650607109069824
Validation loss: 1.9204073580362464

Epoch: 5| Step: 10
Training loss: 0.8526192307472229
Validation loss: 1.9068763691891906

Epoch: 573| Step: 0
Training loss: 1.0364105701446533
Validation loss: 1.8595933183546989

Epoch: 5| Step: 1
Training loss: 0.8131256103515625
Validation loss: 1.8710445812953416

Epoch: 5| Step: 2
Training loss: 0.6762348413467407
Validation loss: 1.8265396805219754

Epoch: 5| Step: 3
Training loss: 1.203147053718567
Validation loss: 1.8838328981912265

Epoch: 5| Step: 4
Training loss: 0.8175466656684875
Validation loss: 1.844409664471944

Epoch: 5| Step: 5
Training loss: 0.7789648175239563
Validation loss: 1.8341532676450667

Epoch: 5| Step: 6
Training loss: 0.8777627944946289
Validation loss: 1.8414970328730922

Epoch: 5| Step: 7
Training loss: 1.5893216133117676
Validation loss: 1.9222522756104827

Epoch: 5| Step: 8
Training loss: 1.0193712711334229
Validation loss: 1.8925415251844673

Epoch: 5| Step: 9
Training loss: 0.7164113521575928
Validation loss: 1.8814332690290225

Epoch: 5| Step: 10
Training loss: 1.822988748550415
Validation loss: 1.8401982886816866

Epoch: 574| Step: 0
Training loss: 0.9446862936019897
Validation loss: 1.8858212604317615

Epoch: 5| Step: 1
Training loss: 0.7453068494796753
Validation loss: 1.8680034093959357

Epoch: 5| Step: 2
Training loss: 0.6990758180618286
Validation loss: 1.8843029109380578

Epoch: 5| Step: 3
Training loss: 1.0649776458740234
Validation loss: 1.9406258854814755

Epoch: 5| Step: 4
Training loss: 1.1380845308303833
Validation loss: 1.9031433892506424

Epoch: 5| Step: 5
Training loss: 1.0536692142486572
Validation loss: 1.8605584457356443

Epoch: 5| Step: 6
Training loss: 0.8673162460327148
Validation loss: 1.8413152246065037

Epoch: 5| Step: 7
Training loss: 0.8982250094413757
Validation loss: 1.8575185063064739

Epoch: 5| Step: 8
Training loss: 1.6844673156738281
Validation loss: 1.821903521014798

Epoch: 5| Step: 9
Training loss: 0.844806969165802
Validation loss: 1.820599618778434

Epoch: 5| Step: 10
Training loss: 1.2575820684432983
Validation loss: 1.863603977746861

Epoch: 575| Step: 0
Training loss: 0.8892046809196472
Validation loss: 1.8773432675228323

Epoch: 5| Step: 1
Training loss: 1.1069120168685913
Validation loss: 1.8181188503901164

Epoch: 5| Step: 2
Training loss: 0.8534919023513794
Validation loss: 1.899868921567035

Epoch: 5| Step: 3
Training loss: 0.7841471433639526
Validation loss: 1.8187718519600489

Epoch: 5| Step: 4
Training loss: 1.488882303237915
Validation loss: 1.889610425118477

Epoch: 5| Step: 5
Training loss: 1.079643964767456
Validation loss: 1.8828811619871406

Epoch: 5| Step: 6
Training loss: 1.2185804843902588
Validation loss: 1.8698474079050043

Epoch: 5| Step: 7
Training loss: 1.13759446144104
Validation loss: 1.8908954820325297

Epoch: 5| Step: 8
Training loss: 0.6940599679946899
Validation loss: 1.8461295379105436

Epoch: 5| Step: 9
Training loss: 1.0901429653167725
Validation loss: 1.8900117105053318

Epoch: 5| Step: 10
Training loss: 0.5239893198013306
Validation loss: 1.8840799306028633

Epoch: 576| Step: 0
Training loss: 0.9342836141586304
Validation loss: 1.8608301480611165

Epoch: 5| Step: 1
Training loss: 1.0751065015792847
Validation loss: 1.799705268234335

Epoch: 5| Step: 2
Training loss: 1.354778528213501
Validation loss: 1.8993277152379353

Epoch: 5| Step: 3
Training loss: 1.3495184183120728
Validation loss: 1.8987988528384958

Epoch: 5| Step: 4
Training loss: 0.9131417274475098
Validation loss: 1.893199300253263

Epoch: 5| Step: 5
Training loss: 0.6439070701599121
Validation loss: 1.8845621411518385

Epoch: 5| Step: 6
Training loss: 0.5477797985076904
Validation loss: 1.8614240128506896

Epoch: 5| Step: 7
Training loss: 0.8992122411727905
Validation loss: 1.8581724961598713

Epoch: 5| Step: 8
Training loss: 1.1625525951385498
Validation loss: 1.8624843282084311

Epoch: 5| Step: 9
Training loss: 1.1526267528533936
Validation loss: 1.8739817398850636

Epoch: 5| Step: 10
Training loss: 1.1609461307525635
Validation loss: 1.9008284730295981

Epoch: 577| Step: 0
Training loss: 1.0459924936294556
Validation loss: 1.8001415844886535

Epoch: 5| Step: 1
Training loss: 1.3572936058044434
Validation loss: 1.891588795569635

Epoch: 5| Step: 2
Training loss: 1.2347967624664307
Validation loss: 1.888807036543405

Epoch: 5| Step: 3
Training loss: 1.1864840984344482
Validation loss: 1.895348451470816

Epoch: 5| Step: 4
Training loss: 1.165753960609436
Validation loss: 1.8211747548913444

Epoch: 5| Step: 5
Training loss: 1.0811837911605835
Validation loss: 1.8742793324173137

Epoch: 5| Step: 6
Training loss: 1.4574718475341797
Validation loss: 1.824545532144526

Epoch: 5| Step: 7
Training loss: 0.9412827491760254
Validation loss: 1.8254830978249992

Epoch: 5| Step: 8
Training loss: 0.6321674585342407
Validation loss: 1.8393212338929534

Epoch: 5| Step: 9
Training loss: 0.42869728803634644
Validation loss: 1.9402258601239932

Epoch: 5| Step: 10
Training loss: 1.0336049795150757
Validation loss: 1.813271531494715

Epoch: 578| Step: 0
Training loss: 0.9830150604248047
Validation loss: 1.8377140004147765

Epoch: 5| Step: 1
Training loss: 1.1888587474822998
Validation loss: 1.8636730922165738

Epoch: 5| Step: 2
Training loss: 1.4599907398223877
Validation loss: 1.8653455459943382

Epoch: 5| Step: 3
Training loss: 0.8058841824531555
Validation loss: 1.8539913521018079

Epoch: 5| Step: 4
Training loss: 1.0256177186965942
Validation loss: 1.8934332478430964

Epoch: 5| Step: 5
Training loss: 0.7875199317932129
Validation loss: 1.8599703875921105

Epoch: 5| Step: 6
Training loss: 0.8674119114875793
Validation loss: 1.8645005969591038

Epoch: 5| Step: 7
Training loss: 1.1384518146514893
Validation loss: 1.8924813475660098

Epoch: 5| Step: 8
Training loss: 1.1518199443817139
Validation loss: 1.8521265458035212

Epoch: 5| Step: 9
Training loss: 0.8993415832519531
Validation loss: 1.883270006025991

Epoch: 5| Step: 10
Training loss: 0.7873502373695374
Validation loss: 1.8740183820006668

Epoch: 579| Step: 0
Training loss: 1.4568549394607544
Validation loss: 1.8866831948680263

Epoch: 5| Step: 1
Training loss: 0.8502044677734375
Validation loss: 1.8609240234539073

Epoch: 5| Step: 2
Training loss: 1.2126712799072266
Validation loss: 1.8920431931813557

Epoch: 5| Step: 3
Training loss: 0.6806912422180176
Validation loss: 1.8819171254352858

Epoch: 5| Step: 4
Training loss: 1.2572437524795532
Validation loss: 1.916830075684414

Epoch: 5| Step: 5
Training loss: 0.9581974744796753
Validation loss: 1.8555447439993582

Epoch: 5| Step: 6
Training loss: 0.7101823091506958
Validation loss: 1.8921839524340887

Epoch: 5| Step: 7
Training loss: 0.6823261976242065
Validation loss: 1.8397180393177976

Epoch: 5| Step: 8
Training loss: 0.9941667318344116
Validation loss: 1.8547651280638993

Epoch: 5| Step: 9
Training loss: 0.8393344879150391
Validation loss: 1.8817640299438148

Epoch: 5| Step: 10
Training loss: 1.1968343257904053
Validation loss: 1.8090560987431517

Epoch: 580| Step: 0
Training loss: 1.1887818574905396
Validation loss: 1.8471137977415515

Epoch: 5| Step: 1
Training loss: 1.1927636861801147
Validation loss: 1.8326538096192062

Epoch: 5| Step: 2
Training loss: 0.8095793724060059
Validation loss: 1.8613639339323966

Epoch: 5| Step: 3
Training loss: 0.7356353998184204
Validation loss: 1.8302860900919924

Epoch: 5| Step: 4
Training loss: 0.9134601354598999
Validation loss: 1.8517859007722588

Epoch: 5| Step: 5
Training loss: 0.8687207102775574
Validation loss: 1.8437652933982112

Epoch: 5| Step: 6
Training loss: 0.768433690071106
Validation loss: 1.9020301218955749

Epoch: 5| Step: 7
Training loss: 1.338921308517456
Validation loss: 1.86819927923141

Epoch: 5| Step: 8
Training loss: 1.097460150718689
Validation loss: 1.8239468361741753

Epoch: 5| Step: 9
Training loss: 0.9276958703994751
Validation loss: 1.8674233395566222

Epoch: 5| Step: 10
Training loss: 1.1814285516738892
Validation loss: 1.9202477355157175

Epoch: 581| Step: 0
Training loss: 0.9145904779434204
Validation loss: 1.907846866115447

Epoch: 5| Step: 1
Training loss: 0.5320886373519897
Validation loss: 1.9307468078469718

Epoch: 5| Step: 2
Training loss: 1.0700105428695679
Validation loss: 1.9356677532196045

Epoch: 5| Step: 3
Training loss: 1.1159331798553467
Validation loss: 1.8395288939117103

Epoch: 5| Step: 4
Training loss: 1.4029088020324707
Validation loss: 1.905612798147304

Epoch: 5| Step: 5
Training loss: 1.335758924484253
Validation loss: 1.872973790732763

Epoch: 5| Step: 6
Training loss: 0.9057731628417969
Validation loss: 1.895053853270828

Epoch: 5| Step: 7
Training loss: 1.1859314441680908
Validation loss: 1.818652988761984

Epoch: 5| Step: 8
Training loss: 0.8811293840408325
Validation loss: 1.8574667669111682

Epoch: 5| Step: 9
Training loss: 0.9388599395751953
Validation loss: 1.8455605147987284

Epoch: 5| Step: 10
Training loss: 0.8339741230010986
Validation loss: 1.8556897960683352

Epoch: 582| Step: 0
Training loss: 1.2947648763656616
Validation loss: 1.8636581577280515

Epoch: 5| Step: 1
Training loss: 0.9878071546554565
Validation loss: 1.8537023477656867

Epoch: 5| Step: 2
Training loss: 0.7193285226821899
Validation loss: 1.8622005113991358

Epoch: 5| Step: 3
Training loss: 0.6766239404678345
Validation loss: 1.845835260165635

Epoch: 5| Step: 4
Training loss: 1.4907889366149902
Validation loss: 1.864596777064826

Epoch: 5| Step: 5
Training loss: 1.3160511255264282
Validation loss: 1.8503908867477088

Epoch: 5| Step: 6
Training loss: 1.4722259044647217
Validation loss: 1.831136990618962

Epoch: 5| Step: 7
Training loss: 1.0180904865264893
Validation loss: 1.8755266756139777

Epoch: 5| Step: 8
Training loss: 0.8428448438644409
Validation loss: 1.9056341161010086

Epoch: 5| Step: 9
Training loss: 0.4347439408302307
Validation loss: 1.8984619596953034

Epoch: 5| Step: 10
Training loss: 0.9161677956581116
Validation loss: 1.8771451955200524

Epoch: 583| Step: 0
Training loss: 1.1565182209014893
Validation loss: 1.8493123631323538

Epoch: 5| Step: 1
Training loss: 1.2610161304473877
Validation loss: 1.8433976199037285

Epoch: 5| Step: 2
Training loss: 1.0069563388824463
Validation loss: 1.8246945950292772

Epoch: 5| Step: 3
Training loss: 1.1622247695922852
Validation loss: 1.8608618961867465

Epoch: 5| Step: 4
Training loss: 0.886335015296936
Validation loss: 1.885143970930448

Epoch: 5| Step: 5
Training loss: 0.9963184595108032
Validation loss: 1.8207469242875294

Epoch: 5| Step: 6
Training loss: 0.9851499795913696
Validation loss: 1.8822019177098428

Epoch: 5| Step: 7
Training loss: 0.8734515905380249
Validation loss: 1.9196588659799227

Epoch: 5| Step: 8
Training loss: 1.301396131515503
Validation loss: 1.849401444517156

Epoch: 5| Step: 9
Training loss: 0.47250741720199585
Validation loss: 1.8537135457479825

Epoch: 5| Step: 10
Training loss: 0.7165736556053162
Validation loss: 1.9093856183431481

Epoch: 584| Step: 0
Training loss: 0.9202481508255005
Validation loss: 1.880439260954498

Epoch: 5| Step: 1
Training loss: 0.8219717741012573
Validation loss: 1.9066899438058176

Epoch: 5| Step: 2
Training loss: 1.4941976070404053
Validation loss: 1.8827194936813847

Epoch: 5| Step: 3
Training loss: 0.7863677144050598
Validation loss: 1.9085773767963532

Epoch: 5| Step: 4
Training loss: 0.6980220079421997
Validation loss: 1.9266294715225056

Epoch: 5| Step: 5
Training loss: 0.6742203831672668
Validation loss: 1.8778790171428392

Epoch: 5| Step: 6
Training loss: 1.1677322387695312
Validation loss: 1.9125716481157529

Epoch: 5| Step: 7
Training loss: 0.5309791564941406
Validation loss: 1.8597710568417785

Epoch: 5| Step: 8
Training loss: 0.9589495658874512
Validation loss: 1.8371072623037523

Epoch: 5| Step: 9
Training loss: 1.2340271472930908
Validation loss: 1.879792747959014

Epoch: 5| Step: 10
Training loss: 1.5881322622299194
Validation loss: 1.8748675430974653

Epoch: 585| Step: 0
Training loss: 1.1961076259613037
Validation loss: 1.8961199381018197

Epoch: 5| Step: 1
Training loss: 1.0673530101776123
Validation loss: 1.8715375110667238

Epoch: 5| Step: 2
Training loss: 0.7057892084121704
Validation loss: 1.8970997820618332

Epoch: 5| Step: 3
Training loss: 1.2348066568374634
Validation loss: 1.9040870281957811

Epoch: 5| Step: 4
Training loss: 0.6959165334701538
Validation loss: 1.8336679781636884

Epoch: 5| Step: 5
Training loss: 0.8335808515548706
Validation loss: 1.8725546342070385

Epoch: 5| Step: 6
Training loss: 1.0446475744247437
Validation loss: 1.895071316790837

Epoch: 5| Step: 7
Training loss: 1.0739953517913818
Validation loss: 1.8273361857219408

Epoch: 5| Step: 8
Training loss: 0.7093738317489624
Validation loss: 1.8630996596428655

Epoch: 5| Step: 9
Training loss: 1.3277225494384766
Validation loss: 1.8427878656694967

Epoch: 5| Step: 10
Training loss: 0.9483904838562012
Validation loss: 1.8348152868209346

Epoch: 586| Step: 0
Training loss: 0.8342312574386597
Validation loss: 1.9103522505811465

Epoch: 5| Step: 1
Training loss: 0.765154242515564
Validation loss: 1.8952084587466331

Epoch: 5| Step: 2
Training loss: 0.7624459266662598
Validation loss: 1.847774902979533

Epoch: 5| Step: 3
Training loss: 1.0266780853271484
Validation loss: 1.9384024579037902

Epoch: 5| Step: 4
Training loss: 0.8164218068122864
Validation loss: 1.8474436267729728

Epoch: 5| Step: 5
Training loss: 1.2313743829727173
Validation loss: 1.8891275467411164

Epoch: 5| Step: 6
Training loss: 1.3154866695404053
Validation loss: 1.8721722236243628

Epoch: 5| Step: 7
Training loss: 0.7038077712059021
Validation loss: 1.8541484404635686

Epoch: 5| Step: 8
Training loss: 1.0504165887832642
Validation loss: 1.8617307037435553

Epoch: 5| Step: 9
Training loss: 1.2223331928253174
Validation loss: 1.9206159499383741

Epoch: 5| Step: 10
Training loss: 1.072121500968933
Validation loss: 1.8529869177008187

Epoch: 587| Step: 0
Training loss: 0.994416356086731
Validation loss: 1.889114538828532

Epoch: 5| Step: 1
Training loss: 0.9050544500350952
Validation loss: 1.8650475240522815

Epoch: 5| Step: 2
Training loss: 0.7291846871376038
Validation loss: 1.844564890348783

Epoch: 5| Step: 3
Training loss: 0.5064893364906311
Validation loss: 1.871002956103253

Epoch: 5| Step: 4
Training loss: 1.1539463996887207
Validation loss: 1.849063947636594

Epoch: 5| Step: 5
Training loss: 1.147996187210083
Validation loss: 1.842508195548929

Epoch: 5| Step: 6
Training loss: 1.2086256742477417
Validation loss: 1.8360706490855063

Epoch: 5| Step: 7
Training loss: 1.4352188110351562
Validation loss: 1.8811938929301437

Epoch: 5| Step: 8
Training loss: 0.6647239923477173
Validation loss: 1.7970866451981247

Epoch: 5| Step: 9
Training loss: 1.1906800270080566
Validation loss: 1.832600389757464

Epoch: 5| Step: 10
Training loss: 0.9186432361602783
Validation loss: 1.8434355515305714

Epoch: 588| Step: 0
Training loss: 1.0421277284622192
Validation loss: 1.845995072395571

Epoch: 5| Step: 1
Training loss: 1.1598973274230957
Validation loss: 1.84384919751075

Epoch: 5| Step: 2
Training loss: 1.405105710029602
Validation loss: 1.881252432382235

Epoch: 5| Step: 3
Training loss: 0.8222478032112122
Validation loss: 1.876452963839295

Epoch: 5| Step: 4
Training loss: 0.6688952445983887
Validation loss: 1.8712869972311041

Epoch: 5| Step: 5
Training loss: 0.8107717633247375
Validation loss: 1.843117316563924

Epoch: 5| Step: 6
Training loss: 1.159426212310791
Validation loss: 1.866443818615329

Epoch: 5| Step: 7
Training loss: 0.8726116418838501
Validation loss: 1.8662954773954166

Epoch: 5| Step: 8
Training loss: 0.918389618396759
Validation loss: 1.847530044535155

Epoch: 5| Step: 9
Training loss: 1.1670641899108887
Validation loss: 1.8687932901484992

Epoch: 5| Step: 10
Training loss: 1.104641079902649
Validation loss: 1.8412969214941866

Epoch: 589| Step: 0
Training loss: 1.3374381065368652
Validation loss: 1.9613671533523067

Epoch: 5| Step: 1
Training loss: 1.564000129699707
Validation loss: 1.8542813588214178

Epoch: 5| Step: 2
Training loss: 1.3555607795715332
Validation loss: 1.883845124193417

Epoch: 5| Step: 3
Training loss: 0.9082794189453125
Validation loss: 1.8376794220298849

Epoch: 5| Step: 4
Training loss: 0.7962663173675537
Validation loss: 1.8749790665923909

Epoch: 5| Step: 5
Training loss: 0.7880640029907227
Validation loss: 1.8759436671451857

Epoch: 5| Step: 6
Training loss: 0.6102570295333862
Validation loss: 1.839277845557018

Epoch: 5| Step: 7
Training loss: 0.9975011944770813
Validation loss: 1.8593812155467209

Epoch: 5| Step: 8
Training loss: 0.8724643588066101
Validation loss: 1.8919115925347934

Epoch: 5| Step: 9
Training loss: 0.790064811706543
Validation loss: 1.8529420001532442

Epoch: 5| Step: 10
Training loss: 1.2047637701034546
Validation loss: 1.9109159285022366

Epoch: 590| Step: 0
Training loss: 1.3371970653533936
Validation loss: 1.8777998788382417

Epoch: 5| Step: 1
Training loss: 0.9429810643196106
Validation loss: 1.8648487701210925

Epoch: 5| Step: 2
Training loss: 0.8620063662528992
Validation loss: 1.8540352762386363

Epoch: 5| Step: 3
Training loss: 0.8237489461898804
Validation loss: 1.866665174884181

Epoch: 5| Step: 4
Training loss: 1.0842833518981934
Validation loss: 1.8382953495107672

Epoch: 5| Step: 5
Training loss: 0.7759795188903809
Validation loss: 1.8940812951775008

Epoch: 5| Step: 6
Training loss: 1.4161455631256104
Validation loss: 1.8384451943059121

Epoch: 5| Step: 7
Training loss: 1.5363075733184814
Validation loss: 1.8573360443115234

Epoch: 5| Step: 8
Training loss: 0.8181396722793579
Validation loss: 1.9123640521880119

Epoch: 5| Step: 9
Training loss: 0.666601300239563
Validation loss: 1.8542079515354608

Epoch: 5| Step: 10
Training loss: 0.8625192046165466
Validation loss: 1.8475229906779465

Epoch: 591| Step: 0
Training loss: 0.74602872133255
Validation loss: 1.8726177446303829

Epoch: 5| Step: 1
Training loss: 0.9724187850952148
Validation loss: 1.8399030457260788

Epoch: 5| Step: 2
Training loss: 1.034433126449585
Validation loss: 1.9460805410979896

Epoch: 5| Step: 3
Training loss: 1.218239665031433
Validation loss: 1.907361977843828

Epoch: 5| Step: 4
Training loss: 1.0457277297973633
Validation loss: 1.880556421895181

Epoch: 5| Step: 5
Training loss: 0.9286370277404785
Validation loss: 1.8816749677863172

Epoch: 5| Step: 6
Training loss: 0.999921977519989
Validation loss: 1.8851447310498965

Epoch: 5| Step: 7
Training loss: 0.7455018162727356
Validation loss: 1.8685587747122652

Epoch: 5| Step: 8
Training loss: 1.3078083992004395
Validation loss: 1.8673670150900399

Epoch: 5| Step: 9
Training loss: 1.1038768291473389
Validation loss: 1.9302300637768162

Epoch: 5| Step: 10
Training loss: 0.8126471638679504
Validation loss: 1.905002236366272

Epoch: 592| Step: 0
Training loss: 0.7412014007568359
Validation loss: 1.8877397045012443

Epoch: 5| Step: 1
Training loss: 1.048844337463379
Validation loss: 1.8860748519179642

Epoch: 5| Step: 2
Training loss: 1.1545827388763428
Validation loss: 1.9096870396726875

Epoch: 5| Step: 3
Training loss: 1.3943498134613037
Validation loss: 1.8617573989334928

Epoch: 5| Step: 4
Training loss: 1.063362717628479
Validation loss: 1.8762906187324113

Epoch: 5| Step: 5
Training loss: 0.6052221059799194
Validation loss: 1.8650475189250002

Epoch: 5| Step: 6
Training loss: 0.9370064735412598
Validation loss: 1.8100387075895905

Epoch: 5| Step: 7
Training loss: 0.9275611639022827
Validation loss: 1.8527765607321134

Epoch: 5| Step: 8
Training loss: 1.1306025981903076
Validation loss: 1.873612029578096

Epoch: 5| Step: 9
Training loss: 0.9893056750297546
Validation loss: 1.8759481701799618

Epoch: 5| Step: 10
Training loss: 0.7882487177848816
Validation loss: 1.852044218329973

Epoch: 593| Step: 0
Training loss: 1.0723581314086914
Validation loss: 1.8760402202606201

Epoch: 5| Step: 1
Training loss: 1.5124849081039429
Validation loss: 1.8525870371890325

Epoch: 5| Step: 2
Training loss: 1.1050004959106445
Validation loss: 1.8863832232772664

Epoch: 5| Step: 3
Training loss: 0.752707839012146
Validation loss: 1.9068400295831824

Epoch: 5| Step: 4
Training loss: 1.1082535982131958
Validation loss: 1.8818275044041295

Epoch: 5| Step: 5
Training loss: 0.9947797060012817
Validation loss: 1.9037112343695857

Epoch: 5| Step: 6
Training loss: 0.6188709735870361
Validation loss: 1.9222544277867963

Epoch: 5| Step: 7
Training loss: 0.6200098395347595
Validation loss: 1.8711200388528968

Epoch: 5| Step: 8
Training loss: 1.1310104131698608
Validation loss: 1.8917964760975172

Epoch: 5| Step: 9
Training loss: 1.0882521867752075
Validation loss: 1.8803390085056264

Epoch: 5| Step: 10
Training loss: 0.6135445833206177
Validation loss: 1.8707665749775466

Epoch: 594| Step: 0
Training loss: 0.8973113894462585
Validation loss: 1.8496496908126339

Epoch: 5| Step: 1
Training loss: 1.0347360372543335
Validation loss: 1.8901127461464173

Epoch: 5| Step: 2
Training loss: 0.8949352502822876
Validation loss: 1.9087869377546414

Epoch: 5| Step: 3
Training loss: 1.0263440608978271
Validation loss: 1.8595837995570192

Epoch: 5| Step: 4
Training loss: 0.7385923862457275
Validation loss: 1.830610131704679

Epoch: 5| Step: 5
Training loss: 1.3698889017105103
Validation loss: 1.9094000734308714

Epoch: 5| Step: 6
Training loss: 0.8031800985336304
Validation loss: 1.842198823087959

Epoch: 5| Step: 7
Training loss: 1.0183192491531372
Validation loss: 1.8616916889785438

Epoch: 5| Step: 8
Training loss: 0.5457700490951538
Validation loss: 1.8528931012717627

Epoch: 5| Step: 9
Training loss: 1.274244785308838
Validation loss: 1.9001959921211324

Epoch: 5| Step: 10
Training loss: 1.0510954856872559
Validation loss: 1.880906719033436

Epoch: 595| Step: 0
Training loss: 1.2855507135391235
Validation loss: 1.8777607564003236

Epoch: 5| Step: 1
Training loss: 0.9756468534469604
Validation loss: 1.8490228627317695

Epoch: 5| Step: 2
Training loss: 0.9204249382019043
Validation loss: 1.8464436646430724

Epoch: 5| Step: 3
Training loss: 1.5498569011688232
Validation loss: 1.830307734909878

Epoch: 5| Step: 4
Training loss: 0.8842806816101074
Validation loss: 1.8616385241990447

Epoch: 5| Step: 5
Training loss: 1.2190731763839722
Validation loss: 1.8558852557213075

Epoch: 5| Step: 6
Training loss: 1.0435512065887451
Validation loss: 1.8524904046007382

Epoch: 5| Step: 7
Training loss: 0.8063141703605652
Validation loss: 1.8514353459881199

Epoch: 5| Step: 8
Training loss: 0.7259188890457153
Validation loss: 1.8645423407195716

Epoch: 5| Step: 9
Training loss: 0.8643766641616821
Validation loss: 1.8302617355059552

Epoch: 5| Step: 10
Training loss: 0.7529423236846924
Validation loss: 1.8823023739681448

Epoch: 596| Step: 0
Training loss: 1.1980960369110107
Validation loss: 1.8625677990657028

Epoch: 5| Step: 1
Training loss: 1.1356276273727417
Validation loss: 1.8785547966598182

Epoch: 5| Step: 2
Training loss: 1.0587459802627563
Validation loss: 1.9172317366446219

Epoch: 5| Step: 3
Training loss: 0.7850335836410522
Validation loss: 1.875947739488335

Epoch: 5| Step: 4
Training loss: 0.5442391633987427
Validation loss: 1.8987984529105566

Epoch: 5| Step: 5
Training loss: 0.6056111454963684
Validation loss: 1.8632199777069913

Epoch: 5| Step: 6
Training loss: 1.2445231676101685
Validation loss: 1.8702311028716385

Epoch: 5| Step: 7
Training loss: 1.093797206878662
Validation loss: 1.9017076184672694

Epoch: 5| Step: 8
Training loss: 1.1133090257644653
Validation loss: 1.8812639303104852

Epoch: 5| Step: 9
Training loss: 1.0031604766845703
Validation loss: 1.8917251453604749

Epoch: 5| Step: 10
Training loss: 1.0275754928588867
Validation loss: 1.8650193739962835

Epoch: 597| Step: 0
Training loss: 1.1749916076660156
Validation loss: 1.8415442410335745

Epoch: 5| Step: 1
Training loss: 1.1370086669921875
Validation loss: 1.8662357445686095

Epoch: 5| Step: 2
Training loss: 0.9204727411270142
Validation loss: 1.8680312966787687

Epoch: 5| Step: 3
Training loss: 1.0521644353866577
Validation loss: 1.8324903185649584

Epoch: 5| Step: 4
Training loss: 0.9339507222175598
Validation loss: 1.8375787734985352

Epoch: 5| Step: 5
Training loss: 0.8721261024475098
Validation loss: 1.8542086475638933

Epoch: 5| Step: 6
Training loss: 0.9843535423278809
Validation loss: 1.8713647883425477

Epoch: 5| Step: 7
Training loss: 1.0359725952148438
Validation loss: 1.8647227928202639

Epoch: 5| Step: 8
Training loss: 0.8650927543640137
Validation loss: 1.8237846166856828

Epoch: 5| Step: 9
Training loss: 1.222389817237854
Validation loss: 1.863158102958433

Epoch: 5| Step: 10
Training loss: 0.4196818470954895
Validation loss: 1.878027408353744

Epoch: 598| Step: 0
Training loss: 0.5938147306442261
Validation loss: 1.9009569101436163

Epoch: 5| Step: 1
Training loss: 1.252557396888733
Validation loss: 1.8477859497070312

Epoch: 5| Step: 2
Training loss: 1.0946118831634521
Validation loss: 1.9178247195418163

Epoch: 5| Step: 3
Training loss: 0.791975736618042
Validation loss: 1.8564657434340446

Epoch: 5| Step: 4
Training loss: 1.1327016353607178
Validation loss: 1.8662966758974138

Epoch: 5| Step: 5
Training loss: 0.6354514360427856
Validation loss: 1.9167533100292247

Epoch: 5| Step: 6
Training loss: 0.9294236898422241
Validation loss: 1.8817197251063522

Epoch: 5| Step: 7
Training loss: 1.1372348070144653
Validation loss: 1.9008526571335331

Epoch: 5| Step: 8
Training loss: 1.2910021543502808
Validation loss: 1.895528595934632

Epoch: 5| Step: 9
Training loss: 1.073918104171753
Validation loss: 1.8768108249992452

Epoch: 5| Step: 10
Training loss: 0.8109457492828369
Validation loss: 1.8907330574527863

Epoch: 599| Step: 0
Training loss: 0.9005153775215149
Validation loss: 1.8824202232463385

Epoch: 5| Step: 1
Training loss: 1.3591820001602173
Validation loss: 1.858418732561091

Epoch: 5| Step: 2
Training loss: 0.6597029566764832
Validation loss: 1.8498726275659376

Epoch: 5| Step: 3
Training loss: 1.6102473735809326
Validation loss: 1.8674625042946107

Epoch: 5| Step: 4
Training loss: 0.9397574663162231
Validation loss: 1.8882949326627998

Epoch: 5| Step: 5
Training loss: 0.5657016038894653
Validation loss: 1.8321133480277112

Epoch: 5| Step: 6
Training loss: 0.8918642997741699
Validation loss: 1.9098194991388628

Epoch: 5| Step: 7
Training loss: 1.3121395111083984
Validation loss: 1.8570772960621824

Epoch: 5| Step: 8
Training loss: 0.8707537651062012
Validation loss: 1.8382798830668132

Epoch: 5| Step: 9
Training loss: 0.800646960735321
Validation loss: 1.8424799185927196

Epoch: 5| Step: 10
Training loss: 1.1417897939682007
Validation loss: 1.860286719055586

Epoch: 600| Step: 0
Training loss: 1.2785394191741943
Validation loss: 1.8447419917711647

Epoch: 5| Step: 1
Training loss: 0.7133471965789795
Validation loss: 1.8360064145057433

Epoch: 5| Step: 2
Training loss: 0.7045608758926392
Validation loss: 1.9414106133163616

Epoch: 5| Step: 3
Training loss: 1.1879689693450928
Validation loss: 1.8600383855963265

Epoch: 5| Step: 4
Training loss: 0.7920351028442383
Validation loss: 1.834522512651259

Epoch: 5| Step: 5
Training loss: 0.9102839231491089
Validation loss: 1.8555303017298381

Epoch: 5| Step: 6
Training loss: 1.5759488344192505
Validation loss: 1.9033609667131979

Epoch: 5| Step: 7
Training loss: 0.6509407758712769
Validation loss: 1.8556591605627408

Epoch: 5| Step: 8
Training loss: 0.7047334909439087
Validation loss: 1.9266916154533305

Epoch: 5| Step: 9
Training loss: 0.9780648350715637
Validation loss: 1.889305296764579

Epoch: 5| Step: 10
Training loss: 1.1625474691390991
Validation loss: 1.8505587218910136

Epoch: 601| Step: 0
Training loss: 0.7777408361434937
Validation loss: 1.829648838248304

Epoch: 5| Step: 1
Training loss: 0.733833909034729
Validation loss: 1.840772880020962

Epoch: 5| Step: 2
Training loss: 1.7810337543487549
Validation loss: 1.8504663231552287

Epoch: 5| Step: 3
Training loss: 0.5773168206214905
Validation loss: 1.8261248270670574

Epoch: 5| Step: 4
Training loss: 0.6836517453193665
Validation loss: 1.867924483873511

Epoch: 5| Step: 5
Training loss: 0.7502168416976929
Validation loss: 1.8663227353044736

Epoch: 5| Step: 6
Training loss: 1.1980246305465698
Validation loss: 1.8142813636410622

Epoch: 5| Step: 7
Training loss: 1.2827421426773071
Validation loss: 1.7937540238903416

Epoch: 5| Step: 8
Training loss: 0.7451512813568115
Validation loss: 1.8035878699312928

Epoch: 5| Step: 9
Training loss: 1.016464114189148
Validation loss: 1.9168750047683716

Epoch: 5| Step: 10
Training loss: 1.005782961845398
Validation loss: 1.8692294038752073

Epoch: 602| Step: 0
Training loss: 0.9475206136703491
Validation loss: 1.8865051423349688

Epoch: 5| Step: 1
Training loss: 1.2542976140975952
Validation loss: 1.8728722564635738

Epoch: 5| Step: 2
Training loss: 1.2489019632339478
Validation loss: 1.8727720136283545

Epoch: 5| Step: 3
Training loss: 1.064286231994629
Validation loss: 1.8863417051171745

Epoch: 5| Step: 4
Training loss: 0.6925021409988403
Validation loss: 1.9488197026714202

Epoch: 5| Step: 5
Training loss: 0.4941312372684479
Validation loss: 1.920233823919809

Epoch: 5| Step: 6
Training loss: 0.8601220846176147
Validation loss: 1.9151783886776175

Epoch: 5| Step: 7
Training loss: 0.9511710405349731
Validation loss: 1.8148073086174585

Epoch: 5| Step: 8
Training loss: 1.0124483108520508
Validation loss: 1.857461869075734

Epoch: 5| Step: 9
Training loss: 1.1560695171356201
Validation loss: 1.826684054508004

Epoch: 5| Step: 10
Training loss: 0.9043865203857422
Validation loss: 1.8544759006910427

Epoch: 603| Step: 0
Training loss: 1.1169583797454834
Validation loss: 1.8580060928098616

Epoch: 5| Step: 1
Training loss: 1.099191427230835
Validation loss: 1.8390928724760651

Epoch: 5| Step: 2
Training loss: 1.0486667156219482
Validation loss: 1.8234044274976176

Epoch: 5| Step: 3
Training loss: 1.0864770412445068
Validation loss: 1.8615671716710573

Epoch: 5| Step: 4
Training loss: 1.0610443353652954
Validation loss: 1.8509330941784767

Epoch: 5| Step: 5
Training loss: 0.8100317716598511
Validation loss: 1.8590217726204985

Epoch: 5| Step: 6
Training loss: 0.8475835919380188
Validation loss: 1.8364642448322748

Epoch: 5| Step: 7
Training loss: 1.1051084995269775
Validation loss: 1.8764235614448466

Epoch: 5| Step: 8
Training loss: 0.6850318908691406
Validation loss: 1.8888941336703557

Epoch: 5| Step: 9
Training loss: 1.1517630815505981
Validation loss: 1.8774259846697572

Epoch: 5| Step: 10
Training loss: 0.7390179634094238
Validation loss: 1.8706678216175368

Epoch: 604| Step: 0
Training loss: 1.0142167806625366
Validation loss: 1.9048251939076248

Epoch: 5| Step: 1
Training loss: 0.7107843160629272
Validation loss: 1.8841466544776835

Epoch: 5| Step: 2
Training loss: 0.8401250839233398
Validation loss: 1.8928874615700013

Epoch: 5| Step: 3
Training loss: 1.21883225440979
Validation loss: 1.8100244742567821

Epoch: 5| Step: 4
Training loss: 0.6492859125137329
Validation loss: 1.866753250040034

Epoch: 5| Step: 5
Training loss: 1.2638410329818726
Validation loss: 1.9043122235164847

Epoch: 5| Step: 6
Training loss: 0.9228485226631165
Validation loss: 1.8915027341535013

Epoch: 5| Step: 7
Training loss: 1.0792133808135986
Validation loss: 1.8789251145496164

Epoch: 5| Step: 8
Training loss: 1.1998531818389893
Validation loss: 1.8256172069939234

Epoch: 5| Step: 9
Training loss: 0.9163073301315308
Validation loss: 1.8763302449257142

Epoch: 5| Step: 10
Training loss: 0.9711348414421082
Validation loss: 1.8518835267712992

Epoch: 605| Step: 0
Training loss: 0.5610857009887695
Validation loss: 1.850120726452079

Epoch: 5| Step: 1
Training loss: 0.6458184123039246
Validation loss: 1.8510415374591787

Epoch: 5| Step: 2
Training loss: 1.1865179538726807
Validation loss: 1.8524491415228894

Epoch: 5| Step: 3
Training loss: 0.9526063799858093
Validation loss: 1.8612445887698923

Epoch: 5| Step: 4
Training loss: 0.9752602577209473
Validation loss: 1.8624036812013196

Epoch: 5| Step: 5
Training loss: 1.0120445489883423
Validation loss: 1.8406665594347063

Epoch: 5| Step: 6
Training loss: 1.1713929176330566
Validation loss: 1.8725568735471336

Epoch: 5| Step: 7
Training loss: 0.4633772373199463
Validation loss: 1.8603475939842962

Epoch: 5| Step: 8
Training loss: 1.0597984790802002
Validation loss: 1.8597609663522372

Epoch: 5| Step: 9
Training loss: 1.4892250299453735
Validation loss: 1.8554316477109027

Epoch: 5| Step: 10
Training loss: 1.1492799520492554
Validation loss: 1.8941827051101192

Epoch: 606| Step: 0
Training loss: 0.9764235615730286
Validation loss: 1.887874496880398

Epoch: 5| Step: 1
Training loss: 1.4337362051010132
Validation loss: 1.9274618292367587

Epoch: 5| Step: 2
Training loss: 0.8996078372001648
Validation loss: 1.9023280143737793

Epoch: 5| Step: 3
Training loss: 1.2308919429779053
Validation loss: 1.9427796140793832

Epoch: 5| Step: 4
Training loss: 1.1648082733154297
Validation loss: 1.9223791553128151

Epoch: 5| Step: 5
Training loss: 1.1599301099777222
Validation loss: 1.86740658872871

Epoch: 5| Step: 6
Training loss: 0.5229891538619995
Validation loss: 1.8627919535483084

Epoch: 5| Step: 7
Training loss: 0.5581758618354797
Validation loss: 1.83834881167258

Epoch: 5| Step: 8
Training loss: 0.957953155040741
Validation loss: 1.8441627230695499

Epoch: 5| Step: 9
Training loss: 1.1462441682815552
Validation loss: 1.875845560463526

Epoch: 5| Step: 10
Training loss: 0.7217159271240234
Validation loss: 1.8747307536422566

Epoch: 607| Step: 0
Training loss: 0.9104007482528687
Validation loss: 1.8198895838952833

Epoch: 5| Step: 1
Training loss: 1.0580177307128906
Validation loss: 1.8148354125279251

Epoch: 5| Step: 2
Training loss: 0.844753623008728
Validation loss: 1.8298704393448368

Epoch: 5| Step: 3
Training loss: 0.9198006391525269
Validation loss: 1.8602115031211608

Epoch: 5| Step: 4
Training loss: 1.1063027381896973
Validation loss: 1.8711107956465853

Epoch: 5| Step: 5
Training loss: 0.7219899296760559
Validation loss: 1.8797875604321879

Epoch: 5| Step: 6
Training loss: 0.927468478679657
Validation loss: 1.8347351384419266

Epoch: 5| Step: 7
Training loss: 1.5308654308319092
Validation loss: 1.912701355513706

Epoch: 5| Step: 8
Training loss: 1.0099177360534668
Validation loss: 1.8753626756770636

Epoch: 5| Step: 9
Training loss: 0.8125160932540894
Validation loss: 1.8858118890434183

Epoch: 5| Step: 10
Training loss: 0.4728822708129883
Validation loss: 1.9142022017509706

Epoch: 608| Step: 0
Training loss: 0.8272953033447266
Validation loss: 1.8921841857253865

Epoch: 5| Step: 1
Training loss: 1.2144830226898193
Validation loss: 1.8841236740030267

Epoch: 5| Step: 2
Training loss: 0.7355481386184692
Validation loss: 1.8462121371299989

Epoch: 5| Step: 3
Training loss: 0.9595946073532104
Validation loss: 1.8445889026887956

Epoch: 5| Step: 4
Training loss: 1.313632607460022
Validation loss: 1.87928512788588

Epoch: 5| Step: 5
Training loss: 0.4982783794403076
Validation loss: 1.8323432091743714

Epoch: 5| Step: 6
Training loss: 0.9932424426078796
Validation loss: 1.8247529332355787

Epoch: 5| Step: 7
Training loss: 1.1865969896316528
Validation loss: 1.8167434661619124

Epoch: 5| Step: 8
Training loss: 1.1012980937957764
Validation loss: 1.8633263777661067

Epoch: 5| Step: 9
Training loss: 1.091421365737915
Validation loss: 1.8508389970307708

Epoch: 5| Step: 10
Training loss: 0.6310504674911499
Validation loss: 1.8549905284758537

Epoch: 609| Step: 0
Training loss: 1.2010471820831299
Validation loss: 1.8752138255744852

Epoch: 5| Step: 1
Training loss: 1.0130603313446045
Validation loss: 1.862868021893245

Epoch: 5| Step: 2
Training loss: 0.5389605760574341
Validation loss: 1.9001030627117361

Epoch: 5| Step: 3
Training loss: 0.6830123662948608
Validation loss: 1.917135779575635

Epoch: 5| Step: 4
Training loss: 0.8697568774223328
Validation loss: 1.8726361028609737

Epoch: 5| Step: 5
Training loss: 1.0573573112487793
Validation loss: 1.8915687504635061

Epoch: 5| Step: 6
Training loss: 0.8207484483718872
Validation loss: 1.8903796185729325

Epoch: 5| Step: 7
Training loss: 1.3106873035430908
Validation loss: 1.8623023648415842

Epoch: 5| Step: 8
Training loss: 0.9404099583625793
Validation loss: 1.8797326241770098

Epoch: 5| Step: 9
Training loss: 0.8158538937568665
Validation loss: 1.8995288854004235

Epoch: 5| Step: 10
Training loss: 1.0932503938674927
Validation loss: 1.8532035607163624

Epoch: 610| Step: 0
Training loss: 1.0055201053619385
Validation loss: 1.899348610190935

Epoch: 5| Step: 1
Training loss: 0.5636801719665527
Validation loss: 1.9004411928115352

Epoch: 5| Step: 2
Training loss: 0.8936850428581238
Validation loss: 1.8984051289096955

Epoch: 5| Step: 3
Training loss: 1.0465025901794434
Validation loss: 1.8912812971299695

Epoch: 5| Step: 4
Training loss: 0.8581282496452332
Validation loss: 1.8354030347639514

Epoch: 5| Step: 5
Training loss: 0.7230499982833862
Validation loss: 1.84245248891974

Epoch: 5| Step: 6
Training loss: 0.9730164408683777
Validation loss: 1.8577563326845887

Epoch: 5| Step: 7
Training loss: 0.7765944004058838
Validation loss: 1.8329087790622507

Epoch: 5| Step: 8
Training loss: 1.2751545906066895
Validation loss: 1.8523374667731665

Epoch: 5| Step: 9
Training loss: 1.0181306600570679
Validation loss: 1.842630217152257

Epoch: 5| Step: 10
Training loss: 1.2507679462432861
Validation loss: 1.8539509081071424

Epoch: 611| Step: 0
Training loss: 1.5818042755126953
Validation loss: 1.8199145922096827

Epoch: 5| Step: 1
Training loss: 1.2698118686676025
Validation loss: 1.870548136772648

Epoch: 5| Step: 2
Training loss: 0.7558201551437378
Validation loss: 1.8408330255939114

Epoch: 5| Step: 3
Training loss: 0.8112309575080872
Validation loss: 1.8614354736061507

Epoch: 5| Step: 4
Training loss: 0.970653235912323
Validation loss: 1.8544761621823875

Epoch: 5| Step: 5
Training loss: 0.7822967171669006
Validation loss: 1.864806689241881

Epoch: 5| Step: 6
Training loss: 0.7890356183052063
Validation loss: 1.9112302680169382

Epoch: 5| Step: 7
Training loss: 0.8086018562316895
Validation loss: 1.8299100552835772

Epoch: 5| Step: 8
Training loss: 1.0788333415985107
Validation loss: 1.8530575562548894

Epoch: 5| Step: 9
Training loss: 0.6050726771354675
Validation loss: 1.8496490998934674

Epoch: 5| Step: 10
Training loss: 0.7667542695999146
Validation loss: 1.8865075124207364

Epoch: 612| Step: 0
Training loss: 0.7948611378669739
Validation loss: 1.841406427403932

Epoch: 5| Step: 1
Training loss: 1.1203111410140991
Validation loss: 1.8902254360978321

Epoch: 5| Step: 2
Training loss: 1.1017608642578125
Validation loss: 1.9387269020080566

Epoch: 5| Step: 3
Training loss: 1.007907509803772
Validation loss: 1.9110413148838987

Epoch: 5| Step: 4
Training loss: 0.752875566482544
Validation loss: 1.8381200067458614

Epoch: 5| Step: 5
Training loss: 0.7387716174125671
Validation loss: 1.8827435201214207

Epoch: 5| Step: 6
Training loss: 0.9567729830741882
Validation loss: 1.915502639227016

Epoch: 5| Step: 7
Training loss: 1.0476405620574951
Validation loss: 1.9417415254859514

Epoch: 5| Step: 8
Training loss: 1.1557000875473022
Validation loss: 1.9574527048295545

Epoch: 5| Step: 9
Training loss: 0.831322193145752
Validation loss: 1.8995646763873357

Epoch: 5| Step: 10
Training loss: 0.8536942601203918
Validation loss: 1.8638643545489157

Epoch: 613| Step: 0
Training loss: 1.1171458959579468
Validation loss: 1.8608332013571134

Epoch: 5| Step: 1
Training loss: 0.7954362034797668
Validation loss: 1.8700861712937713

Epoch: 5| Step: 2
Training loss: 1.0573276281356812
Validation loss: 1.8192439848376858

Epoch: 5| Step: 3
Training loss: 1.214072823524475
Validation loss: 1.8613345084651824

Epoch: 5| Step: 4
Training loss: 0.9413180351257324
Validation loss: 1.838269284976426

Epoch: 5| Step: 5
Training loss: 0.9704371690750122
Validation loss: 1.885043869736374

Epoch: 5| Step: 6
Training loss: 1.0324833393096924
Validation loss: 1.8925635148120183

Epoch: 5| Step: 7
Training loss: 0.7304688692092896
Validation loss: 1.863351063061786

Epoch: 5| Step: 8
Training loss: 0.6910535097122192
Validation loss: 1.8542270724491408

Epoch: 5| Step: 9
Training loss: 0.7584720849990845
Validation loss: 1.904692078149447

Epoch: 5| Step: 10
Training loss: 0.9873327612876892
Validation loss: 1.8730425373200448

Epoch: 614| Step: 0
Training loss: 1.2102227210998535
Validation loss: 1.8726433964185818

Epoch: 5| Step: 1
Training loss: 0.908347487449646
Validation loss: 1.8489726076843918

Epoch: 5| Step: 2
Training loss: 0.6939758062362671
Validation loss: 1.8505223105030675

Epoch: 5| Step: 3
Training loss: 1.0804506540298462
Validation loss: 1.8713184018288889

Epoch: 5| Step: 4
Training loss: 0.875859260559082
Validation loss: 1.7870756169801116

Epoch: 5| Step: 5
Training loss: 0.6864927411079407
Validation loss: 1.8534372621966946

Epoch: 5| Step: 6
Training loss: 0.8645073175430298
Validation loss: 1.8336736873913837

Epoch: 5| Step: 7
Training loss: 1.1017634868621826
Validation loss: 1.9533383577100691

Epoch: 5| Step: 8
Training loss: 1.3393399715423584
Validation loss: 1.877772617083724

Epoch: 5| Step: 9
Training loss: 0.9744356870651245
Validation loss: 1.9049687667559552

Epoch: 5| Step: 10
Training loss: 0.5695882439613342
Validation loss: 1.9164215185308968

Epoch: 615| Step: 0
Training loss: 0.881064772605896
Validation loss: 1.880160867526967

Epoch: 5| Step: 1
Training loss: 0.7628363370895386
Validation loss: 1.8556034654699347

Epoch: 5| Step: 2
Training loss: 0.7206205129623413
Validation loss: 1.9063777718492734

Epoch: 5| Step: 3
Training loss: 1.562957763671875
Validation loss: 1.8767136796828239

Epoch: 5| Step: 4
Training loss: 1.0608580112457275
Validation loss: 1.8895494476441415

Epoch: 5| Step: 5
Training loss: 0.6964258551597595
Validation loss: 1.8779841199997933

Epoch: 5| Step: 6
Training loss: 0.7651380896568298
Validation loss: 1.8499773856132262

Epoch: 5| Step: 7
Training loss: 1.2747766971588135
Validation loss: 1.8305756866291005

Epoch: 5| Step: 8
Training loss: 0.9214862585067749
Validation loss: 1.8606319683854298

Epoch: 5| Step: 9
Training loss: 0.6652215719223022
Validation loss: 1.8608556306490334

Epoch: 5| Step: 10
Training loss: 0.7043228149414062
Validation loss: 1.8606994254614717

Epoch: 616| Step: 0
Training loss: 0.8577998876571655
Validation loss: 1.831854171650384

Epoch: 5| Step: 1
Training loss: 0.7965072393417358
Validation loss: 1.8698864290791173

Epoch: 5| Step: 2
Training loss: 1.0202080011367798
Validation loss: 1.8500558278893913

Epoch: 5| Step: 3
Training loss: 0.8584251403808594
Validation loss: 1.8597569478455411

Epoch: 5| Step: 4
Training loss: 0.4812535345554352
Validation loss: 1.885991342606083

Epoch: 5| Step: 5
Training loss: 0.738728940486908
Validation loss: 1.8980119959000619

Epoch: 5| Step: 6
Training loss: 1.4045159816741943
Validation loss: 1.9034646121404504

Epoch: 5| Step: 7
Training loss: 0.6760072112083435
Validation loss: 1.8659213947993454

Epoch: 5| Step: 8
Training loss: 1.3270790576934814
Validation loss: 1.8358497978538595

Epoch: 5| Step: 9
Training loss: 1.0650947093963623
Validation loss: 1.8574346803849744

Epoch: 5| Step: 10
Training loss: 1.1574105024337769
Validation loss: 1.8701543577255741

Epoch: 617| Step: 0
Training loss: 0.8885198831558228
Validation loss: 1.8443488331251248

Epoch: 5| Step: 1
Training loss: 0.81292724609375
Validation loss: 1.8767996193260275

Epoch: 5| Step: 2
Training loss: 1.4561219215393066
Validation loss: 1.8244095822816253

Epoch: 5| Step: 3
Training loss: 0.9273112416267395
Validation loss: 1.8430455448806926

Epoch: 5| Step: 4
Training loss: 1.126806616783142
Validation loss: 1.8617277658113869

Epoch: 5| Step: 5
Training loss: 0.7531085014343262
Validation loss: 1.8745676958432762

Epoch: 5| Step: 6
Training loss: 0.7150055170059204
Validation loss: 1.8623075228865429

Epoch: 5| Step: 7
Training loss: 0.6420087814331055
Validation loss: 1.875538154314923

Epoch: 5| Step: 8
Training loss: 1.4586105346679688
Validation loss: 1.9273925878668343

Epoch: 5| Step: 9
Training loss: 0.9356986284255981
Validation loss: 1.883911100766992

Epoch: 5| Step: 10
Training loss: 0.8132264614105225
Validation loss: 1.9205380178266955

Epoch: 618| Step: 0
Training loss: 1.1538165807724
Validation loss: 1.9152051902586413

Epoch: 5| Step: 1
Training loss: 0.7624987363815308
Validation loss: 1.8839780156330397

Epoch: 5| Step: 2
Training loss: 1.1636841297149658
Validation loss: 1.860311556887883

Epoch: 5| Step: 3
Training loss: 0.5799867510795593
Validation loss: 1.9386933260066535

Epoch: 5| Step: 4
Training loss: 1.0284587144851685
Validation loss: 1.929942900134671

Epoch: 5| Step: 5
Training loss: 1.476036548614502
Validation loss: 1.8639397095608454

Epoch: 5| Step: 6
Training loss: 0.9758524894714355
Validation loss: 1.877769950897463

Epoch: 5| Step: 7
Training loss: 0.6840932369232178
Validation loss: 1.8352544781982258

Epoch: 5| Step: 8
Training loss: 0.8259347081184387
Validation loss: 1.8182944661827498

Epoch: 5| Step: 9
Training loss: 0.5994542837142944
Validation loss: 1.828969451688951

Epoch: 5| Step: 10
Training loss: 1.305981993675232
Validation loss: 1.8584275040575253

Epoch: 619| Step: 0
Training loss: 0.529615044593811
Validation loss: 1.8813911740497877

Epoch: 5| Step: 1
Training loss: 1.1387218236923218
Validation loss: 1.8822964352946128

Epoch: 5| Step: 2
Training loss: 0.9602968096733093
Validation loss: 1.8656818456547235

Epoch: 5| Step: 3
Training loss: 0.9185884594917297
Validation loss: 1.8188859621683757

Epoch: 5| Step: 4
Training loss: 0.9113909602165222
Validation loss: 1.8855674023269324

Epoch: 5| Step: 5
Training loss: 0.9374779462814331
Validation loss: 1.8734758054056475

Epoch: 5| Step: 6
Training loss: 0.6453975439071655
Validation loss: 1.8635331943470945

Epoch: 5| Step: 7
Training loss: 1.1982409954071045
Validation loss: 1.9217915099154237

Epoch: 5| Step: 8
Training loss: 0.7528725862503052
Validation loss: 1.858261905690675

Epoch: 5| Step: 9
Training loss: 1.124014973640442
Validation loss: 1.861314603077468

Epoch: 5| Step: 10
Training loss: 1.3577287197113037
Validation loss: 1.865157493980982

Epoch: 620| Step: 0
Training loss: 0.8834152221679688
Validation loss: 1.88457735635901

Epoch: 5| Step: 1
Training loss: 0.8284343481063843
Validation loss: 1.9056143260771228

Epoch: 5| Step: 2
Training loss: 0.6436929106712341
Validation loss: 1.8799331547111593

Epoch: 5| Step: 3
Training loss: 0.6096664667129517
Validation loss: 1.8774812400981944

Epoch: 5| Step: 4
Training loss: 0.8204761743545532
Validation loss: 1.84431637999832

Epoch: 5| Step: 5
Training loss: 1.8433036804199219
Validation loss: 1.7947621973611976

Epoch: 5| Step: 6
Training loss: 0.9230254292488098
Validation loss: 1.905532185749341

Epoch: 5| Step: 7
Training loss: 0.7112403512001038
Validation loss: 1.8762657988455989

Epoch: 5| Step: 8
Training loss: 0.7169735431671143
Validation loss: 1.8693069219589233

Epoch: 5| Step: 9
Training loss: 1.0776708126068115
Validation loss: 1.856990566817663

Epoch: 5| Step: 10
Training loss: 0.7862029075622559
Validation loss: 1.859185061147136

Epoch: 621| Step: 0
Training loss: 0.8384394645690918
Validation loss: 1.8685744398383684

Epoch: 5| Step: 1
Training loss: 0.7849345803260803
Validation loss: 1.8706729642806514

Epoch: 5| Step: 2
Training loss: 1.1774442195892334
Validation loss: 1.8322510155298377

Epoch: 5| Step: 3
Training loss: 0.5546033978462219
Validation loss: 1.8469637106823664

Epoch: 5| Step: 4
Training loss: 1.0963510274887085
Validation loss: 1.8489009872559579

Epoch: 5| Step: 5
Training loss: 1.5034677982330322
Validation loss: 1.8979416970283753

Epoch: 5| Step: 6
Training loss: 0.7900248765945435
Validation loss: 1.8985283900332708

Epoch: 5| Step: 7
Training loss: 0.7655047178268433
Validation loss: 1.8434662588181034

Epoch: 5| Step: 8
Training loss: 0.9798362851142883
Validation loss: 1.886706877780217

Epoch: 5| Step: 9
Training loss: 0.9152634739875793
Validation loss: 1.899600241773872

Epoch: 5| Step: 10
Training loss: 0.5764479041099548
Validation loss: 1.8738257564524168

Epoch: 622| Step: 0
Training loss: 0.5575770139694214
Validation loss: 1.849086687129031

Epoch: 5| Step: 1
Training loss: 1.212551474571228
Validation loss: 1.8756856687607304

Epoch: 5| Step: 2
Training loss: 0.5603518486022949
Validation loss: 1.860256859051284

Epoch: 5| Step: 3
Training loss: 0.5722031593322754
Validation loss: 1.8867825961882068

Epoch: 5| Step: 4
Training loss: 1.269030213356018
Validation loss: 1.9061261453936178

Epoch: 5| Step: 5
Training loss: 1.101399302482605
Validation loss: 1.8634215324155745

Epoch: 5| Step: 6
Training loss: 0.8592011332511902
Validation loss: 1.8323198287717757

Epoch: 5| Step: 7
Training loss: 0.691362738609314
Validation loss: 1.85767497042174

Epoch: 5| Step: 8
Training loss: 1.203883409500122
Validation loss: 1.8738324167907878

Epoch: 5| Step: 9
Training loss: 0.8544237017631531
Validation loss: 1.8540234488825644

Epoch: 5| Step: 10
Training loss: 0.9681166410446167
Validation loss: 1.828479184899279

Epoch: 623| Step: 0
Training loss: 1.1779074668884277
Validation loss: 1.8808567870047785

Epoch: 5| Step: 1
Training loss: 0.8243439793586731
Validation loss: 1.8693038007264495

Epoch: 5| Step: 2
Training loss: 0.9075964689254761
Validation loss: 1.9087956169600129

Epoch: 5| Step: 3
Training loss: 1.2454135417938232
Validation loss: 1.8081842186630412

Epoch: 5| Step: 4
Training loss: 0.6339679956436157
Validation loss: 1.7984919804398731

Epoch: 5| Step: 5
Training loss: 0.7683902978897095
Validation loss: 1.8627631536094091

Epoch: 5| Step: 6
Training loss: 0.9607692956924438
Validation loss: 1.8337232182102818

Epoch: 5| Step: 7
Training loss: 0.6551530957221985
Validation loss: 1.8768773668555803

Epoch: 5| Step: 8
Training loss: 0.8832818865776062
Validation loss: 1.8488919324772333

Epoch: 5| Step: 9
Training loss: 0.4724331796169281
Validation loss: 1.8196784309161607

Epoch: 5| Step: 10
Training loss: 1.722792148590088
Validation loss: 1.82161594078105

Epoch: 624| Step: 0
Training loss: 0.7595980763435364
Validation loss: 1.8604376469888995

Epoch: 5| Step: 1
Training loss: 0.954706072807312
Validation loss: 1.8315675694455382

Epoch: 5| Step: 2
Training loss: 1.1507017612457275
Validation loss: 1.874237609165971

Epoch: 5| Step: 3
Training loss: 0.9192067980766296
Validation loss: 1.8844794432322185

Epoch: 5| Step: 4
Training loss: 1.137394666671753
Validation loss: 1.8562079552681214

Epoch: 5| Step: 5
Training loss: 1.050270438194275
Validation loss: 1.838166662441787

Epoch: 5| Step: 6
Training loss: 0.6222797632217407
Validation loss: 1.8897105904035671

Epoch: 5| Step: 7
Training loss: 0.7952284216880798
Validation loss: 1.841413728652462

Epoch: 5| Step: 8
Training loss: 1.1850395202636719
Validation loss: 1.9126650261622604

Epoch: 5| Step: 9
Training loss: 0.8541208505630493
Validation loss: 1.8762935566645798

Epoch: 5| Step: 10
Training loss: 0.5905585885047913
Validation loss: 1.8642187503076368

Epoch: 625| Step: 0
Training loss: 0.9324213862419128
Validation loss: 1.8596048611466602

Epoch: 5| Step: 1
Training loss: 0.994156002998352
Validation loss: 1.966945081628779

Epoch: 5| Step: 2
Training loss: 0.8461979627609253
Validation loss: 1.9438542576246365

Epoch: 5| Step: 3
Training loss: 0.8576279878616333
Validation loss: 1.902158833319141

Epoch: 5| Step: 4
Training loss: 1.061920166015625
Validation loss: 1.8860994590226041

Epoch: 5| Step: 5
Training loss: 0.7746186256408691
Validation loss: 1.874376432870024

Epoch: 5| Step: 6
Training loss: 0.5700548887252808
Validation loss: 1.860851122486976

Epoch: 5| Step: 7
Training loss: 0.7790055274963379
Validation loss: 1.88555783097462

Epoch: 5| Step: 8
Training loss: 1.1398589611053467
Validation loss: 1.8600843132183116

Epoch: 5| Step: 9
Training loss: 0.830987274646759
Validation loss: 1.9178473154703777

Epoch: 5| Step: 10
Training loss: 1.1375788450241089
Validation loss: 1.9069682013603948

Epoch: 626| Step: 0
Training loss: 0.5647200345993042
Validation loss: 1.869398291392993

Epoch: 5| Step: 1
Training loss: 0.715682864189148
Validation loss: 1.8532060346295756

Epoch: 5| Step: 2
Training loss: 1.0346803665161133
Validation loss: 1.876234685221026

Epoch: 5| Step: 3
Training loss: 1.6609220504760742
Validation loss: 1.8541014745671263

Epoch: 5| Step: 4
Training loss: 0.7404873967170715
Validation loss: 1.8693223922483382

Epoch: 5| Step: 5
Training loss: 1.028436303138733
Validation loss: 1.885340549612558

Epoch: 5| Step: 6
Training loss: 1.3581323623657227
Validation loss: 1.9065663327452957

Epoch: 5| Step: 7
Training loss: 0.7339275479316711
Validation loss: 1.8473653203697615

Epoch: 5| Step: 8
Training loss: 0.8598272204399109
Validation loss: 1.848533259925022

Epoch: 5| Step: 9
Training loss: 0.8261749148368835
Validation loss: 1.8940638137120072

Epoch: 5| Step: 10
Training loss: 0.7424004673957825
Validation loss: 1.849069595336914

Epoch: 627| Step: 0
Training loss: 0.7637333869934082
Validation loss: 1.8373011081449446

Epoch: 5| Step: 1
Training loss: 1.3182318210601807
Validation loss: 1.879872214409613

Epoch: 5| Step: 2
Training loss: 0.8345847129821777
Validation loss: 1.8238217215384207

Epoch: 5| Step: 3
Training loss: 1.1627790927886963
Validation loss: 1.855428909742704

Epoch: 5| Step: 4
Training loss: 1.0312778949737549
Validation loss: 1.8458810429419241

Epoch: 5| Step: 5
Training loss: 0.9005628824234009
Validation loss: 1.8473381432153846

Epoch: 5| Step: 6
Training loss: 0.7622639536857605
Validation loss: 1.836386908767044

Epoch: 5| Step: 7
Training loss: 1.0228111743927002
Validation loss: 1.8355761202432777

Epoch: 5| Step: 8
Training loss: 0.9086045026779175
Validation loss: 1.85212081222124

Epoch: 5| Step: 9
Training loss: 0.8070240020751953
Validation loss: 1.8890003696564706

Epoch: 5| Step: 10
Training loss: 0.6609821319580078
Validation loss: 1.8828287906544183

Epoch: 628| Step: 0
Training loss: 0.7471248507499695
Validation loss: 1.906890748649515

Epoch: 5| Step: 1
Training loss: 0.8687068223953247
Validation loss: 1.8820328648372362

Epoch: 5| Step: 2
Training loss: 0.9101155996322632
Validation loss: 1.8367062063627346

Epoch: 5| Step: 3
Training loss: 0.9479875564575195
Validation loss: 1.8609120679158035

Epoch: 5| Step: 4
Training loss: 0.8981407880783081
Validation loss: 1.889427355540696

Epoch: 5| Step: 5
Training loss: 0.9684690237045288
Validation loss: 1.8928283260714622

Epoch: 5| Step: 6
Training loss: 0.6927251219749451
Validation loss: 1.9053994301826722

Epoch: 5| Step: 7
Training loss: 0.5931817293167114
Validation loss: 1.8624737352453253

Epoch: 5| Step: 8
Training loss: 1.2574245929718018
Validation loss: 1.8933583754365162

Epoch: 5| Step: 9
Training loss: 0.8867653012275696
Validation loss: 1.8627897308718773

Epoch: 5| Step: 10
Training loss: 1.04303777217865
Validation loss: 1.8522222580448273

Epoch: 629| Step: 0
Training loss: 1.0188822746276855
Validation loss: 1.8677205526700584

Epoch: 5| Step: 1
Training loss: 0.8347366452217102
Validation loss: 1.9025461853191417

Epoch: 5| Step: 2
Training loss: 1.068211317062378
Validation loss: 1.8536189268994074

Epoch: 5| Step: 3
Training loss: 1.0205800533294678
Validation loss: 1.841612845979711

Epoch: 5| Step: 4
Training loss: 0.8521798253059387
Validation loss: 1.789418093619808

Epoch: 5| Step: 5
Training loss: 1.011772632598877
Validation loss: 1.8322716707824378

Epoch: 5| Step: 6
Training loss: 0.8317289352416992
Validation loss: 1.8471734126408894

Epoch: 5| Step: 7
Training loss: 1.0751363039016724
Validation loss: 1.8980179499554377

Epoch: 5| Step: 8
Training loss: 0.8126837611198425
Validation loss: 1.837843382230369

Epoch: 5| Step: 9
Training loss: 0.9591878056526184
Validation loss: 1.839096139836055

Epoch: 5| Step: 10
Training loss: 0.8296056389808655
Validation loss: 1.841566224252024

Epoch: 630| Step: 0
Training loss: 1.0456541776657104
Validation loss: 1.8567177198266471

Epoch: 5| Step: 1
Training loss: 1.0448286533355713
Validation loss: 1.857663651948334

Epoch: 5| Step: 2
Training loss: 0.723592221736908
Validation loss: 1.8998187062560872

Epoch: 5| Step: 3
Training loss: 1.0552341938018799
Validation loss: 1.8828444724441857

Epoch: 5| Step: 4
Training loss: 1.329308271408081
Validation loss: 1.8621632181188112

Epoch: 5| Step: 5
Training loss: 0.5553097724914551
Validation loss: 1.8561577386753534

Epoch: 5| Step: 6
Training loss: 0.6715444326400757
Validation loss: 1.893693494540389

Epoch: 5| Step: 7
Training loss: 0.8705232739448547
Validation loss: 1.9205160961356214

Epoch: 5| Step: 8
Training loss: 1.1787848472595215
Validation loss: 1.8896711795560774

Epoch: 5| Step: 9
Training loss: 0.9513195157051086
Validation loss: 1.8622280577177643

Epoch: 5| Step: 10
Training loss: 0.5104129910469055
Validation loss: 1.9230012586039882

Epoch: 631| Step: 0
Training loss: 1.1497366428375244
Validation loss: 1.8808509995860438

Epoch: 5| Step: 1
Training loss: 0.9893480539321899
Validation loss: 1.8414629287617181

Epoch: 5| Step: 2
Training loss: 0.8493658304214478
Validation loss: 1.8462748207071775

Epoch: 5| Step: 3
Training loss: 0.8154220581054688
Validation loss: 1.8347970131904847

Epoch: 5| Step: 4
Training loss: 1.1843070983886719
Validation loss: 1.8586053989266837

Epoch: 5| Step: 5
Training loss: 0.7239007949829102
Validation loss: 1.8769278128941853

Epoch: 5| Step: 6
Training loss: 1.3902915716171265
Validation loss: 1.8059371645732591

Epoch: 5| Step: 7
Training loss: 0.6659871339797974
Validation loss: 1.8353069725856985

Epoch: 5| Step: 8
Training loss: 0.4508746266365051
Validation loss: 1.8698339423825663

Epoch: 5| Step: 9
Training loss: 0.7542060613632202
Validation loss: 1.8572530438823085

Epoch: 5| Step: 10
Training loss: 1.3076276779174805
Validation loss: 1.883586625899038

Epoch: 632| Step: 0
Training loss: 1.1167073249816895
Validation loss: 1.8862714972547305

Epoch: 5| Step: 1
Training loss: 0.915135383605957
Validation loss: 1.8614894638779342

Epoch: 5| Step: 2
Training loss: 1.0033893585205078
Validation loss: 1.903764324803506

Epoch: 5| Step: 3
Training loss: 0.9116511344909668
Validation loss: 1.8932399595937421

Epoch: 5| Step: 4
Training loss: 1.2714474201202393
Validation loss: 1.8804488758887015

Epoch: 5| Step: 5
Training loss: 0.6903588175773621
Validation loss: 1.9185939604236233

Epoch: 5| Step: 6
Training loss: 1.0385000705718994
Validation loss: 1.8985874473407705

Epoch: 5| Step: 7
Training loss: 0.829653263092041
Validation loss: 1.8337952616394206

Epoch: 5| Step: 8
Training loss: 1.198225498199463
Validation loss: 1.8859425488338675

Epoch: 5| Step: 9
Training loss: 0.7374826669692993
Validation loss: 1.9290379785722302

Epoch: 5| Step: 10
Training loss: 0.4270407259464264
Validation loss: 1.867107323420945

Epoch: 633| Step: 0
Training loss: 0.829736590385437
Validation loss: 1.8491286923808437

Epoch: 5| Step: 1
Training loss: 0.7649543285369873
Validation loss: 1.9244174290728826

Epoch: 5| Step: 2
Training loss: 0.966110348701477
Validation loss: 1.93456857819711

Epoch: 5| Step: 3
Training loss: 1.233398675918579
Validation loss: 1.8449433542067004

Epoch: 5| Step: 4
Training loss: 0.5905547142028809
Validation loss: 1.8928395573810866

Epoch: 5| Step: 5
Training loss: 1.0625555515289307
Validation loss: 1.8340599665077784

Epoch: 5| Step: 6
Training loss: 0.8424800634384155
Validation loss: 1.8231535252704416

Epoch: 5| Step: 7
Training loss: 0.9257074594497681
Validation loss: 1.788896967005986

Epoch: 5| Step: 8
Training loss: 1.049229383468628
Validation loss: 1.8208552727135279

Epoch: 5| Step: 9
Training loss: 0.6197459101676941
Validation loss: 1.7962670031414236

Epoch: 5| Step: 10
Training loss: 1.1027806997299194
Validation loss: 1.905438882048412

Epoch: 634| Step: 0
Training loss: 0.5927267670631409
Validation loss: 1.839710448377876

Epoch: 5| Step: 1
Training loss: 0.8063650131225586
Validation loss: 1.8423939315221642

Epoch: 5| Step: 2
Training loss: 0.9674889445304871
Validation loss: 1.8345260838026642

Epoch: 5| Step: 3
Training loss: 1.095420002937317
Validation loss: 1.912466836232011

Epoch: 5| Step: 4
Training loss: 0.5414201617240906
Validation loss: 1.868462602297465

Epoch: 5| Step: 5
Training loss: 0.911371111869812
Validation loss: 1.8598616225745088

Epoch: 5| Step: 6
Training loss: 0.9876890182495117
Validation loss: 1.8935852883964457

Epoch: 5| Step: 7
Training loss: 0.904181957244873
Validation loss: 1.886125394093093

Epoch: 5| Step: 8
Training loss: 0.8448363542556763
Validation loss: 1.8715012470881145

Epoch: 5| Step: 9
Training loss: 0.7911006212234497
Validation loss: 1.8594685754468363

Epoch: 5| Step: 10
Training loss: 1.504480242729187
Validation loss: 1.9023849271958875

Epoch: 635| Step: 0
Training loss: 1.0304880142211914
Validation loss: 1.9011796905148415

Epoch: 5| Step: 1
Training loss: 0.5209308862686157
Validation loss: 1.8679032966654787

Epoch: 5| Step: 2
Training loss: 1.5304973125457764
Validation loss: 1.9012450466873825

Epoch: 5| Step: 3
Training loss: 0.7280219793319702
Validation loss: 1.8344074615868189

Epoch: 5| Step: 4
Training loss: 0.8179687261581421
Validation loss: 1.8353758691459574

Epoch: 5| Step: 5
Training loss: 0.7081871628761292
Validation loss: 1.9097760595301145

Epoch: 5| Step: 6
Training loss: 0.7021306753158569
Validation loss: 1.8551624346804876

Epoch: 5| Step: 7
Training loss: 1.0736984014511108
Validation loss: 1.8900990306690175

Epoch: 5| Step: 8
Training loss: 0.9735392332077026
Validation loss: 1.9365389141985165

Epoch: 5| Step: 9
Training loss: 0.9885309934616089
Validation loss: 1.9173218075947096

Epoch: 5| Step: 10
Training loss: 1.2229959964752197
Validation loss: 1.8796416405708558

Epoch: 636| Step: 0
Training loss: 0.6563578844070435
Validation loss: 1.895734130695302

Epoch: 5| Step: 1
Training loss: 1.0537099838256836
Validation loss: 1.8502529410905735

Epoch: 5| Step: 2
Training loss: 0.9260338544845581
Validation loss: 1.8580251124597364

Epoch: 5| Step: 3
Training loss: 1.4288688898086548
Validation loss: 1.933454651986399

Epoch: 5| Step: 4
Training loss: 0.8089759945869446
Validation loss: 1.918351896347538

Epoch: 5| Step: 5
Training loss: 1.1877747774124146
Validation loss: 1.8440359266855384

Epoch: 5| Step: 6
Training loss: 0.8932267427444458
Validation loss: 1.8145946866722518

Epoch: 5| Step: 7
Training loss: 0.5243932008743286
Validation loss: 1.8791590211211995

Epoch: 5| Step: 8
Training loss: 0.6833115816116333
Validation loss: 1.9504927691592966

Epoch: 5| Step: 9
Training loss: 0.7511507272720337
Validation loss: 1.8639887199606946

Epoch: 5| Step: 10
Training loss: 0.6191216707229614
Validation loss: 1.908744599229546

Epoch: 637| Step: 0
Training loss: 0.8165976405143738
Validation loss: 1.923226115524128

Epoch: 5| Step: 1
Training loss: 1.0915751457214355
Validation loss: 1.8493952828068887

Epoch: 5| Step: 2
Training loss: 1.1072804927825928
Validation loss: 1.8087937972878898

Epoch: 5| Step: 3
Training loss: 1.410980224609375
Validation loss: 1.9115994361139113

Epoch: 5| Step: 4
Training loss: 0.8903681039810181
Validation loss: 1.8487427542286534

Epoch: 5| Step: 5
Training loss: 0.5607528686523438
Validation loss: 1.9019219516426005

Epoch: 5| Step: 6
Training loss: 0.5993586778640747
Validation loss: 1.864675691050868

Epoch: 5| Step: 7
Training loss: 0.9714422225952148
Validation loss: 1.8556644070533015

Epoch: 5| Step: 8
Training loss: 0.506985604763031
Validation loss: 1.8715779858250772

Epoch: 5| Step: 9
Training loss: 1.0662614107131958
Validation loss: 1.8506925990504604

Epoch: 5| Step: 10
Training loss: 0.9119082093238831
Validation loss: 1.8520978253374818

Epoch: 638| Step: 0
Training loss: 0.942927360534668
Validation loss: 1.8214349515976445

Epoch: 5| Step: 1
Training loss: 1.0534305572509766
Validation loss: 1.8411338072951122

Epoch: 5| Step: 2
Training loss: 0.7834717035293579
Validation loss: 1.8591501046252508

Epoch: 5| Step: 3
Training loss: 0.7983518838882446
Validation loss: 1.816629958409135

Epoch: 5| Step: 4
Training loss: 0.919452965259552
Validation loss: 1.8884776740945795

Epoch: 5| Step: 5
Training loss: 1.0097227096557617
Validation loss: 1.8555194947027391

Epoch: 5| Step: 6
Training loss: 1.2923710346221924
Validation loss: 1.8666654914937995

Epoch: 5| Step: 7
Training loss: 0.5964062213897705
Validation loss: 1.8999006427744383

Epoch: 5| Step: 8
Training loss: 1.2846845388412476
Validation loss: 1.8811399731584775

Epoch: 5| Step: 9
Training loss: 0.6836244463920593
Validation loss: 1.836309512456258

Epoch: 5| Step: 10
Training loss: 0.6398580074310303
Validation loss: 1.8713600673983175

Epoch: 639| Step: 0
Training loss: 0.652551531791687
Validation loss: 1.8829669260209607

Epoch: 5| Step: 1
Training loss: 0.9979422688484192
Validation loss: 1.8420438266569568

Epoch: 5| Step: 2
Training loss: 0.7793110609054565
Validation loss: 1.8731646947963263

Epoch: 5| Step: 3
Training loss: 0.7155755162239075
Validation loss: 1.8203469014936877

Epoch: 5| Step: 4
Training loss: 0.8846761584281921
Validation loss: 1.8517000431655555

Epoch: 5| Step: 5
Training loss: 0.8904412388801575
Validation loss: 1.9217826256188013

Epoch: 5| Step: 6
Training loss: 0.6444013714790344
Validation loss: 1.9048443186667658

Epoch: 5| Step: 7
Training loss: 1.3260948657989502
Validation loss: 1.8802290039677774

Epoch: 5| Step: 8
Training loss: 0.7019454836845398
Validation loss: 1.8642066935057282

Epoch: 5| Step: 9
Training loss: 1.0482652187347412
Validation loss: 1.888516431213707

Epoch: 5| Step: 10
Training loss: 1.0421277284622192
Validation loss: 1.8785816943773659

Epoch: 640| Step: 0
Training loss: 1.1134142875671387
Validation loss: 1.8201051809454476

Epoch: 5| Step: 1
Training loss: 1.1850172281265259
Validation loss: 1.8412854363841396

Epoch: 5| Step: 2
Training loss: 0.7376405596733093
Validation loss: 1.863590564779056

Epoch: 5| Step: 3
Training loss: 1.0572017431259155
Validation loss: 1.8501732477577784

Epoch: 5| Step: 4
Training loss: 0.46909862756729126
Validation loss: 1.855441003717402

Epoch: 5| Step: 5
Training loss: 1.2099554538726807
Validation loss: 1.8406937019799345

Epoch: 5| Step: 6
Training loss: 0.6251643896102905
Validation loss: 1.8317465013073337

Epoch: 5| Step: 7
Training loss: 0.7050499320030212
Validation loss: 1.825214639786751

Epoch: 5| Step: 8
Training loss: 1.0419038534164429
Validation loss: 1.8468794220237321

Epoch: 5| Step: 9
Training loss: 0.7668845653533936
Validation loss: 1.8382948214007961

Epoch: 5| Step: 10
Training loss: 1.1116117238998413
Validation loss: 1.8842609159408077

Epoch: 641| Step: 0
Training loss: 1.216848611831665
Validation loss: 1.8538142840067546

Epoch: 5| Step: 1
Training loss: 0.690194308757782
Validation loss: 1.8489300333043581

Epoch: 5| Step: 2
Training loss: 0.7321933507919312
Validation loss: 1.8808173979482343

Epoch: 5| Step: 3
Training loss: 0.8193280100822449
Validation loss: 1.8632492250011814

Epoch: 5| Step: 4
Training loss: 0.986493706703186
Validation loss: 1.8762003939638856

Epoch: 5| Step: 5
Training loss: 1.0891401767730713
Validation loss: 1.8944294580849268

Epoch: 5| Step: 6
Training loss: 0.8345049023628235
Validation loss: 1.8215552324889808

Epoch: 5| Step: 7
Training loss: 0.9072017669677734
Validation loss: 1.8747288129662956

Epoch: 5| Step: 8
Training loss: 0.9356428384780884
Validation loss: 1.815899682301347

Epoch: 5| Step: 9
Training loss: 0.723061740398407
Validation loss: 1.9038426427431003

Epoch: 5| Step: 10
Training loss: 0.9881950616836548
Validation loss: 1.811688958957631

Epoch: 642| Step: 0
Training loss: 1.0175093412399292
Validation loss: 1.8729667894301876

Epoch: 5| Step: 1
Training loss: 1.0535622835159302
Validation loss: 1.8470328084884151

Epoch: 5| Step: 2
Training loss: 0.8459632992744446
Validation loss: 1.8833562507424304

Epoch: 5| Step: 3
Training loss: 0.9310176968574524
Validation loss: 1.8993658096559587

Epoch: 5| Step: 4
Training loss: 0.8837774395942688
Validation loss: 1.8619828365182365

Epoch: 5| Step: 5
Training loss: 1.2908575534820557
Validation loss: 1.910918028123917

Epoch: 5| Step: 6
Training loss: 0.7735941410064697
Validation loss: 1.8687337598493021

Epoch: 5| Step: 7
Training loss: 0.7616232633590698
Validation loss: 1.8993867930545603

Epoch: 5| Step: 8
Training loss: 0.5655410289764404
Validation loss: 1.8877086870131954

Epoch: 5| Step: 9
Training loss: 0.696483850479126
Validation loss: 1.8693085614071097

Epoch: 5| Step: 10
Training loss: 0.8337951898574829
Validation loss: 1.8108665456054032

Epoch: 643| Step: 0
Training loss: 0.6555153727531433
Validation loss: 1.8131464168589602

Epoch: 5| Step: 1
Training loss: 0.9255735278129578
Validation loss: 1.8471951407770957

Epoch: 5| Step: 2
Training loss: 1.1362323760986328
Validation loss: 1.8575255915682802

Epoch: 5| Step: 3
Training loss: 1.0890251398086548
Validation loss: 1.8473004448798396

Epoch: 5| Step: 4
Training loss: 0.9918781518936157
Validation loss: 1.8177652666645665

Epoch: 5| Step: 5
Training loss: 0.8242223858833313
Validation loss: 1.8680101825344948

Epoch: 5| Step: 6
Training loss: 0.9402897953987122
Validation loss: 1.8441004548021542

Epoch: 5| Step: 7
Training loss: 0.9557798504829407
Validation loss: 1.9109916802375548

Epoch: 5| Step: 8
Training loss: 0.49883347749710083
Validation loss: 1.8679893529543312

Epoch: 5| Step: 9
Training loss: 1.0790469646453857
Validation loss: 1.8959187141028784

Epoch: 5| Step: 10
Training loss: 0.5773103833198547
Validation loss: 1.8742890742517286

Epoch: 644| Step: 0
Training loss: 0.6872639656066895
Validation loss: 1.9098874227975005

Epoch: 5| Step: 1
Training loss: 0.7221980094909668
Validation loss: 1.896354849620532

Epoch: 5| Step: 2
Training loss: 1.0464684963226318
Validation loss: 1.9670345680688017

Epoch: 5| Step: 3
Training loss: 1.0365569591522217
Validation loss: 1.9112302898078837

Epoch: 5| Step: 4
Training loss: 0.7036784887313843
Validation loss: 1.8404174043286232

Epoch: 5| Step: 5
Training loss: 1.1016923189163208
Validation loss: 1.9186225373257872

Epoch: 5| Step: 6
Training loss: 0.8574930429458618
Validation loss: 1.9116217910602529

Epoch: 5| Step: 7
Training loss: 0.753154456615448
Validation loss: 1.8943037192026775

Epoch: 5| Step: 8
Training loss: 1.037555456161499
Validation loss: 1.8555927494520783

Epoch: 5| Step: 9
Training loss: 0.7861489057540894
Validation loss: 1.8638146090251144

Epoch: 5| Step: 10
Training loss: 1.2375537157058716
Validation loss: 1.8540844532751268

Epoch: 645| Step: 0
Training loss: 0.8922885656356812
Validation loss: 1.8602892788507606

Epoch: 5| Step: 1
Training loss: 1.0976189374923706
Validation loss: 1.8582134285280782

Epoch: 5| Step: 2
Training loss: 0.9688618779182434
Validation loss: 1.8569140588083575

Epoch: 5| Step: 3
Training loss: 0.6608635187149048
Validation loss: 1.871621431842927

Epoch: 5| Step: 4
Training loss: 0.6713034510612488
Validation loss: 1.9116405953643143

Epoch: 5| Step: 5
Training loss: 0.7448007464408875
Validation loss: 1.897829391623056

Epoch: 5| Step: 6
Training loss: 0.8825911283493042
Validation loss: 1.8920675734037995

Epoch: 5| Step: 7
Training loss: 0.9645037651062012
Validation loss: 1.9030998342780656

Epoch: 5| Step: 8
Training loss: 1.1087511777877808
Validation loss: 1.9049909525020148

Epoch: 5| Step: 9
Training loss: 0.7850956320762634
Validation loss: 1.8890113830566406

Epoch: 5| Step: 10
Training loss: 1.0266474485397339
Validation loss: 1.918357959357641

Epoch: 646| Step: 0
Training loss: 0.8865180015563965
Validation loss: 1.8978590042360368

Epoch: 5| Step: 1
Training loss: 0.8114708065986633
Validation loss: 1.9068613026731758

Epoch: 5| Step: 2
Training loss: 0.6753283739089966
Validation loss: 1.8897845027267293

Epoch: 5| Step: 3
Training loss: 1.4024585485458374
Validation loss: 1.8932985105822164

Epoch: 5| Step: 4
Training loss: 0.5548406839370728
Validation loss: 1.8835473534881428

Epoch: 5| Step: 5
Training loss: 0.7678554654121399
Validation loss: 1.8754939622776483

Epoch: 5| Step: 6
Training loss: 1.1989792585372925
Validation loss: 1.9308240452120382

Epoch: 5| Step: 7
Training loss: 0.8884885907173157
Validation loss: 1.8486186701764342

Epoch: 5| Step: 8
Training loss: 0.5289658904075623
Validation loss: 1.8503190471280007

Epoch: 5| Step: 9
Training loss: 1.0257847309112549
Validation loss: 1.865272368154218

Epoch: 5| Step: 10
Training loss: 0.7257069945335388
Validation loss: 1.8404511943940194

Epoch: 647| Step: 0
Training loss: 0.3634083867073059
Validation loss: 1.8571070881300076

Epoch: 5| Step: 1
Training loss: 1.0185167789459229
Validation loss: 1.909412904452252

Epoch: 5| Step: 2
Training loss: 1.4187246561050415
Validation loss: 1.8694643743576542

Epoch: 5| Step: 3
Training loss: 0.7222331762313843
Validation loss: 1.867620252793835

Epoch: 5| Step: 4
Training loss: 0.7378126382827759
Validation loss: 1.8270935140630251

Epoch: 5| Step: 5
Training loss: 0.7989079356193542
Validation loss: 1.8858445664887786

Epoch: 5| Step: 6
Training loss: 0.7029892206192017
Validation loss: 1.8688500594067317

Epoch: 5| Step: 7
Training loss: 0.8899564743041992
Validation loss: 1.9060596778828611

Epoch: 5| Step: 8
Training loss: 0.9700706601142883
Validation loss: 1.8486169448462866

Epoch: 5| Step: 9
Training loss: 0.6468769311904907
Validation loss: 1.9086289046913065

Epoch: 5| Step: 10
Training loss: 1.1494274139404297
Validation loss: 1.850152773241843

Epoch: 648| Step: 0
Training loss: 0.559506893157959
Validation loss: 1.8674774580104376

Epoch: 5| Step: 1
Training loss: 0.674850583076477
Validation loss: 1.9351715362200173

Epoch: 5| Step: 2
Training loss: 0.9431264996528625
Validation loss: 1.8966538060096003

Epoch: 5| Step: 3
Training loss: 1.0407049655914307
Validation loss: 1.842868567794882

Epoch: 5| Step: 4
Training loss: 0.7030438780784607
Validation loss: 1.816435178120931

Epoch: 5| Step: 5
Training loss: 0.8764459490776062
Validation loss: 1.8966444538485618

Epoch: 5| Step: 6
Training loss: 1.1537630558013916
Validation loss: 1.9112028255257556

Epoch: 5| Step: 7
Training loss: 0.888525664806366
Validation loss: 1.8749314059493363

Epoch: 5| Step: 8
Training loss: 0.7611411213874817
Validation loss: 1.8562874294096423

Epoch: 5| Step: 9
Training loss: 0.960281491279602
Validation loss: 1.8645668439967658

Epoch: 5| Step: 10
Training loss: 1.1093354225158691
Validation loss: 1.8762253022963

Epoch: 649| Step: 0
Training loss: 1.3867456912994385
Validation loss: 1.9039851311714417

Epoch: 5| Step: 1
Training loss: 0.8252429962158203
Validation loss: 1.905125940999677

Epoch: 5| Step: 2
Training loss: 0.8069605827331543
Validation loss: 1.899333966675625

Epoch: 5| Step: 3
Training loss: 1.1496553421020508
Validation loss: 1.9304934522157073

Epoch: 5| Step: 4
Training loss: 0.64853835105896
Validation loss: 1.8891949204988376

Epoch: 5| Step: 5
Training loss: 0.5026602745056152
Validation loss: 1.905347752314742

Epoch: 5| Step: 6
Training loss: 0.9572534561157227
Validation loss: 1.8912976185480754

Epoch: 5| Step: 7
Training loss: 0.7583673000335693
Validation loss: 1.8831417381122548

Epoch: 5| Step: 8
Training loss: 1.0927058458328247
Validation loss: 1.8475726112242667

Epoch: 5| Step: 9
Training loss: 0.7309139966964722
Validation loss: 1.8433759430403351

Epoch: 5| Step: 10
Training loss: 0.9163004159927368
Validation loss: 1.8847882850195772

Epoch: 650| Step: 0
Training loss: 0.7202175855636597
Validation loss: 1.8962502056552517

Epoch: 5| Step: 1
Training loss: 0.8680703043937683
Validation loss: 1.8737160441696004

Epoch: 5| Step: 2
Training loss: 0.8684417009353638
Validation loss: 1.834728084584718

Epoch: 5| Step: 3
Training loss: 0.7516511678695679
Validation loss: 1.8262557624488749

Epoch: 5| Step: 4
Training loss: 1.0682575702667236
Validation loss: 1.8434669317737702

Epoch: 5| Step: 5
Training loss: 0.9045988321304321
Validation loss: 1.8642416743821995

Epoch: 5| Step: 6
Training loss: 0.691789448261261
Validation loss: 1.867426085215743

Epoch: 5| Step: 7
Training loss: 1.0303937196731567
Validation loss: 1.7910884349576888

Epoch: 5| Step: 8
Training loss: 1.438202977180481
Validation loss: 1.8802991323573615

Epoch: 5| Step: 9
Training loss: 0.9619854092597961
Validation loss: 1.9076760866308724

Epoch: 5| Step: 10
Training loss: 0.8078632950782776
Validation loss: 1.87019726281525

Epoch: 651| Step: 0
Training loss: 1.1447592973709106
Validation loss: 1.876518029038624

Epoch: 5| Step: 1
Training loss: 0.7515007853507996
Validation loss: 1.8633440694501322

Epoch: 5| Step: 2
Training loss: 0.6395257711410522
Validation loss: 1.8820737920781618

Epoch: 5| Step: 3
Training loss: 0.8383447527885437
Validation loss: 1.888674041276337

Epoch: 5| Step: 4
Training loss: 1.4196244478225708
Validation loss: 1.8407443851552985

Epoch: 5| Step: 5
Training loss: 0.5904339551925659
Validation loss: 1.8330341077619983

Epoch: 5| Step: 6
Training loss: 0.7675188779830933
Validation loss: 1.8836227360592093

Epoch: 5| Step: 7
Training loss: 1.0492326021194458
Validation loss: 1.8345805470661452

Epoch: 5| Step: 8
Training loss: 0.6647421717643738
Validation loss: 1.8328529250237249

Epoch: 5| Step: 9
Training loss: 1.1796420812606812
Validation loss: 1.8158297000392791

Epoch: 5| Step: 10
Training loss: 0.6434439420700073
Validation loss: 1.858894273798953

Epoch: 652| Step: 0
Training loss: 1.0944812297821045
Validation loss: 1.8521842648906093

Epoch: 5| Step: 1
Training loss: 0.7192392945289612
Validation loss: 1.8441951544054094

Epoch: 5| Step: 2
Training loss: 0.8831462860107422
Validation loss: 1.9125682461646296

Epoch: 5| Step: 3
Training loss: 0.5366439819335938
Validation loss: 1.8572365648003035

Epoch: 5| Step: 4
Training loss: 1.0745487213134766
Validation loss: 1.874248784075501

Epoch: 5| Step: 5
Training loss: 0.7416247129440308
Validation loss: 1.8977276907172254

Epoch: 5| Step: 6
Training loss: 0.6249309182167053
Validation loss: 1.8485771456072408

Epoch: 5| Step: 7
Training loss: 0.9175818562507629
Validation loss: 1.881933428907907

Epoch: 5| Step: 8
Training loss: 0.9162492752075195
Validation loss: 1.8898439586803477

Epoch: 5| Step: 9
Training loss: 0.9535964727401733
Validation loss: 1.886351070096416

Epoch: 5| Step: 10
Training loss: 1.0572137832641602
Validation loss: 1.8520723888950963

Epoch: 653| Step: 0
Training loss: 1.0288023948669434
Validation loss: 1.8524821881325013

Epoch: 5| Step: 1
Training loss: 0.6584419012069702
Validation loss: 1.8543598177612468

Epoch: 5| Step: 2
Training loss: 0.7620378732681274
Validation loss: 1.849784876710625

Epoch: 5| Step: 3
Training loss: 1.0250208377838135
Validation loss: 1.8274572985146635

Epoch: 5| Step: 4
Training loss: 0.568423867225647
Validation loss: 1.8570152495497017

Epoch: 5| Step: 5
Training loss: 0.9605642557144165
Validation loss: 1.8774491292174145

Epoch: 5| Step: 6
Training loss: 0.8375563621520996
Validation loss: 1.8766249328531244

Epoch: 5| Step: 7
Training loss: 0.8887370824813843
Validation loss: 1.8612003608416485

Epoch: 5| Step: 8
Training loss: 0.8945208787918091
Validation loss: 1.8804707821979318

Epoch: 5| Step: 9
Training loss: 0.9756304621696472
Validation loss: 1.857741690451099

Epoch: 5| Step: 10
Training loss: 0.8818307518959045
Validation loss: 1.8769183338329356

Epoch: 654| Step: 0
Training loss: 0.7372738122940063
Validation loss: 1.8738963001517839

Epoch: 5| Step: 1
Training loss: 0.6369967460632324
Validation loss: 1.8883673837107997

Epoch: 5| Step: 2
Training loss: 0.5265607833862305
Validation loss: 1.9142614372314946

Epoch: 5| Step: 3
Training loss: 0.9544891119003296
Validation loss: 1.8561388190074632

Epoch: 5| Step: 4
Training loss: 1.0513675212860107
Validation loss: 1.8258135113664853

Epoch: 5| Step: 5
Training loss: 0.8548458218574524
Validation loss: 1.9266323889455488

Epoch: 5| Step: 6
Training loss: 1.2184672355651855
Validation loss: 1.8632884897211546

Epoch: 5| Step: 7
Training loss: 0.6382034420967102
Validation loss: 1.8436730036171534

Epoch: 5| Step: 8
Training loss: 0.6742843389511108
Validation loss: 1.8329727354870047

Epoch: 5| Step: 9
Training loss: 1.0750935077667236
Validation loss: 1.8114978831301454

Epoch: 5| Step: 10
Training loss: 0.9971336126327515
Validation loss: 1.8464961282668575

Epoch: 655| Step: 0
Training loss: 0.7106559872627258
Validation loss: 1.839583102092948

Epoch: 5| Step: 1
Training loss: 0.5867400765419006
Validation loss: 1.8319098603340886

Epoch: 5| Step: 2
Training loss: 1.1570172309875488
Validation loss: 1.8168663081302439

Epoch: 5| Step: 3
Training loss: 0.829089343547821
Validation loss: 1.8788964645836943

Epoch: 5| Step: 4
Training loss: 0.9551445245742798
Validation loss: 1.8425650519709433

Epoch: 5| Step: 5
Training loss: 0.6248751878738403
Validation loss: 1.8511248480889104

Epoch: 5| Step: 6
Training loss: 0.6439532041549683
Validation loss: 1.8582489208508564

Epoch: 5| Step: 7
Training loss: 1.2846834659576416
Validation loss: 1.8301822972554032

Epoch: 5| Step: 8
Training loss: 0.7195954322814941
Validation loss: 1.8101102793088524

Epoch: 5| Step: 9
Training loss: 1.286276936531067
Validation loss: 1.8900692988467473

Epoch: 5| Step: 10
Training loss: 0.911128580570221
Validation loss: 1.8432581629804385

Epoch: 656| Step: 0
Training loss: 0.8957271575927734
Validation loss: 1.9138629821039015

Epoch: 5| Step: 1
Training loss: 0.7817859649658203
Validation loss: 1.912068454168176

Epoch: 5| Step: 2
Training loss: 0.5783578157424927
Validation loss: 1.933509926642141

Epoch: 5| Step: 3
Training loss: 0.547572910785675
Validation loss: 1.8620080281329412

Epoch: 5| Step: 4
Training loss: 1.532361626625061
Validation loss: 1.9433415948703725

Epoch: 5| Step: 5
Training loss: 0.8636531829833984
Validation loss: 1.8821137233447003

Epoch: 5| Step: 6
Training loss: 1.2092792987823486
Validation loss: 1.8861662739066667

Epoch: 5| Step: 7
Training loss: 0.7066677212715149
Validation loss: 1.8845315517917756

Epoch: 5| Step: 8
Training loss: 0.5210936665534973
Validation loss: 1.8725473406494304

Epoch: 5| Step: 9
Training loss: 1.055764079093933
Validation loss: 1.8283807398170553

Epoch: 5| Step: 10
Training loss: 0.8617209196090698
Validation loss: 1.8589766025543213

Epoch: 657| Step: 0
Training loss: 0.6801794171333313
Validation loss: 1.8587424921733078

Epoch: 5| Step: 1
Training loss: 1.2873389720916748
Validation loss: 1.8303881870803012

Epoch: 5| Step: 2
Training loss: 0.49569153785705566
Validation loss: 1.8398637515242382

Epoch: 5| Step: 3
Training loss: 1.2730321884155273
Validation loss: 1.8451667588244203

Epoch: 5| Step: 4
Training loss: 0.7608598470687866
Validation loss: 1.891500606331774

Epoch: 5| Step: 5
Training loss: 0.7903230786323547
Validation loss: 1.7766804554129159

Epoch: 5| Step: 6
Training loss: 0.6241680383682251
Validation loss: 1.8705752280450636

Epoch: 5| Step: 7
Training loss: 0.9546467661857605
Validation loss: 1.8187155364662089

Epoch: 5| Step: 8
Training loss: 0.5994288325309753
Validation loss: 1.8696380815198343

Epoch: 5| Step: 9
Training loss: 0.5755049586296082
Validation loss: 1.8966666601037467

Epoch: 5| Step: 10
Training loss: 1.2564377784729004
Validation loss: 1.909121419793816

Epoch: 658| Step: 0
Training loss: 0.550757884979248
Validation loss: 1.8960403050145795

Epoch: 5| Step: 1
Training loss: 1.3656208515167236
Validation loss: 1.888426742246074

Epoch: 5| Step: 2
Training loss: 0.8341531753540039
Validation loss: 1.9073738051999

Epoch: 5| Step: 3
Training loss: 0.8931552767753601
Validation loss: 1.9011109054729503

Epoch: 5| Step: 4
Training loss: 1.4031599760055542
Validation loss: 1.8663954068255681

Epoch: 5| Step: 5
Training loss: 0.8482961654663086
Validation loss: 1.9124154634373163

Epoch: 5| Step: 6
Training loss: 0.7463480234146118
Validation loss: 1.8816538267238165

Epoch: 5| Step: 7
Training loss: 0.6171442270278931
Validation loss: 1.8643687540485012

Epoch: 5| Step: 8
Training loss: 0.7046023607254028
Validation loss: 1.8611249154613865

Epoch: 5| Step: 9
Training loss: 0.801953136920929
Validation loss: 1.8767134604915496

Epoch: 5| Step: 10
Training loss: 0.4820503890514374
Validation loss: 1.8630826742418352

Epoch: 659| Step: 0
Training loss: 0.591144323348999
Validation loss: 1.8766846990072599

Epoch: 5| Step: 1
Training loss: 0.7112061381340027
Validation loss: 1.8723471074975946

Epoch: 5| Step: 2
Training loss: 0.4795501232147217
Validation loss: 1.8502067981227752

Epoch: 5| Step: 3
Training loss: 1.1607660055160522
Validation loss: 1.8575345239331644

Epoch: 5| Step: 4
Training loss: 0.8217402696609497
Validation loss: 1.8841528674607635

Epoch: 5| Step: 5
Training loss: 0.8987337946891785
Validation loss: 1.824839275370362

Epoch: 5| Step: 6
Training loss: 1.0364837646484375
Validation loss: 1.812369813201248

Epoch: 5| Step: 7
Training loss: 1.099947214126587
Validation loss: 1.8723628238965107

Epoch: 5| Step: 8
Training loss: 0.758257269859314
Validation loss: 1.8384208345925936

Epoch: 5| Step: 9
Training loss: 0.8001943826675415
Validation loss: 1.879900368311072

Epoch: 5| Step: 10
Training loss: 1.107372760772705
Validation loss: 1.8739159619936379

Epoch: 660| Step: 0
Training loss: 0.7807925939559937
Validation loss: 1.914563096979613

Epoch: 5| Step: 1
Training loss: 0.9470016360282898
Validation loss: 1.8330988178970993

Epoch: 5| Step: 2
Training loss: 0.8806679844856262
Validation loss: 1.8467490576928662

Epoch: 5| Step: 3
Training loss: 0.6281596422195435
Validation loss: 1.871290824746573

Epoch: 5| Step: 4
Training loss: 0.6956111192703247
Validation loss: 1.8676687876383464

Epoch: 5| Step: 5
Training loss: 1.120234489440918
Validation loss: 1.8490554414769655

Epoch: 5| Step: 6
Training loss: 1.4554239511489868
Validation loss: 1.8804754980148808

Epoch: 5| Step: 7
Training loss: 1.0260387659072876
Validation loss: 1.8664210970683763

Epoch: 5| Step: 8
Training loss: 0.8326324224472046
Validation loss: 1.865694845876386

Epoch: 5| Step: 9
Training loss: 0.34889623522758484
Validation loss: 1.832395044706201

Epoch: 5| Step: 10
Training loss: 0.9752206206321716
Validation loss: 1.8947521678863033

Epoch: 661| Step: 0
Training loss: 1.1232534646987915
Validation loss: 1.8627902397545435

Epoch: 5| Step: 1
Training loss: 1.2234997749328613
Validation loss: 1.8514026800791423

Epoch: 5| Step: 2
Training loss: 1.2115166187286377
Validation loss: 1.8878701515095209

Epoch: 5| Step: 3
Training loss: 0.7751141786575317
Validation loss: 1.8889185151746195

Epoch: 5| Step: 4
Training loss: 0.4090305268764496
Validation loss: 1.8410932812639462

Epoch: 5| Step: 5
Training loss: 0.9869022369384766
Validation loss: 1.8412136211190173

Epoch: 5| Step: 6
Training loss: 0.696911633014679
Validation loss: 1.8370557215905958

Epoch: 5| Step: 7
Training loss: 0.6275472640991211
Validation loss: 1.8748224025131555

Epoch: 5| Step: 8
Training loss: 0.6680232882499695
Validation loss: 1.864097963097275

Epoch: 5| Step: 9
Training loss: 0.7781428694725037
Validation loss: 1.8568996255115797

Epoch: 5| Step: 10
Training loss: 0.9157760739326477
Validation loss: 1.8831814283965735

Epoch: 662| Step: 0
Training loss: 0.8107401132583618
Validation loss: 1.9026964531149915

Epoch: 5| Step: 1
Training loss: 0.6138449907302856
Validation loss: 1.8736017519427883

Epoch: 5| Step: 2
Training loss: 0.9421896934509277
Validation loss: 1.9125378477957942

Epoch: 5| Step: 3
Training loss: 1.3313318490982056
Validation loss: 1.846227934283595

Epoch: 5| Step: 4
Training loss: 1.188176155090332
Validation loss: 1.9170476749379148

Epoch: 5| Step: 5
Training loss: 0.8326843976974487
Validation loss: 1.8635334148201892

Epoch: 5| Step: 6
Training loss: 0.7269625067710876
Validation loss: 1.8751020969883088

Epoch: 5| Step: 7
Training loss: 0.7472692131996155
Validation loss: 1.8611957103975358

Epoch: 5| Step: 8
Training loss: 0.7021029591560364
Validation loss: 1.831988726892779

Epoch: 5| Step: 9
Training loss: 0.6062245965003967
Validation loss: 1.8399890520239388

Epoch: 5| Step: 10
Training loss: 0.9484145045280457
Validation loss: 1.8398382663726807

Epoch: 663| Step: 0
Training loss: 1.025493860244751
Validation loss: 1.859809051277817

Epoch: 5| Step: 1
Training loss: 0.7359496355056763
Validation loss: 1.8462706163365354

Epoch: 5| Step: 2
Training loss: 1.5237758159637451
Validation loss: 1.8408359583987985

Epoch: 5| Step: 3
Training loss: 0.616048276424408
Validation loss: 1.8348164532774238

Epoch: 5| Step: 4
Training loss: 0.8934555053710938
Validation loss: 1.9133008180126068

Epoch: 5| Step: 5
Training loss: 0.5300213098526001
Validation loss: 1.8815269060032342

Epoch: 5| Step: 6
Training loss: 0.7084286212921143
Validation loss: 1.8936530710548483

Epoch: 5| Step: 7
Training loss: 0.7135800123214722
Validation loss: 1.8804054606345393

Epoch: 5| Step: 8
Training loss: 0.6264109015464783
Validation loss: 1.8655785232461908

Epoch: 5| Step: 9
Training loss: 1.0961368083953857
Validation loss: 1.8873708248138428

Epoch: 5| Step: 10
Training loss: 0.8301841020584106
Validation loss: 1.8885670349162111

Epoch: 664| Step: 0
Training loss: 0.6447575092315674
Validation loss: 1.801391060634326

Epoch: 5| Step: 1
Training loss: 0.7987012267112732
Validation loss: 1.857458641452174

Epoch: 5| Step: 2
Training loss: 0.9288781881332397
Validation loss: 1.8805679416143766

Epoch: 5| Step: 3
Training loss: 1.5751510858535767
Validation loss: 1.790202474081388

Epoch: 5| Step: 4
Training loss: 0.792322039604187
Validation loss: 1.8369482576206166

Epoch: 5| Step: 5
Training loss: 0.8548495173454285
Validation loss: 1.9122955286374657

Epoch: 5| Step: 6
Training loss: 0.674152672290802
Validation loss: 1.843256583777807

Epoch: 5| Step: 7
Training loss: 0.6546967625617981
Validation loss: 1.8477719291563957

Epoch: 5| Step: 8
Training loss: 0.9838224649429321
Validation loss: 1.806691300484442

Epoch: 5| Step: 9
Training loss: 0.521114706993103
Validation loss: 1.839234503366614

Epoch: 5| Step: 10
Training loss: 1.0770572423934937
Validation loss: 1.8427917700941845

Epoch: 665| Step: 0
Training loss: 0.7548413276672363
Validation loss: 1.8528944318012526

Epoch: 5| Step: 1
Training loss: 0.9119037389755249
Validation loss: 1.8868897448303878

Epoch: 5| Step: 2
Training loss: 0.7101584672927856
Validation loss: 1.8584649973018195

Epoch: 5| Step: 3
Training loss: 0.9319032430648804
Validation loss: 1.8182191784663866

Epoch: 5| Step: 4
Training loss: 1.3705997467041016
Validation loss: 1.9002083450235345

Epoch: 5| Step: 5
Training loss: 0.7120348215103149
Validation loss: 1.9043966236934866

Epoch: 5| Step: 6
Training loss: 0.8208287358283997
Validation loss: 1.886970672556149

Epoch: 5| Step: 7
Training loss: 0.8648505210876465
Validation loss: 1.8907555598084644

Epoch: 5| Step: 8
Training loss: 0.897494912147522
Validation loss: 1.854127799310992

Epoch: 5| Step: 9
Training loss: 0.6040529012680054
Validation loss: 1.8577195803324382

Epoch: 5| Step: 10
Training loss: 0.5713396668434143
Validation loss: 1.8119262905531033

Epoch: 666| Step: 0
Training loss: 0.7095847129821777
Validation loss: 1.8545716129323488

Epoch: 5| Step: 1
Training loss: 1.4833829402923584
Validation loss: 1.8268030112789524

Epoch: 5| Step: 2
Training loss: 0.8233564496040344
Validation loss: 1.9056397702104302

Epoch: 5| Step: 3
Training loss: 0.7757793664932251
Validation loss: 1.8759689228509062

Epoch: 5| Step: 4
Training loss: 0.5958354473114014
Validation loss: 1.8477526851879653

Epoch: 5| Step: 5
Training loss: 0.7055720090866089
Validation loss: 1.8692481710064797

Epoch: 5| Step: 6
Training loss: 0.9088519811630249
Validation loss: 1.8300009465986682

Epoch: 5| Step: 7
Training loss: 0.7659465670585632
Validation loss: 1.9043043121214835

Epoch: 5| Step: 8
Training loss: 0.7143274545669556
Validation loss: 1.8599031202254757

Epoch: 5| Step: 9
Training loss: 1.1874701976776123
Validation loss: 1.8386683079504198

Epoch: 5| Step: 10
Training loss: 0.7529821991920471
Validation loss: 1.8411047958558606

Epoch: 667| Step: 0
Training loss: 0.47566866874694824
Validation loss: 1.8670825342978201

Epoch: 5| Step: 1
Training loss: 1.0663280487060547
Validation loss: 1.7991203582415016

Epoch: 5| Step: 2
Training loss: 0.6028600931167603
Validation loss: 1.885956669366488

Epoch: 5| Step: 3
Training loss: 0.8569456338882446
Validation loss: 1.8232496861488587

Epoch: 5| Step: 4
Training loss: 0.7392919063568115
Validation loss: 1.8516586096056047

Epoch: 5| Step: 5
Training loss: 1.0135462284088135
Validation loss: 1.8840475697671213

Epoch: 5| Step: 6
Training loss: 0.8076142072677612
Validation loss: 1.8477216882090415

Epoch: 5| Step: 7
Training loss: 1.0908520221710205
Validation loss: 1.8613313731326853

Epoch: 5| Step: 8
Training loss: 0.7211747765541077
Validation loss: 1.8907836996099001

Epoch: 5| Step: 9
Training loss: 0.9359973669052124
Validation loss: 1.8209688740391885

Epoch: 5| Step: 10
Training loss: 0.7319506406784058
Validation loss: 1.880358572929136

Epoch: 668| Step: 0
Training loss: 0.6565811634063721
Validation loss: 1.8650595180449947

Epoch: 5| Step: 1
Training loss: 0.7062614560127258
Validation loss: 1.88411622406334

Epoch: 5| Step: 2
Training loss: 0.7252174615859985
Validation loss: 1.8473058221160725

Epoch: 5| Step: 3
Training loss: 1.3479678630828857
Validation loss: 1.843541508079857

Epoch: 5| Step: 4
Training loss: 0.7945932745933533
Validation loss: 1.8497872326963691

Epoch: 5| Step: 5
Training loss: 0.7942284345626831
Validation loss: 1.8608738401884675

Epoch: 5| Step: 6
Training loss: 1.0547711849212646
Validation loss: 1.8432579655801096

Epoch: 5| Step: 7
Training loss: 0.8865043520927429
Validation loss: 1.8954555244855984

Epoch: 5| Step: 8
Training loss: 0.41805464029312134
Validation loss: 1.8419943548017932

Epoch: 5| Step: 9
Training loss: 1.0539041757583618
Validation loss: 1.8471509538671023

Epoch: 5| Step: 10
Training loss: 1.0266309976577759
Validation loss: 1.8529767503020584

Epoch: 669| Step: 0
Training loss: 0.8611149787902832
Validation loss: 1.8473556067353936

Epoch: 5| Step: 1
Training loss: 1.0287129878997803
Validation loss: 1.8530549599278359

Epoch: 5| Step: 2
Training loss: 0.9092462658882141
Validation loss: 1.8737194307388798

Epoch: 5| Step: 3
Training loss: 0.9069689512252808
Validation loss: 1.882780990292949

Epoch: 5| Step: 4
Training loss: 0.5092723965644836
Validation loss: 1.86390487353007

Epoch: 5| Step: 5
Training loss: 1.1281896829605103
Validation loss: 1.842433544897264

Epoch: 5| Step: 6
Training loss: 0.6896029114723206
Validation loss: 1.8325711488723755

Epoch: 5| Step: 7
Training loss: 0.9307845234870911
Validation loss: 1.8299295210069226

Epoch: 5| Step: 8
Training loss: 1.1408888101577759
Validation loss: 1.8433381767683132

Epoch: 5| Step: 9
Training loss: 0.4347122609615326
Validation loss: 1.8447455103679369

Epoch: 5| Step: 10
Training loss: 0.6474922299385071
Validation loss: 1.8276930034801524

Epoch: 670| Step: 0
Training loss: 0.5875343084335327
Validation loss: 1.8723727323675667

Epoch: 5| Step: 1
Training loss: 0.7125333547592163
Validation loss: 1.909592137541822

Epoch: 5| Step: 2
Training loss: 0.9233728647232056
Validation loss: 1.8063490403595792

Epoch: 5| Step: 3
Training loss: 0.7467598915100098
Validation loss: 1.7621517912034066

Epoch: 5| Step: 4
Training loss: 1.0580722093582153
Validation loss: 1.8638912657255768

Epoch: 5| Step: 5
Training loss: 0.5504436492919922
Validation loss: 1.7833634704671881

Epoch: 5| Step: 6
Training loss: 0.7750174403190613
Validation loss: 1.909748952875855

Epoch: 5| Step: 7
Training loss: 1.141531229019165
Validation loss: 1.9084942674124112

Epoch: 5| Step: 8
Training loss: 0.8877598643302917
Validation loss: 1.8806269117580947

Epoch: 5| Step: 9
Training loss: 0.826382040977478
Validation loss: 1.9230431561828942

Epoch: 5| Step: 10
Training loss: 1.0213490724563599
Validation loss: 1.8334437339536604

Epoch: 671| Step: 0
Training loss: 0.5887108445167542
Validation loss: 1.8845933842402633

Epoch: 5| Step: 1
Training loss: 0.4484991431236267
Validation loss: 1.8899001857285858

Epoch: 5| Step: 2
Training loss: 0.5876775979995728
Validation loss: 1.8679532453578005

Epoch: 5| Step: 3
Training loss: 0.966387927532196
Validation loss: 1.9048866136099702

Epoch: 5| Step: 4
Training loss: 0.8668664693832397
Validation loss: 1.8458062743627897

Epoch: 5| Step: 5
Training loss: 1.247479796409607
Validation loss: 1.8088074448288127

Epoch: 5| Step: 6
Training loss: 1.1449801921844482
Validation loss: 1.8487452947965233

Epoch: 5| Step: 7
Training loss: 0.6710072755813599
Validation loss: 1.8282210980692217

Epoch: 5| Step: 8
Training loss: 0.9914796948432922
Validation loss: 1.8423721239130983

Epoch: 5| Step: 9
Training loss: 1.204063057899475
Validation loss: 1.9056436733532978

Epoch: 5| Step: 10
Training loss: 0.4901564121246338
Validation loss: 1.8224092401484007

Epoch: 672| Step: 0
Training loss: 0.8293660879135132
Validation loss: 1.80465869749746

Epoch: 5| Step: 1
Training loss: 0.7278674244880676
Validation loss: 1.8597321125768846

Epoch: 5| Step: 2
Training loss: 0.7533334493637085
Validation loss: 1.8571313978523336

Epoch: 5| Step: 3
Training loss: 1.1788994073867798
Validation loss: 1.8790436637017034

Epoch: 5| Step: 4
Training loss: 0.6661502122879028
Validation loss: 1.860674047982821

Epoch: 5| Step: 5
Training loss: 0.7946401834487915
Validation loss: 1.914758200286537

Epoch: 5| Step: 6
Training loss: 0.9172323942184448
Validation loss: 1.9101527749851186

Epoch: 5| Step: 7
Training loss: 1.4328564405441284
Validation loss: 1.8890984173743957

Epoch: 5| Step: 8
Training loss: 0.8470993041992188
Validation loss: 1.8644650918181225

Epoch: 5| Step: 9
Training loss: 0.6400607228279114
Validation loss: 1.8458045554417435

Epoch: 5| Step: 10
Training loss: 0.48265698552131653
Validation loss: 1.8887192433880222

Epoch: 673| Step: 0
Training loss: 0.7893365025520325
Validation loss: 1.8238655905569754

Epoch: 5| Step: 1
Training loss: 0.7560580968856812
Validation loss: 1.8155952038303498

Epoch: 5| Step: 2
Training loss: 0.6175610423088074
Validation loss: 1.8592649454711585

Epoch: 5| Step: 3
Training loss: 1.110175371170044
Validation loss: 1.880541145160634

Epoch: 5| Step: 4
Training loss: 0.9286172986030579
Validation loss: 1.809866471957135

Epoch: 5| Step: 5
Training loss: 1.0314760208129883
Validation loss: 1.9086429560056297

Epoch: 5| Step: 6
Training loss: 0.6296820640563965
Validation loss: 1.8487552032675794

Epoch: 5| Step: 7
Training loss: 0.9460604786872864
Validation loss: 1.860423457237982

Epoch: 5| Step: 8
Training loss: 0.7198979258537292
Validation loss: 1.8440807006692375

Epoch: 5| Step: 9
Training loss: 0.7281363606452942
Validation loss: 1.824440683087995

Epoch: 5| Step: 10
Training loss: 1.0617263317108154
Validation loss: 1.9233410127701298

Epoch: 674| Step: 0
Training loss: 0.7113945484161377
Validation loss: 1.9020172049922328

Epoch: 5| Step: 1
Training loss: 1.058046579360962
Validation loss: 1.899277087180845

Epoch: 5| Step: 2
Training loss: 0.6172311305999756
Validation loss: 1.845255652422546

Epoch: 5| Step: 3
Training loss: 1.0526933670043945
Validation loss: 1.9063630821884319

Epoch: 5| Step: 4
Training loss: 1.0195143222808838
Validation loss: 1.9167934284415296

Epoch: 5| Step: 5
Training loss: 0.7188240885734558
Validation loss: 1.8783386599633

Epoch: 5| Step: 6
Training loss: 0.7543851137161255
Validation loss: 1.8785270708863453

Epoch: 5| Step: 7
Training loss: 0.8179615139961243
Validation loss: 1.8575643031827864

Epoch: 5| Step: 8
Training loss: 0.5778541564941406
Validation loss: 1.8728692429040068

Epoch: 5| Step: 9
Training loss: 0.8200761675834656
Validation loss: 1.863706523372281

Epoch: 5| Step: 10
Training loss: 1.0372267961502075
Validation loss: 1.818790974155549

Epoch: 675| Step: 0
Training loss: 0.9955501556396484
Validation loss: 1.8317818526298768

Epoch: 5| Step: 1
Training loss: 0.9816484451293945
Validation loss: 1.881484373923271

Epoch: 5| Step: 2
Training loss: 0.5600638389587402
Validation loss: 1.8773869596501833

Epoch: 5| Step: 3
Training loss: 0.5586625337600708
Validation loss: 1.8183325106097805

Epoch: 5| Step: 4
Training loss: 1.0197948217391968
Validation loss: 1.8403525224295996

Epoch: 5| Step: 5
Training loss: 1.221880555152893
Validation loss: 1.862618048985799

Epoch: 5| Step: 6
Training loss: 1.0598280429840088
Validation loss: 1.8668970292614353

Epoch: 5| Step: 7
Training loss: 0.7385331392288208
Validation loss: 1.819654219893999

Epoch: 5| Step: 8
Training loss: 0.7261749505996704
Validation loss: 1.8426216904835035

Epoch: 5| Step: 9
Training loss: 0.5794010162353516
Validation loss: 1.8373051945881178

Epoch: 5| Step: 10
Training loss: 0.9305960536003113
Validation loss: 1.8483790107952651

Epoch: 676| Step: 0
Training loss: 0.6810833811759949
Validation loss: 1.8915779334242626

Epoch: 5| Step: 1
Training loss: 0.7857327461242676
Validation loss: 1.8683143687504593

Epoch: 5| Step: 2
Training loss: 0.44316011667251587
Validation loss: 1.8780525897138862

Epoch: 5| Step: 3
Training loss: 1.2007596492767334
Validation loss: 1.874442103088543

Epoch: 5| Step: 4
Training loss: 0.952612578868866
Validation loss: 1.8516486690890404

Epoch: 5| Step: 5
Training loss: 0.7502763867378235
Validation loss: 1.8259505943585468

Epoch: 5| Step: 6
Training loss: 0.5717699527740479
Validation loss: 1.8730772656779135

Epoch: 5| Step: 7
Training loss: 0.9399527311325073
Validation loss: 1.8800656744228896

Epoch: 5| Step: 8
Training loss: 0.7399678230285645
Validation loss: 1.8762802026605094

Epoch: 5| Step: 9
Training loss: 1.1601918935775757
Validation loss: 1.8659905900237381

Epoch: 5| Step: 10
Training loss: 0.8653676509857178
Validation loss: 1.913423297225788

Epoch: 677| Step: 0
Training loss: 1.0363892316818237
Validation loss: 1.8720218930193173

Epoch: 5| Step: 1
Training loss: 1.3371747732162476
Validation loss: 1.8443108527891097

Epoch: 5| Step: 2
Training loss: 0.7676573991775513
Validation loss: 1.8478129345883605

Epoch: 5| Step: 3
Training loss: 0.5790970921516418
Validation loss: 1.9464005013947845

Epoch: 5| Step: 4
Training loss: 0.6088914275169373
Validation loss: 1.774652478515461

Epoch: 5| Step: 5
Training loss: 0.6807219982147217
Validation loss: 1.8547989822203113

Epoch: 5| Step: 6
Training loss: 0.8641732335090637
Validation loss: 1.8489510884848974

Epoch: 5| Step: 7
Training loss: 0.9445363879203796
Validation loss: 1.854492623318908

Epoch: 5| Step: 8
Training loss: 0.65883868932724
Validation loss: 1.8194863616779287

Epoch: 5| Step: 9
Training loss: 1.1524217128753662
Validation loss: 1.832871635754903

Epoch: 5| Step: 10
Training loss: 0.5052704811096191
Validation loss: 1.877386208503477

Epoch: 678| Step: 0
Training loss: 0.5763090252876282
Validation loss: 1.817645461328568

Epoch: 5| Step: 1
Training loss: 1.0093214511871338
Validation loss: 1.8455488117792274

Epoch: 5| Step: 2
Training loss: 0.7556830644607544
Validation loss: 1.8491831235988165

Epoch: 5| Step: 3
Training loss: 1.02897047996521
Validation loss: 1.849138629051947

Epoch: 5| Step: 4
Training loss: 0.6001663208007812
Validation loss: 1.8883662262270529

Epoch: 5| Step: 5
Training loss: 0.62610924243927
Validation loss: 1.8587487154109503

Epoch: 5| Step: 6
Training loss: 0.9619238972663879
Validation loss: 1.8538082081784484

Epoch: 5| Step: 7
Training loss: 0.5572356581687927
Validation loss: 1.9026760298718688

Epoch: 5| Step: 8
Training loss: 0.8955180048942566
Validation loss: 1.8537751256778676

Epoch: 5| Step: 9
Training loss: 1.0610475540161133
Validation loss: 1.8094474423316218

Epoch: 5| Step: 10
Training loss: 1.0029873847961426
Validation loss: 1.8369515557442941

Epoch: 679| Step: 0
Training loss: 1.0805022716522217
Validation loss: 1.8220913705005441

Epoch: 5| Step: 1
Training loss: 0.5521942377090454
Validation loss: 1.872850469363633

Epoch: 5| Step: 2
Training loss: 0.5490996837615967
Validation loss: 1.9072953424146097

Epoch: 5| Step: 3
Training loss: 1.2086260318756104
Validation loss: 1.8912183289886804

Epoch: 5| Step: 4
Training loss: 0.673835813999176
Validation loss: 1.85485375952977

Epoch: 5| Step: 5
Training loss: 0.9784447550773621
Validation loss: 1.8753295508764123

Epoch: 5| Step: 6
Training loss: 0.7359761595726013
Validation loss: 1.878200807879048

Epoch: 5| Step: 7
Training loss: 0.7552791833877563
Validation loss: 1.8753049206990067

Epoch: 5| Step: 8
Training loss: 0.6135013699531555
Validation loss: 1.8597015052713373

Epoch: 5| Step: 9
Training loss: 0.9917442202568054
Validation loss: 1.871941977931607

Epoch: 5| Step: 10
Training loss: 0.9272326231002808
Validation loss: 1.8444081480785082

Epoch: 680| Step: 0
Training loss: 1.2158864736557007
Validation loss: 1.8687035934899443

Epoch: 5| Step: 1
Training loss: 0.557214617729187
Validation loss: 1.8956012302829373

Epoch: 5| Step: 2
Training loss: 0.921276867389679
Validation loss: 1.8309154715589298

Epoch: 5| Step: 3
Training loss: 0.4347274899482727
Validation loss: 1.804189387188163

Epoch: 5| Step: 4
Training loss: 0.7155969738960266
Validation loss: 1.8696126104683004

Epoch: 5| Step: 5
Training loss: 0.8992490768432617
Validation loss: 1.8406423317488803

Epoch: 5| Step: 6
Training loss: 1.198403000831604
Validation loss: 1.8308384713306223

Epoch: 5| Step: 7
Training loss: 0.5814878344535828
Validation loss: 1.8161486541071246

Epoch: 5| Step: 8
Training loss: 0.4199886918067932
Validation loss: 1.8319143749052478

Epoch: 5| Step: 9
Training loss: 0.7103254199028015
Validation loss: 1.844113540905778

Epoch: 5| Step: 10
Training loss: 0.9053067564964294
Validation loss: 1.8461598542428785

Epoch: 681| Step: 0
Training loss: 0.7717146873474121
Validation loss: 1.8874288015468146

Epoch: 5| Step: 1
Training loss: 0.6471268534660339
Validation loss: 1.8450294438228811

Epoch: 5| Step: 2
Training loss: 1.223404884338379
Validation loss: 1.8631327075342978

Epoch: 5| Step: 3
Training loss: 0.9905573129653931
Validation loss: 1.8523278069752518

Epoch: 5| Step: 4
Training loss: 0.8495109677314758
Validation loss: 1.8553570162865423

Epoch: 5| Step: 5
Training loss: 1.1795905828475952
Validation loss: 1.814022224436524

Epoch: 5| Step: 6
Training loss: 0.6356202960014343
Validation loss: 1.8554730902435959

Epoch: 5| Step: 7
Training loss: 0.7202829122543335
Validation loss: 1.8511756761099702

Epoch: 5| Step: 8
Training loss: 0.6962268948554993
Validation loss: 1.848699523556617

Epoch: 5| Step: 9
Training loss: 0.6913301348686218
Validation loss: 1.8412488788686774

Epoch: 5| Step: 10
Training loss: 0.538053035736084
Validation loss: 1.866605725339664

Epoch: 682| Step: 0
Training loss: 1.065308928489685
Validation loss: 1.8054718868706816

Epoch: 5| Step: 1
Training loss: 0.7536226511001587
Validation loss: 1.8471889470213203

Epoch: 5| Step: 2
Training loss: 1.2670071125030518
Validation loss: 1.8387058114492765

Epoch: 5| Step: 3
Training loss: 0.8323712348937988
Validation loss: 1.8799021218412666

Epoch: 5| Step: 4
Training loss: 0.8601621389389038
Validation loss: 1.8530965466653146

Epoch: 5| Step: 5
Training loss: 0.7353433966636658
Validation loss: 1.8369335128415016

Epoch: 5| Step: 6
Training loss: 0.5762938857078552
Validation loss: 1.8665447965745003

Epoch: 5| Step: 7
Training loss: 0.48498445749282837
Validation loss: 1.832824812140516

Epoch: 5| Step: 8
Training loss: 0.7634066343307495
Validation loss: 1.9448284231206423

Epoch: 5| Step: 9
Training loss: 0.8503828048706055
Validation loss: 1.8492532596793225

Epoch: 5| Step: 10
Training loss: 0.7046249508857727
Validation loss: 1.8815540434211813

Epoch: 683| Step: 0
Training loss: 0.6485621929168701
Validation loss: 1.8615003888325026

Epoch: 5| Step: 1
Training loss: 1.0632097721099854
Validation loss: 1.8980390666633524

Epoch: 5| Step: 2
Training loss: 0.8735825419425964
Validation loss: 1.8073883832141917

Epoch: 5| Step: 3
Training loss: 1.1041724681854248
Validation loss: 1.8764910800482637

Epoch: 5| Step: 4
Training loss: 0.8424968719482422
Validation loss: 1.8842601622304609

Epoch: 5| Step: 5
Training loss: 0.7207452654838562
Validation loss: 1.8645100683294318

Epoch: 5| Step: 6
Training loss: 0.711682915687561
Validation loss: 1.8303595460871214

Epoch: 5| Step: 7
Training loss: 0.6325178742408752
Validation loss: 1.8374704007179505

Epoch: 5| Step: 8
Training loss: 0.6283441781997681
Validation loss: 1.8872492467203448

Epoch: 5| Step: 9
Training loss: 1.0474544763565063
Validation loss: 1.8720329756377845

Epoch: 5| Step: 10
Training loss: 0.5998356938362122
Validation loss: 1.872181459139752

Epoch: 684| Step: 0
Training loss: 0.6721123456954956
Validation loss: 1.8418995282983268

Epoch: 5| Step: 1
Training loss: 0.720015287399292
Validation loss: 1.851225822202621

Epoch: 5| Step: 2
Training loss: 0.6680359244346619
Validation loss: 1.8326804996818624

Epoch: 5| Step: 3
Training loss: 0.7314653396606445
Validation loss: 1.8474057874371927

Epoch: 5| Step: 4
Training loss: 1.13117253780365
Validation loss: 1.8222182745574622

Epoch: 5| Step: 5
Training loss: 0.7543227076530457
Validation loss: 1.852710525194804

Epoch: 5| Step: 6
Training loss: 0.4934159219264984
Validation loss: 1.8709320765669628

Epoch: 5| Step: 7
Training loss: 0.5229696035385132
Validation loss: 1.9189685211386731

Epoch: 5| Step: 8
Training loss: 0.6265523433685303
Validation loss: 1.884854934548819

Epoch: 5| Step: 9
Training loss: 1.201150894165039
Validation loss: 1.8686950232392998

Epoch: 5| Step: 10
Training loss: 1.322494387626648
Validation loss: 1.8593549779666367

Epoch: 685| Step: 0
Training loss: 1.2412083148956299
Validation loss: 1.8142742341564548

Epoch: 5| Step: 1
Training loss: 0.9495828747749329
Validation loss: 1.8968528701413063

Epoch: 5| Step: 2
Training loss: 0.7479447722434998
Validation loss: 1.8668212839352187

Epoch: 5| Step: 3
Training loss: 0.4133075177669525
Validation loss: 1.7606302858680807

Epoch: 5| Step: 4
Training loss: 0.6734363436698914
Validation loss: 1.8594118574614167

Epoch: 5| Step: 5
Training loss: 0.4887591004371643
Validation loss: 1.8445061047871907

Epoch: 5| Step: 6
Training loss: 0.9610910415649414
Validation loss: 1.8303721643263293

Epoch: 5| Step: 7
Training loss: 0.9799246788024902
Validation loss: 1.8774176425831293

Epoch: 5| Step: 8
Training loss: 0.7855006456375122
Validation loss: 1.8019805736439203

Epoch: 5| Step: 9
Training loss: 0.8485913276672363
Validation loss: 1.830986334431556

Epoch: 5| Step: 10
Training loss: 0.9408900737762451
Validation loss: 1.8862047092888945

Epoch: 686| Step: 0
Training loss: 0.6501142382621765
Validation loss: 1.8342842568633377

Epoch: 5| Step: 1
Training loss: 0.721068263053894
Validation loss: 1.876819977196314

Epoch: 5| Step: 2
Training loss: 0.7491812109947205
Validation loss: 1.8421454455262871

Epoch: 5| Step: 3
Training loss: 0.6730015873908997
Validation loss: 1.8485312743853497

Epoch: 5| Step: 4
Training loss: 1.0299968719482422
Validation loss: 1.8309724356538506

Epoch: 5| Step: 5
Training loss: 1.0432630777359009
Validation loss: 1.844375620606125

Epoch: 5| Step: 6
Training loss: 1.141373634338379
Validation loss: 1.8224263524496427

Epoch: 5| Step: 7
Training loss: 0.5070762634277344
Validation loss: 1.8311026109162198

Epoch: 5| Step: 8
Training loss: 0.3972390294075012
Validation loss: 1.8095771439613835

Epoch: 5| Step: 9
Training loss: 0.978259265422821
Validation loss: 1.8547983169555664

Epoch: 5| Step: 10
Training loss: 1.3057820796966553
Validation loss: 1.894548144391788

Epoch: 687| Step: 0
Training loss: 1.1087372303009033
Validation loss: 1.7966789430187595

Epoch: 5| Step: 1
Training loss: 0.951316237449646
Validation loss: 1.8736261219106696

Epoch: 5| Step: 2
Training loss: 0.7488670349121094
Validation loss: 1.8620409580969042

Epoch: 5| Step: 3
Training loss: 0.7823100090026855
Validation loss: 1.8590825039853331

Epoch: 5| Step: 4
Training loss: 0.7113669514656067
Validation loss: 1.8313874403635662

Epoch: 5| Step: 5
Training loss: 0.9118372201919556
Validation loss: 1.8610536372789772

Epoch: 5| Step: 6
Training loss: 0.4412369132041931
Validation loss: 1.8656196260965

Epoch: 5| Step: 7
Training loss: 0.7294493317604065
Validation loss: 1.8750854922879128

Epoch: 5| Step: 8
Training loss: 0.590597927570343
Validation loss: 1.9181953976231236

Epoch: 5| Step: 9
Training loss: 0.7391109466552734
Validation loss: 1.8179931409897343

Epoch: 5| Step: 10
Training loss: 1.0059514045715332
Validation loss: 1.8724850839184177

Epoch: 688| Step: 0
Training loss: 0.8487597703933716
Validation loss: 1.8773265192585606

Epoch: 5| Step: 1
Training loss: 0.5831789374351501
Validation loss: 1.8259402090503323

Epoch: 5| Step: 2
Training loss: 0.5561807155609131
Validation loss: 1.8908602447919949

Epoch: 5| Step: 3
Training loss: 0.7712394595146179
Validation loss: 1.8335068456588253

Epoch: 5| Step: 4
Training loss: 0.8087831735610962
Validation loss: 1.8056047167829288

Epoch: 5| Step: 5
Training loss: 0.6704114675521851
Validation loss: 1.8325186980667936

Epoch: 5| Step: 6
Training loss: 1.0364590883255005
Validation loss: 1.8538320525999992

Epoch: 5| Step: 7
Training loss: 1.1214725971221924
Validation loss: 1.8415067913711711

Epoch: 5| Step: 8
Training loss: 1.2222591638565063
Validation loss: 1.8394764110606203

Epoch: 5| Step: 9
Training loss: 0.42623311281204224
Validation loss: 1.8714908758799236

Epoch: 5| Step: 10
Training loss: 0.6327870488166809
Validation loss: 1.7980214190739456

Epoch: 689| Step: 0
Training loss: 0.4840930998325348
Validation loss: 1.800490358824371

Epoch: 5| Step: 1
Training loss: 0.7627381682395935
Validation loss: 1.875995046348982

Epoch: 5| Step: 2
Training loss: 0.9788085222244263
Validation loss: 1.8838963175332675

Epoch: 5| Step: 3
Training loss: 0.7654191851615906
Validation loss: 1.90933193186278

Epoch: 5| Step: 4
Training loss: 1.2846946716308594
Validation loss: 1.8406876197425268

Epoch: 5| Step: 5
Training loss: 0.8457285761833191
Validation loss: 1.9083282819358252

Epoch: 5| Step: 6
Training loss: 0.8513156771659851
Validation loss: 1.8564722396994149

Epoch: 5| Step: 7
Training loss: 0.9474183917045593
Validation loss: 1.8665357879413071

Epoch: 5| Step: 8
Training loss: 0.7688753008842468
Validation loss: 1.8655716488438268

Epoch: 5| Step: 9
Training loss: 0.6807743906974792
Validation loss: 1.8687331240664247

Epoch: 5| Step: 10
Training loss: 0.589871883392334
Validation loss: 1.8739443158590665

Epoch: 690| Step: 0
Training loss: 1.0005875825881958
Validation loss: 1.8385026813835226

Epoch: 5| Step: 1
Training loss: 0.7547017931938171
Validation loss: 1.8629236528950353

Epoch: 5| Step: 2
Training loss: 0.5365272164344788
Validation loss: 1.8174029832245202

Epoch: 5| Step: 3
Training loss: 0.5592543482780457
Validation loss: 1.882335707705508

Epoch: 5| Step: 4
Training loss: 0.964737057685852
Validation loss: 1.851367360802107

Epoch: 5| Step: 5
Training loss: 0.7300556898117065
Validation loss: 1.8864545270960817

Epoch: 5| Step: 6
Training loss: 0.4398774206638336
Validation loss: 1.871387291980046

Epoch: 5| Step: 7
Training loss: 0.8100658655166626
Validation loss: 1.8643607439533356

Epoch: 5| Step: 8
Training loss: 0.7343643307685852
Validation loss: 1.8492755197709607

Epoch: 5| Step: 9
Training loss: 1.1418952941894531
Validation loss: 1.9056509047426202

Epoch: 5| Step: 10
Training loss: 0.9836621880531311
Validation loss: 1.8844063948559504

Epoch: 691| Step: 0
Training loss: 1.0679014921188354
Validation loss: 1.8347125348224436

Epoch: 5| Step: 1
Training loss: 0.5395230054855347
Validation loss: 1.836029242443782

Epoch: 5| Step: 2
Training loss: 1.0758079290390015
Validation loss: 1.8694908119017077

Epoch: 5| Step: 3
Training loss: 0.9168817400932312
Validation loss: 1.8561950793830297

Epoch: 5| Step: 4
Training loss: 0.8085993528366089
Validation loss: 1.9012934751408075

Epoch: 5| Step: 5
Training loss: 0.8227475881576538
Validation loss: 1.8988905209366993

Epoch: 5| Step: 6
Training loss: 0.7645152807235718
Validation loss: 1.8823174404841598

Epoch: 5| Step: 7
Training loss: 0.658523678779602
Validation loss: 1.88921703574478

Epoch: 5| Step: 8
Training loss: 0.9029668569564819
Validation loss: 1.8361104021790207

Epoch: 5| Step: 9
Training loss: 0.7110825777053833
Validation loss: 1.8540118176450011

Epoch: 5| Step: 10
Training loss: 0.6504117250442505
Validation loss: 1.8473273631065124

Epoch: 692| Step: 0
Training loss: 0.9695255160331726
Validation loss: 1.8279997174457838

Epoch: 5| Step: 1
Training loss: 0.7179383635520935
Validation loss: 1.8514335450305734

Epoch: 5| Step: 2
Training loss: 0.44710150361061096
Validation loss: 1.8335743847713675

Epoch: 5| Step: 3
Training loss: 0.567177414894104
Validation loss: 1.9261731473348473

Epoch: 5| Step: 4
Training loss: 0.9026051759719849
Validation loss: 1.8814446515934442

Epoch: 5| Step: 5
Training loss: 0.9275057911872864
Validation loss: 1.8033805290857952

Epoch: 5| Step: 6
Training loss: 0.7229313254356384
Validation loss: 1.8788589777485016

Epoch: 5| Step: 7
Training loss: 0.958507239818573
Validation loss: 1.8345148127566102

Epoch: 5| Step: 8
Training loss: 1.0772705078125
Validation loss: 1.8690290938141525

Epoch: 5| Step: 9
Training loss: 0.6763783097267151
Validation loss: 1.844656890438449

Epoch: 5| Step: 10
Training loss: 0.790243923664093
Validation loss: 1.8606612554160498

Epoch: 693| Step: 0
Training loss: 0.651053786277771
Validation loss: 1.8299185281158776

Epoch: 5| Step: 1
Training loss: 0.6165920495986938
Validation loss: 1.8542130941985755

Epoch: 5| Step: 2
Training loss: 0.8631095886230469
Validation loss: 1.8325119121100313

Epoch: 5| Step: 3
Training loss: 1.1077255010604858
Validation loss: 1.8479929547156058

Epoch: 5| Step: 4
Training loss: 0.7182196974754333
Validation loss: 1.8134960089960406

Epoch: 5| Step: 5
Training loss: 1.0269262790679932
Validation loss: 1.8799199186345583

Epoch: 5| Step: 6
Training loss: 0.46867308020591736
Validation loss: 1.8481581634090793

Epoch: 5| Step: 7
Training loss: 0.5254665017127991
Validation loss: 1.9392506204625612

Epoch: 5| Step: 8
Training loss: 0.8672899007797241
Validation loss: 1.8437464993487123

Epoch: 5| Step: 9
Training loss: 0.867973804473877
Validation loss: 1.85547806883371

Epoch: 5| Step: 10
Training loss: 0.784296452999115
Validation loss: 1.824787324474704

Epoch: 694| Step: 0
Training loss: 0.8249630928039551
Validation loss: 1.8488011924169396

Epoch: 5| Step: 1
Training loss: 0.9684794545173645
Validation loss: 1.8717388491476736

Epoch: 5| Step: 2
Training loss: 0.9946036338806152
Validation loss: 1.8127879968253515

Epoch: 5| Step: 3
Training loss: 0.4940548539161682
Validation loss: 1.8078355007274176

Epoch: 5| Step: 4
Training loss: 0.6266123652458191
Validation loss: 1.8743223733799432

Epoch: 5| Step: 5
Training loss: 0.3879443109035492
Validation loss: 1.860854855147741

Epoch: 5| Step: 6
Training loss: 0.6047478318214417
Validation loss: 1.8489071258934595

Epoch: 5| Step: 7
Training loss: 0.887738823890686
Validation loss: 1.8825356075840611

Epoch: 5| Step: 8
Training loss: 0.9622554779052734
Validation loss: 1.917022350013897

Epoch: 5| Step: 9
Training loss: 0.8273841142654419
Validation loss: 1.8833434069028465

Epoch: 5| Step: 10
Training loss: 1.0862317085266113
Validation loss: 1.8804402120651738

Epoch: 695| Step: 0
Training loss: 0.9475517272949219
Validation loss: 1.8871777108920518

Epoch: 5| Step: 1
Training loss: 0.6739705204963684
Validation loss: 1.9086043219412527

Epoch: 5| Step: 2
Training loss: 1.1007800102233887
Validation loss: 1.9099184056764007

Epoch: 5| Step: 3
Training loss: 0.530928909778595
Validation loss: 1.8856870076989616

Epoch: 5| Step: 4
Training loss: 0.4507569372653961
Validation loss: 1.8609703561311126

Epoch: 5| Step: 5
Training loss: 0.9696725606918335
Validation loss: 1.7905346744803972

Epoch: 5| Step: 6
Training loss: 1.1699997186660767
Validation loss: 1.8208054393850348

Epoch: 5| Step: 7
Training loss: 0.6353791356086731
Validation loss: 1.8205943812606156

Epoch: 5| Step: 8
Training loss: 0.49867573380470276
Validation loss: 1.8077200176895305

Epoch: 5| Step: 9
Training loss: 1.05405592918396
Validation loss: 1.8539508670888922

Epoch: 5| Step: 10
Training loss: 0.9614669680595398
Validation loss: 1.8111170222682338

Epoch: 696| Step: 0
Training loss: 0.7524094581604004
Validation loss: 1.8123158152385423

Epoch: 5| Step: 1
Training loss: 0.5215991735458374
Validation loss: 1.8282807642413723

Epoch: 5| Step: 2
Training loss: 0.8635320663452148
Validation loss: 1.8775899538429834

Epoch: 5| Step: 3
Training loss: 0.8470332026481628
Validation loss: 1.8624104517762379

Epoch: 5| Step: 4
Training loss: 0.595075249671936
Validation loss: 1.8505010745858634

Epoch: 5| Step: 5
Training loss: 0.6163046360015869
Validation loss: 1.9141960285043205

Epoch: 5| Step: 6
Training loss: 0.819061279296875
Validation loss: 1.91327541617937

Epoch: 5| Step: 7
Training loss: 1.0244214534759521
Validation loss: 1.9198018632909304

Epoch: 5| Step: 8
Training loss: 0.7120928764343262
Validation loss: 1.9186371962229412

Epoch: 5| Step: 9
Training loss: 1.0662672519683838
Validation loss: 1.8923053920909922

Epoch: 5| Step: 10
Training loss: 0.7331186532974243
Validation loss: 1.832627878394178

Epoch: 697| Step: 0
Training loss: 1.1709415912628174
Validation loss: 1.837574480682291

Epoch: 5| Step: 1
Training loss: 1.0042967796325684
Validation loss: 1.785588409311028

Epoch: 5| Step: 2
Training loss: 0.7885817289352417
Validation loss: 1.7915409739299486

Epoch: 5| Step: 3
Training loss: 1.054445505142212
Validation loss: 1.8017519366356634

Epoch: 5| Step: 4
Training loss: 0.5425690412521362
Validation loss: 1.8464439197253155

Epoch: 5| Step: 5
Training loss: 0.5787296891212463
Validation loss: 1.8402005780127741

Epoch: 5| Step: 6
Training loss: 0.7105884552001953
Validation loss: 1.7965563933054607

Epoch: 5| Step: 7
Training loss: 0.5676971673965454
Validation loss: 1.8709855951288694

Epoch: 5| Step: 8
Training loss: 0.8203176259994507
Validation loss: 1.878508997219865

Epoch: 5| Step: 9
Training loss: 0.6635964512825012
Validation loss: 1.9019160270690918

Epoch: 5| Step: 10
Training loss: 0.8077651858329773
Validation loss: 1.8518282867247058

Epoch: 698| Step: 0
Training loss: 0.5727627873420715
Validation loss: 1.8246668513103197

Epoch: 5| Step: 1
Training loss: 0.549375593662262
Validation loss: 1.8886931865446028

Epoch: 5| Step: 2
Training loss: 0.6714872121810913
Validation loss: 1.9245997987767702

Epoch: 5| Step: 3
Training loss: 0.6260625720024109
Validation loss: 1.9443173664872364

Epoch: 5| Step: 4
Training loss: 0.6191343069076538
Validation loss: 1.8855001772603681

Epoch: 5| Step: 5
Training loss: 0.7688928842544556
Validation loss: 1.8742880295681696

Epoch: 5| Step: 6
Training loss: 0.8658996820449829
Validation loss: 1.9072405215232604

Epoch: 5| Step: 7
Training loss: 0.6169650554656982
Validation loss: 1.863873238204628

Epoch: 5| Step: 8
Training loss: 0.8917245864868164
Validation loss: 1.8708257418806835

Epoch: 5| Step: 9
Training loss: 0.738283634185791
Validation loss: 1.8424507751259753

Epoch: 5| Step: 10
Training loss: 1.641517996788025
Validation loss: 1.8410595854123433

Epoch: 699| Step: 0
Training loss: 0.6580654382705688
Validation loss: 1.8251091100836312

Epoch: 5| Step: 1
Training loss: 1.1033101081848145
Validation loss: 1.8676575255650345

Epoch: 5| Step: 2
Training loss: 0.8555378913879395
Validation loss: 1.8524885856977074

Epoch: 5| Step: 3
Training loss: 0.5811456441879272
Validation loss: 1.9039138029980403

Epoch: 5| Step: 4
Training loss: 0.9612321853637695
Validation loss: 1.8277367443166754

Epoch: 5| Step: 5
Training loss: 0.6833909749984741
Validation loss: 1.8452203978774369

Epoch: 5| Step: 6
Training loss: 1.2677311897277832
Validation loss: 1.848273261900871

Epoch: 5| Step: 7
Training loss: 0.8834792971611023
Validation loss: 1.8123580794180594

Epoch: 5| Step: 8
Training loss: 0.6919270753860474
Validation loss: 1.8482708136240642

Epoch: 5| Step: 9
Training loss: 0.5175390839576721
Validation loss: 1.862135725636636

Epoch: 5| Step: 10
Training loss: 0.3908694386482239
Validation loss: 1.8955106248137772

Epoch: 700| Step: 0
Training loss: 0.8057852983474731
Validation loss: 1.846904835393352

Epoch: 5| Step: 1
Training loss: 0.508228063583374
Validation loss: 1.8904031015211535

Epoch: 5| Step: 2
Training loss: 0.7323287725448608
Validation loss: 1.8321511194270144

Epoch: 5| Step: 3
Training loss: 0.9168904423713684
Validation loss: 1.8462050114908526

Epoch: 5| Step: 4
Training loss: 0.6560645699501038
Validation loss: 1.8861767040785922

Epoch: 5| Step: 5
Training loss: 0.9975956082344055
Validation loss: 1.9099298920682681

Epoch: 5| Step: 6
Training loss: 0.8079785108566284
Validation loss: 1.8571462977317073

Epoch: 5| Step: 7
Training loss: 0.6819105744361877
Validation loss: 1.936618056348575

Epoch: 5| Step: 8
Training loss: 0.9662600755691528
Validation loss: 1.8442162659860426

Epoch: 5| Step: 9
Training loss: 0.631961464881897
Validation loss: 1.8343121467098114

Epoch: 5| Step: 10
Training loss: 0.5675613880157471
Validation loss: 1.8658340310537687

Epoch: 701| Step: 0
Training loss: 0.7733529806137085
Validation loss: 1.8736009020959177

Epoch: 5| Step: 1
Training loss: 0.6740333437919617
Validation loss: 1.8564970108770555

Epoch: 5| Step: 2
Training loss: 0.6467222571372986
Validation loss: 1.875436871282516

Epoch: 5| Step: 3
Training loss: 0.980604350566864
Validation loss: 1.8578927850210538

Epoch: 5| Step: 4
Training loss: 0.7910043001174927
Validation loss: 1.8399592445742698

Epoch: 5| Step: 5
Training loss: 1.0477631092071533
Validation loss: 1.8242058625785254

Epoch: 5| Step: 6
Training loss: 0.6932517290115356
Validation loss: 1.8518807195848035

Epoch: 5| Step: 7
Training loss: 0.8958002924919128
Validation loss: 1.8489850105777863

Epoch: 5| Step: 8
Training loss: 0.5687674283981323
Validation loss: 1.817404035599001

Epoch: 5| Step: 9
Training loss: 0.46349048614501953
Validation loss: 1.775267372849167

Epoch: 5| Step: 10
Training loss: 0.8712654709815979
Validation loss: 1.8527299127271097

Epoch: 702| Step: 0
Training loss: 0.7336851358413696
Validation loss: 1.7980874520476147

Epoch: 5| Step: 1
Training loss: 0.7534990310668945
Validation loss: 1.8416497066456785

Epoch: 5| Step: 2
Training loss: 0.6706916689872742
Validation loss: 1.8408048998924993

Epoch: 5| Step: 3
Training loss: 0.6435989141464233
Validation loss: 1.8297086877207602

Epoch: 5| Step: 4
Training loss: 0.3744358420372009
Validation loss: 1.8119717387742893

Epoch: 5| Step: 5
Training loss: 1.23873770236969
Validation loss: 1.8409379566869428

Epoch: 5| Step: 6
Training loss: 1.0459092855453491
Validation loss: 1.873788446508428

Epoch: 5| Step: 7
Training loss: 0.8488998413085938
Validation loss: 1.8824200989097677

Epoch: 5| Step: 8
Training loss: 0.5441002249717712
Validation loss: 1.9166864938633417

Epoch: 5| Step: 9
Training loss: 0.5872284173965454
Validation loss: 1.8377906455788562

Epoch: 5| Step: 10
Training loss: 0.9812027215957642
Validation loss: 1.8171601141652753

Epoch: 703| Step: 0
Training loss: 0.7162543535232544
Validation loss: 1.8533952313084756

Epoch: 5| Step: 1
Training loss: 0.6878763437271118
Validation loss: 1.8234235189294303

Epoch: 5| Step: 2
Training loss: 1.0601600408554077
Validation loss: 1.8644552641017462

Epoch: 5| Step: 3
Training loss: 0.9499914050102234
Validation loss: 1.8669367118548321

Epoch: 5| Step: 4
Training loss: 0.7764586210250854
Validation loss: 1.832325017580422

Epoch: 5| Step: 5
Training loss: 0.6297773122787476
Validation loss: 1.851554443759303

Epoch: 5| Step: 6
Training loss: 0.6582244634628296
Validation loss: 1.8614527461349324

Epoch: 5| Step: 7
Training loss: 0.6340121626853943
Validation loss: 1.8476907681393366

Epoch: 5| Step: 8
Training loss: 0.833088219165802
Validation loss: 1.7946959105871056

Epoch: 5| Step: 9
Training loss: 0.906607985496521
Validation loss: 1.8620336504392727

Epoch: 5| Step: 10
Training loss: 0.8175763487815857
Validation loss: 1.8869931723481865

Epoch: 704| Step: 0
Training loss: 0.8288366198539734
Validation loss: 1.8537647865151847

Epoch: 5| Step: 1
Training loss: 0.562116801738739
Validation loss: 1.8500206649944346

Epoch: 5| Step: 2
Training loss: 0.7665661573410034
Validation loss: 1.8754662493223786

Epoch: 5| Step: 3
Training loss: 0.8791211843490601
Validation loss: 1.847412855394425

Epoch: 5| Step: 4
Training loss: 0.825592041015625
Validation loss: 1.841391909507013

Epoch: 5| Step: 5
Training loss: 1.0660003423690796
Validation loss: 1.7977253006350609

Epoch: 5| Step: 6
Training loss: 0.6650902032852173
Validation loss: 1.8818935873687908

Epoch: 5| Step: 7
Training loss: 0.8001211881637573
Validation loss: 1.903308404389248

Epoch: 5| Step: 8
Training loss: 0.67672199010849
Validation loss: 1.8471919080262542

Epoch: 5| Step: 9
Training loss: 0.6894655823707581
Validation loss: 1.9219794209285448

Epoch: 5| Step: 10
Training loss: 0.7717412114143372
Validation loss: 1.8569039080732612

Epoch: 705| Step: 0
Training loss: 0.66876620054245
Validation loss: 1.8569328733669814

Epoch: 5| Step: 1
Training loss: 0.7901492714881897
Validation loss: 1.7862480430192844

Epoch: 5| Step: 2
Training loss: 0.5851716995239258
Validation loss: 1.8695653202713176

Epoch: 5| Step: 3
Training loss: 0.6372845768928528
Validation loss: 1.8426031489526071

Epoch: 5| Step: 4
Training loss: 0.8843622207641602
Validation loss: 1.8707037843683714

Epoch: 5| Step: 5
Training loss: 0.7425962686538696
Validation loss: 1.8938706972265755

Epoch: 5| Step: 6
Training loss: 0.7058277130126953
Validation loss: 1.8453645629267539

Epoch: 5| Step: 7
Training loss: 0.5888884663581848
Validation loss: 1.839953053382135

Epoch: 5| Step: 8
Training loss: 1.3073867559432983
Validation loss: 1.8922984087339012

Epoch: 5| Step: 9
Training loss: 0.7780494093894958
Validation loss: 1.854548305593511

Epoch: 5| Step: 10
Training loss: 0.8878317475318909
Validation loss: 1.9056696955875685

Epoch: 706| Step: 0
Training loss: 0.8083938360214233
Validation loss: 1.8354057368411814

Epoch: 5| Step: 1
Training loss: 0.7173274159431458
Validation loss: 1.8131577135414205

Epoch: 5| Step: 2
Training loss: 0.88367760181427
Validation loss: 1.7948948157730924

Epoch: 5| Step: 3
Training loss: 0.6180857419967651
Validation loss: 1.8176557992094307

Epoch: 5| Step: 4
Training loss: 0.43446117639541626
Validation loss: 1.7929524913910897

Epoch: 5| Step: 5
Training loss: 0.7750747799873352
Validation loss: 1.8468894484222576

Epoch: 5| Step: 6
Training loss: 0.48824343085289
Validation loss: 1.8568767181006811

Epoch: 5| Step: 7
Training loss: 0.7414234280586243
Validation loss: 1.8465033526061683

Epoch: 5| Step: 8
Training loss: 1.003086805343628
Validation loss: 1.792221778182573

Epoch: 5| Step: 9
Training loss: 1.154008150100708
Validation loss: 1.8524399085711407

Epoch: 5| Step: 10
Training loss: 0.7617124915122986
Validation loss: 1.8974362393861175

Epoch: 707| Step: 0
Training loss: 0.734084963798523
Validation loss: 1.8851730669698408

Epoch: 5| Step: 1
Training loss: 0.6264988780021667
Validation loss: 1.8966559774132186

Epoch: 5| Step: 2
Training loss: 1.0824692249298096
Validation loss: 1.8449923197428386

Epoch: 5| Step: 3
Training loss: 0.9840530157089233
Validation loss: 1.9183846237838909

Epoch: 5| Step: 4
Training loss: 0.7287454009056091
Validation loss: 1.8361686493760796

Epoch: 5| Step: 5
Training loss: 0.4668735861778259
Validation loss: 1.927613971053913

Epoch: 5| Step: 6
Training loss: 0.557334303855896
Validation loss: 1.8233921476589736

Epoch: 5| Step: 7
Training loss: 0.6255492568016052
Validation loss: 1.8291461826652609

Epoch: 5| Step: 8
Training loss: 0.6877945065498352
Validation loss: 1.8313349741761402

Epoch: 5| Step: 9
Training loss: 1.587906837463379
Validation loss: 1.906443429249589

Epoch: 5| Step: 10
Training loss: 0.4290925860404968
Validation loss: 1.8234389059005245

Epoch: 708| Step: 0
Training loss: 0.7133169770240784
Validation loss: 1.8478069830966253

Epoch: 5| Step: 1
Training loss: 0.7480587959289551
Validation loss: 1.814999634219754

Epoch: 5| Step: 2
Training loss: 0.5275911092758179
Validation loss: 1.8239807698034471

Epoch: 5| Step: 3
Training loss: 0.5487173795700073
Validation loss: 1.859283052464967

Epoch: 5| Step: 4
Training loss: 0.7995129227638245
Validation loss: 1.8866465117341729

Epoch: 5| Step: 5
Training loss: 0.7911514043807983
Validation loss: 1.8605825221666725

Epoch: 5| Step: 6
Training loss: 0.5825400352478027
Validation loss: 1.8936714946582753

Epoch: 5| Step: 7
Training loss: 0.6489818692207336
Validation loss: 1.7899110240321006

Epoch: 5| Step: 8
Training loss: 0.7807425856590271
Validation loss: 1.8633762046854982

Epoch: 5| Step: 9
Training loss: 1.0169334411621094
Validation loss: 1.8547881200749388

Epoch: 5| Step: 10
Training loss: 1.3040223121643066
Validation loss: 1.8583629310771983

Epoch: 709| Step: 0
Training loss: 0.7323681116104126
Validation loss: 1.8483733515585623

Epoch: 5| Step: 1
Training loss: 0.6585866212844849
Validation loss: 1.8377480763261036

Epoch: 5| Step: 2
Training loss: 0.9135001301765442
Validation loss: 1.864544455723096

Epoch: 5| Step: 3
Training loss: 0.5907500982284546
Validation loss: 1.8321364105388682

Epoch: 5| Step: 4
Training loss: 0.875766396522522
Validation loss: 1.8244931210753739

Epoch: 5| Step: 5
Training loss: 0.6813784837722778
Validation loss: 1.8768437152267785

Epoch: 5| Step: 6
Training loss: 0.6864343285560608
Validation loss: 1.8571638599518807

Epoch: 5| Step: 7
Training loss: 0.8292015194892883
Validation loss: 1.8800062248783727

Epoch: 5| Step: 8
Training loss: 0.5215915441513062
Validation loss: 1.910319823090748

Epoch: 5| Step: 9
Training loss: 1.0671601295471191
Validation loss: 1.8721507864613687

Epoch: 5| Step: 10
Training loss: 0.8650211095809937
Validation loss: 1.8652040138039538

Epoch: 710| Step: 0
Training loss: 0.7526742219924927
Validation loss: 1.8250204747722996

Epoch: 5| Step: 1
Training loss: 0.6370172500610352
Validation loss: 1.8553208881808865

Epoch: 5| Step: 2
Training loss: 0.8176993131637573
Validation loss: 1.844754567710302

Epoch: 5| Step: 3
Training loss: 0.5373585820198059
Validation loss: 1.827304925969852

Epoch: 5| Step: 4
Training loss: 0.5847005844116211
Validation loss: 1.8543585782409997

Epoch: 5| Step: 5
Training loss: 1.0970150232315063
Validation loss: 1.8454885880152385

Epoch: 5| Step: 6
Training loss: 0.5707597732543945
Validation loss: 1.8467709531066239

Epoch: 5| Step: 7
Training loss: 0.8449080586433411
Validation loss: 1.8005349648896085

Epoch: 5| Step: 8
Training loss: 0.855009913444519
Validation loss: 1.8582387034611036

Epoch: 5| Step: 9
Training loss: 1.0071446895599365
Validation loss: 1.8395093692246305

Epoch: 5| Step: 10
Training loss: 0.7354443669319153
Validation loss: 1.8511149293632918

Epoch: 711| Step: 0
Training loss: 0.5605198740959167
Validation loss: 1.8939158185835807

Epoch: 5| Step: 1
Training loss: 0.7365289926528931
Validation loss: 1.8297009160441737

Epoch: 5| Step: 2
Training loss: 1.0400254726409912
Validation loss: 1.816196773641853

Epoch: 5| Step: 3
Training loss: 0.6794115304946899
Validation loss: 1.8249036471048992

Epoch: 5| Step: 4
Training loss: 1.1723239421844482
Validation loss: 1.87084416292047

Epoch: 5| Step: 5
Training loss: 0.8042091131210327
Validation loss: 1.886492262604416

Epoch: 5| Step: 6
Training loss: 0.7240773439407349
Validation loss: 1.8618954304725892

Epoch: 5| Step: 7
Training loss: 0.42150983214378357
Validation loss: 1.8704820576534475

Epoch: 5| Step: 8
Training loss: 0.36535516381263733
Validation loss: 1.8757554331133444

Epoch: 5| Step: 9
Training loss: 1.2415529489517212
Validation loss: 1.7871530171363585

Epoch: 5| Step: 10
Training loss: 0.8319342136383057
Validation loss: 1.8869932633574291

Epoch: 712| Step: 0
Training loss: 1.1431084871292114
Validation loss: 1.8511638654175626

Epoch: 5| Step: 1
Training loss: 0.7919629812240601
Validation loss: 1.8374444130928285

Epoch: 5| Step: 2
Training loss: 0.4012428820133209
Validation loss: 1.842359204446116

Epoch: 5| Step: 3
Training loss: 0.9800909161567688
Validation loss: 1.796197743826015

Epoch: 5| Step: 4
Training loss: 0.4399792551994324
Validation loss: 1.844420127971198

Epoch: 5| Step: 5
Training loss: 0.6479282379150391
Validation loss: 1.8449371002053703

Epoch: 5| Step: 6
Training loss: 1.0421266555786133
Validation loss: 1.7824800065768662

Epoch: 5| Step: 7
Training loss: 0.5973097085952759
Validation loss: 1.86000447247618

Epoch: 5| Step: 8
Training loss: 0.6471234560012817
Validation loss: 1.872474830637696

Epoch: 5| Step: 9
Training loss: 0.8449519872665405
Validation loss: 1.8777423110059512

Epoch: 5| Step: 10
Training loss: 0.5227641463279724
Validation loss: 1.861950764092066

Epoch: 713| Step: 0
Training loss: 0.7519658207893372
Validation loss: 1.8788192118367841

Epoch: 5| Step: 1
Training loss: 0.5796784162521362
Validation loss: 1.8800504822884836

Epoch: 5| Step: 2
Training loss: 0.6508691310882568
Validation loss: 1.9136383918023878

Epoch: 5| Step: 3
Training loss: 0.4763566851615906
Validation loss: 1.8696687682982414

Epoch: 5| Step: 4
Training loss: 1.1721261739730835
Validation loss: 1.892061407848071

Epoch: 5| Step: 5
Training loss: 0.6465963125228882
Validation loss: 1.9023348964670652

Epoch: 5| Step: 6
Training loss: 1.367672324180603
Validation loss: 1.8699352587423017

Epoch: 5| Step: 7
Training loss: 0.5219748616218567
Validation loss: 1.8441153610906293

Epoch: 5| Step: 8
Training loss: 0.7733827829360962
Validation loss: 1.881313270138156

Epoch: 5| Step: 9
Training loss: 0.5888728499412537
Validation loss: 1.8161142692771008

Epoch: 5| Step: 10
Training loss: 1.1567462682724
Validation loss: 1.86382382915866

Epoch: 714| Step: 0
Training loss: 0.8017798662185669
Validation loss: 1.859595698695029

Epoch: 5| Step: 1
Training loss: 0.7812920212745667
Validation loss: 1.8110646393991285

Epoch: 5| Step: 2
Training loss: 1.4779784679412842
Validation loss: 1.81574720721091

Epoch: 5| Step: 3
Training loss: 0.675693154335022
Validation loss: 1.7820182910529516

Epoch: 5| Step: 4
Training loss: 0.6705511808395386
Validation loss: 1.8179951201203048

Epoch: 5| Step: 5
Training loss: 0.7655385136604309
Validation loss: 1.8451563183979323

Epoch: 5| Step: 6
Training loss: 0.5525903701782227
Validation loss: 1.838557392038325

Epoch: 5| Step: 7
Training loss: 0.7669164538383484
Validation loss: 1.8415646091584237

Epoch: 5| Step: 8
Training loss: 0.5861561894416809
Validation loss: 1.8305416799360705

Epoch: 5| Step: 9
Training loss: 0.5458424091339111
Validation loss: 1.8395969521614812

Epoch: 5| Step: 10
Training loss: 0.44491925835609436
Validation loss: 1.9098045518321376

Epoch: 715| Step: 0
Training loss: 0.7909259796142578
Validation loss: 1.8822387565848648

Epoch: 5| Step: 1
Training loss: 0.5465124249458313
Validation loss: 1.9168071362280077

Epoch: 5| Step: 2
Training loss: 0.7833655476570129
Validation loss: 1.8352905652856315

Epoch: 5| Step: 3
Training loss: 0.8969203233718872
Validation loss: 1.858190744153915

Epoch: 5| Step: 4
Training loss: 0.7980258464813232
Validation loss: 1.8884358764976583

Epoch: 5| Step: 5
Training loss: 0.9715226888656616
Validation loss: 1.8543894008923603

Epoch: 5| Step: 6
Training loss: 0.6999121904373169
Validation loss: 1.7797802661054878

Epoch: 5| Step: 7
Training loss: 0.7586047053337097
Validation loss: 1.792334500179496

Epoch: 5| Step: 8
Training loss: 0.9642771482467651
Validation loss: 1.8087507370979554

Epoch: 5| Step: 9
Training loss: 0.8141093254089355
Validation loss: 1.8374683722372978

Epoch: 5| Step: 10
Training loss: 0.46705085039138794
Validation loss: 1.8636608546780002

Epoch: 716| Step: 0
Training loss: 0.7895596623420715
Validation loss: 1.9008405080405615

Epoch: 5| Step: 1
Training loss: 0.7396572232246399
Validation loss: 1.8683094196422125

Epoch: 5| Step: 2
Training loss: 0.6595900058746338
Validation loss: 1.8315444441251858

Epoch: 5| Step: 3
Training loss: 1.01930832862854
Validation loss: 1.7945589980771464

Epoch: 5| Step: 4
Training loss: 1.0195999145507812
Validation loss: 1.8753476322338145

Epoch: 5| Step: 5
Training loss: 0.48228365182876587
Validation loss: 1.834838660814429

Epoch: 5| Step: 6
Training loss: 0.5175015330314636
Validation loss: 1.9349698020565895

Epoch: 5| Step: 7
Training loss: 1.153865098953247
Validation loss: 1.841654936472575

Epoch: 5| Step: 8
Training loss: 0.7013128399848938
Validation loss: 1.8627670529068157

Epoch: 5| Step: 9
Training loss: 0.9842613935470581
Validation loss: 1.8932929846548265

Epoch: 5| Step: 10
Training loss: 0.5620930790901184
Validation loss: 1.9146731938085249

Epoch: 717| Step: 0
Training loss: 0.6005977392196655
Validation loss: 1.886438577405868

Epoch: 5| Step: 1
Training loss: 1.3653106689453125
Validation loss: 1.8157244536184496

Epoch: 5| Step: 2
Training loss: 0.5865381956100464
Validation loss: 1.7804835240046184

Epoch: 5| Step: 3
Training loss: 0.35886719822883606
Validation loss: 1.7883969122363674

Epoch: 5| Step: 4
Training loss: 0.9848896861076355
Validation loss: 1.818245276328056

Epoch: 5| Step: 5
Training loss: 0.6095916032791138
Validation loss: 1.837152083714803

Epoch: 5| Step: 6
Training loss: 0.7662325501441956
Validation loss: 1.8628016825645202

Epoch: 5| Step: 7
Training loss: 0.5620375871658325
Validation loss: 1.8374054970279816

Epoch: 5| Step: 8
Training loss: 0.8412639498710632
Validation loss: 1.8271466673061412

Epoch: 5| Step: 9
Training loss: 0.9779033660888672
Validation loss: 1.799790628494755

Epoch: 5| Step: 10
Training loss: 0.682248055934906
Validation loss: 1.8158156179612683

Epoch: 718| Step: 0
Training loss: 0.7119943499565125
Validation loss: 1.829638317067136

Epoch: 5| Step: 1
Training loss: 1.2074960470199585
Validation loss: 1.854009315531741

Epoch: 5| Step: 2
Training loss: 0.6251488924026489
Validation loss: 1.8077181616137106

Epoch: 5| Step: 3
Training loss: 0.9309400320053101
Validation loss: 1.8840589420769804

Epoch: 5| Step: 4
Training loss: 0.44393882155418396
Validation loss: 1.8946650079501572

Epoch: 5| Step: 5
Training loss: 0.7877437472343445
Validation loss: 1.902444734368273

Epoch: 5| Step: 6
Training loss: 0.6926981210708618
Validation loss: 1.9221172666036954

Epoch: 5| Step: 7
Training loss: 0.9839022755622864
Validation loss: 1.8815957602634226

Epoch: 5| Step: 8
Training loss: 0.7188491821289062
Validation loss: 1.85252635581519

Epoch: 5| Step: 9
Training loss: 0.9728745222091675
Validation loss: 1.8402970208916614

Epoch: 5| Step: 10
Training loss: 0.6644940376281738
Validation loss: 1.804112410032621

Epoch: 719| Step: 0
Training loss: 0.5443719029426575
Validation loss: 1.8505885011406356

Epoch: 5| Step: 1
Training loss: 0.6890880465507507
Validation loss: 1.797468505879884

Epoch: 5| Step: 2
Training loss: 1.238237977027893
Validation loss: 1.8180610928484189

Epoch: 5| Step: 3
Training loss: 0.6555495858192444
Validation loss: 1.8104759916182487

Epoch: 5| Step: 4
Training loss: 1.0618231296539307
Validation loss: 1.856364070728261

Epoch: 5| Step: 5
Training loss: 0.5860795974731445
Validation loss: 1.8259281394302205

Epoch: 5| Step: 6
Training loss: 0.5589864253997803
Validation loss: 1.8363843246172833

Epoch: 5| Step: 7
Training loss: 0.8087800145149231
Validation loss: 1.884225110853872

Epoch: 5| Step: 8
Training loss: 0.6584351658821106
Validation loss: 1.8337364581323439

Epoch: 5| Step: 9
Training loss: 0.764203667640686
Validation loss: 1.8059311271995626

Epoch: 5| Step: 10
Training loss: 0.8111959099769592
Validation loss: 1.8044043510190901

Epoch: 720| Step: 0
Training loss: 0.6169432401657104
Validation loss: 1.87535427078124

Epoch: 5| Step: 1
Training loss: 0.6108149290084839
Validation loss: 1.8416195095226329

Epoch: 5| Step: 2
Training loss: 0.5176005363464355
Validation loss: 1.8581626774162374

Epoch: 5| Step: 3
Training loss: 0.74146568775177
Validation loss: 1.8648310912552701

Epoch: 5| Step: 4
Training loss: 0.5125443339347839
Validation loss: 1.7829870741854432

Epoch: 5| Step: 5
Training loss: 0.8936643600463867
Validation loss: 1.8024138148112963

Epoch: 5| Step: 6
Training loss: 0.7264132499694824
Validation loss: 1.7956577077988656

Epoch: 5| Step: 7
Training loss: 0.7336446046829224
Validation loss: 1.8342942601890975

Epoch: 5| Step: 8
Training loss: 0.8666656613349915
Validation loss: 1.8153648299555625

Epoch: 5| Step: 9
Training loss: 1.0197616815567017
Validation loss: 1.8289822686103083

Epoch: 5| Step: 10
Training loss: 0.9313474893569946
Validation loss: 1.8341863873184368

Epoch: 721| Step: 0
Training loss: 0.8847769498825073
Validation loss: 1.8170693920504661

Epoch: 5| Step: 1
Training loss: 0.8740612268447876
Validation loss: 1.8215435602331673

Epoch: 5| Step: 2
Training loss: 0.6310470700263977
Validation loss: 1.8437264465516614

Epoch: 5| Step: 3
Training loss: 0.5104358196258545
Validation loss: 1.8187647865664573

Epoch: 5| Step: 4
Training loss: 0.5716037750244141
Validation loss: 1.8599488799289992

Epoch: 5| Step: 5
Training loss: 0.6538594961166382
Validation loss: 1.9367233553240377

Epoch: 5| Step: 6
Training loss: 0.5199505686759949
Validation loss: 1.8491054991240143

Epoch: 5| Step: 7
Training loss: 0.9819064140319824
Validation loss: 1.8213149834704656

Epoch: 5| Step: 8
Training loss: 0.8163948059082031
Validation loss: 1.878533230032972

Epoch: 5| Step: 9
Training loss: 1.085923433303833
Validation loss: 1.8983010591999177

Epoch: 5| Step: 10
Training loss: 0.7251089215278625
Validation loss: 1.8652754086320118

Epoch: 722| Step: 0
Training loss: 0.7515567541122437
Validation loss: 1.8513403310570666

Epoch: 5| Step: 1
Training loss: 0.6138979196548462
Validation loss: 1.896187041395454

Epoch: 5| Step: 2
Training loss: 0.6860352754592896
Validation loss: 1.8363423270563926

Epoch: 5| Step: 3
Training loss: 0.8274378776550293
Validation loss: 1.8672778055232058

Epoch: 5| Step: 4
Training loss: 0.7270357012748718
Validation loss: 1.8481872491939093

Epoch: 5| Step: 5
Training loss: 1.0873485803604126
Validation loss: 1.8061080568580217

Epoch: 5| Step: 6
Training loss: 0.9935104250907898
Validation loss: 1.8223515748977661

Epoch: 5| Step: 7
Training loss: 0.5863391757011414
Validation loss: 1.8163559000979188

Epoch: 5| Step: 8
Training loss: 0.5051156282424927
Validation loss: 1.7865760762204406

Epoch: 5| Step: 9
Training loss: 1.0071380138397217
Validation loss: 1.8182163494889454

Epoch: 5| Step: 10
Training loss: 0.7128348350524902
Validation loss: 1.7735766236500075

Epoch: 723| Step: 0
Training loss: 1.0642045736312866
Validation loss: 1.844070493534047

Epoch: 5| Step: 1
Training loss: 0.5809650421142578
Validation loss: 1.7991115239358717

Epoch: 5| Step: 2
Training loss: 0.802487850189209
Validation loss: 1.8046557211106824

Epoch: 5| Step: 3
Training loss: 1.0055785179138184
Validation loss: 1.8219380147995488

Epoch: 5| Step: 4
Training loss: 0.37307435274124146
Validation loss: 1.836258073006907

Epoch: 5| Step: 5
Training loss: 0.7233928442001343
Validation loss: 1.859398780330535

Epoch: 5| Step: 6
Training loss: 0.6198694109916687
Validation loss: 1.8525997977102957

Epoch: 5| Step: 7
Training loss: 0.7399054765701294
Validation loss: 1.8851781980965727

Epoch: 5| Step: 8
Training loss: 0.9112399816513062
Validation loss: 1.8440768718719482

Epoch: 5| Step: 9
Training loss: 0.37332138419151306
Validation loss: 1.8238903553255144

Epoch: 5| Step: 10
Training loss: 1.030298113822937
Validation loss: 1.9266370573351461

Epoch: 724| Step: 0
Training loss: 0.5712422132492065
Validation loss: 1.8399951778432375

Epoch: 5| Step: 1
Training loss: 0.9890292882919312
Validation loss: 1.8709265185940651

Epoch: 5| Step: 2
Training loss: 0.5250715017318726
Validation loss: 1.820556745734266

Epoch: 5| Step: 3
Training loss: 0.42335575819015503
Validation loss: 1.825189599426844

Epoch: 5| Step: 4
Training loss: 0.6843721270561218
Validation loss: 1.8670175562622726

Epoch: 5| Step: 5
Training loss: 0.6337041854858398
Validation loss: 1.757165878049789

Epoch: 5| Step: 6
Training loss: 0.656540036201477
Validation loss: 1.8099683305268646

Epoch: 5| Step: 7
Training loss: 0.5815702080726624
Validation loss: 1.802441450857347

Epoch: 5| Step: 8
Training loss: 0.6372735500335693
Validation loss: 1.8286087359151533

Epoch: 5| Step: 9
Training loss: 1.1709041595458984
Validation loss: 1.8340054750442505

Epoch: 5| Step: 10
Training loss: 1.0311716794967651
Validation loss: 1.8770970708580428

Epoch: 725| Step: 0
Training loss: 0.7657992839813232
Validation loss: 1.9289538424502137

Epoch: 5| Step: 1
Training loss: 0.6781283617019653
Validation loss: 1.887191814761008

Epoch: 5| Step: 2
Training loss: 0.902723491191864
Validation loss: 1.8878128938777472

Epoch: 5| Step: 3
Training loss: 1.14738130569458
Validation loss: 1.8569695847008818

Epoch: 5| Step: 4
Training loss: 0.583375096321106
Validation loss: 1.8355034692313081

Epoch: 5| Step: 5
Training loss: 0.5229519605636597
Validation loss: 1.8291725830365253

Epoch: 5| Step: 6
Training loss: 0.5164963603019714
Validation loss: 1.900121456833296

Epoch: 5| Step: 7
Training loss: 1.0702658891677856
Validation loss: 1.8602596970014675

Epoch: 5| Step: 8
Training loss: 0.687947690486908
Validation loss: 1.8535613744489607

Epoch: 5| Step: 9
Training loss: 0.5944759249687195
Validation loss: 1.8719365468589209

Epoch: 5| Step: 10
Training loss: 0.6146782636642456
Validation loss: 1.812664875420191

Epoch: 726| Step: 0
Training loss: 0.8557125329971313
Validation loss: 1.8409556932346796

Epoch: 5| Step: 1
Training loss: 0.4438261389732361
Validation loss: 1.8605833412498556

Epoch: 5| Step: 2
Training loss: 0.9719308614730835
Validation loss: 1.8302747190639537

Epoch: 5| Step: 3
Training loss: 0.550042986869812
Validation loss: 1.8433508949895059

Epoch: 5| Step: 4
Training loss: 0.7067723274230957
Validation loss: 1.814250216689161

Epoch: 5| Step: 5
Training loss: 0.5560296773910522
Validation loss: 1.8040406614221551

Epoch: 5| Step: 6
Training loss: 0.8130909204483032
Validation loss: 1.8155681305034186

Epoch: 5| Step: 7
Training loss: 0.5678486227989197
Validation loss: 1.8253298010877383

Epoch: 5| Step: 8
Training loss: 0.6432754397392273
Validation loss: 1.8576764009332145

Epoch: 5| Step: 9
Training loss: 1.2036793231964111
Validation loss: 1.8394578477387786

Epoch: 5| Step: 10
Training loss: 0.8905083537101746
Validation loss: 1.8625709920801141

Epoch: 727| Step: 0
Training loss: 0.8254461288452148
Validation loss: 1.7790934424246512

Epoch: 5| Step: 1
Training loss: 1.1632115840911865
Validation loss: 1.878635973058721

Epoch: 5| Step: 2
Training loss: 0.5975795984268188
Validation loss: 1.7600721954017557

Epoch: 5| Step: 3
Training loss: 0.6963536143302917
Validation loss: 1.7998978284097487

Epoch: 5| Step: 4
Training loss: 0.6984688639640808
Validation loss: 1.832791292539207

Epoch: 5| Step: 5
Training loss: 0.8965871930122375
Validation loss: 1.7932812295934206

Epoch: 5| Step: 6
Training loss: 0.7679460048675537
Validation loss: 1.7907879647388254

Epoch: 5| Step: 7
Training loss: 0.647189736366272
Validation loss: 1.8357397074340491

Epoch: 5| Step: 8
Training loss: 0.4572451710700989
Validation loss: 1.8286087666788409

Epoch: 5| Step: 9
Training loss: 0.804060161113739
Validation loss: 1.9078115673475369

Epoch: 5| Step: 10
Training loss: 0.4744187593460083
Validation loss: 1.8431387511632775

Epoch: 728| Step: 0
Training loss: 1.2535903453826904
Validation loss: 1.8007430568818124

Epoch: 5| Step: 1
Training loss: 0.4924493432044983
Validation loss: 1.8390741976358558

Epoch: 5| Step: 2
Training loss: 0.8317521810531616
Validation loss: 1.8385528467034782

Epoch: 5| Step: 3
Training loss: 0.8409678339958191
Validation loss: 1.8540415148581229

Epoch: 5| Step: 4
Training loss: 0.3708498775959015
Validation loss: 1.8008980187036658

Epoch: 5| Step: 5
Training loss: 0.8186542391777039
Validation loss: 1.8687140185345885

Epoch: 5| Step: 6
Training loss: 0.47327059507369995
Validation loss: 1.855689751204624

Epoch: 5| Step: 7
Training loss: 0.8585578203201294
Validation loss: 1.8477393978385515

Epoch: 5| Step: 8
Training loss: 0.6051626205444336
Validation loss: 1.8414391907312537

Epoch: 5| Step: 9
Training loss: 0.5784756541252136
Validation loss: 1.8548058771318006

Epoch: 5| Step: 10
Training loss: 0.7460368871688843
Validation loss: 1.8244633674621582

Epoch: 729| Step: 0
Training loss: 0.8287739753723145
Validation loss: 1.8190138570723995

Epoch: 5| Step: 1
Training loss: 0.6539965271949768
Validation loss: 1.8352433045705159

Epoch: 5| Step: 2
Training loss: 0.6914501190185547
Validation loss: 1.8607350293026175

Epoch: 5| Step: 3
Training loss: 1.2541736364364624
Validation loss: 1.8507901468584615

Epoch: 5| Step: 4
Training loss: 0.9661452174186707
Validation loss: 1.8471002155734646

Epoch: 5| Step: 5
Training loss: 0.6833186149597168
Validation loss: 1.8839818598121725

Epoch: 5| Step: 6
Training loss: 0.6145964860916138
Validation loss: 1.8638090459249352

Epoch: 5| Step: 7
Training loss: 0.6424407958984375
Validation loss: 1.8179970120870939

Epoch: 5| Step: 8
Training loss: 0.7401174306869507
Validation loss: 1.7938033246224927

Epoch: 5| Step: 9
Training loss: 0.3865925371646881
Validation loss: 1.858697142652286

Epoch: 5| Step: 10
Training loss: 0.5805014371871948
Validation loss: 1.8768288525201942

Epoch: 730| Step: 0
Training loss: 0.6495844721794128
Validation loss: 1.7822497711386731

Epoch: 5| Step: 1
Training loss: 0.9787007570266724
Validation loss: 1.8399980593753118

Epoch: 5| Step: 2
Training loss: 0.6967107653617859
Validation loss: 1.9177458824649933

Epoch: 5| Step: 3
Training loss: 0.746324896812439
Validation loss: 1.8578702147288988

Epoch: 5| Step: 4
Training loss: 0.6315606832504272
Validation loss: 1.83392136327682

Epoch: 5| Step: 5
Training loss: 0.5406096577644348
Validation loss: 1.803051766528878

Epoch: 5| Step: 6
Training loss: 0.9104827642440796
Validation loss: 1.79881295722018

Epoch: 5| Step: 7
Training loss: 0.9363697171211243
Validation loss: 1.804462089333483

Epoch: 5| Step: 8
Training loss: 0.8499383926391602
Validation loss: 1.8210472599152596

Epoch: 5| Step: 9
Training loss: 0.5160974264144897
Validation loss: 1.84635038786037

Epoch: 5| Step: 10
Training loss: 0.6041538119316101
Validation loss: 1.841113933952906

Epoch: 731| Step: 0
Training loss: 0.6894011497497559
Validation loss: 1.846930093662713

Epoch: 5| Step: 1
Training loss: 0.5263806581497192
Validation loss: 1.8478219534761162

Epoch: 5| Step: 2
Training loss: 0.32951802015304565
Validation loss: 1.8101755906176824

Epoch: 5| Step: 3
Training loss: 1.2058556079864502
Validation loss: 1.8499447402133737

Epoch: 5| Step: 4
Training loss: 0.5210751891136169
Validation loss: 1.8642322145482546

Epoch: 5| Step: 5
Training loss: 1.0498099327087402
Validation loss: 1.8219647228076894

Epoch: 5| Step: 6
Training loss: 0.5820706486701965
Validation loss: 1.865299537617673

Epoch: 5| Step: 7
Training loss: 0.7893033027648926
Validation loss: 1.7927693115767611

Epoch: 5| Step: 8
Training loss: 0.6960685849189758
Validation loss: 1.8064852119773946

Epoch: 5| Step: 9
Training loss: 0.6631381511688232
Validation loss: 1.8576347469001688

Epoch: 5| Step: 10
Training loss: 0.8233307003974915
Validation loss: 1.8813646147328038

Epoch: 732| Step: 0
Training loss: 1.0994055271148682
Validation loss: 1.851307140883579

Epoch: 5| Step: 1
Training loss: 0.6107544898986816
Validation loss: 1.8474342887119581

Epoch: 5| Step: 2
Training loss: 0.9934455752372742
Validation loss: 1.8453902711150467

Epoch: 5| Step: 3
Training loss: 0.7468641996383667
Validation loss: 1.8711463917968094

Epoch: 5| Step: 4
Training loss: 0.5983103513717651
Validation loss: 1.8469639516645862

Epoch: 5| Step: 5
Training loss: 0.4714769423007965
Validation loss: 1.862237484224381

Epoch: 5| Step: 6
Training loss: 0.5564049482345581
Validation loss: 1.8260985305232387

Epoch: 5| Step: 7
Training loss: 0.8751298785209656
Validation loss: 1.8517846317701443

Epoch: 5| Step: 8
Training loss: 0.5428791642189026
Validation loss: 1.83057866942498

Epoch: 5| Step: 9
Training loss: 0.7186452150344849
Validation loss: 1.8554474269190142

Epoch: 5| Step: 10
Training loss: 0.5799292325973511
Validation loss: 1.8172787517629645

Epoch: 733| Step: 0
Training loss: 0.7983106374740601
Validation loss: 1.8402253376540316

Epoch: 5| Step: 1
Training loss: 1.3755462169647217
Validation loss: 1.821493516045232

Epoch: 5| Step: 2
Training loss: 0.6429335474967957
Validation loss: 1.9003298115986649

Epoch: 5| Step: 3
Training loss: 0.42758750915527344
Validation loss: 1.8547154805993522

Epoch: 5| Step: 4
Training loss: 0.5544171333312988
Validation loss: 1.8049861872068016

Epoch: 5| Step: 5
Training loss: 0.8196455836296082
Validation loss: 1.8681512225058772

Epoch: 5| Step: 6
Training loss: 0.753103494644165
Validation loss: 1.8362203772350023

Epoch: 5| Step: 7
Training loss: 0.7684023976325989
Validation loss: 1.8073151598694503

Epoch: 5| Step: 8
Training loss: 0.6601787805557251
Validation loss: 1.8892434476524271

Epoch: 5| Step: 9
Training loss: 0.5362005829811096
Validation loss: 1.839165231233002

Epoch: 5| Step: 10
Training loss: 0.5889080166816711
Validation loss: 1.832173107772745

Epoch: 734| Step: 0
Training loss: 0.7127648591995239
Validation loss: 1.8042110807152205

Epoch: 5| Step: 1
Training loss: 0.7843998670578003
Validation loss: 1.7729254653376918

Epoch: 5| Step: 2
Training loss: 1.0956642627716064
Validation loss: 1.8278889386884627

Epoch: 5| Step: 3
Training loss: 0.7564490437507629
Validation loss: 1.8675734625067761

Epoch: 5| Step: 4
Training loss: 0.45882588624954224
Validation loss: 1.7801240785147554

Epoch: 5| Step: 5
Training loss: 0.7521536350250244
Validation loss: 1.8254078126722766

Epoch: 5| Step: 6
Training loss: 1.250823974609375
Validation loss: 1.8127477130582255

Epoch: 5| Step: 7
Training loss: 0.3937520980834961
Validation loss: 1.8238565626964773

Epoch: 5| Step: 8
Training loss: 0.4663744866847992
Validation loss: 1.8693918592186385

Epoch: 5| Step: 9
Training loss: 0.6384608745574951
Validation loss: 1.7895718377123597

Epoch: 5| Step: 10
Training loss: 1.1714072227478027
Validation loss: 1.849069606873297

Epoch: 735| Step: 0
Training loss: 0.6293010711669922
Validation loss: 1.786074702457715

Epoch: 5| Step: 1
Training loss: 0.2730933129787445
Validation loss: 1.861062390829927

Epoch: 5| Step: 2
Training loss: 0.7790178656578064
Validation loss: 1.9018406778253534

Epoch: 5| Step: 3
Training loss: 0.9514113664627075
Validation loss: 1.8636711746133783

Epoch: 5| Step: 4
Training loss: 0.6752738356590271
Validation loss: 1.8283454641219108

Epoch: 5| Step: 5
Training loss: 0.6339076161384583
Validation loss: 1.8286689096881497

Epoch: 5| Step: 6
Training loss: 1.184187412261963
Validation loss: 1.8356796503067017

Epoch: 5| Step: 7
Training loss: 0.5474166870117188
Validation loss: 1.8367098851870465

Epoch: 5| Step: 8
Training loss: 0.5973842144012451
Validation loss: 1.8343591728518087

Epoch: 5| Step: 9
Training loss: 0.5662263631820679
Validation loss: 1.7622153630820654

Epoch: 5| Step: 10
Training loss: 0.8064894676208496
Validation loss: 1.8201822401374899

Epoch: 736| Step: 0
Training loss: 0.5086467266082764
Validation loss: 1.7969312219209568

Epoch: 5| Step: 1
Training loss: 0.5921627283096313
Validation loss: 1.7728373389090262

Epoch: 5| Step: 2
Training loss: 0.9764699935913086
Validation loss: 1.8198040339254564

Epoch: 5| Step: 3
Training loss: 0.6689007878303528
Validation loss: 1.8173669999645603

Epoch: 5| Step: 4
Training loss: 0.6681536436080933
Validation loss: 1.822392452147699

Epoch: 5| Step: 5
Training loss: 0.6810899972915649
Validation loss: 1.824572201698057

Epoch: 5| Step: 6
Training loss: 0.6738277673721313
Validation loss: 1.8180629181605514

Epoch: 5| Step: 7
Training loss: 0.5278192162513733
Validation loss: 1.8570779933724353

Epoch: 5| Step: 8
Training loss: 0.9134087562561035
Validation loss: 1.8435621197505663

Epoch: 5| Step: 9
Training loss: 0.5993463397026062
Validation loss: 1.7925417141247821

Epoch: 5| Step: 10
Training loss: 1.0597195625305176
Validation loss: 1.8655671996455039

Epoch: 737| Step: 0
Training loss: 0.9065796136856079
Validation loss: 1.814329574185033

Epoch: 5| Step: 1
Training loss: 0.7131766080856323
Validation loss: 1.86635160446167

Epoch: 5| Step: 2
Training loss: 0.8578851819038391
Validation loss: 1.852509311450425

Epoch: 5| Step: 3
Training loss: 0.594010055065155
Validation loss: 1.8583682083314466

Epoch: 5| Step: 4
Training loss: 0.5356531739234924
Validation loss: 1.8513545297807263

Epoch: 5| Step: 5
Training loss: 0.3981429636478424
Validation loss: 1.8303479481768865

Epoch: 5| Step: 6
Training loss: 0.5254128575325012
Validation loss: 1.806253589609618

Epoch: 5| Step: 7
Training loss: 0.8443378210067749
Validation loss: 1.820302096746301

Epoch: 5| Step: 8
Training loss: 0.7382220029830933
Validation loss: 1.849727475514976

Epoch: 5| Step: 9
Training loss: 0.6402353644371033
Validation loss: 1.7961650817624983

Epoch: 5| Step: 10
Training loss: 0.7462806105613708
Validation loss: 1.8105961725276003

Epoch: 738| Step: 0
Training loss: 0.47955742478370667
Validation loss: 1.8482113499795236

Epoch: 5| Step: 1
Training loss: 0.7120760083198547
Validation loss: 1.803644916062714

Epoch: 5| Step: 2
Training loss: 0.7769100069999695
Validation loss: 1.8453548928742767

Epoch: 5| Step: 3
Training loss: 0.418526828289032
Validation loss: 1.8140927617267897

Epoch: 5| Step: 4
Training loss: 0.8205822110176086
Validation loss: 1.8488560145901096

Epoch: 5| Step: 5
Training loss: 0.5182449817657471
Validation loss: 1.8476311122217486

Epoch: 5| Step: 6
Training loss: 0.6747135519981384
Validation loss: 1.8579826585708126

Epoch: 5| Step: 7
Training loss: 0.9279767274856567
Validation loss: 1.837528859415362

Epoch: 5| Step: 8
Training loss: 0.8650174140930176
Validation loss: 1.906333484957295

Epoch: 5| Step: 9
Training loss: 0.5372183918952942
Validation loss: 1.8773648315860378

Epoch: 5| Step: 10
Training loss: 1.5676541328430176
Validation loss: 1.8658260465950094

Epoch: 739| Step: 0
Training loss: 0.46081265807151794
Validation loss: 1.8615662160740103

Epoch: 5| Step: 1
Training loss: 0.5978768467903137
Validation loss: 1.8646334435350151

Epoch: 5| Step: 2
Training loss: 0.8291270136833191
Validation loss: 1.8706656873867076

Epoch: 5| Step: 3
Training loss: 0.5968279838562012
Validation loss: 1.8744767135189426

Epoch: 5| Step: 4
Training loss: 0.9005139470100403
Validation loss: 1.8477366355157667

Epoch: 5| Step: 5
Training loss: 0.6656506657600403
Validation loss: 1.8630748538560764

Epoch: 5| Step: 6
Training loss: 0.989883542060852
Validation loss: 1.8692845503489177

Epoch: 5| Step: 7
Training loss: 0.7782756090164185
Validation loss: 1.8399119082317557

Epoch: 5| Step: 8
Training loss: 1.050304651260376
Validation loss: 1.8485369182402087

Epoch: 5| Step: 9
Training loss: 0.6184157133102417
Validation loss: 1.80069778555183

Epoch: 5| Step: 10
Training loss: 0.46148958802223206
Validation loss: 1.8656884906112507

Epoch: 740| Step: 0
Training loss: 0.5690234303474426
Validation loss: 1.796146882477627

Epoch: 5| Step: 1
Training loss: 0.6013920903205872
Validation loss: 1.8604181415291243

Epoch: 5| Step: 2
Training loss: 0.6585347652435303
Validation loss: 1.8795459347386514

Epoch: 5| Step: 3
Training loss: 0.6476781368255615
Validation loss: 1.869051400051322

Epoch: 5| Step: 4
Training loss: 0.658671498298645
Validation loss: 1.8722626727114442

Epoch: 5| Step: 5
Training loss: 0.9823380708694458
Validation loss: 1.8514702807190597

Epoch: 5| Step: 6
Training loss: 0.7097294926643372
Validation loss: 1.8685156401767526

Epoch: 5| Step: 7
Training loss: 1.230605125427246
Validation loss: 1.8079244949484383

Epoch: 5| Step: 8
Training loss: 0.6807113885879517
Validation loss: 1.897210031427363

Epoch: 5| Step: 9
Training loss: 0.7077378034591675
Validation loss: 1.82622181728322

Epoch: 5| Step: 10
Training loss: 0.5694705247879028
Validation loss: 1.828278809465388

Epoch: 741| Step: 0
Training loss: 0.6366696357727051
Validation loss: 1.830314472157468

Epoch: 5| Step: 1
Training loss: 0.5620967149734497
Validation loss: 1.8598521935042513

Epoch: 5| Step: 2
Training loss: 0.4232215881347656
Validation loss: 1.87661228897751

Epoch: 5| Step: 3
Training loss: 1.0984795093536377
Validation loss: 1.8537676667654386

Epoch: 5| Step: 4
Training loss: 0.9057474136352539
Validation loss: 1.8542119277420865

Epoch: 5| Step: 5
Training loss: 0.46239250898361206
Validation loss: 1.830592914294171

Epoch: 5| Step: 6
Training loss: 0.856650710105896
Validation loss: 1.857109929925652

Epoch: 5| Step: 7
Training loss: 0.6921780705451965
Validation loss: 1.8818374859389437

Epoch: 5| Step: 8
Training loss: 0.7862798571586609
Validation loss: 1.7719078948420863

Epoch: 5| Step: 9
Training loss: 0.7182937264442444
Validation loss: 1.783925776840538

Epoch: 5| Step: 10
Training loss: 0.9760846495628357
Validation loss: 1.816177547618907

Epoch: 742| Step: 0
Training loss: 0.8652116656303406
Validation loss: 1.839111433234266

Epoch: 5| Step: 1
Training loss: 0.8451557159423828
Validation loss: 1.8278816771763626

Epoch: 5| Step: 2
Training loss: 1.0917155742645264
Validation loss: 1.7969081453097764

Epoch: 5| Step: 3
Training loss: 0.3874242305755615
Validation loss: 1.8228373001980525

Epoch: 5| Step: 4
Training loss: 0.778096079826355
Validation loss: 1.8303960959116619

Epoch: 5| Step: 5
Training loss: 0.5357892513275146
Validation loss: 1.8413186534758537

Epoch: 5| Step: 6
Training loss: 0.8849360346794128
Validation loss: 1.9103096710738314

Epoch: 5| Step: 7
Training loss: 0.5435803532600403
Validation loss: 1.8801724398007957

Epoch: 5| Step: 8
Training loss: 0.7545241117477417
Validation loss: 1.8489017416072149

Epoch: 5| Step: 9
Training loss: 0.3844911456108093
Validation loss: 1.8027546533974268

Epoch: 5| Step: 10
Training loss: 0.6320888996124268
Validation loss: 1.8236798381292691

Epoch: 743| Step: 0
Training loss: 0.5594989061355591
Validation loss: 1.7973553596004364

Epoch: 5| Step: 1
Training loss: 0.5391519665718079
Validation loss: 1.8095519388875654

Epoch: 5| Step: 2
Training loss: 0.7853856086730957
Validation loss: 1.8599398648867043

Epoch: 5| Step: 3
Training loss: 0.7637994289398193
Validation loss: 1.8341384036566621

Epoch: 5| Step: 4
Training loss: 0.4615575671195984
Validation loss: 1.8991147497648835

Epoch: 5| Step: 5
Training loss: 0.7523568272590637
Validation loss: 1.8932763504725632

Epoch: 5| Step: 6
Training loss: 0.860692024230957
Validation loss: 1.8820053403095534

Epoch: 5| Step: 7
Training loss: 0.9352992177009583
Validation loss: 1.9029032171413462

Epoch: 5| Step: 8
Training loss: 0.6512535810470581
Validation loss: 1.8619626773300992

Epoch: 5| Step: 9
Training loss: 0.686124861240387
Validation loss: 1.8693694145448747

Epoch: 5| Step: 10
Training loss: 1.111799716949463
Validation loss: 1.8138310229906471

Epoch: 744| Step: 0
Training loss: 0.5473661422729492
Validation loss: 1.8163620669354674

Epoch: 5| Step: 1
Training loss: 1.069469928741455
Validation loss: 1.815989880151646

Epoch: 5| Step: 2
Training loss: 0.9275881052017212
Validation loss: 1.865878317945747

Epoch: 5| Step: 3
Training loss: 0.6995897889137268
Validation loss: 1.807640653784557

Epoch: 5| Step: 4
Training loss: 0.5661746859550476
Validation loss: 1.839156364881864

Epoch: 5| Step: 5
Training loss: 0.5377933382987976
Validation loss: 1.797672240964828

Epoch: 5| Step: 6
Training loss: 0.6013118028640747
Validation loss: 1.7669396426088066

Epoch: 5| Step: 7
Training loss: 0.8396819829940796
Validation loss: 1.7965096542912145

Epoch: 5| Step: 8
Training loss: 0.7080937623977661
Validation loss: 1.825116370313911

Epoch: 5| Step: 9
Training loss: 0.9175628423690796
Validation loss: 1.9085250413545998

Epoch: 5| Step: 10
Training loss: 0.5655463933944702
Validation loss: 1.8351591402484524

Epoch: 745| Step: 0
Training loss: 0.9383398294448853
Validation loss: 1.7980638921901744

Epoch: 5| Step: 1
Training loss: 0.8440725207328796
Validation loss: 1.9081574921966882

Epoch: 5| Step: 2
Training loss: 0.6247686147689819
Validation loss: 1.904463755187168

Epoch: 5| Step: 3
Training loss: 0.502127468585968
Validation loss: 1.8782927528504403

Epoch: 5| Step: 4
Training loss: 1.2288998365402222
Validation loss: 1.8689946410476521

Epoch: 5| Step: 5
Training loss: 0.7287330627441406
Validation loss: 1.84551033794239

Epoch: 5| Step: 6
Training loss: 0.7050269246101379
Validation loss: 1.8303284209261659

Epoch: 5| Step: 7
Training loss: 0.772304356098175
Validation loss: 1.82049867158295

Epoch: 5| Step: 8
Training loss: 0.5449134111404419
Validation loss: 1.8539805232837636

Epoch: 5| Step: 9
Training loss: 0.48177003860473633
Validation loss: 1.7821992853636384

Epoch: 5| Step: 10
Training loss: 0.7111821174621582
Validation loss: 1.8263889935708815

Epoch: 746| Step: 0
Training loss: 0.6506447196006775
Validation loss: 1.8331259437786636

Epoch: 5| Step: 1
Training loss: 0.5672386884689331
Validation loss: 1.8847618038936327

Epoch: 5| Step: 2
Training loss: 0.811109721660614
Validation loss: 1.7865143540085002

Epoch: 5| Step: 3
Training loss: 0.7120124101638794
Validation loss: 1.805096846754833

Epoch: 5| Step: 4
Training loss: 0.5641447305679321
Validation loss: 1.8021197780486076

Epoch: 5| Step: 5
Training loss: 0.83636873960495
Validation loss: 1.8204658723646594

Epoch: 5| Step: 6
Training loss: 0.9425821304321289
Validation loss: 1.8245811718766407

Epoch: 5| Step: 7
Training loss: 0.7408230900764465
Validation loss: 1.8351469142462618

Epoch: 5| Step: 8
Training loss: 0.6659317016601562
Validation loss: 1.831364885453255

Epoch: 5| Step: 9
Training loss: 0.742516815662384
Validation loss: 1.8193963702007006

Epoch: 5| Step: 10
Training loss: 0.4603826701641083
Validation loss: 1.877390036018946

Epoch: 747| Step: 0
Training loss: 0.5554758310317993
Validation loss: 1.8509217654505083

Epoch: 5| Step: 1
Training loss: 0.5859004259109497
Validation loss: 1.8206929609339724

Epoch: 5| Step: 2
Training loss: 0.6683588027954102
Validation loss: 1.841771738503569

Epoch: 5| Step: 3
Training loss: 0.6762980222702026
Validation loss: 1.84118515188976

Epoch: 5| Step: 4
Training loss: 0.8143223524093628
Validation loss: 1.7395476000283354

Epoch: 5| Step: 5
Training loss: 0.5091368556022644
Validation loss: 1.8675379958204044

Epoch: 5| Step: 6
Training loss: 0.41278329491615295
Validation loss: 1.8505960241440804

Epoch: 5| Step: 7
Training loss: 0.8844181299209595
Validation loss: 1.8183702653454197

Epoch: 5| Step: 8
Training loss: 0.9438112378120422
Validation loss: 1.8591427969676193

Epoch: 5| Step: 9
Training loss: 0.9208990335464478
Validation loss: 1.804749773394677

Epoch: 5| Step: 10
Training loss: 0.5843147039413452
Validation loss: 1.7728226595027472

Epoch: 748| Step: 0
Training loss: 0.6755561232566833
Validation loss: 1.8020908947913878

Epoch: 5| Step: 1
Training loss: 0.3248208165168762
Validation loss: 1.809933998251474

Epoch: 5| Step: 2
Training loss: 0.7727673649787903
Validation loss: 1.8184321785485873

Epoch: 5| Step: 3
Training loss: 1.1246411800384521
Validation loss: 1.8463996059151107

Epoch: 5| Step: 4
Training loss: 0.5698286890983582
Validation loss: 1.761532207970978

Epoch: 5| Step: 5
Training loss: 1.0907844305038452
Validation loss: 1.7645606622901013

Epoch: 5| Step: 6
Training loss: 0.6928169131278992
Validation loss: 1.7956683302438388

Epoch: 5| Step: 7
Training loss: 0.4502357542514801
Validation loss: 1.8480439519369474

Epoch: 5| Step: 8
Training loss: 0.47149381041526794
Validation loss: 1.8285054365793865

Epoch: 5| Step: 9
Training loss: 0.9374696612358093
Validation loss: 1.8037171517649004

Epoch: 5| Step: 10
Training loss: 0.46473851799964905
Validation loss: 1.8102197531730897

Epoch: 749| Step: 0
Training loss: 0.7065367698669434
Validation loss: 1.8362247431150047

Epoch: 5| Step: 1
Training loss: 0.5922425985336304
Validation loss: 1.8534639471320695

Epoch: 5| Step: 2
Training loss: 0.8460114598274231
Validation loss: 1.8389431148447015

Epoch: 5| Step: 3
Training loss: 0.6584994196891785
Validation loss: 1.8080443925754999

Epoch: 5| Step: 4
Training loss: 0.8200685381889343
Validation loss: 1.8671992004558604

Epoch: 5| Step: 5
Training loss: 0.5781657695770264
Validation loss: 1.8263645966847737

Epoch: 5| Step: 6
Training loss: 0.9337868690490723
Validation loss: 1.8498829257103704

Epoch: 5| Step: 7
Training loss: 0.9784964323043823
Validation loss: 1.8828500419534662

Epoch: 5| Step: 8
Training loss: 0.49781984090805054
Validation loss: 1.8700534182210122

Epoch: 5| Step: 9
Training loss: 0.6316593885421753
Validation loss: 1.8467671384093582

Epoch: 5| Step: 10
Training loss: 0.5534005761146545
Validation loss: 1.8110370187349216

Epoch: 750| Step: 0
Training loss: 0.9264302253723145
Validation loss: 1.770611079790259

Epoch: 5| Step: 1
Training loss: 0.6728957891464233
Validation loss: 1.8521806604118758

Epoch: 5| Step: 2
Training loss: 0.7408901453018188
Validation loss: 1.843741064430565

Epoch: 5| Step: 3
Training loss: 0.5175967216491699
Validation loss: 1.7927797404668664

Epoch: 5| Step: 4
Training loss: 0.49392247200012207
Validation loss: 1.8110150239800895

Epoch: 5| Step: 5
Training loss: 0.9555819630622864
Validation loss: 1.8255164007986746

Epoch: 5| Step: 6
Training loss: 0.6307835578918457
Validation loss: 1.7953330227123794

Epoch: 5| Step: 7
Training loss: 0.49189847707748413
Validation loss: 1.8194914633227932

Epoch: 5| Step: 8
Training loss: 0.7949508428573608
Validation loss: 1.8169118794061805

Epoch: 5| Step: 9
Training loss: 0.32100239396095276
Validation loss: 1.7807491030744327

Epoch: 5| Step: 10
Training loss: 1.369950294494629
Validation loss: 1.8362914849353094

Epoch: 751| Step: 0
Training loss: 0.4293884336948395
Validation loss: 1.8321272173235494

Epoch: 5| Step: 1
Training loss: 0.46602630615234375
Validation loss: 1.8955199449293074

Epoch: 5| Step: 2
Training loss: 0.8048590421676636
Validation loss: 1.8356704276095155

Epoch: 5| Step: 3
Training loss: 0.5800939798355103
Validation loss: 1.8428995045282508

Epoch: 5| Step: 4
Training loss: 0.8507404327392578
Validation loss: 1.8660779050601426

Epoch: 5| Step: 5
Training loss: 0.9923922419548035
Validation loss: 1.9129481315612793

Epoch: 5| Step: 6
Training loss: 0.695416271686554
Validation loss: 1.8618569309993456

Epoch: 5| Step: 7
Training loss: 1.0313799381256104
Validation loss: 1.892981365162839

Epoch: 5| Step: 8
Training loss: 0.6572504639625549
Validation loss: 1.8100850953850696

Epoch: 5| Step: 9
Training loss: 0.6967710256576538
Validation loss: 1.7723007304694063

Epoch: 5| Step: 10
Training loss: 0.6786637306213379
Validation loss: 1.7978334401243476

Epoch: 752| Step: 0
Training loss: 0.6453431248664856
Validation loss: 1.8181999498798

Epoch: 5| Step: 1
Training loss: 0.6468252539634705
Validation loss: 1.7968824217396397

Epoch: 5| Step: 2
Training loss: 1.059907078742981
Validation loss: 1.848472273477944

Epoch: 5| Step: 3
Training loss: 0.49748820066452026
Validation loss: 1.905865023213048

Epoch: 5| Step: 4
Training loss: 0.7656590342521667
Validation loss: 1.8156842954697148

Epoch: 5| Step: 5
Training loss: 0.6306268572807312
Validation loss: 1.8436422783841369

Epoch: 5| Step: 6
Training loss: 0.9149383306503296
Validation loss: 1.83324126274355

Epoch: 5| Step: 7
Training loss: 0.7072504758834839
Validation loss: 1.8105591484295425

Epoch: 5| Step: 8
Training loss: 0.45751476287841797
Validation loss: 1.8525208580878474

Epoch: 5| Step: 9
Training loss: 0.8774030804634094
Validation loss: 1.8777946169658373

Epoch: 5| Step: 10
Training loss: 0.629928708076477
Validation loss: 1.7831219832102458

Epoch: 753| Step: 0
Training loss: 0.7413870096206665
Validation loss: 1.8512123515529018

Epoch: 5| Step: 1
Training loss: 0.8807204961776733
Validation loss: 1.855708122253418

Epoch: 5| Step: 2
Training loss: 0.3900712728500366
Validation loss: 1.8697017867078063

Epoch: 5| Step: 3
Training loss: 0.725247859954834
Validation loss: 1.8717869789369646

Epoch: 5| Step: 4
Training loss: 1.076553225517273
Validation loss: 1.8632047548088977

Epoch: 5| Step: 5
Training loss: 0.7712620496749878
Validation loss: 1.835189878299672

Epoch: 5| Step: 6
Training loss: 0.5842717289924622
Validation loss: 1.8491733202370264

Epoch: 5| Step: 7
Training loss: 0.6563794016838074
Validation loss: 1.903090997408795

Epoch: 5| Step: 8
Training loss: 0.9519704580307007
Validation loss: 1.8385385826069822

Epoch: 5| Step: 9
Training loss: 0.7515605092048645
Validation loss: 1.878601481837611

Epoch: 5| Step: 10
Training loss: 0.5456839799880981
Validation loss: 1.860641324391929

Epoch: 754| Step: 0
Training loss: 0.7973929047584534
Validation loss: 1.8489484428077616

Epoch: 5| Step: 1
Training loss: 0.3652898371219635
Validation loss: 1.7432200703569638

Epoch: 5| Step: 2
Training loss: 0.831421971321106
Validation loss: 1.7967509710660545

Epoch: 5| Step: 3
Training loss: 0.7513513565063477
Validation loss: 1.8307447125834804

Epoch: 5| Step: 4
Training loss: 1.0583430528640747
Validation loss: 1.8278412998363536

Epoch: 5| Step: 5
Training loss: 0.5674063563346863
Validation loss: 1.8336075531539096

Epoch: 5| Step: 6
Training loss: 0.6384361982345581
Validation loss: 1.7557985628804853

Epoch: 5| Step: 7
Training loss: 0.6048769354820251
Validation loss: 1.8180771720024846

Epoch: 5| Step: 8
Training loss: 0.7852435111999512
Validation loss: 1.8360263839844735

Epoch: 5| Step: 9
Training loss: 0.6238924860954285
Validation loss: 1.8893427541179042

Epoch: 5| Step: 10
Training loss: 0.8044625520706177
Validation loss: 1.807901220936929

Epoch: 755| Step: 0
Training loss: 0.5405194163322449
Validation loss: 1.870740790520945

Epoch: 5| Step: 1
Training loss: 0.9625319242477417
Validation loss: 1.8401729791395125

Epoch: 5| Step: 2
Training loss: 0.4198581576347351
Validation loss: 1.819870271990376

Epoch: 5| Step: 3
Training loss: 0.8742388486862183
Validation loss: 1.9116790730466124

Epoch: 5| Step: 4
Training loss: 0.5720992684364319
Validation loss: 1.8877293012475456

Epoch: 5| Step: 5
Training loss: 0.5183149576187134
Validation loss: 1.8844308340421287

Epoch: 5| Step: 6
Training loss: 0.6684665083885193
Validation loss: 1.819453357368387

Epoch: 5| Step: 7
Training loss: 0.533344030380249
Validation loss: 1.8242486394861692

Epoch: 5| Step: 8
Training loss: 0.39211541414260864
Validation loss: 1.8238688233078166

Epoch: 5| Step: 9
Training loss: 0.8231499791145325
Validation loss: 1.8142724472989318

Epoch: 5| Step: 10
Training loss: 1.2154226303100586
Validation loss: 1.7713255536171697

Epoch: 756| Step: 0
Training loss: 0.5711600184440613
Validation loss: 1.8471923156451153

Epoch: 5| Step: 1
Training loss: 0.9591374397277832
Validation loss: 1.7983979589195662

Epoch: 5| Step: 2
Training loss: 0.5417805910110474
Validation loss: 1.8210128404760872

Epoch: 5| Step: 3
Training loss: 1.000889778137207
Validation loss: 1.8385436316972137

Epoch: 5| Step: 4
Training loss: 0.47033295035362244
Validation loss: 1.814550240834554

Epoch: 5| Step: 5
Training loss: 0.5241482853889465
Validation loss: 1.8116952334680865

Epoch: 5| Step: 6
Training loss: 0.7238426208496094
Validation loss: 1.8462369903441398

Epoch: 5| Step: 7
Training loss: 0.5584820508956909
Validation loss: 1.8791388696239841

Epoch: 5| Step: 8
Training loss: 1.108459711074829
Validation loss: 1.833987941024124

Epoch: 5| Step: 9
Training loss: 0.7957186698913574
Validation loss: 1.8806342040338824

Epoch: 5| Step: 10
Training loss: 0.5356643795967102
Validation loss: 1.8755453158450384

Epoch: 757| Step: 0
Training loss: 0.4875568449497223
Validation loss: 1.810908240656699

Epoch: 5| Step: 1
Training loss: 0.639840304851532
Validation loss: 1.8419408247035036

Epoch: 5| Step: 2
Training loss: 0.7316420674324036
Validation loss: 1.8521644094938874

Epoch: 5| Step: 3
Training loss: 0.6640601754188538
Validation loss: 1.778796495929841

Epoch: 5| Step: 4
Training loss: 0.4906145930290222
Validation loss: 1.8267111880804903

Epoch: 5| Step: 5
Training loss: 0.7476234436035156
Validation loss: 1.840309314830329

Epoch: 5| Step: 6
Training loss: 1.0978902578353882
Validation loss: 1.8818776876695695

Epoch: 5| Step: 7
Training loss: 0.699569582939148
Validation loss: 1.8908908649157452

Epoch: 5| Step: 8
Training loss: 0.5053596496582031
Validation loss: 1.8403711459969962

Epoch: 5| Step: 9
Training loss: 0.8194286227226257
Validation loss: 1.8484040075732815

Epoch: 5| Step: 10
Training loss: 0.568914532661438
Validation loss: 1.8604356742674304

Epoch: 758| Step: 0
Training loss: 0.4450129568576813
Validation loss: 1.916490400991132

Epoch: 5| Step: 1
Training loss: 1.0220787525177002
Validation loss: 1.9006737637263473

Epoch: 5| Step: 2
Training loss: 0.6608090400695801
Validation loss: 1.8356926877011535

Epoch: 5| Step: 3
Training loss: 0.6028863787651062
Validation loss: 1.843932851668327

Epoch: 5| Step: 4
Training loss: 0.513031005859375
Validation loss: 1.8599468097891858

Epoch: 5| Step: 5
Training loss: 0.6070245504379272
Validation loss: 1.888867993508616

Epoch: 5| Step: 6
Training loss: 0.7565469741821289
Validation loss: 1.8269497053597563

Epoch: 5| Step: 7
Training loss: 0.72282874584198
Validation loss: 1.7664600623551237

Epoch: 5| Step: 8
Training loss: 0.9589764475822449
Validation loss: 1.8255023251297653

Epoch: 5| Step: 9
Training loss: 0.6249321699142456
Validation loss: 1.8238740428801505

Epoch: 5| Step: 10
Training loss: 0.8905128240585327
Validation loss: 1.8402604345352418

Epoch: 759| Step: 0
Training loss: 0.540494978427887
Validation loss: 1.8012715590897428

Epoch: 5| Step: 1
Training loss: 1.2604418992996216
Validation loss: 1.8819676419740081

Epoch: 5| Step: 2
Training loss: 0.811486542224884
Validation loss: 1.7880345467598207

Epoch: 5| Step: 3
Training loss: 0.8429850339889526
Validation loss: 1.8255368740327897

Epoch: 5| Step: 4
Training loss: 0.4288352131843567
Validation loss: 1.866459463232307

Epoch: 5| Step: 5
Training loss: 0.611906886100769
Validation loss: 1.7787091860207178

Epoch: 5| Step: 6
Training loss: 0.5664252638816833
Validation loss: 1.8133319552226732

Epoch: 5| Step: 7
Training loss: 0.41528692841529846
Validation loss: 1.8485479931677542

Epoch: 5| Step: 8
Training loss: 0.5479321479797363
Validation loss: 1.8549306572124522

Epoch: 5| Step: 9
Training loss: 1.2266255617141724
Validation loss: 1.8705418391894268

Epoch: 5| Step: 10
Training loss: 0.35476598143577576
Validation loss: 1.871277347687752

Epoch: 760| Step: 0
Training loss: 0.8877642750740051
Validation loss: 1.851262838609757

Epoch: 5| Step: 1
Training loss: 1.1790004968643188
Validation loss: 1.8644346678128807

Epoch: 5| Step: 2
Training loss: 0.6276071071624756
Validation loss: 1.8535681514329807

Epoch: 5| Step: 3
Training loss: 0.59430330991745
Validation loss: 1.8446756857697681

Epoch: 5| Step: 4
Training loss: 0.667395293712616
Validation loss: 1.8405293572333552

Epoch: 5| Step: 5
Training loss: 0.9050151705741882
Validation loss: 1.7851243595923147

Epoch: 5| Step: 6
Training loss: 0.3949551582336426
Validation loss: 1.8271276002289147

Epoch: 5| Step: 7
Training loss: 0.7127987146377563
Validation loss: 1.773514296418877

Epoch: 5| Step: 8
Training loss: 0.5593999624252319
Validation loss: 1.8095679821506623

Epoch: 5| Step: 9
Training loss: 0.4780200123786926
Validation loss: 1.806413250584756

Epoch: 5| Step: 10
Training loss: 0.38022446632385254
Validation loss: 1.7850084086900115

Epoch: 761| Step: 0
Training loss: 0.4415300488471985
Validation loss: 1.7474301194631925

Epoch: 5| Step: 1
Training loss: 0.5741980075836182
Validation loss: 1.8381627592989194

Epoch: 5| Step: 2
Training loss: 0.5169376134872437
Validation loss: 1.920388711396084

Epoch: 5| Step: 3
Training loss: 0.8485575914382935
Validation loss: 1.8600935641155447

Epoch: 5| Step: 4
Training loss: 0.8395349383354187
Validation loss: 1.9001536600051387

Epoch: 5| Step: 5
Training loss: 0.610781192779541
Validation loss: 1.8770868137318601

Epoch: 5| Step: 6
Training loss: 0.5959566235542297
Validation loss: 1.8626247836697487

Epoch: 5| Step: 7
Training loss: 0.5871109366416931
Validation loss: 1.8630071942524244

Epoch: 5| Step: 8
Training loss: 0.7591785788536072
Validation loss: 1.841177845513949

Epoch: 5| Step: 9
Training loss: 0.6859311461448669
Validation loss: 1.847775229843714

Epoch: 5| Step: 10
Training loss: 0.8878575563430786
Validation loss: 1.8347704102916103

Epoch: 762| Step: 0
Training loss: 0.40735673904418945
Validation loss: 1.869909285217203

Epoch: 5| Step: 1
Training loss: 0.4781249165534973
Validation loss: 1.8462837549947924

Epoch: 5| Step: 2
Training loss: 0.6795531511306763
Validation loss: 1.8168321578733382

Epoch: 5| Step: 3
Training loss: 0.4634064733982086
Validation loss: 1.81176132540549

Epoch: 5| Step: 4
Training loss: 0.8706120252609253
Validation loss: 1.817800816669259

Epoch: 5| Step: 5
Training loss: 1.342002272605896
Validation loss: 1.826924285581035

Epoch: 5| Step: 6
Training loss: 0.4953426718711853
Validation loss: 1.8148418889250806

Epoch: 5| Step: 7
Training loss: 0.6390610933303833
Validation loss: 1.8313658724548996

Epoch: 5| Step: 8
Training loss: 0.65309077501297
Validation loss: 1.846590704815362

Epoch: 5| Step: 9
Training loss: 0.8044487237930298
Validation loss: 1.893784289718956

Epoch: 5| Step: 10
Training loss: 0.599933922290802
Validation loss: 1.8256560564041138

Epoch: 763| Step: 0
Training loss: 0.8426200747489929
Validation loss: 1.8226301477801414

Epoch: 5| Step: 1
Training loss: 0.7484179735183716
Validation loss: 1.8016903361966532

Epoch: 5| Step: 2
Training loss: 0.43753281235694885
Validation loss: 1.8823405683681529

Epoch: 5| Step: 3
Training loss: 0.6259168386459351
Validation loss: 1.8037455851031887

Epoch: 5| Step: 4
Training loss: 0.6810084581375122
Validation loss: 1.8360393739515735

Epoch: 5| Step: 5
Training loss: 0.5710073709487915
Validation loss: 1.8111672901338147

Epoch: 5| Step: 6
Training loss: 0.6032447814941406
Validation loss: 1.8586627232131137

Epoch: 5| Step: 7
Training loss: 0.4436357617378235
Validation loss: 1.8191815217336018

Epoch: 5| Step: 8
Training loss: 1.2316577434539795
Validation loss: 1.8038041271189207

Epoch: 5| Step: 9
Training loss: 0.6967121362686157
Validation loss: 1.815821006733884

Epoch: 5| Step: 10
Training loss: 0.6355100870132446
Validation loss: 1.856304694247502

Epoch: 764| Step: 0
Training loss: 0.7405564188957214
Validation loss: 1.8648384194220267

Epoch: 5| Step: 1
Training loss: 0.5560678243637085
Validation loss: 1.8365721664121073

Epoch: 5| Step: 2
Training loss: 1.2444759607315063
Validation loss: 1.8034449854204733

Epoch: 5| Step: 3
Training loss: 0.6868245601654053
Validation loss: 1.8350892554047287

Epoch: 5| Step: 4
Training loss: 0.3795211911201477
Validation loss: 1.772500697002616

Epoch: 5| Step: 5
Training loss: 0.893288254737854
Validation loss: 1.805660113211601

Epoch: 5| Step: 6
Training loss: 0.5146461129188538
Validation loss: 1.805798239605401

Epoch: 5| Step: 7
Training loss: 0.33344948291778564
Validation loss: 1.882153586674762

Epoch: 5| Step: 8
Training loss: 0.642673909664154
Validation loss: 1.8083946948410363

Epoch: 5| Step: 9
Training loss: 0.9514206647872925
Validation loss: 1.8687301989524596

Epoch: 5| Step: 10
Training loss: 0.5535590052604675
Validation loss: 1.787846040982072

Epoch: 765| Step: 0
Training loss: 0.4386548101902008
Validation loss: 1.761789192435562

Epoch: 5| Step: 1
Training loss: 0.5677204728126526
Validation loss: 1.8781979135287705

Epoch: 5| Step: 2
Training loss: 0.6690710783004761
Validation loss: 1.8345498602877381

Epoch: 5| Step: 3
Training loss: 0.7492605447769165
Validation loss: 1.865466961296656

Epoch: 5| Step: 4
Training loss: 0.7746198773384094
Validation loss: 1.8504563172658284

Epoch: 5| Step: 5
Training loss: 0.8427068591117859
Validation loss: 1.8541844839690833

Epoch: 5| Step: 6
Training loss: 0.9176250696182251
Validation loss: 1.824351623494138

Epoch: 5| Step: 7
Training loss: 0.5426501631736755
Validation loss: 1.8095924162095594

Epoch: 5| Step: 8
Training loss: 0.8969331979751587
Validation loss: 1.8325670585837415

Epoch: 5| Step: 9
Training loss: 0.522943913936615
Validation loss: 1.8390089581089635

Epoch: 5| Step: 10
Training loss: 0.4308353364467621
Validation loss: 1.7694464101586291

Epoch: 766| Step: 0
Training loss: 0.6855941414833069
Validation loss: 1.8513304764224636

Epoch: 5| Step: 1
Training loss: 0.6710844039916992
Validation loss: 1.7562160453488749

Epoch: 5| Step: 2
Training loss: 0.678449273109436
Validation loss: 1.802075191210675

Epoch: 5| Step: 3
Training loss: 0.3877085745334625
Validation loss: 1.8325539045436408

Epoch: 5| Step: 4
Training loss: 0.8314746022224426
Validation loss: 1.855986002952822

Epoch: 5| Step: 5
Training loss: 0.7155938744544983
Validation loss: 1.8543948691378358

Epoch: 5| Step: 6
Training loss: 0.6508536338806152
Validation loss: 1.8419338759555612

Epoch: 5| Step: 7
Training loss: 0.5636261701583862
Validation loss: 1.7907339103760258

Epoch: 5| Step: 8
Training loss: 0.540534496307373
Validation loss: 1.8104592651449225

Epoch: 5| Step: 9
Training loss: 0.7840129137039185
Validation loss: 1.797307901484992

Epoch: 5| Step: 10
Training loss: 0.6312794089317322
Validation loss: 1.784078981286736

Epoch: 767| Step: 0
Training loss: 0.8865829706192017
Validation loss: 1.80737720253647

Epoch: 5| Step: 1
Training loss: 0.6104143857955933
Validation loss: 1.842415750667613

Epoch: 5| Step: 2
Training loss: 0.9822196960449219
Validation loss: 1.8401848680229598

Epoch: 5| Step: 3
Training loss: 0.39907413721084595
Validation loss: 1.7797841525846911

Epoch: 5| Step: 4
Training loss: 0.9520305395126343
Validation loss: 1.8356804873353691

Epoch: 5| Step: 5
Training loss: 0.6341145038604736
Validation loss: 1.8159587562725108

Epoch: 5| Step: 6
Training loss: 0.9014131426811218
Validation loss: 1.8518589196666595

Epoch: 5| Step: 7
Training loss: 0.5049434900283813
Validation loss: 1.8782787758816955

Epoch: 5| Step: 8
Training loss: 0.3867446780204773
Validation loss: 1.842829555593511

Epoch: 5| Step: 9
Training loss: 0.5852400660514832
Validation loss: 1.8229605715761903

Epoch: 5| Step: 10
Training loss: 0.6337237358093262
Validation loss: 1.8046778619930308

Epoch: 768| Step: 0
Training loss: 0.583457350730896
Validation loss: 1.771901088376199

Epoch: 5| Step: 1
Training loss: 0.6929658651351929
Validation loss: 1.8215338389078777

Epoch: 5| Step: 2
Training loss: 0.6256726980209351
Validation loss: 1.8191003389255975

Epoch: 5| Step: 3
Training loss: 0.4930781424045563
Validation loss: 1.8143832042653074

Epoch: 5| Step: 4
Training loss: 0.9532383680343628
Validation loss: 1.8164470054770028

Epoch: 5| Step: 5
Training loss: 0.9737924337387085
Validation loss: 1.761204828498184

Epoch: 5| Step: 6
Training loss: 0.43776410818099976
Validation loss: 1.7341203048665037

Epoch: 5| Step: 7
Training loss: 0.652084469795227
Validation loss: 1.764433730033136

Epoch: 5| Step: 8
Training loss: 0.8280689120292664
Validation loss: 1.8154239962177892

Epoch: 5| Step: 9
Training loss: 0.3640325367450714
Validation loss: 1.7689634317992835

Epoch: 5| Step: 10
Training loss: 0.6953023672103882
Validation loss: 1.810053421605018

Epoch: 769| Step: 0
Training loss: 0.3605949282646179
Validation loss: 1.8096073442889797

Epoch: 5| Step: 1
Training loss: 0.6959657669067383
Validation loss: 1.7545735823210848

Epoch: 5| Step: 2
Training loss: 0.5642155408859253
Validation loss: 1.7789615866958455

Epoch: 5| Step: 3
Training loss: 1.0956417322158813
Validation loss: 1.8425378831483985

Epoch: 5| Step: 4
Training loss: 0.659420371055603
Validation loss: 1.8213215515177736

Epoch: 5| Step: 5
Training loss: 0.7906031608581543
Validation loss: 1.9014321706628288

Epoch: 5| Step: 6
Training loss: 0.7451245188713074
Validation loss: 1.8680537567343762

Epoch: 5| Step: 7
Training loss: 0.49974697828292847
Validation loss: 1.833547310162616

Epoch: 5| Step: 8
Training loss: 1.1129363775253296
Validation loss: 1.8486838750941779

Epoch: 5| Step: 9
Training loss: 0.40972909331321716
Validation loss: 1.8160209232761013

Epoch: 5| Step: 10
Training loss: 0.3052426874637604
Validation loss: 1.8195267146633518

Epoch: 770| Step: 0
Training loss: 0.282553106546402
Validation loss: 1.8213832968024797

Epoch: 5| Step: 1
Training loss: 0.9394515156745911
Validation loss: 1.8233055107055172

Epoch: 5| Step: 2
Training loss: 0.5354026556015015
Validation loss: 1.8211076298067648

Epoch: 5| Step: 3
Training loss: 0.5618160963058472
Validation loss: 1.8006861748233918

Epoch: 5| Step: 4
Training loss: 1.0220204591751099
Validation loss: 1.7621879603273125

Epoch: 5| Step: 5
Training loss: 0.751980721950531
Validation loss: 1.8790008034757388

Epoch: 5| Step: 6
Training loss: 0.9518316984176636
Validation loss: 1.807712447258734

Epoch: 5| Step: 7
Training loss: 0.3050592839717865
Validation loss: 1.8296627081850523

Epoch: 5| Step: 8
Training loss: 0.6819024682044983
Validation loss: 1.7961868521987752

Epoch: 5| Step: 9
Training loss: 0.7716084718704224
Validation loss: 1.8214803075277677

Epoch: 5| Step: 10
Training loss: 0.5500013828277588
Validation loss: 1.8050848835258073

Epoch: 771| Step: 0
Training loss: 0.5821393728256226
Validation loss: 1.8142426475401847

Epoch: 5| Step: 1
Training loss: 0.5915632247924805
Validation loss: 1.8561935450441094

Epoch: 5| Step: 2
Training loss: 0.8742826581001282
Validation loss: 1.8589376993076776

Epoch: 5| Step: 3
Training loss: 0.776355504989624
Validation loss: 1.830557333525791

Epoch: 5| Step: 4
Training loss: 0.4838915467262268
Validation loss: 1.8332744823989047

Epoch: 5| Step: 5
Training loss: 0.6201434135437012
Validation loss: 1.8877563989290627

Epoch: 5| Step: 6
Training loss: 0.5476007461547852
Validation loss: 1.8521882641700007

Epoch: 5| Step: 7
Training loss: 0.5097606778144836
Validation loss: 1.800239025905568

Epoch: 5| Step: 8
Training loss: 0.7492868304252625
Validation loss: 1.8067084794403405

Epoch: 5| Step: 9
Training loss: 1.3827553987503052
Validation loss: 1.8447914841354534

Epoch: 5| Step: 10
Training loss: 0.4337185025215149
Validation loss: 1.8123117890409244

Epoch: 772| Step: 0
Training loss: 0.5064502954483032
Validation loss: 1.8221351177461687

Epoch: 5| Step: 1
Training loss: 0.45795679092407227
Validation loss: 1.8218120708260486

Epoch: 5| Step: 2
Training loss: 0.6644967794418335
Validation loss: 1.786417124091938

Epoch: 5| Step: 3
Training loss: 1.0160505771636963
Validation loss: 1.8204809734898229

Epoch: 5| Step: 4
Training loss: 0.4599215090274811
Validation loss: 1.7936684213658816

Epoch: 5| Step: 5
Training loss: 0.4977802634239197
Validation loss: 1.8464556432539416

Epoch: 5| Step: 6
Training loss: 0.7746092677116394
Validation loss: 1.855095266014017

Epoch: 5| Step: 7
Training loss: 1.1030175685882568
Validation loss: 1.8147436265022523

Epoch: 5| Step: 8
Training loss: 0.826803982257843
Validation loss: 1.845600684483846

Epoch: 5| Step: 9
Training loss: 0.40562209486961365
Validation loss: 1.7863970841130903

Epoch: 5| Step: 10
Training loss: 0.4565422534942627
Validation loss: 1.8513103223616076

Epoch: 773| Step: 0
Training loss: 1.1648879051208496
Validation loss: 1.857843368284164

Epoch: 5| Step: 1
Training loss: 0.38612884283065796
Validation loss: 1.8820543314820977

Epoch: 5| Step: 2
Training loss: 0.6662157773971558
Validation loss: 1.859912553141194

Epoch: 5| Step: 3
Training loss: 0.6339858174324036
Validation loss: 1.832120313439318

Epoch: 5| Step: 4
Training loss: 0.7541306614875793
Validation loss: 1.756578900480783

Epoch: 5| Step: 5
Training loss: 0.720186710357666
Validation loss: 1.8167632010675245

Epoch: 5| Step: 6
Training loss: 0.9867383241653442
Validation loss: 1.7760858305038945

Epoch: 5| Step: 7
Training loss: 0.5728995203971863
Validation loss: 1.7392922973120084

Epoch: 5| Step: 8
Training loss: 0.3564022183418274
Validation loss: 1.8109050527695687

Epoch: 5| Step: 9
Training loss: 0.6560903787612915
Validation loss: 1.822300773794933

Epoch: 5| Step: 10
Training loss: 0.5358940958976746
Validation loss: 1.7871475796545706

Epoch: 774| Step: 0
Training loss: 0.5139575004577637
Validation loss: 1.8099786055985319

Epoch: 5| Step: 1
Training loss: 0.6156406402587891
Validation loss: 1.817038805254044

Epoch: 5| Step: 2
Training loss: 0.4295133948326111
Validation loss: 1.7504482833288049

Epoch: 5| Step: 3
Training loss: 0.46942561864852905
Validation loss: 1.7939113827161892

Epoch: 5| Step: 4
Training loss: 0.4447402060031891
Validation loss: 1.8490298460888606

Epoch: 5| Step: 5
Training loss: 0.5928133726119995
Validation loss: 1.7748274636524979

Epoch: 5| Step: 6
Training loss: 1.0687240362167358
Validation loss: 1.814494712378389

Epoch: 5| Step: 7
Training loss: 0.7043002247810364
Validation loss: 1.8469440539677937

Epoch: 5| Step: 8
Training loss: 0.7617009878158569
Validation loss: 1.827077216999505

Epoch: 5| Step: 9
Training loss: 0.6167689561843872
Validation loss: 1.8330864137218845

Epoch: 5| Step: 10
Training loss: 0.7256899476051331
Validation loss: 1.8272392083239812

Epoch: 775| Step: 0
Training loss: 0.8347969055175781
Validation loss: 1.829456861301135

Epoch: 5| Step: 1
Training loss: 0.8405817151069641
Validation loss: 1.8360922721124464

Epoch: 5| Step: 2
Training loss: 0.5393792390823364
Validation loss: 1.8727628146448443

Epoch: 5| Step: 3
Training loss: 0.32169321179389954
Validation loss: 1.7970952680034022

Epoch: 5| Step: 4
Training loss: 0.5787355303764343
Validation loss: 1.8155781440837409

Epoch: 5| Step: 5
Training loss: 0.6906890869140625
Validation loss: 1.8317606513218214

Epoch: 5| Step: 6
Training loss: 1.1781808137893677
Validation loss: 1.8321144837205128

Epoch: 5| Step: 7
Training loss: 0.5348936319351196
Validation loss: 1.795753530276719

Epoch: 5| Step: 8
Training loss: 0.8439537286758423
Validation loss: 1.7736732613655828

Epoch: 5| Step: 9
Training loss: 0.4714091718196869
Validation loss: 1.863032074384792

Epoch: 5| Step: 10
Training loss: 0.5733214020729065
Validation loss: 1.8220397477508874

Epoch: 776| Step: 0
Training loss: 1.0427207946777344
Validation loss: 1.7855814426176009

Epoch: 5| Step: 1
Training loss: 0.652752697467804
Validation loss: 1.8429090207622898

Epoch: 5| Step: 2
Training loss: 0.7614337205886841
Validation loss: 1.8666770060857136

Epoch: 5| Step: 3
Training loss: 0.6805867552757263
Validation loss: 1.861487696247716

Epoch: 5| Step: 4
Training loss: 0.5339490175247192
Validation loss: 1.7854950786918722

Epoch: 5| Step: 5
Training loss: 0.5774641036987305
Validation loss: 1.82965394502045

Epoch: 5| Step: 6
Training loss: 0.9850226640701294
Validation loss: 1.8496802904272591

Epoch: 5| Step: 7
Training loss: 0.41654425859451294
Validation loss: 1.8164674658929147

Epoch: 5| Step: 8
Training loss: 0.4100955128669739
Validation loss: 1.803056768191758

Epoch: 5| Step: 9
Training loss: 0.5466318726539612
Validation loss: 1.7908473745469125

Epoch: 5| Step: 10
Training loss: 0.6254525780677795
Validation loss: 1.799000265777752

Epoch: 777| Step: 0
Training loss: 0.7357004880905151
Validation loss: 1.884971103360576

Epoch: 5| Step: 1
Training loss: 0.6980851888656616
Validation loss: 1.7640362760072112

Epoch: 5| Step: 2
Training loss: 0.6221423149108887
Validation loss: 1.7970789568398589

Epoch: 5| Step: 3
Training loss: 0.5083633661270142
Validation loss: 1.78225875413546

Epoch: 5| Step: 4
Training loss: 0.6661345362663269
Validation loss: 1.7682651063447357

Epoch: 5| Step: 5
Training loss: 0.6160567998886108
Validation loss: 1.8423395567042853

Epoch: 5| Step: 6
Training loss: 0.8329414129257202
Validation loss: 1.7916746242071993

Epoch: 5| Step: 7
Training loss: 0.7668904066085815
Validation loss: 1.799440517220446

Epoch: 5| Step: 8
Training loss: 0.37247234582901
Validation loss: 1.8583805561065674

Epoch: 5| Step: 9
Training loss: 0.5701984167098999
Validation loss: 1.8348534004662627

Epoch: 5| Step: 10
Training loss: 0.8302874565124512
Validation loss: 1.791825279112785

Epoch: 778| Step: 0
Training loss: 0.9210597276687622
Validation loss: 1.8468713580921132

Epoch: 5| Step: 1
Training loss: 0.464343398809433
Validation loss: 1.8776270087047289

Epoch: 5| Step: 2
Training loss: 0.4062449336051941
Validation loss: 1.9056339007551952

Epoch: 5| Step: 3
Training loss: 0.5649275779724121
Validation loss: 1.8769201655541696

Epoch: 5| Step: 4
Training loss: 0.6584367752075195
Validation loss: 1.789519565079802

Epoch: 5| Step: 5
Training loss: 0.6887311935424805
Validation loss: 1.83241561407684

Epoch: 5| Step: 6
Training loss: 0.792641818523407
Validation loss: 1.8566809674744964

Epoch: 5| Step: 7
Training loss: 1.0860002040863037
Validation loss: 1.7897006926998016

Epoch: 5| Step: 8
Training loss: 0.8162800669670105
Validation loss: 1.8193395688969602

Epoch: 5| Step: 9
Training loss: 0.4438038766384125
Validation loss: 1.7868812058561592

Epoch: 5| Step: 10
Training loss: 0.6337831020355225
Validation loss: 1.8232440346030778

Epoch: 779| Step: 0
Training loss: 0.48559632897377014
Validation loss: 1.8390246828397114

Epoch: 5| Step: 1
Training loss: 0.6858140826225281
Validation loss: 1.831130721235788

Epoch: 5| Step: 2
Training loss: 0.57989501953125
Validation loss: 1.7683510011242283

Epoch: 5| Step: 3
Training loss: 0.5058827996253967
Validation loss: 1.7930814143150084

Epoch: 5| Step: 4
Training loss: 0.6941319704055786
Validation loss: 1.8194294180921329

Epoch: 5| Step: 5
Training loss: 0.9412199854850769
Validation loss: 1.7997129950472104

Epoch: 5| Step: 6
Training loss: 0.7311049699783325
Validation loss: 1.7805169102966145

Epoch: 5| Step: 7
Training loss: 0.683917760848999
Validation loss: 1.8534351305295063

Epoch: 5| Step: 8
Training loss: 0.42781490087509155
Validation loss: 1.819689182824986

Epoch: 5| Step: 9
Training loss: 0.3958341181278229
Validation loss: 1.8548789537081154

Epoch: 5| Step: 10
Training loss: 1.1235151290893555
Validation loss: 1.7961955519132717

Epoch: 780| Step: 0
Training loss: 0.5376259088516235
Validation loss: 1.8547174840845086

Epoch: 5| Step: 1
Training loss: 0.8177559971809387
Validation loss: 1.7880555865585164

Epoch: 5| Step: 2
Training loss: 0.4719943404197693
Validation loss: 1.8216440780188448

Epoch: 5| Step: 3
Training loss: 0.5623528361320496
Validation loss: 1.8012750635864914

Epoch: 5| Step: 4
Training loss: 0.6547058820724487
Validation loss: 1.8078913765568887

Epoch: 5| Step: 5
Training loss: 0.7901607751846313
Validation loss: 1.8426206393908429

Epoch: 5| Step: 6
Training loss: 0.642086386680603
Validation loss: 1.831067778089995

Epoch: 5| Step: 7
Training loss: 0.7283010482788086
Validation loss: 1.8352858571596042

Epoch: 5| Step: 8
Training loss: 0.42166319489479065
Validation loss: 1.8253466339521511

Epoch: 5| Step: 9
Training loss: 0.8781963586807251
Validation loss: 1.843366951070806

Epoch: 5| Step: 10
Training loss: 0.7633833885192871
Validation loss: 1.8201590417533793

Epoch: 781| Step: 0
Training loss: 0.452976793050766
Validation loss: 1.8471276785737725

Epoch: 5| Step: 1
Training loss: 0.8124158978462219
Validation loss: 1.869901616086242

Epoch: 5| Step: 2
Training loss: 0.8503003120422363
Validation loss: 1.806476777599704

Epoch: 5| Step: 3
Training loss: 0.48687323927879333
Validation loss: 1.8011859681016655

Epoch: 5| Step: 4
Training loss: 0.7628761529922485
Validation loss: 1.8011014435880928

Epoch: 5| Step: 5
Training loss: 0.7108050584793091
Validation loss: 1.8139887676444104

Epoch: 5| Step: 6
Training loss: 0.9353516697883606
Validation loss: 1.780846376572886

Epoch: 5| Step: 7
Training loss: 0.5861829519271851
Validation loss: 1.7566378629335793

Epoch: 5| Step: 8
Training loss: 0.6869004964828491
Validation loss: 1.826558360489466

Epoch: 5| Step: 9
Training loss: 0.5073224306106567
Validation loss: 1.8103679226290794

Epoch: 5| Step: 10
Training loss: 0.39032530784606934
Validation loss: 1.7670384632643832

Epoch: 782| Step: 0
Training loss: 0.7107400298118591
Validation loss: 1.8038656051440904

Epoch: 5| Step: 1
Training loss: 0.3852686285972595
Validation loss: 1.8545307113278298

Epoch: 5| Step: 2
Training loss: 0.9257209897041321
Validation loss: 1.8520265676641976

Epoch: 5| Step: 3
Training loss: 0.4635912775993347
Validation loss: 1.8226564981604134

Epoch: 5| Step: 4
Training loss: 0.8317846059799194
Validation loss: 1.8055230391922819

Epoch: 5| Step: 5
Training loss: 0.7310922145843506
Validation loss: 1.849889927012946

Epoch: 5| Step: 6
Training loss: 0.6855555772781372
Validation loss: 1.8536261256023119

Epoch: 5| Step: 7
Training loss: 0.5551767349243164
Validation loss: 1.8337117587366412

Epoch: 5| Step: 8
Training loss: 0.9051211476325989
Validation loss: 1.785630069753175

Epoch: 5| Step: 9
Training loss: 0.6948859095573425
Validation loss: 1.8591319963496218

Epoch: 5| Step: 10
Training loss: 0.4546459913253784
Validation loss: 1.8620958661520353

Epoch: 783| Step: 0
Training loss: 0.4833250045776367
Validation loss: 1.7545085812127719

Epoch: 5| Step: 1
Training loss: 1.078187346458435
Validation loss: 1.8171561610314153

Epoch: 5| Step: 2
Training loss: 0.6589406728744507
Validation loss: 1.7318167532643964

Epoch: 5| Step: 3
Training loss: 0.5299315452575684
Validation loss: 1.8145137345919045

Epoch: 5| Step: 4
Training loss: 1.049440622329712
Validation loss: 1.8421418372020926

Epoch: 5| Step: 5
Training loss: 0.9246408343315125
Validation loss: 1.8011452895338818

Epoch: 5| Step: 6
Training loss: 0.45623669028282166
Validation loss: 1.8529058938385339

Epoch: 5| Step: 7
Training loss: 0.3323943018913269
Validation loss: 1.8178458380442795

Epoch: 5| Step: 8
Training loss: 0.7455852031707764
Validation loss: 1.8365914167896393

Epoch: 5| Step: 9
Training loss: 0.6320845484733582
Validation loss: 1.816984022817304

Epoch: 5| Step: 10
Training loss: 0.4056609272956848
Validation loss: 1.8060751345849806

Epoch: 784| Step: 0
Training loss: 0.5696765184402466
Validation loss: 1.8607580918137745

Epoch: 5| Step: 1
Training loss: 1.0244637727737427
Validation loss: 1.8584078665702575

Epoch: 5| Step: 2
Training loss: 0.49122387170791626
Validation loss: 1.8278643918293778

Epoch: 5| Step: 3
Training loss: 0.5232644081115723
Validation loss: 1.8370824372896584

Epoch: 5| Step: 4
Training loss: 0.5216385722160339
Validation loss: 1.808881293060959

Epoch: 5| Step: 5
Training loss: 0.5203484296798706
Validation loss: 1.8151514132817586

Epoch: 5| Step: 6
Training loss: 1.160400152206421
Validation loss: 1.7688875454728321

Epoch: 5| Step: 7
Training loss: 0.6214404106140137
Validation loss: 1.8568078369222663

Epoch: 5| Step: 8
Training loss: 0.362753301858902
Validation loss: 1.8136563019085956

Epoch: 5| Step: 9
Training loss: 0.8650733232498169
Validation loss: 1.8022786263496644

Epoch: 5| Step: 10
Training loss: 0.7769439816474915
Validation loss: 1.7808397444345618

Epoch: 785| Step: 0
Training loss: 1.0410568714141846
Validation loss: 1.81008997912048

Epoch: 5| Step: 1
Training loss: 0.564346432685852
Validation loss: 1.8023763036215177

Epoch: 5| Step: 2
Training loss: 0.6454989314079285
Validation loss: 1.8180573730058567

Epoch: 5| Step: 3
Training loss: 0.36272352933883667
Validation loss: 1.8399811931835708

Epoch: 5| Step: 4
Training loss: 1.0057225227355957
Validation loss: 1.7786491429933937

Epoch: 5| Step: 5
Training loss: 0.48783817887306213
Validation loss: 1.859347524181489

Epoch: 5| Step: 6
Training loss: 0.5193414092063904
Validation loss: 1.8674483619710451

Epoch: 5| Step: 7
Training loss: 0.9305592775344849
Validation loss: 1.8985725064431467

Epoch: 5| Step: 8
Training loss: 0.645658016204834
Validation loss: 1.8191806718867312

Epoch: 5| Step: 9
Training loss: 0.44261178374290466
Validation loss: 1.8273302778120963

Epoch: 5| Step: 10
Training loss: 0.6705787777900696
Validation loss: 1.7991978147978425

Epoch: 786| Step: 0
Training loss: 0.7279235124588013
Validation loss: 1.8573566944368425

Epoch: 5| Step: 1
Training loss: 0.31595176458358765
Validation loss: 1.8434658511992423

Epoch: 5| Step: 2
Training loss: 0.6859775185585022
Validation loss: 1.8218313519672682

Epoch: 5| Step: 3
Training loss: 0.5099890828132629
Validation loss: 1.8100361734308221

Epoch: 5| Step: 4
Training loss: 0.3676303029060364
Validation loss: 1.7923854294643606

Epoch: 5| Step: 5
Training loss: 1.0324621200561523
Validation loss: 1.7871236173055505

Epoch: 5| Step: 6
Training loss: 0.5188981294631958
Validation loss: 1.759010334168711

Epoch: 5| Step: 7
Training loss: 1.1203901767730713
Validation loss: 1.7718911145323066

Epoch: 5| Step: 8
Training loss: 0.8125913739204407
Validation loss: 1.815648336564341

Epoch: 5| Step: 9
Training loss: 0.7341769337654114
Validation loss: 1.7613453224141111

Epoch: 5| Step: 10
Training loss: 0.5208340883255005
Validation loss: 1.798437523585494

Epoch: 787| Step: 0
Training loss: 0.6725260019302368
Validation loss: 1.7823868387488908

Epoch: 5| Step: 1
Training loss: 0.7882548570632935
Validation loss: 1.8070405490936772

Epoch: 5| Step: 2
Training loss: 1.2944815158843994
Validation loss: 1.8430350031903995

Epoch: 5| Step: 3
Training loss: 0.7367235422134399
Validation loss: 1.7683193632351455

Epoch: 5| Step: 4
Training loss: 0.6747275590896606
Validation loss: 1.8302754791834022

Epoch: 5| Step: 5
Training loss: 0.5365034341812134
Validation loss: 1.853839990913227

Epoch: 5| Step: 6
Training loss: 0.44549912214279175
Validation loss: 1.8091770269537484

Epoch: 5| Step: 7
Training loss: 0.4578893780708313
Validation loss: 1.7776597187083254

Epoch: 5| Step: 8
Training loss: 0.5118330717086792
Validation loss: 1.8137916288068217

Epoch: 5| Step: 9
Training loss: 0.4374641478061676
Validation loss: 1.8338737769793438

Epoch: 5| Step: 10
Training loss: 0.7145639657974243
Validation loss: 1.7454655029440438

Epoch: 788| Step: 0
Training loss: 0.4738808572292328
Validation loss: 1.7738125349885674

Epoch: 5| Step: 1
Training loss: 0.5449578166007996
Validation loss: 1.76773283045779

Epoch: 5| Step: 2
Training loss: 0.276579350233078
Validation loss: 1.8416611622738581

Epoch: 5| Step: 3
Training loss: 0.6225786209106445
Validation loss: 1.831272586699455

Epoch: 5| Step: 4
Training loss: 0.6250077486038208
Validation loss: 1.8163071191439064

Epoch: 5| Step: 5
Training loss: 0.5642403364181519
Validation loss: 1.770727534447947

Epoch: 5| Step: 6
Training loss: 0.9535549283027649
Validation loss: 1.861143413410392

Epoch: 5| Step: 7
Training loss: 0.613106906414032
Validation loss: 1.7764140918690672

Epoch: 5| Step: 8
Training loss: 0.7053413987159729
Validation loss: 1.8002637240194506

Epoch: 5| Step: 9
Training loss: 1.1957546472549438
Validation loss: 1.8130901026469406

Epoch: 5| Step: 10
Training loss: 0.611879825592041
Validation loss: 1.8348979462859452

Epoch: 789| Step: 0
Training loss: 0.7208935618400574
Validation loss: 1.74617689142945

Epoch: 5| Step: 1
Training loss: 0.737950325012207
Validation loss: 1.8125616735027683

Epoch: 5| Step: 2
Training loss: 0.9339640736579895
Validation loss: 1.7544983817685036

Epoch: 5| Step: 3
Training loss: 0.7053497433662415
Validation loss: 1.8124258966856106

Epoch: 5| Step: 4
Training loss: 0.5349210500717163
Validation loss: 1.8350544488558205

Epoch: 5| Step: 5
Training loss: 0.883095920085907
Validation loss: 1.8494576408017067

Epoch: 5| Step: 6
Training loss: 0.474759966135025
Validation loss: 1.8605947225324568

Epoch: 5| Step: 7
Training loss: 0.5889959335327148
Validation loss: 1.86961502926324

Epoch: 5| Step: 8
Training loss: 0.3323182463645935
Validation loss: 1.838921723827239

Epoch: 5| Step: 9
Training loss: 0.8111773729324341
Validation loss: 1.8415998656262633

Epoch: 5| Step: 10
Training loss: 0.5427345633506775
Validation loss: 1.7928645956900813

Epoch: 790| Step: 0
Training loss: 0.790194034576416
Validation loss: 1.8758694882033973

Epoch: 5| Step: 1
Training loss: 0.9030953645706177
Validation loss: 1.7804086644162413

Epoch: 5| Step: 2
Training loss: 0.6806572079658508
Validation loss: 1.8532304122883787

Epoch: 5| Step: 3
Training loss: 0.4606700539588928
Validation loss: 1.7788355260766961

Epoch: 5| Step: 4
Training loss: 0.6072208285331726
Validation loss: 1.7767334138193438

Epoch: 5| Step: 5
Training loss: 0.5691993832588196
Validation loss: 1.8276659801442137

Epoch: 5| Step: 6
Training loss: 0.5242099761962891
Validation loss: 1.8015739379390594

Epoch: 5| Step: 7
Training loss: 0.7408133745193481
Validation loss: 1.8219584739336403

Epoch: 5| Step: 8
Training loss: 0.49646568298339844
Validation loss: 1.7560527965586672

Epoch: 5| Step: 9
Training loss: 1.0021414756774902
Validation loss: 1.7658006196380944

Epoch: 5| Step: 10
Training loss: 0.40130865573883057
Validation loss: 1.8096130240348078

Epoch: 791| Step: 0
Training loss: 1.2583849430084229
Validation loss: 1.806173345094086

Epoch: 5| Step: 1
Training loss: 0.7530274391174316
Validation loss: 1.7914701225937053

Epoch: 5| Step: 2
Training loss: 0.6963456869125366
Validation loss: 1.7776351519810256

Epoch: 5| Step: 3
Training loss: 0.40803176164627075
Validation loss: 1.8141743931719052

Epoch: 5| Step: 4
Training loss: 0.8189235925674438
Validation loss: 1.8190598257126347

Epoch: 5| Step: 5
Training loss: 0.4953725337982178
Validation loss: 1.8239858227391397

Epoch: 5| Step: 6
Training loss: 0.9539848566055298
Validation loss: 1.897252518643615

Epoch: 5| Step: 7
Training loss: 0.6265517473220825
Validation loss: 1.8165798840984222

Epoch: 5| Step: 8
Training loss: 0.4636794626712799
Validation loss: 1.8181593520666963

Epoch: 5| Step: 9
Training loss: 0.6256722211837769
Validation loss: 1.802013026770725

Epoch: 5| Step: 10
Training loss: 0.852489709854126
Validation loss: 1.7659645029293594

Epoch: 792| Step: 0
Training loss: 0.6944774389266968
Validation loss: 1.7790565529177267

Epoch: 5| Step: 1
Training loss: 0.818985104560852
Validation loss: 1.7946030503960066

Epoch: 5| Step: 2
Training loss: 0.4031529426574707
Validation loss: 1.8394552020616428

Epoch: 5| Step: 3
Training loss: 0.41170692443847656
Validation loss: 1.835870700497781

Epoch: 5| Step: 4
Training loss: 1.2211066484451294
Validation loss: 1.7796232879802745

Epoch: 5| Step: 5
Training loss: 0.3799416720867157
Validation loss: 1.793327928871237

Epoch: 5| Step: 6
Training loss: 0.825064480304718
Validation loss: 1.8051866267317085

Epoch: 5| Step: 7
Training loss: 0.7023974657058716
Validation loss: 1.838931401570638

Epoch: 5| Step: 8
Training loss: 0.5670753121376038
Validation loss: 1.7354635346320368

Epoch: 5| Step: 9
Training loss: 0.5995086431503296
Validation loss: 1.8086612647579563

Epoch: 5| Step: 10
Training loss: 0.47859910130500793
Validation loss: 1.8497965399936964

Epoch: 793| Step: 0
Training loss: 0.7177454829216003
Validation loss: 1.8330655379961895

Epoch: 5| Step: 1
Training loss: 0.31479454040527344
Validation loss: 1.8128604145460232

Epoch: 5| Step: 2
Training loss: 1.027963399887085
Validation loss: 1.8331928355719453

Epoch: 5| Step: 3
Training loss: 0.5820674896240234
Validation loss: 1.7804668936678159

Epoch: 5| Step: 4
Training loss: 0.5283435583114624
Validation loss: 1.8252014216556345

Epoch: 5| Step: 5
Training loss: 0.48385900259017944
Validation loss: 1.8449876846805695

Epoch: 5| Step: 6
Training loss: 0.7703279852867126
Validation loss: 1.819261803421923

Epoch: 5| Step: 7
Training loss: 0.9047156572341919
Validation loss: 1.7972663730703375

Epoch: 5| Step: 8
Training loss: 0.4834797978401184
Validation loss: 1.805651068687439

Epoch: 5| Step: 9
Training loss: 0.502964973449707
Validation loss: 1.8328933126182967

Epoch: 5| Step: 10
Training loss: 0.8424928188323975
Validation loss: 1.8297807196135163

Epoch: 794| Step: 0
Training loss: 0.6972106695175171
Validation loss: 1.800273254353513

Epoch: 5| Step: 1
Training loss: 0.5181766748428345
Validation loss: 1.8698990088637157

Epoch: 5| Step: 2
Training loss: 1.1195788383483887
Validation loss: 1.8875585768812446

Epoch: 5| Step: 3
Training loss: 0.34586793184280396
Validation loss: 1.8422870635986328

Epoch: 5| Step: 4
Training loss: 0.6464732885360718
Validation loss: 1.8653203877069617

Epoch: 5| Step: 5
Training loss: 0.587262749671936
Validation loss: 1.833526579282617

Epoch: 5| Step: 6
Training loss: 1.095108985900879
Validation loss: 1.8401146883605628

Epoch: 5| Step: 7
Training loss: 0.44749078154563904
Validation loss: 1.8239556717616257

Epoch: 5| Step: 8
Training loss: 0.3818209767341614
Validation loss: 1.7743658545196697

Epoch: 5| Step: 9
Training loss: 0.4876405596733093
Validation loss: 1.7753546866037513

Epoch: 5| Step: 10
Training loss: 0.6833804845809937
Validation loss: 1.8128068370203818

Epoch: 795| Step: 0
Training loss: 0.5053664445877075
Validation loss: 1.8632613676850514

Epoch: 5| Step: 1
Training loss: 0.648106575012207
Validation loss: 1.7836097953140095

Epoch: 5| Step: 2
Training loss: 0.6797158122062683
Validation loss: 1.8238394709043606

Epoch: 5| Step: 3
Training loss: 0.6134707927703857
Validation loss: 1.7821491623437533

Epoch: 5| Step: 4
Training loss: 0.3543660044670105
Validation loss: 1.8609769100783973

Epoch: 5| Step: 5
Training loss: 0.8756966590881348
Validation loss: 1.8594696803759503

Epoch: 5| Step: 6
Training loss: 0.523457944393158
Validation loss: 1.8303334148981238

Epoch: 5| Step: 7
Training loss: 0.6484843492507935
Validation loss: 1.8446585901321904

Epoch: 5| Step: 8
Training loss: 0.68086838722229
Validation loss: 1.8110976026904198

Epoch: 5| Step: 9
Training loss: 0.9604629278182983
Validation loss: 1.7953020808517293

Epoch: 5| Step: 10
Training loss: 0.7529991269111633
Validation loss: 1.824964370778812

Epoch: 796| Step: 0
Training loss: 0.4697062075138092
Validation loss: 1.8374215582365632

Epoch: 5| Step: 1
Training loss: 0.3897000849246979
Validation loss: 1.7860417058390956

Epoch: 5| Step: 2
Training loss: 0.841423511505127
Validation loss: 1.746872946780215

Epoch: 5| Step: 3
Training loss: 1.0529229640960693
Validation loss: 1.873090531236382

Epoch: 5| Step: 4
Training loss: 0.4785528779029846
Validation loss: 1.8013372049536756

Epoch: 5| Step: 5
Training loss: 0.7090333700180054
Validation loss: 1.7795738315069547

Epoch: 5| Step: 6
Training loss: 0.8206853866577148
Validation loss: 1.767954364899666

Epoch: 5| Step: 7
Training loss: 0.80622398853302
Validation loss: 1.8340829290369505

Epoch: 5| Step: 8
Training loss: 0.3745861351490021
Validation loss: 1.8164866790976575

Epoch: 5| Step: 9
Training loss: 0.4365061819553375
Validation loss: 1.8095287097397672

Epoch: 5| Step: 10
Training loss: 0.5736135840415955
Validation loss: 1.7694336573282878

Epoch: 797| Step: 0
Training loss: 0.5651013255119324
Validation loss: 1.8296265140656502

Epoch: 5| Step: 1
Training loss: 0.6692327260971069
Validation loss: 1.7760337988535564

Epoch: 5| Step: 2
Training loss: 0.8126111030578613
Validation loss: 1.833040475845337

Epoch: 5| Step: 3
Training loss: 0.751937985420227
Validation loss: 1.8118214222692675

Epoch: 5| Step: 4
Training loss: 0.4326171875
Validation loss: 1.8225284071378811

Epoch: 5| Step: 5
Training loss: 0.5698294639587402
Validation loss: 1.7783401473875968

Epoch: 5| Step: 6
Training loss: 0.3909074068069458
Validation loss: 1.804908065385716

Epoch: 5| Step: 7
Training loss: 0.6161428689956665
Validation loss: 1.8375772994051698

Epoch: 5| Step: 8
Training loss: 0.5387859344482422
Validation loss: 1.8449766917895245

Epoch: 5| Step: 9
Training loss: 0.6334069967269897
Validation loss: 1.8432830982310797

Epoch: 5| Step: 10
Training loss: 0.6770308613777161
Validation loss: 1.8323772030491983

Epoch: 798| Step: 0
Training loss: 0.3491390645503998
Validation loss: 1.8095629958696262

Epoch: 5| Step: 1
Training loss: 0.43758684396743774
Validation loss: 1.8088532250414613

Epoch: 5| Step: 2
Training loss: 0.41819852590560913
Validation loss: 1.7264740723435597

Epoch: 5| Step: 3
Training loss: 0.571899950504303
Validation loss: 1.822059255133393

Epoch: 5| Step: 4
Training loss: 1.1234906911849976
Validation loss: 1.7980512572873024

Epoch: 5| Step: 5
Training loss: 0.7700960636138916
Validation loss: 1.853256985705386

Epoch: 5| Step: 6
Training loss: 0.3796021640300751
Validation loss: 1.789862919879216

Epoch: 5| Step: 7
Training loss: 0.6035943031311035
Validation loss: 1.8278913087742303

Epoch: 5| Step: 8
Training loss: 0.5301275253295898
Validation loss: 1.8508112122935634

Epoch: 5| Step: 9
Training loss: 1.0061590671539307
Validation loss: 1.8004796504974365

Epoch: 5| Step: 10
Training loss: 0.6473702192306519
Validation loss: 1.7809942037828508

Epoch: 799| Step: 0
Training loss: 0.7967690229415894
Validation loss: 1.7786724900686612

Epoch: 5| Step: 1
Training loss: 0.61799556016922
Validation loss: 1.8252998808378815

Epoch: 5| Step: 2
Training loss: 0.8804064989089966
Validation loss: 1.7883667215224235

Epoch: 5| Step: 3
Training loss: 0.847268283367157
Validation loss: 1.7826605625050043

Epoch: 5| Step: 4
Training loss: 0.7185949087142944
Validation loss: 1.7824867245971516

Epoch: 5| Step: 5
Training loss: 0.4861031472682953
Validation loss: 1.7806143478680683

Epoch: 5| Step: 6
Training loss: 0.547087550163269
Validation loss: 1.781004459627213

Epoch: 5| Step: 7
Training loss: 0.4699283242225647
Validation loss: 1.778740946964551

Epoch: 5| Step: 8
Training loss: 0.8267593383789062
Validation loss: 1.7862684726715088

Epoch: 5| Step: 9
Training loss: 0.644347071647644
Validation loss: 1.8244405151695333

Epoch: 5| Step: 10
Training loss: 0.5094143152236938
Validation loss: 1.822839319065053

Epoch: 800| Step: 0
Training loss: 0.9721605181694031
Validation loss: 1.83385936034623

Epoch: 5| Step: 1
Training loss: 0.291667640209198
Validation loss: 1.8532589731677886

Epoch: 5| Step: 2
Training loss: 0.6523965001106262
Validation loss: 1.812991060236449

Epoch: 5| Step: 3
Training loss: 0.5822295546531677
Validation loss: 1.7950555252772507

Epoch: 5| Step: 4
Training loss: 0.46056556701660156
Validation loss: 1.787408531353038

Epoch: 5| Step: 5
Training loss: 1.0638569593429565
Validation loss: 1.8027034677484983

Epoch: 5| Step: 6
Training loss: 0.3399323523044586
Validation loss: 1.8253585638538483

Epoch: 5| Step: 7
Training loss: 0.826805591583252
Validation loss: 1.858330999651263

Epoch: 5| Step: 8
Training loss: 0.33540064096450806
Validation loss: 1.808830354803352

Epoch: 5| Step: 9
Training loss: 0.7206088304519653
Validation loss: 1.7931590695534982

Epoch: 5| Step: 10
Training loss: 0.5208556056022644
Validation loss: 1.8023920289931759

Testing loss: 2.4390321837531195
