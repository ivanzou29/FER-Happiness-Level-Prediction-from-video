Epoch: 1| Step: 0
Training loss: 4.735705375671387
Validation loss: 5.3180566603137605

Epoch: 5| Step: 1
Training loss: 4.77239465713501
Validation loss: 5.306951492063461

Epoch: 5| Step: 2
Training loss: 5.601888656616211
Validation loss: 5.3010406494140625

Epoch: 5| Step: 3
Training loss: 4.982454776763916
Validation loss: 5.295013719989408

Epoch: 5| Step: 4
Training loss: 5.2964067459106445
Validation loss: 5.289712454683038

Epoch: 5| Step: 5
Training loss: 4.702211380004883
Validation loss: 5.284127025194065

Epoch: 5| Step: 6
Training loss: 4.883360385894775
Validation loss: 5.276462503658828

Epoch: 5| Step: 7
Training loss: 4.575711727142334
Validation loss: 5.269192772526895

Epoch: 5| Step: 8
Training loss: 5.4425859451293945
Validation loss: 5.263237163584719

Epoch: 5| Step: 9
Training loss: 5.586527347564697
Validation loss: 5.258782345761535

Epoch: 5| Step: 10
Training loss: 5.344531059265137
Validation loss: 5.251885614087505

Epoch: 2| Step: 0
Training loss: 4.639267921447754
Validation loss: 5.244317516203849

Epoch: 5| Step: 1
Training loss: 4.891407012939453
Validation loss: 5.236885691201815

Epoch: 5| Step: 2
Training loss: 4.711605548858643
Validation loss: 5.231413292628463

Epoch: 5| Step: 3
Training loss: 4.445394039154053
Validation loss: 5.226421038309733

Epoch: 5| Step: 4
Training loss: 4.091126441955566
Validation loss: 5.219013388438891

Epoch: 5| Step: 5
Training loss: 5.71519660949707
Validation loss: 5.212748271162792

Epoch: 5| Step: 6
Training loss: 4.455718517303467
Validation loss: 5.207157863083706

Epoch: 5| Step: 7
Training loss: 6.222084999084473
Validation loss: 5.203208820794218

Epoch: 5| Step: 8
Training loss: 5.413384914398193
Validation loss: 5.193995147623042

Epoch: 5| Step: 9
Training loss: 5.550625324249268
Validation loss: 5.188184717650055

Epoch: 5| Step: 10
Training loss: 4.946996212005615
Validation loss: 5.179567465218165

Epoch: 3| Step: 0
Training loss: 4.288167953491211
Validation loss: 5.174915149647703

Epoch: 5| Step: 1
Training loss: 4.746912479400635
Validation loss: 5.170202814122682

Epoch: 5| Step: 2
Training loss: 4.432737827301025
Validation loss: 5.163560831418601

Epoch: 5| Step: 3
Training loss: 4.671131134033203
Validation loss: 5.159653238070908

Epoch: 5| Step: 4
Training loss: 4.3600897789001465
Validation loss: 5.153366473413283

Epoch: 5| Step: 5
Training loss: 4.837560176849365
Validation loss: 5.144148965035716

Epoch: 5| Step: 6
Training loss: 4.732831001281738
Validation loss: 5.136537480097945

Epoch: 5| Step: 7
Training loss: 5.677365779876709
Validation loss: 5.13283614189394

Epoch: 5| Step: 8
Training loss: 5.863558769226074
Validation loss: 5.129105393604566

Epoch: 5| Step: 9
Training loss: 5.0910563468933105
Validation loss: 5.122432052448231

Epoch: 5| Step: 10
Training loss: 5.752213001251221
Validation loss: 5.115085386460827

Epoch: 4| Step: 0
Training loss: 4.866806507110596
Validation loss: 5.106145361418365

Epoch: 5| Step: 1
Training loss: 5.99289083480835
Validation loss: 5.104522341041155

Epoch: 5| Step: 2
Training loss: 3.7492263317108154
Validation loss: 5.097542096209782

Epoch: 5| Step: 3
Training loss: 5.107167720794678
Validation loss: 5.089230701487551

Epoch: 5| Step: 4
Training loss: 4.264321804046631
Validation loss: 5.084945914565876

Epoch: 5| Step: 5
Training loss: 5.940650463104248
Validation loss: 5.080252319253901

Epoch: 5| Step: 6
Training loss: 4.586823463439941
Validation loss: 5.073592350047122

Epoch: 5| Step: 7
Training loss: 4.96095085144043
Validation loss: 5.065553762579477

Epoch: 5| Step: 8
Training loss: 4.342057228088379
Validation loss: 5.062337808711554

Epoch: 5| Step: 9
Training loss: 5.096193790435791
Validation loss: 5.054973730476954

Epoch: 5| Step: 10
Training loss: 4.667953968048096
Validation loss: 5.0487885116249

Epoch: 5| Step: 0
Training loss: 4.628991603851318
Validation loss: 5.045532954636441

Epoch: 5| Step: 1
Training loss: 5.316822052001953
Validation loss: 5.037152028852893

Epoch: 5| Step: 2
Training loss: 6.152966499328613
Validation loss: 5.030295633500622

Epoch: 5| Step: 3
Training loss: 3.5549683570861816
Validation loss: 5.025204191925705

Epoch: 5| Step: 4
Training loss: 4.171843528747559
Validation loss: 5.021563155676729

Epoch: 5| Step: 5
Training loss: 4.949599266052246
Validation loss: 5.014330530679354

Epoch: 5| Step: 6
Training loss: 4.526849746704102
Validation loss: 5.009551735334499

Epoch: 5| Step: 7
Training loss: 4.84343147277832
Validation loss: 5.003262724927676

Epoch: 5| Step: 8
Training loss: 4.375702857971191
Validation loss: 4.997924691887312

Epoch: 5| Step: 9
Training loss: 5.934858798980713
Validation loss: 4.992352577947801

Epoch: 5| Step: 10
Training loss: 4.4004340171813965
Validation loss: 4.985292678238244

Epoch: 6| Step: 0
Training loss: 4.980722427368164
Validation loss: 4.979119285460441

Epoch: 5| Step: 1
Training loss: 5.462429523468018
Validation loss: 4.974615158573274

Epoch: 5| Step: 2
Training loss: 4.915279388427734
Validation loss: 4.967635872543499

Epoch: 5| Step: 3
Training loss: 6.104971408843994
Validation loss: 4.962158777380503

Epoch: 5| Step: 4
Training loss: 3.959219455718994
Validation loss: 4.953097481881419

Epoch: 5| Step: 5
Training loss: 4.032308578491211
Validation loss: 4.950014447653166

Epoch: 5| Step: 6
Training loss: 4.562142372131348
Validation loss: 4.942391826260474

Epoch: 5| Step: 7
Training loss: 5.2605438232421875
Validation loss: 4.936991591607371

Epoch: 5| Step: 8
Training loss: 4.293728828430176
Validation loss: 4.932450099657941

Epoch: 5| Step: 9
Training loss: 4.7833638191223145
Validation loss: 4.9219415162199285

Epoch: 5| Step: 10
Training loss: 3.64863920211792
Validation loss: 4.918209870656331

Epoch: 7| Step: 0
Training loss: 4.591488838195801
Validation loss: 4.911153577989148

Epoch: 5| Step: 1
Training loss: 4.363341331481934
Validation loss: 4.907035781491187

Epoch: 5| Step: 2
Training loss: 5.117339134216309
Validation loss: 4.896469880175847

Epoch: 5| Step: 3
Training loss: 4.882086753845215
Validation loss: 4.888601369755243

Epoch: 5| Step: 4
Training loss: 5.8572492599487305
Validation loss: 4.88469486851846

Epoch: 5| Step: 5
Training loss: 5.079300880432129
Validation loss: 4.879577108608779

Epoch: 5| Step: 6
Training loss: 4.418461799621582
Validation loss: 4.869655193821076

Epoch: 5| Step: 7
Training loss: 5.110827445983887
Validation loss: 4.8629988803658435

Epoch: 5| Step: 8
Training loss: 3.4333999156951904
Validation loss: 4.857824602434712

Epoch: 5| Step: 9
Training loss: 4.152627944946289
Validation loss: 4.854341773576634

Epoch: 5| Step: 10
Training loss: 4.259467124938965
Validation loss: 4.843227565929454

Epoch: 8| Step: 0
Training loss: 5.966977119445801
Validation loss: 4.834076460971628

Epoch: 5| Step: 1
Training loss: 4.245134353637695
Validation loss: 4.829637209574382

Epoch: 5| Step: 2
Training loss: 5.040726661682129
Validation loss: 4.82297739418604

Epoch: 5| Step: 3
Training loss: 4.8305864334106445
Validation loss: 4.8133381412875265

Epoch: 5| Step: 4
Training loss: 4.8683671951293945
Validation loss: 4.806625345701812

Epoch: 5| Step: 5
Training loss: 5.050713539123535
Validation loss: 4.796887090129237

Epoch: 5| Step: 6
Training loss: 4.751068115234375
Validation loss: 4.791715232274866

Epoch: 5| Step: 7
Training loss: 3.722885847091675
Validation loss: 4.786542784783148

Epoch: 5| Step: 8
Training loss: 4.360062122344971
Validation loss: 4.7769723656356975

Epoch: 5| Step: 9
Training loss: 3.471271514892578
Validation loss: 4.765726530423728

Epoch: 5| Step: 10
Training loss: 4.094567775726318
Validation loss: 4.760574135729062

Epoch: 9| Step: 0
Training loss: 4.899288654327393
Validation loss: 4.752454501326366

Epoch: 5| Step: 1
Training loss: 4.338889122009277
Validation loss: 4.74099265375445

Epoch: 5| Step: 2
Training loss: 4.482019901275635
Validation loss: 4.731371807795699

Epoch: 5| Step: 3
Training loss: 5.276630401611328
Validation loss: 4.7264382967384915

Epoch: 5| Step: 4
Training loss: 3.628760576248169
Validation loss: 4.720115630857406

Epoch: 5| Step: 5
Training loss: 4.100099563598633
Validation loss: 4.710347103816207

Epoch: 5| Step: 6
Training loss: 4.006438255310059
Validation loss: 4.695558276227725

Epoch: 5| Step: 7
Training loss: 4.6704230308532715
Validation loss: 4.688140612776562

Epoch: 5| Step: 8
Training loss: 5.110630989074707
Validation loss: 4.6796042278248775

Epoch: 5| Step: 9
Training loss: 3.9835784435272217
Validation loss: 4.670024207843247

Epoch: 5| Step: 10
Training loss: 5.0312089920043945
Validation loss: 4.663197655831614

Epoch: 10| Step: 0
Training loss: 3.9825122356414795
Validation loss: 4.652669947634461

Epoch: 5| Step: 1
Training loss: 3.559049606323242
Validation loss: 4.643925436081425

Epoch: 5| Step: 2
Training loss: 3.797208070755005
Validation loss: 4.632329556249803

Epoch: 5| Step: 3
Training loss: 4.70361328125
Validation loss: 4.6227002554042365

Epoch: 5| Step: 4
Training loss: 4.781159400939941
Validation loss: 4.613238462837794

Epoch: 5| Step: 5
Training loss: 5.56093692779541
Validation loss: 4.600602452472974

Epoch: 5| Step: 6
Training loss: 3.780487537384033
Validation loss: 4.589413094264205

Epoch: 5| Step: 7
Training loss: 3.8111720085144043
Validation loss: 4.576059305539695

Epoch: 5| Step: 8
Training loss: 4.858285427093506
Validation loss: 4.5656955626703075

Epoch: 5| Step: 9
Training loss: 4.20920991897583
Validation loss: 4.558035589033557

Epoch: 5| Step: 10
Training loss: 5.327640056610107
Validation loss: 4.546594671023789

Epoch: 11| Step: 0
Training loss: 3.367945909500122
Validation loss: 4.5345915876409055

Epoch: 5| Step: 1
Training loss: 5.473492622375488
Validation loss: 4.5230576556216

Epoch: 5| Step: 2
Training loss: 4.020440101623535
Validation loss: 4.513715897836993

Epoch: 5| Step: 3
Training loss: 4.721212387084961
Validation loss: 4.502019359219458

Epoch: 5| Step: 4
Training loss: 4.378597259521484
Validation loss: 4.490808251083538

Epoch: 5| Step: 5
Training loss: 3.2548587322235107
Validation loss: 4.482309513194586

Epoch: 5| Step: 6
Training loss: 4.895458221435547
Validation loss: 4.466509413975541

Epoch: 5| Step: 7
Training loss: 4.077747344970703
Validation loss: 4.454857974924067

Epoch: 5| Step: 8
Training loss: 4.4058027267456055
Validation loss: 4.445853879374843

Epoch: 5| Step: 9
Training loss: 3.659440517425537
Validation loss: 4.434038795450682

Epoch: 5| Step: 10
Training loss: 4.721614360809326
Validation loss: 4.4218898434792795

Epoch: 12| Step: 0
Training loss: 3.4379780292510986
Validation loss: 4.4085863021112255

Epoch: 5| Step: 1
Training loss: 5.1598381996154785
Validation loss: 4.394923107598418

Epoch: 5| Step: 2
Training loss: 4.491302490234375
Validation loss: 4.378046815113355

Epoch: 5| Step: 3
Training loss: 4.170010566711426
Validation loss: 4.36749747491652

Epoch: 5| Step: 4
Training loss: 4.2905168533325195
Validation loss: 4.357403442423831

Epoch: 5| Step: 5
Training loss: 4.297839641571045
Validation loss: 4.343700332026327

Epoch: 5| Step: 6
Training loss: 4.210877418518066
Validation loss: 4.330875940220331

Epoch: 5| Step: 7
Training loss: 4.651801109313965
Validation loss: 4.314338694336594

Epoch: 5| Step: 8
Training loss: 3.2657535076141357
Validation loss: 4.3009488556974675

Epoch: 5| Step: 9
Training loss: 3.598762035369873
Validation loss: 4.291113484290339

Epoch: 5| Step: 10
Training loss: 3.8788890838623047
Validation loss: 4.279331753330846

Epoch: 13| Step: 0
Training loss: 4.29624080657959
Validation loss: 4.263759428454984

Epoch: 5| Step: 1
Training loss: 3.5625081062316895
Validation loss: 4.2520074331632225

Epoch: 5| Step: 2
Training loss: 4.062334060668945
Validation loss: 4.235289619814965

Epoch: 5| Step: 3
Training loss: 3.5115437507629395
Validation loss: 4.222911906498735

Epoch: 5| Step: 4
Training loss: 3.6638569831848145
Validation loss: 4.210466307978476

Epoch: 5| Step: 5
Training loss: 4.591787338256836
Validation loss: 4.193244247026341

Epoch: 5| Step: 6
Training loss: 3.587808132171631
Validation loss: 4.180709820921703

Epoch: 5| Step: 7
Training loss: 3.6473019123077393
Validation loss: 4.1646584695385345

Epoch: 5| Step: 8
Training loss: 3.525164842605591
Validation loss: 4.1504825827895955

Epoch: 5| Step: 9
Training loss: 5.155202388763428
Validation loss: 4.137411727700182

Epoch: 5| Step: 10
Training loss: 4.512322902679443
Validation loss: 4.128577752779889

Epoch: 14| Step: 0
Training loss: 3.860304355621338
Validation loss: 4.110229148659655

Epoch: 5| Step: 1
Training loss: 4.0090250968933105
Validation loss: 4.0965784749677105

Epoch: 5| Step: 2
Training loss: 3.2575621604919434
Validation loss: 4.07619918290005

Epoch: 5| Step: 3
Training loss: 4.038580894470215
Validation loss: 4.065086513437251

Epoch: 5| Step: 4
Training loss: 4.637020111083984
Validation loss: 4.0549899737040205

Epoch: 5| Step: 5
Training loss: 4.366201400756836
Validation loss: 4.034070145699285

Epoch: 5| Step: 6
Training loss: 3.8351197242736816
Validation loss: 4.026824489716561

Epoch: 5| Step: 7
Training loss: 4.35727596282959
Validation loss: 4.0017218589782715

Epoch: 5| Step: 8
Training loss: 3.5440659523010254
Validation loss: 3.9872619029014342

Epoch: 5| Step: 9
Training loss: 2.7404942512512207
Validation loss: 3.976058477996498

Epoch: 5| Step: 10
Training loss: 3.8285274505615234
Validation loss: 3.9520180661191224

Epoch: 15| Step: 0
Training loss: 4.351509094238281
Validation loss: 3.9435416883037937

Epoch: 5| Step: 1
Training loss: 3.5601978302001953
Validation loss: 3.9225227089338404

Epoch: 5| Step: 2
Training loss: 4.069295406341553
Validation loss: 3.9100928204033965

Epoch: 5| Step: 3
Training loss: 3.655043125152588
Validation loss: 3.894693651506978

Epoch: 5| Step: 4
Training loss: 4.746401786804199
Validation loss: 3.87807797872892

Epoch: 5| Step: 5
Training loss: 3.5800933837890625
Validation loss: 3.8622754953240834

Epoch: 5| Step: 6
Training loss: 3.5572891235351562
Validation loss: 3.8450494376561974

Epoch: 5| Step: 7
Training loss: 3.7397217750549316
Validation loss: 3.83267621327472

Epoch: 5| Step: 8
Training loss: 3.1224453449249268
Validation loss: 3.8011675291163947

Epoch: 5| Step: 9
Training loss: 3.206373691558838
Validation loss: 3.7918639747045373

Epoch: 5| Step: 10
Training loss: 3.236276149749756
Validation loss: 3.779844730131088

Epoch: 16| Step: 0
Training loss: 2.6202914714813232
Validation loss: 3.759327742361253

Epoch: 5| Step: 1
Training loss: 4.1116509437561035
Validation loss: 3.7488271241546958

Epoch: 5| Step: 2
Training loss: 3.9928386211395264
Validation loss: 3.727229654148061

Epoch: 5| Step: 3
Training loss: 3.603306531906128
Validation loss: 3.7149972941285823

Epoch: 5| Step: 4
Training loss: 3.462085723876953
Validation loss: 3.694344466732394

Epoch: 5| Step: 5
Training loss: 3.9591598510742188
Validation loss: 3.673583681865405

Epoch: 5| Step: 6
Training loss: 3.172847032546997
Validation loss: 3.6595028984931206

Epoch: 5| Step: 7
Training loss: 3.1181111335754395
Validation loss: 3.638068352976153

Epoch: 5| Step: 8
Training loss: 3.776639223098755
Validation loss: 3.624360566498131

Epoch: 5| Step: 9
Training loss: 3.654754161834717
Validation loss: 3.6015451544074604

Epoch: 5| Step: 10
Training loss: 3.725036859512329
Validation loss: 3.5934371743150937

Epoch: 17| Step: 0
Training loss: 3.692960023880005
Validation loss: 3.57075160549533

Epoch: 5| Step: 1
Training loss: 3.622777223587036
Validation loss: 3.547585215619815

Epoch: 5| Step: 2
Training loss: 3.714674472808838
Validation loss: 3.530005875454154

Epoch: 5| Step: 3
Training loss: 2.8014655113220215
Validation loss: 3.5088889983392533

Epoch: 5| Step: 4
Training loss: 3.8634331226348877
Validation loss: 3.495179776222475

Epoch: 5| Step: 5
Training loss: 4.032273292541504
Validation loss: 3.4796323571153867

Epoch: 5| Step: 6
Training loss: 2.4310107231140137
Validation loss: 3.4614701091602282

Epoch: 5| Step: 7
Training loss: 3.667428493499756
Validation loss: 3.4421694535081104

Epoch: 5| Step: 8
Training loss: 3.540919065475464
Validation loss: 3.422256403071906

Epoch: 5| Step: 9
Training loss: 3.3525891304016113
Validation loss: 3.4049693179386917

Epoch: 5| Step: 10
Training loss: 2.278352975845337
Validation loss: 3.3842016266238306

Epoch: 18| Step: 0
Training loss: 2.5571775436401367
Validation loss: 3.3718383978771906

Epoch: 5| Step: 1
Training loss: 3.8549187183380127
Validation loss: 3.345809531468217

Epoch: 5| Step: 2
Training loss: 3.459012269973755
Validation loss: 3.31703765930668

Epoch: 5| Step: 3
Training loss: 3.8974571228027344
Validation loss: 3.292197499223935

Epoch: 5| Step: 4
Training loss: 3.377920150756836
Validation loss: 3.270778222750592

Epoch: 5| Step: 5
Training loss: 3.252859115600586
Validation loss: 3.2494947371944303

Epoch: 5| Step: 6
Training loss: 2.495286226272583
Validation loss: 3.214814696260678

Epoch: 5| Step: 7
Training loss: 2.4240036010742188
Validation loss: 3.1985213064378306

Epoch: 5| Step: 8
Training loss: 3.246936321258545
Validation loss: 3.1758547265042543

Epoch: 5| Step: 9
Training loss: 3.5087742805480957
Validation loss: 3.1508475913796374

Epoch: 5| Step: 10
Training loss: 2.952026128768921
Validation loss: 3.126344701295258

Epoch: 19| Step: 0
Training loss: 3.0279529094696045
Validation loss: 3.113772176927136

Epoch: 5| Step: 1
Training loss: 2.860290765762329
Validation loss: 3.083642139229723

Epoch: 5| Step: 2
Training loss: 3.5206642150878906
Validation loss: 3.060507315461354

Epoch: 5| Step: 3
Training loss: 2.509702682495117
Validation loss: 3.0490401996079313

Epoch: 5| Step: 4
Training loss: 3.090153217315674
Validation loss: 3.023915652305849

Epoch: 5| Step: 5
Training loss: 3.3427071571350098
Validation loss: 3.01089717495826

Epoch: 5| Step: 6
Training loss: 3.507500410079956
Validation loss: 2.9911227790258264

Epoch: 5| Step: 7
Training loss: 3.101268768310547
Validation loss: 2.96599175853114

Epoch: 5| Step: 8
Training loss: 2.621971845626831
Validation loss: 2.946374144605411

Epoch: 5| Step: 9
Training loss: 2.924098014831543
Validation loss: 2.92323887219993

Epoch: 5| Step: 10
Training loss: 2.848994255065918
Validation loss: 2.9087321527542604

Epoch: 20| Step: 0
Training loss: 2.1266956329345703
Validation loss: 2.8895030970214517

Epoch: 5| Step: 1
Training loss: 2.4251198768615723
Validation loss: 2.874291189255253

Epoch: 5| Step: 2
Training loss: 2.692563533782959
Validation loss: 2.8450767686290126

Epoch: 5| Step: 3
Training loss: 3.9231574535369873
Validation loss: 2.838025244333411

Epoch: 5| Step: 4
Training loss: 2.342452049255371
Validation loss: 2.8255449213007444

Epoch: 5| Step: 5
Training loss: 3.078676223754883
Validation loss: 2.8025156631264636

Epoch: 5| Step: 6
Training loss: 3.7901058197021484
Validation loss: 2.7698595446925007

Epoch: 5| Step: 7
Training loss: 2.682717800140381
Validation loss: 2.763651860657559

Epoch: 5| Step: 8
Training loss: 3.4970154762268066
Validation loss: 2.735160789182109

Epoch: 5| Step: 9
Training loss: 3.015772819519043
Validation loss: 2.712394283663842

Epoch: 5| Step: 10
Training loss: 2.0404555797576904
Validation loss: 2.70799018234335

Epoch: 21| Step: 0
Training loss: 2.4788405895233154
Validation loss: 2.6897381556931363

Epoch: 5| Step: 1
Training loss: 2.973423480987549
Validation loss: 2.6721950756606234

Epoch: 5| Step: 2
Training loss: 3.0877161026000977
Validation loss: 2.6493930996105237

Epoch: 5| Step: 3
Training loss: 3.151230573654175
Validation loss: 2.6228673227371706

Epoch: 5| Step: 4
Training loss: 2.856044292449951
Validation loss: 2.61317003157831

Epoch: 5| Step: 5
Training loss: 2.6458847522735596
Validation loss: 2.604102614105389

Epoch: 5| Step: 6
Training loss: 2.3837294578552246
Validation loss: 2.5777777112940305

Epoch: 5| Step: 7
Training loss: 2.5616869926452637
Validation loss: 2.5728529396877495

Epoch: 5| Step: 8
Training loss: 2.374411106109619
Validation loss: 2.5481679183180614

Epoch: 5| Step: 9
Training loss: 2.6130588054656982
Validation loss: 2.5234412531698904

Epoch: 5| Step: 10
Training loss: 3.3157575130462646
Validation loss: 2.5246966705527356

Epoch: 22| Step: 0
Training loss: 2.2678537368774414
Validation loss: 2.5074914475922943

Epoch: 5| Step: 1
Training loss: 2.377861261367798
Validation loss: 2.488336842547181

Epoch: 5| Step: 2
Training loss: 3.0434768199920654
Validation loss: 2.4668397134350193

Epoch: 5| Step: 3
Training loss: 2.982837438583374
Validation loss: 2.461293605066115

Epoch: 5| Step: 4
Training loss: 2.6174895763397217
Validation loss: 2.451576017564343

Epoch: 5| Step: 5
Training loss: 2.761648178100586
Validation loss: 2.437993211130942

Epoch: 5| Step: 6
Training loss: 2.0809128284454346
Validation loss: 2.4340413257639897

Epoch: 5| Step: 7
Training loss: 2.3705508708953857
Validation loss: 2.4207349438821115

Epoch: 5| Step: 8
Training loss: 3.1261165142059326
Validation loss: 2.3994571521718013

Epoch: 5| Step: 9
Training loss: 3.444026231765747
Validation loss: 2.394413471221924

Epoch: 5| Step: 10
Training loss: 1.7297645807266235
Validation loss: 2.3913337107627624

Epoch: 23| Step: 0
Training loss: 2.415696382522583
Validation loss: 2.383776669861168

Epoch: 5| Step: 1
Training loss: 2.5548431873321533
Validation loss: 2.366585918652114

Epoch: 5| Step: 2
Training loss: 2.623136520385742
Validation loss: 2.3734871905337096

Epoch: 5| Step: 3
Training loss: 2.1623940467834473
Validation loss: 2.360889645032985

Epoch: 5| Step: 4
Training loss: 2.4148550033569336
Validation loss: 2.350256945497246

Epoch: 5| Step: 5
Training loss: 2.937638282775879
Validation loss: 2.325435092372279

Epoch: 5| Step: 6
Training loss: 2.5734400749206543
Validation loss: 2.326100948036358

Epoch: 5| Step: 7
Training loss: 2.5209121704101562
Validation loss: 2.309757504411923

Epoch: 5| Step: 8
Training loss: 2.981198310852051
Validation loss: 2.3173315102054226

Epoch: 5| Step: 9
Training loss: 2.692385196685791
Validation loss: 2.29916972755104

Epoch: 5| Step: 10
Training loss: 2.4347686767578125
Validation loss: 2.304336755506454

Epoch: 24| Step: 0
Training loss: 2.2528326511383057
Validation loss: 2.2871843653340496

Epoch: 5| Step: 1
Training loss: 1.9949162006378174
Validation loss: 2.2877407663611957

Epoch: 5| Step: 2
Training loss: 2.2177481651306152
Validation loss: 2.2815733340478714

Epoch: 5| Step: 3
Training loss: 3.1219558715820312
Validation loss: 2.2678159308689896

Epoch: 5| Step: 4
Training loss: 2.7810349464416504
Validation loss: 2.2658174909571165

Epoch: 5| Step: 5
Training loss: 2.578512668609619
Validation loss: 2.2478354771931968

Epoch: 5| Step: 6
Training loss: 2.748152494430542
Validation loss: 2.264790904137396

Epoch: 5| Step: 7
Training loss: 2.783324956893921
Validation loss: 2.265916439794725

Epoch: 5| Step: 8
Training loss: 2.3472118377685547
Validation loss: 2.2410812762475785

Epoch: 5| Step: 9
Training loss: 2.6791067123413086
Validation loss: 2.250574532375541

Epoch: 5| Step: 10
Training loss: 2.2771124839782715
Validation loss: 2.237495879973135

Epoch: 25| Step: 0
Training loss: 2.5121054649353027
Validation loss: 2.245772377137215

Epoch: 5| Step: 1
Training loss: 2.385446071624756
Validation loss: 2.22899769454874

Epoch: 5| Step: 2
Training loss: 2.5507640838623047
Validation loss: 2.2293124173277166

Epoch: 5| Step: 3
Training loss: 2.4541783332824707
Validation loss: 2.2040429371659473

Epoch: 5| Step: 4
Training loss: 3.026973247528076
Validation loss: 2.210834603155813

Epoch: 5| Step: 5
Training loss: 2.820554733276367
Validation loss: 2.2309254984701834

Epoch: 5| Step: 6
Training loss: 2.635103225708008
Validation loss: 2.211356550134638

Epoch: 5| Step: 7
Training loss: 2.194026231765747
Validation loss: 2.1999419017504622

Epoch: 5| Step: 8
Training loss: 2.4828412532806396
Validation loss: 2.1958742603178947

Epoch: 5| Step: 9
Training loss: 2.206141233444214
Validation loss: 2.18921075841432

Epoch: 5| Step: 10
Training loss: 2.3202285766601562
Validation loss: 2.18406355509194

Epoch: 26| Step: 0
Training loss: 2.2369468212127686
Validation loss: 2.1958475010369414

Epoch: 5| Step: 1
Training loss: 2.7278010845184326
Validation loss: 2.177436964486235

Epoch: 5| Step: 2
Training loss: 2.1744649410247803
Validation loss: 2.1832982775985554

Epoch: 5| Step: 3
Training loss: 2.7619996070861816
Validation loss: 2.1935001163072485

Epoch: 5| Step: 4
Training loss: 2.455213785171509
Validation loss: 2.168354733015901

Epoch: 5| Step: 5
Training loss: 2.687859535217285
Validation loss: 2.1837148345926756

Epoch: 5| Step: 6
Training loss: 2.35488224029541
Validation loss: 2.1732886581010717

Epoch: 5| Step: 7
Training loss: 2.4189021587371826
Validation loss: 2.1753225249628865

Epoch: 5| Step: 8
Training loss: 2.46107816696167
Validation loss: 2.192780117834768

Epoch: 5| Step: 9
Training loss: 2.6219770908355713
Validation loss: 2.171532725775114

Epoch: 5| Step: 10
Training loss: 2.554828643798828
Validation loss: 2.170159375795754

Epoch: 27| Step: 0
Training loss: 2.6127963066101074
Validation loss: 2.1993210238795124

Epoch: 5| Step: 1
Training loss: 2.011125087738037
Validation loss: 2.174954257985597

Epoch: 5| Step: 2
Training loss: 2.2537550926208496
Validation loss: 2.172615748579784

Epoch: 5| Step: 3
Training loss: 2.8364174365997314
Validation loss: 2.171408325113276

Epoch: 5| Step: 4
Training loss: 1.9001843929290771
Validation loss: 2.1799238048573977

Epoch: 5| Step: 5
Training loss: 2.5618441104888916
Validation loss: 2.1898410781737296

Epoch: 5| Step: 6
Training loss: 2.671271324157715
Validation loss: 2.1659491831256497

Epoch: 5| Step: 7
Training loss: 3.1650214195251465
Validation loss: 2.173380841491043

Epoch: 5| Step: 8
Training loss: 2.747480869293213
Validation loss: 2.1564008599968365

Epoch: 5| Step: 9
Training loss: 2.576550245285034
Validation loss: 2.179224410364705

Epoch: 5| Step: 10
Training loss: 2.0713419914245605
Validation loss: 2.1799802664787538

Epoch: 28| Step: 0
Training loss: 1.8068532943725586
Validation loss: 2.1801193042468

Epoch: 5| Step: 1
Training loss: 2.07710337638855
Validation loss: 2.177088651605832

Epoch: 5| Step: 2
Training loss: 2.717855453491211
Validation loss: 2.1798966828212945

Epoch: 5| Step: 3
Training loss: 2.8943917751312256
Validation loss: 2.1810048651951615

Epoch: 5| Step: 4
Training loss: 2.9886341094970703
Validation loss: 2.1700086414173083

Epoch: 5| Step: 5
Training loss: 3.1515979766845703
Validation loss: 2.171185164041417

Epoch: 5| Step: 6
Training loss: 2.5548508167266846
Validation loss: 2.1745974556092293

Epoch: 5| Step: 7
Training loss: 1.5505683422088623
Validation loss: 2.1825580904560704

Epoch: 5| Step: 8
Training loss: 2.6996893882751465
Validation loss: 2.1738479727058

Epoch: 5| Step: 9
Training loss: 2.116860866546631
Validation loss: 2.17477439167679

Epoch: 5| Step: 10
Training loss: 2.6731700897216797
Validation loss: 2.154551306078511

Epoch: 29| Step: 0
Training loss: 2.2544353008270264
Validation loss: 2.1674813019332064

Epoch: 5| Step: 1
Training loss: 2.9384655952453613
Validation loss: 2.1525232150990474

Epoch: 5| Step: 2
Training loss: 2.411895513534546
Validation loss: 2.171210435128981

Epoch: 5| Step: 3
Training loss: 2.6839723587036133
Validation loss: 2.1592234334638043

Epoch: 5| Step: 4
Training loss: 2.5645713806152344
Validation loss: 2.1698319911956787

Epoch: 5| Step: 5
Training loss: 1.8622630834579468
Validation loss: 2.170181482068954

Epoch: 5| Step: 6
Training loss: 2.1704163551330566
Validation loss: 2.151210359347764

Epoch: 5| Step: 7
Training loss: 2.817169666290283
Validation loss: 2.1614620172849266

Epoch: 5| Step: 8
Training loss: 3.0448384284973145
Validation loss: 2.159888316226262

Epoch: 5| Step: 9
Training loss: 2.398256778717041
Validation loss: 2.1628107768233105

Epoch: 5| Step: 10
Training loss: 2.1035373210906982
Validation loss: 2.1762036738857145

Epoch: 30| Step: 0
Training loss: 2.5154953002929688
Validation loss: 2.183271095316897

Epoch: 5| Step: 1
Training loss: 2.3490869998931885
Validation loss: 2.1601030749659382

Epoch: 5| Step: 2
Training loss: 2.5931620597839355
Validation loss: 2.1585510123160576

Epoch: 5| Step: 3
Training loss: 2.0297796726226807
Validation loss: 2.1660150058807863

Epoch: 5| Step: 4
Training loss: 2.2128381729125977
Validation loss: 2.169127377130652

Epoch: 5| Step: 5
Training loss: 2.3393757343292236
Validation loss: 2.170681776538972

Epoch: 5| Step: 6
Training loss: 2.6582865715026855
Validation loss: 2.161543878175879

Epoch: 5| Step: 7
Training loss: 2.224738359451294
Validation loss: 2.1687525600515385

Epoch: 5| Step: 8
Training loss: 2.8115439414978027
Validation loss: 2.155519131691225

Epoch: 5| Step: 9
Training loss: 2.728365898132324
Validation loss: 2.1560762672014135

Epoch: 5| Step: 10
Training loss: 2.8551557064056396
Validation loss: 2.161381826605848

Epoch: 31| Step: 0
Training loss: 2.2458770275115967
Validation loss: 2.165736747044389

Epoch: 5| Step: 1
Training loss: 2.1711137294769287
Validation loss: 2.1516837176456245

Epoch: 5| Step: 2
Training loss: 2.315068244934082
Validation loss: 2.1459427943793674

Epoch: 5| Step: 3
Training loss: 2.1747729778289795
Validation loss: 2.152873812183257

Epoch: 5| Step: 4
Training loss: 2.8723442554473877
Validation loss: 2.158349939571914

Epoch: 5| Step: 5
Training loss: 2.9343581199645996
Validation loss: 2.1639157149099533

Epoch: 5| Step: 6
Training loss: 2.5968048572540283
Validation loss: 2.169237644441666

Epoch: 5| Step: 7
Training loss: 2.2254443168640137
Validation loss: 2.1645066840674287

Epoch: 5| Step: 8
Training loss: 2.249908924102783
Validation loss: 2.163074517762789

Epoch: 5| Step: 9
Training loss: 3.1899030208587646
Validation loss: 2.1534384476241244

Epoch: 5| Step: 10
Training loss: 1.9862695932388306
Validation loss: 2.156604895027735

Epoch: 32| Step: 0
Training loss: 2.8498520851135254
Validation loss: 2.1689367268675115

Epoch: 5| Step: 1
Training loss: 2.566021203994751
Validation loss: 2.1699371901891564

Epoch: 5| Step: 2
Training loss: 2.4834818840026855
Validation loss: 2.155534185389037

Epoch: 5| Step: 3
Training loss: 2.5489673614501953
Validation loss: 2.1596069592301563

Epoch: 5| Step: 4
Training loss: 2.36466121673584
Validation loss: 2.163186055357738

Epoch: 5| Step: 5
Training loss: 2.882101535797119
Validation loss: 2.162653148815196

Epoch: 5| Step: 6
Training loss: 2.441274881362915
Validation loss: 2.1731544438228814

Epoch: 5| Step: 7
Training loss: 2.4615275859832764
Validation loss: 2.143541289914039

Epoch: 5| Step: 8
Training loss: 1.864559531211853
Validation loss: 2.178057121974166

Epoch: 5| Step: 9
Training loss: 2.877840757369995
Validation loss: 2.1441924700173

Epoch: 5| Step: 10
Training loss: 1.583699107170105
Validation loss: 2.151790495841734

Epoch: 33| Step: 0
Training loss: 2.4523215293884277
Validation loss: 2.1661942107703096

Epoch: 5| Step: 1
Training loss: 2.520246744155884
Validation loss: 2.1613106625054472

Epoch: 5| Step: 2
Training loss: 2.796912908554077
Validation loss: 2.1646054496047316

Epoch: 5| Step: 3
Training loss: 2.3786187171936035
Validation loss: 2.156461351661272

Epoch: 5| Step: 4
Training loss: 2.3484482765197754
Validation loss: 2.164235347060747

Epoch: 5| Step: 5
Training loss: 1.8868634700775146
Validation loss: 2.1663577479700886

Epoch: 5| Step: 6
Training loss: 3.021700143814087
Validation loss: 2.1534583594209407

Epoch: 5| Step: 7
Training loss: 2.1906208992004395
Validation loss: 2.1666045252994826

Epoch: 5| Step: 8
Training loss: 2.0565972328186035
Validation loss: 2.1657213344368884

Epoch: 5| Step: 9
Training loss: 2.725130081176758
Validation loss: 2.1561189120815647

Epoch: 5| Step: 10
Training loss: 2.5767621994018555
Validation loss: 2.1547117117912538

Epoch: 34| Step: 0
Training loss: 2.0849337577819824
Validation loss: 2.1678969744713075

Epoch: 5| Step: 1
Training loss: 3.073150157928467
Validation loss: 2.154176640254195

Epoch: 5| Step: 2
Training loss: 2.8256068229675293
Validation loss: 2.175523793825539

Epoch: 5| Step: 3
Training loss: 1.876857042312622
Validation loss: 2.1615608969042377

Epoch: 5| Step: 4
Training loss: 2.762439489364624
Validation loss: 2.171239508095608

Epoch: 5| Step: 5
Training loss: 2.0988051891326904
Validation loss: 2.1593249446602276

Epoch: 5| Step: 6
Training loss: 2.764803886413574
Validation loss: 2.165311913336477

Epoch: 5| Step: 7
Training loss: 2.2834527492523193
Validation loss: 2.1359439280725296

Epoch: 5| Step: 8
Training loss: 2.4300475120544434
Validation loss: 2.1582502370239585

Epoch: 5| Step: 9
Training loss: 2.406831741333008
Validation loss: 2.163463577147453

Epoch: 5| Step: 10
Training loss: 2.2489778995513916
Validation loss: 2.1593016706487185

Epoch: 35| Step: 0
Training loss: 1.9658199548721313
Validation loss: 2.138741083042596

Epoch: 5| Step: 1
Training loss: 2.589207410812378
Validation loss: 2.1602542554178545

Epoch: 5| Step: 2
Training loss: 2.386176347732544
Validation loss: 2.170083502287506

Epoch: 5| Step: 3
Training loss: 2.66524076461792
Validation loss: 2.151925430502943

Epoch: 5| Step: 4
Training loss: 1.9662936925888062
Validation loss: 2.173043607383646

Epoch: 5| Step: 5
Training loss: 2.4172310829162598
Validation loss: 2.161598338875719

Epoch: 5| Step: 6
Training loss: 1.9631160497665405
Validation loss: 2.1590021092404603

Epoch: 5| Step: 7
Training loss: 2.4557957649230957
Validation loss: 2.18384967055372

Epoch: 5| Step: 8
Training loss: 2.827138662338257
Validation loss: 2.1804560461351947

Epoch: 5| Step: 9
Training loss: 2.4942290782928467
Validation loss: 2.1651069451403875

Epoch: 5| Step: 10
Training loss: 3.078120231628418
Validation loss: 2.166336586398463

Epoch: 36| Step: 0
Training loss: 1.8561820983886719
Validation loss: 2.1688838235793577

Epoch: 5| Step: 1
Training loss: 2.573901414871216
Validation loss: 2.1482586604292675

Epoch: 5| Step: 2
Training loss: 2.193758726119995
Validation loss: 2.1515626317711285

Epoch: 5| Step: 3
Training loss: 2.8118820190429688
Validation loss: 2.160118495264361

Epoch: 5| Step: 4
Training loss: 2.3163552284240723
Validation loss: 2.1585233211517334

Epoch: 5| Step: 5
Training loss: 2.3460192680358887
Validation loss: 2.1373061133969213

Epoch: 5| Step: 6
Training loss: 2.4407458305358887
Validation loss: 2.1396950419231127

Epoch: 5| Step: 7
Training loss: 2.3673062324523926
Validation loss: 2.151172420029999

Epoch: 5| Step: 8
Training loss: 2.333799362182617
Validation loss: 2.140788819200249

Epoch: 5| Step: 9
Training loss: 2.911487579345703
Validation loss: 2.145144416439918

Epoch: 5| Step: 10
Training loss: 2.752108335494995
Validation loss: 2.160812895785096

Epoch: 37| Step: 0
Training loss: 2.5055274963378906
Validation loss: 2.1406552099412486

Epoch: 5| Step: 1
Training loss: 2.304067611694336
Validation loss: 2.1517671923483572

Epoch: 5| Step: 2
Training loss: 2.4935221672058105
Validation loss: 2.132278488528344

Epoch: 5| Step: 3
Training loss: 3.1493186950683594
Validation loss: 2.1377509845200406

Epoch: 5| Step: 4
Training loss: 2.5148494243621826
Validation loss: 2.13268623300778

Epoch: 5| Step: 5
Training loss: 2.5920448303222656
Validation loss: 2.1485123736884004

Epoch: 5| Step: 6
Training loss: 2.623119831085205
Validation loss: 2.1348408857981362

Epoch: 5| Step: 7
Training loss: 1.668607473373413
Validation loss: 2.1406741014090915

Epoch: 5| Step: 8
Training loss: 2.239976167678833
Validation loss: 2.143294629230294

Epoch: 5| Step: 9
Training loss: 2.368537187576294
Validation loss: 2.13057045526402

Epoch: 5| Step: 10
Training loss: 2.2122554779052734
Validation loss: 2.1517980175633586

Epoch: 38| Step: 0
Training loss: 2.764967441558838
Validation loss: 2.128079222094628

Epoch: 5| Step: 1
Training loss: 2.1098380088806152
Validation loss: 2.140644152959188

Epoch: 5| Step: 2
Training loss: 2.325273036956787
Validation loss: 2.152651268948791

Epoch: 5| Step: 3
Training loss: 2.6502349376678467
Validation loss: 2.1412124044151715

Epoch: 5| Step: 4
Training loss: 2.117201089859009
Validation loss: 2.1332108115637176

Epoch: 5| Step: 5
Training loss: 2.304849147796631
Validation loss: 2.1573931991413073

Epoch: 5| Step: 6
Training loss: 3.698223114013672
Validation loss: 2.1311509814313663

Epoch: 5| Step: 7
Training loss: 2.2997031211853027
Validation loss: 2.159545421600342

Epoch: 5| Step: 8
Training loss: 2.0979113578796387
Validation loss: 2.150476396724742

Epoch: 5| Step: 9
Training loss: 1.9891033172607422
Validation loss: 2.1351394730229534

Epoch: 5| Step: 10
Training loss: 2.2589099407196045
Validation loss: 2.1721916467912736

Epoch: 39| Step: 0
Training loss: 2.09370756149292
Validation loss: 2.1556906213042555

Epoch: 5| Step: 1
Training loss: 2.113314151763916
Validation loss: 2.1387494276928645

Epoch: 5| Step: 2
Training loss: 2.731255292892456
Validation loss: 2.1419279024165165

Epoch: 5| Step: 3
Training loss: 2.2620370388031006
Validation loss: 2.157056277798068

Epoch: 5| Step: 4
Training loss: 2.6010096073150635
Validation loss: 2.1574197917856197

Epoch: 5| Step: 5
Training loss: 2.0193581581115723
Validation loss: 2.166290307557711

Epoch: 5| Step: 6
Training loss: 2.5115857124328613
Validation loss: 2.155374921778197

Epoch: 5| Step: 7
Training loss: 2.608856678009033
Validation loss: 2.140866788484717

Epoch: 5| Step: 8
Training loss: 2.8568973541259766
Validation loss: 2.150918847771101

Epoch: 5| Step: 9
Training loss: 2.3780293464660645
Validation loss: 2.1632744830141784

Epoch: 5| Step: 10
Training loss: 2.427734375
Validation loss: 2.139864394741674

Epoch: 40| Step: 0
Training loss: 2.523444414138794
Validation loss: 2.1447450653199227

Epoch: 5| Step: 1
Training loss: 2.4664604663848877
Validation loss: 2.1294777957342004

Epoch: 5| Step: 2
Training loss: 2.3851401805877686
Validation loss: 2.156334341213267

Epoch: 5| Step: 3
Training loss: 2.712071180343628
Validation loss: 2.1560570578421316

Epoch: 5| Step: 4
Training loss: 2.167639970779419
Validation loss: 2.130118244437761

Epoch: 5| Step: 5
Training loss: 1.6355708837509155
Validation loss: 2.1723120879101496

Epoch: 5| Step: 6
Training loss: 2.473487615585327
Validation loss: 2.1710955353193384

Epoch: 5| Step: 7
Training loss: 2.1063313484191895
Validation loss: 2.1437457453820015

Epoch: 5| Step: 8
Training loss: 2.332603931427002
Validation loss: 2.159799339950726

Epoch: 5| Step: 9
Training loss: 2.9204204082489014
Validation loss: 2.1647128840928436

Epoch: 5| Step: 10
Training loss: 2.789149522781372
Validation loss: 2.1447891484024706

Epoch: 41| Step: 0
Training loss: 2.322267532348633
Validation loss: 2.1300153937391055

Epoch: 5| Step: 1
Training loss: 2.4184017181396484
Validation loss: 2.1305149780806674

Epoch: 5| Step: 2
Training loss: 2.4296209812164307
Validation loss: 2.144533452167306

Epoch: 5| Step: 3
Training loss: 2.546314239501953
Validation loss: 2.1340254327302337

Epoch: 5| Step: 4
Training loss: 2.7675535678863525
Validation loss: 2.130152230621666

Epoch: 5| Step: 5
Training loss: 2.445408344268799
Validation loss: 2.1151264944384174

Epoch: 5| Step: 6
Training loss: 2.086738348007202
Validation loss: 2.1174934576916438

Epoch: 5| Step: 7
Training loss: 2.4055233001708984
Validation loss: 2.1370373336217736

Epoch: 5| Step: 8
Training loss: 2.05241060256958
Validation loss: 2.12428085009257

Epoch: 5| Step: 9
Training loss: 2.160796642303467
Validation loss: 2.1238706650272494

Epoch: 5| Step: 10
Training loss: 2.9753036499023438
Validation loss: 2.1288788754452943

Epoch: 42| Step: 0
Training loss: 2.321561336517334
Validation loss: 2.1148885783328804

Epoch: 5| Step: 1
Training loss: 2.524576187133789
Validation loss: 2.117192608053966

Epoch: 5| Step: 2
Training loss: 2.2959747314453125
Validation loss: 2.120353760257844

Epoch: 5| Step: 3
Training loss: 2.347973346710205
Validation loss: 2.1360319788737963

Epoch: 5| Step: 4
Training loss: 2.5687549114227295
Validation loss: 2.122861087963145

Epoch: 5| Step: 5
Training loss: 2.8941712379455566
Validation loss: 2.122983412076068

Epoch: 5| Step: 6
Training loss: 2.3627758026123047
Validation loss: 2.12550030216094

Epoch: 5| Step: 7
Training loss: 2.0784237384796143
Validation loss: 2.1304986323079755

Epoch: 5| Step: 8
Training loss: 1.9704792499542236
Validation loss: 2.133352541154431

Epoch: 5| Step: 9
Training loss: 2.3153328895568848
Validation loss: 2.1209267544490036

Epoch: 5| Step: 10
Training loss: 2.8318943977355957
Validation loss: 2.1211421207715104

Epoch: 43| Step: 0
Training loss: 2.5844790935516357
Validation loss: 2.1254512392064577

Epoch: 5| Step: 1
Training loss: 2.6047658920288086
Validation loss: 2.103945328343299

Epoch: 5| Step: 2
Training loss: 2.2908802032470703
Validation loss: 2.1194357666918027

Epoch: 5| Step: 3
Training loss: 2.5818536281585693
Validation loss: 2.1206753253936768

Epoch: 5| Step: 4
Training loss: 2.8744378089904785
Validation loss: 2.138708327406196

Epoch: 5| Step: 5
Training loss: 2.4778056144714355
Validation loss: 2.1269221369938185

Epoch: 5| Step: 6
Training loss: 2.291658401489258
Validation loss: 2.1243510489822715

Epoch: 5| Step: 7
Training loss: 2.371408462524414
Validation loss: 2.1316540292514268

Epoch: 5| Step: 8
Training loss: 1.8779970407485962
Validation loss: 2.153651440015403

Epoch: 5| Step: 9
Training loss: 2.0820670127868652
Validation loss: 2.126649659167054

Epoch: 5| Step: 10
Training loss: 2.264350175857544
Validation loss: 2.1482547713864233

Epoch: 44| Step: 0
Training loss: 2.5145742893218994
Validation loss: 2.124300128670149

Epoch: 5| Step: 1
Training loss: 2.7943832874298096
Validation loss: 2.127686692822364

Epoch: 5| Step: 2
Training loss: 2.5907835960388184
Validation loss: 2.122858093630883

Epoch: 5| Step: 3
Training loss: 2.4606986045837402
Validation loss: 2.126974134035008

Epoch: 5| Step: 4
Training loss: 2.0910086631774902
Validation loss: 2.1334650772874073

Epoch: 5| Step: 5
Training loss: 2.1859164237976074
Validation loss: 2.1224703788757324

Epoch: 5| Step: 6
Training loss: 1.8102655410766602
Validation loss: 2.1354620930969075

Epoch: 5| Step: 7
Training loss: 2.042301893234253
Validation loss: 2.1364032940198014

Epoch: 5| Step: 8
Training loss: 2.8493194580078125
Validation loss: 2.1450373331705728

Epoch: 5| Step: 9
Training loss: 2.371213674545288
Validation loss: 2.139715797157698

Epoch: 5| Step: 10
Training loss: 2.630767583847046
Validation loss: 2.1231811508055656

Epoch: 45| Step: 0
Training loss: 1.9883983135223389
Validation loss: 2.1270602544148765

Epoch: 5| Step: 1
Training loss: 2.382690906524658
Validation loss: 2.129320603544994

Epoch: 5| Step: 2
Training loss: 2.1466469764709473
Validation loss: 2.1072769934131252

Epoch: 5| Step: 3
Training loss: 2.421938419342041
Validation loss: 2.1160160418479674

Epoch: 5| Step: 4
Training loss: 2.832996368408203
Validation loss: 2.118616000298531

Epoch: 5| Step: 5
Training loss: 2.341216564178467
Validation loss: 2.10357908023301

Epoch: 5| Step: 6
Training loss: 2.158090114593506
Validation loss: 2.1156517997864754

Epoch: 5| Step: 7
Training loss: 2.034782648086548
Validation loss: 2.116054722057876

Epoch: 5| Step: 8
Training loss: 2.540196657180786
Validation loss: 2.1134508143189135

Epoch: 5| Step: 9
Training loss: 1.9803047180175781
Validation loss: 2.1169523321172243

Epoch: 5| Step: 10
Training loss: 3.557652711868286
Validation loss: 2.093918897772348

Epoch: 46| Step: 0
Training loss: 2.768437623977661
Validation loss: 2.093512124912713

Epoch: 5| Step: 1
Training loss: 2.338503122329712
Validation loss: 2.091503240728891

Epoch: 5| Step: 2
Training loss: 1.9927704334259033
Validation loss: 2.0993526392085577

Epoch: 5| Step: 3
Training loss: 2.4819343090057373
Validation loss: 2.0863700246298187

Epoch: 5| Step: 4
Training loss: 2.4072232246398926
Validation loss: 2.0855011427274315

Epoch: 5| Step: 5
Training loss: 2.9547343254089355
Validation loss: 2.0859968226443053

Epoch: 5| Step: 6
Training loss: 2.4676575660705566
Validation loss: 2.0784727693885885

Epoch: 5| Step: 7
Training loss: 2.538985252380371
Validation loss: 2.1021000557048346

Epoch: 5| Step: 8
Training loss: 2.0700578689575195
Validation loss: 2.102297276578924

Epoch: 5| Step: 9
Training loss: 1.835463523864746
Validation loss: 2.0907849752774803

Epoch: 5| Step: 10
Training loss: 2.2641873359680176
Validation loss: 2.0964620087736394

Epoch: 47| Step: 0
Training loss: 2.458155632019043
Validation loss: 2.1012798957927252

Epoch: 5| Step: 1
Training loss: 2.478337049484253
Validation loss: 2.0936283796064314

Epoch: 5| Step: 2
Training loss: 2.6514220237731934
Validation loss: 2.0909231426895305

Epoch: 5| Step: 3
Training loss: 2.2906932830810547
Validation loss: 2.105826034340807

Epoch: 5| Step: 4
Training loss: 2.1289260387420654
Validation loss: 2.095741546282204

Epoch: 5| Step: 5
Training loss: 2.1056952476501465
Validation loss: 2.095367339349562

Epoch: 5| Step: 6
Training loss: 2.6021838188171387
Validation loss: 2.098300871028695

Epoch: 5| Step: 7
Training loss: 2.3080363273620605
Validation loss: 2.091628013118621

Epoch: 5| Step: 8
Training loss: 2.0355143547058105
Validation loss: 2.0998216085536505

Epoch: 5| Step: 9
Training loss: 2.217609405517578
Validation loss: 2.1044242843504875

Epoch: 5| Step: 10
Training loss: 2.930760383605957
Validation loss: 2.1008040738362137

Epoch: 48| Step: 0
Training loss: 1.988743543624878
Validation loss: 2.0935245508788736

Epoch: 5| Step: 1
Training loss: 2.7658653259277344
Validation loss: 2.1030897478903494

Epoch: 5| Step: 2
Training loss: 1.9586727619171143
Validation loss: 2.096689124261179

Epoch: 5| Step: 3
Training loss: 1.9394556283950806
Validation loss: 2.0832912639905046

Epoch: 5| Step: 4
Training loss: 2.5529003143310547
Validation loss: 2.1014544617745186

Epoch: 5| Step: 5
Training loss: 2.5537612438201904
Validation loss: 2.0896177855871056

Epoch: 5| Step: 6
Training loss: 2.2386085987091064
Validation loss: 2.0986540830263527

Epoch: 5| Step: 7
Training loss: 2.632828712463379
Validation loss: 2.0924204754573044

Epoch: 5| Step: 8
Training loss: 2.5682997703552246
Validation loss: 2.102351834697108

Epoch: 5| Step: 9
Training loss: 2.3809287548065186
Validation loss: 2.090355183488579

Epoch: 5| Step: 10
Training loss: 2.42779541015625
Validation loss: 2.08524691161289

Epoch: 49| Step: 0
Training loss: 2.307863712310791
Validation loss: 2.098276348524196

Epoch: 5| Step: 1
Training loss: 2.3146510124206543
Validation loss: 2.077887976041404

Epoch: 5| Step: 2
Training loss: 2.008803606033325
Validation loss: 2.072405196005298

Epoch: 5| Step: 3
Training loss: 2.2519679069519043
Validation loss: 2.0965138507145706

Epoch: 5| Step: 4
Training loss: 2.7414333820343018
Validation loss: 2.0860088333006828

Epoch: 5| Step: 5
Training loss: 2.106926441192627
Validation loss: 2.0693166255950928

Epoch: 5| Step: 6
Training loss: 2.364217519760132
Validation loss: 2.0915700466402116

Epoch: 5| Step: 7
Training loss: 2.616788148880005
Validation loss: 2.0859474341074624

Epoch: 5| Step: 8
Training loss: 2.181795835494995
Validation loss: 2.094901689919092

Epoch: 5| Step: 9
Training loss: 2.7891335487365723
Validation loss: 2.079739752636161

Epoch: 5| Step: 10
Training loss: 2.1635491847991943
Validation loss: 2.0826979029563164

Epoch: 50| Step: 0
Training loss: 3.0984690189361572
Validation loss: 2.083951183544692

Epoch: 5| Step: 1
Training loss: 2.3287739753723145
Validation loss: 2.0804605227644726

Epoch: 5| Step: 2
Training loss: 1.6807758808135986
Validation loss: 2.0937587932873796

Epoch: 5| Step: 3
Training loss: 2.395228147506714
Validation loss: 2.0681703167576946

Epoch: 5| Step: 4
Training loss: 2.1860785484313965
Validation loss: 2.0839941757981495

Epoch: 5| Step: 5
Training loss: 2.397258996963501
Validation loss: 2.0940566268018497

Epoch: 5| Step: 6
Training loss: 2.035047769546509
Validation loss: 2.080579229580459

Epoch: 5| Step: 7
Training loss: 2.572244644165039
Validation loss: 2.079109723849963

Epoch: 5| Step: 8
Training loss: 2.326551675796509
Validation loss: 2.107561792096784

Epoch: 5| Step: 9
Training loss: 2.6713356971740723
Validation loss: 2.0776467169484785

Epoch: 5| Step: 10
Training loss: 2.1205334663391113
Validation loss: 2.089376505985055

Testing loss: 2.1140297651290894
