Epoch: 1| Step: 0
Training loss: 5.392404079437256
Validation loss: 6.705693983262585

Epoch: 5| Step: 1
Training loss: 7.997078895568848
Validation loss: 6.701197947225263

Epoch: 5| Step: 2
Training loss: 7.359039306640625
Validation loss: 6.695240579625612

Epoch: 5| Step: 3
Training loss: 5.820432186126709
Validation loss: 6.68902935007567

Epoch: 5| Step: 4
Training loss: 7.053869724273682
Validation loss: 6.685001732200704

Epoch: 5| Step: 5
Training loss: 6.5409135818481445
Validation loss: 6.680758307057042

Epoch: 5| Step: 6
Training loss: 6.357908725738525
Validation loss: 6.675485816053165

Epoch: 5| Step: 7
Training loss: 6.293271541595459
Validation loss: 6.670227645545878

Epoch: 5| Step: 8
Training loss: 5.626570701599121
Validation loss: 6.666465082476216

Epoch: 5| Step: 9
Training loss: 6.209112644195557
Validation loss: 6.661228779823549

Epoch: 5| Step: 10
Training loss: 6.608928203582764
Validation loss: 6.654563360316779

Epoch: 2| Step: 0
Training loss: 7.28378438949585
Validation loss: 6.647602691445299

Epoch: 5| Step: 1
Training loss: 7.04342794418335
Validation loss: 6.645444603376491

Epoch: 5| Step: 2
Training loss: 5.043460369110107
Validation loss: 6.6373502464704615

Epoch: 5| Step: 3
Training loss: 6.391125679016113
Validation loss: 6.635110598738476

Epoch: 5| Step: 4
Training loss: 6.387089729309082
Validation loss: 6.627371203514837

Epoch: 5| Step: 5
Training loss: 6.616602897644043
Validation loss: 6.625215638068415

Epoch: 5| Step: 6
Training loss: 7.168787479400635
Validation loss: 6.617674068738055

Epoch: 5| Step: 7
Training loss: 6.475155830383301
Validation loss: 6.611152397688999

Epoch: 5| Step: 8
Training loss: 5.234764575958252
Validation loss: 6.604576531276908

Epoch: 5| Step: 9
Training loss: 6.041108131408691
Validation loss: 6.599179088428456

Epoch: 5| Step: 10
Training loss: 6.970027446746826
Validation loss: 6.594492276509603

Epoch: 3| Step: 0
Training loss: 6.165570259094238
Validation loss: 6.587502294971097

Epoch: 5| Step: 1
Training loss: 6.533963680267334
Validation loss: 6.584521047530636

Epoch: 5| Step: 2
Training loss: 6.1413702964782715
Validation loss: 6.580102735950101

Epoch: 5| Step: 3
Training loss: 5.482417583465576
Validation loss: 6.5737539311890965

Epoch: 5| Step: 4
Training loss: 6.4737114906311035
Validation loss: 6.5646772589734805

Epoch: 5| Step: 5
Training loss: 6.236289024353027
Validation loss: 6.561537875924059

Epoch: 5| Step: 6
Training loss: 7.418253421783447
Validation loss: 6.553823676160587

Epoch: 5| Step: 7
Training loss: 6.551218509674072
Validation loss: 6.549728332027312

Epoch: 5| Step: 8
Training loss: 6.4952802658081055
Validation loss: 6.544206814099383

Epoch: 5| Step: 9
Training loss: 5.633795738220215
Validation loss: 6.536560268812282

Epoch: 5| Step: 10
Training loss: 6.828115940093994
Validation loss: 6.52915314192413

Epoch: 4| Step: 0
Training loss: 6.039329528808594
Validation loss: 6.52347340122346

Epoch: 5| Step: 1
Training loss: 6.422106742858887
Validation loss: 6.5173316976075535

Epoch: 5| Step: 2
Training loss: 4.364404201507568
Validation loss: 6.511616619684363

Epoch: 5| Step: 3
Training loss: 6.249424934387207
Validation loss: 6.503989670866279

Epoch: 5| Step: 4
Training loss: 6.2152509689331055
Validation loss: 6.496367228928433

Epoch: 5| Step: 5
Training loss: 6.872302055358887
Validation loss: 6.493417539904194

Epoch: 5| Step: 6
Training loss: 6.131263256072998
Validation loss: 6.48574431737264

Epoch: 5| Step: 7
Training loss: 7.1140570640563965
Validation loss: 6.477622027038246

Epoch: 5| Step: 8
Training loss: 7.244174957275391
Validation loss: 6.4728775844779065

Epoch: 5| Step: 9
Training loss: 6.430759429931641
Validation loss: 6.463731073564099

Epoch: 5| Step: 10
Training loss: 5.975283145904541
Validation loss: 6.458736086404452

Epoch: 5| Step: 0
Training loss: 6.8410515785217285
Validation loss: 6.452006724572951

Epoch: 5| Step: 1
Training loss: 7.423281669616699
Validation loss: 6.441719096194031

Epoch: 5| Step: 2
Training loss: 6.4290361404418945
Validation loss: 6.436656039248231

Epoch: 5| Step: 3
Training loss: 6.581528663635254
Validation loss: 6.428684080800703

Epoch: 5| Step: 4
Training loss: 5.497271537780762
Validation loss: 6.4216991445069675

Epoch: 5| Step: 5
Training loss: 6.1694440841674805
Validation loss: 6.416217034862887

Epoch: 5| Step: 6
Training loss: 6.496517181396484
Validation loss: 6.407384195635395

Epoch: 5| Step: 7
Training loss: 5.597259521484375
Validation loss: 6.400225290688136

Epoch: 5| Step: 8
Training loss: 6.50557804107666
Validation loss: 6.394447721460814

Epoch: 5| Step: 9
Training loss: 5.688620567321777
Validation loss: 6.386344771231374

Epoch: 5| Step: 10
Training loss: 4.831918716430664
Validation loss: 6.378139265121952

Epoch: 6| Step: 0
Training loss: 5.917779445648193
Validation loss: 6.369393112838909

Epoch: 5| Step: 1
Training loss: 6.36004638671875
Validation loss: 6.365402749789658

Epoch: 5| Step: 2
Training loss: 5.967872619628906
Validation loss: 6.354641499057893

Epoch: 5| Step: 3
Training loss: 5.6338210105896
Validation loss: 6.3484414726175284

Epoch: 5| Step: 4
Training loss: 6.173531532287598
Validation loss: 6.33978424790085

Epoch: 5| Step: 5
Training loss: 5.973757743835449
Validation loss: 6.33259303082702

Epoch: 5| Step: 6
Training loss: 5.957715034484863
Validation loss: 6.322401077516617

Epoch: 5| Step: 7
Training loss: 4.662174701690674
Validation loss: 6.316251252287177

Epoch: 5| Step: 8
Training loss: 6.9894819259643555
Validation loss: 6.306651633272889

Epoch: 5| Step: 9
Training loss: 7.110577583312988
Validation loss: 6.299313524717926

Epoch: 5| Step: 10
Training loss: 6.639694690704346
Validation loss: 6.290877362733246

Epoch: 7| Step: 0
Training loss: 5.843461036682129
Validation loss: 6.282436996377925

Epoch: 5| Step: 1
Training loss: 6.2573089599609375
Validation loss: 6.2726167965960755

Epoch: 5| Step: 2
Training loss: 5.507821083068848
Validation loss: 6.2652854252887025

Epoch: 5| Step: 3
Training loss: 5.342324733734131
Validation loss: 6.25765319537091

Epoch: 5| Step: 4
Training loss: 6.305505275726318
Validation loss: 6.2486009495232695

Epoch: 5| Step: 5
Training loss: 7.259490966796875
Validation loss: 6.238332635612898

Epoch: 5| Step: 6
Training loss: 5.872931480407715
Validation loss: 6.232462119030696

Epoch: 5| Step: 7
Training loss: 6.648778438568115
Validation loss: 6.224586435543594

Epoch: 5| Step: 8
Training loss: 5.534575462341309
Validation loss: 6.211269568371517

Epoch: 5| Step: 9
Training loss: 5.418048858642578
Validation loss: 6.205210916457638

Epoch: 5| Step: 10
Training loss: 6.3504533767700195
Validation loss: 6.195300168888544

Epoch: 8| Step: 0
Training loss: 6.920384407043457
Validation loss: 6.188483627893591

Epoch: 5| Step: 1
Training loss: 7.406313896179199
Validation loss: 6.176423344560849

Epoch: 5| Step: 2
Training loss: 5.686121463775635
Validation loss: 6.165252075400404

Epoch: 5| Step: 3
Training loss: 5.688094139099121
Validation loss: 6.156729559744558

Epoch: 5| Step: 4
Training loss: 5.364182472229004
Validation loss: 6.149853849923739

Epoch: 5| Step: 5
Training loss: 5.078856468200684
Validation loss: 6.136028535904423

Epoch: 5| Step: 6
Training loss: 6.028571605682373
Validation loss: 6.128225680320494

Epoch: 5| Step: 7
Training loss: 5.132907390594482
Validation loss: 6.119249036235194

Epoch: 5| Step: 8
Training loss: 5.838877201080322
Validation loss: 6.111364985025057

Epoch: 5| Step: 9
Training loss: 5.717016696929932
Validation loss: 6.098982221336775

Epoch: 5| Step: 10
Training loss: 6.378452301025391
Validation loss: 6.090538337666501

Epoch: 9| Step: 0
Training loss: 5.6051530838012695
Validation loss: 6.078318011376165

Epoch: 5| Step: 1
Training loss: 6.6324782371521
Validation loss: 6.07311458997829

Epoch: 5| Step: 2
Training loss: 4.7460737228393555
Validation loss: 6.055807923757902

Epoch: 5| Step: 3
Training loss: 6.769654750823975
Validation loss: 6.051110923931163

Epoch: 5| Step: 4
Training loss: 4.942407608032227
Validation loss: 6.036482851992371

Epoch: 5| Step: 5
Training loss: 6.469773769378662
Validation loss: 6.026455761283956

Epoch: 5| Step: 6
Training loss: 6.000616073608398
Validation loss: 6.0145995437458

Epoch: 5| Step: 7
Training loss: 7.739187717437744
Validation loss: 6.00445379236693

Epoch: 5| Step: 8
Training loss: 5.546182632446289
Validation loss: 5.9928502575043705

Epoch: 5| Step: 9
Training loss: 3.9878933429718018
Validation loss: 5.980813426356161

Epoch: 5| Step: 10
Training loss: 5.361639022827148
Validation loss: 5.969838455159177

Epoch: 10| Step: 0
Training loss: 6.380749702453613
Validation loss: 5.959880423802201

Epoch: 5| Step: 1
Training loss: 5.526185035705566
Validation loss: 5.946845264844997

Epoch: 5| Step: 2
Training loss: 6.310032844543457
Validation loss: 5.936610293644731

Epoch: 5| Step: 3
Training loss: 4.8036627769470215
Validation loss: 5.9243951920540106

Epoch: 5| Step: 4
Training loss: 5.823357582092285
Validation loss: 5.914257054687829

Epoch: 5| Step: 5
Training loss: 6.4124040603637695
Validation loss: 5.901980712849607

Epoch: 5| Step: 6
Training loss: 5.739578723907471
Validation loss: 5.891438514955582

Epoch: 5| Step: 7
Training loss: 5.970951557159424
Validation loss: 5.876899298801217

Epoch: 5| Step: 8
Training loss: 5.347103118896484
Validation loss: 5.861785622053249

Epoch: 5| Step: 9
Training loss: 4.764382362365723
Validation loss: 5.85685367994411

Epoch: 5| Step: 10
Training loss: 5.367244720458984
Validation loss: 5.8426463680882605

Epoch: 11| Step: 0
Training loss: 5.958066940307617
Validation loss: 5.8263839547352125

Epoch: 5| Step: 1
Training loss: 4.364072322845459
Validation loss: 5.818546305420578

Epoch: 5| Step: 2
Training loss: 5.200441837310791
Validation loss: 5.800096491331695

Epoch: 5| Step: 3
Training loss: 5.778912544250488
Validation loss: 5.788801429092243

Epoch: 5| Step: 4
Training loss: 5.543049335479736
Validation loss: 5.7733777005185365

Epoch: 5| Step: 5
Training loss: 6.734835147857666
Validation loss: 5.756963263275803

Epoch: 5| Step: 6
Training loss: 4.467619895935059
Validation loss: 5.745325252573977

Epoch: 5| Step: 7
Training loss: 6.719058036804199
Validation loss: 5.732506936596286

Epoch: 5| Step: 8
Training loss: 5.505677223205566
Validation loss: 5.71932739339849

Epoch: 5| Step: 9
Training loss: 4.739863872528076
Validation loss: 5.706191160345591

Epoch: 5| Step: 10
Training loss: 5.950450897216797
Validation loss: 5.688451705440398

Epoch: 12| Step: 0
Training loss: 5.437127590179443
Validation loss: 5.67829260774838

Epoch: 5| Step: 1
Training loss: 5.401400566101074
Validation loss: 5.66496059971471

Epoch: 5| Step: 2
Training loss: 6.461325645446777
Validation loss: 5.646023247831611

Epoch: 5| Step: 3
Training loss: 5.348396301269531
Validation loss: 5.6312403422529975

Epoch: 5| Step: 4
Training loss: 6.10738468170166
Validation loss: 5.61172697108279

Epoch: 5| Step: 5
Training loss: 5.021781921386719
Validation loss: 5.597683855282363

Epoch: 5| Step: 6
Training loss: 5.372176170349121
Validation loss: 5.577808923618768

Epoch: 5| Step: 7
Training loss: 4.840615272521973
Validation loss: 5.569424306192706

Epoch: 5| Step: 8
Training loss: 5.185116291046143
Validation loss: 5.5412741271398405

Epoch: 5| Step: 9
Training loss: 5.104363441467285
Validation loss: 5.5331253441431185

Epoch: 5| Step: 10
Training loss: 4.686031818389893
Validation loss: 5.513101439322194

Epoch: 13| Step: 0
Training loss: 4.488046169281006
Validation loss: 5.499093363361974

Epoch: 5| Step: 1
Training loss: 5.322623252868652
Validation loss: 5.477066516876221

Epoch: 5| Step: 2
Training loss: 4.930966377258301
Validation loss: 5.464623594796786

Epoch: 5| Step: 3
Training loss: 5.898876667022705
Validation loss: 5.443329298368064

Epoch: 5| Step: 4
Training loss: 6.016475677490234
Validation loss: 5.430511013154061

Epoch: 5| Step: 5
Training loss: 4.721447944641113
Validation loss: 5.410374144072174

Epoch: 5| Step: 6
Training loss: 4.802702903747559
Validation loss: 5.390990703336654

Epoch: 5| Step: 7
Training loss: 5.128568649291992
Validation loss: 5.371514310118973

Epoch: 5| Step: 8
Training loss: 5.599781036376953
Validation loss: 5.355930169423421

Epoch: 5| Step: 9
Training loss: 4.990810871124268
Validation loss: 5.334220788812124

Epoch: 5| Step: 10
Training loss: 4.964183330535889
Validation loss: 5.314309115050941

Epoch: 14| Step: 0
Training loss: 4.323455333709717
Validation loss: 5.296417067127843

Epoch: 5| Step: 1
Training loss: 5.1115617752075195
Validation loss: 5.273676292870634

Epoch: 5| Step: 2
Training loss: 5.377429008483887
Validation loss: 5.253969946215229

Epoch: 5| Step: 3
Training loss: 6.139974594116211
Validation loss: 5.234317569322483

Epoch: 5| Step: 4
Training loss: 3.7039051055908203
Validation loss: 5.216660350881597

Epoch: 5| Step: 5
Training loss: 6.0173234939575195
Validation loss: 5.193715116029145

Epoch: 5| Step: 6
Training loss: 4.950751781463623
Validation loss: 5.171981011667559

Epoch: 5| Step: 7
Training loss: 4.880972862243652
Validation loss: 5.147516676174697

Epoch: 5| Step: 8
Training loss: 4.040883541107178
Validation loss: 5.128427300401913

Epoch: 5| Step: 9
Training loss: 4.732373237609863
Validation loss: 5.117202522934124

Epoch: 5| Step: 10
Training loss: 5.314559459686279
Validation loss: 5.0877947756039195

Epoch: 15| Step: 0
Training loss: 4.485363960266113
Validation loss: 5.060944449517034

Epoch: 5| Step: 1
Training loss: 4.642453193664551
Validation loss: 5.041789136907106

Epoch: 5| Step: 2
Training loss: 4.486027717590332
Validation loss: 5.021832953217209

Epoch: 5| Step: 3
Training loss: 5.418820381164551
Validation loss: 4.994144711443173

Epoch: 5| Step: 4
Training loss: 5.146515846252441
Validation loss: 4.975255971313805

Epoch: 5| Step: 5
Training loss: 5.717304229736328
Validation loss: 4.950445270025602

Epoch: 5| Step: 6
Training loss: 4.415248870849609
Validation loss: 4.926508903503418

Epoch: 5| Step: 7
Training loss: 3.7140700817108154
Validation loss: 4.909743226984496

Epoch: 5| Step: 8
Training loss: 4.6602301597595215
Validation loss: 4.881888174241589

Epoch: 5| Step: 9
Training loss: 3.9070656299591064
Validation loss: 4.85908866185014

Epoch: 5| Step: 10
Training loss: 5.4400529861450195
Validation loss: 4.842002889161469

Epoch: 16| Step: 0
Training loss: 5.392954349517822
Validation loss: 4.808644197320425

Epoch: 5| Step: 1
Training loss: 5.143160343170166
Validation loss: 4.791825473949474

Epoch: 5| Step: 2
Training loss: 3.9575488567352295
Validation loss: 4.764719588782198

Epoch: 5| Step: 3
Training loss: 5.0937042236328125
Validation loss: 4.742975873331869

Epoch: 5| Step: 4
Training loss: 3.197672128677368
Validation loss: 4.715496170905329

Epoch: 5| Step: 5
Training loss: 4.312941551208496
Validation loss: 4.694150847773398

Epoch: 5| Step: 6
Training loss: 5.227059364318848
Validation loss: 4.657953564838697

Epoch: 5| Step: 7
Training loss: 4.366158962249756
Validation loss: 4.63949728012085

Epoch: 5| Step: 8
Training loss: 3.5890464782714844
Validation loss: 4.614309700586462

Epoch: 5| Step: 9
Training loss: 3.691096544265747
Validation loss: 4.577857809682047

Epoch: 5| Step: 10
Training loss: 5.044857978820801
Validation loss: 4.5659969750271046

Epoch: 17| Step: 0
Training loss: 4.306133270263672
Validation loss: 4.534653689271661

Epoch: 5| Step: 1
Training loss: 3.609187602996826
Validation loss: 4.504860370389877

Epoch: 5| Step: 2
Training loss: 4.428254127502441
Validation loss: 4.470742784520631

Epoch: 5| Step: 3
Training loss: 4.739436149597168
Validation loss: 4.450139584079865

Epoch: 5| Step: 4
Training loss: 4.479855060577393
Validation loss: 4.423040677142399

Epoch: 5| Step: 5
Training loss: 3.58463716506958
Validation loss: 4.397054354349772

Epoch: 5| Step: 6
Training loss: 3.9820950031280518
Validation loss: 4.366261313038487

Epoch: 5| Step: 7
Training loss: 4.162362575531006
Validation loss: 4.326974648301319

Epoch: 5| Step: 8
Training loss: 4.24475622177124
Validation loss: 4.300951829520605

Epoch: 5| Step: 9
Training loss: 3.8926150798797607
Validation loss: 4.270790228279688

Epoch: 5| Step: 10
Training loss: 4.491308689117432
Validation loss: 4.2420591641497865

Epoch: 18| Step: 0
Training loss: 4.198698043823242
Validation loss: 4.212249966077907

Epoch: 5| Step: 1
Training loss: 3.616551160812378
Validation loss: 4.197474761675763

Epoch: 5| Step: 2
Training loss: 3.502786636352539
Validation loss: 4.163699242376512

Epoch: 5| Step: 3
Training loss: 4.0151472091674805
Validation loss: 4.12619311066084

Epoch: 5| Step: 4
Training loss: 4.201840400695801
Validation loss: 4.113652998401273

Epoch: 5| Step: 5
Training loss: 3.387012481689453
Validation loss: 4.080574325335923

Epoch: 5| Step: 6
Training loss: 3.5839686393737793
Validation loss: 4.062675629892657

Epoch: 5| Step: 7
Training loss: 4.177063941955566
Validation loss: 4.025109752531974

Epoch: 5| Step: 8
Training loss: 3.6950085163116455
Validation loss: 4.000260978616694

Epoch: 5| Step: 9
Training loss: 3.9686119556427
Validation loss: 3.96983407133369

Epoch: 5| Step: 10
Training loss: 4.210245609283447
Validation loss: 3.940411111359955

Epoch: 19| Step: 0
Training loss: 4.149738311767578
Validation loss: 3.916447957356771

Epoch: 5| Step: 1
Training loss: 3.338672637939453
Validation loss: 3.89638941262358

Epoch: 5| Step: 2
Training loss: 3.803602695465088
Validation loss: 3.8627402090257212

Epoch: 5| Step: 3
Training loss: 3.5255305767059326
Validation loss: 3.833855782785723

Epoch: 5| Step: 4
Training loss: 2.7583205699920654
Validation loss: 3.802886386071482

Epoch: 5| Step: 5
Training loss: 4.351065635681152
Validation loss: 3.781978935323736

Epoch: 5| Step: 6
Training loss: 3.6500773429870605
Validation loss: 3.7413678528160177

Epoch: 5| Step: 7
Training loss: 3.477428436279297
Validation loss: 3.7054647963534117

Epoch: 5| Step: 8
Training loss: 3.2373251914978027
Validation loss: 3.703165925959105

Epoch: 5| Step: 9
Training loss: 3.1905174255371094
Validation loss: 3.6585813824848463

Epoch: 5| Step: 10
Training loss: 3.9999887943267822
Validation loss: 3.6314709160917547

Epoch: 20| Step: 0
Training loss: 2.7681884765625
Validation loss: 3.6027138387003252

Epoch: 5| Step: 1
Training loss: 3.9041221141815186
Validation loss: 3.5626108338755946

Epoch: 5| Step: 2
Training loss: 3.5348846912384033
Validation loss: 3.5503305517217165

Epoch: 5| Step: 3
Training loss: 3.4712271690368652
Validation loss: 3.502394830026934

Epoch: 5| Step: 4
Training loss: 3.1287877559661865
Validation loss: 3.4782589250995266

Epoch: 5| Step: 5
Training loss: 2.983692169189453
Validation loss: 3.467747219147221

Epoch: 5| Step: 6
Training loss: 3.34637451171875
Validation loss: 3.4403812654556765

Epoch: 5| Step: 7
Training loss: 3.1676344871520996
Validation loss: 3.396202346330048

Epoch: 5| Step: 8
Training loss: 3.023024320602417
Validation loss: 3.3653428375080066

Epoch: 5| Step: 9
Training loss: 3.111527919769287
Validation loss: 3.3470908082941526

Epoch: 5| Step: 10
Training loss: 4.149872779846191
Validation loss: 3.31107428509702

Epoch: 21| Step: 0
Training loss: 3.2269930839538574
Validation loss: 3.280689557393392

Epoch: 5| Step: 1
Training loss: 2.51173996925354
Validation loss: 3.2523840806817494

Epoch: 5| Step: 2
Training loss: 3.073460102081299
Validation loss: 3.2298550400682675

Epoch: 5| Step: 3
Training loss: 3.728332042694092
Validation loss: 3.205178745331303

Epoch: 5| Step: 4
Training loss: 3.5609893798828125
Validation loss: 3.1746680608359714

Epoch: 5| Step: 5
Training loss: 2.80696702003479
Validation loss: 3.154356279680806

Epoch: 5| Step: 6
Training loss: 3.1450765132904053
Validation loss: 3.11297248512186

Epoch: 5| Step: 7
Training loss: 3.5310559272766113
Validation loss: 3.0818311552847586

Epoch: 5| Step: 8
Training loss: 2.5082435607910156
Validation loss: 3.07902511729989

Epoch: 5| Step: 9
Training loss: 3.284512996673584
Validation loss: 3.042540383595292

Epoch: 5| Step: 10
Training loss: 2.4719934463500977
Validation loss: 3.020352748132521

Epoch: 22| Step: 0
Training loss: 2.751793384552002
Validation loss: 2.992164565670875

Epoch: 5| Step: 1
Training loss: 3.2206108570098877
Validation loss: 2.9555365090729087

Epoch: 5| Step: 2
Training loss: 3.022942304611206
Validation loss: 2.9250231942822857

Epoch: 5| Step: 3
Training loss: 2.801652193069458
Validation loss: 2.9277504156994563

Epoch: 5| Step: 4
Training loss: 2.8352770805358887
Validation loss: 2.8966215784831713

Epoch: 5| Step: 5
Training loss: 3.0130815505981445
Validation loss: 2.868762211133075

Epoch: 5| Step: 6
Training loss: 2.7525103092193604
Validation loss: 2.840714241868706

Epoch: 5| Step: 7
Training loss: 3.319992780685425
Validation loss: 2.830948101576938

Epoch: 5| Step: 8
Training loss: 2.3100528717041016
Validation loss: 2.825658639272054

Epoch: 5| Step: 9
Training loss: 2.982865810394287
Validation loss: 2.7742488256064792

Epoch: 5| Step: 10
Training loss: 2.7503950595855713
Validation loss: 2.754532842225926

Epoch: 23| Step: 0
Training loss: 3.6995110511779785
Validation loss: 2.7399581683579313

Epoch: 5| Step: 1
Training loss: 2.314439058303833
Validation loss: 2.7357166633811048

Epoch: 5| Step: 2
Training loss: 2.059382200241089
Validation loss: 2.707791336121098

Epoch: 5| Step: 3
Training loss: 2.7429537773132324
Validation loss: 2.683369962118005

Epoch: 5| Step: 4
Training loss: 3.2412915229797363
Validation loss: 2.6752693294197

Epoch: 5| Step: 5
Training loss: 3.0811331272125244
Validation loss: 2.6281717438851633

Epoch: 5| Step: 6
Training loss: 3.3466179370880127
Validation loss: 2.60851357060094

Epoch: 5| Step: 7
Training loss: 2.360894203186035
Validation loss: 2.5842391995973486

Epoch: 5| Step: 8
Training loss: 2.1994452476501465
Validation loss: 2.574956768302507

Epoch: 5| Step: 9
Training loss: 2.7727975845336914
Validation loss: 2.5389054334291847

Epoch: 5| Step: 10
Training loss: 1.973326325416565
Validation loss: 2.522632601440594

Epoch: 24| Step: 0
Training loss: 2.9079766273498535
Validation loss: 2.5122224105301725

Epoch: 5| Step: 1
Training loss: 1.8617976903915405
Validation loss: 2.505238192055815

Epoch: 5| Step: 2
Training loss: 2.034350633621216
Validation loss: 2.4836788433854298

Epoch: 5| Step: 3
Training loss: 2.384079694747925
Validation loss: 2.4863843302572928

Epoch: 5| Step: 4
Training loss: 3.028873920440674
Validation loss: 2.4572559172107327

Epoch: 5| Step: 5
Training loss: 1.740740418434143
Validation loss: 2.4559456866274596

Epoch: 5| Step: 6
Training loss: 2.5902533531188965
Validation loss: 2.419584681910853

Epoch: 5| Step: 7
Training loss: 3.1418418884277344
Validation loss: 2.4312979482835337

Epoch: 5| Step: 8
Training loss: 2.9044406414031982
Validation loss: 2.3961437491960424

Epoch: 5| Step: 9
Training loss: 2.7520363330841064
Validation loss: 2.394046942392985

Epoch: 5| Step: 10
Training loss: 2.907102108001709
Validation loss: 2.3689523871226976

Epoch: 25| Step: 0
Training loss: 2.643867015838623
Validation loss: 2.384513424288842

Epoch: 5| Step: 1
Training loss: 2.0375254154205322
Validation loss: 2.3419198989868164

Epoch: 5| Step: 2
Training loss: 2.569815158843994
Validation loss: 2.3225952092037407

Epoch: 5| Step: 3
Training loss: 2.3856327533721924
Validation loss: 2.342415007211829

Epoch: 5| Step: 4
Training loss: 2.542876720428467
Validation loss: 2.291645162849016

Epoch: 5| Step: 5
Training loss: 2.4429523944854736
Validation loss: 2.30228441761386

Epoch: 5| Step: 6
Training loss: 2.7162957191467285
Validation loss: 2.293953295676939

Epoch: 5| Step: 7
Training loss: 2.5472006797790527
Validation loss: 2.273557315590561

Epoch: 5| Step: 8
Training loss: 2.5771279335021973
Validation loss: 2.2795190195883475

Epoch: 5| Step: 9
Training loss: 2.672675609588623
Validation loss: 2.273299232605965

Epoch: 5| Step: 10
Training loss: 2.4526150226593018
Validation loss: 2.2695413097258537

Epoch: 26| Step: 0
Training loss: 2.9411137104034424
Validation loss: 2.233733961659093

Epoch: 5| Step: 1
Training loss: 2.592134952545166
Validation loss: 2.2595131448520127

Epoch: 5| Step: 2
Training loss: 2.6822032928466797
Validation loss: 2.2381825344536894

Epoch: 5| Step: 3
Training loss: 2.569868564605713
Validation loss: 2.2180554687335925

Epoch: 5| Step: 4
Training loss: 2.710114002227783
Validation loss: 2.2069743807597826

Epoch: 5| Step: 5
Training loss: 1.7344334125518799
Validation loss: 2.20031056609205

Epoch: 5| Step: 6
Training loss: 1.9088411331176758
Validation loss: 2.1956964128760883

Epoch: 5| Step: 7
Training loss: 2.1860556602478027
Validation loss: 2.1971451800356627

Epoch: 5| Step: 8
Training loss: 2.1590514183044434
Validation loss: 2.1937723493063324

Epoch: 5| Step: 9
Training loss: 2.9438018798828125
Validation loss: 2.2021394314304477

Epoch: 5| Step: 10
Training loss: 2.737548828125
Validation loss: 2.2091282439488236

Epoch: 27| Step: 0
Training loss: 2.138292074203491
Validation loss: 2.1771780290911273

Epoch: 5| Step: 1
Training loss: 2.1079437732696533
Validation loss: 2.204410404287359

Epoch: 5| Step: 2
Training loss: 2.854020118713379
Validation loss: 2.1824119731944096

Epoch: 5| Step: 3
Training loss: 2.7911574840545654
Validation loss: 2.1842666261939594

Epoch: 5| Step: 4
Training loss: 2.3293349742889404
Validation loss: 2.1696833231115855

Epoch: 5| Step: 5
Training loss: 2.1345255374908447
Validation loss: 2.1775552380469536

Epoch: 5| Step: 6
Training loss: 2.0892088413238525
Validation loss: 2.1949899196624756

Epoch: 5| Step: 7
Training loss: 2.9318113327026367
Validation loss: 2.1796492556089997

Epoch: 5| Step: 8
Training loss: 2.115117073059082
Validation loss: 2.177645670470371

Epoch: 5| Step: 9
Training loss: 2.1686716079711914
Validation loss: 2.1736757242551414

Epoch: 5| Step: 10
Training loss: 3.470351219177246
Validation loss: 2.1541588588427474

Epoch: 28| Step: 0
Training loss: 2.6129214763641357
Validation loss: 2.1568831295095463

Epoch: 5| Step: 1
Training loss: 2.240557909011841
Validation loss: 2.168749241418736

Epoch: 5| Step: 2
Training loss: 2.293459415435791
Validation loss: 2.159382383028666

Epoch: 5| Step: 3
Training loss: 2.9899215698242188
Validation loss: 2.1778360720603698

Epoch: 5| Step: 4
Training loss: 2.5823662281036377
Validation loss: 2.156135037381162

Epoch: 5| Step: 5
Training loss: 2.009108304977417
Validation loss: 2.1801472633115706

Epoch: 5| Step: 6
Training loss: 1.940256118774414
Validation loss: 2.185621428233321

Epoch: 5| Step: 7
Training loss: 2.4758429527282715
Validation loss: 2.183213333929739

Epoch: 5| Step: 8
Training loss: 2.8540077209472656
Validation loss: 2.1756350019926667

Epoch: 5| Step: 9
Training loss: 2.2048494815826416
Validation loss: 2.1695533337131625

Epoch: 5| Step: 10
Training loss: 2.4672911167144775
Validation loss: 2.1568399167829946

Epoch: 29| Step: 0
Training loss: 2.4588730335235596
Validation loss: 2.186811251025046

Epoch: 5| Step: 1
Training loss: 2.3560967445373535
Validation loss: 2.1690768734101327

Epoch: 5| Step: 2
Training loss: 2.0465657711029053
Validation loss: 2.1665901676301034

Epoch: 5| Step: 3
Training loss: 2.786907911300659
Validation loss: 2.1449891354448054

Epoch: 5| Step: 4
Training loss: 2.317183256149292
Validation loss: 2.158323052108929

Epoch: 5| Step: 5
Training loss: 2.608119010925293
Validation loss: 2.157864891072755

Epoch: 5| Step: 6
Training loss: 2.5823516845703125
Validation loss: 2.167928872569915

Epoch: 5| Step: 7
Training loss: 2.5276660919189453
Validation loss: 2.1536304053439888

Epoch: 5| Step: 8
Training loss: 2.724172353744507
Validation loss: 2.1611632993144374

Epoch: 5| Step: 9
Training loss: 2.380934476852417
Validation loss: 2.175666998791438

Epoch: 5| Step: 10
Training loss: 1.9694989919662476
Validation loss: 2.141787267500354

Epoch: 30| Step: 0
Training loss: 2.1506409645080566
Validation loss: 2.157808765288322

Epoch: 5| Step: 1
Training loss: 3.0059170722961426
Validation loss: 2.150226726326891

Epoch: 5| Step: 2
Training loss: 2.278771162033081
Validation loss: 2.1595976403964463

Epoch: 5| Step: 3
Training loss: 2.4750583171844482
Validation loss: 2.1501512014737694

Epoch: 5| Step: 4
Training loss: 1.7233299016952515
Validation loss: 2.183913582114763

Epoch: 5| Step: 5
Training loss: 2.6410229206085205
Validation loss: 2.183805929717197

Epoch: 5| Step: 6
Training loss: 2.2634053230285645
Validation loss: 2.2091526049439625

Epoch: 5| Step: 7
Training loss: 2.4074041843414307
Validation loss: 2.171367447863343

Epoch: 5| Step: 8
Training loss: 2.8613522052764893
Validation loss: 2.182815359484765

Epoch: 5| Step: 9
Training loss: 2.1481690406799316
Validation loss: 2.1691779616058513

Epoch: 5| Step: 10
Training loss: 2.812420606613159
Validation loss: 2.1620932368821997

Epoch: 31| Step: 0
Training loss: 2.8414032459259033
Validation loss: 2.1997216081106536

Epoch: 5| Step: 1
Training loss: 2.1657330989837646
Validation loss: 2.1907770377333446

Epoch: 5| Step: 2
Training loss: 2.121781587600708
Validation loss: 2.1779213515661096

Epoch: 5| Step: 3
Training loss: 2.1039414405822754
Validation loss: 2.1742723193219913

Epoch: 5| Step: 4
Training loss: 2.1819756031036377
Validation loss: 2.167948002456337

Epoch: 5| Step: 5
Training loss: 2.2629170417785645
Validation loss: 2.184898594374298

Epoch: 5| Step: 6
Training loss: 3.0230190753936768
Validation loss: 2.1648137697609524

Epoch: 5| Step: 7
Training loss: 2.5503926277160645
Validation loss: 2.1852798154277187

Epoch: 5| Step: 8
Training loss: 2.8361120223999023
Validation loss: 2.1715644123733684

Epoch: 5| Step: 9
Training loss: 2.3013224601745605
Validation loss: 2.1606077404432398

Epoch: 5| Step: 10
Training loss: 2.5603997707366943
Validation loss: 2.1730506650863157

Epoch: 32| Step: 0
Training loss: 2.2604496479034424
Validation loss: 2.1758162488219557

Epoch: 5| Step: 1
Training loss: 1.9067493677139282
Validation loss: 2.173294921075144

Epoch: 5| Step: 2
Training loss: 1.783198356628418
Validation loss: 2.179647837915728

Epoch: 5| Step: 3
Training loss: 2.925671100616455
Validation loss: 2.161589927570794

Epoch: 5| Step: 4
Training loss: 2.331393241882324
Validation loss: 2.1535298798673894

Epoch: 5| Step: 5
Training loss: 2.2360570430755615
Validation loss: 2.1734878939967

Epoch: 5| Step: 6
Training loss: 2.6265711784362793
Validation loss: 2.182226202821219

Epoch: 5| Step: 7
Training loss: 2.417074680328369
Validation loss: 2.174365456386279

Epoch: 5| Step: 8
Training loss: 2.791944980621338
Validation loss: 2.172431586891092

Epoch: 5| Step: 9
Training loss: 2.7046914100646973
Validation loss: 2.1631101433948805

Epoch: 5| Step: 10
Training loss: 2.756743907928467
Validation loss: 2.1681996160937893

Epoch: 33| Step: 0
Training loss: 2.2350335121154785
Validation loss: 2.1508944803668606

Epoch: 5| Step: 1
Training loss: 3.1453940868377686
Validation loss: 2.156871562362999

Epoch: 5| Step: 2
Training loss: 1.9497175216674805
Validation loss: 2.183231364014328

Epoch: 5| Step: 3
Training loss: 2.058713674545288
Validation loss: 2.1606622460067912

Epoch: 5| Step: 4
Training loss: 2.6264469623565674
Validation loss: 2.1759149079681723

Epoch: 5| Step: 5
Training loss: 2.2753615379333496
Validation loss: 2.1792717928527505

Epoch: 5| Step: 6
Training loss: 2.596360206604004
Validation loss: 2.1604805095221407

Epoch: 5| Step: 7
Training loss: 2.323359251022339
Validation loss: 2.175918476555937

Epoch: 5| Step: 8
Training loss: 2.631242275238037
Validation loss: 2.146177686670775

Epoch: 5| Step: 9
Training loss: 1.8179079294204712
Validation loss: 2.1941046740419123

Epoch: 5| Step: 10
Training loss: 2.8639111518859863
Validation loss: 2.159559396005446

Epoch: 34| Step: 0
Training loss: 2.2825775146484375
Validation loss: 2.1594722706784486

Epoch: 5| Step: 1
Training loss: 2.551917552947998
Validation loss: 2.170839766020416

Epoch: 5| Step: 2
Training loss: 2.3978183269500732
Validation loss: 2.1678127037581576

Epoch: 5| Step: 3
Training loss: 2.318004846572876
Validation loss: 2.153066172394701

Epoch: 5| Step: 4
Training loss: 2.046574592590332
Validation loss: 2.1752196332459808

Epoch: 5| Step: 5
Training loss: 2.607924699783325
Validation loss: 2.1671379304701284

Epoch: 5| Step: 6
Training loss: 2.4176087379455566
Validation loss: 2.1863457349038895

Epoch: 5| Step: 7
Training loss: 2.6707499027252197
Validation loss: 2.119306802749634

Epoch: 5| Step: 8
Training loss: 1.9463363885879517
Validation loss: 2.166417829452022

Epoch: 5| Step: 9
Training loss: 2.947465181350708
Validation loss: 2.1611654630271335

Epoch: 5| Step: 10
Training loss: 2.3499433994293213
Validation loss: 2.16062807267712

Epoch: 35| Step: 0
Training loss: 2.4725394248962402
Validation loss: 2.159492825949064

Epoch: 5| Step: 1
Training loss: 2.4748177528381348
Validation loss: 2.1601414039570797

Epoch: 5| Step: 2
Training loss: 1.8000065088272095
Validation loss: 2.1657756297819075

Epoch: 5| Step: 3
Training loss: 2.4143710136413574
Validation loss: 2.187630125271377

Epoch: 5| Step: 4
Training loss: 2.0633773803710938
Validation loss: 2.1596476262615574

Epoch: 5| Step: 5
Training loss: 2.587602138519287
Validation loss: 2.1536413892622916

Epoch: 5| Step: 6
Training loss: 2.72113299369812
Validation loss: 2.1438968104700886

Epoch: 5| Step: 7
Training loss: 1.9193916320800781
Validation loss: 2.155543622150216

Epoch: 5| Step: 8
Training loss: 2.6308035850524902
Validation loss: 2.149167274916044

Epoch: 5| Step: 9
Training loss: 2.1099982261657715
Validation loss: 2.1530810351012857

Epoch: 5| Step: 10
Training loss: 3.403773069381714
Validation loss: 2.1605140111779653

Epoch: 36| Step: 0
Training loss: 2.124051570892334
Validation loss: 2.144799276064801

Epoch: 5| Step: 1
Training loss: 2.609980344772339
Validation loss: 2.1389842699932795

Epoch: 5| Step: 2
Training loss: 2.670602798461914
Validation loss: 2.155291857257966

Epoch: 5| Step: 3
Training loss: 2.610652446746826
Validation loss: 2.1326269436908025

Epoch: 5| Step: 4
Training loss: 2.464700698852539
Validation loss: 2.1608840188672467

Epoch: 5| Step: 5
Training loss: 2.261683940887451
Validation loss: 2.1587728018401773

Epoch: 5| Step: 6
Training loss: 2.6261239051818848
Validation loss: 2.143230717669251

Epoch: 5| Step: 7
Training loss: 2.479227066040039
Validation loss: 2.160540780713481

Epoch: 5| Step: 8
Training loss: 2.297966480255127
Validation loss: 2.158155184920116

Epoch: 5| Step: 9
Training loss: 2.4087491035461426
Validation loss: 2.1473575663822952

Epoch: 5| Step: 10
Training loss: 1.6165599822998047
Validation loss: 2.152748974420691

Epoch: 37| Step: 0
Training loss: 2.68558669090271
Validation loss: 2.1504324354151243

Epoch: 5| Step: 1
Training loss: 2.5582752227783203
Validation loss: 2.1388977355854486

Epoch: 5| Step: 2
Training loss: 2.7891488075256348
Validation loss: 2.1219915369505524

Epoch: 5| Step: 3
Training loss: 3.2273430824279785
Validation loss: 2.1445895253971057

Epoch: 5| Step: 4
Training loss: 2.1141228675842285
Validation loss: 2.1421166235400784

Epoch: 5| Step: 5
Training loss: 2.607811689376831
Validation loss: 2.1774381693973335

Epoch: 5| Step: 6
Training loss: 1.8402881622314453
Validation loss: 2.155471385166209

Epoch: 5| Step: 7
Training loss: 2.3717763423919678
Validation loss: 2.145585767684444

Epoch: 5| Step: 8
Training loss: 2.0575718879699707
Validation loss: 2.1479319705758044

Epoch: 5| Step: 9
Training loss: 2.210867404937744
Validation loss: 2.149866020807656

Epoch: 5| Step: 10
Training loss: 1.909166693687439
Validation loss: 2.1636826517761394

Epoch: 38| Step: 0
Training loss: 2.3457961082458496
Validation loss: 2.150670187447661

Epoch: 5| Step: 1
Training loss: 2.293611526489258
Validation loss: 2.1361551746245353

Epoch: 5| Step: 2
Training loss: 1.993322730064392
Validation loss: 2.151168919378711

Epoch: 5| Step: 3
Training loss: 3.1187877655029297
Validation loss: 2.1718268074015135

Epoch: 5| Step: 4
Training loss: 2.430753231048584
Validation loss: 2.1481148427532566

Epoch: 5| Step: 5
Training loss: 2.2316784858703613
Validation loss: 2.134725314314647

Epoch: 5| Step: 6
Training loss: 3.0784997940063477
Validation loss: 2.1423058445735643

Epoch: 5| Step: 7
Training loss: 2.743281364440918
Validation loss: 2.1382459978903494

Epoch: 5| Step: 8
Training loss: 2.451056957244873
Validation loss: 2.1255187167916247

Epoch: 5| Step: 9
Training loss: 1.9998188018798828
Validation loss: 2.1204931607810398

Epoch: 5| Step: 10
Training loss: 1.6615732908248901
Validation loss: 2.151497548626315

Epoch: 39| Step: 0
Training loss: 2.353698492050171
Validation loss: 2.116630173498584

Epoch: 5| Step: 1
Training loss: 2.3483870029449463
Validation loss: 2.1387265638638566

Epoch: 5| Step: 2
Training loss: 2.0509908199310303
Validation loss: 2.131476486882856

Epoch: 5| Step: 3
Training loss: 2.2107691764831543
Validation loss: 2.1587330884830926

Epoch: 5| Step: 4
Training loss: 2.9137401580810547
Validation loss: 2.108436958764189

Epoch: 5| Step: 5
Training loss: 2.539858102798462
Validation loss: 2.1308258169440815

Epoch: 5| Step: 6
Training loss: 2.1024317741394043
Validation loss: 2.116925967636929

Epoch: 5| Step: 7
Training loss: 2.2611191272735596
Validation loss: 2.138035874212942

Epoch: 5| Step: 8
Training loss: 3.079153537750244
Validation loss: 2.1202706367738786

Epoch: 5| Step: 9
Training loss: 2.343306064605713
Validation loss: 2.14215991573949

Epoch: 5| Step: 10
Training loss: 2.1300976276397705
Validation loss: 2.1210973288423274

Epoch: 40| Step: 0
Training loss: 3.479365110397339
Validation loss: 2.1465246754307903

Epoch: 5| Step: 1
Training loss: 2.675402879714966
Validation loss: 2.1484640862352107

Epoch: 5| Step: 2
Training loss: 2.522501230239868
Validation loss: 2.1424615703603274

Epoch: 5| Step: 3
Training loss: 2.455031633377075
Validation loss: 2.141843368930201

Epoch: 5| Step: 4
Training loss: 2.157902717590332
Validation loss: 2.134503949073053

Epoch: 5| Step: 5
Training loss: 1.9296846389770508
Validation loss: 2.1385188641086703

Epoch: 5| Step: 6
Training loss: 2.3070895671844482
Validation loss: 2.138427415201741

Epoch: 5| Step: 7
Training loss: 2.283041477203369
Validation loss: 2.154805980702882

Epoch: 5| Step: 8
Training loss: 2.4692137241363525
Validation loss: 2.147857158414779

Epoch: 5| Step: 9
Training loss: 1.7727845907211304
Validation loss: 2.1559762570165817

Epoch: 5| Step: 10
Training loss: 2.2633841037750244
Validation loss: 2.1178803059362594

Epoch: 41| Step: 0
Training loss: 2.344485282897949
Validation loss: 2.139802561011366

Epoch: 5| Step: 1
Training loss: 2.5200061798095703
Validation loss: 2.122193630023669

Epoch: 5| Step: 2
Training loss: 2.2542595863342285
Validation loss: 2.1367542154045513

Epoch: 5| Step: 3
Training loss: 2.3079471588134766
Validation loss: 2.1367545345778107

Epoch: 5| Step: 4
Training loss: 2.479207992553711
Validation loss: 2.137499632373933

Epoch: 5| Step: 5
Training loss: 2.9618067741394043
Validation loss: 2.149078058940108

Epoch: 5| Step: 6
Training loss: 2.463237762451172
Validation loss: 2.151431675880186

Epoch: 5| Step: 7
Training loss: 2.3156445026397705
Validation loss: 2.1469052119921614

Epoch: 5| Step: 8
Training loss: 2.6751856803894043
Validation loss: 2.13748267645477

Epoch: 5| Step: 9
Training loss: 1.58856999874115
Validation loss: 2.1235180016486876

Epoch: 5| Step: 10
Training loss: 2.1304612159729004
Validation loss: 2.1173249342108287

Epoch: 42| Step: 0
Training loss: 2.8179843425750732
Validation loss: 2.1647150913874307

Epoch: 5| Step: 1
Training loss: 2.172004222869873
Validation loss: 2.1408449372937604

Epoch: 5| Step: 2
Training loss: 2.6184639930725098
Validation loss: 2.146617243366857

Epoch: 5| Step: 3
Training loss: 2.352293014526367
Validation loss: 2.1262266200075866

Epoch: 5| Step: 4
Training loss: 2.831650733947754
Validation loss: 2.1496860314440984

Epoch: 5| Step: 5
Training loss: 1.9826831817626953
Validation loss: 2.156876266643565

Epoch: 5| Step: 6
Training loss: 2.476996660232544
Validation loss: 2.145197711965089

Epoch: 5| Step: 7
Training loss: 2.118185043334961
Validation loss: 2.129551545266182

Epoch: 5| Step: 8
Training loss: 2.4482131004333496
Validation loss: 2.1515803324278964

Epoch: 5| Step: 9
Training loss: 2.277067184448242
Validation loss: 2.1552829921886487

Epoch: 5| Step: 10
Training loss: 2.085007905960083
Validation loss: 2.1417618054215626

Epoch: 43| Step: 0
Training loss: 1.7919034957885742
Validation loss: 2.1564030903641895

Epoch: 5| Step: 1
Training loss: 2.418551206588745
Validation loss: 2.1399178043488534

Epoch: 5| Step: 2
Training loss: 2.0078940391540527
Validation loss: 2.123958238991358

Epoch: 5| Step: 3
Training loss: 1.381753921508789
Validation loss: 2.1496949913681194

Epoch: 5| Step: 4
Training loss: 2.0559463500976562
Validation loss: 2.1479562995254353

Epoch: 5| Step: 5
Training loss: 2.486320972442627
Validation loss: 2.126027504603068

Epoch: 5| Step: 6
Training loss: 2.818185567855835
Validation loss: 2.1240028565929783

Epoch: 5| Step: 7
Training loss: 3.176970958709717
Validation loss: 2.1371018245656

Epoch: 5| Step: 8
Training loss: 2.9403538703918457
Validation loss: 2.1476827257422992

Epoch: 5| Step: 9
Training loss: 2.330071210861206
Validation loss: 2.1450105213349864

Epoch: 5| Step: 10
Training loss: 2.7902746200561523
Validation loss: 2.1284864999914683

Epoch: 44| Step: 0
Training loss: 2.524073839187622
Validation loss: 2.1302929578288907

Epoch: 5| Step: 1
Training loss: 2.202887773513794
Validation loss: 2.1442299324979066

Epoch: 5| Step: 2
Training loss: 2.1130645275115967
Validation loss: 2.13605998921138

Epoch: 5| Step: 3
Training loss: 2.108811616897583
Validation loss: 2.1470790934819046

Epoch: 5| Step: 4
Training loss: 2.424905300140381
Validation loss: 2.1105752247636036

Epoch: 5| Step: 5
Training loss: 2.589790105819702
Validation loss: 2.121349738490197

Epoch: 5| Step: 6
Training loss: 3.422666549682617
Validation loss: 2.141800170303673

Epoch: 5| Step: 7
Training loss: 2.0821444988250732
Validation loss: 2.1402103747090986

Epoch: 5| Step: 8
Training loss: 2.48447847366333
Validation loss: 2.1392190764027257

Epoch: 5| Step: 9
Training loss: 2.1022377014160156
Validation loss: 2.146406732579713

Epoch: 5| Step: 10
Training loss: 1.898819923400879
Validation loss: 2.1348222327488724

Epoch: 45| Step: 0
Training loss: 1.6390001773834229
Validation loss: 2.1652449664249214

Epoch: 5| Step: 1
Training loss: 2.364508867263794
Validation loss: 2.1438554922739663

Epoch: 5| Step: 2
Training loss: 1.9501367807388306
Validation loss: 2.1487373203359623

Epoch: 5| Step: 3
Training loss: 2.634678840637207
Validation loss: 2.1470208014211347

Epoch: 5| Step: 4
Training loss: 2.8034048080444336
Validation loss: 2.1369888654319187

Epoch: 5| Step: 5
Training loss: 2.1854774951934814
Validation loss: 2.1541885252921813

Epoch: 5| Step: 6
Training loss: 2.360616683959961
Validation loss: 2.1247248982870452

Epoch: 5| Step: 7
Training loss: 2.5235180854797363
Validation loss: 2.124255298286356

Epoch: 5| Step: 8
Training loss: 2.38396954536438
Validation loss: 2.1431578807933356

Epoch: 5| Step: 9
Training loss: 2.435698986053467
Validation loss: 2.130624989027618

Epoch: 5| Step: 10
Training loss: 2.7558939456939697
Validation loss: 2.148923002263551

Epoch: 46| Step: 0
Training loss: 2.4349327087402344
Validation loss: 2.1119552555904595

Epoch: 5| Step: 1
Training loss: 2.221160411834717
Validation loss: 2.126921115383025

Epoch: 5| Step: 2
Training loss: 2.442807197570801
Validation loss: 2.126041886627033

Epoch: 5| Step: 3
Training loss: 2.2325611114501953
Validation loss: 2.131813382589689

Epoch: 5| Step: 4
Training loss: 1.9840177297592163
Validation loss: 2.129750100515222

Epoch: 5| Step: 5
Training loss: 1.944933295249939
Validation loss: 2.1583165148253083

Epoch: 5| Step: 6
Training loss: 2.6563704013824463
Validation loss: 2.120530725807272

Epoch: 5| Step: 7
Training loss: 2.853926420211792
Validation loss: 2.1649658192870436

Epoch: 5| Step: 8
Training loss: 2.0166468620300293
Validation loss: 2.1228350208651636

Epoch: 5| Step: 9
Training loss: 2.2810301780700684
Validation loss: 2.134807138032811

Epoch: 5| Step: 10
Training loss: 2.742992401123047
Validation loss: 2.119610099382298

Epoch: 47| Step: 0
Training loss: 1.9074472188949585
Validation loss: 2.1163503739141647

Epoch: 5| Step: 1
Training loss: 2.3169426918029785
Validation loss: 2.117228502868324

Epoch: 5| Step: 2
Training loss: 2.5799057483673096
Validation loss: 2.124167300039722

Epoch: 5| Step: 3
Training loss: 2.0570414066314697
Validation loss: 2.112572976337966

Epoch: 5| Step: 4
Training loss: 2.1800131797790527
Validation loss: 2.133017252850276

Epoch: 5| Step: 5
Training loss: 2.3420517444610596
Validation loss: 2.1064990669168453

Epoch: 5| Step: 6
Training loss: 1.7140849828720093
Validation loss: 2.1036496828961115

Epoch: 5| Step: 7
Training loss: 3.12261962890625
Validation loss: 2.1192103432070826

Epoch: 5| Step: 8
Training loss: 2.6531708240509033
Validation loss: 2.1244710671004428

Epoch: 5| Step: 9
Training loss: 2.296929121017456
Validation loss: 2.1082117275525163

Epoch: 5| Step: 10
Training loss: 2.822944402694702
Validation loss: 2.135478658060874

Epoch: 48| Step: 0
Training loss: 1.9569000005722046
Validation loss: 2.108575808104648

Epoch: 5| Step: 1
Training loss: 2.8752071857452393
Validation loss: 2.0954769221685265

Epoch: 5| Step: 2
Training loss: 1.8912967443466187
Validation loss: 2.119087198729156

Epoch: 5| Step: 3
Training loss: 2.701010227203369
Validation loss: 2.1374345569200415

Epoch: 5| Step: 4
Training loss: 2.4340660572052
Validation loss: 2.1080402353758454

Epoch: 5| Step: 5
Training loss: 2.535083055496216
Validation loss: 2.133256225175755

Epoch: 5| Step: 6
Training loss: 2.15362811088562
Validation loss: 2.1082922591957995

Epoch: 5| Step: 7
Training loss: 2.2672011852264404
Validation loss: 2.0989473776150773

Epoch: 5| Step: 8
Training loss: 1.449074625968933
Validation loss: 2.123442671632254

Epoch: 5| Step: 9
Training loss: 2.5211408138275146
Validation loss: 2.1277383296720442

Epoch: 5| Step: 10
Training loss: 2.8996317386627197
Validation loss: 2.1190100126369025

Epoch: 49| Step: 0
Training loss: 2.1198935508728027
Validation loss: 2.11408660745108

Epoch: 5| Step: 1
Training loss: 2.6612324714660645
Validation loss: 2.1228435808612454

Epoch: 5| Step: 2
Training loss: 2.5859732627868652
Validation loss: 2.1171617636116604

Epoch: 5| Step: 3
Training loss: 2.121211528778076
Validation loss: 2.1326542515908518

Epoch: 5| Step: 4
Training loss: 2.9270873069763184
Validation loss: 2.1393317432813745

Epoch: 5| Step: 5
Training loss: 2.2946906089782715
Validation loss: 2.1184213366559757

Epoch: 5| Step: 6
Training loss: 1.7051918506622314
Validation loss: 2.126096192226615

Epoch: 5| Step: 7
Training loss: 1.7764536142349243
Validation loss: 2.1124009829695507

Epoch: 5| Step: 8
Training loss: 2.6032702922821045
Validation loss: 2.132070872091478

Epoch: 5| Step: 9
Training loss: 2.8048484325408936
Validation loss: 2.1118320034396265

Epoch: 5| Step: 10
Training loss: 1.9899866580963135
Validation loss: 2.0904558832927416

Epoch: 50| Step: 0
Training loss: 2.8629887104034424
Validation loss: 2.1114417827257546

Epoch: 5| Step: 1
Training loss: 3.01288104057312
Validation loss: 2.1290470643710067

Epoch: 5| Step: 2
Training loss: 2.1206512451171875
Validation loss: 2.1015346421990344

Epoch: 5| Step: 3
Training loss: 2.5900168418884277
Validation loss: 2.140228702176002

Epoch: 5| Step: 4
Training loss: 2.5848236083984375
Validation loss: 2.09784988434084

Epoch: 5| Step: 5
Training loss: 2.2514805793762207
Validation loss: 2.1002229311132945

Epoch: 5| Step: 6
Training loss: 2.1970303058624268
Validation loss: 2.107093313688873

Epoch: 5| Step: 7
Training loss: 1.9425910711288452
Validation loss: 2.1051039259920836

Epoch: 5| Step: 8
Training loss: 2.308958053588867
Validation loss: 2.1267352360551075

Epoch: 5| Step: 9
Training loss: 2.0386343002319336
Validation loss: 2.0940880031995874

Epoch: 5| Step: 10
Training loss: 1.748415470123291
Validation loss: 2.0999592170920423

Epoch: 51| Step: 0
Training loss: 2.7845730781555176
Validation loss: 2.105470270238897

Epoch: 5| Step: 1
Training loss: 1.7585442066192627
Validation loss: 2.1047940177302205

Epoch: 5| Step: 2
Training loss: 2.2415199279785156
Validation loss: 2.1075932466855614

Epoch: 5| Step: 3
Training loss: 2.443586826324463
Validation loss: 2.1066369036192536

Epoch: 5| Step: 4
Training loss: 1.924203872680664
Validation loss: 2.100909453566356

Epoch: 5| Step: 5
Training loss: 2.3243331909179688
Validation loss: 2.1176687248291506

Epoch: 5| Step: 6
Training loss: 3.0317273139953613
Validation loss: 2.119384906625235

Epoch: 5| Step: 7
Training loss: 2.7771682739257812
Validation loss: 2.1185668117256573

Epoch: 5| Step: 8
Training loss: 2.1969504356384277
Validation loss: 2.109711020223556

Epoch: 5| Step: 9
Training loss: 2.33343243598938
Validation loss: 2.0966266406479703

Epoch: 5| Step: 10
Training loss: 1.7409337759017944
Validation loss: 2.1116308499408025

Epoch: 52| Step: 0
Training loss: 2.3285701274871826
Validation loss: 2.1268493398543327

Epoch: 5| Step: 1
Training loss: 1.924595832824707
Validation loss: 2.107338656661331

Epoch: 5| Step: 2
Training loss: 2.872863292694092
Validation loss: 2.1154540187569073

Epoch: 5| Step: 3
Training loss: 2.515305280685425
Validation loss: 2.119149345223622

Epoch: 5| Step: 4
Training loss: 2.18916654586792
Validation loss: 2.106025654782531

Epoch: 5| Step: 5
Training loss: 2.3964083194732666
Validation loss: 2.1253235878482943

Epoch: 5| Step: 6
Training loss: 1.9074451923370361
Validation loss: 2.113835652669271

Epoch: 5| Step: 7
Training loss: 2.7645316123962402
Validation loss: 2.1335777903115876

Epoch: 5| Step: 8
Training loss: 2.3862876892089844
Validation loss: 2.1134816113338677

Epoch: 5| Step: 9
Training loss: 2.1232950687408447
Validation loss: 2.0996170261854767

Epoch: 5| Step: 10
Training loss: 1.8129159212112427
Validation loss: 2.1093352661337903

Epoch: 53| Step: 0
Training loss: 2.4358482360839844
Validation loss: 2.104966168762535

Epoch: 5| Step: 1
Training loss: 2.3706183433532715
Validation loss: 2.1011422193178566

Epoch: 5| Step: 2
Training loss: 2.6310908794403076
Validation loss: 2.1252609811803347

Epoch: 5| Step: 3
Training loss: 2.1021251678466797
Validation loss: 2.1093924481381654

Epoch: 5| Step: 4
Training loss: 2.148622989654541
Validation loss: 2.112315111262824

Epoch: 5| Step: 5
Training loss: 1.974578857421875
Validation loss: 2.092457890510559

Epoch: 5| Step: 6
Training loss: 1.767472505569458
Validation loss: 2.103901861816324

Epoch: 5| Step: 7
Training loss: 1.991702675819397
Validation loss: 2.137447773769338

Epoch: 5| Step: 8
Training loss: 3.104461431503296
Validation loss: 2.1279460281454106

Epoch: 5| Step: 9
Training loss: 2.4068551063537598
Validation loss: 2.123398111712548

Epoch: 5| Step: 10
Training loss: 2.663562774658203
Validation loss: 2.130118730247662

Epoch: 54| Step: 0
Training loss: 1.7872635126113892
Validation loss: 2.10674447654396

Epoch: 5| Step: 1
Training loss: 1.9719676971435547
Validation loss: 2.102718109725624

Epoch: 5| Step: 2
Training loss: 2.395482301712036
Validation loss: 2.109066342794767

Epoch: 5| Step: 3
Training loss: 1.8875175714492798
Validation loss: 2.124562167352246

Epoch: 5| Step: 4
Training loss: 2.61657977104187
Validation loss: 2.0892496942191996

Epoch: 5| Step: 5
Training loss: 2.5051445960998535
Validation loss: 2.1209425951844905

Epoch: 5| Step: 6
Training loss: 2.2905755043029785
Validation loss: 2.1279463819278184

Epoch: 5| Step: 7
Training loss: 2.764185667037964
Validation loss: 2.1355503592439877

Epoch: 5| Step: 8
Training loss: 2.824392795562744
Validation loss: 2.1064768196434103

Epoch: 5| Step: 9
Training loss: 2.0622663497924805
Validation loss: 2.111332262715986

Epoch: 5| Step: 10
Training loss: 2.409858465194702
Validation loss: 2.129270290815702

Epoch: 55| Step: 0
Training loss: 2.0309128761291504
Validation loss: 2.1179720970892135

Epoch: 5| Step: 1
Training loss: 2.291738748550415
Validation loss: 2.1608292031031784

Epoch: 5| Step: 2
Training loss: 2.273953914642334
Validation loss: 2.126955093876008

Epoch: 5| Step: 3
Training loss: 2.0982441902160645
Validation loss: 2.1336812075748237

Epoch: 5| Step: 4
Training loss: 2.5392093658447266
Validation loss: 2.1090991202221123

Epoch: 5| Step: 5
Training loss: 2.2893645763397217
Validation loss: 2.1133712004589778

Epoch: 5| Step: 6
Training loss: 1.9063609838485718
Validation loss: 2.1261086438291814

Epoch: 5| Step: 7
Training loss: 2.2659759521484375
Validation loss: 2.1188946821356334

Epoch: 5| Step: 8
Training loss: 2.6118295192718506
Validation loss: 2.1201365122231106

Epoch: 5| Step: 9
Training loss: 1.8535324335098267
Validation loss: 2.125644918411009

Epoch: 5| Step: 10
Training loss: 3.4195737838745117
Validation loss: 2.1233184517070813

Epoch: 56| Step: 0
Training loss: 2.161381959915161
Validation loss: 2.0951471405644573

Epoch: 5| Step: 1
Training loss: 2.4003844261169434
Validation loss: 2.126303841990809

Epoch: 5| Step: 2
Training loss: 2.544443368911743
Validation loss: 2.096247428206987

Epoch: 5| Step: 3
Training loss: 2.4606070518493652
Validation loss: 2.1057083863084034

Epoch: 5| Step: 4
Training loss: 3.1139636039733887
Validation loss: 2.13033027033652

Epoch: 5| Step: 5
Training loss: 1.9006426334381104
Validation loss: 2.112817887336977

Epoch: 5| Step: 6
Training loss: 2.7861640453338623
Validation loss: 2.1372388896121772

Epoch: 5| Step: 7
Training loss: 1.7495235204696655
Validation loss: 2.1163192282440844

Epoch: 5| Step: 8
Training loss: 1.947164535522461
Validation loss: 2.095834529528054

Epoch: 5| Step: 9
Training loss: 2.2139534950256348
Validation loss: 2.0945120780698714

Epoch: 5| Step: 10
Training loss: 2.1084938049316406
Validation loss: 2.1105138294158445

Epoch: 57| Step: 0
Training loss: 2.9205386638641357
Validation loss: 2.109893468118483

Epoch: 5| Step: 1
Training loss: 1.6854263544082642
Validation loss: 2.109162051190612

Epoch: 5| Step: 2
Training loss: 2.398376226425171
Validation loss: 2.1460233580681587

Epoch: 5| Step: 3
Training loss: 2.0113120079040527
Validation loss: 2.109545046283353

Epoch: 5| Step: 4
Training loss: 1.5784269571304321
Validation loss: 2.121795792733469

Epoch: 5| Step: 5
Training loss: 2.458604574203491
Validation loss: 2.1214206859629643

Epoch: 5| Step: 6
Training loss: 2.318661689758301
Validation loss: 2.1032468862431024

Epoch: 5| Step: 7
Training loss: 2.222808361053467
Validation loss: 2.1266153038188977

Epoch: 5| Step: 8
Training loss: 2.532031536102295
Validation loss: 2.10950203352077

Epoch: 5| Step: 9
Training loss: 2.821362257003784
Validation loss: 2.0936273477410756

Epoch: 5| Step: 10
Training loss: 2.4193811416625977
Validation loss: 2.092110013449064

Epoch: 58| Step: 0
Training loss: 2.348980665206909
Validation loss: 2.10689563392311

Epoch: 5| Step: 1
Training loss: 3.2132339477539062
Validation loss: 2.1133616637158137

Epoch: 5| Step: 2
Training loss: 2.2638893127441406
Validation loss: 2.123572798185451

Epoch: 5| Step: 3
Training loss: 2.2790284156799316
Validation loss: 2.1140451456910823

Epoch: 5| Step: 4
Training loss: 2.524531841278076
Validation loss: 2.138441421652353

Epoch: 5| Step: 5
Training loss: 1.591840147972107
Validation loss: 2.1107823438541864

Epoch: 5| Step: 6
Training loss: 2.717372179031372
Validation loss: 2.12481306317032

Epoch: 5| Step: 7
Training loss: 1.971161127090454
Validation loss: 2.102909564971924

Epoch: 5| Step: 8
Training loss: 2.150697708129883
Validation loss: 2.1100803741844754

Epoch: 5| Step: 9
Training loss: 2.3203556537628174
Validation loss: 2.1128808195872972

Epoch: 5| Step: 10
Training loss: 1.684025764465332
Validation loss: 2.1165408293406167

Epoch: 59| Step: 0
Training loss: 1.6730552911758423
Validation loss: 2.113611562277681

Epoch: 5| Step: 1
Training loss: 2.0832531452178955
Validation loss: 2.0774292663861345

Epoch: 5| Step: 2
Training loss: 2.2552547454833984
Validation loss: 2.1013572062215498

Epoch: 5| Step: 3
Training loss: 2.903378963470459
Validation loss: 2.098778114523939

Epoch: 5| Step: 4
Training loss: 2.331794500350952
Validation loss: 2.133572177220416

Epoch: 5| Step: 5
Training loss: 3.007319688796997
Validation loss: 2.109360084738783

Epoch: 5| Step: 6
Training loss: 1.9238675832748413
Validation loss: 2.1168975342986402

Epoch: 5| Step: 7
Training loss: 1.8347110748291016
Validation loss: 2.127553000245043

Epoch: 5| Step: 8
Training loss: 2.4214253425598145
Validation loss: 2.1040671704917826

Epoch: 5| Step: 9
Training loss: 2.4361844062805176
Validation loss: 2.1280141620225805

Epoch: 5| Step: 10
Training loss: 2.2062058448791504
Validation loss: 2.130757785612537

Epoch: 60| Step: 0
Training loss: 2.3451943397521973
Validation loss: 2.1096565620873564

Epoch: 5| Step: 1
Training loss: 1.9810848236083984
Validation loss: 2.123485137057561

Epoch: 5| Step: 2
Training loss: 2.3106462955474854
Validation loss: 2.1085866241044897

Epoch: 5| Step: 3
Training loss: 1.6693099737167358
Validation loss: 2.132948283226259

Epoch: 5| Step: 4
Training loss: 1.7539279460906982
Validation loss: 2.122582135661956

Epoch: 5| Step: 5
Training loss: 2.4593894481658936
Validation loss: 2.109497585604268

Epoch: 5| Step: 6
Training loss: 2.830866575241089
Validation loss: 2.1399216728825725

Epoch: 5| Step: 7
Training loss: 2.458895206451416
Validation loss: 2.1235459363588722

Epoch: 5| Step: 8
Training loss: 2.9370276927948
Validation loss: 2.1286212257159653

Epoch: 5| Step: 9
Training loss: 2.199601411819458
Validation loss: 2.12159296517731

Epoch: 5| Step: 10
Training loss: 2.303858995437622
Validation loss: 2.106811897729033

Epoch: 61| Step: 0
Training loss: 1.8329235315322876
Validation loss: 2.1421457285522134

Epoch: 5| Step: 1
Training loss: 2.3671340942382812
Validation loss: 2.125917109110022

Epoch: 5| Step: 2
Training loss: 2.4843597412109375
Validation loss: 2.1238389066470567

Epoch: 5| Step: 3
Training loss: 2.247128963470459
Validation loss: 2.117799159019224

Epoch: 5| Step: 4
Training loss: 3.1496376991271973
Validation loss: 2.0984946373970277

Epoch: 5| Step: 5
Training loss: 1.8158851861953735
Validation loss: 2.0994339771168207

Epoch: 5| Step: 6
Training loss: 2.112616777420044
Validation loss: 2.095492770594935

Epoch: 5| Step: 7
Training loss: 1.7721763849258423
Validation loss: 2.1271677183848556

Epoch: 5| Step: 8
Training loss: 2.8891830444335938
Validation loss: 2.103569210216563

Epoch: 5| Step: 9
Training loss: 2.408029079437256
Validation loss: 2.093839937640775

Epoch: 5| Step: 10
Training loss: 2.280473470687866
Validation loss: 2.111055111372343

Epoch: 62| Step: 0
Training loss: 2.427131414413452
Validation loss: 2.14021744010269

Epoch: 5| Step: 1
Training loss: 2.557223320007324
Validation loss: 2.120402874485139

Epoch: 5| Step: 2
Training loss: 2.138568878173828
Validation loss: 2.101781883547383

Epoch: 5| Step: 3
Training loss: 2.639383316040039
Validation loss: 2.12491282468201

Epoch: 5| Step: 4
Training loss: 2.074497938156128
Validation loss: 2.0812921613775273

Epoch: 5| Step: 5
Training loss: 2.4752743244171143
Validation loss: 2.1125185835746025

Epoch: 5| Step: 6
Training loss: 2.2340636253356934
Validation loss: 2.0854693433289886

Epoch: 5| Step: 7
Training loss: 2.1110775470733643
Validation loss: 2.1145077443891958

Epoch: 5| Step: 8
Training loss: 1.9978710412979126
Validation loss: 2.1106710767233245

Epoch: 5| Step: 9
Training loss: 2.295318365097046
Validation loss: 2.1201633637951267

Epoch: 5| Step: 10
Training loss: 2.1007816791534424
Validation loss: 2.1051399605248564

Epoch: 63| Step: 0
Training loss: 2.297571897506714
Validation loss: 2.093283366131526

Epoch: 5| Step: 1
Training loss: 2.3438596725463867
Validation loss: 2.085149339450303

Epoch: 5| Step: 2
Training loss: 2.5246448516845703
Validation loss: 2.113275420281195

Epoch: 5| Step: 3
Training loss: 2.15558123588562
Validation loss: 2.132973796577864

Epoch: 5| Step: 4
Training loss: 1.5461393594741821
Validation loss: 2.124743789754888

Epoch: 5| Step: 5
Training loss: 2.176278591156006
Validation loss: 2.1281577720437

Epoch: 5| Step: 6
Training loss: 2.674349784851074
Validation loss: 2.120274559144051

Epoch: 5| Step: 7
Training loss: 2.4439964294433594
Validation loss: 2.1387468461067445

Epoch: 5| Step: 8
Training loss: 2.2708282470703125
Validation loss: 2.1419857881402455

Epoch: 5| Step: 9
Training loss: 2.8052611351013184
Validation loss: 2.129758047801192

Epoch: 5| Step: 10
Training loss: 1.9999181032180786
Validation loss: 2.139633447893204

Epoch: 64| Step: 0
Training loss: 2.089428663253784
Validation loss: 2.157831391980571

Epoch: 5| Step: 1
Training loss: 2.076409101486206
Validation loss: 2.103268038841986

Epoch: 5| Step: 2
Training loss: 2.5899581909179688
Validation loss: 2.1167152645767375

Epoch: 5| Step: 3
Training loss: 2.448225975036621
Validation loss: 2.1238779124393257

Epoch: 5| Step: 4
Training loss: 2.963268280029297
Validation loss: 2.130250561621881

Epoch: 5| Step: 5
Training loss: 1.8210426568984985
Validation loss: 2.1243332867981284

Epoch: 5| Step: 6
Training loss: 2.5879085063934326
Validation loss: 2.1302673842317317

Epoch: 5| Step: 7
Training loss: 1.8709280490875244
Validation loss: 2.13269220372682

Epoch: 5| Step: 8
Training loss: 2.6512067317962646
Validation loss: 2.1220713302653325

Epoch: 5| Step: 9
Training loss: 1.8135299682617188
Validation loss: 2.1209919632122083

Epoch: 5| Step: 10
Training loss: 2.2678942680358887
Validation loss: 2.1413759518695135

Epoch: 65| Step: 0
Training loss: 1.993412733078003
Validation loss: 2.1239385938131683

Epoch: 5| Step: 1
Training loss: 2.7735228538513184
Validation loss: 2.1446635953841673

Epoch: 5| Step: 2
Training loss: 2.206164836883545
Validation loss: 2.1041246229602444

Epoch: 5| Step: 3
Training loss: 2.722843647003174
Validation loss: 2.1334977047417754

Epoch: 5| Step: 4
Training loss: 2.131173610687256
Validation loss: 2.1189230154919367

Epoch: 5| Step: 5
Training loss: 2.385780096054077
Validation loss: 2.1147525233607136

Epoch: 5| Step: 6
Training loss: 1.443263053894043
Validation loss: 2.129853945906444

Epoch: 5| Step: 7
Training loss: 2.40417742729187
Validation loss: 2.070797868954238

Epoch: 5| Step: 8
Training loss: 2.5663270950317383
Validation loss: 2.1283762070440475

Epoch: 5| Step: 9
Training loss: 2.158850908279419
Validation loss: 2.1333514516071608

Epoch: 5| Step: 10
Training loss: 2.230518341064453
Validation loss: 2.1232203975800545

Epoch: 66| Step: 0
Training loss: 2.0903680324554443
Validation loss: 2.1171174151923067

Epoch: 5| Step: 1
Training loss: 2.349180221557617
Validation loss: 2.114590116726455

Epoch: 5| Step: 2
Training loss: 1.9561328887939453
Validation loss: 2.101210992823365

Epoch: 5| Step: 3
Training loss: 2.6359384059906006
Validation loss: 2.0942733838994014

Epoch: 5| Step: 4
Training loss: 2.5131418704986572
Validation loss: 2.115032571618275

Epoch: 5| Step: 5
Training loss: 2.051239013671875
Validation loss: 2.14091408124534

Epoch: 5| Step: 6
Training loss: 2.603980302810669
Validation loss: 2.1148904754269506

Epoch: 5| Step: 7
Training loss: 1.9605048894882202
Validation loss: 2.1240793556295414

Epoch: 5| Step: 8
Training loss: 2.57720947265625
Validation loss: 2.1190010450219594

Epoch: 5| Step: 9
Training loss: 2.250641345977783
Validation loss: 2.1131221504621607

Epoch: 5| Step: 10
Training loss: 1.9087928533554077
Validation loss: 2.1167031180474067

Epoch: 67| Step: 0
Training loss: 2.025681734085083
Validation loss: 2.0875451795516478

Epoch: 5| Step: 1
Training loss: 1.6191184520721436
Validation loss: 2.1050984551829677

Epoch: 5| Step: 2
Training loss: 2.025736093521118
Validation loss: 2.1047464263054634

Epoch: 5| Step: 3
Training loss: 2.587860345840454
Validation loss: 2.109809058968739

Epoch: 5| Step: 4
Training loss: 1.98970627784729
Validation loss: 2.1089307620961177

Epoch: 5| Step: 5
Training loss: 2.2589449882507324
Validation loss: 2.1233816377578245

Epoch: 5| Step: 6
Training loss: 2.200491428375244
Validation loss: 2.0977532773889522

Epoch: 5| Step: 7
Training loss: 3.020183801651001
Validation loss: 2.1005857131814443

Epoch: 5| Step: 8
Training loss: 2.569742202758789
Validation loss: 2.1164917176769626

Epoch: 5| Step: 9
Training loss: 2.155639171600342
Validation loss: 2.118281328549949

Epoch: 5| Step: 10
Training loss: 2.3480899333953857
Validation loss: 2.113209165552611

Epoch: 68| Step: 0
Training loss: 1.8554805517196655
Validation loss: 2.1126023825778755

Epoch: 5| Step: 1
Training loss: 2.495281934738159
Validation loss: 2.108068650768649

Epoch: 5| Step: 2
Training loss: 2.6161797046661377
Validation loss: 2.105295587611455

Epoch: 5| Step: 3
Training loss: 2.236485481262207
Validation loss: 2.1294873734956146

Epoch: 5| Step: 4
Training loss: 2.2271814346313477
Validation loss: 2.1708512049849316

Epoch: 5| Step: 5
Training loss: 2.1070384979248047
Validation loss: 2.157029777444819

Epoch: 5| Step: 6
Training loss: 2.101341485977173
Validation loss: 2.099843003416574

Epoch: 5| Step: 7
Training loss: 2.466587781906128
Validation loss: 2.1232984117282334

Epoch: 5| Step: 8
Training loss: 2.530944347381592
Validation loss: 2.112010963501469

Epoch: 5| Step: 9
Training loss: 2.1734061241149902
Validation loss: 2.1371446655642603

Epoch: 5| Step: 10
Training loss: 2.2107348442077637
Validation loss: 2.1218603298228276

Epoch: 69| Step: 0
Training loss: 1.9980669021606445
Validation loss: 2.1253284305654545

Epoch: 5| Step: 1
Training loss: 3.2038321495056152
Validation loss: 2.1214360524249334

Epoch: 5| Step: 2
Training loss: 2.069828510284424
Validation loss: 2.111460192229158

Epoch: 5| Step: 3
Training loss: 2.5655062198638916
Validation loss: 2.1235232532665296

Epoch: 5| Step: 4
Training loss: 2.7877259254455566
Validation loss: 2.1348128139331775

Epoch: 5| Step: 5
Training loss: 2.1853840351104736
Validation loss: 2.116931887083156

Epoch: 5| Step: 6
Training loss: 2.284522533416748
Validation loss: 2.1542203913452806

Epoch: 5| Step: 7
Training loss: 1.84479558467865
Validation loss: 2.114178587031621

Epoch: 5| Step: 8
Training loss: 2.0826809406280518
Validation loss: 2.1389985225533925

Epoch: 5| Step: 9
Training loss: 2.407083034515381
Validation loss: 2.118864236339446

Epoch: 5| Step: 10
Training loss: 1.4911129474639893
Validation loss: 2.1246628992019163

Epoch: 70| Step: 0
Training loss: 2.7345190048217773
Validation loss: 2.1201528708140054

Epoch: 5| Step: 1
Training loss: 2.7315216064453125
Validation loss: 2.1584484295178483

Epoch: 5| Step: 2
Training loss: 2.5271568298339844
Validation loss: 2.126160906207177

Epoch: 5| Step: 3
Training loss: 2.181084156036377
Validation loss: 2.1315282621691303

Epoch: 5| Step: 4
Training loss: 1.9942712783813477
Validation loss: 2.1425719671351935

Epoch: 5| Step: 5
Training loss: 1.9701223373413086
Validation loss: 2.1319196019121396

Epoch: 5| Step: 6
Training loss: 2.403434991836548
Validation loss: 2.113675591766193

Epoch: 5| Step: 7
Training loss: 1.779512643814087
Validation loss: 2.101073957258655

Epoch: 5| Step: 8
Training loss: 1.9523319005966187
Validation loss: 2.1466442538845922

Epoch: 5| Step: 9
Training loss: 2.347372055053711
Validation loss: 2.1497896025257726

Epoch: 5| Step: 10
Training loss: 2.167546033859253
Validation loss: 2.1168824434280396

Epoch: 71| Step: 0
Training loss: 2.4144158363342285
Validation loss: 2.122059400363635

Epoch: 5| Step: 1
Training loss: 2.9180538654327393
Validation loss: 2.1549779702258367

Epoch: 5| Step: 2
Training loss: 2.100252389907837
Validation loss: 2.1191178060347036

Epoch: 5| Step: 3
Training loss: 2.241543769836426
Validation loss: 2.134566032758323

Epoch: 5| Step: 4
Training loss: 2.709343433380127
Validation loss: 2.123902408025598

Epoch: 5| Step: 5
Training loss: 1.7947709560394287
Validation loss: 2.1268793562407136

Epoch: 5| Step: 6
Training loss: 1.9172080755233765
Validation loss: 2.1236482217747676

Epoch: 5| Step: 7
Training loss: 1.8931190967559814
Validation loss: 2.153272436511132

Epoch: 5| Step: 8
Training loss: 1.8993021249771118
Validation loss: 2.1245603099946053

Epoch: 5| Step: 9
Training loss: 2.247807502746582
Validation loss: 2.1229769055561354

Epoch: 5| Step: 10
Training loss: 2.7104201316833496
Validation loss: 2.1359087203138616

Epoch: 72| Step: 0
Training loss: 2.1844635009765625
Validation loss: 2.1161823170159453

Epoch: 5| Step: 1
Training loss: 2.830695390701294
Validation loss: 2.112656722786606

Epoch: 5| Step: 2
Training loss: 2.957596778869629
Validation loss: 2.1145817002942486

Epoch: 5| Step: 3
Training loss: 2.0273001194000244
Validation loss: 2.121693877763646

Epoch: 5| Step: 4
Training loss: 2.3850605487823486
Validation loss: 2.1520313114248295

Epoch: 5| Step: 5
Training loss: 2.4245476722717285
Validation loss: 2.1143400002551336

Epoch: 5| Step: 6
Training loss: 1.9759252071380615
Validation loss: 2.129278867475448

Epoch: 5| Step: 7
Training loss: 1.5872125625610352
Validation loss: 2.0956151408533894

Epoch: 5| Step: 8
Training loss: 2.3126895427703857
Validation loss: 2.1490177505759784

Epoch: 5| Step: 9
Training loss: 1.5784275531768799
Validation loss: 2.102101896398811

Epoch: 5| Step: 10
Training loss: 2.60638427734375
Validation loss: 2.106048568602531

Epoch: 73| Step: 0
Training loss: 1.7333004474639893
Validation loss: 2.11883189857647

Epoch: 5| Step: 1
Training loss: 1.52004075050354
Validation loss: 2.09554611995656

Epoch: 5| Step: 2
Training loss: 2.41656756401062
Validation loss: 2.1182163633326048

Epoch: 5| Step: 3
Training loss: 2.366001605987549
Validation loss: 2.1208552916844687

Epoch: 5| Step: 4
Training loss: 2.318100929260254
Validation loss: 2.0752845502668813

Epoch: 5| Step: 5
Training loss: 2.270780086517334
Validation loss: 2.112570858770801

Epoch: 5| Step: 6
Training loss: 2.9470489025115967
Validation loss: 2.082851791894564

Epoch: 5| Step: 7
Training loss: 1.9435698986053467
Validation loss: 2.1067069217722905

Epoch: 5| Step: 8
Training loss: 2.099877119064331
Validation loss: 2.1189674177477436

Epoch: 5| Step: 9
Training loss: 2.9839603900909424
Validation loss: 2.116404062958174

Epoch: 5| Step: 10
Training loss: 2.1254405975341797
Validation loss: 2.0996620270513717

Epoch: 74| Step: 0
Training loss: 2.7831387519836426
Validation loss: 2.106417750799528

Epoch: 5| Step: 1
Training loss: 1.9637854099273682
Validation loss: 2.1274430674891316

Epoch: 5| Step: 2
Training loss: 2.1869359016418457
Validation loss: 2.138829228698566

Epoch: 5| Step: 3
Training loss: 1.9961645603179932
Validation loss: 2.11678288572578

Epoch: 5| Step: 4
Training loss: 2.0342724323272705
Validation loss: 2.0973264735232116

Epoch: 5| Step: 5
Training loss: 3.0213968753814697
Validation loss: 2.111885916802191

Epoch: 5| Step: 6
Training loss: 2.032496452331543
Validation loss: 2.135151024787657

Epoch: 5| Step: 7
Training loss: 1.826333999633789
Validation loss: 2.133386540156539

Epoch: 5| Step: 8
Training loss: 1.9691016674041748
Validation loss: 2.119606807667722

Epoch: 5| Step: 9
Training loss: 2.0208826065063477
Validation loss: 2.1211369037628174

Epoch: 5| Step: 10
Training loss: 2.9095489978790283
Validation loss: 2.116708637565695

Epoch: 75| Step: 0
Training loss: 2.944125175476074
Validation loss: 2.119049119692977

Epoch: 5| Step: 1
Training loss: 2.2084736824035645
Validation loss: 2.120511561311701

Epoch: 5| Step: 2
Training loss: 2.0030956268310547
Validation loss: 2.122176403640419

Epoch: 5| Step: 3
Training loss: 1.6421051025390625
Validation loss: 2.1429666626837944

Epoch: 5| Step: 4
Training loss: 2.1847031116485596
Validation loss: 2.1222117203538136

Epoch: 5| Step: 5
Training loss: 2.227552890777588
Validation loss: 2.1227490748128583

Epoch: 5| Step: 6
Training loss: 2.6920549869537354
Validation loss: 2.090152609732843

Epoch: 5| Step: 7
Training loss: 2.2150356769561768
Validation loss: 2.1410541765151487

Epoch: 5| Step: 8
Training loss: 2.4113245010375977
Validation loss: 2.1330763165668776

Epoch: 5| Step: 9
Training loss: 2.2550723552703857
Validation loss: 2.1444374207527406

Epoch: 5| Step: 10
Training loss: 1.9328773021697998
Validation loss: 2.1172029484984694

Epoch: 76| Step: 0
Training loss: 1.7223100662231445
Validation loss: 2.142610913963728

Epoch: 5| Step: 1
Training loss: 2.5064163208007812
Validation loss: 2.127395183809342

Epoch: 5| Step: 2
Training loss: 1.658121109008789
Validation loss: 2.102455633942799

Epoch: 5| Step: 3
Training loss: 2.4068400859832764
Validation loss: 2.129293910918697

Epoch: 5| Step: 4
Training loss: 1.755070447921753
Validation loss: 2.10413464935877

Epoch: 5| Step: 5
Training loss: 2.6391525268554688
Validation loss: 2.1156787718496015

Epoch: 5| Step: 6
Training loss: 2.0473363399505615
Validation loss: 2.142210837333433

Epoch: 5| Step: 7
Training loss: 2.027545213699341
Validation loss: 2.124145938504127

Epoch: 5| Step: 8
Training loss: 2.4937992095947266
Validation loss: 2.111722607766428

Epoch: 5| Step: 9
Training loss: 2.160128116607666
Validation loss: 2.136821994217493

Epoch: 5| Step: 10
Training loss: 3.499204635620117
Validation loss: 2.112632441264327

Epoch: 77| Step: 0
Training loss: 2.911276340484619
Validation loss: 2.120800229810899

Epoch: 5| Step: 1
Training loss: 2.3579580783843994
Validation loss: 2.102612057039815

Epoch: 5| Step: 2
Training loss: 1.9928802251815796
Validation loss: 2.1313180154369724

Epoch: 5| Step: 3
Training loss: 1.8769168853759766
Validation loss: 2.135929758830737

Epoch: 5| Step: 4
Training loss: 2.1333210468292236
Validation loss: 2.1167241475915395

Epoch: 5| Step: 5
Training loss: 1.5327874422073364
Validation loss: 2.143876849964101

Epoch: 5| Step: 6
Training loss: 3.0141348838806152
Validation loss: 2.169726320492324

Epoch: 5| Step: 7
Training loss: 2.0669498443603516
Validation loss: 2.131051277601591

Epoch: 5| Step: 8
Training loss: 2.601813316345215
Validation loss: 2.131085208667222

Epoch: 5| Step: 9
Training loss: 1.8143298625946045
Validation loss: 2.145910752716885

Epoch: 5| Step: 10
Training loss: 2.4282543659210205
Validation loss: 2.136745910490713

Epoch: 78| Step: 0
Training loss: 2.8018298149108887
Validation loss: 2.1209084244184595

Epoch: 5| Step: 1
Training loss: 2.0523505210876465
Validation loss: 2.1305134937327397

Epoch: 5| Step: 2
Training loss: 2.1492996215820312
Validation loss: 2.1546885428890103

Epoch: 5| Step: 3
Training loss: 2.586740493774414
Validation loss: 2.152514434629871

Epoch: 5| Step: 4
Training loss: 2.305952548980713
Validation loss: 2.142464659547293

Epoch: 5| Step: 5
Training loss: 1.5916584730148315
Validation loss: 2.1268029520588536

Epoch: 5| Step: 6
Training loss: 2.564664125442505
Validation loss: 2.150181826724801

Epoch: 5| Step: 7
Training loss: 1.980046272277832
Validation loss: 2.147573482605719

Epoch: 5| Step: 8
Training loss: 2.076648712158203
Validation loss: 2.142999840039079

Epoch: 5| Step: 9
Training loss: 2.3044238090515137
Validation loss: 2.119074208762056

Epoch: 5| Step: 10
Training loss: 2.0744407176971436
Validation loss: 2.1504208669867566

Epoch: 79| Step: 0
Training loss: 2.687528610229492
Validation loss: 2.1291195641281786

Epoch: 5| Step: 1
Training loss: 2.1727404594421387
Validation loss: 2.152364261688725

Epoch: 5| Step: 2
Training loss: 2.2379837036132812
Validation loss: 2.1488868574942313

Epoch: 5| Step: 3
Training loss: 1.5965173244476318
Validation loss: 2.119669665572464

Epoch: 5| Step: 4
Training loss: 2.4959652423858643
Validation loss: 2.1200709637775215

Epoch: 5| Step: 5
Training loss: 2.421186685562134
Validation loss: 2.1359681339674097

Epoch: 5| Step: 6
Training loss: 2.7728590965270996
Validation loss: 2.132881574733283

Epoch: 5| Step: 7
Training loss: 1.575855016708374
Validation loss: 2.144388393689227

Epoch: 5| Step: 8
Training loss: 2.009326219558716
Validation loss: 2.1620762091810986

Epoch: 5| Step: 9
Training loss: 2.4307923316955566
Validation loss: 2.143642411437086

Epoch: 5| Step: 10
Training loss: 2.1044435501098633
Validation loss: 2.147672512198007

Epoch: 80| Step: 0
Training loss: 2.230764627456665
Validation loss: 2.1434548926609818

Epoch: 5| Step: 1
Training loss: 2.5733635425567627
Validation loss: 2.1164454721635386

Epoch: 5| Step: 2
Training loss: 2.458883762359619
Validation loss: 2.147398696150831

Epoch: 5| Step: 3
Training loss: 2.887026309967041
Validation loss: 2.123089603198472

Epoch: 5| Step: 4
Training loss: 1.639751672744751
Validation loss: 2.122431990920856

Epoch: 5| Step: 5
Training loss: 2.1113393306732178
Validation loss: 2.145614035667912

Epoch: 5| Step: 6
Training loss: 1.797846794128418
Validation loss: 2.1270383660511305

Epoch: 5| Step: 7
Training loss: 2.405848264694214
Validation loss: 2.1086610235193723

Epoch: 5| Step: 8
Training loss: 2.2801876068115234
Validation loss: 2.1348409639891757

Epoch: 5| Step: 9
Training loss: 2.3282129764556885
Validation loss: 2.130379251254502

Epoch: 5| Step: 10
Training loss: 2.0929014682769775
Validation loss: 2.1369814565104823

Epoch: 81| Step: 0
Training loss: 2.0589041709899902
Validation loss: 2.1228726704915366

Epoch: 5| Step: 1
Training loss: 2.6643521785736084
Validation loss: 2.125501355817241

Epoch: 5| Step: 2
Training loss: 1.9845126867294312
Validation loss: 2.1298624905206824

Epoch: 5| Step: 3
Training loss: 1.8747717142105103
Validation loss: 2.106492442469443

Epoch: 5| Step: 4
Training loss: 1.840714693069458
Validation loss: 2.1418574599809546

Epoch: 5| Step: 5
Training loss: 2.2967185974121094
Validation loss: 2.1056699265715895

Epoch: 5| Step: 6
Training loss: 2.6257145404815674
Validation loss: 2.1070377749781453

Epoch: 5| Step: 7
Training loss: 2.3046915531158447
Validation loss: 2.1255658570156304

Epoch: 5| Step: 8
Training loss: 1.8825066089630127
Validation loss: 2.1250588714435534

Epoch: 5| Step: 9
Training loss: 3.0637731552124023
Validation loss: 2.124170610981603

Epoch: 5| Step: 10
Training loss: 1.9965088367462158
Validation loss: 2.1341698541436145

Epoch: 82| Step: 0
Training loss: 2.1542561054229736
Validation loss: 2.135974335414107

Epoch: 5| Step: 1
Training loss: 1.928521752357483
Validation loss: 2.126548215907107

Epoch: 5| Step: 2
Training loss: 2.7713942527770996
Validation loss: 2.1139562335065616

Epoch: 5| Step: 3
Training loss: 1.8254613876342773
Validation loss: 2.106396951983052

Epoch: 5| Step: 4
Training loss: 2.055264949798584
Validation loss: 2.125431658119284

Epoch: 5| Step: 5
Training loss: 2.3608155250549316
Validation loss: 2.1666931080561813

Epoch: 5| Step: 6
Training loss: 2.2332699298858643
Validation loss: 2.0861053979525

Epoch: 5| Step: 7
Training loss: 2.5266175270080566
Validation loss: 2.137377932507505

Epoch: 5| Step: 8
Training loss: 2.5245819091796875
Validation loss: 2.150734301536314

Epoch: 5| Step: 9
Training loss: 1.9118232727050781
Validation loss: 2.116233834656336

Epoch: 5| Step: 10
Training loss: 2.0749099254608154
Validation loss: 2.1322298921564573

Epoch: 83| Step: 0
Training loss: 2.2538771629333496
Validation loss: 2.1342462826800603

Epoch: 5| Step: 1
Training loss: 2.0448062419891357
Validation loss: 2.111912247955158

Epoch: 5| Step: 2
Training loss: 2.4626858234405518
Validation loss: 2.1136792885359896

Epoch: 5| Step: 3
Training loss: 1.799936294555664
Validation loss: 2.096441474012149

Epoch: 5| Step: 4
Training loss: 1.9728606939315796
Validation loss: 2.132879129020117

Epoch: 5| Step: 5
Training loss: 2.5178229808807373
Validation loss: 2.1055582620764293

Epoch: 5| Step: 6
Training loss: 2.2820987701416016
Validation loss: 2.1215975399940246

Epoch: 5| Step: 7
Training loss: 2.901615858078003
Validation loss: 2.1043076425470333

Epoch: 5| Step: 8
Training loss: 2.169346570968628
Validation loss: 2.1303256070742043

Epoch: 5| Step: 9
Training loss: 2.1599020957946777
Validation loss: 2.132022867920578

Epoch: 5| Step: 10
Training loss: 1.8696956634521484
Validation loss: 2.123903474500102

Epoch: 84| Step: 0
Training loss: 1.9247305393218994
Validation loss: 2.1409234436609412

Epoch: 5| Step: 1
Training loss: 1.591363787651062
Validation loss: 2.128850554907194

Epoch: 5| Step: 2
Training loss: 2.5827841758728027
Validation loss: 2.1464594948676323

Epoch: 5| Step: 3
Training loss: 2.1759676933288574
Validation loss: 2.1390487327370593

Epoch: 5| Step: 4
Training loss: 2.070960521697998
Validation loss: 2.136696433508268

Epoch: 5| Step: 5
Training loss: 1.9379584789276123
Validation loss: 2.1359248392043577

Epoch: 5| Step: 6
Training loss: 2.723189115524292
Validation loss: 2.1204978471161215

Epoch: 5| Step: 7
Training loss: 2.9716579914093018
Validation loss: 2.1291274806504608

Epoch: 5| Step: 8
Training loss: 2.038771629333496
Validation loss: 2.1683183588007444

Epoch: 5| Step: 9
Training loss: 2.4116711616516113
Validation loss: 2.1257441595036495

Epoch: 5| Step: 10
Training loss: 2.142824172973633
Validation loss: 2.1428103908415763

Epoch: 85| Step: 0
Training loss: 1.8921775817871094
Validation loss: 2.1586274690525507

Epoch: 5| Step: 1
Training loss: 1.8352620601654053
Validation loss: 2.15323942963795

Epoch: 5| Step: 2
Training loss: 2.1228785514831543
Validation loss: 2.169830900366588

Epoch: 5| Step: 3
Training loss: 2.084178924560547
Validation loss: 2.1372244563153995

Epoch: 5| Step: 4
Training loss: 2.7434895038604736
Validation loss: 2.1402696306987474

Epoch: 5| Step: 5
Training loss: 2.3344016075134277
Validation loss: 2.1188162975413825

Epoch: 5| Step: 6
Training loss: 2.387981414794922
Validation loss: 2.1702708992906796

Epoch: 5| Step: 7
Training loss: 2.5455729961395264
Validation loss: 2.130124020320113

Epoch: 5| Step: 8
Training loss: 2.8315505981445312
Validation loss: 2.1258685640109483

Epoch: 5| Step: 9
Training loss: 2.0253899097442627
Validation loss: 2.156417126296669

Epoch: 5| Step: 10
Training loss: 1.808135986328125
Validation loss: 2.1332706328361266

Epoch: 86| Step: 0
Training loss: 2.271935224533081
Validation loss: 2.131760465201511

Epoch: 5| Step: 1
Training loss: 2.790003538131714
Validation loss: 2.121661388745872

Epoch: 5| Step: 2
Training loss: 1.746192216873169
Validation loss: 2.14890484399693

Epoch: 5| Step: 3
Training loss: 2.0604121685028076
Validation loss: 2.135121600602263

Epoch: 5| Step: 4
Training loss: 1.586800217628479
Validation loss: 2.1519809743409515

Epoch: 5| Step: 5
Training loss: 2.5305216312408447
Validation loss: 2.1475271704376384

Epoch: 5| Step: 6
Training loss: 2.270195484161377
Validation loss: 2.113394174524533

Epoch: 5| Step: 7
Training loss: 1.8788944482803345
Validation loss: 2.150268021450248

Epoch: 5| Step: 8
Training loss: 2.1391947269439697
Validation loss: 2.1397699809843496

Epoch: 5| Step: 9
Training loss: 2.363133192062378
Validation loss: 2.1294750423841577

Epoch: 5| Step: 10
Training loss: 2.7642428874969482
Validation loss: 2.1529685451138403

Epoch: 87| Step: 0
Training loss: 2.4706568717956543
Validation loss: 2.124056157245431

Epoch: 5| Step: 1
Training loss: 2.546288013458252
Validation loss: 2.1182399885628813

Epoch: 5| Step: 2
Training loss: 2.4380013942718506
Validation loss: 2.1641366456144597

Epoch: 5| Step: 3
Training loss: 2.4239261150360107
Validation loss: 2.1288925499044438

Epoch: 5| Step: 4
Training loss: 1.810916543006897
Validation loss: 2.1307698744599537

Epoch: 5| Step: 5
Training loss: 2.334787368774414
Validation loss: 2.134251730416411

Epoch: 5| Step: 6
Training loss: 2.401854991912842
Validation loss: 2.1206245473636094

Epoch: 5| Step: 7
Training loss: 2.4328455924987793
Validation loss: 2.1266511306967786

Epoch: 5| Step: 8
Training loss: 1.4201112985610962
Validation loss: 2.1246994644083004

Epoch: 5| Step: 9
Training loss: 2.2495954036712646
Validation loss: 2.112469288610643

Epoch: 5| Step: 10
Training loss: 1.9950700998306274
Validation loss: 2.1436133871796312

Epoch: 88| Step: 0
Training loss: 1.718199372291565
Validation loss: 2.1458257090660835

Epoch: 5| Step: 1
Training loss: 2.6428489685058594
Validation loss: 2.1174783334937146

Epoch: 5| Step: 2
Training loss: 2.0496127605438232
Validation loss: 2.140614050690846

Epoch: 5| Step: 3
Training loss: 2.009838104248047
Validation loss: 2.114210599212236

Epoch: 5| Step: 4
Training loss: 2.0642216205596924
Validation loss: 2.106931168545959

Epoch: 5| Step: 5
Training loss: 2.7108283042907715
Validation loss: 2.1600114914678756

Epoch: 5| Step: 6
Training loss: 1.750030279159546
Validation loss: 2.1455631179194294

Epoch: 5| Step: 7
Training loss: 2.35178279876709
Validation loss: 2.1271222919546147

Epoch: 5| Step: 8
Training loss: 2.0398144721984863
Validation loss: 2.10000612402475

Epoch: 5| Step: 9
Training loss: 2.627934217453003
Validation loss: 2.148821207784837

Epoch: 5| Step: 10
Training loss: 2.2088499069213867
Validation loss: 2.1265231460653324

Epoch: 89| Step: 0
Training loss: 1.8928337097167969
Validation loss: 2.11575642196081

Epoch: 5| Step: 1
Training loss: 2.2610485553741455
Validation loss: 2.1024391535789735

Epoch: 5| Step: 2
Training loss: 2.015346050262451
Validation loss: 2.106906919069188

Epoch: 5| Step: 3
Training loss: 3.3964896202087402
Validation loss: 2.1112930351688015

Epoch: 5| Step: 4
Training loss: 2.481523275375366
Validation loss: 2.1157300805532806

Epoch: 5| Step: 5
Training loss: 2.086099624633789
Validation loss: 2.123725055366434

Epoch: 5| Step: 6
Training loss: 2.3268425464630127
Validation loss: 2.119823435301422

Epoch: 5| Step: 7
Training loss: 2.439490556716919
Validation loss: 2.1180076958030782

Epoch: 5| Step: 8
Training loss: 1.770330786705017
Validation loss: 2.1506085754722677

Epoch: 5| Step: 9
Training loss: 1.647376298904419
Validation loss: 2.125419834608673

Epoch: 5| Step: 10
Training loss: 1.7473162412643433
Validation loss: 2.0973180058181926

Epoch: 90| Step: 0
Training loss: 2.8096365928649902
Validation loss: 2.143373630380118

Epoch: 5| Step: 1
Training loss: 1.8340826034545898
Validation loss: 2.1278699046822003

Epoch: 5| Step: 2
Training loss: 2.3625996112823486
Validation loss: 2.134747789752099

Epoch: 5| Step: 3
Training loss: 2.3392345905303955
Validation loss: 2.1321141873636553

Epoch: 5| Step: 4
Training loss: 2.2728097438812256
Validation loss: 2.096616698849586

Epoch: 5| Step: 5
Training loss: 2.604703664779663
Validation loss: 2.1301744317495697

Epoch: 5| Step: 6
Training loss: 2.3068184852600098
Validation loss: 2.122049641865556

Epoch: 5| Step: 7
Training loss: 2.0809412002563477
Validation loss: 2.102562386502502

Epoch: 5| Step: 8
Training loss: 2.1620020866394043
Validation loss: 2.117371525815738

Epoch: 5| Step: 9
Training loss: 1.4353597164154053
Validation loss: 2.1311609129751883

Epoch: 5| Step: 10
Training loss: 1.9860895872116089
Validation loss: 2.1682905843180995

Epoch: 91| Step: 0
Training loss: 2.5138344764709473
Validation loss: 2.129943791256156

Epoch: 5| Step: 1
Training loss: 2.612334728240967
Validation loss: 2.171544644140428

Epoch: 5| Step: 2
Training loss: 1.8318078517913818
Validation loss: 2.1367451836985927

Epoch: 5| Step: 3
Training loss: 2.2135396003723145
Validation loss: 2.138452850362306

Epoch: 5| Step: 4
Training loss: 1.9680070877075195
Validation loss: 2.1384027055514756

Epoch: 5| Step: 5
Training loss: 2.1080687046051025
Validation loss: 2.132146713554218

Epoch: 5| Step: 6
Training loss: 2.2410521507263184
Validation loss: 2.120505617510888

Epoch: 5| Step: 7
Training loss: 2.6653881072998047
Validation loss: 2.091966591855531

Epoch: 5| Step: 8
Training loss: 3.343165159225464
Validation loss: 2.1543522855286956

Epoch: 5| Step: 9
Training loss: 1.2848504781723022
Validation loss: 2.122678747741125

Epoch: 5| Step: 10
Training loss: 1.680197834968567
Validation loss: 2.109853685543101

Epoch: 92| Step: 0
Training loss: 1.8362613916397095
Validation loss: 2.136326395055299

Epoch: 5| Step: 1
Training loss: 2.378002166748047
Validation loss: 2.1317215786185315

Epoch: 5| Step: 2
Training loss: 2.329346179962158
Validation loss: 2.111149190574564

Epoch: 5| Step: 3
Training loss: 2.1877050399780273
Validation loss: 2.1381041657540107

Epoch: 5| Step: 4
Training loss: 2.280291795730591
Validation loss: 2.1344664173741497

Epoch: 5| Step: 5
Training loss: 2.5238468647003174
Validation loss: 2.1473595634583504

Epoch: 5| Step: 6
Training loss: 2.5162785053253174
Validation loss: 2.134312529717722

Epoch: 5| Step: 7
Training loss: 1.5787065029144287
Validation loss: 2.123659914539706

Epoch: 5| Step: 8
Training loss: 1.8571712970733643
Validation loss: 2.1565484487882225

Epoch: 5| Step: 9
Training loss: 2.4727907180786133
Validation loss: 2.147347342583441

Epoch: 5| Step: 10
Training loss: 2.4061880111694336
Validation loss: 2.137059393749442

Epoch: 93| Step: 0
Training loss: 1.8758004903793335
Validation loss: 2.134437532835109

Epoch: 5| Step: 1
Training loss: 2.1655468940734863
Validation loss: 2.1545989218578545

Epoch: 5| Step: 2
Training loss: 2.4740586280822754
Validation loss: 2.141678435828096

Epoch: 5| Step: 3
Training loss: 2.2316291332244873
Validation loss: 2.1616366858123452

Epoch: 5| Step: 4
Training loss: 1.843785047531128
Validation loss: 2.155530268146146

Epoch: 5| Step: 5
Training loss: 2.3867344856262207
Validation loss: 2.1052944890914427

Epoch: 5| Step: 6
Training loss: 1.7628599405288696
Validation loss: 2.134026999114662

Epoch: 5| Step: 7
Training loss: 2.3763039112091064
Validation loss: 2.1380015239920667

Epoch: 5| Step: 8
Training loss: 2.877795696258545
Validation loss: 2.1361185709635415

Epoch: 5| Step: 9
Training loss: 2.031437397003174
Validation loss: 2.1370393255705475

Epoch: 5| Step: 10
Training loss: 2.0169193744659424
Validation loss: 2.128465388410835

Epoch: 94| Step: 0
Training loss: 1.735372543334961
Validation loss: 2.164366845161684

Epoch: 5| Step: 1
Training loss: 1.5900684595108032
Validation loss: 2.12948860660676

Epoch: 5| Step: 2
Training loss: 2.0717742443084717
Validation loss: 2.1386027361757014

Epoch: 5| Step: 3
Training loss: 1.9516887664794922
Validation loss: 2.13846827578801

Epoch: 5| Step: 4
Training loss: 1.764281988143921
Validation loss: 2.1848128457223215

Epoch: 5| Step: 5
Training loss: 1.9878705739974976
Validation loss: 2.1309207152294856

Epoch: 5| Step: 6
Training loss: 2.578146457672119
Validation loss: 2.117320127384637

Epoch: 5| Step: 7
Training loss: 3.0199978351593018
Validation loss: 2.1502416287699053

Epoch: 5| Step: 8
Training loss: 2.3335483074188232
Validation loss: 2.1249263876227924

Epoch: 5| Step: 9
Training loss: 2.816387414932251
Validation loss: 2.126243188817014

Epoch: 5| Step: 10
Training loss: 2.2272183895111084
Validation loss: 2.1386332793902327

Epoch: 95| Step: 0
Training loss: 2.8265254497528076
Validation loss: 2.153513895568027

Epoch: 5| Step: 1
Training loss: 2.1666178703308105
Validation loss: 2.131947058503346

Epoch: 5| Step: 2
Training loss: 2.1663460731506348
Validation loss: 2.1587131484862296

Epoch: 5| Step: 3
Training loss: 1.7395541667938232
Validation loss: 2.1437213933596047

Epoch: 5| Step: 4
Training loss: 2.081224203109741
Validation loss: 2.129311784621208

Epoch: 5| Step: 5
Training loss: 2.3945908546447754
Validation loss: 2.106563239969233

Epoch: 5| Step: 6
Training loss: 1.9308674335479736
Validation loss: 2.1499614369484688

Epoch: 5| Step: 7
Training loss: 2.462340831756592
Validation loss: 2.11852353618991

Epoch: 5| Step: 8
Training loss: 2.0152344703674316
Validation loss: 2.1461483534946235

Epoch: 5| Step: 9
Training loss: 2.5395073890686035
Validation loss: 2.1524290269420994

Epoch: 5| Step: 10
Training loss: 1.7701126337051392
Validation loss: 2.1315729964163994

Epoch: 96| Step: 0
Training loss: 2.1060192584991455
Validation loss: 2.1352384949243195

Epoch: 5| Step: 1
Training loss: 1.8893640041351318
Validation loss: 2.1254721149321525

Epoch: 5| Step: 2
Training loss: 2.461068630218506
Validation loss: 2.1562694554687827

Epoch: 5| Step: 3
Training loss: 2.532827615737915
Validation loss: 2.174769140058948

Epoch: 5| Step: 4
Training loss: 2.4641330242156982
Validation loss: 2.151046899057204

Epoch: 5| Step: 5
Training loss: 1.9566723108291626
Validation loss: 2.115189629216348

Epoch: 5| Step: 6
Training loss: 1.974851369857788
Validation loss: 2.118962208429972

Epoch: 5| Step: 7
Training loss: 1.7020082473754883
Validation loss: 2.1474087161402546

Epoch: 5| Step: 8
Training loss: 2.3173069953918457
Validation loss: 2.107085210020824

Epoch: 5| Step: 9
Training loss: 1.939530611038208
Validation loss: 2.1436680132342922

Epoch: 5| Step: 10
Training loss: 3.0435478687286377
Validation loss: 2.12646665880757

Epoch: 97| Step: 0
Training loss: 2.2939486503601074
Validation loss: 2.1891407248794392

Epoch: 5| Step: 1
Training loss: 1.9437134265899658
Validation loss: 2.1469760646102247

Epoch: 5| Step: 2
Training loss: 2.134251117706299
Validation loss: 2.138468837225309

Epoch: 5| Step: 3
Training loss: 1.7251338958740234
Validation loss: 2.154577798740838

Epoch: 5| Step: 4
Training loss: 2.5891427993774414
Validation loss: 2.1441882964103454

Epoch: 5| Step: 5
Training loss: 2.0876030921936035
Validation loss: 2.12681754173771

Epoch: 5| Step: 6
Training loss: 2.118264675140381
Validation loss: 2.153162364036806

Epoch: 5| Step: 7
Training loss: 3.3932414054870605
Validation loss: 2.129860121716735

Epoch: 5| Step: 8
Training loss: 1.8022277355194092
Validation loss: 2.143936377699657

Epoch: 5| Step: 9
Training loss: 2.124138593673706
Validation loss: 2.1434776872716923

Epoch: 5| Step: 10
Training loss: 1.7813977003097534
Validation loss: 2.154139902002068

Epoch: 98| Step: 0
Training loss: 2.219740390777588
Validation loss: 2.1470520445095596

Epoch: 5| Step: 1
Training loss: 1.878363847732544
Validation loss: 2.13854629506347

Epoch: 5| Step: 2
Training loss: 2.0030906200408936
Validation loss: 2.1669437910920832

Epoch: 5| Step: 3
Training loss: 2.0523276329040527
Validation loss: 2.1370695842209684

Epoch: 5| Step: 4
Training loss: 2.2718558311462402
Validation loss: 2.158778514913333

Epoch: 5| Step: 5
Training loss: 2.2323460578918457
Validation loss: 2.092116457159801

Epoch: 5| Step: 6
Training loss: 2.5076398849487305
Validation loss: 2.138261741207492

Epoch: 5| Step: 7
Training loss: 1.936853051185608
Validation loss: 2.151338129915217

Epoch: 5| Step: 8
Training loss: 2.9196648597717285
Validation loss: 2.1560737138153403

Epoch: 5| Step: 9
Training loss: 2.08968186378479
Validation loss: 2.1515967115279166

Epoch: 5| Step: 10
Training loss: 1.8217343091964722
Validation loss: 2.1457470181167766

Epoch: 99| Step: 0
Training loss: 2.6621551513671875
Validation loss: 2.1301981428618073

Epoch: 5| Step: 1
Training loss: 2.850515604019165
Validation loss: 2.133839702093473

Epoch: 5| Step: 2
Training loss: 2.1254172325134277
Validation loss: 2.159074378269975

Epoch: 5| Step: 3
Training loss: 2.3396077156066895
Validation loss: 2.114110838982367

Epoch: 5| Step: 4
Training loss: 1.7845165729522705
Validation loss: 2.106022357940674

Epoch: 5| Step: 5
Training loss: 1.6388671398162842
Validation loss: 2.1402639573620212

Epoch: 5| Step: 6
Training loss: 2.7973570823669434
Validation loss: 2.129856958184191

Epoch: 5| Step: 7
Training loss: 1.5818517208099365
Validation loss: 2.1072999187695083

Epoch: 5| Step: 8
Training loss: 1.9832394123077393
Validation loss: 2.0680555861483336

Epoch: 5| Step: 9
Training loss: 1.8444793224334717
Validation loss: 2.0956301227692635

Epoch: 5| Step: 10
Training loss: 2.7432994842529297
Validation loss: 2.128116144928881

Epoch: 100| Step: 0
Training loss: 2.271462917327881
Validation loss: 2.104926921988046

Epoch: 5| Step: 1
Training loss: 2.3305771350860596
Validation loss: 2.1439189551978983

Epoch: 5| Step: 2
Training loss: 2.415919542312622
Validation loss: 2.1225777979820006

Epoch: 5| Step: 3
Training loss: 2.459211826324463
Validation loss: 2.117792273080477

Epoch: 5| Step: 4
Training loss: 2.4769062995910645
Validation loss: 2.1479163656952562

Epoch: 5| Step: 5
Training loss: 2.2329299449920654
Validation loss: 2.158479226532803

Epoch: 5| Step: 6
Training loss: 1.5498396158218384
Validation loss: 2.1397979438945813

Epoch: 5| Step: 7
Training loss: 2.2049224376678467
Validation loss: 2.1446376936410063

Epoch: 5| Step: 8
Training loss: 2.6367459297180176
Validation loss: 2.1188271455867316

Epoch: 5| Step: 9
Training loss: 1.7564510107040405
Validation loss: 2.14374908836939

Epoch: 5| Step: 10
Training loss: 1.6496467590332031
Validation loss: 2.173158968648603

Epoch: 101| Step: 0
Training loss: 2.540039539337158
Validation loss: 2.1219921881152737

Epoch: 5| Step: 1
Training loss: 2.2886993885040283
Validation loss: 2.1089593492528445

Epoch: 5| Step: 2
Training loss: 1.76409113407135
Validation loss: 2.1466002284839587

Epoch: 5| Step: 3
Training loss: 2.1517550945281982
Validation loss: 2.141277987469909

Epoch: 5| Step: 4
Training loss: 2.0374984741210938
Validation loss: 2.1569985471745974

Epoch: 5| Step: 5
Training loss: 1.9441217184066772
Validation loss: 2.1152603446796374

Epoch: 5| Step: 6
Training loss: 2.279776096343994
Validation loss: 2.1209678496083906

Epoch: 5| Step: 7
Training loss: 2.8389809131622314
Validation loss: 2.1703968304459766

Epoch: 5| Step: 8
Training loss: 2.451037645339966
Validation loss: 2.1517623368129937

Epoch: 5| Step: 9
Training loss: 2.119196653366089
Validation loss: 2.145397059379085

Epoch: 5| Step: 10
Training loss: 1.5033226013183594
Validation loss: 2.151576260084747

Epoch: 102| Step: 0
Training loss: 2.1742451190948486
Validation loss: 2.1060000670853483

Epoch: 5| Step: 1
Training loss: 2.398803472518921
Validation loss: 2.1540553864612373

Epoch: 5| Step: 2
Training loss: 2.4007785320281982
Validation loss: 2.143637684083754

Epoch: 5| Step: 3
Training loss: 2.056363105773926
Validation loss: 2.1332965358611076

Epoch: 5| Step: 4
Training loss: 1.7225764989852905
Validation loss: 2.13676703873501

Epoch: 5| Step: 5
Training loss: 2.3882393836975098
Validation loss: 2.1223685023605183

Epoch: 5| Step: 6
Training loss: 1.8471076488494873
Validation loss: 2.0827649049861456

Epoch: 5| Step: 7
Training loss: 2.772629976272583
Validation loss: 2.126361377777592

Epoch: 5| Step: 8
Training loss: 1.5672928094863892
Validation loss: 2.135925756987705

Epoch: 5| Step: 9
Training loss: 2.5897765159606934
Validation loss: 2.1308877980837257

Epoch: 5| Step: 10
Training loss: 2.3594987392425537
Validation loss: 2.10358343842209

Epoch: 103| Step: 0
Training loss: 1.6752464771270752
Validation loss: 2.1054491137945526

Epoch: 5| Step: 1
Training loss: 2.6384387016296387
Validation loss: 2.1133229655604207

Epoch: 5| Step: 2
Training loss: 2.53843355178833
Validation loss: 2.1279911636024393

Epoch: 5| Step: 3
Training loss: 2.2979722023010254
Validation loss: 2.115864658868441

Epoch: 5| Step: 4
Training loss: 2.4994845390319824
Validation loss: 2.151407858376862

Epoch: 5| Step: 5
Training loss: 2.1360955238342285
Validation loss: 2.1757033819793374

Epoch: 5| Step: 6
Training loss: 2.329185724258423
Validation loss: 2.1195685504585184

Epoch: 5| Step: 7
Training loss: 2.456653356552124
Validation loss: 2.1328032350027435

Epoch: 5| Step: 8
Training loss: 1.7165902853012085
Validation loss: 2.1381991140304075

Epoch: 5| Step: 9
Training loss: 1.8266032934188843
Validation loss: 2.1113226118908135

Epoch: 5| Step: 10
Training loss: 1.8483991622924805
Validation loss: 2.1025103651067263

Epoch: 104| Step: 0
Training loss: 1.8420732021331787
Validation loss: 2.1238579826970256

Epoch: 5| Step: 1
Training loss: 2.0368523597717285
Validation loss: 2.128756005276916

Epoch: 5| Step: 2
Training loss: 2.1184186935424805
Validation loss: 2.125521008686353

Epoch: 5| Step: 3
Training loss: 2.294816493988037
Validation loss: 2.1345573291983655

Epoch: 5| Step: 4
Training loss: 2.1541123390197754
Validation loss: 2.1403507468520955

Epoch: 5| Step: 5
Training loss: 1.5197689533233643
Validation loss: 2.1027863153847317

Epoch: 5| Step: 6
Training loss: 2.2383830547332764
Validation loss: 2.145313001448108

Epoch: 5| Step: 7
Training loss: 2.3879947662353516
Validation loss: 2.114695769484325

Epoch: 5| Step: 8
Training loss: 1.8572803735733032
Validation loss: 2.121105947802144

Epoch: 5| Step: 9
Training loss: 2.9165964126586914
Validation loss: 2.1262372975708335

Epoch: 5| Step: 10
Training loss: 2.339993715286255
Validation loss: 2.1334491237517326

Epoch: 105| Step: 0
Training loss: 1.9667205810546875
Validation loss: 2.090489000402471

Epoch: 5| Step: 1
Training loss: 2.0059075355529785
Validation loss: 2.134880824755597

Epoch: 5| Step: 2
Training loss: 1.884539246559143
Validation loss: 2.1140346219462733

Epoch: 5| Step: 3
Training loss: 2.139700174331665
Validation loss: 2.14483126260901

Epoch: 5| Step: 4
Training loss: 2.1285998821258545
Validation loss: 2.1470762580953617

Epoch: 5| Step: 5
Training loss: 2.1082603931427
Validation loss: 2.139374376625143

Epoch: 5| Step: 6
Training loss: 1.4357010126113892
Validation loss: 2.133835365695338

Epoch: 5| Step: 7
Training loss: 3.0368003845214844
Validation loss: 2.134790494877805

Epoch: 5| Step: 8
Training loss: 2.695502996444702
Validation loss: 2.135578909227925

Epoch: 5| Step: 9
Training loss: 2.2585511207580566
Validation loss: 2.159594738355247

Epoch: 5| Step: 10
Training loss: 2.304051399230957
Validation loss: 2.148918172364594

Epoch: 106| Step: 0
Training loss: 3.137213945388794
Validation loss: 2.113237500190735

Epoch: 5| Step: 1
Training loss: 2.0874032974243164
Validation loss: 2.129486971004035

Epoch: 5| Step: 2
Training loss: 2.0281624794006348
Validation loss: 2.139107378580237

Epoch: 5| Step: 3
Training loss: 1.8583542108535767
Validation loss: 2.150977994806023

Epoch: 5| Step: 4
Training loss: 2.204761028289795
Validation loss: 2.14302146562966

Epoch: 5| Step: 5
Training loss: 1.9726769924163818
Validation loss: 2.1598350450556767

Epoch: 5| Step: 6
Training loss: 2.103663206100464
Validation loss: 2.1366089620897846

Epoch: 5| Step: 7
Training loss: 2.3022067546844482
Validation loss: 2.1182474449116695

Epoch: 5| Step: 8
Training loss: 1.882677435874939
Validation loss: 2.1556380974349154

Epoch: 5| Step: 9
Training loss: 1.7876123189926147
Validation loss: 2.134671034351472

Epoch: 5| Step: 10
Training loss: 2.648597240447998
Validation loss: 2.124202253997967

Epoch: 107| Step: 0
Training loss: 2.3810818195343018
Validation loss: 2.109535026293929

Epoch: 5| Step: 1
Training loss: 1.7928411960601807
Validation loss: 2.133767725318991

Epoch: 5| Step: 2
Training loss: 1.9012782573699951
Validation loss: 2.0889167836917344

Epoch: 5| Step: 3
Training loss: 1.576000690460205
Validation loss: 2.135136647890973

Epoch: 5| Step: 4
Training loss: 2.3467774391174316
Validation loss: 2.109043485374861

Epoch: 5| Step: 5
Training loss: 1.879988431930542
Validation loss: 2.1541950702667236

Epoch: 5| Step: 6
Training loss: 1.8782743215560913
Validation loss: 2.111812194188436

Epoch: 5| Step: 7
Training loss: 2.915647029876709
Validation loss: 2.126288725483802

Epoch: 5| Step: 8
Training loss: 3.007650852203369
Validation loss: 2.149635754605775

Epoch: 5| Step: 9
Training loss: 1.860180139541626
Validation loss: 2.149447860256318

Epoch: 5| Step: 10
Training loss: 2.0561459064483643
Validation loss: 2.133103250175394

Epoch: 108| Step: 0
Training loss: 1.6857337951660156
Validation loss: 2.1213460788931897

Epoch: 5| Step: 1
Training loss: 1.8832279443740845
Validation loss: 2.160432574569538

Epoch: 5| Step: 2
Training loss: 1.9995441436767578
Validation loss: 2.146769792802872

Epoch: 5| Step: 3
Training loss: 2.1489131450653076
Validation loss: 2.125199943460444

Epoch: 5| Step: 4
Training loss: 2.068143367767334
Validation loss: 2.1245580642454085

Epoch: 5| Step: 5
Training loss: 1.884588599205017
Validation loss: 2.1455306596653436

Epoch: 5| Step: 6
Training loss: 2.6186599731445312
Validation loss: 2.078689759777438

Epoch: 5| Step: 7
Training loss: 2.6906228065490723
Validation loss: 2.1614402327486264

Epoch: 5| Step: 8
Training loss: 2.0436482429504395
Validation loss: 2.140887560382966

Epoch: 5| Step: 9
Training loss: 2.2922794818878174
Validation loss: 2.130627150176674

Epoch: 5| Step: 10
Training loss: 2.3619892597198486
Validation loss: 2.1333655311215307

Epoch: 109| Step: 0
Training loss: 2.6963276863098145
Validation loss: 2.1440210867953557

Epoch: 5| Step: 1
Training loss: 1.878637671470642
Validation loss: 2.1206045227666057

Epoch: 5| Step: 2
Training loss: 2.3571019172668457
Validation loss: 2.158686545587355

Epoch: 5| Step: 3
Training loss: 2.773277997970581
Validation loss: 2.114358511022342

Epoch: 5| Step: 4
Training loss: 2.0282444953918457
Validation loss: 2.1579851924732165

Epoch: 5| Step: 5
Training loss: 1.7070850133895874
Validation loss: 2.1486614109367452

Epoch: 5| Step: 6
Training loss: 1.9349148273468018
Validation loss: 2.130101885846866

Epoch: 5| Step: 7
Training loss: 1.7150886058807373
Validation loss: 2.0951373628390733

Epoch: 5| Step: 8
Training loss: 2.5802578926086426
Validation loss: 2.1088747311663885

Epoch: 5| Step: 9
Training loss: 2.2230639457702637
Validation loss: 2.15579927608531

Epoch: 5| Step: 10
Training loss: 2.0546021461486816
Validation loss: 2.1506299844352146

Epoch: 110| Step: 0
Training loss: 1.5456796884536743
Validation loss: 2.1274138137858403

Epoch: 5| Step: 1
Training loss: 2.172513246536255
Validation loss: 2.163951696888093

Epoch: 5| Step: 2
Training loss: 1.9052479267120361
Validation loss: 2.097868625835706

Epoch: 5| Step: 3
Training loss: 2.5562021732330322
Validation loss: 2.1236427061019407

Epoch: 5| Step: 4
Training loss: 2.2641828060150146
Validation loss: 2.1157533904557586

Epoch: 5| Step: 5
Training loss: 2.369098663330078
Validation loss: 2.132089803295751

Epoch: 5| Step: 6
Training loss: 1.8727909326553345
Validation loss: 2.151825640791206

Epoch: 5| Step: 7
Training loss: 2.437631130218506
Validation loss: 2.1093412496710338

Epoch: 5| Step: 8
Training loss: 2.2941203117370605
Validation loss: 2.1214012907397364

Epoch: 5| Step: 9
Training loss: 2.001830577850342
Validation loss: 2.144792905417822

Epoch: 5| Step: 10
Training loss: 2.3617711067199707
Validation loss: 2.112409084073959

Epoch: 111| Step: 0
Training loss: 2.1754403114318848
Validation loss: 2.148430921698129

Epoch: 5| Step: 1
Training loss: 1.998464584350586
Validation loss: 2.1044373281540407

Epoch: 5| Step: 2
Training loss: 1.659792184829712
Validation loss: 2.169634521648448

Epoch: 5| Step: 3
Training loss: 1.7215538024902344
Validation loss: 2.1477638918866395

Epoch: 5| Step: 4
Training loss: 1.8909492492675781
Validation loss: 2.136589425866322

Epoch: 5| Step: 5
Training loss: 2.8182361125946045
Validation loss: 2.1623055486268896

Epoch: 5| Step: 6
Training loss: 2.036403179168701
Validation loss: 2.137604075093423

Epoch: 5| Step: 7
Training loss: 1.8193609714508057
Validation loss: 2.1522829404441257

Epoch: 5| Step: 8
Training loss: 2.9348721504211426
Validation loss: 2.1233828324143604

Epoch: 5| Step: 9
Training loss: 2.0931479930877686
Validation loss: 2.1024290387348463

Epoch: 5| Step: 10
Training loss: 2.479104518890381
Validation loss: 2.1112774546428392

Epoch: 112| Step: 0
Training loss: 2.204726457595825
Validation loss: 2.133054914013032

Epoch: 5| Step: 1
Training loss: 2.151686191558838
Validation loss: 2.154467377611386

Epoch: 5| Step: 2
Training loss: 2.3692524433135986
Validation loss: 2.1549601798416465

Epoch: 5| Step: 3
Training loss: 2.468729257583618
Validation loss: 2.1192109328444286

Epoch: 5| Step: 4
Training loss: 1.933227777481079
Validation loss: 2.147598284547047

Epoch: 5| Step: 5
Training loss: 2.1721673011779785
Validation loss: 2.1549879889334402

Epoch: 5| Step: 6
Training loss: 2.5926804542541504
Validation loss: 2.1433546773848997

Epoch: 5| Step: 7
Training loss: 2.0698323249816895
Validation loss: 2.1238484421084003

Epoch: 5| Step: 8
Training loss: 2.3247036933898926
Validation loss: 2.1485096357202016

Epoch: 5| Step: 9
Training loss: 1.9016717672348022
Validation loss: 2.1804265565769647

Epoch: 5| Step: 10
Training loss: 1.4606527090072632
Validation loss: 2.1398798445219636

Epoch: 113| Step: 0
Training loss: 2.6331944465637207
Validation loss: 2.128746506988361

Epoch: 5| Step: 1
Training loss: 2.3712801933288574
Validation loss: 2.171905384268812

Epoch: 5| Step: 2
Training loss: 2.2588233947753906
Validation loss: 2.145090790205104

Epoch: 5| Step: 3
Training loss: 1.8553937673568726
Validation loss: 2.1260978611566688

Epoch: 5| Step: 4
Training loss: 2.1862988471984863
Validation loss: 2.2030530873165337

Epoch: 5| Step: 5
Training loss: 2.3792641162872314
Validation loss: 2.1422764639700613

Epoch: 5| Step: 6
Training loss: 1.9364484548568726
Validation loss: 2.1160457339338077

Epoch: 5| Step: 7
Training loss: 1.9046461582183838
Validation loss: 2.1403009994055635

Epoch: 5| Step: 8
Training loss: 2.065753221511841
Validation loss: 2.146514481113803

Epoch: 5| Step: 9
Training loss: 2.2585031986236572
Validation loss: 2.1709192363164758

Epoch: 5| Step: 10
Training loss: 1.9859812259674072
Validation loss: 2.157202852669583

Epoch: 114| Step: 0
Training loss: 1.7774264812469482
Validation loss: 2.1578326917463735

Epoch: 5| Step: 1
Training loss: 1.9110809564590454
Validation loss: 2.1632959893954697

Epoch: 5| Step: 2
Training loss: 1.9792972803115845
Validation loss: 2.1511630742780623

Epoch: 5| Step: 3
Training loss: 2.387913703918457
Validation loss: 2.1904124598349295

Epoch: 5| Step: 4
Training loss: 2.08624529838562
Validation loss: 2.1518227464409283

Epoch: 5| Step: 5
Training loss: 1.9836761951446533
Validation loss: 2.1307283473271195

Epoch: 5| Step: 6
Training loss: 2.399728536605835
Validation loss: 2.157818571213753

Epoch: 5| Step: 7
Training loss: 1.9677741527557373
Validation loss: 2.154880286544882

Epoch: 5| Step: 8
Training loss: 2.609409809112549
Validation loss: 2.1563469594524753

Epoch: 5| Step: 9
Training loss: 2.305546760559082
Validation loss: 2.1587167324558383

Epoch: 5| Step: 10
Training loss: 2.1429591178894043
Validation loss: 2.139246750903386

Epoch: 115| Step: 0
Training loss: 2.4874112606048584
Validation loss: 2.164792735089538

Epoch: 5| Step: 1
Training loss: 2.5759623050689697
Validation loss: 2.1212521932458364

Epoch: 5| Step: 2
Training loss: 1.9828345775604248
Validation loss: 2.1201016185104207

Epoch: 5| Step: 3
Training loss: 2.194450855255127
Validation loss: 2.145948004978959

Epoch: 5| Step: 4
Training loss: 1.726091980934143
Validation loss: 2.1253317171527493

Epoch: 5| Step: 5
Training loss: 2.054328441619873
Validation loss: 2.1391277928506174

Epoch: 5| Step: 6
Training loss: 1.464645266532898
Validation loss: 2.1567466335911907

Epoch: 5| Step: 7
Training loss: 2.520810842514038
Validation loss: 2.1307451327641806

Epoch: 5| Step: 8
Training loss: 2.4368371963500977
Validation loss: 2.121658591813939

Epoch: 5| Step: 9
Training loss: 2.004805326461792
Validation loss: 2.113459469169699

Epoch: 5| Step: 10
Training loss: 2.47835636138916
Validation loss: 2.112357021659933

Epoch: 116| Step: 0
Training loss: 1.9079368114471436
Validation loss: 2.1184443273851947

Epoch: 5| Step: 1
Training loss: 1.7652028799057007
Validation loss: 2.101302239202684

Epoch: 5| Step: 2
Training loss: 2.513620376586914
Validation loss: 2.089462980147331

Epoch: 5| Step: 3
Training loss: 2.237144947052002
Validation loss: 2.1346412089563187

Epoch: 5| Step: 4
Training loss: 1.8561668395996094
Validation loss: 2.1189820933085617

Epoch: 5| Step: 5
Training loss: 1.9906822443008423
Validation loss: 2.1548374340098393

Epoch: 5| Step: 6
Training loss: 2.2675116062164307
Validation loss: 2.131927526125344

Epoch: 5| Step: 7
Training loss: 1.9541747570037842
Validation loss: 2.090536061153617

Epoch: 5| Step: 8
Training loss: 2.292457103729248
Validation loss: 2.135158272199733

Epoch: 5| Step: 9
Training loss: 2.3669350147247314
Validation loss: 2.1151969048284713

Epoch: 5| Step: 10
Training loss: 2.412686586380005
Validation loss: 2.1400809454661545

Epoch: 117| Step: 0
Training loss: 2.548685312271118
Validation loss: 2.1001035372416177

Epoch: 5| Step: 1
Training loss: 2.075204610824585
Validation loss: 2.1614028125680904

Epoch: 5| Step: 2
Training loss: 2.0019638538360596
Validation loss: 2.092626631900828

Epoch: 5| Step: 3
Training loss: 1.5986063480377197
Validation loss: 2.1123462236055763

Epoch: 5| Step: 4
Training loss: 2.31935453414917
Validation loss: 2.1430136272984166

Epoch: 5| Step: 5
Training loss: 2.0962283611297607
Validation loss: 2.1366790033155874

Epoch: 5| Step: 6
Training loss: 2.0654726028442383
Validation loss: 2.1032908578072824

Epoch: 5| Step: 7
Training loss: 2.5751147270202637
Validation loss: 2.1325511842645626

Epoch: 5| Step: 8
Training loss: 1.8842380046844482
Validation loss: 2.136809023477698

Epoch: 5| Step: 9
Training loss: 2.43517804145813
Validation loss: 2.1363704589105423

Epoch: 5| Step: 10
Training loss: 2.1812596321105957
Validation loss: 2.0961562843732935

Epoch: 118| Step: 0
Training loss: 1.9119470119476318
Validation loss: 2.1531401821362075

Epoch: 5| Step: 1
Training loss: 2.001516342163086
Validation loss: 2.1111650697646605

Epoch: 5| Step: 2
Training loss: 2.2622382640838623
Validation loss: 2.158663486921659

Epoch: 5| Step: 3
Training loss: 1.9298534393310547
Validation loss: 2.121718688677716

Epoch: 5| Step: 4
Training loss: 2.642432451248169
Validation loss: 2.141414242406045

Epoch: 5| Step: 5
Training loss: 2.1025142669677734
Validation loss: 2.166805837744026

Epoch: 5| Step: 6
Training loss: 1.5426757335662842
Validation loss: 2.127684026636103

Epoch: 5| Step: 7
Training loss: 2.850365161895752
Validation loss: 2.1189618290111585

Epoch: 5| Step: 8
Training loss: 2.362853765487671
Validation loss: 2.166670209618025

Epoch: 5| Step: 9
Training loss: 2.0987327098846436
Validation loss: 2.1019306516134613

Epoch: 5| Step: 10
Training loss: 2.025571584701538
Validation loss: 2.1582261439292663

Epoch: 119| Step: 0
Training loss: 1.9044477939605713
Validation loss: 2.133500570892006

Epoch: 5| Step: 1
Training loss: 1.4306107759475708
Validation loss: 2.103570140818114

Epoch: 5| Step: 2
Training loss: 2.7482962608337402
Validation loss: 2.1265873883360173

Epoch: 5| Step: 3
Training loss: 1.849628210067749
Validation loss: 2.1255177387627224

Epoch: 5| Step: 4
Training loss: 2.3248379230499268
Validation loss: 2.1216522416760846

Epoch: 5| Step: 5
Training loss: 2.3319709300994873
Validation loss: 2.162151603288548

Epoch: 5| Step: 6
Training loss: 2.4465389251708984
Validation loss: 2.1217085379426197

Epoch: 5| Step: 7
Training loss: 1.7045276165008545
Validation loss: 2.1554005812573176

Epoch: 5| Step: 8
Training loss: 2.0879392623901367
Validation loss: 2.1233642357651905

Epoch: 5| Step: 9
Training loss: 2.274512767791748
Validation loss: 2.1231181544642292

Epoch: 5| Step: 10
Training loss: 2.388378143310547
Validation loss: 2.1329038540522256

Epoch: 120| Step: 0
Training loss: 2.5001766681671143
Validation loss: 2.1211076590322677

Epoch: 5| Step: 1
Training loss: 1.8624193668365479
Validation loss: 2.0972274900764547

Epoch: 5| Step: 2
Training loss: 1.692207932472229
Validation loss: 2.113246848506312

Epoch: 5| Step: 3
Training loss: 2.647005319595337
Validation loss: 2.0964988995623846

Epoch: 5| Step: 4
Training loss: 2.0363450050354004
Validation loss: 2.122218942129484

Epoch: 5| Step: 5
Training loss: 2.376032590866089
Validation loss: 2.136440230954078

Epoch: 5| Step: 6
Training loss: 1.8955777883529663
Validation loss: 2.1246316612407727

Epoch: 5| Step: 7
Training loss: 2.198809862136841
Validation loss: 2.154800490666461

Epoch: 5| Step: 8
Training loss: 2.027005434036255
Validation loss: 2.116294350675357

Epoch: 5| Step: 9
Training loss: 2.1787312030792236
Validation loss: 2.146152678356376

Epoch: 5| Step: 10
Training loss: 2.160355806350708
Validation loss: 2.164479413340169

Epoch: 121| Step: 0
Training loss: 2.1359453201293945
Validation loss: 2.1079097922130297

Epoch: 5| Step: 1
Training loss: 1.8380744457244873
Validation loss: 2.0848507701709704

Epoch: 5| Step: 2
Training loss: 1.877598524093628
Validation loss: 2.107679279901648

Epoch: 5| Step: 3
Training loss: 2.3407044410705566
Validation loss: 2.146144728506765

Epoch: 5| Step: 4
Training loss: 2.591374635696411
Validation loss: 2.1239831780874603

Epoch: 5| Step: 5
Training loss: 2.542651414871216
Validation loss: 2.1425774751170987

Epoch: 5| Step: 6
Training loss: 2.476830244064331
Validation loss: 2.13297801633035

Epoch: 5| Step: 7
Training loss: 1.8688510656356812
Validation loss: 2.1349721711169005

Epoch: 5| Step: 8
Training loss: 2.1122851371765137
Validation loss: 2.1009211463312947

Epoch: 5| Step: 9
Training loss: 2.0233407020568848
Validation loss: 2.1258659067974297

Epoch: 5| Step: 10
Training loss: 1.5208224058151245
Validation loss: 2.171611393651655

Epoch: 122| Step: 0
Training loss: 2.032957077026367
Validation loss: 2.1477463604301534

Epoch: 5| Step: 1
Training loss: 2.2229342460632324
Validation loss: 2.1376388175513155

Epoch: 5| Step: 2
Training loss: 2.3363394737243652
Validation loss: 2.127279379034555

Epoch: 5| Step: 3
Training loss: 2.1505305767059326
Validation loss: 2.1582112158498457

Epoch: 5| Step: 4
Training loss: 2.142941951751709
Validation loss: 2.1289904386766496

Epoch: 5| Step: 5
Training loss: 2.2571511268615723
Validation loss: 2.1497938133055166

Epoch: 5| Step: 6
Training loss: 2.334721088409424
Validation loss: 2.1359582857419084

Epoch: 5| Step: 7
Training loss: 1.9190212488174438
Validation loss: 2.1332735810228574

Epoch: 5| Step: 8
Training loss: 1.8966134786605835
Validation loss: 2.1744696645326513

Epoch: 5| Step: 9
Training loss: 2.2813057899475098
Validation loss: 2.109515095269808

Epoch: 5| Step: 10
Training loss: 1.9377964735031128
Validation loss: 2.188664806786404

Epoch: 123| Step: 0
Training loss: 3.012099504470825
Validation loss: 2.148163369906846

Epoch: 5| Step: 1
Training loss: 2.61625075340271
Validation loss: 2.1169983853576

Epoch: 5| Step: 2
Training loss: 2.1673388481140137
Validation loss: 2.149292428006408

Epoch: 5| Step: 3
Training loss: 2.0433993339538574
Validation loss: 2.111808487164077

Epoch: 5| Step: 4
Training loss: 1.5059993267059326
Validation loss: 2.1494116526778027

Epoch: 5| Step: 5
Training loss: 2.13615345954895
Validation loss: 2.171105738609068

Epoch: 5| Step: 6
Training loss: 2.4410407543182373
Validation loss: 2.1406747141192035

Epoch: 5| Step: 7
Training loss: 1.520754098892212
Validation loss: 2.1307120964091313

Epoch: 5| Step: 8
Training loss: 2.1289496421813965
Validation loss: 2.1167898972829184

Epoch: 5| Step: 9
Training loss: 2.3110413551330566
Validation loss: 2.1565881852180726

Epoch: 5| Step: 10
Training loss: 1.6944265365600586
Validation loss: 2.1643425290302565

Epoch: 124| Step: 0
Training loss: 2.2377541065216064
Validation loss: 2.160150735608993

Epoch: 5| Step: 1
Training loss: 2.7245306968688965
Validation loss: 2.1423124369754585

Epoch: 5| Step: 2
Training loss: 1.8465226888656616
Validation loss: 2.144779095085718

Epoch: 5| Step: 3
Training loss: 1.7514768838882446
Validation loss: 2.1528264476406958

Epoch: 5| Step: 4
Training loss: 1.729555368423462
Validation loss: 2.1359293909483057

Epoch: 5| Step: 5
Training loss: 1.669878602027893
Validation loss: 2.098902056294103

Epoch: 5| Step: 6
Training loss: 2.0232033729553223
Validation loss: 2.1557867245007585

Epoch: 5| Step: 7
Training loss: 2.5054686069488525
Validation loss: 2.1654012639035463

Epoch: 5| Step: 8
Training loss: 2.2288975715637207
Validation loss: 2.1248642206192017

Epoch: 5| Step: 9
Training loss: 2.4982008934020996
Validation loss: 2.1339356091714676

Epoch: 5| Step: 10
Training loss: 2.383999824523926
Validation loss: 2.1236571996442732

Epoch: 125| Step: 0
Training loss: 1.8346407413482666
Validation loss: 2.1644633380315637

Epoch: 5| Step: 1
Training loss: 2.2715818881988525
Validation loss: 2.1085900645102225

Epoch: 5| Step: 2
Training loss: 2.4010119438171387
Validation loss: 2.1544562514110277

Epoch: 5| Step: 3
Training loss: 1.6949892044067383
Validation loss: 2.11403714969594

Epoch: 5| Step: 4
Training loss: 2.0451254844665527
Validation loss: 2.0871596964456702

Epoch: 5| Step: 5
Training loss: 2.468825340270996
Validation loss: 2.1367287071802283

Epoch: 5| Step: 6
Training loss: 2.4182982444763184
Validation loss: 2.148893328123195

Epoch: 5| Step: 7
Training loss: 2.2685563564300537
Validation loss: 2.1257458745792346

Epoch: 5| Step: 8
Training loss: 1.7439401149749756
Validation loss: 2.1136652577307915

Epoch: 5| Step: 9
Training loss: 1.868513822555542
Validation loss: 2.1393885509942168

Epoch: 5| Step: 10
Training loss: 2.5032215118408203
Validation loss: 2.137665735777988

Epoch: 126| Step: 0
Training loss: 2.5636439323425293
Validation loss: 2.1307067691638903

Epoch: 5| Step: 1
Training loss: 1.6006815433502197
Validation loss: 2.1550113885633406

Epoch: 5| Step: 2
Training loss: 2.1134486198425293
Validation loss: 2.1446087616746143

Epoch: 5| Step: 3
Training loss: 1.2702566385269165
Validation loss: 2.1241655119003786

Epoch: 5| Step: 4
Training loss: 2.539083480834961
Validation loss: 2.147700766081451

Epoch: 5| Step: 5
Training loss: 2.3633360862731934
Validation loss: 2.169302337913103

Epoch: 5| Step: 6
Training loss: 2.395939350128174
Validation loss: 2.1508497615014353

Epoch: 5| Step: 7
Training loss: 2.1032798290252686
Validation loss: 2.165253313638831

Epoch: 5| Step: 8
Training loss: 2.0444278717041016
Validation loss: 2.14479705210655

Epoch: 5| Step: 9
Training loss: 2.2604453563690186
Validation loss: 2.104695918739483

Epoch: 5| Step: 10
Training loss: 2.3449723720550537
Validation loss: 2.152106959332702

Epoch: 127| Step: 0
Training loss: 1.9723930358886719
Validation loss: 2.162463895736202

Epoch: 5| Step: 1
Training loss: 2.764329195022583
Validation loss: 2.153677942932293

Epoch: 5| Step: 2
Training loss: 2.045213222503662
Validation loss: 2.1431307279935448

Epoch: 5| Step: 3
Training loss: 2.232978343963623
Validation loss: 2.1762876254256054

Epoch: 5| Step: 4
Training loss: 2.1136667728424072
Validation loss: 2.118783263749974

Epoch: 5| Step: 5
Training loss: 2.0586791038513184
Validation loss: 2.140969694301646

Epoch: 5| Step: 6
Training loss: 2.1443586349487305
Validation loss: 2.1373153809578187

Epoch: 5| Step: 7
Training loss: 2.171945571899414
Validation loss: 2.1713881287523495

Epoch: 5| Step: 8
Training loss: 2.366921901702881
Validation loss: 2.1555191111821

Epoch: 5| Step: 9
Training loss: 1.5915048122406006
Validation loss: 2.1313949131196543

Epoch: 5| Step: 10
Training loss: 1.7333394289016724
Validation loss: 2.110499241018808

Epoch: 128| Step: 0
Training loss: 1.5983346700668335
Validation loss: 2.113857420541907

Epoch: 5| Step: 1
Training loss: 2.2637054920196533
Validation loss: 2.1199429919642787

Epoch: 5| Step: 2
Training loss: 2.486307382583618
Validation loss: 2.1517769841737646

Epoch: 5| Step: 3
Training loss: 1.5658273696899414
Validation loss: 2.129954050945979

Epoch: 5| Step: 4
Training loss: 2.089660406112671
Validation loss: 2.1882356212985132

Epoch: 5| Step: 5
Training loss: 2.2884483337402344
Validation loss: 2.1793236629937285

Epoch: 5| Step: 6
Training loss: 2.072786331176758
Validation loss: 2.140488237463018

Epoch: 5| Step: 7
Training loss: 2.1214640140533447
Validation loss: 2.16939353686507

Epoch: 5| Step: 8
Training loss: 3.055940628051758
Validation loss: 2.1321650628120667

Epoch: 5| Step: 9
Training loss: 1.6469590663909912
Validation loss: 2.151706832711415

Epoch: 5| Step: 10
Training loss: 1.9063884019851685
Validation loss: 2.130364687212052

Epoch: 129| Step: 0
Training loss: 1.66677725315094
Validation loss: 2.1266615941960323

Epoch: 5| Step: 1
Training loss: 2.695194721221924
Validation loss: 2.141600424243558

Epoch: 5| Step: 2
Training loss: 1.7658382654190063
Validation loss: 2.162410852729633

Epoch: 5| Step: 3
Training loss: 2.0566253662109375
Validation loss: 2.1414543954274987

Epoch: 5| Step: 4
Training loss: 1.4036216735839844
Validation loss: 2.160897380562239

Epoch: 5| Step: 5
Training loss: 2.4585037231445312
Validation loss: 2.147017655834075

Epoch: 5| Step: 6
Training loss: 2.652254104614258
Validation loss: 2.122488598669729

Epoch: 5| Step: 7
Training loss: 1.9432966709136963
Validation loss: 2.159580728059174

Epoch: 5| Step: 8
Training loss: 1.6488393545150757
Validation loss: 2.161598931076706

Epoch: 5| Step: 9
Training loss: 3.097402572631836
Validation loss: 2.1387959859704457

Epoch: 5| Step: 10
Training loss: 1.916566014289856
Validation loss: 2.1256994508927867

Epoch: 130| Step: 0
Training loss: 1.8376537561416626
Validation loss: 2.1606854597727456

Epoch: 5| Step: 1
Training loss: 2.4130630493164062
Validation loss: 2.1429846991774855

Epoch: 5| Step: 2
Training loss: 1.8798452615737915
Validation loss: 2.112363733271117

Epoch: 5| Step: 3
Training loss: 2.632518768310547
Validation loss: 2.169257733129686

Epoch: 5| Step: 4
Training loss: 1.6946933269500732
Validation loss: 2.1417066640751337

Epoch: 5| Step: 5
Training loss: 1.8992894887924194
Validation loss: 2.125451073851637

Epoch: 5| Step: 6
Training loss: 2.2914397716522217
Validation loss: 2.1477118974090903

Epoch: 5| Step: 7
Training loss: 1.4001270532608032
Validation loss: 2.190152601529193

Epoch: 5| Step: 8
Training loss: 2.5880393981933594
Validation loss: 2.1861407064622447

Epoch: 5| Step: 9
Training loss: 1.937875747680664
Validation loss: 2.1309703011666574

Epoch: 5| Step: 10
Training loss: 2.576455593109131
Validation loss: 2.106287125618227

Epoch: 131| Step: 0
Training loss: 1.8760910034179688
Validation loss: 2.190509219323435

Epoch: 5| Step: 1
Training loss: 2.9072277545928955
Validation loss: 2.1471179890376266

Epoch: 5| Step: 2
Training loss: 2.3463480472564697
Validation loss: 2.1427879948769846

Epoch: 5| Step: 3
Training loss: 1.4494454860687256
Validation loss: 2.12718217859986

Epoch: 5| Step: 4
Training loss: 2.126026153564453
Validation loss: 2.133029091742731

Epoch: 5| Step: 5
Training loss: 1.8229482173919678
Validation loss: 2.1447683841951433

Epoch: 5| Step: 6
Training loss: 2.3898143768310547
Validation loss: 2.1237869621605

Epoch: 5| Step: 7
Training loss: 1.633194923400879
Validation loss: 2.1373451089346283

Epoch: 5| Step: 8
Training loss: 1.4647105932235718
Validation loss: 2.130273688224054

Epoch: 5| Step: 9
Training loss: 2.3430936336517334
Validation loss: 2.159145632097798

Epoch: 5| Step: 10
Training loss: 2.973687171936035
Validation loss: 2.117757240931193

Epoch: 132| Step: 0
Training loss: 1.8387985229492188
Validation loss: 2.1752426470479658

Epoch: 5| Step: 1
Training loss: 1.4374349117279053
Validation loss: 2.1346983319969586

Epoch: 5| Step: 2
Training loss: 2.0927913188934326
Validation loss: 2.1443634751022502

Epoch: 5| Step: 3
Training loss: 2.1354966163635254
Validation loss: 2.157076771541308

Epoch: 5| Step: 4
Training loss: 2.979440212249756
Validation loss: 2.160118738810221

Epoch: 5| Step: 5
Training loss: 1.6791789531707764
Validation loss: 2.123392830612839

Epoch: 5| Step: 6
Training loss: 2.1834444999694824
Validation loss: 2.1689989284802507

Epoch: 5| Step: 7
Training loss: 2.123720645904541
Validation loss: 2.1720366183147637

Epoch: 5| Step: 8
Training loss: 2.2238826751708984
Validation loss: 2.173679215933687

Epoch: 5| Step: 9
Training loss: 2.288857936859131
Validation loss: 2.0975706141482116

Epoch: 5| Step: 10
Training loss: 2.2584738731384277
Validation loss: 2.177303675682314

Epoch: 133| Step: 0
Training loss: 2.377380609512329
Validation loss: 2.1275578275803597

Epoch: 5| Step: 1
Training loss: 2.543632984161377
Validation loss: 2.153099203622469

Epoch: 5| Step: 2
Training loss: 2.3740200996398926
Validation loss: 2.164944205232846

Epoch: 5| Step: 3
Training loss: 1.7974151372909546
Validation loss: 2.1197366009476366

Epoch: 5| Step: 4
Training loss: 1.856459617614746
Validation loss: 2.1297224362691245

Epoch: 5| Step: 5
Training loss: 1.7622411251068115
Validation loss: 2.1121699874119093

Epoch: 5| Step: 6
Training loss: 2.6167359352111816
Validation loss: 2.1363839923694568

Epoch: 5| Step: 7
Training loss: 2.5933966636657715
Validation loss: 2.171445885012227

Epoch: 5| Step: 8
Training loss: 1.6565163135528564
Validation loss: 2.1154550762586695

Epoch: 5| Step: 9
Training loss: 1.2048287391662598
Validation loss: 2.130581808346574

Epoch: 5| Step: 10
Training loss: 2.1152851581573486
Validation loss: 2.1455960273742676

Epoch: 134| Step: 0
Training loss: 2.233689069747925
Validation loss: 2.156837127541983

Epoch: 5| Step: 1
Training loss: 1.657965898513794
Validation loss: 2.111224630827545

Epoch: 5| Step: 2
Training loss: 2.711413621902466
Validation loss: 2.1584244838324924

Epoch: 5| Step: 3
Training loss: 1.250527262687683
Validation loss: 2.1268168457092775

Epoch: 5| Step: 4
Training loss: 2.248478889465332
Validation loss: 2.108175737883455

Epoch: 5| Step: 5
Training loss: 1.9960887432098389
Validation loss: 2.1797156436468965

Epoch: 5| Step: 6
Training loss: 2.243776798248291
Validation loss: 2.1943004156953547

Epoch: 5| Step: 7
Training loss: 1.4138894081115723
Validation loss: 2.146373774415703

Epoch: 5| Step: 8
Training loss: 2.934244394302368
Validation loss: 2.146990300506674

Epoch: 5| Step: 9
Training loss: 2.537477493286133
Validation loss: 2.095991244880102

Epoch: 5| Step: 10
Training loss: 1.7674310207366943
Validation loss: 2.1465129313930387

Epoch: 135| Step: 0
Training loss: 2.27702260017395
Validation loss: 2.160717579626268

Epoch: 5| Step: 1
Training loss: 1.3806767463684082
Validation loss: 2.12434789698611

Epoch: 5| Step: 2
Training loss: 2.194556951522827
Validation loss: 2.0905012481956073

Epoch: 5| Step: 3
Training loss: 1.8383738994598389
Validation loss: 2.1273614104076097

Epoch: 5| Step: 4
Training loss: 2.334446430206299
Validation loss: 2.1512294635977796

Epoch: 5| Step: 5
Training loss: 1.7291570901870728
Validation loss: 2.1149725144909275

Epoch: 5| Step: 6
Training loss: 2.519763469696045
Validation loss: 2.1738324511435723

Epoch: 5| Step: 7
Training loss: 2.059149742126465
Validation loss: 2.129064472772742

Epoch: 5| Step: 8
Training loss: 2.217487335205078
Validation loss: 2.1368062393639677

Epoch: 5| Step: 9
Training loss: 2.6426842212677
Validation loss: 2.1740309628107215

Epoch: 5| Step: 10
Training loss: 1.7109347581863403
Validation loss: 2.1281742536893455

Epoch: 136| Step: 0
Training loss: 2.553553581237793
Validation loss: 2.109971405357443

Epoch: 5| Step: 1
Training loss: 2.222564220428467
Validation loss: 2.1562385700082265

Epoch: 5| Step: 2
Training loss: 2.552802562713623
Validation loss: 2.124147379270164

Epoch: 5| Step: 3
Training loss: 2.1242737770080566
Validation loss: 2.1143271269336825

Epoch: 5| Step: 4
Training loss: 2.0800371170043945
Validation loss: 2.1528653098690893

Epoch: 5| Step: 5
Training loss: 1.877041220664978
Validation loss: 2.1438211510258336

Epoch: 5| Step: 6
Training loss: 1.6124407052993774
Validation loss: 2.114815758120629

Epoch: 5| Step: 7
Training loss: 2.4612793922424316
Validation loss: 2.1348696934279574

Epoch: 5| Step: 8
Training loss: 1.3270881175994873
Validation loss: 2.187033176422119

Epoch: 5| Step: 9
Training loss: 1.938929796218872
Validation loss: 2.130980363456152

Epoch: 5| Step: 10
Training loss: 2.4499447345733643
Validation loss: 2.098908241077136

Epoch: 137| Step: 0
Training loss: 2.528028964996338
Validation loss: 2.1947893763101227

Epoch: 5| Step: 1
Training loss: 2.331409454345703
Validation loss: 2.1426568505584553

Epoch: 5| Step: 2
Training loss: 1.9217913150787354
Validation loss: 2.167949773932016

Epoch: 5| Step: 3
Training loss: 2.068239212036133
Validation loss: 2.100762200611894

Epoch: 5| Step: 4
Training loss: 3.111057996749878
Validation loss: 2.170649843831216

Epoch: 5| Step: 5
Training loss: 1.7978017330169678
Validation loss: 2.184745239955123

Epoch: 5| Step: 6
Training loss: 2.116133213043213
Validation loss: 2.146760807242445

Epoch: 5| Step: 7
Training loss: 1.6494865417480469
Validation loss: 2.112591746032879

Epoch: 5| Step: 8
Training loss: 1.6600115299224854
Validation loss: 2.0866327824131137

Epoch: 5| Step: 9
Training loss: 2.297245502471924
Validation loss: 2.1631968277756886

Epoch: 5| Step: 10
Training loss: 1.4526954889297485
Validation loss: 2.167939063041441

Epoch: 138| Step: 0
Training loss: 1.8631395101547241
Validation loss: 2.1247568104856756

Epoch: 5| Step: 1
Training loss: 2.224860668182373
Validation loss: 2.128539700661936

Epoch: 5| Step: 2
Training loss: 2.6803343296051025
Validation loss: 2.1260308988632692

Epoch: 5| Step: 3
Training loss: 1.6256996393203735
Validation loss: 2.128595854646416

Epoch: 5| Step: 4
Training loss: 1.3839308023452759
Validation loss: 2.129871855499924

Epoch: 5| Step: 5
Training loss: 1.8913685083389282
Validation loss: 2.097497199171333

Epoch: 5| Step: 6
Training loss: 1.9429746866226196
Validation loss: 2.138699487973285

Epoch: 5| Step: 7
Training loss: 2.4585156440734863
Validation loss: 2.141170399163359

Epoch: 5| Step: 8
Training loss: 2.514450788497925
Validation loss: 2.160008035680299

Epoch: 5| Step: 9
Training loss: 2.427022695541382
Validation loss: 2.146021850647465

Epoch: 5| Step: 10
Training loss: 1.7798471450805664
Validation loss: 2.163194587153773

Epoch: 139| Step: 0
Training loss: 2.5860109329223633
Validation loss: 2.133981598320828

Epoch: 5| Step: 1
Training loss: 2.9584357738494873
Validation loss: 2.1297409739545596

Epoch: 5| Step: 2
Training loss: 1.9302685260772705
Validation loss: 2.167429188246368

Epoch: 5| Step: 3
Training loss: 1.5100619792938232
Validation loss: 2.1423738720596477

Epoch: 5| Step: 4
Training loss: 2.0703418254852295
Validation loss: 2.117790798987112

Epoch: 5| Step: 5
Training loss: 1.517859935760498
Validation loss: 2.1514341395388366

Epoch: 5| Step: 6
Training loss: 1.6066093444824219
Validation loss: 2.1435697245341476

Epoch: 5| Step: 7
Training loss: 3.065918445587158
Validation loss: 2.140129800765745

Epoch: 5| Step: 8
Training loss: 1.7238445281982422
Validation loss: 2.162857278700798

Epoch: 5| Step: 9
Training loss: 2.0069618225097656
Validation loss: 2.1524641270278604

Epoch: 5| Step: 10
Training loss: 2.204202651977539
Validation loss: 2.157698098049369

Epoch: 140| Step: 0
Training loss: 1.9200236797332764
Validation loss: 2.128102017987159

Epoch: 5| Step: 1
Training loss: 3.0794827938079834
Validation loss: 2.1386257435685847

Epoch: 5| Step: 2
Training loss: 1.6153627634048462
Validation loss: 2.160597483317057

Epoch: 5| Step: 3
Training loss: 1.6683464050292969
Validation loss: 2.1478704047459427

Epoch: 5| Step: 4
Training loss: 2.2471582889556885
Validation loss: 2.1822822068327214

Epoch: 5| Step: 5
Training loss: 1.848828911781311
Validation loss: 2.1610715863525227

Epoch: 5| Step: 6
Training loss: 1.8337600231170654
Validation loss: 2.1166742129992415

Epoch: 5| Step: 7
Training loss: 2.6723592281341553
Validation loss: 2.1609494224671395

Epoch: 5| Step: 8
Training loss: 1.8497629165649414
Validation loss: 2.141809968538182

Epoch: 5| Step: 9
Training loss: 2.2663686275482178
Validation loss: 2.126593928183279

Epoch: 5| Step: 10
Training loss: 2.041229248046875
Validation loss: 2.116101925091077

Epoch: 141| Step: 0
Training loss: 2.354651689529419
Validation loss: 2.13093985537047

Epoch: 5| Step: 1
Training loss: 1.987860918045044
Validation loss: 2.1364450864894415

Epoch: 5| Step: 2
Training loss: 1.7568542957305908
Validation loss: 2.07445514458482

Epoch: 5| Step: 3
Training loss: 1.700619101524353
Validation loss: 2.1476050961402153

Epoch: 5| Step: 4
Training loss: 2.032186985015869
Validation loss: 2.1587632625333724

Epoch: 5| Step: 5
Training loss: 2.0787549018859863
Validation loss: 2.1256507109570246

Epoch: 5| Step: 6
Training loss: 2.3282155990600586
Validation loss: 2.1452662073155886

Epoch: 5| Step: 7
Training loss: 1.6283843517303467
Validation loss: 2.132131076628162

Epoch: 5| Step: 8
Training loss: 2.102505922317505
Validation loss: 2.104347793004846

Epoch: 5| Step: 9
Training loss: 2.665250062942505
Validation loss: 2.1170180356630715

Epoch: 5| Step: 10
Training loss: 2.6597487926483154
Validation loss: 2.1515591580380677

Epoch: 142| Step: 0
Training loss: 1.901868462562561
Validation loss: 2.1385288776889926

Epoch: 5| Step: 1
Training loss: 2.314378261566162
Validation loss: 2.1697526311361663

Epoch: 5| Step: 2
Training loss: 2.404463529586792
Validation loss: 2.170324320434242

Epoch: 5| Step: 3
Training loss: 1.433870553970337
Validation loss: 2.099550483047321

Epoch: 5| Step: 4
Training loss: 2.3829727172851562
Validation loss: 2.1386915458145963

Epoch: 5| Step: 5
Training loss: 2.105149507522583
Validation loss: 2.167063210600166

Epoch: 5| Step: 6
Training loss: 2.6948628425598145
Validation loss: 2.146279145312566

Epoch: 5| Step: 7
Training loss: 1.2605806589126587
Validation loss: 2.156961730731431

Epoch: 5| Step: 8
Training loss: 2.4483590126037598
Validation loss: 2.103909760393122

Epoch: 5| Step: 9
Training loss: 1.9048525094985962
Validation loss: 2.134964555822393

Epoch: 5| Step: 10
Training loss: 2.1439337730407715
Validation loss: 2.1073986804613503

Epoch: 143| Step: 0
Training loss: 2.1304874420166016
Validation loss: 2.155960161198852

Epoch: 5| Step: 1
Training loss: 2.316917896270752
Validation loss: 2.140798689216696

Epoch: 5| Step: 2
Training loss: 2.496047019958496
Validation loss: 2.1273193410647813

Epoch: 5| Step: 3
Training loss: 1.3427244424819946
Validation loss: 2.1608974061986452

Epoch: 5| Step: 4
Training loss: 1.8981252908706665
Validation loss: 2.120561397203835

Epoch: 5| Step: 5
Training loss: 2.1386852264404297
Validation loss: 2.127452693959718

Epoch: 5| Step: 6
Training loss: 2.16542649269104
Validation loss: 2.1087515879702825

Epoch: 5| Step: 7
Training loss: 2.3407044410705566
Validation loss: 2.1310602567529164

Epoch: 5| Step: 8
Training loss: 2.0648117065429688
Validation loss: 2.0872398960974907

Epoch: 5| Step: 9
Training loss: 2.0779409408569336
Validation loss: 2.1658290996346423

Epoch: 5| Step: 10
Training loss: 1.8857498168945312
Validation loss: 2.123871321319252

Epoch: 144| Step: 0
Training loss: 2.3097071647644043
Validation loss: 2.0918034648382537

Epoch: 5| Step: 1
Training loss: 2.069185495376587
Validation loss: 2.1536536703827562

Epoch: 5| Step: 2
Training loss: 2.1093661785125732
Validation loss: 2.1356398200476043

Epoch: 5| Step: 3
Training loss: 2.1638309955596924
Validation loss: 2.1456095659604637

Epoch: 5| Step: 4
Training loss: 2.2495903968811035
Validation loss: 2.185716326518725

Epoch: 5| Step: 5
Training loss: 1.006225824356079
Validation loss: 2.1481569300415697

Epoch: 5| Step: 6
Training loss: 2.0772576332092285
Validation loss: 2.1558215669406358

Epoch: 5| Step: 7
Training loss: 2.3417229652404785
Validation loss: 2.154645205825888

Epoch: 5| Step: 8
Training loss: 1.8617465496063232
Validation loss: 2.107556927588678

Epoch: 5| Step: 9
Training loss: 1.829393982887268
Validation loss: 2.138736412089358

Epoch: 5| Step: 10
Training loss: 2.8632538318634033
Validation loss: 2.11778929925734

Epoch: 145| Step: 0
Training loss: 2.102273941040039
Validation loss: 2.1598899569562686

Epoch: 5| Step: 1
Training loss: 1.9020004272460938
Validation loss: 2.1159119439381424

Epoch: 5| Step: 2
Training loss: 1.8184547424316406
Validation loss: 2.1251240289339455

Epoch: 5| Step: 3
Training loss: 1.6075465679168701
Validation loss: 2.114823564406364

Epoch: 5| Step: 4
Training loss: 1.527143955230713
Validation loss: 2.1318592127933296

Epoch: 5| Step: 5
Training loss: 2.1739745140075684
Validation loss: 2.1377060490269817

Epoch: 5| Step: 6
Training loss: 2.576359272003174
Validation loss: 2.159385427351921

Epoch: 5| Step: 7
Training loss: 2.832655429840088
Validation loss: 2.1272497638579337

Epoch: 5| Step: 8
Training loss: 1.9975864887237549
Validation loss: 2.1835215630069857

Epoch: 5| Step: 9
Training loss: 2.3360908031463623
Validation loss: 2.1355003272333453

Epoch: 5| Step: 10
Training loss: 1.9864494800567627
Validation loss: 2.140485648185976

Epoch: 146| Step: 0
Training loss: 2.1661622524261475
Validation loss: 2.1347733915493055

Epoch: 5| Step: 1
Training loss: 2.208517074584961
Validation loss: 2.1505660151922577

Epoch: 5| Step: 2
Training loss: 1.88692307472229
Validation loss: 2.141136602688861

Epoch: 5| Step: 3
Training loss: 2.0484302043914795
Validation loss: 2.0885958607478807

Epoch: 5| Step: 4
Training loss: 1.8011395931243896
Validation loss: 2.1270031134287515

Epoch: 5| Step: 5
Training loss: 2.3853163719177246
Validation loss: 2.1244610971020115

Epoch: 5| Step: 6
Training loss: 2.282877206802368
Validation loss: 2.1417558757207726

Epoch: 5| Step: 7
Training loss: 2.4970850944519043
Validation loss: 2.1373903879555325

Epoch: 5| Step: 8
Training loss: 1.7561429738998413
Validation loss: 2.149908814378964

Epoch: 5| Step: 9
Training loss: 2.0865530967712402
Validation loss: 2.135317915229387

Epoch: 5| Step: 10
Training loss: 1.6127784252166748
Validation loss: 2.09542175005841

Epoch: 147| Step: 0
Training loss: 2.054265260696411
Validation loss: 2.1188524256470385

Epoch: 5| Step: 1
Training loss: 1.929843544960022
Validation loss: 2.1449541532865135

Epoch: 5| Step: 2
Training loss: 2.020139217376709
Validation loss: 2.163632259573988

Epoch: 5| Step: 3
Training loss: 2.2216925621032715
Validation loss: 2.1373037522838962

Epoch: 5| Step: 4
Training loss: 2.242922306060791
Validation loss: 2.1057283083597818

Epoch: 5| Step: 5
Training loss: 2.915109157562256
Validation loss: 2.1308446353481663

Epoch: 5| Step: 6
Training loss: 1.2224940061569214
Validation loss: 2.1124585802837084

Epoch: 5| Step: 7
Training loss: 1.3962918519973755
Validation loss: 2.117525892872964

Epoch: 5| Step: 8
Training loss: 1.9584667682647705
Validation loss: 2.1383022441658923

Epoch: 5| Step: 9
Training loss: 2.7005934715270996
Validation loss: 2.146791297902343

Epoch: 5| Step: 10
Training loss: 1.9052505493164062
Validation loss: 2.107460311664048

Epoch: 148| Step: 0
Training loss: 2.820263624191284
Validation loss: 2.133646947081371

Epoch: 5| Step: 1
Training loss: 1.6032005548477173
Validation loss: 2.118223577417353

Epoch: 5| Step: 2
Training loss: 3.1775970458984375
Validation loss: 2.1503328354127946

Epoch: 5| Step: 3
Training loss: 2.553097724914551
Validation loss: 2.1111982176380772

Epoch: 5| Step: 4
Training loss: 1.9832239151000977
Validation loss: 2.1289442969906713

Epoch: 5| Step: 5
Training loss: 2.4031612873077393
Validation loss: 2.1297727118256273

Epoch: 5| Step: 6
Training loss: 1.385498046875
Validation loss: 2.120589397286856

Epoch: 5| Step: 7
Training loss: 1.8420311212539673
Validation loss: 2.1417737122504943

Epoch: 5| Step: 8
Training loss: 1.3298521041870117
Validation loss: 2.1209780067525883

Epoch: 5| Step: 9
Training loss: 1.313147783279419
Validation loss: 2.170453817613663

Epoch: 5| Step: 10
Training loss: 2.671556234359741
Validation loss: 2.1393001464105423

Epoch: 149| Step: 0
Training loss: 2.4915895462036133
Validation loss: 2.1361972747310514

Epoch: 5| Step: 1
Training loss: 2.296804428100586
Validation loss: 2.105430487663515

Epoch: 5| Step: 2
Training loss: 2.3775076866149902
Validation loss: 2.135808273028302

Epoch: 5| Step: 3
Training loss: 2.055478572845459
Validation loss: 2.121646245320638

Epoch: 5| Step: 4
Training loss: 2.343435287475586
Validation loss: 2.1319336122082126

Epoch: 5| Step: 5
Training loss: 1.898193597793579
Validation loss: 2.1495682219023347

Epoch: 5| Step: 6
Training loss: 1.8609758615493774
Validation loss: 2.1162627640590874

Epoch: 5| Step: 7
Training loss: 2.138622760772705
Validation loss: 2.141938932480351

Epoch: 5| Step: 8
Training loss: 1.876430869102478
Validation loss: 2.1756459256654144

Epoch: 5| Step: 9
Training loss: 1.6803795099258423
Validation loss: 2.1493411256420996

Epoch: 5| Step: 10
Training loss: 1.4132122993469238
Validation loss: 2.160033864359702

Epoch: 150| Step: 0
Training loss: 2.193206548690796
Validation loss: 2.1257568251702095

Epoch: 5| Step: 1
Training loss: 2.385423183441162
Validation loss: 2.151264423965126

Epoch: 5| Step: 2
Training loss: 1.3856995105743408
Validation loss: 2.1528192771378385

Epoch: 5| Step: 3
Training loss: 2.0004804134368896
Validation loss: 2.1473120412518902

Epoch: 5| Step: 4
Training loss: 2.06902813911438
Validation loss: 2.1431630157655284

Epoch: 5| Step: 5
Training loss: 1.1789392232894897
Validation loss: 2.1256007327828357

Epoch: 5| Step: 6
Training loss: 2.244547128677368
Validation loss: 2.1533566008331957

Epoch: 5| Step: 7
Training loss: 2.531153440475464
Validation loss: 2.1722322202497915

Epoch: 5| Step: 8
Training loss: 1.9484617710113525
Validation loss: 2.1359797780231764

Epoch: 5| Step: 9
Training loss: 2.35941743850708
Validation loss: 2.0822781593568864

Epoch: 5| Step: 10
Training loss: 1.9214284420013428
Validation loss: 2.1701215749145835

Epoch: 151| Step: 0
Training loss: 1.120102047920227
Validation loss: 2.0852707791072067

Epoch: 5| Step: 1
Training loss: 2.1774678230285645
Validation loss: 2.116159048131717

Epoch: 5| Step: 2
Training loss: 2.8341972827911377
Validation loss: 2.1190786079693864

Epoch: 5| Step: 3
Training loss: 1.771287202835083
Validation loss: 2.1307967683320403

Epoch: 5| Step: 4
Training loss: 1.725111961364746
Validation loss: 2.159414288818195

Epoch: 5| Step: 5
Training loss: 2.288264751434326
Validation loss: 2.140959724303215

Epoch: 5| Step: 6
Training loss: 1.895451307296753
Validation loss: 2.115298399361231

Epoch: 5| Step: 7
Training loss: 2.6991782188415527
Validation loss: 2.119722180469062

Epoch: 5| Step: 8
Training loss: 1.82962965965271
Validation loss: 2.14215620358785

Epoch: 5| Step: 9
Training loss: 2.3505234718322754
Validation loss: 2.0960633588093582

Epoch: 5| Step: 10
Training loss: 1.8035799264907837
Validation loss: 2.1633653102382535

Epoch: 152| Step: 0
Training loss: 1.8922744989395142
Validation loss: 2.097752037868705

Epoch: 5| Step: 1
Training loss: 1.86776602268219
Validation loss: 2.131192094536238

Epoch: 5| Step: 2
Training loss: 2.1056432723999023
Validation loss: 2.1104314814331713

Epoch: 5| Step: 3
Training loss: 1.9204750061035156
Validation loss: 2.108690575886798

Epoch: 5| Step: 4
Training loss: 2.1453499794006348
Validation loss: 2.146170457204183

Epoch: 5| Step: 5
Training loss: 1.893883466720581
Validation loss: 2.1439400616512505

Epoch: 5| Step: 6
Training loss: 1.7261838912963867
Validation loss: 2.120708119484686

Epoch: 5| Step: 7
Training loss: 2.139979124069214
Validation loss: 2.165961451427911

Epoch: 5| Step: 8
Training loss: 2.335604667663574
Validation loss: 2.1356541495169363

Epoch: 5| Step: 9
Training loss: 2.4905879497528076
Validation loss: 2.100620961958362

Epoch: 5| Step: 10
Training loss: 2.0508100986480713
Validation loss: 2.111986308969477

Epoch: 153| Step: 0
Training loss: 1.6675834655761719
Validation loss: 2.147761068036479

Epoch: 5| Step: 1
Training loss: 2.869969367980957
Validation loss: 2.0992380790812994

Epoch: 5| Step: 2
Training loss: 2.339282274246216
Validation loss: 2.1033132178809053

Epoch: 5| Step: 3
Training loss: 1.9711358547210693
Validation loss: 2.1169986699217107

Epoch: 5| Step: 4
Training loss: 2.2061245441436768
Validation loss: 2.1113866477884273

Epoch: 5| Step: 5
Training loss: 1.9397563934326172
Validation loss: 2.1525601584424257

Epoch: 5| Step: 6
Training loss: 1.94240403175354
Validation loss: 2.1853340236089562

Epoch: 5| Step: 7
Training loss: 1.281180739402771
Validation loss: 2.175935358129522

Epoch: 5| Step: 8
Training loss: 2.1011600494384766
Validation loss: 2.131410050135787

Epoch: 5| Step: 9
Training loss: 1.756116509437561
Validation loss: 2.1743603521777737

Epoch: 5| Step: 10
Training loss: 2.3539106845855713
Validation loss: 2.1173132311913276

Epoch: 154| Step: 0
Training loss: 2.6057841777801514
Validation loss: 2.137821747410682

Epoch: 5| Step: 1
Training loss: 2.1311376094818115
Validation loss: 2.1499932171196066

Epoch: 5| Step: 2
Training loss: 2.2315762042999268
Validation loss: 2.12492649914116

Epoch: 5| Step: 3
Training loss: 1.8733022212982178
Validation loss: 2.1269458904061267

Epoch: 5| Step: 4
Training loss: 1.9701915979385376
Validation loss: 2.1216769577354513

Epoch: 5| Step: 5
Training loss: 1.9574085474014282
Validation loss: 2.1783585086945565

Epoch: 5| Step: 6
Training loss: 2.163370132446289
Validation loss: 2.142752730718223

Epoch: 5| Step: 7
Training loss: 1.864566445350647
Validation loss: 2.124835700117132

Epoch: 5| Step: 8
Training loss: 2.6519644260406494
Validation loss: 2.1284977569374988

Epoch: 5| Step: 9
Training loss: 1.433411955833435
Validation loss: 2.13817996363486

Epoch: 5| Step: 10
Training loss: 1.9888951778411865
Validation loss: 2.138411929530482

Epoch: 155| Step: 0
Training loss: 1.7128490209579468
Validation loss: 2.116967314033098

Epoch: 5| Step: 1
Training loss: 1.8173002004623413
Validation loss: 2.155487977048402

Epoch: 5| Step: 2
Training loss: 1.2861686944961548
Validation loss: 2.1329793186597925

Epoch: 5| Step: 3
Training loss: 3.0429391860961914
Validation loss: 2.0809781807725147

Epoch: 5| Step: 4
Training loss: 2.553607702255249
Validation loss: 2.1624038629634406

Epoch: 5| Step: 5
Training loss: 2.101933479309082
Validation loss: 2.146194158061858

Epoch: 5| Step: 6
Training loss: 2.580009698867798
Validation loss: 2.0859613585215744

Epoch: 5| Step: 7
Training loss: 1.535277009010315
Validation loss: 2.1614461637312368

Epoch: 5| Step: 8
Training loss: 1.4181278944015503
Validation loss: 2.141623362418144

Epoch: 5| Step: 9
Training loss: 2.5703017711639404
Validation loss: 2.124968436456496

Epoch: 5| Step: 10
Training loss: 1.8696976900100708
Validation loss: 2.1220115705202987

Epoch: 156| Step: 0
Training loss: 1.356043815612793
Validation loss: 2.1059801527248916

Epoch: 5| Step: 1
Training loss: 2.387392520904541
Validation loss: 2.131313516247657

Epoch: 5| Step: 2
Training loss: 2.107703685760498
Validation loss: 2.1243034050028813

Epoch: 5| Step: 3
Training loss: 2.4512722492218018
Validation loss: 2.121495476333044

Epoch: 5| Step: 4
Training loss: 2.0635294914245605
Validation loss: 2.1412589421836277

Epoch: 5| Step: 5
Training loss: 2.270136833190918
Validation loss: 2.100759821553384

Epoch: 5| Step: 6
Training loss: 1.455493688583374
Validation loss: 2.1464633352013043

Epoch: 5| Step: 7
Training loss: 1.7629045248031616
Validation loss: 2.0627908898938085

Epoch: 5| Step: 8
Training loss: 2.7657558917999268
Validation loss: 2.0990295794702347

Epoch: 5| Step: 9
Training loss: 1.568178415298462
Validation loss: 2.148707507759012

Epoch: 5| Step: 10
Training loss: 2.229654312133789
Validation loss: 2.127583198649909

Epoch: 157| Step: 0
Training loss: 2.312408924102783
Validation loss: 2.099952245271334

Epoch: 5| Step: 1
Training loss: 1.5320372581481934
Validation loss: 2.1468570616937455

Epoch: 5| Step: 2
Training loss: 2.042656421661377
Validation loss: 2.1460332767937773

Epoch: 5| Step: 3
Training loss: 1.7882699966430664
Validation loss: 2.1090639842453824

Epoch: 5| Step: 4
Training loss: 1.7275184392929077
Validation loss: 2.146065970902802

Epoch: 5| Step: 5
Training loss: 1.6999943256378174
Validation loss: 2.1619407771736063

Epoch: 5| Step: 6
Training loss: 2.648387908935547
Validation loss: 2.147963270064323

Epoch: 5| Step: 7
Training loss: 2.4634485244750977
Validation loss: 2.1186092540781987

Epoch: 5| Step: 8
Training loss: 2.5595104694366455
Validation loss: 2.129724725600212

Epoch: 5| Step: 9
Training loss: 1.5763356685638428
Validation loss: 2.1211652550646054

Epoch: 5| Step: 10
Training loss: 2.1869587898254395
Validation loss: 2.1033019532439527

Epoch: 158| Step: 0
Training loss: 2.9028971195220947
Validation loss: 2.1409481520293863

Epoch: 5| Step: 1
Training loss: 1.4757455587387085
Validation loss: 2.1195052721167125

Epoch: 5| Step: 2
Training loss: 1.4090889692306519
Validation loss: 2.099326609283365

Epoch: 5| Step: 3
Training loss: 1.9833917617797852
Validation loss: 2.1422603771250737

Epoch: 5| Step: 4
Training loss: 1.7144060134887695
Validation loss: 2.1555350467722905

Epoch: 5| Step: 5
Training loss: 2.2196319103240967
Validation loss: 2.097491761689545

Epoch: 5| Step: 6
Training loss: 1.7481086254119873
Validation loss: 2.139798266913301

Epoch: 5| Step: 7
Training loss: 1.6766011714935303
Validation loss: 2.1177379597899733

Epoch: 5| Step: 8
Training loss: 2.5676372051239014
Validation loss: 2.119304705691594

Epoch: 5| Step: 9
Training loss: 1.8437063694000244
Validation loss: 2.147049282186775

Epoch: 5| Step: 10
Training loss: 2.8005971908569336
Validation loss: 2.1556096282056583

Epoch: 159| Step: 0
Training loss: 1.9326270818710327
Validation loss: 2.179753964947116

Epoch: 5| Step: 1
Training loss: 2.5107524394989014
Validation loss: 2.136016240683935

Epoch: 5| Step: 2
Training loss: 1.8879163265228271
Validation loss: 2.158193470329367

Epoch: 5| Step: 3
Training loss: 2.1917874813079834
Validation loss: 2.1458191230732906

Epoch: 5| Step: 4
Training loss: 2.4961414337158203
Validation loss: 2.1226476366801927

Epoch: 5| Step: 5
Training loss: 1.8091819286346436
Validation loss: 2.0983379233268

Epoch: 5| Step: 6
Training loss: 2.2583935260772705
Validation loss: 2.102783144161265

Epoch: 5| Step: 7
Training loss: 1.4269273281097412
Validation loss: 2.1443860197579987

Epoch: 5| Step: 8
Training loss: 2.3256938457489014
Validation loss: 2.09513916507844

Epoch: 5| Step: 9
Training loss: 2.132117509841919
Validation loss: 2.1359591407160603

Epoch: 5| Step: 10
Training loss: 1.4185588359832764
Validation loss: 2.1517884705656316

Epoch: 160| Step: 0
Training loss: 2.126457452774048
Validation loss: 2.1400871405037503

Epoch: 5| Step: 1
Training loss: 1.7990423440933228
Validation loss: 2.111711730239212

Epoch: 5| Step: 2
Training loss: 1.9511635303497314
Validation loss: 2.114431740135275

Epoch: 5| Step: 3
Training loss: 2.176389455795288
Validation loss: 2.121242871848486

Epoch: 5| Step: 4
Training loss: 2.065333843231201
Validation loss: 2.0864973837329495

Epoch: 5| Step: 5
Training loss: 2.491293430328369
Validation loss: 2.1301804511777815

Epoch: 5| Step: 6
Training loss: 1.8172792196273804
Validation loss: 2.1200007674514607

Epoch: 5| Step: 7
Training loss: 2.203895330429077
Validation loss: 2.16818130400873

Epoch: 5| Step: 8
Training loss: 1.8240032196044922
Validation loss: 2.1435419744060886

Epoch: 5| Step: 9
Training loss: 2.014899969100952
Validation loss: 2.118161286077192

Epoch: 5| Step: 10
Training loss: 1.9217529296875
Validation loss: 2.142717489632227

Epoch: 161| Step: 0
Training loss: 1.7101389169692993
Validation loss: 2.1416484284144577

Epoch: 5| Step: 1
Training loss: 1.7067903280258179
Validation loss: 2.126684460588681

Epoch: 5| Step: 2
Training loss: 2.3899636268615723
Validation loss: 2.1904721721526115

Epoch: 5| Step: 3
Training loss: 2.3738601207733154
Validation loss: 2.1479676359443256

Epoch: 5| Step: 4
Training loss: 2.4840664863586426
Validation loss: 2.096793779762842

Epoch: 5| Step: 5
Training loss: 1.2593910694122314
Validation loss: 2.0929521181250132

Epoch: 5| Step: 6
Training loss: 2.1395134925842285
Validation loss: 2.1211491784741803

Epoch: 5| Step: 7
Training loss: 2.1598050594329834
Validation loss: 2.118859801241147

Epoch: 5| Step: 8
Training loss: 1.5789510011672974
Validation loss: 2.0802813704295824

Epoch: 5| Step: 9
Training loss: 1.7442318201065063
Validation loss: 2.133995399680189

Epoch: 5| Step: 10
Training loss: 2.6439666748046875
Validation loss: 2.0624521727203042

Epoch: 162| Step: 0
Training loss: 2.211198091506958
Validation loss: 2.1307149574320805

Epoch: 5| Step: 1
Training loss: 1.7427566051483154
Validation loss: 2.1381445059212307

Epoch: 5| Step: 2
Training loss: 2.164269208908081
Validation loss: 2.081060544137032

Epoch: 5| Step: 3
Training loss: 1.9849154949188232
Validation loss: 2.0988721347624257

Epoch: 5| Step: 4
Training loss: 1.6667362451553345
Validation loss: 2.138747710053639

Epoch: 5| Step: 5
Training loss: 2.2359142303466797
Validation loss: 2.100955652934249

Epoch: 5| Step: 6
Training loss: 2.1320714950561523
Validation loss: 2.149362487177695

Epoch: 5| Step: 7
Training loss: 1.8075065612792969
Validation loss: 2.099230145895353

Epoch: 5| Step: 8
Training loss: 2.2119269371032715
Validation loss: 2.092027084801787

Epoch: 5| Step: 9
Training loss: 2.264737606048584
Validation loss: 2.1533819026844476

Epoch: 5| Step: 10
Training loss: 1.6079615354537964
Validation loss: 2.1013328682991768

Epoch: 163| Step: 0
Training loss: 1.679131269454956
Validation loss: 2.1313349623833933

Epoch: 5| Step: 1
Training loss: 1.5060837268829346
Validation loss: 2.157328131378338

Epoch: 5| Step: 2
Training loss: 2.321760654449463
Validation loss: 2.12975618403445

Epoch: 5| Step: 3
Training loss: 1.7714580297470093
Validation loss: 2.129361080866988

Epoch: 5| Step: 4
Training loss: 1.9925329685211182
Validation loss: 2.1170590564768803

Epoch: 5| Step: 5
Training loss: 2.241558790206909
Validation loss: 2.1406489918308873

Epoch: 5| Step: 6
Training loss: 2.907747268676758
Validation loss: 2.117507617960694

Epoch: 5| Step: 7
Training loss: 1.2754427194595337
Validation loss: 2.1353540497441448

Epoch: 5| Step: 8
Training loss: 2.069000244140625
Validation loss: 2.131670695479198

Epoch: 5| Step: 9
Training loss: 1.8884481191635132
Validation loss: 2.1159074024487565

Epoch: 5| Step: 10
Training loss: 2.9595441818237305
Validation loss: 2.1315280647688013

Epoch: 164| Step: 0
Training loss: 1.9970448017120361
Validation loss: 2.117062730173911

Epoch: 5| Step: 1
Training loss: 2.408161163330078
Validation loss: 2.133835595141175

Epoch: 5| Step: 2
Training loss: 1.4198492765426636
Validation loss: 2.120847905835798

Epoch: 5| Step: 3
Training loss: 1.9813216924667358
Validation loss: 2.1495958066755727

Epoch: 5| Step: 4
Training loss: 1.7402355670928955
Validation loss: 2.132765193139353

Epoch: 5| Step: 5
Training loss: 1.797637701034546
Validation loss: 2.145536317620226

Epoch: 5| Step: 6
Training loss: 2.694920778274536
Validation loss: 2.1195689542319185

Epoch: 5| Step: 7
Training loss: 1.6959247589111328
Validation loss: 2.145410663338118

Epoch: 5| Step: 8
Training loss: 2.028862476348877
Validation loss: 2.100335636446553

Epoch: 5| Step: 9
Training loss: 1.5088672637939453
Validation loss: 2.076766149972075

Epoch: 5| Step: 10
Training loss: 3.0097246170043945
Validation loss: 2.125397038716142

Epoch: 165| Step: 0
Training loss: 2.1143178939819336
Validation loss: 2.1550237696657897

Epoch: 5| Step: 1
Training loss: 1.803633451461792
Validation loss: 2.1625107231960503

Epoch: 5| Step: 2
Training loss: 1.8046386241912842
Validation loss: 2.136286897044028

Epoch: 5| Step: 3
Training loss: 1.8168013095855713
Validation loss: 2.1094614382713073

Epoch: 5| Step: 4
Training loss: 1.5465917587280273
Validation loss: 2.112877566327331

Epoch: 5| Step: 5
Training loss: 1.9072504043579102
Validation loss: 2.0939654252862416

Epoch: 5| Step: 6
Training loss: 2.6066784858703613
Validation loss: 2.1278919225097983

Epoch: 5| Step: 7
Training loss: 1.8627212047576904
Validation loss: 2.1170275877880793

Epoch: 5| Step: 8
Training loss: 2.0837349891662598
Validation loss: 2.12100814747554

Epoch: 5| Step: 9
Training loss: 1.8038192987442017
Validation loss: 2.1402769806564494

Epoch: 5| Step: 10
Training loss: 3.106123924255371
Validation loss: 2.1107427432972896

Epoch: 166| Step: 0
Training loss: 1.8773008584976196
Validation loss: 2.1150515246134933

Epoch: 5| Step: 1
Training loss: 1.945855736732483
Validation loss: 2.077475422172136

Epoch: 5| Step: 2
Training loss: 1.1429774761199951
Validation loss: 2.134726542298512

Epoch: 5| Step: 3
Training loss: 2.506685972213745
Validation loss: 2.084424473906076

Epoch: 5| Step: 4
Training loss: 2.2736077308654785
Validation loss: 2.1596898237864175

Epoch: 5| Step: 5
Training loss: 2.1023807525634766
Validation loss: 2.166047047543269

Epoch: 5| Step: 6
Training loss: 2.0166378021240234
Validation loss: 2.157211653647884

Epoch: 5| Step: 7
Training loss: 2.0435543060302734
Validation loss: 2.104166211620454

Epoch: 5| Step: 8
Training loss: 2.7867138385772705
Validation loss: 2.1042577835821334

Epoch: 5| Step: 9
Training loss: 1.7932649850845337
Validation loss: 2.126205152080905

Epoch: 5| Step: 10
Training loss: 1.6628838777542114
Validation loss: 2.1564191541364117

Epoch: 167| Step: 0
Training loss: 1.9931347370147705
Validation loss: 2.112406906261239

Epoch: 5| Step: 1
Training loss: 2.581341505050659
Validation loss: 2.1073600745970205

Epoch: 5| Step: 2
Training loss: 1.5202510356903076
Validation loss: 2.115889069854572

Epoch: 5| Step: 3
Training loss: 2.990766763687134
Validation loss: 2.12107765546409

Epoch: 5| Step: 4
Training loss: 2.649446964263916
Validation loss: 2.1622753322765393

Epoch: 5| Step: 5
Training loss: 1.3268760442733765
Validation loss: 2.100873489533701

Epoch: 5| Step: 6
Training loss: 2.2003657817840576
Validation loss: 2.1318666037692817

Epoch: 5| Step: 7
Training loss: 1.6362863779067993
Validation loss: 2.1363147407449703

Epoch: 5| Step: 8
Training loss: 1.800458550453186
Validation loss: 2.1130568570988153

Epoch: 5| Step: 9
Training loss: 1.4395010471343994
Validation loss: 2.117464565461682

Epoch: 5| Step: 10
Training loss: 2.0630810260772705
Validation loss: 2.0894384666155745

Epoch: 168| Step: 0
Training loss: 1.7326406240463257
Validation loss: 2.1159348974945726

Epoch: 5| Step: 1
Training loss: 1.9523359537124634
Validation loss: 2.1403925072762275

Epoch: 5| Step: 2
Training loss: 1.4613862037658691
Validation loss: 2.11472503600582

Epoch: 5| Step: 3
Training loss: 2.2930221557617188
Validation loss: 2.1389770815449376

Epoch: 5| Step: 4
Training loss: 2.934852123260498
Validation loss: 2.1296198752618607

Epoch: 5| Step: 5
Training loss: 1.5433323383331299
Validation loss: 2.11969579163418

Epoch: 5| Step: 6
Training loss: 1.9933297634124756
Validation loss: 2.1353090860510386

Epoch: 5| Step: 7
Training loss: 2.4048266410827637
Validation loss: 2.089970560484035

Epoch: 5| Step: 8
Training loss: 2.8330159187316895
Validation loss: 2.1616953906192573

Epoch: 5| Step: 9
Training loss: 1.5686639547348022
Validation loss: 2.1547954159398235

Epoch: 5| Step: 10
Training loss: 1.3216583728790283
Validation loss: 2.1338435116634575

Epoch: 169| Step: 0
Training loss: 1.7296549081802368
Validation loss: 2.1343776000443326

Epoch: 5| Step: 1
Training loss: 2.029083728790283
Validation loss: 2.165116099901097

Epoch: 5| Step: 2
Training loss: 2.2631096839904785
Validation loss: 2.1070760706419587

Epoch: 5| Step: 3
Training loss: 2.2438204288482666
Validation loss: 2.152457860208327

Epoch: 5| Step: 4
Training loss: 1.9852657318115234
Validation loss: 2.123351158634309

Epoch: 5| Step: 5
Training loss: 1.7381820678710938
Validation loss: 2.1362423948062363

Epoch: 5| Step: 6
Training loss: 1.9376739263534546
Validation loss: 2.1183399974658923

Epoch: 5| Step: 7
Training loss: 2.007601499557495
Validation loss: 2.1232235072761454

Epoch: 5| Step: 8
Training loss: 2.1406877040863037
Validation loss: 2.098760551021945

Epoch: 5| Step: 9
Training loss: 1.9466626644134521
Validation loss: 2.135944720237486

Epoch: 5| Step: 10
Training loss: 2.5378520488739014
Validation loss: 2.0875844981080744

Epoch: 170| Step: 0
Training loss: 2.322282552719116
Validation loss: 2.13965868437162

Epoch: 5| Step: 1
Training loss: 1.861331582069397
Validation loss: 2.116678455824493

Epoch: 5| Step: 2
Training loss: 1.7067382335662842
Validation loss: 2.1115755957941853

Epoch: 5| Step: 3
Training loss: 1.8712966442108154
Validation loss: 2.1348246733347573

Epoch: 5| Step: 4
Training loss: 2.849827289581299
Validation loss: 2.1168856659243183

Epoch: 5| Step: 5
Training loss: 2.025447368621826
Validation loss: 2.139626767045708

Epoch: 5| Step: 6
Training loss: 1.9163999557495117
Validation loss: 2.1208569772781862

Epoch: 5| Step: 7
Training loss: 1.575150966644287
Validation loss: 2.1757643145899617

Epoch: 5| Step: 8
Training loss: 2.086880683898926
Validation loss: 2.1020307899803243

Epoch: 5| Step: 9
Training loss: 1.7483069896697998
Validation loss: 2.116198300033487

Epoch: 5| Step: 10
Training loss: 1.923277497291565
Validation loss: 2.12395586762377

Epoch: 171| Step: 0
Training loss: 2.2318761348724365
Validation loss: 2.1300545405316096

Epoch: 5| Step: 1
Training loss: 2.029508113861084
Validation loss: 2.165423268912941

Epoch: 5| Step: 2
Training loss: 1.9350475072860718
Validation loss: 2.136835385394353

Epoch: 5| Step: 3
Training loss: 1.5965585708618164
Validation loss: 2.088855119161708

Epoch: 5| Step: 4
Training loss: 2.379084825515747
Validation loss: 2.0990856975637455

Epoch: 5| Step: 5
Training loss: 2.3461241722106934
Validation loss: 2.1187602730207544

Epoch: 5| Step: 6
Training loss: 1.7663764953613281
Validation loss: 2.159116937268165

Epoch: 5| Step: 7
Training loss: 2.3657374382019043
Validation loss: 2.162859275776853

Epoch: 5| Step: 8
Training loss: 2.0695152282714844
Validation loss: 2.0927485086584605

Epoch: 5| Step: 9
Training loss: 1.6697975397109985
Validation loss: 2.1134457280558925

Epoch: 5| Step: 10
Training loss: 1.7180861234664917
Validation loss: 2.099650970069311

Epoch: 172| Step: 0
Training loss: 1.9877620935440063
Validation loss: 2.1069484782475296

Epoch: 5| Step: 1
Training loss: 1.7696088552474976
Validation loss: 2.1115219029047156

Epoch: 5| Step: 2
Training loss: 1.7467453479766846
Validation loss: 2.1097859182665424

Epoch: 5| Step: 3
Training loss: 1.8601200580596924
Validation loss: 2.110786609752204

Epoch: 5| Step: 4
Training loss: 2.16257381439209
Validation loss: 2.1368186268755185

Epoch: 5| Step: 5
Training loss: 2.2943484783172607
Validation loss: 2.1495619922555904

Epoch: 5| Step: 6
Training loss: 2.1223273277282715
Validation loss: 2.096471384007444

Epoch: 5| Step: 7
Training loss: 2.202455520629883
Validation loss: 2.128032753544469

Epoch: 5| Step: 8
Training loss: 1.8920122385025024
Validation loss: 2.132500879226192

Epoch: 5| Step: 9
Training loss: 1.7524385452270508
Validation loss: 2.074941071130896

Epoch: 5| Step: 10
Training loss: 2.4167799949645996
Validation loss: 2.135058379942371

Epoch: 173| Step: 0
Training loss: 1.9793965816497803
Validation loss: 2.081313504967638

Epoch: 5| Step: 1
Training loss: 2.0765490531921387
Validation loss: 2.1331027553927515

Epoch: 5| Step: 2
Training loss: 1.981682538986206
Validation loss: 2.130630070163358

Epoch: 5| Step: 3
Training loss: 1.7340242862701416
Validation loss: 2.1264920273134784

Epoch: 5| Step: 4
Training loss: 2.1797914505004883
Validation loss: 2.1153657128733974

Epoch: 5| Step: 5
Training loss: 2.5843844413757324
Validation loss: 2.094906727472941

Epoch: 5| Step: 6
Training loss: 1.355141282081604
Validation loss: 2.149377114029341

Epoch: 5| Step: 7
Training loss: 2.0246570110321045
Validation loss: 2.135897892777638

Epoch: 5| Step: 8
Training loss: 2.2421274185180664
Validation loss: 2.1316079221745974

Epoch: 5| Step: 9
Training loss: 2.0596365928649902
Validation loss: 2.094140278395786

Epoch: 5| Step: 10
Training loss: 1.8445327281951904
Validation loss: 2.1722187585728143

Epoch: 174| Step: 0
Training loss: 2.0296835899353027
Validation loss: 2.1297032243462017

Epoch: 5| Step: 1
Training loss: 1.781760573387146
Validation loss: 2.131327175324963

Epoch: 5| Step: 2
Training loss: 2.0988948345184326
Validation loss: 2.152336758951987

Epoch: 5| Step: 3
Training loss: 1.5674586296081543
Validation loss: 2.1291201576109855

Epoch: 5| Step: 4
Training loss: 2.6764743328094482
Validation loss: 2.1018134470908874

Epoch: 5| Step: 5
Training loss: 2.018554210662842
Validation loss: 2.132080375507314

Epoch: 5| Step: 6
Training loss: 1.7317121028900146
Validation loss: 2.1420093300522014

Epoch: 5| Step: 7
Training loss: 1.8892170190811157
Validation loss: 2.1298830765549854

Epoch: 5| Step: 8
Training loss: 1.9728920459747314
Validation loss: 2.098187618358161

Epoch: 5| Step: 9
Training loss: 2.3836541175842285
Validation loss: 2.0882348014462377

Epoch: 5| Step: 10
Training loss: 2.3533666133880615
Validation loss: 2.0915640349029214

Epoch: 175| Step: 0
Training loss: 1.7472015619277954
Validation loss: 2.081245396726875

Epoch: 5| Step: 1
Training loss: 1.4695231914520264
Validation loss: 2.1499810821266583

Epoch: 5| Step: 2
Training loss: 2.4738521575927734
Validation loss: 2.0919829632646296

Epoch: 5| Step: 3
Training loss: 1.5307413339614868
Validation loss: 2.1450120992557977

Epoch: 5| Step: 4
Training loss: 1.8864314556121826
Validation loss: 2.114084771884385

Epoch: 5| Step: 5
Training loss: 2.178285837173462
Validation loss: 2.1012175134433213

Epoch: 5| Step: 6
Training loss: 1.7297292947769165
Validation loss: 2.1331701740141837

Epoch: 5| Step: 7
Training loss: 1.8982480764389038
Validation loss: 2.107097916705634

Epoch: 5| Step: 8
Training loss: 2.640169143676758
Validation loss: 2.1530254822905346

Epoch: 5| Step: 9
Training loss: 2.38459849357605
Validation loss: 2.0992192324771675

Epoch: 5| Step: 10
Training loss: 1.9057886600494385
Validation loss: 2.084425475007744

Epoch: 176| Step: 0
Training loss: 1.5645484924316406
Validation loss: 2.104872329260713

Epoch: 5| Step: 1
Training loss: 2.2498717308044434
Validation loss: 2.094004882279263

Epoch: 5| Step: 2
Training loss: 1.6867717504501343
Validation loss: 2.129118903990715

Epoch: 5| Step: 3
Training loss: 1.4538630247116089
Validation loss: 2.0715236997091644

Epoch: 5| Step: 4
Training loss: 2.396544933319092
Validation loss: 2.124166464292875

Epoch: 5| Step: 5
Training loss: 2.2172203063964844
Validation loss: 2.1126429573182137

Epoch: 5| Step: 6
Training loss: 2.011892080307007
Validation loss: 2.111084395839322

Epoch: 5| Step: 7
Training loss: 2.3262927532196045
Validation loss: 2.0917424899275585

Epoch: 5| Step: 8
Training loss: 2.081864833831787
Validation loss: 2.0953844285780385

Epoch: 5| Step: 9
Training loss: 2.1721320152282715
Validation loss: 2.084834626925889

Epoch: 5| Step: 10
Training loss: 1.6995065212249756
Validation loss: 2.1204951706752984

Epoch: 177| Step: 0
Training loss: 2.029135227203369
Validation loss: 2.095215617969472

Epoch: 5| Step: 1
Training loss: 2.321284532546997
Validation loss: 2.142701354078067

Epoch: 5| Step: 2
Training loss: 2.305845260620117
Validation loss: 2.1155428886413574

Epoch: 5| Step: 3
Training loss: 1.3355579376220703
Validation loss: 2.109223452947473

Epoch: 5| Step: 4
Training loss: 1.72149658203125
Validation loss: 2.1080324701083604

Epoch: 5| Step: 5
Training loss: 1.7393834590911865
Validation loss: 2.1017099939366823

Epoch: 5| Step: 6
Training loss: 2.374361276626587
Validation loss: 2.131806000586479

Epoch: 5| Step: 7
Training loss: 1.4331111907958984
Validation loss: 2.0880722435571815

Epoch: 5| Step: 8
Training loss: 2.92034649848938
Validation loss: 2.091132406265505

Epoch: 5| Step: 9
Training loss: 1.6737598180770874
Validation loss: 2.120698146922614

Epoch: 5| Step: 10
Training loss: 1.9651237726211548
Validation loss: 2.11960889703484

Epoch: 178| Step: 0
Training loss: 2.1057214736938477
Validation loss: 2.159661748075998

Epoch: 5| Step: 1
Training loss: 2.4191699028015137
Validation loss: 2.083831557663538

Epoch: 5| Step: 2
Training loss: 1.364271879196167
Validation loss: 2.1050799098066104

Epoch: 5| Step: 3
Training loss: 2.2200045585632324
Validation loss: 2.133661634178572

Epoch: 5| Step: 4
Training loss: 2.3228421211242676
Validation loss: 2.0901444983738724

Epoch: 5| Step: 5
Training loss: 1.8788840770721436
Validation loss: 2.0908771291855843

Epoch: 5| Step: 6
Training loss: 2.403266429901123
Validation loss: 2.1030886109157274

Epoch: 5| Step: 7
Training loss: 1.7729415893554688
Validation loss: 2.112529198328654

Epoch: 5| Step: 8
Training loss: 1.8638986349105835
Validation loss: 2.128077153236635

Epoch: 5| Step: 9
Training loss: 1.809918999671936
Validation loss: 2.125802037536457

Epoch: 5| Step: 10
Training loss: 1.791364073753357
Validation loss: 2.1564147959473314

Epoch: 179| Step: 0
Training loss: 1.325158715248108
Validation loss: 2.149037027871737

Epoch: 5| Step: 1
Training loss: 1.6073341369628906
Validation loss: 2.107918591909511

Epoch: 5| Step: 2
Training loss: 2.358168125152588
Validation loss: 2.135873791992023

Epoch: 5| Step: 3
Training loss: 1.7303050756454468
Validation loss: 2.124364601668491

Epoch: 5| Step: 4
Training loss: 1.7586097717285156
Validation loss: 2.1223968036713137

Epoch: 5| Step: 5
Training loss: 2.329505205154419
Validation loss: 2.1468896186479958

Epoch: 5| Step: 6
Training loss: 2.126936912536621
Validation loss: 2.089687648639884

Epoch: 5| Step: 7
Training loss: 2.1751089096069336
Validation loss: 2.124128592911587

Epoch: 5| Step: 8
Training loss: 1.5539026260375977
Validation loss: 2.059837718163767

Epoch: 5| Step: 9
Training loss: 3.004471778869629
Validation loss: 2.05833371608488

Epoch: 5| Step: 10
Training loss: 1.9165056943893433
Validation loss: 2.1328038400219334

Epoch: 180| Step: 0
Training loss: 1.942803144454956
Validation loss: 2.101239497943591

Epoch: 5| Step: 1
Training loss: 2.121274471282959
Validation loss: 2.122287683589484

Epoch: 5| Step: 2
Training loss: 2.419074296951294
Validation loss: 2.0757513597447383

Epoch: 5| Step: 3
Training loss: 2.2078258991241455
Validation loss: 2.093426271151471

Epoch: 5| Step: 4
Training loss: 1.7896579504013062
Validation loss: 2.0479163841534684

Epoch: 5| Step: 5
Training loss: 2.10312819480896
Validation loss: 2.051545668673772

Epoch: 5| Step: 6
Training loss: 1.4973433017730713
Validation loss: 2.086421858879828

Epoch: 5| Step: 7
Training loss: 2.233330249786377
Validation loss: 2.0858586654868176

Epoch: 5| Step: 8
Training loss: 2.0448391437530518
Validation loss: 2.08220088097357

Epoch: 5| Step: 9
Training loss: 1.6609147787094116
Validation loss: 2.0864089663310716

Epoch: 5| Step: 10
Training loss: 1.8867075443267822
Validation loss: 2.148193695211923

Epoch: 181| Step: 0
Training loss: 2.0449652671813965
Validation loss: 2.097157383477816

Epoch: 5| Step: 1
Training loss: 1.4956997632980347
Validation loss: 2.1580293396467805

Epoch: 5| Step: 2
Training loss: 1.844255805015564
Validation loss: 2.148323825610581

Epoch: 5| Step: 3
Training loss: 2.569420576095581
Validation loss: 2.093916393095447

Epoch: 5| Step: 4
Training loss: 1.8112308979034424
Validation loss: 2.1160012214414534

Epoch: 5| Step: 5
Training loss: 1.7988183498382568
Validation loss: 2.0856024065325336

Epoch: 5| Step: 6
Training loss: 1.9497207403182983
Validation loss: 2.1468214168343493

Epoch: 5| Step: 7
Training loss: 1.7476199865341187
Validation loss: 2.1238449850390033

Epoch: 5| Step: 8
Training loss: 2.6450791358947754
Validation loss: 2.1375635772623043

Epoch: 5| Step: 9
Training loss: 1.415083885192871
Validation loss: 2.1001362441688456

Epoch: 5| Step: 10
Training loss: 2.7454962730407715
Validation loss: 2.0911532114910822

Epoch: 182| Step: 0
Training loss: 2.695525884628296
Validation loss: 2.1120285782762753

Epoch: 5| Step: 1
Training loss: 1.7823587656021118
Validation loss: 2.125253455613249

Epoch: 5| Step: 2
Training loss: 1.9025558233261108
Validation loss: 2.101978709620814

Epoch: 5| Step: 3
Training loss: 2.0067975521087646
Validation loss: 2.1302713322383102

Epoch: 5| Step: 4
Training loss: 2.418147087097168
Validation loss: 2.168765216745356

Epoch: 5| Step: 5
Training loss: 1.5278629064559937
Validation loss: 2.1049850794576828

Epoch: 5| Step: 6
Training loss: 2.0440890789031982
Validation loss: 2.1035885144305486

Epoch: 5| Step: 7
Training loss: 2.314990282058716
Validation loss: 2.149757856963783

Epoch: 5| Step: 8
Training loss: 1.5637179613113403
Validation loss: 2.133789321427704

Epoch: 5| Step: 9
Training loss: 1.947180151939392
Validation loss: 2.101887397868659

Epoch: 5| Step: 10
Training loss: 1.943218469619751
Validation loss: 2.1306866215121363

Epoch: 183| Step: 0
Training loss: 1.8794336318969727
Validation loss: 2.0830540080224313

Epoch: 5| Step: 1
Training loss: 1.7282750606536865
Validation loss: 2.0721014417627805

Epoch: 5| Step: 2
Training loss: 1.5188572406768799
Validation loss: 2.0762318552181287

Epoch: 5| Step: 3
Training loss: 2.6888632774353027
Validation loss: 2.0533920846959597

Epoch: 5| Step: 4
Training loss: 1.7104170322418213
Validation loss: 2.1163833115690496

Epoch: 5| Step: 5
Training loss: 2.0750534534454346
Validation loss: 2.073341026101061

Epoch: 5| Step: 6
Training loss: 2.1931777000427246
Validation loss: 2.0737048451618483

Epoch: 5| Step: 7
Training loss: 2.795170545578003
Validation loss: 2.1290172492304156

Epoch: 5| Step: 8
Training loss: 2.0100748538970947
Validation loss: 2.108951912131361

Epoch: 5| Step: 9
Training loss: 1.688788652420044
Validation loss: 2.0699003152949835

Epoch: 5| Step: 10
Training loss: 1.5175174474716187
Validation loss: 2.022075245457311

Epoch: 184| Step: 0
Training loss: 1.9799655675888062
Validation loss: 2.1098996593106176

Epoch: 5| Step: 1
Training loss: 1.6107534170150757
Validation loss: 2.0741543795472834

Epoch: 5| Step: 2
Training loss: 1.9412486553192139
Validation loss: 2.08792475218414

Epoch: 5| Step: 3
Training loss: 1.9693883657455444
Validation loss: 2.130647897720337

Epoch: 5| Step: 4
Training loss: 1.9049879312515259
Validation loss: 2.0992711667091615

Epoch: 5| Step: 5
Training loss: 1.8365284204483032
Validation loss: 2.058294860265588

Epoch: 5| Step: 6
Training loss: 1.7517588138580322
Validation loss: 2.0959933214290167

Epoch: 5| Step: 7
Training loss: 1.9601671695709229
Validation loss: 2.072509742552234

Epoch: 5| Step: 8
Training loss: 2.3092124462127686
Validation loss: 2.1000279572702225

Epoch: 5| Step: 9
Training loss: 2.447446346282959
Validation loss: 2.08439286293522

Epoch: 5| Step: 10
Training loss: 1.8763829469680786
Validation loss: 2.1143172684536187

Epoch: 185| Step: 0
Training loss: 1.972609281539917
Validation loss: 2.0812749375579176

Epoch: 5| Step: 1
Training loss: 1.7545804977416992
Validation loss: 2.0795139215325795

Epoch: 5| Step: 2
Training loss: 1.8541615009307861
Validation loss: 2.128875950331329

Epoch: 5| Step: 3
Training loss: 2.060415267944336
Validation loss: 2.1271590289249214

Epoch: 5| Step: 4
Training loss: 2.3435676097869873
Validation loss: 2.1197201026383268

Epoch: 5| Step: 5
Training loss: 1.9875043630599976
Validation loss: 2.1287753146181823

Epoch: 5| Step: 6
Training loss: 2.177208423614502
Validation loss: 2.120004577021445

Epoch: 5| Step: 7
Training loss: 2.267927408218384
Validation loss: 2.1247084486869072

Epoch: 5| Step: 8
Training loss: 2.1710715293884277
Validation loss: 2.149369978135632

Epoch: 5| Step: 9
Training loss: 1.584316372871399
Validation loss: 2.089930475399058

Epoch: 5| Step: 10
Training loss: 1.1879148483276367
Validation loss: 2.1190604702118905

Epoch: 186| Step: 0
Training loss: 1.5057951211929321
Validation loss: 2.11387118985576

Epoch: 5| Step: 1
Training loss: 1.8972129821777344
Validation loss: 2.1237401577734176

Epoch: 5| Step: 2
Training loss: 1.912405252456665
Validation loss: 2.0598020656134493

Epoch: 5| Step: 3
Training loss: 1.907335638999939
Validation loss: 2.1185431506044123

Epoch: 5| Step: 4
Training loss: 2.301109552383423
Validation loss: 2.0990980081660773

Epoch: 5| Step: 5
Training loss: 2.339071750640869
Validation loss: 2.0979059357796945

Epoch: 5| Step: 6
Training loss: 2.169177532196045
Validation loss: 2.0923425356547036

Epoch: 5| Step: 7
Training loss: 1.9279413223266602
Validation loss: 2.0780045217083347

Epoch: 5| Step: 8
Training loss: 2.087954044342041
Validation loss: 2.1212912272381526

Epoch: 5| Step: 9
Training loss: 2.3092222213745117
Validation loss: 2.0550780732144593

Epoch: 5| Step: 10
Training loss: 1.3755944967269897
Validation loss: 2.1182747963936097

Epoch: 187| Step: 0
Training loss: 2.44140625
Validation loss: 2.1379026418091147

Epoch: 5| Step: 1
Training loss: 1.9207932949066162
Validation loss: 2.0603510846373854

Epoch: 5| Step: 2
Training loss: 2.057638168334961
Validation loss: 2.1343131321732716

Epoch: 5| Step: 3
Training loss: 2.3905062675476074
Validation loss: 2.1286593803795437

Epoch: 5| Step: 4
Training loss: 2.212902307510376
Validation loss: 2.1144939840480848

Epoch: 5| Step: 5
Training loss: 1.9034423828125
Validation loss: 2.0607844629595355

Epoch: 5| Step: 6
Training loss: 1.465248465538025
Validation loss: 2.095297251978228

Epoch: 5| Step: 7
Training loss: 2.0857787132263184
Validation loss: 2.1097380012594242

Epoch: 5| Step: 8
Training loss: 1.5122339725494385
Validation loss: 2.1248420361549623

Epoch: 5| Step: 9
Training loss: 1.6256755590438843
Validation loss: 2.1192346567748697

Epoch: 5| Step: 10
Training loss: 1.944960594177246
Validation loss: 2.134747584660848

Epoch: 188| Step: 0
Training loss: 2.396710157394409
Validation loss: 2.103607769935362

Epoch: 5| Step: 1
Training loss: 1.6064281463623047
Validation loss: 2.0919505626924577

Epoch: 5| Step: 2
Training loss: 2.1061673164367676
Validation loss: 2.122133049913632

Epoch: 5| Step: 3
Training loss: 1.3885066509246826
Validation loss: 2.1146137637476765

Epoch: 5| Step: 4
Training loss: 1.8411012887954712
Validation loss: 2.1295961026222474

Epoch: 5| Step: 5
Training loss: 2.3910279273986816
Validation loss: 2.1193255839809293

Epoch: 5| Step: 6
Training loss: 2.128221035003662
Validation loss: 2.1072872646393312

Epoch: 5| Step: 7
Training loss: 2.0130975246429443
Validation loss: 2.0885901707474903

Epoch: 5| Step: 8
Training loss: 2.0185799598693848
Validation loss: 2.057128547340311

Epoch: 5| Step: 9
Training loss: 2.108341693878174
Validation loss: 2.061842644086448

Epoch: 5| Step: 10
Training loss: 1.8279690742492676
Validation loss: 2.073801852041675

Epoch: 189| Step: 0
Training loss: 1.7071787118911743
Validation loss: 2.0557915600397254

Epoch: 5| Step: 1
Training loss: 1.5988425016403198
Validation loss: 2.116071493394913

Epoch: 5| Step: 2
Training loss: 1.7235853672027588
Validation loss: 2.09648657614185

Epoch: 5| Step: 3
Training loss: 1.7913949489593506
Validation loss: 2.101280789221487

Epoch: 5| Step: 4
Training loss: 2.6143648624420166
Validation loss: 2.09486747172571

Epoch: 5| Step: 5
Training loss: 2.543160915374756
Validation loss: 2.116046805535593

Epoch: 5| Step: 6
Training loss: 1.8518741130828857
Validation loss: 2.087487700164959

Epoch: 5| Step: 7
Training loss: 1.9069998264312744
Validation loss: 2.0890983894307125

Epoch: 5| Step: 8
Training loss: 2.150177001953125
Validation loss: 2.027445129168931

Epoch: 5| Step: 9
Training loss: 1.6303592920303345
Validation loss: 2.0899368575824204

Epoch: 5| Step: 10
Training loss: 2.0896239280700684
Validation loss: 2.0920489359927434

Epoch: 190| Step: 0
Training loss: 2.2037720680236816
Validation loss: 2.124279660563315

Epoch: 5| Step: 1
Training loss: 1.712080717086792
Validation loss: 2.078995786687379

Epoch: 5| Step: 2
Training loss: 1.867051362991333
Validation loss: 2.0803282504440634

Epoch: 5| Step: 3
Training loss: 2.308422327041626
Validation loss: 2.1004631391135593

Epoch: 5| Step: 4
Training loss: 1.8692893981933594
Validation loss: 2.058657883315958

Epoch: 5| Step: 5
Training loss: 1.966748833656311
Validation loss: 2.0883550297829414

Epoch: 5| Step: 6
Training loss: 2.1401734352111816
Validation loss: 2.098218737110015

Epoch: 5| Step: 7
Training loss: 2.1976799964904785
Validation loss: 2.0958398567732943

Epoch: 5| Step: 8
Training loss: 1.6100507974624634
Validation loss: 2.126655767040868

Epoch: 5| Step: 9
Training loss: 1.8842884302139282
Validation loss: 2.1146474589583693

Epoch: 5| Step: 10
Training loss: 2.2541399002075195
Validation loss: 2.149484029380224

Epoch: 191| Step: 0
Training loss: 2.2834696769714355
Validation loss: 2.1082315906401603

Epoch: 5| Step: 1
Training loss: 2.287611484527588
Validation loss: 2.142205940779819

Epoch: 5| Step: 2
Training loss: 1.950470209121704
Validation loss: 2.1259585926609654

Epoch: 5| Step: 3
Training loss: 1.58982515335083
Validation loss: 2.090078624345923

Epoch: 5| Step: 4
Training loss: 1.3078291416168213
Validation loss: 2.0835756435189197

Epoch: 5| Step: 5
Training loss: 1.6330597400665283
Validation loss: 2.151327056269492

Epoch: 5| Step: 6
Training loss: 1.7539403438568115
Validation loss: 2.1463707493197535

Epoch: 5| Step: 7
Training loss: 2.049252986907959
Validation loss: 2.106687059966467

Epoch: 5| Step: 8
Training loss: 2.6467785835266113
Validation loss: 2.103312970489584

Epoch: 5| Step: 9
Training loss: 2.463671922683716
Validation loss: 2.0649626742127123

Epoch: 5| Step: 10
Training loss: 1.6348440647125244
Validation loss: 2.062715907250681

Epoch: 192| Step: 0
Training loss: 2.3129396438598633
Validation loss: 2.0754410682186

Epoch: 5| Step: 1
Training loss: 2.035956859588623
Validation loss: 2.0778821283771145

Epoch: 5| Step: 2
Training loss: 2.011725902557373
Validation loss: 2.052790173920252

Epoch: 5| Step: 3
Training loss: 1.7695839405059814
Validation loss: 2.0838426364365445

Epoch: 5| Step: 4
Training loss: 2.5855026245117188
Validation loss: 2.08266185175988

Epoch: 5| Step: 5
Training loss: 2.2795968055725098
Validation loss: 2.1234909821582097

Epoch: 5| Step: 6
Training loss: 1.750927209854126
Validation loss: 2.075909132598549

Epoch: 5| Step: 7
Training loss: 1.4306800365447998
Validation loss: 2.0920834387502363

Epoch: 5| Step: 8
Training loss: 1.918708086013794
Validation loss: 2.0995611093377553

Epoch: 5| Step: 9
Training loss: 1.4835026264190674
Validation loss: 2.1017094747994536

Epoch: 5| Step: 10
Training loss: 2.0628342628479004
Validation loss: 2.0969349927799676

Epoch: 193| Step: 0
Training loss: 1.640312910079956
Validation loss: 2.1141453660944456

Epoch: 5| Step: 1
Training loss: 2.431593418121338
Validation loss: 2.132606009001373

Epoch: 5| Step: 2
Training loss: 1.5136381387710571
Validation loss: 2.1044721282938474

Epoch: 5| Step: 3
Training loss: 1.930639624595642
Validation loss: 2.1326792342688448

Epoch: 5| Step: 4
Training loss: 2.1460986137390137
Validation loss: 2.0609920947782454

Epoch: 5| Step: 5
Training loss: 2.1036887168884277
Validation loss: 2.1102130951419955

Epoch: 5| Step: 6
Training loss: 2.0472218990325928
Validation loss: 2.073571376903083

Epoch: 5| Step: 7
Training loss: 1.2432048320770264
Validation loss: 2.0919760375894527

Epoch: 5| Step: 8
Training loss: 1.8934752941131592
Validation loss: 2.103420442150485

Epoch: 5| Step: 9
Training loss: 2.472468852996826
Validation loss: 2.1109294327356483

Epoch: 5| Step: 10
Training loss: 1.9811434745788574
Validation loss: 2.1038320987455306

Epoch: 194| Step: 0
Training loss: 1.8283240795135498
Validation loss: 2.147215658618558

Epoch: 5| Step: 1
Training loss: 1.9947162866592407
Validation loss: 2.1075507338329027

Epoch: 5| Step: 2
Training loss: 1.6210060119628906
Validation loss: 2.093291485181419

Epoch: 5| Step: 3
Training loss: 1.625187635421753
Validation loss: 2.082156623563459

Epoch: 5| Step: 4
Training loss: 1.7335264682769775
Validation loss: 2.0952305896307832

Epoch: 5| Step: 5
Training loss: 1.8120324611663818
Validation loss: 2.043949968071394

Epoch: 5| Step: 6
Training loss: 1.8666622638702393
Validation loss: 2.082179334855849

Epoch: 5| Step: 7
Training loss: 1.920279860496521
Validation loss: 2.065954339119696

Epoch: 5| Step: 8
Training loss: 2.1305432319641113
Validation loss: 2.078737662684533

Epoch: 5| Step: 9
Training loss: 2.3783888816833496
Validation loss: 2.0652458770300752

Epoch: 5| Step: 10
Training loss: 2.0118556022644043
Validation loss: 2.050027593489616

Epoch: 195| Step: 0
Training loss: 1.3674747943878174
Validation loss: 2.0550969416095364

Epoch: 5| Step: 1
Training loss: 2.3815064430236816
Validation loss: 2.065310906338435

Epoch: 5| Step: 2
Training loss: 1.878626823425293
Validation loss: 2.0772462698721115

Epoch: 5| Step: 3
Training loss: 1.8494971990585327
Validation loss: 2.029744279000067

Epoch: 5| Step: 4
Training loss: 2.12913179397583
Validation loss: 2.091136404263076

Epoch: 5| Step: 5
Training loss: 1.6582359075546265
Validation loss: 2.1128763357798257

Epoch: 5| Step: 6
Training loss: 2.668151378631592
Validation loss: 2.055542166515063

Epoch: 5| Step: 7
Training loss: 1.8209617137908936
Validation loss: 2.0986204865158244

Epoch: 5| Step: 8
Training loss: 2.3726682662963867
Validation loss: 2.1128394526820027

Epoch: 5| Step: 9
Training loss: 1.9762678146362305
Validation loss: 2.0909858672849593

Epoch: 5| Step: 10
Training loss: 1.0398648977279663
Validation loss: 2.078151102988951

Epoch: 196| Step: 0
Training loss: 2.033215045928955
Validation loss: 2.132315330607917

Epoch: 5| Step: 1
Training loss: 0.9431592226028442
Validation loss: 2.0836284622069328

Epoch: 5| Step: 2
Training loss: 1.6767076253890991
Validation loss: 2.0865099455720637

Epoch: 5| Step: 3
Training loss: 2.588765859603882
Validation loss: 2.1369907035622546

Epoch: 5| Step: 4
Training loss: 2.3817031383514404
Validation loss: 2.0852482113786923

Epoch: 5| Step: 5
Training loss: 2.111293077468872
Validation loss: 2.034953368607388

Epoch: 5| Step: 6
Training loss: 2.171355724334717
Validation loss: 2.0849787983843076

Epoch: 5| Step: 7
Training loss: 1.3844339847564697
Validation loss: 2.095420027291903

Epoch: 5| Step: 8
Training loss: 2.2491631507873535
Validation loss: 2.116011716986215

Epoch: 5| Step: 9
Training loss: 1.7719652652740479
Validation loss: 2.090631467039867

Epoch: 5| Step: 10
Training loss: 1.9155598878860474
Validation loss: 2.1118128773986653

Epoch: 197| Step: 0
Training loss: 1.6683229207992554
Validation loss: 2.1035268614369054

Epoch: 5| Step: 1
Training loss: 1.4934656620025635
Validation loss: 2.0951057813500844

Epoch: 5| Step: 2
Training loss: 1.6464602947235107
Validation loss: 2.0901433037173365

Epoch: 5| Step: 3
Training loss: 1.8336589336395264
Validation loss: 2.0571081330699306

Epoch: 5| Step: 4
Training loss: 2.1791133880615234
Validation loss: 2.1177825133005777

Epoch: 5| Step: 5
Training loss: 2.3326022624969482
Validation loss: 2.0487476036112797

Epoch: 5| Step: 6
Training loss: 2.0138449668884277
Validation loss: 2.088246173756097

Epoch: 5| Step: 7
Training loss: 2.220642566680908
Validation loss: 2.0455701210165538

Epoch: 5| Step: 8
Training loss: 2.61932110786438
Validation loss: 2.0541834600510134

Epoch: 5| Step: 9
Training loss: 1.1201890707015991
Validation loss: 2.103278870223671

Epoch: 5| Step: 10
Training loss: 1.761505126953125
Validation loss: 2.093157943858895

Epoch: 198| Step: 0
Training loss: 1.9636306762695312
Validation loss: 2.1251494602490495

Epoch: 5| Step: 1
Training loss: 1.8061294555664062
Validation loss: 2.0705898141348236

Epoch: 5| Step: 2
Training loss: 1.6523364782333374
Validation loss: 2.0836680102091965

Epoch: 5| Step: 3
Training loss: 2.003105640411377
Validation loss: 2.0910678935307327

Epoch: 5| Step: 4
Training loss: 2.0995101928710938
Validation loss: 2.1026612148490003

Epoch: 5| Step: 5
Training loss: 1.9665939807891846
Validation loss: 2.086502400777673

Epoch: 5| Step: 6
Training loss: 1.952951431274414
Validation loss: 2.051560212207097

Epoch: 5| Step: 7
Training loss: 2.408332347869873
Validation loss: 2.0842125838802708

Epoch: 5| Step: 8
Training loss: 1.9605286121368408
Validation loss: 2.1058792760295253

Epoch: 5| Step: 9
Training loss: 1.4720287322998047
Validation loss: 2.067222092741279

Epoch: 5| Step: 10
Training loss: 1.752837061882019
Validation loss: 2.078886729414745

Epoch: 199| Step: 0
Training loss: 1.456897497177124
Validation loss: 2.0930731681085404

Epoch: 5| Step: 1
Training loss: 1.6851228475570679
Validation loss: 2.0842628338003673

Epoch: 5| Step: 2
Training loss: 2.6556849479675293
Validation loss: 2.071313255576677

Epoch: 5| Step: 3
Training loss: 2.653759479522705
Validation loss: 2.1114039036535446

Epoch: 5| Step: 4
Training loss: 2.5032100677490234
Validation loss: 2.025219794242613

Epoch: 5| Step: 5
Training loss: 2.0736663341522217
Validation loss: 2.0664201244231193

Epoch: 5| Step: 6
Training loss: 1.8666175603866577
Validation loss: 2.054461253586636

Epoch: 5| Step: 7
Training loss: 1.3450579643249512
Validation loss: 2.0979197563663607

Epoch: 5| Step: 8
Training loss: 1.7846298217773438
Validation loss: 2.072168873202416

Epoch: 5| Step: 9
Training loss: 1.9377849102020264
Validation loss: 2.048902161659733

Epoch: 5| Step: 10
Training loss: 1.5901963710784912
Validation loss: 2.1077239282669558

Epoch: 200| Step: 0
Training loss: 1.6249479055404663
Validation loss: 2.089971419303648

Epoch: 5| Step: 1
Training loss: 2.367621898651123
Validation loss: 2.126511045681533

Epoch: 5| Step: 2
Training loss: 1.5044453144073486
Validation loss: 2.08875435526653

Epoch: 5| Step: 3
Training loss: 1.9812501668930054
Validation loss: 2.1043404815017537

Epoch: 5| Step: 4
Training loss: 2.3674557209014893
Validation loss: 2.0565363745535574

Epoch: 5| Step: 5
Training loss: 1.1441526412963867
Validation loss: 2.08622682222756

Epoch: 5| Step: 6
Training loss: 2.358720302581787
Validation loss: 2.0751777823253343

Epoch: 5| Step: 7
Training loss: 1.887211561203003
Validation loss: 2.1027982170863817

Epoch: 5| Step: 8
Training loss: 1.7883625030517578
Validation loss: 2.0402267197126984

Epoch: 5| Step: 9
Training loss: 1.701107382774353
Validation loss: 2.0748142875650877

Epoch: 5| Step: 10
Training loss: 2.665184259414673
Validation loss: 2.0471882820129395

Epoch: 201| Step: 0
Training loss: 1.967431664466858
Validation loss: 2.114618965374526

Epoch: 5| Step: 1
Training loss: 1.457658290863037
Validation loss: 2.079962779116887

Epoch: 5| Step: 2
Training loss: 1.994652509689331
Validation loss: 2.0462479104277906

Epoch: 5| Step: 3
Training loss: 2.7350738048553467
Validation loss: 2.140640131888851

Epoch: 5| Step: 4
Training loss: 1.751247763633728
Validation loss: 2.0811120130682506

Epoch: 5| Step: 5
Training loss: 2.0904629230499268
Validation loss: 2.0919387750728156

Epoch: 5| Step: 6
Training loss: 1.6527740955352783
Validation loss: 2.0596811335573912

Epoch: 5| Step: 7
Training loss: 1.7816082239151
Validation loss: 2.074195465733928

Epoch: 5| Step: 8
Training loss: 2.049424171447754
Validation loss: 2.1036081519178165

Epoch: 5| Step: 9
Training loss: 1.4674994945526123
Validation loss: 2.0403687454039052

Epoch: 5| Step: 10
Training loss: 1.7168185710906982
Validation loss: 2.084600317862726

Epoch: 202| Step: 0
Training loss: 1.3854334354400635
Validation loss: 2.1168100590346963

Epoch: 5| Step: 1
Training loss: 2.7316393852233887
Validation loss: 2.109200075108518

Epoch: 5| Step: 2
Training loss: 2.4642043113708496
Validation loss: 2.0763873977045857

Epoch: 5| Step: 3
Training loss: 1.7666635513305664
Validation loss: 2.107178326575987

Epoch: 5| Step: 4
Training loss: 0.8889700174331665
Validation loss: 2.1210880920451176

Epoch: 5| Step: 5
Training loss: 1.8625322580337524
Validation loss: 2.080349096687891

Epoch: 5| Step: 6
Training loss: 1.5349451303482056
Validation loss: 2.0922302225584626

Epoch: 5| Step: 7
Training loss: 2.0510551929473877
Validation loss: 2.0943865596607165

Epoch: 5| Step: 8
Training loss: 2.058586835861206
Validation loss: 2.108122137925958

Epoch: 5| Step: 9
Training loss: 2.239755392074585
Validation loss: 2.089835093867394

Epoch: 5| Step: 10
Training loss: 1.8319172859191895
Validation loss: 2.0767923785794165

Epoch: 203| Step: 0
Training loss: 2.6072871685028076
Validation loss: 2.0930362491197485

Epoch: 5| Step: 1
Training loss: 2.1433844566345215
Validation loss: 2.08471014166391

Epoch: 5| Step: 2
Training loss: 2.1813430786132812
Validation loss: 2.0853546665560816

Epoch: 5| Step: 3
Training loss: 1.7349967956542969
Validation loss: 2.118495502779561

Epoch: 5| Step: 4
Training loss: 2.100358247756958
Validation loss: 2.142141934364073

Epoch: 5| Step: 5
Training loss: 2.2963924407958984
Validation loss: 2.0683769090201265

Epoch: 5| Step: 6
Training loss: 1.3547542095184326
Validation loss: 2.078624230559154

Epoch: 5| Step: 7
Training loss: 1.9860643148422241
Validation loss: 2.1434703244957873

Epoch: 5| Step: 8
Training loss: 1.8462880849838257
Validation loss: 2.0606735291019564

Epoch: 5| Step: 9
Training loss: 1.3156261444091797
Validation loss: 2.0765182561771844

Epoch: 5| Step: 10
Training loss: 1.2476893663406372
Validation loss: 2.0653831394769813

Epoch: 204| Step: 0
Training loss: 1.3271759748458862
Validation loss: 2.0664908706500964

Epoch: 5| Step: 1
Training loss: 2.4154553413391113
Validation loss: 2.022827814984065

Epoch: 5| Step: 2
Training loss: 1.8060916662216187
Validation loss: 2.0561599936536563

Epoch: 5| Step: 3
Training loss: 1.8118455410003662
Validation loss: 2.092684374060682

Epoch: 5| Step: 4
Training loss: 2.2575619220733643
Validation loss: 2.0610669377029582

Epoch: 5| Step: 5
Training loss: 1.726618766784668
Validation loss: 2.0817377426291026

Epoch: 5| Step: 6
Training loss: 1.5317262411117554
Validation loss: 2.0686561971582393

Epoch: 5| Step: 7
Training loss: 1.6798620223999023
Validation loss: 2.038566558591781

Epoch: 5| Step: 8
Training loss: 2.458296298980713
Validation loss: 2.057196447926183

Epoch: 5| Step: 9
Training loss: 2.336869478225708
Validation loss: 2.045940440188172

Epoch: 5| Step: 10
Training loss: 1.4508174657821655
Validation loss: 2.0715412619293376

Epoch: 205| Step: 0
Training loss: 1.483829379081726
Validation loss: 2.0447271447027884

Epoch: 5| Step: 1
Training loss: 2.107084274291992
Validation loss: 2.0555999150840183

Epoch: 5| Step: 2
Training loss: 1.7847356796264648
Validation loss: 2.086089439289544

Epoch: 5| Step: 3
Training loss: 2.751038074493408
Validation loss: 2.110660129977811

Epoch: 5| Step: 4
Training loss: 1.7467139959335327
Validation loss: 2.081398520418393

Epoch: 5| Step: 5
Training loss: 1.7445266246795654
Validation loss: 2.0232583245923443

Epoch: 5| Step: 6
Training loss: 1.864344596862793
Validation loss: 2.0809827953256588

Epoch: 5| Step: 7
Training loss: 1.5178252458572388
Validation loss: 2.087982846844581

Epoch: 5| Step: 8
Training loss: 1.9774526357650757
Validation loss: 2.0436099562593686

Epoch: 5| Step: 9
Training loss: 2.2613818645477295
Validation loss: 2.0783814640455347

Epoch: 5| Step: 10
Training loss: 1.8621056079864502
Validation loss: 2.0802458460612963

Epoch: 206| Step: 0
Training loss: 2.311494827270508
Validation loss: 2.125528040752616

Epoch: 5| Step: 1
Training loss: 1.7029682397842407
Validation loss: 2.108066569092453

Epoch: 5| Step: 2
Training loss: 1.9720659255981445
Validation loss: 2.0677539558820826

Epoch: 5| Step: 3
Training loss: 1.9684921503067017
Validation loss: 2.0791841219830256

Epoch: 5| Step: 4
Training loss: 1.917535424232483
Validation loss: 2.057875492239511

Epoch: 5| Step: 5
Training loss: 2.227881908416748
Validation loss: 2.096790458566399

Epoch: 5| Step: 6
Training loss: 1.4979970455169678
Validation loss: 2.0743830627010715

Epoch: 5| Step: 7
Training loss: 1.6274572610855103
Validation loss: 2.0918740854468396

Epoch: 5| Step: 8
Training loss: 1.9701522588729858
Validation loss: 2.0790337567688315

Epoch: 5| Step: 9
Training loss: 1.8929023742675781
Validation loss: 2.0893705250114523

Epoch: 5| Step: 10
Training loss: 1.9784187078475952
Validation loss: 2.0747306680166595

Epoch: 207| Step: 0
Training loss: 2.536566734313965
Validation loss: 2.058264240141838

Epoch: 5| Step: 1
Training loss: 2.8231799602508545
Validation loss: 2.043426470089984

Epoch: 5| Step: 2
Training loss: 2.063904285430908
Validation loss: 2.1013735032850698

Epoch: 5| Step: 3
Training loss: 1.225974440574646
Validation loss: 2.108258528094138

Epoch: 5| Step: 4
Training loss: 1.4598969221115112
Validation loss: 2.0709635801212762

Epoch: 5| Step: 5
Training loss: 1.45357084274292
Validation loss: 2.029144287109375

Epoch: 5| Step: 6
Training loss: 1.6459472179412842
Validation loss: 2.099229899785852

Epoch: 5| Step: 7
Training loss: 1.4503369331359863
Validation loss: 2.081999303192221

Epoch: 5| Step: 8
Training loss: 1.4471886157989502
Validation loss: 2.14327775022035

Epoch: 5| Step: 9
Training loss: 2.2112269401550293
Validation loss: 2.0261197602877052

Epoch: 5| Step: 10
Training loss: 2.288905620574951
Validation loss: 2.0404283667123444

Epoch: 208| Step: 0
Training loss: 2.0793821811676025
Validation loss: 2.081052582751038

Epoch: 5| Step: 1
Training loss: 1.602594017982483
Validation loss: 2.1192145424504436

Epoch: 5| Step: 2
Training loss: 1.8887907266616821
Validation loss: 2.0813760462627617

Epoch: 5| Step: 3
Training loss: 1.8255218267440796
Validation loss: 2.053628126780192

Epoch: 5| Step: 4
Training loss: 1.8662294149398804
Validation loss: 2.0789956764508317

Epoch: 5| Step: 5
Training loss: 1.7513021230697632
Validation loss: 2.1098538342342583

Epoch: 5| Step: 6
Training loss: 1.4940444231033325
Validation loss: 2.08864640292301

Epoch: 5| Step: 7
Training loss: 2.0963127613067627
Validation loss: 2.0785744446580128

Epoch: 5| Step: 8
Training loss: 1.9329570531845093
Validation loss: 2.052236580079602

Epoch: 5| Step: 9
Training loss: 2.242147207260132
Validation loss: 2.1354486878200243

Epoch: 5| Step: 10
Training loss: 2.1884171962738037
Validation loss: 2.0620248702264603

Epoch: 209| Step: 0
Training loss: 1.6685807704925537
Validation loss: 2.0493818880409322

Epoch: 5| Step: 1
Training loss: 2.663996934890747
Validation loss: 2.0352579944877216

Epoch: 5| Step: 2
Training loss: 2.0506093502044678
Validation loss: 2.078719501854271

Epoch: 5| Step: 3
Training loss: 1.8582645654678345
Validation loss: 2.0952635170311056

Epoch: 5| Step: 4
Training loss: 1.9408495426177979
Validation loss: 2.0608188285622546

Epoch: 5| Step: 5
Training loss: 2.0482211112976074
Validation loss: 2.05179282798562

Epoch: 5| Step: 6
Training loss: 1.5483487844467163
Validation loss: 2.0561772443914927

Epoch: 5| Step: 7
Training loss: 1.902022123336792
Validation loss: 2.087362600911048

Epoch: 5| Step: 8
Training loss: 1.5103548765182495
Validation loss: 2.07506194678686

Epoch: 5| Step: 9
Training loss: 2.0976500511169434
Validation loss: 2.096694148996825

Epoch: 5| Step: 10
Training loss: 1.587450385093689
Validation loss: 2.138442773972788

Epoch: 210| Step: 0
Training loss: 1.6348193883895874
Validation loss: 2.0590990461328977

Epoch: 5| Step: 1
Training loss: 1.937350869178772
Validation loss: 2.061258690331572

Epoch: 5| Step: 2
Training loss: 1.9451977014541626
Validation loss: 2.0350627514623825

Epoch: 5| Step: 3
Training loss: 1.665449857711792
Validation loss: 2.1125688963038947

Epoch: 5| Step: 4
Training loss: 2.1669857501983643
Validation loss: 2.0142574464121172

Epoch: 5| Step: 5
Training loss: 2.2881898880004883
Validation loss: 2.115694148566133

Epoch: 5| Step: 6
Training loss: 1.7809616327285767
Validation loss: 2.085768397136401

Epoch: 5| Step: 7
Training loss: 1.3078020811080933
Validation loss: 2.0601390049021733

Epoch: 5| Step: 8
Training loss: 2.522540807723999
Validation loss: 2.0439470762847574

Epoch: 5| Step: 9
Training loss: 2.1630959510803223
Validation loss: 2.047555172315208

Epoch: 5| Step: 10
Training loss: 1.4054843187332153
Validation loss: 2.078529630937884

Epoch: 211| Step: 0
Training loss: 1.6025669574737549
Validation loss: 2.0553451609867874

Epoch: 5| Step: 1
Training loss: 1.7249953746795654
Validation loss: 2.0892532922888316

Epoch: 5| Step: 2
Training loss: 1.4650245904922485
Validation loss: 2.0676460676295783

Epoch: 5| Step: 3
Training loss: 2.7399566173553467
Validation loss: 2.0893956127987114

Epoch: 5| Step: 4
Training loss: 1.5391203165054321
Validation loss: 2.0694072682370424

Epoch: 5| Step: 5
Training loss: 1.7024730443954468
Validation loss: 2.0771427564723517

Epoch: 5| Step: 6
Training loss: 1.943904161453247
Validation loss: 2.0955230676999657

Epoch: 5| Step: 7
Training loss: 1.302003264427185
Validation loss: 2.066256598759723

Epoch: 5| Step: 8
Training loss: 2.541342258453369
Validation loss: 2.056837538237213

Epoch: 5| Step: 9
Training loss: 2.06361985206604
Validation loss: 2.079115531777823

Epoch: 5| Step: 10
Training loss: 1.9104944467544556
Validation loss: 2.039903683047141

Epoch: 212| Step: 0
Training loss: 1.7417322397232056
Validation loss: 2.093860557002406

Epoch: 5| Step: 1
Training loss: 1.8361724615097046
Validation loss: 2.0731848785954137

Epoch: 5| Step: 2
Training loss: 1.7888275384902954
Validation loss: 2.0187930035334762

Epoch: 5| Step: 3
Training loss: 1.941558599472046
Validation loss: 2.093559452282485

Epoch: 5| Step: 4
Training loss: 2.068352222442627
Validation loss: 2.0783216876368367

Epoch: 5| Step: 5
Training loss: 2.3169682025909424
Validation loss: 2.0405728740076863

Epoch: 5| Step: 6
Training loss: 2.801384449005127
Validation loss: 2.0493254353923183

Epoch: 5| Step: 7
Training loss: 1.1839675903320312
Validation loss: 2.0560781955718994

Epoch: 5| Step: 8
Training loss: 2.3484175205230713
Validation loss: 2.1159309110333844

Epoch: 5| Step: 9
Training loss: 1.4098551273345947
Validation loss: 2.1009165548509166

Epoch: 5| Step: 10
Training loss: 1.2341622114181519
Validation loss: 2.0746581605685654

Epoch: 213| Step: 0
Training loss: 2.2383344173431396
Validation loss: 2.0388806135423723

Epoch: 5| Step: 1
Training loss: 2.136789560317993
Validation loss: 2.0696153307473786

Epoch: 5| Step: 2
Training loss: 1.4796839952468872
Validation loss: 2.085616518092412

Epoch: 5| Step: 3
Training loss: 2.008143186569214
Validation loss: 2.102208261848778

Epoch: 5| Step: 4
Training loss: 1.7853437662124634
Validation loss: 2.0776140971850325

Epoch: 5| Step: 5
Training loss: 1.8382354974746704
Validation loss: 2.040757656097412

Epoch: 5| Step: 6
Training loss: 1.7287794351577759
Validation loss: 2.064593748379779

Epoch: 5| Step: 7
Training loss: 2.1853652000427246
Validation loss: 2.0925148815237065

Epoch: 5| Step: 8
Training loss: 1.8277852535247803
Validation loss: 2.0497141973946684

Epoch: 5| Step: 9
Training loss: 1.7562916278839111
Validation loss: 2.0890199779182352

Epoch: 5| Step: 10
Training loss: 1.447314739227295
Validation loss: 2.0277039594547723

Epoch: 214| Step: 0
Training loss: 1.9061647653579712
Validation loss: 2.0871438467374412

Epoch: 5| Step: 1
Training loss: 1.8992221355438232
Validation loss: 2.1067115696527625

Epoch: 5| Step: 2
Training loss: 1.7867543697357178
Validation loss: 2.106454853088625

Epoch: 5| Step: 3
Training loss: 1.8355690240859985
Validation loss: 2.0765685727519374

Epoch: 5| Step: 4
Training loss: 1.9460780620574951
Validation loss: 2.0687101387208506

Epoch: 5| Step: 5
Training loss: 1.7836544513702393
Validation loss: 2.0508844019264303

Epoch: 5| Step: 6
Training loss: 1.7051022052764893
Validation loss: 2.0723639688184186

Epoch: 5| Step: 7
Training loss: 2.7869930267333984
Validation loss: 2.07059895864097

Epoch: 5| Step: 8
Training loss: 2.106658697128296
Validation loss: 2.0993298535705893

Epoch: 5| Step: 9
Training loss: 1.371002197265625
Validation loss: 2.0497320390516713

Epoch: 5| Step: 10
Training loss: 1.5406486988067627
Validation loss: 2.024631433589484

Epoch: 215| Step: 0
Training loss: 1.801064133644104
Validation loss: 2.046380146857231

Epoch: 5| Step: 1
Training loss: 1.923644781112671
Validation loss: 2.0751089460106305

Epoch: 5| Step: 2
Training loss: 1.4047253131866455
Validation loss: 2.0644528327449674

Epoch: 5| Step: 3
Training loss: 1.5630099773406982
Validation loss: 2.03923281802926

Epoch: 5| Step: 4
Training loss: 2.1950345039367676
Validation loss: 2.0695903711421515

Epoch: 5| Step: 5
Training loss: 1.8723331689834595
Validation loss: 2.104406287593226

Epoch: 5| Step: 6
Training loss: 2.356645107269287
Validation loss: 2.0408060730144544

Epoch: 5| Step: 7
Training loss: 1.8990389108657837
Validation loss: 2.067194401576955

Epoch: 5| Step: 8
Training loss: 1.3838427066802979
Validation loss: 2.082207364420737

Epoch: 5| Step: 9
Training loss: 1.8734333515167236
Validation loss: 2.070487096745481

Epoch: 5| Step: 10
Training loss: 2.0060157775878906
Validation loss: 2.0747401406688075

Epoch: 216| Step: 0
Training loss: 2.721358299255371
Validation loss: 2.0822591973889257

Epoch: 5| Step: 1
Training loss: 2.126232147216797
Validation loss: 2.0449796107507523

Epoch: 5| Step: 2
Training loss: 2.3988595008850098
Validation loss: 2.075810037633424

Epoch: 5| Step: 3
Training loss: 1.6156234741210938
Validation loss: 2.1119528150045745

Epoch: 5| Step: 4
Training loss: 1.4550111293792725
Validation loss: 2.040387879135788

Epoch: 5| Step: 5
Training loss: 1.8593801259994507
Validation loss: 2.1113119791912776

Epoch: 5| Step: 6
Training loss: 1.961280107498169
Validation loss: 2.077233229914019

Epoch: 5| Step: 7
Training loss: 1.6555156707763672
Validation loss: 2.1174318072616414

Epoch: 5| Step: 8
Training loss: 1.4223365783691406
Validation loss: 2.067281569204023

Epoch: 5| Step: 9
Training loss: 1.4754588603973389
Validation loss: 2.0684254836010676

Epoch: 5| Step: 10
Training loss: 2.1191539764404297
Validation loss: 2.0795555319837344

Epoch: 217| Step: 0
Training loss: 1.796250343322754
Validation loss: 2.049824191677955

Epoch: 5| Step: 1
Training loss: 1.854798674583435
Validation loss: 2.0377116228944514

Epoch: 5| Step: 2
Training loss: 2.0270798206329346
Validation loss: 2.051999253611411

Epoch: 5| Step: 3
Training loss: 1.4035168886184692
Validation loss: 2.0163291692733765

Epoch: 5| Step: 4
Training loss: 2.1177468299865723
Validation loss: 2.0210422123632124

Epoch: 5| Step: 5
Training loss: 1.9535146951675415
Validation loss: 2.088987459418594

Epoch: 5| Step: 6
Training loss: 1.8656708002090454
Validation loss: 2.0598933209655104

Epoch: 5| Step: 7
Training loss: 2.156790018081665
Validation loss: 2.0090830582444386

Epoch: 5| Step: 8
Training loss: 1.5109975337982178
Validation loss: 2.079565704509776

Epoch: 5| Step: 9
Training loss: 1.5338737964630127
Validation loss: 2.0317974552031486

Epoch: 5| Step: 10
Training loss: 2.4457054138183594
Validation loss: 2.0197527934146184

Epoch: 218| Step: 0
Training loss: 2.2279555797576904
Validation loss: 2.0991804010124615

Epoch: 5| Step: 1
Training loss: 2.2065911293029785
Validation loss: 2.0294637141689176

Epoch: 5| Step: 2
Training loss: 1.655311942100525
Validation loss: 2.0522684961236934

Epoch: 5| Step: 3
Training loss: 2.6193039417266846
Validation loss: 2.038297184052006

Epoch: 5| Step: 4
Training loss: 1.7002376317977905
Validation loss: 2.0668597759739047

Epoch: 5| Step: 5
Training loss: 1.4176713228225708
Validation loss: 2.069408587230149

Epoch: 5| Step: 6
Training loss: 1.927103042602539
Validation loss: 2.03028412788145

Epoch: 5| Step: 7
Training loss: 1.8728511333465576
Validation loss: 2.062673571289227

Epoch: 5| Step: 8
Training loss: 1.3035658597946167
Validation loss: 2.0488816948347193

Epoch: 5| Step: 9
Training loss: 1.595766305923462
Validation loss: 2.0586015178311254

Epoch: 5| Step: 10
Training loss: 2.097642660140991
Validation loss: 2.106859476335587

Epoch: 219| Step: 0
Training loss: 1.9706017971038818
Validation loss: 2.0284244501462547

Epoch: 5| Step: 1
Training loss: 2.153308868408203
Validation loss: 2.097408502332626

Epoch: 5| Step: 2
Training loss: 1.5697572231292725
Validation loss: 2.088656239612128

Epoch: 5| Step: 3
Training loss: 1.5686336755752563
Validation loss: 2.033080117676848

Epoch: 5| Step: 4
Training loss: 1.5892070531845093
Validation loss: 2.09441348045103

Epoch: 5| Step: 5
Training loss: 2.086057424545288
Validation loss: 2.040320351559629

Epoch: 5| Step: 6
Training loss: 1.6374849081039429
Validation loss: 2.0515422962045156

Epoch: 5| Step: 7
Training loss: 2.1390931606292725
Validation loss: 2.058025328061914

Epoch: 5| Step: 8
Training loss: 1.7628206014633179
Validation loss: 2.046158595751691

Epoch: 5| Step: 9
Training loss: 2.106144666671753
Validation loss: 2.042406742290784

Epoch: 5| Step: 10
Training loss: 1.4996922016143799
Validation loss: 2.0841582205987748

Epoch: 220| Step: 0
Training loss: 2.4273252487182617
Validation loss: 2.0439372344683577

Epoch: 5| Step: 1
Training loss: 1.4670859575271606
Validation loss: 2.008580561607115

Epoch: 5| Step: 2
Training loss: 1.9345149993896484
Validation loss: 2.101519307782573

Epoch: 5| Step: 3
Training loss: 1.8561763763427734
Validation loss: 2.004940894342238

Epoch: 5| Step: 4
Training loss: 2.2285873889923096
Validation loss: 2.0553435228204213

Epoch: 5| Step: 5
Training loss: 1.9608951807022095
Validation loss: 2.0740991536007134

Epoch: 5| Step: 6
Training loss: 1.893515944480896
Validation loss: 2.023083879101661

Epoch: 5| Step: 7
Training loss: 1.4145389795303345
Validation loss: 2.063704603461809

Epoch: 5| Step: 8
Training loss: 1.6412785053253174
Validation loss: 2.0819870912900535

Epoch: 5| Step: 9
Training loss: 2.027846097946167
Validation loss: 2.033830322245116

Epoch: 5| Step: 10
Training loss: 1.6761542558670044
Validation loss: 2.020367737739317

Epoch: 221| Step: 0
Training loss: 1.9711580276489258
Validation loss: 2.022866832312717

Epoch: 5| Step: 1
Training loss: 2.1880855560302734
Validation loss: 2.05115169607183

Epoch: 5| Step: 2
Training loss: 1.8241634368896484
Validation loss: 2.0761238118653655

Epoch: 5| Step: 3
Training loss: 1.6107956171035767
Validation loss: 2.0530685865750877

Epoch: 5| Step: 4
Training loss: 2.2016215324401855
Validation loss: 2.042316177839874

Epoch: 5| Step: 5
Training loss: 1.4922324419021606
Validation loss: 2.0550360320716776

Epoch: 5| Step: 6
Training loss: 1.895432472229004
Validation loss: 2.0158227130930912

Epoch: 5| Step: 7
Training loss: 2.0890421867370605
Validation loss: 2.0703094338858

Epoch: 5| Step: 8
Training loss: 1.323620080947876
Validation loss: 2.0343943642031763

Epoch: 5| Step: 9
Training loss: 1.9423420429229736
Validation loss: 2.0605620902071715

Epoch: 5| Step: 10
Training loss: 1.498795509338379
Validation loss: 2.039883639222832

Epoch: 222| Step: 0
Training loss: 2.0991106033325195
Validation loss: 2.087586572093348

Epoch: 5| Step: 1
Training loss: 1.998464584350586
Validation loss: 2.064357683222781

Epoch: 5| Step: 2
Training loss: 1.3426045179367065
Validation loss: 2.0417843634082424

Epoch: 5| Step: 3
Training loss: 2.053659200668335
Validation loss: 2.0334371674445366

Epoch: 5| Step: 4
Training loss: 2.036783218383789
Validation loss: 2.0481582662110687

Epoch: 5| Step: 5
Training loss: 1.712988257408142
Validation loss: 2.0609151131363324

Epoch: 5| Step: 6
Training loss: 1.8484289646148682
Validation loss: 2.0767602433440504

Epoch: 5| Step: 7
Training loss: 1.9329302310943604
Validation loss: 2.0446015250298286

Epoch: 5| Step: 8
Training loss: 1.2776439189910889
Validation loss: 2.0258518393321703

Epoch: 5| Step: 9
Training loss: 2.0435376167297363
Validation loss: 1.9893159251059256

Epoch: 5| Step: 10
Training loss: 1.6530418395996094
Validation loss: 2.0526521923721477

Epoch: 223| Step: 0
Training loss: 1.3929436206817627
Validation loss: 2.029342064293482

Epoch: 5| Step: 1
Training loss: 2.2528936862945557
Validation loss: 2.049830669997841

Epoch: 5| Step: 2
Training loss: 1.4889198541641235
Validation loss: 2.0289516192610546

Epoch: 5| Step: 3
Training loss: 1.4170838594436646
Validation loss: 2.0596959116638347

Epoch: 5| Step: 4
Training loss: 1.4841166734695435
Validation loss: 2.0727432773959253

Epoch: 5| Step: 5
Training loss: 1.8433444499969482
Validation loss: 2.0531717167105725

Epoch: 5| Step: 6
Training loss: 1.8245925903320312
Validation loss: 2.036416410118021

Epoch: 5| Step: 7
Training loss: 1.4300791025161743
Validation loss: 2.048657153242378

Epoch: 5| Step: 8
Training loss: 2.55576753616333
Validation loss: 2.0935958893068376

Epoch: 5| Step: 9
Training loss: 2.3809382915496826
Validation loss: 2.054746861098915

Epoch: 5| Step: 10
Training loss: 2.297606945037842
Validation loss: 2.0466289212626796

Epoch: 224| Step: 0
Training loss: 1.6872936487197876
Validation loss: 2.0477969864363312

Epoch: 5| Step: 1
Training loss: 1.8647050857543945
Validation loss: 2.030708046369655

Epoch: 5| Step: 2
Training loss: 2.23435115814209
Validation loss: 2.068472377715572

Epoch: 5| Step: 3
Training loss: 2.0091049671173096
Validation loss: 2.037413913716552

Epoch: 5| Step: 4
Training loss: 1.8720054626464844
Validation loss: 2.0790904670633297

Epoch: 5| Step: 5
Training loss: 1.6208454370498657
Validation loss: 2.0132916358209427

Epoch: 5| Step: 6
Training loss: 1.7165435552597046
Validation loss: 2.0469029872648177

Epoch: 5| Step: 7
Training loss: 1.5959398746490479
Validation loss: 2.0225016276041665

Epoch: 5| Step: 8
Training loss: 1.4490630626678467
Validation loss: 2.073058174502465

Epoch: 5| Step: 9
Training loss: 1.812037467956543
Validation loss: 2.0204712178117488

Epoch: 5| Step: 10
Training loss: 2.082653522491455
Validation loss: 2.022497210451352

Epoch: 225| Step: 0
Training loss: 1.135994553565979
Validation loss: 2.047927825681625

Epoch: 5| Step: 1
Training loss: 1.9418938159942627
Validation loss: 2.061238778534756

Epoch: 5| Step: 2
Training loss: 1.4393310546875
Validation loss: 2.051519005529342

Epoch: 5| Step: 3
Training loss: 2.534041166305542
Validation loss: 2.07193584083229

Epoch: 5| Step: 4
Training loss: 1.9585483074188232
Validation loss: 2.050733845721009

Epoch: 5| Step: 5
Training loss: 1.8017654418945312
Validation loss: 2.071980805807216

Epoch: 5| Step: 6
Training loss: 2.0916748046875
Validation loss: 2.0587947368621826

Epoch: 5| Step: 7
Training loss: 2.2339494228363037
Validation loss: 2.029470423216461

Epoch: 5| Step: 8
Training loss: 1.913086175918579
Validation loss: 2.074928911783362

Epoch: 5| Step: 9
Training loss: 1.6145102977752686
Validation loss: 2.0388880622002388

Epoch: 5| Step: 10
Training loss: 1.3538261651992798
Validation loss: 2.0733045147311304

Epoch: 226| Step: 0
Training loss: 2.077840805053711
Validation loss: 2.056612732589886

Epoch: 5| Step: 1
Training loss: 1.6632168292999268
Validation loss: 2.0347224512407855

Epoch: 5| Step: 2
Training loss: 2.567577838897705
Validation loss: 2.0161993375388523

Epoch: 5| Step: 3
Training loss: 1.5657074451446533
Validation loss: 2.034482225295036

Epoch: 5| Step: 4
Training loss: 1.580480933189392
Validation loss: 2.0522798697153726

Epoch: 5| Step: 5
Training loss: 1.7538585662841797
Validation loss: 2.000988878229613

Epoch: 5| Step: 6
Training loss: 1.7580420970916748
Validation loss: 2.0137176436762654

Epoch: 5| Step: 7
Training loss: 1.5702908039093018
Validation loss: 2.0330570295292842

Epoch: 5| Step: 8
Training loss: 1.2934414148330688
Validation loss: 2.024271011352539

Epoch: 5| Step: 9
Training loss: 1.9219481945037842
Validation loss: 2.0469187100728354

Epoch: 5| Step: 10
Training loss: 1.9607762098312378
Validation loss: 2.0500185182017665

Epoch: 227| Step: 0
Training loss: 1.9937067031860352
Validation loss: 2.010343596499453

Epoch: 5| Step: 1
Training loss: 1.5354516506195068
Validation loss: 2.004368733334285

Epoch: 5| Step: 2
Training loss: 2.0011308193206787
Validation loss: 2.025393601386778

Epoch: 5| Step: 3
Training loss: 1.5384657382965088
Validation loss: 2.0982587196493663

Epoch: 5| Step: 4
Training loss: 1.2780354022979736
Validation loss: 2.04361359278361

Epoch: 5| Step: 5
Training loss: 2.226555585861206
Validation loss: 2.055209361096864

Epoch: 5| Step: 6
Training loss: 1.568359375
Validation loss: 2.0193985969789567

Epoch: 5| Step: 7
Training loss: 1.7736499309539795
Validation loss: 2.08224089940389

Epoch: 5| Step: 8
Training loss: 1.7399898767471313
Validation loss: 2.0586980517192552

Epoch: 5| Step: 9
Training loss: 2.494101047515869
Validation loss: 2.0518462645110263

Epoch: 5| Step: 10
Training loss: 1.926707148551941
Validation loss: 2.0606249763119604

Epoch: 228| Step: 0
Training loss: 1.979174256324768
Validation loss: 2.057754490965156

Epoch: 5| Step: 1
Training loss: 1.6353099346160889
Validation loss: 2.070671109743016

Epoch: 5| Step: 2
Training loss: 1.7047960758209229
Validation loss: 2.01169176255503

Epoch: 5| Step: 3
Training loss: 1.8759098052978516
Validation loss: 2.044807690446095

Epoch: 5| Step: 4
Training loss: 1.971914529800415
Validation loss: 2.0014643387127946

Epoch: 5| Step: 5
Training loss: 1.8864021301269531
Validation loss: 2.053678834310142

Epoch: 5| Step: 6
Training loss: 2.1527984142303467
Validation loss: 2.0284263728767313

Epoch: 5| Step: 7
Training loss: 1.7935676574707031
Validation loss: 2.050780932108561

Epoch: 5| Step: 8
Training loss: 1.6888744831085205
Validation loss: 2.02252015759868

Epoch: 5| Step: 9
Training loss: 1.3146092891693115
Validation loss: 2.0454502413349767

Epoch: 5| Step: 10
Training loss: 2.043686866760254
Validation loss: 1.9876524863704559

Epoch: 229| Step: 0
Training loss: 2.395801067352295
Validation loss: 2.040283195434078

Epoch: 5| Step: 1
Training loss: 1.0914289951324463
Validation loss: 2.010649169645002

Epoch: 5| Step: 2
Training loss: 1.765572190284729
Validation loss: 2.0192004967761297

Epoch: 5| Step: 3
Training loss: 2.064509868621826
Validation loss: 2.043714483579

Epoch: 5| Step: 4
Training loss: 2.377971649169922
Validation loss: 2.0898336697650213

Epoch: 5| Step: 5
Training loss: 2.117765426635742
Validation loss: 2.0581842673722135

Epoch: 5| Step: 6
Training loss: 0.9462071657180786
Validation loss: 2.1013591212611042

Epoch: 5| Step: 7
Training loss: 1.979154348373413
Validation loss: 2.0766329150046072

Epoch: 5| Step: 8
Training loss: 2.0635790824890137
Validation loss: 2.0572353845001548

Epoch: 5| Step: 9
Training loss: 1.5828222036361694
Validation loss: 2.04811663909625

Epoch: 5| Step: 10
Training loss: 1.6822123527526855
Validation loss: 2.0760388669147285

Epoch: 230| Step: 0
Training loss: 1.9563566446304321
Validation loss: 2.132394939340571

Epoch: 5| Step: 1
Training loss: 1.6949832439422607
Validation loss: 2.0624755582501813

Epoch: 5| Step: 2
Training loss: 2.029048442840576
Validation loss: 2.0518926394883024

Epoch: 5| Step: 3
Training loss: 1.8147163391113281
Validation loss: 2.0288969650063464

Epoch: 5| Step: 4
Training loss: 1.6813619136810303
Validation loss: 2.068761717888617

Epoch: 5| Step: 5
Training loss: 1.6157338619232178
Validation loss: 2.0686065945574033

Epoch: 5| Step: 6
Training loss: 1.678877592086792
Validation loss: 2.0463651905777636

Epoch: 5| Step: 7
Training loss: 1.5726416110992432
Validation loss: 2.0718297009826987

Epoch: 5| Step: 8
Training loss: 1.9887539148330688
Validation loss: 2.067536369446785

Epoch: 5| Step: 9
Training loss: 2.1758666038513184
Validation loss: 2.1045766991953694

Epoch: 5| Step: 10
Training loss: 1.366075038909912
Validation loss: 2.0586667791489632

Epoch: 231| Step: 0
Training loss: 1.4259179830551147
Validation loss: 2.023641868304181

Epoch: 5| Step: 1
Training loss: 1.7278223037719727
Validation loss: 2.0228710738561486

Epoch: 5| Step: 2
Training loss: 1.9696842432022095
Validation loss: 2.006300533971479

Epoch: 5| Step: 3
Training loss: 2.2044429779052734
Validation loss: 2.039143676398903

Epoch: 5| Step: 4
Training loss: 2.255382537841797
Validation loss: 1.9956543881406066

Epoch: 5| Step: 5
Training loss: 1.2149873971939087
Validation loss: 2.0702542925393708

Epoch: 5| Step: 6
Training loss: 1.67913019657135
Validation loss: 2.07474426556659

Epoch: 5| Step: 7
Training loss: 1.7488139867782593
Validation loss: 2.054108952963224

Epoch: 5| Step: 8
Training loss: 1.8218914270401
Validation loss: 2.0002092725487164

Epoch: 5| Step: 9
Training loss: 1.6514085531234741
Validation loss: 2.044359803199768

Epoch: 5| Step: 10
Training loss: 2.0831220149993896
Validation loss: 2.0407902861154206

Epoch: 232| Step: 0
Training loss: 1.598056435585022
Validation loss: 2.040490642670662

Epoch: 5| Step: 1
Training loss: 1.240339994430542
Validation loss: 2.088680705716533

Epoch: 5| Step: 2
Training loss: 1.8477420806884766
Validation loss: 2.052509976971534

Epoch: 5| Step: 3
Training loss: 2.5955123901367188
Validation loss: 2.077266787969938

Epoch: 5| Step: 4
Training loss: 1.437172293663025
Validation loss: 2.019329281263454

Epoch: 5| Step: 5
Training loss: 1.681369423866272
Validation loss: 2.053970821442143

Epoch: 5| Step: 6
Training loss: 1.3113343715667725
Validation loss: 2.101749212511124

Epoch: 5| Step: 7
Training loss: 1.882083535194397
Validation loss: 2.071144998714488

Epoch: 5| Step: 8
Training loss: 2.6963770389556885
Validation loss: 2.092146376127838

Epoch: 5| Step: 9
Training loss: 1.8253309726715088
Validation loss: 2.0376406151761293

Epoch: 5| Step: 10
Training loss: 1.989214301109314
Validation loss: 2.066899194512316

Epoch: 233| Step: 0
Training loss: 1.6790651082992554
Validation loss: 2.0992764862634803

Epoch: 5| Step: 1
Training loss: 1.6750017404556274
Validation loss: 2.05813878966916

Epoch: 5| Step: 2
Training loss: 2.6114730834960938
Validation loss: 2.052774290884695

Epoch: 5| Step: 3
Training loss: 1.8541702032089233
Validation loss: 2.015283059048396

Epoch: 5| Step: 4
Training loss: 1.9949325323104858
Validation loss: 2.0185149382519465

Epoch: 5| Step: 5
Training loss: 1.4481594562530518
Validation loss: 2.0576847227670814

Epoch: 5| Step: 6
Training loss: 1.4232978820800781
Validation loss: 2.002745842420927

Epoch: 5| Step: 7
Training loss: 2.215433120727539
Validation loss: 2.0095371225828766

Epoch: 5| Step: 8
Training loss: 1.300607442855835
Validation loss: 1.9922307896357712

Epoch: 5| Step: 9
Training loss: 1.7904506921768188
Validation loss: 2.078760939259683

Epoch: 5| Step: 10
Training loss: 1.7170430421829224
Validation loss: 2.0244710894041162

Epoch: 234| Step: 0
Training loss: 1.5210347175598145
Validation loss: 2.0600761034155406

Epoch: 5| Step: 1
Training loss: 2.074193239212036
Validation loss: 2.066588132612167

Epoch: 5| Step: 2
Training loss: 2.984251022338867
Validation loss: 2.055732527086812

Epoch: 5| Step: 3
Training loss: 1.5002963542938232
Validation loss: 2.0658447434825282

Epoch: 5| Step: 4
Training loss: 1.496134638786316
Validation loss: 2.0868206126715547

Epoch: 5| Step: 5
Training loss: 1.992327094078064
Validation loss: 2.017743093993074

Epoch: 5| Step: 6
Training loss: 1.3858591318130493
Validation loss: 2.031905730565389

Epoch: 5| Step: 7
Training loss: 1.5267138481140137
Validation loss: 2.062673176488569

Epoch: 5| Step: 8
Training loss: 1.5552979707717896
Validation loss: 2.0356731466067735

Epoch: 5| Step: 9
Training loss: 1.8195912837982178
Validation loss: 2.0929798541530484

Epoch: 5| Step: 10
Training loss: 1.862676739692688
Validation loss: 2.039901659052859

Epoch: 235| Step: 0
Training loss: 1.6591215133666992
Validation loss: 2.045821725681264

Epoch: 5| Step: 1
Training loss: 2.0623891353607178
Validation loss: 2.0412885553093365

Epoch: 5| Step: 2
Training loss: 1.8013890981674194
Validation loss: 2.0423567500165714

Epoch: 5| Step: 3
Training loss: 1.834853172302246
Validation loss: 2.0593997586158013

Epoch: 5| Step: 4
Training loss: 1.476743459701538
Validation loss: 2.0954846964087537

Epoch: 5| Step: 5
Training loss: 1.6134967803955078
Validation loss: 2.036224893344346

Epoch: 5| Step: 6
Training loss: 2.0013184547424316
Validation loss: 2.0322127419133342

Epoch: 5| Step: 7
Training loss: 1.8011360168457031
Validation loss: 2.014715922776089

Epoch: 5| Step: 8
Training loss: 2.414137840270996
Validation loss: 2.053352827666908

Epoch: 5| Step: 9
Training loss: 1.477213740348816
Validation loss: 2.059630424745621

Epoch: 5| Step: 10
Training loss: 1.7617007493972778
Validation loss: 2.0090154601681616

Epoch: 236| Step: 0
Training loss: 1.4288854598999023
Validation loss: 2.0611275652403473

Epoch: 5| Step: 1
Training loss: 1.4807121753692627
Validation loss: 2.0726477843458935

Epoch: 5| Step: 2
Training loss: 2.247100353240967
Validation loss: 2.0550995308865785

Epoch: 5| Step: 3
Training loss: 2.4603493213653564
Validation loss: 2.067855629869687

Epoch: 5| Step: 4
Training loss: 1.6028995513916016
Validation loss: 2.046668311601044

Epoch: 5| Step: 5
Training loss: 1.8693618774414062
Validation loss: 2.0127594958069506

Epoch: 5| Step: 6
Training loss: 1.8977882862091064
Validation loss: 2.0852423842235277

Epoch: 5| Step: 7
Training loss: 1.7017450332641602
Validation loss: 2.0687227351691133

Epoch: 5| Step: 8
Training loss: 1.8615782260894775
Validation loss: 2.0425747517616517

Epoch: 5| Step: 9
Training loss: 1.361993670463562
Validation loss: 2.036776004299041

Epoch: 5| Step: 10
Training loss: 2.077794313430786
Validation loss: 2.0518574676206036

Epoch: 237| Step: 0
Training loss: 1.8128023147583008
Validation loss: 2.0618161783423474

Epoch: 5| Step: 1
Training loss: 2.021514892578125
Validation loss: 2.12855431982266

Epoch: 5| Step: 2
Training loss: 1.342536211013794
Validation loss: 2.0098478742825088

Epoch: 5| Step: 3
Training loss: 1.2873471975326538
Validation loss: 2.0812021660548385

Epoch: 5| Step: 4
Training loss: 1.7997944355010986
Validation loss: 2.034794786924957

Epoch: 5| Step: 5
Training loss: 2.346052646636963
Validation loss: 2.0679157895426594

Epoch: 5| Step: 6
Training loss: 1.9199193716049194
Validation loss: 2.058230186021456

Epoch: 5| Step: 7
Training loss: 2.5511999130249023
Validation loss: 2.1059001812370877

Epoch: 5| Step: 8
Training loss: 1.2864086627960205
Validation loss: 2.0360648119321434

Epoch: 5| Step: 9
Training loss: 1.6747394800186157
Validation loss: 2.0315546092166694

Epoch: 5| Step: 10
Training loss: 1.493861198425293
Validation loss: 1.9849235447504188

Epoch: 238| Step: 0
Training loss: 1.7477165460586548
Validation loss: 2.031356470559233

Epoch: 5| Step: 1
Training loss: 1.7486435174942017
Validation loss: 2.0233751343142603

Epoch: 5| Step: 2
Training loss: 1.7613672018051147
Validation loss: 2.027363105486798

Epoch: 5| Step: 3
Training loss: 2.0512850284576416
Validation loss: 2.0720766154668664

Epoch: 5| Step: 4
Training loss: 1.3631254434585571
Validation loss: 1.9658551164852676

Epoch: 5| Step: 5
Training loss: 1.2134110927581787
Validation loss: 2.0585047070698073

Epoch: 5| Step: 6
Training loss: 1.343198537826538
Validation loss: 1.979532903240573

Epoch: 5| Step: 7
Training loss: 1.9363460540771484
Validation loss: 1.946332852045695

Epoch: 5| Step: 8
Training loss: 2.1845009326934814
Validation loss: 2.0157327036703787

Epoch: 5| Step: 9
Training loss: 1.9713213443756104
Validation loss: 1.9855959184708134

Epoch: 5| Step: 10
Training loss: 2.4497761726379395
Validation loss: 2.0517305289545367

Epoch: 239| Step: 0
Training loss: 1.3486146926879883
Validation loss: 2.0474376537466563

Epoch: 5| Step: 1
Training loss: 1.5304502248764038
Validation loss: 2.0379923825622885

Epoch: 5| Step: 2
Training loss: 2.2570812702178955
Validation loss: 2.0412798312402542

Epoch: 5| Step: 3
Training loss: 1.9599403142929077
Validation loss: 2.073629751000353

Epoch: 5| Step: 4
Training loss: 2.0046372413635254
Validation loss: 2.031294471474104

Epoch: 5| Step: 5
Training loss: 2.138308048248291
Validation loss: 2.041339458957795

Epoch: 5| Step: 6
Training loss: 1.3063552379608154
Validation loss: 2.0250933016500166

Epoch: 5| Step: 7
Training loss: 1.8840491771697998
Validation loss: 2.0185831874929447

Epoch: 5| Step: 8
Training loss: 2.3905367851257324
Validation loss: 2.1176676263091383

Epoch: 5| Step: 9
Training loss: 1.5089480876922607
Validation loss: 2.065401784835323

Epoch: 5| Step: 10
Training loss: 1.43914794921875
Validation loss: 2.144562122642353

Epoch: 240| Step: 0
Training loss: 2.126269817352295
Validation loss: 2.071012722548618

Epoch: 5| Step: 1
Training loss: 1.6294384002685547
Validation loss: 2.1295685409217753

Epoch: 5| Step: 2
Training loss: 2.085782527923584
Validation loss: 2.051053821399648

Epoch: 5| Step: 3
Training loss: 1.9450124502182007
Validation loss: 2.049087046295084

Epoch: 5| Step: 4
Training loss: 2.003286838531494
Validation loss: 2.0313674301229496

Epoch: 5| Step: 5
Training loss: 1.896127462387085
Validation loss: 2.017928364456341

Epoch: 5| Step: 6
Training loss: 1.3642044067382812
Validation loss: 2.057490958962389

Epoch: 5| Step: 7
Training loss: 2.0721778869628906
Validation loss: 2.033939415408719

Epoch: 5| Step: 8
Training loss: 1.6029390096664429
Validation loss: 2.050956372291811

Epoch: 5| Step: 9
Training loss: 1.9935293197631836
Validation loss: 2.0450393961321924

Epoch: 5| Step: 10
Training loss: 1.356390357017517
Validation loss: 2.0207499855308124

Epoch: 241| Step: 0
Training loss: 1.8340282440185547
Validation loss: 2.036731889170985

Epoch: 5| Step: 1
Training loss: 1.7386497259140015
Validation loss: 2.0074329542857345

Epoch: 5| Step: 2
Training loss: 1.8172515630722046
Validation loss: 2.0240706333550076

Epoch: 5| Step: 3
Training loss: 1.8076505661010742
Validation loss: 1.9794869205003143

Epoch: 5| Step: 4
Training loss: 1.4857486486434937
Validation loss: 2.0163563297640894

Epoch: 5| Step: 5
Training loss: 2.366285800933838
Validation loss: 2.0102504504624235

Epoch: 5| Step: 6
Training loss: 2.393697738647461
Validation loss: 2.1012762849048903

Epoch: 5| Step: 7
Training loss: 1.5351415872573853
Validation loss: 2.063956058153542

Epoch: 5| Step: 8
Training loss: 1.624389886856079
Validation loss: 1.9950723404525428

Epoch: 5| Step: 9
Training loss: 1.8719907999038696
Validation loss: 2.0383628568341656

Epoch: 5| Step: 10
Training loss: 1.1741498708724976
Validation loss: 2.0264721070566485

Epoch: 242| Step: 0
Training loss: 1.4319998025894165
Validation loss: 2.0683344256493355

Epoch: 5| Step: 1
Training loss: 2.0338082313537598
Validation loss: 2.0423749121286536

Epoch: 5| Step: 2
Training loss: 1.7356131076812744
Validation loss: 2.0201767208755657

Epoch: 5| Step: 3
Training loss: 1.713184118270874
Validation loss: 2.037871371033371

Epoch: 5| Step: 4
Training loss: 1.9328899383544922
Validation loss: 2.022491962678971

Epoch: 5| Step: 5
Training loss: 1.829944372177124
Validation loss: 1.9711871275337793

Epoch: 5| Step: 6
Training loss: 2.490786075592041
Validation loss: 2.0454829559531262

Epoch: 5| Step: 7
Training loss: 1.6055879592895508
Validation loss: 2.0028208840277886

Epoch: 5| Step: 8
Training loss: 1.8168773651123047
Validation loss: 2.0525177601845033

Epoch: 5| Step: 9
Training loss: 1.3964338302612305
Validation loss: 2.0492010744669105

Epoch: 5| Step: 10
Training loss: 1.4724045991897583
Validation loss: 2.0257995872087378

Epoch: 243| Step: 0
Training loss: 1.761338472366333
Validation loss: 2.060262108361849

Epoch: 5| Step: 1
Training loss: 1.7812106609344482
Validation loss: 2.00201512664877

Epoch: 5| Step: 2
Training loss: 1.9524714946746826
Validation loss: 1.9828426555920673

Epoch: 5| Step: 3
Training loss: 1.6953980922698975
Validation loss: 2.0488726785106044

Epoch: 5| Step: 4
Training loss: 2.178366184234619
Validation loss: 2.0754021521537536

Epoch: 5| Step: 5
Training loss: 1.2062698602676392
Validation loss: 1.984656951760733

Epoch: 5| Step: 6
Training loss: 2.153444766998291
Validation loss: 1.9990694599766885

Epoch: 5| Step: 7
Training loss: 1.0996615886688232
Validation loss: 2.0549538661074895

Epoch: 5| Step: 8
Training loss: 1.3726049661636353
Validation loss: 2.01114793233974

Epoch: 5| Step: 9
Training loss: 2.084786891937256
Validation loss: 2.070640763928813

Epoch: 5| Step: 10
Training loss: 1.972394347190857
Validation loss: 2.033346040274507

Epoch: 244| Step: 0
Training loss: 2.0703959465026855
Validation loss: 2.022493598281696

Epoch: 5| Step: 1
Training loss: 1.7269160747528076
Validation loss: 1.994135954046762

Epoch: 5| Step: 2
Training loss: 2.5261504650115967
Validation loss: 2.003430064006518

Epoch: 5| Step: 3
Training loss: 1.085432767868042
Validation loss: 2.018070408093032

Epoch: 5| Step: 4
Training loss: 1.6594175100326538
Validation loss: 2.069727031133508

Epoch: 5| Step: 5
Training loss: 1.4980666637420654
Validation loss: 2.0021946302024265

Epoch: 5| Step: 6
Training loss: 1.9707139730453491
Validation loss: 2.0101560469596618

Epoch: 5| Step: 7
Training loss: 1.5685564279556274
Validation loss: 1.9756010757979525

Epoch: 5| Step: 8
Training loss: 2.0409350395202637
Validation loss: 2.0171632587268786

Epoch: 5| Step: 9
Training loss: 1.7615467309951782
Validation loss: 2.022042989730835

Epoch: 5| Step: 10
Training loss: 1.5552396774291992
Validation loss: 2.022243192118983

Epoch: 245| Step: 0
Training loss: 0.9991472363471985
Validation loss: 2.0378969305305072

Epoch: 5| Step: 1
Training loss: 2.1326518058776855
Validation loss: 2.031753502866273

Epoch: 5| Step: 2
Training loss: 1.638636827468872
Validation loss: 2.0019213986653153

Epoch: 5| Step: 3
Training loss: 1.164980173110962
Validation loss: 2.038711800370165

Epoch: 5| Step: 4
Training loss: 1.487997055053711
Validation loss: 1.9841736555099487

Epoch: 5| Step: 5
Training loss: 1.804962158203125
Validation loss: 2.0470872566264164

Epoch: 5| Step: 6
Training loss: 2.1346468925476074
Validation loss: 2.0295760977652764

Epoch: 5| Step: 7
Training loss: 1.816904067993164
Validation loss: 2.022190888722738

Epoch: 5| Step: 8
Training loss: 2.3401715755462646
Validation loss: 1.9707089444642425

Epoch: 5| Step: 9
Training loss: 1.5383107662200928
Validation loss: 1.995253057890041

Epoch: 5| Step: 10
Training loss: 2.1218149662017822
Validation loss: 1.998931090037028

Epoch: 246| Step: 0
Training loss: 1.4876335859298706
Validation loss: 2.029359427831506

Epoch: 5| Step: 1
Training loss: 1.7715877294540405
Validation loss: 1.9445382959099227

Epoch: 5| Step: 2
Training loss: 2.2173068523406982
Validation loss: 2.0383690198262534

Epoch: 5| Step: 3
Training loss: 1.679003119468689
Validation loss: 2.0526598679122103

Epoch: 5| Step: 4
Training loss: 1.671800971031189
Validation loss: 2.0273142335235432

Epoch: 5| Step: 5
Training loss: 1.356738805770874
Validation loss: 2.0445852305299494

Epoch: 5| Step: 6
Training loss: 2.0906455516815186
Validation loss: 2.0223753401028213

Epoch: 5| Step: 7
Training loss: 1.6143968105316162
Validation loss: 2.05276822018367

Epoch: 5| Step: 8
Training loss: 1.43875253200531
Validation loss: 2.018236937061433

Epoch: 5| Step: 9
Training loss: 1.8340885639190674
Validation loss: 1.9972135379750242

Epoch: 5| Step: 10
Training loss: 1.7232415676116943
Validation loss: 2.0134595042915753

Epoch: 247| Step: 0
Training loss: 1.9370676279067993
Validation loss: 1.9949929752657491

Epoch: 5| Step: 1
Training loss: 1.7055160999298096
Validation loss: 2.084519724692068

Epoch: 5| Step: 2
Training loss: 1.8890278339385986
Validation loss: 2.025983520733413

Epoch: 5| Step: 3
Training loss: 1.9105030298233032
Validation loss: 1.952527343585927

Epoch: 5| Step: 4
Training loss: 1.4814623594284058
Validation loss: 2.0507555392480667

Epoch: 5| Step: 5
Training loss: 2.0821034908294678
Validation loss: 2.0466201997572377

Epoch: 5| Step: 6
Training loss: 1.3702212572097778
Validation loss: 1.998793532771449

Epoch: 5| Step: 7
Training loss: 2.2942864894866943
Validation loss: 2.0027323358802387

Epoch: 5| Step: 8
Training loss: 1.416606068611145
Validation loss: 2.0049406431054555

Epoch: 5| Step: 9
Training loss: 1.751930594444275
Validation loss: 2.0233383165892733

Epoch: 5| Step: 10
Training loss: 1.5734868049621582
Validation loss: 2.041627045600645

Epoch: 248| Step: 0
Training loss: 1.271047830581665
Validation loss: 2.0795583955703245

Epoch: 5| Step: 1
Training loss: 2.2232043743133545
Validation loss: 2.06016686783042

Epoch: 5| Step: 2
Training loss: 2.038865089416504
Validation loss: 1.970471525704989

Epoch: 5| Step: 3
Training loss: 1.8914680480957031
Validation loss: 1.986433304766173

Epoch: 5| Step: 4
Training loss: 1.7364689111709595
Validation loss: 1.990802118855138

Epoch: 5| Step: 5
Training loss: 2.158477544784546
Validation loss: 2.037951938567623

Epoch: 5| Step: 6
Training loss: 1.9308273792266846
Validation loss: 2.024000608792869

Epoch: 5| Step: 7
Training loss: 2.049896001815796
Validation loss: 2.025523276739223

Epoch: 5| Step: 8
Training loss: 1.0822041034698486
Validation loss: 1.9892379622305594

Epoch: 5| Step: 9
Training loss: 1.442402720451355
Validation loss: 2.020295414873349

Epoch: 5| Step: 10
Training loss: 1.2074482440948486
Validation loss: 2.03156372808641

Epoch: 249| Step: 0
Training loss: 1.8535997867584229
Validation loss: 2.0618305924118205

Epoch: 5| Step: 1
Training loss: 2.1361405849456787
Validation loss: 2.013387264743928

Epoch: 5| Step: 2
Training loss: 1.596574068069458
Validation loss: 2.0397190393940097

Epoch: 5| Step: 3
Training loss: 1.4640992879867554
Validation loss: 2.0247970857927875

Epoch: 5| Step: 4
Training loss: 2.0093588829040527
Validation loss: 2.027035827277809

Epoch: 5| Step: 5
Training loss: 0.8472965955734253
Validation loss: 2.0326192455907024

Epoch: 5| Step: 6
Training loss: 1.7976148128509521
Validation loss: 2.0121232835195397

Epoch: 5| Step: 7
Training loss: 1.6399892568588257
Validation loss: 1.9871274912229149

Epoch: 5| Step: 8
Training loss: 1.6072463989257812
Validation loss: 2.0594830436091267

Epoch: 5| Step: 9
Training loss: 2.013942003250122
Validation loss: 1.9842052485353203

Epoch: 5| Step: 10
Training loss: 2.08811092376709
Validation loss: 2.0468529270541285

Epoch: 250| Step: 0
Training loss: 1.4457108974456787
Validation loss: 1.955637857478152

Epoch: 5| Step: 1
Training loss: 1.838658332824707
Validation loss: 2.0215092320596018

Epoch: 5| Step: 2
Training loss: 1.1885778903961182
Validation loss: 2.00324043022689

Epoch: 5| Step: 3
Training loss: 1.834249496459961
Validation loss: 2.037668458877071

Epoch: 5| Step: 4
Training loss: 1.7039343118667603
Validation loss: 2.027701565014419

Epoch: 5| Step: 5
Training loss: 1.6153968572616577
Validation loss: 2.012208256670224

Epoch: 5| Step: 6
Training loss: 1.830061912536621
Validation loss: 2.036895195643107

Epoch: 5| Step: 7
Training loss: 2.159658670425415
Validation loss: 2.065338671848338

Epoch: 5| Step: 8
Training loss: 1.5544230937957764
Validation loss: 2.1005237897237143

Epoch: 5| Step: 9
Training loss: 2.3119986057281494
Validation loss: 2.0512972621507544

Epoch: 5| Step: 10
Training loss: 1.5048918724060059
Validation loss: 1.9913785739611554

Epoch: 251| Step: 0
Training loss: 1.495233416557312
Validation loss: 2.0757760617040817

Epoch: 5| Step: 1
Training loss: 1.3854488134384155
Validation loss: 2.018842110069849

Epoch: 5| Step: 2
Training loss: 1.221384048461914
Validation loss: 2.025151934674991

Epoch: 5| Step: 3
Training loss: 2.2494735717773438
Validation loss: 2.0706793287748932

Epoch: 5| Step: 4
Training loss: 1.555413007736206
Validation loss: 2.023862423435334

Epoch: 5| Step: 5
Training loss: 2.301180362701416
Validation loss: 2.0210239784691924

Epoch: 5| Step: 6
Training loss: 2.0011329650878906
Validation loss: 2.019989590491018

Epoch: 5| Step: 7
Training loss: 1.5252236127853394
Validation loss: 2.0110876970393683

Epoch: 5| Step: 8
Training loss: 2.102928876876831
Validation loss: 2.0077401796976724

Epoch: 5| Step: 9
Training loss: 1.80231511592865
Validation loss: 2.031068899298227

Epoch: 5| Step: 10
Training loss: 1.4675413370132446
Validation loss: 2.0002957736292193

Epoch: 252| Step: 0
Training loss: 1.3125547170639038
Validation loss: 1.9821214201629802

Epoch: 5| Step: 1
Training loss: 1.2619632482528687
Validation loss: 2.0550219487118464

Epoch: 5| Step: 2
Training loss: 1.7008224725723267
Validation loss: 1.9657654967359317

Epoch: 5| Step: 3
Training loss: 1.5566203594207764
Validation loss: 2.035968798463063

Epoch: 5| Step: 4
Training loss: 1.8445755243301392
Validation loss: 2.0104083912346953

Epoch: 5| Step: 5
Training loss: 1.9130735397338867
Validation loss: 2.0319187025870047

Epoch: 5| Step: 6
Training loss: 1.8114445209503174
Validation loss: 1.985221403901295

Epoch: 5| Step: 7
Training loss: 1.442367434501648
Validation loss: 2.04070161491312

Epoch: 5| Step: 8
Training loss: 1.6696170568466187
Validation loss: 1.9584924328711726

Epoch: 5| Step: 9
Training loss: 2.1944639682769775
Validation loss: 1.9419717532332226

Epoch: 5| Step: 10
Training loss: 2.385345220565796
Validation loss: 1.996925320676578

Epoch: 253| Step: 0
Training loss: 2.3650400638580322
Validation loss: 2.007335728214633

Epoch: 5| Step: 1
Training loss: 1.2261910438537598
Validation loss: 1.9549871029392365

Epoch: 5| Step: 2
Training loss: 1.5287564992904663
Validation loss: 2.0150023275806057

Epoch: 5| Step: 3
Training loss: 1.545208215713501
Validation loss: 1.985809523572204

Epoch: 5| Step: 4
Training loss: 2.4974374771118164
Validation loss: 2.0121312884874243

Epoch: 5| Step: 5
Training loss: 1.6463954448699951
Validation loss: 2.0057369278323267

Epoch: 5| Step: 6
Training loss: 1.6039295196533203
Validation loss: 2.025396418827836

Epoch: 5| Step: 7
Training loss: 1.8466403484344482
Validation loss: 1.9987778919999317

Epoch: 5| Step: 8
Training loss: 1.2949014902114868
Validation loss: 2.0213106780923824

Epoch: 5| Step: 9
Training loss: 1.925824761390686
Validation loss: 2.014165332240443

Epoch: 5| Step: 10
Training loss: 1.4368677139282227
Validation loss: 2.014840884875226

Epoch: 254| Step: 0
Training loss: 1.6761716604232788
Validation loss: 2.0783079029411398

Epoch: 5| Step: 1
Training loss: 1.4244695901870728
Validation loss: 2.0484124127254693

Epoch: 5| Step: 2
Training loss: 2.069121837615967
Validation loss: 2.02773222872006

Epoch: 5| Step: 3
Training loss: 1.2998054027557373
Validation loss: 2.02471354956268

Epoch: 5| Step: 4
Training loss: 1.5045948028564453
Validation loss: 1.9866458459566998

Epoch: 5| Step: 5
Training loss: 1.9011719226837158
Validation loss: 2.0039609452729583

Epoch: 5| Step: 6
Training loss: 1.675013780593872
Validation loss: 1.9954130059929305

Epoch: 5| Step: 7
Training loss: 2.286658763885498
Validation loss: 2.037111477185321

Epoch: 5| Step: 8
Training loss: 1.7106540203094482
Validation loss: 2.0036416310136036

Epoch: 5| Step: 9
Training loss: 1.845052719116211
Validation loss: 1.9594881649940246

Epoch: 5| Step: 10
Training loss: 1.7852978706359863
Validation loss: 1.9969805363685853

Epoch: 255| Step: 0
Training loss: 1.8173290491104126
Validation loss: 2.0361574055046163

Epoch: 5| Step: 1
Training loss: 1.5920246839523315
Validation loss: 2.0273677995128017

Epoch: 5| Step: 2
Training loss: 1.413299560546875
Validation loss: 2.064502860910149

Epoch: 5| Step: 3
Training loss: 2.1744565963745117
Validation loss: 2.0436242818832397

Epoch: 5| Step: 4
Training loss: 2.0396313667297363
Validation loss: 2.039930530773696

Epoch: 5| Step: 5
Training loss: 1.5484020709991455
Validation loss: 2.017172034068774

Epoch: 5| Step: 6
Training loss: 1.6427028179168701
Validation loss: 1.978546965506769

Epoch: 5| Step: 7
Training loss: 1.7949644327163696
Validation loss: 2.0403477658507643

Epoch: 5| Step: 8
Training loss: 1.8956445455551147
Validation loss: 1.9920628096467705

Epoch: 5| Step: 9
Training loss: 1.8212881088256836
Validation loss: 1.9834674942877986

Epoch: 5| Step: 10
Training loss: 1.2760165929794312
Validation loss: 2.0137580210162747

Epoch: 256| Step: 0
Training loss: 2.326892375946045
Validation loss: 2.0406652471070648

Epoch: 5| Step: 1
Training loss: 1.1869505643844604
Validation loss: 1.9754654540810535

Epoch: 5| Step: 2
Training loss: 1.2860190868377686
Validation loss: 1.962667647228446

Epoch: 5| Step: 3
Training loss: 1.4849263429641724
Validation loss: 1.986273124653806

Epoch: 5| Step: 4
Training loss: 1.2191423177719116
Validation loss: 2.0279471976782686

Epoch: 5| Step: 5
Training loss: 1.6661202907562256
Validation loss: 2.0344236435428744

Epoch: 5| Step: 6
Training loss: 2.2331058979034424
Validation loss: 2.0028935683670865

Epoch: 5| Step: 7
Training loss: 2.0353381633758545
Validation loss: 2.019051710764567

Epoch: 5| Step: 8
Training loss: 1.5726890563964844
Validation loss: 1.9886852977096394

Epoch: 5| Step: 9
Training loss: 1.7419607639312744
Validation loss: 2.0315277268809657

Epoch: 5| Step: 10
Training loss: 2.238018751144409
Validation loss: 2.043368931739561

Epoch: 257| Step: 0
Training loss: 1.8523824214935303
Validation loss: 2.03086043173267

Epoch: 5| Step: 1
Training loss: 2.125549793243408
Validation loss: 1.964606620932138

Epoch: 5| Step: 2
Training loss: 2.0846199989318848
Validation loss: 1.9872491039255613

Epoch: 5| Step: 3
Training loss: 1.5864003896713257
Validation loss: 2.0553173301040486

Epoch: 5| Step: 4
Training loss: 1.9416080713272095
Validation loss: 1.9860113141357258

Epoch: 5| Step: 5
Training loss: 1.1111565828323364
Validation loss: 1.9974324921126008

Epoch: 5| Step: 6
Training loss: 2.2593226432800293
Validation loss: 1.9880692343558035

Epoch: 5| Step: 7
Training loss: 0.9738427996635437
Validation loss: 2.0090290179816623

Epoch: 5| Step: 8
Training loss: 1.4899181127548218
Validation loss: 1.9640789006346016

Epoch: 5| Step: 9
Training loss: 1.7335708141326904
Validation loss: 2.0953816495915896

Epoch: 5| Step: 10
Training loss: 1.7492427825927734
Validation loss: 2.0045112332990094

Epoch: 258| Step: 0
Training loss: 1.5583560466766357
Validation loss: 1.9640996686873897

Epoch: 5| Step: 1
Training loss: 1.819146752357483
Validation loss: 2.0111610504888717

Epoch: 5| Step: 2
Training loss: 1.4287219047546387
Validation loss: 2.078302606459587

Epoch: 5| Step: 3
Training loss: 1.4551901817321777
Validation loss: 2.052211207728232

Epoch: 5| Step: 4
Training loss: 1.3365461826324463
Validation loss: 1.997474516591718

Epoch: 5| Step: 5
Training loss: 2.1882898807525635
Validation loss: 1.9108665143289874

Epoch: 5| Step: 6
Training loss: 1.3385159969329834
Validation loss: 2.009526255310223

Epoch: 5| Step: 7
Training loss: 2.0341553688049316
Validation loss: 2.006213531699232

Epoch: 5| Step: 8
Training loss: 1.1416966915130615
Validation loss: 1.990620946371427

Epoch: 5| Step: 9
Training loss: 2.012540578842163
Validation loss: 2.0081286609813733

Epoch: 5| Step: 10
Training loss: 2.263065814971924
Validation loss: 2.0401534982906875

Epoch: 259| Step: 0
Training loss: 1.871233582496643
Validation loss: 2.0159240589346936

Epoch: 5| Step: 1
Training loss: 1.6550629138946533
Validation loss: 2.0363185546731435

Epoch: 5| Step: 2
Training loss: 1.9350051879882812
Validation loss: 1.9858751348269883

Epoch: 5| Step: 3
Training loss: 1.307361125946045
Validation loss: 2.0655629224674676

Epoch: 5| Step: 4
Training loss: 1.5068519115447998
Validation loss: 2.0687986484137912

Epoch: 5| Step: 5
Training loss: 1.3060195446014404
Validation loss: 2.015538074636972

Epoch: 5| Step: 6
Training loss: 1.781245470046997
Validation loss: 2.0086236243606894

Epoch: 5| Step: 7
Training loss: 1.1546907424926758
Validation loss: 1.9825606166675527

Epoch: 5| Step: 8
Training loss: 2.092772960662842
Validation loss: 2.055119360646894

Epoch: 5| Step: 9
Training loss: 2.4290404319763184
Validation loss: 1.9933934942368539

Epoch: 5| Step: 10
Training loss: 1.634873628616333
Validation loss: 1.9911420832398117

Epoch: 260| Step: 0
Training loss: 1.4604724645614624
Validation loss: 1.9880162874857585

Epoch: 5| Step: 1
Training loss: 1.4860761165618896
Validation loss: 2.0457655383694555

Epoch: 5| Step: 2
Training loss: 1.4386985301971436
Validation loss: 2.044556825391708

Epoch: 5| Step: 3
Training loss: 1.301818609237671
Validation loss: 2.042797739787768

Epoch: 5| Step: 4
Training loss: 1.4671084880828857
Validation loss: 2.0338738913177163

Epoch: 5| Step: 5
Training loss: 2.4530513286590576
Validation loss: 1.9953725132890927

Epoch: 5| Step: 6
Training loss: 1.4320600032806396
Validation loss: 1.9978739369300105

Epoch: 5| Step: 7
Training loss: 1.5854995250701904
Validation loss: 2.0055594418638494

Epoch: 5| Step: 8
Training loss: 2.023444652557373
Validation loss: 1.9686790384272093

Epoch: 5| Step: 9
Training loss: 1.9352163076400757
Validation loss: 1.885285682575677

Epoch: 5| Step: 10
Training loss: 1.938586711883545
Validation loss: 1.9735733245008735

Epoch: 261| Step: 0
Training loss: 2.2228598594665527
Validation loss: 2.0054728600286666

Epoch: 5| Step: 1
Training loss: 1.760597586631775
Validation loss: 2.0243436739008915

Epoch: 5| Step: 2
Training loss: 1.3874298334121704
Validation loss: 1.9772298707756946

Epoch: 5| Step: 3
Training loss: 1.7143256664276123
Validation loss: 1.9285714164856942

Epoch: 5| Step: 4
Training loss: 1.0573017597198486
Validation loss: 1.9709882454205585

Epoch: 5| Step: 5
Training loss: 1.7099316120147705
Validation loss: 2.00122493825933

Epoch: 5| Step: 6
Training loss: 1.8615515232086182
Validation loss: 2.0368580561812206

Epoch: 5| Step: 7
Training loss: 1.550353765487671
Validation loss: 1.998929137824684

Epoch: 5| Step: 8
Training loss: 2.118574857711792
Validation loss: 1.9910245018620645

Epoch: 5| Step: 9
Training loss: 1.615265130996704
Validation loss: 1.9964467633155085

Epoch: 5| Step: 10
Training loss: 1.5051355361938477
Validation loss: 2.060056801765196

Epoch: 262| Step: 0
Training loss: 2.140373706817627
Validation loss: 2.000945491175498

Epoch: 5| Step: 1
Training loss: 1.5704554319381714
Validation loss: 1.9565708714146768

Epoch: 5| Step: 2
Training loss: 1.9883568286895752
Validation loss: 2.051476311940019

Epoch: 5| Step: 3
Training loss: 1.844785451889038
Validation loss: 1.9877755744482881

Epoch: 5| Step: 4
Training loss: 2.464613914489746
Validation loss: 2.0332095405106902

Epoch: 5| Step: 5
Training loss: 1.853329062461853
Validation loss: 2.0495576281701364

Epoch: 5| Step: 6
Training loss: 1.1111657619476318
Validation loss: 2.0265286353326615

Epoch: 5| Step: 7
Training loss: 2.027696371078491
Validation loss: 2.0232668897157073

Epoch: 5| Step: 8
Training loss: 1.462568998336792
Validation loss: 2.0465662069218133

Epoch: 5| Step: 9
Training loss: 1.0958976745605469
Validation loss: 1.9914138676017843

Epoch: 5| Step: 10
Training loss: 1.1888535022735596
Validation loss: 2.0361078080310615

Epoch: 263| Step: 0
Training loss: 1.7608171701431274
Validation loss: 2.0192548869758524

Epoch: 5| Step: 1
Training loss: 1.5860941410064697
Validation loss: 2.0032543059318297

Epoch: 5| Step: 2
Training loss: 1.6025129556655884
Validation loss: 2.0227367262686453

Epoch: 5| Step: 3
Training loss: 1.8740406036376953
Validation loss: 1.9814832454086633

Epoch: 5| Step: 4
Training loss: 1.3735431432724
Validation loss: 2.0291542776169313

Epoch: 5| Step: 5
Training loss: 1.963850736618042
Validation loss: 1.9879958398880497

Epoch: 5| Step: 6
Training loss: 1.5364387035369873
Validation loss: 1.9838933611428866

Epoch: 5| Step: 7
Training loss: 1.4860568046569824
Validation loss: 1.9949648995553293

Epoch: 5| Step: 8
Training loss: 1.5720131397247314
Validation loss: 2.0227738477850474

Epoch: 5| Step: 9
Training loss: 1.5651252269744873
Validation loss: 2.0212412457312308

Epoch: 5| Step: 10
Training loss: 1.9693020582199097
Validation loss: 2.032635945145802

Epoch: 264| Step: 0
Training loss: 1.7734285593032837
Validation loss: 1.9964007305842575

Epoch: 5| Step: 1
Training loss: 1.9879753589630127
Validation loss: 1.9724948713856358

Epoch: 5| Step: 2
Training loss: 1.3409230709075928
Validation loss: 2.0143167280381724

Epoch: 5| Step: 3
Training loss: 1.4442176818847656
Validation loss: 2.022848759928057

Epoch: 5| Step: 4
Training loss: 1.8507639169692993
Validation loss: 1.9603049550005185

Epoch: 5| Step: 5
Training loss: 1.730536699295044
Validation loss: 1.9768585312751032

Epoch: 5| Step: 6
Training loss: 1.5423476696014404
Validation loss: 2.025594865122149

Epoch: 5| Step: 7
Training loss: 1.4128798246383667
Validation loss: 1.9890535108504757

Epoch: 5| Step: 8
Training loss: 2.332099437713623
Validation loss: 2.0052988631750948

Epoch: 5| Step: 9
Training loss: 1.9414317607879639
Validation loss: 1.963256828246578

Epoch: 5| Step: 10
Training loss: 1.2035945653915405
Validation loss: 1.9549537217745216

Epoch: 265| Step: 0
Training loss: 1.6399511098861694
Validation loss: 2.014101659097979

Epoch: 5| Step: 1
Training loss: 1.9890873432159424
Validation loss: 1.997109333674113

Epoch: 5| Step: 2
Training loss: 1.609623670578003
Validation loss: 1.950389480078092

Epoch: 5| Step: 3
Training loss: 1.5203136205673218
Validation loss: 2.0291038508056314

Epoch: 5| Step: 4
Training loss: 1.7794923782348633
Validation loss: 2.0055195644337642

Epoch: 5| Step: 5
Training loss: 1.5107108354568481
Validation loss: 2.0360084246563654

Epoch: 5| Step: 6
Training loss: 2.4533498287200928
Validation loss: 2.0172689858303277

Epoch: 5| Step: 7
Training loss: 1.7104237079620361
Validation loss: 2.0602696980199506

Epoch: 5| Step: 8
Training loss: 1.454138994216919
Validation loss: 2.037994941075643

Epoch: 5| Step: 9
Training loss: 1.5514503717422485
Validation loss: 2.0605445574688654

Epoch: 5| Step: 10
Training loss: 1.778018832206726
Validation loss: 1.9951487228434572

Epoch: 266| Step: 0
Training loss: 2.218991756439209
Validation loss: 2.0570035160228772

Epoch: 5| Step: 1
Training loss: 0.9860566854476929
Validation loss: 1.954280786616828

Epoch: 5| Step: 2
Training loss: 1.243666410446167
Validation loss: 1.9904693429188063

Epoch: 5| Step: 3
Training loss: 1.5948965549468994
Validation loss: 1.9494976612829393

Epoch: 5| Step: 4
Training loss: 1.280482292175293
Validation loss: 2.020632290071057

Epoch: 5| Step: 5
Training loss: 2.0506627559661865
Validation loss: 1.9961140309610674

Epoch: 5| Step: 6
Training loss: 1.6333978176116943
Validation loss: 2.0038203026658747

Epoch: 5| Step: 7
Training loss: 1.937791109085083
Validation loss: 1.991195773565641

Epoch: 5| Step: 8
Training loss: 1.781521201133728
Validation loss: 1.9456298607651905

Epoch: 5| Step: 9
Training loss: 2.346259593963623
Validation loss: 2.0197637568237963

Epoch: 5| Step: 10
Training loss: 1.6115611791610718
Validation loss: 1.9824906728600944

Epoch: 267| Step: 0
Training loss: 1.2166032791137695
Validation loss: 2.006580352783203

Epoch: 5| Step: 1
Training loss: 1.2787511348724365
Validation loss: 2.0071097099652855

Epoch: 5| Step: 2
Training loss: 2.011627435684204
Validation loss: 2.008899470811249

Epoch: 5| Step: 3
Training loss: 1.6996581554412842
Validation loss: 1.9572238127390544

Epoch: 5| Step: 4
Training loss: 1.8224267959594727
Validation loss: 1.978902679617687

Epoch: 5| Step: 5
Training loss: 1.8629143238067627
Validation loss: 2.036953805595316

Epoch: 5| Step: 6
Training loss: 1.6494548320770264
Validation loss: 1.9705987232987598

Epoch: 5| Step: 7
Training loss: 1.754842758178711
Validation loss: 2.0268687086720623

Epoch: 5| Step: 8
Training loss: 1.5343643426895142
Validation loss: 2.0129714422328497

Epoch: 5| Step: 9
Training loss: 1.9524619579315186
Validation loss: 2.0089718180318035

Epoch: 5| Step: 10
Training loss: 1.707686424255371
Validation loss: 1.9868067310702415

Epoch: 268| Step: 0
Training loss: 2.0396568775177
Validation loss: 2.008231180970387

Epoch: 5| Step: 1
Training loss: 1.5920307636260986
Validation loss: 1.9764217369018062

Epoch: 5| Step: 2
Training loss: 1.8166831731796265
Validation loss: 1.9809696853801768

Epoch: 5| Step: 3
Training loss: 1.7565042972564697
Validation loss: 1.9746301661255539

Epoch: 5| Step: 4
Training loss: 1.3079090118408203
Validation loss: 2.0182922706809094

Epoch: 5| Step: 5
Training loss: 1.7871516942977905
Validation loss: 1.984604993174153

Epoch: 5| Step: 6
Training loss: 1.4999805688858032
Validation loss: 2.015417925773128

Epoch: 5| Step: 7
Training loss: 2.2240989208221436
Validation loss: 1.96698425662133

Epoch: 5| Step: 8
Training loss: 1.288811445236206
Validation loss: 1.985401484274095

Epoch: 5| Step: 9
Training loss: 1.4805223941802979
Validation loss: 1.966130232298246

Epoch: 5| Step: 10
Training loss: 1.9244353771209717
Validation loss: 1.9508124551465433

Epoch: 269| Step: 0
Training loss: 1.5651856660842896
Validation loss: 1.9893688873578144

Epoch: 5| Step: 1
Training loss: 1.5823880434036255
Validation loss: 1.9914387426068705

Epoch: 5| Step: 2
Training loss: 1.7058441638946533
Validation loss: 1.952145581604332

Epoch: 5| Step: 3
Training loss: 1.8518187999725342
Validation loss: 1.999672028326219

Epoch: 5| Step: 4
Training loss: 1.8175846338272095
Validation loss: 1.9900102205173944

Epoch: 5| Step: 5
Training loss: 1.1646102666854858
Validation loss: 2.051204107140982

Epoch: 5| Step: 6
Training loss: 1.4276516437530518
Validation loss: 1.9636903193689161

Epoch: 5| Step: 7
Training loss: 1.8422123193740845
Validation loss: 1.9823325551966184

Epoch: 5| Step: 8
Training loss: 1.836035966873169
Validation loss: 1.9541437536157586

Epoch: 5| Step: 9
Training loss: 1.8917604684829712
Validation loss: 2.0105520602195495

Epoch: 5| Step: 10
Training loss: 1.7275168895721436
Validation loss: 1.9435167556167932

Epoch: 270| Step: 0
Training loss: 2.078188419342041
Validation loss: 2.0163437692067956

Epoch: 5| Step: 1
Training loss: 1.4359807968139648
Validation loss: 1.9875947762561101

Epoch: 5| Step: 2
Training loss: 2.085660934448242
Validation loss: 1.9553231564901208

Epoch: 5| Step: 3
Training loss: 1.3652839660644531
Validation loss: 1.9950557242157638

Epoch: 5| Step: 4
Training loss: 1.4881633520126343
Validation loss: 1.991087112375485

Epoch: 5| Step: 5
Training loss: 1.3495540618896484
Validation loss: 1.9716701456295547

Epoch: 5| Step: 6
Training loss: 1.5272157192230225
Validation loss: 2.0061047461725052

Epoch: 5| Step: 7
Training loss: 2.000708818435669
Validation loss: 1.9945518944853096

Epoch: 5| Step: 8
Training loss: 1.6383788585662842
Validation loss: 1.999302347501119

Epoch: 5| Step: 9
Training loss: 1.2608951330184937
Validation loss: 2.0274872882391817

Epoch: 5| Step: 10
Training loss: 1.8269319534301758
Validation loss: 2.0219465301882837

Epoch: 271| Step: 0
Training loss: 1.508569359779358
Validation loss: 1.966215261849024

Epoch: 5| Step: 1
Training loss: 1.6593141555786133
Validation loss: 1.968922689396848

Epoch: 5| Step: 2
Training loss: 1.2067255973815918
Validation loss: 1.951676143113003

Epoch: 5| Step: 3
Training loss: 2.0292444229125977
Validation loss: 2.0133228801911875

Epoch: 5| Step: 4
Training loss: 2.1409637928009033
Validation loss: 1.9237523002009238

Epoch: 5| Step: 5
Training loss: 1.8081254959106445
Validation loss: 1.9767487292648644

Epoch: 5| Step: 6
Training loss: 1.1588561534881592
Validation loss: 2.023118975341961

Epoch: 5| Step: 7
Training loss: 1.4293897151947021
Validation loss: 1.9793943846097557

Epoch: 5| Step: 8
Training loss: 1.6034142971038818
Validation loss: 2.059876016391221

Epoch: 5| Step: 9
Training loss: 1.8340240716934204
Validation loss: 1.9994096140707693

Epoch: 5| Step: 10
Training loss: 1.9522618055343628
Validation loss: 1.9793414377397107

Epoch: 272| Step: 0
Training loss: 1.7746191024780273
Validation loss: 2.0067542137638217

Epoch: 5| Step: 1
Training loss: 1.7725969552993774
Validation loss: 1.9244360411038963

Epoch: 5| Step: 2
Training loss: 1.0211331844329834
Validation loss: 1.946589813437513

Epoch: 5| Step: 3
Training loss: 1.5950838327407837
Validation loss: 2.0064009235751246

Epoch: 5| Step: 4
Training loss: 1.4407850503921509
Validation loss: 1.9687622119021673

Epoch: 5| Step: 5
Training loss: 1.6320499181747437
Validation loss: 1.9495126329442507

Epoch: 5| Step: 6
Training loss: 1.9519697427749634
Validation loss: 1.9352952639261882

Epoch: 5| Step: 7
Training loss: 2.091374635696411
Validation loss: 1.955694313972227

Epoch: 5| Step: 8
Training loss: 1.7606121301651
Validation loss: 2.0207478320726784

Epoch: 5| Step: 9
Training loss: 1.1553592681884766
Validation loss: 1.9623167642983057

Epoch: 5| Step: 10
Training loss: 2.067528009414673
Validation loss: 1.9404262945216189

Epoch: 273| Step: 0
Training loss: 1.5015456676483154
Validation loss: 1.987243083215529

Epoch: 5| Step: 1
Training loss: 1.162085771560669
Validation loss: 1.9865035651832499

Epoch: 5| Step: 2
Training loss: 1.624018907546997
Validation loss: 1.9523498114719187

Epoch: 5| Step: 3
Training loss: 1.9528347253799438
Validation loss: 1.9401533488304383

Epoch: 5| Step: 4
Training loss: 2.017784833908081
Validation loss: 1.9637240286796325

Epoch: 5| Step: 5
Training loss: 1.4010206460952759
Validation loss: 1.9932626421733568

Epoch: 5| Step: 6
Training loss: 1.1765867471694946
Validation loss: 1.9051116089667044

Epoch: 5| Step: 7
Training loss: 1.7463499307632446
Validation loss: 1.9874452134614349

Epoch: 5| Step: 8
Training loss: 2.0385539531707764
Validation loss: 1.975509858900501

Epoch: 5| Step: 9
Training loss: 1.634939193725586
Validation loss: 1.9799414706486527

Epoch: 5| Step: 10
Training loss: 1.7212046384811401
Validation loss: 1.933770097712035

Epoch: 274| Step: 0
Training loss: 1.9092296361923218
Validation loss: 1.9933234466019498

Epoch: 5| Step: 1
Training loss: 1.6645004749298096
Validation loss: 2.025171523453087

Epoch: 5| Step: 2
Training loss: 1.6748754978179932
Validation loss: 2.0062752718566568

Epoch: 5| Step: 3
Training loss: 1.0758295059204102
Validation loss: 1.882979637833052

Epoch: 5| Step: 4
Training loss: 1.6261221170425415
Validation loss: 1.9516348825987948

Epoch: 5| Step: 5
Training loss: 1.6646515130996704
Validation loss: 1.978891904636096

Epoch: 5| Step: 6
Training loss: 1.365970492362976
Validation loss: 2.001544734483124

Epoch: 5| Step: 7
Training loss: 1.7850841283798218
Validation loss: 1.9112259931461786

Epoch: 5| Step: 8
Training loss: 1.7170966863632202
Validation loss: 1.9229294253933815

Epoch: 5| Step: 9
Training loss: 1.3566831350326538
Validation loss: 1.954662420416391

Epoch: 5| Step: 10
Training loss: 2.5829122066497803
Validation loss: 1.9697032923339515

Epoch: 275| Step: 0
Training loss: 2.08683443069458
Validation loss: 1.9860142661679177

Epoch: 5| Step: 1
Training loss: 1.279473066329956
Validation loss: 1.9504427294577322

Epoch: 5| Step: 2
Training loss: 2.431396007537842
Validation loss: 1.9472101388439056

Epoch: 5| Step: 3
Training loss: 1.6825920343399048
Validation loss: 1.9344746502496863

Epoch: 5| Step: 4
Training loss: 1.6237132549285889
Validation loss: 2.0014511103271158

Epoch: 5| Step: 5
Training loss: 1.5627343654632568
Validation loss: 1.986772173194475

Epoch: 5| Step: 6
Training loss: 1.4457910060882568
Validation loss: 1.93856515038398

Epoch: 5| Step: 7
Training loss: 1.411575198173523
Validation loss: 1.9493650300528413

Epoch: 5| Step: 8
Training loss: 1.887478232383728
Validation loss: 1.9312420519449378

Epoch: 5| Step: 9
Training loss: 1.6761858463287354
Validation loss: 2.0196337353798652

Epoch: 5| Step: 10
Training loss: 1.2599045038223267
Validation loss: 1.9816708231485018

Epoch: 276| Step: 0
Training loss: 1.3119817972183228
Validation loss: 1.9989562842153734

Epoch: 5| Step: 1
Training loss: 1.411257266998291
Validation loss: 1.9834904388714862

Epoch: 5| Step: 2
Training loss: 1.592340350151062
Validation loss: 1.9458151376375588

Epoch: 5| Step: 3
Training loss: 1.6659538745880127
Validation loss: 1.9765872660503592

Epoch: 5| Step: 4
Training loss: 1.4264910221099854
Validation loss: 1.9100002806673768

Epoch: 5| Step: 5
Training loss: 1.3949222564697266
Validation loss: 1.974479011310044

Epoch: 5| Step: 6
Training loss: 2.349112033843994
Validation loss: 1.9266000716916976

Epoch: 5| Step: 7
Training loss: 1.2302379608154297
Validation loss: 2.0586541673188568

Epoch: 5| Step: 8
Training loss: 1.4780654907226562
Validation loss: 1.9480102677499094

Epoch: 5| Step: 9
Training loss: 2.223938226699829
Validation loss: 1.9511531758052048

Epoch: 5| Step: 10
Training loss: 1.5875329971313477
Validation loss: 1.9660302195497739

Epoch: 277| Step: 0
Training loss: 1.6687043905258179
Validation loss: 1.957092305665375

Epoch: 5| Step: 1
Training loss: 1.8780139684677124
Validation loss: 1.9845125393200946

Epoch: 5| Step: 2
Training loss: 1.8363685607910156
Validation loss: 1.9473424803826116

Epoch: 5| Step: 3
Training loss: 1.582882285118103
Validation loss: 1.9772612946007841

Epoch: 5| Step: 4
Training loss: 1.6695600748062134
Validation loss: 2.012826536291389

Epoch: 5| Step: 5
Training loss: 1.5033581256866455
Validation loss: 1.9549087209086264

Epoch: 5| Step: 6
Training loss: 1.4565178155899048
Validation loss: 1.9900911597795383

Epoch: 5| Step: 7
Training loss: 1.7577106952667236
Validation loss: 1.9757751367425407

Epoch: 5| Step: 8
Training loss: 1.461676001548767
Validation loss: 1.959739887586204

Epoch: 5| Step: 9
Training loss: 1.9821641445159912
Validation loss: 1.9265582510220107

Epoch: 5| Step: 10
Training loss: 0.9636834263801575
Validation loss: 1.9210042876581992

Epoch: 278| Step: 0
Training loss: 1.9281800985336304
Validation loss: 1.982774406351069

Epoch: 5| Step: 1
Training loss: 1.6149629354476929
Validation loss: 2.0074267259208103

Epoch: 5| Step: 2
Training loss: 1.779632568359375
Validation loss: 1.9613869267125283

Epoch: 5| Step: 3
Training loss: 1.5706661939620972
Validation loss: 2.0233564402467463

Epoch: 5| Step: 4
Training loss: 1.450665831565857
Validation loss: 1.9803516928867628

Epoch: 5| Step: 5
Training loss: 1.32975435256958
Validation loss: 1.991380537709882

Epoch: 5| Step: 6
Training loss: 2.328131675720215
Validation loss: 2.040996774550407

Epoch: 5| Step: 7
Training loss: 1.5113071203231812
Validation loss: 1.9838224393065258

Epoch: 5| Step: 8
Training loss: 1.7909603118896484
Validation loss: 1.973292794278873

Epoch: 5| Step: 9
Training loss: 1.168931484222412
Validation loss: 2.0100421367153043

Epoch: 5| Step: 10
Training loss: 1.6060223579406738
Validation loss: 2.007338725110536

Epoch: 279| Step: 0
Training loss: 1.1840068101882935
Validation loss: 1.9301648806500178

Epoch: 5| Step: 1
Training loss: 0.8728445172309875
Validation loss: 1.997294246509511

Epoch: 5| Step: 2
Training loss: 1.7497966289520264
Validation loss: 1.9577048132496495

Epoch: 5| Step: 3
Training loss: 1.577402114868164
Validation loss: 1.9435162005885955

Epoch: 5| Step: 4
Training loss: 2.2077536582946777
Validation loss: 1.9140600863323416

Epoch: 5| Step: 5
Training loss: 2.1429123878479004
Validation loss: 1.9738010873076737

Epoch: 5| Step: 6
Training loss: 1.3918325901031494
Validation loss: 1.9486383135600756

Epoch: 5| Step: 7
Training loss: 1.825060248374939
Validation loss: 1.9524392158754411

Epoch: 5| Step: 8
Training loss: 1.2485253810882568
Validation loss: 1.9165600192162298

Epoch: 5| Step: 9
Training loss: 1.977996826171875
Validation loss: 1.9393281270098943

Epoch: 5| Step: 10
Training loss: 1.4238637685775757
Validation loss: 1.9635243492741739

Epoch: 280| Step: 0
Training loss: 1.5962145328521729
Validation loss: 1.9296102985259025

Epoch: 5| Step: 1
Training loss: 1.2439000606536865
Validation loss: 1.9720449409177225

Epoch: 5| Step: 2
Training loss: 1.7339776754379272
Validation loss: 1.9454006225832048

Epoch: 5| Step: 3
Training loss: 1.8748857975006104
Validation loss: 1.970168190617715

Epoch: 5| Step: 4
Training loss: 2.576725482940674
Validation loss: 2.00678789231085

Epoch: 5| Step: 5
Training loss: 1.5869213342666626
Validation loss: 1.989123813567623

Epoch: 5| Step: 6
Training loss: 1.9237897396087646
Validation loss: 1.9592601086503716

Epoch: 5| Step: 7
Training loss: 1.0007283687591553
Validation loss: 2.0121888934925036

Epoch: 5| Step: 8
Training loss: 1.487708330154419
Validation loss: 1.9845644825248308

Epoch: 5| Step: 9
Training loss: 1.747446060180664
Validation loss: 1.9709432714728898

Epoch: 5| Step: 10
Training loss: 1.2575732469558716
Validation loss: 1.981162291701122

Epoch: 281| Step: 0
Training loss: 1.6251437664031982
Validation loss: 1.9807341355149464

Epoch: 5| Step: 1
Training loss: 1.775193452835083
Validation loss: 2.016919153992848

Epoch: 5| Step: 2
Training loss: 1.5782078504562378
Validation loss: 1.959988458182222

Epoch: 5| Step: 3
Training loss: 1.4394491910934448
Validation loss: 1.9950171132241525

Epoch: 5| Step: 4
Training loss: 2.085289239883423
Validation loss: 1.9881925762340587

Epoch: 5| Step: 5
Training loss: 1.7877899408340454
Validation loss: 1.9663231680470128

Epoch: 5| Step: 6
Training loss: 1.693105936050415
Validation loss: 2.008476816197877

Epoch: 5| Step: 7
Training loss: 1.766222596168518
Validation loss: 2.0129822736145346

Epoch: 5| Step: 8
Training loss: 1.317840576171875
Validation loss: 1.9671610324613509

Epoch: 5| Step: 9
Training loss: 1.2137186527252197
Validation loss: 1.9441855261402745

Epoch: 5| Step: 10
Training loss: 1.747223138809204
Validation loss: 2.000097713162822

Epoch: 282| Step: 0
Training loss: 1.9756004810333252
Validation loss: 1.9624390550839004

Epoch: 5| Step: 1
Training loss: 2.0404117107391357
Validation loss: 1.9176351485713836

Epoch: 5| Step: 2
Training loss: 1.676269769668579
Validation loss: 1.977194422034807

Epoch: 5| Step: 3
Training loss: 1.5464720726013184
Validation loss: 1.978599682930977

Epoch: 5| Step: 4
Training loss: 1.9181886911392212
Validation loss: 1.9272390116927445

Epoch: 5| Step: 5
Training loss: 1.4443142414093018
Validation loss: 1.9598376494581982

Epoch: 5| Step: 6
Training loss: 1.415409803390503
Validation loss: 1.9588216402197396

Epoch: 5| Step: 7
Training loss: 1.0642330646514893
Validation loss: 1.9314841660120154

Epoch: 5| Step: 8
Training loss: 1.6660130023956299
Validation loss: 1.9646689917451592

Epoch: 5| Step: 9
Training loss: 2.0030646324157715
Validation loss: 1.991006887087258

Epoch: 5| Step: 10
Training loss: 0.9853679537773132
Validation loss: 1.966198839167113

Epoch: 283| Step: 0
Training loss: 2.112765312194824
Validation loss: 1.959235547691263

Epoch: 5| Step: 1
Training loss: 2.18816876411438
Validation loss: 1.9434244055901804

Epoch: 5| Step: 2
Training loss: 1.984147310256958
Validation loss: 1.9626376526330107

Epoch: 5| Step: 3
Training loss: 1.1925932168960571
Validation loss: 1.976680786378922

Epoch: 5| Step: 4
Training loss: 1.9819395542144775
Validation loss: 2.0027509479112524

Epoch: 5| Step: 5
Training loss: 1.130693793296814
Validation loss: 1.9452582392641293

Epoch: 5| Step: 6
Training loss: 1.1884583234786987
Validation loss: 1.9378118002286522

Epoch: 5| Step: 7
Training loss: 1.3689976930618286
Validation loss: 1.9797671635945637

Epoch: 5| Step: 8
Training loss: 1.3761186599731445
Validation loss: 1.9790964203496133

Epoch: 5| Step: 9
Training loss: 1.546098232269287
Validation loss: 1.934515312153806

Epoch: 5| Step: 10
Training loss: 2.0002315044403076
Validation loss: 2.0077481667200723

Epoch: 284| Step: 0
Training loss: 1.8220040798187256
Validation loss: 1.9903226872926116

Epoch: 5| Step: 1
Training loss: 1.5347856283187866
Validation loss: 2.0032971430850286

Epoch: 5| Step: 2
Training loss: 2.3370580673217773
Validation loss: 2.016445464985345

Epoch: 5| Step: 3
Training loss: 1.4106860160827637
Validation loss: 1.963420311609904

Epoch: 5| Step: 4
Training loss: 1.8298600912094116
Validation loss: 1.9910488756754066

Epoch: 5| Step: 5
Training loss: 1.1425387859344482
Validation loss: 1.9889029123449837

Epoch: 5| Step: 6
Training loss: 1.4857654571533203
Validation loss: 1.9495888474167034

Epoch: 5| Step: 7
Training loss: 1.4134470224380493
Validation loss: 2.024691984217654

Epoch: 5| Step: 8
Training loss: 1.2557270526885986
Validation loss: 1.9936004530998968

Epoch: 5| Step: 9
Training loss: 1.5696886777877808
Validation loss: 1.9812363245153939

Epoch: 5| Step: 10
Training loss: 1.6093604564666748
Validation loss: 1.9541392454537012

Epoch: 285| Step: 0
Training loss: 1.4943325519561768
Validation loss: 2.004014781726304

Epoch: 5| Step: 1
Training loss: 1.4358798265457153
Validation loss: 1.9929587776942919

Epoch: 5| Step: 2
Training loss: 1.5085471868515015
Validation loss: 1.9696249269670056

Epoch: 5| Step: 3
Training loss: 1.966848373413086
Validation loss: 1.9425198608829128

Epoch: 5| Step: 4
Training loss: 1.546533226966858
Validation loss: 1.941945698953444

Epoch: 5| Step: 5
Training loss: 1.691640853881836
Validation loss: 1.977640950551597

Epoch: 5| Step: 6
Training loss: 1.396045207977295
Validation loss: 1.999177079046926

Epoch: 5| Step: 7
Training loss: 1.5750974416732788
Validation loss: 1.9179279881138955

Epoch: 5| Step: 8
Training loss: 1.5991538763046265
Validation loss: 2.0026732772909184

Epoch: 5| Step: 9
Training loss: 1.7505054473876953
Validation loss: 1.944692301493819

Epoch: 5| Step: 10
Training loss: 1.5233724117279053
Validation loss: 1.9808566057553856

Epoch: 286| Step: 0
Training loss: 1.8505913019180298
Validation loss: 1.981789881183255

Epoch: 5| Step: 1
Training loss: 1.5231107473373413
Validation loss: 1.9799373034507997

Epoch: 5| Step: 2
Training loss: 1.1885039806365967
Validation loss: 1.9297807178189677

Epoch: 5| Step: 3
Training loss: 1.5848398208618164
Validation loss: 1.9545495971556632

Epoch: 5| Step: 4
Training loss: 1.602813482284546
Validation loss: 1.9651252326144968

Epoch: 5| Step: 5
Training loss: 1.5317418575286865
Validation loss: 1.970928333138907

Epoch: 5| Step: 6
Training loss: 1.8212435245513916
Validation loss: 2.0130714421631186

Epoch: 5| Step: 7
Training loss: 1.8661091327667236
Validation loss: 1.9122761885325115

Epoch: 5| Step: 8
Training loss: 1.9924657344818115
Validation loss: 1.9376835438512987

Epoch: 5| Step: 9
Training loss: 1.700116753578186
Validation loss: 1.9615948943681614

Epoch: 5| Step: 10
Training loss: 1.10513436794281
Validation loss: 1.9344550345533638

Epoch: 287| Step: 0
Training loss: 1.2130697965621948
Validation loss: 1.929065614618281

Epoch: 5| Step: 1
Training loss: 1.9018900394439697
Validation loss: 1.965195587886277

Epoch: 5| Step: 2
Training loss: 1.6911144256591797
Validation loss: 1.9588597641196301

Epoch: 5| Step: 3
Training loss: 1.4686013460159302
Validation loss: 1.9700784478136288

Epoch: 5| Step: 4
Training loss: 1.4279310703277588
Validation loss: 1.9794909902798232

Epoch: 5| Step: 5
Training loss: 1.4549823999404907
Validation loss: 1.9392584267482962

Epoch: 5| Step: 6
Training loss: 1.2474275827407837
Validation loss: 1.9127323781290362

Epoch: 5| Step: 7
Training loss: 1.7442314624786377
Validation loss: 1.9699232462913758

Epoch: 5| Step: 8
Training loss: 1.9243533611297607
Validation loss: 1.9527618115948093

Epoch: 5| Step: 9
Training loss: 1.9217236042022705
Validation loss: 1.9232623987300421

Epoch: 5| Step: 10
Training loss: 1.3108818531036377
Validation loss: 1.9482937474404611

Epoch: 288| Step: 0
Training loss: 1.4006344079971313
Validation loss: 1.957734730935866

Epoch: 5| Step: 1
Training loss: 1.8733307123184204
Validation loss: 1.9511229004911197

Epoch: 5| Step: 2
Training loss: 1.470434308052063
Validation loss: 1.9304713485061482

Epoch: 5| Step: 3
Training loss: 1.706716775894165
Validation loss: 1.9928756080647951

Epoch: 5| Step: 4
Training loss: 1.4791985750198364
Validation loss: 1.937542660261995

Epoch: 5| Step: 5
Training loss: 1.4358351230621338
Validation loss: 1.9300575845985002

Epoch: 5| Step: 6
Training loss: 1.4160881042480469
Validation loss: 1.935402726614347

Epoch: 5| Step: 7
Training loss: 1.9757869243621826
Validation loss: 1.965762520349154

Epoch: 5| Step: 8
Training loss: 1.3433852195739746
Validation loss: 2.051506878227316

Epoch: 5| Step: 9
Training loss: 2.011121988296509
Validation loss: 1.9595130669173373

Epoch: 5| Step: 10
Training loss: 1.5258307456970215
Validation loss: 1.9993015694361862

Epoch: 289| Step: 0
Training loss: 1.661057710647583
Validation loss: 1.9607999363253195

Epoch: 5| Step: 1
Training loss: 1.9204132556915283
Validation loss: 1.9541441894346667

Epoch: 5| Step: 2
Training loss: 2.248291254043579
Validation loss: 1.9604874221227502

Epoch: 5| Step: 3
Training loss: 1.193284034729004
Validation loss: 1.919154118466121

Epoch: 5| Step: 4
Training loss: 1.74565851688385
Validation loss: 1.8497738325467674

Epoch: 5| Step: 5
Training loss: 1.173219919204712
Validation loss: 1.9715890474216913

Epoch: 5| Step: 6
Training loss: 1.8233249187469482
Validation loss: 1.9446987464863768

Epoch: 5| Step: 7
Training loss: 1.4983628988265991
Validation loss: 1.928508359898803

Epoch: 5| Step: 8
Training loss: 1.5072764158248901
Validation loss: 1.9645656360092985

Epoch: 5| Step: 9
Training loss: 1.3103135824203491
Validation loss: 1.9643314858918548

Epoch: 5| Step: 10
Training loss: 1.4036329984664917
Validation loss: 1.9583955900643462

Epoch: 290| Step: 0
Training loss: 1.0996429920196533
Validation loss: 1.9683611598066104

Epoch: 5| Step: 1
Training loss: 1.1322181224822998
Validation loss: 2.0116144482807448

Epoch: 5| Step: 2
Training loss: 1.676581621170044
Validation loss: 1.9154648588549705

Epoch: 5| Step: 3
Training loss: 1.317551612854004
Validation loss: 1.9662645068219913

Epoch: 5| Step: 4
Training loss: 2.2973148822784424
Validation loss: 1.9539849770966398

Epoch: 5| Step: 5
Training loss: 1.871638536453247
Validation loss: 1.974851563412656

Epoch: 5| Step: 6
Training loss: 1.8960669040679932
Validation loss: 1.941934504816609

Epoch: 5| Step: 7
Training loss: 1.6982784271240234
Validation loss: 1.9614135398659656

Epoch: 5| Step: 8
Training loss: 1.5946650505065918
Validation loss: 2.0140447539667927

Epoch: 5| Step: 9
Training loss: 1.4178389310836792
Validation loss: 2.0289379076291154

Epoch: 5| Step: 10
Training loss: 1.2805447578430176
Validation loss: 1.9474750898217643

Epoch: 291| Step: 0
Training loss: 1.1628029346466064
Validation loss: 1.9223856349145212

Epoch: 5| Step: 1
Training loss: 1.5500630140304565
Validation loss: 1.9577989027064333

Epoch: 5| Step: 2
Training loss: 1.321628212928772
Validation loss: 1.9838384582150368

Epoch: 5| Step: 3
Training loss: 1.7695846557617188
Validation loss: 2.0316158058822795

Epoch: 5| Step: 4
Training loss: 1.9668508768081665
Validation loss: 1.9221348659966582

Epoch: 5| Step: 5
Training loss: 1.8330039978027344
Validation loss: 1.9530144045429845

Epoch: 5| Step: 6
Training loss: 0.9595798254013062
Validation loss: 1.9116950752914592

Epoch: 5| Step: 7
Training loss: 1.580522894859314
Validation loss: 1.983173248588398

Epoch: 5| Step: 8
Training loss: 1.420960783958435
Validation loss: 1.9665105163410146

Epoch: 5| Step: 9
Training loss: 1.7408440113067627
Validation loss: 1.9869637950774162

Epoch: 5| Step: 10
Training loss: 2.023860216140747
Validation loss: 1.9521595867731238

Epoch: 292| Step: 0
Training loss: 1.83895742893219
Validation loss: 1.9478984981454828

Epoch: 5| Step: 1
Training loss: 1.4357794523239136
Validation loss: 1.9365151492498254

Epoch: 5| Step: 2
Training loss: 1.7696529626846313
Validation loss: 1.9121018225146877

Epoch: 5| Step: 3
Training loss: 1.5426051616668701
Validation loss: 1.9311952232032694

Epoch: 5| Step: 4
Training loss: 1.5936191082000732
Validation loss: 2.02157917458524

Epoch: 5| Step: 5
Training loss: 1.3404613733291626
Validation loss: 1.9691447814305623

Epoch: 5| Step: 6
Training loss: 1.683145523071289
Validation loss: 1.9951955759397118

Epoch: 5| Step: 7
Training loss: 1.8815572261810303
Validation loss: 2.0392635099349485

Epoch: 5| Step: 8
Training loss: 1.60489821434021
Validation loss: 1.9955058213203185

Epoch: 5| Step: 9
Training loss: 1.8688501119613647
Validation loss: 1.9093437220460625

Epoch: 5| Step: 10
Training loss: 1.1075630187988281
Validation loss: 1.983148290264991

Epoch: 293| Step: 0
Training loss: 1.374781847000122
Validation loss: 1.9825817346572876

Epoch: 5| Step: 1
Training loss: 1.2427699565887451
Validation loss: 1.958046438873455

Epoch: 5| Step: 2
Training loss: 1.0626180171966553
Validation loss: 1.9736211248623428

Epoch: 5| Step: 3
Training loss: 1.3119834661483765
Validation loss: 1.943538893935501

Epoch: 5| Step: 4
Training loss: 1.8120189905166626
Validation loss: 2.004119505164444

Epoch: 5| Step: 5
Training loss: 1.6807632446289062
Validation loss: 1.941727533135363

Epoch: 5| Step: 6
Training loss: 2.0732197761535645
Validation loss: 1.9624163361005886

Epoch: 5| Step: 7
Training loss: 1.6378434896469116
Validation loss: 1.9774136568910332

Epoch: 5| Step: 8
Training loss: 1.3452205657958984
Validation loss: 1.922419027615619

Epoch: 5| Step: 9
Training loss: 1.6880683898925781
Validation loss: 1.9125216032869072

Epoch: 5| Step: 10
Training loss: 1.6358752250671387
Validation loss: 1.9806185114768244

Epoch: 294| Step: 0
Training loss: 1.4272674322128296
Validation loss: 1.9445898430321806

Epoch: 5| Step: 1
Training loss: 1.1097033023834229
Validation loss: 1.9917969908765567

Epoch: 5| Step: 2
Training loss: 1.4890077114105225
Validation loss: 1.9690508457922167

Epoch: 5| Step: 3
Training loss: 1.68137526512146
Validation loss: 1.8747334223921581

Epoch: 5| Step: 4
Training loss: 2.31353497505188
Validation loss: 1.9781082394302532

Epoch: 5| Step: 5
Training loss: 1.5741804838180542
Validation loss: 1.9766859649330057

Epoch: 5| Step: 6
Training loss: 1.400499939918518
Validation loss: 1.9819555744048087

Epoch: 5| Step: 7
Training loss: 1.6234757900238037
Validation loss: 1.9064003344505065

Epoch: 5| Step: 8
Training loss: 1.7669302225112915
Validation loss: 1.9291201727364653

Epoch: 5| Step: 9
Training loss: 1.4647973775863647
Validation loss: 1.917437441887394

Epoch: 5| Step: 10
Training loss: 1.145769715309143
Validation loss: 1.9290905562780236

Epoch: 295| Step: 0
Training loss: 1.967989206314087
Validation loss: 1.9464836018059843

Epoch: 5| Step: 1
Training loss: 1.2971655130386353
Validation loss: 1.9713006865593694

Epoch: 5| Step: 2
Training loss: 1.5044150352478027
Validation loss: 1.9717266931328723

Epoch: 5| Step: 3
Training loss: 1.2586259841918945
Validation loss: 1.9558531084368307

Epoch: 5| Step: 4
Training loss: 1.5048611164093018
Validation loss: 1.9700338609756962

Epoch: 5| Step: 5
Training loss: 1.3180333375930786
Validation loss: 1.942154138318954

Epoch: 5| Step: 6
Training loss: 1.7562921047210693
Validation loss: 1.939917851519841

Epoch: 5| Step: 7
Training loss: 1.9443371295928955
Validation loss: 1.9059005527086155

Epoch: 5| Step: 8
Training loss: 1.554114580154419
Validation loss: 1.9567645724101732

Epoch: 5| Step: 9
Training loss: 1.5802030563354492
Validation loss: 2.0040613925585182

Epoch: 5| Step: 10
Training loss: 1.5590081214904785
Validation loss: 1.9516178279794671

Epoch: 296| Step: 0
Training loss: 0.9669704437255859
Validation loss: 1.9320239866933515

Epoch: 5| Step: 1
Training loss: 1.633669137954712
Validation loss: 1.9337008050692979

Epoch: 5| Step: 2
Training loss: 1.7568334341049194
Validation loss: 1.9907892365609445

Epoch: 5| Step: 3
Training loss: 1.073354721069336
Validation loss: 1.9221320959829515

Epoch: 5| Step: 4
Training loss: 1.1717628240585327
Validation loss: 1.9258063993146342

Epoch: 5| Step: 5
Training loss: 1.5171747207641602
Validation loss: 1.9022209669954033

Epoch: 5| Step: 6
Training loss: 1.681501030921936
Validation loss: 1.9440870515761837

Epoch: 5| Step: 7
Training loss: 1.8936983346939087
Validation loss: 1.907798505598499

Epoch: 5| Step: 8
Training loss: 2.742917537689209
Validation loss: 1.9052430275947816

Epoch: 5| Step: 9
Training loss: 1.2784736156463623
Validation loss: 1.9524342424126082

Epoch: 5| Step: 10
Training loss: 1.4898223876953125
Validation loss: 1.927841078850531

Epoch: 297| Step: 0
Training loss: 1.70369553565979
Validation loss: 1.94347963025493

Epoch: 5| Step: 1
Training loss: 2.025407314300537
Validation loss: 1.9257252754703644

Epoch: 5| Step: 2
Training loss: 1.5678770542144775
Validation loss: 1.9326704650796869

Epoch: 5| Step: 3
Training loss: 1.3423386812210083
Validation loss: 1.9543706217119772

Epoch: 5| Step: 4
Training loss: 1.820924162864685
Validation loss: 1.967080908436929

Epoch: 5| Step: 5
Training loss: 1.2622164487838745
Validation loss: 1.9662195687652917

Epoch: 5| Step: 6
Training loss: 1.7962909936904907
Validation loss: 1.9598500036424207

Epoch: 5| Step: 7
Training loss: 1.6971566677093506
Validation loss: 1.9373063605318788

Epoch: 5| Step: 8
Training loss: 1.1513621807098389
Validation loss: 2.012279132361053

Epoch: 5| Step: 9
Training loss: 1.3426223993301392
Validation loss: 1.9608906776674333

Epoch: 5| Step: 10
Training loss: 1.5156821012496948
Validation loss: 1.984504835579985

Epoch: 298| Step: 0
Training loss: 1.2944071292877197
Validation loss: 1.9196908204786238

Epoch: 5| Step: 1
Training loss: 1.6569257974624634
Validation loss: 1.9630676008039905

Epoch: 5| Step: 2
Training loss: 1.4165652990341187
Validation loss: 1.943067922387072

Epoch: 5| Step: 3
Training loss: 1.771274209022522
Validation loss: 1.9799501434449227

Epoch: 5| Step: 4
Training loss: 1.4879601001739502
Validation loss: 1.996977283108619

Epoch: 5| Step: 5
Training loss: 2.2673728466033936
Validation loss: 1.9882048099271712

Epoch: 5| Step: 6
Training loss: 2.014308214187622
Validation loss: 1.9283196797934912

Epoch: 5| Step: 7
Training loss: 0.8473203778266907
Validation loss: 1.991788475744186

Epoch: 5| Step: 8
Training loss: 1.708683729171753
Validation loss: 1.955250757996754

Epoch: 5| Step: 9
Training loss: 1.5627986192703247
Validation loss: 1.9187995131297777

Epoch: 5| Step: 10
Training loss: 1.0896929502487183
Validation loss: 1.9391168445669196

Epoch: 299| Step: 0
Training loss: 1.6094928979873657
Validation loss: 1.9252361841099237

Epoch: 5| Step: 1
Training loss: 1.6931743621826172
Validation loss: 1.955246889463035

Epoch: 5| Step: 2
Training loss: 0.994462788105011
Validation loss: 1.9668612762164044

Epoch: 5| Step: 3
Training loss: 2.0674843788146973
Validation loss: 1.9537583025552894

Epoch: 5| Step: 4
Training loss: 1.1730515956878662
Validation loss: 1.8781202839266868

Epoch: 5| Step: 5
Training loss: 1.868465781211853
Validation loss: 1.9294109472664454

Epoch: 5| Step: 6
Training loss: 1.1127734184265137
Validation loss: 1.9234140483281945

Epoch: 5| Step: 7
Training loss: 2.0122244358062744
Validation loss: 1.976233841270529

Epoch: 5| Step: 8
Training loss: 1.8799244165420532
Validation loss: 1.9565655544239988

Epoch: 5| Step: 9
Training loss: 1.6234276294708252
Validation loss: 1.928148679835822

Epoch: 5| Step: 10
Training loss: 0.911675751209259
Validation loss: 1.956222672616282

Epoch: 300| Step: 0
Training loss: 1.6013705730438232
Validation loss: 1.986970724598054

Epoch: 5| Step: 1
Training loss: 2.084413766860962
Validation loss: 1.9335770786449473

Epoch: 5| Step: 2
Training loss: 1.7673933506011963
Validation loss: 1.9330207686270438

Epoch: 5| Step: 3
Training loss: 1.1854807138442993
Validation loss: 1.9299629619044643

Epoch: 5| Step: 4
Training loss: 1.2795315980911255
Validation loss: 1.9574142835473503

Epoch: 5| Step: 5
Training loss: 1.8855024576187134
Validation loss: 1.9696591515694895

Epoch: 5| Step: 6
Training loss: 1.5962425470352173
Validation loss: 1.9192908502394153

Epoch: 5| Step: 7
Training loss: 1.165667176246643
Validation loss: 1.9240688495738532

Epoch: 5| Step: 8
Training loss: 1.2666404247283936
Validation loss: 2.0049997504039476

Epoch: 5| Step: 9
Training loss: 1.7197049856185913
Validation loss: 1.946834635990922

Epoch: 5| Step: 10
Training loss: 1.4205937385559082
Validation loss: 1.965863202207832

Epoch: 301| Step: 0
Training loss: 1.891473412513733
Validation loss: 1.9940461138243317

Epoch: 5| Step: 1
Training loss: 1.7953733205795288
Validation loss: 1.9871465262546335

Epoch: 5| Step: 2
Training loss: 1.7338922023773193
Validation loss: 1.943932137181682

Epoch: 5| Step: 3
Training loss: 1.9966901540756226
Validation loss: 1.8911035086518975

Epoch: 5| Step: 4
Training loss: 1.662605881690979
Validation loss: 1.9306563792690155

Epoch: 5| Step: 5
Training loss: 1.1318187713623047
Validation loss: 1.9569851711232176

Epoch: 5| Step: 6
Training loss: 1.3247438669204712
Validation loss: 1.9342319221906765

Epoch: 5| Step: 7
Training loss: 1.2112321853637695
Validation loss: 1.9960646578060683

Epoch: 5| Step: 8
Training loss: 0.8592197299003601
Validation loss: 1.9516755239937895

Epoch: 5| Step: 9
Training loss: 1.7354074716567993
Validation loss: 1.9736807000252508

Epoch: 5| Step: 10
Training loss: 1.3256304264068604
Validation loss: 1.9998849361173567

Epoch: 302| Step: 0
Training loss: 1.2124969959259033
Validation loss: 1.9447072462369037

Epoch: 5| Step: 1
Training loss: 1.6412986516952515
Validation loss: 1.8917244095956125

Epoch: 5| Step: 2
Training loss: 0.9773025512695312
Validation loss: 1.9036679716520413

Epoch: 5| Step: 3
Training loss: 1.6120576858520508
Validation loss: 2.0016509961056452

Epoch: 5| Step: 4
Training loss: 2.152843475341797
Validation loss: 1.8688195828468568

Epoch: 5| Step: 5
Training loss: 1.1308681964874268
Validation loss: 1.9068261743873678

Epoch: 5| Step: 6
Training loss: 1.6161857843399048
Validation loss: 1.9452352857076993

Epoch: 5| Step: 7
Training loss: 1.8172887563705444
Validation loss: 1.9602981062345608

Epoch: 5| Step: 8
Training loss: 1.3905586004257202
Validation loss: 1.9867706145009687

Epoch: 5| Step: 9
Training loss: 1.8248240947723389
Validation loss: 1.998232049326743

Epoch: 5| Step: 10
Training loss: 1.605987310409546
Validation loss: 1.981387065302941

Epoch: 303| Step: 0
Training loss: 1.0132591724395752
Validation loss: 1.9015201535276187

Epoch: 5| Step: 1
Training loss: 1.5643256902694702
Validation loss: 1.9196963899879045

Epoch: 5| Step: 2
Training loss: 1.6228100061416626
Validation loss: 1.9899924762787358

Epoch: 5| Step: 3
Training loss: 1.5715744495391846
Validation loss: 1.945366749199488

Epoch: 5| Step: 4
Training loss: 1.1008121967315674
Validation loss: 1.944116332197702

Epoch: 5| Step: 5
Training loss: 2.3932125568389893
Validation loss: 1.9632211808235414

Epoch: 5| Step: 6
Training loss: 2.0343432426452637
Validation loss: 1.9587426775245256

Epoch: 5| Step: 7
Training loss: 1.180776596069336
Validation loss: 1.939752160861928

Epoch: 5| Step: 8
Training loss: 1.327598214149475
Validation loss: 2.0038806930665047

Epoch: 5| Step: 9
Training loss: 1.7142788171768188
Validation loss: 1.9421507453405729

Epoch: 5| Step: 10
Training loss: 1.2936283349990845
Validation loss: 1.9451665980841524

Epoch: 304| Step: 0
Training loss: 1.1517462730407715
Validation loss: 1.946795904508201

Epoch: 5| Step: 1
Training loss: 1.3420064449310303
Validation loss: 1.9556132567826139

Epoch: 5| Step: 2
Training loss: 1.1277806758880615
Validation loss: 1.9422827151513868

Epoch: 5| Step: 3
Training loss: 1.665369987487793
Validation loss: 2.017481050183696

Epoch: 5| Step: 4
Training loss: 2.0734479427337646
Validation loss: 1.9602490522528206

Epoch: 5| Step: 5
Training loss: 1.462240219116211
Validation loss: 1.9331276096323484

Epoch: 5| Step: 6
Training loss: 2.0711007118225098
Validation loss: 1.9743818724027244

Epoch: 5| Step: 7
Training loss: 1.5216401815414429
Validation loss: 1.9749539949560677

Epoch: 5| Step: 8
Training loss: 1.1900566816329956
Validation loss: 1.9580168031877088

Epoch: 5| Step: 9
Training loss: 2.045013904571533
Validation loss: 1.9771814013040194

Epoch: 5| Step: 10
Training loss: 1.0257863998413086
Validation loss: 1.9977429810390677

Epoch: 305| Step: 0
Training loss: 1.7270307540893555
Validation loss: 1.92108444757359

Epoch: 5| Step: 1
Training loss: 1.3366518020629883
Validation loss: 1.90235141400368

Epoch: 5| Step: 2
Training loss: 1.5352166891098022
Validation loss: 1.9601565304622854

Epoch: 5| Step: 3
Training loss: 1.467120885848999
Validation loss: 1.9015506736693844

Epoch: 5| Step: 4
Training loss: 1.5376116037368774
Validation loss: 1.9562708344510806

Epoch: 5| Step: 5
Training loss: 1.14322829246521
Validation loss: 1.983007691239798

Epoch: 5| Step: 6
Training loss: 1.4301865100860596
Validation loss: 1.926947638552676

Epoch: 5| Step: 7
Training loss: 1.9003973007202148
Validation loss: 1.9996155128684094

Epoch: 5| Step: 8
Training loss: 1.952845573425293
Validation loss: 1.896284980158652

Epoch: 5| Step: 9
Training loss: 1.2848529815673828
Validation loss: 1.9971485343030704

Epoch: 5| Step: 10
Training loss: 1.3624372482299805
Validation loss: 1.9875116578994259

Epoch: 306| Step: 0
Training loss: 1.4668216705322266
Validation loss: 1.9749445530676073

Epoch: 5| Step: 1
Training loss: 1.2166097164154053
Validation loss: 1.9567398922417754

Epoch: 5| Step: 2
Training loss: 1.6364132165908813
Validation loss: 1.9110940912718415

Epoch: 5| Step: 3
Training loss: 1.8449214696884155
Validation loss: 1.9281068719843382

Epoch: 5| Step: 4
Training loss: 1.6226451396942139
Validation loss: 1.9062027277485016

Epoch: 5| Step: 5
Training loss: 1.3166978359222412
Validation loss: 1.8895450920187018

Epoch: 5| Step: 6
Training loss: 1.555219054222107
Validation loss: 1.9185278518225557

Epoch: 5| Step: 7
Training loss: 1.4756011962890625
Validation loss: 1.9423796028219245

Epoch: 5| Step: 8
Training loss: 1.6648235321044922
Validation loss: 1.926633506692866

Epoch: 5| Step: 9
Training loss: 1.693155288696289
Validation loss: 1.9484655190539617

Epoch: 5| Step: 10
Training loss: 1.6446963548660278
Validation loss: 1.9700737742967502

Epoch: 307| Step: 0
Training loss: 1.9234898090362549
Validation loss: 1.9814925680878341

Epoch: 5| Step: 1
Training loss: 1.269648790359497
Validation loss: 1.93008219170314

Epoch: 5| Step: 2
Training loss: 1.923357605934143
Validation loss: 1.9867860976085867

Epoch: 5| Step: 3
Training loss: 1.197937250137329
Validation loss: 1.9420058778537217

Epoch: 5| Step: 4
Training loss: 1.689510703086853
Validation loss: 2.05307267045462

Epoch: 5| Step: 5
Training loss: 1.4429529905319214
Validation loss: 1.9619715059957197

Epoch: 5| Step: 6
Training loss: 0.9580283164978027
Validation loss: 2.0236484876243015

Epoch: 5| Step: 7
Training loss: 1.629602074623108
Validation loss: 2.000615789044288

Epoch: 5| Step: 8
Training loss: 1.5389986038208008
Validation loss: 1.9158585507382628

Epoch: 5| Step: 9
Training loss: 2.096737861633301
Validation loss: 1.9474174578984578

Epoch: 5| Step: 10
Training loss: 1.0388609170913696
Validation loss: 1.9190162907364547

Epoch: 308| Step: 0
Training loss: 1.2588447332382202
Validation loss: 1.9334135132451211

Epoch: 5| Step: 1
Training loss: 1.554240107536316
Validation loss: 1.9089224543622745

Epoch: 5| Step: 2
Training loss: 1.6914482116699219
Validation loss: 1.9683078809451031

Epoch: 5| Step: 3
Training loss: 1.5326976776123047
Validation loss: 1.9738895867460517

Epoch: 5| Step: 4
Training loss: 1.6601873636245728
Validation loss: 1.9315874858569073

Epoch: 5| Step: 5
Training loss: 1.2267367839813232
Validation loss: 1.8748238753247004

Epoch: 5| Step: 6
Training loss: 1.388074517250061
Validation loss: 1.9425111406592912

Epoch: 5| Step: 7
Training loss: 1.2830164432525635
Validation loss: 1.9621830614664222

Epoch: 5| Step: 8
Training loss: 1.3032864332199097
Validation loss: 1.9115422720550208

Epoch: 5| Step: 9
Training loss: 1.7142932415008545
Validation loss: 1.8620014293219453

Epoch: 5| Step: 10
Training loss: 1.7055673599243164
Validation loss: 1.9279387779133295

Epoch: 309| Step: 0
Training loss: 2.0123050212860107
Validation loss: 1.8703022990175473

Epoch: 5| Step: 1
Training loss: 1.2478282451629639
Validation loss: 1.9331909238651235

Epoch: 5| Step: 2
Training loss: 1.8465454578399658
Validation loss: 1.961709234022325

Epoch: 5| Step: 3
Training loss: 1.4503400325775146
Validation loss: 1.9334464919182561

Epoch: 5| Step: 4
Training loss: 1.5222522020339966
Validation loss: 1.9139772871489167

Epoch: 5| Step: 5
Training loss: 1.994319200515747
Validation loss: 1.9567358057986024

Epoch: 5| Step: 6
Training loss: 1.1864019632339478
Validation loss: 1.9411124324285856

Epoch: 5| Step: 7
Training loss: 1.4669760465621948
Validation loss: 1.9344600554435485

Epoch: 5| Step: 8
Training loss: 1.2387288808822632
Validation loss: 1.971841316069326

Epoch: 5| Step: 9
Training loss: 1.3197104930877686
Validation loss: 1.9828348672518166

Epoch: 5| Step: 10
Training loss: 1.3574128150939941
Validation loss: 1.9334538162395518

Epoch: 310| Step: 0
Training loss: 1.9160716533660889
Validation loss: 1.9872198938041605

Epoch: 5| Step: 1
Training loss: 1.116629719734192
Validation loss: 1.971702817947634

Epoch: 5| Step: 2
Training loss: 1.7271709442138672
Validation loss: 2.0147948726530998

Epoch: 5| Step: 3
Training loss: 1.817095160484314
Validation loss: 1.969869553401906

Epoch: 5| Step: 4
Training loss: 1.592764973640442
Validation loss: 2.03328279782367

Epoch: 5| Step: 5
Training loss: 1.6501572132110596
Validation loss: 2.0465271396021687

Epoch: 5| Step: 6
Training loss: 2.0112760066986084
Validation loss: 1.9481921183165682

Epoch: 5| Step: 7
Training loss: 1.557610273361206
Validation loss: 1.9489399950991395

Epoch: 5| Step: 8
Training loss: 1.5162315368652344
Validation loss: 1.9848554365096553

Epoch: 5| Step: 9
Training loss: 1.2468551397323608
Validation loss: 1.9908115543344969

Epoch: 5| Step: 10
Training loss: 0.6957453489303589
Validation loss: 1.9737014334688905

Epoch: 311| Step: 0
Training loss: 1.918756127357483
Validation loss: 1.9271628446476434

Epoch: 5| Step: 1
Training loss: 1.924119234085083
Validation loss: 1.9519815201400428

Epoch: 5| Step: 2
Training loss: 1.702047348022461
Validation loss: 1.946260247179257

Epoch: 5| Step: 3
Training loss: 1.1132190227508545
Validation loss: 1.943116198303879

Epoch: 5| Step: 4
Training loss: 1.784635305404663
Validation loss: 2.0041889413710563

Epoch: 5| Step: 5
Training loss: 1.358154058456421
Validation loss: 1.928852722208987

Epoch: 5| Step: 6
Training loss: 1.3226341009140015
Validation loss: 1.9749777137592275

Epoch: 5| Step: 7
Training loss: 1.0193344354629517
Validation loss: 1.9555747598730109

Epoch: 5| Step: 8
Training loss: 1.4903242588043213
Validation loss: 1.9560192913137457

Epoch: 5| Step: 9
Training loss: 1.8288501501083374
Validation loss: 1.8853973637345016

Epoch: 5| Step: 10
Training loss: 1.2879095077514648
Validation loss: 1.9244631862127652

Epoch: 312| Step: 0
Training loss: 2.251363515853882
Validation loss: 1.9365019952097247

Epoch: 5| Step: 1
Training loss: 1.3682212829589844
Validation loss: 1.8982374770666963

Epoch: 5| Step: 2
Training loss: 0.9236711263656616
Validation loss: 1.9538239830283708

Epoch: 5| Step: 3
Training loss: 1.6393520832061768
Validation loss: 1.8980209096785514

Epoch: 5| Step: 4
Training loss: 1.4997214078903198
Validation loss: 1.9137768847967989

Epoch: 5| Step: 5
Training loss: 1.5505797863006592
Validation loss: 1.9666583409873388

Epoch: 5| Step: 6
Training loss: 1.0606706142425537
Validation loss: 1.9910812198474843

Epoch: 5| Step: 7
Training loss: 1.6102927923202515
Validation loss: 1.9337259274657055

Epoch: 5| Step: 8
Training loss: 1.6399562358856201
Validation loss: 2.002039714526105

Epoch: 5| Step: 9
Training loss: 1.5673097372055054
Validation loss: 1.9849666664677281

Epoch: 5| Step: 10
Training loss: 1.276423454284668
Validation loss: 1.9151025843876663

Epoch: 313| Step: 0
Training loss: 1.4971753358840942
Validation loss: 1.912081044207337

Epoch: 5| Step: 1
Training loss: 1.24563467502594
Validation loss: 1.9520044839510353

Epoch: 5| Step: 2
Training loss: 1.3166744709014893
Validation loss: 1.9195209972320064

Epoch: 5| Step: 3
Training loss: 1.040573000907898
Validation loss: 1.9860675078566357

Epoch: 5| Step: 4
Training loss: 1.7449054718017578
Validation loss: 1.9291543704207226

Epoch: 5| Step: 5
Training loss: 1.4938764572143555
Validation loss: 1.8704442477995349

Epoch: 5| Step: 6
Training loss: 1.784456491470337
Validation loss: 1.952123922686423

Epoch: 5| Step: 7
Training loss: 1.3754647970199585
Validation loss: 1.997493843878469

Epoch: 5| Step: 8
Training loss: 1.362183928489685
Validation loss: 1.9290810451712659

Epoch: 5| Step: 9
Training loss: 1.2648398876190186
Validation loss: 1.9558881713498024

Epoch: 5| Step: 10
Training loss: 2.0633387565612793
Validation loss: 1.9266266925360567

Epoch: 314| Step: 0
Training loss: 0.9217256307601929
Validation loss: 1.9402184230025097

Epoch: 5| Step: 1
Training loss: 1.2784208059310913
Validation loss: 1.9694198716071345

Epoch: 5| Step: 2
Training loss: 1.780932068824768
Validation loss: 1.9343418113646969

Epoch: 5| Step: 3
Training loss: 0.744396984577179
Validation loss: 1.9661232117683656

Epoch: 5| Step: 4
Training loss: 1.825582504272461
Validation loss: 1.9224095985453615

Epoch: 5| Step: 5
Training loss: 1.6603748798370361
Validation loss: 1.9696180423100789

Epoch: 5| Step: 6
Training loss: 1.5367252826690674
Validation loss: 1.9286707934512888

Epoch: 5| Step: 7
Training loss: 1.3493640422821045
Validation loss: 1.960176093603975

Epoch: 5| Step: 8
Training loss: 1.5732135772705078
Validation loss: 1.968211725193967

Epoch: 5| Step: 9
Training loss: 1.498022198677063
Validation loss: 1.9079715692868797

Epoch: 5| Step: 10
Training loss: 1.9343109130859375
Validation loss: 1.9338601558439192

Epoch: 315| Step: 0
Training loss: 1.6685009002685547
Validation loss: 1.9642777955660256

Epoch: 5| Step: 1
Training loss: 1.772489309310913
Validation loss: 1.9255030488455167

Epoch: 5| Step: 2
Training loss: 0.9372113943099976
Validation loss: 1.8705034743073166

Epoch: 5| Step: 3
Training loss: 1.807326078414917
Validation loss: 1.9916797376448108

Epoch: 5| Step: 4
Training loss: 1.4295241832733154
Validation loss: 1.965242858855955

Epoch: 5| Step: 5
Training loss: 1.2701811790466309
Validation loss: 1.9372165510731358

Epoch: 5| Step: 6
Training loss: 1.6018108129501343
Validation loss: 1.9360869840909076

Epoch: 5| Step: 7
Training loss: 1.4399421215057373
Validation loss: 1.9435528170677923

Epoch: 5| Step: 8
Training loss: 1.9807672500610352
Validation loss: 1.9368617739728702

Epoch: 5| Step: 9
Training loss: 1.2366063594818115
Validation loss: 1.9611659742170764

Epoch: 5| Step: 10
Training loss: 1.2162468433380127
Validation loss: 1.941544622503301

Epoch: 316| Step: 0
Training loss: 1.7696545124053955
Validation loss: 1.9203331778126378

Epoch: 5| Step: 1
Training loss: 1.5510526895523071
Validation loss: 1.929073808013752

Epoch: 5| Step: 2
Training loss: 1.5826551914215088
Validation loss: 1.927630380917621

Epoch: 5| Step: 3
Training loss: 1.5747687816619873
Validation loss: 1.9849912684450868

Epoch: 5| Step: 4
Training loss: 1.0307252407073975
Validation loss: 1.937275271261892

Epoch: 5| Step: 5
Training loss: 1.897099256515503
Validation loss: 1.9715811949904247

Epoch: 5| Step: 6
Training loss: 1.624924898147583
Validation loss: 1.9753449783530286

Epoch: 5| Step: 7
Training loss: 1.3427207469940186
Validation loss: 1.975590322607307

Epoch: 5| Step: 8
Training loss: 1.4520363807678223
Validation loss: 1.9438151108321322

Epoch: 5| Step: 9
Training loss: 1.2221698760986328
Validation loss: 1.9576860986730105

Epoch: 5| Step: 10
Training loss: 1.299296259880066
Validation loss: 2.019893597531062

Epoch: 317| Step: 0
Training loss: 1.3848506212234497
Validation loss: 1.998826015380121

Epoch: 5| Step: 1
Training loss: 1.0315115451812744
Validation loss: 1.9454739080962313

Epoch: 5| Step: 2
Training loss: 1.6682720184326172
Validation loss: 1.9964824491931545

Epoch: 5| Step: 3
Training loss: 1.5556468963623047
Validation loss: 1.9246060335507957

Epoch: 5| Step: 4
Training loss: 1.6519434452056885
Validation loss: 1.9256074582376788

Epoch: 5| Step: 5
Training loss: 1.203690767288208
Validation loss: 2.0246944722308906

Epoch: 5| Step: 6
Training loss: 1.9162819385528564
Validation loss: 1.9209156279922814

Epoch: 5| Step: 7
Training loss: 1.6155369281768799
Validation loss: 1.9422472497468353

Epoch: 5| Step: 8
Training loss: 1.7235918045043945
Validation loss: 1.9777114237508466

Epoch: 5| Step: 9
Training loss: 1.1484062671661377
Validation loss: 1.8631818614980227

Epoch: 5| Step: 10
Training loss: 1.4357974529266357
Validation loss: 2.0068031639181156

Epoch: 318| Step: 0
Training loss: 1.5935561656951904
Validation loss: 1.9708336450720345

Epoch: 5| Step: 1
Training loss: 0.769031822681427
Validation loss: 1.916049116401262

Epoch: 5| Step: 2
Training loss: 1.5420879125595093
Validation loss: 1.9437575391543809

Epoch: 5| Step: 3
Training loss: 1.1869149208068848
Validation loss: 1.9439611640027774

Epoch: 5| Step: 4
Training loss: 1.0279496908187866
Validation loss: 1.9499328110807685

Epoch: 5| Step: 5
Training loss: 1.468074083328247
Validation loss: 1.8886558086641374

Epoch: 5| Step: 6
Training loss: 1.9864351749420166
Validation loss: 1.9662083169465423

Epoch: 5| Step: 7
Training loss: 1.6631238460540771
Validation loss: 1.94721556222567

Epoch: 5| Step: 8
Training loss: 1.893916368484497
Validation loss: 1.99472943429024

Epoch: 5| Step: 9
Training loss: 1.7290436029434204
Validation loss: 1.9933638188146776

Epoch: 5| Step: 10
Training loss: 1.606031894683838
Validation loss: 1.9597370137450516

Epoch: 319| Step: 0
Training loss: 1.2906873226165771
Validation loss: 1.926472867688825

Epoch: 5| Step: 1
Training loss: 1.3547499179840088
Validation loss: 1.9469947520122732

Epoch: 5| Step: 2
Training loss: 1.2085336446762085
Validation loss: 1.943788456660445

Epoch: 5| Step: 3
Training loss: 1.459879755973816
Validation loss: 1.9474683730832991

Epoch: 5| Step: 4
Training loss: 1.7970044612884521
Validation loss: 1.9065304802310081

Epoch: 5| Step: 5
Training loss: 1.4537303447723389
Validation loss: 1.947597683116954

Epoch: 5| Step: 6
Training loss: 1.2153620719909668
Validation loss: 1.963694199439018

Epoch: 5| Step: 7
Training loss: 1.809406042098999
Validation loss: 1.9619351920261179

Epoch: 5| Step: 8
Training loss: 1.220941185951233
Validation loss: 1.9259485685697166

Epoch: 5| Step: 9
Training loss: 1.9445626735687256
Validation loss: 1.9260514397774973

Epoch: 5| Step: 10
Training loss: 1.3323520421981812
Validation loss: 1.981511046809535

Epoch: 320| Step: 0
Training loss: 1.5045487880706787
Validation loss: 1.9448197234061457

Epoch: 5| Step: 1
Training loss: 1.4895403385162354
Validation loss: 1.8899238699225969

Epoch: 5| Step: 2
Training loss: 1.5485225915908813
Validation loss: 1.9457376618539133

Epoch: 5| Step: 3
Training loss: 1.3220188617706299
Validation loss: 2.0137031514157533

Epoch: 5| Step: 4
Training loss: 1.1868747472763062
Validation loss: 1.9380091826121013

Epoch: 5| Step: 5
Training loss: 1.2842919826507568
Validation loss: 1.980982898384012

Epoch: 5| Step: 6
Training loss: 2.287670850753784
Validation loss: 1.9789618881799842

Epoch: 5| Step: 7
Training loss: 1.8413108587265015
Validation loss: 1.9414953852212558

Epoch: 5| Step: 8
Training loss: 2.088214635848999
Validation loss: 1.9549044601378902

Epoch: 5| Step: 9
Training loss: 0.9157663583755493
Validation loss: 1.9002625326956473

Epoch: 5| Step: 10
Training loss: 0.961466372013092
Validation loss: 1.9305193424224854

Epoch: 321| Step: 0
Training loss: 1.5087844133377075
Validation loss: 1.9099116197196386

Epoch: 5| Step: 1
Training loss: 1.260105013847351
Validation loss: 1.9023596650810652

Epoch: 5| Step: 2
Training loss: 1.1617443561553955
Validation loss: 1.9990110679339337

Epoch: 5| Step: 3
Training loss: 1.7518657445907593
Validation loss: 1.9913945685150802

Epoch: 5| Step: 4
Training loss: 1.6989164352416992
Validation loss: 1.9051544679108487

Epoch: 5| Step: 5
Training loss: 1.3619747161865234
Validation loss: 1.9354970814079366

Epoch: 5| Step: 6
Training loss: 1.0557961463928223
Validation loss: 1.9320307072772775

Epoch: 5| Step: 7
Training loss: 1.1675097942352295
Validation loss: 1.9994599434637255

Epoch: 5| Step: 8
Training loss: 0.9762636423110962
Validation loss: 1.9651730650214738

Epoch: 5| Step: 9
Training loss: 2.185105562210083
Validation loss: 1.9511124600646317

Epoch: 5| Step: 10
Training loss: 2.3721325397491455
Validation loss: 1.927178527719231

Epoch: 322| Step: 0
Training loss: 1.6655528545379639
Validation loss: 1.9574973403766591

Epoch: 5| Step: 1
Training loss: 1.3233428001403809
Validation loss: 1.9066679746873918

Epoch: 5| Step: 2
Training loss: 1.3669884204864502
Validation loss: 1.8784160178194764

Epoch: 5| Step: 3
Training loss: 1.1700023412704468
Validation loss: 1.9501446024064095

Epoch: 5| Step: 4
Training loss: 1.1595563888549805
Validation loss: 1.9229501857552478

Epoch: 5| Step: 5
Training loss: 1.7286030054092407
Validation loss: 1.9580015174804195

Epoch: 5| Step: 6
Training loss: 1.7290246486663818
Validation loss: 1.9027316595918389

Epoch: 5| Step: 7
Training loss: 0.8708972930908203
Validation loss: 1.9608319959332865

Epoch: 5| Step: 8
Training loss: 1.9591407775878906
Validation loss: 1.952835605990502

Epoch: 5| Step: 9
Training loss: 2.0750391483306885
Validation loss: 1.9430312469441404

Epoch: 5| Step: 10
Training loss: 1.2038720846176147
Validation loss: 1.968203636907762

Epoch: 323| Step: 0
Training loss: 1.9835777282714844
Validation loss: 1.9642093258519326

Epoch: 5| Step: 1
Training loss: 0.994539737701416
Validation loss: 1.9990838202097083

Epoch: 5| Step: 2
Training loss: 1.1675994396209717
Validation loss: 1.9488600454022806

Epoch: 5| Step: 3
Training loss: 1.5821208953857422
Validation loss: 2.019855107030561

Epoch: 5| Step: 4
Training loss: 1.3754056692123413
Validation loss: 1.9503441241479689

Epoch: 5| Step: 5
Training loss: 1.6218898296356201
Validation loss: 1.9600344729679886

Epoch: 5| Step: 6
Training loss: 1.5814238786697388
Validation loss: 1.9544143958758282

Epoch: 5| Step: 7
Training loss: 1.632887840270996
Validation loss: 1.955190089441115

Epoch: 5| Step: 8
Training loss: 1.4304372072219849
Validation loss: 1.9454109463640439

Epoch: 5| Step: 9
Training loss: 1.3484838008880615
Validation loss: 1.9370356810990201

Epoch: 5| Step: 10
Training loss: 1.1720917224884033
Validation loss: 1.9545305646875852

Epoch: 324| Step: 0
Training loss: 1.5148515701293945
Validation loss: 1.973303218041697

Epoch: 5| Step: 1
Training loss: 1.1976922750473022
Validation loss: 1.9510453465164348

Epoch: 5| Step: 2
Training loss: 1.167214274406433
Validation loss: 1.8925021733007124

Epoch: 5| Step: 3
Training loss: 1.5713751316070557
Validation loss: 1.9084380467732747

Epoch: 5| Step: 4
Training loss: 1.3698365688323975
Validation loss: 1.9460917160075197

Epoch: 5| Step: 5
Training loss: 1.3867685794830322
Validation loss: 1.9741117095434537

Epoch: 5| Step: 6
Training loss: 1.6688213348388672
Validation loss: 1.9790927338343796

Epoch: 5| Step: 7
Training loss: 1.428708791732788
Validation loss: 1.9753126175172868

Epoch: 5| Step: 8
Training loss: 1.6418602466583252
Validation loss: 1.9813703785660446

Epoch: 5| Step: 9
Training loss: 1.3286672830581665
Validation loss: 1.9308550280909385

Epoch: 5| Step: 10
Training loss: 1.5208927392959595
Validation loss: 1.9787809630875945

Epoch: 325| Step: 0
Training loss: 2.020993709564209
Validation loss: 1.9344411857666508

Epoch: 5| Step: 1
Training loss: 1.5134679079055786
Validation loss: 1.9367504632601173

Epoch: 5| Step: 2
Training loss: 1.399884819984436
Validation loss: 1.9431565141165128

Epoch: 5| Step: 3
Training loss: 1.9096266031265259
Validation loss: 1.9299673854663808

Epoch: 5| Step: 4
Training loss: 1.2944399118423462
Validation loss: 1.9890614325000393

Epoch: 5| Step: 5
Training loss: 1.1938955783843994
Validation loss: 1.9511823449083554

Epoch: 5| Step: 6
Training loss: 1.454402208328247
Validation loss: 1.9101889235998994

Epoch: 5| Step: 7
Training loss: 1.37674081325531
Validation loss: 1.9508247708761564

Epoch: 5| Step: 8
Training loss: 0.9205865859985352
Validation loss: 1.9428577115458827

Epoch: 5| Step: 9
Training loss: 1.3648407459259033
Validation loss: 1.9351605728108396

Epoch: 5| Step: 10
Training loss: 1.6964504718780518
Validation loss: 1.910261446429837

Epoch: 326| Step: 0
Training loss: 1.915716528892517
Validation loss: 1.9210623400185698

Epoch: 5| Step: 1
Training loss: 1.6526124477386475
Validation loss: 1.886287171353576

Epoch: 5| Step: 2
Training loss: 1.0656760931015015
Validation loss: 1.9377249081929524

Epoch: 5| Step: 3
Training loss: 1.5598366260528564
Validation loss: 1.9467097879737936

Epoch: 5| Step: 4
Training loss: 1.6670048236846924
Validation loss: 1.902957667586624

Epoch: 5| Step: 5
Training loss: 1.10907781124115
Validation loss: 1.9202471574147542

Epoch: 5| Step: 6
Training loss: 1.5231584310531616
Validation loss: 1.9485062527400192

Epoch: 5| Step: 7
Training loss: 0.9752503633499146
Validation loss: 1.948641320710541

Epoch: 5| Step: 8
Training loss: 1.708120346069336
Validation loss: 1.882096008587909

Epoch: 5| Step: 9
Training loss: 1.5400266647338867
Validation loss: 1.914073759509671

Epoch: 5| Step: 10
Training loss: 1.6227861642837524
Validation loss: 1.9457005249556674

Epoch: 327| Step: 0
Training loss: 0.7577654123306274
Validation loss: 1.8852371182492984

Epoch: 5| Step: 1
Training loss: 1.837529182434082
Validation loss: 1.867394349908316

Epoch: 5| Step: 2
Training loss: 1.33622145652771
Validation loss: 1.8940681360101188

Epoch: 5| Step: 3
Training loss: 1.5225927829742432
Validation loss: 1.8662376865263908

Epoch: 5| Step: 4
Training loss: 1.2067959308624268
Validation loss: 1.9956886037703483

Epoch: 5| Step: 5
Training loss: 2.1322712898254395
Validation loss: 1.9114110982546242

Epoch: 5| Step: 6
Training loss: 1.3711225986480713
Validation loss: 1.9905030932477725

Epoch: 5| Step: 7
Training loss: 1.1986196041107178
Validation loss: 2.008676371266765

Epoch: 5| Step: 8
Training loss: 1.80645751953125
Validation loss: 2.019014476447977

Epoch: 5| Step: 9
Training loss: 1.7572078704833984
Validation loss: 1.9766956619037095

Epoch: 5| Step: 10
Training loss: 1.371651291847229
Validation loss: 2.0156401741889214

Epoch: 328| Step: 0
Training loss: 1.2946245670318604
Validation loss: 1.9848261821654536

Epoch: 5| Step: 1
Training loss: 1.163704514503479
Validation loss: 1.9640906997906264

Epoch: 5| Step: 2
Training loss: 1.8507068157196045
Validation loss: 1.9349602486497612

Epoch: 5| Step: 3
Training loss: 1.4468257427215576
Validation loss: 1.9530347893314977

Epoch: 5| Step: 4
Training loss: 1.6037238836288452
Validation loss: 1.9502726985562233

Epoch: 5| Step: 5
Training loss: 1.117748498916626
Validation loss: 1.9847584052752423

Epoch: 5| Step: 6
Training loss: 1.492119550704956
Validation loss: 1.950417976225576

Epoch: 5| Step: 7
Training loss: 1.6972728967666626
Validation loss: 1.8694249186464535

Epoch: 5| Step: 8
Training loss: 1.5475102663040161
Validation loss: 1.8719231518366004

Epoch: 5| Step: 9
Training loss: 1.237001657485962
Validation loss: 1.9626058224708802

Epoch: 5| Step: 10
Training loss: 1.017295241355896
Validation loss: 1.9027654355572117

Epoch: 329| Step: 0
Training loss: 1.2033268213272095
Validation loss: 1.9577527161567443

Epoch: 5| Step: 1
Training loss: 1.1771297454833984
Validation loss: 1.9633457429947392

Epoch: 5| Step: 2
Training loss: 1.4050079584121704
Validation loss: 1.922653503315423

Epoch: 5| Step: 3
Training loss: 2.5524284839630127
Validation loss: 1.9273256217279742

Epoch: 5| Step: 4
Training loss: 0.9863902926445007
Validation loss: 1.9006841105799521

Epoch: 5| Step: 5
Training loss: 1.5553916692733765
Validation loss: 1.8781491684657272

Epoch: 5| Step: 6
Training loss: 1.2593613862991333
Validation loss: 1.8796942669858214

Epoch: 5| Step: 7
Training loss: 1.3068372011184692
Validation loss: 1.8902824847928938

Epoch: 5| Step: 8
Training loss: 1.5889840126037598
Validation loss: 1.9059503745007258

Epoch: 5| Step: 9
Training loss: 1.5750916004180908
Validation loss: 1.9073235309252174

Epoch: 5| Step: 10
Training loss: 1.887010931968689
Validation loss: 1.8972269899101668

Epoch: 330| Step: 0
Training loss: 1.061652421951294
Validation loss: 1.9260561914854153

Epoch: 5| Step: 1
Training loss: 1.2053083181381226
Validation loss: 1.9280283938172043

Epoch: 5| Step: 2
Training loss: 1.426297903060913
Validation loss: 1.9547517145833662

Epoch: 5| Step: 3
Training loss: 1.4901362657546997
Validation loss: 1.9410874843597412

Epoch: 5| Step: 4
Training loss: 1.6583964824676514
Validation loss: 1.947300862240535

Epoch: 5| Step: 5
Training loss: 1.969569206237793
Validation loss: 1.94215468693805

Epoch: 5| Step: 6
Training loss: 1.2461271286010742
Validation loss: 1.9119714049882786

Epoch: 5| Step: 7
Training loss: 1.8307969570159912
Validation loss: 1.936468824263542

Epoch: 5| Step: 8
Training loss: 1.2992702722549438
Validation loss: 1.9386754766587289

Epoch: 5| Step: 9
Training loss: 1.507972002029419
Validation loss: 1.9709223931835544

Epoch: 5| Step: 10
Training loss: 1.4452565908432007
Validation loss: 1.9826622893733363

Epoch: 331| Step: 0
Training loss: 1.6042671203613281
Validation loss: 1.8929025434678601

Epoch: 5| Step: 1
Training loss: 0.7522759437561035
Validation loss: 1.8539683639362294

Epoch: 5| Step: 2
Training loss: 1.3821680545806885
Validation loss: 1.9811445974534558

Epoch: 5| Step: 3
Training loss: 1.593851923942566
Validation loss: 1.9347843329111736

Epoch: 5| Step: 4
Training loss: 1.1635555028915405
Validation loss: 1.9349594141847344

Epoch: 5| Step: 5
Training loss: 1.8534576892852783
Validation loss: 1.9617330476801882

Epoch: 5| Step: 6
Training loss: 1.6435668468475342
Validation loss: 1.8660676658794444

Epoch: 5| Step: 7
Training loss: 1.3252906799316406
Validation loss: 1.9237078723087107

Epoch: 5| Step: 8
Training loss: 1.7304786443710327
Validation loss: 1.9299536007706837

Epoch: 5| Step: 9
Training loss: 1.6994292736053467
Validation loss: 1.9061659330962806

Epoch: 5| Step: 10
Training loss: 1.2757705450057983
Validation loss: 1.8992380634430917

Epoch: 332| Step: 0
Training loss: 1.0547330379486084
Validation loss: 1.9415217548288324

Epoch: 5| Step: 1
Training loss: 1.4658268690109253
Validation loss: 1.926393816548009

Epoch: 5| Step: 2
Training loss: 1.7921288013458252
Validation loss: 1.9137414834832633

Epoch: 5| Step: 3
Training loss: 1.7571016550064087
Validation loss: 1.9420772316635295

Epoch: 5| Step: 4
Training loss: 2.0868499279022217
Validation loss: 1.920123528408748

Epoch: 5| Step: 5
Training loss: 0.9010431170463562
Validation loss: 1.9316700530308548

Epoch: 5| Step: 6
Training loss: 1.3521372079849243
Validation loss: 1.9285453865605016

Epoch: 5| Step: 7
Training loss: 1.6254135370254517
Validation loss: 1.9528013544697915

Epoch: 5| Step: 8
Training loss: 1.3437883853912354
Validation loss: 1.9299654114630915

Epoch: 5| Step: 9
Training loss: 0.8218733072280884
Validation loss: 1.9934641789364558

Epoch: 5| Step: 10
Training loss: 1.5939301252365112
Validation loss: 1.9337774835607058

Epoch: 333| Step: 0
Training loss: 1.3422768115997314
Validation loss: 2.004294821011123

Epoch: 5| Step: 1
Training loss: 1.6681430339813232
Validation loss: 1.997928782175946

Epoch: 5| Step: 2
Training loss: 1.1343921422958374
Validation loss: 2.0165572679170998

Epoch: 5| Step: 3
Training loss: 1.0958045721054077
Validation loss: 1.9425362130647064

Epoch: 5| Step: 4
Training loss: 1.3073492050170898
Validation loss: 1.8958144341745684

Epoch: 5| Step: 5
Training loss: 1.7000443935394287
Validation loss: 2.0013821637758644

Epoch: 5| Step: 6
Training loss: 1.9312841892242432
Validation loss: 2.0057616926008657

Epoch: 5| Step: 7
Training loss: 1.9493366479873657
Validation loss: 1.9900554944110174

Epoch: 5| Step: 8
Training loss: 1.5601444244384766
Validation loss: 1.8809002266135266

Epoch: 5| Step: 9
Training loss: 1.11809504032135
Validation loss: 1.9108152543344805

Epoch: 5| Step: 10
Training loss: 1.1165345907211304
Validation loss: 1.9355315726290467

Epoch: 334| Step: 0
Training loss: 1.1852271556854248
Validation loss: 1.9140967963844218

Epoch: 5| Step: 1
Training loss: 1.5371053218841553
Validation loss: 1.9368167487523889

Epoch: 5| Step: 2
Training loss: 1.8407951593399048
Validation loss: 1.9166685009515414

Epoch: 5| Step: 3
Training loss: 1.0664279460906982
Validation loss: 1.9440681947174894

Epoch: 5| Step: 4
Training loss: 1.1208995580673218
Validation loss: 1.946610612253989

Epoch: 5| Step: 5
Training loss: 1.4931700229644775
Validation loss: 1.9865935951150873

Epoch: 5| Step: 6
Training loss: 1.442509412765503
Validation loss: 1.9303027711888796

Epoch: 5| Step: 7
Training loss: 1.4664276838302612
Validation loss: 1.9261469533366542

Epoch: 5| Step: 8
Training loss: 1.9874694347381592
Validation loss: 1.9135893647388746

Epoch: 5| Step: 9
Training loss: 0.9379929304122925
Validation loss: 1.9401104360498407

Epoch: 5| Step: 10
Training loss: 1.5340828895568848
Validation loss: 2.008048317765677

Epoch: 335| Step: 0
Training loss: 0.9727678298950195
Validation loss: 2.0005624063553347

Epoch: 5| Step: 1
Training loss: 1.3494137525558472
Validation loss: 1.9110455782182756

Epoch: 5| Step: 2
Training loss: 1.3666133880615234
Validation loss: 1.947828790192963

Epoch: 5| Step: 3
Training loss: 1.4787242412567139
Validation loss: 1.960394900332215

Epoch: 5| Step: 4
Training loss: 1.5530967712402344
Validation loss: 1.8805340836125035

Epoch: 5| Step: 5
Training loss: 1.4373868703842163
Validation loss: 1.9396494332180227

Epoch: 5| Step: 6
Training loss: 1.6944973468780518
Validation loss: 1.942392308224914

Epoch: 5| Step: 7
Training loss: 1.0283946990966797
Validation loss: 1.9801732365803053

Epoch: 5| Step: 8
Training loss: 1.524728536605835
Validation loss: 1.928737614744453

Epoch: 5| Step: 9
Training loss: 1.492375373840332
Validation loss: 1.924128818255599

Epoch: 5| Step: 10
Training loss: 1.8488235473632812
Validation loss: 1.8977316335965229

Epoch: 336| Step: 0
Training loss: 1.6078641414642334
Validation loss: 1.9046403836178523

Epoch: 5| Step: 1
Training loss: 1.312457799911499
Validation loss: 1.9633739430417296

Epoch: 5| Step: 2
Training loss: 1.9925987720489502
Validation loss: 1.9126082722858717

Epoch: 5| Step: 3
Training loss: 1.5779904127120972
Validation loss: 1.9095041559588524

Epoch: 5| Step: 4
Training loss: 1.3505280017852783
Validation loss: 1.9613600853950746

Epoch: 5| Step: 5
Training loss: 1.1881402730941772
Validation loss: 1.9115202760183683

Epoch: 5| Step: 6
Training loss: 1.6141560077667236
Validation loss: 1.9372750405342347

Epoch: 5| Step: 7
Training loss: 1.9347721338272095
Validation loss: 1.9647500284256474

Epoch: 5| Step: 8
Training loss: 1.0380184650421143
Validation loss: 1.9641254768576673

Epoch: 5| Step: 9
Training loss: 0.8476192355155945
Validation loss: 2.0034376126463695

Epoch: 5| Step: 10
Training loss: 1.2976125478744507
Validation loss: 1.9309825435761483

Epoch: 337| Step: 0
Training loss: 2.0582997798919678
Validation loss: 1.9211275628817979

Epoch: 5| Step: 1
Training loss: 1.386680006980896
Validation loss: 1.9107782712546728

Epoch: 5| Step: 2
Training loss: 1.0518749952316284
Validation loss: 1.9979834146397089

Epoch: 5| Step: 3
Training loss: 1.517273187637329
Validation loss: 1.8899465683967835

Epoch: 5| Step: 4
Training loss: 1.3425213098526
Validation loss: 1.907093506987377

Epoch: 5| Step: 5
Training loss: 1.1851366758346558
Validation loss: 1.873445749282837

Epoch: 5| Step: 6
Training loss: 1.3605509996414185
Validation loss: 1.8475258529827159

Epoch: 5| Step: 7
Training loss: 1.3203858137130737
Validation loss: 1.8504832483107043

Epoch: 5| Step: 8
Training loss: 1.0099009275436401
Validation loss: 1.907617389514882

Epoch: 5| Step: 9
Training loss: 1.590624213218689
Validation loss: 1.916327609810778

Epoch: 5| Step: 10
Training loss: 1.4699071645736694
Validation loss: 2.0200572898311

Epoch: 338| Step: 0
Training loss: 1.2972285747528076
Validation loss: 1.8870451193983837

Epoch: 5| Step: 1
Training loss: 1.3785154819488525
Validation loss: 1.8926376476082751

Epoch: 5| Step: 2
Training loss: 0.9466155767440796
Validation loss: 1.9288349741248674

Epoch: 5| Step: 3
Training loss: 1.7420707941055298
Validation loss: 1.9139907590804561

Epoch: 5| Step: 4
Training loss: 1.1861540079116821
Validation loss: 1.878629457566046

Epoch: 5| Step: 5
Training loss: 1.2443349361419678
Validation loss: 1.8880590469606462

Epoch: 5| Step: 6
Training loss: 1.8204494714736938
Validation loss: 1.9044473722416868

Epoch: 5| Step: 7
Training loss: 0.9536164999008179
Validation loss: 1.928893744304616

Epoch: 5| Step: 8
Training loss: 1.638238549232483
Validation loss: 1.8833322883934103

Epoch: 5| Step: 9
Training loss: 1.658164620399475
Validation loss: 1.9014121024839339

Epoch: 5| Step: 10
Training loss: 1.6334766149520874
Validation loss: 1.9680766354324997

Epoch: 339| Step: 0
Training loss: 1.6559760570526123
Validation loss: 1.8973846461183281

Epoch: 5| Step: 1
Training loss: 1.0282385349273682
Validation loss: 1.9720141067299792

Epoch: 5| Step: 2
Training loss: 1.2601884603500366
Validation loss: 2.008560606228408

Epoch: 5| Step: 3
Training loss: 1.4303420782089233
Validation loss: 1.9266246544417513

Epoch: 5| Step: 4
Training loss: 1.7160046100616455
Validation loss: 1.9286566703550276

Epoch: 5| Step: 5
Training loss: 1.6300369501113892
Validation loss: 1.9707839001891434

Epoch: 5| Step: 6
Training loss: 1.3430891036987305
Validation loss: 1.9276546624399

Epoch: 5| Step: 7
Training loss: 1.236223578453064
Validation loss: 1.966357672086326

Epoch: 5| Step: 8
Training loss: 1.25043523311615
Validation loss: 1.9887116134807628

Epoch: 5| Step: 9
Training loss: 1.9068714380264282
Validation loss: 1.948926874386367

Epoch: 5| Step: 10
Training loss: 1.0998204946517944
Validation loss: 1.9732194280111661

Epoch: 340| Step: 0
Training loss: 1.4929510354995728
Validation loss: 1.8942731208698724

Epoch: 5| Step: 1
Training loss: 1.7558587789535522
Validation loss: 1.8874264455610705

Epoch: 5| Step: 2
Training loss: 0.9548748135566711
Validation loss: 1.9254804285623695

Epoch: 5| Step: 3
Training loss: 1.515106439590454
Validation loss: 1.9211285652652863

Epoch: 5| Step: 4
Training loss: 1.329996109008789
Validation loss: 1.8427415278650099

Epoch: 5| Step: 5
Training loss: 1.7193132638931274
Validation loss: 1.8980215595614525

Epoch: 5| Step: 6
Training loss: 1.3773424625396729
Validation loss: 1.8528900659212502

Epoch: 5| Step: 7
Training loss: 1.1573050022125244
Validation loss: 1.8280798619793308

Epoch: 5| Step: 8
Training loss: 1.1336872577667236
Validation loss: 1.8940541616050146

Epoch: 5| Step: 9
Training loss: 1.4915690422058105
Validation loss: 1.8840100278136551

Epoch: 5| Step: 10
Training loss: 1.4709970951080322
Validation loss: 1.8642612426511702

Epoch: 341| Step: 0
Training loss: 1.294249176979065
Validation loss: 1.945967879346622

Epoch: 5| Step: 1
Training loss: 0.9647110104560852
Validation loss: 1.9434619231890606

Epoch: 5| Step: 2
Training loss: 2.220907211303711
Validation loss: 1.9147503593916535

Epoch: 5| Step: 3
Training loss: 0.9234193563461304
Validation loss: 1.9419775752611057

Epoch: 5| Step: 4
Training loss: 0.9347071647644043
Validation loss: 1.9265646857600058

Epoch: 5| Step: 5
Training loss: 1.3328661918640137
Validation loss: 1.8461399296278596

Epoch: 5| Step: 6
Training loss: 1.9933280944824219
Validation loss: 1.8818180484156455

Epoch: 5| Step: 7
Training loss: 1.302581548690796
Validation loss: 1.9134942664895007

Epoch: 5| Step: 8
Training loss: 1.1128177642822266
Validation loss: 1.8830304030449159

Epoch: 5| Step: 9
Training loss: 1.693193793296814
Validation loss: 1.9574754135583037

Epoch: 5| Step: 10
Training loss: 1.6201969385147095
Validation loss: 1.9217601540268108

Epoch: 342| Step: 0
Training loss: 1.2233319282531738
Validation loss: 1.96918825949392

Epoch: 5| Step: 1
Training loss: 1.8078464269638062
Validation loss: 1.9049598811775126

Epoch: 5| Step: 2
Training loss: 1.235600233078003
Validation loss: 1.9281432910632061

Epoch: 5| Step: 3
Training loss: 1.041710615158081
Validation loss: 1.9562694398305749

Epoch: 5| Step: 4
Training loss: 1.6945701837539673
Validation loss: 1.8626982755558465

Epoch: 5| Step: 5
Training loss: 1.6059297323226929
Validation loss: 1.936486465956575

Epoch: 5| Step: 6
Training loss: 1.5210697650909424
Validation loss: 1.9808786389648274

Epoch: 5| Step: 7
Training loss: 1.3691532611846924
Validation loss: 1.944723052363242

Epoch: 5| Step: 8
Training loss: 1.0339972972869873
Validation loss: 1.9252096042838147

Epoch: 5| Step: 9
Training loss: 1.352642297744751
Validation loss: 1.9156804302687287

Epoch: 5| Step: 10
Training loss: 1.6776823997497559
Validation loss: 1.8984358361972276

Epoch: 343| Step: 0
Training loss: 2.03645920753479
Validation loss: 1.9668803497027325

Epoch: 5| Step: 1
Training loss: 1.417903184890747
Validation loss: 1.9026168982187908

Epoch: 5| Step: 2
Training loss: 1.7441209554672241
Validation loss: 1.8740620408006894

Epoch: 5| Step: 3
Training loss: 0.9686071276664734
Validation loss: 1.9155349859627344

Epoch: 5| Step: 4
Training loss: 1.703620195388794
Validation loss: 1.8979124023068337

Epoch: 5| Step: 5
Training loss: 0.6634765863418579
Validation loss: 1.9761214666469122

Epoch: 5| Step: 6
Training loss: 1.800073266029358
Validation loss: 1.9154193785882765

Epoch: 5| Step: 7
Training loss: 1.1598646640777588
Validation loss: 1.8965056891082435

Epoch: 5| Step: 8
Training loss: 1.3601326942443848
Validation loss: 1.9425764494044806

Epoch: 5| Step: 9
Training loss: 1.1606312990188599
Validation loss: 1.9520461520841044

Epoch: 5| Step: 10
Training loss: 1.6654657125473022
Validation loss: 1.9093938617296116

Epoch: 344| Step: 0
Training loss: 1.3459231853485107
Validation loss: 1.926053685526694

Epoch: 5| Step: 1
Training loss: 1.4027775526046753
Validation loss: 1.989447444997808

Epoch: 5| Step: 2
Training loss: 1.3143870830535889
Validation loss: 1.892445356615128

Epoch: 5| Step: 3
Training loss: 1.104280948638916
Validation loss: 1.9536535227170555

Epoch: 5| Step: 4
Training loss: 1.4369299411773682
Validation loss: 1.929991683652324

Epoch: 5| Step: 5
Training loss: 1.7804510593414307
Validation loss: 1.9280659152615456

Epoch: 5| Step: 6
Training loss: 1.2144277095794678
Validation loss: 1.8128393657745854

Epoch: 5| Step: 7
Training loss: 1.4798732995986938
Validation loss: 1.9493365890236312

Epoch: 5| Step: 8
Training loss: 1.520090103149414
Validation loss: 1.9207912363031858

Epoch: 5| Step: 9
Training loss: 1.5579618215560913
Validation loss: 1.9274788928288284

Epoch: 5| Step: 10
Training loss: 1.3885198831558228
Validation loss: 1.900544689547631

Epoch: 345| Step: 0
Training loss: 1.584969162940979
Validation loss: 1.905025553959672

Epoch: 5| Step: 1
Training loss: 1.2588194608688354
Validation loss: 1.8490074155151204

Epoch: 5| Step: 2
Training loss: 1.4917646646499634
Validation loss: 1.9583668529346425

Epoch: 5| Step: 3
Training loss: 1.6600595712661743
Validation loss: 1.9235013518282162

Epoch: 5| Step: 4
Training loss: 1.424818754196167
Validation loss: 1.9375164124273485

Epoch: 5| Step: 5
Training loss: 2.1549770832061768
Validation loss: 1.8571816259814846

Epoch: 5| Step: 6
Training loss: 1.4243483543395996
Validation loss: 1.9307080263732581

Epoch: 5| Step: 7
Training loss: 1.4642457962036133
Validation loss: 1.9150154616243096

Epoch: 5| Step: 8
Training loss: 1.0687830448150635
Validation loss: 1.9298962649478708

Epoch: 5| Step: 9
Training loss: 1.0758213996887207
Validation loss: 1.9585104642375823

Epoch: 5| Step: 10
Training loss: 0.8444675207138062
Validation loss: 1.9410864960762761

Epoch: 346| Step: 0
Training loss: 1.6760413646697998
Validation loss: 1.9198493726791874

Epoch: 5| Step: 1
Training loss: 1.6671106815338135
Validation loss: 1.9557407645769016

Epoch: 5| Step: 2
Training loss: 1.3688563108444214
Validation loss: 1.9285002036761212

Epoch: 5| Step: 3
Training loss: 1.5038461685180664
Validation loss: 1.991394712078956

Epoch: 5| Step: 4
Training loss: 1.1564152240753174
Validation loss: 1.9594379368648733

Epoch: 5| Step: 5
Training loss: 1.3657677173614502
Validation loss: 1.9576475492087744

Epoch: 5| Step: 6
Training loss: 0.9581842422485352
Validation loss: 2.0162268889847623

Epoch: 5| Step: 7
Training loss: 1.2101669311523438
Validation loss: 1.9769196420587518

Epoch: 5| Step: 8
Training loss: 2.075432300567627
Validation loss: 1.9292910355393604

Epoch: 5| Step: 9
Training loss: 1.6141217947006226
Validation loss: 1.9396957274406188

Epoch: 5| Step: 10
Training loss: 1.4641423225402832
Validation loss: 1.9522013920609669

Epoch: 347| Step: 0
Training loss: 1.7290645837783813
Validation loss: 1.9365537217868272

Epoch: 5| Step: 1
Training loss: 1.0682756900787354
Validation loss: 1.9078611596938102

Epoch: 5| Step: 2
Training loss: 0.7858369946479797
Validation loss: 1.919420688383041

Epoch: 5| Step: 3
Training loss: 1.14011549949646
Validation loss: 1.9335847144485803

Epoch: 5| Step: 4
Training loss: 1.3977946043014526
Validation loss: 1.9208040737336682

Epoch: 5| Step: 5
Training loss: 2.1194872856140137
Validation loss: 1.952633725699558

Epoch: 5| Step: 6
Training loss: 1.167811632156372
Validation loss: 1.9214510725390526

Epoch: 5| Step: 7
Training loss: 1.3638981580734253
Validation loss: 1.8866703971739738

Epoch: 5| Step: 8
Training loss: 2.1789193153381348
Validation loss: 1.8957474359902002

Epoch: 5| Step: 9
Training loss: 1.4330161809921265
Validation loss: 1.9740298665979856

Epoch: 5| Step: 10
Training loss: 0.7815005779266357
Validation loss: 1.9198710559516825

Epoch: 348| Step: 0
Training loss: 1.6276273727416992
Validation loss: 1.904350749907955

Epoch: 5| Step: 1
Training loss: 1.666662573814392
Validation loss: 1.9039503964044715

Epoch: 5| Step: 2
Training loss: 1.9845218658447266
Validation loss: 1.9489042605123212

Epoch: 5| Step: 3
Training loss: 1.1384862661361694
Validation loss: 1.8599561888684508

Epoch: 5| Step: 4
Training loss: 1.5558044910430908
Validation loss: 1.9098811636688888

Epoch: 5| Step: 5
Training loss: 1.209673523902893
Validation loss: 1.8380981760640298

Epoch: 5| Step: 6
Training loss: 0.9797887802124023
Validation loss: 1.926293767908568

Epoch: 5| Step: 7
Training loss: 1.3739475011825562
Validation loss: 1.9750576942197737

Epoch: 5| Step: 8
Training loss: 0.9795303344726562
Validation loss: 1.9434606362414617

Epoch: 5| Step: 9
Training loss: 1.4325754642486572
Validation loss: 1.9727687451147264

Epoch: 5| Step: 10
Training loss: 1.3463727235794067
Validation loss: 1.877265836602898

Epoch: 349| Step: 0
Training loss: 1.322150707244873
Validation loss: 1.9659522271925403

Epoch: 5| Step: 1
Training loss: 1.6092884540557861
Validation loss: 1.9037032063289354

Epoch: 5| Step: 2
Training loss: 1.5626981258392334
Validation loss: 1.9111919697894846

Epoch: 5| Step: 3
Training loss: 1.2718427181243896
Validation loss: 1.923340392369096

Epoch: 5| Step: 4
Training loss: 1.2160917520523071
Validation loss: 1.9349731155621108

Epoch: 5| Step: 5
Training loss: 1.1647183895111084
Validation loss: 1.8801691685953448

Epoch: 5| Step: 6
Training loss: 2.1585071086883545
Validation loss: 1.9391033982717862

Epoch: 5| Step: 7
Training loss: 1.4418704509735107
Validation loss: 1.8746736511107414

Epoch: 5| Step: 8
Training loss: 1.0236042737960815
Validation loss: 1.913763464138072

Epoch: 5| Step: 9
Training loss: 1.4016247987747192
Validation loss: 1.8236044042853898

Epoch: 5| Step: 10
Training loss: 1.3047518730163574
Validation loss: 1.9221349890514086

Epoch: 350| Step: 0
Training loss: 1.781818151473999
Validation loss: 1.996549319195491

Epoch: 5| Step: 1
Training loss: 1.6460939645767212
Validation loss: 1.9107937940987207

Epoch: 5| Step: 2
Training loss: 0.5010745525360107
Validation loss: 1.9335212117882186

Epoch: 5| Step: 3
Training loss: 1.7309749126434326
Validation loss: 1.9852348219963811

Epoch: 5| Step: 4
Training loss: 1.5903065204620361
Validation loss: 1.9687301215305124

Epoch: 5| Step: 5
Training loss: 1.375523328781128
Validation loss: 2.005975810430383

Epoch: 5| Step: 6
Training loss: 2.2903027534484863
Validation loss: 2.043367216663976

Epoch: 5| Step: 7
Training loss: 1.0687053203582764
Validation loss: 1.8954476669270506

Epoch: 5| Step: 8
Training loss: 1.0997718572616577
Validation loss: 1.9004132901468584

Epoch: 5| Step: 9
Training loss: 1.006678819656372
Validation loss: 1.9514465178212812

Epoch: 5| Step: 10
Training loss: 1.48344886302948
Validation loss: 1.928580230282199

Epoch: 351| Step: 0
Training loss: 1.171937346458435
Validation loss: 1.9010587917861117

Epoch: 5| Step: 1
Training loss: 1.3508002758026123
Validation loss: 1.9167342403883576

Epoch: 5| Step: 2
Training loss: 1.0897562503814697
Validation loss: 1.892074538815406

Epoch: 5| Step: 3
Training loss: 1.7082029581069946
Validation loss: 1.9144032462950675

Epoch: 5| Step: 4
Training loss: 1.0218548774719238
Validation loss: 1.9996753123498732

Epoch: 5| Step: 5
Training loss: 1.4478845596313477
Validation loss: 1.9791661488112582

Epoch: 5| Step: 6
Training loss: 1.5595942735671997
Validation loss: 2.006958471831455

Epoch: 5| Step: 7
Training loss: 0.9597236514091492
Validation loss: 1.905610107606457

Epoch: 5| Step: 8
Training loss: 1.6955715417861938
Validation loss: 1.8753348230033793

Epoch: 5| Step: 9
Training loss: 1.6805260181427002
Validation loss: 1.9222826547520135

Epoch: 5| Step: 10
Training loss: 1.518341064453125
Validation loss: 1.9174435189975205

Epoch: 352| Step: 0
Training loss: 1.5675873756408691
Validation loss: 1.9375418847607029

Epoch: 5| Step: 1
Training loss: 1.2061887979507446
Validation loss: 1.9240311961020193

Epoch: 5| Step: 2
Training loss: 1.181827187538147
Validation loss: 1.8921220200036162

Epoch: 5| Step: 3
Training loss: 1.5304898023605347
Validation loss: 1.9368416058119906

Epoch: 5| Step: 4
Training loss: 1.378298044204712
Validation loss: 1.9358478259014826

Epoch: 5| Step: 5
Training loss: 1.3633270263671875
Validation loss: 1.9029950307261558

Epoch: 5| Step: 6
Training loss: 1.5565872192382812
Validation loss: 1.9314614662560083

Epoch: 5| Step: 7
Training loss: 1.751214623451233
Validation loss: 1.8790054359743673

Epoch: 5| Step: 8
Training loss: 1.572713851928711
Validation loss: 1.942857087299388

Epoch: 5| Step: 9
Training loss: 1.1036171913146973
Validation loss: 1.8895417144221645

Epoch: 5| Step: 10
Training loss: 1.2234349250793457
Validation loss: 1.8727777760515931

Epoch: 353| Step: 0
Training loss: 1.816298484802246
Validation loss: 1.8935321620715562

Epoch: 5| Step: 1
Training loss: 1.589361310005188
Validation loss: 1.9287453953937819

Epoch: 5| Step: 2
Training loss: 1.8311229944229126
Validation loss: 1.9059698479149931

Epoch: 5| Step: 3
Training loss: 1.6383028030395508
Validation loss: 1.9256645338509673

Epoch: 5| Step: 4
Training loss: 0.9508739709854126
Validation loss: 1.9228445406882995

Epoch: 5| Step: 5
Training loss: 1.220634937286377
Validation loss: 1.9573026036703458

Epoch: 5| Step: 6
Training loss: 1.7817795276641846
Validation loss: 1.9482717667856524

Epoch: 5| Step: 7
Training loss: 1.768009901046753
Validation loss: 1.9169922336455314

Epoch: 5| Step: 8
Training loss: 0.775314211845398
Validation loss: 1.9747350728639992

Epoch: 5| Step: 9
Training loss: 0.8378598093986511
Validation loss: 1.907687101312863

Epoch: 5| Step: 10
Training loss: 1.5606896877288818
Validation loss: 1.8836950384160525

Epoch: 354| Step: 0
Training loss: 1.2282323837280273
Validation loss: 1.89172488386913

Epoch: 5| Step: 1
Training loss: 1.0170738697052002
Validation loss: 1.8845017853603567

Epoch: 5| Step: 2
Training loss: 1.7509944438934326
Validation loss: 1.9791320728999313

Epoch: 5| Step: 3
Training loss: 2.095655918121338
Validation loss: 1.8989348770469747

Epoch: 5| Step: 4
Training loss: 1.8744808435440063
Validation loss: 1.9056554045728458

Epoch: 5| Step: 5
Training loss: 1.4443753957748413
Validation loss: 1.8998992712266984

Epoch: 5| Step: 6
Training loss: 0.7212921977043152
Validation loss: 1.8945392549678843

Epoch: 5| Step: 7
Training loss: 1.5942997932434082
Validation loss: 1.8913961751486665

Epoch: 5| Step: 8
Training loss: 0.9255703091621399
Validation loss: 1.9118202078726985

Epoch: 5| Step: 9
Training loss: 1.4821455478668213
Validation loss: 1.8808635178432669

Epoch: 5| Step: 10
Training loss: 0.8791453242301941
Validation loss: 1.9488112990574171

Epoch: 355| Step: 0
Training loss: 0.5850059390068054
Validation loss: 1.9630553055835027

Epoch: 5| Step: 1
Training loss: 1.0220857858657837
Validation loss: 1.881624847330073

Epoch: 5| Step: 2
Training loss: 2.0236546993255615
Validation loss: 1.843852412316107

Epoch: 5| Step: 3
Training loss: 1.7648839950561523
Validation loss: 1.9167557813787972

Epoch: 5| Step: 4
Training loss: 1.6543452739715576
Validation loss: 1.9273280430865545

Epoch: 5| Step: 5
Training loss: 1.3683925867080688
Validation loss: 1.8780584719873243

Epoch: 5| Step: 6
Training loss: 1.2260034084320068
Validation loss: 1.888997580415459

Epoch: 5| Step: 7
Training loss: 0.9842853546142578
Validation loss: 1.8922282085623792

Epoch: 5| Step: 8
Training loss: 1.3592993021011353
Validation loss: 1.8939472616359752

Epoch: 5| Step: 9
Training loss: 1.4345800876617432
Validation loss: 1.9302294433757823

Epoch: 5| Step: 10
Training loss: 1.5566718578338623
Validation loss: 1.8652958075205486

Epoch: 356| Step: 0
Training loss: 1.4966871738433838
Validation loss: 1.9113154283133886

Epoch: 5| Step: 1
Training loss: 1.6500251293182373
Validation loss: 1.9280827365895754

Epoch: 5| Step: 2
Training loss: 1.706983208656311
Validation loss: 1.9257047035360848

Epoch: 5| Step: 3
Training loss: 1.4986594915390015
Validation loss: 1.9367680549621582

Epoch: 5| Step: 4
Training loss: 1.0232311487197876
Validation loss: 1.97362353468454

Epoch: 5| Step: 5
Training loss: 1.5902130603790283
Validation loss: 1.917149641180551

Epoch: 5| Step: 6
Training loss: 1.2324968576431274
Validation loss: 1.9655636433632142

Epoch: 5| Step: 7
Training loss: 0.8424588441848755
Validation loss: 1.9669725510381884

Epoch: 5| Step: 8
Training loss: 0.7661980986595154
Validation loss: 1.8651883166323426

Epoch: 5| Step: 9
Training loss: 1.285835862159729
Validation loss: 1.915420824481595

Epoch: 5| Step: 10
Training loss: 1.7868313789367676
Validation loss: 1.8769501691223474

Epoch: 357| Step: 0
Training loss: 1.316533088684082
Validation loss: 1.972967347791118

Epoch: 5| Step: 1
Training loss: 1.5371153354644775
Validation loss: 1.904196980178997

Epoch: 5| Step: 2
Training loss: 1.335284948348999
Validation loss: 1.9108337792017127

Epoch: 5| Step: 3
Training loss: 1.3424198627471924
Validation loss: 1.8971849897856354

Epoch: 5| Step: 4
Training loss: 1.5900962352752686
Validation loss: 1.89298810497407

Epoch: 5| Step: 5
Training loss: 1.2256572246551514
Validation loss: 1.9512795863613006

Epoch: 5| Step: 6
Training loss: 1.2662811279296875
Validation loss: 1.890396256600657

Epoch: 5| Step: 7
Training loss: 1.430430293083191
Validation loss: 1.9779748301352225

Epoch: 5| Step: 8
Training loss: 0.9934253692626953
Validation loss: 1.866281832418134

Epoch: 5| Step: 9
Training loss: 1.3585506677627563
Validation loss: 1.9505461441573275

Epoch: 5| Step: 10
Training loss: 1.1733169555664062
Validation loss: 1.8958594260677215

Epoch: 358| Step: 0
Training loss: 1.7346198558807373
Validation loss: 1.9677662926335489

Epoch: 5| Step: 1
Training loss: 1.1694213151931763
Validation loss: 1.9307711534602667

Epoch: 5| Step: 2
Training loss: 1.0353052616119385
Validation loss: 1.9415308916440575

Epoch: 5| Step: 3
Training loss: 1.3077571392059326
Validation loss: 1.9202439759367256

Epoch: 5| Step: 4
Training loss: 1.4797108173370361
Validation loss: 1.9435116449991863

Epoch: 5| Step: 5
Training loss: 1.3296781778335571
Validation loss: 1.9959802178926365

Epoch: 5| Step: 6
Training loss: 1.6865358352661133
Validation loss: 1.919904952408165

Epoch: 5| Step: 7
Training loss: 1.2089166641235352
Validation loss: 1.9328415060556063

Epoch: 5| Step: 8
Training loss: 1.2747600078582764
Validation loss: 1.987590161702966

Epoch: 5| Step: 9
Training loss: 1.4420955181121826
Validation loss: 1.8945590552463327

Epoch: 5| Step: 10
Training loss: 1.3764950037002563
Validation loss: 1.9548539346264255

Epoch: 359| Step: 0
Training loss: 1.3273561000823975
Validation loss: 1.918258825937907

Epoch: 5| Step: 1
Training loss: 1.5025866031646729
Validation loss: 1.910018269733716

Epoch: 5| Step: 2
Training loss: 1.44033682346344
Validation loss: 1.886640259014663

Epoch: 5| Step: 3
Training loss: 1.3622668981552124
Validation loss: 1.920692773275478

Epoch: 5| Step: 4
Training loss: 1.3239113092422485
Validation loss: 1.8700409204729143

Epoch: 5| Step: 5
Training loss: 1.6072533130645752
Validation loss: 2.0185424755978327

Epoch: 5| Step: 6
Training loss: 1.3211195468902588
Validation loss: 1.9333709183559622

Epoch: 5| Step: 7
Training loss: 1.7186381816864014
Validation loss: 1.9625989929322274

Epoch: 5| Step: 8
Training loss: 0.9269219636917114
Validation loss: 1.9487315326608636

Epoch: 5| Step: 9
Training loss: 0.7343040704727173
Validation loss: 1.8585939663712696

Epoch: 5| Step: 10
Training loss: 1.5650508403778076
Validation loss: 1.9978990734264415

Epoch: 360| Step: 0
Training loss: 1.1659910678863525
Validation loss: 1.9361044181290494

Epoch: 5| Step: 1
Training loss: 1.283089518547058
Validation loss: 1.9416792931095246

Epoch: 5| Step: 2
Training loss: 1.1234608888626099
Validation loss: 1.9113511987911758

Epoch: 5| Step: 3
Training loss: 2.1120171546936035
Validation loss: 1.9416389798605314

Epoch: 5| Step: 4
Training loss: 1.467810034751892
Validation loss: 1.869033928840391

Epoch: 5| Step: 5
Training loss: 0.6454541683197021
Validation loss: 1.9293208429890294

Epoch: 5| Step: 6
Training loss: 2.1420600414276123
Validation loss: 1.860453805615825

Epoch: 5| Step: 7
Training loss: 1.3902498483657837
Validation loss: 1.8891286952521211

Epoch: 5| Step: 8
Training loss: 1.0384901762008667
Validation loss: 1.8961999762442805

Epoch: 5| Step: 9
Training loss: 1.6991809606552124
Validation loss: 1.9538269376242032

Epoch: 5| Step: 10
Training loss: 0.8751909136772156
Validation loss: 1.918267276979262

Epoch: 361| Step: 0
Training loss: 1.115073323249817
Validation loss: 1.8874693121961368

Epoch: 5| Step: 1
Training loss: 1.7223806381225586
Validation loss: 1.8872084233068651

Epoch: 5| Step: 2
Training loss: 1.156577467918396
Validation loss: 1.9342973462996944

Epoch: 5| Step: 3
Training loss: 1.434981107711792
Validation loss: 1.9442089808884488

Epoch: 5| Step: 4
Training loss: 1.2531708478927612
Validation loss: 1.927083674297538

Epoch: 5| Step: 5
Training loss: 1.621316909790039
Validation loss: 1.9027709909664687

Epoch: 5| Step: 6
Training loss: 1.0843865871429443
Validation loss: 1.9884541137244112

Epoch: 5| Step: 7
Training loss: 2.1531271934509277
Validation loss: 1.930549180635842

Epoch: 5| Step: 8
Training loss: 1.1682722568511963
Validation loss: 1.904634924345119

Epoch: 5| Step: 9
Training loss: 1.0722068548202515
Validation loss: 1.8934907349207069

Epoch: 5| Step: 10
Training loss: 1.408818244934082
Validation loss: 1.969962772502694

Epoch: 362| Step: 0
Training loss: 1.4151722192764282
Validation loss: 1.904547317053682

Epoch: 5| Step: 1
Training loss: 1.1723376512527466
Validation loss: 1.8282071441732428

Epoch: 5| Step: 2
Training loss: 1.4135690927505493
Validation loss: 1.9154052606192968

Epoch: 5| Step: 3
Training loss: 1.9978559017181396
Validation loss: 1.880590736225087

Epoch: 5| Step: 4
Training loss: 1.544857144355774
Validation loss: 1.8681130370786112

Epoch: 5| Step: 5
Training loss: 0.9424026608467102
Validation loss: 1.9518840274503153

Epoch: 5| Step: 6
Training loss: 1.7001845836639404
Validation loss: 1.925762414932251

Epoch: 5| Step: 7
Training loss: 1.1647974252700806
Validation loss: 1.949501996399254

Epoch: 5| Step: 8
Training loss: 0.8025199174880981
Validation loss: 1.8776726568898847

Epoch: 5| Step: 9
Training loss: 1.4267909526824951
Validation loss: 1.9636501855747674

Epoch: 5| Step: 10
Training loss: 1.3498600721359253
Validation loss: 1.9026110608090636

Epoch: 363| Step: 0
Training loss: 1.6826651096343994
Validation loss: 1.886715991522676

Epoch: 5| Step: 1
Training loss: 1.3362151384353638
Validation loss: 1.854757724269744

Epoch: 5| Step: 2
Training loss: 1.382237434387207
Validation loss: 2.004102430035991

Epoch: 5| Step: 3
Training loss: 1.1030504703521729
Validation loss: 1.9113556402985767

Epoch: 5| Step: 4
Training loss: 1.396392583847046
Validation loss: 1.8834117843258766

Epoch: 5| Step: 5
Training loss: 1.3564221858978271
Validation loss: 2.013428939286099

Epoch: 5| Step: 6
Training loss: 1.278524398803711
Validation loss: 1.8947819650814097

Epoch: 5| Step: 7
Training loss: 1.5230125188827515
Validation loss: 1.8927063198499783

Epoch: 5| Step: 8
Training loss: 1.2172987461090088
Validation loss: 2.0182617813028316

Epoch: 5| Step: 9
Training loss: 1.8030554056167603
Validation loss: 1.9425050853401102

Epoch: 5| Step: 10
Training loss: 0.8497878909111023
Validation loss: 1.918310126950664

Epoch: 364| Step: 0
Training loss: 1.4633159637451172
Validation loss: 1.9714411958571403

Epoch: 5| Step: 1
Training loss: 1.059384822845459
Validation loss: 1.9630423322800667

Epoch: 5| Step: 2
Training loss: 1.2658439874649048
Validation loss: 1.9088383156766173

Epoch: 5| Step: 3
Training loss: 2.0730361938476562
Validation loss: 1.9771592309398036

Epoch: 5| Step: 4
Training loss: 1.3343160152435303
Validation loss: 1.9692211535669142

Epoch: 5| Step: 5
Training loss: 1.3360226154327393
Validation loss: 1.9686570334178146

Epoch: 5| Step: 6
Training loss: 1.1554107666015625
Validation loss: 1.970826771951491

Epoch: 5| Step: 7
Training loss: 0.7700047492980957
Validation loss: 1.9062707924073743

Epoch: 5| Step: 8
Training loss: 1.4882831573486328
Validation loss: 1.868209377411873

Epoch: 5| Step: 9
Training loss: 1.1484720706939697
Validation loss: 1.8697459748996201

Epoch: 5| Step: 10
Training loss: 1.778783917427063
Validation loss: 1.925905542988931

Epoch: 365| Step: 0
Training loss: 0.9966123700141907
Validation loss: 1.9374835145088933

Epoch: 5| Step: 1
Training loss: 1.2186411619186401
Validation loss: 1.9158435149859356

Epoch: 5| Step: 2
Training loss: 1.3701610565185547
Validation loss: 1.9304324273140199

Epoch: 5| Step: 3
Training loss: 1.9109348058700562
Validation loss: 1.8840870767511346

Epoch: 5| Step: 4
Training loss: 1.3712207078933716
Validation loss: 1.8978265741819977

Epoch: 5| Step: 5
Training loss: 1.6194032430648804
Validation loss: 1.920111817698325

Epoch: 5| Step: 6
Training loss: 0.9906711578369141
Validation loss: 1.9553076938916278

Epoch: 5| Step: 7
Training loss: 1.3146615028381348
Validation loss: 1.9595153921393937

Epoch: 5| Step: 8
Training loss: 1.4913703203201294
Validation loss: 1.9755777799954979

Epoch: 5| Step: 9
Training loss: 1.3981002569198608
Validation loss: 1.9237488495406283

Epoch: 5| Step: 10
Training loss: 1.7621206045150757
Validation loss: 1.9419397000343568

Epoch: 366| Step: 0
Training loss: 1.6052125692367554
Validation loss: 1.9621500840751074

Epoch: 5| Step: 1
Training loss: 1.5223891735076904
Validation loss: 1.9309818552386375

Epoch: 5| Step: 2
Training loss: 1.4288079738616943
Validation loss: 1.9015221288127284

Epoch: 5| Step: 3
Training loss: 1.291932463645935
Validation loss: 1.91818961404985

Epoch: 5| Step: 4
Training loss: 1.1777229309082031
Validation loss: 1.9151331417022213

Epoch: 5| Step: 5
Training loss: 1.8711912631988525
Validation loss: 1.8706957435095182

Epoch: 5| Step: 6
Training loss: 1.207766056060791
Validation loss: 1.8735841807498728

Epoch: 5| Step: 7
Training loss: 1.1529591083526611
Validation loss: 2.0141404187807472

Epoch: 5| Step: 8
Training loss: 1.1409012079238892
Validation loss: 1.9244379202524822

Epoch: 5| Step: 9
Training loss: 1.0747625827789307
Validation loss: 1.9275007324834024

Epoch: 5| Step: 10
Training loss: 1.3029001951217651
Validation loss: 1.9502113698631205

Epoch: 367| Step: 0
Training loss: 1.1925204992294312
Validation loss: 2.019373955265168

Epoch: 5| Step: 1
Training loss: 1.3039556741714478
Validation loss: 1.946751004906111

Epoch: 5| Step: 2
Training loss: 1.5346330404281616
Validation loss: 1.9793538662695116

Epoch: 5| Step: 3
Training loss: 1.015093207359314
Validation loss: 1.935912944937265

Epoch: 5| Step: 4
Training loss: 1.6336772441864014
Validation loss: 1.855090977043234

Epoch: 5| Step: 5
Training loss: 1.7530558109283447
Validation loss: 1.9700108561464535

Epoch: 5| Step: 6
Training loss: 1.2419322729110718
Validation loss: 1.8864721341799664

Epoch: 5| Step: 7
Training loss: 1.197595238685608
Validation loss: 1.8726021397498347

Epoch: 5| Step: 8
Training loss: 1.4673535823822021
Validation loss: 1.896422116987167

Epoch: 5| Step: 9
Training loss: 1.323642611503601
Validation loss: 1.8828219700885076

Epoch: 5| Step: 10
Training loss: 1.2667704820632935
Validation loss: 1.9265958647574148

Epoch: 368| Step: 0
Training loss: 1.5328820943832397
Validation loss: 1.866956490342335

Epoch: 5| Step: 1
Training loss: 1.276448130607605
Validation loss: 1.8983859157049527

Epoch: 5| Step: 2
Training loss: 1.4663503170013428
Validation loss: 1.911979785529516

Epoch: 5| Step: 3
Training loss: 1.097195029258728
Validation loss: 1.8929815266721992

Epoch: 5| Step: 4
Training loss: 1.2018539905548096
Validation loss: 1.8945324587565597

Epoch: 5| Step: 5
Training loss: 1.110032081604004
Validation loss: 1.94890715998988

Epoch: 5| Step: 6
Training loss: 1.6311956644058228
Validation loss: 1.9484952342125677

Epoch: 5| Step: 7
Training loss: 1.1610891819000244
Validation loss: 1.9390736087676017

Epoch: 5| Step: 8
Training loss: 1.4249897003173828
Validation loss: 1.9259126865735618

Epoch: 5| Step: 9
Training loss: 1.1681933403015137
Validation loss: 1.959157254106255

Epoch: 5| Step: 10
Training loss: 1.9257805347442627
Validation loss: 1.8755550384521484

Epoch: 369| Step: 0
Training loss: 1.4765573740005493
Validation loss: 1.9430217999283985

Epoch: 5| Step: 1
Training loss: 1.7193272113800049
Validation loss: 1.937643640784807

Epoch: 5| Step: 2
Training loss: 1.1514132022857666
Validation loss: 1.90907383349634

Epoch: 5| Step: 3
Training loss: 1.669198751449585
Validation loss: 1.9397573112159647

Epoch: 5| Step: 4
Training loss: 0.9321691393852234
Validation loss: 1.967118078662503

Epoch: 5| Step: 5
Training loss: 1.9838030338287354
Validation loss: 1.916953940545359

Epoch: 5| Step: 6
Training loss: 1.1425663232803345
Validation loss: 1.9587920891341342

Epoch: 5| Step: 7
Training loss: 1.204402208328247
Validation loss: 1.9392930192332114

Epoch: 5| Step: 8
Training loss: 1.2621055841445923
Validation loss: 1.9184033281059676

Epoch: 5| Step: 9
Training loss: 0.974047064781189
Validation loss: 1.9333518256423294

Epoch: 5| Step: 10
Training loss: 1.470422625541687
Validation loss: 1.8865030837315384

Epoch: 370| Step: 0
Training loss: 1.109954595565796
Validation loss: 1.9476808809464978

Epoch: 5| Step: 1
Training loss: 1.6177294254302979
Validation loss: 1.8744355170957503

Epoch: 5| Step: 2
Training loss: 1.0128976106643677
Validation loss: 1.919764398246683

Epoch: 5| Step: 3
Training loss: 1.1920592784881592
Validation loss: 1.9132773055825183

Epoch: 5| Step: 4
Training loss: 1.5408703088760376
Validation loss: 1.9289937737167522

Epoch: 5| Step: 5
Training loss: 1.112567663192749
Validation loss: 1.9322551783695017

Epoch: 5| Step: 6
Training loss: 1.9715276956558228
Validation loss: 1.8583700990164151

Epoch: 5| Step: 7
Training loss: 0.9554513692855835
Validation loss: 1.8916918795595887

Epoch: 5| Step: 8
Training loss: 1.8964927196502686
Validation loss: 1.924171083716936

Epoch: 5| Step: 9
Training loss: 1.0851072072982788
Validation loss: 1.8928038151033464

Epoch: 5| Step: 10
Training loss: 1.3301277160644531
Validation loss: 1.8954464568886706

Epoch: 371| Step: 0
Training loss: 0.8500422239303589
Validation loss: 1.9778146307955506

Epoch: 5| Step: 1
Training loss: 1.5785300731658936
Validation loss: 1.9018336637045747

Epoch: 5| Step: 2
Training loss: 1.8589980602264404
Validation loss: 1.9515701096544984

Epoch: 5| Step: 3
Training loss: 1.6885915994644165
Validation loss: 1.9340104967035272

Epoch: 5| Step: 4
Training loss: 1.179456114768982
Validation loss: 1.9205657256546842

Epoch: 5| Step: 5
Training loss: 1.608704924583435
Validation loss: 1.8282195342484342

Epoch: 5| Step: 6
Training loss: 1.0123472213745117
Validation loss: 1.9458389948773127

Epoch: 5| Step: 7
Training loss: 1.5408365726470947
Validation loss: 1.9530031501605947

Epoch: 5| Step: 8
Training loss: 0.8677471280097961
Validation loss: 1.92985410587762

Epoch: 5| Step: 9
Training loss: 0.9143195152282715
Validation loss: 1.8782017692442863

Epoch: 5| Step: 10
Training loss: 1.324225664138794
Validation loss: 1.9280871229787027

Epoch: 372| Step: 0
Training loss: 1.3631591796875
Validation loss: 1.9388118584950764

Epoch: 5| Step: 1
Training loss: 1.3012521266937256
Validation loss: 1.9477786274366482

Epoch: 5| Step: 2
Training loss: 0.9701512455940247
Validation loss: 1.9425782631802302

Epoch: 5| Step: 3
Training loss: 1.4240291118621826
Validation loss: 1.9352862988748858

Epoch: 5| Step: 4
Training loss: 1.258865475654602
Validation loss: 1.8971414155857538

Epoch: 5| Step: 5
Training loss: 1.4332729578018188
Validation loss: 1.9071999288374377

Epoch: 5| Step: 6
Training loss: 1.5581438541412354
Validation loss: 1.9161314272111463

Epoch: 5| Step: 7
Training loss: 1.5031111240386963
Validation loss: 1.8738032771695046

Epoch: 5| Step: 8
Training loss: 1.4141016006469727
Validation loss: 1.8718180412887244

Epoch: 5| Step: 9
Training loss: 1.150978446006775
Validation loss: 1.8970002987051522

Epoch: 5| Step: 10
Training loss: 1.1012941598892212
Validation loss: 1.9538876420708113

Epoch: 373| Step: 0
Training loss: 1.474308729171753
Validation loss: 1.8903815618125341

Epoch: 5| Step: 1
Training loss: 1.8207597732543945
Validation loss: 1.927264710908295

Epoch: 5| Step: 2
Training loss: 1.2816894054412842
Validation loss: 1.8465332702923847

Epoch: 5| Step: 3
Training loss: 1.258331298828125
Validation loss: 1.9067861495479461

Epoch: 5| Step: 4
Training loss: 1.2906162738800049
Validation loss: 1.8641827747385988

Epoch: 5| Step: 5
Training loss: 1.3464901447296143
Validation loss: 1.9112205479734687

Epoch: 5| Step: 6
Training loss: 1.9190423488616943
Validation loss: 1.9252610078421972

Epoch: 5| Step: 7
Training loss: 1.2404013872146606
Validation loss: 1.9007390750351774

Epoch: 5| Step: 8
Training loss: 0.9797264933586121
Validation loss: 1.9140088212105535

Epoch: 5| Step: 9
Training loss: 1.0718780755996704
Validation loss: 1.8999654554551648

Epoch: 5| Step: 10
Training loss: 1.0275462865829468
Validation loss: 1.9444555582538727

Epoch: 374| Step: 0
Training loss: 1.2362871170043945
Validation loss: 1.9561057475305372

Epoch: 5| Step: 1
Training loss: 1.0117342472076416
Validation loss: 1.937549380845921

Epoch: 5| Step: 2
Training loss: 1.2027628421783447
Validation loss: 1.951238191255959

Epoch: 5| Step: 3
Training loss: 1.04758620262146
Validation loss: 1.9535193545843965

Epoch: 5| Step: 4
Training loss: 1.685792326927185
Validation loss: 2.011736093028899

Epoch: 5| Step: 5
Training loss: 1.5899003744125366
Validation loss: 1.9690574599850563

Epoch: 5| Step: 6
Training loss: 0.8132209777832031
Validation loss: 1.941187802181449

Epoch: 5| Step: 7
Training loss: 1.362321376800537
Validation loss: 1.9350262764961488

Epoch: 5| Step: 8
Training loss: 1.9261360168457031
Validation loss: 1.9288543334571264

Epoch: 5| Step: 9
Training loss: 1.0017127990722656
Validation loss: 1.9285798790634319

Epoch: 5| Step: 10
Training loss: 2.0773136615753174
Validation loss: 1.9809955550778298

Epoch: 375| Step: 0
Training loss: 1.0288171768188477
Validation loss: 1.909157181298861

Epoch: 5| Step: 1
Training loss: 2.02219557762146
Validation loss: 1.9041048801073464

Epoch: 5| Step: 2
Training loss: 1.3698999881744385
Validation loss: 1.9843840176059353

Epoch: 5| Step: 3
Training loss: 1.1455587148666382
Validation loss: 1.9447809470597135

Epoch: 5| Step: 4
Training loss: 0.814949631690979
Validation loss: 1.9356197464850642

Epoch: 5| Step: 5
Training loss: 0.9424155950546265
Validation loss: 1.9466175110109392

Epoch: 5| Step: 6
Training loss: 1.007434606552124
Validation loss: 1.9041473545053953

Epoch: 5| Step: 7
Training loss: 1.371284008026123
Validation loss: 1.9580538683040167

Epoch: 5| Step: 8
Training loss: 1.4718174934387207
Validation loss: 1.9296428823983798

Epoch: 5| Step: 9
Training loss: 1.9741290807724
Validation loss: 1.884476387372581

Epoch: 5| Step: 10
Training loss: 0.9378544688224792
Validation loss: 1.9169056223284813

Epoch: 376| Step: 0
Training loss: 1.107901692390442
Validation loss: 1.8559703288539764

Epoch: 5| Step: 1
Training loss: 1.9849531650543213
Validation loss: 1.893034117196196

Epoch: 5| Step: 2
Training loss: 1.0761476755142212
Validation loss: 1.9154572499695646

Epoch: 5| Step: 3
Training loss: 1.356755256652832
Validation loss: 1.9243274939957487

Epoch: 5| Step: 4
Training loss: 0.9130176305770874
Validation loss: 1.9716989148047663

Epoch: 5| Step: 5
Training loss: 1.340334177017212
Validation loss: 1.8626333641749557

Epoch: 5| Step: 6
Training loss: 0.8773213624954224
Validation loss: 1.9226524419682

Epoch: 5| Step: 7
Training loss: 1.0585585832595825
Validation loss: 1.9270956131719774

Epoch: 5| Step: 8
Training loss: 1.325476884841919
Validation loss: 1.9252512224258915

Epoch: 5| Step: 9
Training loss: 1.3635046482086182
Validation loss: 1.8942125612689602

Epoch: 5| Step: 10
Training loss: 1.8325804471969604
Validation loss: 1.911942934477201

Epoch: 377| Step: 0
Training loss: 1.1211130619049072
Validation loss: 1.88166908935834

Epoch: 5| Step: 1
Training loss: 1.4097336530685425
Validation loss: 1.9070777841793594

Epoch: 5| Step: 2
Training loss: 1.4436519145965576
Validation loss: 1.8786669572194417

Epoch: 5| Step: 3
Training loss: 1.4410951137542725
Validation loss: 1.918462744323156

Epoch: 5| Step: 4
Training loss: 0.7771631479263306
Validation loss: 1.9169966802802136

Epoch: 5| Step: 5
Training loss: 1.4349068403244019
Validation loss: 1.9430647024544336

Epoch: 5| Step: 6
Training loss: 1.351823091506958
Validation loss: 1.9145247269702215

Epoch: 5| Step: 7
Training loss: 1.2344133853912354
Validation loss: 1.8459884479481687

Epoch: 5| Step: 8
Training loss: 1.2146837711334229
Validation loss: 1.900425014957305

Epoch: 5| Step: 9
Training loss: 1.1670141220092773
Validation loss: 1.8873761687227475

Epoch: 5| Step: 10
Training loss: 2.061075448989868
Validation loss: 1.8736500586232832

Epoch: 378| Step: 0
Training loss: 1.591283917427063
Validation loss: 1.9127550817305041

Epoch: 5| Step: 1
Training loss: 1.2662866115570068
Validation loss: 1.9030471412084435

Epoch: 5| Step: 2
Training loss: 0.8282537460327148
Validation loss: 1.9100990923502112

Epoch: 5| Step: 3
Training loss: 0.8069661855697632
Validation loss: 1.9348739321513841

Epoch: 5| Step: 4
Training loss: 1.1329553127288818
Validation loss: 1.9578524507502073

Epoch: 5| Step: 5
Training loss: 1.064378023147583
Validation loss: 1.9172669354305472

Epoch: 5| Step: 6
Training loss: 1.838951826095581
Validation loss: 1.893579283068257

Epoch: 5| Step: 7
Training loss: 1.4364564418792725
Validation loss: 1.9181006044469855

Epoch: 5| Step: 8
Training loss: 1.1126213073730469
Validation loss: 1.931397568794989

Epoch: 5| Step: 9
Training loss: 1.3877155780792236
Validation loss: 1.884429565040014

Epoch: 5| Step: 10
Training loss: 1.5047162771224976
Validation loss: 1.933742978239572

Epoch: 379| Step: 0
Training loss: 0.9847664833068848
Validation loss: 1.9010119335625761

Epoch: 5| Step: 1
Training loss: 1.5681368112564087
Validation loss: 1.9055514284359512

Epoch: 5| Step: 2
Training loss: 1.7681100368499756
Validation loss: 1.870654703468405

Epoch: 5| Step: 3
Training loss: 1.6735633611679077
Validation loss: 1.8813144788947156

Epoch: 5| Step: 4
Training loss: 1.087781548500061
Validation loss: 1.8906112832407798

Epoch: 5| Step: 5
Training loss: 1.1875417232513428
Validation loss: 1.8513233687288018

Epoch: 5| Step: 6
Training loss: 1.1919376850128174
Validation loss: 1.8777176077647875

Epoch: 5| Step: 7
Training loss: 1.027685523033142
Validation loss: 1.9235692152412989

Epoch: 5| Step: 8
Training loss: 1.5547597408294678
Validation loss: 1.8909856222009147

Epoch: 5| Step: 9
Training loss: 2.0921692848205566
Validation loss: 1.8766416195900208

Epoch: 5| Step: 10
Training loss: 0.9060805439949036
Validation loss: 1.927538444918971

Epoch: 380| Step: 0
Training loss: 0.8590782284736633
Validation loss: 1.90289080719794

Epoch: 5| Step: 1
Training loss: 1.126253366470337
Validation loss: 1.9037858029847503

Epoch: 5| Step: 2
Training loss: 1.1655151844024658
Validation loss: 1.9528702471845893

Epoch: 5| Step: 3
Training loss: 1.2081403732299805
Validation loss: 1.9095371397592689

Epoch: 5| Step: 4
Training loss: 1.4776842594146729
Validation loss: 1.857442170061091

Epoch: 5| Step: 5
Training loss: 1.5939204692840576
Validation loss: 1.9248881288754043

Epoch: 5| Step: 6
Training loss: 1.6166483163833618
Validation loss: 1.9397686168711672

Epoch: 5| Step: 7
Training loss: 1.464782953262329
Validation loss: 1.8445443017508394

Epoch: 5| Step: 8
Training loss: 1.267399549484253
Validation loss: 1.9319907696016374

Epoch: 5| Step: 9
Training loss: 1.3942829370498657
Validation loss: 1.8704817782166183

Epoch: 5| Step: 10
Training loss: 1.1910359859466553
Validation loss: 1.8720224313838507

Epoch: 381| Step: 0
Training loss: 0.8469093441963196
Validation loss: 1.9332456204199022

Epoch: 5| Step: 1
Training loss: 1.420180082321167
Validation loss: 1.9311199918870003

Epoch: 5| Step: 2
Training loss: 1.283761739730835
Validation loss: 1.891297318602121

Epoch: 5| Step: 3
Training loss: 1.1696008443832397
Validation loss: 1.8988484759484567

Epoch: 5| Step: 4
Training loss: 2.0162858963012695
Validation loss: 1.9200840521884222

Epoch: 5| Step: 5
Training loss: 1.0403661727905273
Validation loss: 1.9260090243431829

Epoch: 5| Step: 6
Training loss: 1.0573939085006714
Validation loss: 1.9044248493768836

Epoch: 5| Step: 7
Training loss: 1.4729982614517212
Validation loss: 1.9673416922169347

Epoch: 5| Step: 8
Training loss: 1.765127182006836
Validation loss: 1.8817486557909238

Epoch: 5| Step: 9
Training loss: 1.4986158609390259
Validation loss: 1.939490408025762

Epoch: 5| Step: 10
Training loss: 1.0320119857788086
Validation loss: 1.8605997767499698

Epoch: 382| Step: 0
Training loss: 1.3690792322158813
Validation loss: 1.9289700651681552

Epoch: 5| Step: 1
Training loss: 1.3983049392700195
Validation loss: 1.8944454628934142

Epoch: 5| Step: 2
Training loss: 1.6484899520874023
Validation loss: 1.8730953970263082

Epoch: 5| Step: 3
Training loss: 1.7174174785614014
Validation loss: 1.9187238934219524

Epoch: 5| Step: 4
Training loss: 1.0681993961334229
Validation loss: 1.8508141463802708

Epoch: 5| Step: 5
Training loss: 1.093353033065796
Validation loss: 1.8674051197626258

Epoch: 5| Step: 6
Training loss: 1.3860973119735718
Validation loss: 1.868746111469884

Epoch: 5| Step: 7
Training loss: 1.0502111911773682
Validation loss: 1.90062758486758

Epoch: 5| Step: 8
Training loss: 1.2611182928085327
Validation loss: 1.8877292704838577

Epoch: 5| Step: 9
Training loss: 1.188477873802185
Validation loss: 1.8570122513719785

Epoch: 5| Step: 10
Training loss: 1.5298188924789429
Validation loss: 1.8859678045395882

Epoch: 383| Step: 0
Training loss: 1.0160093307495117
Validation loss: 1.8966571002878168

Epoch: 5| Step: 1
Training loss: 1.2613732814788818
Validation loss: 1.8684368953909924

Epoch: 5| Step: 2
Training loss: 0.761178195476532
Validation loss: 1.8935414668052428

Epoch: 5| Step: 3
Training loss: 1.7062227725982666
Validation loss: 1.9897263101352158

Epoch: 5| Step: 4
Training loss: 1.3132387399673462
Validation loss: 1.9181709417732813

Epoch: 5| Step: 5
Training loss: 1.4091140031814575
Validation loss: 1.8805138731515536

Epoch: 5| Step: 6
Training loss: 1.0506861209869385
Validation loss: 1.9879822346471971

Epoch: 5| Step: 7
Training loss: 0.9811525344848633
Validation loss: 1.9455310913824266

Epoch: 5| Step: 8
Training loss: 0.962624192237854
Validation loss: 1.9723961148210751

Epoch: 5| Step: 9
Training loss: 1.5069084167480469
Validation loss: 1.9603184653866677

Epoch: 5| Step: 10
Training loss: 1.9128999710083008
Validation loss: 1.9287992113380021

Epoch: 384| Step: 0
Training loss: 1.5808570384979248
Validation loss: 1.9765163570322015

Epoch: 5| Step: 1
Training loss: 1.177968144416809
Validation loss: 1.9341580444766628

Epoch: 5| Step: 2
Training loss: 1.443788766860962
Validation loss: 1.8674356040134226

Epoch: 5| Step: 3
Training loss: 1.2434602975845337
Validation loss: 1.985699979207849

Epoch: 5| Step: 4
Training loss: 1.5604255199432373
Validation loss: 1.8497689898296068

Epoch: 5| Step: 5
Training loss: 1.0700684785842896
Validation loss: 1.9310588170123357

Epoch: 5| Step: 6
Training loss: 0.7563075423240662
Validation loss: 1.8809947877801874

Epoch: 5| Step: 7
Training loss: 1.1644999980926514
Validation loss: 1.919471921459321

Epoch: 5| Step: 8
Training loss: 1.3156154155731201
Validation loss: 1.9315481467913556

Epoch: 5| Step: 9
Training loss: 1.1704819202423096
Validation loss: 1.9254880130931895

Epoch: 5| Step: 10
Training loss: 1.635023593902588
Validation loss: 1.8666778277325373

Epoch: 385| Step: 0
Training loss: 1.2307575941085815
Validation loss: 1.9527646482631724

Epoch: 5| Step: 1
Training loss: 1.4593226909637451
Validation loss: 1.9531271893491027

Epoch: 5| Step: 2
Training loss: 1.4464833736419678
Validation loss: 1.8857692133995794

Epoch: 5| Step: 3
Training loss: 1.9554193019866943
Validation loss: 1.894123342729384

Epoch: 5| Step: 4
Training loss: 1.4791433811187744
Validation loss: 1.9098366268219487

Epoch: 5| Step: 5
Training loss: 1.226538062095642
Validation loss: 1.9171928333979782

Epoch: 5| Step: 6
Training loss: 1.1548833847045898
Validation loss: 1.968686080748035

Epoch: 5| Step: 7
Training loss: 1.3287618160247803
Validation loss: 1.93312624449371

Epoch: 5| Step: 8
Training loss: 1.1572436094284058
Validation loss: 1.9231648893766506

Epoch: 5| Step: 9
Training loss: 0.9355180859565735
Validation loss: 1.9650539710957518

Epoch: 5| Step: 10
Training loss: 1.3409202098846436
Validation loss: 1.8555774022174139

Epoch: 386| Step: 0
Training loss: 1.3679282665252686
Validation loss: 1.9150731640477334

Epoch: 5| Step: 1
Training loss: 1.1308344602584839
Validation loss: 1.9526219803799865

Epoch: 5| Step: 2
Training loss: 1.116224765777588
Validation loss: 1.914854008664367

Epoch: 5| Step: 3
Training loss: 1.5483423471450806
Validation loss: 1.9817910527670255

Epoch: 5| Step: 4
Training loss: 1.0745875835418701
Validation loss: 1.9012497522497689

Epoch: 5| Step: 5
Training loss: 1.1199232339859009
Validation loss: 1.8812715725232196

Epoch: 5| Step: 6
Training loss: 1.3981462717056274
Validation loss: 1.8875334006483837

Epoch: 5| Step: 7
Training loss: 1.5912890434265137
Validation loss: 1.9301687158564085

Epoch: 5| Step: 8
Training loss: 1.1120250225067139
Validation loss: 1.9238642646420387

Epoch: 5| Step: 9
Training loss: 0.9925950169563293
Validation loss: 1.916412023446893

Epoch: 5| Step: 10
Training loss: 1.5310206413269043
Validation loss: 1.9324709574381511

Epoch: 387| Step: 0
Training loss: 1.1282851696014404
Validation loss: 1.8908493275283484

Epoch: 5| Step: 1
Training loss: 1.2845232486724854
Validation loss: 1.9338555848726662

Epoch: 5| Step: 2
Training loss: 1.3589165210723877
Validation loss: 1.879242516333057

Epoch: 5| Step: 3
Training loss: 2.181776523590088
Validation loss: 1.904802845370385

Epoch: 5| Step: 4
Training loss: 1.0306727886199951
Validation loss: 1.9577525649019467

Epoch: 5| Step: 5
Training loss: 1.2792198657989502
Validation loss: 1.9619829654693604

Epoch: 5| Step: 6
Training loss: 0.6628434062004089
Validation loss: 1.9086556921723068

Epoch: 5| Step: 7
Training loss: 1.044831395149231
Validation loss: 1.8708678906963718

Epoch: 5| Step: 8
Training loss: 1.6360012292861938
Validation loss: 1.9446704720938077

Epoch: 5| Step: 9
Training loss: 0.8722105026245117
Validation loss: 1.88337851724317

Epoch: 5| Step: 10
Training loss: 1.537562370300293
Validation loss: 1.8677444663099063

Epoch: 388| Step: 0
Training loss: 1.286452054977417
Validation loss: 1.9514531025322535

Epoch: 5| Step: 1
Training loss: 1.378962755203247
Validation loss: 1.8820885509573004

Epoch: 5| Step: 2
Training loss: 1.7616281509399414
Validation loss: 1.8728277503803212

Epoch: 5| Step: 3
Training loss: 1.8163502216339111
Validation loss: 1.8719305146125056

Epoch: 5| Step: 4
Training loss: 0.7907975912094116
Validation loss: 1.8465665976206462

Epoch: 5| Step: 5
Training loss: 1.405154824256897
Validation loss: 1.934002339199025

Epoch: 5| Step: 6
Training loss: 1.009073257446289
Validation loss: 1.8974085277126682

Epoch: 5| Step: 7
Training loss: 1.487074851989746
Validation loss: 1.9113543930874075

Epoch: 5| Step: 8
Training loss: 1.0234980583190918
Validation loss: 1.901207232988009

Epoch: 5| Step: 9
Training loss: 1.327904224395752
Validation loss: 1.9676682910611552

Epoch: 5| Step: 10
Training loss: 0.9643615484237671
Validation loss: 1.9323424575149373

Epoch: 389| Step: 0
Training loss: 1.087632179260254
Validation loss: 1.901129928968286

Epoch: 5| Step: 1
Training loss: 1.2180347442626953
Validation loss: 1.8818352530079503

Epoch: 5| Step: 2
Training loss: 1.1854922771453857
Validation loss: 1.8849802055666525

Epoch: 5| Step: 3
Training loss: 1.540269136428833
Validation loss: 1.8677739289499098

Epoch: 5| Step: 4
Training loss: 1.5290539264678955
Validation loss: 1.9177415358122958

Epoch: 5| Step: 5
Training loss: 1.3948099613189697
Validation loss: 1.9209817712024977

Epoch: 5| Step: 6
Training loss: 1.3984984159469604
Validation loss: 1.8724849506091046

Epoch: 5| Step: 7
Training loss: 1.160605549812317
Validation loss: 1.9474558202169274

Epoch: 5| Step: 8
Training loss: 1.2237379550933838
Validation loss: 1.8685820243691886

Epoch: 5| Step: 9
Training loss: 1.292921781539917
Validation loss: 1.9110624162099694

Epoch: 5| Step: 10
Training loss: 1.483161449432373
Validation loss: 1.9306960695533342

Epoch: 390| Step: 0
Training loss: 1.4023730754852295
Validation loss: 1.823742696034011

Epoch: 5| Step: 1
Training loss: 1.1960030794143677
Validation loss: 1.885330477068501

Epoch: 5| Step: 2
Training loss: 1.1860138177871704
Validation loss: 1.8814348879680838

Epoch: 5| Step: 3
Training loss: 1.0466923713684082
Validation loss: 1.9010286151721913

Epoch: 5| Step: 4
Training loss: 1.5699902772903442
Validation loss: 1.900134131472598

Epoch: 5| Step: 5
Training loss: 0.8391620516777039
Validation loss: 1.8827984807311848

Epoch: 5| Step: 6
Training loss: 2.4301509857177734
Validation loss: 1.9122798994023313

Epoch: 5| Step: 7
Training loss: 1.05447518825531
Validation loss: 1.872025917935115

Epoch: 5| Step: 8
Training loss: 1.1962077617645264
Validation loss: 1.8474723626208562

Epoch: 5| Step: 9
Training loss: 1.552694320678711
Validation loss: 1.8965589307969617

Epoch: 5| Step: 10
Training loss: 0.6892400979995728
Validation loss: 1.8779949001086655

Epoch: 391| Step: 0
Training loss: 1.1258106231689453
Validation loss: 1.8633183317799722

Epoch: 5| Step: 1
Training loss: 1.088161826133728
Validation loss: 1.9424761867010465

Epoch: 5| Step: 2
Training loss: 1.001863956451416
Validation loss: 1.870825921335528

Epoch: 5| Step: 3
Training loss: 0.7116277813911438
Validation loss: 1.9188638758915726

Epoch: 5| Step: 4
Training loss: 1.582021713256836
Validation loss: 1.9695943529887865

Epoch: 5| Step: 5
Training loss: 1.077832818031311
Validation loss: 1.864558219909668

Epoch: 5| Step: 6
Training loss: 1.7847096920013428
Validation loss: 1.9213538964589436

Epoch: 5| Step: 7
Training loss: 0.8498020172119141
Validation loss: 1.8174714093567224

Epoch: 5| Step: 8
Training loss: 1.248281478881836
Validation loss: 1.848361284502091

Epoch: 5| Step: 9
Training loss: 1.8208913803100586
Validation loss: 1.9055461870726718

Epoch: 5| Step: 10
Training loss: 1.6859207153320312
Validation loss: 1.8571219841639202

Epoch: 392| Step: 0
Training loss: 1.1654531955718994
Validation loss: 1.8973791009636336

Epoch: 5| Step: 1
Training loss: 0.7603025436401367
Validation loss: 1.907637241066143

Epoch: 5| Step: 2
Training loss: 1.5782686471939087
Validation loss: 1.948883714214448

Epoch: 5| Step: 3
Training loss: 0.9926220178604126
Validation loss: 1.8743305437026485

Epoch: 5| Step: 4
Training loss: 1.345394492149353
Validation loss: 1.8957131742149271

Epoch: 5| Step: 5
Training loss: 1.0298409461975098
Validation loss: 1.877456222811053

Epoch: 5| Step: 6
Training loss: 1.9013452529907227
Validation loss: 1.9525191066085652

Epoch: 5| Step: 7
Training loss: 1.1918814182281494
Validation loss: 1.8470911774584042

Epoch: 5| Step: 8
Training loss: 1.7391855716705322
Validation loss: 1.8867103207495906

Epoch: 5| Step: 9
Training loss: 1.2566556930541992
Validation loss: 1.9353167010891823

Epoch: 5| Step: 10
Training loss: 1.0561590194702148
Validation loss: 1.9106633355540614

Epoch: 393| Step: 0
Training loss: 1.2567799091339111
Validation loss: 1.9473163184299265

Epoch: 5| Step: 1
Training loss: 0.9920943379402161
Validation loss: 1.8355282224634641

Epoch: 5| Step: 2
Training loss: 1.311443567276001
Validation loss: 1.8670583284029396

Epoch: 5| Step: 3
Training loss: 1.8482635021209717
Validation loss: 1.8691829032795404

Epoch: 5| Step: 4
Training loss: 1.356380820274353
Validation loss: 1.9646050494204286

Epoch: 5| Step: 5
Training loss: 0.8120711445808411
Validation loss: 1.907187060643268

Epoch: 5| Step: 6
Training loss: 1.1755954027175903
Validation loss: 1.8549620131010651

Epoch: 5| Step: 7
Training loss: 1.3998109102249146
Validation loss: 1.8973769064872497

Epoch: 5| Step: 8
Training loss: 0.9402802586555481
Validation loss: 1.9079283847603747

Epoch: 5| Step: 9
Training loss: 1.2883113622665405
Validation loss: 1.8734797341849214

Epoch: 5| Step: 10
Training loss: 1.2165226936340332
Validation loss: 1.920094669506114

Epoch: 394| Step: 0
Training loss: 1.1577494144439697
Validation loss: 1.8441183746501963

Epoch: 5| Step: 1
Training loss: 1.3119065761566162
Validation loss: 1.936795380807692

Epoch: 5| Step: 2
Training loss: 1.2681934833526611
Validation loss: 1.9604626342814455

Epoch: 5| Step: 3
Training loss: 1.1387547254562378
Validation loss: 1.909384354468315

Epoch: 5| Step: 4
Training loss: 1.2432034015655518
Validation loss: 1.8754739274260819

Epoch: 5| Step: 5
Training loss: 1.8689502477645874
Validation loss: 1.8770683273192375

Epoch: 5| Step: 6
Training loss: 1.0540043115615845
Validation loss: 1.8467253536306403

Epoch: 5| Step: 7
Training loss: 0.7500013113021851
Validation loss: 1.9101648881871214

Epoch: 5| Step: 8
Training loss: 1.2337687015533447
Validation loss: 1.8787953533152097

Epoch: 5| Step: 9
Training loss: 1.4551165103912354
Validation loss: 1.841137360501033

Epoch: 5| Step: 10
Training loss: 1.3505457639694214
Validation loss: 1.9103537990200905

Epoch: 395| Step: 0
Training loss: 0.9271038174629211
Validation loss: 1.9266902926147624

Epoch: 5| Step: 1
Training loss: 1.3642524480819702
Validation loss: 1.958301039152248

Epoch: 5| Step: 2
Training loss: 1.251499891281128
Validation loss: 1.958284003760225

Epoch: 5| Step: 3
Training loss: 0.7759596705436707
Validation loss: 1.9392562745719828

Epoch: 5| Step: 4
Training loss: 1.8255031108856201
Validation loss: 1.952950777546052

Epoch: 5| Step: 5
Training loss: 1.6742417812347412
Validation loss: 1.8948730602059314

Epoch: 5| Step: 6
Training loss: 0.9294673800468445
Validation loss: 1.9465908465846893

Epoch: 5| Step: 7
Training loss: 1.0637705326080322
Validation loss: 1.8595957615042245

Epoch: 5| Step: 8
Training loss: 1.6051476001739502
Validation loss: 1.8926446719836163

Epoch: 5| Step: 9
Training loss: 1.222630262374878
Validation loss: 1.9475566674304265

Epoch: 5| Step: 10
Training loss: 1.1731181144714355
Validation loss: 1.9423391293453913

Epoch: 396| Step: 0
Training loss: 0.8309799432754517
Validation loss: 1.8669316602009598

Epoch: 5| Step: 1
Training loss: 1.1326758861541748
Validation loss: 1.8907486315696471

Epoch: 5| Step: 2
Training loss: 1.7271945476531982
Validation loss: 1.9333803781899073

Epoch: 5| Step: 3
Training loss: 1.4782600402832031
Validation loss: 1.9654284882289108

Epoch: 5| Step: 4
Training loss: 1.0935115814208984
Validation loss: 1.9246024764994139

Epoch: 5| Step: 5
Training loss: 0.8742029070854187
Validation loss: 1.8958982575324275

Epoch: 5| Step: 6
Training loss: 0.8869598507881165
Validation loss: 1.9328490303408714

Epoch: 5| Step: 7
Training loss: 1.240351915359497
Validation loss: 1.8737113783436437

Epoch: 5| Step: 8
Training loss: 1.7961580753326416
Validation loss: 1.9369429875445623

Epoch: 5| Step: 9
Training loss: 1.6095731258392334
Validation loss: 1.8930036496090632

Epoch: 5| Step: 10
Training loss: 1.4088798761367798
Validation loss: 1.9091564173339515

Epoch: 397| Step: 0
Training loss: 1.1967566013336182
Validation loss: 1.930101143416538

Epoch: 5| Step: 1
Training loss: 1.328526496887207
Validation loss: 1.9323720009096208

Epoch: 5| Step: 2
Training loss: 1.0067377090454102
Validation loss: 1.9189350553738174

Epoch: 5| Step: 3
Training loss: 1.258253812789917
Validation loss: 1.9772373425063265

Epoch: 5| Step: 4
Training loss: 1.5376532077789307
Validation loss: 1.892418630661503

Epoch: 5| Step: 5
Training loss: 1.199715256690979
Validation loss: 1.9137961326106903

Epoch: 5| Step: 6
Training loss: 1.321007490158081
Validation loss: 1.9193550258554437

Epoch: 5| Step: 7
Training loss: 1.2054516077041626
Validation loss: 1.8898318890602357

Epoch: 5| Step: 8
Training loss: 1.2692677974700928
Validation loss: 1.9648962277238087

Epoch: 5| Step: 9
Training loss: 1.0777076482772827
Validation loss: 1.94104826834894

Epoch: 5| Step: 10
Training loss: 1.2617849111557007
Validation loss: 1.9429780052554222

Epoch: 398| Step: 0
Training loss: 1.13910710811615
Validation loss: 1.872501992410229

Epoch: 5| Step: 1
Training loss: 1.6004581451416016
Validation loss: 1.8910984941708144

Epoch: 5| Step: 2
Training loss: 0.9602680206298828
Validation loss: 1.8931068874174548

Epoch: 5| Step: 3
Training loss: 1.5636628866195679
Validation loss: 1.860833626921459

Epoch: 5| Step: 4
Training loss: 1.0961827039718628
Validation loss: 1.9046083214462444

Epoch: 5| Step: 5
Training loss: 1.4677873849868774
Validation loss: 1.8841134655860163

Epoch: 5| Step: 6
Training loss: 1.1375278234481812
Validation loss: 1.969884067453364

Epoch: 5| Step: 7
Training loss: 1.3473718166351318
Validation loss: 1.8881793996339202

Epoch: 5| Step: 8
Training loss: 1.1918208599090576
Validation loss: 1.8589700434797554

Epoch: 5| Step: 9
Training loss: 0.8340088129043579
Validation loss: 1.906039950668171

Epoch: 5| Step: 10
Training loss: 1.3307524919509888
Validation loss: 1.8841844771497993

Epoch: 399| Step: 0
Training loss: 0.9815242886543274
Validation loss: 1.888744511911946

Epoch: 5| Step: 1
Training loss: 1.4015958309173584
Validation loss: 1.8926441413100048

Epoch: 5| Step: 2
Training loss: 1.2774085998535156
Validation loss: 1.925436524934666

Epoch: 5| Step: 3
Training loss: 1.6266933679580688
Validation loss: 1.8880402259929205

Epoch: 5| Step: 4
Training loss: 1.5852155685424805
Validation loss: 1.881164353380921

Epoch: 5| Step: 5
Training loss: 0.999068558216095
Validation loss: 1.9096038905523156

Epoch: 5| Step: 6
Training loss: 1.168521523475647
Validation loss: 1.9375706590631956

Epoch: 5| Step: 7
Training loss: 1.2283718585968018
Validation loss: 1.9410752801484958

Epoch: 5| Step: 8
Training loss: 1.1347682476043701
Validation loss: 1.9464253494816441

Epoch: 5| Step: 9
Training loss: 1.4074500799179077
Validation loss: 1.9099509946761593

Epoch: 5| Step: 10
Training loss: 1.0860422849655151
Validation loss: 1.9598770064692344

Epoch: 400| Step: 0
Training loss: 1.3527177572250366
Validation loss: 1.9584989086274178

Epoch: 5| Step: 1
Training loss: 1.7097055912017822
Validation loss: 1.8765544916993828

Epoch: 5| Step: 2
Training loss: 0.9066227078437805
Validation loss: 1.9287595569446523

Epoch: 5| Step: 3
Training loss: 0.8265819549560547
Validation loss: 1.8746675214459818

Epoch: 5| Step: 4
Training loss: 1.2282124757766724
Validation loss: 1.9079741816366873

Epoch: 5| Step: 5
Training loss: 1.451087474822998
Validation loss: 1.9737776966505154

Epoch: 5| Step: 6
Training loss: 1.1870170831680298
Validation loss: 1.9178285162935975

Epoch: 5| Step: 7
Training loss: 1.537198543548584
Validation loss: 1.9494337715128416

Epoch: 5| Step: 8
Training loss: 1.4354422092437744
Validation loss: 1.9557150717704528

Epoch: 5| Step: 9
Training loss: 1.3577494621276855
Validation loss: 1.9011216548181349

Epoch: 5| Step: 10
Training loss: 0.6762636303901672
Validation loss: 1.9355078845895746

Epoch: 401| Step: 0
Training loss: 1.8463680744171143
Validation loss: 1.9417223263812322

Epoch: 5| Step: 1
Training loss: 1.5287044048309326
Validation loss: 1.9980575307723014

Epoch: 5| Step: 2
Training loss: 1.1846215724945068
Validation loss: 1.8696026058607205

Epoch: 5| Step: 3
Training loss: 1.1194026470184326
Validation loss: 1.9107509787364672

Epoch: 5| Step: 4
Training loss: 1.2473646402359009
Validation loss: 1.8796610293849823

Epoch: 5| Step: 5
Training loss: 1.452828049659729
Validation loss: 1.8567132796010664

Epoch: 5| Step: 6
Training loss: 0.6724807024002075
Validation loss: 1.9033089504447034

Epoch: 5| Step: 7
Training loss: 1.8467674255371094
Validation loss: 1.9560355422317341

Epoch: 5| Step: 8
Training loss: 0.8902519941329956
Validation loss: 1.870145998975282

Epoch: 5| Step: 9
Training loss: 1.0127699375152588
Validation loss: 1.8915943637970956

Epoch: 5| Step: 10
Training loss: 1.1701637506484985
Validation loss: 1.890541849597808

Epoch: 402| Step: 0
Training loss: 1.8694454431533813
Validation loss: 1.8745329354398994

Epoch: 5| Step: 1
Training loss: 1.0273312330245972
Validation loss: 1.7964007521188388

Epoch: 5| Step: 2
Training loss: 1.3344874382019043
Validation loss: 1.939661192637618

Epoch: 5| Step: 3
Training loss: 1.3741683959960938
Validation loss: 1.917614044681672

Epoch: 5| Step: 4
Training loss: 1.7151567935943604
Validation loss: 1.8774218405446699

Epoch: 5| Step: 5
Training loss: 0.9550650715827942
Validation loss: 1.8771945738023328

Epoch: 5| Step: 6
Training loss: 1.1206302642822266
Validation loss: 1.9261307024186658

Epoch: 5| Step: 7
Training loss: 1.437290906906128
Validation loss: 1.8873886921072518

Epoch: 5| Step: 8
Training loss: 0.8068515658378601
Validation loss: 1.9287145881242649

Epoch: 5| Step: 9
Training loss: 1.0833210945129395
Validation loss: 1.8393482700470956

Epoch: 5| Step: 10
Training loss: 1.1667989492416382
Validation loss: 1.9511568905204855

Epoch: 403| Step: 0
Training loss: 1.2503684759140015
Validation loss: 1.8912979274667718

Epoch: 5| Step: 1
Training loss: 1.1404017210006714
Validation loss: 1.879057635543167

Epoch: 5| Step: 2
Training loss: 1.296384572982788
Validation loss: 1.8729013819848337

Epoch: 5| Step: 3
Training loss: 1.1817220449447632
Validation loss: 1.9389148066120763

Epoch: 5| Step: 4
Training loss: 0.7963801622390747
Validation loss: 1.9706036839433896

Epoch: 5| Step: 5
Training loss: 0.9758226275444031
Validation loss: 1.8866180245594313

Epoch: 5| Step: 6
Training loss: 1.1337296962738037
Validation loss: 1.9117418322511899

Epoch: 5| Step: 7
Training loss: 1.4078772068023682
Validation loss: 1.834545414934876

Epoch: 5| Step: 8
Training loss: 1.1155840158462524
Validation loss: 1.8621227587423017

Epoch: 5| Step: 9
Training loss: 1.8232364654541016
Validation loss: 1.854961299127148

Epoch: 5| Step: 10
Training loss: 1.3733032941818237
Validation loss: 1.9156856472774217

Epoch: 404| Step: 0
Training loss: 1.8883975744247437
Validation loss: 1.9375591406258204

Epoch: 5| Step: 1
Training loss: 0.5770612955093384
Validation loss: 1.9136618670596872

Epoch: 5| Step: 2
Training loss: 1.5067914724349976
Validation loss: 1.8709517217451526

Epoch: 5| Step: 3
Training loss: 1.8064966201782227
Validation loss: 1.9352923618849887

Epoch: 5| Step: 4
Training loss: 0.948493480682373
Validation loss: 1.8386374340262464

Epoch: 5| Step: 5
Training loss: 1.0292670726776123
Validation loss: 1.8540207378325924

Epoch: 5| Step: 6
Training loss: 1.1544533967971802
Validation loss: 1.898318354801465

Epoch: 5| Step: 7
Training loss: 0.5823651552200317
Validation loss: 1.8881400041682745

Epoch: 5| Step: 8
Training loss: 1.139258623123169
Validation loss: 1.9242579475525887

Epoch: 5| Step: 9
Training loss: 2.022420883178711
Validation loss: 1.9114658140367078

Epoch: 5| Step: 10
Training loss: 1.1237175464630127
Validation loss: 1.869723391789262

Epoch: 405| Step: 0
Training loss: 1.606414556503296
Validation loss: 1.8813652300065564

Epoch: 5| Step: 1
Training loss: 1.278654932975769
Validation loss: 1.8225770483734787

Epoch: 5| Step: 2
Training loss: 1.0537967681884766
Validation loss: 1.8925718543350056

Epoch: 5| Step: 3
Training loss: 1.309061050415039
Validation loss: 1.897625232255587

Epoch: 5| Step: 4
Training loss: 0.9451149702072144
Validation loss: 1.9075008476934125

Epoch: 5| Step: 5
Training loss: 1.3536274433135986
Validation loss: 1.9089402691010506

Epoch: 5| Step: 6
Training loss: 1.1419334411621094
Validation loss: 1.9183804476132957

Epoch: 5| Step: 7
Training loss: 1.2431085109710693
Validation loss: 1.929155421513383

Epoch: 5| Step: 8
Training loss: 1.0395587682724
Validation loss: 1.9029139293137418

Epoch: 5| Step: 9
Training loss: 1.1767847537994385
Validation loss: 1.881011491180748

Epoch: 5| Step: 10
Training loss: 1.795374870300293
Validation loss: 1.9092419262855285

Epoch: 406| Step: 0
Training loss: 0.9619929194450378
Validation loss: 1.840962371518535

Epoch: 5| Step: 1
Training loss: 1.7583051919937134
Validation loss: 1.9016920033321585

Epoch: 5| Step: 2
Training loss: 1.2223403453826904
Validation loss: 1.929147021744841

Epoch: 5| Step: 3
Training loss: 1.19674813747406
Validation loss: 1.9000621918709046

Epoch: 5| Step: 4
Training loss: 0.8147772550582886
Validation loss: 1.9182965909281084

Epoch: 5| Step: 5
Training loss: 1.7704797983169556
Validation loss: 1.9161440672412995

Epoch: 5| Step: 6
Training loss: 1.1291019916534424
Validation loss: 1.8919062716986543

Epoch: 5| Step: 7
Training loss: 1.384198784828186
Validation loss: 1.9114500873832292

Epoch: 5| Step: 8
Training loss: 0.8323491215705872
Validation loss: 1.9078464123510546

Epoch: 5| Step: 9
Training loss: 0.9617948532104492
Validation loss: 1.9262371550324142

Epoch: 5| Step: 10
Training loss: 1.6531975269317627
Validation loss: 1.9183105653332126

Epoch: 407| Step: 0
Training loss: 1.834994912147522
Validation loss: 1.8675090882085985

Epoch: 5| Step: 1
Training loss: 0.8538213968276978
Validation loss: 1.9062730394383913

Epoch: 5| Step: 2
Training loss: 1.2875120639801025
Validation loss: 1.8836079323163597

Epoch: 5| Step: 3
Training loss: 1.3909130096435547
Validation loss: 1.8871972932610461

Epoch: 5| Step: 4
Training loss: 0.9161859750747681
Validation loss: 1.9226158959891206

Epoch: 5| Step: 5
Training loss: 1.686795949935913
Validation loss: 1.8979190831543298

Epoch: 5| Step: 6
Training loss: 1.6215457916259766
Validation loss: 1.8624905975916053

Epoch: 5| Step: 7
Training loss: 1.2898693084716797
Validation loss: 1.9512980958466888

Epoch: 5| Step: 8
Training loss: 1.125938057899475
Validation loss: 1.8450430285546087

Epoch: 5| Step: 9
Training loss: 0.8065236210823059
Validation loss: 1.8717856419983732

Epoch: 5| Step: 10
Training loss: 1.156914234161377
Validation loss: 1.9051279842212636

Epoch: 408| Step: 0
Training loss: 0.8617926836013794
Validation loss: 1.8525631222673642

Epoch: 5| Step: 1
Training loss: 0.7927874326705933
Validation loss: 1.8811613769941433

Epoch: 5| Step: 2
Training loss: 1.1049525737762451
Validation loss: 1.9069471577162385

Epoch: 5| Step: 3
Training loss: 0.9644768834114075
Validation loss: 1.936496921764907

Epoch: 5| Step: 4
Training loss: 1.429389238357544
Validation loss: 1.9502710578262166

Epoch: 5| Step: 5
Training loss: 1.1663124561309814
Validation loss: 1.860938015804496

Epoch: 5| Step: 6
Training loss: 1.2583351135253906
Validation loss: 1.8747016627301452

Epoch: 5| Step: 7
Training loss: 1.050940752029419
Validation loss: 1.9414722650281844

Epoch: 5| Step: 8
Training loss: 1.4343734979629517
Validation loss: 1.883238838564965

Epoch: 5| Step: 9
Training loss: 1.835942268371582
Validation loss: 1.878111070202243

Epoch: 5| Step: 10
Training loss: 1.5308736562728882
Validation loss: 1.874562292970637

Epoch: 409| Step: 0
Training loss: 1.4801337718963623
Validation loss: 1.9261859001651886

Epoch: 5| Step: 1
Training loss: 0.8672943115234375
Validation loss: 1.8840062067072878

Epoch: 5| Step: 2
Training loss: 1.0341475009918213
Validation loss: 1.8225468435595114

Epoch: 5| Step: 3
Training loss: 1.5856614112854004
Validation loss: 1.9503587010086223

Epoch: 5| Step: 4
Training loss: 1.2708368301391602
Validation loss: 1.885153260282291

Epoch: 5| Step: 5
Training loss: 1.348050832748413
Validation loss: 1.8201119207566785

Epoch: 5| Step: 6
Training loss: 1.515697717666626
Validation loss: 1.9110109857333604

Epoch: 5| Step: 7
Training loss: 1.0438474416732788
Validation loss: 1.899532764188705

Epoch: 5| Step: 8
Training loss: 1.404858946800232
Validation loss: 1.9491734120153612

Epoch: 5| Step: 9
Training loss: 0.9365142583847046
Validation loss: 1.917873728659845

Epoch: 5| Step: 10
Training loss: 0.9927518367767334
Validation loss: 1.918738902256053

Epoch: 410| Step: 0
Training loss: 1.884884238243103
Validation loss: 1.9424477815628052

Epoch: 5| Step: 1
Training loss: 1.3887159824371338
Validation loss: 1.9167288951976325

Epoch: 5| Step: 2
Training loss: 1.317444086074829
Validation loss: 1.94413584919386

Epoch: 5| Step: 3
Training loss: 0.8988165855407715
Validation loss: 1.950895345339211

Epoch: 5| Step: 4
Training loss: 1.0740854740142822
Validation loss: 1.862476809050447

Epoch: 5| Step: 5
Training loss: 0.9246591329574585
Validation loss: 1.916221071315068

Epoch: 5| Step: 6
Training loss: 1.1950103044509888
Validation loss: 1.9642422904250443

Epoch: 5| Step: 7
Training loss: 1.1773208379745483
Validation loss: 1.9018998222966348

Epoch: 5| Step: 8
Training loss: 1.6835209131240845
Validation loss: 1.881891321110469

Epoch: 5| Step: 9
Training loss: 1.1813442707061768
Validation loss: 1.90823285554045

Epoch: 5| Step: 10
Training loss: 0.7709060907363892
Validation loss: 1.9376393210503362

Epoch: 411| Step: 0
Training loss: 1.292030692100525
Validation loss: 1.9618227866388136

Epoch: 5| Step: 1
Training loss: 1.3475176095962524
Validation loss: 1.8885676117353543

Epoch: 5| Step: 2
Training loss: 1.2830928564071655
Validation loss: 1.8598706722259521

Epoch: 5| Step: 3
Training loss: 1.8223234415054321
Validation loss: 1.8603438177416403

Epoch: 5| Step: 4
Training loss: 1.1417484283447266
Validation loss: 1.9550980355149956

Epoch: 5| Step: 5
Training loss: 1.2870479822158813
Validation loss: 1.9344978037700857

Epoch: 5| Step: 6
Training loss: 0.9844279289245605
Validation loss: 1.9086349510377454

Epoch: 5| Step: 7
Training loss: 1.084267258644104
Validation loss: 1.9523111261347288

Epoch: 5| Step: 8
Training loss: 1.4621809720993042
Validation loss: 1.959679534358363

Epoch: 5| Step: 9
Training loss: 1.1335712671279907
Validation loss: 1.8986219744528494

Epoch: 5| Step: 10
Training loss: 1.4791383743286133
Validation loss: 1.8829954221684446

Epoch: 412| Step: 0
Training loss: 0.7477697134017944
Validation loss: 1.9317271940169796

Epoch: 5| Step: 1
Training loss: 1.3809491395950317
Validation loss: 1.8343823289358487

Epoch: 5| Step: 2
Training loss: 1.5435906648635864
Validation loss: 1.890965538640176

Epoch: 5| Step: 3
Training loss: 1.2811639308929443
Validation loss: 1.900430538321054

Epoch: 5| Step: 4
Training loss: 1.8087921142578125
Validation loss: 1.8316698792160198

Epoch: 5| Step: 5
Training loss: 1.1634204387664795
Validation loss: 1.8973950237356207

Epoch: 5| Step: 6
Training loss: 1.3146882057189941
Validation loss: 1.8557005928408714

Epoch: 5| Step: 7
Training loss: 1.0432974100112915
Validation loss: 1.9762361959744525

Epoch: 5| Step: 8
Training loss: 1.3329054117202759
Validation loss: 1.8600523779469151

Epoch: 5| Step: 9
Training loss: 1.134255051612854
Validation loss: 1.953917331593011

Epoch: 5| Step: 10
Training loss: 1.1860239505767822
Validation loss: 1.9835738712741482

Epoch: 413| Step: 0
Training loss: 1.5342113971710205
Validation loss: 1.889103042182102

Epoch: 5| Step: 1
Training loss: 1.2532862424850464
Validation loss: 1.951545358985983

Epoch: 5| Step: 2
Training loss: 1.49078369140625
Validation loss: 1.8910097563138573

Epoch: 5| Step: 3
Training loss: 1.2323769330978394
Validation loss: 1.937733414352581

Epoch: 5| Step: 4
Training loss: 1.16571044921875
Validation loss: 1.8735306814152708

Epoch: 5| Step: 5
Training loss: 0.9329160451889038
Validation loss: 1.9365982663246892

Epoch: 5| Step: 6
Training loss: 1.0202739238739014
Validation loss: 1.9206202991547123

Epoch: 5| Step: 7
Training loss: 1.1415722370147705
Validation loss: 1.8581003399305447

Epoch: 5| Step: 8
Training loss: 1.3279176950454712
Validation loss: 1.9330757433368313

Epoch: 5| Step: 9
Training loss: 0.9412063360214233
Validation loss: 1.936801682236374

Epoch: 5| Step: 10
Training loss: 1.5764358043670654
Validation loss: 1.920300317066972

Epoch: 414| Step: 0
Training loss: 1.4319459199905396
Validation loss: 1.9531436017764512

Epoch: 5| Step: 1
Training loss: 1.1508519649505615
Validation loss: 1.9218134636520057

Epoch: 5| Step: 2
Training loss: 1.2921884059906006
Validation loss: 1.9576405145788704

Epoch: 5| Step: 3
Training loss: 1.018539309501648
Validation loss: 1.9166994056394022

Epoch: 5| Step: 4
Training loss: 1.0111347436904907
Validation loss: 1.9510757141215826

Epoch: 5| Step: 5
Training loss: 1.1818145513534546
Validation loss: 1.9288751015099146

Epoch: 5| Step: 6
Training loss: 1.4585040807724
Validation loss: 1.8855105894868092

Epoch: 5| Step: 7
Training loss: 0.9636659622192383
Validation loss: 1.885372773293526

Epoch: 5| Step: 8
Training loss: 1.0305306911468506
Validation loss: 1.9272958155601256

Epoch: 5| Step: 9
Training loss: 1.6740577220916748
Validation loss: 1.9140661685697493

Epoch: 5| Step: 10
Training loss: 1.2294293642044067
Validation loss: 1.9200407151252992

Epoch: 415| Step: 0
Training loss: 1.3099581003189087
Validation loss: 1.8594355019189979

Epoch: 5| Step: 1
Training loss: 1.580514907836914
Validation loss: 1.8981759317459599

Epoch: 5| Step: 2
Training loss: 0.949567973613739
Validation loss: 1.9037455730540778

Epoch: 5| Step: 3
Training loss: 1.4457913637161255
Validation loss: 1.8543234191915041

Epoch: 5| Step: 4
Training loss: 0.7126410603523254
Validation loss: 1.9003509039519935

Epoch: 5| Step: 5
Training loss: 1.1676603555679321
Validation loss: 1.877135815158967

Epoch: 5| Step: 6
Training loss: 1.7522062063217163
Validation loss: 1.8471301768415718

Epoch: 5| Step: 7
Training loss: 0.8433228731155396
Validation loss: 1.8752803212852889

Epoch: 5| Step: 8
Training loss: 1.2258275747299194
Validation loss: 1.9422530551110544

Epoch: 5| Step: 9
Training loss: 1.2046540975570679
Validation loss: 1.846900434904201

Epoch: 5| Step: 10
Training loss: 1.1823359727859497
Validation loss: 1.9750513517728416

Epoch: 416| Step: 0
Training loss: 1.202528476715088
Validation loss: 1.8751251992358957

Epoch: 5| Step: 1
Training loss: 1.6374019384384155
Validation loss: 1.898032654998123

Epoch: 5| Step: 2
Training loss: 1.366206407546997
Validation loss: 1.9433854254343177

Epoch: 5| Step: 3
Training loss: 0.6674877405166626
Validation loss: 1.9542110863552298

Epoch: 5| Step: 4
Training loss: 1.192948341369629
Validation loss: 1.9318170239848476

Epoch: 5| Step: 5
Training loss: 1.1549415588378906
Validation loss: 1.9036329625755228

Epoch: 5| Step: 6
Training loss: 1.016897201538086
Validation loss: 1.8542675125983454

Epoch: 5| Step: 7
Training loss: 1.3159310817718506
Validation loss: 1.8765926155992734

Epoch: 5| Step: 8
Training loss: 1.540167212486267
Validation loss: 1.9328317539666289

Epoch: 5| Step: 9
Training loss: 1.4700815677642822
Validation loss: 1.895704759064541

Epoch: 5| Step: 10
Training loss: 0.8322069644927979
Validation loss: 1.915613861494167

Epoch: 417| Step: 0
Training loss: 0.8166260719299316
Validation loss: 1.907801930622388

Epoch: 5| Step: 1
Training loss: 1.0965478420257568
Validation loss: 1.9009351140709334

Epoch: 5| Step: 2
Training loss: 0.9180951118469238
Validation loss: 1.914032805350519

Epoch: 5| Step: 3
Training loss: 1.1831352710723877
Validation loss: 1.8610548614173807

Epoch: 5| Step: 4
Training loss: 1.5463321208953857
Validation loss: 1.8774343959746822

Epoch: 5| Step: 5
Training loss: 1.1001946926116943
Validation loss: 1.8904387566351122

Epoch: 5| Step: 6
Training loss: 1.0631810426712036
Validation loss: 1.8921226352773688

Epoch: 5| Step: 7
Training loss: 1.648672342300415
Validation loss: 1.9130407430792367

Epoch: 5| Step: 8
Training loss: 1.1150842905044556
Validation loss: 1.8733665558599657

Epoch: 5| Step: 9
Training loss: 1.8749719858169556
Validation loss: 1.9027199668269004

Epoch: 5| Step: 10
Training loss: 0.9689680933952332
Validation loss: 1.8752712639429236

Epoch: 418| Step: 0
Training loss: 1.193331241607666
Validation loss: 1.9132672984112975

Epoch: 5| Step: 1
Training loss: 1.4698858261108398
Validation loss: 1.8645355342536845

Epoch: 5| Step: 2
Training loss: 1.301999807357788
Validation loss: 1.8851941721413725

Epoch: 5| Step: 3
Training loss: 1.1500331163406372
Validation loss: 1.8687498441306494

Epoch: 5| Step: 4
Training loss: 1.0379326343536377
Validation loss: 1.9305531363333426

Epoch: 5| Step: 5
Training loss: 0.9574990272521973
Validation loss: 1.9673167967027234

Epoch: 5| Step: 6
Training loss: 0.9752666354179382
Validation loss: 1.8822148730677943

Epoch: 5| Step: 7
Training loss: 1.140893578529358
Validation loss: 1.8819832032726658

Epoch: 5| Step: 8
Training loss: 1.6441646814346313
Validation loss: 1.8844955634045344

Epoch: 5| Step: 9
Training loss: 1.8181867599487305
Validation loss: 1.9676928956021544

Epoch: 5| Step: 10
Training loss: 0.8606657981872559
Validation loss: 1.8313045963164298

Epoch: 419| Step: 0
Training loss: 1.2807484865188599
Validation loss: 1.8827741248633272

Epoch: 5| Step: 1
Training loss: 1.4099912643432617
Validation loss: 1.9475578697778846

Epoch: 5| Step: 2
Training loss: 1.6139405965805054
Validation loss: 1.920994512496456

Epoch: 5| Step: 3
Training loss: 1.0563900470733643
Validation loss: 1.9489893144176853

Epoch: 5| Step: 4
Training loss: 1.5964043140411377
Validation loss: 1.9335705105976393

Epoch: 5| Step: 5
Training loss: 0.5594121813774109
Validation loss: 1.8946341942715388

Epoch: 5| Step: 6
Training loss: 0.7821772694587708
Validation loss: 1.9496801335324523

Epoch: 5| Step: 7
Training loss: 1.5960814952850342
Validation loss: 1.9372293282580633

Epoch: 5| Step: 8
Training loss: 0.8288617134094238
Validation loss: 1.9126973382888302

Epoch: 5| Step: 9
Training loss: 1.09437096118927
Validation loss: 1.892074300396827

Epoch: 5| Step: 10
Training loss: 1.3950519561767578
Validation loss: 1.8909645285657657

Epoch: 420| Step: 0
Training loss: 0.8638321757316589
Validation loss: 1.8911646937811246

Epoch: 5| Step: 1
Training loss: 1.5029245615005493
Validation loss: 1.8805890724223147

Epoch: 5| Step: 2
Training loss: 1.1851825714111328
Validation loss: 1.8947875397179716

Epoch: 5| Step: 3
Training loss: 1.5164296627044678
Validation loss: 1.8698322978070987

Epoch: 5| Step: 4
Training loss: 1.245553970336914
Validation loss: 1.8655226999713528

Epoch: 5| Step: 5
Training loss: 0.6347711086273193
Validation loss: 1.8518054767321515

Epoch: 5| Step: 6
Training loss: 1.4347764253616333
Validation loss: 1.928416403391028

Epoch: 5| Step: 7
Training loss: 1.3068755865097046
Validation loss: 1.9408918285882601

Epoch: 5| Step: 8
Training loss: 1.7181079387664795
Validation loss: 1.8440960748221285

Epoch: 5| Step: 9
Training loss: 1.1426446437835693
Validation loss: 1.8967143566377702

Epoch: 5| Step: 10
Training loss: 1.1688092947006226
Validation loss: 1.8927512835430842

Epoch: 421| Step: 0
Training loss: 1.2935174703598022
Validation loss: 1.8602100059550295

Epoch: 5| Step: 1
Training loss: 1.214117407798767
Validation loss: 1.924410932807512

Epoch: 5| Step: 2
Training loss: 1.3464138507843018
Validation loss: 1.9478049457714122

Epoch: 5| Step: 3
Training loss: 1.1355632543563843
Validation loss: 1.9059085999765704

Epoch: 5| Step: 4
Training loss: 1.3154520988464355
Validation loss: 1.9352710400858233

Epoch: 5| Step: 5
Training loss: 1.651694893836975
Validation loss: 1.9576148409997263

Epoch: 5| Step: 6
Training loss: 1.1604598760604858
Validation loss: 1.9354850220423874

Epoch: 5| Step: 7
Training loss: 1.3358807563781738
Validation loss: 1.9436113731835478

Epoch: 5| Step: 8
Training loss: 0.8912833333015442
Validation loss: 1.8942261293370237

Epoch: 5| Step: 9
Training loss: 1.0061465501785278
Validation loss: 1.9025785987095167

Epoch: 5| Step: 10
Training loss: 0.7295883893966675
Validation loss: 1.9490840435028076

Epoch: 422| Step: 0
Training loss: 1.638437271118164
Validation loss: 1.8860678057516775

Epoch: 5| Step: 1
Training loss: 1.4328792095184326
Validation loss: 1.9156401900834934

Epoch: 5| Step: 2
Training loss: 1.40871000289917
Validation loss: 1.9193006100193146

Epoch: 5| Step: 3
Training loss: 1.2022509574890137
Validation loss: 1.8881035325347737

Epoch: 5| Step: 4
Training loss: 0.9506582021713257
Validation loss: 1.8627179104794738

Epoch: 5| Step: 5
Training loss: 1.328925371170044
Validation loss: 1.909940960586712

Epoch: 5| Step: 6
Training loss: 1.1685634851455688
Validation loss: 1.8606802750659246

Epoch: 5| Step: 7
Training loss: 1.180088758468628
Validation loss: 1.9424909904438963

Epoch: 5| Step: 8
Training loss: 0.941489577293396
Validation loss: 1.859149625224452

Epoch: 5| Step: 9
Training loss: 0.8698664903640747
Validation loss: 1.8642075395071378

Epoch: 5| Step: 10
Training loss: 1.0906769037246704
Validation loss: 1.880685180746099

Epoch: 423| Step: 0
Training loss: 1.3598514795303345
Validation loss: 1.934420431813886

Epoch: 5| Step: 1
Training loss: 1.7035150527954102
Validation loss: 1.901947780322003

Epoch: 5| Step: 2
Training loss: 0.7258701324462891
Validation loss: 1.8156845095337077

Epoch: 5| Step: 3
Training loss: 0.9778226017951965
Validation loss: 1.919971868556033

Epoch: 5| Step: 4
Training loss: 1.1913306713104248
Validation loss: 1.9041526086868779

Epoch: 5| Step: 5
Training loss: 0.9186436533927917
Validation loss: 1.9001403418920373

Epoch: 5| Step: 6
Training loss: 1.2994221448898315
Validation loss: 1.8818164217856623

Epoch: 5| Step: 7
Training loss: 1.1611533164978027
Validation loss: 1.9299758967532907

Epoch: 5| Step: 8
Training loss: 1.868090033531189
Validation loss: 1.9324458952872985

Epoch: 5| Step: 9
Training loss: 0.7685051560401917
Validation loss: 1.9597829106033489

Epoch: 5| Step: 10
Training loss: 1.1952002048492432
Validation loss: 1.9364988752590713

Epoch: 424| Step: 0
Training loss: 1.133264183998108
Validation loss: 1.909903331469464

Epoch: 5| Step: 1
Training loss: 0.6437962651252747
Validation loss: 1.9526151713504587

Epoch: 5| Step: 2
Training loss: 1.5698261260986328
Validation loss: 1.9364921546751452

Epoch: 5| Step: 3
Training loss: 1.2282545566558838
Validation loss: 1.922205699387417

Epoch: 5| Step: 4
Training loss: 1.1376206874847412
Validation loss: 1.8634075785195956

Epoch: 5| Step: 5
Training loss: 1.3402866125106812
Validation loss: 1.8934510677091536

Epoch: 5| Step: 6
Training loss: 1.0918482542037964
Validation loss: 1.865545726591541

Epoch: 5| Step: 7
Training loss: 1.4579706192016602
Validation loss: 1.880564151271697

Epoch: 5| Step: 8
Training loss: 1.9718618392944336
Validation loss: 1.8998626150110716

Epoch: 5| Step: 9
Training loss: 0.8153980374336243
Validation loss: 1.8177537046453005

Epoch: 5| Step: 10
Training loss: 1.0897502899169922
Validation loss: 1.858584605237489

Epoch: 425| Step: 0
Training loss: 1.2928894758224487
Validation loss: 1.8987747571801628

Epoch: 5| Step: 1
Training loss: 1.8204091787338257
Validation loss: 1.8836844941621185

Epoch: 5| Step: 2
Training loss: 1.136290431022644
Validation loss: 1.8818576387179795

Epoch: 5| Step: 3
Training loss: 1.1008193492889404
Validation loss: 1.8335463487973778

Epoch: 5| Step: 4
Training loss: 1.396474003791809
Validation loss: 1.862805962562561

Epoch: 5| Step: 5
Training loss: 0.8152840733528137
Validation loss: 1.833428458500934

Epoch: 5| Step: 6
Training loss: 1.4316319227218628
Validation loss: 1.8910209799325595

Epoch: 5| Step: 7
Training loss: 0.8785950541496277
Validation loss: 1.9390453497568767

Epoch: 5| Step: 8
Training loss: 0.8521621823310852
Validation loss: 1.8994791866630636

Epoch: 5| Step: 9
Training loss: 1.4032785892486572
Validation loss: 1.90193534281946

Epoch: 5| Step: 10
Training loss: 0.994020938873291
Validation loss: 1.8828363431397306

Epoch: 426| Step: 0
Training loss: 1.2007949352264404
Validation loss: 1.9153469134402532

Epoch: 5| Step: 1
Training loss: 1.3088438510894775
Validation loss: 1.9206942871052732

Epoch: 5| Step: 2
Training loss: 1.3732826709747314
Validation loss: 1.8993499663568312

Epoch: 5| Step: 3
Training loss: 1.146254539489746
Validation loss: 1.9741887046444802

Epoch: 5| Step: 4
Training loss: 1.0949466228485107
Validation loss: 1.9094894265615812

Epoch: 5| Step: 5
Training loss: 1.0361855030059814
Validation loss: 1.9357014625303206

Epoch: 5| Step: 6
Training loss: 0.8000537753105164
Validation loss: 1.9317368435603317

Epoch: 5| Step: 7
Training loss: 1.4544252157211304
Validation loss: 1.8912601291492421

Epoch: 5| Step: 8
Training loss: 1.2957264184951782
Validation loss: 1.8533162186222691

Epoch: 5| Step: 9
Training loss: 1.0912797451019287
Validation loss: 1.89612792640604

Epoch: 5| Step: 10
Training loss: 1.4320881366729736
Validation loss: 1.9076464112086962

Epoch: 427| Step: 0
Training loss: 1.5399627685546875
Validation loss: 1.9120827541556409

Epoch: 5| Step: 1
Training loss: 1.2434301376342773
Validation loss: 1.8823389622472948

Epoch: 5| Step: 2
Training loss: 0.9446853399276733
Validation loss: 1.8594491392053583

Epoch: 5| Step: 3
Training loss: 1.0288010835647583
Validation loss: 1.8434970801876438

Epoch: 5| Step: 4
Training loss: 0.987180233001709
Validation loss: 1.9226419182233914

Epoch: 5| Step: 5
Training loss: 1.0434376001358032
Validation loss: 1.8719807901690084

Epoch: 5| Step: 6
Training loss: 1.3045536279678345
Validation loss: 1.850754855781473

Epoch: 5| Step: 7
Training loss: 1.1727473735809326
Validation loss: 1.884793899392569

Epoch: 5| Step: 8
Training loss: 1.2248562574386597
Validation loss: 1.9410940293342835

Epoch: 5| Step: 9
Training loss: 1.2331809997558594
Validation loss: 1.8929372500347834

Epoch: 5| Step: 10
Training loss: 1.4125620126724243
Validation loss: 1.8967554120607273

Epoch: 428| Step: 0
Training loss: 1.2169438600540161
Validation loss: 1.9005693440796227

Epoch: 5| Step: 1
Training loss: 0.9902717471122742
Validation loss: 1.8799741665522258

Epoch: 5| Step: 2
Training loss: 0.9411337971687317
Validation loss: 1.9101670467725365

Epoch: 5| Step: 3
Training loss: 1.1630491018295288
Validation loss: 1.9228408003366122

Epoch: 5| Step: 4
Training loss: 1.0783132314682007
Validation loss: 1.9406385729389806

Epoch: 5| Step: 5
Training loss: 1.2685494422912598
Validation loss: 1.8496917883555095

Epoch: 5| Step: 6
Training loss: 1.6291602849960327
Validation loss: 1.9641995019810174

Epoch: 5| Step: 7
Training loss: 1.1065027713775635
Validation loss: 1.949959220424775

Epoch: 5| Step: 8
Training loss: 1.1207339763641357
Validation loss: 1.8746606124344694

Epoch: 5| Step: 9
Training loss: 1.0076329708099365
Validation loss: 1.9177979192426127

Epoch: 5| Step: 10
Training loss: 1.1448858976364136
Validation loss: 1.8515541707315752

Epoch: 429| Step: 0
Training loss: 0.5547610521316528
Validation loss: 1.9356587574046145

Epoch: 5| Step: 1
Training loss: 0.7782723307609558
Validation loss: 1.9080580396036948

Epoch: 5| Step: 2
Training loss: 1.1597728729248047
Validation loss: 1.909345515312687

Epoch: 5| Step: 3
Training loss: 1.1631475687026978
Validation loss: 1.9561528005907614

Epoch: 5| Step: 4
Training loss: 1.2817339897155762
Validation loss: 1.9416249875099427

Epoch: 5| Step: 5
Training loss: 1.8183904886245728
Validation loss: 1.9038092115873932

Epoch: 5| Step: 6
Training loss: 1.267024278640747
Validation loss: 1.9448839720859323

Epoch: 5| Step: 7
Training loss: 1.298243522644043
Validation loss: 1.9033045871283418

Epoch: 5| Step: 8
Training loss: 1.2201473712921143
Validation loss: 1.9198656825609104

Epoch: 5| Step: 9
Training loss: 1.273538589477539
Validation loss: 1.9141729800931868

Epoch: 5| Step: 10
Training loss: 1.343631386756897
Validation loss: 1.8943389820796188

Epoch: 430| Step: 0
Training loss: 1.135867714881897
Validation loss: 1.8469253945094284

Epoch: 5| Step: 1
Training loss: 1.6661427021026611
Validation loss: 1.9039497977943831

Epoch: 5| Step: 2
Training loss: 0.9396251440048218
Validation loss: 1.9077762878069313

Epoch: 5| Step: 3
Training loss: 1.4164860248565674
Validation loss: 1.8191303271119312

Epoch: 5| Step: 4
Training loss: 0.899985671043396
Validation loss: 1.8823304817240725

Epoch: 5| Step: 5
Training loss: 0.7583134770393372
Validation loss: 1.9043667418982393

Epoch: 5| Step: 6
Training loss: 0.6407502889633179
Validation loss: 1.8960231683587516

Epoch: 5| Step: 7
Training loss: 1.6717529296875
Validation loss: 1.8384431049387941

Epoch: 5| Step: 8
Training loss: 1.1239944696426392
Validation loss: 1.9177410987115675

Epoch: 5| Step: 9
Training loss: 1.3099626302719116
Validation loss: 1.8882275499323362

Epoch: 5| Step: 10
Training loss: 1.3154523372650146
Validation loss: 1.9160973359179754

Epoch: 431| Step: 0
Training loss: 1.3151870965957642
Validation loss: 1.9140168466875631

Epoch: 5| Step: 1
Training loss: 1.5839459896087646
Validation loss: 1.8817630813967796

Epoch: 5| Step: 2
Training loss: 0.9872703552246094
Validation loss: 1.8766237881875807

Epoch: 5| Step: 3
Training loss: 0.9300284385681152
Validation loss: 1.9067475135608385

Epoch: 5| Step: 4
Training loss: 1.3480244874954224
Validation loss: 1.9493262921610186

Epoch: 5| Step: 5
Training loss: 1.0906438827514648
Validation loss: 1.914317218206262

Epoch: 5| Step: 6
Training loss: 1.0428062677383423
Validation loss: 1.9477155516224522

Epoch: 5| Step: 7
Training loss: 1.3925373554229736
Validation loss: 1.8583875522818616

Epoch: 5| Step: 8
Training loss: 1.4414318799972534
Validation loss: 1.8591642879670667

Epoch: 5| Step: 9
Training loss: 1.1172997951507568
Validation loss: 1.9428364384558894

Epoch: 5| Step: 10
Training loss: 1.0392999649047852
Validation loss: 1.85569013831436

Epoch: 432| Step: 0
Training loss: 0.8257328271865845
Validation loss: 1.8459189771324076

Epoch: 5| Step: 1
Training loss: 1.172365665435791
Validation loss: 1.9417599554984801

Epoch: 5| Step: 2
Training loss: 0.6916994452476501
Validation loss: 1.9139048220008932

Epoch: 5| Step: 3
Training loss: 0.801600456237793
Validation loss: 1.9082978297305364

Epoch: 5| Step: 4
Training loss: 1.4067370891571045
Validation loss: 1.8441805903629591

Epoch: 5| Step: 5
Training loss: 1.325286626815796
Validation loss: 1.8930309664818548

Epoch: 5| Step: 6
Training loss: 1.139265537261963
Validation loss: 1.8555255397673576

Epoch: 5| Step: 7
Training loss: 1.184377670288086
Validation loss: 1.8855962586659256

Epoch: 5| Step: 8
Training loss: 1.5161137580871582
Validation loss: 1.9455622485888902

Epoch: 5| Step: 9
Training loss: 1.0823545455932617
Validation loss: 1.87428500447222

Epoch: 5| Step: 10
Training loss: 1.6455252170562744
Validation loss: 1.9249892337347871

Epoch: 433| Step: 0
Training loss: 0.9607995748519897
Validation loss: 1.9015928173577914

Epoch: 5| Step: 1
Training loss: 0.7290345430374146
Validation loss: 1.893950673841661

Epoch: 5| Step: 2
Training loss: 0.951636791229248
Validation loss: 1.9146429338762838

Epoch: 5| Step: 3
Training loss: 1.4673888683319092
Validation loss: 1.9486174480889433

Epoch: 5| Step: 4
Training loss: 1.4629459381103516
Validation loss: 1.8958251104559949

Epoch: 5| Step: 5
Training loss: 1.6708781719207764
Validation loss: 1.8930352746799428

Epoch: 5| Step: 6
Training loss: 1.1168973445892334
Validation loss: 1.9237979842770485

Epoch: 5| Step: 7
Training loss: 1.3505330085754395
Validation loss: 1.9030395259139359

Epoch: 5| Step: 8
Training loss: 1.2684056758880615
Validation loss: 1.9261951305532967

Epoch: 5| Step: 9
Training loss: 1.3484500646591187
Validation loss: 1.9065336642726776

Epoch: 5| Step: 10
Training loss: 0.872897207736969
Validation loss: 1.9022079770283034

Epoch: 434| Step: 0
Training loss: 1.284842848777771
Validation loss: 1.9228416130106936

Epoch: 5| Step: 1
Training loss: 1.576775074005127
Validation loss: 1.9527942826670985

Epoch: 5| Step: 2
Training loss: 1.390877604484558
Validation loss: 1.7968410676525486

Epoch: 5| Step: 3
Training loss: 1.0726218223571777
Validation loss: 1.8753523762508104

Epoch: 5| Step: 4
Training loss: 1.0027902126312256
Validation loss: 1.9132685251133417

Epoch: 5| Step: 5
Training loss: 1.0486186742782593
Validation loss: 1.8771188874398508

Epoch: 5| Step: 6
Training loss: 1.209189772605896
Validation loss: 1.9546761794756817

Epoch: 5| Step: 7
Training loss: 1.1595251560211182
Validation loss: 1.8940838229271673

Epoch: 5| Step: 8
Training loss: 1.2492594718933105
Validation loss: 1.8801703991428498

Epoch: 5| Step: 9
Training loss: 1.1079195737838745
Validation loss: 1.8531763553619385

Epoch: 5| Step: 10
Training loss: 1.0841580629348755
Validation loss: 1.8613582708502328

Epoch: 435| Step: 0
Training loss: 1.0139437913894653
Validation loss: 1.951115608215332

Epoch: 5| Step: 1
Training loss: 0.9349125623703003
Validation loss: 1.8870040473117624

Epoch: 5| Step: 2
Training loss: 1.015082836151123
Validation loss: 1.869890619349736

Epoch: 5| Step: 3
Training loss: 1.3603732585906982
Validation loss: 1.8904426969507688

Epoch: 5| Step: 4
Training loss: 1.4301201105117798
Validation loss: 1.929632309944399

Epoch: 5| Step: 5
Training loss: 1.5893580913543701
Validation loss: 1.926891214104109

Epoch: 5| Step: 6
Training loss: 1.3797410726547241
Validation loss: 1.9263923988547376

Epoch: 5| Step: 7
Training loss: 0.8365176320075989
Validation loss: 1.857326840841642

Epoch: 5| Step: 8
Training loss: 1.149540662765503
Validation loss: 1.8913747161947272

Epoch: 5| Step: 9
Training loss: 1.3272385597229004
Validation loss: 1.9270219687492616

Epoch: 5| Step: 10
Training loss: 0.7553380131721497
Validation loss: 1.9272497148923977

Epoch: 436| Step: 0
Training loss: 1.398002028465271
Validation loss: 1.8671622763397873

Epoch: 5| Step: 1
Training loss: 0.927852988243103
Validation loss: 1.9040796910562823

Epoch: 5| Step: 2
Training loss: 1.3974802494049072
Validation loss: 1.8957053256291214

Epoch: 5| Step: 3
Training loss: 1.2915728092193604
Validation loss: 1.9386594731320617

Epoch: 5| Step: 4
Training loss: 1.0531584024429321
Validation loss: 1.9080723639457458

Epoch: 5| Step: 5
Training loss: 1.7093887329101562
Validation loss: 1.87041223818256

Epoch: 5| Step: 6
Training loss: 1.075916051864624
Validation loss: 1.7642579117128927

Epoch: 5| Step: 7
Training loss: 0.9746931195259094
Validation loss: 1.873526902608974

Epoch: 5| Step: 8
Training loss: 0.9261794090270996
Validation loss: 1.8745526626545896

Epoch: 5| Step: 9
Training loss: 1.2928804159164429
Validation loss: 1.8814408420234598

Epoch: 5| Step: 10
Training loss: 1.2992093563079834
Validation loss: 1.8161213013433641

Epoch: 437| Step: 0
Training loss: 1.0944033861160278
Validation loss: 1.8808102428272206

Epoch: 5| Step: 1
Training loss: 1.073065996170044
Validation loss: 1.8938621833760252

Epoch: 5| Step: 2
Training loss: 1.0202934741973877
Validation loss: 1.8727342415881414

Epoch: 5| Step: 3
Training loss: 1.717067003250122
Validation loss: 1.8960250116163684

Epoch: 5| Step: 4
Training loss: 1.617992639541626
Validation loss: 1.8590857982635498

Epoch: 5| Step: 5
Training loss: 1.3834456205368042
Validation loss: 1.8902627639873053

Epoch: 5| Step: 6
Training loss: 1.1096216440200806
Validation loss: 1.885579647556428

Epoch: 5| Step: 7
Training loss: 0.5419903993606567
Validation loss: 1.9870935716936666

Epoch: 5| Step: 8
Training loss: 1.2233202457427979
Validation loss: 1.8958586185209212

Epoch: 5| Step: 9
Training loss: 0.9014881253242493
Validation loss: 1.881614592767531

Epoch: 5| Step: 10
Training loss: 1.2168874740600586
Validation loss: 1.8858878240790418

Epoch: 438| Step: 0
Training loss: 1.2033687829971313
Validation loss: 1.8590084506619362

Epoch: 5| Step: 1
Training loss: 0.9127575159072876
Validation loss: 1.9512638738078456

Epoch: 5| Step: 2
Training loss: 1.5021865367889404
Validation loss: 1.944372247624141

Epoch: 5| Step: 3
Training loss: 0.8979195356369019
Validation loss: 1.8960923430740193

Epoch: 5| Step: 4
Training loss: 0.8402460813522339
Validation loss: 2.014980957072268

Epoch: 5| Step: 5
Training loss: 1.31020188331604
Validation loss: 1.9109753485648864

Epoch: 5| Step: 6
Training loss: 1.5293766260147095
Validation loss: 1.9322941687799269

Epoch: 5| Step: 7
Training loss: 1.0593974590301514
Validation loss: 1.864874687246097

Epoch: 5| Step: 8
Training loss: 1.6591062545776367
Validation loss: 1.9023653499541744

Epoch: 5| Step: 9
Training loss: 0.8679534792900085
Validation loss: 1.8573056113335393

Epoch: 5| Step: 10
Training loss: 1.3677338361740112
Validation loss: 1.904441947578102

Epoch: 439| Step: 0
Training loss: 1.0275280475616455
Validation loss: 1.9912457901944396

Epoch: 5| Step: 1
Training loss: 0.7393091917037964
Validation loss: 1.8685915649578135

Epoch: 5| Step: 2
Training loss: 1.2109880447387695
Validation loss: 1.885391343024469

Epoch: 5| Step: 3
Training loss: 1.6474212408065796
Validation loss: 1.8791941904252576

Epoch: 5| Step: 4
Training loss: 0.8426653742790222
Validation loss: 1.908686480214519

Epoch: 5| Step: 5
Training loss: 1.3311731815338135
Validation loss: 1.9451788779227965

Epoch: 5| Step: 6
Training loss: 1.4726569652557373
Validation loss: 1.8942988495672903

Epoch: 5| Step: 7
Training loss: 1.4203273057937622
Validation loss: 1.9059033470769082

Epoch: 5| Step: 8
Training loss: 1.1038944721221924
Validation loss: 1.925146218269102

Epoch: 5| Step: 9
Training loss: 1.014977216720581
Validation loss: 1.8877821481356056

Epoch: 5| Step: 10
Training loss: 1.285247564315796
Validation loss: 1.91315754254659

Epoch: 440| Step: 0
Training loss: 0.7635267376899719
Validation loss: 1.9119204731397732

Epoch: 5| Step: 1
Training loss: 1.3814438581466675
Validation loss: 1.9398839871088664

Epoch: 5| Step: 2
Training loss: 0.8810895085334778
Validation loss: 1.9525202846014371

Epoch: 5| Step: 3
Training loss: 1.0465940237045288
Validation loss: 1.867399191343656

Epoch: 5| Step: 4
Training loss: 1.0243825912475586
Validation loss: 1.8859247533223962

Epoch: 5| Step: 5
Training loss: 1.4263051748275757
Validation loss: 1.8415152590761903

Epoch: 5| Step: 6
Training loss: 1.2932924032211304
Validation loss: 1.9046842411000242

Epoch: 5| Step: 7
Training loss: 1.4254595041275024
Validation loss: 1.9170690351916897

Epoch: 5| Step: 8
Training loss: 0.7727283239364624
Validation loss: 1.9524134999962264

Epoch: 5| Step: 9
Training loss: 1.2699594497680664
Validation loss: 1.9084018609857047

Epoch: 5| Step: 10
Training loss: 1.6083801984786987
Validation loss: 1.8548466697815926

Epoch: 441| Step: 0
Training loss: 0.8168430328369141
Validation loss: 1.8978201778986121

Epoch: 5| Step: 1
Training loss: 1.2267465591430664
Validation loss: 1.878299028642716

Epoch: 5| Step: 2
Training loss: 1.1662462949752808
Validation loss: 1.9353408352021249

Epoch: 5| Step: 3
Training loss: 1.0788049697875977
Validation loss: 1.8239478693213513

Epoch: 5| Step: 4
Training loss: 1.4110828638076782
Validation loss: 1.9133921156647384

Epoch: 5| Step: 5
Training loss: 1.2945928573608398
Validation loss: 1.8692784232477988

Epoch: 5| Step: 6
Training loss: 1.0292662382125854
Validation loss: 1.9019147516578756

Epoch: 5| Step: 7
Training loss: 1.3005186319351196
Validation loss: 1.892218659001012

Epoch: 5| Step: 8
Training loss: 1.199325442314148
Validation loss: 1.9356799817854358

Epoch: 5| Step: 9
Training loss: 1.2156457901000977
Validation loss: 1.8858118211069415

Epoch: 5| Step: 10
Training loss: 1.2464213371276855
Validation loss: 1.9271873786885252

Epoch: 442| Step: 0
Training loss: 0.8882877230644226
Validation loss: 1.9839301404132639

Epoch: 5| Step: 1
Training loss: 0.7018617391586304
Validation loss: 1.8729499950203845

Epoch: 5| Step: 2
Training loss: 1.1264283657073975
Validation loss: 1.8820180085397535

Epoch: 5| Step: 3
Training loss: 1.1286935806274414
Validation loss: 1.9066181336679766

Epoch: 5| Step: 4
Training loss: 1.3342373371124268
Validation loss: 1.863888713621324

Epoch: 5| Step: 5
Training loss: 0.8114341497421265
Validation loss: 1.9080790242841166

Epoch: 5| Step: 6
Training loss: 1.2840759754180908
Validation loss: 1.812190160956434

Epoch: 5| Step: 7
Training loss: 1.8339369297027588
Validation loss: 1.9378810595440608

Epoch: 5| Step: 8
Training loss: 1.463646650314331
Validation loss: 1.959463543789361

Epoch: 5| Step: 9
Training loss: 1.1101820468902588
Validation loss: 1.9116417951481317

Epoch: 5| Step: 10
Training loss: 1.258325457572937
Validation loss: 1.9175295932318575

Epoch: 443| Step: 0
Training loss: 1.9249515533447266
Validation loss: 1.9006370062469153

Epoch: 5| Step: 1
Training loss: 1.4134596586227417
Validation loss: 1.9432242108929543

Epoch: 5| Step: 2
Training loss: 0.782855749130249
Validation loss: 1.918653142067694

Epoch: 5| Step: 3
Training loss: 1.2931857109069824
Validation loss: 1.8775008468217746

Epoch: 5| Step: 4
Training loss: 0.9000223278999329
Validation loss: 1.9113023076006161

Epoch: 5| Step: 5
Training loss: 1.536614179611206
Validation loss: 1.9159482538059194

Epoch: 5| Step: 6
Training loss: 0.8585870862007141
Validation loss: 1.9354573090871174

Epoch: 5| Step: 7
Training loss: 0.9280616641044617
Validation loss: 1.9030494202849686

Epoch: 5| Step: 8
Training loss: 1.2107899188995361
Validation loss: 1.8889646812151837

Epoch: 5| Step: 9
Training loss: 1.1186037063598633
Validation loss: 1.9005486119178034

Epoch: 5| Step: 10
Training loss: 1.1775405406951904
Validation loss: 1.8891071299070954

Epoch: 444| Step: 0
Training loss: 1.4951287508010864
Validation loss: 1.8852221632516513

Epoch: 5| Step: 1
Training loss: 1.074781894683838
Validation loss: 1.7850979451210267

Epoch: 5| Step: 2
Training loss: 0.9584771990776062
Validation loss: 1.9034790736372753

Epoch: 5| Step: 3
Training loss: 1.610144853591919
Validation loss: 1.9344302121029104

Epoch: 5| Step: 4
Training loss: 0.9242889285087585
Validation loss: 1.9088164439765356

Epoch: 5| Step: 5
Training loss: 0.7118829488754272
Validation loss: 1.890792747979523

Epoch: 5| Step: 6
Training loss: 0.7632535696029663
Validation loss: 1.836225753189415

Epoch: 5| Step: 7
Training loss: 1.2455114126205444
Validation loss: 1.8817996055849138

Epoch: 5| Step: 8
Training loss: 1.6266762018203735
Validation loss: 1.8368723853941886

Epoch: 5| Step: 9
Training loss: 1.3013719320297241
Validation loss: 1.8525212913431146

Epoch: 5| Step: 10
Training loss: 0.9318576455116272
Validation loss: 1.8858124543261785

Epoch: 445| Step: 0
Training loss: 0.9188963770866394
Validation loss: 1.930776035913857

Epoch: 5| Step: 1
Training loss: 0.6864131689071655
Validation loss: 1.9146119445882819

Epoch: 5| Step: 2
Training loss: 1.3452789783477783
Validation loss: 1.9488580598626086

Epoch: 5| Step: 3
Training loss: 1.0306317806243896
Validation loss: 1.8759657644456433

Epoch: 5| Step: 4
Training loss: 1.3029521703720093
Validation loss: 1.831972699652436

Epoch: 5| Step: 5
Training loss: 1.2494268417358398
Validation loss: 1.8686399331656836

Epoch: 5| Step: 6
Training loss: 1.0405116081237793
Validation loss: 1.9417631356946883

Epoch: 5| Step: 7
Training loss: 1.2772018909454346
Validation loss: 1.9979742611608198

Epoch: 5| Step: 8
Training loss: 1.1627309322357178
Validation loss: 1.9813788731892903

Epoch: 5| Step: 9
Training loss: 1.6728522777557373
Validation loss: 1.846091567829091

Epoch: 5| Step: 10
Training loss: 0.9385908842086792
Validation loss: 1.9259723053183606

Epoch: 446| Step: 0
Training loss: 1.2505663633346558
Validation loss: 1.8393272071756341

Epoch: 5| Step: 1
Training loss: 1.116267442703247
Validation loss: 1.880844509729775

Epoch: 5| Step: 2
Training loss: 0.9520872831344604
Validation loss: 1.9029310441786242

Epoch: 5| Step: 3
Training loss: 1.404987096786499
Validation loss: 1.8683695177878104

Epoch: 5| Step: 4
Training loss: 1.5013591051101685
Validation loss: 1.86674548861801

Epoch: 5| Step: 5
Training loss: 1.3121364116668701
Validation loss: 1.9309497328214749

Epoch: 5| Step: 6
Training loss: 1.1726547479629517
Validation loss: 1.8581057543395667

Epoch: 5| Step: 7
Training loss: 0.9726904630661011
Validation loss: 1.8204451658392464

Epoch: 5| Step: 8
Training loss: 0.867597758769989
Validation loss: 1.8842892339152675

Epoch: 5| Step: 9
Training loss: 1.3665579557418823
Validation loss: 1.9777819392501668

Epoch: 5| Step: 10
Training loss: 1.0723848342895508
Validation loss: 1.9110701443046652

Epoch: 447| Step: 0
Training loss: 1.0677032470703125
Validation loss: 1.9672479655153008

Epoch: 5| Step: 1
Training loss: 1.5175484418869019
Validation loss: 1.9015688973088418

Epoch: 5| Step: 2
Training loss: 1.0855066776275635
Validation loss: 1.8523697596724316

Epoch: 5| Step: 3
Training loss: 1.2053439617156982
Validation loss: 1.8015562975278465

Epoch: 5| Step: 4
Training loss: 0.7350630760192871
Validation loss: 1.8824014650878085

Epoch: 5| Step: 5
Training loss: 0.9638091325759888
Validation loss: 1.9196130896127352

Epoch: 5| Step: 6
Training loss: 1.6112655401229858
Validation loss: 1.8721192421451691

Epoch: 5| Step: 7
Training loss: 1.1004064083099365
Validation loss: 1.8347382955653693

Epoch: 5| Step: 8
Training loss: 1.1060738563537598
Validation loss: 1.878511736469884

Epoch: 5| Step: 9
Training loss: 1.6799825429916382
Validation loss: 1.8832108769365536

Epoch: 5| Step: 10
Training loss: 0.6506249904632568
Validation loss: 1.861625309913389

Epoch: 448| Step: 0
Training loss: 1.3237289190292358
Validation loss: 1.8192740896696686

Epoch: 5| Step: 1
Training loss: 1.5336352586746216
Validation loss: 1.8874166960357337

Epoch: 5| Step: 2
Training loss: 0.6863122582435608
Validation loss: 1.8382944112182946

Epoch: 5| Step: 3
Training loss: 1.365630865097046
Validation loss: 1.9553885998264435

Epoch: 5| Step: 4
Training loss: 0.9294939041137695
Validation loss: 1.90729574618801

Epoch: 5| Step: 5
Training loss: 0.7256934642791748
Validation loss: 1.891344504971658

Epoch: 5| Step: 6
Training loss: 1.2055902481079102
Validation loss: 1.875601622366136

Epoch: 5| Step: 7
Training loss: 0.9805291295051575
Validation loss: 1.8725971098869079

Epoch: 5| Step: 8
Training loss: 1.1663024425506592
Validation loss: 1.888578817408572

Epoch: 5| Step: 9
Training loss: 1.107176423072815
Validation loss: 1.8952951700456682

Epoch: 5| Step: 10
Training loss: 1.7353553771972656
Validation loss: 1.905196028371011

Epoch: 449| Step: 0
Training loss: 1.165594458580017
Validation loss: 1.8554961707002373

Epoch: 5| Step: 1
Training loss: 0.7488418817520142
Validation loss: 1.878069798151652

Epoch: 5| Step: 2
Training loss: 1.6171566247940063
Validation loss: 1.8823741379604544

Epoch: 5| Step: 3
Training loss: 1.1900873184204102
Validation loss: 1.909864325677195

Epoch: 5| Step: 4
Training loss: 0.8193140029907227
Validation loss: 1.8778266547828593

Epoch: 5| Step: 5
Training loss: 0.9431997537612915
Validation loss: 1.871231827684628

Epoch: 5| Step: 6
Training loss: 0.9852620363235474
Validation loss: 1.844488259284727

Epoch: 5| Step: 7
Training loss: 1.094329833984375
Validation loss: 1.8712529559289255

Epoch: 5| Step: 8
Training loss: 1.694581389427185
Validation loss: 1.8444578801431963

Epoch: 5| Step: 9
Training loss: 1.3707563877105713
Validation loss: 1.8937562998904978

Epoch: 5| Step: 10
Training loss: 1.2616348266601562
Validation loss: 1.9400616025411954

Epoch: 450| Step: 0
Training loss: 1.3654954433441162
Validation loss: 1.8865353676580614

Epoch: 5| Step: 1
Training loss: 1.089768648147583
Validation loss: 1.8543549122348908

Epoch: 5| Step: 2
Training loss: 0.7167788147926331
Validation loss: 1.8615340763522732

Epoch: 5| Step: 3
Training loss: 1.8050025701522827
Validation loss: 1.8772576803802161

Epoch: 5| Step: 4
Training loss: 1.7064510583877563
Validation loss: 1.8835833393117434

Epoch: 5| Step: 5
Training loss: 1.3748177289962769
Validation loss: 1.8509221089783536

Epoch: 5| Step: 6
Training loss: 0.8882806897163391
Validation loss: 1.9226723473559144

Epoch: 5| Step: 7
Training loss: 0.9140644073486328
Validation loss: 1.9245475056350871

Epoch: 5| Step: 8
Training loss: 0.7097007036209106
Validation loss: 1.9386681202919251

Epoch: 5| Step: 9
Training loss: 0.737781822681427
Validation loss: 1.8955671543716102

Epoch: 5| Step: 10
Training loss: 0.8005449771881104
Validation loss: 1.833108470004092

Epoch: 451| Step: 0
Training loss: 1.0967036485671997
Validation loss: 1.8948495106030536

Epoch: 5| Step: 1
Training loss: 1.6107006072998047
Validation loss: 1.8941748885698215

Epoch: 5| Step: 2
Training loss: 1.3089947700500488
Validation loss: 1.8266354389088129

Epoch: 5| Step: 3
Training loss: 0.8582808375358582
Validation loss: 1.9343053653676023

Epoch: 5| Step: 4
Training loss: 0.9869030117988586
Validation loss: 1.9317759134436165

Epoch: 5| Step: 5
Training loss: 1.2725293636322021
Validation loss: 1.8945177806321012

Epoch: 5| Step: 6
Training loss: 1.2812246084213257
Validation loss: 1.8890888562766455

Epoch: 5| Step: 7
Training loss: 1.6009814739227295
Validation loss: 1.885939682683637

Epoch: 5| Step: 8
Training loss: 0.385053813457489
Validation loss: 1.8656809214622743

Epoch: 5| Step: 9
Training loss: 1.1922013759613037
Validation loss: 1.893898517854752

Epoch: 5| Step: 10
Training loss: 0.9193543791770935
Validation loss: 1.9117323172989713

Epoch: 452| Step: 0
Training loss: 1.192649006843567
Validation loss: 1.8737839710327886

Epoch: 5| Step: 1
Training loss: 0.966931164264679
Validation loss: 1.9268947955100768

Epoch: 5| Step: 2
Training loss: 1.2445117235183716
Validation loss: 1.8815522514363772

Epoch: 5| Step: 3
Training loss: 1.6244014501571655
Validation loss: 1.8899866893727293

Epoch: 5| Step: 4
Training loss: 0.6293621063232422
Validation loss: 1.8387708189666911

Epoch: 5| Step: 5
Training loss: 1.096684455871582
Validation loss: 1.9334172664150115

Epoch: 5| Step: 6
Training loss: 1.057842493057251
Validation loss: 1.8921575238627772

Epoch: 5| Step: 7
Training loss: 1.38503897190094
Validation loss: 1.8877180468651555

Epoch: 5| Step: 8
Training loss: 1.158477783203125
Validation loss: 1.860927435659593

Epoch: 5| Step: 9
Training loss: 0.9626392126083374
Validation loss: 1.91969084483321

Epoch: 5| Step: 10
Training loss: 1.4328433275222778
Validation loss: 1.8329097635002547

Epoch: 453| Step: 0
Training loss: 1.0947980880737305
Validation loss: 1.9099110621278004

Epoch: 5| Step: 1
Training loss: 1.0861382484436035
Validation loss: 1.8757841753703293

Epoch: 5| Step: 2
Training loss: 0.9189356565475464
Validation loss: 1.9152048992854294

Epoch: 5| Step: 3
Training loss: 1.4862943887710571
Validation loss: 1.8906112127406622

Epoch: 5| Step: 4
Training loss: 1.1357556581497192
Validation loss: 1.9039413672621532

Epoch: 5| Step: 5
Training loss: 1.5504575967788696
Validation loss: 1.8951027354886454

Epoch: 5| Step: 6
Training loss: 0.927820086479187
Validation loss: 1.965410364571438

Epoch: 5| Step: 7
Training loss: 1.1696176528930664
Validation loss: 1.905160827021445

Epoch: 5| Step: 8
Training loss: 0.9046003222465515
Validation loss: 1.906445066134135

Epoch: 5| Step: 9
Training loss: 1.360947608947754
Validation loss: 1.916571423571597

Epoch: 5| Step: 10
Training loss: 0.8410362601280212
Validation loss: 1.857613807083458

Epoch: 454| Step: 0
Training loss: 1.1095094680786133
Validation loss: 1.9044484656344178

Epoch: 5| Step: 1
Training loss: 1.2350012063980103
Validation loss: 1.8738399397942327

Epoch: 5| Step: 2
Training loss: 1.626617431640625
Validation loss: 1.8777049613255326

Epoch: 5| Step: 3
Training loss: 1.3794865608215332
Validation loss: 1.8130297737736856

Epoch: 5| Step: 4
Training loss: 0.6978086233139038
Validation loss: 1.8877511973022132

Epoch: 5| Step: 5
Training loss: 1.0801440477371216
Validation loss: 1.878086809189089

Epoch: 5| Step: 6
Training loss: 1.4264899492263794
Validation loss: 1.8514750760088685

Epoch: 5| Step: 7
Training loss: 0.9586113691329956
Validation loss: 1.8719070393552062

Epoch: 5| Step: 8
Training loss: 0.7758464813232422
Validation loss: 1.8333124832440448

Epoch: 5| Step: 9
Training loss: 1.3395382165908813
Validation loss: 1.9112156847471833

Epoch: 5| Step: 10
Training loss: 1.3016492128372192
Validation loss: 1.837225160291118

Epoch: 455| Step: 0
Training loss: 0.7413598895072937
Validation loss: 1.8807222163805397

Epoch: 5| Step: 1
Training loss: 1.3452764749526978
Validation loss: 1.8860787409608082

Epoch: 5| Step: 2
Training loss: 1.2348177433013916
Validation loss: 1.859751082235767

Epoch: 5| Step: 3
Training loss: 0.7030166387557983
Validation loss: 1.8919649329236758

Epoch: 5| Step: 4
Training loss: 1.5270159244537354
Validation loss: 1.9173369484563028

Epoch: 5| Step: 5
Training loss: 1.3525443077087402
Validation loss: 1.8211533190101705

Epoch: 5| Step: 6
Training loss: 0.822912335395813
Validation loss: 1.9269616578214912

Epoch: 5| Step: 7
Training loss: 1.0482269525527954
Validation loss: 1.8750926320270827

Epoch: 5| Step: 8
Training loss: 1.1612343788146973
Validation loss: 1.8424602080416936

Epoch: 5| Step: 9
Training loss: 1.3770287036895752
Validation loss: 1.921040650336973

Epoch: 5| Step: 10
Training loss: 1.294908046722412
Validation loss: 1.9098036045669227

Epoch: 456| Step: 0
Training loss: 1.2518937587738037
Validation loss: 1.8937145599754908

Epoch: 5| Step: 1
Training loss: 1.7539350986480713
Validation loss: 1.8783713822723718

Epoch: 5| Step: 2
Training loss: 0.6776229739189148
Validation loss: 1.8294144702214066

Epoch: 5| Step: 3
Training loss: 1.5727155208587646
Validation loss: 1.8883368751054168

Epoch: 5| Step: 4
Training loss: 1.2673122882843018
Validation loss: 1.8581889085872199

Epoch: 5| Step: 5
Training loss: 0.5906222462654114
Validation loss: 1.8414999297870103

Epoch: 5| Step: 6
Training loss: 1.1378960609436035
Validation loss: 1.8984995324124572

Epoch: 5| Step: 7
Training loss: 0.7872024178504944
Validation loss: 1.8392287223569808

Epoch: 5| Step: 8
Training loss: 1.092479944229126
Validation loss: 1.9253216405068674

Epoch: 5| Step: 9
Training loss: 0.9556293487548828
Validation loss: 1.813579297834827

Epoch: 5| Step: 10
Training loss: 1.4106353521347046
Validation loss: 1.8694810957036994

Epoch: 457| Step: 0
Training loss: 1.0170114040374756
Validation loss: 1.8703716698513235

Epoch: 5| Step: 1
Training loss: 0.8529893755912781
Validation loss: 1.8827693013734714

Epoch: 5| Step: 2
Training loss: 2.0791778564453125
Validation loss: 1.9301301971558602

Epoch: 5| Step: 3
Training loss: 1.4292956590652466
Validation loss: 1.8341400213139032

Epoch: 5| Step: 4
Training loss: 1.5096768140792847
Validation loss: 1.8280765491147195

Epoch: 5| Step: 5
Training loss: 0.8895547986030579
Validation loss: 1.898652938104445

Epoch: 5| Step: 6
Training loss: 1.3285564184188843
Validation loss: 1.816528686913111

Epoch: 5| Step: 7
Training loss: 0.8287549018859863
Validation loss: 1.847291963074797

Epoch: 5| Step: 8
Training loss: 0.8599376678466797
Validation loss: 1.9371948383187736

Epoch: 5| Step: 9
Training loss: 0.9625817537307739
Validation loss: 1.9366271624001123

Epoch: 5| Step: 10
Training loss: 0.800835371017456
Validation loss: 1.8935723356021348

Epoch: 458| Step: 0
Training loss: 1.3316186666488647
Validation loss: 1.9002903994693552

Epoch: 5| Step: 1
Training loss: 1.1759942770004272
Validation loss: 1.9186053558062481

Epoch: 5| Step: 2
Training loss: 0.8736379742622375
Validation loss: 1.8834934901165705

Epoch: 5| Step: 3
Training loss: 0.7267154455184937
Validation loss: 1.9204686111019504

Epoch: 5| Step: 4
Training loss: 1.045967936515808
Validation loss: 1.9155470773737917

Epoch: 5| Step: 5
Training loss: 1.2195994853973389
Validation loss: 1.8283216953277588

Epoch: 5| Step: 6
Training loss: 0.8572027087211609
Validation loss: 1.8951241303515691

Epoch: 5| Step: 7
Training loss: 1.1739494800567627
Validation loss: 1.8883318644697948

Epoch: 5| Step: 8
Training loss: 1.560899019241333
Validation loss: 1.87499237573275

Epoch: 5| Step: 9
Training loss: 1.5102226734161377
Validation loss: 1.9173149447287283

Epoch: 5| Step: 10
Training loss: 1.0725935697555542
Validation loss: 1.8558889255728772

Epoch: 459| Step: 0
Training loss: 1.1200339794158936
Validation loss: 1.904804778355424

Epoch: 5| Step: 1
Training loss: 0.8794773817062378
Validation loss: 1.9125118537615704

Epoch: 5| Step: 2
Training loss: 1.2404617071151733
Validation loss: 1.919045050938924

Epoch: 5| Step: 3
Training loss: 0.8396274447441101
Validation loss: 1.872067561713598

Epoch: 5| Step: 4
Training loss: 1.1060031652450562
Validation loss: 1.8607791213579075

Epoch: 5| Step: 5
Training loss: 1.1932971477508545
Validation loss: 1.91214370471175

Epoch: 5| Step: 6
Training loss: 1.3008886575698853
Validation loss: 1.852180573248094

Epoch: 5| Step: 7
Training loss: 1.0034067630767822
Validation loss: 1.8921008494592482

Epoch: 5| Step: 8
Training loss: 1.3041863441467285
Validation loss: 1.9068908870861094

Epoch: 5| Step: 9
Training loss: 1.1618387699127197
Validation loss: 1.835314614798433

Epoch: 5| Step: 10
Training loss: 1.0769037008285522
Validation loss: 1.8611027527880926

Epoch: 460| Step: 0
Training loss: 1.1577472686767578
Validation loss: 1.8641776346391248

Epoch: 5| Step: 1
Training loss: 1.2315510511398315
Validation loss: 1.933193314460016

Epoch: 5| Step: 2
Training loss: 1.288102149963379
Validation loss: 1.8970563334803427

Epoch: 5| Step: 3
Training loss: 1.6658416986465454
Validation loss: 1.8691419337385444

Epoch: 5| Step: 4
Training loss: 0.8960014581680298
Validation loss: 1.8913222230890745

Epoch: 5| Step: 5
Training loss: 0.9801470637321472
Validation loss: 1.87828222269653

Epoch: 5| Step: 6
Training loss: 0.6111949682235718
Validation loss: 1.9432074716014247

Epoch: 5| Step: 7
Training loss: 1.3497812747955322
Validation loss: 1.8452497118262834

Epoch: 5| Step: 8
Training loss: 0.8997771143913269
Validation loss: 1.9242834660314745

Epoch: 5| Step: 9
Training loss: 1.102552890777588
Validation loss: 1.8768838945255484

Epoch: 5| Step: 10
Training loss: 0.9637466669082642
Validation loss: 1.8677153330977245

Epoch: 461| Step: 0
Training loss: 1.0696417093276978
Validation loss: 1.868549858370135

Epoch: 5| Step: 1
Training loss: 1.3591716289520264
Validation loss: 1.9250098402782152

Epoch: 5| Step: 2
Training loss: 1.0755486488342285
Validation loss: 1.861470773655881

Epoch: 5| Step: 3
Training loss: 1.2895164489746094
Validation loss: 1.925570264939339

Epoch: 5| Step: 4
Training loss: 1.1585805416107178
Validation loss: 1.8054369111214914

Epoch: 5| Step: 5
Training loss: 1.0596973896026611
Validation loss: 1.8937406052825272

Epoch: 5| Step: 6
Training loss: 0.806597113609314
Validation loss: 1.9311679665760328

Epoch: 5| Step: 7
Training loss: 1.0945825576782227
Validation loss: 1.8944731412395355

Epoch: 5| Step: 8
Training loss: 1.3271270990371704
Validation loss: 1.843227171128796

Epoch: 5| Step: 9
Training loss: 0.7408941388130188
Validation loss: 1.8516281227911673

Epoch: 5| Step: 10
Training loss: 1.1338731050491333
Validation loss: 1.8840790512741252

Epoch: 462| Step: 0
Training loss: 0.937599778175354
Validation loss: 1.8901150623957317

Epoch: 5| Step: 1
Training loss: 1.1496556997299194
Validation loss: 1.8837221771158197

Epoch: 5| Step: 2
Training loss: 1.7385847568511963
Validation loss: 1.8437323544615059

Epoch: 5| Step: 3
Training loss: 1.1611714363098145
Validation loss: 1.8847772844376103

Epoch: 5| Step: 4
Training loss: 1.0772875547409058
Validation loss: 1.9134185262905654

Epoch: 5| Step: 5
Training loss: 1.0892575979232788
Validation loss: 1.8905931941924556

Epoch: 5| Step: 6
Training loss: 1.2360807657241821
Validation loss: 1.893457156355663

Epoch: 5| Step: 7
Training loss: 1.0856009721755981
Validation loss: 1.9027245352345128

Epoch: 5| Step: 8
Training loss: 1.262707233428955
Validation loss: 1.9255856339649489

Epoch: 5| Step: 9
Training loss: 1.261480689048767
Validation loss: 1.88072032185011

Epoch: 5| Step: 10
Training loss: 0.5972588658332825
Validation loss: 1.8516189206031062

Epoch: 463| Step: 0
Training loss: 1.0814697742462158
Validation loss: 1.9046129039538804

Epoch: 5| Step: 1
Training loss: 1.4234155416488647
Validation loss: 1.916426932939919

Epoch: 5| Step: 2
Training loss: 1.0631706714630127
Validation loss: 1.8584317443191365

Epoch: 5| Step: 3
Training loss: 1.2549190521240234
Validation loss: 1.8974786689204555

Epoch: 5| Step: 4
Training loss: 1.1259845495224
Validation loss: 1.945960944698703

Epoch: 5| Step: 5
Training loss: 1.371699571609497
Validation loss: 1.8708575053881573

Epoch: 5| Step: 6
Training loss: 1.2930986881256104
Validation loss: 1.828473412862388

Epoch: 5| Step: 7
Training loss: 0.9333233833312988
Validation loss: 1.938202622116253

Epoch: 5| Step: 8
Training loss: 0.89167320728302
Validation loss: 1.863491669777901

Epoch: 5| Step: 9
Training loss: 1.1188889741897583
Validation loss: 1.8725966971407655

Epoch: 5| Step: 10
Training loss: 0.8335767388343811
Validation loss: 1.8265768718975846

Epoch: 464| Step: 0
Training loss: 0.7909499406814575
Validation loss: 1.8728983991889543

Epoch: 5| Step: 1
Training loss: 1.202193021774292
Validation loss: 1.8675250891716249

Epoch: 5| Step: 2
Training loss: 0.8968672752380371
Validation loss: 1.897159925071142

Epoch: 5| Step: 3
Training loss: 1.0990474224090576
Validation loss: 1.8462395424483924

Epoch: 5| Step: 4
Training loss: 0.8611809015274048
Validation loss: 1.8505395432954193

Epoch: 5| Step: 5
Training loss: 1.4079972505569458
Validation loss: 1.8561740844480452

Epoch: 5| Step: 6
Training loss: 1.1139312982559204
Validation loss: 1.8418837529356762

Epoch: 5| Step: 7
Training loss: 0.9644209146499634
Validation loss: 1.8266445667512956

Epoch: 5| Step: 8
Training loss: 1.1763877868652344
Validation loss: 1.8686099795884983

Epoch: 5| Step: 9
Training loss: 1.314760446548462
Validation loss: 1.8583315982613513

Epoch: 5| Step: 10
Training loss: 1.1407761573791504
Validation loss: 1.890210646455006

Epoch: 465| Step: 0
Training loss: 1.5814571380615234
Validation loss: 1.870539298621557

Epoch: 5| Step: 1
Training loss: 0.8166539072990417
Validation loss: 1.8702577121796147

Epoch: 5| Step: 2
Training loss: 1.3668254613876343
Validation loss: 1.8948974276101718

Epoch: 5| Step: 3
Training loss: 0.9929739236831665
Validation loss: 1.866872759275539

Epoch: 5| Step: 4
Training loss: 0.9683791995048523
Validation loss: 1.867761532465617

Epoch: 5| Step: 5
Training loss: 0.8334822654724121
Validation loss: 1.894383902190834

Epoch: 5| Step: 6
Training loss: 1.2209309339523315
Validation loss: 1.863852059969338

Epoch: 5| Step: 7
Training loss: 1.1969677209854126
Validation loss: 1.8367376186514413

Epoch: 5| Step: 8
Training loss: 0.7432507872581482
Validation loss: 1.992423031919746

Epoch: 5| Step: 9
Training loss: 1.6780483722686768
Validation loss: 1.8830804747919883

Epoch: 5| Step: 10
Training loss: 1.2059848308563232
Validation loss: 1.8385757746235016

Epoch: 466| Step: 0
Training loss: 0.8200753927230835
Validation loss: 1.8709125621344453

Epoch: 5| Step: 1
Training loss: 0.7021583318710327
Validation loss: 1.9136680710700251

Epoch: 5| Step: 2
Training loss: 1.3726803064346313
Validation loss: 1.876186886141377

Epoch: 5| Step: 3
Training loss: 0.6734218001365662
Validation loss: 1.8288802523766794

Epoch: 5| Step: 4
Training loss: 1.4206253290176392
Validation loss: 1.9145343649771907

Epoch: 5| Step: 5
Training loss: 1.4201124906539917
Validation loss: 1.9180047563327256

Epoch: 5| Step: 6
Training loss: 1.4891397953033447
Validation loss: 1.898310988180099

Epoch: 5| Step: 7
Training loss: 1.1558784246444702
Validation loss: 1.8749143295390631

Epoch: 5| Step: 8
Training loss: 1.1461588144302368
Validation loss: 1.9171788564292334

Epoch: 5| Step: 9
Training loss: 0.9597295522689819
Validation loss: 1.8637404172651229

Epoch: 5| Step: 10
Training loss: 1.2817926406860352
Validation loss: 1.8754349729066253

Epoch: 467| Step: 0
Training loss: 0.8732149004936218
Validation loss: 1.886305711602652

Epoch: 5| Step: 1
Training loss: 1.3988841772079468
Validation loss: 1.8824948187797301

Epoch: 5| Step: 2
Training loss: 1.3107903003692627
Validation loss: 1.864320050003708

Epoch: 5| Step: 3
Training loss: 1.181409478187561
Validation loss: 1.9083804110045075

Epoch: 5| Step: 4
Training loss: 1.3568999767303467
Validation loss: 1.9410122158706828

Epoch: 5| Step: 5
Training loss: 1.3091932535171509
Validation loss: 1.898264677293839

Epoch: 5| Step: 6
Training loss: 1.2804542779922485
Validation loss: 1.9428026650541572

Epoch: 5| Step: 7
Training loss: 0.7510493993759155
Validation loss: 1.87345048176345

Epoch: 5| Step: 8
Training loss: 1.280576467514038
Validation loss: 1.9314580220048145

Epoch: 5| Step: 9
Training loss: 0.731261670589447
Validation loss: 1.9003857105009017

Epoch: 5| Step: 10
Training loss: 0.6957108974456787
Validation loss: 1.8428372695881834

Epoch: 468| Step: 0
Training loss: 1.4317933320999146
Validation loss: 1.875859401559317

Epoch: 5| Step: 1
Training loss: 1.0460625886917114
Validation loss: 1.8676597392687233

Epoch: 5| Step: 2
Training loss: 0.666302502155304
Validation loss: 1.848902170376111

Epoch: 5| Step: 3
Training loss: 1.0318641662597656
Validation loss: 1.887229263141591

Epoch: 5| Step: 4
Training loss: 0.7196656465530396
Validation loss: 1.8751570832344793

Epoch: 5| Step: 5
Training loss: 1.320038080215454
Validation loss: 1.8569621603976014

Epoch: 5| Step: 6
Training loss: 1.0225296020507812
Validation loss: 1.8574117998923025

Epoch: 5| Step: 7
Training loss: 1.0377743244171143
Validation loss: 1.8709905532098585

Epoch: 5| Step: 8
Training loss: 1.741151213645935
Validation loss: 1.91497605077682

Epoch: 5| Step: 9
Training loss: 0.8120971918106079
Validation loss: 1.9408012526009673

Epoch: 5| Step: 10
Training loss: 1.3810681104660034
Validation loss: 1.8819126057368454

Epoch: 469| Step: 0
Training loss: 1.2684696912765503
Validation loss: 1.9386842109823739

Epoch: 5| Step: 1
Training loss: 1.0699585676193237
Validation loss: 1.9217966371966946

Epoch: 5| Step: 2
Training loss: 1.1904715299606323
Validation loss: 1.8724134070898897

Epoch: 5| Step: 3
Training loss: 1.1197621822357178
Validation loss: 1.879503385995024

Epoch: 5| Step: 4
Training loss: 0.9703184962272644
Validation loss: 1.8601825852547922

Epoch: 5| Step: 5
Training loss: 1.0674481391906738
Validation loss: 1.8729599868097613

Epoch: 5| Step: 6
Training loss: 1.1934798955917358
Validation loss: 1.8647462398775163

Epoch: 5| Step: 7
Training loss: 1.2421612739562988
Validation loss: 1.8283047214631112

Epoch: 5| Step: 8
Training loss: 1.147886037826538
Validation loss: 1.88452422747048

Epoch: 5| Step: 9
Training loss: 0.9064468145370483
Validation loss: 1.847696206902945

Epoch: 5| Step: 10
Training loss: 0.821747362613678
Validation loss: 1.860779062394173

Epoch: 470| Step: 0
Training loss: 1.7376693487167358
Validation loss: 1.8225577159594464

Epoch: 5| Step: 1
Training loss: 1.1060388088226318
Validation loss: 1.8686133738486999

Epoch: 5| Step: 2
Training loss: 1.3015661239624023
Validation loss: 1.7654332191713396

Epoch: 5| Step: 3
Training loss: 1.247873067855835
Validation loss: 1.79282751775557

Epoch: 5| Step: 4
Training loss: 0.9530460238456726
Validation loss: 1.855177314050736

Epoch: 5| Step: 5
Training loss: 0.7198666334152222
Validation loss: 1.875614558496783

Epoch: 5| Step: 6
Training loss: 0.9574861526489258
Validation loss: 1.8543860091957995

Epoch: 5| Step: 7
Training loss: 1.1460635662078857
Validation loss: 1.9143706701135124

Epoch: 5| Step: 8
Training loss: 0.902686595916748
Validation loss: 1.8615909302106468

Epoch: 5| Step: 9
Training loss: 1.2061207294464111
Validation loss: 1.8915251454999369

Epoch: 5| Step: 10
Training loss: 0.915596067905426
Validation loss: 1.8550433061456169

Epoch: 471| Step: 0
Training loss: 0.9998092651367188
Validation loss: 1.8616529203230334

Epoch: 5| Step: 1
Training loss: 1.1177747249603271
Validation loss: 1.891323031917695

Epoch: 5| Step: 2
Training loss: 1.4932587146759033
Validation loss: 1.851405559047576

Epoch: 5| Step: 3
Training loss: 1.3781874179840088
Validation loss: 1.8065676778875372

Epoch: 5| Step: 4
Training loss: 0.9779588580131531
Validation loss: 1.932739362921766

Epoch: 5| Step: 5
Training loss: 0.8563283681869507
Validation loss: 1.841529720573015

Epoch: 5| Step: 6
Training loss: 1.0835845470428467
Validation loss: 1.9052913394025577

Epoch: 5| Step: 7
Training loss: 1.0231173038482666
Validation loss: 1.919379077931886

Epoch: 5| Step: 8
Training loss: 0.7818093299865723
Validation loss: 1.8511726522958407

Epoch: 5| Step: 9
Training loss: 0.9712216258049011
Validation loss: 1.8750347296396892

Epoch: 5| Step: 10
Training loss: 1.2042862176895142
Validation loss: 1.8801883369363763

Epoch: 472| Step: 0
Training loss: 0.9975044131278992
Validation loss: 1.8688209902855657

Epoch: 5| Step: 1
Training loss: 1.0077310800552368
Validation loss: 1.867027949261409

Epoch: 5| Step: 2
Training loss: 1.2340401411056519
Validation loss: 1.8793009993850545

Epoch: 5| Step: 3
Training loss: 1.079371452331543
Validation loss: 1.8479262654499342

Epoch: 5| Step: 4
Training loss: 1.1705597639083862
Validation loss: 1.8650409111412622

Epoch: 5| Step: 5
Training loss: 1.2373485565185547
Validation loss: 1.8973074164441837

Epoch: 5| Step: 6
Training loss: 0.9389912486076355
Validation loss: 1.8429086759526243

Epoch: 5| Step: 7
Training loss: 1.1831791400909424
Validation loss: 1.9341669736369964

Epoch: 5| Step: 8
Training loss: 1.434154748916626
Validation loss: 1.8466736373081003

Epoch: 5| Step: 9
Training loss: 0.9544429779052734
Validation loss: 1.933217143499723

Epoch: 5| Step: 10
Training loss: 0.8547503352165222
Validation loss: 1.8766480876553444

Epoch: 473| Step: 0
Training loss: 0.9180954098701477
Validation loss: 1.8230975879135953

Epoch: 5| Step: 1
Training loss: 0.9260687828063965
Validation loss: 1.8449293439106276

Epoch: 5| Step: 2
Training loss: 1.3789786100387573
Validation loss: 1.9130735858794181

Epoch: 5| Step: 3
Training loss: 0.9905099868774414
Validation loss: 1.8416616147564304

Epoch: 5| Step: 4
Training loss: 1.1314679384231567
Validation loss: 1.9119681594192341

Epoch: 5| Step: 5
Training loss: 1.5050417184829712
Validation loss: 1.8797084375094342

Epoch: 5| Step: 6
Training loss: 0.991083025932312
Validation loss: 1.879537328597038

Epoch: 5| Step: 7
Training loss: 1.1068893671035767
Validation loss: 1.8735774409386419

Epoch: 5| Step: 8
Training loss: 0.8331475257873535
Validation loss: 1.9283421231854347

Epoch: 5| Step: 9
Training loss: 1.1052687168121338
Validation loss: 1.8430210441671393

Epoch: 5| Step: 10
Training loss: 1.0463532209396362
Validation loss: 1.7932079799713627

Epoch: 474| Step: 0
Training loss: 1.2045577764511108
Validation loss: 1.890498262579723

Epoch: 5| Step: 1
Training loss: 1.0683637857437134
Validation loss: 1.896491592289299

Epoch: 5| Step: 2
Training loss: 1.4437991380691528
Validation loss: 1.8580422093791347

Epoch: 5| Step: 3
Training loss: 1.091012954711914
Validation loss: 1.8658672481454828

Epoch: 5| Step: 4
Training loss: 0.8249502182006836
Validation loss: 1.8380795691602974

Epoch: 5| Step: 5
Training loss: 1.2419378757476807
Validation loss: 1.8621961814101025

Epoch: 5| Step: 6
Training loss: 1.0302679538726807
Validation loss: 1.8715974336029382

Epoch: 5| Step: 7
Training loss: 0.717169463634491
Validation loss: 1.8716610272725422

Epoch: 5| Step: 8
Training loss: 1.1991878747940063
Validation loss: 1.8405331796215427

Epoch: 5| Step: 9
Training loss: 1.2456246614456177
Validation loss: 1.8816523667304748

Epoch: 5| Step: 10
Training loss: 0.6961289048194885
Validation loss: 1.8712179558251494

Epoch: 475| Step: 0
Training loss: 1.0694462060928345
Validation loss: 1.8421821414783437

Epoch: 5| Step: 1
Training loss: 1.1250396966934204
Validation loss: 1.845936115070056

Epoch: 5| Step: 2
Training loss: 1.7554848194122314
Validation loss: 1.8109266193964149

Epoch: 5| Step: 3
Training loss: 0.7973120212554932
Validation loss: 1.873861361575383

Epoch: 5| Step: 4
Training loss: 1.3162081241607666
Validation loss: 1.8217101558562248

Epoch: 5| Step: 5
Training loss: 1.0718616247177124
Validation loss: 1.8626085942791355

Epoch: 5| Step: 6
Training loss: 1.1293714046478271
Validation loss: 1.8837054467970324

Epoch: 5| Step: 7
Training loss: 1.252785325050354
Validation loss: 1.8499395642229306

Epoch: 5| Step: 8
Training loss: 1.0293580293655396
Validation loss: 1.8707637504864765

Epoch: 5| Step: 9
Training loss: 1.024855136871338
Validation loss: 1.8513232020921604

Epoch: 5| Step: 10
Training loss: 0.43436944484710693
Validation loss: 1.886991645700188

Epoch: 476| Step: 0
Training loss: 1.4029405117034912
Validation loss: 1.9308782931297057

Epoch: 5| Step: 1
Training loss: 0.7603289484977722
Validation loss: 1.9187199723336004

Epoch: 5| Step: 2
Training loss: 0.8107879757881165
Validation loss: 1.9189856795854465

Epoch: 5| Step: 3
Training loss: 1.2717275619506836
Validation loss: 1.9120907142598143

Epoch: 5| Step: 4
Training loss: 1.3755565881729126
Validation loss: 1.8632537229086763

Epoch: 5| Step: 5
Training loss: 0.9651939272880554
Validation loss: 1.8648664079686648

Epoch: 5| Step: 6
Training loss: 1.3565170764923096
Validation loss: 1.8596757932375836

Epoch: 5| Step: 7
Training loss: 0.8922867774963379
Validation loss: 1.862162523372199

Epoch: 5| Step: 8
Training loss: 0.9485664367675781
Validation loss: 1.8524751329934726

Epoch: 5| Step: 9
Training loss: 0.8558098077774048
Validation loss: 1.875674847633608

Epoch: 5| Step: 10
Training loss: 1.389275312423706
Validation loss: 1.961110705970436

Epoch: 477| Step: 0
Training loss: 0.9045316576957703
Validation loss: 1.896092099528159

Epoch: 5| Step: 1
Training loss: 0.9757224917411804
Validation loss: 1.8577353518496278

Epoch: 5| Step: 2
Training loss: 1.0358068943023682
Validation loss: 1.8523772198666808

Epoch: 5| Step: 3
Training loss: 1.166546106338501
Validation loss: 1.8906846046447754

Epoch: 5| Step: 4
Training loss: 1.2595291137695312
Validation loss: 1.9415488512285295

Epoch: 5| Step: 5
Training loss: 0.4607465863227844
Validation loss: 1.8496718124676776

Epoch: 5| Step: 6
Training loss: 1.36678147315979
Validation loss: 1.8592339126012658

Epoch: 5| Step: 7
Training loss: 1.2401647567749023
Validation loss: 1.874483282848071

Epoch: 5| Step: 8
Training loss: 0.8278430700302124
Validation loss: 1.9006304458905292

Epoch: 5| Step: 9
Training loss: 1.740813970565796
Validation loss: 1.8500290339992893

Epoch: 5| Step: 10
Training loss: 1.006363868713379
Validation loss: 1.9345221327197166

Epoch: 478| Step: 0
Training loss: 0.8363946080207825
Validation loss: 1.9438308259492278

Epoch: 5| Step: 1
Training loss: 1.1898193359375
Validation loss: 1.9036736795979161

Epoch: 5| Step: 2
Training loss: 0.6108490228652954
Validation loss: 1.9052543511954687

Epoch: 5| Step: 3
Training loss: 0.9651228785514832
Validation loss: 1.8468341929938203

Epoch: 5| Step: 4
Training loss: 1.678264856338501
Validation loss: 1.8663311107184297

Epoch: 5| Step: 5
Training loss: 0.7319074869155884
Validation loss: 1.870905524940901

Epoch: 5| Step: 6
Training loss: 1.314953088760376
Validation loss: 1.854767345613049

Epoch: 5| Step: 7
Training loss: 0.8595320582389832
Validation loss: 1.926943181663431

Epoch: 5| Step: 8
Training loss: 1.1558332443237305
Validation loss: 1.8853489096446703

Epoch: 5| Step: 9
Training loss: 0.9789085388183594
Validation loss: 1.867169234060472

Epoch: 5| Step: 10
Training loss: 1.4911442995071411
Validation loss: 1.8941571033129128

Epoch: 479| Step: 0
Training loss: 1.387880563735962
Validation loss: 1.9355201259736092

Epoch: 5| Step: 1
Training loss: 0.8841312527656555
Validation loss: 1.921814094307602

Epoch: 5| Step: 2
Training loss: 1.2253363132476807
Validation loss: 1.8602118402399042

Epoch: 5| Step: 3
Training loss: 0.7494561672210693
Validation loss: 1.8867607770427581

Epoch: 5| Step: 4
Training loss: 0.9988386034965515
Validation loss: 1.8547454751947874

Epoch: 5| Step: 5
Training loss: 1.348923921585083
Validation loss: 1.8715649420215237

Epoch: 5| Step: 6
Training loss: 1.3622925281524658
Validation loss: 1.91811450066105

Epoch: 5| Step: 7
Training loss: 0.9110684394836426
Validation loss: 1.9143554561881608

Epoch: 5| Step: 8
Training loss: 0.9441463351249695
Validation loss: 1.9209988476127706

Epoch: 5| Step: 9
Training loss: 1.0317270755767822
Validation loss: 1.8999961704336188

Epoch: 5| Step: 10
Training loss: 1.0821317434310913
Validation loss: 1.8981933625795508

Epoch: 480| Step: 0
Training loss: 1.4744793176651
Validation loss: 1.8548357743088917

Epoch: 5| Step: 1
Training loss: 0.8240398168563843
Validation loss: 1.89014999071757

Epoch: 5| Step: 2
Training loss: 0.9503351449966431
Validation loss: 1.8774531425968293

Epoch: 5| Step: 3
Training loss: 1.1350051164627075
Validation loss: 1.8483556996109665

Epoch: 5| Step: 4
Training loss: 0.4585968852043152
Validation loss: 1.9407167229601132

Epoch: 5| Step: 5
Training loss: 1.665653944015503
Validation loss: 1.837911618653164

Epoch: 5| Step: 6
Training loss: 1.495138168334961
Validation loss: 1.8540654515707364

Epoch: 5| Step: 7
Training loss: 0.9322606921195984
Validation loss: 1.8641137538417694

Epoch: 5| Step: 8
Training loss: 0.8674980401992798
Validation loss: 1.857782656146634

Epoch: 5| Step: 9
Training loss: 1.1601852178573608
Validation loss: 1.8702789903968893

Epoch: 5| Step: 10
Training loss: 0.9593425989151001
Validation loss: 1.8423396336135043

Epoch: 481| Step: 0
Training loss: 1.3222659826278687
Validation loss: 1.8384681209441154

Epoch: 5| Step: 1
Training loss: 1.0462331771850586
Validation loss: 1.872407982426305

Epoch: 5| Step: 2
Training loss: 1.188827395439148
Validation loss: 1.9243703631944553

Epoch: 5| Step: 3
Training loss: 0.951377272605896
Validation loss: 1.907902866281489

Epoch: 5| Step: 4
Training loss: 0.8460515141487122
Validation loss: 1.84479590769737

Epoch: 5| Step: 5
Training loss: 1.4621946811676025
Validation loss: 1.8123121094960037

Epoch: 5| Step: 6
Training loss: 1.2975953817367554
Validation loss: 1.8696638589264245

Epoch: 5| Step: 7
Training loss: 1.434645414352417
Validation loss: 1.8954075920966365

Epoch: 5| Step: 8
Training loss: 0.7577407956123352
Validation loss: 1.8945198059082031

Epoch: 5| Step: 9
Training loss: 0.9190545082092285
Validation loss: 1.8336875002871278

Epoch: 5| Step: 10
Training loss: 0.9060015678405762
Validation loss: 1.8955327054505706

Epoch: 482| Step: 0
Training loss: 0.9587991833686829
Validation loss: 1.8257643522754792

Epoch: 5| Step: 1
Training loss: 1.283851981163025
Validation loss: 1.8413538932800293

Epoch: 5| Step: 2
Training loss: 1.0541198253631592
Validation loss: 1.8643181388096144

Epoch: 5| Step: 3
Training loss: 1.5861924886703491
Validation loss: 1.8122124466844785

Epoch: 5| Step: 4
Training loss: 1.1179107427597046
Validation loss: 1.9003705081119333

Epoch: 5| Step: 5
Training loss: 0.6640132665634155
Validation loss: 1.90203925999262

Epoch: 5| Step: 6
Training loss: 1.173449158668518
Validation loss: 1.8970666521339006

Epoch: 5| Step: 7
Training loss: 1.0803136825561523
Validation loss: 1.8631891101919196

Epoch: 5| Step: 8
Training loss: 0.9187310338020325
Validation loss: 1.8777979932805544

Epoch: 5| Step: 9
Training loss: 0.569830596446991
Validation loss: 1.9355496809046755

Epoch: 5| Step: 10
Training loss: 1.1520299911499023
Validation loss: 1.893726089949249

Epoch: 483| Step: 0
Training loss: 0.9599056243896484
Validation loss: 1.8762733346672469

Epoch: 5| Step: 1
Training loss: 0.9697305560112
Validation loss: 1.8737325104334022

Epoch: 5| Step: 2
Training loss: 1.0207622051239014
Validation loss: 1.911710431498866

Epoch: 5| Step: 3
Training loss: 1.4304965734481812
Validation loss: 1.8825863984323317

Epoch: 5| Step: 4
Training loss: 1.013007402420044
Validation loss: 1.8160336120154268

Epoch: 5| Step: 5
Training loss: 1.5346757173538208
Validation loss: 1.8535918625452186

Epoch: 5| Step: 6
Training loss: 1.0091021060943604
Validation loss: 1.8460190847355833

Epoch: 5| Step: 7
Training loss: 0.7663373947143555
Validation loss: 1.8341175125491234

Epoch: 5| Step: 8
Training loss: 1.6451523303985596
Validation loss: 1.8412002260966966

Epoch: 5| Step: 9
Training loss: 1.0607343912124634
Validation loss: 1.8541889421401485

Epoch: 5| Step: 10
Training loss: 0.7768656611442566
Validation loss: 1.8806862831115723

Epoch: 484| Step: 0
Training loss: 1.2331674098968506
Validation loss: 1.922844184342251

Epoch: 5| Step: 1
Training loss: 0.9113188982009888
Validation loss: 1.8626181605041667

Epoch: 5| Step: 2
Training loss: 1.0530425310134888
Validation loss: 1.8622698758238105

Epoch: 5| Step: 3
Training loss: 0.8885202407836914
Validation loss: 1.8545956227087206

Epoch: 5| Step: 4
Training loss: 1.2855998277664185
Validation loss: 1.8010916197171776

Epoch: 5| Step: 5
Training loss: 0.8268967866897583
Validation loss: 1.8636983415131927

Epoch: 5| Step: 6
Training loss: 1.276680827140808
Validation loss: 1.8236015432624406

Epoch: 5| Step: 7
Training loss: 0.7983474135398865
Validation loss: 1.8484547151032316

Epoch: 5| Step: 8
Training loss: 1.3187555074691772
Validation loss: 1.8775819334932553

Epoch: 5| Step: 9
Training loss: 1.1575331687927246
Validation loss: 1.8551015315517303

Epoch: 5| Step: 10
Training loss: 1.2292770147323608
Validation loss: 1.8529993116214711

Epoch: 485| Step: 0
Training loss: 1.1583852767944336
Validation loss: 1.8960701573279597

Epoch: 5| Step: 1
Training loss: 1.0227075815200806
Validation loss: 1.8581708374843802

Epoch: 5| Step: 2
Training loss: 1.1342004537582397
Validation loss: 1.9006632784361481

Epoch: 5| Step: 3
Training loss: 1.3807477951049805
Validation loss: 1.841602699730986

Epoch: 5| Step: 4
Training loss: 0.9021226167678833
Validation loss: 1.8528659625719952

Epoch: 5| Step: 5
Training loss: 0.9358571171760559
Validation loss: 1.8981608793299685

Epoch: 5| Step: 6
Training loss: 0.723746657371521
Validation loss: 1.8824881353685934

Epoch: 5| Step: 7
Training loss: 0.6100741624832153
Validation loss: 1.8692251097771428

Epoch: 5| Step: 8
Training loss: 0.7504597902297974
Validation loss: 1.9070387553143244

Epoch: 5| Step: 9
Training loss: 1.3260220289230347
Validation loss: 1.8597309999568488

Epoch: 5| Step: 10
Training loss: 1.4212599992752075
Validation loss: 1.8976143662647535

Epoch: 486| Step: 0
Training loss: 1.32920241355896
Validation loss: 1.9355925488215622

Epoch: 5| Step: 1
Training loss: 0.9769183397293091
Validation loss: 1.903787507805773

Epoch: 5| Step: 2
Training loss: 1.2544817924499512
Validation loss: 1.8378175586782477

Epoch: 5| Step: 3
Training loss: 0.7769715189933777
Validation loss: 1.889155731406263

Epoch: 5| Step: 4
Training loss: 1.2216975688934326
Validation loss: 1.8485436272877518

Epoch: 5| Step: 5
Training loss: 1.1721744537353516
Validation loss: 1.8436833466252973

Epoch: 5| Step: 6
Training loss: 1.511269450187683
Validation loss: 1.8448813307669856

Epoch: 5| Step: 7
Training loss: 1.0360147953033447
Validation loss: 1.8590951247881817

Epoch: 5| Step: 8
Training loss: 0.9709588885307312
Validation loss: 1.8758725837994648

Epoch: 5| Step: 9
Training loss: 0.861197292804718
Validation loss: 1.8988852936734435

Epoch: 5| Step: 10
Training loss: 0.6922618746757507
Validation loss: 1.8314364187179073

Epoch: 487| Step: 0
Training loss: 0.5996893644332886
Validation loss: 1.800553708948115

Epoch: 5| Step: 1
Training loss: 0.997780978679657
Validation loss: 1.8199583971372215

Epoch: 5| Step: 2
Training loss: 1.0082371234893799
Validation loss: 1.8305219655395837

Epoch: 5| Step: 3
Training loss: 0.9712619781494141
Validation loss: 1.8768763272993025

Epoch: 5| Step: 4
Training loss: 1.3008618354797363
Validation loss: 1.837970672115203

Epoch: 5| Step: 5
Training loss: 1.6650797128677368
Validation loss: 1.9370520486626575

Epoch: 5| Step: 6
Training loss: 0.5945693850517273
Validation loss: 1.8512010805068477

Epoch: 5| Step: 7
Training loss: 0.9453384280204773
Validation loss: 1.8757814950840448

Epoch: 5| Step: 8
Training loss: 1.1893384456634521
Validation loss: 1.9019827765803183

Epoch: 5| Step: 9
Training loss: 1.1546897888183594
Validation loss: 1.8505535382096485

Epoch: 5| Step: 10
Training loss: 1.3700350522994995
Validation loss: 1.9137554066155547

Epoch: 488| Step: 0
Training loss: 1.39707350730896
Validation loss: 1.9273652184394099

Epoch: 5| Step: 1
Training loss: 1.4981855154037476
Validation loss: 1.8435876830931632

Epoch: 5| Step: 2
Training loss: 0.9496732950210571
Validation loss: 1.8690139708980438

Epoch: 5| Step: 3
Training loss: 0.9627786874771118
Validation loss: 1.899281935025287

Epoch: 5| Step: 4
Training loss: 0.9926311373710632
Validation loss: 1.8880563705198226

Epoch: 5| Step: 5
Training loss: 0.9576263427734375
Validation loss: 1.8152476856785436

Epoch: 5| Step: 6
Training loss: 0.9931076765060425
Validation loss: 1.8603367344025643

Epoch: 5| Step: 7
Training loss: 1.0682785511016846
Validation loss: 1.87754790500928

Epoch: 5| Step: 8
Training loss: 1.3778259754180908
Validation loss: 1.8763301321255264

Epoch: 5| Step: 9
Training loss: 0.5847806334495544
Validation loss: 1.9089112435617754

Epoch: 5| Step: 10
Training loss: 0.882968008518219
Validation loss: 1.8312343141084075

Epoch: 489| Step: 0
Training loss: 1.473204493522644
Validation loss: 1.89218085171074

Epoch: 5| Step: 1
Training loss: 1.246191382408142
Validation loss: 1.8530956493910922

Epoch: 5| Step: 2
Training loss: 0.5834333300590515
Validation loss: 1.8097081069023377

Epoch: 5| Step: 3
Training loss: 0.9015965461730957
Validation loss: 1.897066987970824

Epoch: 5| Step: 4
Training loss: 0.8792344927787781
Validation loss: 1.9280346901186052

Epoch: 5| Step: 5
Training loss: 0.9427632093429565
Validation loss: 1.7904217755922707

Epoch: 5| Step: 6
Training loss: 1.7468807697296143
Validation loss: 1.8702575506702546

Epoch: 5| Step: 7
Training loss: 1.1249868869781494
Validation loss: 1.8053917654099003

Epoch: 5| Step: 8
Training loss: 0.9780230522155762
Validation loss: 1.8197011229812459

Epoch: 5| Step: 9
Training loss: 0.8953733444213867
Validation loss: 1.8938552179644186

Epoch: 5| Step: 10
Training loss: 0.9427436590194702
Validation loss: 1.9108713442279446

Epoch: 490| Step: 0
Training loss: 1.116919994354248
Validation loss: 1.87498612301324

Epoch: 5| Step: 1
Training loss: 1.021515130996704
Validation loss: 1.8962267380888744

Epoch: 5| Step: 2
Training loss: 0.9204313158988953
Validation loss: 1.8798799822407384

Epoch: 5| Step: 3
Training loss: 1.1621663570404053
Validation loss: 1.8609862737758185

Epoch: 5| Step: 4
Training loss: 1.15085768699646
Validation loss: 1.8488526049480642

Epoch: 5| Step: 5
Training loss: 1.1152698993682861
Validation loss: 1.8594980855141916

Epoch: 5| Step: 6
Training loss: 1.2299973964691162
Validation loss: 1.8683843561398086

Epoch: 5| Step: 7
Training loss: 1.0564810037612915
Validation loss: 1.8412144946795639

Epoch: 5| Step: 8
Training loss: 0.8033453822135925
Validation loss: 1.9311469280591576

Epoch: 5| Step: 9
Training loss: 1.2636499404907227
Validation loss: 1.8634090346674765

Epoch: 5| Step: 10
Training loss: 0.9897899627685547
Validation loss: 1.8542623237896991

Epoch: 491| Step: 0
Training loss: 1.476116418838501
Validation loss: 1.8767042672762306

Epoch: 5| Step: 1
Training loss: 0.8849371671676636
Validation loss: 1.8369768332409602

Epoch: 5| Step: 2
Training loss: 1.0233047008514404
Validation loss: 1.8996334998838362

Epoch: 5| Step: 3
Training loss: 0.770901083946228
Validation loss: 1.8648048229114984

Epoch: 5| Step: 4
Training loss: 1.2335174083709717
Validation loss: 1.8769884417133946

Epoch: 5| Step: 5
Training loss: 0.9053584933280945
Validation loss: 1.807130931526102

Epoch: 5| Step: 6
Training loss: 0.9725960493087769
Validation loss: 1.8810790264478294

Epoch: 5| Step: 7
Training loss: 1.0627717971801758
Validation loss: 1.9120506983931347

Epoch: 5| Step: 8
Training loss: 0.677417516708374
Validation loss: 1.8641631808332217

Epoch: 5| Step: 9
Training loss: 0.9260546565055847
Validation loss: 1.8617891137317946

Epoch: 5| Step: 10
Training loss: 1.5018163919448853
Validation loss: 1.857206303586242

Epoch: 492| Step: 0
Training loss: 1.7789576053619385
Validation loss: 1.835360401420183

Epoch: 5| Step: 1
Training loss: 1.0322452783584595
Validation loss: 1.8195376267997168

Epoch: 5| Step: 2
Training loss: 0.9068374633789062
Validation loss: 1.8994510404525264

Epoch: 5| Step: 3
Training loss: 1.2717615365982056
Validation loss: 1.9158661186054189

Epoch: 5| Step: 4
Training loss: 0.9008631706237793
Validation loss: 1.8638622876136535

Epoch: 5| Step: 5
Training loss: 1.4075860977172852
Validation loss: 1.868725940745364

Epoch: 5| Step: 6
Training loss: 0.7071235775947571
Validation loss: 1.9089670617093322

Epoch: 5| Step: 7
Training loss: 0.6003774404525757
Validation loss: 1.8418009973341418

Epoch: 5| Step: 8
Training loss: 0.613017201423645
Validation loss: 1.9157771987299765

Epoch: 5| Step: 9
Training loss: 1.01545250415802
Validation loss: 1.8467618675642117

Epoch: 5| Step: 10
Training loss: 1.3242697715759277
Validation loss: 1.830258669391755

Epoch: 493| Step: 0
Training loss: 0.572725772857666
Validation loss: 1.8927928657941921

Epoch: 5| Step: 1
Training loss: 1.2900152206420898
Validation loss: 1.8973920832398117

Epoch: 5| Step: 2
Training loss: 1.0744740962982178
Validation loss: 1.8633720221058014

Epoch: 5| Step: 3
Training loss: 0.9722225069999695
Validation loss: 1.9152556773154967

Epoch: 5| Step: 4
Training loss: 1.2557649612426758
Validation loss: 1.8512299163367159

Epoch: 5| Step: 5
Training loss: 0.7353416681289673
Validation loss: 1.9535130082920034

Epoch: 5| Step: 6
Training loss: 1.1775391101837158
Validation loss: 1.8416133567851076

Epoch: 5| Step: 7
Training loss: 1.2826982736587524
Validation loss: 1.8614909661713468

Epoch: 5| Step: 8
Training loss: 0.9448757171630859
Validation loss: 1.8812877298683248

Epoch: 5| Step: 9
Training loss: 0.929730236530304
Validation loss: 1.8824598020122898

Epoch: 5| Step: 10
Training loss: 1.365149736404419
Validation loss: 1.823761615701901

Epoch: 494| Step: 0
Training loss: 1.1525001525878906
Validation loss: 1.881548907167168

Epoch: 5| Step: 1
Training loss: 0.6300640106201172
Validation loss: 1.8705172615666543

Epoch: 5| Step: 2
Training loss: 1.039548397064209
Validation loss: 1.834122484730136

Epoch: 5| Step: 3
Training loss: 0.959234893321991
Validation loss: 1.803428457629296

Epoch: 5| Step: 4
Training loss: 1.3076196908950806
Validation loss: 1.833457503908424

Epoch: 5| Step: 5
Training loss: 1.207176923751831
Validation loss: 1.9005506064302178

Epoch: 5| Step: 6
Training loss: 1.4133672714233398
Validation loss: 1.8774295801757483

Epoch: 5| Step: 7
Training loss: 0.9404670596122742
Validation loss: 1.859866807537694

Epoch: 5| Step: 8
Training loss: 0.743020236492157
Validation loss: 1.9044092650054603

Epoch: 5| Step: 9
Training loss: 1.2085034847259521
Validation loss: 1.8856633863141459

Epoch: 5| Step: 10
Training loss: 1.2670364379882812
Validation loss: 1.9235623857026458

Epoch: 495| Step: 0
Training loss: 0.7426067590713501
Validation loss: 1.8486236705574939

Epoch: 5| Step: 1
Training loss: 0.7145273089408875
Validation loss: 1.841982392854588

Epoch: 5| Step: 2
Training loss: 0.8313045501708984
Validation loss: 1.8518152236938477

Epoch: 5| Step: 3
Training loss: 0.773011326789856
Validation loss: 1.9086559254636046

Epoch: 5| Step: 4
Training loss: 1.7459827661514282
Validation loss: 1.8832647133898992

Epoch: 5| Step: 5
Training loss: 1.098932147026062
Validation loss: 1.8339233629165157

Epoch: 5| Step: 6
Training loss: 0.973028302192688
Validation loss: 1.8654608444500995

Epoch: 5| Step: 7
Training loss: 1.0899288654327393
Validation loss: 1.8897696823202155

Epoch: 5| Step: 8
Training loss: 1.1063613891601562
Validation loss: 1.885639541892595

Epoch: 5| Step: 9
Training loss: 1.5086698532104492
Validation loss: 1.8950917605430848

Epoch: 5| Step: 10
Training loss: 1.0788910388946533
Validation loss: 1.8549935458808817

Epoch: 496| Step: 0
Training loss: 1.0810048580169678
Validation loss: 1.8832568430131482

Epoch: 5| Step: 1
Training loss: 1.1628748178482056
Validation loss: 1.8766928539481214

Epoch: 5| Step: 2
Training loss: 0.707377552986145
Validation loss: 1.8392569057403072

Epoch: 5| Step: 3
Training loss: 0.9277912378311157
Validation loss: 1.8480961438148253

Epoch: 5| Step: 4
Training loss: 0.7480244636535645
Validation loss: 1.8417551440577353

Epoch: 5| Step: 5
Training loss: 1.049386739730835
Validation loss: 1.8838117968651555

Epoch: 5| Step: 6
Training loss: 1.4300134181976318
Validation loss: 1.8808241749322543

Epoch: 5| Step: 7
Training loss: 0.7426592111587524
Validation loss: 1.8758128586635794

Epoch: 5| Step: 8
Training loss: 0.9768015742301941
Validation loss: 1.8573557099988383

Epoch: 5| Step: 9
Training loss: 1.736794114112854
Validation loss: 1.881528212178138

Epoch: 5| Step: 10
Training loss: 1.2664110660552979
Validation loss: 1.8587134345885246

Epoch: 497| Step: 0
Training loss: 1.2786232233047485
Validation loss: 1.9078844824144918

Epoch: 5| Step: 1
Training loss: 1.473575234413147
Validation loss: 1.8429889063681326

Epoch: 5| Step: 2
Training loss: 1.1013976335525513
Validation loss: 1.90893417532726

Epoch: 5| Step: 3
Training loss: 0.7770394086837769
Validation loss: 1.8673801947665472

Epoch: 5| Step: 4
Training loss: 1.0544698238372803
Validation loss: 1.7918449730001471

Epoch: 5| Step: 5
Training loss: 0.8557031750679016
Validation loss: 1.8158914581421883

Epoch: 5| Step: 6
Training loss: 1.1100976467132568
Validation loss: 1.8435211720005158

Epoch: 5| Step: 7
Training loss: 0.593559741973877
Validation loss: 1.8849295134185462

Epoch: 5| Step: 8
Training loss: 1.0091053247451782
Validation loss: 1.861949723253968

Epoch: 5| Step: 9
Training loss: 1.0270270109176636
Validation loss: 1.896045168240865

Epoch: 5| Step: 10
Training loss: 1.0850410461425781
Validation loss: 1.853233979594323

Epoch: 498| Step: 0
Training loss: 1.0718891620635986
Validation loss: 1.8802396251309303

Epoch: 5| Step: 1
Training loss: 1.0200254917144775
Validation loss: 1.8492587920158141

Epoch: 5| Step: 2
Training loss: 0.9535658955574036
Validation loss: 1.8974503432550738

Epoch: 5| Step: 3
Training loss: 1.074810266494751
Validation loss: 1.8604332221451627

Epoch: 5| Step: 4
Training loss: 1.7418159246444702
Validation loss: 1.91333423378647

Epoch: 5| Step: 5
Training loss: 0.7026571035385132
Validation loss: 1.8068774515582668

Epoch: 5| Step: 6
Training loss: 0.8563529253005981
Validation loss: 1.8667192971834572

Epoch: 5| Step: 7
Training loss: 1.062821626663208
Validation loss: 1.8117207455378708

Epoch: 5| Step: 8
Training loss: 0.9743016958236694
Validation loss: 1.847817228686425

Epoch: 5| Step: 9
Training loss: 1.1859134435653687
Validation loss: 1.8679178478897258

Epoch: 5| Step: 10
Training loss: 0.9573469758033752
Validation loss: 1.82560529247407

Epoch: 499| Step: 0
Training loss: 0.9544106721878052
Validation loss: 1.9021016218328988

Epoch: 5| Step: 1
Training loss: 0.9312793612480164
Validation loss: 1.828200376161965

Epoch: 5| Step: 2
Training loss: 0.8860623240470886
Validation loss: 1.9054946899414062

Epoch: 5| Step: 3
Training loss: 0.976575493812561
Validation loss: 1.883945885524955

Epoch: 5| Step: 4
Training loss: 1.0730860233306885
Validation loss: 1.9237294363719162

Epoch: 5| Step: 5
Training loss: 1.0845096111297607
Validation loss: 1.90713749136976

Epoch: 5| Step: 6
Training loss: 0.7430931329727173
Validation loss: 1.9021514192704232

Epoch: 5| Step: 7
Training loss: 1.0950645208358765
Validation loss: 1.921892237919633

Epoch: 5| Step: 8
Training loss: 1.0876483917236328
Validation loss: 1.9411187287299865

Epoch: 5| Step: 9
Training loss: 1.8520534038543701
Validation loss: 1.8545998193884408

Epoch: 5| Step: 10
Training loss: 1.0647706985473633
Validation loss: 1.8395044534437117

Epoch: 500| Step: 0
Training loss: 0.6518429517745972
Validation loss: 1.8160524188831288

Epoch: 5| Step: 1
Training loss: 1.2076138257980347
Validation loss: 1.8553505533485002

Epoch: 5| Step: 2
Training loss: 1.3631665706634521
Validation loss: 1.7927761667518205

Epoch: 5| Step: 3
Training loss: 0.7675508260726929
Validation loss: 1.8264833137553225

Epoch: 5| Step: 4
Training loss: 0.6559475660324097
Validation loss: 1.8513925767713977

Epoch: 5| Step: 5
Training loss: 1.4151970148086548
Validation loss: 1.8879006114057315

Epoch: 5| Step: 6
Training loss: 1.1717050075531006
Validation loss: 1.8602085087888984

Epoch: 5| Step: 7
Training loss: 0.9823463559150696
Validation loss: 1.822426329376877

Epoch: 5| Step: 8
Training loss: 1.0884854793548584
Validation loss: 1.8574342727661133

Epoch: 5| Step: 9
Training loss: 0.7672606110572815
Validation loss: 1.8129070138418546

Epoch: 5| Step: 10
Training loss: 1.2581843137741089
Validation loss: 1.8590201511177966

Epoch: 501| Step: 0
Training loss: 1.360900640487671
Validation loss: 1.8108610171143726

Epoch: 5| Step: 1
Training loss: 0.9821643829345703
Validation loss: 1.8643376647785146

Epoch: 5| Step: 2
Training loss: 0.8345862627029419
Validation loss: 1.870168899977079

Epoch: 5| Step: 3
Training loss: 0.9979322552680969
Validation loss: 1.8526523959252141

Epoch: 5| Step: 4
Training loss: 0.9247224926948547
Validation loss: 1.9007744660941504

Epoch: 5| Step: 5
Training loss: 1.138920545578003
Validation loss: 1.8986933538990636

Epoch: 5| Step: 6
Training loss: 1.0172830820083618
Validation loss: 1.880068330354588

Epoch: 5| Step: 7
Training loss: 0.9956072568893433
Validation loss: 1.8868242566303541

Epoch: 5| Step: 8
Training loss: 1.035744547843933
Validation loss: 1.8951955969615648

Epoch: 5| Step: 9
Training loss: 0.9583531618118286
Validation loss: 1.8281080261353524

Epoch: 5| Step: 10
Training loss: 1.3060052394866943
Validation loss: 1.8966328174837175

Epoch: 502| Step: 0
Training loss: 0.870198130607605
Validation loss: 1.8619397122372863

Epoch: 5| Step: 1
Training loss: 1.4602080583572388
Validation loss: 1.8045285363351145

Epoch: 5| Step: 2
Training loss: 1.2175041437149048
Validation loss: 1.870581619201168

Epoch: 5| Step: 3
Training loss: 1.0381325483322144
Validation loss: 1.8712993039879748

Epoch: 5| Step: 4
Training loss: 1.292909860610962
Validation loss: 1.8347849589522167

Epoch: 5| Step: 5
Training loss: 0.4909330904483795
Validation loss: 1.8903776535423853

Epoch: 5| Step: 6
Training loss: 1.4208329916000366
Validation loss: 1.8523278569662442

Epoch: 5| Step: 7
Training loss: 1.0354019403457642
Validation loss: 1.8353394308397848

Epoch: 5| Step: 8
Training loss: 0.8226643800735474
Validation loss: 1.8824634308456092

Epoch: 5| Step: 9
Training loss: 0.9135721325874329
Validation loss: 1.845107973262828

Epoch: 5| Step: 10
Training loss: 1.1326780319213867
Validation loss: 1.8611060060480589

Epoch: 503| Step: 0
Training loss: 1.5259065628051758
Validation loss: 1.8146943097473474

Epoch: 5| Step: 1
Training loss: 1.5177333354949951
Validation loss: 1.8232681879433252

Epoch: 5| Step: 2
Training loss: 0.9725826382637024
Validation loss: 1.859582624127788

Epoch: 5| Step: 3
Training loss: 1.0049316883087158
Validation loss: 1.87266283394188

Epoch: 5| Step: 4
Training loss: 0.8269619941711426
Validation loss: 1.8700518505547636

Epoch: 5| Step: 5
Training loss: 0.9471522569656372
Validation loss: 1.8222557126834829

Epoch: 5| Step: 6
Training loss: 0.8681341409683228
Validation loss: 1.8668930274184032

Epoch: 5| Step: 7
Training loss: 1.0386450290679932
Validation loss: 1.8391687357297508

Epoch: 5| Step: 8
Training loss: 1.1320537328720093
Validation loss: 1.8412104396409885

Epoch: 5| Step: 9
Training loss: 0.9786140322685242
Validation loss: 1.8796821294292327

Epoch: 5| Step: 10
Training loss: 0.7512698173522949
Validation loss: 1.905431967909618

Epoch: 504| Step: 0
Training loss: 1.0298765897750854
Validation loss: 1.8175397637069866

Epoch: 5| Step: 1
Training loss: 0.9800230860710144
Validation loss: 1.8859982798176427

Epoch: 5| Step: 2
Training loss: 1.2201664447784424
Validation loss: 1.901131058251986

Epoch: 5| Step: 3
Training loss: 1.2283060550689697
Validation loss: 1.8195625876867643

Epoch: 5| Step: 4
Training loss: 0.5760540962219238
Validation loss: 1.8357362606192147

Epoch: 5| Step: 5
Training loss: 0.636970043182373
Validation loss: 1.8252004948995446

Epoch: 5| Step: 6
Training loss: 1.3144252300262451
Validation loss: 1.8314168235307098

Epoch: 5| Step: 7
Training loss: 1.4198410511016846
Validation loss: 1.8153326613928682

Epoch: 5| Step: 8
Training loss: 1.0850740671157837
Validation loss: 1.8787750659450408

Epoch: 5| Step: 9
Training loss: 1.4522663354873657
Validation loss: 1.8945230104589974

Epoch: 5| Step: 10
Training loss: 0.8945212364196777
Validation loss: 1.8692250379952051

Epoch: 505| Step: 0
Training loss: 0.8989157676696777
Validation loss: 1.8465217851823377

Epoch: 5| Step: 1
Training loss: 0.9707071185112
Validation loss: 1.9052028220186952

Epoch: 5| Step: 2
Training loss: 1.0455617904663086
Validation loss: 1.8215117480165215

Epoch: 5| Step: 3
Training loss: 0.5944713354110718
Validation loss: 1.8520541255192091

Epoch: 5| Step: 4
Training loss: 1.4055144786834717
Validation loss: 1.7910363122981081

Epoch: 5| Step: 5
Training loss: 1.4060741662979126
Validation loss: 1.7636245040483371

Epoch: 5| Step: 6
Training loss: 1.4413416385650635
Validation loss: 1.826223963050432

Epoch: 5| Step: 7
Training loss: 0.7799832820892334
Validation loss: 1.858506687225834

Epoch: 5| Step: 8
Training loss: 0.8486639261245728
Validation loss: 1.8279530438043738

Epoch: 5| Step: 9
Training loss: 0.8158875703811646
Validation loss: 1.911776634954637

Epoch: 5| Step: 10
Training loss: 1.2093099355697632
Validation loss: 1.8298214045904015

Epoch: 506| Step: 0
Training loss: 0.9351056814193726
Validation loss: 1.8972064525850358

Epoch: 5| Step: 1
Training loss: 0.7390510439872742
Validation loss: 1.8159939653129988

Epoch: 5| Step: 2
Training loss: 1.3704650402069092
Validation loss: 1.8825918602687057

Epoch: 5| Step: 3
Training loss: 0.9714975357055664
Validation loss: 1.8946367348394086

Epoch: 5| Step: 4
Training loss: 1.327115774154663
Validation loss: 1.834073838367257

Epoch: 5| Step: 5
Training loss: 0.6955915689468384
Validation loss: 1.8987517728600452

Epoch: 5| Step: 6
Training loss: 0.7420418858528137
Validation loss: 1.890860854938466

Epoch: 5| Step: 7
Training loss: 1.2752330303192139
Validation loss: 1.8231123044926634

Epoch: 5| Step: 8
Training loss: 0.9107222557067871
Validation loss: 1.869651613696929

Epoch: 5| Step: 9
Training loss: 0.8074153661727905
Validation loss: 1.8592826640734108

Epoch: 5| Step: 10
Training loss: 1.6484287977218628
Validation loss: 1.913539457064803

Epoch: 507| Step: 0
Training loss: 1.1676946878433228
Validation loss: 1.9313289939716298

Epoch: 5| Step: 1
Training loss: 0.8694334030151367
Validation loss: 1.8441574804244503

Epoch: 5| Step: 2
Training loss: 0.7759712934494019
Validation loss: 1.7651741607214815

Epoch: 5| Step: 3
Training loss: 0.9936652183532715
Validation loss: 1.8862577407590804

Epoch: 5| Step: 4
Training loss: 1.0432366132736206
Validation loss: 1.8071040132994294

Epoch: 5| Step: 5
Training loss: 0.6618632674217224
Validation loss: 1.9032124152747534

Epoch: 5| Step: 6
Training loss: 1.4753025770187378
Validation loss: 1.9306689186762738

Epoch: 5| Step: 7
Training loss: 1.3421270847320557
Validation loss: 1.91780819431428

Epoch: 5| Step: 8
Training loss: 0.9761012196540833
Validation loss: 1.8611560021677325

Epoch: 5| Step: 9
Training loss: 0.7144969701766968
Validation loss: 1.918850250141595

Epoch: 5| Step: 10
Training loss: 1.028681993484497
Validation loss: 1.8418982541689308

Epoch: 508| Step: 0
Training loss: 0.5956977605819702
Validation loss: 1.8391513952644922

Epoch: 5| Step: 1
Training loss: 0.9318251609802246
Validation loss: 1.8859211603800456

Epoch: 5| Step: 2
Training loss: 0.9337373971939087
Validation loss: 1.7769825689254268

Epoch: 5| Step: 3
Training loss: 0.9728196263313293
Validation loss: 1.888058126613658

Epoch: 5| Step: 4
Training loss: 0.9542126655578613
Validation loss: 1.770401907223527

Epoch: 5| Step: 5
Training loss: 1.2860453128814697
Validation loss: 1.8946361157201952

Epoch: 5| Step: 6
Training loss: 0.9690214395523071
Validation loss: 1.771084959788989

Epoch: 5| Step: 7
Training loss: 1.494476079940796
Validation loss: 1.8078565341170116

Epoch: 5| Step: 8
Training loss: 0.928641676902771
Validation loss: 1.8531167314898582

Epoch: 5| Step: 9
Training loss: 1.1739128828048706
Validation loss: 1.7892889617591776

Epoch: 5| Step: 10
Training loss: 0.9948793053627014
Validation loss: 1.8677626784129808

Epoch: 509| Step: 0
Training loss: 0.5565912127494812
Validation loss: 1.820991608404344

Epoch: 5| Step: 1
Training loss: 1.0319029092788696
Validation loss: 1.829152335402786

Epoch: 5| Step: 2
Training loss: 1.1424295902252197
Validation loss: 1.8479259026947843

Epoch: 5| Step: 3
Training loss: 0.78978031873703
Validation loss: 1.9053019426202262

Epoch: 5| Step: 4
Training loss: 1.669859528541565
Validation loss: 1.8058287866653935

Epoch: 5| Step: 5
Training loss: 0.7418182492256165
Validation loss: 1.8343671278287006

Epoch: 5| Step: 6
Training loss: 0.9755905866622925
Validation loss: 1.8554486869483866

Epoch: 5| Step: 7
Training loss: 1.021366000175476
Validation loss: 1.8880024994573286

Epoch: 5| Step: 8
Training loss: 0.7748432755470276
Validation loss: 1.8973966362655803

Epoch: 5| Step: 9
Training loss: 1.187450647354126
Validation loss: 1.8179406248113161

Epoch: 5| Step: 10
Training loss: 1.4860233068466187
Validation loss: 1.8912539712844356

Epoch: 510| Step: 0
Training loss: 1.6230369806289673
Validation loss: 1.873616260866965

Epoch: 5| Step: 1
Training loss: 1.3376529216766357
Validation loss: 1.8255224522723947

Epoch: 5| Step: 2
Training loss: 1.4568636417388916
Validation loss: 1.8421787933636737

Epoch: 5| Step: 3
Training loss: 0.6715874671936035
Validation loss: 1.8447055303922264

Epoch: 5| Step: 4
Training loss: 0.9976071119308472
Validation loss: 1.837746884233208

Epoch: 5| Step: 5
Training loss: 0.718305230140686
Validation loss: 1.9209281026676137

Epoch: 5| Step: 6
Training loss: 1.175060749053955
Validation loss: 1.911758670242884

Epoch: 5| Step: 7
Training loss: 0.7753769755363464
Validation loss: 1.8946226155886086

Epoch: 5| Step: 8
Training loss: 1.18356192111969
Validation loss: 1.8708082706697526

Epoch: 5| Step: 9
Training loss: 0.8715422749519348
Validation loss: 1.8885769869691582

Epoch: 5| Step: 10
Training loss: 0.7996867895126343
Validation loss: 1.8789162571712206

Epoch: 511| Step: 0
Training loss: 0.8373876810073853
Validation loss: 1.9065209845060944

Epoch: 5| Step: 1
Training loss: 1.0463612079620361
Validation loss: 1.8744006054375761

Epoch: 5| Step: 2
Training loss: 0.8441709280014038
Validation loss: 1.8069863178396737

Epoch: 5| Step: 3
Training loss: 1.2072737216949463
Validation loss: 1.8663360969994658

Epoch: 5| Step: 4
Training loss: 1.1181236505508423
Validation loss: 1.830235622262442

Epoch: 5| Step: 5
Training loss: 0.7298405170440674
Validation loss: 1.8397902481017574

Epoch: 5| Step: 6
Training loss: 1.2223789691925049
Validation loss: 1.8486107997996832

Epoch: 5| Step: 7
Training loss: 0.7984437942504883
Validation loss: 1.8633473380919425

Epoch: 5| Step: 8
Training loss: 0.9401731491088867
Validation loss: 1.852212562355944

Epoch: 5| Step: 9
Training loss: 0.8892080187797546
Validation loss: 1.8346018688653105

Epoch: 5| Step: 10
Training loss: 1.6650381088256836
Validation loss: 1.8180757261091662

Epoch: 512| Step: 0
Training loss: 0.8399416208267212
Validation loss: 1.8757895410701793

Epoch: 5| Step: 1
Training loss: 1.165616512298584
Validation loss: 1.9180317514686174

Epoch: 5| Step: 2
Training loss: 0.9968485832214355
Validation loss: 1.956230955739175

Epoch: 5| Step: 3
Training loss: 1.0611833333969116
Validation loss: 1.848452680854387

Epoch: 5| Step: 4
Training loss: 1.114375352859497
Validation loss: 1.857089755355671

Epoch: 5| Step: 5
Training loss: 0.6201441884040833
Validation loss: 1.9462405391918716

Epoch: 5| Step: 6
Training loss: 1.3922102451324463
Validation loss: 1.8921160749209824

Epoch: 5| Step: 7
Training loss: 0.7515652775764465
Validation loss: 1.8515243312363983

Epoch: 5| Step: 8
Training loss: 1.3568708896636963
Validation loss: 1.8542139927546184

Epoch: 5| Step: 9
Training loss: 1.3082101345062256
Validation loss: 1.8585274834786691

Epoch: 5| Step: 10
Training loss: 0.7472832798957825
Validation loss: 1.8563994822963592

Epoch: 513| Step: 0
Training loss: 0.7422779202461243
Validation loss: 1.8717075047954437

Epoch: 5| Step: 1
Training loss: 0.46954917907714844
Validation loss: 1.826315382475494

Epoch: 5| Step: 2
Training loss: 1.1086968183517456
Validation loss: 1.8511503627223354

Epoch: 5| Step: 3
Training loss: 1.283517837524414
Validation loss: 1.948191463306386

Epoch: 5| Step: 4
Training loss: 1.036800503730774
Validation loss: 1.8583730061848958

Epoch: 5| Step: 5
Training loss: 1.7589941024780273
Validation loss: 1.8619927283256286

Epoch: 5| Step: 6
Training loss: 1.1955249309539795
Validation loss: 1.8842124028872418

Epoch: 5| Step: 7
Training loss: 0.963618278503418
Validation loss: 1.853753589814709

Epoch: 5| Step: 8
Training loss: 1.0410549640655518
Validation loss: 1.857616025914428

Epoch: 5| Step: 9
Training loss: 0.7608779668807983
Validation loss: 1.838055872148083

Epoch: 5| Step: 10
Training loss: 1.1068344116210938
Validation loss: 1.8357015912250807

Epoch: 514| Step: 0
Training loss: 0.8325662612915039
Validation loss: 1.868102035214824

Epoch: 5| Step: 1
Training loss: 0.9982820749282837
Validation loss: 1.8449600922164096

Epoch: 5| Step: 2
Training loss: 1.014378309249878
Validation loss: 1.8294908128758913

Epoch: 5| Step: 3
Training loss: 0.8353070020675659
Validation loss: 1.9211685272955126

Epoch: 5| Step: 4
Training loss: 0.6992253661155701
Validation loss: 1.8842756261107743

Epoch: 5| Step: 5
Training loss: 1.5834373235702515
Validation loss: 1.9020303474959506

Epoch: 5| Step: 6
Training loss: 0.7436985373497009
Validation loss: 1.8673933244520617

Epoch: 5| Step: 7
Training loss: 1.2280417680740356
Validation loss: 1.8618333583237023

Epoch: 5| Step: 8
Training loss: 1.0911660194396973
Validation loss: 1.899299519036406

Epoch: 5| Step: 9
Training loss: 0.7768866419792175
Validation loss: 1.9406357606252034

Epoch: 5| Step: 10
Training loss: 0.9396414160728455
Validation loss: 1.802896548342961

Epoch: 515| Step: 0
Training loss: 1.0526763200759888
Validation loss: 1.8849600361239525

Epoch: 5| Step: 1
Training loss: 0.858012318611145
Validation loss: 1.813232155256374

Epoch: 5| Step: 2
Training loss: 0.966194748878479
Validation loss: 1.800947784095682

Epoch: 5| Step: 3
Training loss: 0.958013653755188
Validation loss: 1.8035936945228166

Epoch: 5| Step: 4
Training loss: 1.1126508712768555
Validation loss: 1.889352657461679

Epoch: 5| Step: 5
Training loss: 0.9973743557929993
Validation loss: 1.8931170137979652

Epoch: 5| Step: 6
Training loss: 1.2742341756820679
Validation loss: 1.8523077362327165

Epoch: 5| Step: 7
Training loss: 0.6196228861808777
Validation loss: 1.8736359432179441

Epoch: 5| Step: 8
Training loss: 1.3088276386260986
Validation loss: 1.910075928575249

Epoch: 5| Step: 9
Training loss: 1.2315822839736938
Validation loss: 1.8519934351726244

Epoch: 5| Step: 10
Training loss: 0.6619982123374939
Validation loss: 1.908853316819796

Epoch: 516| Step: 0
Training loss: 0.7677325010299683
Validation loss: 1.9155593277305685

Epoch: 5| Step: 1
Training loss: 0.7022615075111389
Validation loss: 1.883260461591905

Epoch: 5| Step: 2
Training loss: 0.8410114049911499
Validation loss: 1.8684603642391902

Epoch: 5| Step: 3
Training loss: 0.9531043171882629
Validation loss: 1.836872649449174

Epoch: 5| Step: 4
Training loss: 1.1123265027999878
Validation loss: 1.8550868444545294

Epoch: 5| Step: 5
Training loss: 1.115480661392212
Validation loss: 1.819547519888929

Epoch: 5| Step: 6
Training loss: 0.9233428835868835
Validation loss: 1.8079134828300887

Epoch: 5| Step: 7
Training loss: 1.2468745708465576
Validation loss: 1.8174218208559099

Epoch: 5| Step: 8
Training loss: 1.131650447845459
Validation loss: 1.8378466149812103

Epoch: 5| Step: 9
Training loss: 1.4642596244812012
Validation loss: 1.8077427905092958

Epoch: 5| Step: 10
Training loss: 0.7587935328483582
Validation loss: 1.8318250666382492

Epoch: 517| Step: 0
Training loss: 1.3756654262542725
Validation loss: 1.8413827368008193

Epoch: 5| Step: 1
Training loss: 1.5035604238510132
Validation loss: 1.8658756773958924

Epoch: 5| Step: 2
Training loss: 0.6801865696907043
Validation loss: 1.9073051393672984

Epoch: 5| Step: 3
Training loss: 1.4169410467147827
Validation loss: 1.833013161536186

Epoch: 5| Step: 4
Training loss: 0.9847642779350281
Validation loss: 1.7969684306011404

Epoch: 5| Step: 5
Training loss: 0.6553001403808594
Validation loss: 1.8765103124803113

Epoch: 5| Step: 6
Training loss: 0.6500213742256165
Validation loss: 1.850358796376054

Epoch: 5| Step: 7
Training loss: 0.9637709856033325
Validation loss: 1.8171226055391374

Epoch: 5| Step: 8
Training loss: 1.4376778602600098
Validation loss: 1.8596505067681754

Epoch: 5| Step: 9
Training loss: 0.9340206980705261
Validation loss: 1.8385043605681388

Epoch: 5| Step: 10
Training loss: 0.7093819975852966
Validation loss: 1.873413114137547

Epoch: 518| Step: 0
Training loss: 1.4744937419891357
Validation loss: 1.8805026854238203

Epoch: 5| Step: 1
Training loss: 0.6181731224060059
Validation loss: 1.8527728575532154

Epoch: 5| Step: 2
Training loss: 0.9148194193840027
Validation loss: 1.8759367376245477

Epoch: 5| Step: 3
Training loss: 0.953494668006897
Validation loss: 1.836515857327369

Epoch: 5| Step: 4
Training loss: 1.1121604442596436
Validation loss: 1.8365994499575706

Epoch: 5| Step: 5
Training loss: 0.9492256045341492
Validation loss: 1.8138033036262757

Epoch: 5| Step: 6
Training loss: 1.3348753452301025
Validation loss: 1.8277757975362963

Epoch: 5| Step: 7
Training loss: 0.9899677038192749
Validation loss: 1.8524248497460478

Epoch: 5| Step: 8
Training loss: 1.1237120628356934
Validation loss: 1.7655178744305846

Epoch: 5| Step: 9
Training loss: 0.791582465171814
Validation loss: 1.8071085714524793

Epoch: 5| Step: 10
Training loss: 0.9555177092552185
Validation loss: 1.7975586088754798

Epoch: 519| Step: 0
Training loss: 1.2876582145690918
Validation loss: 1.771626785237302

Epoch: 5| Step: 1
Training loss: 1.010979175567627
Validation loss: 1.826508100314807

Epoch: 5| Step: 2
Training loss: 1.0601637363433838
Validation loss: 1.865607109121097

Epoch: 5| Step: 3
Training loss: 1.0689667463302612
Validation loss: 1.8427974665036766

Epoch: 5| Step: 4
Training loss: 0.9898849725723267
Validation loss: 1.821887573888225

Epoch: 5| Step: 5
Training loss: 1.1479905843734741
Validation loss: 1.866229139348512

Epoch: 5| Step: 6
Training loss: 1.060677409172058
Validation loss: 1.7791570476306382

Epoch: 5| Step: 7
Training loss: 0.7297089695930481
Validation loss: 1.8150504353225871

Epoch: 5| Step: 8
Training loss: 0.5119940638542175
Validation loss: 1.8350506982495707

Epoch: 5| Step: 9
Training loss: 0.9283420443534851
Validation loss: 1.921246620916551

Epoch: 5| Step: 10
Training loss: 1.2953392267227173
Validation loss: 1.8893392983303274

Epoch: 520| Step: 0
Training loss: 0.9306274652481079
Validation loss: 1.8831864377503753

Epoch: 5| Step: 1
Training loss: 0.7029904723167419
Validation loss: 1.8245804091935516

Epoch: 5| Step: 2
Training loss: 0.9221517443656921
Validation loss: 1.9239549893204884

Epoch: 5| Step: 3
Training loss: 1.2358589172363281
Validation loss: 1.8233926526961788

Epoch: 5| Step: 4
Training loss: 1.1286671161651611
Validation loss: 1.9126146660056165

Epoch: 5| Step: 5
Training loss: 0.883259117603302
Validation loss: 1.8544554838570215

Epoch: 5| Step: 6
Training loss: 0.980312168598175
Validation loss: 1.8905621305588753

Epoch: 5| Step: 7
Training loss: 1.1699647903442383
Validation loss: 1.808827410462082

Epoch: 5| Step: 8
Training loss: 1.0104079246520996
Validation loss: 1.8668189151312715

Epoch: 5| Step: 9
Training loss: 1.4752018451690674
Validation loss: 1.8804906363128333

Epoch: 5| Step: 10
Training loss: 1.0053240060806274
Validation loss: 1.7893473691837762

Epoch: 521| Step: 0
Training loss: 0.9093621969223022
Validation loss: 1.824707326068673

Epoch: 5| Step: 1
Training loss: 1.053013563156128
Validation loss: 1.8092695859170729

Epoch: 5| Step: 2
Training loss: 1.0493519306182861
Validation loss: 1.8799690328618532

Epoch: 5| Step: 3
Training loss: 0.5971182584762573
Validation loss: 1.8012537763964744

Epoch: 5| Step: 4
Training loss: 0.9324213266372681
Validation loss: 1.9001782965916458

Epoch: 5| Step: 5
Training loss: 1.5943470001220703
Validation loss: 1.8227760279050438

Epoch: 5| Step: 6
Training loss: 0.8820406794548035
Validation loss: 1.8509052504775345

Epoch: 5| Step: 7
Training loss: 1.0689363479614258
Validation loss: 1.840316311005623

Epoch: 5| Step: 8
Training loss: 1.1193701028823853
Validation loss: 1.8492752121340843

Epoch: 5| Step: 9
Training loss: 0.9154030680656433
Validation loss: 1.829893473655947

Epoch: 5| Step: 10
Training loss: 0.8983123898506165
Validation loss: 1.8731284461995608

Epoch: 522| Step: 0
Training loss: 1.0696040391921997
Validation loss: 1.8064098678609377

Epoch: 5| Step: 1
Training loss: 0.8364385366439819
Validation loss: 1.8614475034898328

Epoch: 5| Step: 2
Training loss: 1.1410441398620605
Validation loss: 1.7902539007125362

Epoch: 5| Step: 3
Training loss: 0.9785272479057312
Validation loss: 1.792415916278798

Epoch: 5| Step: 4
Training loss: 1.1284438371658325
Validation loss: 1.8106782987553587

Epoch: 5| Step: 5
Training loss: 1.401039481163025
Validation loss: 1.8400003320427352

Epoch: 5| Step: 6
Training loss: 0.7694398164749146
Validation loss: 1.8572982767576813

Epoch: 5| Step: 7
Training loss: 0.6961096525192261
Validation loss: 1.8050748378999772

Epoch: 5| Step: 8
Training loss: 0.777720034122467
Validation loss: 1.9169323687912316

Epoch: 5| Step: 9
Training loss: 1.2962735891342163
Validation loss: 1.8060293800087386

Epoch: 5| Step: 10
Training loss: 0.9536561369895935
Validation loss: 1.8297351970467517

Epoch: 523| Step: 0
Training loss: 0.810962975025177
Validation loss: 1.7629460147632066

Epoch: 5| Step: 1
Training loss: 1.0263437032699585
Validation loss: 1.830439785475372

Epoch: 5| Step: 2
Training loss: 1.0599157810211182
Validation loss: 1.8657494693674066

Epoch: 5| Step: 3
Training loss: 1.1468536853790283
Validation loss: 1.849887155717419

Epoch: 5| Step: 4
Training loss: 0.9604784250259399
Validation loss: 1.7714312948206419

Epoch: 5| Step: 5
Training loss: 1.289729356765747
Validation loss: 1.770938309290076

Epoch: 5| Step: 6
Training loss: 0.8869595527648926
Validation loss: 1.8640323505606702

Epoch: 5| Step: 7
Training loss: 1.0631357431411743
Validation loss: 1.822785464666223

Epoch: 5| Step: 8
Training loss: 1.270383358001709
Validation loss: 1.8236368894577026

Epoch: 5| Step: 9
Training loss: 0.8382306098937988
Validation loss: 1.7889869482286516

Epoch: 5| Step: 10
Training loss: 0.6864994168281555
Validation loss: 1.897645688826038

Epoch: 524| Step: 0
Training loss: 1.2089720964431763
Validation loss: 1.808668557033744

Epoch: 5| Step: 1
Training loss: 1.0897144079208374
Validation loss: 1.8291836823186567

Epoch: 5| Step: 2
Training loss: 0.8094683885574341
Validation loss: 1.881502959036058

Epoch: 5| Step: 3
Training loss: 1.0446748733520508
Validation loss: 1.8237812916437786

Epoch: 5| Step: 4
Training loss: 1.1179453134536743
Validation loss: 1.8510074384750859

Epoch: 5| Step: 5
Training loss: 0.7138034105300903
Validation loss: 1.8625786381383096

Epoch: 5| Step: 6
Training loss: 1.074284553527832
Validation loss: 1.8842030417534612

Epoch: 5| Step: 7
Training loss: 1.0400621891021729
Validation loss: 1.8288673893097909

Epoch: 5| Step: 8
Training loss: 0.7532191872596741
Validation loss: 1.8187330358771867

Epoch: 5| Step: 9
Training loss: 1.3359142541885376
Validation loss: 1.82473159861821

Epoch: 5| Step: 10
Training loss: 0.8753056526184082
Validation loss: 1.7945208357226463

Epoch: 525| Step: 0
Training loss: 0.696959376335144
Validation loss: 1.8821067284512263

Epoch: 5| Step: 1
Training loss: 0.6623337864875793
Validation loss: 1.877219497516591

Epoch: 5| Step: 2
Training loss: 1.2741515636444092
Validation loss: 1.8978415714797152

Epoch: 5| Step: 3
Training loss: 0.997693657875061
Validation loss: 1.8555088056031095

Epoch: 5| Step: 4
Training loss: 1.0153659582138062
Validation loss: 1.8573249745112594

Epoch: 5| Step: 5
Training loss: 1.2615315914154053
Validation loss: 1.8586532826064734

Epoch: 5| Step: 6
Training loss: 1.617423415184021
Validation loss: 1.836927488286008

Epoch: 5| Step: 7
Training loss: 0.9938609004020691
Validation loss: 1.8675738637165358

Epoch: 5| Step: 8
Training loss: 0.7896569967269897
Validation loss: 1.8338696123451315

Epoch: 5| Step: 9
Training loss: 1.043480634689331
Validation loss: 1.8836018923790223

Epoch: 5| Step: 10
Training loss: 0.9538809657096863
Validation loss: 1.8023696381558654

Epoch: 526| Step: 0
Training loss: 0.914752185344696
Validation loss: 1.853036779229359

Epoch: 5| Step: 1
Training loss: 1.0526593923568726
Validation loss: 1.8049859423791208

Epoch: 5| Step: 2
Training loss: 1.0522781610488892
Validation loss: 1.84792189187901

Epoch: 5| Step: 3
Training loss: 0.4703591763973236
Validation loss: 1.833872164449384

Epoch: 5| Step: 4
Training loss: 1.2180912494659424
Validation loss: 1.833007304258244

Epoch: 5| Step: 5
Training loss: 1.6254088878631592
Validation loss: 1.8190558745015053

Epoch: 5| Step: 6
Training loss: 0.8016913533210754
Validation loss: 1.8559856696795392

Epoch: 5| Step: 7
Training loss: 1.2821934223175049
Validation loss: 1.8511764528930827

Epoch: 5| Step: 8
Training loss: 0.7620002627372742
Validation loss: 1.8507358207497546

Epoch: 5| Step: 9
Training loss: 1.0756961107254028
Validation loss: 1.8822980388518302

Epoch: 5| Step: 10
Training loss: 0.7005692720413208
Validation loss: 1.8440298341935681

Epoch: 527| Step: 0
Training loss: 1.5651801824569702
Validation loss: 1.8310227778650099

Epoch: 5| Step: 1
Training loss: 1.3379408121109009
Validation loss: 1.8487292566607076

Epoch: 5| Step: 2
Training loss: 0.5932061076164246
Validation loss: 1.8450406430869974

Epoch: 5| Step: 3
Training loss: 1.0927157402038574
Validation loss: 1.849865564735987

Epoch: 5| Step: 4
Training loss: 1.2987310886383057
Validation loss: 1.8576291222726145

Epoch: 5| Step: 5
Training loss: 1.2365968227386475
Validation loss: 1.8613838482928533

Epoch: 5| Step: 6
Training loss: 0.8709023594856262
Validation loss: 1.804964489834283

Epoch: 5| Step: 7
Training loss: 0.6962941884994507
Validation loss: 1.86096614919683

Epoch: 5| Step: 8
Training loss: 0.9191898107528687
Validation loss: 1.8616514116205194

Epoch: 5| Step: 9
Training loss: 1.0872448682785034
Validation loss: 1.9295459024367794

Epoch: 5| Step: 10
Training loss: 0.6716268062591553
Validation loss: 1.8632025205960838

Epoch: 528| Step: 0
Training loss: 1.1942309141159058
Validation loss: 1.7927858880771104

Epoch: 5| Step: 1
Training loss: 1.0758103132247925
Validation loss: 1.9004913542860298

Epoch: 5| Step: 2
Training loss: 1.0402216911315918
Validation loss: 1.8816113753985333

Epoch: 5| Step: 3
Training loss: 0.992780864238739
Validation loss: 1.8892751586052678

Epoch: 5| Step: 4
Training loss: 1.061798334121704
Validation loss: 1.8699023287783387

Epoch: 5| Step: 5
Training loss: 0.8277814984321594
Validation loss: 1.870006581788422

Epoch: 5| Step: 6
Training loss: 0.8029682040214539
Validation loss: 1.7922761978641633

Epoch: 5| Step: 7
Training loss: 0.6300517916679382
Validation loss: 1.850493097818026

Epoch: 5| Step: 8
Training loss: 1.1417315006256104
Validation loss: 1.8368676234317083

Epoch: 5| Step: 9
Training loss: 0.742913007736206
Validation loss: 1.9052591445625469

Epoch: 5| Step: 10
Training loss: 1.0807111263275146
Validation loss: 1.8358304077579128

Epoch: 529| Step: 0
Training loss: 0.574863851070404
Validation loss: 1.834258589693295

Epoch: 5| Step: 1
Training loss: 1.1567872762680054
Validation loss: 1.9128973125129618

Epoch: 5| Step: 2
Training loss: 0.8024330139160156
Validation loss: 1.833585266144045

Epoch: 5| Step: 3
Training loss: 1.3259433507919312
Validation loss: 1.8086280425389607

Epoch: 5| Step: 4
Training loss: 0.9324498176574707
Validation loss: 1.8646550921983616

Epoch: 5| Step: 5
Training loss: 1.0033541917800903
Validation loss: 1.8115331139615787

Epoch: 5| Step: 6
Training loss: 1.6490062475204468
Validation loss: 1.8665282726287842

Epoch: 5| Step: 7
Training loss: 0.578224778175354
Validation loss: 1.8242039206207439

Epoch: 5| Step: 8
Training loss: 1.3099253177642822
Validation loss: 1.8054919191586074

Epoch: 5| Step: 9
Training loss: 0.9068002700805664
Validation loss: 1.8483429044805548

Epoch: 5| Step: 10
Training loss: 1.0186418294906616
Validation loss: 1.7755649423086515

Epoch: 530| Step: 0
Training loss: 1.1399757862091064
Validation loss: 1.8567605749253304

Epoch: 5| Step: 1
Training loss: 0.8058997988700867
Validation loss: 1.8188453682007328

Epoch: 5| Step: 2
Training loss: 0.9175688028335571
Validation loss: 1.8194848081117034

Epoch: 5| Step: 3
Training loss: 0.8555876016616821
Validation loss: 1.8799150720719369

Epoch: 5| Step: 4
Training loss: 0.9209473729133606
Validation loss: 1.8245193855736845

Epoch: 5| Step: 5
Training loss: 0.9001415371894836
Validation loss: 1.8897358063728578

Epoch: 5| Step: 6
Training loss: 1.1779778003692627
Validation loss: 1.8891978417673418

Epoch: 5| Step: 7
Training loss: 0.7170413136482239
Validation loss: 1.8278062112869755

Epoch: 5| Step: 8
Training loss: 0.9287209510803223
Validation loss: 1.8001254258617279

Epoch: 5| Step: 9
Training loss: 1.2858803272247314
Validation loss: 1.8177833467401483

Epoch: 5| Step: 10
Training loss: 1.4230072498321533
Validation loss: 1.8563996015056488

Epoch: 531| Step: 0
Training loss: 0.8140243291854858
Validation loss: 1.8596784965966338

Epoch: 5| Step: 1
Training loss: 0.6287466287612915
Validation loss: 1.8099870156216364

Epoch: 5| Step: 2
Training loss: 0.588521420955658
Validation loss: 1.907529269495318

Epoch: 5| Step: 3
Training loss: 0.8591315150260925
Validation loss: 1.8404829745651574

Epoch: 5| Step: 4
Training loss: 1.149256944656372
Validation loss: 1.8033779897997457

Epoch: 5| Step: 5
Training loss: 1.3180468082427979
Validation loss: 1.9044937395280408

Epoch: 5| Step: 6
Training loss: 0.9577643275260925
Validation loss: 1.8467058648345291

Epoch: 5| Step: 7
Training loss: 1.628968596458435
Validation loss: 1.8809330873591925

Epoch: 5| Step: 8
Training loss: 0.9602869153022766
Validation loss: 1.8316927417632072

Epoch: 5| Step: 9
Training loss: 1.3113806247711182
Validation loss: 1.8581949049426663

Epoch: 5| Step: 10
Training loss: 0.7188243865966797
Validation loss: 1.768765336723738

Epoch: 532| Step: 0
Training loss: 0.5757546424865723
Validation loss: 1.8284451641062254

Epoch: 5| Step: 1
Training loss: 0.8779934048652649
Validation loss: 1.8103271094701623

Epoch: 5| Step: 2
Training loss: 0.7546086311340332
Validation loss: 1.816247240189583

Epoch: 5| Step: 3
Training loss: 0.8858075141906738
Validation loss: 1.8613858710053146

Epoch: 5| Step: 4
Training loss: 1.026186227798462
Validation loss: 1.904914709829515

Epoch: 5| Step: 5
Training loss: 0.6637581586837769
Validation loss: 1.7911185269714684

Epoch: 5| Step: 6
Training loss: 1.0098930597305298
Validation loss: 1.8149312388512395

Epoch: 5| Step: 7
Training loss: 1.1122967004776
Validation loss: 1.8566532096555155

Epoch: 5| Step: 8
Training loss: 0.9191745519638062
Validation loss: 1.8888209609575168

Epoch: 5| Step: 9
Training loss: 1.9337413311004639
Validation loss: 1.8326217923113095

Epoch: 5| Step: 10
Training loss: 0.8081170320510864
Validation loss: 1.7783813425289687

Epoch: 533| Step: 0
Training loss: 1.0497682094573975
Validation loss: 1.8363971607659453

Epoch: 5| Step: 1
Training loss: 1.200148344039917
Validation loss: 1.791334226567258

Epoch: 5| Step: 2
Training loss: 0.7704129219055176
Validation loss: 1.8400125785540509

Epoch: 5| Step: 3
Training loss: 1.200211524963379
Validation loss: 1.876087078484156

Epoch: 5| Step: 4
Training loss: 1.0651365518569946
Validation loss: 1.8518771830425467

Epoch: 5| Step: 5
Training loss: 1.8206417560577393
Validation loss: 1.845733159331865

Epoch: 5| Step: 6
Training loss: 0.7332594990730286
Validation loss: 1.873122153743621

Epoch: 5| Step: 7
Training loss: 0.8968508839607239
Validation loss: 1.8306504859719226

Epoch: 5| Step: 8
Training loss: 0.7761512994766235
Validation loss: 1.811500112215678

Epoch: 5| Step: 9
Training loss: 0.7133203744888306
Validation loss: 1.8851052753386959

Epoch: 5| Step: 10
Training loss: 0.9813488125801086
Validation loss: 1.8194519294205533

Epoch: 534| Step: 0
Training loss: 0.9286249279975891
Validation loss: 1.856184369774275

Epoch: 5| Step: 1
Training loss: 1.0972660779953003
Validation loss: 1.8182921422425138

Epoch: 5| Step: 2
Training loss: 0.9844262003898621
Validation loss: 1.82073627748797

Epoch: 5| Step: 3
Training loss: 1.11562979221344
Validation loss: 1.8364035057765182

Epoch: 5| Step: 4
Training loss: 1.0999677181243896
Validation loss: 1.8496740556532336

Epoch: 5| Step: 5
Training loss: 1.031185269355774
Validation loss: 1.8675146564360587

Epoch: 5| Step: 6
Training loss: 0.8125737905502319
Validation loss: 1.8727393945058186

Epoch: 5| Step: 7
Training loss: 1.4479436874389648
Validation loss: 1.8461113065801642

Epoch: 5| Step: 8
Training loss: 0.9373559951782227
Validation loss: 1.8317182474238898

Epoch: 5| Step: 9
Training loss: 0.5665552020072937
Validation loss: 1.8333681437277025

Epoch: 5| Step: 10
Training loss: 1.121355414390564
Validation loss: 1.8042597257962791

Epoch: 535| Step: 0
Training loss: 1.3093286752700806
Validation loss: 1.8016572511324318

Epoch: 5| Step: 1
Training loss: 1.166890025138855
Validation loss: 1.823153188151698

Epoch: 5| Step: 2
Training loss: 1.0885343551635742
Validation loss: 1.8491796652475994

Epoch: 5| Step: 3
Training loss: 1.0885953903198242
Validation loss: 1.8846729352910032

Epoch: 5| Step: 4
Training loss: 1.1891415119171143
Validation loss: 1.8854270827385686

Epoch: 5| Step: 5
Training loss: 0.8393244743347168
Validation loss: 1.8462394014481576

Epoch: 5| Step: 6
Training loss: 0.9518290758132935
Validation loss: 1.832653186654532

Epoch: 5| Step: 7
Training loss: 1.0916662216186523
Validation loss: 1.868764264609224

Epoch: 5| Step: 8
Training loss: 0.6810810565948486
Validation loss: 1.8325602303269088

Epoch: 5| Step: 9
Training loss: 0.750853419303894
Validation loss: 1.8393678742070352

Epoch: 5| Step: 10
Training loss: 0.6592546105384827
Validation loss: 1.8847048974806262

Epoch: 536| Step: 0
Training loss: 0.8357354998588562
Validation loss: 1.8084918158028715

Epoch: 5| Step: 1
Training loss: 1.5621721744537354
Validation loss: 1.8332630767617175

Epoch: 5| Step: 2
Training loss: 1.1174346208572388
Validation loss: 1.8709982300317416

Epoch: 5| Step: 3
Training loss: 1.0290265083312988
Validation loss: 1.8462696895804456

Epoch: 5| Step: 4
Training loss: 0.7816532254219055
Validation loss: 1.7920666663877425

Epoch: 5| Step: 5
Training loss: 1.0893700122833252
Validation loss: 1.8869667014768046

Epoch: 5| Step: 6
Training loss: 1.0770454406738281
Validation loss: 1.8604491884990404

Epoch: 5| Step: 7
Training loss: 0.7244855165481567
Validation loss: 1.8095434916916715

Epoch: 5| Step: 8
Training loss: 1.0621235370635986
Validation loss: 1.8548957160724107

Epoch: 5| Step: 9
Training loss: 0.7354442477226257
Validation loss: 1.805743153377246

Epoch: 5| Step: 10
Training loss: 0.7752235531806946
Validation loss: 1.8649122920087589

Epoch: 537| Step: 0
Training loss: 1.5135595798492432
Validation loss: 1.8741082837504726

Epoch: 5| Step: 1
Training loss: 0.8213835954666138
Validation loss: 1.8360860193929365

Epoch: 5| Step: 2
Training loss: 1.4137372970581055
Validation loss: 1.8373332869622014

Epoch: 5| Step: 3
Training loss: 0.8669885396957397
Validation loss: 1.8120874666398572

Epoch: 5| Step: 4
Training loss: 1.3736951351165771
Validation loss: 1.7947524542449622

Epoch: 5| Step: 5
Training loss: 0.4003104269504547
Validation loss: 1.7592800996636833

Epoch: 5| Step: 6
Training loss: 0.8233829736709595
Validation loss: 1.9016187780646867

Epoch: 5| Step: 7
Training loss: 0.9209686517715454
Validation loss: 1.8079484265337709

Epoch: 5| Step: 8
Training loss: 0.8152335286140442
Validation loss: 1.8566432114570373

Epoch: 5| Step: 9
Training loss: 0.8052653074264526
Validation loss: 1.7882378088530673

Epoch: 5| Step: 10
Training loss: 1.1853408813476562
Validation loss: 1.768051903734925

Epoch: 538| Step: 0
Training loss: 0.8260530233383179
Validation loss: 1.817495358887539

Epoch: 5| Step: 1
Training loss: 0.49800148606300354
Validation loss: 1.8509497745062715

Epoch: 5| Step: 2
Training loss: 1.095691442489624
Validation loss: 1.7939486939419982

Epoch: 5| Step: 3
Training loss: 1.1656440496444702
Validation loss: 1.8404857868789344

Epoch: 5| Step: 4
Training loss: 1.1832726001739502
Validation loss: 1.8447246730968516

Epoch: 5| Step: 5
Training loss: 1.1471614837646484
Validation loss: 1.8464288121910506

Epoch: 5| Step: 6
Training loss: 0.9954760670661926
Validation loss: 1.848788551104966

Epoch: 5| Step: 7
Training loss: 0.8980825543403625
Validation loss: 1.8708585859626852

Epoch: 5| Step: 8
Training loss: 0.6620008945465088
Validation loss: 1.8348911193109327

Epoch: 5| Step: 9
Training loss: 1.3459844589233398
Validation loss: 1.813052245365676

Epoch: 5| Step: 10
Training loss: 1.0147860050201416
Validation loss: 1.814752972254189

Epoch: 539| Step: 0
Training loss: 0.686526894569397
Validation loss: 1.9133166343935075

Epoch: 5| Step: 1
Training loss: 0.8025243878364563
Validation loss: 1.7816294290686165

Epoch: 5| Step: 2
Training loss: 1.1449848413467407
Validation loss: 1.7941979304436715

Epoch: 5| Step: 3
Training loss: 0.9880905151367188
Validation loss: 1.7649405335867276

Epoch: 5| Step: 4
Training loss: 1.3534294366836548
Validation loss: 1.8537594836245301

Epoch: 5| Step: 5
Training loss: 1.059177041053772
Validation loss: 1.8303599819060294

Epoch: 5| Step: 6
Training loss: 0.872480034828186
Validation loss: 1.8373194189481838

Epoch: 5| Step: 7
Training loss: 1.1116759777069092
Validation loss: 1.8406216534235145

Epoch: 5| Step: 8
Training loss: 0.8718705177307129
Validation loss: 1.822297465416693

Epoch: 5| Step: 9
Training loss: 1.1253396272659302
Validation loss: 1.8116518605139948

Epoch: 5| Step: 10
Training loss: 0.9140944480895996
Validation loss: 1.7880231782954226

Epoch: 540| Step: 0
Training loss: 1.3782885074615479
Validation loss: 1.8799583155621764

Epoch: 5| Step: 1
Training loss: 1.2935690879821777
Validation loss: 1.83530839027897

Epoch: 5| Step: 2
Training loss: 0.5030487775802612
Validation loss: 1.8548396953972437

Epoch: 5| Step: 3
Training loss: 1.1805330514907837
Validation loss: 1.8594954988007903

Epoch: 5| Step: 4
Training loss: 0.6490322947502136
Validation loss: 1.88915761440031

Epoch: 5| Step: 5
Training loss: 0.8237174153327942
Validation loss: 1.8300856069851947

Epoch: 5| Step: 6
Training loss: 1.2440474033355713
Validation loss: 1.7946907115238968

Epoch: 5| Step: 7
Training loss: 1.1001392602920532
Validation loss: 1.962476271455006

Epoch: 5| Step: 8
Training loss: 1.0722328424453735
Validation loss: 1.9313365797842703

Epoch: 5| Step: 9
Training loss: 1.222571849822998
Validation loss: 1.8676407670462003

Epoch: 5| Step: 10
Training loss: 0.6400672793388367
Validation loss: 1.8450661154203518

Epoch: 541| Step: 0
Training loss: 0.8288918733596802
Validation loss: 1.8453299153235652

Epoch: 5| Step: 1
Training loss: 1.177707552909851
Validation loss: 1.819821197499511

Epoch: 5| Step: 2
Training loss: 1.036968469619751
Validation loss: 1.8445588119568364

Epoch: 5| Step: 3
Training loss: 0.6858624219894409
Validation loss: 1.839139194898708

Epoch: 5| Step: 4
Training loss: 0.991437554359436
Validation loss: 1.8457550374410485

Epoch: 5| Step: 5
Training loss: 1.0978893041610718
Validation loss: 1.8541807602810603

Epoch: 5| Step: 6
Training loss: 0.9535438418388367
Validation loss: 1.832110776696154

Epoch: 5| Step: 7
Training loss: 1.0802761316299438
Validation loss: 1.854664594896378

Epoch: 5| Step: 8
Training loss: 1.207853078842163
Validation loss: 1.8886351418751541

Epoch: 5| Step: 9
Training loss: 0.8867486119270325
Validation loss: 1.8598620622388777

Epoch: 5| Step: 10
Training loss: 0.7577635645866394
Validation loss: 1.8546704553788709

Epoch: 542| Step: 0
Training loss: 0.9615129232406616
Validation loss: 1.8494719920619842

Epoch: 5| Step: 1
Training loss: 0.7279382944107056
Validation loss: 1.8473609314169934

Epoch: 5| Step: 2
Training loss: 1.2701189517974854
Validation loss: 1.8509159908499768

Epoch: 5| Step: 3
Training loss: 1.2291035652160645
Validation loss: 1.8644090237156037

Epoch: 5| Step: 4
Training loss: 0.8179454803466797
Validation loss: 1.8328405323848929

Epoch: 5| Step: 5
Training loss: 0.9136632680892944
Validation loss: 1.829077180995736

Epoch: 5| Step: 6
Training loss: 1.39729905128479
Validation loss: 1.844532698713323

Epoch: 5| Step: 7
Training loss: 0.9699653387069702
Validation loss: 1.8219258682702177

Epoch: 5| Step: 8
Training loss: 1.0965468883514404
Validation loss: 1.7713841315238708

Epoch: 5| Step: 9
Training loss: 0.8026294708251953
Validation loss: 1.8256046143911218

Epoch: 5| Step: 10
Training loss: 0.6184133887290955
Validation loss: 1.8612691484471804

Epoch: 543| Step: 0
Training loss: 0.8304667472839355
Validation loss: 1.872953035498178

Epoch: 5| Step: 1
Training loss: 0.7943889498710632
Validation loss: 1.7933023040012648

Epoch: 5| Step: 2
Training loss: 0.9213091731071472
Validation loss: 1.8284128430069133

Epoch: 5| Step: 3
Training loss: 0.8024161458015442
Validation loss: 1.8229191316071378

Epoch: 5| Step: 4
Training loss: 0.9555595517158508
Validation loss: 1.865845957110005

Epoch: 5| Step: 5
Training loss: 1.0678411722183228
Validation loss: 1.8030380100332282

Epoch: 5| Step: 6
Training loss: 0.600692868232727
Validation loss: 1.8012739368664321

Epoch: 5| Step: 7
Training loss: 1.4556884765625
Validation loss: 1.7844953254986835

Epoch: 5| Step: 8
Training loss: 0.8829997181892395
Validation loss: 1.81711265220437

Epoch: 5| Step: 9
Training loss: 0.7366098165512085
Validation loss: 1.8442796968644666

Epoch: 5| Step: 10
Training loss: 1.5716724395751953
Validation loss: 1.9304546797147362

Epoch: 544| Step: 0
Training loss: 1.2757904529571533
Validation loss: 1.8230676651000977

Epoch: 5| Step: 1
Training loss: 1.0420702695846558
Validation loss: 1.8234580601415327

Epoch: 5| Step: 2
Training loss: 0.5789087414741516
Validation loss: 1.8229132813792075

Epoch: 5| Step: 3
Training loss: 1.056204080581665
Validation loss: 1.8865435995081419

Epoch: 5| Step: 4
Training loss: 1.1882280111312866
Validation loss: 1.8738476153342956

Epoch: 5| Step: 5
Training loss: 0.9859796762466431
Validation loss: 1.8721368107744443

Epoch: 5| Step: 6
Training loss: 0.9607465863227844
Validation loss: 1.9310799183384064

Epoch: 5| Step: 7
Training loss: 0.6453778743743896
Validation loss: 1.9167605792322466

Epoch: 5| Step: 8
Training loss: 0.966230571269989
Validation loss: 1.8726860553987565

Epoch: 5| Step: 9
Training loss: 1.1394412517547607
Validation loss: 1.852937190763412

Epoch: 5| Step: 10
Training loss: 0.8746337890625
Validation loss: 1.797776981066632

Epoch: 545| Step: 0
Training loss: 1.1440207958221436
Validation loss: 1.8300895562735937

Epoch: 5| Step: 1
Training loss: 0.9403325319290161
Validation loss: 1.822412399835484

Epoch: 5| Step: 2
Training loss: 1.0368421077728271
Validation loss: 1.8260856238744592

Epoch: 5| Step: 3
Training loss: 1.0947496891021729
Validation loss: 1.7593680991921374

Epoch: 5| Step: 4
Training loss: 0.7223246097564697
Validation loss: 1.8238177825045843

Epoch: 5| Step: 5
Training loss: 1.1313846111297607
Validation loss: 1.9182309155823083

Epoch: 5| Step: 6
Training loss: 0.6080141067504883
Validation loss: 1.8060648646405948

Epoch: 5| Step: 7
Training loss: 0.7237581610679626
Validation loss: 1.8229838084149104

Epoch: 5| Step: 8
Training loss: 0.7318967580795288
Validation loss: 1.8291664264535392

Epoch: 5| Step: 9
Training loss: 0.913040280342102
Validation loss: 1.8360804357836324

Epoch: 5| Step: 10
Training loss: 1.4742822647094727
Validation loss: 1.827286793339637

Epoch: 546| Step: 0
Training loss: 1.0864136219024658
Validation loss: 1.8373567929831884

Epoch: 5| Step: 1
Training loss: 0.8320792317390442
Validation loss: 1.8180329081832722

Epoch: 5| Step: 2
Training loss: 1.357404351234436
Validation loss: 1.8792163274621452

Epoch: 5| Step: 3
Training loss: 1.1915076971054077
Validation loss: 1.8414560082138225

Epoch: 5| Step: 4
Training loss: 0.9675118327140808
Validation loss: 1.8364568935927523

Epoch: 5| Step: 5
Training loss: 0.7296306490898132
Validation loss: 1.861949715563046

Epoch: 5| Step: 6
Training loss: 0.8818631172180176
Validation loss: 1.8361298294477566

Epoch: 5| Step: 7
Training loss: 1.0171475410461426
Validation loss: 1.82287674309105

Epoch: 5| Step: 8
Training loss: 0.547362208366394
Validation loss: 1.7853249349901754

Epoch: 5| Step: 9
Training loss: 1.1460669040679932
Validation loss: 1.8095768677291049

Epoch: 5| Step: 10
Training loss: 0.5460436344146729
Validation loss: 1.865930131686631

Epoch: 547| Step: 0
Training loss: 1.0477144718170166
Validation loss: 1.8458682644751765

Epoch: 5| Step: 1
Training loss: 0.7665786147117615
Validation loss: 1.8354062623875116

Epoch: 5| Step: 2
Training loss: 0.9174433946609497
Validation loss: 1.8483695368612967

Epoch: 5| Step: 3
Training loss: 0.9751524925231934
Validation loss: 1.7762677349070066

Epoch: 5| Step: 4
Training loss: 1.138989806175232
Validation loss: 1.8371773791569534

Epoch: 5| Step: 5
Training loss: 1.0892083644866943
Validation loss: 1.8537137072573426

Epoch: 5| Step: 6
Training loss: 1.2768207788467407
Validation loss: 1.792959374766196

Epoch: 5| Step: 7
Training loss: 0.8175315856933594
Validation loss: 1.828403530582305

Epoch: 5| Step: 8
Training loss: 1.0642545223236084
Validation loss: 1.8360869781945341

Epoch: 5| Step: 9
Training loss: 1.0316890478134155
Validation loss: 1.8489022524126115

Epoch: 5| Step: 10
Training loss: 0.6762270331382751
Validation loss: 1.79217436493084

Epoch: 548| Step: 0
Training loss: 1.1362807750701904
Validation loss: 1.7551723064914826

Epoch: 5| Step: 1
Training loss: 0.9903236627578735
Validation loss: 1.8066873204323552

Epoch: 5| Step: 2
Training loss: 0.9288703203201294
Validation loss: 1.805972997860242

Epoch: 5| Step: 3
Training loss: 0.6364368796348572
Validation loss: 1.8294397720726587

Epoch: 5| Step: 4
Training loss: 0.9856451749801636
Validation loss: 1.7875094336848105

Epoch: 5| Step: 5
Training loss: 1.4702796936035156
Validation loss: 1.8335887949953797

Epoch: 5| Step: 6
Training loss: 0.8915418386459351
Validation loss: 1.8164423755420152

Epoch: 5| Step: 7
Training loss: 0.886587917804718
Validation loss: 1.8544839453953568

Epoch: 5| Step: 8
Training loss: 0.6392646431922913
Validation loss: 1.8782222014601513

Epoch: 5| Step: 9
Training loss: 0.9972073435783386
Validation loss: 1.804801356407904

Epoch: 5| Step: 10
Training loss: 1.035338044166565
Validation loss: 1.808946886370259

Epoch: 549| Step: 0
Training loss: 0.8705517053604126
Validation loss: 1.8051789992599077

Epoch: 5| Step: 1
Training loss: 0.5629498362541199
Validation loss: 1.8125417424786476

Epoch: 5| Step: 2
Training loss: 0.9509708285331726
Validation loss: 1.8812695395561956

Epoch: 5| Step: 3
Training loss: 1.2210187911987305
Validation loss: 1.8255435446257233

Epoch: 5| Step: 4
Training loss: 1.1002147197723389
Validation loss: 1.8555121908905685

Epoch: 5| Step: 5
Training loss: 0.8397056460380554
Validation loss: 1.8748538596655733

Epoch: 5| Step: 6
Training loss: 0.7717761397361755
Validation loss: 1.8140215591717792

Epoch: 5| Step: 7
Training loss: 0.8140732049942017
Validation loss: 1.822611073011993

Epoch: 5| Step: 8
Training loss: 1.027061939239502
Validation loss: 1.774021251227266

Epoch: 5| Step: 9
Training loss: 1.215364694595337
Validation loss: 1.804300009563405

Epoch: 5| Step: 10
Training loss: 1.0187901258468628
Validation loss: 1.851317544137278

Epoch: 550| Step: 0
Training loss: 0.96125328540802
Validation loss: 1.8608650751011346

Epoch: 5| Step: 1
Training loss: 0.8454159498214722
Validation loss: 1.836961175805779

Epoch: 5| Step: 2
Training loss: 0.6445515751838684
Validation loss: 1.8750894056853427

Epoch: 5| Step: 3
Training loss: 0.5723934173583984
Validation loss: 1.8351619166712607

Epoch: 5| Step: 4
Training loss: 0.8108077049255371
Validation loss: 1.7811928308138283

Epoch: 5| Step: 5
Training loss: 0.9375618100166321
Validation loss: 1.8328851756229196

Epoch: 5| Step: 6
Training loss: 1.0015772581100464
Validation loss: 1.8565071577666907

Epoch: 5| Step: 7
Training loss: 1.1340107917785645
Validation loss: 1.845279275730092

Epoch: 5| Step: 8
Training loss: 1.2217743396759033
Validation loss: 1.8612019592715847

Epoch: 5| Step: 9
Training loss: 1.2787131071090698
Validation loss: 1.8546639001497658

Epoch: 5| Step: 10
Training loss: 0.6308907270431519
Validation loss: 1.876845880221295

Testing loss: 2.3854918082555137
