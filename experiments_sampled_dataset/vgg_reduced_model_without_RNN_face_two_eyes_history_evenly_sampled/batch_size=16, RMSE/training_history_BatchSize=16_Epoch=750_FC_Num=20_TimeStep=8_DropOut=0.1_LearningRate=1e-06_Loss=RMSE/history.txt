Epoch: 1| Step: 0
Training loss: 4.490047044401372
Validation loss: 5.256239092665317

Epoch: 6| Step: 1
Training loss: 5.293492500320761
Validation loss: 5.250131026282

Epoch: 6| Step: 2
Training loss: 6.317038538042433
Validation loss: 5.242599750581297

Epoch: 6| Step: 3
Training loss: 4.8017100466978
Validation loss: 5.235421240390535

Epoch: 6| Step: 4
Training loss: 5.50432485987936
Validation loss: 5.2324306784675505

Epoch: 6| Step: 5
Training loss: 5.555571967206662
Validation loss: 5.223034647290393

Epoch: 6| Step: 6
Training loss: 5.270717252676908
Validation loss: 5.218527687156155

Epoch: 6| Step: 7
Training loss: 4.810183673611326
Validation loss: 5.214270002225328

Epoch: 6| Step: 8
Training loss: 6.26648156454086
Validation loss: 5.207199994562194

Epoch: 6| Step: 9
Training loss: 4.2849161085999405
Validation loss: 5.200033328483555

Epoch: 6| Step: 10
Training loss: 4.307339884416229
Validation loss: 5.197231269812868

Epoch: 6| Step: 11
Training loss: 5.399166692792741
Validation loss: 5.187804949371816

Epoch: 6| Step: 12
Training loss: 5.412663530870276
Validation loss: 5.182916167061651

Epoch: 6| Step: 13
Training loss: 6.090725974923788
Validation loss: 5.1804193475150795

Epoch: 2| Step: 0
Training loss: 4.909707958602989
Validation loss: 5.171850560500489

Epoch: 6| Step: 1
Training loss: 5.561006495537314
Validation loss: 5.164288261499781

Epoch: 6| Step: 2
Training loss: 4.0685452598706835
Validation loss: 5.158106409365122

Epoch: 6| Step: 3
Training loss: 5.616665408684263
Validation loss: 5.153191848299701

Epoch: 6| Step: 4
Training loss: 5.664216053953043
Validation loss: 5.149077682507834

Epoch: 6| Step: 5
Training loss: 5.9935363285933265
Validation loss: 5.142520327109846

Epoch: 6| Step: 6
Training loss: 4.864221835812298
Validation loss: 5.138031529584561

Epoch: 6| Step: 7
Training loss: 5.529866018483002
Validation loss: 5.133270785128183

Epoch: 6| Step: 8
Training loss: 5.1776205458300595
Validation loss: 5.122264501180526

Epoch: 6| Step: 9
Training loss: 4.3609316654637835
Validation loss: 5.1184455382873075

Epoch: 6| Step: 10
Training loss: 4.407045116784823
Validation loss: 5.111282631247818

Epoch: 6| Step: 11
Training loss: 5.342181951671128
Validation loss: 5.106894641770643

Epoch: 6| Step: 12
Training loss: 5.250934880896266
Validation loss: 5.10224694352918

Epoch: 6| Step: 13
Training loss: 5.984527028197024
Validation loss: 5.095765790564739

Epoch: 3| Step: 0
Training loss: 5.63034685113293
Validation loss: 5.091419618238663

Epoch: 6| Step: 1
Training loss: 3.300585498309782
Validation loss: 5.084665366350561

Epoch: 6| Step: 2
Training loss: 4.0929604271215965
Validation loss: 5.0814829073660785

Epoch: 6| Step: 3
Training loss: 4.429940675635334
Validation loss: 5.071373773886503

Epoch: 6| Step: 4
Training loss: 5.173158238649711
Validation loss: 5.0654414706290805

Epoch: 6| Step: 5
Training loss: 5.258241088993123
Validation loss: 5.059016506013887

Epoch: 6| Step: 6
Training loss: 5.0794277926198985
Validation loss: 5.0560752362354116

Epoch: 6| Step: 7
Training loss: 5.444834530840887
Validation loss: 5.0470213560741435

Epoch: 6| Step: 8
Training loss: 4.057952448356205
Validation loss: 5.043936894674467

Epoch: 6| Step: 9
Training loss: 5.639713287641214
Validation loss: 5.0380269255757515

Epoch: 6| Step: 10
Training loss: 6.0334367493816545
Validation loss: 5.034552366083382

Epoch: 6| Step: 11
Training loss: 6.0093070008015745
Validation loss: 5.0265163684787435

Epoch: 6| Step: 12
Training loss: 4.933670490359717
Validation loss: 5.023800147950794

Epoch: 6| Step: 13
Training loss: 6.197309636327334
Validation loss: 5.015662956432797

Epoch: 4| Step: 0
Training loss: 4.994943732478375
Validation loss: 5.008625519386866

Epoch: 6| Step: 1
Training loss: 4.986064947275283
Validation loss: 5.0049989834160415

Epoch: 6| Step: 2
Training loss: 5.072677742451196
Validation loss: 4.9968873046185

Epoch: 6| Step: 3
Training loss: 5.441200487966248
Validation loss: 4.991985456572489

Epoch: 6| Step: 4
Training loss: 5.129126399502192
Validation loss: 4.985707773502868

Epoch: 6| Step: 5
Training loss: 4.665603562016429
Validation loss: 4.9803680948939615

Epoch: 6| Step: 6
Training loss: 5.408433418151158
Validation loss: 4.973346268677928

Epoch: 6| Step: 7
Training loss: 5.146455652493379
Validation loss: 4.968261176688252

Epoch: 6| Step: 8
Training loss: 5.215277150178486
Validation loss: 4.960819998568782

Epoch: 6| Step: 9
Training loss: 4.830808221079332
Validation loss: 4.9564156915950806

Epoch: 6| Step: 10
Training loss: 5.493926596379963
Validation loss: 4.947982595249522

Epoch: 6| Step: 11
Training loss: 4.622084239791239
Validation loss: 4.943429487543956

Epoch: 6| Step: 12
Training loss: 3.8214970723876758
Validation loss: 4.9369256487859445

Epoch: 6| Step: 13
Training loss: 5.82913943709948
Validation loss: 4.93016997062165

Epoch: 5| Step: 0
Training loss: 4.951344648427804
Validation loss: 4.922535043821665

Epoch: 6| Step: 1
Training loss: 4.270083378641086
Validation loss: 4.9169084785999395

Epoch: 6| Step: 2
Training loss: 5.359263249336013
Validation loss: 4.9113018800146975

Epoch: 6| Step: 3
Training loss: 5.205624458312044
Validation loss: 4.904391064412831

Epoch: 6| Step: 4
Training loss: 5.913978646614916
Validation loss: 4.898489730935148

Epoch: 6| Step: 5
Training loss: 5.013986099911668
Validation loss: 4.892042087678318

Epoch: 6| Step: 6
Training loss: 6.2935400525318235
Validation loss: 4.8835999008097115

Epoch: 6| Step: 7
Training loss: 4.861082506852536
Validation loss: 4.879492612982522

Epoch: 6| Step: 8
Training loss: 5.133028766134556
Validation loss: 4.870989106352888

Epoch: 6| Step: 9
Training loss: 4.532523140782462
Validation loss: 4.864629640345865

Epoch: 6| Step: 10
Training loss: 4.112890328200673
Validation loss: 4.856154945351142

Epoch: 6| Step: 11
Training loss: 4.13899861189604
Validation loss: 4.850422113044949

Epoch: 6| Step: 12
Training loss: 4.017435934603993
Validation loss: 4.8438659124831895

Epoch: 6| Step: 13
Training loss: 5.084741032700575
Validation loss: 4.835848542458692

Epoch: 6| Step: 0
Training loss: 4.833424052121535
Validation loss: 4.829871800221336

Epoch: 6| Step: 1
Training loss: 4.684864982035485
Validation loss: 4.822163360384149

Epoch: 6| Step: 2
Training loss: 5.190233728221154
Validation loss: 4.8144877877427295

Epoch: 6| Step: 3
Training loss: 5.010211625797689
Validation loss: 4.806568638748625

Epoch: 6| Step: 4
Training loss: 5.290603390698541
Validation loss: 4.8017837523146145

Epoch: 6| Step: 5
Training loss: 4.129778781535862
Validation loss: 4.7931752095616424

Epoch: 6| Step: 6
Training loss: 4.517324583176475
Validation loss: 4.786576045247908

Epoch: 6| Step: 7
Training loss: 4.793542555556756
Validation loss: 4.7786118962997195

Epoch: 6| Step: 8
Training loss: 4.4818084496517825
Validation loss: 4.769393193404775

Epoch: 6| Step: 9
Training loss: 5.65462306107937
Validation loss: 4.761655409593873

Epoch: 6| Step: 10
Training loss: 5.206715853984242
Validation loss: 4.7532850864699485

Epoch: 6| Step: 11
Training loss: 4.97595441088384
Validation loss: 4.746213412940121

Epoch: 6| Step: 12
Training loss: 4.6222703456411285
Validation loss: 4.737036029571549

Epoch: 6| Step: 13
Training loss: 4.058199675210898
Validation loss: 4.729650500423391

Epoch: 7| Step: 0
Training loss: 5.658993219129211
Validation loss: 4.720780061237442

Epoch: 6| Step: 1
Training loss: 4.553237919922473
Validation loss: 4.713415776213849

Epoch: 6| Step: 2
Training loss: 5.514127101071173
Validation loss: 4.704030680794745

Epoch: 6| Step: 3
Training loss: 4.616961736694445
Validation loss: 4.695848155507591

Epoch: 6| Step: 4
Training loss: 3.9732502331033666
Validation loss: 4.68632413930311

Epoch: 6| Step: 5
Training loss: 4.51748946086792
Validation loss: 4.67622421570204

Epoch: 6| Step: 6
Training loss: 5.398729860198004
Validation loss: 4.668041274371092

Epoch: 6| Step: 7
Training loss: 4.719094573317952
Validation loss: 4.660623535084204

Epoch: 6| Step: 8
Training loss: 5.080726872503433
Validation loss: 4.65178968312308

Epoch: 6| Step: 9
Training loss: 5.426951030307125
Validation loss: 4.643362375468675

Epoch: 6| Step: 10
Training loss: 3.9084337157892
Validation loss: 4.630811955653225

Epoch: 6| Step: 11
Training loss: 3.884645700881164
Validation loss: 4.6257817439979805

Epoch: 6| Step: 12
Training loss: 4.230062956645858
Validation loss: 4.614255733477585

Epoch: 6| Step: 13
Training loss: 4.3069734405839455
Validation loss: 4.606203068293087

Epoch: 8| Step: 0
Training loss: 4.017705356213383
Validation loss: 4.595122512279831

Epoch: 6| Step: 1
Training loss: 5.277021713087827
Validation loss: 4.588597899596112

Epoch: 6| Step: 2
Training loss: 4.4778946364062495
Validation loss: 4.578989053437482

Epoch: 6| Step: 3
Training loss: 4.328918824920263
Validation loss: 4.568364825110413

Epoch: 6| Step: 4
Training loss: 4.5071020244107265
Validation loss: 4.55513422270072

Epoch: 6| Step: 5
Training loss: 4.5700614664631125
Validation loss: 4.54730762920805

Epoch: 6| Step: 6
Training loss: 4.8835249480235845
Validation loss: 4.536142300395474

Epoch: 6| Step: 7
Training loss: 4.6072910576490145
Validation loss: 4.524968641008507

Epoch: 6| Step: 8
Training loss: 5.682031035164302
Validation loss: 4.519238691989474

Epoch: 6| Step: 9
Training loss: 4.361885250465952
Validation loss: 4.505622120474903

Epoch: 6| Step: 10
Training loss: 4.5106456719012415
Validation loss: 4.492739050463473

Epoch: 6| Step: 11
Training loss: 3.44441429418952
Validation loss: 4.484825150272462

Epoch: 6| Step: 12
Training loss: 5.109749783177224
Validation loss: 4.473398097640916

Epoch: 6| Step: 13
Training loss: 4.320975778721498
Validation loss: 4.461035850766386

Epoch: 9| Step: 0
Training loss: 4.354103538140729
Validation loss: 4.453648160648087

Epoch: 6| Step: 1
Training loss: 3.607161598750396
Validation loss: 4.439741572277913

Epoch: 6| Step: 2
Training loss: 4.085813093753184
Validation loss: 4.429767958122374

Epoch: 6| Step: 3
Training loss: 4.980848254536249
Validation loss: 4.416543388077984

Epoch: 6| Step: 4
Training loss: 4.974195459382316
Validation loss: 4.4060024941634675

Epoch: 6| Step: 5
Training loss: 4.624641610771171
Validation loss: 4.3944718391294675

Epoch: 6| Step: 6
Training loss: 4.046416621226017
Validation loss: 4.3844992342691995

Epoch: 6| Step: 7
Training loss: 3.3314988492448157
Validation loss: 4.3714156086158855

Epoch: 6| Step: 8
Training loss: 4.821808766709319
Validation loss: 4.360364433741494

Epoch: 6| Step: 9
Training loss: 4.101165345355074
Validation loss: 4.345668871436829

Epoch: 6| Step: 10
Training loss: 4.352270976115358
Validation loss: 4.333801960433231

Epoch: 6| Step: 11
Training loss: 5.451586312230794
Validation loss: 4.322055700174935

Epoch: 6| Step: 12
Training loss: 4.202842731286264
Validation loss: 4.3120199337255265

Epoch: 6| Step: 13
Training loss: 5.474374897426931
Validation loss: 4.30308283734559

Epoch: 10| Step: 0
Training loss: 4.592441917554678
Validation loss: 4.285858062426321

Epoch: 6| Step: 1
Training loss: 3.8182548489129897
Validation loss: 4.276003659117046

Epoch: 6| Step: 2
Training loss: 3.57778129426087
Validation loss: 4.254415311695389

Epoch: 6| Step: 3
Training loss: 3.798842936587449
Validation loss: 4.246564044419152

Epoch: 6| Step: 4
Training loss: 4.654815657721909
Validation loss: 4.2312352362881835

Epoch: 6| Step: 5
Training loss: 4.578767802969033
Validation loss: 4.220167500858896

Epoch: 6| Step: 6
Training loss: 4.157580628751571
Validation loss: 4.203433280032986

Epoch: 6| Step: 7
Training loss: 4.3677539219271235
Validation loss: 4.192814072463017

Epoch: 6| Step: 8
Training loss: 4.966796490980126
Validation loss: 4.17867077880092

Epoch: 6| Step: 9
Training loss: 3.5569744424789227
Validation loss: 4.165105022940119

Epoch: 6| Step: 10
Training loss: 4.149988721349626
Validation loss: 4.147258085615459

Epoch: 6| Step: 11
Training loss: 4.621923712318306
Validation loss: 4.137432035150606

Epoch: 6| Step: 12
Training loss: 5.060893427865085
Validation loss: 4.119862608649287

Epoch: 6| Step: 13
Training loss: 3.5017035289520573
Validation loss: 4.100590855232601

Epoch: 11| Step: 0
Training loss: 4.507101178035915
Validation loss: 4.087443121616308

Epoch: 6| Step: 1
Training loss: 4.450156416983578
Validation loss: 4.073600580489919

Epoch: 6| Step: 2
Training loss: 4.818639628807539
Validation loss: 4.059505295970849

Epoch: 6| Step: 3
Training loss: 3.5524041859687476
Validation loss: 4.039386846287849

Epoch: 6| Step: 4
Training loss: 3.302155663373016
Validation loss: 4.029085082127535

Epoch: 6| Step: 5
Training loss: 4.079777525277784
Validation loss: 4.017240866727876

Epoch: 6| Step: 6
Training loss: 3.861026179037433
Validation loss: 3.9939758149640814

Epoch: 6| Step: 7
Training loss: 4.39551638263578
Validation loss: 3.9839391416492576

Epoch: 6| Step: 8
Training loss: 3.4765758042670294
Validation loss: 3.9662962881144703

Epoch: 6| Step: 9
Training loss: 3.585868751681337
Validation loss: 3.947124128376119

Epoch: 6| Step: 10
Training loss: 3.903158444581242
Validation loss: 3.936748257736438

Epoch: 6| Step: 11
Training loss: 5.440896913415298
Validation loss: 3.9222287515824137

Epoch: 6| Step: 12
Training loss: 3.5778887141807543
Validation loss: 3.902051628028706

Epoch: 6| Step: 13
Training loss: 3.7844843627348586
Validation loss: 3.8907266382722203

Epoch: 12| Step: 0
Training loss: 3.688179082895754
Validation loss: 3.8715885267889076

Epoch: 6| Step: 1
Training loss: 3.9178196582970695
Validation loss: 3.856390039321057

Epoch: 6| Step: 2
Training loss: 4.346217051774199
Validation loss: 3.845558971376297

Epoch: 6| Step: 3
Training loss: 3.855098316210486
Validation loss: 3.8202613008280464

Epoch: 6| Step: 4
Training loss: 3.7884684618104996
Validation loss: 3.804047833744849

Epoch: 6| Step: 5
Training loss: 3.0170667295223392
Validation loss: 3.7864805551167344

Epoch: 6| Step: 6
Training loss: 4.035707360417227
Validation loss: 3.76421431250779

Epoch: 6| Step: 7
Training loss: 3.6097401355825527
Validation loss: 3.7501530674147507

Epoch: 6| Step: 8
Training loss: 3.964757397843515
Validation loss: 3.7367667506939326

Epoch: 6| Step: 9
Training loss: 4.060640584461614
Validation loss: 3.719753733475496

Epoch: 6| Step: 10
Training loss: 4.203383200276789
Validation loss: 3.706745737461064

Epoch: 6| Step: 11
Training loss: 3.685126365037425
Validation loss: 3.679192800931539

Epoch: 6| Step: 12
Training loss: 4.015638536957363
Validation loss: 3.6667926958710937

Epoch: 6| Step: 13
Training loss: 4.278682857948386
Validation loss: 3.6504632469029956

Epoch: 13| Step: 0
Training loss: 3.096058764321399
Validation loss: 3.629850095569418

Epoch: 6| Step: 1
Training loss: 3.8323064893826606
Validation loss: 3.6110968699672714

Epoch: 6| Step: 2
Training loss: 4.329592239174439
Validation loss: 3.5972390065131745

Epoch: 6| Step: 3
Training loss: 3.9331904245266816
Validation loss: 3.5733804628052512

Epoch: 6| Step: 4
Training loss: 3.659922784709954
Validation loss: 3.555048257668014

Epoch: 6| Step: 5
Training loss: 4.0501356502468395
Validation loss: 3.533255172309226

Epoch: 6| Step: 6
Training loss: 3.1851214341709233
Validation loss: 3.518939386553781

Epoch: 6| Step: 7
Training loss: 3.9241331370221366
Validation loss: 3.496817546822903

Epoch: 6| Step: 8
Training loss: 4.308792953520579
Validation loss: 3.4736072352839393

Epoch: 6| Step: 9
Training loss: 2.648966328534716
Validation loss: 3.454167081233

Epoch: 6| Step: 10
Training loss: 3.488428332740407
Validation loss: 3.443171242250334

Epoch: 6| Step: 11
Training loss: 3.3060438470442435
Validation loss: 3.4224149808261695

Epoch: 6| Step: 12
Training loss: 4.0209773273412255
Validation loss: 3.399940645048461

Epoch: 6| Step: 13
Training loss: 2.615471576306515
Validation loss: 3.383463773016851

Epoch: 14| Step: 0
Training loss: 4.44547897590297
Validation loss: 3.3684702623660847

Epoch: 6| Step: 1
Training loss: 3.2053905383615846
Validation loss: 3.35332813200234

Epoch: 6| Step: 2
Training loss: 2.735987770755943
Validation loss: 3.3264220812507896

Epoch: 6| Step: 3
Training loss: 3.295519509467403
Validation loss: 3.308534839713584

Epoch: 6| Step: 4
Training loss: 3.5656766949583005
Validation loss: 3.295333083387658

Epoch: 6| Step: 5
Training loss: 3.440704793810334
Validation loss: 3.283588047952745

Epoch: 6| Step: 6
Training loss: 2.9283294378380296
Validation loss: 3.2599929992454153

Epoch: 6| Step: 7
Training loss: 3.737850598888267
Validation loss: 3.2404155951383595

Epoch: 6| Step: 8
Training loss: 2.231283116028101
Validation loss: 3.2140040666363916

Epoch: 6| Step: 9
Training loss: 4.006946492465484
Validation loss: 3.2036618482905856

Epoch: 6| Step: 10
Training loss: 3.701599064232135
Validation loss: 3.193120227689942

Epoch: 6| Step: 11
Training loss: 3.5618899977596357
Validation loss: 3.177144193074787

Epoch: 6| Step: 12
Training loss: 3.253995053841478
Validation loss: 3.1572385474694697

Epoch: 6| Step: 13
Training loss: 3.5388426049235187
Validation loss: 3.1388567731891786

Epoch: 15| Step: 0
Training loss: 2.7970708853038655
Validation loss: 3.1331707363926995

Epoch: 6| Step: 1
Training loss: 3.5264097817023945
Validation loss: 3.107084501971169

Epoch: 6| Step: 2
Training loss: 2.5273729938778535
Validation loss: 3.092099140941441

Epoch: 6| Step: 3
Training loss: 3.6556758592850076
Validation loss: 3.0731169276458155

Epoch: 6| Step: 4
Training loss: 2.9670090238500153
Validation loss: 3.052510463302979

Epoch: 6| Step: 5
Training loss: 3.387391125945854
Validation loss: 3.038654122278998

Epoch: 6| Step: 6
Training loss: 3.722866824940188
Validation loss: 3.025576392725865

Epoch: 6| Step: 7
Training loss: 3.658457814896056
Validation loss: 3.0093837291139556

Epoch: 6| Step: 8
Training loss: 3.2071945018779227
Validation loss: 2.998586930306137

Epoch: 6| Step: 9
Training loss: 3.233202883130579
Validation loss: 2.9736288260352977

Epoch: 6| Step: 10
Training loss: 2.630036109850477
Validation loss: 2.960519859303566

Epoch: 6| Step: 11
Training loss: 2.830453830630187
Validation loss: 2.957860939846951

Epoch: 6| Step: 12
Training loss: 2.9596968897711955
Validation loss: 2.93809933854814

Epoch: 6| Step: 13
Training loss: 4.200665630092431
Validation loss: 2.9180351972712137

Epoch: 16| Step: 0
Training loss: 2.943138392708167
Validation loss: 2.910454102352921

Epoch: 6| Step: 1
Training loss: 3.0474907668539473
Validation loss: 2.901594224282219

Epoch: 6| Step: 2
Training loss: 3.5131873601982067
Validation loss: 2.8908517932029016

Epoch: 6| Step: 3
Training loss: 3.2638752461321885
Validation loss: 2.8736299993062766

Epoch: 6| Step: 4
Training loss: 2.669694869933147
Validation loss: 2.8641693967656265

Epoch: 6| Step: 5
Training loss: 3.1813825358603984
Validation loss: 2.853704726062925

Epoch: 6| Step: 6
Training loss: 3.413733983765294
Validation loss: 2.8407623632879013

Epoch: 6| Step: 7
Training loss: 3.0895789186047846
Validation loss: 2.8226680990520423

Epoch: 6| Step: 8
Training loss: 2.568129519776345
Validation loss: 2.815471917513498

Epoch: 6| Step: 9
Training loss: 2.6793037339937626
Validation loss: 2.807410503839103

Epoch: 6| Step: 10
Training loss: 3.230195519402331
Validation loss: 2.797975290850532

Epoch: 6| Step: 11
Training loss: 3.5261494757635057
Validation loss: 2.78516570684795

Epoch: 6| Step: 12
Training loss: 2.9385614303650853
Validation loss: 2.782960420859011

Epoch: 6| Step: 13
Training loss: 2.896585782951723
Validation loss: 2.774645790198761

Epoch: 17| Step: 0
Training loss: 3.0758388956688507
Validation loss: 2.7581612255726533

Epoch: 6| Step: 1
Training loss: 2.9927574790126306
Validation loss: 2.746994239434448

Epoch: 6| Step: 2
Training loss: 2.5191678517000535
Validation loss: 2.7526467359079776

Epoch: 6| Step: 3
Training loss: 2.949832756344887
Validation loss: 2.7380015691914514

Epoch: 6| Step: 4
Training loss: 2.646368698463615
Validation loss: 2.7268228173610543

Epoch: 6| Step: 5
Training loss: 3.7739122301416854
Validation loss: 2.723824299021058

Epoch: 6| Step: 6
Training loss: 3.25551108618155
Validation loss: 2.7261397361940074

Epoch: 6| Step: 7
Training loss: 2.2024855531181893
Validation loss: 2.7165961356500294

Epoch: 6| Step: 8
Training loss: 3.431165928323133
Validation loss: 2.725502513068

Epoch: 6| Step: 9
Training loss: 3.4460974251142273
Validation loss: 2.700758533164577

Epoch: 6| Step: 10
Training loss: 2.519501915102967
Validation loss: 2.7004534752261797

Epoch: 6| Step: 11
Training loss: 3.305557028363182
Validation loss: 2.694797090291806

Epoch: 6| Step: 12
Training loss: 2.541828608955987
Validation loss: 2.6931865785760447

Epoch: 6| Step: 13
Training loss: 2.784880936164647
Validation loss: 2.690796398955752

Epoch: 18| Step: 0
Training loss: 3.1048858287417724
Validation loss: 2.6740474642274155

Epoch: 6| Step: 1
Training loss: 3.0953945836482633
Validation loss: 2.6829049944497867

Epoch: 6| Step: 2
Training loss: 2.551697547454977
Validation loss: 2.6765600546694395

Epoch: 6| Step: 3
Training loss: 2.4888359661190127
Validation loss: 2.6722884051139437

Epoch: 6| Step: 4
Training loss: 3.0333458645181004
Validation loss: 2.6589974321224616

Epoch: 6| Step: 5
Training loss: 2.6400976613794223
Validation loss: 2.6491643840009647

Epoch: 6| Step: 6
Training loss: 3.5564526545433988
Validation loss: 2.657107338027537

Epoch: 6| Step: 7
Training loss: 2.570038476500093
Validation loss: 2.6479210659365013

Epoch: 6| Step: 8
Training loss: 3.021219075446741
Validation loss: 2.636488722745113

Epoch: 6| Step: 9
Training loss: 3.106304550459449
Validation loss: 2.640704492657736

Epoch: 6| Step: 10
Training loss: 2.760830187263696
Validation loss: 2.638944539309277

Epoch: 6| Step: 11
Training loss: 3.717230221798293
Validation loss: 2.6426602130973675

Epoch: 6| Step: 12
Training loss: 2.948659598794922
Validation loss: 2.636145535733018

Epoch: 6| Step: 13
Training loss: 2.457066958703157
Validation loss: 2.640448297174522

Epoch: 19| Step: 0
Training loss: 2.922412516881086
Validation loss: 2.6355277407746533

Epoch: 6| Step: 1
Training loss: 2.903391426927155
Validation loss: 2.623776376749528

Epoch: 6| Step: 2
Training loss: 2.789318767496204
Validation loss: 2.6370190598967613

Epoch: 6| Step: 3
Training loss: 2.957307790022743
Validation loss: 2.634956776612228

Epoch: 6| Step: 4
Training loss: 2.89168813589373
Validation loss: 2.628507691589073

Epoch: 6| Step: 5
Training loss: 2.6807019507226832
Validation loss: 2.6425394825547883

Epoch: 6| Step: 6
Training loss: 2.81959926219838
Validation loss: 2.625401139556059

Epoch: 6| Step: 7
Training loss: 3.142287084973244
Validation loss: 2.633264291015792

Epoch: 6| Step: 8
Training loss: 2.515376487446003
Validation loss: 2.6343597318633836

Epoch: 6| Step: 9
Training loss: 3.1344902892127364
Validation loss: 2.6209195989410516

Epoch: 6| Step: 10
Training loss: 2.734165728599002
Validation loss: 2.6303639297166828

Epoch: 6| Step: 11
Training loss: 3.2841542787728817
Validation loss: 2.627937472267632

Epoch: 6| Step: 12
Training loss: 3.035822143561989
Validation loss: 2.6181624165064106

Epoch: 6| Step: 13
Training loss: 3.4753854880820754
Validation loss: 2.6258248821792987

Epoch: 20| Step: 0
Training loss: 2.6998970294673392
Validation loss: 2.617158689602048

Epoch: 6| Step: 1
Training loss: 2.506281875826215
Validation loss: 2.6176586561472246

Epoch: 6| Step: 2
Training loss: 3.204887389110557
Validation loss: 2.6162863499741853

Epoch: 6| Step: 3
Training loss: 3.530923878962258
Validation loss: 2.621413439583165

Epoch: 6| Step: 4
Training loss: 2.796144699139841
Validation loss: 2.6170761709176977

Epoch: 6| Step: 5
Training loss: 2.9193020676306785
Validation loss: 2.6279937296980003

Epoch: 6| Step: 6
Training loss: 2.9355012302568286
Validation loss: 2.617758590989931

Epoch: 6| Step: 7
Training loss: 3.384777036054409
Validation loss: 2.6232553300772463

Epoch: 6| Step: 8
Training loss: 3.2293247471334823
Validation loss: 2.6144034361337334

Epoch: 6| Step: 9
Training loss: 3.0298888306320366
Validation loss: 2.6188275564722336

Epoch: 6| Step: 10
Training loss: 2.2041482916236115
Validation loss: 2.6072865367026092

Epoch: 6| Step: 11
Training loss: 3.0800985602920696
Validation loss: 2.609292366812585

Epoch: 6| Step: 12
Training loss: 2.28689712334394
Validation loss: 2.603452785143973

Epoch: 6| Step: 13
Training loss: 2.848683531698376
Validation loss: 2.6098272619282166

Epoch: 21| Step: 0
Training loss: 2.397389335106935
Validation loss: 2.615398169375535

Epoch: 6| Step: 1
Training loss: 2.98218539936144
Validation loss: 2.6098761192477293

Epoch: 6| Step: 2
Training loss: 3.4277560763201924
Validation loss: 2.5991109160873456

Epoch: 6| Step: 3
Training loss: 2.822485934307775
Validation loss: 2.6130819120953914

Epoch: 6| Step: 4
Training loss: 3.529966137861416
Validation loss: 2.5960666586461736

Epoch: 6| Step: 5
Training loss: 2.96961898132169
Validation loss: 2.598893159695299

Epoch: 6| Step: 6
Training loss: 2.7303815181042954
Validation loss: 2.6021516524470716

Epoch: 6| Step: 7
Training loss: 3.338359159260834
Validation loss: 2.596594431819398

Epoch: 6| Step: 8
Training loss: 2.6683506615493253
Validation loss: 2.5965599182349157

Epoch: 6| Step: 9
Training loss: 2.9981060407435507
Validation loss: 2.5966532283570394

Epoch: 6| Step: 10
Training loss: 2.522472563217257
Validation loss: 2.584714942494532

Epoch: 6| Step: 11
Training loss: 2.9900194087084326
Validation loss: 2.584286039397323

Epoch: 6| Step: 12
Training loss: 2.7125889917357435
Validation loss: 2.6036918794706128

Epoch: 6| Step: 13
Training loss: 2.5110599965076084
Validation loss: 2.59227009004609

Epoch: 22| Step: 0
Training loss: 2.1227726202085173
Validation loss: 2.595234957447579

Epoch: 6| Step: 1
Training loss: 2.867463558534177
Validation loss: 2.5939419810388826

Epoch: 6| Step: 2
Training loss: 2.917524556740623
Validation loss: 2.5916567818034695

Epoch: 6| Step: 3
Training loss: 3.376500114207052
Validation loss: 2.6076994211102247

Epoch: 6| Step: 4
Training loss: 2.90067815415073
Validation loss: 2.5966659830797982

Epoch: 6| Step: 5
Training loss: 2.5843876461287008
Validation loss: 2.598798604180798

Epoch: 6| Step: 6
Training loss: 2.4803580191819714
Validation loss: 2.5953234720648575

Epoch: 6| Step: 7
Training loss: 2.382513408963396
Validation loss: 2.604019064052978

Epoch: 6| Step: 8
Training loss: 3.92302027542044
Validation loss: 2.5884633965546686

Epoch: 6| Step: 9
Training loss: 2.3364545065011875
Validation loss: 2.5895444863236916

Epoch: 6| Step: 10
Training loss: 2.9917928968344096
Validation loss: 2.597527716225652

Epoch: 6| Step: 11
Training loss: 3.5830177937054355
Validation loss: 2.585436718557165

Epoch: 6| Step: 12
Training loss: 3.0477775606303736
Validation loss: 2.591780651133957

Epoch: 6| Step: 13
Training loss: 2.333727349210722
Validation loss: 2.6024715332401636

Epoch: 23| Step: 0
Training loss: 2.7950839482838616
Validation loss: 2.589383137566083

Epoch: 6| Step: 1
Training loss: 3.482014082878508
Validation loss: 2.602969031472393

Epoch: 6| Step: 2
Training loss: 3.19983813353278
Validation loss: 2.6024862148194887

Epoch: 6| Step: 3
Training loss: 2.7817763784115583
Validation loss: 2.589106364807541

Epoch: 6| Step: 4
Training loss: 2.2116591283482414
Validation loss: 2.5930203902738413

Epoch: 6| Step: 5
Training loss: 2.090484691980787
Validation loss: 2.5968700540729297

Epoch: 6| Step: 6
Training loss: 2.923636328879658
Validation loss: 2.5829845481463964

Epoch: 6| Step: 7
Training loss: 2.942757143049067
Validation loss: 2.5856320771739014

Epoch: 6| Step: 8
Training loss: 3.013815223117814
Validation loss: 2.585526706896564

Epoch: 6| Step: 9
Training loss: 2.9638681528005018
Validation loss: 2.5826165881762377

Epoch: 6| Step: 10
Training loss: 2.9124962737096434
Validation loss: 2.588121700793751

Epoch: 6| Step: 11
Training loss: 3.758283875020845
Validation loss: 2.5859710023991997

Epoch: 6| Step: 12
Training loss: 2.633462163534224
Validation loss: 2.5817869096636294

Epoch: 6| Step: 13
Training loss: 2.1514489725007224
Validation loss: 2.5925736678667057

Epoch: 24| Step: 0
Training loss: 2.893144324174888
Validation loss: 2.5840611128988202

Epoch: 6| Step: 1
Training loss: 2.9451729415087846
Validation loss: 2.5953219241938053

Epoch: 6| Step: 2
Training loss: 2.3687897852472886
Validation loss: 2.5943332475462784

Epoch: 6| Step: 3
Training loss: 2.999217567135577
Validation loss: 2.5823768911968243

Epoch: 6| Step: 4
Training loss: 3.4221096568014633
Validation loss: 2.594851534086495

Epoch: 6| Step: 5
Training loss: 2.4497562287172903
Validation loss: 2.5770554626975453

Epoch: 6| Step: 6
Training loss: 2.824108918350838
Validation loss: 2.5730809811942823

Epoch: 6| Step: 7
Training loss: 2.861892342515939
Validation loss: 2.580020760168642

Epoch: 6| Step: 8
Training loss: 3.1701577334466564
Validation loss: 2.57983644122999

Epoch: 6| Step: 9
Training loss: 2.8996829418627956
Validation loss: 2.5713182392872422

Epoch: 6| Step: 10
Training loss: 3.0918357398457474
Validation loss: 2.583324700962004

Epoch: 6| Step: 11
Training loss: 3.2818464917739294
Validation loss: 2.582562844421753

Epoch: 6| Step: 12
Training loss: 2.6877675477743868
Validation loss: 2.578763377734953

Epoch: 6| Step: 13
Training loss: 2.275879482423897
Validation loss: 2.5815570806652843

Epoch: 25| Step: 0
Training loss: 3.363114515684155
Validation loss: 2.5770919445385165

Epoch: 6| Step: 1
Training loss: 2.9058264967284875
Validation loss: 2.5762584304502467

Epoch: 6| Step: 2
Training loss: 2.739466346786056
Validation loss: 2.5736005557625776

Epoch: 6| Step: 3
Training loss: 2.5597081676678473
Validation loss: 2.580572479644796

Epoch: 6| Step: 4
Training loss: 3.2860786875650345
Validation loss: 2.5800523084002642

Epoch: 6| Step: 5
Training loss: 3.2169516270836422
Validation loss: 2.584407338685301

Epoch: 6| Step: 6
Training loss: 2.6287825443359276
Validation loss: 2.579458544739813

Epoch: 6| Step: 7
Training loss: 2.929938628559729
Validation loss: 2.579028682989337

Epoch: 6| Step: 8
Training loss: 2.727684424132944
Validation loss: 2.5845297273576673

Epoch: 6| Step: 9
Training loss: 2.4901888016663185
Validation loss: 2.5855572489736875

Epoch: 6| Step: 10
Training loss: 3.0827408470492483
Validation loss: 2.585433864818078

Epoch: 6| Step: 11
Training loss: 2.591510771287234
Validation loss: 2.572685509973793

Epoch: 6| Step: 12
Training loss: 3.15644926443042
Validation loss: 2.5839996676001435

Epoch: 6| Step: 13
Training loss: 2.429128797267572
Validation loss: 2.5759105659777566

Epoch: 26| Step: 0
Training loss: 2.847442744535989
Validation loss: 2.588082272999803

Epoch: 6| Step: 1
Training loss: 2.983748285287493
Validation loss: 2.5802412518770463

Epoch: 6| Step: 2
Training loss: 3.0301020700114214
Validation loss: 2.569922200043582

Epoch: 6| Step: 3
Training loss: 3.3356037196251958
Validation loss: 2.5876090153350755

Epoch: 6| Step: 4
Training loss: 2.6464355464245477
Validation loss: 2.581696134095212

Epoch: 6| Step: 5
Training loss: 2.6826315852703364
Validation loss: 2.576611865540898

Epoch: 6| Step: 6
Training loss: 2.9647967871362906
Validation loss: 2.5935501187665713

Epoch: 6| Step: 7
Training loss: 3.1928011625069397
Validation loss: 2.5926144779625755

Epoch: 6| Step: 8
Training loss: 2.4878965167207774
Validation loss: 2.587682919315473

Epoch: 6| Step: 9
Training loss: 3.3171434784967615
Validation loss: 2.589415198925157

Epoch: 6| Step: 10
Training loss: 3.130723213761722
Validation loss: 2.5832908218675494

Epoch: 6| Step: 11
Training loss: 2.1047551178920374
Validation loss: 2.581046346146773

Epoch: 6| Step: 12
Training loss: 2.837350540594158
Validation loss: 2.5834963959097474

Epoch: 6| Step: 13
Training loss: 2.1757523211160312
Validation loss: 2.574581338244171

Epoch: 27| Step: 0
Training loss: 3.145783548192736
Validation loss: 2.5812359259941604

Epoch: 6| Step: 1
Training loss: 2.443390014358753
Validation loss: 2.570785231133692

Epoch: 6| Step: 2
Training loss: 2.5843024025698824
Validation loss: 2.5753933761491226

Epoch: 6| Step: 3
Training loss: 2.806839481282773
Validation loss: 2.5733212123119733

Epoch: 6| Step: 4
Training loss: 3.411133231865491
Validation loss: 2.574794081504676

Epoch: 6| Step: 5
Training loss: 3.2045948656848697
Validation loss: 2.576898123183763

Epoch: 6| Step: 6
Training loss: 2.8415243640817023
Validation loss: 2.5735414661488116

Epoch: 6| Step: 7
Training loss: 3.239112517232458
Validation loss: 2.583955540652463

Epoch: 6| Step: 8
Training loss: 3.038521765137106
Validation loss: 2.576986386225128

Epoch: 6| Step: 9
Training loss: 2.4325182943254062
Validation loss: 2.5759379408119454

Epoch: 6| Step: 10
Training loss: 2.6566063137051503
Validation loss: 2.5721007244799634

Epoch: 6| Step: 11
Training loss: 3.1112255934435775
Validation loss: 2.5652895284794357

Epoch: 6| Step: 12
Training loss: 2.6667688668058287
Validation loss: 2.558525362457397

Epoch: 6| Step: 13
Training loss: 2.026602254814385
Validation loss: 2.5573348565979526

Epoch: 28| Step: 0
Training loss: 2.7252328685687113
Validation loss: 2.5637777810819378

Epoch: 6| Step: 1
Training loss: 2.5027046831780155
Validation loss: 2.5629683636043032

Epoch: 6| Step: 2
Training loss: 2.7217384663268533
Validation loss: 2.560056036675858

Epoch: 6| Step: 3
Training loss: 3.1258276796980513
Validation loss: 2.569954947594687

Epoch: 6| Step: 4
Training loss: 1.8709143311681358
Validation loss: 2.548415057048526

Epoch: 6| Step: 5
Training loss: 2.7857923811141827
Validation loss: 2.5588434924884553

Epoch: 6| Step: 6
Training loss: 3.013356675026661
Validation loss: 2.567981207178668

Epoch: 6| Step: 7
Training loss: 2.90190094436067
Validation loss: 2.556475813685671

Epoch: 6| Step: 8
Training loss: 2.99026116496817
Validation loss: 2.556022732383968

Epoch: 6| Step: 9
Training loss: 3.0998405846245465
Validation loss: 2.549269720470168

Epoch: 6| Step: 10
Training loss: 3.275876540898032
Validation loss: 2.55431854191836

Epoch: 6| Step: 11
Training loss: 2.924717790080152
Validation loss: 2.5520509123024664

Epoch: 6| Step: 12
Training loss: 2.7590792505013106
Validation loss: 2.5661079654316254

Epoch: 6| Step: 13
Training loss: 3.474777346277193
Validation loss: 2.557339903005619

Epoch: 29| Step: 0
Training loss: 3.038690147045832
Validation loss: 2.5521833827531797

Epoch: 6| Step: 1
Training loss: 2.837052895699269
Validation loss: 2.5527854598164597

Epoch: 6| Step: 2
Training loss: 3.0681868710460223
Validation loss: 2.5672197703100696

Epoch: 6| Step: 3
Training loss: 3.3021178298897187
Validation loss: 2.5443115681181285

Epoch: 6| Step: 4
Training loss: 2.7410348931491963
Validation loss: 2.5578251276363466

Epoch: 6| Step: 5
Training loss: 2.7004920617057353
Validation loss: 2.559183054396469

Epoch: 6| Step: 6
Training loss: 2.647294689715207
Validation loss: 2.5566936923509425

Epoch: 6| Step: 7
Training loss: 2.5822982765432205
Validation loss: 2.554183901794715

Epoch: 6| Step: 8
Training loss: 2.9963740052370387
Validation loss: 2.557721480421912

Epoch: 6| Step: 9
Training loss: 2.808613613944446
Validation loss: 2.5502614489474986

Epoch: 6| Step: 10
Training loss: 3.2710908112149446
Validation loss: 2.5693377684318066

Epoch: 6| Step: 11
Training loss: 2.2781461738261766
Validation loss: 2.5550684882352783

Epoch: 6| Step: 12
Training loss: 2.6455748624531945
Validation loss: 2.545828419973272

Epoch: 6| Step: 13
Training loss: 2.871857791886438
Validation loss: 2.5682699700034477

Epoch: 30| Step: 0
Training loss: 2.556366068622927
Validation loss: 2.560104631162316

Epoch: 6| Step: 1
Training loss: 2.775138397889627
Validation loss: 2.560973413255848

Epoch: 6| Step: 2
Training loss: 2.8401773668700274
Validation loss: 2.561313705712652

Epoch: 6| Step: 3
Training loss: 3.2230828020263864
Validation loss: 2.557501328663777

Epoch: 6| Step: 4
Training loss: 2.747280076226344
Validation loss: 2.5457544237786434

Epoch: 6| Step: 5
Training loss: 2.754670944640145
Validation loss: 2.5632198337146566

Epoch: 6| Step: 6
Training loss: 2.609371345197665
Validation loss: 2.5529375864498203

Epoch: 6| Step: 7
Training loss: 2.652417997913741
Validation loss: 2.5558790604344073

Epoch: 6| Step: 8
Training loss: 2.916007612336195
Validation loss: 2.552715062769012

Epoch: 6| Step: 9
Training loss: 3.614322326793504
Validation loss: 2.5568397399500626

Epoch: 6| Step: 10
Training loss: 2.8163906737173297
Validation loss: 2.5412673804671155

Epoch: 6| Step: 11
Training loss: 2.8913197275371854
Validation loss: 2.5549645064384428

Epoch: 6| Step: 12
Training loss: 2.315028792628606
Validation loss: 2.5533903246284053

Epoch: 6| Step: 13
Training loss: 3.130412183440453
Validation loss: 2.561028143613326

Epoch: 31| Step: 0
Training loss: 2.727070233746087
Validation loss: 2.5540676106835654

Epoch: 6| Step: 1
Training loss: 3.5592120875987816
Validation loss: 2.5415379837788827

Epoch: 6| Step: 2
Training loss: 2.8080723985592924
Validation loss: 2.5518255616312366

Epoch: 6| Step: 3
Training loss: 2.7710580854161546
Validation loss: 2.5529660792472386

Epoch: 6| Step: 4
Training loss: 2.910649405048029
Validation loss: 2.5473743469859276

Epoch: 6| Step: 5
Training loss: 2.354036063113305
Validation loss: 2.560638650110018

Epoch: 6| Step: 6
Training loss: 2.491499755099945
Validation loss: 2.563437827728347

Epoch: 6| Step: 7
Training loss: 2.823221159744201
Validation loss: 2.544958537433444

Epoch: 6| Step: 8
Training loss: 3.1277487300821134
Validation loss: 2.551185616437302

Epoch: 6| Step: 9
Training loss: 2.3403784343179015
Validation loss: 2.545943410349308

Epoch: 6| Step: 10
Training loss: 2.6674999087618785
Validation loss: 2.546899080367113

Epoch: 6| Step: 11
Training loss: 2.757658351664175
Validation loss: 2.5414388330246265

Epoch: 6| Step: 12
Training loss: 2.995684062296729
Validation loss: 2.5542326049879773

Epoch: 6| Step: 13
Training loss: 3.5881779472087167
Validation loss: 2.5476943655282533

Epoch: 32| Step: 0
Training loss: 2.5723662823770743
Validation loss: 2.548541480767511

Epoch: 6| Step: 1
Training loss: 3.0077784152390983
Validation loss: 2.550497986482797

Epoch: 6| Step: 2
Training loss: 3.166137316445987
Validation loss: 2.557120378073975

Epoch: 6| Step: 3
Training loss: 2.916826588923914
Validation loss: 2.555108499711008

Epoch: 6| Step: 4
Training loss: 2.630469029162862
Validation loss: 2.5492343469338676

Epoch: 6| Step: 5
Training loss: 3.163863262920817
Validation loss: 2.5514069833540587

Epoch: 6| Step: 6
Training loss: 3.3486098864135725
Validation loss: 2.5497360732713488

Epoch: 6| Step: 7
Training loss: 2.2226987274884356
Validation loss: 2.5457166675801686

Epoch: 6| Step: 8
Training loss: 3.3702551372175678
Validation loss: 2.5508717202080184

Epoch: 6| Step: 9
Training loss: 2.8958863909866963
Validation loss: 2.5403499437073696

Epoch: 6| Step: 10
Training loss: 2.4972119997932936
Validation loss: 2.551881745952766

Epoch: 6| Step: 11
Training loss: 2.2349983892925698
Validation loss: 2.5443728867082434

Epoch: 6| Step: 12
Training loss: 3.0422070863599715
Validation loss: 2.551824555996361

Epoch: 6| Step: 13
Training loss: 1.8934554673592296
Validation loss: 2.5457393707110105

Epoch: 33| Step: 0
Training loss: 2.8684661259372426
Validation loss: 2.5475856620700923

Epoch: 6| Step: 1
Training loss: 2.4361547034362796
Validation loss: 2.5477021700618674

Epoch: 6| Step: 2
Training loss: 2.6407950081355986
Validation loss: 2.538233603197805

Epoch: 6| Step: 3
Training loss: 3.4761161603405406
Validation loss: 2.541262348547905

Epoch: 6| Step: 4
Training loss: 2.599479505818785
Validation loss: 2.5416592332747068

Epoch: 6| Step: 5
Training loss: 2.480559387954005
Validation loss: 2.5490182142732274

Epoch: 6| Step: 6
Training loss: 2.7368558256388393
Validation loss: 2.5385716965879057

Epoch: 6| Step: 7
Training loss: 3.2739129278853767
Validation loss: 2.544095235911796

Epoch: 6| Step: 8
Training loss: 2.6974606122384137
Validation loss: 2.54476740848886

Epoch: 6| Step: 9
Training loss: 2.170513357448712
Validation loss: 2.543206570632895

Epoch: 6| Step: 10
Training loss: 2.9098386860080176
Validation loss: 2.5429067997161163

Epoch: 6| Step: 11
Training loss: 2.919517504399673
Validation loss: 2.5460208678810075

Epoch: 6| Step: 12
Training loss: 3.3428872680005317
Validation loss: 2.5571787318243615

Epoch: 6| Step: 13
Training loss: 2.7161787304786373
Validation loss: 2.539884442362174

Epoch: 34| Step: 0
Training loss: 2.458674089339189
Validation loss: 2.547459166763885

Epoch: 6| Step: 1
Training loss: 2.2436416642326082
Validation loss: 2.548186178511483

Epoch: 6| Step: 2
Training loss: 2.7812130529114114
Validation loss: 2.546302197005055

Epoch: 6| Step: 3
Training loss: 3.139980268963093
Validation loss: 2.5515755351395955

Epoch: 6| Step: 4
Training loss: 2.72245833828298
Validation loss: 2.545941299778831

Epoch: 6| Step: 5
Training loss: 2.0635802012322477
Validation loss: 2.542199271842463

Epoch: 6| Step: 6
Training loss: 3.4194997966000455
Validation loss: 2.54539456885805

Epoch: 6| Step: 7
Training loss: 3.618239840847817
Validation loss: 2.5493264538709504

Epoch: 6| Step: 8
Training loss: 2.826086584780104
Validation loss: 2.54632934144488

Epoch: 6| Step: 9
Training loss: 2.46062261595355
Validation loss: 2.5357319013821766

Epoch: 6| Step: 10
Training loss: 3.061782441446485
Validation loss: 2.5428874607362157

Epoch: 6| Step: 11
Training loss: 2.681324094802265
Validation loss: 2.540347605463341

Epoch: 6| Step: 12
Training loss: 2.7510172956360472
Validation loss: 2.541397952664003

Epoch: 6| Step: 13
Training loss: 2.9842899969488004
Validation loss: 2.542311924553904

Epoch: 35| Step: 0
Training loss: 3.6505380991562206
Validation loss: 2.5419608204315316

Epoch: 6| Step: 1
Training loss: 3.6721488688175894
Validation loss: 2.5488312379846865

Epoch: 6| Step: 2
Training loss: 3.0095918222753304
Validation loss: 2.5480915945840934

Epoch: 6| Step: 3
Training loss: 2.804582854207467
Validation loss: 2.5332701782305453

Epoch: 6| Step: 4
Training loss: 1.817681240400891
Validation loss: 2.532317059829472

Epoch: 6| Step: 5
Training loss: 3.3443905225809525
Validation loss: 2.534358334255449

Epoch: 6| Step: 6
Training loss: 2.1506666791048343
Validation loss: 2.548380895936524

Epoch: 6| Step: 7
Training loss: 2.3535331503821038
Validation loss: 2.540286861832015

Epoch: 6| Step: 8
Training loss: 2.6120931208136047
Validation loss: 2.5341145845203377

Epoch: 6| Step: 9
Training loss: 3.183483210791845
Validation loss: 2.5553405495013854

Epoch: 6| Step: 10
Training loss: 2.3359134124228396
Validation loss: 2.5349757147317447

Epoch: 6| Step: 11
Training loss: 2.432697357608591
Validation loss: 2.539160134179244

Epoch: 6| Step: 12
Training loss: 2.305515153625365
Validation loss: 2.525614772525134

Epoch: 6| Step: 13
Training loss: 3.0732474628569277
Validation loss: 2.540943201817519

Epoch: 36| Step: 0
Training loss: 2.42227642055075
Validation loss: 2.532631650318468

Epoch: 6| Step: 1
Training loss: 3.171262785359894
Validation loss: 2.527010710076423

Epoch: 6| Step: 2
Training loss: 2.4895232976806674
Validation loss: 2.531381915306363

Epoch: 6| Step: 3
Training loss: 2.944871297721522
Validation loss: 2.5378175632639097

Epoch: 6| Step: 4
Training loss: 3.0019032481014296
Validation loss: 2.536254139465435

Epoch: 6| Step: 5
Training loss: 2.9854077853922347
Validation loss: 2.535839100146056

Epoch: 6| Step: 6
Training loss: 2.8618496884928053
Validation loss: 2.5332870682645963

Epoch: 6| Step: 7
Training loss: 3.50465274543554
Validation loss: 2.5393462092790355

Epoch: 6| Step: 8
Training loss: 2.463587324325573
Validation loss: 2.5375049260647975

Epoch: 6| Step: 9
Training loss: 2.613470552484729
Validation loss: 2.5412094179648963

Epoch: 6| Step: 10
Training loss: 2.371457921928212
Validation loss: 2.537189515122009

Epoch: 6| Step: 11
Training loss: 2.6226451847410024
Validation loss: 2.5409984695397614

Epoch: 6| Step: 12
Training loss: 2.7134704189990195
Validation loss: 2.534687782091457

Epoch: 6| Step: 13
Training loss: 3.127775561834634
Validation loss: 2.5378159934509976

Epoch: 37| Step: 0
Training loss: 2.4033264631295737
Validation loss: 2.5462288398255497

Epoch: 6| Step: 1
Training loss: 3.2698730873421096
Validation loss: 2.534272467028628

Epoch: 6| Step: 2
Training loss: 2.657588486871464
Validation loss: 2.542488975449778

Epoch: 6| Step: 3
Training loss: 2.7259610887298606
Validation loss: 2.5343497410885614

Epoch: 6| Step: 4
Training loss: 2.733994201302396
Validation loss: 2.5298963365884863

Epoch: 6| Step: 5
Training loss: 2.7276500729848574
Validation loss: 2.532384428582375

Epoch: 6| Step: 6
Training loss: 2.642931861631289
Validation loss: 2.527739499609985

Epoch: 6| Step: 7
Training loss: 3.122100247647385
Validation loss: 2.52689206713162

Epoch: 6| Step: 8
Training loss: 2.832120317834315
Validation loss: 2.539126745630703

Epoch: 6| Step: 9
Training loss: 3.08037720983694
Validation loss: 2.5340345757925413

Epoch: 6| Step: 10
Training loss: 3.461907313330868
Validation loss: 2.5503589971785567

Epoch: 6| Step: 11
Training loss: 2.7521608706074283
Validation loss: 2.5422880820809044

Epoch: 6| Step: 12
Training loss: 2.250245186903881
Validation loss: 2.5367801810173387

Epoch: 6| Step: 13
Training loss: 1.9411514698380365
Validation loss: 2.551854460655548

Epoch: 38| Step: 0
Training loss: 2.458692513643776
Validation loss: 2.5293146216816402

Epoch: 6| Step: 1
Training loss: 3.214579278165015
Validation loss: 2.549332807337893

Epoch: 6| Step: 2
Training loss: 2.163484792339847
Validation loss: 2.5239693848683

Epoch: 6| Step: 3
Training loss: 2.85785855797913
Validation loss: 2.54150643962413

Epoch: 6| Step: 4
Training loss: 3.230419891984296
Validation loss: 2.5330797431468466

Epoch: 6| Step: 5
Training loss: 2.8865545533266914
Validation loss: 2.547243286054786

Epoch: 6| Step: 6
Training loss: 2.3493818646995637
Validation loss: 2.5256278758501045

Epoch: 6| Step: 7
Training loss: 2.6504735631482452
Validation loss: 2.531706203367002

Epoch: 6| Step: 8
Training loss: 2.7724091678527794
Validation loss: 2.527881138199256

Epoch: 6| Step: 9
Training loss: 2.5560522138190542
Validation loss: 2.525730235560323

Epoch: 6| Step: 10
Training loss: 2.326851105835005
Validation loss: 2.5345117742793417

Epoch: 6| Step: 11
Training loss: 3.1382976657854984
Validation loss: 2.528241342785746

Epoch: 6| Step: 12
Training loss: 3.5208087596750537
Validation loss: 2.533393923202746

Epoch: 6| Step: 13
Training loss: 2.67172508488415
Validation loss: 2.5343750501322924

Epoch: 39| Step: 0
Training loss: 2.5513289186419366
Validation loss: 2.519093915016445

Epoch: 6| Step: 1
Training loss: 3.1205232215754464
Validation loss: 2.52645654513696

Epoch: 6| Step: 2
Training loss: 3.246668648794249
Validation loss: 2.5255372931210203

Epoch: 6| Step: 3
Training loss: 2.602878088993199
Validation loss: 2.5323444948951606

Epoch: 6| Step: 4
Training loss: 2.752774572857085
Validation loss: 2.530006834654271

Epoch: 6| Step: 5
Training loss: 2.489287695363002
Validation loss: 2.5242430450370907

Epoch: 6| Step: 6
Training loss: 2.8735188525052564
Validation loss: 2.529610929995039

Epoch: 6| Step: 7
Training loss: 2.8134979173087515
Validation loss: 2.5371751933124997

Epoch: 6| Step: 8
Training loss: 2.5023904815702562
Validation loss: 2.523127245805198

Epoch: 6| Step: 9
Training loss: 3.197920129299878
Validation loss: 2.529064835992982

Epoch: 6| Step: 10
Training loss: 2.2684948864467835
Validation loss: 2.5274942940328193

Epoch: 6| Step: 11
Training loss: 2.4883274331590317
Validation loss: 2.5389931178808722

Epoch: 6| Step: 12
Training loss: 2.9863784216967018
Validation loss: 2.5360407388983073

Epoch: 6| Step: 13
Training loss: 3.2434694260693564
Validation loss: 2.533764136373744

Epoch: 40| Step: 0
Training loss: 2.5981064944036083
Validation loss: 2.523103401887235

Epoch: 6| Step: 1
Training loss: 2.652663648412687
Validation loss: 2.5294348415537287

Epoch: 6| Step: 2
Training loss: 2.795028844421807
Validation loss: 2.5384068947517044

Epoch: 6| Step: 3
Training loss: 2.8639374900794397
Validation loss: 2.5258867563680854

Epoch: 6| Step: 4
Training loss: 2.658309317772309
Validation loss: 2.5188384136020074

Epoch: 6| Step: 5
Training loss: 2.843111574380689
Validation loss: 2.5259677473153674

Epoch: 6| Step: 6
Training loss: 3.034072977233204
Validation loss: 2.5266625001192082

Epoch: 6| Step: 7
Training loss: 2.7574358890997117
Validation loss: 2.5364321529420892

Epoch: 6| Step: 8
Training loss: 2.9662288199792655
Validation loss: 2.5250085722311644

Epoch: 6| Step: 9
Training loss: 2.587533233724008
Validation loss: 2.5325194876810984

Epoch: 6| Step: 10
Training loss: 3.217023664307409
Validation loss: 2.530155459233063

Epoch: 6| Step: 11
Training loss: 2.797911638343896
Validation loss: 2.517352751162948

Epoch: 6| Step: 12
Training loss: 2.438784529824264
Validation loss: 2.516306150092012

Epoch: 6| Step: 13
Training loss: 2.749122219445238
Validation loss: 2.5216786096172927

Epoch: 41| Step: 0
Training loss: 3.0896415788986866
Validation loss: 2.5230697160124134

Epoch: 6| Step: 1
Training loss: 2.840155037422549
Validation loss: 2.5192295421332673

Epoch: 6| Step: 2
Training loss: 2.302739965999892
Validation loss: 2.535541829139769

Epoch: 6| Step: 3
Training loss: 3.0767227309365275
Validation loss: 2.536674766371824

Epoch: 6| Step: 4
Training loss: 2.753464164150185
Validation loss: 2.514736813884764

Epoch: 6| Step: 5
Training loss: 2.4830303271834784
Validation loss: 2.5193362148531877

Epoch: 6| Step: 6
Training loss: 3.1025272281506275
Validation loss: 2.5308716133018963

Epoch: 6| Step: 7
Training loss: 2.4742858241643475
Validation loss: 2.5271018192476173

Epoch: 6| Step: 8
Training loss: 2.612530291075981
Validation loss: 2.5320235589183366

Epoch: 6| Step: 9
Training loss: 2.670531085483548
Validation loss: 2.5198147003080544

Epoch: 6| Step: 10
Training loss: 2.588795629639821
Validation loss: 2.524401399713917

Epoch: 6| Step: 11
Training loss: 2.7721890070608715
Validation loss: 2.5305582273791023

Epoch: 6| Step: 12
Training loss: 3.0196051545370364
Validation loss: 2.550830892529464

Epoch: 6| Step: 13
Training loss: 3.2331930018643624
Validation loss: 2.5232745778704047

Epoch: 42| Step: 0
Training loss: 1.615866448605894
Validation loss: 2.5098327844794617

Epoch: 6| Step: 1
Training loss: 3.508910824929458
Validation loss: 2.522120396784835

Epoch: 6| Step: 2
Training loss: 2.3823661010838584
Validation loss: 2.516815484736225

Epoch: 6| Step: 3
Training loss: 3.418947544004556
Validation loss: 2.5220379689744767

Epoch: 6| Step: 4
Training loss: 3.323050628799896
Validation loss: 2.544074290133957

Epoch: 6| Step: 5
Training loss: 2.5412627561054855
Validation loss: 2.531325596012617

Epoch: 6| Step: 6
Training loss: 2.4286846286773693
Validation loss: 2.5233162781267744

Epoch: 6| Step: 7
Training loss: 3.0648206365230606
Validation loss: 2.5249240247727975

Epoch: 6| Step: 8
Training loss: 2.7038469177455386
Validation loss: 2.5188646815260642

Epoch: 6| Step: 9
Training loss: 2.4821296958143146
Validation loss: 2.516120924435687

Epoch: 6| Step: 10
Training loss: 3.178435057872704
Validation loss: 2.5152594391753045

Epoch: 6| Step: 11
Training loss: 2.5973032317104625
Validation loss: 2.5170896527823876

Epoch: 6| Step: 12
Training loss: 2.321449797397031
Validation loss: 2.524490610629281

Epoch: 6| Step: 13
Training loss: 2.712854328832743
Validation loss: 2.5177330438414405

Epoch: 43| Step: 0
Training loss: 2.3588840403272155
Validation loss: 2.5212695168902663

Epoch: 6| Step: 1
Training loss: 2.6643651527475156
Validation loss: 2.522405416059208

Epoch: 6| Step: 2
Training loss: 3.095517973071138
Validation loss: 2.515237532660506

Epoch: 6| Step: 3
Training loss: 2.750239448526429
Validation loss: 2.514950716858545

Epoch: 6| Step: 4
Training loss: 2.9185045355558485
Validation loss: 2.5228785292555598

Epoch: 6| Step: 5
Training loss: 2.729939552727835
Validation loss: 2.5145377437075607

Epoch: 6| Step: 6
Training loss: 3.4715853263811227
Validation loss: 2.5139744079175075

Epoch: 6| Step: 7
Training loss: 3.0568150284709956
Validation loss: 2.5156404238338665

Epoch: 6| Step: 8
Training loss: 2.2718764776044025
Validation loss: 2.5144094848837373

Epoch: 6| Step: 9
Training loss: 2.4395532030112124
Validation loss: 2.512576861882557

Epoch: 6| Step: 10
Training loss: 2.0198794863415146
Validation loss: 2.5134700288034786

Epoch: 6| Step: 11
Training loss: 2.9601128469040248
Validation loss: 2.515936686781446

Epoch: 6| Step: 12
Training loss: 3.180767653795486
Validation loss: 2.514550848681205

Epoch: 6| Step: 13
Training loss: 2.6314737329029163
Validation loss: 2.5069137985490513

Epoch: 44| Step: 0
Training loss: 2.48673122161988
Validation loss: 2.5190545405291456

Epoch: 6| Step: 1
Training loss: 2.4578516428959514
Validation loss: 2.5220769334931528

Epoch: 6| Step: 2
Training loss: 2.997735440359229
Validation loss: 2.5195741640089597

Epoch: 6| Step: 3
Training loss: 3.634829644116495
Validation loss: 2.5143644710607225

Epoch: 6| Step: 4
Training loss: 2.9392787336661574
Validation loss: 2.5110122814202462

Epoch: 6| Step: 5
Training loss: 2.4274409171240254
Validation loss: 2.5079114100457116

Epoch: 6| Step: 6
Training loss: 2.424426992300926
Validation loss: 2.5172130392842917

Epoch: 6| Step: 7
Training loss: 3.3191504745094824
Validation loss: 2.5167997309432275

Epoch: 6| Step: 8
Training loss: 3.1076999158686225
Validation loss: 2.5183117617306934

Epoch: 6| Step: 9
Training loss: 2.3401005115278135
Validation loss: 2.5239487900901265

Epoch: 6| Step: 10
Training loss: 3.0715916422393787
Validation loss: 2.517759372172589

Epoch: 6| Step: 11
Training loss: 2.4921255074088333
Validation loss: 2.5253816866221035

Epoch: 6| Step: 12
Training loss: 2.0839031457488173
Validation loss: 2.5217418560637475

Epoch: 6| Step: 13
Training loss: 2.3983130407192843
Validation loss: 2.515041036155865

Epoch: 45| Step: 0
Training loss: 2.0920945640474744
Validation loss: 2.515768716709739

Epoch: 6| Step: 1
Training loss: 3.2065490285770553
Validation loss: 2.5272056023367644

Epoch: 6| Step: 2
Training loss: 2.8356935170206854
Validation loss: 2.5272279102852515

Epoch: 6| Step: 3
Training loss: 2.724366448623738
Validation loss: 2.508521032732353

Epoch: 6| Step: 4
Training loss: 2.3547587930053653
Validation loss: 2.522589241737219

Epoch: 6| Step: 5
Training loss: 2.5131326970056294
Validation loss: 2.5209622703967716

Epoch: 6| Step: 6
Training loss: 2.3862286203344847
Validation loss: 2.51867652125728

Epoch: 6| Step: 7
Training loss: 2.4189770495874208
Validation loss: 2.5144238150342844

Epoch: 6| Step: 8
Training loss: 3.1726014756972223
Validation loss: 2.5285258723406123

Epoch: 6| Step: 9
Training loss: 2.435426857445386
Validation loss: 2.5196448113948957

Epoch: 6| Step: 10
Training loss: 2.948373029091936
Validation loss: 2.5190666653722302

Epoch: 6| Step: 11
Training loss: 3.246180270404191
Validation loss: 2.5246458024060647

Epoch: 6| Step: 12
Training loss: 2.775120012592167
Validation loss: 2.523079758926983

Epoch: 6| Step: 13
Training loss: 3.696497914550391
Validation loss: 2.5171104055299875

Epoch: 46| Step: 0
Training loss: 2.408318559365897
Validation loss: 2.5175232361913653

Epoch: 6| Step: 1
Training loss: 2.945314118969217
Validation loss: 2.514080061093073

Epoch: 6| Step: 2
Training loss: 2.6735749664725836
Validation loss: 2.521243676680447

Epoch: 6| Step: 3
Training loss: 3.4255719006728915
Validation loss: 2.5219112286034964

Epoch: 6| Step: 4
Training loss: 2.4241485752738923
Validation loss: 2.5074197612869504

Epoch: 6| Step: 5
Training loss: 2.740968351702624
Validation loss: 2.521494918352191

Epoch: 6| Step: 6
Training loss: 2.585542769716251
Validation loss: 2.5212655757491853

Epoch: 6| Step: 7
Training loss: 2.830185955933994
Validation loss: 2.5258809884189364

Epoch: 6| Step: 8
Training loss: 2.0110219989561635
Validation loss: 2.5197247301723524

Epoch: 6| Step: 9
Training loss: 3.8401420221291387
Validation loss: 2.514151149903919

Epoch: 6| Step: 10
Training loss: 1.848228962631342
Validation loss: 2.522293831839567

Epoch: 6| Step: 11
Training loss: 2.372172429229499
Validation loss: 2.5137452980615516

Epoch: 6| Step: 12
Training loss: 2.9897702963891555
Validation loss: 2.5203179683752746

Epoch: 6| Step: 13
Training loss: 3.0898147369450126
Validation loss: 2.5208397803092355

Epoch: 47| Step: 0
Training loss: 2.6851151996812135
Validation loss: 2.5148868933976516

Epoch: 6| Step: 1
Training loss: 3.1512317610639933
Validation loss: 2.5222662508607923

Epoch: 6| Step: 2
Training loss: 3.3331887849619752
Validation loss: 2.523790340988068

Epoch: 6| Step: 3
Training loss: 2.8974599500756657
Validation loss: 2.513500173561029

Epoch: 6| Step: 4
Training loss: 2.20721035120916
Validation loss: 2.516491091131032

Epoch: 6| Step: 5
Training loss: 3.0859923538934075
Validation loss: 2.512150785694156

Epoch: 6| Step: 6
Training loss: 3.0926009076739125
Validation loss: 2.5162046408382626

Epoch: 6| Step: 7
Training loss: 2.800319660195919
Validation loss: 2.5102044452689083

Epoch: 6| Step: 8
Training loss: 2.8460613541038153
Validation loss: 2.5198606509310815

Epoch: 6| Step: 9
Training loss: 2.263166474871205
Validation loss: 2.514197577744046

Epoch: 6| Step: 10
Training loss: 2.593162745901884
Validation loss: 2.513875945992416

Epoch: 6| Step: 11
Training loss: 2.261784317041297
Validation loss: 2.51468952639596

Epoch: 6| Step: 12
Training loss: 2.507803943655088
Validation loss: 2.5169900914999643

Epoch: 6| Step: 13
Training loss: 2.392347924193525
Validation loss: 2.514469200952229

Epoch: 48| Step: 0
Training loss: 2.537301447574619
Validation loss: 2.520700049650209

Epoch: 6| Step: 1
Training loss: 2.8715597384384846
Validation loss: 2.5035915847982366

Epoch: 6| Step: 2
Training loss: 2.759828344065713
Validation loss: 2.5171965058093315

Epoch: 6| Step: 3
Training loss: 2.1820923586004333
Validation loss: 2.5063092961811404

Epoch: 6| Step: 4
Training loss: 3.0640939729388195
Validation loss: 2.5216164941501926

Epoch: 6| Step: 5
Training loss: 2.286134793990758
Validation loss: 2.5141188448208713

Epoch: 6| Step: 6
Training loss: 2.784689587290601
Validation loss: 2.5116499782302637

Epoch: 6| Step: 7
Training loss: 1.9449450900409853
Validation loss: 2.518310814990788

Epoch: 6| Step: 8
Training loss: 2.5158037394648596
Validation loss: 2.49283311923878

Epoch: 6| Step: 9
Training loss: 2.664920433817697
Validation loss: 2.5230093032376457

Epoch: 6| Step: 10
Training loss: 2.8326314355938633
Validation loss: 2.5168301683926155

Epoch: 6| Step: 11
Training loss: 3.562808642486098
Validation loss: 2.5224291720556304

Epoch: 6| Step: 12
Training loss: 3.2789185006360673
Validation loss: 2.521949287826221

Epoch: 6| Step: 13
Training loss: 3.0912696837135205
Validation loss: 2.5203718666290613

Epoch: 49| Step: 0
Training loss: 2.092769905831423
Validation loss: 2.521371404840453

Epoch: 6| Step: 1
Training loss: 2.9617216737612515
Validation loss: 2.49945282229127

Epoch: 6| Step: 2
Training loss: 2.6661488705827856
Validation loss: 2.505334292522816

Epoch: 6| Step: 3
Training loss: 2.652066245751921
Validation loss: 2.514118365817937

Epoch: 6| Step: 4
Training loss: 3.602018182686384
Validation loss: 2.519850427828002

Epoch: 6| Step: 5
Training loss: 2.4754384856543186
Validation loss: 2.4997072899618993

Epoch: 6| Step: 6
Training loss: 2.3302180974827094
Validation loss: 2.513127979049796

Epoch: 6| Step: 7
Training loss: 2.8564431423602867
Validation loss: 2.5090634240498146

Epoch: 6| Step: 8
Training loss: 2.3092254961941134
Validation loss: 2.5300070646719885

Epoch: 6| Step: 9
Training loss: 2.9510975493205014
Validation loss: 2.51762666773769

Epoch: 6| Step: 10
Training loss: 2.887383700584218
Validation loss: 2.5244079753526005

Epoch: 6| Step: 11
Training loss: 2.8338972166344076
Validation loss: 2.5192762152476424

Epoch: 6| Step: 12
Training loss: 2.6730292431580005
Validation loss: 2.512427360689867

Epoch: 6| Step: 13
Training loss: 2.979058128104828
Validation loss: 2.509373573034436

Epoch: 50| Step: 0
Training loss: 2.4179596785219575
Validation loss: 2.523174573287811

Epoch: 6| Step: 1
Training loss: 2.399511736635032
Validation loss: 2.5072963698315203

Epoch: 6| Step: 2
Training loss: 2.662050981224015
Validation loss: 2.525137899835121

Epoch: 6| Step: 3
Training loss: 2.755900208990533
Validation loss: 2.509858148720052

Epoch: 6| Step: 4
Training loss: 3.384539086475566
Validation loss: 2.504930356246599

Epoch: 6| Step: 5
Training loss: 3.061389332439667
Validation loss: 2.5094655789619584

Epoch: 6| Step: 6
Training loss: 2.629715634771787
Validation loss: 2.5128807233266555

Epoch: 6| Step: 7
Training loss: 2.5207368080848
Validation loss: 2.5176933415781693

Epoch: 6| Step: 8
Training loss: 2.9711116030906712
Validation loss: 2.5093132606340283

Epoch: 6| Step: 9
Training loss: 2.3590038083358236
Validation loss: 2.4939879278498402

Epoch: 6| Step: 10
Training loss: 2.7827845422624415
Validation loss: 2.523629060910465

Epoch: 6| Step: 11
Training loss: 2.271484165076839
Validation loss: 2.5090814160167225

Epoch: 6| Step: 12
Training loss: 3.383786525973075
Validation loss: 2.527280911541866

Epoch: 6| Step: 13
Training loss: 2.4799713837603083
Validation loss: 2.511805160634186

Epoch: 51| Step: 0
Training loss: 2.9088621808211745
Validation loss: 2.5108302883693896

Epoch: 6| Step: 1
Training loss: 2.895944021474292
Validation loss: 2.5190560731841796

Epoch: 6| Step: 2
Training loss: 1.9973449965816805
Validation loss: 2.515179962045674

Epoch: 6| Step: 3
Training loss: 2.5568475486533107
Validation loss: 2.5229223790967854

Epoch: 6| Step: 4
Training loss: 2.351529244729557
Validation loss: 2.5169757998959477

Epoch: 6| Step: 5
Training loss: 2.5709300125549053
Validation loss: 2.518340079269332

Epoch: 6| Step: 6
Training loss: 1.9850181078144955
Validation loss: 2.519018927917571

Epoch: 6| Step: 7
Training loss: 3.361220593591587
Validation loss: 2.5103329102576235

Epoch: 6| Step: 8
Training loss: 3.0722948037791107
Validation loss: 2.51087805949743

Epoch: 6| Step: 9
Training loss: 2.7347418838688813
Validation loss: 2.513453238154447

Epoch: 6| Step: 10
Training loss: 2.683108978685716
Validation loss: 2.5264557465538604

Epoch: 6| Step: 11
Training loss: 2.413508280617983
Validation loss: 2.5114484758407722

Epoch: 6| Step: 12
Training loss: 2.65583385124796
Validation loss: 2.5053776175219205

Epoch: 6| Step: 13
Training loss: 4.303438701290134
Validation loss: 2.5109974162129287

Epoch: 52| Step: 0
Training loss: 2.6864916661948124
Validation loss: 2.5051107905471333

Epoch: 6| Step: 1
Training loss: 2.5430811609599187
Validation loss: 2.5169723144495126

Epoch: 6| Step: 2
Training loss: 2.590674265725533
Validation loss: 2.515533715667455

Epoch: 6| Step: 3
Training loss: 2.61299649499015
Validation loss: 2.513934372995597

Epoch: 6| Step: 4
Training loss: 2.9785751787079078
Validation loss: 2.5144791456758715

Epoch: 6| Step: 5
Training loss: 2.7949375709290227
Validation loss: 2.507183728193852

Epoch: 6| Step: 6
Training loss: 2.238398097851254
Validation loss: 2.518394238716354

Epoch: 6| Step: 7
Training loss: 2.7671041897209507
Validation loss: 2.51981881667484

Epoch: 6| Step: 8
Training loss: 3.138001518137305
Validation loss: 2.5177470628440073

Epoch: 6| Step: 9
Training loss: 2.6505546996929628
Validation loss: 2.5167333726355485

Epoch: 6| Step: 10
Training loss: 2.845442551181231
Validation loss: 2.5041188642241665

Epoch: 6| Step: 11
Training loss: 3.3539444433170655
Validation loss: 2.518256109107774

Epoch: 6| Step: 12
Training loss: 2.255696925799925
Validation loss: 2.5190178867960125

Epoch: 6| Step: 13
Training loss: 2.6678525751380824
Validation loss: 2.5129616391781044

Epoch: 53| Step: 0
Training loss: 3.1676294636632267
Validation loss: 2.5201664015851435

Epoch: 6| Step: 1
Training loss: 2.6150941590375525
Validation loss: 2.5119354711325546

Epoch: 6| Step: 2
Training loss: 2.59720519315834
Validation loss: 2.520803355933087

Epoch: 6| Step: 3
Training loss: 2.666218262960598
Validation loss: 2.5129379671106276

Epoch: 6| Step: 4
Training loss: 2.7784827535168497
Validation loss: 2.501225663265496

Epoch: 6| Step: 5
Training loss: 2.444413870080803
Validation loss: 2.5179985261362345

Epoch: 6| Step: 6
Training loss: 3.10665882267869
Validation loss: 2.519372037687299

Epoch: 6| Step: 7
Training loss: 3.8934911259155336
Validation loss: 2.511565708861632

Epoch: 6| Step: 8
Training loss: 1.8357941267156277
Validation loss: 2.50834928123281

Epoch: 6| Step: 9
Training loss: 3.0756999886077763
Validation loss: 2.5250495235078634

Epoch: 6| Step: 10
Training loss: 2.3041452578147297
Validation loss: 2.5265222655299806

Epoch: 6| Step: 11
Training loss: 2.559113194975174
Validation loss: 2.519239767247096

Epoch: 6| Step: 12
Training loss: 2.3078236077931735
Validation loss: 2.501186270907633

Epoch: 6| Step: 13
Training loss: 2.0459901484143193
Validation loss: 2.5163567916257463

Epoch: 54| Step: 0
Training loss: 2.559562115472376
Validation loss: 2.5156262361521797

Epoch: 6| Step: 1
Training loss: 2.7505852336648338
Validation loss: 2.5151058337211905

Epoch: 6| Step: 2
Training loss: 2.4657988473694434
Validation loss: 2.507841548419845

Epoch: 6| Step: 3
Training loss: 2.702514755956857
Validation loss: 2.5109699633332747

Epoch: 6| Step: 4
Training loss: 2.4952690182828574
Validation loss: 2.5205267256406487

Epoch: 6| Step: 5
Training loss: 2.6898001652625854
Validation loss: 2.5203724026763363

Epoch: 6| Step: 6
Training loss: 2.9018179621319393
Validation loss: 2.521760901257525

Epoch: 6| Step: 7
Training loss: 2.610516966414832
Validation loss: 2.512148887570281

Epoch: 6| Step: 8
Training loss: 2.7775008402633428
Validation loss: 2.5133876778678816

Epoch: 6| Step: 9
Training loss: 2.9170940267730754
Validation loss: 2.5065487504746438

Epoch: 6| Step: 10
Training loss: 2.1379962010577347
Validation loss: 2.516809603304545

Epoch: 6| Step: 11
Training loss: 2.9896042631437894
Validation loss: 2.524414310291475

Epoch: 6| Step: 12
Training loss: 3.2840331853381666
Validation loss: 2.500777895712083

Epoch: 6| Step: 13
Training loss: 2.8982532370674368
Validation loss: 2.5128131576402493

Epoch: 55| Step: 0
Training loss: 2.814452023740893
Validation loss: 2.520707012263454

Epoch: 6| Step: 1
Training loss: 3.126310302689676
Validation loss: 2.5050352661559803

Epoch: 6| Step: 2
Training loss: 2.085480829319519
Validation loss: 2.5145125643083115

Epoch: 6| Step: 3
Training loss: 3.56294863368932
Validation loss: 2.5168744358055686

Epoch: 6| Step: 4
Training loss: 2.586901159603533
Validation loss: 2.517282698874824

Epoch: 6| Step: 5
Training loss: 2.1447814906581226
Validation loss: 2.5248335406670113

Epoch: 6| Step: 6
Training loss: 2.252503168271088
Validation loss: 2.5089064223411213

Epoch: 6| Step: 7
Training loss: 2.8875755927689717
Validation loss: 2.5124437510643114

Epoch: 6| Step: 8
Training loss: 2.4387947947319732
Validation loss: 2.5154782736949426

Epoch: 6| Step: 9
Training loss: 2.975625839441602
Validation loss: 2.514209225356551

Epoch: 6| Step: 10
Training loss: 2.594763500336912
Validation loss: 2.5076788203876603

Epoch: 6| Step: 11
Training loss: 2.7705356944754915
Validation loss: 2.508688063539971

Epoch: 6| Step: 12
Training loss: 3.1274470094724394
Validation loss: 2.5130797901067425

Epoch: 6| Step: 13
Training loss: 2.1656426675359324
Validation loss: 2.5156637657692946

Epoch: 56| Step: 0
Training loss: 3.030418989968341
Validation loss: 2.509677389202734

Epoch: 6| Step: 1
Training loss: 2.7047745627280406
Validation loss: 2.4990574008291597

Epoch: 6| Step: 2
Training loss: 2.0468887445119406
Validation loss: 2.5230403084541506

Epoch: 6| Step: 3
Training loss: 2.664003254072247
Validation loss: 2.51433063751728

Epoch: 6| Step: 4
Training loss: 3.13864695949196
Validation loss: 2.5149163718308976

Epoch: 6| Step: 5
Training loss: 2.652983418383725
Validation loss: 2.502416092331152

Epoch: 6| Step: 6
Training loss: 3.2890740981090048
Validation loss: 2.5042159673948903

Epoch: 6| Step: 7
Training loss: 2.979678147875908
Validation loss: 2.507050938437352

Epoch: 6| Step: 8
Training loss: 2.16950903810059
Validation loss: 2.5096654549657336

Epoch: 6| Step: 9
Training loss: 2.220775378283953
Validation loss: 2.503024955830243

Epoch: 6| Step: 10
Training loss: 2.3854599550364535
Validation loss: 2.5169371307262307

Epoch: 6| Step: 11
Training loss: 3.3703329525160313
Validation loss: 2.5169054386756935

Epoch: 6| Step: 12
Training loss: 2.467134647395169
Validation loss: 2.4978999505551114

Epoch: 6| Step: 13
Training loss: 2.811039863491043
Validation loss: 2.5021109641396677

Epoch: 57| Step: 0
Training loss: 2.704941772990645
Validation loss: 2.5036310703787086

Epoch: 6| Step: 1
Training loss: 3.4608300323678787
Validation loss: 2.5023045516030162

Epoch: 6| Step: 2
Training loss: 3.6442816056982834
Validation loss: 2.5004189550407823

Epoch: 6| Step: 3
Training loss: 2.840469983931226
Validation loss: 2.515214824822061

Epoch: 6| Step: 4
Training loss: 2.858747569801622
Validation loss: 2.5130137222464017

Epoch: 6| Step: 5
Training loss: 2.126664015051804
Validation loss: 2.5150077325953255

Epoch: 6| Step: 6
Training loss: 2.5623373584771114
Validation loss: 2.50077261112385

Epoch: 6| Step: 7
Training loss: 3.2252380756358514
Validation loss: 2.508548246702374

Epoch: 6| Step: 8
Training loss: 2.2088660791158774
Validation loss: 2.5187133041343244

Epoch: 6| Step: 9
Training loss: 2.3852576545678073
Validation loss: 2.5101289362569204

Epoch: 6| Step: 10
Training loss: 2.4891055192600295
Validation loss: 2.4976132166632516

Epoch: 6| Step: 11
Training loss: 2.600951893491746
Validation loss: 2.517901446935988

Epoch: 6| Step: 12
Training loss: 1.3777871494119758
Validation loss: 2.5081011077352966

Epoch: 6| Step: 13
Training loss: 2.8422763904933763
Validation loss: 2.5065554102788137

Epoch: 58| Step: 0
Training loss: 2.4069734947162083
Validation loss: 2.5189706440531716

Epoch: 6| Step: 1
Training loss: 2.8913490831917934
Validation loss: 2.515176344153866

Epoch: 6| Step: 2
Training loss: 3.2713633956175707
Validation loss: 2.5144696383414553

Epoch: 6| Step: 3
Training loss: 3.7385952776769718
Validation loss: 2.5122396979242136

Epoch: 6| Step: 4
Training loss: 2.6532766417895837
Validation loss: 2.499853402115721

Epoch: 6| Step: 5
Training loss: 2.555305616162612
Validation loss: 2.507973243454075

Epoch: 6| Step: 6
Training loss: 2.090149587908771
Validation loss: 2.513691435179249

Epoch: 6| Step: 7
Training loss: 2.5150217790210476
Validation loss: 2.5140228009952854

Epoch: 6| Step: 8
Training loss: 2.6594409401021863
Validation loss: 2.4988533015352803

Epoch: 6| Step: 9
Training loss: 3.065665030339595
Validation loss: 2.5083697107656358

Epoch: 6| Step: 10
Training loss: 2.0845658153484354
Validation loss: 2.5004473019441575

Epoch: 6| Step: 11
Training loss: 3.0409715633348546
Validation loss: 2.508895367800757

Epoch: 6| Step: 12
Training loss: 1.8649424059772743
Validation loss: 2.5014544419549103

Epoch: 6| Step: 13
Training loss: 2.7444086453020162
Validation loss: 2.500295364200564

Epoch: 59| Step: 0
Training loss: 2.4701871913757896
Validation loss: 2.5167362889948923

Epoch: 6| Step: 1
Training loss: 2.9067118288025533
Validation loss: 2.503114663338648

Epoch: 6| Step: 2
Training loss: 3.240033199234402
Validation loss: 2.4938885755780302

Epoch: 6| Step: 3
Training loss: 2.2298473020200125
Validation loss: 2.502197790581705

Epoch: 6| Step: 4
Training loss: 3.0958277343316016
Validation loss: 2.5056800581507415

Epoch: 6| Step: 5
Training loss: 3.055692307465736
Validation loss: 2.5000207459194

Epoch: 6| Step: 6
Training loss: 2.9077840058551514
Validation loss: 2.508762332445252

Epoch: 6| Step: 7
Training loss: 2.569238130918241
Validation loss: 2.5117467131911497

Epoch: 6| Step: 8
Training loss: 3.0498667578437892
Validation loss: 2.510961323817592

Epoch: 6| Step: 9
Training loss: 2.778326062027223
Validation loss: 2.5037749185330127

Epoch: 6| Step: 10
Training loss: 2.459562662373704
Validation loss: 2.5037681586688576

Epoch: 6| Step: 11
Training loss: 2.737082574102589
Validation loss: 2.51774086386412

Epoch: 6| Step: 12
Training loss: 1.7541139475435445
Validation loss: 2.503659825311396

Epoch: 6| Step: 13
Training loss: 2.2875390304821037
Validation loss: 2.495243204711789

Epoch: 60| Step: 0
Training loss: 2.3559708447619654
Validation loss: 2.511787616847961

Epoch: 6| Step: 1
Training loss: 3.043827195334215
Validation loss: 2.505279148763744

Epoch: 6| Step: 2
Training loss: 2.310897890774162
Validation loss: 2.513539675854541

Epoch: 6| Step: 3
Training loss: 2.239941472242582
Validation loss: 2.5167435686734922

Epoch: 6| Step: 4
Training loss: 2.8673065742900246
Validation loss: 2.5034133958229634

Epoch: 6| Step: 5
Training loss: 2.7589062475111676
Validation loss: 2.5041160949260104

Epoch: 6| Step: 6
Training loss: 2.6638718701843147
Validation loss: 2.4986369313817254

Epoch: 6| Step: 7
Training loss: 2.9599098697033965
Validation loss: 2.508063533438398

Epoch: 6| Step: 8
Training loss: 2.569531539494796
Validation loss: 2.5016217765260125

Epoch: 6| Step: 9
Training loss: 3.2866863447713186
Validation loss: 2.5059815845375764

Epoch: 6| Step: 10
Training loss: 2.4924510469670413
Validation loss: 2.5012188616631303

Epoch: 6| Step: 11
Training loss: 2.8323240352425767
Validation loss: 2.51396182307648

Epoch: 6| Step: 12
Training loss: 2.503388587893831
Validation loss: 2.51136715803357

Epoch: 6| Step: 13
Training loss: 3.148712070504684
Validation loss: 2.4908167822609775

Epoch: 61| Step: 0
Training loss: 2.863545529189592
Validation loss: 2.5079688520954986

Epoch: 6| Step: 1
Training loss: 2.8317000412466347
Validation loss: 2.502852534231114

Epoch: 6| Step: 2
Training loss: 2.282699542478797
Validation loss: 2.511258181653047

Epoch: 6| Step: 3
Training loss: 2.3555541774257893
Validation loss: 2.5138337571877587

Epoch: 6| Step: 4
Training loss: 2.760119113839656
Validation loss: 2.5016434599945643

Epoch: 6| Step: 5
Training loss: 2.665350191679718
Validation loss: 2.5031187897575284

Epoch: 6| Step: 6
Training loss: 2.5674991690124536
Validation loss: 2.5063215113223087

Epoch: 6| Step: 7
Training loss: 3.03856225297188
Validation loss: 2.4998034984518234

Epoch: 6| Step: 8
Training loss: 2.325913165845559
Validation loss: 2.5159550473675045

Epoch: 6| Step: 9
Training loss: 2.9215340644904395
Validation loss: 2.505927129199771

Epoch: 6| Step: 10
Training loss: 2.550670393540085
Validation loss: 2.5152505055640337

Epoch: 6| Step: 11
Training loss: 2.9872909600452817
Validation loss: 2.514795623049566

Epoch: 6| Step: 12
Training loss: 3.226698754784211
Validation loss: 2.5049423872418095

Epoch: 6| Step: 13
Training loss: 2.042563987299275
Validation loss: 2.4968363238131217

Epoch: 62| Step: 0
Training loss: 2.9399903475025564
Validation loss: 2.5086175306719443

Epoch: 6| Step: 1
Training loss: 2.376702351063708
Validation loss: 2.50928362340557

Epoch: 6| Step: 2
Training loss: 3.0453477993480713
Validation loss: 2.5011659866711122

Epoch: 6| Step: 3
Training loss: 2.432743517927308
Validation loss: 2.4921284895980262

Epoch: 6| Step: 4
Training loss: 3.1213940987954594
Validation loss: 2.498577673144239

Epoch: 6| Step: 5
Training loss: 2.705263383491533
Validation loss: 2.5067537337252856

Epoch: 6| Step: 6
Training loss: 2.516855637821872
Validation loss: 2.501143824494073

Epoch: 6| Step: 7
Training loss: 2.3563497992712965
Validation loss: 2.505236537357497

Epoch: 6| Step: 8
Training loss: 2.772690707390584
Validation loss: 2.506111134994141

Epoch: 6| Step: 9
Training loss: 2.7862057199977084
Validation loss: 2.5104931630059464

Epoch: 6| Step: 10
Training loss: 2.7878529893927886
Validation loss: 2.504336312648687

Epoch: 6| Step: 11
Training loss: 2.4982793608831355
Validation loss: 2.49283782007102

Epoch: 6| Step: 12
Training loss: 3.1349913518807653
Validation loss: 2.5051063706333654

Epoch: 6| Step: 13
Training loss: 2.1522837109508393
Validation loss: 2.5098623978590013

Epoch: 63| Step: 0
Training loss: 2.759448120254346
Validation loss: 2.497347917056136

Epoch: 6| Step: 1
Training loss: 2.6503807298198665
Validation loss: 2.501091804823056

Epoch: 6| Step: 2
Training loss: 2.6397363194363037
Validation loss: 2.513466042793925

Epoch: 6| Step: 3
Training loss: 2.463757452409177
Validation loss: 2.519234029363639

Epoch: 6| Step: 4
Training loss: 2.6446145522099704
Validation loss: 2.5049873708108152

Epoch: 6| Step: 5
Training loss: 2.4167005821566696
Validation loss: 2.5070695052123395

Epoch: 6| Step: 6
Training loss: 2.7167579982671777
Validation loss: 2.501457652839275

Epoch: 6| Step: 7
Training loss: 3.094579720255972
Validation loss: 2.519498638690211

Epoch: 6| Step: 8
Training loss: 2.3236581847636586
Validation loss: 2.5155797521320142

Epoch: 6| Step: 9
Training loss: 2.5181422936893556
Validation loss: 2.5248945976902535

Epoch: 6| Step: 10
Training loss: 2.6796035086144565
Validation loss: 2.5265551311734944

Epoch: 6| Step: 11
Training loss: 2.7159729729151785
Validation loss: 2.512768298864771

Epoch: 6| Step: 12
Training loss: 3.624504976344682
Validation loss: 2.5014621130203563

Epoch: 6| Step: 13
Training loss: 2.2514770745743746
Validation loss: 2.5098397823470555

Epoch: 64| Step: 0
Training loss: 2.3880929939463402
Validation loss: 2.5153124480135842

Epoch: 6| Step: 1
Training loss: 2.2307248477922186
Validation loss: 2.521764485812449

Epoch: 6| Step: 2
Training loss: 3.121534333147335
Validation loss: 2.510476421886978

Epoch: 6| Step: 3
Training loss: 3.0354657303809875
Validation loss: 2.5039014481085116

Epoch: 6| Step: 4
Training loss: 2.196136754285618
Validation loss: 2.511720272841946

Epoch: 6| Step: 5
Training loss: 3.189176978486748
Validation loss: 2.4984637883171428

Epoch: 6| Step: 6
Training loss: 2.255867618694353
Validation loss: 2.519722462831139

Epoch: 6| Step: 7
Training loss: 3.09246583739325
Validation loss: 2.5147635732039255

Epoch: 6| Step: 8
Training loss: 2.969425967707859
Validation loss: 2.507116185876304

Epoch: 6| Step: 9
Training loss: 3.3388610464900386
Validation loss: 2.5147039059236906

Epoch: 6| Step: 10
Training loss: 2.3599883033979836
Validation loss: 2.510584012826442

Epoch: 6| Step: 11
Training loss: 2.31938116732214
Validation loss: 2.504834088293762

Epoch: 6| Step: 12
Training loss: 2.653608377408825
Validation loss: 2.502713303051923

Epoch: 6| Step: 13
Training loss: 1.7882411354002017
Validation loss: 2.5162965895504916

Epoch: 65| Step: 0
Training loss: 2.508997081835476
Validation loss: 2.5090016665538504

Epoch: 6| Step: 1
Training loss: 2.4168724323236375
Validation loss: 2.505283212778139

Epoch: 6| Step: 2
Training loss: 2.906815504614741
Validation loss: 2.499830742202876

Epoch: 6| Step: 3
Training loss: 2.702533458746087
Validation loss: 2.4970467823830207

Epoch: 6| Step: 4
Training loss: 2.7665610588170804
Validation loss: 2.510485447032569

Epoch: 6| Step: 5
Training loss: 3.1605284746308864
Validation loss: 2.5006660138277885

Epoch: 6| Step: 6
Training loss: 3.0806894221876706
Validation loss: 2.505246880982006

Epoch: 6| Step: 7
Training loss: 2.784114434137549
Validation loss: 2.502081645293448

Epoch: 6| Step: 8
Training loss: 2.588073033076179
Validation loss: 2.5054451801042417

Epoch: 6| Step: 9
Training loss: 2.5191523303970955
Validation loss: 2.497747311821715

Epoch: 6| Step: 10
Training loss: 2.8711611785236864
Validation loss: 2.4960156531111295

Epoch: 6| Step: 11
Training loss: 2.6361016349590893
Validation loss: 2.5017739744363743

Epoch: 6| Step: 12
Training loss: 2.2782533376621767
Validation loss: 2.5083853447802

Epoch: 6| Step: 13
Training loss: 2.465608360321407
Validation loss: 2.494266134475508

Epoch: 66| Step: 0
Training loss: 2.7623452604980065
Validation loss: 2.505619014302021

Epoch: 6| Step: 1
Training loss: 2.745365659473712
Validation loss: 2.4974666444572238

Epoch: 6| Step: 2
Training loss: 3.2636600405137766
Validation loss: 2.5112035263065957

Epoch: 6| Step: 3
Training loss: 2.1108497268194784
Validation loss: 2.510685360291175

Epoch: 6| Step: 4
Training loss: 2.8603128864959486
Validation loss: 2.5019393228490867

Epoch: 6| Step: 5
Training loss: 2.344984111122034
Validation loss: 2.505598486627036

Epoch: 6| Step: 6
Training loss: 2.437547536533162
Validation loss: 2.4936672943634144

Epoch: 6| Step: 7
Training loss: 2.74531693954847
Validation loss: 2.501266425344183

Epoch: 6| Step: 8
Training loss: 2.5912434059570737
Validation loss: 2.5037266386545682

Epoch: 6| Step: 9
Training loss: 3.077852808347253
Validation loss: 2.498835618597947

Epoch: 6| Step: 10
Training loss: 2.937834213398959
Validation loss: 2.5035404577210185

Epoch: 6| Step: 11
Training loss: 2.2149473028178917
Validation loss: 2.4978311503548887

Epoch: 6| Step: 12
Training loss: 3.0767949517790374
Validation loss: 2.5078110064752313

Epoch: 6| Step: 13
Training loss: 2.2405600140669613
Validation loss: 2.5131814878002703

Epoch: 67| Step: 0
Training loss: 2.6726296234811664
Validation loss: 2.5075138806045065

Epoch: 6| Step: 1
Training loss: 2.678770036146286
Validation loss: 2.512490552275205

Epoch: 6| Step: 2
Training loss: 2.3484652072797387
Validation loss: 2.513349268676075

Epoch: 6| Step: 3
Training loss: 3.3068856217843345
Validation loss: 2.516398671721059

Epoch: 6| Step: 4
Training loss: 2.7218247488925664
Validation loss: 2.506614369459615

Epoch: 6| Step: 5
Training loss: 3.1524880528658494
Validation loss: 2.513801502331615

Epoch: 6| Step: 6
Training loss: 2.401803205510495
Validation loss: 2.5061495743051614

Epoch: 6| Step: 7
Training loss: 2.9140158641857243
Validation loss: 2.5105023759859755

Epoch: 6| Step: 8
Training loss: 2.0288614167499133
Validation loss: 2.4995824834366864

Epoch: 6| Step: 9
Training loss: 2.7132795699070704
Validation loss: 2.5133070746006156

Epoch: 6| Step: 10
Training loss: 2.4986242323535555
Validation loss: 2.506193847780062

Epoch: 6| Step: 11
Training loss: 2.85180846943228
Validation loss: 2.504161395345047

Epoch: 6| Step: 12
Training loss: 2.391269771416421
Validation loss: 2.493572925884183

Epoch: 6| Step: 13
Training loss: 2.8255774051376323
Validation loss: 2.504158621998912

Epoch: 68| Step: 0
Training loss: 2.3685745858738874
Validation loss: 2.5098491917975836

Epoch: 6| Step: 1
Training loss: 3.009388854885195
Validation loss: 2.506932368384962

Epoch: 6| Step: 2
Training loss: 3.159819444737285
Validation loss: 2.4968907515333547

Epoch: 6| Step: 3
Training loss: 2.610647473757951
Validation loss: 2.494224520011639

Epoch: 6| Step: 4
Training loss: 2.8450939649675244
Validation loss: 2.5223439354286046

Epoch: 6| Step: 5
Training loss: 1.849787251379523
Validation loss: 2.5096967721295673

Epoch: 6| Step: 6
Training loss: 2.5698510773255614
Validation loss: 2.501674683900091

Epoch: 6| Step: 7
Training loss: 2.6646573921114105
Validation loss: 2.4986826676634837

Epoch: 6| Step: 8
Training loss: 2.2451044441515244
Validation loss: 2.5085979033377415

Epoch: 6| Step: 9
Training loss: 2.4786547177652443
Validation loss: 2.4980174561144186

Epoch: 6| Step: 10
Training loss: 2.7445016860998432
Validation loss: 2.5170013488246776

Epoch: 6| Step: 11
Training loss: 2.7600094956773695
Validation loss: 2.5130841842658245

Epoch: 6| Step: 12
Training loss: 2.8939677937158272
Validation loss: 2.497774168991589

Epoch: 6| Step: 13
Training loss: 3.4945620116925173
Validation loss: 2.5145916659442613

Epoch: 69| Step: 0
Training loss: 3.7829462455542413
Validation loss: 2.5059447702807907

Epoch: 6| Step: 1
Training loss: 2.774541071153494
Validation loss: 2.516252919705473

Epoch: 6| Step: 2
Training loss: 2.3511066184975467
Validation loss: 2.507214096796237

Epoch: 6| Step: 3
Training loss: 2.3479379494443453
Validation loss: 2.511459359391637

Epoch: 6| Step: 4
Training loss: 3.2009603489830547
Validation loss: 2.5185475234989387

Epoch: 6| Step: 5
Training loss: 2.443062719301216
Validation loss: 2.5133257665226756

Epoch: 6| Step: 6
Training loss: 2.4506493972851984
Validation loss: 2.5113752969763765

Epoch: 6| Step: 7
Training loss: 2.8622762001205206
Validation loss: 2.5070119045068235

Epoch: 6| Step: 8
Training loss: 2.9332291418413536
Validation loss: 2.51505049036431

Epoch: 6| Step: 9
Training loss: 2.4066218299422815
Validation loss: 2.501025221427455

Epoch: 6| Step: 10
Training loss: 2.4386841269727166
Validation loss: 2.4910311517685972

Epoch: 6| Step: 11
Training loss: 2.4015000265082938
Validation loss: 2.511925203528302

Epoch: 6| Step: 12
Training loss: 2.3970041372035116
Validation loss: 2.501489218288042

Epoch: 6| Step: 13
Training loss: 2.4006778554502923
Validation loss: 2.5110910522778287

Epoch: 70| Step: 0
Training loss: 2.4657270055056646
Validation loss: 2.498499812937794

Epoch: 6| Step: 1
Training loss: 3.0837730059869215
Validation loss: 2.5088655386403698

Epoch: 6| Step: 2
Training loss: 2.846503632795601
Validation loss: 2.509029503696787

Epoch: 6| Step: 3
Training loss: 2.5641429565378173
Validation loss: 2.5004388403533264

Epoch: 6| Step: 4
Training loss: 2.4565914470004135
Validation loss: 2.508625039829066

Epoch: 6| Step: 5
Training loss: 2.9435126271690617
Validation loss: 2.4955282744676404

Epoch: 6| Step: 6
Training loss: 2.477869886084272
Validation loss: 2.49336900792498

Epoch: 6| Step: 7
Training loss: 3.053810715760771
Validation loss: 2.502925470634684

Epoch: 6| Step: 8
Training loss: 2.7610665378089854
Validation loss: 2.508923135618274

Epoch: 6| Step: 9
Training loss: 2.1830195728076354
Validation loss: 2.511575727346342

Epoch: 6| Step: 10
Training loss: 2.3347126993528104
Validation loss: 2.505612884563323

Epoch: 6| Step: 11
Training loss: 2.735462604571801
Validation loss: 2.500885730652421

Epoch: 6| Step: 12
Training loss: 2.5580093298735194
Validation loss: 2.5087791590877804

Epoch: 6| Step: 13
Training loss: 3.0829779617754274
Validation loss: 2.505540294465983

Epoch: 71| Step: 0
Training loss: 3.251341322892633
Validation loss: 2.5059738608109754

Epoch: 6| Step: 1
Training loss: 2.9497997797892532
Validation loss: 2.5119184793754847

Epoch: 6| Step: 2
Training loss: 2.510109488238379
Validation loss: 2.5016893800804545

Epoch: 6| Step: 3
Training loss: 2.1810542371286026
Validation loss: 2.513273364528033

Epoch: 6| Step: 4
Training loss: 2.3951876115683706
Validation loss: 2.5000919560984105

Epoch: 6| Step: 5
Training loss: 2.5618087952829085
Validation loss: 2.51149392318264

Epoch: 6| Step: 6
Training loss: 3.1535014658401783
Validation loss: 2.508929980708483

Epoch: 6| Step: 7
Training loss: 2.9780482791653244
Validation loss: 2.50901284017327

Epoch: 6| Step: 8
Training loss: 3.074140884596008
Validation loss: 2.5106226905005182

Epoch: 6| Step: 9
Training loss: 2.522817813145205
Validation loss: 2.508619481542498

Epoch: 6| Step: 10
Training loss: 2.5490572888479015
Validation loss: 2.5032428341688022

Epoch: 6| Step: 11
Training loss: 2.994236177535973
Validation loss: 2.4933286858444546

Epoch: 6| Step: 12
Training loss: 2.056467771738111
Validation loss: 2.51172622641021

Epoch: 6| Step: 13
Training loss: 1.8271033537872268
Validation loss: 2.5197372836869514

Epoch: 72| Step: 0
Training loss: 2.794223914177648
Validation loss: 2.512226966630445

Epoch: 6| Step: 1
Training loss: 2.4356735429045044
Validation loss: 2.5116578978275417

Epoch: 6| Step: 2
Training loss: 3.1639417837215036
Validation loss: 2.504418823021243

Epoch: 6| Step: 3
Training loss: 2.6382979573496566
Validation loss: 2.493513961634695

Epoch: 6| Step: 4
Training loss: 2.6580677768800474
Validation loss: 2.503928958009866

Epoch: 6| Step: 5
Training loss: 2.587261310569994
Validation loss: 2.512592853358251

Epoch: 6| Step: 6
Training loss: 2.693393455328482
Validation loss: 2.5067026465985807

Epoch: 6| Step: 7
Training loss: 3.3560172399866914
Validation loss: 2.5024468425188457

Epoch: 6| Step: 8
Training loss: 1.9931304495190596
Validation loss: 2.5158373055804777

Epoch: 6| Step: 9
Training loss: 2.603907813876621
Validation loss: 2.4892329716336374

Epoch: 6| Step: 10
Training loss: 2.414420585863593
Validation loss: 2.5096091948413726

Epoch: 6| Step: 11
Training loss: 2.5257719125288953
Validation loss: 2.4992435151657784

Epoch: 6| Step: 12
Training loss: 3.0353623643013674
Validation loss: 2.5011832995181353

Epoch: 6| Step: 13
Training loss: 1.9348697652040514
Validation loss: 2.505470443466088

Epoch: 73| Step: 0
Training loss: 3.1713307482190514
Validation loss: 2.496628015164977

Epoch: 6| Step: 1
Training loss: 2.7117896595802553
Validation loss: 2.497107445466682

Epoch: 6| Step: 2
Training loss: 2.897025615311588
Validation loss: 2.4925807637840816

Epoch: 6| Step: 3
Training loss: 2.48885694518291
Validation loss: 2.500245530879345

Epoch: 6| Step: 4
Training loss: 3.248010906999813
Validation loss: 2.4933235170775343

Epoch: 6| Step: 5
Training loss: 3.4097178593590596
Validation loss: 2.5077871958288145

Epoch: 6| Step: 6
Training loss: 2.700627225854191
Validation loss: 2.5023514425582403

Epoch: 6| Step: 7
Training loss: 2.3399197624991506
Validation loss: 2.5053111633791585

Epoch: 6| Step: 8
Training loss: 2.776186931500037
Validation loss: 2.487312629986216

Epoch: 6| Step: 9
Training loss: 2.576996434894267
Validation loss: 2.49431988854715

Epoch: 6| Step: 10
Training loss: 1.842780294643111
Validation loss: 2.4980680835581746

Epoch: 6| Step: 11
Training loss: 1.8632854085751878
Validation loss: 2.50004239405301

Epoch: 6| Step: 12
Training loss: 2.239506730536473
Validation loss: 2.486515785466802

Epoch: 6| Step: 13
Training loss: 2.701754801554158
Validation loss: 2.5047877100175433

Epoch: 74| Step: 0
Training loss: 2.5823468406438552
Validation loss: 2.514128956885461

Epoch: 6| Step: 1
Training loss: 2.8780604120187423
Validation loss: 2.506351498617455

Epoch: 6| Step: 2
Training loss: 2.7469097460739715
Validation loss: 2.501497162879809

Epoch: 6| Step: 3
Training loss: 2.3803733473547024
Validation loss: 2.5064876096487168

Epoch: 6| Step: 4
Training loss: 2.9464785749147473
Validation loss: 2.498348336522976

Epoch: 6| Step: 5
Training loss: 2.7328739951070418
Validation loss: 2.502233976597548

Epoch: 6| Step: 6
Training loss: 1.8354988385734323
Validation loss: 2.5061581137936995

Epoch: 6| Step: 7
Training loss: 3.3366535499256504
Validation loss: 2.492599728381152

Epoch: 6| Step: 8
Training loss: 2.3632515897544746
Validation loss: 2.515635408932682

Epoch: 6| Step: 9
Training loss: 3.1938586670068
Validation loss: 2.507061444322294

Epoch: 6| Step: 10
Training loss: 2.7052420556149452
Validation loss: 2.5007578244688444

Epoch: 6| Step: 11
Training loss: 3.0487355347087264
Validation loss: 2.5142404267839784

Epoch: 6| Step: 12
Training loss: 2.0666271877619877
Validation loss: 2.4969537428741724

Epoch: 6| Step: 13
Training loss: 1.8743947005755037
Validation loss: 2.4900764769477552

Epoch: 75| Step: 0
Training loss: 2.972993247621466
Validation loss: 2.5022671253934305

Epoch: 6| Step: 1
Training loss: 2.976056874500834
Validation loss: 2.5076999582190944

Epoch: 6| Step: 2
Training loss: 2.697806799184537
Validation loss: 2.4953460207621623

Epoch: 6| Step: 3
Training loss: 2.124201231782881
Validation loss: 2.5028201214666965

Epoch: 6| Step: 4
Training loss: 3.2686624956544605
Validation loss: 2.509983512658561

Epoch: 6| Step: 5
Training loss: 2.575059397484596
Validation loss: 2.4944877829066026

Epoch: 6| Step: 6
Training loss: 3.2954515032619676
Validation loss: 2.493555928260153

Epoch: 6| Step: 7
Training loss: 2.821819462868624
Validation loss: 2.4851218099668326

Epoch: 6| Step: 8
Training loss: 2.600401931653305
Validation loss: 2.5033118051551657

Epoch: 6| Step: 9
Training loss: 1.6508148551008175
Validation loss: 2.4824211577775586

Epoch: 6| Step: 10
Training loss: 2.941827062569187
Validation loss: 2.5061607151198952

Epoch: 6| Step: 11
Training loss: 2.227508879193249
Validation loss: 2.4906165907195676

Epoch: 6| Step: 12
Training loss: 2.210090825557709
Validation loss: 2.497430477646055

Epoch: 6| Step: 13
Training loss: 2.517028322402262
Validation loss: 2.501140291360382

Epoch: 76| Step: 0
Training loss: 2.573036674964601
Validation loss: 2.5027981511425543

Epoch: 6| Step: 1
Training loss: 3.342592983963993
Validation loss: 2.5086556158056075

Epoch: 6| Step: 2
Training loss: 2.866609187621868
Validation loss: 2.499303571029748

Epoch: 6| Step: 3
Training loss: 3.072387615287065
Validation loss: 2.5067697101915196

Epoch: 6| Step: 4
Training loss: 2.175583561626205
Validation loss: 2.497014518073168

Epoch: 6| Step: 5
Training loss: 2.568454523100915
Validation loss: 2.5096072600631425

Epoch: 6| Step: 6
Training loss: 2.2300026535223667
Validation loss: 2.5073270698802186

Epoch: 6| Step: 7
Training loss: 2.4097015594954825
Validation loss: 2.508815996640521

Epoch: 6| Step: 8
Training loss: 1.9367389414766902
Validation loss: 2.5088020600624823

Epoch: 6| Step: 9
Training loss: 2.669630747775387
Validation loss: 2.5067311453931844

Epoch: 6| Step: 10
Training loss: 2.488443174737757
Validation loss: 2.5065993452124635

Epoch: 6| Step: 11
Training loss: 3.039849108414546
Validation loss: 2.513364182193664

Epoch: 6| Step: 12
Training loss: 3.2049870730896677
Validation loss: 2.4945127214904352

Epoch: 6| Step: 13
Training loss: 2.0926195195746486
Validation loss: 2.5170127145719685

Epoch: 77| Step: 0
Training loss: 2.420088767638392
Validation loss: 2.5043463395806245

Epoch: 6| Step: 1
Training loss: 3.4768761654059337
Validation loss: 2.51112431385895

Epoch: 6| Step: 2
Training loss: 2.5094913555451646
Validation loss: 2.5097347550815705

Epoch: 6| Step: 3
Training loss: 2.6023084699380243
Validation loss: 2.5001500874248554

Epoch: 6| Step: 4
Training loss: 2.490590794805849
Validation loss: 2.522270805361457

Epoch: 6| Step: 5
Training loss: 2.453863239366829
Validation loss: 2.507950412598775

Epoch: 6| Step: 6
Training loss: 2.7478997273148367
Validation loss: 2.5053093593317675

Epoch: 6| Step: 7
Training loss: 2.7911030973871496
Validation loss: 2.5115546154994877

Epoch: 6| Step: 8
Training loss: 2.36628751359273
Validation loss: 2.5050736789938277

Epoch: 6| Step: 9
Training loss: 2.274520982888292
Validation loss: 2.5120060833122575

Epoch: 6| Step: 10
Training loss: 2.5119841392405124
Validation loss: 2.4961760290712443

Epoch: 6| Step: 11
Training loss: 3.3505542012031673
Validation loss: 2.5092275805124866

Epoch: 6| Step: 12
Training loss: 2.546045835359598
Validation loss: 2.5134794848412874

Epoch: 6| Step: 13
Training loss: 2.56900287877772
Validation loss: 2.5127481458739176

Epoch: 78| Step: 0
Training loss: 2.814160513772772
Validation loss: 2.490502483903509

Epoch: 6| Step: 1
Training loss: 1.8448847495371377
Validation loss: 2.502520579552517

Epoch: 6| Step: 2
Training loss: 2.7206664072641242
Validation loss: 2.509881239026433

Epoch: 6| Step: 3
Training loss: 2.389328548968725
Validation loss: 2.5055996540580106

Epoch: 6| Step: 4
Training loss: 2.7943327020845183
Validation loss: 2.5034237172827516

Epoch: 6| Step: 5
Training loss: 2.3997125373981767
Validation loss: 2.5076179908147775

Epoch: 6| Step: 6
Training loss: 2.4492883505050353
Validation loss: 2.505063569008977

Epoch: 6| Step: 7
Training loss: 3.1577495374258677
Validation loss: 2.5059913614114016

Epoch: 6| Step: 8
Training loss: 2.6410735161344814
Validation loss: 2.5072526623460725

Epoch: 6| Step: 9
Training loss: 3.369597738464843
Validation loss: 2.5004360474991767

Epoch: 6| Step: 10
Training loss: 2.5336891949155653
Validation loss: 2.511207468946951

Epoch: 6| Step: 11
Training loss: 2.7135238402812867
Validation loss: 2.4958090529858983

Epoch: 6| Step: 12
Training loss: 2.7815810445868694
Validation loss: 2.5028915398205314

Epoch: 6| Step: 13
Training loss: 1.9904988630684906
Validation loss: 2.5066885975329103

Epoch: 79| Step: 0
Training loss: 1.5183577921991365
Validation loss: 2.498223437478566

Epoch: 6| Step: 1
Training loss: 3.18592571202109
Validation loss: 2.487880887911706

Epoch: 6| Step: 2
Training loss: 2.5058110411599324
Validation loss: 2.5022954626297382

Epoch: 6| Step: 3
Training loss: 2.399154108705169
Validation loss: 2.4943851483388544

Epoch: 6| Step: 4
Training loss: 2.8072747753156504
Validation loss: 2.5001827870478275

Epoch: 6| Step: 5
Training loss: 3.1190713720689462
Validation loss: 2.502527367372746

Epoch: 6| Step: 6
Training loss: 1.913143388821179
Validation loss: 2.4949391516036625

Epoch: 6| Step: 7
Training loss: 2.75928749645595
Validation loss: 2.501777548176617

Epoch: 6| Step: 8
Training loss: 2.9296285801366886
Validation loss: 2.502093141313934

Epoch: 6| Step: 9
Training loss: 2.884208527262783
Validation loss: 2.510889812357422

Epoch: 6| Step: 10
Training loss: 3.2129197139640615
Validation loss: 2.5028922916357477

Epoch: 6| Step: 11
Training loss: 1.8333183923748282
Validation loss: 2.4899159722091193

Epoch: 6| Step: 12
Training loss: 2.757165070958869
Validation loss: 2.504323640473804

Epoch: 6| Step: 13
Training loss: 2.8872426632573167
Validation loss: 2.506918128352926

Epoch: 80| Step: 0
Training loss: 1.9801512093074614
Validation loss: 2.5034779608262414

Epoch: 6| Step: 1
Training loss: 3.0329550440846424
Validation loss: 2.4956185616833246

Epoch: 6| Step: 2
Training loss: 2.4142626830620415
Validation loss: 2.4910759460775553

Epoch: 6| Step: 3
Training loss: 2.839292952947309
Validation loss: 2.499936771618713

Epoch: 6| Step: 4
Training loss: 2.046708777281283
Validation loss: 2.5019448181021104

Epoch: 6| Step: 5
Training loss: 3.198397240993346
Validation loss: 2.4939323430384577

Epoch: 6| Step: 6
Training loss: 2.2099028953519126
Validation loss: 2.5155479375018577

Epoch: 6| Step: 7
Training loss: 2.370892737727672
Validation loss: 2.49419715695157

Epoch: 6| Step: 8
Training loss: 2.8937436987394274
Validation loss: 2.5011598747185793

Epoch: 6| Step: 9
Training loss: 2.4399906051955167
Validation loss: 2.4903434344447772

Epoch: 6| Step: 10
Training loss: 2.8174672661193947
Validation loss: 2.4855867292938814

Epoch: 6| Step: 11
Training loss: 3.022947128706776
Validation loss: 2.499213524646439

Epoch: 6| Step: 12
Training loss: 2.216511201306589
Validation loss: 2.4951320363513507

Epoch: 6| Step: 13
Training loss: 3.856769995353379
Validation loss: 2.4906258051721664

Epoch: 81| Step: 0
Training loss: 2.149208734975019
Validation loss: 2.5106635307818084

Epoch: 6| Step: 1
Training loss: 3.950240337930971
Validation loss: 2.4970597348061006

Epoch: 6| Step: 2
Training loss: 2.7145258216494033
Validation loss: 2.4927591902613253

Epoch: 6| Step: 3
Training loss: 2.0924421182554878
Validation loss: 2.5148801338396196

Epoch: 6| Step: 4
Training loss: 2.7956678459965807
Validation loss: 2.4890381754253665

Epoch: 6| Step: 5
Training loss: 2.6359064503973926
Validation loss: 2.4942691192443935

Epoch: 6| Step: 6
Training loss: 2.4642683466897575
Validation loss: 2.5000746767109336

Epoch: 6| Step: 7
Training loss: 1.9195035243875194
Validation loss: 2.5111303137602423

Epoch: 6| Step: 8
Training loss: 2.493091096568634
Validation loss: 2.500109052843217

Epoch: 6| Step: 9
Training loss: 2.38799704924997
Validation loss: 2.5034692831671066

Epoch: 6| Step: 10
Training loss: 2.654262831626101
Validation loss: 2.4983397498173554

Epoch: 6| Step: 11
Training loss: 2.929723632589684
Validation loss: 2.5024147799896412

Epoch: 6| Step: 12
Training loss: 2.5054620203273354
Validation loss: 2.501725005739183

Epoch: 6| Step: 13
Training loss: 3.1309926366972256
Validation loss: 2.4868834499620736

Epoch: 82| Step: 0
Training loss: 2.8645383149279797
Validation loss: 2.4932516549927035

Epoch: 6| Step: 1
Training loss: 2.77702173010649
Validation loss: 2.494278768328187

Epoch: 6| Step: 2
Training loss: 2.9574940166912675
Validation loss: 2.484379189533466

Epoch: 6| Step: 3
Training loss: 2.8714818575374115
Validation loss: 2.494444040608015

Epoch: 6| Step: 4
Training loss: 2.343467797138067
Validation loss: 2.488834313908501

Epoch: 6| Step: 5
Training loss: 2.3662357242433703
Validation loss: 2.498221197314643

Epoch: 6| Step: 6
Training loss: 2.7576206562002317
Validation loss: 2.495992365718998

Epoch: 6| Step: 7
Training loss: 3.0815387520891964
Validation loss: 2.5030204554168316

Epoch: 6| Step: 8
Training loss: 2.406512159458291
Validation loss: 2.4998865717105274

Epoch: 6| Step: 9
Training loss: 2.7591386151613624
Validation loss: 2.509981394320773

Epoch: 6| Step: 10
Training loss: 2.1484376109730086
Validation loss: 2.4936307187897677

Epoch: 6| Step: 11
Training loss: 2.496015616135775
Validation loss: 2.5144157583492355

Epoch: 6| Step: 12
Training loss: 2.905928727307068
Validation loss: 2.5085336898353847

Epoch: 6| Step: 13
Training loss: 2.2610843803185796
Validation loss: 2.5014318272916065

Epoch: 83| Step: 0
Training loss: 3.0458005918177222
Validation loss: 2.507190512591984

Epoch: 6| Step: 1
Training loss: 2.2713695441336856
Validation loss: 2.5061907994708714

Epoch: 6| Step: 2
Training loss: 2.6658283545147583
Validation loss: 2.5088978211904975

Epoch: 6| Step: 3
Training loss: 1.982824605990489
Validation loss: 2.5053325550048644

Epoch: 6| Step: 4
Training loss: 2.392125375689744
Validation loss: 2.4974445556957603

Epoch: 6| Step: 5
Training loss: 2.3801323498062024
Validation loss: 2.5069726951032307

Epoch: 6| Step: 6
Training loss: 2.6583776591879547
Validation loss: 2.505401387627088

Epoch: 6| Step: 7
Training loss: 3.2997380701787695
Validation loss: 2.5070972840495545

Epoch: 6| Step: 8
Training loss: 2.5830110430922613
Validation loss: 2.5090073864559574

Epoch: 6| Step: 9
Training loss: 2.569816750253374
Validation loss: 2.503293332378299

Epoch: 6| Step: 10
Training loss: 3.42034961720381
Validation loss: 2.4902575762297454

Epoch: 6| Step: 11
Training loss: 2.6316484090772883
Validation loss: 2.495729422807624

Epoch: 6| Step: 12
Training loss: 2.6053465853165028
Validation loss: 2.4961610965648524

Epoch: 6| Step: 13
Training loss: 2.2342450297508347
Validation loss: 2.501900820900938

Epoch: 84| Step: 0
Training loss: 3.113637331865612
Validation loss: 2.5117781779157107

Epoch: 6| Step: 1
Training loss: 2.838584148310741
Validation loss: 2.500530340486154

Epoch: 6| Step: 2
Training loss: 3.24652544770636
Validation loss: 2.5127474908709457

Epoch: 6| Step: 3
Training loss: 2.4792585168915124
Validation loss: 2.4970353770905525

Epoch: 6| Step: 4
Training loss: 2.086191226229624
Validation loss: 2.495296602806396

Epoch: 6| Step: 5
Training loss: 2.2818350890782573
Validation loss: 2.501652052781728

Epoch: 6| Step: 6
Training loss: 1.9863921598692231
Validation loss: 2.5091002722442837

Epoch: 6| Step: 7
Training loss: 2.7740408227745457
Validation loss: 2.496781574551665

Epoch: 6| Step: 8
Training loss: 2.49746136518042
Validation loss: 2.5185181893587685

Epoch: 6| Step: 9
Training loss: 2.150026268022332
Validation loss: 2.5022772825350956

Epoch: 6| Step: 10
Training loss: 2.7073965555508837
Validation loss: 2.497265318833038

Epoch: 6| Step: 11
Training loss: 2.816894150375364
Validation loss: 2.5068111348062976

Epoch: 6| Step: 12
Training loss: 3.1063645708227474
Validation loss: 2.4928436829867535

Epoch: 6| Step: 13
Training loss: 2.7183173701388483
Validation loss: 2.5105768996026363

Epoch: 85| Step: 0
Training loss: 2.3210948305952446
Validation loss: 2.5110919899990964

Epoch: 6| Step: 1
Training loss: 2.5579491189067407
Validation loss: 2.4881990751147605

Epoch: 6| Step: 2
Training loss: 2.3335031947115485
Validation loss: 2.515207086640236

Epoch: 6| Step: 3
Training loss: 2.8799997062153135
Validation loss: 2.4996057102028746

Epoch: 6| Step: 4
Training loss: 3.077217549208019
Validation loss: 2.49908278056996

Epoch: 6| Step: 5
Training loss: 2.937074346342357
Validation loss: 2.5127023687131635

Epoch: 6| Step: 6
Training loss: 2.2368785996899736
Validation loss: 2.5057679425972794

Epoch: 6| Step: 7
Training loss: 3.09974521082125
Validation loss: 2.5138010250529077

Epoch: 6| Step: 8
Training loss: 2.3826852232913636
Validation loss: 2.512477406964598

Epoch: 6| Step: 9
Training loss: 3.2497153524310667
Validation loss: 2.516626431692855

Epoch: 6| Step: 10
Training loss: 2.5906686519170834
Validation loss: 2.510404813896189

Epoch: 6| Step: 11
Training loss: 2.124686274089816
Validation loss: 2.503986205771238

Epoch: 6| Step: 12
Training loss: 2.523759850855473
Validation loss: 2.510558800921647

Epoch: 6| Step: 13
Training loss: 2.5277855794970203
Validation loss: 2.520114226264798

Epoch: 86| Step: 0
Training loss: 2.843481030162938
Validation loss: 2.490368254969721

Epoch: 6| Step: 1
Training loss: 2.873808738370368
Validation loss: 2.49808824824939

Epoch: 6| Step: 2
Training loss: 2.797601530876319
Validation loss: 2.5121533558128264

Epoch: 6| Step: 3
Training loss: 2.660641260507372
Validation loss: 2.5028081186812217

Epoch: 6| Step: 4
Training loss: 2.2742782034616438
Validation loss: 2.4990799867132583

Epoch: 6| Step: 5
Training loss: 2.5055248248275546
Validation loss: 2.503678811454779

Epoch: 6| Step: 6
Training loss: 2.223761794781082
Validation loss: 2.5043088655725723

Epoch: 6| Step: 7
Training loss: 2.4826531351269088
Validation loss: 2.5016376848256767

Epoch: 6| Step: 8
Training loss: 2.400928508439333
Validation loss: 2.504166644116866

Epoch: 6| Step: 9
Training loss: 2.714274262999278
Validation loss: 2.4978781098913014

Epoch: 6| Step: 10
Training loss: 3.0486222954624314
Validation loss: 2.498895319041097

Epoch: 6| Step: 11
Training loss: 2.9890229943910662
Validation loss: 2.5058026953856634

Epoch: 6| Step: 12
Training loss: 2.589300728740287
Validation loss: 2.4987493206621734

Epoch: 6| Step: 13
Training loss: 2.3211424913299425
Validation loss: 2.494434340776322

Epoch: 87| Step: 0
Training loss: 2.706234769359837
Validation loss: 2.495552434245446

Epoch: 6| Step: 1
Training loss: 2.6807835953540953
Validation loss: 2.504327017611095

Epoch: 6| Step: 2
Training loss: 2.9164464776621344
Validation loss: 2.506687028679895

Epoch: 6| Step: 3
Training loss: 2.907122409275992
Validation loss: 2.520200149663129

Epoch: 6| Step: 4
Training loss: 2.561041347034343
Validation loss: 2.499041681273932

Epoch: 6| Step: 5
Training loss: 3.0169377607349537
Validation loss: 2.502683888826428

Epoch: 6| Step: 6
Training loss: 2.488425833006339
Validation loss: 2.5131553338895456

Epoch: 6| Step: 7
Training loss: 2.174911900632459
Validation loss: 2.497349121193421

Epoch: 6| Step: 8
Training loss: 2.5100106086354788
Validation loss: 2.4898079957704518

Epoch: 6| Step: 9
Training loss: 2.8489861542193555
Validation loss: 2.505182168158047

Epoch: 6| Step: 10
Training loss: 2.3400232822531524
Validation loss: 2.500753336377809

Epoch: 6| Step: 11
Training loss: 2.689740156649063
Validation loss: 2.4903395689224865

Epoch: 6| Step: 12
Training loss: 2.339002556755818
Validation loss: 2.5033218269738575

Epoch: 6| Step: 13
Training loss: 3.044579056581534
Validation loss: 2.5024912593586834

Epoch: 88| Step: 0
Training loss: 2.7700684622281284
Validation loss: 2.499818113334922

Epoch: 6| Step: 1
Training loss: 2.2652345518219668
Validation loss: 2.50576244242827

Epoch: 6| Step: 2
Training loss: 2.3189246140202644
Validation loss: 2.5159133259797284

Epoch: 6| Step: 3
Training loss: 2.163152510262235
Validation loss: 2.4979785447803513

Epoch: 6| Step: 4
Training loss: 3.047650517289853
Validation loss: 2.510223637231837

Epoch: 6| Step: 5
Training loss: 2.5859123297904087
Validation loss: 2.505704333366844

Epoch: 6| Step: 6
Training loss: 2.492204719890548
Validation loss: 2.4960651882962104

Epoch: 6| Step: 7
Training loss: 2.3812592994328137
Validation loss: 2.5094515474076444

Epoch: 6| Step: 8
Training loss: 2.40683699544908
Validation loss: 2.5111157014181527

Epoch: 6| Step: 9
Training loss: 2.532568035059151
Validation loss: 2.5071751952661416

Epoch: 6| Step: 10
Training loss: 3.1019509790458986
Validation loss: 2.513608046605236

Epoch: 6| Step: 11
Training loss: 2.8990150554854233
Validation loss: 2.5123204191113855

Epoch: 6| Step: 12
Training loss: 3.000177378179015
Validation loss: 2.509310805607166

Epoch: 6| Step: 13
Training loss: 2.9262254935390892
Validation loss: 2.509917118158699

Epoch: 89| Step: 0
Training loss: 2.777142009034159
Validation loss: 2.50263461986445

Epoch: 6| Step: 1
Training loss: 2.8011560335617025
Validation loss: 2.501814270559642

Epoch: 6| Step: 2
Training loss: 2.107392686530372
Validation loss: 2.5139119124103715

Epoch: 6| Step: 3
Training loss: 2.6457224745066092
Validation loss: 2.5049325510081903

Epoch: 6| Step: 4
Training loss: 3.155187295713634
Validation loss: 2.492823386400207

Epoch: 6| Step: 5
Training loss: 2.3319737924114095
Validation loss: 2.496980608579561

Epoch: 6| Step: 6
Training loss: 2.525860075306159
Validation loss: 2.5033402268302103

Epoch: 6| Step: 7
Training loss: 2.37860907341139
Validation loss: 2.499018949371684

Epoch: 6| Step: 8
Training loss: 2.5083444571855664
Validation loss: 2.497612873833535

Epoch: 6| Step: 9
Training loss: 2.4039341074185163
Validation loss: 2.5050255776565176

Epoch: 6| Step: 10
Training loss: 2.765142193909576
Validation loss: 2.495638447237338

Epoch: 6| Step: 11
Training loss: 2.8985896726078573
Validation loss: 2.5006807784717795

Epoch: 6| Step: 12
Training loss: 2.4493389678119164
Validation loss: 2.4975784653972823

Epoch: 6| Step: 13
Training loss: 3.1699123981778397
Validation loss: 2.4997818103041825

Epoch: 90| Step: 0
Training loss: 2.2714711498029656
Validation loss: 2.5058755934932964

Epoch: 6| Step: 1
Training loss: 2.4913661643745253
Validation loss: 2.4968640522204306

Epoch: 6| Step: 2
Training loss: 3.212355845738588
Validation loss: 2.503273937761694

Epoch: 6| Step: 3
Training loss: 2.4120035125112183
Validation loss: 2.497832389154989

Epoch: 6| Step: 4
Training loss: 2.383356951438704
Validation loss: 2.49599868855555

Epoch: 6| Step: 5
Training loss: 3.207798669695131
Validation loss: 2.500395510776984

Epoch: 6| Step: 6
Training loss: 1.911285066850507
Validation loss: 2.4876116596418423

Epoch: 6| Step: 7
Training loss: 2.6093344314071274
Validation loss: 2.5149546826762297

Epoch: 6| Step: 8
Training loss: 2.8100760292818125
Validation loss: 2.501197230886733

Epoch: 6| Step: 9
Training loss: 3.009384576736693
Validation loss: 2.492702213286337

Epoch: 6| Step: 10
Training loss: 2.341992953047994
Validation loss: 2.5050313798103483

Epoch: 6| Step: 11
Training loss: 2.37095407894719
Validation loss: 2.505263526064119

Epoch: 6| Step: 12
Training loss: 2.587398335399212
Validation loss: 2.502887424293998

Epoch: 6| Step: 13
Training loss: 3.314488803579329
Validation loss: 2.512424596978331

Epoch: 91| Step: 0
Training loss: 3.010330058153258
Validation loss: 2.5060869337916656

Epoch: 6| Step: 1
Training loss: 2.684633900210906
Validation loss: 2.4896457983675884

Epoch: 6| Step: 2
Training loss: 2.7668621507393256
Validation loss: 2.4937810702982444

Epoch: 6| Step: 3
Training loss: 2.5068344157815794
Validation loss: 2.4893084584686065

Epoch: 6| Step: 4
Training loss: 2.7139271897322916
Validation loss: 2.507635966571809

Epoch: 6| Step: 5
Training loss: 3.1457298884952074
Validation loss: 2.5122852819782153

Epoch: 6| Step: 6
Training loss: 2.1789035275983575
Validation loss: 2.514350261904788

Epoch: 6| Step: 7
Training loss: 2.1708283681196465
Validation loss: 2.5116635065490063

Epoch: 6| Step: 8
Training loss: 2.9595544649871854
Validation loss: 2.4968637678122763

Epoch: 6| Step: 9
Training loss: 2.6200703244562797
Validation loss: 2.5034389858787334

Epoch: 6| Step: 10
Training loss: 3.073173451874726
Validation loss: 2.4980656564773884

Epoch: 6| Step: 11
Training loss: 2.3531444209337185
Validation loss: 2.5071920852200074

Epoch: 6| Step: 12
Training loss: 2.528530496677019
Validation loss: 2.5259703165694583

Epoch: 6| Step: 13
Training loss: 1.523155929758553
Validation loss: 2.5087623906921066

Epoch: 92| Step: 0
Training loss: 2.825491759448033
Validation loss: 2.5010987851219526

Epoch: 6| Step: 1
Training loss: 2.6263062996074753
Validation loss: 2.51458799979895

Epoch: 6| Step: 2
Training loss: 2.779790945631706
Validation loss: 2.5050801518597585

Epoch: 6| Step: 3
Training loss: 2.0752935408737327
Validation loss: 2.5114129676984485

Epoch: 6| Step: 4
Training loss: 2.5961871359666073
Validation loss: 2.4868938178632893

Epoch: 6| Step: 5
Training loss: 3.0906245309734857
Validation loss: 2.5125354445790897

Epoch: 6| Step: 6
Training loss: 2.402783758294436
Validation loss: 2.509768269574474

Epoch: 6| Step: 7
Training loss: 2.375979974244879
Validation loss: 2.5045566553345946

Epoch: 6| Step: 8
Training loss: 2.701757184190359
Validation loss: 2.4951588610519897

Epoch: 6| Step: 9
Training loss: 2.6366361025820315
Validation loss: 2.496843325249626

Epoch: 6| Step: 10
Training loss: 2.8074354560749666
Validation loss: 2.497437455860203

Epoch: 6| Step: 11
Training loss: 2.5036420995246518
Validation loss: 2.501216733339965

Epoch: 6| Step: 12
Training loss: 3.183720161408994
Validation loss: 2.5113597611990044

Epoch: 6| Step: 13
Training loss: 1.8268974943338958
Validation loss: 2.500967535841968

Epoch: 93| Step: 0
Training loss: 2.3894482876820824
Validation loss: 2.499593297630083

Epoch: 6| Step: 1
Training loss: 2.2925208724973873
Validation loss: 2.508937575783733

Epoch: 6| Step: 2
Training loss: 2.754279275074291
Validation loss: 2.4936829033558556

Epoch: 6| Step: 3
Training loss: 2.713342309073084
Validation loss: 2.4885672911009165

Epoch: 6| Step: 4
Training loss: 3.400198784795243
Validation loss: 2.484126172381422

Epoch: 6| Step: 5
Training loss: 2.4808099466984936
Validation loss: 2.494386295323831

Epoch: 6| Step: 6
Training loss: 2.9149937509564636
Validation loss: 2.5088412429195457

Epoch: 6| Step: 7
Training loss: 2.001413561053938
Validation loss: 2.502071104154447

Epoch: 6| Step: 8
Training loss: 2.7616929372743924
Validation loss: 2.4964070373629665

Epoch: 6| Step: 9
Training loss: 2.567804382467374
Validation loss: 2.486704721476603

Epoch: 6| Step: 10
Training loss: 1.835779840720611
Validation loss: 2.5103261552875042

Epoch: 6| Step: 11
Training loss: 3.1856687184507777
Validation loss: 2.5069530845471006

Epoch: 6| Step: 12
Training loss: 2.6721196648190726
Validation loss: 2.491768609570528

Epoch: 6| Step: 13
Training loss: 2.4313651913221506
Validation loss: 2.5041034533737534

Epoch: 94| Step: 0
Training loss: 2.389431624403891
Validation loss: 2.4854540399322342

Epoch: 6| Step: 1
Training loss: 2.508108816733909
Validation loss: 2.4985075725950487

Epoch: 6| Step: 2
Training loss: 2.9239452188268156
Validation loss: 2.5038530805685584

Epoch: 6| Step: 3
Training loss: 2.082213774905626
Validation loss: 2.5092011115748893

Epoch: 6| Step: 4
Training loss: 2.505269314875623
Validation loss: 2.5056828073040447

Epoch: 6| Step: 5
Training loss: 2.1162449614391066
Validation loss: 2.494306849950836

Epoch: 6| Step: 6
Training loss: 3.0100203696540695
Validation loss: 2.502354429976995

Epoch: 6| Step: 7
Training loss: 2.8324314439764753
Validation loss: 2.5042587318086165

Epoch: 6| Step: 8
Training loss: 2.8667444203795607
Validation loss: 2.4940932224848806

Epoch: 6| Step: 9
Training loss: 3.077471048821654
Validation loss: 2.4940005024643694

Epoch: 6| Step: 10
Training loss: 2.085839658578489
Validation loss: 2.500601261397147

Epoch: 6| Step: 11
Training loss: 2.5622294213329035
Validation loss: 2.5023335937838107

Epoch: 6| Step: 12
Training loss: 3.145103032982184
Validation loss: 2.498346020537046

Epoch: 6| Step: 13
Training loss: 2.2065924014053753
Validation loss: 2.499047802510345

Epoch: 95| Step: 0
Training loss: 2.5533750003107483
Validation loss: 2.503445035944526

Epoch: 6| Step: 1
Training loss: 2.1770916319571825
Validation loss: 2.493945526477191

Epoch: 6| Step: 2
Training loss: 3.0698234032650618
Validation loss: 2.5160315278189462

Epoch: 6| Step: 3
Training loss: 2.5910989472765484
Validation loss: 2.4942658127698327

Epoch: 6| Step: 4
Training loss: 2.502666672406665
Validation loss: 2.513472516486381

Epoch: 6| Step: 5
Training loss: 2.870300764746186
Validation loss: 2.5148580945572463

Epoch: 6| Step: 6
Training loss: 1.9818793996848092
Validation loss: 2.5030822467992224

Epoch: 6| Step: 7
Training loss: 2.165212938263505
Validation loss: 2.495697804026536

Epoch: 6| Step: 8
Training loss: 2.548477885419197
Validation loss: 2.494193647896457

Epoch: 6| Step: 9
Training loss: 2.983613721007068
Validation loss: 2.506295279688478

Epoch: 6| Step: 10
Training loss: 2.323272666394492
Validation loss: 2.4903913777462456

Epoch: 6| Step: 11
Training loss: 3.6515031306182717
Validation loss: 2.493600624782286

Epoch: 6| Step: 12
Training loss: 2.5552110048122776
Validation loss: 2.4959512946232216

Epoch: 6| Step: 13
Training loss: 2.0284731150315407
Validation loss: 2.492813746080754

Epoch: 96| Step: 0
Training loss: 2.5832099474902344
Validation loss: 2.490694109635835

Epoch: 6| Step: 1
Training loss: 2.549740542507501
Validation loss: 2.4945021699491083

Epoch: 6| Step: 2
Training loss: 2.6249611261304975
Validation loss: 2.497934694269667

Epoch: 6| Step: 3
Training loss: 2.209257856012518
Validation loss: 2.4860764755788165

Epoch: 6| Step: 4
Training loss: 3.103043133134986
Validation loss: 2.4936977196258105

Epoch: 6| Step: 5
Training loss: 2.2094814506903706
Validation loss: 2.508797797376252

Epoch: 6| Step: 6
Training loss: 3.319510472987461
Validation loss: 2.5031638235085536

Epoch: 6| Step: 7
Training loss: 2.585101865609673
Validation loss: 2.5097630795050585

Epoch: 6| Step: 8
Training loss: 2.335398940450982
Validation loss: 2.488627321058145

Epoch: 6| Step: 9
Training loss: 2.6175361970367956
Validation loss: 2.488421633802204

Epoch: 6| Step: 10
Training loss: 2.114336635186287
Validation loss: 2.5019580904767977

Epoch: 6| Step: 11
Training loss: 2.571115478497995
Validation loss: 2.5049371073455355

Epoch: 6| Step: 12
Training loss: 3.050483014992193
Validation loss: 2.4938168551918363

Epoch: 6| Step: 13
Training loss: 2.408949390625602
Validation loss: 2.4969756403914487

Epoch: 97| Step: 0
Training loss: 2.7803926325103743
Validation loss: 2.4886893683395273

Epoch: 6| Step: 1
Training loss: 2.3508443654678324
Validation loss: 2.499468689522047

Epoch: 6| Step: 2
Training loss: 3.2033771694755195
Validation loss: 2.5062316710557524

Epoch: 6| Step: 3
Training loss: 2.409227386979662
Validation loss: 2.4901235698552076

Epoch: 6| Step: 4
Training loss: 2.7733390683182084
Validation loss: 2.4881838881553784

Epoch: 6| Step: 5
Training loss: 2.386428740467919
Validation loss: 2.4991376353414325

Epoch: 6| Step: 6
Training loss: 2.866774693013549
Validation loss: 2.49251023281215

Epoch: 6| Step: 7
Training loss: 2.352226189013507
Validation loss: 2.4946736559968437

Epoch: 6| Step: 8
Training loss: 2.1032367829633354
Validation loss: 2.5096912443077475

Epoch: 6| Step: 9
Training loss: 2.8641948829602506
Validation loss: 2.4857824879885966

Epoch: 6| Step: 10
Training loss: 2.6221600565123775
Validation loss: 2.481434216723742

Epoch: 6| Step: 11
Training loss: 2.8532318663455802
Validation loss: 2.5040664425795756

Epoch: 6| Step: 12
Training loss: 2.797938991598639
Validation loss: 2.4984659882462066

Epoch: 6| Step: 13
Training loss: 1.5222777035542105
Validation loss: 2.5062898870565404

Epoch: 98| Step: 0
Training loss: 2.955436165468918
Validation loss: 2.4924596251600346

Epoch: 6| Step: 1
Training loss: 3.0751878696519968
Validation loss: 2.509430993873856

Epoch: 6| Step: 2
Training loss: 2.7048364414259365
Validation loss: 2.4935703885337643

Epoch: 6| Step: 3
Training loss: 2.7425342134134194
Validation loss: 2.4912854372340645

Epoch: 6| Step: 4
Training loss: 2.7684182754091964
Validation loss: 2.495317302556969

Epoch: 6| Step: 5
Training loss: 2.6666870613112983
Validation loss: 2.5068792692715616

Epoch: 6| Step: 6
Training loss: 2.8980284862395096
Validation loss: 2.507360555208554

Epoch: 6| Step: 7
Training loss: 2.36473838084962
Validation loss: 2.491272641047527

Epoch: 6| Step: 8
Training loss: 2.218703793326629
Validation loss: 2.4930810840107185

Epoch: 6| Step: 9
Training loss: 2.005215876841702
Validation loss: 2.494415452820361

Epoch: 6| Step: 10
Training loss: 2.8245029754920123
Validation loss: 2.483770434038115

Epoch: 6| Step: 11
Training loss: 2.013906293187262
Validation loss: 2.4958832470184045

Epoch: 6| Step: 12
Training loss: 2.5923521572471278
Validation loss: 2.4961327328243152

Epoch: 6| Step: 13
Training loss: 2.1335681512862115
Validation loss: 2.501263302359037

Epoch: 99| Step: 0
Training loss: 2.682496492040497
Validation loss: 2.500326858195614

Epoch: 6| Step: 1
Training loss: 2.996736340701115
Validation loss: 2.4885044596317636

Epoch: 6| Step: 2
Training loss: 2.433880784449517
Validation loss: 2.5081976555601275

Epoch: 6| Step: 3
Training loss: 2.579465575350628
Validation loss: 2.508181727029761

Epoch: 6| Step: 4
Training loss: 2.992299687844618
Validation loss: 2.4986822711156558

Epoch: 6| Step: 5
Training loss: 2.6951357576222685
Validation loss: 2.4937422686543944

Epoch: 6| Step: 6
Training loss: 2.559106487120193
Validation loss: 2.4997512970549693

Epoch: 6| Step: 7
Training loss: 2.086415096856419
Validation loss: 2.4850404214178474

Epoch: 6| Step: 8
Training loss: 3.144673181967678
Validation loss: 2.5002820953036284

Epoch: 6| Step: 9
Training loss: 3.125412265286442
Validation loss: 2.4907632804065387

Epoch: 6| Step: 10
Training loss: 2.0207803725810938
Validation loss: 2.479999349316496

Epoch: 6| Step: 11
Training loss: 2.3027630546149256
Validation loss: 2.4967141836286895

Epoch: 6| Step: 12
Training loss: 2.460886249311325
Validation loss: 2.5035046725489987

Epoch: 6| Step: 13
Training loss: 1.5637575048423606
Validation loss: 2.508556268068199

Epoch: 100| Step: 0
Training loss: 2.849182473431061
Validation loss: 2.5132021876437185

Epoch: 6| Step: 1
Training loss: 2.31045710049865
Validation loss: 2.4957548112247667

Epoch: 6| Step: 2
Training loss: 2.366910307615579
Validation loss: 2.5012036676612013

Epoch: 6| Step: 3
Training loss: 2.659082495699053
Validation loss: 2.5036848773241944

Epoch: 6| Step: 4
Training loss: 2.0172467471994877
Validation loss: 2.496650203052145

Epoch: 6| Step: 5
Training loss: 2.72388263157137
Validation loss: 2.4883492273231713

Epoch: 6| Step: 6
Training loss: 2.078070733071704
Validation loss: 2.4954946242062164

Epoch: 6| Step: 7
Training loss: 2.391208253407329
Validation loss: 2.4917847448752903

Epoch: 6| Step: 8
Training loss: 2.7697154684633434
Validation loss: 2.5108950327700734

Epoch: 6| Step: 9
Training loss: 3.177889828903519
Validation loss: 2.497384429977121

Epoch: 6| Step: 10
Training loss: 2.684550774074043
Validation loss: 2.4952020021031465

Epoch: 6| Step: 11
Training loss: 2.737574335073163
Validation loss: 2.496996392444526

Epoch: 6| Step: 12
Training loss: 2.7497222933565992
Validation loss: 2.504935192497674

Epoch: 6| Step: 13
Training loss: 3.0030932374161723
Validation loss: 2.486300588422967

Epoch: 101| Step: 0
Training loss: 1.944227046015336
Validation loss: 2.5010003477826483

Epoch: 6| Step: 1
Training loss: 2.4981663655207864
Validation loss: 2.4974997354039417

Epoch: 6| Step: 2
Training loss: 2.837093737586845
Validation loss: 2.501445661963758

Epoch: 6| Step: 3
Training loss: 2.400902391698611
Validation loss: 2.4960605941953955

Epoch: 6| Step: 4
Training loss: 3.2170158084745397
Validation loss: 2.5102032667027587

Epoch: 6| Step: 5
Training loss: 2.374258829213476
Validation loss: 2.505116585851748

Epoch: 6| Step: 6
Training loss: 3.298275907561759
Validation loss: 2.5025337500172755

Epoch: 6| Step: 7
Training loss: 2.530540837918457
Validation loss: 2.497075806148249

Epoch: 6| Step: 8
Training loss: 1.8485161552559028
Validation loss: 2.513421744420397

Epoch: 6| Step: 9
Training loss: 3.0035325550838037
Validation loss: 2.499475418961642

Epoch: 6| Step: 10
Training loss: 2.6886945331976038
Validation loss: 2.5135637833718705

Epoch: 6| Step: 11
Training loss: 2.3681356715437336
Validation loss: 2.4938950353280953

Epoch: 6| Step: 12
Training loss: 2.497011305582151
Validation loss: 2.5099977230432167

Epoch: 6| Step: 13
Training loss: 2.5331054292191535
Validation loss: 2.523415490755495

Epoch: 102| Step: 0
Training loss: 2.8192203340788637
Validation loss: 2.4958743734740003

Epoch: 6| Step: 1
Training loss: 2.6700342094715817
Validation loss: 2.4936963276486024

Epoch: 6| Step: 2
Training loss: 2.431643860596492
Validation loss: 2.4882499589956955

Epoch: 6| Step: 3
Training loss: 2.2508669348643373
Validation loss: 2.4858646148789987

Epoch: 6| Step: 4
Training loss: 3.336065285444084
Validation loss: 2.489605429886776

Epoch: 6| Step: 5
Training loss: 2.518860247071064
Validation loss: 2.49007743957021

Epoch: 6| Step: 6
Training loss: 2.6962904772949927
Validation loss: 2.495524150907063

Epoch: 6| Step: 7
Training loss: 2.509087924522012
Validation loss: 2.4992593816738786

Epoch: 6| Step: 8
Training loss: 2.697408817365831
Validation loss: 2.4909424231912882

Epoch: 6| Step: 9
Training loss: 2.4400879253116994
Validation loss: 2.4981190373427764

Epoch: 6| Step: 10
Training loss: 2.8389988708923823
Validation loss: 2.494136634823661

Epoch: 6| Step: 11
Training loss: 2.3524871731772268
Validation loss: 2.517061945519908

Epoch: 6| Step: 12
Training loss: 2.3367483715550827
Validation loss: 2.4978703267256734

Epoch: 6| Step: 13
Training loss: 2.4304699389198214
Validation loss: 2.5017953927203274

Epoch: 103| Step: 0
Training loss: 2.5513567662268986
Validation loss: 2.495563166256428

Epoch: 6| Step: 1
Training loss: 2.520995100731574
Validation loss: 2.492249152624839

Epoch: 6| Step: 2
Training loss: 2.941989795202921
Validation loss: 2.506831621871429

Epoch: 6| Step: 3
Training loss: 2.4072544924216426
Validation loss: 2.4948594936601363

Epoch: 6| Step: 4
Training loss: 2.6366771553432153
Validation loss: 2.5076521899320525

Epoch: 6| Step: 5
Training loss: 2.2170360553788044
Validation loss: 2.4996537061009265

Epoch: 6| Step: 6
Training loss: 2.284843123411823
Validation loss: 2.4960974956887916

Epoch: 6| Step: 7
Training loss: 2.9688251686618528
Validation loss: 2.4886134403650466

Epoch: 6| Step: 8
Training loss: 2.3118837927418796
Validation loss: 2.4853429463638887

Epoch: 6| Step: 9
Training loss: 2.276549212142715
Validation loss: 2.4987089946048773

Epoch: 6| Step: 10
Training loss: 3.0702225766590687
Validation loss: 2.486457695215066

Epoch: 6| Step: 11
Training loss: 2.851256973411933
Validation loss: 2.4836523731331863

Epoch: 6| Step: 12
Training loss: 2.485506963461877
Validation loss: 2.498812983311697

Epoch: 6| Step: 13
Training loss: 2.9485868269601707
Validation loss: 2.496484495599172

Epoch: 104| Step: 0
Training loss: 2.860110995933133
Validation loss: 2.481365262697288

Epoch: 6| Step: 1
Training loss: 2.1769137765178175
Validation loss: 2.495313743707966

Epoch: 6| Step: 2
Training loss: 2.7778420303119167
Validation loss: 2.499986207575335

Epoch: 6| Step: 3
Training loss: 2.224062724347282
Validation loss: 2.4849497318059095

Epoch: 6| Step: 4
Training loss: 2.3136372218579244
Validation loss: 2.4980220897196426

Epoch: 6| Step: 5
Training loss: 3.3348438337328097
Validation loss: 2.509335364962475

Epoch: 6| Step: 6
Training loss: 3.3306303668287622
Validation loss: 2.500441666013161

Epoch: 6| Step: 7
Training loss: 2.5852623372172285
Validation loss: 2.490707615911487

Epoch: 6| Step: 8
Training loss: 2.4140700059298763
Validation loss: 2.513709327729865

Epoch: 6| Step: 9
Training loss: 2.747315917577839
Validation loss: 2.483414712868948

Epoch: 6| Step: 10
Training loss: 2.372546987118528
Validation loss: 2.501930918562213

Epoch: 6| Step: 11
Training loss: 2.4156579729719216
Validation loss: 2.496970044879465

Epoch: 6| Step: 12
Training loss: 1.8615544472764047
Validation loss: 2.4980857945059025

Epoch: 6| Step: 13
Training loss: 2.552686648517361
Validation loss: 2.4884286547933603

Epoch: 105| Step: 0
Training loss: 3.2219298127744533
Validation loss: 2.5036184970316286

Epoch: 6| Step: 1
Training loss: 2.6666477222564438
Validation loss: 2.5055326205386255

Epoch: 6| Step: 2
Training loss: 2.238706005863315
Validation loss: 2.508306195621239

Epoch: 6| Step: 3
Training loss: 2.3850515383224113
Validation loss: 2.506487194391055

Epoch: 6| Step: 4
Training loss: 3.359285149370728
Validation loss: 2.5015627129976954

Epoch: 6| Step: 5
Training loss: 2.359543649064802
Validation loss: 2.494509322844566

Epoch: 6| Step: 6
Training loss: 1.878200533295333
Validation loss: 2.4925396313306325

Epoch: 6| Step: 7
Training loss: 2.5504899844474203
Validation loss: 2.501614971901456

Epoch: 6| Step: 8
Training loss: 2.4789629833847746
Validation loss: 2.4939324314422557

Epoch: 6| Step: 9
Training loss: 2.7047656598359286
Validation loss: 2.474469439435867

Epoch: 6| Step: 10
Training loss: 2.546688517664824
Validation loss: 2.4952656597083647

Epoch: 6| Step: 11
Training loss: 2.8639672928972417
Validation loss: 2.4838369102417786

Epoch: 6| Step: 12
Training loss: 2.170356713785935
Validation loss: 2.4812956682455978

Epoch: 6| Step: 13
Training loss: 2.5472932249836986
Validation loss: 2.4952187840571876

Epoch: 106| Step: 0
Training loss: 2.840239989120775
Validation loss: 2.486731186568331

Epoch: 6| Step: 1
Training loss: 1.6995969855616002
Validation loss: 2.488981809547286

Epoch: 6| Step: 2
Training loss: 2.2417004418458055
Validation loss: 2.4910847821708475

Epoch: 6| Step: 3
Training loss: 2.6206458173744256
Validation loss: 2.487559201368841

Epoch: 6| Step: 4
Training loss: 2.9632655832493513
Validation loss: 2.5056635063833976

Epoch: 6| Step: 5
Training loss: 2.8413365781107074
Validation loss: 2.501398554689149

Epoch: 6| Step: 6
Training loss: 3.0833783704887963
Validation loss: 2.505877811468703

Epoch: 6| Step: 7
Training loss: 2.6590165933332996
Validation loss: 2.5124960591430154

Epoch: 6| Step: 8
Training loss: 2.746875374959979
Validation loss: 2.4869645560518925

Epoch: 6| Step: 9
Training loss: 2.978149631714605
Validation loss: 2.4865806273574327

Epoch: 6| Step: 10
Training loss: 2.49999542235909
Validation loss: 2.492285840021774

Epoch: 6| Step: 11
Training loss: 2.5480807206079894
Validation loss: 2.5033356573454744

Epoch: 6| Step: 12
Training loss: 1.7271622526622925
Validation loss: 2.4870568250709986

Epoch: 6| Step: 13
Training loss: 2.4732848418521365
Validation loss: 2.485798037688127

Epoch: 107| Step: 0
Training loss: 2.483982175084289
Validation loss: 2.4854321832480832

Epoch: 6| Step: 1
Training loss: 2.874342801817208
Validation loss: 2.4957992762846994

Epoch: 6| Step: 2
Training loss: 2.4299597878916153
Validation loss: 2.4847633851252504

Epoch: 6| Step: 3
Training loss: 3.0051730378104047
Validation loss: 2.487943595248511

Epoch: 6| Step: 4
Training loss: 2.708395609995504
Validation loss: 2.504170507234562

Epoch: 6| Step: 5
Training loss: 2.0402536238292384
Validation loss: 2.483849199773915

Epoch: 6| Step: 6
Training loss: 3.127618836753081
Validation loss: 2.491558649718781

Epoch: 6| Step: 7
Training loss: 2.8771682524158995
Validation loss: 2.4870840832103296

Epoch: 6| Step: 8
Training loss: 2.1154663296902703
Validation loss: 2.5224534614006955

Epoch: 6| Step: 9
Training loss: 2.7815268732336556
Validation loss: 2.5108573318148717

Epoch: 6| Step: 10
Training loss: 2.2479840890450293
Validation loss: 2.5025970034443272

Epoch: 6| Step: 11
Training loss: 2.216147064555297
Validation loss: 2.504731864373298

Epoch: 6| Step: 12
Training loss: 2.766666194808491
Validation loss: 2.5131348677723873

Epoch: 6| Step: 13
Training loss: 2.049688022413971
Validation loss: 2.502691703118174

Epoch: 108| Step: 0
Training loss: 2.1070761127384667
Validation loss: 2.50041935490168

Epoch: 6| Step: 1
Training loss: 2.5062589497775054
Validation loss: 2.501422748983052

Epoch: 6| Step: 2
Training loss: 2.59899133777239
Validation loss: 2.4878927092234266

Epoch: 6| Step: 3
Training loss: 2.5652042169309928
Validation loss: 2.5062326059921074

Epoch: 6| Step: 4
Training loss: 2.4745902020826414
Validation loss: 2.4951292889300785

Epoch: 6| Step: 5
Training loss: 3.135854561644578
Validation loss: 2.4734388471602355

Epoch: 6| Step: 6
Training loss: 2.6934026613692117
Validation loss: 2.489020144663138

Epoch: 6| Step: 7
Training loss: 3.301457118073477
Validation loss: 2.497106645710797

Epoch: 6| Step: 8
Training loss: 2.639396968807033
Validation loss: 2.465740732756498

Epoch: 6| Step: 9
Training loss: 2.5082591006763013
Validation loss: 2.497963387515091

Epoch: 6| Step: 10
Training loss: 2.5777915970205343
Validation loss: 2.4770882562360224

Epoch: 6| Step: 11
Training loss: 2.151553581845397
Validation loss: 2.4959044462289186

Epoch: 6| Step: 12
Training loss: 2.0264135442739697
Validation loss: 2.502780801323284

Epoch: 6| Step: 13
Training loss: 2.845295412786333
Validation loss: 2.5056831449371044

Epoch: 109| Step: 0
Training loss: 2.974174122015866
Validation loss: 2.4983793060868806

Epoch: 6| Step: 1
Training loss: 3.349834005314171
Validation loss: 2.4947598030754157

Epoch: 6| Step: 2
Training loss: 1.9836396784834576
Validation loss: 2.509279307900039

Epoch: 6| Step: 3
Training loss: 2.5032632510978297
Validation loss: 2.49844781414726

Epoch: 6| Step: 4
Training loss: 2.471867391813315
Validation loss: 2.4778701105956538

Epoch: 6| Step: 5
Training loss: 2.747181922335013
Validation loss: 2.487458526658048

Epoch: 6| Step: 6
Training loss: 1.7607230948684063
Validation loss: 2.4777369014176944

Epoch: 6| Step: 7
Training loss: 3.419393955095201
Validation loss: 2.486273558850907

Epoch: 6| Step: 8
Training loss: 1.6702306629255461
Validation loss: 2.493946234731693

Epoch: 6| Step: 9
Training loss: 2.701173993356002
Validation loss: 2.5005884339406474

Epoch: 6| Step: 10
Training loss: 2.7573909275205883
Validation loss: 2.4849895455798343

Epoch: 6| Step: 11
Training loss: 2.9122655815122256
Validation loss: 2.4933759738578156

Epoch: 6| Step: 12
Training loss: 1.7779558071098174
Validation loss: 2.4973691921157677

Epoch: 6| Step: 13
Training loss: 2.2711030175827314
Validation loss: 2.4971632398704684

Epoch: 110| Step: 0
Training loss: 2.1814020448175144
Validation loss: 2.498117768924185

Epoch: 6| Step: 1
Training loss: 2.770943909544419
Validation loss: 2.4837948010772006

Epoch: 6| Step: 2
Training loss: 2.744948515973784
Validation loss: 2.491029790204939

Epoch: 6| Step: 3
Training loss: 2.474234753609042
Validation loss: 2.5072461746389814

Epoch: 6| Step: 4
Training loss: 2.3133103265451944
Validation loss: 2.4806905430098065

Epoch: 6| Step: 5
Training loss: 2.618931431278001
Validation loss: 2.492244361189943

Epoch: 6| Step: 6
Training loss: 2.234458655011775
Validation loss: 2.492203602761473

Epoch: 6| Step: 7
Training loss: 3.0779209747084626
Validation loss: 2.4891151028755116

Epoch: 6| Step: 8
Training loss: 3.0652297952208682
Validation loss: 2.5013696610232103

Epoch: 6| Step: 9
Training loss: 2.9981823819132223
Validation loss: 2.471437656110889

Epoch: 6| Step: 10
Training loss: 2.0503173303394604
Validation loss: 2.4884616794568317

Epoch: 6| Step: 11
Training loss: 2.4944977291828585
Validation loss: 2.5118539874213495

Epoch: 6| Step: 12
Training loss: 2.132820436791265
Validation loss: 2.4901659529163527

Epoch: 6| Step: 13
Training loss: 2.808318441636384
Validation loss: 2.5033538241214335

Epoch: 111| Step: 0
Training loss: 1.8999712992056421
Validation loss: 2.482160043540474

Epoch: 6| Step: 1
Training loss: 2.493827352065086
Validation loss: 2.4994754322953714

Epoch: 6| Step: 2
Training loss: 3.1532332100272646
Validation loss: 2.502751323358356

Epoch: 6| Step: 3
Training loss: 3.1704439589993956
Validation loss: 2.4935896324422067

Epoch: 6| Step: 4
Training loss: 2.4976407362927744
Validation loss: 2.498474610430855

Epoch: 6| Step: 5
Training loss: 2.126190973771124
Validation loss: 2.506232964009219

Epoch: 6| Step: 6
Training loss: 2.057885527708917
Validation loss: 2.5198945857200554

Epoch: 6| Step: 7
Training loss: 2.6714516466046105
Validation loss: 2.502514242461354

Epoch: 6| Step: 8
Training loss: 2.7906044509660823
Validation loss: 2.489255132746826

Epoch: 6| Step: 9
Training loss: 1.9966339753881266
Validation loss: 2.5078284134971827

Epoch: 6| Step: 10
Training loss: 2.3600828612053797
Validation loss: 2.4902450588961464

Epoch: 6| Step: 11
Training loss: 2.7526580795643185
Validation loss: 2.499915975778886

Epoch: 6| Step: 12
Training loss: 3.1940482700166397
Validation loss: 2.4982308619195344

Epoch: 6| Step: 13
Training loss: 2.517188871491033
Validation loss: 2.500763321292985

Epoch: 112| Step: 0
Training loss: 1.6068870795028485
Validation loss: 2.4986456504476435

Epoch: 6| Step: 1
Training loss: 2.7733550583312505
Validation loss: 2.505278875543856

Epoch: 6| Step: 2
Training loss: 2.7645651300478287
Validation loss: 2.484578433936458

Epoch: 6| Step: 3
Training loss: 2.278115300496702
Validation loss: 2.4890359033052043

Epoch: 6| Step: 4
Training loss: 2.3362649031113243
Validation loss: 2.5173430566042456

Epoch: 6| Step: 5
Training loss: 2.3254233436326848
Validation loss: 2.4857682433368287

Epoch: 6| Step: 6
Training loss: 2.237508856899697
Validation loss: 2.482928746086976

Epoch: 6| Step: 7
Training loss: 2.2050619065640276
Validation loss: 2.501118793154159

Epoch: 6| Step: 8
Training loss: 2.3429728936301513
Validation loss: 2.4956415084357326

Epoch: 6| Step: 9
Training loss: 3.5229390335200135
Validation loss: 2.4780468919929537

Epoch: 6| Step: 10
Training loss: 2.908799888402687
Validation loss: 2.4978402304272045

Epoch: 6| Step: 11
Training loss: 2.4806901968079496
Validation loss: 2.486123897925741

Epoch: 6| Step: 12
Training loss: 2.628924750933228
Validation loss: 2.4997699703503486

Epoch: 6| Step: 13
Training loss: 3.4982648363051645
Validation loss: 2.4753912304000414

Epoch: 113| Step: 0
Training loss: 3.3057178667611704
Validation loss: 2.49180772847609

Epoch: 6| Step: 1
Training loss: 2.336965277397949
Validation loss: 2.493183502857584

Epoch: 6| Step: 2
Training loss: 2.343447246070879
Validation loss: 2.4808079398570855

Epoch: 6| Step: 3
Training loss: 3.3267274886427662
Validation loss: 2.481781393896238

Epoch: 6| Step: 4
Training loss: 2.4972488524483674
Validation loss: 2.481883436162382

Epoch: 6| Step: 5
Training loss: 2.186780647800098
Validation loss: 2.478348838471929

Epoch: 6| Step: 6
Training loss: 2.9498757546333096
Validation loss: 2.495977494253904

Epoch: 6| Step: 7
Training loss: 2.574206246561298
Validation loss: 2.4997238673227744

Epoch: 6| Step: 8
Training loss: 3.1173904850008958
Validation loss: 2.486390560114967

Epoch: 6| Step: 9
Training loss: 2.1326131762472005
Validation loss: 2.4679503396422

Epoch: 6| Step: 10
Training loss: 2.3155410977915127
Validation loss: 2.4741453656846497

Epoch: 6| Step: 11
Training loss: 2.0099814014618174
Validation loss: 2.473198971918858

Epoch: 6| Step: 12
Training loss: 2.187624900521865
Validation loss: 2.4795060939240763

Epoch: 6| Step: 13
Training loss: 2.1083809099621726
Validation loss: 2.4810889810542704

Epoch: 114| Step: 0
Training loss: 2.5429226216294367
Validation loss: 2.50093043251158

Epoch: 6| Step: 1
Training loss: 3.0501844381629653
Validation loss: 2.4999588942481137

Epoch: 6| Step: 2
Training loss: 2.828006636529498
Validation loss: 2.496012026442503

Epoch: 6| Step: 3
Training loss: 2.167536292030772
Validation loss: 2.4812666004125976

Epoch: 6| Step: 4
Training loss: 2.3976795104667574
Validation loss: 2.501683987767696

Epoch: 6| Step: 5
Training loss: 2.326156500854421
Validation loss: 2.498136740745711

Epoch: 6| Step: 6
Training loss: 3.013897336683334
Validation loss: 2.48581709064283

Epoch: 6| Step: 7
Training loss: 2.36649596937438
Validation loss: 2.5003914957222673

Epoch: 6| Step: 8
Training loss: 2.864567445653148
Validation loss: 2.494300431351469

Epoch: 6| Step: 9
Training loss: 2.945870344117437
Validation loss: 2.4913276569801397

Epoch: 6| Step: 10
Training loss: 2.671621834879925
Validation loss: 2.493892117957366

Epoch: 6| Step: 11
Training loss: 2.3769097931547427
Validation loss: 2.491273606294931

Epoch: 6| Step: 12
Training loss: 2.146676746526395
Validation loss: 2.481450106190596

Epoch: 6| Step: 13
Training loss: 1.938684040179757
Validation loss: 2.503455690087131

Epoch: 115| Step: 0
Training loss: 2.7592785966391378
Validation loss: 2.505952924788623

Epoch: 6| Step: 1
Training loss: 2.581899573219099
Validation loss: 2.494758005784518

Epoch: 6| Step: 2
Training loss: 2.7077730822019164
Validation loss: 2.496165377236088

Epoch: 6| Step: 3
Training loss: 2.936306650160098
Validation loss: 2.4794819049675065

Epoch: 6| Step: 4
Training loss: 2.6101220255129123
Validation loss: 2.4824510418704038

Epoch: 6| Step: 5
Training loss: 2.487095716584826
Validation loss: 2.497054326335768

Epoch: 6| Step: 6
Training loss: 2.495422368506224
Validation loss: 2.4867853220665515

Epoch: 6| Step: 7
Training loss: 2.789442704302409
Validation loss: 2.4828423103467534

Epoch: 6| Step: 8
Training loss: 2.383694844960571
Validation loss: 2.4913006608544155

Epoch: 6| Step: 9
Training loss: 2.3142922132222528
Validation loss: 2.485907565561899

Epoch: 6| Step: 10
Training loss: 2.4735154140247375
Validation loss: 2.492482327400761

Epoch: 6| Step: 11
Training loss: 2.329900793984231
Validation loss: 2.476823326105622

Epoch: 6| Step: 12
Training loss: 2.525876216123761
Validation loss: 2.4956857053531527

Epoch: 6| Step: 13
Training loss: 2.367112262398865
Validation loss: 2.485720408885366

Epoch: 116| Step: 0
Training loss: 2.6002483542743087
Validation loss: 2.496889784350491

Epoch: 6| Step: 1
Training loss: 2.6677102093514358
Validation loss: 2.512014233452115

Epoch: 6| Step: 2
Training loss: 3.08323856586157
Validation loss: 2.465036265896802

Epoch: 6| Step: 3
Training loss: 2.801768534584311
Validation loss: 2.4778020589193557

Epoch: 6| Step: 4
Training loss: 2.798900275887659
Validation loss: 2.4762040848027307

Epoch: 6| Step: 5
Training loss: 2.7926358111217384
Validation loss: 2.4857938850950823

Epoch: 6| Step: 6
Training loss: 2.5315917926370197
Validation loss: 2.4958637896844484

Epoch: 6| Step: 7
Training loss: 2.20307814095086
Validation loss: 2.486740911292483

Epoch: 6| Step: 8
Training loss: 3.015122762176707
Validation loss: 2.500552909990448

Epoch: 6| Step: 9
Training loss: 2.350328191200914
Validation loss: 2.486997557893509

Epoch: 6| Step: 10
Training loss: 2.5084530971826804
Validation loss: 2.496598186275271

Epoch: 6| Step: 11
Training loss: 2.1360085264171484
Validation loss: 2.499550713396082

Epoch: 6| Step: 12
Training loss: 2.0696802865406223
Validation loss: 2.5074468512287282

Epoch: 6| Step: 13
Training loss: 1.78946211570508
Validation loss: 2.4985877508887944

Epoch: 117| Step: 0
Training loss: 2.443989161035006
Validation loss: 2.4976926533509043

Epoch: 6| Step: 1
Training loss: 2.4452805197090086
Validation loss: 2.494153388998803

Epoch: 6| Step: 2
Training loss: 2.714909965750494
Validation loss: 2.4979277656810326

Epoch: 6| Step: 3
Training loss: 2.386346116765434
Validation loss: 2.487882796307184

Epoch: 6| Step: 4
Training loss: 3.0646396869497785
Validation loss: 2.459227168118307

Epoch: 6| Step: 5
Training loss: 2.1398737347867227
Validation loss: 2.484782036929982

Epoch: 6| Step: 6
Training loss: 2.2748830073530275
Validation loss: 2.499968863877862

Epoch: 6| Step: 7
Training loss: 3.1171908653451443
Validation loss: 2.472513366022394

Epoch: 6| Step: 8
Training loss: 2.6462261679273995
Validation loss: 2.4912467016843034

Epoch: 6| Step: 9
Training loss: 2.5436337681114503
Validation loss: 2.4750326745909406

Epoch: 6| Step: 10
Training loss: 2.8466329528217753
Validation loss: 2.48355634412956

Epoch: 6| Step: 11
Training loss: 2.539149825721865
Validation loss: 2.4802050471577477

Epoch: 6| Step: 12
Training loss: 2.09343238812859
Validation loss: 2.48851969614411

Epoch: 6| Step: 13
Training loss: 2.4646234912669387
Validation loss: 2.5026616407276165

Epoch: 118| Step: 0
Training loss: 2.027976464708689
Validation loss: 2.490135385667934

Epoch: 6| Step: 1
Training loss: 2.5036596215438944
Validation loss: 2.486103604225308

Epoch: 6| Step: 2
Training loss: 2.369073399834566
Validation loss: 2.4833205339270252

Epoch: 6| Step: 3
Training loss: 2.6429577517414526
Validation loss: 2.492532241363773

Epoch: 6| Step: 4
Training loss: 2.128058532483489
Validation loss: 2.48056783571098

Epoch: 6| Step: 5
Training loss: 2.8548919053333166
Validation loss: 2.4749682516085927

Epoch: 6| Step: 6
Training loss: 2.5003628467458405
Validation loss: 2.476555897735059

Epoch: 6| Step: 7
Training loss: 3.2289495251568647
Validation loss: 2.492472284112131

Epoch: 6| Step: 8
Training loss: 2.562446221508377
Validation loss: 2.4873028425638077

Epoch: 6| Step: 9
Training loss: 2.53073020590126
Validation loss: 2.4930704626551994

Epoch: 6| Step: 10
Training loss: 2.4885587193216314
Validation loss: 2.499367219048821

Epoch: 6| Step: 11
Training loss: 2.560987072430521
Validation loss: 2.497303666404659

Epoch: 6| Step: 12
Training loss: 2.483292541766262
Validation loss: 2.4821500013482365

Epoch: 6| Step: 13
Training loss: 2.9842796110716745
Validation loss: 2.477498085947807

Epoch: 119| Step: 0
Training loss: 1.9598644101674088
Validation loss: 2.49873999355588

Epoch: 6| Step: 1
Training loss: 2.179273996815968
Validation loss: 2.502783128570166

Epoch: 6| Step: 2
Training loss: 2.3932863269464906
Validation loss: 2.496276779945183

Epoch: 6| Step: 3
Training loss: 3.052873233656112
Validation loss: 2.4892412272326476

Epoch: 6| Step: 4
Training loss: 2.7387629587275164
Validation loss: 2.4906530571897068

Epoch: 6| Step: 5
Training loss: 2.3676326320600305
Validation loss: 2.4843806176880867

Epoch: 6| Step: 6
Training loss: 2.571116220334903
Validation loss: 2.4927440598806445

Epoch: 6| Step: 7
Training loss: 2.7256375468174587
Validation loss: 2.4855697564746113

Epoch: 6| Step: 8
Training loss: 2.4991043393753034
Validation loss: 2.495123032730262

Epoch: 6| Step: 9
Training loss: 2.787250346820251
Validation loss: 2.488503867270542

Epoch: 6| Step: 10
Training loss: 2.5838839856727343
Validation loss: 2.4749591109303033

Epoch: 6| Step: 11
Training loss: 2.2963881203648975
Validation loss: 2.4845796906943294

Epoch: 6| Step: 12
Training loss: 3.018606026890733
Validation loss: 2.496670510628508

Epoch: 6| Step: 13
Training loss: 2.1800362912928217
Validation loss: 2.483795919923984

Epoch: 120| Step: 0
Training loss: 2.0419571598502193
Validation loss: 2.4884099757194287

Epoch: 6| Step: 1
Training loss: 2.1730527908927653
Validation loss: 2.492448850986031

Epoch: 6| Step: 2
Training loss: 2.084538022462014
Validation loss: 2.4956173531156436

Epoch: 6| Step: 3
Training loss: 3.0288161112095366
Validation loss: 2.490343474592647

Epoch: 6| Step: 4
Training loss: 2.593221403744835
Validation loss: 2.474562573219597

Epoch: 6| Step: 5
Training loss: 2.87712963673767
Validation loss: 2.464928120041387

Epoch: 6| Step: 6
Training loss: 2.8988757354852512
Validation loss: 2.490138447454296

Epoch: 6| Step: 7
Training loss: 2.243373968975961
Validation loss: 2.4859756072762473

Epoch: 6| Step: 8
Training loss: 2.950424331923007
Validation loss: 2.497856193087632

Epoch: 6| Step: 9
Training loss: 2.2565835426193637
Validation loss: 2.486444221530531

Epoch: 6| Step: 10
Training loss: 2.8352561111081607
Validation loss: 2.4867176617880333

Epoch: 6| Step: 11
Training loss: 2.055865164228026
Validation loss: 2.4928287783398804

Epoch: 6| Step: 12
Training loss: 2.8862717299141063
Validation loss: 2.496091010826711

Epoch: 6| Step: 13
Training loss: 2.128649774903513
Validation loss: 2.495485128783848

Epoch: 121| Step: 0
Training loss: 2.424504876469959
Validation loss: 2.481058624360266

Epoch: 6| Step: 1
Training loss: 2.1984060625486888
Validation loss: 2.497889381506054

Epoch: 6| Step: 2
Training loss: 2.5598797310949784
Validation loss: 2.4711718950694928

Epoch: 6| Step: 3
Training loss: 3.3501907066607557
Validation loss: 2.478069887659351

Epoch: 6| Step: 4
Training loss: 2.565570015730468
Validation loss: 2.4765352368176425

Epoch: 6| Step: 5
Training loss: 2.1231280664888414
Validation loss: 2.4867201782955246

Epoch: 6| Step: 6
Training loss: 2.6527607158846735
Validation loss: 2.4738764820040604

Epoch: 6| Step: 7
Training loss: 2.512334816280557
Validation loss: 2.49481183557559

Epoch: 6| Step: 8
Training loss: 2.3035105658144586
Validation loss: 2.491326876463887

Epoch: 6| Step: 9
Training loss: 2.5021109252052054
Validation loss: 2.4821743842948054

Epoch: 6| Step: 10
Training loss: 2.566811168203004
Validation loss: 2.481328683493459

Epoch: 6| Step: 11
Training loss: 2.7544994824530695
Validation loss: 2.5091310712959918

Epoch: 6| Step: 12
Training loss: 2.6741772821472662
Validation loss: 2.4774945051237167

Epoch: 6| Step: 13
Training loss: 2.49478339483898
Validation loss: 2.4796212123397368

Epoch: 122| Step: 0
Training loss: 2.309520761228487
Validation loss: 2.4791642679595993

Epoch: 6| Step: 1
Training loss: 2.465315348976163
Validation loss: 2.4728741200152746

Epoch: 6| Step: 2
Training loss: 3.1526703127687146
Validation loss: 2.4817670260792726

Epoch: 6| Step: 3
Training loss: 2.6063241998369584
Validation loss: 2.4778175154034057

Epoch: 6| Step: 4
Training loss: 2.3374318730019263
Validation loss: 2.4739064102466632

Epoch: 6| Step: 5
Training loss: 2.6299611394063596
Validation loss: 2.4613437903829847

Epoch: 6| Step: 6
Training loss: 2.594020048124301
Validation loss: 2.4786013097061237

Epoch: 6| Step: 7
Training loss: 2.5865095260742614
Validation loss: 2.4817731424058005

Epoch: 6| Step: 8
Training loss: 2.3410128059542097
Validation loss: 2.4874156697477674

Epoch: 6| Step: 9
Training loss: 1.5668553495753588
Validation loss: 2.486354679680248

Epoch: 6| Step: 10
Training loss: 2.693057147711924
Validation loss: 2.465448006458673

Epoch: 6| Step: 11
Training loss: 2.8681785263616404
Validation loss: 2.4879497149382974

Epoch: 6| Step: 12
Training loss: 2.4563823868113075
Validation loss: 2.498439584865207

Epoch: 6| Step: 13
Training loss: 3.0512865261093562
Validation loss: 2.4936299826876045

Epoch: 123| Step: 0
Training loss: 2.4313708787694597
Validation loss: 2.503507503964664

Epoch: 6| Step: 1
Training loss: 2.393116768130164
Validation loss: 2.4797398662968857

Epoch: 6| Step: 2
Training loss: 1.8064954544715486
Validation loss: 2.4602340002622607

Epoch: 6| Step: 3
Training loss: 2.980876369775299
Validation loss: 2.469548819046742

Epoch: 6| Step: 4
Training loss: 3.0400056527737713
Validation loss: 2.458400019065715

Epoch: 6| Step: 5
Training loss: 2.2019551735801297
Validation loss: 2.4877338257682617

Epoch: 6| Step: 6
Training loss: 2.3989420307338167
Validation loss: 2.4863772067023695

Epoch: 6| Step: 7
Training loss: 2.2950681469342618
Validation loss: 2.4995412938952755

Epoch: 6| Step: 8
Training loss: 2.933229954660723
Validation loss: 2.4620282114473717

Epoch: 6| Step: 9
Training loss: 2.5833545704450644
Validation loss: 2.4712465227520584

Epoch: 6| Step: 10
Training loss: 2.2578239044640607
Validation loss: 2.481334971373514

Epoch: 6| Step: 11
Training loss: 2.6009602350746728
Validation loss: 2.465864377500715

Epoch: 6| Step: 12
Training loss: 2.773547017258911
Validation loss: 2.473783096471542

Epoch: 6| Step: 13
Training loss: 2.620620889549025
Validation loss: 2.4937895431712143

Epoch: 124| Step: 0
Training loss: 3.453128866478322
Validation loss: 2.490499016993628

Epoch: 6| Step: 1
Training loss: 1.917250178151179
Validation loss: 2.488627430768313

Epoch: 6| Step: 2
Training loss: 2.6191388044130512
Validation loss: 2.4861397048299767

Epoch: 6| Step: 3
Training loss: 2.0806642091722938
Validation loss: 2.473662606371095

Epoch: 6| Step: 4
Training loss: 2.401425665367938
Validation loss: 2.5007442002480094

Epoch: 6| Step: 5
Training loss: 3.16058173221107
Validation loss: 2.4939846024997485

Epoch: 6| Step: 6
Training loss: 2.7734484175346297
Validation loss: 2.483107463472173

Epoch: 6| Step: 7
Training loss: 2.5701718741213426
Validation loss: 2.4815434191122994

Epoch: 6| Step: 8
Training loss: 2.12216333781376
Validation loss: 2.4785545770982176

Epoch: 6| Step: 9
Training loss: 2.4654683381219353
Validation loss: 2.477298385919792

Epoch: 6| Step: 10
Training loss: 2.424581184794887
Validation loss: 2.476283179207958

Epoch: 6| Step: 11
Training loss: 2.6577488877602082
Validation loss: 2.481640918549385

Epoch: 6| Step: 12
Training loss: 1.8545138501935468
Validation loss: 2.4839094193570257

Epoch: 6| Step: 13
Training loss: 2.5520645348511795
Validation loss: 2.473598378305668

Epoch: 125| Step: 0
Training loss: 3.2328425660908553
Validation loss: 2.4855064910642777

Epoch: 6| Step: 1
Training loss: 2.3855211215630305
Validation loss: 2.481959679509248

Epoch: 6| Step: 2
Training loss: 2.4651293702445387
Validation loss: 2.4713667359405216

Epoch: 6| Step: 3
Training loss: 3.2549597235793906
Validation loss: 2.4844000540272533

Epoch: 6| Step: 4
Training loss: 2.6499063475272635
Validation loss: 2.486676089045634

Epoch: 6| Step: 5
Training loss: 1.4696222515413073
Validation loss: 2.46971360997634

Epoch: 6| Step: 6
Training loss: 2.414502051375689
Validation loss: 2.493076456646755

Epoch: 6| Step: 7
Training loss: 2.906457216812527
Validation loss: 2.4775007390966053

Epoch: 6| Step: 8
Training loss: 1.7025477279717385
Validation loss: 2.4982154691355496

Epoch: 6| Step: 9
Training loss: 3.0442167766243347
Validation loss: 2.4770276493392616

Epoch: 6| Step: 10
Training loss: 2.161995130930454
Validation loss: 2.4748229523119933

Epoch: 6| Step: 11
Training loss: 2.170577944952059
Validation loss: 2.481457077687893

Epoch: 6| Step: 12
Training loss: 2.500736509552728
Validation loss: 2.4714911556996757

Epoch: 6| Step: 13
Training loss: 2.3419904080071525
Validation loss: 2.463882342258021

Epoch: 126| Step: 0
Training loss: 2.4384719671374904
Validation loss: 2.4816448947269327

Epoch: 6| Step: 1
Training loss: 2.49353115488695
Validation loss: 2.480507459557275

Epoch: 6| Step: 2
Training loss: 1.8979786761887854
Validation loss: 2.4790592203065707

Epoch: 6| Step: 3
Training loss: 3.1632719582920306
Validation loss: 2.471559372841726

Epoch: 6| Step: 4
Training loss: 2.4205136318378466
Validation loss: 2.480701638495378

Epoch: 6| Step: 5
Training loss: 1.8679981467096909
Validation loss: 2.472756720769391

Epoch: 6| Step: 6
Training loss: 2.5837869143421224
Validation loss: 2.4991323647235646

Epoch: 6| Step: 7
Training loss: 2.2457442832754264
Validation loss: 2.4807630593493517

Epoch: 6| Step: 8
Training loss: 2.395242159234279
Validation loss: 2.4937502317582427

Epoch: 6| Step: 9
Training loss: 2.4735668849781383
Validation loss: 2.4726662478056673

Epoch: 6| Step: 10
Training loss: 2.2039426544330825
Validation loss: 2.471511084975501

Epoch: 6| Step: 11
Training loss: 2.791011695512017
Validation loss: 2.480484062743777

Epoch: 6| Step: 12
Training loss: 3.3394919405350327
Validation loss: 2.4758021942622612

Epoch: 6| Step: 13
Training loss: 2.817072140177217
Validation loss: 2.465328131190419

Epoch: 127| Step: 0
Training loss: 2.285592948724313
Validation loss: 2.4824679275792296

Epoch: 6| Step: 1
Training loss: 2.1658181460783648
Validation loss: 2.493680269480166

Epoch: 6| Step: 2
Training loss: 2.2610821659860862
Validation loss: 2.4865114170429305

Epoch: 6| Step: 3
Training loss: 3.2194519758936377
Validation loss: 2.4766757644554733

Epoch: 6| Step: 4
Training loss: 2.145930488633856
Validation loss: 2.4807545719541215

Epoch: 6| Step: 5
Training loss: 3.467460598876466
Validation loss: 2.481869673210408

Epoch: 6| Step: 6
Training loss: 2.7329679520169474
Validation loss: 2.4928779109915316

Epoch: 6| Step: 7
Training loss: 2.802282465745069
Validation loss: 2.4731655236939645

Epoch: 6| Step: 8
Training loss: 2.319420639900698
Validation loss: 2.4961191840099417

Epoch: 6| Step: 9
Training loss: 2.7978818988320455
Validation loss: 2.458306270872409

Epoch: 6| Step: 10
Training loss: 2.0150263880665413
Validation loss: 2.4702283016560878

Epoch: 6| Step: 11
Training loss: 2.575864783689178
Validation loss: 2.4877128197141576

Epoch: 6| Step: 12
Training loss: 2.095144803635172
Validation loss: 2.4865739609648827

Epoch: 6| Step: 13
Training loss: 1.4403491602225766
Validation loss: 2.4732615456698026

Epoch: 128| Step: 0
Training loss: 2.57008884929448
Validation loss: 2.470297645423054

Epoch: 6| Step: 1
Training loss: 2.2552250486346175
Validation loss: 2.4651522732191755

Epoch: 6| Step: 2
Training loss: 2.1774538689160154
Validation loss: 2.470614280661346

Epoch: 6| Step: 3
Training loss: 2.5405157537304097
Validation loss: 2.4801183955524824

Epoch: 6| Step: 4
Training loss: 2.7592126679759827
Validation loss: 2.5017392399771023

Epoch: 6| Step: 5
Training loss: 2.666609187301411
Validation loss: 2.46478759531085

Epoch: 6| Step: 6
Training loss: 3.2111617332554308
Validation loss: 2.479616817295064

Epoch: 6| Step: 7
Training loss: 2.472409204372275
Validation loss: 2.4762649334073994

Epoch: 6| Step: 8
Training loss: 2.1788469560227894
Validation loss: 2.4801228599981955

Epoch: 6| Step: 9
Training loss: 2.0232907982156907
Validation loss: 2.475891597956851

Epoch: 6| Step: 10
Training loss: 2.447917099540077
Validation loss: 2.4792632093389173

Epoch: 6| Step: 11
Training loss: 2.9337666913903906
Validation loss: 2.4691242314960657

Epoch: 6| Step: 12
Training loss: 2.4466610441048
Validation loss: 2.4815927968952667

Epoch: 6| Step: 13
Training loss: 2.310315517989604
Validation loss: 2.4709204554876045

Epoch: 129| Step: 0
Training loss: 2.7456446751185477
Validation loss: 2.47346861849278

Epoch: 6| Step: 1
Training loss: 2.8307398725983917
Validation loss: 2.492389891001119

Epoch: 6| Step: 2
Training loss: 3.018962693076465
Validation loss: 2.4937701764152664

Epoch: 6| Step: 3
Training loss: 1.8768967888958632
Validation loss: 2.4654104933564134

Epoch: 6| Step: 4
Training loss: 2.2979263702030917
Validation loss: 2.487898064448752

Epoch: 6| Step: 5
Training loss: 2.0907090151659538
Validation loss: 2.481269874616108

Epoch: 6| Step: 6
Training loss: 2.422346499907227
Validation loss: 2.470329341283721

Epoch: 6| Step: 7
Training loss: 2.9223797204137667
Validation loss: 2.4843974665485455

Epoch: 6| Step: 8
Training loss: 2.5393950728708217
Validation loss: 2.474627967107626

Epoch: 6| Step: 9
Training loss: 1.861258378378288
Validation loss: 2.4669965823403355

Epoch: 6| Step: 10
Training loss: 2.555219775637047
Validation loss: 2.4747181803313487

Epoch: 6| Step: 11
Training loss: 2.861348122797012
Validation loss: 2.4570000477602343

Epoch: 6| Step: 12
Training loss: 2.690192980314198
Validation loss: 2.468740865893774

Epoch: 6| Step: 13
Training loss: 1.8150884626704384
Validation loss: 2.496598429639543

Epoch: 130| Step: 0
Training loss: 2.243634863319418
Validation loss: 2.4798126978343262

Epoch: 6| Step: 1
Training loss: 2.775471889479256
Validation loss: 2.475236956101493

Epoch: 6| Step: 2
Training loss: 2.8343725168707254
Validation loss: 2.466421058663833

Epoch: 6| Step: 3
Training loss: 2.9274351693653955
Validation loss: 2.4835481202135585

Epoch: 6| Step: 4
Training loss: 2.875461707151892
Validation loss: 2.4771035671084767

Epoch: 6| Step: 5
Training loss: 2.713850583426851
Validation loss: 2.472790572113743

Epoch: 6| Step: 6
Training loss: 1.9539650293147297
Validation loss: 2.497934704532708

Epoch: 6| Step: 7
Training loss: 1.4504566920382407
Validation loss: 2.4818714560768473

Epoch: 6| Step: 8
Training loss: 2.1421449931105947
Validation loss: 2.459776799927545

Epoch: 6| Step: 9
Training loss: 2.76774696798833
Validation loss: 2.473862093147542

Epoch: 6| Step: 10
Training loss: 2.9598840938247823
Validation loss: 2.4973108205150054

Epoch: 6| Step: 11
Training loss: 2.319906077128028
Validation loss: 2.495523150321082

Epoch: 6| Step: 12
Training loss: 2.4081923336829894
Validation loss: 2.4674991041413055

Epoch: 6| Step: 13
Training loss: 2.3617873837728665
Validation loss: 2.4964971521130797

Epoch: 131| Step: 0
Training loss: 2.4161565395698297
Validation loss: 2.4824017772024134

Epoch: 6| Step: 1
Training loss: 1.988839841068564
Validation loss: 2.4865714602898232

Epoch: 6| Step: 2
Training loss: 2.1356922871185278
Validation loss: 2.4701348415101596

Epoch: 6| Step: 3
Training loss: 3.0580549094320664
Validation loss: 2.4697937073436647

Epoch: 6| Step: 4
Training loss: 2.760062275335995
Validation loss: 2.499255618157117

Epoch: 6| Step: 5
Training loss: 3.1066790831267252
Validation loss: 2.472795941902193

Epoch: 6| Step: 6
Training loss: 1.9502665239760504
Validation loss: 2.4591803878991456

Epoch: 6| Step: 7
Training loss: 1.7692451835287548
Validation loss: 2.4719802110349636

Epoch: 6| Step: 8
Training loss: 2.726061580955952
Validation loss: 2.4816109084821725

Epoch: 6| Step: 9
Training loss: 2.7135295513758804
Validation loss: 2.4661621449423956

Epoch: 6| Step: 10
Training loss: 2.773002225003483
Validation loss: 2.484747588552848

Epoch: 6| Step: 11
Training loss: 2.7083743067845396
Validation loss: 2.4761338369385872

Epoch: 6| Step: 12
Training loss: 2.151095989240261
Validation loss: 2.4709415109211275

Epoch: 6| Step: 13
Training loss: 2.3924119043025667
Validation loss: 2.475787190129275

Epoch: 132| Step: 0
Training loss: 2.6952631406825516
Validation loss: 2.485009105595786

Epoch: 6| Step: 1
Training loss: 1.8332276169323325
Validation loss: 2.474234328275686

Epoch: 6| Step: 2
Training loss: 2.410039815455101
Validation loss: 2.4720433362366747

Epoch: 6| Step: 3
Training loss: 2.1381162993056972
Validation loss: 2.50299784875714

Epoch: 6| Step: 4
Training loss: 2.8817424494006634
Validation loss: 2.472796880149582

Epoch: 6| Step: 5
Training loss: 2.2916679266723867
Validation loss: 2.4849252027702486

Epoch: 6| Step: 6
Training loss: 1.9490319661336974
Validation loss: 2.4769607109414764

Epoch: 6| Step: 7
Training loss: 2.8641815643618633
Validation loss: 2.467166573007882

Epoch: 6| Step: 8
Training loss: 3.087233027603137
Validation loss: 2.4911670573942315

Epoch: 6| Step: 9
Training loss: 2.9579686401231755
Validation loss: 2.477853558775729

Epoch: 6| Step: 10
Training loss: 1.9079804617563167
Validation loss: 2.4652423647156354

Epoch: 6| Step: 11
Training loss: 2.795447896511068
Validation loss: 2.466758791063202

Epoch: 6| Step: 12
Training loss: 2.6616284837971844
Validation loss: 2.4678952544435857

Epoch: 6| Step: 13
Training loss: 2.2638965195707295
Validation loss: 2.462102507154402

Epoch: 133| Step: 0
Training loss: 2.5525567270937857
Validation loss: 2.4725950202047486

Epoch: 6| Step: 1
Training loss: 2.1792792481418797
Validation loss: 2.4876834311388736

Epoch: 6| Step: 2
Training loss: 1.9905665366601886
Validation loss: 2.4593148070295765

Epoch: 6| Step: 3
Training loss: 3.242125728891981
Validation loss: 2.4575574323750806

Epoch: 6| Step: 4
Training loss: 2.888855758705251
Validation loss: 2.492318517333701

Epoch: 6| Step: 5
Training loss: 2.485660244521823
Validation loss: 2.4928230984458244

Epoch: 6| Step: 6
Training loss: 2.6226032759674562
Validation loss: 2.475426632830066

Epoch: 6| Step: 7
Training loss: 2.1230675381354156
Validation loss: 2.484402272085121

Epoch: 6| Step: 8
Training loss: 2.536215350806012
Validation loss: 2.474121977613396

Epoch: 6| Step: 9
Training loss: 2.4767457912259525
Validation loss: 2.4819613492074817

Epoch: 6| Step: 10
Training loss: 2.632479864552466
Validation loss: 2.492562521061113

Epoch: 6| Step: 11
Training loss: 2.6601555329936626
Validation loss: 2.4614177370054997

Epoch: 6| Step: 12
Training loss: 2.284365055673144
Validation loss: 2.4728501481724465

Epoch: 6| Step: 13
Training loss: 2.179978217969793
Validation loss: 2.487219721099826

Epoch: 134| Step: 0
Training loss: 2.4535454067881823
Validation loss: 2.486568148218902

Epoch: 6| Step: 1
Training loss: 2.874585494968501
Validation loss: 2.4759462655523428

Epoch: 6| Step: 2
Training loss: 2.42308654014719
Validation loss: 2.4683495265913127

Epoch: 6| Step: 3
Training loss: 2.8366146907983
Validation loss: 2.486691057374853

Epoch: 6| Step: 4
Training loss: 2.1183387469750996
Validation loss: 2.482942760261246

Epoch: 6| Step: 5
Training loss: 2.68277164843588
Validation loss: 2.473274138592231

Epoch: 6| Step: 6
Training loss: 2.766811051871637
Validation loss: 2.483377610529216

Epoch: 6| Step: 7
Training loss: 2.337357411650988
Validation loss: 2.4837044453106065

Epoch: 6| Step: 8
Training loss: 2.085551022505651
Validation loss: 2.485666373958678

Epoch: 6| Step: 9
Training loss: 2.454428259784339
Validation loss: 2.468258747712368

Epoch: 6| Step: 10
Training loss: 2.2046215845064165
Validation loss: 2.446839709424187

Epoch: 6| Step: 11
Training loss: 2.5913074436620067
Validation loss: 2.4762733864972843

Epoch: 6| Step: 12
Training loss: 2.442630357182317
Validation loss: 2.4955876451772268

Epoch: 6| Step: 13
Training loss: 2.6492528869895398
Validation loss: 2.4847170861970054

Epoch: 135| Step: 0
Training loss: 2.6028202899766364
Validation loss: 2.4529389926881233

Epoch: 6| Step: 1
Training loss: 2.2693196656024335
Validation loss: 2.462228356584469

Epoch: 6| Step: 2
Training loss: 2.6959178300102162
Validation loss: 2.4814299591971674

Epoch: 6| Step: 3
Training loss: 2.674387770852061
Validation loss: 2.480785763221379

Epoch: 6| Step: 4
Training loss: 2.39829097138672
Validation loss: 2.4665146865547003

Epoch: 6| Step: 5
Training loss: 2.469820007993944
Validation loss: 2.4589387938208165

Epoch: 6| Step: 6
Training loss: 2.781620901000628
Validation loss: 2.4756365846020607

Epoch: 6| Step: 7
Training loss: 2.6369570928156163
Validation loss: 2.472117695986258

Epoch: 6| Step: 8
Training loss: 2.854914787610839
Validation loss: 2.4841916948024663

Epoch: 6| Step: 9
Training loss: 2.5834430753306954
Validation loss: 2.481493797567415

Epoch: 6| Step: 10
Training loss: 2.509488125314111
Validation loss: 2.4780516022527785

Epoch: 6| Step: 11
Training loss: 1.8360891725913073
Validation loss: 2.4657042253577948

Epoch: 6| Step: 12
Training loss: 2.0740990900556975
Validation loss: 2.4867961960338625

Epoch: 6| Step: 13
Training loss: 2.4419110806184103
Validation loss: 2.4631460503869422

Epoch: 136| Step: 0
Training loss: 2.864802311706036
Validation loss: 2.4882303780923354

Epoch: 6| Step: 1
Training loss: 2.4630116274919702
Validation loss: 2.475622956234448

Epoch: 6| Step: 2
Training loss: 2.0975387227754534
Validation loss: 2.4641201936757047

Epoch: 6| Step: 3
Training loss: 2.0267902419830124
Validation loss: 2.494557878746586

Epoch: 6| Step: 4
Training loss: 1.8874004388281378
Validation loss: 2.4723481457729823

Epoch: 6| Step: 5
Training loss: 2.414985060714733
Validation loss: 2.4822252987257447

Epoch: 6| Step: 6
Training loss: 2.801286340602892
Validation loss: 2.4855050707766315

Epoch: 6| Step: 7
Training loss: 2.460914829694687
Validation loss: 2.458409890271925

Epoch: 6| Step: 8
Training loss: 2.1886783151091
Validation loss: 2.4749497718557802

Epoch: 6| Step: 9
Training loss: 2.419897244060988
Validation loss: 2.4578219681934184

Epoch: 6| Step: 10
Training loss: 2.299555764627187
Validation loss: 2.4760328219219963

Epoch: 6| Step: 11
Training loss: 2.672580023656751
Validation loss: 2.460506304421389

Epoch: 6| Step: 12
Training loss: 3.427272215549494
Validation loss: 2.4603194484644693

Epoch: 6| Step: 13
Training loss: 2.822458987888357
Validation loss: 2.4638960444097333

Epoch: 137| Step: 0
Training loss: 2.3333743523216564
Validation loss: 2.4626902016096652

Epoch: 6| Step: 1
Training loss: 2.4387873648983307
Validation loss: 2.4924861649147694

Epoch: 6| Step: 2
Training loss: 2.8862827988748028
Validation loss: 2.461889447652061

Epoch: 6| Step: 3
Training loss: 3.311151337930392
Validation loss: 2.4760861580329547

Epoch: 6| Step: 4
Training loss: 2.1028584735100546
Validation loss: 2.4652734589951724

Epoch: 6| Step: 5
Training loss: 2.6918002478302046
Validation loss: 2.4623001787120296

Epoch: 6| Step: 6
Training loss: 1.932876854752632
Validation loss: 2.476700659069943

Epoch: 6| Step: 7
Training loss: 2.431051086290717
Validation loss: 2.4728331812379114

Epoch: 6| Step: 8
Training loss: 2.4007049677529313
Validation loss: 2.46643706771662

Epoch: 6| Step: 9
Training loss: 1.9438479628822605
Validation loss: 2.4739995740336256

Epoch: 6| Step: 10
Training loss: 2.837955145945825
Validation loss: 2.4644251957004952

Epoch: 6| Step: 11
Training loss: 2.16702321371153
Validation loss: 2.4699779969918816

Epoch: 6| Step: 12
Training loss: 2.8029039923087087
Validation loss: 2.4702812940106593

Epoch: 6| Step: 13
Training loss: 2.0427121061387172
Validation loss: 2.459155595049033

Epoch: 138| Step: 0
Training loss: 2.146014036205567
Validation loss: 2.4701908237869925

Epoch: 6| Step: 1
Training loss: 2.2896174776853697
Validation loss: 2.4741455335445397

Epoch: 6| Step: 2
Training loss: 2.750102821508612
Validation loss: 2.4665512204141855

Epoch: 6| Step: 3
Training loss: 2.113045219172226
Validation loss: 2.4700381032708205

Epoch: 6| Step: 4
Training loss: 1.8794244063657266
Validation loss: 2.4709186273686696

Epoch: 6| Step: 5
Training loss: 2.506116061543883
Validation loss: 2.4391449993024095

Epoch: 6| Step: 6
Training loss: 2.657947491554129
Validation loss: 2.478856433813212

Epoch: 6| Step: 7
Training loss: 2.4848220710837765
Validation loss: 2.463090808304894

Epoch: 6| Step: 8
Training loss: 2.078026102337174
Validation loss: 2.475886366901427

Epoch: 6| Step: 9
Training loss: 3.0988840986491173
Validation loss: 2.4771690196589824

Epoch: 6| Step: 10
Training loss: 2.400099287363521
Validation loss: 2.4553575714924927

Epoch: 6| Step: 11
Training loss: 2.5630439553125135
Validation loss: 2.467820551907705

Epoch: 6| Step: 12
Training loss: 2.716990899316108
Validation loss: 2.472361498225539

Epoch: 6| Step: 13
Training loss: 3.0675636002616784
Validation loss: 2.4778402679919336

Epoch: 139| Step: 0
Training loss: 2.393089868741466
Validation loss: 2.473909798336562

Epoch: 6| Step: 1
Training loss: 2.831476912342206
Validation loss: 2.4755185168824503

Epoch: 6| Step: 2
Training loss: 2.8676070652124817
Validation loss: 2.4856875633559814

Epoch: 6| Step: 3
Training loss: 2.6521645037347525
Validation loss: 2.4759242793777205

Epoch: 6| Step: 4
Training loss: 1.64644093303455
Validation loss: 2.471866093329857

Epoch: 6| Step: 5
Training loss: 2.604903633107117
Validation loss: 2.4511756548206676

Epoch: 6| Step: 6
Training loss: 1.6099801268446883
Validation loss: 2.467860256626276

Epoch: 6| Step: 7
Training loss: 2.1118253815741355
Validation loss: 2.4581336150080424

Epoch: 6| Step: 8
Training loss: 2.7457676309955383
Validation loss: 2.4652629429726494

Epoch: 6| Step: 9
Training loss: 2.414295962997959
Validation loss: 2.473111071404452

Epoch: 6| Step: 10
Training loss: 2.9420076239284167
Validation loss: 2.442668764832171

Epoch: 6| Step: 11
Training loss: 2.3742074145855803
Validation loss: 2.4514799206784033

Epoch: 6| Step: 12
Training loss: 2.590729114754921
Validation loss: 2.482733370574615

Epoch: 6| Step: 13
Training loss: 2.502082910677969
Validation loss: 2.4709869858537448

Epoch: 140| Step: 0
Training loss: 1.5550968263905862
Validation loss: 2.48246182019343

Epoch: 6| Step: 1
Training loss: 3.2518325920793
Validation loss: 2.465481916040062

Epoch: 6| Step: 2
Training loss: 2.6271717533616594
Validation loss: 2.4712394809546225

Epoch: 6| Step: 3
Training loss: 2.499000444861743
Validation loss: 2.4692612608370275

Epoch: 6| Step: 4
Training loss: 1.8566177825838817
Validation loss: 2.4644681060131113

Epoch: 6| Step: 5
Training loss: 2.246504930094733
Validation loss: 2.479084951105873

Epoch: 6| Step: 6
Training loss: 2.857546195443608
Validation loss: 2.4668083961973895

Epoch: 6| Step: 7
Training loss: 2.3836986457401896
Validation loss: 2.4741077539023264

Epoch: 6| Step: 8
Training loss: 2.5678106033561456
Validation loss: 2.4668404850362213

Epoch: 6| Step: 9
Training loss: 2.948791553807698
Validation loss: 2.4623062653073036

Epoch: 6| Step: 10
Training loss: 2.161092544918291
Validation loss: 2.4844894171291796

Epoch: 6| Step: 11
Training loss: 2.5576537290965375
Validation loss: 2.497678371930917

Epoch: 6| Step: 12
Training loss: 1.8903858884823086
Validation loss: 2.481396752615406

Epoch: 6| Step: 13
Training loss: 3.1850398424372335
Validation loss: 2.4783086283749234

Epoch: 141| Step: 0
Training loss: 1.9767676084946795
Validation loss: 2.453547299050452

Epoch: 6| Step: 1
Training loss: 2.205126671472083
Validation loss: 2.4702631242639894

Epoch: 6| Step: 2
Training loss: 2.6520150926255437
Validation loss: 2.477419518756818

Epoch: 6| Step: 3
Training loss: 2.319771443487119
Validation loss: 2.477322309544971

Epoch: 6| Step: 4
Training loss: 1.887695249349294
Validation loss: 2.477099988301422

Epoch: 6| Step: 5
Training loss: 3.3413393832266376
Validation loss: 2.468956069165312

Epoch: 6| Step: 6
Training loss: 2.0228521612420063
Validation loss: 2.4583497968914627

Epoch: 6| Step: 7
Training loss: 2.4769534214647058
Validation loss: 2.486209641106262

Epoch: 6| Step: 8
Training loss: 2.7932586306079537
Validation loss: 2.4562025275025565

Epoch: 6| Step: 9
Training loss: 2.6335766868977792
Validation loss: 2.501765837561589

Epoch: 6| Step: 10
Training loss: 2.177615804822859
Validation loss: 2.4704464906035475

Epoch: 6| Step: 11
Training loss: 2.1734729624089537
Validation loss: 2.4580110457202946

Epoch: 6| Step: 12
Training loss: 2.5128736910789793
Validation loss: 2.4658531617102906

Epoch: 6| Step: 13
Training loss: 3.40178380622138
Validation loss: 2.469939971446145

Epoch: 142| Step: 0
Training loss: 2.8016431857488002
Validation loss: 2.476841925918034

Epoch: 6| Step: 1
Training loss: 2.099160335339908
Validation loss: 2.463555396035104

Epoch: 6| Step: 2
Training loss: 2.7231137563120043
Validation loss: 2.46502359032978

Epoch: 6| Step: 3
Training loss: 2.4821462170537965
Validation loss: 2.4830048231147144

Epoch: 6| Step: 4
Training loss: 2.6005457818787696
Validation loss: 2.475101371048976

Epoch: 6| Step: 5
Training loss: 2.736268526853643
Validation loss: 2.4850469542021214

Epoch: 6| Step: 6
Training loss: 2.635779093271633
Validation loss: 2.475763322083699

Epoch: 6| Step: 7
Training loss: 2.175587725978931
Validation loss: 2.4990791665590275

Epoch: 6| Step: 8
Training loss: 2.8760780303619993
Validation loss: 2.4810246765829596

Epoch: 6| Step: 9
Training loss: 2.4819170230640264
Validation loss: 2.4728511734832863

Epoch: 6| Step: 10
Training loss: 2.3824644741359773
Validation loss: 2.495322090146062

Epoch: 6| Step: 11
Training loss: 1.8779857387102796
Validation loss: 2.4745495931728962

Epoch: 6| Step: 12
Training loss: 1.789359255503927
Validation loss: 2.4791973177954914

Epoch: 6| Step: 13
Training loss: 2.889034844240857
Validation loss: 2.4839544205336246

Epoch: 143| Step: 0
Training loss: 2.5017465212803396
Validation loss: 2.4718743644089085

Epoch: 6| Step: 1
Training loss: 3.1173043671309966
Validation loss: 2.456191035881198

Epoch: 6| Step: 2
Training loss: 1.8997088912008
Validation loss: 2.4720969917537277

Epoch: 6| Step: 3
Training loss: 2.6910234464193112
Validation loss: 2.4476848470709234

Epoch: 6| Step: 4
Training loss: 1.9309472670819736
Validation loss: 2.487338446498631

Epoch: 6| Step: 5
Training loss: 2.376119249530267
Validation loss: 2.4677175634854747

Epoch: 6| Step: 6
Training loss: 1.8722712688014769
Validation loss: 2.472469234958027

Epoch: 6| Step: 7
Training loss: 2.1778519534542635
Validation loss: 2.4854803007058064

Epoch: 6| Step: 8
Training loss: 2.701223597717472
Validation loss: 2.455407497793661

Epoch: 6| Step: 9
Training loss: 1.8428678826983378
Validation loss: 2.47828506494663

Epoch: 6| Step: 10
Training loss: 2.3247161076638347
Validation loss: 2.4743693148436883

Epoch: 6| Step: 11
Training loss: 2.772692857093813
Validation loss: 2.460168077358008

Epoch: 6| Step: 12
Training loss: 3.4231347678398443
Validation loss: 2.4556673178481554

Epoch: 6| Step: 13
Training loss: 2.5820589511326077
Validation loss: 2.4662095084285576

Epoch: 144| Step: 0
Training loss: 2.540964957339772
Validation loss: 2.4543452533237153

Epoch: 6| Step: 1
Training loss: 2.259679319535458
Validation loss: 2.4639197392030274

Epoch: 6| Step: 2
Training loss: 2.106453801378062
Validation loss: 2.4532256760534863

Epoch: 6| Step: 3
Training loss: 1.9928147469194297
Validation loss: 2.4520112244614873

Epoch: 6| Step: 4
Training loss: 3.03870787917351
Validation loss: 2.448829231179973

Epoch: 6| Step: 5
Training loss: 2.2123236203337036
Validation loss: 2.4665567165565174

Epoch: 6| Step: 6
Training loss: 3.23531309520031
Validation loss: 2.4707180147420718

Epoch: 6| Step: 7
Training loss: 2.6224284518857726
Validation loss: 2.4779722725445708

Epoch: 6| Step: 8
Training loss: 2.467097634822362
Validation loss: 2.4686691854553797

Epoch: 6| Step: 9
Training loss: 1.7217450489223918
Validation loss: 2.4640689977400405

Epoch: 6| Step: 10
Training loss: 1.6742192882941054
Validation loss: 2.473125538229043

Epoch: 6| Step: 11
Training loss: 2.1042216328406917
Validation loss: 2.455425741971086

Epoch: 6| Step: 12
Training loss: 3.1329397427790986
Validation loss: 2.4502024806943936

Epoch: 6| Step: 13
Training loss: 3.1165264451685726
Validation loss: 2.4636294791916105

Epoch: 145| Step: 0
Training loss: 2.3785609603874045
Validation loss: 2.4533545812051285

Epoch: 6| Step: 1
Training loss: 2.760403547915589
Validation loss: 2.4717041218746796

Epoch: 6| Step: 2
Training loss: 3.2528873235852185
Validation loss: 2.447558330489511

Epoch: 6| Step: 3
Training loss: 2.0717474804698695
Validation loss: 2.4520646701048516

Epoch: 6| Step: 4
Training loss: 2.8050522420985495
Validation loss: 2.493909844170016

Epoch: 6| Step: 5
Training loss: 2.3638385714554695
Validation loss: 2.473136036886246

Epoch: 6| Step: 6
Training loss: 2.2083287029097853
Validation loss: 2.4834387902266335

Epoch: 6| Step: 7
Training loss: 2.476157940573961
Validation loss: 2.4510729512345897

Epoch: 6| Step: 8
Training loss: 1.7037383208850607
Validation loss: 2.440551671250101

Epoch: 6| Step: 9
Training loss: 2.706393344245595
Validation loss: 2.4263939474990366

Epoch: 6| Step: 10
Training loss: 2.2861246779409954
Validation loss: 2.4529308829868817

Epoch: 6| Step: 11
Training loss: 1.7782249865049742
Validation loss: 2.4580240025472095

Epoch: 6| Step: 12
Training loss: 2.81236165024305
Validation loss: 2.4515890038056156

Epoch: 6| Step: 13
Training loss: 2.1981867643848974
Validation loss: 2.4606357267685124

Epoch: 146| Step: 0
Training loss: 2.0412139650190446
Validation loss: 2.460979592958984

Epoch: 6| Step: 1
Training loss: 2.208456527824473
Validation loss: 2.462385671820493

Epoch: 6| Step: 2
Training loss: 2.3988221695674934
Validation loss: 2.470765458983738

Epoch: 6| Step: 3
Training loss: 2.85367570724395
Validation loss: 2.4613300438175014

Epoch: 6| Step: 4
Training loss: 2.4207328810562725
Validation loss: 2.4644108036743875

Epoch: 6| Step: 5
Training loss: 2.36981216813047
Validation loss: 2.4729261024427016

Epoch: 6| Step: 6
Training loss: 2.5609835347663283
Validation loss: 2.4849224234303606

Epoch: 6| Step: 7
Training loss: 2.2315570694798965
Validation loss: 2.4600851978722345

Epoch: 6| Step: 8
Training loss: 2.264328368525699
Validation loss: 2.4753846208685144

Epoch: 6| Step: 9
Training loss: 2.4365702102850304
Validation loss: 2.4687708548364236

Epoch: 6| Step: 10
Training loss: 1.9171785486536204
Validation loss: 2.4722119356455807

Epoch: 6| Step: 11
Training loss: 2.662574150951287
Validation loss: 2.447140320825917

Epoch: 6| Step: 12
Training loss: 3.1131173620798505
Validation loss: 2.475623766555125

Epoch: 6| Step: 13
Training loss: 2.950887649956951
Validation loss: 2.4645108803496316

Epoch: 147| Step: 0
Training loss: 1.95315600561327
Validation loss: 2.457842295142546

Epoch: 6| Step: 1
Training loss: 2.7735879346855232
Validation loss: 2.4684519371704536

Epoch: 6| Step: 2
Training loss: 2.1917841784324157
Validation loss: 2.4701313885657243

Epoch: 6| Step: 3
Training loss: 2.350933916098568
Validation loss: 2.4650253177800243

Epoch: 6| Step: 4
Training loss: 1.989699601642419
Validation loss: 2.4726064791336952

Epoch: 6| Step: 5
Training loss: 2.6673245413223032
Validation loss: 2.468094101663864

Epoch: 6| Step: 6
Training loss: 3.1283456821702615
Validation loss: 2.4680335200807924

Epoch: 6| Step: 7
Training loss: 2.0348184784857253
Validation loss: 2.433527549989256

Epoch: 6| Step: 8
Training loss: 2.7487796329776253
Validation loss: 2.4803792776995808

Epoch: 6| Step: 9
Training loss: 2.171364484106562
Validation loss: 2.4628408306179126

Epoch: 6| Step: 10
Training loss: 2.485531136071594
Validation loss: 2.4564515072583366

Epoch: 6| Step: 11
Training loss: 2.4001851129668244
Validation loss: 2.451607865127067

Epoch: 6| Step: 12
Training loss: 2.7543982100195916
Validation loss: 2.467332904960082

Epoch: 6| Step: 13
Training loss: 2.3968126589788388
Validation loss: 2.4693621863828286

Epoch: 148| Step: 0
Training loss: 2.828286856556235
Validation loss: 2.451485663943016

Epoch: 6| Step: 1
Training loss: 2.3396865206003463
Validation loss: 2.453682611349473

Epoch: 6| Step: 2
Training loss: 2.2125288018544853
Validation loss: 2.453869638892273

Epoch: 6| Step: 3
Training loss: 2.6343172114539937
Validation loss: 2.462329614121835

Epoch: 6| Step: 4
Training loss: 2.358637107003313
Validation loss: 2.439155704128315

Epoch: 6| Step: 5
Training loss: 2.3927010889958105
Validation loss: 2.4765945193895837

Epoch: 6| Step: 6
Training loss: 2.887378415937421
Validation loss: 2.45517809080367

Epoch: 6| Step: 7
Training loss: 2.0532401321157288
Validation loss: 2.4690745306412194

Epoch: 6| Step: 8
Training loss: 2.310638503307852
Validation loss: 2.4685498757881206

Epoch: 6| Step: 9
Training loss: 2.9263693774811603
Validation loss: 2.4517166801032535

Epoch: 6| Step: 10
Training loss: 1.647764095504819
Validation loss: 2.4633401897910088

Epoch: 6| Step: 11
Training loss: 2.269801847573064
Validation loss: 2.4495044652879567

Epoch: 6| Step: 12
Training loss: 2.2704647593364387
Validation loss: 2.449120068700132

Epoch: 6| Step: 13
Training loss: 3.2686820437075927
Validation loss: 2.462271588379639

Epoch: 149| Step: 0
Training loss: 2.5988001549134596
Validation loss: 2.472714138838905

Epoch: 6| Step: 1
Training loss: 2.2037614484761163
Validation loss: 2.471859696318327

Epoch: 6| Step: 2
Training loss: 1.6284004725212624
Validation loss: 2.471474133794659

Epoch: 6| Step: 3
Training loss: 2.554201318983915
Validation loss: 2.4709080850514202

Epoch: 6| Step: 4
Training loss: 2.7486766752322507
Validation loss: 2.479435158972251

Epoch: 6| Step: 5
Training loss: 2.4836558134730713
Validation loss: 2.4615985483202114

Epoch: 6| Step: 6
Training loss: 2.5995091305040603
Validation loss: 2.467094689919901

Epoch: 6| Step: 7
Training loss: 2.838112913642355
Validation loss: 2.4502335890130373

Epoch: 6| Step: 8
Training loss: 1.87990982630753
Validation loss: 2.4595544937324525

Epoch: 6| Step: 9
Training loss: 2.089271196028462
Validation loss: 2.478600479155536

Epoch: 6| Step: 10
Training loss: 2.057918430576571
Validation loss: 2.4576027011948116

Epoch: 6| Step: 11
Training loss: 2.461572571206348
Validation loss: 2.465473562166677

Epoch: 6| Step: 12
Training loss: 2.693476928181581
Validation loss: 2.4480671316458444

Epoch: 6| Step: 13
Training loss: 3.778665589434951
Validation loss: 2.4356100592587477

Epoch: 150| Step: 0
Training loss: 2.4216123376971206
Validation loss: 2.462346162014981

Epoch: 6| Step: 1
Training loss: 1.6588641714835373
Validation loss: 2.4663394776110175

Epoch: 6| Step: 2
Training loss: 1.7649516619366035
Validation loss: 2.449359752947097

Epoch: 6| Step: 3
Training loss: 2.7604701390875332
Validation loss: 2.460673158469265

Epoch: 6| Step: 4
Training loss: 2.806801172176147
Validation loss: 2.4487978919774105

Epoch: 6| Step: 5
Training loss: 2.41243375380882
Validation loss: 2.4296771206459487

Epoch: 6| Step: 6
Training loss: 2.0266106075556256
Validation loss: 2.444313268445068

Epoch: 6| Step: 7
Training loss: 2.4861221407948153
Validation loss: 2.466520707143322

Epoch: 6| Step: 8
Training loss: 2.4502118544554197
Validation loss: 2.4695071410236276

Epoch: 6| Step: 9
Training loss: 3.5445678197846258
Validation loss: 2.4523205404444273

Epoch: 6| Step: 10
Training loss: 2.4589039953788334
Validation loss: 2.4470909518614294

Epoch: 6| Step: 11
Training loss: 2.170360338907322
Validation loss: 2.4634865243399653

Epoch: 6| Step: 12
Training loss: 2.336089164377794
Validation loss: 2.4562113846773883

Epoch: 6| Step: 13
Training loss: 2.415605268114046
Validation loss: 2.4635162941900592

Epoch: 151| Step: 0
Training loss: 2.1739275996094043
Validation loss: 2.445550514832196

Epoch: 6| Step: 1
Training loss: 1.715405348316602
Validation loss: 2.4593157181050898

Epoch: 6| Step: 2
Training loss: 2.083596047685155
Validation loss: 2.470770578445703

Epoch: 6| Step: 3
Training loss: 1.722462476700894
Validation loss: 2.4650438433337833

Epoch: 6| Step: 4
Training loss: 2.6946282001859827
Validation loss: 2.4688578320286134

Epoch: 6| Step: 5
Training loss: 2.5988257507469332
Validation loss: 2.4767815603751475

Epoch: 6| Step: 6
Training loss: 2.389443099128876
Validation loss: 2.4607679364316692

Epoch: 6| Step: 7
Training loss: 2.7916984176728
Validation loss: 2.444623037246918

Epoch: 6| Step: 8
Training loss: 2.8792638259003263
Validation loss: 2.443639624466827

Epoch: 6| Step: 9
Training loss: 2.4047785632047947
Validation loss: 2.4562403565800177

Epoch: 6| Step: 10
Training loss: 2.217647654747135
Validation loss: 2.45555425235498

Epoch: 6| Step: 11
Training loss: 3.1285017611715227
Validation loss: 2.462078643890935

Epoch: 6| Step: 12
Training loss: 2.381885585916539
Validation loss: 2.4520476701693523

Epoch: 6| Step: 13
Training loss: 2.622468363350159
Validation loss: 2.4596956686764755

Epoch: 152| Step: 0
Training loss: 2.6177174501352654
Validation loss: 2.4510425668994245

Epoch: 6| Step: 1
Training loss: 1.8879787115901177
Validation loss: 2.480937975071375

Epoch: 6| Step: 2
Training loss: 2.7826743604075084
Validation loss: 2.4397151716324776

Epoch: 6| Step: 3
Training loss: 2.8457748414521813
Validation loss: 2.453875735428987

Epoch: 6| Step: 4
Training loss: 2.5236884308286625
Validation loss: 2.4816981928659545

Epoch: 6| Step: 5
Training loss: 2.8695962958229817
Validation loss: 2.473843254344566

Epoch: 6| Step: 6
Training loss: 2.43077705706123
Validation loss: 2.471850878620627

Epoch: 6| Step: 7
Training loss: 2.45746845182424
Validation loss: 2.45707043000716

Epoch: 6| Step: 8
Training loss: 2.1032673893831655
Validation loss: 2.438744878387367

Epoch: 6| Step: 9
Training loss: 2.338433402655719
Validation loss: 2.44749467537954

Epoch: 6| Step: 10
Training loss: 2.808368021206516
Validation loss: 2.4639011916711224

Epoch: 6| Step: 11
Training loss: 1.879845081297484
Validation loss: 2.4303004975297258

Epoch: 6| Step: 12
Training loss: 1.998081121216471
Validation loss: 2.4713831242578452

Epoch: 6| Step: 13
Training loss: 2.008209308050076
Validation loss: 2.45196202048507

Epoch: 153| Step: 0
Training loss: 2.3366274628046426
Validation loss: 2.469739968570716

Epoch: 6| Step: 1
Training loss: 2.4503243367906933
Validation loss: 2.4343110325516686

Epoch: 6| Step: 2
Training loss: 2.195992035411851
Validation loss: 2.4607264514020986

Epoch: 6| Step: 3
Training loss: 2.6308003782186518
Validation loss: 2.452384037885855

Epoch: 6| Step: 4
Training loss: 2.3983410744434983
Validation loss: 2.454237740487517

Epoch: 6| Step: 5
Training loss: 1.3845584429236033
Validation loss: 2.470577544354547

Epoch: 6| Step: 6
Training loss: 2.6607855277979406
Validation loss: 2.4464181639129707

Epoch: 6| Step: 7
Training loss: 2.829700010325741
Validation loss: 2.455483016990796

Epoch: 6| Step: 8
Training loss: 2.1079047836790172
Validation loss: 2.463348904221512

Epoch: 6| Step: 9
Training loss: 2.907475694995951
Validation loss: 2.4669965574001407

Epoch: 6| Step: 10
Training loss: 2.2680823318365797
Validation loss: 2.458985415475425

Epoch: 6| Step: 11
Training loss: 2.444401678038745
Validation loss: 2.4660414363418175

Epoch: 6| Step: 12
Training loss: 2.2885103047901305
Validation loss: 2.4666900898747803

Epoch: 6| Step: 13
Training loss: 2.8756529025220847
Validation loss: 2.470837484293759

Epoch: 154| Step: 0
Training loss: 2.5381098911612545
Validation loss: 2.461206745212236

Epoch: 6| Step: 1
Training loss: 2.6030945262064002
Validation loss: 2.4770753582480243

Epoch: 6| Step: 2
Training loss: 2.072289555705367
Validation loss: 2.4619108593972414

Epoch: 6| Step: 3
Training loss: 2.431474525263301
Validation loss: 2.4566900828093967

Epoch: 6| Step: 4
Training loss: 3.0002466736151985
Validation loss: 2.4438093998308434

Epoch: 6| Step: 5
Training loss: 2.6940175359504974
Validation loss: 2.4537344481772574

Epoch: 6| Step: 6
Training loss: 2.802529187284417
Validation loss: 2.4417281352826605

Epoch: 6| Step: 7
Training loss: 2.016653109208031
Validation loss: 2.4546428076534523

Epoch: 6| Step: 8
Training loss: 2.3416572891898313
Validation loss: 2.4547255168506723

Epoch: 6| Step: 9
Training loss: 2.673825093303157
Validation loss: 2.4536423533115244

Epoch: 6| Step: 10
Training loss: 2.2096890540610477
Validation loss: 2.4415990893263055

Epoch: 6| Step: 11
Training loss: 1.7270813589541105
Validation loss: 2.4559550527854705

Epoch: 6| Step: 12
Training loss: 2.1306398385276184
Validation loss: 2.4562464013086744

Epoch: 6| Step: 13
Training loss: 2.501141192325322
Validation loss: 2.459786435277897

Epoch: 155| Step: 0
Training loss: 1.928066978632648
Validation loss: 2.453903938831417

Epoch: 6| Step: 1
Training loss: 2.0928679928621574
Validation loss: 2.473949713095568

Epoch: 6| Step: 2
Training loss: 1.746372209230672
Validation loss: 2.4553228089566703

Epoch: 6| Step: 3
Training loss: 3.070063379484654
Validation loss: 2.4490899741686087

Epoch: 6| Step: 4
Training loss: 1.96450748182558
Validation loss: 2.4393826574527417

Epoch: 6| Step: 5
Training loss: 2.242298402602173
Validation loss: 2.4408417064016867

Epoch: 6| Step: 6
Training loss: 2.7672609135320094
Validation loss: 2.4288082214069746

Epoch: 6| Step: 7
Training loss: 2.2443828402249233
Validation loss: 2.4466704880155166

Epoch: 6| Step: 8
Training loss: 3.0136843747209183
Validation loss: 2.443670418724981

Epoch: 6| Step: 9
Training loss: 2.8194047729841456
Validation loss: 2.4785066830699796

Epoch: 6| Step: 10
Training loss: 2.340479285233461
Validation loss: 2.463672994931299

Epoch: 6| Step: 11
Training loss: 2.1886279876355688
Validation loss: 2.4316835761647466

Epoch: 6| Step: 12
Training loss: 2.0333600162360432
Validation loss: 2.4546177877654793

Epoch: 6| Step: 13
Training loss: 3.0849154940859975
Validation loss: 2.4492019710576725

Epoch: 156| Step: 0
Training loss: 2.026323653523327
Validation loss: 2.467801727237044

Epoch: 6| Step: 1
Training loss: 2.4394192109144277
Validation loss: 2.462653315866238

Epoch: 6| Step: 2
Training loss: 2.624653747973803
Validation loss: 2.4628227215222895

Epoch: 6| Step: 3
Training loss: 2.7110071530587203
Validation loss: 2.4578712738968105

Epoch: 6| Step: 4
Training loss: 2.131235063338307
Validation loss: 2.4606079693486285

Epoch: 6| Step: 5
Training loss: 2.0726944949708392
Validation loss: 2.4638550740314664

Epoch: 6| Step: 6
Training loss: 3.150869788324112
Validation loss: 2.4796146140834296

Epoch: 6| Step: 7
Training loss: 2.721279677446944
Validation loss: 2.4479946379766373

Epoch: 6| Step: 8
Training loss: 1.9407089485525497
Validation loss: 2.452369514563136

Epoch: 6| Step: 9
Training loss: 2.2962739119014097
Validation loss: 2.4561911360808537

Epoch: 6| Step: 10
Training loss: 2.54996962435713
Validation loss: 2.4487962446834834

Epoch: 6| Step: 11
Training loss: 2.3793516947810125
Validation loss: 2.437002143784593

Epoch: 6| Step: 12
Training loss: 2.2452860300392583
Validation loss: 2.439975871515356

Epoch: 6| Step: 13
Training loss: 2.3567960678070374
Validation loss: 2.4528061885782666

Epoch: 157| Step: 0
Training loss: 2.304344229268998
Validation loss: 2.4340893316812053

Epoch: 6| Step: 1
Training loss: 2.2231825488698327
Validation loss: 2.459720928221545

Epoch: 6| Step: 2
Training loss: 2.723106401794536
Validation loss: 2.4490969524691732

Epoch: 6| Step: 3
Training loss: 2.020253507928549
Validation loss: 2.450901433261595

Epoch: 6| Step: 4
Training loss: 2.186347657907542
Validation loss: 2.472239412937984

Epoch: 6| Step: 5
Training loss: 2.36604911197307
Validation loss: 2.473459963036129

Epoch: 6| Step: 6
Training loss: 2.3698960724911924
Validation loss: 2.466254627792312

Epoch: 6| Step: 7
Training loss: 2.4448426986675496
Validation loss: 2.445753270436039

Epoch: 6| Step: 8
Training loss: 2.1646558037804375
Validation loss: 2.4505315086910997

Epoch: 6| Step: 9
Training loss: 2.9201436344510854
Validation loss: 2.4334673488807037

Epoch: 6| Step: 10
Training loss: 3.0186760050232655
Validation loss: 2.4491783285687303

Epoch: 6| Step: 11
Training loss: 2.313807762080351
Validation loss: 2.45197254284381

Epoch: 6| Step: 12
Training loss: 1.7492048636971842
Validation loss: 2.4474561926262512

Epoch: 6| Step: 13
Training loss: 3.204262731440668
Validation loss: 2.4663467506434773

Epoch: 158| Step: 0
Training loss: 2.0497906135995527
Validation loss: 2.4688354930142755

Epoch: 6| Step: 1
Training loss: 2.0392639528344128
Validation loss: 2.464660469223706

Epoch: 6| Step: 2
Training loss: 2.636812787674941
Validation loss: 2.435871334259081

Epoch: 6| Step: 3
Training loss: 2.1587260307567284
Validation loss: 2.467837238542507

Epoch: 6| Step: 4
Training loss: 2.0616331879907617
Validation loss: 2.455067119945237

Epoch: 6| Step: 5
Training loss: 2.1716064726225226
Validation loss: 2.459646453743196

Epoch: 6| Step: 6
Training loss: 2.571820219807651
Validation loss: 2.4691687089051095

Epoch: 6| Step: 7
Training loss: 3.2086229730301192
Validation loss: 2.474724638325231

Epoch: 6| Step: 8
Training loss: 2.187499128069023
Validation loss: 2.4689919252085617

Epoch: 6| Step: 9
Training loss: 2.1543151356674515
Validation loss: 2.462248982936997

Epoch: 6| Step: 10
Training loss: 2.766098240595141
Validation loss: 2.452514782596635

Epoch: 6| Step: 11
Training loss: 2.693829556947649
Validation loss: 2.4699754748439386

Epoch: 6| Step: 12
Training loss: 2.6546315367459625
Validation loss: 2.465127116646061

Epoch: 6| Step: 13
Training loss: 2.0420397073843652
Validation loss: 2.461786018448836

Epoch: 159| Step: 0
Training loss: 1.5445305368424709
Validation loss: 2.4597135334567803

Epoch: 6| Step: 1
Training loss: 2.813063331984088
Validation loss: 2.460233551146764

Epoch: 6| Step: 2
Training loss: 2.087811374855281
Validation loss: 2.453769289633313

Epoch: 6| Step: 3
Training loss: 2.724854904651587
Validation loss: 2.4529446750544732

Epoch: 6| Step: 4
Training loss: 2.3500231396773614
Validation loss: 2.4624335191796574

Epoch: 6| Step: 5
Training loss: 2.004333331606051
Validation loss: 2.458960207280101

Epoch: 6| Step: 6
Training loss: 3.167266655014201
Validation loss: 2.4306947659083162

Epoch: 6| Step: 7
Training loss: 2.6164615364418577
Validation loss: 2.462507055170565

Epoch: 6| Step: 8
Training loss: 2.1582321786435243
Validation loss: 2.449522638830119

Epoch: 6| Step: 9
Training loss: 2.5365558164272817
Validation loss: 2.4461698570564714

Epoch: 6| Step: 10
Training loss: 2.557793738238689
Validation loss: 2.45600957386045

Epoch: 6| Step: 11
Training loss: 1.734775943635223
Validation loss: 2.4736054662441713

Epoch: 6| Step: 12
Training loss: 1.9294464331410177
Validation loss: 2.457662701228845

Epoch: 6| Step: 13
Training loss: 2.9041371202174497
Validation loss: 2.458372633717039

Epoch: 160| Step: 0
Training loss: 2.4822073062633367
Validation loss: 2.424596724676955

Epoch: 6| Step: 1
Training loss: 2.9274328889655137
Validation loss: 2.429004663055645

Epoch: 6| Step: 2
Training loss: 2.329609647149767
Validation loss: 2.4648823918789966

Epoch: 6| Step: 3
Training loss: 2.3409042375182625
Validation loss: 2.4485876182776254

Epoch: 6| Step: 4
Training loss: 2.415306881663505
Validation loss: 2.461764329651224

Epoch: 6| Step: 5
Training loss: 2.306364218925397
Validation loss: 2.4160600444717235

Epoch: 6| Step: 6
Training loss: 1.9323120184663747
Validation loss: 2.4532930358265754

Epoch: 6| Step: 7
Training loss: 2.0914608412106075
Validation loss: 2.448310834628714

Epoch: 6| Step: 8
Training loss: 1.3797088967000173
Validation loss: 2.454629399548508

Epoch: 6| Step: 9
Training loss: 2.6219682897400465
Validation loss: 2.434199645414382

Epoch: 6| Step: 10
Training loss: 2.6827985759855886
Validation loss: 2.4354315953972736

Epoch: 6| Step: 11
Training loss: 3.681992895945213
Validation loss: 2.4332718169521685

Epoch: 6| Step: 12
Training loss: 1.9585584213545963
Validation loss: 2.439964518861491

Epoch: 6| Step: 13
Training loss: 2.055337897223991
Validation loss: 2.4436880639023593

Epoch: 161| Step: 0
Training loss: 2.4071759510716544
Validation loss: 2.4510973086354775

Epoch: 6| Step: 1
Training loss: 2.3111483773666697
Validation loss: 2.453153594517705

Epoch: 6| Step: 2
Training loss: 1.796617970535072
Validation loss: 2.42209121633413

Epoch: 6| Step: 3
Training loss: 2.711833179271857
Validation loss: 2.470107088086254

Epoch: 6| Step: 4
Training loss: 2.379056477931789
Validation loss: 2.431151147423894

Epoch: 6| Step: 5
Training loss: 2.4786429827158654
Validation loss: 2.464002578146896

Epoch: 6| Step: 6
Training loss: 2.905692426457565
Validation loss: 2.473327750824448

Epoch: 6| Step: 7
Training loss: 1.9908669077726193
Validation loss: 2.456296305890669

Epoch: 6| Step: 8
Training loss: 2.0526306532653082
Validation loss: 2.452870654852522

Epoch: 6| Step: 9
Training loss: 2.1192837293271105
Validation loss: 2.4873058593945134

Epoch: 6| Step: 10
Training loss: 2.5763499304701214
Validation loss: 2.4776453376175858

Epoch: 6| Step: 11
Training loss: 2.5766987872702205
Validation loss: 2.466962433781481

Epoch: 6| Step: 12
Training loss: 2.5104153159574514
Validation loss: 2.473895045940606

Epoch: 6| Step: 13
Training loss: 2.846355041522386
Validation loss: 2.4538465506882954

Epoch: 162| Step: 0
Training loss: 2.4798238081025388
Validation loss: 2.4700644443910225

Epoch: 6| Step: 1
Training loss: 2.69426169436606
Validation loss: 2.445562795492299

Epoch: 6| Step: 2
Training loss: 2.997382134418133
Validation loss: 2.4600412419441384

Epoch: 6| Step: 3
Training loss: 2.37321274417096
Validation loss: 2.4889445491728623

Epoch: 6| Step: 4
Training loss: 1.8601224022244676
Validation loss: 2.4243924936869954

Epoch: 6| Step: 5
Training loss: 2.9173383938340414
Validation loss: 2.45186066205393

Epoch: 6| Step: 6
Training loss: 2.368144128459917
Validation loss: 2.473858825720354

Epoch: 6| Step: 7
Training loss: 1.986540566395772
Validation loss: 2.444786590003671

Epoch: 6| Step: 8
Training loss: 2.4906093659143584
Validation loss: 2.4301707920015163

Epoch: 6| Step: 9
Training loss: 2.44928192592589
Validation loss: 2.4575521961971956

Epoch: 6| Step: 10
Training loss: 1.920529274309935
Validation loss: 2.445008889487536

Epoch: 6| Step: 11
Training loss: 1.809111551926819
Validation loss: 2.4480016225412933

Epoch: 6| Step: 12
Training loss: 2.405945597628924
Validation loss: 2.4340104586913744

Epoch: 6| Step: 13
Training loss: 2.4918404938485623
Validation loss: 2.456660806277086

Epoch: 163| Step: 0
Training loss: 2.4667305714688905
Validation loss: 2.44750005772135

Epoch: 6| Step: 1
Training loss: 2.454899625882235
Validation loss: 2.4683805069511853

Epoch: 6| Step: 2
Training loss: 2.1774050339532067
Validation loss: 2.418635669111196

Epoch: 6| Step: 3
Training loss: 2.158685276494775
Validation loss: 2.4430377476672454

Epoch: 6| Step: 4
Training loss: 2.265140876346826
Validation loss: 2.4515195428650913

Epoch: 6| Step: 5
Training loss: 2.933453308888636
Validation loss: 2.440944403560347

Epoch: 6| Step: 6
Training loss: 2.5994725352555377
Validation loss: 2.462833214134012

Epoch: 6| Step: 7
Training loss: 2.1439848657187746
Validation loss: 2.454764898666927

Epoch: 6| Step: 8
Training loss: 2.094349789469136
Validation loss: 2.4569171558380685

Epoch: 6| Step: 9
Training loss: 2.650317579709162
Validation loss: 2.464345914201819

Epoch: 6| Step: 10
Training loss: 2.3180978397723164
Validation loss: 2.4263567603854845

Epoch: 6| Step: 11
Training loss: 1.9789298133335764
Validation loss: 2.427276986674197

Epoch: 6| Step: 12
Training loss: 2.475492131790296
Validation loss: 2.4489932127716547

Epoch: 6| Step: 13
Training loss: 2.728252510158433
Validation loss: 2.4535953584703223

Epoch: 164| Step: 0
Training loss: 2.1115593796803385
Validation loss: 2.4525808077307505

Epoch: 6| Step: 1
Training loss: 2.3250311449487486
Validation loss: 2.4379018531723187

Epoch: 6| Step: 2
Training loss: 2.5340903088164213
Validation loss: 2.449519392835747

Epoch: 6| Step: 3
Training loss: 2.4749405901935893
Validation loss: 2.457607238879631

Epoch: 6| Step: 4
Training loss: 2.6706249145822043
Validation loss: 2.4349054769461342

Epoch: 6| Step: 5
Training loss: 2.8036512410376706
Validation loss: 2.4370798506644276

Epoch: 6| Step: 6
Training loss: 1.974474380663122
Validation loss: 2.427851270304798

Epoch: 6| Step: 7
Training loss: 2.433251811538817
Validation loss: 2.4693614015191745

Epoch: 6| Step: 8
Training loss: 2.1640425588191685
Validation loss: 2.442130517779344

Epoch: 6| Step: 9
Training loss: 2.1765128913916505
Validation loss: 2.4494089825089

Epoch: 6| Step: 10
Training loss: 2.8250330256329304
Validation loss: 2.4641319760395923

Epoch: 6| Step: 11
Training loss: 2.2193659612438816
Validation loss: 2.439629885513615

Epoch: 6| Step: 12
Training loss: 2.4001121017978075
Validation loss: 2.436505091767833

Epoch: 6| Step: 13
Training loss: 2.087660174592033
Validation loss: 2.431500455965405

Epoch: 165| Step: 0
Training loss: 2.9137456890452342
Validation loss: 2.4418375648071375

Epoch: 6| Step: 1
Training loss: 1.9561528654023068
Validation loss: 2.438087632344723

Epoch: 6| Step: 2
Training loss: 1.636871840571165
Validation loss: 2.4763385928595434

Epoch: 6| Step: 3
Training loss: 2.5491290269284046
Validation loss: 2.476044298073161

Epoch: 6| Step: 4
Training loss: 2.4648419121736906
Validation loss: 2.454718795278909

Epoch: 6| Step: 5
Training loss: 1.5388716371183608
Validation loss: 2.4647660816621997

Epoch: 6| Step: 6
Training loss: 2.3462901274268164
Validation loss: 2.45407453659647

Epoch: 6| Step: 7
Training loss: 1.8247980998983027
Validation loss: 2.472418820562417

Epoch: 6| Step: 8
Training loss: 2.6375627989321027
Validation loss: 2.4442632948857805

Epoch: 6| Step: 9
Training loss: 3.107353281622333
Validation loss: 2.4392814668117544

Epoch: 6| Step: 10
Training loss: 2.334476281845255
Validation loss: 2.461183280540687

Epoch: 6| Step: 11
Training loss: 2.639381883536813
Validation loss: 2.4622285804397057

Epoch: 6| Step: 12
Training loss: 1.9621485279998574
Validation loss: 2.4632856113718415

Epoch: 6| Step: 13
Training loss: 3.1285130400164123
Validation loss: 2.453463578371036

Epoch: 166| Step: 0
Training loss: 2.6833017959478966
Validation loss: 2.456207937209058

Epoch: 6| Step: 1
Training loss: 2.2221848670151
Validation loss: 2.437222159142629

Epoch: 6| Step: 2
Training loss: 2.208117840407356
Validation loss: 2.455277578500137

Epoch: 6| Step: 3
Training loss: 2.4035748560473515
Validation loss: 2.4558627650845954

Epoch: 6| Step: 4
Training loss: 2.509578475208532
Validation loss: 2.4583033024027916

Epoch: 6| Step: 5
Training loss: 2.1788257276251084
Validation loss: 2.449480873862564

Epoch: 6| Step: 6
Training loss: 2.3922708866827302
Validation loss: 2.457405493663331

Epoch: 6| Step: 7
Training loss: 2.624333160713714
Validation loss: 2.434926417401454

Epoch: 6| Step: 8
Training loss: 2.424158705454273
Validation loss: 2.4486812580023747

Epoch: 6| Step: 9
Training loss: 1.7579583001599663
Validation loss: 2.4469581341885815

Epoch: 6| Step: 10
Training loss: 2.613401310419385
Validation loss: 2.4437609633249204

Epoch: 6| Step: 11
Training loss: 2.499705488023633
Validation loss: 2.4829883034582743

Epoch: 6| Step: 12
Training loss: 2.2578730063597243
Validation loss: 2.458539473030385

Epoch: 6| Step: 13
Training loss: 1.937961215836768
Validation loss: 2.4419979982624804

Epoch: 167| Step: 0
Training loss: 3.0724822863447634
Validation loss: 2.466823849856823

Epoch: 6| Step: 1
Training loss: 2.5205564320548057
Validation loss: 2.4500845789671795

Epoch: 6| Step: 2
Training loss: 1.9767392045596246
Validation loss: 2.4653025926928542

Epoch: 6| Step: 3
Training loss: 2.295256271348751
Validation loss: 2.4174497512789017

Epoch: 6| Step: 4
Training loss: 1.8419656686306785
Validation loss: 2.440612161894678

Epoch: 6| Step: 5
Training loss: 2.5117064100469615
Validation loss: 2.454720395256952

Epoch: 6| Step: 6
Training loss: 3.15987784499659
Validation loss: 2.4464508974447807

Epoch: 6| Step: 7
Training loss: 2.1434077531858553
Validation loss: 2.475405161933918

Epoch: 6| Step: 8
Training loss: 1.9532569535504072
Validation loss: 2.46138446718501

Epoch: 6| Step: 9
Training loss: 2.7117832414656315
Validation loss: 2.470837903467717

Epoch: 6| Step: 10
Training loss: 2.726001845814674
Validation loss: 2.4559403167570624

Epoch: 6| Step: 11
Training loss: 2.0261129123219623
Validation loss: 2.459418898871862

Epoch: 6| Step: 12
Training loss: 2.010232261409614
Validation loss: 2.4580420802468934

Epoch: 6| Step: 13
Training loss: 1.3371543919047726
Validation loss: 2.453802035324123

Epoch: 168| Step: 0
Training loss: 2.703291694925652
Validation loss: 2.44054660499735

Epoch: 6| Step: 1
Training loss: 2.3331961477913947
Validation loss: 2.4477164817405055

Epoch: 6| Step: 2
Training loss: 2.1155123118558703
Validation loss: 2.4253875633308692

Epoch: 6| Step: 3
Training loss: 2.9573763163509765
Validation loss: 2.462660572719009

Epoch: 6| Step: 4
Training loss: 1.768605510080432
Validation loss: 2.426078629277631

Epoch: 6| Step: 5
Training loss: 2.351483416574068
Validation loss: 2.4450026140874916

Epoch: 6| Step: 6
Training loss: 1.995217565848597
Validation loss: 2.4435198910919556

Epoch: 6| Step: 7
Training loss: 2.598848043686819
Validation loss: 2.4510952251709415

Epoch: 6| Step: 8
Training loss: 2.1450094721658344
Validation loss: 2.4250754431865507

Epoch: 6| Step: 9
Training loss: 2.6740181341990086
Validation loss: 2.43048617317173

Epoch: 6| Step: 10
Training loss: 2.3141986690950938
Validation loss: 2.4428682565939583

Epoch: 6| Step: 11
Training loss: 2.587387554286969
Validation loss: 2.433678529230135

Epoch: 6| Step: 12
Training loss: 2.1011122891369944
Validation loss: 2.44346180476834

Epoch: 6| Step: 13
Training loss: 2.467340090902757
Validation loss: 2.440335714340396

Epoch: 169| Step: 0
Training loss: 2.48455569971653
Validation loss: 2.446416382455192

Epoch: 6| Step: 1
Training loss: 2.2975703633588593
Validation loss: 2.458165680987778

Epoch: 6| Step: 2
Training loss: 2.6283670357055433
Validation loss: 2.406016035442345

Epoch: 6| Step: 3
Training loss: 2.373290802149493
Validation loss: 2.4483821006638107

Epoch: 6| Step: 4
Training loss: 2.047463485336283
Validation loss: 2.4476993824794104

Epoch: 6| Step: 5
Training loss: 2.69656086635949
Validation loss: 2.443220213000191

Epoch: 6| Step: 6
Training loss: 1.8262233135302341
Validation loss: 2.454085976494788

Epoch: 6| Step: 7
Training loss: 3.086687909404032
Validation loss: 2.4317378554837874

Epoch: 6| Step: 8
Training loss: 2.5910619571982525
Validation loss: 2.4476734851350948

Epoch: 6| Step: 9
Training loss: 1.6976552500680155
Validation loss: 2.4305505922640878

Epoch: 6| Step: 10
Training loss: 1.8686977009169004
Validation loss: 2.4461403529538805

Epoch: 6| Step: 11
Training loss: 2.133338947090074
Validation loss: 2.4582243537697632

Epoch: 6| Step: 12
Training loss: 2.2531399539869237
Validation loss: 2.4409261278152563

Epoch: 6| Step: 13
Training loss: 2.876809421531941
Validation loss: 2.4377059544506223

Epoch: 170| Step: 0
Training loss: 2.5035460119238033
Validation loss: 2.416637616377198

Epoch: 6| Step: 1
Training loss: 2.7801669294338387
Validation loss: 2.440869660244259

Epoch: 6| Step: 2
Training loss: 2.01021043843049
Validation loss: 2.4780014059197577

Epoch: 6| Step: 3
Training loss: 2.2678998378858397
Validation loss: 2.4394057779855247

Epoch: 6| Step: 4
Training loss: 2.127517443180859
Validation loss: 2.449600328430787

Epoch: 6| Step: 5
Training loss: 1.8910288734027105
Validation loss: 2.4456889666618955

Epoch: 6| Step: 6
Training loss: 2.2631609968026427
Validation loss: 2.42344866121207

Epoch: 6| Step: 7
Training loss: 2.140019909061979
Validation loss: 2.437503067952832

Epoch: 6| Step: 8
Training loss: 2.7030076900010087
Validation loss: 2.439271595969913

Epoch: 6| Step: 9
Training loss: 2.6351281009350194
Validation loss: 2.4650139203300783

Epoch: 6| Step: 10
Training loss: 2.3932911086895836
Validation loss: 2.4538092927569086

Epoch: 6| Step: 11
Training loss: 1.9232394949347076
Validation loss: 2.4511707757760166

Epoch: 6| Step: 12
Training loss: 2.5532825584774774
Validation loss: 2.4617168264867435

Epoch: 6| Step: 13
Training loss: 2.807249211619609
Validation loss: 2.4585957495730604

Epoch: 171| Step: 0
Training loss: 2.706877997217697
Validation loss: 2.4529952764845255

Epoch: 6| Step: 1
Training loss: 2.0035523814167093
Validation loss: 2.4593026085924214

Epoch: 6| Step: 2
Training loss: 2.549095262581382
Validation loss: 2.4307653060234613

Epoch: 6| Step: 3
Training loss: 2.604576037973445
Validation loss: 2.434862548923512

Epoch: 6| Step: 4
Training loss: 2.495444343155663
Validation loss: 2.436371347669066

Epoch: 6| Step: 5
Training loss: 2.4392051601294025
Validation loss: 2.4394200873836693

Epoch: 6| Step: 6
Training loss: 2.796902107661494
Validation loss: 2.459097750869689

Epoch: 6| Step: 7
Training loss: 2.4123285973887936
Validation loss: 2.470205766432667

Epoch: 6| Step: 8
Training loss: 2.183637642461922
Validation loss: 2.4373780644168455

Epoch: 6| Step: 9
Training loss: 2.204239583627154
Validation loss: 2.461862769140077

Epoch: 6| Step: 10
Training loss: 1.7363651301728422
Validation loss: 2.4367955790986935

Epoch: 6| Step: 11
Training loss: 2.491438606652589
Validation loss: 2.4273086053193937

Epoch: 6| Step: 12
Training loss: 2.221354929904128
Validation loss: 2.426807869764892

Epoch: 6| Step: 13
Training loss: 1.4696058660989222
Validation loss: 2.4202770803520544

Epoch: 172| Step: 0
Training loss: 1.9838596786244853
Validation loss: 2.4326390039078225

Epoch: 6| Step: 1
Training loss: 2.3524501810666756
Validation loss: 2.4467870360543644

Epoch: 6| Step: 2
Training loss: 2.687279714383336
Validation loss: 2.4556651150725077

Epoch: 6| Step: 3
Training loss: 2.0971461977733465
Validation loss: 2.4505504817205885

Epoch: 6| Step: 4
Training loss: 2.210676305864131
Validation loss: 2.4244647292570196

Epoch: 6| Step: 5
Training loss: 2.7238746664255267
Validation loss: 2.4344742092360954

Epoch: 6| Step: 6
Training loss: 2.3572009851463664
Validation loss: 2.4178598529069175

Epoch: 6| Step: 7
Training loss: 2.3408480162367717
Validation loss: 2.4548482094547843

Epoch: 6| Step: 8
Training loss: 2.235887562362723
Validation loss: 2.4127042773694103

Epoch: 6| Step: 9
Training loss: 2.68925667061173
Validation loss: 2.43334572851126

Epoch: 6| Step: 10
Training loss: 2.568664114971199
Validation loss: 2.4622292197285023

Epoch: 6| Step: 11
Training loss: 1.6442901362084705
Validation loss: 2.4300874000414234

Epoch: 6| Step: 12
Training loss: 2.452569400532574
Validation loss: 2.4109108634146508

Epoch: 6| Step: 13
Training loss: 2.196846422685141
Validation loss: 2.435913213117711

Epoch: 173| Step: 0
Training loss: 1.9387916443396214
Validation loss: 2.4414131237302428

Epoch: 6| Step: 1
Training loss: 2.9331925647366166
Validation loss: 2.444495698347063

Epoch: 6| Step: 2
Training loss: 2.5097590702431427
Validation loss: 2.435363251575171

Epoch: 6| Step: 3
Training loss: 2.6481210525191567
Validation loss: 2.4260195864262704

Epoch: 6| Step: 4
Training loss: 2.02566794223106
Validation loss: 2.440864640864735

Epoch: 6| Step: 5
Training loss: 2.488535534188619
Validation loss: 2.425432071182331

Epoch: 6| Step: 6
Training loss: 2.57655194004502
Validation loss: 2.4572029431358

Epoch: 6| Step: 7
Training loss: 2.0815008751131776
Validation loss: 2.4515092517619586

Epoch: 6| Step: 8
Training loss: 1.9238425007394362
Validation loss: 2.467133632178015

Epoch: 6| Step: 9
Training loss: 1.6143796566708843
Validation loss: 2.420395067709568

Epoch: 6| Step: 10
Training loss: 2.682539331551324
Validation loss: 2.4742148048260657

Epoch: 6| Step: 11
Training loss: 2.537230972535927
Validation loss: 2.4211421920397074

Epoch: 6| Step: 12
Training loss: 2.0843810943560177
Validation loss: 2.4451750941748265

Epoch: 6| Step: 13
Training loss: 2.193698928108098
Validation loss: 2.451914144437327

Epoch: 174| Step: 0
Training loss: 2.273402262935685
Validation loss: 2.46036348382232

Epoch: 6| Step: 1
Training loss: 2.620619615858148
Validation loss: 2.4270390673720175

Epoch: 6| Step: 2
Training loss: 1.8751439357188253
Validation loss: 2.4236215328192245

Epoch: 6| Step: 3
Training loss: 2.995153008375215
Validation loss: 2.4450511056824333

Epoch: 6| Step: 4
Training loss: 2.5165384659945254
Validation loss: 2.458226908832031

Epoch: 6| Step: 5
Training loss: 2.826388252585233
Validation loss: 2.4484193343814558

Epoch: 6| Step: 6
Training loss: 2.018648939880451
Validation loss: 2.453094452970258

Epoch: 6| Step: 7
Training loss: 2.2661254330132334
Validation loss: 2.463088996232041

Epoch: 6| Step: 8
Training loss: 2.068396491419218
Validation loss: 2.469282545328461

Epoch: 6| Step: 9
Training loss: 2.3389020499098003
Validation loss: 2.463898495785207

Epoch: 6| Step: 10
Training loss: 2.3109717603185347
Validation loss: 2.4470041176863453

Epoch: 6| Step: 11
Training loss: 2.174359553962883
Validation loss: 2.4460991229106264

Epoch: 6| Step: 12
Training loss: 1.9596103265281946
Validation loss: 2.453297700087604

Epoch: 6| Step: 13
Training loss: 2.3302048986822017
Validation loss: 2.4352522446992553

Epoch: 175| Step: 0
Training loss: 2.499263654986939
Validation loss: 2.4738150658220714

Epoch: 6| Step: 1
Training loss: 2.4999087317019395
Validation loss: 2.4248154461187736

Epoch: 6| Step: 2
Training loss: 2.0342279759030886
Validation loss: 2.443549425785593

Epoch: 6| Step: 3
Training loss: 2.5211675963507783
Validation loss: 2.434992788895032

Epoch: 6| Step: 4
Training loss: 2.4308642515304917
Validation loss: 2.429009217225153

Epoch: 6| Step: 5
Training loss: 2.5891126978905206
Validation loss: 2.4283004054820085

Epoch: 6| Step: 6
Training loss: 1.893334142266132
Validation loss: 2.423098529444035

Epoch: 6| Step: 7
Training loss: 2.0654313035602425
Validation loss: 2.436551066842095

Epoch: 6| Step: 8
Training loss: 2.184280205717628
Validation loss: 2.45541000045095

Epoch: 6| Step: 9
Training loss: 2.410425897534982
Validation loss: 2.42668497382274

Epoch: 6| Step: 10
Training loss: 2.3650547403529
Validation loss: 2.4294383938162243

Epoch: 6| Step: 11
Training loss: 2.05148413828799
Validation loss: 2.4502638358556355

Epoch: 6| Step: 12
Training loss: 2.5580037375833675
Validation loss: 2.437662608799494

Epoch: 6| Step: 13
Training loss: 1.951105278948267
Validation loss: 2.4444410169516195

Epoch: 176| Step: 0
Training loss: 2.208931056288989
Validation loss: 2.4435702145294464

Epoch: 6| Step: 1
Training loss: 2.285692357486035
Validation loss: 2.4243639586004306

Epoch: 6| Step: 2
Training loss: 2.3074367870793746
Validation loss: 2.4428974360644258

Epoch: 6| Step: 3
Training loss: 2.6040706972876464
Validation loss: 2.4284150703271576

Epoch: 6| Step: 4
Training loss: 2.558920989330986
Validation loss: 2.4414782667469628

Epoch: 6| Step: 5
Training loss: 1.5114600775945455
Validation loss: 2.4392765082741783

Epoch: 6| Step: 6
Training loss: 2.5778614256247603
Validation loss: 2.4164593745243304

Epoch: 6| Step: 7
Training loss: 2.4021690739341444
Validation loss: 2.4136582901103036

Epoch: 6| Step: 8
Training loss: 2.6971390436898304
Validation loss: 2.4361903919217256

Epoch: 6| Step: 9
Training loss: 1.9814469970575639
Validation loss: 2.4460239679976064

Epoch: 6| Step: 10
Training loss: 2.133846046507412
Validation loss: 2.4365277072083984

Epoch: 6| Step: 11
Training loss: 2.6421827427907534
Validation loss: 2.4306670905645498

Epoch: 6| Step: 12
Training loss: 2.4984333851811997
Validation loss: 2.4329776055365904

Epoch: 6| Step: 13
Training loss: 2.274044100136683
Validation loss: 2.418420514479171

Epoch: 177| Step: 0
Training loss: 2.038841966417672
Validation loss: 2.4232603156698556

Epoch: 6| Step: 1
Training loss: 2.250090703195634
Validation loss: 2.4376993699913

Epoch: 6| Step: 2
Training loss: 1.7797135536222612
Validation loss: 2.4309210601393705

Epoch: 6| Step: 3
Training loss: 1.8403428488049343
Validation loss: 2.3883807254798977

Epoch: 6| Step: 4
Training loss: 2.2419119742040152
Validation loss: 2.411878611693445

Epoch: 6| Step: 5
Training loss: 1.922223935588938
Validation loss: 2.4399195962966167

Epoch: 6| Step: 6
Training loss: 2.4528595604612073
Validation loss: 2.43823725044975

Epoch: 6| Step: 7
Training loss: 2.756467669622097
Validation loss: 2.4261572201698223

Epoch: 6| Step: 8
Training loss: 2.890831687342495
Validation loss: 2.4378928989807984

Epoch: 6| Step: 9
Training loss: 2.9357122297283103
Validation loss: 2.432827617599268

Epoch: 6| Step: 10
Training loss: 2.1770648012482834
Validation loss: 2.417354098416958

Epoch: 6| Step: 11
Training loss: 2.6419610249592185
Validation loss: 2.4520699802081487

Epoch: 6| Step: 12
Training loss: 2.427669754457254
Validation loss: 2.409631649662529

Epoch: 6| Step: 13
Training loss: 2.0380156303382893
Validation loss: 2.4052050947617687

Epoch: 178| Step: 0
Training loss: 2.260267038857263
Validation loss: 2.4569049590614296

Epoch: 6| Step: 1
Training loss: 2.550385659169618
Validation loss: 2.428575980903548

Epoch: 6| Step: 2
Training loss: 3.1330968104703207
Validation loss: 2.4379459075259633

Epoch: 6| Step: 3
Training loss: 2.4834900245473843
Validation loss: 2.4414151965561883

Epoch: 6| Step: 4
Training loss: 2.4522800812806635
Validation loss: 2.4249193516623975

Epoch: 6| Step: 5
Training loss: 2.52384184913464
Validation loss: 2.430740434810019

Epoch: 6| Step: 6
Training loss: 1.8308437378486002
Validation loss: 2.422752125740174

Epoch: 6| Step: 7
Training loss: 1.791078855507006
Validation loss: 2.4175259456066622

Epoch: 6| Step: 8
Training loss: 2.1807854187710927
Validation loss: 2.408835573310343

Epoch: 6| Step: 9
Training loss: 2.270572075703468
Validation loss: 2.425130854582661

Epoch: 6| Step: 10
Training loss: 2.8050235982572027
Validation loss: 2.44334045839837

Epoch: 6| Step: 11
Training loss: 1.756926724525056
Validation loss: 2.4309161689162764

Epoch: 6| Step: 12
Training loss: 2.175084219869518
Validation loss: 2.4565839681994097

Epoch: 6| Step: 13
Training loss: 0.945608612846388
Validation loss: 2.451423187962543

Epoch: 179| Step: 0
Training loss: 2.4325198625339763
Validation loss: 2.451930510643718

Epoch: 6| Step: 1
Training loss: 1.579498901579337
Validation loss: 2.4429645963208158

Epoch: 6| Step: 2
Training loss: 2.5993051444057373
Validation loss: 2.453942965052673

Epoch: 6| Step: 3
Training loss: 2.8010012062775624
Validation loss: 2.4305232359284825

Epoch: 6| Step: 4
Training loss: 2.270278466239333
Validation loss: 2.4386066735836014

Epoch: 6| Step: 5
Training loss: 1.8065713405211359
Validation loss: 2.4361720084287084

Epoch: 6| Step: 6
Training loss: 2.73808081052466
Validation loss: 2.4498328524209776

Epoch: 6| Step: 7
Training loss: 2.467870628094536
Validation loss: 2.4553607069249863

Epoch: 6| Step: 8
Training loss: 2.226213608561592
Validation loss: 2.4521527233888314

Epoch: 6| Step: 9
Training loss: 2.5724719405798777
Validation loss: 2.4319397492409682

Epoch: 6| Step: 10
Training loss: 2.149284722866258
Validation loss: 2.4404250296344268

Epoch: 6| Step: 11
Training loss: 2.520954812225559
Validation loss: 2.453480292642356

Epoch: 6| Step: 12
Training loss: 2.0589578440474328
Validation loss: 2.44586889159328

Epoch: 6| Step: 13
Training loss: 1.837309304547158
Validation loss: 2.427333565032259

Epoch: 180| Step: 0
Training loss: 2.2212629459757336
Validation loss: 2.447229111217554

Epoch: 6| Step: 1
Training loss: 2.522667262389104
Validation loss: 2.4319979594920818

Epoch: 6| Step: 2
Training loss: 2.239262816685152
Validation loss: 2.4337771466813356

Epoch: 6| Step: 3
Training loss: 2.1488058988125207
Validation loss: 2.4086069667437666

Epoch: 6| Step: 4
Training loss: 2.35955243990779
Validation loss: 2.4494394415324567

Epoch: 6| Step: 5
Training loss: 2.8361530484760307
Validation loss: 2.423228976396427

Epoch: 6| Step: 6
Training loss: 2.5908203125
Validation loss: 2.416263845546963

Epoch: 6| Step: 7
Training loss: 2.072437965927962
Validation loss: 2.4263086881492875

Epoch: 6| Step: 8
Training loss: 2.232783784675011
Validation loss: 2.4298505577680523

Epoch: 6| Step: 9
Training loss: 2.4423917932661756
Validation loss: 2.43876439197862

Epoch: 6| Step: 10
Training loss: 2.002899452401609
Validation loss: 2.4191021869023768

Epoch: 6| Step: 11
Training loss: 1.6980522975304133
Validation loss: 2.4475189982121885

Epoch: 6| Step: 12
Training loss: 2.7975045459972874
Validation loss: 2.436453271377881

Epoch: 6| Step: 13
Training loss: 1.8468471957468129
Validation loss: 2.4543283840839485

Epoch: 181| Step: 0
Training loss: 2.1124985914959247
Validation loss: 2.4410164202800053

Epoch: 6| Step: 1
Training loss: 2.07792857683082
Validation loss: 2.447216473316042

Epoch: 6| Step: 2
Training loss: 2.4448134427969275
Validation loss: 2.4206063707349808

Epoch: 6| Step: 3
Training loss: 2.360220852232578
Validation loss: 2.466510490582909

Epoch: 6| Step: 4
Training loss: 2.4631306881416655
Validation loss: 2.4064444697870435

Epoch: 6| Step: 5
Training loss: 1.7502516156916414
Validation loss: 2.4455719899606585

Epoch: 6| Step: 6
Training loss: 2.731590117133916
Validation loss: 2.4426424273984253

Epoch: 6| Step: 7
Training loss: 2.196862376191726
Validation loss: 2.4456409531369054

Epoch: 6| Step: 8
Training loss: 2.2833211197723666
Validation loss: 2.446740546591262

Epoch: 6| Step: 9
Training loss: 2.3822956462693985
Validation loss: 2.4207946167092933

Epoch: 6| Step: 10
Training loss: 2.1797340962341356
Validation loss: 2.4325976035202683

Epoch: 6| Step: 11
Training loss: 2.04487593780483
Validation loss: 2.406565998765885

Epoch: 6| Step: 12
Training loss: 2.499866577402817
Validation loss: 2.4253602269790404

Epoch: 6| Step: 13
Training loss: 2.514201075194422
Validation loss: 2.435562270182829

Epoch: 182| Step: 0
Training loss: 1.9743023642196145
Validation loss: 2.429935038201418

Epoch: 6| Step: 1
Training loss: 1.9005774850121302
Validation loss: 2.426813205025651

Epoch: 6| Step: 2
Training loss: 1.417502082136936
Validation loss: 2.4508390773254236

Epoch: 6| Step: 3
Training loss: 3.1890729127421413
Validation loss: 2.3907758759125177

Epoch: 6| Step: 4
Training loss: 2.351072241286162
Validation loss: 2.428615954594057

Epoch: 6| Step: 5
Training loss: 2.873527813353511
Validation loss: 2.4531319049032354

Epoch: 6| Step: 6
Training loss: 2.0055057321607777
Validation loss: 2.4366643002592583

Epoch: 6| Step: 7
Training loss: 2.403520398295632
Validation loss: 2.41980078265277

Epoch: 6| Step: 8
Training loss: 2.203648281854904
Validation loss: 2.442306591168667

Epoch: 6| Step: 9
Training loss: 2.4602574937859614
Validation loss: 2.4228045227571515

Epoch: 6| Step: 10
Training loss: 1.9352591692430454
Validation loss: 2.450660071734225

Epoch: 6| Step: 11
Training loss: 2.0338969663707185
Validation loss: 2.4015415690829998

Epoch: 6| Step: 12
Training loss: 2.4500281351770594
Validation loss: 2.4524682909047386

Epoch: 6| Step: 13
Training loss: 2.5788309691268796
Validation loss: 2.4003891596901505

Epoch: 183| Step: 0
Training loss: 1.6615491341998008
Validation loss: 2.4268229316390544

Epoch: 6| Step: 1
Training loss: 2.7982247787725383
Validation loss: 2.412130818382331

Epoch: 6| Step: 2
Training loss: 2.2632836180869775
Validation loss: 2.453455564968142

Epoch: 6| Step: 3
Training loss: 2.0961779281428154
Validation loss: 2.4364658020174703

Epoch: 6| Step: 4
Training loss: 2.1586639602735276
Validation loss: 2.4417804274753947

Epoch: 6| Step: 5
Training loss: 2.313791378399342
Validation loss: 2.432142895335348

Epoch: 6| Step: 6
Training loss: 2.395648440538193
Validation loss: 2.459740167533896

Epoch: 6| Step: 7
Training loss: 1.9397830432821304
Validation loss: 2.4350062293233483

Epoch: 6| Step: 8
Training loss: 1.9252199666566487
Validation loss: 2.4291420780642112

Epoch: 6| Step: 9
Training loss: 2.3383215536562667
Validation loss: 2.4420822474318515

Epoch: 6| Step: 10
Training loss: 2.2550418313623024
Validation loss: 2.4420804680599795

Epoch: 6| Step: 11
Training loss: 2.488615339957587
Validation loss: 2.419238639488498

Epoch: 6| Step: 12
Training loss: 2.7457988032561027
Validation loss: 2.43118893817957

Epoch: 6| Step: 13
Training loss: 2.1342779581509355
Validation loss: 2.4227607464912926

Epoch: 184| Step: 0
Training loss: 2.395887877354805
Validation loss: 2.4608367164862783

Epoch: 6| Step: 1
Training loss: 2.5694027482049036
Validation loss: 2.429156100708302

Epoch: 6| Step: 2
Training loss: 1.8002403257788397
Validation loss: 2.4342942003517605

Epoch: 6| Step: 3
Training loss: 2.5216848233164533
Validation loss: 2.4439645020188965

Epoch: 6| Step: 4
Training loss: 2.319159121549639
Validation loss: 2.4508288848299116

Epoch: 6| Step: 5
Training loss: 2.7661300456657694
Validation loss: 2.436986157548062

Epoch: 6| Step: 6
Training loss: 2.3947595484370288
Validation loss: 2.4289230527903407

Epoch: 6| Step: 7
Training loss: 2.149498362016819
Validation loss: 2.4015024177438136

Epoch: 6| Step: 8
Training loss: 1.5699849712357141
Validation loss: 2.4587689975348033

Epoch: 6| Step: 9
Training loss: 1.2611553245072389
Validation loss: 2.4330094546150574

Epoch: 6| Step: 10
Training loss: 2.4213427543302815
Validation loss: 2.424275690689031

Epoch: 6| Step: 11
Training loss: 2.0297439860999433
Validation loss: 2.4626466253017805

Epoch: 6| Step: 12
Training loss: 3.069931822029072
Validation loss: 2.4497653791917693

Epoch: 6| Step: 13
Training loss: 2.4294822090975043
Validation loss: 2.397914833666921

Epoch: 185| Step: 0
Training loss: 1.9944429682115472
Validation loss: 2.4135372180961365

Epoch: 6| Step: 1
Training loss: 2.064313149375967
Validation loss: 2.3770953975142457

Epoch: 6| Step: 2
Training loss: 1.908091671674778
Validation loss: 2.4236211107678898

Epoch: 6| Step: 3
Training loss: 1.4895801232932477
Validation loss: 2.424258084519859

Epoch: 6| Step: 4
Training loss: 2.0643258538258746
Validation loss: 2.426189845077059

Epoch: 6| Step: 5
Training loss: 2.5014464962025986
Validation loss: 2.4043565933652045

Epoch: 6| Step: 6
Training loss: 2.0323931485062663
Validation loss: 2.410888819017324

Epoch: 6| Step: 7
Training loss: 1.9494810978965424
Validation loss: 2.409769615664848

Epoch: 6| Step: 8
Training loss: 2.3949898160905083
Validation loss: 2.3951841907919427

Epoch: 6| Step: 9
Training loss: 2.7743427357405657
Validation loss: 2.4332330816006835

Epoch: 6| Step: 10
Training loss: 3.0309556641188276
Validation loss: 2.4253175602183146

Epoch: 6| Step: 11
Training loss: 2.3556306950962598
Validation loss: 2.40518231057513

Epoch: 6| Step: 12
Training loss: 2.6378560192041864
Validation loss: 2.4340951749594235

Epoch: 6| Step: 13
Training loss: 2.231431422618149
Validation loss: 2.4223075435453048

Epoch: 186| Step: 0
Training loss: 2.0495623935602536
Validation loss: 2.4233934694730905

Epoch: 6| Step: 1
Training loss: 1.8623798357199688
Validation loss: 2.4426193789590958

Epoch: 6| Step: 2
Training loss: 2.229182472054134
Validation loss: 2.431901326053995

Epoch: 6| Step: 3
Training loss: 2.259333431552687
Validation loss: 2.431081410454101

Epoch: 6| Step: 4
Training loss: 2.6801027915941473
Validation loss: 2.4280126258075283

Epoch: 6| Step: 5
Training loss: 1.5343523322954091
Validation loss: 2.4564476964194033

Epoch: 6| Step: 6
Training loss: 2.188904338734811
Validation loss: 2.4270343980675624

Epoch: 6| Step: 7
Training loss: 2.4435769646694543
Validation loss: 2.4244320795492516

Epoch: 6| Step: 8
Training loss: 2.8546159673705658
Validation loss: 2.428943159294709

Epoch: 6| Step: 9
Training loss: 2.0118959219236654
Validation loss: 2.4202381881317048

Epoch: 6| Step: 10
Training loss: 2.0865162250208815
Validation loss: 2.3979652535497418

Epoch: 6| Step: 11
Training loss: 2.6508043903720293
Validation loss: 2.4053373573067565

Epoch: 6| Step: 12
Training loss: 2.7302965538290134
Validation loss: 2.434143637397175

Epoch: 6| Step: 13
Training loss: 1.422850221988044
Validation loss: 2.446474977588845

Epoch: 187| Step: 0
Training loss: 1.748046875
Validation loss: 2.4418604332237943

Epoch: 6| Step: 1
Training loss: 2.3425031269911636
Validation loss: 2.405871575287149

Epoch: 6| Step: 2
Training loss: 2.266621758446216
Validation loss: 2.4035503615711193

Epoch: 6| Step: 3
Training loss: 2.185639707555638
Validation loss: 2.4339857064792896

Epoch: 6| Step: 4
Training loss: 1.9713818352058141
Validation loss: 2.427965491773891

Epoch: 6| Step: 5
Training loss: 2.2587569746153604
Validation loss: 2.4211110879485687

Epoch: 6| Step: 6
Training loss: 2.4623258035304616
Validation loss: 2.4344819297128395

Epoch: 6| Step: 7
Training loss: 2.0478545895155262
Validation loss: 2.4229033151083303

Epoch: 6| Step: 8
Training loss: 2.9231812520270015
Validation loss: 2.4210352950026746

Epoch: 6| Step: 9
Training loss: 2.6948024985959935
Validation loss: 2.440499296004301

Epoch: 6| Step: 10
Training loss: 2.132129378138116
Validation loss: 2.4183884563100078

Epoch: 6| Step: 11
Training loss: 2.2100098082380866
Validation loss: 2.4480332792979644

Epoch: 6| Step: 12
Training loss: 2.44786684242568
Validation loss: 2.40545656557453

Epoch: 6| Step: 13
Training loss: 2.0939844484161623
Validation loss: 2.416235982631651

Epoch: 188| Step: 0
Training loss: 2.0172236999998447
Validation loss: 2.4185451866330356

Epoch: 6| Step: 1
Training loss: 2.0434441387175433
Validation loss: 2.422135550846307

Epoch: 6| Step: 2
Training loss: 1.6899806263055823
Validation loss: 2.445797868878804

Epoch: 6| Step: 3
Training loss: 2.3581236495583613
Validation loss: 2.436952866622119

Epoch: 6| Step: 4
Training loss: 2.677099640990781
Validation loss: 2.4344325509892264

Epoch: 6| Step: 5
Training loss: 2.5915770103262723
Validation loss: 2.4304531202006454

Epoch: 6| Step: 6
Training loss: 2.5572685245831597
Validation loss: 2.4150026463788556

Epoch: 6| Step: 7
Training loss: 1.96628476761468
Validation loss: 2.401541641139109

Epoch: 6| Step: 8
Training loss: 2.033727924435784
Validation loss: 2.4295319854723885

Epoch: 6| Step: 9
Training loss: 2.568794706749133
Validation loss: 2.408833646988988

Epoch: 6| Step: 10
Training loss: 2.1973981079851703
Validation loss: 2.461589411630945

Epoch: 6| Step: 11
Training loss: 1.9613175346849865
Validation loss: 2.4305006901359016

Epoch: 6| Step: 12
Training loss: 2.5843353379145566
Validation loss: 2.423927229941252

Epoch: 6| Step: 13
Training loss: 2.511011003179229
Validation loss: 2.43294259593652

Epoch: 189| Step: 0
Training loss: 1.4974537536918464
Validation loss: 2.4025952055254187

Epoch: 6| Step: 1
Training loss: 2.3794393709381847
Validation loss: 2.429652854499119

Epoch: 6| Step: 2
Training loss: 1.3050384963046715
Validation loss: 2.391498038168481

Epoch: 6| Step: 3
Training loss: 2.6625644801395665
Validation loss: 2.405557478189744

Epoch: 6| Step: 4
Training loss: 1.9873861460194122
Validation loss: 2.4219689987735324

Epoch: 6| Step: 5
Training loss: 2.119981449513877
Validation loss: 2.4075115036297983

Epoch: 6| Step: 6
Training loss: 2.862391314046527
Validation loss: 2.4222707921853726

Epoch: 6| Step: 7
Training loss: 2.778624935244359
Validation loss: 2.4342591991554996

Epoch: 6| Step: 8
Training loss: 2.508724629074775
Validation loss: 2.428760134360248

Epoch: 6| Step: 9
Training loss: 2.2411605131173986
Validation loss: 2.410729883059631

Epoch: 6| Step: 10
Training loss: 1.9361110754148363
Validation loss: 2.4478810102021105

Epoch: 6| Step: 11
Training loss: 2.3719267787986067
Validation loss: 2.4206043743490135

Epoch: 6| Step: 12
Training loss: 2.172894684438679
Validation loss: 2.407551584281602

Epoch: 6| Step: 13
Training loss: 1.8757432100441829
Validation loss: 2.426819658979998

Epoch: 190| Step: 0
Training loss: 1.8732053433110927
Validation loss: 2.4500417055368637

Epoch: 6| Step: 1
Training loss: 2.0265936667487643
Validation loss: 2.446693585783562

Epoch: 6| Step: 2
Training loss: 2.7637034491902197
Validation loss: 2.421088574161036

Epoch: 6| Step: 3
Training loss: 2.193371005889409
Validation loss: 2.4339026848550835

Epoch: 6| Step: 4
Training loss: 2.425898206658685
Validation loss: 2.4436421541259556

Epoch: 6| Step: 5
Training loss: 1.8872698182472651
Validation loss: 2.440039835194011

Epoch: 6| Step: 6
Training loss: 2.56876482065942
Validation loss: 2.4258361316657906

Epoch: 6| Step: 7
Training loss: 2.2928534353656613
Validation loss: 2.470007359586442

Epoch: 6| Step: 8
Training loss: 2.2451269573515136
Validation loss: 2.4446751479694115

Epoch: 6| Step: 9
Training loss: 1.7338242902289198
Validation loss: 2.426754406645833

Epoch: 6| Step: 10
Training loss: 2.8539128063010684
Validation loss: 2.42133024601082

Epoch: 6| Step: 11
Training loss: 1.9708693465423162
Validation loss: 2.421082529011422

Epoch: 6| Step: 12
Training loss: 2.1175523281725126
Validation loss: 2.4041996901051133

Epoch: 6| Step: 13
Training loss: 2.6369677616791702
Validation loss: 2.4333408674471007

Epoch: 191| Step: 0
Training loss: 2.728002042501138
Validation loss: 2.394254621395498

Epoch: 6| Step: 1
Training loss: 2.160328752966162
Validation loss: 2.413389868407483

Epoch: 6| Step: 2
Training loss: 2.8800866283527666
Validation loss: 2.435110327486979

Epoch: 6| Step: 3
Training loss: 2.2909109314447362
Validation loss: 2.3908011660893185

Epoch: 6| Step: 4
Training loss: 2.5220200658812213
Validation loss: 2.408515812669404

Epoch: 6| Step: 5
Training loss: 2.505960892057814
Validation loss: 2.418041594664411

Epoch: 6| Step: 6
Training loss: 2.3335461065373124
Validation loss: 2.4278313670014118

Epoch: 6| Step: 7
Training loss: 2.436314221040172
Validation loss: 2.4424334553600784

Epoch: 6| Step: 8
Training loss: 1.810483534280047
Validation loss: 2.4438635042408605

Epoch: 6| Step: 9
Training loss: 2.1975796216616317
Validation loss: 2.41257108192263

Epoch: 6| Step: 10
Training loss: 1.6544329194355718
Validation loss: 2.4201139675940198

Epoch: 6| Step: 11
Training loss: 1.8710601102795434
Validation loss: 2.4464936347041104

Epoch: 6| Step: 12
Training loss: 1.8842229348438386
Validation loss: 2.3828480772162792

Epoch: 6| Step: 13
Training loss: 1.5578858720800557
Validation loss: 2.4471430959345346

Epoch: 192| Step: 0
Training loss: 1.9923637760936839
Validation loss: 2.407050377992157

Epoch: 6| Step: 1
Training loss: 2.6769477028139854
Validation loss: 2.3894132121563914

Epoch: 6| Step: 2
Training loss: 2.711138715064985
Validation loss: 2.376241857979478

Epoch: 6| Step: 3
Training loss: 2.3954996512422126
Validation loss: 2.4324918243298126

Epoch: 6| Step: 4
Training loss: 2.756479173332154
Validation loss: 2.4428986512996924

Epoch: 6| Step: 5
Training loss: 2.388567668797108
Validation loss: 2.4532192586505186

Epoch: 6| Step: 6
Training loss: 1.4473833249889874
Validation loss: 2.414669306932797

Epoch: 6| Step: 7
Training loss: 2.3935905463195195
Validation loss: 2.4047877163871054

Epoch: 6| Step: 8
Training loss: 2.2558253430198114
Validation loss: 2.4250931079066804

Epoch: 6| Step: 9
Training loss: 2.1299255730605573
Validation loss: 2.437469235066474

Epoch: 6| Step: 10
Training loss: 2.0275120307010392
Validation loss: 2.4381421339541336

Epoch: 6| Step: 11
Training loss: 1.9314322672636863
Validation loss: 2.430301174753411

Epoch: 6| Step: 12
Training loss: 2.1363743813131975
Validation loss: 2.4117505005900575

Epoch: 6| Step: 13
Training loss: 1.5491819807297413
Validation loss: 2.421941948268692

Epoch: 193| Step: 0
Training loss: 2.0999251443146383
Validation loss: 2.427436506811526

Epoch: 6| Step: 1
Training loss: 2.82753144669184
Validation loss: 2.400963381570621

Epoch: 6| Step: 2
Training loss: 2.027208386203789
Validation loss: 2.4074315437175886

Epoch: 6| Step: 3
Training loss: 2.5742937693568906
Validation loss: 2.4213595484527435

Epoch: 6| Step: 4
Training loss: 1.9096359449221394
Validation loss: 2.416674039685887

Epoch: 6| Step: 5
Training loss: 1.5795921078036326
Validation loss: 2.376237821947653

Epoch: 6| Step: 6
Training loss: 2.371882550977667
Validation loss: 2.4010244681243513

Epoch: 6| Step: 7
Training loss: 2.495197738272916
Validation loss: 2.3771855299869373

Epoch: 6| Step: 8
Training loss: 2.3774354393634045
Validation loss: 2.3917654514081543

Epoch: 6| Step: 9
Training loss: 2.4054962563002893
Validation loss: 2.398407454678417

Epoch: 6| Step: 10
Training loss: 1.717008644904278
Validation loss: 2.416585874922005

Epoch: 6| Step: 11
Training loss: 1.5312816071654212
Validation loss: 2.4113381165652212

Epoch: 6| Step: 12
Training loss: 2.5246347710879835
Validation loss: 2.3943163684296267

Epoch: 6| Step: 13
Training loss: 2.6219745639815537
Validation loss: 2.395649609113199

Epoch: 194| Step: 0
Training loss: 2.0883456270546623
Validation loss: 2.36782738702218

Epoch: 6| Step: 1
Training loss: 1.88079713458967
Validation loss: 2.408462543841476

Epoch: 6| Step: 2
Training loss: 2.068991185445617
Validation loss: 2.447362379279774

Epoch: 6| Step: 3
Training loss: 2.5236950438790164
Validation loss: 2.4225673198067206

Epoch: 6| Step: 4
Training loss: 2.0308549937065044
Validation loss: 2.4260976128436513

Epoch: 6| Step: 5
Training loss: 2.5473476041633516
Validation loss: 2.4413187956866613

Epoch: 6| Step: 6
Training loss: 2.031891589441695
Validation loss: 2.443057019196971

Epoch: 6| Step: 7
Training loss: 2.352359775981454
Validation loss: 2.4508241881505337

Epoch: 6| Step: 8
Training loss: 2.382922160642609
Validation loss: 2.4505493320027023

Epoch: 6| Step: 9
Training loss: 2.574848844665639
Validation loss: 2.406736920465629

Epoch: 6| Step: 10
Training loss: 2.4466875494118616
Validation loss: 2.463683403277432

Epoch: 6| Step: 11
Training loss: 1.9957505619775096
Validation loss: 2.469508769830754

Epoch: 6| Step: 12
Training loss: 2.1083645131013236
Validation loss: 2.474139869821221

Epoch: 6| Step: 13
Training loss: 2.3450028186447676
Validation loss: 2.4567123172964473

Epoch: 195| Step: 0
Training loss: 2.1727100111898525
Validation loss: 2.4390345671106535

Epoch: 6| Step: 1
Training loss: 2.1737966475217068
Validation loss: 2.435852094285735

Epoch: 6| Step: 2
Training loss: 2.3653853704512144
Validation loss: 2.4491285244118663

Epoch: 6| Step: 3
Training loss: 1.997557161489648
Validation loss: 2.421514505846426

Epoch: 6| Step: 4
Training loss: 2.389239539303641
Validation loss: 2.437783964374493

Epoch: 6| Step: 5
Training loss: 2.806517107853142
Validation loss: 2.4496486536620283

Epoch: 6| Step: 6
Training loss: 1.7706893263960206
Validation loss: 2.3892464080673914

Epoch: 6| Step: 7
Training loss: 2.0233726932943514
Validation loss: 2.3735186410181064

Epoch: 6| Step: 8
Training loss: 1.98002056640964
Validation loss: 2.4284094794145497

Epoch: 6| Step: 9
Training loss: 1.6334539002404738
Validation loss: 2.381441976878624

Epoch: 6| Step: 10
Training loss: 2.133623912015612
Validation loss: 2.3995612212518975

Epoch: 6| Step: 11
Training loss: 2.6304003252012977
Validation loss: 2.4126729741783084

Epoch: 6| Step: 12
Training loss: 1.9676279170370512
Validation loss: 2.4256039178577984

Epoch: 6| Step: 13
Training loss: 3.3621267005152236
Validation loss: 2.433620446084605

Epoch: 196| Step: 0
Training loss: 1.8005989296855414
Validation loss: 2.3964129038956172

Epoch: 6| Step: 1
Training loss: 1.8082046914232928
Validation loss: 2.3900084542651703

Epoch: 6| Step: 2
Training loss: 2.0564722932358412
Validation loss: 2.425405395953917

Epoch: 6| Step: 3
Training loss: 2.2806726012380834
Validation loss: 2.4247803329444615

Epoch: 6| Step: 4
Training loss: 2.0710374246749614
Validation loss: 2.379169793217875

Epoch: 6| Step: 5
Training loss: 2.072547943701875
Validation loss: 2.409037063603943

Epoch: 6| Step: 6
Training loss: 2.378834189339878
Validation loss: 2.409990109856658

Epoch: 6| Step: 7
Training loss: 1.9072054985355955
Validation loss: 2.4038031061134295

Epoch: 6| Step: 8
Training loss: 2.050474307386929
Validation loss: 2.402094764455659

Epoch: 6| Step: 9
Training loss: 2.5195576511153104
Validation loss: 2.4391575697166337

Epoch: 6| Step: 10
Training loss: 2.5506851622167974
Validation loss: 2.3888830725575287

Epoch: 6| Step: 11
Training loss: 2.080657333897409
Validation loss: 2.4010445210369125

Epoch: 6| Step: 12
Training loss: 2.6364195251221054
Validation loss: 2.4222065381441755

Epoch: 6| Step: 13
Training loss: 2.6845219990423406
Validation loss: 2.4016925870020356

Epoch: 197| Step: 0
Training loss: 2.281697477583614
Validation loss: 2.402652996230344

Epoch: 6| Step: 1
Training loss: 2.5373348990412317
Validation loss: 2.429332679680819

Epoch: 6| Step: 2
Training loss: 2.3223588441918896
Validation loss: 2.4192096123125806

Epoch: 6| Step: 3
Training loss: 2.082166141341494
Validation loss: 2.414375458785952

Epoch: 6| Step: 4
Training loss: 2.0332444009979356
Validation loss: 2.4065892758505956

Epoch: 6| Step: 5
Training loss: 2.006713922879898
Validation loss: 2.4368029361014947

Epoch: 6| Step: 6
Training loss: 2.178674168364093
Validation loss: 2.4584947657848106

Epoch: 6| Step: 7
Training loss: 2.328152547583718
Validation loss: 2.4468944666078483

Epoch: 6| Step: 8
Training loss: 1.755240495728565
Validation loss: 2.434573844311922

Epoch: 6| Step: 9
Training loss: 2.376638750587362
Validation loss: 2.413320342675771

Epoch: 6| Step: 10
Training loss: 1.9859118180073776
Validation loss: 2.4628799889870523

Epoch: 6| Step: 11
Training loss: 1.6476833552902503
Validation loss: 2.443054395801373

Epoch: 6| Step: 12
Training loss: 2.6489748789372696
Validation loss: 2.4191928053846032

Epoch: 6| Step: 13
Training loss: 2.3916250892064537
Validation loss: 2.43708509348451

Epoch: 198| Step: 0
Training loss: 2.775141490731437
Validation loss: 2.4394615248926277

Epoch: 6| Step: 1
Training loss: 2.134190823161211
Validation loss: 2.4544706095560387

Epoch: 6| Step: 2
Training loss: 1.9047441632148463
Validation loss: 2.4360550235709857

Epoch: 6| Step: 3
Training loss: 1.8936788312676496
Validation loss: 2.4294287446822582

Epoch: 6| Step: 4
Training loss: 1.8085766785312354
Validation loss: 2.433790392632514

Epoch: 6| Step: 5
Training loss: 2.888431521018168
Validation loss: 2.4262382514503784

Epoch: 6| Step: 6
Training loss: 1.8299361166721297
Validation loss: 2.4407650325619454

Epoch: 6| Step: 7
Training loss: 2.4035189103616017
Validation loss: 2.4014468956298987

Epoch: 6| Step: 8
Training loss: 2.333553667110563
Validation loss: 2.4102114845294644

Epoch: 6| Step: 9
Training loss: 2.4018049923066895
Validation loss: 2.4248667254634166

Epoch: 6| Step: 10
Training loss: 1.650953352659078
Validation loss: 2.4106979459412936

Epoch: 6| Step: 11
Training loss: 1.9581640927929378
Validation loss: 2.3911259224432255

Epoch: 6| Step: 12
Training loss: 2.2193791746563805
Validation loss: 2.4385159712415785

Epoch: 6| Step: 13
Training loss: 2.1798152544325933
Validation loss: 2.4398236984842168

Epoch: 199| Step: 0
Training loss: 2.0958496497589065
Validation loss: 2.422708087159201

Epoch: 6| Step: 1
Training loss: 2.1120188780287696
Validation loss: 2.4011308434912193

Epoch: 6| Step: 2
Training loss: 2.2463833033471023
Validation loss: 2.452877002096884

Epoch: 6| Step: 3
Training loss: 2.5862769512027812
Validation loss: 2.3675323335882736

Epoch: 6| Step: 4
Training loss: 2.5757461207606003
Validation loss: 2.4092669698289666

Epoch: 6| Step: 5
Training loss: 1.9384571910437949
Validation loss: 2.4060563477120205

Epoch: 6| Step: 6
Training loss: 1.5372365586280523
Validation loss: 2.3867789895415714

Epoch: 6| Step: 7
Training loss: 1.6270896973365392
Validation loss: 2.4201004476369996

Epoch: 6| Step: 8
Training loss: 2.856246153580561
Validation loss: 2.389771888013258

Epoch: 6| Step: 9
Training loss: 1.7450058383352116
Validation loss: 2.379226616389917

Epoch: 6| Step: 10
Training loss: 2.4228345385272023
Validation loss: 2.3736693632927324

Epoch: 6| Step: 11
Training loss: 1.9924833190296294
Validation loss: 2.3930693592274155

Epoch: 6| Step: 12
Training loss: 2.0303152427754627
Validation loss: 2.397103185418563

Epoch: 6| Step: 13
Training loss: 3.1350961481222854
Validation loss: 2.415784049465591

Epoch: 200| Step: 0
Training loss: 1.9317081389474777
Validation loss: 2.420993075127876

Epoch: 6| Step: 1
Training loss: 1.36481230273208
Validation loss: 2.4031321757401063

Epoch: 6| Step: 2
Training loss: 2.2289229880746393
Validation loss: 2.4352438734492474

Epoch: 6| Step: 3
Training loss: 2.026386953969858
Validation loss: 2.4232083305306773

Epoch: 6| Step: 4
Training loss: 1.9233421370218304
Validation loss: 2.4224119138380478

Epoch: 6| Step: 5
Training loss: 2.9425265545809545
Validation loss: 2.4065728026306457

Epoch: 6| Step: 6
Training loss: 2.285568226251802
Validation loss: 2.4325211008700025

Epoch: 6| Step: 7
Training loss: 2.573731534057003
Validation loss: 2.4128601624890074

Epoch: 6| Step: 8
Training loss: 2.0247838317026616
Validation loss: 2.447390353966359

Epoch: 6| Step: 9
Training loss: 2.4661534815142314
Validation loss: 2.434811804396686

Epoch: 6| Step: 10
Training loss: 2.8236544349984
Validation loss: 2.4883342761803564

Epoch: 6| Step: 11
Training loss: 2.1998248984271984
Validation loss: 2.476457727080002

Epoch: 6| Step: 12
Training loss: 1.7754236602227673
Validation loss: 2.4335313182373097

Epoch: 6| Step: 13
Training loss: 1.2683423857965295
Validation loss: 2.4623022349958994

Epoch: 201| Step: 0
Training loss: 2.1897290453229945
Validation loss: 2.442181164821457

Epoch: 6| Step: 1
Training loss: 1.9262137091879876
Validation loss: 2.4325399783025015

Epoch: 6| Step: 2
Training loss: 2.3398829792790856
Validation loss: 2.4391287512103137

Epoch: 6| Step: 3
Training loss: 2.015101638388771
Validation loss: 2.4605169684074952

Epoch: 6| Step: 4
Training loss: 2.2336530252592404
Validation loss: 2.423315591900233

Epoch: 6| Step: 5
Training loss: 1.9961148315033095
Validation loss: 2.424133945183999

Epoch: 6| Step: 6
Training loss: 2.2069301345752845
Validation loss: 2.4214590783948835

Epoch: 6| Step: 7
Training loss: 2.277691089975763
Validation loss: 2.4502165418456308

Epoch: 6| Step: 8
Training loss: 2.7691972151785675
Validation loss: 2.443631892532385

Epoch: 6| Step: 9
Training loss: 1.9601109803173193
Validation loss: 2.4015046525861083

Epoch: 6| Step: 10
Training loss: 2.3169773163390985
Validation loss: 2.4053824567753113

Epoch: 6| Step: 11
Training loss: 2.202719793188568
Validation loss: 2.4122974503275203

Epoch: 6| Step: 12
Training loss: 2.020337060246536
Validation loss: 2.420988237971487

Epoch: 6| Step: 13
Training loss: 2.6149864848500624
Validation loss: 2.396508549102486

Epoch: 202| Step: 0
Training loss: 2.648924026137091
Validation loss: 2.3771804257474907

Epoch: 6| Step: 1
Training loss: 1.9183888645348444
Validation loss: 2.405927097584749

Epoch: 6| Step: 2
Training loss: 1.9141645131855356
Validation loss: 2.3884998754946065

Epoch: 6| Step: 3
Training loss: 1.9495289160165759
Validation loss: 2.4080979328803918

Epoch: 6| Step: 4
Training loss: 2.683086319526184
Validation loss: 2.388616627775439

Epoch: 6| Step: 5
Training loss: 2.118063319735723
Validation loss: 2.44208588280528

Epoch: 6| Step: 6
Training loss: 2.059560704287984
Validation loss: 2.448144559042077

Epoch: 6| Step: 7
Training loss: 1.5633759141557741
Validation loss: 2.415020449530619

Epoch: 6| Step: 8
Training loss: 1.8409001583520574
Validation loss: 2.447052589524078

Epoch: 6| Step: 9
Training loss: 2.8585961120045242
Validation loss: 2.4017732759429333

Epoch: 6| Step: 10
Training loss: 1.9969172561305666
Validation loss: 2.435148636874537

Epoch: 6| Step: 11
Training loss: 2.5025452055454145
Validation loss: 2.463899948296858

Epoch: 6| Step: 12
Training loss: 1.8971599157493033
Validation loss: 2.425964422531168

Epoch: 6| Step: 13
Training loss: 1.9922192140934627
Validation loss: 2.4197679683069104

Epoch: 203| Step: 0
Training loss: 2.2568458679059975
Validation loss: 2.4210926084879034

Epoch: 6| Step: 1
Training loss: 2.6383189227187973
Validation loss: 2.4211708646281815

Epoch: 6| Step: 2
Training loss: 2.3370846384414
Validation loss: 2.408640706926398

Epoch: 6| Step: 3
Training loss: 2.954184044561311
Validation loss: 2.3745671845607434

Epoch: 6| Step: 4
Training loss: 2.114749306865921
Validation loss: 2.37410390061359

Epoch: 6| Step: 5
Training loss: 2.5809232380273537
Validation loss: 2.449337718091996

Epoch: 6| Step: 6
Training loss: 1.9059584973190806
Validation loss: 2.4118162651539916

Epoch: 6| Step: 7
Training loss: 1.7234313328374118
Validation loss: 2.443944578887846

Epoch: 6| Step: 8
Training loss: 2.14181619065303
Validation loss: 2.40623562332672

Epoch: 6| Step: 9
Training loss: 1.9401482971770643
Validation loss: 2.4108197571061427

Epoch: 6| Step: 10
Training loss: 1.739026816277056
Validation loss: 2.4065639001846466

Epoch: 6| Step: 11
Training loss: 2.126660091226551
Validation loss: 2.3913010674703434

Epoch: 6| Step: 12
Training loss: 1.50988745352069
Validation loss: 2.388542388244302

Epoch: 6| Step: 13
Training loss: 1.5832447060659602
Validation loss: 2.4048635091760353

Epoch: 204| Step: 0
Training loss: 2.3276294974616585
Validation loss: 2.4225053711142097

Epoch: 6| Step: 1
Training loss: 2.1561449550528153
Validation loss: 2.407680770627571

Epoch: 6| Step: 2
Training loss: 2.5595658413972777
Validation loss: 2.411216334776787

Epoch: 6| Step: 3
Training loss: 2.1790980700849265
Validation loss: 2.3948970390091775

Epoch: 6| Step: 4
Training loss: 1.6443424796089718
Validation loss: 2.4418735707603867

Epoch: 6| Step: 5
Training loss: 1.9365842562467992
Validation loss: 2.428924974261639

Epoch: 6| Step: 6
Training loss: 2.1993004900578836
Validation loss: 2.4071988835917426

Epoch: 6| Step: 7
Training loss: 2.168069043288254
Validation loss: 2.411854070276781

Epoch: 6| Step: 8
Training loss: 2.2493706988743742
Validation loss: 2.4748497464588852

Epoch: 6| Step: 9
Training loss: 2.117077476204564
Validation loss: 2.4483615454406045

Epoch: 6| Step: 10
Training loss: 1.5738631005281563
Validation loss: 2.4326394870987573

Epoch: 6| Step: 11
Training loss: 2.252480940489412
Validation loss: 2.449522163155894

Epoch: 6| Step: 12
Training loss: 2.332519991217638
Validation loss: 2.421015639572313

Epoch: 6| Step: 13
Training loss: 2.9855446645410826
Validation loss: 2.4266887975947045

Epoch: 205| Step: 0
Training loss: 1.7841337184485853
Validation loss: 2.4169656280785228

Epoch: 6| Step: 1
Training loss: 2.2873059716822457
Validation loss: 2.404133067252858

Epoch: 6| Step: 2
Training loss: 2.7127167856807253
Validation loss: 2.3999883382267804

Epoch: 6| Step: 3
Training loss: 2.255106958191407
Validation loss: 2.4321174974675843

Epoch: 6| Step: 4
Training loss: 2.0241189052348916
Validation loss: 2.415488188789099

Epoch: 6| Step: 5
Training loss: 1.7405795901280448
Validation loss: 2.4049045022212647

Epoch: 6| Step: 6
Training loss: 2.478204706168122
Validation loss: 2.4084131484444216

Epoch: 6| Step: 7
Training loss: 1.7790193477391207
Validation loss: 2.3427868620389263

Epoch: 6| Step: 8
Training loss: 1.9790429996871204
Validation loss: 2.3985746589689616

Epoch: 6| Step: 9
Training loss: 2.349107036972727
Validation loss: 2.407322176355429

Epoch: 6| Step: 10
Training loss: 2.2955035831902886
Validation loss: 2.428458949465295

Epoch: 6| Step: 11
Training loss: 1.8699218010489005
Validation loss: 2.406561304119943

Epoch: 6| Step: 12
Training loss: 2.213789431599342
Validation loss: 2.3949732791429823

Epoch: 6| Step: 13
Training loss: 2.2687939810365
Validation loss: 2.4161025346428415

Epoch: 206| Step: 0
Training loss: 1.7911052119854969
Validation loss: 2.3952398040260716

Epoch: 6| Step: 1
Training loss: 2.0646887061068067
Validation loss: 2.3888459615132716

Epoch: 6| Step: 2
Training loss: 1.9669583357571385
Validation loss: 2.3803316477832577

Epoch: 6| Step: 3
Training loss: 2.5475970221884343
Validation loss: 2.4046570814195536

Epoch: 6| Step: 4
Training loss: 1.3737141926119125
Validation loss: 2.4302007452722267

Epoch: 6| Step: 5
Training loss: 1.8646790321839322
Validation loss: 2.3923230972300917

Epoch: 6| Step: 6
Training loss: 2.545808908331829
Validation loss: 2.395957483086241

Epoch: 6| Step: 7
Training loss: 1.6522466392026924
Validation loss: 2.410425382770267

Epoch: 6| Step: 8
Training loss: 2.52810020859001
Validation loss: 2.4470151757657215

Epoch: 6| Step: 9
Training loss: 2.0437883006015523
Validation loss: 2.4173118062937387

Epoch: 6| Step: 10
Training loss: 2.54639397507655
Validation loss: 2.404289674970132

Epoch: 6| Step: 11
Training loss: 2.0862281396816504
Validation loss: 2.4241264413328527

Epoch: 6| Step: 12
Training loss: 2.2641634732325553
Validation loss: 2.415416279131133

Epoch: 6| Step: 13
Training loss: 2.318033145618192
Validation loss: 2.4099539674231214

Epoch: 207| Step: 0
Training loss: 1.9429385242327546
Validation loss: 2.427758431177055

Epoch: 6| Step: 1
Training loss: 2.513296245972514
Validation loss: 2.3909576525589102

Epoch: 6| Step: 2
Training loss: 1.5716933067682641
Validation loss: 2.4012171681804917

Epoch: 6| Step: 3
Training loss: 2.160095765851914
Validation loss: 2.3550398355530473

Epoch: 6| Step: 4
Training loss: 2.242105196728245
Validation loss: 2.4187902498670875

Epoch: 6| Step: 5
Training loss: 2.108257760765423
Validation loss: 2.404549445120929

Epoch: 6| Step: 6
Training loss: 2.630286479330415
Validation loss: 2.4052928346741727

Epoch: 6| Step: 7
Training loss: 1.6584173452799775
Validation loss: 2.387625870696301

Epoch: 6| Step: 8
Training loss: 2.110876269691344
Validation loss: 2.4422821492451523

Epoch: 6| Step: 9
Training loss: 2.037766084673294
Validation loss: 2.4646617298970095

Epoch: 6| Step: 10
Training loss: 2.475472580460658
Validation loss: 2.4223183735805116

Epoch: 6| Step: 11
Training loss: 2.0892773582654702
Validation loss: 2.426516050478374

Epoch: 6| Step: 12
Training loss: 1.7271019968727754
Validation loss: 2.4310968191516835

Epoch: 6| Step: 13
Training loss: 2.719747426143045
Validation loss: 2.367773433428965

Epoch: 208| Step: 0
Training loss: 1.8905178071207178
Validation loss: 2.44099193918173

Epoch: 6| Step: 1
Training loss: 3.1019002504721835
Validation loss: 2.3801279164583327

Epoch: 6| Step: 2
Training loss: 1.3880080126467902
Validation loss: 2.370486851986191

Epoch: 6| Step: 3
Training loss: 2.318568026658779
Validation loss: 2.431086493268232

Epoch: 6| Step: 4
Training loss: 2.333529248414158
Validation loss: 2.3866568106986707

Epoch: 6| Step: 5
Training loss: 2.124469690908847
Validation loss: 2.424156963688095

Epoch: 6| Step: 6
Training loss: 2.690350905578621
Validation loss: 2.3873475409911356

Epoch: 6| Step: 7
Training loss: 2.0729445514688414
Validation loss: 2.403409833222059

Epoch: 6| Step: 8
Training loss: 1.922298043684447
Validation loss: 2.460121306172952

Epoch: 6| Step: 9
Training loss: 1.6924069728106304
Validation loss: 2.3694861026523046

Epoch: 6| Step: 10
Training loss: 2.2195076521921813
Validation loss: 2.387257638089298

Epoch: 6| Step: 11
Training loss: 1.7591719732139757
Validation loss: 2.4349095178605302

Epoch: 6| Step: 12
Training loss: 1.9759351616851182
Validation loss: 2.4185650036484088

Epoch: 6| Step: 13
Training loss: 2.108963198554604
Validation loss: 2.42334900457991

Epoch: 209| Step: 0
Training loss: 2.0920201457568917
Validation loss: 2.4092302791811635

Epoch: 6| Step: 1
Training loss: 2.6081770471260715
Validation loss: 2.3779563745818444

Epoch: 6| Step: 2
Training loss: 2.100867968521794
Validation loss: 2.398652001693861

Epoch: 6| Step: 3
Training loss: 2.4090423235566063
Validation loss: 2.363692681067737

Epoch: 6| Step: 4
Training loss: 1.8521024665087389
Validation loss: 2.3877978861867644

Epoch: 6| Step: 5
Training loss: 2.5648489629882487
Validation loss: 2.3737935000903287

Epoch: 6| Step: 6
Training loss: 1.8888053018488264
Validation loss: 2.429274256237748

Epoch: 6| Step: 7
Training loss: 1.6662671166561749
Validation loss: 2.450548710589899

Epoch: 6| Step: 8
Training loss: 1.7380701515517398
Validation loss: 2.4023794050661293

Epoch: 6| Step: 9
Training loss: 2.4046365852741176
Validation loss: 2.3829766803127996

Epoch: 6| Step: 10
Training loss: 1.7942774033852937
Validation loss: 2.4103826430891244

Epoch: 6| Step: 11
Training loss: 2.672226732091167
Validation loss: 2.4133922754809767

Epoch: 6| Step: 12
Training loss: 1.9090593617173535
Validation loss: 2.3997916990471193

Epoch: 6| Step: 13
Training loss: 2.6717191951900143
Validation loss: 2.401306091515424

Epoch: 210| Step: 0
Training loss: 2.0651055264237983
Validation loss: 2.407163426647634

Epoch: 6| Step: 1
Training loss: 2.2037934716275887
Validation loss: 2.3943908315129567

Epoch: 6| Step: 2
Training loss: 1.7708069369274797
Validation loss: 2.4128776611103535

Epoch: 6| Step: 3
Training loss: 2.6823922345218265
Validation loss: 2.449589093640763

Epoch: 6| Step: 4
Training loss: 2.0255744872699704
Validation loss: 2.4602447623371564

Epoch: 6| Step: 5
Training loss: 2.552886608111397
Validation loss: 2.4666372687670184

Epoch: 6| Step: 6
Training loss: 2.282899860901118
Validation loss: 2.4552851829217297

Epoch: 6| Step: 7
Training loss: 2.210388762513353
Validation loss: 2.4562732984225937

Epoch: 6| Step: 8
Training loss: 2.336336746034086
Validation loss: 2.454989669654765

Epoch: 6| Step: 9
Training loss: 2.0313194849894134
Validation loss: 2.462051153682837

Epoch: 6| Step: 10
Training loss: 1.463394465346256
Validation loss: 2.449811980780597

Epoch: 6| Step: 11
Training loss: 1.815689700314894
Validation loss: 2.455978703628735

Epoch: 6| Step: 12
Training loss: 2.2736764893647017
Validation loss: 2.439651077546247

Epoch: 6| Step: 13
Training loss: 2.234489918134424
Validation loss: 2.433219023714014

Epoch: 211| Step: 0
Training loss: 1.409341212034684
Validation loss: 2.4294366801058165

Epoch: 6| Step: 1
Training loss: 2.8946060397515603
Validation loss: 2.4283828506163654

Epoch: 6| Step: 2
Training loss: 2.8106235602377065
Validation loss: 2.426580270699592

Epoch: 6| Step: 3
Training loss: 1.8900557993165252
Validation loss: 2.415449998492551

Epoch: 6| Step: 4
Training loss: 2.136901512907579
Validation loss: 2.4202382156722404

Epoch: 6| Step: 5
Training loss: 2.3915451373371357
Validation loss: 2.4088263721852474

Epoch: 6| Step: 6
Training loss: 2.2909195693644766
Validation loss: 2.3963572991644635

Epoch: 6| Step: 7
Training loss: 1.969913925769084
Validation loss: 2.425674348139857

Epoch: 6| Step: 8
Training loss: 2.034679393585185
Validation loss: 2.374452350775267

Epoch: 6| Step: 9
Training loss: 2.450778494952827
Validation loss: 2.400626707629834

Epoch: 6| Step: 10
Training loss: 1.6917079453842487
Validation loss: 2.3919141385905576

Epoch: 6| Step: 11
Training loss: 1.7446072457242334
Validation loss: 2.413943421481103

Epoch: 6| Step: 12
Training loss: 1.4985400883757218
Validation loss: 2.3950250363360603

Epoch: 6| Step: 13
Training loss: 2.5578905842862825
Validation loss: 2.4330451281225693

Epoch: 212| Step: 0
Training loss: 1.985830899310598
Validation loss: 2.3981714849685853

Epoch: 6| Step: 1
Training loss: 2.647364216061037
Validation loss: 2.4055764814261433

Epoch: 6| Step: 2
Training loss: 2.672717045391098
Validation loss: 2.39551825107847

Epoch: 6| Step: 3
Training loss: 1.9551556216494772
Validation loss: 2.4148555814444226

Epoch: 6| Step: 4
Training loss: 2.3293382184538394
Validation loss: 2.3980859561166237

Epoch: 6| Step: 5
Training loss: 2.0262611747494743
Validation loss: 2.429234161463677

Epoch: 6| Step: 6
Training loss: 1.9842061849560202
Validation loss: 2.4237831138448107

Epoch: 6| Step: 7
Training loss: 1.698891724435189
Validation loss: 2.4418923806165114

Epoch: 6| Step: 8
Training loss: 2.402901834312379
Validation loss: 2.4258320344215423

Epoch: 6| Step: 9
Training loss: 2.6659109912502785
Validation loss: 2.426007528611762

Epoch: 6| Step: 10
Training loss: 1.5991062588768
Validation loss: 2.4082497111684136

Epoch: 6| Step: 11
Training loss: 1.9388790760077368
Validation loss: 2.4425837487222277

Epoch: 6| Step: 12
Training loss: 1.8038953223213432
Validation loss: 2.4336265211885166

Epoch: 6| Step: 13
Training loss: 1.822119540362132
Validation loss: 2.4414539288859114

Epoch: 213| Step: 0
Training loss: 2.18438215131776
Validation loss: 2.42657468506791

Epoch: 6| Step: 1
Training loss: 1.2448205452392942
Validation loss: 2.411148151980931

Epoch: 6| Step: 2
Training loss: 2.050365006120909
Validation loss: 2.4448436481667324

Epoch: 6| Step: 3
Training loss: 1.7573351402611095
Validation loss: 2.4412786918541745

Epoch: 6| Step: 4
Training loss: 2.2751661722047953
Validation loss: 2.4330171823739963

Epoch: 6| Step: 5
Training loss: 2.3807604349058487
Validation loss: 2.4326930137323988

Epoch: 6| Step: 6
Training loss: 2.118213137686451
Validation loss: 2.4037392820229466

Epoch: 6| Step: 7
Training loss: 2.207799079136104
Validation loss: 2.4043856492498925

Epoch: 6| Step: 8
Training loss: 2.1067838224396467
Validation loss: 2.3980916220016524

Epoch: 6| Step: 9
Training loss: 1.5706710785597109
Validation loss: 2.379646127345858

Epoch: 6| Step: 10
Training loss: 2.2771587525698593
Validation loss: 2.3697244278758984

Epoch: 6| Step: 11
Training loss: 2.753249589263794
Validation loss: 2.4166376630536983

Epoch: 6| Step: 12
Training loss: 1.921397638350483
Validation loss: 2.3902971060393474

Epoch: 6| Step: 13
Training loss: 2.523730659580803
Validation loss: 2.4254140717508523

Epoch: 214| Step: 0
Training loss: 1.7365684042653982
Validation loss: 2.4148253550269287

Epoch: 6| Step: 1
Training loss: 2.1135596693038994
Validation loss: 2.3801914280098795

Epoch: 6| Step: 2
Training loss: 2.250837170304445
Validation loss: 2.3950931654117684

Epoch: 6| Step: 3
Training loss: 2.2213406549350627
Validation loss: 2.4071642706638

Epoch: 6| Step: 4
Training loss: 2.0479265380290315
Validation loss: 2.413818885497165

Epoch: 6| Step: 5
Training loss: 2.010614599521763
Validation loss: 2.3998024234490924

Epoch: 6| Step: 6
Training loss: 2.538653813262799
Validation loss: 2.4140627601804727

Epoch: 6| Step: 7
Training loss: 1.6641604255911995
Validation loss: 2.3759965667786815

Epoch: 6| Step: 8
Training loss: 2.061626133603836
Validation loss: 2.4243353227191844

Epoch: 6| Step: 9
Training loss: 2.035597272010035
Validation loss: 2.3611900455938

Epoch: 6| Step: 10
Training loss: 2.023009265963293
Validation loss: 2.4368661035728283

Epoch: 6| Step: 11
Training loss: 2.7966311897267646
Validation loss: 2.385984467567002

Epoch: 6| Step: 12
Training loss: 1.705801025119455
Validation loss: 2.394745184141776

Epoch: 6| Step: 13
Training loss: 2.247124636050223
Validation loss: 2.4285166261274815

Epoch: 215| Step: 0
Training loss: 2.501570589718435
Validation loss: 2.4429890041324396

Epoch: 6| Step: 1
Training loss: 1.6657886417583807
Validation loss: 2.411687714905917

Epoch: 6| Step: 2
Training loss: 2.023462832966117
Validation loss: 2.3850518521869146

Epoch: 6| Step: 3
Training loss: 1.404055557420599
Validation loss: 2.3956384198771015

Epoch: 6| Step: 4
Training loss: 2.2691589155098613
Validation loss: 2.4294828211256045

Epoch: 6| Step: 5
Training loss: 2.2511794919373784
Validation loss: 2.405951604625115

Epoch: 6| Step: 6
Training loss: 2.281716599495077
Validation loss: 2.419430550036638

Epoch: 6| Step: 7
Training loss: 2.0766921302169066
Validation loss: 2.409131263464297

Epoch: 6| Step: 8
Training loss: 2.337037506860273
Validation loss: 2.409920673268982

Epoch: 6| Step: 9
Training loss: 2.511131300981014
Validation loss: 2.412432467967917

Epoch: 6| Step: 10
Training loss: 2.228683799663343
Validation loss: 2.3950649229451355

Epoch: 6| Step: 11
Training loss: 1.7877906376302604
Validation loss: 2.4013070907912533

Epoch: 6| Step: 12
Training loss: 1.578323200734426
Validation loss: 2.401772693145227

Epoch: 6| Step: 13
Training loss: 2.2262776510501627
Validation loss: 2.384441071088422

Epoch: 216| Step: 0
Training loss: 2.164182694054698
Validation loss: 2.4343120351291327

Epoch: 6| Step: 1
Training loss: 1.8007851557161751
Validation loss: 2.3792445342373845

Epoch: 6| Step: 2
Training loss: 2.1913556587784875
Validation loss: 2.4033293410982557

Epoch: 6| Step: 3
Training loss: 1.8862971433053162
Validation loss: 2.439838467757804

Epoch: 6| Step: 4
Training loss: 1.745074014924845
Validation loss: 2.392639315276613

Epoch: 6| Step: 5
Training loss: 2.2705409943811907
Validation loss: 2.3951819463061317

Epoch: 6| Step: 6
Training loss: 1.8898943285188008
Validation loss: 2.448459558934458

Epoch: 6| Step: 7
Training loss: 2.2779644861174213
Validation loss: 2.4253989778736402

Epoch: 6| Step: 8
Training loss: 2.500101087433805
Validation loss: 2.403470267744275

Epoch: 6| Step: 9
Training loss: 2.3059087071738795
Validation loss: 2.4082973364556817

Epoch: 6| Step: 10
Training loss: 1.568623407735008
Validation loss: 2.4347806790895548

Epoch: 6| Step: 11
Training loss: 2.3486773766237268
Validation loss: 2.425914198328881

Epoch: 6| Step: 12
Training loss: 2.499660564267468
Validation loss: 2.39241464216642

Epoch: 6| Step: 13
Training loss: 1.8621650087317378
Validation loss: 2.3737977595128923

Epoch: 217| Step: 0
Training loss: 2.6441293971764037
Validation loss: 2.4162230457520684

Epoch: 6| Step: 1
Training loss: 2.113336643473122
Validation loss: 2.4157090169052617

Epoch: 6| Step: 2
Training loss: 1.6213704436069574
Validation loss: 2.4510369083637324

Epoch: 6| Step: 3
Training loss: 2.149095469204287
Validation loss: 2.43245527584945

Epoch: 6| Step: 4
Training loss: 1.8862819126430264
Validation loss: 2.4234970340086113

Epoch: 6| Step: 5
Training loss: 1.7825053292257675
Validation loss: 2.40950087939122

Epoch: 6| Step: 6
Training loss: 2.090893975305012
Validation loss: 2.4356797212987673

Epoch: 6| Step: 7
Training loss: 2.340641554403397
Validation loss: 2.3989697578879867

Epoch: 6| Step: 8
Training loss: 2.056162953490942
Validation loss: 2.3688693774595695

Epoch: 6| Step: 9
Training loss: 2.27646165780216
Validation loss: 2.4327589108283747

Epoch: 6| Step: 10
Training loss: 2.5213749726641415
Validation loss: 2.4302669430750368

Epoch: 6| Step: 11
Training loss: 1.8252863567865838
Validation loss: 2.4183962095878164

Epoch: 6| Step: 12
Training loss: 1.5981245403863502
Validation loss: 2.438005149460279

Epoch: 6| Step: 13
Training loss: 1.4795443988312054
Validation loss: 2.401828643214944

Epoch: 218| Step: 0
Training loss: 2.025750565066607
Validation loss: 2.4372981187439593

Epoch: 6| Step: 1
Training loss: 1.4133951709522854
Validation loss: 2.4199503141530068

Epoch: 6| Step: 2
Training loss: 2.487597600661116
Validation loss: 2.384232189679986

Epoch: 6| Step: 3
Training loss: 2.1059375021736813
Validation loss: 2.4526300735068234

Epoch: 6| Step: 4
Training loss: 2.0684695696271755
Validation loss: 2.447099589537818

Epoch: 6| Step: 5
Training loss: 1.3830408457353276
Validation loss: 2.423061410253098

Epoch: 6| Step: 6
Training loss: 2.0638908551655857
Validation loss: 2.3636556018524297

Epoch: 6| Step: 7
Training loss: 2.300784980498886
Validation loss: 2.432703046156707

Epoch: 6| Step: 8
Training loss: 1.9783871638176629
Validation loss: 2.440863580061296

Epoch: 6| Step: 9
Training loss: 2.285908267185617
Validation loss: 2.395170324609669

Epoch: 6| Step: 10
Training loss: 2.0812810580482233
Validation loss: 2.4437896967834107

Epoch: 6| Step: 11
Training loss: 2.214497749442884
Validation loss: 2.4254453965312837

Epoch: 6| Step: 12
Training loss: 2.07516176443471
Validation loss: 2.3997833825015884

Epoch: 6| Step: 13
Training loss: 2.3225664179803718
Validation loss: 2.390473073225176

Epoch: 219| Step: 0
Training loss: 1.8739645960139288
Validation loss: 2.419751488393794

Epoch: 6| Step: 1
Training loss: 2.1645619611324465
Validation loss: 2.389337630437706

Epoch: 6| Step: 2
Training loss: 2.5109316243623403
Validation loss: 2.4056240599949463

Epoch: 6| Step: 3
Training loss: 2.202020787770672
Validation loss: 2.4042029834250123

Epoch: 6| Step: 4
Training loss: 1.1019225918536655
Validation loss: 2.4058497926701334

Epoch: 6| Step: 5
Training loss: 1.7190697112536357
Validation loss: 2.416265368072394

Epoch: 6| Step: 6
Training loss: 2.181983750014456
Validation loss: 2.386894767254545

Epoch: 6| Step: 7
Training loss: 2.18426798065808
Validation loss: 2.400687950651419

Epoch: 6| Step: 8
Training loss: 1.6802072829708152
Validation loss: 2.3960369442687117

Epoch: 6| Step: 9
Training loss: 2.8999797491484647
Validation loss: 2.4089134677725883

Epoch: 6| Step: 10
Training loss: 2.8156388463432434
Validation loss: 2.409317827818588

Epoch: 6| Step: 11
Training loss: 1.7571108625735667
Validation loss: 2.435754938571365

Epoch: 6| Step: 12
Training loss: 1.2456628419111162
Validation loss: 2.4185940359107807

Epoch: 6| Step: 13
Training loss: 1.8957943196177485
Validation loss: 2.389735858179662

Epoch: 220| Step: 0
Training loss: 1.30631561114519
Validation loss: 2.397365730229265

Epoch: 6| Step: 1
Training loss: 1.622265422186321
Validation loss: 2.40875649708453

Epoch: 6| Step: 2
Training loss: 1.6877133269927351
Validation loss: 2.40725357495453

Epoch: 6| Step: 3
Training loss: 2.47016228949642
Validation loss: 2.417057078660782

Epoch: 6| Step: 4
Training loss: 2.1228534852553627
Validation loss: 2.416668713335041

Epoch: 6| Step: 5
Training loss: 2.326203647912207
Validation loss: 2.406833991726303

Epoch: 6| Step: 6
Training loss: 2.8515999569457713
Validation loss: 2.4094112327918564

Epoch: 6| Step: 7
Training loss: 1.9431923952681773
Validation loss: 2.4411741909201545

Epoch: 6| Step: 8
Training loss: 2.4656742105540936
Validation loss: 2.4093122723941294

Epoch: 6| Step: 9
Training loss: 1.6141356637183415
Validation loss: 2.40380707986531

Epoch: 6| Step: 10
Training loss: 2.4956897772854343
Validation loss: 2.4205309649815434

Epoch: 6| Step: 11
Training loss: 1.5362933657603686
Validation loss: 2.417798894815595

Epoch: 6| Step: 12
Training loss: 1.3479842077173498
Validation loss: 2.424442825017696

Epoch: 6| Step: 13
Training loss: 2.480123949491252
Validation loss: 2.4120527110926098

Epoch: 221| Step: 0
Training loss: 2.4575182215343965
Validation loss: 2.375626835897175

Epoch: 6| Step: 1
Training loss: 2.103946963885559
Validation loss: 2.4097474634839315

Epoch: 6| Step: 2
Training loss: 2.154141044341344
Validation loss: 2.4017468503010937

Epoch: 6| Step: 3
Training loss: 2.276453488684761
Validation loss: 2.435387578721909

Epoch: 6| Step: 4
Training loss: 1.8780878072854819
Validation loss: 2.3657900031775068

Epoch: 6| Step: 5
Training loss: 2.4763126668457507
Validation loss: 2.4339571485144815

Epoch: 6| Step: 6
Training loss: 1.8287880502055078
Validation loss: 2.4268876750832518

Epoch: 6| Step: 7
Training loss: 1.6893210298792196
Validation loss: 2.3871513318268445

Epoch: 6| Step: 8
Training loss: 1.8602300649301997
Validation loss: 2.4531085090404265

Epoch: 6| Step: 9
Training loss: 2.5420180739653877
Validation loss: 2.4279358899926495

Epoch: 6| Step: 10
Training loss: 1.8226013201478237
Validation loss: 2.424400875970078

Epoch: 6| Step: 11
Training loss: 1.9681727456206692
Validation loss: 2.414392299248164

Epoch: 6| Step: 12
Training loss: 2.1606061856590286
Validation loss: 2.3790710511754622

Epoch: 6| Step: 13
Training loss: 1.88095514008134
Validation loss: 2.4215766513911032

Epoch: 222| Step: 0
Training loss: 1.5523584450581507
Validation loss: 2.4075525032323983

Epoch: 6| Step: 1
Training loss: 2.24543511063214
Validation loss: 2.432470035584896

Epoch: 6| Step: 2
Training loss: 2.5879777771291916
Validation loss: 2.397364633068385

Epoch: 6| Step: 3
Training loss: 2.279045607602174
Validation loss: 2.421994934923079

Epoch: 6| Step: 4
Training loss: 2.0754197948437088
Validation loss: 2.40254697102703

Epoch: 6| Step: 5
Training loss: 2.0504039598999007
Validation loss: 2.3848327980398167

Epoch: 6| Step: 6
Training loss: 1.5007426489771196
Validation loss: 2.402892319736243

Epoch: 6| Step: 7
Training loss: 2.3748359623526625
Validation loss: 2.4119633729783825

Epoch: 6| Step: 8
Training loss: 2.111821091486855
Validation loss: 2.4039924385989693

Epoch: 6| Step: 9
Training loss: 1.6557717262534861
Validation loss: 2.4131000927553563

Epoch: 6| Step: 10
Training loss: 2.4107910507332257
Validation loss: 2.4140935388015183

Epoch: 6| Step: 11
Training loss: 2.1807128244800054
Validation loss: 2.430438675733936

Epoch: 6| Step: 12
Training loss: 1.5561854368245418
Validation loss: 2.4119023817176686

Epoch: 6| Step: 13
Training loss: 1.6690602360638447
Validation loss: 2.4220225490012455

Epoch: 223| Step: 0
Training loss: 1.6714051914559434
Validation loss: 2.4127911251284506

Epoch: 6| Step: 1
Training loss: 1.558367337486551
Validation loss: 2.392481311131002

Epoch: 6| Step: 2
Training loss: 2.200524926416928
Validation loss: 2.408709122476809

Epoch: 6| Step: 3
Training loss: 1.9294185064839722
Validation loss: 2.3882829771830263

Epoch: 6| Step: 4
Training loss: 2.002960755373689
Validation loss: 2.365162141672993

Epoch: 6| Step: 5
Training loss: 1.9718296245305449
Validation loss: 2.4140877830391236

Epoch: 6| Step: 6
Training loss: 2.140706415786071
Validation loss: 2.376021088514478

Epoch: 6| Step: 7
Training loss: 1.6573718608041321
Validation loss: 2.3584736248092057

Epoch: 6| Step: 8
Training loss: 2.212161099615454
Validation loss: 2.396226962061156

Epoch: 6| Step: 9
Training loss: 2.3006821823164363
Validation loss: 2.392626781190713

Epoch: 6| Step: 10
Training loss: 2.317520156822074
Validation loss: 2.3773494513439193

Epoch: 6| Step: 11
Training loss: 2.317614286993495
Validation loss: 2.4153519669268975

Epoch: 6| Step: 12
Training loss: 1.6683536416010856
Validation loss: 2.415710808273244

Epoch: 6| Step: 13
Training loss: 2.9306412835460955
Validation loss: 2.4399908773206986

Epoch: 224| Step: 0
Training loss: 2.5754601780325768
Validation loss: 2.3858583776370965

Epoch: 6| Step: 1
Training loss: 1.9767653772024507
Validation loss: 2.443390230496964

Epoch: 6| Step: 2
Training loss: 2.1285560249839235
Validation loss: 2.44708335550009

Epoch: 6| Step: 3
Training loss: 2.305096502704341
Validation loss: 2.458338475904166

Epoch: 6| Step: 4
Training loss: 1.988213258791134
Validation loss: 2.488042148347823

Epoch: 6| Step: 5
Training loss: 1.505176037856617
Validation loss: 2.4209322626435257

Epoch: 6| Step: 6
Training loss: 2.0970939010312417
Validation loss: 2.4502611762326443

Epoch: 6| Step: 7
Training loss: 1.931396530666358
Validation loss: 2.496997121907496

Epoch: 6| Step: 8
Training loss: 2.2013330409055376
Validation loss: 2.4778987454589534

Epoch: 6| Step: 9
Training loss: 1.7738344529674757
Validation loss: 2.4490298164468793

Epoch: 6| Step: 10
Training loss: 1.6676473911006853
Validation loss: 2.469147315452348

Epoch: 6| Step: 11
Training loss: 2.3902305327445523
Validation loss: 2.4711917885358474

Epoch: 6| Step: 12
Training loss: 2.3332218983698207
Validation loss: 2.4125253798981645

Epoch: 6| Step: 13
Training loss: 1.4458814171409327
Validation loss: 2.438823514168947

Epoch: 225| Step: 0
Training loss: 1.6358571846237395
Validation loss: 2.4181470830886265

Epoch: 6| Step: 1
Training loss: 2.073397198927172
Validation loss: 2.426462567194612

Epoch: 6| Step: 2
Training loss: 2.5950249904833114
Validation loss: 2.4229611134373674

Epoch: 6| Step: 3
Training loss: 2.307541557425479
Validation loss: 2.3609879382162773

Epoch: 6| Step: 4
Training loss: 1.7633033274433398
Validation loss: 2.4118854324590577

Epoch: 6| Step: 5
Training loss: 2.0334559273372146
Validation loss: 2.389177813430696

Epoch: 6| Step: 6
Training loss: 1.69280053303337
Validation loss: 2.421067883570612

Epoch: 6| Step: 7
Training loss: 1.7839885874498658
Validation loss: 2.393259245218522

Epoch: 6| Step: 8
Training loss: 1.5872322397372503
Validation loss: 2.3965011464914654

Epoch: 6| Step: 9
Training loss: 2.8129728979330064
Validation loss: 2.386803214682532

Epoch: 6| Step: 10
Training loss: 2.0588977451732142
Validation loss: 2.4162137565778146

Epoch: 6| Step: 11
Training loss: 1.7425494993997377
Validation loss: 2.384237129363684

Epoch: 6| Step: 12
Training loss: 1.586148478187899
Validation loss: 2.3950979274920137

Epoch: 6| Step: 13
Training loss: 2.1963180465448007
Validation loss: 2.4037352505667062

Epoch: 226| Step: 0
Training loss: 1.5660836893668326
Validation loss: 2.3797958410443982

Epoch: 6| Step: 1
Training loss: 2.235309752093695
Validation loss: 2.402739653274115

Epoch: 6| Step: 2
Training loss: 2.204725617444895
Validation loss: 2.387693674051019

Epoch: 6| Step: 3
Training loss: 2.872719067220525
Validation loss: 2.3926400374471117

Epoch: 6| Step: 4
Training loss: 1.3377600835891714
Validation loss: 2.433476082321381

Epoch: 6| Step: 5
Training loss: 1.8981915852332947
Validation loss: 2.3443805833463873

Epoch: 6| Step: 6
Training loss: 1.8586852132541445
Validation loss: 2.383743972850285

Epoch: 6| Step: 7
Training loss: 2.529732143109493
Validation loss: 2.4066570274932184

Epoch: 6| Step: 8
Training loss: 2.277534071230917
Validation loss: 2.3787579029065284

Epoch: 6| Step: 9
Training loss: 1.4538898711022445
Validation loss: 2.412840902649588

Epoch: 6| Step: 10
Training loss: 1.625418535766205
Validation loss: 2.4198344769385574

Epoch: 6| Step: 11
Training loss: 2.0977494487268467
Validation loss: 2.3834463442802867

Epoch: 6| Step: 12
Training loss: 1.8441977522974204
Validation loss: 2.4189954545969816

Epoch: 6| Step: 13
Training loss: 1.8879836997403419
Validation loss: 2.4401385806045512

Epoch: 227| Step: 0
Training loss: 1.6475851739101977
Validation loss: 2.3739411055769546

Epoch: 6| Step: 1
Training loss: 2.3962790254318485
Validation loss: 2.3997228999978986

Epoch: 6| Step: 2
Training loss: 2.0005838018940567
Validation loss: 2.4141342885696004

Epoch: 6| Step: 3
Training loss: 1.9129394350529727
Validation loss: 2.4098294194191747

Epoch: 6| Step: 4
Training loss: 2.6516879230209143
Validation loss: 2.4202888515948318

Epoch: 6| Step: 5
Training loss: 2.269262616382916
Validation loss: 2.41556827044651

Epoch: 6| Step: 6
Training loss: 2.0256494634434605
Validation loss: 2.4026103188876995

Epoch: 6| Step: 7
Training loss: 1.4482929737860675
Validation loss: 2.366991141418297

Epoch: 6| Step: 8
Training loss: 2.0746219336550307
Validation loss: 2.4287886779622756

Epoch: 6| Step: 9
Training loss: 1.4248255204579152
Validation loss: 2.455952964569212

Epoch: 6| Step: 10
Training loss: 2.38611231714923
Validation loss: 2.420804620077296

Epoch: 6| Step: 11
Training loss: 2.1690720508685577
Validation loss: 2.419108749917782

Epoch: 6| Step: 12
Training loss: 1.6498993814017873
Validation loss: 2.425795515061844

Epoch: 6| Step: 13
Training loss: 1.8472588335518594
Validation loss: 2.3801547878483515

Epoch: 228| Step: 0
Training loss: 2.0411047519041863
Validation loss: 2.4196708289628033

Epoch: 6| Step: 1
Training loss: 1.6541634858274585
Validation loss: 2.4178426305012857

Epoch: 6| Step: 2
Training loss: 1.8275975175506303
Validation loss: 2.4465982982261147

Epoch: 6| Step: 3
Training loss: 2.0157141850575653
Validation loss: 2.4240248026039026

Epoch: 6| Step: 4
Training loss: 1.7887113801317875
Validation loss: 2.4548834225397624

Epoch: 6| Step: 5
Training loss: 1.5030761012889098
Validation loss: 2.4008604541897456

Epoch: 6| Step: 6
Training loss: 1.6631693704299415
Validation loss: 2.4236185319162837

Epoch: 6| Step: 7
Training loss: 2.0536697245701334
Validation loss: 2.3981856416679466

Epoch: 6| Step: 8
Training loss: 2.6301308397012786
Validation loss: 2.410570560144027

Epoch: 6| Step: 9
Training loss: 2.638862518268018
Validation loss: 2.424681412481833

Epoch: 6| Step: 10
Training loss: 2.0863659593686705
Validation loss: 2.357135723019583

Epoch: 6| Step: 11
Training loss: 2.3667044067955567
Validation loss: 2.362931307636609

Epoch: 6| Step: 12
Training loss: 1.936156760938971
Validation loss: 2.4229725838494143

Epoch: 6| Step: 13
Training loss: 1.7322749577685794
Validation loss: 2.4045282635756964

Epoch: 229| Step: 0
Training loss: 2.2437375124103016
Validation loss: 2.417809060082507

Epoch: 6| Step: 1
Training loss: 1.6943576074803002
Validation loss: 2.4143458178005894

Epoch: 6| Step: 2
Training loss: 1.6946419651133084
Validation loss: 2.3841439532052426

Epoch: 6| Step: 3
Training loss: 2.0057768837255048
Validation loss: 2.4120737399409653

Epoch: 6| Step: 4
Training loss: 2.0581457240465584
Validation loss: 2.4305562984936153

Epoch: 6| Step: 5
Training loss: 2.3773910131654787
Validation loss: 2.372639758623414

Epoch: 6| Step: 6
Training loss: 1.4912639376172057
Validation loss: 2.3905625023830286

Epoch: 6| Step: 7
Training loss: 2.7698469103157475
Validation loss: 2.4296673194646754

Epoch: 6| Step: 8
Training loss: 1.5685594936976937
Validation loss: 2.401281661440773

Epoch: 6| Step: 9
Training loss: 1.7980170559694724
Validation loss: 2.4279705863904044

Epoch: 6| Step: 10
Training loss: 2.0218506706931945
Validation loss: 2.45813711400751

Epoch: 6| Step: 11
Training loss: 1.9458369884688078
Validation loss: 2.3875746440595553

Epoch: 6| Step: 12
Training loss: 1.9067891093377405
Validation loss: 2.409172930369783

Epoch: 6| Step: 13
Training loss: 2.6087845002814416
Validation loss: 2.4319755565030743

Epoch: 230| Step: 0
Training loss: 1.9040457065930456
Validation loss: 2.408359887990492

Epoch: 6| Step: 1
Training loss: 2.254168040709391
Validation loss: 2.480759068324066

Epoch: 6| Step: 2
Training loss: 1.6531011049674575
Validation loss: 2.412809413166289

Epoch: 6| Step: 3
Training loss: 1.6184749178069806
Validation loss: 2.399334315686443

Epoch: 6| Step: 4
Training loss: 2.0582591296989343
Validation loss: 2.425959162018359

Epoch: 6| Step: 5
Training loss: 1.920286995677264
Validation loss: 2.451099111793114

Epoch: 6| Step: 6
Training loss: 1.5792585022458778
Validation loss: 2.417854514854337

Epoch: 6| Step: 7
Training loss: 2.1011412244391954
Validation loss: 2.4181653751472587

Epoch: 6| Step: 8
Training loss: 2.1054266251293847
Validation loss: 2.430786513114455

Epoch: 6| Step: 9
Training loss: 1.8599110319537995
Validation loss: 2.4630131700402025

Epoch: 6| Step: 10
Training loss: 2.3807594334668725
Validation loss: 2.422854949504002

Epoch: 6| Step: 11
Training loss: 2.163537798458554
Validation loss: 2.3951247738232215

Epoch: 6| Step: 12
Training loss: 2.5436351740833882
Validation loss: 2.4129024789835456

Epoch: 6| Step: 13
Training loss: 2.01857063276086
Validation loss: 2.348517197473453

Epoch: 231| Step: 0
Training loss: 2.3694276187722187
Validation loss: 2.40270341164587

Epoch: 6| Step: 1
Training loss: 1.753206109059313
Validation loss: 2.399181953085729

Epoch: 6| Step: 2
Training loss: 1.9338963127389464
Validation loss: 2.435554099990577

Epoch: 6| Step: 3
Training loss: 2.2083058145595857
Validation loss: 2.386727886512422

Epoch: 6| Step: 4
Training loss: 1.803042566276191
Validation loss: 2.3939377492969838

Epoch: 6| Step: 5
Training loss: 2.2917192164089193
Validation loss: 2.42515142382652

Epoch: 6| Step: 6
Training loss: 2.3106520202394116
Validation loss: 2.4259403770968784

Epoch: 6| Step: 7
Training loss: 1.1511221407323449
Validation loss: 2.3924211755220255

Epoch: 6| Step: 8
Training loss: 1.84792869446405
Validation loss: 2.3767013705665847

Epoch: 6| Step: 9
Training loss: 1.806043833546012
Validation loss: 2.40649567186155

Epoch: 6| Step: 10
Training loss: 2.638380371978925
Validation loss: 2.446070274043628

Epoch: 6| Step: 11
Training loss: 2.2279881246719424
Validation loss: 2.3879657184829832

Epoch: 6| Step: 12
Training loss: 1.8924109480553055
Validation loss: 2.4054550585886854

Epoch: 6| Step: 13
Training loss: 1.59935284282069
Validation loss: 2.4189592713163535

Epoch: 232| Step: 0
Training loss: 2.1017925604500283
Validation loss: 2.4187319824916225

Epoch: 6| Step: 1
Training loss: 2.2068639101037713
Validation loss: 2.3949554511387725

Epoch: 6| Step: 2
Training loss: 2.175636382562219
Validation loss: 2.4103053183423944

Epoch: 6| Step: 3
Training loss: 1.8422940211281216
Validation loss: 2.4004617918439495

Epoch: 6| Step: 4
Training loss: 1.2784106730441698
Validation loss: 2.3895827837960018

Epoch: 6| Step: 5
Training loss: 1.8564654112906283
Validation loss: 2.3781167128544944

Epoch: 6| Step: 6
Training loss: 1.9617757031655376
Validation loss: 2.4186884557948303

Epoch: 6| Step: 7
Training loss: 1.7161910688336142
Validation loss: 2.386935053398044

Epoch: 6| Step: 8
Training loss: 2.0309156876329055
Validation loss: 2.3925679125388943

Epoch: 6| Step: 9
Training loss: 2.4454006386372082
Validation loss: 2.435400965654466

Epoch: 6| Step: 10
Training loss: 2.0162533512548797
Validation loss: 2.467818060797344

Epoch: 6| Step: 11
Training loss: 2.1744461757570934
Validation loss: 2.4156427098856263

Epoch: 6| Step: 12
Training loss: 2.0671115529705495
Validation loss: 2.4775475122774613

Epoch: 6| Step: 13
Training loss: 2.2968933727541647
Validation loss: 2.4275140504698762

Epoch: 233| Step: 0
Training loss: 1.7960033126834487
Validation loss: 2.3797629027489426

Epoch: 6| Step: 1
Training loss: 2.000744919333489
Validation loss: 2.4024752331706956

Epoch: 6| Step: 2
Training loss: 1.7398518185713223
Validation loss: 2.4466157928802432

Epoch: 6| Step: 3
Training loss: 2.0647111080085008
Validation loss: 2.4654982493716724

Epoch: 6| Step: 4
Training loss: 1.8865616063609842
Validation loss: 2.4851689441527673

Epoch: 6| Step: 5
Training loss: 1.5929267103214657
Validation loss: 2.4356073599514314

Epoch: 6| Step: 6
Training loss: 2.7347551354069646
Validation loss: 2.475201574780342

Epoch: 6| Step: 7
Training loss: 1.6869325036801728
Validation loss: 2.422762401434972

Epoch: 6| Step: 8
Training loss: 2.467997472486639
Validation loss: 2.4240552802340454

Epoch: 6| Step: 9
Training loss: 1.5070136924025426
Validation loss: 2.4328940716397423

Epoch: 6| Step: 10
Training loss: 1.616830095243395
Validation loss: 2.42550238120551

Epoch: 6| Step: 11
Training loss: 2.170538841182987
Validation loss: 2.413113103745789

Epoch: 6| Step: 12
Training loss: 1.820125586609752
Validation loss: 2.4373758104027874

Epoch: 6| Step: 13
Training loss: 2.544534368281786
Validation loss: 2.3938268690656956

Epoch: 234| Step: 0
Training loss: 2.4934084780312014
Validation loss: 2.371069836847745

Epoch: 6| Step: 1
Training loss: 2.2340151623763744
Validation loss: 2.449786591333612

Epoch: 6| Step: 2
Training loss: 1.665344604022388
Validation loss: 2.440850314727881

Epoch: 6| Step: 3
Training loss: 2.341717156333124
Validation loss: 2.4013576177346736

Epoch: 6| Step: 4
Training loss: 1.7616732775450747
Validation loss: 2.396749752062459

Epoch: 6| Step: 5
Training loss: 2.2105527077918277
Validation loss: 2.3950000878013182

Epoch: 6| Step: 6
Training loss: 1.6451396043435162
Validation loss: 2.4434793218789173

Epoch: 6| Step: 7
Training loss: 1.7868773596402119
Validation loss: 2.407327371100715

Epoch: 6| Step: 8
Training loss: 1.3104185220597095
Validation loss: 2.412896241204043

Epoch: 6| Step: 9
Training loss: 1.4560243947532112
Validation loss: 2.4098882695880466

Epoch: 6| Step: 10
Training loss: 2.123580683020394
Validation loss: 2.3777421816598032

Epoch: 6| Step: 11
Training loss: 2.129122605835256
Validation loss: 2.419780524961257

Epoch: 6| Step: 12
Training loss: 2.366680632357516
Validation loss: 2.3950996224220886

Epoch: 6| Step: 13
Training loss: 1.993035468850576
Validation loss: 2.43258775298128

Epoch: 235| Step: 0
Training loss: 1.6236326627204685
Validation loss: 2.386578663529573

Epoch: 6| Step: 1
Training loss: 2.17376067270266
Validation loss: 2.385785526556297

Epoch: 6| Step: 2
Training loss: 2.2345721818042397
Validation loss: 2.4145246786041716

Epoch: 6| Step: 3
Training loss: 2.517406709338435
Validation loss: 2.4562904601104787

Epoch: 6| Step: 4
Training loss: 1.8771715305056158
Validation loss: 2.430412460505809

Epoch: 6| Step: 5
Training loss: 1.7283797560919043
Validation loss: 2.4006247095792377

Epoch: 6| Step: 6
Training loss: 1.9365361800474294
Validation loss: 2.397292827823003

Epoch: 6| Step: 7
Training loss: 2.0439511448047463
Validation loss: 2.4055897840818683

Epoch: 6| Step: 8
Training loss: 2.414021216968509
Validation loss: 2.423093494412107

Epoch: 6| Step: 9
Training loss: 1.6336048156859717
Validation loss: 2.415076298623566

Epoch: 6| Step: 10
Training loss: 2.0121177499871203
Validation loss: 2.3954137369597945

Epoch: 6| Step: 11
Training loss: 1.6183766586261032
Validation loss: 2.3528893683045333

Epoch: 6| Step: 12
Training loss: 2.1016931883156733
Validation loss: 2.4056734338008425

Epoch: 6| Step: 13
Training loss: 1.9030878072778126
Validation loss: 2.4464704543604716

Epoch: 236| Step: 0
Training loss: 2.1119765451386
Validation loss: 2.4147525731192663

Epoch: 6| Step: 1
Training loss: 1.910262715311695
Validation loss: 2.421204817260533

Epoch: 6| Step: 2
Training loss: 2.1485375953245383
Validation loss: 2.4003944313837966

Epoch: 6| Step: 3
Training loss: 1.4258646901419174
Validation loss: 2.4060528134630235

Epoch: 6| Step: 4
Training loss: 2.108632387907566
Validation loss: 2.43098332693264

Epoch: 6| Step: 5
Training loss: 1.699579871379035
Validation loss: 2.4490739281366323

Epoch: 6| Step: 6
Training loss: 1.970308443892658
Validation loss: 2.4402181206720397

Epoch: 6| Step: 7
Training loss: 1.7794362253335456
Validation loss: 2.389176878828249

Epoch: 6| Step: 8
Training loss: 2.1130826789794868
Validation loss: 2.4242439912439506

Epoch: 6| Step: 9
Training loss: 1.6812540954766857
Validation loss: 2.429280389699429

Epoch: 6| Step: 10
Training loss: 2.0055556619890114
Validation loss: 2.4149965764411694

Epoch: 6| Step: 11
Training loss: 1.7022971844967913
Validation loss: 2.428849931260566

Epoch: 6| Step: 12
Training loss: 2.099009157485214
Validation loss: 2.4406314903915507

Epoch: 6| Step: 13
Training loss: 3.088177527093087
Validation loss: 2.411290431196695

Epoch: 237| Step: 0
Training loss: 1.426325445962987
Validation loss: 2.408368588999343

Epoch: 6| Step: 1
Training loss: 2.42347074051767
Validation loss: 2.4081397523336023

Epoch: 6| Step: 2
Training loss: 1.3461113519563843
Validation loss: 2.3527105699493216

Epoch: 6| Step: 3
Training loss: 2.02886717490259
Validation loss: 2.401178273662336

Epoch: 6| Step: 4
Training loss: 1.5406389247427494
Validation loss: 2.372093196419036

Epoch: 6| Step: 5
Training loss: 2.3384221874094084
Validation loss: 2.4034956606060924

Epoch: 6| Step: 6
Training loss: 2.237517594422793
Validation loss: 2.4503718086709085

Epoch: 6| Step: 7
Training loss: 2.080490486928198
Validation loss: 2.402539191144113

Epoch: 6| Step: 8
Training loss: 1.4730905555190834
Validation loss: 2.4631773886539037

Epoch: 6| Step: 9
Training loss: 1.9040520926409756
Validation loss: 2.438432171840076

Epoch: 6| Step: 10
Training loss: 1.8968078148898473
Validation loss: 2.4194611914991286

Epoch: 6| Step: 11
Training loss: 1.5156369552927322
Validation loss: 2.4058724959452205

Epoch: 6| Step: 12
Training loss: 2.596176942358501
Validation loss: 2.42012803725206

Epoch: 6| Step: 13
Training loss: 2.3005015489804768
Validation loss: 2.4054822204249127

Epoch: 238| Step: 0
Training loss: 2.361223721779542
Validation loss: 2.3963107096715843

Epoch: 6| Step: 1
Training loss: 1.5460042332915744
Validation loss: 2.4091238421761334

Epoch: 6| Step: 2
Training loss: 1.6010072071120516
Validation loss: 2.4339284432801773

Epoch: 6| Step: 3
Training loss: 2.9101287226047075
Validation loss: 2.3835049370014527

Epoch: 6| Step: 4
Training loss: 1.8544000057312617
Validation loss: 2.375292941832395

Epoch: 6| Step: 5
Training loss: 2.437997522686145
Validation loss: 2.4136064614185333

Epoch: 6| Step: 6
Training loss: 1.8770488988474836
Validation loss: 2.3977863202322425

Epoch: 6| Step: 7
Training loss: 1.6690915904664196
Validation loss: 2.418559054479897

Epoch: 6| Step: 8
Training loss: 1.8647998563333568
Validation loss: 2.425965453920048

Epoch: 6| Step: 9
Training loss: 2.343916416617884
Validation loss: 2.4268655751028985

Epoch: 6| Step: 10
Training loss: 1.7126570469482283
Validation loss: 2.4262292404771464

Epoch: 6| Step: 11
Training loss: 1.4549447427331177
Validation loss: 2.3967604210847813

Epoch: 6| Step: 12
Training loss: 1.425578565430829
Validation loss: 2.427026493872167

Epoch: 6| Step: 13
Training loss: 2.0487048872984315
Validation loss: 2.427169849667543

Epoch: 239| Step: 0
Training loss: 2.008923887217071
Validation loss: 2.439759107079671

Epoch: 6| Step: 1
Training loss: 1.829400945908888
Validation loss: 2.417150339417545

Epoch: 6| Step: 2
Training loss: 2.0416168933432566
Validation loss: 2.3935152121878605

Epoch: 6| Step: 3
Training loss: 1.6601401653632575
Validation loss: 2.411026314875484

Epoch: 6| Step: 4
Training loss: 2.043531759666312
Validation loss: 2.4150185992658146

Epoch: 6| Step: 5
Training loss: 1.6303675109695959
Validation loss: 2.34060539917458

Epoch: 6| Step: 6
Training loss: 2.4826163539145303
Validation loss: 2.397044282319486

Epoch: 6| Step: 7
Training loss: 2.531049178834483
Validation loss: 2.41478191556702

Epoch: 6| Step: 8
Training loss: 2.206910688770166
Validation loss: 2.4215966569180605

Epoch: 6| Step: 9
Training loss: 1.7181726352919655
Validation loss: 2.385806369469308

Epoch: 6| Step: 10
Training loss: 1.918776767307917
Validation loss: 2.4114204027592128

Epoch: 6| Step: 11
Training loss: 1.3172615510119523
Validation loss: 2.360881415512025

Epoch: 6| Step: 12
Training loss: 1.7675972784701215
Validation loss: 2.46906704344696

Epoch: 6| Step: 13
Training loss: 1.8330811702822278
Validation loss: 2.4275375617879944

Epoch: 240| Step: 0
Training loss: 1.6216196700784609
Validation loss: 2.4538986797091735

Epoch: 6| Step: 1
Training loss: 2.0461035286522966
Validation loss: 2.4095704153192554

Epoch: 6| Step: 2
Training loss: 1.1686607530759425
Validation loss: 2.4189591759333244

Epoch: 6| Step: 3
Training loss: 2.1186080615006673
Validation loss: 2.416511666104752

Epoch: 6| Step: 4
Training loss: 1.9083213183872956
Validation loss: 2.406097134508988

Epoch: 6| Step: 5
Training loss: 2.1806808997194813
Validation loss: 2.4717591185594268

Epoch: 6| Step: 6
Training loss: 2.046600672851798
Validation loss: 2.381562803191213

Epoch: 6| Step: 7
Training loss: 1.9088497881732873
Validation loss: 2.450288392765367

Epoch: 6| Step: 8
Training loss: 2.1662317964435043
Validation loss: 2.4440161327290606

Epoch: 6| Step: 9
Training loss: 2.0455651205210947
Validation loss: 2.38740029088427

Epoch: 6| Step: 10
Training loss: 2.6348299622368656
Validation loss: 2.438816521714653

Epoch: 6| Step: 11
Training loss: 1.9661791531263677
Validation loss: 2.398949013313354

Epoch: 6| Step: 12
Training loss: 1.6380836786081956
Validation loss: 2.4467285421705833

Epoch: 6| Step: 13
Training loss: 1.0684674921370045
Validation loss: 2.3970756805165947

Epoch: 241| Step: 0
Training loss: 1.8798216812300725
Validation loss: 2.416959064547123

Epoch: 6| Step: 1
Training loss: 1.9372272914806414
Validation loss: 2.4222098106857053

Epoch: 6| Step: 2
Training loss: 1.9934690654221152
Validation loss: 2.4027966848445113

Epoch: 6| Step: 3
Training loss: 1.7283422350799853
Validation loss: 2.4536578700418428

Epoch: 6| Step: 4
Training loss: 1.8843065088075563
Validation loss: 2.397101794031886

Epoch: 6| Step: 5
Training loss: 1.6142106969549601
Validation loss: 2.449372229595464

Epoch: 6| Step: 6
Training loss: 1.6785775709184774
Validation loss: 2.400005844708986

Epoch: 6| Step: 7
Training loss: 2.2802440567901083
Validation loss: 2.4528353397098983

Epoch: 6| Step: 8
Training loss: 2.641374921683439
Validation loss: 2.4788918281222707

Epoch: 6| Step: 9
Training loss: 2.604196034583754
Validation loss: 2.3804139258751533

Epoch: 6| Step: 10
Training loss: 2.2105844168568396
Validation loss: 2.4403155934975023

Epoch: 6| Step: 11
Training loss: 1.1920975977446322
Validation loss: 2.4463269626110766

Epoch: 6| Step: 12
Training loss: 1.6245424653546987
Validation loss: 2.4157907859816583

Epoch: 6| Step: 13
Training loss: 1.7670480175607444
Validation loss: 2.398053680628298

Epoch: 242| Step: 0
Training loss: 2.3630141934918205
Validation loss: 2.3824272437401577

Epoch: 6| Step: 1
Training loss: 1.9159483047153314
Validation loss: 2.422802000175408

Epoch: 6| Step: 2
Training loss: 1.4872501836697427
Validation loss: 2.3971346512896137

Epoch: 6| Step: 3
Training loss: 2.325660168843949
Validation loss: 2.406254051747378

Epoch: 6| Step: 4
Training loss: 1.518547386814243
Validation loss: 2.394805730807406

Epoch: 6| Step: 5
Training loss: 2.0971058384459385
Validation loss: 2.40570900808102

Epoch: 6| Step: 6
Training loss: 1.9807333985720723
Validation loss: 2.40639628687615

Epoch: 6| Step: 7
Training loss: 1.9807052922488069
Validation loss: 2.406818657237049

Epoch: 6| Step: 8
Training loss: 1.9442400446437391
Validation loss: 2.3799138371085613

Epoch: 6| Step: 9
Training loss: 1.5748937782919938
Validation loss: 2.4206768961167726

Epoch: 6| Step: 10
Training loss: 1.5064444388732394
Validation loss: 2.423236631667356

Epoch: 6| Step: 11
Training loss: 2.315496513724869
Validation loss: 2.433032597778356

Epoch: 6| Step: 12
Training loss: 1.705622390627656
Validation loss: 2.420250329240545

Epoch: 6| Step: 13
Training loss: 2.1152045053220543
Validation loss: 2.406221081427154

Epoch: 243| Step: 0
Training loss: 1.7239720861648928
Validation loss: 2.3964566265781344

Epoch: 6| Step: 1
Training loss: 2.5084036727455
Validation loss: 2.441879659977013

Epoch: 6| Step: 2
Training loss: 2.0112659722565853
Validation loss: 2.4324826415474514

Epoch: 6| Step: 3
Training loss: 1.9548282368321666
Validation loss: 2.435501450959596

Epoch: 6| Step: 4
Training loss: 1.968784876923216
Validation loss: 2.43942564045006

Epoch: 6| Step: 5
Training loss: 1.4818202470295903
Validation loss: 2.4783984267853327

Epoch: 6| Step: 6
Training loss: 1.7637016826151182
Validation loss: 2.3966070765334164

Epoch: 6| Step: 7
Training loss: 1.5961655655219429
Validation loss: 2.4253931955619703

Epoch: 6| Step: 8
Training loss: 2.2563796199011428
Validation loss: 2.4425851824221296

Epoch: 6| Step: 9
Training loss: 1.7274178850059636
Validation loss: 2.4226619991195877

Epoch: 6| Step: 10
Training loss: 1.7712083157713736
Validation loss: 2.398171949448192

Epoch: 6| Step: 11
Training loss: 1.573511007158335
Validation loss: 2.442972096352345

Epoch: 6| Step: 12
Training loss: 2.6309306043739995
Validation loss: 2.441713055109065

Epoch: 6| Step: 13
Training loss: 1.207213057865383
Validation loss: 2.421626421939797

Epoch: 244| Step: 0
Training loss: 2.0782105851296735
Validation loss: 2.402070867495451

Epoch: 6| Step: 1
Training loss: 2.157108412443252
Validation loss: 2.4182183698122173

Epoch: 6| Step: 2
Training loss: 2.1216908662928717
Validation loss: 2.4559148226032392

Epoch: 6| Step: 3
Training loss: 1.651777454488126
Validation loss: 2.4456023122777304

Epoch: 6| Step: 4
Training loss: 1.401171521074321
Validation loss: 2.4330870292850757

Epoch: 6| Step: 5
Training loss: 2.079104773365299
Validation loss: 2.4400794955309704

Epoch: 6| Step: 6
Training loss: 1.8818982702442606
Validation loss: 2.4324736431670075

Epoch: 6| Step: 7
Training loss: 1.7182137779925828
Validation loss: 2.429406538812886

Epoch: 6| Step: 8
Training loss: 1.8345210678458728
Validation loss: 2.430116745636555

Epoch: 6| Step: 9
Training loss: 1.655160365560956
Validation loss: 2.405338725810692

Epoch: 6| Step: 10
Training loss: 2.6002841133995243
Validation loss: 2.4207408899945517

Epoch: 6| Step: 11
Training loss: 1.84424888197741
Validation loss: 2.4226266330391812

Epoch: 6| Step: 12
Training loss: 1.9189383547901853
Validation loss: 2.416610554463429

Epoch: 6| Step: 13
Training loss: 1.842919631439292
Validation loss: 2.4031978267836624

Epoch: 245| Step: 0
Training loss: 1.6322081693202022
Validation loss: 2.4269363807392716

Epoch: 6| Step: 1
Training loss: 1.5661381898809144
Validation loss: 2.391952308106772

Epoch: 6| Step: 2
Training loss: 1.947892955560919
Validation loss: 2.445377897680016

Epoch: 6| Step: 3
Training loss: 1.282776225944371
Validation loss: 2.4076736302293074

Epoch: 6| Step: 4
Training loss: 1.9170480915299561
Validation loss: 2.4541844340926646

Epoch: 6| Step: 5
Training loss: 1.8007748949182873
Validation loss: 2.409028686125909

Epoch: 6| Step: 6
Training loss: 1.6167067398269634
Validation loss: 2.438209402063123

Epoch: 6| Step: 7
Training loss: 1.4722218163607697
Validation loss: 2.3514287456302467

Epoch: 6| Step: 8
Training loss: 1.449453823221228
Validation loss: 2.412342966443588

Epoch: 6| Step: 9
Training loss: 2.8976984032809474
Validation loss: 2.3628325520894213

Epoch: 6| Step: 10
Training loss: 2.185109385320989
Validation loss: 2.4244361696426378

Epoch: 6| Step: 11
Training loss: 2.4638534466892903
Validation loss: 2.4144173261241297

Epoch: 6| Step: 12
Training loss: 1.9718721247680788
Validation loss: 2.376680596660621

Epoch: 6| Step: 13
Training loss: 2.512332633597872
Validation loss: 2.4185043352230986

Epoch: 246| Step: 0
Training loss: 2.535408654013526
Validation loss: 2.3903564521054026

Epoch: 6| Step: 1
Training loss: 1.9548860468910574
Validation loss: 2.369902691724552

Epoch: 6| Step: 2
Training loss: 1.8128486824074415
Validation loss: 2.4054258821335193

Epoch: 6| Step: 3
Training loss: 1.371665378970117
Validation loss: 2.422252897325674

Epoch: 6| Step: 4
Training loss: 1.817167979666121
Validation loss: 2.3522694780423117

Epoch: 6| Step: 5
Training loss: 2.217575944634354
Validation loss: 2.425863566220706

Epoch: 6| Step: 6
Training loss: 1.9529630059773442
Validation loss: 2.399279307036281

Epoch: 6| Step: 7
Training loss: 1.9499441261111674
Validation loss: 2.414331883279322

Epoch: 6| Step: 8
Training loss: 1.512630690295754
Validation loss: 2.402253891806443

Epoch: 6| Step: 9
Training loss: 2.1784151253476702
Validation loss: 2.424771991620793

Epoch: 6| Step: 10
Training loss: 1.6819379058607196
Validation loss: 2.4428169594887534

Epoch: 6| Step: 11
Training loss: 2.326244234613964
Validation loss: 2.373629886687642

Epoch: 6| Step: 12
Training loss: 1.8038943971398977
Validation loss: 2.4114711430419202

Epoch: 6| Step: 13
Training loss: 1.359158290382706
Validation loss: 2.426883371513162

Epoch: 247| Step: 0
Training loss: 1.8914448875568104
Validation loss: 2.4497396836852414

Epoch: 6| Step: 1
Training loss: 1.6321973600168267
Validation loss: 2.417586402642356

Epoch: 6| Step: 2
Training loss: 1.4675859749091362
Validation loss: 2.413249013248421

Epoch: 6| Step: 3
Training loss: 1.6217542658503201
Validation loss: 2.3957134427270224

Epoch: 6| Step: 4
Training loss: 2.0819876202848295
Validation loss: 2.419175017042217

Epoch: 6| Step: 5
Training loss: 1.7701160399336318
Validation loss: 2.395853210694907

Epoch: 6| Step: 6
Training loss: 2.188835826086454
Validation loss: 2.405397094336694

Epoch: 6| Step: 7
Training loss: 1.5825620914469398
Validation loss: 2.4559007225721747

Epoch: 6| Step: 8
Training loss: 2.0402001024727654
Validation loss: 2.415370308810903

Epoch: 6| Step: 9
Training loss: 1.5766490417258834
Validation loss: 2.439312960331632

Epoch: 6| Step: 10
Training loss: 2.24887183834208
Validation loss: 2.3909809818808494

Epoch: 6| Step: 11
Training loss: 1.9611095945672405
Validation loss: 2.406350777066799

Epoch: 6| Step: 12
Training loss: 2.3866126603492974
Validation loss: 2.424481507040885

Epoch: 6| Step: 13
Training loss: 1.4243106312286506
Validation loss: 2.3759304290132937

Epoch: 248| Step: 0
Training loss: 1.46638826451681
Validation loss: 2.3832793834261596

Epoch: 6| Step: 1
Training loss: 1.9007156580258908
Validation loss: 2.375986820917995

Epoch: 6| Step: 2
Training loss: 1.717563080607903
Validation loss: 2.345143546644836

Epoch: 6| Step: 3
Training loss: 1.926587228237331
Validation loss: 2.3770108963293684

Epoch: 6| Step: 4
Training loss: 2.230289806129179
Validation loss: 2.3801373561618964

Epoch: 6| Step: 5
Training loss: 1.8394842424269926
Validation loss: 2.402258981189077

Epoch: 6| Step: 6
Training loss: 2.2907597105375586
Validation loss: 2.4043711142875885

Epoch: 6| Step: 7
Training loss: 1.8045416438623947
Validation loss: 2.3835169694394622

Epoch: 6| Step: 8
Training loss: 2.1219398679635515
Validation loss: 2.441433604097431

Epoch: 6| Step: 9
Training loss: 1.9926456896887137
Validation loss: 2.4557074560415093

Epoch: 6| Step: 10
Training loss: 1.8350292800105654
Validation loss: 2.420500024086567

Epoch: 6| Step: 11
Training loss: 1.8876733359267819
Validation loss: 2.397034460004559

Epoch: 6| Step: 12
Training loss: 2.013606043571099
Validation loss: 2.3910920241027993

Epoch: 6| Step: 13
Training loss: 1.5442714937754394
Validation loss: 2.4129749745894973

Epoch: 249| Step: 0
Training loss: 2.3292032087686203
Validation loss: 2.3882301201193226

Epoch: 6| Step: 1
Training loss: 1.9791933425979467
Validation loss: 2.4123593460627046

Epoch: 6| Step: 2
Training loss: 1.6291161271603463
Validation loss: 2.3699731850343504

Epoch: 6| Step: 3
Training loss: 2.4844692380293933
Validation loss: 2.4234282880292906

Epoch: 6| Step: 4
Training loss: 1.68895602106777
Validation loss: 2.412531370511262

Epoch: 6| Step: 5
Training loss: 1.868843652936514
Validation loss: 2.417535441826069

Epoch: 6| Step: 6
Training loss: 2.490972144848254
Validation loss: 2.424687295349215

Epoch: 6| Step: 7
Training loss: 1.801148879781983
Validation loss: 2.3723083575780888

Epoch: 6| Step: 8
Training loss: 2.1534518454725293
Validation loss: 2.342125414500955

Epoch: 6| Step: 9
Training loss: 1.3196712494160578
Validation loss: 2.407239130259361

Epoch: 6| Step: 10
Training loss: 1.428869795295127
Validation loss: 2.4082943888440407

Epoch: 6| Step: 11
Training loss: 1.1745146966650482
Validation loss: 2.3824660602268004

Epoch: 6| Step: 12
Training loss: 1.5772607533053107
Validation loss: 2.3987428466048626

Epoch: 6| Step: 13
Training loss: 2.347881084218774
Validation loss: 2.3959314683787207

Epoch: 250| Step: 0
Training loss: 1.5321090779628332
Validation loss: 2.433659186594757

Epoch: 6| Step: 1
Training loss: 1.5010053126821208
Validation loss: 2.4289180266659756

Epoch: 6| Step: 2
Training loss: 1.6305094269237548
Validation loss: 2.3938764074768493

Epoch: 6| Step: 3
Training loss: 1.4059748062437807
Validation loss: 2.434977309042998

Epoch: 6| Step: 4
Training loss: 1.7570302621474825
Validation loss: 2.4330929971943926

Epoch: 6| Step: 5
Training loss: 2.598449952903723
Validation loss: 2.4069994811462774

Epoch: 6| Step: 6
Training loss: 1.6638653419001679
Validation loss: 2.450995397741383

Epoch: 6| Step: 7
Training loss: 2.1335586528203097
Validation loss: 2.4055039424260425

Epoch: 6| Step: 8
Training loss: 2.2106018890044226
Validation loss: 2.4290841291857483

Epoch: 6| Step: 9
Training loss: 1.5934634979634898
Validation loss: 2.4234473970832244

Epoch: 6| Step: 10
Training loss: 2.0402639072478497
Validation loss: 2.3818791151487875

Epoch: 6| Step: 11
Training loss: 2.190188036993659
Validation loss: 2.389229065782389

Epoch: 6| Step: 12
Training loss: 1.723272096749856
Validation loss: 2.399396771801184

Epoch: 6| Step: 13
Training loss: 2.3641945831655
Validation loss: 2.366705237618374

Epoch: 251| Step: 0
Training loss: 1.919476508857089
Validation loss: 2.455861245186182

Epoch: 6| Step: 1
Training loss: 2.1968061585581027
Validation loss: 2.4160754980374968

Epoch: 6| Step: 2
Training loss: 1.5871665964930062
Validation loss: 2.424068911388218

Epoch: 6| Step: 3
Training loss: 1.4556125146011814
Validation loss: 2.4313055018461847

Epoch: 6| Step: 4
Training loss: 2.126129747653567
Validation loss: 2.4054760465321547

Epoch: 6| Step: 5
Training loss: 2.6244200111157654
Validation loss: 2.3744447228478514

Epoch: 6| Step: 6
Training loss: 1.958341544384347
Validation loss: 2.4277455979368985

Epoch: 6| Step: 7
Training loss: 2.187078925886732
Validation loss: 2.3816688260782133

Epoch: 6| Step: 8
Training loss: 2.073297500770905
Validation loss: 2.3948036631348755

Epoch: 6| Step: 9
Training loss: 1.8296437272097719
Validation loss: 2.339938444226829

Epoch: 6| Step: 10
Training loss: 1.3224965377070026
Validation loss: 2.3765253529135273

Epoch: 6| Step: 11
Training loss: 1.565450476629153
Validation loss: 2.3952821717325845

Epoch: 6| Step: 12
Training loss: 1.6116903002063694
Validation loss: 2.4265284665626043

Epoch: 6| Step: 13
Training loss: 0.9133706368070272
Validation loss: 2.431631510694785

Epoch: 252| Step: 0
Training loss: 2.2475567373682046
Validation loss: 2.342302195974626

Epoch: 6| Step: 1
Training loss: 1.9992993438802054
Validation loss: 2.3985758605877026

Epoch: 6| Step: 2
Training loss: 1.8354308382916802
Validation loss: 2.402790077807569

Epoch: 6| Step: 3
Training loss: 1.9887876933594024
Validation loss: 2.422632670103004

Epoch: 6| Step: 4
Training loss: 1.4869555879539527
Validation loss: 2.416434065374952

Epoch: 6| Step: 5
Training loss: 1.4649263485827029
Validation loss: 2.3894205530391632

Epoch: 6| Step: 6
Training loss: 1.434960651722188
Validation loss: 2.408191422428199

Epoch: 6| Step: 7
Training loss: 2.1039902515548152
Validation loss: 2.3485014674692977

Epoch: 6| Step: 8
Training loss: 1.5738442403801924
Validation loss: 2.395197711178906

Epoch: 6| Step: 9
Training loss: 1.8486172715232585
Validation loss: 2.4177563607631365

Epoch: 6| Step: 10
Training loss: 2.5130901952997857
Validation loss: 2.4449421471352513

Epoch: 6| Step: 11
Training loss: 1.7102132858308132
Validation loss: 2.4057892111937207

Epoch: 6| Step: 12
Training loss: 2.0652087370737
Validation loss: 2.4020992671879675

Epoch: 6| Step: 13
Training loss: 1.8025338008637246
Validation loss: 2.4520861158885685

Epoch: 253| Step: 0
Training loss: 1.3001752020077266
Validation loss: 2.3874880097125777

Epoch: 6| Step: 1
Training loss: 2.4571228495445454
Validation loss: 2.328666144564807

Epoch: 6| Step: 2
Training loss: 1.7106087425387633
Validation loss: 2.4375865553850677

Epoch: 6| Step: 3
Training loss: 2.028369680730449
Validation loss: 2.445539020330054

Epoch: 6| Step: 4
Training loss: 2.309675605422267
Validation loss: 2.398441997840648

Epoch: 6| Step: 5
Training loss: 1.6401281421887994
Validation loss: 2.438513796076477

Epoch: 6| Step: 6
Training loss: 1.7988225582670379
Validation loss: 2.3758779078680425

Epoch: 6| Step: 7
Training loss: 1.9367493436612078
Validation loss: 2.445834704851864

Epoch: 6| Step: 8
Training loss: 1.9181954119782858
Validation loss: 2.379241578647688

Epoch: 6| Step: 9
Training loss: 1.592144175830078
Validation loss: 2.423063941557914

Epoch: 6| Step: 10
Training loss: 2.2905909932566906
Validation loss: 2.4004976553487873

Epoch: 6| Step: 11
Training loss: 1.4082442659884005
Validation loss: 2.4175088109602845

Epoch: 6| Step: 12
Training loss: 2.0568292283164364
Validation loss: 2.425338107795271

Epoch: 6| Step: 13
Training loss: 1.5211509564520753
Validation loss: 2.4096681607835593

Epoch: 254| Step: 0
Training loss: 1.6447860266709784
Validation loss: 2.461042819070264

Epoch: 6| Step: 1
Training loss: 1.7568021456154679
Validation loss: 2.368403787204567

Epoch: 6| Step: 2
Training loss: 1.9196330073411259
Validation loss: 2.4043560983594756

Epoch: 6| Step: 3
Training loss: 2.026780007836271
Validation loss: 2.4631687261764763

Epoch: 6| Step: 4
Training loss: 1.9280933173496362
Validation loss: 2.4563273913054675

Epoch: 6| Step: 5
Training loss: 2.0351724166374443
Validation loss: 2.401178612110353

Epoch: 6| Step: 6
Training loss: 1.9116047552781987
Validation loss: 2.4231534898559994

Epoch: 6| Step: 7
Training loss: 1.7593214552000014
Validation loss: 2.3749044838454987

Epoch: 6| Step: 8
Training loss: 1.6801027716128416
Validation loss: 2.424307320983847

Epoch: 6| Step: 9
Training loss: 1.76843348929865
Validation loss: 2.3779648148993924

Epoch: 6| Step: 10
Training loss: 1.8426365480588371
Validation loss: 2.4114151806849438

Epoch: 6| Step: 11
Training loss: 2.2370277076816243
Validation loss: 2.3720817134184005

Epoch: 6| Step: 12
Training loss: 1.777318799189565
Validation loss: 2.394016738878453

Epoch: 6| Step: 13
Training loss: 2.2702232264525892
Validation loss: 2.4384205092095113

Epoch: 255| Step: 0
Training loss: 2.097630903776397
Validation loss: 2.360452861182738

Epoch: 6| Step: 1
Training loss: 2.0946251477854236
Validation loss: 2.456687279874373

Epoch: 6| Step: 2
Training loss: 1.505181740214596
Validation loss: 2.472913658586105

Epoch: 6| Step: 3
Training loss: 1.2574516868790229
Validation loss: 2.4020809563085512

Epoch: 6| Step: 4
Training loss: 1.6607940525756952
Validation loss: 2.4414177167069426

Epoch: 6| Step: 5
Training loss: 1.697242938593527
Validation loss: 2.433169797949892

Epoch: 6| Step: 6
Training loss: 2.919125982406321
Validation loss: 2.4549193097292252

Epoch: 6| Step: 7
Training loss: 1.5818366036941816
Validation loss: 2.451431852727995

Epoch: 6| Step: 8
Training loss: 1.684167609248337
Validation loss: 2.4570281073087816

Epoch: 6| Step: 9
Training loss: 2.3984577786958274
Validation loss: 2.4167865989325765

Epoch: 6| Step: 10
Training loss: 1.8275187212484778
Validation loss: 2.401972379541851

Epoch: 6| Step: 11
Training loss: 1.5309579531815334
Validation loss: 2.4292398222404623

Epoch: 6| Step: 12
Training loss: 1.8342893954160735
Validation loss: 2.4557923612753165

Epoch: 6| Step: 13
Training loss: 1.998479264980899
Validation loss: 2.3842860783448283

Epoch: 256| Step: 0
Training loss: 2.3875557139022545
Validation loss: 2.437266020671026

Epoch: 6| Step: 1
Training loss: 1.7389209727427466
Validation loss: 2.4388383704398238

Epoch: 6| Step: 2
Training loss: 1.8453230532119118
Validation loss: 2.4210023539061805

Epoch: 6| Step: 3
Training loss: 1.3975847510637573
Validation loss: 2.3765282627989075

Epoch: 6| Step: 4
Training loss: 1.5251222342609971
Validation loss: 2.4426558650928754

Epoch: 6| Step: 5
Training loss: 2.255676949130866
Validation loss: 2.430264896606462

Epoch: 6| Step: 6
Training loss: 1.9820611634964913
Validation loss: 2.34731066443871

Epoch: 6| Step: 7
Training loss: 1.382402520907938
Validation loss: 2.435249849231949

Epoch: 6| Step: 8
Training loss: 1.5006114984847896
Validation loss: 2.396536075489574

Epoch: 6| Step: 9
Training loss: 2.5124962346442556
Validation loss: 2.381341845562436

Epoch: 6| Step: 10
Training loss: 1.8566949587206751
Validation loss: 2.4152072977453174

Epoch: 6| Step: 11
Training loss: 1.704467804035945
Validation loss: 2.4029952358328197

Epoch: 6| Step: 12
Training loss: 1.7984968081189598
Validation loss: 2.389480097901893

Epoch: 6| Step: 13
Training loss: 1.5905536688078634
Validation loss: 2.3852369605556434

Epoch: 257| Step: 0
Training loss: 1.2430813050873781
Validation loss: 2.385557023765318

Epoch: 6| Step: 1
Training loss: 1.9687826971336158
Validation loss: 2.3741637432387472

Epoch: 6| Step: 2
Training loss: 2.627875161287493
Validation loss: 2.435726671320429

Epoch: 6| Step: 3
Training loss: 2.3026964800873646
Validation loss: 2.381746997644334

Epoch: 6| Step: 4
Training loss: 1.7687988112760955
Validation loss: 2.4475997548609922

Epoch: 6| Step: 5
Training loss: 1.7115134745944192
Validation loss: 2.4492060595616354

Epoch: 6| Step: 6
Training loss: 1.9144752524513173
Validation loss: 2.451350650789111

Epoch: 6| Step: 7
Training loss: 2.0203642022051373
Validation loss: 2.477033466879124

Epoch: 6| Step: 8
Training loss: 1.7036529562636114
Validation loss: 2.4576938256890393

Epoch: 6| Step: 9
Training loss: 1.625758507572717
Validation loss: 2.47273169443585

Epoch: 6| Step: 10
Training loss: 1.5813668068424869
Validation loss: 2.4019091397343395

Epoch: 6| Step: 11
Training loss: 1.9686980467707917
Validation loss: 2.4466506634099683

Epoch: 6| Step: 12
Training loss: 1.2471744072708875
Validation loss: 2.4038133572280835

Epoch: 6| Step: 13
Training loss: 1.8922445123275147
Validation loss: 2.4018135825723452

Epoch: 258| Step: 0
Training loss: 2.2070713275882716
Validation loss: 2.4213156243027187

Epoch: 6| Step: 1
Training loss: 1.6388287838548412
Validation loss: 2.4143603521755477

Epoch: 6| Step: 2
Training loss: 2.3925729432341845
Validation loss: 2.449258098942695

Epoch: 6| Step: 3
Training loss: 1.7711939126706986
Validation loss: 2.468403272786287

Epoch: 6| Step: 4
Training loss: 1.9896837245784917
Validation loss: 2.3750114278728884

Epoch: 6| Step: 5
Training loss: 1.5686568456705228
Validation loss: 2.416072365738002

Epoch: 6| Step: 6
Training loss: 1.9462289145325251
Validation loss: 2.34368523292883

Epoch: 6| Step: 7
Training loss: 1.5336059041253365
Validation loss: 2.3916842174182626

Epoch: 6| Step: 8
Training loss: 1.707924406219142
Validation loss: 2.4177146779593746

Epoch: 6| Step: 9
Training loss: 1.8589768183731554
Validation loss: 2.353690835916066

Epoch: 6| Step: 10
Training loss: 2.273510279588382
Validation loss: 2.3637115214289883

Epoch: 6| Step: 11
Training loss: 1.6099041559585716
Validation loss: 2.4284704065773

Epoch: 6| Step: 12
Training loss: 1.419245121807553
Validation loss: 2.394740717896776

Epoch: 6| Step: 13
Training loss: 2.1081637825722104
Validation loss: 2.381129652901034

Epoch: 259| Step: 0
Training loss: 2.0632711182778505
Validation loss: 2.4279012057699565

Epoch: 6| Step: 1
Training loss: 1.3525115633486093
Validation loss: 2.406130152342485

Epoch: 6| Step: 2
Training loss: 1.6553778601373053
Validation loss: 2.4311415253869404

Epoch: 6| Step: 3
Training loss: 2.4189461010041104
Validation loss: 2.4224608041991162

Epoch: 6| Step: 4
Training loss: 1.991054437089518
Validation loss: 2.406996247036723

Epoch: 6| Step: 5
Training loss: 2.501424669594315
Validation loss: 2.406877677415954

Epoch: 6| Step: 6
Training loss: 1.6264212335370398
Validation loss: 2.3971714821541386

Epoch: 6| Step: 7
Training loss: 1.647685959875056
Validation loss: 2.4364202383291262

Epoch: 6| Step: 8
Training loss: 1.1880693576552015
Validation loss: 2.3798442964385433

Epoch: 6| Step: 9
Training loss: 1.8828501084239915
Validation loss: 2.4454468275414993

Epoch: 6| Step: 10
Training loss: 1.7575010574793448
Validation loss: 2.4232533491884825

Epoch: 6| Step: 11
Training loss: 1.5608064247061686
Validation loss: 2.3871316551449837

Epoch: 6| Step: 12
Training loss: 1.812784567231245
Validation loss: 2.3597999097232787

Epoch: 6| Step: 13
Training loss: 1.2077084712423856
Validation loss: 2.4245482992761613

Epoch: 260| Step: 0
Training loss: 1.7368592350022278
Validation loss: 2.3725676643121494

Epoch: 6| Step: 1
Training loss: 1.8515190409135296
Validation loss: 2.373344286818125

Epoch: 6| Step: 2
Training loss: 1.6736326871389555
Validation loss: 2.4330571315670353

Epoch: 6| Step: 3
Training loss: 1.3336895327817808
Validation loss: 2.379297753079964

Epoch: 6| Step: 4
Training loss: 2.1255187355136465
Validation loss: 2.3607748065563734

Epoch: 6| Step: 5
Training loss: 1.360426485144024
Validation loss: 2.410104041778014

Epoch: 6| Step: 6
Training loss: 2.015878114406611
Validation loss: 2.426845485189428

Epoch: 6| Step: 7
Training loss: 2.147550198520066
Validation loss: 2.435102585314893

Epoch: 6| Step: 8
Training loss: 1.3815565709761484
Validation loss: 2.38934133962417

Epoch: 6| Step: 9
Training loss: 1.8014495999509201
Validation loss: 2.4477941883440155

Epoch: 6| Step: 10
Training loss: 2.3732009900444484
Validation loss: 2.4045808727229434

Epoch: 6| Step: 11
Training loss: 1.9371748620679619
Validation loss: 2.4351765086834187

Epoch: 6| Step: 12
Training loss: 1.632105039806542
Validation loss: 2.427477879578954

Epoch: 6| Step: 13
Training loss: 2.180636947743427
Validation loss: 2.4622326067069302

Epoch: 261| Step: 0
Training loss: 1.5591246960181744
Validation loss: 2.439502617532386

Epoch: 6| Step: 1
Training loss: 2.0394590730257067
Validation loss: 2.429316116911432

Epoch: 6| Step: 2
Training loss: 1.5244928861347593
Validation loss: 2.43576709022039

Epoch: 6| Step: 3
Training loss: 1.6843826322081838
Validation loss: 2.3923262402641803

Epoch: 6| Step: 4
Training loss: 1.4013289921569607
Validation loss: 2.434703436363664

Epoch: 6| Step: 5
Training loss: 1.9629471044812836
Validation loss: 2.4156412410923718

Epoch: 6| Step: 6
Training loss: 1.275500913469383
Validation loss: 2.392710920528153

Epoch: 6| Step: 7
Training loss: 1.9160519595497236
Validation loss: 2.429968895279492

Epoch: 6| Step: 8
Training loss: 2.398372288913977
Validation loss: 2.387173738260187

Epoch: 6| Step: 9
Training loss: 1.7061384646672337
Validation loss: 2.4024412036507483

Epoch: 6| Step: 10
Training loss: 2.263120226914272
Validation loss: 2.445453242277775

Epoch: 6| Step: 11
Training loss: 1.4821329149316547
Validation loss: 2.379998551910558

Epoch: 6| Step: 12
Training loss: 2.1649507427999373
Validation loss: 2.4096715407844735

Epoch: 6| Step: 13
Training loss: 2.1999153944566445
Validation loss: 2.4483185968121903

Epoch: 262| Step: 0
Training loss: 1.654162981363927
Validation loss: 2.4001149173966065

Epoch: 6| Step: 1
Training loss: 1.761361028719675
Validation loss: 2.4028712548128763

Epoch: 6| Step: 2
Training loss: 1.8392736762574802
Validation loss: 2.449928405009453

Epoch: 6| Step: 3
Training loss: 2.3495276889569823
Validation loss: 2.390196601326765

Epoch: 6| Step: 4
Training loss: 1.4956006066532541
Validation loss: 2.3846541621366817

Epoch: 6| Step: 5
Training loss: 1.2397178715802308
Validation loss: 2.3673207506009146

Epoch: 6| Step: 6
Training loss: 1.7715886094825088
Validation loss: 2.4315195922539967

Epoch: 6| Step: 7
Training loss: 1.8363084783519452
Validation loss: 2.4304194075213337

Epoch: 6| Step: 8
Training loss: 1.4745476109788578
Validation loss: 2.4215048283137004

Epoch: 6| Step: 9
Training loss: 2.0407336172548924
Validation loss: 2.4437679521220033

Epoch: 6| Step: 10
Training loss: 2.7457973271403255
Validation loss: 2.421864343699796

Epoch: 6| Step: 11
Training loss: 1.5122247681949388
Validation loss: 2.398726752343697

Epoch: 6| Step: 12
Training loss: 1.8886822263321557
Validation loss: 2.42906511460666

Epoch: 6| Step: 13
Training loss: 1.5271600871380304
Validation loss: 2.4706288793600675

Epoch: 263| Step: 0
Training loss: 1.872066300795291
Validation loss: 2.4194728300247275

Epoch: 6| Step: 1
Training loss: 0.9660794457233143
Validation loss: 2.4533800094861538

Epoch: 6| Step: 2
Training loss: 2.4246127497786447
Validation loss: 2.401018737622271

Epoch: 6| Step: 3
Training loss: 2.508739074470363
Validation loss: 2.420355341676394

Epoch: 6| Step: 4
Training loss: 1.6574060975599807
Validation loss: 2.402207767784183

Epoch: 6| Step: 5
Training loss: 1.9841255571874907
Validation loss: 2.3943371750911218

Epoch: 6| Step: 6
Training loss: 1.9099743216221472
Validation loss: 2.469515044205847

Epoch: 6| Step: 7
Training loss: 1.818316499100104
Validation loss: 2.412760507336256

Epoch: 6| Step: 8
Training loss: 1.8043279248324569
Validation loss: 2.408040839225019

Epoch: 6| Step: 9
Training loss: 1.6067005638778284
Validation loss: 2.4514462221263824

Epoch: 6| Step: 10
Training loss: 1.5037279692167274
Validation loss: 2.4612667709216924

Epoch: 6| Step: 11
Training loss: 1.7934487226061624
Validation loss: 2.427623430077043

Epoch: 6| Step: 12
Training loss: 1.3139987290519943
Validation loss: 2.41540628528851

Epoch: 6| Step: 13
Training loss: 1.372537835994539
Validation loss: 2.4323883945605664

Epoch: 264| Step: 0
Training loss: 1.7202327228172487
Validation loss: 2.45157538397368

Epoch: 6| Step: 1
Training loss: 2.520649317390701
Validation loss: 2.470794763454071

Epoch: 6| Step: 2
Training loss: 1.778596005130435
Validation loss: 2.432852256723455

Epoch: 6| Step: 3
Training loss: 1.8124422524559365
Validation loss: 2.4676573612056263

Epoch: 6| Step: 4
Training loss: 1.6113014912571573
Validation loss: 2.4407345346100486

Epoch: 6| Step: 5
Training loss: 1.5835338097526175
Validation loss: 2.4414174363403

Epoch: 6| Step: 6
Training loss: 1.579948957560368
Validation loss: 2.431539118493507

Epoch: 6| Step: 7
Training loss: 1.709101697981776
Validation loss: 2.4172781160849

Epoch: 6| Step: 8
Training loss: 1.7606700135564763
Validation loss: 2.453628490459836

Epoch: 6| Step: 9
Training loss: 1.7967270499977461
Validation loss: 2.41338387195844

Epoch: 6| Step: 10
Training loss: 1.8302081376410178
Validation loss: 2.4429632866725406

Epoch: 6| Step: 11
Training loss: 1.6510024522362283
Validation loss: 2.5060598107359073

Epoch: 6| Step: 12
Training loss: 2.1037853638277038
Validation loss: 2.421731740979738

Epoch: 6| Step: 13
Training loss: 1.9742606408792633
Validation loss: 2.4505553562464346

Epoch: 265| Step: 0
Training loss: 1.8276254998570307
Validation loss: 2.378788098340606

Epoch: 6| Step: 1
Training loss: 1.380470577253893
Validation loss: 2.3848831300862714

Epoch: 6| Step: 2
Training loss: 1.750761207149227
Validation loss: 2.431321738954312

Epoch: 6| Step: 3
Training loss: 1.8938823414503463
Validation loss: 2.369345420372983

Epoch: 6| Step: 4
Training loss: 2.5039070117491042
Validation loss: 2.4031049558710724

Epoch: 6| Step: 5
Training loss: 1.2698003395708586
Validation loss: 2.429376372347219

Epoch: 6| Step: 6
Training loss: 1.9964957532295364
Validation loss: 2.379833622138521

Epoch: 6| Step: 7
Training loss: 1.6876055366575382
Validation loss: 2.400879943610249

Epoch: 6| Step: 8
Training loss: 1.437531097739163
Validation loss: 2.3885730159528604

Epoch: 6| Step: 9
Training loss: 1.7380508784538962
Validation loss: 2.3791490807344955

Epoch: 6| Step: 10
Training loss: 1.7798620471645115
Validation loss: 2.4232235650066576

Epoch: 6| Step: 11
Training loss: 1.777696578668226
Validation loss: 2.407127183728497

Epoch: 6| Step: 12
Training loss: 2.4323515683843238
Validation loss: 2.375809448979962

Epoch: 6| Step: 13
Training loss: 1.5243718338761836
Validation loss: 2.3407227981266967

Epoch: 266| Step: 0
Training loss: 1.7480198010953314
Validation loss: 2.379236280558098

Epoch: 6| Step: 1
Training loss: 1.3142713673323885
Validation loss: 2.4781061684032433

Epoch: 6| Step: 2
Training loss: 1.8462598495892175
Validation loss: 2.388611807696077

Epoch: 6| Step: 3
Training loss: 1.878465945863453
Validation loss: 2.4126858227741823

Epoch: 6| Step: 4
Training loss: 2.018295529822906
Validation loss: 2.4186787409862207

Epoch: 6| Step: 5
Training loss: 1.6568146229049376
Validation loss: 2.4790200558669806

Epoch: 6| Step: 6
Training loss: 1.7050514175403328
Validation loss: 2.4477295171498863

Epoch: 6| Step: 7
Training loss: 1.4999440500633057
Validation loss: 2.4437425712164322

Epoch: 6| Step: 8
Training loss: 1.7964307152849885
Validation loss: 2.4178749482557027

Epoch: 6| Step: 9
Training loss: 1.9124459427318357
Validation loss: 2.358471876926327

Epoch: 6| Step: 10
Training loss: 1.5270825721284322
Validation loss: 2.4348392410023307

Epoch: 6| Step: 11
Training loss: 1.55226698264688
Validation loss: 2.4164586918300546

Epoch: 6| Step: 12
Training loss: 2.8769431803545027
Validation loss: 2.469359259753728

Epoch: 6| Step: 13
Training loss: 0.9591477948267485
Validation loss: 2.4246204820955164

Epoch: 267| Step: 0
Training loss: 1.7967097994286771
Validation loss: 2.399457719544345

Epoch: 6| Step: 1
Training loss: 1.5853089839475965
Validation loss: 2.4866583463195377

Epoch: 6| Step: 2
Training loss: 1.5962929726882626
Validation loss: 2.4085463417920723

Epoch: 6| Step: 3
Training loss: 1.2352512002216092
Validation loss: 2.4060151883596017

Epoch: 6| Step: 4
Training loss: 1.8136888748479754
Validation loss: 2.3762285771325358

Epoch: 6| Step: 5
Training loss: 2.056753186281963
Validation loss: 2.4269745434539676

Epoch: 6| Step: 6
Training loss: 1.7402819146407105
Validation loss: 2.468907660811837

Epoch: 6| Step: 7
Training loss: 2.1050357975033944
Validation loss: 2.3973990677471617

Epoch: 6| Step: 8
Training loss: 1.7627713258367868
Validation loss: 2.4318326215759387

Epoch: 6| Step: 9
Training loss: 1.4880494265089592
Validation loss: 2.3985754611170074

Epoch: 6| Step: 10
Training loss: 1.796101411900184
Validation loss: 2.408405839904638

Epoch: 6| Step: 11
Training loss: 1.3348352893559876
Validation loss: 2.4000550382124466

Epoch: 6| Step: 12
Training loss: 2.8967140194176104
Validation loss: 2.3980513276468565

Epoch: 6| Step: 13
Training loss: 1.1542334111512749
Validation loss: 2.4091490802089024

Epoch: 268| Step: 0
Training loss: 1.9835714079780682
Validation loss: 2.34087161770881

Epoch: 6| Step: 1
Training loss: 1.6970314417428793
Validation loss: 2.395679012712619

Epoch: 6| Step: 2
Training loss: 2.0551135415594857
Validation loss: 2.3765409680880327

Epoch: 6| Step: 3
Training loss: 1.7995709305224186
Validation loss: 2.387115450381094

Epoch: 6| Step: 4
Training loss: 1.727837691472706
Validation loss: 2.377403043657823

Epoch: 6| Step: 5
Training loss: 1.576648890507328
Validation loss: 2.400359223705402

Epoch: 6| Step: 6
Training loss: 1.7929126340108714
Validation loss: 2.42492514197579

Epoch: 6| Step: 7
Training loss: 1.5283058043939979
Validation loss: 2.3718584868921053

Epoch: 6| Step: 8
Training loss: 2.228613086545142
Validation loss: 2.3700074308701278

Epoch: 6| Step: 9
Training loss: 1.5008787918760935
Validation loss: 2.4340840976802713

Epoch: 6| Step: 10
Training loss: 1.543063776494302
Validation loss: 2.4184943689813325

Epoch: 6| Step: 11
Training loss: 1.632744089546072
Validation loss: 2.4359730117477225

Epoch: 6| Step: 12
Training loss: 1.7834643603999758
Validation loss: 2.4439792252898536

Epoch: 6| Step: 13
Training loss: 2.510427187400289
Validation loss: 2.4567535596657053

Epoch: 269| Step: 0
Training loss: 2.024724013748082
Validation loss: 2.3685017551915584

Epoch: 6| Step: 1
Training loss: 1.873405796065924
Validation loss: 2.36630012977544

Epoch: 6| Step: 2
Training loss: 1.4791094092807342
Validation loss: 2.4347443929292933

Epoch: 6| Step: 3
Training loss: 2.018082178157126
Validation loss: 2.351128064336566

Epoch: 6| Step: 4
Training loss: 1.4937844244529668
Validation loss: 2.424105231498738

Epoch: 6| Step: 5
Training loss: 2.1289744514949933
Validation loss: 2.411135551434368

Epoch: 6| Step: 6
Training loss: 1.6094526253654993
Validation loss: 2.363150264588457

Epoch: 6| Step: 7
Training loss: 1.1967075160996339
Validation loss: 2.3792344056974546

Epoch: 6| Step: 8
Training loss: 1.7068489029690146
Validation loss: 2.4274943577307866

Epoch: 6| Step: 9
Training loss: 1.6216899464900796
Validation loss: 2.4501237152017774

Epoch: 6| Step: 10
Training loss: 1.0604230552036227
Validation loss: 2.363028478363368

Epoch: 6| Step: 11
Training loss: 2.5948129337337167
Validation loss: 2.383308738491525

Epoch: 6| Step: 12
Training loss: 1.5729959059538918
Validation loss: 2.3857047062967687

Epoch: 6| Step: 13
Training loss: 1.73063820726088
Validation loss: 2.3959006394129605

Epoch: 270| Step: 0
Training loss: 2.0592674586185953
Validation loss: 2.4177008853266093

Epoch: 6| Step: 1
Training loss: 1.6544291725988138
Validation loss: 2.4742684464098006

Epoch: 6| Step: 2
Training loss: 1.4199795507919677
Validation loss: 2.3978722740602803

Epoch: 6| Step: 3
Training loss: 1.49631365163437
Validation loss: 2.440620564100676

Epoch: 6| Step: 4
Training loss: 2.231987057289417
Validation loss: 2.4637537366344753

Epoch: 6| Step: 5
Training loss: 1.544960687007538
Validation loss: 2.461066090287074

Epoch: 6| Step: 6
Training loss: 1.340573081765185
Validation loss: 2.407729046021441

Epoch: 6| Step: 7
Training loss: 2.2271937496075673
Validation loss: 2.4544282691848034

Epoch: 6| Step: 8
Training loss: 1.97864449957789
Validation loss: 2.373339176477846

Epoch: 6| Step: 9
Training loss: 1.6243057235029805
Validation loss: 2.4042806217216723

Epoch: 6| Step: 10
Training loss: 2.404538821853534
Validation loss: 2.39307703705877

Epoch: 6| Step: 11
Training loss: 1.5577902957783945
Validation loss: 2.3779415659512937

Epoch: 6| Step: 12
Training loss: 1.4736119414836635
Validation loss: 2.360718593709036

Epoch: 6| Step: 13
Training loss: 1.1245568780283086
Validation loss: 2.4259829335700216

Epoch: 271| Step: 0
Training loss: 1.5094357780398389
Validation loss: 2.416059556373419

Epoch: 6| Step: 1
Training loss: 1.4794934766908574
Validation loss: 2.4013943336548915

Epoch: 6| Step: 2
Training loss: 1.7545334134337798
Validation loss: 2.3988750550725797

Epoch: 6| Step: 3
Training loss: 1.4378936062849
Validation loss: 2.435665133632139

Epoch: 6| Step: 4
Training loss: 2.403804576807658
Validation loss: 2.4167521694646052

Epoch: 6| Step: 5
Training loss: 2.0250193182883263
Validation loss: 2.4053542258752922

Epoch: 6| Step: 6
Training loss: 1.5374846915126479
Validation loss: 2.3884900446070043

Epoch: 6| Step: 7
Training loss: 1.7137702240644435
Validation loss: 2.3818370418139625

Epoch: 6| Step: 8
Training loss: 1.5827410577314462
Validation loss: 2.3667794407266665

Epoch: 6| Step: 9
Training loss: 1.9930498239019063
Validation loss: 2.400902631949575

Epoch: 6| Step: 10
Training loss: 1.5357535949694763
Validation loss: 2.3645541787546787

Epoch: 6| Step: 11
Training loss: 1.5338920066151214
Validation loss: 2.4023667617283984

Epoch: 6| Step: 12
Training loss: 1.6059890238195609
Validation loss: 2.4049564832696513

Epoch: 6| Step: 13
Training loss: 2.9331205471483788
Validation loss: 2.4242312842776874

Epoch: 272| Step: 0
Training loss: 1.6035979199868668
Validation loss: 2.372908165927

Epoch: 6| Step: 1
Training loss: 2.1243205386680892
Validation loss: 2.4082454147440076

Epoch: 6| Step: 2
Training loss: 1.6727415316995506
Validation loss: 2.436539343125366

Epoch: 6| Step: 3
Training loss: 0.9931216910747046
Validation loss: 2.4595196789856693

Epoch: 6| Step: 4
Training loss: 1.4846642463354884
Validation loss: 2.442751114381417

Epoch: 6| Step: 5
Training loss: 2.701290676899833
Validation loss: 2.439900277395606

Epoch: 6| Step: 6
Training loss: 1.510700207985755
Validation loss: 2.4420198846606262

Epoch: 6| Step: 7
Training loss: 1.816087657921859
Validation loss: 2.393411135452528

Epoch: 6| Step: 8
Training loss: 1.4786106819828881
Validation loss: 2.4069397439440485

Epoch: 6| Step: 9
Training loss: 1.7764918706671953
Validation loss: 2.434706098240214

Epoch: 6| Step: 10
Training loss: 1.6639756014346483
Validation loss: 2.3934608683044836

Epoch: 6| Step: 11
Training loss: 1.561806792028848
Validation loss: 2.3727179780735894

Epoch: 6| Step: 12
Training loss: 1.9810104080843383
Validation loss: 2.4056569756229145

Epoch: 6| Step: 13
Training loss: 1.852269162559164
Validation loss: 2.420025911731454

Epoch: 273| Step: 0
Training loss: 1.790733722894514
Validation loss: 2.3690615321071786

Epoch: 6| Step: 1
Training loss: 1.801967933208583
Validation loss: 2.3742375998667606

Epoch: 6| Step: 2
Training loss: 1.1968574761684003
Validation loss: 2.441245411158655

Epoch: 6| Step: 3
Training loss: 1.6702322331297075
Validation loss: 2.3850676899296004

Epoch: 6| Step: 4
Training loss: 2.2395093920426232
Validation loss: 2.4149771701599283

Epoch: 6| Step: 5
Training loss: 1.6629081626578426
Validation loss: 2.4128655163719346

Epoch: 6| Step: 6
Training loss: 1.8113698395546376
Validation loss: 2.4063502044333247

Epoch: 6| Step: 7
Training loss: 2.2056500189106183
Validation loss: 2.3811862495081004

Epoch: 6| Step: 8
Training loss: 1.6377089243387437
Validation loss: 2.4506607972059204

Epoch: 6| Step: 9
Training loss: 2.0098681187422045
Validation loss: 2.4148100866779756

Epoch: 6| Step: 10
Training loss: 1.6467641138028206
Validation loss: 2.412986829263601

Epoch: 6| Step: 11
Training loss: 2.053549679943094
Validation loss: 2.3367290636576254

Epoch: 6| Step: 12
Training loss: 1.8504092330915014
Validation loss: 2.388487760557342

Epoch: 6| Step: 13
Training loss: 1.4597678985047187
Validation loss: 2.4107764735710666

Epoch: 274| Step: 0
Training loss: 2.0017953205716728
Validation loss: 2.420372613461303

Epoch: 6| Step: 1
Training loss: 2.2048166692732027
Validation loss: 2.368341314788403

Epoch: 6| Step: 2
Training loss: 1.3060652259936583
Validation loss: 2.3559682005653046

Epoch: 6| Step: 3
Training loss: 1.4100090224741675
Validation loss: 2.4036198595304117

Epoch: 6| Step: 4
Training loss: 1.8027199592716547
Validation loss: 2.4400453574316967

Epoch: 6| Step: 5
Training loss: 1.5542012129856826
Validation loss: 2.388970813131859

Epoch: 6| Step: 6
Training loss: 2.1894464824483872
Validation loss: 2.427270306328517

Epoch: 6| Step: 7
Training loss: 1.924463900934428
Validation loss: 2.4083366897593117

Epoch: 6| Step: 8
Training loss: 1.3880193494415463
Validation loss: 2.4562492031812218

Epoch: 6| Step: 9
Training loss: 2.1613689970988
Validation loss: 2.417957780674537

Epoch: 6| Step: 10
Training loss: 1.5824932412821273
Validation loss: 2.43603248267093

Epoch: 6| Step: 11
Training loss: 1.6718504716731664
Validation loss: 2.3695517938629957

Epoch: 6| Step: 12
Training loss: 1.6460452687746678
Validation loss: 2.399620243119672

Epoch: 6| Step: 13
Training loss: 1.123419233871329
Validation loss: 2.4575964683841893

Epoch: 275| Step: 0
Training loss: 1.884366229338977
Validation loss: 2.3976463238676424

Epoch: 6| Step: 1
Training loss: 1.1996721535108763
Validation loss: 2.4193064967832476

Epoch: 6| Step: 2
Training loss: 1.865494283572814
Validation loss: 2.422458163790297

Epoch: 6| Step: 3
Training loss: 1.844812378066158
Validation loss: 2.41078097338071

Epoch: 6| Step: 4
Training loss: 2.4782867686710057
Validation loss: 2.401745799972689

Epoch: 6| Step: 5
Training loss: 1.9507723256962282
Validation loss: 2.406026089599149

Epoch: 6| Step: 6
Training loss: 1.710842878956402
Validation loss: 2.4024878183154015

Epoch: 6| Step: 7
Training loss: 1.718752566248972
Validation loss: 2.4126022132313327

Epoch: 6| Step: 8
Training loss: 1.8102439783378368
Validation loss: 2.4220105755476693

Epoch: 6| Step: 9
Training loss: 1.6459744388917792
Validation loss: 2.412766266264927

Epoch: 6| Step: 10
Training loss: 1.5063082450273833
Validation loss: 2.4536109789373928

Epoch: 6| Step: 11
Training loss: 1.3493782872437814
Validation loss: 2.443747921433383

Epoch: 6| Step: 12
Training loss: 2.098118906838959
Validation loss: 2.3835527270516534

Epoch: 6| Step: 13
Training loss: 1.5551201299893587
Validation loss: 2.4102191574798737

Epoch: 276| Step: 0
Training loss: 1.9257156329940603
Validation loss: 2.419528953549064

Epoch: 6| Step: 1
Training loss: 1.4199209514966478
Validation loss: 2.4175824292706722

Epoch: 6| Step: 2
Training loss: 1.9075768027586337
Validation loss: 2.3970723693833857

Epoch: 6| Step: 3
Training loss: 1.312568208647804
Validation loss: 2.388237685768222

Epoch: 6| Step: 4
Training loss: 2.132346748668043
Validation loss: 2.447292713525096

Epoch: 6| Step: 5
Training loss: 1.5546319846204697
Validation loss: 2.464275743391333

Epoch: 6| Step: 6
Training loss: 1.966757113860752
Validation loss: 2.4107869651383065

Epoch: 6| Step: 7
Training loss: 2.410638152035437
Validation loss: 2.4391074705549345

Epoch: 6| Step: 8
Training loss: 1.1414616273035398
Validation loss: 2.393937846747844

Epoch: 6| Step: 9
Training loss: 1.7443386875310731
Validation loss: 2.4239394202608695

Epoch: 6| Step: 10
Training loss: 1.6327552602855806
Validation loss: 2.36906061770427

Epoch: 6| Step: 11
Training loss: 1.9495894513404806
Validation loss: 2.427563684503688

Epoch: 6| Step: 12
Training loss: 1.2769306226388961
Validation loss: 2.4314878206606796

Epoch: 6| Step: 13
Training loss: 1.005696403856117
Validation loss: 2.456985055581912

Epoch: 277| Step: 0
Training loss: 1.8934426867219933
Validation loss: 2.451472653735268

Epoch: 6| Step: 1
Training loss: 1.7033759116035072
Validation loss: 2.404710738381557

Epoch: 6| Step: 2
Training loss: 1.5162267375271699
Validation loss: 2.415203857558123

Epoch: 6| Step: 3
Training loss: 2.493210633347602
Validation loss: 2.433311050811416

Epoch: 6| Step: 4
Training loss: 1.933054839278419
Validation loss: 2.4141170491430812

Epoch: 6| Step: 5
Training loss: 1.2455255534377274
Validation loss: 2.4704052179156104

Epoch: 6| Step: 6
Training loss: 1.8502175641360266
Validation loss: 2.405490418153418

Epoch: 6| Step: 7
Training loss: 1.9615497013420182
Validation loss: 2.3805814021506126

Epoch: 6| Step: 8
Training loss: 1.2466509299806496
Validation loss: 2.3990524287715833

Epoch: 6| Step: 9
Training loss: 2.2259151119898783
Validation loss: 2.398837556777081

Epoch: 6| Step: 10
Training loss: 1.9866863816625038
Validation loss: 2.419881397494661

Epoch: 6| Step: 11
Training loss: 1.474894636237972
Validation loss: 2.4332172884334695

Epoch: 6| Step: 12
Training loss: 1.2266510366570484
Validation loss: 2.471190429527546

Epoch: 6| Step: 13
Training loss: 1.0910214313007027
Validation loss: 2.4213321443912106

Epoch: 278| Step: 0
Training loss: 1.379917843556904
Validation loss: 2.385483512223042

Epoch: 6| Step: 1
Training loss: 1.8777890125417602
Validation loss: 2.4473371330709717

Epoch: 6| Step: 2
Training loss: 1.7185092410609664
Validation loss: 2.4285039336001177

Epoch: 6| Step: 3
Training loss: 1.1407192661576948
Validation loss: 2.4279758837243626

Epoch: 6| Step: 4
Training loss: 1.3561561446522221
Validation loss: 2.4292449827805114

Epoch: 6| Step: 5
Training loss: 1.5128106011132716
Validation loss: 2.383575122678041

Epoch: 6| Step: 6
Training loss: 2.4389946096625827
Validation loss: 2.3989229060133765

Epoch: 6| Step: 7
Training loss: 1.7413453945036248
Validation loss: 2.4050584396342836

Epoch: 6| Step: 8
Training loss: 2.2528869333827948
Validation loss: 2.373627530015831

Epoch: 6| Step: 9
Training loss: 1.7750247120815998
Validation loss: 2.3526503826820293

Epoch: 6| Step: 10
Training loss: 1.899611749633836
Validation loss: 2.3893476850342354

Epoch: 6| Step: 11
Training loss: 1.6596071300034392
Validation loss: 2.407001588400897

Epoch: 6| Step: 12
Training loss: 1.4785884300054797
Validation loss: 2.382864413207797

Epoch: 6| Step: 13
Training loss: 1.772764574005252
Validation loss: 2.3992523875182026

Epoch: 279| Step: 0
Training loss: 1.6420626199934447
Validation loss: 2.4928892550912094

Epoch: 6| Step: 1
Training loss: 1.8162883761316637
Validation loss: 2.4615232693417672

Epoch: 6| Step: 2
Training loss: 1.9027610493440523
Validation loss: 2.419344406857441

Epoch: 6| Step: 3
Training loss: 1.9709829352969268
Validation loss: 2.450687147845178

Epoch: 6| Step: 4
Training loss: 1.7984565740480287
Validation loss: 2.420369982955181

Epoch: 6| Step: 5
Training loss: 2.0844548703380053
Validation loss: 2.3896962446891594

Epoch: 6| Step: 6
Training loss: 1.5621914368175602
Validation loss: 2.4569726953262863

Epoch: 6| Step: 7
Training loss: 1.7349713649090706
Validation loss: 2.408392562915662

Epoch: 6| Step: 8
Training loss: 1.0202441299221001
Validation loss: 2.4338577336174074

Epoch: 6| Step: 9
Training loss: 1.616218755881769
Validation loss: 2.3649475607146244

Epoch: 6| Step: 10
Training loss: 1.86190265062589
Validation loss: 2.46927692547642

Epoch: 6| Step: 11
Training loss: 1.6913456366340487
Validation loss: 2.4467700266922408

Epoch: 6| Step: 12
Training loss: 1.5294837886154438
Validation loss: 2.3963649076222096

Epoch: 6| Step: 13
Training loss: 2.1306628898011026
Validation loss: 2.4282815067042893

Epoch: 280| Step: 0
Training loss: 1.2715093138515272
Validation loss: 2.371571077080153

Epoch: 6| Step: 1
Training loss: 1.9890862954177972
Validation loss: 2.388659744031328

Epoch: 6| Step: 2
Training loss: 1.3979098214191752
Validation loss: 2.4036927321564705

Epoch: 6| Step: 3
Training loss: 1.5236874888790284
Validation loss: 2.4010300192349017

Epoch: 6| Step: 4
Training loss: 2.146875430888614
Validation loss: 2.3688730737831585

Epoch: 6| Step: 5
Training loss: 1.3844202038551319
Validation loss: 2.3628746524326183

Epoch: 6| Step: 6
Training loss: 1.6093864070154755
Validation loss: 2.419639915211405

Epoch: 6| Step: 7
Training loss: 1.7188857978579848
Validation loss: 2.413233981385662

Epoch: 6| Step: 8
Training loss: 2.4949232052162964
Validation loss: 2.415222729700306

Epoch: 6| Step: 9
Training loss: 1.8805608304486783
Validation loss: 2.4138720339983686

Epoch: 6| Step: 10
Training loss: 1.5317738473865368
Validation loss: 2.3831146054101313

Epoch: 6| Step: 11
Training loss: 1.6918829054660094
Validation loss: 2.4406335155629515

Epoch: 6| Step: 12
Training loss: 1.4994370675766298
Validation loss: 2.415063358185654

Epoch: 6| Step: 13
Training loss: 1.4402966040215996
Validation loss: 2.405592863957225

Epoch: 281| Step: 0
Training loss: 1.6097736050195768
Validation loss: 2.4556330931728474

Epoch: 6| Step: 1
Training loss: 1.9882403596222
Validation loss: 2.375090338819013

Epoch: 6| Step: 2
Training loss: 1.4185166154385174
Validation loss: 2.418233378112669

Epoch: 6| Step: 3
Training loss: 1.80641923527389
Validation loss: 2.4610399690081737

Epoch: 6| Step: 4
Training loss: 1.8944979635244314
Validation loss: 2.414617847654372

Epoch: 6| Step: 5
Training loss: 1.9560657792293488
Validation loss: 2.4381039031474203

Epoch: 6| Step: 6
Training loss: 1.9352841165223824
Validation loss: 2.469738061726382

Epoch: 6| Step: 7
Training loss: 1.3351387179023273
Validation loss: 2.4999225358344184

Epoch: 6| Step: 8
Training loss: 2.484972036346353
Validation loss: 2.41762305766902

Epoch: 6| Step: 9
Training loss: 1.7897823834399593
Validation loss: 2.3743724339279786

Epoch: 6| Step: 10
Training loss: 1.3731333025758137
Validation loss: 2.404399407909665

Epoch: 6| Step: 11
Training loss: 1.4164959112741886
Validation loss: 2.451574850137888

Epoch: 6| Step: 12
Training loss: 1.402026212226832
Validation loss: 2.4744291235604496

Epoch: 6| Step: 13
Training loss: 2.05876688799159
Validation loss: 2.407013881481549

Epoch: 282| Step: 0
Training loss: 1.9776803576065554
Validation loss: 2.4169467637115227

Epoch: 6| Step: 1
Training loss: 1.928902037605516
Validation loss: 2.437712046716023

Epoch: 6| Step: 2
Training loss: 2.7470291736721433
Validation loss: 2.414888118318349

Epoch: 6| Step: 3
Training loss: 1.5689326814465727
Validation loss: 2.4104114330300623

Epoch: 6| Step: 4
Training loss: 1.5525135579031653
Validation loss: 2.4425907891672516

Epoch: 6| Step: 5
Training loss: 1.391295110857145
Validation loss: 2.4404572332251258

Epoch: 6| Step: 6
Training loss: 2.015979233006585
Validation loss: 2.4322039355672076

Epoch: 6| Step: 7
Training loss: 1.3350225963180355
Validation loss: 2.4241927494876334

Epoch: 6| Step: 8
Training loss: 2.067569859349622
Validation loss: 2.396056121982548

Epoch: 6| Step: 9
Training loss: 1.4217976978793672
Validation loss: 2.3725041853170206

Epoch: 6| Step: 10
Training loss: 1.2689360176862765
Validation loss: 2.4686556229906853

Epoch: 6| Step: 11
Training loss: 1.5635056883120166
Validation loss: 2.419508277170282

Epoch: 6| Step: 12
Training loss: 1.6771150984826144
Validation loss: 2.3750446560411915

Epoch: 6| Step: 13
Training loss: 1.7440574429658628
Validation loss: 2.463413360493623

Epoch: 283| Step: 0
Training loss: 1.8471344741337723
Validation loss: 2.369377319792873

Epoch: 6| Step: 1
Training loss: 1.596570455098638
Validation loss: 2.4592850207204298

Epoch: 6| Step: 2
Training loss: 1.9279238405816261
Validation loss: 2.4597963665800417

Epoch: 6| Step: 3
Training loss: 1.694565568913222
Validation loss: 2.4606561815423946

Epoch: 6| Step: 4
Training loss: 1.7978632324105228
Validation loss: 2.438247887763952

Epoch: 6| Step: 5
Training loss: 1.5398232375916867
Validation loss: 2.479709478096186

Epoch: 6| Step: 6
Training loss: 1.7907049643884594
Validation loss: 2.494287568408065

Epoch: 6| Step: 7
Training loss: 1.5981823491028446
Validation loss: 2.47372184482332

Epoch: 6| Step: 8
Training loss: 1.3673556851073303
Validation loss: 2.4497407668074556

Epoch: 6| Step: 9
Training loss: 1.5611448133110688
Validation loss: 2.425899761181524

Epoch: 6| Step: 10
Training loss: 1.7002802898242524
Validation loss: 2.4302424032715497

Epoch: 6| Step: 11
Training loss: 1.5889631452229567
Validation loss: 2.4259973105167902

Epoch: 6| Step: 12
Training loss: 2.454191717031853
Validation loss: 2.415315803893447

Epoch: 6| Step: 13
Training loss: 2.2092722090532595
Validation loss: 2.4213031116079633

Epoch: 284| Step: 0
Training loss: 1.2914584463732472
Validation loss: 2.372005006629001

Epoch: 6| Step: 1
Training loss: 1.7344998151526705
Validation loss: 2.359812465804244

Epoch: 6| Step: 2
Training loss: 1.770918615942927
Validation loss: 2.443077305295336

Epoch: 6| Step: 3
Training loss: 1.6039475708333797
Validation loss: 2.419209796700676

Epoch: 6| Step: 4
Training loss: 1.8801098812741432
Validation loss: 2.4403120069632096

Epoch: 6| Step: 5
Training loss: 1.7972151724539365
Validation loss: 2.441251312918015

Epoch: 6| Step: 6
Training loss: 1.606028957965722
Validation loss: 2.426959349424665

Epoch: 6| Step: 7
Training loss: 2.3669726585868713
Validation loss: 2.388973079013303

Epoch: 6| Step: 8
Training loss: 2.058082473644522
Validation loss: 2.3913358065539665

Epoch: 6| Step: 9
Training loss: 1.4602706937807766
Validation loss: 2.4248682034698072

Epoch: 6| Step: 10
Training loss: 2.3001870908523037
Validation loss: 2.4119641031805363

Epoch: 6| Step: 11
Training loss: 1.0878882690623335
Validation loss: 2.425277042748914

Epoch: 6| Step: 12
Training loss: 1.1599583312475983
Validation loss: 2.449922092505779

Epoch: 6| Step: 13
Training loss: 1.852275083532925
Validation loss: 2.3816184293313967

Epoch: 285| Step: 0
Training loss: 1.4441987566382741
Validation loss: 2.3705019624149903

Epoch: 6| Step: 1
Training loss: 1.6054463999879451
Validation loss: 2.4122581164721764

Epoch: 6| Step: 2
Training loss: 1.5700872458981556
Validation loss: 2.410731200648093

Epoch: 6| Step: 3
Training loss: 1.4050990586978995
Validation loss: 2.4938278753141976

Epoch: 6| Step: 4
Training loss: 2.1006146530536673
Validation loss: 2.4680848207486306

Epoch: 6| Step: 5
Training loss: 2.135198690562813
Validation loss: 2.4280858665213416

Epoch: 6| Step: 6
Training loss: 2.0869105209156307
Validation loss: 2.447160622312259

Epoch: 6| Step: 7
Training loss: 1.6495844751276836
Validation loss: 2.4137544383294776

Epoch: 6| Step: 8
Training loss: 1.4865708021437718
Validation loss: 2.40114906659324

Epoch: 6| Step: 9
Training loss: 2.2070876392823973
Validation loss: 2.449403490801476

Epoch: 6| Step: 10
Training loss: 1.7148624497352085
Validation loss: 2.439497976287259

Epoch: 6| Step: 11
Training loss: 1.564700294047672
Validation loss: 2.425629322626813

Epoch: 6| Step: 12
Training loss: 1.4847147502578328
Validation loss: 2.420228116748649

Epoch: 6| Step: 13
Training loss: 1.324999733690919
Validation loss: 2.4754498257869137

Epoch: 286| Step: 0
Training loss: 1.0238382268390542
Validation loss: 2.3965088507690977

Epoch: 6| Step: 1
Training loss: 1.676349961317761
Validation loss: 2.3576065408331806

Epoch: 6| Step: 2
Training loss: 1.498535792654231
Validation loss: 2.4262739833068587

Epoch: 6| Step: 3
Training loss: 1.8293689505865116
Validation loss: 2.4152583087457873

Epoch: 6| Step: 4
Training loss: 1.8019422648640329
Validation loss: 2.4044113922949695

Epoch: 6| Step: 5
Training loss: 1.6392781133086682
Validation loss: 2.4045578454012078

Epoch: 6| Step: 6
Training loss: 1.6686900810314038
Validation loss: 2.407414040385663

Epoch: 6| Step: 7
Training loss: 1.8996632704246208
Validation loss: 2.366565537216565

Epoch: 6| Step: 8
Training loss: 2.186806378068793
Validation loss: 2.4120007798768035

Epoch: 6| Step: 9
Training loss: 1.4411653146735595
Validation loss: 2.400222411839543

Epoch: 6| Step: 10
Training loss: 1.7943897475510533
Validation loss: 2.391639540843869

Epoch: 6| Step: 11
Training loss: 2.199798453375589
Validation loss: 2.3143064975221286

Epoch: 6| Step: 12
Training loss: 1.2292351730566557
Validation loss: 2.3893634513847193

Epoch: 6| Step: 13
Training loss: 1.7361625189057683
Validation loss: 2.4532925718556866

Epoch: 287| Step: 0
Training loss: 2.2705447745647347
Validation loss: 2.368185197985166

Epoch: 6| Step: 1
Training loss: 1.5377112328795277
Validation loss: 2.4038248891465726

Epoch: 6| Step: 2
Training loss: 1.7067151508050629
Validation loss: 2.3882394902277637

Epoch: 6| Step: 3
Training loss: 1.0581945813954665
Validation loss: 2.457795357138332

Epoch: 6| Step: 4
Training loss: 1.3279295384804897
Validation loss: 2.3822399315561995

Epoch: 6| Step: 5
Training loss: 1.696479852517969
Validation loss: 2.4640641275786592

Epoch: 6| Step: 6
Training loss: 2.448566258592421
Validation loss: 2.4928014570361623

Epoch: 6| Step: 7
Training loss: 1.1992050319222507
Validation loss: 2.449460377050851

Epoch: 6| Step: 8
Training loss: 1.6107932942889567
Validation loss: 2.486715486517318

Epoch: 6| Step: 9
Training loss: 1.3716124941687615
Validation loss: 2.446158947119677

Epoch: 6| Step: 10
Training loss: 1.9106582574816813
Validation loss: 2.435780390078401

Epoch: 6| Step: 11
Training loss: 2.456598240672793
Validation loss: 2.415882497513164

Epoch: 6| Step: 12
Training loss: 1.3288589693390196
Validation loss: 2.4244865148701775

Epoch: 6| Step: 13
Training loss: 1.2417295079469066
Validation loss: 2.4052049007730667

Epoch: 288| Step: 0
Training loss: 1.71454410932998
Validation loss: 2.4049956012977507

Epoch: 6| Step: 1
Training loss: 1.8355845010541612
Validation loss: 2.368083971329191

Epoch: 6| Step: 2
Training loss: 1.6712392864012289
Validation loss: 2.3913848653766783

Epoch: 6| Step: 3
Training loss: 1.8912503808141554
Validation loss: 2.3919414938474746

Epoch: 6| Step: 4
Training loss: 1.3996586076838002
Validation loss: 2.373953588213583

Epoch: 6| Step: 5
Training loss: 2.0006180046838735
Validation loss: 2.3750347961743743

Epoch: 6| Step: 6
Training loss: 1.8185382759108368
Validation loss: 2.4137813453374295

Epoch: 6| Step: 7
Training loss: 1.3832689383275698
Validation loss: 2.410110653761586

Epoch: 6| Step: 8
Training loss: 1.440741657159451
Validation loss: 2.4642024380814798

Epoch: 6| Step: 9
Training loss: 1.8794595454906675
Validation loss: 2.4536793285433647

Epoch: 6| Step: 10
Training loss: 1.3268000557389705
Validation loss: 2.40631131351227

Epoch: 6| Step: 11
Training loss: 1.676296199471996
Validation loss: 2.3853336439253146

Epoch: 6| Step: 12
Training loss: 2.3017240448175387
Validation loss: 2.4293576444521743

Epoch: 6| Step: 13
Training loss: 1.0151692468258324
Validation loss: 2.348106676447945

Epoch: 289| Step: 0
Training loss: 1.6074435300979046
Validation loss: 2.423893975419088

Epoch: 6| Step: 1
Training loss: 1.6992971117213196
Validation loss: 2.4504130630741052

Epoch: 6| Step: 2
Training loss: 1.5161020373727587
Validation loss: 2.4050779014322057

Epoch: 6| Step: 3
Training loss: 2.561031572104856
Validation loss: 2.368398034061205

Epoch: 6| Step: 4
Training loss: 1.7629111033728802
Validation loss: 2.4088115708105655

Epoch: 6| Step: 5
Training loss: 1.7801109151894403
Validation loss: 2.4220774576205657

Epoch: 6| Step: 6
Training loss: 1.8678559579144751
Validation loss: 2.3356244431018354

Epoch: 6| Step: 7
Training loss: 1.7455883958955307
Validation loss: 2.4271021403922353

Epoch: 6| Step: 8
Training loss: 1.4642977498054994
Validation loss: 2.4099485719674263

Epoch: 6| Step: 9
Training loss: 1.3557317736914833
Validation loss: 2.4255731457807856

Epoch: 6| Step: 10
Training loss: 1.512867729945532
Validation loss: 2.4093087929319497

Epoch: 6| Step: 11
Training loss: 1.567073308981442
Validation loss: 2.4027525392502547

Epoch: 6| Step: 12
Training loss: 1.8887639619928491
Validation loss: 2.399969324391026

Epoch: 6| Step: 13
Training loss: 1.2196270647843712
Validation loss: 2.4784714973740485

Epoch: 290| Step: 0
Training loss: 1.7792479658052223
Validation loss: 2.4009970903590774

Epoch: 6| Step: 1
Training loss: 1.8440148114914912
Validation loss: 2.4000834286453148

Epoch: 6| Step: 2
Training loss: 2.1370119664272638
Validation loss: 2.440916280428721

Epoch: 6| Step: 3
Training loss: 2.17351223277565
Validation loss: 2.4392386031899274

Epoch: 6| Step: 4
Training loss: 1.7655104878518404
Validation loss: 2.3935840086584173

Epoch: 6| Step: 5
Training loss: 2.0419870501489656
Validation loss: 2.384588330343204

Epoch: 6| Step: 6
Training loss: 1.7935308767850766
Validation loss: 2.404394814590281

Epoch: 6| Step: 7
Training loss: 1.4673880085624011
Validation loss: 2.3741095805392276

Epoch: 6| Step: 8
Training loss: 1.3673209424972488
Validation loss: 2.4434831167467093

Epoch: 6| Step: 9
Training loss: 1.2045611442669526
Validation loss: 2.41127931135029

Epoch: 6| Step: 10
Training loss: 1.5501430937642562
Validation loss: 2.39753799536856

Epoch: 6| Step: 11
Training loss: 1.3352477317437963
Validation loss: 2.410385384471286

Epoch: 6| Step: 12
Training loss: 1.6110443050228576
Validation loss: 2.439687159377113

Epoch: 6| Step: 13
Training loss: 1.5958626899641857
Validation loss: 2.491117687234896

Epoch: 291| Step: 0
Training loss: 2.117272181770501
Validation loss: 2.4144938752185694

Epoch: 6| Step: 1
Training loss: 1.221106622765966
Validation loss: 2.414088255606848

Epoch: 6| Step: 2
Training loss: 1.79507727879014
Validation loss: 2.4303849538845066

Epoch: 6| Step: 3
Training loss: 1.4501223972883495
Validation loss: 2.436093750621312

Epoch: 6| Step: 4
Training loss: 1.9717387567961127
Validation loss: 2.5204191126046904

Epoch: 6| Step: 5
Training loss: 1.5096355742469307
Validation loss: 2.4150188795125542

Epoch: 6| Step: 6
Training loss: 1.9684741114512057
Validation loss: 2.4886080650459768

Epoch: 6| Step: 7
Training loss: 1.564868962222397
Validation loss: 2.437221187214645

Epoch: 6| Step: 8
Training loss: 0.8977176602093679
Validation loss: 2.362275737764177

Epoch: 6| Step: 9
Training loss: 1.7852553459058593
Validation loss: 2.4326822941677633

Epoch: 6| Step: 10
Training loss: 2.291478363161361
Validation loss: 2.437790956635657

Epoch: 6| Step: 11
Training loss: 1.4813720845963179
Validation loss: 2.392665877935599

Epoch: 6| Step: 12
Training loss: 1.1445078147598053
Validation loss: 2.4261698758392707

Epoch: 6| Step: 13
Training loss: 1.973811228830996
Validation loss: 2.3972259354847694

Epoch: 292| Step: 0
Training loss: 2.917822817583688
Validation loss: 2.371799234093491

Epoch: 6| Step: 1
Training loss: 1.3665082715674308
Validation loss: 2.416533573277767

Epoch: 6| Step: 2
Training loss: 1.3383123248356745
Validation loss: 2.452327491257809

Epoch: 6| Step: 3
Training loss: 1.2563722788195166
Validation loss: 2.363737779030431

Epoch: 6| Step: 4
Training loss: 1.4275552660771027
Validation loss: 2.488940033599888

Epoch: 6| Step: 5
Training loss: 2.315834322180256
Validation loss: 2.3977354876207198

Epoch: 6| Step: 6
Training loss: 0.9809305387786483
Validation loss: 2.4305966298685235

Epoch: 6| Step: 7
Training loss: 1.7597333797163672
Validation loss: 2.425374797878493

Epoch: 6| Step: 8
Training loss: 1.2040601291628203
Validation loss: 2.384022665196101

Epoch: 6| Step: 9
Training loss: 1.5736022196278434
Validation loss: 2.3954946234826227

Epoch: 6| Step: 10
Training loss: 1.7286983070175028
Validation loss: 2.3861918085807665

Epoch: 6| Step: 11
Training loss: 1.599077036010444
Validation loss: 2.434822486157449

Epoch: 6| Step: 12
Training loss: 1.7664072110132558
Validation loss: 2.361316545136204

Epoch: 6| Step: 13
Training loss: 1.397316083458236
Validation loss: 2.3942674692526875

Epoch: 293| Step: 0
Training loss: 1.4507186818638174
Validation loss: 2.4295828128394694

Epoch: 6| Step: 1
Training loss: 1.6368689274684365
Validation loss: 2.403682388804326

Epoch: 6| Step: 2
Training loss: 1.9099383083586339
Validation loss: 2.415248459666758

Epoch: 6| Step: 3
Training loss: 1.5895439446378368
Validation loss: 2.397709336367731

Epoch: 6| Step: 4
Training loss: 1.5562893843359051
Validation loss: 2.4547400304116977

Epoch: 6| Step: 5
Training loss: 1.4548317515046738
Validation loss: 2.450241918467217

Epoch: 6| Step: 6
Training loss: 1.7090823772123385
Validation loss: 2.430634159237134

Epoch: 6| Step: 7
Training loss: 2.1469726007256362
Validation loss: 2.430087587296497

Epoch: 6| Step: 8
Training loss: 1.3626595202514893
Validation loss: 2.455716496648925

Epoch: 6| Step: 9
Training loss: 1.5916228216766477
Validation loss: 2.459116805842991

Epoch: 6| Step: 10
Training loss: 1.7126134737385748
Validation loss: 2.4320689936020115

Epoch: 6| Step: 11
Training loss: 1.685820273353323
Validation loss: 2.3987561224988982

Epoch: 6| Step: 12
Training loss: 2.020619436787936
Validation loss: 2.419394307036783

Epoch: 6| Step: 13
Training loss: 1.0004992430920958
Validation loss: 2.437460308735179

Epoch: 294| Step: 0
Training loss: 1.4650260303254854
Validation loss: 2.435621395369504

Epoch: 6| Step: 1
Training loss: 1.416668256122969
Validation loss: 2.4456227109159894

Epoch: 6| Step: 2
Training loss: 1.6836921680829942
Validation loss: 2.4512397194888518

Epoch: 6| Step: 3
Training loss: 1.382677664352229
Validation loss: 2.424870722844861

Epoch: 6| Step: 4
Training loss: 2.144746029630597
Validation loss: 2.439504486008063

Epoch: 6| Step: 5
Training loss: 1.6044600907851723
Validation loss: 2.3678479809205113

Epoch: 6| Step: 6
Training loss: 1.179051057025495
Validation loss: 2.414207965182228

Epoch: 6| Step: 7
Training loss: 1.5864881489741192
Validation loss: 2.4030249122758476

Epoch: 6| Step: 8
Training loss: 1.5249794223835407
Validation loss: 2.3777332375778695

Epoch: 6| Step: 9
Training loss: 1.2614787437411081
Validation loss: 2.40072236008741

Epoch: 6| Step: 10
Training loss: 2.0572336180662023
Validation loss: 2.4686058623341447

Epoch: 6| Step: 11
Training loss: 1.6413625603316953
Validation loss: 2.4382622302429224

Epoch: 6| Step: 12
Training loss: 2.204466174808596
Validation loss: 2.4547415541374202

Epoch: 6| Step: 13
Training loss: 2.0634390109500207
Validation loss: 2.4262945956900546

Epoch: 295| Step: 0
Training loss: 1.991172921125109
Validation loss: 2.4479272643632037

Epoch: 6| Step: 1
Training loss: 1.1899288835833173
Validation loss: 2.4369818265764462

Epoch: 6| Step: 2
Training loss: 1.766397087954111
Validation loss: 2.348450151555314

Epoch: 6| Step: 3
Training loss: 1.654203121766899
Validation loss: 2.42522451733413

Epoch: 6| Step: 4
Training loss: 1.201851306826557
Validation loss: 2.3276862505780773

Epoch: 6| Step: 5
Training loss: 1.9492687761694814
Validation loss: 2.389858296896456

Epoch: 6| Step: 6
Training loss: 1.2548173108056884
Validation loss: 2.4054978357307975

Epoch: 6| Step: 7
Training loss: 1.3513690611606735
Validation loss: 2.3673027230108024

Epoch: 6| Step: 8
Training loss: 1.8320171298721246
Validation loss: 2.4775323283192225

Epoch: 6| Step: 9
Training loss: 1.5810748941922144
Validation loss: 2.4101213864955278

Epoch: 6| Step: 10
Training loss: 1.6320657437022437
Validation loss: 2.4500902208680797

Epoch: 6| Step: 11
Training loss: 1.7759880512754909
Validation loss: 2.3981805783832377

Epoch: 6| Step: 12
Training loss: 2.3988286298991386
Validation loss: 2.395685897791988

Epoch: 6| Step: 13
Training loss: 1.6507482739326433
Validation loss: 2.428466561858188

Epoch: 296| Step: 0
Training loss: 1.721134820102634
Validation loss: 2.4303561294551432

Epoch: 6| Step: 1
Training loss: 1.4609960860474764
Validation loss: 2.4621964731437607

Epoch: 6| Step: 2
Training loss: 1.9151792421444567
Validation loss: 2.4810731781366626

Epoch: 6| Step: 3
Training loss: 1.337355324237922
Validation loss: 2.4014265087318507

Epoch: 6| Step: 4
Training loss: 2.3462474486835574
Validation loss: 2.467816229341375

Epoch: 6| Step: 5
Training loss: 1.7829753483743869
Validation loss: 2.483956943968885

Epoch: 6| Step: 6
Training loss: 1.4461886662803658
Validation loss: 2.4488107420882836

Epoch: 6| Step: 7
Training loss: 1.5139500909891255
Validation loss: 2.405783999274126

Epoch: 6| Step: 8
Training loss: 1.4361715397930102
Validation loss: 2.406766567815

Epoch: 6| Step: 9
Training loss: 1.443759393042192
Validation loss: 2.455859886045458

Epoch: 6| Step: 10
Training loss: 1.6886654114450599
Validation loss: 2.4417264606456865

Epoch: 6| Step: 11
Training loss: 1.4723238380119612
Validation loss: 2.4222536424182826

Epoch: 6| Step: 12
Training loss: 1.9009132097991652
Validation loss: 2.4354243626747465

Epoch: 6| Step: 13
Training loss: 1.4444533810379847
Validation loss: 2.4104366437550864

Epoch: 297| Step: 0
Training loss: 1.737397318488566
Validation loss: 2.4494236552608504

Epoch: 6| Step: 1
Training loss: 1.8115627891194164
Validation loss: 2.399695625432491

Epoch: 6| Step: 2
Training loss: 1.2309941214724014
Validation loss: 2.391129317933213

Epoch: 6| Step: 3
Training loss: 1.0346782804428054
Validation loss: 2.3932843238389054

Epoch: 6| Step: 4
Training loss: 1.642858964314843
Validation loss: 2.4773230246216555

Epoch: 6| Step: 5
Training loss: 2.0058295406511197
Validation loss: 2.456152237432311

Epoch: 6| Step: 6
Training loss: 1.5112526345052544
Validation loss: 2.433754670006939

Epoch: 6| Step: 7
Training loss: 1.8965902878389225
Validation loss: 2.4361273563622077

Epoch: 6| Step: 8
Training loss: 1.5255907540421743
Validation loss: 2.41152833939617

Epoch: 6| Step: 9
Training loss: 1.3672587784851358
Validation loss: 2.4043417370180475

Epoch: 6| Step: 10
Training loss: 1.3901476094201517
Validation loss: 2.372334159093629

Epoch: 6| Step: 11
Training loss: 2.56464314973324
Validation loss: 2.3511869685118256

Epoch: 6| Step: 12
Training loss: 1.6942068968782802
Validation loss: 2.4738458927597384

Epoch: 6| Step: 13
Training loss: 1.6262025051819675
Validation loss: 2.3355935178512097

Epoch: 298| Step: 0
Training loss: 2.3791883580098077
Validation loss: 2.4145548047346868

Epoch: 6| Step: 1
Training loss: 1.5442406928566432
Validation loss: 2.4461080281976706

Epoch: 6| Step: 2
Training loss: 1.1977633613123038
Validation loss: 2.455892912325792

Epoch: 6| Step: 3
Training loss: 1.6762163357693203
Validation loss: 2.4135551361514405

Epoch: 6| Step: 4
Training loss: 2.0534608609779634
Validation loss: 2.432261761631281

Epoch: 6| Step: 5
Training loss: 1.4596684293617976
Validation loss: 2.4488217051178798

Epoch: 6| Step: 6
Training loss: 1.7844506670245701
Validation loss: 2.391992234700293

Epoch: 6| Step: 7
Training loss: 1.1610140727732068
Validation loss: 2.4617977505434867

Epoch: 6| Step: 8
Training loss: 1.2206959472445222
Validation loss: 2.4423031933518087

Epoch: 6| Step: 9
Training loss: 2.103684952490153
Validation loss: 2.5019701321782004

Epoch: 6| Step: 10
Training loss: 1.8575751946325052
Validation loss: 2.4611932280804685

Epoch: 6| Step: 11
Training loss: 1.7593260627838234
Validation loss: 2.460196758826639

Epoch: 6| Step: 12
Training loss: 1.3295559523315479
Validation loss: 2.441755416479604

Epoch: 6| Step: 13
Training loss: 1.3276267070610235
Validation loss: 2.3849860912968346

Epoch: 299| Step: 0
Training loss: 1.2061465579729511
Validation loss: 2.415357922402567

Epoch: 6| Step: 1
Training loss: 1.4214835833374067
Validation loss: 2.4359093885654515

Epoch: 6| Step: 2
Training loss: 0.9145123931437124
Validation loss: 2.412249942274224

Epoch: 6| Step: 3
Training loss: 1.7875247660168334
Validation loss: 2.437431091520941

Epoch: 6| Step: 4
Training loss: 1.7001857067101922
Validation loss: 2.434714490818884

Epoch: 6| Step: 5
Training loss: 0.9472920207642452
Validation loss: 2.4457279583511427

Epoch: 6| Step: 6
Training loss: 1.136858115550568
Validation loss: 2.467843171240921

Epoch: 6| Step: 7
Training loss: 1.6447323927568185
Validation loss: 2.4601331504138217

Epoch: 6| Step: 8
Training loss: 1.6861571160956241
Validation loss: 2.380507915728491

Epoch: 6| Step: 9
Training loss: 1.5494478965189826
Validation loss: 2.4618959903230673

Epoch: 6| Step: 10
Training loss: 2.158309616292406
Validation loss: 2.441515391545663

Epoch: 6| Step: 11
Training loss: 1.9798553540155646
Validation loss: 2.4217768707137113

Epoch: 6| Step: 12
Training loss: 1.3211616178345282
Validation loss: 2.39391159805463

Epoch: 6| Step: 13
Training loss: 3.0733143349789187
Validation loss: 2.4154215026380927

Epoch: 300| Step: 0
Training loss: 1.5406371450815977
Validation loss: 2.4091044556289587

Epoch: 6| Step: 1
Training loss: 1.5200840746064246
Validation loss: 2.418140289526571

Epoch: 6| Step: 2
Training loss: 1.2747601620107678
Validation loss: 2.4910410696516414

Epoch: 6| Step: 3
Training loss: 2.554853054830141
Validation loss: 2.3857680779849977

Epoch: 6| Step: 4
Training loss: 1.4756201103287776
Validation loss: 2.4123970379993835

Epoch: 6| Step: 5
Training loss: 1.5552794896493918
Validation loss: 2.4139432281946283

Epoch: 6| Step: 6
Training loss: 1.341124431352924
Validation loss: 2.415983392730226

Epoch: 6| Step: 7
Training loss: 1.7395298962942023
Validation loss: 2.4672499419648735

Epoch: 6| Step: 8
Training loss: 1.5666073030357828
Validation loss: 2.4448909459715926

Epoch: 6| Step: 9
Training loss: 0.9950009803192064
Validation loss: 2.4044620107367414

Epoch: 6| Step: 10
Training loss: 1.2113824334590124
Validation loss: 2.4049610190193387

Epoch: 6| Step: 11
Training loss: 1.5774757636093115
Validation loss: 2.3941858527610904

Epoch: 6| Step: 12
Training loss: 2.097363442669041
Validation loss: 2.4241385074464583

Epoch: 6| Step: 13
Training loss: 2.364487924765594
Validation loss: 2.452073532816614

Epoch: 301| Step: 0
Training loss: 1.6353197332273626
Validation loss: 2.470325746436073

Epoch: 6| Step: 1
Training loss: 1.6112631674880316
Validation loss: 2.424863513598069

Epoch: 6| Step: 2
Training loss: 1.3453430668529485
Validation loss: 2.466125293456482

Epoch: 6| Step: 3
Training loss: 1.18609727027038
Validation loss: 2.4101789520652255

Epoch: 6| Step: 4
Training loss: 1.2644697026205154
Validation loss: 2.373266465005636

Epoch: 6| Step: 5
Training loss: 1.7482867028436628
Validation loss: 2.3924599595195972

Epoch: 6| Step: 6
Training loss: 2.6670417124543966
Validation loss: 2.40336864241317

Epoch: 6| Step: 7
Training loss: 1.7406797171027641
Validation loss: 2.370612953846478

Epoch: 6| Step: 8
Training loss: 1.8497548997744273
Validation loss: 2.426663469417043

Epoch: 6| Step: 9
Training loss: 1.3594479596081686
Validation loss: 2.398765566379278

Epoch: 6| Step: 10
Training loss: 1.3750322945010112
Validation loss: 2.4586516776079224

Epoch: 6| Step: 11
Training loss: 1.1085448046599644
Validation loss: 2.4344861550878556

Epoch: 6| Step: 12
Training loss: 1.6877699741994838
Validation loss: 2.381084575876293

Epoch: 6| Step: 13
Training loss: 1.458851186451245
Validation loss: 2.4751769077107064

Epoch: 302| Step: 0
Training loss: 1.5138922155656729
Validation loss: 2.412239530931998

Epoch: 6| Step: 1
Training loss: 1.8192190397898453
Validation loss: 2.413903372617712

Epoch: 6| Step: 2
Training loss: 1.6567134568625361
Validation loss: 2.416591223733282

Epoch: 6| Step: 3
Training loss: 1.4457076898485755
Validation loss: 2.4245012559731824

Epoch: 6| Step: 4
Training loss: 1.5038662199167239
Validation loss: 2.385372520052957

Epoch: 6| Step: 5
Training loss: 1.344154740525227
Validation loss: 2.379757763101347

Epoch: 6| Step: 6
Training loss: 1.4861049008264444
Validation loss: 2.4614151404696174

Epoch: 6| Step: 7
Training loss: 1.2466647953301595
Validation loss: 2.347693403914154

Epoch: 6| Step: 8
Training loss: 1.4953689612368959
Validation loss: 2.395009565759673

Epoch: 6| Step: 9
Training loss: 1.8917603039637971
Validation loss: 2.4035173402968804

Epoch: 6| Step: 10
Training loss: 2.1698218871118318
Validation loss: 2.375419376200499

Epoch: 6| Step: 11
Training loss: 2.2708101067244706
Validation loss: 2.4491594569110204

Epoch: 6| Step: 12
Training loss: 1.1196733574875068
Validation loss: 2.4989057514937913

Epoch: 6| Step: 13
Training loss: 1.3999803865285005
Validation loss: 2.424414333878023

Epoch: 303| Step: 0
Training loss: 1.3273070565507383
Validation loss: 2.427036493208451

Epoch: 6| Step: 1
Training loss: 1.4722234358072777
Validation loss: 2.38966638662997

Epoch: 6| Step: 2
Training loss: 2.2809327832544417
Validation loss: 2.3567395522908927

Epoch: 6| Step: 3
Training loss: 1.9964267281285664
Validation loss: 2.4303184006444436

Epoch: 6| Step: 4
Training loss: 1.494876774969067
Validation loss: 2.4129375158589195

Epoch: 6| Step: 5
Training loss: 1.5267577937607937
Validation loss: 2.376608998157131

Epoch: 6| Step: 6
Training loss: 1.7771449386573976
Validation loss: 2.425049722870259

Epoch: 6| Step: 7
Training loss: 1.3846305490747453
Validation loss: 2.400863230470136

Epoch: 6| Step: 8
Training loss: 1.6478480148322454
Validation loss: 2.412083482414439

Epoch: 6| Step: 9
Training loss: 1.4718959474794062
Validation loss: 2.345229699431979

Epoch: 6| Step: 10
Training loss: 1.930642328057986
Validation loss: 2.3733573656097104

Epoch: 6| Step: 11
Training loss: 1.217621451944943
Validation loss: 2.3784984691267392

Epoch: 6| Step: 12
Training loss: 1.6216564994145666
Validation loss: 2.4229237710030724

Epoch: 6| Step: 13
Training loss: 2.0544308114079444
Validation loss: 2.3629389890051447

Epoch: 304| Step: 0
Training loss: 1.1705636889384299
Validation loss: 2.3834302112651167

Epoch: 6| Step: 1
Training loss: 1.9234881570251647
Validation loss: 2.424079954586872

Epoch: 6| Step: 2
Training loss: 1.4854255572566142
Validation loss: 2.3324714924338448

Epoch: 6| Step: 3
Training loss: 1.5518516862633642
Validation loss: 2.3972906804872074

Epoch: 6| Step: 4
Training loss: 1.6609981780573289
Validation loss: 2.3686045896712624

Epoch: 6| Step: 5
Training loss: 1.1598034460338558
Validation loss: 2.340641286061587

Epoch: 6| Step: 6
Training loss: 1.6136534033008751
Validation loss: 2.4470772561842056

Epoch: 6| Step: 7
Training loss: 1.1798192133857242
Validation loss: 2.427821027229507

Epoch: 6| Step: 8
Training loss: 1.6052439734157615
Validation loss: 2.4239735139092695

Epoch: 6| Step: 9
Training loss: 1.453628698849628
Validation loss: 2.4656164818723987

Epoch: 6| Step: 10
Training loss: 1.4457883309314907
Validation loss: 2.3973913540328606

Epoch: 6| Step: 11
Training loss: 2.3069677419734553
Validation loss: 2.4103642451699883

Epoch: 6| Step: 12
Training loss: 1.883762547299947
Validation loss: 2.3413897677935362

Epoch: 6| Step: 13
Training loss: 2.05295248714863
Validation loss: 2.377947766052375

Epoch: 305| Step: 0
Training loss: 1.4872371184842348
Validation loss: 2.4058319120651794

Epoch: 6| Step: 1
Training loss: 1.86103093115321
Validation loss: 2.362099654499901

Epoch: 6| Step: 2
Training loss: 1.7701193398583888
Validation loss: 2.355106483784719

Epoch: 6| Step: 3
Training loss: 1.7923101408152387
Validation loss: 2.382540239460579

Epoch: 6| Step: 4
Training loss: 2.260764228598009
Validation loss: 2.411624009125144

Epoch: 6| Step: 5
Training loss: 1.1987113749115785
Validation loss: 2.3882595807155544

Epoch: 6| Step: 6
Training loss: 1.1860321409235033
Validation loss: 2.445766785900342

Epoch: 6| Step: 7
Training loss: 1.7660716344317227
Validation loss: 2.4088559294308656

Epoch: 6| Step: 8
Training loss: 1.5618725852138602
Validation loss: 2.4106129359734654

Epoch: 6| Step: 9
Training loss: 1.7171735990341719
Validation loss: 2.3940762208256823

Epoch: 6| Step: 10
Training loss: 2.1883935465764073
Validation loss: 2.3455611419556157

Epoch: 6| Step: 11
Training loss: 1.2081398425347427
Validation loss: 2.444962873969467

Epoch: 6| Step: 12
Training loss: 1.3319254634610993
Validation loss: 2.4062666725291715

Epoch: 6| Step: 13
Training loss: 1.3644279313839907
Validation loss: 2.424138859609615

Epoch: 306| Step: 0
Training loss: 1.2688995198058535
Validation loss: 2.3697461725731936

Epoch: 6| Step: 1
Training loss: 1.2157505980577827
Validation loss: 2.457536451085476

Epoch: 6| Step: 2
Training loss: 1.6998529763317176
Validation loss: 2.4880570208765547

Epoch: 6| Step: 3
Training loss: 0.9313355912167762
Validation loss: 2.449478669709976

Epoch: 6| Step: 4
Training loss: 1.5898915876460034
Validation loss: 2.37325927507641

Epoch: 6| Step: 5
Training loss: 2.2712194365322422
Validation loss: 2.378761654455185

Epoch: 6| Step: 6
Training loss: 1.5674036517792997
Validation loss: 2.4496238056789394

Epoch: 6| Step: 7
Training loss: 1.3603424488208713
Validation loss: 2.4791852440727857

Epoch: 6| Step: 8
Training loss: 1.8257420977604668
Validation loss: 2.4656895101645415

Epoch: 6| Step: 9
Training loss: 1.6202853105814905
Validation loss: 2.4656654960240614

Epoch: 6| Step: 10
Training loss: 1.677590485021288
Validation loss: 2.414114452705296

Epoch: 6| Step: 11
Training loss: 1.787056477081702
Validation loss: 2.4382530266099507

Epoch: 6| Step: 12
Training loss: 1.8191404703478904
Validation loss: 2.446998750492525

Epoch: 6| Step: 13
Training loss: 1.4508864685588658
Validation loss: 2.3879980025645606

Epoch: 307| Step: 0
Training loss: 2.274077859469943
Validation loss: 2.327207722248105

Epoch: 6| Step: 1
Training loss: 1.585732808551099
Validation loss: 2.448521727326565

Epoch: 6| Step: 2
Training loss: 2.050486981305697
Validation loss: 2.356778072295524

Epoch: 6| Step: 3
Training loss: 1.496245692732116
Validation loss: 2.3862985797951826

Epoch: 6| Step: 4
Training loss: 1.2479456709779908
Validation loss: 2.4117707130549872

Epoch: 6| Step: 5
Training loss: 1.3291789192822825
Validation loss: 2.39822983124126

Epoch: 6| Step: 6
Training loss: 1.8057537809604616
Validation loss: 2.3899716063361023

Epoch: 6| Step: 7
Training loss: 1.651514589305885
Validation loss: 2.45351925559506

Epoch: 6| Step: 8
Training loss: 1.145606099340649
Validation loss: 2.3837328212953235

Epoch: 6| Step: 9
Training loss: 1.2425783130366193
Validation loss: 2.393009417303692

Epoch: 6| Step: 10
Training loss: 1.5050021055593368
Validation loss: 2.4918726883202242

Epoch: 6| Step: 11
Training loss: 1.2185183573933909
Validation loss: 2.4120567902922034

Epoch: 6| Step: 12
Training loss: 1.6204089821145855
Validation loss: 2.3971758294400174

Epoch: 6| Step: 13
Training loss: 1.8683343661144078
Validation loss: 2.3388385296970227

Epoch: 308| Step: 0
Training loss: 1.3688956353035422
Validation loss: 2.4246602725275075

Epoch: 6| Step: 1
Training loss: 1.3907278644364331
Validation loss: 2.4310243287725326

Epoch: 6| Step: 2
Training loss: 1.2513427198508824
Validation loss: 2.4869091606283984

Epoch: 6| Step: 3
Training loss: 1.7644823140754857
Validation loss: 2.3995809562662256

Epoch: 6| Step: 4
Training loss: 1.6094915847771636
Validation loss: 2.513624049368834

Epoch: 6| Step: 5
Training loss: 1.3115372532779386
Validation loss: 2.420544557201679

Epoch: 6| Step: 6
Training loss: 1.0090589282367493
Validation loss: 2.448513020328709

Epoch: 6| Step: 7
Training loss: 2.0250204956524516
Validation loss: 2.455888439325332

Epoch: 6| Step: 8
Training loss: 2.619311845546454
Validation loss: 2.503279642076294

Epoch: 6| Step: 9
Training loss: 1.6076872781493048
Validation loss: 2.481013042640798

Epoch: 6| Step: 10
Training loss: 2.375106006063532
Validation loss: 2.468720191494191

Epoch: 6| Step: 11
Training loss: 1.5023064365206673
Validation loss: 2.4168786248370098

Epoch: 6| Step: 12
Training loss: 1.0796440590539496
Validation loss: 2.4173150838709185

Epoch: 6| Step: 13
Training loss: 1.4013051301726565
Validation loss: 2.4142661989213647

Epoch: 309| Step: 0
Training loss: 1.5134214132502792
Validation loss: 2.3919068632378107

Epoch: 6| Step: 1
Training loss: 1.1862651528133312
Validation loss: 2.386848897426456

Epoch: 6| Step: 2
Training loss: 1.2606091890870774
Validation loss: 2.3777124818519226

Epoch: 6| Step: 3
Training loss: 1.3905252142262383
Validation loss: 2.413347724049467

Epoch: 6| Step: 4
Training loss: 1.8960714784500086
Validation loss: 2.3793473429426446

Epoch: 6| Step: 5
Training loss: 1.5522151438749578
Validation loss: 2.3741492057412206

Epoch: 6| Step: 6
Training loss: 1.1857224260599009
Validation loss: 2.411366187041634

Epoch: 6| Step: 7
Training loss: 1.656447416811797
Validation loss: 2.3890790493606557

Epoch: 6| Step: 8
Training loss: 2.5629792114260126
Validation loss: 2.401363856662312

Epoch: 6| Step: 9
Training loss: 1.9063142859453466
Validation loss: 2.3887549293750405

Epoch: 6| Step: 10
Training loss: 1.7749719913045872
Validation loss: 2.3849050171325588

Epoch: 6| Step: 11
Training loss: 1.7737790757659884
Validation loss: 2.448424907872638

Epoch: 6| Step: 12
Training loss: 1.6272111667459948
Validation loss: 2.4521533700090474

Epoch: 6| Step: 13
Training loss: 1.2425193583248806
Validation loss: 2.4603355055554714

Epoch: 310| Step: 0
Training loss: 2.0037412222267212
Validation loss: 2.4305058743682437

Epoch: 6| Step: 1
Training loss: 1.5266594097570219
Validation loss: 2.478475346237918

Epoch: 6| Step: 2
Training loss: 1.3305061984657884
Validation loss: 2.4036277105755026

Epoch: 6| Step: 3
Training loss: 1.6215998950997739
Validation loss: 2.357691795927879

Epoch: 6| Step: 4
Training loss: 1.1878525561950415
Validation loss: 2.406320452873958

Epoch: 6| Step: 5
Training loss: 1.2012623326425693
Validation loss: 2.4184369875613156

Epoch: 6| Step: 6
Training loss: 1.6981905226830605
Validation loss: 2.405396223588665

Epoch: 6| Step: 7
Training loss: 1.6364954247531636
Validation loss: 2.439700517200643

Epoch: 6| Step: 8
Training loss: 1.728924615609886
Validation loss: 2.3628283011097926

Epoch: 6| Step: 9
Training loss: 1.8496157556441883
Validation loss: 2.432171314913454

Epoch: 6| Step: 10
Training loss: 1.5225801843283495
Validation loss: 2.295379369373127

Epoch: 6| Step: 11
Training loss: 1.2854811422952324
Validation loss: 2.356363816650089

Epoch: 6| Step: 12
Training loss: 2.2388082419806192
Validation loss: 2.3858241970698275

Epoch: 6| Step: 13
Training loss: 1.0611698575981154
Validation loss: 2.4513701456072217

Epoch: 311| Step: 0
Training loss: 1.4375529901440316
Validation loss: 2.419887109813457

Epoch: 6| Step: 1
Training loss: 2.254407803746532
Validation loss: 2.428004913796174

Epoch: 6| Step: 2
Training loss: 1.2122531757623884
Validation loss: 2.460862500307245

Epoch: 6| Step: 3
Training loss: 1.33504246404884
Validation loss: 2.495571096840805

Epoch: 6| Step: 4
Training loss: 2.036517312316961
Validation loss: 2.3989513931992255

Epoch: 6| Step: 5
Training loss: 1.388660629377154
Validation loss: 2.4312500898816345

Epoch: 6| Step: 6
Training loss: 1.5874320819173076
Validation loss: 2.4033324878725217

Epoch: 6| Step: 7
Training loss: 1.8285324425138882
Validation loss: 2.3787053321055023

Epoch: 6| Step: 8
Training loss: 1.1734300595389213
Validation loss: 2.4195278770339588

Epoch: 6| Step: 9
Training loss: 2.1030101682423488
Validation loss: 2.4067250754842453

Epoch: 6| Step: 10
Training loss: 1.6324497531793356
Validation loss: 2.48050826931582

Epoch: 6| Step: 11
Training loss: 1.2822204264300057
Validation loss: 2.4402716239461437

Epoch: 6| Step: 12
Training loss: 1.5376734007770556
Validation loss: 2.4629509750203518

Epoch: 6| Step: 13
Training loss: 1.6707786459150207
Validation loss: 2.433656937036915

Epoch: 312| Step: 0
Training loss: 1.3693090055051025
Validation loss: 2.4804782615649144

Epoch: 6| Step: 1
Training loss: 1.2215089625319822
Validation loss: 2.454463323266462

Epoch: 6| Step: 2
Training loss: 1.2804661655923621
Validation loss: 2.4026849570590483

Epoch: 6| Step: 3
Training loss: 1.4672995365091914
Validation loss: 2.445314443713881

Epoch: 6| Step: 4
Training loss: 1.2895164846288856
Validation loss: 2.4477309740196254

Epoch: 6| Step: 5
Training loss: 1.227521630696759
Validation loss: 2.4047238907110757

Epoch: 6| Step: 6
Training loss: 2.8522568784810187
Validation loss: 2.415007574078503

Epoch: 6| Step: 7
Training loss: 1.291228353313383
Validation loss: 2.4925525495777636

Epoch: 6| Step: 8
Training loss: 1.848320484730143
Validation loss: 2.466198818121288

Epoch: 6| Step: 9
Training loss: 1.4895794030339957
Validation loss: 2.4637822655451083

Epoch: 6| Step: 10
Training loss: 1.800067751986898
Validation loss: 2.3547631837536125

Epoch: 6| Step: 11
Training loss: 1.495382832275226
Validation loss: 2.4326508454831006

Epoch: 6| Step: 12
Training loss: 1.5046926052684273
Validation loss: 2.4069579156111574

Epoch: 6| Step: 13
Training loss: 1.370555456843839
Validation loss: 2.4177989181426356

Epoch: 313| Step: 0
Training loss: 1.449942107524759
Validation loss: 2.370841278216264

Epoch: 6| Step: 1
Training loss: 1.1686825819511288
Validation loss: 2.399101607630133

Epoch: 6| Step: 2
Training loss: 1.6894596871485634
Validation loss: 2.413581004451906

Epoch: 6| Step: 3
Training loss: 1.4188596170569656
Validation loss: 2.341033185656721

Epoch: 6| Step: 4
Training loss: 1.9003273932825775
Validation loss: 2.434614532437536

Epoch: 6| Step: 5
Training loss: 2.331041595716274
Validation loss: 2.429273548651401

Epoch: 6| Step: 6
Training loss: 1.0443034686207666
Validation loss: 2.4379750786118244

Epoch: 6| Step: 7
Training loss: 0.97820016492937
Validation loss: 2.410007035213634

Epoch: 6| Step: 8
Training loss: 1.976782383203992
Validation loss: 2.379597387807475

Epoch: 6| Step: 9
Training loss: 1.598805431630841
Validation loss: 2.3343514478718514

Epoch: 6| Step: 10
Training loss: 1.4196389190536949
Validation loss: 2.388124508758257

Epoch: 6| Step: 11
Training loss: 1.8523598414847966
Validation loss: 2.400297412637643

Epoch: 6| Step: 12
Training loss: 1.6030093472946556
Validation loss: 2.374597770122583

Epoch: 6| Step: 13
Training loss: 0.9370355409234838
Validation loss: 2.418880919249697

Epoch: 314| Step: 0
Training loss: 1.8195342008600348
Validation loss: 2.461281681294258

Epoch: 6| Step: 1
Training loss: 1.9033839458321238
Validation loss: 2.425518835256652

Epoch: 6| Step: 2
Training loss: 1.2997787323960517
Validation loss: 2.457687147179577

Epoch: 6| Step: 3
Training loss: 1.4112839350577802
Validation loss: 2.4037029378807024

Epoch: 6| Step: 4
Training loss: 1.2827316649008882
Validation loss: 2.3650378716026057

Epoch: 6| Step: 5
Training loss: 1.6662472276600169
Validation loss: 2.3582778413726313

Epoch: 6| Step: 6
Training loss: 1.1179663337558783
Validation loss: 2.4218197491099662

Epoch: 6| Step: 7
Training loss: 1.2527883900439378
Validation loss: 2.4323082095254196

Epoch: 6| Step: 8
Training loss: 1.291067887026051
Validation loss: 2.4432643403910577

Epoch: 6| Step: 9
Training loss: 1.3746035611245693
Validation loss: 2.517118951627929

Epoch: 6| Step: 10
Training loss: 1.5494815943936688
Validation loss: 2.333826051129532

Epoch: 6| Step: 11
Training loss: 2.553318788604877
Validation loss: 2.4374358897353847

Epoch: 6| Step: 12
Training loss: 1.1724564190799263
Validation loss: 2.4695659772364142

Epoch: 6| Step: 13
Training loss: 1.42486693446961
Validation loss: 2.36001782976475

Epoch: 315| Step: 0
Training loss: 1.5308491707724785
Validation loss: 2.3987676007122487

Epoch: 6| Step: 1
Training loss: 1.2536183439673907
Validation loss: 2.4425636096627867

Epoch: 6| Step: 2
Training loss: 1.2964189026136872
Validation loss: 2.414628532219004

Epoch: 6| Step: 3
Training loss: 1.7819651456393408
Validation loss: 2.4207897092616872

Epoch: 6| Step: 4
Training loss: 1.1255096764506547
Validation loss: 2.367275364605396

Epoch: 6| Step: 5
Training loss: 2.3932494673561484
Validation loss: 2.43310151914122

Epoch: 6| Step: 6
Training loss: 1.7574990226124287
Validation loss: 2.395298580789621

Epoch: 6| Step: 7
Training loss: 1.933723522416809
Validation loss: 2.449658464375486

Epoch: 6| Step: 8
Training loss: 1.2914191234429293
Validation loss: 2.4555816827071215

Epoch: 6| Step: 9
Training loss: 1.613665075571754
Validation loss: 2.348509912125848

Epoch: 6| Step: 10
Training loss: 1.7278600451695616
Validation loss: 2.4342708754040965

Epoch: 6| Step: 11
Training loss: 1.4289552241171655
Validation loss: 2.3729214064773942

Epoch: 6| Step: 12
Training loss: 1.3638875318176467
Validation loss: 2.412979073478742

Epoch: 6| Step: 13
Training loss: 1.2106956486527434
Validation loss: 2.416874328901875

Epoch: 316| Step: 0
Training loss: 1.6790666719232525
Validation loss: 2.3720306082577847

Epoch: 6| Step: 1
Training loss: 1.183282993929404
Validation loss: 2.441177181794007

Epoch: 6| Step: 2
Training loss: 1.8195382628709047
Validation loss: 2.346055662288203

Epoch: 6| Step: 3
Training loss: 1.252861371931888
Validation loss: 2.4087411498230784

Epoch: 6| Step: 4
Training loss: 1.8259285014967386
Validation loss: 2.3998353954237293

Epoch: 6| Step: 5
Training loss: 1.336844822140394
Validation loss: 2.4217589081598625

Epoch: 6| Step: 6
Training loss: 2.396289870398582
Validation loss: 2.3944750426945602

Epoch: 6| Step: 7
Training loss: 0.9967317221108806
Validation loss: 2.4095795077414546

Epoch: 6| Step: 8
Training loss: 1.3733608706191813
Validation loss: 2.4832791345295995

Epoch: 6| Step: 9
Training loss: 1.245227572466019
Validation loss: 2.4800085629021953

Epoch: 6| Step: 10
Training loss: 2.0000318286270446
Validation loss: 2.449873904519448

Epoch: 6| Step: 11
Training loss: 2.025517753061856
Validation loss: 2.4511968819509797

Epoch: 6| Step: 12
Training loss: 1.1459808543638155
Validation loss: 2.4814215877277115

Epoch: 6| Step: 13
Training loss: 1.5909408045988993
Validation loss: 2.3758983219257916

Epoch: 317| Step: 0
Training loss: 1.4424619866028323
Validation loss: 2.428938018167094

Epoch: 6| Step: 1
Training loss: 1.56905781738944
Validation loss: 2.51445251689242

Epoch: 6| Step: 2
Training loss: 1.5672028530353868
Validation loss: 2.3803285182598235

Epoch: 6| Step: 3
Training loss: 1.421273575908482
Validation loss: 2.436903141886014

Epoch: 6| Step: 4
Training loss: 2.2728141638011343
Validation loss: 2.4353276999237834

Epoch: 6| Step: 5
Training loss: 1.8525826907010143
Validation loss: 2.3403106360055297

Epoch: 6| Step: 6
Training loss: 1.247348834952897
Validation loss: 2.405699671381968

Epoch: 6| Step: 7
Training loss: 1.2671815225293233
Validation loss: 2.4510861382326214

Epoch: 6| Step: 8
Training loss: 1.1352198835627638
Validation loss: 2.4139839943060046

Epoch: 6| Step: 9
Training loss: 1.4286511943891316
Validation loss: 2.394202449221329

Epoch: 6| Step: 10
Training loss: 1.369308700802104
Validation loss: 2.424869268099031

Epoch: 6| Step: 11
Training loss: 1.8296332373256754
Validation loss: 2.4420884143363093

Epoch: 6| Step: 12
Training loss: 1.9064034572180977
Validation loss: 2.377596285039514

Epoch: 6| Step: 13
Training loss: 1.229424508847665
Validation loss: 2.349730748242939

Epoch: 318| Step: 0
Training loss: 1.7509666225578853
Validation loss: 2.4214537922135975

Epoch: 6| Step: 1
Training loss: 2.437857577187476
Validation loss: 2.411402219005478

Epoch: 6| Step: 2
Training loss: 1.052355526502116
Validation loss: 2.423512221183492

Epoch: 6| Step: 3
Training loss: 1.127138489497693
Validation loss: 2.3527533935091567

Epoch: 6| Step: 4
Training loss: 1.5148157535226392
Validation loss: 2.479890217459988

Epoch: 6| Step: 5
Training loss: 1.2730635579582499
Validation loss: 2.386077759339127

Epoch: 6| Step: 6
Training loss: 1.3020309997214101
Validation loss: 2.4276499077466536

Epoch: 6| Step: 7
Training loss: 1.2752118065623723
Validation loss: 2.3892021097469547

Epoch: 6| Step: 8
Training loss: 1.6581663165820446
Validation loss: 2.375947634763536

Epoch: 6| Step: 9
Training loss: 1.2439139981670018
Validation loss: 2.374163268123248

Epoch: 6| Step: 10
Training loss: 1.8575928425850596
Validation loss: 2.395028570267099

Epoch: 6| Step: 11
Training loss: 1.5254680696919816
Validation loss: 2.3784417201771673

Epoch: 6| Step: 12
Training loss: 1.5854145559663628
Validation loss: 2.4137629690751368

Epoch: 6| Step: 13
Training loss: 2.1058417221685213
Validation loss: 2.415640757154514

Epoch: 319| Step: 0
Training loss: 1.3847328257476252
Validation loss: 2.4217220749011363

Epoch: 6| Step: 1
Training loss: 1.4713788145808389
Validation loss: 2.436728734876351

Epoch: 6| Step: 2
Training loss: 1.5469915172736408
Validation loss: 2.518554228426374

Epoch: 6| Step: 3
Training loss: 1.149173111725775
Validation loss: 2.4311996516749543

Epoch: 6| Step: 4
Training loss: 1.4517684675421247
Validation loss: 2.384370249662577

Epoch: 6| Step: 5
Training loss: 1.7587166728404973
Validation loss: 2.429221072186006

Epoch: 6| Step: 6
Training loss: 1.41766917529416
Validation loss: 2.43267630838953

Epoch: 6| Step: 7
Training loss: 1.9050429227704178
Validation loss: 2.4563084472425634

Epoch: 6| Step: 8
Training loss: 2.3126351600532247
Validation loss: 2.418250541548991

Epoch: 6| Step: 9
Training loss: 1.3982820477740743
Validation loss: 2.4558665731775884

Epoch: 6| Step: 10
Training loss: 1.816872420018808
Validation loss: 2.4389133515476105

Epoch: 6| Step: 11
Training loss: 1.4120567807946358
Validation loss: 2.425574026724774

Epoch: 6| Step: 12
Training loss: 1.200619851398698
Validation loss: 2.457112891786101

Epoch: 6| Step: 13
Training loss: 1.0935213122390641
Validation loss: 2.4217967560269322

Epoch: 320| Step: 0
Training loss: 1.4153581447741472
Validation loss: 2.4498532739115433

Epoch: 6| Step: 1
Training loss: 1.7072382960687118
Validation loss: 2.3989297048390372

Epoch: 6| Step: 2
Training loss: 1.544743311771077
Validation loss: 2.327701822777161

Epoch: 6| Step: 3
Training loss: 1.4079313187835407
Validation loss: 2.358121108880991

Epoch: 6| Step: 4
Training loss: 1.2005484599191563
Validation loss: 2.390876714409021

Epoch: 6| Step: 5
Training loss: 1.6213447836034491
Validation loss: 2.428576822228361

Epoch: 6| Step: 6
Training loss: 1.8252934102433458
Validation loss: 2.375995574121575

Epoch: 6| Step: 7
Training loss: 1.7864925132870044
Validation loss: 2.432225468458403

Epoch: 6| Step: 8
Training loss: 2.4088444780034606
Validation loss: 2.351748107752072

Epoch: 6| Step: 9
Training loss: 1.3155258811889883
Validation loss: 2.456214301922771

Epoch: 6| Step: 10
Training loss: 1.5484845043635103
Validation loss: 2.3605145801299012

Epoch: 6| Step: 11
Training loss: 1.2903454032060138
Validation loss: 2.410574289833961

Epoch: 6| Step: 12
Training loss: 1.311265001093002
Validation loss: 2.401039216603515

Epoch: 6| Step: 13
Training loss: 1.2031582914428085
Validation loss: 2.4434508397234413

Epoch: 321| Step: 0
Training loss: 1.3719199536025097
Validation loss: 2.4506391475107905

Epoch: 6| Step: 1
Training loss: 1.7761792738361677
Validation loss: 2.4264502944625557

Epoch: 6| Step: 2
Training loss: 1.4020674494409968
Validation loss: 2.4088403374902163

Epoch: 6| Step: 3
Training loss: 1.0521381225420217
Validation loss: 2.4442439206401345

Epoch: 6| Step: 4
Training loss: 1.158422388225703
Validation loss: 2.435951028923217

Epoch: 6| Step: 5
Training loss: 1.7539433600698888
Validation loss: 2.4314621860994836

Epoch: 6| Step: 6
Training loss: 1.0417426399500094
Validation loss: 2.4034674795423165

Epoch: 6| Step: 7
Training loss: 1.356104149425272
Validation loss: 2.43011204268513

Epoch: 6| Step: 8
Training loss: 1.4771297919208644
Validation loss: 2.402702217693021

Epoch: 6| Step: 9
Training loss: 2.169161961369999
Validation loss: 2.413099085614444

Epoch: 6| Step: 10
Training loss: 1.3196712042497745
Validation loss: 2.4234709044826306

Epoch: 6| Step: 11
Training loss: 1.650772177025432
Validation loss: 2.4002402402417573

Epoch: 6| Step: 12
Training loss: 1.8207102328777396
Validation loss: 2.4438683595852257

Epoch: 6| Step: 13
Training loss: 1.9159964619804957
Validation loss: 2.4428055938018716

Epoch: 322| Step: 0
Training loss: 1.6928415881793777
Validation loss: 2.427649429370707

Epoch: 6| Step: 1
Training loss: 1.1502367315026611
Validation loss: 2.4178354336984453

Epoch: 6| Step: 2
Training loss: 0.9696668777461219
Validation loss: 2.398613067718056

Epoch: 6| Step: 3
Training loss: 1.645604017031917
Validation loss: 2.4154290696185394

Epoch: 6| Step: 4
Training loss: 1.2378429034090725
Validation loss: 2.3210055060522836

Epoch: 6| Step: 5
Training loss: 1.8566921336940299
Validation loss: 2.4338686218026973

Epoch: 6| Step: 6
Training loss: 1.5105210717608817
Validation loss: 2.4097875569469815

Epoch: 6| Step: 7
Training loss: 2.06885543508465
Validation loss: 2.4189510673023182

Epoch: 6| Step: 8
Training loss: 1.5049865805702498
Validation loss: 2.473130099262529

Epoch: 6| Step: 9
Training loss: 1.7607308131912147
Validation loss: 2.5432644654425633

Epoch: 6| Step: 10
Training loss: 1.4604442396114137
Validation loss: 2.378173963277625

Epoch: 6| Step: 11
Training loss: 1.845681940189268
Validation loss: 2.452788531129019

Epoch: 6| Step: 12
Training loss: 0.9489191783499822
Validation loss: 2.3484372206064785

Epoch: 6| Step: 13
Training loss: 1.6632818262359925
Validation loss: 2.4382258413345723

Epoch: 323| Step: 0
Training loss: 0.9816779776592406
Validation loss: 2.465667966954902

Epoch: 6| Step: 1
Training loss: 1.8560260136647515
Validation loss: 2.421176376960314

Epoch: 6| Step: 2
Training loss: 1.4283129645593762
Validation loss: 2.436633003972747

Epoch: 6| Step: 3
Training loss: 1.8064570483167681
Validation loss: 2.453266945165169

Epoch: 6| Step: 4
Training loss: 2.350492620577058
Validation loss: 2.3728406720576745

Epoch: 6| Step: 5
Training loss: 0.9384066012818624
Validation loss: 2.3949234385394518

Epoch: 6| Step: 6
Training loss: 1.162322106645119
Validation loss: 2.3994887477415183

Epoch: 6| Step: 7
Training loss: 1.4269284166587721
Validation loss: 2.4324590136137654

Epoch: 6| Step: 8
Training loss: 1.7912212158147818
Validation loss: 2.4833253343212034

Epoch: 6| Step: 9
Training loss: 1.4723414076938597
Validation loss: 2.3852531705579714

Epoch: 6| Step: 10
Training loss: 1.4290051108523163
Validation loss: 2.4099749012939067

Epoch: 6| Step: 11
Training loss: 1.7455883958955307
Validation loss: 2.396816188669754

Epoch: 6| Step: 12
Training loss: 1.3210321756064183
Validation loss: 2.4060437258269793

Epoch: 6| Step: 13
Training loss: 1.5788069658429706
Validation loss: 2.3915847759441307

Epoch: 324| Step: 0
Training loss: 1.5544506256762887
Validation loss: 2.4234515925074667

Epoch: 6| Step: 1
Training loss: 1.2963740288926942
Validation loss: 2.361800106489213

Epoch: 6| Step: 2
Training loss: 1.7180217934226478
Validation loss: 2.466872465897646

Epoch: 6| Step: 3
Training loss: 2.1191380373328097
Validation loss: 2.4444186262716894

Epoch: 6| Step: 4
Training loss: 1.6608407797154416
Validation loss: 2.4072055205948275

Epoch: 6| Step: 5
Training loss: 1.1512207248705701
Validation loss: 2.4592889767516763

Epoch: 6| Step: 6
Training loss: 1.2775014610804734
Validation loss: 2.4069736321126665

Epoch: 6| Step: 7
Training loss: 1.15534112623976
Validation loss: 2.409354623536791

Epoch: 6| Step: 8
Training loss: 1.572431662185951
Validation loss: 2.4263869160550424

Epoch: 6| Step: 9
Training loss: 1.3418535556510005
Validation loss: 2.3994752910648094

Epoch: 6| Step: 10
Training loss: 1.5909190747331725
Validation loss: 2.4757521770255186

Epoch: 6| Step: 11
Training loss: 1.444382982087539
Validation loss: 2.403380853808009

Epoch: 6| Step: 12
Training loss: 2.3519432798799507
Validation loss: 2.3998056368077396

Epoch: 6| Step: 13
Training loss: 1.4730330979201924
Validation loss: 2.446003520825029

Epoch: 325| Step: 0
Training loss: 1.6547803296209853
Validation loss: 2.319727201540558

Epoch: 6| Step: 1
Training loss: 1.1613451071433254
Validation loss: 2.3667221020669813

Epoch: 6| Step: 2
Training loss: 1.665833654449773
Validation loss: 2.3400417725281035

Epoch: 6| Step: 3
Training loss: 1.2681535023305845
Validation loss: 2.4612735095046787

Epoch: 6| Step: 4
Training loss: 1.5016370423358911
Validation loss: 2.3921577922500608

Epoch: 6| Step: 5
Training loss: 1.3831736206251897
Validation loss: 2.4228119063726794

Epoch: 6| Step: 6
Training loss: 1.1685527247432017
Validation loss: 2.4052180003046706

Epoch: 6| Step: 7
Training loss: 2.4706915451803733
Validation loss: 2.422552286502354

Epoch: 6| Step: 8
Training loss: 0.7787160597212476
Validation loss: 2.4944639005822715

Epoch: 6| Step: 9
Training loss: 1.698528842522798
Validation loss: 2.415942301692719

Epoch: 6| Step: 10
Training loss: 1.4971086132627103
Validation loss: 2.3853842029188614

Epoch: 6| Step: 11
Training loss: 1.1342118663502756
Validation loss: 2.380762472240616

Epoch: 6| Step: 12
Training loss: 1.609212922758802
Validation loss: 2.4311457652672557

Epoch: 6| Step: 13
Training loss: 2.0906622593956508
Validation loss: 2.352733984864174

Epoch: 326| Step: 0
Training loss: 2.5599033876904578
Validation loss: 2.4645520145803976

Epoch: 6| Step: 1
Training loss: 1.2622601555098232
Validation loss: 2.4517629675106325

Epoch: 6| Step: 2
Training loss: 1.5232374793570655
Validation loss: 2.366869560405782

Epoch: 6| Step: 3
Training loss: 1.536270009369125
Validation loss: 2.4335680975910314

Epoch: 6| Step: 4
Training loss: 1.4563096946956797
Validation loss: 2.419183602853258

Epoch: 6| Step: 5
Training loss: 1.7615304918208206
Validation loss: 2.3900830762318144

Epoch: 6| Step: 6
Training loss: 1.186516706031574
Validation loss: 2.4237389332229156

Epoch: 6| Step: 7
Training loss: 1.4270146300027702
Validation loss: 2.4178032103143305

Epoch: 6| Step: 8
Training loss: 0.9284717721176357
Validation loss: 2.3358394404537415

Epoch: 6| Step: 9
Training loss: 1.4408897570359616
Validation loss: 2.379218837832014

Epoch: 6| Step: 10
Training loss: 1.365640211566207
Validation loss: 2.4025379048093782

Epoch: 6| Step: 11
Training loss: 1.8189341029163077
Validation loss: 2.3828794924851806

Epoch: 6| Step: 12
Training loss: 1.801171250220153
Validation loss: 2.4257916132618864

Epoch: 6| Step: 13
Training loss: 1.117642396734098
Validation loss: 2.4296995105360164

Epoch: 327| Step: 0
Training loss: 1.2771149876681758
Validation loss: 2.3720185478153604

Epoch: 6| Step: 1
Training loss: 1.3023898971793748
Validation loss: 2.4673492883801105

Epoch: 6| Step: 2
Training loss: 2.512124985373672
Validation loss: 2.4060757279197067

Epoch: 6| Step: 3
Training loss: 1.1885803728991937
Validation loss: 2.4355463097572634

Epoch: 6| Step: 4
Training loss: 1.768670485363828
Validation loss: 2.395165133467132

Epoch: 6| Step: 5
Training loss: 1.0490541694044444
Validation loss: 2.444732788106219

Epoch: 6| Step: 6
Training loss: 1.0749161554507796
Validation loss: 2.45392730177636

Epoch: 6| Step: 7
Training loss: 1.4462193299044266
Validation loss: 2.3818755687042477

Epoch: 6| Step: 8
Training loss: 1.3232735830713926
Validation loss: 2.481859425318857

Epoch: 6| Step: 9
Training loss: 1.5808471769706378
Validation loss: 2.4047405301118645

Epoch: 6| Step: 10
Training loss: 1.3659322153031528
Validation loss: 2.4227642129832794

Epoch: 6| Step: 11
Training loss: 1.7710024883784814
Validation loss: 2.423846345099423

Epoch: 6| Step: 12
Training loss: 1.7483572742918811
Validation loss: 2.377522293368792

Epoch: 6| Step: 13
Training loss: 1.1323858575794126
Validation loss: 2.482214880857

Epoch: 328| Step: 0
Training loss: 1.8020500959149988
Validation loss: 2.426953738257423

Epoch: 6| Step: 1
Training loss: 1.63335391472805
Validation loss: 2.445107733563708

Epoch: 6| Step: 2
Training loss: 1.5831453144804726
Validation loss: 2.4286918508596735

Epoch: 6| Step: 3
Training loss: 1.2105107693797788
Validation loss: 2.3960924424870824

Epoch: 6| Step: 4
Training loss: 1.2586882012964473
Validation loss: 2.415642505061187

Epoch: 6| Step: 5
Training loss: 1.464617739725932
Validation loss: 2.4386915140202077

Epoch: 6| Step: 6
Training loss: 1.5496169939904392
Validation loss: 2.4219166794762046

Epoch: 6| Step: 7
Training loss: 1.018779024050044
Validation loss: 2.4515838892536217

Epoch: 6| Step: 8
Training loss: 1.3695268072740618
Validation loss: 2.353107756191286

Epoch: 6| Step: 9
Training loss: 2.2637368588669107
Validation loss: 2.4477662245567493

Epoch: 6| Step: 10
Training loss: 1.1304647913549113
Validation loss: 2.4557428833400037

Epoch: 6| Step: 11
Training loss: 1.5195186192789238
Validation loss: 2.460972051968784

Epoch: 6| Step: 12
Training loss: 1.8916843693558874
Validation loss: 2.3440578157380547

Epoch: 6| Step: 13
Training loss: 1.7300385571190755
Validation loss: 2.4424058458527362

Epoch: 329| Step: 0
Training loss: 1.1974012786533454
Validation loss: 2.3909905545783943

Epoch: 6| Step: 1
Training loss: 1.2433115833432309
Validation loss: 2.404869340849658

Epoch: 6| Step: 2
Training loss: 1.1682161305222183
Validation loss: 2.3582701149269405

Epoch: 6| Step: 3
Training loss: 1.3840613464088827
Validation loss: 2.428061905446303

Epoch: 6| Step: 4
Training loss: 2.107341549167147
Validation loss: 2.4087148304256476

Epoch: 6| Step: 5
Training loss: 1.4867701430866922
Validation loss: 2.4085385706439113

Epoch: 6| Step: 6
Training loss: 1.3221201062951773
Validation loss: 2.43198766115276

Epoch: 6| Step: 7
Training loss: 1.3711593047117847
Validation loss: 2.4212717544134286

Epoch: 6| Step: 8
Training loss: 1.2638194544843104
Validation loss: 2.423138711988341

Epoch: 6| Step: 9
Training loss: 1.8192814211169177
Validation loss: 2.4313316083299945

Epoch: 6| Step: 10
Training loss: 1.7172165011732956
Validation loss: 2.425201075558292

Epoch: 6| Step: 11
Training loss: 1.501529708329588
Validation loss: 2.4151933554568137

Epoch: 6| Step: 12
Training loss: 1.4065698048084745
Validation loss: 2.429351942794108

Epoch: 6| Step: 13
Training loss: 1.5545253956690541
Validation loss: 2.410734183563622

Epoch: 330| Step: 0
Training loss: 1.1119417397173446
Validation loss: 2.431706857403186

Epoch: 6| Step: 1
Training loss: 1.627770043630674
Validation loss: 2.466793167960677

Epoch: 6| Step: 2
Training loss: 1.1155729030551722
Validation loss: 2.38121219975679

Epoch: 6| Step: 3
Training loss: 1.0866105443312613
Validation loss: 2.3942750211779082

Epoch: 6| Step: 4
Training loss: 1.3947633608889045
Validation loss: 2.4234626728989763

Epoch: 6| Step: 5
Training loss: 1.6211158107497419
Validation loss: 2.3891158005317084

Epoch: 6| Step: 6
Training loss: 1.2074588647789877
Validation loss: 2.444521473096339

Epoch: 6| Step: 7
Training loss: 1.046487081594694
Validation loss: 2.4236842097998412

Epoch: 6| Step: 8
Training loss: 1.8337346923646864
Validation loss: 2.3881349796092737

Epoch: 6| Step: 9
Training loss: 2.428584004618035
Validation loss: 2.41126887295847

Epoch: 6| Step: 10
Training loss: 1.6661899202680444
Validation loss: 2.4252210089045545

Epoch: 6| Step: 11
Training loss: 1.4674900413318248
Validation loss: 2.4479635614229007

Epoch: 6| Step: 12
Training loss: 0.9740853898238303
Validation loss: 2.4039056403543486

Epoch: 6| Step: 13
Training loss: 1.7897794527970592
Validation loss: 2.4026567352766066

Epoch: 331| Step: 0
Training loss: 1.6529412958944851
Validation loss: 2.3604338471036557

Epoch: 6| Step: 1
Training loss: 2.1089630855044637
Validation loss: 2.3810627705316896

Epoch: 6| Step: 2
Training loss: 1.4203516586495457
Validation loss: 2.396614660664968

Epoch: 6| Step: 3
Training loss: 1.8188529650719503
Validation loss: 2.4685198841608957

Epoch: 6| Step: 4
Training loss: 1.5519003877625643
Validation loss: 2.2787137791689096

Epoch: 6| Step: 5
Training loss: 1.1315345132396115
Validation loss: 2.3259032194972176

Epoch: 6| Step: 6
Training loss: 1.238341706060665
Validation loss: 2.4849060950036606

Epoch: 6| Step: 7
Training loss: 1.10412364851926
Validation loss: 2.364708684674437

Epoch: 6| Step: 8
Training loss: 1.7287768495230311
Validation loss: 2.3439871413057984

Epoch: 6| Step: 9
Training loss: 1.705132727169294
Validation loss: 2.3867328264015266

Epoch: 6| Step: 10
Training loss: 1.3653019573200154
Validation loss: 2.4535661599459657

Epoch: 6| Step: 11
Training loss: 1.038548277767238
Validation loss: 2.4039709354194514

Epoch: 6| Step: 12
Training loss: 1.1540236819463636
Validation loss: 2.405881029064842

Epoch: 6| Step: 13
Training loss: 2.13363642724962
Validation loss: 2.418968857291561

Epoch: 332| Step: 0
Training loss: 1.1579232352117252
Validation loss: 2.381697409845954

Epoch: 6| Step: 1
Training loss: 1.5120725390225136
Validation loss: 2.4103751123819452

Epoch: 6| Step: 2
Training loss: 0.9699259972609553
Validation loss: 2.431115357545622

Epoch: 6| Step: 3
Training loss: 1.0687481662667588
Validation loss: 2.3902259025437447

Epoch: 6| Step: 4
Training loss: 1.8090866438875068
Validation loss: 2.3935447716061664

Epoch: 6| Step: 5
Training loss: 1.6635715673821327
Validation loss: 2.440355692146778

Epoch: 6| Step: 6
Training loss: 1.2310328568040945
Validation loss: 2.4324672848394626

Epoch: 6| Step: 7
Training loss: 1.6458571066125283
Validation loss: 2.4027665830690412

Epoch: 6| Step: 8
Training loss: 1.3375987827507667
Validation loss: 2.483136146343869

Epoch: 6| Step: 9
Training loss: 1.114333234636548
Validation loss: 2.4806529131687585

Epoch: 6| Step: 10
Training loss: 1.6168846547089564
Validation loss: 2.435887641967176

Epoch: 6| Step: 11
Training loss: 1.824564474211199
Validation loss: 2.479748331319359

Epoch: 6| Step: 12
Training loss: 1.2810998689105466
Validation loss: 2.4565357246114132

Epoch: 6| Step: 13
Training loss: 2.9001181940130656
Validation loss: 2.42871696788449

Epoch: 333| Step: 0
Training loss: 1.8593479443032224
Validation loss: 2.3833616111185596

Epoch: 6| Step: 1
Training loss: 1.398760454617754
Validation loss: 2.3673191251237102

Epoch: 6| Step: 2
Training loss: 1.8249701641204465
Validation loss: 2.411251948484749

Epoch: 6| Step: 3
Training loss: 1.9644563873257859
Validation loss: 2.3498093276997145

Epoch: 6| Step: 4
Training loss: 1.497114107470554
Validation loss: 2.3997492784879566

Epoch: 6| Step: 5
Training loss: 0.864766909555013
Validation loss: 2.3644554953264585

Epoch: 6| Step: 6
Training loss: 1.3519586412548181
Validation loss: 2.3818463864853

Epoch: 6| Step: 7
Training loss: 1.3363598607634535
Validation loss: 2.4122556700077227

Epoch: 6| Step: 8
Training loss: 1.5474088113814706
Validation loss: 2.4288342972080805

Epoch: 6| Step: 9
Training loss: 1.427199570128885
Validation loss: 2.342298115689584

Epoch: 6| Step: 10
Training loss: 1.1111325593043855
Validation loss: 2.4559433674155224

Epoch: 6| Step: 11
Training loss: 1.3063849639527194
Validation loss: 2.4247133684178084

Epoch: 6| Step: 12
Training loss: 1.9968256793550332
Validation loss: 2.4619364960776946

Epoch: 6| Step: 13
Training loss: 1.7672349459673002
Validation loss: 2.451480897410807

Epoch: 334| Step: 0
Training loss: 1.2909108175652029
Validation loss: 2.4137915062819513

Epoch: 6| Step: 1
Training loss: 1.1978566140864968
Validation loss: 2.38918699419029

Epoch: 6| Step: 2
Training loss: 2.151871922003555
Validation loss: 2.395783327997724

Epoch: 6| Step: 3
Training loss: 1.2954645875149147
Validation loss: 2.4310446894426034

Epoch: 6| Step: 4
Training loss: 0.6895421864852254
Validation loss: 2.3628737855439574

Epoch: 6| Step: 5
Training loss: 1.4353398387854235
Validation loss: 2.4652734205188302

Epoch: 6| Step: 6
Training loss: 1.4605325555826367
Validation loss: 2.477348149449844

Epoch: 6| Step: 7
Training loss: 1.8027095111029117
Validation loss: 2.333170073887466

Epoch: 6| Step: 8
Training loss: 1.1311190344941628
Validation loss: 2.325365114206723

Epoch: 6| Step: 9
Training loss: 1.9868883451317811
Validation loss: 2.3941486986308536

Epoch: 6| Step: 10
Training loss: 1.4996571148931865
Validation loss: 2.442416134377318

Epoch: 6| Step: 11
Training loss: 1.3707591895756048
Validation loss: 2.4498223847059912

Epoch: 6| Step: 12
Training loss: 1.5419499764152031
Validation loss: 2.4104672527774085

Epoch: 6| Step: 13
Training loss: 1.6229083464592449
Validation loss: 2.394382096840999

Epoch: 335| Step: 0
Training loss: 1.7689655401777689
Validation loss: 2.4616859205596646

Epoch: 6| Step: 1
Training loss: 1.1004176582371439
Validation loss: 2.434523612914145

Epoch: 6| Step: 2
Training loss: 1.1265572260760959
Validation loss: 2.4163448436287958

Epoch: 6| Step: 3
Training loss: 1.496841443030126
Validation loss: 2.39763755721687

Epoch: 6| Step: 4
Training loss: 0.9303287250204658
Validation loss: 2.3968299298139395

Epoch: 6| Step: 5
Training loss: 1.2392837365387126
Validation loss: 2.3956832171720497

Epoch: 6| Step: 6
Training loss: 1.475367956010072
Validation loss: 2.4413703253615293

Epoch: 6| Step: 7
Training loss: 1.450863216223132
Validation loss: 2.4163928981871634

Epoch: 6| Step: 8
Training loss: 1.6477580184220528
Validation loss: 2.4541824399507846

Epoch: 6| Step: 9
Training loss: 1.397468401597707
Validation loss: 2.395833510246823

Epoch: 6| Step: 10
Training loss: 0.9714636174259434
Validation loss: 2.4145770396886777

Epoch: 6| Step: 11
Training loss: 1.6746805484240925
Validation loss: 2.3681041700229715

Epoch: 6| Step: 12
Training loss: 1.4654970873748772
Validation loss: 2.4328695678192713

Epoch: 6| Step: 13
Training loss: 2.761194160418336
Validation loss: 2.424780223781624

Epoch: 336| Step: 0
Training loss: 1.87178921765665
Validation loss: 2.3847571636019373

Epoch: 6| Step: 1
Training loss: 1.457802085389514
Validation loss: 2.438024602726222

Epoch: 6| Step: 2
Training loss: 2.26014995026856
Validation loss: 2.414757653145963

Epoch: 6| Step: 3
Training loss: 1.4641272661831042
Validation loss: 2.4218795675763247

Epoch: 6| Step: 4
Training loss: 1.5959320090972338
Validation loss: 2.4180062378719667

Epoch: 6| Step: 5
Training loss: 1.2867345886552695
Validation loss: 2.4007818189856645

Epoch: 6| Step: 6
Training loss: 1.1357225595157443
Validation loss: 2.406576321202292

Epoch: 6| Step: 7
Training loss: 1.4296111206330877
Validation loss: 2.4058801968525843

Epoch: 6| Step: 8
Training loss: 1.5423412737180633
Validation loss: 2.3770170772877317

Epoch: 6| Step: 9
Training loss: 0.9325797667660275
Validation loss: 2.3839673360372973

Epoch: 6| Step: 10
Training loss: 1.3671030944927598
Validation loss: 2.480180735811661

Epoch: 6| Step: 11
Training loss: 1.2494677841136612
Validation loss: 2.400055469214606

Epoch: 6| Step: 12
Training loss: 1.317151184305431
Validation loss: 2.3958738435064153

Epoch: 6| Step: 13
Training loss: 1.8717729773126928
Validation loss: 2.4193276792799767

Epoch: 337| Step: 0
Training loss: 1.7339336074165552
Validation loss: 2.419511535348698

Epoch: 6| Step: 1
Training loss: 1.8526480667308016
Validation loss: 2.3620486833921484

Epoch: 6| Step: 2
Training loss: 1.1120688813919977
Validation loss: 2.439414708758108

Epoch: 6| Step: 3
Training loss: 1.194733123985783
Validation loss: 2.4335507777692778

Epoch: 6| Step: 4
Training loss: 1.960481142233078
Validation loss: 2.3741787913931867

Epoch: 6| Step: 5
Training loss: 1.2008081893529823
Validation loss: 2.403266867709214

Epoch: 6| Step: 6
Training loss: 1.3611359426391536
Validation loss: 2.429039585348992

Epoch: 6| Step: 7
Training loss: 1.0923675519674267
Validation loss: 2.4048982937991346

Epoch: 6| Step: 8
Training loss: 2.022567974593939
Validation loss: 2.4239342632322196

Epoch: 6| Step: 9
Training loss: 1.2228021504183284
Validation loss: 2.3998385243460465

Epoch: 6| Step: 10
Training loss: 1.5647661179375065
Validation loss: 2.460327895903669

Epoch: 6| Step: 11
Training loss: 1.3041060745414867
Validation loss: 2.426946633436313

Epoch: 6| Step: 12
Training loss: 1.4132646870736458
Validation loss: 2.430349225507369

Epoch: 6| Step: 13
Training loss: 0.784906755728729
Validation loss: 2.3653587778118066

Epoch: 338| Step: 0
Training loss: 1.2146423761707583
Validation loss: 2.446778168862536

Epoch: 6| Step: 1
Training loss: 1.2724690879859364
Validation loss: 2.3857443602741712

Epoch: 6| Step: 2
Training loss: 1.403267983540696
Validation loss: 2.377048169497049

Epoch: 6| Step: 3
Training loss: 1.1729823157919754
Validation loss: 2.424910628635417

Epoch: 6| Step: 4
Training loss: 1.5922858300510303
Validation loss: 2.45528866196547

Epoch: 6| Step: 5
Training loss: 1.2487227590222525
Validation loss: 2.3595578566196638

Epoch: 6| Step: 6
Training loss: 1.2927538644219814
Validation loss: 2.422928212807496

Epoch: 6| Step: 7
Training loss: 2.503522394188705
Validation loss: 2.3094413648656467

Epoch: 6| Step: 8
Training loss: 1.2758707775465798
Validation loss: 2.430112869763833

Epoch: 6| Step: 9
Training loss: 0.842215201748559
Validation loss: 2.360089635052317

Epoch: 6| Step: 10
Training loss: 1.4350967220447322
Validation loss: 2.4199028843033044

Epoch: 6| Step: 11
Training loss: 1.8316297274131323
Validation loss: 2.3793919179323284

Epoch: 6| Step: 12
Training loss: 1.1878831145009305
Validation loss: 2.387138413988579

Epoch: 6| Step: 13
Training loss: 1.3910436535833883
Validation loss: 2.4070158987251413

Epoch: 339| Step: 0
Training loss: 1.415918386343393
Validation loss: 2.374655359086026

Epoch: 6| Step: 1
Training loss: 1.1264113474272959
Validation loss: 2.4041079050587815

Epoch: 6| Step: 2
Training loss: 2.355064344721719
Validation loss: 2.4035798818371723

Epoch: 6| Step: 3
Training loss: 1.1682304675973267
Validation loss: 2.4049228896741686

Epoch: 6| Step: 4
Training loss: 2.1758294639518905
Validation loss: 2.347932183277133

Epoch: 6| Step: 5
Training loss: 1.3848818796102134
Validation loss: 2.468507883357676

Epoch: 6| Step: 6
Training loss: 1.1864216576395539
Validation loss: 2.451236357063614

Epoch: 6| Step: 7
Training loss: 1.4739062116953112
Validation loss: 2.410661289834688

Epoch: 6| Step: 8
Training loss: 1.2958920901961641
Validation loss: 2.3808176233718004

Epoch: 6| Step: 9
Training loss: 1.3146432906239782
Validation loss: 2.399153343615932

Epoch: 6| Step: 10
Training loss: 0.9689943866724618
Validation loss: 2.415967497147843

Epoch: 6| Step: 11
Training loss: 1.3947737453563835
Validation loss: 2.404442612191177

Epoch: 6| Step: 12
Training loss: 1.240316601528038
Validation loss: 2.368705786502538

Epoch: 6| Step: 13
Training loss: 1.3226941539833346
Validation loss: 2.4407181910129556

Epoch: 340| Step: 0
Training loss: 0.8428754159133476
Validation loss: 2.4292323009183896

Epoch: 6| Step: 1
Training loss: 2.3426851015025996
Validation loss: 2.4457928543722787

Epoch: 6| Step: 2
Training loss: 0.855970018095736
Validation loss: 2.41443825421199

Epoch: 6| Step: 3
Training loss: 1.3495322618108598
Validation loss: 2.4025246386086105

Epoch: 6| Step: 4
Training loss: 1.1210203778118766
Validation loss: 2.411560906012731

Epoch: 6| Step: 5
Training loss: 1.9553741932105049
Validation loss: 2.4367326633507354

Epoch: 6| Step: 6
Training loss: 1.4113762563041548
Validation loss: 2.433990940691802

Epoch: 6| Step: 7
Training loss: 1.3715067619076378
Validation loss: 2.4398557639597778

Epoch: 6| Step: 8
Training loss: 1.3245139004074047
Validation loss: 2.3686844143083623

Epoch: 6| Step: 9
Training loss: 1.6338548755330071
Validation loss: 2.3629758038955933

Epoch: 6| Step: 10
Training loss: 1.4048644551637384
Validation loss: 2.409613440707121

Epoch: 6| Step: 11
Training loss: 1.713003713774121
Validation loss: 2.353809599314494

Epoch: 6| Step: 12
Training loss: 1.2918164053641086
Validation loss: 2.386447647874411

Epoch: 6| Step: 13
Training loss: 0.9219948642198758
Validation loss: 2.383493019589908

Epoch: 341| Step: 0
Training loss: 1.7827024059755106
Validation loss: 2.3987868169780517

Epoch: 6| Step: 1
Training loss: 1.619903715945777
Validation loss: 2.4337933715132354

Epoch: 6| Step: 2
Training loss: 1.4700934576311542
Validation loss: 2.3863597382549724

Epoch: 6| Step: 3
Training loss: 1.2130014857246125
Validation loss: 2.435469993415134

Epoch: 6| Step: 4
Training loss: 1.9080186987066605
Validation loss: 2.377342354640406

Epoch: 6| Step: 5
Training loss: 1.2272905266559577
Validation loss: 2.3708335089116224

Epoch: 6| Step: 6
Training loss: 1.150791066134995
Validation loss: 2.411318768020615

Epoch: 6| Step: 7
Training loss: 2.1965910422814825
Validation loss: 2.374052867599927

Epoch: 6| Step: 8
Training loss: 1.2843596705800426
Validation loss: 2.419186939887613

Epoch: 6| Step: 9
Training loss: 1.6392109908197652
Validation loss: 2.394870746235034

Epoch: 6| Step: 10
Training loss: 1.5135015970252552
Validation loss: 2.4410933519248204

Epoch: 6| Step: 11
Training loss: 1.0219600000522762
Validation loss: 2.400668753874874

Epoch: 6| Step: 12
Training loss: 1.0490230897666002
Validation loss: 2.390980729910806

Epoch: 6| Step: 13
Training loss: 1.2196468085915362
Validation loss: 2.394190054488795

Epoch: 342| Step: 0
Training loss: 1.1754804967952244
Validation loss: 2.37831337740697

Epoch: 6| Step: 1
Training loss: 1.1502532099724834
Validation loss: 2.4292149406852297

Epoch: 6| Step: 2
Training loss: 1.2959472371092717
Validation loss: 2.4227904823977915

Epoch: 6| Step: 3
Training loss: 2.3044117908111907
Validation loss: 2.454802781228682

Epoch: 6| Step: 4
Training loss: 1.7177295082812063
Validation loss: 2.4460798198009988

Epoch: 6| Step: 5
Training loss: 1.4323881729443044
Validation loss: 2.4273397218803936

Epoch: 6| Step: 6
Training loss: 1.7418330221110472
Validation loss: 2.381994060145229

Epoch: 6| Step: 7
Training loss: 1.32366283529613
Validation loss: 2.4377905833089395

Epoch: 6| Step: 8
Training loss: 1.449809897227269
Validation loss: 2.395602263177039

Epoch: 6| Step: 9
Training loss: 1.4329519888268116
Validation loss: 2.3738603647990137

Epoch: 6| Step: 10
Training loss: 1.2461624365743245
Validation loss: 2.423779248998036

Epoch: 6| Step: 11
Training loss: 1.4300594992363784
Validation loss: 2.4096312804843736

Epoch: 6| Step: 12
Training loss: 1.25032439790884
Validation loss: 2.3747250981279513

Epoch: 6| Step: 13
Training loss: 1.2041948194193726
Validation loss: 2.473198214187024

Epoch: 343| Step: 0
Training loss: 1.5608617204785702
Validation loss: 2.4262465491661827

Epoch: 6| Step: 1
Training loss: 1.053756302784163
Validation loss: 2.3985130108713024

Epoch: 6| Step: 2
Training loss: 1.3205786442417737
Validation loss: 2.426730005631481

Epoch: 6| Step: 3
Training loss: 1.3021358733703237
Validation loss: 2.4697491840992285

Epoch: 6| Step: 4
Training loss: 1.5088805532030123
Validation loss: 2.422855149486283

Epoch: 6| Step: 5
Training loss: 1.4881608568891915
Validation loss: 2.373402551588675

Epoch: 6| Step: 6
Training loss: 1.9128014594951184
Validation loss: 2.4185926547675827

Epoch: 6| Step: 7
Training loss: 1.5294643812169197
Validation loss: 2.4255348965436427

Epoch: 6| Step: 8
Training loss: 1.2323017817533823
Validation loss: 2.407314913490624

Epoch: 6| Step: 9
Training loss: 1.3316492332746477
Validation loss: 2.355509465873341

Epoch: 6| Step: 10
Training loss: 1.3786286244785313
Validation loss: 2.452951478826919

Epoch: 6| Step: 11
Training loss: 1.4657446773770093
Validation loss: 2.4877422223693895

Epoch: 6| Step: 12
Training loss: 1.3317456428652767
Validation loss: 2.398014250512246

Epoch: 6| Step: 13
Training loss: 1.5580982003659598
Validation loss: 2.4681604765889382

Epoch: 344| Step: 0
Training loss: 1.320267941778283
Validation loss: 2.4123886618281936

Epoch: 6| Step: 1
Training loss: 1.4297040094141558
Validation loss: 2.426452672731855

Epoch: 6| Step: 2
Training loss: 1.6199698723240346
Validation loss: 2.42367006188599

Epoch: 6| Step: 3
Training loss: 1.3036280916444163
Validation loss: 2.4472660838282048

Epoch: 6| Step: 4
Training loss: 1.3044848256104027
Validation loss: 2.4385656967318097

Epoch: 6| Step: 5
Training loss: 1.6957687959254997
Validation loss: 2.4305991738932704

Epoch: 6| Step: 6
Training loss: 1.1032104070090976
Validation loss: 2.479569422999768

Epoch: 6| Step: 7
Training loss: 1.4833409773526058
Validation loss: 2.4151771956758523

Epoch: 6| Step: 8
Training loss: 1.235641457540213
Validation loss: 2.4325398802903058

Epoch: 6| Step: 9
Training loss: 2.264991092790685
Validation loss: 2.3875923951064353

Epoch: 6| Step: 10
Training loss: 1.5982193455840539
Validation loss: 2.4407123031947844

Epoch: 6| Step: 11
Training loss: 1.0493600870859725
Validation loss: 2.397387038148889

Epoch: 6| Step: 12
Training loss: 1.477043517544123
Validation loss: 2.3995660780975703

Epoch: 6| Step: 13
Training loss: 1.2385473597176204
Validation loss: 2.4472359337611396

Epoch: 345| Step: 0
Training loss: 1.401017563434107
Validation loss: 2.3811254130538684

Epoch: 6| Step: 1
Training loss: 1.5398060508073033
Validation loss: 2.3618982778349564

Epoch: 6| Step: 2
Training loss: 1.4709658850286818
Validation loss: 2.3515017082596423

Epoch: 6| Step: 3
Training loss: 1.7576223312931731
Validation loss: 2.3938852077132085

Epoch: 6| Step: 4
Training loss: 2.04286966758265
Validation loss: 2.4862715693085384

Epoch: 6| Step: 5
Training loss: 1.1075544866587688
Validation loss: 2.4451273106586795

Epoch: 6| Step: 6
Training loss: 1.2631956733211565
Validation loss: 2.373479785674956

Epoch: 6| Step: 7
Training loss: 1.5071528281396631
Validation loss: 2.38568368841139

Epoch: 6| Step: 8
Training loss: 1.7134509154369775
Validation loss: 2.4028120364660945

Epoch: 6| Step: 9
Training loss: 1.4106242916864282
Validation loss: 2.3803845404956907

Epoch: 6| Step: 10
Training loss: 1.1005426108929692
Validation loss: 2.436184168520577

Epoch: 6| Step: 11
Training loss: 1.1768508051301152
Validation loss: 2.4282300577027613

Epoch: 6| Step: 12
Training loss: 1.550072649822118
Validation loss: 2.345171049548288

Epoch: 6| Step: 13
Training loss: 1.4811473891373501
Validation loss: 2.4990583163939033

Epoch: 346| Step: 0
Training loss: 1.599854763711029
Validation loss: 2.440188570872315

Epoch: 6| Step: 1
Training loss: 1.5557268971734297
Validation loss: 2.479449559946984

Epoch: 6| Step: 2
Training loss: 1.5588845959195907
Validation loss: 2.5057411772453415

Epoch: 6| Step: 3
Training loss: 1.2975595345188318
Validation loss: 2.554203973757408

Epoch: 6| Step: 4
Training loss: 1.3659657278048207
Validation loss: 2.5211006778064213

Epoch: 6| Step: 5
Training loss: 1.1928822863908999
Validation loss: 2.502843976294186

Epoch: 6| Step: 6
Training loss: 1.1474749625140226
Validation loss: 2.5012841197948568

Epoch: 6| Step: 7
Training loss: 2.415780551733394
Validation loss: 2.4916734283857065

Epoch: 6| Step: 8
Training loss: 1.7601114117515273
Validation loss: 2.4476633402057133

Epoch: 6| Step: 9
Training loss: 1.3140369680421278
Validation loss: 2.3440453007659805

Epoch: 6| Step: 10
Training loss: 1.094187730662454
Validation loss: 2.350027119277801

Epoch: 6| Step: 11
Training loss: 1.3694584759158237
Validation loss: 2.4361877558702547

Epoch: 6| Step: 12
Training loss: 1.4271323295405711
Validation loss: 2.3951679299958832

Epoch: 6| Step: 13
Training loss: 2.0668313755522103
Validation loss: 2.4441466621657217

Epoch: 347| Step: 0
Training loss: 1.297791582247141
Validation loss: 2.4341237044480333

Epoch: 6| Step: 1
Training loss: 1.5622305065446052
Validation loss: 2.4114782344557093

Epoch: 6| Step: 2
Training loss: 1.5589226014877067
Validation loss: 2.4501938926697795

Epoch: 6| Step: 3
Training loss: 1.242850888249048
Validation loss: 2.4181289849037118

Epoch: 6| Step: 4
Training loss: 1.3464649186860373
Validation loss: 2.37611712567691

Epoch: 6| Step: 5
Training loss: 1.062380727917452
Validation loss: 2.4419719895379868

Epoch: 6| Step: 6
Training loss: 1.3017050638693939
Validation loss: 2.479377274026758

Epoch: 6| Step: 7
Training loss: 1.6144725474424495
Validation loss: 2.346950897675708

Epoch: 6| Step: 8
Training loss: 1.0137382588488602
Validation loss: 2.442226731250418

Epoch: 6| Step: 9
Training loss: 2.0530871987310384
Validation loss: 2.4167015315742084

Epoch: 6| Step: 10
Training loss: 1.1314594475343758
Validation loss: 2.42370538418208

Epoch: 6| Step: 11
Training loss: 2.5497796281323164
Validation loss: 2.4475228459970184

Epoch: 6| Step: 12
Training loss: 1.3274252001563753
Validation loss: 2.493054491975334

Epoch: 6| Step: 13
Training loss: 1.3612777722540805
Validation loss: 2.500158159831557

Epoch: 348| Step: 0
Training loss: 0.8743598162823559
Validation loss: 2.4451105172700944

Epoch: 6| Step: 1
Training loss: 1.263913917060806
Validation loss: 2.5159484516743094

Epoch: 6| Step: 2
Training loss: 2.220494940803741
Validation loss: 2.442373655359393

Epoch: 6| Step: 3
Training loss: 1.475228489134415
Validation loss: 2.470858107256929

Epoch: 6| Step: 4
Training loss: 1.618817378817986
Validation loss: 2.410183636473567

Epoch: 6| Step: 5
Training loss: 1.5193410720081322
Validation loss: 2.3354563049914314

Epoch: 6| Step: 6
Training loss: 1.7454607539445828
Validation loss: 2.3721993983012264

Epoch: 6| Step: 7
Training loss: 1.186511481581996
Validation loss: 2.4007978717067084

Epoch: 6| Step: 8
Training loss: 1.324929060926328
Validation loss: 2.4228336063265927

Epoch: 6| Step: 9
Training loss: 1.6883319640585546
Validation loss: 2.396296081866745

Epoch: 6| Step: 10
Training loss: 1.0109243919784492
Validation loss: 2.423977756015684

Epoch: 6| Step: 11
Training loss: 1.5226708463827467
Validation loss: 2.367040898671074

Epoch: 6| Step: 12
Training loss: 1.730557062724304
Validation loss: 2.4130375769798524

Epoch: 6| Step: 13
Training loss: 1.305344467593573
Validation loss: 2.354288590439533

Epoch: 349| Step: 0
Training loss: 1.8890047933821599
Validation loss: 2.390164125454161

Epoch: 6| Step: 1
Training loss: 1.393807829952922
Validation loss: 2.3825296417999997

Epoch: 6| Step: 2
Training loss: 1.4624215814156194
Validation loss: 2.4503531146484563

Epoch: 6| Step: 3
Training loss: 1.0645408104294087
Validation loss: 2.4050709958057013

Epoch: 6| Step: 4
Training loss: 1.3597365150743859
Validation loss: 2.3898816841490502

Epoch: 6| Step: 5
Training loss: 1.491490385980469
Validation loss: 2.4085199840760843

Epoch: 6| Step: 6
Training loss: 1.08155939162898
Validation loss: 2.423442006280344

Epoch: 6| Step: 7
Training loss: 1.528947695334595
Validation loss: 2.4261619239190813

Epoch: 6| Step: 8
Training loss: 1.3996431491959826
Validation loss: 2.3739652068662127

Epoch: 6| Step: 9
Training loss: 1.2164249739678916
Validation loss: 2.4074255388168013

Epoch: 6| Step: 10
Training loss: 1.1762584845696002
Validation loss: 2.3949993299483787

Epoch: 6| Step: 11
Training loss: 1.4689812985366557
Validation loss: 2.3842805097553557

Epoch: 6| Step: 12
Training loss: 1.022627182118282
Validation loss: 2.444071834266998

Epoch: 6| Step: 13
Training loss: 2.4276798699445195
Validation loss: 2.402071884596587

Epoch: 350| Step: 0
Training loss: 1.4135182213109774
Validation loss: 2.37902616952319

Epoch: 6| Step: 1
Training loss: 1.15927373027391
Validation loss: 2.413399253431126

Epoch: 6| Step: 2
Training loss: 1.0126070225043604
Validation loss: 2.40060111195262

Epoch: 6| Step: 3
Training loss: 1.3263098935653108
Validation loss: 2.3954607837533812

Epoch: 6| Step: 4
Training loss: 1.3317671259456865
Validation loss: 2.391259949504147

Epoch: 6| Step: 5
Training loss: 2.434670885000234
Validation loss: 2.461301836974605

Epoch: 6| Step: 6
Training loss: 1.6022714673891407
Validation loss: 2.370770864786305

Epoch: 6| Step: 7
Training loss: 1.0819360023194207
Validation loss: 2.354680214320057

Epoch: 6| Step: 8
Training loss: 1.0385505734555627
Validation loss: 2.3507637032949535

Epoch: 6| Step: 9
Training loss: 1.1936855838032627
Validation loss: 2.400786759856559

Epoch: 6| Step: 10
Training loss: 1.2814570003860843
Validation loss: 2.377636808523477

Epoch: 6| Step: 11
Training loss: 1.7779499068310562
Validation loss: 2.3441443523768988

Epoch: 6| Step: 12
Training loss: 1.6650420695079151
Validation loss: 2.353392856523971

Epoch: 6| Step: 13
Training loss: 1.2084029221501607
Validation loss: 2.441176298604462

Epoch: 351| Step: 0
Training loss: 1.377767898069529
Validation loss: 2.3507401836905486

Epoch: 6| Step: 1
Training loss: 1.4775109852545434
Validation loss: 2.4662836833732413

Epoch: 6| Step: 2
Training loss: 1.0959065566359596
Validation loss: 2.4257794872053813

Epoch: 6| Step: 3
Training loss: 1.6504689937245764
Validation loss: 2.352624208376206

Epoch: 6| Step: 4
Training loss: 1.2705528022605808
Validation loss: 2.4588736462981324

Epoch: 6| Step: 5
Training loss: 2.332355317006409
Validation loss: 2.400892822216219

Epoch: 6| Step: 6
Training loss: 1.2962456980296364
Validation loss: 2.4511124952813033

Epoch: 6| Step: 7
Training loss: 1.4395071198107496
Validation loss: 2.4265299847605117

Epoch: 6| Step: 8
Training loss: 1.4394908884547815
Validation loss: 2.3673751260146454

Epoch: 6| Step: 9
Training loss: 1.4535761307238293
Validation loss: 2.4050197900491654

Epoch: 6| Step: 10
Training loss: 1.170589403058292
Validation loss: 2.344081482775154

Epoch: 6| Step: 11
Training loss: 1.193928534453671
Validation loss: 2.403118469032263

Epoch: 6| Step: 12
Training loss: 1.173869356012044
Validation loss: 2.4388460886641266

Epoch: 6| Step: 13
Training loss: 0.6405741508586345
Validation loss: 2.3782980290696853

Epoch: 352| Step: 0
Training loss: 1.368849697575527
Validation loss: 2.408721603209226

Epoch: 6| Step: 1
Training loss: 1.1035645600668198
Validation loss: 2.366671203974052

Epoch: 6| Step: 2
Training loss: 1.2807219743106533
Validation loss: 2.4425693445046277

Epoch: 6| Step: 3
Training loss: 0.9438918607082613
Validation loss: 2.404254450759078

Epoch: 6| Step: 4
Training loss: 1.6864699292820007
Validation loss: 2.416561322432108

Epoch: 6| Step: 5
Training loss: 1.389366780821753
Validation loss: 2.3971968855920824

Epoch: 6| Step: 6
Training loss: 1.3731326514592164
Validation loss: 2.411600477136911

Epoch: 6| Step: 7
Training loss: 1.6582649498007829
Validation loss: 2.387412601136801

Epoch: 6| Step: 8
Training loss: 1.4123188459646536
Validation loss: 2.4287680688017375

Epoch: 6| Step: 9
Training loss: 1.6734431390462514
Validation loss: 2.480932665789236

Epoch: 6| Step: 10
Training loss: 1.7080362883561078
Validation loss: 2.468369014902214

Epoch: 6| Step: 11
Training loss: 1.2381961444285137
Validation loss: 2.366405473629617

Epoch: 6| Step: 12
Training loss: 2.0357956714662437
Validation loss: 2.451468572148751

Epoch: 6| Step: 13
Training loss: 1.1471028260167027
Validation loss: 2.406388413968686

Epoch: 353| Step: 0
Training loss: 1.4739892729442643
Validation loss: 2.4370293700612056

Epoch: 6| Step: 1
Training loss: 1.2089069692948031
Validation loss: 2.417856897867647

Epoch: 6| Step: 2
Training loss: 1.257232627125102
Validation loss: 2.3747556287585536

Epoch: 6| Step: 3
Training loss: 1.2960288723096054
Validation loss: 2.472351667169195

Epoch: 6| Step: 4
Training loss: 1.664119952289104
Validation loss: 2.4546827610324407

Epoch: 6| Step: 5
Training loss: 1.8697135150979787
Validation loss: 2.483020817134867

Epoch: 6| Step: 6
Training loss: 1.0651715854986228
Validation loss: 2.439844245780959

Epoch: 6| Step: 7
Training loss: 1.7480819272410901
Validation loss: 2.449597502731579

Epoch: 6| Step: 8
Training loss: 1.5776285580394784
Validation loss: 2.417868603491801

Epoch: 6| Step: 9
Training loss: 1.6332561127580236
Validation loss: 2.464425308048471

Epoch: 6| Step: 10
Training loss: 1.3747522390999105
Validation loss: 2.454811557296452

Epoch: 6| Step: 11
Training loss: 1.0154808529016504
Validation loss: 2.3321980422418096

Epoch: 6| Step: 12
Training loss: 0.9847110901152384
Validation loss: 2.407425637851463

Epoch: 6| Step: 13
Training loss: 1.1142126102623389
Validation loss: 2.4408721252925294

Epoch: 354| Step: 0
Training loss: 1.2863610831914527
Validation loss: 2.338888310416197

Epoch: 6| Step: 1
Training loss: 1.4829087092518458
Validation loss: 2.4029882468742167

Epoch: 6| Step: 2
Training loss: 1.1702192689559991
Validation loss: 2.386686175782174

Epoch: 6| Step: 3
Training loss: 0.8790455347533481
Validation loss: 2.4076150852989535

Epoch: 6| Step: 4
Training loss: 1.6789500902220242
Validation loss: 2.4138149999169873

Epoch: 6| Step: 5
Training loss: 1.4708721980650703
Validation loss: 2.3933763665078045

Epoch: 6| Step: 6
Training loss: 1.3553012007791383
Validation loss: 2.4092858581494005

Epoch: 6| Step: 7
Training loss: 1.4735727064086073
Validation loss: 2.4242792560046755

Epoch: 6| Step: 8
Training loss: 1.5626062738516981
Validation loss: 2.4100076904824337

Epoch: 6| Step: 9
Training loss: 1.051564715129452
Validation loss: 2.3611426156113926

Epoch: 6| Step: 10
Training loss: 1.2630329197046408
Validation loss: 2.363422245520501

Epoch: 6| Step: 11
Training loss: 2.1584620531893983
Validation loss: 2.4356304094871404

Epoch: 6| Step: 12
Training loss: 1.443271825300606
Validation loss: 2.4041343436701523

Epoch: 6| Step: 13
Training loss: 0.5770029313808005
Validation loss: 2.369539018640987

Epoch: 355| Step: 0
Training loss: 1.433708664448737
Validation loss: 2.4594404645061645

Epoch: 6| Step: 1
Training loss: 1.1201617789933531
Validation loss: 2.3905847438677776

Epoch: 6| Step: 2
Training loss: 1.2021675263290754
Validation loss: 2.3940893769658387

Epoch: 6| Step: 3
Training loss: 0.9093395711283063
Validation loss: 2.498600073549104

Epoch: 6| Step: 4
Training loss: 1.776392822751735
Validation loss: 2.4155579949259502

Epoch: 6| Step: 5
Training loss: 2.244702991642974
Validation loss: 2.397316956879621

Epoch: 6| Step: 6
Training loss: 1.2731761547180689
Validation loss: 2.4177223766689737

Epoch: 6| Step: 7
Training loss: 1.7668837389950829
Validation loss: 2.428692802978568

Epoch: 6| Step: 8
Training loss: 0.996654517207097
Validation loss: 2.4273222076422134

Epoch: 6| Step: 9
Training loss: 1.525879843749712
Validation loss: 2.3946037788034804

Epoch: 6| Step: 10
Training loss: 1.0769579555553956
Validation loss: 2.3899683872640813

Epoch: 6| Step: 11
Training loss: 1.1189330542637532
Validation loss: 2.4282592093146915

Epoch: 6| Step: 12
Training loss: 1.3963007452749903
Validation loss: 2.384807963789642

Epoch: 6| Step: 13
Training loss: 1.4519914697443814
Validation loss: 2.4137825688588843

Epoch: 356| Step: 0
Training loss: 1.3894689233550426
Validation loss: 2.4303114111457536

Epoch: 6| Step: 1
Training loss: 0.9921589043769268
Validation loss: 2.3634250104585774

Epoch: 6| Step: 2
Training loss: 1.559500141511931
Validation loss: 2.4303139923891592

Epoch: 6| Step: 3
Training loss: 1.2964566026950184
Validation loss: 2.4029792180612435

Epoch: 6| Step: 4
Training loss: 1.5179562287886665
Validation loss: 2.3909588936571216

Epoch: 6| Step: 5
Training loss: 1.3303357293590001
Validation loss: 2.3986639121920454

Epoch: 6| Step: 6
Training loss: 1.077234314912997
Validation loss: 2.3504134493441677

Epoch: 6| Step: 7
Training loss: 1.1973714112784455
Validation loss: 2.4628040054233318

Epoch: 6| Step: 8
Training loss: 1.1617524953429132
Validation loss: 2.417422650204532

Epoch: 6| Step: 9
Training loss: 2.4519435686086575
Validation loss: 2.4853757613769005

Epoch: 6| Step: 10
Training loss: 1.139282952470588
Validation loss: 2.3902348669132754

Epoch: 6| Step: 11
Training loss: 1.1343371949845222
Validation loss: 2.4983572371950467

Epoch: 6| Step: 12
Training loss: 1.8473615028182022
Validation loss: 2.408221576688083

Epoch: 6| Step: 13
Training loss: 1.05672399505753
Validation loss: 2.4077334136409485

Epoch: 357| Step: 0
Training loss: 1.2287714802444885
Validation loss: 2.409679707238631

Epoch: 6| Step: 1
Training loss: 1.1573544974772467
Validation loss: 2.3709548012351918

Epoch: 6| Step: 2
Training loss: 1.589525795524776
Validation loss: 2.397277940800573

Epoch: 6| Step: 3
Training loss: 1.2064282537597197
Validation loss: 2.3559361206738543

Epoch: 6| Step: 4
Training loss: 1.5008534546639485
Validation loss: 2.3944902105209955

Epoch: 6| Step: 5
Training loss: 1.5730192475205345
Validation loss: 2.4175244440234946

Epoch: 6| Step: 6
Training loss: 1.2299721336309482
Validation loss: 2.376801746995504

Epoch: 6| Step: 7
Training loss: 1.532534391505806
Validation loss: 2.4073803157568663

Epoch: 6| Step: 8
Training loss: 1.2211783254747248
Validation loss: 2.382486730961125

Epoch: 6| Step: 9
Training loss: 0.7057136566785068
Validation loss: 2.3840238819457076

Epoch: 6| Step: 10
Training loss: 2.209592376331765
Validation loss: 2.45316776102248

Epoch: 6| Step: 11
Training loss: 1.2963209232508919
Validation loss: 2.469477123130542

Epoch: 6| Step: 12
Training loss: 1.5122320205747244
Validation loss: 2.423321084014146

Epoch: 6| Step: 13
Training loss: 0.6671581369053767
Validation loss: 2.461422343688774

Epoch: 358| Step: 0
Training loss: 0.9109786088150967
Validation loss: 2.3431969781163584

Epoch: 6| Step: 1
Training loss: 1.7966776200398815
Validation loss: 2.4121293272571833

Epoch: 6| Step: 2
Training loss: 1.0017790466545204
Validation loss: 2.4658637630663534

Epoch: 6| Step: 3
Training loss: 1.2922383806942772
Validation loss: 2.3961459718716265

Epoch: 6| Step: 4
Training loss: 1.6342847109885856
Validation loss: 2.4714313855795393

Epoch: 6| Step: 5
Training loss: 1.3156877588811218
Validation loss: 2.440671988248377

Epoch: 6| Step: 6
Training loss: 1.4630223050714979
Validation loss: 2.4387065844948372

Epoch: 6| Step: 7
Training loss: 2.4329572552470737
Validation loss: 2.447043751581016

Epoch: 6| Step: 8
Training loss: 1.16177378705609
Validation loss: 2.3914749636645447

Epoch: 6| Step: 9
Training loss: 1.3989819367274015
Validation loss: 2.364814432233321

Epoch: 6| Step: 10
Training loss: 1.3169081096352253
Validation loss: 2.4348953209341757

Epoch: 6| Step: 11
Training loss: 1.0064957170617992
Validation loss: 2.392982302445045

Epoch: 6| Step: 12
Training loss: 0.9984432859059112
Validation loss: 2.345402079130699

Epoch: 6| Step: 13
Training loss: 1.2772577939291307
Validation loss: 2.3293801757750066

Epoch: 359| Step: 0
Training loss: 2.194305840741254
Validation loss: 2.4180756490162327

Epoch: 6| Step: 1
Training loss: 1.4581227650075463
Validation loss: 2.4680491623894056

Epoch: 6| Step: 2
Training loss: 1.4082837551276233
Validation loss: 2.34856162406887

Epoch: 6| Step: 3
Training loss: 1.6248945788886833
Validation loss: 2.459203420814113

Epoch: 6| Step: 4
Training loss: 1.270116395347333
Validation loss: 2.3404715498690853

Epoch: 6| Step: 5
Training loss: 1.02361977388215
Validation loss: 2.4006937219884046

Epoch: 6| Step: 6
Training loss: 1.5483035802429115
Validation loss: 2.346094247890204

Epoch: 6| Step: 7
Training loss: 0.9752194438861815
Validation loss: 2.3614869586078786

Epoch: 6| Step: 8
Training loss: 1.382380703681916
Validation loss: 2.3832591665146974

Epoch: 6| Step: 9
Training loss: 1.3601224751581822
Validation loss: 2.3816440847768923

Epoch: 6| Step: 10
Training loss: 1.598896095812504
Validation loss: 2.3834981307469945

Epoch: 6| Step: 11
Training loss: 0.8108190608034462
Validation loss: 2.4624275911465814

Epoch: 6| Step: 12
Training loss: 1.393556526680089
Validation loss: 2.450139325365691

Epoch: 6| Step: 13
Training loss: 1.4377086322148238
Validation loss: 2.4951051949228344

Epoch: 360| Step: 0
Training loss: 1.8359869767684969
Validation loss: 2.4336578245353993

Epoch: 6| Step: 1
Training loss: 1.2513555805733168
Validation loss: 2.431851311435499

Epoch: 6| Step: 2
Training loss: 1.1763823230674775
Validation loss: 2.3938474117140824

Epoch: 6| Step: 3
Training loss: 1.3551725124323282
Validation loss: 2.417061927926996

Epoch: 6| Step: 4
Training loss: 1.7198360133176849
Validation loss: 2.3661541213781443

Epoch: 6| Step: 5
Training loss: 2.0640697863188127
Validation loss: 2.406233433896952

Epoch: 6| Step: 6
Training loss: 0.8422273389349956
Validation loss: 2.387765334206258

Epoch: 6| Step: 7
Training loss: 0.7737725042912915
Validation loss: 2.3470570990661788

Epoch: 6| Step: 8
Training loss: 0.8423185568558696
Validation loss: 2.3867619424307973

Epoch: 6| Step: 9
Training loss: 1.410280005606641
Validation loss: 2.38464631984719

Epoch: 6| Step: 10
Training loss: 1.5310327804016173
Validation loss: 2.4091004193170193

Epoch: 6| Step: 11
Training loss: 1.8813982198629537
Validation loss: 2.4475712546670025

Epoch: 6| Step: 12
Training loss: 1.28904109127878
Validation loss: 2.433903719199877

Epoch: 6| Step: 13
Training loss: 0.7921779428842306
Validation loss: 2.398417728854709

Epoch: 361| Step: 0
Training loss: 1.2128913129967351
Validation loss: 2.354856064723083

Epoch: 6| Step: 1
Training loss: 1.501277220873878
Validation loss: 2.4219620111126345

Epoch: 6| Step: 2
Training loss: 1.6465939884646428
Validation loss: 2.3641194238187118

Epoch: 6| Step: 3
Training loss: 1.0917958923226234
Validation loss: 2.4164629572073664

Epoch: 6| Step: 4
Training loss: 2.0347768829028405
Validation loss: 2.3635744001678343

Epoch: 6| Step: 5
Training loss: 1.2237790348399875
Validation loss: 2.3862072493026196

Epoch: 6| Step: 6
Training loss: 1.3122664198339604
Validation loss: 2.4289544821914713

Epoch: 6| Step: 7
Training loss: 1.5240693176004412
Validation loss: 2.430160814528745

Epoch: 6| Step: 8
Training loss: 1.5174911650851381
Validation loss: 2.4096659638336173

Epoch: 6| Step: 9
Training loss: 1.6463496287676662
Validation loss: 2.45060270491609

Epoch: 6| Step: 10
Training loss: 0.9014062346063177
Validation loss: 2.4374423718325318

Epoch: 6| Step: 11
Training loss: 1.3287162362345883
Validation loss: 2.4066800608276573

Epoch: 6| Step: 12
Training loss: 1.56610127284049
Validation loss: 2.404592402559805

Epoch: 6| Step: 13
Training loss: 1.319402256787544
Validation loss: 2.3877443978056654

Epoch: 362| Step: 0
Training loss: 1.1886607068979134
Validation loss: 2.358218446286517

Epoch: 6| Step: 1
Training loss: 1.2423970747442252
Validation loss: 2.4176620258903707

Epoch: 6| Step: 2
Training loss: 1.4031872775863614
Validation loss: 2.36126049718485

Epoch: 6| Step: 3
Training loss: 1.5664780902322684
Validation loss: 2.3962769852417365

Epoch: 6| Step: 4
Training loss: 0.9474483353109531
Validation loss: 2.4429749827092597

Epoch: 6| Step: 5
Training loss: 1.645058880247884
Validation loss: 2.3735124822723455

Epoch: 6| Step: 6
Training loss: 1.1083683228287846
Validation loss: 2.3760129131920427

Epoch: 6| Step: 7
Training loss: 1.6050735321313425
Validation loss: 2.4325443530148614

Epoch: 6| Step: 8
Training loss: 1.1876099184261288
Validation loss: 2.4292247737686994

Epoch: 6| Step: 9
Training loss: 1.2773867725278152
Validation loss: 2.354343566288339

Epoch: 6| Step: 10
Training loss: 1.148842357455245
Validation loss: 2.3923744868730754

Epoch: 6| Step: 11
Training loss: 2.1777028445026834
Validation loss: 2.3844247577255557

Epoch: 6| Step: 12
Training loss: 1.2413505757777061
Validation loss: 2.470510690615561

Epoch: 6| Step: 13
Training loss: 1.6193646504915429
Validation loss: 2.4391114361892376

Epoch: 363| Step: 0
Training loss: 1.3579558934393308
Validation loss: 2.371011835342179

Epoch: 6| Step: 1
Training loss: 1.2474402922138397
Validation loss: 2.40265000221493

Epoch: 6| Step: 2
Training loss: 1.1448012414357713
Validation loss: 2.4035721127637544

Epoch: 6| Step: 3
Training loss: 1.6911656162274615
Validation loss: 2.3338532227542466

Epoch: 6| Step: 4
Training loss: 0.809798002722857
Validation loss: 2.3605779091212638

Epoch: 6| Step: 5
Training loss: 1.3789863887333658
Validation loss: 2.3999065883464867

Epoch: 6| Step: 6
Training loss: 1.3360928004607975
Validation loss: 2.4000230033730907

Epoch: 6| Step: 7
Training loss: 1.2950631319218175
Validation loss: 2.400564986214145

Epoch: 6| Step: 8
Training loss: 2.0597746210970693
Validation loss: 2.4068791046914098

Epoch: 6| Step: 9
Training loss: 1.5131685466085913
Validation loss: 2.3999234459487684

Epoch: 6| Step: 10
Training loss: 1.2561943117770595
Validation loss: 2.3576890995654827

Epoch: 6| Step: 11
Training loss: 1.2027087792116484
Validation loss: 2.4069317439362123

Epoch: 6| Step: 12
Training loss: 1.5913455253030686
Validation loss: 2.365799928122365

Epoch: 6| Step: 13
Training loss: 1.2752440574281692
Validation loss: 2.360404674036633

Epoch: 364| Step: 0
Training loss: 1.185471156811587
Validation loss: 2.3614470004286243

Epoch: 6| Step: 1
Training loss: 1.3238601424059118
Validation loss: 2.3725330761585015

Epoch: 6| Step: 2
Training loss: 1.5863481563082111
Validation loss: 2.3754072493222647

Epoch: 6| Step: 3
Training loss: 1.3441529667805143
Validation loss: 2.384586644605718

Epoch: 6| Step: 4
Training loss: 1.2247758718710309
Validation loss: 2.3722406418538418

Epoch: 6| Step: 5
Training loss: 1.5720342809467616
Validation loss: 2.40066408614048

Epoch: 6| Step: 6
Training loss: 1.0563043140238415
Validation loss: 2.3906647627074125

Epoch: 6| Step: 7
Training loss: 1.088531579270539
Validation loss: 2.4037863301105156

Epoch: 6| Step: 8
Training loss: 1.0658438181019683
Validation loss: 2.4578240355252543

Epoch: 6| Step: 9
Training loss: 2.0172866950551147
Validation loss: 2.437440268281883

Epoch: 6| Step: 10
Training loss: 1.5335677375472372
Validation loss: 2.4386703147002184

Epoch: 6| Step: 11
Training loss: 1.0464908407423785
Validation loss: 2.3303952734428193

Epoch: 6| Step: 12
Training loss: 1.5435593645637258
Validation loss: 2.3630330587907187

Epoch: 6| Step: 13
Training loss: 1.5313471549216784
Validation loss: 2.398581950436737

Epoch: 365| Step: 0
Training loss: 1.688328645491925
Validation loss: 2.4944372832064716

Epoch: 6| Step: 1
Training loss: 0.8561041575504317
Validation loss: 2.4467110671828722

Epoch: 6| Step: 2
Training loss: 1.307897672990248
Validation loss: 2.31793753935586

Epoch: 6| Step: 3
Training loss: 1.5054543985930913
Validation loss: 2.3837623073601883

Epoch: 6| Step: 4
Training loss: 1.0270608142501654
Validation loss: 2.4887635964163617

Epoch: 6| Step: 5
Training loss: 1.3655103150840315
Validation loss: 2.379125670950188

Epoch: 6| Step: 6
Training loss: 1.010870854393421
Validation loss: 2.364854088516917

Epoch: 6| Step: 7
Training loss: 1.4501609515605185
Validation loss: 2.3757115147248324

Epoch: 6| Step: 8
Training loss: 1.2175689745875233
Validation loss: 2.380878722345023

Epoch: 6| Step: 9
Training loss: 1.3253454405853944
Validation loss: 2.4711371796742037

Epoch: 6| Step: 10
Training loss: 1.3077531534491287
Validation loss: 2.3982720178517787

Epoch: 6| Step: 11
Training loss: 2.386643428831437
Validation loss: 2.4253367622033206

Epoch: 6| Step: 12
Training loss: 1.1732007474837733
Validation loss: 2.4240082310645428

Epoch: 6| Step: 13
Training loss: 0.8334353781845838
Validation loss: 2.4098608111419098

Epoch: 366| Step: 0
Training loss: 2.349966121997535
Validation loss: 2.3759689513348508

Epoch: 6| Step: 1
Training loss: 1.1442045715528757
Validation loss: 2.3739994923050034

Epoch: 6| Step: 2
Training loss: 1.1851262410035368
Validation loss: 2.3983254451428584

Epoch: 6| Step: 3
Training loss: 1.4449145619830481
Validation loss: 2.4240077921588714

Epoch: 6| Step: 4
Training loss: 1.2426815370077902
Validation loss: 2.3986843701301965

Epoch: 6| Step: 5
Training loss: 1.4127613636019531
Validation loss: 2.3883063948895726

Epoch: 6| Step: 6
Training loss: 1.3252908873195606
Validation loss: 2.3712523208473524

Epoch: 6| Step: 7
Training loss: 1.1368345221327907
Validation loss: 2.369015189290601

Epoch: 6| Step: 8
Training loss: 1.4971457186804686
Validation loss: 2.4505020183946247

Epoch: 6| Step: 9
Training loss: 1.0242134239587875
Validation loss: 2.4403180401958156

Epoch: 6| Step: 10
Training loss: 0.8852853154008934
Validation loss: 2.4053668567074067

Epoch: 6| Step: 11
Training loss: 1.641092796844784
Validation loss: 2.5034364052775016

Epoch: 6| Step: 12
Training loss: 1.8287516115068074
Validation loss: 2.3707924874260713

Epoch: 6| Step: 13
Training loss: 0.9288432992662581
Validation loss: 2.4445553620157034

Epoch: 367| Step: 0
Training loss: 1.7087854236874047
Validation loss: 2.4909993076563666

Epoch: 6| Step: 1
Training loss: 0.917794426131889
Validation loss: 2.424748157447898

Epoch: 6| Step: 2
Training loss: 0.9231516193846974
Validation loss: 2.4390154330246445

Epoch: 6| Step: 3
Training loss: 1.2916330312635906
Validation loss: 2.3750680456036797

Epoch: 6| Step: 4
Training loss: 1.5879068408996722
Validation loss: 2.36552231683457

Epoch: 6| Step: 5
Training loss: 1.2648217748908972
Validation loss: 2.349264413947787

Epoch: 6| Step: 6
Training loss: 0.7954479229639002
Validation loss: 2.3719647987175536

Epoch: 6| Step: 7
Training loss: 1.3332918975272596
Validation loss: 2.4002823552039882

Epoch: 6| Step: 8
Training loss: 2.3289948956837785
Validation loss: 2.373016984627177

Epoch: 6| Step: 9
Training loss: 1.1609431722304755
Validation loss: 2.3934207637687743

Epoch: 6| Step: 10
Training loss: 1.6174308851708141
Validation loss: 2.43091970129151

Epoch: 6| Step: 11
Training loss: 1.20916529766893
Validation loss: 2.3826419978446687

Epoch: 6| Step: 12
Training loss: 1.2113147271087958
Validation loss: 2.336140957025112

Epoch: 6| Step: 13
Training loss: 1.1639949599776334
Validation loss: 2.3495020789002985

Epoch: 368| Step: 0
Training loss: 1.218548489075035
Validation loss: 2.4180486880132404

Epoch: 6| Step: 1
Training loss: 1.3542660701165128
Validation loss: 2.343504500024924

Epoch: 6| Step: 2
Training loss: 1.1289228814295824
Validation loss: 2.461310055020251

Epoch: 6| Step: 3
Training loss: 2.3318288130571077
Validation loss: 2.415679290933576

Epoch: 6| Step: 4
Training loss: 0.9307475738042932
Validation loss: 2.4047954527498785

Epoch: 6| Step: 5
Training loss: 1.4630144828241192
Validation loss: 2.4233523453993837

Epoch: 6| Step: 6
Training loss: 1.2210848036113109
Validation loss: 2.4242837127740433

Epoch: 6| Step: 7
Training loss: 0.9970480143924089
Validation loss: 2.4397165607831437

Epoch: 6| Step: 8
Training loss: 0.7912765261044049
Validation loss: 2.4010982213589056

Epoch: 6| Step: 9
Training loss: 1.3220806133259515
Validation loss: 2.4023252296884374

Epoch: 6| Step: 10
Training loss: 1.392278866493802
Validation loss: 2.368926125212371

Epoch: 6| Step: 11
Training loss: 1.442781779305281
Validation loss: 2.428229675515752

Epoch: 6| Step: 12
Training loss: 1.209087114790975
Validation loss: 2.4181574955000418

Epoch: 6| Step: 13
Training loss: 1.0729286353668965
Validation loss: 2.440868729680013

Epoch: 369| Step: 0
Training loss: 1.2772782335190453
Validation loss: 2.4285971965561965

Epoch: 6| Step: 1
Training loss: 1.0508142629209412
Validation loss: 2.4141487615646002

Epoch: 6| Step: 2
Training loss: 2.1336600048571244
Validation loss: 2.452969088595481

Epoch: 6| Step: 3
Training loss: 1.3698715457421935
Validation loss: 2.3991277546597862

Epoch: 6| Step: 4
Training loss: 1.1153716689276703
Validation loss: 2.381579756190568

Epoch: 6| Step: 5
Training loss: 1.266820037281865
Validation loss: 2.3229172795491397

Epoch: 6| Step: 6
Training loss: 1.5848330706470024
Validation loss: 2.4101858358767267

Epoch: 6| Step: 7
Training loss: 1.2802702251193252
Validation loss: 2.411375473626953

Epoch: 6| Step: 8
Training loss: 1.1806058025263395
Validation loss: 2.3708971515803805

Epoch: 6| Step: 9
Training loss: 1.1696814797949975
Validation loss: 2.416372377456549

Epoch: 6| Step: 10
Training loss: 1.510853443352074
Validation loss: 2.3796648521730766

Epoch: 6| Step: 11
Training loss: 1.1780069772711241
Validation loss: 2.3501772482727254

Epoch: 6| Step: 12
Training loss: 1.5510674892280274
Validation loss: 2.4184499825602663

Epoch: 6| Step: 13
Training loss: 1.5286106016744465
Validation loss: 2.37850310598962

Epoch: 370| Step: 0
Training loss: 0.8246614975496137
Validation loss: 2.415077430198696

Epoch: 6| Step: 1
Training loss: 1.5489994449799185
Validation loss: 2.3916114757312976

Epoch: 6| Step: 2
Training loss: 1.0716183902986498
Validation loss: 2.43908684032367

Epoch: 6| Step: 3
Training loss: 2.2583773741234294
Validation loss: 2.5600775897217054

Epoch: 6| Step: 4
Training loss: 1.4800110766279853
Validation loss: 2.4474948848705393

Epoch: 6| Step: 5
Training loss: 1.7390178362791022
Validation loss: 2.448695974898664

Epoch: 6| Step: 6
Training loss: 1.3514276779051453
Validation loss: 2.4528539238850025

Epoch: 6| Step: 7
Training loss: 1.1991162085416156
Validation loss: 2.440815699535372

Epoch: 6| Step: 8
Training loss: 1.364082341525045
Validation loss: 2.364914091488486

Epoch: 6| Step: 9
Training loss: 1.18370121131262
Validation loss: 2.442802697274875

Epoch: 6| Step: 10
Training loss: 1.3692027906379935
Validation loss: 2.3544708115015194

Epoch: 6| Step: 11
Training loss: 0.8901457584694239
Validation loss: 2.398661934950838

Epoch: 6| Step: 12
Training loss: 1.2842640200000588
Validation loss: 2.32098997508026

Epoch: 6| Step: 13
Training loss: 1.450934122358109
Validation loss: 2.3261931473598896

Epoch: 371| Step: 0
Training loss: 1.291863836601019
Validation loss: 2.429554370368831

Epoch: 6| Step: 1
Training loss: 1.1279324882439523
Validation loss: 2.396650213769599

Epoch: 6| Step: 2
Training loss: 1.3790137921723136
Validation loss: 2.323354310034742

Epoch: 6| Step: 3
Training loss: 1.132265893010549
Validation loss: 2.408785820512175

Epoch: 6| Step: 4
Training loss: 1.2003711543690443
Validation loss: 2.438117048833615

Epoch: 6| Step: 5
Training loss: 0.8776472781012916
Validation loss: 2.4280087592462993

Epoch: 6| Step: 6
Training loss: 1.1828255253305169
Validation loss: 2.426112564476761

Epoch: 6| Step: 7
Training loss: 2.384576463500032
Validation loss: 2.416978477189718

Epoch: 6| Step: 8
Training loss: 1.161731613693386
Validation loss: 2.449182273709703

Epoch: 6| Step: 9
Training loss: 1.5832915384230695
Validation loss: 2.416935240305763

Epoch: 6| Step: 10
Training loss: 1.289658564692887
Validation loss: 2.4657649681388896

Epoch: 6| Step: 11
Training loss: 1.679193397416487
Validation loss: 2.407288381484193

Epoch: 6| Step: 12
Training loss: 1.058876309567514
Validation loss: 2.425546892499006

Epoch: 6| Step: 13
Training loss: 1.7186997839787874
Validation loss: 2.347642364086877

Epoch: 372| Step: 0
Training loss: 1.2157546672947175
Validation loss: 2.3580077116507536

Epoch: 6| Step: 1
Training loss: 1.4703037079275603
Validation loss: 2.374681644658999

Epoch: 6| Step: 2
Training loss: 0.8352078970488274
Validation loss: 2.4155102856696145

Epoch: 6| Step: 3
Training loss: 0.9491645577741934
Validation loss: 2.4213514319786484

Epoch: 6| Step: 4
Training loss: 1.5854678656606707
Validation loss: 2.4110390372083286

Epoch: 6| Step: 5
Training loss: 1.3367056618010165
Validation loss: 2.3920564429560285

Epoch: 6| Step: 6
Training loss: 1.5293908802824614
Validation loss: 2.3735833360457366

Epoch: 6| Step: 7
Training loss: 2.254747891426898
Validation loss: 2.4024113879422657

Epoch: 6| Step: 8
Training loss: 1.5636407121482934
Validation loss: 2.410431840719639

Epoch: 6| Step: 9
Training loss: 1.2826517392345347
Validation loss: 2.3801554804170437

Epoch: 6| Step: 10
Training loss: 1.1370702246029973
Validation loss: 2.4046635335379993

Epoch: 6| Step: 11
Training loss: 1.2262791591836537
Validation loss: 2.4137520741010547

Epoch: 6| Step: 12
Training loss: 1.2366654115260935
Validation loss: 2.389817328426131

Epoch: 6| Step: 13
Training loss: 0.8021418479944142
Validation loss: 2.4565533827814257

Epoch: 373| Step: 0
Training loss: 1.4095940565572829
Validation loss: 2.460333648731747

Epoch: 6| Step: 1
Training loss: 1.5761357980449477
Validation loss: 2.367294475345262

Epoch: 6| Step: 2
Training loss: 1.0007892116971433
Validation loss: 2.3768889768490222

Epoch: 6| Step: 3
Training loss: 1.5669915302098834
Validation loss: 2.417544574280167

Epoch: 6| Step: 4
Training loss: 1.1125761241799759
Validation loss: 2.4056985002292355

Epoch: 6| Step: 5
Training loss: 1.0810616345686337
Validation loss: 2.3911524686778627

Epoch: 6| Step: 6
Training loss: 1.1272254231426662
Validation loss: 2.406546910131391

Epoch: 6| Step: 7
Training loss: 1.2303572346851204
Validation loss: 2.382122844948573

Epoch: 6| Step: 8
Training loss: 2.166610924908499
Validation loss: 2.3917145889087146

Epoch: 6| Step: 9
Training loss: 0.966375548137943
Validation loss: 2.363674699559352

Epoch: 6| Step: 10
Training loss: 1.0339703370493514
Validation loss: 2.3288689753101055

Epoch: 6| Step: 11
Training loss: 1.654790631215124
Validation loss: 2.4185830609414514

Epoch: 6| Step: 12
Training loss: 1.3603931867005452
Validation loss: 2.4927953394871736

Epoch: 6| Step: 13
Training loss: 1.0505133645443563
Validation loss: 2.4192749558184987

Epoch: 374| Step: 0
Training loss: 1.2138394439301121
Validation loss: 2.416188900036075

Epoch: 6| Step: 1
Training loss: 1.1173393306396726
Validation loss: 2.4599151503503607

Epoch: 6| Step: 2
Training loss: 1.1477749009469207
Validation loss: 2.4027796398791605

Epoch: 6| Step: 3
Training loss: 1.2878982372481282
Validation loss: 2.3590163526246766

Epoch: 6| Step: 4
Training loss: 1.0700516208781679
Validation loss: 2.380571397757767

Epoch: 6| Step: 5
Training loss: 1.1924872825152355
Validation loss: 2.3645144502198754

Epoch: 6| Step: 6
Training loss: 2.19975358276561
Validation loss: 2.3959772745330086

Epoch: 6| Step: 7
Training loss: 1.3830595927194334
Validation loss: 2.396157765368982

Epoch: 6| Step: 8
Training loss: 1.4967210216606528
Validation loss: 2.4295133854017847

Epoch: 6| Step: 9
Training loss: 1.1987360377289173
Validation loss: 2.384699926094276

Epoch: 6| Step: 10
Training loss: 1.2597583386114377
Validation loss: 2.4126619685556117

Epoch: 6| Step: 11
Training loss: 1.3180447577429593
Validation loss: 2.3764956017604897

Epoch: 6| Step: 12
Training loss: 1.36801527849388
Validation loss: 2.388678218968727

Epoch: 6| Step: 13
Training loss: 1.169760563958624
Validation loss: 2.373473568501794

Epoch: 375| Step: 0
Training loss: 1.0078947639897804
Validation loss: 2.4156421219439252

Epoch: 6| Step: 1
Training loss: 1.5651782161652246
Validation loss: 2.3960938173410793

Epoch: 6| Step: 2
Training loss: 1.1306367170697793
Validation loss: 2.296960311911425

Epoch: 6| Step: 3
Training loss: 1.408188903144204
Validation loss: 2.420648945789097

Epoch: 6| Step: 4
Training loss: 1.0374438649813134
Validation loss: 2.4523415961528214

Epoch: 6| Step: 5
Training loss: 0.9169499039168838
Validation loss: 2.407035134879139

Epoch: 6| Step: 6
Training loss: 1.1522628497158125
Validation loss: 2.463387616380752

Epoch: 6| Step: 7
Training loss: 1.1307565909207722
Validation loss: 2.4466366194867524

Epoch: 6| Step: 8
Training loss: 2.351740326605329
Validation loss: 2.405225673996332

Epoch: 6| Step: 9
Training loss: 1.3466084262950833
Validation loss: 2.3644245291881045

Epoch: 6| Step: 10
Training loss: 1.3212484619940086
Validation loss: 2.4565087943662895

Epoch: 6| Step: 11
Training loss: 1.011552657113963
Validation loss: 2.3785152995377783

Epoch: 6| Step: 12
Training loss: 1.7431223460957215
Validation loss: 2.38800001010643

Epoch: 6| Step: 13
Training loss: 1.2306548931468586
Validation loss: 2.4605063002537255

Epoch: 376| Step: 0
Training loss: 1.1300732345818072
Validation loss: 2.444588811059951

Epoch: 6| Step: 1
Training loss: 1.807240187674916
Validation loss: 2.4132716479763565

Epoch: 6| Step: 2
Training loss: 2.1399991867919517
Validation loss: 2.406870494160067

Epoch: 6| Step: 3
Training loss: 1.0754138748643107
Validation loss: 2.3608419889483656

Epoch: 6| Step: 4
Training loss: 1.1759479189129107
Validation loss: 2.4055742578266446

Epoch: 6| Step: 5
Training loss: 1.3615710617752321
Validation loss: 2.437987555161964

Epoch: 6| Step: 6
Training loss: 1.329001148923746
Validation loss: 2.3613337683445055

Epoch: 6| Step: 7
Training loss: 1.1934719001424996
Validation loss: 2.376910940742668

Epoch: 6| Step: 8
Training loss: 1.4166406554283795
Validation loss: 2.4427780105396537

Epoch: 6| Step: 9
Training loss: 1.324123682981326
Validation loss: 2.383949497776965

Epoch: 6| Step: 10
Training loss: 1.024220523789046
Validation loss: 2.461452034352392

Epoch: 6| Step: 11
Training loss: 1.127411324424774
Validation loss: 2.408099711279867

Epoch: 6| Step: 12
Training loss: 0.9371908631857487
Validation loss: 2.3502790269253206

Epoch: 6| Step: 13
Training loss: 1.2605701804925022
Validation loss: 2.390693279130154

Epoch: 377| Step: 0
Training loss: 1.1891391884815332
Validation loss: 2.396572118618197

Epoch: 6| Step: 1
Training loss: 1.402702009507
Validation loss: 2.458960683735008

Epoch: 6| Step: 2
Training loss: 1.095461133593905
Validation loss: 2.345055729559138

Epoch: 6| Step: 3
Training loss: 1.4828321771150204
Validation loss: 2.359287080768078

Epoch: 6| Step: 4
Training loss: 1.3734209356947398
Validation loss: 2.338595000380853

Epoch: 6| Step: 5
Training loss: 1.1616640920806625
Validation loss: 2.348279188299843

Epoch: 6| Step: 6
Training loss: 2.2054416029175186
Validation loss: 2.387692696993752

Epoch: 6| Step: 7
Training loss: 1.0416547520274002
Validation loss: 2.401037249860135

Epoch: 6| Step: 8
Training loss: 1.1887997491095676
Validation loss: 2.4443450002386053

Epoch: 6| Step: 9
Training loss: 1.106712477398441
Validation loss: 2.414154783723691

Epoch: 6| Step: 10
Training loss: 1.8560805426419205
Validation loss: 2.394552439680008

Epoch: 6| Step: 11
Training loss: 1.0071504769428334
Validation loss: 2.4100559671338915

Epoch: 6| Step: 12
Training loss: 1.1627381234703549
Validation loss: 2.3640511362744925

Epoch: 6| Step: 13
Training loss: 1.1038542911425917
Validation loss: 2.328628755873172

Epoch: 378| Step: 0
Training loss: 1.0952753602178391
Validation loss: 2.362707299051401

Epoch: 6| Step: 1
Training loss: 1.5007047587039333
Validation loss: 2.39765477292554

Epoch: 6| Step: 2
Training loss: 1.2731128114876253
Validation loss: 2.3833810672272464

Epoch: 6| Step: 3
Training loss: 1.3632279962232619
Validation loss: 2.4320207106612646

Epoch: 6| Step: 4
Training loss: 0.8885647551982934
Validation loss: 2.4688806453813332

Epoch: 6| Step: 5
Training loss: 1.3862316726835209
Validation loss: 2.404519834405328

Epoch: 6| Step: 6
Training loss: 1.4587593364661955
Validation loss: 2.454459147427336

Epoch: 6| Step: 7
Training loss: 1.5937568066021548
Validation loss: 2.4340221814230745

Epoch: 6| Step: 8
Training loss: 1.314876267228838
Validation loss: 2.421483476941672

Epoch: 6| Step: 9
Training loss: 1.345794054566379
Validation loss: 2.37238039060978

Epoch: 6| Step: 10
Training loss: 1.2590001345839668
Validation loss: 2.404450181203693

Epoch: 6| Step: 11
Training loss: 2.1220245847940733
Validation loss: 2.484256722221011

Epoch: 6| Step: 12
Training loss: 1.063217537881972
Validation loss: 2.338805237098909

Epoch: 6| Step: 13
Training loss: 1.3237248402654915
Validation loss: 2.311026699455178

Epoch: 379| Step: 0
Training loss: 1.4587288547215655
Validation loss: 2.421825889806638

Epoch: 6| Step: 1
Training loss: 1.1394463288814296
Validation loss: 2.441713717618125

Epoch: 6| Step: 2
Training loss: 1.2464688014698642
Validation loss: 2.3963743593214377

Epoch: 6| Step: 3
Training loss: 1.3316521874326146
Validation loss: 2.377344773409839

Epoch: 6| Step: 4
Training loss: 2.1586534677557117
Validation loss: 2.4537020829383867

Epoch: 6| Step: 5
Training loss: 1.3651674005891987
Validation loss: 2.4029733513949996

Epoch: 6| Step: 6
Training loss: 1.4117253837999573
Validation loss: 2.3438144278472786

Epoch: 6| Step: 7
Training loss: 1.4356178733240255
Validation loss: 2.50044256159082

Epoch: 6| Step: 8
Training loss: 0.9600486676476429
Validation loss: 2.3437982654045473

Epoch: 6| Step: 9
Training loss: 1.0261636200025728
Validation loss: 2.356977563136533

Epoch: 6| Step: 10
Training loss: 1.1488183875580826
Validation loss: 2.386399835227563

Epoch: 6| Step: 11
Training loss: 1.0622535307500764
Validation loss: 2.3905522019531804

Epoch: 6| Step: 12
Training loss: 1.5699795042510303
Validation loss: 2.4014468315774975

Epoch: 6| Step: 13
Training loss: 1.079020473833968
Validation loss: 2.338144704209824

Epoch: 380| Step: 0
Training loss: 1.4776314393266172
Validation loss: 2.3533158815416524

Epoch: 6| Step: 1
Training loss: 1.375420332731076
Validation loss: 2.376851164048686

Epoch: 6| Step: 2
Training loss: 1.4601292950064342
Validation loss: 2.3694139242862438

Epoch: 6| Step: 3
Training loss: 1.1159610552025643
Validation loss: 2.442064420061694

Epoch: 6| Step: 4
Training loss: 1.0552768332317137
Validation loss: 2.318934984973627

Epoch: 6| Step: 5
Training loss: 0.9188522307940582
Validation loss: 2.421390612296117

Epoch: 6| Step: 6
Training loss: 1.5047822853094166
Validation loss: 2.4358061507490443

Epoch: 6| Step: 7
Training loss: 1.0028807155461001
Validation loss: 2.386252671648422

Epoch: 6| Step: 8
Training loss: 1.2035243374844393
Validation loss: 2.445496205585936

Epoch: 6| Step: 9
Training loss: 1.28067040708738
Validation loss: 2.371469778744198

Epoch: 6| Step: 10
Training loss: 2.0112330174366284
Validation loss: 2.4009630302792027

Epoch: 6| Step: 11
Training loss: 1.3913466049338803
Validation loss: 2.526378922085378

Epoch: 6| Step: 12
Training loss: 0.8355274799194953
Validation loss: 2.401526234960139

Epoch: 6| Step: 13
Training loss: 2.0623164239739675
Validation loss: 2.376321145572755

Epoch: 381| Step: 0
Training loss: 1.119846460938715
Validation loss: 2.402127543812411

Epoch: 6| Step: 1
Training loss: 1.050990711309036
Validation loss: 2.3487332205741245

Epoch: 6| Step: 2
Training loss: 1.422040154224145
Validation loss: 2.323056691394882

Epoch: 6| Step: 3
Training loss: 1.5057737966877303
Validation loss: 2.366282085742462

Epoch: 6| Step: 4
Training loss: 1.0772601542637203
Validation loss: 2.304560337691638

Epoch: 6| Step: 5
Training loss: 1.89910330694189
Validation loss: 2.398087869690612

Epoch: 6| Step: 6
Training loss: 0.9699008627500196
Validation loss: 2.460355133409443

Epoch: 6| Step: 7
Training loss: 1.326075464713426
Validation loss: 2.405240610418675

Epoch: 6| Step: 8
Training loss: 1.2235595486347102
Validation loss: 2.418570400551826

Epoch: 6| Step: 9
Training loss: 1.1034637709055843
Validation loss: 2.318420099184224

Epoch: 6| Step: 10
Training loss: 1.2249375775061442
Validation loss: 2.354338486572431

Epoch: 6| Step: 11
Training loss: 1.288680511288411
Validation loss: 2.379911147341317

Epoch: 6| Step: 12
Training loss: 1.2190849626393654
Validation loss: 2.419930513249296

Epoch: 6| Step: 13
Training loss: 1.4925053442726746
Validation loss: 2.4399090061976314

Epoch: 382| Step: 0
Training loss: 0.6838019353749372
Validation loss: 2.456903482588937

Epoch: 6| Step: 1
Training loss: 1.3110742545380394
Validation loss: 2.4339796717695577

Epoch: 6| Step: 2
Training loss: 1.5135660245247655
Validation loss: 2.3767563522080484

Epoch: 6| Step: 3
Training loss: 1.1281269908264009
Validation loss: 2.36581096482021

Epoch: 6| Step: 4
Training loss: 1.4299195314988495
Validation loss: 2.488218473384136

Epoch: 6| Step: 5
Training loss: 1.4486347677303273
Validation loss: 2.465565745394741

Epoch: 6| Step: 6
Training loss: 1.1719697023908697
Validation loss: 2.465011781027321

Epoch: 6| Step: 7
Training loss: 1.201987186776162
Validation loss: 2.494297659374786

Epoch: 6| Step: 8
Training loss: 1.0024671518742412
Validation loss: 2.3932321514008503

Epoch: 6| Step: 9
Training loss: 1.010303700742388
Validation loss: 2.3886582039101336

Epoch: 6| Step: 10
Training loss: 1.4381521652951794
Validation loss: 2.4328169945212146

Epoch: 6| Step: 11
Training loss: 2.274691835428921
Validation loss: 2.4250977814774775

Epoch: 6| Step: 12
Training loss: 1.212492700928417
Validation loss: 2.4341257845346296

Epoch: 6| Step: 13
Training loss: 1.0690631675327853
Validation loss: 2.3824149852045267

Epoch: 383| Step: 0
Training loss: 1.2457693030362118
Validation loss: 2.3555213017510015

Epoch: 6| Step: 1
Training loss: 1.5795727123056709
Validation loss: 2.3698492299881826

Epoch: 6| Step: 2
Training loss: 1.2401069155100104
Validation loss: 2.489672799566014

Epoch: 6| Step: 3
Training loss: 1.1809778798233865
Validation loss: 2.39672853848859

Epoch: 6| Step: 4
Training loss: 1.9879663963816643
Validation loss: 2.4100862852786955

Epoch: 6| Step: 5
Training loss: 0.8312843086218242
Validation loss: 2.399745493515078

Epoch: 6| Step: 6
Training loss: 1.1029159131616186
Validation loss: 2.4161535569823376

Epoch: 6| Step: 7
Training loss: 1.2527266328178086
Validation loss: 2.4222929954710555

Epoch: 6| Step: 8
Training loss: 1.0220726172072954
Validation loss: 2.3606289999521466

Epoch: 6| Step: 9
Training loss: 1.1353659428923282
Validation loss: 2.381835431625012

Epoch: 6| Step: 10
Training loss: 1.120205038495167
Validation loss: 2.4685207565288954

Epoch: 6| Step: 11
Training loss: 1.3203518201401658
Validation loss: 2.458721078863084

Epoch: 6| Step: 12
Training loss: 1.7691265931923805
Validation loss: 2.4142518790098593

Epoch: 6| Step: 13
Training loss: 0.9571336652491275
Validation loss: 2.381785114286301

Epoch: 384| Step: 0
Training loss: 1.1260158402936271
Validation loss: 2.3367896845878438

Epoch: 6| Step: 1
Training loss: 1.4284573458350933
Validation loss: 2.442000216515815

Epoch: 6| Step: 2
Training loss: 1.5531673955216008
Validation loss: 2.405677446024118

Epoch: 6| Step: 3
Training loss: 1.2272670204659275
Validation loss: 2.441510145638789

Epoch: 6| Step: 4
Training loss: 1.1057094136775345
Validation loss: 2.3989962985421203

Epoch: 6| Step: 5
Training loss: 0.6419954992103866
Validation loss: 2.4356957766302734

Epoch: 6| Step: 6
Training loss: 2.15068086888038
Validation loss: 2.3752171951961687

Epoch: 6| Step: 7
Training loss: 1.4363755513718748
Validation loss: 2.3896246381468527

Epoch: 6| Step: 8
Training loss: 1.4624088650209357
Validation loss: 2.4481687172958995

Epoch: 6| Step: 9
Training loss: 1.5535766620265963
Validation loss: 2.3455133117713127

Epoch: 6| Step: 10
Training loss: 1.337665622474712
Validation loss: 2.353578810094072

Epoch: 6| Step: 11
Training loss: 1.0408596473057279
Validation loss: 2.380326907050421

Epoch: 6| Step: 12
Training loss: 1.0570861666807687
Validation loss: 2.3296295923392325

Epoch: 6| Step: 13
Training loss: 1.2948899301124275
Validation loss: 2.4402233462437866

Epoch: 385| Step: 0
Training loss: 1.3512363371039213
Validation loss: 2.312201157749265

Epoch: 6| Step: 1
Training loss: 1.3633665916160502
Validation loss: 2.401807761090998

Epoch: 6| Step: 2
Training loss: 2.041264306209256
Validation loss: 2.3655008774043287

Epoch: 6| Step: 3
Training loss: 1.1715990886128567
Validation loss: 2.4509452382654513

Epoch: 6| Step: 4
Training loss: 1.6089115401395258
Validation loss: 2.4066365859299825

Epoch: 6| Step: 5
Training loss: 1.0767219370029633
Validation loss: 2.3951449703205943

Epoch: 6| Step: 6
Training loss: 1.5901862298119043
Validation loss: 2.4323850993516705

Epoch: 6| Step: 7
Training loss: 0.8317905131483959
Validation loss: 2.3874713445643696

Epoch: 6| Step: 8
Training loss: 1.5367327256529593
Validation loss: 2.4411568200456046

Epoch: 6| Step: 9
Training loss: 1.363886439266625
Validation loss: 2.406480382089979

Epoch: 6| Step: 10
Training loss: 0.6198848258991875
Validation loss: 2.4287667873864422

Epoch: 6| Step: 11
Training loss: 0.8261009528558766
Validation loss: 2.341203276976964

Epoch: 6| Step: 12
Training loss: 0.8287923031650231
Validation loss: 2.356013653131257

Epoch: 6| Step: 13
Training loss: 1.2595367933519739
Validation loss: 2.329867066676301

Epoch: 386| Step: 0
Training loss: 1.2695201697232812
Validation loss: 2.36787832820049

Epoch: 6| Step: 1
Training loss: 1.0662808187308401
Validation loss: 2.3612359839306847

Epoch: 6| Step: 2
Training loss: 1.9829644423782107
Validation loss: 2.4243478980156308

Epoch: 6| Step: 3
Training loss: 1.0329283725762037
Validation loss: 2.3158963568137567

Epoch: 6| Step: 4
Training loss: 1.3441798387620334
Validation loss: 2.3066364060555116

Epoch: 6| Step: 5
Training loss: 1.541495631585132
Validation loss: 2.354307093358282

Epoch: 6| Step: 6
Training loss: 1.4796799140904906
Validation loss: 2.3534628498170185

Epoch: 6| Step: 7
Training loss: 1.292651595664409
Validation loss: 2.37986303532628

Epoch: 6| Step: 8
Training loss: 1.0506119148487958
Validation loss: 2.3652112946530286

Epoch: 6| Step: 9
Training loss: 1.1773635508208125
Validation loss: 2.4701502209096384

Epoch: 6| Step: 10
Training loss: 1.171992385071372
Validation loss: 2.3992466228650478

Epoch: 6| Step: 11
Training loss: 1.0591020665751276
Validation loss: 2.4184593415875515

Epoch: 6| Step: 12
Training loss: 1.4522091840648257
Validation loss: 2.367571049942912

Epoch: 6| Step: 13
Training loss: 1.1052973314430288
Validation loss: 2.32253254663462

Epoch: 387| Step: 0
Training loss: 1.1347143585127664
Validation loss: 2.3734690487276553

Epoch: 6| Step: 1
Training loss: 1.4279703970600233
Validation loss: 2.453974536807339

Epoch: 6| Step: 2
Training loss: 1.7518733760242373
Validation loss: 2.4313366452811813

Epoch: 6| Step: 3
Training loss: 1.1114009571847712
Validation loss: 2.378909619825351

Epoch: 6| Step: 4
Training loss: 1.9760755459286377
Validation loss: 2.3649932439532795

Epoch: 6| Step: 5
Training loss: 1.360203983492544
Validation loss: 2.3509779993303233

Epoch: 6| Step: 6
Training loss: 1.436761832408063
Validation loss: 2.3815286341721533

Epoch: 6| Step: 7
Training loss: 1.1200188458083284
Validation loss: 2.3965329326280065

Epoch: 6| Step: 8
Training loss: 1.0673832592348105
Validation loss: 2.3117675829766675

Epoch: 6| Step: 9
Training loss: 1.443475246295159
Validation loss: 2.369730057716171

Epoch: 6| Step: 10
Training loss: 1.500417492304925
Validation loss: 2.368748151515623

Epoch: 6| Step: 11
Training loss: 0.8599203286859294
Validation loss: 2.361143520051568

Epoch: 6| Step: 12
Training loss: 1.0240802057229703
Validation loss: 2.4241000504988657

Epoch: 6| Step: 13
Training loss: 1.1833057116029322
Validation loss: 2.3834948755048018

Epoch: 388| Step: 0
Training loss: 0.843308721932102
Validation loss: 2.3854498647086815

Epoch: 6| Step: 1
Training loss: 1.2195950048522648
Validation loss: 2.352622204427968

Epoch: 6| Step: 2
Training loss: 0.8552729413017371
Validation loss: 2.4071503845633604

Epoch: 6| Step: 3
Training loss: 1.0245815027527487
Validation loss: 2.3767896417317154

Epoch: 6| Step: 4
Training loss: 1.3010077293658988
Validation loss: 2.449559566880805

Epoch: 6| Step: 5
Training loss: 1.1427095777747658
Validation loss: 2.4253667783453166

Epoch: 6| Step: 6
Training loss: 1.4138934629791424
Validation loss: 2.463980976489226

Epoch: 6| Step: 7
Training loss: 1.5201635932725397
Validation loss: 2.451173097637705

Epoch: 6| Step: 8
Training loss: 2.0996574076991252
Validation loss: 2.4710764999591324

Epoch: 6| Step: 9
Training loss: 1.1042332299280213
Validation loss: 2.4369080032083033

Epoch: 6| Step: 10
Training loss: 1.1498527888738335
Validation loss: 2.408322223883674

Epoch: 6| Step: 11
Training loss: 1.4381127088304173
Validation loss: 2.3534008958258332

Epoch: 6| Step: 12
Training loss: 1.6203195216763389
Validation loss: 2.4004246034902925

Epoch: 6| Step: 13
Training loss: 1.1953621648306603
Validation loss: 2.3602842043111862

Epoch: 389| Step: 0
Training loss: 1.2527007966497103
Validation loss: 2.3115329815797123

Epoch: 6| Step: 1
Training loss: 0.8892551059292114
Validation loss: 2.405987833286989

Epoch: 6| Step: 2
Training loss: 1.246776955557358
Validation loss: 2.4160507063912964

Epoch: 6| Step: 3
Training loss: 1.2016812864799564
Validation loss: 2.352098995669485

Epoch: 6| Step: 4
Training loss: 1.2198097805347239
Validation loss: 2.3992899445088307

Epoch: 6| Step: 5
Training loss: 1.268381202352511
Validation loss: 2.397470470423131

Epoch: 6| Step: 6
Training loss: 1.1322209885667147
Validation loss: 2.4138915723604826

Epoch: 6| Step: 7
Training loss: 1.3016177400404656
Validation loss: 2.3314784502988797

Epoch: 6| Step: 8
Training loss: 0.884165781567772
Validation loss: 2.360819706698001

Epoch: 6| Step: 9
Training loss: 1.6416442611378852
Validation loss: 2.4830286958890513

Epoch: 6| Step: 10
Training loss: 1.38354515882106
Validation loss: 2.4463348201652417

Epoch: 6| Step: 11
Training loss: 1.229398667806335
Validation loss: 2.4597586693163223

Epoch: 6| Step: 12
Training loss: 1.3698768105775578
Validation loss: 2.414176801484484

Epoch: 6| Step: 13
Training loss: 2.793213648162891
Validation loss: 2.397344670213348

Epoch: 390| Step: 0
Training loss: 1.0595242397997346
Validation loss: 2.4132388755154985

Epoch: 6| Step: 1
Training loss: 1.0817950159540248
Validation loss: 2.51067613164508

Epoch: 6| Step: 2
Training loss: 1.4116071596780722
Validation loss: 2.362220778575318

Epoch: 6| Step: 3
Training loss: 1.1120503363365637
Validation loss: 2.4058453640892967

Epoch: 6| Step: 4
Training loss: 0.961241697218497
Validation loss: 2.4179563949269043

Epoch: 6| Step: 5
Training loss: 1.4555484702800923
Validation loss: 2.285201627373513

Epoch: 6| Step: 6
Training loss: 1.0182550854648418
Validation loss: 2.397045914377061

Epoch: 6| Step: 7
Training loss: 1.3202504702110154
Validation loss: 2.333990538095507

Epoch: 6| Step: 8
Training loss: 1.2495924285187947
Validation loss: 2.3311932651973324

Epoch: 6| Step: 9
Training loss: 1.3256528847300684
Validation loss: 2.4001099131908448

Epoch: 6| Step: 10
Training loss: 2.0031095411921167
Validation loss: 2.3615198684759817

Epoch: 6| Step: 11
Training loss: 1.0995559272853717
Validation loss: 2.411749194188258

Epoch: 6| Step: 12
Training loss: 1.356537279563762
Validation loss: 2.371030420760235

Epoch: 6| Step: 13
Training loss: 1.0746157380792392
Validation loss: 2.401471953331979

Epoch: 391| Step: 0
Training loss: 0.6855184869784529
Validation loss: 2.3476183239875006

Epoch: 6| Step: 1
Training loss: 0.9109913674289957
Validation loss: 2.344950554839795

Epoch: 6| Step: 2
Training loss: 1.2502337713990401
Validation loss: 2.40425711542479

Epoch: 6| Step: 3
Training loss: 1.3813843329513644
Validation loss: 2.3771094403104036

Epoch: 6| Step: 4
Training loss: 1.241124496031094
Validation loss: 2.3452726584958348

Epoch: 6| Step: 5
Training loss: 0.9033306719211726
Validation loss: 2.363575055293702

Epoch: 6| Step: 6
Training loss: 1.508723640875337
Validation loss: 2.387824224095752

Epoch: 6| Step: 7
Training loss: 1.3059325530612758
Validation loss: 2.4181278886821973

Epoch: 6| Step: 8
Training loss: 1.1611644846428144
Validation loss: 2.4110534671127875

Epoch: 6| Step: 9
Training loss: 1.4100509139263384
Validation loss: 2.453303441186685

Epoch: 6| Step: 10
Training loss: 0.8994745654570304
Validation loss: 2.363147163028012

Epoch: 6| Step: 11
Training loss: 1.1107247965836216
Validation loss: 2.4398860732590144

Epoch: 6| Step: 12
Training loss: 2.422849397608364
Validation loss: 2.3456544386665286

Epoch: 6| Step: 13
Training loss: 1.620705505207527
Validation loss: 2.405231770191043

Epoch: 392| Step: 0
Training loss: 0.9718631130362441
Validation loss: 2.4218328593355904

Epoch: 6| Step: 1
Training loss: 2.048275999545105
Validation loss: 2.414299766572029

Epoch: 6| Step: 2
Training loss: 1.5323925815790056
Validation loss: 2.410553149530497

Epoch: 6| Step: 3
Training loss: 1.2777020713013705
Validation loss: 2.3380225727038635

Epoch: 6| Step: 4
Training loss: 1.0671012206826938
Validation loss: 2.456689760357243

Epoch: 6| Step: 5
Training loss: 1.2095175015971955
Validation loss: 2.316698477399691

Epoch: 6| Step: 6
Training loss: 1.146017054076399
Validation loss: 2.4002329762412407

Epoch: 6| Step: 7
Training loss: 1.1731363247795774
Validation loss: 2.405596438312816

Epoch: 6| Step: 8
Training loss: 1.5907043077524334
Validation loss: 2.306950674070224

Epoch: 6| Step: 9
Training loss: 1.3181665802317042
Validation loss: 2.392270268349394

Epoch: 6| Step: 10
Training loss: 0.7928939558563046
Validation loss: 2.288996149708844

Epoch: 6| Step: 11
Training loss: 1.5243068464307985
Validation loss: 2.398543763506443

Epoch: 6| Step: 12
Training loss: 0.7630063642533883
Validation loss: 2.404442090814455

Epoch: 6| Step: 13
Training loss: 0.8183579911468386
Validation loss: 2.3864676626734984

Epoch: 393| Step: 0
Training loss: 1.4427070847194883
Validation loss: 2.3968151768255566

Epoch: 6| Step: 1
Training loss: 1.549249387314069
Validation loss: 2.4031789332838134

Epoch: 6| Step: 2
Training loss: 1.2771023863490765
Validation loss: 2.3707148457038523

Epoch: 6| Step: 3
Training loss: 1.3952388303986647
Validation loss: 2.3810259348997445

Epoch: 6| Step: 4
Training loss: 0.8742275575086768
Validation loss: 2.3436085746508932

Epoch: 6| Step: 5
Training loss: 1.1297697045265966
Validation loss: 2.3924379626386516

Epoch: 6| Step: 6
Training loss: 0.8345964316528811
Validation loss: 2.3783015751898056

Epoch: 6| Step: 7
Training loss: 1.7541282870095298
Validation loss: 2.3941006430446756

Epoch: 6| Step: 8
Training loss: 1.5601712993570296
Validation loss: 2.396625551179174

Epoch: 6| Step: 9
Training loss: 0.9562501483493266
Validation loss: 2.4064733441283357

Epoch: 6| Step: 10
Training loss: 0.9315117001046985
Validation loss: 2.451414123155527

Epoch: 6| Step: 11
Training loss: 0.6197540661815776
Validation loss: 2.3723660442612258

Epoch: 6| Step: 12
Training loss: 1.3124205247340832
Validation loss: 2.3822345588856573

Epoch: 6| Step: 13
Training loss: 2.474558311122218
Validation loss: 2.3870268919645223

Epoch: 394| Step: 0
Training loss: 1.2298716231550912
Validation loss: 2.4481470816901316

Epoch: 6| Step: 1
Training loss: 1.016313055693398
Validation loss: 2.3806280980942507

Epoch: 6| Step: 2
Training loss: 1.2703926333294318
Validation loss: 2.4214148172546115

Epoch: 6| Step: 3
Training loss: 1.1051104608620748
Validation loss: 2.3626288284740213

Epoch: 6| Step: 4
Training loss: 0.707016749786566
Validation loss: 2.3187114480966478

Epoch: 6| Step: 5
Training loss: 1.0528507769888176
Validation loss: 2.4080484246074847

Epoch: 6| Step: 6
Training loss: 1.460516802755443
Validation loss: 2.354446132826703

Epoch: 6| Step: 7
Training loss: 1.289370875608548
Validation loss: 2.3922276260038022

Epoch: 6| Step: 8
Training loss: 1.7606923566506634
Validation loss: 2.4005102594049847

Epoch: 6| Step: 9
Training loss: 2.078083927064151
Validation loss: 2.376376905197487

Epoch: 6| Step: 10
Training loss: 0.7410201680351315
Validation loss: 2.4176142659001427

Epoch: 6| Step: 11
Training loss: 1.1290145346902896
Validation loss: 2.3460558589822984

Epoch: 6| Step: 12
Training loss: 1.2314162708460905
Validation loss: 2.405481045969061

Epoch: 6| Step: 13
Training loss: 1.5410102873154945
Validation loss: 2.4609722176020536

Epoch: 395| Step: 0
Training loss: 1.2860619967928166
Validation loss: 2.37716033598869

Epoch: 6| Step: 1
Training loss: 1.049084964042372
Validation loss: 2.3817749002162625

Epoch: 6| Step: 2
Training loss: 1.060602962914604
Validation loss: 2.3683450563170423

Epoch: 6| Step: 3
Training loss: 1.068208952361738
Validation loss: 2.311699934770292

Epoch: 6| Step: 4
Training loss: 0.9582978877824005
Validation loss: 2.351813432178007

Epoch: 6| Step: 5
Training loss: 1.0688158137709156
Validation loss: 2.3285302294495325

Epoch: 6| Step: 6
Training loss: 1.03911974756388
Validation loss: 2.350414116318749

Epoch: 6| Step: 7
Training loss: 0.859947395434678
Validation loss: 2.4050022038746084

Epoch: 6| Step: 8
Training loss: 1.5037399398200832
Validation loss: 2.374920726590835

Epoch: 6| Step: 9
Training loss: 1.83510723413947
Validation loss: 2.33775069628711

Epoch: 6| Step: 10
Training loss: 1.6937007713905763
Validation loss: 2.4251181945481184

Epoch: 6| Step: 11
Training loss: 1.2553334892632104
Validation loss: 2.3975034750028996

Epoch: 6| Step: 12
Training loss: 1.5266067795203007
Validation loss: 2.34138350428027

Epoch: 6| Step: 13
Training loss: 0.9293740649754144
Validation loss: 2.372698386986769

Epoch: 396| Step: 0
Training loss: 1.2749670473216088
Validation loss: 2.4239306704393684

Epoch: 6| Step: 1
Training loss: 1.8377418255137015
Validation loss: 2.3408402339029712

Epoch: 6| Step: 2
Training loss: 1.2417137154150326
Validation loss: 2.341032748716008

Epoch: 6| Step: 3
Training loss: 1.2487049546771023
Validation loss: 2.400442732631025

Epoch: 6| Step: 4
Training loss: 1.374670292598544
Validation loss: 2.3455571318254322

Epoch: 6| Step: 5
Training loss: 0.917343803487629
Validation loss: 2.361330407092842

Epoch: 6| Step: 6
Training loss: 1.4059488185911113
Validation loss: 2.4411268310784657

Epoch: 6| Step: 7
Training loss: 1.1326814246803816
Validation loss: 2.3716631917109616

Epoch: 6| Step: 8
Training loss: 1.3227017245555908
Validation loss: 2.3435024412391203

Epoch: 6| Step: 9
Training loss: 1.2361473204396798
Validation loss: 2.397552239211839

Epoch: 6| Step: 10
Training loss: 1.3589847925442644
Validation loss: 2.4008324509513073

Epoch: 6| Step: 11
Training loss: 1.3439727421164924
Validation loss: 2.3940193624675086

Epoch: 6| Step: 12
Training loss: 1.1617643469229773
Validation loss: 2.4059428879492812

Epoch: 6| Step: 13
Training loss: 1.2704778809947073
Validation loss: 2.3964767214569993

Epoch: 397| Step: 0
Training loss: 1.206841413760536
Validation loss: 2.423340122505483

Epoch: 6| Step: 1
Training loss: 0.8820922073641058
Validation loss: 2.3940788716556036

Epoch: 6| Step: 2
Training loss: 0.5772930035207966
Validation loss: 2.4105661928792887

Epoch: 6| Step: 3
Training loss: 1.2056614284835758
Validation loss: 2.402163458220855

Epoch: 6| Step: 4
Training loss: 1.2497746264417369
Validation loss: 2.4539913854965203

Epoch: 6| Step: 5
Training loss: 0.9602169343598047
Validation loss: 2.46182797401957

Epoch: 6| Step: 6
Training loss: 1.6022357549035604
Validation loss: 2.405462642000449

Epoch: 6| Step: 7
Training loss: 1.204804276522358
Validation loss: 2.4469835325534737

Epoch: 6| Step: 8
Training loss: 1.4616899643494454
Validation loss: 2.395913862575485

Epoch: 6| Step: 9
Training loss: 1.138611309344855
Validation loss: 2.4212482150748333

Epoch: 6| Step: 10
Training loss: 1.2972503486613718
Validation loss: 2.3879523396564575

Epoch: 6| Step: 11
Training loss: 2.170799483061575
Validation loss: 2.346875660180724

Epoch: 6| Step: 12
Training loss: 1.3820565091461587
Validation loss: 2.390682958353009

Epoch: 6| Step: 13
Training loss: 0.8463426598964883
Validation loss: 2.3526581232249635

Epoch: 398| Step: 0
Training loss: 1.426727566147143
Validation loss: 2.4150267317157454

Epoch: 6| Step: 1
Training loss: 1.0858778902886814
Validation loss: 2.3495294140332073

Epoch: 6| Step: 2
Training loss: 1.3403569787210379
Validation loss: 2.4082771576452235

Epoch: 6| Step: 3
Training loss: 0.8985883834856386
Validation loss: 2.3628220168502465

Epoch: 6| Step: 4
Training loss: 1.1334123798928115
Validation loss: 2.3925858804837823

Epoch: 6| Step: 5
Training loss: 1.103879615370586
Validation loss: 2.3762581088449855

Epoch: 6| Step: 6
Training loss: 0.6278922394640022
Validation loss: 2.3304658969431307

Epoch: 6| Step: 7
Training loss: 1.1686753907078433
Validation loss: 2.3689093435509574

Epoch: 6| Step: 8
Training loss: 1.1108751496793188
Validation loss: 2.420158370370527

Epoch: 6| Step: 9
Training loss: 1.356334047306223
Validation loss: 2.3951708576376887

Epoch: 6| Step: 10
Training loss: 2.1020780590383135
Validation loss: 2.3969608993829685

Epoch: 6| Step: 11
Training loss: 1.6827211884755393
Validation loss: 2.3923801512824023

Epoch: 6| Step: 12
Training loss: 1.2349645438104666
Validation loss: 2.412849539687117

Epoch: 6| Step: 13
Training loss: 1.1451938520856089
Validation loss: 2.4007802118923345

Epoch: 399| Step: 0
Training loss: 1.9737525839423284
Validation loss: 2.4720150815587516

Epoch: 6| Step: 1
Training loss: 1.2789583879491422
Validation loss: 2.3646366797667184

Epoch: 6| Step: 2
Training loss: 1.215931347292449
Validation loss: 2.412831334828656

Epoch: 6| Step: 3
Training loss: 1.4454301116103985
Validation loss: 2.3757414381000728

Epoch: 6| Step: 4
Training loss: 0.974144497927258
Validation loss: 2.306421345251773

Epoch: 6| Step: 5
Training loss: 1.2609736365300925
Validation loss: 2.4025605076004557

Epoch: 6| Step: 6
Training loss: 1.6690121676925431
Validation loss: 2.340025164427947

Epoch: 6| Step: 7
Training loss: 1.0961853706856393
Validation loss: 2.3665769126571305

Epoch: 6| Step: 8
Training loss: 1.252451305090024
Validation loss: 2.3502798417388813

Epoch: 6| Step: 9
Training loss: 1.1959305206485915
Validation loss: 2.4209733971172156

Epoch: 6| Step: 10
Training loss: 1.2955200286753952
Validation loss: 2.3840096933055346

Epoch: 6| Step: 11
Training loss: 1.192488432134346
Validation loss: 2.3590703326238334

Epoch: 6| Step: 12
Training loss: 1.037502121061432
Validation loss: 2.3678428868679107

Epoch: 6| Step: 13
Training loss: 1.1715230286044735
Validation loss: 2.3634970267902924

Epoch: 400| Step: 0
Training loss: 1.1511082637157188
Validation loss: 2.332416282431385

Epoch: 6| Step: 1
Training loss: 1.1249827277659006
Validation loss: 2.3675661545327844

Epoch: 6| Step: 2
Training loss: 1.1112943352521862
Validation loss: 2.423428021449306

Epoch: 6| Step: 3
Training loss: 0.8336495435324635
Validation loss: 2.396582853148555

Epoch: 6| Step: 4
Training loss: 2.1293581981572687
Validation loss: 2.4592280344006174

Epoch: 6| Step: 5
Training loss: 1.4549009893753932
Validation loss: 2.4685735762790366

Epoch: 6| Step: 6
Training loss: 1.84455595343276
Validation loss: 2.431312317669958

Epoch: 6| Step: 7
Training loss: 1.1963748574145712
Validation loss: 2.419983736219327

Epoch: 6| Step: 8
Training loss: 1.53811174643525
Validation loss: 2.32881365843522

Epoch: 6| Step: 9
Training loss: 1.3066091490918776
Validation loss: 2.4313556742550535

Epoch: 6| Step: 10
Training loss: 0.996677033430001
Validation loss: 2.3701506265179444

Epoch: 6| Step: 11
Training loss: 1.1770516562911582
Validation loss: 2.3908373149757076

Epoch: 6| Step: 12
Training loss: 1.2273956190739992
Validation loss: 2.36227486522952

Epoch: 6| Step: 13
Training loss: 0.4842697613740434
Validation loss: 2.329056562172705

Epoch: 401| Step: 0
Training loss: 1.7109163187187746
Validation loss: 2.309640471685722

Epoch: 6| Step: 1
Training loss: 1.2739850604709946
Validation loss: 2.4006902577996385

Epoch: 6| Step: 2
Training loss: 1.5042619557018886
Validation loss: 2.434558696656675

Epoch: 6| Step: 3
Training loss: 0.812175355756614
Validation loss: 2.393551887747575

Epoch: 6| Step: 4
Training loss: 1.2326111565038738
Validation loss: 2.408367536768661

Epoch: 6| Step: 5
Training loss: 1.2204446992078186
Validation loss: 2.3922677591146413

Epoch: 6| Step: 6
Training loss: 1.381526197894028
Validation loss: 2.417159993020835

Epoch: 6| Step: 7
Training loss: 2.109192790886119
Validation loss: 2.3677972028493848

Epoch: 6| Step: 8
Training loss: 1.021714193774698
Validation loss: 2.3445761085397963

Epoch: 6| Step: 9
Training loss: 1.0803612998332965
Validation loss: 2.3989910558351144

Epoch: 6| Step: 10
Training loss: 1.2367730326978226
Validation loss: 2.3603212908712

Epoch: 6| Step: 11
Training loss: 0.7756628524310543
Validation loss: 2.3932037739587897

Epoch: 6| Step: 12
Training loss: 1.2266073522445988
Validation loss: 2.434234169858456

Epoch: 6| Step: 13
Training loss: 0.8044972241071058
Validation loss: 2.454267156648018

Epoch: 402| Step: 0
Training loss: 1.182931343266155
Validation loss: 2.4694504258916177

Epoch: 6| Step: 1
Training loss: 1.0425472479343154
Validation loss: 2.47340194032629

Epoch: 6| Step: 2
Training loss: 0.7656643915747373
Validation loss: 2.4272889320370052

Epoch: 6| Step: 3
Training loss: 1.4944603671360541
Validation loss: 2.3833601299609226

Epoch: 6| Step: 4
Training loss: 1.561437932501072
Validation loss: 2.358995530568356

Epoch: 6| Step: 5
Training loss: 0.9276654990880291
Validation loss: 2.3788065454089438

Epoch: 6| Step: 6
Training loss: 1.0947450743444858
Validation loss: 2.418277007350258

Epoch: 6| Step: 7
Training loss: 1.275178993974887
Validation loss: 2.2574133937698737

Epoch: 6| Step: 8
Training loss: 2.1053419198812753
Validation loss: 2.3889178285597064

Epoch: 6| Step: 9
Training loss: 1.7029302643202802
Validation loss: 2.3823244226726548

Epoch: 6| Step: 10
Training loss: 0.7169443753105458
Validation loss: 2.38808207632926

Epoch: 6| Step: 11
Training loss: 1.1808175743646974
Validation loss: 2.3804993105029477

Epoch: 6| Step: 12
Training loss: 0.916361859247279
Validation loss: 2.432958306853219

Epoch: 6| Step: 13
Training loss: 0.727057995577874
Validation loss: 2.371833604344952

Epoch: 403| Step: 0
Training loss: 1.2362245633832312
Validation loss: 2.3504591854741586

Epoch: 6| Step: 1
Training loss: 1.1059816067219874
Validation loss: 2.3868929295569323

Epoch: 6| Step: 2
Training loss: 0.7596356984424472
Validation loss: 2.351191998337935

Epoch: 6| Step: 3
Training loss: 1.6113302704767913
Validation loss: 2.342091829848624

Epoch: 6| Step: 4
Training loss: 1.6918059618998056
Validation loss: 2.3943907999277205

Epoch: 6| Step: 5
Training loss: 0.6724123247775211
Validation loss: 2.3586172207025933

Epoch: 6| Step: 6
Training loss: 1.989467544248747
Validation loss: 2.4196252557411837

Epoch: 6| Step: 7
Training loss: 1.5403557780108992
Validation loss: 2.398250735967367

Epoch: 6| Step: 8
Training loss: 0.873863503938298
Validation loss: 2.4076860141111407

Epoch: 6| Step: 9
Training loss: 0.927661162047435
Validation loss: 2.3199844435041914

Epoch: 6| Step: 10
Training loss: 1.127584931500997
Validation loss: 2.3938889559026246

Epoch: 6| Step: 11
Training loss: 0.9770172281142142
Validation loss: 2.3380851556730384

Epoch: 6| Step: 12
Training loss: 1.033576479628396
Validation loss: 2.4071421466924012

Epoch: 6| Step: 13
Training loss: 1.2223100751070703
Validation loss: 2.314184548083221

Epoch: 404| Step: 0
Training loss: 2.0022770317235272
Validation loss: 2.398824390341856

Epoch: 6| Step: 1
Training loss: 1.3799900626087367
Validation loss: 2.37353926438326

Epoch: 6| Step: 2
Training loss: 1.1723555533246963
Validation loss: 2.348571191739639

Epoch: 6| Step: 3
Training loss: 1.0245828989427992
Validation loss: 2.3301731187179495

Epoch: 6| Step: 4
Training loss: 1.1141552088016853
Validation loss: 2.356120839847637

Epoch: 6| Step: 5
Training loss: 1.0925772783196352
Validation loss: 2.381098451411316

Epoch: 6| Step: 6
Training loss: 0.8029000141559524
Validation loss: 2.386426886297551

Epoch: 6| Step: 7
Training loss: 0.9929018227677179
Validation loss: 2.4757921252461297

Epoch: 6| Step: 8
Training loss: 1.0427148059767293
Validation loss: 2.4415629265502847

Epoch: 6| Step: 9
Training loss: 1.4526078319081592
Validation loss: 2.4050504013903806

Epoch: 6| Step: 10
Training loss: 1.378783698755242
Validation loss: 2.4664448092340248

Epoch: 6| Step: 11
Training loss: 1.3824114891539525
Validation loss: 2.4435710202667535

Epoch: 6| Step: 12
Training loss: 1.1290076187187579
Validation loss: 2.4626316815528067

Epoch: 6| Step: 13
Training loss: 1.2052482596169016
Validation loss: 2.3717855916726345

Epoch: 405| Step: 0
Training loss: 0.7292407316103424
Validation loss: 2.4464458779893508

Epoch: 6| Step: 1
Training loss: 1.3335252365453365
Validation loss: 2.369369042561149

Epoch: 6| Step: 2
Training loss: 1.2418392340967408
Validation loss: 2.3830152167489445

Epoch: 6| Step: 3
Training loss: 1.1300896906071343
Validation loss: 2.3869817853426376

Epoch: 6| Step: 4
Training loss: 0.7367467120498177
Validation loss: 2.3997591922469352

Epoch: 6| Step: 5
Training loss: 1.2754590423599625
Validation loss: 2.329819107962812

Epoch: 6| Step: 6
Training loss: 1.3967365597388421
Validation loss: 2.446361774381393

Epoch: 6| Step: 7
Training loss: 2.1239084918610116
Validation loss: 2.382513632776292

Epoch: 6| Step: 8
Training loss: 1.2700018377365874
Validation loss: 2.4057818307456773

Epoch: 6| Step: 9
Training loss: 1.0550302019361226
Validation loss: 2.3915224052461364

Epoch: 6| Step: 10
Training loss: 1.1718003821458793
Validation loss: 2.350713089477654

Epoch: 6| Step: 11
Training loss: 1.328536654235531
Validation loss: 2.3713545106397595

Epoch: 6| Step: 12
Training loss: 1.373045138579094
Validation loss: 2.3777953376322243

Epoch: 6| Step: 13
Training loss: 0.6641330681498696
Validation loss: 2.3116750390311607

Epoch: 406| Step: 0
Training loss: 1.2459777012662034
Validation loss: 2.400537805050029

Epoch: 6| Step: 1
Training loss: 2.3400183916591817
Validation loss: 2.470177821805891

Epoch: 6| Step: 2
Training loss: 0.7661741583848382
Validation loss: 2.4208396686043723

Epoch: 6| Step: 3
Training loss: 0.7176751101868716
Validation loss: 2.363279441670765

Epoch: 6| Step: 4
Training loss: 1.1527996648423968
Validation loss: 2.358255474289244

Epoch: 6| Step: 5
Training loss: 0.833740770554824
Validation loss: 2.4658166393413903

Epoch: 6| Step: 6
Training loss: 1.1321317008174936
Validation loss: 2.3027967964854965

Epoch: 6| Step: 7
Training loss: 1.2107435994110023
Validation loss: 2.321754798112448

Epoch: 6| Step: 8
Training loss: 1.2600698177733851
Validation loss: 2.3871350004715675

Epoch: 6| Step: 9
Training loss: 1.5478897619497733
Validation loss: 2.3921048782687624

Epoch: 6| Step: 10
Training loss: 0.803142694359984
Validation loss: 2.3867641035355693

Epoch: 6| Step: 11
Training loss: 1.063311659513314
Validation loss: 2.4000517685752065

Epoch: 6| Step: 12
Training loss: 1.5518033673349831
Validation loss: 2.3407463302193725

Epoch: 6| Step: 13
Training loss: 0.9781950770128468
Validation loss: 2.482155765569482

Epoch: 407| Step: 0
Training loss: 0.9186139700218705
Validation loss: 2.430983427116731

Epoch: 6| Step: 1
Training loss: 1.364428455600465
Validation loss: 2.431462680595077

Epoch: 6| Step: 2
Training loss: 1.1404833771039005
Validation loss: 2.373434740504392

Epoch: 6| Step: 3
Training loss: 1.1794894222676229
Validation loss: 2.352405400709225

Epoch: 6| Step: 4
Training loss: 0.9110297730497713
Validation loss: 2.367895268471512

Epoch: 6| Step: 5
Training loss: 1.2286468096194634
Validation loss: 2.3635707416553053

Epoch: 6| Step: 6
Training loss: 0.9002984717619129
Validation loss: 2.3927037895640533

Epoch: 6| Step: 7
Training loss: 0.7593795854720454
Validation loss: 2.4501944241906957

Epoch: 6| Step: 8
Training loss: 1.2214815877181782
Validation loss: 2.332324522079279

Epoch: 6| Step: 9
Training loss: 1.4211728384901614
Validation loss: 2.358516706234359

Epoch: 6| Step: 10
Training loss: 0.8671713475278144
Validation loss: 2.349237634459113

Epoch: 6| Step: 11
Training loss: 2.0216527896330403
Validation loss: 2.3957788093822145

Epoch: 6| Step: 12
Training loss: 1.2826620090321408
Validation loss: 2.3452923781145603

Epoch: 6| Step: 13
Training loss: 1.2136491501433002
Validation loss: 2.299102778226728

Epoch: 408| Step: 0
Training loss: 1.372751565054559
Validation loss: 2.3601137409259207

Epoch: 6| Step: 1
Training loss: 1.0913510307919188
Validation loss: 2.3745627257078485

Epoch: 6| Step: 2
Training loss: 1.0193326325444303
Validation loss: 2.355510726193074

Epoch: 6| Step: 3
Training loss: 1.2100692589697506
Validation loss: 2.446284323569364

Epoch: 6| Step: 4
Training loss: 1.1257235001967685
Validation loss: 2.3372223661164884

Epoch: 6| Step: 5
Training loss: 0.9225747636928762
Validation loss: 2.3816127861512006

Epoch: 6| Step: 6
Training loss: 1.189163197728644
Validation loss: 2.3111946858590455

Epoch: 6| Step: 7
Training loss: 1.2937774434150564
Validation loss: 2.404557865658226

Epoch: 6| Step: 8
Training loss: 1.3899688458553399
Validation loss: 2.365752488698745

Epoch: 6| Step: 9
Training loss: 1.3506849670513499
Validation loss: 2.374878207215847

Epoch: 6| Step: 10
Training loss: 2.047952732248518
Validation loss: 2.3581168157062056

Epoch: 6| Step: 11
Training loss: 1.1022282746065086
Validation loss: 2.35805962191444

Epoch: 6| Step: 12
Training loss: 0.9828882949300578
Validation loss: 2.374244108197162

Epoch: 6| Step: 13
Training loss: 1.1860233964333111
Validation loss: 2.333239470702019

Epoch: 409| Step: 0
Training loss: 1.146861129801601
Validation loss: 2.4471242651527145

Epoch: 6| Step: 1
Training loss: 1.0725125165800282
Validation loss: 2.3878364403678116

Epoch: 6| Step: 2
Training loss: 1.0109919584956264
Validation loss: 2.480025015574827

Epoch: 6| Step: 3
Training loss: 0.7272725890983104
Validation loss: 2.4025006274792675

Epoch: 6| Step: 4
Training loss: 1.3470921317058129
Validation loss: 2.4398262213296125

Epoch: 6| Step: 5
Training loss: 1.1654610648964954
Validation loss: 2.382045224910471

Epoch: 6| Step: 6
Training loss: 1.9839783519902054
Validation loss: 2.408182111854242

Epoch: 6| Step: 7
Training loss: 0.9669166259583698
Validation loss: 2.458240576805741

Epoch: 6| Step: 8
Training loss: 1.2449660504932647
Validation loss: 2.4046244634143434

Epoch: 6| Step: 9
Training loss: 1.2736458637169636
Validation loss: 2.392910651211228

Epoch: 6| Step: 10
Training loss: 1.3849381311142241
Validation loss: 2.3697004641229067

Epoch: 6| Step: 11
Training loss: 1.2153992195607728
Validation loss: 2.357458492220695

Epoch: 6| Step: 12
Training loss: 1.0696371133378537
Validation loss: 2.3646654948942425

Epoch: 6| Step: 13
Training loss: 1.131645654016025
Validation loss: 2.3796211441612853

Epoch: 410| Step: 0
Training loss: 0.9922746034370217
Validation loss: 2.434154076695456

Epoch: 6| Step: 1
Training loss: 1.3453801934449385
Validation loss: 2.395047904839747

Epoch: 6| Step: 2
Training loss: 1.261364583008057
Validation loss: 2.436070688105572

Epoch: 6| Step: 3
Training loss: 2.0192813091450748
Validation loss: 2.4331261444285084

Epoch: 6| Step: 4
Training loss: 1.1863193666136709
Validation loss: 2.470323746644138

Epoch: 6| Step: 5
Training loss: 0.9483371612413469
Validation loss: 2.434050931894482

Epoch: 6| Step: 6
Training loss: 1.3123493562259099
Validation loss: 2.397622194383339

Epoch: 6| Step: 7
Training loss: 1.0786453870879533
Validation loss: 2.3630781150982476

Epoch: 6| Step: 8
Training loss: 1.0350645780457843
Validation loss: 2.3914876270656285

Epoch: 6| Step: 9
Training loss: 0.9418523847248126
Validation loss: 2.385587180423945

Epoch: 6| Step: 10
Training loss: 1.234879499263311
Validation loss: 2.4209263007606703

Epoch: 6| Step: 11
Training loss: 0.9896905673635664
Validation loss: 2.39345980148669

Epoch: 6| Step: 12
Training loss: 1.0502817320920885
Validation loss: 2.4161958402009414

Epoch: 6| Step: 13
Training loss: 1.36189273635358
Validation loss: 2.527875222678507

Epoch: 411| Step: 0
Training loss: 0.592204944685803
Validation loss: 2.373231137355496

Epoch: 6| Step: 1
Training loss: 1.959492184969188
Validation loss: 2.4808929966807054

Epoch: 6| Step: 2
Training loss: 1.4941323273870906
Validation loss: 2.4093967132507155

Epoch: 6| Step: 3
Training loss: 1.3850320363384956
Validation loss: 2.3768681013087813

Epoch: 6| Step: 4
Training loss: 1.0533404755249607
Validation loss: 2.4535654139136303

Epoch: 6| Step: 5
Training loss: 1.0208064614217025
Validation loss: 2.330638968218236

Epoch: 6| Step: 6
Training loss: 0.9797844493539853
Validation loss: 2.409679439137657

Epoch: 6| Step: 7
Training loss: 1.5286929520250445
Validation loss: 2.3511102675097444

Epoch: 6| Step: 8
Training loss: 0.8486377290115781
Validation loss: 2.4403145419102255

Epoch: 6| Step: 9
Training loss: 1.2186285105087422
Validation loss: 2.3755158240401255

Epoch: 6| Step: 10
Training loss: 0.9395357599218379
Validation loss: 2.3433679128412543

Epoch: 6| Step: 11
Training loss: 0.8103906687772631
Validation loss: 2.428386654295828

Epoch: 6| Step: 12
Training loss: 1.132365908231576
Validation loss: 2.3825497535350384

Epoch: 6| Step: 13
Training loss: 1.089139704109089
Validation loss: 2.4049612711236237

Epoch: 412| Step: 0
Training loss: 1.0465463150791334
Validation loss: 2.40807537620965

Epoch: 6| Step: 1
Training loss: 1.1199274143471853
Validation loss: 2.41893820111395

Epoch: 6| Step: 2
Training loss: 0.8406758998506991
Validation loss: 2.3983817401847163

Epoch: 6| Step: 3
Training loss: 0.9242600445458236
Validation loss: 2.4198551102722115

Epoch: 6| Step: 4
Training loss: 1.0036143312655668
Validation loss: 2.3727154476213297

Epoch: 6| Step: 5
Training loss: 0.9723524975157152
Validation loss: 2.401312595341678

Epoch: 6| Step: 6
Training loss: 0.554902907977422
Validation loss: 2.445503916949683

Epoch: 6| Step: 7
Training loss: 1.1338511473802848
Validation loss: 2.3949140956524304

Epoch: 6| Step: 8
Training loss: 1.294790223853038
Validation loss: 2.406399991075528

Epoch: 6| Step: 9
Training loss: 1.220148067166039
Validation loss: 2.403657371743855

Epoch: 6| Step: 10
Training loss: 1.2163615175032534
Validation loss: 2.406829169784772

Epoch: 6| Step: 11
Training loss: 1.1598355142125485
Validation loss: 2.4089108481663053

Epoch: 6| Step: 12
Training loss: 2.3525629798493632
Validation loss: 2.347053981700506

Epoch: 6| Step: 13
Training loss: 1.0421676702485916
Validation loss: 2.4411250830409155

Epoch: 413| Step: 0
Training loss: 1.1118037541825136
Validation loss: 2.386219605460963

Epoch: 6| Step: 1
Training loss: 0.9083091427851174
Validation loss: 2.4143619990735616

Epoch: 6| Step: 2
Training loss: 1.0990645852935506
Validation loss: 2.3331494002499986

Epoch: 6| Step: 3
Training loss: 2.015885565423921
Validation loss: 2.3724686615369643

Epoch: 6| Step: 4
Training loss: 1.2788819084111387
Validation loss: 2.329581699717377

Epoch: 6| Step: 5
Training loss: 0.9290544935408169
Validation loss: 2.3925249213606046

Epoch: 6| Step: 6
Training loss: 0.9574701353848908
Validation loss: 2.3365157764207716

Epoch: 6| Step: 7
Training loss: 1.473028646885901
Validation loss: 2.375797640258926

Epoch: 6| Step: 8
Training loss: 1.137846763910046
Validation loss: 2.4359884368618947

Epoch: 6| Step: 9
Training loss: 1.1995412784230257
Validation loss: 2.400190771760391

Epoch: 6| Step: 10
Training loss: 1.2986461540612002
Validation loss: 2.3472035439577708

Epoch: 6| Step: 11
Training loss: 1.2509834235760326
Validation loss: 2.3733166599563678

Epoch: 6| Step: 12
Training loss: 1.1101286571276217
Validation loss: 2.31830944485045

Epoch: 6| Step: 13
Training loss: 1.1648895090941123
Validation loss: 2.407385066310618

Epoch: 414| Step: 0
Training loss: 1.0918748858429401
Validation loss: 2.397847995031511

Epoch: 6| Step: 1
Training loss: 2.1565104893889866
Validation loss: 2.3606492466869042

Epoch: 6| Step: 2
Training loss: 1.206953472112956
Validation loss: 2.422361832406589

Epoch: 6| Step: 3
Training loss: 0.859171271017362
Validation loss: 2.3312261221535793

Epoch: 6| Step: 4
Training loss: 1.2984341819895229
Validation loss: 2.470986998303704

Epoch: 6| Step: 5
Training loss: 0.9907948489745577
Validation loss: 2.4143716956804835

Epoch: 6| Step: 6
Training loss: 1.4202504361633266
Validation loss: 2.3952978658423434

Epoch: 6| Step: 7
Training loss: 1.116151983351266
Validation loss: 2.486108046579992

Epoch: 6| Step: 8
Training loss: 1.000002920623329
Validation loss: 2.3803606022092683

Epoch: 6| Step: 9
Training loss: 1.034087871333642
Validation loss: 2.447943527364056

Epoch: 6| Step: 10
Training loss: 1.170894568709726
Validation loss: 2.351667097754773

Epoch: 6| Step: 11
Training loss: 1.4014319640816124
Validation loss: 2.454156005143712

Epoch: 6| Step: 12
Training loss: 1.2861690067189069
Validation loss: 2.4412199378674178

Epoch: 6| Step: 13
Training loss: 1.0710934762098767
Validation loss: 2.3719317376240836

Epoch: 415| Step: 0
Training loss: 1.2919092360759803
Validation loss: 2.4071735835771086

Epoch: 6| Step: 1
Training loss: 0.9808137446294545
Validation loss: 2.4581557357970434

Epoch: 6| Step: 2
Training loss: 1.0678024932776489
Validation loss: 2.460014983686049

Epoch: 6| Step: 3
Training loss: 0.8285673507521965
Validation loss: 2.363740965496873

Epoch: 6| Step: 4
Training loss: 1.1424517700232355
Validation loss: 2.3278700782654465

Epoch: 6| Step: 5
Training loss: 1.3712237695847125
Validation loss: 2.370580296742741

Epoch: 6| Step: 6
Training loss: 1.1420988202404825
Validation loss: 2.3389198782484577

Epoch: 6| Step: 7
Training loss: 0.8483872316197307
Validation loss: 2.414530801754177

Epoch: 6| Step: 8
Training loss: 1.9982110605806769
Validation loss: 2.384763168606882

Epoch: 6| Step: 9
Training loss: 0.6737385565895316
Validation loss: 2.376470696567548

Epoch: 6| Step: 10
Training loss: 1.1419284636410498
Validation loss: 2.379875584389987

Epoch: 6| Step: 11
Training loss: 0.9135211743644851
Validation loss: 2.383257140457583

Epoch: 6| Step: 12
Training loss: 1.6946898692608816
Validation loss: 2.4065643582507583

Epoch: 6| Step: 13
Training loss: 1.2490550761208605
Validation loss: 2.4008833338477706

Epoch: 416| Step: 0
Training loss: 1.1488693359620543
Validation loss: 2.368190813081579

Epoch: 6| Step: 1
Training loss: 0.7554462102074003
Validation loss: 2.4154698902539122

Epoch: 6| Step: 2
Training loss: 0.8972237390781594
Validation loss: 2.3848911255837626

Epoch: 6| Step: 3
Training loss: 0.8439952705779606
Validation loss: 2.3778253080977825

Epoch: 6| Step: 4
Training loss: 1.2402531179378529
Validation loss: 2.422138373655125

Epoch: 6| Step: 5
Training loss: 1.511702663129038
Validation loss: 2.388113743185538

Epoch: 6| Step: 6
Training loss: 0.6952342300080528
Validation loss: 2.4204303244680423

Epoch: 6| Step: 7
Training loss: 1.4032735053573886
Validation loss: 2.444747407130194

Epoch: 6| Step: 8
Training loss: 0.9947073469659774
Validation loss: 2.420589332030877

Epoch: 6| Step: 9
Training loss: 0.8695678346791477
Validation loss: 2.4126674631382774

Epoch: 6| Step: 10
Training loss: 1.2718577503281183
Validation loss: 2.417810897608723

Epoch: 6| Step: 11
Training loss: 1.383148540463705
Validation loss: 2.4111596062895106

Epoch: 6| Step: 12
Training loss: 2.098814916010047
Validation loss: 2.380474457428913

Epoch: 6| Step: 13
Training loss: 1.217744265576313
Validation loss: 2.4420514782878247

Epoch: 417| Step: 0
Training loss: 0.9702302022485306
Validation loss: 2.425153968806405

Epoch: 6| Step: 1
Training loss: 1.5065810160358581
Validation loss: 2.387683890576035

Epoch: 6| Step: 2
Training loss: 1.2846961777713428
Validation loss: 2.4021903691289967

Epoch: 6| Step: 3
Training loss: 1.3371578242322473
Validation loss: 2.4445811114913765

Epoch: 6| Step: 4
Training loss: 1.7737507816498468
Validation loss: 2.4334039930984344

Epoch: 6| Step: 5
Training loss: 0.7125520921369812
Validation loss: 2.337621295101072

Epoch: 6| Step: 6
Training loss: 0.9178916411784241
Validation loss: 2.3760516132819935

Epoch: 6| Step: 7
Training loss: 0.8927539009622182
Validation loss: 2.3871247593542715

Epoch: 6| Step: 8
Training loss: 0.852368454614479
Validation loss: 2.335280603659757

Epoch: 6| Step: 9
Training loss: 1.2285035440551413
Validation loss: 2.295690336326866

Epoch: 6| Step: 10
Training loss: 1.3388400753289482
Validation loss: 2.3501437159613214

Epoch: 6| Step: 11
Training loss: 1.2896633712918386
Validation loss: 2.3733430122045855

Epoch: 6| Step: 12
Training loss: 0.8146970461398416
Validation loss: 2.3570719741658115

Epoch: 6| Step: 13
Training loss: 0.8819160298319912
Validation loss: 2.3998434425891997

Epoch: 418| Step: 0
Training loss: 0.9596496263519102
Validation loss: 2.426110970464502

Epoch: 6| Step: 1
Training loss: 0.9793467694214106
Validation loss: 2.3661718576023136

Epoch: 6| Step: 2
Training loss: 0.9394202593409823
Validation loss: 2.451675826168146

Epoch: 6| Step: 3
Training loss: 1.3089116863216619
Validation loss: 2.445777604297514

Epoch: 6| Step: 4
Training loss: 2.0992953753213146
Validation loss: 2.4628300309634734

Epoch: 6| Step: 5
Training loss: 1.0520622075040296
Validation loss: 2.437871235274648

Epoch: 6| Step: 6
Training loss: 1.2824403769035424
Validation loss: 2.4301726454987658

Epoch: 6| Step: 7
Training loss: 1.0170241475234563
Validation loss: 2.3730441277546848

Epoch: 6| Step: 8
Training loss: 1.2007581541065295
Validation loss: 2.4446719201822384

Epoch: 6| Step: 9
Training loss: 1.127128917926309
Validation loss: 2.4164577545175536

Epoch: 6| Step: 10
Training loss: 1.4626432038972246
Validation loss: 2.3841986890213116

Epoch: 6| Step: 11
Training loss: 0.9753460441181774
Validation loss: 2.48969861219903

Epoch: 6| Step: 12
Training loss: 1.1696423943455236
Validation loss: 2.3876872260025137

Epoch: 6| Step: 13
Training loss: 0.951223133123805
Validation loss: 2.4023538835540053

Epoch: 419| Step: 0
Training loss: 0.9459854441988729
Validation loss: 2.4032367878242

Epoch: 6| Step: 1
Training loss: 0.8536203699850812
Validation loss: 2.4023480046892645

Epoch: 6| Step: 2
Training loss: 1.5334116411254077
Validation loss: 2.400673374613298

Epoch: 6| Step: 3
Training loss: 1.226356051619691
Validation loss: 2.3168517065908136

Epoch: 6| Step: 4
Training loss: 1.1275837685705385
Validation loss: 2.444836371459824

Epoch: 6| Step: 5
Training loss: 1.369961088699968
Validation loss: 2.3480512084666554

Epoch: 6| Step: 6
Training loss: 1.4942368420306693
Validation loss: 2.3697335233500496

Epoch: 6| Step: 7
Training loss: 0.7644887394471854
Validation loss: 2.3643847832949776

Epoch: 6| Step: 8
Training loss: 1.0768290484560183
Validation loss: 2.3489949278757973

Epoch: 6| Step: 9
Training loss: 0.9416107335541113
Validation loss: 2.3383535791891408

Epoch: 6| Step: 10
Training loss: 0.848301303673565
Validation loss: 2.4286172044210317

Epoch: 6| Step: 11
Training loss: 2.147594050522832
Validation loss: 2.3079569212231754

Epoch: 6| Step: 12
Training loss: 1.0218933337138918
Validation loss: 2.3287898725621448

Epoch: 6| Step: 13
Training loss: 1.3837093742216824
Validation loss: 2.385715293614323

Epoch: 420| Step: 0
Training loss: 0.8833395136011196
Validation loss: 2.419994909292501

Epoch: 6| Step: 1
Training loss: 1.10509837925224
Validation loss: 2.378619311314819

Epoch: 6| Step: 2
Training loss: 2.0591318777128462
Validation loss: 2.325546866593677

Epoch: 6| Step: 3
Training loss: 1.4752301052803223
Validation loss: 2.4458935114950355

Epoch: 6| Step: 4
Training loss: 0.9714841099498281
Validation loss: 2.3711649820206606

Epoch: 6| Step: 5
Training loss: 1.4954005296200872
Validation loss: 2.3521025891903076

Epoch: 6| Step: 6
Training loss: 1.342184618768053
Validation loss: 2.3821379095487134

Epoch: 6| Step: 7
Training loss: 0.8657047551730742
Validation loss: 2.4189459865438523

Epoch: 6| Step: 8
Training loss: 1.1365263471289175
Validation loss: 2.3582302392160996

Epoch: 6| Step: 9
Training loss: 0.5721369263379184
Validation loss: 2.3746527410926634

Epoch: 6| Step: 10
Training loss: 0.9998273700481803
Validation loss: 2.318323431814456

Epoch: 6| Step: 11
Training loss: 1.0772852183950454
Validation loss: 2.4346710650584646

Epoch: 6| Step: 12
Training loss: 1.267877340635606
Validation loss: 2.42550342494581

Epoch: 6| Step: 13
Training loss: 0.8596770709343615
Validation loss: 2.3768101471904353

Epoch: 421| Step: 0
Training loss: 0.7505243772960876
Validation loss: 2.367835790363401

Epoch: 6| Step: 1
Training loss: 1.078600626534949
Validation loss: 2.357177900096372

Epoch: 6| Step: 2
Training loss: 1.2789251588275286
Validation loss: 2.406584494963921

Epoch: 6| Step: 3
Training loss: 1.006948647910512
Validation loss: 2.3795120790925344

Epoch: 6| Step: 4
Training loss: 1.391707309921286
Validation loss: 2.3935756705440925

Epoch: 6| Step: 5
Training loss: 1.3454021233491005
Validation loss: 2.373242860006117

Epoch: 6| Step: 6
Training loss: 1.3004706759463194
Validation loss: 2.365222955166419

Epoch: 6| Step: 7
Training loss: 1.1468752660932935
Validation loss: 2.4043195140352522

Epoch: 6| Step: 8
Training loss: 0.963785649245146
Validation loss: 2.381141083655031

Epoch: 6| Step: 9
Training loss: 1.9905691716915588
Validation loss: 2.390709773836757

Epoch: 6| Step: 10
Training loss: 0.9422650357506993
Validation loss: 2.428890432403526

Epoch: 6| Step: 11
Training loss: 1.2288245463144851
Validation loss: 2.3706359351024386

Epoch: 6| Step: 12
Training loss: 0.9020597993689627
Validation loss: 2.3274091440520506

Epoch: 6| Step: 13
Training loss: 1.8110069176022017
Validation loss: 2.386378195010216

Epoch: 422| Step: 0
Training loss: 1.0106494805762833
Validation loss: 2.394975994811112

Epoch: 6| Step: 1
Training loss: 1.125226474854209
Validation loss: 2.4414717365629137

Epoch: 6| Step: 2
Training loss: 1.8070946695073193
Validation loss: 2.411266336182152

Epoch: 6| Step: 3
Training loss: 0.9655383000138524
Validation loss: 2.435373349844336

Epoch: 6| Step: 4
Training loss: 1.1802847152643334
Validation loss: 2.3527423440472877

Epoch: 6| Step: 5
Training loss: 1.1219598700848759
Validation loss: 2.3444231079917324

Epoch: 6| Step: 6
Training loss: 1.0873640830507907
Validation loss: 2.395363054671216

Epoch: 6| Step: 7
Training loss: 1.3791719780365395
Validation loss: 2.4107196868785628

Epoch: 6| Step: 8
Training loss: 1.473479023385738
Validation loss: 2.4224929492259903

Epoch: 6| Step: 9
Training loss: 1.3275893084698676
Validation loss: 2.3280903445511902

Epoch: 6| Step: 10
Training loss: 0.8797425762707748
Validation loss: 2.3812020876610265

Epoch: 6| Step: 11
Training loss: 1.0462518232140556
Validation loss: 2.33925622422569

Epoch: 6| Step: 12
Training loss: 1.529625322677779
Validation loss: 2.338061737145799

Epoch: 6| Step: 13
Training loss: 0.9338798563385062
Validation loss: 2.363896403012283

Epoch: 423| Step: 0
Training loss: 1.0557021170364116
Validation loss: 2.395472978739365

Epoch: 6| Step: 1
Training loss: 2.2413565661088395
Validation loss: 2.3966091624394097

Epoch: 6| Step: 2
Training loss: 1.450817942938481
Validation loss: 2.3724576682375145

Epoch: 6| Step: 3
Training loss: 0.8874576867453441
Validation loss: 2.433689663658616

Epoch: 6| Step: 4
Training loss: 1.0054567586781005
Validation loss: 2.3838572631957207

Epoch: 6| Step: 5
Training loss: 1.2096567087041277
Validation loss: 2.364506788064238

Epoch: 6| Step: 6
Training loss: 1.1072325637178333
Validation loss: 2.3881207225370384

Epoch: 6| Step: 7
Training loss: 1.0350688393592595
Validation loss: 2.347535970762329

Epoch: 6| Step: 8
Training loss: 1.4649384734998725
Validation loss: 2.351704123713038

Epoch: 6| Step: 9
Training loss: 0.9771434124259438
Validation loss: 2.32657215443642

Epoch: 6| Step: 10
Training loss: 0.9855977290607274
Validation loss: 2.3380364729869947

Epoch: 6| Step: 11
Training loss: 0.9031772149643207
Validation loss: 2.389350168366069

Epoch: 6| Step: 12
Training loss: 1.2740698806365525
Validation loss: 2.4015834343853566

Epoch: 6| Step: 13
Training loss: 0.8306823685398373
Validation loss: 2.4236708329867085

Epoch: 424| Step: 0
Training loss: 0.9825073265695518
Validation loss: 2.4472714902426493

Epoch: 6| Step: 1
Training loss: 0.9744488845814897
Validation loss: 2.446696884249429

Epoch: 6| Step: 2
Training loss: 1.043413046167293
Validation loss: 2.3336912439525004

Epoch: 6| Step: 3
Training loss: 1.3980307813401842
Validation loss: 2.438862796420592

Epoch: 6| Step: 4
Training loss: 2.316191948020648
Validation loss: 2.4807250611592697

Epoch: 6| Step: 5
Training loss: 1.1936067864756907
Validation loss: 2.377125939761923

Epoch: 6| Step: 6
Training loss: 0.9413839313821412
Validation loss: 2.43665179483913

Epoch: 6| Step: 7
Training loss: 1.236322677142297
Validation loss: 2.3663134468444045

Epoch: 6| Step: 8
Training loss: 0.7907333812384381
Validation loss: 2.3868885538761493

Epoch: 6| Step: 9
Training loss: 1.3912131105315226
Validation loss: 2.35996416365395

Epoch: 6| Step: 10
Training loss: 1.0433153012477523
Validation loss: 2.41736938887598

Epoch: 6| Step: 11
Training loss: 1.139748798517831
Validation loss: 2.308815020293408

Epoch: 6| Step: 12
Training loss: 0.8943990418130454
Validation loss: 2.324093526112491

Epoch: 6| Step: 13
Training loss: 0.914580304452896
Validation loss: 2.4284059238576905

Epoch: 425| Step: 0
Training loss: 0.9382457945617867
Validation loss: 2.380111896665772

Epoch: 6| Step: 1
Training loss: 1.1978627842381075
Validation loss: 2.468386161040413

Epoch: 6| Step: 2
Training loss: 0.9898080303006673
Validation loss: 2.3325397724879737

Epoch: 6| Step: 3
Training loss: 1.9736195242470769
Validation loss: 2.3502116636641177

Epoch: 6| Step: 4
Training loss: 1.2483183993747955
Validation loss: 2.319806780463065

Epoch: 6| Step: 5
Training loss: 0.9486895055168512
Validation loss: 2.3682222853043977

Epoch: 6| Step: 6
Training loss: 0.8710741117855365
Validation loss: 2.335536347126122

Epoch: 6| Step: 7
Training loss: 1.2141194530271195
Validation loss: 2.43255562542462

Epoch: 6| Step: 8
Training loss: 1.1720367828592502
Validation loss: 2.3791380978298506

Epoch: 6| Step: 9
Training loss: 0.8649319018862194
Validation loss: 2.4426022723540326

Epoch: 6| Step: 10
Training loss: 1.2628084089311555
Validation loss: 2.354928171099507

Epoch: 6| Step: 11
Training loss: 1.1991030360755026
Validation loss: 2.383751877527819

Epoch: 6| Step: 12
Training loss: 1.4571896382577332
Validation loss: 2.38535867905268

Epoch: 6| Step: 13
Training loss: 0.8668653903750339
Validation loss: 2.375488741531212

Epoch: 426| Step: 0
Training loss: 1.0850264755218249
Validation loss: 2.4410956539660837

Epoch: 6| Step: 1
Training loss: 0.9701450516700619
Validation loss: 2.359309616546561

Epoch: 6| Step: 2
Training loss: 2.0271774547193355
Validation loss: 2.4025927967044813

Epoch: 6| Step: 3
Training loss: 0.9525475550717438
Validation loss: 2.381004926318516

Epoch: 6| Step: 4
Training loss: 1.275089947014802
Validation loss: 2.3870029193355746

Epoch: 6| Step: 5
Training loss: 1.1707546728099145
Validation loss: 2.4059816660193034

Epoch: 6| Step: 6
Training loss: 0.9280335275290859
Validation loss: 2.377652675172143

Epoch: 6| Step: 7
Training loss: 1.216114324233673
Validation loss: 2.3808898237392615

Epoch: 6| Step: 8
Training loss: 1.4514951692370042
Validation loss: 2.3745137889772123

Epoch: 6| Step: 9
Training loss: 1.0875193648970964
Validation loss: 2.4273566160351465

Epoch: 6| Step: 10
Training loss: 0.8967594896425387
Validation loss: 2.2974319725843038

Epoch: 6| Step: 11
Training loss: 1.026036580391039
Validation loss: 2.377913465307887

Epoch: 6| Step: 12
Training loss: 1.3794979738591833
Validation loss: 2.3384385514553285

Epoch: 6| Step: 13
Training loss: 1.1097952355714795
Validation loss: 2.388481793896625

Epoch: 427| Step: 0
Training loss: 1.1002140313778488
Validation loss: 2.3496510772677186

Epoch: 6| Step: 1
Training loss: 1.3166734554421575
Validation loss: 2.397071260323856

Epoch: 6| Step: 2
Training loss: 1.1773951913471368
Validation loss: 2.298270346298021

Epoch: 6| Step: 3
Training loss: 0.9760167237103629
Validation loss: 2.386278324540417

Epoch: 6| Step: 4
Training loss: 0.7905205578480367
Validation loss: 2.4142884227291352

Epoch: 6| Step: 5
Training loss: 2.1085318681725256
Validation loss: 2.371737698009641

Epoch: 6| Step: 6
Training loss: 1.226214803021397
Validation loss: 2.3295989671676383

Epoch: 6| Step: 7
Training loss: 1.005556286822686
Validation loss: 2.4315722410474647

Epoch: 6| Step: 8
Training loss: 1.344965939072782
Validation loss: 2.383354656015961

Epoch: 6| Step: 9
Training loss: 0.9088222895208398
Validation loss: 2.337888940681071

Epoch: 6| Step: 10
Training loss: 1.0299199514856485
Validation loss: 2.3411291940088588

Epoch: 6| Step: 11
Training loss: 1.339003007205951
Validation loss: 2.3870346697802214

Epoch: 6| Step: 12
Training loss: 0.9980833640398887
Validation loss: 2.3529672604646605

Epoch: 6| Step: 13
Training loss: 0.7952681403539001
Validation loss: 2.337149700312925

Epoch: 428| Step: 0
Training loss: 1.4500701130983291
Validation loss: 2.355978482447505

Epoch: 6| Step: 1
Training loss: 1.127963771552796
Validation loss: 2.3828126473967237

Epoch: 6| Step: 2
Training loss: 1.1345483043267788
Validation loss: 2.3312239425545833

Epoch: 6| Step: 3
Training loss: 1.1472500741259912
Validation loss: 2.3713720836445287

Epoch: 6| Step: 4
Training loss: 1.1218954270397248
Validation loss: 2.391352435122624

Epoch: 6| Step: 5
Training loss: 1.185950975504875
Validation loss: 2.4744016703249367

Epoch: 6| Step: 6
Training loss: 0.8459624494150508
Validation loss: 2.458275074387532

Epoch: 6| Step: 7
Training loss: 1.257744828767255
Validation loss: 2.40961744051838

Epoch: 6| Step: 8
Training loss: 1.1009886850092658
Validation loss: 2.4083687028978313

Epoch: 6| Step: 9
Training loss: 0.7479699794997451
Validation loss: 2.341837774935602

Epoch: 6| Step: 10
Training loss: 1.8782509912259489
Validation loss: 2.4438323746297947

Epoch: 6| Step: 11
Training loss: 1.1128689186386784
Validation loss: 2.417430000415398

Epoch: 6| Step: 12
Training loss: 0.889154156618024
Validation loss: 2.3626513025383606

Epoch: 6| Step: 13
Training loss: 1.1190830502171796
Validation loss: 2.3075833244728106

Epoch: 429| Step: 0
Training loss: 1.5154643809362445
Validation loss: 2.3999445735989884

Epoch: 6| Step: 1
Training loss: 1.0604717305294546
Validation loss: 2.321153258818229

Epoch: 6| Step: 2
Training loss: 1.0395065162017756
Validation loss: 2.345512085974081

Epoch: 6| Step: 3
Training loss: 1.755690179295957
Validation loss: 2.376319928655007

Epoch: 6| Step: 4
Training loss: 0.8785158095438057
Validation loss: 2.304669128200137

Epoch: 6| Step: 5
Training loss: 1.0691100556948028
Validation loss: 2.251245754251354

Epoch: 6| Step: 6
Training loss: 1.0478546910448112
Validation loss: 2.3593517362896503

Epoch: 6| Step: 7
Training loss: 1.059394899254536
Validation loss: 2.406572942180512

Epoch: 6| Step: 8
Training loss: 1.3184061677893788
Validation loss: 2.3250159975697433

Epoch: 6| Step: 9
Training loss: 0.9736012843009922
Validation loss: 2.4008196595826425

Epoch: 6| Step: 10
Training loss: 1.1735506412093644
Validation loss: 2.4377440642493045

Epoch: 6| Step: 11
Training loss: 1.0396189526181028
Validation loss: 2.3763352506612336

Epoch: 6| Step: 12
Training loss: 1.2429097792796613
Validation loss: 2.3897078345405913

Epoch: 6| Step: 13
Training loss: 1.015835256087059
Validation loss: 2.364337339331582

Epoch: 430| Step: 0
Training loss: 0.590782176907147
Validation loss: 2.393966474640345

Epoch: 6| Step: 1
Training loss: 1.231295304989792
Validation loss: 2.3327165918758355

Epoch: 6| Step: 2
Training loss: 1.0126627049581027
Validation loss: 2.3554397554285917

Epoch: 6| Step: 3
Training loss: 1.6205286718678646
Validation loss: 2.450631811123176

Epoch: 6| Step: 4
Training loss: 0.9369787674557208
Validation loss: 2.3807894931433613

Epoch: 6| Step: 5
Training loss: 0.8196039318514484
Validation loss: 2.411349793234177

Epoch: 6| Step: 6
Training loss: 0.8214225887293959
Validation loss: 2.366935919943143

Epoch: 6| Step: 7
Training loss: 1.0556909379528794
Validation loss: 2.386312527072178

Epoch: 6| Step: 8
Training loss: 1.2994797527589668
Validation loss: 2.401735934975564

Epoch: 6| Step: 9
Training loss: 1.127465619157228
Validation loss: 2.3015223801370284

Epoch: 6| Step: 10
Training loss: 0.8193456128609673
Validation loss: 2.388466046949823

Epoch: 6| Step: 11
Training loss: 1.9475019152806943
Validation loss: 2.4146303265120004

Epoch: 6| Step: 12
Training loss: 1.3258570885982741
Validation loss: 2.4554880816594626

Epoch: 6| Step: 13
Training loss: 1.7737910384631905
Validation loss: 2.3998758894950605

Epoch: 431| Step: 0
Training loss: 1.0502998355373212
Validation loss: 2.482813576066708

Epoch: 6| Step: 1
Training loss: 1.1019947475508949
Validation loss: 2.400536658211083

Epoch: 6| Step: 2
Training loss: 0.8260731739579189
Validation loss: 2.333575278657691

Epoch: 6| Step: 3
Training loss: 1.1776052628784386
Validation loss: 2.3274979348055274

Epoch: 6| Step: 4
Training loss: 0.933418417072406
Validation loss: 2.326789221135244

Epoch: 6| Step: 5
Training loss: 1.4345428069446604
Validation loss: 2.3786088384531983

Epoch: 6| Step: 6
Training loss: 0.7447117493619638
Validation loss: 2.372933116073167

Epoch: 6| Step: 7
Training loss: 1.003239035140803
Validation loss: 2.37189921108504

Epoch: 6| Step: 8
Training loss: 1.1769041358230063
Validation loss: 2.3510020623238543

Epoch: 6| Step: 9
Training loss: 1.2050726842525579
Validation loss: 2.345367396412741

Epoch: 6| Step: 10
Training loss: 1.2651887306584662
Validation loss: 2.380924959149348

Epoch: 6| Step: 11
Training loss: 1.0272595621287368
Validation loss: 2.3614701789038377

Epoch: 6| Step: 12
Training loss: 1.1210009174258095
Validation loss: 2.3944489508533153

Epoch: 6| Step: 13
Training loss: 2.3438830528639714
Validation loss: 2.434514713691934

Epoch: 432| Step: 0
Training loss: 1.0243437736551029
Validation loss: 2.295115102689853

Epoch: 6| Step: 1
Training loss: 1.1428788791871454
Validation loss: 2.331795698531807

Epoch: 6| Step: 2
Training loss: 1.1965503142666143
Validation loss: 2.3043135511870525

Epoch: 6| Step: 3
Training loss: 1.033985382644514
Validation loss: 2.3734517353585827

Epoch: 6| Step: 4
Training loss: 1.2163084467363672
Validation loss: 2.4130872293670365

Epoch: 6| Step: 5
Training loss: 1.2814793265197395
Validation loss: 2.345090224484202

Epoch: 6| Step: 6
Training loss: 1.0301189577980623
Validation loss: 2.4070719090443395

Epoch: 6| Step: 7
Training loss: 1.1008365484552167
Validation loss: 2.3427839272058

Epoch: 6| Step: 8
Training loss: 0.9428871505057576
Validation loss: 2.369801082995797

Epoch: 6| Step: 9
Training loss: 0.984746771953141
Validation loss: 2.3486877630091754

Epoch: 6| Step: 10
Training loss: 1.149748229371939
Validation loss: 2.396050641734305

Epoch: 6| Step: 11
Training loss: 1.9175833569329217
Validation loss: 2.328594053975517

Epoch: 6| Step: 12
Training loss: 1.0295059599775678
Validation loss: 2.387553757526902

Epoch: 6| Step: 13
Training loss: 1.3464871850577864
Validation loss: 2.3284185400264783

Epoch: 433| Step: 0
Training loss: 1.0700432654573186
Validation loss: 2.353718268353577

Epoch: 6| Step: 1
Training loss: 1.070399371332004
Validation loss: 2.3475985381824063

Epoch: 6| Step: 2
Training loss: 1.0733418162427286
Validation loss: 2.341123341536241

Epoch: 6| Step: 3
Training loss: 1.9002354275255458
Validation loss: 2.391796843873559

Epoch: 6| Step: 4
Training loss: 1.2970294171058305
Validation loss: 2.4038094362778755

Epoch: 6| Step: 5
Training loss: 1.024841045056772
Validation loss: 2.450053095205616

Epoch: 6| Step: 6
Training loss: 1.2297033442212062
Validation loss: 2.4463321662262234

Epoch: 6| Step: 7
Training loss: 1.1022939215198257
Validation loss: 2.3830424934259242

Epoch: 6| Step: 8
Training loss: 0.462107079726748
Validation loss: 2.355305682458067

Epoch: 6| Step: 9
Training loss: 1.072076944173274
Validation loss: 2.4149443677655142

Epoch: 6| Step: 10
Training loss: 0.9222814342883904
Validation loss: 2.4081936494661664

Epoch: 6| Step: 11
Training loss: 0.9567866732982548
Validation loss: 2.383555962854885

Epoch: 6| Step: 12
Training loss: 1.3907356646791726
Validation loss: 2.3445796621995476

Epoch: 6| Step: 13
Training loss: 1.189806004186637
Validation loss: 2.340913616361732

Epoch: 434| Step: 0
Training loss: 0.9527843992419015
Validation loss: 2.4493353452970594

Epoch: 6| Step: 1
Training loss: 0.7609765373728524
Validation loss: 2.3430739829980345

Epoch: 6| Step: 2
Training loss: 1.2518351435303927
Validation loss: 2.386167869462806

Epoch: 6| Step: 3
Training loss: 1.1612156613039177
Validation loss: 2.4111914267175196

Epoch: 6| Step: 4
Training loss: 1.0078063491515306
Validation loss: 2.4166281526981033

Epoch: 6| Step: 5
Training loss: 1.900244586661344
Validation loss: 2.383483826578396

Epoch: 6| Step: 6
Training loss: 1.1543145347832158
Validation loss: 2.3809907353003057

Epoch: 6| Step: 7
Training loss: 0.8524919040217197
Validation loss: 2.4145361795382785

Epoch: 6| Step: 8
Training loss: 0.7768879996920739
Validation loss: 2.324157753751788

Epoch: 6| Step: 9
Training loss: 1.6507946355072107
Validation loss: 2.343643117128793

Epoch: 6| Step: 10
Training loss: 1.0538387698322327
Validation loss: 2.386321566840869

Epoch: 6| Step: 11
Training loss: 1.0094989594203352
Validation loss: 2.405649762080146

Epoch: 6| Step: 12
Training loss: 1.1401157025967221
Validation loss: 2.4053109665579417

Epoch: 6| Step: 13
Training loss: 1.4738766093788422
Validation loss: 2.3477721247208243

Epoch: 435| Step: 0
Training loss: 1.075836406282803
Validation loss: 2.345145318672781

Epoch: 6| Step: 1
Training loss: 1.9940107193049397
Validation loss: 2.332580740220502

Epoch: 6| Step: 2
Training loss: 0.6644452506646645
Validation loss: 2.43442968872905

Epoch: 6| Step: 3
Training loss: 1.0541835569956044
Validation loss: 2.3940379277581902

Epoch: 6| Step: 4
Training loss: 1.2527126442404566
Validation loss: 2.441131896127033

Epoch: 6| Step: 5
Training loss: 1.1929770198952572
Validation loss: 2.336675813889996

Epoch: 6| Step: 6
Training loss: 1.0124376018747128
Validation loss: 2.3869389489028605

Epoch: 6| Step: 7
Training loss: 1.1871013976240474
Validation loss: 2.413166493010772

Epoch: 6| Step: 8
Training loss: 1.1959569353209474
Validation loss: 2.432359745117852

Epoch: 6| Step: 9
Training loss: 1.3871506139393293
Validation loss: 2.3598202792699756

Epoch: 6| Step: 10
Training loss: 1.2515222816815568
Validation loss: 2.395732356043927

Epoch: 6| Step: 11
Training loss: 0.8196058590276956
Validation loss: 2.323551519618281

Epoch: 6| Step: 12
Training loss: 0.9176909330683529
Validation loss: 2.430851222706991

Epoch: 6| Step: 13
Training loss: 0.7238021837702766
Validation loss: 2.4021565404807363

Epoch: 436| Step: 0
Training loss: 0.9987512182197255
Validation loss: 2.3540183792070764

Epoch: 6| Step: 1
Training loss: 0.8482541555341662
Validation loss: 2.349845831166085

Epoch: 6| Step: 2
Training loss: 0.8429353808143526
Validation loss: 2.3770848338171193

Epoch: 6| Step: 3
Training loss: 1.4021829071887884
Validation loss: 2.3699249421219526

Epoch: 6| Step: 4
Training loss: 1.4707470566873961
Validation loss: 2.426336016456738

Epoch: 6| Step: 5
Training loss: 1.1392058859164096
Validation loss: 2.402554230165397

Epoch: 6| Step: 6
Training loss: 1.249347802725359
Validation loss: 2.365872361946085

Epoch: 6| Step: 7
Training loss: 1.2161505928463756
Validation loss: 2.359091753882061

Epoch: 6| Step: 8
Training loss: 0.6287931731552343
Validation loss: 2.3683146124531826

Epoch: 6| Step: 9
Training loss: 0.9589713847412886
Validation loss: 2.3728534883859127

Epoch: 6| Step: 10
Training loss: 1.3717916076618122
Validation loss: 2.38946996124994

Epoch: 6| Step: 11
Training loss: 0.8725566810625371
Validation loss: 2.353194673058528

Epoch: 6| Step: 12
Training loss: 2.0312575120053404
Validation loss: 2.4484644522815806

Epoch: 6| Step: 13
Training loss: 1.0631364150558584
Validation loss: 2.3217670280037854

Epoch: 437| Step: 0
Training loss: 1.2364494179862455
Validation loss: 2.271117779811525

Epoch: 6| Step: 1
Training loss: 1.489060485774436
Validation loss: 2.413884446085942

Epoch: 6| Step: 2
Training loss: 1.150346687138426
Validation loss: 2.3493912926307914

Epoch: 6| Step: 3
Training loss: 0.7779865003753185
Validation loss: 2.4180405742085855

Epoch: 6| Step: 4
Training loss: 1.0670388828975992
Validation loss: 2.4118648106650333

Epoch: 6| Step: 5
Training loss: 0.9419767621711421
Validation loss: 2.390194071145165

Epoch: 6| Step: 6
Training loss: 0.8294379065429758
Validation loss: 2.4573310507290356

Epoch: 6| Step: 7
Training loss: 2.0739427515808426
Validation loss: 2.4086570936281793

Epoch: 6| Step: 8
Training loss: 1.249309348995398
Validation loss: 2.3759244496999754

Epoch: 6| Step: 9
Training loss: 1.051428613174035
Validation loss: 2.2781366040953115

Epoch: 6| Step: 10
Training loss: 1.0817254801563823
Validation loss: 2.290401125149213

Epoch: 6| Step: 11
Training loss: 0.9969096712881387
Validation loss: 2.4026481530937818

Epoch: 6| Step: 12
Training loss: 1.1570240213707979
Validation loss: 2.3507632196330963

Epoch: 6| Step: 13
Training loss: 0.748757445691619
Validation loss: 2.354023958396911

Epoch: 438| Step: 0
Training loss: 1.3635594649740304
Validation loss: 2.312852750001931

Epoch: 6| Step: 1
Training loss: 1.247012000337445
Validation loss: 2.3516856169387506

Epoch: 6| Step: 2
Training loss: 0.9882963880502851
Validation loss: 2.329910853104412

Epoch: 6| Step: 3
Training loss: 1.1714584627557898
Validation loss: 2.276857081119402

Epoch: 6| Step: 4
Training loss: 2.100711806324514
Validation loss: 2.317082944262253

Epoch: 6| Step: 5
Training loss: 0.9740696331762858
Validation loss: 2.3227678620360805

Epoch: 6| Step: 6
Training loss: 1.4583397274785417
Validation loss: 2.349413776566395

Epoch: 6| Step: 7
Training loss: 0.9098771940410043
Validation loss: 2.429491848522176

Epoch: 6| Step: 8
Training loss: 1.112591231816515
Validation loss: 2.3668346474391173

Epoch: 6| Step: 9
Training loss: 0.872983174912389
Validation loss: 2.3820777872565184

Epoch: 6| Step: 10
Training loss: 0.8053969431707111
Validation loss: 2.3687290719850496

Epoch: 6| Step: 11
Training loss: 1.164449640196532
Validation loss: 2.416224132227684

Epoch: 6| Step: 12
Training loss: 1.5185286246758607
Validation loss: 2.3592870965240196

Epoch: 6| Step: 13
Training loss: 1.0897042243271422
Validation loss: 2.386030414181676

Epoch: 439| Step: 0
Training loss: 0.8123557256104609
Validation loss: 2.4144629790646865

Epoch: 6| Step: 1
Training loss: 1.1700881559628784
Validation loss: 2.3723190019799967

Epoch: 6| Step: 2
Training loss: 0.5843578152501226
Validation loss: 2.356930864161047

Epoch: 6| Step: 3
Training loss: 2.0561780273456773
Validation loss: 2.327025496411823

Epoch: 6| Step: 4
Training loss: 1.1333840868375156
Validation loss: 2.4008503100610246

Epoch: 6| Step: 5
Training loss: 0.8179050176616519
Validation loss: 2.422429849325642

Epoch: 6| Step: 6
Training loss: 0.9025776217358603
Validation loss: 2.382176278756102

Epoch: 6| Step: 7
Training loss: 1.3253024457834832
Validation loss: 2.360251200095487

Epoch: 6| Step: 8
Training loss: 1.058219759146065
Validation loss: 2.362153032785908

Epoch: 6| Step: 9
Training loss: 1.3587893397331092
Validation loss: 2.3393777505176403

Epoch: 6| Step: 10
Training loss: 0.9255799022251603
Validation loss: 2.3514085198063173

Epoch: 6| Step: 11
Training loss: 0.9788744300974099
Validation loss: 2.3930718863689893

Epoch: 6| Step: 12
Training loss: 1.2183126985513268
Validation loss: 2.4029833526707574

Epoch: 6| Step: 13
Training loss: 0.6493358134689722
Validation loss: 2.428234307153713

Epoch: 440| Step: 0
Training loss: 1.1705677115805901
Validation loss: 2.337778883818711

Epoch: 6| Step: 1
Training loss: 0.7722567398108142
Validation loss: 2.4188922722906105

Epoch: 6| Step: 2
Training loss: 1.878097836112349
Validation loss: 2.370127767108985

Epoch: 6| Step: 3
Training loss: 1.1980166794311553
Validation loss: 2.401682859485471

Epoch: 6| Step: 4
Training loss: 1.183458780077729
Validation loss: 2.480767432470217

Epoch: 6| Step: 5
Training loss: 1.0753455338618632
Validation loss: 2.3473692919891422

Epoch: 6| Step: 6
Training loss: 0.9298876378671929
Validation loss: 2.3770794662115264

Epoch: 6| Step: 7
Training loss: 0.9938824811233341
Validation loss: 2.41880908925791

Epoch: 6| Step: 8
Training loss: 1.406462165933905
Validation loss: 2.3997465895874317

Epoch: 6| Step: 9
Training loss: 0.7770606057232866
Validation loss: 2.3656137111654174

Epoch: 6| Step: 10
Training loss: 0.9797396437595747
Validation loss: 2.3452055558948386

Epoch: 6| Step: 11
Training loss: 0.9029792100386667
Validation loss: 2.3331824669942764

Epoch: 6| Step: 12
Training loss: 1.261548577043548
Validation loss: 2.4766387094422924

Epoch: 6| Step: 13
Training loss: 1.1847115956811625
Validation loss: 2.4010202965081113

Epoch: 441| Step: 0
Training loss: 0.935413964373134
Validation loss: 2.4335560861323455

Epoch: 6| Step: 1
Training loss: 1.1092851091958196
Validation loss: 2.403876819954538

Epoch: 6| Step: 2
Training loss: 1.8647436005604896
Validation loss: 2.3481106134412997

Epoch: 6| Step: 3
Training loss: 1.4463965397270133
Validation loss: 2.4100379709401123

Epoch: 6| Step: 4
Training loss: 0.8570319746878524
Validation loss: 2.436025208584621

Epoch: 6| Step: 5
Training loss: 1.1129420784396409
Validation loss: 2.3644109184878577

Epoch: 6| Step: 6
Training loss: 1.418020704594417
Validation loss: 2.341721001160624

Epoch: 6| Step: 7
Training loss: 1.013838855315942
Validation loss: 2.4543409550733215

Epoch: 6| Step: 8
Training loss: 1.451324660214986
Validation loss: 2.347301246171368

Epoch: 6| Step: 9
Training loss: 1.1187654035988934
Validation loss: 2.3669809842727787

Epoch: 6| Step: 10
Training loss: 0.9124404992339686
Validation loss: 2.3520605336444698

Epoch: 6| Step: 11
Training loss: 1.0496872663256336
Validation loss: 2.3858570087045825

Epoch: 6| Step: 12
Training loss: 0.8196766887014351
Validation loss: 2.3732607836022788

Epoch: 6| Step: 13
Training loss: 0.9665923856005542
Validation loss: 2.382095577112791

Epoch: 442| Step: 0
Training loss: 0.901828106608132
Validation loss: 2.356064181914676

Epoch: 6| Step: 1
Training loss: 0.9519318789184105
Validation loss: 2.3901647427234853

Epoch: 6| Step: 2
Training loss: 1.920212375398912
Validation loss: 2.3604854721384876

Epoch: 6| Step: 3
Training loss: 1.1821413602807154
Validation loss: 2.3161715196437647

Epoch: 6| Step: 4
Training loss: 1.3219523882927258
Validation loss: 2.3623299276122025

Epoch: 6| Step: 5
Training loss: 1.1398897806224373
Validation loss: 2.3748255969499596

Epoch: 6| Step: 6
Training loss: 1.066396971721599
Validation loss: 2.379474184075787

Epoch: 6| Step: 7
Training loss: 1.1713304398800743
Validation loss: 2.405602108888116

Epoch: 6| Step: 8
Training loss: 0.876570314314719
Validation loss: 2.3538628481144945

Epoch: 6| Step: 9
Training loss: 1.1284230395953783
Validation loss: 2.415665442106667

Epoch: 6| Step: 10
Training loss: 1.3781369578562848
Validation loss: 2.3887061430706287

Epoch: 6| Step: 11
Training loss: 1.0443060941125852
Validation loss: 2.345878659329581

Epoch: 6| Step: 12
Training loss: 0.8831322352605001
Validation loss: 2.350074446333941

Epoch: 6| Step: 13
Training loss: 1.1360507326214986
Validation loss: 2.465856541111913

Epoch: 443| Step: 0
Training loss: 1.1396784578241328
Validation loss: 2.450694310416621

Epoch: 6| Step: 1
Training loss: 2.321287829984948
Validation loss: 2.425158011698347

Epoch: 6| Step: 2
Training loss: 1.0874559503162295
Validation loss: 2.4517619480196897

Epoch: 6| Step: 3
Training loss: 0.9977268071567525
Validation loss: 2.4073251086510146

Epoch: 6| Step: 4
Training loss: 1.196319206013724
Validation loss: 2.4299192433805326

Epoch: 6| Step: 5
Training loss: 0.953072874801376
Validation loss: 2.3509297079419715

Epoch: 6| Step: 6
Training loss: 1.2835861400859276
Validation loss: 2.431316774727554

Epoch: 6| Step: 7
Training loss: 0.7083360213808404
Validation loss: 2.3990078119395957

Epoch: 6| Step: 8
Training loss: 0.9301707830820439
Validation loss: 2.4441345946581614

Epoch: 6| Step: 9
Training loss: 1.045983803450459
Validation loss: 2.3991788874200872

Epoch: 6| Step: 10
Training loss: 1.2372997738470408
Validation loss: 2.411375929715911

Epoch: 6| Step: 11
Training loss: 0.8364238571973273
Validation loss: 2.36249458402217

Epoch: 6| Step: 12
Training loss: 1.2693545174460497
Validation loss: 2.3454343123932606

Epoch: 6| Step: 13
Training loss: 0.9359592492533088
Validation loss: 2.3421359886547983

Epoch: 444| Step: 0
Training loss: 0.8547289710993539
Validation loss: 2.28253426323246

Epoch: 6| Step: 1
Training loss: 1.1715153460146717
Validation loss: 2.347981869463656

Epoch: 6| Step: 2
Training loss: 1.2717725014215433
Validation loss: 2.3170622144968696

Epoch: 6| Step: 3
Training loss: 0.9689903576374096
Validation loss: 2.327535092736802

Epoch: 6| Step: 4
Training loss: 1.0828758826703002
Validation loss: 2.3465259391656565

Epoch: 6| Step: 5
Training loss: 1.0791814299841487
Validation loss: 2.3956893809882662

Epoch: 6| Step: 6
Training loss: 1.194447472418168
Validation loss: 2.3331363762587953

Epoch: 6| Step: 7
Training loss: 1.1331627139986515
Validation loss: 2.3479969063539476

Epoch: 6| Step: 8
Training loss: 0.9144941109748717
Validation loss: 2.2942302534938563

Epoch: 6| Step: 9
Training loss: 1.1673979113787707
Validation loss: 2.3486914823620357

Epoch: 6| Step: 10
Training loss: 2.001551264925655
Validation loss: 2.4201296399718077

Epoch: 6| Step: 11
Training loss: 1.2119626535761447
Validation loss: 2.4041096160302096

Epoch: 6| Step: 12
Training loss: 0.9163785756282959
Validation loss: 2.3733923846158835

Epoch: 6| Step: 13
Training loss: 0.8838650665480295
Validation loss: 2.376930316990851

Epoch: 445| Step: 0
Training loss: 0.9007814763011797
Validation loss: 2.2921962211959634

Epoch: 6| Step: 1
Training loss: 0.7584895619307238
Validation loss: 2.332989421966307

Epoch: 6| Step: 2
Training loss: 1.332306998340872
Validation loss: 2.43022581400038

Epoch: 6| Step: 3
Training loss: 1.0943770654681728
Validation loss: 2.373063154226777

Epoch: 6| Step: 4
Training loss: 2.0590955205977104
Validation loss: 2.383993176974655

Epoch: 6| Step: 5
Training loss: 0.8533894251353964
Validation loss: 2.378514486852079

Epoch: 6| Step: 6
Training loss: 1.4752870732924006
Validation loss: 2.31805989077667

Epoch: 6| Step: 7
Training loss: 1.0003896192659554
Validation loss: 2.416076327268543

Epoch: 6| Step: 8
Training loss: 1.2030554416910597
Validation loss: 2.338854270980059

Epoch: 6| Step: 9
Training loss: 0.9157658543486128
Validation loss: 2.359756255291356

Epoch: 6| Step: 10
Training loss: 1.1996648499242861
Validation loss: 2.3598590743506898

Epoch: 6| Step: 11
Training loss: 1.141181809894038
Validation loss: 2.3454589039011795

Epoch: 6| Step: 12
Training loss: 1.2744918857943217
Validation loss: 2.3519025774811593

Epoch: 6| Step: 13
Training loss: 0.9727608191722572
Validation loss: 2.442914413622906

Epoch: 446| Step: 0
Training loss: 1.1963266794946688
Validation loss: 2.4428903770887214

Epoch: 6| Step: 1
Training loss: 0.9190902676711731
Validation loss: 2.348751280997639

Epoch: 6| Step: 2
Training loss: 1.2817307012424675
Validation loss: 2.4475065356842323

Epoch: 6| Step: 3
Training loss: 0.9828536978669957
Validation loss: 2.431639790006658

Epoch: 6| Step: 4
Training loss: 1.0234612615025478
Validation loss: 2.3911696785429513

Epoch: 6| Step: 5
Training loss: 1.0465456885886673
Validation loss: 2.482439806010052

Epoch: 6| Step: 6
Training loss: 1.105279589533263
Validation loss: 2.327749387331035

Epoch: 6| Step: 7
Training loss: 1.361566290142045
Validation loss: 2.3732703926681107

Epoch: 6| Step: 8
Training loss: 0.9989986174213973
Validation loss: 2.3204267008370563

Epoch: 6| Step: 9
Training loss: 0.8661714392153708
Validation loss: 2.3705017417939054

Epoch: 6| Step: 10
Training loss: 1.866361171837508
Validation loss: 2.387754824156107

Epoch: 6| Step: 11
Training loss: 1.4065329373025863
Validation loss: 2.367269911946335

Epoch: 6| Step: 12
Training loss: 0.9316489101337411
Validation loss: 2.3562534977117253

Epoch: 6| Step: 13
Training loss: 0.9362161428545814
Validation loss: 2.255455767611157

Epoch: 447| Step: 0
Training loss: 1.6691384424168096
Validation loss: 2.3887131544980242

Epoch: 6| Step: 1
Training loss: 1.4278800670844778
Validation loss: 2.362285912970419

Epoch: 6| Step: 2
Training loss: 1.3778848296068085
Validation loss: 2.3593798765487817

Epoch: 6| Step: 3
Training loss: 1.8308393102498248
Validation loss: 2.3648443688266894

Epoch: 6| Step: 4
Training loss: 0.8655744104027988
Validation loss: 2.3657369328946234

Epoch: 6| Step: 5
Training loss: 0.9025845557252599
Validation loss: 2.36586866147612

Epoch: 6| Step: 6
Training loss: 0.4788284213624878
Validation loss: 2.3919912036673376

Epoch: 6| Step: 7
Training loss: 1.1739608004165265
Validation loss: 2.395464601716397

Epoch: 6| Step: 8
Training loss: 1.097632302671241
Validation loss: 2.4205713230663033

Epoch: 6| Step: 9
Training loss: 0.953895445066551
Validation loss: 2.402154805172854

Epoch: 6| Step: 10
Training loss: 0.6316662048935355
Validation loss: 2.3129765685486308

Epoch: 6| Step: 11
Training loss: 0.715261410296513
Validation loss: 2.3716361268221906

Epoch: 6| Step: 12
Training loss: 1.1507239385086505
Validation loss: 2.4566734863820843

Epoch: 6| Step: 13
Training loss: 0.5658247494877486
Validation loss: 2.350409322059802

Epoch: 448| Step: 0
Training loss: 0.5264711578109386
Validation loss: 2.462933054094662

Epoch: 6| Step: 1
Training loss: 1.0364984986974772
Validation loss: 2.3178443801474082

Epoch: 6| Step: 2
Training loss: 1.4590381372394587
Validation loss: 2.3637039304224476

Epoch: 6| Step: 3
Training loss: 1.848672986286769
Validation loss: 2.4239287042899513

Epoch: 6| Step: 4
Training loss: 0.8960310178181741
Validation loss: 2.3566164448289246

Epoch: 6| Step: 5
Training loss: 1.0632534160796827
Validation loss: 2.320386859786021

Epoch: 6| Step: 6
Training loss: 0.5630697967195392
Validation loss: 2.326462935243368

Epoch: 6| Step: 7
Training loss: 1.4630170087627405
Validation loss: 2.3684134484489654

Epoch: 6| Step: 8
Training loss: 1.0767904120647562
Validation loss: 2.3426747295410775

Epoch: 6| Step: 9
Training loss: 0.98336731332054
Validation loss: 2.3851516557795835

Epoch: 6| Step: 10
Training loss: 1.2750655924062708
Validation loss: 2.34553258342744

Epoch: 6| Step: 11
Training loss: 0.9562563191622707
Validation loss: 2.3965944508800834

Epoch: 6| Step: 12
Training loss: 0.9509407718337652
Validation loss: 2.3319200789602617

Epoch: 6| Step: 13
Training loss: 1.2319143371649461
Validation loss: 2.3113140445266414

Epoch: 449| Step: 0
Training loss: 1.0727912434473037
Validation loss: 2.347253111228919

Epoch: 6| Step: 1
Training loss: 1.102168464377292
Validation loss: 2.361083881632149

Epoch: 6| Step: 2
Training loss: 1.5059670336839943
Validation loss: 2.3349784165959035

Epoch: 6| Step: 3
Training loss: 0.9749694648264915
Validation loss: 2.4409211862722646

Epoch: 6| Step: 4
Training loss: 1.0151783474546765
Validation loss: 2.3524135684392813

Epoch: 6| Step: 5
Training loss: 1.9912166249267416
Validation loss: 2.365550249847488

Epoch: 6| Step: 6
Training loss: 1.2894226033626683
Validation loss: 2.358023466303362

Epoch: 6| Step: 7
Training loss: 0.8904314332724441
Validation loss: 2.3889355621141033

Epoch: 6| Step: 8
Training loss: 0.744883809469833
Validation loss: 2.334729824540302

Epoch: 6| Step: 9
Training loss: 0.9341083847930659
Validation loss: 2.3457413371676608

Epoch: 6| Step: 10
Training loss: 1.1839776250683953
Validation loss: 2.34529283667024

Epoch: 6| Step: 11
Training loss: 1.1435466606451317
Validation loss: 2.317113436684285

Epoch: 6| Step: 12
Training loss: 0.9397996037516679
Validation loss: 2.2681881695205344

Epoch: 6| Step: 13
Training loss: 0.7509884678327284
Validation loss: 2.447284572019157

Epoch: 450| Step: 0
Training loss: 0.9966015886240895
Validation loss: 2.4362986711902948

Epoch: 6| Step: 1
Training loss: 1.020103381752053
Validation loss: 2.3181964537703608

Epoch: 6| Step: 2
Training loss: 1.973330482607578
Validation loss: 2.435856919817095

Epoch: 6| Step: 3
Training loss: 0.6246389299739893
Validation loss: 2.3757636251815994

Epoch: 6| Step: 4
Training loss: 0.9521965445078612
Validation loss: 2.4346323343316563

Epoch: 6| Step: 5
Training loss: 1.1389866912271907
Validation loss: 2.308642315097375

Epoch: 6| Step: 6
Training loss: 1.21986455571992
Validation loss: 2.4347021443837673

Epoch: 6| Step: 7
Training loss: 0.9557428211757776
Validation loss: 2.4474226628335165

Epoch: 6| Step: 8
Training loss: 0.9071275145764065
Validation loss: 2.364780854339902

Epoch: 6| Step: 9
Training loss: 0.9172815875740692
Validation loss: 2.283888417818001

Epoch: 6| Step: 10
Training loss: 0.9358654395688031
Validation loss: 2.3644706789948584

Epoch: 6| Step: 11
Training loss: 1.3113812719625446
Validation loss: 2.393075757957559

Epoch: 6| Step: 12
Training loss: 1.2641444081857556
Validation loss: 2.3363700145546287

Epoch: 6| Step: 13
Training loss: 0.9925770332843852
Validation loss: 2.2913397429026916

Epoch: 451| Step: 0
Training loss: 0.9310612506447078
Validation loss: 2.378275980162978

Epoch: 6| Step: 1
Training loss: 0.9209647129518271
Validation loss: 2.2792797860369785

Epoch: 6| Step: 2
Training loss: 0.8891212752344784
Validation loss: 2.3723640342958525

Epoch: 6| Step: 3
Training loss: 1.0503451779068038
Validation loss: 2.3403579317054826

Epoch: 6| Step: 4
Training loss: 0.9279610768450719
Validation loss: 2.3033840007598276

Epoch: 6| Step: 5
Training loss: 1.9558225390159827
Validation loss: 2.3101019760335326

Epoch: 6| Step: 6
Training loss: 0.9266791837919471
Validation loss: 2.3066488639228235

Epoch: 6| Step: 7
Training loss: 1.022535144696248
Validation loss: 2.372459651649266

Epoch: 6| Step: 8
Training loss: 1.303497411265142
Validation loss: 2.397370206554903

Epoch: 6| Step: 9
Training loss: 0.9087633599475937
Validation loss: 2.364097881118121

Epoch: 6| Step: 10
Training loss: 1.1267083231055075
Validation loss: 2.3707956698173462

Epoch: 6| Step: 11
Training loss: 1.1085256091864675
Validation loss: 2.3749736898850693

Epoch: 6| Step: 12
Training loss: 0.8178296616721061
Validation loss: 2.3557589307356928

Epoch: 6| Step: 13
Training loss: 1.3887709355600364
Validation loss: 2.389166821366842

Epoch: 452| Step: 0
Training loss: 0.6735750469459625
Validation loss: 2.311912620553333

Epoch: 6| Step: 1
Training loss: 1.2843721542883764
Validation loss: 2.363753891899475

Epoch: 6| Step: 2
Training loss: 1.162074702410802
Validation loss: 2.417162062251152

Epoch: 6| Step: 3
Training loss: 1.1508540465203274
Validation loss: 2.340906214262684

Epoch: 6| Step: 4
Training loss: 1.072417924136859
Validation loss: 2.3639095514280024

Epoch: 6| Step: 5
Training loss: 0.8643570147978809
Validation loss: 2.343930488664639

Epoch: 6| Step: 6
Training loss: 0.9879329504899087
Validation loss: 2.386254947631247

Epoch: 6| Step: 7
Training loss: 1.0506659802597567
Validation loss: 2.33134501938034

Epoch: 6| Step: 8
Training loss: 0.892734839373423
Validation loss: 2.372359986263647

Epoch: 6| Step: 9
Training loss: 0.9974503796886846
Validation loss: 2.4091202996575625

Epoch: 6| Step: 10
Training loss: 1.1882973052275099
Validation loss: 2.3605370221934727

Epoch: 6| Step: 11
Training loss: 1.9021620144679232
Validation loss: 2.420889203329483

Epoch: 6| Step: 12
Training loss: 0.9677556071866705
Validation loss: 2.3674340612631117

Epoch: 6| Step: 13
Training loss: 1.0110598742133845
Validation loss: 2.413979600825772

Epoch: 453| Step: 0
Training loss: 1.2721055911370471
Validation loss: 2.356290516608753

Epoch: 6| Step: 1
Training loss: 1.0746010394866818
Validation loss: 2.347580921539172

Epoch: 6| Step: 2
Training loss: 1.9943577333454214
Validation loss: 2.3765034032555272

Epoch: 6| Step: 3
Training loss: 1.444226656088051
Validation loss: 2.3799417132377774

Epoch: 6| Step: 4
Training loss: 1.064038229061942
Validation loss: 2.3486232843760715

Epoch: 6| Step: 5
Training loss: 1.2165746593088167
Validation loss: 2.386531833726002

Epoch: 6| Step: 6
Training loss: 0.7986366023726834
Validation loss: 2.406443073148189

Epoch: 6| Step: 7
Training loss: 0.7548461352440733
Validation loss: 2.3825847079097944

Epoch: 6| Step: 8
Training loss: 0.7499872047604428
Validation loss: 2.400004155914236

Epoch: 6| Step: 9
Training loss: 0.7756505573743574
Validation loss: 2.4218669148924454

Epoch: 6| Step: 10
Training loss: 1.2884330368612347
Validation loss: 2.357840688029684

Epoch: 6| Step: 11
Training loss: 0.8695402790982037
Validation loss: 2.412289418670249

Epoch: 6| Step: 12
Training loss: 0.9128002352153398
Validation loss: 2.4120137298368167

Epoch: 6| Step: 13
Training loss: 0.9162278895292918
Validation loss: 2.35752240243673

Epoch: 454| Step: 0
Training loss: 0.8325031715195188
Validation loss: 2.3616658920022933

Epoch: 6| Step: 1
Training loss: 1.1018483217226165
Validation loss: 2.3227000088338934

Epoch: 6| Step: 2
Training loss: 0.6718163131987509
Validation loss: 2.3769607373279174

Epoch: 6| Step: 3
Training loss: 1.9843042315982744
Validation loss: 2.329688623024948

Epoch: 6| Step: 4
Training loss: 1.1166931338993051
Validation loss: 2.365179567750443

Epoch: 6| Step: 5
Training loss: 0.9131008208178719
Validation loss: 2.3218875435347206

Epoch: 6| Step: 6
Training loss: 0.9481001176882115
Validation loss: 2.374584351606029

Epoch: 6| Step: 7
Training loss: 1.112845887837806
Validation loss: 2.3292152113405704

Epoch: 6| Step: 8
Training loss: 1.0297885133228235
Validation loss: 2.3378464846969504

Epoch: 6| Step: 9
Training loss: 0.9247313392820986
Validation loss: 2.331045355872369

Epoch: 6| Step: 10
Training loss: 0.7708830989203748
Validation loss: 2.3512237984093733

Epoch: 6| Step: 11
Training loss: 1.047577465716324
Validation loss: 2.389385861214836

Epoch: 6| Step: 12
Training loss: 1.3141363932804095
Validation loss: 2.4559777934029885

Epoch: 6| Step: 13
Training loss: 0.8135781837177195
Validation loss: 2.338006040173855

Epoch: 455| Step: 0
Training loss: 0.9189536796618613
Validation loss: 2.3455075932004186

Epoch: 6| Step: 1
Training loss: 1.0163677140832017
Validation loss: 2.50656267503465

Epoch: 6| Step: 2
Training loss: 0.9398386396235848
Validation loss: 2.4960901388507817

Epoch: 6| Step: 3
Training loss: 0.8769643736119993
Validation loss: 2.3928163273167047

Epoch: 6| Step: 4
Training loss: 1.2466055557416047
Validation loss: 2.4317872799637383

Epoch: 6| Step: 5
Training loss: 0.6004231550230975
Validation loss: 2.320314913031967

Epoch: 6| Step: 6
Training loss: 1.071205268023858
Validation loss: 2.3757614119860877

Epoch: 6| Step: 7
Training loss: 1.1455841429272255
Validation loss: 2.3086072511418556

Epoch: 6| Step: 8
Training loss: 1.2381441539840674
Validation loss: 2.3760585627880957

Epoch: 6| Step: 9
Training loss: 0.9862482321835764
Validation loss: 2.38759562275055

Epoch: 6| Step: 10
Training loss: 1.1115390463460197
Validation loss: 2.342561052984757

Epoch: 6| Step: 11
Training loss: 1.1802912297754995
Validation loss: 2.288473985769672

Epoch: 6| Step: 12
Training loss: 1.8388688081885118
Validation loss: 2.274641998564752

Epoch: 6| Step: 13
Training loss: 0.949327690246594
Validation loss: 2.3597249547957877

Epoch: 456| Step: 0
Training loss: 0.860098794097463
Validation loss: 2.343171780266799

Epoch: 6| Step: 1
Training loss: 0.8726136500275224
Validation loss: 2.340963858900413

Epoch: 6| Step: 2
Training loss: 1.006488906742368
Validation loss: 2.284986811560528

Epoch: 6| Step: 3
Training loss: 0.7948858079530932
Validation loss: 2.372503402989159

Epoch: 6| Step: 4
Training loss: 0.9883082993013496
Validation loss: 2.3313135650607024

Epoch: 6| Step: 5
Training loss: 1.2126147560007021
Validation loss: 2.4129550495113308

Epoch: 6| Step: 6
Training loss: 0.987263664502661
Validation loss: 2.398824091103852

Epoch: 6| Step: 7
Training loss: 1.118888786700624
Validation loss: 2.355297587615724

Epoch: 6| Step: 8
Training loss: 1.1367195365352465
Validation loss: 2.3667381052549623

Epoch: 6| Step: 9
Training loss: 1.3454463807943182
Validation loss: 2.4256271337918984

Epoch: 6| Step: 10
Training loss: 1.2801564830256944
Validation loss: 2.4229167326626673

Epoch: 6| Step: 11
Training loss: 0.9999833105601942
Validation loss: 2.3551168184133053

Epoch: 6| Step: 12
Training loss: 1.9224857507383486
Validation loss: 2.3375663712366928

Epoch: 6| Step: 13
Training loss: 0.8785203892030354
Validation loss: 2.3471006576469517

Epoch: 457| Step: 0
Training loss: 1.1952173531754746
Validation loss: 2.419945594092465

Epoch: 6| Step: 1
Training loss: 0.7589208618541825
Validation loss: 2.3602542967720854

Epoch: 6| Step: 2
Training loss: 0.8551528904948363
Validation loss: 2.491607119075419

Epoch: 6| Step: 3
Training loss: 1.9673797440767669
Validation loss: 2.416298537668803

Epoch: 6| Step: 4
Training loss: 1.2560128552756926
Validation loss: 2.371927747218695

Epoch: 6| Step: 5
Training loss: 1.0085283442889104
Validation loss: 2.377941843021014

Epoch: 6| Step: 6
Training loss: 1.1390640865780595
Validation loss: 2.3767111205084412

Epoch: 6| Step: 7
Training loss: 1.090604236481646
Validation loss: 2.411041993160716

Epoch: 6| Step: 8
Training loss: 1.2047268001414786
Validation loss: 2.3671040887986567

Epoch: 6| Step: 9
Training loss: 1.1754123958296852
Validation loss: 2.3782559061263155

Epoch: 6| Step: 10
Training loss: 0.6322542247548105
Validation loss: 2.3979814833498723

Epoch: 6| Step: 11
Training loss: 0.7673112633472932
Validation loss: 2.4325882651639197

Epoch: 6| Step: 12
Training loss: 1.149767099514204
Validation loss: 2.3687381653286192

Epoch: 6| Step: 13
Training loss: 0.921332053951897
Validation loss: 2.394119449707531

Epoch: 458| Step: 0
Training loss: 1.2638390266913677
Validation loss: 2.3724296641884255

Epoch: 6| Step: 1
Training loss: 1.1956684854020543
Validation loss: 2.363582745958871

Epoch: 6| Step: 2
Training loss: 0.8343324314645467
Validation loss: 2.340271815923724

Epoch: 6| Step: 3
Training loss: 1.055048223902937
Validation loss: 2.3735960311767603

Epoch: 6| Step: 4
Training loss: 0.8678345886430427
Validation loss: 2.3438091585083334

Epoch: 6| Step: 5
Training loss: 0.9257842438082032
Validation loss: 2.3621107768618765

Epoch: 6| Step: 6
Training loss: 0.9011897845528656
Validation loss: 2.349590551400691

Epoch: 6| Step: 7
Training loss: 0.7899309798764683
Validation loss: 2.3052842446795037

Epoch: 6| Step: 8
Training loss: 1.0030611392219988
Validation loss: 2.2934064650495007

Epoch: 6| Step: 9
Training loss: 0.6897108552657292
Validation loss: 2.3353837274914966

Epoch: 6| Step: 10
Training loss: 1.0263882679321539
Validation loss: 2.379703387298294

Epoch: 6| Step: 11
Training loss: 2.0861851691611837
Validation loss: 2.328236786087779

Epoch: 6| Step: 12
Training loss: 1.0749226985905784
Validation loss: 2.3621569745859903

Epoch: 6| Step: 13
Training loss: 1.5491381187058941
Validation loss: 2.318627365500622

Epoch: 459| Step: 0
Training loss: 1.2646164820106038
Validation loss: 2.404457436728611

Epoch: 6| Step: 1
Training loss: 0.8828878454953317
Validation loss: 2.4337130700205045

Epoch: 6| Step: 2
Training loss: 0.762472317927926
Validation loss: 2.3027324603967076

Epoch: 6| Step: 3
Training loss: 1.0889997598316778
Validation loss: 2.374680354029908

Epoch: 6| Step: 4
Training loss: 0.9690686593940974
Validation loss: 2.3535801760157953

Epoch: 6| Step: 5
Training loss: 0.8579862297082381
Validation loss: 2.381586154573586

Epoch: 6| Step: 6
Training loss: 1.088383835053611
Validation loss: 2.387815245844797

Epoch: 6| Step: 7
Training loss: 1.0088687654750903
Validation loss: 2.2443608884055672

Epoch: 6| Step: 8
Training loss: 1.0202240325756384
Validation loss: 2.4757267719455416

Epoch: 6| Step: 9
Training loss: 1.8493231901419178
Validation loss: 2.3784704559018612

Epoch: 6| Step: 10
Training loss: 0.7381260623003675
Validation loss: 2.3303431484748014

Epoch: 6| Step: 11
Training loss: 1.294938261408858
Validation loss: 2.368982437655863

Epoch: 6| Step: 12
Training loss: 0.9944686498365911
Validation loss: 2.378767209021101

Epoch: 6| Step: 13
Training loss: 0.8736557170987598
Validation loss: 2.3503687321660913

Epoch: 460| Step: 0
Training loss: 0.8295156929596528
Validation loss: 2.3379132442110224

Epoch: 6| Step: 1
Training loss: 1.149685240253655
Validation loss: 2.372164153105052

Epoch: 6| Step: 2
Training loss: 0.9278545101081853
Validation loss: 2.2472485076803443

Epoch: 6| Step: 3
Training loss: 1.0371422484049686
Validation loss: 2.3774838382697014

Epoch: 6| Step: 4
Training loss: 0.8935387448415542
Validation loss: 2.3304367838060127

Epoch: 6| Step: 5
Training loss: 1.279803226813475
Validation loss: 2.3065639036891077

Epoch: 6| Step: 6
Training loss: 1.0474341877586137
Validation loss: 2.342720383665397

Epoch: 6| Step: 7
Training loss: 1.0234681335989673
Validation loss: 2.4345260970244413

Epoch: 6| Step: 8
Training loss: 0.6793578653008429
Validation loss: 2.4303159960946044

Epoch: 6| Step: 9
Training loss: 0.7689869693773186
Validation loss: 2.306290211807615

Epoch: 6| Step: 10
Training loss: 1.8104084048358853
Validation loss: 2.4010019042600454

Epoch: 6| Step: 11
Training loss: 1.0549321773839326
Validation loss: 2.3321939690119646

Epoch: 6| Step: 12
Training loss: 1.0521672973868599
Validation loss: 2.3823276058008056

Epoch: 6| Step: 13
Training loss: 0.9655423125878332
Validation loss: 2.362775119818619

Epoch: 461| Step: 0
Training loss: 1.001440322255858
Validation loss: 2.3398047161871225

Epoch: 6| Step: 1
Training loss: 1.0171776860433166
Validation loss: 2.3925587393950773

Epoch: 6| Step: 2
Training loss: 1.0051559803560743
Validation loss: 2.3570456977771324

Epoch: 6| Step: 3
Training loss: 0.7172037575734471
Validation loss: 2.497529070058429

Epoch: 6| Step: 4
Training loss: 1.0624084994241823
Validation loss: 2.3904569484885245

Epoch: 6| Step: 5
Training loss: 1.1098839035837056
Validation loss: 2.3499848116783366

Epoch: 6| Step: 6
Training loss: 1.8671267830780867
Validation loss: 2.4334890612730264

Epoch: 6| Step: 7
Training loss: 0.9838144432006513
Validation loss: 2.4592520598005763

Epoch: 6| Step: 8
Training loss: 0.9926892311096949
Validation loss: 2.404656283432452

Epoch: 6| Step: 9
Training loss: 0.7985023636421663
Validation loss: 2.3219169167842746

Epoch: 6| Step: 10
Training loss: 0.7252091139084464
Validation loss: 2.39592162224167

Epoch: 6| Step: 11
Training loss: 0.9087749362866724
Validation loss: 2.4143002985622295

Epoch: 6| Step: 12
Training loss: 1.4580076489764644
Validation loss: 2.3577739028861067

Epoch: 6| Step: 13
Training loss: 1.052788161565143
Validation loss: 2.3296477865564897

Epoch: 462| Step: 0
Training loss: 1.1041974417278362
Validation loss: 2.3030654251911757

Epoch: 6| Step: 1
Training loss: 0.9952399390583381
Validation loss: 2.361059669482767

Epoch: 6| Step: 2
Training loss: 0.9143080422323202
Validation loss: 2.356658236317415

Epoch: 6| Step: 3
Training loss: 0.7257792034469346
Validation loss: 2.325843537207209

Epoch: 6| Step: 4
Training loss: 0.887252512528685
Validation loss: 2.393769702237512

Epoch: 6| Step: 5
Training loss: 1.1190660062349898
Validation loss: 2.3464720647236974

Epoch: 6| Step: 6
Training loss: 1.335908320593477
Validation loss: 2.3525728156634105

Epoch: 6| Step: 7
Training loss: 0.9503051443420562
Validation loss: 2.399745215757872

Epoch: 6| Step: 8
Training loss: 1.0161313481995442
Validation loss: 2.3600061674317283

Epoch: 6| Step: 9
Training loss: 0.7989114284216987
Validation loss: 2.370777747048688

Epoch: 6| Step: 10
Training loss: 1.0133897098326738
Validation loss: 2.4104634622996914

Epoch: 6| Step: 11
Training loss: 1.3131615470147016
Validation loss: 2.358303396893817

Epoch: 6| Step: 12
Training loss: 1.01837630643769
Validation loss: 2.410150342301053

Epoch: 6| Step: 13
Training loss: 2.4956294957786094
Validation loss: 2.4045175431926413

Epoch: 463| Step: 0
Training loss: 1.0367808135829957
Validation loss: 2.3478988034310144

Epoch: 6| Step: 1
Training loss: 1.040758169090361
Validation loss: 2.4257076215859104

Epoch: 6| Step: 2
Training loss: 1.089599800836374
Validation loss: 2.349832106020896

Epoch: 6| Step: 3
Training loss: 0.969558255590285
Validation loss: 2.3523223808086478

Epoch: 6| Step: 4
Training loss: 1.0669544194432843
Validation loss: 2.374202963695342

Epoch: 6| Step: 5
Training loss: 1.1896898256504103
Validation loss: 2.339430847281611

Epoch: 6| Step: 6
Training loss: 0.7084669005927762
Validation loss: 2.3696712542186105

Epoch: 6| Step: 7
Training loss: 0.9141879199457302
Validation loss: 2.2878378383893883

Epoch: 6| Step: 8
Training loss: 1.8861790234538862
Validation loss: 2.347613240093845

Epoch: 6| Step: 9
Training loss: 0.8664299001123081
Validation loss: 2.300741950141548

Epoch: 6| Step: 10
Training loss: 1.1188803698057472
Validation loss: 2.3328631254333305

Epoch: 6| Step: 11
Training loss: 1.1608385333957756
Validation loss: 2.341905663135685

Epoch: 6| Step: 12
Training loss: 1.09131624018574
Validation loss: 2.3373992140562736

Epoch: 6| Step: 13
Training loss: 0.6769583929157386
Validation loss: 2.3922730685301046

Epoch: 464| Step: 0
Training loss: 1.0456058153397902
Validation loss: 2.3464307323321414

Epoch: 6| Step: 1
Training loss: 0.9656123756151332
Validation loss: 2.438606499072326

Epoch: 6| Step: 2
Training loss: 1.8099339176992038
Validation loss: 2.2977546133237046

Epoch: 6| Step: 3
Training loss: 0.8552589333387434
Validation loss: 2.303012018207936

Epoch: 6| Step: 4
Training loss: 0.9178395281803657
Validation loss: 2.430308177203605

Epoch: 6| Step: 5
Training loss: 1.079591003168899
Validation loss: 2.3237581473107873

Epoch: 6| Step: 6
Training loss: 1.0071638518660284
Validation loss: 2.366224263738385

Epoch: 6| Step: 7
Training loss: 0.9340653764483261
Validation loss: 2.3234705625818557

Epoch: 6| Step: 8
Training loss: 1.0770815346934626
Validation loss: 2.380323677089251

Epoch: 6| Step: 9
Training loss: 1.054711405165285
Validation loss: 2.34399660624734

Epoch: 6| Step: 10
Training loss: 0.9086622492782438
Validation loss: 2.4260533739831964

Epoch: 6| Step: 11
Training loss: 0.9877755299799942
Validation loss: 2.362674899424805

Epoch: 6| Step: 12
Training loss: 0.7765716091673284
Validation loss: 2.346349594470313

Epoch: 6| Step: 13
Training loss: 1.3695521368859251
Validation loss: 2.3376728048604303

Epoch: 465| Step: 0
Training loss: 0.8549290875257262
Validation loss: 2.3191501455367165

Epoch: 6| Step: 1
Training loss: 1.0216199737466258
Validation loss: 2.3298769806981405

Epoch: 6| Step: 2
Training loss: 0.7135310810352714
Validation loss: 2.30154993703083

Epoch: 6| Step: 3
Training loss: 1.0647496921478852
Validation loss: 2.3591850718810097

Epoch: 6| Step: 4
Training loss: 0.8817599613415483
Validation loss: 2.285379110287534

Epoch: 6| Step: 5
Training loss: 0.8464515317029726
Validation loss: 2.3573797457881236

Epoch: 6| Step: 6
Training loss: 0.9364651372462234
Validation loss: 2.3000387413664174

Epoch: 6| Step: 7
Training loss: 1.2299639922973447
Validation loss: 2.2757850127377046

Epoch: 6| Step: 8
Training loss: 0.8109271892266974
Validation loss: 2.4049151601173495

Epoch: 6| Step: 9
Training loss: 1.8679631748858145
Validation loss: 2.363267447216813

Epoch: 6| Step: 10
Training loss: 0.8449875268636305
Validation loss: 2.353114785442128

Epoch: 6| Step: 11
Training loss: 1.3567621837298764
Validation loss: 2.3373705382549117

Epoch: 6| Step: 12
Training loss: 0.9277564116420627
Validation loss: 2.3314827100572093

Epoch: 6| Step: 13
Training loss: 1.1082754461807944
Validation loss: 2.3495896621531953

Epoch: 466| Step: 0
Training loss: 0.8244173795899493
Validation loss: 2.3539203562496827

Epoch: 6| Step: 1
Training loss: 1.0607815477587408
Validation loss: 2.2905324659277735

Epoch: 6| Step: 2
Training loss: 0.5590099038319848
Validation loss: 2.3376797719537947

Epoch: 6| Step: 3
Training loss: 1.0983138100235248
Validation loss: 2.391063397712768

Epoch: 6| Step: 4
Training loss: 0.8381152441038714
Validation loss: 2.4386444786339614

Epoch: 6| Step: 5
Training loss: 0.9070638750962573
Validation loss: 2.3862559344090593

Epoch: 6| Step: 6
Training loss: 1.1793707618172267
Validation loss: 2.453301057597671

Epoch: 6| Step: 7
Training loss: 2.2354781622010935
Validation loss: 2.4432293339154936

Epoch: 6| Step: 8
Training loss: 0.8584687743376321
Validation loss: 2.3706198760392057

Epoch: 6| Step: 9
Training loss: 1.183923857830966
Validation loss: 2.3723524326559846

Epoch: 6| Step: 10
Training loss: 0.7934495567556599
Validation loss: 2.2986120793564098

Epoch: 6| Step: 11
Training loss: 1.0062283626149249
Validation loss: 2.3030241238845095

Epoch: 6| Step: 12
Training loss: 1.434345100440261
Validation loss: 2.319541033637476

Epoch: 6| Step: 13
Training loss: 1.2641798646288656
Validation loss: 2.415273974419846

Epoch: 467| Step: 0
Training loss: 1.4101752705229094
Validation loss: 2.28421034979529

Epoch: 6| Step: 1
Training loss: 0.9277834588166882
Validation loss: 2.362931673261638

Epoch: 6| Step: 2
Training loss: 0.9929592705370934
Validation loss: 2.374760575199786

Epoch: 6| Step: 3
Training loss: 0.6371958998369198
Validation loss: 2.42018205827994

Epoch: 6| Step: 4
Training loss: 0.7460996617587287
Validation loss: 2.3660103327905957

Epoch: 6| Step: 5
Training loss: 0.5503753627504725
Validation loss: 2.372119070522892

Epoch: 6| Step: 6
Training loss: 0.628717097868162
Validation loss: 2.401867734267857

Epoch: 6| Step: 7
Training loss: 1.5765908215098927
Validation loss: 2.4858000946449086

Epoch: 6| Step: 8
Training loss: 1.4016654836866638
Validation loss: 2.3968500702293056

Epoch: 6| Step: 9
Training loss: 0.9490427866657231
Validation loss: 2.375257964877635

Epoch: 6| Step: 10
Training loss: 1.1160540399559193
Validation loss: 2.334589413182084

Epoch: 6| Step: 11
Training loss: 0.8534028351936243
Validation loss: 2.3493318381976884

Epoch: 6| Step: 12
Training loss: 1.8989391527516808
Validation loss: 2.313064298482228

Epoch: 6| Step: 13
Training loss: 1.129510579164768
Validation loss: 2.3637248059029186

Epoch: 468| Step: 0
Training loss: 0.8586665267576475
Validation loss: 2.3073803969726274

Epoch: 6| Step: 1
Training loss: 1.863030502753528
Validation loss: 2.3265659656291

Epoch: 6| Step: 2
Training loss: 0.7050050607797234
Validation loss: 2.340888110287837

Epoch: 6| Step: 3
Training loss: 0.6612566292471919
Validation loss: 2.2871970446277383

Epoch: 6| Step: 4
Training loss: 1.192133047077722
Validation loss: 2.331389407032918

Epoch: 6| Step: 5
Training loss: 0.8857864318362326
Validation loss: 2.351879064360713

Epoch: 6| Step: 6
Training loss: 0.8943313975072102
Validation loss: 2.3575781064688903

Epoch: 6| Step: 7
Training loss: 1.0853407063815643
Validation loss: 2.3793469906147036

Epoch: 6| Step: 8
Training loss: 0.973631251419025
Validation loss: 2.3239431384470306

Epoch: 6| Step: 9
Training loss: 0.9815587523837295
Validation loss: 2.430649537019136

Epoch: 6| Step: 10
Training loss: 0.9901854373193113
Validation loss: 2.354150370386165

Epoch: 6| Step: 11
Training loss: 1.3942799488672615
Validation loss: 2.4655387723701434

Epoch: 6| Step: 12
Training loss: 0.9240595586147459
Validation loss: 2.3345181731776457

Epoch: 6| Step: 13
Training loss: 1.0794958714684062
Validation loss: 2.40005702178308

Epoch: 469| Step: 0
Training loss: 0.9193917790171281
Validation loss: 2.3635017261666342

Epoch: 6| Step: 1
Training loss: 1.8299228923999822
Validation loss: 2.393621498218051

Epoch: 6| Step: 2
Training loss: 0.9516472225964211
Validation loss: 2.294460259246107

Epoch: 6| Step: 3
Training loss: 1.1086216369949518
Validation loss: 2.3752860116722267

Epoch: 6| Step: 4
Training loss: 1.2257195753211414
Validation loss: 2.384283177389819

Epoch: 6| Step: 5
Training loss: 1.2671034384055153
Validation loss: 2.295916183835155

Epoch: 6| Step: 6
Training loss: 0.8371137027032287
Validation loss: 2.379856093159472

Epoch: 6| Step: 7
Training loss: 0.9550368723317035
Validation loss: 2.329109135299393

Epoch: 6| Step: 8
Training loss: 1.3112505006016448
Validation loss: 2.350408296781907

Epoch: 6| Step: 9
Training loss: 0.787258276095458
Validation loss: 2.3009430308761556

Epoch: 6| Step: 10
Training loss: 0.8048403696571655
Validation loss: 2.3504316910034984

Epoch: 6| Step: 11
Training loss: 0.9489019045643121
Validation loss: 2.2694545574254685

Epoch: 6| Step: 12
Training loss: 1.1355452100218648
Validation loss: 2.34494353172706

Epoch: 6| Step: 13
Training loss: 0.7738185675934431
Validation loss: 2.313797501103204

Epoch: 470| Step: 0
Training loss: 0.7426279066356724
Validation loss: 2.4045352054113724

Epoch: 6| Step: 1
Training loss: 1.9682235013771405
Validation loss: 2.452137292794868

Epoch: 6| Step: 2
Training loss: 1.0923248815837163
Validation loss: 2.434093167518993

Epoch: 6| Step: 3
Training loss: 1.022623043818014
Validation loss: 2.3950666955013955

Epoch: 6| Step: 4
Training loss: 0.7260695805558606
Validation loss: 2.3469781489212806

Epoch: 6| Step: 5
Training loss: 0.6724575090279378
Validation loss: 2.381060669929745

Epoch: 6| Step: 6
Training loss: 0.8310332424386806
Validation loss: 2.3783180448125205

Epoch: 6| Step: 7
Training loss: 0.9336335241551968
Validation loss: 2.293853290077826

Epoch: 6| Step: 8
Training loss: 0.924311569854126
Validation loss: 2.332984292458419

Epoch: 6| Step: 9
Training loss: 1.2796962434984658
Validation loss: 2.2999184040685257

Epoch: 6| Step: 10
Training loss: 0.7820639375758641
Validation loss: 2.3977351818316652

Epoch: 6| Step: 11
Training loss: 1.0601117275843397
Validation loss: 2.368437211446253

Epoch: 6| Step: 12
Training loss: 1.2648546676682921
Validation loss: 2.357701257229547

Epoch: 6| Step: 13
Training loss: 0.765654738490926
Validation loss: 2.328337241325781

Epoch: 471| Step: 0
Training loss: 1.857246334473344
Validation loss: 2.2867274988691233

Epoch: 6| Step: 1
Training loss: 0.9478028966239204
Validation loss: 2.398935537579175

Epoch: 6| Step: 2
Training loss: 0.661644561463989
Validation loss: 2.3032815005565213

Epoch: 6| Step: 3
Training loss: 1.2040880980593502
Validation loss: 2.3236100515618214

Epoch: 6| Step: 4
Training loss: 0.9532148600258414
Validation loss: 2.3308687253659945

Epoch: 6| Step: 5
Training loss: 1.1341480669173054
Validation loss: 2.3240962087801016

Epoch: 6| Step: 6
Training loss: 0.7195176296208277
Validation loss: 2.35024901279281

Epoch: 6| Step: 7
Training loss: 1.0247346069266807
Validation loss: 2.356059818617383

Epoch: 6| Step: 8
Training loss: 0.9043573149221958
Validation loss: 2.3633259967583804

Epoch: 6| Step: 9
Training loss: 0.9633855572957657
Validation loss: 2.339294606909148

Epoch: 6| Step: 10
Training loss: 0.8027292515946218
Validation loss: 2.3598111906715573

Epoch: 6| Step: 11
Training loss: 1.4347878454135425
Validation loss: 2.3154961572171637

Epoch: 6| Step: 12
Training loss: 1.0209603068475601
Validation loss: 2.353926309230189

Epoch: 6| Step: 13
Training loss: 0.7905703951709576
Validation loss: 2.4078507635639834

Epoch: 472| Step: 0
Training loss: 1.2230187022041659
Validation loss: 2.377239217661199

Epoch: 6| Step: 1
Training loss: 1.0472714257141897
Validation loss: 2.4133710068958814

Epoch: 6| Step: 2
Training loss: 0.8810059283833211
Validation loss: 2.389594180550997

Epoch: 6| Step: 3
Training loss: 0.8678458524235313
Validation loss: 2.3592713590026246

Epoch: 6| Step: 4
Training loss: 0.9783582732180635
Validation loss: 2.3207528898042433

Epoch: 6| Step: 5
Training loss: 0.8594062799483068
Validation loss: 2.330044789748808

Epoch: 6| Step: 6
Training loss: 2.026378364991763
Validation loss: 2.408970817971901

Epoch: 6| Step: 7
Training loss: 1.1254441656043552
Validation loss: 2.3931438525417015

Epoch: 6| Step: 8
Training loss: 1.3697618063027817
Validation loss: 2.3222029176327905

Epoch: 6| Step: 9
Training loss: 1.1302008152490477
Validation loss: 2.2914905694850627

Epoch: 6| Step: 10
Training loss: 0.8388962834988788
Validation loss: 2.3152129697939885

Epoch: 6| Step: 11
Training loss: 0.8670366860606162
Validation loss: 2.3709726183237527

Epoch: 6| Step: 12
Training loss: 1.3295650080596806
Validation loss: 2.2411122976439772

Epoch: 6| Step: 13
Training loss: 0.9259882828236855
Validation loss: 2.361349752680914

Epoch: 473| Step: 0
Training loss: 0.6510867955143318
Validation loss: 2.433263311405489

Epoch: 6| Step: 1
Training loss: 0.9995107347924291
Validation loss: 2.4097534477046385

Epoch: 6| Step: 2
Training loss: 0.9882927995692934
Validation loss: 2.3832571598199634

Epoch: 6| Step: 3
Training loss: 0.969078561993552
Validation loss: 2.4414145392164386

Epoch: 6| Step: 4
Training loss: 1.032183138277711
Validation loss: 2.3506467076634068

Epoch: 6| Step: 5
Training loss: 0.9825043236052527
Validation loss: 2.314965636185837

Epoch: 6| Step: 6
Training loss: 0.8227471325875653
Validation loss: 2.326061926684347

Epoch: 6| Step: 7
Training loss: 1.0728803585291564
Validation loss: 2.3698604804082457

Epoch: 6| Step: 8
Training loss: 0.644528521907697
Validation loss: 2.3881405370640407

Epoch: 6| Step: 9
Training loss: 1.8927377292979497
Validation loss: 2.430591663106067

Epoch: 6| Step: 10
Training loss: 1.2561653678056939
Validation loss: 2.3328307096802536

Epoch: 6| Step: 11
Training loss: 1.2425480445307635
Validation loss: 2.289664635354105

Epoch: 6| Step: 12
Training loss: 0.9907294546225901
Validation loss: 2.3209967205340445

Epoch: 6| Step: 13
Training loss: 1.018963827616099
Validation loss: 2.4080971046280477

Epoch: 474| Step: 0
Training loss: 1.12505001380798
Validation loss: 2.4262350556652144

Epoch: 6| Step: 1
Training loss: 2.064562604269544
Validation loss: 2.3722048547593517

Epoch: 6| Step: 2
Training loss: 0.7871268675116971
Validation loss: 2.375818242222571

Epoch: 6| Step: 3
Training loss: 0.9610194349635945
Validation loss: 2.4437843613445542

Epoch: 6| Step: 4
Training loss: 1.085067125784198
Validation loss: 2.3689718810684766

Epoch: 6| Step: 5
Training loss: 0.849436319199511
Validation loss: 2.402655331901218

Epoch: 6| Step: 6
Training loss: 0.5815254932663702
Validation loss: 2.360842013924088

Epoch: 6| Step: 7
Training loss: 1.3255104808990175
Validation loss: 2.44710337617239

Epoch: 6| Step: 8
Training loss: 0.7992482467980556
Validation loss: 2.3698734075076646

Epoch: 6| Step: 9
Training loss: 1.0955051508459877
Validation loss: 2.3216933396144097

Epoch: 6| Step: 10
Training loss: 0.8429164301038615
Validation loss: 2.2956436503045814

Epoch: 6| Step: 11
Training loss: 0.9534331902200572
Validation loss: 2.3636381612855923

Epoch: 6| Step: 12
Training loss: 0.656190120144965
Validation loss: 2.4059434004764157

Epoch: 6| Step: 13
Training loss: 0.7036893910654423
Validation loss: 2.4336337455597294

Epoch: 475| Step: 0
Training loss: 1.1494178998780995
Validation loss: 2.316151250473645

Epoch: 6| Step: 1
Training loss: 1.0806295632419907
Validation loss: 2.4040175780076365

Epoch: 6| Step: 2
Training loss: 1.086989188532682
Validation loss: 2.347744370562534

Epoch: 6| Step: 3
Training loss: 1.255731697770865
Validation loss: 2.3232766620231122

Epoch: 6| Step: 4
Training loss: 0.685050306317644
Validation loss: 2.264561600394093

Epoch: 6| Step: 5
Training loss: 0.8991759209661911
Validation loss: 2.3975206323288676

Epoch: 6| Step: 6
Training loss: 1.042915828662332
Validation loss: 2.338256122016406

Epoch: 6| Step: 7
Training loss: 0.8215306274917834
Validation loss: 2.2547122099179746

Epoch: 6| Step: 8
Training loss: 0.6698768533865034
Validation loss: 2.3458237036709892

Epoch: 6| Step: 9
Training loss: 1.1063647733299105
Validation loss: 2.3049264757867576

Epoch: 6| Step: 10
Training loss: 1.1169235878116872
Validation loss: 2.365898365846743

Epoch: 6| Step: 11
Training loss: 1.9398327597077476
Validation loss: 2.377046655555626

Epoch: 6| Step: 12
Training loss: 0.8109705541559119
Validation loss: 2.363012625806803

Epoch: 6| Step: 13
Training loss: 0.7063571392927432
Validation loss: 2.3243589992300193

Epoch: 476| Step: 0
Training loss: 1.3253405835019245
Validation loss: 2.3592447441734232

Epoch: 6| Step: 1
Training loss: 0.8212476214137825
Validation loss: 2.3251063979801945

Epoch: 6| Step: 2
Training loss: 1.0423558752572408
Validation loss: 2.3554606219782217

Epoch: 6| Step: 3
Training loss: 0.9877524186097245
Validation loss: 2.3999062689471384

Epoch: 6| Step: 4
Training loss: 0.6557783066504237
Validation loss: 2.3107364285429814

Epoch: 6| Step: 5
Training loss: 1.0742179177020923
Validation loss: 2.3005393195798614

Epoch: 6| Step: 6
Training loss: 1.1136572487311198
Validation loss: 2.343486986066686

Epoch: 6| Step: 7
Training loss: 0.817290343018477
Validation loss: 2.312119976813613

Epoch: 6| Step: 8
Training loss: 1.0094811280382092
Validation loss: 2.3773188424126026

Epoch: 6| Step: 9
Training loss: 0.7989876361697189
Validation loss: 2.3915607728940356

Epoch: 6| Step: 10
Training loss: 0.6909446899854317
Validation loss: 2.369310773277505

Epoch: 6| Step: 11
Training loss: 1.9623104927263402
Validation loss: 2.371051071174017

Epoch: 6| Step: 12
Training loss: 1.1139536115552118
Validation loss: 2.3521354063810143

Epoch: 6| Step: 13
Training loss: 1.162876831013881
Validation loss: 2.3406941268993178

Epoch: 477| Step: 0
Training loss: 1.0995178726638002
Validation loss: 2.3836652827759406

Epoch: 6| Step: 1
Training loss: 0.7804922625386042
Validation loss: 2.32137123642464

Epoch: 6| Step: 2
Training loss: 0.9156845242678021
Validation loss: 2.3067686256187323

Epoch: 6| Step: 3
Training loss: 1.0500788840680033
Validation loss: 2.341996583968141

Epoch: 6| Step: 4
Training loss: 0.7492664246411983
Validation loss: 2.4071638281544145

Epoch: 6| Step: 5
Training loss: 1.0497235501893842
Validation loss: 2.294325762118841

Epoch: 6| Step: 6
Training loss: 0.9183360562108192
Validation loss: 2.3784315289355935

Epoch: 6| Step: 7
Training loss: 0.7297200328427967
Validation loss: 2.403459887168789

Epoch: 6| Step: 8
Training loss: 0.7724090057162146
Validation loss: 2.312927395060513

Epoch: 6| Step: 9
Training loss: 1.8316635055560995
Validation loss: 2.3777224767099736

Epoch: 6| Step: 10
Training loss: 0.8777318950188527
Validation loss: 2.2954583050454573

Epoch: 6| Step: 11
Training loss: 0.43402363542063527
Validation loss: 2.3795780128068467

Epoch: 6| Step: 12
Training loss: 0.7830896461830187
Validation loss: 2.387398029416113

Epoch: 6| Step: 13
Training loss: 1.6968232907448078
Validation loss: 2.420281002693698

Epoch: 478| Step: 0
Training loss: 1.1207042376305638
Validation loss: 2.426639779540412

Epoch: 6| Step: 1
Training loss: 1.168877391706265
Validation loss: 2.383839421960864

Epoch: 6| Step: 2
Training loss: 1.1949225394230591
Validation loss: 2.419336614232487

Epoch: 6| Step: 3
Training loss: 0.9162921284856328
Validation loss: 2.3343222096728917

Epoch: 6| Step: 4
Training loss: 0.965336723875797
Validation loss: 2.349840639174721

Epoch: 6| Step: 5
Training loss: 1.0353319127006961
Validation loss: 2.395397775515126

Epoch: 6| Step: 6
Training loss: 1.2898406483308502
Validation loss: 2.2695345918906376

Epoch: 6| Step: 7
Training loss: 1.0341807249242319
Validation loss: 2.3580119713208507

Epoch: 6| Step: 8
Training loss: 0.9968178604156928
Validation loss: 2.368600341474429

Epoch: 6| Step: 9
Training loss: 0.583736915850171
Validation loss: 2.2997696626987314

Epoch: 6| Step: 10
Training loss: 1.820931652682284
Validation loss: 2.306563786986391

Epoch: 6| Step: 11
Training loss: 0.5114422699166139
Validation loss: 2.4375724760670536

Epoch: 6| Step: 12
Training loss: 0.6209828019763042
Validation loss: 2.3811930386850513

Epoch: 6| Step: 13
Training loss: 0.987100581985517
Validation loss: 2.3858540247728253

Epoch: 479| Step: 0
Training loss: 1.1922769335477985
Validation loss: 2.3428688104622046

Epoch: 6| Step: 1
Training loss: 0.8373541904317504
Validation loss: 2.3682438392002143

Epoch: 6| Step: 2
Training loss: 0.9147364422339997
Validation loss: 2.368743889506638

Epoch: 6| Step: 3
Training loss: 0.7023479406382427
Validation loss: 2.3736253180687577

Epoch: 6| Step: 4
Training loss: 0.8998048411808666
Validation loss: 2.332473491712435

Epoch: 6| Step: 5
Training loss: 1.3687838580677416
Validation loss: 2.38522731048968

Epoch: 6| Step: 6
Training loss: 0.6598271559756688
Validation loss: 2.305694302324732

Epoch: 6| Step: 7
Training loss: 0.9220118017041264
Validation loss: 2.3241831665679364

Epoch: 6| Step: 8
Training loss: 0.8129354190537296
Validation loss: 2.3053933985738717

Epoch: 6| Step: 9
Training loss: 0.9261028519889992
Validation loss: 2.405090920112449

Epoch: 6| Step: 10
Training loss: 1.0822300917604541
Validation loss: 2.3767995806075968

Epoch: 6| Step: 11
Training loss: 2.1025932648755443
Validation loss: 2.3563063730460834

Epoch: 6| Step: 12
Training loss: 0.8482015938633913
Validation loss: 2.332320075348998

Epoch: 6| Step: 13
Training loss: 0.9024197434961686
Validation loss: 2.3871006824604977

Epoch: 480| Step: 0
Training loss: 0.7183751911954955
Validation loss: 2.3933304784397103

Epoch: 6| Step: 1
Training loss: 1.7849014734810407
Validation loss: 2.3438293979554445

Epoch: 6| Step: 2
Training loss: 0.9140277432085524
Validation loss: 2.2765552503266404

Epoch: 6| Step: 3
Training loss: 0.8270756172633795
Validation loss: 2.3987406685047823

Epoch: 6| Step: 4
Training loss: 0.9589968367813815
Validation loss: 2.401245102874589

Epoch: 6| Step: 5
Training loss: 0.8144080792235224
Validation loss: 2.33875274326827

Epoch: 6| Step: 6
Training loss: 1.0136215403266449
Validation loss: 2.3033404023492494

Epoch: 6| Step: 7
Training loss: 0.9277456824968799
Validation loss: 2.352763217630876

Epoch: 6| Step: 8
Training loss: 0.8421514698028648
Validation loss: 2.3647517240592437

Epoch: 6| Step: 9
Training loss: 0.9072322783685319
Validation loss: 2.304241294485284

Epoch: 6| Step: 10
Training loss: 0.7595251335269738
Validation loss: 2.3193884678986847

Epoch: 6| Step: 11
Training loss: 0.8354034500471844
Validation loss: 2.3708589901892827

Epoch: 6| Step: 12
Training loss: 1.417202408784719
Validation loss: 2.336923659208151

Epoch: 6| Step: 13
Training loss: 1.1069821085013865
Validation loss: 2.3530703609210764

Epoch: 481| Step: 0
Training loss: 1.1676486798355872
Validation loss: 2.4028380956418487

Epoch: 6| Step: 1
Training loss: 0.7680377700230281
Validation loss: 2.4157964336890645

Epoch: 6| Step: 2
Training loss: 0.6316859024418668
Validation loss: 2.3344538003733737

Epoch: 6| Step: 3
Training loss: 0.9097047922213439
Validation loss: 2.365515570465872

Epoch: 6| Step: 4
Training loss: 1.3237754057120363
Validation loss: 2.3139806440056514

Epoch: 6| Step: 5
Training loss: 0.8686800647277148
Validation loss: 2.3056039569327553

Epoch: 6| Step: 6
Training loss: 0.5842294338297214
Validation loss: 2.4077240118563155

Epoch: 6| Step: 7
Training loss: 1.0460983925816802
Validation loss: 2.3742396795110645

Epoch: 6| Step: 8
Training loss: 0.8330833338215067
Validation loss: 2.405149605894046

Epoch: 6| Step: 9
Training loss: 0.7266722565473853
Validation loss: 2.341132766588797

Epoch: 6| Step: 10
Training loss: 0.7727846029377715
Validation loss: 2.2841128687576737

Epoch: 6| Step: 11
Training loss: 0.6736683974098323
Validation loss: 2.3383055237316603

Epoch: 6| Step: 12
Training loss: 0.9932686029588882
Validation loss: 2.3078704009466344

Epoch: 6| Step: 13
Training loss: 2.422952129424842
Validation loss: 2.344237798429006

Epoch: 482| Step: 0
Training loss: 1.2639726283846027
Validation loss: 2.319112828385421

Epoch: 6| Step: 1
Training loss: 0.6708663199787039
Validation loss: 2.361451059568675

Epoch: 6| Step: 2
Training loss: 0.9810875691381546
Validation loss: 2.3887129639995415

Epoch: 6| Step: 3
Training loss: 0.9133458384704258
Validation loss: 2.379852023399695

Epoch: 6| Step: 4
Training loss: 1.010029682629719
Validation loss: 2.372383759979151

Epoch: 6| Step: 5
Training loss: 0.8875097704067509
Validation loss: 2.3160623407418326

Epoch: 6| Step: 6
Training loss: 0.89612646999337
Validation loss: 2.377504136100772

Epoch: 6| Step: 7
Training loss: 0.7260799651441233
Validation loss: 2.347717696582113

Epoch: 6| Step: 8
Training loss: 0.932150775059404
Validation loss: 2.3204197824795036

Epoch: 6| Step: 9
Training loss: 1.0168046409495017
Validation loss: 2.3152353698574086

Epoch: 6| Step: 10
Training loss: 1.1101841729106807
Validation loss: 2.3394633414355193

Epoch: 6| Step: 11
Training loss: 0.7500510993080279
Validation loss: 2.2987258164466104

Epoch: 6| Step: 12
Training loss: 0.6695561425512476
Validation loss: 2.2843518371516494

Epoch: 6| Step: 13
Training loss: 2.359945468272565
Validation loss: 2.3970557858418506

Epoch: 483| Step: 0
Training loss: 1.8603167032495194
Validation loss: 2.4093254216832336

Epoch: 6| Step: 1
Training loss: 0.7278767666055819
Validation loss: 2.4071609952404174

Epoch: 6| Step: 2
Training loss: 0.6193884705465414
Validation loss: 2.3384249720405896

Epoch: 6| Step: 3
Training loss: 0.9837032326871946
Validation loss: 2.31419032910097

Epoch: 6| Step: 4
Training loss: 1.179514537535726
Validation loss: 2.385708204065847

Epoch: 6| Step: 5
Training loss: 0.922161962814188
Validation loss: 2.392165715743113

Epoch: 6| Step: 6
Training loss: 0.9888554891263153
Validation loss: 2.3973526669244327

Epoch: 6| Step: 7
Training loss: 1.0884470860521596
Validation loss: 2.3779368358163584

Epoch: 6| Step: 8
Training loss: 1.3830649797368302
Validation loss: 2.3205408319778664

Epoch: 6| Step: 9
Training loss: 0.9493253985488139
Validation loss: 2.2808894177122165

Epoch: 6| Step: 10
Training loss: 1.1783115876676407
Validation loss: 2.340218248017217

Epoch: 6| Step: 11
Training loss: 1.0180749540633363
Validation loss: 2.4063705991566042

Epoch: 6| Step: 12
Training loss: 0.8147941991236233
Validation loss: 2.3327789886016927

Epoch: 6| Step: 13
Training loss: 1.080640208554845
Validation loss: 2.344524327279149

Epoch: 484| Step: 0
Training loss: 0.7125986415777286
Validation loss: 2.3329661160201636

Epoch: 6| Step: 1
Training loss: 0.9943445142751847
Validation loss: 2.3561061817742197

Epoch: 6| Step: 2
Training loss: 0.7456090660982718
Validation loss: 2.363760656853152

Epoch: 6| Step: 3
Training loss: 1.0322399012227985
Validation loss: 2.415461920620605

Epoch: 6| Step: 4
Training loss: 0.8258154350430122
Validation loss: 2.414913689161774

Epoch: 6| Step: 5
Training loss: 0.8602438955669662
Validation loss: 2.3751996554966195

Epoch: 6| Step: 6
Training loss: 0.9426865478583656
Validation loss: 2.2885476795869777

Epoch: 6| Step: 7
Training loss: 0.8290781977116739
Validation loss: 2.4118932884860578

Epoch: 6| Step: 8
Training loss: 1.1500704826648869
Validation loss: 2.3792651284431083

Epoch: 6| Step: 9
Training loss: 1.1184422842319397
Validation loss: 2.315597611337946

Epoch: 6| Step: 10
Training loss: 1.0503514201322934
Validation loss: 2.366315985767815

Epoch: 6| Step: 11
Training loss: 1.8972515907577499
Validation loss: 2.3492641542296804

Epoch: 6| Step: 12
Training loss: 1.1453301567600536
Validation loss: 2.3326454930490206

Epoch: 6| Step: 13
Training loss: 0.9397709996707733
Validation loss: 2.2715622167823106

Epoch: 485| Step: 0
Training loss: 1.1043248812966806
Validation loss: 2.3340489532396678

Epoch: 6| Step: 1
Training loss: 1.1321520754699728
Validation loss: 2.283966756135123

Epoch: 6| Step: 2
Training loss: 1.2426790908139869
Validation loss: 2.358891751720436

Epoch: 6| Step: 3
Training loss: 1.07421836159439
Validation loss: 2.321842868233531

Epoch: 6| Step: 4
Training loss: 0.6377160155132597
Validation loss: 2.298306736947227

Epoch: 6| Step: 5
Training loss: 0.8398608893486403
Validation loss: 2.299685663426875

Epoch: 6| Step: 6
Training loss: 1.0233207810799068
Validation loss: 2.2795063524316075

Epoch: 6| Step: 7
Training loss: 0.8841190291205396
Validation loss: 2.361682784837567

Epoch: 6| Step: 8
Training loss: 0.6980346798165059
Validation loss: 2.331403810900778

Epoch: 6| Step: 9
Training loss: 0.7693672586356815
Validation loss: 2.383924377950742

Epoch: 6| Step: 10
Training loss: 0.7850362961268557
Validation loss: 2.3373534554483326

Epoch: 6| Step: 11
Training loss: 1.4075275128455267
Validation loss: 2.371765405955693

Epoch: 6| Step: 12
Training loss: 1.3228824140464763
Validation loss: 2.361126438777168

Epoch: 6| Step: 13
Training loss: 2.2355533507108505
Validation loss: 2.413528082162921

Epoch: 486| Step: 0
Training loss: 1.1004042792835733
Validation loss: 2.3704135620118083

Epoch: 6| Step: 1
Training loss: 0.9075539514567096
Validation loss: 2.3084329734047144

Epoch: 6| Step: 2
Training loss: 0.6886981580439042
Validation loss: 2.3992292882184643

Epoch: 6| Step: 3
Training loss: 1.8660884160215754
Validation loss: 2.3712270394837174

Epoch: 6| Step: 4
Training loss: 0.6807306987703375
Validation loss: 2.302421740576714

Epoch: 6| Step: 5
Training loss: 0.7829429213253264
Validation loss: 2.3797055698953242

Epoch: 6| Step: 6
Training loss: 1.2956965504095097
Validation loss: 2.336936288012321

Epoch: 6| Step: 7
Training loss: 0.7557261347080003
Validation loss: 2.3579842093969137

Epoch: 6| Step: 8
Training loss: 0.9173305809285582
Validation loss: 2.3206539163203357

Epoch: 6| Step: 9
Training loss: 0.8716391664899505
Validation loss: 2.2913121166392956

Epoch: 6| Step: 10
Training loss: 1.0330209264934396
Validation loss: 2.3813460807180524

Epoch: 6| Step: 11
Training loss: 1.1950223483306257
Validation loss: 2.4092467938193196

Epoch: 6| Step: 12
Training loss: 0.7968918293690487
Validation loss: 2.336598541366646

Epoch: 6| Step: 13
Training loss: 1.193035425147826
Validation loss: 2.3633714217161246

Epoch: 487| Step: 0
Training loss: 0.7780052705748048
Validation loss: 2.4575543769396346

Epoch: 6| Step: 1
Training loss: 0.8639688644582957
Validation loss: 2.4335811066018014

Epoch: 6| Step: 2
Training loss: 1.168047950126169
Validation loss: 2.43616383975518

Epoch: 6| Step: 3
Training loss: 1.0142611810050517
Validation loss: 2.4099237348440554

Epoch: 6| Step: 4
Training loss: 1.0522626340057328
Validation loss: 2.324523354315155

Epoch: 6| Step: 5
Training loss: 0.8087035026331985
Validation loss: 2.359282891857155

Epoch: 6| Step: 6
Training loss: 1.77318809873002
Validation loss: 2.38114480453288

Epoch: 6| Step: 7
Training loss: 1.3157632315679066
Validation loss: 2.360626583060227

Epoch: 6| Step: 8
Training loss: 1.0092930527245674
Validation loss: 2.386658664690413

Epoch: 6| Step: 9
Training loss: 0.6482188763956958
Validation loss: 2.314303445707421

Epoch: 6| Step: 10
Training loss: 0.9931516993530527
Validation loss: 2.310404257181279

Epoch: 6| Step: 11
Training loss: 0.7701168252826548
Validation loss: 2.3716539982445615

Epoch: 6| Step: 12
Training loss: 0.961345306949764
Validation loss: 2.4294146750703605

Epoch: 6| Step: 13
Training loss: 0.9607834421115149
Validation loss: 2.4021392972704314

Epoch: 488| Step: 0
Training loss: 1.3082032489292454
Validation loss: 2.411494916551003

Epoch: 6| Step: 1
Training loss: 1.2072886960923142
Validation loss: 2.3346881357554494

Epoch: 6| Step: 2
Training loss: 1.8365343787477841
Validation loss: 2.3506460080364886

Epoch: 6| Step: 3
Training loss: 0.9619323418908793
Validation loss: 2.37306344050855

Epoch: 6| Step: 4
Training loss: 0.7779380405216051
Validation loss: 2.4310425814106638

Epoch: 6| Step: 5
Training loss: 0.8292810180700538
Validation loss: 2.3601797549126013

Epoch: 6| Step: 6
Training loss: 0.5679410725688266
Validation loss: 2.366495185060292

Epoch: 6| Step: 7
Training loss: 0.9823122968290618
Validation loss: 2.372206760031831

Epoch: 6| Step: 8
Training loss: 1.3545998198437708
Validation loss: 2.351068068815651

Epoch: 6| Step: 9
Training loss: 0.7538522493461828
Validation loss: 2.3479705786304947

Epoch: 6| Step: 10
Training loss: 0.4992021363886256
Validation loss: 2.336449770279708

Epoch: 6| Step: 11
Training loss: 0.6651641907239251
Validation loss: 2.4244152030826784

Epoch: 6| Step: 12
Training loss: 0.9258349439284779
Validation loss: 2.3198458349822193

Epoch: 6| Step: 13
Training loss: 0.883993354916949
Validation loss: 2.3318546084187544

Epoch: 489| Step: 0
Training loss: 1.2094682701872177
Validation loss: 2.328921967667085

Epoch: 6| Step: 1
Training loss: 0.8198246549749435
Validation loss: 2.403562772563581

Epoch: 6| Step: 2
Training loss: 0.6653645932868812
Validation loss: 2.3413527711605964

Epoch: 6| Step: 3
Training loss: 0.9088254047786928
Validation loss: 2.3609195427227183

Epoch: 6| Step: 4
Training loss: 1.3394660973553438
Validation loss: 2.4017114260143084

Epoch: 6| Step: 5
Training loss: 1.849812835813968
Validation loss: 2.311803141822283

Epoch: 6| Step: 6
Training loss: 0.8869330193518845
Validation loss: 2.3740054543290987

Epoch: 6| Step: 7
Training loss: 0.9937382091566471
Validation loss: 2.3973691382686786

Epoch: 6| Step: 8
Training loss: 0.8599493708234448
Validation loss: 2.436912089194261

Epoch: 6| Step: 9
Training loss: 0.7915480717286413
Validation loss: 2.251171072781675

Epoch: 6| Step: 10
Training loss: 0.9830383732602479
Validation loss: 2.331960408413449

Epoch: 6| Step: 11
Training loss: 0.6812603608489698
Validation loss: 2.3360662207766727

Epoch: 6| Step: 12
Training loss: 0.8663160051792723
Validation loss: 2.3014857568436837

Epoch: 6| Step: 13
Training loss: 0.7842075822745294
Validation loss: 2.339003961878826

Epoch: 490| Step: 0
Training loss: 1.071959849744435
Validation loss: 2.368573178810822

Epoch: 6| Step: 1
Training loss: 1.7278212019862833
Validation loss: 2.3169470909987244

Epoch: 6| Step: 2
Training loss: 1.2293787412290755
Validation loss: 2.331673258657819

Epoch: 6| Step: 3
Training loss: 0.8719717826586822
Validation loss: 2.3864727126735734

Epoch: 6| Step: 4
Training loss: 1.036779663780124
Validation loss: 2.3216077252006047

Epoch: 6| Step: 5
Training loss: 0.9156141885893815
Validation loss: 2.3526137718081555

Epoch: 6| Step: 6
Training loss: 1.3520655054328712
Validation loss: 2.387232910680721

Epoch: 6| Step: 7
Training loss: 1.2261153456923957
Validation loss: 2.356661936020165

Epoch: 6| Step: 8
Training loss: 0.8617658476007293
Validation loss: 2.287254909706559

Epoch: 6| Step: 9
Training loss: 0.673460044394977
Validation loss: 2.3311223195130806

Epoch: 6| Step: 10
Training loss: 0.704134936341996
Validation loss: 2.4032907282424922

Epoch: 6| Step: 11
Training loss: 1.0094308796346028
Validation loss: 2.3220308162475174

Epoch: 6| Step: 12
Training loss: 0.8098356136654454
Validation loss: 2.3798882718090764

Epoch: 6| Step: 13
Training loss: 0.56881284156976
Validation loss: 2.3930925062018678

Epoch: 491| Step: 0
Training loss: 0.886368434455085
Validation loss: 2.4489688354902914

Epoch: 6| Step: 1
Training loss: 1.1920905477515944
Validation loss: 2.3984820654471366

Epoch: 6| Step: 2
Training loss: 0.9013274443389817
Validation loss: 2.341020611806419

Epoch: 6| Step: 3
Training loss: 0.719051007805228
Validation loss: 2.4088668273930076

Epoch: 6| Step: 4
Training loss: 0.8326745568523407
Validation loss: 2.4090739804020678

Epoch: 6| Step: 5
Training loss: 0.7953453341977861
Validation loss: 2.407348920973958

Epoch: 6| Step: 6
Training loss: 0.7705475732869219
Validation loss: 2.4438648889354946

Epoch: 6| Step: 7
Training loss: 1.0426424923490345
Validation loss: 2.330022094703136

Epoch: 6| Step: 8
Training loss: 1.2696336440828404
Validation loss: 2.2619862757500986

Epoch: 6| Step: 9
Training loss: 1.7998239616566647
Validation loss: 2.3285706533937764

Epoch: 6| Step: 10
Training loss: 1.2439603330568105
Validation loss: 2.3593327176828836

Epoch: 6| Step: 11
Training loss: 1.219407124528786
Validation loss: 2.3725443106103405

Epoch: 6| Step: 12
Training loss: 0.927459226262149
Validation loss: 2.3439546305701286

Epoch: 6| Step: 13
Training loss: 0.8208379243506086
Validation loss: 2.336716579649458

Epoch: 492| Step: 0
Training loss: 0.9220420879948181
Validation loss: 2.3320845816350966

Epoch: 6| Step: 1
Training loss: 1.9116166038021984
Validation loss: 2.2970744516503014

Epoch: 6| Step: 2
Training loss: 0.990606896268121
Validation loss: 2.3074917048345838

Epoch: 6| Step: 3
Training loss: 0.9833287931326671
Validation loss: 2.3278423423214827

Epoch: 6| Step: 4
Training loss: 0.8178613280666971
Validation loss: 2.4288285257136373

Epoch: 6| Step: 5
Training loss: 1.3703497800029518
Validation loss: 2.323056467371475

Epoch: 6| Step: 6
Training loss: 0.633057817545546
Validation loss: 2.3648906622063315

Epoch: 6| Step: 7
Training loss: 1.0009596511528744
Validation loss: 2.3550509781940634

Epoch: 6| Step: 8
Training loss: 0.724470963329947
Validation loss: 2.27160338363718

Epoch: 6| Step: 9
Training loss: 0.952402810572515
Validation loss: 2.328281888144237

Epoch: 6| Step: 10
Training loss: 1.082023152345179
Validation loss: 2.342296031764439

Epoch: 6| Step: 11
Training loss: 0.7620215572126348
Validation loss: 2.291822994937276

Epoch: 6| Step: 12
Training loss: 0.9074243960138214
Validation loss: 2.3522266244199077

Epoch: 6| Step: 13
Training loss: 0.8978254140581693
Validation loss: 2.393366614831378

Epoch: 493| Step: 0
Training loss: 1.9475763469025187
Validation loss: 2.373646569092227

Epoch: 6| Step: 1
Training loss: 0.6751747717476416
Validation loss: 2.3928218364002154

Epoch: 6| Step: 2
Training loss: 0.865186461764606
Validation loss: 2.3624529402695047

Epoch: 6| Step: 3
Training loss: 0.9500658941003142
Validation loss: 2.291275259098832

Epoch: 6| Step: 4
Training loss: 1.0579263194844364
Validation loss: 2.349568098616724

Epoch: 6| Step: 5
Training loss: 0.9256869561828207
Validation loss: 2.3778650039898044

Epoch: 6| Step: 6
Training loss: 1.1313436522102214
Validation loss: 2.3729854193451936

Epoch: 6| Step: 7
Training loss: 0.86620443485748
Validation loss: 2.3967530197865075

Epoch: 6| Step: 8
Training loss: 0.9528326305290951
Validation loss: 2.315901534132601

Epoch: 6| Step: 9
Training loss: 0.9027695745111739
Validation loss: 2.2686266496384015

Epoch: 6| Step: 10
Training loss: 0.9972555528334578
Validation loss: 2.3593651740712938

Epoch: 6| Step: 11
Training loss: 0.47879572864095593
Validation loss: 2.30191515347803

Epoch: 6| Step: 12
Training loss: 0.7481139628553042
Validation loss: 2.3552386012040922

Epoch: 6| Step: 13
Training loss: 1.2471778004803675
Validation loss: 2.3599578435235773

Epoch: 494| Step: 0
Training loss: 1.1835126691687274
Validation loss: 2.3432284840732867

Epoch: 6| Step: 1
Training loss: 1.148927181970964
Validation loss: 2.353631752596401

Epoch: 6| Step: 2
Training loss: 0.9507585446006115
Validation loss: 2.3168097160239753

Epoch: 6| Step: 3
Training loss: 0.6371045494247671
Validation loss: 2.385474150633544

Epoch: 6| Step: 4
Training loss: 0.9627137553669024
Validation loss: 2.3717192905408657

Epoch: 6| Step: 5
Training loss: 0.8812052181039183
Validation loss: 2.302669450718457

Epoch: 6| Step: 6
Training loss: 0.9123529276489943
Validation loss: 2.3547424307821574

Epoch: 6| Step: 7
Training loss: 1.2527153563237825
Validation loss: 2.302164381927309

Epoch: 6| Step: 8
Training loss: 0.8644615148799963
Validation loss: 2.3968526094284486

Epoch: 6| Step: 9
Training loss: 1.725671598751002
Validation loss: 2.3508150117824846

Epoch: 6| Step: 10
Training loss: 1.265229716797345
Validation loss: 2.31366150035531

Epoch: 6| Step: 11
Training loss: 0.8336589812735814
Validation loss: 2.3159908584950455

Epoch: 6| Step: 12
Training loss: 0.6590791074524323
Validation loss: 2.3268648392819533

Epoch: 6| Step: 13
Training loss: 0.5742736582551343
Validation loss: 2.3783052110421066

Epoch: 495| Step: 0
Training loss: 0.8801745609523433
Validation loss: 2.3846441025325196

Epoch: 6| Step: 1
Training loss: 0.7878767868135512
Validation loss: 2.3170399997185585

Epoch: 6| Step: 2
Training loss: 0.8634968829228479
Validation loss: 2.4662087589443096

Epoch: 6| Step: 3
Training loss: 1.1026437201213042
Validation loss: 2.362515360047697

Epoch: 6| Step: 4
Training loss: 0.7176793043211296
Validation loss: 2.397462720047229

Epoch: 6| Step: 5
Training loss: 0.891010268018407
Validation loss: 2.362624139839885

Epoch: 6| Step: 6
Training loss: 0.8747712244956898
Validation loss: 2.4508836292466496

Epoch: 6| Step: 7
Training loss: 1.1552072926898715
Validation loss: 2.4680245339404774

Epoch: 6| Step: 8
Training loss: 1.0060678210518565
Validation loss: 2.417368954067481

Epoch: 6| Step: 9
Training loss: 0.7923597430715992
Validation loss: 2.3215442585372688

Epoch: 6| Step: 10
Training loss: 1.134783378632904
Validation loss: 2.333361109848056

Epoch: 6| Step: 11
Training loss: 0.8049444140322372
Validation loss: 2.3510297093274604

Epoch: 6| Step: 12
Training loss: 0.5689329157119406
Validation loss: 2.2969358792055834

Epoch: 6| Step: 13
Training loss: 2.330514488065511
Validation loss: 2.316069508990619

Epoch: 496| Step: 0
Training loss: 1.755538418876664
Validation loss: 2.337558539592351

Epoch: 6| Step: 1
Training loss: 0.870031076402415
Validation loss: 2.3690870594968

Epoch: 6| Step: 2
Training loss: 1.105019737688772
Validation loss: 2.390389521931122

Epoch: 6| Step: 3
Training loss: 0.8804713576649703
Validation loss: 2.4088171257933753

Epoch: 6| Step: 4
Training loss: 1.1325576495556222
Validation loss: 2.371561235742064

Epoch: 6| Step: 5
Training loss: 1.0509932633827408
Validation loss: 2.3339519149562657

Epoch: 6| Step: 6
Training loss: 0.9414000451607629
Validation loss: 2.297883378914382

Epoch: 6| Step: 7
Training loss: 0.777676573386808
Validation loss: 2.345352737262937

Epoch: 6| Step: 8
Training loss: 0.8161824846020859
Validation loss: 2.3725530434230166

Epoch: 6| Step: 9
Training loss: 0.5815245707922315
Validation loss: 2.4105249132489077

Epoch: 6| Step: 10
Training loss: 1.2206785153769324
Validation loss: 2.443765081912951

Epoch: 6| Step: 11
Training loss: 0.9584550814762004
Validation loss: 2.459619818130151

Epoch: 6| Step: 12
Training loss: 1.3974836282334115
Validation loss: 2.5128254595111708

Epoch: 6| Step: 13
Training loss: 1.1682552126689187
Validation loss: 2.4531465849100846

Epoch: 497| Step: 0
Training loss: 1.1989048351258116
Validation loss: 2.4747840202082774

Epoch: 6| Step: 1
Training loss: 0.6926581046649481
Validation loss: 2.401730097294797

Epoch: 6| Step: 2
Training loss: 0.7672528846987294
Validation loss: 2.3563449795541076

Epoch: 6| Step: 3
Training loss: 1.7380995066068408
Validation loss: 2.3900501810271084

Epoch: 6| Step: 4
Training loss: 1.0705882921400716
Validation loss: 2.361611739023479

Epoch: 6| Step: 5
Training loss: 0.786088077385941
Validation loss: 2.366070857942269

Epoch: 6| Step: 6
Training loss: 0.66716253694026
Validation loss: 2.3521126318366177

Epoch: 6| Step: 7
Training loss: 0.9926386130561645
Validation loss: 2.2770229368254924

Epoch: 6| Step: 8
Training loss: 1.0488777930293325
Validation loss: 2.3518097531897872

Epoch: 6| Step: 9
Training loss: 1.04174561519263
Validation loss: 2.3144150519970306

Epoch: 6| Step: 10
Training loss: 0.9030719477504953
Validation loss: 2.3828067536724378

Epoch: 6| Step: 11
Training loss: 0.9509585726907506
Validation loss: 2.304286197007584

Epoch: 6| Step: 12
Training loss: 0.5985179249478172
Validation loss: 2.4228680128621556

Epoch: 6| Step: 13
Training loss: 1.044659676142781
Validation loss: 2.408717416719102

Epoch: 498| Step: 0
Training loss: 0.8655114688168514
Validation loss: 2.397283465296518

Epoch: 6| Step: 1
Training loss: 0.9558928901212407
Validation loss: 2.3168900283494307

Epoch: 6| Step: 2
Training loss: 1.32734765135858
Validation loss: 2.433884715414085

Epoch: 6| Step: 3
Training loss: 1.7323276704895427
Validation loss: 2.3649071038131155

Epoch: 6| Step: 4
Training loss: 0.6954432803829382
Validation loss: 2.322021489205243

Epoch: 6| Step: 5
Training loss: 0.8014621352034583
Validation loss: 2.384844176645232

Epoch: 6| Step: 6
Training loss: 0.6698954273931094
Validation loss: 2.340060106541825

Epoch: 6| Step: 7
Training loss: 0.7902097387994453
Validation loss: 2.3896911972100265

Epoch: 6| Step: 8
Training loss: 1.0824004827482807
Validation loss: 2.3404972324509505

Epoch: 6| Step: 9
Training loss: 0.9899615451780925
Validation loss: 2.328094161229173

Epoch: 6| Step: 10
Training loss: 0.7410861627752139
Validation loss: 2.383934198899802

Epoch: 6| Step: 11
Training loss: 0.7169336089809376
Validation loss: 2.3478681730657143

Epoch: 6| Step: 12
Training loss: 0.804479220203156
Validation loss: 2.342364529981997

Epoch: 6| Step: 13
Training loss: 0.7198034941552167
Validation loss: 2.303887979862038

Epoch: 499| Step: 0
Training loss: 0.7638431366792103
Validation loss: 2.3589172136478136

Epoch: 6| Step: 1
Training loss: 0.5079686731662886
Validation loss: 2.3330150286790143

Epoch: 6| Step: 2
Training loss: 0.8288518486903022
Validation loss: 2.338394319536877

Epoch: 6| Step: 3
Training loss: 0.8515560954841767
Validation loss: 2.381559726686298

Epoch: 6| Step: 4
Training loss: 1.0505643145606651
Validation loss: 2.3737793977183848

Epoch: 6| Step: 5
Training loss: 0.9665714810358377
Validation loss: 2.3532122754562894

Epoch: 6| Step: 6
Training loss: 0.9530291587295551
Validation loss: 2.3830921683421344

Epoch: 6| Step: 7
Training loss: 1.3371090576100175
Validation loss: 2.375966294326816

Epoch: 6| Step: 8
Training loss: 0.83675547714196
Validation loss: 2.3464919094648247

Epoch: 6| Step: 9
Training loss: 1.1240470877113895
Validation loss: 2.337087090648539

Epoch: 6| Step: 10
Training loss: 0.7006741725806634
Validation loss: 2.31541759907353

Epoch: 6| Step: 11
Training loss: 0.836239733383496
Validation loss: 2.3707023406071084

Epoch: 6| Step: 12
Training loss: 0.8602977307178082
Validation loss: 2.3433862864715507

Epoch: 6| Step: 13
Training loss: 2.3257913862833366
Validation loss: 2.3275492484027502

Epoch: 500| Step: 0
Training loss: 0.6225269982791315
Validation loss: 2.4775995585874826

Epoch: 6| Step: 1
Training loss: 1.2095628380602261
Validation loss: 2.3704185121062245

Epoch: 6| Step: 2
Training loss: 1.007918951045887
Validation loss: 2.368174486288513

Epoch: 6| Step: 3
Training loss: 1.986749144939288
Validation loss: 2.397196720899448

Epoch: 6| Step: 4
Training loss: 0.604402600183833
Validation loss: 2.3964598369347536

Epoch: 6| Step: 5
Training loss: 0.9699913808105414
Validation loss: 2.3541320540874464

Epoch: 6| Step: 6
Training loss: 0.775948273502919
Validation loss: 2.3060095347462517

Epoch: 6| Step: 7
Training loss: 0.8146507334488182
Validation loss: 2.3097818824710905

Epoch: 6| Step: 8
Training loss: 0.8709347840736619
Validation loss: 2.337172907502277

Epoch: 6| Step: 9
Training loss: 1.1798798360094005
Validation loss: 2.3846640830165553

Epoch: 6| Step: 10
Training loss: 0.8090945917972103
Validation loss: 2.3708793890711783

Epoch: 6| Step: 11
Training loss: 1.089923924057337
Validation loss: 2.343273043759792

Epoch: 6| Step: 12
Training loss: 0.8750416881984566
Validation loss: 2.378904869523318

Epoch: 6| Step: 13
Training loss: 0.7008310408749396
Validation loss: 2.318943707549596

Epoch: 501| Step: 0
Training loss: 0.8457299067461165
Validation loss: 2.3983544626599116

Epoch: 6| Step: 1
Training loss: 0.9645700413973848
Validation loss: 2.3075427561763826

Epoch: 6| Step: 2
Training loss: 0.830312825850027
Validation loss: 2.316051633710009

Epoch: 6| Step: 3
Training loss: 0.7727446487201978
Validation loss: 2.357813215484301

Epoch: 6| Step: 4
Training loss: 1.0329962308728122
Validation loss: 2.400466921337307

Epoch: 6| Step: 5
Training loss: 0.9078157973106501
Validation loss: 2.3208516066635565

Epoch: 6| Step: 6
Training loss: 0.7708311381609478
Validation loss: 2.339237529926089

Epoch: 6| Step: 7
Training loss: 1.1493264215937147
Validation loss: 2.303745608597531

Epoch: 6| Step: 8
Training loss: 0.6759039706777675
Validation loss: 2.400490448729386

Epoch: 6| Step: 9
Training loss: 1.7717676577607906
Validation loss: 2.3814507224111554

Epoch: 6| Step: 10
Training loss: 0.9948152003408898
Validation loss: 2.398405219622378

Epoch: 6| Step: 11
Training loss: 1.0931390418344387
Validation loss: 2.3664760396994606

Epoch: 6| Step: 12
Training loss: 1.1728269652265626
Validation loss: 2.3297356694422864

Epoch: 6| Step: 13
Training loss: 0.775533283476149
Validation loss: 2.299011391000413

Epoch: 502| Step: 0
Training loss: 1.0219272798469616
Validation loss: 2.3616963526428907

Epoch: 6| Step: 1
Training loss: 1.7719310125953598
Validation loss: 2.4042729263537073

Epoch: 6| Step: 2
Training loss: 0.9690270181635016
Validation loss: 2.3017362675328115

Epoch: 6| Step: 3
Training loss: 0.5163500052566505
Validation loss: 2.3783839480323103

Epoch: 6| Step: 4
Training loss: 0.8187190974569797
Validation loss: 2.347782920767178

Epoch: 6| Step: 5
Training loss: 1.3125821042492953
Validation loss: 2.381173870461038

Epoch: 6| Step: 6
Training loss: 0.6638835890366438
Validation loss: 2.4025545118660467

Epoch: 6| Step: 7
Training loss: 0.9335168463663623
Validation loss: 2.3341972763010306

Epoch: 6| Step: 8
Training loss: 0.8234482911070593
Validation loss: 2.4317991694364096

Epoch: 6| Step: 9
Training loss: 0.9874790237709838
Validation loss: 2.3485038488087557

Epoch: 6| Step: 10
Training loss: 0.7059054606117179
Validation loss: 2.323824685493413

Epoch: 6| Step: 11
Training loss: 0.6177820890715111
Validation loss: 2.3530611002594983

Epoch: 6| Step: 12
Training loss: 0.9637966265451352
Validation loss: 2.331792708086716

Epoch: 6| Step: 13
Training loss: 0.5007543238216524
Validation loss: 2.292605286359771

Epoch: 503| Step: 0
Training loss: 0.7569172083380852
Validation loss: 2.4195063990800794

Epoch: 6| Step: 1
Training loss: 0.8969163041123969
Validation loss: 2.3957616933533084

Epoch: 6| Step: 2
Training loss: 0.8897336213484659
Validation loss: 2.3774719284172408

Epoch: 6| Step: 3
Training loss: 1.0810330741120822
Validation loss: 2.3109675648117562

Epoch: 6| Step: 4
Training loss: 0.6802592010716946
Validation loss: 2.3533158096429814

Epoch: 6| Step: 5
Training loss: 0.8430118510882791
Validation loss: 2.410230045023521

Epoch: 6| Step: 6
Training loss: 0.7736189658243534
Validation loss: 2.4069422437413377

Epoch: 6| Step: 7
Training loss: 1.0123054835592207
Validation loss: 2.2906495235669078

Epoch: 6| Step: 8
Training loss: 1.7600063620799125
Validation loss: 2.374371477302123

Epoch: 6| Step: 9
Training loss: 1.0258882023763722
Validation loss: 2.373790722389753

Epoch: 6| Step: 10
Training loss: 0.8014249122129073
Validation loss: 2.3972643134422618

Epoch: 6| Step: 11
Training loss: 0.6015740182938092
Validation loss: 2.397830173432875

Epoch: 6| Step: 12
Training loss: 1.239767488322804
Validation loss: 2.3342450297431956

Epoch: 6| Step: 13
Training loss: 0.8902865653580487
Validation loss: 2.3636822014517356

Epoch: 504| Step: 0
Training loss: 1.600423864010603
Validation loss: 2.339007160119779

Epoch: 6| Step: 1
Training loss: 0.5881641550032979
Validation loss: 2.360450649922829

Epoch: 6| Step: 2
Training loss: 0.8927080322823003
Validation loss: 2.3709460970013585

Epoch: 6| Step: 3
Training loss: 1.0466847602734124
Validation loss: 2.354771610309265

Epoch: 6| Step: 4
Training loss: 1.783748681135432
Validation loss: 2.4494512102610018

Epoch: 6| Step: 5
Training loss: 0.8306664749135592
Validation loss: 2.3733468165999194

Epoch: 6| Step: 6
Training loss: 0.9293616228609577
Validation loss: 2.330798200413446

Epoch: 6| Step: 7
Training loss: 0.8100645905514732
Validation loss: 2.387572775746679

Epoch: 6| Step: 8
Training loss: 0.8966979061295826
Validation loss: 2.369580628739983

Epoch: 6| Step: 9
Training loss: 0.766735828085851
Validation loss: 2.3690183307832617

Epoch: 6| Step: 10
Training loss: 0.8354447240390854
Validation loss: 2.3078214638560426

Epoch: 6| Step: 11
Training loss: 0.9230808841027347
Validation loss: 2.3769431398494283

Epoch: 6| Step: 12
Training loss: 0.8461655548426014
Validation loss: 2.4154438118687707

Epoch: 6| Step: 13
Training loss: 0.9384228932161374
Validation loss: 2.4346965921265777

Epoch: 505| Step: 0
Training loss: 1.915275096207548
Validation loss: 2.3380603506449664

Epoch: 6| Step: 1
Training loss: 0.9703001724909787
Validation loss: 2.3954848718677417

Epoch: 6| Step: 2
Training loss: 0.8559585632206057
Validation loss: 2.395282628210172

Epoch: 6| Step: 3
Training loss: 0.7886473819581588
Validation loss: 2.2827234301389963

Epoch: 6| Step: 4
Training loss: 0.7179055436199401
Validation loss: 2.356019172101852

Epoch: 6| Step: 5
Training loss: 0.9777278203435904
Validation loss: 2.327167653033597

Epoch: 6| Step: 6
Training loss: 0.9204856942747184
Validation loss: 2.3611984025268176

Epoch: 6| Step: 7
Training loss: 0.7409867461534019
Validation loss: 2.3930088720098786

Epoch: 6| Step: 8
Training loss: 0.6983918996513757
Validation loss: 2.37243645789272

Epoch: 6| Step: 9
Training loss: 0.7130714082765794
Validation loss: 2.4260445599292217

Epoch: 6| Step: 10
Training loss: 1.0854582792616956
Validation loss: 2.385775805102367

Epoch: 6| Step: 11
Training loss: 0.8605443454866293
Validation loss: 2.3015467034472894

Epoch: 6| Step: 12
Training loss: 0.7904854964265505
Validation loss: 2.4128582117559385

Epoch: 6| Step: 13
Training loss: 0.7920446413781562
Validation loss: 2.392304760817641

Epoch: 506| Step: 0
Training loss: 0.8016205645791994
Validation loss: 2.3783542783355753

Epoch: 6| Step: 1
Training loss: 1.008955905703178
Validation loss: 2.3832212251226235

Epoch: 6| Step: 2
Training loss: 0.9485005302789681
Validation loss: 2.3253478004335015

Epoch: 6| Step: 3
Training loss: 0.8605045178309755
Validation loss: 2.4556245638121603

Epoch: 6| Step: 4
Training loss: 0.6360233464514433
Validation loss: 2.3739035913977515

Epoch: 6| Step: 5
Training loss: 1.7604677618011602
Validation loss: 2.3136156224128155

Epoch: 6| Step: 6
Training loss: 0.7985606596854529
Validation loss: 2.3471473861847896

Epoch: 6| Step: 7
Training loss: 1.2267965105691843
Validation loss: 2.3915993875435624

Epoch: 6| Step: 8
Training loss: 0.9953890832395494
Validation loss: 2.3230671023898655

Epoch: 6| Step: 9
Training loss: 0.8021566349239496
Validation loss: 2.3237911093949637

Epoch: 6| Step: 10
Training loss: 0.7561488028670889
Validation loss: 2.2841352309301772

Epoch: 6| Step: 11
Training loss: 0.839757693117772
Validation loss: 2.307179206143133

Epoch: 6| Step: 12
Training loss: 0.9853037131631833
Validation loss: 2.282704948950904

Epoch: 6| Step: 13
Training loss: 0.7900482290370375
Validation loss: 2.2710756438090227

Epoch: 507| Step: 0
Training loss: 0.733787545148526
Validation loss: 2.2821261568822178

Epoch: 6| Step: 1
Training loss: 1.8929453081229468
Validation loss: 2.367929484813064

Epoch: 6| Step: 2
Training loss: 1.0389494870328562
Validation loss: 2.4182212385388513

Epoch: 6| Step: 3
Training loss: 0.7709371050155982
Validation loss: 2.337461368977925

Epoch: 6| Step: 4
Training loss: 0.8437357654077227
Validation loss: 2.401985321665108

Epoch: 6| Step: 5
Training loss: 0.9008538963754035
Validation loss: 2.3737913962956347

Epoch: 6| Step: 6
Training loss: 0.7435377587489793
Validation loss: 2.3625093863893754

Epoch: 6| Step: 7
Training loss: 0.5057620098424745
Validation loss: 2.4029123453253303

Epoch: 6| Step: 8
Training loss: 0.8048379627775845
Validation loss: 2.2895556704732374

Epoch: 6| Step: 9
Training loss: 0.7687654509193436
Validation loss: 2.400018216883492

Epoch: 6| Step: 10
Training loss: 1.1539980635535854
Validation loss: 2.406113527878931

Epoch: 6| Step: 11
Training loss: 0.8573398420503072
Validation loss: 2.326917279039649

Epoch: 6| Step: 12
Training loss: 1.0270821706108852
Validation loss: 2.2561041035250637

Epoch: 6| Step: 13
Training loss: 1.296263171269773
Validation loss: 2.453327034517609

Epoch: 508| Step: 0
Training loss: 0.5594373082243832
Validation loss: 2.325240129562613

Epoch: 6| Step: 1
Training loss: 0.6999545780840124
Validation loss: 2.3409800622669983

Epoch: 6| Step: 2
Training loss: 0.8961719641769826
Validation loss: 2.406707662616652

Epoch: 6| Step: 3
Training loss: 0.8550059490666135
Validation loss: 2.336132322802192

Epoch: 6| Step: 4
Training loss: 1.1182083054497634
Validation loss: 2.3512686694158087

Epoch: 6| Step: 5
Training loss: 0.8075493596111094
Validation loss: 2.337096725587346

Epoch: 6| Step: 6
Training loss: 1.0675983961618554
Validation loss: 2.3375743552974595

Epoch: 6| Step: 7
Training loss: 0.6441963481685874
Validation loss: 2.3404550691420236

Epoch: 6| Step: 8
Training loss: 1.7582788823572075
Validation loss: 2.387653240725116

Epoch: 6| Step: 9
Training loss: 0.9140621739574405
Validation loss: 2.350769513772802

Epoch: 6| Step: 10
Training loss: 0.8478779305147741
Validation loss: 2.321579382184194

Epoch: 6| Step: 11
Training loss: 1.1307584358455616
Validation loss: 2.3697717499236908

Epoch: 6| Step: 12
Training loss: 0.9542662245160924
Validation loss: 2.332040484241052

Epoch: 6| Step: 13
Training loss: 1.0498816741393306
Validation loss: 2.412000074131745

Epoch: 509| Step: 0
Training loss: 1.9090129028211982
Validation loss: 2.3822735426220105

Epoch: 6| Step: 1
Training loss: 0.6085844536243908
Validation loss: 2.3644789321733115

Epoch: 6| Step: 2
Training loss: 0.6540432794392306
Validation loss: 2.43117005658351

Epoch: 6| Step: 3
Training loss: 0.5993066079238644
Validation loss: 2.3567915633672336

Epoch: 6| Step: 4
Training loss: 1.0194385237930412
Validation loss: 2.3797411558556227

Epoch: 6| Step: 5
Training loss: 0.8026984362202895
Validation loss: 2.3814906829716285

Epoch: 6| Step: 6
Training loss: 0.9308322302237736
Validation loss: 2.3250447546261164

Epoch: 6| Step: 7
Training loss: 0.7693585816900685
Validation loss: 2.368854635396654

Epoch: 6| Step: 8
Training loss: 1.1985188781085412
Validation loss: 2.347321783701229

Epoch: 6| Step: 9
Training loss: 0.9015541750624362
Validation loss: 2.3399302244603235

Epoch: 6| Step: 10
Training loss: 0.876869248624879
Validation loss: 2.320290941701943

Epoch: 6| Step: 11
Training loss: 1.0933047341952105
Validation loss: 2.3695097623874104

Epoch: 6| Step: 12
Training loss: 0.46329210471291427
Validation loss: 2.364440083326254

Epoch: 6| Step: 13
Training loss: 0.5300308712479497
Validation loss: 2.30394944486975

Epoch: 510| Step: 0
Training loss: 1.1761069622896618
Validation loss: 2.381537425674437

Epoch: 6| Step: 1
Training loss: 1.1106287359497915
Validation loss: 2.38038986618511

Epoch: 6| Step: 2
Training loss: 0.9179151154128543
Validation loss: 2.233625762955318

Epoch: 6| Step: 3
Training loss: 0.7859764938843599
Validation loss: 2.3394742240407242

Epoch: 6| Step: 4
Training loss: 0.7011453310051728
Validation loss: 2.3862581303508157

Epoch: 6| Step: 5
Training loss: 1.0910753517178458
Validation loss: 2.394663750939949

Epoch: 6| Step: 6
Training loss: 1.6549501176444803
Validation loss: 2.3616434997452367

Epoch: 6| Step: 7
Training loss: 0.715604616899347
Validation loss: 2.388701301707173

Epoch: 6| Step: 8
Training loss: 0.8389934049604009
Validation loss: 2.34869301921984

Epoch: 6| Step: 9
Training loss: 0.8161865376780018
Validation loss: 2.3299250251449077

Epoch: 6| Step: 10
Training loss: 0.9710546889240472
Validation loss: 2.370897174287588

Epoch: 6| Step: 11
Training loss: 0.7317461482508049
Validation loss: 2.3550243265549202

Epoch: 6| Step: 12
Training loss: 0.8624378071351855
Validation loss: 2.4229386083755844

Epoch: 6| Step: 13
Training loss: 0.8270546455756965
Validation loss: 2.367676581955884

Epoch: 511| Step: 0
Training loss: 0.5609124882044217
Validation loss: 2.378573770143982

Epoch: 6| Step: 1
Training loss: 0.988652186082767
Validation loss: 2.359099094573885

Epoch: 6| Step: 2
Training loss: 0.9221890448024406
Validation loss: 2.3162568031738275

Epoch: 6| Step: 3
Training loss: 0.8474283571260011
Validation loss: 2.365221628485139

Epoch: 6| Step: 4
Training loss: 1.1245093865314504
Validation loss: 2.296227870775605

Epoch: 6| Step: 5
Training loss: 1.743223216017509
Validation loss: 2.318070868334582

Epoch: 6| Step: 6
Training loss: 0.80495681700182
Validation loss: 2.3617933961631024

Epoch: 6| Step: 7
Training loss: 0.9400408328095344
Validation loss: 2.294178446641019

Epoch: 6| Step: 8
Training loss: 0.8487091908033321
Validation loss: 2.276847239680698

Epoch: 6| Step: 9
Training loss: 0.8275376882354871
Validation loss: 2.345249752813701

Epoch: 6| Step: 10
Training loss: 1.0734636461830058
Validation loss: 2.409585272676839

Epoch: 6| Step: 11
Training loss: 0.8780223895087922
Validation loss: 2.3238059806822537

Epoch: 6| Step: 12
Training loss: 0.9736599932734326
Validation loss: 2.302679561440737

Epoch: 6| Step: 13
Training loss: 0.5560306084272797
Validation loss: 2.3968865300473015

Epoch: 512| Step: 0
Training loss: 0.874677121672231
Validation loss: 2.427134652783271

Epoch: 6| Step: 1
Training loss: 0.6551534938049203
Validation loss: 2.353956080441367

Epoch: 6| Step: 2
Training loss: 0.6617290563580179
Validation loss: 2.383733629513255

Epoch: 6| Step: 3
Training loss: 0.712127946453484
Validation loss: 2.348254717485409

Epoch: 6| Step: 4
Training loss: 0.7304950240198751
Validation loss: 2.3128403543705827

Epoch: 6| Step: 5
Training loss: 0.8169944141201654
Validation loss: 2.3474417823228864

Epoch: 6| Step: 6
Training loss: 0.8628954823790259
Validation loss: 2.3822357216649563

Epoch: 6| Step: 7
Training loss: 0.971299293474922
Validation loss: 2.4301972904427993

Epoch: 6| Step: 8
Training loss: 0.9655028651751573
Validation loss: 2.2788487595353297

Epoch: 6| Step: 9
Training loss: 1.0581253535748345
Validation loss: 2.399653195162425

Epoch: 6| Step: 10
Training loss: 0.719562693021734
Validation loss: 2.4075873315284744

Epoch: 6| Step: 11
Training loss: 1.7548161718487243
Validation loss: 2.314098711259401

Epoch: 6| Step: 12
Training loss: 0.8095471202809255
Validation loss: 2.3726609838984283

Epoch: 6| Step: 13
Training loss: 0.413915698100944
Validation loss: 2.3613612884125463

Epoch: 513| Step: 0
Training loss: 0.8095100849788687
Validation loss: 2.3517981024774177

Epoch: 6| Step: 1
Training loss: 0.6863735464021974
Validation loss: 2.4227749224651953

Epoch: 6| Step: 2
Training loss: 0.9213398171977413
Validation loss: 2.3754624821566126

Epoch: 6| Step: 3
Training loss: 1.8423880379767608
Validation loss: 2.3785324720390384

Epoch: 6| Step: 4
Training loss: 0.713399209236881
Validation loss: 2.3651909639476165

Epoch: 6| Step: 5
Training loss: 0.9981963163348012
Validation loss: 2.3828077714652234

Epoch: 6| Step: 6
Training loss: 0.6988653643235007
Validation loss: 2.3219399311919

Epoch: 6| Step: 7
Training loss: 0.9811444025258402
Validation loss: 2.3357593373639687

Epoch: 6| Step: 8
Training loss: 0.9442481046460163
Validation loss: 2.354804016884726

Epoch: 6| Step: 9
Training loss: 0.7769438131703604
Validation loss: 2.3439780164709916

Epoch: 6| Step: 10
Training loss: 0.8383510365016807
Validation loss: 2.323645993511296

Epoch: 6| Step: 11
Training loss: 1.052263540313602
Validation loss: 2.3880702880379028

Epoch: 6| Step: 12
Training loss: 0.8285570996670975
Validation loss: 2.3019495553834894

Epoch: 6| Step: 13
Training loss: 0.3495790265939171
Validation loss: 2.383136266656768

Epoch: 514| Step: 0
Training loss: 0.7340721155075202
Validation loss: 2.38931767133202

Epoch: 6| Step: 1
Training loss: 1.2554326259351114
Validation loss: 2.3632921303200565

Epoch: 6| Step: 2
Training loss: 0.8087300356209369
Validation loss: 2.3673770703684656

Epoch: 6| Step: 3
Training loss: 0.8914362241233987
Validation loss: 2.386390986439211

Epoch: 6| Step: 4
Training loss: 0.7740757168198588
Validation loss: 2.245004286450555

Epoch: 6| Step: 5
Training loss: 1.2673612388483038
Validation loss: 2.47460917816419

Epoch: 6| Step: 6
Training loss: 1.1557636269028662
Validation loss: 2.3486526174262217

Epoch: 6| Step: 7
Training loss: 0.902539153636671
Validation loss: 2.3395554250215342

Epoch: 6| Step: 8
Training loss: 1.7299247902855648
Validation loss: 2.2152466893692178

Epoch: 6| Step: 9
Training loss: 0.8932446551671497
Validation loss: 2.4024722319977005

Epoch: 6| Step: 10
Training loss: 1.0272338576340119
Validation loss: 2.364564584846828

Epoch: 6| Step: 11
Training loss: 0.6242432781647411
Validation loss: 2.293565343560454

Epoch: 6| Step: 12
Training loss: 0.8093754772052315
Validation loss: 2.379306873373774

Epoch: 6| Step: 13
Training loss: 0.7255519278810304
Validation loss: 2.318196310282788

Epoch: 515| Step: 0
Training loss: 0.7591496890780145
Validation loss: 2.320838814116226

Epoch: 6| Step: 1
Training loss: 1.2178613406150143
Validation loss: 2.3268652138794503

Epoch: 6| Step: 2
Training loss: 0.5391024422705765
Validation loss: 2.3304178636471042

Epoch: 6| Step: 3
Training loss: 0.8731302993821121
Validation loss: 2.3322883505870178

Epoch: 6| Step: 4
Training loss: 0.708321505803114
Validation loss: 2.3476851288544967

Epoch: 6| Step: 5
Training loss: 0.8095780430920484
Validation loss: 2.406272931756096

Epoch: 6| Step: 6
Training loss: 0.8584058672308941
Validation loss: 2.4391474461239016

Epoch: 6| Step: 7
Training loss: 0.6898398030946865
Validation loss: 2.3618665574438937

Epoch: 6| Step: 8
Training loss: 0.9288704110459449
Validation loss: 2.350195172700473

Epoch: 6| Step: 9
Training loss: 0.7195238839931136
Validation loss: 2.3698899984439876

Epoch: 6| Step: 10
Training loss: 1.8591560427186762
Validation loss: 2.350222741931379

Epoch: 6| Step: 11
Training loss: 0.7886548641764175
Validation loss: 2.3276238307749546

Epoch: 6| Step: 12
Training loss: 0.6679332790660801
Validation loss: 2.3382919221650975

Epoch: 6| Step: 13
Training loss: 1.1862008869065561
Validation loss: 2.2924785290883

Epoch: 516| Step: 0
Training loss: 1.04241391400546
Validation loss: 2.343988703122219

Epoch: 6| Step: 1
Training loss: 0.9582275387514849
Validation loss: 2.2619991200618195

Epoch: 6| Step: 2
Training loss: 0.7226423932370823
Validation loss: 2.3305913889375

Epoch: 6| Step: 3
Training loss: 1.17432214176419
Validation loss: 2.3720558561993363

Epoch: 6| Step: 4
Training loss: 0.7185908431599668
Validation loss: 2.3217625113653404

Epoch: 6| Step: 5
Training loss: 0.7627430606602646
Validation loss: 2.387320007452841

Epoch: 6| Step: 6
Training loss: 1.0007201224485849
Validation loss: 2.401377315566856

Epoch: 6| Step: 7
Training loss: 1.7873891809430373
Validation loss: 2.3283816543876945

Epoch: 6| Step: 8
Training loss: 0.909967165448913
Validation loss: 2.2918247701599355

Epoch: 6| Step: 9
Training loss: 0.8556442429111184
Validation loss: 2.3494418165314905

Epoch: 6| Step: 10
Training loss: 0.7555890844500733
Validation loss: 2.3477323333214497

Epoch: 6| Step: 11
Training loss: 1.1099588174311368
Validation loss: 2.337079595804723

Epoch: 6| Step: 12
Training loss: 0.5145828813352672
Validation loss: 2.332387765196531

Epoch: 6| Step: 13
Training loss: 0.9518068297453546
Validation loss: 2.406801291381187

Epoch: 517| Step: 0
Training loss: 1.091592568268155
Validation loss: 2.3725011208379008

Epoch: 6| Step: 1
Training loss: 1.0616647017464254
Validation loss: 2.323276271398579

Epoch: 6| Step: 2
Training loss: 0.7732403436471607
Validation loss: 2.430071752850988

Epoch: 6| Step: 3
Training loss: 0.8981913353746053
Validation loss: 2.307688014845777

Epoch: 6| Step: 4
Training loss: 0.7721553926419522
Validation loss: 2.337301585469379

Epoch: 6| Step: 5
Training loss: 0.8313673352484833
Validation loss: 2.2859898558014855

Epoch: 6| Step: 6
Training loss: 0.6874561295817263
Validation loss: 2.390489418238129

Epoch: 6| Step: 7
Training loss: 0.7902246358651278
Validation loss: 2.3693871280045355

Epoch: 6| Step: 8
Training loss: 1.701739246166868
Validation loss: 2.2935653547379884

Epoch: 6| Step: 9
Training loss: 0.8271421321912309
Validation loss: 2.3971628570728396

Epoch: 6| Step: 10
Training loss: 0.7239573545014788
Validation loss: 2.400861447244254

Epoch: 6| Step: 11
Training loss: 0.5983867544067988
Validation loss: 2.428677750589602

Epoch: 6| Step: 12
Training loss: 0.9948182560161689
Validation loss: 2.2989525751146536

Epoch: 6| Step: 13
Training loss: 1.076673553452645
Validation loss: 2.361542410629631

Epoch: 518| Step: 0
Training loss: 0.9121565551318185
Validation loss: 2.2674225060994195

Epoch: 6| Step: 1
Training loss: 0.7770043020141593
Validation loss: 2.327105724974534

Epoch: 6| Step: 2
Training loss: 0.8394726310299169
Validation loss: 2.3181496583802166

Epoch: 6| Step: 3
Training loss: 0.6608212073353257
Validation loss: 2.415409483725968

Epoch: 6| Step: 4
Training loss: 1.8585269179961805
Validation loss: 2.440631013509659

Epoch: 6| Step: 5
Training loss: 0.8893937752431449
Validation loss: 2.34023746687711

Epoch: 6| Step: 6
Training loss: 0.962958993090152
Validation loss: 2.3845868865005198

Epoch: 6| Step: 7
Training loss: 0.7457999404876513
Validation loss: 2.3606447843512384

Epoch: 6| Step: 8
Training loss: 0.8276589719768268
Validation loss: 2.338211452468245

Epoch: 6| Step: 9
Training loss: 0.8951429249748374
Validation loss: 2.322546689742107

Epoch: 6| Step: 10
Training loss: 0.8292829586951144
Validation loss: 2.411147067471033

Epoch: 6| Step: 11
Training loss: 0.8381568112406141
Validation loss: 2.270551678915984

Epoch: 6| Step: 12
Training loss: 0.9332416461005582
Validation loss: 2.3655470262616576

Epoch: 6| Step: 13
Training loss: 0.848188312390988
Validation loss: 2.4037676524051323

Epoch: 519| Step: 0
Training loss: 0.6552090336038298
Validation loss: 2.351736105720337

Epoch: 6| Step: 1
Training loss: 0.9657507274465958
Validation loss: 2.3063790080593143

Epoch: 6| Step: 2
Training loss: 0.6974145212060314
Validation loss: 2.3459000169059787

Epoch: 6| Step: 3
Training loss: 0.879680174124587
Validation loss: 2.360212636301641

Epoch: 6| Step: 4
Training loss: 0.5380193596444591
Validation loss: 2.338689433304775

Epoch: 6| Step: 5
Training loss: 1.5910269718341545
Validation loss: 2.2777212470286425

Epoch: 6| Step: 6
Training loss: 1.0385018463816273
Validation loss: 2.4127064364883246

Epoch: 6| Step: 7
Training loss: 1.115237795528905
Validation loss: 2.356971691825069

Epoch: 6| Step: 8
Training loss: 1.1683531163799532
Validation loss: 2.3995009596503785

Epoch: 6| Step: 9
Training loss: 0.7698660185287376
Validation loss: 2.3770448962547204

Epoch: 6| Step: 10
Training loss: 0.929979839362793
Validation loss: 2.3608338663950432

Epoch: 6| Step: 11
Training loss: 0.9449012429238779
Validation loss: 2.3101770384494786

Epoch: 6| Step: 12
Training loss: 0.6724237817874863
Validation loss: 2.3844126083746944

Epoch: 6| Step: 13
Training loss: 0.628229025392343
Validation loss: 2.446946616963405

Epoch: 520| Step: 0
Training loss: 0.6595456612103092
Validation loss: 2.4020358941094906

Epoch: 6| Step: 1
Training loss: 0.6500049169060998
Validation loss: 2.449990551302288

Epoch: 6| Step: 2
Training loss: 0.914318016399108
Validation loss: 2.3726439812192175

Epoch: 6| Step: 3
Training loss: 1.8684245205670997
Validation loss: 2.403539694423345

Epoch: 6| Step: 4
Training loss: 0.9618314601073739
Validation loss: 2.3315568532360116

Epoch: 6| Step: 5
Training loss: 0.6127093619042144
Validation loss: 2.364296454527211

Epoch: 6| Step: 6
Training loss: 0.6469512360103813
Validation loss: 2.3832906210052553

Epoch: 6| Step: 7
Training loss: 0.6756838689771263
Validation loss: 2.3452809420676215

Epoch: 6| Step: 8
Training loss: 0.8156655707079788
Validation loss: 2.3727100884991787

Epoch: 6| Step: 9
Training loss: 0.9124159042590271
Validation loss: 2.3488421889691673

Epoch: 6| Step: 10
Training loss: 0.9019017313526834
Validation loss: 2.305645035790829

Epoch: 6| Step: 11
Training loss: 0.9647575988608662
Validation loss: 2.3656059740009927

Epoch: 6| Step: 12
Training loss: 0.7199356831195596
Validation loss: 2.379979048761073

Epoch: 6| Step: 13
Training loss: 1.2551435503987358
Validation loss: 2.338838563676649

Epoch: 521| Step: 0
Training loss: 1.6849677548591726
Validation loss: 2.369827553307091

Epoch: 6| Step: 1
Training loss: 0.9335935584670633
Validation loss: 2.3467221404416265

Epoch: 6| Step: 2
Training loss: 0.8615842338978168
Validation loss: 2.348640490421665

Epoch: 6| Step: 3
Training loss: 0.9162219370334385
Validation loss: 2.345005409611781

Epoch: 6| Step: 4
Training loss: 1.134617439613819
Validation loss: 2.342435314658927

Epoch: 6| Step: 5
Training loss: 0.6112011177316152
Validation loss: 2.3663296456382006

Epoch: 6| Step: 6
Training loss: 1.0583080173578399
Validation loss: 2.3091872276461034

Epoch: 6| Step: 7
Training loss: 0.6118948749903027
Validation loss: 2.331554167057602

Epoch: 6| Step: 8
Training loss: 0.744087477660909
Validation loss: 2.40817334523358

Epoch: 6| Step: 9
Training loss: 0.9413209931955636
Validation loss: 2.3230927213610637

Epoch: 6| Step: 10
Training loss: 0.8975189489101617
Validation loss: 2.3484525673331427

Epoch: 6| Step: 11
Training loss: 0.7639021660392644
Validation loss: 2.4018556016361186

Epoch: 6| Step: 12
Training loss: 0.6644762433227908
Validation loss: 2.2993998855233206

Epoch: 6| Step: 13
Training loss: 0.8893151271287169
Validation loss: 2.3509162132195174

Epoch: 522| Step: 0
Training loss: 0.9033057299287472
Validation loss: 2.373125369466269

Epoch: 6| Step: 1
Training loss: 0.7771941381277582
Validation loss: 2.3571688991930433

Epoch: 6| Step: 2
Training loss: 0.6930666453337045
Validation loss: 2.3070049755456465

Epoch: 6| Step: 3
Training loss: 0.8085911700073951
Validation loss: 2.363605629078399

Epoch: 6| Step: 4
Training loss: 0.7741059006438862
Validation loss: 2.435849423136893

Epoch: 6| Step: 5
Training loss: 0.8115192509622381
Validation loss: 2.3588359727446915

Epoch: 6| Step: 6
Training loss: 0.909373786112706
Validation loss: 2.3550652221049515

Epoch: 6| Step: 7
Training loss: 1.1221530707826664
Validation loss: 2.3717813956518032

Epoch: 6| Step: 8
Training loss: 0.9567037216568693
Validation loss: 2.3184422089606636

Epoch: 6| Step: 9
Training loss: 1.0279178538249232
Validation loss: 2.3776038974647293

Epoch: 6| Step: 10
Training loss: 1.715527791255385
Validation loss: 2.3349159589686157

Epoch: 6| Step: 11
Training loss: 0.8149474768301085
Validation loss: 2.328008239861825

Epoch: 6| Step: 12
Training loss: 0.7887616103174736
Validation loss: 2.355318875565588

Epoch: 6| Step: 13
Training loss: 0.9786123810404158
Validation loss: 2.352350295648108

Epoch: 523| Step: 0
Training loss: 0.7627161391927786
Validation loss: 2.329473339170842

Epoch: 6| Step: 1
Training loss: 0.8983990868359117
Validation loss: 2.362314457792983

Epoch: 6| Step: 2
Training loss: 0.7789874310979175
Validation loss: 2.3625400173697844

Epoch: 6| Step: 3
Training loss: 1.510644654354066
Validation loss: 2.3730938002244737

Epoch: 6| Step: 4
Training loss: 0.7170244318259079
Validation loss: 2.3408207461948

Epoch: 6| Step: 5
Training loss: 1.6863166757441925
Validation loss: 2.3471905324166036

Epoch: 6| Step: 6
Training loss: 0.7349146219866647
Validation loss: 2.3686167394721496

Epoch: 6| Step: 7
Training loss: 0.8153231431259801
Validation loss: 2.3405385696762373

Epoch: 6| Step: 8
Training loss: 0.8210355569269657
Validation loss: 2.3524898616075425

Epoch: 6| Step: 9
Training loss: 0.743903455210201
Validation loss: 2.4296683118242077

Epoch: 6| Step: 10
Training loss: 0.830809578347125
Validation loss: 2.3010351237803883

Epoch: 6| Step: 11
Training loss: 0.9461829221425611
Validation loss: 2.291948601131384

Epoch: 6| Step: 12
Training loss: 0.8517421567895573
Validation loss: 2.3468260914917565

Epoch: 6| Step: 13
Training loss: 0.8786501702135859
Validation loss: 2.3805182143887915

Epoch: 524| Step: 0
Training loss: 0.8863043804190867
Validation loss: 2.366866805990398

Epoch: 6| Step: 1
Training loss: 0.5858752153989129
Validation loss: 2.405646370034461

Epoch: 6| Step: 2
Training loss: 0.7216690331112633
Validation loss: 2.324809809736824

Epoch: 6| Step: 3
Training loss: 0.5789746922280542
Validation loss: 2.3195739252325276

Epoch: 6| Step: 4
Training loss: 0.8246855656759077
Validation loss: 2.3308358864691416

Epoch: 6| Step: 5
Training loss: 1.0369937350930885
Validation loss: 2.3706056839542886

Epoch: 6| Step: 6
Training loss: 1.3138514327682125
Validation loss: 2.418104480947719

Epoch: 6| Step: 7
Training loss: 0.7876713641986204
Validation loss: 2.3914233295685308

Epoch: 6| Step: 8
Training loss: 0.6936923664656799
Validation loss: 2.3029830010595607

Epoch: 6| Step: 9
Training loss: 0.6337961628520561
Validation loss: 2.3982077183836914

Epoch: 6| Step: 10
Training loss: 1.0537767787440402
Validation loss: 2.325294421230057

Epoch: 6| Step: 11
Training loss: 1.7811061064840947
Validation loss: 2.320210979129102

Epoch: 6| Step: 12
Training loss: 0.9157337657917263
Validation loss: 2.2978764596236534

Epoch: 6| Step: 13
Training loss: 0.949426259408032
Validation loss: 2.3383392345762224

Epoch: 525| Step: 0
Training loss: 0.9855547601881071
Validation loss: 2.3015092891184414

Epoch: 6| Step: 1
Training loss: 0.8642853640890031
Validation loss: 2.3293812928509774

Epoch: 6| Step: 2
Training loss: 0.6619828815090854
Validation loss: 2.3430933720946068

Epoch: 6| Step: 3
Training loss: 0.737216646104218
Validation loss: 2.33241382366484

Epoch: 6| Step: 4
Training loss: 1.155335606041368
Validation loss: 2.3516461168736713

Epoch: 6| Step: 5
Training loss: 0.7262630050466495
Validation loss: 2.369161152296547

Epoch: 6| Step: 6
Training loss: 1.0183847931212724
Validation loss: 2.3633453119094345

Epoch: 6| Step: 7
Training loss: 0.7410290561518555
Validation loss: 2.4027198852537692

Epoch: 6| Step: 8
Training loss: 0.8972471893768208
Validation loss: 2.3576895181964024

Epoch: 6| Step: 9
Training loss: 0.6493088945403807
Validation loss: 2.3533274212498925

Epoch: 6| Step: 10
Training loss: 0.6874579936979515
Validation loss: 2.3467136079650968

Epoch: 6| Step: 11
Training loss: 0.8772429601126474
Validation loss: 2.4396880966968832

Epoch: 6| Step: 12
Training loss: 1.8481436282197266
Validation loss: 2.38720089654289

Epoch: 6| Step: 13
Training loss: 1.2847900332634352
Validation loss: 2.3338651563756017

Epoch: 526| Step: 0
Training loss: 0.8285952258685868
Validation loss: 2.3728885850535173

Epoch: 6| Step: 1
Training loss: 0.48456978726771777
Validation loss: 2.3172208860815617

Epoch: 6| Step: 2
Training loss: 0.8207583351211658
Validation loss: 2.370631724069714

Epoch: 6| Step: 3
Training loss: 0.7195260792234766
Validation loss: 2.390975863131019

Epoch: 6| Step: 4
Training loss: 1.6510386983401535
Validation loss: 2.3412238945527846

Epoch: 6| Step: 5
Training loss: 1.153536525166229
Validation loss: 2.395749221616465

Epoch: 6| Step: 6
Training loss: 0.5618215549073272
Validation loss: 2.3288526667631664

Epoch: 6| Step: 7
Training loss: 0.819922508904665
Validation loss: 2.2990861185923483

Epoch: 6| Step: 8
Training loss: 0.7181769450020155
Validation loss: 2.3886890834187513

Epoch: 6| Step: 9
Training loss: 0.7547464383253861
Validation loss: 2.3440301291573205

Epoch: 6| Step: 10
Training loss: 0.6942151014123513
Validation loss: 2.306035815695383

Epoch: 6| Step: 11
Training loss: 0.7834640410788712
Validation loss: 2.324408799430334

Epoch: 6| Step: 12
Training loss: 0.7036894757684973
Validation loss: 2.3201434058389188

Epoch: 6| Step: 13
Training loss: 1.3589271596962464
Validation loss: 2.325509894617609

Epoch: 527| Step: 0
Training loss: 0.6423126878328894
Validation loss: 2.371926542097654

Epoch: 6| Step: 1
Training loss: 0.8243193361636785
Validation loss: 2.2710005369455204

Epoch: 6| Step: 2
Training loss: 0.607313189335073
Validation loss: 2.3057274637165253

Epoch: 6| Step: 3
Training loss: 0.863321847090538
Validation loss: 2.3586768307348107

Epoch: 6| Step: 4
Training loss: 1.1138694949111971
Validation loss: 2.3463905232137754

Epoch: 6| Step: 5
Training loss: 0.9794888710277696
Validation loss: 2.370241255079554

Epoch: 6| Step: 6
Training loss: 0.7463711527461873
Validation loss: 2.3552890029380817

Epoch: 6| Step: 7
Training loss: 0.6891199230738465
Validation loss: 2.339614345525543

Epoch: 6| Step: 8
Training loss: 0.8111331887339605
Validation loss: 2.390686495485505

Epoch: 6| Step: 9
Training loss: 1.6844806503538787
Validation loss: 2.355971757716419

Epoch: 6| Step: 10
Training loss: 0.9864432994713378
Validation loss: 2.356399422201578

Epoch: 6| Step: 11
Training loss: 0.8306625642455775
Validation loss: 2.276433003823899

Epoch: 6| Step: 12
Training loss: 0.8491281132904218
Validation loss: 2.3019355056806803

Epoch: 6| Step: 13
Training loss: 0.8145463556220439
Validation loss: 2.356093717198892

Epoch: 528| Step: 0
Training loss: 0.7393837422154773
Validation loss: 2.34106303459208

Epoch: 6| Step: 1
Training loss: 0.7942376718738057
Validation loss: 2.40101115085211

Epoch: 6| Step: 2
Training loss: 1.0746145178263775
Validation loss: 2.2600587149639506

Epoch: 6| Step: 3
Training loss: 0.8279985295296479
Validation loss: 2.3825816063625895

Epoch: 6| Step: 4
Training loss: 1.7132249982081962
Validation loss: 2.347821885269608

Epoch: 6| Step: 5
Training loss: 0.8796266782071605
Validation loss: 2.303768673780272

Epoch: 6| Step: 6
Training loss: 0.7028517722033734
Validation loss: 2.363151329901389

Epoch: 6| Step: 7
Training loss: 0.6013123128248573
Validation loss: 2.4366088639147176

Epoch: 6| Step: 8
Training loss: 0.9129094080692282
Validation loss: 2.318119292391825

Epoch: 6| Step: 9
Training loss: 0.8259714302774906
Validation loss: 2.3533696317198785

Epoch: 6| Step: 10
Training loss: 0.726438080994276
Validation loss: 2.3594688337649816

Epoch: 6| Step: 11
Training loss: 0.9075010806200724
Validation loss: 2.3654499757934415

Epoch: 6| Step: 12
Training loss: 1.0698872856239667
Validation loss: 2.3785327021545637

Epoch: 6| Step: 13
Training loss: 0.9398123199204972
Validation loss: 2.3825730274566115

Epoch: 529| Step: 0
Training loss: 0.9355285897588403
Validation loss: 2.2444502603695886

Epoch: 6| Step: 1
Training loss: 0.9902006064531583
Validation loss: 2.2939038933673523

Epoch: 6| Step: 2
Training loss: 0.7351815279142687
Validation loss: 2.2844057191073

Epoch: 6| Step: 3
Training loss: 0.6541715587343954
Validation loss: 2.42548589216308

Epoch: 6| Step: 4
Training loss: 0.6230060480307955
Validation loss: 2.3578180572079597

Epoch: 6| Step: 5
Training loss: 0.7661419894089384
Validation loss: 2.30413773982168

Epoch: 6| Step: 6
Training loss: 0.7379251256968037
Validation loss: 2.273527716934988

Epoch: 6| Step: 7
Training loss: 1.8003366049642817
Validation loss: 2.400580423658356

Epoch: 6| Step: 8
Training loss: 0.860158112651253
Validation loss: 2.3478490314095186

Epoch: 6| Step: 9
Training loss: 0.8056187102528772
Validation loss: 2.3844493180406015

Epoch: 6| Step: 10
Training loss: 0.9796327469171279
Validation loss: 2.36707446562418

Epoch: 6| Step: 11
Training loss: 0.8466337162900028
Validation loss: 2.407285400688607

Epoch: 6| Step: 12
Training loss: 0.9525600697756897
Validation loss: 2.346093155709268

Epoch: 6| Step: 13
Training loss: 0.7076675333954218
Validation loss: 2.3300382157230755

Epoch: 530| Step: 0
Training loss: 1.0122252856907394
Validation loss: 2.334296852325099

Epoch: 6| Step: 1
Training loss: 0.999428108717495
Validation loss: 2.320062757508876

Epoch: 6| Step: 2
Training loss: 0.8703938225328841
Validation loss: 2.300227464553805

Epoch: 6| Step: 3
Training loss: 0.7276374494349018
Validation loss: 2.297998892960643

Epoch: 6| Step: 4
Training loss: 0.5632950409405977
Validation loss: 2.3608070547123385

Epoch: 6| Step: 5
Training loss: 0.7134053919246993
Validation loss: 2.3266461334582402

Epoch: 6| Step: 6
Training loss: 0.6794622420696835
Validation loss: 2.332523753936359

Epoch: 6| Step: 7
Training loss: 1.8088719460927714
Validation loss: 2.2724077983789948

Epoch: 6| Step: 8
Training loss: 0.6455671136022568
Validation loss: 2.276659948673329

Epoch: 6| Step: 9
Training loss: 0.6539443703390514
Validation loss: 2.2912698762058183

Epoch: 6| Step: 10
Training loss: 0.9120571276712303
Validation loss: 2.3286817509444306

Epoch: 6| Step: 11
Training loss: 0.7139989728653089
Validation loss: 2.394215961232355

Epoch: 6| Step: 12
Training loss: 0.8149400165927712
Validation loss: 2.3061158762484517

Epoch: 6| Step: 13
Training loss: 0.5938404415917505
Validation loss: 2.434870465585013

Epoch: 531| Step: 0
Training loss: 1.0234826929728422
Validation loss: 2.3952572376494006

Epoch: 6| Step: 1
Training loss: 0.9181152226892816
Validation loss: 2.2737293964481604

Epoch: 6| Step: 2
Training loss: 1.6556710724920167
Validation loss: 2.3446145566653267

Epoch: 6| Step: 3
Training loss: 0.778450948935173
Validation loss: 2.3370708227208223

Epoch: 6| Step: 4
Training loss: 1.0539486593051441
Validation loss: 2.292849838433443

Epoch: 6| Step: 5
Training loss: 0.9123653077304403
Validation loss: 2.3252979707309938

Epoch: 6| Step: 6
Training loss: 0.6311084503630209
Validation loss: 2.351955640555764

Epoch: 6| Step: 7
Training loss: 0.8337391262689379
Validation loss: 2.2992049908404795

Epoch: 6| Step: 8
Training loss: 0.9140576093493964
Validation loss: 2.2820909438861725

Epoch: 6| Step: 9
Training loss: 0.6783671654255327
Validation loss: 2.383240933552205

Epoch: 6| Step: 10
Training loss: 0.9830051154530356
Validation loss: 2.3699302902343655

Epoch: 6| Step: 11
Training loss: 0.6626628261780441
Validation loss: 2.3689606837838837

Epoch: 6| Step: 12
Training loss: 0.8474828305376046
Validation loss: 2.3452765313808226

Epoch: 6| Step: 13
Training loss: 0.7731749734478218
Validation loss: 2.377332876879487

Epoch: 532| Step: 0
Training loss: 0.5204742592594727
Validation loss: 2.4156181945055417

Epoch: 6| Step: 1
Training loss: 0.5777865269601692
Validation loss: 2.48385634928731

Epoch: 6| Step: 2
Training loss: 0.7141062366271483
Validation loss: 2.442160885975593

Epoch: 6| Step: 3
Training loss: 0.7012306337521327
Validation loss: 2.3649085905658174

Epoch: 6| Step: 4
Training loss: 0.8939816314807183
Validation loss: 2.4891574135045906

Epoch: 6| Step: 5
Training loss: 1.0042081742525888
Validation loss: 2.4774252256876443

Epoch: 6| Step: 6
Training loss: 1.8916150487951742
Validation loss: 2.4014243362685113

Epoch: 6| Step: 7
Training loss: 0.6654512133754154
Validation loss: 2.4215428315432925

Epoch: 6| Step: 8
Training loss: 1.0726294951078539
Validation loss: 2.389173403305724

Epoch: 6| Step: 9
Training loss: 0.8308391717446086
Validation loss: 2.3826377316375638

Epoch: 6| Step: 10
Training loss: 0.5875658424492562
Validation loss: 2.3242893350633476

Epoch: 6| Step: 11
Training loss: 0.7818484874959788
Validation loss: 2.340868805871016

Epoch: 6| Step: 12
Training loss: 0.837579842932083
Validation loss: 2.3100865637442554

Epoch: 6| Step: 13
Training loss: 1.194535495308916
Validation loss: 2.3042024491674513

Epoch: 533| Step: 0
Training loss: 0.9427105743774978
Validation loss: 2.4015634692367707

Epoch: 6| Step: 1
Training loss: 0.7676554633628997
Validation loss: 2.3145112091594706

Epoch: 6| Step: 2
Training loss: 0.7058572664635752
Validation loss: 2.3570200954459106

Epoch: 6| Step: 3
Training loss: 0.9796398656237275
Validation loss: 2.328642925808222

Epoch: 6| Step: 4
Training loss: 1.2036030797932282
Validation loss: 2.29277133848277

Epoch: 6| Step: 5
Training loss: 0.9125206487749266
Validation loss: 2.3479169532557402

Epoch: 6| Step: 6
Training loss: 0.855204780995607
Validation loss: 2.461895864322405

Epoch: 6| Step: 7
Training loss: 0.7290593386179717
Validation loss: 2.356947752864122

Epoch: 6| Step: 8
Training loss: 1.6422332147538075
Validation loss: 2.388327380033833

Epoch: 6| Step: 9
Training loss: 0.7210437414284032
Validation loss: 2.4258121018689196

Epoch: 6| Step: 10
Training loss: 0.7509967617696545
Validation loss: 2.419459321319319

Epoch: 6| Step: 11
Training loss: 0.8886092279171848
Validation loss: 2.4207045580608737

Epoch: 6| Step: 12
Training loss: 0.9073787762723214
Validation loss: 2.395248665612015

Epoch: 6| Step: 13
Training loss: 0.5439427647967574
Validation loss: 2.3362629213424997

Epoch: 534| Step: 0
Training loss: 0.9458954645047519
Validation loss: 2.3966585080275498

Epoch: 6| Step: 1
Training loss: 0.8912333368399575
Validation loss: 2.367740511951777

Epoch: 6| Step: 2
Training loss: 1.6647728491820677
Validation loss: 2.274588935475364

Epoch: 6| Step: 3
Training loss: 0.5309829040476437
Validation loss: 2.3057999212268587

Epoch: 6| Step: 4
Training loss: 0.7597999859176517
Validation loss: 2.332051138750889

Epoch: 6| Step: 5
Training loss: 1.0803041411350396
Validation loss: 2.388559583106395

Epoch: 6| Step: 6
Training loss: 0.9504547235500251
Validation loss: 2.3830003938337962

Epoch: 6| Step: 7
Training loss: 0.9296305021877452
Validation loss: 2.3515719998620592

Epoch: 6| Step: 8
Training loss: 0.5652698561071416
Validation loss: 2.320497825482974

Epoch: 6| Step: 9
Training loss: 0.7950843438805547
Validation loss: 2.3158879054551536

Epoch: 6| Step: 10
Training loss: 1.0317286912045427
Validation loss: 2.3206110505643536

Epoch: 6| Step: 11
Training loss: 0.7545760346861343
Validation loss: 2.3373479987952024

Epoch: 6| Step: 12
Training loss: 0.5903356913286687
Validation loss: 2.3200557993913695

Epoch: 6| Step: 13
Training loss: 0.9503143016493283
Validation loss: 2.377916756221429

Epoch: 535| Step: 0
Training loss: 1.0758738581094125
Validation loss: 2.4330833077635927

Epoch: 6| Step: 1
Training loss: 0.6372430199292834
Validation loss: 2.442175096301586

Epoch: 6| Step: 2
Training loss: 0.9744862572340489
Validation loss: 2.4630677747925507

Epoch: 6| Step: 3
Training loss: 0.9048881822077214
Validation loss: 2.419131786564974

Epoch: 6| Step: 4
Training loss: 0.8803574512882405
Validation loss: 2.4746327755582724

Epoch: 6| Step: 5
Training loss: 1.2867138360490755
Validation loss: 2.4603752466655515

Epoch: 6| Step: 6
Training loss: 0.5990814469454969
Validation loss: 2.3196572009965446

Epoch: 6| Step: 7
Training loss: 0.8579938019481951
Validation loss: 2.343682520178685

Epoch: 6| Step: 8
Training loss: 0.7452064550680226
Validation loss: 2.3616508900385385

Epoch: 6| Step: 9
Training loss: 1.6531799941839866
Validation loss: 2.362599985793842

Epoch: 6| Step: 10
Training loss: 0.8160997755488099
Validation loss: 2.3518838583487183

Epoch: 6| Step: 11
Training loss: 0.7061086082710104
Validation loss: 2.394131532666857

Epoch: 6| Step: 12
Training loss: 0.8510490759562425
Validation loss: 2.2753658919522

Epoch: 6| Step: 13
Training loss: 1.0547053017703374
Validation loss: 2.2879464800228915

Epoch: 536| Step: 0
Training loss: 0.8212388394089504
Validation loss: 2.306439136222116

Epoch: 6| Step: 1
Training loss: 0.7987902196271083
Validation loss: 2.356822654812945

Epoch: 6| Step: 2
Training loss: 0.486509511435155
Validation loss: 2.342294789507758

Epoch: 6| Step: 3
Training loss: 0.6315449629835168
Validation loss: 2.3641456644193384

Epoch: 6| Step: 4
Training loss: 0.6848984610696915
Validation loss: 2.339807571486701

Epoch: 6| Step: 5
Training loss: 0.6992461556119941
Validation loss: 2.338075323604323

Epoch: 6| Step: 6
Training loss: 0.748928815094626
Validation loss: 2.3119437771838856

Epoch: 6| Step: 7
Training loss: 0.739397768909905
Validation loss: 2.3638191692341226

Epoch: 6| Step: 8
Training loss: 1.1407016049096632
Validation loss: 2.3385961634817902

Epoch: 6| Step: 9
Training loss: 1.7825984201104776
Validation loss: 2.333087687006561

Epoch: 6| Step: 10
Training loss: 1.0447413778832428
Validation loss: 2.4396543634664933

Epoch: 6| Step: 11
Training loss: 1.2567406109136072
Validation loss: 2.402950873577198

Epoch: 6| Step: 12
Training loss: 0.6946280035503501
Validation loss: 2.382478468607133

Epoch: 6| Step: 13
Training loss: 0.806620562952791
Validation loss: 2.315443627089105

Epoch: 537| Step: 0
Training loss: 0.7188756667034392
Validation loss: 2.278818936337246

Epoch: 6| Step: 1
Training loss: 0.7876696237413602
Validation loss: 2.344908010241084

Epoch: 6| Step: 2
Training loss: 0.7955506858071344
Validation loss: 2.346442887145751

Epoch: 6| Step: 3
Training loss: 0.6875563945181898
Validation loss: 2.3322127214194297

Epoch: 6| Step: 4
Training loss: 0.8635378149949069
Validation loss: 2.314867080852701

Epoch: 6| Step: 5
Training loss: 0.724848910734994
Validation loss: 2.3804315116961954

Epoch: 6| Step: 6
Training loss: 1.0881871584645855
Validation loss: 2.328446375354281

Epoch: 6| Step: 7
Training loss: 0.592224143109935
Validation loss: 2.2965180247500276

Epoch: 6| Step: 8
Training loss: 0.7224828151124302
Validation loss: 2.398398307075763

Epoch: 6| Step: 9
Training loss: 0.9593462911777396
Validation loss: 2.3035937667841235

Epoch: 6| Step: 10
Training loss: 0.7794053998829096
Validation loss: 2.3180776101175025

Epoch: 6| Step: 11
Training loss: 0.8233843733788387
Validation loss: 2.374576372146483

Epoch: 6| Step: 12
Training loss: 1.688274064726149
Validation loss: 2.358153879277836

Epoch: 6| Step: 13
Training loss: 0.6562688007386432
Validation loss: 2.3446513137653184

Epoch: 538| Step: 0
Training loss: 0.744297321472002
Validation loss: 2.337437768168839

Epoch: 6| Step: 1
Training loss: 0.8850284211395829
Validation loss: 2.42285854918254

Epoch: 6| Step: 2
Training loss: 0.7231076866721533
Validation loss: 2.3398301902448075

Epoch: 6| Step: 3
Training loss: 0.9426015965574274
Validation loss: 2.3160386807144153

Epoch: 6| Step: 4
Training loss: 0.5939019410324043
Validation loss: 2.351290578794949

Epoch: 6| Step: 5
Training loss: 1.7606735343052886
Validation loss: 2.2751085270135483

Epoch: 6| Step: 6
Training loss: 0.9906877311314961
Validation loss: 2.399253571434133

Epoch: 6| Step: 7
Training loss: 0.7233033453384179
Validation loss: 2.403455415785015

Epoch: 6| Step: 8
Training loss: 0.6805795975631596
Validation loss: 2.4080293445304295

Epoch: 6| Step: 9
Training loss: 0.7173072598598228
Validation loss: 2.356383864490197

Epoch: 6| Step: 10
Training loss: 0.7943097506301534
Validation loss: 2.326982172388673

Epoch: 6| Step: 11
Training loss: 0.9486711594463377
Validation loss: 2.4092883730695203

Epoch: 6| Step: 12
Training loss: 0.7603225823990961
Validation loss: 2.313370599250021

Epoch: 6| Step: 13
Training loss: 0.9325333962072399
Validation loss: 2.3126558519041716

Epoch: 539| Step: 0
Training loss: 1.1973580204968133
Validation loss: 2.341363336212128

Epoch: 6| Step: 1
Training loss: 0.8487073297125892
Validation loss: 2.3788274613252933

Epoch: 6| Step: 2
Training loss: 0.6133941740805993
Validation loss: 2.3224524967670104

Epoch: 6| Step: 3
Training loss: 0.9162185867045561
Validation loss: 2.334127632282724

Epoch: 6| Step: 4
Training loss: 1.118906366086969
Validation loss: 2.3287850569032966

Epoch: 6| Step: 5
Training loss: 0.6959343176410544
Validation loss: 2.389846358603742

Epoch: 6| Step: 6
Training loss: 1.0061244578265855
Validation loss: 2.348897119845941

Epoch: 6| Step: 7
Training loss: 0.6429564918656667
Validation loss: 2.3247499085987564

Epoch: 6| Step: 8
Training loss: 0.8338877065768647
Validation loss: 2.346537737051312

Epoch: 6| Step: 9
Training loss: 0.6012387829009825
Validation loss: 2.3211750885352886

Epoch: 6| Step: 10
Training loss: 1.8312812359850674
Validation loss: 2.3677326036263593

Epoch: 6| Step: 11
Training loss: 0.6311081434187191
Validation loss: 2.3664572078061474

Epoch: 6| Step: 12
Training loss: 0.8867807912758473
Validation loss: 2.333304290400294

Epoch: 6| Step: 13
Training loss: 0.7420697570564162
Validation loss: 2.3631954271433178

Epoch: 540| Step: 0
Training loss: 0.8604676669494784
Validation loss: 2.335422322011726

Epoch: 6| Step: 1
Training loss: 0.5268948940625546
Validation loss: 2.314015799367433

Epoch: 6| Step: 2
Training loss: 0.719725154632061
Validation loss: 2.3253130727247306

Epoch: 6| Step: 3
Training loss: 1.7759393865792454
Validation loss: 2.3723734270871653

Epoch: 6| Step: 4
Training loss: 0.8829710488870856
Validation loss: 2.3374513275446995

Epoch: 6| Step: 5
Training loss: 1.0450757064956748
Validation loss: 2.3748620181542197

Epoch: 6| Step: 6
Training loss: 0.9142153359471482
Validation loss: 2.3866399152463784

Epoch: 6| Step: 7
Training loss: 0.7160323220661472
Validation loss: 2.3411237647719583

Epoch: 6| Step: 8
Training loss: 1.1398204944897303
Validation loss: 2.2806239463786113

Epoch: 6| Step: 9
Training loss: 0.4734854872150159
Validation loss: 2.3026242923274323

Epoch: 6| Step: 10
Training loss: 0.8718150278883819
Validation loss: 2.3257356241853517

Epoch: 6| Step: 11
Training loss: 1.0353803284151164
Validation loss: 2.267087303391077

Epoch: 6| Step: 12
Training loss: 0.9107581182825369
Validation loss: 2.2966743310704936

Epoch: 6| Step: 13
Training loss: 0.8395383767585702
Validation loss: 2.345973037289721

Epoch: 541| Step: 0
Training loss: 0.6269577834291984
Validation loss: 2.3004971237599157

Epoch: 6| Step: 1
Training loss: 0.7503385177225884
Validation loss: 2.3772586570162324

Epoch: 6| Step: 2
Training loss: 0.7870856345408779
Validation loss: 2.2494410215853304

Epoch: 6| Step: 3
Training loss: 0.7164851038143671
Validation loss: 2.343860073991344

Epoch: 6| Step: 4
Training loss: 0.700806822889626
Validation loss: 2.364239463361023

Epoch: 6| Step: 5
Training loss: 0.7164325671837742
Validation loss: 2.387312072709247

Epoch: 6| Step: 6
Training loss: 1.7663655036367032
Validation loss: 2.316941243278719

Epoch: 6| Step: 7
Training loss: 0.6161594762337003
Validation loss: 2.303760825167515

Epoch: 6| Step: 8
Training loss: 0.6492968001656506
Validation loss: 2.2852138492745837

Epoch: 6| Step: 9
Training loss: 1.1995533032295056
Validation loss: 2.4036837881137982

Epoch: 6| Step: 10
Training loss: 0.5548751943321085
Validation loss: 2.2965351076757043

Epoch: 6| Step: 11
Training loss: 0.8091751441026955
Validation loss: 2.3591515480695584

Epoch: 6| Step: 12
Training loss: 0.6467829127347701
Validation loss: 2.3496160110138384

Epoch: 6| Step: 13
Training loss: 0.8000243540871542
Validation loss: 2.2993904783896393

Epoch: 542| Step: 0
Training loss: 0.822851918888445
Validation loss: 2.347800015042669

Epoch: 6| Step: 1
Training loss: 0.4756072585948818
Validation loss: 2.314399455199228

Epoch: 6| Step: 2
Training loss: 0.8941928273332457
Validation loss: 2.2619808019068337

Epoch: 6| Step: 3
Training loss: 0.5922546378856232
Validation loss: 2.335575815596636

Epoch: 6| Step: 4
Training loss: 0.8640248130043388
Validation loss: 2.402457169520662

Epoch: 6| Step: 5
Training loss: 1.0369351055620466
Validation loss: 2.2468492535811184

Epoch: 6| Step: 6
Training loss: 0.7961186578240145
Validation loss: 2.2966756806047206

Epoch: 6| Step: 7
Training loss: 0.8700139490741267
Validation loss: 2.386701473668125

Epoch: 6| Step: 8
Training loss: 0.6023834868508269
Validation loss: 2.3515588337014526

Epoch: 6| Step: 9
Training loss: 0.7596547651436838
Validation loss: 2.307934061739425

Epoch: 6| Step: 10
Training loss: 0.7592757737122031
Validation loss: 2.3508374003121477

Epoch: 6| Step: 11
Training loss: 0.9434092885588607
Validation loss: 2.361299736536076

Epoch: 6| Step: 12
Training loss: 0.8276217749042644
Validation loss: 2.3335902732537233

Epoch: 6| Step: 13
Training loss: 2.263192600861931
Validation loss: 2.2974927393949303

Epoch: 543| Step: 0
Training loss: 1.0647216458187327
Validation loss: 2.3828342780360825

Epoch: 6| Step: 1
Training loss: 0.8484143852892889
Validation loss: 2.433204245869358

Epoch: 6| Step: 2
Training loss: 1.8201996600495391
Validation loss: 2.33299078126203

Epoch: 6| Step: 3
Training loss: 0.5583199850545963
Validation loss: 2.3750848274647463

Epoch: 6| Step: 4
Training loss: 0.6993081232844764
Validation loss: 2.358379180754173

Epoch: 6| Step: 5
Training loss: 0.5931641298255719
Validation loss: 2.360202074161207

Epoch: 6| Step: 6
Training loss: 0.926545805241935
Validation loss: 2.393086106445237

Epoch: 6| Step: 7
Training loss: 0.8002626554137343
Validation loss: 2.4064702973391925

Epoch: 6| Step: 8
Training loss: 0.6957737110962243
Validation loss: 2.3193785554676

Epoch: 6| Step: 9
Training loss: 0.8323510500109955
Validation loss: 2.333063176625441

Epoch: 6| Step: 10
Training loss: 0.683769116387245
Validation loss: 2.3367051726701566

Epoch: 6| Step: 11
Training loss: 0.7453757621099762
Validation loss: 2.3142213764143214

Epoch: 6| Step: 12
Training loss: 0.9926867993405223
Validation loss: 2.3811107996274057

Epoch: 6| Step: 13
Training loss: 0.4827946909610604
Validation loss: 2.331069864374996

Epoch: 544| Step: 0
Training loss: 1.6842666308020897
Validation loss: 2.3351973959623162

Epoch: 6| Step: 1
Training loss: 0.8567742615295898
Validation loss: 2.408673860186806

Epoch: 6| Step: 2
Training loss: 0.7235281967753093
Validation loss: 2.3562186243766603

Epoch: 6| Step: 3
Training loss: 1.0228464297999322
Validation loss: 2.3858055388509554

Epoch: 6| Step: 4
Training loss: 0.6663836583805967
Validation loss: 2.4100303109755075

Epoch: 6| Step: 5
Training loss: 0.8529956901280417
Validation loss: 2.3092020003655223

Epoch: 6| Step: 6
Training loss: 1.1756088789504313
Validation loss: 2.429932452335359

Epoch: 6| Step: 7
Training loss: 0.5076129814816189
Validation loss: 2.3654198853784894

Epoch: 6| Step: 8
Training loss: 0.8991068129877792
Validation loss: 2.379935400379027

Epoch: 6| Step: 9
Training loss: 0.7871532569939511
Validation loss: 2.3775309271609353

Epoch: 6| Step: 10
Training loss: 0.7329121487340713
Validation loss: 2.280966904814044

Epoch: 6| Step: 11
Training loss: 0.7183820777943987
Validation loss: 2.387374266689807

Epoch: 6| Step: 12
Training loss: 0.7655632227672261
Validation loss: 2.371621731651883

Epoch: 6| Step: 13
Training loss: 0.732827768390421
Validation loss: 2.381168954030032

Epoch: 545| Step: 0
Training loss: 0.6633016603382643
Validation loss: 2.380281166988456

Epoch: 6| Step: 1
Training loss: 0.8245530377130391
Validation loss: 2.3077808242068025

Epoch: 6| Step: 2
Training loss: 0.8062702649549044
Validation loss: 2.3338026096370146

Epoch: 6| Step: 3
Training loss: 0.8436746916894798
Validation loss: 2.3571333634519567

Epoch: 6| Step: 4
Training loss: 1.0189652315035094
Validation loss: 2.2766351376409353

Epoch: 6| Step: 5
Training loss: 0.8085638215796603
Validation loss: 2.370190493128451

Epoch: 6| Step: 6
Training loss: 0.6525988964975177
Validation loss: 2.374427028985002

Epoch: 6| Step: 7
Training loss: 0.8661619428435243
Validation loss: 2.317790015729538

Epoch: 6| Step: 8
Training loss: 0.7862085151947774
Validation loss: 2.363100104295281

Epoch: 6| Step: 9
Training loss: 0.7139138181723157
Validation loss: 2.3042686124832636

Epoch: 6| Step: 10
Training loss: 0.682180371319321
Validation loss: 2.391534041989807

Epoch: 6| Step: 11
Training loss: 1.6999616730801335
Validation loss: 2.361855764989512

Epoch: 6| Step: 12
Training loss: 0.8801671118178636
Validation loss: 2.4210619633184725

Epoch: 6| Step: 13
Training loss: 1.1214294994166443
Validation loss: 2.345813224279497

Epoch: 546| Step: 0
Training loss: 0.6783362362851848
Validation loss: 2.325743843965037

Epoch: 6| Step: 1
Training loss: 0.6747581587344474
Validation loss: 2.3796406058045414

Epoch: 6| Step: 2
Training loss: 0.9281339086239908
Validation loss: 2.325736812456224

Epoch: 6| Step: 3
Training loss: 0.9080664419051483
Validation loss: 2.310086850617082

Epoch: 6| Step: 4
Training loss: 0.7396675294759611
Validation loss: 2.345613129301042

Epoch: 6| Step: 5
Training loss: 1.594463936460992
Validation loss: 2.3504230427436603

Epoch: 6| Step: 6
Training loss: 0.9184921395843355
Validation loss: 2.3217150554895896

Epoch: 6| Step: 7
Training loss: 0.8507687430255015
Validation loss: 2.3378724647759896

Epoch: 6| Step: 8
Training loss: 0.6363422708361622
Validation loss: 2.3012527441500468

Epoch: 6| Step: 9
Training loss: 0.7228108833449938
Validation loss: 2.2991484144469836

Epoch: 6| Step: 10
Training loss: 0.914119490452598
Validation loss: 2.34462073446136

Epoch: 6| Step: 11
Training loss: 0.9755213871737224
Validation loss: 2.3890788755238805

Epoch: 6| Step: 12
Training loss: 0.8007538581443163
Validation loss: 2.40530440106679

Epoch: 6| Step: 13
Training loss: 0.7529243835183237
Validation loss: 2.367437891938508

Epoch: 547| Step: 0
Training loss: 0.6774814144625777
Validation loss: 2.3064748227876124

Epoch: 6| Step: 1
Training loss: 1.8555163568111375
Validation loss: 2.4443889405672734

Epoch: 6| Step: 2
Training loss: 0.8645569019796856
Validation loss: 2.475072267756917

Epoch: 6| Step: 3
Training loss: 1.0235368520254773
Validation loss: 2.4032444257056915

Epoch: 6| Step: 4
Training loss: 0.7770688131439988
Validation loss: 2.423209973531202

Epoch: 6| Step: 5
Training loss: 0.6636997354013485
Validation loss: 2.4150715525836373

Epoch: 6| Step: 6
Training loss: 0.860560691608294
Validation loss: 2.3966324463755293

Epoch: 6| Step: 7
Training loss: 0.6609000355448507
Validation loss: 2.351183707242279

Epoch: 6| Step: 8
Training loss: 0.7567087374207327
Validation loss: 2.3958416981883213

Epoch: 6| Step: 9
Training loss: 0.9106697304028554
Validation loss: 2.3588564842935704

Epoch: 6| Step: 10
Training loss: 0.8315959741047249
Validation loss: 2.4032808194509023

Epoch: 6| Step: 11
Training loss: 0.5984218904137713
Validation loss: 2.3577053282551796

Epoch: 6| Step: 12
Training loss: 0.8549222201946503
Validation loss: 2.3797193268897616

Epoch: 6| Step: 13
Training loss: 1.3688671584480805
Validation loss: 2.368345463863491

Epoch: 548| Step: 0
Training loss: 0.8588854001952997
Validation loss: 2.36819095651697

Epoch: 6| Step: 1
Training loss: 0.7489068488905176
Validation loss: 2.304161935666532

Epoch: 6| Step: 2
Training loss: 0.7381922754028774
Validation loss: 2.4004833435453605

Epoch: 6| Step: 3
Training loss: 0.762359037032962
Validation loss: 2.333110924436325

Epoch: 6| Step: 4
Training loss: 0.6965624257939514
Validation loss: 2.379017926939967

Epoch: 6| Step: 5
Training loss: 0.8711203669428799
Validation loss: 2.2776238540734983

Epoch: 6| Step: 6
Training loss: 1.7385974382155864
Validation loss: 2.3291070439764403

Epoch: 6| Step: 7
Training loss: 0.6511264796643902
Validation loss: 2.390332826575925

Epoch: 6| Step: 8
Training loss: 1.1791696990999696
Validation loss: 2.336137034976104

Epoch: 6| Step: 9
Training loss: 0.7874602867890916
Validation loss: 2.3728071958599113

Epoch: 6| Step: 10
Training loss: 0.771593535221282
Validation loss: 2.321659221434791

Epoch: 6| Step: 11
Training loss: 0.6486633550890023
Validation loss: 2.3189119070240904

Epoch: 6| Step: 12
Training loss: 0.9214047024361156
Validation loss: 2.4118633597667474

Epoch: 6| Step: 13
Training loss: 0.6789151111020116
Validation loss: 2.369680293099688

Epoch: 549| Step: 0
Training loss: 0.6895714244985909
Validation loss: 2.335086141262481

Epoch: 6| Step: 1
Training loss: 0.6841663251481809
Validation loss: 2.415402002655316

Epoch: 6| Step: 2
Training loss: 1.1565368915022294
Validation loss: 2.3487236262757962

Epoch: 6| Step: 3
Training loss: 1.0113330238314988
Validation loss: 2.3685814501649456

Epoch: 6| Step: 4
Training loss: 0.7817553602327032
Validation loss: 2.357498785513241

Epoch: 6| Step: 5
Training loss: 0.865292342678934
Validation loss: 2.3436078034611283

Epoch: 6| Step: 6
Training loss: 0.7410210126118927
Validation loss: 2.338563950524253

Epoch: 6| Step: 7
Training loss: 0.724416907729925
Validation loss: 2.323283897392772

Epoch: 6| Step: 8
Training loss: 1.6330636301345882
Validation loss: 2.303467713249046

Epoch: 6| Step: 9
Training loss: 0.7095785882342802
Validation loss: 2.419447521140119

Epoch: 6| Step: 10
Training loss: 0.7461476331496767
Validation loss: 2.273231515340347

Epoch: 6| Step: 11
Training loss: 0.8773973525021055
Validation loss: 2.2784919467886238

Epoch: 6| Step: 12
Training loss: 0.6110259701802084
Validation loss: 2.265111090536713

Epoch: 6| Step: 13
Training loss: 0.9415605663908948
Validation loss: 2.3413202353420335

Epoch: 550| Step: 0
Training loss: 0.720681787190478
Validation loss: 2.2613153296391553

Epoch: 6| Step: 1
Training loss: 0.5635642738767038
Validation loss: 2.383403504264639

Epoch: 6| Step: 2
Training loss: 0.9617005706729883
Validation loss: 2.3918119375775295

Epoch: 6| Step: 3
Training loss: 1.12635218631974
Validation loss: 2.373412479804856

Epoch: 6| Step: 4
Training loss: 0.6645498394871863
Validation loss: 2.373483930628036

Epoch: 6| Step: 5
Training loss: 0.8586539277776515
Validation loss: 2.3253965547279396

Epoch: 6| Step: 6
Training loss: 0.47397385735991
Validation loss: 2.3350067451894154

Epoch: 6| Step: 7
Training loss: 0.7370826235204039
Validation loss: 2.396920789235344

Epoch: 6| Step: 8
Training loss: 0.8111472973815029
Validation loss: 2.3424912756794836

Epoch: 6| Step: 9
Training loss: 0.6015826630619217
Validation loss: 2.37119715103742

Epoch: 6| Step: 10
Training loss: 0.9110692565273847
Validation loss: 2.2989664975229553

Epoch: 6| Step: 11
Training loss: 0.8447030301206462
Validation loss: 2.3924149545291615

Epoch: 6| Step: 12
Training loss: 1.7311497160032518
Validation loss: 2.317590434850455

Epoch: 6| Step: 13
Training loss: 0.688977236673455
Validation loss: 2.335064515702568

Epoch: 551| Step: 0
Training loss: 0.5909006868028224
Validation loss: 2.32778899058546

Epoch: 6| Step: 1
Training loss: 0.7319091222742616
Validation loss: 2.361990790857413

Epoch: 6| Step: 2
Training loss: 0.8293737676822617
Validation loss: 2.4130728658064795

Epoch: 6| Step: 3
Training loss: 0.9046514816888537
Validation loss: 2.2950213655939318

Epoch: 6| Step: 4
Training loss: 0.9281990895096486
Validation loss: 2.3532498928886527

Epoch: 6| Step: 5
Training loss: 1.7601652548974882
Validation loss: 2.2880435579547997

Epoch: 6| Step: 6
Training loss: 0.7500942488897027
Validation loss: 2.34350844584367

Epoch: 6| Step: 7
Training loss: 0.9008277609761888
Validation loss: 2.330006887347482

Epoch: 6| Step: 8
Training loss: 0.5168962701666976
Validation loss: 2.2613002769610158

Epoch: 6| Step: 9
Training loss: 0.6938501904284958
Validation loss: 2.318486004935838

Epoch: 6| Step: 10
Training loss: 0.7651963493709754
Validation loss: 2.3857773191459337

Epoch: 6| Step: 11
Training loss: 0.7185533918082357
Validation loss: 2.3980352725760152

Epoch: 6| Step: 12
Training loss: 0.7492897326244654
Validation loss: 2.30081180693101

Epoch: 6| Step: 13
Training loss: 0.45155293609628494
Validation loss: 2.3765654761162462

Epoch: 552| Step: 0
Training loss: 0.6968681420643104
Validation loss: 2.287236912351099

Epoch: 6| Step: 1
Training loss: 0.706947954023835
Validation loss: 2.365383467270945

Epoch: 6| Step: 2
Training loss: 1.708058970990029
Validation loss: 2.346981521989154

Epoch: 6| Step: 3
Training loss: 0.7090162790229327
Validation loss: 2.3937638863616697

Epoch: 6| Step: 4
Training loss: 0.643035215926279
Validation loss: 2.368462500940836

Epoch: 6| Step: 5
Training loss: 1.1175242630033515
Validation loss: 2.393027785812114

Epoch: 6| Step: 6
Training loss: 0.717211486481777
Validation loss: 2.401898015947794

Epoch: 6| Step: 7
Training loss: 0.7265376425151804
Validation loss: 2.317383533784988

Epoch: 6| Step: 8
Training loss: 0.9085929444195496
Validation loss: 2.338826438399316

Epoch: 6| Step: 9
Training loss: 0.9313004550450615
Validation loss: 2.3842114104239287

Epoch: 6| Step: 10
Training loss: 1.0320020880899818
Validation loss: 2.3994968067536133

Epoch: 6| Step: 11
Training loss: 0.6126959127338693
Validation loss: 2.3140670823405562

Epoch: 6| Step: 12
Training loss: 0.8088296371117157
Validation loss: 2.3218783892643216

Epoch: 6| Step: 13
Training loss: 0.5641527795796347
Validation loss: 2.386550995439005

Epoch: 553| Step: 0
Training loss: 0.6407921735776139
Validation loss: 2.3484729981862467

Epoch: 6| Step: 1
Training loss: 0.7796289028249243
Validation loss: 2.383565765424269

Epoch: 6| Step: 2
Training loss: 1.7071896267884141
Validation loss: 2.373284513187541

Epoch: 6| Step: 3
Training loss: 0.6409209660964666
Validation loss: 2.356707588416393

Epoch: 6| Step: 4
Training loss: 0.6336157610323717
Validation loss: 2.3898780364092094

Epoch: 6| Step: 5
Training loss: 0.6079790803987039
Validation loss: 2.3218460790717477

Epoch: 6| Step: 6
Training loss: 0.7609012226958721
Validation loss: 2.3793675623847093

Epoch: 6| Step: 7
Training loss: 0.8316016005735054
Validation loss: 2.301648164294461

Epoch: 6| Step: 8
Training loss: 0.8021726847500217
Validation loss: 2.3633303916579376

Epoch: 6| Step: 9
Training loss: 1.0826613041290027
Validation loss: 2.453814233419737

Epoch: 6| Step: 10
Training loss: 0.6625506975461181
Validation loss: 2.327197259274276

Epoch: 6| Step: 11
Training loss: 0.8605195832913954
Validation loss: 2.4217267846183312

Epoch: 6| Step: 12
Training loss: 0.7412629643250553
Validation loss: 2.3120237578999334

Epoch: 6| Step: 13
Training loss: 0.6479972815780369
Validation loss: 2.3707187786750716

Epoch: 554| Step: 0
Training loss: 0.7019729076521011
Validation loss: 2.418405734191626

Epoch: 6| Step: 1
Training loss: 0.8650654440582297
Validation loss: 2.4049668605833014

Epoch: 6| Step: 2
Training loss: 0.724375314259893
Validation loss: 2.3399007974047277

Epoch: 6| Step: 3
Training loss: 0.854526854765514
Validation loss: 2.310434601403445

Epoch: 6| Step: 4
Training loss: 0.5602514837756887
Validation loss: 2.257187171506884

Epoch: 6| Step: 5
Training loss: 0.7505020209837355
Validation loss: 2.364924701419952

Epoch: 6| Step: 6
Training loss: 0.578812499698482
Validation loss: 2.334574124118729

Epoch: 6| Step: 7
Training loss: 0.8293404566363343
Validation loss: 2.3596436015502698

Epoch: 6| Step: 8
Training loss: 1.7315894775271827
Validation loss: 2.454882082699425

Epoch: 6| Step: 9
Training loss: 0.5255461395290282
Validation loss: 2.4025339999175923

Epoch: 6| Step: 10
Training loss: 0.8693961121596168
Validation loss: 2.381256512138926

Epoch: 6| Step: 11
Training loss: 0.8237685289165874
Validation loss: 2.272941573323023

Epoch: 6| Step: 12
Training loss: 0.8114333487219898
Validation loss: 2.3671706139580797

Epoch: 6| Step: 13
Training loss: 0.42611203774465156
Validation loss: 2.313180179887545

Epoch: 555| Step: 0
Training loss: 0.6941560278768385
Validation loss: 2.378707434248539

Epoch: 6| Step: 1
Training loss: 0.782032003030786
Validation loss: 2.2937760840610983

Epoch: 6| Step: 2
Training loss: 0.7884035663960507
Validation loss: 2.3336181276380703

Epoch: 6| Step: 3
Training loss: 0.7451638623338916
Validation loss: 2.35025678469665

Epoch: 6| Step: 4
Training loss: 0.6480049161106406
Validation loss: 2.4012442925434954

Epoch: 6| Step: 5
Training loss: 1.0474197336913225
Validation loss: 2.365716197081666

Epoch: 6| Step: 6
Training loss: 0.921681399949074
Validation loss: 2.3725441306996093

Epoch: 6| Step: 7
Training loss: 0.5919948284577324
Validation loss: 2.3432608145192106

Epoch: 6| Step: 8
Training loss: 1.051038859388511
Validation loss: 2.2776354863175343

Epoch: 6| Step: 9
Training loss: 0.7457754045149868
Validation loss: 2.347823166094897

Epoch: 6| Step: 10
Training loss: 1.7174490426623568
Validation loss: 2.4014576734896225

Epoch: 6| Step: 11
Training loss: 0.6410583797983315
Validation loss: 2.2832373630872373

Epoch: 6| Step: 12
Training loss: 0.6617667738096801
Validation loss: 2.3827504559284414

Epoch: 6| Step: 13
Training loss: 0.5124728928352059
Validation loss: 2.2934983382906893

Epoch: 556| Step: 0
Training loss: 0.821981675509932
Validation loss: 2.3437274847008807

Epoch: 6| Step: 1
Training loss: 1.6299756242532555
Validation loss: 2.383521527703055

Epoch: 6| Step: 2
Training loss: 0.7315161228919307
Validation loss: 2.355854322101141

Epoch: 6| Step: 3
Training loss: 0.6983274607840124
Validation loss: 2.3409824846584755

Epoch: 6| Step: 4
Training loss: 0.7532385206338527
Validation loss: 2.3297270554968255

Epoch: 6| Step: 5
Training loss: 0.8026472726609102
Validation loss: 2.335553806548487

Epoch: 6| Step: 6
Training loss: 0.7910306575900874
Validation loss: 2.377851072390962

Epoch: 6| Step: 7
Training loss: 0.6973092201773268
Validation loss: 2.2530408566966695

Epoch: 6| Step: 8
Training loss: 1.066823242040447
Validation loss: 2.307654627780155

Epoch: 6| Step: 9
Training loss: 1.0593660922505865
Validation loss: 2.3303606935598618

Epoch: 6| Step: 10
Training loss: 0.7161746117560478
Validation loss: 2.298043452818973

Epoch: 6| Step: 11
Training loss: 0.6469802337778537
Validation loss: 2.311870757622761

Epoch: 6| Step: 12
Training loss: 0.5318303304398384
Validation loss: 2.3029347685782136

Epoch: 6| Step: 13
Training loss: 0.31570908776580325
Validation loss: 2.3606339428712317

Epoch: 557| Step: 0
Training loss: 0.7052047700289505
Validation loss: 2.391242126513977

Epoch: 6| Step: 1
Training loss: 0.8406846560613809
Validation loss: 2.367239617242018

Epoch: 6| Step: 2
Training loss: 1.5137529117672774
Validation loss: 2.379070983287888

Epoch: 6| Step: 3
Training loss: 0.862239398839146
Validation loss: 2.3926099675403276

Epoch: 6| Step: 4
Training loss: 0.5706631614484194
Validation loss: 2.3527115228516084

Epoch: 6| Step: 5
Training loss: 0.6890782317703416
Validation loss: 2.3614087080317874

Epoch: 6| Step: 6
Training loss: 0.7710950037860049
Validation loss: 2.3394146622247254

Epoch: 6| Step: 7
Training loss: 0.6487444645125475
Validation loss: 2.328818477337424

Epoch: 6| Step: 8
Training loss: 0.6380668130512699
Validation loss: 2.4196188959658005

Epoch: 6| Step: 9
Training loss: 0.9024544850229259
Validation loss: 2.403478278207041

Epoch: 6| Step: 10
Training loss: 0.9240784255594721
Validation loss: 2.3541109356357723

Epoch: 6| Step: 11
Training loss: 0.9448981204443454
Validation loss: 2.416607095056997

Epoch: 6| Step: 12
Training loss: 0.4614452216680223
Validation loss: 2.3784345211015823

Epoch: 6| Step: 13
Training loss: 0.7023186404414758
Validation loss: 2.3536807106888085

Epoch: 558| Step: 0
Training loss: 0.6678129761854374
Validation loss: 2.372389585583731

Epoch: 6| Step: 1
Training loss: 0.675429191834059
Validation loss: 2.3994209026716113

Epoch: 6| Step: 2
Training loss: 0.7686007533148896
Validation loss: 2.3604181986851422

Epoch: 6| Step: 3
Training loss: 1.1947320264161574
Validation loss: 2.4044243580744498

Epoch: 6| Step: 4
Training loss: 0.5500589599218059
Validation loss: 2.3517887975631346

Epoch: 6| Step: 5
Training loss: 0.7604233902586063
Validation loss: 2.3794041058482316

Epoch: 6| Step: 6
Training loss: 1.8007371611586964
Validation loss: 2.3587484263228955

Epoch: 6| Step: 7
Training loss: 0.7006390175280638
Validation loss: 2.3016297069733263

Epoch: 6| Step: 8
Training loss: 0.7535998655763535
Validation loss: 2.3166859142235436

Epoch: 6| Step: 9
Training loss: 0.8563074677388183
Validation loss: 2.3132373429169024

Epoch: 6| Step: 10
Training loss: 0.6788170162156413
Validation loss: 2.2936579911571067

Epoch: 6| Step: 11
Training loss: 0.7815273936858844
Validation loss: 2.3123191534409666

Epoch: 6| Step: 12
Training loss: 0.7429029529851232
Validation loss: 2.289661486314663

Epoch: 6| Step: 13
Training loss: 0.7638680286641807
Validation loss: 2.3098793956388466

Epoch: 559| Step: 0
Training loss: 0.72758608672485
Validation loss: 2.3689710542871194

Epoch: 6| Step: 1
Training loss: 0.6182790351000859
Validation loss: 2.2704547044477574

Epoch: 6| Step: 2
Training loss: 0.5479051696335029
Validation loss: 2.3359902030554593

Epoch: 6| Step: 3
Training loss: 0.7674142211171999
Validation loss: 2.3244726676388963

Epoch: 6| Step: 4
Training loss: 0.9582205097846785
Validation loss: 2.25051344661119

Epoch: 6| Step: 5
Training loss: 1.1242796392963923
Validation loss: 2.3801812345663427

Epoch: 6| Step: 6
Training loss: 0.6110304573930699
Validation loss: 2.3018548820826217

Epoch: 6| Step: 7
Training loss: 0.7102331927659653
Validation loss: 2.3052388194522218

Epoch: 6| Step: 8
Training loss: 0.7620641463255762
Validation loss: 2.3249893737790073

Epoch: 6| Step: 9
Training loss: 0.7361795695478719
Validation loss: 2.293452803702814

Epoch: 6| Step: 10
Training loss: 0.7675191065494442
Validation loss: 2.3433194022642025

Epoch: 6| Step: 11
Training loss: 1.6618469246239131
Validation loss: 2.3165704937015947

Epoch: 6| Step: 12
Training loss: 0.8433251194183244
Validation loss: 2.314667905560871

Epoch: 6| Step: 13
Training loss: 0.6864442956055435
Validation loss: 2.330477470042901

Epoch: 560| Step: 0
Training loss: 0.7752384834061513
Validation loss: 2.335050003766392

Epoch: 6| Step: 1
Training loss: 1.0501280388649061
Validation loss: 2.3224938300857794

Epoch: 6| Step: 2
Training loss: 0.7109982810395356
Validation loss: 2.3330838125682205

Epoch: 6| Step: 3
Training loss: 0.8699563645239281
Validation loss: 2.3275321695127698

Epoch: 6| Step: 4
Training loss: 1.6203855875097979
Validation loss: 2.2735407474980485

Epoch: 6| Step: 5
Training loss: 1.030857820787953
Validation loss: 2.3951628804007354

Epoch: 6| Step: 6
Training loss: 0.8503724978980841
Validation loss: 2.3144161962343706

Epoch: 6| Step: 7
Training loss: 0.7407205640729352
Validation loss: 2.267704929957819

Epoch: 6| Step: 8
Training loss: 0.7364139253931443
Validation loss: 2.352072666994584

Epoch: 6| Step: 9
Training loss: 0.4237863019005398
Validation loss: 2.260389628862254

Epoch: 6| Step: 10
Training loss: 0.6795717995922212
Validation loss: 2.289409855385908

Epoch: 6| Step: 11
Training loss: 0.8136678518854198
Validation loss: 2.3361828892872434

Epoch: 6| Step: 12
Training loss: 0.6135709042105186
Validation loss: 2.397045822400058

Epoch: 6| Step: 13
Training loss: 0.9406722440292917
Validation loss: 2.294821271888374

Epoch: 561| Step: 0
Training loss: 1.633580077600753
Validation loss: 2.3430319809445286

Epoch: 6| Step: 1
Training loss: 0.7150987264190544
Validation loss: 2.3583984983734605

Epoch: 6| Step: 2
Training loss: 0.8535767278033637
Validation loss: 2.4063167735885607

Epoch: 6| Step: 3
Training loss: 0.8271100644485023
Validation loss: 2.359173046830533

Epoch: 6| Step: 4
Training loss: 0.6969522792578839
Validation loss: 2.312620366585455

Epoch: 6| Step: 5
Training loss: 0.9794063207198425
Validation loss: 2.274701534608356

Epoch: 6| Step: 6
Training loss: 0.5892595846815205
Validation loss: 2.405589540036213

Epoch: 6| Step: 7
Training loss: 1.0915682148886192
Validation loss: 2.35630397565622

Epoch: 6| Step: 8
Training loss: 0.6860311596302624
Validation loss: 2.30780115856204

Epoch: 6| Step: 9
Training loss: 0.6624074619370488
Validation loss: 2.3159293898354587

Epoch: 6| Step: 10
Training loss: 0.68427896217709
Validation loss: 2.3741006341102766

Epoch: 6| Step: 11
Training loss: 0.5236027015642568
Validation loss: 2.3338936951024167

Epoch: 6| Step: 12
Training loss: 0.47383450018736506
Validation loss: 2.3598786003836847

Epoch: 6| Step: 13
Training loss: 1.0804141523864264
Validation loss: 2.312648455802561

Epoch: 562| Step: 0
Training loss: 0.7593430861686004
Validation loss: 2.259422129580012

Epoch: 6| Step: 1
Training loss: 0.8178094732500389
Validation loss: 2.2943885609782475

Epoch: 6| Step: 2
Training loss: 0.5186894415931569
Validation loss: 2.311506257946305

Epoch: 6| Step: 3
Training loss: 0.7771953652002704
Validation loss: 2.2560221329545658

Epoch: 6| Step: 4
Training loss: 0.7240393933991556
Validation loss: 2.3718346236038896

Epoch: 6| Step: 5
Training loss: 0.8049410078101267
Validation loss: 2.3848164723067806

Epoch: 6| Step: 6
Training loss: 0.7617646032372726
Validation loss: 2.2948517361414953

Epoch: 6| Step: 7
Training loss: 0.5483071783701764
Validation loss: 2.3057599591940843

Epoch: 6| Step: 8
Training loss: 0.5360855609798693
Validation loss: 2.3497505490975605

Epoch: 6| Step: 9
Training loss: 0.728884197199978
Validation loss: 2.3847350773947706

Epoch: 6| Step: 10
Training loss: 1.5839907720133235
Validation loss: 2.278212181817936

Epoch: 6| Step: 11
Training loss: 0.7437572543006825
Validation loss: 2.302319280489201

Epoch: 6| Step: 12
Training loss: 0.710518262726431
Validation loss: 2.349233058780818

Epoch: 6| Step: 13
Training loss: 1.1394125360027936
Validation loss: 2.2948511574696813

Epoch: 563| Step: 0
Training loss: 0.6915599846050784
Validation loss: 2.294210781642937

Epoch: 6| Step: 1
Training loss: 0.8590826057309876
Validation loss: 2.381524359511772

Epoch: 6| Step: 2
Training loss: 0.6990797021801628
Validation loss: 2.3738084037159854

Epoch: 6| Step: 3
Training loss: 1.6732326236120687
Validation loss: 2.353051581350901

Epoch: 6| Step: 4
Training loss: 0.8324183964757321
Validation loss: 2.3341716501579084

Epoch: 6| Step: 5
Training loss: 0.6336257794771049
Validation loss: 2.3247435985988854

Epoch: 6| Step: 6
Training loss: 0.7053058499558101
Validation loss: 2.2907291482185075

Epoch: 6| Step: 7
Training loss: 0.9345822388337441
Validation loss: 2.3768302544701996

Epoch: 6| Step: 8
Training loss: 0.6834008952988143
Validation loss: 2.3510553049245004

Epoch: 6| Step: 9
Training loss: 0.7001132251925565
Validation loss: 2.3572036116464927

Epoch: 6| Step: 10
Training loss: 0.797711737157162
Validation loss: 2.3323037667516076

Epoch: 6| Step: 11
Training loss: 0.8324147088517942
Validation loss: 2.3313079678099955

Epoch: 6| Step: 12
Training loss: 0.5023076924009364
Validation loss: 2.3623826696556436

Epoch: 6| Step: 13
Training loss: 1.0904205873968187
Validation loss: 2.3085922908325482

Epoch: 564| Step: 0
Training loss: 0.7270518879981293
Validation loss: 2.3218624103331633

Epoch: 6| Step: 1
Training loss: 0.7663744547525762
Validation loss: 2.302127494902549

Epoch: 6| Step: 2
Training loss: 0.73235465186298
Validation loss: 2.3599530648506852

Epoch: 6| Step: 3
Training loss: 0.8666183047066938
Validation loss: 2.3924392185065497

Epoch: 6| Step: 4
Training loss: 0.6566390519177204
Validation loss: 2.327064819494373

Epoch: 6| Step: 5
Training loss: 0.6047178965575284
Validation loss: 2.3119525898960807

Epoch: 6| Step: 6
Training loss: 1.0195410717019726
Validation loss: 2.3890715990484988

Epoch: 6| Step: 7
Training loss: 0.6137355895205578
Validation loss: 2.3803044189336973

Epoch: 6| Step: 8
Training loss: 0.6219120752602227
Validation loss: 2.4141101221169605

Epoch: 6| Step: 9
Training loss: 0.6796877411589798
Validation loss: 2.390309088198938

Epoch: 6| Step: 10
Training loss: 1.6979554840830589
Validation loss: 2.364122697606678

Epoch: 6| Step: 11
Training loss: 0.6103598388110745
Validation loss: 2.3098966228073436

Epoch: 6| Step: 12
Training loss: 0.7385100156586567
Validation loss: 2.3584284408598117

Epoch: 6| Step: 13
Training loss: 0.4338262295591391
Validation loss: 2.2914140295419645

Epoch: 565| Step: 0
Training loss: 0.914519204054348
Validation loss: 2.3018116784907003

Epoch: 6| Step: 1
Training loss: 0.4722612006877078
Validation loss: 2.3293108422783275

Epoch: 6| Step: 2
Training loss: 0.4822802470882767
Validation loss: 2.262457725153971

Epoch: 6| Step: 3
Training loss: 0.558443195888202
Validation loss: 2.359939100294201

Epoch: 6| Step: 4
Training loss: 0.5205139961376359
Validation loss: 2.279037392627782

Epoch: 6| Step: 5
Training loss: 0.8656079452432054
Validation loss: 2.3435571510522806

Epoch: 6| Step: 6
Training loss: 0.91332371517556
Validation loss: 2.3757251826212427

Epoch: 6| Step: 7
Training loss: 1.8358975669900819
Validation loss: 2.358926301343464

Epoch: 6| Step: 8
Training loss: 0.7560599994793089
Validation loss: 2.356935400421802

Epoch: 6| Step: 9
Training loss: 0.6878709009344052
Validation loss: 2.3937577668519725

Epoch: 6| Step: 10
Training loss: 0.6731482572796921
Validation loss: 2.3644628383402218

Epoch: 6| Step: 11
Training loss: 0.6225674497685058
Validation loss: 2.329728236229864

Epoch: 6| Step: 12
Training loss: 0.5334259238436815
Validation loss: 2.3150734028669206

Epoch: 6| Step: 13
Training loss: 0.7523224555276926
Validation loss: 2.328358854496501

Epoch: 566| Step: 0
Training loss: 0.7180243436357774
Validation loss: 2.3325374149667826

Epoch: 6| Step: 1
Training loss: 0.4958276410403868
Validation loss: 2.3769508708489138

Epoch: 6| Step: 2
Training loss: 0.810290339674806
Validation loss: 2.280393954822946

Epoch: 6| Step: 3
Training loss: 0.6750066430153505
Validation loss: 2.356935656575338

Epoch: 6| Step: 4
Training loss: 0.7783219207019536
Validation loss: 2.2965217404060163

Epoch: 6| Step: 5
Training loss: 0.8311368047753982
Validation loss: 2.361315933896738

Epoch: 6| Step: 6
Training loss: 0.679584232246308
Validation loss: 2.3383909828687304

Epoch: 6| Step: 7
Training loss: 0.9466891077956904
Validation loss: 2.3361366267490244

Epoch: 6| Step: 8
Training loss: 0.7550463579484472
Validation loss: 2.3601239086165964

Epoch: 6| Step: 9
Training loss: 1.5724083118969163
Validation loss: 2.3191870155040295

Epoch: 6| Step: 10
Training loss: 0.5176211357239606
Validation loss: 2.3100478683240278

Epoch: 6| Step: 11
Training loss: 0.7512635871813711
Validation loss: 2.3403982576111857

Epoch: 6| Step: 12
Training loss: 0.7427389003960474
Validation loss: 2.3009123263871403

Epoch: 6| Step: 13
Training loss: 0.8761807717200276
Validation loss: 2.3014591176083807

Epoch: 567| Step: 0
Training loss: 0.5217421105505309
Validation loss: 2.3800903069892416

Epoch: 6| Step: 1
Training loss: 0.7387827224713545
Validation loss: 2.360032207182517

Epoch: 6| Step: 2
Training loss: 0.7956386399579488
Validation loss: 2.314638719706157

Epoch: 6| Step: 3
Training loss: 1.6350427754957377
Validation loss: 2.2935437764057305

Epoch: 6| Step: 4
Training loss: 0.8281850972951487
Validation loss: 2.3206087582556343

Epoch: 6| Step: 5
Training loss: 1.2508367598806707
Validation loss: 2.4217811526594715

Epoch: 6| Step: 6
Training loss: 0.7136422153734393
Validation loss: 2.366412157877333

Epoch: 6| Step: 7
Training loss: 1.008286534686732
Validation loss: 2.356842690048122

Epoch: 6| Step: 8
Training loss: 0.6070726623548588
Validation loss: 2.361008143326202

Epoch: 6| Step: 9
Training loss: 0.646885681064162
Validation loss: 2.3259262578380784

Epoch: 6| Step: 10
Training loss: 0.8439726006074008
Validation loss: 2.269419467502892

Epoch: 6| Step: 11
Training loss: 0.6771508158775968
Validation loss: 2.3926850719545225

Epoch: 6| Step: 12
Training loss: 0.7207545647187164
Validation loss: 2.3024684172075993

Epoch: 6| Step: 13
Training loss: 0.9601071809998172
Validation loss: 2.283924708735816

Epoch: 568| Step: 0
Training loss: 0.679661191233827
Validation loss: 2.3209403185705244

Epoch: 6| Step: 1
Training loss: 0.6139369059632332
Validation loss: 2.425950623964096

Epoch: 6| Step: 2
Training loss: 1.6216801697239738
Validation loss: 2.407854123757365

Epoch: 6| Step: 3
Training loss: 0.6141987152053875
Validation loss: 2.2678093111511544

Epoch: 6| Step: 4
Training loss: 0.7942380471055077
Validation loss: 2.3720678159412123

Epoch: 6| Step: 5
Training loss: 0.746121391063979
Validation loss: 2.3217683441818235

Epoch: 6| Step: 6
Training loss: 0.8230792661574557
Validation loss: 2.338361284284239

Epoch: 6| Step: 7
Training loss: 0.6903006339963709
Validation loss: 2.3351019007047866

Epoch: 6| Step: 8
Training loss: 0.9145669441811212
Validation loss: 2.3277049462356265

Epoch: 6| Step: 9
Training loss: 1.146494980719152
Validation loss: 2.3472049987818644

Epoch: 6| Step: 10
Training loss: 0.7325720874610405
Validation loss: 2.281925329022628

Epoch: 6| Step: 11
Training loss: 0.775545196116369
Validation loss: 2.2859608917332572

Epoch: 6| Step: 12
Training loss: 0.585797305819384
Validation loss: 2.3463789067780465

Epoch: 6| Step: 13
Training loss: 0.9503744491661851
Validation loss: 2.2702264256044256

Epoch: 569| Step: 0
Training loss: 0.8767641539332652
Validation loss: 2.285833233278708

Epoch: 6| Step: 1
Training loss: 0.43980359830923893
Validation loss: 2.3060422747152867

Epoch: 6| Step: 2
Training loss: 1.5915261254834348
Validation loss: 2.3060119944290047

Epoch: 6| Step: 3
Training loss: 1.0241144867763303
Validation loss: 2.306462196698994

Epoch: 6| Step: 4
Training loss: 0.7317522166498441
Validation loss: 2.298735297675629

Epoch: 6| Step: 5
Training loss: 0.8993920604156026
Validation loss: 2.376109734522956

Epoch: 6| Step: 6
Training loss: 0.7887497083660379
Validation loss: 2.3337922805859885

Epoch: 6| Step: 7
Training loss: 0.787164122994205
Validation loss: 2.2854821469790108

Epoch: 6| Step: 8
Training loss: 0.7119148160200488
Validation loss: 2.270143930538598

Epoch: 6| Step: 9
Training loss: 0.6347789352195254
Validation loss: 2.36323938470809

Epoch: 6| Step: 10
Training loss: 0.6309465991682406
Validation loss: 2.308124141966022

Epoch: 6| Step: 11
Training loss: 0.5771262589016033
Validation loss: 2.3913967670441694

Epoch: 6| Step: 12
Training loss: 0.7272271018726262
Validation loss: 2.325357096494343

Epoch: 6| Step: 13
Training loss: 0.7506630271534862
Validation loss: 2.3369282973835603

Epoch: 570| Step: 0
Training loss: 0.7757277056299203
Validation loss: 2.390085954594316

Epoch: 6| Step: 1
Training loss: 0.7894752102970967
Validation loss: 2.330168084228397

Epoch: 6| Step: 2
Training loss: 0.7625022184621087
Validation loss: 2.3200280562179967

Epoch: 6| Step: 3
Training loss: 1.656944776955836
Validation loss: 2.357902825447421

Epoch: 6| Step: 4
Training loss: 0.4749377335343136
Validation loss: 2.308043750652529

Epoch: 6| Step: 5
Training loss: 0.6262017617140252
Validation loss: 2.40781971881791

Epoch: 6| Step: 6
Training loss: 0.9913372090906735
Validation loss: 2.319838770677571

Epoch: 6| Step: 7
Training loss: 0.9646216689058836
Validation loss: 2.383441065755607

Epoch: 6| Step: 8
Training loss: 0.7562206104967731
Validation loss: 2.374418924832204

Epoch: 6| Step: 9
Training loss: 0.7064274691521193
Validation loss: 2.2699737035642977

Epoch: 6| Step: 10
Training loss: 0.7588171837111282
Validation loss: 2.3164211642707526

Epoch: 6| Step: 11
Training loss: 0.5719007038114126
Validation loss: 2.2991182842174984

Epoch: 6| Step: 12
Training loss: 0.8987169577476145
Validation loss: 2.2927095771569217

Epoch: 6| Step: 13
Training loss: 0.742869736163846
Validation loss: 2.330331675368782

Epoch: 571| Step: 0
Training loss: 0.8108885263344204
Validation loss: 2.2637741879881754

Epoch: 6| Step: 1
Training loss: 0.5965183370798195
Validation loss: 2.3822984506415485

Epoch: 6| Step: 2
Training loss: 1.6458353774947336
Validation loss: 2.32978810070137

Epoch: 6| Step: 3
Training loss: 0.5725330339921069
Validation loss: 2.241037050835247

Epoch: 6| Step: 4
Training loss: 0.9366818672917465
Validation loss: 2.247529729833827

Epoch: 6| Step: 5
Training loss: 0.7801392097224223
Validation loss: 2.340577282922948

Epoch: 6| Step: 6
Training loss: 0.9113107652641788
Validation loss: 2.318402255296418

Epoch: 6| Step: 7
Training loss: 0.5061108174144638
Validation loss: 2.3546835959521135

Epoch: 6| Step: 8
Training loss: 0.5427895119762087
Validation loss: 2.4082137310386447

Epoch: 6| Step: 9
Training loss: 0.8001761034018595
Validation loss: 2.325996134192546

Epoch: 6| Step: 10
Training loss: 0.890521729488519
Validation loss: 2.309177545088357

Epoch: 6| Step: 11
Training loss: 0.7482219122736307
Validation loss: 2.29218328438251

Epoch: 6| Step: 12
Training loss: 0.7360677486419441
Validation loss: 2.271567685876431

Epoch: 6| Step: 13
Training loss: 0.7512324855749501
Validation loss: 2.3578163621165276

Epoch: 572| Step: 0
Training loss: 1.0462277817275476
Validation loss: 2.3658168271984223

Epoch: 6| Step: 1
Training loss: 0.7449792256755082
Validation loss: 2.3031089520017396

Epoch: 6| Step: 2
Training loss: 0.7485419246320301
Validation loss: 2.3159807566263884

Epoch: 6| Step: 3
Training loss: 0.740184530628281
Validation loss: 2.331724130191456

Epoch: 6| Step: 4
Training loss: 0.8854188171061412
Validation loss: 2.249013808253693

Epoch: 6| Step: 5
Training loss: 0.6958037580459897
Validation loss: 2.3415669540603097

Epoch: 6| Step: 6
Training loss: 0.6352930078926605
Validation loss: 2.272301314458738

Epoch: 6| Step: 7
Training loss: 0.6745628884295906
Validation loss: 2.3195423129479837

Epoch: 6| Step: 8
Training loss: 0.620428917095434
Validation loss: 2.357289687450981

Epoch: 6| Step: 9
Training loss: 0.7454406116350608
Validation loss: 2.374863528900487

Epoch: 6| Step: 10
Training loss: 0.7311035498663211
Validation loss: 2.3585233911001153

Epoch: 6| Step: 11
Training loss: 1.6609685369195277
Validation loss: 2.3988800126949426

Epoch: 6| Step: 12
Training loss: 1.0190841454456336
Validation loss: 2.4305749343552687

Epoch: 6| Step: 13
Training loss: 0.7206102016679721
Validation loss: 2.3902556806810997

Epoch: 573| Step: 0
Training loss: 0.6023075394686921
Validation loss: 2.4194385648753562

Epoch: 6| Step: 1
Training loss: 0.7753305099591153
Validation loss: 2.372020832592475

Epoch: 6| Step: 2
Training loss: 0.46139159706687927
Validation loss: 2.3846559082983867

Epoch: 6| Step: 3
Training loss: 0.6587297500523638
Validation loss: 2.3691234044412384

Epoch: 6| Step: 4
Training loss: 0.7825053238611432
Validation loss: 2.420512080210669

Epoch: 6| Step: 5
Training loss: 1.002294233233355
Validation loss: 2.32323674073897

Epoch: 6| Step: 6
Training loss: 0.5924766337941961
Validation loss: 2.3116062885135795

Epoch: 6| Step: 7
Training loss: 0.7350820830306808
Validation loss: 2.3625271434649426

Epoch: 6| Step: 8
Training loss: 0.941357781519817
Validation loss: 2.343265129441943

Epoch: 6| Step: 9
Training loss: 0.5385799182856568
Validation loss: 2.2695364133516898

Epoch: 6| Step: 10
Training loss: 1.587033499111164
Validation loss: 2.3003452229866808

Epoch: 6| Step: 11
Training loss: 0.681546158242678
Validation loss: 2.3341762471237373

Epoch: 6| Step: 12
Training loss: 0.7116244005461714
Validation loss: 2.3080747290330184

Epoch: 6| Step: 13
Training loss: 0.9567104502593122
Validation loss: 2.3091902390392924

Epoch: 574| Step: 0
Training loss: 0.6725409334693679
Validation loss: 2.297652744001095

Epoch: 6| Step: 1
Training loss: 0.7069659123869839
Validation loss: 2.3094921932828916

Epoch: 6| Step: 2
Training loss: 0.6429361198368205
Validation loss: 2.2955888081473663

Epoch: 6| Step: 3
Training loss: 0.8416293656861868
Validation loss: 2.3149335827820607

Epoch: 6| Step: 4
Training loss: 0.7996246545148935
Validation loss: 2.312023283320768

Epoch: 6| Step: 5
Training loss: 0.8489025815354018
Validation loss: 2.3675833387745673

Epoch: 6| Step: 6
Training loss: 0.7327532616200736
Validation loss: 2.307277520419552

Epoch: 6| Step: 7
Training loss: 1.0580590505940901
Validation loss: 2.301102715912586

Epoch: 6| Step: 8
Training loss: 0.7170877308316319
Validation loss: 2.301748244037863

Epoch: 6| Step: 9
Training loss: 0.6697630179543695
Validation loss: 2.327020609348137

Epoch: 6| Step: 10
Training loss: 0.5599447066393326
Validation loss: 2.3545213363750688

Epoch: 6| Step: 11
Training loss: 1.6814399271615248
Validation loss: 2.4346641701875757

Epoch: 6| Step: 12
Training loss: 0.6677874268826254
Validation loss: 2.3261685026154764

Epoch: 6| Step: 13
Training loss: 0.49467981647011483
Validation loss: 2.367766893778421

Epoch: 575| Step: 0
Training loss: 1.7230838582271353
Validation loss: 2.3130166458584935

Epoch: 6| Step: 1
Training loss: 0.5474432037018059
Validation loss: 2.2702979615498764

Epoch: 6| Step: 2
Training loss: 0.7247672924282856
Validation loss: 2.2913266605587452

Epoch: 6| Step: 3
Training loss: 0.6178725581289694
Validation loss: 2.3814313732541295

Epoch: 6| Step: 4
Training loss: 0.5695933680939886
Validation loss: 2.309194407800157

Epoch: 6| Step: 5
Training loss: 0.8041035283129283
Validation loss: 2.2733036519590493

Epoch: 6| Step: 6
Training loss: 0.9757982849637687
Validation loss: 2.413528912800296

Epoch: 6| Step: 7
Training loss: 0.9484821491321226
Validation loss: 2.342474850750202

Epoch: 6| Step: 8
Training loss: 0.5632097217365565
Validation loss: 2.3606673717844835

Epoch: 6| Step: 9
Training loss: 0.8944236324158357
Validation loss: 2.3169667230754616

Epoch: 6| Step: 10
Training loss: 0.8488623832042516
Validation loss: 2.32700238522529

Epoch: 6| Step: 11
Training loss: 0.7692706446215881
Validation loss: 2.3489375294395587

Epoch: 6| Step: 12
Training loss: 0.5791835887641442
Validation loss: 2.2537130649566284

Epoch: 6| Step: 13
Training loss: 0.6368450203410296
Validation loss: 2.4207491509549617

Epoch: 576| Step: 0
Training loss: 0.7996065409003993
Validation loss: 2.3252115860591123

Epoch: 6| Step: 1
Training loss: 1.5887319065267242
Validation loss: 2.327183894073195

Epoch: 6| Step: 2
Training loss: 0.7156645851347806
Validation loss: 2.299712464780635

Epoch: 6| Step: 3
Training loss: 0.6036799679294282
Validation loss: 2.322370658047602

Epoch: 6| Step: 4
Training loss: 0.676763801493161
Validation loss: 2.280139648942288

Epoch: 6| Step: 5
Training loss: 0.6624380550574749
Validation loss: 2.3343636018845126

Epoch: 6| Step: 6
Training loss: 0.6157698465727367
Validation loss: 2.235454163615631

Epoch: 6| Step: 7
Training loss: 0.9053127111580194
Validation loss: 2.3384242210675463

Epoch: 6| Step: 8
Training loss: 0.7656139450832148
Validation loss: 2.344000387182221

Epoch: 6| Step: 9
Training loss: 0.5905949943227006
Validation loss: 2.3202854498945884

Epoch: 6| Step: 10
Training loss: 0.8214113414331592
Validation loss: 2.3034968111003797

Epoch: 6| Step: 11
Training loss: 0.9676023884496585
Validation loss: 2.3747479014078725

Epoch: 6| Step: 12
Training loss: 0.6392340329622407
Validation loss: 2.4260986293822113

Epoch: 6| Step: 13
Training loss: 0.6751495231040814
Validation loss: 2.265130398305417

Epoch: 577| Step: 0
Training loss: 0.7357176822949016
Validation loss: 2.2917774371301722

Epoch: 6| Step: 1
Training loss: 0.7111002976701372
Validation loss: 2.4078520614339096

Epoch: 6| Step: 2
Training loss: 0.8115695614336791
Validation loss: 2.3008228968661686

Epoch: 6| Step: 3
Training loss: 0.772042683291088
Validation loss: 2.3706860354363712

Epoch: 6| Step: 4
Training loss: 1.5802044906351553
Validation loss: 2.325442393724725

Epoch: 6| Step: 5
Training loss: 0.8232310374671222
Validation loss: 2.2541864340101974

Epoch: 6| Step: 6
Training loss: 0.8456835315011583
Validation loss: 2.3233725120154234

Epoch: 6| Step: 7
Training loss: 0.5784395238675035
Validation loss: 2.2977743357434806

Epoch: 6| Step: 8
Training loss: 0.704459005726635
Validation loss: 2.3261919747511888

Epoch: 6| Step: 9
Training loss: 0.797679906002996
Validation loss: 2.419009247266938

Epoch: 6| Step: 10
Training loss: 0.49497425491640695
Validation loss: 2.3820501454521787

Epoch: 6| Step: 11
Training loss: 0.8394680513569978
Validation loss: 2.3396729741783577

Epoch: 6| Step: 12
Training loss: 0.7181542041839559
Validation loss: 2.3185012768011615

Epoch: 6| Step: 13
Training loss: 0.8980137696537974
Validation loss: 2.3309331908543482

Epoch: 578| Step: 0
Training loss: 0.5848519505530475
Validation loss: 2.374424098169813

Epoch: 6| Step: 1
Training loss: 0.9676271206736811
Validation loss: 2.3347115266308363

Epoch: 6| Step: 2
Training loss: 0.6959395206732121
Validation loss: 2.380202287038117

Epoch: 6| Step: 3
Training loss: 0.6341255834566633
Validation loss: 2.2953742384660534

Epoch: 6| Step: 4
Training loss: 1.5955961418007667
Validation loss: 2.297172744178199

Epoch: 6| Step: 5
Training loss: 0.7933338245689516
Validation loss: 2.3124011427954674

Epoch: 6| Step: 6
Training loss: 1.0926218481661003
Validation loss: 2.3491742011006695

Epoch: 6| Step: 7
Training loss: 0.5396651064893583
Validation loss: 2.3253545823060326

Epoch: 6| Step: 8
Training loss: 0.6844468814951307
Validation loss: 2.2950887301985183

Epoch: 6| Step: 9
Training loss: 0.5779453204568386
Validation loss: 2.300481468819158

Epoch: 6| Step: 10
Training loss: 0.6295155482110455
Validation loss: 2.2810078648473793

Epoch: 6| Step: 11
Training loss: 0.6125371999537738
Validation loss: 2.3908505854430264

Epoch: 6| Step: 12
Training loss: 0.74006687171456
Validation loss: 2.340000946923643

Epoch: 6| Step: 13
Training loss: 0.4093824444159455
Validation loss: 2.3214770785409957

Epoch: 579| Step: 0
Training loss: 0.6741718244964371
Validation loss: 2.2938872932063465

Epoch: 6| Step: 1
Training loss: 0.5587218344499956
Validation loss: 2.2690700241453037

Epoch: 6| Step: 2
Training loss: 0.5476377345286975
Validation loss: 2.35752583327595

Epoch: 6| Step: 3
Training loss: 0.8794444153154403
Validation loss: 2.35244857800758

Epoch: 6| Step: 4
Training loss: 0.5690775525418634
Validation loss: 2.2871600042010574

Epoch: 6| Step: 5
Training loss: 1.5292672535644996
Validation loss: 2.3303041689473623

Epoch: 6| Step: 6
Training loss: 0.6348064233433295
Validation loss: 2.3416956002214864

Epoch: 6| Step: 7
Training loss: 0.6511015114299894
Validation loss: 2.297134479629405

Epoch: 6| Step: 8
Training loss: 0.5906916202332446
Validation loss: 2.3709029132569337

Epoch: 6| Step: 9
Training loss: 0.8156880774533575
Validation loss: 2.313335404161817

Epoch: 6| Step: 10
Training loss: 0.6953929897397142
Validation loss: 2.3360056995962735

Epoch: 6| Step: 11
Training loss: 0.8117299098403289
Validation loss: 2.3454493891162644

Epoch: 6| Step: 12
Training loss: 0.8334232202371473
Validation loss: 2.3421100684570426

Epoch: 6| Step: 13
Training loss: 0.9569598735739849
Validation loss: 2.3703092658669465

Epoch: 580| Step: 0
Training loss: 0.711007712114467
Validation loss: 2.313823633764572

Epoch: 6| Step: 1
Training loss: 0.5946752967725002
Validation loss: 2.3462045375167158

Epoch: 6| Step: 2
Training loss: 0.8505308569188815
Validation loss: 2.3068804830882383

Epoch: 6| Step: 3
Training loss: 0.7688925944253104
Validation loss: 2.310716374083872

Epoch: 6| Step: 4
Training loss: 0.5615222433326297
Validation loss: 2.266262029666544

Epoch: 6| Step: 5
Training loss: 0.7654444033879187
Validation loss: 2.2677602028252855

Epoch: 6| Step: 6
Training loss: 0.8043335812211659
Validation loss: 2.388317720449923

Epoch: 6| Step: 7
Training loss: 0.756430634292904
Validation loss: 2.322123684959323

Epoch: 6| Step: 8
Training loss: 0.923618284753716
Validation loss: 2.424628169979722

Epoch: 6| Step: 9
Training loss: 0.5246320729518518
Validation loss: 2.294752348234929

Epoch: 6| Step: 10
Training loss: 0.5219185839516336
Validation loss: 2.378513278601342

Epoch: 6| Step: 11
Training loss: 0.5059236758100603
Validation loss: 2.343285603335682

Epoch: 6| Step: 12
Training loss: 1.7413662056577965
Validation loss: 2.324206257255127

Epoch: 6| Step: 13
Training loss: 0.5402633173782655
Validation loss: 2.341373154473576

Epoch: 581| Step: 0
Training loss: 0.6056711658404449
Validation loss: 2.3343996665430997

Epoch: 6| Step: 1
Training loss: 0.6361804395022096
Validation loss: 2.392466607406991

Epoch: 6| Step: 2
Training loss: 0.6836378464781282
Validation loss: 2.276740452184472

Epoch: 6| Step: 3
Training loss: 0.8271953474882393
Validation loss: 2.354036067469467

Epoch: 6| Step: 4
Training loss: 0.8023479487560917
Validation loss: 2.4330060701565905

Epoch: 6| Step: 5
Training loss: 1.011403038223709
Validation loss: 2.255404188583704

Epoch: 6| Step: 6
Training loss: 0.4622731335423257
Validation loss: 2.303279029610064

Epoch: 6| Step: 7
Training loss: 0.6044904619478855
Validation loss: 2.3450420479840086

Epoch: 6| Step: 8
Training loss: 0.719613841532379
Validation loss: 2.2966377750232523

Epoch: 6| Step: 9
Training loss: 0.4661396939034958
Validation loss: 2.3283355082555923

Epoch: 6| Step: 10
Training loss: 1.5703463574455572
Validation loss: 2.2451121849450333

Epoch: 6| Step: 11
Training loss: 0.8190599597366104
Validation loss: 2.345890976555636

Epoch: 6| Step: 12
Training loss: 0.6432498331392192
Validation loss: 2.344865319461596

Epoch: 6| Step: 13
Training loss: 0.8937373073716979
Validation loss: 2.3775616773101853

Epoch: 582| Step: 0
Training loss: 0.727980921165181
Validation loss: 2.3131218495107433

Epoch: 6| Step: 1
Training loss: 0.8322111839622885
Validation loss: 2.3984767048429236

Epoch: 6| Step: 2
Training loss: 0.6504719084846956
Validation loss: 2.3455833041131715

Epoch: 6| Step: 3
Training loss: 1.4749121752956023
Validation loss: 2.333424531967983

Epoch: 6| Step: 4
Training loss: 0.8493112325976794
Validation loss: 2.351923674886479

Epoch: 6| Step: 5
Training loss: 0.4539330446669881
Validation loss: 2.3554577290574357

Epoch: 6| Step: 6
Training loss: 0.6551267911773343
Validation loss: 2.3506610267940085

Epoch: 6| Step: 7
Training loss: 0.7157981629737374
Validation loss: 2.3208630592529644

Epoch: 6| Step: 8
Training loss: 0.6435492924882338
Validation loss: 2.3698770141017333

Epoch: 6| Step: 9
Training loss: 0.5904403095002866
Validation loss: 2.338599996996997

Epoch: 6| Step: 10
Training loss: 0.741507409352629
Validation loss: 2.3192663811107304

Epoch: 6| Step: 11
Training loss: 0.9513504205399768
Validation loss: 2.2731500857003875

Epoch: 6| Step: 12
Training loss: 0.802297951525018
Validation loss: 2.3398018006224457

Epoch: 6| Step: 13
Training loss: 0.6566857979943843
Validation loss: 2.3275318112688783

Epoch: 583| Step: 0
Training loss: 0.9144789570284821
Validation loss: 2.3399199136933935

Epoch: 6| Step: 1
Training loss: 1.611952190348056
Validation loss: 2.366255237743494

Epoch: 6| Step: 2
Training loss: 0.7230323431449686
Validation loss: 2.3289943563163202

Epoch: 6| Step: 3
Training loss: 0.5830022405872508
Validation loss: 2.3010692305131535

Epoch: 6| Step: 4
Training loss: 0.5717512820304105
Validation loss: 2.26587480434507

Epoch: 6| Step: 5
Training loss: 0.5281833887270858
Validation loss: 2.242993345225173

Epoch: 6| Step: 6
Training loss: 0.8455592643184702
Validation loss: 2.350563345895725

Epoch: 6| Step: 7
Training loss: 0.6482112443830834
Validation loss: 2.3187095187687126

Epoch: 6| Step: 8
Training loss: 0.8133519181358648
Validation loss: 2.3619412718308976

Epoch: 6| Step: 9
Training loss: 0.5992451409567424
Validation loss: 2.313344424900465

Epoch: 6| Step: 10
Training loss: 0.5062686045489437
Validation loss: 2.3603910656802825

Epoch: 6| Step: 11
Training loss: 0.8785256473008589
Validation loss: 2.388178599431071

Epoch: 6| Step: 12
Training loss: 0.7817627178044532
Validation loss: 2.4454794765813697

Epoch: 6| Step: 13
Training loss: 0.5830852259065972
Validation loss: 2.384048433486581

Epoch: 584| Step: 0
Training loss: 0.6890566715331331
Validation loss: 2.3869340137364614

Epoch: 6| Step: 1
Training loss: 0.6532957246313217
Validation loss: 2.3382565518012477

Epoch: 6| Step: 2
Training loss: 1.0333906555171162
Validation loss: 2.389700734308292

Epoch: 6| Step: 3
Training loss: 1.7043526101119266
Validation loss: 2.351069007117845

Epoch: 6| Step: 4
Training loss: 0.6324909947625009
Validation loss: 2.3604462578071224

Epoch: 6| Step: 5
Training loss: 0.6826940665113911
Validation loss: 2.2871065514294187

Epoch: 6| Step: 6
Training loss: 0.6611597458552763
Validation loss: 2.2470236111770836

Epoch: 6| Step: 7
Training loss: 0.5896280412156792
Validation loss: 2.326943144823123

Epoch: 6| Step: 8
Training loss: 0.7227019836800771
Validation loss: 2.3448373767404442

Epoch: 6| Step: 9
Training loss: 0.9140682383300114
Validation loss: 2.3176945623136427

Epoch: 6| Step: 10
Training loss: 0.7636618845254444
Validation loss: 2.3247328179652795

Epoch: 6| Step: 11
Training loss: 0.8069255778138328
Validation loss: 2.3889047973985797

Epoch: 6| Step: 12
Training loss: 0.5838354935213607
Validation loss: 2.3805762922695304

Epoch: 6| Step: 13
Training loss: 0.6420839954878628
Validation loss: 2.322963172987465

Epoch: 585| Step: 0
Training loss: 0.5384511106589622
Validation loss: 2.3159792268414288

Epoch: 6| Step: 1
Training loss: 0.7692632450529283
Validation loss: 2.2581929038504795

Epoch: 6| Step: 2
Training loss: 0.8551365804056792
Validation loss: 2.4043602076769655

Epoch: 6| Step: 3
Training loss: 0.7257035212783151
Validation loss: 2.3474631365986522

Epoch: 6| Step: 4
Training loss: 1.0327338900061036
Validation loss: 2.354564671944117

Epoch: 6| Step: 5
Training loss: 0.6393363832090079
Validation loss: 2.3447521711419728

Epoch: 6| Step: 6
Training loss: 0.5506555129656171
Validation loss: 2.345393963223912

Epoch: 6| Step: 7
Training loss: 1.6191682341537441
Validation loss: 2.363778435980987

Epoch: 6| Step: 8
Training loss: 0.7670145465262211
Validation loss: 2.3605789951434772

Epoch: 6| Step: 9
Training loss: 0.5937279144998143
Validation loss: 2.3370044101944805

Epoch: 6| Step: 10
Training loss: 0.6330306301224072
Validation loss: 2.3566872191611705

Epoch: 6| Step: 11
Training loss: 0.699339659056163
Validation loss: 2.368711907960417

Epoch: 6| Step: 12
Training loss: 0.6555190784287999
Validation loss: 2.358136549677734

Epoch: 6| Step: 13
Training loss: 0.7755504606764871
Validation loss: 2.295685758891802

Epoch: 586| Step: 0
Training loss: 0.596528878640859
Validation loss: 2.2732839185370204

Epoch: 6| Step: 1
Training loss: 0.47493905128158387
Validation loss: 2.366539301240532

Epoch: 6| Step: 2
Training loss: 0.6492166548969419
Validation loss: 2.365532144823358

Epoch: 6| Step: 3
Training loss: 0.6487856011002929
Validation loss: 2.356843764738589

Epoch: 6| Step: 4
Training loss: 0.8159816678269275
Validation loss: 2.3158505641035854

Epoch: 6| Step: 5
Training loss: 0.48166914373583664
Validation loss: 2.272502403946156

Epoch: 6| Step: 6
Training loss: 0.6273391105888854
Validation loss: 2.33702791720142

Epoch: 6| Step: 7
Training loss: 0.5796709783209825
Validation loss: 2.3576113340487734

Epoch: 6| Step: 8
Training loss: 0.6746413037243929
Validation loss: 2.382964596734785

Epoch: 6| Step: 9
Training loss: 1.0784928620287482
Validation loss: 2.3201317010823574

Epoch: 6| Step: 10
Training loss: 0.9301655606086286
Validation loss: 2.2821414322291083

Epoch: 6| Step: 11
Training loss: 1.690941726997942
Validation loss: 2.3227272212114585

Epoch: 6| Step: 12
Training loss: 0.5305887763483772
Validation loss: 2.3637376250213924

Epoch: 6| Step: 13
Training loss: 0.6763326126589569
Validation loss: 2.351299083214171

Epoch: 587| Step: 0
Training loss: 0.9026807675854406
Validation loss: 2.366320398948664

Epoch: 6| Step: 1
Training loss: 0.5568960574157971
Validation loss: 2.400644019371123

Epoch: 6| Step: 2
Training loss: 0.5666286952489216
Validation loss: 2.313420119037024

Epoch: 6| Step: 3
Training loss: 0.7378838493880207
Validation loss: 2.3577864156627184

Epoch: 6| Step: 4
Training loss: 0.8792411335749447
Validation loss: 2.338121891247011

Epoch: 6| Step: 5
Training loss: 1.1145344423403172
Validation loss: 2.2772353410391437

Epoch: 6| Step: 6
Training loss: 0.7536296831328093
Validation loss: 2.366851111285535

Epoch: 6| Step: 7
Training loss: 0.52343619047542
Validation loss: 2.282732650461893

Epoch: 6| Step: 8
Training loss: 0.7243866282493292
Validation loss: 2.317980552431579

Epoch: 6| Step: 9
Training loss: 0.5832158776515912
Validation loss: 2.3843608342434015

Epoch: 6| Step: 10
Training loss: 0.6901420199011282
Validation loss: 2.340019488318799

Epoch: 6| Step: 11
Training loss: 0.5787671106004865
Validation loss: 2.2776375281025594

Epoch: 6| Step: 12
Training loss: 1.5676845747286936
Validation loss: 2.3797554361979265

Epoch: 6| Step: 13
Training loss: 0.6883803929466962
Validation loss: 2.324816238651644

Epoch: 588| Step: 0
Training loss: 0.7606458884562692
Validation loss: 2.3636706664722955

Epoch: 6| Step: 1
Training loss: 0.5001191354916407
Validation loss: 2.331708756372264

Epoch: 6| Step: 2
Training loss: 0.677702207653913
Validation loss: 2.368748953482429

Epoch: 6| Step: 3
Training loss: 0.574261203156707
Validation loss: 2.313491267383407

Epoch: 6| Step: 4
Training loss: 0.7681275553773319
Validation loss: 2.3886234688154873

Epoch: 6| Step: 5
Training loss: 0.6210488357138694
Validation loss: 2.3431651861775475

Epoch: 6| Step: 6
Training loss: 1.037438406896939
Validation loss: 2.3829678102065355

Epoch: 6| Step: 7
Training loss: 0.882401193323219
Validation loss: 2.3824471459711485

Epoch: 6| Step: 8
Training loss: 1.5979469986100356
Validation loss: 2.4051021900851164

Epoch: 6| Step: 9
Training loss: 0.7948571631033046
Validation loss: 2.319322809412124

Epoch: 6| Step: 10
Training loss: 0.8598670937726027
Validation loss: 2.2966450256666247

Epoch: 6| Step: 11
Training loss: 0.6156516945565202
Validation loss: 2.320289285487796

Epoch: 6| Step: 12
Training loss: 0.7443314755620577
Validation loss: 2.3559829688553204

Epoch: 6| Step: 13
Training loss: 0.734211355603593
Validation loss: 2.3528527224689433

Epoch: 589| Step: 0
Training loss: 0.7833082171397382
Validation loss: 2.416068388815313

Epoch: 6| Step: 1
Training loss: 0.6240633144382899
Validation loss: 2.340509023758174

Epoch: 6| Step: 2
Training loss: 0.8256642831702
Validation loss: 2.286663538897685

Epoch: 6| Step: 3
Training loss: 0.7347978226919627
Validation loss: 2.337286069002503

Epoch: 6| Step: 4
Training loss: 1.6050725666171781
Validation loss: 2.373469072490381

Epoch: 6| Step: 5
Training loss: 0.5873105047893743
Validation loss: 2.382519660652261

Epoch: 6| Step: 6
Training loss: 0.5843443000603591
Validation loss: 2.3852655939959946

Epoch: 6| Step: 7
Training loss: 0.9901840528233002
Validation loss: 2.2612064328311026

Epoch: 6| Step: 8
Training loss: 0.7327927121091531
Validation loss: 2.3626036751070596

Epoch: 6| Step: 9
Training loss: 0.9806076498545104
Validation loss: 2.331820090855501

Epoch: 6| Step: 10
Training loss: 0.6027902978948486
Validation loss: 2.3494523768518762

Epoch: 6| Step: 11
Training loss: 0.6722442588092848
Validation loss: 2.3607178791487335

Epoch: 6| Step: 12
Training loss: 0.6051238031058324
Validation loss: 2.2719597853865863

Epoch: 6| Step: 13
Training loss: 0.7518633107634689
Validation loss: 2.397305719283073

Epoch: 590| Step: 0
Training loss: 0.9749939796066256
Validation loss: 2.3350448691784793

Epoch: 6| Step: 1
Training loss: 0.6142572545472054
Validation loss: 2.2828416013112443

Epoch: 6| Step: 2
Training loss: 0.6581779950605423
Validation loss: 2.318562901180827

Epoch: 6| Step: 3
Training loss: 0.6141078747784702
Validation loss: 2.3450012553172943

Epoch: 6| Step: 4
Training loss: 0.7282597805902508
Validation loss: 2.3466536454266445

Epoch: 6| Step: 5
Training loss: 0.7693719069591485
Validation loss: 2.358087706927023

Epoch: 6| Step: 6
Training loss: 0.7484097310371969
Validation loss: 2.304730785944343

Epoch: 6| Step: 7
Training loss: 0.7204760268602307
Validation loss: 2.364232428691471

Epoch: 6| Step: 8
Training loss: 0.9870064697246829
Validation loss: 2.3438344971660148

Epoch: 6| Step: 9
Training loss: 0.9486710337870972
Validation loss: 2.363250713240934

Epoch: 6| Step: 10
Training loss: 0.4721000646228338
Validation loss: 2.398417945839023

Epoch: 6| Step: 11
Training loss: 0.649862607777248
Validation loss: 2.326786990002863

Epoch: 6| Step: 12
Training loss: 0.6438975831642417
Validation loss: 2.396787950996886

Epoch: 6| Step: 13
Training loss: 2.0309484404682894
Validation loss: 2.3340514113820783

Epoch: 591| Step: 0
Training loss: 0.6301644575330339
Validation loss: 2.3530958809368

Epoch: 6| Step: 1
Training loss: 0.6486162835427034
Validation loss: 2.3243562606154375

Epoch: 6| Step: 2
Training loss: 0.6233654582913295
Validation loss: 2.423382053947051

Epoch: 6| Step: 3
Training loss: 0.7983490269683988
Validation loss: 2.2710991350422063

Epoch: 6| Step: 4
Training loss: 0.5428282466750048
Validation loss: 2.410432057686017

Epoch: 6| Step: 5
Training loss: 0.47334392428582234
Validation loss: 2.323317096272592

Epoch: 6| Step: 6
Training loss: 0.86565032674047
Validation loss: 2.373708048130336

Epoch: 6| Step: 7
Training loss: 0.2486201892174464
Validation loss: 2.4214697280088604

Epoch: 6| Step: 8
Training loss: 0.5491348983980543
Validation loss: 2.353990436229905

Epoch: 6| Step: 9
Training loss: 0.9088801004085413
Validation loss: 2.384573357555336

Epoch: 6| Step: 10
Training loss: 0.5103568671352653
Validation loss: 2.387895289317354

Epoch: 6| Step: 11
Training loss: 0.9576867486196089
Validation loss: 2.3804349267487117

Epoch: 6| Step: 12
Training loss: 0.8663042054824708
Validation loss: 2.276499725908054

Epoch: 6| Step: 13
Training loss: 2.1187315093277306
Validation loss: 2.247476802280833

Epoch: 592| Step: 0
Training loss: 0.4672449746389772
Validation loss: 2.2793045660319504

Epoch: 6| Step: 1
Training loss: 1.5327323433763262
Validation loss: 2.2978152115009856

Epoch: 6| Step: 2
Training loss: 0.7124994328145229
Validation loss: 2.3479604702261097

Epoch: 6| Step: 3
Training loss: 0.6001446350928255
Validation loss: 2.306355908957803

Epoch: 6| Step: 4
Training loss: 1.0110989590556194
Validation loss: 2.336023463890765

Epoch: 6| Step: 5
Training loss: 0.810148577897504
Validation loss: 2.368781831723182

Epoch: 6| Step: 6
Training loss: 0.7587980174121686
Validation loss: 2.2836435134107247

Epoch: 6| Step: 7
Training loss: 0.5625371126011733
Validation loss: 2.2624475678255105

Epoch: 6| Step: 8
Training loss: 0.6020440985315699
Validation loss: 2.296515682158957

Epoch: 6| Step: 9
Training loss: 0.5545320158625581
Validation loss: 2.3276042709626097

Epoch: 6| Step: 10
Training loss: 0.9616317722087546
Validation loss: 2.3657051957027693

Epoch: 6| Step: 11
Training loss: 0.4580531636703796
Validation loss: 2.3627266008146806

Epoch: 6| Step: 12
Training loss: 1.00625762462689
Validation loss: 2.378029137781229

Epoch: 6| Step: 13
Training loss: 1.226121033352442
Validation loss: 2.400030386041913

Epoch: 593| Step: 0
Training loss: 0.5751439121770789
Validation loss: 2.374500935725102

Epoch: 6| Step: 1
Training loss: 0.6609409792111856
Validation loss: 2.3256101678045904

Epoch: 6| Step: 2
Training loss: 0.5212972355212965
Validation loss: 2.368200427022375

Epoch: 6| Step: 3
Training loss: 0.40582921170302994
Validation loss: 2.3758663298610445

Epoch: 6| Step: 4
Training loss: 0.6662853735073387
Validation loss: 2.245862174845367

Epoch: 6| Step: 5
Training loss: 0.9887041837973943
Validation loss: 2.4313288562965725

Epoch: 6| Step: 6
Training loss: 1.4688934905390014
Validation loss: 2.3332270998730507

Epoch: 6| Step: 7
Training loss: 0.780176111293584
Validation loss: 2.3219462283851824

Epoch: 6| Step: 8
Training loss: 0.9709730176074054
Validation loss: 2.3544795483328245

Epoch: 6| Step: 9
Training loss: 0.636765952203648
Validation loss: 2.388057938771447

Epoch: 6| Step: 10
Training loss: 0.7095024800973011
Validation loss: 2.3443886885455507

Epoch: 6| Step: 11
Training loss: 0.6321070471204364
Validation loss: 2.3276351784526734

Epoch: 6| Step: 12
Training loss: 0.8375534054823398
Validation loss: 2.406605019260327

Epoch: 6| Step: 13
Training loss: 0.8128710779702291
Validation loss: 2.3616716170391707

Epoch: 594| Step: 0
Training loss: 0.7862631743014185
Validation loss: 2.373133405657969

Epoch: 6| Step: 1
Training loss: 0.6458674596158449
Validation loss: 2.3795196223622734

Epoch: 6| Step: 2
Training loss: 0.8154443065680561
Validation loss: 2.3451497394448655

Epoch: 6| Step: 3
Training loss: 1.6931575316059952
Validation loss: 2.3974153938777

Epoch: 6| Step: 4
Training loss: 0.7054444943606253
Validation loss: 2.4003059281950994

Epoch: 6| Step: 5
Training loss: 0.5542042736209449
Validation loss: 2.3264928055497185

Epoch: 6| Step: 6
Training loss: 0.5564287284289107
Validation loss: 2.325215633482856

Epoch: 6| Step: 7
Training loss: 0.7314393230442569
Validation loss: 2.301265201361876

Epoch: 6| Step: 8
Training loss: 0.5639173347311721
Validation loss: 2.4171922679333644

Epoch: 6| Step: 9
Training loss: 0.9399187357757123
Validation loss: 2.3107482696452633

Epoch: 6| Step: 10
Training loss: 0.4644211202234858
Validation loss: 2.287072884649371

Epoch: 6| Step: 11
Training loss: 0.8166727242601944
Validation loss: 2.3447346074617186

Epoch: 6| Step: 12
Training loss: 0.6969817622903285
Validation loss: 2.299308395822127

Epoch: 6| Step: 13
Training loss: 0.6647155467771252
Validation loss: 2.3830023544852286

Epoch: 595| Step: 0
Training loss: 0.6850218759649483
Validation loss: 2.3584162255278773

Epoch: 6| Step: 1
Training loss: 0.7037672923929594
Validation loss: 2.3696237700461515

Epoch: 6| Step: 2
Training loss: 0.6107042926075912
Validation loss: 2.3272803388152954

Epoch: 6| Step: 3
Training loss: 1.4901105396819363
Validation loss: 2.267938743760378

Epoch: 6| Step: 4
Training loss: 0.6389488063119003
Validation loss: 2.375278804111514

Epoch: 6| Step: 5
Training loss: 0.5361462367310559
Validation loss: 2.3608423755290837

Epoch: 6| Step: 6
Training loss: 0.6212360051227082
Validation loss: 2.374837061285643

Epoch: 6| Step: 7
Training loss: 0.9612006470668931
Validation loss: 2.3139707305668313

Epoch: 6| Step: 8
Training loss: 0.53376014315685
Validation loss: 2.2341218738007047

Epoch: 6| Step: 9
Training loss: 0.8940596024253956
Validation loss: 2.353211284082288

Epoch: 6| Step: 10
Training loss: 0.8100225384249179
Validation loss: 2.324544139960929

Epoch: 6| Step: 11
Training loss: 0.8181778517540242
Validation loss: 2.363598097386683

Epoch: 6| Step: 12
Training loss: 0.7988331988110566
Validation loss: 2.3243254187174394

Epoch: 6| Step: 13
Training loss: 0.8416267807325671
Validation loss: 2.2645844720404256

Epoch: 596| Step: 0
Training loss: 0.7832497751702584
Validation loss: 2.3232188455673004

Epoch: 6| Step: 1
Training loss: 0.9770653002497574
Validation loss: 2.3351257990382046

Epoch: 6| Step: 2
Training loss: 0.6537992948251156
Validation loss: 2.249904293271685

Epoch: 6| Step: 3
Training loss: 0.7969678936836929
Validation loss: 2.280620390859665

Epoch: 6| Step: 4
Training loss: 1.5721463555062913
Validation loss: 2.276335484799831

Epoch: 6| Step: 5
Training loss: 0.6733432960560065
Validation loss: 2.397134312270636

Epoch: 6| Step: 6
Training loss: 0.8468751956615714
Validation loss: 2.310448020774756

Epoch: 6| Step: 7
Training loss: 0.6796014665546276
Validation loss: 2.3421108374035047

Epoch: 6| Step: 8
Training loss: 0.9289973927308319
Validation loss: 2.359882434632731

Epoch: 6| Step: 9
Training loss: 0.5100846735469216
Validation loss: 2.325579990727324

Epoch: 6| Step: 10
Training loss: 0.8799435068550411
Validation loss: 2.3911484771122153

Epoch: 6| Step: 11
Training loss: 0.648432283495407
Validation loss: 2.3182273498385455

Epoch: 6| Step: 12
Training loss: 0.810505620067392
Validation loss: 2.400746982727503

Epoch: 6| Step: 13
Training loss: 0.47812470018464703
Validation loss: 2.3270188841108492

Epoch: 597| Step: 0
Training loss: 1.0533631098035334
Validation loss: 2.3318567302595232

Epoch: 6| Step: 1
Training loss: 0.4810736655155873
Validation loss: 2.339217467197123

Epoch: 6| Step: 2
Training loss: 0.590347201497141
Validation loss: 2.2548412926242003

Epoch: 6| Step: 3
Training loss: 0.5683382430195474
Validation loss: 2.3821955207029912

Epoch: 6| Step: 4
Training loss: 0.48887031118299507
Validation loss: 2.3189948920476455

Epoch: 6| Step: 5
Training loss: 0.570990747016051
Validation loss: 2.3708892948736024

Epoch: 6| Step: 6
Training loss: 0.6196824359542606
Validation loss: 2.2537401872192775

Epoch: 6| Step: 7
Training loss: 0.6996517439067597
Validation loss: 2.348388182129238

Epoch: 6| Step: 8
Training loss: 0.8065430071787207
Validation loss: 2.3806386051476207

Epoch: 6| Step: 9
Training loss: 0.5750015009984867
Validation loss: 2.289101974615637

Epoch: 6| Step: 10
Training loss: 0.7628494868830655
Validation loss: 2.4028101437253353

Epoch: 6| Step: 11
Training loss: 0.5330074076862412
Validation loss: 2.411059208853125

Epoch: 6| Step: 12
Training loss: 0.5168797225459644
Validation loss: 2.3755592633295337

Epoch: 6| Step: 13
Training loss: 2.191758506600881
Validation loss: 2.412096479757646

Epoch: 598| Step: 0
Training loss: 0.5421236995569718
Validation loss: 2.3517370584724153

Epoch: 6| Step: 1
Training loss: 0.8644468973506895
Validation loss: 2.36550570989542

Epoch: 6| Step: 2
Training loss: 0.770569231996346
Validation loss: 2.341378967451833

Epoch: 6| Step: 3
Training loss: 0.84571179392118
Validation loss: 2.2539551927006345

Epoch: 6| Step: 4
Training loss: 0.60156641376758
Validation loss: 2.241251827979289

Epoch: 6| Step: 5
Training loss: 0.7591496498205089
Validation loss: 2.373379421594899

Epoch: 6| Step: 6
Training loss: 1.6170497227456888
Validation loss: 2.356744911832229

Epoch: 6| Step: 7
Training loss: 0.7571473496167554
Validation loss: 2.3342040533295783

Epoch: 6| Step: 8
Training loss: 0.5299627191099321
Validation loss: 2.248686684050879

Epoch: 6| Step: 9
Training loss: 0.6008156437943872
Validation loss: 2.2436916158054774

Epoch: 6| Step: 10
Training loss: 0.7875027868433491
Validation loss: 2.3866417241364277

Epoch: 6| Step: 11
Training loss: 0.4860057145104566
Validation loss: 2.435423294238438

Epoch: 6| Step: 12
Training loss: 0.671691514621265
Validation loss: 2.386730079871708

Epoch: 6| Step: 13
Training loss: 0.9814560011855772
Validation loss: 2.3651922548772752

Epoch: 599| Step: 0
Training loss: 0.8369573984755411
Validation loss: 2.3285710904710175

Epoch: 6| Step: 1
Training loss: 0.5249768865129524
Validation loss: 2.2870634918263604

Epoch: 6| Step: 2
Training loss: 1.6042076782664878
Validation loss: 2.306223798571257

Epoch: 6| Step: 3
Training loss: 0.6002469726734011
Validation loss: 2.375350354210091

Epoch: 6| Step: 4
Training loss: 0.6398364773477887
Validation loss: 2.3675697473165207

Epoch: 6| Step: 5
Training loss: 0.7539954651536842
Validation loss: 2.309644661833383

Epoch: 6| Step: 6
Training loss: 0.7370148954503719
Validation loss: 2.248867613048855

Epoch: 6| Step: 7
Training loss: 0.5750841638916251
Validation loss: 2.2828927594736914

Epoch: 6| Step: 8
Training loss: 0.7078740697359833
Validation loss: 2.3482324386149642

Epoch: 6| Step: 9
Training loss: 0.7071343025430448
Validation loss: 2.2572040296462244

Epoch: 6| Step: 10
Training loss: 0.8551608014730548
Validation loss: 2.4052887365425444

Epoch: 6| Step: 11
Training loss: 0.6211353983800372
Validation loss: 2.346380734961044

Epoch: 6| Step: 12
Training loss: 0.8542511867172219
Validation loss: 2.2924689258096698

Epoch: 6| Step: 13
Training loss: 0.730978884526368
Validation loss: 2.311642096041159

Epoch: 600| Step: 0
Training loss: 0.6805411929822942
Validation loss: 2.3100189994847837

Epoch: 6| Step: 1
Training loss: 0.6113451385568076
Validation loss: 2.3062220811203056

Epoch: 6| Step: 2
Training loss: 0.8001373679717858
Validation loss: 2.324261594994258

Epoch: 6| Step: 3
Training loss: 0.659978221837443
Validation loss: 2.316521460136715

Epoch: 6| Step: 4
Training loss: 0.7082520372823976
Validation loss: 2.332200605663341

Epoch: 6| Step: 5
Training loss: 0.7128989441268664
Validation loss: 2.347933397438117

Epoch: 6| Step: 6
Training loss: 0.7778075478358959
Validation loss: 2.3395368131053855

Epoch: 6| Step: 7
Training loss: 0.2471393594269872
Validation loss: 2.379236473431609

Epoch: 6| Step: 8
Training loss: 0.7639774579422461
Validation loss: 2.2897328058179

Epoch: 6| Step: 9
Training loss: 0.7928840328870539
Validation loss: 2.3228844452281487

Epoch: 6| Step: 10
Training loss: 1.624978872308566
Validation loss: 2.360461374948478

Epoch: 6| Step: 11
Training loss: 0.7290720923716969
Validation loss: 2.3984027697163777

Epoch: 6| Step: 12
Training loss: 0.8437979649226496
Validation loss: 2.297988425290296

Epoch: 6| Step: 13
Training loss: 0.8934511218478575
Validation loss: 2.3022612216833345

Epoch: 601| Step: 0
Training loss: 0.5592135745222317
Validation loss: 2.3006800874392623

Epoch: 6| Step: 1
Training loss: 0.6808528775087318
Validation loss: 2.3978042822170105

Epoch: 6| Step: 2
Training loss: 0.5137830258634527
Validation loss: 2.2705848048318753

Epoch: 6| Step: 3
Training loss: 0.7793478506907241
Validation loss: 2.358720213317701

Epoch: 6| Step: 4
Training loss: 0.4538570935523624
Validation loss: 2.3099701692299055

Epoch: 6| Step: 5
Training loss: 0.763195738204617
Validation loss: 2.2736011476251825

Epoch: 6| Step: 6
Training loss: 0.5515489571181179
Validation loss: 2.2968902447866855

Epoch: 6| Step: 7
Training loss: 0.9958807624045919
Validation loss: 2.377256991962867

Epoch: 6| Step: 8
Training loss: 0.6156321133042877
Validation loss: 2.3752054137520067

Epoch: 6| Step: 9
Training loss: 0.5826629692297854
Validation loss: 2.327003842763761

Epoch: 6| Step: 10
Training loss: 0.6866948441477003
Validation loss: 2.3478766161784064

Epoch: 6| Step: 11
Training loss: 0.5576415849950128
Validation loss: 2.3721674006605915

Epoch: 6| Step: 12
Training loss: 1.564086794974155
Validation loss: 2.3146704676296688

Epoch: 6| Step: 13
Training loss: 0.6920242134196433
Validation loss: 2.3571550388657987

Epoch: 602| Step: 0
Training loss: 0.7473566441557138
Validation loss: 2.310152439241893

Epoch: 6| Step: 1
Training loss: 0.8536981173678325
Validation loss: 2.4004851249161856

Epoch: 6| Step: 2
Training loss: 0.6957236371023122
Validation loss: 2.3433242465841824

Epoch: 6| Step: 3
Training loss: 0.6248861209118637
Validation loss: 2.341907932956526

Epoch: 6| Step: 4
Training loss: 0.5264032241856614
Validation loss: 2.360516280886093

Epoch: 6| Step: 5
Training loss: 0.6869247587540988
Validation loss: 2.3100227428102107

Epoch: 6| Step: 6
Training loss: 0.76171389847213
Validation loss: 2.3477077989322654

Epoch: 6| Step: 7
Training loss: 0.9049306012516457
Validation loss: 2.335464117340499

Epoch: 6| Step: 8
Training loss: 0.7341498983620959
Validation loss: 2.325891167869663

Epoch: 6| Step: 9
Training loss: 0.6049727592562019
Validation loss: 2.258960738332043

Epoch: 6| Step: 10
Training loss: 0.6660283554516123
Validation loss: 2.3576023228388934

Epoch: 6| Step: 11
Training loss: 0.8383513919889978
Validation loss: 2.3767730018819653

Epoch: 6| Step: 12
Training loss: 1.5353652772969055
Validation loss: 2.236352999188338

Epoch: 6| Step: 13
Training loss: 0.4888261729831383
Validation loss: 2.3069883213028977

Epoch: 603| Step: 0
Training loss: 0.9079266199024748
Validation loss: 2.3167148742726797

Epoch: 6| Step: 1
Training loss: 0.7885179434617213
Validation loss: 2.3621631184413396

Epoch: 6| Step: 2
Training loss: 0.7464942855616241
Validation loss: 2.302913229055988

Epoch: 6| Step: 3
Training loss: 0.7251177544168521
Validation loss: 2.3137998588827804

Epoch: 6| Step: 4
Training loss: 1.557516925897368
Validation loss: 2.2812807269575903

Epoch: 6| Step: 5
Training loss: 0.7481935521636955
Validation loss: 2.2784110235829536

Epoch: 6| Step: 6
Training loss: 0.6711842734552976
Validation loss: 2.314344825978272

Epoch: 6| Step: 7
Training loss: 0.7942717421896482
Validation loss: 2.356523284030777

Epoch: 6| Step: 8
Training loss: 0.6679014651670119
Validation loss: 2.303514858372463

Epoch: 6| Step: 9
Training loss: 0.8031336030610627
Validation loss: 2.352910360980365

Epoch: 6| Step: 10
Training loss: 0.78015907413912
Validation loss: 2.290884907822091

Epoch: 6| Step: 11
Training loss: 0.4303459151459177
Validation loss: 2.312411916618917

Epoch: 6| Step: 12
Training loss: 0.5495828075806496
Validation loss: 2.2863096641591523

Epoch: 6| Step: 13
Training loss: 0.7865545622372428
Validation loss: 2.36591523496323

Epoch: 604| Step: 0
Training loss: 0.7334150980391659
Validation loss: 2.313244997573104

Epoch: 6| Step: 1
Training loss: 0.73041032363682
Validation loss: 2.336240897917995

Epoch: 6| Step: 2
Training loss: 0.46940820893958923
Validation loss: 2.2896482373485654

Epoch: 6| Step: 3
Training loss: 0.5719989767298849
Validation loss: 2.4004998500100014

Epoch: 6| Step: 4
Training loss: 0.7503499168462548
Validation loss: 2.37106828205742

Epoch: 6| Step: 5
Training loss: 1.5833084037558218
Validation loss: 2.352224713317621

Epoch: 6| Step: 6
Training loss: 0.5412956091713461
Validation loss: 2.267128291986339

Epoch: 6| Step: 7
Training loss: 0.6132158621170992
Validation loss: 2.3605877647545435

Epoch: 6| Step: 8
Training loss: 0.6252067462384491
Validation loss: 2.3520643160584997

Epoch: 6| Step: 9
Training loss: 0.654416839078201
Validation loss: 2.35432162706378

Epoch: 6| Step: 10
Training loss: 0.7679738196887678
Validation loss: 2.2542545617254834

Epoch: 6| Step: 11
Training loss: 0.4729761034491861
Validation loss: 2.3506469546867352

Epoch: 6| Step: 12
Training loss: 0.9175778144975562
Validation loss: 2.2788605700213727

Epoch: 6| Step: 13
Training loss: 0.6393952079555194
Validation loss: 2.262842508031843

Epoch: 605| Step: 0
Training loss: 1.5416854736968042
Validation loss: 2.328879113741726

Epoch: 6| Step: 1
Training loss: 0.7463051860857617
Validation loss: 2.297263408314383

Epoch: 6| Step: 2
Training loss: 0.6040858812143792
Validation loss: 2.2719936315446017

Epoch: 6| Step: 3
Training loss: 0.6475426807844407
Validation loss: 2.2641055898024396

Epoch: 6| Step: 4
Training loss: 0.7844141019520346
Validation loss: 2.312908848187473

Epoch: 6| Step: 5
Training loss: 0.7134811255024281
Validation loss: 2.266085368658216

Epoch: 6| Step: 6
Training loss: 0.4803830667404571
Validation loss: 2.2985495481306155

Epoch: 6| Step: 7
Training loss: 0.8138646989257498
Validation loss: 2.3789497728614943

Epoch: 6| Step: 8
Training loss: 0.9570191051724621
Validation loss: 2.388866052266418

Epoch: 6| Step: 9
Training loss: 0.6872093713462226
Validation loss: 2.392395641005221

Epoch: 6| Step: 10
Training loss: 0.7485686790489653
Validation loss: 2.3278537985123093

Epoch: 6| Step: 11
Training loss: 0.42801836245020036
Validation loss: 2.304810238909229

Epoch: 6| Step: 12
Training loss: 0.420579050056763
Validation loss: 2.2520216492667413

Epoch: 6| Step: 13
Training loss: 1.050329458683736
Validation loss: 2.344257624081755

Epoch: 606| Step: 0
Training loss: 0.7527532902762555
Validation loss: 2.3058296867513817

Epoch: 6| Step: 1
Training loss: 0.8152096754206519
Validation loss: 2.3022881979419765

Epoch: 6| Step: 2
Training loss: 0.7256094311367276
Validation loss: 2.3018826566251325

Epoch: 6| Step: 3
Training loss: 0.5423059053880644
Validation loss: 2.332965835806749

Epoch: 6| Step: 4
Training loss: 0.6189958902616991
Validation loss: 2.329150339482075

Epoch: 6| Step: 5
Training loss: 1.6767632157200363
Validation loss: 2.322236645304693

Epoch: 6| Step: 6
Training loss: 0.6861751752893683
Validation loss: 2.3063306987605543

Epoch: 6| Step: 7
Training loss: 0.4576348614342615
Validation loss: 2.317813463765977

Epoch: 6| Step: 8
Training loss: 0.8308639576457791
Validation loss: 2.33330582420845

Epoch: 6| Step: 9
Training loss: 0.7910763187435671
Validation loss: 2.3583537733490236

Epoch: 6| Step: 10
Training loss: 0.4949254975942797
Validation loss: 2.2891614327615275

Epoch: 6| Step: 11
Training loss: 0.6376890500565874
Validation loss: 2.279940650966642

Epoch: 6| Step: 12
Training loss: 0.4074017447511975
Validation loss: 2.2510375304895733

Epoch: 6| Step: 13
Training loss: 0.9087161676229867
Validation loss: 2.378951372610798

Epoch: 607| Step: 0
Training loss: 0.9168936419525856
Validation loss: 2.2999794178416746

Epoch: 6| Step: 1
Training loss: 1.5277177201613907
Validation loss: 2.332823856681269

Epoch: 6| Step: 2
Training loss: 0.5884734398334555
Validation loss: 2.371546787148201

Epoch: 6| Step: 3
Training loss: 0.5057788917408746
Validation loss: 2.295244486031377

Epoch: 6| Step: 4
Training loss: 0.677843046682787
Validation loss: 2.3439967604597296

Epoch: 6| Step: 5
Training loss: 0.835686298310441
Validation loss: 2.3888600919163854

Epoch: 6| Step: 6
Training loss: 0.7016325051228924
Validation loss: 2.3907847425170416

Epoch: 6| Step: 7
Training loss: 0.9476699123671378
Validation loss: 2.2085761793658145

Epoch: 6| Step: 8
Training loss: 0.6621480384723288
Validation loss: 2.3235880726042923

Epoch: 6| Step: 9
Training loss: 0.6560136051380844
Validation loss: 2.3370168268468157

Epoch: 6| Step: 10
Training loss: 0.4930382294214938
Validation loss: 2.342667927225278

Epoch: 6| Step: 11
Training loss: 0.8286596767404891
Validation loss: 2.3884264199122547

Epoch: 6| Step: 12
Training loss: 0.6569666355579701
Validation loss: 2.3736615082015886

Epoch: 6| Step: 13
Training loss: 0.5010634675970034
Validation loss: 2.336537951959037

Epoch: 608| Step: 0
Training loss: 0.7376494757259008
Validation loss: 2.3782620234839382

Epoch: 6| Step: 1
Training loss: 0.8065776661832965
Validation loss: 2.3646645581926444

Epoch: 6| Step: 2
Training loss: 0.6941497596049523
Validation loss: 2.339801101587609

Epoch: 6| Step: 3
Training loss: 0.656340547400267
Validation loss: 2.335915756659411

Epoch: 6| Step: 4
Training loss: 0.6653828229600164
Validation loss: 2.284278262732575

Epoch: 6| Step: 5
Training loss: 0.7409250866683929
Validation loss: 2.2685943618833857

Epoch: 6| Step: 6
Training loss: 0.606974372506596
Validation loss: 2.3281406672671054

Epoch: 6| Step: 7
Training loss: 0.6252770763393094
Validation loss: 2.2719081714367872

Epoch: 6| Step: 8
Training loss: 0.5218467167939533
Validation loss: 2.2765470297440626

Epoch: 6| Step: 9
Training loss: 0.6569299354411666
Validation loss: 2.3535662384575113

Epoch: 6| Step: 10
Training loss: 0.6558057780174431
Validation loss: 2.347678334367717

Epoch: 6| Step: 11
Training loss: 0.6462241856420055
Validation loss: 2.305415810090388

Epoch: 6| Step: 12
Training loss: 1.6212769186568976
Validation loss: 2.260436867214003

Epoch: 6| Step: 13
Training loss: 0.5975535186038362
Validation loss: 2.339909257214394

Epoch: 609| Step: 0
Training loss: 0.6267412011693337
Validation loss: 2.3223141183458176

Epoch: 6| Step: 1
Training loss: 0.44116038674132757
Validation loss: 2.3203858643310182

Epoch: 6| Step: 2
Training loss: 0.5458771457512019
Validation loss: 2.360287568138888

Epoch: 6| Step: 3
Training loss: 0.8080582988145035
Validation loss: 2.2951262692989074

Epoch: 6| Step: 4
Training loss: 0.6120743751865784
Validation loss: 2.3362176913464983

Epoch: 6| Step: 5
Training loss: 0.784634051156631
Validation loss: 2.386463809369082

Epoch: 6| Step: 6
Training loss: 0.8045557525335233
Validation loss: 2.317060826494372

Epoch: 6| Step: 7
Training loss: 0.6645952668110138
Validation loss: 2.323701494084185

Epoch: 6| Step: 8
Training loss: 0.5873608150372687
Validation loss: 2.3792349789308656

Epoch: 6| Step: 9
Training loss: 0.5719647186025512
Validation loss: 2.309446411791536

Epoch: 6| Step: 10
Training loss: 0.4777393973984054
Validation loss: 2.392674733518335

Epoch: 6| Step: 11
Training loss: 0.547010023614516
Validation loss: 2.3662383027951712

Epoch: 6| Step: 12
Training loss: 1.5804174410175036
Validation loss: 2.2871540786410827

Epoch: 6| Step: 13
Training loss: 0.4731658363860154
Validation loss: 2.330576935498454

Epoch: 610| Step: 0
Training loss: 0.544318819136146
Validation loss: 2.2812702404500373

Epoch: 6| Step: 1
Training loss: 0.651289745113784
Validation loss: 2.2138530576357347

Epoch: 6| Step: 2
Training loss: 0.5808938709474837
Validation loss: 2.291515466357664

Epoch: 6| Step: 3
Training loss: 0.4570708624472397
Validation loss: 2.3797893947576725

Epoch: 6| Step: 4
Training loss: 0.8745589166340327
Validation loss: 2.197938601017896

Epoch: 6| Step: 5
Training loss: 0.5170327245991563
Validation loss: 2.285593761922101

Epoch: 6| Step: 6
Training loss: 0.5708769004327403
Validation loss: 2.353488194557639

Epoch: 6| Step: 7
Training loss: 0.5778350618536643
Validation loss: 2.272564739258763

Epoch: 6| Step: 8
Training loss: 1.5956392497208238
Validation loss: 2.3539329526776696

Epoch: 6| Step: 9
Training loss: 0.8046483891435856
Validation loss: 2.390227252885838

Epoch: 6| Step: 10
Training loss: 0.660949816938485
Validation loss: 2.348266706742528

Epoch: 6| Step: 11
Training loss: 0.9466840079279604
Validation loss: 2.3315359365877666

Epoch: 6| Step: 12
Training loss: 0.7598392872539093
Validation loss: 2.3424390652809266

Epoch: 6| Step: 13
Training loss: 0.5089867733059383
Validation loss: 2.3143350503492752

Epoch: 611| Step: 0
Training loss: 0.5836784556654474
Validation loss: 2.3500079712070363

Epoch: 6| Step: 1
Training loss: 1.5290007127868708
Validation loss: 2.30815514536873

Epoch: 6| Step: 2
Training loss: 0.6605753499395577
Validation loss: 2.27684376102229

Epoch: 6| Step: 3
Training loss: 0.565255199119956
Validation loss: 2.307453830277409

Epoch: 6| Step: 4
Training loss: 0.521364148171751
Validation loss: 2.3407498163135134

Epoch: 6| Step: 5
Training loss: 0.46723803817782117
Validation loss: 2.28999914840365

Epoch: 6| Step: 6
Training loss: 0.6122233018829063
Validation loss: 2.3124401535986068

Epoch: 6| Step: 7
Training loss: 0.6638537808192738
Validation loss: 2.315311080788704

Epoch: 6| Step: 8
Training loss: 0.9184989534308753
Validation loss: 2.3776102925300204

Epoch: 6| Step: 9
Training loss: 0.7828382369815005
Validation loss: 2.3808475541772087

Epoch: 6| Step: 10
Training loss: 0.6898738884741498
Validation loss: 2.3136339392383767

Epoch: 6| Step: 11
Training loss: 0.7282639546889076
Validation loss: 2.384174843869777

Epoch: 6| Step: 12
Training loss: 0.5011992377930712
Validation loss: 2.3755426386033944

Epoch: 6| Step: 13
Training loss: 0.5639358050644221
Validation loss: 2.3354464146539478

Epoch: 612| Step: 0
Training loss: 1.031802462934352
Validation loss: 2.328642076451247

Epoch: 6| Step: 1
Training loss: 0.6301694469171976
Validation loss: 2.3487350444687247

Epoch: 6| Step: 2
Training loss: 0.7651182950253756
Validation loss: 2.3813735315351847

Epoch: 6| Step: 3
Training loss: 0.7722706325216223
Validation loss: 2.3669573772432724

Epoch: 6| Step: 4
Training loss: 0.4028531895485088
Validation loss: 2.28193500981464

Epoch: 6| Step: 5
Training loss: 0.5304236998270305
Validation loss: 2.305882150165657

Epoch: 6| Step: 6
Training loss: 0.6004336776635559
Validation loss: 2.338741835930715

Epoch: 6| Step: 7
Training loss: 1.5930030418697416
Validation loss: 2.3551801406989967

Epoch: 6| Step: 8
Training loss: 0.6741076345811853
Validation loss: 2.326885460784475

Epoch: 6| Step: 9
Training loss: 0.41530875027056685
Validation loss: 2.318019985820814

Epoch: 6| Step: 10
Training loss: 0.5128139394941007
Validation loss: 2.3835409868086304

Epoch: 6| Step: 11
Training loss: 0.7240393522379652
Validation loss: 2.3432466793718523

Epoch: 6| Step: 12
Training loss: 0.4850274275860198
Validation loss: 2.368288999880951

Epoch: 6| Step: 13
Training loss: 0.7419519954277952
Validation loss: 2.2946517047327206

Epoch: 613| Step: 0
Training loss: 0.6860886739579114
Validation loss: 2.2902244321601732

Epoch: 6| Step: 1
Training loss: 0.5802752227396227
Validation loss: 2.236623530892162

Epoch: 6| Step: 2
Training loss: 0.6408404011413098
Validation loss: 2.245687549557964

Epoch: 6| Step: 3
Training loss: 0.5989152201740374
Validation loss: 2.3385212162845765

Epoch: 6| Step: 4
Training loss: 0.41336737169898724
Validation loss: 2.368309045279288

Epoch: 6| Step: 5
Training loss: 0.6525326529550312
Validation loss: 2.3211046009488867

Epoch: 6| Step: 6
Training loss: 0.44136590688884114
Validation loss: 2.333881368383661

Epoch: 6| Step: 7
Training loss: 0.6303845913104592
Validation loss: 2.3462322279403622

Epoch: 6| Step: 8
Training loss: 1.0690728687005455
Validation loss: 2.3724044126608064

Epoch: 6| Step: 9
Training loss: 0.8636924144247023
Validation loss: 2.3737021361200847

Epoch: 6| Step: 10
Training loss: 1.5243529870202228
Validation loss: 2.353546728133638

Epoch: 6| Step: 11
Training loss: 0.4440888608695982
Validation loss: 2.3308903499839255

Epoch: 6| Step: 12
Training loss: 0.7633264643416984
Validation loss: 2.265093109077687

Epoch: 6| Step: 13
Training loss: 0.5809240883627779
Validation loss: 2.2724265517130005

Epoch: 614| Step: 0
Training loss: 0.8279187287444295
Validation loss: 2.3792132789328995

Epoch: 6| Step: 1
Training loss: 0.5865335865647967
Validation loss: 2.3704550886250666

Epoch: 6| Step: 2
Training loss: 0.7974970016901461
Validation loss: 2.3169562298988535

Epoch: 6| Step: 3
Training loss: 0.5728522669114452
Validation loss: 2.394828905424475

Epoch: 6| Step: 4
Training loss: 1.5351410299619246
Validation loss: 2.291966424468631

Epoch: 6| Step: 5
Training loss: 0.7837584469840446
Validation loss: 2.350521163558854

Epoch: 6| Step: 6
Training loss: 0.6126798852176687
Validation loss: 2.2864102869094065

Epoch: 6| Step: 7
Training loss: 0.49632098783203815
Validation loss: 2.3301322934909967

Epoch: 6| Step: 8
Training loss: 0.6771440821073788
Validation loss: 2.229473296674166

Epoch: 6| Step: 9
Training loss: 0.5821597322321652
Validation loss: 2.3807412804279755

Epoch: 6| Step: 10
Training loss: 0.5376026454766782
Validation loss: 2.3207339569759053

Epoch: 6| Step: 11
Training loss: 0.4966901813318061
Validation loss: 2.3478015459324286

Epoch: 6| Step: 12
Training loss: 0.8401672095246754
Validation loss: 2.301289448017741

Epoch: 6| Step: 13
Training loss: 0.6754285520425243
Validation loss: 2.333397154294144

Epoch: 615| Step: 0
Training loss: 0.5459095743916529
Validation loss: 2.354667394341159

Epoch: 6| Step: 1
Training loss: 0.5590296025243112
Validation loss: 2.260819395604652

Epoch: 6| Step: 2
Training loss: 0.7100262933214475
Validation loss: 2.323127332181105

Epoch: 6| Step: 3
Training loss: 0.3990492892188369
Validation loss: 2.3293693236016972

Epoch: 6| Step: 4
Training loss: 0.5899966717480681
Validation loss: 2.2660799887163643

Epoch: 6| Step: 5
Training loss: 0.6899957007813239
Validation loss: 2.3583071320630324

Epoch: 6| Step: 6
Training loss: 0.5970075989276331
Validation loss: 2.328043186699012

Epoch: 6| Step: 7
Training loss: 0.6597156521542531
Validation loss: 2.3024363312313505

Epoch: 6| Step: 8
Training loss: 0.7018345541098304
Validation loss: 2.392260696486102

Epoch: 6| Step: 9
Training loss: 0.6245667147784797
Validation loss: 2.2633926975542353

Epoch: 6| Step: 10
Training loss: 1.5300608318677065
Validation loss: 2.2869674501130546

Epoch: 6| Step: 11
Training loss: 0.6263479479031593
Validation loss: 2.315489001586619

Epoch: 6| Step: 12
Training loss: 1.0573178869043574
Validation loss: 2.3395230488489016

Epoch: 6| Step: 13
Training loss: 0.6823622155054943
Validation loss: 2.2522364739109517

Epoch: 616| Step: 0
Training loss: 0.8701497252745913
Validation loss: 2.3346390989267563

Epoch: 6| Step: 1
Training loss: 0.5835649649224912
Validation loss: 2.3309901516846314

Epoch: 6| Step: 2
Training loss: 0.7418959195434227
Validation loss: 2.2925226695448804

Epoch: 6| Step: 3
Training loss: 0.529544336107184
Validation loss: 2.3131393595286904

Epoch: 6| Step: 4
Training loss: 1.6092484804068932
Validation loss: 2.3481345027483345

Epoch: 6| Step: 5
Training loss: 0.6429688909073926
Validation loss: 2.2661592084977262

Epoch: 6| Step: 6
Training loss: 0.7158000781854085
Validation loss: 2.380285702907321

Epoch: 6| Step: 7
Training loss: 0.6860834179393256
Validation loss: 2.3270206170599224

Epoch: 6| Step: 8
Training loss: 0.7850570995678653
Validation loss: 2.29949758141814

Epoch: 6| Step: 9
Training loss: 0.6340064805854848
Validation loss: 2.296050766446312

Epoch: 6| Step: 10
Training loss: 0.514029287871269
Validation loss: 2.342337703348206

Epoch: 6| Step: 11
Training loss: 0.7473170452702308
Validation loss: 2.3916114585804142

Epoch: 6| Step: 12
Training loss: 0.5555539684140528
Validation loss: 2.402628568647445

Epoch: 6| Step: 13
Training loss: 0.6792581232390389
Validation loss: 2.3048991967290693

Epoch: 617| Step: 0
Training loss: 0.5077619087253923
Validation loss: 2.311287770353868

Epoch: 6| Step: 1
Training loss: 0.8215854758513832
Validation loss: 2.2536659957919754

Epoch: 6| Step: 2
Training loss: 0.8454630733504571
Validation loss: 2.336835266638554

Epoch: 6| Step: 3
Training loss: 0.65435025580987
Validation loss: 2.321029130912433

Epoch: 6| Step: 4
Training loss: 1.540388591339569
Validation loss: 2.2761456833809226

Epoch: 6| Step: 5
Training loss: 0.5398379843109987
Validation loss: 2.2815805595473084

Epoch: 6| Step: 6
Training loss: 0.4824105388838425
Validation loss: 2.3057755310438495

Epoch: 6| Step: 7
Training loss: 0.7830038602010349
Validation loss: 2.3195222263100352

Epoch: 6| Step: 8
Training loss: 0.617907116658174
Validation loss: 2.35743139692406

Epoch: 6| Step: 9
Training loss: 0.4930845593113841
Validation loss: 2.262652116347322

Epoch: 6| Step: 10
Training loss: 0.6179467854412272
Validation loss: 2.29310177105208

Epoch: 6| Step: 11
Training loss: 0.6739691103074084
Validation loss: 2.299087022913474

Epoch: 6| Step: 12
Training loss: 0.8160541998262972
Validation loss: 2.2788016092286494

Epoch: 6| Step: 13
Training loss: 0.45729262873983595
Validation loss: 2.380957189033564

Epoch: 618| Step: 0
Training loss: 0.8243102253416758
Validation loss: 2.294107033465373

Epoch: 6| Step: 1
Training loss: 0.6169876064650932
Validation loss: 2.338291501705931

Epoch: 6| Step: 2
Training loss: 0.6274942219988705
Validation loss: 2.334482445838439

Epoch: 6| Step: 3
Training loss: 1.525141071611023
Validation loss: 2.276311570648529

Epoch: 6| Step: 4
Training loss: 0.674268539906485
Validation loss: 2.2836412760482556

Epoch: 6| Step: 5
Training loss: 0.6729915124547869
Validation loss: 2.3359238012361248

Epoch: 6| Step: 6
Training loss: 0.6746588851705498
Validation loss: 2.2130806426287157

Epoch: 6| Step: 7
Training loss: 0.8395184263850624
Validation loss: 2.405798569390261

Epoch: 6| Step: 8
Training loss: 0.6433324820960875
Validation loss: 2.347477865022042

Epoch: 6| Step: 9
Training loss: 0.7030007146557666
Validation loss: 2.275646831480292

Epoch: 6| Step: 10
Training loss: 0.7140573647479289
Validation loss: 2.21335126855418

Epoch: 6| Step: 11
Training loss: 0.4854018647743575
Validation loss: 2.3382758865554503

Epoch: 6| Step: 12
Training loss: 0.6156917264764439
Validation loss: 2.336687964589742

Epoch: 6| Step: 13
Training loss: 0.8702515777687558
Validation loss: 2.344606761138235

Epoch: 619| Step: 0
Training loss: 0.5080655274537369
Validation loss: 2.3350060282503335

Epoch: 6| Step: 1
Training loss: 0.3739552846623139
Validation loss: 2.342846257150116

Epoch: 6| Step: 2
Training loss: 0.5467102074970995
Validation loss: 2.3503726293760363

Epoch: 6| Step: 3
Training loss: 0.7151607373434167
Validation loss: 2.295757614300624

Epoch: 6| Step: 4
Training loss: 0.5876864462095244
Validation loss: 2.3370534752771794

Epoch: 6| Step: 5
Training loss: 1.5582316271933372
Validation loss: 2.3605859912865994

Epoch: 6| Step: 6
Training loss: 0.827625159798984
Validation loss: 2.304944960095621

Epoch: 6| Step: 7
Training loss: 0.5957508255668296
Validation loss: 2.243207883063288

Epoch: 6| Step: 8
Training loss: 0.6019312979016542
Validation loss: 2.339205249632557

Epoch: 6| Step: 9
Training loss: 0.6491873668150114
Validation loss: 2.3704895610989274

Epoch: 6| Step: 10
Training loss: 0.5668664838241626
Validation loss: 2.284972790510098

Epoch: 6| Step: 11
Training loss: 0.9358613315978671
Validation loss: 2.32455474832176

Epoch: 6| Step: 12
Training loss: 0.5856730818170064
Validation loss: 2.287062319892577

Epoch: 6| Step: 13
Training loss: 0.36076837433266307
Validation loss: 2.2760665346662807

Epoch: 620| Step: 0
Training loss: 0.549356443853405
Validation loss: 2.341523343996316

Epoch: 6| Step: 1
Training loss: 0.6127363079973922
Validation loss: 2.310033069385076

Epoch: 6| Step: 2
Training loss: 0.5460810483838799
Validation loss: 2.378360531794839

Epoch: 6| Step: 3
Training loss: 1.5712715370808308
Validation loss: 2.3258048972688883

Epoch: 6| Step: 4
Training loss: 0.4468846760215777
Validation loss: 2.335130217919534

Epoch: 6| Step: 5
Training loss: 0.5208581600629919
Validation loss: 2.2808828795964997

Epoch: 6| Step: 6
Training loss: 0.589507708287984
Validation loss: 2.3571100509708773

Epoch: 6| Step: 7
Training loss: 1.0309587703197656
Validation loss: 2.4449640265764594

Epoch: 6| Step: 8
Training loss: 0.6689304767829108
Validation loss: 2.292878774737897

Epoch: 6| Step: 9
Training loss: 0.6653563964897482
Validation loss: 2.349778188733181

Epoch: 6| Step: 10
Training loss: 0.4684123412559574
Validation loss: 2.3057115663215613

Epoch: 6| Step: 11
Training loss: 0.63972086023241
Validation loss: 2.3247734138040674

Epoch: 6| Step: 12
Training loss: 0.6259747771477197
Validation loss: 2.306697852285885

Epoch: 6| Step: 13
Training loss: 0.7836413215961326
Validation loss: 2.2526142208100945

Epoch: 621| Step: 0
Training loss: 0.6807556747454966
Validation loss: 2.308459098496309

Epoch: 6| Step: 1
Training loss: 0.5719297028523754
Validation loss: 2.2675462519351006

Epoch: 6| Step: 2
Training loss: 0.696723043014054
Validation loss: 2.3015127644695

Epoch: 6| Step: 3
Training loss: 0.7204195617417573
Validation loss: 2.219892870422565

Epoch: 6| Step: 4
Training loss: 0.6742189904629133
Validation loss: 2.3489706435055036

Epoch: 6| Step: 5
Training loss: 0.6348091227959984
Validation loss: 2.3917900971221444

Epoch: 6| Step: 6
Training loss: 0.9662466930515408
Validation loss: 2.330421928430521

Epoch: 6| Step: 7
Training loss: 0.5616609620569617
Validation loss: 2.3937727432372182

Epoch: 6| Step: 8
Training loss: 0.44126246650851064
Validation loss: 2.3475458178102193

Epoch: 6| Step: 9
Training loss: 0.8001795299073219
Validation loss: 2.35635864228433

Epoch: 6| Step: 10
Training loss: 0.5401355181294286
Validation loss: 2.3410447103492387

Epoch: 6| Step: 11
Training loss: 0.5019754486463468
Validation loss: 2.394561483136813

Epoch: 6| Step: 12
Training loss: 1.4874136090235532
Validation loss: 2.3790010936191277

Epoch: 6| Step: 13
Training loss: 0.42936972224783004
Validation loss: 2.367110729918665

Epoch: 622| Step: 0
Training loss: 0.9647719630667159
Validation loss: 2.3545456359020114

Epoch: 6| Step: 1
Training loss: 0.6021894927850522
Validation loss: 2.328065631244651

Epoch: 6| Step: 2
Training loss: 0.5768973486922225
Validation loss: 2.3291267551710604

Epoch: 6| Step: 3
Training loss: 0.5555840888908211
Validation loss: 2.3430193696777053

Epoch: 6| Step: 4
Training loss: 0.5148758792837275
Validation loss: 2.3169903050260636

Epoch: 6| Step: 5
Training loss: 0.7221181980028628
Validation loss: 2.365650743975757

Epoch: 6| Step: 6
Training loss: 0.7132630929798127
Validation loss: 2.2952496479441695

Epoch: 6| Step: 7
Training loss: 0.6090815644585829
Validation loss: 2.3082157848146903

Epoch: 6| Step: 8
Training loss: 0.5048053320455742
Validation loss: 2.337476572802554

Epoch: 6| Step: 9
Training loss: 0.8289279643674238
Validation loss: 2.4098265135750676

Epoch: 6| Step: 10
Training loss: 0.3853746425640615
Validation loss: 2.343034182383765

Epoch: 6| Step: 11
Training loss: 0.6364824757677002
Validation loss: 2.2913339419940084

Epoch: 6| Step: 12
Training loss: 1.6322856582436887
Validation loss: 2.3536908816624758

Epoch: 6| Step: 13
Training loss: 0.6119325958279855
Validation loss: 2.384119283827511

Epoch: 623| Step: 0
Training loss: 0.6127953761080079
Validation loss: 2.3939551061964277

Epoch: 6| Step: 1
Training loss: 0.6618709078510063
Validation loss: 2.3450024633431608

Epoch: 6| Step: 2
Training loss: 0.7218650817189727
Validation loss: 2.283984536811274

Epoch: 6| Step: 3
Training loss: 0.6520996779281483
Validation loss: 2.2799651184986693

Epoch: 6| Step: 4
Training loss: 1.4976278462549686
Validation loss: 2.288203632866745

Epoch: 6| Step: 5
Training loss: 0.711588048396706
Validation loss: 2.318931155431811

Epoch: 6| Step: 6
Training loss: 0.5738882553972702
Validation loss: 2.36204381343859

Epoch: 6| Step: 7
Training loss: 0.8401507504045355
Validation loss: 2.2327797660367708

Epoch: 6| Step: 8
Training loss: 0.6462402804914745
Validation loss: 2.2681879412081565

Epoch: 6| Step: 9
Training loss: 0.7024765839526179
Validation loss: 2.370273384717159

Epoch: 6| Step: 10
Training loss: 0.809998365742012
Validation loss: 2.253371493980035

Epoch: 6| Step: 11
Training loss: 0.9534775128966007
Validation loss: 2.3311462328004313

Epoch: 6| Step: 12
Training loss: 0.42700446571409134
Validation loss: 2.2966699096380796

Epoch: 6| Step: 13
Training loss: 0.5337314154451508
Validation loss: 2.303098451900466

Epoch: 624| Step: 0
Training loss: 0.7249898811160347
Validation loss: 2.394676735774648

Epoch: 6| Step: 1
Training loss: 0.5143798474701045
Validation loss: 2.3873206184774753

Epoch: 6| Step: 2
Training loss: 0.5540176968175236
Validation loss: 2.2786066673651355

Epoch: 6| Step: 3
Training loss: 1.6503012728909658
Validation loss: 2.433390750311554

Epoch: 6| Step: 4
Training loss: 0.5155836146536669
Validation loss: 2.316493841191661

Epoch: 6| Step: 5
Training loss: 0.9470882918338113
Validation loss: 2.313285534578756

Epoch: 6| Step: 6
Training loss: 0.5651962509954239
Validation loss: 2.348107068400713

Epoch: 6| Step: 7
Training loss: 0.3775402497313847
Validation loss: 2.3356554980098756

Epoch: 6| Step: 8
Training loss: 0.5588032256341184
Validation loss: 2.3411276987251233

Epoch: 6| Step: 9
Training loss: 0.4296779631510015
Validation loss: 2.379412360022793

Epoch: 6| Step: 10
Training loss: 0.5609981036587656
Validation loss: 2.3762982856471786

Epoch: 6| Step: 11
Training loss: 0.8250316931676869
Validation loss: 2.3125159283294248

Epoch: 6| Step: 12
Training loss: 0.4640434492420121
Validation loss: 2.285429778940935

Epoch: 6| Step: 13
Training loss: 0.6732094398460008
Validation loss: 2.346887459858482

Epoch: 625| Step: 0
Training loss: 0.5820890052353412
Validation loss: 2.280979753513049

Epoch: 6| Step: 1
Training loss: 0.7068725534290503
Validation loss: 2.3429677017270243

Epoch: 6| Step: 2
Training loss: 0.582955771828064
Validation loss: 2.3065053034556984

Epoch: 6| Step: 3
Training loss: 0.6706614513036435
Validation loss: 2.267152749094746

Epoch: 6| Step: 4
Training loss: 0.5721422654860329
Validation loss: 2.3276917877023187

Epoch: 6| Step: 5
Training loss: 0.4286489767775876
Validation loss: 2.4046043380070174

Epoch: 6| Step: 6
Training loss: 0.5892781963116533
Validation loss: 2.3730792561724696

Epoch: 6| Step: 7
Training loss: 0.7539041944090338
Validation loss: 2.3252093291570053

Epoch: 6| Step: 8
Training loss: 0.6144854149697707
Validation loss: 2.3254382794472264

Epoch: 6| Step: 9
Training loss: 0.5207237382659138
Validation loss: 2.3914874201723717

Epoch: 6| Step: 10
Training loss: 0.6375489702302725
Validation loss: 2.3898981040047538

Epoch: 6| Step: 11
Training loss: 0.7840571135498976
Validation loss: 2.3076988956575883

Epoch: 6| Step: 12
Training loss: 1.521251263958822
Validation loss: 2.367813263192033

Epoch: 6| Step: 13
Training loss: 0.6469063894055084
Validation loss: 2.3547983127109253

Epoch: 626| Step: 0
Training loss: 0.58620690827921
Validation loss: 2.3230482717416954

Epoch: 6| Step: 1
Training loss: 0.5992692112968406
Validation loss: 2.343466303893489

Epoch: 6| Step: 2
Training loss: 0.7370879606321296
Validation loss: 2.2983918100001812

Epoch: 6| Step: 3
Training loss: 0.4637594640028322
Validation loss: 2.359012625098872

Epoch: 6| Step: 4
Training loss: 0.6862754753817917
Validation loss: 2.303813370191006

Epoch: 6| Step: 5
Training loss: 0.6733170492340255
Validation loss: 2.2263304429165762

Epoch: 6| Step: 6
Training loss: 0.8123295678604673
Validation loss: 2.353231806528374

Epoch: 6| Step: 7
Training loss: 1.4895308247450272
Validation loss: 2.3496445597346587

Epoch: 6| Step: 8
Training loss: 0.6185873068184647
Validation loss: 2.329968397875156

Epoch: 6| Step: 9
Training loss: 0.5935744477799061
Validation loss: 2.2763394209139647

Epoch: 6| Step: 10
Training loss: 0.6672502858907031
Validation loss: 2.3346493056382043

Epoch: 6| Step: 11
Training loss: 0.5493980245354725
Validation loss: 2.311030056773702

Epoch: 6| Step: 12
Training loss: 0.5658670423894894
Validation loss: 2.363183719741572

Epoch: 6| Step: 13
Training loss: 0.5365295887508711
Validation loss: 2.3888877638478485

Epoch: 627| Step: 0
Training loss: 0.6312805517753735
Validation loss: 2.383023997387931

Epoch: 6| Step: 1
Training loss: 1.4885425088006696
Validation loss: 2.336130059440943

Epoch: 6| Step: 2
Training loss: 0.6210055978464366
Validation loss: 2.3402538932684314

Epoch: 6| Step: 3
Training loss: 0.3743338230777525
Validation loss: 2.3608386454568726

Epoch: 6| Step: 4
Training loss: 0.56865943774555
Validation loss: 2.3223590815293322

Epoch: 6| Step: 5
Training loss: 0.6951715990954128
Validation loss: 2.4090934794624785

Epoch: 6| Step: 6
Training loss: 0.5346072924600009
Validation loss: 2.3425355134123436

Epoch: 6| Step: 7
Training loss: 0.564229689993553
Validation loss: 2.2931856179772083

Epoch: 6| Step: 8
Training loss: 0.4907872399490173
Validation loss: 2.3350349120475853

Epoch: 6| Step: 9
Training loss: 0.8866585194301835
Validation loss: 2.2621043368568046

Epoch: 6| Step: 10
Training loss: 0.7215245225906577
Validation loss: 2.308916291101021

Epoch: 6| Step: 11
Training loss: 0.7801698847533659
Validation loss: 2.3033857053015714

Epoch: 6| Step: 12
Training loss: 0.5942130541873277
Validation loss: 2.338603150845087

Epoch: 6| Step: 13
Training loss: 0.3361936080896859
Validation loss: 2.3912864658409068

Epoch: 628| Step: 0
Training loss: 0.5232033846522577
Validation loss: 2.353669363324486

Epoch: 6| Step: 1
Training loss: 0.5078785193150251
Validation loss: 2.3284358989539253

Epoch: 6| Step: 2
Training loss: 0.6728405114139754
Validation loss: 2.326450601109321

Epoch: 6| Step: 3
Training loss: 0.8519943262323217
Validation loss: 2.325266206391212

Epoch: 6| Step: 4
Training loss: 1.4755975708922622
Validation loss: 2.311654299585617

Epoch: 6| Step: 5
Training loss: 0.5745737444672492
Validation loss: 2.3313488147853003

Epoch: 6| Step: 6
Training loss: 0.638547412748967
Validation loss: 2.4221263235090413

Epoch: 6| Step: 7
Training loss: 0.8317804809342034
Validation loss: 2.2790015351495936

Epoch: 6| Step: 8
Training loss: 0.5093486147172603
Validation loss: 2.2826823388848

Epoch: 6| Step: 9
Training loss: 0.5454857755881619
Validation loss: 2.3175543602715147

Epoch: 6| Step: 10
Training loss: 0.6164045558659585
Validation loss: 2.3047699955406467

Epoch: 6| Step: 11
Training loss: 0.5934786176372883
Validation loss: 2.317599080630801

Epoch: 6| Step: 12
Training loss: 0.6470353927424409
Validation loss: 2.3050825984136307

Epoch: 6| Step: 13
Training loss: 0.4059064953411423
Validation loss: 2.34837789103111

Epoch: 629| Step: 0
Training loss: 0.6327674520023311
Validation loss: 2.3168727945356062

Epoch: 6| Step: 1
Training loss: 0.8526394185255154
Validation loss: 2.330048321560831

Epoch: 6| Step: 2
Training loss: 0.6587938323810978
Validation loss: 2.4147045283842656

Epoch: 6| Step: 3
Training loss: 0.5582008580668328
Validation loss: 2.3883302739297974

Epoch: 6| Step: 4
Training loss: 0.5428443052541462
Validation loss: 2.3489186971820217

Epoch: 6| Step: 5
Training loss: 0.6555098037684935
Validation loss: 2.2461566418674583

Epoch: 6| Step: 6
Training loss: 0.45155465208315565
Validation loss: 2.332413199630138

Epoch: 6| Step: 7
Training loss: 0.7705779339849493
Validation loss: 2.279682629579424

Epoch: 6| Step: 8
Training loss: 0.47260496949005826
Validation loss: 2.3322975310489626

Epoch: 6| Step: 9
Training loss: 1.5704233310740574
Validation loss: 2.296747319753117

Epoch: 6| Step: 10
Training loss: 0.6541897358643393
Validation loss: 2.3431622127044016

Epoch: 6| Step: 11
Training loss: 0.4604665322148427
Validation loss: 2.326577918447447

Epoch: 6| Step: 12
Training loss: 0.8266830125725713
Validation loss: 2.294462317344047

Epoch: 6| Step: 13
Training loss: 0.8900561942351347
Validation loss: 2.37139167379674

Epoch: 630| Step: 0
Training loss: 0.7024647898012341
Validation loss: 2.3496396406136553

Epoch: 6| Step: 1
Training loss: 1.528812180609015
Validation loss: 2.3473978019609683

Epoch: 6| Step: 2
Training loss: 0.502381672473418
Validation loss: 2.4046756213519376

Epoch: 6| Step: 3
Training loss: 0.6479631320405351
Validation loss: 2.2933733926657394

Epoch: 6| Step: 4
Training loss: 0.6735113090197199
Validation loss: 2.3530503529436726

Epoch: 6| Step: 5
Training loss: 0.5569725251775377
Validation loss: 2.3386457224450927

Epoch: 6| Step: 6
Training loss: 0.553356561843462
Validation loss: 2.265426440337531

Epoch: 6| Step: 7
Training loss: 0.7416521651389743
Validation loss: 2.3225702249713094

Epoch: 6| Step: 8
Training loss: 0.8060437966367322
Validation loss: 2.3423051292223565

Epoch: 6| Step: 9
Training loss: 0.7021841323968717
Validation loss: 2.367462757337997

Epoch: 6| Step: 10
Training loss: 0.6725916035033067
Validation loss: 2.3052812198433603

Epoch: 6| Step: 11
Training loss: 0.5852342326986872
Validation loss: 2.3240699335059105

Epoch: 6| Step: 12
Training loss: 0.6630940275302692
Validation loss: 2.281460220645806

Epoch: 6| Step: 13
Training loss: 0.5069027013299953
Validation loss: 2.290407746904638

Epoch: 631| Step: 0
Training loss: 1.461300483529884
Validation loss: 2.2610805247935537

Epoch: 6| Step: 1
Training loss: 0.700075189775653
Validation loss: 2.357065190558935

Epoch: 6| Step: 2
Training loss: 0.5703897293265614
Validation loss: 2.3209742727984985

Epoch: 6| Step: 3
Training loss: 0.4824707068312133
Validation loss: 2.3277688264297387

Epoch: 6| Step: 4
Training loss: 0.5662805615108261
Validation loss: 2.2585244293817177

Epoch: 6| Step: 5
Training loss: 0.7667189198461313
Validation loss: 2.291941814927385

Epoch: 6| Step: 6
Training loss: 0.7480022526671408
Validation loss: 2.3679843296409984

Epoch: 6| Step: 7
Training loss: 0.46903102715798495
Validation loss: 2.2610006602043144

Epoch: 6| Step: 8
Training loss: 0.4774163211280361
Validation loss: 2.3351107264729962

Epoch: 6| Step: 9
Training loss: 0.8236671518391017
Validation loss: 2.3485475093637205

Epoch: 6| Step: 10
Training loss: 0.6836015101401053
Validation loss: 2.3340068140374455

Epoch: 6| Step: 11
Training loss: 0.6846786391548018
Validation loss: 2.332476828602406

Epoch: 6| Step: 12
Training loss: 0.45919019264396427
Validation loss: 2.380414589290198

Epoch: 6| Step: 13
Training loss: 0.8702299342550283
Validation loss: 2.3056766935152124

Epoch: 632| Step: 0
Training loss: 0.5242043756142994
Validation loss: 2.3159960344957073

Epoch: 6| Step: 1
Training loss: 0.6485023006554281
Validation loss: 2.2755317915657836

Epoch: 6| Step: 2
Training loss: 0.755344382999277
Validation loss: 2.338620946383377

Epoch: 6| Step: 3
Training loss: 0.6864249971444719
Validation loss: 2.239858559945791

Epoch: 6| Step: 4
Training loss: 0.6356262241903123
Validation loss: 2.2308164760510074

Epoch: 6| Step: 5
Training loss: 0.5306196961514124
Validation loss: 2.2934298611311075

Epoch: 6| Step: 6
Training loss: 1.549129577009411
Validation loss: 2.3162554761163103

Epoch: 6| Step: 7
Training loss: 0.7049341662423045
Validation loss: 2.34786545477551

Epoch: 6| Step: 8
Training loss: 0.7738275796579271
Validation loss: 2.372621905431232

Epoch: 6| Step: 9
Training loss: 0.5229089830094946
Validation loss: 2.3425661943536333

Epoch: 6| Step: 10
Training loss: 0.6392447326049289
Validation loss: 2.327793252139406

Epoch: 6| Step: 11
Training loss: 0.6577241326280083
Validation loss: 2.3410415017508823

Epoch: 6| Step: 12
Training loss: 0.3774369055712827
Validation loss: 2.327992202793516

Epoch: 6| Step: 13
Training loss: 0.6689534207708873
Validation loss: 2.2858067410804157

Epoch: 633| Step: 0
Training loss: 0.5245954033076868
Validation loss: 2.2702455933191326

Epoch: 6| Step: 1
Training loss: 0.6675853409664544
Validation loss: 2.3034817252264

Epoch: 6| Step: 2
Training loss: 0.5696485652372804
Validation loss: 2.346709669720475

Epoch: 6| Step: 3
Training loss: 0.6990766540717861
Validation loss: 2.417761406909742

Epoch: 6| Step: 4
Training loss: 0.567227577075638
Validation loss: 2.296342138465442

Epoch: 6| Step: 5
Training loss: 0.7704335069303007
Validation loss: 2.3426887882543954

Epoch: 6| Step: 6
Training loss: 1.5405356236158236
Validation loss: 2.275468391456695

Epoch: 6| Step: 7
Training loss: 0.6787651644113939
Validation loss: 2.248179208310503

Epoch: 6| Step: 8
Training loss: 0.451169992418201
Validation loss: 2.3239412051888504

Epoch: 6| Step: 9
Training loss: 0.5191374698999426
Validation loss: 2.2960936463420363

Epoch: 6| Step: 10
Training loss: 0.5560850884796544
Validation loss: 2.283615620876775

Epoch: 6| Step: 11
Training loss: 0.6424254725978413
Validation loss: 2.375489324302138

Epoch: 6| Step: 12
Training loss: 0.4871004398997887
Validation loss: 2.334948081717124

Epoch: 6| Step: 13
Training loss: 1.1456413223760404
Validation loss: 2.2730462215726255

Epoch: 634| Step: 0
Training loss: 0.7858601541550382
Validation loss: 2.3474124636293148

Epoch: 6| Step: 1
Training loss: 0.7661001327096266
Validation loss: 2.2926733727406696

Epoch: 6| Step: 2
Training loss: 0.6043701048596557
Validation loss: 2.2758765227020836

Epoch: 6| Step: 3
Training loss: 0.7220359820912731
Validation loss: 2.3634069498983803

Epoch: 6| Step: 4
Training loss: 0.35898461077228894
Validation loss: 2.314294823062919

Epoch: 6| Step: 5
Training loss: 0.8540127002924149
Validation loss: 2.2791225027361843

Epoch: 6| Step: 6
Training loss: 0.6510658997158286
Validation loss: 2.3032591573163597

Epoch: 6| Step: 7
Training loss: 0.7046477465190298
Validation loss: 2.2892771892531987

Epoch: 6| Step: 8
Training loss: 0.5289943154071055
Validation loss: 2.2726560207377218

Epoch: 6| Step: 9
Training loss: 1.4804031236742898
Validation loss: 2.405730600157731

Epoch: 6| Step: 10
Training loss: 0.6177609351042087
Validation loss: 2.21889044782059

Epoch: 6| Step: 11
Training loss: 0.6009010294749417
Validation loss: 2.354052918132942

Epoch: 6| Step: 12
Training loss: 0.7513857199374266
Validation loss: 2.310329491209637

Epoch: 6| Step: 13
Training loss: 0.4560938130163376
Validation loss: 2.317892778520702

Epoch: 635| Step: 0
Training loss: 0.8133156423781378
Validation loss: 2.3691386664031064

Epoch: 6| Step: 1
Training loss: 0.8282412681292024
Validation loss: 2.362957517491629

Epoch: 6| Step: 2
Training loss: 0.7018019626487799
Validation loss: 2.301380168309866

Epoch: 6| Step: 3
Training loss: 1.53577928785726
Validation loss: 2.3704467648669456

Epoch: 6| Step: 4
Training loss: 0.7040425988850173
Validation loss: 2.4187111493212314

Epoch: 6| Step: 5
Training loss: 0.4807226084147819
Validation loss: 2.2647071866169792

Epoch: 6| Step: 6
Training loss: 0.5689506208366629
Validation loss: 2.3278620851493996

Epoch: 6| Step: 7
Training loss: 0.7804947063112568
Validation loss: 2.3380160660666407

Epoch: 6| Step: 8
Training loss: 0.5584906369519851
Validation loss: 2.3570138305058226

Epoch: 6| Step: 9
Training loss: 0.5319594806768227
Validation loss: 2.3411885923013958

Epoch: 6| Step: 10
Training loss: 0.44161013730280985
Validation loss: 2.299112356583727

Epoch: 6| Step: 11
Training loss: 0.5348558905625268
Validation loss: 2.308589022693882

Epoch: 6| Step: 12
Training loss: 0.47333962716140343
Validation loss: 2.2491257152765383

Epoch: 6| Step: 13
Training loss: 0.6440964590538236
Validation loss: 2.3797061861069566

Epoch: 636| Step: 0
Training loss: 0.5390633016386844
Validation loss: 2.3771118852000805

Epoch: 6| Step: 1
Training loss: 0.4633198450232639
Validation loss: 2.2690236343927896

Epoch: 6| Step: 2
Training loss: 0.5403978973291998
Validation loss: 2.281743174854541

Epoch: 6| Step: 3
Training loss: 0.7558838596370451
Validation loss: 2.393884028103239

Epoch: 6| Step: 4
Training loss: 0.5898729531846181
Validation loss: 2.3779993693268295

Epoch: 6| Step: 5
Training loss: 0.5649769078658538
Validation loss: 2.297897390916335

Epoch: 6| Step: 6
Training loss: 0.6602373694064309
Validation loss: 2.3334074960809166

Epoch: 6| Step: 7
Training loss: 0.7705704696184972
Validation loss: 2.3369412717198563

Epoch: 6| Step: 8
Training loss: 0.4577594889131801
Validation loss: 2.435966235274858

Epoch: 6| Step: 9
Training loss: 1.5915389337598185
Validation loss: 2.3986007027245697

Epoch: 6| Step: 10
Training loss: 0.42580350765182884
Validation loss: 2.2950245223590766

Epoch: 6| Step: 11
Training loss: 0.7215403834043319
Validation loss: 2.3531769408859637

Epoch: 6| Step: 12
Training loss: 0.6397162947442459
Validation loss: 2.32511124827152

Epoch: 6| Step: 13
Training loss: 0.48802599529303414
Validation loss: 2.302854325799716

Epoch: 637| Step: 0
Training loss: 0.5812569658825941
Validation loss: 2.22488161638322

Epoch: 6| Step: 1
Training loss: 0.7481173091228598
Validation loss: 2.3019117970651815

Epoch: 6| Step: 2
Training loss: 0.2957993269009634
Validation loss: 2.2429931423506377

Epoch: 6| Step: 3
Training loss: 0.7634372204324504
Validation loss: 2.2799210508897803

Epoch: 6| Step: 4
Training loss: 0.6230707911382569
Validation loss: 2.363518470839033

Epoch: 6| Step: 5
Training loss: 0.8031243261193443
Validation loss: 2.345811783892274

Epoch: 6| Step: 6
Training loss: 0.5526319213378534
Validation loss: 2.3497802098355374

Epoch: 6| Step: 7
Training loss: 0.6352153182862926
Validation loss: 2.40578938169182

Epoch: 6| Step: 8
Training loss: 0.37453875388154634
Validation loss: 2.3156830305868175

Epoch: 6| Step: 9
Training loss: 0.8494123910136211
Validation loss: 2.382787537103592

Epoch: 6| Step: 10
Training loss: 0.402486405498448
Validation loss: 2.303690554243284

Epoch: 6| Step: 11
Training loss: 0.6045112175480439
Validation loss: 2.3659322892490056

Epoch: 6| Step: 12
Training loss: 1.4543010095808555
Validation loss: 2.343605210948995

Epoch: 6| Step: 13
Training loss: 0.719660721022673
Validation loss: 2.4068354957184597

Epoch: 638| Step: 0
Training loss: 0.5487756127047901
Validation loss: 2.3113851844985818

Epoch: 6| Step: 1
Training loss: 0.5521490010008013
Validation loss: 2.2615735517852245

Epoch: 6| Step: 2
Training loss: 0.7021247106371218
Validation loss: 2.34874804308767

Epoch: 6| Step: 3
Training loss: 0.6133402413345466
Validation loss: 2.2791310708824337

Epoch: 6| Step: 4
Training loss: 0.6401138825347832
Validation loss: 2.3782203378265616

Epoch: 6| Step: 5
Training loss: 0.5597886862732862
Validation loss: 2.288723770026873

Epoch: 6| Step: 6
Training loss: 0.5326738070758165
Validation loss: 2.2809559588612536

Epoch: 6| Step: 7
Training loss: 0.6147461907081436
Validation loss: 2.3411782378004657

Epoch: 6| Step: 8
Training loss: 0.47622565575203624
Validation loss: 2.2825449236368454

Epoch: 6| Step: 9
Training loss: 0.47483181548364156
Validation loss: 2.357535497232675

Epoch: 6| Step: 10
Training loss: 0.560447444803289
Validation loss: 2.3857676207615124

Epoch: 6| Step: 11
Training loss: 1.5855189179753777
Validation loss: 2.3372993588876656

Epoch: 6| Step: 12
Training loss: 0.7322558812549591
Validation loss: 2.299004825806412

Epoch: 6| Step: 13
Training loss: 0.3917975945813159
Validation loss: 2.3197323316294165

Epoch: 639| Step: 0
Training loss: 0.5284358266739658
Validation loss: 2.25125135127604

Epoch: 6| Step: 1
Training loss: 0.7333775097010966
Validation loss: 2.3119982236283447

Epoch: 6| Step: 2
Training loss: 0.48913102020353033
Validation loss: 2.322597017224807

Epoch: 6| Step: 3
Training loss: 0.6958010596559202
Validation loss: 2.2835554070471265

Epoch: 6| Step: 4
Training loss: 0.6191930417757866
Validation loss: 2.259295551914572

Epoch: 6| Step: 5
Training loss: 0.9348280659857789
Validation loss: 2.2662128493491225

Epoch: 6| Step: 6
Training loss: 0.4607928420840405
Validation loss: 2.2661279495621165

Epoch: 6| Step: 7
Training loss: 0.6439982204205348
Validation loss: 2.262393935151376

Epoch: 6| Step: 8
Training loss: 0.545016099447038
Validation loss: 2.1871514776666503

Epoch: 6| Step: 9
Training loss: 0.5121168379017982
Validation loss: 2.356215870566732

Epoch: 6| Step: 10
Training loss: 0.8612101986661683
Validation loss: 2.331197388013054

Epoch: 6| Step: 11
Training loss: 0.743723835204404
Validation loss: 2.3031705891799787

Epoch: 6| Step: 12
Training loss: 0.6987319189199225
Validation loss: 2.343507312529068

Epoch: 6| Step: 13
Training loss: 1.8035679106293594
Validation loss: 2.337189849032782

Epoch: 640| Step: 0
Training loss: 0.5870240627292546
Validation loss: 2.2997372258236406

Epoch: 6| Step: 1
Training loss: 0.7068547613415435
Validation loss: 2.3427149411543744

Epoch: 6| Step: 2
Training loss: 0.682524165854013
Validation loss: 2.230085105710407

Epoch: 6| Step: 3
Training loss: 1.6025867443441504
Validation loss: 2.3419605788276785

Epoch: 6| Step: 4
Training loss: 0.6938094921206651
Validation loss: 2.299203823980362

Epoch: 6| Step: 5
Training loss: 0.6073918963820293
Validation loss: 2.381641672526628

Epoch: 6| Step: 6
Training loss: 0.6226522936150845
Validation loss: 2.289899891342046

Epoch: 6| Step: 7
Training loss: 0.5518607254601514
Validation loss: 2.31856276794368

Epoch: 6| Step: 8
Training loss: 0.7237598961398988
Validation loss: 2.305699391364605

Epoch: 6| Step: 9
Training loss: 0.5145008954206262
Validation loss: 2.295504918894284

Epoch: 6| Step: 10
Training loss: 0.6709349954075965
Validation loss: 2.381808194941764

Epoch: 6| Step: 11
Training loss: 0.49553256696636827
Validation loss: 2.324350945510109

Epoch: 6| Step: 12
Training loss: 0.540472039871371
Validation loss: 2.3087523962000964

Epoch: 6| Step: 13
Training loss: 0.6686075513413288
Validation loss: 2.3978028190687017

Epoch: 641| Step: 0
Training loss: 0.4575415313870344
Validation loss: 2.31502413106407

Epoch: 6| Step: 1
Training loss: 0.4150960008048569
Validation loss: 2.3412275526718487

Epoch: 6| Step: 2
Training loss: 0.5872439252491288
Validation loss: 2.37430298145721

Epoch: 6| Step: 3
Training loss: 0.8275384805266275
Validation loss: 2.3220356884198314

Epoch: 6| Step: 4
Training loss: 1.4289784992487842
Validation loss: 2.322747544747859

Epoch: 6| Step: 5
Training loss: 0.7365441448140272
Validation loss: 2.3395363704062544

Epoch: 6| Step: 6
Training loss: 0.5542128775505701
Validation loss: 2.330298892711508

Epoch: 6| Step: 7
Training loss: 0.6959779105682172
Validation loss: 2.300321162246403

Epoch: 6| Step: 8
Training loss: 0.7262241437055005
Validation loss: 2.305629846110917

Epoch: 6| Step: 9
Training loss: 0.7635451111622582
Validation loss: 2.282376624616254

Epoch: 6| Step: 10
Training loss: 0.8046127210518415
Validation loss: 2.2766122721999706

Epoch: 6| Step: 11
Training loss: 0.6657707010116977
Validation loss: 2.3229604542476783

Epoch: 6| Step: 12
Training loss: 0.6519131409924687
Validation loss: 2.3023995343003087

Epoch: 6| Step: 13
Training loss: 0.6288470127806073
Validation loss: 2.3228158923888085

Epoch: 642| Step: 0
Training loss: 0.6908193565062212
Validation loss: 2.333083008231377

Epoch: 6| Step: 1
Training loss: 0.7634570509866104
Validation loss: 2.33015462329655

Epoch: 6| Step: 2
Training loss: 1.4724186470343275
Validation loss: 2.3120292266416005

Epoch: 6| Step: 3
Training loss: 0.500742718289891
Validation loss: 2.3467003238735678

Epoch: 6| Step: 4
Training loss: 0.49664831328670633
Validation loss: 2.348356875304939

Epoch: 6| Step: 5
Training loss: 0.5406033704543248
Validation loss: 2.318800822315396

Epoch: 6| Step: 6
Training loss: 0.8395616989251192
Validation loss: 2.3640119252416056

Epoch: 6| Step: 7
Training loss: 0.6133421120542301
Validation loss: 2.2450476600076628

Epoch: 6| Step: 8
Training loss: 0.7220730464471843
Validation loss: 2.3269531726602177

Epoch: 6| Step: 9
Training loss: 0.575707458570893
Validation loss: 2.3571790986190893

Epoch: 6| Step: 10
Training loss: 0.5006224810552387
Validation loss: 2.307125461582525

Epoch: 6| Step: 11
Training loss: 0.5300131311679306
Validation loss: 2.3885493421939494

Epoch: 6| Step: 12
Training loss: 0.4720461667585141
Validation loss: 2.319677734612612

Epoch: 6| Step: 13
Training loss: 0.7338264526880963
Validation loss: 2.325172806068269

Epoch: 643| Step: 0
Training loss: 0.7441918863577479
Validation loss: 2.338487240570695

Epoch: 6| Step: 1
Training loss: 1.532053444724454
Validation loss: 2.354906250385012

Epoch: 6| Step: 2
Training loss: 0.5166874833938154
Validation loss: 2.345878204166896

Epoch: 6| Step: 3
Training loss: 0.46930696459117105
Validation loss: 2.334021581791804

Epoch: 6| Step: 4
Training loss: 0.657013675849286
Validation loss: 2.3358666786539493

Epoch: 6| Step: 5
Training loss: 0.6939733661163631
Validation loss: 2.260838457108413

Epoch: 6| Step: 6
Training loss: 0.4300158200015249
Validation loss: 2.299529964816061

Epoch: 6| Step: 7
Training loss: 0.49225688626891
Validation loss: 2.2766309300927303

Epoch: 6| Step: 8
Training loss: 0.8453809022992115
Validation loss: 2.336576969028456

Epoch: 6| Step: 9
Training loss: 0.5173242774185918
Validation loss: 2.305331515013087

Epoch: 6| Step: 10
Training loss: 0.8231933506862061
Validation loss: 2.293768466140714

Epoch: 6| Step: 11
Training loss: 0.5490113627850817
Validation loss: 2.3083238238617856

Epoch: 6| Step: 12
Training loss: 0.51498500524376
Validation loss: 2.4049203048965033

Epoch: 6| Step: 13
Training loss: 0.6642941239259764
Validation loss: 2.3270940563385123

Epoch: 644| Step: 0
Training loss: 0.6755544028155561
Validation loss: 2.3261753090963406

Epoch: 6| Step: 1
Training loss: 1.525251433485152
Validation loss: 2.2422754528369846

Epoch: 6| Step: 2
Training loss: 0.6295408044896222
Validation loss: 2.3106327916232745

Epoch: 6| Step: 3
Training loss: 0.5251208609018556
Validation loss: 2.3062955818748456

Epoch: 6| Step: 4
Training loss: 0.9452823917859094
Validation loss: 2.3283850169605063

Epoch: 6| Step: 5
Training loss: 0.7637442630109074
Validation loss: 2.3293480653898073

Epoch: 6| Step: 6
Training loss: 0.5280408419758127
Validation loss: 2.3479914012822833

Epoch: 6| Step: 7
Training loss: 0.7875226547373404
Validation loss: 2.3502282837724393

Epoch: 6| Step: 8
Training loss: 0.540506143679713
Validation loss: 2.300344338663226

Epoch: 6| Step: 9
Training loss: 0.5785917511487486
Validation loss: 2.326619977334796

Epoch: 6| Step: 10
Training loss: 0.5071830369490906
Validation loss: 2.3217315847711624

Epoch: 6| Step: 11
Training loss: 0.5124827207583212
Validation loss: 2.2736218778743127

Epoch: 6| Step: 12
Training loss: 0.8111012596645457
Validation loss: 2.308971090394772

Epoch: 6| Step: 13
Training loss: 0.5080924802839717
Validation loss: 2.35369073135284

Epoch: 645| Step: 0
Training loss: 0.5808358429462759
Validation loss: 2.350550255884501

Epoch: 6| Step: 1
Training loss: 0.6755597848674425
Validation loss: 2.3219413941163825

Epoch: 6| Step: 2
Training loss: 0.5494985049733312
Validation loss: 2.319348641344046

Epoch: 6| Step: 3
Training loss: 0.4504222008520716
Validation loss: 2.3510623163226043

Epoch: 6| Step: 4
Training loss: 0.48429550010706296
Validation loss: 2.3420129126401417

Epoch: 6| Step: 5
Training loss: 0.5955268974411372
Validation loss: 2.3381881908978617

Epoch: 6| Step: 6
Training loss: 0.8936117518813377
Validation loss: 2.3389816705221

Epoch: 6| Step: 7
Training loss: 0.5729253826056352
Validation loss: 2.2696140615828813

Epoch: 6| Step: 8
Training loss: 1.5046767601826203
Validation loss: 2.2653666551600056

Epoch: 6| Step: 9
Training loss: 0.6904304644676056
Validation loss: 2.271290143764661

Epoch: 6| Step: 10
Training loss: 0.8884435339369547
Validation loss: 2.349603196136329

Epoch: 6| Step: 11
Training loss: 0.7297883970764719
Validation loss: 2.2701103363048207

Epoch: 6| Step: 12
Training loss: 0.48543270054587595
Validation loss: 2.3720848465268647

Epoch: 6| Step: 13
Training loss: 0.7554514570337917
Validation loss: 2.3263476521214583

Epoch: 646| Step: 0
Training loss: 0.6402359921130646
Validation loss: 2.4239557373826055

Epoch: 6| Step: 1
Training loss: 0.6323705943418438
Validation loss: 2.37704730669885

Epoch: 6| Step: 2
Training loss: 0.6093660256140669
Validation loss: 2.451490384453055

Epoch: 6| Step: 3
Training loss: 0.6228662306696309
Validation loss: 2.3074137113441164

Epoch: 6| Step: 4
Training loss: 0.4693796379581502
Validation loss: 2.363238016775667

Epoch: 6| Step: 5
Training loss: 0.569234587087537
Validation loss: 2.239188083608984

Epoch: 6| Step: 6
Training loss: 1.5528232764938965
Validation loss: 2.2852748944173

Epoch: 6| Step: 7
Training loss: 0.5815908570834879
Validation loss: 2.255585828408884

Epoch: 6| Step: 8
Training loss: 0.5125093831389635
Validation loss: 2.3797757372763373

Epoch: 6| Step: 9
Training loss: 0.6698319844697974
Validation loss: 2.305434259339938

Epoch: 6| Step: 10
Training loss: 0.6486560958639381
Validation loss: 2.213930128105981

Epoch: 6| Step: 11
Training loss: 0.9042552831325118
Validation loss: 2.313497478977327

Epoch: 6| Step: 12
Training loss: 0.6105034723065955
Validation loss: 2.3017857970441127

Epoch: 6| Step: 13
Training loss: 0.49408168215011156
Validation loss: 2.32161522527001

Epoch: 647| Step: 0
Training loss: 0.7016782074732006
Validation loss: 2.3548372602015815

Epoch: 6| Step: 1
Training loss: 0.8054398658228092
Validation loss: 2.284991559647406

Epoch: 6| Step: 2
Training loss: 0.4910694320439959
Validation loss: 2.331026280083623

Epoch: 6| Step: 3
Training loss: 0.5663738372999594
Validation loss: 2.2089476165392523

Epoch: 6| Step: 4
Training loss: 0.505912689580833
Validation loss: 2.389659568958863

Epoch: 6| Step: 5
Training loss: 0.5324848913010419
Validation loss: 2.3471716195164873

Epoch: 6| Step: 6
Training loss: 1.618973266640031
Validation loss: 2.308324217016636

Epoch: 6| Step: 7
Training loss: 0.6458777033013023
Validation loss: 2.3211465811921315

Epoch: 6| Step: 8
Training loss: 0.352591555589161
Validation loss: 2.28984057104562

Epoch: 6| Step: 9
Training loss: 0.7624888122238119
Validation loss: 2.313882325365371

Epoch: 6| Step: 10
Training loss: 0.5111269550038875
Validation loss: 2.278803165096336

Epoch: 6| Step: 11
Training loss: 0.5942340433789287
Validation loss: 2.277915885957557

Epoch: 6| Step: 12
Training loss: 0.446546284279075
Validation loss: 2.390248623369022

Epoch: 6| Step: 13
Training loss: 0.7313291409044002
Validation loss: 2.37903144437353

Epoch: 648| Step: 0
Training loss: 0.7453027896528449
Validation loss: 2.261960916152116

Epoch: 6| Step: 1
Training loss: 0.5908146629378648
Validation loss: 2.3330456024159894

Epoch: 6| Step: 2
Training loss: 0.4175783990586098
Validation loss: 2.331464926284308

Epoch: 6| Step: 3
Training loss: 1.494905403231862
Validation loss: 2.291362076781468

Epoch: 6| Step: 4
Training loss: 0.5946915088464321
Validation loss: 2.283386960203379

Epoch: 6| Step: 5
Training loss: 0.32158908923130786
Validation loss: 2.2598177011987284

Epoch: 6| Step: 6
Training loss: 0.7224671399916867
Validation loss: 2.367045905639111

Epoch: 6| Step: 7
Training loss: 0.5410299471395111
Validation loss: 2.308968402367358

Epoch: 6| Step: 8
Training loss: 0.5711089804062677
Validation loss: 2.3218343409411566

Epoch: 6| Step: 9
Training loss: 0.5224205785831951
Validation loss: 2.3581347058760174

Epoch: 6| Step: 10
Training loss: 0.8072809444248678
Validation loss: 2.326110561861165

Epoch: 6| Step: 11
Training loss: 0.7155313155640753
Validation loss: 2.3368965814265725

Epoch: 6| Step: 12
Training loss: 0.748811017767838
Validation loss: 2.3073365074190613

Epoch: 6| Step: 13
Training loss: 0.6249345506731451
Validation loss: 2.334186477275981

Epoch: 649| Step: 0
Training loss: 0.5545343268151375
Validation loss: 2.282143322824205

Epoch: 6| Step: 1
Training loss: 0.6946538741827795
Validation loss: 2.250352160833532

Epoch: 6| Step: 2
Training loss: 0.3771803768784321
Validation loss: 2.265001725408041

Epoch: 6| Step: 3
Training loss: 0.47461063086575095
Validation loss: 2.3432548792993773

Epoch: 6| Step: 4
Training loss: 0.5951618424461049
Validation loss: 2.3249600200499327

Epoch: 6| Step: 5
Training loss: 0.5590156615729837
Validation loss: 2.2119698254653124

Epoch: 6| Step: 6
Training loss: 0.5010265897939674
Validation loss: 2.3779468760892857

Epoch: 6| Step: 7
Training loss: 0.7087290070131002
Validation loss: 2.3222770021720964

Epoch: 6| Step: 8
Training loss: 0.45939523691249917
Validation loss: 2.3659218880888946

Epoch: 6| Step: 9
Training loss: 0.569663109186596
Validation loss: 2.380713502500074

Epoch: 6| Step: 10
Training loss: 1.4952626920594154
Validation loss: 2.3322210333775963

Epoch: 6| Step: 11
Training loss: 0.5898112357569577
Validation loss: 2.252297173319537

Epoch: 6| Step: 12
Training loss: 0.7846615879485428
Validation loss: 2.3295761302193134

Epoch: 6| Step: 13
Training loss: 0.5743544800904512
Validation loss: 2.3000918239402846

Epoch: 650| Step: 0
Training loss: 0.6023791331228365
Validation loss: 2.328179587218187

Epoch: 6| Step: 1
Training loss: 0.6187612532546016
Validation loss: 2.312083803575553

Epoch: 6| Step: 2
Training loss: 0.6033987036965152
Validation loss: 2.3083020536403858

Epoch: 6| Step: 3
Training loss: 1.4731411325366826
Validation loss: 2.280486379556105

Epoch: 6| Step: 4
Training loss: 0.8384455552711221
Validation loss: 2.27830879121272

Epoch: 6| Step: 5
Training loss: 0.5684263314465374
Validation loss: 2.277492169596278

Epoch: 6| Step: 6
Training loss: 0.6081870800295583
Validation loss: 2.3711441758274128

Epoch: 6| Step: 7
Training loss: 0.4543707921123201
Validation loss: 2.3388132799579386

Epoch: 6| Step: 8
Training loss: 0.5023432896257489
Validation loss: 2.2716461398576406

Epoch: 6| Step: 9
Training loss: 0.5935397779845956
Validation loss: 2.3100071574187555

Epoch: 6| Step: 10
Training loss: 0.5926427304299554
Validation loss: 2.3088497571478213

Epoch: 6| Step: 11
Training loss: 0.8159844435910634
Validation loss: 2.3207388097775388

Epoch: 6| Step: 12
Training loss: 0.6309270910998165
Validation loss: 2.3479596868174935

Epoch: 6| Step: 13
Training loss: 0.7650750968574797
Validation loss: 2.2976807339127268

Epoch: 651| Step: 0
Training loss: 0.5489307728411329
Validation loss: 2.3390090431122355

Epoch: 6| Step: 1
Training loss: 0.6181450670647323
Validation loss: 2.358534512935597

Epoch: 6| Step: 2
Training loss: 0.7371388634148955
Validation loss: 2.3587533264477543

Epoch: 6| Step: 3
Training loss: 0.4678539931473118
Validation loss: 2.339224905326144

Epoch: 6| Step: 4
Training loss: 0.760692433210309
Validation loss: 2.315050120869253

Epoch: 6| Step: 5
Training loss: 0.5624533474967282
Validation loss: 2.3327274224327494

Epoch: 6| Step: 6
Training loss: 0.5545553667892389
Validation loss: 2.3200294794629084

Epoch: 6| Step: 7
Training loss: 0.48564774439117153
Validation loss: 2.3603407071826576

Epoch: 6| Step: 8
Training loss: 0.6075701271993439
Validation loss: 2.2595263045527427

Epoch: 6| Step: 9
Training loss: 0.6714026986734644
Validation loss: 2.307289359273201

Epoch: 6| Step: 10
Training loss: 0.43893665057695846
Validation loss: 2.3082018082395184

Epoch: 6| Step: 11
Training loss: 1.5604383218414506
Validation loss: 2.2898853713873693

Epoch: 6| Step: 12
Training loss: 0.6634459831281211
Validation loss: 2.346452624062028

Epoch: 6| Step: 13
Training loss: 0.6853307834452878
Validation loss: 2.3103052412246097

Epoch: 652| Step: 0
Training loss: 0.6579258728188538
Validation loss: 2.35152859387919

Epoch: 6| Step: 1
Training loss: 0.7437812157499447
Validation loss: 2.33547282867714

Epoch: 6| Step: 2
Training loss: 0.49631857095581056
Validation loss: 2.373436518413358

Epoch: 6| Step: 3
Training loss: 0.615529017058054
Validation loss: 2.2798350518883495

Epoch: 6| Step: 4
Training loss: 0.7083334128061886
Validation loss: 2.320969608263691

Epoch: 6| Step: 5
Training loss: 0.7608934675632376
Validation loss: 2.4073390816000924

Epoch: 6| Step: 6
Training loss: 0.5251980680405469
Validation loss: 2.2771822165127165

Epoch: 6| Step: 7
Training loss: 0.6962246644360313
Validation loss: 2.294533006636267

Epoch: 6| Step: 8
Training loss: 0.5612977743737064
Validation loss: 2.40816974915336

Epoch: 6| Step: 9
Training loss: 0.6289717361759128
Validation loss: 2.364031696758031

Epoch: 6| Step: 10
Training loss: 1.4967253225906816
Validation loss: 2.3570721634147853

Epoch: 6| Step: 11
Training loss: 0.6066292255065008
Validation loss: 2.253105630609754

Epoch: 6| Step: 12
Training loss: 0.48957809655114526
Validation loss: 2.2882396732886474

Epoch: 6| Step: 13
Training loss: 0.724656589337386
Validation loss: 2.358751263581748

Epoch: 653| Step: 0
Training loss: 0.6237985507210753
Validation loss: 2.2556600988997006

Epoch: 6| Step: 1
Training loss: 0.8959869467452891
Validation loss: 2.3349751261002214

Epoch: 6| Step: 2
Training loss: 0.6116940314315559
Validation loss: 2.3007686344508897

Epoch: 6| Step: 3
Training loss: 1.3920697197718979
Validation loss: 2.317284614975673

Epoch: 6| Step: 4
Training loss: 0.5364893993777359
Validation loss: 2.2348210321067468

Epoch: 6| Step: 5
Training loss: 0.62213139256586
Validation loss: 2.3029109973344495

Epoch: 6| Step: 6
Training loss: 0.4917109316630689
Validation loss: 2.320855354609193

Epoch: 6| Step: 7
Training loss: 0.6091365836874064
Validation loss: 2.403813117268034

Epoch: 6| Step: 8
Training loss: 0.6159162829502902
Validation loss: 2.2969602583385567

Epoch: 6| Step: 9
Training loss: 0.6619139526403116
Validation loss: 2.3053619704863495

Epoch: 6| Step: 10
Training loss: 0.46203134350329045
Validation loss: 2.3334362639813095

Epoch: 6| Step: 11
Training loss: 0.7958221960703149
Validation loss: 2.3577219406635135

Epoch: 6| Step: 12
Training loss: 0.7224944887314044
Validation loss: 2.317208216209217

Epoch: 6| Step: 13
Training loss: 0.5794843981109737
Validation loss: 2.234521975890517

Epoch: 654| Step: 0
Training loss: 0.5833760541077141
Validation loss: 2.2479675666140193

Epoch: 6| Step: 1
Training loss: 0.46006663539516746
Validation loss: 2.291054623967093

Epoch: 6| Step: 2
Training loss: 1.522954306635257
Validation loss: 2.2849894526289742

Epoch: 6| Step: 3
Training loss: 0.4130469409761472
Validation loss: 2.31293754573341

Epoch: 6| Step: 4
Training loss: 0.4427820219159322
Validation loss: 2.2537766576081344

Epoch: 6| Step: 5
Training loss: 0.615664086819572
Validation loss: 2.32180908460232

Epoch: 6| Step: 6
Training loss: 0.43106489493517947
Validation loss: 2.2915483155178515

Epoch: 6| Step: 7
Training loss: 0.6752961021455459
Validation loss: 2.3162054192614336

Epoch: 6| Step: 8
Training loss: 0.7518169329283675
Validation loss: 2.306495224786845

Epoch: 6| Step: 9
Training loss: 0.531377468524261
Validation loss: 2.2895556749520813

Epoch: 6| Step: 10
Training loss: 0.5761566677349588
Validation loss: 2.350505056503444

Epoch: 6| Step: 11
Training loss: 0.659481900485196
Validation loss: 2.309224668004636

Epoch: 6| Step: 12
Training loss: 0.5208420244127567
Validation loss: 2.2825327576421777

Epoch: 6| Step: 13
Training loss: 0.35849608876210926
Validation loss: 2.272439800681524

Epoch: 655| Step: 0
Training loss: 0.47492032010199936
Validation loss: 2.339954145790513

Epoch: 6| Step: 1
Training loss: 0.5379510561614559
Validation loss: 2.286866697736843

Epoch: 6| Step: 2
Training loss: 0.9960965025620669
Validation loss: 2.300068095484559

Epoch: 6| Step: 3
Training loss: 0.6105752519784537
Validation loss: 2.321682724804372

Epoch: 6| Step: 4
Training loss: 0.6546757981522335
Validation loss: 2.379931405081047

Epoch: 6| Step: 5
Training loss: 0.5304707815049926
Validation loss: 2.2856327014193396

Epoch: 6| Step: 6
Training loss: 0.5145585852114629
Validation loss: 2.3250187602164534

Epoch: 6| Step: 7
Training loss: 1.4012162290071595
Validation loss: 2.352366573702416

Epoch: 6| Step: 8
Training loss: 0.6108922409893689
Validation loss: 2.2785614629967617

Epoch: 6| Step: 9
Training loss: 0.42195135767763825
Validation loss: 2.3214087050105205

Epoch: 6| Step: 10
Training loss: 0.6602828903167035
Validation loss: 2.303002567387236

Epoch: 6| Step: 11
Training loss: 0.456530810515538
Validation loss: 2.3567544941439733

Epoch: 6| Step: 12
Training loss: 0.5749698838349707
Validation loss: 2.2839417926897627

Epoch: 6| Step: 13
Training loss: 0.6305787256463281
Validation loss: 2.3093846762459984

Epoch: 656| Step: 0
Training loss: 0.5289357772992016
Validation loss: 2.3292431917867162

Epoch: 6| Step: 1
Training loss: 0.6994560947054783
Validation loss: 2.244815989786222

Epoch: 6| Step: 2
Training loss: 0.6665184606283484
Validation loss: 2.247278734443

Epoch: 6| Step: 3
Training loss: 0.7004578336349677
Validation loss: 2.44890370695992

Epoch: 6| Step: 4
Training loss: 0.4620818464474824
Validation loss: 2.3779876075959967

Epoch: 6| Step: 5
Training loss: 1.4613349088436414
Validation loss: 2.3185269484346924

Epoch: 6| Step: 6
Training loss: 0.7183441591959058
Validation loss: 2.3315743798419284

Epoch: 6| Step: 7
Training loss: 0.5347545257597986
Validation loss: 2.2837036699108637

Epoch: 6| Step: 8
Training loss: 0.4476447019036188
Validation loss: 2.3248806415026406

Epoch: 6| Step: 9
Training loss: 0.6527967193799822
Validation loss: 2.275985788799064

Epoch: 6| Step: 10
Training loss: 0.45053169112452807
Validation loss: 2.335241533643294

Epoch: 6| Step: 11
Training loss: 0.7349880176008624
Validation loss: 2.3254325534015288

Epoch: 6| Step: 12
Training loss: 0.5487410180957825
Validation loss: 2.3275703561779792

Epoch: 6| Step: 13
Training loss: 0.6184432858991096
Validation loss: 2.2840627601525547

Epoch: 657| Step: 0
Training loss: 0.609432071067361
Validation loss: 2.2838013965692765

Epoch: 6| Step: 1
Training loss: 0.3810836718400867
Validation loss: 2.2907668852203944

Epoch: 6| Step: 2
Training loss: 0.5529821265231167
Validation loss: 2.305354456461122

Epoch: 6| Step: 3
Training loss: 0.6760418119464673
Validation loss: 2.31079549532495

Epoch: 6| Step: 4
Training loss: 0.6441889923424837
Validation loss: 2.3168330799268837

Epoch: 6| Step: 5
Training loss: 0.6978644356232896
Validation loss: 2.2583793561281365

Epoch: 6| Step: 6
Training loss: 1.5378706911639513
Validation loss: 2.31538683519392

Epoch: 6| Step: 7
Training loss: 0.7431218740591614
Validation loss: 2.321606093115154

Epoch: 6| Step: 8
Training loss: 0.5559222220025702
Validation loss: 2.3142466047845165

Epoch: 6| Step: 9
Training loss: 0.4420197873131106
Validation loss: 2.326512286001634

Epoch: 6| Step: 10
Training loss: 0.4084010214885767
Validation loss: 2.287686403138015

Epoch: 6| Step: 11
Training loss: 0.720609746740122
Validation loss: 2.3142684542318017

Epoch: 6| Step: 12
Training loss: 0.4531870667930703
Validation loss: 2.249567729234549

Epoch: 6| Step: 13
Training loss: 0.36441200408697677
Validation loss: 2.2881532934122712

Epoch: 658| Step: 0
Training loss: 0.747126558467828
Validation loss: 2.3233046797826593

Epoch: 6| Step: 1
Training loss: 0.5490869746563878
Validation loss: 2.409942283991101

Epoch: 6| Step: 2
Training loss: 0.6730817116053511
Validation loss: 2.315347627124754

Epoch: 6| Step: 3
Training loss: 0.6869569714604565
Validation loss: 2.2525604268458665

Epoch: 6| Step: 4
Training loss: 0.5527504962416845
Validation loss: 2.2839693422606273

Epoch: 6| Step: 5
Training loss: 0.6390663818390708
Validation loss: 2.3083804841151685

Epoch: 6| Step: 6
Training loss: 0.44475942698840015
Validation loss: 2.4143622496652952

Epoch: 6| Step: 7
Training loss: 0.6763863472974556
Validation loss: 2.305212281417159

Epoch: 6| Step: 8
Training loss: 0.546421544223945
Validation loss: 2.3687812840989584

Epoch: 6| Step: 9
Training loss: 0.6033651417396517
Validation loss: 2.2613870233395743

Epoch: 6| Step: 10
Training loss: 0.49090946115012607
Validation loss: 2.351190294108009

Epoch: 6| Step: 11
Training loss: 0.563967089627901
Validation loss: 2.3059706677973875

Epoch: 6| Step: 12
Training loss: 1.4403826793176937
Validation loss: 2.3079855537137317

Epoch: 6| Step: 13
Training loss: 0.5156669888595055
Validation loss: 2.2941317432612185

Epoch: 659| Step: 0
Training loss: 0.5228991230710545
Validation loss: 2.303968719249853

Epoch: 6| Step: 1
Training loss: 0.5509506938910224
Validation loss: 2.358815048020528

Epoch: 6| Step: 2
Training loss: 0.5135105010113185
Validation loss: 2.4112700616063045

Epoch: 6| Step: 3
Training loss: 0.7029606945070618
Validation loss: 2.3470331998850673

Epoch: 6| Step: 4
Training loss: 0.707805188880197
Validation loss: 2.306010892157939

Epoch: 6| Step: 5
Training loss: 0.5156896724024087
Validation loss: 2.3615936635105244

Epoch: 6| Step: 6
Training loss: 1.426933345662816
Validation loss: 2.323275894015493

Epoch: 6| Step: 7
Training loss: 0.7805505673402597
Validation loss: 2.340383714667251

Epoch: 6| Step: 8
Training loss: 0.5951872796552259
Validation loss: 2.3085588796432877

Epoch: 6| Step: 9
Training loss: 0.5966865301910476
Validation loss: 2.256522764238624

Epoch: 6| Step: 10
Training loss: 0.6588805473584787
Validation loss: 2.3210464664077004

Epoch: 6| Step: 11
Training loss: 0.714479155402585
Validation loss: 2.29661949064196

Epoch: 6| Step: 12
Training loss: 0.8442293147884532
Validation loss: 2.3230712666644395

Epoch: 6| Step: 13
Training loss: 0.44064227807548645
Validation loss: 2.398309347546181

Epoch: 660| Step: 0
Training loss: 0.6332679334135016
Validation loss: 2.3335518335474608

Epoch: 6| Step: 1
Training loss: 0.7165422117120255
Validation loss: 2.276613885867688

Epoch: 6| Step: 2
Training loss: 0.54412871578463
Validation loss: 2.368926344897999

Epoch: 6| Step: 3
Training loss: 0.4377764781915402
Validation loss: 2.3347957052699426

Epoch: 6| Step: 4
Training loss: 0.558518091159786
Validation loss: 2.345405570328293

Epoch: 6| Step: 5
Training loss: 0.622919649629457
Validation loss: 2.286629857186445

Epoch: 6| Step: 6
Training loss: 0.5006407565948351
Validation loss: 2.3306257459516844

Epoch: 6| Step: 7
Training loss: 0.6915068903377702
Validation loss: 2.3249512913762396

Epoch: 6| Step: 8
Training loss: 0.45392752973407624
Validation loss: 2.3744892981006602

Epoch: 6| Step: 9
Training loss: 0.5632760205072402
Validation loss: 2.334229671428996

Epoch: 6| Step: 10
Training loss: 0.7415354625147071
Validation loss: 2.2524107821167876

Epoch: 6| Step: 11
Training loss: 0.36617492498711024
Validation loss: 2.307746143747754

Epoch: 6| Step: 12
Training loss: 1.4618193061204034
Validation loss: 2.3309259550322383

Epoch: 6| Step: 13
Training loss: 0.851497612677121
Validation loss: 2.3584988211361346

Epoch: 661| Step: 0
Training loss: 0.8274376373763452
Validation loss: 2.3218092182052548

Epoch: 6| Step: 1
Training loss: 0.6937502981305556
Validation loss: 2.346157197958023

Epoch: 6| Step: 2
Training loss: 1.3854394733970576
Validation loss: 2.335334245855429

Epoch: 6| Step: 3
Training loss: 0.5627624905918877
Validation loss: 2.248998203600621

Epoch: 6| Step: 4
Training loss: 0.6141380593596032
Validation loss: 2.315022690899521

Epoch: 6| Step: 5
Training loss: 0.6337421558579368
Validation loss: 2.288355595719295

Epoch: 6| Step: 6
Training loss: 0.589097997875823
Validation loss: 2.2898658513941967

Epoch: 6| Step: 7
Training loss: 0.5794474451723524
Validation loss: 2.360818292298198

Epoch: 6| Step: 8
Training loss: 0.5929457588412759
Validation loss: 2.2834247287284914

Epoch: 6| Step: 9
Training loss: 0.3511688147423188
Validation loss: 2.290156358047951

Epoch: 6| Step: 10
Training loss: 0.5188744200443858
Validation loss: 2.2813010311894737

Epoch: 6| Step: 11
Training loss: 0.46433075880216435
Validation loss: 2.2961507434855375

Epoch: 6| Step: 12
Training loss: 0.41960977000670874
Validation loss: 2.3209776869713608

Epoch: 6| Step: 13
Training loss: 0.46199867167219955
Validation loss: 2.3748606045611833

Epoch: 662| Step: 0
Training loss: 0.4089065404824612
Validation loss: 2.3562781835690574

Epoch: 6| Step: 1
Training loss: 0.5221757627454491
Validation loss: 2.279947088336804

Epoch: 6| Step: 2
Training loss: 0.5240144823398969
Validation loss: 2.335303964998682

Epoch: 6| Step: 3
Training loss: 0.4434384850994456
Validation loss: 2.33124934872247

Epoch: 6| Step: 4
Training loss: 0.5146068577916959
Validation loss: 2.3438435427138855

Epoch: 6| Step: 5
Training loss: 1.3591135584787233
Validation loss: 2.3241183803798786

Epoch: 6| Step: 6
Training loss: 0.8230666655635581
Validation loss: 2.2673547893084423

Epoch: 6| Step: 7
Training loss: 0.6785520298952831
Validation loss: 2.30139699124069

Epoch: 6| Step: 8
Training loss: 0.7214294743161305
Validation loss: 2.241451536389976

Epoch: 6| Step: 9
Training loss: 0.6433362112409166
Validation loss: 2.3299825508608234

Epoch: 6| Step: 10
Training loss: 0.6727172983359185
Validation loss: 2.3790666470997746

Epoch: 6| Step: 11
Training loss: 0.6260500669841428
Validation loss: 2.3384968626148845

Epoch: 6| Step: 12
Training loss: 0.7139452931979697
Validation loss: 2.32650648160766

Epoch: 6| Step: 13
Training loss: 0.39540618721139853
Validation loss: 2.2845717292643806

Epoch: 663| Step: 0
Training loss: 0.9049007961528951
Validation loss: 2.3307059154816168

Epoch: 6| Step: 1
Training loss: 0.7074563450369618
Validation loss: 2.3197190057524817

Epoch: 6| Step: 2
Training loss: 0.6682116864228052
Validation loss: 2.298367380799935

Epoch: 6| Step: 3
Training loss: 0.6451696759686476
Validation loss: 2.2747970700484763

Epoch: 6| Step: 4
Training loss: 0.5751395595194216
Validation loss: 2.2971062330709238

Epoch: 6| Step: 5
Training loss: 1.4489917011747315
Validation loss: 2.289345638889575

Epoch: 6| Step: 6
Training loss: 0.42600296967102624
Validation loss: 2.2803424991718377

Epoch: 6| Step: 7
Training loss: 0.5735133502906261
Validation loss: 2.2962791323456795

Epoch: 6| Step: 8
Training loss: 0.7597955928276032
Validation loss: 2.363035432537828

Epoch: 6| Step: 9
Training loss: 0.6837834776122098
Validation loss: 2.2761987954949947

Epoch: 6| Step: 10
Training loss: 0.5466089964119655
Validation loss: 2.3486291547266718

Epoch: 6| Step: 11
Training loss: 0.511385627235198
Validation loss: 2.376870424297725

Epoch: 6| Step: 12
Training loss: 0.5560743697568429
Validation loss: 2.3058644382822386

Epoch: 6| Step: 13
Training loss: 0.5611815365364963
Validation loss: 2.3986184186655257

Epoch: 664| Step: 0
Training loss: 0.552155882788902
Validation loss: 2.4153097963047006

Epoch: 6| Step: 1
Training loss: 0.6830966340830484
Validation loss: 2.33631456858604

Epoch: 6| Step: 2
Training loss: 0.5777287800835859
Validation loss: 2.297998315081332

Epoch: 6| Step: 3
Training loss: 0.583389080880594
Validation loss: 2.3494856822507275

Epoch: 6| Step: 4
Training loss: 0.4285317570058755
Validation loss: 2.3168579799922853

Epoch: 6| Step: 5
Training loss: 1.5436853989895307
Validation loss: 2.339292808531172

Epoch: 6| Step: 6
Training loss: 0.5648627988945742
Validation loss: 2.2827896381939348

Epoch: 6| Step: 7
Training loss: 0.6235643826582722
Validation loss: 2.3369556644057017

Epoch: 6| Step: 8
Training loss: 0.6407448493685016
Validation loss: 2.3388062784246353

Epoch: 6| Step: 9
Training loss: 0.740205628332608
Validation loss: 2.340284796918953

Epoch: 6| Step: 10
Training loss: 0.5630310783430431
Validation loss: 2.294253514347763

Epoch: 6| Step: 11
Training loss: 0.6856685649971962
Validation loss: 2.343778078191326

Epoch: 6| Step: 12
Training loss: 0.5725723850515821
Validation loss: 2.3102718733950476

Epoch: 6| Step: 13
Training loss: 0.40386545502822097
Validation loss: 2.336595185950872

Epoch: 665| Step: 0
Training loss: 0.6447255621956939
Validation loss: 2.301308004985254

Epoch: 6| Step: 1
Training loss: 0.7734433183547526
Validation loss: 2.286982778877958

Epoch: 6| Step: 2
Training loss: 0.4895607473019886
Validation loss: 2.2882286175993327

Epoch: 6| Step: 3
Training loss: 0.5574689624682687
Validation loss: 2.278598160533612

Epoch: 6| Step: 4
Training loss: 0.4739362236427326
Validation loss: 2.3569390947948397

Epoch: 6| Step: 5
Training loss: 0.7212705781800905
Validation loss: 2.379047741916909

Epoch: 6| Step: 6
Training loss: 0.6533518556925968
Validation loss: 2.3560691480117884

Epoch: 6| Step: 7
Training loss: 0.46881753117168373
Validation loss: 2.3833726676031683

Epoch: 6| Step: 8
Training loss: 0.603274275535138
Validation loss: 2.399200586350182

Epoch: 6| Step: 9
Training loss: 0.9032472653108699
Validation loss: 2.3461783410174077

Epoch: 6| Step: 10
Training loss: 1.4201052204960989
Validation loss: 2.3379968832236573

Epoch: 6| Step: 11
Training loss: 0.39494517301967824
Validation loss: 2.36575437966204

Epoch: 6| Step: 12
Training loss: 0.5202320219927059
Validation loss: 2.2911955180378647

Epoch: 6| Step: 13
Training loss: 0.4987792072492118
Validation loss: 2.292626520729546

Epoch: 666| Step: 0
Training loss: 0.4959837874245108
Validation loss: 2.25942789966484

Epoch: 6| Step: 1
Training loss: 0.5513709948871433
Validation loss: 2.2888363032730754

Epoch: 6| Step: 2
Training loss: 0.8597883790821187
Validation loss: 2.284670472729143

Epoch: 6| Step: 3
Training loss: 0.768035403024245
Validation loss: 2.2742840236381525

Epoch: 6| Step: 4
Training loss: 1.548846597068283
Validation loss: 2.32550315343571

Epoch: 6| Step: 5
Training loss: 0.39648373608467224
Validation loss: 2.2798787343440634

Epoch: 6| Step: 6
Training loss: 0.5218062818135937
Validation loss: 2.274694971944759

Epoch: 6| Step: 7
Training loss: 0.43557887964737146
Validation loss: 2.3581703836181394

Epoch: 6| Step: 8
Training loss: 0.4809670849054312
Validation loss: 2.4017878639852395

Epoch: 6| Step: 9
Training loss: 0.5314565144977178
Validation loss: 2.392369888683035

Epoch: 6| Step: 10
Training loss: 0.5604159105808684
Validation loss: 2.339698205874012

Epoch: 6| Step: 11
Training loss: 0.46264403652056907
Validation loss: 2.3375188671563847

Epoch: 6| Step: 12
Training loss: 0.7331845394455536
Validation loss: 2.309994757060846

Epoch: 6| Step: 13
Training loss: 0.5775414176224649
Validation loss: 2.250262460474936

Epoch: 667| Step: 0
Training loss: 0.5594134418768324
Validation loss: 2.3080456511309406

Epoch: 6| Step: 1
Training loss: 0.6220633657597554
Validation loss: 2.297692266290885

Epoch: 6| Step: 2
Training loss: 0.6363791747951897
Validation loss: 2.4096204827962313

Epoch: 6| Step: 3
Training loss: 0.5813455574898728
Validation loss: 2.241971403014992

Epoch: 6| Step: 4
Training loss: 0.5933430431496568
Validation loss: 2.2558142080208103

Epoch: 6| Step: 5
Training loss: 1.4279257336920368
Validation loss: 2.3496013652779655

Epoch: 6| Step: 6
Training loss: 0.4633376140305258
Validation loss: 2.2835515170507024

Epoch: 6| Step: 7
Training loss: 0.5286508256147211
Validation loss: 2.259203657991417

Epoch: 6| Step: 8
Training loss: 0.6651487778111086
Validation loss: 2.2715120231779706

Epoch: 6| Step: 9
Training loss: 0.3192495760082157
Validation loss: 2.314873649788334

Epoch: 6| Step: 10
Training loss: 0.5711046491801396
Validation loss: 2.3615349744023915

Epoch: 6| Step: 11
Training loss: 0.503134617210072
Validation loss: 2.362195023417309

Epoch: 6| Step: 12
Training loss: 0.6816307001566366
Validation loss: 2.3603594846941816

Epoch: 6| Step: 13
Training loss: 0.7768061710351212
Validation loss: 2.2362652553546845

Epoch: 668| Step: 0
Training loss: 0.5096727191552365
Validation loss: 2.2985042708744876

Epoch: 6| Step: 1
Training loss: 0.47975925070474645
Validation loss: 2.2638511902027627

Epoch: 6| Step: 2
Training loss: 0.6999750149900066
Validation loss: 2.337641636376934

Epoch: 6| Step: 3
Training loss: 0.6205246675415673
Validation loss: 2.3256076522363425

Epoch: 6| Step: 4
Training loss: 0.7383577821815496
Validation loss: 2.279032366664177

Epoch: 6| Step: 5
Training loss: 0.6466596198763123
Validation loss: 2.431624934035517

Epoch: 6| Step: 6
Training loss: 0.6036389172486685
Validation loss: 2.3344341591422824

Epoch: 6| Step: 7
Training loss: 0.7601115167516932
Validation loss: 2.338743009920246

Epoch: 6| Step: 8
Training loss: 1.4640789018850127
Validation loss: 2.35704512893614

Epoch: 6| Step: 9
Training loss: 0.5743926427246477
Validation loss: 2.3023205899689745

Epoch: 6| Step: 10
Training loss: 0.6441869104896573
Validation loss: 2.3190488811023675

Epoch: 6| Step: 11
Training loss: 0.525402990713273
Validation loss: 2.3104731694031844

Epoch: 6| Step: 12
Training loss: 0.36692169389451007
Validation loss: 2.322265777343639

Epoch: 6| Step: 13
Training loss: 0.5798240901705176
Validation loss: 2.314215106943312

Epoch: 669| Step: 0
Training loss: 0.30942658418183755
Validation loss: 2.332356899801807

Epoch: 6| Step: 1
Training loss: 0.427017970627163
Validation loss: 2.278894529679139

Epoch: 6| Step: 2
Training loss: 1.490585745688464
Validation loss: 2.3571117346064314

Epoch: 6| Step: 3
Training loss: 0.23154493996349437
Validation loss: 2.271891095165825

Epoch: 6| Step: 4
Training loss: 0.596727584689561
Validation loss: 2.3139283653154594

Epoch: 6| Step: 5
Training loss: 0.5449900430679703
Validation loss: 2.3364634489527254

Epoch: 6| Step: 6
Training loss: 0.6647616128355481
Validation loss: 2.3535203873331665

Epoch: 6| Step: 7
Training loss: 0.781440482759889
Validation loss: 2.3059616774135927

Epoch: 6| Step: 8
Training loss: 0.7320201535030183
Validation loss: 2.3358034254637055

Epoch: 6| Step: 9
Training loss: 0.4669958831628113
Validation loss: 2.358741468204186

Epoch: 6| Step: 10
Training loss: 0.6843832198394024
Validation loss: 2.319684678391812

Epoch: 6| Step: 11
Training loss: 0.42609019838593826
Validation loss: 2.2384198561828605

Epoch: 6| Step: 12
Training loss: 0.6599759414290433
Validation loss: 2.2956763761822767

Epoch: 6| Step: 13
Training loss: 0.5518523818810488
Validation loss: 2.3464218759402082

Epoch: 670| Step: 0
Training loss: 0.5921559770794756
Validation loss: 2.305468083877977

Epoch: 6| Step: 1
Training loss: 0.6507481002149721
Validation loss: 2.3230618362023474

Epoch: 6| Step: 2
Training loss: 0.672781045039327
Validation loss: 2.264490482684794

Epoch: 6| Step: 3
Training loss: 0.6102846643025278
Validation loss: 2.36034192962346

Epoch: 6| Step: 4
Training loss: 0.6007325032353589
Validation loss: 2.353205407731555

Epoch: 6| Step: 5
Training loss: 0.4630904591249919
Validation loss: 2.3463239092978796

Epoch: 6| Step: 6
Training loss: 0.4713477947443714
Validation loss: 2.3633289418789425

Epoch: 6| Step: 7
Training loss: 0.4845324844792401
Validation loss: 2.340552784159071

Epoch: 6| Step: 8
Training loss: 0.5045099117224097
Validation loss: 2.2991007995495205

Epoch: 6| Step: 9
Training loss: 0.6763671804500252
Validation loss: 2.3408383912624506

Epoch: 6| Step: 10
Training loss: 0.45340936879783766
Validation loss: 2.3437179552300837

Epoch: 6| Step: 11
Training loss: 0.6703747478116892
Validation loss: 2.3185213534868847

Epoch: 6| Step: 12
Training loss: 1.44237950659743
Validation loss: 2.2343262743769685

Epoch: 6| Step: 13
Training loss: 0.778090535208754
Validation loss: 2.2983459825190047

Epoch: 671| Step: 0
Training loss: 0.45350052630174204
Validation loss: 2.3442644398288253

Epoch: 6| Step: 1
Training loss: 0.44020160935600383
Validation loss: 2.3281982183522416

Epoch: 6| Step: 2
Training loss: 0.601955236076005
Validation loss: 2.3390599611525187

Epoch: 6| Step: 3
Training loss: 0.5130832330801632
Validation loss: 2.3078174814597645

Epoch: 6| Step: 4
Training loss: 0.470706702254382
Validation loss: 2.2945952741568747

Epoch: 6| Step: 5
Training loss: 1.4737831883337555
Validation loss: 2.337462051712657

Epoch: 6| Step: 6
Training loss: 0.5091879776315262
Validation loss: 2.283565343628401

Epoch: 6| Step: 7
Training loss: 0.5796318521034975
Validation loss: 2.2717278333069144

Epoch: 6| Step: 8
Training loss: 0.8496033766962288
Validation loss: 2.302110158370242

Epoch: 6| Step: 9
Training loss: 0.5699642372205768
Validation loss: 2.3356073321573185

Epoch: 6| Step: 10
Training loss: 0.5817262759401947
Validation loss: 2.2924517997231515

Epoch: 6| Step: 11
Training loss: 0.624145830118151
Validation loss: 2.3182042593150647

Epoch: 6| Step: 12
Training loss: 0.42361223198094455
Validation loss: 2.2911814812740725

Epoch: 6| Step: 13
Training loss: 0.49817887595200316
Validation loss: 2.303000553656117

Epoch: 672| Step: 0
Training loss: 0.39160316067414686
Validation loss: 2.3532766343449327

Epoch: 6| Step: 1
Training loss: 0.7566069225708518
Validation loss: 2.3755558801181618

Epoch: 6| Step: 2
Training loss: 0.5670564799662465
Validation loss: 2.3253339339975962

Epoch: 6| Step: 3
Training loss: 0.6599807505979403
Validation loss: 2.3617882999062543

Epoch: 6| Step: 4
Training loss: 0.6226983126764332
Validation loss: 2.3485872640289065

Epoch: 6| Step: 5
Training loss: 0.4821821999644876
Validation loss: 2.305889415656288

Epoch: 6| Step: 6
Training loss: 0.6427425649502989
Validation loss: 2.297716173253071

Epoch: 6| Step: 7
Training loss: 0.493156070455624
Validation loss: 2.246652272938038

Epoch: 6| Step: 8
Training loss: 0.48252583360445334
Validation loss: 2.318818356890318

Epoch: 6| Step: 9
Training loss: 0.37951487396328004
Validation loss: 2.2653380543599377

Epoch: 6| Step: 10
Training loss: 0.6106583213499673
Validation loss: 2.3245055683072744

Epoch: 6| Step: 11
Training loss: 0.59550622906698
Validation loss: 2.305173731049034

Epoch: 6| Step: 12
Training loss: 0.8357042718119695
Validation loss: 2.266262031080569

Epoch: 6| Step: 13
Training loss: 1.7781694108347887
Validation loss: 2.315832879752032

Epoch: 673| Step: 0
Training loss: 0.3093569167468314
Validation loss: 2.308576629154871

Epoch: 6| Step: 1
Training loss: 0.45076741836986073
Validation loss: 2.3132523474377757

Epoch: 6| Step: 2
Training loss: 0.8153895202611691
Validation loss: 2.2930583717974837

Epoch: 6| Step: 3
Training loss: 0.5652847235979541
Validation loss: 2.3830925050557004

Epoch: 6| Step: 4
Training loss: 0.5624685543595533
Validation loss: 2.3326405842392677

Epoch: 6| Step: 5
Training loss: 0.5478386698955082
Validation loss: 2.278191239020971

Epoch: 6| Step: 6
Training loss: 1.4915350641060658
Validation loss: 2.2696333717082395

Epoch: 6| Step: 7
Training loss: 0.40999578334221737
Validation loss: 2.325947503787312

Epoch: 6| Step: 8
Training loss: 0.46619347554407287
Validation loss: 2.3477639220073274

Epoch: 6| Step: 9
Training loss: 0.6931996551086329
Validation loss: 2.3428295994458326

Epoch: 6| Step: 10
Training loss: 0.36540287639183167
Validation loss: 2.3651313761005377

Epoch: 6| Step: 11
Training loss: 0.7522282084854943
Validation loss: 2.346956743808921

Epoch: 6| Step: 12
Training loss: 0.6252385161182981
Validation loss: 2.3030308624052758

Epoch: 6| Step: 13
Training loss: 0.544543445948626
Validation loss: 2.3428673540397487

Epoch: 674| Step: 0
Training loss: 0.5242626461746748
Validation loss: 2.2535493245744704

Epoch: 6| Step: 1
Training loss: 0.6126944778139986
Validation loss: 2.221935806629638

Epoch: 6| Step: 2
Training loss: 0.43033391706681695
Validation loss: 2.253269029485744

Epoch: 6| Step: 3
Training loss: 0.41477545052058373
Validation loss: 2.2690744360880126

Epoch: 6| Step: 4
Training loss: 0.6481896581741671
Validation loss: 2.272135083067212

Epoch: 6| Step: 5
Training loss: 0.6440821152041046
Validation loss: 2.3486708340123297

Epoch: 6| Step: 6
Training loss: 0.5911943244931371
Validation loss: 2.3402514186363947

Epoch: 6| Step: 7
Training loss: 0.5933749369526218
Validation loss: 2.3572281091930622

Epoch: 6| Step: 8
Training loss: 0.3825886130068703
Validation loss: 2.3448160892976277

Epoch: 6| Step: 9
Training loss: 0.45286560855491315
Validation loss: 2.2912937108798386

Epoch: 6| Step: 10
Training loss: 0.3267694356051608
Validation loss: 2.342078850659389

Epoch: 6| Step: 11
Training loss: 1.4678583888319428
Validation loss: 2.3509922886366486

Epoch: 6| Step: 12
Training loss: 0.5265528646883648
Validation loss: 2.2712672047615237

Epoch: 6| Step: 13
Training loss: 0.5113931158508007
Validation loss: 2.381751819776337

Epoch: 675| Step: 0
Training loss: 0.6155929247250634
Validation loss: 2.346729150038241

Epoch: 6| Step: 1
Training loss: 0.520881590197082
Validation loss: 2.3158443294856363

Epoch: 6| Step: 2
Training loss: 0.6924401435736167
Validation loss: 2.2953059462738947

Epoch: 6| Step: 3
Training loss: 1.5678634144402797
Validation loss: 2.2756032333957306

Epoch: 6| Step: 4
Training loss: 0.5819645785862443
Validation loss: 2.2876411383688326

Epoch: 6| Step: 5
Training loss: 0.47054766228496137
Validation loss: 2.3339695883373612

Epoch: 6| Step: 6
Training loss: 0.44649639363770777
Validation loss: 2.290414661335548

Epoch: 6| Step: 7
Training loss: 0.719765112166707
Validation loss: 2.288636314024906

Epoch: 6| Step: 8
Training loss: 0.47852719351350104
Validation loss: 2.269807226034737

Epoch: 6| Step: 9
Training loss: 0.5731836448292712
Validation loss: 2.336482500100691

Epoch: 6| Step: 10
Training loss: 0.5260048434774243
Validation loss: 2.31098147584941

Epoch: 6| Step: 11
Training loss: 0.41389969558105555
Validation loss: 2.304286613102387

Epoch: 6| Step: 12
Training loss: 0.36088446107703825
Validation loss: 2.27412778281751

Epoch: 6| Step: 13
Training loss: 0.4464024372625641
Validation loss: 2.3549171236771222

Epoch: 676| Step: 0
Training loss: 0.39833391002323326
Validation loss: 2.3110196642125036

Epoch: 6| Step: 1
Training loss: 0.5477824992067098
Validation loss: 2.338432910413877

Epoch: 6| Step: 2
Training loss: 0.6080557162502134
Validation loss: 2.308673271010465

Epoch: 6| Step: 3
Training loss: 0.5774891423777672
Validation loss: 2.2802112690763776

Epoch: 6| Step: 4
Training loss: 0.6690410907425565
Validation loss: 2.334119071888906

Epoch: 6| Step: 5
Training loss: 0.49254976292272307
Validation loss: 2.3478304999800397

Epoch: 6| Step: 6
Training loss: 0.4791033036036682
Validation loss: 2.2696345260973563

Epoch: 6| Step: 7
Training loss: 0.46575917736477807
Validation loss: 2.313037128144804

Epoch: 6| Step: 8
Training loss: 0.4336597289327738
Validation loss: 2.3033212445869387

Epoch: 6| Step: 9
Training loss: 0.7318934454413712
Validation loss: 2.404049733971647

Epoch: 6| Step: 10
Training loss: 0.5798333162002729
Validation loss: 2.4026602678523883

Epoch: 6| Step: 11
Training loss: 0.45405143543159754
Validation loss: 2.3149985174847942

Epoch: 6| Step: 12
Training loss: 1.3822016686945124
Validation loss: 2.401677455055369

Epoch: 6| Step: 13
Training loss: 0.4900675942061684
Validation loss: 2.3044526055714205

Epoch: 677| Step: 0
Training loss: 0.8127907819534028
Validation loss: 2.384102109093011

Epoch: 6| Step: 1
Training loss: 0.5826860367354478
Validation loss: 2.246388687665088

Epoch: 6| Step: 2
Training loss: 0.7041730064091652
Validation loss: 2.329394245390284

Epoch: 6| Step: 3
Training loss: 0.6437597107386327
Validation loss: 2.2393058847292067

Epoch: 6| Step: 4
Training loss: 0.7595247411458824
Validation loss: 2.3636921940861706

Epoch: 6| Step: 5
Training loss: 0.5593713003707527
Validation loss: 2.262561074285061

Epoch: 6| Step: 6
Training loss: 0.6245898808532053
Validation loss: 2.3148382305843223

Epoch: 6| Step: 7
Training loss: 0.42825879213111934
Validation loss: 2.321071229598473

Epoch: 6| Step: 8
Training loss: 0.4526828548946745
Validation loss: 2.28397535240948

Epoch: 6| Step: 9
Training loss: 1.4348494931288538
Validation loss: 2.2908922035305976

Epoch: 6| Step: 10
Training loss: 0.3024129083674421
Validation loss: 2.3138692184090313

Epoch: 6| Step: 11
Training loss: 0.6182535356851645
Validation loss: 2.3050121247688913

Epoch: 6| Step: 12
Training loss: 0.46047811731001675
Validation loss: 2.285342208662403

Epoch: 6| Step: 13
Training loss: 0.6249738926203121
Validation loss: 2.316021083585243

Epoch: 678| Step: 0
Training loss: 0.6536700534259468
Validation loss: 2.319913453406838

Epoch: 6| Step: 1
Training loss: 0.8536351030818508
Validation loss: 2.3878998521063255

Epoch: 6| Step: 2
Training loss: 0.5577488090847814
Validation loss: 2.3099561577670675

Epoch: 6| Step: 3
Training loss: 0.4676051623590952
Validation loss: 2.3062210523165505

Epoch: 6| Step: 4
Training loss: 0.4152600227538133
Validation loss: 2.3976327210571036

Epoch: 6| Step: 5
Training loss: 0.4193041138639821
Validation loss: 2.317675434435337

Epoch: 6| Step: 6
Training loss: 0.4644017722933857
Validation loss: 2.2813475887582

Epoch: 6| Step: 7
Training loss: 0.48720138158101217
Validation loss: 2.347117493659034

Epoch: 6| Step: 8
Training loss: 0.5855379395315293
Validation loss: 2.3599553558773825

Epoch: 6| Step: 9
Training loss: 0.4393624106132414
Validation loss: 2.3693758412541905

Epoch: 6| Step: 10
Training loss: 0.3969395096982818
Validation loss: 2.2993236133255692

Epoch: 6| Step: 11
Training loss: 0.6318103720255276
Validation loss: 2.3015482506223437

Epoch: 6| Step: 12
Training loss: 1.39447871945387
Validation loss: 2.2929813044850484

Epoch: 6| Step: 13
Training loss: 0.4552011773734881
Validation loss: 2.3011370926424215

Epoch: 679| Step: 0
Training loss: 0.45763251701856134
Validation loss: 2.3105542511999486

Epoch: 6| Step: 1
Training loss: 0.754965398892413
Validation loss: 2.373923586146756

Epoch: 6| Step: 2
Training loss: 0.6170559513560191
Validation loss: 2.3220220279842727

Epoch: 6| Step: 3
Training loss: 0.5658672003894222
Validation loss: 2.292879926368424

Epoch: 6| Step: 4
Training loss: 0.4779370761389067
Validation loss: 2.315743058873351

Epoch: 6| Step: 5
Training loss: 0.4960273938593594
Validation loss: 2.2629132147457374

Epoch: 6| Step: 6
Training loss: 0.6133416261535621
Validation loss: 2.3252579584626285

Epoch: 6| Step: 7
Training loss: 0.4203079755177944
Validation loss: 2.302019951283365

Epoch: 6| Step: 8
Training loss: 0.645552086862768
Validation loss: 2.3297996755174872

Epoch: 6| Step: 9
Training loss: 0.6032055054928779
Validation loss: 2.3279130939298445

Epoch: 6| Step: 10
Training loss: 0.41609218054205765
Validation loss: 2.3442111419627483

Epoch: 6| Step: 11
Training loss: 0.6948576521721196
Validation loss: 2.3757964139009715

Epoch: 6| Step: 12
Training loss: 0.5970711929868845
Validation loss: 2.2696586596985915

Epoch: 6| Step: 13
Training loss: 1.7818583737831668
Validation loss: 2.2388782540798915

Epoch: 680| Step: 0
Training loss: 0.3250433764488325
Validation loss: 2.375034979674377

Epoch: 6| Step: 1
Training loss: 0.5481380590712236
Validation loss: 2.3008660666568215

Epoch: 6| Step: 2
Training loss: 0.6228256071848519
Validation loss: 2.331800261152038

Epoch: 6| Step: 3
Training loss: 0.6236413015474184
Validation loss: 2.332404389759137

Epoch: 6| Step: 4
Training loss: 0.5225644588408651
Validation loss: 2.3527193618067153

Epoch: 6| Step: 5
Training loss: 0.8552754501664062
Validation loss: 2.3044267204110214

Epoch: 6| Step: 6
Training loss: 0.5056621211115234
Validation loss: 2.348602601588426

Epoch: 6| Step: 7
Training loss: 0.4338627573592347
Validation loss: 2.2220266810732245

Epoch: 6| Step: 8
Training loss: 0.6668589334599297
Validation loss: 2.3084998883412307

Epoch: 6| Step: 9
Training loss: 0.7758099169395037
Validation loss: 2.2968914842547723

Epoch: 6| Step: 10
Training loss: 0.5151660495019229
Validation loss: 2.267092668220952

Epoch: 6| Step: 11
Training loss: 0.511138178994355
Validation loss: 2.3913843357929077

Epoch: 6| Step: 12
Training loss: 1.3892785315200098
Validation loss: 2.2792996778768897

Epoch: 6| Step: 13
Training loss: 0.46419475032433943
Validation loss: 2.2896482149552506

Epoch: 681| Step: 0
Training loss: 0.493842898453976
Validation loss: 2.2527150490237946

Epoch: 6| Step: 1
Training loss: 0.5003505312530543
Validation loss: 2.2890158311151296

Epoch: 6| Step: 2
Training loss: 1.3886809315231885
Validation loss: 2.297203401560034

Epoch: 6| Step: 3
Training loss: 0.5254044371423726
Validation loss: 2.3055071158084774

Epoch: 6| Step: 4
Training loss: 0.4945409306788461
Validation loss: 2.3350749291524076

Epoch: 6| Step: 5
Training loss: 0.540315774452079
Validation loss: 2.278229746904522

Epoch: 6| Step: 6
Training loss: 0.6259899405777207
Validation loss: 2.3013322531396105

Epoch: 6| Step: 7
Training loss: 0.5429746778425291
Validation loss: 2.253172068957387

Epoch: 6| Step: 8
Training loss: 0.5576976711359317
Validation loss: 2.3475501193966397

Epoch: 6| Step: 9
Training loss: 0.5890821377746621
Validation loss: 2.3262756020905013

Epoch: 6| Step: 10
Training loss: 0.6174670443447342
Validation loss: 2.3646976634304235

Epoch: 6| Step: 11
Training loss: 0.6841559577766679
Validation loss: 2.3733730734585547

Epoch: 6| Step: 12
Training loss: 0.5457873837104228
Validation loss: 2.269466540493372

Epoch: 6| Step: 13
Training loss: 0.48458663869874674
Validation loss: 2.306194772366707

Epoch: 682| Step: 0
Training loss: 0.5155499721618473
Validation loss: 2.2639622941774205

Epoch: 6| Step: 1
Training loss: 0.48240358881714607
Validation loss: 2.2819866856977153

Epoch: 6| Step: 2
Training loss: 0.5671967876083754
Validation loss: 2.281509322866376

Epoch: 6| Step: 3
Training loss: 0.5220785006913177
Validation loss: 2.354672626860722

Epoch: 6| Step: 4
Training loss: 0.5975859606928962
Validation loss: 2.3099575134144925

Epoch: 6| Step: 5
Training loss: 0.7088295002909996
Validation loss: 2.3277527612798963

Epoch: 6| Step: 6
Training loss: 1.3700784254946576
Validation loss: 2.3566003870489536

Epoch: 6| Step: 7
Training loss: 0.6673074761823516
Validation loss: 2.322805377625372

Epoch: 6| Step: 8
Training loss: 0.4517745414436871
Validation loss: 2.334900233955183

Epoch: 6| Step: 9
Training loss: 0.4847624367509952
Validation loss: 2.3906934871644783

Epoch: 6| Step: 10
Training loss: 0.4926994325614807
Validation loss: 2.308369419382538

Epoch: 6| Step: 11
Training loss: 0.5933393011659178
Validation loss: 2.351814836732436

Epoch: 6| Step: 12
Training loss: 0.4727828904415377
Validation loss: 2.3138037844474884

Epoch: 6| Step: 13
Training loss: 0.39113812123639696
Validation loss: 2.240770568915328

Epoch: 683| Step: 0
Training loss: 0.6559850521216357
Validation loss: 2.328606062990097

Epoch: 6| Step: 1
Training loss: 0.5834391929303593
Validation loss: 2.2908302980989856

Epoch: 6| Step: 2
Training loss: 0.67348223668174
Validation loss: 2.2638257682615976

Epoch: 6| Step: 3
Training loss: 0.45153689790369866
Validation loss: 2.280616463258154

Epoch: 6| Step: 4
Training loss: 1.4648416341130552
Validation loss: 2.3617304525496934

Epoch: 6| Step: 5
Training loss: 0.736044588821906
Validation loss: 2.3428446551793667

Epoch: 6| Step: 6
Training loss: 0.6614130910785017
Validation loss: 2.449970860294369

Epoch: 6| Step: 7
Training loss: 0.5058546029237688
Validation loss: 2.3533162867886666

Epoch: 6| Step: 8
Training loss: 0.48406121642285477
Validation loss: 2.354339053889585

Epoch: 6| Step: 9
Training loss: 0.43340271530343794
Validation loss: 2.301630859794471

Epoch: 6| Step: 10
Training loss: 0.44487304084584395
Validation loss: 2.3882945765762718

Epoch: 6| Step: 11
Training loss: 0.4261344529600369
Validation loss: 2.348945475941183

Epoch: 6| Step: 12
Training loss: 0.6457480302485996
Validation loss: 2.286011890093686

Epoch: 6| Step: 13
Training loss: 0.4620119116215695
Validation loss: 2.233152300948566

Epoch: 684| Step: 0
Training loss: 0.5635750881116313
Validation loss: 2.3700366972056974

Epoch: 6| Step: 1
Training loss: 0.5064533825873879
Validation loss: 2.3111862867733763

Epoch: 6| Step: 2
Training loss: 0.6318026361430383
Validation loss: 2.2603569319636834

Epoch: 6| Step: 3
Training loss: 0.6687070770392901
Validation loss: 2.341469312571191

Epoch: 6| Step: 4
Training loss: 1.410362545573428
Validation loss: 2.293588557506045

Epoch: 6| Step: 5
Training loss: 0.45475462847299836
Validation loss: 2.300189462583056

Epoch: 6| Step: 6
Training loss: 0.5157436465539095
Validation loss: 2.328967507767292

Epoch: 6| Step: 7
Training loss: 0.6053177183730801
Validation loss: 2.279166238217131

Epoch: 6| Step: 8
Training loss: 0.45901072000418275
Validation loss: 2.3446689141514314

Epoch: 6| Step: 9
Training loss: 0.7184568304818897
Validation loss: 2.3002952060763504

Epoch: 6| Step: 10
Training loss: 0.49921491200579127
Validation loss: 2.3819020748859607

Epoch: 6| Step: 11
Training loss: 0.337854570879748
Validation loss: 2.305589097779722

Epoch: 6| Step: 12
Training loss: 0.6013177150733708
Validation loss: 2.3210712936599087

Epoch: 6| Step: 13
Training loss: 0.5080925975945799
Validation loss: 2.2366020725886506

Epoch: 685| Step: 0
Training loss: 0.7926877656157351
Validation loss: 2.3357987888960494

Epoch: 6| Step: 1
Training loss: 0.519976203080506
Validation loss: 2.362915109414615

Epoch: 6| Step: 2
Training loss: 0.3986106197267015
Validation loss: 2.3125331668975186

Epoch: 6| Step: 3
Training loss: 0.4459878251270031
Validation loss: 2.2072394438814604

Epoch: 6| Step: 4
Training loss: 0.7610317164063958
Validation loss: 2.294288294284365

Epoch: 6| Step: 5
Training loss: 0.5899250403970882
Validation loss: 2.2054320792225592

Epoch: 6| Step: 6
Training loss: 0.6207131233154279
Validation loss: 2.2713703641167617

Epoch: 6| Step: 7
Training loss: 0.6484348343024556
Validation loss: 2.330750416498228

Epoch: 6| Step: 8
Training loss: 1.311183450790154
Validation loss: 2.3233251000596553

Epoch: 6| Step: 9
Training loss: 0.6640221078593334
Validation loss: 2.3049035423136988

Epoch: 6| Step: 10
Training loss: 0.45024846687881936
Validation loss: 2.2586194394066306

Epoch: 6| Step: 11
Training loss: 0.6932449891204719
Validation loss: 2.2930372426067978

Epoch: 6| Step: 12
Training loss: 0.5934568484558557
Validation loss: 2.2679228527728394

Epoch: 6| Step: 13
Training loss: 0.39403103759551755
Validation loss: 2.331454219888947

Epoch: 686| Step: 0
Training loss: 0.3624939128759279
Validation loss: 2.239191802518905

Epoch: 6| Step: 1
Training loss: 0.4292822400584498
Validation loss: 2.3496827547194816

Epoch: 6| Step: 2
Training loss: 1.419265952378959
Validation loss: 2.2707107622254665

Epoch: 6| Step: 3
Training loss: 0.5620312061792335
Validation loss: 2.292608905480959

Epoch: 6| Step: 4
Training loss: 0.5280592409083681
Validation loss: 2.286878603018733

Epoch: 6| Step: 5
Training loss: 0.53195805207132
Validation loss: 2.303599583839577

Epoch: 6| Step: 6
Training loss: 0.5381649672389949
Validation loss: 2.2908207970223895

Epoch: 6| Step: 7
Training loss: 0.4100741349627727
Validation loss: 2.3550794223873694

Epoch: 6| Step: 8
Training loss: 0.7452616420324065
Validation loss: 2.319038478599565

Epoch: 6| Step: 9
Training loss: 0.4979530545296605
Validation loss: 2.2770434310153957

Epoch: 6| Step: 10
Training loss: 0.3824602959165509
Validation loss: 2.3795378337412623

Epoch: 6| Step: 11
Training loss: 0.36879463733830953
Validation loss: 2.321539776250383

Epoch: 6| Step: 12
Training loss: 0.8916330488647333
Validation loss: 2.2831761253579024

Epoch: 6| Step: 13
Training loss: 0.401342367996632
Validation loss: 2.3177192543014913

Epoch: 687| Step: 0
Training loss: 0.5792198639275763
Validation loss: 2.326529754192475

Epoch: 6| Step: 1
Training loss: 0.49636521008572637
Validation loss: 2.2912222486320184

Epoch: 6| Step: 2
Training loss: 0.4959985236138244
Validation loss: 2.3075879694061467

Epoch: 6| Step: 3
Training loss: 0.7247912237859171
Validation loss: 2.3084498187892435

Epoch: 6| Step: 4
Training loss: 0.557936915779684
Validation loss: 2.322689142557147

Epoch: 6| Step: 5
Training loss: 0.5207342689397987
Validation loss: 2.224844555957222

Epoch: 6| Step: 6
Training loss: 0.4763267277813941
Validation loss: 2.303853188503244

Epoch: 6| Step: 7
Training loss: 0.3052357362980946
Validation loss: 2.271109248597699

Epoch: 6| Step: 8
Training loss: 0.4420233270090824
Validation loss: 2.3288575631920914

Epoch: 6| Step: 9
Training loss: 1.3687646107351075
Validation loss: 2.255461722458843

Epoch: 6| Step: 10
Training loss: 0.6733898783262138
Validation loss: 2.3142500610077184

Epoch: 6| Step: 11
Training loss: 0.5766003324920537
Validation loss: 2.243891449822084

Epoch: 6| Step: 12
Training loss: 0.5958758244557776
Validation loss: 2.315356466188007

Epoch: 6| Step: 13
Training loss: 0.2952705747120154
Validation loss: 2.3448178347866535

Epoch: 688| Step: 0
Training loss: 0.5888279131544415
Validation loss: 2.3552528592189796

Epoch: 6| Step: 1
Training loss: 0.5377638834425147
Validation loss: 2.2493488287845174

Epoch: 6| Step: 2
Training loss: 0.535201411882457
Validation loss: 2.338023734993069

Epoch: 6| Step: 3
Training loss: 0.6957449693213512
Validation loss: 2.3354817320774726

Epoch: 6| Step: 4
Training loss: 0.5451068085817182
Validation loss: 2.253499049999543

Epoch: 6| Step: 5
Training loss: 0.7249574056806851
Validation loss: 2.2445341994743764

Epoch: 6| Step: 6
Training loss: 0.4129698750382801
Validation loss: 2.346539979175484

Epoch: 6| Step: 7
Training loss: 0.40777678790060384
Validation loss: 2.2625683264895544

Epoch: 6| Step: 8
Training loss: 0.45294246614433215
Validation loss: 2.397470048045399

Epoch: 6| Step: 9
Training loss: 0.5104416789199909
Validation loss: 2.321104924564916

Epoch: 6| Step: 10
Training loss: 0.741501742324274
Validation loss: 2.2662980197064995

Epoch: 6| Step: 11
Training loss: 0.5790548579148678
Validation loss: 2.272364036613229

Epoch: 6| Step: 12
Training loss: 0.5954000734010753
Validation loss: 2.2808415492122998

Epoch: 6| Step: 13
Training loss: 1.7818753667246998
Validation loss: 2.2820464893145416

Epoch: 689| Step: 0
Training loss: 0.5170286032458219
Validation loss: 2.359711113284622

Epoch: 6| Step: 1
Training loss: 0.5700866565586109
Validation loss: 2.313140954918699

Epoch: 6| Step: 2
Training loss: 0.5066799739713023
Validation loss: 2.329372127309346

Epoch: 6| Step: 3
Training loss: 0.767182459299966
Validation loss: 2.3103946701572866

Epoch: 6| Step: 4
Training loss: 0.4686173569246006
Validation loss: 2.300806737164892

Epoch: 6| Step: 5
Training loss: 0.5266283056416632
Validation loss: 2.2438973125409496

Epoch: 6| Step: 6
Training loss: 0.5291533046697439
Validation loss: 2.3424629489520976

Epoch: 6| Step: 7
Training loss: 0.47388767582093505
Validation loss: 2.3089424179410107

Epoch: 6| Step: 8
Training loss: 0.7631543056850191
Validation loss: 2.36365535456171

Epoch: 6| Step: 9
Training loss: 0.6019954609573056
Validation loss: 2.328372746959493

Epoch: 6| Step: 10
Training loss: 0.505848092796559
Validation loss: 2.3834098649453384

Epoch: 6| Step: 11
Training loss: 0.4541758650831067
Validation loss: 2.3073005580728463

Epoch: 6| Step: 12
Training loss: 1.4045057287347193
Validation loss: 2.344645831453685

Epoch: 6| Step: 13
Training loss: 0.6682825745557636
Validation loss: 2.275775309164041

Epoch: 690| Step: 0
Training loss: 0.4721582642497818
Validation loss: 2.3827338383394743

Epoch: 6| Step: 1
Training loss: 0.5416138849462709
Validation loss: 2.297043309293046

Epoch: 6| Step: 2
Training loss: 0.3572893991574476
Validation loss: 2.2930104504370252

Epoch: 6| Step: 3
Training loss: 0.6831467393101681
Validation loss: 2.34156115742395

Epoch: 6| Step: 4
Training loss: 0.7006560742227569
Validation loss: 2.3407919595281026

Epoch: 6| Step: 5
Training loss: 0.39540645101125027
Validation loss: 2.323392908524762

Epoch: 6| Step: 6
Training loss: 0.5370501121424988
Validation loss: 2.295504772033891

Epoch: 6| Step: 7
Training loss: 0.5260465137019177
Validation loss: 2.3062668628188967

Epoch: 6| Step: 8
Training loss: 0.4779032311328887
Validation loss: 2.3174756904768947

Epoch: 6| Step: 9
Training loss: 0.5663908331515821
Validation loss: 2.310284089587007

Epoch: 6| Step: 10
Training loss: 1.4279833366533103
Validation loss: 2.280954983287596

Epoch: 6| Step: 11
Training loss: 0.538901429369063
Validation loss: 2.33108245010856

Epoch: 6| Step: 12
Training loss: 0.5943263920303594
Validation loss: 2.294422073484954

Epoch: 6| Step: 13
Training loss: 0.551651557886418
Validation loss: 2.3132630884826866

Epoch: 691| Step: 0
Training loss: 0.6936381464647461
Validation loss: 2.2460623162465594

Epoch: 6| Step: 1
Training loss: 0.4811517001984498
Validation loss: 2.28027086854399

Epoch: 6| Step: 2
Training loss: 0.5684570018910511
Validation loss: 2.358990448915437

Epoch: 6| Step: 3
Training loss: 0.543931971168932
Validation loss: 2.32752023646445

Epoch: 6| Step: 4
Training loss: 0.41946245833564183
Validation loss: 2.334577954355306

Epoch: 6| Step: 5
Training loss: 1.373209047032908
Validation loss: 2.387398579212937

Epoch: 6| Step: 6
Training loss: 0.37746144151501
Validation loss: 2.3046848269989884

Epoch: 6| Step: 7
Training loss: 0.692666924943163
Validation loss: 2.3422324000124717

Epoch: 6| Step: 8
Training loss: 0.4718341456026402
Validation loss: 2.3550480597329067

Epoch: 6| Step: 9
Training loss: 0.5717680137909
Validation loss: 2.356078311978585

Epoch: 6| Step: 10
Training loss: 0.5243638225905487
Validation loss: 2.278696273503267

Epoch: 6| Step: 11
Training loss: 0.6221502183888815
Validation loss: 2.2758282153301597

Epoch: 6| Step: 12
Training loss: 0.6599290445506644
Validation loss: 2.2994623066639863

Epoch: 6| Step: 13
Training loss: 0.4843090996981634
Validation loss: 2.3328735783805383

Epoch: 692| Step: 0
Training loss: 0.4392771220086868
Validation loss: 2.309248996224291

Epoch: 6| Step: 1
Training loss: 0.4708933782127734
Validation loss: 2.3620381012426934

Epoch: 6| Step: 2
Training loss: 0.5271329670431314
Validation loss: 2.350270747879951

Epoch: 6| Step: 3
Training loss: 0.6688918489128061
Validation loss: 2.2990427397523576

Epoch: 6| Step: 4
Training loss: 1.4493493692188837
Validation loss: 2.2736448201820654

Epoch: 6| Step: 5
Training loss: 0.44350597293814087
Validation loss: 2.3344031972574535

Epoch: 6| Step: 6
Training loss: 0.7481535992298767
Validation loss: 2.335079330563897

Epoch: 6| Step: 7
Training loss: 0.5843868845990801
Validation loss: 2.2906034701187985

Epoch: 6| Step: 8
Training loss: 0.4173117134826113
Validation loss: 2.330410577271317

Epoch: 6| Step: 9
Training loss: 0.48629806609501675
Validation loss: 2.313320361115322

Epoch: 6| Step: 10
Training loss: 0.34082323089486877
Validation loss: 2.351255993839882

Epoch: 6| Step: 11
Training loss: 0.39928322213599393
Validation loss: 2.2957429275979524

Epoch: 6| Step: 12
Training loss: 0.5322975601298033
Validation loss: 2.345577068739122

Epoch: 6| Step: 13
Training loss: 0.8649556419266614
Validation loss: 2.28632305917812

Epoch: 693| Step: 0
Training loss: 0.3940622922940656
Validation loss: 2.2880443977326514

Epoch: 6| Step: 1
Training loss: 0.543044791625791
Validation loss: 2.3068425184807575

Epoch: 6| Step: 2
Training loss: 0.5413967951930228
Validation loss: 2.2937970410351873

Epoch: 6| Step: 3
Training loss: 1.4148788203459077
Validation loss: 2.3194149597902727

Epoch: 6| Step: 4
Training loss: 0.8334203595178573
Validation loss: 2.2695934760210297

Epoch: 6| Step: 5
Training loss: 0.6159417823553608
Validation loss: 2.3497028251948695

Epoch: 6| Step: 6
Training loss: 0.5040201457629446
Validation loss: 2.327864767879201

Epoch: 6| Step: 7
Training loss: 0.4621057898800745
Validation loss: 2.271647061027187

Epoch: 6| Step: 8
Training loss: 0.45062728315137424
Validation loss: 2.3632286842227126

Epoch: 6| Step: 9
Training loss: 0.5055216247166711
Validation loss: 2.3121810101082976

Epoch: 6| Step: 10
Training loss: 0.4586742895781089
Validation loss: 2.3384417767808534

Epoch: 6| Step: 11
Training loss: 0.41835131027469674
Validation loss: 2.3308094506945523

Epoch: 6| Step: 12
Training loss: 0.5373087010290906
Validation loss: 2.314963095761585

Epoch: 6| Step: 13
Training loss: 0.4170164686365487
Validation loss: 2.3332309323209053

Epoch: 694| Step: 0
Training loss: 0.616592724228966
Validation loss: 2.3830780801178317

Epoch: 6| Step: 1
Training loss: 0.4747499642324409
Validation loss: 2.3083655867502464

Epoch: 6| Step: 2
Training loss: 1.3649820905076433
Validation loss: 2.2817184117931966

Epoch: 6| Step: 3
Training loss: 0.5459408547397162
Validation loss: 2.279638815163612

Epoch: 6| Step: 4
Training loss: 0.5421613274669143
Validation loss: 2.3005271930273246

Epoch: 6| Step: 5
Training loss: 0.3637987777934796
Validation loss: 2.336441289165965

Epoch: 6| Step: 6
Training loss: 0.4851584405281384
Validation loss: 2.2837454132372224

Epoch: 6| Step: 7
Training loss: 0.5467534066309108
Validation loss: 2.3587135583555456

Epoch: 6| Step: 8
Training loss: 0.507926311943762
Validation loss: 2.3014752292864356

Epoch: 6| Step: 9
Training loss: 0.4076565089723898
Validation loss: 2.3386927777685056

Epoch: 6| Step: 10
Training loss: 0.5805158408613293
Validation loss: 2.2819543415042753

Epoch: 6| Step: 11
Training loss: 0.6931500615919898
Validation loss: 2.308458368870142

Epoch: 6| Step: 12
Training loss: 0.7338617844701749
Validation loss: 2.28628791362529

Epoch: 6| Step: 13
Training loss: 0.5902754612172864
Validation loss: 2.3060269014400068

Epoch: 695| Step: 0
Training loss: 0.498164907194642
Validation loss: 2.3895723332360936

Epoch: 6| Step: 1
Training loss: 0.5145275690646179
Validation loss: 2.3213230359233905

Epoch: 6| Step: 2
Training loss: 1.4620903484748373
Validation loss: 2.368444719090188

Epoch: 6| Step: 3
Training loss: 0.7200030309560346
Validation loss: 2.231236340490233

Epoch: 6| Step: 4
Training loss: 0.6085435623806326
Validation loss: 2.3261544862276713

Epoch: 6| Step: 5
Training loss: 0.48373139599455445
Validation loss: 2.358176936836001

Epoch: 6| Step: 6
Training loss: 0.4261906956224062
Validation loss: 2.2410993198975024

Epoch: 6| Step: 7
Training loss: 0.4257223280987536
Validation loss: 2.295717907949306

Epoch: 6| Step: 8
Training loss: 0.47450723059102423
Validation loss: 2.3745955040191067

Epoch: 6| Step: 9
Training loss: 0.5374456843943989
Validation loss: 2.385528025213333

Epoch: 6| Step: 10
Training loss: 0.4501059023432191
Validation loss: 2.354599249674117

Epoch: 6| Step: 11
Training loss: 0.478852958887898
Validation loss: 2.3381428731505527

Epoch: 6| Step: 12
Training loss: 0.7542637585126973
Validation loss: 2.286635479715137

Epoch: 6| Step: 13
Training loss: 0.49069256286963375
Validation loss: 2.3206104186606824

Epoch: 696| Step: 0
Training loss: 0.5396971076945084
Validation loss: 2.2311693931554615

Epoch: 6| Step: 1
Training loss: 0.5718562513936484
Validation loss: 2.3129228129448323

Epoch: 6| Step: 2
Training loss: 0.7230682848002309
Validation loss: 2.3455602265885362

Epoch: 6| Step: 3
Training loss: 1.417543037339809
Validation loss: 2.306429188701289

Epoch: 6| Step: 4
Training loss: 0.6372987410805414
Validation loss: 2.323782998545943

Epoch: 6| Step: 5
Training loss: 0.693992755276301
Validation loss: 2.2641327342027813

Epoch: 6| Step: 6
Training loss: 0.5422652372977955
Validation loss: 2.289960500340948

Epoch: 6| Step: 7
Training loss: 0.5062617171073635
Validation loss: 2.2626000283382885

Epoch: 6| Step: 8
Training loss: 0.6143064737376571
Validation loss: 2.3094197039761006

Epoch: 6| Step: 9
Training loss: 0.6084215579224452
Validation loss: 2.3624980108961657

Epoch: 6| Step: 10
Training loss: 0.467278347942377
Validation loss: 2.3470299787199713

Epoch: 6| Step: 11
Training loss: 0.6162844944985492
Validation loss: 2.382208136577435

Epoch: 6| Step: 12
Training loss: 0.7645854509897728
Validation loss: 2.3207162214627273

Epoch: 6| Step: 13
Training loss: 0.4335224505389187
Validation loss: 2.4643062079968163

Epoch: 697| Step: 0
Training loss: 0.5415649379668745
Validation loss: 2.3143222749522776

Epoch: 6| Step: 1
Training loss: 0.4335517519294608
Validation loss: 2.261206074566376

Epoch: 6| Step: 2
Training loss: 0.5041680653870572
Validation loss: 2.2755183656950955

Epoch: 6| Step: 3
Training loss: 0.6000980287182911
Validation loss: 2.317343119354233

Epoch: 6| Step: 4
Training loss: 0.5014550970480495
Validation loss: 2.3430623501195607

Epoch: 6| Step: 5
Training loss: 0.5001528923401036
Validation loss: 2.295985710673976

Epoch: 6| Step: 6
Training loss: 0.6869799641182074
Validation loss: 2.3162781732330466

Epoch: 6| Step: 7
Training loss: 0.5133142422969673
Validation loss: 2.3300976200366277

Epoch: 6| Step: 8
Training loss: 0.493698314182725
Validation loss: 2.281381180458866

Epoch: 6| Step: 9
Training loss: 0.4990836627846802
Validation loss: 2.351803361002198

Epoch: 6| Step: 10
Training loss: 1.3515011547477438
Validation loss: 2.313245153281426

Epoch: 6| Step: 11
Training loss: 0.8843311312413564
Validation loss: 2.3357156589279326

Epoch: 6| Step: 12
Training loss: 0.4735451056689367
Validation loss: 2.3484825673096914

Epoch: 6| Step: 13
Training loss: 0.4426209606642414
Validation loss: 2.3688552706643606

Epoch: 698| Step: 0
Training loss: 0.4783745071033802
Validation loss: 2.3100494985875457

Epoch: 6| Step: 1
Training loss: 0.5869038306437705
Validation loss: 2.361848958217553

Epoch: 6| Step: 2
Training loss: 0.42137913348994804
Validation loss: 2.3225014089769074

Epoch: 6| Step: 3
Training loss: 0.42723409581367966
Validation loss: 2.2983847979879695

Epoch: 6| Step: 4
Training loss: 0.73912980497009
Validation loss: 2.4003077785866003

Epoch: 6| Step: 5
Training loss: 0.691844801101565
Validation loss: 2.419100934278973

Epoch: 6| Step: 6
Training loss: 0.608768699484121
Validation loss: 2.3366779329985228

Epoch: 6| Step: 7
Training loss: 0.5807038602461229
Validation loss: 2.297328040121738

Epoch: 6| Step: 8
Training loss: 0.5298732420650765
Validation loss: 2.291882221976514

Epoch: 6| Step: 9
Training loss: 0.5528954315084428
Validation loss: 2.3395087497596485

Epoch: 6| Step: 10
Training loss: 0.5941157970971759
Validation loss: 2.3491737285701495

Epoch: 6| Step: 11
Training loss: 0.4884244479963385
Validation loss: 2.3533023362289938

Epoch: 6| Step: 12
Training loss: 0.4348932844837291
Validation loss: 2.3356702827801876

Epoch: 6| Step: 13
Training loss: 1.912934449659595
Validation loss: 2.3561497270239

Epoch: 699| Step: 0
Training loss: 0.4393082613065529
Validation loss: 2.335902372200296

Epoch: 6| Step: 1
Training loss: 0.38661627904982687
Validation loss: 2.383906478071461

Epoch: 6| Step: 2
Training loss: 0.46551081134111577
Validation loss: 2.313616331575452

Epoch: 6| Step: 3
Training loss: 0.5638659105593655
Validation loss: 2.3295274766044978

Epoch: 6| Step: 4
Training loss: 0.41056568962852336
Validation loss: 2.387638895952939

Epoch: 6| Step: 5
Training loss: 0.720616818767866
Validation loss: 2.3585758421819127

Epoch: 6| Step: 6
Training loss: 0.42740995044281965
Validation loss: 2.314543142420486

Epoch: 6| Step: 7
Training loss: 0.6789980932694912
Validation loss: 2.316913399741136

Epoch: 6| Step: 8
Training loss: 0.49160123149874324
Validation loss: 2.363020085591399

Epoch: 6| Step: 9
Training loss: 0.5036888836591843
Validation loss: 2.2932814523759943

Epoch: 6| Step: 10
Training loss: 0.666975342299065
Validation loss: 2.31929340386155

Epoch: 6| Step: 11
Training loss: 1.3371534112381616
Validation loss: 2.2691750091078466

Epoch: 6| Step: 12
Training loss: 0.5873296348619147
Validation loss: 2.3990107111185006

Epoch: 6| Step: 13
Training loss: 0.6750398659412986
Validation loss: 2.289164567370176

Epoch: 700| Step: 0
Training loss: 0.6090622612926785
Validation loss: 2.3951658773531963

Epoch: 6| Step: 1
Training loss: 0.4674371454242902
Validation loss: 2.2999181844793317

Epoch: 6| Step: 2
Training loss: 0.5385157811961411
Validation loss: 2.3153331416396647

Epoch: 6| Step: 3
Training loss: 0.4005038031672518
Validation loss: 2.3344256081089236

Epoch: 6| Step: 4
Training loss: 0.423003171739794
Validation loss: 2.303925939744171

Epoch: 6| Step: 5
Training loss: 0.4838751397927195
Validation loss: 2.327810238255781

Epoch: 6| Step: 6
Training loss: 0.5431550344452793
Validation loss: 2.4366394766324446

Epoch: 6| Step: 7
Training loss: 0.5310626541106943
Validation loss: 2.370685281706109

Epoch: 6| Step: 8
Training loss: 0.6059592198555989
Validation loss: 2.394368374840415

Epoch: 6| Step: 9
Training loss: 0.42596566292567156
Validation loss: 2.2958665790618142

Epoch: 6| Step: 10
Training loss: 1.3042757218237324
Validation loss: 2.293908743137567

Epoch: 6| Step: 11
Training loss: 0.5677429736940164
Validation loss: 2.329283745336854

Epoch: 6| Step: 12
Training loss: 0.4645625634390322
Validation loss: 2.3405946379300087

Epoch: 6| Step: 13
Training loss: 0.588587047436463
Validation loss: 2.352494219266491

Epoch: 701| Step: 0
Training loss: 0.5429582663422764
Validation loss: 2.365771922744587

Epoch: 6| Step: 1
Training loss: 1.3865158577365362
Validation loss: 2.302299424408712

Epoch: 6| Step: 2
Training loss: 0.5981225332769314
Validation loss: 2.281379547688679

Epoch: 6| Step: 3
Training loss: 0.5344580111805106
Validation loss: 2.3206028346984717

Epoch: 6| Step: 4
Training loss: 0.3994376028720638
Validation loss: 2.29043845286258

Epoch: 6| Step: 5
Training loss: 0.4824640047156393
Validation loss: 2.4363687886267815

Epoch: 6| Step: 6
Training loss: 0.5049822652176577
Validation loss: 2.2602988160824995

Epoch: 6| Step: 7
Training loss: 0.5927873638094601
Validation loss: 2.4509257421595785

Epoch: 6| Step: 8
Training loss: 0.5203407405944713
Validation loss: 2.289233138520179

Epoch: 6| Step: 9
Training loss: 0.6566685295643337
Validation loss: 2.306507282171844

Epoch: 6| Step: 10
Training loss: 0.4614890887715699
Validation loss: 2.3666092599471904

Epoch: 6| Step: 11
Training loss: 0.5900743299069532
Validation loss: 2.353230298780703

Epoch: 6| Step: 12
Training loss: 0.6315861817100363
Validation loss: 2.359339940273023

Epoch: 6| Step: 13
Training loss: 0.6482632874091755
Validation loss: 2.311464733140115

Epoch: 702| Step: 0
Training loss: 0.41511219053598347
Validation loss: 2.3195132268341374

Epoch: 6| Step: 1
Training loss: 0.2868735973681233
Validation loss: 2.2570560035448093

Epoch: 6| Step: 2
Training loss: 0.6062788681157301
Validation loss: 2.2827139548426696

Epoch: 6| Step: 3
Training loss: 0.5792722916740505
Validation loss: 2.3228892935371475

Epoch: 6| Step: 4
Training loss: 0.7328051568743149
Validation loss: 2.3375663953643904

Epoch: 6| Step: 5
Training loss: 0.5517403118767723
Validation loss: 2.298893094202204

Epoch: 6| Step: 6
Training loss: 1.3967045537063065
Validation loss: 2.264110148426761

Epoch: 6| Step: 7
Training loss: 0.48236451213355414
Validation loss: 2.36643338917621

Epoch: 6| Step: 8
Training loss: 0.7593242078835084
Validation loss: 2.3469333908664476

Epoch: 6| Step: 9
Training loss: 0.34422468875535983
Validation loss: 2.3170280768071847

Epoch: 6| Step: 10
Training loss: 0.5536971586689482
Validation loss: 2.3945491073925633

Epoch: 6| Step: 11
Training loss: 0.7575137935931106
Validation loss: 2.3712243225643754

Epoch: 6| Step: 12
Training loss: 0.43753162337862733
Validation loss: 2.2781393375044305

Epoch: 6| Step: 13
Training loss: 0.3892226222889671
Validation loss: 2.397646127128911

Epoch: 703| Step: 0
Training loss: 0.4652781340216543
Validation loss: 2.388408495811578

Epoch: 6| Step: 1
Training loss: 0.584719523700257
Validation loss: 2.294592681014047

Epoch: 6| Step: 2
Training loss: 0.4286002187765705
Validation loss: 2.30470676598301

Epoch: 6| Step: 3
Training loss: 0.3568791923343512
Validation loss: 2.329522610196677

Epoch: 6| Step: 4
Training loss: 0.4015311210335824
Validation loss: 2.38903934771731

Epoch: 6| Step: 5
Training loss: 0.6348291453344134
Validation loss: 2.3281187420931815

Epoch: 6| Step: 6
Training loss: 1.308509846744651
Validation loss: 2.3821130730324165

Epoch: 6| Step: 7
Training loss: 0.49187694318937675
Validation loss: 2.2779841064050217

Epoch: 6| Step: 8
Training loss: 0.4974877753505023
Validation loss: 2.3453686610894047

Epoch: 6| Step: 9
Training loss: 0.6133617421193084
Validation loss: 2.245964492138914

Epoch: 6| Step: 10
Training loss: 0.5124129035258563
Validation loss: 2.334343059622356

Epoch: 6| Step: 11
Training loss: 0.5777426821593116
Validation loss: 2.3623697373777923

Epoch: 6| Step: 12
Training loss: 0.44407189876695685
Validation loss: 2.322474263495444

Epoch: 6| Step: 13
Training loss: 0.6792208066864853
Validation loss: 2.331259159544215

Epoch: 704| Step: 0
Training loss: 1.3325190392112731
Validation loss: 2.313755808559858

Epoch: 6| Step: 1
Training loss: 0.44437795587085066
Validation loss: 2.2682883433151177

Epoch: 6| Step: 2
Training loss: 0.6385085804152881
Validation loss: 2.3338173578124928

Epoch: 6| Step: 3
Training loss: 0.511224814076744
Validation loss: 2.3559243184370553

Epoch: 6| Step: 4
Training loss: 0.5133397874591554
Validation loss: 2.3438377697551998

Epoch: 6| Step: 5
Training loss: 0.4345547619726941
Validation loss: 2.2839523909627997

Epoch: 6| Step: 6
Training loss: 0.48379461834288856
Validation loss: 2.3299023091268567

Epoch: 6| Step: 7
Training loss: 0.5738556680632559
Validation loss: 2.318043335866308

Epoch: 6| Step: 8
Training loss: 0.339746976644581
Validation loss: 2.3423275388948883

Epoch: 6| Step: 9
Training loss: 0.6162222787142873
Validation loss: 2.254826368975938

Epoch: 6| Step: 10
Training loss: 0.44444598836763094
Validation loss: 2.3107196536366663

Epoch: 6| Step: 11
Training loss: 0.6946927426749983
Validation loss: 2.2763194744869035

Epoch: 6| Step: 12
Training loss: 0.5603957554013181
Validation loss: 2.347331352603031

Epoch: 6| Step: 13
Training loss: 0.47378852093785395
Validation loss: 2.307838745265661

Epoch: 705| Step: 0
Training loss: 0.3731617575899409
Validation loss: 2.3280684612990705

Epoch: 6| Step: 1
Training loss: 0.4483070742115118
Validation loss: 2.3192516658652083

Epoch: 6| Step: 2
Training loss: 0.4616233443109904
Validation loss: 2.271519215768517

Epoch: 6| Step: 3
Training loss: 0.6883260792433896
Validation loss: 2.3082228930213455

Epoch: 6| Step: 4
Training loss: 0.5769269489195076
Validation loss: 2.3264880104806362

Epoch: 6| Step: 5
Training loss: 0.5556882239587908
Validation loss: 2.3334202603732614

Epoch: 6| Step: 6
Training loss: 1.2565713291194813
Validation loss: 2.343648751645816

Epoch: 6| Step: 7
Training loss: 0.5314467851028872
Validation loss: 2.3316408236138084

Epoch: 6| Step: 8
Training loss: 0.5426962189106328
Validation loss: 2.26764728728644

Epoch: 6| Step: 9
Training loss: 0.5737519734999016
Validation loss: 2.268236027582617

Epoch: 6| Step: 10
Training loss: 0.47015061935141406
Validation loss: 2.340635565992622

Epoch: 6| Step: 11
Training loss: 0.5501653054382408
Validation loss: 2.316449617435982

Epoch: 6| Step: 12
Training loss: 0.4176627134999648
Validation loss: 2.2703482994302133

Epoch: 6| Step: 13
Training loss: 0.3677182521328798
Validation loss: 2.296543309734479

Epoch: 706| Step: 0
Training loss: 0.5172832296694584
Validation loss: 2.2952217735888696

Epoch: 6| Step: 1
Training loss: 0.40550456982164856
Validation loss: 2.330826633157227

Epoch: 6| Step: 2
Training loss: 1.2581248399077767
Validation loss: 2.2683663908376825

Epoch: 6| Step: 3
Training loss: 0.6830580001600461
Validation loss: 2.326029960612751

Epoch: 6| Step: 4
Training loss: 0.49287173227866304
Validation loss: 2.268998812734555

Epoch: 6| Step: 5
Training loss: 0.5104892023926718
Validation loss: 2.3054829732783126

Epoch: 6| Step: 6
Training loss: 0.7261519553995758
Validation loss: 2.363341190937685

Epoch: 6| Step: 7
Training loss: 0.7097426213938732
Validation loss: 2.2493747357398792

Epoch: 6| Step: 8
Training loss: 0.4941001543804114
Validation loss: 2.3659468588146715

Epoch: 6| Step: 9
Training loss: 0.4242552086494101
Validation loss: 2.3416770222849133

Epoch: 6| Step: 10
Training loss: 0.4481726698479867
Validation loss: 2.2574224625169763

Epoch: 6| Step: 11
Training loss: 0.506023100644174
Validation loss: 2.303224189498985

Epoch: 6| Step: 12
Training loss: 0.4215838169168772
Validation loss: 2.301507526935227

Epoch: 6| Step: 13
Training loss: 0.6821274863182586
Validation loss: 2.2605438555784576

Epoch: 707| Step: 0
Training loss: 0.35948194073638673
Validation loss: 2.3600437406640746

Epoch: 6| Step: 1
Training loss: 0.408394982913059
Validation loss: 2.3640791658325178

Epoch: 6| Step: 2
Training loss: 0.3881048926460091
Validation loss: 2.285019766356151

Epoch: 6| Step: 3
Training loss: 0.4076974282571196
Validation loss: 2.301145633686986

Epoch: 6| Step: 4
Training loss: 0.4791100216292542
Validation loss: 2.268143996863938

Epoch: 6| Step: 5
Training loss: 1.4044446588886945
Validation loss: 2.3247169534927097

Epoch: 6| Step: 6
Training loss: 0.7163018536396851
Validation loss: 2.2980262483514817

Epoch: 6| Step: 7
Training loss: 0.539654751939863
Validation loss: 2.282472678107481

Epoch: 6| Step: 8
Training loss: 0.5879775074984039
Validation loss: 2.3029899283845445

Epoch: 6| Step: 9
Training loss: 0.4787213253168863
Validation loss: 2.28245676138766

Epoch: 6| Step: 10
Training loss: 0.7965720105566849
Validation loss: 2.327700384398898

Epoch: 6| Step: 11
Training loss: 0.540812292346057
Validation loss: 2.2961937984753904

Epoch: 6| Step: 12
Training loss: 0.5708566447414972
Validation loss: 2.267029253746025

Epoch: 6| Step: 13
Training loss: 0.6169907703002999
Validation loss: 2.3472943420391705

Epoch: 708| Step: 0
Training loss: 0.46486522721113727
Validation loss: 2.3218589930447098

Epoch: 6| Step: 1
Training loss: 0.3693155348622894
Validation loss: 2.3367502958631845

Epoch: 6| Step: 2
Training loss: 0.808874883015942
Validation loss: 2.2726542034689943

Epoch: 6| Step: 3
Training loss: 0.5114325094080925
Validation loss: 2.358704247028786

Epoch: 6| Step: 4
Training loss: 1.4185612389109783
Validation loss: 2.2636932018414666

Epoch: 6| Step: 5
Training loss: 0.5125183962799981
Validation loss: 2.245818171490979

Epoch: 6| Step: 6
Training loss: 0.577916030232529
Validation loss: 2.2731319755432216

Epoch: 6| Step: 7
Training loss: 0.40373640787494286
Validation loss: 2.2266938129614204

Epoch: 6| Step: 8
Training loss: 0.677082770909785
Validation loss: 2.2752844417998266

Epoch: 6| Step: 9
Training loss: 0.6172684242214999
Validation loss: 2.2757466026102415

Epoch: 6| Step: 10
Training loss: 0.43648549369421485
Validation loss: 2.2592913330664564

Epoch: 6| Step: 11
Training loss: 0.49243318390119784
Validation loss: 2.279236201768295

Epoch: 6| Step: 12
Training loss: 0.3619312099093997
Validation loss: 2.3134395727115913

Epoch: 6| Step: 13
Training loss: 0.47374486482600014
Validation loss: 2.294714304190602

Epoch: 709| Step: 0
Training loss: 0.482125164015141
Validation loss: 2.2228016369918744

Epoch: 6| Step: 1
Training loss: 0.4183608738064743
Validation loss: 2.279092678620777

Epoch: 6| Step: 2
Training loss: 0.47260872152665895
Validation loss: 2.299212117984692

Epoch: 6| Step: 3
Training loss: 0.6804690197879506
Validation loss: 2.221054944682329

Epoch: 6| Step: 4
Training loss: 0.5679979518850097
Validation loss: 2.330110223124073

Epoch: 6| Step: 5
Training loss: 0.43379686083218416
Validation loss: 2.289933275301308

Epoch: 6| Step: 6
Training loss: 0.43926648733105755
Validation loss: 2.3087588276328925

Epoch: 6| Step: 7
Training loss: 0.4823091506535232
Validation loss: 2.26982302815699

Epoch: 6| Step: 8
Training loss: 0.4059988125609899
Validation loss: 2.268157605409382

Epoch: 6| Step: 9
Training loss: 0.5137604031588489
Validation loss: 2.284546263527294

Epoch: 6| Step: 10
Training loss: 0.5239479366001577
Validation loss: 2.2685491410771212

Epoch: 6| Step: 11
Training loss: 0.455972831617347
Validation loss: 2.2599878117462002

Epoch: 6| Step: 12
Training loss: 1.3302137218934769
Validation loss: 2.330832047883492

Epoch: 6| Step: 13
Training loss: 0.5040340113763155
Validation loss: 2.2386767438087523

Epoch: 710| Step: 0
Training loss: 0.35929865648160203
Validation loss: 2.2797723474857134

Epoch: 6| Step: 1
Training loss: 0.4701427749117573
Validation loss: 2.2888182029849857

Epoch: 6| Step: 2
Training loss: 1.269632799048552
Validation loss: 2.3625876308929814

Epoch: 6| Step: 3
Training loss: 0.462014959497723
Validation loss: 2.3506613430691865

Epoch: 6| Step: 4
Training loss: 0.49315406109327903
Validation loss: 2.3008319627620986

Epoch: 6| Step: 5
Training loss: 0.5185354915305872
Validation loss: 2.331183861543154

Epoch: 6| Step: 6
Training loss: 0.3113809815915337
Validation loss: 2.298542983290479

Epoch: 6| Step: 7
Training loss: 0.5724627054552248
Validation loss: 2.3038384949885313

Epoch: 6| Step: 8
Training loss: 0.6359756205237658
Validation loss: 2.265143357206738

Epoch: 6| Step: 9
Training loss: 0.3952170350975703
Validation loss: 2.3201954605174486

Epoch: 6| Step: 10
Training loss: 0.6677447383991806
Validation loss: 2.3363698104614516

Epoch: 6| Step: 11
Training loss: 0.6388372737886734
Validation loss: 2.3352784283938477

Epoch: 6| Step: 12
Training loss: 0.47331463066053703
Validation loss: 2.2880919172282823

Epoch: 6| Step: 13
Training loss: 0.35830221521564204
Validation loss: 2.2594116011902217

Epoch: 711| Step: 0
Training loss: 1.2071309958912724
Validation loss: 2.3651798159657087

Epoch: 6| Step: 1
Training loss: 0.4970012534382862
Validation loss: 2.3533893063682414

Epoch: 6| Step: 2
Training loss: 0.38739442079181746
Validation loss: 2.2618033477441193

Epoch: 6| Step: 3
Training loss: 0.3120981254985195
Validation loss: 2.313947130030062

Epoch: 6| Step: 4
Training loss: 0.38149009711235454
Validation loss: 2.2930990778380256

Epoch: 6| Step: 5
Training loss: 0.33503545482748376
Validation loss: 2.2672192722029947

Epoch: 6| Step: 6
Training loss: 0.6193997776375982
Validation loss: 2.2722683749035717

Epoch: 6| Step: 7
Training loss: 0.4965911834383533
Validation loss: 2.2611473206507027

Epoch: 6| Step: 8
Training loss: 0.5747346182710843
Validation loss: 2.3046566952272984

Epoch: 6| Step: 9
Training loss: 0.5511894607171679
Validation loss: 2.222130414282332

Epoch: 6| Step: 10
Training loss: 0.4749114248861451
Validation loss: 2.3489164401386478

Epoch: 6| Step: 11
Training loss: 0.5709877458500081
Validation loss: 2.2918169623020446

Epoch: 6| Step: 12
Training loss: 0.6902520411183852
Validation loss: 2.377905823686656

Epoch: 6| Step: 13
Training loss: 0.46843268462614174
Validation loss: 2.3349401150268445

Epoch: 712| Step: 0
Training loss: 0.5516864561678462
Validation loss: 2.2983021245669497

Epoch: 6| Step: 1
Training loss: 0.576375039698993
Validation loss: 2.3229004689998356

Epoch: 6| Step: 2
Training loss: 0.4145310108516275
Validation loss: 2.393302048604864

Epoch: 6| Step: 3
Training loss: 0.46662158947037286
Validation loss: 2.3172465685809187

Epoch: 6| Step: 4
Training loss: 0.3832486645687101
Validation loss: 2.3301339086023614

Epoch: 6| Step: 5
Training loss: 1.2636425834456533
Validation loss: 2.2977553184558466

Epoch: 6| Step: 6
Training loss: 0.5425753368858068
Validation loss: 2.306331844785641

Epoch: 6| Step: 7
Training loss: 0.3628309186388678
Validation loss: 2.3640266519572455

Epoch: 6| Step: 8
Training loss: 0.6550744517797168
Validation loss: 2.303221929973809

Epoch: 6| Step: 9
Training loss: 0.49413293523421586
Validation loss: 2.286023012575629

Epoch: 6| Step: 10
Training loss: 0.5599218199857502
Validation loss: 2.3061100410834197

Epoch: 6| Step: 11
Training loss: 0.5546228881599709
Validation loss: 2.2137625639187615

Epoch: 6| Step: 12
Training loss: 0.4157819315414835
Validation loss: 2.3346306019015217

Epoch: 6| Step: 13
Training loss: 0.40002627658963336
Validation loss: 2.35826655635072

Epoch: 713| Step: 0
Training loss: 0.5293333597031081
Validation loss: 2.320926133641518

Epoch: 6| Step: 1
Training loss: 1.3429943000178262
Validation loss: 2.2982310726630244

Epoch: 6| Step: 2
Training loss: 0.629189516330473
Validation loss: 2.305472952133118

Epoch: 6| Step: 3
Training loss: 0.5426768060070094
Validation loss: 2.2866544134648286

Epoch: 6| Step: 4
Training loss: 0.5881026383140838
Validation loss: 2.311187695496954

Epoch: 6| Step: 5
Training loss: 0.4022651521521045
Validation loss: 2.302969485869795

Epoch: 6| Step: 6
Training loss: 0.7103079639026488
Validation loss: 2.2613865182946533

Epoch: 6| Step: 7
Training loss: 0.4749532011468581
Validation loss: 2.324554914852457

Epoch: 6| Step: 8
Training loss: 0.7526690357239672
Validation loss: 2.2268738680590214

Epoch: 6| Step: 9
Training loss: 0.4593429139018908
Validation loss: 2.26592037211872

Epoch: 6| Step: 10
Training loss: 0.4480240234826694
Validation loss: 2.276078067303647

Epoch: 6| Step: 11
Training loss: 0.5966624056097429
Validation loss: 2.269589532725753

Epoch: 6| Step: 12
Training loss: 0.5013048015041889
Validation loss: 2.298907392778369

Epoch: 6| Step: 13
Training loss: 0.44038152325617475
Validation loss: 2.388021740833989

Epoch: 714| Step: 0
Training loss: 0.5439446002400802
Validation loss: 2.390808712343166

Epoch: 6| Step: 1
Training loss: 0.5467021669029831
Validation loss: 2.329001370285026

Epoch: 6| Step: 2
Training loss: 0.6569990696777074
Validation loss: 2.3387722213523494

Epoch: 6| Step: 3
Training loss: 0.585219286386889
Validation loss: 2.311262310031698

Epoch: 6| Step: 4
Training loss: 0.6783613004199123
Validation loss: 2.2234140071818684

Epoch: 6| Step: 5
Training loss: 0.5186877753384231
Validation loss: 2.2892961873820057

Epoch: 6| Step: 6
Training loss: 0.4513724405601194
Validation loss: 2.313845604649345

Epoch: 6| Step: 7
Training loss: 0.5856114306755671
Validation loss: 2.2542045769614005

Epoch: 6| Step: 8
Training loss: 0.6902312731497755
Validation loss: 2.2936263117312268

Epoch: 6| Step: 9
Training loss: 0.7731560088887692
Validation loss: 2.311880508187102

Epoch: 6| Step: 10
Training loss: 0.3514349388125566
Validation loss: 2.3040895326256163

Epoch: 6| Step: 11
Training loss: 0.48795357963049535
Validation loss: 2.307192673894381

Epoch: 6| Step: 12
Training loss: 1.2842995243218063
Validation loss: 2.246810324823977

Epoch: 6| Step: 13
Training loss: 0.4008973799246173
Validation loss: 2.2358598342663036

Epoch: 715| Step: 0
Training loss: 0.6312341197065343
Validation loss: 2.291504653580895

Epoch: 6| Step: 1
Training loss: 1.3419767256451047
Validation loss: 2.3138850220875002

Epoch: 6| Step: 2
Training loss: 0.6389259043166254
Validation loss: 2.371021134016232

Epoch: 6| Step: 3
Training loss: 0.5946477828441635
Validation loss: 2.378550693131779

Epoch: 6| Step: 4
Training loss: 0.7383908790855779
Validation loss: 2.301610188008631

Epoch: 6| Step: 5
Training loss: 0.46564925149832664
Validation loss: 2.381543058806814

Epoch: 6| Step: 6
Training loss: 0.47689088857437306
Validation loss: 2.246718409752348

Epoch: 6| Step: 7
Training loss: 0.42943419879904193
Validation loss: 2.402713261467493

Epoch: 6| Step: 8
Training loss: 0.548461221252588
Validation loss: 2.257786755720742

Epoch: 6| Step: 9
Training loss: 0.5204430230274701
Validation loss: 2.2779027723799867

Epoch: 6| Step: 10
Training loss: 0.5550568385274142
Validation loss: 2.2963363968034955

Epoch: 6| Step: 11
Training loss: 0.45248736537766004
Validation loss: 2.316202087153832

Epoch: 6| Step: 12
Training loss: 0.5129405570438205
Validation loss: 2.3033343915315245

Epoch: 6| Step: 13
Training loss: 0.34253112400951563
Validation loss: 2.3566752314050414

Epoch: 716| Step: 0
Training loss: 0.438720703125
Validation loss: 2.2824311243516715

Epoch: 6| Step: 1
Training loss: 0.41694451445962205
Validation loss: 2.2059087993356314

Epoch: 6| Step: 2
Training loss: 1.2946547380851208
Validation loss: 2.293562369216525

Epoch: 6| Step: 3
Training loss: 0.38104585826035947
Validation loss: 2.29395024320618

Epoch: 6| Step: 4
Training loss: 0.43106935421700454
Validation loss: 2.3152150991353233

Epoch: 6| Step: 5
Training loss: 0.5755073983075668
Validation loss: 2.2580224151173067

Epoch: 6| Step: 6
Training loss: 0.38346237372418585
Validation loss: 2.2991158126993687

Epoch: 6| Step: 7
Training loss: 0.6741616349765344
Validation loss: 2.301153973610692

Epoch: 6| Step: 8
Training loss: 0.40861696501913386
Validation loss: 2.306209354713323

Epoch: 6| Step: 9
Training loss: 0.6774092012349818
Validation loss: 2.240327988778272

Epoch: 6| Step: 10
Training loss: 0.5471416640677743
Validation loss: 2.336717393706685

Epoch: 6| Step: 11
Training loss: 0.3770320987494251
Validation loss: 2.3555389743742325

Epoch: 6| Step: 12
Training loss: 0.4373202806276468
Validation loss: 2.331874921391837

Epoch: 6| Step: 13
Training loss: 0.4790756374083166
Validation loss: 2.329808000898676

Epoch: 717| Step: 0
Training loss: 0.4956553316636342
Validation loss: 2.371250125063928

Epoch: 6| Step: 1
Training loss: 0.5924249218401205
Validation loss: 2.3408691650855356

Epoch: 6| Step: 2
Training loss: 0.46050576826556455
Validation loss: 2.2865793883462886

Epoch: 6| Step: 3
Training loss: 0.6527488501431621
Validation loss: 2.3310135048817817

Epoch: 6| Step: 4
Training loss: 0.4182769138480498
Validation loss: 2.3272955303897795

Epoch: 6| Step: 5
Training loss: 0.5977986484005638
Validation loss: 2.312389118359866

Epoch: 6| Step: 6
Training loss: 1.355554451555487
Validation loss: 2.2486490115501394

Epoch: 6| Step: 7
Training loss: 0.4952899097381407
Validation loss: 2.2914974616296755

Epoch: 6| Step: 8
Training loss: 0.38784037837941293
Validation loss: 2.319443965898143

Epoch: 6| Step: 9
Training loss: 0.4072761779858038
Validation loss: 2.2802428785407574

Epoch: 6| Step: 10
Training loss: 0.41940840444543687
Validation loss: 2.3430724670726835

Epoch: 6| Step: 11
Training loss: 0.5215647774767191
Validation loss: 2.3090328941768616

Epoch: 6| Step: 12
Training loss: 0.6292520366206835
Validation loss: 2.3575996532871786

Epoch: 6| Step: 13
Training loss: 0.49396265918806254
Validation loss: 2.2381612885189766

Epoch: 718| Step: 0
Training loss: 0.45384346795344205
Validation loss: 2.296417768980423

Epoch: 6| Step: 1
Training loss: 0.4074784010153722
Validation loss: 2.298042176600415

Epoch: 6| Step: 2
Training loss: 0.47775238826599914
Validation loss: 2.3321025011161374

Epoch: 6| Step: 3
Training loss: 0.6133246193876654
Validation loss: 2.3010453472467227

Epoch: 6| Step: 4
Training loss: 1.2770547802436527
Validation loss: 2.2958497267730866

Epoch: 6| Step: 5
Training loss: 0.742767187910247
Validation loss: 2.380065791633167

Epoch: 6| Step: 6
Training loss: 0.4077429299188913
Validation loss: 2.3340595650812315

Epoch: 6| Step: 7
Training loss: 0.4186387796876356
Validation loss: 2.245234336134469

Epoch: 6| Step: 8
Training loss: 0.3359097092244791
Validation loss: 2.2851363850205084

Epoch: 6| Step: 9
Training loss: 0.5679179046833802
Validation loss: 2.2724027069851185

Epoch: 6| Step: 10
Training loss: 0.5024466852591054
Validation loss: 2.3171781609415567

Epoch: 6| Step: 11
Training loss: 0.6046240297664218
Validation loss: 2.29232124160843

Epoch: 6| Step: 12
Training loss: 0.4731471452355392
Validation loss: 2.308059125489108

Epoch: 6| Step: 13
Training loss: 0.6052175677629644
Validation loss: 2.3118119927742486

Epoch: 719| Step: 0
Training loss: 0.5777956565766306
Validation loss: 2.3278038145811606

Epoch: 6| Step: 1
Training loss: 0.6213087033834136
Validation loss: 2.253500703539311

Epoch: 6| Step: 2
Training loss: 0.46951900028238186
Validation loss: 2.3273055787395003

Epoch: 6| Step: 3
Training loss: 0.30491700454172616
Validation loss: 2.3512374254778963

Epoch: 6| Step: 4
Training loss: 0.5181669520568225
Validation loss: 2.3340638481370863

Epoch: 6| Step: 5
Training loss: 0.43338024622115917
Validation loss: 2.3108197554195513

Epoch: 6| Step: 6
Training loss: 0.46280590521462384
Validation loss: 2.408403934528693

Epoch: 6| Step: 7
Training loss: 0.4676742767163218
Validation loss: 2.3044374614306564

Epoch: 6| Step: 8
Training loss: 0.41390817393355833
Validation loss: 2.3533610509028966

Epoch: 6| Step: 9
Training loss: 1.356117423121569
Validation loss: 2.299968710062769

Epoch: 6| Step: 10
Training loss: 0.5562621318908586
Validation loss: 2.23444547799485

Epoch: 6| Step: 11
Training loss: 0.4414073640252293
Validation loss: 2.3328338130843322

Epoch: 6| Step: 12
Training loss: 0.30469821030792565
Validation loss: 2.2606509330038387

Epoch: 6| Step: 13
Training loss: 0.6662027538001578
Validation loss: 2.2927334835215025

Epoch: 720| Step: 0
Training loss: 0.6559534992522172
Validation loss: 2.2920285223559334

Epoch: 6| Step: 1
Training loss: 0.6511890219185419
Validation loss: 2.2283087747083106

Epoch: 6| Step: 2
Training loss: 0.6313614397543158
Validation loss: 2.3047311997342037

Epoch: 6| Step: 3
Training loss: 0.6121330203106774
Validation loss: 2.264081323409063

Epoch: 6| Step: 4
Training loss: 0.5100376674822632
Validation loss: 2.32249582691516

Epoch: 6| Step: 5
Training loss: 0.6615217634010362
Validation loss: 2.317923297340568

Epoch: 6| Step: 6
Training loss: 0.30714549882519504
Validation loss: 2.31222715627893

Epoch: 6| Step: 7
Training loss: 0.53453281035498
Validation loss: 2.356503854216177

Epoch: 6| Step: 8
Training loss: 0.4933367587332543
Validation loss: 2.2860052320545554

Epoch: 6| Step: 9
Training loss: 0.4893435709520755
Validation loss: 2.315598174861124

Epoch: 6| Step: 10
Training loss: 0.5104714253953615
Validation loss: 2.3318954117379525

Epoch: 6| Step: 11
Training loss: 0.5320061743564404
Validation loss: 2.2749033393865874

Epoch: 6| Step: 12
Training loss: 1.2978537210026022
Validation loss: 2.2790139556594116

Epoch: 6| Step: 13
Training loss: 0.3624316915739669
Validation loss: 2.3156119994034836

Epoch: 721| Step: 0
Training loss: 0.5340089682083133
Validation loss: 2.2736206680042104

Epoch: 6| Step: 1
Training loss: 0.471446419920898
Validation loss: 2.243537772665392

Epoch: 6| Step: 2
Training loss: 0.5130280495796078
Validation loss: 2.2658536485168153

Epoch: 6| Step: 3
Training loss: 1.3001774483396566
Validation loss: 2.327045563451443

Epoch: 6| Step: 4
Training loss: 0.40823387869746586
Validation loss: 2.3021333886033655

Epoch: 6| Step: 5
Training loss: 0.3965729487660605
Validation loss: 2.3162543637781057

Epoch: 6| Step: 6
Training loss: 0.47943071332555687
Validation loss: 2.3286027756000727

Epoch: 6| Step: 7
Training loss: 0.42945357804450596
Validation loss: 2.2726879834482845

Epoch: 6| Step: 8
Training loss: 0.5428160857596633
Validation loss: 2.3431874442998875

Epoch: 6| Step: 9
Training loss: 0.736570768572911
Validation loss: 2.28792818108845

Epoch: 6| Step: 10
Training loss: 0.5017280222304157
Validation loss: 2.2931473562106754

Epoch: 6| Step: 11
Training loss: 0.6328750861972341
Validation loss: 2.2650764443395257

Epoch: 6| Step: 12
Training loss: 0.47159024292855983
Validation loss: 2.2423904908460504

Epoch: 6| Step: 13
Training loss: 0.586317168253487
Validation loss: 2.262092346521361

Epoch: 722| Step: 0
Training loss: 0.6525953801185924
Validation loss: 2.214105666595153

Epoch: 6| Step: 1
Training loss: 0.5114313730979803
Validation loss: 2.330727642528819

Epoch: 6| Step: 2
Training loss: 0.5287870647524846
Validation loss: 2.308839457203264

Epoch: 6| Step: 3
Training loss: 0.41406586483721797
Validation loss: 2.3675312437172478

Epoch: 6| Step: 4
Training loss: 0.5467564045513951
Validation loss: 2.2799533457805103

Epoch: 6| Step: 5
Training loss: 0.6260779145506118
Validation loss: 2.3257128485088625

Epoch: 6| Step: 6
Training loss: 0.4805226799696292
Validation loss: 2.3062634924526084

Epoch: 6| Step: 7
Training loss: 1.3602268137148452
Validation loss: 2.318228294244907

Epoch: 6| Step: 8
Training loss: 0.398861808736853
Validation loss: 2.342871674064047

Epoch: 6| Step: 9
Training loss: 0.6816598621703436
Validation loss: 2.3334206767661976

Epoch: 6| Step: 10
Training loss: 0.47412840094076986
Validation loss: 2.368890453623477

Epoch: 6| Step: 11
Training loss: 0.6156468537610157
Validation loss: 2.3331074480803498

Epoch: 6| Step: 12
Training loss: 0.5004231629226581
Validation loss: 2.342640258142578

Epoch: 6| Step: 13
Training loss: 0.40856623584310875
Validation loss: 2.335081925954561

Epoch: 723| Step: 0
Training loss: 0.6527163874614953
Validation loss: 2.311970627713862

Epoch: 6| Step: 1
Training loss: 0.6067251398347863
Validation loss: 2.2502420003587096

Epoch: 6| Step: 2
Training loss: 0.4358452771168896
Validation loss: 2.3085633876890173

Epoch: 6| Step: 3
Training loss: 0.5530093691809952
Validation loss: 2.270033873351887

Epoch: 6| Step: 4
Training loss: 0.363545598479745
Validation loss: 2.3240967774125796

Epoch: 6| Step: 5
Training loss: 0.4126736542723052
Validation loss: 2.286434224939928

Epoch: 6| Step: 6
Training loss: 0.6130256120035821
Validation loss: 2.2799983201599123

Epoch: 6| Step: 7
Training loss: 0.5776369509208774
Validation loss: 2.3032384161086803

Epoch: 6| Step: 8
Training loss: 0.7314548466345001
Validation loss: 2.344254894496625

Epoch: 6| Step: 9
Training loss: 0.5603441410098435
Validation loss: 2.332285202489256

Epoch: 6| Step: 10
Training loss: 0.6059615068170486
Validation loss: 2.262410242311173

Epoch: 6| Step: 11
Training loss: 0.5572663120194412
Validation loss: 2.312585537544337

Epoch: 6| Step: 12
Training loss: 0.49986295013899695
Validation loss: 2.2796131768004284

Epoch: 6| Step: 13
Training loss: 1.7844447882211074
Validation loss: 2.3060615304915326

Epoch: 724| Step: 0
Training loss: 0.40396642771587726
Validation loss: 2.341687287545025

Epoch: 6| Step: 1
Training loss: 0.2404294656214864
Validation loss: 2.2522378255995403

Epoch: 6| Step: 2
Training loss: 0.504788447107535
Validation loss: 2.339340759324659

Epoch: 6| Step: 3
Training loss: 0.6863974921008402
Validation loss: 2.2906007873977243

Epoch: 6| Step: 4
Training loss: 0.4885580270246961
Validation loss: 2.2691962164431647

Epoch: 6| Step: 5
Training loss: 1.4522472725066244
Validation loss: 2.2728323227365963

Epoch: 6| Step: 6
Training loss: 0.540040938803533
Validation loss: 2.3363455759158422

Epoch: 6| Step: 7
Training loss: 0.36028295344541383
Validation loss: 2.2958394156841195

Epoch: 6| Step: 8
Training loss: 0.41732715669391296
Validation loss: 2.254902171467701

Epoch: 6| Step: 9
Training loss: 0.31740888048370025
Validation loss: 2.3100692114786927

Epoch: 6| Step: 10
Training loss: 0.37570469923159594
Validation loss: 2.300613054819822

Epoch: 6| Step: 11
Training loss: 0.5172733777249793
Validation loss: 2.34748382451133

Epoch: 6| Step: 12
Training loss: 0.642836962110652
Validation loss: 2.3052552327787375

Epoch: 6| Step: 13
Training loss: 0.4392646554945631
Validation loss: 2.370973519014139

Epoch: 725| Step: 0
Training loss: 0.36986428429827695
Validation loss: 2.2973708900399847

Epoch: 6| Step: 1
Training loss: 0.46582044045628485
Validation loss: 2.27891443781862

Epoch: 6| Step: 2
Training loss: 0.3039957287427158
Validation loss: 2.339454661395621

Epoch: 6| Step: 3
Training loss: 0.7756324602332358
Validation loss: 2.253085524008806

Epoch: 6| Step: 4
Training loss: 0.5876630171386438
Validation loss: 2.3067659305794015

Epoch: 6| Step: 5
Training loss: 1.3166037391561984
Validation loss: 2.345615868781573

Epoch: 6| Step: 6
Training loss: 0.6640857916842435
Validation loss: 2.2688020025901765

Epoch: 6| Step: 7
Training loss: 0.48671705328337916
Validation loss: 2.2797502287096187

Epoch: 6| Step: 8
Training loss: 0.6622164254309076
Validation loss: 2.332377197958411

Epoch: 6| Step: 9
Training loss: 0.4479250814697222
Validation loss: 2.3064905020715774

Epoch: 6| Step: 10
Training loss: 0.48614581264280293
Validation loss: 2.2937935931114333

Epoch: 6| Step: 11
Training loss: 0.48838356471991196
Validation loss: 2.240235795725829

Epoch: 6| Step: 12
Training loss: 0.479312451271953
Validation loss: 2.2581961756732483

Epoch: 6| Step: 13
Training loss: 0.3491819848798946
Validation loss: 2.238252123846302

Epoch: 726| Step: 0
Training loss: 0.5432910100078303
Validation loss: 2.2476181950525698

Epoch: 6| Step: 1
Training loss: 0.4738618591829135
Validation loss: 2.3465257108277084

Epoch: 6| Step: 2
Training loss: 0.4906672659970507
Validation loss: 2.2779759213646664

Epoch: 6| Step: 3
Training loss: 0.41089929758477445
Validation loss: 2.270427830972547

Epoch: 6| Step: 4
Training loss: 0.5413388825486048
Validation loss: 2.3773483632775467

Epoch: 6| Step: 5
Training loss: 0.6107425261503573
Validation loss: 2.2694164592535864

Epoch: 6| Step: 6
Training loss: 0.40367340075789787
Validation loss: 2.3598163520350544

Epoch: 6| Step: 7
Training loss: 0.43988654909205926
Validation loss: 2.3621165838470923

Epoch: 6| Step: 8
Training loss: 0.3567647260528347
Validation loss: 2.2682336800824934

Epoch: 6| Step: 9
Training loss: 0.5323705355996012
Validation loss: 2.2041820188835546

Epoch: 6| Step: 10
Training loss: 0.36893142342866375
Validation loss: 2.3268683638013163

Epoch: 6| Step: 11
Training loss: 0.38429465733536
Validation loss: 2.2662452762383647

Epoch: 6| Step: 12
Training loss: 1.1678420798720595
Validation loss: 2.2771451989423723

Epoch: 6| Step: 13
Training loss: 0.358823352850923
Validation loss: 2.2880289192159817

Epoch: 727| Step: 0
Training loss: 0.7382279634167612
Validation loss: 2.2788453351185383

Epoch: 6| Step: 1
Training loss: 1.2802503454248506
Validation loss: 2.3648180172728233

Epoch: 6| Step: 2
Training loss: 0.5080037857124864
Validation loss: 2.2876380756355963

Epoch: 6| Step: 3
Training loss: 0.5692159221954849
Validation loss: 2.2799676911724425

Epoch: 6| Step: 4
Training loss: 0.37809008760299867
Validation loss: 2.299998255118644

Epoch: 6| Step: 5
Training loss: 0.547163424046638
Validation loss: 2.250030723599007

Epoch: 6| Step: 6
Training loss: 0.5070106925382332
Validation loss: 2.197325107001783

Epoch: 6| Step: 7
Training loss: 0.4019180193548807
Validation loss: 2.2878012756150037

Epoch: 6| Step: 8
Training loss: 0.5856930540719296
Validation loss: 2.2518925529302414

Epoch: 6| Step: 9
Training loss: 0.40633116424838
Validation loss: 2.3054544209059986

Epoch: 6| Step: 10
Training loss: 0.5528977223504452
Validation loss: 2.194282049627855

Epoch: 6| Step: 11
Training loss: 0.38745886368979654
Validation loss: 2.2370146409163825

Epoch: 6| Step: 12
Training loss: 0.47001749969937406
Validation loss: 2.2660557185770283

Epoch: 6| Step: 13
Training loss: 0.5187451144068812
Validation loss: 2.2758644320154495

Epoch: 728| Step: 0
Training loss: 0.4153351569041289
Validation loss: 2.2300963002023955

Epoch: 6| Step: 1
Training loss: 0.7170662023155641
Validation loss: 2.3566444774189406

Epoch: 6| Step: 2
Training loss: 0.5695543867940062
Validation loss: 2.338224804522649

Epoch: 6| Step: 3
Training loss: 0.6960182037631164
Validation loss: 2.3082553039449256

Epoch: 6| Step: 4
Training loss: 0.4249830200505828
Validation loss: 2.305741249597864

Epoch: 6| Step: 5
Training loss: 0.4978638855107537
Validation loss: 2.2950000701617603

Epoch: 6| Step: 6
Training loss: 0.6405681957088795
Validation loss: 2.2811328207733004

Epoch: 6| Step: 7
Training loss: 0.4769440827383438
Validation loss: 2.2707374833255565

Epoch: 6| Step: 8
Training loss: 0.41818616684812454
Validation loss: 2.3231312745385777

Epoch: 6| Step: 9
Training loss: 0.479937841592879
Validation loss: 2.3067725086925446

Epoch: 6| Step: 10
Training loss: 0.5327376125655204
Validation loss: 2.288219511292215

Epoch: 6| Step: 11
Training loss: 1.2576095701681
Validation loss: 2.330482973034156

Epoch: 6| Step: 12
Training loss: 0.5077889657069117
Validation loss: 2.2179237981194615

Epoch: 6| Step: 13
Training loss: 0.38548929157425227
Validation loss: 2.3136111868172042

Epoch: 729| Step: 0
Training loss: 0.5747941695717985
Validation loss: 2.311687461981943

Epoch: 6| Step: 1
Training loss: 0.6065445725053262
Validation loss: 2.3356248854448163

Epoch: 6| Step: 2
Training loss: 0.4468234012398221
Validation loss: 2.2746155698786343

Epoch: 6| Step: 3
Training loss: 0.43043269648557386
Validation loss: 2.2628382635081454

Epoch: 6| Step: 4
Training loss: 0.3841845389420062
Validation loss: 2.2807404464159005

Epoch: 6| Step: 5
Training loss: 0.622477160345032
Validation loss: 2.2667760904321654

Epoch: 6| Step: 6
Training loss: 0.4587123632973296
Validation loss: 2.382073404883144

Epoch: 6| Step: 7
Training loss: 0.6722861074622267
Validation loss: 2.251014111770031

Epoch: 6| Step: 8
Training loss: 0.5721774244853719
Validation loss: 2.3578468222018585

Epoch: 6| Step: 9
Training loss: 0.45748171655152253
Validation loss: 2.3135681745063437

Epoch: 6| Step: 10
Training loss: 0.427071741768687
Validation loss: 2.287425585004318

Epoch: 6| Step: 11
Training loss: 0.5364305124815533
Validation loss: 2.2326234170234955

Epoch: 6| Step: 12
Training loss: 1.2435232214513803
Validation loss: 2.26780617076427

Epoch: 6| Step: 13
Training loss: 0.36718461867480295
Validation loss: 2.22378438340528

Epoch: 730| Step: 0
Training loss: 1.2731505930841776
Validation loss: 2.318883815183721

Epoch: 6| Step: 1
Training loss: 0.6558866403170914
Validation loss: 2.3099678486045865

Epoch: 6| Step: 2
Training loss: 0.4303967258133841
Validation loss: 2.2927790379857598

Epoch: 6| Step: 3
Training loss: 0.371998857660488
Validation loss: 2.309527651183302

Epoch: 6| Step: 4
Training loss: 0.4481369593153728
Validation loss: 2.2882458296307937

Epoch: 6| Step: 5
Training loss: 0.3701889049124026
Validation loss: 2.29229291337181

Epoch: 6| Step: 6
Training loss: 0.700447664847625
Validation loss: 2.2282799985376394

Epoch: 6| Step: 7
Training loss: 0.47541748134009426
Validation loss: 2.2692852344761256

Epoch: 6| Step: 8
Training loss: 0.43292144684941286
Validation loss: 2.338861526118294

Epoch: 6| Step: 9
Training loss: 0.4118683096381374
Validation loss: 2.2730418883933807

Epoch: 6| Step: 10
Training loss: 0.6553314228809382
Validation loss: 2.290033376681288

Epoch: 6| Step: 11
Training loss: 0.30114812893401033
Validation loss: 2.375630345267023

Epoch: 6| Step: 12
Training loss: 0.43131347272072545
Validation loss: 2.405867452567458

Epoch: 6| Step: 13
Training loss: 0.45373584417850577
Validation loss: 2.2806204914664265

Epoch: 731| Step: 0
Training loss: 0.2730868543572109
Validation loss: 2.297610019844232

Epoch: 6| Step: 1
Training loss: 0.3294810249685457
Validation loss: 2.284295535392685

Epoch: 6| Step: 2
Training loss: 0.5645715925771874
Validation loss: 2.3114379466074544

Epoch: 6| Step: 3
Training loss: 0.4868991670499153
Validation loss: 2.2528304683021014

Epoch: 6| Step: 4
Training loss: 0.5279142331632042
Validation loss: 2.3061095508355045

Epoch: 6| Step: 5
Training loss: 1.1970602982709488
Validation loss: 2.302638180845315

Epoch: 6| Step: 6
Training loss: 0.5307236476183216
Validation loss: 2.2793978067636074

Epoch: 6| Step: 7
Training loss: 0.6138007278222412
Validation loss: 2.287746460053584

Epoch: 6| Step: 8
Training loss: 0.5776381633672764
Validation loss: 2.342634320256183

Epoch: 6| Step: 9
Training loss: 0.5162743612088101
Validation loss: 2.3017707678959973

Epoch: 6| Step: 10
Training loss: 0.40587227941270326
Validation loss: 2.288291681254743

Epoch: 6| Step: 11
Training loss: 0.5623927014056369
Validation loss: 2.3132605871934597

Epoch: 6| Step: 12
Training loss: 0.4749311447431188
Validation loss: 2.267434289043001

Epoch: 6| Step: 13
Training loss: 0.5955231191357613
Validation loss: 2.27338169081412

Epoch: 732| Step: 0
Training loss: 0.49881477248469175
Validation loss: 2.336782003931898

Epoch: 6| Step: 1
Training loss: 0.5212281129664943
Validation loss: 2.3165032004503265

Epoch: 6| Step: 2
Training loss: 0.4219374787018852
Validation loss: 2.3021298228744147

Epoch: 6| Step: 3
Training loss: 0.37135494476422315
Validation loss: 2.308012375316071

Epoch: 6| Step: 4
Training loss: 0.6924982015125043
Validation loss: 2.29102254710775

Epoch: 6| Step: 5
Training loss: 0.5705680013561258
Validation loss: 2.3065241332843445

Epoch: 6| Step: 6
Training loss: 0.42283119346419007
Validation loss: 2.2612114927474325

Epoch: 6| Step: 7
Training loss: 0.522503802956426
Validation loss: 2.272186759558804

Epoch: 6| Step: 8
Training loss: 1.2265400489647607
Validation loss: 2.3100056386601007

Epoch: 6| Step: 9
Training loss: 0.6028942378243473
Validation loss: 2.2220884964385434

Epoch: 6| Step: 10
Training loss: 0.5975728942985286
Validation loss: 2.269315275600753

Epoch: 6| Step: 11
Training loss: 0.4191780422037277
Validation loss: 2.2255404659923803

Epoch: 6| Step: 12
Training loss: 0.4563412470564434
Validation loss: 2.317096913735884

Epoch: 6| Step: 13
Training loss: 0.2763711504433045
Validation loss: 2.2938952627738436

Epoch: 733| Step: 0
Training loss: 0.4530340136238276
Validation loss: 2.268822060870062

Epoch: 6| Step: 1
Training loss: 0.46801713238029763
Validation loss: 2.288258006143366

Epoch: 6| Step: 2
Training loss: 0.5825156685764248
Validation loss: 2.3128837116334315

Epoch: 6| Step: 3
Training loss: 0.38516127871312095
Validation loss: 2.2965180085634405

Epoch: 6| Step: 4
Training loss: 0.46668213268037617
Validation loss: 2.3352264420644633

Epoch: 6| Step: 5
Training loss: 0.39473330167805587
Validation loss: 2.284263361373963

Epoch: 6| Step: 6
Training loss: 0.5199624760091788
Validation loss: 2.2976310166054885

Epoch: 6| Step: 7
Training loss: 0.3159489329049451
Validation loss: 2.293276293299323

Epoch: 6| Step: 8
Training loss: 0.314899009985532
Validation loss: 2.272641088859663

Epoch: 6| Step: 9
Training loss: 1.2172219404996678
Validation loss: 2.288581083271205

Epoch: 6| Step: 10
Training loss: 0.4659264241724425
Validation loss: 2.3187969328501032

Epoch: 6| Step: 11
Training loss: 0.4977864201497722
Validation loss: 2.2663325963257406

Epoch: 6| Step: 12
Training loss: 0.4482222741717271
Validation loss: 2.3473007552430785

Epoch: 6| Step: 13
Training loss: 0.5501126228245529
Validation loss: 2.3059380321505603

Epoch: 734| Step: 0
Training loss: 0.4558659884014776
Validation loss: 2.190515921927973

Epoch: 6| Step: 1
Training loss: 0.6521096637597684
Validation loss: 2.303754211747407

Epoch: 6| Step: 2
Training loss: 0.7050557859479999
Validation loss: 2.322314621731641

Epoch: 6| Step: 3
Training loss: 0.43785424876829043
Validation loss: 2.341264161470155

Epoch: 6| Step: 4
Training loss: 0.5484548364925951
Validation loss: 2.281088937559727

Epoch: 6| Step: 5
Training loss: 0.3800789294964548
Validation loss: 2.3651780145075993

Epoch: 6| Step: 6
Training loss: 0.6063502140393637
Validation loss: 2.258267532471929

Epoch: 6| Step: 7
Training loss: 0.5204565656387296
Validation loss: 2.322544175271007

Epoch: 6| Step: 8
Training loss: 1.248060151747407
Validation loss: 2.3166826729949297

Epoch: 6| Step: 9
Training loss: 0.5920327600906375
Validation loss: 2.290107003527018

Epoch: 6| Step: 10
Training loss: 0.5144494846594638
Validation loss: 2.297200137306559

Epoch: 6| Step: 11
Training loss: 0.4356572306461679
Validation loss: 2.310664849213276

Epoch: 6| Step: 12
Training loss: 0.3598228028097756
Validation loss: 2.2830451485338847

Epoch: 6| Step: 13
Training loss: 0.37795381690776575
Validation loss: 2.327650688214464

Epoch: 735| Step: 0
Training loss: 0.5771222310320994
Validation loss: 2.3315345654483552

Epoch: 6| Step: 1
Training loss: 0.4605452598174603
Validation loss: 2.2630478002412597

Epoch: 6| Step: 2
Training loss: 0.4151580281016757
Validation loss: 2.3269522786178283

Epoch: 6| Step: 3
Training loss: 0.41306303064488564
Validation loss: 2.3595667316125315

Epoch: 6| Step: 4
Training loss: 0.38565197626164177
Validation loss: 2.3042809079243165

Epoch: 6| Step: 5
Training loss: 0.7126876751194389
Validation loss: 2.2954536322168058

Epoch: 6| Step: 6
Training loss: 0.44170416846697413
Validation loss: 2.30285959812112

Epoch: 6| Step: 7
Training loss: 0.6476651843367004
Validation loss: 2.2660596544458382

Epoch: 6| Step: 8
Training loss: 1.2146746158922483
Validation loss: 2.360362449264945

Epoch: 6| Step: 9
Training loss: 0.530424992100698
Validation loss: 2.3312851794931895

Epoch: 6| Step: 10
Training loss: 0.5920873250251815
Validation loss: 2.320090059382466

Epoch: 6| Step: 11
Training loss: 0.472404901809318
Validation loss: 2.3353408840113663

Epoch: 6| Step: 12
Training loss: 0.40086701128058944
Validation loss: 2.369228166135017

Epoch: 6| Step: 13
Training loss: 0.4418676715928372
Validation loss: 2.2885823261192444

Epoch: 736| Step: 0
Training loss: 0.38697459687537833
Validation loss: 2.3715920870760847

Epoch: 6| Step: 1
Training loss: 0.47775131220515094
Validation loss: 2.280249647844808

Epoch: 6| Step: 2
Training loss: 0.3360270669102594
Validation loss: 2.3247962725674878

Epoch: 6| Step: 3
Training loss: 0.2836978406061545
Validation loss: 2.3366525567807663

Epoch: 6| Step: 4
Training loss: 0.3310564204257857
Validation loss: 2.3275254975210307

Epoch: 6| Step: 5
Training loss: 0.522679021364929
Validation loss: 2.313231264168691

Epoch: 6| Step: 6
Training loss: 1.3584214735786002
Validation loss: 2.3245863382094387

Epoch: 6| Step: 7
Training loss: 0.5743768694891823
Validation loss: 2.3537536448993643

Epoch: 6| Step: 8
Training loss: 0.5756646461377729
Validation loss: 2.3060672546099372

Epoch: 6| Step: 9
Training loss: 0.7093031825879584
Validation loss: 2.2443618570406922

Epoch: 6| Step: 10
Training loss: 0.4744446393992083
Validation loss: 2.3342069885165344

Epoch: 6| Step: 11
Training loss: 0.6384817884621655
Validation loss: 2.3312001537815843

Epoch: 6| Step: 12
Training loss: 0.5310230331274562
Validation loss: 2.272446874137007

Epoch: 6| Step: 13
Training loss: 0.32883195558991807
Validation loss: 2.2224646298503012

Epoch: 737| Step: 0
Training loss: 0.4204499583615044
Validation loss: 2.3242027595833754

Epoch: 6| Step: 1
Training loss: 0.6187481523736669
Validation loss: 2.3464626646683424

Epoch: 6| Step: 2
Training loss: 0.3778262921033251
Validation loss: 2.318881470312235

Epoch: 6| Step: 3
Training loss: 1.3377982671560207
Validation loss: 2.320608282117973

Epoch: 6| Step: 4
Training loss: 0.3582938766749964
Validation loss: 2.382598331535849

Epoch: 6| Step: 5
Training loss: 0.5184098955730239
Validation loss: 2.329500005808163

Epoch: 6| Step: 6
Training loss: 0.4569404218358796
Validation loss: 2.3300973988906173

Epoch: 6| Step: 7
Training loss: 0.3897571268720797
Validation loss: 2.377804450211759

Epoch: 6| Step: 8
Training loss: 0.4862285343521661
Validation loss: 2.2981529249675954

Epoch: 6| Step: 9
Training loss: 0.4540180744824892
Validation loss: 2.261910087863839

Epoch: 6| Step: 10
Training loss: 0.41212260871357753
Validation loss: 2.3014534956488197

Epoch: 6| Step: 11
Training loss: 0.46465999914395323
Validation loss: 2.2668272602904787

Epoch: 6| Step: 12
Training loss: 0.46420614607426675
Validation loss: 2.2684806142879057

Epoch: 6| Step: 13
Training loss: 0.5828379985968775
Validation loss: 2.2890822777108415

Epoch: 738| Step: 0
Training loss: 0.5921185818228308
Validation loss: 2.2867521931133665

Epoch: 6| Step: 1
Training loss: 0.6394440069463172
Validation loss: 2.3420238561909796

Epoch: 6| Step: 2
Training loss: 0.32877076273793854
Validation loss: 2.338598083528868

Epoch: 6| Step: 3
Training loss: 1.2586089745991276
Validation loss: 2.3192061698806232

Epoch: 6| Step: 4
Training loss: 0.49609582254772844
Validation loss: 2.3365764873673043

Epoch: 6| Step: 5
Training loss: 0.5089022168288668
Validation loss: 2.315726986682716

Epoch: 6| Step: 6
Training loss: 0.518140235695279
Validation loss: 2.3046740059295048

Epoch: 6| Step: 7
Training loss: 0.35380689729541276
Validation loss: 2.271487180745333

Epoch: 6| Step: 8
Training loss: 0.5166267143717633
Validation loss: 2.2898299910688826

Epoch: 6| Step: 9
Training loss: 0.4507810212503312
Validation loss: 2.2830886657040117

Epoch: 6| Step: 10
Training loss: 0.49434461642528865
Validation loss: 2.296168886456273

Epoch: 6| Step: 11
Training loss: 0.475402483325967
Validation loss: 2.308242874739393

Epoch: 6| Step: 12
Training loss: 0.38265978433418407
Validation loss: 2.3067246466287386

Epoch: 6| Step: 13
Training loss: 0.473639686770547
Validation loss: 2.359741117336699

Epoch: 739| Step: 0
Training loss: 0.38921195993277874
Validation loss: 2.2894718552127205

Epoch: 6| Step: 1
Training loss: 0.502540630481941
Validation loss: 2.289513162490503

Epoch: 6| Step: 2
Training loss: 0.55651950522323
Validation loss: 2.3491022242219217

Epoch: 6| Step: 3
Training loss: 0.6214653918557813
Validation loss: 2.3560078849661927

Epoch: 6| Step: 4
Training loss: 1.3529355345971799
Validation loss: 2.3486526589046175

Epoch: 6| Step: 5
Training loss: 0.4161166574358641
Validation loss: 2.3436403113508493

Epoch: 6| Step: 6
Training loss: 0.5458602755451649
Validation loss: 2.2609558700465073

Epoch: 6| Step: 7
Training loss: 0.5336263465140558
Validation loss: 2.322506595855954

Epoch: 6| Step: 8
Training loss: 0.615805660403788
Validation loss: 2.213113722913756

Epoch: 6| Step: 9
Training loss: 0.5096043006261871
Validation loss: 2.3891516508621904

Epoch: 6| Step: 10
Training loss: 0.6730553217450279
Validation loss: 2.286803200732267

Epoch: 6| Step: 11
Training loss: 0.604040220336207
Validation loss: 2.388587110405604

Epoch: 6| Step: 12
Training loss: 0.3309712825350847
Validation loss: 2.3339441980504696

Epoch: 6| Step: 13
Training loss: 0.7540682287587457
Validation loss: 2.2810618617566303

Epoch: 740| Step: 0
Training loss: 0.5660589797828796
Validation loss: 2.310988551698754

Epoch: 6| Step: 1
Training loss: 0.4257745304802344
Validation loss: 2.38197273506983

Epoch: 6| Step: 2
Training loss: 0.3783684285868897
Validation loss: 2.3434277379244963

Epoch: 6| Step: 3
Training loss: 0.35718753824709387
Validation loss: 2.294980896954646

Epoch: 6| Step: 4
Training loss: 0.4361150482564255
Validation loss: 2.286190539114811

Epoch: 6| Step: 5
Training loss: 0.2388766619845572
Validation loss: 2.324237580540643

Epoch: 6| Step: 6
Training loss: 0.5456160086014368
Validation loss: 2.2969042544761753

Epoch: 6| Step: 7
Training loss: 0.3649040809430327
Validation loss: 2.396881213203315

Epoch: 6| Step: 8
Training loss: 1.2485689554723094
Validation loss: 2.3607945481725316

Epoch: 6| Step: 9
Training loss: 0.5694471613759714
Validation loss: 2.3117090129039717

Epoch: 6| Step: 10
Training loss: 0.42284042660892407
Validation loss: 2.311044555918668

Epoch: 6| Step: 11
Training loss: 0.6767061111936399
Validation loss: 2.2403726646740445

Epoch: 6| Step: 12
Training loss: 0.3827876258086777
Validation loss: 2.393911930033698

Epoch: 6| Step: 13
Training loss: 0.369486087031263
Validation loss: 2.2968796905855866

Epoch: 741| Step: 0
Training loss: 0.5144042389393951
Validation loss: 2.2719778608808103

Epoch: 6| Step: 1
Training loss: 0.44230849966083957
Validation loss: 2.2533055615423305

Epoch: 6| Step: 2
Training loss: 0.4979537577627014
Validation loss: 2.3214981542862128

Epoch: 6| Step: 3
Training loss: 0.45617073102057276
Validation loss: 2.3317366651169835

Epoch: 6| Step: 4
Training loss: 0.3506567094611338
Validation loss: 2.2616959746258964

Epoch: 6| Step: 5
Training loss: 0.6095890256190493
Validation loss: 2.327386980669662

Epoch: 6| Step: 6
Training loss: 1.3396495533777382
Validation loss: 2.291823216420707

Epoch: 6| Step: 7
Training loss: 0.595350968126769
Validation loss: 2.3186248003408845

Epoch: 6| Step: 8
Training loss: 0.3901028003677189
Validation loss: 2.3362439254653413

Epoch: 6| Step: 9
Training loss: 0.6535800024269781
Validation loss: 2.26910707459413

Epoch: 6| Step: 10
Training loss: 0.5553106112386325
Validation loss: 2.3741080590547763

Epoch: 6| Step: 11
Training loss: 0.6154414237261377
Validation loss: 2.3703785033238525

Epoch: 6| Step: 12
Training loss: 0.4208373271009836
Validation loss: 2.3296252031906994

Epoch: 6| Step: 13
Training loss: 0.40507362679583825
Validation loss: 2.2930716044144046

Epoch: 742| Step: 0
Training loss: 1.287587425819118
Validation loss: 2.262570669670102

Epoch: 6| Step: 1
Training loss: 0.41633377088547174
Validation loss: 2.326735118050962

Epoch: 6| Step: 2
Training loss: 0.4315544663827176
Validation loss: 2.3220670106240817

Epoch: 6| Step: 3
Training loss: 0.4755413496668783
Validation loss: 2.290266108966705

Epoch: 6| Step: 4
Training loss: 0.3901292707092753
Validation loss: 2.2986129414826717

Epoch: 6| Step: 5
Training loss: 0.42888113132431305
Validation loss: 2.267721995923015

Epoch: 6| Step: 6
Training loss: 0.5310826037843008
Validation loss: 2.277708965507733

Epoch: 6| Step: 7
Training loss: 0.4461415754559349
Validation loss: 2.268461401146413

Epoch: 6| Step: 8
Training loss: 0.5427345758879502
Validation loss: 2.3192262012231373

Epoch: 6| Step: 9
Training loss: 0.5902762437937632
Validation loss: 2.282343286818738

Epoch: 6| Step: 10
Training loss: 0.3962264325928277
Validation loss: 2.31021625104452

Epoch: 6| Step: 11
Training loss: 0.4882398053700251
Validation loss: 2.331497030881014

Epoch: 6| Step: 12
Training loss: 0.49299930048616314
Validation loss: 2.298471454762644

Epoch: 6| Step: 13
Training loss: 0.8054835631731692
Validation loss: 2.28366627870181

Epoch: 743| Step: 0
Training loss: 0.4592888005145969
Validation loss: 2.3402289069233246

Epoch: 6| Step: 1
Training loss: 0.436369798492141
Validation loss: 2.327885838378683

Epoch: 6| Step: 2
Training loss: 0.4256429360093358
Validation loss: 2.3922105539566325

Epoch: 6| Step: 3
Training loss: 0.7026612553875226
Validation loss: 2.326793879512401

Epoch: 6| Step: 4
Training loss: 0.2829966614647598
Validation loss: 2.2965767271698816

Epoch: 6| Step: 5
Training loss: 1.25790234357411
Validation loss: 2.32153041024161

Epoch: 6| Step: 6
Training loss: 0.5218374364434316
Validation loss: 2.250981998470406

Epoch: 6| Step: 7
Training loss: 0.6648051428875954
Validation loss: 2.2674698528889676

Epoch: 6| Step: 8
Training loss: 0.2867173353362979
Validation loss: 2.3494809717526803

Epoch: 6| Step: 9
Training loss: 0.5184165353887789
Validation loss: 2.2691858379054324

Epoch: 6| Step: 10
Training loss: 0.5182954244253808
Validation loss: 2.3523674286608807

Epoch: 6| Step: 11
Training loss: 0.5045680350523728
Validation loss: 2.323399552661429

Epoch: 6| Step: 12
Training loss: 0.38583500385266084
Validation loss: 2.325254624443359

Epoch: 6| Step: 13
Training loss: 0.6377709710423985
Validation loss: 2.2703738369085578

Epoch: 744| Step: 0
Training loss: 0.49817471826859044
Validation loss: 2.3149714589960326

Epoch: 6| Step: 1
Training loss: 0.3059241191014635
Validation loss: 2.328319707969159

Epoch: 6| Step: 2
Training loss: 0.32313171527311313
Validation loss: 2.282730524512548

Epoch: 6| Step: 3
Training loss: 0.5840619906387027
Validation loss: 2.2647465933367026

Epoch: 6| Step: 4
Training loss: 0.5036965458719503
Validation loss: 2.334988281467582

Epoch: 6| Step: 5
Training loss: 1.2983811606109241
Validation loss: 2.2920769697986536

Epoch: 6| Step: 6
Training loss: 0.48535024232128365
Validation loss: 2.3700391245126866

Epoch: 6| Step: 7
Training loss: 0.6118391783206577
Validation loss: 2.268275852207274

Epoch: 6| Step: 8
Training loss: 0.5278456383573628
Validation loss: 2.3131856536531545

Epoch: 6| Step: 9
Training loss: 0.38604957791021144
Validation loss: 2.3191447798099376

Epoch: 6| Step: 10
Training loss: 0.5297690674760382
Validation loss: 2.2596060490840406

Epoch: 6| Step: 11
Training loss: 0.318494007686016
Validation loss: 2.2454592702737997

Epoch: 6| Step: 12
Training loss: 0.43880207578694896
Validation loss: 2.2867039462063414

Epoch: 6| Step: 13
Training loss: 0.5352670318213547
Validation loss: 2.2563834533501246

Epoch: 745| Step: 0
Training loss: 0.43794291079480335
Validation loss: 2.3265935718911006

Epoch: 6| Step: 1
Training loss: 0.38825890152472964
Validation loss: 2.27837717317712

Epoch: 6| Step: 2
Training loss: 0.3698407552490696
Validation loss: 2.288431174268406

Epoch: 6| Step: 3
Training loss: 0.42864004257140886
Validation loss: 2.3234721161220064

Epoch: 6| Step: 4
Training loss: 1.2561448219262135
Validation loss: 2.316993164098586

Epoch: 6| Step: 5
Training loss: 0.38815906375178116
Validation loss: 2.327639361538784

Epoch: 6| Step: 6
Training loss: 0.34116376824833516
Validation loss: 2.2880320721830256

Epoch: 6| Step: 7
Training loss: 0.3478444265225879
Validation loss: 2.3264137437750083

Epoch: 6| Step: 8
Training loss: 0.3696298737809332
Validation loss: 2.3097154769539325

Epoch: 6| Step: 9
Training loss: 0.4903007553570924
Validation loss: 2.2715830948598024

Epoch: 6| Step: 10
Training loss: 0.778148062490615
Validation loss: 2.2535582632589373

Epoch: 6| Step: 11
Training loss: 0.5432381819077242
Validation loss: 2.3063180902238725

Epoch: 6| Step: 12
Training loss: 0.5924944401733678
Validation loss: 2.3146289203978054

Epoch: 6| Step: 13
Training loss: 0.6586142594480175
Validation loss: 2.2477791649073784

Epoch: 746| Step: 0
Training loss: 0.4850799598849602
Validation loss: 2.2545126425216697

Epoch: 6| Step: 1
Training loss: 1.3428596385683331
Validation loss: 2.3179098858543834

Epoch: 6| Step: 2
Training loss: 0.5383687184970184
Validation loss: 2.2642741678739458

Epoch: 6| Step: 3
Training loss: 0.4302365523159057
Validation loss: 2.3046995279100124

Epoch: 6| Step: 4
Training loss: 0.4221549165125623
Validation loss: 2.3381897335629036

Epoch: 6| Step: 5
Training loss: 0.39329908604087715
Validation loss: 2.3808423086548354

Epoch: 6| Step: 6
Training loss: 0.42259754894410556
Validation loss: 2.335419284617511

Epoch: 6| Step: 7
Training loss: 0.5500017968061748
Validation loss: 2.274127600193735

Epoch: 6| Step: 8
Training loss: 0.46164145298675535
Validation loss: 2.305111904983814

Epoch: 6| Step: 9
Training loss: 0.5412830008826484
Validation loss: 2.255195412073862

Epoch: 6| Step: 10
Training loss: 0.42922695795021787
Validation loss: 2.303961678033279

Epoch: 6| Step: 11
Training loss: 0.500605841995165
Validation loss: 2.304344349421698

Epoch: 6| Step: 12
Training loss: 0.6366426153241984
Validation loss: 2.266862183380738

Epoch: 6| Step: 13
Training loss: 0.6781956095345548
Validation loss: 2.3085102206177086

Epoch: 747| Step: 0
Training loss: 0.45675031064194677
Validation loss: 2.3132637222548653

Epoch: 6| Step: 1
Training loss: 1.2058446291957068
Validation loss: 2.2689716096071586

Epoch: 6| Step: 2
Training loss: 0.5531392585942471
Validation loss: 2.3448794065863834

Epoch: 6| Step: 3
Training loss: 0.3969393407676563
Validation loss: 2.311827399105206

Epoch: 6| Step: 4
Training loss: 0.3761051304945245
Validation loss: 2.3615595149489916

Epoch: 6| Step: 5
Training loss: 0.4099330839933265
Validation loss: 2.2617403077860323

Epoch: 6| Step: 6
Training loss: 0.34533889893992586
Validation loss: 2.350797429058053

Epoch: 6| Step: 7
Training loss: 0.5750180345277842
Validation loss: 2.2148252105414423

Epoch: 6| Step: 8
Training loss: 0.46208262039601966
Validation loss: 2.307423789056444

Epoch: 6| Step: 9
Training loss: 0.5110123978993902
Validation loss: 2.3788539141782996

Epoch: 6| Step: 10
Training loss: 0.5681319420771218
Validation loss: 2.315821443245955

Epoch: 6| Step: 11
Training loss: 0.5575761930291387
Validation loss: 2.247549696220736

Epoch: 6| Step: 12
Training loss: 0.5323554486645548
Validation loss: 2.2312789774936106

Epoch: 6| Step: 13
Training loss: 0.47710158390912827
Validation loss: 2.305017812566319

Epoch: 748| Step: 0
Training loss: 0.5020952431729043
Validation loss: 2.315615131973307

Epoch: 6| Step: 1
Training loss: 0.6253854754948952
Validation loss: 2.328702309019355

Epoch: 6| Step: 2
Training loss: 0.6822383850104217
Validation loss: 2.2545515468775172

Epoch: 6| Step: 3
Training loss: 0.39784138160379945
Validation loss: 2.290269521624096

Epoch: 6| Step: 4
Training loss: 0.42722903844306537
Validation loss: 2.303677956017351

Epoch: 6| Step: 5
Training loss: 0.4711970669895558
Validation loss: 2.3082684150127095

Epoch: 6| Step: 6
Training loss: 1.3231233550481794
Validation loss: 2.297859554019661

Epoch: 6| Step: 7
Training loss: 0.32250165676460235
Validation loss: 2.280060051386446

Epoch: 6| Step: 8
Training loss: 0.46147200741396094
Validation loss: 2.2500272234200653

Epoch: 6| Step: 9
Training loss: 0.58687072187658
Validation loss: 2.329749194416815

Epoch: 6| Step: 10
Training loss: 0.5016775599381617
Validation loss: 2.3427348606722274

Epoch: 6| Step: 11
Training loss: 0.4864155947298899
Validation loss: 2.2981069304109916

Epoch: 6| Step: 12
Training loss: 0.406301165073066
Validation loss: 2.290294157529499

Epoch: 6| Step: 13
Training loss: 0.5538075142521798
Validation loss: 2.323714521861488

Epoch: 749| Step: 0
Training loss: 0.6552839207272578
Validation loss: 2.375443712332033

Epoch: 6| Step: 1
Training loss: 0.49567270809368486
Validation loss: 2.299515652273321

Epoch: 6| Step: 2
Training loss: 0.6018095376213867
Validation loss: 2.2526330956806415

Epoch: 6| Step: 3
Training loss: 0.5511055931503832
Validation loss: 2.2670917372852135

Epoch: 6| Step: 4
Training loss: 0.3443284802594901
Validation loss: 2.262445595050382

Epoch: 6| Step: 5
Training loss: 1.2672465732789269
Validation loss: 2.2776787373826126

Epoch: 6| Step: 6
Training loss: 0.44305942488701083
Validation loss: 2.253153718008102

Epoch: 6| Step: 7
Training loss: 0.4138314484183199
Validation loss: 2.2009856479060907

Epoch: 6| Step: 8
Training loss: 0.46783239833225104
Validation loss: 2.2841346686236643

Epoch: 6| Step: 9
Training loss: 0.5353273828133395
Validation loss: 2.244303130496066

Epoch: 6| Step: 10
Training loss: 0.41350098088688964
Validation loss: 2.2844138104091614

Epoch: 6| Step: 11
Training loss: 0.45141519037875827
Validation loss: 2.2592561238732203

Epoch: 6| Step: 12
Training loss: 0.40166924241666
Validation loss: 2.302775368670944

Epoch: 6| Step: 13
Training loss: 0.4051306967247959
Validation loss: 2.335756090773385

Epoch: 750| Step: 0
Training loss: 0.3608673250421454
Validation loss: 2.3445756154007404

Epoch: 6| Step: 1
Training loss: 0.49021147108336977
Validation loss: 2.3062641849788013

Epoch: 6| Step: 2
Training loss: 0.4749213241370637
Validation loss: 2.29334551953959

Epoch: 6| Step: 3
Training loss: 0.3286988258963767
Validation loss: 2.285991066975343

Epoch: 6| Step: 4
Training loss: 0.4331144312605379
Validation loss: 2.312878261538473

Epoch: 6| Step: 5
Training loss: 0.49359263314618596
Validation loss: 2.300153091689423

Epoch: 6| Step: 6
Training loss: 1.4359522240748261
Validation loss: 2.2507300394604446

Epoch: 6| Step: 7
Training loss: 0.4696321927957284
Validation loss: 2.26488440279318

Epoch: 6| Step: 8
Training loss: 0.2932125094726524
Validation loss: 2.2271225344945305

Epoch: 6| Step: 9
Training loss: 0.3712433764319593
Validation loss: 2.266801116250585

Epoch: 6| Step: 10
Training loss: 0.4977145713275783
Validation loss: 2.272109477376405

Epoch: 6| Step: 11
Training loss: 0.4181578912328605
Validation loss: 2.2443442102250692

Epoch: 6| Step: 12
Training loss: 0.5711885804060612
Validation loss: 2.2805616728489717

Epoch: 6| Step: 13
Training loss: 0.3476154860696971
Validation loss: 2.2996607156586255

Testing loss: 2.947442696686327
