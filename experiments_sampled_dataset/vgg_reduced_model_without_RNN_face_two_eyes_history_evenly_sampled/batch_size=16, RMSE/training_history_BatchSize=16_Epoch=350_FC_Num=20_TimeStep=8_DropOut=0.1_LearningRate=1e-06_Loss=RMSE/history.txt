Epoch: 1| Step: 0
Training loss: 4.350654219617077
Validation loss: 4.458723177506199

Epoch: 6| Step: 1
Training loss: 4.644202705999606
Validation loss: 4.456829595262598

Epoch: 6| Step: 2
Training loss: 4.741120923933121
Validation loss: 4.4509362371839725

Epoch: 6| Step: 3
Training loss: 4.834997526402911
Validation loss: 4.446090535863244

Epoch: 6| Step: 4
Training loss: 4.534894227599755
Validation loss: 4.439723336996374

Epoch: 6| Step: 5
Training loss: 4.150154634834947
Validation loss: 4.43620482207829

Epoch: 6| Step: 6
Training loss: 4.604609518487862
Validation loss: 4.431104514521724

Epoch: 6| Step: 7
Training loss: 4.442859046350368
Validation loss: 4.423986392563103

Epoch: 6| Step: 8
Training loss: 5.133713920323439
Validation loss: 4.42401347999972

Epoch: 6| Step: 9
Training loss: 4.061534356012915
Validation loss: 4.4169654934712606

Epoch: 6| Step: 10
Training loss: 4.912207224423032
Validation loss: 4.411132678829721

Epoch: 6| Step: 11
Training loss: 3.7404342717470342
Validation loss: 4.407110147296616

Epoch: 6| Step: 12
Training loss: 5.045576276880602
Validation loss: 4.40140786314583

Epoch: 6| Step: 13
Training loss: 3.98773853222342
Validation loss: 4.397881325557849

Epoch: 2| Step: 0
Training loss: 4.255919205278731
Validation loss: 4.394721718729261

Epoch: 6| Step: 1
Training loss: 3.7947355294331495
Validation loss: 4.391445442495331

Epoch: 6| Step: 2
Training loss: 4.732283227694549
Validation loss: 4.385245114661379

Epoch: 6| Step: 3
Training loss: 3.6186874937677707
Validation loss: 4.385302108699828

Epoch: 6| Step: 4
Training loss: 3.690152265100185
Validation loss: 4.378198277925626

Epoch: 6| Step: 5
Training loss: 4.604204180580463
Validation loss: 4.374295205158211

Epoch: 6| Step: 6
Training loss: 4.139631274476393
Validation loss: 4.370080491310232

Epoch: 6| Step: 7
Training loss: 5.234442775913823
Validation loss: 4.364911823313099

Epoch: 6| Step: 8
Training loss: 4.837607543696178
Validation loss: 4.3616315946797775

Epoch: 6| Step: 9
Training loss: 3.6442452305204296
Validation loss: 4.360171261174977

Epoch: 6| Step: 10
Training loss: 5.806861685898861
Validation loss: 4.354108418006697

Epoch: 6| Step: 11
Training loss: 4.470074650697962
Validation loss: 4.34655854589763

Epoch: 6| Step: 12
Training loss: 4.758595369320238
Validation loss: 4.344271527251325

Epoch: 6| Step: 13
Training loss: 4.775682386600938
Validation loss: 4.34167910220136

Epoch: 3| Step: 0
Training loss: 4.757485163911587
Validation loss: 4.334649185962501

Epoch: 6| Step: 1
Training loss: 4.167933970684322
Validation loss: 4.330595809867059

Epoch: 6| Step: 2
Training loss: 4.587907670120529
Validation loss: 4.326207140995911

Epoch: 6| Step: 3
Training loss: 4.330288453041882
Validation loss: 4.321050911374325

Epoch: 6| Step: 4
Training loss: 3.9862509705526485
Validation loss: 4.316253293835744

Epoch: 6| Step: 5
Training loss: 4.693842754641217
Validation loss: 4.313009675736684

Epoch: 6| Step: 6
Training loss: 4.791146203122721
Validation loss: 4.305817657989419

Epoch: 6| Step: 7
Training loss: 4.988081268627411
Validation loss: 4.302301099174443

Epoch: 6| Step: 8
Training loss: 4.000199312966422
Validation loss: 4.294750362986346

Epoch: 6| Step: 9
Training loss: 4.338619138370183
Validation loss: 4.29448831240938

Epoch: 6| Step: 10
Training loss: 4.880779068779625
Validation loss: 4.285796932150184

Epoch: 6| Step: 11
Training loss: 3.988007807908598
Validation loss: 4.285060924470674

Epoch: 6| Step: 12
Training loss: 4.566816404537619
Validation loss: 4.274137479476649

Epoch: 6| Step: 13
Training loss: 3.0492805570475765
Validation loss: 4.271245704909522

Epoch: 4| Step: 0
Training loss: 4.7776725200522385
Validation loss: 4.265145506066359

Epoch: 6| Step: 1
Training loss: 4.388032086487178
Validation loss: 4.261668011288007

Epoch: 6| Step: 2
Training loss: 4.571973397792475
Validation loss: 4.254319627584382

Epoch: 6| Step: 3
Training loss: 4.4887163899161155
Validation loss: 4.251415456114342

Epoch: 6| Step: 4
Training loss: 4.72679735341117
Validation loss: 4.244005316150785

Epoch: 6| Step: 5
Training loss: 4.586906889531596
Validation loss: 4.237701895100347

Epoch: 6| Step: 6
Training loss: 5.1265569043325145
Validation loss: 4.231910540853228

Epoch: 6| Step: 7
Training loss: 3.676993969631982
Validation loss: 4.2265772829211805

Epoch: 6| Step: 8
Training loss: 4.2376336090719695
Validation loss: 4.219568232919064

Epoch: 6| Step: 9
Training loss: 4.6449394335457805
Validation loss: 4.21647314373114

Epoch: 6| Step: 10
Training loss: 4.309692132137017
Validation loss: 4.208036069667291

Epoch: 6| Step: 11
Training loss: 3.300946365831353
Validation loss: 4.199085880208318

Epoch: 6| Step: 12
Training loss: 3.891814881033951
Validation loss: 4.193131160134749

Epoch: 6| Step: 13
Training loss: 3.604180367210382
Validation loss: 4.187230554077899

Epoch: 5| Step: 0
Training loss: 3.791687235234962
Validation loss: 4.182675212933504

Epoch: 6| Step: 1
Training loss: 4.908891489172054
Validation loss: 4.176032451868231

Epoch: 6| Step: 2
Training loss: 3.5040506356556507
Validation loss: 4.169006802102766

Epoch: 6| Step: 3
Training loss: 4.323230165198159
Validation loss: 4.1640713309967206

Epoch: 6| Step: 4
Training loss: 4.468065756318186
Validation loss: 4.156097924985205

Epoch: 6| Step: 5
Training loss: 3.6439674325653857
Validation loss: 4.149080945025717

Epoch: 6| Step: 6
Training loss: 3.684030872998429
Validation loss: 4.143239145510613

Epoch: 6| Step: 7
Training loss: 4.849679381794344
Validation loss: 4.136768531215096

Epoch: 6| Step: 8
Training loss: 4.730531246361526
Validation loss: 4.128081610325383

Epoch: 6| Step: 9
Training loss: 5.818360358446543
Validation loss: 4.122214951060228

Epoch: 6| Step: 10
Training loss: 3.278451943617055
Validation loss: 4.115342599772501

Epoch: 6| Step: 11
Training loss: 3.0445356729703885
Validation loss: 4.107535248736988

Epoch: 6| Step: 12
Training loss: 4.6049029882030865
Validation loss: 4.101859220757929

Epoch: 6| Step: 13
Training loss: 4.329132733963176
Validation loss: 4.0963252137816175

Epoch: 6| Step: 0
Training loss: 4.397575768300014
Validation loss: 4.08806833485209

Epoch: 6| Step: 1
Training loss: 4.2191851356177965
Validation loss: 4.081672440334531

Epoch: 6| Step: 2
Training loss: 3.926180721474525
Validation loss: 4.070929702761914

Epoch: 6| Step: 3
Training loss: 3.3831242864760585
Validation loss: 4.065769570436109

Epoch: 6| Step: 4
Training loss: 4.171422812426151
Validation loss: 4.054922893348382

Epoch: 6| Step: 5
Training loss: 4.28467862467514
Validation loss: 4.048427532150829

Epoch: 6| Step: 6
Training loss: 4.192898586845419
Validation loss: 4.042427830284855

Epoch: 6| Step: 7
Training loss: 4.576135821654285
Validation loss: 4.032320493973676

Epoch: 6| Step: 8
Training loss: 5.253667367942919
Validation loss: 4.027458693034322

Epoch: 6| Step: 9
Training loss: 4.020574584436119
Validation loss: 4.019939269436317

Epoch: 6| Step: 10
Training loss: 3.64691744716755
Validation loss: 4.009582893542647

Epoch: 6| Step: 11
Training loss: 4.067974920324925
Validation loss: 4.0018773416139215

Epoch: 6| Step: 12
Training loss: 4.3411246949314135
Validation loss: 3.9947738628881404

Epoch: 6| Step: 13
Training loss: 3.375505480176873
Validation loss: 3.986451301485011

Epoch: 7| Step: 0
Training loss: 4.333468117207229
Validation loss: 3.9779957948861258

Epoch: 6| Step: 1
Training loss: 3.427288911135959
Validation loss: 3.970216408648148

Epoch: 6| Step: 2
Training loss: 3.100703891703211
Validation loss: 3.9641170394821326

Epoch: 6| Step: 3
Training loss: 4.2356891915302395
Validation loss: 3.954000575554932

Epoch: 6| Step: 4
Training loss: 4.135698028652975
Validation loss: 3.9501086076681142

Epoch: 6| Step: 5
Training loss: 3.8234949878506628
Validation loss: 3.9403024139162914

Epoch: 6| Step: 6
Training loss: 4.50661871852611
Validation loss: 3.9314118987907545

Epoch: 6| Step: 7
Training loss: 4.302906810406538
Validation loss: 3.9241615058681143

Epoch: 6| Step: 8
Training loss: 4.141823188592377
Validation loss: 3.9113825828700235

Epoch: 6| Step: 9
Training loss: 4.637536250792762
Validation loss: 3.90678833498583

Epoch: 6| Step: 10
Training loss: 3.919792929649234
Validation loss: 3.8958344213038814

Epoch: 6| Step: 11
Training loss: 4.086832273113793
Validation loss: 3.8902525404137815

Epoch: 6| Step: 12
Training loss: 3.522671567638645
Validation loss: 3.879283008082297

Epoch: 6| Step: 13
Training loss: 4.830276158180009
Validation loss: 3.868928973156871

Epoch: 8| Step: 0
Training loss: 3.471527911810658
Validation loss: 3.8620045305212343

Epoch: 6| Step: 1
Training loss: 3.5954919988261755
Validation loss: 3.852934418468504

Epoch: 6| Step: 2
Training loss: 3.8526104783859147
Validation loss: 3.842486979964439

Epoch: 6| Step: 3
Training loss: 5.100062665367341
Validation loss: 3.833061564862639

Epoch: 6| Step: 4
Training loss: 4.041979092717071
Validation loss: 3.8249896404381563

Epoch: 6| Step: 5
Training loss: 2.848095434829387
Validation loss: 3.8138546418999852

Epoch: 6| Step: 6
Training loss: 4.256451814547011
Validation loss: 3.803349252356367

Epoch: 6| Step: 7
Training loss: 4.342190689025345
Validation loss: 3.795974233657545

Epoch: 6| Step: 8
Training loss: 3.8390598370081324
Validation loss: 3.785834107109904

Epoch: 6| Step: 9
Training loss: 4.097132326565936
Validation loss: 3.774450542989644

Epoch: 6| Step: 10
Training loss: 3.4666348443649264
Validation loss: 3.763889630950837

Epoch: 6| Step: 11
Training loss: 3.6902106715491243
Validation loss: 3.7581988642088358

Epoch: 6| Step: 12
Training loss: 4.312594647681932
Validation loss: 3.747754420694516

Epoch: 6| Step: 13
Training loss: 4.085895953869801
Validation loss: 3.73459487880762

Epoch: 9| Step: 0
Training loss: 4.364788017238043
Validation loss: 3.7253780390364035

Epoch: 6| Step: 1
Training loss: 3.762449833228158
Validation loss: 3.7143695925894775

Epoch: 6| Step: 2
Training loss: 3.363290607293168
Validation loss: 3.7042260029245018

Epoch: 6| Step: 3
Training loss: 3.9405851841608412
Validation loss: 3.693236696681879

Epoch: 6| Step: 4
Training loss: 4.2105307302953765
Validation loss: 3.6811297304644954

Epoch: 6| Step: 5
Training loss: 3.0910884313012645
Validation loss: 3.6730849779588244

Epoch: 6| Step: 6
Training loss: 3.5709089119093083
Validation loss: 3.6641413927259694

Epoch: 6| Step: 7
Training loss: 4.296076807965775
Validation loss: 3.6517738026122846

Epoch: 6| Step: 8
Training loss: 3.538996613754459
Validation loss: 3.638891734280998

Epoch: 6| Step: 9
Training loss: 3.658960886130836
Validation loss: 3.630085281676089

Epoch: 6| Step: 10
Training loss: 4.09009371251423
Validation loss: 3.6185777865809836

Epoch: 6| Step: 11
Training loss: 3.224274717879955
Validation loss: 3.6071952279014083

Epoch: 6| Step: 12
Training loss: 3.490732730579339
Validation loss: 3.59784030918904

Epoch: 6| Step: 13
Training loss: 5.113295238175576
Validation loss: 3.58347278694685

Epoch: 10| Step: 0
Training loss: 3.13639007024469
Validation loss: 3.5795683234667943

Epoch: 6| Step: 1
Training loss: 3.582039769619094
Validation loss: 3.566323390914166

Epoch: 6| Step: 2
Training loss: 3.5787595494416395
Validation loss: 3.5543310766287126

Epoch: 6| Step: 3
Training loss: 3.8762085783417355
Validation loss: 3.5424682511137857

Epoch: 6| Step: 4
Training loss: 4.010594166712504
Validation loss: 3.530620326061622

Epoch: 6| Step: 5
Training loss: 3.3259098041574466
Validation loss: 3.5170805658116135

Epoch: 6| Step: 6
Training loss: 3.7075542245862123
Validation loss: 3.5048761841090808

Epoch: 6| Step: 7
Training loss: 3.4978920174404795
Validation loss: 3.4926680268481443

Epoch: 6| Step: 8
Training loss: 2.9409474373445765
Validation loss: 3.483523549862707

Epoch: 6| Step: 9
Training loss: 4.907455393451957
Validation loss: 3.4726236065172427

Epoch: 6| Step: 10
Training loss: 3.3746176609061664
Validation loss: 3.459244016754374

Epoch: 6| Step: 11
Training loss: 3.2458519507001946
Validation loss: 3.44399402793702

Epoch: 6| Step: 12
Training loss: 4.552535999874286
Validation loss: 3.4348098281501827

Epoch: 6| Step: 13
Training loss: 2.8186075652478757
Validation loss: 3.427405897641289

Epoch: 11| Step: 0
Training loss: 2.8926084569645325
Validation loss: 3.410964495471097

Epoch: 6| Step: 1
Training loss: 4.0345367517408315
Validation loss: 3.399322027282941

Epoch: 6| Step: 2
Training loss: 3.472665037952885
Validation loss: 3.3823467552515174

Epoch: 6| Step: 3
Training loss: 3.2990512986971794
Validation loss: 3.3710473347023724

Epoch: 6| Step: 4
Training loss: 3.5674799862295568
Validation loss: 3.3626782823636394

Epoch: 6| Step: 5
Training loss: 2.961458910122302
Validation loss: 3.3413537675874183

Epoch: 6| Step: 6
Training loss: 4.127982708473363
Validation loss: 3.3281088776703203

Epoch: 6| Step: 7
Training loss: 4.2505622940587315
Validation loss: 3.319407142970423

Epoch: 6| Step: 8
Training loss: 3.651398268121264
Validation loss: 3.3030406624827418

Epoch: 6| Step: 9
Training loss: 3.9363047889925524
Validation loss: 3.2912914788687933

Epoch: 6| Step: 10
Training loss: 3.3242672335073347
Validation loss: 3.2722548611980344

Epoch: 6| Step: 11
Training loss: 2.7164309026846345
Validation loss: 3.2550498627841216

Epoch: 6| Step: 12
Training loss: 3.4763813100168224
Validation loss: 3.2501061440323684

Epoch: 6| Step: 13
Training loss: 3.060227777318588
Validation loss: 3.237338938832171

Epoch: 12| Step: 0
Training loss: 3.294816083854791
Validation loss: 3.2219062572350046

Epoch: 6| Step: 1
Training loss: 3.406446818693764
Validation loss: 3.2164876944078586

Epoch: 6| Step: 2
Training loss: 3.753130686785021
Validation loss: 3.2015386423355405

Epoch: 6| Step: 3
Training loss: 4.383943408433737
Validation loss: 3.186382935217419

Epoch: 6| Step: 4
Training loss: 3.176418714369852
Validation loss: 3.1733978509906406

Epoch: 6| Step: 5
Training loss: 3.4615971128271417
Validation loss: 3.164158381998578

Epoch: 6| Step: 6
Training loss: 3.205788598128185
Validation loss: 3.1429704578922117

Epoch: 6| Step: 7
Training loss: 3.2989865451895675
Validation loss: 3.1299400693068993

Epoch: 6| Step: 8
Training loss: 2.864156924791577
Validation loss: 3.119247728207822

Epoch: 6| Step: 9
Training loss: 3.0904452465461048
Validation loss: 3.0972779825672174

Epoch: 6| Step: 10
Training loss: 3.1526376428890206
Validation loss: 3.0926608889375045

Epoch: 6| Step: 11
Training loss: 3.512700335128116
Validation loss: 3.0757352560724427

Epoch: 6| Step: 12
Training loss: 3.169720298389044
Validation loss: 3.0665531589087327

Epoch: 6| Step: 13
Training loss: 2.806571391505382
Validation loss: 3.0540506809915384

Epoch: 13| Step: 0
Training loss: 2.7467385806079534
Validation loss: 3.038555778396881

Epoch: 6| Step: 1
Training loss: 3.842984006897571
Validation loss: 3.030704342193115

Epoch: 6| Step: 2
Training loss: 3.2290373909617403
Validation loss: 3.0175174855583715

Epoch: 6| Step: 3
Training loss: 3.5873600417426457
Validation loss: 3.0059283330570734

Epoch: 6| Step: 4
Training loss: 2.9888148012239943
Validation loss: 2.9865216995424735

Epoch: 6| Step: 5
Training loss: 2.9432229641374397
Validation loss: 2.9796874381908522

Epoch: 6| Step: 6
Training loss: 3.4443532425759638
Validation loss: 2.967187674389118

Epoch: 6| Step: 7
Training loss: 3.6154944657589496
Validation loss: 2.961372187949297

Epoch: 6| Step: 8
Training loss: 2.807147633968991
Validation loss: 2.949745848803374

Epoch: 6| Step: 9
Training loss: 3.160654149010645
Validation loss: 2.9312038491550747

Epoch: 6| Step: 10
Training loss: 3.070362508041377
Validation loss: 2.919751163850439

Epoch: 6| Step: 11
Training loss: 2.9201168543805407
Validation loss: 2.903322179167807

Epoch: 6| Step: 12
Training loss: 2.6787151207301916
Validation loss: 2.8974129523582253

Epoch: 6| Step: 13
Training loss: 3.602480293553581
Validation loss: 2.879309135231489

Epoch: 14| Step: 0
Training loss: 3.8866267361124684
Validation loss: 2.8681703934650997

Epoch: 6| Step: 1
Training loss: 2.800960433952893
Validation loss: 2.8542095947869686

Epoch: 6| Step: 2
Training loss: 2.856373196205029
Validation loss: 2.839678305431658

Epoch: 6| Step: 3
Training loss: 2.974139331090961
Validation loss: 2.8274795556236207

Epoch: 6| Step: 4
Training loss: 2.8750441174646633
Validation loss: 2.8182441017517634

Epoch: 6| Step: 5
Training loss: 3.1304991592822846
Validation loss: 2.7989166456211034

Epoch: 6| Step: 6
Training loss: 3.0904810425467457
Validation loss: 2.7914118190536352

Epoch: 6| Step: 7
Training loss: 2.587969301575271
Validation loss: 2.775153670841069

Epoch: 6| Step: 8
Training loss: 3.3330767691738727
Validation loss: 2.765356065714278

Epoch: 6| Step: 9
Training loss: 2.723301727534857
Validation loss: 2.755058341405274

Epoch: 6| Step: 10
Training loss: 3.727712393836481
Validation loss: 2.7572726832497665

Epoch: 6| Step: 11
Training loss: 2.5887732501346643
Validation loss: 2.7375498239468232

Epoch: 6| Step: 12
Training loss: 2.6836058326238184
Validation loss: 2.721257158071291

Epoch: 6| Step: 13
Training loss: 3.1750538498524543
Validation loss: 2.713422051348689

Epoch: 15| Step: 0
Training loss: 3.536338852824292
Validation loss: 2.7064597193806668

Epoch: 6| Step: 1
Training loss: 2.497055322201535
Validation loss: 2.6856037469922005

Epoch: 6| Step: 2
Training loss: 3.64733870172521
Validation loss: 2.6798094230780354

Epoch: 6| Step: 3
Training loss: 3.2300318061514504
Validation loss: 2.675234837344768

Epoch: 6| Step: 4
Training loss: 2.7672404081175093
Validation loss: 2.6595293102868482

Epoch: 6| Step: 5
Training loss: 2.728157866499565
Validation loss: 2.6492660435936917

Epoch: 6| Step: 6
Training loss: 2.7779800394383365
Validation loss: 2.642422560298922

Epoch: 6| Step: 7
Training loss: 2.9201887027958526
Validation loss: 2.6334756521326805

Epoch: 6| Step: 8
Training loss: 3.123231311001714
Validation loss: 2.6238945851893845

Epoch: 6| Step: 9
Training loss: 2.66998429354502
Validation loss: 2.601178624617918

Epoch: 6| Step: 10
Training loss: 3.2019118081694447
Validation loss: 2.5972135921800863

Epoch: 6| Step: 11
Training loss: 2.192852991063806
Validation loss: 2.592773396960682

Epoch: 6| Step: 12
Training loss: 2.6063429525435047
Validation loss: 2.5961004697657115

Epoch: 6| Step: 13
Training loss: 2.574951067709566
Validation loss: 2.5878569453612075

Epoch: 16| Step: 0
Training loss: 3.4507957646464327
Validation loss: 2.5699193769592945

Epoch: 6| Step: 1
Training loss: 2.79357843747005
Validation loss: 2.5723863958396804

Epoch: 6| Step: 2
Training loss: 2.46617339675039
Validation loss: 2.5621455738059526

Epoch: 6| Step: 3
Training loss: 2.6299828964663567
Validation loss: 2.5531394362143494

Epoch: 6| Step: 4
Training loss: 2.5444562226883067
Validation loss: 2.5445664179407266

Epoch: 6| Step: 5
Training loss: 3.7928219107776466
Validation loss: 2.5439892174262724

Epoch: 6| Step: 6
Training loss: 3.5521598800212275
Validation loss: 2.544993664172973

Epoch: 6| Step: 7
Training loss: 2.157032258041461
Validation loss: 2.5312247640287837

Epoch: 6| Step: 8
Training loss: 2.535234118001936
Validation loss: 2.5226535603598763

Epoch: 6| Step: 9
Training loss: 2.378366393421119
Validation loss: 2.525462896282719

Epoch: 6| Step: 10
Training loss: 2.628838774904874
Validation loss: 2.520066323507072

Epoch: 6| Step: 11
Training loss: 2.9094063631163984
Validation loss: 2.5184522183593394

Epoch: 6| Step: 12
Training loss: 2.834156664731881
Validation loss: 2.5175972495512595

Epoch: 6| Step: 13
Training loss: 2.5116549612817543
Validation loss: 2.5084130267730926

Epoch: 17| Step: 0
Training loss: 2.8171428082349226
Validation loss: 2.5059446782086647

Epoch: 6| Step: 1
Training loss: 2.809146407590057
Validation loss: 2.5074350014600446

Epoch: 6| Step: 2
Training loss: 3.010755174517887
Validation loss: 2.486525981175358

Epoch: 6| Step: 3
Training loss: 3.3146735204051394
Validation loss: 2.48513916547

Epoch: 6| Step: 4
Training loss: 2.507628627227781
Validation loss: 2.491566152668539

Epoch: 6| Step: 5
Training loss: 2.5286481695560514
Validation loss: 2.491779804394552

Epoch: 6| Step: 6
Training loss: 2.330753967039551
Validation loss: 2.484645132025509

Epoch: 6| Step: 7
Training loss: 2.7357015825010107
Validation loss: 2.484850873444181

Epoch: 6| Step: 8
Training loss: 2.5287619713704017
Validation loss: 2.485650819309984

Epoch: 6| Step: 9
Training loss: 3.2549025898082764
Validation loss: 2.476194091963492

Epoch: 6| Step: 10
Training loss: 2.33410194771206
Validation loss: 2.4765977645748833

Epoch: 6| Step: 11
Training loss: 2.994629503365443
Validation loss: 2.472915725741694

Epoch: 6| Step: 12
Training loss: 2.9269490782514898
Validation loss: 2.4769361265958545

Epoch: 6| Step: 13
Training loss: 2.9436018855905175
Validation loss: 2.4689228542007817

Epoch: 18| Step: 0
Training loss: 2.9302728907343023
Validation loss: 2.465988753121523

Epoch: 6| Step: 1
Training loss: 1.9258482884621855
Validation loss: 2.4759006746194303

Epoch: 6| Step: 2
Training loss: 2.910373838342121
Validation loss: 2.4673643126536895

Epoch: 6| Step: 3
Training loss: 2.6527345619431904
Validation loss: 2.4596084748464597

Epoch: 6| Step: 4
Training loss: 2.3142967461015265
Validation loss: 2.46875098651468

Epoch: 6| Step: 5
Training loss: 3.327290461682937
Validation loss: 2.46654125810531

Epoch: 6| Step: 6
Training loss: 2.6166028636596845
Validation loss: 2.4586413996743737

Epoch: 6| Step: 7
Training loss: 2.2602034320251314
Validation loss: 2.467316811323416

Epoch: 6| Step: 8
Training loss: 2.803855156187181
Validation loss: 2.462282287408154

Epoch: 6| Step: 9
Training loss: 2.9572550639787116
Validation loss: 2.457274586642713

Epoch: 6| Step: 10
Training loss: 3.4921356129045185
Validation loss: 2.452587705542521

Epoch: 6| Step: 11
Training loss: 2.500394980699905
Validation loss: 2.462354769082671

Epoch: 6| Step: 12
Training loss: 2.880362774994874
Validation loss: 2.4605899136259084

Epoch: 6| Step: 13
Training loss: 3.1380300856753296
Validation loss: 2.447835350038734

Epoch: 19| Step: 0
Training loss: 3.001285277655407
Validation loss: 2.4529384753486165

Epoch: 6| Step: 1
Training loss: 3.4093903230904945
Validation loss: 2.445457002632596

Epoch: 6| Step: 2
Training loss: 3.157689889738747
Validation loss: 2.4528170501353768

Epoch: 6| Step: 3
Training loss: 2.596917757308906
Validation loss: 2.4547874054112953

Epoch: 6| Step: 4
Training loss: 2.7497457039906417
Validation loss: 2.4569529976707085

Epoch: 6| Step: 5
Training loss: 2.1771544911803566
Validation loss: 2.4544960758873384

Epoch: 6| Step: 6
Training loss: 2.7340496632628573
Validation loss: 2.4410979812099716

Epoch: 6| Step: 7
Training loss: 2.320007304147206
Validation loss: 2.4491219350722915

Epoch: 6| Step: 8
Training loss: 2.88336523696213
Validation loss: 2.456049614605484

Epoch: 6| Step: 9
Training loss: 2.6337744882510647
Validation loss: 2.443476665363039

Epoch: 6| Step: 10
Training loss: 3.177836861390897
Validation loss: 2.455642060975452

Epoch: 6| Step: 11
Training loss: 2.5352504812634553
Validation loss: 2.4485391307593094

Epoch: 6| Step: 12
Training loss: 2.761899346000235
Validation loss: 2.4450901023011813

Epoch: 6| Step: 13
Training loss: 2.3395428344627267
Validation loss: 2.4517197877768284

Epoch: 20| Step: 0
Training loss: 2.6387058484581982
Validation loss: 2.4501604892785513

Epoch: 6| Step: 1
Training loss: 3.3348108037216524
Validation loss: 2.4458774015188047

Epoch: 6| Step: 2
Training loss: 2.618183185716715
Validation loss: 2.447475267008133

Epoch: 6| Step: 3
Training loss: 3.014716609459596
Validation loss: 2.4581310389903477

Epoch: 6| Step: 4
Training loss: 3.0683971380851727
Validation loss: 2.4538370226075843

Epoch: 6| Step: 5
Training loss: 2.485882955224891
Validation loss: 2.44794108095651

Epoch: 6| Step: 6
Training loss: 2.4604784340551906
Validation loss: 2.4478092530474145

Epoch: 6| Step: 7
Training loss: 2.0561281672505567
Validation loss: 2.450189405080129

Epoch: 6| Step: 8
Training loss: 2.6893237823212077
Validation loss: 2.451893981116671

Epoch: 6| Step: 9
Training loss: 2.67296020599211
Validation loss: 2.4511379358399585

Epoch: 6| Step: 10
Training loss: 3.31165432481493
Validation loss: 2.4524083268611006

Epoch: 6| Step: 11
Training loss: 2.5652886080712625
Validation loss: 2.4547234531755318

Epoch: 6| Step: 12
Training loss: 2.6583229503209584
Validation loss: 2.453549089958843

Epoch: 6| Step: 13
Training loss: 3.0517182809939607
Validation loss: 2.4500637157493514

Epoch: 21| Step: 0
Training loss: 2.747626841205771
Validation loss: 2.442151987290259

Epoch: 6| Step: 1
Training loss: 2.483876880156085
Validation loss: 2.450087691849939

Epoch: 6| Step: 2
Training loss: 3.446867507552912
Validation loss: 2.4518290766721282

Epoch: 6| Step: 3
Training loss: 3.1559665665976917
Validation loss: 2.447802690528813

Epoch: 6| Step: 4
Training loss: 2.7110689774437247
Validation loss: 2.4386132692596365

Epoch: 6| Step: 5
Training loss: 2.871190242054137
Validation loss: 2.4401970858991233

Epoch: 6| Step: 6
Training loss: 3.2627287802739486
Validation loss: 2.4564161100092314

Epoch: 6| Step: 7
Training loss: 2.540081488736412
Validation loss: 2.461778132108803

Epoch: 6| Step: 8
Training loss: 2.2897528430876504
Validation loss: 2.454053003201508

Epoch: 6| Step: 9
Training loss: 2.8406126720803035
Validation loss: 2.4408632586692725

Epoch: 6| Step: 10
Training loss: 2.8163713725519015
Validation loss: 2.4448954527236477

Epoch: 6| Step: 11
Training loss: 2.4525143780612515
Validation loss: 2.448433637171956

Epoch: 6| Step: 12
Training loss: 2.203275851232327
Validation loss: 2.447644514473747

Epoch: 6| Step: 13
Training loss: 2.7022615497987066
Validation loss: 2.447530403810207

Epoch: 22| Step: 0
Training loss: 3.05052631402214
Validation loss: 2.4526687301209944

Epoch: 6| Step: 1
Training loss: 2.6715712346741713
Validation loss: 2.445004958583027

Epoch: 6| Step: 2
Training loss: 3.35544118103852
Validation loss: 2.46219365773552

Epoch: 6| Step: 3
Training loss: 2.8167386645834447
Validation loss: 2.4487725919958705

Epoch: 6| Step: 4
Training loss: 2.247170894913163
Validation loss: 2.454580907091566

Epoch: 6| Step: 5
Training loss: 2.9991243991980783
Validation loss: 2.4455715119455976

Epoch: 6| Step: 6
Training loss: 2.258011753041551
Validation loss: 2.448213883271237

Epoch: 6| Step: 7
Training loss: 2.894638986165545
Validation loss: 2.4503185384916684

Epoch: 6| Step: 8
Training loss: 2.1787154241675566
Validation loss: 2.443375377770337

Epoch: 6| Step: 9
Training loss: 2.302887604899723
Validation loss: 2.4431610912252113

Epoch: 6| Step: 10
Training loss: 2.9817125517411864
Validation loss: 2.4535206954434536

Epoch: 6| Step: 11
Training loss: 3.1752655999536517
Validation loss: 2.448903508581389

Epoch: 6| Step: 12
Training loss: 2.8608074664946543
Validation loss: 2.447787487537504

Epoch: 6| Step: 13
Training loss: 2.306716387971732
Validation loss: 2.450792338359899

Epoch: 23| Step: 0
Training loss: 2.8257439638039767
Validation loss: 2.4609911195142153

Epoch: 6| Step: 1
Training loss: 2.8138240664481153
Validation loss: 2.4490613437199067

Epoch: 6| Step: 2
Training loss: 2.3906766599172187
Validation loss: 2.4455818238418723

Epoch: 6| Step: 3
Training loss: 3.065087918238758
Validation loss: 2.450002069913966

Epoch: 6| Step: 4
Training loss: 3.079588566337237
Validation loss: 2.4453827956211747

Epoch: 6| Step: 5
Training loss: 2.9332959548418236
Validation loss: 2.4553131884574815

Epoch: 6| Step: 6
Training loss: 2.3126177371184085
Validation loss: 2.4530880738914718

Epoch: 6| Step: 7
Training loss: 3.1700668818882245
Validation loss: 2.4588328528902617

Epoch: 6| Step: 8
Training loss: 2.3579372041864723
Validation loss: 2.4595597777634732

Epoch: 6| Step: 9
Training loss: 2.7536048670136677
Validation loss: 2.4455758339950444

Epoch: 6| Step: 10
Training loss: 2.7478077560100993
Validation loss: 2.445581013525685

Epoch: 6| Step: 11
Training loss: 2.841680255607563
Validation loss: 2.451538766542571

Epoch: 6| Step: 12
Training loss: 2.1603142954729084
Validation loss: 2.4443797856980782

Epoch: 6| Step: 13
Training loss: 3.1748170033981356
Validation loss: 2.453545277224064

Epoch: 24| Step: 0
Training loss: 2.6485439042853804
Validation loss: 2.451904055740119

Epoch: 6| Step: 1
Training loss: 2.3012023436809073
Validation loss: 2.4443431239261955

Epoch: 6| Step: 2
Training loss: 2.939134508271924
Validation loss: 2.448975492238392

Epoch: 6| Step: 3
Training loss: 3.4161325983224495
Validation loss: 2.454441851773873

Epoch: 6| Step: 4
Training loss: 2.5726828732750704
Validation loss: 2.447088494125256

Epoch: 6| Step: 5
Training loss: 3.122990228975409
Validation loss: 2.453126884226157

Epoch: 6| Step: 6
Training loss: 2.6083510896933513
Validation loss: 2.452448714916756

Epoch: 6| Step: 7
Training loss: 2.37628329892333
Validation loss: 2.4367130319624204

Epoch: 6| Step: 8
Training loss: 2.6859315243000443
Validation loss: 2.454174440385771

Epoch: 6| Step: 9
Training loss: 2.8153864142366865
Validation loss: 2.4515666872983504

Epoch: 6| Step: 10
Training loss: 2.60438160327196
Validation loss: 2.439313999739076

Epoch: 6| Step: 11
Training loss: 2.230288523325588
Validation loss: 2.4439264535542415

Epoch: 6| Step: 12
Training loss: 3.069030649439211
Validation loss: 2.453236498133217

Epoch: 6| Step: 13
Training loss: 3.0788756099203334
Validation loss: 2.4542191782815745

Epoch: 25| Step: 0
Training loss: 2.9252471232558626
Validation loss: 2.442637993105712

Epoch: 6| Step: 1
Training loss: 2.448158825739736
Validation loss: 2.448236596838647

Epoch: 6| Step: 2
Training loss: 2.785881814705023
Validation loss: 2.457916890517968

Epoch: 6| Step: 3
Training loss: 3.1304846888632167
Validation loss: 2.4435636385280577

Epoch: 6| Step: 4
Training loss: 2.6598159191425945
Validation loss: 2.4472001562472014

Epoch: 6| Step: 5
Training loss: 2.2310270823190415
Validation loss: 2.452081435208716

Epoch: 6| Step: 6
Training loss: 3.0893152993106234
Validation loss: 2.4461683762004696

Epoch: 6| Step: 7
Training loss: 3.8382763850738173
Validation loss: 2.448340067555746

Epoch: 6| Step: 8
Training loss: 2.059332293471377
Validation loss: 2.4421948029276783

Epoch: 6| Step: 9
Training loss: 3.019742536369933
Validation loss: 2.443319375484944

Epoch: 6| Step: 10
Training loss: 2.4331175704125347
Validation loss: 2.4397999073249155

Epoch: 6| Step: 11
Training loss: 2.8960517050832544
Validation loss: 2.452337960824476

Epoch: 6| Step: 12
Training loss: 2.3015286797280714
Validation loss: 2.4491182933947275

Epoch: 6| Step: 13
Training loss: 1.9074181901379392
Validation loss: 2.44923046588328

Epoch: 26| Step: 0
Training loss: 2.546958968761748
Validation loss: 2.4576303350439392

Epoch: 6| Step: 1
Training loss: 2.2955322492823136
Validation loss: 2.4545650797316565

Epoch: 6| Step: 2
Training loss: 2.957593010337109
Validation loss: 2.4509623431229444

Epoch: 6| Step: 3
Training loss: 2.708234335239307
Validation loss: 2.4514349320039295

Epoch: 6| Step: 4
Training loss: 2.4734932445574986
Validation loss: 2.448527116310328

Epoch: 6| Step: 5
Training loss: 3.003570974462367
Validation loss: 2.4559830658183115

Epoch: 6| Step: 6
Training loss: 2.5819668898878807
Validation loss: 2.453175324957816

Epoch: 6| Step: 7
Training loss: 3.177923889698786
Validation loss: 2.449627639168914

Epoch: 6| Step: 8
Training loss: 3.0388327857430775
Validation loss: 2.4611514575179863

Epoch: 6| Step: 9
Training loss: 2.4237745157686996
Validation loss: 2.452695385823585

Epoch: 6| Step: 10
Training loss: 3.2398267125071976
Validation loss: 2.4527441507315846

Epoch: 6| Step: 11
Training loss: 3.3931624941986103
Validation loss: 2.445415502126607

Epoch: 6| Step: 12
Training loss: 2.0272085038130956
Validation loss: 2.4514986500296003

Epoch: 6| Step: 13
Training loss: 2.0018503451131746
Validation loss: 2.447365925104184

Epoch: 27| Step: 0
Training loss: 2.0640592749755986
Validation loss: 2.4438011921702882

Epoch: 6| Step: 1
Training loss: 2.87185646358315
Validation loss: 2.458383789782199

Epoch: 6| Step: 2
Training loss: 3.041585703429807
Validation loss: 2.4457950115337455

Epoch: 6| Step: 3
Training loss: 2.5425228073612534
Validation loss: 2.443134195086964

Epoch: 6| Step: 4
Training loss: 2.8078345703887915
Validation loss: 2.4482081658401293

Epoch: 6| Step: 5
Training loss: 2.896379012328435
Validation loss: 2.4492250910076647

Epoch: 6| Step: 6
Training loss: 2.508560401887304
Validation loss: 2.445314505568828

Epoch: 6| Step: 7
Training loss: 2.722222927205866
Validation loss: 2.4482216394792373

Epoch: 6| Step: 8
Training loss: 2.7825028244511474
Validation loss: 2.4509579332964644

Epoch: 6| Step: 9
Training loss: 3.427726445637196
Validation loss: 2.4391038349465513

Epoch: 6| Step: 10
Training loss: 1.8195123182583692
Validation loss: 2.4299545592385643

Epoch: 6| Step: 11
Training loss: 2.867987664019285
Validation loss: 2.452661766686451

Epoch: 6| Step: 12
Training loss: 3.193762965465289
Validation loss: 2.4552356911112194

Epoch: 6| Step: 13
Training loss: 2.697226555145621
Validation loss: 2.4524155115848205

Epoch: 28| Step: 0
Training loss: 3.146470584282705
Validation loss: 2.4515448788101146

Epoch: 6| Step: 1
Training loss: 3.048286776040262
Validation loss: 2.4364947456651405

Epoch: 6| Step: 2
Training loss: 2.5682099157439766
Validation loss: 2.440223983943473

Epoch: 6| Step: 3
Training loss: 2.524660174475375
Validation loss: 2.4477310504764604

Epoch: 6| Step: 4
Training loss: 2.6717001874521924
Validation loss: 2.452430916907942

Epoch: 6| Step: 5
Training loss: 2.5530216490279267
Validation loss: 2.4491462867545772

Epoch: 6| Step: 6
Training loss: 2.7636327086999444
Validation loss: 2.4445790287654456

Epoch: 6| Step: 7
Training loss: 2.206979504544114
Validation loss: 2.43897090396516

Epoch: 6| Step: 8
Training loss: 2.6583868968035715
Validation loss: 2.452735865834927

Epoch: 6| Step: 9
Training loss: 3.059154317843554
Validation loss: 2.4469649755602068

Epoch: 6| Step: 10
Training loss: 3.445510823949282
Validation loss: 2.4536467039823253

Epoch: 6| Step: 11
Training loss: 2.662963640561423
Validation loss: 2.4556756695862183

Epoch: 6| Step: 12
Training loss: 2.41358493661324
Validation loss: 2.443363387243897

Epoch: 6| Step: 13
Training loss: 2.3986446527245224
Validation loss: 2.442697391493812

Epoch: 29| Step: 0
Training loss: 2.75154191918721
Validation loss: 2.4487206951488547

Epoch: 6| Step: 1
Training loss: 2.4904174258702345
Validation loss: 2.4506979288305426

Epoch: 6| Step: 2
Training loss: 2.5659309307028697
Validation loss: 2.4482780704669516

Epoch: 6| Step: 3
Training loss: 3.201730117394173
Validation loss: 2.4443893800085226

Epoch: 6| Step: 4
Training loss: 2.5882207926175638
Validation loss: 2.4424545947278062

Epoch: 6| Step: 5
Training loss: 2.8487084724911176
Validation loss: 2.434673831214526

Epoch: 6| Step: 6
Training loss: 2.7127684640534637
Validation loss: 2.442007476478505

Epoch: 6| Step: 7
Training loss: 2.7924515678829898
Validation loss: 2.455443287534049

Epoch: 6| Step: 8
Training loss: 2.3611358741010218
Validation loss: 2.44098295011452

Epoch: 6| Step: 9
Training loss: 2.4335147850977914
Validation loss: 2.4380919182407292

Epoch: 6| Step: 10
Training loss: 2.936829510726362
Validation loss: 2.453824145013393

Epoch: 6| Step: 11
Training loss: 3.308729797232429
Validation loss: 2.44429733317136

Epoch: 6| Step: 12
Training loss: 2.363636336960159
Validation loss: 2.455988581435294

Epoch: 6| Step: 13
Training loss: 2.953075428703077
Validation loss: 2.446465420274627

Epoch: 30| Step: 0
Training loss: 3.00719701241205
Validation loss: 2.4538135177607976

Epoch: 6| Step: 1
Training loss: 2.887271069455659
Validation loss: 2.4421424723689484

Epoch: 6| Step: 2
Training loss: 3.130574861331756
Validation loss: 2.45513539037783

Epoch: 6| Step: 3
Training loss: 2.6426332500428766
Validation loss: 2.443682967958423

Epoch: 6| Step: 4
Training loss: 2.4709514990646784
Validation loss: 2.445299712756411

Epoch: 6| Step: 5
Training loss: 2.4733617658943046
Validation loss: 2.4480588864232056

Epoch: 6| Step: 6
Training loss: 2.3384145406197203
Validation loss: 2.4438814936708644

Epoch: 6| Step: 7
Training loss: 3.0404034085895395
Validation loss: 2.4531031917796358

Epoch: 6| Step: 8
Training loss: 2.447006272732357
Validation loss: 2.4523528946457414

Epoch: 6| Step: 9
Training loss: 2.9480794765054217
Validation loss: 2.4495958805694498

Epoch: 6| Step: 10
Training loss: 2.8165922275465496
Validation loss: 2.443336543695922

Epoch: 6| Step: 11
Training loss: 2.6979975939853764
Validation loss: 2.4423808832474174

Epoch: 6| Step: 12
Training loss: 2.228459670946594
Validation loss: 2.446953462557978

Epoch: 6| Step: 13
Training loss: 3.374348754215498
Validation loss: 2.444214777172591

Epoch: 31| Step: 0
Training loss: 2.6116606244583522
Validation loss: 2.4480160241176616

Epoch: 6| Step: 1
Training loss: 2.7735085061883127
Validation loss: 2.447604177022322

Epoch: 6| Step: 2
Training loss: 2.9525275054864935
Validation loss: 2.453445247503574

Epoch: 6| Step: 3
Training loss: 2.8307390303499855
Validation loss: 2.449460303787838

Epoch: 6| Step: 4
Training loss: 2.652474086969269
Validation loss: 2.447374980812635

Epoch: 6| Step: 5
Training loss: 2.780338952512253
Validation loss: 2.450832649489133

Epoch: 6| Step: 6
Training loss: 2.342801118140974
Validation loss: 2.436890296839316

Epoch: 6| Step: 7
Training loss: 2.69031882499016
Validation loss: 2.4356979406291006

Epoch: 6| Step: 8
Training loss: 3.0333196122694064
Validation loss: 2.4433681423319515

Epoch: 6| Step: 9
Training loss: 3.394423646615165
Validation loss: 2.457999598015375

Epoch: 6| Step: 10
Training loss: 2.9121398310152866
Validation loss: 2.4434109502984853

Epoch: 6| Step: 11
Training loss: 2.762542385967161
Validation loss: 2.439531771579953

Epoch: 6| Step: 12
Training loss: 2.3452359384624106
Validation loss: 2.4466647124916236

Epoch: 6| Step: 13
Training loss: 1.7406386260179043
Validation loss: 2.4448585884432594

Epoch: 32| Step: 0
Training loss: 2.5113755817827523
Validation loss: 2.4464188513457428

Epoch: 6| Step: 1
Training loss: 2.544509069611361
Validation loss: 2.4404902536499318

Epoch: 6| Step: 2
Training loss: 2.886762358009591
Validation loss: 2.4520742897578347

Epoch: 6| Step: 3
Training loss: 2.64717850819703
Validation loss: 2.4551303375119677

Epoch: 6| Step: 4
Training loss: 2.9740219688399376
Validation loss: 2.441168600874685

Epoch: 6| Step: 5
Training loss: 2.329358893999734
Validation loss: 2.4457714639903707

Epoch: 6| Step: 6
Training loss: 2.176244826729732
Validation loss: 2.4612577736165053

Epoch: 6| Step: 7
Training loss: 2.3773362564836305
Validation loss: 2.4451461798857714

Epoch: 6| Step: 8
Training loss: 3.18743327949855
Validation loss: 2.4484798850815244

Epoch: 6| Step: 9
Training loss: 2.928151615636607
Validation loss: 2.443586572623336

Epoch: 6| Step: 10
Training loss: 2.7923922283854066
Validation loss: 2.4427601347234607

Epoch: 6| Step: 11
Training loss: 3.413765831110594
Validation loss: 2.4476074763558637

Epoch: 6| Step: 12
Training loss: 2.2933349316983236
Validation loss: 2.438533470263842

Epoch: 6| Step: 13
Training loss: 3.243734923458159
Validation loss: 2.4487754971650015

Epoch: 33| Step: 0
Training loss: 2.1330977587968123
Validation loss: 2.4437556005478296

Epoch: 6| Step: 1
Training loss: 2.9172241404785844
Validation loss: 2.454690274346503

Epoch: 6| Step: 2
Training loss: 2.295763642164322
Validation loss: 2.4443827731740546

Epoch: 6| Step: 3
Training loss: 2.440887737907289
Validation loss: 2.450066457202426

Epoch: 6| Step: 4
Training loss: 3.062272511032245
Validation loss: 2.444801071338143

Epoch: 6| Step: 5
Training loss: 2.6881096614141935
Validation loss: 2.45304077371703

Epoch: 6| Step: 6
Training loss: 2.5656222418934056
Validation loss: 2.441589998545579

Epoch: 6| Step: 7
Training loss: 2.6816235546616185
Validation loss: 2.443864048677708

Epoch: 6| Step: 8
Training loss: 3.0106951486858167
Validation loss: 2.4345880099431665

Epoch: 6| Step: 9
Training loss: 2.9136947931650776
Validation loss: 2.4452156729963894

Epoch: 6| Step: 10
Training loss: 2.8061504320861985
Validation loss: 2.4587041082683543

Epoch: 6| Step: 11
Training loss: 3.3071375212704304
Validation loss: 2.456770366860913

Epoch: 6| Step: 12
Training loss: 2.9393591983020833
Validation loss: 2.4424919933268847

Epoch: 6| Step: 13
Training loss: 1.9909211565747091
Validation loss: 2.439366228079148

Epoch: 34| Step: 0
Training loss: 3.363868157088129
Validation loss: 2.44461417059527

Epoch: 6| Step: 1
Training loss: 2.3420894589559214
Validation loss: 2.453150835613779

Epoch: 6| Step: 2
Training loss: 2.5343685954397537
Validation loss: 2.452886538087344

Epoch: 6| Step: 3
Training loss: 2.833582212699665
Validation loss: 2.449086530283856

Epoch: 6| Step: 4
Training loss: 3.2434920662291447
Validation loss: 2.4453396604832096

Epoch: 6| Step: 5
Training loss: 2.3178768025294403
Validation loss: 2.4509949898173486

Epoch: 6| Step: 6
Training loss: 2.981632270536409
Validation loss: 2.4493447705231923

Epoch: 6| Step: 7
Training loss: 2.5404527819306617
Validation loss: 2.443269811271587

Epoch: 6| Step: 8
Training loss: 2.813137067062509
Validation loss: 2.441858246339662

Epoch: 6| Step: 9
Training loss: 2.1111412283215896
Validation loss: 2.453105231736396

Epoch: 6| Step: 10
Training loss: 3.0642968959140684
Validation loss: 2.4426501682373356

Epoch: 6| Step: 11
Training loss: 2.310567512323305
Validation loss: 2.4469742045716543

Epoch: 6| Step: 12
Training loss: 2.766542616518175
Validation loss: 2.4414726427464357

Epoch: 6| Step: 13
Training loss: 2.745397531042561
Validation loss: 2.442138293308055

Epoch: 35| Step: 0
Training loss: 3.149265530654467
Validation loss: 2.442847936226722

Epoch: 6| Step: 1
Training loss: 1.804460255240924
Validation loss: 2.451581337725023

Epoch: 6| Step: 2
Training loss: 2.1395385658263333
Validation loss: 2.4543081471104604

Epoch: 6| Step: 3
Training loss: 1.7333778745479274
Validation loss: 2.458347996966423

Epoch: 6| Step: 4
Training loss: 3.017248635682649
Validation loss: 2.439568010702439

Epoch: 6| Step: 5
Training loss: 3.551579384652451
Validation loss: 2.4592103865747816

Epoch: 6| Step: 6
Training loss: 2.904752940507289
Validation loss: 2.448502360600985

Epoch: 6| Step: 7
Training loss: 2.3802115831972026
Validation loss: 2.4560499820253563

Epoch: 6| Step: 8
Training loss: 2.568306276185903
Validation loss: 2.448099867214825

Epoch: 6| Step: 9
Training loss: 3.025561471330053
Validation loss: 2.450406025748947

Epoch: 6| Step: 10
Training loss: 2.834288398740306
Validation loss: 2.4451571928962874

Epoch: 6| Step: 11
Training loss: 2.6807425065366757
Validation loss: 2.457785276414703

Epoch: 6| Step: 12
Training loss: 3.0816911671725156
Validation loss: 2.4580323092526446

Epoch: 6| Step: 13
Training loss: 2.8403972941536284
Validation loss: 2.454203163696095

Epoch: 36| Step: 0
Training loss: 2.655850907806127
Validation loss: 2.4552029029356324

Epoch: 6| Step: 1
Training loss: 2.6436506464621137
Validation loss: 2.433454225483949

Epoch: 6| Step: 2
Training loss: 2.5202791745086808
Validation loss: 2.455374385633095

Epoch: 6| Step: 3
Training loss: 2.5768302671929386
Validation loss: 2.450492865439989

Epoch: 6| Step: 4
Training loss: 2.998647066856549
Validation loss: 2.447736191931303

Epoch: 6| Step: 5
Training loss: 3.0961112827340753
Validation loss: 2.4510307524687085

Epoch: 6| Step: 6
Training loss: 2.537549879965032
Validation loss: 2.4488359793862413

Epoch: 6| Step: 7
Training loss: 3.043965833715315
Validation loss: 2.4514022075056507

Epoch: 6| Step: 8
Training loss: 1.9331203304990408
Validation loss: 2.4463886271754545

Epoch: 6| Step: 9
Training loss: 2.7599492858981995
Validation loss: 2.4476643718776154

Epoch: 6| Step: 10
Training loss: 2.59146385094353
Validation loss: 2.4486938401846823

Epoch: 6| Step: 11
Training loss: 3.0966216352273026
Validation loss: 2.443260254535583

Epoch: 6| Step: 12
Training loss: 2.632720221195568
Validation loss: 2.4531663648583373

Epoch: 6| Step: 13
Training loss: 3.012692463531878
Validation loss: 2.4538234721922376

Epoch: 37| Step: 0
Training loss: 2.323083937115023
Validation loss: 2.4399911767634315

Epoch: 6| Step: 1
Training loss: 2.0753189301416297
Validation loss: 2.4457929104501153

Epoch: 6| Step: 2
Training loss: 2.9078700974636305
Validation loss: 2.451048719103999

Epoch: 6| Step: 3
Training loss: 2.7579006796941794
Validation loss: 2.444436327400913

Epoch: 6| Step: 4
Training loss: 3.073908517542243
Validation loss: 2.4543455416143596

Epoch: 6| Step: 5
Training loss: 2.929919424413772
Validation loss: 2.446445105683916

Epoch: 6| Step: 6
Training loss: 3.2504646262588457
Validation loss: 2.4508653418437265

Epoch: 6| Step: 7
Training loss: 2.572333101098653
Validation loss: 2.4455808174983136

Epoch: 6| Step: 8
Training loss: 2.4048870239369644
Validation loss: 2.4426770634080417

Epoch: 6| Step: 9
Training loss: 3.0437416593527438
Validation loss: 2.4483022263562604

Epoch: 6| Step: 10
Training loss: 2.752779856079152
Validation loss: 2.4465071235489773

Epoch: 6| Step: 11
Training loss: 2.671745787948382
Validation loss: 2.4485293956573804

Epoch: 6| Step: 12
Training loss: 2.625440106509507
Validation loss: 2.444542574482095

Epoch: 6| Step: 13
Training loss: 2.461794749315293
Validation loss: 2.4535235113999527

Epoch: 38| Step: 0
Training loss: 2.71817291098249
Validation loss: 2.453703863808162

Epoch: 6| Step: 1
Training loss: 2.107608309640393
Validation loss: 2.4369179188660213

Epoch: 6| Step: 2
Training loss: 2.5185408663952873
Validation loss: 2.458160811124083

Epoch: 6| Step: 3
Training loss: 2.970942601088894
Validation loss: 2.4470802052713347

Epoch: 6| Step: 4
Training loss: 2.5401772267546123
Validation loss: 2.4441582334911995

Epoch: 6| Step: 5
Training loss: 2.7924762424971297
Validation loss: 2.4523995542148582

Epoch: 6| Step: 6
Training loss: 3.1664245077868483
Validation loss: 2.4609781189310826

Epoch: 6| Step: 7
Training loss: 2.533459958458886
Validation loss: 2.4608327233556238

Epoch: 6| Step: 8
Training loss: 2.7840869450585166
Validation loss: 2.4510154643821864

Epoch: 6| Step: 9
Training loss: 2.8234356523939463
Validation loss: 2.4578792249238486

Epoch: 6| Step: 10
Training loss: 2.5735266164556116
Validation loss: 2.446473503728833

Epoch: 6| Step: 11
Training loss: 2.5580189299431044
Validation loss: 2.459546636197338

Epoch: 6| Step: 12
Training loss: 2.8200471282970874
Validation loss: 2.4450451376025546

Epoch: 6| Step: 13
Training loss: 3.4630864276813567
Validation loss: 2.444341098681839

Epoch: 39| Step: 0
Training loss: 2.4090989327010845
Validation loss: 2.453698546792722

Epoch: 6| Step: 1
Training loss: 2.3572695603108826
Validation loss: 2.4576997244589527

Epoch: 6| Step: 2
Training loss: 2.9203934610817934
Validation loss: 2.446729097495524

Epoch: 6| Step: 3
Training loss: 1.9954389181095902
Validation loss: 2.4511456127203664

Epoch: 6| Step: 4
Training loss: 3.0389680430974875
Validation loss: 2.4373860339122726

Epoch: 6| Step: 5
Training loss: 2.4707781995140414
Validation loss: 2.449299584581184

Epoch: 6| Step: 6
Training loss: 2.9107578551820326
Validation loss: 2.446611903327322

Epoch: 6| Step: 7
Training loss: 2.881402722860196
Validation loss: 2.459338873278269

Epoch: 6| Step: 8
Training loss: 3.2532130278038145
Validation loss: 2.4502588283962594

Epoch: 6| Step: 9
Training loss: 2.42493162157064
Validation loss: 2.445901459533354

Epoch: 6| Step: 10
Training loss: 3.373621906507368
Validation loss: 2.4470781540061344

Epoch: 6| Step: 11
Training loss: 2.6015934756156125
Validation loss: 2.4457336952069912

Epoch: 6| Step: 12
Training loss: 2.6946744744163977
Validation loss: 2.45252599144068

Epoch: 6| Step: 13
Training loss: 2.0914669969961097
Validation loss: 2.4438604495178033

Epoch: 40| Step: 0
Training loss: 3.474931175593247
Validation loss: 2.453970618175113

Epoch: 6| Step: 1
Training loss: 2.9220176294775393
Validation loss: 2.452694671928652

Epoch: 6| Step: 2
Training loss: 2.3005176127604616
Validation loss: 2.4567466594630205

Epoch: 6| Step: 3
Training loss: 2.487419134771293
Validation loss: 2.4559753988396094

Epoch: 6| Step: 4
Training loss: 2.5201720849575078
Validation loss: 2.449833210308673

Epoch: 6| Step: 5
Training loss: 2.5843272194372027
Validation loss: 2.4480894297890377

Epoch: 6| Step: 6
Training loss: 2.5381130849656746
Validation loss: 2.458036607827403

Epoch: 6| Step: 7
Training loss: 2.6554903627140667
Validation loss: 2.4510817453636196

Epoch: 6| Step: 8
Training loss: 2.819218558129791
Validation loss: 2.4480892852753553

Epoch: 6| Step: 9
Training loss: 2.733566775083933
Validation loss: 2.453753491516105

Epoch: 6| Step: 10
Training loss: 2.826451433402545
Validation loss: 2.4508314507402558

Epoch: 6| Step: 11
Training loss: 2.1481860204381187
Validation loss: 2.450308393004738

Epoch: 6| Step: 12
Training loss: 2.556489641293557
Validation loss: 2.4317750193453866

Epoch: 6| Step: 13
Training loss: 3.7434761520365933
Validation loss: 2.4480194014384247

Epoch: 41| Step: 0
Training loss: 3.1415844111379037
Validation loss: 2.4473325564410264

Epoch: 6| Step: 1
Training loss: 3.019950492149933
Validation loss: 2.4437523946253883

Epoch: 6| Step: 2
Training loss: 2.2369339168236695
Validation loss: 2.4551725694502236

Epoch: 6| Step: 3
Training loss: 2.7751703570887782
Validation loss: 2.441564333549639

Epoch: 6| Step: 4
Training loss: 2.919607823046285
Validation loss: 2.4471887019686305

Epoch: 6| Step: 5
Training loss: 2.6734675072970764
Validation loss: 2.4519977277336933

Epoch: 6| Step: 6
Training loss: 2.482782777352671
Validation loss: 2.45402192031681

Epoch: 6| Step: 7
Training loss: 2.7544136175188525
Validation loss: 2.4485435988628788

Epoch: 6| Step: 8
Training loss: 2.911779578177175
Validation loss: 2.4444703554114504

Epoch: 6| Step: 9
Training loss: 3.0139424269960884
Validation loss: 2.462981471624921

Epoch: 6| Step: 10
Training loss: 2.2579237966594436
Validation loss: 2.443607150177768

Epoch: 6| Step: 11
Training loss: 2.7337715572977626
Validation loss: 2.442510910202099

Epoch: 6| Step: 12
Training loss: 2.639940613309886
Validation loss: 2.4535001205775027

Epoch: 6| Step: 13
Training loss: 2.261578333157363
Validation loss: 2.4529447252206062

Epoch: 42| Step: 0
Training loss: 3.1303719696248384
Validation loss: 2.451212315850245

Epoch: 6| Step: 1
Training loss: 2.091007543213646
Validation loss: 2.4538827518339517

Epoch: 6| Step: 2
Training loss: 3.0413151019646874
Validation loss: 2.446549970375308

Epoch: 6| Step: 3
Training loss: 2.4318871062954615
Validation loss: 2.451382278938085

Epoch: 6| Step: 4
Training loss: 3.1044395036717995
Validation loss: 2.438865258241465

Epoch: 6| Step: 5
Training loss: 2.3120980815608414
Validation loss: 2.450163649149001

Epoch: 6| Step: 6
Training loss: 2.9609584354677088
Validation loss: 2.4453508246364963

Epoch: 6| Step: 7
Training loss: 2.113677997682467
Validation loss: 2.4563770755937346

Epoch: 6| Step: 8
Training loss: 3.1168567606298785
Validation loss: 2.4536704711093624

Epoch: 6| Step: 9
Training loss: 2.734316928791839
Validation loss: 2.450691540375408

Epoch: 6| Step: 10
Training loss: 2.768673353662766
Validation loss: 2.470105661019829

Epoch: 6| Step: 11
Training loss: 3.167085536224465
Validation loss: 2.447772909711429

Epoch: 6| Step: 12
Training loss: 2.280253989812679
Validation loss: 2.451914155938564

Epoch: 6| Step: 13
Training loss: 2.4299347681151695
Validation loss: 2.443424497604606

Epoch: 43| Step: 0
Training loss: 2.811190915095327
Validation loss: 2.442399518630013

Epoch: 6| Step: 1
Training loss: 1.5953320149900987
Validation loss: 2.4506510595481044

Epoch: 6| Step: 2
Training loss: 2.8126923389364795
Validation loss: 2.4468206206580745

Epoch: 6| Step: 3
Training loss: 2.7280045770064185
Validation loss: 2.449481267386274

Epoch: 6| Step: 4
Training loss: 2.2810936443099674
Validation loss: 2.455435634530928

Epoch: 6| Step: 5
Training loss: 2.7299603383183983
Validation loss: 2.4546823380553606

Epoch: 6| Step: 6
Training loss: 3.0822565071358436
Validation loss: 2.4566687810491374

Epoch: 6| Step: 7
Training loss: 2.7226298042228003
Validation loss: 2.4353329702013538

Epoch: 6| Step: 8
Training loss: 2.6490936816748385
Validation loss: 2.4459223781688166

Epoch: 6| Step: 9
Training loss: 2.9221139085984
Validation loss: 2.4525116210515328

Epoch: 6| Step: 10
Training loss: 3.5497034029567036
Validation loss: 2.447999039003469

Epoch: 6| Step: 11
Training loss: 2.4477339872550044
Validation loss: 2.4536954374460684

Epoch: 6| Step: 12
Training loss: 2.834322382765553
Validation loss: 2.4432538078098136

Epoch: 6| Step: 13
Training loss: 2.549360782315242
Validation loss: 2.4419655546337182

Epoch: 44| Step: 0
Training loss: 2.751694763921228
Validation loss: 2.4495134979147695

Epoch: 6| Step: 1
Training loss: 2.185298574897763
Validation loss: 2.4543621725846982

Epoch: 6| Step: 2
Training loss: 2.435275113898036
Validation loss: 2.4494970627059773

Epoch: 6| Step: 3
Training loss: 3.2891467303366206
Validation loss: 2.4607581184406317

Epoch: 6| Step: 4
Training loss: 2.643864737832313
Validation loss: 2.4501687907308174

Epoch: 6| Step: 5
Training loss: 2.7221285118356793
Validation loss: 2.456337625693517

Epoch: 6| Step: 6
Training loss: 2.6836596707128213
Validation loss: 2.4375433716808104

Epoch: 6| Step: 7
Training loss: 3.419827061792505
Validation loss: 2.449968683788935

Epoch: 6| Step: 8
Training loss: 2.037544006621319
Validation loss: 2.445578123430706

Epoch: 6| Step: 9
Training loss: 2.9689832093845565
Validation loss: 2.4562630408047665

Epoch: 6| Step: 10
Training loss: 2.7346235761733344
Validation loss: 2.4237248073119155

Epoch: 6| Step: 11
Training loss: 2.4816630214291204
Validation loss: 2.4524747541765457

Epoch: 6| Step: 12
Training loss: 2.4631876029069035
Validation loss: 2.4494048681776985

Epoch: 6| Step: 13
Training loss: 3.109865849536249
Validation loss: 2.453425884115646

Epoch: 45| Step: 0
Training loss: 3.1655978021837248
Validation loss: 2.4617085842845703

Epoch: 6| Step: 1
Training loss: 2.8092130315170674
Validation loss: 2.437949912379931

Epoch: 6| Step: 2
Training loss: 2.6272919049962526
Validation loss: 2.4491131517010603

Epoch: 6| Step: 3
Training loss: 3.216265858664112
Validation loss: 2.4484788631765464

Epoch: 6| Step: 4
Training loss: 3.276203743827501
Validation loss: 2.451821736525798

Epoch: 6| Step: 5
Training loss: 2.555003108789751
Validation loss: 2.4492305276393287

Epoch: 6| Step: 6
Training loss: 2.525911329125102
Validation loss: 2.455015810406049

Epoch: 6| Step: 7
Training loss: 2.253466478943588
Validation loss: 2.452854346132213

Epoch: 6| Step: 8
Training loss: 2.324988178510248
Validation loss: 2.452983414500181

Epoch: 6| Step: 9
Training loss: 2.9815294370706207
Validation loss: 2.45799715118669

Epoch: 6| Step: 10
Training loss: 2.209191809239797
Validation loss: 2.44706714545034

Epoch: 6| Step: 11
Training loss: 2.6362000357829656
Validation loss: 2.4556824438688913

Epoch: 6| Step: 12
Training loss: 2.914474335478123
Validation loss: 2.4488330962733964

Epoch: 6| Step: 13
Training loss: 1.6913031355016868
Validation loss: 2.443956927408995

Epoch: 46| Step: 0
Training loss: 2.1661134771700636
Validation loss: 2.446317862676684

Epoch: 6| Step: 1
Training loss: 2.514297229721897
Validation loss: 2.442494814651199

Epoch: 6| Step: 2
Training loss: 3.0670680018430776
Validation loss: 2.4508548000871286

Epoch: 6| Step: 3
Training loss: 3.147096561333545
Validation loss: 2.45569939880699

Epoch: 6| Step: 4
Training loss: 2.6272308316269752
Validation loss: 2.462031562257859

Epoch: 6| Step: 5
Training loss: 2.9026866109627476
Validation loss: 2.435532113385024

Epoch: 6| Step: 6
Training loss: 2.6984551283940323
Validation loss: 2.442433293717734

Epoch: 6| Step: 7
Training loss: 2.542179577046658
Validation loss: 2.4508462436369447

Epoch: 6| Step: 8
Training loss: 1.516095904313662
Validation loss: 2.447935817925482

Epoch: 6| Step: 9
Training loss: 3.5338663856709274
Validation loss: 2.45153596399222

Epoch: 6| Step: 10
Training loss: 2.2516469226181406
Validation loss: 2.4420776913974476

Epoch: 6| Step: 11
Training loss: 2.549757747736744
Validation loss: 2.447472122521144

Epoch: 6| Step: 12
Training loss: 3.1078162191837664
Validation loss: 2.4552881889745186

Epoch: 6| Step: 13
Training loss: 2.886710325649497
Validation loss: 2.443497298399806

Epoch: 47| Step: 0
Training loss: 2.5626120193931965
Validation loss: 2.4536596462420035

Epoch: 6| Step: 1
Training loss: 2.9852723375364354
Validation loss: 2.4536730324809124

Epoch: 6| Step: 2
Training loss: 2.6656698708374464
Validation loss: 2.4383160466438816

Epoch: 6| Step: 3
Training loss: 2.1509677483248084
Validation loss: 2.4556137731366565

Epoch: 6| Step: 4
Training loss: 2.572550810672635
Validation loss: 2.453543024479108

Epoch: 6| Step: 5
Training loss: 2.8172352241455636
Validation loss: 2.45452008598182

Epoch: 6| Step: 6
Training loss: 2.7288487858350394
Validation loss: 2.4636084601225763

Epoch: 6| Step: 7
Training loss: 3.3115290532335897
Validation loss: 2.442348250517317

Epoch: 6| Step: 8
Training loss: 2.694643241609999
Validation loss: 2.4539515143616395

Epoch: 6| Step: 9
Training loss: 2.1890043263190027
Validation loss: 2.4575969910020556

Epoch: 6| Step: 10
Training loss: 3.0563101982943817
Validation loss: 2.4534280836771467

Epoch: 6| Step: 11
Training loss: 2.898246985083889
Validation loss: 2.4486272600445456

Epoch: 6| Step: 12
Training loss: 2.780356617290581
Validation loss: 2.463187788166043

Epoch: 6| Step: 13
Training loss: 2.2389532814620816
Validation loss: 2.4505667367279345

Epoch: 48| Step: 0
Training loss: 2.854448587643847
Validation loss: 2.441895803151706

Epoch: 6| Step: 1
Training loss: 2.5605306733969697
Validation loss: 2.45840169173011

Epoch: 6| Step: 2
Training loss: 2.662930155647155
Validation loss: 2.444834590946643

Epoch: 6| Step: 3
Training loss: 2.615279045606637
Validation loss: 2.451345511686191

Epoch: 6| Step: 4
Training loss: 2.410285736018481
Validation loss: 2.4473475642774853

Epoch: 6| Step: 5
Training loss: 2.8593543213476997
Validation loss: 2.454422397020978

Epoch: 6| Step: 6
Training loss: 3.1397703915369775
Validation loss: 2.458719563859604

Epoch: 6| Step: 7
Training loss: 2.800966562607446
Validation loss: 2.4550345086051455

Epoch: 6| Step: 8
Training loss: 2.645037243442057
Validation loss: 2.4386379014393738

Epoch: 6| Step: 9
Training loss: 3.0924266720761495
Validation loss: 2.4504534923849617

Epoch: 6| Step: 10
Training loss: 2.2904611942690476
Validation loss: 2.4644709760362122

Epoch: 6| Step: 11
Training loss: 2.573488910580747
Validation loss: 2.442164194762437

Epoch: 6| Step: 12
Training loss: 2.8628413967127018
Validation loss: 2.4487379160497995

Epoch: 6| Step: 13
Training loss: 2.403889575859512
Validation loss: 2.450344497857157

Epoch: 49| Step: 0
Training loss: 2.164451811989202
Validation loss: 2.446095480925002

Epoch: 6| Step: 1
Training loss: 2.6353041633646894
Validation loss: 2.4615237343649707

Epoch: 6| Step: 2
Training loss: 2.886064881227937
Validation loss: 2.456610349225381

Epoch: 6| Step: 3
Training loss: 1.820763135149003
Validation loss: 2.447246102722992

Epoch: 6| Step: 4
Training loss: 2.667052797336284
Validation loss: 2.4581979739001945

Epoch: 6| Step: 5
Training loss: 2.7712594949837515
Validation loss: 2.4537001265399154

Epoch: 6| Step: 6
Training loss: 3.06572631295224
Validation loss: 2.455564852237743

Epoch: 6| Step: 7
Training loss: 2.653315819661728
Validation loss: 2.440774136918689

Epoch: 6| Step: 8
Training loss: 3.1860869024174248
Validation loss: 2.455754717380293

Epoch: 6| Step: 9
Training loss: 2.9555318399623527
Validation loss: 2.45018150966463

Epoch: 6| Step: 10
Training loss: 3.0428310064399637
Validation loss: 2.4464229371655057

Epoch: 6| Step: 11
Training loss: 2.755410334219627
Validation loss: 2.451604312889504

Epoch: 6| Step: 12
Training loss: 2.520491164343508
Validation loss: 2.439414435517728

Epoch: 6| Step: 13
Training loss: 2.4371955877121705
Validation loss: 2.4559965349039468

Epoch: 50| Step: 0
Training loss: 2.797399120131196
Validation loss: 2.4524043618212317

Epoch: 6| Step: 1
Training loss: 2.577758763049505
Validation loss: 2.4595270128357587

Epoch: 6| Step: 2
Training loss: 2.4778756592276325
Validation loss: 2.4537267167087586

Epoch: 6| Step: 3
Training loss: 2.188018301460117
Validation loss: 2.452754962393404

Epoch: 6| Step: 4
Training loss: 2.620147124811498
Validation loss: 2.447804398712415

Epoch: 6| Step: 5
Training loss: 3.1530470506694552
Validation loss: 2.4669861271806997

Epoch: 6| Step: 6
Training loss: 2.3613017722048415
Validation loss: 2.444003551115405

Epoch: 6| Step: 7
Training loss: 2.6639392634103736
Validation loss: 2.447853621327939

Epoch: 6| Step: 8
Training loss: 2.424162934546178
Validation loss: 2.450835705982308

Epoch: 6| Step: 9
Training loss: 2.8684102707038095
Validation loss: 2.4482334962622

Epoch: 6| Step: 10
Training loss: 2.428862796663465
Validation loss: 2.4548634982135296

Epoch: 6| Step: 11
Training loss: 2.7172816904599415
Validation loss: 2.4536010481977852

Epoch: 6| Step: 12
Training loss: 3.3975312526407904
Validation loss: 2.4470211254212915

Epoch: 6| Step: 13
Training loss: 3.3147304870689407
Validation loss: 2.436652931124276

Epoch: 51| Step: 0
Training loss: 2.908696447255683
Validation loss: 2.47589319771328

Epoch: 6| Step: 1
Training loss: 3.075041024779531
Validation loss: 2.4565306746259146

Epoch: 6| Step: 2
Training loss: 3.7835761867559015
Validation loss: 2.4438698738296805

Epoch: 6| Step: 3
Training loss: 2.269524421615965
Validation loss: 2.4512591566217976

Epoch: 6| Step: 4
Training loss: 2.8895525618282774
Validation loss: 2.4498260263833784

Epoch: 6| Step: 5
Training loss: 3.0909975697098417
Validation loss: 2.455118306240419

Epoch: 6| Step: 6
Training loss: 2.8729292004602085
Validation loss: 2.4649323863097217

Epoch: 6| Step: 7
Training loss: 2.46143638761415
Validation loss: 2.4615438057866705

Epoch: 6| Step: 8
Training loss: 2.2915003167089134
Validation loss: 2.459545410947012

Epoch: 6| Step: 9
Training loss: 2.3249342386113176
Validation loss: 2.4559823998516075

Epoch: 6| Step: 10
Training loss: 2.278747021562782
Validation loss: 2.459443718775127

Epoch: 6| Step: 11
Training loss: 2.186979722412601
Validation loss: 2.458922498239972

Epoch: 6| Step: 12
Training loss: 2.5459231604812245
Validation loss: 2.4488034127856797

Epoch: 6| Step: 13
Training loss: 2.233553755496524
Validation loss: 2.4675189918937273

Epoch: 52| Step: 0
Training loss: 1.9763059788882213
Validation loss: 2.449872457295556

Epoch: 6| Step: 1
Training loss: 3.048399402061637
Validation loss: 2.44936371087905

Epoch: 6| Step: 2
Training loss: 2.0596195104736177
Validation loss: 2.4485648043136616

Epoch: 6| Step: 3
Training loss: 2.371027987980656
Validation loss: 2.445579762933681

Epoch: 6| Step: 4
Training loss: 2.851154287722764
Validation loss: 2.451041336875032

Epoch: 6| Step: 5
Training loss: 2.6628080306269153
Validation loss: 2.460747519050223

Epoch: 6| Step: 6
Training loss: 2.479593822534198
Validation loss: 2.443588731732474

Epoch: 6| Step: 7
Training loss: 3.2822233663700593
Validation loss: 2.450715862862201

Epoch: 6| Step: 8
Training loss: 3.3117110554434084
Validation loss: 2.4656549036930597

Epoch: 6| Step: 9
Training loss: 2.8716922473561457
Validation loss: 2.4545071252809407

Epoch: 6| Step: 10
Training loss: 2.9200293275588365
Validation loss: 2.461081870630248

Epoch: 6| Step: 11
Training loss: 2.725647956035944
Validation loss: 2.4508682712055267

Epoch: 6| Step: 12
Training loss: 2.3980721558889453
Validation loss: 2.460019623217687

Epoch: 6| Step: 13
Training loss: 2.3192776514057782
Validation loss: 2.4544897401411463

Epoch: 53| Step: 0
Training loss: 3.1625011217921983
Validation loss: 2.445648085412568

Epoch: 6| Step: 1
Training loss: 2.3677633359410852
Validation loss: 2.455741175458626

Epoch: 6| Step: 2
Training loss: 2.6687564608564944
Validation loss: 2.453940781100882

Epoch: 6| Step: 3
Training loss: 2.8417428447398057
Validation loss: 2.4542486071994287

Epoch: 6| Step: 4
Training loss: 2.1650856436337107
Validation loss: 2.4571579434352073

Epoch: 6| Step: 5
Training loss: 2.6989032213146253
Validation loss: 2.4573722748896816

Epoch: 6| Step: 6
Training loss: 3.098022285376346
Validation loss: 2.4584802665689383

Epoch: 6| Step: 7
Training loss: 2.8026430121759587
Validation loss: 2.458855620587264

Epoch: 6| Step: 8
Training loss: 2.113135933947884
Validation loss: 2.4559417750192525

Epoch: 6| Step: 9
Training loss: 2.5291510462605875
Validation loss: 2.4594661639408733

Epoch: 6| Step: 10
Training loss: 2.738794558923018
Validation loss: 2.452396999353451

Epoch: 6| Step: 11
Training loss: 2.961633766462422
Validation loss: 2.4531948293112653

Epoch: 6| Step: 12
Training loss: 2.533087452032072
Validation loss: 2.4490867846499773

Epoch: 6| Step: 13
Training loss: 3.0447702816657998
Validation loss: 2.466938024146386

Epoch: 54| Step: 0
Training loss: 2.505955183616359
Validation loss: 2.4553095998157777

Epoch: 6| Step: 1
Training loss: 2.957039312757337
Validation loss: 2.4581047102660376

Epoch: 6| Step: 2
Training loss: 2.9740325508722094
Validation loss: 2.4526890506520638

Epoch: 6| Step: 3
Training loss: 3.6604838840404454
Validation loss: 2.449530055986992

Epoch: 6| Step: 4
Training loss: 2.0217848697248284
Validation loss: 2.459008638918294

Epoch: 6| Step: 5
Training loss: 2.9996642878568514
Validation loss: 2.454572154743348

Epoch: 6| Step: 6
Training loss: 2.4299045478063936
Validation loss: 2.457830803886593

Epoch: 6| Step: 7
Training loss: 2.465137010832813
Validation loss: 2.4410807767760607

Epoch: 6| Step: 8
Training loss: 2.645275918309937
Validation loss: 2.44313058330927

Epoch: 6| Step: 9
Training loss: 2.664081383243881
Validation loss: 2.4584587410012073

Epoch: 6| Step: 10
Training loss: 2.1732197721725295
Validation loss: 2.445715848331511

Epoch: 6| Step: 11
Training loss: 2.8502923514347542
Validation loss: 2.4496981688718806

Epoch: 6| Step: 12
Training loss: 2.4008944473865266
Validation loss: 2.4462709786410657

Epoch: 6| Step: 13
Training loss: 2.6742165104385522
Validation loss: 2.4565416731241028

Epoch: 55| Step: 0
Training loss: 2.3292667738181647
Validation loss: 2.4578540210288375

Epoch: 6| Step: 1
Training loss: 2.8315489891107966
Validation loss: 2.4448205848268914

Epoch: 6| Step: 2
Training loss: 2.63277365092698
Validation loss: 2.4629179460607395

Epoch: 6| Step: 3
Training loss: 2.532313653203707
Validation loss: 2.445351893452893

Epoch: 6| Step: 4
Training loss: 2.792432613533055
Validation loss: 2.46205061743278

Epoch: 6| Step: 5
Training loss: 3.004654769996918
Validation loss: 2.4600641443520437

Epoch: 6| Step: 6
Training loss: 2.9012006970596054
Validation loss: 2.4585482571358956

Epoch: 6| Step: 7
Training loss: 2.6301147041400292
Validation loss: 2.4531618210491746

Epoch: 6| Step: 8
Training loss: 2.7296481884646027
Validation loss: 2.453394545635912

Epoch: 6| Step: 9
Training loss: 2.6625566001929344
Validation loss: 2.4387970442809888

Epoch: 6| Step: 10
Training loss: 3.2633331871876927
Validation loss: 2.4521389634583954

Epoch: 6| Step: 11
Training loss: 2.8842576289241784
Validation loss: 2.4575602134543657

Epoch: 6| Step: 12
Training loss: 2.143715513969609
Validation loss: 2.445472264141539

Epoch: 6| Step: 13
Training loss: 1.8726799280279438
Validation loss: 2.4686709415087216

Epoch: 56| Step: 0
Training loss: 2.6317662727039126
Validation loss: 2.4588955117699265

Epoch: 6| Step: 1
Training loss: 2.1630643339778977
Validation loss: 2.4619036919711292

Epoch: 6| Step: 2
Training loss: 3.313298111260813
Validation loss: 2.4607873910235787

Epoch: 6| Step: 3
Training loss: 2.862670833370811
Validation loss: 2.4545620007269906

Epoch: 6| Step: 4
Training loss: 2.9234848075721174
Validation loss: 2.452664504190321

Epoch: 6| Step: 5
Training loss: 2.133007334099674
Validation loss: 2.4433616392325908

Epoch: 6| Step: 6
Training loss: 2.3383713102984007
Validation loss: 2.457013257725388

Epoch: 6| Step: 7
Training loss: 2.641515096493844
Validation loss: 2.4703934722168466

Epoch: 6| Step: 8
Training loss: 2.8638499112893627
Validation loss: 2.4502325165715204

Epoch: 6| Step: 9
Training loss: 2.3577976638397957
Validation loss: 2.454536875570345

Epoch: 6| Step: 10
Training loss: 1.9468044702971194
Validation loss: 2.4456826458364676

Epoch: 6| Step: 11
Training loss: 3.2926156973587375
Validation loss: 2.4716061630324364

Epoch: 6| Step: 12
Training loss: 2.453036944515852
Validation loss: 2.454687775132965

Epoch: 6| Step: 13
Training loss: 3.4892437366337274
Validation loss: 2.448447957678708

Epoch: 57| Step: 0
Training loss: 2.7951381980837224
Validation loss: 2.451395362830659

Epoch: 6| Step: 1
Training loss: 2.8692114232457984
Validation loss: 2.453700379382956

Epoch: 6| Step: 2
Training loss: 3.091877534432314
Validation loss: 2.452865876379438

Epoch: 6| Step: 3
Training loss: 2.254523075529657
Validation loss: 2.4458329596549495

Epoch: 6| Step: 4
Training loss: 3.2153217613849847
Validation loss: 2.470650064907957

Epoch: 6| Step: 5
Training loss: 2.8302698590374002
Validation loss: 2.461390764352991

Epoch: 6| Step: 6
Training loss: 2.6570541062307145
Validation loss: 2.451393499758061

Epoch: 6| Step: 7
Training loss: 2.3090999454957712
Validation loss: 2.4604525357639826

Epoch: 6| Step: 8
Training loss: 2.013406641722342
Validation loss: 2.456320246203646

Epoch: 6| Step: 9
Training loss: 2.883093181891836
Validation loss: 2.454718768125226

Epoch: 6| Step: 10
Training loss: 2.946934584726182
Validation loss: 2.4566803069595955

Epoch: 6| Step: 11
Training loss: 2.485986918420354
Validation loss: 2.469176393060004

Epoch: 6| Step: 12
Training loss: 2.1947789748708537
Validation loss: 2.4603014646065335

Epoch: 6| Step: 13
Training loss: 2.8752776302134135
Validation loss: 2.4575355445662166

Epoch: 58| Step: 0
Training loss: 2.5986878605358865
Validation loss: 2.4528769017618464

Epoch: 6| Step: 1
Training loss: 2.8427863531890556
Validation loss: 2.4536446623860853

Epoch: 6| Step: 2
Training loss: 2.266191082970748
Validation loss: 2.4496794236618222

Epoch: 6| Step: 3
Training loss: 2.6589016413521223
Validation loss: 2.459555902947477

Epoch: 6| Step: 4
Training loss: 2.724688303908282
Validation loss: 2.4634226595288684

Epoch: 6| Step: 5
Training loss: 2.387381254109181
Validation loss: 2.457743001491056

Epoch: 6| Step: 6
Training loss: 3.374791315479324
Validation loss: 2.452088904741481

Epoch: 6| Step: 7
Training loss: 2.5269123163140423
Validation loss: 2.46086404211909

Epoch: 6| Step: 8
Training loss: 2.6625324229384026
Validation loss: 2.44566224717399

Epoch: 6| Step: 9
Training loss: 2.986878149202949
Validation loss: 2.455914817905852

Epoch: 6| Step: 10
Training loss: 2.561605716129957
Validation loss: 2.454324519288235

Epoch: 6| Step: 11
Training loss: 2.9143241376240536
Validation loss: 2.4589575330839972

Epoch: 6| Step: 12
Training loss: 2.428309598801066
Validation loss: 2.4502906966305127

Epoch: 6| Step: 13
Training loss: 2.407181893760257
Validation loss: 2.4507606387878735

Epoch: 59| Step: 0
Training loss: 2.265263074708529
Validation loss: 2.4697982963280345

Epoch: 6| Step: 1
Training loss: 2.9015011289450725
Validation loss: 2.446329860728984

Epoch: 6| Step: 2
Training loss: 2.7198966228250256
Validation loss: 2.4622690172116637

Epoch: 6| Step: 3
Training loss: 2.7319297101877
Validation loss: 2.4439215054899894

Epoch: 6| Step: 4
Training loss: 2.647168060616836
Validation loss: 2.4577989750070754

Epoch: 6| Step: 5
Training loss: 2.906971339464708
Validation loss: 2.452780125661913

Epoch: 6| Step: 6
Training loss: 2.749777871610848
Validation loss: 2.4572961721391287

Epoch: 6| Step: 7
Training loss: 2.62009644046948
Validation loss: 2.46371415823953

Epoch: 6| Step: 8
Training loss: 2.5419301902195235
Validation loss: 2.4559047853101386

Epoch: 6| Step: 9
Training loss: 2.533220442548748
Validation loss: 2.459732255874113

Epoch: 6| Step: 10
Training loss: 3.0448495245774194
Validation loss: 2.462460565779613

Epoch: 6| Step: 11
Training loss: 2.5277425696001847
Validation loss: 2.4429661945524956

Epoch: 6| Step: 12
Training loss: 3.0078641812727183
Validation loss: 2.4640706270206785

Epoch: 6| Step: 13
Training loss: 1.94210532667497
Validation loss: 2.4507269057626884

Epoch: 60| Step: 0
Training loss: 3.3473935819865295
Validation loss: 2.4510467370540585

Epoch: 6| Step: 1
Training loss: 2.9702913800270814
Validation loss: 2.450231129197701

Epoch: 6| Step: 2
Training loss: 2.0312460092358635
Validation loss: 2.449432026194446

Epoch: 6| Step: 3
Training loss: 3.113505930911925
Validation loss: 2.4513415261026177

Epoch: 6| Step: 4
Training loss: 1.9783611331433713
Validation loss: 2.4594556600916118

Epoch: 6| Step: 5
Training loss: 3.0693668530200116
Validation loss: 2.4594907363311447

Epoch: 6| Step: 6
Training loss: 1.8510969518313583
Validation loss: 2.4673951194015724

Epoch: 6| Step: 7
Training loss: 2.890598606298421
Validation loss: 2.4411163449347724

Epoch: 6| Step: 8
Training loss: 2.8864075282588653
Validation loss: 2.46373522219103

Epoch: 6| Step: 9
Training loss: 2.9593517717458915
Validation loss: 2.461343303973772

Epoch: 6| Step: 10
Training loss: 3.089296931554336
Validation loss: 2.4565865985400963

Epoch: 6| Step: 11
Training loss: 1.9852279872310385
Validation loss: 2.458589761192863

Epoch: 6| Step: 12
Training loss: 2.568092291691683
Validation loss: 2.4537756554486307

Epoch: 6| Step: 13
Training loss: 2.338474082961393
Validation loss: 2.4608944010309557

Epoch: 61| Step: 0
Training loss: 2.367533743435593
Validation loss: 2.4530128948220105

Epoch: 6| Step: 1
Training loss: 2.3044179985104982
Validation loss: 2.4588849377137674

Epoch: 6| Step: 2
Training loss: 3.0898690590382554
Validation loss: 2.4474067409966374

Epoch: 6| Step: 3
Training loss: 3.8044558852113837
Validation loss: 2.461491685572551

Epoch: 6| Step: 4
Training loss: 2.834682554741752
Validation loss: 2.454583392836324

Epoch: 6| Step: 5
Training loss: 2.5055192105499438
Validation loss: 2.4652336907757153

Epoch: 6| Step: 6
Training loss: 2.7378436077585646
Validation loss: 2.467624478872911

Epoch: 6| Step: 7
Training loss: 2.8589243716163724
Validation loss: 2.4552471908585223

Epoch: 6| Step: 8
Training loss: 2.244042244158272
Validation loss: 2.457259834531738

Epoch: 6| Step: 9
Training loss: 2.4129170783632174
Validation loss: 2.4656094874208514

Epoch: 6| Step: 10
Training loss: 2.8404874426307827
Validation loss: 2.4550708770612335

Epoch: 6| Step: 11
Training loss: 2.072641811327747
Validation loss: 2.4607181991107834

Epoch: 6| Step: 12
Training loss: 2.8009004235018864
Validation loss: 2.4560249931735476

Epoch: 6| Step: 13
Training loss: 2.235364574762804
Validation loss: 2.463934269358106

Epoch: 62| Step: 0
Training loss: 3.686609451604174
Validation loss: 2.4513099403066443

Epoch: 6| Step: 1
Training loss: 2.5795669684622444
Validation loss: 2.4510509176609503

Epoch: 6| Step: 2
Training loss: 2.7307460573149265
Validation loss: 2.4567182674685935

Epoch: 6| Step: 3
Training loss: 2.646901993687067
Validation loss: 2.454614913532597

Epoch: 6| Step: 4
Training loss: 2.6819106241819197
Validation loss: 2.4527656621707346

Epoch: 6| Step: 5
Training loss: 1.8965718085173233
Validation loss: 2.4499625299186376

Epoch: 6| Step: 6
Training loss: 2.571612090419414
Validation loss: 2.465114850253661

Epoch: 6| Step: 7
Training loss: 3.091480385925568
Validation loss: 2.468801073423777

Epoch: 6| Step: 8
Training loss: 2.5552706271661054
Validation loss: 2.4601862841479636

Epoch: 6| Step: 9
Training loss: 2.988677433653421
Validation loss: 2.4537170909964323

Epoch: 6| Step: 10
Training loss: 2.669066084785765
Validation loss: 2.446721816442096

Epoch: 6| Step: 11
Training loss: 2.083930260653727
Validation loss: 2.4496558757826046

Epoch: 6| Step: 12
Training loss: 1.8655821471029121
Validation loss: 2.464576721418314

Epoch: 6| Step: 13
Training loss: 3.0720964447021775
Validation loss: 2.4496412713999782

Epoch: 63| Step: 0
Training loss: 3.58116786789375
Validation loss: 2.4421877424459266

Epoch: 6| Step: 1
Training loss: 2.6916037875961343
Validation loss: 2.4573848532590037

Epoch: 6| Step: 2
Training loss: 2.4307704854727965
Validation loss: 2.462922861165208

Epoch: 6| Step: 3
Training loss: 2.4161537766180414
Validation loss: 2.4501840626509566

Epoch: 6| Step: 4
Training loss: 2.5733962648072444
Validation loss: 2.4529302397070287

Epoch: 6| Step: 5
Training loss: 2.288229728996539
Validation loss: 2.453597866110533

Epoch: 6| Step: 6
Training loss: 3.02785309475267
Validation loss: 2.4686961533538825

Epoch: 6| Step: 7
Training loss: 2.623409516013178
Validation loss: 2.4543669376993815

Epoch: 6| Step: 8
Training loss: 2.9077636714650312
Validation loss: 2.4594743896837357

Epoch: 6| Step: 9
Training loss: 2.4222533884094646
Validation loss: 2.4528993759238853

Epoch: 6| Step: 10
Training loss: 2.349544838187872
Validation loss: 2.455229902844673

Epoch: 6| Step: 11
Training loss: 2.5758978269169717
Validation loss: 2.4602026870248417

Epoch: 6| Step: 12
Training loss: 2.9058611209708762
Validation loss: 2.4604094777927776

Epoch: 6| Step: 13
Training loss: 2.1447801567115867
Validation loss: 2.4779603894225235

Epoch: 64| Step: 0
Training loss: 2.391444844804025
Validation loss: 2.4620682136625156

Epoch: 6| Step: 1
Training loss: 3.0506710564986346
Validation loss: 2.4544950977436137

Epoch: 6| Step: 2
Training loss: 3.351944339226337
Validation loss: 2.452071384837802

Epoch: 6| Step: 3
Training loss: 3.094573402647376
Validation loss: 2.4531237114518283

Epoch: 6| Step: 4
Training loss: 2.7334399559190516
Validation loss: 2.458663642582457

Epoch: 6| Step: 5
Training loss: 2.433573568147154
Validation loss: 2.45961654845979

Epoch: 6| Step: 6
Training loss: 2.087679589135874
Validation loss: 2.4551032331312825

Epoch: 6| Step: 7
Training loss: 2.5501141690894205
Validation loss: 2.4605127351179075

Epoch: 6| Step: 8
Training loss: 2.9004697024678747
Validation loss: 2.465330679410289

Epoch: 6| Step: 9
Training loss: 2.2594991014094297
Validation loss: 2.4626296796769345

Epoch: 6| Step: 10
Training loss: 1.9702958592582622
Validation loss: 2.454997579890302

Epoch: 6| Step: 11
Training loss: 2.4434926631685423
Validation loss: 2.4537703218723363

Epoch: 6| Step: 12
Training loss: 2.5236563100518756
Validation loss: 2.4566764542122024

Epoch: 6| Step: 13
Training loss: 3.7706560265320364
Validation loss: 2.459522508920465

Epoch: 65| Step: 0
Training loss: 2.8968196991186144
Validation loss: 2.46034773325695

Epoch: 6| Step: 1
Training loss: 3.1663721014516084
Validation loss: 2.453282917270372

Epoch: 6| Step: 2
Training loss: 2.265429889564824
Validation loss: 2.4598377203453743

Epoch: 6| Step: 3
Training loss: 2.375824433837122
Validation loss: 2.4674594840025557

Epoch: 6| Step: 4
Training loss: 2.8804280000126434
Validation loss: 2.4418550557740373

Epoch: 6| Step: 5
Training loss: 2.9170698341377306
Validation loss: 2.455445640853815

Epoch: 6| Step: 6
Training loss: 2.587232282858949
Validation loss: 2.454444058780824

Epoch: 6| Step: 7
Training loss: 2.9667036532835986
Validation loss: 2.4632374443985388

Epoch: 6| Step: 8
Training loss: 1.9985280580858251
Validation loss: 2.4526407393354974

Epoch: 6| Step: 9
Training loss: 3.0924729302716445
Validation loss: 2.4692033253098016

Epoch: 6| Step: 10
Training loss: 2.8166459784415743
Validation loss: 2.449767809126756

Epoch: 6| Step: 11
Training loss: 2.164924532519863
Validation loss: 2.462629989900135

Epoch: 6| Step: 12
Training loss: 2.6661186449875762
Validation loss: 2.4660686076233556

Epoch: 6| Step: 13
Training loss: 2.2095254763196035
Validation loss: 2.4501601241144524

Epoch: 66| Step: 0
Training loss: 1.603723398703071
Validation loss: 2.461123052797224

Epoch: 6| Step: 1
Training loss: 1.979814831523484
Validation loss: 2.463490966894003

Epoch: 6| Step: 2
Training loss: 2.568450067463636
Validation loss: 2.45702328162138

Epoch: 6| Step: 3
Training loss: 3.0432454719130586
Validation loss: 2.4508751126455057

Epoch: 6| Step: 4
Training loss: 2.197318575750873
Validation loss: 2.4500642493912212

Epoch: 6| Step: 5
Training loss: 3.478503836044734
Validation loss: 2.4679424870238122

Epoch: 6| Step: 6
Training loss: 3.3691815271520813
Validation loss: 2.457379786761762

Epoch: 6| Step: 7
Training loss: 2.8808252778702514
Validation loss: 2.4524076573102622

Epoch: 6| Step: 8
Training loss: 2.614483247540967
Validation loss: 2.454395631599689

Epoch: 6| Step: 9
Training loss: 2.4270260085074655
Validation loss: 2.462987930207525

Epoch: 6| Step: 10
Training loss: 2.439972039672243
Validation loss: 2.4638764062653835

Epoch: 6| Step: 11
Training loss: 3.4132231285017047
Validation loss: 2.4678841616316025

Epoch: 6| Step: 12
Training loss: 2.5643511342949346
Validation loss: 2.4499533728556813

Epoch: 6| Step: 13
Training loss: 1.9746442691727062
Validation loss: 2.452620979711914

Epoch: 67| Step: 0
Training loss: 3.440788222208378
Validation loss: 2.4529056611691225

Epoch: 6| Step: 1
Training loss: 2.6111036958882257
Validation loss: 2.4509469955118623

Epoch: 6| Step: 2
Training loss: 2.623517208013122
Validation loss: 2.4533117748477395

Epoch: 6| Step: 3
Training loss: 2.209154684043149
Validation loss: 2.460252250329349

Epoch: 6| Step: 4
Training loss: 2.79125386122946
Validation loss: 2.4560914354020187

Epoch: 6| Step: 5
Training loss: 2.6771348188820188
Validation loss: 2.458967539671107

Epoch: 6| Step: 6
Training loss: 3.219303268732503
Validation loss: 2.4707997588650796

Epoch: 6| Step: 7
Training loss: 2.6586686734995766
Validation loss: 2.4475634691648995

Epoch: 6| Step: 8
Training loss: 2.6956450768547207
Validation loss: 2.451015684031763

Epoch: 6| Step: 9
Training loss: 2.3301599812738347
Validation loss: 2.4479159967600044

Epoch: 6| Step: 10
Training loss: 2.1354936787434244
Validation loss: 2.446120451736848

Epoch: 6| Step: 11
Training loss: 2.913219831192125
Validation loss: 2.460926964928207

Epoch: 6| Step: 12
Training loss: 2.4325463259011184
Validation loss: 2.4582371238401586

Epoch: 6| Step: 13
Training loss: 2.2238757604297836
Validation loss: 2.4513109861311833

Epoch: 68| Step: 0
Training loss: 3.0755127021925395
Validation loss: 2.4464492490944774

Epoch: 6| Step: 1
Training loss: 2.662051249909967
Validation loss: 2.453607446317388

Epoch: 6| Step: 2
Training loss: 2.98472712970857
Validation loss: 2.4698642507482274

Epoch: 6| Step: 3
Training loss: 2.612508206149268
Validation loss: 2.455279475692241

Epoch: 6| Step: 4
Training loss: 2.595153153297239
Validation loss: 2.4574315111754346

Epoch: 6| Step: 5
Training loss: 2.890417802962678
Validation loss: 2.458507984924186

Epoch: 6| Step: 6
Training loss: 1.9835672010919012
Validation loss: 2.4573390504506807

Epoch: 6| Step: 7
Training loss: 2.3795367628360937
Validation loss: 2.456560789146087

Epoch: 6| Step: 8
Training loss: 2.00576939515654
Validation loss: 2.4666034135244144

Epoch: 6| Step: 9
Training loss: 2.651082926031281
Validation loss: 2.4445969416186384

Epoch: 6| Step: 10
Training loss: 2.759440948977005
Validation loss: 2.4668055621499456

Epoch: 6| Step: 11
Training loss: 3.0533925309196617
Validation loss: 2.4583251463550573

Epoch: 6| Step: 12
Training loss: 2.535858668279019
Validation loss: 2.462658785313706

Epoch: 6| Step: 13
Training loss: 3.1435243499040917
Validation loss: 2.4560748819002796

Epoch: 69| Step: 0
Training loss: 2.58420590051586
Validation loss: 2.4498560156001083

Epoch: 6| Step: 1
Training loss: 3.1114639089760225
Validation loss: 2.458211366712208

Epoch: 6| Step: 2
Training loss: 2.464811636206211
Validation loss: 2.448882265759358

Epoch: 6| Step: 3
Training loss: 2.958199798005854
Validation loss: 2.4598216547939273

Epoch: 6| Step: 4
Training loss: 2.5580500600180023
Validation loss: 2.470671338472665

Epoch: 6| Step: 5
Training loss: 2.659041430198982
Validation loss: 2.4632059081078164

Epoch: 6| Step: 6
Training loss: 2.8875805467873223
Validation loss: 2.4600121105485253

Epoch: 6| Step: 7
Training loss: 2.3457976488162604
Validation loss: 2.4604061617627044

Epoch: 6| Step: 8
Training loss: 2.4997449744801896
Validation loss: 2.4626850372432663

Epoch: 6| Step: 9
Training loss: 2.6829717767676278
Validation loss: 2.448975345683353

Epoch: 6| Step: 10
Training loss: 2.3110449053479925
Validation loss: 2.4688036460961698

Epoch: 6| Step: 11
Training loss: 2.67558913829057
Validation loss: 2.4604540028131883

Epoch: 6| Step: 12
Training loss: 2.723236241129293
Validation loss: 2.472433198117465

Epoch: 6| Step: 13
Training loss: 2.912054356874641
Validation loss: 2.46534166204661

Epoch: 70| Step: 0
Training loss: 3.0205273878892025
Validation loss: 2.460176572209466

Epoch: 6| Step: 1
Training loss: 2.6002448700255596
Validation loss: 2.465770295524344

Epoch: 6| Step: 2
Training loss: 2.5221981630937673
Validation loss: 2.4617026414881575

Epoch: 6| Step: 3
Training loss: 2.0697589638105027
Validation loss: 2.4580388992155107

Epoch: 6| Step: 4
Training loss: 2.7144687311237417
Validation loss: 2.459276664039566

Epoch: 6| Step: 5
Training loss: 2.522112330126064
Validation loss: 2.4469665847989006

Epoch: 6| Step: 6
Training loss: 2.6960084762949377
Validation loss: 2.462098749314878

Epoch: 6| Step: 7
Training loss: 2.1037996431546415
Validation loss: 2.463892285143711

Epoch: 6| Step: 8
Training loss: 2.576773734424109
Validation loss: 2.459102205001165

Epoch: 6| Step: 9
Training loss: 3.0591533826101234
Validation loss: 2.4474500827173027

Epoch: 6| Step: 10
Training loss: 3.1966713998048153
Validation loss: 2.455903855223495

Epoch: 6| Step: 11
Training loss: 2.883732181224495
Validation loss: 2.454255087718744

Epoch: 6| Step: 12
Training loss: 2.8095228756694457
Validation loss: 2.448451437014159

Epoch: 6| Step: 13
Training loss: 2.3734272216413594
Validation loss: 2.4628358664260084

Epoch: 71| Step: 0
Training loss: 3.1346043815617706
Validation loss: 2.463029205406779

Epoch: 6| Step: 1
Training loss: 2.416152296463998
Validation loss: 2.4426949036239503

Epoch: 6| Step: 2
Training loss: 2.080667188451022
Validation loss: 2.4646608083157635

Epoch: 6| Step: 3
Training loss: 3.0423569266187873
Validation loss: 2.4496935652574865

Epoch: 6| Step: 4
Training loss: 2.878829396023017
Validation loss: 2.458147989554385

Epoch: 6| Step: 5
Training loss: 2.5338318455579723
Validation loss: 2.4511906631822358

Epoch: 6| Step: 6
Training loss: 2.420836392092674
Validation loss: 2.456452047339783

Epoch: 6| Step: 7
Training loss: 2.9668421989831195
Validation loss: 2.452711159399322

Epoch: 6| Step: 8
Training loss: 2.373196670137169
Validation loss: 2.463099601158717

Epoch: 6| Step: 9
Training loss: 3.0080501313901906
Validation loss: 2.460822189918834

Epoch: 6| Step: 10
Training loss: 2.5478048674872547
Validation loss: 2.4483437145792135

Epoch: 6| Step: 11
Training loss: 1.892770983747829
Validation loss: 2.465003504601795

Epoch: 6| Step: 12
Training loss: 3.36916185455268
Validation loss: 2.4533560268974073

Epoch: 6| Step: 13
Training loss: 1.62699261785707
Validation loss: 2.4659745604685246

Epoch: 72| Step: 0
Training loss: 2.8098515226295557
Validation loss: 2.4529191299081323

Epoch: 6| Step: 1
Training loss: 2.9551920443383874
Validation loss: 2.4640583938642555

Epoch: 6| Step: 2
Training loss: 2.455522859604057
Validation loss: 2.459498243296472

Epoch: 6| Step: 3
Training loss: 2.8783423856303156
Validation loss: 2.4638559938330906

Epoch: 6| Step: 4
Training loss: 2.839499178502575
Validation loss: 2.453298055379892

Epoch: 6| Step: 5
Training loss: 2.3160632749620484
Validation loss: 2.4623439183629015

Epoch: 6| Step: 6
Training loss: 2.4702294660845387
Validation loss: 2.458889269725117

Epoch: 6| Step: 7
Training loss: 2.7903111331512114
Validation loss: 2.4601365704981033

Epoch: 6| Step: 8
Training loss: 3.2159103163175518
Validation loss: 2.461571576607476

Epoch: 6| Step: 9
Training loss: 2.7238231112369604
Validation loss: 2.4492445190076824

Epoch: 6| Step: 10
Training loss: 2.247261500110285
Validation loss: 2.4571644872280873

Epoch: 6| Step: 11
Training loss: 2.9492527031365094
Validation loss: 2.4573728966634527

Epoch: 6| Step: 12
Training loss: 2.4746136142179553
Validation loss: 2.4589464155907717

Epoch: 6| Step: 13
Training loss: 1.4310045689870428
Validation loss: 2.4506921565215527

Epoch: 73| Step: 0
Training loss: 2.066080626591957
Validation loss: 2.4547413995717284

Epoch: 6| Step: 1
Training loss: 2.8479271695757964
Validation loss: 2.4582881075156164

Epoch: 6| Step: 2
Training loss: 2.81409409170088
Validation loss: 2.460559791634564

Epoch: 6| Step: 3
Training loss: 2.5565185517731535
Validation loss: 2.4499098802633172

Epoch: 6| Step: 4
Training loss: 2.4630412479962764
Validation loss: 2.4656890849167126

Epoch: 6| Step: 5
Training loss: 2.5231061310401572
Validation loss: 2.446513033049

Epoch: 6| Step: 6
Training loss: 3.350755429852139
Validation loss: 2.4619425049533326

Epoch: 6| Step: 7
Training loss: 2.176752336032254
Validation loss: 2.464410568574456

Epoch: 6| Step: 8
Training loss: 2.0249214769374273
Validation loss: 2.462214539991629

Epoch: 6| Step: 9
Training loss: 3.3719378107565054
Validation loss: 2.469555450425829

Epoch: 6| Step: 10
Training loss: 2.739392369411302
Validation loss: 2.453856161266438

Epoch: 6| Step: 11
Training loss: 2.5720865452326818
Validation loss: 2.464684570647601

Epoch: 6| Step: 12
Training loss: 2.4712956498309326
Validation loss: 2.456275703132663

Epoch: 6| Step: 13
Training loss: 3.1458347817390258
Validation loss: 2.4431831361420673

Epoch: 74| Step: 0
Training loss: 2.698575286793239
Validation loss: 2.451514147910509

Epoch: 6| Step: 1
Training loss: 2.3089384541327957
Validation loss: 2.459378902557659

Epoch: 6| Step: 2
Training loss: 2.1312395380831703
Validation loss: 2.455445963469348

Epoch: 6| Step: 3
Training loss: 2.7611689472174867
Validation loss: 2.4778749722449698

Epoch: 6| Step: 4
Training loss: 3.311991670579618
Validation loss: 2.4544947065904617

Epoch: 6| Step: 5
Training loss: 2.451703674258386
Validation loss: 2.465699276288257

Epoch: 6| Step: 6
Training loss: 3.1626485797221227
Validation loss: 2.450764139945409

Epoch: 6| Step: 7
Training loss: 2.769305178262071
Validation loss: 2.452718382954478

Epoch: 6| Step: 8
Training loss: 2.651903523245207
Validation loss: 2.4635769160938255

Epoch: 6| Step: 9
Training loss: 2.1189152610941075
Validation loss: 2.4527139031194203

Epoch: 6| Step: 10
Training loss: 2.730180062025496
Validation loss: 2.4601845324588862

Epoch: 6| Step: 11
Training loss: 2.180796351436885
Validation loss: 2.446704210432171

Epoch: 6| Step: 12
Training loss: 2.9204478322813197
Validation loss: 2.4571557419958663

Epoch: 6| Step: 13
Training loss: 3.007517138754954
Validation loss: 2.4634467376801656

Epoch: 75| Step: 0
Training loss: 2.4958994615186882
Validation loss: 2.465900727622535

Epoch: 6| Step: 1
Training loss: 2.3886626922605587
Validation loss: 2.4568290140087443

Epoch: 6| Step: 2
Training loss: 2.696238306238586
Validation loss: 2.4491351430428097

Epoch: 6| Step: 3
Training loss: 2.7700876556739478
Validation loss: 2.454781172762919

Epoch: 6| Step: 4
Training loss: 2.593872435104457
Validation loss: 2.465099746751687

Epoch: 6| Step: 5
Training loss: 2.3142320487109242
Validation loss: 2.467893579903267

Epoch: 6| Step: 6
Training loss: 3.0746506965544484
Validation loss: 2.4507941176828836

Epoch: 6| Step: 7
Training loss: 2.5865115539835464
Validation loss: 2.462322286536797

Epoch: 6| Step: 8
Training loss: 2.343970631705129
Validation loss: 2.4606950610844223

Epoch: 6| Step: 9
Training loss: 3.0161179846192283
Validation loss: 2.459902876727394

Epoch: 6| Step: 10
Training loss: 2.955890470744243
Validation loss: 2.46258070660291

Epoch: 6| Step: 11
Training loss: 2.6106434554346576
Validation loss: 2.4507128773529705

Epoch: 6| Step: 12
Training loss: 2.967851362244077
Validation loss: 2.4564169778047176

Epoch: 6| Step: 13
Training loss: 2.031812971301222
Validation loss: 2.4585988621068937

Epoch: 76| Step: 0
Training loss: 3.328756496352913
Validation loss: 2.4607674144872487

Epoch: 6| Step: 1
Training loss: 1.880259131875146
Validation loss: 2.453197885996408

Epoch: 6| Step: 2
Training loss: 2.220835176029359
Validation loss: 2.4695549677102

Epoch: 6| Step: 3
Training loss: 2.3531931549374736
Validation loss: 2.463430598882197

Epoch: 6| Step: 4
Training loss: 2.7468045482779493
Validation loss: 2.4560654986800508

Epoch: 6| Step: 5
Training loss: 3.105578534566916
Validation loss: 2.4518696284933412

Epoch: 6| Step: 6
Training loss: 2.9307158026089155
Validation loss: 2.4579199924383253

Epoch: 6| Step: 7
Training loss: 2.781525844653452
Validation loss: 2.4645174977186755

Epoch: 6| Step: 8
Training loss: 2.8633247153611734
Validation loss: 2.4542996079224704

Epoch: 6| Step: 9
Training loss: 2.117921596383524
Validation loss: 2.4609738708089823

Epoch: 6| Step: 10
Training loss: 2.2255567989810374
Validation loss: 2.4612476325996173

Epoch: 6| Step: 11
Training loss: 2.5832815677829752
Validation loss: 2.4671956157708657

Epoch: 6| Step: 12
Training loss: 2.9592003066839063
Validation loss: 2.4750681836566275

Epoch: 6| Step: 13
Training loss: 2.662301026552303
Validation loss: 2.4599086732783673

Epoch: 77| Step: 0
Training loss: 2.981416684015434
Validation loss: 2.458064192994557

Epoch: 6| Step: 1
Training loss: 3.33301024460613
Validation loss: 2.4593225819119953

Epoch: 6| Step: 2
Training loss: 3.3925429865588166
Validation loss: 2.452833524241343

Epoch: 6| Step: 3
Training loss: 1.93003162605187
Validation loss: 2.460180906114655

Epoch: 6| Step: 4
Training loss: 2.4622589922858995
Validation loss: 2.470853653566402

Epoch: 6| Step: 5
Training loss: 2.7278437623509295
Validation loss: 2.451036105080712

Epoch: 6| Step: 6
Training loss: 2.1766194727027908
Validation loss: 2.4630472370028733

Epoch: 6| Step: 7
Training loss: 2.723258916413196
Validation loss: 2.4495917686452784

Epoch: 6| Step: 8
Training loss: 2.178632583474519
Validation loss: 2.4597479655643886

Epoch: 6| Step: 9
Training loss: 2.45809714481217
Validation loss: 2.4610594745754426

Epoch: 6| Step: 10
Training loss: 2.6311229865436934
Validation loss: 2.4633161277702413

Epoch: 6| Step: 11
Training loss: 3.015866917211219
Validation loss: 2.456879438396463

Epoch: 6| Step: 12
Training loss: 2.1774273711573113
Validation loss: 2.457595416889224

Epoch: 6| Step: 13
Training loss: 2.6344806582076967
Validation loss: 2.4578433220203415

Epoch: 78| Step: 0
Training loss: 2.605559431839992
Validation loss: 2.466608698564804

Epoch: 6| Step: 1
Training loss: 2.639571843251484
Validation loss: 2.4560978359063594

Epoch: 6| Step: 2
Training loss: 2.7671954335250297
Validation loss: 2.449259383244352

Epoch: 6| Step: 3
Training loss: 3.015528385808642
Validation loss: 2.451149444876195

Epoch: 6| Step: 4
Training loss: 2.4272534115730315
Validation loss: 2.460382182017402

Epoch: 6| Step: 5
Training loss: 2.1867541540291113
Validation loss: 2.459720705701464

Epoch: 6| Step: 6
Training loss: 2.4576537491444137
Validation loss: 2.4492930218689617

Epoch: 6| Step: 7
Training loss: 3.1258995287388127
Validation loss: 2.462078736562228

Epoch: 6| Step: 8
Training loss: 2.7006903472247643
Validation loss: 2.4642650010014147

Epoch: 6| Step: 9
Training loss: 2.6493616882839306
Validation loss: 2.4695760731950833

Epoch: 6| Step: 10
Training loss: 2.483941478211875
Validation loss: 2.459576508455719

Epoch: 6| Step: 11
Training loss: 2.9348629416806156
Validation loss: 2.450671992038608

Epoch: 6| Step: 12
Training loss: 2.3011944696045306
Validation loss: 2.4573825988176825

Epoch: 6| Step: 13
Training loss: 2.8561488227536893
Validation loss: 2.456484814145994

Epoch: 79| Step: 0
Training loss: 3.1681162544652053
Validation loss: 2.469853874157991

Epoch: 6| Step: 1
Training loss: 2.415436683805668
Validation loss: 2.4398898978820993

Epoch: 6| Step: 2
Training loss: 2.239913691322497
Validation loss: 2.447093387594971

Epoch: 6| Step: 3
Training loss: 2.9071788329030417
Validation loss: 2.469866498467416

Epoch: 6| Step: 4
Training loss: 2.6500211498927984
Validation loss: 2.452095113913762

Epoch: 6| Step: 5
Training loss: 2.6192551373759696
Validation loss: 2.4618554000737194

Epoch: 6| Step: 6
Training loss: 2.8242393482348773
Validation loss: 2.4623603682935706

Epoch: 6| Step: 7
Training loss: 2.0131622172684223
Validation loss: 2.4542924287142753

Epoch: 6| Step: 8
Training loss: 2.6966804902799466
Validation loss: 2.454703267500494

Epoch: 6| Step: 9
Training loss: 2.859427863294212
Validation loss: 2.463143918829095

Epoch: 6| Step: 10
Training loss: 2.745880162057311
Validation loss: 2.4597886729249794

Epoch: 6| Step: 11
Training loss: 1.9797693104689142
Validation loss: 2.453090051287487

Epoch: 6| Step: 12
Training loss: 2.719142403182106
Validation loss: 2.4514771672111904

Epoch: 6| Step: 13
Training loss: 3.388320350553299
Validation loss: 2.4624509825366174

Epoch: 80| Step: 0
Training loss: 2.063201784902439
Validation loss: 2.4611163351562664

Epoch: 6| Step: 1
Training loss: 2.270222386293365
Validation loss: 2.4548691270426652

Epoch: 6| Step: 2
Training loss: 2.4402790366540867
Validation loss: 2.461654587258351

Epoch: 6| Step: 3
Training loss: 2.9042978600998666
Validation loss: 2.4408910200621685

Epoch: 6| Step: 4
Training loss: 2.729241134753553
Validation loss: 2.453034155173131

Epoch: 6| Step: 5
Training loss: 2.5808347391090427
Validation loss: 2.468185858797541

Epoch: 6| Step: 6
Training loss: 2.6590182072882977
Validation loss: 2.457129966228782

Epoch: 6| Step: 7
Training loss: 2.5865457516688304
Validation loss: 2.456845354779149

Epoch: 6| Step: 8
Training loss: 2.5629331641321813
Validation loss: 2.462581297912548

Epoch: 6| Step: 9
Training loss: 2.618977313315939
Validation loss: 2.4671387965843756

Epoch: 6| Step: 10
Training loss: 2.8318101678253647
Validation loss: 2.459002467532987

Epoch: 6| Step: 11
Training loss: 3.080020998350622
Validation loss: 2.4714811189099017

Epoch: 6| Step: 12
Training loss: 2.6475578355100393
Validation loss: 2.463305834954565

Epoch: 6| Step: 13
Training loss: 3.2579172972877624
Validation loss: 2.4707821018654617

Epoch: 81| Step: 0
Training loss: 1.781070767135648
Validation loss: 2.472985485527939

Epoch: 6| Step: 1
Training loss: 2.6488317685649987
Validation loss: 2.4631357693501994

Epoch: 6| Step: 2
Training loss: 2.6336130798409023
Validation loss: 2.4588156547305244

Epoch: 6| Step: 3
Training loss: 2.7896946636734854
Validation loss: 2.4555167770751236

Epoch: 6| Step: 4
Training loss: 3.2317089942755737
Validation loss: 2.4660669183283184

Epoch: 6| Step: 5
Training loss: 2.3310327996327866
Validation loss: 2.4645394946348333

Epoch: 6| Step: 6
Training loss: 1.96284106747142
Validation loss: 2.4526423145377416

Epoch: 6| Step: 7
Training loss: 2.6986984436001267
Validation loss: 2.4592140383267944

Epoch: 6| Step: 8
Training loss: 2.8446429181725392
Validation loss: 2.4660371761504662

Epoch: 6| Step: 9
Training loss: 2.6051222815341326
Validation loss: 2.4748849815738994

Epoch: 6| Step: 10
Training loss: 3.1505400119087814
Validation loss: 2.455782767669672

Epoch: 6| Step: 11
Training loss: 2.273504406970258
Validation loss: 2.471479518372171

Epoch: 6| Step: 12
Training loss: 3.028385499943343
Validation loss: 2.461150269003292

Epoch: 6| Step: 13
Training loss: 2.8170152659139664
Validation loss: 2.455885143809629

Epoch: 82| Step: 0
Training loss: 1.954491404356637
Validation loss: 2.471461182131354

Epoch: 6| Step: 1
Training loss: 2.8297461821160206
Validation loss: 2.46673878182131

Epoch: 6| Step: 2
Training loss: 2.105596931250055
Validation loss: 2.45904100729127

Epoch: 6| Step: 3
Training loss: 2.934619058975333
Validation loss: 2.452339375231803

Epoch: 6| Step: 4
Training loss: 2.596403029022542
Validation loss: 2.459297304723929

Epoch: 6| Step: 5
Training loss: 2.7473168721837133
Validation loss: 2.4577030989036337

Epoch: 6| Step: 6
Training loss: 2.601530515915206
Validation loss: 2.4631623783919268

Epoch: 6| Step: 7
Training loss: 2.2717564191134585
Validation loss: 2.45978992046185

Epoch: 6| Step: 8
Training loss: 2.7960405010515332
Validation loss: 2.4546233534488726

Epoch: 6| Step: 9
Training loss: 3.1444877289787208
Validation loss: 2.4671510061540083

Epoch: 6| Step: 10
Training loss: 3.0300919985259935
Validation loss: 2.468193528874245

Epoch: 6| Step: 11
Training loss: 2.4107770074021664
Validation loss: 2.463645689527933

Epoch: 6| Step: 12
Training loss: 2.522521522967007
Validation loss: 2.4531071504646698

Epoch: 6| Step: 13
Training loss: 2.948327259454963
Validation loss: 2.465336714328989

Epoch: 83| Step: 0
Training loss: 2.595733252035474
Validation loss: 2.477023134811277

Epoch: 6| Step: 1
Training loss: 3.099830585895765
Validation loss: 2.4621809675344513

Epoch: 6| Step: 2
Training loss: 2.17847345922525
Validation loss: 2.459656972411817

Epoch: 6| Step: 3
Training loss: 2.7870818299160054
Validation loss: 2.4565397664708146

Epoch: 6| Step: 4
Training loss: 2.3012263801684534
Validation loss: 2.4618656260596787

Epoch: 6| Step: 5
Training loss: 3.193348325191127
Validation loss: 2.4598887469258113

Epoch: 6| Step: 6
Training loss: 3.198374728885293
Validation loss: 2.4513869452660284

Epoch: 6| Step: 7
Training loss: 2.5853444136719363
Validation loss: 2.4587245155089494

Epoch: 6| Step: 8
Training loss: 2.0899784793384595
Validation loss: 2.4634375037780707

Epoch: 6| Step: 9
Training loss: 2.712295324101043
Validation loss: 2.474466426639917

Epoch: 6| Step: 10
Training loss: 2.1660101213720657
Validation loss: 2.4617861861100887

Epoch: 6| Step: 11
Training loss: 2.1670201331146464
Validation loss: 2.452261646433342

Epoch: 6| Step: 12
Training loss: 3.2053280581252643
Validation loss: 2.4546224103437173

Epoch: 6| Step: 13
Training loss: 1.9875389167286421
Validation loss: 2.45976753557294

Epoch: 84| Step: 0
Training loss: 2.422617349370752
Validation loss: 2.4674264972114335

Epoch: 6| Step: 1
Training loss: 2.443510811653986
Validation loss: 2.457338665488146

Epoch: 6| Step: 2
Training loss: 2.8313671096261355
Validation loss: 2.4700206250541936

Epoch: 6| Step: 3
Training loss: 2.578384941174748
Validation loss: 2.4559049241445905

Epoch: 6| Step: 4
Training loss: 2.641323651768623
Validation loss: 2.455815559586314

Epoch: 6| Step: 5
Training loss: 2.8264306825822536
Validation loss: 2.4542072067855396

Epoch: 6| Step: 6
Training loss: 2.3595568858388996
Validation loss: 2.4605802418302716

Epoch: 6| Step: 7
Training loss: 2.6122215414630032
Validation loss: 2.4661082469890774

Epoch: 6| Step: 8
Training loss: 2.258969337272164
Validation loss: 2.455097030522608

Epoch: 6| Step: 9
Training loss: 2.8874811345264395
Validation loss: 2.46664797692118

Epoch: 6| Step: 10
Training loss: 2.672876181609308
Validation loss: 2.4633423081700663

Epoch: 6| Step: 11
Training loss: 2.8304405217312207
Validation loss: 2.4618064490860014

Epoch: 6| Step: 12
Training loss: 3.02529637169595
Validation loss: 2.4533752027467046

Epoch: 6| Step: 13
Training loss: 2.3844572800504817
Validation loss: 2.459358102549369

Epoch: 85| Step: 0
Training loss: 2.988943069074086
Validation loss: 2.454558182254509

Epoch: 6| Step: 1
Training loss: 2.7378144349273263
Validation loss: 2.471473479781893

Epoch: 6| Step: 2
Training loss: 2.5523512303920266
Validation loss: 2.4588326193422474

Epoch: 6| Step: 3
Training loss: 3.028018605476172
Validation loss: 2.4502242938067726

Epoch: 6| Step: 4
Training loss: 2.5229756313482206
Validation loss: 2.4502931208132526

Epoch: 6| Step: 5
Training loss: 2.6406950630960337
Validation loss: 2.453636798985718

Epoch: 6| Step: 6
Training loss: 2.628757875061574
Validation loss: 2.4446535422679507

Epoch: 6| Step: 7
Training loss: 2.4564621695399382
Validation loss: 2.4695224449166657

Epoch: 6| Step: 8
Training loss: 2.353195789179195
Validation loss: 2.446658518876741

Epoch: 6| Step: 9
Training loss: 2.5790969403711896
Validation loss: 2.4517269546510043

Epoch: 6| Step: 10
Training loss: 2.056833169442813
Validation loss: 2.4597428997656507

Epoch: 6| Step: 11
Training loss: 2.7963559825254474
Validation loss: 2.4546688800354466

Epoch: 6| Step: 12
Training loss: 2.733398786396905
Validation loss: 2.451589772399197

Epoch: 6| Step: 13
Training loss: 2.8190703892954225
Validation loss: 2.454670056022435

Epoch: 86| Step: 0
Training loss: 2.4643798004575754
Validation loss: 2.4674158189303688

Epoch: 6| Step: 1
Training loss: 2.280768461223576
Validation loss: 2.448487838859121

Epoch: 6| Step: 2
Training loss: 3.277025391457894
Validation loss: 2.4683106814128446

Epoch: 6| Step: 3
Training loss: 3.198094581517492
Validation loss: 2.4517962235955433

Epoch: 6| Step: 4
Training loss: 2.2621614487401236
Validation loss: 2.4594123506535333

Epoch: 6| Step: 5
Training loss: 1.9255800587016585
Validation loss: 2.458475548530993

Epoch: 6| Step: 6
Training loss: 2.3151054139164304
Validation loss: 2.4587104946726583

Epoch: 6| Step: 7
Training loss: 2.5115352581388852
Validation loss: 2.4739719406470453

Epoch: 6| Step: 8
Training loss: 2.483818231729179
Validation loss: 2.4414619428291555

Epoch: 6| Step: 9
Training loss: 3.350985106059153
Validation loss: 2.4585304907703818

Epoch: 6| Step: 10
Training loss: 2.542989563746907
Validation loss: 2.4431173948188487

Epoch: 6| Step: 11
Training loss: 2.838070070247176
Validation loss: 2.4664655967718754

Epoch: 6| Step: 12
Training loss: 1.9491475614035711
Validation loss: 2.451064609961497

Epoch: 6| Step: 13
Training loss: 3.2073399050236975
Validation loss: 2.4606237224156806

Epoch: 87| Step: 0
Training loss: 2.3035151199099624
Validation loss: 2.4662487276547154

Epoch: 6| Step: 1
Training loss: 1.9505168743288601
Validation loss: 2.4614800228413647

Epoch: 6| Step: 2
Training loss: 2.298529930512366
Validation loss: 2.4539488049333484

Epoch: 6| Step: 3
Training loss: 2.3970209467692367
Validation loss: 2.4426525023964074

Epoch: 6| Step: 4
Training loss: 3.0064456360541145
Validation loss: 2.458897452044866

Epoch: 6| Step: 5
Training loss: 2.3281159880802926
Validation loss: 2.455937899714282

Epoch: 6| Step: 6
Training loss: 2.976568267095791
Validation loss: 2.457582960603622

Epoch: 6| Step: 7
Training loss: 2.3823065548926263
Validation loss: 2.4673562062070684

Epoch: 6| Step: 8
Training loss: 3.11823685271679
Validation loss: 2.465455646059475

Epoch: 6| Step: 9
Training loss: 3.027586935796988
Validation loss: 2.4646724934411695

Epoch: 6| Step: 10
Training loss: 2.2962688243013387
Validation loss: 2.4674217458885765

Epoch: 6| Step: 11
Training loss: 2.8180485565247366
Validation loss: 2.4557665075186277

Epoch: 6| Step: 12
Training loss: 2.5696374998223317
Validation loss: 2.4561966084370894

Epoch: 6| Step: 13
Training loss: 3.51114134661483
Validation loss: 2.4626943104014005

Epoch: 88| Step: 0
Training loss: 1.909949418241991
Validation loss: 2.4634986697995833

Epoch: 6| Step: 1
Training loss: 1.8370615014261151
Validation loss: 2.460301705309133

Epoch: 6| Step: 2
Training loss: 2.368884595605054
Validation loss: 2.459340635993773

Epoch: 6| Step: 3
Training loss: 3.031144602408141
Validation loss: 2.463166047182336

Epoch: 6| Step: 4
Training loss: 3.432484522463028
Validation loss: 2.451670460836256

Epoch: 6| Step: 5
Training loss: 2.1599943296923207
Validation loss: 2.4756547407994276

Epoch: 6| Step: 6
Training loss: 2.4567238231757704
Validation loss: 2.4584985771003316

Epoch: 6| Step: 7
Training loss: 3.196501643509355
Validation loss: 2.455257121726935

Epoch: 6| Step: 8
Training loss: 2.7403968115778428
Validation loss: 2.480042672408745

Epoch: 6| Step: 9
Training loss: 1.8756539158179522
Validation loss: 2.466110281385848

Epoch: 6| Step: 10
Training loss: 3.1538883854112267
Validation loss: 2.4704337556266562

Epoch: 6| Step: 11
Training loss: 2.3350117868130056
Validation loss: 2.454680214813756

Epoch: 6| Step: 12
Training loss: 2.16735556238924
Validation loss: 2.452581025149572

Epoch: 6| Step: 13
Training loss: 3.905594793683012
Validation loss: 2.44595369080344

Epoch: 89| Step: 0
Training loss: 2.2911553823993707
Validation loss: 2.457118705352409

Epoch: 6| Step: 1
Training loss: 2.56856136325505
Validation loss: 2.457904743552084

Epoch: 6| Step: 2
Training loss: 2.9305661117419834
Validation loss: 2.456110491257605

Epoch: 6| Step: 3
Training loss: 2.9424832868466018
Validation loss: 2.4589799461978745

Epoch: 6| Step: 4
Training loss: 2.6297257890367396
Validation loss: 2.459110344390856

Epoch: 6| Step: 5
Training loss: 2.44273157386596
Validation loss: 2.46843833612368

Epoch: 6| Step: 6
Training loss: 2.552538139663589
Validation loss: 2.459359428484785

Epoch: 6| Step: 7
Training loss: 2.760015974413212
Validation loss: 2.457610394391147

Epoch: 6| Step: 8
Training loss: 2.5736991114724432
Validation loss: 2.4557818777277496

Epoch: 6| Step: 9
Training loss: 2.375309974118016
Validation loss: 2.4736106440849324

Epoch: 6| Step: 10
Training loss: 2.8479147795024686
Validation loss: 2.4675108911500603

Epoch: 6| Step: 11
Training loss: 2.595536225911384
Validation loss: 2.4490208369932445

Epoch: 6| Step: 12
Training loss: 2.7517447572098304
Validation loss: 2.4570998967671676

Epoch: 6| Step: 13
Training loss: 2.300769643964785
Validation loss: 2.4759106520759744

Epoch: 90| Step: 0
Training loss: 2.53146097693296
Validation loss: 2.462688268486885

Epoch: 6| Step: 1
Training loss: 2.7428009129618816
Validation loss: 2.463557902902682

Epoch: 6| Step: 2
Training loss: 2.711939557800124
Validation loss: 2.4597592696422175

Epoch: 6| Step: 3
Training loss: 2.009126225996287
Validation loss: 2.4678302773945595

Epoch: 6| Step: 4
Training loss: 2.650162486726934
Validation loss: 2.4672175882902456

Epoch: 6| Step: 5
Training loss: 2.5184763037918843
Validation loss: 2.450852815788322

Epoch: 6| Step: 6
Training loss: 3.5417326229162196
Validation loss: 2.4691513460117083

Epoch: 6| Step: 7
Training loss: 2.6883198574301517
Validation loss: 2.465073424859037

Epoch: 6| Step: 8
Training loss: 2.2338787674892644
Validation loss: 2.476124915396939

Epoch: 6| Step: 9
Training loss: 1.6634575545660597
Validation loss: 2.446703033759848

Epoch: 6| Step: 10
Training loss: 2.9590892810920932
Validation loss: 2.459273578945753

Epoch: 6| Step: 11
Training loss: 2.502165428760805
Validation loss: 2.4660749817129464

Epoch: 6| Step: 12
Training loss: 2.832312081981138
Validation loss: 2.4642692861032978

Epoch: 6| Step: 13
Training loss: 2.998295776770938
Validation loss: 2.4516948321684824

Epoch: 91| Step: 0
Training loss: 3.457279519686844
Validation loss: 2.476545141326242

Epoch: 6| Step: 1
Training loss: 2.026209990137572
Validation loss: 2.4774335692692877

Epoch: 6| Step: 2
Training loss: 2.4122999355395063
Validation loss: 2.460180269419757

Epoch: 6| Step: 3
Training loss: 2.95189273697247
Validation loss: 2.468383302839689

Epoch: 6| Step: 4
Training loss: 3.2109576964845368
Validation loss: 2.4610292343696885

Epoch: 6| Step: 5
Training loss: 3.0275313386941023
Validation loss: 2.470346552167024

Epoch: 6| Step: 6
Training loss: 2.250092080669251
Validation loss: 2.4593233168161475

Epoch: 6| Step: 7
Training loss: 2.0674358607979073
Validation loss: 2.4469681647014845

Epoch: 6| Step: 8
Training loss: 2.4807597793098792
Validation loss: 2.4433804402561767

Epoch: 6| Step: 9
Training loss: 2.402866511338796
Validation loss: 2.450748821428958

Epoch: 6| Step: 10
Training loss: 2.0940624402491226
Validation loss: 2.461930329949097

Epoch: 6| Step: 11
Training loss: 2.386051765308833
Validation loss: 2.4581878692766317

Epoch: 6| Step: 12
Training loss: 2.6950226116470373
Validation loss: 2.467033623447358

Epoch: 6| Step: 13
Training loss: 2.862568890271515
Validation loss: 2.4603834573864676

Epoch: 92| Step: 0
Training loss: 2.7607563505561714
Validation loss: 2.453499632613273

Epoch: 6| Step: 1
Training loss: 2.9446509146925064
Validation loss: 2.458987049166913

Epoch: 6| Step: 2
Training loss: 2.7513914922703737
Validation loss: 2.4671983080540474

Epoch: 6| Step: 3
Training loss: 2.540029300610807
Validation loss: 2.4682086513559516

Epoch: 6| Step: 4
Training loss: 2.6505568585028034
Validation loss: 2.4583122599431806

Epoch: 6| Step: 5
Training loss: 2.702942593985643
Validation loss: 2.4558318575149

Epoch: 6| Step: 6
Training loss: 2.447299917457263
Validation loss: 2.4552925012286053

Epoch: 6| Step: 7
Training loss: 2.904438233414715
Validation loss: 2.4612368926172135

Epoch: 6| Step: 8
Training loss: 2.652447121225227
Validation loss: 2.463569607828039

Epoch: 6| Step: 9
Training loss: 2.6673849648408794
Validation loss: 2.4540399292996913

Epoch: 6| Step: 10
Training loss: 2.1451853048315965
Validation loss: 2.4615689948143937

Epoch: 6| Step: 11
Training loss: 2.5990002360562157
Validation loss: 2.466050567971691

Epoch: 6| Step: 12
Training loss: 2.3857427871085
Validation loss: 2.4591377486291583

Epoch: 6| Step: 13
Training loss: 2.62359272609516
Validation loss: 2.4650495737160325

Epoch: 93| Step: 0
Training loss: 2.412648203354441
Validation loss: 2.4588116395502366

Epoch: 6| Step: 1
Training loss: 2.690565091306858
Validation loss: 2.457671939616441

Epoch: 6| Step: 2
Training loss: 2.795005471867373
Validation loss: 2.459394467528471

Epoch: 6| Step: 3
Training loss: 2.4629270231747378
Validation loss: 2.4575002062237297

Epoch: 6| Step: 4
Training loss: 2.3416663508115216
Validation loss: 2.4530017780817404

Epoch: 6| Step: 5
Training loss: 2.6402042211669485
Validation loss: 2.461119579917679

Epoch: 6| Step: 6
Training loss: 2.841291769436462
Validation loss: 2.441780108303861

Epoch: 6| Step: 7
Training loss: 2.425823020882562
Validation loss: 2.465519056328029

Epoch: 6| Step: 8
Training loss: 2.4889132716577786
Validation loss: 2.4632093031102245

Epoch: 6| Step: 9
Training loss: 2.792241782166162
Validation loss: 2.47801545106378

Epoch: 6| Step: 10
Training loss: 2.498472605465189
Validation loss: 2.4569497672317735

Epoch: 6| Step: 11
Training loss: 2.4282286947095892
Validation loss: 2.47381076202064

Epoch: 6| Step: 12
Training loss: 2.868891321495253
Validation loss: 2.4749052792170745

Epoch: 6| Step: 13
Training loss: 3.381417848154581
Validation loss: 2.46051664854068

Epoch: 94| Step: 0
Training loss: 2.564554832748432
Validation loss: 2.4583950876189893

Epoch: 6| Step: 1
Training loss: 2.715816976523931
Validation loss: 2.4504748141732855

Epoch: 6| Step: 2
Training loss: 2.9042899792915784
Validation loss: 2.4553746028045507

Epoch: 6| Step: 3
Training loss: 2.45092781949226
Validation loss: 2.456139104772121

Epoch: 6| Step: 4
Training loss: 1.9463462074722038
Validation loss: 2.4519972635177045

Epoch: 6| Step: 5
Training loss: 2.9161918980336714
Validation loss: 2.463040685940687

Epoch: 6| Step: 6
Training loss: 2.549169150737123
Validation loss: 2.466088707546582

Epoch: 6| Step: 7
Training loss: 2.446237212524363
Validation loss: 2.466832253198177

Epoch: 6| Step: 8
Training loss: 2.77735405127309
Validation loss: 2.452972300761656

Epoch: 6| Step: 9
Training loss: 2.054768259760297
Validation loss: 2.453336803874994

Epoch: 6| Step: 10
Training loss: 3.0478651736419082
Validation loss: 2.451801964027997

Epoch: 6| Step: 11
Training loss: 2.6802876414902728
Validation loss: 2.4657874659711454

Epoch: 6| Step: 12
Training loss: 2.410872144425153
Validation loss: 2.46275269260359

Epoch: 6| Step: 13
Training loss: 3.314764004875765
Validation loss: 2.462443323203042

Epoch: 95| Step: 0
Training loss: 3.041293622137976
Validation loss: 2.4498848251198893

Epoch: 6| Step: 1
Training loss: 2.516130669043476
Validation loss: 2.4462090684977094

Epoch: 6| Step: 2
Training loss: 3.020750127939949
Validation loss: 2.4489809210496

Epoch: 6| Step: 3
Training loss: 2.9619000563776163
Validation loss: 2.445100674153982

Epoch: 6| Step: 4
Training loss: 2.4684255845549803
Validation loss: 2.4568169401861044

Epoch: 6| Step: 5
Training loss: 2.368687120071059
Validation loss: 2.4702793388078734

Epoch: 6| Step: 6
Training loss: 1.9928048168487098
Validation loss: 2.457026011135678

Epoch: 6| Step: 7
Training loss: 2.418590656719427
Validation loss: 2.458073449689188

Epoch: 6| Step: 8
Training loss: 2.8744851356237477
Validation loss: 2.4640119118938593

Epoch: 6| Step: 9
Training loss: 2.3922112880448436
Validation loss: 2.4584560965003908

Epoch: 6| Step: 10
Training loss: 2.7142701345727986
Validation loss: 2.4723616952402963

Epoch: 6| Step: 11
Training loss: 2.8646445158002236
Validation loss: 2.4602155020545093

Epoch: 6| Step: 12
Training loss: 2.512456663906184
Validation loss: 2.4785976978950646

Epoch: 6| Step: 13
Training loss: 1.8332559034584637
Validation loss: 2.4582804967403526

Epoch: 96| Step: 0
Training loss: 2.8555971630774324
Validation loss: 2.4638179133424796

Epoch: 6| Step: 1
Training loss: 2.618898748939341
Validation loss: 2.4740350595870075

Epoch: 6| Step: 2
Training loss: 2.8602133600638764
Validation loss: 2.4627868422816475

Epoch: 6| Step: 3
Training loss: 2.5637808599153824
Validation loss: 2.4530955753687085

Epoch: 6| Step: 4
Training loss: 2.3667942639550708
Validation loss: 2.4701409056867356

Epoch: 6| Step: 5
Training loss: 2.029941548224723
Validation loss: 2.4678226233295018

Epoch: 6| Step: 6
Training loss: 3.003045126084001
Validation loss: 2.4549671511892543

Epoch: 6| Step: 7
Training loss: 2.7767511907980063
Validation loss: 2.472883098899826

Epoch: 6| Step: 8
Training loss: 3.2882934541083815
Validation loss: 2.4611124028955307

Epoch: 6| Step: 9
Training loss: 2.0764598628757045
Validation loss: 2.4628383204181197

Epoch: 6| Step: 10
Training loss: 2.27996999285845
Validation loss: 2.4554446865797894

Epoch: 6| Step: 11
Training loss: 2.715703638691885
Validation loss: 2.4651588436286898

Epoch: 6| Step: 12
Training loss: 2.3225130377691983
Validation loss: 2.4547959710996152

Epoch: 6| Step: 13
Training loss: 2.5410910616444538
Validation loss: 2.4723662016893604

Epoch: 97| Step: 0
Training loss: 2.051188575619976
Validation loss: 2.458588459867847

Epoch: 6| Step: 1
Training loss: 2.2577658255745487
Validation loss: 2.464848709107957

Epoch: 6| Step: 2
Training loss: 2.7628685959927854
Validation loss: 2.447619123491409

Epoch: 6| Step: 3
Training loss: 1.8959903721866735
Validation loss: 2.4551550279566707

Epoch: 6| Step: 4
Training loss: 2.6820634368289658
Validation loss: 2.450187117860605

Epoch: 6| Step: 5
Training loss: 2.3240572833225412
Validation loss: 2.4565966565278257

Epoch: 6| Step: 6
Training loss: 2.7561472763330137
Validation loss: 2.4703848355617044

Epoch: 6| Step: 7
Training loss: 2.467730927488035
Validation loss: 2.456881540955339

Epoch: 6| Step: 8
Training loss: 2.483065565978867
Validation loss: 2.4582067957271807

Epoch: 6| Step: 9
Training loss: 2.971224747206627
Validation loss: 2.4523404488427323

Epoch: 6| Step: 10
Training loss: 3.6168173153583223
Validation loss: 2.452240740057368

Epoch: 6| Step: 11
Training loss: 3.117825932721859
Validation loss: 2.4449414362192052

Epoch: 6| Step: 12
Training loss: 1.9172960022160181
Validation loss: 2.466770305163574

Epoch: 6| Step: 13
Training loss: 2.95516719545209
Validation loss: 2.4522293783217455

Epoch: 98| Step: 0
Training loss: 3.366180623412968
Validation loss: 2.463629170134862

Epoch: 6| Step: 1
Training loss: 1.9235040227075988
Validation loss: 2.465203140918362

Epoch: 6| Step: 2
Training loss: 2.601515760946984
Validation loss: 2.4542104841848977

Epoch: 6| Step: 3
Training loss: 2.122960851307457
Validation loss: 2.4594373733636092

Epoch: 6| Step: 4
Training loss: 2.499332911181607
Validation loss: 2.4543466582180202

Epoch: 6| Step: 5
Training loss: 2.941792861637898
Validation loss: 2.454607322700794

Epoch: 6| Step: 6
Training loss: 2.7417928297548606
Validation loss: 2.456507815458581

Epoch: 6| Step: 7
Training loss: 2.594577151854195
Validation loss: 2.461449539921322

Epoch: 6| Step: 8
Training loss: 3.090224598249608
Validation loss: 2.46810383645989

Epoch: 6| Step: 9
Training loss: 2.238131053738475
Validation loss: 2.4480465832029448

Epoch: 6| Step: 10
Training loss: 2.9613548930741778
Validation loss: 2.4487773125013685

Epoch: 6| Step: 11
Training loss: 1.8665390484759417
Validation loss: 2.4516572958033627

Epoch: 6| Step: 12
Training loss: 2.5055194960219906
Validation loss: 2.455864820495171

Epoch: 6| Step: 13
Training loss: 2.729516732475731
Validation loss: 2.4634875441820783

Epoch: 99| Step: 0
Training loss: 2.474065345992841
Validation loss: 2.471332192889217

Epoch: 6| Step: 1
Training loss: 2.9471510756815005
Validation loss: 2.4659398633919505

Epoch: 6| Step: 2
Training loss: 2.155688005269318
Validation loss: 2.465168891600001

Epoch: 6| Step: 3
Training loss: 2.7252431043623897
Validation loss: 2.4394511576995606

Epoch: 6| Step: 4
Training loss: 2.575962153553605
Validation loss: 2.45256005250683

Epoch: 6| Step: 5
Training loss: 2.8925817516646743
Validation loss: 2.4715059514882354

Epoch: 6| Step: 6
Training loss: 2.757029824865918
Validation loss: 2.4503653461295785

Epoch: 6| Step: 7
Training loss: 2.315680816430711
Validation loss: 2.458647627750629

Epoch: 6| Step: 8
Training loss: 2.804333932846672
Validation loss: 2.462254893179504

Epoch: 6| Step: 9
Training loss: 2.3137396505444836
Validation loss: 2.46221760942679

Epoch: 6| Step: 10
Training loss: 2.217414346479288
Validation loss: 2.4575005802074616

Epoch: 6| Step: 11
Training loss: 2.683997422332208
Validation loss: 2.4625916374799606

Epoch: 6| Step: 12
Training loss: 2.8639063549608865
Validation loss: 2.4604268424642397

Epoch: 6| Step: 13
Training loss: 2.7980086091122485
Validation loss: 2.4596315470075476

Epoch: 100| Step: 0
Training loss: 2.0856403039102696
Validation loss: 2.450124940455186

Epoch: 6| Step: 1
Training loss: 3.223519356483838
Validation loss: 2.464331117036507

Epoch: 6| Step: 2
Training loss: 2.2387538231285076
Validation loss: 2.4601629472955038

Epoch: 6| Step: 3
Training loss: 2.90319992313674
Validation loss: 2.469233450873842

Epoch: 6| Step: 4
Training loss: 2.685569247065905
Validation loss: 2.4529356012382593

Epoch: 6| Step: 5
Training loss: 3.0123390123080838
Validation loss: 2.4614777971468786

Epoch: 6| Step: 6
Training loss: 2.3358197134679903
Validation loss: 2.4565542411360903

Epoch: 6| Step: 7
Training loss: 3.061451479417506
Validation loss: 2.460909997565343

Epoch: 6| Step: 8
Training loss: 2.524185589425243
Validation loss: 2.451020295622379

Epoch: 6| Step: 9
Training loss: 2.8279770448878034
Validation loss: 2.466789850639015

Epoch: 6| Step: 10
Training loss: 2.2581016065038813
Validation loss: 2.4702138043721322

Epoch: 6| Step: 11
Training loss: 2.3738396470275336
Validation loss: 2.451524191154294

Epoch: 6| Step: 12
Training loss: 2.2819127204512717
Validation loss: 2.450634545664062

Epoch: 6| Step: 13
Training loss: 2.5081726005822493
Validation loss: 2.465302498062969

Epoch: 101| Step: 0
Training loss: 2.6795401574378888
Validation loss: 2.465524139373035

Epoch: 6| Step: 1
Training loss: 2.500800004749945
Validation loss: 2.4512066399266432

Epoch: 6| Step: 2
Training loss: 3.2964617574155213
Validation loss: 2.4667728690415918

Epoch: 6| Step: 3
Training loss: 2.8429136618413304
Validation loss: 2.4700220698140813

Epoch: 6| Step: 4
Training loss: 2.3725364355860994
Validation loss: 2.457770076238739

Epoch: 6| Step: 5
Training loss: 2.005248811651776
Validation loss: 2.4618615512905273

Epoch: 6| Step: 6
Training loss: 2.100961819141586
Validation loss: 2.45528933647338

Epoch: 6| Step: 7
Training loss: 2.4564510078785746
Validation loss: 2.453895344955976

Epoch: 6| Step: 8
Training loss: 2.6791667821556846
Validation loss: 2.455908821944722

Epoch: 6| Step: 9
Training loss: 2.944630349086491
Validation loss: 2.459126534476877

Epoch: 6| Step: 10
Training loss: 2.293720388611125
Validation loss: 2.4436739520719297

Epoch: 6| Step: 11
Training loss: 2.710238231871607
Validation loss: 2.4581408142852843

Epoch: 6| Step: 12
Training loss: 2.7643413258588074
Validation loss: 2.450870053088415

Epoch: 6| Step: 13
Training loss: 2.8074580457614924
Validation loss: 2.4651452535315417

Epoch: 102| Step: 0
Training loss: 2.490856616499625
Validation loss: 2.462388814961808

Epoch: 6| Step: 1
Training loss: 2.5073220792499393
Validation loss: 2.4517990467607245

Epoch: 6| Step: 2
Training loss: 2.596787937141695
Validation loss: 2.4581532813019273

Epoch: 6| Step: 3
Training loss: 2.500450093760465
Validation loss: 2.4579458642207612

Epoch: 6| Step: 4
Training loss: 2.5858825493359054
Validation loss: 2.452578516469692

Epoch: 6| Step: 5
Training loss: 1.4965679323611993
Validation loss: 2.4557038867671315

Epoch: 6| Step: 6
Training loss: 2.5838172725931363
Validation loss: 2.4474929837390644

Epoch: 6| Step: 7
Training loss: 3.5248389998658927
Validation loss: 2.444591225166488

Epoch: 6| Step: 8
Training loss: 2.2766348780827874
Validation loss: 2.4542602405759357

Epoch: 6| Step: 9
Training loss: 2.652249903416135
Validation loss: 2.457701218185887

Epoch: 6| Step: 10
Training loss: 2.2147387928793805
Validation loss: 2.450308351154648

Epoch: 6| Step: 11
Training loss: 2.4693965789462267
Validation loss: 2.445542443003235

Epoch: 6| Step: 12
Training loss: 3.264349875575297
Validation loss: 2.4634206936790073

Epoch: 6| Step: 13
Training loss: 2.8663791275716677
Validation loss: 2.4663629701458363

Epoch: 103| Step: 0
Training loss: 2.2496977709071957
Validation loss: 2.450908446675368

Epoch: 6| Step: 1
Training loss: 1.9165193943442642
Validation loss: 2.4585734257601475

Epoch: 6| Step: 2
Training loss: 3.155342046994702
Validation loss: 2.468078374465088

Epoch: 6| Step: 3
Training loss: 2.427572918630572
Validation loss: 2.4556977493569123

Epoch: 6| Step: 4
Training loss: 2.9088818518340838
Validation loss: 2.4740841302586207

Epoch: 6| Step: 5
Training loss: 1.9933742204935998
Validation loss: 2.4709089482760174

Epoch: 6| Step: 6
Training loss: 2.5201897758596785
Validation loss: 2.467674171532895

Epoch: 6| Step: 7
Training loss: 2.9899710870065705
Validation loss: 2.455944016169262

Epoch: 6| Step: 8
Training loss: 2.32300983692571
Validation loss: 2.4467335248976894

Epoch: 6| Step: 9
Training loss: 2.755467528258297
Validation loss: 2.4601802381581375

Epoch: 6| Step: 10
Training loss: 2.490499660348706
Validation loss: 2.457988795342237

Epoch: 6| Step: 11
Training loss: 3.0331108437849803
Validation loss: 2.452735545475969

Epoch: 6| Step: 12
Training loss: 2.1583677203214213
Validation loss: 2.455625583787452

Epoch: 6| Step: 13
Training loss: 3.5051868696911264
Validation loss: 2.457238796449404

Epoch: 104| Step: 0
Training loss: 2.6228844428311278
Validation loss: 2.4557338804115956

Epoch: 6| Step: 1
Training loss: 3.574004219996219
Validation loss: 2.447619653476654

Epoch: 6| Step: 2
Training loss: 2.4863017546041166
Validation loss: 2.4710697528351018

Epoch: 6| Step: 3
Training loss: 1.8805771216817064
Validation loss: 2.4577839819652256

Epoch: 6| Step: 4
Training loss: 2.3093746820225065
Validation loss: 2.4553012489207733

Epoch: 6| Step: 5
Training loss: 2.6724771635330606
Validation loss: 2.464472667465441

Epoch: 6| Step: 6
Training loss: 2.3243955913553753
Validation loss: 2.4573327741976105

Epoch: 6| Step: 7
Training loss: 2.87254460843793
Validation loss: 2.4346384332352784

Epoch: 6| Step: 8
Training loss: 2.4835723924033513
Validation loss: 2.4529408410001965

Epoch: 6| Step: 9
Training loss: 2.039908982471718
Validation loss: 2.4561022678178897

Epoch: 6| Step: 10
Training loss: 2.8503865364696765
Validation loss: 2.4650026351490966

Epoch: 6| Step: 11
Training loss: 3.120580829206141
Validation loss: 2.449583439073482

Epoch: 6| Step: 12
Training loss: 2.170527417477036
Validation loss: 2.4525303461824612

Epoch: 6| Step: 13
Training loss: 2.5662441347615386
Validation loss: 2.4625347745272412

Epoch: 105| Step: 0
Training loss: 2.926265579697086
Validation loss: 2.455555134549273

Epoch: 6| Step: 1
Training loss: 2.465949292728186
Validation loss: 2.4520451128502834

Epoch: 6| Step: 2
Training loss: 2.1549180934413537
Validation loss: 2.4558895270428795

Epoch: 6| Step: 3
Training loss: 2.7010970253548576
Validation loss: 2.4583032841529233

Epoch: 6| Step: 4
Training loss: 2.8533391565043607
Validation loss: 2.46560431981123

Epoch: 6| Step: 5
Training loss: 3.5741154890309104
Validation loss: 2.443678869164719

Epoch: 6| Step: 6
Training loss: 2.237041456238286
Validation loss: 2.4623911366568576

Epoch: 6| Step: 7
Training loss: 2.4099243646046724
Validation loss: 2.4613320785181805

Epoch: 6| Step: 8
Training loss: 2.197693751693559
Validation loss: 2.462860110615792

Epoch: 6| Step: 9
Training loss: 2.092203964385133
Validation loss: 2.4571177141674534

Epoch: 6| Step: 10
Training loss: 2.540613915300763
Validation loss: 2.470327988027599

Epoch: 6| Step: 11
Training loss: 2.591817204640738
Validation loss: 2.4480445327474913

Epoch: 6| Step: 12
Training loss: 2.522194192910794
Validation loss: 2.4537240535256575

Epoch: 6| Step: 13
Training loss: 2.736768274624152
Validation loss: 2.453157231249958

Epoch: 106| Step: 0
Training loss: 3.2606398208512393
Validation loss: 2.4523896107294587

Epoch: 6| Step: 1
Training loss: 2.8719154064503085
Validation loss: 2.457265513165987

Epoch: 6| Step: 2
Training loss: 2.304804187988798
Validation loss: 2.448093047864318

Epoch: 6| Step: 3
Training loss: 3.0649381002177685
Validation loss: 2.4603670098678623

Epoch: 6| Step: 4
Training loss: 3.1879197386590263
Validation loss: 2.4424980956961355

Epoch: 6| Step: 5
Training loss: 2.420087388407554
Validation loss: 2.4736881088230414

Epoch: 6| Step: 6
Training loss: 2.7116074847246234
Validation loss: 2.4732248191425357

Epoch: 6| Step: 7
Training loss: 2.3889893564886933
Validation loss: 2.46324053233349

Epoch: 6| Step: 8
Training loss: 2.2851102384189903
Validation loss: 2.4687252123912176

Epoch: 6| Step: 9
Training loss: 2.5036200063690783
Validation loss: 2.4621770557157645

Epoch: 6| Step: 10
Training loss: 2.6917558728091393
Validation loss: 2.4644983061032346

Epoch: 6| Step: 11
Training loss: 1.779402393683579
Validation loss: 2.449506147166535

Epoch: 6| Step: 12
Training loss: 2.0824505525101675
Validation loss: 2.4677303244265123

Epoch: 6| Step: 13
Training loss: 2.101758983176772
Validation loss: 2.454502183401672

Epoch: 107| Step: 0
Training loss: 2.4489979621626388
Validation loss: 2.4489814549274143

Epoch: 6| Step: 1
Training loss: 2.275201381950656
Validation loss: 2.4558398318470838

Epoch: 6| Step: 2
Training loss: 2.6821608625696176
Validation loss: 2.4572947835370185

Epoch: 6| Step: 3
Training loss: 2.864454583251282
Validation loss: 2.442996452669236

Epoch: 6| Step: 4
Training loss: 2.6262917746154173
Validation loss: 2.4779838742073923

Epoch: 6| Step: 5
Training loss: 3.0222484211939262
Validation loss: 2.469452766901112

Epoch: 6| Step: 6
Training loss: 2.6341954795696085
Validation loss: 2.4589514267313484

Epoch: 6| Step: 7
Training loss: 2.2740100257672653
Validation loss: 2.454263355474428

Epoch: 6| Step: 8
Training loss: 2.169905723422393
Validation loss: 2.454059019366727

Epoch: 6| Step: 9
Training loss: 2.424834676396563
Validation loss: 2.467336758730958

Epoch: 6| Step: 10
Training loss: 2.4579548517461944
Validation loss: 2.4547145780994106

Epoch: 6| Step: 11
Training loss: 3.0487849582546303
Validation loss: 2.46035154847493

Epoch: 6| Step: 12
Training loss: 2.721677847903711
Validation loss: 2.453455521081915

Epoch: 6| Step: 13
Training loss: 2.234344375507186
Validation loss: 2.4615621247737463

Epoch: 108| Step: 0
Training loss: 2.4570714222545624
Validation loss: 2.459929245608993

Epoch: 6| Step: 1
Training loss: 3.219624817119643
Validation loss: 2.470531430971187

Epoch: 6| Step: 2
Training loss: 3.252167932329264
Validation loss: 2.4635996774097864

Epoch: 6| Step: 3
Training loss: 2.3857957519314352
Validation loss: 2.458614054552164

Epoch: 6| Step: 4
Training loss: 2.6258509028831707
Validation loss: 2.4669008298785147

Epoch: 6| Step: 5
Training loss: 2.7955797488812113
Validation loss: 2.4650451672508655

Epoch: 6| Step: 6
Training loss: 2.0974230077205287
Validation loss: 2.4687046468984035

Epoch: 6| Step: 7
Training loss: 2.185602291383003
Validation loss: 2.478656183349652

Epoch: 6| Step: 8
Training loss: 2.4166358638861185
Validation loss: 2.459825400479071

Epoch: 6| Step: 9
Training loss: 2.6196507036167933
Validation loss: 2.461195667044425

Epoch: 6| Step: 10
Training loss: 2.117897730994156
Validation loss: 2.4501890728788895

Epoch: 6| Step: 11
Training loss: 2.4487069551930647
Validation loss: 2.461459398898019

Epoch: 6| Step: 12
Training loss: 2.805756856497149
Validation loss: 2.4623188653238115

Epoch: 6| Step: 13
Training loss: 2.433393687540512
Validation loss: 2.461073367445161

Epoch: 109| Step: 0
Training loss: 2.585198241994013
Validation loss: 2.4622209974623788

Epoch: 6| Step: 1
Training loss: 2.6661443993624863
Validation loss: 2.4507504825783646

Epoch: 6| Step: 2
Training loss: 3.422268222180415
Validation loss: 2.463609956510567

Epoch: 6| Step: 3
Training loss: 2.257766670369104
Validation loss: 2.449855988392527

Epoch: 6| Step: 4
Training loss: 2.3189703659263166
Validation loss: 2.467704940129586

Epoch: 6| Step: 5
Training loss: 3.2024997007800162
Validation loss: 2.4559032445603557

Epoch: 6| Step: 6
Training loss: 2.7762144988021684
Validation loss: 2.4601386494318374

Epoch: 6| Step: 7
Training loss: 1.8146083013989833
Validation loss: 2.4352309375375136

Epoch: 6| Step: 8
Training loss: 2.79886799136384
Validation loss: 2.454521421841933

Epoch: 6| Step: 9
Training loss: 1.8613762223873285
Validation loss: 2.4570741538021243

Epoch: 6| Step: 10
Training loss: 2.6287244986160156
Validation loss: 2.4679660281837523

Epoch: 6| Step: 11
Training loss: 2.897019360678741
Validation loss: 2.4414632018306888

Epoch: 6| Step: 12
Training loss: 2.142923610655484
Validation loss: 2.461297855014355

Epoch: 6| Step: 13
Training loss: 2.3657232105423756
Validation loss: 2.456879362224321

Epoch: 110| Step: 0
Training loss: 2.1300898909965245
Validation loss: 2.4630719995274615

Epoch: 6| Step: 1
Training loss: 2.4383163063391757
Validation loss: 2.4409683106456233

Epoch: 6| Step: 2
Training loss: 3.332868464161443
Validation loss: 2.4513863763551633

Epoch: 6| Step: 3
Training loss: 2.4152769718920744
Validation loss: 2.451033734975891

Epoch: 6| Step: 4
Training loss: 2.7193505511788163
Validation loss: 2.4496884760506004

Epoch: 6| Step: 5
Training loss: 3.3468180333693565
Validation loss: 2.4483601842307947

Epoch: 6| Step: 6
Training loss: 2.388400370403945
Validation loss: 2.456586677852051

Epoch: 6| Step: 7
Training loss: 2.5606798360072625
Validation loss: 2.459211657860461

Epoch: 6| Step: 8
Training loss: 2.022101355120672
Validation loss: 2.4400626248503676

Epoch: 6| Step: 9
Training loss: 2.630990413809247
Validation loss: 2.459644856969512

Epoch: 6| Step: 10
Training loss: 1.9080673060111897
Validation loss: 2.468896370584662

Epoch: 6| Step: 11
Training loss: 2.947964311805555
Validation loss: 2.461041010697917

Epoch: 6| Step: 12
Training loss: 2.6000511201087866
Validation loss: 2.4712363376590716

Epoch: 6| Step: 13
Training loss: 1.9280231418012195
Validation loss: 2.462125637160327

Epoch: 111| Step: 0
Training loss: 2.4585662559036248
Validation loss: 2.4553704034569472

Epoch: 6| Step: 1
Training loss: 2.5697528264564298
Validation loss: 2.4633686860256474

Epoch: 6| Step: 2
Training loss: 2.7604700527187007
Validation loss: 2.4592198656903137

Epoch: 6| Step: 3
Training loss: 2.598963908850143
Validation loss: 2.458441318109864

Epoch: 6| Step: 4
Training loss: 2.6332701333425343
Validation loss: 2.4694575060111

Epoch: 6| Step: 5
Training loss: 2.2324541278154615
Validation loss: 2.4576792033544916

Epoch: 6| Step: 6
Training loss: 2.271795459808399
Validation loss: 2.456150566367305

Epoch: 6| Step: 7
Training loss: 2.69582240492086
Validation loss: 2.4559574050929363

Epoch: 6| Step: 8
Training loss: 2.5094236148291325
Validation loss: 2.445942576567237

Epoch: 6| Step: 9
Training loss: 2.2910562106779135
Validation loss: 2.454918532779479

Epoch: 6| Step: 10
Training loss: 2.3138634039045414
Validation loss: 2.4539894413425434

Epoch: 6| Step: 11
Training loss: 2.97979256695251
Validation loss: 2.4672119471092704

Epoch: 6| Step: 12
Training loss: 3.1955934881323755
Validation loss: 2.4558814056852607

Epoch: 6| Step: 13
Training loss: 2.395370560332445
Validation loss: 2.448000312446045

Epoch: 112| Step: 0
Training loss: 2.06434825966517
Validation loss: 2.4647733634978715

Epoch: 6| Step: 1
Training loss: 2.1800823332611463
Validation loss: 2.4529872495330243

Epoch: 6| Step: 2
Training loss: 2.718541016713193
Validation loss: 2.4484776287231407

Epoch: 6| Step: 3
Training loss: 2.8113060006228747
Validation loss: 2.4575361141399212

Epoch: 6| Step: 4
Training loss: 2.624917528582632
Validation loss: 2.4670592687234505

Epoch: 6| Step: 5
Training loss: 2.6052331088684157
Validation loss: 2.45107243454715

Epoch: 6| Step: 6
Training loss: 3.0878566520506228
Validation loss: 2.464822445899864

Epoch: 6| Step: 7
Training loss: 2.7708021941383234
Validation loss: 2.4450567439946918

Epoch: 6| Step: 8
Training loss: 1.8750877359844154
Validation loss: 2.4571492628667397

Epoch: 6| Step: 9
Training loss: 2.630351469973323
Validation loss: 2.4386982639980728

Epoch: 6| Step: 10
Training loss: 2.16067382792638
Validation loss: 2.4546660309278665

Epoch: 6| Step: 11
Training loss: 2.1345858066278183
Validation loss: 2.451826138525024

Epoch: 6| Step: 12
Training loss: 2.857415700555103
Validation loss: 2.4588788259678083

Epoch: 6| Step: 13
Training loss: 3.578271054947596
Validation loss: 2.4506562775189886

Epoch: 113| Step: 0
Training loss: 2.705035289879714
Validation loss: 2.4573868030726196

Epoch: 6| Step: 1
Training loss: 2.45716767773813
Validation loss: 2.4561468495221996

Epoch: 6| Step: 2
Training loss: 2.852276271167116
Validation loss: 2.448074361573726

Epoch: 6| Step: 3
Training loss: 2.694224173815756
Validation loss: 2.44669210210115

Epoch: 6| Step: 4
Training loss: 2.6669406948754806
Validation loss: 2.4519663971393713

Epoch: 6| Step: 5
Training loss: 2.814247605644618
Validation loss: 2.4603629774217475

Epoch: 6| Step: 6
Training loss: 2.333587995891801
Validation loss: 2.450850041742174

Epoch: 6| Step: 7
Training loss: 2.2622754823343665
Validation loss: 2.4621826647016585

Epoch: 6| Step: 8
Training loss: 3.131674086430158
Validation loss: 2.456344492081912

Epoch: 6| Step: 9
Training loss: 2.1352921488364465
Validation loss: 2.4414189683808507

Epoch: 6| Step: 10
Training loss: 2.7115791726685132
Validation loss: 2.470046244507176

Epoch: 6| Step: 11
Training loss: 2.3078769145388
Validation loss: 2.4519544339869626

Epoch: 6| Step: 12
Training loss: 2.313192521609217
Validation loss: 2.4589805467138843

Epoch: 6| Step: 13
Training loss: 2.6496446047294855
Validation loss: 2.457085541130023

Epoch: 114| Step: 0
Training loss: 2.2672368071207267
Validation loss: 2.473344416888574

Epoch: 6| Step: 1
Training loss: 2.5307452793606764
Validation loss: 2.451467065212324

Epoch: 6| Step: 2
Training loss: 2.4751712007747124
Validation loss: 2.464406395026805

Epoch: 6| Step: 3
Training loss: 2.4984507528768267
Validation loss: 2.453754596896572

Epoch: 6| Step: 4
Training loss: 3.094603911955003
Validation loss: 2.462479247009968

Epoch: 6| Step: 5
Training loss: 2.3809767358533356
Validation loss: 2.4505425341146787

Epoch: 6| Step: 6
Training loss: 2.669688439925523
Validation loss: 2.461610751001633

Epoch: 6| Step: 7
Training loss: 2.512712391848289
Validation loss: 2.45648150795051

Epoch: 6| Step: 8
Training loss: 2.9658775487356586
Validation loss: 2.4514030002108553

Epoch: 6| Step: 9
Training loss: 2.646346535559372
Validation loss: 2.459790557257786

Epoch: 6| Step: 10
Training loss: 1.9345975485920348
Validation loss: 2.460667169935496

Epoch: 6| Step: 11
Training loss: 2.6227683617495714
Validation loss: 2.4468825111372885

Epoch: 6| Step: 12
Training loss: 2.532037588910175
Validation loss: 2.4538027379268827

Epoch: 6| Step: 13
Training loss: 2.9021797801301505
Validation loss: 2.4642799800996404

Epoch: 115| Step: 0
Training loss: 2.799331694274602
Validation loss: 2.468526960718133

Epoch: 6| Step: 1
Training loss: 2.152241173046266
Validation loss: 2.4548976740931674

Epoch: 6| Step: 2
Training loss: 2.5855965288681864
Validation loss: 2.4503855978797078

Epoch: 6| Step: 3
Training loss: 2.624186889418687
Validation loss: 2.4741375912724526

Epoch: 6| Step: 4
Training loss: 2.5260872643409273
Validation loss: 2.452052223361665

Epoch: 6| Step: 5
Training loss: 3.0099307045294807
Validation loss: 2.451917566575889

Epoch: 6| Step: 6
Training loss: 2.7881387842517853
Validation loss: 2.472097707304852

Epoch: 6| Step: 7
Training loss: 2.5412417405759355
Validation loss: 2.454529808812586

Epoch: 6| Step: 8
Training loss: 2.997833105163797
Validation loss: 2.456907089771406

Epoch: 6| Step: 9
Training loss: 2.3952786895495795
Validation loss: 2.443140318412572

Epoch: 6| Step: 10
Training loss: 2.7361546419901113
Validation loss: 2.4557656118292126

Epoch: 6| Step: 11
Training loss: 2.1631820485137645
Validation loss: 2.45057760088788

Epoch: 6| Step: 12
Training loss: 2.060155518596405
Validation loss: 2.4638669554696815

Epoch: 6| Step: 13
Training loss: 2.385939750345564
Validation loss: 2.4684113591769963

Epoch: 116| Step: 0
Training loss: 2.704986460540789
Validation loss: 2.4493746337542026

Epoch: 6| Step: 1
Training loss: 2.3918426005908033
Validation loss: 2.4402465964354976

Epoch: 6| Step: 2
Training loss: 2.363595484500122
Validation loss: 2.450269471066172

Epoch: 6| Step: 3
Training loss: 2.57267935169365
Validation loss: 2.4500182950757954

Epoch: 6| Step: 4
Training loss: 2.150881289460229
Validation loss: 2.4380466793662166

Epoch: 6| Step: 5
Training loss: 2.6345432829589144
Validation loss: 2.4482205001862845

Epoch: 6| Step: 6
Training loss: 2.204896471702863
Validation loss: 2.4472609330052704

Epoch: 6| Step: 7
Training loss: 2.131620751851539
Validation loss: 2.468290797962041

Epoch: 6| Step: 8
Training loss: 2.508681292388937
Validation loss: 2.464674639279346

Epoch: 6| Step: 9
Training loss: 2.621328056312028
Validation loss: 2.4608301939180874

Epoch: 6| Step: 10
Training loss: 2.676246413291299
Validation loss: 2.441868107775272

Epoch: 6| Step: 11
Training loss: 3.1794286524132183
Validation loss: 2.466964432141439

Epoch: 6| Step: 12
Training loss: 2.650851969249191
Validation loss: 2.4563626760726383

Epoch: 6| Step: 13
Training loss: 3.306009231194487
Validation loss: 2.447070802752015

Epoch: 117| Step: 0
Training loss: 1.8459582924434659
Validation loss: 2.4553841186541687

Epoch: 6| Step: 1
Training loss: 2.0968885668615576
Validation loss: 2.4590031034902933

Epoch: 6| Step: 2
Training loss: 2.3231477722250555
Validation loss: 2.465286184232357

Epoch: 6| Step: 3
Training loss: 2.779618030900123
Validation loss: 2.4598608810267324

Epoch: 6| Step: 4
Training loss: 2.8859039519486864
Validation loss: 2.458559917090719

Epoch: 6| Step: 5
Training loss: 2.690998018749561
Validation loss: 2.426863885984702

Epoch: 6| Step: 6
Training loss: 2.3021849412775715
Validation loss: 2.460741009789215

Epoch: 6| Step: 7
Training loss: 2.6020789564557574
Validation loss: 2.455758467702703

Epoch: 6| Step: 8
Training loss: 2.850711894217479
Validation loss: 2.4516045000696516

Epoch: 6| Step: 9
Training loss: 2.452973476516891
Validation loss: 2.474782952190202

Epoch: 6| Step: 10
Training loss: 2.8449231756527644
Validation loss: 2.453622795049395

Epoch: 6| Step: 11
Training loss: 2.9509233613722303
Validation loss: 2.4549319852536615

Epoch: 6| Step: 12
Training loss: 2.113248306553531
Validation loss: 2.4568246533211826

Epoch: 6| Step: 13
Training loss: 2.9922690915768673
Validation loss: 2.442717309054536

Epoch: 118| Step: 0
Training loss: 2.1239054609836203
Validation loss: 2.455044561465006

Epoch: 6| Step: 1
Training loss: 2.066391481516223
Validation loss: 2.4583691423525385

Epoch: 6| Step: 2
Training loss: 2.3577155536315098
Validation loss: 2.4646853715626516

Epoch: 6| Step: 3
Training loss: 3.1409637116695412
Validation loss: 2.44169295401574

Epoch: 6| Step: 4
Training loss: 2.9969723046251096
Validation loss: 2.471935944963375

Epoch: 6| Step: 5
Training loss: 2.3778603044292512
Validation loss: 2.4514295149018923

Epoch: 6| Step: 6
Training loss: 2.475836132882135
Validation loss: 2.4602713495037576

Epoch: 6| Step: 7
Training loss: 2.4573475644711524
Validation loss: 2.4374009021001544

Epoch: 6| Step: 8
Training loss: 2.3852278677730503
Validation loss: 2.450519616995887

Epoch: 6| Step: 9
Training loss: 2.3927728316820307
Validation loss: 2.4405332854189012

Epoch: 6| Step: 10
Training loss: 2.930248318718157
Validation loss: 2.4435693542367165

Epoch: 6| Step: 11
Training loss: 2.837249536425339
Validation loss: 2.45337797028034

Epoch: 6| Step: 12
Training loss: 2.627077552089234
Validation loss: 2.448855124153492

Epoch: 6| Step: 13
Training loss: 2.0895621707208467
Validation loss: 2.4498910503426456

Epoch: 119| Step: 0
Training loss: 2.7200338905691464
Validation loss: 2.4504119823414725

Epoch: 6| Step: 1
Training loss: 2.288153562307593
Validation loss: 2.4488036075081867

Epoch: 6| Step: 2
Training loss: 2.043412869613159
Validation loss: 2.45734911996417

Epoch: 6| Step: 3
Training loss: 2.289129366890787
Validation loss: 2.4344183702367834

Epoch: 6| Step: 4
Training loss: 2.2706980767055316
Validation loss: 2.471458305703567

Epoch: 6| Step: 5
Training loss: 2.10522980475357
Validation loss: 2.4533810617428595

Epoch: 6| Step: 6
Training loss: 2.0829712998220997
Validation loss: 2.449456437590878

Epoch: 6| Step: 7
Training loss: 2.8969951649982004
Validation loss: 2.4609879615663823

Epoch: 6| Step: 8
Training loss: 2.4844716371179025
Validation loss: 2.4569742614907675

Epoch: 6| Step: 9
Training loss: 3.659590540010211
Validation loss: 2.4650029897943133

Epoch: 6| Step: 10
Training loss: 2.710915689078326
Validation loss: 2.451155186823359

Epoch: 6| Step: 11
Training loss: 2.47003430145786
Validation loss: 2.457844425039944

Epoch: 6| Step: 12
Training loss: 3.091864117043587
Validation loss: 2.4684976376341976

Epoch: 6| Step: 13
Training loss: 2.151549814224244
Validation loss: 2.454478584655107

Epoch: 120| Step: 0
Training loss: 2.5591084435797122
Validation loss: 2.4641307317413954

Epoch: 6| Step: 1
Training loss: 2.558794459267456
Validation loss: 2.4454537171709667

Epoch: 6| Step: 2
Training loss: 2.4194881367622174
Validation loss: 2.4640030837994598

Epoch: 6| Step: 3
Training loss: 2.363920368124937
Validation loss: 2.4556939430900364

Epoch: 6| Step: 4
Training loss: 3.2193540728478913
Validation loss: 2.4628440866393766

Epoch: 6| Step: 5
Training loss: 2.883679928831527
Validation loss: 2.4575193982442656

Epoch: 6| Step: 6
Training loss: 3.165762286960906
Validation loss: 2.4667671790371153

Epoch: 6| Step: 7
Training loss: 3.122401874060219
Validation loss: 2.4725189722971224

Epoch: 6| Step: 8
Training loss: 2.3482314942665434
Validation loss: 2.4480925619639256

Epoch: 6| Step: 9
Training loss: 2.4387192244472256
Validation loss: 2.4574377454476553

Epoch: 6| Step: 10
Training loss: 2.6055271307997345
Validation loss: 2.460902180819473

Epoch: 6| Step: 11
Training loss: 1.824335000624552
Validation loss: 2.453741121250819

Epoch: 6| Step: 12
Training loss: 1.8406407923903372
Validation loss: 2.4499551653448166

Epoch: 6| Step: 13
Training loss: 1.785471748502428
Validation loss: 2.4776069020383495

Epoch: 121| Step: 0
Training loss: 2.449299642148757
Validation loss: 2.4603684498767335

Epoch: 6| Step: 1
Training loss: 3.184992982386549
Validation loss: 2.4404896086665904

Epoch: 6| Step: 2
Training loss: 2.4896173408345668
Validation loss: 2.4483168282553516

Epoch: 6| Step: 3
Training loss: 2.0146194433732223
Validation loss: 2.4718458319213394

Epoch: 6| Step: 4
Training loss: 2.2889398014657107
Validation loss: 2.4576334498435806

Epoch: 6| Step: 5
Training loss: 2.9800180316865945
Validation loss: 2.4553921998931547

Epoch: 6| Step: 6
Training loss: 2.5848565276892628
Validation loss: 2.4549820162818254

Epoch: 6| Step: 7
Training loss: 2.251781817733524
Validation loss: 2.4492030062683585

Epoch: 6| Step: 8
Training loss: 2.2304156241962922
Validation loss: 2.4717298524891533

Epoch: 6| Step: 9
Training loss: 2.2615820229006447
Validation loss: 2.456599774725246

Epoch: 6| Step: 10
Training loss: 1.9219741175453962
Validation loss: 2.4423215868525903

Epoch: 6| Step: 11
Training loss: 2.908948896203764
Validation loss: 2.4596200807875754

Epoch: 6| Step: 12
Training loss: 2.4507015430547847
Validation loss: 2.476612126150896

Epoch: 6| Step: 13
Training loss: 3.6941354824763297
Validation loss: 2.450070241867528

Epoch: 122| Step: 0
Training loss: 3.054727773571629
Validation loss: 2.4469324511106936

Epoch: 6| Step: 1
Training loss: 2.621849712845503
Validation loss: 2.4379741932107284

Epoch: 6| Step: 2
Training loss: 2.643585441644391
Validation loss: 2.4500346205816146

Epoch: 6| Step: 3
Training loss: 2.6859367614709573
Validation loss: 2.4494383959554575

Epoch: 6| Step: 4
Training loss: 2.0748655528438293
Validation loss: 2.4381708337408825

Epoch: 6| Step: 5
Training loss: 2.453353093713847
Validation loss: 2.456799920698888

Epoch: 6| Step: 6
Training loss: 2.671313310443249
Validation loss: 2.443350557273473

Epoch: 6| Step: 7
Training loss: 2.848410675207104
Validation loss: 2.4499017804171546

Epoch: 6| Step: 8
Training loss: 1.999200661187217
Validation loss: 2.440083064020877

Epoch: 6| Step: 9
Training loss: 2.153342456660514
Validation loss: 2.4499819196327315

Epoch: 6| Step: 10
Training loss: 2.6245288426040205
Validation loss: 2.448356085937615

Epoch: 6| Step: 11
Training loss: 2.8253465355526695
Validation loss: 2.450231450407245

Epoch: 6| Step: 12
Training loss: 2.139918524002182
Validation loss: 2.4412577518052134

Epoch: 6| Step: 13
Training loss: 2.859244922118111
Validation loss: 2.456052757504947

Epoch: 123| Step: 0
Training loss: 2.6604355092726872
Validation loss: 2.4566577685103397

Epoch: 6| Step: 1
Training loss: 3.1334812278203517
Validation loss: 2.4578192353908452

Epoch: 6| Step: 2
Training loss: 2.3587399063743444
Validation loss: 2.4578656801049306

Epoch: 6| Step: 3
Training loss: 2.481124767150668
Validation loss: 2.4411814622658006

Epoch: 6| Step: 4
Training loss: 2.3237209780780397
Validation loss: 2.4598162019666274

Epoch: 6| Step: 5
Training loss: 2.5869429094571785
Validation loss: 2.4402033684044806

Epoch: 6| Step: 6
Training loss: 3.13364313771929
Validation loss: 2.4693108707246076

Epoch: 6| Step: 7
Training loss: 2.553115967976202
Validation loss: 2.4420487120902403

Epoch: 6| Step: 8
Training loss: 2.2915172759405147
Validation loss: 2.4527457990322943

Epoch: 6| Step: 9
Training loss: 2.5124427143607346
Validation loss: 2.444439799861218

Epoch: 6| Step: 10
Training loss: 2.217911897785918
Validation loss: 2.447363147105702

Epoch: 6| Step: 11
Training loss: 2.1875431601489943
Validation loss: 2.4340323315989765

Epoch: 6| Step: 12
Training loss: 2.6586054512190156
Validation loss: 2.4458529785086194

Epoch: 6| Step: 13
Training loss: 2.328747659662599
Validation loss: 2.4560482482623507

Epoch: 124| Step: 0
Training loss: 2.812752606386037
Validation loss: 2.4537427427621177

Epoch: 6| Step: 1
Training loss: 2.7013839671513153
Validation loss: 2.452882797483493

Epoch: 6| Step: 2
Training loss: 2.6199699528259743
Validation loss: 2.466010436472432

Epoch: 6| Step: 3
Training loss: 1.726296175616066
Validation loss: 2.4695772171692885

Epoch: 6| Step: 4
Training loss: 2.70524293693549
Validation loss: 2.4452702317039003

Epoch: 6| Step: 5
Training loss: 2.7755297009214335
Validation loss: 2.4449930934832365

Epoch: 6| Step: 6
Training loss: 2.576631703092261
Validation loss: 2.455883677162796

Epoch: 6| Step: 7
Training loss: 2.8193074387793695
Validation loss: 2.4524580602308803

Epoch: 6| Step: 8
Training loss: 2.30138457957895
Validation loss: 2.44440871115017

Epoch: 6| Step: 9
Training loss: 2.5874057992198334
Validation loss: 2.4660309537420892

Epoch: 6| Step: 10
Training loss: 2.5369998946439836
Validation loss: 2.4455244794191637

Epoch: 6| Step: 11
Training loss: 2.869093591396741
Validation loss: 2.446645700946571

Epoch: 6| Step: 12
Training loss: 1.987458784047907
Validation loss: 2.4464232295334702

Epoch: 6| Step: 13
Training loss: 2.396375633452574
Validation loss: 2.447534683645286

Epoch: 125| Step: 0
Training loss: 2.4147190818335664
Validation loss: 2.444149378788934

Epoch: 6| Step: 1
Training loss: 3.3852624633099877
Validation loss: 2.4579068191584406

Epoch: 6| Step: 2
Training loss: 2.437105978394612
Validation loss: 2.4408928265583314

Epoch: 6| Step: 3
Training loss: 2.9459341187527004
Validation loss: 2.4219368330319444

Epoch: 6| Step: 4
Training loss: 2.622017392098644
Validation loss: 2.448166348080206

Epoch: 6| Step: 5
Training loss: 2.9223426811747832
Validation loss: 2.4557166031316315

Epoch: 6| Step: 6
Training loss: 1.752567655533529
Validation loss: 2.464726520563547

Epoch: 6| Step: 7
Training loss: 3.0372465930617865
Validation loss: 2.44305105254194

Epoch: 6| Step: 8
Training loss: 2.481474424729612
Validation loss: 2.441714056747099

Epoch: 6| Step: 9
Training loss: 2.192024891614546
Validation loss: 2.459018876221417

Epoch: 6| Step: 10
Training loss: 2.119026539627801
Validation loss: 2.4431545151719405

Epoch: 6| Step: 11
Training loss: 2.220207487840382
Validation loss: 2.4659207374268886

Epoch: 6| Step: 12
Training loss: 2.1029590376829415
Validation loss: 2.463312835947216

Epoch: 6| Step: 13
Training loss: 2.3087823213092094
Validation loss: 2.4677329595082047

Epoch: 126| Step: 0
Training loss: 2.463589840526168
Validation loss: 2.4526571153269363

Epoch: 6| Step: 1
Training loss: 2.555718730010936
Validation loss: 2.4507023030349786

Epoch: 6| Step: 2
Training loss: 2.200474761540786
Validation loss: 2.443929454696663

Epoch: 6| Step: 3
Training loss: 1.7942007980372119
Validation loss: 2.4454277174192853

Epoch: 6| Step: 4
Training loss: 2.5806799048922926
Validation loss: 2.4502280635800653

Epoch: 6| Step: 5
Training loss: 2.681033138583995
Validation loss: 2.4574594093163307

Epoch: 6| Step: 6
Training loss: 2.7085002749905756
Validation loss: 2.4535152599590972

Epoch: 6| Step: 7
Training loss: 2.885566698344237
Validation loss: 2.445397475757197

Epoch: 6| Step: 8
Training loss: 2.386044770772821
Validation loss: 2.4472245244336723

Epoch: 6| Step: 9
Training loss: 2.9427496893123197
Validation loss: 2.4498965786285645

Epoch: 6| Step: 10
Training loss: 2.1016605169986273
Validation loss: 2.458916653490293

Epoch: 6| Step: 11
Training loss: 2.5068910991691005
Validation loss: 2.459108964110723

Epoch: 6| Step: 12
Training loss: 3.256293292499142
Validation loss: 2.44817340440934

Epoch: 6| Step: 13
Training loss: 1.9612912774589655
Validation loss: 2.457281788436713

Epoch: 127| Step: 0
Training loss: 2.880207487155636
Validation loss: 2.447862856414663

Epoch: 6| Step: 1
Training loss: 2.4879152037714682
Validation loss: 2.451404715297755

Epoch: 6| Step: 2
Training loss: 2.4622782612221665
Validation loss: 2.4397174728725606

Epoch: 6| Step: 3
Training loss: 2.4433341021187456
Validation loss: 2.459692622150715

Epoch: 6| Step: 4
Training loss: 2.7305760614921524
Validation loss: 2.4587914415612686

Epoch: 6| Step: 5
Training loss: 2.2015432536987536
Validation loss: 2.4660809524365757

Epoch: 6| Step: 6
Training loss: 2.3123750395133262
Validation loss: 2.4398668554879888

Epoch: 6| Step: 7
Training loss: 2.661879285355267
Validation loss: 2.4688583169573297

Epoch: 6| Step: 8
Training loss: 2.5006446960787154
Validation loss: 2.4476646567656175

Epoch: 6| Step: 9
Training loss: 2.7238454315147798
Validation loss: 2.453728156435414

Epoch: 6| Step: 10
Training loss: 2.9320987798332627
Validation loss: 2.4564873339690774

Epoch: 6| Step: 11
Training loss: 2.436510227450412
Validation loss: 2.4594893760690772

Epoch: 6| Step: 12
Training loss: 2.316238062704816
Validation loss: 2.438456954087734

Epoch: 6| Step: 13
Training loss: 2.2883162079365
Validation loss: 2.4544935399196746

Epoch: 128| Step: 0
Training loss: 2.128776112349824
Validation loss: 2.4528221642063803

Epoch: 6| Step: 1
Training loss: 2.5136688398388825
Validation loss: 2.4492318580107764

Epoch: 6| Step: 2
Training loss: 2.4869415653175686
Validation loss: 2.4476663252450512

Epoch: 6| Step: 3
Training loss: 2.484141884669176
Validation loss: 2.4309335043452176

Epoch: 6| Step: 4
Training loss: 2.5230718294578938
Validation loss: 2.453152969584436

Epoch: 6| Step: 5
Training loss: 2.615407765618307
Validation loss: 2.455518741944511

Epoch: 6| Step: 6
Training loss: 2.220263220329429
Validation loss: 2.45219245963555

Epoch: 6| Step: 7
Training loss: 2.375997534618961
Validation loss: 2.4384976836040977

Epoch: 6| Step: 8
Training loss: 2.4062006561372256
Validation loss: 2.454669671685719

Epoch: 6| Step: 9
Training loss: 2.477995737560138
Validation loss: 2.4491271740959077

Epoch: 6| Step: 10
Training loss: 3.062623624836592
Validation loss: 2.4674670456861723

Epoch: 6| Step: 11
Training loss: 3.0649354553894157
Validation loss: 2.434184669732243

Epoch: 6| Step: 12
Training loss: 2.201985165787708
Validation loss: 2.4637652793461227

Epoch: 6| Step: 13
Training loss: 2.849538759084769
Validation loss: 2.452643512401545

Epoch: 129| Step: 0
Training loss: 3.214715595866093
Validation loss: 2.4671792765311227

Epoch: 6| Step: 1
Training loss: 2.1251802928959305
Validation loss: 2.466839413578993

Epoch: 6| Step: 2
Training loss: 2.2849465298396097
Validation loss: 2.46702641063295

Epoch: 6| Step: 3
Training loss: 2.673188449979766
Validation loss: 2.4445881503787716

Epoch: 6| Step: 4
Training loss: 2.878448739829693
Validation loss: 2.4383758767649124

Epoch: 6| Step: 5
Training loss: 2.5894566127208654
Validation loss: 2.448631950468129

Epoch: 6| Step: 6
Training loss: 3.28508831956372
Validation loss: 2.434466034339195

Epoch: 6| Step: 7
Training loss: 2.555399850810431
Validation loss: 2.4594098416451695

Epoch: 6| Step: 8
Training loss: 1.717027043351236
Validation loss: 2.4447464696529067

Epoch: 6| Step: 9
Training loss: 2.6378327001659794
Validation loss: 2.4456655449343456

Epoch: 6| Step: 10
Training loss: 2.446987078403018
Validation loss: 2.4503815500540025

Epoch: 6| Step: 11
Training loss: 2.2979923566686145
Validation loss: 2.4498027467627304

Epoch: 6| Step: 12
Training loss: 2.0579141439651667
Validation loss: 2.439518272014542

Epoch: 6| Step: 13
Training loss: 1.9776677596046714
Validation loss: 2.440748270079344

Epoch: 130| Step: 0
Training loss: 2.337807407666807
Validation loss: 2.44593912405846

Epoch: 6| Step: 1
Training loss: 2.7609722418075373
Validation loss: 2.464207705383575

Epoch: 6| Step: 2
Training loss: 2.035385616798405
Validation loss: 2.449646765713942

Epoch: 6| Step: 3
Training loss: 2.496863877673914
Validation loss: 2.455909653906081

Epoch: 6| Step: 4
Training loss: 2.9794020837633512
Validation loss: 2.4499751583637233

Epoch: 6| Step: 5
Training loss: 2.3325106896322114
Validation loss: 2.4417855069167542

Epoch: 6| Step: 6
Training loss: 1.9090596114933094
Validation loss: 2.4456711236529607

Epoch: 6| Step: 7
Training loss: 2.895080761351243
Validation loss: 2.445333803187548

Epoch: 6| Step: 8
Training loss: 2.57424672043558
Validation loss: 2.4553976912573634

Epoch: 6| Step: 9
Training loss: 2.3955109973735453
Validation loss: 2.440449760130676

Epoch: 6| Step: 10
Training loss: 2.4034827036829443
Validation loss: 2.4435011383538585

Epoch: 6| Step: 11
Training loss: 2.570780146299545
Validation loss: 2.44640885578176

Epoch: 6| Step: 12
Training loss: 2.620085793903194
Validation loss: 2.4518794172502316

Epoch: 6| Step: 13
Training loss: 3.1692071227558274
Validation loss: 2.453976620961359

Epoch: 131| Step: 0
Training loss: 2.1891666058135075
Validation loss: 2.4459541986150817

Epoch: 6| Step: 1
Training loss: 2.369478030287862
Validation loss: 2.4648582507863495

Epoch: 6| Step: 2
Training loss: 2.846131218604157
Validation loss: 2.45164902135056

Epoch: 6| Step: 3
Training loss: 1.9952019119385076
Validation loss: 2.4535454046984384

Epoch: 6| Step: 4
Training loss: 2.057228866455619
Validation loss: 2.459710110178658

Epoch: 6| Step: 5
Training loss: 2.183400918433826
Validation loss: 2.4618429101509642

Epoch: 6| Step: 6
Training loss: 3.0122008179062396
Validation loss: 2.4423351213072424

Epoch: 6| Step: 7
Training loss: 1.9699827300926787
Validation loss: 2.445182365155713

Epoch: 6| Step: 8
Training loss: 3.196058265565515
Validation loss: 2.4516933264167875

Epoch: 6| Step: 9
Training loss: 2.979561483902042
Validation loss: 2.45930599855898

Epoch: 6| Step: 10
Training loss: 3.0069296593971897
Validation loss: 2.447863806313306

Epoch: 6| Step: 11
Training loss: 2.2611947778608754
Validation loss: 2.4523612811923416

Epoch: 6| Step: 12
Training loss: 2.534770354303118
Validation loss: 2.452498652349829

Epoch: 6| Step: 13
Training loss: 2.125160211245711
Validation loss: 2.450173956890121

Epoch: 132| Step: 0
Training loss: 2.1078279826936694
Validation loss: 2.4540902313168917

Epoch: 6| Step: 1
Training loss: 2.6428886507431693
Validation loss: 2.4588398134449974

Epoch: 6| Step: 2
Training loss: 2.68793253412049
Validation loss: 2.454599317209515

Epoch: 6| Step: 3
Training loss: 2.6292295441360873
Validation loss: 2.452803978007202

Epoch: 6| Step: 4
Training loss: 2.659185067016226
Validation loss: 2.4505061538994335

Epoch: 6| Step: 5
Training loss: 2.756599829654208
Validation loss: 2.4572708579350495

Epoch: 6| Step: 6
Training loss: 2.737742154633107
Validation loss: 2.4514469395221803

Epoch: 6| Step: 7
Training loss: 2.512614373787495
Validation loss: 2.449696017240497

Epoch: 6| Step: 8
Training loss: 1.6893697199878326
Validation loss: 2.434278452771862

Epoch: 6| Step: 9
Training loss: 2.579597838499702
Validation loss: 2.462087415369578

Epoch: 6| Step: 10
Training loss: 2.6018071789851476
Validation loss: 2.453288109266342

Epoch: 6| Step: 11
Training loss: 2.098670983976959
Validation loss: 2.4521501541564574

Epoch: 6| Step: 12
Training loss: 3.017111772468962
Validation loss: 2.449077852510222

Epoch: 6| Step: 13
Training loss: 2.1035116579944604
Validation loss: 2.4419598530182633

Epoch: 133| Step: 0
Training loss: 2.7161126334385353
Validation loss: 2.4541464270782556

Epoch: 6| Step: 1
Training loss: 2.264522099888042
Validation loss: 2.4326590591490356

Epoch: 6| Step: 2
Training loss: 2.6580600629956486
Validation loss: 2.4496864133647245

Epoch: 6| Step: 3
Training loss: 2.937767665923865
Validation loss: 2.4372355651876694

Epoch: 6| Step: 4
Training loss: 2.041483760607519
Validation loss: 2.4561296315109225

Epoch: 6| Step: 5
Training loss: 2.734589312192941
Validation loss: 2.4332852131542384

Epoch: 6| Step: 6
Training loss: 2.4162920190085195
Validation loss: 2.457383917473107

Epoch: 6| Step: 7
Training loss: 2.591702491864267
Validation loss: 2.453305910983731

Epoch: 6| Step: 8
Training loss: 2.3657924456778985
Validation loss: 2.4443360077701777

Epoch: 6| Step: 9
Training loss: 2.802783542959406
Validation loss: 2.449264560218775

Epoch: 6| Step: 10
Training loss: 1.9046322571251364
Validation loss: 2.456469366410358

Epoch: 6| Step: 11
Training loss: 2.3554693573149095
Validation loss: 2.4401959512643243

Epoch: 6| Step: 12
Training loss: 2.6898127518329407
Validation loss: 2.4177021906331464

Epoch: 6| Step: 13
Training loss: 2.743644827041336
Validation loss: 2.4576889710585816

Epoch: 134| Step: 0
Training loss: 2.383698845781054
Validation loss: 2.4438368329808977

Epoch: 6| Step: 1
Training loss: 2.529393681032322
Validation loss: 2.458621004256472

Epoch: 6| Step: 2
Training loss: 2.0156089131504364
Validation loss: 2.442639074654062

Epoch: 6| Step: 3
Training loss: 2.3078039790301603
Validation loss: 2.4558111349866816

Epoch: 6| Step: 4
Training loss: 2.6221390528698985
Validation loss: 2.452985132139968

Epoch: 6| Step: 5
Training loss: 2.7749428545592316
Validation loss: 2.4493092925482784

Epoch: 6| Step: 6
Training loss: 2.1184384637412066
Validation loss: 2.451147700848596

Epoch: 6| Step: 7
Training loss: 2.668876705690659
Validation loss: 2.452047069000964

Epoch: 6| Step: 8
Training loss: 3.4051957204979364
Validation loss: 2.458950825165652

Epoch: 6| Step: 9
Training loss: 2.510410472392649
Validation loss: 2.4186230503353414

Epoch: 6| Step: 10
Training loss: 2.9877061078468268
Validation loss: 2.4324884728764777

Epoch: 6| Step: 11
Training loss: 2.2032436041324144
Validation loss: 2.4418360718748677

Epoch: 6| Step: 12
Training loss: 1.7174880510161639
Validation loss: 2.4322200159507945

Epoch: 6| Step: 13
Training loss: 2.7456255713101214
Validation loss: 2.4607703638364016

Epoch: 135| Step: 0
Training loss: 2.399795595047681
Validation loss: 2.450541515162156

Epoch: 6| Step: 1
Training loss: 2.476650489182688
Validation loss: 2.4349494560109974

Epoch: 6| Step: 2
Training loss: 2.465892731764521
Validation loss: 2.458783033677183

Epoch: 6| Step: 3
Training loss: 1.7324293753580946
Validation loss: 2.442461649190094

Epoch: 6| Step: 4
Training loss: 2.3018412973431284
Validation loss: 2.443467882682757

Epoch: 6| Step: 5
Training loss: 2.3588665546999645
Validation loss: 2.4406212846785658

Epoch: 6| Step: 6
Training loss: 2.4897678790997517
Validation loss: 2.4463640520781693

Epoch: 6| Step: 7
Training loss: 2.272290336916509
Validation loss: 2.4452582871634903

Epoch: 6| Step: 8
Training loss: 2.439580274189617
Validation loss: 2.4555094103669717

Epoch: 6| Step: 9
Training loss: 3.1375617275776984
Validation loss: 2.4471854691160844

Epoch: 6| Step: 10
Training loss: 2.3675071576019335
Validation loss: 2.4579323760914473

Epoch: 6| Step: 11
Training loss: 2.8247823614496186
Validation loss: 2.452797490518348

Epoch: 6| Step: 12
Training loss: 2.7849622661561457
Validation loss: 2.447147963104978

Epoch: 6| Step: 13
Training loss: 2.989062557429838
Validation loss: 2.4534571354676027

Epoch: 136| Step: 0
Training loss: 2.723643054306891
Validation loss: 2.4515866415552643

Epoch: 6| Step: 1
Training loss: 3.1999406570654143
Validation loss: 2.45388514426048

Epoch: 6| Step: 2
Training loss: 1.9722266607577863
Validation loss: 2.4625035832018134

Epoch: 6| Step: 3
Training loss: 2.272995738732455
Validation loss: 2.454784650432279

Epoch: 6| Step: 4
Training loss: 2.3748125705043828
Validation loss: 2.4482244720021575

Epoch: 6| Step: 5
Training loss: 1.8592422822661547
Validation loss: 2.4479192736805317

Epoch: 6| Step: 6
Training loss: 2.2331690167952947
Validation loss: 2.447210788648495

Epoch: 6| Step: 7
Training loss: 1.5865613339960647
Validation loss: 2.454552807556427

Epoch: 6| Step: 8
Training loss: 2.428774352371238
Validation loss: 2.430154903769316

Epoch: 6| Step: 9
Training loss: 2.4210569907614006
Validation loss: 2.4504173023034115

Epoch: 6| Step: 10
Training loss: 3.2176654062384897
Validation loss: 2.429679727886457

Epoch: 6| Step: 11
Training loss: 2.533380247819404
Validation loss: 2.4528003125310747

Epoch: 6| Step: 12
Training loss: 2.9531330734223307
Validation loss: 2.442835790940727

Epoch: 6| Step: 13
Training loss: 2.977136111119762
Validation loss: 2.4476991038796556

Epoch: 137| Step: 0
Training loss: 2.344880708698185
Validation loss: 2.4379095507011592

Epoch: 6| Step: 1
Training loss: 2.1158113969424686
Validation loss: 2.451198295970867

Epoch: 6| Step: 2
Training loss: 1.6506036925610703
Validation loss: 2.451025386247715

Epoch: 6| Step: 3
Training loss: 2.19273534714345
Validation loss: 2.4634397037664506

Epoch: 6| Step: 4
Training loss: 2.477858339757198
Validation loss: 2.436855177231289

Epoch: 6| Step: 5
Training loss: 3.1546959403134367
Validation loss: 2.4454600338706407

Epoch: 6| Step: 6
Training loss: 2.53688683829655
Validation loss: 2.448125086708621

Epoch: 6| Step: 7
Training loss: 2.2962367410126436
Validation loss: 2.4544303519090462

Epoch: 6| Step: 8
Training loss: 2.8381668449967954
Validation loss: 2.4442763770296487

Epoch: 6| Step: 9
Training loss: 3.161778961128631
Validation loss: 2.4552012949186874

Epoch: 6| Step: 10
Training loss: 2.466020741390176
Validation loss: 2.4406009886700724

Epoch: 6| Step: 11
Training loss: 2.3584423116389983
Validation loss: 2.4558422975274845

Epoch: 6| Step: 12
Training loss: 2.211123509215202
Validation loss: 2.43796830770382

Epoch: 6| Step: 13
Training loss: 3.0628177711512294
Validation loss: 2.4426725672563587

Epoch: 138| Step: 0
Training loss: 2.7250312068447196
Validation loss: 2.4338025019495353

Epoch: 6| Step: 1
Training loss: 2.3124944325972887
Validation loss: 2.4456666990445957

Epoch: 6| Step: 2
Training loss: 2.5123444010820726
Validation loss: 2.4412797640285735

Epoch: 6| Step: 3
Training loss: 2.877387009563993
Validation loss: 2.449064380441258

Epoch: 6| Step: 4
Training loss: 2.2352517281932953
Validation loss: 2.453413945843652

Epoch: 6| Step: 5
Training loss: 2.3343027576058466
Validation loss: 2.4481085400775697

Epoch: 6| Step: 6
Training loss: 2.2112907424028445
Validation loss: 2.455100038372088

Epoch: 6| Step: 7
Training loss: 2.2299838365730262
Validation loss: 2.4652569775472

Epoch: 6| Step: 8
Training loss: 2.7474236991638277
Validation loss: 2.434510358315853

Epoch: 6| Step: 9
Training loss: 2.653796150859169
Validation loss: 2.44726099271591

Epoch: 6| Step: 10
Training loss: 1.8446981287512225
Validation loss: 2.451729664966214

Epoch: 6| Step: 11
Training loss: 2.612407178918159
Validation loss: 2.4410008967085908

Epoch: 6| Step: 12
Training loss: 3.0995958372420183
Validation loss: 2.4500727510229763

Epoch: 6| Step: 13
Training loss: 2.2012913425252263
Validation loss: 2.4387840084309733

Epoch: 139| Step: 0
Training loss: 2.1771537246153954
Validation loss: 2.432601794756011

Epoch: 6| Step: 1
Training loss: 2.99931740942591
Validation loss: 2.4436129276826706

Epoch: 6| Step: 2
Training loss: 1.6827684402010847
Validation loss: 2.4496824481052624

Epoch: 6| Step: 3
Training loss: 2.0226408225922854
Validation loss: 2.4479460743063006

Epoch: 6| Step: 4
Training loss: 3.0199430710435173
Validation loss: 2.433487562165508

Epoch: 6| Step: 5
Training loss: 1.9450736148112524
Validation loss: 2.4452625353293738

Epoch: 6| Step: 6
Training loss: 3.1692166016869536
Validation loss: 2.458773808848168

Epoch: 6| Step: 7
Training loss: 2.242594824819973
Validation loss: 2.4535618300296416

Epoch: 6| Step: 8
Training loss: 2.564811966159104
Validation loss: 2.4428112976411875

Epoch: 6| Step: 9
Training loss: 2.319792409850197
Validation loss: 2.4616366891794086

Epoch: 6| Step: 10
Training loss: 1.982378097576981
Validation loss: 2.450712480888787

Epoch: 6| Step: 11
Training loss: 3.2056514545672217
Validation loss: 2.442067709033368

Epoch: 6| Step: 12
Training loss: 2.7803029365971055
Validation loss: 2.449154512091869

Epoch: 6| Step: 13
Training loss: 1.987492133071013
Validation loss: 2.454487724835661

Epoch: 140| Step: 0
Training loss: 2.230940413167889
Validation loss: 2.441543103523195

Epoch: 6| Step: 1
Training loss: 2.6093227358398017
Validation loss: 2.4526178224847732

Epoch: 6| Step: 2
Training loss: 2.7326667026998432
Validation loss: 2.4471396859761647

Epoch: 6| Step: 3
Training loss: 2.6191740325458426
Validation loss: 2.4604983222907477

Epoch: 6| Step: 4
Training loss: 2.55089098006467
Validation loss: 2.438600487887157

Epoch: 6| Step: 5
Training loss: 2.97042028722187
Validation loss: 2.4490376485804184

Epoch: 6| Step: 6
Training loss: 2.512943331193725
Validation loss: 2.451166522684477

Epoch: 6| Step: 7
Training loss: 1.8916566414364357
Validation loss: 2.438704723817671

Epoch: 6| Step: 8
Training loss: 3.0301744578279726
Validation loss: 2.4480572669067895

Epoch: 6| Step: 9
Training loss: 2.774649857434243
Validation loss: 2.4353030747914994

Epoch: 6| Step: 10
Training loss: 2.115163588814418
Validation loss: 2.452608057057767

Epoch: 6| Step: 11
Training loss: 1.9779429082239355
Validation loss: 2.4517267141522106

Epoch: 6| Step: 12
Training loss: 1.968879332154452
Validation loss: 2.4548417430330884

Epoch: 6| Step: 13
Training loss: 2.326936456820076
Validation loss: 2.441366961419423

Epoch: 141| Step: 0
Training loss: 2.109664218996199
Validation loss: 2.433686575097562

Epoch: 6| Step: 1
Training loss: 2.040631855928316
Validation loss: 2.416791085960859

Epoch: 6| Step: 2
Training loss: 2.176322499863723
Validation loss: 2.447797461238309

Epoch: 6| Step: 3
Training loss: 2.9614540796901245
Validation loss: 2.4515998780752435

Epoch: 6| Step: 4
Training loss: 1.9739044168669566
Validation loss: 2.4505006897589143

Epoch: 6| Step: 5
Training loss: 1.8063370073211544
Validation loss: 2.4511669274423076

Epoch: 6| Step: 6
Training loss: 1.991306484113351
Validation loss: 2.4629677477312004

Epoch: 6| Step: 7
Training loss: 2.7027983716193433
Validation loss: 2.4387742564637453

Epoch: 6| Step: 8
Training loss: 2.7162026935500836
Validation loss: 2.4402333639928337

Epoch: 6| Step: 9
Training loss: 2.034120145852066
Validation loss: 2.441393222831507

Epoch: 6| Step: 10
Training loss: 2.4704209479427144
Validation loss: 2.449604446619907

Epoch: 6| Step: 11
Training loss: 3.487674536490662
Validation loss: 2.4487707682807307

Epoch: 6| Step: 12
Training loss: 2.6645700636814897
Validation loss: 2.4542839845263265

Epoch: 6| Step: 13
Training loss: 3.2959882800254965
Validation loss: 2.4409400123947296

Epoch: 142| Step: 0
Training loss: 2.55139797635699
Validation loss: 2.4395633070555243

Epoch: 6| Step: 1
Training loss: 3.1746405210266153
Validation loss: 2.442451568681571

Epoch: 6| Step: 2
Training loss: 2.3530279010329544
Validation loss: 2.452142763743219

Epoch: 6| Step: 3
Training loss: 2.5651076470107785
Validation loss: 2.447521654530333

Epoch: 6| Step: 4
Training loss: 2.63415520272621
Validation loss: 2.4490698462161666

Epoch: 6| Step: 5
Training loss: 2.037080349445661
Validation loss: 2.4394727169978765

Epoch: 6| Step: 6
Training loss: 2.786340234458212
Validation loss: 2.4319509896662015

Epoch: 6| Step: 7
Training loss: 2.7967611961014476
Validation loss: 2.4426785726186333

Epoch: 6| Step: 8
Training loss: 2.564240864484085
Validation loss: 2.449407877260597

Epoch: 6| Step: 9
Training loss: 2.1921530146479573
Validation loss: 2.442004608924423

Epoch: 6| Step: 10
Training loss: 2.165107997817179
Validation loss: 2.4475923224278366

Epoch: 6| Step: 11
Training loss: 2.249636196818474
Validation loss: 2.452034679671794

Epoch: 6| Step: 12
Training loss: 2.1877843399534953
Validation loss: 2.4427390662169923

Epoch: 6| Step: 13
Training loss: 2.1558650682156095
Validation loss: 2.445882458825958

Epoch: 143| Step: 0
Training loss: 2.6619684037899245
Validation loss: 2.433020473038916

Epoch: 6| Step: 1
Training loss: 2.5995704882985597
Validation loss: 2.4315303559547714

Epoch: 6| Step: 2
Training loss: 2.1356964176194193
Validation loss: 2.443127436378332

Epoch: 6| Step: 3
Training loss: 3.1675608192391667
Validation loss: 2.4385995175597954

Epoch: 6| Step: 4
Training loss: 1.9294461860042325
Validation loss: 2.434828824646856

Epoch: 6| Step: 5
Training loss: 2.6284883118751092
Validation loss: 2.4282059534093183

Epoch: 6| Step: 6
Training loss: 1.9555108718511331
Validation loss: 2.4287749329118635

Epoch: 6| Step: 7
Training loss: 2.7222483259580033
Validation loss: 2.446039582315693

Epoch: 6| Step: 8
Training loss: 2.0308508847677884
Validation loss: 2.4576187520437243

Epoch: 6| Step: 9
Training loss: 2.153160092714236
Validation loss: 2.428415146336455

Epoch: 6| Step: 10
Training loss: 2.632032692088782
Validation loss: 2.438599935967524

Epoch: 6| Step: 11
Training loss: 2.5290223668603797
Validation loss: 2.466102547134715

Epoch: 6| Step: 12
Training loss: 2.5183250201239757
Validation loss: 2.4569868147690728

Epoch: 6| Step: 13
Training loss: 2.8396669356385593
Validation loss: 2.441183702264363

Epoch: 144| Step: 0
Training loss: 3.227190820140577
Validation loss: 2.454756408063846

Epoch: 6| Step: 1
Training loss: 2.7556261251840524
Validation loss: 2.4342039618523734

Epoch: 6| Step: 2
Training loss: 2.73656389090701
Validation loss: 2.441244256008356

Epoch: 6| Step: 3
Training loss: 2.411727417886108
Validation loss: 2.4531672803073707

Epoch: 6| Step: 4
Training loss: 1.6272090422081815
Validation loss: 2.438163993979905

Epoch: 6| Step: 5
Training loss: 2.104082943097326
Validation loss: 2.4340473614071048

Epoch: 6| Step: 6
Training loss: 2.263753183532195
Validation loss: 2.440887139241763

Epoch: 6| Step: 7
Training loss: 3.1951993814978765
Validation loss: 2.4322865640612603

Epoch: 6| Step: 8
Training loss: 2.3787087043709754
Validation loss: 2.4339026121770724

Epoch: 6| Step: 9
Training loss: 2.6303976966499767
Validation loss: 2.434536532576674

Epoch: 6| Step: 10
Training loss: 1.581118775000145
Validation loss: 2.443719156011494

Epoch: 6| Step: 11
Training loss: 2.4724082400552634
Validation loss: 2.445627374081916

Epoch: 6| Step: 12
Training loss: 2.560839789751005
Validation loss: 2.451864441858344

Epoch: 6| Step: 13
Training loss: 2.1075913411502487
Validation loss: 2.43616597913474

Epoch: 145| Step: 0
Training loss: 3.032183631187628
Validation loss: 2.4412109695926207

Epoch: 6| Step: 1
Training loss: 2.473018384693141
Validation loss: 2.4349993638279135

Epoch: 6| Step: 2
Training loss: 2.5428236115695606
Validation loss: 2.4197021793572753

Epoch: 6| Step: 3
Training loss: 2.75040606188414
Validation loss: 2.4335143479067107

Epoch: 6| Step: 4
Training loss: 1.9618212163819584
Validation loss: 2.4425273792993005

Epoch: 6| Step: 5
Training loss: 2.699616376679804
Validation loss: 2.4491152651143198

Epoch: 6| Step: 6
Training loss: 2.3223129537137264
Validation loss: 2.4282114402689943

Epoch: 6| Step: 7
Training loss: 2.598826392933062
Validation loss: 2.4374729130798864

Epoch: 6| Step: 8
Training loss: 2.1878509240004025
Validation loss: 2.4300765466071987

Epoch: 6| Step: 9
Training loss: 1.7913336851027133
Validation loss: 2.438197442909789

Epoch: 6| Step: 10
Training loss: 2.746751340267708
Validation loss: 2.444908332258006

Epoch: 6| Step: 11
Training loss: 2.435091246788914
Validation loss: 2.4368129473969558

Epoch: 6| Step: 12
Training loss: 2.422262837519562
Validation loss: 2.4514151835765374

Epoch: 6| Step: 13
Training loss: 2.5070446894907477
Validation loss: 2.4443853809853637

Epoch: 146| Step: 0
Training loss: 2.277543492660879
Validation loss: 2.4560046428330433

Epoch: 6| Step: 1
Training loss: 2.3634597080412485
Validation loss: 2.4480563369802932

Epoch: 6| Step: 2
Training loss: 2.8480375058244087
Validation loss: 2.429166141407865

Epoch: 6| Step: 3
Training loss: 2.21383466389597
Validation loss: 2.441058642508522

Epoch: 6| Step: 4
Training loss: 2.2519582068459574
Validation loss: 2.4372872237907126

Epoch: 6| Step: 5
Training loss: 2.263990878386707
Validation loss: 2.4354406060068454

Epoch: 6| Step: 6
Training loss: 3.4132859942262894
Validation loss: 2.421909159757834

Epoch: 6| Step: 7
Training loss: 1.6740615664136462
Validation loss: 2.44107176545645

Epoch: 6| Step: 8
Training loss: 1.8166880399280787
Validation loss: 2.4368347625364084

Epoch: 6| Step: 9
Training loss: 2.1396667117544586
Validation loss: 2.442149740831598

Epoch: 6| Step: 10
Training loss: 2.755122009732633
Validation loss: 2.4510727138094035

Epoch: 6| Step: 11
Training loss: 2.870659246458441
Validation loss: 2.4263743935892244

Epoch: 6| Step: 12
Training loss: 2.4205035849018497
Validation loss: 2.4507664904358752

Epoch: 6| Step: 13
Training loss: 2.9381132094538804
Validation loss: 2.4489722345271616

Epoch: 147| Step: 0
Training loss: 2.5748075468864497
Validation loss: 2.439198195044618

Epoch: 6| Step: 1
Training loss: 1.9847336092136487
Validation loss: 2.4498558314257055

Epoch: 6| Step: 2
Training loss: 2.1814632497345965
Validation loss: 2.4559605157512236

Epoch: 6| Step: 3
Training loss: 2.116708736552275
Validation loss: 2.448366531650381

Epoch: 6| Step: 4
Training loss: 2.1953217312764655
Validation loss: 2.4335031041679027

Epoch: 6| Step: 5
Training loss: 2.4502625499879174
Validation loss: 2.447139044840604

Epoch: 6| Step: 6
Training loss: 2.739345196912781
Validation loss: 2.4322562175055116

Epoch: 6| Step: 7
Training loss: 2.722349918596922
Validation loss: 2.434136701010586

Epoch: 6| Step: 8
Training loss: 3.44363701664458
Validation loss: 2.4652884085683713

Epoch: 6| Step: 9
Training loss: 2.6431648634932836
Validation loss: 2.438551094264839

Epoch: 6| Step: 10
Training loss: 1.4947709493054282
Validation loss: 2.4400974377382108

Epoch: 6| Step: 11
Training loss: 2.223538242183643
Validation loss: 2.443608953616846

Epoch: 6| Step: 12
Training loss: 2.2541664541906044
Validation loss: 2.428024275079438

Epoch: 6| Step: 13
Training loss: 3.1732885659156183
Validation loss: 2.438129935259553

Epoch: 148| Step: 0
Training loss: 2.5323423689412845
Validation loss: 2.4271695687113306

Epoch: 6| Step: 1
Training loss: 2.6091686783958177
Validation loss: 2.4329461627766107

Epoch: 6| Step: 2
Training loss: 2.3853951887693587
Validation loss: 2.433788927417922

Epoch: 6| Step: 3
Training loss: 2.2797488146165055
Validation loss: 2.4405218964914113

Epoch: 6| Step: 4
Training loss: 3.2621552500778304
Validation loss: 2.4466036558200552

Epoch: 6| Step: 5
Training loss: 2.4239642576094163
Validation loss: 2.430596466384255

Epoch: 6| Step: 6
Training loss: 2.817556117395075
Validation loss: 2.441810166939929

Epoch: 6| Step: 7
Training loss: 2.0936952270631237
Validation loss: 2.449443646861667

Epoch: 6| Step: 8
Training loss: 2.6312897124204504
Validation loss: 2.442824120998741

Epoch: 6| Step: 9
Training loss: 2.62646307362775
Validation loss: 2.4422341852611935

Epoch: 6| Step: 10
Training loss: 2.2525836098381617
Validation loss: 2.446416697354147

Epoch: 6| Step: 11
Training loss: 2.4598848543898737
Validation loss: 2.4451618648134104

Epoch: 6| Step: 12
Training loss: 1.8738030745895655
Validation loss: 2.4374373622236747

Epoch: 6| Step: 13
Training loss: 1.4803349175264684
Validation loss: 2.4389756108567715

Epoch: 149| Step: 0
Training loss: 3.2551639319888475
Validation loss: 2.427577806029351

Epoch: 6| Step: 1
Training loss: 2.0955850331505403
Validation loss: 2.4462086901676834

Epoch: 6| Step: 2
Training loss: 2.7199011809966933
Validation loss: 2.429356378121722

Epoch: 6| Step: 3
Training loss: 3.169975426034113
Validation loss: 2.435804369949887

Epoch: 6| Step: 4
Training loss: 1.804406280405002
Validation loss: 2.4345748151907474

Epoch: 6| Step: 5
Training loss: 2.4787432097910926
Validation loss: 2.4382899140063423

Epoch: 6| Step: 6
Training loss: 2.8071096688031245
Validation loss: 2.445847397584395

Epoch: 6| Step: 7
Training loss: 1.6450799674450298
Validation loss: 2.4297911022414107

Epoch: 6| Step: 8
Training loss: 2.1143527602092544
Validation loss: 2.450106382665844

Epoch: 6| Step: 9
Training loss: 2.0362912342821224
Validation loss: 2.437616629974711

Epoch: 6| Step: 10
Training loss: 2.4243008185708597
Validation loss: 2.4308205191655827

Epoch: 6| Step: 11
Training loss: 2.5064736473392073
Validation loss: 2.4382876019562465

Epoch: 6| Step: 12
Training loss: 2.5333943644082013
Validation loss: 2.4424101913478995

Epoch: 6| Step: 13
Training loss: 2.357614833263985
Validation loss: 2.418187858902256

Epoch: 150| Step: 0
Training loss: 2.3976683734725266
Validation loss: 2.4292868735071904

Epoch: 6| Step: 1
Training loss: 2.854723038475678
Validation loss: 2.441522399370846

Epoch: 6| Step: 2
Training loss: 2.405417459305959
Validation loss: 2.421694377471338

Epoch: 6| Step: 3
Training loss: 2.7094111914235954
Validation loss: 2.433326842579913

Epoch: 6| Step: 4
Training loss: 2.3074973354138235
Validation loss: 2.426838017188078

Epoch: 6| Step: 5
Training loss: 2.1248555975824317
Validation loss: 2.433844497512693

Epoch: 6| Step: 6
Training loss: 2.4641787543294367
Validation loss: 2.426169781796383

Epoch: 6| Step: 7
Training loss: 2.5070767378016323
Validation loss: 2.442832032847689

Epoch: 6| Step: 8
Training loss: 1.569664588987334
Validation loss: 2.4293994435393618

Epoch: 6| Step: 9
Training loss: 2.310173513988481
Validation loss: 2.4330318770603285

Epoch: 6| Step: 10
Training loss: 2.3169335831304476
Validation loss: 2.4420875603451067

Epoch: 6| Step: 11
Training loss: 2.5839585398840756
Validation loss: 2.436916093117212

Epoch: 6| Step: 12
Training loss: 3.0782870332313004
Validation loss: 2.4258185125152907

Epoch: 6| Step: 13
Training loss: 2.2807017673525896
Validation loss: 2.422200515894165

Epoch: 151| Step: 0
Training loss: 2.092814677833858
Validation loss: 2.432064771933266

Epoch: 6| Step: 1
Training loss: 2.767380065938144
Validation loss: 2.426057174974651

Epoch: 6| Step: 2
Training loss: 2.0840988914251413
Validation loss: 2.441997706414518

Epoch: 6| Step: 3
Training loss: 2.347239630319221
Validation loss: 2.4338830690864492

Epoch: 6| Step: 4
Training loss: 1.9921176673767136
Validation loss: 2.4318880972220964

Epoch: 6| Step: 5
Training loss: 2.9654038695526963
Validation loss: 2.432684039314419

Epoch: 6| Step: 6
Training loss: 2.765619051652104
Validation loss: 2.445103656031006

Epoch: 6| Step: 7
Training loss: 2.884497834769349
Validation loss: 2.432479459762715

Epoch: 6| Step: 8
Training loss: 2.842541951563587
Validation loss: 2.4539756729065543

Epoch: 6| Step: 9
Training loss: 2.6364452983202886
Validation loss: 2.438665045853229

Epoch: 6| Step: 10
Training loss: 1.4508481800620476
Validation loss: 2.442304802513116

Epoch: 6| Step: 11
Training loss: 2.2726846084058097
Validation loss: 2.4386606726595326

Epoch: 6| Step: 12
Training loss: 2.5611212207744525
Validation loss: 2.4422726663217844

Epoch: 6| Step: 13
Training loss: 2.0708415956799286
Validation loss: 2.446996116655452

Epoch: 152| Step: 0
Training loss: 2.4693736966495843
Validation loss: 2.4410140057887766

Epoch: 6| Step: 1
Training loss: 2.3998683178062206
Validation loss: 2.443360422129142

Epoch: 6| Step: 2
Training loss: 2.4935048606676786
Validation loss: 2.4325008426673187

Epoch: 6| Step: 3
Training loss: 3.362353472725513
Validation loss: 2.4316801582328815

Epoch: 6| Step: 4
Training loss: 1.9918387313427877
Validation loss: 2.4442374817530585

Epoch: 6| Step: 5
Training loss: 2.304502007729998
Validation loss: 2.434000078813078

Epoch: 6| Step: 6
Training loss: 2.7354204195746896
Validation loss: 2.44177560000149

Epoch: 6| Step: 7
Training loss: 2.3641150146622034
Validation loss: 2.4468247540030688

Epoch: 6| Step: 8
Training loss: 2.8433423431301437
Validation loss: 2.43670147104754

Epoch: 6| Step: 9
Training loss: 2.5316472624821373
Validation loss: 2.428185528288353

Epoch: 6| Step: 10
Training loss: 2.147559302047454
Validation loss: 2.4349716921370352

Epoch: 6| Step: 11
Training loss: 2.267806482768345
Validation loss: 2.429479374772257

Epoch: 6| Step: 12
Training loss: 1.8526039252943716
Validation loss: 2.434299474446565

Epoch: 6| Step: 13
Training loss: 2.1663214946555804
Validation loss: 2.4414961886995616

Epoch: 153| Step: 0
Training loss: 1.5469074438526702
Validation loss: 2.436358271481932

Epoch: 6| Step: 1
Training loss: 2.1795751617906585
Validation loss: 2.437368535066475

Epoch: 6| Step: 2
Training loss: 1.8034421909544265
Validation loss: 2.428279406831019

Epoch: 6| Step: 3
Training loss: 2.8809219405282387
Validation loss: 2.4416385479412894

Epoch: 6| Step: 4
Training loss: 3.344042613693382
Validation loss: 2.4231022879896256

Epoch: 6| Step: 5
Training loss: 2.5215556683496847
Validation loss: 2.437888289899107

Epoch: 6| Step: 6
Training loss: 2.5732778586533738
Validation loss: 2.428951058836146

Epoch: 6| Step: 7
Training loss: 2.4558939280141434
Validation loss: 2.430090525880567

Epoch: 6| Step: 8
Training loss: 2.411270255107059
Validation loss: 2.429156200967752

Epoch: 6| Step: 9
Training loss: 2.138861828036957
Validation loss: 2.429123363138096

Epoch: 6| Step: 10
Training loss: 2.285514086232395
Validation loss: 2.43695292342937

Epoch: 6| Step: 11
Training loss: 2.334441557603072
Validation loss: 2.4239054678578618

Epoch: 6| Step: 12
Training loss: 2.2331072004854273
Validation loss: 2.4388378742861967

Epoch: 6| Step: 13
Training loss: 3.203058604971174
Validation loss: 2.451966673163174

Epoch: 154| Step: 0
Training loss: 2.210816396894502
Validation loss: 2.443777242512399

Epoch: 6| Step: 1
Training loss: 2.757363085559809
Validation loss: 2.4406769197921

Epoch: 6| Step: 2
Training loss: 1.9668036634068549
Validation loss: 2.4438763241753527

Epoch: 6| Step: 3
Training loss: 2.4750557055128772
Validation loss: 2.4397397506557743

Epoch: 6| Step: 4
Training loss: 2.1832744658398946
Validation loss: 2.4382603029870746

Epoch: 6| Step: 5
Training loss: 2.599666420004746
Validation loss: 2.4264487814974873

Epoch: 6| Step: 6
Training loss: 1.7465505663794594
Validation loss: 2.443598431963106

Epoch: 6| Step: 7
Training loss: 2.731147474376738
Validation loss: 2.4350047701045003

Epoch: 6| Step: 8
Training loss: 2.5439949836201663
Validation loss: 2.4316406292171373

Epoch: 6| Step: 9
Training loss: 2.253106304202243
Validation loss: 2.4114192099329843

Epoch: 6| Step: 10
Training loss: 2.3440354237011687
Validation loss: 2.426701106095623

Epoch: 6| Step: 11
Training loss: 2.68891018087541
Validation loss: 2.444321119886707

Epoch: 6| Step: 12
Training loss: 2.805199706504259
Validation loss: 2.4378422869375105

Epoch: 6| Step: 13
Training loss: 2.5969352926331326
Validation loss: 2.4408665167001824

Epoch: 155| Step: 0
Training loss: 2.3192070276675643
Validation loss: 2.4563100409666676

Epoch: 6| Step: 1
Training loss: 1.9960041660578793
Validation loss: 2.426027785557963

Epoch: 6| Step: 2
Training loss: 2.608796746603286
Validation loss: 2.4407037348210494

Epoch: 6| Step: 3
Training loss: 2.2950995193877852
Validation loss: 2.4339510410573784

Epoch: 6| Step: 4
Training loss: 2.428846992758786
Validation loss: 2.4328562262314137

Epoch: 6| Step: 5
Training loss: 1.7506463355902795
Validation loss: 2.4446291835846754

Epoch: 6| Step: 6
Training loss: 3.173473537884678
Validation loss: 2.4490506664898115

Epoch: 6| Step: 7
Training loss: 2.2383771146846425
Validation loss: 2.4442259275844473

Epoch: 6| Step: 8
Training loss: 2.35405550894034
Validation loss: 2.4374573448536023

Epoch: 6| Step: 9
Training loss: 2.4079021380236423
Validation loss: 2.4349581462332908

Epoch: 6| Step: 10
Training loss: 2.4802731414321326
Validation loss: 2.4109033274456295

Epoch: 6| Step: 11
Training loss: 2.435554510500762
Validation loss: 2.43861213073411

Epoch: 6| Step: 12
Training loss: 2.825406364313749
Validation loss: 2.427044170270878

Epoch: 6| Step: 13
Training loss: 2.6570941256963514
Validation loss: 2.431470762789711

Epoch: 156| Step: 0
Training loss: 2.4704868629104735
Validation loss: 2.4299864300041265

Epoch: 6| Step: 1
Training loss: 2.271879101189397
Validation loss: 2.450245596140839

Epoch: 6| Step: 2
Training loss: 2.7864767959315824
Validation loss: 2.4132364874108405

Epoch: 6| Step: 3
Training loss: 2.4137000148186694
Validation loss: 2.4305708509003967

Epoch: 6| Step: 4
Training loss: 2.258099494830165
Validation loss: 2.4239454191532386

Epoch: 6| Step: 5
Training loss: 1.7648410238149526
Validation loss: 2.4467237317939823

Epoch: 6| Step: 6
Training loss: 2.1992657996882103
Validation loss: 2.4297975393177444

Epoch: 6| Step: 7
Training loss: 2.676621977439759
Validation loss: 2.4372559586438474

Epoch: 6| Step: 8
Training loss: 2.2696083567877263
Validation loss: 2.4355567062027803

Epoch: 6| Step: 9
Training loss: 2.8146978479709532
Validation loss: 2.431172509322303

Epoch: 6| Step: 10
Training loss: 3.2531583551607874
Validation loss: 2.4441340649661125

Epoch: 6| Step: 11
Training loss: 2.3014419720925887
Validation loss: 2.4430215590450444

Epoch: 6| Step: 12
Training loss: 1.9865435668177505
Validation loss: 2.445621169978009

Epoch: 6| Step: 13
Training loss: 2.061574092298676
Validation loss: 2.4207252729375033

Epoch: 157| Step: 0
Training loss: 2.81710624725753
Validation loss: 2.4368015558103693

Epoch: 6| Step: 1
Training loss: 3.2195371387541694
Validation loss: 2.4266743560759565

Epoch: 6| Step: 2
Training loss: 2.3477531324253382
Validation loss: 2.4419508717133738

Epoch: 6| Step: 3
Training loss: 2.4077464813152845
Validation loss: 2.4267557356056266

Epoch: 6| Step: 4
Training loss: 2.9511856088880464
Validation loss: 2.44253802311982

Epoch: 6| Step: 5
Training loss: 2.1345005830650936
Validation loss: 2.4193413847545773

Epoch: 6| Step: 6
Training loss: 1.824222344143776
Validation loss: 2.426463611050156

Epoch: 6| Step: 7
Training loss: 2.521408729984605
Validation loss: 2.430739968643721

Epoch: 6| Step: 8
Training loss: 2.4095670947572643
Validation loss: 2.422801933513187

Epoch: 6| Step: 9
Training loss: 1.513467491871975
Validation loss: 2.4470364515584553

Epoch: 6| Step: 10
Training loss: 1.774470696309166
Validation loss: 2.419196566289283

Epoch: 6| Step: 11
Training loss: 2.4591612203088076
Validation loss: 2.4270180166124815

Epoch: 6| Step: 12
Training loss: 2.411184527436235
Validation loss: 2.420611535912678

Epoch: 6| Step: 13
Training loss: 2.6817426891310823
Validation loss: 2.4238109925980176

Epoch: 158| Step: 0
Training loss: 3.3163290385501787
Validation loss: 2.4253256898452986

Epoch: 6| Step: 1
Training loss: 2.2882101405416924
Validation loss: 2.4350247569048076

Epoch: 6| Step: 2
Training loss: 2.8809025751527892
Validation loss: 2.437797697539223

Epoch: 6| Step: 3
Training loss: 2.134184455464782
Validation loss: 2.437575622281612

Epoch: 6| Step: 4
Training loss: 2.569090764445085
Validation loss: 2.4294428764717217

Epoch: 6| Step: 5
Training loss: 2.281062183748332
Validation loss: 2.434606884511783

Epoch: 6| Step: 6
Training loss: 2.1994756680664835
Validation loss: 2.438202198609669

Epoch: 6| Step: 7
Training loss: 2.3840059887279588
Validation loss: 2.4348460037654145

Epoch: 6| Step: 8
Training loss: 2.0410074480248883
Validation loss: 2.420972840120129

Epoch: 6| Step: 9
Training loss: 2.723997729705223
Validation loss: 2.424744550001768

Epoch: 6| Step: 10
Training loss: 2.277400387408119
Validation loss: 2.422790372880764

Epoch: 6| Step: 11
Training loss: 2.1503328597983304
Validation loss: 2.4172364123074894

Epoch: 6| Step: 12
Training loss: 2.3401980123940653
Validation loss: 2.418828283558074

Epoch: 6| Step: 13
Training loss: 1.5204090240668355
Validation loss: 2.4515287861023825

Epoch: 159| Step: 0
Training loss: 2.790059314903963
Validation loss: 2.4264754970254407

Epoch: 6| Step: 1
Training loss: 2.3925918765548686
Validation loss: 2.4332680261770783

Epoch: 6| Step: 2
Training loss: 1.630444429341402
Validation loss: 2.4255505122277126

Epoch: 6| Step: 3
Training loss: 2.397520902858779
Validation loss: 2.422649493378697

Epoch: 6| Step: 4
Training loss: 2.288660215890788
Validation loss: 2.435520276871418

Epoch: 6| Step: 5
Training loss: 2.4642184230549526
Validation loss: 2.425567018798567

Epoch: 6| Step: 6
Training loss: 2.6092510079716975
Validation loss: 2.4324781223368848

Epoch: 6| Step: 7
Training loss: 2.339272762167048
Validation loss: 2.4190277680775907

Epoch: 6| Step: 8
Training loss: 2.4025795425442116
Validation loss: 2.4220370754137215

Epoch: 6| Step: 9
Training loss: 2.9038236600652736
Validation loss: 2.4272408566107426

Epoch: 6| Step: 10
Training loss: 2.3766517918332135
Validation loss: 2.437087521335575

Epoch: 6| Step: 11
Training loss: 1.616458157074218
Validation loss: 2.431322356845888

Epoch: 6| Step: 12
Training loss: 3.040449360462627
Validation loss: 2.420995199322659

Epoch: 6| Step: 13
Training loss: 1.5634466736680879
Validation loss: 2.4065506109031

Epoch: 160| Step: 0
Training loss: 2.590951719952441
Validation loss: 2.4419416357899966

Epoch: 6| Step: 1
Training loss: 2.1240873059722225
Validation loss: 2.428916704166593

Epoch: 6| Step: 2
Training loss: 2.0378397933239
Validation loss: 2.445344718902484

Epoch: 6| Step: 3
Training loss: 2.3012349793681075
Validation loss: 2.4438762664800286

Epoch: 6| Step: 4
Training loss: 2.7503133075142085
Validation loss: 2.4388904491905468

Epoch: 6| Step: 5
Training loss: 2.631651851748448
Validation loss: 2.411846690317776

Epoch: 6| Step: 6
Training loss: 2.3081155401098497
Validation loss: 2.4294526099682696

Epoch: 6| Step: 7
Training loss: 2.4016849762083843
Validation loss: 2.430627346785327

Epoch: 6| Step: 8
Training loss: 1.7865274784805205
Validation loss: 2.413291225192903

Epoch: 6| Step: 9
Training loss: 2.276745778222409
Validation loss: 2.448206074681131

Epoch: 6| Step: 10
Training loss: 2.9883935844898866
Validation loss: 2.4480898130644144

Epoch: 6| Step: 11
Training loss: 2.6116911151506854
Validation loss: 2.4317388464712417

Epoch: 6| Step: 12
Training loss: 2.149423601821744
Validation loss: 2.411743938810484

Epoch: 6| Step: 13
Training loss: 2.0902781382659343
Validation loss: 2.4377516444925473

Epoch: 161| Step: 0
Training loss: 2.471586505244207
Validation loss: 2.4283906807210514

Epoch: 6| Step: 1
Training loss: 1.8049086398095284
Validation loss: 2.4309808360384344

Epoch: 6| Step: 2
Training loss: 2.456839889085283
Validation loss: 2.4236906033330086

Epoch: 6| Step: 3
Training loss: 1.8696747498011372
Validation loss: 2.4280049665893246

Epoch: 6| Step: 4
Training loss: 2.5087177864899384
Validation loss: 2.4389833207634455

Epoch: 6| Step: 5
Training loss: 2.6973396086714883
Validation loss: 2.427509472373765

Epoch: 6| Step: 6
Training loss: 2.3323214812003727
Validation loss: 2.431821259369891

Epoch: 6| Step: 7
Training loss: 1.8704665373149465
Validation loss: 2.4212675552120966

Epoch: 6| Step: 8
Training loss: 2.942534008882925
Validation loss: 2.434674350329112

Epoch: 6| Step: 9
Training loss: 2.3590910279619246
Validation loss: 2.418227336426881

Epoch: 6| Step: 10
Training loss: 2.2250776727384682
Validation loss: 2.4237044195265818

Epoch: 6| Step: 11
Training loss: 2.386585288054505
Validation loss: 2.4415108575539537

Epoch: 6| Step: 12
Training loss: 3.1684733975464385
Validation loss: 2.422173366897191

Epoch: 6| Step: 13
Training loss: 2.0672452265492534
Validation loss: 2.4336727650102503

Epoch: 162| Step: 0
Training loss: 2.2659809753683287
Validation loss: 2.418247092969619

Epoch: 6| Step: 1
Training loss: 1.9473550024153605
Validation loss: 2.4275949836584005

Epoch: 6| Step: 2
Training loss: 2.257715665331261
Validation loss: 2.420016813535902

Epoch: 6| Step: 3
Training loss: 1.9329880507485162
Validation loss: 2.4258118366077177

Epoch: 6| Step: 4
Training loss: 2.7477294044420386
Validation loss: 2.4125719936484087

Epoch: 6| Step: 5
Training loss: 2.880782573128798
Validation loss: 2.431199411254513

Epoch: 6| Step: 6
Training loss: 2.5935558568154793
Validation loss: 2.424040953109328

Epoch: 6| Step: 7
Training loss: 2.3212894733382052
Validation loss: 2.4274412381809443

Epoch: 6| Step: 8
Training loss: 1.874596552358827
Validation loss: 2.4238970394401638

Epoch: 6| Step: 9
Training loss: 2.781301262200951
Validation loss: 2.4315026669261126

Epoch: 6| Step: 10
Training loss: 2.3081267993216548
Validation loss: 2.423265349297236

Epoch: 6| Step: 11
Training loss: 2.227698748934294
Validation loss: 2.422797605755553

Epoch: 6| Step: 12
Training loss: 2.317691645758628
Validation loss: 2.414123155274106

Epoch: 6| Step: 13
Training loss: 2.9968679290783533
Validation loss: 2.4210668426831163

Epoch: 163| Step: 0
Training loss: 2.7702280306000473
Validation loss: 2.430607898654434

Epoch: 6| Step: 1
Training loss: 2.6323710900720605
Validation loss: 2.4287513559899288

Epoch: 6| Step: 2
Training loss: 2.341087965768129
Validation loss: 2.4182005393171098

Epoch: 6| Step: 3
Training loss: 2.295853679679904
Validation loss: 2.423658095513767

Epoch: 6| Step: 4
Training loss: 2.4644113394108733
Validation loss: 2.4101047108486053

Epoch: 6| Step: 5
Training loss: 2.952849037153485
Validation loss: 2.4255075068909027

Epoch: 6| Step: 6
Training loss: 2.9265186312636557
Validation loss: 2.4209184030964415

Epoch: 6| Step: 7
Training loss: 1.9478916703794622
Validation loss: 2.421581863197742

Epoch: 6| Step: 8
Training loss: 1.7285791417752596
Validation loss: 2.423974440383406

Epoch: 6| Step: 9
Training loss: 1.887280745750682
Validation loss: 2.4384597306678386

Epoch: 6| Step: 10
Training loss: 2.6565979673564373
Validation loss: 2.4219441182054866

Epoch: 6| Step: 11
Training loss: 2.4914250179049198
Validation loss: 2.4132070661499836

Epoch: 6| Step: 12
Training loss: 1.7834929014577465
Validation loss: 2.4288424435625955

Epoch: 6| Step: 13
Training loss: 2.0481011598309493
Validation loss: 2.441775771136548

Epoch: 164| Step: 0
Training loss: 2.539758768716329
Validation loss: 2.4347197203057873

Epoch: 6| Step: 1
Training loss: 2.549135667509124
Validation loss: 2.4259801902634797

Epoch: 6| Step: 2
Training loss: 2.6875351304707906
Validation loss: 2.42294885788592

Epoch: 6| Step: 3
Training loss: 1.8274443573836923
Validation loss: 2.4081037849328593

Epoch: 6| Step: 4
Training loss: 2.772523369376755
Validation loss: 2.416968601708771

Epoch: 6| Step: 5
Training loss: 1.8903621774642299
Validation loss: 2.420806691487312

Epoch: 6| Step: 6
Training loss: 2.5597364829453797
Validation loss: 2.416949759109178

Epoch: 6| Step: 7
Training loss: 2.1193460531910002
Validation loss: 2.4176028082399625

Epoch: 6| Step: 8
Training loss: 1.7378774795498075
Validation loss: 2.42093086906796

Epoch: 6| Step: 9
Training loss: 1.7826476386135848
Validation loss: 2.421739006127645

Epoch: 6| Step: 10
Training loss: 2.772509610406233
Validation loss: 2.4189771025776015

Epoch: 6| Step: 11
Training loss: 1.89971253077537
Validation loss: 2.4288529858631738

Epoch: 6| Step: 12
Training loss: 2.970610346903458
Validation loss: 2.4407087965461725

Epoch: 6| Step: 13
Training loss: 3.031389842789489
Validation loss: 2.439115793859995

Epoch: 165| Step: 0
Training loss: 2.5768540457447893
Validation loss: 2.4218057157441946

Epoch: 6| Step: 1
Training loss: 2.672198181238063
Validation loss: 2.418430923063237

Epoch: 6| Step: 2
Training loss: 2.36464935300196
Validation loss: 2.414294523117434

Epoch: 6| Step: 3
Training loss: 2.271626488527845
Validation loss: 2.402829885130182

Epoch: 6| Step: 4
Training loss: 3.2017895403478898
Validation loss: 2.4277288638304912

Epoch: 6| Step: 5
Training loss: 2.427250759478643
Validation loss: 2.4341076503325407

Epoch: 6| Step: 6
Training loss: 2.8168525077712374
Validation loss: 2.4327772326480446

Epoch: 6| Step: 7
Training loss: 2.235508771162033
Validation loss: 2.4180144620552957

Epoch: 6| Step: 8
Training loss: 2.1705581734714756
Validation loss: 2.4334731093732

Epoch: 6| Step: 9
Training loss: 2.276529418453607
Validation loss: 2.422437218208832

Epoch: 6| Step: 10
Training loss: 2.017597977576577
Validation loss: 2.424572332610965

Epoch: 6| Step: 11
Training loss: 2.115787282379726
Validation loss: 2.431922193285784

Epoch: 6| Step: 12
Training loss: 2.0211229673912485
Validation loss: 2.436508016825003

Epoch: 6| Step: 13
Training loss: 1.7798012982592748
Validation loss: 2.44839076100902

Epoch: 166| Step: 0
Training loss: 2.5375328738333445
Validation loss: 2.4389219235834436

Epoch: 6| Step: 1
Training loss: 2.6872705760881033
Validation loss: 2.411709267274124

Epoch: 6| Step: 2
Training loss: 2.1839627686006438
Validation loss: 2.4182454561383406

Epoch: 6| Step: 3
Training loss: 2.6406064907531315
Validation loss: 2.4203405340136093

Epoch: 6| Step: 4
Training loss: 2.1610105732487455
Validation loss: 2.4374497037441283

Epoch: 6| Step: 5
Training loss: 2.2473598461135644
Validation loss: 2.41134347595385

Epoch: 6| Step: 6
Training loss: 2.098954294609431
Validation loss: 2.4487686283973997

Epoch: 6| Step: 7
Training loss: 2.7185491728875744
Validation loss: 2.4056891672192027

Epoch: 6| Step: 8
Training loss: 1.8477024451644533
Validation loss: 2.4257571541352987

Epoch: 6| Step: 9
Training loss: 2.518648119965028
Validation loss: 2.445634797811147

Epoch: 6| Step: 10
Training loss: 2.89720666462017
Validation loss: 2.422837518180776

Epoch: 6| Step: 11
Training loss: 2.2748423427407385
Validation loss: 2.41027069684312

Epoch: 6| Step: 12
Training loss: 2.0055040678117613
Validation loss: 2.406218579815233

Epoch: 6| Step: 13
Training loss: 1.59099295506575
Validation loss: 2.4171728898861864

Epoch: 167| Step: 0
Training loss: 2.344469697443634
Validation loss: 2.419206801452082

Epoch: 6| Step: 1
Training loss: 3.06464264321954
Validation loss: 2.4033809860764466

Epoch: 6| Step: 2
Training loss: 3.1262004835256167
Validation loss: 2.4155012017747586

Epoch: 6| Step: 3
Training loss: 2.0297848625999606
Validation loss: 2.4157361419796395

Epoch: 6| Step: 4
Training loss: 2.398128725734478
Validation loss: 2.412960196006703

Epoch: 6| Step: 5
Training loss: 2.6150242305821916
Validation loss: 2.410215543178915

Epoch: 6| Step: 6
Training loss: 1.782055053819536
Validation loss: 2.396190265392388

Epoch: 6| Step: 7
Training loss: 1.8367343553069186
Validation loss: 2.427778915857177

Epoch: 6| Step: 8
Training loss: 2.135368631954665
Validation loss: 2.3957440659708906

Epoch: 6| Step: 9
Training loss: 2.2451628505714094
Validation loss: 2.4177787444094707

Epoch: 6| Step: 10
Training loss: 2.386412255918955
Validation loss: 2.4175555794141537

Epoch: 6| Step: 11
Training loss: 2.0337283933648846
Validation loss: 2.4106725965095124

Epoch: 6| Step: 12
Training loss: 2.2222836790593643
Validation loss: 2.4104715346061782

Epoch: 6| Step: 13
Training loss: 3.076189236062121
Validation loss: 2.4016437696932

Epoch: 168| Step: 0
Training loss: 2.0600558740019674
Validation loss: 2.416334102465113

Epoch: 6| Step: 1
Training loss: 3.025200696860726
Validation loss: 2.410140208553273

Epoch: 6| Step: 2
Training loss: 2.094855059615027
Validation loss: 2.42914536131417

Epoch: 6| Step: 3
Training loss: 2.2617887443292775
Validation loss: 2.3991300018655557

Epoch: 6| Step: 4
Training loss: 2.410024679540368
Validation loss: 2.3887199013541984

Epoch: 6| Step: 5
Training loss: 2.040343601984763
Validation loss: 2.4153810457695104

Epoch: 6| Step: 6
Training loss: 1.815397905601982
Validation loss: 2.3917440033689683

Epoch: 6| Step: 7
Training loss: 2.7889161485586844
Validation loss: 2.429310796645236

Epoch: 6| Step: 8
Training loss: 2.495680797248348
Validation loss: 2.402389798847279

Epoch: 6| Step: 9
Training loss: 2.8905568707659643
Validation loss: 2.4238261027101813

Epoch: 6| Step: 10
Training loss: 2.31534648666944
Validation loss: 2.4243724023139883

Epoch: 6| Step: 11
Training loss: 2.3719410521466164
Validation loss: 2.407365834017677

Epoch: 6| Step: 12
Training loss: 2.202470506347212
Validation loss: 2.439200313895512

Epoch: 6| Step: 13
Training loss: 1.7695204037634964
Validation loss: 2.394274508294474

Epoch: 169| Step: 0
Training loss: 3.0254568212173814
Validation loss: 2.4315283263645298

Epoch: 6| Step: 1
Training loss: 2.8792398122355674
Validation loss: 2.4240995280622566

Epoch: 6| Step: 2
Training loss: 2.0138029394407355
Validation loss: 2.414512864395192

Epoch: 6| Step: 3
Training loss: 1.6988802868730852
Validation loss: 2.4196628551545554

Epoch: 6| Step: 4
Training loss: 1.9872659365463328
Validation loss: 2.4059640804822764

Epoch: 6| Step: 5
Training loss: 2.094668172809457
Validation loss: 2.424814896347745

Epoch: 6| Step: 6
Training loss: 2.430504762633491
Validation loss: 2.41210903702288

Epoch: 6| Step: 7
Training loss: 1.7807650658900542
Validation loss: 2.412757479111791

Epoch: 6| Step: 8
Training loss: 2.7036665004723432
Validation loss: 2.425992711593876

Epoch: 6| Step: 9
Training loss: 2.9934133702759262
Validation loss: 2.4077386596717503

Epoch: 6| Step: 10
Training loss: 2.5658242597808756
Validation loss: 2.4037912221458355

Epoch: 6| Step: 11
Training loss: 2.047820593545638
Validation loss: 2.4171386684969582

Epoch: 6| Step: 12
Training loss: 2.2565559665832056
Validation loss: 2.4101960718104007

Epoch: 6| Step: 13
Training loss: 2.2329032692635153
Validation loss: 2.422341919453043

Epoch: 170| Step: 0
Training loss: 2.0332972846457555
Validation loss: 2.437314998567621

Epoch: 6| Step: 1
Training loss: 2.732884115040862
Validation loss: 2.42967216044493

Epoch: 6| Step: 2
Training loss: 2.000648155090322
Validation loss: 2.423127131273909

Epoch: 6| Step: 3
Training loss: 2.6792110097329163
Validation loss: 2.4028377814333224

Epoch: 6| Step: 4
Training loss: 2.2595688479512175
Validation loss: 2.415665203323944

Epoch: 6| Step: 5
Training loss: 1.607947077183914
Validation loss: 2.407191926007727

Epoch: 6| Step: 6
Training loss: 2.203188523262788
Validation loss: 2.419835250320945

Epoch: 6| Step: 7
Training loss: 3.198935546263849
Validation loss: 2.4103687771250657

Epoch: 6| Step: 8
Training loss: 2.8149619453256545
Validation loss: 2.4098388927764187

Epoch: 6| Step: 9
Training loss: 1.980139168847983
Validation loss: 2.4258899553066415

Epoch: 6| Step: 10
Training loss: 2.4683928412408274
Validation loss: 2.431476222776452

Epoch: 6| Step: 11
Training loss: 2.508120128741882
Validation loss: 2.422874765657458

Epoch: 6| Step: 12
Training loss: 2.0048595042483406
Validation loss: 2.4185648875801387

Epoch: 6| Step: 13
Training loss: 1.9292950559315174
Validation loss: 2.419489375410628

Epoch: 171| Step: 0
Training loss: 2.0788217394774198
Validation loss: 2.419585091664645

Epoch: 6| Step: 1
Training loss: 1.923892938906621
Validation loss: 2.4169878785082624

Epoch: 6| Step: 2
Training loss: 2.243735812256567
Validation loss: 2.408559012296818

Epoch: 6| Step: 3
Training loss: 2.4097078917190538
Validation loss: 2.416002211563887

Epoch: 6| Step: 4
Training loss: 1.6970012357906232
Validation loss: 2.407115156950521

Epoch: 6| Step: 5
Training loss: 2.4694813478008353
Validation loss: 2.406334314998601

Epoch: 6| Step: 6
Training loss: 2.3872237599926485
Validation loss: 2.4223268879248234

Epoch: 6| Step: 7
Training loss: 2.6470446679727875
Validation loss: 2.4016050592839266

Epoch: 6| Step: 8
Training loss: 2.1200657947694954
Validation loss: 2.41427601484219

Epoch: 6| Step: 9
Training loss: 2.7253446728469832
Validation loss: 2.410284724510708

Epoch: 6| Step: 10
Training loss: 2.281293685703822
Validation loss: 2.4103832663483495

Epoch: 6| Step: 11
Training loss: 2.7699241198120577
Validation loss: 2.3888908577442125

Epoch: 6| Step: 12
Training loss: 2.631551468856299
Validation loss: 2.4262227495548427

Epoch: 6| Step: 13
Training loss: 2.4290440924872216
Validation loss: 2.4114085010486246

Epoch: 172| Step: 0
Training loss: 1.938032384761293
Validation loss: 2.4197277181330517

Epoch: 6| Step: 1
Training loss: 1.330259515210328
Validation loss: 2.417570857994664

Epoch: 6| Step: 2
Training loss: 2.393617141263702
Validation loss: 2.416599815541608

Epoch: 6| Step: 3
Training loss: 2.1834155506446487
Validation loss: 2.4194265955876584

Epoch: 6| Step: 4
Training loss: 2.485203634779903
Validation loss: 2.4264640442289442

Epoch: 6| Step: 5
Training loss: 2.610126318670049
Validation loss: 2.4196987127165293

Epoch: 6| Step: 6
Training loss: 2.3484005375007246
Validation loss: 2.4142617422422785

Epoch: 6| Step: 7
Training loss: 2.3223980608394252
Validation loss: 2.409222343176243

Epoch: 6| Step: 8
Training loss: 2.1541052946673513
Validation loss: 2.434458269056817

Epoch: 6| Step: 9
Training loss: 2.562213044265465
Validation loss: 2.427154951549826

Epoch: 6| Step: 10
Training loss: 2.891155792166032
Validation loss: 2.3852750359375814

Epoch: 6| Step: 11
Training loss: 2.535093803400777
Validation loss: 2.42050907333442

Epoch: 6| Step: 12
Training loss: 2.4268502599657142
Validation loss: 2.416257028653043

Epoch: 6| Step: 13
Training loss: 2.4581112087783334
Validation loss: 2.409773619472288

Epoch: 173| Step: 0
Training loss: 1.6886998608626445
Validation loss: 2.413765899387811

Epoch: 6| Step: 1
Training loss: 1.7651078808804408
Validation loss: 2.3975102131615436

Epoch: 6| Step: 2
Training loss: 2.754513331385336
Validation loss: 2.4132948561335072

Epoch: 6| Step: 3
Training loss: 2.5384477546068687
Validation loss: 2.4168295457100215

Epoch: 6| Step: 4
Training loss: 2.4360020264991387
Validation loss: 2.4258995508824355

Epoch: 6| Step: 5
Training loss: 2.220367057285707
Validation loss: 2.419073414551397

Epoch: 6| Step: 6
Training loss: 2.683187351244307
Validation loss: 2.418873362537774

Epoch: 6| Step: 7
Training loss: 2.4048206988966045
Validation loss: 2.419952747011948

Epoch: 6| Step: 8
Training loss: 2.28002959750858
Validation loss: 2.4096000873857006

Epoch: 6| Step: 9
Training loss: 2.1993408169248574
Validation loss: 2.41384162321133

Epoch: 6| Step: 10
Training loss: 2.5310832781103785
Validation loss: 2.3986450791705662

Epoch: 6| Step: 11
Training loss: 2.2522470062469697
Validation loss: 2.4264691752786343

Epoch: 6| Step: 12
Training loss: 2.4807317158837243
Validation loss: 2.4124558425356954

Epoch: 6| Step: 13
Training loss: 2.346564472241855
Validation loss: 2.4221135884981058

Epoch: 174| Step: 0
Training loss: 2.365984217432287
Validation loss: 2.3953363843932625

Epoch: 6| Step: 1
Training loss: 2.1513290644318546
Validation loss: 2.4145280719800133

Epoch: 6| Step: 2
Training loss: 1.636640159886929
Validation loss: 2.4261036275333865

Epoch: 6| Step: 3
Training loss: 2.0263891894513364
Validation loss: 2.4085955540466273

Epoch: 6| Step: 4
Training loss: 2.5781262946848074
Validation loss: 2.422393643792084

Epoch: 6| Step: 5
Training loss: 3.498207723304982
Validation loss: 2.4196460587913897

Epoch: 6| Step: 6
Training loss: 2.310899747858682
Validation loss: 2.4437761903166155

Epoch: 6| Step: 7
Training loss: 2.3417524853747436
Validation loss: 2.391356321287464

Epoch: 6| Step: 8
Training loss: 2.3664329005919753
Validation loss: 2.4180896785847983

Epoch: 6| Step: 9
Training loss: 2.4007188713791026
Validation loss: 2.4097151963097825

Epoch: 6| Step: 10
Training loss: 1.6026012494599235
Validation loss: 2.3981998260773616

Epoch: 6| Step: 11
Training loss: 1.7482288116737776
Validation loss: 2.401459982567184

Epoch: 6| Step: 12
Training loss: 2.8758139080171583
Validation loss: 2.3827392287128553

Epoch: 6| Step: 13
Training loss: 2.466285827809572
Validation loss: 2.398773729884686

Epoch: 175| Step: 0
Training loss: 2.1918096324091834
Validation loss: 2.421570239043231

Epoch: 6| Step: 1
Training loss: 2.2888594918179037
Validation loss: 2.4071614372178205

Epoch: 6| Step: 2
Training loss: 1.7367380900470888
Validation loss: 2.4086542560843966

Epoch: 6| Step: 3
Training loss: 1.8881142077978843
Validation loss: 2.4161244598497214

Epoch: 6| Step: 4
Training loss: 1.4675594942942563
Validation loss: 2.3981726769011122

Epoch: 6| Step: 5
Training loss: 2.46534291093299
Validation loss: 2.4075301086317027

Epoch: 6| Step: 6
Training loss: 1.9043195361231793
Validation loss: 2.4221723878722794

Epoch: 6| Step: 7
Training loss: 3.3387053752560547
Validation loss: 2.41583606914465

Epoch: 6| Step: 8
Training loss: 2.5433066241793822
Validation loss: 2.4039562561150682

Epoch: 6| Step: 9
Training loss: 2.2281814846246415
Validation loss: 2.4164854249753147

Epoch: 6| Step: 10
Training loss: 2.711880742418865
Validation loss: 2.39570256465305

Epoch: 6| Step: 11
Training loss: 2.80604337683476
Validation loss: 2.4115661612578467

Epoch: 6| Step: 12
Training loss: 2.1011072963386566
Validation loss: 2.398215030208718

Epoch: 6| Step: 13
Training loss: 2.3860010044962325
Validation loss: 2.4093371179489687

Epoch: 176| Step: 0
Training loss: 2.591870097755228
Validation loss: 2.40527235034126

Epoch: 6| Step: 1
Training loss: 1.9142245477083069
Validation loss: 2.4065159859878205

Epoch: 6| Step: 2
Training loss: 2.2810277961264873
Validation loss: 2.3988736583015062

Epoch: 6| Step: 3
Training loss: 2.1599916805884187
Validation loss: 2.4067889918888428

Epoch: 6| Step: 4
Training loss: 2.8323285808358
Validation loss: 2.405056956382573

Epoch: 6| Step: 5
Training loss: 2.256875975784771
Validation loss: 2.4323204137026417

Epoch: 6| Step: 6
Training loss: 1.9242340124456563
Validation loss: 2.4113886608355974

Epoch: 6| Step: 7
Training loss: 2.39922307472746
Validation loss: 2.398401912462466

Epoch: 6| Step: 8
Training loss: 1.5744206982893825
Validation loss: 2.390024896848063

Epoch: 6| Step: 9
Training loss: 2.9926770160938267
Validation loss: 2.416957788538545

Epoch: 6| Step: 10
Training loss: 2.4514280633674983
Validation loss: 2.408913718931115

Epoch: 6| Step: 11
Training loss: 2.6690310685317242
Validation loss: 2.3996826693578095

Epoch: 6| Step: 12
Training loss: 2.2128070165692546
Validation loss: 2.4154015282218775

Epoch: 6| Step: 13
Training loss: 1.9695862099266257
Validation loss: 2.413733232413515

Epoch: 177| Step: 0
Training loss: 2.1442470674925023
Validation loss: 2.404479123207472

Epoch: 6| Step: 1
Training loss: 2.6089835415807547
Validation loss: 2.397897812266974

Epoch: 6| Step: 2
Training loss: 2.0600695305728585
Validation loss: 2.4048599534525485

Epoch: 6| Step: 3
Training loss: 2.1116987074318243
Validation loss: 2.381771533906645

Epoch: 6| Step: 4
Training loss: 2.85319760617715
Validation loss: 2.401311801047361

Epoch: 6| Step: 5
Training loss: 2.0253491889445145
Validation loss: 2.3993433101338937

Epoch: 6| Step: 6
Training loss: 1.700541855904603
Validation loss: 2.407181853290384

Epoch: 6| Step: 7
Training loss: 1.9156154016251172
Validation loss: 2.4211180203571208

Epoch: 6| Step: 8
Training loss: 2.688978985869952
Validation loss: 2.4029377456832663

Epoch: 6| Step: 9
Training loss: 2.4360721024865386
Validation loss: 2.4125515551815035

Epoch: 6| Step: 10
Training loss: 2.5644613063940325
Validation loss: 2.394418956126462

Epoch: 6| Step: 11
Training loss: 2.09973677847472
Validation loss: 2.423324793551057

Epoch: 6| Step: 12
Training loss: 2.4598151660114507
Validation loss: 2.408966233901201

Epoch: 6| Step: 13
Training loss: 2.6995516404767717
Validation loss: 2.3964712186359405

Epoch: 178| Step: 0
Training loss: 2.479202355734342
Validation loss: 2.409710314705106

Epoch: 6| Step: 1
Training loss: 2.15013183366989
Validation loss: 2.3961182644672503

Epoch: 6| Step: 2
Training loss: 2.1537171013390077
Validation loss: 2.3998667111693988

Epoch: 6| Step: 3
Training loss: 2.8580399194896637
Validation loss: 2.4133948498572315

Epoch: 6| Step: 4
Training loss: 2.390428722028259
Validation loss: 2.398094683712067

Epoch: 6| Step: 5
Training loss: 2.106779635253425
Validation loss: 2.4068893842450816

Epoch: 6| Step: 6
Training loss: 2.324379590023029
Validation loss: 2.4071367715595904

Epoch: 6| Step: 7
Training loss: 2.558935151364082
Validation loss: 2.401269423356436

Epoch: 6| Step: 8
Training loss: 2.5541415783229247
Validation loss: 2.381031680141628

Epoch: 6| Step: 9
Training loss: 1.8345594063240447
Validation loss: 2.4099568459874052

Epoch: 6| Step: 10
Training loss: 2.1127215929451935
Validation loss: 2.405342964544187

Epoch: 6| Step: 11
Training loss: 2.345258913692349
Validation loss: 2.3934890059876692

Epoch: 6| Step: 12
Training loss: 1.8665568671404156
Validation loss: 2.4134529380392054

Epoch: 6| Step: 13
Training loss: 2.961442969666215
Validation loss: 2.4048959837588555

Epoch: 179| Step: 0
Training loss: 1.6823435520481302
Validation loss: 2.393701551023065

Epoch: 6| Step: 1
Training loss: 2.5841419636139094
Validation loss: 2.408237059262406

Epoch: 6| Step: 2
Training loss: 2.3599291018165327
Validation loss: 2.417250634466155

Epoch: 6| Step: 3
Training loss: 2.21415201785528
Validation loss: 2.41916116968193

Epoch: 6| Step: 4
Training loss: 2.6628480531530347
Validation loss: 2.3950916181885584

Epoch: 6| Step: 5
Training loss: 2.484855845240274
Validation loss: 2.4021079727310966

Epoch: 6| Step: 6
Training loss: 2.4418136378853905
Validation loss: 2.393933746312065

Epoch: 6| Step: 7
Training loss: 1.78324189828123
Validation loss: 2.403074223201034

Epoch: 6| Step: 8
Training loss: 2.223434124405873
Validation loss: 2.4118036606573177

Epoch: 6| Step: 9
Training loss: 2.029494128218505
Validation loss: 2.3917403504303825

Epoch: 6| Step: 10
Training loss: 2.213385530836794
Validation loss: 2.3929311615498756

Epoch: 6| Step: 11
Training loss: 2.3210154281031126
Validation loss: 2.4078699696251262

Epoch: 6| Step: 12
Training loss: 2.8193842239922424
Validation loss: 2.4063698310350214

Epoch: 6| Step: 13
Training loss: 2.2254257780582662
Validation loss: 2.400162018371245

Epoch: 180| Step: 0
Training loss: 2.591562474682149
Validation loss: 2.4011927927190775

Epoch: 6| Step: 1
Training loss: 2.576464956645257
Validation loss: 2.3979043734477616

Epoch: 6| Step: 2
Training loss: 2.163031597617395
Validation loss: 2.4181182421234775

Epoch: 6| Step: 3
Training loss: 1.9714051764543423
Validation loss: 2.405930715131358

Epoch: 6| Step: 4
Training loss: 1.7983384516905079
Validation loss: 2.3780519190809004

Epoch: 6| Step: 5
Training loss: 2.244272784266698
Validation loss: 2.378862253242901

Epoch: 6| Step: 6
Training loss: 2.4224383283545934
Validation loss: 2.403046660756785

Epoch: 6| Step: 7
Training loss: 2.48828594500759
Validation loss: 2.3725481692330117

Epoch: 6| Step: 8
Training loss: 1.9928518346978517
Validation loss: 2.407492205260764

Epoch: 6| Step: 9
Training loss: 2.4772998181564714
Validation loss: 2.4059204815627555

Epoch: 6| Step: 10
Training loss: 2.285272161690337
Validation loss: 2.400326693083883

Epoch: 6| Step: 11
Training loss: 1.8411343658248411
Validation loss: 2.413537467711313

Epoch: 6| Step: 12
Training loss: 2.667687598141292
Validation loss: 2.3987479861864673

Epoch: 6| Step: 13
Training loss: 2.6882504147416024
Validation loss: 2.390533210653885

Epoch: 181| Step: 0
Training loss: 2.2817179578761335
Validation loss: 2.397142820883855

Epoch: 6| Step: 1
Training loss: 1.789851784989876
Validation loss: 2.379834593804506

Epoch: 6| Step: 2
Training loss: 2.1190022366247754
Validation loss: 2.410229950890514

Epoch: 6| Step: 3
Training loss: 1.9539295828126597
Validation loss: 2.4190938689197585

Epoch: 6| Step: 4
Training loss: 1.5292159603534283
Validation loss: 2.382051798545275

Epoch: 6| Step: 5
Training loss: 2.5205766741610356
Validation loss: 2.4186835742819452

Epoch: 6| Step: 6
Training loss: 2.81613543050933
Validation loss: 2.3883923888009213

Epoch: 6| Step: 7
Training loss: 2.034058023771048
Validation loss: 2.386733707180854

Epoch: 6| Step: 8
Training loss: 2.5131310842308046
Validation loss: 2.421627749479192

Epoch: 6| Step: 9
Training loss: 2.759947903735766
Validation loss: 2.4007026216415586

Epoch: 6| Step: 10
Training loss: 2.429772084226548
Validation loss: 2.3808225566801258

Epoch: 6| Step: 11
Training loss: 2.360246712025244
Validation loss: 2.4032520758303972

Epoch: 6| Step: 12
Training loss: 2.726773141851071
Validation loss: 2.4197436313928127

Epoch: 6| Step: 13
Training loss: 1.7958902065302136
Validation loss: 2.381407193584167

Epoch: 182| Step: 0
Training loss: 2.397293364656651
Validation loss: 2.408718478907955

Epoch: 6| Step: 1
Training loss: 1.9576766421345742
Validation loss: 2.4084202962302292

Epoch: 6| Step: 2
Training loss: 2.256919393807959
Validation loss: 2.4132016572519626

Epoch: 6| Step: 3
Training loss: 2.5966510405292698
Validation loss: 2.3974577830190524

Epoch: 6| Step: 4
Training loss: 2.5910893777546895
Validation loss: 2.394636926739889

Epoch: 6| Step: 5
Training loss: 2.007673563027902
Validation loss: 2.3979305346011595

Epoch: 6| Step: 6
Training loss: 2.8209275185334586
Validation loss: 2.3778904994021337

Epoch: 6| Step: 7
Training loss: 2.6149976992186716
Validation loss: 2.4096904057198127

Epoch: 6| Step: 8
Training loss: 2.0575313251470027
Validation loss: 2.399278961909316

Epoch: 6| Step: 9
Training loss: 1.789717774971879
Validation loss: 2.3923053877150164

Epoch: 6| Step: 10
Training loss: 1.964038236311877
Validation loss: 2.4014054026602167

Epoch: 6| Step: 11
Training loss: 2.2991705601341113
Validation loss: 2.4035975626784998

Epoch: 6| Step: 12
Training loss: 2.427295157121432
Validation loss: 2.4127547441436925

Epoch: 6| Step: 13
Training loss: 2.0011931674948147
Validation loss: 2.406809183176158

Epoch: 183| Step: 0
Training loss: 2.4688820139681167
Validation loss: 2.383242465879407

Epoch: 6| Step: 1
Training loss: 2.3490467491905758
Validation loss: 2.3911082994832578

Epoch: 6| Step: 2
Training loss: 2.2039907932123812
Validation loss: 2.3980168857637643

Epoch: 6| Step: 3
Training loss: 2.138433964007402
Validation loss: 2.395421725133822

Epoch: 6| Step: 4
Training loss: 2.3229353238256025
Validation loss: 2.3938041554296783

Epoch: 6| Step: 5
Training loss: 1.8416229521912784
Validation loss: 2.398808919688123

Epoch: 6| Step: 6
Training loss: 2.064693325075501
Validation loss: 2.391046358095996

Epoch: 6| Step: 7
Training loss: 2.9802106793067833
Validation loss: 2.3852262147315457

Epoch: 6| Step: 8
Training loss: 2.4465731457741646
Validation loss: 2.3694920900979946

Epoch: 6| Step: 9
Training loss: 1.855665465517902
Validation loss: 2.38318603320601

Epoch: 6| Step: 10
Training loss: 2.3080304228233697
Validation loss: 2.403122432181492

Epoch: 6| Step: 11
Training loss: 3.02963402530248
Validation loss: 2.401407917292835

Epoch: 6| Step: 12
Training loss: 1.5618759434923464
Validation loss: 2.373156378710282

Epoch: 6| Step: 13
Training loss: 1.8022943788404484
Validation loss: 2.397858050293426

Epoch: 184| Step: 0
Training loss: 2.1074205174057257
Validation loss: 2.3771895703411112

Epoch: 6| Step: 1
Training loss: 2.180754807015294
Validation loss: 2.3896703409775797

Epoch: 6| Step: 2
Training loss: 2.586632764764534
Validation loss: 2.3681593003863135

Epoch: 6| Step: 3
Training loss: 3.114093516607326
Validation loss: 2.3845948319248023

Epoch: 6| Step: 4
Training loss: 1.811233670073531
Validation loss: 2.3883090102604485

Epoch: 6| Step: 5
Training loss: 2.2764281432877986
Validation loss: 2.3933101557642997

Epoch: 6| Step: 6
Training loss: 2.4520141613412867
Validation loss: 2.398091505476982

Epoch: 6| Step: 7
Training loss: 2.029990642131415
Validation loss: 2.402163333355929

Epoch: 6| Step: 8
Training loss: 2.6097043680425416
Validation loss: 2.3880768558227454

Epoch: 6| Step: 9
Training loss: 2.4607361726303583
Validation loss: 2.3760309847494296

Epoch: 6| Step: 10
Training loss: 1.5175629643256154
Validation loss: 2.4195635225678567

Epoch: 6| Step: 11
Training loss: 2.63738742967802
Validation loss: 2.3996882406654514

Epoch: 6| Step: 12
Training loss: 1.7215684842933379
Validation loss: 2.399042860458798

Epoch: 6| Step: 13
Training loss: 1.6611619483684532
Validation loss: 2.3911555574996743

Epoch: 185| Step: 0
Training loss: 2.2477354733822175
Validation loss: 2.4058289028251547

Epoch: 6| Step: 1
Training loss: 2.0667638919889937
Validation loss: 2.376445540838731

Epoch: 6| Step: 2
Training loss: 2.0109033209705243
Validation loss: 2.3905402156501014

Epoch: 6| Step: 3
Training loss: 2.5141089947789004
Validation loss: 2.39820222434494

Epoch: 6| Step: 4
Training loss: 1.68440542105131
Validation loss: 2.3960815757631218

Epoch: 6| Step: 5
Training loss: 2.410327577606843
Validation loss: 2.383708225097588

Epoch: 6| Step: 6
Training loss: 2.1430910482356627
Validation loss: 2.390165091311652

Epoch: 6| Step: 7
Training loss: 2.3215175800237073
Validation loss: 2.4155515878270215

Epoch: 6| Step: 8
Training loss: 2.4103835630877533
Validation loss: 2.38777796896678

Epoch: 6| Step: 9
Training loss: 1.6509871448776545
Validation loss: 2.3912701884568284

Epoch: 6| Step: 10
Training loss: 2.81436146488277
Validation loss: 2.4006814510062457

Epoch: 6| Step: 11
Training loss: 2.174582132121208
Validation loss: 2.38404564192627

Epoch: 6| Step: 12
Training loss: 2.841180499897112
Validation loss: 2.3980773332553413

Epoch: 6| Step: 13
Training loss: 2.47971160626968
Validation loss: 2.3917063160935816

Epoch: 186| Step: 0
Training loss: 1.792953058976139
Validation loss: 2.3790958871217973

Epoch: 6| Step: 1
Training loss: 1.9501330232486367
Validation loss: 2.394943561803961

Epoch: 6| Step: 2
Training loss: 2.299971795945767
Validation loss: 2.3575671747678415

Epoch: 6| Step: 3
Training loss: 2.0626313138832444
Validation loss: 2.405408087903115

Epoch: 6| Step: 4
Training loss: 2.1485890837859984
Validation loss: 2.4239508373925247

Epoch: 6| Step: 5
Training loss: 2.6733890281577097
Validation loss: 2.371127320125439

Epoch: 6| Step: 6
Training loss: 1.8963267204843035
Validation loss: 2.4020073896068332

Epoch: 6| Step: 7
Training loss: 1.8394335635755779
Validation loss: 2.390050261474392

Epoch: 6| Step: 8
Training loss: 2.187401033615087
Validation loss: 2.363208108650008

Epoch: 6| Step: 9
Training loss: 3.150506563175874
Validation loss: 2.3796710273153634

Epoch: 6| Step: 10
Training loss: 2.5793073312818118
Validation loss: 2.396763326191059

Epoch: 6| Step: 11
Training loss: 2.409608256209871
Validation loss: 2.363060239571303

Epoch: 6| Step: 12
Training loss: 2.5184384363922714
Validation loss: 2.3792813780539386

Epoch: 6| Step: 13
Training loss: 1.754664811406319
Validation loss: 2.3984132544841352

Epoch: 187| Step: 0
Training loss: 2.1433681537218274
Validation loss: 2.404655208255024

Epoch: 6| Step: 1
Training loss: 2.391552315170272
Validation loss: 2.3871445681871117

Epoch: 6| Step: 2
Training loss: 2.5973733618874433
Validation loss: 2.40307648698582

Epoch: 6| Step: 3
Training loss: 1.825771936695665
Validation loss: 2.4031929548756907

Epoch: 6| Step: 4
Training loss: 1.7530360452587854
Validation loss: 2.3915147556549

Epoch: 6| Step: 5
Training loss: 2.0708712993291036
Validation loss: 2.390929103369419

Epoch: 6| Step: 6
Training loss: 3.1417371005014076
Validation loss: 2.378735025983501

Epoch: 6| Step: 7
Training loss: 2.9037566615737256
Validation loss: 2.39017924073057

Epoch: 6| Step: 8
Training loss: 2.0475595508900146
Validation loss: 2.387365158960102

Epoch: 6| Step: 9
Training loss: 1.5325708725738167
Validation loss: 2.3648211372392764

Epoch: 6| Step: 10
Training loss: 2.913366976208374
Validation loss: 2.4038308843785576

Epoch: 6| Step: 11
Training loss: 1.6912265179928896
Validation loss: 2.40289840958142

Epoch: 6| Step: 12
Training loss: 2.1427850892804843
Validation loss: 2.406293089019649

Epoch: 6| Step: 13
Training loss: 1.7355656016883003
Validation loss: 2.4113282387161687

Epoch: 188| Step: 0
Training loss: 3.0251059647593275
Validation loss: 2.376963025982805

Epoch: 6| Step: 1
Training loss: 2.5217585691592146
Validation loss: 2.384492440303627

Epoch: 6| Step: 2
Training loss: 2.103948776999524
Validation loss: 2.3783596101880686

Epoch: 6| Step: 3
Training loss: 2.0902489385238305
Validation loss: 2.3963005034893694

Epoch: 6| Step: 4
Training loss: 2.3255906616070687
Validation loss: 2.40706914099

Epoch: 6| Step: 5
Training loss: 2.669806499541702
Validation loss: 2.363284365486594

Epoch: 6| Step: 6
Training loss: 1.5442423139729484
Validation loss: 2.3895705995180085

Epoch: 6| Step: 7
Training loss: 2.373788223320439
Validation loss: 2.383398436467401

Epoch: 6| Step: 8
Training loss: 1.9397799090766326
Validation loss: 2.3935522497662443

Epoch: 6| Step: 9
Training loss: 2.375116947707903
Validation loss: 2.3887883465506

Epoch: 6| Step: 10
Training loss: 1.7190084089747009
Validation loss: 2.383665202113168

Epoch: 6| Step: 11
Training loss: 2.42471452192787
Validation loss: 2.3855659788131773

Epoch: 6| Step: 12
Training loss: 2.1598721363934597
Validation loss: 2.38760644703018

Epoch: 6| Step: 13
Training loss: 2.0822591173822214
Validation loss: 2.3884564619876083

Epoch: 189| Step: 0
Training loss: 1.8990593037116223
Validation loss: 2.402389068936395

Epoch: 6| Step: 1
Training loss: 2.9999074921650255
Validation loss: 2.3750678453755816

Epoch: 6| Step: 2
Training loss: 2.426386808285194
Validation loss: 2.386033320533437

Epoch: 6| Step: 3
Training loss: 2.007054048366402
Validation loss: 2.3709409166154702

Epoch: 6| Step: 4
Training loss: 2.192191515352646
Validation loss: 2.372660034145984

Epoch: 6| Step: 5
Training loss: 2.156182329525771
Validation loss: 2.383721454592547

Epoch: 6| Step: 6
Training loss: 2.3333331743876085
Validation loss: 2.380977840565802

Epoch: 6| Step: 7
Training loss: 2.3746940014119287
Validation loss: 2.3657018011081816

Epoch: 6| Step: 8
Training loss: 2.2169541088924367
Validation loss: 2.372511040399847

Epoch: 6| Step: 9
Training loss: 1.770385805314255
Validation loss: 2.370221552666642

Epoch: 6| Step: 10
Training loss: 2.0444733019303305
Validation loss: 2.3982744133747853

Epoch: 6| Step: 11
Training loss: 2.4424884320300446
Validation loss: 2.383933279985452

Epoch: 6| Step: 12
Training loss: 2.126450436321026
Validation loss: 2.395093631558724

Epoch: 6| Step: 13
Training loss: 2.477624515056683
Validation loss: 2.369448330760972

Epoch: 190| Step: 0
Training loss: 2.0130812095941133
Validation loss: 2.382715543256734

Epoch: 6| Step: 1
Training loss: 2.2816297659201656
Validation loss: 2.3807416734689006

Epoch: 6| Step: 2
Training loss: 2.2465616020893844
Validation loss: 2.3941095211614583

Epoch: 6| Step: 3
Training loss: 1.9532392544706545
Validation loss: 2.3807640691566596

Epoch: 6| Step: 4
Training loss: 2.8699000361774565
Validation loss: 2.405109147318907

Epoch: 6| Step: 5
Training loss: 2.0034212414098604
Validation loss: 2.3956216209430616

Epoch: 6| Step: 6
Training loss: 2.0433451960324582
Validation loss: 2.3879050848093453

Epoch: 6| Step: 7
Training loss: 2.2012167166988608
Validation loss: 2.4129040562222914

Epoch: 6| Step: 8
Training loss: 2.5940118680460427
Validation loss: 2.383170201783694

Epoch: 6| Step: 9
Training loss: 2.391793557587933
Validation loss: 2.3677321726954914

Epoch: 6| Step: 10
Training loss: 2.2269345692074127
Validation loss: 2.3731275721568212

Epoch: 6| Step: 11
Training loss: 1.9832769043959793
Validation loss: 2.3786272855645305

Epoch: 6| Step: 12
Training loss: 2.1321291544944723
Validation loss: 2.389641563991363

Epoch: 6| Step: 13
Training loss: 2.5417979368070145
Validation loss: 2.3816212345009733

Epoch: 191| Step: 0
Training loss: 1.7456336044498275
Validation loss: 2.4146030573614548

Epoch: 6| Step: 1
Training loss: 2.148116431087377
Validation loss: 2.3694043585483295

Epoch: 6| Step: 2
Training loss: 2.207967212005095
Validation loss: 2.3837915704428845

Epoch: 6| Step: 3
Training loss: 2.193794567383609
Validation loss: 2.382611033507739

Epoch: 6| Step: 4
Training loss: 1.884240712810403
Validation loss: 2.3995619819375706

Epoch: 6| Step: 5
Training loss: 1.9100309303535445
Validation loss: 2.398719470934865

Epoch: 6| Step: 6
Training loss: 2.3043012909653715
Validation loss: 2.366850330338565

Epoch: 6| Step: 7
Training loss: 1.8553961488674535
Validation loss: 2.3962346008888846

Epoch: 6| Step: 8
Training loss: 2.393682780703966
Validation loss: 2.384848951665929

Epoch: 6| Step: 9
Training loss: 2.9664281499183374
Validation loss: 2.386938577288945

Epoch: 6| Step: 10
Training loss: 2.8199351050302615
Validation loss: 2.398728780831462

Epoch: 6| Step: 11
Training loss: 2.046029068957547
Validation loss: 2.3953351584063327

Epoch: 6| Step: 12
Training loss: 2.4449889727696794
Validation loss: 2.3875067796091725

Epoch: 6| Step: 13
Training loss: 1.8788619006468439
Validation loss: 2.35128198711968

Epoch: 192| Step: 0
Training loss: 1.3125702975384688
Validation loss: 2.379117361903002

Epoch: 6| Step: 1
Training loss: 1.9223031288213985
Validation loss: 2.3876314497366957

Epoch: 6| Step: 2
Training loss: 2.189783702602741
Validation loss: 2.3924763863257663

Epoch: 6| Step: 3
Training loss: 2.4355492243873993
Validation loss: 2.3789217768051167

Epoch: 6| Step: 4
Training loss: 2.101958170234142
Validation loss: 2.385991855530318

Epoch: 6| Step: 5
Training loss: 2.2066545283088397
Validation loss: 2.3798647044810646

Epoch: 6| Step: 6
Training loss: 2.293433485099084
Validation loss: 2.3780230462368763

Epoch: 6| Step: 7
Training loss: 2.800870290109673
Validation loss: 2.3990350221933423

Epoch: 6| Step: 8
Training loss: 2.529860974891034
Validation loss: 2.382558708049942

Epoch: 6| Step: 9
Training loss: 2.0925635776865077
Validation loss: 2.403345825882854

Epoch: 6| Step: 10
Training loss: 2.889030717970974
Validation loss: 2.371499055139689

Epoch: 6| Step: 11
Training loss: 2.0293451621044625
Validation loss: 2.399864921861832

Epoch: 6| Step: 12
Training loss: 2.429601342737394
Validation loss: 2.359041962632514

Epoch: 6| Step: 13
Training loss: 1.610527440744223
Validation loss: 2.37309132634834

Epoch: 193| Step: 0
Training loss: 2.099265960287425
Validation loss: 2.3758897998144435

Epoch: 6| Step: 1
Training loss: 2.509524417670998
Validation loss: 2.390226421658667

Epoch: 6| Step: 2
Training loss: 2.949443318488601
Validation loss: 2.392302770819244

Epoch: 6| Step: 3
Training loss: 2.3153685228240395
Validation loss: 2.3532949992428662

Epoch: 6| Step: 4
Training loss: 2.1970915729675182
Validation loss: 2.4011045453082356

Epoch: 6| Step: 5
Training loss: 2.249772802114207
Validation loss: 2.400011109767344

Epoch: 6| Step: 6
Training loss: 1.8309105412011784
Validation loss: 2.3794033866638027

Epoch: 6| Step: 7
Training loss: 2.126274175669071
Validation loss: 2.358805032823012

Epoch: 6| Step: 8
Training loss: 2.5879225934051404
Validation loss: 2.378869667636089

Epoch: 6| Step: 9
Training loss: 1.2716283760622207
Validation loss: 2.371688500853412

Epoch: 6| Step: 10
Training loss: 1.9672809145368766
Validation loss: 2.3855212666430603

Epoch: 6| Step: 11
Training loss: 2.043485207859056
Validation loss: 2.3656716548355687

Epoch: 6| Step: 12
Training loss: 2.5792740544244515
Validation loss: 2.3542743641529125

Epoch: 6| Step: 13
Training loss: 2.3805277893136596
Validation loss: 2.376893268474327

Epoch: 194| Step: 0
Training loss: 2.381208937083153
Validation loss: 2.3816343840929797

Epoch: 6| Step: 1
Training loss: 1.8493427861931726
Validation loss: 2.363712691151146

Epoch: 6| Step: 2
Training loss: 1.7177204169439604
Validation loss: 2.402088481534443

Epoch: 6| Step: 3
Training loss: 2.479665647240961
Validation loss: 2.385189426200618

Epoch: 6| Step: 4
Training loss: 2.1807236481797103
Validation loss: 2.38671179179085

Epoch: 6| Step: 5
Training loss: 1.8276529599323452
Validation loss: 2.3588762006656903

Epoch: 6| Step: 6
Training loss: 2.26439754515924
Validation loss: 2.384411789097656

Epoch: 6| Step: 7
Training loss: 1.9861234036163766
Validation loss: 2.3641543335076234

Epoch: 6| Step: 8
Training loss: 2.752352315351773
Validation loss: 2.3916703722124986

Epoch: 6| Step: 9
Training loss: 2.394332603690629
Validation loss: 2.379814695040145

Epoch: 6| Step: 10
Training loss: 1.9336806769049526
Validation loss: 2.3999149098061734

Epoch: 6| Step: 11
Training loss: 2.521860486145987
Validation loss: 2.365171357121624

Epoch: 6| Step: 12
Training loss: 2.3043870633096404
Validation loss: 2.3613977321820876

Epoch: 6| Step: 13
Training loss: 2.4680066498553987
Validation loss: 2.364115310702728

Epoch: 195| Step: 0
Training loss: 2.0200748265448207
Validation loss: 2.375794915078116

Epoch: 6| Step: 1
Training loss: 2.832601303080247
Validation loss: 2.3894364020590535

Epoch: 6| Step: 2
Training loss: 1.9450950654242063
Validation loss: 2.3562948642468973

Epoch: 6| Step: 3
Training loss: 1.5690069892392111
Validation loss: 2.403319667141666

Epoch: 6| Step: 4
Training loss: 2.601391302667618
Validation loss: 2.372317652250866

Epoch: 6| Step: 5
Training loss: 2.2900257362352128
Validation loss: 2.3906754792602594

Epoch: 6| Step: 6
Training loss: 2.5077855949503496
Validation loss: 2.373851234919291

Epoch: 6| Step: 7
Training loss: 2.527589105078701
Validation loss: 2.352381664845194

Epoch: 6| Step: 8
Training loss: 1.7761173921999762
Validation loss: 2.3790426298193132

Epoch: 6| Step: 9
Training loss: 2.2992105870777624
Validation loss: 2.3579734073271736

Epoch: 6| Step: 10
Training loss: 2.0645526728452914
Validation loss: 2.3703177550458077

Epoch: 6| Step: 11
Training loss: 2.467875265323455
Validation loss: 2.362700202855041

Epoch: 6| Step: 12
Training loss: 1.7417320032352135
Validation loss: 2.3841223634813216

Epoch: 6| Step: 13
Training loss: 1.9388348687864683
Validation loss: 2.3898285095166343

Epoch: 196| Step: 0
Training loss: 1.8229145231688477
Validation loss: 2.3816019760733993

Epoch: 6| Step: 1
Training loss: 3.084704498037042
Validation loss: 2.3843289170182373

Epoch: 6| Step: 2
Training loss: 2.3365791995900826
Validation loss: 2.382023127011171

Epoch: 6| Step: 3
Training loss: 1.854984388876978
Validation loss: 2.3713253632728652

Epoch: 6| Step: 4
Training loss: 2.5598360496414028
Validation loss: 2.3700423490195974

Epoch: 6| Step: 5
Training loss: 2.3360411962247123
Validation loss: 2.3921751963580187

Epoch: 6| Step: 6
Training loss: 1.6061598874950147
Validation loss: 2.348998402819761

Epoch: 6| Step: 7
Training loss: 1.872452340226169
Validation loss: 2.3475521003733664

Epoch: 6| Step: 8
Training loss: 2.4124586586053614
Validation loss: 2.3545997570455546

Epoch: 6| Step: 9
Training loss: 2.6360830035071725
Validation loss: 2.384840608810605

Epoch: 6| Step: 10
Training loss: 2.0498940138052193
Validation loss: 2.3762924539817925

Epoch: 6| Step: 11
Training loss: 2.0400590471062183
Validation loss: 2.3936569918918935

Epoch: 6| Step: 12
Training loss: 2.048619582451441
Validation loss: 2.3793718059029447

Epoch: 6| Step: 13
Training loss: 1.7055978583737539
Validation loss: 2.3798101641483913

Epoch: 197| Step: 0
Training loss: 2.2495318031615064
Validation loss: 2.350027513092061

Epoch: 6| Step: 1
Training loss: 2.296771715398069
Validation loss: 2.354158079861477

Epoch: 6| Step: 2
Training loss: 2.2058438237883182
Validation loss: 2.369361114785432

Epoch: 6| Step: 3
Training loss: 2.141003763144766
Validation loss: 2.3691598483802587

Epoch: 6| Step: 4
Training loss: 1.9799429592431923
Validation loss: 2.3767307486305174

Epoch: 6| Step: 5
Training loss: 2.359367320067178
Validation loss: 2.369822506240226

Epoch: 6| Step: 6
Training loss: 2.2270732093155083
Validation loss: 2.3813639772355417

Epoch: 6| Step: 7
Training loss: 2.3633181734589748
Validation loss: 2.3531927333277927

Epoch: 6| Step: 8
Training loss: 2.608433719283568
Validation loss: 2.3618846181146864

Epoch: 6| Step: 9
Training loss: 1.7056290303508015
Validation loss: 2.351741440690961

Epoch: 6| Step: 10
Training loss: 2.1829750126148224
Validation loss: 2.3569626526090155

Epoch: 6| Step: 11
Training loss: 2.34651356846097
Validation loss: 2.37846616927809

Epoch: 6| Step: 12
Training loss: 2.1536541115641294
Validation loss: 2.3865962297056513

Epoch: 6| Step: 13
Training loss: 1.9196453652096204
Validation loss: 2.345857587335703

Epoch: 198| Step: 0
Training loss: 1.850452138447239
Validation loss: 2.3527253902875764

Epoch: 6| Step: 1
Training loss: 1.8688098451351784
Validation loss: 2.3375589026057133

Epoch: 6| Step: 2
Training loss: 1.7350733270458139
Validation loss: 2.35040275100239

Epoch: 6| Step: 3
Training loss: 2.460915217223028
Validation loss: 2.360889927732326

Epoch: 6| Step: 4
Training loss: 2.4613640309620637
Validation loss: 2.3620796717231216

Epoch: 6| Step: 5
Training loss: 1.8850842458582997
Validation loss: 2.34185884259564

Epoch: 6| Step: 6
Training loss: 2.922515309394046
Validation loss: 2.368778331146788

Epoch: 6| Step: 7
Training loss: 2.3039178112589815
Validation loss: 2.378250009733239

Epoch: 6| Step: 8
Training loss: 2.3146353476854897
Validation loss: 2.36197383347409

Epoch: 6| Step: 9
Training loss: 2.098684616479046
Validation loss: 2.3778701800722457

Epoch: 6| Step: 10
Training loss: 1.6599362216325346
Validation loss: 2.3572029362610256

Epoch: 6| Step: 11
Training loss: 2.150416790684361
Validation loss: 2.36377451315314

Epoch: 6| Step: 12
Training loss: 2.5607594417095183
Validation loss: 2.3538366676867124

Epoch: 6| Step: 13
Training loss: 2.115150626119354
Validation loss: 2.377599110050016

Epoch: 199| Step: 0
Training loss: 2.1646933617284643
Validation loss: 2.3663928200911544

Epoch: 6| Step: 1
Training loss: 2.0129149204700085
Validation loss: 2.353107267019143

Epoch: 6| Step: 2
Training loss: 2.2084623575005913
Validation loss: 2.370553626116523

Epoch: 6| Step: 3
Training loss: 1.9744675582535107
Validation loss: 2.3631223525676095

Epoch: 6| Step: 4
Training loss: 2.08435192638706
Validation loss: 2.3641934033803302

Epoch: 6| Step: 5
Training loss: 3.120950134563454
Validation loss: 2.362421365143163

Epoch: 6| Step: 6
Training loss: 2.1623870202688615
Validation loss: 2.36804762612912

Epoch: 6| Step: 7
Training loss: 2.5448691303352806
Validation loss: 2.3718793084363528

Epoch: 6| Step: 8
Training loss: 1.7488665316013183
Validation loss: 2.381656348356807

Epoch: 6| Step: 9
Training loss: 2.042371615200132
Validation loss: 2.3471886335971486

Epoch: 6| Step: 10
Training loss: 2.342336202816309
Validation loss: 2.3848933442811924

Epoch: 6| Step: 11
Training loss: 1.7105426071333276
Validation loss: 2.37147463042205

Epoch: 6| Step: 12
Training loss: 2.165018139205956
Validation loss: 2.3624130982654505

Epoch: 6| Step: 13
Training loss: 1.97297403023242
Validation loss: 2.3687802169889416

Epoch: 200| Step: 0
Training loss: 1.742478145424003
Validation loss: 2.3855068542423403

Epoch: 6| Step: 1
Training loss: 1.5473317714575352
Validation loss: 2.3510361123419576

Epoch: 6| Step: 2
Training loss: 2.406418237130576
Validation loss: 2.355158713797176

Epoch: 6| Step: 3
Training loss: 2.8741365877743363
Validation loss: 2.3523188105101362

Epoch: 6| Step: 4
Training loss: 2.7103214498376746
Validation loss: 2.363129269580921

Epoch: 6| Step: 5
Training loss: 1.9136730810014826
Validation loss: 2.3835795560675206

Epoch: 6| Step: 6
Training loss: 2.119020913957449
Validation loss: 2.3630239535281765

Epoch: 6| Step: 7
Training loss: 1.81267448111633
Validation loss: 2.3823214590667603

Epoch: 6| Step: 8
Training loss: 1.8372909426973387
Validation loss: 2.362585185079371

Epoch: 6| Step: 9
Training loss: 2.26239867852886
Validation loss: 2.390955197166167

Epoch: 6| Step: 10
Training loss: 2.015170970317858
Validation loss: 2.365359793357855

Epoch: 6| Step: 11
Training loss: 2.760794003205818
Validation loss: 2.340992362557989

Epoch: 6| Step: 12
Training loss: 2.2053972795495445
Validation loss: 2.3611186147044187

Epoch: 6| Step: 13
Training loss: 1.7427936406147142
Validation loss: 2.3679767317618157

Epoch: 201| Step: 0
Training loss: 2.212686770039892
Validation loss: 2.3670191432015653

Epoch: 6| Step: 1
Training loss: 2.4168481649009435
Validation loss: 2.3373139753158774

Epoch: 6| Step: 2
Training loss: 2.345329769510609
Validation loss: 2.3437950605757405

Epoch: 6| Step: 3
Training loss: 2.0822687353563842
Validation loss: 2.3933898681866523

Epoch: 6| Step: 4
Training loss: 1.5327524093686145
Validation loss: 2.3703589999737735

Epoch: 6| Step: 5
Training loss: 2.392832515972108
Validation loss: 2.3548847801667856

Epoch: 6| Step: 6
Training loss: 2.3625407422301756
Validation loss: 2.3872131079504633

Epoch: 6| Step: 7
Training loss: 1.7981186253471466
Validation loss: 2.378311658117859

Epoch: 6| Step: 8
Training loss: 2.0020879337232795
Validation loss: 2.3593563064696297

Epoch: 6| Step: 9
Training loss: 2.6534322715728433
Validation loss: 2.3734006542971375

Epoch: 6| Step: 10
Training loss: 1.8961047373022268
Validation loss: 2.3833122903331025

Epoch: 6| Step: 11
Training loss: 2.009099762903725
Validation loss: 2.354517431877454

Epoch: 6| Step: 12
Training loss: 2.7587063559228677
Validation loss: 2.3717184166162646

Epoch: 6| Step: 13
Training loss: 2.1922034787107543
Validation loss: 2.384100586458437

Epoch: 202| Step: 0
Training loss: 2.314659141674789
Validation loss: 2.387587962725771

Epoch: 6| Step: 1
Training loss: 2.8874887309329273
Validation loss: 2.359680898082595

Epoch: 6| Step: 2
Training loss: 2.561268580356745
Validation loss: 2.3582443552143886

Epoch: 6| Step: 3
Training loss: 2.1730530103246797
Validation loss: 2.3441786572996985

Epoch: 6| Step: 4
Training loss: 2.1793195078868206
Validation loss: 2.3515751275911243

Epoch: 6| Step: 5
Training loss: 2.280995080369781
Validation loss: 2.3562927442847053

Epoch: 6| Step: 6
Training loss: 2.0721956721227976
Validation loss: 2.3694557010389485

Epoch: 6| Step: 7
Training loss: 1.9901572260255616
Validation loss: 2.356107025582946

Epoch: 6| Step: 8
Training loss: 2.4120591625593524
Validation loss: 2.369779940286206

Epoch: 6| Step: 9
Training loss: 1.738062949885384
Validation loss: 2.3825084398812675

Epoch: 6| Step: 10
Training loss: 2.294379507053638
Validation loss: 2.3346977580841233

Epoch: 6| Step: 11
Training loss: 1.6707206377311619
Validation loss: 2.3681627580347118

Epoch: 6| Step: 12
Training loss: 2.0169244170658684
Validation loss: 2.331745790579544

Epoch: 6| Step: 13
Training loss: 1.1985860143199776
Validation loss: 2.344730392552491

Epoch: 203| Step: 0
Training loss: 1.9205584474869863
Validation loss: 2.3724687242105658

Epoch: 6| Step: 1
Training loss: 2.03895399016835
Validation loss: 2.3610456522948695

Epoch: 6| Step: 2
Training loss: 1.9649470095490345
Validation loss: 2.355070521775752

Epoch: 6| Step: 3
Training loss: 2.0543785878316374
Validation loss: 2.3727527828632304

Epoch: 6| Step: 4
Training loss: 2.442404483422951
Validation loss: 2.371061367661115

Epoch: 6| Step: 5
Training loss: 2.3017589518916886
Validation loss: 2.3791014031925326

Epoch: 6| Step: 6
Training loss: 2.1379297371034007
Validation loss: 2.363409719193236

Epoch: 6| Step: 7
Training loss: 2.1735905520029175
Validation loss: 2.361740589942166

Epoch: 6| Step: 8
Training loss: 2.2584556006897425
Validation loss: 2.349212159832538

Epoch: 6| Step: 9
Training loss: 2.0099238712450487
Validation loss: 2.3403556050633294

Epoch: 6| Step: 10
Training loss: 2.647015485221782
Validation loss: 2.326577338851495

Epoch: 6| Step: 11
Training loss: 2.482887446506886
Validation loss: 2.35750631494211

Epoch: 6| Step: 12
Training loss: 1.854112888656415
Validation loss: 2.3863450145381075

Epoch: 6| Step: 13
Training loss: 1.655053768379386
Validation loss: 2.3665023733325135

Epoch: 204| Step: 0
Training loss: 2.537588777539427
Validation loss: 2.3455830111985128

Epoch: 6| Step: 1
Training loss: 1.8879761859394086
Validation loss: 2.347360829031412

Epoch: 6| Step: 2
Training loss: 1.6402541695163724
Validation loss: 2.342154912664379

Epoch: 6| Step: 3
Training loss: 1.754237630077739
Validation loss: 2.3467974740737683

Epoch: 6| Step: 4
Training loss: 2.3553863561589603
Validation loss: 2.337789174420162

Epoch: 6| Step: 5
Training loss: 2.0899074081280107
Validation loss: 2.374837344115071

Epoch: 6| Step: 6
Training loss: 2.1904209798366825
Validation loss: 2.3793809539263506

Epoch: 6| Step: 7
Training loss: 1.8409743672067465
Validation loss: 2.344178102834299

Epoch: 6| Step: 8
Training loss: 2.5863373323411194
Validation loss: 2.356518693125992

Epoch: 6| Step: 9
Training loss: 1.9016933073316913
Validation loss: 2.356312752473941

Epoch: 6| Step: 10
Training loss: 2.3233156645589634
Validation loss: 2.342821509643678

Epoch: 6| Step: 11
Training loss: 1.971803990942997
Validation loss: 2.3501746919144333

Epoch: 6| Step: 12
Training loss: 2.7015054955985236
Validation loss: 2.3327006959780565

Epoch: 6| Step: 13
Training loss: 2.2204787276000015
Validation loss: 2.344053976930864

Epoch: 205| Step: 0
Training loss: 2.1171994367312257
Validation loss: 2.3425836998749214

Epoch: 6| Step: 1
Training loss: 2.3453533537557596
Validation loss: 2.362746995041167

Epoch: 6| Step: 2
Training loss: 2.104021980170833
Validation loss: 2.375185286240991

Epoch: 6| Step: 3
Training loss: 1.7259201304763345
Validation loss: 2.348355957206749

Epoch: 6| Step: 4
Training loss: 2.1453906840325816
Validation loss: 2.3759533717842527

Epoch: 6| Step: 5
Training loss: 1.7518433671504923
Validation loss: 2.365621152452494

Epoch: 6| Step: 6
Training loss: 2.4374920771543414
Validation loss: 2.3694438222428698

Epoch: 6| Step: 7
Training loss: 2.3209418782225897
Validation loss: 2.3696212319621623

Epoch: 6| Step: 8
Training loss: 2.1446786631797172
Validation loss: 2.336498790502962

Epoch: 6| Step: 9
Training loss: 1.921010513022716
Validation loss: 2.3735539244259267

Epoch: 6| Step: 10
Training loss: 2.4381198583967714
Validation loss: 2.3314701726667355

Epoch: 6| Step: 11
Training loss: 1.922074594445426
Validation loss: 2.334838616398641

Epoch: 6| Step: 12
Training loss: 2.414897983994729
Validation loss: 2.3619849184404016

Epoch: 6| Step: 13
Training loss: 2.250956438020127
Validation loss: 2.3398610721004265

Epoch: 206| Step: 0
Training loss: 2.9418790926073117
Validation loss: 2.335270158742201

Epoch: 6| Step: 1
Training loss: 2.7380852513496445
Validation loss: 2.3347559743582322

Epoch: 6| Step: 2
Training loss: 2.0523160876677724
Validation loss: 2.3499988299323045

Epoch: 6| Step: 3
Training loss: 1.8296639249538664
Validation loss: 2.340948303190632

Epoch: 6| Step: 4
Training loss: 2.5064783082697244
Validation loss: 2.3391368046650407

Epoch: 6| Step: 5
Training loss: 1.4838190744289002
Validation loss: 2.337244665477578

Epoch: 6| Step: 6
Training loss: 1.7691768602942126
Validation loss: 2.358129286438688

Epoch: 6| Step: 7
Training loss: 2.155636133357115
Validation loss: 2.355078153128355

Epoch: 6| Step: 8
Training loss: 1.6097601272352127
Validation loss: 2.348662329900105

Epoch: 6| Step: 9
Training loss: 2.289775437917725
Validation loss: 2.3640763317147293

Epoch: 6| Step: 10
Training loss: 2.0830139932661464
Validation loss: 2.3451598337285193

Epoch: 6| Step: 11
Training loss: 1.5683227382765526
Validation loss: 2.341910869982109

Epoch: 6| Step: 12
Training loss: 2.2829893614178154
Validation loss: 2.3507589773636126

Epoch: 6| Step: 13
Training loss: 1.8261833639344482
Validation loss: 2.340191725424633

Epoch: 207| Step: 0
Training loss: 1.9138708524710737
Validation loss: 2.3438607510340312

Epoch: 6| Step: 1
Training loss: 2.4428962250262614
Validation loss: 2.3493087685776812

Epoch: 6| Step: 2
Training loss: 2.1140256124296473
Validation loss: 2.3571031684998536

Epoch: 6| Step: 3
Training loss: 1.807777302893105
Validation loss: 2.35618532057795

Epoch: 6| Step: 4
Training loss: 1.3876904588865462
Validation loss: 2.3570894317758917

Epoch: 6| Step: 5
Training loss: 2.5000869735847755
Validation loss: 2.3671858841782143

Epoch: 6| Step: 6
Training loss: 2.212576861582034
Validation loss: 2.3458166230652644

Epoch: 6| Step: 7
Training loss: 2.178240114341745
Validation loss: 2.3567716402822847

Epoch: 6| Step: 8
Training loss: 2.501903953337065
Validation loss: 2.3584298893032067

Epoch: 6| Step: 9
Training loss: 2.4491482713892645
Validation loss: 2.3446850241237733

Epoch: 6| Step: 10
Training loss: 2.346634983838664
Validation loss: 2.3607344247479296

Epoch: 6| Step: 11
Training loss: 1.8618942632635862
Validation loss: 2.3778994865560663

Epoch: 6| Step: 12
Training loss: 2.489293920914308
Validation loss: 2.3410139820901725

Epoch: 6| Step: 13
Training loss: 1.9673458117472047
Validation loss: 2.347139479469631

Epoch: 208| Step: 0
Training loss: 2.5188261716319267
Validation loss: 2.3404721665522863

Epoch: 6| Step: 1
Training loss: 1.75292084673084
Validation loss: 2.3342846617224637

Epoch: 6| Step: 2
Training loss: 2.2517072770046993
Validation loss: 2.333266503575318

Epoch: 6| Step: 3
Training loss: 1.769654461274217
Validation loss: 2.3408632325630663

Epoch: 6| Step: 4
Training loss: 2.2124333258458835
Validation loss: 2.376385008067003

Epoch: 6| Step: 5
Training loss: 2.4685127047682567
Validation loss: 2.3521067930686335

Epoch: 6| Step: 6
Training loss: 1.5896534348908578
Validation loss: 2.3718034187334984

Epoch: 6| Step: 7
Training loss: 1.9586492310720234
Validation loss: 2.352887309013949

Epoch: 6| Step: 8
Training loss: 2.310041719035148
Validation loss: 2.309339943350424

Epoch: 6| Step: 9
Training loss: 2.3536236116953333
Validation loss: 2.3474122888911624

Epoch: 6| Step: 10
Training loss: 1.3589321160417935
Validation loss: 2.3595375576030984

Epoch: 6| Step: 11
Training loss: 2.4181602291282918
Validation loss: 2.3484929572857265

Epoch: 6| Step: 12
Training loss: 2.656005937920103
Validation loss: 2.3248163566435682

Epoch: 6| Step: 13
Training loss: 1.6049578891114007
Validation loss: 2.3415899461301093

Epoch: 209| Step: 0
Training loss: 2.5018147557610164
Validation loss: 2.350070367543727

Epoch: 6| Step: 1
Training loss: 2.9564487382408142
Validation loss: 2.355867176428383

Epoch: 6| Step: 2
Training loss: 2.3650965756785443
Validation loss: 2.352439855428953

Epoch: 6| Step: 3
Training loss: 1.9374026612472333
Validation loss: 2.346799522322135

Epoch: 6| Step: 4
Training loss: 2.565945054046509
Validation loss: 2.3109446568997996

Epoch: 6| Step: 5
Training loss: 1.9574265375883029
Validation loss: 2.3246033372821864

Epoch: 6| Step: 6
Training loss: 1.6239151634691824
Validation loss: 2.3555788374178364

Epoch: 6| Step: 7
Training loss: 2.204852029242714
Validation loss: 2.337140277845273

Epoch: 6| Step: 8
Training loss: 2.3223966235917817
Validation loss: 2.353883285374772

Epoch: 6| Step: 9
Training loss: 1.9144338442195992
Validation loss: 2.3742127692481496

Epoch: 6| Step: 10
Training loss: 1.1041933932158723
Validation loss: 2.323464519433194

Epoch: 6| Step: 11
Training loss: 2.1471614863052815
Validation loss: 2.328040864267526

Epoch: 6| Step: 12
Training loss: 1.7687607997389345
Validation loss: 2.3269446778664964

Epoch: 6| Step: 13
Training loss: 1.6212668452862
Validation loss: 2.338625236432365

Epoch: 210| Step: 0
Training loss: 2.1462761011686053
Validation loss: 2.327579934136832

Epoch: 6| Step: 1
Training loss: 2.332225797835326
Validation loss: 2.3477567686324794

Epoch: 6| Step: 2
Training loss: 2.0955957276768395
Validation loss: 2.339684305054044

Epoch: 6| Step: 3
Training loss: 1.972003367941497
Validation loss: 2.3624912754237823

Epoch: 6| Step: 4
Training loss: 2.1279357377868324
Validation loss: 2.3301590020961545

Epoch: 6| Step: 5
Training loss: 2.3391225273263174
Validation loss: 2.346706775843862

Epoch: 6| Step: 6
Training loss: 2.222316937282499
Validation loss: 2.36759740496358

Epoch: 6| Step: 7
Training loss: 2.0409380592318556
Validation loss: 2.346974384799012

Epoch: 6| Step: 8
Training loss: 1.5527371388536721
Validation loss: 2.3734083849540384

Epoch: 6| Step: 9
Training loss: 2.671175145629798
Validation loss: 2.359070824906353

Epoch: 6| Step: 10
Training loss: 1.7379405855837435
Validation loss: 2.3538949410139125

Epoch: 6| Step: 11
Training loss: 2.2060890549696834
Validation loss: 2.3391819464348744

Epoch: 6| Step: 12
Training loss: 2.262788878487332
Validation loss: 2.3364396509836456

Epoch: 6| Step: 13
Training loss: 0.7874941205002026
Validation loss: 2.354388304337582

Epoch: 211| Step: 0
Training loss: 2.099568722353535
Validation loss: 2.362206815215452

Epoch: 6| Step: 1
Training loss: 2.3240886748002882
Validation loss: 2.3469011044591026

Epoch: 6| Step: 2
Training loss: 2.0990985479605984
Validation loss: 2.3507261611329575

Epoch: 6| Step: 3
Training loss: 1.9031903460829822
Validation loss: 2.3699438670731374

Epoch: 6| Step: 4
Training loss: 2.148247394820775
Validation loss: 2.346129754694126

Epoch: 6| Step: 5
Training loss: 1.9564877057916357
Validation loss: 2.3549344753355475

Epoch: 6| Step: 6
Training loss: 1.9675098327817566
Validation loss: 2.3601123136113147

Epoch: 6| Step: 7
Training loss: 1.8575062697498586
Validation loss: 2.3318346872081546

Epoch: 6| Step: 8
Training loss: 2.415446751817199
Validation loss: 2.343622682456317

Epoch: 6| Step: 9
Training loss: 1.9409634182964812
Validation loss: 2.326323978786007

Epoch: 6| Step: 10
Training loss: 2.5323904788406937
Validation loss: 2.313693974704925

Epoch: 6| Step: 11
Training loss: 1.7549932632969076
Validation loss: 2.3286442738796738

Epoch: 6| Step: 12
Training loss: 2.428000597424253
Validation loss: 2.315167837927146

Epoch: 6| Step: 13
Training loss: 1.8910061790893884
Validation loss: 2.3351356731679562

Epoch: 212| Step: 0
Training loss: 3.078983709933386
Validation loss: 2.353326198978179

Epoch: 6| Step: 1
Training loss: 1.7555703337901776
Validation loss: 2.3509496636319933

Epoch: 6| Step: 2
Training loss: 1.744772460224474
Validation loss: 2.3534239490252395

Epoch: 6| Step: 3
Training loss: 1.7983969172614207
Validation loss: 2.3077235904497457

Epoch: 6| Step: 4
Training loss: 1.7582184725424002
Validation loss: 2.356864759175413

Epoch: 6| Step: 5
Training loss: 2.7124313943510683
Validation loss: 2.3494616419171868

Epoch: 6| Step: 6
Training loss: 2.1615157031676366
Validation loss: 2.3440940937960875

Epoch: 6| Step: 7
Training loss: 2.1583972135931626
Validation loss: 2.3299234054875

Epoch: 6| Step: 8
Training loss: 2.3645030496778885
Validation loss: 2.346001339118969

Epoch: 6| Step: 9
Training loss: 1.42984758325079
Validation loss: 2.337639236843788

Epoch: 6| Step: 10
Training loss: 2.322639403168227
Validation loss: 2.341665884429529

Epoch: 6| Step: 11
Training loss: 1.5261195122801914
Validation loss: 2.3276012784367017

Epoch: 6| Step: 12
Training loss: 1.824205941720961
Validation loss: 2.3476656717571327

Epoch: 6| Step: 13
Training loss: 2.4725325374178775
Validation loss: 2.3344947056902767

Epoch: 213| Step: 0
Training loss: 1.8596247016510081
Validation loss: 2.336985127449097

Epoch: 6| Step: 1
Training loss: 1.8977927537729702
Validation loss: 2.336703393967387

Epoch: 6| Step: 2
Training loss: 2.0709459019644925
Validation loss: 2.3329723241122573

Epoch: 6| Step: 3
Training loss: 2.1845386623908647
Validation loss: 2.3064301290464537

Epoch: 6| Step: 4
Training loss: 2.77377334495509
Validation loss: 2.362407943660478

Epoch: 6| Step: 5
Training loss: 2.1425441854009133
Validation loss: 2.3392977181764945

Epoch: 6| Step: 6
Training loss: 2.4187895778996076
Validation loss: 2.3552308773056434

Epoch: 6| Step: 7
Training loss: 2.1070855042824386
Validation loss: 2.33961919532556

Epoch: 6| Step: 8
Training loss: 2.0608685138484866
Validation loss: 2.335423156279052

Epoch: 6| Step: 9
Training loss: 2.2497388900141697
Validation loss: 2.3544490612891997

Epoch: 6| Step: 10
Training loss: 1.9399578133154978
Validation loss: 2.3743799740913056

Epoch: 6| Step: 11
Training loss: 2.461997636392607
Validation loss: 2.3359954669852643

Epoch: 6| Step: 12
Training loss: 1.5327506205505101
Validation loss: 2.3587419377311174

Epoch: 6| Step: 13
Training loss: 1.3842107309397007
Validation loss: 2.3173233156718496

Epoch: 214| Step: 0
Training loss: 1.8770162549948501
Validation loss: 2.3293741237452372

Epoch: 6| Step: 1
Training loss: 2.218614386054131
Validation loss: 2.3464417601650074

Epoch: 6| Step: 2
Training loss: 1.9635550366122718
Validation loss: 2.3296548348723447

Epoch: 6| Step: 3
Training loss: 1.846366125443814
Validation loss: 2.318725007522876

Epoch: 6| Step: 4
Training loss: 2.156828208466637
Validation loss: 2.325903528116821

Epoch: 6| Step: 5
Training loss: 2.218825325560329
Validation loss: 2.334347026418097

Epoch: 6| Step: 6
Training loss: 2.2543321864856445
Validation loss: 2.3188952299532923

Epoch: 6| Step: 7
Training loss: 1.6865361604724207
Validation loss: 2.305305594683063

Epoch: 6| Step: 8
Training loss: 1.6146159343094344
Validation loss: 2.380479251445821

Epoch: 6| Step: 9
Training loss: 2.0588253694413883
Validation loss: 2.320991288385309

Epoch: 6| Step: 10
Training loss: 2.871165994786212
Validation loss: 2.3117107517850255

Epoch: 6| Step: 11
Training loss: 2.3918083104669057
Validation loss: 2.3146504688532734

Epoch: 6| Step: 12
Training loss: 1.9780982161843492
Validation loss: 2.3177253201728525

Epoch: 6| Step: 13
Training loss: 2.170964660869987
Validation loss: 2.339627972276533

Epoch: 215| Step: 0
Training loss: 2.0150266247071795
Validation loss: 2.3574850608815074

Epoch: 6| Step: 1
Training loss: 1.4734731983378906
Validation loss: 2.338894671039025

Epoch: 6| Step: 2
Training loss: 2.2308336483890203
Validation loss: 2.3162076129931686

Epoch: 6| Step: 3
Training loss: 1.609134396835789
Validation loss: 2.3397380791232085

Epoch: 6| Step: 4
Training loss: 2.387476224930706
Validation loss: 2.33243243636421

Epoch: 6| Step: 5
Training loss: 2.01927882965239
Validation loss: 2.331534424705852

Epoch: 6| Step: 6
Training loss: 1.7120763741998017
Validation loss: 2.3280875646270074

Epoch: 6| Step: 7
Training loss: 2.2897131714410657
Validation loss: 2.330499562782831

Epoch: 6| Step: 8
Training loss: 1.8643791754711325
Validation loss: 2.339740065618424

Epoch: 6| Step: 9
Training loss: 1.766487855979105
Validation loss: 2.3181471081744798

Epoch: 6| Step: 10
Training loss: 2.1323631847359943
Validation loss: 2.352208304585074

Epoch: 6| Step: 11
Training loss: 2.9155783303012237
Validation loss: 2.3408744240674073

Epoch: 6| Step: 12
Training loss: 2.20339120108849
Validation loss: 2.321286208718633

Epoch: 6| Step: 13
Training loss: 2.2938654899106927
Validation loss: 2.337862090104901

Epoch: 216| Step: 0
Training loss: 1.7353019642866425
Validation loss: 2.325367140542031

Epoch: 6| Step: 1
Training loss: 1.8154166858816974
Validation loss: 2.3132681342741237

Epoch: 6| Step: 2
Training loss: 2.1403249265755893
Validation loss: 2.329253340146092

Epoch: 6| Step: 3
Training loss: 2.3935622577399664
Validation loss: 2.3537130048488533

Epoch: 6| Step: 4
Training loss: 1.5293870609433002
Validation loss: 2.3452471823393837

Epoch: 6| Step: 5
Training loss: 1.9739080404217482
Validation loss: 2.34889158850703

Epoch: 6| Step: 6
Training loss: 2.2500996037795105
Validation loss: 2.3531861008637525

Epoch: 6| Step: 7
Training loss: 2.1811977609756874
Validation loss: 2.364827157635459

Epoch: 6| Step: 8
Training loss: 2.0714545788565157
Validation loss: 2.338407892551706

Epoch: 6| Step: 9
Training loss: 2.4548040584521336
Validation loss: 2.2955345387124373

Epoch: 6| Step: 10
Training loss: 2.235183889517481
Validation loss: 2.334349271190995

Epoch: 6| Step: 11
Training loss: 1.6510405756067308
Validation loss: 2.3381706530162947

Epoch: 6| Step: 12
Training loss: 2.7115134031487513
Validation loss: 2.3480679634201618

Epoch: 6| Step: 13
Training loss: 1.8279403854140222
Validation loss: 2.3097657626958963

Epoch: 217| Step: 0
Training loss: 2.072446133933971
Validation loss: 2.3428079310126537

Epoch: 6| Step: 1
Training loss: 2.026648841495092
Validation loss: 2.3468633481226604

Epoch: 6| Step: 2
Training loss: 2.13741769464878
Validation loss: 2.3274889419363647

Epoch: 6| Step: 3
Training loss: 1.6155789248834196
Validation loss: 2.3490043780961214

Epoch: 6| Step: 4
Training loss: 2.0287894972213465
Validation loss: 2.341645629567022

Epoch: 6| Step: 5
Training loss: 2.1644750539250204
Validation loss: 2.3660451409013095

Epoch: 6| Step: 6
Training loss: 1.8708093223928388
Validation loss: 2.316206855923521

Epoch: 6| Step: 7
Training loss: 2.323576715091526
Validation loss: 2.3391315949315583

Epoch: 6| Step: 8
Training loss: 2.021281268102664
Validation loss: 2.3376751868125205

Epoch: 6| Step: 9
Training loss: 1.8089485891447952
Validation loss: 2.341027294068315

Epoch: 6| Step: 10
Training loss: 1.9575420025330001
Validation loss: 2.327105057378545

Epoch: 6| Step: 11
Training loss: 1.5556924150449123
Validation loss: 2.3471446119018022

Epoch: 6| Step: 12
Training loss: 2.185011729158743
Validation loss: 2.3354179135625937

Epoch: 6| Step: 13
Training loss: 3.334128253247983
Validation loss: 2.3333295299862336

Epoch: 218| Step: 0
Training loss: 1.4450670188488988
Validation loss: 2.3315837940158866

Epoch: 6| Step: 1
Training loss: 1.8770184143333761
Validation loss: 2.3362721487335327

Epoch: 6| Step: 2
Training loss: 1.586274209946258
Validation loss: 2.3292797765219655

Epoch: 6| Step: 3
Training loss: 2.1067375365943675
Validation loss: 2.321142487464285

Epoch: 6| Step: 4
Training loss: 2.2273925304925037
Validation loss: 2.3230600991965535

Epoch: 6| Step: 5
Training loss: 2.6694655234194538
Validation loss: 2.339165267020093

Epoch: 6| Step: 6
Training loss: 1.8011496740034798
Validation loss: 2.3442149017731504

Epoch: 6| Step: 7
Training loss: 1.8617697288970783
Validation loss: 2.335444143492845

Epoch: 6| Step: 8
Training loss: 2.2142690622784698
Validation loss: 2.331177669033061

Epoch: 6| Step: 9
Training loss: 1.7738376115664143
Validation loss: 2.3267097077656578

Epoch: 6| Step: 10
Training loss: 2.4653755980472876
Validation loss: 2.324309663415502

Epoch: 6| Step: 11
Training loss: 2.4817494848133026
Validation loss: 2.311075406441932

Epoch: 6| Step: 12
Training loss: 2.1091508534337424
Validation loss: 2.3139816832081106

Epoch: 6| Step: 13
Training loss: 1.8817837385728797
Validation loss: 2.28702278653199

Epoch: 219| Step: 0
Training loss: 2.1353902923692027
Validation loss: 2.313653657046773

Epoch: 6| Step: 1
Training loss: 2.2153961192549656
Validation loss: 2.3236438476236034

Epoch: 6| Step: 2
Training loss: 2.300052754170337
Validation loss: 2.3286520815594947

Epoch: 6| Step: 3
Training loss: 1.9560924722542556
Validation loss: 2.3155921421667767

Epoch: 6| Step: 4
Training loss: 1.7977597919272237
Validation loss: 2.3435117320153425

Epoch: 6| Step: 5
Training loss: 1.3659110950229651
Validation loss: 2.287311908617221

Epoch: 6| Step: 6
Training loss: 2.0771748371177323
Validation loss: 2.31995031234827

Epoch: 6| Step: 7
Training loss: 2.019366200415218
Validation loss: 2.305819968414357

Epoch: 6| Step: 8
Training loss: 1.8644450969351374
Validation loss: 2.3591865769096696

Epoch: 6| Step: 9
Training loss: 2.151891975967407
Validation loss: 2.314341776429545

Epoch: 6| Step: 10
Training loss: 2.692660146216916
Validation loss: 2.3156285429112833

Epoch: 6| Step: 11
Training loss: 2.1939406265946353
Validation loss: 2.348416808545927

Epoch: 6| Step: 12
Training loss: 2.004621530519249
Validation loss: 2.3289709074705067

Epoch: 6| Step: 13
Training loss: 2.187731921299467
Validation loss: 2.3266988194472944

Epoch: 220| Step: 0
Training loss: 1.989818405990446
Validation loss: 2.3139574723285268

Epoch: 6| Step: 1
Training loss: 2.165369954028937
Validation loss: 2.33237772994866

Epoch: 6| Step: 2
Training loss: 1.894733787800463
Validation loss: 2.314163822819267

Epoch: 6| Step: 3
Training loss: 2.1969019881390937
Validation loss: 2.2966864109921525

Epoch: 6| Step: 4
Training loss: 1.7827006004849042
Validation loss: 2.3047422246482534

Epoch: 6| Step: 5
Training loss: 1.8610197854607082
Validation loss: 2.3377739018968113

Epoch: 6| Step: 6
Training loss: 1.9426651677985727
Validation loss: 2.3207304761642957

Epoch: 6| Step: 7
Training loss: 1.7926884184785348
Validation loss: 2.3153599960462534

Epoch: 6| Step: 8
Training loss: 2.63575810770016
Validation loss: 2.31250816150878

Epoch: 6| Step: 9
Training loss: 1.9480253859046675
Validation loss: 2.309753060253769

Epoch: 6| Step: 10
Training loss: 2.04683434831859
Validation loss: 2.3161077108663477

Epoch: 6| Step: 11
Training loss: 2.2172127354632747
Validation loss: 2.274740089733746

Epoch: 6| Step: 12
Training loss: 2.2992938533316063
Validation loss: 2.3076441167007142

Epoch: 6| Step: 13
Training loss: 1.9080524365559173
Validation loss: 2.290488903827045

Epoch: 221| Step: 0
Training loss: 1.8554284663595808
Validation loss: 2.298979674946202

Epoch: 6| Step: 1
Training loss: 1.5496546883637414
Validation loss: 2.3237679770728805

Epoch: 6| Step: 2
Training loss: 2.744886238645283
Validation loss: 2.3109230772171556

Epoch: 6| Step: 3
Training loss: 1.943152641916949
Validation loss: 2.2971576413249823

Epoch: 6| Step: 4
Training loss: 2.0412314852957025
Validation loss: 2.3014678340134784

Epoch: 6| Step: 5
Training loss: 2.1807552443291165
Validation loss: 2.3369733271378257

Epoch: 6| Step: 6
Training loss: 1.8145475332215562
Validation loss: 2.28446301635417

Epoch: 6| Step: 7
Training loss: 2.438727436596752
Validation loss: 2.283645637387518

Epoch: 6| Step: 8
Training loss: 2.1338342028978126
Validation loss: 2.313947641883521

Epoch: 6| Step: 9
Training loss: 1.8052305255046024
Validation loss: 2.2983130236010614

Epoch: 6| Step: 10
Training loss: 1.6526822223698079
Validation loss: 2.2982493107586515

Epoch: 6| Step: 11
Training loss: 2.0693434264626758
Validation loss: 2.2939914720779457

Epoch: 6| Step: 12
Training loss: 1.7133558765862869
Validation loss: 2.32176567759551

Epoch: 6| Step: 13
Training loss: 2.8519281858308125
Validation loss: 2.3012966912461814

Epoch: 222| Step: 0
Training loss: 2.1448579688721865
Validation loss: 2.2971311907255867

Epoch: 6| Step: 1
Training loss: 2.419768469430122
Validation loss: 2.302868461738978

Epoch: 6| Step: 2
Training loss: 2.2039053326334055
Validation loss: 2.3313649205832108

Epoch: 6| Step: 3
Training loss: 1.7428541062840044
Validation loss: 2.3260496240392876

Epoch: 6| Step: 4
Training loss: 1.57755639436398
Validation loss: 2.327177172061329

Epoch: 6| Step: 5
Training loss: 1.6446763651922296
Validation loss: 2.2962469342068528

Epoch: 6| Step: 6
Training loss: 1.6189081004345454
Validation loss: 2.3026951669247233

Epoch: 6| Step: 7
Training loss: 2.7398656160576884
Validation loss: 2.3163859790102563

Epoch: 6| Step: 8
Training loss: 1.948387075596145
Validation loss: 2.3309536245891227

Epoch: 6| Step: 9
Training loss: 1.9999828933937904
Validation loss: 2.3173863293153283

Epoch: 6| Step: 10
Training loss: 2.494970603265142
Validation loss: 2.2958722839332792

Epoch: 6| Step: 11
Training loss: 2.214955052938015
Validation loss: 2.2969801628052684

Epoch: 6| Step: 12
Training loss: 1.6589141148185576
Validation loss: 2.3229504665625305

Epoch: 6| Step: 13
Training loss: 1.1810998104629835
Validation loss: 2.304541329124448

Epoch: 223| Step: 0
Training loss: 1.909388725368784
Validation loss: 2.288851724247182

Epoch: 6| Step: 1
Training loss: 2.654576211789139
Validation loss: 2.3171159338144234

Epoch: 6| Step: 2
Training loss: 2.0971191400565568
Validation loss: 2.3258819488945592

Epoch: 6| Step: 3
Training loss: 1.7345128734877344
Validation loss: 2.323465396060353

Epoch: 6| Step: 4
Training loss: 2.418649211035466
Validation loss: 2.2807803545004695

Epoch: 6| Step: 5
Training loss: 2.198603976086769
Validation loss: 2.308283446279942

Epoch: 6| Step: 6
Training loss: 1.8803115633226306
Validation loss: 2.306886091822047

Epoch: 6| Step: 7
Training loss: 2.2484755119837803
Validation loss: 2.3189801551803084

Epoch: 6| Step: 8
Training loss: 2.6942934625367125
Validation loss: 2.2884304483390383

Epoch: 6| Step: 9
Training loss: 0.9528017277544981
Validation loss: 2.2913668267619047

Epoch: 6| Step: 10
Training loss: 1.908100918050289
Validation loss: 2.330474475156143

Epoch: 6| Step: 11
Training loss: 2.0085412272675165
Validation loss: 2.328875311559839

Epoch: 6| Step: 12
Training loss: 1.8247857529806084
Validation loss: 2.2599890487658576

Epoch: 6| Step: 13
Training loss: 1.0461265963354065
Validation loss: 2.327899469084981

Epoch: 224| Step: 0
Training loss: 2.3844154844434335
Validation loss: 2.296776002691588

Epoch: 6| Step: 1
Training loss: 2.272876158952693
Validation loss: 2.2976841575935336

Epoch: 6| Step: 2
Training loss: 1.892248229257927
Validation loss: 2.279884618654457

Epoch: 6| Step: 3
Training loss: 2.073959535540608
Validation loss: 2.2865757075473523

Epoch: 6| Step: 4
Training loss: 2.4517798167590303
Validation loss: 2.327705521145367

Epoch: 6| Step: 5
Training loss: 1.9093978405973906
Validation loss: 2.251438030553549

Epoch: 6| Step: 6
Training loss: 1.8941003683056117
Validation loss: 2.296051523462703

Epoch: 6| Step: 7
Training loss: 2.0078792338283598
Validation loss: 2.302707573192333

Epoch: 6| Step: 8
Training loss: 2.0375495062120312
Validation loss: 2.306293538783053

Epoch: 6| Step: 9
Training loss: 1.6595348676263708
Validation loss: 2.301218961815068

Epoch: 6| Step: 10
Training loss: 1.977430673148405
Validation loss: 2.3178185206665356

Epoch: 6| Step: 11
Training loss: 1.6891101643403346
Validation loss: 2.3081138718269756

Epoch: 6| Step: 12
Training loss: 1.5967916000296254
Validation loss: 2.3349630702421713

Epoch: 6| Step: 13
Training loss: 2.207978981906258
Validation loss: 2.349345590817832

Epoch: 225| Step: 0
Training loss: 2.0469104094026913
Validation loss: 2.3258760883673566

Epoch: 6| Step: 1
Training loss: 1.6120606023362951
Validation loss: 2.3065750882277745

Epoch: 6| Step: 2
Training loss: 2.150596615715702
Validation loss: 2.332395963731173

Epoch: 6| Step: 3
Training loss: 2.658153076597638
Validation loss: 2.3192337891342882

Epoch: 6| Step: 4
Training loss: 2.0781525344745435
Validation loss: 2.3001179250703103

Epoch: 6| Step: 5
Training loss: 2.581525652116477
Validation loss: 2.304853926305808

Epoch: 6| Step: 6
Training loss: 1.9722739274078198
Validation loss: 2.3433528746916514

Epoch: 6| Step: 7
Training loss: 2.029727658762105
Validation loss: 2.3205339283225026

Epoch: 6| Step: 8
Training loss: 1.7002301593257267
Validation loss: 2.297238196539867

Epoch: 6| Step: 9
Training loss: 1.7114835242354067
Validation loss: 2.3389969598202653

Epoch: 6| Step: 10
Training loss: 1.7584440326043937
Validation loss: 2.3049925221135092

Epoch: 6| Step: 11
Training loss: 1.9702381383187646
Validation loss: 2.2979045427555707

Epoch: 6| Step: 12
Training loss: 1.6043276107440854
Validation loss: 2.311453290548963

Epoch: 6| Step: 13
Training loss: 2.1896534810200814
Validation loss: 2.331844239955601

Epoch: 226| Step: 0
Training loss: 1.5430681800192323
Validation loss: 2.319618832669471

Epoch: 6| Step: 1
Training loss: 2.2150865855634105
Validation loss: 2.2758931382094625

Epoch: 6| Step: 2
Training loss: 1.720067161091616
Validation loss: 2.2942239064853425

Epoch: 6| Step: 3
Training loss: 2.4555505314752075
Validation loss: 2.315604806489005

Epoch: 6| Step: 4
Training loss: 1.7657963492370121
Validation loss: 2.290282061802071

Epoch: 6| Step: 5
Training loss: 1.6770996740583681
Validation loss: 2.311213816071445

Epoch: 6| Step: 6
Training loss: 1.6333386609256557
Validation loss: 2.3209031334818566

Epoch: 6| Step: 7
Training loss: 1.722481993427474
Validation loss: 2.3112759198144763

Epoch: 6| Step: 8
Training loss: 1.9180372424045191
Validation loss: 2.2794118699795693

Epoch: 6| Step: 9
Training loss: 2.541671023339045
Validation loss: 2.3137685350088852

Epoch: 6| Step: 10
Training loss: 1.488451129499332
Validation loss: 2.3052365646819624

Epoch: 6| Step: 11
Training loss: 2.1462679919653467
Validation loss: 2.311397829724107

Epoch: 6| Step: 12
Training loss: 2.815884736303056
Validation loss: 2.2811322790797512

Epoch: 6| Step: 13
Training loss: 2.3019654832136345
Validation loss: 2.3188021987732674

Epoch: 227| Step: 0
Training loss: 2.7520211335246785
Validation loss: 2.289775215116614

Epoch: 6| Step: 1
Training loss: 1.8809426547713597
Validation loss: 2.3352384342622994

Epoch: 6| Step: 2
Training loss: 1.4488743786745086
Validation loss: 2.324065575223269

Epoch: 6| Step: 3
Training loss: 2.404295883364438
Validation loss: 2.3014869576349013

Epoch: 6| Step: 4
Training loss: 1.7511377723125126
Validation loss: 2.292322789418299

Epoch: 6| Step: 5
Training loss: 2.338087744437684
Validation loss: 2.308011083505453

Epoch: 6| Step: 6
Training loss: 1.6248805662427077
Validation loss: 2.322370953889975

Epoch: 6| Step: 7
Training loss: 2.201526034549294
Validation loss: 2.31082513049236

Epoch: 6| Step: 8
Training loss: 1.715866096940908
Validation loss: 2.3009599394509497

Epoch: 6| Step: 9
Training loss: 2.17777652443095
Validation loss: 2.3135543942641004

Epoch: 6| Step: 10
Training loss: 2.0771840195148177
Validation loss: 2.330183202516966

Epoch: 6| Step: 11
Training loss: 2.148417302816996
Validation loss: 2.2984426725210065

Epoch: 6| Step: 12
Training loss: 1.6588836459699936
Validation loss: 2.304509782621978

Epoch: 6| Step: 13
Training loss: 1.7753900878368274
Validation loss: 2.2837453902247478

Epoch: 228| Step: 0
Training loss: 1.833985545002622
Validation loss: 2.2942186824818864

Epoch: 6| Step: 1
Training loss: 1.8915341295818067
Validation loss: 2.279666810334466

Epoch: 6| Step: 2
Training loss: 2.742802042989539
Validation loss: 2.299723228654604

Epoch: 6| Step: 3
Training loss: 2.1787410308250577
Validation loss: 2.2859062580217833

Epoch: 6| Step: 4
Training loss: 2.2801027940700127
Validation loss: 2.2784696631237034

Epoch: 6| Step: 5
Training loss: 2.2060717632279596
Validation loss: 2.2776536552134496

Epoch: 6| Step: 6
Training loss: 1.9521425141191713
Validation loss: 2.279586676137284

Epoch: 6| Step: 7
Training loss: 1.6418636913803162
Validation loss: 2.2737263826260357

Epoch: 6| Step: 8
Training loss: 1.8263143065695497
Validation loss: 2.3029896183640983

Epoch: 6| Step: 9
Training loss: 1.9416474282726444
Validation loss: 2.2782171150671164

Epoch: 6| Step: 10
Training loss: 2.3654440323057115
Validation loss: 2.258687087232154

Epoch: 6| Step: 11
Training loss: 1.360445981880638
Validation loss: 2.2676654627256077

Epoch: 6| Step: 12
Training loss: 1.4093593554252264
Validation loss: 2.275628788508674

Epoch: 6| Step: 13
Training loss: 1.6293286112161771
Validation loss: 2.3265502927163446

Epoch: 229| Step: 0
Training loss: 1.4909762114706548
Validation loss: 2.275480512131944

Epoch: 6| Step: 1
Training loss: 1.7721035011065334
Validation loss: 2.2846661907716577

Epoch: 6| Step: 2
Training loss: 1.977165401619224
Validation loss: 2.322624559732185

Epoch: 6| Step: 3
Training loss: 2.5693268436863965
Validation loss: 2.3086243167919998

Epoch: 6| Step: 4
Training loss: 1.9585786287068667
Validation loss: 2.313452472662723

Epoch: 6| Step: 5
Training loss: 2.7701604690618606
Validation loss: 2.3227070109054546

Epoch: 6| Step: 6
Training loss: 1.316001671445069
Validation loss: 2.3504929205146645

Epoch: 6| Step: 7
Training loss: 1.7879364601212506
Validation loss: 2.2911580018111066

Epoch: 6| Step: 8
Training loss: 1.918104986569284
Validation loss: 2.2984503530257814

Epoch: 6| Step: 9
Training loss: 1.9438875180382826
Validation loss: 2.3078672470339865

Epoch: 6| Step: 10
Training loss: 1.4386976477463427
Validation loss: 2.319820506159392

Epoch: 6| Step: 11
Training loss: 2.0117624815104143
Validation loss: 2.2766688365953263

Epoch: 6| Step: 12
Training loss: 2.5478793545161587
Validation loss: 2.296758636926818

Epoch: 6| Step: 13
Training loss: 2.2692383463905883
Validation loss: 2.326678794592759

Epoch: 230| Step: 0
Training loss: 2.1544279056933138
Validation loss: 2.33209723774319

Epoch: 6| Step: 1
Training loss: 2.3676474347879086
Validation loss: 2.2906677123477595

Epoch: 6| Step: 2
Training loss: 1.6005296307400725
Validation loss: 2.2497776233796687

Epoch: 6| Step: 3
Training loss: 1.9632141757593193
Validation loss: 2.3159522927195924

Epoch: 6| Step: 4
Training loss: 2.491060773569848
Validation loss: 2.271924216785692

Epoch: 6| Step: 5
Training loss: 0.8939133554838672
Validation loss: 2.260860209251552

Epoch: 6| Step: 6
Training loss: 2.4312094677682077
Validation loss: 2.307281038193202

Epoch: 6| Step: 7
Training loss: 1.9582454851074846
Validation loss: 2.295329900428633

Epoch: 6| Step: 8
Training loss: 1.915184657404449
Validation loss: 2.275656876946387

Epoch: 6| Step: 9
Training loss: 1.8138647531899919
Validation loss: 2.281549306831421

Epoch: 6| Step: 10
Training loss: 2.0450763516524595
Validation loss: 2.299639062974756

Epoch: 6| Step: 11
Training loss: 1.793121996212581
Validation loss: 2.340502322491184

Epoch: 6| Step: 12
Training loss: 2.3603477241254476
Validation loss: 2.2680980340762775

Epoch: 6| Step: 13
Training loss: 2.1279349534913616
Validation loss: 2.276836728812795

Epoch: 231| Step: 0
Training loss: 2.260908703202119
Validation loss: 2.310055140688757

Epoch: 6| Step: 1
Training loss: 1.847555081136157
Validation loss: 2.2890125641455574

Epoch: 6| Step: 2
Training loss: 2.1730889968588594
Validation loss: 2.333287107504909

Epoch: 6| Step: 3
Training loss: 1.2539303025645305
Validation loss: 2.254646637334174

Epoch: 6| Step: 4
Training loss: 2.4952428379259897
Validation loss: 2.269087893307651

Epoch: 6| Step: 5
Training loss: 2.090203313110167
Validation loss: 2.321261987881112

Epoch: 6| Step: 6
Training loss: 1.8153532524085425
Validation loss: 2.3136488508810915

Epoch: 6| Step: 7
Training loss: 1.580723879290499
Validation loss: 2.324089413859418

Epoch: 6| Step: 8
Training loss: 1.6462077749017505
Validation loss: 2.2936998366574386

Epoch: 6| Step: 9
Training loss: 2.5103767571238227
Validation loss: 2.292334778199231

Epoch: 6| Step: 10
Training loss: 2.005755963208823
Validation loss: 2.3006726450383854

Epoch: 6| Step: 11
Training loss: 2.011815218788331
Validation loss: 2.310131094636688

Epoch: 6| Step: 12
Training loss: 1.6033440334309335
Validation loss: 2.2887415014257386

Epoch: 6| Step: 13
Training loss: 2.3650266145011103
Validation loss: 2.2876413826701

Epoch: 232| Step: 0
Training loss: 2.1909755888797333
Validation loss: 2.288970818875026

Epoch: 6| Step: 1
Training loss: 2.2293511311392527
Validation loss: 2.3179574223988992

Epoch: 6| Step: 2
Training loss: 1.4789889949778616
Validation loss: 2.275424458995389

Epoch: 6| Step: 3
Training loss: 2.2948198531179216
Validation loss: 2.264317638774571

Epoch: 6| Step: 4
Training loss: 1.9563956989472695
Validation loss: 2.2899331308824045

Epoch: 6| Step: 5
Training loss: 2.384548567907809
Validation loss: 2.266493988004451

Epoch: 6| Step: 6
Training loss: 1.7061280538836407
Validation loss: 2.279492254934269

Epoch: 6| Step: 7
Training loss: 1.7460620715107351
Validation loss: 2.2634178264748464

Epoch: 6| Step: 8
Training loss: 2.5560918558536825
Validation loss: 2.2565464927458834

Epoch: 6| Step: 9
Training loss: 2.5313099041667373
Validation loss: 2.3008917785065606

Epoch: 6| Step: 10
Training loss: 1.2689251670747255
Validation loss: 2.259663296719854

Epoch: 6| Step: 11
Training loss: 1.5067675037876882
Validation loss: 2.298588022222813

Epoch: 6| Step: 12
Training loss: 1.3420007542467343
Validation loss: 2.2583106524277508

Epoch: 6| Step: 13
Training loss: 0.7124402439423672
Validation loss: 2.3235849921575116

Epoch: 233| Step: 0
Training loss: 1.8931316436318524
Validation loss: 2.262107114004356

Epoch: 6| Step: 1
Training loss: 2.2861205063610477
Validation loss: 2.2982384443290726

Epoch: 6| Step: 2
Training loss: 2.096016297844866
Validation loss: 2.262365387423674

Epoch: 6| Step: 3
Training loss: 1.672355083807464
Validation loss: 2.295386487175376

Epoch: 6| Step: 4
Training loss: 2.7604319638002344
Validation loss: 2.3089584052317407

Epoch: 6| Step: 5
Training loss: 2.071352254936852
Validation loss: 2.301889935853138

Epoch: 6| Step: 6
Training loss: 1.3179771490909158
Validation loss: 2.257868706509244

Epoch: 6| Step: 7
Training loss: 1.7254247584733187
Validation loss: 2.2633927847685866

Epoch: 6| Step: 8
Training loss: 1.6820758252011334
Validation loss: 2.257770881846921

Epoch: 6| Step: 9
Training loss: 1.921573025930041
Validation loss: 2.27689873153566

Epoch: 6| Step: 10
Training loss: 1.7841756786182383
Validation loss: 2.291424181536888

Epoch: 6| Step: 11
Training loss: 1.8903278716350436
Validation loss: 2.3075466390584913

Epoch: 6| Step: 12
Training loss: 2.1498858754231
Validation loss: 2.291920039544245

Epoch: 6| Step: 13
Training loss: 2.183667449526335
Validation loss: 2.278966757024505

Epoch: 234| Step: 0
Training loss: 0.9932157939990165
Validation loss: 2.2906460418068235

Epoch: 6| Step: 1
Training loss: 1.5863434971879693
Validation loss: 2.2512579242036423

Epoch: 6| Step: 2
Training loss: 2.145368013268007
Validation loss: 2.2823240544621703

Epoch: 6| Step: 3
Training loss: 2.0073369869493276
Validation loss: 2.2923918901237865

Epoch: 6| Step: 4
Training loss: 2.020893043605987
Validation loss: 2.2718171171967625

Epoch: 6| Step: 5
Training loss: 1.8142813774760778
Validation loss: 2.308066632930613

Epoch: 6| Step: 6
Training loss: 2.026165276085143
Validation loss: 2.26943322033651

Epoch: 6| Step: 7
Training loss: 2.669341732417157
Validation loss: 2.28956556309842

Epoch: 6| Step: 8
Training loss: 1.7712006431061527
Validation loss: 2.2978718140256045

Epoch: 6| Step: 9
Training loss: 1.7973404654640577
Validation loss: 2.295770965360911

Epoch: 6| Step: 10
Training loss: 2.00991948227431
Validation loss: 2.284400973169475

Epoch: 6| Step: 11
Training loss: 2.0560219496212144
Validation loss: 2.2955975183646022

Epoch: 6| Step: 12
Training loss: 2.1969922790044407
Validation loss: 2.2671494698436137

Epoch: 6| Step: 13
Training loss: 1.579644104675646
Validation loss: 2.2791722447219325

Epoch: 235| Step: 0
Training loss: 1.8185243132263615
Validation loss: 2.2949375061466313

Epoch: 6| Step: 1
Training loss: 2.0959552140437885
Validation loss: 2.2952790750372474

Epoch: 6| Step: 2
Training loss: 2.5397216880189832
Validation loss: 2.293110535994144

Epoch: 6| Step: 3
Training loss: 1.5612465217496612
Validation loss: 2.2909248076051623

Epoch: 6| Step: 4
Training loss: 1.1065932845773188
Validation loss: 2.2790612781770805

Epoch: 6| Step: 5
Training loss: 1.9514984682327816
Validation loss: 2.28601485183267

Epoch: 6| Step: 6
Training loss: 2.0636096627979494
Validation loss: 2.2776991252173704

Epoch: 6| Step: 7
Training loss: 1.5577385642853763
Validation loss: 2.290284585948133

Epoch: 6| Step: 8
Training loss: 2.221995491806113
Validation loss: 2.243754232233924

Epoch: 6| Step: 9
Training loss: 1.964940942745553
Validation loss: 2.275193154222809

Epoch: 6| Step: 10
Training loss: 1.8477868322315114
Validation loss: 2.298221142600503

Epoch: 6| Step: 11
Training loss: 1.9772725394277773
Validation loss: 2.28874812798275

Epoch: 6| Step: 12
Training loss: 2.542307215370605
Validation loss: 2.27452977941943

Epoch: 6| Step: 13
Training loss: 1.296083001660738
Validation loss: 2.2388812724450693

Epoch: 236| Step: 0
Training loss: 1.7677207594168587
Validation loss: 2.2694985244015604

Epoch: 6| Step: 1
Training loss: 2.3006272580177938
Validation loss: 2.311392257448356

Epoch: 6| Step: 2
Training loss: 1.801763237839054
Validation loss: 2.2381507769506284

Epoch: 6| Step: 3
Training loss: 1.7169412979639975
Validation loss: 2.270800280285745

Epoch: 6| Step: 4
Training loss: 1.7004993042062548
Validation loss: 2.2946635796790367

Epoch: 6| Step: 5
Training loss: 2.3972630312282286
Validation loss: 2.2824452519946807

Epoch: 6| Step: 6
Training loss: 2.6062480899062805
Validation loss: 2.266404498654365

Epoch: 6| Step: 7
Training loss: 1.186781816646289
Validation loss: 2.2442626006079736

Epoch: 6| Step: 8
Training loss: 1.9242635631105582
Validation loss: 2.310014681280025

Epoch: 6| Step: 9
Training loss: 2.1608519166891966
Validation loss: 2.266508667991432

Epoch: 6| Step: 10
Training loss: 1.8836530020281232
Validation loss: 2.2765412696880354

Epoch: 6| Step: 11
Training loss: 1.6901885620425312
Validation loss: 2.2679443832368693

Epoch: 6| Step: 12
Training loss: 1.4698941258820277
Validation loss: 2.2390907549098826

Epoch: 6| Step: 13
Training loss: 2.0795300545195654
Validation loss: 2.251736056630947

Epoch: 237| Step: 0
Training loss: 1.7873229519320715
Validation loss: 2.2923967274362536

Epoch: 6| Step: 1
Training loss: 2.4788370848347125
Validation loss: 2.269730646698425

Epoch: 6| Step: 2
Training loss: 1.7820747206293024
Validation loss: 2.2919425117809715

Epoch: 6| Step: 3
Training loss: 2.1384103275430726
Validation loss: 2.286865971310857

Epoch: 6| Step: 4
Training loss: 2.0776896773692592
Validation loss: 2.2504765565322153

Epoch: 6| Step: 5
Training loss: 1.6495544120923593
Validation loss: 2.3063411763654154

Epoch: 6| Step: 6
Training loss: 1.5142241620974861
Validation loss: 2.283301632922115

Epoch: 6| Step: 7
Training loss: 1.8951432645486364
Validation loss: 2.293261386129574

Epoch: 6| Step: 8
Training loss: 2.541974366953958
Validation loss: 2.278378362518146

Epoch: 6| Step: 9
Training loss: 1.5544206399816545
Validation loss: 2.2866212277271805

Epoch: 6| Step: 10
Training loss: 1.6464217458015482
Validation loss: 2.275664268227149

Epoch: 6| Step: 11
Training loss: 1.039203892316129
Validation loss: 2.28166612647033

Epoch: 6| Step: 12
Training loss: 2.214565037543823
Validation loss: 2.289119816197295

Epoch: 6| Step: 13
Training loss: 2.9421241563004146
Validation loss: 2.2840454004287936

Epoch: 238| Step: 0
Training loss: 2.572976630331954
Validation loss: 2.274459892579826

Epoch: 6| Step: 1
Training loss: 1.9068685059763488
Validation loss: 2.2916995526263317

Epoch: 6| Step: 2
Training loss: 1.9818078804981243
Validation loss: 2.2665280464240167

Epoch: 6| Step: 3
Training loss: 1.6780406596835333
Validation loss: 2.2572861469625183

Epoch: 6| Step: 4
Training loss: 1.9721732275284245
Validation loss: 2.3125315888255833

Epoch: 6| Step: 5
Training loss: 1.5885333535232231
Validation loss: 2.2917794730276415

Epoch: 6| Step: 6
Training loss: 1.721093816493133
Validation loss: 2.267314079001356

Epoch: 6| Step: 7
Training loss: 1.5603287679296727
Validation loss: 2.26263319135735

Epoch: 6| Step: 8
Training loss: 2.3365403229988897
Validation loss: 2.2638651223789688

Epoch: 6| Step: 9
Training loss: 1.6319710055234629
Validation loss: 2.276121579703239

Epoch: 6| Step: 10
Training loss: 1.8113332478917878
Validation loss: 2.26816342009894

Epoch: 6| Step: 11
Training loss: 1.7740740200929952
Validation loss: 2.2798729590917297

Epoch: 6| Step: 12
Training loss: 2.3198247840092185
Validation loss: 2.2322576822728317

Epoch: 6| Step: 13
Training loss: 1.92797961312908
Validation loss: 2.3045877531368424

Epoch: 239| Step: 0
Training loss: 2.004938941463451
Validation loss: 2.2593333056022122

Epoch: 6| Step: 1
Training loss: 1.4999802111274014
Validation loss: 2.267855059922682

Epoch: 6| Step: 2
Training loss: 2.001814972367264
Validation loss: 2.2516285347595004

Epoch: 6| Step: 3
Training loss: 1.715540090658939
Validation loss: 2.2487884755391874

Epoch: 6| Step: 4
Training loss: 1.8574286780648943
Validation loss: 2.291343329059106

Epoch: 6| Step: 5
Training loss: 1.8254363021833595
Validation loss: 2.244273128100022

Epoch: 6| Step: 6
Training loss: 1.7501837770149784
Validation loss: 2.2583375043557674

Epoch: 6| Step: 7
Training loss: 2.025559303374156
Validation loss: 2.261449221225008

Epoch: 6| Step: 8
Training loss: 1.9806895838301584
Validation loss: 2.296821302297306

Epoch: 6| Step: 9
Training loss: 1.9031555824766562
Validation loss: 2.260128468056403

Epoch: 6| Step: 10
Training loss: 2.5037190431308454
Validation loss: 2.262816542842135

Epoch: 6| Step: 11
Training loss: 2.5114580793366104
Validation loss: 2.3069911338747833

Epoch: 6| Step: 12
Training loss: 1.7744852743518615
Validation loss: 2.3135348401633764

Epoch: 6| Step: 13
Training loss: 1.7233959867400808
Validation loss: 2.2636922250569254

Epoch: 240| Step: 0
Training loss: 1.7897696617507552
Validation loss: 2.319002219819329

Epoch: 6| Step: 1
Training loss: 1.9263324683753429
Validation loss: 2.254288362679914

Epoch: 6| Step: 2
Training loss: 1.716767155690576
Validation loss: 2.288652467806486

Epoch: 6| Step: 3
Training loss: 2.8370443238704377
Validation loss: 2.240059202843097

Epoch: 6| Step: 4
Training loss: 1.587220373081769
Validation loss: 2.2519908304528866

Epoch: 6| Step: 5
Training loss: 2.0162738081111162
Validation loss: 2.2719368734556986

Epoch: 6| Step: 6
Training loss: 1.7797095346803171
Validation loss: 2.2564797362271047

Epoch: 6| Step: 7
Training loss: 1.884732608802466
Validation loss: 2.2371528557389784

Epoch: 6| Step: 8
Training loss: 1.2728750472853128
Validation loss: 2.296310731075322

Epoch: 6| Step: 9
Training loss: 1.9386306663005837
Validation loss: 2.2876295967852047

Epoch: 6| Step: 10
Training loss: 1.8432590671545497
Validation loss: 2.2818294075340932

Epoch: 6| Step: 11
Training loss: 1.911122458015192
Validation loss: 2.2735148932138896

Epoch: 6| Step: 12
Training loss: 2.1603999353960774
Validation loss: 2.2883019238441147

Epoch: 6| Step: 13
Training loss: 1.1477523109115306
Validation loss: 2.2637306641833685

Epoch: 241| Step: 0
Training loss: 2.0924170507034936
Validation loss: 2.2773661493722948

Epoch: 6| Step: 1
Training loss: 1.5075461987553933
Validation loss: 2.298885458668117

Epoch: 6| Step: 2
Training loss: 2.0335884132271262
Validation loss: 2.285378607740221

Epoch: 6| Step: 3
Training loss: 1.9225630110198086
Validation loss: 2.2636648851113126

Epoch: 6| Step: 4
Training loss: 1.9143912519611364
Validation loss: 2.267164563405706

Epoch: 6| Step: 5
Training loss: 2.1554093864647843
Validation loss: 2.2316461110108246

Epoch: 6| Step: 6
Training loss: 1.8420206785501347
Validation loss: 2.2457204965677304

Epoch: 6| Step: 7
Training loss: 1.7051877470488541
Validation loss: 2.2982704466898887

Epoch: 6| Step: 8
Training loss: 1.7629677686119711
Validation loss: 2.324452270126625

Epoch: 6| Step: 9
Training loss: 1.5494488197581904
Validation loss: 2.2739617131294123

Epoch: 6| Step: 10
Training loss: 2.190493034708721
Validation loss: 2.242473112894388

Epoch: 6| Step: 11
Training loss: 1.8552268422692264
Validation loss: 2.2593875930102274

Epoch: 6| Step: 12
Training loss: 2.241275721592275
Validation loss: 2.300134675870083

Epoch: 6| Step: 13
Training loss: 2.002530523631885
Validation loss: 2.2325217233176096

Epoch: 242| Step: 0
Training loss: 1.5522362635836109
Validation loss: 2.2532742301021234

Epoch: 6| Step: 1
Training loss: 2.297421241215599
Validation loss: 2.2259984526588346

Epoch: 6| Step: 2
Training loss: 1.9001360543376615
Validation loss: 2.268836006024341

Epoch: 6| Step: 3
Training loss: 1.9129151934556627
Validation loss: 2.2650964682684127

Epoch: 6| Step: 4
Training loss: 1.4296111206330877
Validation loss: 2.2785906932622546

Epoch: 6| Step: 5
Training loss: 1.5862226558700268
Validation loss: 2.2454373346863825

Epoch: 6| Step: 6
Training loss: 1.4036627811501006
Validation loss: 2.2938416981647896

Epoch: 6| Step: 7
Training loss: 1.9938498947326049
Validation loss: 2.2471273147733024

Epoch: 6| Step: 8
Training loss: 2.040268815224824
Validation loss: 2.272360729908824

Epoch: 6| Step: 9
Training loss: 2.624923432459628
Validation loss: 2.2726687066091684

Epoch: 6| Step: 10
Training loss: 1.906788609190956
Validation loss: 2.26462144418207

Epoch: 6| Step: 11
Training loss: 1.981830798197239
Validation loss: 2.2280106290245336

Epoch: 6| Step: 12
Training loss: 1.8869451856874546
Validation loss: 2.242308508290376

Epoch: 6| Step: 13
Training loss: 1.730280812135063
Validation loss: 2.2795130609428043

Epoch: 243| Step: 0
Training loss: 1.4919890426560651
Validation loss: 2.260823447746817

Epoch: 6| Step: 1
Training loss: 1.67436375277089
Validation loss: 2.284233886082477

Epoch: 6| Step: 2
Training loss: 2.030297393437311
Validation loss: 2.261619206221787

Epoch: 6| Step: 3
Training loss: 1.83397507995265
Validation loss: 2.271539419343475

Epoch: 6| Step: 4
Training loss: 1.7554661668012328
Validation loss: 2.318974828858417

Epoch: 6| Step: 5
Training loss: 2.192121256495619
Validation loss: 2.316945283020265

Epoch: 6| Step: 6
Training loss: 1.855990366647647
Validation loss: 2.2613490414928337

Epoch: 6| Step: 7
Training loss: 2.238433140366082
Validation loss: 2.2812875285807452

Epoch: 6| Step: 8
Training loss: 2.0108500855126543
Validation loss: 2.2890280673699075

Epoch: 6| Step: 9
Training loss: 1.7170171151571774
Validation loss: 2.2962896212049926

Epoch: 6| Step: 10
Training loss: 1.659829715704261
Validation loss: 2.308894938399227

Epoch: 6| Step: 11
Training loss: 1.9879357538031202
Validation loss: 2.2889829136915485

Epoch: 6| Step: 12
Training loss: 2.4596996282162915
Validation loss: 2.2788218354257213

Epoch: 6| Step: 13
Training loss: 1.2451614192511167
Validation loss: 2.247883312073644

Epoch: 244| Step: 0
Training loss: 1.4931442628674185
Validation loss: 2.279641055329731

Epoch: 6| Step: 1
Training loss: 1.7158230220836246
Validation loss: 2.240190452212833

Epoch: 6| Step: 2
Training loss: 1.7455436642249371
Validation loss: 2.2858609411792385

Epoch: 6| Step: 3
Training loss: 1.4543727317041562
Validation loss: 2.254210556722386

Epoch: 6| Step: 4
Training loss: 2.1286071007209157
Validation loss: 2.2407355120424315

Epoch: 6| Step: 5
Training loss: 1.4440017943014478
Validation loss: 2.2766825191754427

Epoch: 6| Step: 6
Training loss: 2.035768383903933
Validation loss: 2.2365117852174827

Epoch: 6| Step: 7
Training loss: 2.266705695919535
Validation loss: 2.2453980811753866

Epoch: 6| Step: 8
Training loss: 2.0188315265833974
Validation loss: 2.242039684219568

Epoch: 6| Step: 9
Training loss: 1.8420168602676068
Validation loss: 2.237390235861676

Epoch: 6| Step: 10
Training loss: 2.380274487222321
Validation loss: 2.241885715713341

Epoch: 6| Step: 11
Training loss: 1.882166708208009
Validation loss: 2.288953660455435

Epoch: 6| Step: 12
Training loss: 1.7666396879739326
Validation loss: 2.28561147385897

Epoch: 6| Step: 13
Training loss: 1.5965880761419147
Validation loss: 2.2852201478275687

Epoch: 245| Step: 0
Training loss: 1.6855088248439132
Validation loss: 2.2435942043805843

Epoch: 6| Step: 1
Training loss: 2.562758828094076
Validation loss: 2.278579123274944

Epoch: 6| Step: 2
Training loss: 1.2182069204233767
Validation loss: 2.289965982029975

Epoch: 6| Step: 3
Training loss: 1.5195390951155132
Validation loss: 2.2760498725546263

Epoch: 6| Step: 4
Training loss: 2.4206762485018594
Validation loss: 2.2475139620287714

Epoch: 6| Step: 5
Training loss: 1.8708827272052833
Validation loss: 2.2600401074234355

Epoch: 6| Step: 6
Training loss: 1.2735233862998259
Validation loss: 2.2657971750593395

Epoch: 6| Step: 7
Training loss: 2.0192438802887325
Validation loss: 2.2866197859304997

Epoch: 6| Step: 8
Training loss: 1.9724597795299663
Validation loss: 2.2364131948745825

Epoch: 6| Step: 9
Training loss: 1.9099500423908242
Validation loss: 2.2851559067087726

Epoch: 6| Step: 10
Training loss: 1.8430583755802497
Validation loss: 2.228730825468782

Epoch: 6| Step: 11
Training loss: 1.702137371996806
Validation loss: 2.2589886339826792

Epoch: 6| Step: 12
Training loss: 1.1721022322010624
Validation loss: 2.2665444754046042

Epoch: 6| Step: 13
Training loss: 2.5375306188680984
Validation loss: 2.2288975156863784

Epoch: 246| Step: 0
Training loss: 1.5968840208750599
Validation loss: 2.2636717255081154

Epoch: 6| Step: 1
Training loss: 2.098756412862099
Validation loss: 2.279547899897707

Epoch: 6| Step: 2
Training loss: 1.5539532945357497
Validation loss: 2.2851422518657354

Epoch: 6| Step: 3
Training loss: 2.019713166711391
Validation loss: 2.2488276539106553

Epoch: 6| Step: 4
Training loss: 1.6441022807276982
Validation loss: 2.22061400833966

Epoch: 6| Step: 5
Training loss: 2.255112667271825
Validation loss: 2.2712709893800267

Epoch: 6| Step: 6
Training loss: 2.383367054929679
Validation loss: 2.2634829501506384

Epoch: 6| Step: 7
Training loss: 2.1440266778197135
Validation loss: 2.252165973262636

Epoch: 6| Step: 8
Training loss: 1.5180286342649278
Validation loss: 2.265894078452455

Epoch: 6| Step: 9
Training loss: 1.9180532774780112
Validation loss: 2.237129866939219

Epoch: 6| Step: 10
Training loss: 1.9096438104734712
Validation loss: 2.282305262264664

Epoch: 6| Step: 11
Training loss: 1.7879927322871505
Validation loss: 2.282499905089248

Epoch: 6| Step: 12
Training loss: 1.5920441417900317
Validation loss: 2.2891005702193374

Epoch: 6| Step: 13
Training loss: 1.5378844114008015
Validation loss: 2.216340838721891

Epoch: 247| Step: 0
Training loss: 1.766083649335845
Validation loss: 2.2403593221889784

Epoch: 6| Step: 1
Training loss: 1.5044331209804342
Validation loss: 2.283429446382061

Epoch: 6| Step: 2
Training loss: 2.3787880854081016
Validation loss: 2.2667199080015408

Epoch: 6| Step: 3
Training loss: 2.4109350396055373
Validation loss: 2.2666135855340124

Epoch: 6| Step: 4
Training loss: 1.8610317638746827
Validation loss: 2.239421978513488

Epoch: 6| Step: 5
Training loss: 2.2089824322355516
Validation loss: 2.2639028734686644

Epoch: 6| Step: 6
Training loss: 1.9136538322300523
Validation loss: 2.289662163708402

Epoch: 6| Step: 7
Training loss: 2.0198558789952368
Validation loss: 2.228084380447456

Epoch: 6| Step: 8
Training loss: 1.7013345108511466
Validation loss: 2.2725849792258184

Epoch: 6| Step: 9
Training loss: 1.7797081950309857
Validation loss: 2.2390251977097475

Epoch: 6| Step: 10
Training loss: 2.02398662406663
Validation loss: 2.2738081980790437

Epoch: 6| Step: 11
Training loss: 1.5628823384754391
Validation loss: 2.257430471670694

Epoch: 6| Step: 12
Training loss: 1.4342831817028154
Validation loss: 2.2921815452272134

Epoch: 6| Step: 13
Training loss: 1.3105947198676153
Validation loss: 2.292785080948176

Epoch: 248| Step: 0
Training loss: 1.8489398650917075
Validation loss: 2.256789338298815

Epoch: 6| Step: 1
Training loss: 1.3107335146766417
Validation loss: 2.2302058246166587

Epoch: 6| Step: 2
Training loss: 1.9613515713066563
Validation loss: 2.2569788666133475

Epoch: 6| Step: 3
Training loss: 2.0648174559888814
Validation loss: 2.2553283614752444

Epoch: 6| Step: 4
Training loss: 1.988089441666802
Validation loss: 2.2142887722697626

Epoch: 6| Step: 5
Training loss: 1.7674521385522024
Validation loss: 2.2042389788411207

Epoch: 6| Step: 6
Training loss: 1.9475725519379903
Validation loss: 2.239023248665505

Epoch: 6| Step: 7
Training loss: 1.4829203655857401
Validation loss: 2.254770408394685

Epoch: 6| Step: 8
Training loss: 1.6780790922964393
Validation loss: 2.2559190303019365

Epoch: 6| Step: 9
Training loss: 1.9486869744073452
Validation loss: 2.302780573819656

Epoch: 6| Step: 10
Training loss: 2.058352490643555
Validation loss: 2.280885244987098

Epoch: 6| Step: 11
Training loss: 2.6238758768288553
Validation loss: 2.281592814890736

Epoch: 6| Step: 12
Training loss: 1.501651569943993
Validation loss: 2.2721613586695564

Epoch: 6| Step: 13
Training loss: 1.4041087484819246
Validation loss: 2.248613189939053

Epoch: 249| Step: 0
Training loss: 1.4523742541248794
Validation loss: 2.2737940551059594

Epoch: 6| Step: 1
Training loss: 2.3923505153215276
Validation loss: 2.2357472408796433

Epoch: 6| Step: 2
Training loss: 1.4176056031680402
Validation loss: 2.2798011484093155

Epoch: 6| Step: 3
Training loss: 1.5961324798172116
Validation loss: 2.229320477306631

Epoch: 6| Step: 4
Training loss: 1.660061104235851
Validation loss: 2.2533890934233787

Epoch: 6| Step: 5
Training loss: 1.9406558760737567
Validation loss: 2.2848177622435726

Epoch: 6| Step: 6
Training loss: 1.2488077199615426
Validation loss: 2.1976183340997726

Epoch: 6| Step: 7
Training loss: 1.6287208652891378
Validation loss: 2.2515839945307783

Epoch: 6| Step: 8
Training loss: 1.5849003900702094
Validation loss: 2.287201269726959

Epoch: 6| Step: 9
Training loss: 1.940350251090913
Validation loss: 2.225023959644854

Epoch: 6| Step: 10
Training loss: 2.0432728528297046
Validation loss: 2.2516814162419

Epoch: 6| Step: 11
Training loss: 1.9992636874933523
Validation loss: 2.2457744349654685

Epoch: 6| Step: 12
Training loss: 2.6104662777589933
Validation loss: 2.2622582378787506

Epoch: 6| Step: 13
Training loss: 1.7633228653715445
Validation loss: 2.2596618297807654

Epoch: 250| Step: 0
Training loss: 1.8599035329311282
Validation loss: 2.2766439530288416

Epoch: 6| Step: 1
Training loss: 1.3848690968151902
Validation loss: 2.2272113953356336

Epoch: 6| Step: 2
Training loss: 2.4104800014588093
Validation loss: 2.2343108958738016

Epoch: 6| Step: 3
Training loss: 1.6932192769774324
Validation loss: 2.196443009376415

Epoch: 6| Step: 4
Training loss: 1.7524357601913436
Validation loss: 2.2516504521589673

Epoch: 6| Step: 5
Training loss: 1.8503973147605746
Validation loss: 2.2440123028218233

Epoch: 6| Step: 6
Training loss: 1.5982591755157738
Validation loss: 2.2194805499512507

Epoch: 6| Step: 7
Training loss: 2.429530589443212
Validation loss: 2.2444974058650318

Epoch: 6| Step: 8
Training loss: 1.991842561666536
Validation loss: 2.2398933438375

Epoch: 6| Step: 9
Training loss: 2.071168427504227
Validation loss: 2.2183331807626954

Epoch: 6| Step: 10
Training loss: 1.714190591148482
Validation loss: 2.245920857770296

Epoch: 6| Step: 11
Training loss: 1.4140005361564083
Validation loss: 2.2805178067487093

Epoch: 6| Step: 12
Training loss: 1.6966512290137352
Validation loss: 2.256545528204992

Epoch: 6| Step: 13
Training loss: 1.9113811785711772
Validation loss: 2.2725731378178593

Epoch: 251| Step: 0
Training loss: 1.440945766262285
Validation loss: 2.28855399696963

Epoch: 6| Step: 1
Training loss: 2.2205302658509427
Validation loss: 2.2613497364370634

Epoch: 6| Step: 2
Training loss: 1.998782562219644
Validation loss: 2.2546426281006346

Epoch: 6| Step: 3
Training loss: 1.2048092237593127
Validation loss: 2.2585302898715387

Epoch: 6| Step: 4
Training loss: 1.9137302655299473
Validation loss: 2.282080766660682

Epoch: 6| Step: 5
Training loss: 2.320579436389382
Validation loss: 2.2312865289919817

Epoch: 6| Step: 6
Training loss: 2.3540180350676647
Validation loss: 2.2633936376568027

Epoch: 6| Step: 7
Training loss: 2.0006120460517507
Validation loss: 2.261201020590118

Epoch: 6| Step: 8
Training loss: 1.775215501195163
Validation loss: 2.2609806513089796

Epoch: 6| Step: 9
Training loss: 1.731191032314343
Validation loss: 2.260478963646084

Epoch: 6| Step: 10
Training loss: 1.7227192216292952
Validation loss: 2.2651946261942677

Epoch: 6| Step: 11
Training loss: 1.6139915694450278
Validation loss: 2.2600127522231026

Epoch: 6| Step: 12
Training loss: 1.6935008692777176
Validation loss: 2.269739008305867

Epoch: 6| Step: 13
Training loss: 1.8002175464562864
Validation loss: 2.2316837247603867

Epoch: 252| Step: 0
Training loss: 2.171314633757515
Validation loss: 2.291028942149912

Epoch: 6| Step: 1
Training loss: 1.9576268308238924
Validation loss: 2.254430747133339

Epoch: 6| Step: 2
Training loss: 1.5783825654700245
Validation loss: 2.251067609002059

Epoch: 6| Step: 3
Training loss: 1.7107024706356568
Validation loss: 2.2590327564236663

Epoch: 6| Step: 4
Training loss: 2.4128922771085692
Validation loss: 2.2865416416570103

Epoch: 6| Step: 5
Training loss: 1.9179813050521481
Validation loss: 2.266783087691488

Epoch: 6| Step: 6
Training loss: 1.5810932157085626
Validation loss: 2.2548441179418885

Epoch: 6| Step: 7
Training loss: 1.7121010921346673
Validation loss: 2.264397236081913

Epoch: 6| Step: 8
Training loss: 1.373585233239952
Validation loss: 2.2720031058509624

Epoch: 6| Step: 9
Training loss: 1.9255247119317285
Validation loss: 2.2070125171397432

Epoch: 6| Step: 10
Training loss: 1.6266295991775548
Validation loss: 2.261197460323353

Epoch: 6| Step: 11
Training loss: 1.7310046190787511
Validation loss: 2.266161093194753

Epoch: 6| Step: 12
Training loss: 1.8374878526143374
Validation loss: 2.2549927417152733

Epoch: 6| Step: 13
Training loss: 1.8718340530120134
Validation loss: 2.2416650781543117

Epoch: 253| Step: 0
Training loss: 2.5589187532133324
Validation loss: 2.232090166808987

Epoch: 6| Step: 1
Training loss: 1.4161156349380912
Validation loss: 2.2566334531041226

Epoch: 6| Step: 2
Training loss: 1.975224219040618
Validation loss: 2.2590452742411267

Epoch: 6| Step: 3
Training loss: 1.706417715472309
Validation loss: 2.2578962693512343

Epoch: 6| Step: 4
Training loss: 1.654980514849604
Validation loss: 2.2538534639412204

Epoch: 6| Step: 5
Training loss: 1.9090307621543035
Validation loss: 2.257532619531868

Epoch: 6| Step: 6
Training loss: 2.403871624151421
Validation loss: 2.311189408148714

Epoch: 6| Step: 7
Training loss: 1.2185119983393868
Validation loss: 2.2472872839691007

Epoch: 6| Step: 8
Training loss: 1.4170844733527037
Validation loss: 2.322043433309006

Epoch: 6| Step: 9
Training loss: 1.4666622826481812
Validation loss: 2.3074885229068536

Epoch: 6| Step: 10
Training loss: 2.066565696751908
Validation loss: 2.320181903055142

Epoch: 6| Step: 11
Training loss: 1.6686651486887614
Validation loss: 2.2868682716590207

Epoch: 6| Step: 12
Training loss: 1.7877997727216965
Validation loss: 2.2548863818843423

Epoch: 6| Step: 13
Training loss: 2.282521350840122
Validation loss: 2.2677265721483373

Epoch: 254| Step: 0
Training loss: 2.766082984374571
Validation loss: 2.2413224854907554

Epoch: 6| Step: 1
Training loss: 2.1784890000698405
Validation loss: 2.24359793326961

Epoch: 6| Step: 2
Training loss: 1.7854337580903998
Validation loss: 2.22704827320877

Epoch: 6| Step: 3
Training loss: 1.2877869739886159
Validation loss: 2.1840925829561604

Epoch: 6| Step: 4
Training loss: 2.1599606637551823
Validation loss: 2.215771535207656

Epoch: 6| Step: 5
Training loss: 1.6886878601207114
Validation loss: 2.2695830354795197

Epoch: 6| Step: 6
Training loss: 1.4190856066118147
Validation loss: 2.2418008043319335

Epoch: 6| Step: 7
Training loss: 1.5470876065965822
Validation loss: 2.2365602763895236

Epoch: 6| Step: 8
Training loss: 1.762286786108237
Validation loss: 2.2689607809170256

Epoch: 6| Step: 9
Training loss: 1.674511052406994
Validation loss: 2.2103425585056535

Epoch: 6| Step: 10
Training loss: 2.0546103343325335
Validation loss: 2.2486536716238925

Epoch: 6| Step: 11
Training loss: 1.4604614624612149
Validation loss: 2.2538625708985305

Epoch: 6| Step: 12
Training loss: 1.4638758195313375
Validation loss: 2.229636425640004

Epoch: 6| Step: 13
Training loss: 2.0892601267792994
Validation loss: 2.242107866583936

Epoch: 255| Step: 0
Training loss: 1.5951487069479862
Validation loss: 2.246922075177034

Epoch: 6| Step: 1
Training loss: 1.835506697087344
Validation loss: 2.2474459094522468

Epoch: 6| Step: 2
Training loss: 1.737763677115983
Validation loss: 2.2729306721866056

Epoch: 6| Step: 3
Training loss: 2.2973997593577122
Validation loss: 2.230138749784844

Epoch: 6| Step: 4
Training loss: 1.9147363838840288
Validation loss: 2.268064999001265

Epoch: 6| Step: 5
Training loss: 1.8474996552834815
Validation loss: 2.2957903335287773

Epoch: 6| Step: 6
Training loss: 1.8065931819150698
Validation loss: 2.2315036433154654

Epoch: 6| Step: 7
Training loss: 1.5038165177166793
Validation loss: 2.288865982507468

Epoch: 6| Step: 8
Training loss: 1.6854231027575355
Validation loss: 2.2528282413048757

Epoch: 6| Step: 9
Training loss: 2.065802963831734
Validation loss: 2.2461116718363714

Epoch: 6| Step: 10
Training loss: 1.811986126895032
Validation loss: 2.2197905796423494

Epoch: 6| Step: 11
Training loss: 2.064541355582671
Validation loss: 2.2337912719139394

Epoch: 6| Step: 12
Training loss: 1.7780058245955024
Validation loss: 2.211133669267855

Epoch: 6| Step: 13
Training loss: 1.1584298489289397
Validation loss: 2.2825164055536553

Epoch: 256| Step: 0
Training loss: 2.503942242391957
Validation loss: 2.259585332068957

Epoch: 6| Step: 1
Training loss: 1.8191425017940448
Validation loss: 2.2465247224338096

Epoch: 6| Step: 2
Training loss: 1.8664963851758818
Validation loss: 2.265805507056191

Epoch: 6| Step: 3
Training loss: 1.7821176657655884
Validation loss: 2.260258725007574

Epoch: 6| Step: 4
Training loss: 1.4113470317504344
Validation loss: 2.2503838428196943

Epoch: 6| Step: 5
Training loss: 1.6358803579703687
Validation loss: 2.264266578071418

Epoch: 6| Step: 6
Training loss: 1.7660846618240311
Validation loss: 2.270883405151635

Epoch: 6| Step: 7
Training loss: 1.5325086442165305
Validation loss: 2.206255166155411

Epoch: 6| Step: 8
Training loss: 2.2162066644432565
Validation loss: 2.2656467921842975

Epoch: 6| Step: 9
Training loss: 1.41996620245458
Validation loss: 2.256707749325056

Epoch: 6| Step: 10
Training loss: 1.610748371673476
Validation loss: 2.2914282975907825

Epoch: 6| Step: 11
Training loss: 1.9041311651658568
Validation loss: 2.2519593270362654

Epoch: 6| Step: 12
Training loss: 1.359251082461489
Validation loss: 2.2410331333654194

Epoch: 6| Step: 13
Training loss: 2.280458391354889
Validation loss: 2.2560520171723373

Epoch: 257| Step: 0
Training loss: 2.104795217270965
Validation loss: 2.251320617717536

Epoch: 6| Step: 1
Training loss: 1.9254595814803672
Validation loss: 2.2561356053130557

Epoch: 6| Step: 2
Training loss: 1.6353749150415609
Validation loss: 2.211695702648094

Epoch: 6| Step: 3
Training loss: 1.8609721272639654
Validation loss: 2.276439761933886

Epoch: 6| Step: 4
Training loss: 1.2409513068409725
Validation loss: 2.2522066523240754

Epoch: 6| Step: 5
Training loss: 2.2088154560400812
Validation loss: 2.2759248673468453

Epoch: 6| Step: 6
Training loss: 1.617611004942711
Validation loss: 2.2392750260027987

Epoch: 6| Step: 7
Training loss: 2.0263005919026718
Validation loss: 2.2412395190489454

Epoch: 6| Step: 8
Training loss: 1.8209234039352857
Validation loss: 2.233666309672693

Epoch: 6| Step: 9
Training loss: 1.7360253257749951
Validation loss: 2.218824730526962

Epoch: 6| Step: 10
Training loss: 1.7276596794912036
Validation loss: 2.2840244516296857

Epoch: 6| Step: 11
Training loss: 1.6932599699593383
Validation loss: 2.298457004014336

Epoch: 6| Step: 12
Training loss: 1.6167053388446906
Validation loss: 2.2985180130816465

Epoch: 6| Step: 13
Training loss: 2.0848812329246984
Validation loss: 2.233585535729514

Epoch: 258| Step: 0
Training loss: 1.5509351370534243
Validation loss: 2.2174594585893477

Epoch: 6| Step: 1
Training loss: 2.1683701152257204
Validation loss: 2.2202579897307992

Epoch: 6| Step: 2
Training loss: 1.194516983096722
Validation loss: 2.2295069909606964

Epoch: 6| Step: 3
Training loss: 2.0170591708020975
Validation loss: 2.2203848357788343

Epoch: 6| Step: 4
Training loss: 1.4947613791699192
Validation loss: 2.2507304529269416

Epoch: 6| Step: 5
Training loss: 1.5770249262299056
Validation loss: 2.29737804407619

Epoch: 6| Step: 6
Training loss: 2.236512342303389
Validation loss: 2.2902675313976237

Epoch: 6| Step: 7
Training loss: 2.0515797831496627
Validation loss: 2.236537420195566

Epoch: 6| Step: 8
Training loss: 2.2597761755641774
Validation loss: 2.273232638580732

Epoch: 6| Step: 9
Training loss: 1.4249533561969796
Validation loss: 2.2599460731377317

Epoch: 6| Step: 10
Training loss: 1.6573865337860956
Validation loss: 2.248084797068085

Epoch: 6| Step: 11
Training loss: 1.8683723297722783
Validation loss: 2.2237747515074866

Epoch: 6| Step: 12
Training loss: 1.746560667961499
Validation loss: 2.265625004526152

Epoch: 6| Step: 13
Training loss: 1.4393405740905336
Validation loss: 2.248415338793446

Epoch: 259| Step: 0
Training loss: 1.6996505714777117
Validation loss: 2.2437066923535625

Epoch: 6| Step: 1
Training loss: 1.667057547827109
Validation loss: 2.186156161008465

Epoch: 6| Step: 2
Training loss: 2.861952990110519
Validation loss: 2.205416968859789

Epoch: 6| Step: 3
Training loss: 1.482095192357834
Validation loss: 2.25933812802529

Epoch: 6| Step: 4
Training loss: 1.2690034678917552
Validation loss: 2.2591183410274733

Epoch: 6| Step: 5
Training loss: 1.591912500593515
Validation loss: 2.261188421455153

Epoch: 6| Step: 6
Training loss: 1.6442274234306968
Validation loss: 2.2466680519255773

Epoch: 6| Step: 7
Training loss: 1.742526444791332
Validation loss: 2.224625747091611

Epoch: 6| Step: 8
Training loss: 1.4975951308154969
Validation loss: 2.2578863236952227

Epoch: 6| Step: 9
Training loss: 1.5954871340824353
Validation loss: 2.19388363179966

Epoch: 6| Step: 10
Training loss: 2.1595596124149883
Validation loss: 2.279825266597669

Epoch: 6| Step: 11
Training loss: 1.8584102403723985
Validation loss: 2.258518920757142

Epoch: 6| Step: 12
Training loss: 1.7335967646224915
Validation loss: 2.1973122976580557

Epoch: 6| Step: 13
Training loss: 1.4172516998587665
Validation loss: 2.294682613651924

Epoch: 260| Step: 0
Training loss: 1.7673859043876288
Validation loss: 2.2682514953663326

Epoch: 6| Step: 1
Training loss: 1.5347472755071154
Validation loss: 2.2690795473778795

Epoch: 6| Step: 2
Training loss: 2.195872388150993
Validation loss: 2.2964217142112715

Epoch: 6| Step: 3
Training loss: 2.042545077738135
Validation loss: 2.24936928106896

Epoch: 6| Step: 4
Training loss: 1.513106623289444
Validation loss: 2.2291899461271485

Epoch: 6| Step: 5
Training loss: 2.0012015071523916
Validation loss: 2.2792160456110313

Epoch: 6| Step: 6
Training loss: 1.9813886383359296
Validation loss: 2.2018679026758323

Epoch: 6| Step: 7
Training loss: 1.9008350695521703
Validation loss: 2.2328938799193887

Epoch: 6| Step: 8
Training loss: 1.9908141544845221
Validation loss: 2.2380767335398537

Epoch: 6| Step: 9
Training loss: 1.4312044028136082
Validation loss: 2.2465225593669556

Epoch: 6| Step: 10
Training loss: 1.8509334992715394
Validation loss: 2.258358207843844

Epoch: 6| Step: 11
Training loss: 1.269956265244656
Validation loss: 2.243169485402549

Epoch: 6| Step: 12
Training loss: 1.7629363933347026
Validation loss: 2.2713815182274137

Epoch: 6| Step: 13
Training loss: 1.2429778265966327
Validation loss: 2.2418594694939706

Epoch: 261| Step: 0
Training loss: 1.427125981197135
Validation loss: 2.240507056600509

Epoch: 6| Step: 1
Training loss: 1.5489504983477642
Validation loss: 2.223357294885687

Epoch: 6| Step: 2
Training loss: 2.2603337028033192
Validation loss: 2.2444132272288333

Epoch: 6| Step: 3
Training loss: 1.7483042266478666
Validation loss: 2.2556032940768382

Epoch: 6| Step: 4
Training loss: 1.7700612198754408
Validation loss: 2.225094445212684

Epoch: 6| Step: 5
Training loss: 1.7472028857914703
Validation loss: 2.2461023114555303

Epoch: 6| Step: 6
Training loss: 1.6747379923627919
Validation loss: 2.2588322712399203

Epoch: 6| Step: 7
Training loss: 2.3210992474717167
Validation loss: 2.251041885526828

Epoch: 6| Step: 8
Training loss: 2.2989804744878577
Validation loss: 2.2576697712807885

Epoch: 6| Step: 9
Training loss: 1.3400960078647741
Validation loss: 2.2216804652419473

Epoch: 6| Step: 10
Training loss: 1.4054897372516726
Validation loss: 2.2353481700784763

Epoch: 6| Step: 11
Training loss: 1.5315626175621002
Validation loss: 2.265580437334765

Epoch: 6| Step: 12
Training loss: 1.8726825379653884
Validation loss: 2.242466314153354

Epoch: 6| Step: 13
Training loss: 1.5747508623987123
Validation loss: 2.2261957580046374

Epoch: 262| Step: 0
Training loss: 2.2921276206924026
Validation loss: 2.2428577049302665

Epoch: 6| Step: 1
Training loss: 1.5502662860646683
Validation loss: 2.230722446738998

Epoch: 6| Step: 2
Training loss: 1.515868649119394
Validation loss: 2.2571856717249315

Epoch: 6| Step: 3
Training loss: 1.9833745161423646
Validation loss: 2.2299985574465353

Epoch: 6| Step: 4
Training loss: 1.8347473182601448
Validation loss: 2.231895608032445

Epoch: 6| Step: 5
Training loss: 1.9582171777677178
Validation loss: 2.215598319070164

Epoch: 6| Step: 6
Training loss: 2.1279743919911187
Validation loss: 2.2331833183248833

Epoch: 6| Step: 7
Training loss: 1.4697319157398356
Validation loss: 2.258422343407049

Epoch: 6| Step: 8
Training loss: 1.6072931249698033
Validation loss: 2.2422890983317187

Epoch: 6| Step: 9
Training loss: 2.204206485304496
Validation loss: 2.222252022144344

Epoch: 6| Step: 10
Training loss: 1.681010873799099
Validation loss: 2.2642319438610543

Epoch: 6| Step: 11
Training loss: 1.2371253265229336
Validation loss: 2.2568103922328704

Epoch: 6| Step: 12
Training loss: 1.6705134186192907
Validation loss: 2.2626359559589444

Epoch: 6| Step: 13
Training loss: 1.0666772966053903
Validation loss: 2.220748791371344

Epoch: 263| Step: 0
Training loss: 1.7118711667472315
Validation loss: 2.2623244785466796

Epoch: 6| Step: 1
Training loss: 1.9864890184384576
Validation loss: 2.231661625050559

Epoch: 6| Step: 2
Training loss: 2.0050169485997777
Validation loss: 2.2843004521371966

Epoch: 6| Step: 3
Training loss: 1.9875967949862712
Validation loss: 2.251603634626987

Epoch: 6| Step: 4
Training loss: 1.7295787580676651
Validation loss: 2.2598276842994665

Epoch: 6| Step: 5
Training loss: 1.5474885436636956
Validation loss: 2.3025512071378422

Epoch: 6| Step: 6
Training loss: 1.5625756817608767
Validation loss: 2.2694449623403767

Epoch: 6| Step: 7
Training loss: 1.7835266555150269
Validation loss: 2.306187542298792

Epoch: 6| Step: 8
Training loss: 1.3989280820498096
Validation loss: 2.291338202540359

Epoch: 6| Step: 9
Training loss: 1.8123389863152972
Validation loss: 2.273755748899609

Epoch: 6| Step: 10
Training loss: 1.4358866386828555
Validation loss: 2.22591951848288

Epoch: 6| Step: 11
Training loss: 2.793919114833705
Validation loss: 2.2885426532253836

Epoch: 6| Step: 12
Training loss: 1.2756786634567037
Validation loss: 2.2481625744211073

Epoch: 6| Step: 13
Training loss: 1.2880670113724004
Validation loss: 2.273565971731636

Epoch: 264| Step: 0
Training loss: 1.6441530349999023
Validation loss: 2.235896243159513

Epoch: 6| Step: 1
Training loss: 1.495821776208178
Validation loss: 2.2181342317735466

Epoch: 6| Step: 2
Training loss: 2.1789354784001205
Validation loss: 2.210412139608044

Epoch: 6| Step: 3
Training loss: 1.5049163992845083
Validation loss: 2.2208808720068145

Epoch: 6| Step: 4
Training loss: 1.478573917665881
Validation loss: 2.2534894808324335

Epoch: 6| Step: 5
Training loss: 1.8862385583003465
Validation loss: 2.2506171557094765

Epoch: 6| Step: 6
Training loss: 1.7685509128203782
Validation loss: 2.309118910430393

Epoch: 6| Step: 7
Training loss: 1.7133000753319088
Validation loss: 2.2452928841821334

Epoch: 6| Step: 8
Training loss: 2.6077764491474396
Validation loss: 2.267859180318995

Epoch: 6| Step: 9
Training loss: 1.130093593603625
Validation loss: 2.25181011483013

Epoch: 6| Step: 10
Training loss: 1.2457400211529386
Validation loss: 2.2455147253785093

Epoch: 6| Step: 11
Training loss: 2.2303327796231054
Validation loss: 2.253066255820497

Epoch: 6| Step: 12
Training loss: 2.010742780362042
Validation loss: 2.2434972763727137

Epoch: 6| Step: 13
Training loss: 1.079394270609475
Validation loss: 2.1781615997886727

Epoch: 265| Step: 0
Training loss: 2.5421598820982725
Validation loss: 2.266256955008532

Epoch: 6| Step: 1
Training loss: 1.190712198183206
Validation loss: 2.2166341143905757

Epoch: 6| Step: 2
Training loss: 2.030925900939323
Validation loss: 2.231078181561358

Epoch: 6| Step: 3
Training loss: 1.9225380846872069
Validation loss: 2.2526307120043283

Epoch: 6| Step: 4
Training loss: 1.5021996264824309
Validation loss: 2.2316901364841866

Epoch: 6| Step: 5
Training loss: 1.6583662368475025
Validation loss: 2.2190407067581526

Epoch: 6| Step: 6
Training loss: 1.3141638790400194
Validation loss: 2.267173891104471

Epoch: 6| Step: 7
Training loss: 2.0489539152355363
Validation loss: 2.200217134028052

Epoch: 6| Step: 8
Training loss: 1.3658091108925712
Validation loss: 2.2196949355255424

Epoch: 6| Step: 9
Training loss: 2.191035438212697
Validation loss: 2.194508648532802

Epoch: 6| Step: 10
Training loss: 1.627428294534453
Validation loss: 2.2425432635061244

Epoch: 6| Step: 11
Training loss: 1.5510679503656863
Validation loss: 2.255025609614532

Epoch: 6| Step: 12
Training loss: 1.4347538632628187
Validation loss: 2.209731400864648

Epoch: 6| Step: 13
Training loss: 1.4041347701905154
Validation loss: 2.22825086763612

Epoch: 266| Step: 0
Training loss: 1.7569294385641974
Validation loss: 2.270952016350608

Epoch: 6| Step: 1
Training loss: 2.207670244195109
Validation loss: 2.2339871493955448

Epoch: 6| Step: 2
Training loss: 1.6357636863092786
Validation loss: 2.2363241921165624

Epoch: 6| Step: 3
Training loss: 2.3345417458500193
Validation loss: 2.2056961858098534

Epoch: 6| Step: 4
Training loss: 1.596063766907409
Validation loss: 2.220796049270242

Epoch: 6| Step: 5
Training loss: 1.122816456915967
Validation loss: 2.2028307456772565

Epoch: 6| Step: 6
Training loss: 2.214086655489703
Validation loss: 2.255999859162379

Epoch: 6| Step: 7
Training loss: 1.0880539940941953
Validation loss: 2.2022914596922374

Epoch: 6| Step: 8
Training loss: 2.1485173990824826
Validation loss: 2.2541821163234053

Epoch: 6| Step: 9
Training loss: 1.4341683964088083
Validation loss: 2.2213709335945584

Epoch: 6| Step: 10
Training loss: 1.5195569033774052
Validation loss: 2.236530281312391

Epoch: 6| Step: 11
Training loss: 1.594298474050305
Validation loss: 2.2391880492620615

Epoch: 6| Step: 12
Training loss: 1.6826592704128773
Validation loss: 2.191239828618424

Epoch: 6| Step: 13
Training loss: 1.7066705877040484
Validation loss: 2.2041142626005437

Epoch: 267| Step: 0
Training loss: 1.3777572556389235
Validation loss: 2.252601690585594

Epoch: 6| Step: 1
Training loss: 1.7715223280974344
Validation loss: 2.2301519315567364

Epoch: 6| Step: 2
Training loss: 2.504086682845436
Validation loss: 2.1932504044442296

Epoch: 6| Step: 3
Training loss: 1.4072578209629019
Validation loss: 2.2302447064039996

Epoch: 6| Step: 4
Training loss: 1.7024570520168172
Validation loss: 2.239048979405054

Epoch: 6| Step: 5
Training loss: 1.4247749016977427
Validation loss: 2.2067285589873396

Epoch: 6| Step: 6
Training loss: 1.816109319228115
Validation loss: 2.197772544805518

Epoch: 6| Step: 7
Training loss: 1.4247050364879963
Validation loss: 2.211199435436059

Epoch: 6| Step: 8
Training loss: 1.7331428618805491
Validation loss: 2.1950947993672254

Epoch: 6| Step: 9
Training loss: 1.380169600417111
Validation loss: 2.1930884920114746

Epoch: 6| Step: 10
Training loss: 2.2071866951273553
Validation loss: 2.2321690188748415

Epoch: 6| Step: 11
Training loss: 1.5660468471627995
Validation loss: 2.227656013484447

Epoch: 6| Step: 12
Training loss: 1.6099027490565005
Validation loss: 2.2076802482770557

Epoch: 6| Step: 13
Training loss: 1.872237204533569
Validation loss: 2.1959282817892927

Epoch: 268| Step: 0
Training loss: 1.654865189792425
Validation loss: 2.221401421881101

Epoch: 6| Step: 1
Training loss: 1.5594921916583955
Validation loss: 2.2246103856548824

Epoch: 6| Step: 2
Training loss: 1.590843767212185
Validation loss: 2.2051374067283893

Epoch: 6| Step: 3
Training loss: 1.3797422041799774
Validation loss: 2.2736575101205987

Epoch: 6| Step: 4
Training loss: 1.354022394955811
Validation loss: 2.2257679697339112

Epoch: 6| Step: 5
Training loss: 1.6254643730406064
Validation loss: 2.250682837716977

Epoch: 6| Step: 6
Training loss: 1.696160311032013
Validation loss: 2.2606475751455117

Epoch: 6| Step: 7
Training loss: 1.7721428535822974
Validation loss: 2.2737391645643537

Epoch: 6| Step: 8
Training loss: 2.322509444826301
Validation loss: 2.2607341390494073

Epoch: 6| Step: 9
Training loss: 1.5136043804256532
Validation loss: 2.2586327773119157

Epoch: 6| Step: 10
Training loss: 2.2472457983003364
Validation loss: 2.2459009676500687

Epoch: 6| Step: 11
Training loss: 2.0918661724049064
Validation loss: 2.2323229357833183

Epoch: 6| Step: 12
Training loss: 1.3629928327499325
Validation loss: 2.260315792788701

Epoch: 6| Step: 13
Training loss: 1.803017640512569
Validation loss: 2.2402487859130034

Epoch: 269| Step: 0
Training loss: 1.6057640973487446
Validation loss: 2.2068457485295876

Epoch: 6| Step: 1
Training loss: 1.5664700235907323
Validation loss: 2.2004409360983077

Epoch: 6| Step: 2
Training loss: 1.3818316240546635
Validation loss: 2.2103183792179495

Epoch: 6| Step: 3
Training loss: 1.7285278319881463
Validation loss: 2.219980370437441

Epoch: 6| Step: 4
Training loss: 1.4115544623077905
Validation loss: 2.259233573315948

Epoch: 6| Step: 5
Training loss: 1.5155255786495376
Validation loss: 2.2560152415228933

Epoch: 6| Step: 6
Training loss: 1.8041770840785312
Validation loss: 2.2263767126780163

Epoch: 6| Step: 7
Training loss: 1.7892532580096698
Validation loss: 2.2535002746543276

Epoch: 6| Step: 8
Training loss: 2.037004038354001
Validation loss: 2.308858977231699

Epoch: 6| Step: 9
Training loss: 1.5718542473031698
Validation loss: 2.2590244113626308

Epoch: 6| Step: 10
Training loss: 2.483123368042593
Validation loss: 2.2813761517926414

Epoch: 6| Step: 11
Training loss: 1.167579611569604
Validation loss: 2.2430751547433427

Epoch: 6| Step: 12
Training loss: 2.192487861138628
Validation loss: 2.234560931720864

Epoch: 6| Step: 13
Training loss: 1.4715707355105994
Validation loss: 2.2350372249844104

Epoch: 270| Step: 0
Training loss: 1.3906353296474894
Validation loss: 2.168766478115112

Epoch: 6| Step: 1
Training loss: 0.9669046361187335
Validation loss: 2.2104258507459136

Epoch: 6| Step: 2
Training loss: 1.5221102679556964
Validation loss: 2.165387221539976

Epoch: 6| Step: 3
Training loss: 1.876852455575395
Validation loss: 2.2246743002886284

Epoch: 6| Step: 4
Training loss: 2.1710398872889707
Validation loss: 2.2152589523568724

Epoch: 6| Step: 5
Training loss: 1.8613816020444507
Validation loss: 2.225975030218595

Epoch: 6| Step: 6
Training loss: 2.1626981434975376
Validation loss: 2.2558313241667203

Epoch: 6| Step: 7
Training loss: 1.7904587673498533
Validation loss: 2.2422060064434093

Epoch: 6| Step: 8
Training loss: 1.6808303139009655
Validation loss: 2.193985294755552

Epoch: 6| Step: 9
Training loss: 1.6843328778550462
Validation loss: 2.2038697446007913

Epoch: 6| Step: 10
Training loss: 1.5064624810622216
Validation loss: 2.205023999137865

Epoch: 6| Step: 11
Training loss: 1.5708260526749775
Validation loss: 2.2187084175036653

Epoch: 6| Step: 12
Training loss: 1.7301118710900796
Validation loss: 2.2322775308792324

Epoch: 6| Step: 13
Training loss: 1.8274279838806622
Validation loss: 2.183810941326204

Epoch: 271| Step: 0
Training loss: 1.9465817519941604
Validation loss: 2.1979072168968705

Epoch: 6| Step: 1
Training loss: 1.4727247308244615
Validation loss: 2.2299975682022826

Epoch: 6| Step: 2
Training loss: 1.712753655797943
Validation loss: 2.2135993966398737

Epoch: 6| Step: 3
Training loss: 1.7657345087980534
Validation loss: 2.18183444991212

Epoch: 6| Step: 4
Training loss: 1.8170237158244271
Validation loss: 2.2399996516268468

Epoch: 6| Step: 5
Training loss: 1.484762201503469
Validation loss: 2.2205025584170883

Epoch: 6| Step: 6
Training loss: 1.495405073499166
Validation loss: 2.205514325079774

Epoch: 6| Step: 7
Training loss: 1.992254757213334
Validation loss: 2.170662461867358

Epoch: 6| Step: 8
Training loss: 1.3191852158772333
Validation loss: 2.187797178131318

Epoch: 6| Step: 9
Training loss: 1.8501455301316208
Validation loss: 2.287970615433624

Epoch: 6| Step: 10
Training loss: 2.4924763957506246
Validation loss: 2.23673040842511

Epoch: 6| Step: 11
Training loss: 1.3660413897263268
Validation loss: 2.225096168251045

Epoch: 6| Step: 12
Training loss: 1.601633209900568
Validation loss: 2.1994402449740247

Epoch: 6| Step: 13
Training loss: 1.8928187230162015
Validation loss: 2.1821270823184538

Epoch: 272| Step: 0
Training loss: 1.541033803931708
Validation loss: 2.234870938789451

Epoch: 6| Step: 1
Training loss: 1.4188232369362606
Validation loss: 2.210007934815912

Epoch: 6| Step: 2
Training loss: 1.7012803473418086
Validation loss: 2.243208867053278

Epoch: 6| Step: 3
Training loss: 2.0490950564168404
Validation loss: 2.2241026817654608

Epoch: 6| Step: 4
Training loss: 2.1659852447993444
Validation loss: 2.2443218479499207

Epoch: 6| Step: 5
Training loss: 1.7001163611138221
Validation loss: 2.2318957935375128

Epoch: 6| Step: 6
Training loss: 1.4782004177862462
Validation loss: 2.2239532270836637

Epoch: 6| Step: 7
Training loss: 1.5284650740147483
Validation loss: 2.1847059474463593

Epoch: 6| Step: 8
Training loss: 1.408694241155618
Validation loss: 2.222958619721672

Epoch: 6| Step: 9
Training loss: 2.3076485959828252
Validation loss: 2.2094709627984286

Epoch: 6| Step: 10
Training loss: 1.895789163375357
Validation loss: 2.187110648245968

Epoch: 6| Step: 11
Training loss: 1.383503498771939
Validation loss: 2.2180012594022473

Epoch: 6| Step: 12
Training loss: 1.217346752947919
Validation loss: 2.2075014923642153

Epoch: 6| Step: 13
Training loss: 1.7744798999721787
Validation loss: 2.2284124392435833

Epoch: 273| Step: 0
Training loss: 1.513082751409491
Validation loss: 2.266819351628645

Epoch: 6| Step: 1
Training loss: 1.4179640420462476
Validation loss: 2.183356788726567

Epoch: 6| Step: 2
Training loss: 2.0617006082087146
Validation loss: 2.207976261493718

Epoch: 6| Step: 3
Training loss: 1.4040309776301303
Validation loss: 2.1747050184198566

Epoch: 6| Step: 4
Training loss: 1.9741365525071832
Validation loss: 2.2513971787572986

Epoch: 6| Step: 5
Training loss: 1.3859963698071256
Validation loss: 2.2124766797736495

Epoch: 6| Step: 6
Training loss: 1.65835739514452
Validation loss: 2.202271039328563

Epoch: 6| Step: 7
Training loss: 1.8973498584316302
Validation loss: 2.1636176802182616

Epoch: 6| Step: 8
Training loss: 2.586673044200127
Validation loss: 2.218381705272117

Epoch: 6| Step: 9
Training loss: 1.2099735976719879
Validation loss: 2.247504007500457

Epoch: 6| Step: 10
Training loss: 1.6615294039681796
Validation loss: 2.22556879724093

Epoch: 6| Step: 11
Training loss: 1.5684716361451116
Validation loss: 2.203261069915662

Epoch: 6| Step: 12
Training loss: 1.0923279918853972
Validation loss: 2.2183964025956295

Epoch: 6| Step: 13
Training loss: 1.6413192733241981
Validation loss: 2.254530975018683

Epoch: 274| Step: 0
Training loss: 1.0529427118757162
Validation loss: 2.220091182595508

Epoch: 6| Step: 1
Training loss: 1.6687140843101824
Validation loss: 2.2185740628608985

Epoch: 6| Step: 2
Training loss: 1.4287839441947976
Validation loss: 2.2689324293672355

Epoch: 6| Step: 3
Training loss: 1.4980381215621865
Validation loss: 2.2075301393188247

Epoch: 6| Step: 4
Training loss: 1.930599846396642
Validation loss: 2.248872130173721

Epoch: 6| Step: 5
Training loss: 1.864043201944585
Validation loss: 2.231866744864204

Epoch: 6| Step: 6
Training loss: 1.2711435262526833
Validation loss: 2.220490455428096

Epoch: 6| Step: 7
Training loss: 1.7585629366018567
Validation loss: 2.218679701693661

Epoch: 6| Step: 8
Training loss: 1.796268792103879
Validation loss: 2.202478019851719

Epoch: 6| Step: 9
Training loss: 1.307390257422024
Validation loss: 2.2106409010537824

Epoch: 6| Step: 10
Training loss: 1.9360841069040229
Validation loss: 2.2307152452876986

Epoch: 6| Step: 11
Training loss: 1.6033339217430087
Validation loss: 2.238152093047048

Epoch: 6| Step: 12
Training loss: 2.20776290243908
Validation loss: 2.2473548993134913

Epoch: 6| Step: 13
Training loss: 1.7937992474644027
Validation loss: 2.186154729177429

Epoch: 275| Step: 0
Training loss: 1.884326247158703
Validation loss: 2.2246474891628667

Epoch: 6| Step: 1
Training loss: 1.718219189606703
Validation loss: 2.211697369474973

Epoch: 6| Step: 2
Training loss: 1.7195069466883444
Validation loss: 2.2317346665263855

Epoch: 6| Step: 3
Training loss: 1.4050321179584515
Validation loss: 2.226105140699601

Epoch: 6| Step: 4
Training loss: 1.9484504607502975
Validation loss: 2.2304859411062274

Epoch: 6| Step: 5
Training loss: 1.7506549154692481
Validation loss: 2.2498896525041645

Epoch: 6| Step: 6
Training loss: 1.4120439485242968
Validation loss: 2.1969038318947667

Epoch: 6| Step: 7
Training loss: 1.9192930416097311
Validation loss: 2.235140189208451

Epoch: 6| Step: 8
Training loss: 2.250175893054278
Validation loss: 2.190153285397276

Epoch: 6| Step: 9
Training loss: 1.4975289813566386
Validation loss: 2.1816202557633257

Epoch: 6| Step: 10
Training loss: 1.5753398528597113
Validation loss: 2.2277178935975357

Epoch: 6| Step: 11
Training loss: 1.2762261497368783
Validation loss: 2.22218209304348

Epoch: 6| Step: 12
Training loss: 1.2934664318741063
Validation loss: 2.189847762134345

Epoch: 6| Step: 13
Training loss: 1.840526219358175
Validation loss: 2.2302058636999487

Epoch: 276| Step: 0
Training loss: 1.6366282872803826
Validation loss: 2.19761419399544

Epoch: 6| Step: 1
Training loss: 1.3764697802489965
Validation loss: 2.2202643120565733

Epoch: 6| Step: 2
Training loss: 1.5940605309838236
Validation loss: 2.2001219207600378

Epoch: 6| Step: 3
Training loss: 1.4342596601932531
Validation loss: 2.2461814551508903

Epoch: 6| Step: 4
Training loss: 1.3011171291060846
Validation loss: 2.207588186948671

Epoch: 6| Step: 5
Training loss: 1.6344359873375591
Validation loss: 2.2347608199186935

Epoch: 6| Step: 6
Training loss: 1.9074416891362194
Validation loss: 2.2164232948348155

Epoch: 6| Step: 7
Training loss: 1.2857912112490002
Validation loss: 2.2339870220160662

Epoch: 6| Step: 8
Training loss: 2.506763084194101
Validation loss: 2.234043720658325

Epoch: 6| Step: 9
Training loss: 1.4768955722946775
Validation loss: 2.2038230386527053

Epoch: 6| Step: 10
Training loss: 1.5924321878508492
Validation loss: 2.2290057648566757

Epoch: 6| Step: 11
Training loss: 1.9180898220283251
Validation loss: 2.2182427652218006

Epoch: 6| Step: 12
Training loss: 1.3924934607579973
Validation loss: 2.2024431106472084

Epoch: 6| Step: 13
Training loss: 2.0783017879234458
Validation loss: 2.2205437390271086

Epoch: 277| Step: 0
Training loss: 0.9899823170826293
Validation loss: 2.20688373153613

Epoch: 6| Step: 1
Training loss: 1.5995936503586465
Validation loss: 2.215645437477408

Epoch: 6| Step: 2
Training loss: 1.6339543926453006
Validation loss: 2.221108465781606

Epoch: 6| Step: 3
Training loss: 1.7916497591980414
Validation loss: 2.2120392742545616

Epoch: 6| Step: 4
Training loss: 1.469332721447572
Validation loss: 2.2246657272398664

Epoch: 6| Step: 5
Training loss: 2.052200959476477
Validation loss: 2.2104660175578488

Epoch: 6| Step: 6
Training loss: 1.1878386566726513
Validation loss: 2.227346819055012

Epoch: 6| Step: 7
Training loss: 1.609558539433721
Validation loss: 2.2235688333413672

Epoch: 6| Step: 8
Training loss: 2.547789427064302
Validation loss: 2.288265239645688

Epoch: 6| Step: 9
Training loss: 1.4974399018368107
Validation loss: 2.2789749970015247

Epoch: 6| Step: 10
Training loss: 1.7896911316254134
Validation loss: 2.2304845578460126

Epoch: 6| Step: 11
Training loss: 1.383290052119859
Validation loss: 2.2404363047169733

Epoch: 6| Step: 12
Training loss: 1.830059234619354
Validation loss: 2.2082380211156076

Epoch: 6| Step: 13
Training loss: 1.2928567244296463
Validation loss: 2.209930214816454

Epoch: 278| Step: 0
Training loss: 1.3839517846336091
Validation loss: 2.2563048118060336

Epoch: 6| Step: 1
Training loss: 1.7052866665094686
Validation loss: 2.2065098579237667

Epoch: 6| Step: 2
Training loss: 1.6440118617351516
Validation loss: 2.211073835242201

Epoch: 6| Step: 3
Training loss: 1.8029794247469357
Validation loss: 2.177568863050762

Epoch: 6| Step: 4
Training loss: 1.5625673661014896
Validation loss: 2.2114008515773618

Epoch: 6| Step: 5
Training loss: 1.7568493726470025
Validation loss: 2.1803128448124234

Epoch: 6| Step: 6
Training loss: 1.2565686253585977
Validation loss: 2.198149389175825

Epoch: 6| Step: 7
Training loss: 1.2968473776208131
Validation loss: 2.2137099804425913

Epoch: 6| Step: 8
Training loss: 1.5031573127556774
Validation loss: 2.215989955608682

Epoch: 6| Step: 9
Training loss: 2.5200911025579313
Validation loss: 2.242866843390134

Epoch: 6| Step: 10
Training loss: 1.6458889754663792
Validation loss: 2.2498510578039115

Epoch: 6| Step: 11
Training loss: 1.462251775820393
Validation loss: 2.213621960992675

Epoch: 6| Step: 12
Training loss: 1.5394240985680572
Validation loss: 2.2057644885695726

Epoch: 6| Step: 13
Training loss: 1.7686832240140034
Validation loss: 2.213579156450765

Epoch: 279| Step: 0
Training loss: 1.403771059280818
Validation loss: 2.193711808801873

Epoch: 6| Step: 1
Training loss: 1.931964349571792
Validation loss: 2.209463224769903

Epoch: 6| Step: 2
Training loss: 1.7089457305898623
Validation loss: 2.281546103330817

Epoch: 6| Step: 3
Training loss: 1.5282107962957987
Validation loss: 2.141851084967008

Epoch: 6| Step: 4
Training loss: 1.640318487690226
Validation loss: 2.207306538033846

Epoch: 6| Step: 5
Training loss: 2.3838967779906106
Validation loss: 2.2560969458775273

Epoch: 6| Step: 6
Training loss: 1.5397448890726324
Validation loss: 2.1979421963939414

Epoch: 6| Step: 7
Training loss: 1.5291330924579696
Validation loss: 2.248870493180118

Epoch: 6| Step: 8
Training loss: 1.2846137295984215
Validation loss: 2.1965280763529247

Epoch: 6| Step: 9
Training loss: 1.8149261022399223
Validation loss: 2.244843468216966

Epoch: 6| Step: 10
Training loss: 1.8798073493376335
Validation loss: 2.138388441162173

Epoch: 6| Step: 11
Training loss: 1.666338586305378
Validation loss: 2.1903920781049644

Epoch: 6| Step: 12
Training loss: 1.3461378748962847
Validation loss: 2.2131192194499634

Epoch: 6| Step: 13
Training loss: 1.5472802296069368
Validation loss: 2.1838979318969343

Epoch: 280| Step: 0
Training loss: 1.1387882336794173
Validation loss: 2.18270879806814

Epoch: 6| Step: 1
Training loss: 1.279327531985961
Validation loss: 2.204579647725041

Epoch: 6| Step: 2
Training loss: 1.0991613854336097
Validation loss: 2.1904466170178476

Epoch: 6| Step: 3
Training loss: 1.5497082281832213
Validation loss: 2.2303140568405038

Epoch: 6| Step: 4
Training loss: 1.7214871199871395
Validation loss: 2.1431510792548285

Epoch: 6| Step: 5
Training loss: 1.7499040849831242
Validation loss: 2.13996983409218

Epoch: 6| Step: 6
Training loss: 1.6110300239166293
Validation loss: 2.213705648661435

Epoch: 6| Step: 7
Training loss: 1.4512766085344895
Validation loss: 2.231293692120374

Epoch: 6| Step: 8
Training loss: 2.3681835936694595
Validation loss: 2.2912396753792823

Epoch: 6| Step: 9
Training loss: 1.6871597512159442
Validation loss: 2.185786795794564

Epoch: 6| Step: 10
Training loss: 1.7489290366370673
Validation loss: 2.20650165522462

Epoch: 6| Step: 11
Training loss: 2.3303674740450084
Validation loss: 2.2155296032192795

Epoch: 6| Step: 12
Training loss: 1.6681641368198232
Validation loss: 2.201331763354826

Epoch: 6| Step: 13
Training loss: 0.7777823739445836
Validation loss: 2.2237032395581258

Epoch: 281| Step: 0
Training loss: 1.8144501685045544
Validation loss: 2.1840612757150497

Epoch: 6| Step: 1
Training loss: 1.2214504548313811
Validation loss: 2.2764308010428373

Epoch: 6| Step: 2
Training loss: 1.6461740294054914
Validation loss: 2.1992777840138724

Epoch: 6| Step: 3
Training loss: 1.5818478324905432
Validation loss: 2.2273471879453655

Epoch: 6| Step: 4
Training loss: 1.9515061650570975
Validation loss: 2.2007109787358567

Epoch: 6| Step: 5
Training loss: 2.095988656792268
Validation loss: 2.191586768490154

Epoch: 6| Step: 6
Training loss: 1.6175065025422932
Validation loss: 2.164429114054952

Epoch: 6| Step: 7
Training loss: 1.4710738283531444
Validation loss: 2.2011861182956154

Epoch: 6| Step: 8
Training loss: 1.684154585251219
Validation loss: 2.2714530651976417

Epoch: 6| Step: 9
Training loss: 1.4475069449724267
Validation loss: 2.1643739325700744

Epoch: 6| Step: 10
Training loss: 1.6996717528791847
Validation loss: 2.235361177773598

Epoch: 6| Step: 11
Training loss: 1.6968607359228687
Validation loss: 2.2274475462964762

Epoch: 6| Step: 12
Training loss: 1.2606103711468575
Validation loss: 2.217794221427637

Epoch: 6| Step: 13
Training loss: 1.27377993420288
Validation loss: 2.2567885272174655

Epoch: 282| Step: 0
Training loss: 1.8002625088537232
Validation loss: 2.1887314970337584

Epoch: 6| Step: 1
Training loss: 1.8450144941386077
Validation loss: 2.2485524663303074

Epoch: 6| Step: 2
Training loss: 1.6715545347162675
Validation loss: 2.1635084268091913

Epoch: 6| Step: 3
Training loss: 1.834540692048353
Validation loss: 2.2236177733608176

Epoch: 6| Step: 4
Training loss: 1.5460208885291797
Validation loss: 2.2456411094468205

Epoch: 6| Step: 5
Training loss: 1.3718935380869266
Validation loss: 2.2484526093053043

Epoch: 6| Step: 6
Training loss: 2.256415756772969
Validation loss: 2.2048015296935892

Epoch: 6| Step: 7
Training loss: 1.4008292943626572
Validation loss: 2.2250782407522

Epoch: 6| Step: 8
Training loss: 1.9169980329365157
Validation loss: 2.2631272456720724

Epoch: 6| Step: 9
Training loss: 1.9407579655943876
Validation loss: 2.222279126058711

Epoch: 6| Step: 10
Training loss: 0.9955140165839547
Validation loss: 2.2146857203598485

Epoch: 6| Step: 11
Training loss: 1.093948291787448
Validation loss: 2.234261418438922

Epoch: 6| Step: 12
Training loss: 1.5514619423971265
Validation loss: 2.255257962028055

Epoch: 6| Step: 13
Training loss: 1.2582057077641287
Validation loss: 2.1562367861382836

Epoch: 283| Step: 0
Training loss: 1.938100045101015
Validation loss: 2.2254764172652184

Epoch: 6| Step: 1
Training loss: 1.5843177378763265
Validation loss: 2.1947698242443736

Epoch: 6| Step: 2
Training loss: 1.323532691963968
Validation loss: 2.2353777865015867

Epoch: 6| Step: 3
Training loss: 1.721665700941132
Validation loss: 2.210997933695573

Epoch: 6| Step: 4
Training loss: 2.144598732253097
Validation loss: 2.232455841154299

Epoch: 6| Step: 5
Training loss: 1.8035757099839993
Validation loss: 2.23064529820467

Epoch: 6| Step: 6
Training loss: 1.1801736095378499
Validation loss: 2.252546572703242

Epoch: 6| Step: 7
Training loss: 1.4935344588420232
Validation loss: 2.217991125029082

Epoch: 6| Step: 8
Training loss: 1.93920435851476
Validation loss: 2.2509835758446535

Epoch: 6| Step: 9
Training loss: 2.299037201091351
Validation loss: 2.2073900255499677

Epoch: 6| Step: 10
Training loss: 1.422174107876822
Validation loss: 2.2396445157011393

Epoch: 6| Step: 11
Training loss: 1.1771602211655623
Validation loss: 2.1961117677914768

Epoch: 6| Step: 12
Training loss: 1.2772354873367342
Validation loss: 2.1836854428688324

Epoch: 6| Step: 13
Training loss: 1.0274409259047743
Validation loss: 2.2182048617246006

Epoch: 284| Step: 0
Training loss: 1.4826576336944552
Validation loss: 2.1863553264868236

Epoch: 6| Step: 1
Training loss: 1.5402680143997216
Validation loss: 2.230009071803999

Epoch: 6| Step: 2
Training loss: 1.3797019845411729
Validation loss: 2.228664534463433

Epoch: 6| Step: 3
Training loss: 1.32484331284165
Validation loss: 2.1960572417437025

Epoch: 6| Step: 4
Training loss: 1.531354083202268
Validation loss: 2.227233833869717

Epoch: 6| Step: 5
Training loss: 2.16347520481586
Validation loss: 2.1989876554624144

Epoch: 6| Step: 6
Training loss: 1.4506894281322007
Validation loss: 2.2353024521661236

Epoch: 6| Step: 7
Training loss: 2.207436961465213
Validation loss: 2.2435573929274577

Epoch: 6| Step: 8
Training loss: 1.4711957818139378
Validation loss: 2.225981724426116

Epoch: 6| Step: 9
Training loss: 1.6762627041169593
Validation loss: 2.1325070439154197

Epoch: 6| Step: 10
Training loss: 1.701510022407673
Validation loss: 2.1979335354059155

Epoch: 6| Step: 11
Training loss: 1.5598729747016549
Validation loss: 2.205155463790593

Epoch: 6| Step: 12
Training loss: 1.538603428569719
Validation loss: 2.2147437656499127

Epoch: 6| Step: 13
Training loss: 1.2538478754543927
Validation loss: 2.264046544257758

Epoch: 285| Step: 0
Training loss: 1.5120519620756576
Validation loss: 2.191760629556255

Epoch: 6| Step: 1
Training loss: 1.8885179869199462
Validation loss: 2.1729748864437863

Epoch: 6| Step: 2
Training loss: 1.1238241408419667
Validation loss: 2.193509926608081

Epoch: 6| Step: 3
Training loss: 1.9360820134422658
Validation loss: 2.2092123663876055

Epoch: 6| Step: 4
Training loss: 1.482252350011215
Validation loss: 2.2370334686316724

Epoch: 6| Step: 5
Training loss: 0.8946656371872044
Validation loss: 2.2826651486382374

Epoch: 6| Step: 6
Training loss: 1.6099311090029516
Validation loss: 2.206252703321808

Epoch: 6| Step: 7
Training loss: 1.4559701937255067
Validation loss: 2.2162402741309513

Epoch: 6| Step: 8
Training loss: 1.335236750408602
Validation loss: 2.2133082554982617

Epoch: 6| Step: 9
Training loss: 1.7721271799658953
Validation loss: 2.2717211582306067

Epoch: 6| Step: 10
Training loss: 1.581918519324629
Validation loss: 2.2302513780252573

Epoch: 6| Step: 11
Training loss: 2.536080731138801
Validation loss: 2.2557317848171525

Epoch: 6| Step: 12
Training loss: 1.3740436522644566
Validation loss: 2.2008303215964626

Epoch: 6| Step: 13
Training loss: 1.4402800504902968
Validation loss: 2.205926474415092

Epoch: 286| Step: 0
Training loss: 1.2714594356593134
Validation loss: 2.2381583851570297

Epoch: 6| Step: 1
Training loss: 1.4832657534317122
Validation loss: 2.2207333834916247

Epoch: 6| Step: 2
Training loss: 1.7766376811604043
Validation loss: 2.173576228129336

Epoch: 6| Step: 3
Training loss: 1.7693376919482622
Validation loss: 2.158128154363616

Epoch: 6| Step: 4
Training loss: 1.872254650609886
Validation loss: 2.2153537274022765

Epoch: 6| Step: 5
Training loss: 1.8050934966538401
Validation loss: 2.2407527556670668

Epoch: 6| Step: 6
Training loss: 1.5795482600544577
Validation loss: 2.213736423174186

Epoch: 6| Step: 7
Training loss: 1.379061854933072
Validation loss: 2.213187707231432

Epoch: 6| Step: 8
Training loss: 1.2483313390022377
Validation loss: 2.250717011240293

Epoch: 6| Step: 9
Training loss: 1.3214238923406054
Validation loss: 2.195054256679547

Epoch: 6| Step: 10
Training loss: 1.5077506729653256
Validation loss: 2.252759897478985

Epoch: 6| Step: 11
Training loss: 1.5638373183304985
Validation loss: 2.1390810084570115

Epoch: 6| Step: 12
Training loss: 1.8485603298158138
Validation loss: 2.173477919898414

Epoch: 6| Step: 13
Training loss: 2.654929337647771
Validation loss: 2.2103311561028915

Epoch: 287| Step: 0
Training loss: 1.871887229917692
Validation loss: 2.2021578752789175

Epoch: 6| Step: 1
Training loss: 1.2209742862889992
Validation loss: 2.2043427693255273

Epoch: 6| Step: 2
Training loss: 1.747091669556611
Validation loss: 2.200501337102764

Epoch: 6| Step: 3
Training loss: 1.7659085476482712
Validation loss: 2.312510553860825

Epoch: 6| Step: 4
Training loss: 1.6041908097204955
Validation loss: 2.210429283736161

Epoch: 6| Step: 5
Training loss: 1.4349877339014971
Validation loss: 2.1915090491213474

Epoch: 6| Step: 6
Training loss: 1.6902705866419419
Validation loss: 2.173146428205274

Epoch: 6| Step: 7
Training loss: 1.1812682014152953
Validation loss: 2.246343427266132

Epoch: 6| Step: 8
Training loss: 1.4547609533988095
Validation loss: 2.1881238747972884

Epoch: 6| Step: 9
Training loss: 1.0653753083195163
Validation loss: 2.208871933244542

Epoch: 6| Step: 10
Training loss: 2.4234699534857036
Validation loss: 2.2052764290409486

Epoch: 6| Step: 11
Training loss: 1.5689531202393878
Validation loss: 2.239760689224523

Epoch: 6| Step: 12
Training loss: 1.1879610873056374
Validation loss: 2.1805178746548632

Epoch: 6| Step: 13
Training loss: 1.5500276593847568
Validation loss: 2.216964387349205

Epoch: 288| Step: 0
Training loss: 1.2457262890523033
Validation loss: 2.2617387107101354

Epoch: 6| Step: 1
Training loss: 1.3463491099082483
Validation loss: 2.195407459428578

Epoch: 6| Step: 2
Training loss: 1.9321334719272565
Validation loss: 2.1859474239194316

Epoch: 6| Step: 3
Training loss: 1.7387205104671903
Validation loss: 2.218461510868133

Epoch: 6| Step: 4
Training loss: 1.7618882463545218
Validation loss: 2.199735426585483

Epoch: 6| Step: 5
Training loss: 1.5115189136832259
Validation loss: 2.186246554438004

Epoch: 6| Step: 6
Training loss: 1.9850376254342508
Validation loss: 2.2027091811571626

Epoch: 6| Step: 7
Training loss: 1.6007950595541176
Validation loss: 2.2026649995016787

Epoch: 6| Step: 8
Training loss: 1.5727309397335472
Validation loss: 2.2173254803370286

Epoch: 6| Step: 9
Training loss: 1.203891262429016
Validation loss: 2.1946359525480155

Epoch: 6| Step: 10
Training loss: 1.3266624026653322
Validation loss: 2.2446895755355185

Epoch: 6| Step: 11
Training loss: 1.7061919150054832
Validation loss: 2.239194847652661

Epoch: 6| Step: 12
Training loss: 1.5281925428320637
Validation loss: 2.224043482516652

Epoch: 6| Step: 13
Training loss: 1.8519974209827237
Validation loss: 2.22184605230346

Epoch: 289| Step: 0
Training loss: 2.1835559712043846
Validation loss: 2.224629465857083

Epoch: 6| Step: 1
Training loss: 1.2685819392400959
Validation loss: 2.2319512473751044

Epoch: 6| Step: 2
Training loss: 1.1818822188134226
Validation loss: 2.240816423527475

Epoch: 6| Step: 3
Training loss: 1.3586464168086494
Validation loss: 2.1960386067243967

Epoch: 6| Step: 4
Training loss: 2.3262391100694693
Validation loss: 2.1577567266248554

Epoch: 6| Step: 5
Training loss: 1.0086013900030157
Validation loss: 2.2479012989043228

Epoch: 6| Step: 6
Training loss: 1.4550895946485871
Validation loss: 2.2269194936546586

Epoch: 6| Step: 7
Training loss: 1.539421388250081
Validation loss: 2.2398282885586065

Epoch: 6| Step: 8
Training loss: 1.2000451238413374
Validation loss: 2.2227293694150525

Epoch: 6| Step: 9
Training loss: 1.7972556996294278
Validation loss: 2.260374626727841

Epoch: 6| Step: 10
Training loss: 2.1250953652917492
Validation loss: 2.208271289456148

Epoch: 6| Step: 11
Training loss: 1.3945212484049168
Validation loss: 2.1997507775937066

Epoch: 6| Step: 12
Training loss: 1.7095463640698783
Validation loss: 2.1752711629522126

Epoch: 6| Step: 13
Training loss: 1.2914394773626814
Validation loss: 2.249766184964667

Epoch: 290| Step: 0
Training loss: 2.05382029287135
Validation loss: 2.2204061252158254

Epoch: 6| Step: 1
Training loss: 1.4420630139882467
Validation loss: 2.1834834173652204

Epoch: 6| Step: 2
Training loss: 1.356936053602934
Validation loss: 2.201069231332782

Epoch: 6| Step: 3
Training loss: 1.3246178489780738
Validation loss: 2.220410218204749

Epoch: 6| Step: 4
Training loss: 1.410472549090219
Validation loss: 2.1620075459632186

Epoch: 6| Step: 5
Training loss: 1.4127189618428895
Validation loss: 2.164617645905406

Epoch: 6| Step: 6
Training loss: 1.775070581241741
Validation loss: 2.25117304518781

Epoch: 6| Step: 7
Training loss: 1.7718074213828678
Validation loss: 2.191220299729063

Epoch: 6| Step: 8
Training loss: 1.4522077064758343
Validation loss: 2.220608200751744

Epoch: 6| Step: 9
Training loss: 1.574552969086692
Validation loss: 2.1753918796498763

Epoch: 6| Step: 10
Training loss: 1.0837217270486212
Validation loss: 2.1920933969804968

Epoch: 6| Step: 11
Training loss: 1.8409987143118873
Validation loss: 2.2000803975174965

Epoch: 6| Step: 12
Training loss: 1.4834252782607087
Validation loss: 2.207263838084309

Epoch: 6| Step: 13
Training loss: 1.9151523523508107
Validation loss: 2.1952400824716354

Epoch: 291| Step: 0
Training loss: 1.6941423728815992
Validation loss: 2.2345736904537814

Epoch: 6| Step: 1
Training loss: 1.9142912436061787
Validation loss: 2.195992624957863

Epoch: 6| Step: 2
Training loss: 1.327893046151158
Validation loss: 2.1918924721675968

Epoch: 6| Step: 3
Training loss: 2.3552703520820035
Validation loss: 2.217699522934786

Epoch: 6| Step: 4
Training loss: 1.7517416325626955
Validation loss: 2.25468011517926

Epoch: 6| Step: 5
Training loss: 1.632063333315606
Validation loss: 2.2091716011971894

Epoch: 6| Step: 6
Training loss: 1.2233833369205545
Validation loss: 2.2082002338071893

Epoch: 6| Step: 7
Training loss: 1.716615773653344
Validation loss: 2.2249019525154723

Epoch: 6| Step: 8
Training loss: 1.2430081325887956
Validation loss: 2.177917040773479

Epoch: 6| Step: 9
Training loss: 1.3413006838192778
Validation loss: 2.1770321865072426

Epoch: 6| Step: 10
Training loss: 1.3214535268982528
Validation loss: 2.2129919036568406

Epoch: 6| Step: 11
Training loss: 1.3409741584996084
Validation loss: 2.228480717009374

Epoch: 6| Step: 12
Training loss: 1.299445030156457
Validation loss: 2.2376827227252187

Epoch: 6| Step: 13
Training loss: 1.1116599608242423
Validation loss: 2.247545230048131

Epoch: 292| Step: 0
Training loss: 1.2308564074985056
Validation loss: 2.206152476617824

Epoch: 6| Step: 1
Training loss: 1.7778363226482812
Validation loss: 2.1745724697382527

Epoch: 6| Step: 2
Training loss: 1.4362693162487346
Validation loss: 2.2148726208725424

Epoch: 6| Step: 3
Training loss: 1.4142549499727193
Validation loss: 2.182571552558694

Epoch: 6| Step: 4
Training loss: 1.3343673312750766
Validation loss: 2.2565454816252686

Epoch: 6| Step: 5
Training loss: 1.7210634787343702
Validation loss: 2.2069970034883353

Epoch: 6| Step: 6
Training loss: 1.1763819177254122
Validation loss: 2.210102422914491

Epoch: 6| Step: 7
Training loss: 1.597863591923724
Validation loss: 2.226292284731684

Epoch: 6| Step: 8
Training loss: 2.1714292658897953
Validation loss: 2.2081667693512483

Epoch: 6| Step: 9
Training loss: 2.0360180573177935
Validation loss: 2.2616861289917893

Epoch: 6| Step: 10
Training loss: 1.748761965292842
Validation loss: 2.1929139021006416

Epoch: 6| Step: 11
Training loss: 1.0920847068078405
Validation loss: 2.1924169113548073

Epoch: 6| Step: 12
Training loss: 1.42357215621292
Validation loss: 2.204243348416477

Epoch: 6| Step: 13
Training loss: 0.86389811298956
Validation loss: 2.225632979230309

Epoch: 293| Step: 0
Training loss: 2.253006092589869
Validation loss: 2.259662703931358

Epoch: 6| Step: 1
Training loss: 1.1610270613244489
Validation loss: 2.192422264502943

Epoch: 6| Step: 2
Training loss: 1.691036615662196
Validation loss: 2.191427959002442

Epoch: 6| Step: 3
Training loss: 1.5982501504684083
Validation loss: 2.193591950684911

Epoch: 6| Step: 4
Training loss: 1.7487567845309053
Validation loss: 2.2560136153942203

Epoch: 6| Step: 5
Training loss: 1.5465278621301093
Validation loss: 2.2063618363411477

Epoch: 6| Step: 6
Training loss: 1.9900451510305637
Validation loss: 2.2294509663467665

Epoch: 6| Step: 7
Training loss: 1.3301144229456545
Validation loss: 2.197608291212744

Epoch: 6| Step: 8
Training loss: 1.4789303156471028
Validation loss: 2.174418511274512

Epoch: 6| Step: 9
Training loss: 1.4322591697011806
Validation loss: 2.226229443743295

Epoch: 6| Step: 10
Training loss: 1.3633088816818288
Validation loss: 2.2130138955637797

Epoch: 6| Step: 11
Training loss: 1.2648544320497193
Validation loss: 2.2910134071459862

Epoch: 6| Step: 12
Training loss: 1.9295605451698572
Validation loss: 2.220916726518423

Epoch: 6| Step: 13
Training loss: 0.8729025360881679
Validation loss: 2.182478007460549

Epoch: 294| Step: 0
Training loss: 1.449303472875173
Validation loss: 2.1751047552122578

Epoch: 6| Step: 1
Training loss: 1.7443254293890464
Validation loss: 2.2098828428820285

Epoch: 6| Step: 2
Training loss: 1.2981263523526372
Validation loss: 2.1820202994831575

Epoch: 6| Step: 3
Training loss: 1.0078373395830607
Validation loss: 2.19613258570669

Epoch: 6| Step: 4
Training loss: 1.4945452372907932
Validation loss: 2.2562711484334512

Epoch: 6| Step: 5
Training loss: 1.7107676243167569
Validation loss: 2.181609766719111

Epoch: 6| Step: 6
Training loss: 2.240273965021799
Validation loss: 2.219536658754301

Epoch: 6| Step: 7
Training loss: 1.212946154909641
Validation loss: 2.1808656221197777

Epoch: 6| Step: 8
Training loss: 1.7331834428730186
Validation loss: 2.152818508228199

Epoch: 6| Step: 9
Training loss: 1.3710254967375581
Validation loss: 2.256535376074683

Epoch: 6| Step: 10
Training loss: 1.4574906593926416
Validation loss: 2.1997317309995563

Epoch: 6| Step: 11
Training loss: 1.4519365434415619
Validation loss: 2.153926937310067

Epoch: 6| Step: 12
Training loss: 1.7796520628176626
Validation loss: 2.1909601535710337

Epoch: 6| Step: 13
Training loss: 1.932748752489478
Validation loss: 2.1907027534938983

Epoch: 295| Step: 0
Training loss: 1.5667384073727308
Validation loss: 2.1689599807687316

Epoch: 6| Step: 1
Training loss: 1.5869487676493526
Validation loss: 2.2168131047237885

Epoch: 6| Step: 2
Training loss: 1.2683524894938654
Validation loss: 2.197587599851049

Epoch: 6| Step: 3
Training loss: 2.2066902910026305
Validation loss: 2.165850332528692

Epoch: 6| Step: 4
Training loss: 1.4996198331364377
Validation loss: 2.246695273499517

Epoch: 6| Step: 5
Training loss: 2.1022044055905984
Validation loss: 2.21573586239433

Epoch: 6| Step: 6
Training loss: 1.3833981152191712
Validation loss: 2.223001394732919

Epoch: 6| Step: 7
Training loss: 1.1911900058301463
Validation loss: 2.2255244991965117

Epoch: 6| Step: 8
Training loss: 1.6839048447806173
Validation loss: 2.247750555311836

Epoch: 6| Step: 9
Training loss: 1.6458747069876505
Validation loss: 2.176257914394073

Epoch: 6| Step: 10
Training loss: 1.7745601780743587
Validation loss: 2.2405000310577265

Epoch: 6| Step: 11
Training loss: 1.2371100533823527
Validation loss: 2.1989131636422745

Epoch: 6| Step: 12
Training loss: 1.1669893272715994
Validation loss: 2.1935200408522166

Epoch: 6| Step: 13
Training loss: 1.098096223127364
Validation loss: 2.210796604923405

Epoch: 296| Step: 0
Training loss: 1.8132833563822388
Validation loss: 2.195188176440248

Epoch: 6| Step: 1
Training loss: 1.4600200526284386
Validation loss: 2.1852989854934357

Epoch: 6| Step: 2
Training loss: 1.4260210227540215
Validation loss: 2.1856626244837902

Epoch: 6| Step: 3
Training loss: 1.7122887975391239
Validation loss: 2.203778005694739

Epoch: 6| Step: 4
Training loss: 1.4480075761902442
Validation loss: 2.192582707884721

Epoch: 6| Step: 5
Training loss: 1.3580391557495275
Validation loss: 2.200063149439891

Epoch: 6| Step: 6
Training loss: 1.298720368239118
Validation loss: 2.2149240395629795

Epoch: 6| Step: 7
Training loss: 1.6305954771048625
Validation loss: 2.1552586427778495

Epoch: 6| Step: 8
Training loss: 1.4010258594552438
Validation loss: 2.1755614352754415

Epoch: 6| Step: 9
Training loss: 1.1454777888455385
Validation loss: 2.1954254663175163

Epoch: 6| Step: 10
Training loss: 1.602391916757232
Validation loss: 2.2165224516305946

Epoch: 6| Step: 11
Training loss: 1.5000657226151517
Validation loss: 2.192683943609736

Epoch: 6| Step: 12
Training loss: 1.062945048303338
Validation loss: 2.2169044267964764

Epoch: 6| Step: 13
Training loss: 3.0688131228789897
Validation loss: 2.16934646986499

Epoch: 297| Step: 0
Training loss: 1.1205009993515087
Validation loss: 2.256549990765279

Epoch: 6| Step: 1
Training loss: 1.2074239641342428
Validation loss: 2.1375984753061004

Epoch: 6| Step: 2
Training loss: 1.4442226940688463
Validation loss: 2.1487426433721133

Epoch: 6| Step: 3
Training loss: 2.058067413738478
Validation loss: 2.2206237359143763

Epoch: 6| Step: 4
Training loss: 1.437292249843208
Validation loss: 2.1807253104657502

Epoch: 6| Step: 5
Training loss: 1.4322317862275613
Validation loss: 2.203231068896147

Epoch: 6| Step: 6
Training loss: 1.7691204613168037
Validation loss: 2.1710923830512536

Epoch: 6| Step: 7
Training loss: 1.7688169406045122
Validation loss: 2.1738093719500533

Epoch: 6| Step: 8
Training loss: 1.4411126227964461
Validation loss: 2.219165436696126

Epoch: 6| Step: 9
Training loss: 1.8609378561664949
Validation loss: 2.191275585502925

Epoch: 6| Step: 10
Training loss: 1.6397183774262234
Validation loss: 2.1892557437476556

Epoch: 6| Step: 11
Training loss: 1.263134943995153
Validation loss: 2.206034734854585

Epoch: 6| Step: 12
Training loss: 1.9682336765980253
Validation loss: 2.2054372839565928

Epoch: 6| Step: 13
Training loss: 1.4679982310811956
Validation loss: 2.22831638056595

Epoch: 298| Step: 0
Training loss: 1.4798212975792602
Validation loss: 2.20274895680801

Epoch: 6| Step: 1
Training loss: 1.409436071049643
Validation loss: 2.1659349179254748

Epoch: 6| Step: 2
Training loss: 1.665366865986166
Validation loss: 2.174073366249625

Epoch: 6| Step: 3
Training loss: 1.378141196365507
Validation loss: 2.173392183697142

Epoch: 6| Step: 4
Training loss: 1.0570782726398764
Validation loss: 2.1765912157187444

Epoch: 6| Step: 5
Training loss: 1.7319259535839024
Validation loss: 2.151342244088582

Epoch: 6| Step: 6
Training loss: 1.3737336309289065
Validation loss: 2.18924114939986

Epoch: 6| Step: 7
Training loss: 2.429885512743657
Validation loss: 2.1540650099684027

Epoch: 6| Step: 8
Training loss: 1.0585367673057167
Validation loss: 2.134870237063284

Epoch: 6| Step: 9
Training loss: 1.7339916321047661
Validation loss: 2.1855932818004336

Epoch: 6| Step: 10
Training loss: 1.5918883127734962
Validation loss: 2.203478226672251

Epoch: 6| Step: 11
Training loss: 1.667409977463169
Validation loss: 2.221145170148673

Epoch: 6| Step: 12
Training loss: 1.461783098102183
Validation loss: 2.19080533813195

Epoch: 6| Step: 13
Training loss: 1.3208958166768507
Validation loss: 2.2062724099805764

Epoch: 299| Step: 0
Training loss: 2.26180476682287
Validation loss: 2.200169378763309

Epoch: 6| Step: 1
Training loss: 1.0157543393454787
Validation loss: 2.1780410789746196

Epoch: 6| Step: 2
Training loss: 1.4168473109840813
Validation loss: 2.204561399304206

Epoch: 6| Step: 3
Training loss: 1.0393272578869548
Validation loss: 2.184588997232373

Epoch: 6| Step: 4
Training loss: 1.3926236652134696
Validation loss: 2.2148412394212333

Epoch: 6| Step: 5
Training loss: 1.5353540191223112
Validation loss: 2.1915518741341264

Epoch: 6| Step: 6
Training loss: 1.5244536312229306
Validation loss: 2.1865571282644636

Epoch: 6| Step: 7
Training loss: 1.8406859978767538
Validation loss: 2.2008708137939244

Epoch: 6| Step: 8
Training loss: 1.3004269045681713
Validation loss: 2.2280437373259954

Epoch: 6| Step: 9
Training loss: 1.5092296364487674
Validation loss: 2.181366107282326

Epoch: 6| Step: 10
Training loss: 1.5968887985439566
Validation loss: 2.2043533948625744

Epoch: 6| Step: 11
Training loss: 1.7929852387245635
Validation loss: 2.145054764862538

Epoch: 6| Step: 12
Training loss: 1.392222226584244
Validation loss: 2.184394267765654

Epoch: 6| Step: 13
Training loss: 1.4740426496600998
Validation loss: 2.211309679002198

Epoch: 300| Step: 0
Training loss: 1.2431430620096307
Validation loss: 2.1725749772523932

Epoch: 6| Step: 1
Training loss: 1.6990519123824495
Validation loss: 2.258306981178826

Epoch: 6| Step: 2
Training loss: 2.1724041630333657
Validation loss: 2.194010802652018

Epoch: 6| Step: 3
Training loss: 1.2289016190021462
Validation loss: 2.1503777721294712

Epoch: 6| Step: 4
Training loss: 1.3474295162812135
Validation loss: 2.16678367240443

Epoch: 6| Step: 5
Training loss: 1.3664268775634887
Validation loss: 2.1520179930961074

Epoch: 6| Step: 6
Training loss: 0.954338177143595
Validation loss: 2.195649372660974

Epoch: 6| Step: 7
Training loss: 1.109101490099615
Validation loss: 2.176989393822211

Epoch: 6| Step: 8
Training loss: 1.4392685998374408
Validation loss: 2.2467103310326237

Epoch: 6| Step: 9
Training loss: 1.582978443059218
Validation loss: 2.2107885897508854

Epoch: 6| Step: 10
Training loss: 1.754059510873259
Validation loss: 2.216614789569296

Epoch: 6| Step: 11
Training loss: 2.003382802194859
Validation loss: 2.2017157777865353

Epoch: 6| Step: 12
Training loss: 1.6060808411818053
Validation loss: 2.169758959605665

Epoch: 6| Step: 13
Training loss: 0.9552234624886887
Validation loss: 2.1963205759626447

Epoch: 301| Step: 0
Training loss: 1.9774578614694496
Validation loss: 2.13793225166277

Epoch: 6| Step: 1
Training loss: 1.6218634191551633
Validation loss: 2.22326605654423

Epoch: 6| Step: 2
Training loss: 1.1487650501481557
Validation loss: 2.126092978338987

Epoch: 6| Step: 3
Training loss: 1.5931422252778873
Validation loss: 2.2199843568148188

Epoch: 6| Step: 4
Training loss: 1.5948768820525425
Validation loss: 2.2368625699920592

Epoch: 6| Step: 5
Training loss: 1.3653833310750456
Validation loss: 2.1849050996248445

Epoch: 6| Step: 6
Training loss: 2.0872094780235564
Validation loss: 2.1637786996627315

Epoch: 6| Step: 7
Training loss: 1.2411592174112
Validation loss: 2.237174423352338

Epoch: 6| Step: 8
Training loss: 1.0587768396355681
Validation loss: 2.1761551570308892

Epoch: 6| Step: 9
Training loss: 1.4654551133069316
Validation loss: 2.235476976412225

Epoch: 6| Step: 10
Training loss: 1.803627264191797
Validation loss: 2.143469244053187

Epoch: 6| Step: 11
Training loss: 1.4933766524951606
Validation loss: 2.2144265138606767

Epoch: 6| Step: 12
Training loss: 1.5402611262150718
Validation loss: 2.1412606358099815

Epoch: 6| Step: 13
Training loss: 1.5397880122191667
Validation loss: 2.1288262621568816

Epoch: 302| Step: 0
Training loss: 1.4361748599855764
Validation loss: 2.201562925075957

Epoch: 6| Step: 1
Training loss: 0.9073589708757257
Validation loss: 2.22581079671946

Epoch: 6| Step: 2
Training loss: 1.554209496706512
Validation loss: 2.185363707311358

Epoch: 6| Step: 3
Training loss: 1.1905209613510377
Validation loss: 2.1994165204727385

Epoch: 6| Step: 4
Training loss: 1.0539208910966427
Validation loss: 2.2079519088337043

Epoch: 6| Step: 5
Training loss: 1.2453726472772086
Validation loss: 2.127928153239942

Epoch: 6| Step: 6
Training loss: 1.6365655722670303
Validation loss: 2.1769891777310897

Epoch: 6| Step: 7
Training loss: 1.4102874863864168
Validation loss: 2.219233841274932

Epoch: 6| Step: 8
Training loss: 2.069885209812205
Validation loss: 2.189901951111947

Epoch: 6| Step: 9
Training loss: 1.5395211248085197
Validation loss: 2.13964644615757

Epoch: 6| Step: 10
Training loss: 1.5116439919136297
Validation loss: 2.2188293636951766

Epoch: 6| Step: 11
Training loss: 1.1528239655848724
Validation loss: 2.1857863492248097

Epoch: 6| Step: 12
Training loss: 1.7993603311505895
Validation loss: 2.152594043549123

Epoch: 6| Step: 13
Training loss: 2.7120278224361876
Validation loss: 2.236407115942121

Epoch: 303| Step: 0
Training loss: 1.6699487159758104
Validation loss: 2.124103631549658

Epoch: 6| Step: 1
Training loss: 1.2211737374084144
Validation loss: 2.1684991724421083

Epoch: 6| Step: 2
Training loss: 1.657817027295229
Validation loss: 2.1560229006046705

Epoch: 6| Step: 3
Training loss: 1.6458190080365325
Validation loss: 2.25377309727242

Epoch: 6| Step: 4
Training loss: 1.4330137987078098
Validation loss: 2.1829596534413045

Epoch: 6| Step: 5
Training loss: 1.5859300585041318
Validation loss: 2.2210155164916987

Epoch: 6| Step: 6
Training loss: 1.6643998784588452
Validation loss: 2.16906118793753

Epoch: 6| Step: 7
Training loss: 1.4746666903441177
Validation loss: 2.200460379660204

Epoch: 6| Step: 8
Training loss: 1.58519490713302
Validation loss: 2.1592859394811104

Epoch: 6| Step: 9
Training loss: 1.1775530269045977
Validation loss: 2.1425032184579673

Epoch: 6| Step: 10
Training loss: 2.0348208218735446
Validation loss: 2.1204429178953994

Epoch: 6| Step: 11
Training loss: 1.3955622689771718
Validation loss: 2.152075980499635

Epoch: 6| Step: 12
Training loss: 1.2054852705173909
Validation loss: 2.1441746087238434

Epoch: 6| Step: 13
Training loss: 0.9283471904373328
Validation loss: 2.162086238656333

Epoch: 304| Step: 0
Training loss: 1.4787178254033213
Validation loss: 2.215125514579127

Epoch: 6| Step: 1
Training loss: 1.5321106341082895
Validation loss: 2.209826051021522

Epoch: 6| Step: 2
Training loss: 1.8847591736045675
Validation loss: 2.1002354165937165

Epoch: 6| Step: 3
Training loss: 2.1889908206376045
Validation loss: 2.1896740494924645

Epoch: 6| Step: 4
Training loss: 1.3239382106273245
Validation loss: 2.160631107552576

Epoch: 6| Step: 5
Training loss: 1.3366982597238721
Validation loss: 2.2114920745880497

Epoch: 6| Step: 6
Training loss: 1.427966723863788
Validation loss: 2.139354720828035

Epoch: 6| Step: 7
Training loss: 1.2674511109654047
Validation loss: 2.1571602905476195

Epoch: 6| Step: 8
Training loss: 1.0617985373321133
Validation loss: 2.1514422173781216

Epoch: 6| Step: 9
Training loss: 1.1476055427499854
Validation loss: 2.1935979075168426

Epoch: 6| Step: 10
Training loss: 1.9285863290443237
Validation loss: 2.164628500935334

Epoch: 6| Step: 11
Training loss: 1.550471123498747
Validation loss: 2.2420671369322136

Epoch: 6| Step: 12
Training loss: 1.3205530523081102
Validation loss: 2.139771115956118

Epoch: 6| Step: 13
Training loss: 1.431297188193345
Validation loss: 2.1725304624388055

Epoch: 305| Step: 0
Training loss: 1.2192029844773176
Validation loss: 2.101079838176031

Epoch: 6| Step: 1
Training loss: 1.1568672491521876
Validation loss: 2.168209829897452

Epoch: 6| Step: 2
Training loss: 1.1674845020155917
Validation loss: 2.1931567718663265

Epoch: 6| Step: 3
Training loss: 1.155094497249859
Validation loss: 2.1850679833251734

Epoch: 6| Step: 4
Training loss: 1.37829904992589
Validation loss: 2.1688699957012485

Epoch: 6| Step: 5
Training loss: 1.8796831773056593
Validation loss: 2.1790579809575745

Epoch: 6| Step: 6
Training loss: 1.3986344438534553
Validation loss: 2.217976029720423

Epoch: 6| Step: 7
Training loss: 0.9709978174407033
Validation loss: 2.2019956672133087

Epoch: 6| Step: 8
Training loss: 2.122279726062693
Validation loss: 2.1631436033170375

Epoch: 6| Step: 9
Training loss: 1.7874061879969791
Validation loss: 2.2219986196364334

Epoch: 6| Step: 10
Training loss: 1.3838857591397025
Validation loss: 2.2330374528909105

Epoch: 6| Step: 11
Training loss: 1.533114640908092
Validation loss: 2.1669382963540835

Epoch: 6| Step: 12
Training loss: 1.6806666159735106
Validation loss: 2.1952063859956947

Epoch: 6| Step: 13
Training loss: 1.2769691314580938
Validation loss: 2.1733530768920666

Epoch: 306| Step: 0
Training loss: 1.5397758573431828
Validation loss: 2.2118774674711084

Epoch: 6| Step: 1
Training loss: 1.2242188629559316
Validation loss: 2.2209440524828254

Epoch: 6| Step: 2
Training loss: 1.4458946911254316
Validation loss: 2.2348446606612917

Epoch: 6| Step: 3
Training loss: 1.0647434783542353
Validation loss: 2.173729423046227

Epoch: 6| Step: 4
Training loss: 1.4354578522567176
Validation loss: 2.1562118488257958

Epoch: 6| Step: 5
Training loss: 1.3180173076917234
Validation loss: 2.1617493863569477

Epoch: 6| Step: 6
Training loss: 1.5060128654497837
Validation loss: 2.181272706762389

Epoch: 6| Step: 7
Training loss: 1.3461140087017955
Validation loss: 2.15354833644968

Epoch: 6| Step: 8
Training loss: 0.9533966802900554
Validation loss: 2.169595665675382

Epoch: 6| Step: 9
Training loss: 2.2488022901340847
Validation loss: 2.183847612235887

Epoch: 6| Step: 10
Training loss: 1.8075131840310783
Validation loss: 2.2355878885277205

Epoch: 6| Step: 11
Training loss: 1.8554576993914351
Validation loss: 2.150818095056946

Epoch: 6| Step: 12
Training loss: 1.5474750626485207
Validation loss: 2.199721004325205

Epoch: 6| Step: 13
Training loss: 1.2281115038569428
Validation loss: 2.2086991364897974

Epoch: 307| Step: 0
Training loss: 1.2031379798089918
Validation loss: 2.1876340986129277

Epoch: 6| Step: 1
Training loss: 1.385318790888771
Validation loss: 2.1872535683953327

Epoch: 6| Step: 2
Training loss: 1.559359484272368
Validation loss: 2.1187258901339603

Epoch: 6| Step: 3
Training loss: 1.09583878654796
Validation loss: 2.2010131048428576

Epoch: 6| Step: 4
Training loss: 1.0804383158448718
Validation loss: 2.2230051531191206

Epoch: 6| Step: 5
Training loss: 2.3344175567220358
Validation loss: 2.225127236863599

Epoch: 6| Step: 6
Training loss: 1.3577051539508485
Validation loss: 2.197715812696516

Epoch: 6| Step: 7
Training loss: 1.3410831868870032
Validation loss: 2.1614472000620126

Epoch: 6| Step: 8
Training loss: 1.0207397781372247
Validation loss: 2.2424221944303255

Epoch: 6| Step: 9
Training loss: 0.9144308538059135
Validation loss: 2.1903081422429853

Epoch: 6| Step: 10
Training loss: 1.9569353700705234
Validation loss: 2.213722988473945

Epoch: 6| Step: 11
Training loss: 1.0330221958785466
Validation loss: 2.1738127931863986

Epoch: 6| Step: 12
Training loss: 1.9644583291838005
Validation loss: 2.191912771676537

Epoch: 6| Step: 13
Training loss: 1.9148030619537626
Validation loss: 2.1771325126785173

Epoch: 308| Step: 0
Training loss: 1.287982742768534
Validation loss: 2.182126230562459

Epoch: 6| Step: 1
Training loss: 1.4879661086232363
Validation loss: 2.1693246946990197

Epoch: 6| Step: 2
Training loss: 0.7957088314819961
Validation loss: 2.208622528274863

Epoch: 6| Step: 3
Training loss: 1.4935766015703047
Validation loss: 2.1507333001471967

Epoch: 6| Step: 4
Training loss: 2.4745454004654763
Validation loss: 2.1948059908392072

Epoch: 6| Step: 5
Training loss: 0.7667057816920936
Validation loss: 2.1499375906493223

Epoch: 6| Step: 6
Training loss: 1.5958879380142776
Validation loss: 2.239412574143859

Epoch: 6| Step: 7
Training loss: 1.4233550030013917
Validation loss: 2.12931436128742

Epoch: 6| Step: 8
Training loss: 1.521474502786088
Validation loss: 2.296215989405044

Epoch: 6| Step: 9
Training loss: 1.7782348411168147
Validation loss: 2.243590007855439

Epoch: 6| Step: 10
Training loss: 1.6952095527858628
Validation loss: 2.152616016539553

Epoch: 6| Step: 11
Training loss: 1.3351532268099322
Validation loss: 2.212483028390572

Epoch: 6| Step: 12
Training loss: 0.9971990698343737
Validation loss: 2.1846421402345015

Epoch: 6| Step: 13
Training loss: 1.5149001915161728
Validation loss: 2.1780792064851857

Epoch: 309| Step: 0
Training loss: 1.2497364720075759
Validation loss: 2.244754178718428

Epoch: 6| Step: 1
Training loss: 1.0986740986166044
Validation loss: 2.229814342367196

Epoch: 6| Step: 2
Training loss: 1.7273198878772142
Validation loss: 2.1795670541520336

Epoch: 6| Step: 3
Training loss: 1.6681279769762274
Validation loss: 2.232573043270834

Epoch: 6| Step: 4
Training loss: 1.187342783910833
Validation loss: 2.2272587175413983

Epoch: 6| Step: 5
Training loss: 1.0236700827457623
Validation loss: 2.159288711738796

Epoch: 6| Step: 6
Training loss: 1.4337876523968
Validation loss: 2.1593019977491923

Epoch: 6| Step: 7
Training loss: 0.9864936312060485
Validation loss: 2.2406010091036737

Epoch: 6| Step: 8
Training loss: 1.4982844715121568
Validation loss: 2.1802015030412236

Epoch: 6| Step: 9
Training loss: 1.5299401422397774
Validation loss: 2.1973698766990983

Epoch: 6| Step: 10
Training loss: 2.03889821293241
Validation loss: 2.2470890947513436

Epoch: 6| Step: 11
Training loss: 1.7991260526218436
Validation loss: 2.2053582921507298

Epoch: 6| Step: 12
Training loss: 1.4745805143854138
Validation loss: 2.2065362004651132

Epoch: 6| Step: 13
Training loss: 1.8961054288789736
Validation loss: 2.239141391343575

Epoch: 310| Step: 0
Training loss: 1.303157160154012
Validation loss: 2.228652848499442

Epoch: 6| Step: 1
Training loss: 1.7866798093060927
Validation loss: 2.157798050882422

Epoch: 6| Step: 2
Training loss: 0.9354733177367911
Validation loss: 2.1962752689438427

Epoch: 6| Step: 3
Training loss: 1.513836779071857
Validation loss: 2.2400294354441397

Epoch: 6| Step: 4
Training loss: 0.9377316506608503
Validation loss: 2.1784965898127657

Epoch: 6| Step: 5
Training loss: 1.7389723871812646
Validation loss: 2.207290337713676

Epoch: 6| Step: 6
Training loss: 2.1082153523521523
Validation loss: 2.2345062987162807

Epoch: 6| Step: 7
Training loss: 1.603636352603545
Validation loss: 2.2058827741322125

Epoch: 6| Step: 8
Training loss: 1.2166618651900634
Validation loss: 2.1731726953346207

Epoch: 6| Step: 9
Training loss: 1.3430123189501757
Validation loss: 2.229810700081822

Epoch: 6| Step: 10
Training loss: 1.4994175097858313
Validation loss: 2.161701049302913

Epoch: 6| Step: 11
Training loss: 1.1888718962321527
Validation loss: 2.209483153416221

Epoch: 6| Step: 12
Training loss: 1.7331919716387387
Validation loss: 2.226835493253577

Epoch: 6| Step: 13
Training loss: 1.3542827067419392
Validation loss: 2.23203657135715

Epoch: 311| Step: 0
Training loss: 1.6189740765989624
Validation loss: 2.204323714144034

Epoch: 6| Step: 1
Training loss: 0.7566412693822477
Validation loss: 2.1919051166925088

Epoch: 6| Step: 2
Training loss: 2.317564907708181
Validation loss: 2.233970660004256

Epoch: 6| Step: 3
Training loss: 1.498962758976507
Validation loss: 2.169081143257197

Epoch: 6| Step: 4
Training loss: 1.3214182089248327
Validation loss: 2.147529901072421

Epoch: 6| Step: 5
Training loss: 0.9842676982223464
Validation loss: 2.2148908827233584

Epoch: 6| Step: 6
Training loss: 1.024564515621409
Validation loss: 2.1933419478359135

Epoch: 6| Step: 7
Training loss: 1.521580743247441
Validation loss: 2.218912176767779

Epoch: 6| Step: 8
Training loss: 1.237308396813328
Validation loss: 2.223770466423569

Epoch: 6| Step: 9
Training loss: 1.3558403187442671
Validation loss: 2.2325760713087255

Epoch: 6| Step: 10
Training loss: 1.3369017573278665
Validation loss: 2.2084491530647954

Epoch: 6| Step: 11
Training loss: 1.6126423233269147
Validation loss: 2.2234975551649145

Epoch: 6| Step: 12
Training loss: 1.8412658637892019
Validation loss: 2.1781139035522736

Epoch: 6| Step: 13
Training loss: 1.1553391657984915
Validation loss: 2.1696848431718117

Epoch: 312| Step: 0
Training loss: 1.3628379297715838
Validation loss: 2.1926082157292264

Epoch: 6| Step: 1
Training loss: 1.5886516929002972
Validation loss: 2.1396270598269584

Epoch: 6| Step: 2
Training loss: 1.5440070027157988
Validation loss: 2.1724502239653884

Epoch: 6| Step: 3
Training loss: 1.1127118712564625
Validation loss: 2.166075770456825

Epoch: 6| Step: 4
Training loss: 0.9630298939359981
Validation loss: 2.198728278485481

Epoch: 6| Step: 5
Training loss: 1.3790529081251772
Validation loss: 2.218826587839322

Epoch: 6| Step: 6
Training loss: 1.4119808829745175
Validation loss: 2.223355368427687

Epoch: 6| Step: 7
Training loss: 1.6095478742766935
Validation loss: 2.234724564030821

Epoch: 6| Step: 8
Training loss: 1.3643930705363958
Validation loss: 2.2368748898276594

Epoch: 6| Step: 9
Training loss: 2.3626049240467877
Validation loss: 2.222852675053352

Epoch: 6| Step: 10
Training loss: 1.2629326334042263
Validation loss: 2.1735935077017534

Epoch: 6| Step: 11
Training loss: 1.131570384986541
Validation loss: 2.194949735569162

Epoch: 6| Step: 12
Training loss: 1.3674921186872087
Validation loss: 2.1668040202061944

Epoch: 6| Step: 13
Training loss: 1.4212071453736204
Validation loss: 2.192675730109907

Epoch: 313| Step: 0
Training loss: 1.5899154309508678
Validation loss: 2.1814779431248805

Epoch: 6| Step: 1
Training loss: 1.7012544211190745
Validation loss: 2.172644797969361

Epoch: 6| Step: 2
Training loss: 1.5856080112291462
Validation loss: 2.229648266270548

Epoch: 6| Step: 3
Training loss: 1.6367859746924989
Validation loss: 2.212922944683296

Epoch: 6| Step: 4
Training loss: 1.1685952640038577
Validation loss: 2.1906575333279537

Epoch: 6| Step: 5
Training loss: 1.2354503727775517
Validation loss: 2.1915084068977086

Epoch: 6| Step: 6
Training loss: 1.051797821785731
Validation loss: 2.2076686939357533

Epoch: 6| Step: 7
Training loss: 1.3259517166702548
Validation loss: 2.160393377952976

Epoch: 6| Step: 8
Training loss: 1.192201142839237
Validation loss: 2.196519224797616

Epoch: 6| Step: 9
Training loss: 2.254583564419424
Validation loss: 2.2030275605919623

Epoch: 6| Step: 10
Training loss: 0.9836151884255955
Validation loss: 2.1822622735150765

Epoch: 6| Step: 11
Training loss: 1.3350482680492268
Validation loss: 2.191265627029961

Epoch: 6| Step: 12
Training loss: 1.4339534297920054
Validation loss: 2.2751253165882304

Epoch: 6| Step: 13
Training loss: 1.164239242756307
Validation loss: 2.229228850233299

Epoch: 314| Step: 0
Training loss: 1.5457849997121473
Validation loss: 2.1879899983587747

Epoch: 6| Step: 1
Training loss: 1.3974154696208705
Validation loss: 2.173031594373225

Epoch: 6| Step: 2
Training loss: 1.4581057598023537
Validation loss: 2.1582476858760598

Epoch: 6| Step: 3
Training loss: 1.537145902594691
Validation loss: 2.229373303200263

Epoch: 6| Step: 4
Training loss: 1.1687883034207673
Validation loss: 2.21222953709848

Epoch: 6| Step: 5
Training loss: 0.8263173076783216
Validation loss: 2.200076398380616

Epoch: 6| Step: 6
Training loss: 1.609038308488329
Validation loss: 2.2342690711566364

Epoch: 6| Step: 7
Training loss: 2.0496566159224283
Validation loss: 2.2745234411189466

Epoch: 6| Step: 8
Training loss: 1.3138189954270931
Validation loss: 2.1703920788366644

Epoch: 6| Step: 9
Training loss: 0.9968569356304048
Validation loss: 2.2104107675617373

Epoch: 6| Step: 10
Training loss: 1.5000050862543974
Validation loss: 2.2002469244688223

Epoch: 6| Step: 11
Training loss: 1.9779237424848322
Validation loss: 2.1888422292176015

Epoch: 6| Step: 12
Training loss: 1.298908202492109
Validation loss: 2.198268575469818

Epoch: 6| Step: 13
Training loss: 1.7934289146439855
Validation loss: 2.2138899280313735

Epoch: 315| Step: 0
Training loss: 1.3518616890924353
Validation loss: 2.2072997279556823

Epoch: 6| Step: 1
Training loss: 1.4347514537399113
Validation loss: 2.1407471027584806

Epoch: 6| Step: 2
Training loss: 2.090587447988136
Validation loss: 2.2248327969236517

Epoch: 6| Step: 3
Training loss: 1.3264744094698064
Validation loss: 2.146886997165795

Epoch: 6| Step: 4
Training loss: 1.5120582692155662
Validation loss: 2.250848581067046

Epoch: 6| Step: 5
Training loss: 1.2507688541977549
Validation loss: 2.2005440209007996

Epoch: 6| Step: 6
Training loss: 1.50186002167445
Validation loss: 2.2601434168120513

Epoch: 6| Step: 7
Training loss: 1.041782518938013
Validation loss: 2.2212359142032856

Epoch: 6| Step: 8
Training loss: 1.4224082030861132
Validation loss: 2.1986440871910746

Epoch: 6| Step: 9
Training loss: 1.516051242314629
Validation loss: 2.1479202366757644

Epoch: 6| Step: 10
Training loss: 1.1897822583966045
Validation loss: 2.2128823104076747

Epoch: 6| Step: 11
Training loss: 2.0042337666763315
Validation loss: 2.1977581073313397

Epoch: 6| Step: 12
Training loss: 1.3044372592721278
Validation loss: 2.219314096770935

Epoch: 6| Step: 13
Training loss: 0.7571525846547923
Validation loss: 2.157041365525433

Epoch: 316| Step: 0
Training loss: 1.6654224838041989
Validation loss: 2.2111519040278798

Epoch: 6| Step: 1
Training loss: 1.4580365923566112
Validation loss: 2.130552367035769

Epoch: 6| Step: 2
Training loss: 1.2247906175065915
Validation loss: 2.200190093617858

Epoch: 6| Step: 3
Training loss: 1.3448865652642772
Validation loss: 2.245567787654707

Epoch: 6| Step: 4
Training loss: 1.3062133546644468
Validation loss: 2.192102985642927

Epoch: 6| Step: 5
Training loss: 1.4803368502114627
Validation loss: 2.2540529407068384

Epoch: 6| Step: 6
Training loss: 1.3172784739942827
Validation loss: 2.159573495653352

Epoch: 6| Step: 7
Training loss: 1.8981938460861514
Validation loss: 2.1539781874479265

Epoch: 6| Step: 8
Training loss: 1.1832943780065772
Validation loss: 2.246367715799308

Epoch: 6| Step: 9
Training loss: 1.4123047077578308
Validation loss: 2.180820059851134

Epoch: 6| Step: 10
Training loss: 1.8434609655350493
Validation loss: 2.236976825712361

Epoch: 6| Step: 11
Training loss: 1.5761331508563976
Validation loss: 2.186144913897658

Epoch: 6| Step: 12
Training loss: 1.5849830498977378
Validation loss: 2.2058969939829955

Epoch: 6| Step: 13
Training loss: 1.1784551385587747
Validation loss: 2.1864569021379157

Epoch: 317| Step: 0
Training loss: 1.0952139185622207
Validation loss: 2.1561252783226568

Epoch: 6| Step: 1
Training loss: 1.1562088623976805
Validation loss: 2.1828401838371874

Epoch: 6| Step: 2
Training loss: 1.1443576095151375
Validation loss: 2.1882550965253977

Epoch: 6| Step: 3
Training loss: 1.51108673841948
Validation loss: 2.1944917118005702

Epoch: 6| Step: 4
Training loss: 1.0260476178353282
Validation loss: 2.1663878437356985

Epoch: 6| Step: 5
Training loss: 1.9037807293301012
Validation loss: 2.2042229060099667

Epoch: 6| Step: 6
Training loss: 0.9529316502805192
Validation loss: 2.197932716602238

Epoch: 6| Step: 7
Training loss: 1.295853269777332
Validation loss: 2.12783234322437

Epoch: 6| Step: 8
Training loss: 1.1443339623718873
Validation loss: 2.1818008918483427

Epoch: 6| Step: 9
Training loss: 1.1071224716173158
Validation loss: 2.16808259889178

Epoch: 6| Step: 10
Training loss: 1.6614487586946352
Validation loss: 2.1807983651574134

Epoch: 6| Step: 11
Training loss: 1.2914260927350145
Validation loss: 2.149858274698928

Epoch: 6| Step: 12
Training loss: 2.3639714013578903
Validation loss: 2.1266383961394775

Epoch: 6| Step: 13
Training loss: 1.4917896798982433
Validation loss: 2.1756631684353787

Epoch: 318| Step: 0
Training loss: 1.140268087068413
Validation loss: 2.1548725518114114

Epoch: 6| Step: 1
Training loss: 1.147983227627212
Validation loss: 2.1875707834631286

Epoch: 6| Step: 2
Training loss: 1.0748870435408877
Validation loss: 2.1459094244224217

Epoch: 6| Step: 3
Training loss: 1.8746256136642991
Validation loss: 2.153087421906524

Epoch: 6| Step: 4
Training loss: 1.1488523188238422
Validation loss: 2.1847340349369753

Epoch: 6| Step: 5
Training loss: 1.3072835711751591
Validation loss: 2.2172503813172386

Epoch: 6| Step: 6
Training loss: 1.6213902213841058
Validation loss: 2.192849179829871

Epoch: 6| Step: 7
Training loss: 1.4758740793236425
Validation loss: 2.1684129834271904

Epoch: 6| Step: 8
Training loss: 0.8955796607095347
Validation loss: 2.215460017367604

Epoch: 6| Step: 9
Training loss: 1.2527023192379283
Validation loss: 2.1257378119498376

Epoch: 6| Step: 10
Training loss: 1.9750670554451155
Validation loss: 2.2333265397977593

Epoch: 6| Step: 11
Training loss: 1.8240038726832453
Validation loss: 2.1818896257199922

Epoch: 6| Step: 12
Training loss: 1.3731080824339839
Validation loss: 2.187361841482714

Epoch: 6| Step: 13
Training loss: 1.7235819779375219
Validation loss: 2.14755718434075

Epoch: 319| Step: 0
Training loss: 1.1960663257248056
Validation loss: 2.1145418038668016

Epoch: 6| Step: 1
Training loss: 1.0119189207972425
Validation loss: 2.141970496110662

Epoch: 6| Step: 2
Training loss: 1.1841780727802675
Validation loss: 2.1827718484626133

Epoch: 6| Step: 3
Training loss: 1.3768799674437582
Validation loss: 2.108979350075271

Epoch: 6| Step: 4
Training loss: 1.4024898697322339
Validation loss: 2.1642484347000988

Epoch: 6| Step: 5
Training loss: 1.2661728791591664
Validation loss: 2.156789727867215

Epoch: 6| Step: 6
Training loss: 2.5452996747166234
Validation loss: 2.188464401882046

Epoch: 6| Step: 7
Training loss: 1.8012241968957974
Validation loss: 2.2688520205579596

Epoch: 6| Step: 8
Training loss: 1.3083783328260892
Validation loss: 2.1612096835967503

Epoch: 6| Step: 9
Training loss: 1.4616819718595186
Validation loss: 2.09677223394001

Epoch: 6| Step: 10
Training loss: 1.5008030966777617
Validation loss: 2.1951313757876827

Epoch: 6| Step: 11
Training loss: 1.1720394782034464
Validation loss: 2.1556883031751064

Epoch: 6| Step: 12
Training loss: 1.2623094528228702
Validation loss: 2.149166865041667

Epoch: 6| Step: 13
Training loss: 0.5532661010167865
Validation loss: 2.1751688858053053

Epoch: 320| Step: 0
Training loss: 1.484429689704894
Validation loss: 2.156186815512843

Epoch: 6| Step: 1
Training loss: 2.0003306592353316
Validation loss: 2.158952897167939

Epoch: 6| Step: 2
Training loss: 1.1438684204165785
Validation loss: 2.2355620712216733

Epoch: 6| Step: 3
Training loss: 1.2156911758415132
Validation loss: 2.194970526546778

Epoch: 6| Step: 4
Training loss: 1.848568584215061
Validation loss: 2.148686732717102

Epoch: 6| Step: 5
Training loss: 1.5559262655189319
Validation loss: 2.207543983326498

Epoch: 6| Step: 6
Training loss: 1.5814305801713595
Validation loss: 2.198956539301985

Epoch: 6| Step: 7
Training loss: 1.2048869421856152
Validation loss: 2.1253576586940555

Epoch: 6| Step: 8
Training loss: 1.225509774930546
Validation loss: 2.1681158064514334

Epoch: 6| Step: 9
Training loss: 0.888615097076575
Validation loss: 2.1658049414700544

Epoch: 6| Step: 10
Training loss: 1.2490332679868714
Validation loss: 2.192330648797118

Epoch: 6| Step: 11
Training loss: 0.9197903354818029
Validation loss: 2.1149216975308383

Epoch: 6| Step: 12
Training loss: 1.4538361644712205
Validation loss: 2.2213746895460154

Epoch: 6| Step: 13
Training loss: 1.5488788456927944
Validation loss: 2.167870138405752

Epoch: 321| Step: 0
Training loss: 1.2302962893773848
Validation loss: 2.1411663281441293

Epoch: 6| Step: 1
Training loss: 0.881676677461938
Validation loss: 2.1388734915856156

Epoch: 6| Step: 2
Training loss: 1.3946882314507005
Validation loss: 2.1705103680273874

Epoch: 6| Step: 3
Training loss: 1.4130010256402463
Validation loss: 2.13943797278526

Epoch: 6| Step: 4
Training loss: 1.206136427360371
Validation loss: 2.194413269357706

Epoch: 6| Step: 5
Training loss: 1.5455972037031416
Validation loss: 2.1384821052920713

Epoch: 6| Step: 6
Training loss: 2.3602596418153294
Validation loss: 2.2177857217726498

Epoch: 6| Step: 7
Training loss: 0.7750525902778344
Validation loss: 2.2014157947987787

Epoch: 6| Step: 8
Training loss: 1.3821662211564438
Validation loss: 2.149688372071554

Epoch: 6| Step: 9
Training loss: 1.3449841974882921
Validation loss: 2.249480186312325

Epoch: 6| Step: 10
Training loss: 1.4382783192486097
Validation loss: 2.1019287442876076

Epoch: 6| Step: 11
Training loss: 1.7695678976613454
Validation loss: 2.175398451983974

Epoch: 6| Step: 12
Training loss: 1.684893042568468
Validation loss: 2.174480809360999

Epoch: 6| Step: 13
Training loss: 1.4264436202221114
Validation loss: 2.214502985543435

Epoch: 322| Step: 0
Training loss: 1.7150575682650944
Validation loss: 2.11639004766557

Epoch: 6| Step: 1
Training loss: 1.1473916929738543
Validation loss: 2.17000391054035

Epoch: 6| Step: 2
Training loss: 1.4008446546630744
Validation loss: 2.1439380987643655

Epoch: 6| Step: 3
Training loss: 1.431746537478966
Validation loss: 2.138370985006353

Epoch: 6| Step: 4
Training loss: 1.265289215001769
Validation loss: 2.187827421843177

Epoch: 6| Step: 5
Training loss: 0.9533121831977551
Validation loss: 2.1805063256971846

Epoch: 6| Step: 6
Training loss: 1.2775972913807705
Validation loss: 2.1387682206913152

Epoch: 6| Step: 7
Training loss: 1.3742623517968329
Validation loss: 2.189304350081719

Epoch: 6| Step: 8
Training loss: 1.2854095951341262
Validation loss: 2.2304738118331002

Epoch: 6| Step: 9
Training loss: 1.382095064595097
Validation loss: 2.1824371605005473

Epoch: 6| Step: 10
Training loss: 2.1554363761259805
Validation loss: 2.2045346575506612

Epoch: 6| Step: 11
Training loss: 1.9472083845688373
Validation loss: 2.2079703550636616

Epoch: 6| Step: 12
Training loss: 0.6399815747469805
Validation loss: 2.2288005882096864

Epoch: 6| Step: 13
Training loss: 1.6482062154931594
Validation loss: 2.15930834539511

Epoch: 323| Step: 0
Training loss: 1.4807052222145312
Validation loss: 2.1761764703821447

Epoch: 6| Step: 1
Training loss: 1.5314734159697392
Validation loss: 2.2042398709004614

Epoch: 6| Step: 2
Training loss: 1.4589121441917656
Validation loss: 2.081300928720255

Epoch: 6| Step: 3
Training loss: 2.074658018679275
Validation loss: 2.1691056120295533

Epoch: 6| Step: 4
Training loss: 1.5164803519757408
Validation loss: 2.157480140133305

Epoch: 6| Step: 5
Training loss: 1.3755764619825082
Validation loss: 2.181185937061709

Epoch: 6| Step: 6
Training loss: 1.6820140251273465
Validation loss: 2.1469535217527307

Epoch: 6| Step: 7
Training loss: 1.2958754858702497
Validation loss: 2.1955664924996805

Epoch: 6| Step: 8
Training loss: 1.5636998719399464
Validation loss: 2.1503757704557716

Epoch: 6| Step: 9
Training loss: 0.9269094232609253
Validation loss: 2.188654076869496

Epoch: 6| Step: 10
Training loss: 1.3347837585878626
Validation loss: 2.195041090130567

Epoch: 6| Step: 11
Training loss: 0.8725734169356811
Validation loss: 2.151456732107353

Epoch: 6| Step: 12
Training loss: 1.1483382097776504
Validation loss: 2.1557924784833324

Epoch: 6| Step: 13
Training loss: 1.0835640857159274
Validation loss: 2.1817042215295954

Epoch: 324| Step: 0
Training loss: 1.0418288613248183
Validation loss: 2.1429870061569414

Epoch: 6| Step: 1
Training loss: 0.9402370552687247
Validation loss: 2.176757241299169

Epoch: 6| Step: 2
Training loss: 1.228958607969088
Validation loss: 2.163081339599268

Epoch: 6| Step: 3
Training loss: 1.9859897921781018
Validation loss: 2.184006279196253

Epoch: 6| Step: 4
Training loss: 1.3902305300713813
Validation loss: 2.2021851307566567

Epoch: 6| Step: 5
Training loss: 1.2920557584570551
Validation loss: 2.119012230433732

Epoch: 6| Step: 6
Training loss: 1.3085477906312424
Validation loss: 2.2127659138410536

Epoch: 6| Step: 7
Training loss: 1.0758028314956363
Validation loss: 2.1866405023208277

Epoch: 6| Step: 8
Training loss: 1.4356485966564607
Validation loss: 2.204842523930297

Epoch: 6| Step: 9
Training loss: 1.5317572707123035
Validation loss: 2.2385357411039983

Epoch: 6| Step: 10
Training loss: 1.5459694571938651
Validation loss: 2.225957322287086

Epoch: 6| Step: 11
Training loss: 1.7218203776534973
Validation loss: 2.2754252949805145

Epoch: 6| Step: 12
Training loss: 1.4796668626258505
Validation loss: 2.196439000115268

Epoch: 6| Step: 13
Training loss: 0.9576409713713868
Validation loss: 2.156318502956433

Epoch: 325| Step: 0
Training loss: 0.9212870905331212
Validation loss: 2.2042987192693086

Epoch: 6| Step: 1
Training loss: 1.0921046824565595
Validation loss: 2.22718381475943

Epoch: 6| Step: 2
Training loss: 1.5010361271830344
Validation loss: 2.2179151862628896

Epoch: 6| Step: 3
Training loss: 1.1806785008357759
Validation loss: 2.1993842092112814

Epoch: 6| Step: 4
Training loss: 1.3508267908488942
Validation loss: 2.2050109406605056

Epoch: 6| Step: 5
Training loss: 1.1451214515207153
Validation loss: 2.16318496273362

Epoch: 6| Step: 6
Training loss: 1.0402108637079082
Validation loss: 2.123068238495294

Epoch: 6| Step: 7
Training loss: 1.4539609575919783
Validation loss: 2.1050832509156203

Epoch: 6| Step: 8
Training loss: 1.3781919709625665
Validation loss: 2.1579138679304797

Epoch: 6| Step: 9
Training loss: 1.630219220824849
Validation loss: 2.213345623178062

Epoch: 6| Step: 10
Training loss: 1.4524539505557852
Validation loss: 2.1360345094213704

Epoch: 6| Step: 11
Training loss: 2.122126262996298
Validation loss: 2.147421947611151

Epoch: 6| Step: 12
Training loss: 1.1294688370632873
Validation loss: 2.0992482264388146

Epoch: 6| Step: 13
Training loss: 2.1502118915560082
Validation loss: 2.1388828190227

Epoch: 326| Step: 0
Training loss: 2.018520198060457
Validation loss: 2.1801929897022436

Epoch: 6| Step: 1
Training loss: 1.4169490289720925
Validation loss: 2.1590396431274272

Epoch: 6| Step: 2
Training loss: 1.5733537214111208
Validation loss: 2.186651397505952

Epoch: 6| Step: 3
Training loss: 1.3217072202290316
Validation loss: 2.1591247886142364

Epoch: 6| Step: 4
Training loss: 0.9660410074430982
Validation loss: 2.220847645378144

Epoch: 6| Step: 5
Training loss: 1.0898681419131409
Validation loss: 2.2418871348209253

Epoch: 6| Step: 6
Training loss: 1.8988439179850392
Validation loss: 2.171576364246604

Epoch: 6| Step: 7
Training loss: 1.072650333174288
Validation loss: 2.1699762490858583

Epoch: 6| Step: 8
Training loss: 1.4561250952334934
Validation loss: 2.2235884087290008

Epoch: 6| Step: 9
Training loss: 1.5916651384569325
Validation loss: 2.225366516085792

Epoch: 6| Step: 10
Training loss: 0.9760655473836307
Validation loss: 2.11737253719795

Epoch: 6| Step: 11
Training loss: 1.22305213442183
Validation loss: 2.1993611129628508

Epoch: 6| Step: 12
Training loss: 1.2496247682043655
Validation loss: 2.193876818032721

Epoch: 6| Step: 13
Training loss: 1.3341465595897664
Validation loss: 2.1730041566834886

Epoch: 327| Step: 0
Training loss: 1.437922042590497
Validation loss: 2.130043662663272

Epoch: 6| Step: 1
Training loss: 1.853349877233329
Validation loss: 2.156216766638715

Epoch: 6| Step: 2
Training loss: 1.7341207369444906
Validation loss: 2.1644322546004977

Epoch: 6| Step: 3
Training loss: 1.2750800836881249
Validation loss: 2.1720700044009504

Epoch: 6| Step: 4
Training loss: 1.6573714292438726
Validation loss: 2.2044965456885883

Epoch: 6| Step: 5
Training loss: 0.693092746242156
Validation loss: 2.138523853555221

Epoch: 6| Step: 6
Training loss: 1.1450039665286729
Validation loss: 2.1828151479040803

Epoch: 6| Step: 7
Training loss: 1.1886047444612984
Validation loss: 2.1908214684442293

Epoch: 6| Step: 8
Training loss: 1.297758421989425
Validation loss: 2.186971643396726

Epoch: 6| Step: 9
Training loss: 1.2928190115805467
Validation loss: 2.136300714690861

Epoch: 6| Step: 10
Training loss: 1.4545742724284036
Validation loss: 2.166252689080018

Epoch: 6| Step: 11
Training loss: 1.2188521122337124
Validation loss: 2.16272549382682

Epoch: 6| Step: 12
Training loss: 1.4509906475940904
Validation loss: 2.0901664330660803

Epoch: 6| Step: 13
Training loss: 1.372095073870208
Validation loss: 2.1943433059498645

Epoch: 328| Step: 0
Training loss: 1.7211459019915722
Validation loss: 2.1914454528602203

Epoch: 6| Step: 1
Training loss: 1.3369782615611994
Validation loss: 2.090001502536234

Epoch: 6| Step: 2
Training loss: 1.1933094270183404
Validation loss: 2.1489629621593425

Epoch: 6| Step: 3
Training loss: 0.8700235061648907
Validation loss: 2.2493917025767507

Epoch: 6| Step: 4
Training loss: 1.340913617915548
Validation loss: 2.2115226228469

Epoch: 6| Step: 5
Training loss: 1.6123735954952236
Validation loss: 2.1686281876958664

Epoch: 6| Step: 6
Training loss: 1.4353596883168243
Validation loss: 2.2238141676669207

Epoch: 6| Step: 7
Training loss: 1.4003112855619524
Validation loss: 2.2381806540959497

Epoch: 6| Step: 8
Training loss: 1.5296970978884847
Validation loss: 2.1933208784317104

Epoch: 6| Step: 9
Training loss: 1.1911609334562627
Validation loss: 2.1767143584104027

Epoch: 6| Step: 10
Training loss: 2.1518704816564167
Validation loss: 2.165810872338329

Epoch: 6| Step: 11
Training loss: 1.3385063592234594
Validation loss: 2.155557487653467

Epoch: 6| Step: 12
Training loss: 1.0984600558617188
Validation loss: 2.148474506197434

Epoch: 6| Step: 13
Training loss: 1.2397349876576436
Validation loss: 2.1932989076408163

Epoch: 329| Step: 0
Training loss: 1.6386393565428474
Validation loss: 2.1390180556979375

Epoch: 6| Step: 1
Training loss: 1.467605307080833
Validation loss: 2.182602948706705

Epoch: 6| Step: 2
Training loss: 1.2055219577955576
Validation loss: 2.220211877949015

Epoch: 6| Step: 3
Training loss: 1.6460890108609698
Validation loss: 2.2199404081099057

Epoch: 6| Step: 4
Training loss: 1.2370783501731664
Validation loss: 2.151519426366893

Epoch: 6| Step: 5
Training loss: 1.5643657226531258
Validation loss: 2.271209088121819

Epoch: 6| Step: 6
Training loss: 2.0642794244569527
Validation loss: 2.1920904580394622

Epoch: 6| Step: 7
Training loss: 0.983220164742807
Validation loss: 2.1828164953089737

Epoch: 6| Step: 8
Training loss: 0.9424291411559843
Validation loss: 2.1825626902110464

Epoch: 6| Step: 9
Training loss: 1.6288538496705056
Validation loss: 2.173919387179924

Epoch: 6| Step: 10
Training loss: 1.1428614599282607
Validation loss: 2.1636299828562393

Epoch: 6| Step: 11
Training loss: 1.367499223321837
Validation loss: 2.1527078242938114

Epoch: 6| Step: 12
Training loss: 1.2782955531555862
Validation loss: 2.1671258729261815

Epoch: 6| Step: 13
Training loss: 0.6864146204697907
Validation loss: 2.200899739830448

Epoch: 330| Step: 0
Training loss: 1.0528737048517383
Validation loss: 2.1353851888293938

Epoch: 6| Step: 1
Training loss: 1.3764826843469578
Validation loss: 2.146219202319317

Epoch: 6| Step: 2
Training loss: 1.3783428564899687
Validation loss: 2.1948378911897946

Epoch: 6| Step: 3
Training loss: 0.8892757837066066
Validation loss: 2.190177961791369

Epoch: 6| Step: 4
Training loss: 1.3294218127388737
Validation loss: 2.116501053798876

Epoch: 6| Step: 5
Training loss: 1.4391378111708504
Validation loss: 2.1945274273819626

Epoch: 6| Step: 6
Training loss: 0.8786170992461435
Validation loss: 2.20071881801557

Epoch: 6| Step: 7
Training loss: 1.470604638681368
Validation loss: 2.1820967789853376

Epoch: 6| Step: 8
Training loss: 1.1948224727491585
Validation loss: 2.171996790688491

Epoch: 6| Step: 9
Training loss: 2.3057227961335385
Validation loss: 2.1595465778782406

Epoch: 6| Step: 10
Training loss: 1.6839997052172042
Validation loss: 2.227622809654765

Epoch: 6| Step: 11
Training loss: 1.1483235205317344
Validation loss: 2.171318855886292

Epoch: 6| Step: 12
Training loss: 1.6036491384923346
Validation loss: 2.127322443709657

Epoch: 6| Step: 13
Training loss: 0.9446611288303648
Validation loss: 2.1999105536455192

Epoch: 331| Step: 0
Training loss: 1.6070921178407385
Validation loss: 2.189622951093849

Epoch: 6| Step: 1
Training loss: 2.061059737900525
Validation loss: 2.191592534252319

Epoch: 6| Step: 2
Training loss: 1.1156236600467104
Validation loss: 2.1559725251911055

Epoch: 6| Step: 3
Training loss: 1.5340977870902575
Validation loss: 2.205386944276843

Epoch: 6| Step: 4
Training loss: 1.02187134395027
Validation loss: 2.232297265614426

Epoch: 6| Step: 5
Training loss: 1.7951087563808237
Validation loss: 2.1127489155811334

Epoch: 6| Step: 6
Training loss: 1.001001631260018
Validation loss: 2.175857074559466

Epoch: 6| Step: 7
Training loss: 1.3533065216026832
Validation loss: 2.1507910367146916

Epoch: 6| Step: 8
Training loss: 1.522777707935214
Validation loss: 2.182245495487636

Epoch: 6| Step: 9
Training loss: 1.2369114372048466
Validation loss: 2.081810258105272

Epoch: 6| Step: 10
Training loss: 1.2880528975754508
Validation loss: 2.191260962489995

Epoch: 6| Step: 11
Training loss: 1.0985482823383503
Validation loss: 2.102867785446628

Epoch: 6| Step: 12
Training loss: 1.2687063500924447
Validation loss: 2.1383877314335384

Epoch: 6| Step: 13
Training loss: 0.6063781799409173
Validation loss: 2.179818608614766

Epoch: 332| Step: 0
Training loss: 1.3433789916518297
Validation loss: 2.1641298743146766

Epoch: 6| Step: 1
Training loss: 2.357762271859279
Validation loss: 2.1448387587345428

Epoch: 6| Step: 2
Training loss: 0.9183116515889198
Validation loss: 2.1879476719084026

Epoch: 6| Step: 3
Training loss: 1.0061006423327845
Validation loss: 2.0990435469674122

Epoch: 6| Step: 4
Training loss: 0.8665209433726023
Validation loss: 2.1928672346151843

Epoch: 6| Step: 5
Training loss: 1.429892103219458
Validation loss: 2.1321490851391376

Epoch: 6| Step: 6
Training loss: 1.0239205421673907
Validation loss: 2.1489450192731083

Epoch: 6| Step: 7
Training loss: 1.3721977636257063
Validation loss: 2.189076459440975

Epoch: 6| Step: 8
Training loss: 0.9172104320876135
Validation loss: 2.225194871753764

Epoch: 6| Step: 9
Training loss: 1.3935460903701833
Validation loss: 2.1340613092962664

Epoch: 6| Step: 10
Training loss: 2.0101202975281525
Validation loss: 2.1461751299077134

Epoch: 6| Step: 11
Training loss: 1.3952730914421212
Validation loss: 2.088322453633485

Epoch: 6| Step: 12
Training loss: 1.4626730335610516
Validation loss: 2.155879122699053

Epoch: 6| Step: 13
Training loss: 1.0601714367154758
Validation loss: 2.104443427332491

Epoch: 333| Step: 0
Training loss: 1.1691291683615814
Validation loss: 2.1897512152509337

Epoch: 6| Step: 1
Training loss: 1.3903395113268529
Validation loss: 2.1183454945057383

Epoch: 6| Step: 2
Training loss: 0.8349243512977592
Validation loss: 2.1639794537753523

Epoch: 6| Step: 3
Training loss: 1.1164953048135833
Validation loss: 2.111757652048187

Epoch: 6| Step: 4
Training loss: 1.3001182172283108
Validation loss: 2.200332543451428

Epoch: 6| Step: 5
Training loss: 1.6439532716333407
Validation loss: 2.1690017735619205

Epoch: 6| Step: 6
Training loss: 1.5402798558136972
Validation loss: 2.169097490077661

Epoch: 6| Step: 7
Training loss: 1.1726552781540047
Validation loss: 2.058091743715516

Epoch: 6| Step: 8
Training loss: 2.078068782648322
Validation loss: 2.1850905665958757

Epoch: 6| Step: 9
Training loss: 1.258108732039692
Validation loss: 2.1856296940798745

Epoch: 6| Step: 10
Training loss: 1.0479121977228592
Validation loss: 2.1833330538456046

Epoch: 6| Step: 11
Training loss: 1.4520177416807831
Validation loss: 2.1768684130003146

Epoch: 6| Step: 12
Training loss: 1.2305364680956654
Validation loss: 2.155827071658922

Epoch: 6| Step: 13
Training loss: 0.8738165413400367
Validation loss: 2.210982100737213

Epoch: 334| Step: 0
Training loss: 0.8225762149898395
Validation loss: 2.14577403008001

Epoch: 6| Step: 1
Training loss: 1.2367243561223022
Validation loss: 2.1267241264263967

Epoch: 6| Step: 2
Training loss: 0.9544189300119466
Validation loss: 2.17813665955647

Epoch: 6| Step: 3
Training loss: 1.8894478151736946
Validation loss: 2.1968038543442923

Epoch: 6| Step: 4
Training loss: 1.1661585427881256
Validation loss: 2.123274214573814

Epoch: 6| Step: 5
Training loss: 1.982425663385389
Validation loss: 2.192124409409794

Epoch: 6| Step: 6
Training loss: 1.4585762729833869
Validation loss: 2.1674036367220384

Epoch: 6| Step: 7
Training loss: 1.0822049218454497
Validation loss: 2.202538354516959

Epoch: 6| Step: 8
Training loss: 1.05461052507733
Validation loss: 2.1674949083087363

Epoch: 6| Step: 9
Training loss: 1.3058727614035872
Validation loss: 2.152044527344271

Epoch: 6| Step: 10
Training loss: 1.649809496892777
Validation loss: 2.221355593505035

Epoch: 6| Step: 11
Training loss: 1.3283176058065902
Validation loss: 2.190118969278861

Epoch: 6| Step: 12
Training loss: 1.1388119436390074
Validation loss: 2.1662076455164576

Epoch: 6| Step: 13
Training loss: 1.3567057744668443
Validation loss: 2.1935583679679715

Epoch: 335| Step: 0
Training loss: 1.187330233836711
Validation loss: 2.2194403504950233

Epoch: 6| Step: 1
Training loss: 1.960907286149051
Validation loss: 2.1459161808337712

Epoch: 6| Step: 2
Training loss: 1.3767848568090737
Validation loss: 2.1755919940197748

Epoch: 6| Step: 3
Training loss: 1.4851495428601096
Validation loss: 2.1724792552329366

Epoch: 6| Step: 4
Training loss: 0.9049213469559015
Validation loss: 2.1601720614762234

Epoch: 6| Step: 5
Training loss: 1.5888433284644543
Validation loss: 2.1198169176332646

Epoch: 6| Step: 6
Training loss: 1.005600505219957
Validation loss: 2.1746538562298063

Epoch: 6| Step: 7
Training loss: 1.516402919948406
Validation loss: 2.2323317326505907

Epoch: 6| Step: 8
Training loss: 1.344199172066614
Validation loss: 2.2613666825803405

Epoch: 6| Step: 9
Training loss: 1.0101642227743302
Validation loss: 2.1304521986460894

Epoch: 6| Step: 10
Training loss: 1.42608831574086
Validation loss: 2.1890345205612998

Epoch: 6| Step: 11
Training loss: 1.5641909033080257
Validation loss: 2.1785466635660695

Epoch: 6| Step: 12
Training loss: 1.390472660935819
Validation loss: 2.1593811024622536

Epoch: 6| Step: 13
Training loss: 1.0341674688696278
Validation loss: 2.175869029935748

Epoch: 336| Step: 0
Training loss: 1.3707630595521383
Validation loss: 2.12443049265275

Epoch: 6| Step: 1
Training loss: 0.9708768201810695
Validation loss: 2.211984464560902

Epoch: 6| Step: 2
Training loss: 0.8106723918017246
Validation loss: 2.171257182591184

Epoch: 6| Step: 3
Training loss: 2.1505542661680033
Validation loss: 2.1756897336344916

Epoch: 6| Step: 4
Training loss: 0.9648778808981681
Validation loss: 2.1934012972234194

Epoch: 6| Step: 5
Training loss: 1.141960303049206
Validation loss: 2.2164784608848875

Epoch: 6| Step: 6
Training loss: 1.285854068983647
Validation loss: 2.14823056355206

Epoch: 6| Step: 7
Training loss: 1.6140940099042675
Validation loss: 2.1688141647861077

Epoch: 6| Step: 8
Training loss: 1.0702978536898493
Validation loss: 2.148402061729467

Epoch: 6| Step: 9
Training loss: 1.5463043084934258
Validation loss: 2.1318294731793235

Epoch: 6| Step: 10
Training loss: 1.6471277611193964
Validation loss: 2.202823084991632

Epoch: 6| Step: 11
Training loss: 0.9354323155737423
Validation loss: 2.2333735843555154

Epoch: 6| Step: 12
Training loss: 1.4242944777837168
Validation loss: 2.170811101375139

Epoch: 6| Step: 13
Training loss: 1.083665185621273
Validation loss: 2.1749536406442327

Epoch: 337| Step: 0
Training loss: 1.5971811796065911
Validation loss: 2.183444963886197

Epoch: 6| Step: 1
Training loss: 1.569287321314481
Validation loss: 2.0987648387839912

Epoch: 6| Step: 2
Training loss: 1.1181361299049322
Validation loss: 2.1708190256009074

Epoch: 6| Step: 3
Training loss: 2.012719596112907
Validation loss: 2.1693940504300984

Epoch: 6| Step: 4
Training loss: 1.2224257376802348
Validation loss: 2.1485197437463435

Epoch: 6| Step: 5
Training loss: 0.9888897858007224
Validation loss: 2.2166197361566846

Epoch: 6| Step: 6
Training loss: 1.1749634290644866
Validation loss: 2.1317817787421824

Epoch: 6| Step: 7
Training loss: 0.898059002303664
Validation loss: 2.132703064707972

Epoch: 6| Step: 8
Training loss: 1.6537346363002725
Validation loss: 2.1408655749858587

Epoch: 6| Step: 9
Training loss: 1.1314619761444453
Validation loss: 2.1512743799104275

Epoch: 6| Step: 10
Training loss: 0.9362113997647318
Validation loss: 2.1579088396382047

Epoch: 6| Step: 11
Training loss: 1.210510473944231
Validation loss: 2.1929235397826936

Epoch: 6| Step: 12
Training loss: 1.2199799127175772
Validation loss: 2.0952258405505506

Epoch: 6| Step: 13
Training loss: 1.4512582909793248
Validation loss: 2.1892149805058105

Epoch: 338| Step: 0
Training loss: 1.0922693311954323
Validation loss: 2.131130137501343

Epoch: 6| Step: 1
Training loss: 1.294894671262258
Validation loss: 2.1450422968276035

Epoch: 6| Step: 2
Training loss: 1.5465082832062798
Validation loss: 2.1409107781269707

Epoch: 6| Step: 3
Training loss: 1.0731710977934321
Validation loss: 2.1898187849360453

Epoch: 6| Step: 4
Training loss: 1.0860785523065979
Validation loss: 2.0912574743679846

Epoch: 6| Step: 5
Training loss: 1.0438779375621714
Validation loss: 2.167801930709885

Epoch: 6| Step: 6
Training loss: 1.2056215813619457
Validation loss: 2.1993988152237693

Epoch: 6| Step: 7
Training loss: 1.2799051251119045
Validation loss: 2.177272883957533

Epoch: 6| Step: 8
Training loss: 0.9612030034674345
Validation loss: 2.0996063468970414

Epoch: 6| Step: 9
Training loss: 1.418467368319692
Validation loss: 2.1955070189008943

Epoch: 6| Step: 10
Training loss: 1.3386441301643655
Validation loss: 2.1384116606677126

Epoch: 6| Step: 11
Training loss: 1.3515444186550194
Validation loss: 2.185309935464996

Epoch: 6| Step: 12
Training loss: 2.2167324510531263
Validation loss: 2.1381849587889707

Epoch: 6| Step: 13
Training loss: 1.8157864733539528
Validation loss: 2.158532088122227

Epoch: 339| Step: 0
Training loss: 1.1459212991876382
Validation loss: 2.1526381941456028

Epoch: 6| Step: 1
Training loss: 0.9871913644896747
Validation loss: 2.1922854160187146

Epoch: 6| Step: 2
Training loss: 1.3501075013062156
Validation loss: 2.1967210334953906

Epoch: 6| Step: 3
Training loss: 1.337578730182278
Validation loss: 2.132166830903234

Epoch: 6| Step: 4
Training loss: 1.016085945579266
Validation loss: 2.1456952881446987

Epoch: 6| Step: 5
Training loss: 1.5030391422740819
Validation loss: 2.106769304148075

Epoch: 6| Step: 6
Training loss: 1.550886020916714
Validation loss: 2.1986816288893114

Epoch: 6| Step: 7
Training loss: 1.166081718986937
Validation loss: 2.174884031667345

Epoch: 6| Step: 8
Training loss: 0.9893458365831025
Validation loss: 2.1188099611058124

Epoch: 6| Step: 9
Training loss: 1.5964762240155805
Validation loss: 2.275541105245267

Epoch: 6| Step: 10
Training loss: 1.5332793198622634
Validation loss: 2.147905686112707

Epoch: 6| Step: 11
Training loss: 1.3615665965777064
Validation loss: 2.2181867880934463

Epoch: 6| Step: 12
Training loss: 1.1129769963563196
Validation loss: 2.1884352939074803

Epoch: 6| Step: 13
Training loss: 2.512658876168972
Validation loss: 2.2230385573856926

Epoch: 340| Step: 0
Training loss: 1.539491854966693
Validation loss: 2.1553909994753457

Epoch: 6| Step: 1
Training loss: 1.1979445855024733
Validation loss: 2.192951942290387

Epoch: 6| Step: 2
Training loss: 1.4582342749966983
Validation loss: 2.1955638641308544

Epoch: 6| Step: 3
Training loss: 1.2048380657463167
Validation loss: 2.169162801375154

Epoch: 6| Step: 4
Training loss: 1.0626967191905952
Validation loss: 2.154680038104062

Epoch: 6| Step: 5
Training loss: 1.152953733218989
Validation loss: 2.1714816424434726

Epoch: 6| Step: 6
Training loss: 1.2070582118310025
Validation loss: 2.1549065678910453

Epoch: 6| Step: 7
Training loss: 1.1926799032273916
Validation loss: 2.111457314951318

Epoch: 6| Step: 8
Training loss: 1.6613932948601602
Validation loss: 2.1516738586707187

Epoch: 6| Step: 9
Training loss: 1.3152819170288637
Validation loss: 2.2461632239969536

Epoch: 6| Step: 10
Training loss: 1.9420027555216324
Validation loss: 2.1191661385760665

Epoch: 6| Step: 11
Training loss: 1.1778226348044163
Validation loss: 2.13224768353967

Epoch: 6| Step: 12
Training loss: 0.8945150915293976
Validation loss: 2.185008465665162

Epoch: 6| Step: 13
Training loss: 1.150415753800913
Validation loss: 2.1743240765847722

Epoch: 341| Step: 0
Training loss: 1.6015995672635037
Validation loss: 2.0864613309932314

Epoch: 6| Step: 1
Training loss: 1.2654739101317423
Validation loss: 2.155886558374402

Epoch: 6| Step: 2
Training loss: 1.1739392220070648
Validation loss: 2.162796456319695

Epoch: 6| Step: 3
Training loss: 1.3573841995389813
Validation loss: 2.2063610276368903

Epoch: 6| Step: 4
Training loss: 1.1934368401840476
Validation loss: 2.283611519929328

Epoch: 6| Step: 5
Training loss: 1.0731041136515889
Validation loss: 2.255155712272474

Epoch: 6| Step: 6
Training loss: 1.6449277132610565
Validation loss: 2.1877481990706316

Epoch: 6| Step: 7
Training loss: 1.1197800864870278
Validation loss: 2.162860227052375

Epoch: 6| Step: 8
Training loss: 1.390111935725917
Validation loss: 2.1716333141049144

Epoch: 6| Step: 9
Training loss: 1.1395180961909428
Validation loss: 2.1528573045211465

Epoch: 6| Step: 10
Training loss: 0.9834215905836367
Validation loss: 2.1594438539534293

Epoch: 6| Step: 11
Training loss: 0.8251721982709527
Validation loss: 2.12926773324441

Epoch: 6| Step: 12
Training loss: 2.0860397942423923
Validation loss: 2.1778736763212705

Epoch: 6| Step: 13
Training loss: 0.8224058416787156
Validation loss: 2.1232055915070145

Epoch: 342| Step: 0
Training loss: 1.077409921761958
Validation loss: 2.1864127279972294

Epoch: 6| Step: 1
Training loss: 1.5939004864423476
Validation loss: 2.1897180893514623

Epoch: 6| Step: 2
Training loss: 1.5026791805625195
Validation loss: 2.168698180990032

Epoch: 6| Step: 3
Training loss: 0.96865653540828
Validation loss: 2.1586409909752358

Epoch: 6| Step: 4
Training loss: 2.0820630842283676
Validation loss: 2.135218402853689

Epoch: 6| Step: 5
Training loss: 1.3200666209950755
Validation loss: 2.1904727337464154

Epoch: 6| Step: 6
Training loss: 0.9429576326361202
Validation loss: 2.1942788536649354

Epoch: 6| Step: 7
Training loss: 1.0326130846179071
Validation loss: 2.1820029879518223

Epoch: 6| Step: 8
Training loss: 1.0079079516253382
Validation loss: 2.217567993271089

Epoch: 6| Step: 9
Training loss: 0.9189683382269017
Validation loss: 2.1044675229579197

Epoch: 6| Step: 10
Training loss: 1.351969530854188
Validation loss: 2.1773101771673344

Epoch: 6| Step: 11
Training loss: 2.024226090223931
Validation loss: 2.17614519239032

Epoch: 6| Step: 12
Training loss: 0.8368775972948517
Validation loss: 2.1162607533229583

Epoch: 6| Step: 13
Training loss: 0.7438306989085376
Validation loss: 2.210404614799228

Epoch: 343| Step: 0
Training loss: 1.23404394611583
Validation loss: 2.1251131796087948

Epoch: 6| Step: 1
Training loss: 0.8391684722754693
Validation loss: 2.185442593050038

Epoch: 6| Step: 2
Training loss: 0.858846120216395
Validation loss: 2.1653425483060222

Epoch: 6| Step: 3
Training loss: 2.0140166260412804
Validation loss: 2.1257300235850356

Epoch: 6| Step: 4
Training loss: 1.1484455964717788
Validation loss: 2.2095751120064113

Epoch: 6| Step: 5
Training loss: 1.1435702198253979
Validation loss: 2.175236483004271

Epoch: 6| Step: 6
Training loss: 1.1773404653562862
Validation loss: 2.1283939367941165

Epoch: 6| Step: 7
Training loss: 1.2268301313438204
Validation loss: 2.1518499348625078

Epoch: 6| Step: 8
Training loss: 1.3448801389273914
Validation loss: 2.1538955843834873

Epoch: 6| Step: 9
Training loss: 1.443996345673901
Validation loss: 2.1889941551971517

Epoch: 6| Step: 10
Training loss: 1.4086086414161463
Validation loss: 2.148626875450387

Epoch: 6| Step: 11
Training loss: 1.0989265015437966
Validation loss: 2.230519021860624

Epoch: 6| Step: 12
Training loss: 1.8801713835941662
Validation loss: 2.1762622400206433

Epoch: 6| Step: 13
Training loss: 1.3533963237550735
Validation loss: 2.1556145110696456

Epoch: 344| Step: 0
Training loss: 1.3873336932890494
Validation loss: 2.1774145766251007

Epoch: 6| Step: 1
Training loss: 1.2198587900267763
Validation loss: 2.2050975276732427

Epoch: 6| Step: 2
Training loss: 1.3983557480086717
Validation loss: 2.232594662016391

Epoch: 6| Step: 3
Training loss: 1.057053575188354
Validation loss: 2.236131096888189

Epoch: 6| Step: 4
Training loss: 1.112993383835204
Validation loss: 2.163334030686451

Epoch: 6| Step: 5
Training loss: 1.2735346189570458
Validation loss: 2.1640326136300128

Epoch: 6| Step: 6
Training loss: 0.9108569350039386
Validation loss: 2.1474946597208855

Epoch: 6| Step: 7
Training loss: 1.3919523526483053
Validation loss: 2.2341809706626616

Epoch: 6| Step: 8
Training loss: 0.9218461953528393
Validation loss: 2.1432527204824203

Epoch: 6| Step: 9
Training loss: 0.9389956940866042
Validation loss: 2.1933885853515047

Epoch: 6| Step: 10
Training loss: 2.191593481758953
Validation loss: 2.1655688292940845

Epoch: 6| Step: 11
Training loss: 1.4673908519283463
Validation loss: 2.1539314149020776

Epoch: 6| Step: 12
Training loss: 1.8763385445314653
Validation loss: 2.203655631963656

Epoch: 6| Step: 13
Training loss: 0.9920810131690462
Validation loss: 2.1165727702889234

Epoch: 345| Step: 0
Training loss: 1.2537702445072054
Validation loss: 2.1457876691808995

Epoch: 6| Step: 1
Training loss: 0.8158749398391769
Validation loss: 2.1270458234720326

Epoch: 6| Step: 2
Training loss: 0.8690794505332129
Validation loss: 2.092101476484982

Epoch: 6| Step: 3
Training loss: 0.9705756735073793
Validation loss: 2.21416650474075

Epoch: 6| Step: 4
Training loss: 1.5118196044714571
Validation loss: 2.1913324796654376

Epoch: 6| Step: 5
Training loss: 1.061530175490345
Validation loss: 2.1809425829159235

Epoch: 6| Step: 6
Training loss: 1.4817187183335472
Validation loss: 2.1481433011429627

Epoch: 6| Step: 7
Training loss: 1.6394213666332573
Validation loss: 2.240945581933608

Epoch: 6| Step: 8
Training loss: 1.9321517962260801
Validation loss: 2.1314364476262093

Epoch: 6| Step: 9
Training loss: 1.2265913650129139
Validation loss: 2.184704624969129

Epoch: 6| Step: 10
Training loss: 1.2313015496166066
Validation loss: 2.1267017973212643

Epoch: 6| Step: 11
Training loss: 1.5028981186275951
Validation loss: 2.095799837456567

Epoch: 6| Step: 12
Training loss: 0.9803145389943051
Validation loss: 2.140025495702761

Epoch: 6| Step: 13
Training loss: 1.233407136066417
Validation loss: 2.131576752242917

Epoch: 346| Step: 0
Training loss: 1.9548153086104036
Validation loss: 2.162649571599064

Epoch: 6| Step: 1
Training loss: 1.3913027793970028
Validation loss: 2.150786184270813

Epoch: 6| Step: 2
Training loss: 0.8893530613866754
Validation loss: 2.1853869039814198

Epoch: 6| Step: 3
Training loss: 1.5273186176700628
Validation loss: 2.177612425468182

Epoch: 6| Step: 4
Training loss: 0.8839567415281683
Validation loss: 2.212087598421863

Epoch: 6| Step: 5
Training loss: 1.2823614556508016
Validation loss: 2.17208160883697

Epoch: 6| Step: 6
Training loss: 1.3995032910945093
Validation loss: 2.132810862875365

Epoch: 6| Step: 7
Training loss: 1.4450325359654637
Validation loss: 2.141470403629456

Epoch: 6| Step: 8
Training loss: 1.2924963788363644
Validation loss: 2.1571455390716485

Epoch: 6| Step: 9
Training loss: 1.1726318458493115
Validation loss: 2.192643697751195

Epoch: 6| Step: 10
Training loss: 1.1090100722444591
Validation loss: 2.112055666593725

Epoch: 6| Step: 11
Training loss: 1.0252998239186488
Validation loss: 2.158481560748164

Epoch: 6| Step: 12
Training loss: 1.6336905568873323
Validation loss: 2.1772285947183003

Epoch: 6| Step: 13
Training loss: 1.5178921447052038
Validation loss: 2.132449388160574

Epoch: 347| Step: 0
Training loss: 1.2810752563407222
Validation loss: 2.1084703754819984

Epoch: 6| Step: 1
Training loss: 1.7203039600461778
Validation loss: 2.1633071845894136

Epoch: 6| Step: 2
Training loss: 1.093482720551195
Validation loss: 2.192292011378666

Epoch: 6| Step: 3
Training loss: 0.8021246829252967
Validation loss: 2.1714405538026886

Epoch: 6| Step: 4
Training loss: 2.0626498081247413
Validation loss: 2.1229323703913194

Epoch: 6| Step: 5
Training loss: 0.9979427156386729
Validation loss: 2.2014379629042047

Epoch: 6| Step: 6
Training loss: 1.4096074185450054
Validation loss: 2.170385062569817

Epoch: 6| Step: 7
Training loss: 1.2152269746364392
Validation loss: 2.16012706676427

Epoch: 6| Step: 8
Training loss: 1.4335267261771951
Validation loss: 2.1146952075502257

Epoch: 6| Step: 9
Training loss: 1.0402193441533405
Validation loss: 2.1634772705036913

Epoch: 6| Step: 10
Training loss: 1.1608573259520012
Validation loss: 2.1409900241184556

Epoch: 6| Step: 11
Training loss: 1.4580970118551217
Validation loss: 2.1947182475910565

Epoch: 6| Step: 12
Training loss: 1.1120454588284219
Validation loss: 2.174289106807328

Epoch: 6| Step: 13
Training loss: 1.2615121961707887
Validation loss: 2.1365648319836206

Epoch: 348| Step: 0
Training loss: 1.5648011619345128
Validation loss: 2.1183125750542784

Epoch: 6| Step: 1
Training loss: 1.1775968101212069
Validation loss: 2.1399588941126755

Epoch: 6| Step: 2
Training loss: 0.92345015876988
Validation loss: 2.0933150848512003

Epoch: 6| Step: 3
Training loss: 0.8559243369509184
Validation loss: 2.2364192852536684

Epoch: 6| Step: 4
Training loss: 1.9926552017820562
Validation loss: 2.1381570259734484

Epoch: 6| Step: 5
Training loss: 1.545403676674805
Validation loss: 2.129402788383636

Epoch: 6| Step: 6
Training loss: 0.9489726936825436
Validation loss: 2.108241145281144

Epoch: 6| Step: 7
Training loss: 1.0518672960512638
Validation loss: 2.1569315719049578

Epoch: 6| Step: 8
Training loss: 1.2882455259867642
Validation loss: 2.2220892740374056

Epoch: 6| Step: 9
Training loss: 1.7991920459271271
Validation loss: 2.185971784819411

Epoch: 6| Step: 10
Training loss: 0.9469318234354906
Validation loss: 2.186562098297107

Epoch: 6| Step: 11
Training loss: 1.1086888407597981
Validation loss: 2.1208047853738754

Epoch: 6| Step: 12
Training loss: 1.4099039713306802
Validation loss: 2.1718784366774355

Epoch: 6| Step: 13
Training loss: 1.3281412011448661
Validation loss: 2.1668505421021966

Epoch: 349| Step: 0
Training loss: 0.9343773334690926
Validation loss: 2.130399579309989

Epoch: 6| Step: 1
Training loss: 1.4971848933595926
Validation loss: 2.136015017096994

Epoch: 6| Step: 2
Training loss: 1.5752655410956524
Validation loss: 2.2378264403942216

Epoch: 6| Step: 3
Training loss: 1.0079308373815343
Validation loss: 2.28299450106944

Epoch: 6| Step: 4
Training loss: 1.2461146050983058
Validation loss: 2.1346739258878933

Epoch: 6| Step: 5
Training loss: 1.1562260290187032
Validation loss: 2.14074285386519

Epoch: 6| Step: 6
Training loss: 1.029437929510134
Validation loss: 2.1580159388397036

Epoch: 6| Step: 7
Training loss: 1.2804124932676793
Validation loss: 2.157556711830688

Epoch: 6| Step: 8
Training loss: 1.009937559501627
Validation loss: 2.1706937308747607

Epoch: 6| Step: 9
Training loss: 1.0934796680431822
Validation loss: 2.109822412437859

Epoch: 6| Step: 10
Training loss: 1.267498560496459
Validation loss: 2.2616129484938416

Epoch: 6| Step: 11
Training loss: 2.1908528382236088
Validation loss: 2.1659025824103426

Epoch: 6| Step: 12
Training loss: 1.1614048465108018
Validation loss: 2.1672892689580565

Epoch: 6| Step: 13
Training loss: 1.4932689642373351
Validation loss: 2.1298589114208273

Epoch: 350| Step: 0
Training loss: 1.4262096858700188
Validation loss: 2.1221873533485462

Epoch: 6| Step: 1
Training loss: 1.1093784923229857
Validation loss: 2.128311184546968

Epoch: 6| Step: 2
Training loss: 0.8892655956883679
Validation loss: 2.239584110390561

Epoch: 6| Step: 3
Training loss: 1.1952408912501509
Validation loss: 2.143576128856134

Epoch: 6| Step: 4
Training loss: 1.3130070297360992
Validation loss: 2.190187376239727

Epoch: 6| Step: 5
Training loss: 2.030407422714854
Validation loss: 2.1657405815384445

Epoch: 6| Step: 6
Training loss: 1.3208912139789826
Validation loss: 2.1446379862447578

Epoch: 6| Step: 7
Training loss: 0.9778419048390299
Validation loss: 2.1945791008053086

Epoch: 6| Step: 8
Training loss: 1.1166191522728481
Validation loss: 2.1250949816676497

Epoch: 6| Step: 9
Training loss: 0.6911451633414667
Validation loss: 2.2284285107435897

Epoch: 6| Step: 10
Training loss: 1.2974417034275683
Validation loss: 2.1431542330378854

Epoch: 6| Step: 11
Training loss: 1.59526057742638
Validation loss: 2.1922923165889916

Epoch: 6| Step: 12
Training loss: 1.3644619176686708
Validation loss: 2.2101074803544836

Epoch: 6| Step: 13
Training loss: 0.7143022748185418
Validation loss: 2.206699640813163

Testing loss: 3.185926759710164
