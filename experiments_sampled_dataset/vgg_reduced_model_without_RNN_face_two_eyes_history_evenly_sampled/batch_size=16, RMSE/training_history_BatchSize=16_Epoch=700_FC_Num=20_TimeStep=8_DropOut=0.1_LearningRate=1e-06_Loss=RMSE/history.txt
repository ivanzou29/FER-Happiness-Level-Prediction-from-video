Epoch: 1| Step: 0
Training loss: 5.382404638598209
Validation loss: 4.457538587185669

Epoch: 6| Step: 1
Training loss: 4.266029422578067
Validation loss: 4.4542048700952535

Epoch: 6| Step: 2
Training loss: 5.347223770119359
Validation loss: 4.446331847977738

Epoch: 6| Step: 3
Training loss: 5.142350391368467
Validation loss: 4.445319810325647

Epoch: 6| Step: 4
Training loss: 5.161712157792445
Validation loss: 4.438836868790867

Epoch: 6| Step: 5
Training loss: 5.07757020707382
Validation loss: 4.433546256177395

Epoch: 6| Step: 6
Training loss: 4.672286509886647
Validation loss: 4.427851001792813

Epoch: 6| Step: 7
Training loss: 4.058935156553075
Validation loss: 4.428387445941915

Epoch: 6| Step: 8
Training loss: 3.0210692916444324
Validation loss: 4.423347515817867

Epoch: 6| Step: 9
Training loss: 4.230902004159258
Validation loss: 4.416005955639926

Epoch: 6| Step: 10
Training loss: 4.165432988954886
Validation loss: 4.411724670593646

Epoch: 6| Step: 11
Training loss: 4.037626442833725
Validation loss: 4.407315784734582

Epoch: 6| Step: 12
Training loss: 4.209679920052934
Validation loss: 4.405529131104023

Epoch: 6| Step: 13
Training loss: 4.036734229062397
Validation loss: 4.40271880461211

Epoch: 2| Step: 0
Training loss: 5.001615644730929
Validation loss: 4.397830125678102

Epoch: 6| Step: 1
Training loss: 2.763510030044622
Validation loss: 4.393806948459252

Epoch: 6| Step: 2
Training loss: 4.000993605231276
Validation loss: 4.390380294357292

Epoch: 6| Step: 3
Training loss: 5.144293592057057
Validation loss: 4.384415887222117

Epoch: 6| Step: 4
Training loss: 5.165994210730664
Validation loss: 4.3842955275105355

Epoch: 6| Step: 5
Training loss: 4.559791492580614
Validation loss: 4.378292581588026

Epoch: 6| Step: 6
Training loss: 4.393011021771097
Validation loss: 4.375102216285342

Epoch: 6| Step: 7
Training loss: 4.989208783431294
Validation loss: 4.372826357672088

Epoch: 6| Step: 8
Training loss: 5.137765013456347
Validation loss: 4.370498739453815

Epoch: 6| Step: 9
Training loss: 3.9245122424248318
Validation loss: 4.361048690249554

Epoch: 6| Step: 10
Training loss: 4.042920393355135
Validation loss: 4.359586704309445

Epoch: 6| Step: 11
Training loss: 4.193363013796745
Validation loss: 4.353307747715679

Epoch: 6| Step: 12
Training loss: 4.3223128421788335
Validation loss: 4.350443784834212

Epoch: 6| Step: 13
Training loss: 4.645255196811673
Validation loss: 4.347382134193123

Epoch: 3| Step: 0
Training loss: 3.502144292920767
Validation loss: 4.3416241938480375

Epoch: 6| Step: 1
Training loss: 5.859907527883999
Validation loss: 4.337747721785069

Epoch: 6| Step: 2
Training loss: 4.4093889459271844
Validation loss: 4.334137339503771

Epoch: 6| Step: 3
Training loss: 3.967828598596693
Validation loss: 4.328827941823354

Epoch: 6| Step: 4
Training loss: 4.400126212650708
Validation loss: 4.3247774715484475

Epoch: 6| Step: 5
Training loss: 3.5419317408079687
Validation loss: 4.322120434044317

Epoch: 6| Step: 6
Training loss: 4.363434682144537
Validation loss: 4.317332851481205

Epoch: 6| Step: 7
Training loss: 4.577389811049503
Validation loss: 4.3144932664724145

Epoch: 6| Step: 8
Training loss: 4.4416510280503205
Validation loss: 4.307757886113654

Epoch: 6| Step: 9
Training loss: 3.3584911514445075
Validation loss: 4.307146787175313

Epoch: 6| Step: 10
Training loss: 4.648966167744502
Validation loss: 4.302511679201802

Epoch: 6| Step: 11
Training loss: 4.835436966094809
Validation loss: 4.2979701282688145

Epoch: 6| Step: 12
Training loss: 5.622814516842994
Validation loss: 4.291193419393471

Epoch: 6| Step: 13
Training loss: 3.177959450580081
Validation loss: 4.286256226516569

Epoch: 4| Step: 0
Training loss: 4.852047218765988
Validation loss: 4.283623076229353

Epoch: 6| Step: 1
Training loss: 4.580982553291864
Validation loss: 4.277453010734281

Epoch: 6| Step: 2
Training loss: 4.516138384189679
Validation loss: 4.274306999646515

Epoch: 6| Step: 3
Training loss: 4.3121592069121055
Validation loss: 4.269053411459205

Epoch: 6| Step: 4
Training loss: 3.3117001125551884
Validation loss: 4.263517327608215

Epoch: 6| Step: 5
Training loss: 3.97910993179432
Validation loss: 4.263113038355723

Epoch: 6| Step: 6
Training loss: 5.141847412955312
Validation loss: 4.254440858750412

Epoch: 6| Step: 7
Training loss: 4.270525342799315
Validation loss: 4.254842803956094

Epoch: 6| Step: 8
Training loss: 3.824699145683576
Validation loss: 4.247024026231896

Epoch: 6| Step: 9
Training loss: 4.248525924856724
Validation loss: 4.244389229465284

Epoch: 6| Step: 10
Training loss: 4.1876462085307855
Validation loss: 4.236767157666666

Epoch: 6| Step: 11
Training loss: 4.212623499296629
Validation loss: 4.232282870858625

Epoch: 6| Step: 12
Training loss: 4.857890500301035
Validation loss: 4.227010215432121

Epoch: 6| Step: 13
Training loss: 4.885522294952959
Validation loss: 4.223050582334893

Epoch: 5| Step: 0
Training loss: 4.290503087989435
Validation loss: 4.218448418183894

Epoch: 6| Step: 1
Training loss: 4.129532375878971
Validation loss: 4.214953202757219

Epoch: 6| Step: 2
Training loss: 3.5450687598701145
Validation loss: 4.209594341884209

Epoch: 6| Step: 3
Training loss: 4.5516458238543285
Validation loss: 4.2041107789334085

Epoch: 6| Step: 4
Training loss: 4.754861452027653
Validation loss: 4.199061583744564

Epoch: 6| Step: 5
Training loss: 4.272656803546088
Validation loss: 4.195787390213919

Epoch: 6| Step: 6
Training loss: 4.2413718210405
Validation loss: 4.191219670532691

Epoch: 6| Step: 7
Training loss: 4.771620684069169
Validation loss: 4.184440497919385

Epoch: 6| Step: 8
Training loss: 4.5278147336443695
Validation loss: 4.179018028541763

Epoch: 6| Step: 9
Training loss: 4.925584926822183
Validation loss: 4.175907798861766

Epoch: 6| Step: 10
Training loss: 2.60416600545239
Validation loss: 4.165749988419831

Epoch: 6| Step: 11
Training loss: 3.997716728857793
Validation loss: 4.165570651873322

Epoch: 6| Step: 12
Training loss: 5.02181786134945
Validation loss: 4.1569479955224455

Epoch: 6| Step: 13
Training loss: 4.106053159225623
Validation loss: 4.156181712996323

Epoch: 6| Step: 0
Training loss: 4.06685416826418
Validation loss: 4.144479471268489

Epoch: 6| Step: 1
Training loss: 3.877928703805592
Validation loss: 4.143302714443482

Epoch: 6| Step: 2
Training loss: 3.0233796185613424
Validation loss: 4.136501110657887

Epoch: 6| Step: 3
Training loss: 4.563416689400992
Validation loss: 4.134015145734151

Epoch: 6| Step: 4
Training loss: 5.29879860846921
Validation loss: 4.126376218604863

Epoch: 6| Step: 5
Training loss: 4.436727967062094
Validation loss: 4.117911743566595

Epoch: 6| Step: 6
Training loss: 3.6192184909240264
Validation loss: 4.11671941141435

Epoch: 6| Step: 7
Training loss: 4.899968688241993
Validation loss: 4.106501090542369

Epoch: 6| Step: 8
Training loss: 3.706747994891457
Validation loss: 4.102072724671039

Epoch: 6| Step: 9
Training loss: 4.02164989870014
Validation loss: 4.097197230305526

Epoch: 6| Step: 10
Training loss: 4.743479218123912
Validation loss: 4.092168634530914

Epoch: 6| Step: 11
Training loss: 4.772468031410985
Validation loss: 4.085092040667147

Epoch: 6| Step: 12
Training loss: 4.082239406699268
Validation loss: 4.082874536428159

Epoch: 6| Step: 13
Training loss: 3.2760797365985703
Validation loss: 4.072855810654863

Epoch: 7| Step: 0
Training loss: 3.4015630270835318
Validation loss: 4.06811013898104

Epoch: 6| Step: 1
Training loss: 4.619880936314556
Validation loss: 4.064312551823381

Epoch: 6| Step: 2
Training loss: 4.415559497949455
Validation loss: 4.057532879242899

Epoch: 6| Step: 3
Training loss: 4.301721121970374
Validation loss: 4.051784708202924

Epoch: 6| Step: 4
Training loss: 3.8156473894891714
Validation loss: 4.042617357893543

Epoch: 6| Step: 5
Training loss: 3.965059742423351
Validation loss: 4.037457218271779

Epoch: 6| Step: 6
Training loss: 4.316831762821648
Validation loss: 4.030534569329723

Epoch: 6| Step: 7
Training loss: 3.158579353943201
Validation loss: 4.0236151256512915

Epoch: 6| Step: 8
Training loss: 5.3517426620563535
Validation loss: 4.017309283230954

Epoch: 6| Step: 9
Training loss: 4.547653918060088
Validation loss: 4.008742099535989

Epoch: 6| Step: 10
Training loss: 3.7969823751454954
Validation loss: 4.002296949585939

Epoch: 6| Step: 11
Training loss: 4.025064617135872
Validation loss: 3.9987696196115206

Epoch: 6| Step: 12
Training loss: 3.8430579578199295
Validation loss: 3.9929255830365724

Epoch: 6| Step: 13
Training loss: 4.38977563862559
Validation loss: 3.984149351411926

Epoch: 8| Step: 0
Training loss: 3.006105567809363
Validation loss: 3.975192945062858

Epoch: 6| Step: 1
Training loss: 4.060413940073856
Validation loss: 3.9669571091238307

Epoch: 6| Step: 2
Training loss: 4.466401877074998
Validation loss: 3.9621438347160334

Epoch: 6| Step: 3
Training loss: 3.8145003777315147
Validation loss: 3.9580944038822716

Epoch: 6| Step: 4
Training loss: 4.330065350821257
Validation loss: 3.9497453947348116

Epoch: 6| Step: 5
Training loss: 4.128475690062556
Validation loss: 3.9399884380876573

Epoch: 6| Step: 6
Training loss: 3.4099070664436337
Validation loss: 3.936461140226713

Epoch: 6| Step: 7
Training loss: 4.120269606203897
Validation loss: 3.9285272484447136

Epoch: 6| Step: 8
Training loss: 3.9278101294907417
Validation loss: 3.917064616858544

Epoch: 6| Step: 9
Training loss: 4.768525388535068
Validation loss: 3.909551722274173

Epoch: 6| Step: 10
Training loss: 3.778318545650918
Validation loss: 3.901642825003819

Epoch: 6| Step: 11
Training loss: 3.8021061030015253
Validation loss: 3.894729046252271

Epoch: 6| Step: 12
Training loss: 4.574086566060852
Validation loss: 3.888774563729617

Epoch: 6| Step: 13
Training loss: 4.765287393587237
Validation loss: 3.8761513448778016

Epoch: 9| Step: 0
Training loss: 3.1690112184980204
Validation loss: 3.8683280654172014

Epoch: 6| Step: 1
Training loss: 3.0249128660152946
Validation loss: 3.862249974761326

Epoch: 6| Step: 2
Training loss: 3.4138141602863623
Validation loss: 3.8500713102600237

Epoch: 6| Step: 3
Training loss: 3.6557002510129775
Validation loss: 3.8440076460027757

Epoch: 6| Step: 4
Training loss: 3.4531009725019546
Validation loss: 3.8365186179221147

Epoch: 6| Step: 5
Training loss: 4.321667643197672
Validation loss: 3.8274672772994744

Epoch: 6| Step: 6
Training loss: 4.153136499760697
Validation loss: 3.8168192872221303

Epoch: 6| Step: 7
Training loss: 4.231389981860437
Validation loss: 3.8076628701317095

Epoch: 6| Step: 8
Training loss: 4.666236766813793
Validation loss: 3.8011933628472216

Epoch: 6| Step: 9
Training loss: 5.073091706292053
Validation loss: 3.7897505427804195

Epoch: 6| Step: 10
Training loss: 3.3820430594150195
Validation loss: 3.780787557055002

Epoch: 6| Step: 11
Training loss: 3.725958241350026
Validation loss: 3.768769750582624

Epoch: 6| Step: 12
Training loss: 4.2496075168468455
Validation loss: 3.761998795661416

Epoch: 6| Step: 13
Training loss: 4.665178992792242
Validation loss: 3.755089011907965

Epoch: 10| Step: 0
Training loss: 4.43817133593656
Validation loss: 3.737980353038051

Epoch: 6| Step: 1
Training loss: 3.8485291086399265
Validation loss: 3.731220907132684

Epoch: 6| Step: 2
Training loss: 3.9882628377849967
Validation loss: 3.721644252040616

Epoch: 6| Step: 3
Training loss: 2.329138004169839
Validation loss: 3.708526353742916

Epoch: 6| Step: 4
Training loss: 3.733488991307966
Validation loss: 3.6957145187277023

Epoch: 6| Step: 5
Training loss: 3.634449186084525
Validation loss: 3.6840532370978374

Epoch: 6| Step: 6
Training loss: 3.5607065069810826
Validation loss: 3.6765519740429973

Epoch: 6| Step: 7
Training loss: 4.226439750990187
Validation loss: 3.6647602902522336

Epoch: 6| Step: 8
Training loss: 3.4567928943252895
Validation loss: 3.6596496443659228

Epoch: 6| Step: 9
Training loss: 4.036377477348772
Validation loss: 3.642965714306917

Epoch: 6| Step: 10
Training loss: 3.8477283761482193
Validation loss: 3.633871328591462

Epoch: 6| Step: 11
Training loss: 4.076716505002304
Validation loss: 3.6222539351275187

Epoch: 6| Step: 12
Training loss: 4.187184336137462
Validation loss: 3.613067915454572

Epoch: 6| Step: 13
Training loss: 4.053868440726314
Validation loss: 3.6044905004504257

Epoch: 11| Step: 0
Training loss: 3.718192307143076
Validation loss: 3.5905561239212584

Epoch: 6| Step: 1
Training loss: 4.03767013899937
Validation loss: 3.575990239156134

Epoch: 6| Step: 2
Training loss: 3.061066895535024
Validation loss: 3.561590543849777

Epoch: 6| Step: 3
Training loss: 4.156457422573226
Validation loss: 3.554970277043236

Epoch: 6| Step: 4
Training loss: 3.7958523350284348
Validation loss: 3.5415118049095358

Epoch: 6| Step: 5
Training loss: 3.190946025185091
Validation loss: 3.5254178771928304

Epoch: 6| Step: 6
Training loss: 4.005257489217346
Validation loss: 3.520689684976275

Epoch: 6| Step: 7
Training loss: 3.002616853623773
Validation loss: 3.5031157452752684

Epoch: 6| Step: 8
Training loss: 4.248042385055099
Validation loss: 3.492979920127805

Epoch: 6| Step: 9
Training loss: 3.3449439653341857
Validation loss: 3.4807165661712984

Epoch: 6| Step: 10
Training loss: 4.2148862877255695
Validation loss: 3.473627513450044

Epoch: 6| Step: 11
Training loss: 3.253877234358176
Validation loss: 3.457555073714168

Epoch: 6| Step: 12
Training loss: 3.719393121581946
Validation loss: 3.4333385795635216

Epoch: 6| Step: 13
Training loss: 3.5862805570176155
Validation loss: 3.429122833098194

Epoch: 12| Step: 0
Training loss: 3.229852583033765
Validation loss: 3.412250085311516

Epoch: 6| Step: 1
Training loss: 3.8714893804830925
Validation loss: 3.4044056392597075

Epoch: 6| Step: 2
Training loss: 3.4083703117571997
Validation loss: 3.392010962712533

Epoch: 6| Step: 3
Training loss: 3.700299049870386
Validation loss: 3.3819052645731906

Epoch: 6| Step: 4
Training loss: 3.4384231714915487
Validation loss: 3.3594019200743332

Epoch: 6| Step: 5
Training loss: 3.6477830450979405
Validation loss: 3.3535100749896536

Epoch: 6| Step: 6
Training loss: 2.9342648161492693
Validation loss: 3.3415305624972276

Epoch: 6| Step: 7
Training loss: 2.5954663216734133
Validation loss: 3.323074731041848

Epoch: 6| Step: 8
Training loss: 3.584363271865348
Validation loss: 3.317768263997146

Epoch: 6| Step: 9
Training loss: 4.535045218279079
Validation loss: 3.304602987748239

Epoch: 6| Step: 10
Training loss: 3.6611113223312337
Validation loss: 3.29076350261979

Epoch: 6| Step: 11
Training loss: 3.706414930202319
Validation loss: 3.280804625646947

Epoch: 6| Step: 12
Training loss: 3.4712178841940102
Validation loss: 3.2620648592529737

Epoch: 6| Step: 13
Training loss: 3.178884943874056
Validation loss: 3.251858888774735

Epoch: 13| Step: 0
Training loss: 2.9813802182850555
Validation loss: 3.2377752671276006

Epoch: 6| Step: 1
Training loss: 4.0124328037232635
Validation loss: 3.2231358213753922

Epoch: 6| Step: 2
Training loss: 2.4914872193120643
Validation loss: 3.2062033966604395

Epoch: 6| Step: 3
Training loss: 3.2579667674618387
Validation loss: 3.202079269700481

Epoch: 6| Step: 4
Training loss: 3.6106697171403552
Validation loss: 3.1792990610588023

Epoch: 6| Step: 5
Training loss: 3.6783933530288646
Validation loss: 3.1610591739359695

Epoch: 6| Step: 6
Training loss: 3.076150948589536
Validation loss: 3.15092696236454

Epoch: 6| Step: 7
Training loss: 3.2750380069769505
Validation loss: 3.141334730625843

Epoch: 6| Step: 8
Training loss: 2.3557861519150434
Validation loss: 3.124872133653878

Epoch: 6| Step: 9
Training loss: 3.2537453418160505
Validation loss: 3.108650702363033

Epoch: 6| Step: 10
Training loss: 4.014349471392195
Validation loss: 3.096606357435384

Epoch: 6| Step: 11
Training loss: 3.527988784633811
Validation loss: 3.094721400797407

Epoch: 6| Step: 12
Training loss: 3.973903883948053
Validation loss: 3.076941156383514

Epoch: 6| Step: 13
Training loss: 3.069446237677678
Validation loss: 3.067919140675272

Epoch: 14| Step: 0
Training loss: 3.387041157970498
Validation loss: 3.0465254161067747

Epoch: 6| Step: 1
Training loss: 3.1923934175508313
Validation loss: 3.0280780762482764

Epoch: 6| Step: 2
Training loss: 3.4571935928071733
Validation loss: 3.009836086342162

Epoch: 6| Step: 3
Training loss: 3.0137864274648085
Validation loss: 2.9976770865914655

Epoch: 6| Step: 4
Training loss: 2.9501511874493134
Validation loss: 2.987655678189449

Epoch: 6| Step: 5
Training loss: 3.110619070864885
Validation loss: 2.970561859641868

Epoch: 6| Step: 6
Training loss: 2.3798900255071245
Validation loss: 2.9648819850315435

Epoch: 6| Step: 7
Training loss: 3.667585488995696
Validation loss: 2.951006378795315

Epoch: 6| Step: 8
Training loss: 3.707483229904677
Validation loss: 2.9354114739903174

Epoch: 6| Step: 9
Training loss: 3.6121825821228635
Validation loss: 2.9199671688936855

Epoch: 6| Step: 10
Training loss: 3.6415321627873545
Validation loss: 2.908347287050394

Epoch: 6| Step: 11
Training loss: 2.6081551081631065
Validation loss: 2.8961647754679802

Epoch: 6| Step: 12
Training loss: 2.7074837354627657
Validation loss: 2.8904820197035406

Epoch: 6| Step: 13
Training loss: 3.3424872750358907
Validation loss: 2.8760752938644454

Epoch: 15| Step: 0
Training loss: 2.7872427338397583
Validation loss: 2.8553684585609793

Epoch: 6| Step: 1
Training loss: 3.1841709479634557
Validation loss: 2.855090135091451

Epoch: 6| Step: 2
Training loss: 2.9369582630344193
Validation loss: 2.8313212522045967

Epoch: 6| Step: 3
Training loss: 3.4145080136054133
Validation loss: 2.83566287550707

Epoch: 6| Step: 4
Training loss: 2.5075145318626655
Validation loss: 2.8157727267988664

Epoch: 6| Step: 5
Training loss: 3.598718012263132
Validation loss: 2.80597177964322

Epoch: 6| Step: 6
Training loss: 3.4714295631151617
Validation loss: 2.792704987098893

Epoch: 6| Step: 7
Training loss: 3.251312724340358
Validation loss: 2.781913244094159

Epoch: 6| Step: 8
Training loss: 1.9220899136100753
Validation loss: 2.776147813404335

Epoch: 6| Step: 9
Training loss: 3.1849753161181997
Validation loss: 2.759789429764795

Epoch: 6| Step: 10
Training loss: 3.223676448366058
Validation loss: 2.7536026558580198

Epoch: 6| Step: 11
Training loss: 3.329724424489509
Validation loss: 2.74790310550835

Epoch: 6| Step: 12
Training loss: 3.0764074810567523
Validation loss: 2.7376828728798563

Epoch: 6| Step: 13
Training loss: 2.5108544270055324
Validation loss: 2.72025494005675

Epoch: 16| Step: 0
Training loss: 2.6143656078938693
Validation loss: 2.7179528013972893

Epoch: 6| Step: 1
Training loss: 2.9615661436877447
Validation loss: 2.7012677109139847

Epoch: 6| Step: 2
Training loss: 3.655148201584898
Validation loss: 2.6964332707887704

Epoch: 6| Step: 3
Training loss: 3.391851247377806
Validation loss: 2.6868096810292483

Epoch: 6| Step: 4
Training loss: 2.72319806918245
Validation loss: 2.6686563208953054

Epoch: 6| Step: 5
Training loss: 2.6780217723915762
Validation loss: 2.6738791935221444

Epoch: 6| Step: 6
Training loss: 2.8723327869587267
Validation loss: 2.666088129615984

Epoch: 6| Step: 7
Training loss: 2.424810586984366
Validation loss: 2.6519080407106355

Epoch: 6| Step: 8
Training loss: 3.148951486135684
Validation loss: 2.6398969387942204

Epoch: 6| Step: 9
Training loss: 3.497294879212785
Validation loss: 2.645880682181406

Epoch: 6| Step: 10
Training loss: 2.7977486210338096
Validation loss: 2.6309052166213633

Epoch: 6| Step: 11
Training loss: 3.2922417504503225
Validation loss: 2.6220514522865734

Epoch: 6| Step: 12
Training loss: 2.287916918840072
Validation loss: 2.6290470106268486

Epoch: 6| Step: 13
Training loss: 3.4774953212199216
Validation loss: 2.6137833789377938

Epoch: 17| Step: 0
Training loss: 3.120735310202192
Validation loss: 2.6177061685808196

Epoch: 6| Step: 1
Training loss: 2.917129334583487
Validation loss: 2.6170195622224814

Epoch: 6| Step: 2
Training loss: 3.006784397140685
Validation loss: 2.602440100157414

Epoch: 6| Step: 3
Training loss: 3.3595417779731176
Validation loss: 2.6083166196271184

Epoch: 6| Step: 4
Training loss: 3.6051550301960726
Validation loss: 2.592598862399528

Epoch: 6| Step: 5
Training loss: 2.8751499302787726
Validation loss: 2.5819840948400823

Epoch: 6| Step: 6
Training loss: 3.0027461198974317
Validation loss: 2.5819604955897195

Epoch: 6| Step: 7
Training loss: 2.460916379807685
Validation loss: 2.580088188455625

Epoch: 6| Step: 8
Training loss: 2.4410509507090423
Validation loss: 2.5693168268843025

Epoch: 6| Step: 9
Training loss: 2.8116689513837314
Validation loss: 2.571713345075793

Epoch: 6| Step: 10
Training loss: 3.050128158628358
Validation loss: 2.5648301158022626

Epoch: 6| Step: 11
Training loss: 2.632647319558715
Validation loss: 2.57369603852734

Epoch: 6| Step: 12
Training loss: 2.87242774334657
Validation loss: 2.5577103717491805

Epoch: 6| Step: 13
Training loss: 3.03621055329267
Validation loss: 2.5702053236856073

Epoch: 18| Step: 0
Training loss: 3.6213486796724816
Validation loss: 2.553647630512655

Epoch: 6| Step: 1
Training loss: 2.6480300274785824
Validation loss: 2.5593597845979765

Epoch: 6| Step: 2
Training loss: 2.756250993032125
Validation loss: 2.563950896975828

Epoch: 6| Step: 3
Training loss: 2.9233394767438594
Validation loss: 2.555662490107137

Epoch: 6| Step: 4
Training loss: 3.1515275732931562
Validation loss: 2.555738129885081

Epoch: 6| Step: 5
Training loss: 2.2617732487834306
Validation loss: 2.549275537069487

Epoch: 6| Step: 6
Training loss: 2.737782562165325
Validation loss: 2.548386098901219

Epoch: 6| Step: 7
Training loss: 2.5669609875391273
Validation loss: 2.546261641398207

Epoch: 6| Step: 8
Training loss: 2.925035042838129
Validation loss: 2.5575596276129526

Epoch: 6| Step: 9
Training loss: 3.2455645886195774
Validation loss: 2.545934990209899

Epoch: 6| Step: 10
Training loss: 3.225015264667196
Validation loss: 2.549870772307419

Epoch: 6| Step: 11
Training loss: 3.0823511844796156
Validation loss: 2.5436245158896367

Epoch: 6| Step: 12
Training loss: 2.2881847169778995
Validation loss: 2.5564333707154

Epoch: 6| Step: 13
Training loss: 3.3346141897427346
Validation loss: 2.5533201420538374

Epoch: 19| Step: 0
Training loss: 2.6378524038629285
Validation loss: 2.5552210096902783

Epoch: 6| Step: 1
Training loss: 2.6915908550849177
Validation loss: 2.5403006937985606

Epoch: 6| Step: 2
Training loss: 2.8233387949356645
Validation loss: 2.5336964496637315

Epoch: 6| Step: 3
Training loss: 3.003442378744184
Validation loss: 2.5358338866022048

Epoch: 6| Step: 4
Training loss: 3.1918350361237575
Validation loss: 2.549832428065523

Epoch: 6| Step: 5
Training loss: 2.80959169699891
Validation loss: 2.5520656438586546

Epoch: 6| Step: 6
Training loss: 3.1650919428724245
Validation loss: 2.5426747908102234

Epoch: 6| Step: 7
Training loss: 3.035650775148899
Validation loss: 2.5429805692773555

Epoch: 6| Step: 8
Training loss: 3.0899844903155462
Validation loss: 2.5337096214811563

Epoch: 6| Step: 9
Training loss: 2.6508469325842743
Validation loss: 2.5502446250915702

Epoch: 6| Step: 10
Training loss: 2.5332966760024416
Validation loss: 2.5340048043053276

Epoch: 6| Step: 11
Training loss: 2.7896037284517656
Validation loss: 2.542164699458423

Epoch: 6| Step: 12
Training loss: 3.10163106770476
Validation loss: 2.5342658310000217

Epoch: 6| Step: 13
Training loss: 3.2037841118742767
Validation loss: 2.535797044728928

Epoch: 20| Step: 0
Training loss: 3.5029256037403016
Validation loss: 2.539917978912099

Epoch: 6| Step: 1
Training loss: 3.250281981926512
Validation loss: 2.5345445484600106

Epoch: 6| Step: 2
Training loss: 3.299826074120544
Validation loss: 2.5386806830111204

Epoch: 6| Step: 3
Training loss: 2.344365255345244
Validation loss: 2.5220483245026952

Epoch: 6| Step: 4
Training loss: 3.251173101129545
Validation loss: 2.5354722697902115

Epoch: 6| Step: 5
Training loss: 2.48979105275707
Validation loss: 2.534433617041758

Epoch: 6| Step: 6
Training loss: 2.7174878753419702
Validation loss: 2.5200523163892115

Epoch: 6| Step: 7
Training loss: 2.0674934051297784
Validation loss: 2.5196853619815855

Epoch: 6| Step: 8
Training loss: 3.0994539949043154
Validation loss: 2.515513628654367

Epoch: 6| Step: 9
Training loss: 2.5207399293183275
Validation loss: 2.5154866806195764

Epoch: 6| Step: 10
Training loss: 3.045344667768792
Validation loss: 2.528834605538754

Epoch: 6| Step: 11
Training loss: 3.205998020792616
Validation loss: 2.5216025759603173

Epoch: 6| Step: 12
Training loss: 2.92841411128162
Validation loss: 2.5165139830486325

Epoch: 6| Step: 13
Training loss: 2.2947309179197326
Validation loss: 2.5323457390835293

Epoch: 21| Step: 0
Training loss: 2.839873805667551
Validation loss: 2.5118409622746722

Epoch: 6| Step: 1
Training loss: 3.0414753335494673
Validation loss: 2.5196953461471066

Epoch: 6| Step: 2
Training loss: 3.295078167603196
Validation loss: 2.51887878684754

Epoch: 6| Step: 3
Training loss: 2.6207639029018654
Validation loss: 2.5280063557655903

Epoch: 6| Step: 4
Training loss: 3.0740538653467384
Validation loss: 2.507211191855939

Epoch: 6| Step: 5
Training loss: 2.617999779207994
Validation loss: 2.521301258306812

Epoch: 6| Step: 6
Training loss: 2.543741931949352
Validation loss: 2.5158588940422404

Epoch: 6| Step: 7
Training loss: 2.645526918304948
Validation loss: 2.5165920560529114

Epoch: 6| Step: 8
Training loss: 3.514687103626917
Validation loss: 2.5194151894631243

Epoch: 6| Step: 9
Training loss: 2.8694886164687854
Validation loss: 2.5129576421604654

Epoch: 6| Step: 10
Training loss: 3.1679973483411694
Validation loss: 2.504454529618856

Epoch: 6| Step: 11
Training loss: 2.411798693459854
Validation loss: 2.523377955529246

Epoch: 6| Step: 12
Training loss: 2.5229857427169264
Validation loss: 2.5117407106796255

Epoch: 6| Step: 13
Training loss: 3.122004179243654
Validation loss: 2.5273217942998025

Epoch: 22| Step: 0
Training loss: 3.395055170748593
Validation loss: 2.518793204121827

Epoch: 6| Step: 1
Training loss: 2.8278410542454773
Validation loss: 2.516831370848421

Epoch: 6| Step: 2
Training loss: 2.400877664940827
Validation loss: 2.5161929545763835

Epoch: 6| Step: 3
Training loss: 3.1481012586039587
Validation loss: 2.5065004539638007

Epoch: 6| Step: 4
Training loss: 2.731437980415615
Validation loss: 2.5240984376571918

Epoch: 6| Step: 5
Training loss: 2.108523726881851
Validation loss: 2.5166772791725585

Epoch: 6| Step: 6
Training loss: 2.627272031351377
Validation loss: 2.5125661780549002

Epoch: 6| Step: 7
Training loss: 3.514159036805522
Validation loss: 2.5071133207018836

Epoch: 6| Step: 8
Training loss: 2.5732218037617707
Validation loss: 2.515771093083648

Epoch: 6| Step: 9
Training loss: 2.3304798070969466
Validation loss: 2.5209564301644933

Epoch: 6| Step: 10
Training loss: 2.991945899392664
Validation loss: 2.5126053246592335

Epoch: 6| Step: 11
Training loss: 3.161803845164632
Validation loss: 2.507722516867489

Epoch: 6| Step: 12
Training loss: 3.455930648867288
Validation loss: 2.521368621446424

Epoch: 6| Step: 13
Training loss: 2.577683659549025
Validation loss: 2.5203169043949734

Epoch: 23| Step: 0
Training loss: 2.6355413676275457
Validation loss: 2.5151722879706253

Epoch: 6| Step: 1
Training loss: 2.753125408748462
Validation loss: 2.5195315460945142

Epoch: 6| Step: 2
Training loss: 3.0530561300766217
Validation loss: 2.5036824290657047

Epoch: 6| Step: 3
Training loss: 2.8973380005832983
Validation loss: 2.5160662718106215

Epoch: 6| Step: 4
Training loss: 2.5022388923391623
Validation loss: 2.5031084916207718

Epoch: 6| Step: 5
Training loss: 2.3404053283203057
Validation loss: 2.5094148760015984

Epoch: 6| Step: 6
Training loss: 2.8912667876538367
Validation loss: 2.50434642659313

Epoch: 6| Step: 7
Training loss: 2.411304070720275
Validation loss: 2.5078204674949274

Epoch: 6| Step: 8
Training loss: 3.5410658532444947
Validation loss: 2.5129930080986114

Epoch: 6| Step: 9
Training loss: 3.000157987885056
Validation loss: 2.509393157012654

Epoch: 6| Step: 10
Training loss: 2.7092479530827296
Validation loss: 2.5060132597517226

Epoch: 6| Step: 11
Training loss: 2.6262320397410623
Validation loss: 2.5130060323748715

Epoch: 6| Step: 12
Training loss: 3.8301173416767775
Validation loss: 2.5067106656885585

Epoch: 6| Step: 13
Training loss: 2.491469228910849
Validation loss: 2.4936401832348136

Epoch: 24| Step: 0
Training loss: 2.8568542709383022
Validation loss: 2.505903110367543

Epoch: 6| Step: 1
Training loss: 2.2631277067162467
Validation loss: 2.5148087562424837

Epoch: 6| Step: 2
Training loss: 2.6135823029366483
Validation loss: 2.5179513864452194

Epoch: 6| Step: 3
Training loss: 3.268042878494141
Validation loss: 2.5047420391549413

Epoch: 6| Step: 4
Training loss: 2.7791981361205025
Validation loss: 2.509100753482374

Epoch: 6| Step: 5
Training loss: 3.3963675673560263
Validation loss: 2.5124959846570203

Epoch: 6| Step: 6
Training loss: 2.6127594339880966
Validation loss: 2.520839843361921

Epoch: 6| Step: 7
Training loss: 2.8699214695942787
Validation loss: 2.506437262735546

Epoch: 6| Step: 8
Training loss: 2.7533422447165057
Validation loss: 2.50088214589938

Epoch: 6| Step: 9
Training loss: 3.1504794709554322
Validation loss: 2.50693860431751

Epoch: 6| Step: 10
Training loss: 2.4403371682705095
Validation loss: 2.5103508609572986

Epoch: 6| Step: 11
Training loss: 3.0515428049259623
Validation loss: 2.5063684667444583

Epoch: 6| Step: 12
Training loss: 2.5156977862140955
Validation loss: 2.5107887600603953

Epoch: 6| Step: 13
Training loss: 3.493219483415545
Validation loss: 2.5125140147950122

Epoch: 25| Step: 0
Training loss: 3.05110414874505
Validation loss: 2.503877907444554

Epoch: 6| Step: 1
Training loss: 3.0273640687322163
Validation loss: 2.510046509409601

Epoch: 6| Step: 2
Training loss: 2.590430283907701
Validation loss: 2.508735977648609

Epoch: 6| Step: 3
Training loss: 2.540639534283457
Validation loss: 2.5186981138829556

Epoch: 6| Step: 4
Training loss: 2.633806623910214
Validation loss: 2.497432328445264

Epoch: 6| Step: 5
Training loss: 2.5179926943017783
Validation loss: 2.505113172937798

Epoch: 6| Step: 6
Training loss: 3.324498739677485
Validation loss: 2.5016875519012243

Epoch: 6| Step: 7
Training loss: 2.7211569293275057
Validation loss: 2.5077972886999733

Epoch: 6| Step: 8
Training loss: 2.441342772612283
Validation loss: 2.506978208978644

Epoch: 6| Step: 9
Training loss: 3.3197854016359307
Validation loss: 2.5001556045549225

Epoch: 6| Step: 10
Training loss: 3.1184948161273076
Validation loss: 2.512330456015408

Epoch: 6| Step: 11
Training loss: 2.7403877634089584
Validation loss: 2.501646494373939

Epoch: 6| Step: 12
Training loss: 3.0792942053398455
Validation loss: 2.5153805570589722

Epoch: 6| Step: 13
Training loss: 2.5692069508077977
Validation loss: 2.502336216502302

Epoch: 26| Step: 0
Training loss: 3.2825333764848175
Validation loss: 2.5005980227576496

Epoch: 6| Step: 1
Training loss: 2.6794121158663913
Validation loss: 2.50656536799032

Epoch: 6| Step: 2
Training loss: 2.788539976438443
Validation loss: 2.4867650162382544

Epoch: 6| Step: 3
Training loss: 3.1080184354296714
Validation loss: 2.511700584016634

Epoch: 6| Step: 4
Training loss: 2.764437318082635
Validation loss: 2.504973568491855

Epoch: 6| Step: 5
Training loss: 2.7345771932777603
Validation loss: 2.516806300977511

Epoch: 6| Step: 6
Training loss: 1.9047709496033587
Validation loss: 2.5006771554933303

Epoch: 6| Step: 7
Training loss: 2.663732066315635
Validation loss: 2.5055206082371444

Epoch: 6| Step: 8
Training loss: 3.0306177168066517
Validation loss: 2.511588270044986

Epoch: 6| Step: 9
Training loss: 3.5309350877627503
Validation loss: 2.50188657477378

Epoch: 6| Step: 10
Training loss: 2.807623896051768
Validation loss: 2.496187734586117

Epoch: 6| Step: 11
Training loss: 2.6091092825270743
Validation loss: 2.508512978550618

Epoch: 6| Step: 12
Training loss: 3.1734451391521636
Validation loss: 2.5150158832014013

Epoch: 6| Step: 13
Training loss: 2.285600250669258
Validation loss: 2.5057674924350906

Epoch: 27| Step: 0
Training loss: 3.078784852537262
Validation loss: 2.508493914533592

Epoch: 6| Step: 1
Training loss: 3.10483576243484
Validation loss: 2.5122509474523196

Epoch: 6| Step: 2
Training loss: 2.919512441246361
Validation loss: 2.5051593497299276

Epoch: 6| Step: 3
Training loss: 3.105252547505446
Validation loss: 2.4966314499466002

Epoch: 6| Step: 4
Training loss: 2.5541817167335505
Validation loss: 2.5035724126506325

Epoch: 6| Step: 5
Training loss: 2.604145772214354
Validation loss: 2.502659011179594

Epoch: 6| Step: 6
Training loss: 2.273060875597295
Validation loss: 2.502378714403705

Epoch: 6| Step: 7
Training loss: 2.514166746947688
Validation loss: 2.5066530373052665

Epoch: 6| Step: 8
Training loss: 2.7837537147281357
Validation loss: 2.4933838255460863

Epoch: 6| Step: 9
Training loss: 3.8999665038797806
Validation loss: 2.496088344571909

Epoch: 6| Step: 10
Training loss: 2.119518840456784
Validation loss: 2.495739590121072

Epoch: 6| Step: 11
Training loss: 2.7006825785203072
Validation loss: 2.4981862020606678

Epoch: 6| Step: 12
Training loss: 2.9992662168196187
Validation loss: 2.493683235417269

Epoch: 6| Step: 13
Training loss: 2.6246143239390944
Validation loss: 2.5029744440122728

Epoch: 28| Step: 0
Training loss: 2.8216978775824875
Validation loss: 2.481513828335864

Epoch: 6| Step: 1
Training loss: 3.083142214513789
Validation loss: 2.4843692316406383

Epoch: 6| Step: 2
Training loss: 2.940659467472848
Validation loss: 2.496439116463225

Epoch: 6| Step: 3
Training loss: 3.0338593882678153
Validation loss: 2.4959466684720035

Epoch: 6| Step: 4
Training loss: 3.0489826444267645
Validation loss: 2.488820412223503

Epoch: 6| Step: 5
Training loss: 2.743584345029067
Validation loss: 2.5089742623403515

Epoch: 6| Step: 6
Training loss: 2.306953169976971
Validation loss: 2.505782869520411

Epoch: 6| Step: 7
Training loss: 2.5042903325863106
Validation loss: 2.4864036866218404

Epoch: 6| Step: 8
Training loss: 2.7679822111219656
Validation loss: 2.4940344668669447

Epoch: 6| Step: 9
Training loss: 2.6486951314473752
Validation loss: 2.476672558965522

Epoch: 6| Step: 10
Training loss: 3.0261629816754083
Validation loss: 2.4845143766204205

Epoch: 6| Step: 11
Training loss: 3.193771774307348
Validation loss: 2.498014695446312

Epoch: 6| Step: 12
Training loss: 2.864531656434918
Validation loss: 2.4834282871222664

Epoch: 6| Step: 13
Training loss: 2.3321273502759823
Validation loss: 2.4912131716188535

Epoch: 29| Step: 0
Training loss: 2.1755701918083137
Validation loss: 2.497295886068249

Epoch: 6| Step: 1
Training loss: 2.5999059586757207
Validation loss: 2.4818666786943115

Epoch: 6| Step: 2
Training loss: 2.875342141400697
Validation loss: 2.4887645657271356

Epoch: 6| Step: 3
Training loss: 2.855319456275899
Validation loss: 2.495251328438354

Epoch: 6| Step: 4
Training loss: 3.344852444027158
Validation loss: 2.4932401326005347

Epoch: 6| Step: 5
Training loss: 3.01180282059825
Validation loss: 2.483376573047294

Epoch: 6| Step: 6
Training loss: 2.4099223859643426
Validation loss: 2.498557555496971

Epoch: 6| Step: 7
Training loss: 2.671404791610292
Validation loss: 2.4891034542203734

Epoch: 6| Step: 8
Training loss: 2.7794682656988288
Validation loss: 2.484252540736664

Epoch: 6| Step: 9
Training loss: 2.884323427146348
Validation loss: 2.487748299273269

Epoch: 6| Step: 10
Training loss: 3.513460705334512
Validation loss: 2.480532001273184

Epoch: 6| Step: 11
Training loss: 2.5921525747051497
Validation loss: 2.50000727662699

Epoch: 6| Step: 12
Training loss: 2.7701392965719447
Validation loss: 2.500138670654258

Epoch: 6| Step: 13
Training loss: 2.8087524878537984
Validation loss: 2.4941237638404035

Epoch: 30| Step: 0
Training loss: 3.24530570590135
Validation loss: 2.4914321312726857

Epoch: 6| Step: 1
Training loss: 3.042715823590807
Validation loss: 2.4943425676900097

Epoch: 6| Step: 2
Training loss: 2.590120096552086
Validation loss: 2.4930324443304586

Epoch: 6| Step: 3
Training loss: 2.358416432061268
Validation loss: 2.5022679614074548

Epoch: 6| Step: 4
Training loss: 3.0378575620830026
Validation loss: 2.4928573904936924

Epoch: 6| Step: 5
Training loss: 2.414024278652977
Validation loss: 2.4822471970734306

Epoch: 6| Step: 6
Training loss: 2.0395953771945403
Validation loss: 2.47937582127643

Epoch: 6| Step: 7
Training loss: 2.626071529579268
Validation loss: 2.494729160578492

Epoch: 6| Step: 8
Training loss: 2.742557163807699
Validation loss: 2.4864106756774462

Epoch: 6| Step: 9
Training loss: 2.809966069081121
Validation loss: 2.481485614338839

Epoch: 6| Step: 10
Training loss: 3.048737724376456
Validation loss: 2.4955137186998413

Epoch: 6| Step: 11
Training loss: 2.9076957798099863
Validation loss: 2.4885745066397345

Epoch: 6| Step: 12
Training loss: 3.029755213956095
Validation loss: 2.4871967182938652

Epoch: 6| Step: 13
Training loss: 3.649934057397757
Validation loss: 2.4977501559221262

Epoch: 31| Step: 0
Training loss: 3.0336033445919286
Validation loss: 2.4795703064719192

Epoch: 6| Step: 1
Training loss: 2.7229875885634702
Validation loss: 2.4826512289071623

Epoch: 6| Step: 2
Training loss: 3.513956581103676
Validation loss: 2.485127270196155

Epoch: 6| Step: 3
Training loss: 2.727781356719398
Validation loss: 2.4916514739817885

Epoch: 6| Step: 4
Training loss: 2.4644342677830524
Validation loss: 2.4920161340033498

Epoch: 6| Step: 5
Training loss: 3.077789443262106
Validation loss: 2.4839131689701666

Epoch: 6| Step: 6
Training loss: 2.3162620460950483
Validation loss: 2.4867613822640817

Epoch: 6| Step: 7
Training loss: 2.9854259937155763
Validation loss: 2.4784396635962636

Epoch: 6| Step: 8
Training loss: 2.870730671664167
Validation loss: 2.4859730503122104

Epoch: 6| Step: 9
Training loss: 2.559064469461898
Validation loss: 2.4946942437656845

Epoch: 6| Step: 10
Training loss: 2.7175556058555173
Validation loss: 2.483146297081374

Epoch: 6| Step: 11
Training loss: 3.1792228790419874
Validation loss: 2.4818129606555597

Epoch: 6| Step: 12
Training loss: 2.802293015662331
Validation loss: 2.4883203768531077

Epoch: 6| Step: 13
Training loss: 1.6479997822104004
Validation loss: 2.49943081108554

Epoch: 32| Step: 0
Training loss: 2.8879624760163383
Validation loss: 2.497718797765596

Epoch: 6| Step: 1
Training loss: 2.1900451023212777
Validation loss: 2.4794439672751025

Epoch: 6| Step: 2
Training loss: 2.7576880926757465
Validation loss: 2.4769149968839317

Epoch: 6| Step: 3
Training loss: 2.593701281721963
Validation loss: 2.490543370018204

Epoch: 6| Step: 4
Training loss: 2.2441236264586846
Validation loss: 2.4898985470403914

Epoch: 6| Step: 5
Training loss: 3.0154545394868606
Validation loss: 2.4881707906163713

Epoch: 6| Step: 6
Training loss: 3.194006020871712
Validation loss: 2.4913718794893733

Epoch: 6| Step: 7
Training loss: 3.544726288078878
Validation loss: 2.477313705842024

Epoch: 6| Step: 8
Training loss: 2.2757095571815533
Validation loss: 2.4906997434353024

Epoch: 6| Step: 9
Training loss: 2.8524780475865
Validation loss: 2.4825260048247055

Epoch: 6| Step: 10
Training loss: 3.5156199815502376
Validation loss: 2.4863868255796513

Epoch: 6| Step: 11
Training loss: 2.9144241067740135
Validation loss: 2.4889065177806367

Epoch: 6| Step: 12
Training loss: 2.437323441591092
Validation loss: 2.4962996436238236

Epoch: 6| Step: 13
Training loss: 2.36713129864441
Validation loss: 2.482724991109018

Epoch: 33| Step: 0
Training loss: 2.808608435750244
Validation loss: 2.492325737184387

Epoch: 6| Step: 1
Training loss: 1.9595436522499932
Validation loss: 2.478101891710151

Epoch: 6| Step: 2
Training loss: 2.6585338871639794
Validation loss: 2.493167577117288

Epoch: 6| Step: 3
Training loss: 2.8492840587096255
Validation loss: 2.482752328817541

Epoch: 6| Step: 4
Training loss: 3.3360644278399687
Validation loss: 2.4970077378539823

Epoch: 6| Step: 5
Training loss: 2.5406141968294493
Validation loss: 2.48690685873001

Epoch: 6| Step: 6
Training loss: 3.036120562254154
Validation loss: 2.4898019135971454

Epoch: 6| Step: 7
Training loss: 2.2674635169007846
Validation loss: 2.482987994746148

Epoch: 6| Step: 8
Training loss: 3.0911052458020576
Validation loss: 2.4738138875367026

Epoch: 6| Step: 9
Training loss: 2.6091148566584024
Validation loss: 2.497833506845687

Epoch: 6| Step: 10
Training loss: 2.8927429688005333
Validation loss: 2.48577432712909

Epoch: 6| Step: 11
Training loss: 3.401005899066963
Validation loss: 2.4909133114936086

Epoch: 6| Step: 12
Training loss: 2.429205058488584
Validation loss: 2.4823526995165572

Epoch: 6| Step: 13
Training loss: 3.1925760877559113
Validation loss: 2.485537187438676

Epoch: 34| Step: 0
Training loss: 3.020109173146661
Validation loss: 2.477807541486718

Epoch: 6| Step: 1
Training loss: 3.2189319151794042
Validation loss: 2.4968052427014142

Epoch: 6| Step: 2
Training loss: 2.7193934238294566
Validation loss: 2.4849188620741867

Epoch: 6| Step: 3
Training loss: 3.048830627401279
Validation loss: 2.4877694833038957

Epoch: 6| Step: 4
Training loss: 3.370824986570482
Validation loss: 2.4874655158417305

Epoch: 6| Step: 5
Training loss: 2.398303397837695
Validation loss: 2.496530285689763

Epoch: 6| Step: 6
Training loss: 3.401223770259166
Validation loss: 2.4983512353503685

Epoch: 6| Step: 7
Training loss: 2.635935756137816
Validation loss: 2.477097211565839

Epoch: 6| Step: 8
Training loss: 2.464443071447337
Validation loss: 2.500313880658847

Epoch: 6| Step: 9
Training loss: 2.4208441724769836
Validation loss: 2.4759938622491253

Epoch: 6| Step: 10
Training loss: 2.340828969952962
Validation loss: 2.496474993672769

Epoch: 6| Step: 11
Training loss: 2.9780346691606288
Validation loss: 2.4896635877645443

Epoch: 6| Step: 12
Training loss: 2.094742838478435
Validation loss: 2.4797488673606614

Epoch: 6| Step: 13
Training loss: 2.3825531364992023
Validation loss: 2.5029143994089362

Epoch: 35| Step: 0
Training loss: 2.741066380172632
Validation loss: 2.473114225793096

Epoch: 6| Step: 1
Training loss: 2.5852906492774568
Validation loss: 2.4809552224098983

Epoch: 6| Step: 2
Training loss: 2.389179765257129
Validation loss: 2.482534192885188

Epoch: 6| Step: 3
Training loss: 2.7397179419417803
Validation loss: 2.4903589978724163

Epoch: 6| Step: 4
Training loss: 3.2335363212917962
Validation loss: 2.4658825567871827

Epoch: 6| Step: 5
Training loss: 2.9306614591999436
Validation loss: 2.4843549623749985

Epoch: 6| Step: 6
Training loss: 2.505823219853163
Validation loss: 2.5019485575928617

Epoch: 6| Step: 7
Training loss: 2.0988534249591826
Validation loss: 2.490421085391594

Epoch: 6| Step: 8
Training loss: 2.637226151988752
Validation loss: 2.4940629253949376

Epoch: 6| Step: 9
Training loss: 2.8766154850561354
Validation loss: 2.483604421545159

Epoch: 6| Step: 10
Training loss: 3.0796520492394537
Validation loss: 2.486464708348265

Epoch: 6| Step: 11
Training loss: 2.5323463232140666
Validation loss: 2.484972701765506

Epoch: 6| Step: 12
Training loss: 3.5727662850958333
Validation loss: 2.494605451247548

Epoch: 6| Step: 13
Training loss: 2.8708804927176605
Validation loss: 2.4881078819036797

Epoch: 36| Step: 0
Training loss: 2.473423072064383
Validation loss: 2.4658496019233542

Epoch: 6| Step: 1
Training loss: 2.7376653438434713
Validation loss: 2.4952108574901692

Epoch: 6| Step: 2
Training loss: 3.284742113787528
Validation loss: 2.496264217824104

Epoch: 6| Step: 3
Training loss: 2.1702694893427568
Validation loss: 2.4910894790984326

Epoch: 6| Step: 4
Training loss: 2.4376394769915417
Validation loss: 2.491016561489507

Epoch: 6| Step: 5
Training loss: 2.6827218806359285
Validation loss: 2.4759899225542306

Epoch: 6| Step: 6
Training loss: 3.029532978589171
Validation loss: 2.4961676336234184

Epoch: 6| Step: 7
Training loss: 3.1333967696187046
Validation loss: 2.4754606180237624

Epoch: 6| Step: 8
Training loss: 2.5077902534425065
Validation loss: 2.4915317008548588

Epoch: 6| Step: 9
Training loss: 3.1835988424997614
Validation loss: 2.48715105837704

Epoch: 6| Step: 10
Training loss: 2.496962991436402
Validation loss: 2.4802091837839835

Epoch: 6| Step: 11
Training loss: 2.8336003869554545
Validation loss: 2.5019108739883875

Epoch: 6| Step: 12
Training loss: 3.0525450547101114
Validation loss: 2.477646140551234

Epoch: 6| Step: 13
Training loss: 2.497353583579473
Validation loss: 2.4820203353669377

Epoch: 37| Step: 0
Training loss: 2.153303482785706
Validation loss: 2.488165421553357

Epoch: 6| Step: 1
Training loss: 3.0428855404721604
Validation loss: 2.478063542871327

Epoch: 6| Step: 2
Training loss: 3.308534371700059
Validation loss: 2.4668364953885655

Epoch: 6| Step: 3
Training loss: 3.1584173635880908
Validation loss: 2.477872679542416

Epoch: 6| Step: 4
Training loss: 3.041332505216685
Validation loss: 2.492749200024349

Epoch: 6| Step: 5
Training loss: 2.804787126647166
Validation loss: 2.4863074617692287

Epoch: 6| Step: 6
Training loss: 2.281763097463621
Validation loss: 2.489967746603975

Epoch: 6| Step: 7
Training loss: 2.602502601468328
Validation loss: 2.4792239943511736

Epoch: 6| Step: 8
Training loss: 2.355536667080289
Validation loss: 2.4808178273071877

Epoch: 6| Step: 9
Training loss: 2.240929014471541
Validation loss: 2.484557899578427

Epoch: 6| Step: 10
Training loss: 3.09955153143885
Validation loss: 2.48134002046974

Epoch: 6| Step: 11
Training loss: 2.701621105822626
Validation loss: 2.473415361716474

Epoch: 6| Step: 12
Training loss: 3.4589996768348015
Validation loss: 2.4793294827473034

Epoch: 6| Step: 13
Training loss: 1.739769733363635
Validation loss: 2.493662995011049

Epoch: 38| Step: 0
Training loss: 3.120363992830629
Validation loss: 2.5054237045115264

Epoch: 6| Step: 1
Training loss: 2.608818954338789
Validation loss: 2.4638263758402026

Epoch: 6| Step: 2
Training loss: 2.333700276086708
Validation loss: 2.4803790864894943

Epoch: 6| Step: 3
Training loss: 3.031708043679235
Validation loss: 2.476702618519417

Epoch: 6| Step: 4
Training loss: 2.7256710486140263
Validation loss: 2.47565910974075

Epoch: 6| Step: 5
Training loss: 2.889641341819186
Validation loss: 2.469764157443204

Epoch: 6| Step: 6
Training loss: 2.7775291670702185
Validation loss: 2.476780963140071

Epoch: 6| Step: 7
Training loss: 2.085931327896416
Validation loss: 2.4809964032911136

Epoch: 6| Step: 8
Training loss: 3.082379339599277
Validation loss: 2.4781763432894723

Epoch: 6| Step: 9
Training loss: 3.480005646624314
Validation loss: 2.4762597269522515

Epoch: 6| Step: 10
Training loss: 3.015706589934151
Validation loss: 2.4928123145302443

Epoch: 6| Step: 11
Training loss: 2.6321948314547887
Validation loss: 2.481735760372592

Epoch: 6| Step: 12
Training loss: 2.507711913566403
Validation loss: 2.4756744118477503

Epoch: 6| Step: 13
Training loss: 1.7565611051273289
Validation loss: 2.4868828695851177

Epoch: 39| Step: 0
Training loss: 2.852395132077944
Validation loss: 2.4873926666925845

Epoch: 6| Step: 1
Training loss: 3.4476263532934985
Validation loss: 2.4717317588340824

Epoch: 6| Step: 2
Training loss: 2.385732593743502
Validation loss: 2.4819608038313805

Epoch: 6| Step: 3
Training loss: 2.194085046119615
Validation loss: 2.482961730327821

Epoch: 6| Step: 4
Training loss: 2.552186447447878
Validation loss: 2.494855852980001

Epoch: 6| Step: 5
Training loss: 2.733320632377827
Validation loss: 2.491186296198981

Epoch: 6| Step: 6
Training loss: 2.509369268921499
Validation loss: 2.477079118723517

Epoch: 6| Step: 7
Training loss: 3.1764736570289434
Validation loss: 2.4863715739348966

Epoch: 6| Step: 8
Training loss: 2.7177620331349837
Validation loss: 2.49025308053867

Epoch: 6| Step: 9
Training loss: 2.677763935262622
Validation loss: 2.4831371921856045

Epoch: 6| Step: 10
Training loss: 3.2668215371094678
Validation loss: 2.4974698686804806

Epoch: 6| Step: 11
Training loss: 2.9281486844109503
Validation loss: 2.4865451517573596

Epoch: 6| Step: 12
Training loss: 2.318442467708487
Validation loss: 2.4899170574170824

Epoch: 6| Step: 13
Training loss: 3.0432681914506343
Validation loss: 2.482116485766896

Epoch: 40| Step: 0
Training loss: 3.1116356993981547
Validation loss: 2.4872296644882472

Epoch: 6| Step: 1
Training loss: 2.8268443205925244
Validation loss: 2.4774182449142534

Epoch: 6| Step: 2
Training loss: 2.3571711472469135
Validation loss: 2.486857494712438

Epoch: 6| Step: 3
Training loss: 2.8631655056862604
Validation loss: 2.483450541841394

Epoch: 6| Step: 4
Training loss: 3.210932896371776
Validation loss: 2.4875309271149

Epoch: 6| Step: 5
Training loss: 2.262529665926345
Validation loss: 2.487372924441227

Epoch: 6| Step: 6
Training loss: 2.5992967975113452
Validation loss: 2.490872663024398

Epoch: 6| Step: 7
Training loss: 2.945122264921182
Validation loss: 2.4715590201745448

Epoch: 6| Step: 8
Training loss: 1.9249382108209385
Validation loss: 2.474541490580695

Epoch: 6| Step: 9
Training loss: 3.0974972312489992
Validation loss: 2.493422262629792

Epoch: 6| Step: 10
Training loss: 2.6328120472169028
Validation loss: 2.4743248024424886

Epoch: 6| Step: 11
Training loss: 3.066701070620182
Validation loss: 2.4685116766168713

Epoch: 6| Step: 12
Training loss: 2.5000595085690898
Validation loss: 2.4720619844583114

Epoch: 6| Step: 13
Training loss: 3.323282363204845
Validation loss: 2.4825605888438416

Epoch: 41| Step: 0
Training loss: 2.8394189068176527
Validation loss: 2.4666469718969437

Epoch: 6| Step: 1
Training loss: 2.394902012359527
Validation loss: 2.4883130629590497

Epoch: 6| Step: 2
Training loss: 3.135200636678068
Validation loss: 2.4962544346896207

Epoch: 6| Step: 3
Training loss: 2.8436889641887397
Validation loss: 2.496499166880408

Epoch: 6| Step: 4
Training loss: 2.8123789443348644
Validation loss: 2.460880786341869

Epoch: 6| Step: 5
Training loss: 2.7666310350199477
Validation loss: 2.4715042627978328

Epoch: 6| Step: 6
Training loss: 2.4434419247520967
Validation loss: 2.476722966994856

Epoch: 6| Step: 7
Training loss: 3.315119876909251
Validation loss: 2.4722866874764855

Epoch: 6| Step: 8
Training loss: 3.1060418901633806
Validation loss: 2.494424006786141

Epoch: 6| Step: 9
Training loss: 2.8441445213220975
Validation loss: 2.4739616393157338

Epoch: 6| Step: 10
Training loss: 2.4403659893147585
Validation loss: 2.463573239590338

Epoch: 6| Step: 11
Training loss: 2.6968789676358598
Validation loss: 2.4880946469262963

Epoch: 6| Step: 12
Training loss: 2.5875139761284682
Validation loss: 2.4868423016218886

Epoch: 6| Step: 13
Training loss: 1.9487882761839075
Validation loss: 2.4782997798316493

Epoch: 42| Step: 0
Training loss: 2.7987187451367603
Validation loss: 2.48204401103532

Epoch: 6| Step: 1
Training loss: 3.1520502835440674
Validation loss: 2.4803652180343048

Epoch: 6| Step: 2
Training loss: 2.725942109364386
Validation loss: 2.4680081851266595

Epoch: 6| Step: 3
Training loss: 2.7463074081455994
Validation loss: 2.467063397256499

Epoch: 6| Step: 4
Training loss: 3.006815797218599
Validation loss: 2.4585032382634027

Epoch: 6| Step: 5
Training loss: 2.38805076278074
Validation loss: 2.4824649905832668

Epoch: 6| Step: 6
Training loss: 2.951195788081476
Validation loss: 2.481593576857385

Epoch: 6| Step: 7
Training loss: 3.226238834874647
Validation loss: 2.489964353079981

Epoch: 6| Step: 8
Training loss: 3.0996561413453714
Validation loss: 2.480727799214454

Epoch: 6| Step: 9
Training loss: 2.8138109330875603
Validation loss: 2.4655853061378417

Epoch: 6| Step: 10
Training loss: 2.7931822368419192
Validation loss: 2.4857296198296113

Epoch: 6| Step: 11
Training loss: 1.8944313258925354
Validation loss: 2.480406036630616

Epoch: 6| Step: 12
Training loss: 2.222644557821565
Validation loss: 2.4907001638983126

Epoch: 6| Step: 13
Training loss: 2.3178890429280536
Validation loss: 2.484860522990785

Epoch: 43| Step: 0
Training loss: 2.6289581248364446
Validation loss: 2.4733834753013966

Epoch: 6| Step: 1
Training loss: 2.3211911782251717
Validation loss: 2.474135724083584

Epoch: 6| Step: 2
Training loss: 1.8623049435467836
Validation loss: 2.49238688649575

Epoch: 6| Step: 3
Training loss: 2.6529489986781507
Validation loss: 2.4744970910953152

Epoch: 6| Step: 4
Training loss: 3.641981797073852
Validation loss: 2.477549025080524

Epoch: 6| Step: 5
Training loss: 2.9498725217010837
Validation loss: 2.4769651220839752

Epoch: 6| Step: 6
Training loss: 2.767305111660832
Validation loss: 2.489587088645697

Epoch: 6| Step: 7
Training loss: 2.334519992804036
Validation loss: 2.469622682967322

Epoch: 6| Step: 8
Training loss: 2.9238129579078054
Validation loss: 2.473739475657999

Epoch: 6| Step: 9
Training loss: 2.585944138256208
Validation loss: 2.4913209698464813

Epoch: 6| Step: 10
Training loss: 2.928640112254234
Validation loss: 2.480267551134124

Epoch: 6| Step: 11
Training loss: 2.906301026255264
Validation loss: 2.4862805529123246

Epoch: 6| Step: 12
Training loss: 2.929046479350958
Validation loss: 2.469684536617689

Epoch: 6| Step: 13
Training loss: 2.5879614708757837
Validation loss: 2.504869737798689

Epoch: 44| Step: 0
Training loss: 2.9173923316315546
Validation loss: 2.471315933385285

Epoch: 6| Step: 1
Training loss: 2.7032623256133177
Validation loss: 2.4754670357628727

Epoch: 6| Step: 2
Training loss: 2.8237840415520403
Validation loss: 2.4725208261909812

Epoch: 6| Step: 3
Training loss: 3.5385860433969154
Validation loss: 2.467433864704904

Epoch: 6| Step: 4
Training loss: 2.3118062396316024
Validation loss: 2.4740398520924365

Epoch: 6| Step: 5
Training loss: 2.2357346459370926
Validation loss: 2.4680329529296836

Epoch: 6| Step: 6
Training loss: 2.280400679834489
Validation loss: 2.4824941806989167

Epoch: 6| Step: 7
Training loss: 1.9637381322976826
Validation loss: 2.474184464297339

Epoch: 6| Step: 8
Training loss: 2.4153847637858665
Validation loss: 2.4710733880988043

Epoch: 6| Step: 9
Training loss: 3.1932127379367756
Validation loss: 2.481987794123606

Epoch: 6| Step: 10
Training loss: 2.7927217814486784
Validation loss: 2.498216584602483

Epoch: 6| Step: 11
Training loss: 3.272230267114542
Validation loss: 2.4658899195368096

Epoch: 6| Step: 12
Training loss: 2.9580305419129207
Validation loss: 2.4805948747475375

Epoch: 6| Step: 13
Training loss: 2.5942919980645827
Validation loss: 2.46904060187172

Epoch: 45| Step: 0
Training loss: 1.985366573549068
Validation loss: 2.480755410050815

Epoch: 6| Step: 1
Training loss: 2.7906673312847854
Validation loss: 2.480435709870121

Epoch: 6| Step: 2
Training loss: 2.4567073250679416
Validation loss: 2.4514212930148855

Epoch: 6| Step: 3
Training loss: 2.846298752385208
Validation loss: 2.472643488042483

Epoch: 6| Step: 4
Training loss: 2.250539820869883
Validation loss: 2.4845380089176548

Epoch: 6| Step: 5
Training loss: 3.259051263518975
Validation loss: 2.459082434225402

Epoch: 6| Step: 6
Training loss: 2.2404634978801266
Validation loss: 2.4689616596356037

Epoch: 6| Step: 7
Training loss: 2.5308182901591247
Validation loss: 2.494872758514959

Epoch: 6| Step: 8
Training loss: 2.4547573417183153
Validation loss: 2.498831062420519

Epoch: 6| Step: 9
Training loss: 3.0321108195502506
Validation loss: 2.465782282099534

Epoch: 6| Step: 10
Training loss: 2.936163415586289
Validation loss: 2.4731847397896995

Epoch: 6| Step: 11
Training loss: 3.1926079008766854
Validation loss: 2.4676133365341446

Epoch: 6| Step: 12
Training loss: 3.057934218582974
Validation loss: 2.5004751933101663

Epoch: 6| Step: 13
Training loss: 3.187390045064683
Validation loss: 2.4759074852008323

Epoch: 46| Step: 0
Training loss: 2.8069759797691494
Validation loss: 2.4828838750041387

Epoch: 6| Step: 1
Training loss: 2.6667504496128345
Validation loss: 2.4626752185671825

Epoch: 6| Step: 2
Training loss: 3.0647481335056184
Validation loss: 2.473370802088905

Epoch: 6| Step: 3
Training loss: 2.633388377069061
Validation loss: 2.485527171268128

Epoch: 6| Step: 4
Training loss: 2.5305704217114218
Validation loss: 2.4689965322964875

Epoch: 6| Step: 5
Training loss: 2.377813880810717
Validation loss: 2.47013840031078

Epoch: 6| Step: 6
Training loss: 3.0133114177053195
Validation loss: 2.4632619031934455

Epoch: 6| Step: 7
Training loss: 2.3493331531188297
Validation loss: 2.4731526949129994

Epoch: 6| Step: 8
Training loss: 2.983927108948225
Validation loss: 2.474926455608572

Epoch: 6| Step: 9
Training loss: 3.313354238089835
Validation loss: 2.4725491694421278

Epoch: 6| Step: 10
Training loss: 2.3250487824931545
Validation loss: 2.470018600105544

Epoch: 6| Step: 11
Training loss: 2.625844728700767
Validation loss: 2.479875892442437

Epoch: 6| Step: 12
Training loss: 2.7339261803808323
Validation loss: 2.4815776604163102

Epoch: 6| Step: 13
Training loss: 3.0152246080940404
Validation loss: 2.459088016909345

Epoch: 47| Step: 0
Training loss: 2.556822278568569
Validation loss: 2.4706377190590145

Epoch: 6| Step: 1
Training loss: 2.532458546667325
Validation loss: 2.470623430669682

Epoch: 6| Step: 2
Training loss: 2.9066749180084606
Validation loss: 2.490083294571714

Epoch: 6| Step: 3
Training loss: 2.5957566737269495
Validation loss: 2.4618177301740753

Epoch: 6| Step: 4
Training loss: 2.8454676879592595
Validation loss: 2.4770665166837325

Epoch: 6| Step: 5
Training loss: 2.5021276956564575
Validation loss: 2.493467409818256

Epoch: 6| Step: 6
Training loss: 1.594433880851095
Validation loss: 2.4942141710194004

Epoch: 6| Step: 7
Training loss: 3.1672955607952966
Validation loss: 2.4711088721000167

Epoch: 6| Step: 8
Training loss: 2.9617693293747243
Validation loss: 2.4679960504328973

Epoch: 6| Step: 9
Training loss: 2.939912170862881
Validation loss: 2.481902993801486

Epoch: 6| Step: 10
Training loss: 3.4206680189759604
Validation loss: 2.467738478470698

Epoch: 6| Step: 11
Training loss: 2.378525576646635
Validation loss: 2.475323282497016

Epoch: 6| Step: 12
Training loss: 2.7905660898584137
Validation loss: 2.484269340932191

Epoch: 6| Step: 13
Training loss: 2.717087862404594
Validation loss: 2.4721902512083918

Epoch: 48| Step: 0
Training loss: 2.1352742837718193
Validation loss: 2.464426691592568

Epoch: 6| Step: 1
Training loss: 3.058751829308141
Validation loss: 2.4787213311660192

Epoch: 6| Step: 2
Training loss: 2.2802008737785084
Validation loss: 2.4876674691572567

Epoch: 6| Step: 3
Training loss: 2.324506161654309
Validation loss: 2.485840467169314

Epoch: 6| Step: 4
Training loss: 2.285123280344426
Validation loss: 2.476138842802874

Epoch: 6| Step: 5
Training loss: 3.043687140659711
Validation loss: 2.4763234920739503

Epoch: 6| Step: 6
Training loss: 2.950008948361031
Validation loss: 2.4784780676427602

Epoch: 6| Step: 7
Training loss: 2.385988613897689
Validation loss: 2.4860639588486704

Epoch: 6| Step: 8
Training loss: 2.989179169630736
Validation loss: 2.5052075610644544

Epoch: 6| Step: 9
Training loss: 2.857943317136868
Validation loss: 2.5047092158426243

Epoch: 6| Step: 10
Training loss: 2.8562493255414103
Validation loss: 2.470527614352049

Epoch: 6| Step: 11
Training loss: 3.268012675173212
Validation loss: 2.478771193857642

Epoch: 6| Step: 12
Training loss: 3.021116642437348
Validation loss: 2.470774906219321

Epoch: 6| Step: 13
Training loss: 2.307674425006928
Validation loss: 2.4754974030318295

Epoch: 49| Step: 0
Training loss: 2.299661516078289
Validation loss: 2.5023508908688927

Epoch: 6| Step: 1
Training loss: 2.765434991376279
Validation loss: 2.470866369778361

Epoch: 6| Step: 2
Training loss: 3.1621078670278986
Validation loss: 2.4794510860649077

Epoch: 6| Step: 3
Training loss: 2.6736117958849626
Validation loss: 2.474328791930974

Epoch: 6| Step: 4
Training loss: 2.348089854079181
Validation loss: 2.467415339432645

Epoch: 6| Step: 5
Training loss: 2.754233482885405
Validation loss: 2.473281979983673

Epoch: 6| Step: 6
Training loss: 2.7013596961092894
Validation loss: 2.4882891162190273

Epoch: 6| Step: 7
Training loss: 2.440269657305563
Validation loss: 2.4689187568129976

Epoch: 6| Step: 8
Training loss: 2.7932452298414443
Validation loss: 2.4753639056414265

Epoch: 6| Step: 9
Training loss: 2.6424075999927625
Validation loss: 2.467727002650884

Epoch: 6| Step: 10
Training loss: 3.2168019149360942
Validation loss: 2.4842897074050816

Epoch: 6| Step: 11
Training loss: 2.6025429101167616
Validation loss: 2.49558315703351

Epoch: 6| Step: 12
Training loss: 2.8845758601684244
Validation loss: 2.479742241013605

Epoch: 6| Step: 13
Training loss: 2.977131145957378
Validation loss: 2.4761719128307456

Epoch: 50| Step: 0
Training loss: 2.7819691274809872
Validation loss: 2.481337192687832

Epoch: 6| Step: 1
Training loss: 2.3389226409135944
Validation loss: 2.4749354503538323

Epoch: 6| Step: 2
Training loss: 2.631667071924869
Validation loss: 2.4630482434959484

Epoch: 6| Step: 3
Training loss: 2.441616885444829
Validation loss: 2.4752418073869182

Epoch: 6| Step: 4
Training loss: 2.7375944530618144
Validation loss: 2.4813215886875475

Epoch: 6| Step: 5
Training loss: 1.6541804212996047
Validation loss: 2.4770795720293832

Epoch: 6| Step: 6
Training loss: 2.0621175700431498
Validation loss: 2.4921023688324095

Epoch: 6| Step: 7
Training loss: 3.1724792806852107
Validation loss: 2.474106771077863

Epoch: 6| Step: 8
Training loss: 2.709434598379431
Validation loss: 2.4736712517913535

Epoch: 6| Step: 9
Training loss: 3.25708877977496
Validation loss: 2.4621315211476027

Epoch: 6| Step: 10
Training loss: 2.8004555399763587
Validation loss: 2.4513480143072535

Epoch: 6| Step: 11
Training loss: 3.5791051596588335
Validation loss: 2.4750131279182983

Epoch: 6| Step: 12
Training loss: 2.5045384220489675
Validation loss: 2.4756900514415654

Epoch: 6| Step: 13
Training loss: 2.9904096216915454
Validation loss: 2.4812513534572376

Epoch: 51| Step: 0
Training loss: 2.883448088756619
Validation loss: 2.4655202786097274

Epoch: 6| Step: 1
Training loss: 3.141829530118667
Validation loss: 2.4719297285881803

Epoch: 6| Step: 2
Training loss: 3.2807384273828126
Validation loss: 2.474755963603745

Epoch: 6| Step: 3
Training loss: 2.737442650041835
Validation loss: 2.4722630552457976

Epoch: 6| Step: 4
Training loss: 2.4792292824753033
Validation loss: 2.4554133926594486

Epoch: 6| Step: 5
Training loss: 2.5780032967249684
Validation loss: 2.4783794383406508

Epoch: 6| Step: 6
Training loss: 2.4412619097956774
Validation loss: 2.472517790283534

Epoch: 6| Step: 7
Training loss: 2.888147560597815
Validation loss: 2.4816614543170514

Epoch: 6| Step: 8
Training loss: 2.879300922478416
Validation loss: 2.4798655866901704

Epoch: 6| Step: 9
Training loss: 2.450548702220702
Validation loss: 2.4870459836825427

Epoch: 6| Step: 10
Training loss: 2.623521479250247
Validation loss: 2.469088194634344

Epoch: 6| Step: 11
Training loss: 2.668595917517298
Validation loss: 2.4757939953277055

Epoch: 6| Step: 12
Training loss: 2.3790395414346253
Validation loss: 2.4768546558927733

Epoch: 6| Step: 13
Training loss: 2.4302913001382844
Validation loss: 2.4871973243659538

Epoch: 52| Step: 0
Training loss: 3.088801269599754
Validation loss: 2.4753155014275685

Epoch: 6| Step: 1
Training loss: 2.5478714941786977
Validation loss: 2.469893041743305

Epoch: 6| Step: 2
Training loss: 2.33278798360647
Validation loss: 2.4758165128214253

Epoch: 6| Step: 3
Training loss: 2.1695372809771682
Validation loss: 2.469016564774251

Epoch: 6| Step: 4
Training loss: 2.49179829873862
Validation loss: 2.4680327202522676

Epoch: 6| Step: 5
Training loss: 3.0652114387005067
Validation loss: 2.469234104441679

Epoch: 6| Step: 6
Training loss: 2.2858524663914577
Validation loss: 2.486959910091375

Epoch: 6| Step: 7
Training loss: 3.123772036568961
Validation loss: 2.478417321989779

Epoch: 6| Step: 8
Training loss: 2.8955440422480443
Validation loss: 2.4747464103629726

Epoch: 6| Step: 9
Training loss: 3.2090403946057497
Validation loss: 2.4742968266278123

Epoch: 6| Step: 10
Training loss: 2.7422667923899255
Validation loss: 2.4709006272763583

Epoch: 6| Step: 11
Training loss: 2.7752548066422245
Validation loss: 2.467847329627052

Epoch: 6| Step: 12
Training loss: 2.371139098586882
Validation loss: 2.4682991277598187

Epoch: 6| Step: 13
Training loss: 2.733565117925082
Validation loss: 2.4622936162918183

Epoch: 53| Step: 0
Training loss: 2.7253061804989582
Validation loss: 2.479747967410829

Epoch: 6| Step: 1
Training loss: 2.333755750112698
Validation loss: 2.4625689355556237

Epoch: 6| Step: 2
Training loss: 3.1667223641031486
Validation loss: 2.487205404282293

Epoch: 6| Step: 3
Training loss: 2.2224865464789176
Validation loss: 2.469792338743079

Epoch: 6| Step: 4
Training loss: 2.8858163788580438
Validation loss: 2.477700739946246

Epoch: 6| Step: 5
Training loss: 2.912296527091042
Validation loss: 2.4853932894273387

Epoch: 6| Step: 6
Training loss: 2.7087856404099084
Validation loss: 2.486247412662297

Epoch: 6| Step: 7
Training loss: 2.5444761809637644
Validation loss: 2.4717716403115517

Epoch: 6| Step: 8
Training loss: 2.8473447778475207
Validation loss: 2.483649742038951

Epoch: 6| Step: 9
Training loss: 2.549206655171421
Validation loss: 2.4890480755004343

Epoch: 6| Step: 10
Training loss: 2.900711689142482
Validation loss: 2.4651917078928087

Epoch: 6| Step: 11
Training loss: 2.724137854024552
Validation loss: 2.4686032312997175

Epoch: 6| Step: 12
Training loss: 2.9586519060848295
Validation loss: 2.4571149263272027

Epoch: 6| Step: 13
Training loss: 2.104613178076555
Validation loss: 2.487307385845553

Epoch: 54| Step: 0
Training loss: 3.246324368030068
Validation loss: 2.477697002142632

Epoch: 6| Step: 1
Training loss: 2.2400201297604845
Validation loss: 2.477980320466793

Epoch: 6| Step: 2
Training loss: 2.544264127995152
Validation loss: 2.4820858679324145

Epoch: 6| Step: 3
Training loss: 2.9559466087361472
Validation loss: 2.475647331496388

Epoch: 6| Step: 4
Training loss: 2.684108101806829
Validation loss: 2.4961101808683916

Epoch: 6| Step: 5
Training loss: 2.5603744250900635
Validation loss: 2.4637669775030497

Epoch: 6| Step: 6
Training loss: 2.517337476831329
Validation loss: 2.4726936220738622

Epoch: 6| Step: 7
Training loss: 2.8015374901118486
Validation loss: 2.482733701002746

Epoch: 6| Step: 8
Training loss: 2.366647488780516
Validation loss: 2.4534511982847165

Epoch: 6| Step: 9
Training loss: 3.166465920225606
Validation loss: 2.4691313571967775

Epoch: 6| Step: 10
Training loss: 2.633830883810067
Validation loss: 2.4667684781260517

Epoch: 6| Step: 11
Training loss: 2.8221035920722697
Validation loss: 2.4598146021765084

Epoch: 6| Step: 12
Training loss: 2.6009963510701106
Validation loss: 2.476659773193437

Epoch: 6| Step: 13
Training loss: 2.7341762797488856
Validation loss: 2.459163140566889

Epoch: 55| Step: 0
Training loss: 2.236183128487213
Validation loss: 2.468036644603246

Epoch: 6| Step: 1
Training loss: 3.2087387390295774
Validation loss: 2.4743004291753743

Epoch: 6| Step: 2
Training loss: 2.611901619020871
Validation loss: 2.48724060969383

Epoch: 6| Step: 3
Training loss: 3.1511290146672253
Validation loss: 2.4594541929680815

Epoch: 6| Step: 4
Training loss: 2.4389513047828673
Validation loss: 2.4614364386487373

Epoch: 6| Step: 5
Training loss: 2.8538050364443532
Validation loss: 2.4818461745805083

Epoch: 6| Step: 6
Training loss: 2.2176093809724806
Validation loss: 2.469876125595266

Epoch: 6| Step: 7
Training loss: 1.999895927582455
Validation loss: 2.4755433493488828

Epoch: 6| Step: 8
Training loss: 3.0385657053979447
Validation loss: 2.4716927749287887

Epoch: 6| Step: 9
Training loss: 3.0119660470170957
Validation loss: 2.4812517491746178

Epoch: 6| Step: 10
Training loss: 2.963532370143225
Validation loss: 2.487645657684223

Epoch: 6| Step: 11
Training loss: 2.971177564226693
Validation loss: 2.4785568753759737

Epoch: 6| Step: 12
Training loss: 2.46548284355326
Validation loss: 2.482683091291585

Epoch: 6| Step: 13
Training loss: 2.489402817655231
Validation loss: 2.4707973594711885

Epoch: 56| Step: 0
Training loss: 1.9784092775704996
Validation loss: 2.4874566735909394

Epoch: 6| Step: 1
Training loss: 2.7142862090490363
Validation loss: 2.4745869770563353

Epoch: 6| Step: 2
Training loss: 3.3057806132518324
Validation loss: 2.4810732504661863

Epoch: 6| Step: 3
Training loss: 3.0537813603668202
Validation loss: 2.472277570584767

Epoch: 6| Step: 4
Training loss: 2.554102746143958
Validation loss: 2.508910318011461

Epoch: 6| Step: 5
Training loss: 2.5882902477417744
Validation loss: 2.4572217071133196

Epoch: 6| Step: 6
Training loss: 2.315794788473136
Validation loss: 2.478670990151

Epoch: 6| Step: 7
Training loss: 2.2629631453617676
Validation loss: 2.461123142379535

Epoch: 6| Step: 8
Training loss: 2.93331009754457
Validation loss: 2.462629858731941

Epoch: 6| Step: 9
Training loss: 2.712400014414504
Validation loss: 2.4734753150239595

Epoch: 6| Step: 10
Training loss: 3.503830312460994
Validation loss: 2.4657707976953303

Epoch: 6| Step: 11
Training loss: 2.7809669264850334
Validation loss: 2.4745915167484394

Epoch: 6| Step: 12
Training loss: 2.231528222611802
Validation loss: 2.471428650191401

Epoch: 6| Step: 13
Training loss: 2.3089594156061426
Validation loss: 2.4764483139459323

Epoch: 57| Step: 0
Training loss: 2.9258369878494213
Validation loss: 2.4571155909435975

Epoch: 6| Step: 1
Training loss: 2.637510370170853
Validation loss: 2.4632528798715683

Epoch: 6| Step: 2
Training loss: 2.2638213245734535
Validation loss: 2.4733350945203783

Epoch: 6| Step: 3
Training loss: 2.902852687649907
Validation loss: 2.464771054447895

Epoch: 6| Step: 4
Training loss: 2.4484168874022663
Validation loss: 2.4915834118366464

Epoch: 6| Step: 5
Training loss: 2.716698672880328
Validation loss: 2.4684081707368666

Epoch: 6| Step: 6
Training loss: 2.4142981355594264
Validation loss: 2.46583533569295

Epoch: 6| Step: 7
Training loss: 3.1322718127557794
Validation loss: 2.479718941398233

Epoch: 6| Step: 8
Training loss: 2.7320367024917886
Validation loss: 2.47566141070651

Epoch: 6| Step: 9
Training loss: 3.100388619459632
Validation loss: 2.496721335834331

Epoch: 6| Step: 10
Training loss: 3.2829040717925775
Validation loss: 2.4825754611663964

Epoch: 6| Step: 11
Training loss: 2.533505035738686
Validation loss: 2.4818717938503565

Epoch: 6| Step: 12
Training loss: 2.2992421103978073
Validation loss: 2.475495555509552

Epoch: 6| Step: 13
Training loss: 1.9789095728349706
Validation loss: 2.478746852417585

Epoch: 58| Step: 0
Training loss: 2.8270948862857845
Validation loss: 2.46240775389102

Epoch: 6| Step: 1
Training loss: 2.3216052836975187
Validation loss: 2.477037926535282

Epoch: 6| Step: 2
Training loss: 3.262642844862104
Validation loss: 2.495374288654455

Epoch: 6| Step: 3
Training loss: 2.482093963455133
Validation loss: 2.4832670341963428

Epoch: 6| Step: 4
Training loss: 2.3515077502191697
Validation loss: 2.4884756645320785

Epoch: 6| Step: 5
Training loss: 3.002627493686942
Validation loss: 2.4883140190517894

Epoch: 6| Step: 6
Training loss: 3.0030641801691225
Validation loss: 2.4891980045015134

Epoch: 6| Step: 7
Training loss: 2.5490092129157356
Validation loss: 2.495492471995831

Epoch: 6| Step: 8
Training loss: 2.832460063171315
Validation loss: 2.4890820590727722

Epoch: 6| Step: 9
Training loss: 2.661270781973866
Validation loss: 2.4910837309182043

Epoch: 6| Step: 10
Training loss: 3.122452269556603
Validation loss: 2.474454993936906

Epoch: 6| Step: 11
Training loss: 2.3789449353509906
Validation loss: 2.4968663485327345

Epoch: 6| Step: 12
Training loss: 2.555758097357704
Validation loss: 2.4700851018310095

Epoch: 6| Step: 13
Training loss: 2.271205265022402
Validation loss: 2.4827955615371273

Epoch: 59| Step: 0
Training loss: 3.6410663648265587
Validation loss: 2.481074610260844

Epoch: 6| Step: 1
Training loss: 2.269478093114034
Validation loss: 2.463621028504734

Epoch: 6| Step: 2
Training loss: 2.2877113077924656
Validation loss: 2.464367094466625

Epoch: 6| Step: 3
Training loss: 2.8442903780770656
Validation loss: 2.4576468665945006

Epoch: 6| Step: 4
Training loss: 3.146630613503033
Validation loss: 2.502816559970305

Epoch: 6| Step: 5
Training loss: 2.5499425096202
Validation loss: 2.478219895316945

Epoch: 6| Step: 6
Training loss: 2.2033011724497755
Validation loss: 2.471984995079252

Epoch: 6| Step: 7
Training loss: 2.2799821230538875
Validation loss: 2.4808147416168103

Epoch: 6| Step: 8
Training loss: 2.577477298640301
Validation loss: 2.487006049753677

Epoch: 6| Step: 9
Training loss: 2.655442148666269
Validation loss: 2.480069918741819

Epoch: 6| Step: 10
Training loss: 2.662351892497929
Validation loss: 2.4752916060484935

Epoch: 6| Step: 11
Training loss: 2.6894822905156515
Validation loss: 2.4643050657369536

Epoch: 6| Step: 12
Training loss: 2.9557173718904717
Validation loss: 2.477507711359428

Epoch: 6| Step: 13
Training loss: 2.823228506809209
Validation loss: 2.476918618393768

Epoch: 60| Step: 0
Training loss: 2.453419661592503
Validation loss: 2.4675631678552583

Epoch: 6| Step: 1
Training loss: 2.232945124729605
Validation loss: 2.4793749899513045

Epoch: 6| Step: 2
Training loss: 2.781469529306794
Validation loss: 2.471711591746091

Epoch: 6| Step: 3
Training loss: 2.9364922600814167
Validation loss: 2.478810759887568

Epoch: 6| Step: 4
Training loss: 2.5219935960075754
Validation loss: 2.4742341277835673

Epoch: 6| Step: 5
Training loss: 3.3999351270881926
Validation loss: 2.4598082978468803

Epoch: 6| Step: 6
Training loss: 2.7254688069656785
Validation loss: 2.4756292384133007

Epoch: 6| Step: 7
Training loss: 2.595632123011941
Validation loss: 2.4708159579553026

Epoch: 6| Step: 8
Training loss: 2.8306883265342972
Validation loss: 2.4921187601797548

Epoch: 6| Step: 9
Training loss: 2.6054537428119153
Validation loss: 2.4784102353999025

Epoch: 6| Step: 10
Training loss: 2.6162615148561565
Validation loss: 2.459475022913133

Epoch: 6| Step: 11
Training loss: 2.476082066286741
Validation loss: 2.4731197436311874

Epoch: 6| Step: 12
Training loss: 2.754366442600198
Validation loss: 2.486155339428877

Epoch: 6| Step: 13
Training loss: 2.718762803321595
Validation loss: 2.489350662826978

Epoch: 61| Step: 0
Training loss: 2.7634654261174383
Validation loss: 2.4717327586792575

Epoch: 6| Step: 1
Training loss: 2.7117661850323964
Validation loss: 2.4852005426720862

Epoch: 6| Step: 2
Training loss: 2.8499811673796978
Validation loss: 2.4754177750205493

Epoch: 6| Step: 3
Training loss: 2.8095995039976374
Validation loss: 2.466714045713396

Epoch: 6| Step: 4
Training loss: 2.6187710198990453
Validation loss: 2.4725099879428205

Epoch: 6| Step: 5
Training loss: 2.459714167666864
Validation loss: 2.46815606944563

Epoch: 6| Step: 6
Training loss: 2.2370420957039814
Validation loss: 2.4914975942939255

Epoch: 6| Step: 7
Training loss: 2.694439555903279
Validation loss: 2.4680029976095086

Epoch: 6| Step: 8
Training loss: 2.23264112088448
Validation loss: 2.4767881491002175

Epoch: 6| Step: 9
Training loss: 2.9131885680567677
Validation loss: 2.4761136932798142

Epoch: 6| Step: 10
Training loss: 3.0335206641176695
Validation loss: 2.4869463504755904

Epoch: 6| Step: 11
Training loss: 2.2820019462503596
Validation loss: 2.4844918435424175

Epoch: 6| Step: 12
Training loss: 3.390574090109588
Validation loss: 2.47538856463373

Epoch: 6| Step: 13
Training loss: 2.1944226399343063
Validation loss: 2.488878983979591

Epoch: 62| Step: 0
Training loss: 2.5828346468419627
Validation loss: 2.4789336048360786

Epoch: 6| Step: 1
Training loss: 2.8223220555560844
Validation loss: 2.468878955933628

Epoch: 6| Step: 2
Training loss: 2.8791714135962154
Validation loss: 2.4957587905964016

Epoch: 6| Step: 3
Training loss: 2.5516621352374975
Validation loss: 2.4834223250720067

Epoch: 6| Step: 4
Training loss: 2.879522663931424
Validation loss: 2.4759177183812695

Epoch: 6| Step: 5
Training loss: 2.5790563577245806
Validation loss: 2.493926791068083

Epoch: 6| Step: 6
Training loss: 2.5474421331929316
Validation loss: 2.4703959249280047

Epoch: 6| Step: 7
Training loss: 2.6650828088487684
Validation loss: 2.47163292463181

Epoch: 6| Step: 8
Training loss: 2.521041630317602
Validation loss: 2.4611884334754754

Epoch: 6| Step: 9
Training loss: 3.1537188965922667
Validation loss: 2.4763652960697633

Epoch: 6| Step: 10
Training loss: 2.6627588746207076
Validation loss: 2.468186050952235

Epoch: 6| Step: 11
Training loss: 2.5787738330385066
Validation loss: 2.4852967768575094

Epoch: 6| Step: 12
Training loss: 2.4898947570191585
Validation loss: 2.4782004741275774

Epoch: 6| Step: 13
Training loss: 2.6499893908018395
Validation loss: 2.481465164930817

Epoch: 63| Step: 0
Training loss: 2.2934903489003977
Validation loss: 2.4883385059246415

Epoch: 6| Step: 1
Training loss: 2.46161634982199
Validation loss: 2.4919816477748373

Epoch: 6| Step: 2
Training loss: 3.0084779473907606
Validation loss: 2.4785475167590736

Epoch: 6| Step: 3
Training loss: 3.4414431064463678
Validation loss: 2.4503883808213898

Epoch: 6| Step: 4
Training loss: 2.8076494563363013
Validation loss: 2.4773179642337344

Epoch: 6| Step: 5
Training loss: 2.2492917323619293
Validation loss: 2.4815572623875903

Epoch: 6| Step: 6
Training loss: 2.310660171633201
Validation loss: 2.4826944096918475

Epoch: 6| Step: 7
Training loss: 3.1179118832511525
Validation loss: 2.47380856503749

Epoch: 6| Step: 8
Training loss: 2.570288568170787
Validation loss: 2.4797050041185056

Epoch: 6| Step: 9
Training loss: 2.737985809974876
Validation loss: 2.462139116895201

Epoch: 6| Step: 10
Training loss: 2.5530920617209554
Validation loss: 2.4599217555914117

Epoch: 6| Step: 11
Training loss: 2.07009161004696
Validation loss: 2.485847959533122

Epoch: 6| Step: 12
Training loss: 3.0509528625907967
Validation loss: 2.4904667563834684

Epoch: 6| Step: 13
Training loss: 2.3469160947490724
Validation loss: 2.494720333282781

Epoch: 64| Step: 0
Training loss: 2.7762778767951395
Validation loss: 2.474149374631626

Epoch: 6| Step: 1
Training loss: 2.21849337960838
Validation loss: 2.4649362053520507

Epoch: 6| Step: 2
Training loss: 2.914542723657504
Validation loss: 2.4722580415337596

Epoch: 6| Step: 3
Training loss: 3.1209955116442596
Validation loss: 2.4543967105782203

Epoch: 6| Step: 4
Training loss: 2.088616297681417
Validation loss: 2.4890735217673856

Epoch: 6| Step: 5
Training loss: 2.6530883822480877
Validation loss: 2.4714074049292596

Epoch: 6| Step: 6
Training loss: 3.08795378280801
Validation loss: 2.4773475989188376

Epoch: 6| Step: 7
Training loss: 2.6642872108709486
Validation loss: 2.4880217672544007

Epoch: 6| Step: 8
Training loss: 3.0248022030563826
Validation loss: 2.494483538410035

Epoch: 6| Step: 9
Training loss: 1.9742849745698765
Validation loss: 2.4880221546822026

Epoch: 6| Step: 10
Training loss: 1.9948375952258104
Validation loss: 2.4796088690267086

Epoch: 6| Step: 11
Training loss: 2.7988620284822865
Validation loss: 2.484084966499219

Epoch: 6| Step: 12
Training loss: 2.9857474960805983
Validation loss: 2.4799419003438143

Epoch: 6| Step: 13
Training loss: 3.087822061027223
Validation loss: 2.4818253242537938

Epoch: 65| Step: 0
Training loss: 2.555832632450505
Validation loss: 2.466823356214188

Epoch: 6| Step: 1
Training loss: 2.509270265134621
Validation loss: 2.4912012466904194

Epoch: 6| Step: 2
Training loss: 2.825480958625007
Validation loss: 2.4842595724785186

Epoch: 6| Step: 3
Training loss: 3.2613108488395874
Validation loss: 2.4799931634903993

Epoch: 6| Step: 4
Training loss: 1.785784254065729
Validation loss: 2.4865983639366913

Epoch: 6| Step: 5
Training loss: 2.533150042210792
Validation loss: 2.463211234783326

Epoch: 6| Step: 6
Training loss: 2.770975658996788
Validation loss: 2.4653575658030826

Epoch: 6| Step: 7
Training loss: 2.7836347492891287
Validation loss: 2.483974884539209

Epoch: 6| Step: 8
Training loss: 2.754589758927858
Validation loss: 2.4897676793436587

Epoch: 6| Step: 9
Training loss: 2.7307242299894483
Validation loss: 2.4931577859446894

Epoch: 6| Step: 10
Training loss: 3.146646070439881
Validation loss: 2.478476444730084

Epoch: 6| Step: 11
Training loss: 2.7540613009044304
Validation loss: 2.4891953792690433

Epoch: 6| Step: 12
Training loss: 2.6882850919661134
Validation loss: 2.505451846423127

Epoch: 6| Step: 13
Training loss: 2.0597706855988114
Validation loss: 2.476981037114452

Epoch: 66| Step: 0
Training loss: 2.400391618248879
Validation loss: 2.4953792538666564

Epoch: 6| Step: 1
Training loss: 2.6109687369559462
Validation loss: 2.4729716823857353

Epoch: 6| Step: 2
Training loss: 3.219978468449793
Validation loss: 2.46462746369345

Epoch: 6| Step: 3
Training loss: 2.9091934557201893
Validation loss: 2.465099224684482

Epoch: 6| Step: 4
Training loss: 2.618300744899441
Validation loss: 2.478783392153778

Epoch: 6| Step: 5
Training loss: 2.745035892939805
Validation loss: 2.479953771903623

Epoch: 6| Step: 6
Training loss: 2.239636395439415
Validation loss: 2.473345882510086

Epoch: 6| Step: 7
Training loss: 2.9512150153510497
Validation loss: 2.4813505783891316

Epoch: 6| Step: 8
Training loss: 2.466675478257945
Validation loss: 2.4616083160940154

Epoch: 6| Step: 9
Training loss: 2.4543838672560327
Validation loss: 2.463295582684588

Epoch: 6| Step: 10
Training loss: 2.5787482230864045
Validation loss: 2.4767001104652167

Epoch: 6| Step: 11
Training loss: 2.88629023322756
Validation loss: 2.4856042053182383

Epoch: 6| Step: 12
Training loss: 2.5709752674790103
Validation loss: 2.46903929671006

Epoch: 6| Step: 13
Training loss: 2.8908643468793387
Validation loss: 2.4674532220631735

Epoch: 67| Step: 0
Training loss: 3.0895582373421466
Validation loss: 2.48272860052986

Epoch: 6| Step: 1
Training loss: 2.4935711215692193
Validation loss: 2.4832701488428306

Epoch: 6| Step: 2
Training loss: 2.366826498875921
Validation loss: 2.4838362187151093

Epoch: 6| Step: 3
Training loss: 1.8920279097726447
Validation loss: 2.458797782905221

Epoch: 6| Step: 4
Training loss: 2.530945182625664
Validation loss: 2.490398733918889

Epoch: 6| Step: 5
Training loss: 3.1217918713320785
Validation loss: 2.4375495621633245

Epoch: 6| Step: 6
Training loss: 2.9820141466753105
Validation loss: 2.4624612763227605

Epoch: 6| Step: 7
Training loss: 2.996627183200749
Validation loss: 2.485221782976852

Epoch: 6| Step: 8
Training loss: 2.559161081095788
Validation loss: 2.4585232905487144

Epoch: 6| Step: 9
Training loss: 2.809388537687245
Validation loss: 2.4586475130532346

Epoch: 6| Step: 10
Training loss: 2.6670692457857945
Validation loss: 2.460587814235817

Epoch: 6| Step: 11
Training loss: 2.233109656088232
Validation loss: 2.4633223835748126

Epoch: 6| Step: 12
Training loss: 2.8154450997345233
Validation loss: 2.4692227144789345

Epoch: 6| Step: 13
Training loss: 2.609956779268277
Validation loss: 2.487613373467588

Epoch: 68| Step: 0
Training loss: 2.467088164153156
Validation loss: 2.4762089176284587

Epoch: 6| Step: 1
Training loss: 2.531350875539864
Validation loss: 2.489809697787848

Epoch: 6| Step: 2
Training loss: 3.1869416589343413
Validation loss: 2.480744307055125

Epoch: 6| Step: 3
Training loss: 2.7888587000995755
Validation loss: 2.4839546517196203

Epoch: 6| Step: 4
Training loss: 2.6208246721166026
Validation loss: 2.481136797337925

Epoch: 6| Step: 5
Training loss: 2.5820884986798283
Validation loss: 2.471737448818964

Epoch: 6| Step: 6
Training loss: 2.0601411682201793
Validation loss: 2.4879736051810966

Epoch: 6| Step: 7
Training loss: 2.508476383358859
Validation loss: 2.5127264102947247

Epoch: 6| Step: 8
Training loss: 2.6000022448016527
Validation loss: 2.477695570135545

Epoch: 6| Step: 9
Training loss: 2.6382793414081043
Validation loss: 2.473002270003591

Epoch: 6| Step: 10
Training loss: 2.935977297640556
Validation loss: 2.484252654767858

Epoch: 6| Step: 11
Training loss: 2.8830063504014483
Validation loss: 2.472795121842582

Epoch: 6| Step: 12
Training loss: 2.8043170142337335
Validation loss: 2.497159258630415

Epoch: 6| Step: 13
Training loss: 2.6335468117178547
Validation loss: 2.4779928645793396

Epoch: 69| Step: 0
Training loss: 3.027951677871592
Validation loss: 2.4747254422065113

Epoch: 6| Step: 1
Training loss: 2.4167733881394717
Validation loss: 2.4601468880361663

Epoch: 6| Step: 2
Training loss: 2.3889689974204327
Validation loss: 2.467030724191544

Epoch: 6| Step: 3
Training loss: 2.5636537327168805
Validation loss: 2.469923526326863

Epoch: 6| Step: 4
Training loss: 2.9323070970652143
Validation loss: 2.477348838648262

Epoch: 6| Step: 5
Training loss: 2.5409422503938233
Validation loss: 2.475574786465363

Epoch: 6| Step: 6
Training loss: 2.5491276239866028
Validation loss: 2.455164376021797

Epoch: 6| Step: 7
Training loss: 3.1148331625944814
Validation loss: 2.4879611175732026

Epoch: 6| Step: 8
Training loss: 2.8298528461816668
Validation loss: 2.47139327347681

Epoch: 6| Step: 9
Training loss: 2.8174929909673936
Validation loss: 2.4890246693605773

Epoch: 6| Step: 10
Training loss: 2.4050334480798923
Validation loss: 2.475093595496546

Epoch: 6| Step: 11
Training loss: 2.5771430717663923
Validation loss: 2.468130518661709

Epoch: 6| Step: 12
Training loss: 2.451490501576804
Validation loss: 2.4750269580001447

Epoch: 6| Step: 13
Training loss: 2.8075759168162353
Validation loss: 2.471791666893171

Epoch: 70| Step: 0
Training loss: 2.8841089987718695
Validation loss: 2.461111024779884

Epoch: 6| Step: 1
Training loss: 2.7099048945500104
Validation loss: 2.4930497452774674

Epoch: 6| Step: 2
Training loss: 2.816068970355801
Validation loss: 2.450121559758769

Epoch: 6| Step: 3
Training loss: 2.611703895574531
Validation loss: 2.484980899302194

Epoch: 6| Step: 4
Training loss: 2.744254265329348
Validation loss: 2.4581852036264187

Epoch: 6| Step: 5
Training loss: 2.623119498104627
Validation loss: 2.4502487914749755

Epoch: 6| Step: 6
Training loss: 2.5022035424299567
Validation loss: 2.4586467164275483

Epoch: 6| Step: 7
Training loss: 2.5165640458495773
Validation loss: 2.4707373857990356

Epoch: 6| Step: 8
Training loss: 2.9453879430200183
Validation loss: 2.487438226325356

Epoch: 6| Step: 9
Training loss: 2.8972858289899053
Validation loss: 2.4680852528546917

Epoch: 6| Step: 10
Training loss: 2.6111930863609136
Validation loss: 2.466962066947678

Epoch: 6| Step: 11
Training loss: 2.307162543157572
Validation loss: 2.489250623916566

Epoch: 6| Step: 12
Training loss: 2.9104377354428403
Validation loss: 2.4785920474481333

Epoch: 6| Step: 13
Training loss: 1.919204469220967
Validation loss: 2.4598201925786185

Epoch: 71| Step: 0
Training loss: 2.588545299709132
Validation loss: 2.4604970032205884

Epoch: 6| Step: 1
Training loss: 2.588498417718797
Validation loss: 2.4804815590298177

Epoch: 6| Step: 2
Training loss: 2.228496688508228
Validation loss: 2.4665548945575893

Epoch: 6| Step: 3
Training loss: 3.541206030715742
Validation loss: 2.4554283521490574

Epoch: 6| Step: 4
Training loss: 2.456157971859109
Validation loss: 2.4827639422187078

Epoch: 6| Step: 5
Training loss: 2.9498199860558065
Validation loss: 2.4638905725063616

Epoch: 6| Step: 6
Training loss: 2.3595180847031063
Validation loss: 2.4742297801571898

Epoch: 6| Step: 7
Training loss: 2.767536343384995
Validation loss: 2.4736789851781187

Epoch: 6| Step: 8
Training loss: 2.218488543512022
Validation loss: 2.4662213941164084

Epoch: 6| Step: 9
Training loss: 2.8133833451669528
Validation loss: 2.4728888048961126

Epoch: 6| Step: 10
Training loss: 2.289851134179976
Validation loss: 2.4772394420390964

Epoch: 6| Step: 11
Training loss: 3.0068300698728883
Validation loss: 2.4929936058405

Epoch: 6| Step: 12
Training loss: 2.511861889024978
Validation loss: 2.493878441837101

Epoch: 6| Step: 13
Training loss: 2.935040844660711
Validation loss: 2.485728113036566

Epoch: 72| Step: 0
Training loss: 2.4641646282388434
Validation loss: 2.4737536672875167

Epoch: 6| Step: 1
Training loss: 3.152331043770861
Validation loss: 2.4818966588125186

Epoch: 6| Step: 2
Training loss: 2.5538401467073233
Validation loss: 2.4692841171820725

Epoch: 6| Step: 3
Training loss: 2.2762195043390685
Validation loss: 2.4789005452791377

Epoch: 6| Step: 4
Training loss: 2.3698801771689184
Validation loss: 2.4555172949154547

Epoch: 6| Step: 5
Training loss: 2.538937140084419
Validation loss: 2.469908999229376

Epoch: 6| Step: 6
Training loss: 2.9314532439283236
Validation loss: 2.482430762551321

Epoch: 6| Step: 7
Training loss: 2.511509721995756
Validation loss: 2.4906243044291942

Epoch: 6| Step: 8
Training loss: 2.5873320815291305
Validation loss: 2.4812377595453627

Epoch: 6| Step: 9
Training loss: 2.5964247918096772
Validation loss: 2.48642469548745

Epoch: 6| Step: 10
Training loss: 2.579637858088192
Validation loss: 2.4527778638526154

Epoch: 6| Step: 11
Training loss: 2.6934609950689854
Validation loss: 2.48859213268863

Epoch: 6| Step: 12
Training loss: 3.177340004147042
Validation loss: 2.479200221436374

Epoch: 6| Step: 13
Training loss: 2.8662548575212496
Validation loss: 2.46824138361108

Epoch: 73| Step: 0
Training loss: 2.4615950417434895
Validation loss: 2.4727715494186295

Epoch: 6| Step: 1
Training loss: 3.040799230619723
Validation loss: 2.4642473736430452

Epoch: 6| Step: 2
Training loss: 3.393803666675769
Validation loss: 2.459182501521709

Epoch: 6| Step: 3
Training loss: 2.2796744562603406
Validation loss: 2.4935905931944014

Epoch: 6| Step: 4
Training loss: 2.3781930640527165
Validation loss: 2.4874727502934877

Epoch: 6| Step: 5
Training loss: 3.11354911924976
Validation loss: 2.4748190532246084

Epoch: 6| Step: 6
Training loss: 2.449745815092503
Validation loss: 2.5071440296384964

Epoch: 6| Step: 7
Training loss: 2.1315688535167507
Validation loss: 2.4557033506969574

Epoch: 6| Step: 8
Training loss: 2.724735730157025
Validation loss: 2.456187157316386

Epoch: 6| Step: 9
Training loss: 2.7206558913534975
Validation loss: 2.47514792752562

Epoch: 6| Step: 10
Training loss: 2.6223596281843666
Validation loss: 2.475163607732938

Epoch: 6| Step: 11
Training loss: 2.0534137215091675
Validation loss: 2.4852695228405035

Epoch: 6| Step: 12
Training loss: 2.6258280220167687
Validation loss: 2.4541555716297236

Epoch: 6| Step: 13
Training loss: 3.1826888032752514
Validation loss: 2.463412771985427

Epoch: 74| Step: 0
Training loss: 2.9411731237504655
Validation loss: 2.4764819616206464

Epoch: 6| Step: 1
Training loss: 2.1466548668001995
Validation loss: 2.4534940001197834

Epoch: 6| Step: 2
Training loss: 2.9220040848721065
Validation loss: 2.452583009618068

Epoch: 6| Step: 3
Training loss: 2.3893169739083677
Validation loss: 2.4797261002353332

Epoch: 6| Step: 4
Training loss: 2.337313345734256
Validation loss: 2.5075012367567826

Epoch: 6| Step: 5
Training loss: 2.242096689757858
Validation loss: 2.4798361299282754

Epoch: 6| Step: 6
Training loss: 2.842514775891177
Validation loss: 2.4789745442156668

Epoch: 6| Step: 7
Training loss: 2.6307098414143577
Validation loss: 2.4803691921225863

Epoch: 6| Step: 8
Training loss: 2.5792760880224956
Validation loss: 2.487255752938682

Epoch: 6| Step: 9
Training loss: 2.401433409359123
Validation loss: 2.475247111268579

Epoch: 6| Step: 10
Training loss: 2.6470575479117917
Validation loss: 2.466647013469826

Epoch: 6| Step: 11
Training loss: 3.2818557906655643
Validation loss: 2.4861225573916963

Epoch: 6| Step: 12
Training loss: 3.0042165687709064
Validation loss: 2.459964049348639

Epoch: 6| Step: 13
Training loss: 2.585021072685487
Validation loss: 2.467119693422456

Epoch: 75| Step: 0
Training loss: 2.5052822575332483
Validation loss: 2.476449819138805

Epoch: 6| Step: 1
Training loss: 2.403997382468831
Validation loss: 2.4815843991154156

Epoch: 6| Step: 2
Training loss: 2.806909132864381
Validation loss: 2.46043307852438

Epoch: 6| Step: 3
Training loss: 2.60475087034396
Validation loss: 2.4679247347891304

Epoch: 6| Step: 4
Training loss: 2.7574339004299775
Validation loss: 2.460932297578213

Epoch: 6| Step: 5
Training loss: 2.358934980375293
Validation loss: 2.491179977613539

Epoch: 6| Step: 6
Training loss: 2.4895830566746597
Validation loss: 2.4702914887491607

Epoch: 6| Step: 7
Training loss: 3.0779886748047924
Validation loss: 2.460344279080714

Epoch: 6| Step: 8
Training loss: 3.236702344274136
Validation loss: 2.4615877098888808

Epoch: 6| Step: 9
Training loss: 2.3608768558855426
Validation loss: 2.479794063444674

Epoch: 6| Step: 10
Training loss: 2.904628013916921
Validation loss: 2.488008452478232

Epoch: 6| Step: 11
Training loss: 2.780808317281315
Validation loss: 2.468195724104081

Epoch: 6| Step: 12
Training loss: 2.2094618115238
Validation loss: 2.483910877712603

Epoch: 6| Step: 13
Training loss: 2.155568886035106
Validation loss: 2.476824022695438

Epoch: 76| Step: 0
Training loss: 2.6523545367508934
Validation loss: 2.4931086351579532

Epoch: 6| Step: 1
Training loss: 2.247663556386391
Validation loss: 2.4866602422508133

Epoch: 6| Step: 2
Training loss: 2.737630421218531
Validation loss: 2.466530822842432

Epoch: 6| Step: 3
Training loss: 2.8178492221171854
Validation loss: 2.468331422597809

Epoch: 6| Step: 4
Training loss: 3.309383149537741
Validation loss: 2.4559581775386503

Epoch: 6| Step: 5
Training loss: 2.4634007312121633
Validation loss: 2.4822681941262474

Epoch: 6| Step: 6
Training loss: 3.018075530404526
Validation loss: 2.483384134783709

Epoch: 6| Step: 7
Training loss: 3.350886634668998
Validation loss: 2.4782904936890735

Epoch: 6| Step: 8
Training loss: 2.1392475903546404
Validation loss: 2.4805986366052

Epoch: 6| Step: 9
Training loss: 2.4536132326648006
Validation loss: 2.4812490814389956

Epoch: 6| Step: 10
Training loss: 2.824755183726891
Validation loss: 2.4983325729998875

Epoch: 6| Step: 11
Training loss: 1.9508314169779668
Validation loss: 2.479525926727924

Epoch: 6| Step: 12
Training loss: 2.190680671017153
Validation loss: 2.477712085762378

Epoch: 6| Step: 13
Training loss: 2.5140874677690235
Validation loss: 2.4695070050301218

Epoch: 77| Step: 0
Training loss: 2.5323502774806737
Validation loss: 2.4598458505270453

Epoch: 6| Step: 1
Training loss: 3.1270379097265812
Validation loss: 2.477009266196082

Epoch: 6| Step: 2
Training loss: 1.9031335965167542
Validation loss: 2.456335181384033

Epoch: 6| Step: 3
Training loss: 2.4485853431727254
Validation loss: 2.475357252539013

Epoch: 6| Step: 4
Training loss: 2.5089038601362823
Validation loss: 2.4675067550540617

Epoch: 6| Step: 5
Training loss: 2.6793360354538116
Validation loss: 2.4904234355117576

Epoch: 6| Step: 6
Training loss: 2.0978217317175467
Validation loss: 2.4925519211518448

Epoch: 6| Step: 7
Training loss: 3.114396684001938
Validation loss: 2.4622283878200846

Epoch: 6| Step: 8
Training loss: 3.0875351259032704
Validation loss: 2.4715407643928886

Epoch: 6| Step: 9
Training loss: 2.560377777358835
Validation loss: 2.4850919523170565

Epoch: 6| Step: 10
Training loss: 2.7274061936174654
Validation loss: 2.4671334305892976

Epoch: 6| Step: 11
Training loss: 2.9204759155074504
Validation loss: 2.487436193912512

Epoch: 6| Step: 12
Training loss: 2.8375839624292087
Validation loss: 2.470294122136627

Epoch: 6| Step: 13
Training loss: 2.301208352826331
Validation loss: 2.461050359843624

Epoch: 78| Step: 0
Training loss: 2.2007444249309702
Validation loss: 2.474093292302971

Epoch: 6| Step: 1
Training loss: 2.4729389432842686
Validation loss: 2.48101994510174

Epoch: 6| Step: 2
Training loss: 3.1191904616987625
Validation loss: 2.476750133400703

Epoch: 6| Step: 3
Training loss: 3.1020224588098873
Validation loss: 2.4743362150252053

Epoch: 6| Step: 4
Training loss: 2.9497173367872658
Validation loss: 2.468943527941666

Epoch: 6| Step: 5
Training loss: 1.7174826370983
Validation loss: 2.4744178235595404

Epoch: 6| Step: 6
Training loss: 3.181595063746831
Validation loss: 2.456100303937213

Epoch: 6| Step: 7
Training loss: 3.0252594891689277
Validation loss: 2.4938207965359687

Epoch: 6| Step: 8
Training loss: 2.1258841526482475
Validation loss: 2.4689205365712232

Epoch: 6| Step: 9
Training loss: 2.8254295697686653
Validation loss: 2.4633486648573792

Epoch: 6| Step: 10
Training loss: 2.6828327904690985
Validation loss: 2.494536512909571

Epoch: 6| Step: 11
Training loss: 2.1414952423520246
Validation loss: 2.491476754767107

Epoch: 6| Step: 12
Training loss: 2.5938364037519235
Validation loss: 2.4707500175265094

Epoch: 6| Step: 13
Training loss: 2.3241653051562703
Validation loss: 2.476392065246897

Epoch: 79| Step: 0
Training loss: 2.400846383737803
Validation loss: 2.4834472684483164

Epoch: 6| Step: 1
Training loss: 2.79390213315332
Validation loss: 2.465640281782628

Epoch: 6| Step: 2
Training loss: 1.9286791062444504
Validation loss: 2.476362548532463

Epoch: 6| Step: 3
Training loss: 2.9056100448384354
Validation loss: 2.4868724289619677

Epoch: 6| Step: 4
Training loss: 2.3525038954472492
Validation loss: 2.469776974761137

Epoch: 6| Step: 5
Training loss: 2.0305607726793573
Validation loss: 2.4742316555641666

Epoch: 6| Step: 6
Training loss: 2.3816207156632574
Validation loss: 2.4712375047247184

Epoch: 6| Step: 7
Training loss: 2.37311961372574
Validation loss: 2.4631226536284103

Epoch: 6| Step: 8
Training loss: 2.879858472843483
Validation loss: 2.4753327278725568

Epoch: 6| Step: 9
Training loss: 3.0155595367125496
Validation loss: 2.466453024695307

Epoch: 6| Step: 10
Training loss: 2.9335136148654697
Validation loss: 2.4685595890549763

Epoch: 6| Step: 11
Training loss: 2.8646857965813224
Validation loss: 2.4585462263877966

Epoch: 6| Step: 12
Training loss: 2.955950641596818
Validation loss: 2.4511114995757266

Epoch: 6| Step: 13
Training loss: 3.21943198080853
Validation loss: 2.475628985738814

Epoch: 80| Step: 0
Training loss: 2.245033504856274
Validation loss: 2.4807758425745923

Epoch: 6| Step: 1
Training loss: 3.060052945046745
Validation loss: 2.486428894970953

Epoch: 6| Step: 2
Training loss: 2.0440308124213016
Validation loss: 2.4920049453847195

Epoch: 6| Step: 3
Training loss: 2.6315843564530046
Validation loss: 2.493347926477422

Epoch: 6| Step: 4
Training loss: 3.147306859254209
Validation loss: 2.475105340124002

Epoch: 6| Step: 5
Training loss: 2.9254939061689633
Validation loss: 2.4808127203118566

Epoch: 6| Step: 6
Training loss: 2.435537673210865
Validation loss: 2.4897052084432802

Epoch: 6| Step: 7
Training loss: 2.4389851276214847
Validation loss: 2.4706594409880243

Epoch: 6| Step: 8
Training loss: 3.021320873687094
Validation loss: 2.478712958822694

Epoch: 6| Step: 9
Training loss: 2.7155344571558078
Validation loss: 2.490742317913986

Epoch: 6| Step: 10
Training loss: 3.337207418468597
Validation loss: 2.4584512788299193

Epoch: 6| Step: 11
Training loss: 1.8967074450627255
Validation loss: 2.469193919301663

Epoch: 6| Step: 12
Training loss: 2.3083388547682113
Validation loss: 2.489903067052738

Epoch: 6| Step: 13
Training loss: 1.775333751946769
Validation loss: 2.4800428657121856

Epoch: 81| Step: 0
Training loss: 2.6676305777168476
Validation loss: 2.498594851559884

Epoch: 6| Step: 1
Training loss: 2.054318935278015
Validation loss: 2.490459847164636

Epoch: 6| Step: 2
Training loss: 3.0822998239285293
Validation loss: 2.476158342281974

Epoch: 6| Step: 3
Training loss: 2.6571351315639475
Validation loss: 2.472849107310451

Epoch: 6| Step: 4
Training loss: 2.465264479432632
Validation loss: 2.464629349527623

Epoch: 6| Step: 5
Training loss: 3.0975794355722623
Validation loss: 2.471958427078693

Epoch: 6| Step: 6
Training loss: 2.1887410594293546
Validation loss: 2.4881762894892803

Epoch: 6| Step: 7
Training loss: 2.710875584667595
Validation loss: 2.4615252028587196

Epoch: 6| Step: 8
Training loss: 1.833109719192904
Validation loss: 2.49174809022569

Epoch: 6| Step: 9
Training loss: 2.589656310972551
Validation loss: 2.468310039544651

Epoch: 6| Step: 10
Training loss: 3.0753081934863564
Validation loss: 2.456316313570814

Epoch: 6| Step: 11
Training loss: 2.7368323047458603
Validation loss: 2.483379554387213

Epoch: 6| Step: 12
Training loss: 2.8043483858522604
Validation loss: 2.4923435095101754

Epoch: 6| Step: 13
Training loss: 2.91001041738212
Validation loss: 2.483551688696584

Epoch: 82| Step: 0
Training loss: 1.9750739361407856
Validation loss: 2.486994096405894

Epoch: 6| Step: 1
Training loss: 2.724303963337381
Validation loss: 2.478635708529477

Epoch: 6| Step: 2
Training loss: 2.2637155839651477
Validation loss: 2.4818875266077276

Epoch: 6| Step: 3
Training loss: 2.2225309581338304
Validation loss: 2.482937191461395

Epoch: 6| Step: 4
Training loss: 3.0884915755757443
Validation loss: 2.4884102044310157

Epoch: 6| Step: 5
Training loss: 3.338933880997035
Validation loss: 2.4715045065584964

Epoch: 6| Step: 6
Training loss: 2.0832350008328557
Validation loss: 2.4646920435909716

Epoch: 6| Step: 7
Training loss: 2.616098114576893
Validation loss: 2.461367904493935

Epoch: 6| Step: 8
Training loss: 3.1335407276370693
Validation loss: 2.4850496034179166

Epoch: 6| Step: 9
Training loss: 2.4912732399537427
Validation loss: 2.4752818270217976

Epoch: 6| Step: 10
Training loss: 2.9606746667646338
Validation loss: 2.4869484595707525

Epoch: 6| Step: 11
Training loss: 2.940740867221138
Validation loss: 2.4631675401963298

Epoch: 6| Step: 12
Training loss: 1.799642140525126
Validation loss: 2.4763627121010834

Epoch: 6| Step: 13
Training loss: 2.300671093931593
Validation loss: 2.465082395757697

Epoch: 83| Step: 0
Training loss: 2.6726396147013163
Validation loss: 2.4709252332835416

Epoch: 6| Step: 1
Training loss: 2.6545384895665634
Validation loss: 2.463093986975133

Epoch: 6| Step: 2
Training loss: 2.5996601836343025
Validation loss: 2.4704347020352806

Epoch: 6| Step: 3
Training loss: 3.049973071870593
Validation loss: 2.480292837868448

Epoch: 6| Step: 4
Training loss: 1.8356267138464373
Validation loss: 2.489709145484576

Epoch: 6| Step: 5
Training loss: 2.244951730731739
Validation loss: 2.4698657672193525

Epoch: 6| Step: 6
Training loss: 2.969127430263571
Validation loss: 2.438623115433288

Epoch: 6| Step: 7
Training loss: 2.537145554164916
Validation loss: 2.467930422124773

Epoch: 6| Step: 8
Training loss: 2.797108901488662
Validation loss: 2.462338284756952

Epoch: 6| Step: 9
Training loss: 2.64018327076873
Validation loss: 2.4673192021530883

Epoch: 6| Step: 10
Training loss: 1.9720225912196752
Validation loss: 2.446622153208038

Epoch: 6| Step: 11
Training loss: 2.672551833418227
Validation loss: 2.465035106295209

Epoch: 6| Step: 12
Training loss: 3.147427910546547
Validation loss: 2.463188137868651

Epoch: 6| Step: 13
Training loss: 2.6333966159057427
Validation loss: 2.4703949260983897

Epoch: 84| Step: 0
Training loss: 2.6995423670872842
Validation loss: 2.4642567303904026

Epoch: 6| Step: 1
Training loss: 2.4617691814519453
Validation loss: 2.476986098190703

Epoch: 6| Step: 2
Training loss: 3.062024760838215
Validation loss: 2.468406203664583

Epoch: 6| Step: 3
Training loss: 2.9179442377860996
Validation loss: 2.4727953862107546

Epoch: 6| Step: 4
Training loss: 2.5286883354871086
Validation loss: 2.48179785960763

Epoch: 6| Step: 5
Training loss: 2.930851005939837
Validation loss: 2.473958179277416

Epoch: 6| Step: 6
Training loss: 2.7480185913278845
Validation loss: 2.476268384010834

Epoch: 6| Step: 7
Training loss: 2.1923364851035108
Validation loss: 2.475950718883423

Epoch: 6| Step: 8
Training loss: 2.6291141966245632
Validation loss: 2.4636164139658443

Epoch: 6| Step: 9
Training loss: 1.9562425070914684
Validation loss: 2.47166407594682

Epoch: 6| Step: 10
Training loss: 2.688000122376848
Validation loss: 2.4636764574477277

Epoch: 6| Step: 11
Training loss: 2.877137757674412
Validation loss: 2.4846482542306036

Epoch: 6| Step: 12
Training loss: 2.796875937690791
Validation loss: 2.4820687988731343

Epoch: 6| Step: 13
Training loss: 1.7937516641110667
Validation loss: 2.4731270267854417

Epoch: 85| Step: 0
Training loss: 1.9492772768212743
Validation loss: 2.488308789384858

Epoch: 6| Step: 1
Training loss: 2.627676552921318
Validation loss: 2.4775585281943693

Epoch: 6| Step: 2
Training loss: 2.351284479580992
Validation loss: 2.433984203991216

Epoch: 6| Step: 3
Training loss: 2.5041890334295704
Validation loss: 2.462067746139013

Epoch: 6| Step: 4
Training loss: 3.1233311583987398
Validation loss: 2.482069654084755

Epoch: 6| Step: 5
Training loss: 2.245991951667313
Validation loss: 2.4680946739944836

Epoch: 6| Step: 6
Training loss: 2.663548752814216
Validation loss: 2.481526256442959

Epoch: 6| Step: 7
Training loss: 2.8189770186327503
Validation loss: 2.4467220867708446

Epoch: 6| Step: 8
Training loss: 3.308472686318157
Validation loss: 2.4828140701440455

Epoch: 6| Step: 9
Training loss: 2.9110484554093583
Validation loss: 2.4931225262994685

Epoch: 6| Step: 10
Training loss: 2.9276982178596205
Validation loss: 2.4698277420216894

Epoch: 6| Step: 11
Training loss: 2.6164454988284858
Validation loss: 2.486921099952535

Epoch: 6| Step: 12
Training loss: 2.1947337843750763
Validation loss: 2.475396647882872

Epoch: 6| Step: 13
Training loss: 2.1158046358778373
Validation loss: 2.484607179276247

Epoch: 86| Step: 0
Training loss: 2.856345818245866
Validation loss: 2.481253160531653

Epoch: 6| Step: 1
Training loss: 2.0382225674435155
Validation loss: 2.484357316169689

Epoch: 6| Step: 2
Training loss: 1.6851223336928682
Validation loss: 2.477028372780739

Epoch: 6| Step: 3
Training loss: 2.283893986481333
Validation loss: 2.478335701369574

Epoch: 6| Step: 4
Training loss: 2.6169950955395627
Validation loss: 2.485948446811002

Epoch: 6| Step: 5
Training loss: 2.5417554454202964
Validation loss: 2.48150483522371

Epoch: 6| Step: 6
Training loss: 2.7714922893429987
Validation loss: 2.462502225645084

Epoch: 6| Step: 7
Training loss: 2.539557493817436
Validation loss: 2.480384697724222

Epoch: 6| Step: 8
Training loss: 3.074454660827968
Validation loss: 2.478244903468876

Epoch: 6| Step: 9
Training loss: 3.4506990360331735
Validation loss: 2.4671829855880434

Epoch: 6| Step: 10
Training loss: 3.015170838939028
Validation loss: 2.471627583433453

Epoch: 6| Step: 11
Training loss: 2.698592956694813
Validation loss: 2.4771653757472247

Epoch: 6| Step: 12
Training loss: 2.074144839821664
Validation loss: 2.4756738029547263

Epoch: 6| Step: 13
Training loss: 2.7423073071339497
Validation loss: 2.4771267919710014

Epoch: 87| Step: 0
Training loss: 2.5299815072450538
Validation loss: 2.4781353777921193

Epoch: 6| Step: 1
Training loss: 2.3858291291592786
Validation loss: 2.480408792091632

Epoch: 6| Step: 2
Training loss: 3.4430635685477182
Validation loss: 2.4593435875751837

Epoch: 6| Step: 3
Training loss: 2.1375100520382815
Validation loss: 2.4663713792152375

Epoch: 6| Step: 4
Training loss: 2.2530418602872304
Validation loss: 2.48333320488289

Epoch: 6| Step: 5
Training loss: 2.4358035321739466
Validation loss: 2.4749084530718224

Epoch: 6| Step: 6
Training loss: 2.489119408023384
Validation loss: 2.4703916338493452

Epoch: 6| Step: 7
Training loss: 2.5133832337496016
Validation loss: 2.47170171869131

Epoch: 6| Step: 8
Training loss: 2.7440917095562463
Validation loss: 2.483712841083189

Epoch: 6| Step: 9
Training loss: 2.3175589409732935
Validation loss: 2.450216493716223

Epoch: 6| Step: 10
Training loss: 2.4138704982808634
Validation loss: 2.461246806609035

Epoch: 6| Step: 11
Training loss: 3.027352885570893
Validation loss: 2.4757321400252494

Epoch: 6| Step: 12
Training loss: 2.9961862164369717
Validation loss: 2.45534657343281

Epoch: 6| Step: 13
Training loss: 2.8309856299787177
Validation loss: 2.4821299509255628

Epoch: 88| Step: 0
Training loss: 1.9253966777363525
Validation loss: 2.4662873527178397

Epoch: 6| Step: 1
Training loss: 2.4469867861024226
Validation loss: 2.4793567565637056

Epoch: 6| Step: 2
Training loss: 3.293150474810353
Validation loss: 2.486116096007462

Epoch: 6| Step: 3
Training loss: 3.1278911186839284
Validation loss: 2.4851929158002113

Epoch: 6| Step: 4
Training loss: 2.312916589277767
Validation loss: 2.4608551714789484

Epoch: 6| Step: 5
Training loss: 3.034359624884612
Validation loss: 2.472031887142016

Epoch: 6| Step: 6
Training loss: 2.9212229608044225
Validation loss: 2.469086876000006

Epoch: 6| Step: 7
Training loss: 2.416480473766845
Validation loss: 2.4826425693227576

Epoch: 6| Step: 8
Training loss: 2.843320877059836
Validation loss: 2.474128112321265

Epoch: 6| Step: 9
Training loss: 3.1181061043685774
Validation loss: 2.474174278864651

Epoch: 6| Step: 10
Training loss: 2.4016155845121183
Validation loss: 2.4852740327041567

Epoch: 6| Step: 11
Training loss: 1.8335926421608684
Validation loss: 2.4376679876101286

Epoch: 6| Step: 12
Training loss: 2.0455848180342504
Validation loss: 2.4730853365014402

Epoch: 6| Step: 13
Training loss: 2.5538584445926307
Validation loss: 2.4690627422714977

Epoch: 89| Step: 0
Training loss: 2.2738527528300363
Validation loss: 2.4715137922659656

Epoch: 6| Step: 1
Training loss: 3.029007229463571
Validation loss: 2.474706721857029

Epoch: 6| Step: 2
Training loss: 1.9386657161334269
Validation loss: 2.464922634828392

Epoch: 6| Step: 3
Training loss: 2.8469180391745286
Validation loss: 2.446709523786965

Epoch: 6| Step: 4
Training loss: 2.687410220043806
Validation loss: 2.449695866542508

Epoch: 6| Step: 5
Training loss: 2.4575669230820556
Validation loss: 2.4882899497173985

Epoch: 6| Step: 6
Training loss: 2.2884386273539805
Validation loss: 2.472513384685804

Epoch: 6| Step: 7
Training loss: 3.3436450407008107
Validation loss: 2.4691262447188524

Epoch: 6| Step: 8
Training loss: 2.872372629182019
Validation loss: 2.4684267695667064

Epoch: 6| Step: 9
Training loss: 2.748099450623128
Validation loss: 2.4747769594711158

Epoch: 6| Step: 10
Training loss: 2.1657953588902568
Validation loss: 2.4754565904878487

Epoch: 6| Step: 11
Training loss: 2.984422293882462
Validation loss: 2.465580969774932

Epoch: 6| Step: 12
Training loss: 2.6229214386193394
Validation loss: 2.4836075388652095

Epoch: 6| Step: 13
Training loss: 2.138868070338714
Validation loss: 2.479330348209862

Epoch: 90| Step: 0
Training loss: 2.4708335872176126
Validation loss: 2.491846370427773

Epoch: 6| Step: 1
Training loss: 2.149606504582231
Validation loss: 2.480758854408236

Epoch: 6| Step: 2
Training loss: 2.674235054521396
Validation loss: 2.4588625060094538

Epoch: 6| Step: 3
Training loss: 2.7962949353744118
Validation loss: 2.477501566394177

Epoch: 6| Step: 4
Training loss: 2.732570728667496
Validation loss: 2.4759844514931566

Epoch: 6| Step: 5
Training loss: 2.3893483062697904
Validation loss: 2.4682078422361955

Epoch: 6| Step: 6
Training loss: 2.411307432480468
Validation loss: 2.4858186169767627

Epoch: 6| Step: 7
Training loss: 3.00010839902224
Validation loss: 2.4777168639127964

Epoch: 6| Step: 8
Training loss: 2.793588252153635
Validation loss: 2.4755556862666745

Epoch: 6| Step: 9
Training loss: 2.3292049488977407
Validation loss: 2.492058708624667

Epoch: 6| Step: 10
Training loss: 2.4539351370834845
Validation loss: 2.4797001977496653

Epoch: 6| Step: 11
Training loss: 2.6377556916451064
Validation loss: 2.478955552944831

Epoch: 6| Step: 12
Training loss: 3.1447853886045802
Validation loss: 2.4667409913368004

Epoch: 6| Step: 13
Training loss: 2.1528976475420833
Validation loss: 2.446426594382332

Epoch: 91| Step: 0
Training loss: 2.6768689694404584
Validation loss: 2.4612824437363092

Epoch: 6| Step: 1
Training loss: 2.2573531056345764
Validation loss: 2.467391039217973

Epoch: 6| Step: 2
Training loss: 2.147556415567338
Validation loss: 2.4858941425219347

Epoch: 6| Step: 3
Training loss: 2.583119957838438
Validation loss: 2.458218578276369

Epoch: 6| Step: 4
Training loss: 2.8792255695535727
Validation loss: 2.4661480364498534

Epoch: 6| Step: 5
Training loss: 3.1161486584480933
Validation loss: 2.4733915184613773

Epoch: 6| Step: 6
Training loss: 2.6054480693402446
Validation loss: 2.4825336569289713

Epoch: 6| Step: 7
Training loss: 2.7714902247339603
Validation loss: 2.475046770762848

Epoch: 6| Step: 8
Training loss: 2.377587164114373
Validation loss: 2.4779332192144095

Epoch: 6| Step: 9
Training loss: 2.1136448348202808
Validation loss: 2.4657978482371936

Epoch: 6| Step: 10
Training loss: 2.4714142149264906
Validation loss: 2.470940208838569

Epoch: 6| Step: 11
Training loss: 2.6296458231388056
Validation loss: 2.461461760005635

Epoch: 6| Step: 12
Training loss: 3.1945567088279976
Validation loss: 2.462331213319081

Epoch: 6| Step: 13
Training loss: 2.33758384839796
Validation loss: 2.4672157750920203

Epoch: 92| Step: 0
Training loss: 2.8002976940484325
Validation loss: 2.4712450330629365

Epoch: 6| Step: 1
Training loss: 2.0326072266694655
Validation loss: 2.46490270324633

Epoch: 6| Step: 2
Training loss: 2.7581792052695464
Validation loss: 2.4631730839590884

Epoch: 6| Step: 3
Training loss: 2.577365277799699
Validation loss: 2.4565059849627358

Epoch: 6| Step: 4
Training loss: 2.4429885497478736
Validation loss: 2.4646803767609025

Epoch: 6| Step: 5
Training loss: 2.7813120631461943
Validation loss: 2.4584340300323215

Epoch: 6| Step: 6
Training loss: 2.2420375654219495
Validation loss: 2.4792182822544784

Epoch: 6| Step: 7
Training loss: 2.9153689812778536
Validation loss: 2.4835814977681316

Epoch: 6| Step: 8
Training loss: 2.8221624758129136
Validation loss: 2.469953021386197

Epoch: 6| Step: 9
Training loss: 2.3207647736956583
Validation loss: 2.4816033568384013

Epoch: 6| Step: 10
Training loss: 2.6560122215208124
Validation loss: 2.490999960144685

Epoch: 6| Step: 11
Training loss: 3.1754238776860193
Validation loss: 2.4709172920732243

Epoch: 6| Step: 12
Training loss: 2.2859175498024045
Validation loss: 2.4845319437667115

Epoch: 6| Step: 13
Training loss: 2.1749990485178303
Validation loss: 2.4914150809705107

Epoch: 93| Step: 0
Training loss: 2.3037129038712996
Validation loss: 2.4591329917164804

Epoch: 6| Step: 1
Training loss: 2.522530501968572
Validation loss: 2.4742162916909893

Epoch: 6| Step: 2
Training loss: 2.296924616478874
Validation loss: 2.4985846789355364

Epoch: 6| Step: 3
Training loss: 2.755509838969233
Validation loss: 2.480040200811026

Epoch: 6| Step: 4
Training loss: 2.378963175375971
Validation loss: 2.4786095624470934

Epoch: 6| Step: 5
Training loss: 2.8970052054071718
Validation loss: 2.462524002680303

Epoch: 6| Step: 6
Training loss: 2.734572398008722
Validation loss: 2.487110074233831

Epoch: 6| Step: 7
Training loss: 2.9566996903781133
Validation loss: 2.479252634258145

Epoch: 6| Step: 8
Training loss: 2.2053873336958243
Validation loss: 2.4903277674612525

Epoch: 6| Step: 9
Training loss: 2.3918363207502327
Validation loss: 2.4329510035550643

Epoch: 6| Step: 10
Training loss: 2.6265154505866533
Validation loss: 2.4635554210101365

Epoch: 6| Step: 11
Training loss: 2.9347381594573636
Validation loss: 2.4746494276536204

Epoch: 6| Step: 12
Training loss: 2.5107522531765363
Validation loss: 2.492168154740901

Epoch: 6| Step: 13
Training loss: 2.914837854236784
Validation loss: 2.4615615504035278

Epoch: 94| Step: 0
Training loss: 2.5610563351870947
Validation loss: 2.4722999023471988

Epoch: 6| Step: 1
Training loss: 2.8099446874312917
Validation loss: 2.461854443077544

Epoch: 6| Step: 2
Training loss: 2.757062512828825
Validation loss: 2.482195590075116

Epoch: 6| Step: 3
Training loss: 2.1683980430820786
Validation loss: 2.4700002997254837

Epoch: 6| Step: 4
Training loss: 2.020180927898616
Validation loss: 2.4812045447086124

Epoch: 6| Step: 5
Training loss: 2.4145120245404432
Validation loss: 2.4738402988188075

Epoch: 6| Step: 6
Training loss: 2.715149786735605
Validation loss: 2.4613719613324223

Epoch: 6| Step: 7
Training loss: 2.6171654543731018
Validation loss: 2.4721572590990597

Epoch: 6| Step: 8
Training loss: 2.828617622086368
Validation loss: 2.4726848104603296

Epoch: 6| Step: 9
Training loss: 2.736591073253268
Validation loss: 2.4430930339363033

Epoch: 6| Step: 10
Training loss: 2.7496246601931214
Validation loss: 2.4703126901627797

Epoch: 6| Step: 11
Training loss: 2.452933528741319
Validation loss: 2.481736324392199

Epoch: 6| Step: 12
Training loss: 2.9759314160904187
Validation loss: 2.4768219184346676

Epoch: 6| Step: 13
Training loss: 2.3226434065088055
Validation loss: 2.4928623098135567

Epoch: 95| Step: 0
Training loss: 2.3992157210961627
Validation loss: 2.4927501492734176

Epoch: 6| Step: 1
Training loss: 2.6198968784043584
Validation loss: 2.4811021511086553

Epoch: 6| Step: 2
Training loss: 1.7396787362197443
Validation loss: 2.4699857409041033

Epoch: 6| Step: 3
Training loss: 2.2453032321513016
Validation loss: 2.451460120325396

Epoch: 6| Step: 4
Training loss: 2.3263742917743193
Validation loss: 2.468955814769539

Epoch: 6| Step: 5
Training loss: 2.8863199704471016
Validation loss: 2.4708102731113324

Epoch: 6| Step: 6
Training loss: 3.055360061479767
Validation loss: 2.4925934894879274

Epoch: 6| Step: 7
Training loss: 2.20082470001565
Validation loss: 2.4621269694145616

Epoch: 6| Step: 8
Training loss: 2.8575967564392477
Validation loss: 2.4649628979214246

Epoch: 6| Step: 9
Training loss: 3.4248379634201083
Validation loss: 2.4503286473180665

Epoch: 6| Step: 10
Training loss: 2.433739328698978
Validation loss: 2.474957428739358

Epoch: 6| Step: 11
Training loss: 2.8077616301159742
Validation loss: 2.489122823298074

Epoch: 6| Step: 12
Training loss: 2.2266496607803004
Validation loss: 2.4663168476053587

Epoch: 6| Step: 13
Training loss: 3.3576837585109125
Validation loss: 2.474594308727466

Epoch: 96| Step: 0
Training loss: 2.230648320814454
Validation loss: 2.4630229863282143

Epoch: 6| Step: 1
Training loss: 2.903176928693268
Validation loss: 2.4902705191832926

Epoch: 6| Step: 2
Training loss: 2.2927289639182704
Validation loss: 2.4661985280977206

Epoch: 6| Step: 3
Training loss: 2.877832758642995
Validation loss: 2.445870265719236

Epoch: 6| Step: 4
Training loss: 2.742039690082422
Validation loss: 2.4905972342880456

Epoch: 6| Step: 5
Training loss: 2.183440774598757
Validation loss: 2.4622467636640817

Epoch: 6| Step: 6
Training loss: 1.4327768602171471
Validation loss: 2.4581983190981807

Epoch: 6| Step: 7
Training loss: 2.9724034366050325
Validation loss: 2.4646273963422027

Epoch: 6| Step: 8
Training loss: 2.36575606473121
Validation loss: 2.477263235322705

Epoch: 6| Step: 9
Training loss: 2.101077793197198
Validation loss: 2.468186607681427

Epoch: 6| Step: 10
Training loss: 2.9354362543091943
Validation loss: 2.4637477410209137

Epoch: 6| Step: 11
Training loss: 3.1500486884819936
Validation loss: 2.487120900396803

Epoch: 6| Step: 12
Training loss: 2.6742753517965503
Validation loss: 2.47825819622044

Epoch: 6| Step: 13
Training loss: 3.21938991666851
Validation loss: 2.476160183097756

Epoch: 97| Step: 0
Training loss: 2.567231624732536
Validation loss: 2.4868906871379424

Epoch: 6| Step: 1
Training loss: 2.0935960399900715
Validation loss: 2.4593931895617693

Epoch: 6| Step: 2
Training loss: 2.9782300067974385
Validation loss: 2.470027546816413

Epoch: 6| Step: 3
Training loss: 2.8503713131669013
Validation loss: 2.466002213299108

Epoch: 6| Step: 4
Training loss: 2.2867454284842474
Validation loss: 2.472038654973763

Epoch: 6| Step: 5
Training loss: 2.2830383397950462
Validation loss: 2.4886925513982883

Epoch: 6| Step: 6
Training loss: 2.811196088532629
Validation loss: 2.4536506931352764

Epoch: 6| Step: 7
Training loss: 2.862384317384323
Validation loss: 2.4605137072227077

Epoch: 6| Step: 8
Training loss: 2.6947102191670265
Validation loss: 2.452185342212647

Epoch: 6| Step: 9
Training loss: 2.482470664228458
Validation loss: 2.4691174992837577

Epoch: 6| Step: 10
Training loss: 2.600885343201704
Validation loss: 2.481539819848074

Epoch: 6| Step: 11
Training loss: 2.992966353839422
Validation loss: 2.4826316843909058

Epoch: 6| Step: 12
Training loss: 2.1710423032767436
Validation loss: 2.4785337270085037

Epoch: 6| Step: 13
Training loss: 2.07516946215517
Validation loss: 2.477251209609051

Epoch: 98| Step: 0
Training loss: 2.2586350576079814
Validation loss: 2.4753595123588057

Epoch: 6| Step: 1
Training loss: 2.9666157328773095
Validation loss: 2.465463906409697

Epoch: 6| Step: 2
Training loss: 2.6329088504717704
Validation loss: 2.486293850133022

Epoch: 6| Step: 3
Training loss: 2.573778962930658
Validation loss: 2.462001236111415

Epoch: 6| Step: 4
Training loss: 2.2028284617308547
Validation loss: 2.4532276772431296

Epoch: 6| Step: 5
Training loss: 3.355103513937148
Validation loss: 2.4799456755969658

Epoch: 6| Step: 6
Training loss: 2.376037973158286
Validation loss: 2.4776537994490666

Epoch: 6| Step: 7
Training loss: 2.7516642649698047
Validation loss: 2.472401174607103

Epoch: 6| Step: 8
Training loss: 2.0967075468645735
Validation loss: 2.5005520159901558

Epoch: 6| Step: 9
Training loss: 2.108468433117596
Validation loss: 2.4874000616224095

Epoch: 6| Step: 10
Training loss: 3.2070128130179536
Validation loss: 2.4838777399057355

Epoch: 6| Step: 11
Training loss: 2.6307839748846287
Validation loss: 2.44914393680267

Epoch: 6| Step: 12
Training loss: 2.4550518073930014
Validation loss: 2.4441361008709643

Epoch: 6| Step: 13
Training loss: 1.787353032079099
Validation loss: 2.469981974299784

Epoch: 99| Step: 0
Training loss: 2.3395322359868085
Validation loss: 2.4703880639982994

Epoch: 6| Step: 1
Training loss: 2.6177129872699805
Validation loss: 2.4807402984315714

Epoch: 6| Step: 2
Training loss: 2.234487357349016
Validation loss: 2.468443473134442

Epoch: 6| Step: 3
Training loss: 2.870667385699508
Validation loss: 2.460519957649435

Epoch: 6| Step: 4
Training loss: 2.4224128372053806
Validation loss: 2.457820791628408

Epoch: 6| Step: 5
Training loss: 2.328601967513536
Validation loss: 2.502319431056457

Epoch: 6| Step: 6
Training loss: 3.4900515721399143
Validation loss: 2.4566453596481135

Epoch: 6| Step: 7
Training loss: 2.4104718908931275
Validation loss: 2.4695500813770073

Epoch: 6| Step: 8
Training loss: 2.522870546313669
Validation loss: 2.467143273087219

Epoch: 6| Step: 9
Training loss: 2.1289642606058496
Validation loss: 2.4781892738230926

Epoch: 6| Step: 10
Training loss: 2.500253283067975
Validation loss: 2.4655784576858926

Epoch: 6| Step: 11
Training loss: 2.81392243760614
Validation loss: 2.4529823777495725

Epoch: 6| Step: 12
Training loss: 2.7445007305147766
Validation loss: 2.4879999269449127

Epoch: 6| Step: 13
Training loss: 2.3875080807534124
Validation loss: 2.470965399604869

Epoch: 100| Step: 0
Training loss: 2.3152365087065205
Validation loss: 2.479501548754943

Epoch: 6| Step: 1
Training loss: 2.5039137722622478
Validation loss: 2.4689787840063175

Epoch: 6| Step: 2
Training loss: 2.351003586766774
Validation loss: 2.460224951246509

Epoch: 6| Step: 3
Training loss: 2.81289212354364
Validation loss: 2.466537990334511

Epoch: 6| Step: 4
Training loss: 2.457590594402087
Validation loss: 2.464337534631277

Epoch: 6| Step: 5
Training loss: 2.1080182268487535
Validation loss: 2.4968843570307864

Epoch: 6| Step: 6
Training loss: 2.300372516485017
Validation loss: 2.46374853807833

Epoch: 6| Step: 7
Training loss: 3.093783599979316
Validation loss: 2.440462022338424

Epoch: 6| Step: 8
Training loss: 3.00935241120319
Validation loss: 2.459269842844534

Epoch: 6| Step: 9
Training loss: 3.300123882858326
Validation loss: 2.47964478685007

Epoch: 6| Step: 10
Training loss: 2.3284072192881142
Validation loss: 2.4757863731314314

Epoch: 6| Step: 11
Training loss: 2.6566224678539747
Validation loss: 2.4568974159993613

Epoch: 6| Step: 12
Training loss: 2.251147507405425
Validation loss: 2.460978821047663

Epoch: 6| Step: 13
Training loss: 2.471645926218949
Validation loss: 2.455897842533664

Epoch: 101| Step: 0
Training loss: 2.3629503254877484
Validation loss: 2.4630549381736517

Epoch: 6| Step: 1
Training loss: 2.2544960030532772
Validation loss: 2.4776603822331746

Epoch: 6| Step: 2
Training loss: 2.1964588362572512
Validation loss: 2.4690157673408297

Epoch: 6| Step: 3
Training loss: 2.7787414553395497
Validation loss: 2.4813178403240572

Epoch: 6| Step: 4
Training loss: 2.2683163146932173
Validation loss: 2.460566281579053

Epoch: 6| Step: 5
Training loss: 2.4366287239276
Validation loss: 2.471888577117602

Epoch: 6| Step: 6
Training loss: 2.6726298018961394
Validation loss: 2.4590364117849535

Epoch: 6| Step: 7
Training loss: 2.7086020311922727
Validation loss: 2.4727552630927154

Epoch: 6| Step: 8
Training loss: 2.9435200789738576
Validation loss: 2.4820023310897943

Epoch: 6| Step: 9
Training loss: 2.461198871598775
Validation loss: 2.4448582324488215

Epoch: 6| Step: 10
Training loss: 2.5473710963586513
Validation loss: 2.4641807403817846

Epoch: 6| Step: 11
Training loss: 3.7907005308823254
Validation loss: 2.466943867557967

Epoch: 6| Step: 12
Training loss: 2.181841916981109
Validation loss: 2.458677161108899

Epoch: 6| Step: 13
Training loss: 2.125577511569604
Validation loss: 2.478939664035122

Epoch: 102| Step: 0
Training loss: 3.0437615552992283
Validation loss: 2.4634014409637843

Epoch: 6| Step: 1
Training loss: 2.5578580541171956
Validation loss: 2.470550273755525

Epoch: 6| Step: 2
Training loss: 2.2617478442914956
Validation loss: 2.461587530758069

Epoch: 6| Step: 3
Training loss: 3.024932570533501
Validation loss: 2.4764087893655047

Epoch: 6| Step: 4
Training loss: 2.2552418577831443
Validation loss: 2.4542431806392235

Epoch: 6| Step: 5
Training loss: 2.6511144921593086
Validation loss: 2.45504278783317

Epoch: 6| Step: 6
Training loss: 2.6364349890712497
Validation loss: 2.4607294622678126

Epoch: 6| Step: 7
Training loss: 2.5893098444824334
Validation loss: 2.4687181509405685

Epoch: 6| Step: 8
Training loss: 2.1892274847490083
Validation loss: 2.487721783170831

Epoch: 6| Step: 9
Training loss: 3.2729692875359095
Validation loss: 2.4674088612690013

Epoch: 6| Step: 10
Training loss: 2.322172915418398
Validation loss: 2.467199401176291

Epoch: 6| Step: 11
Training loss: 2.1053492807666516
Validation loss: 2.4778081374397143

Epoch: 6| Step: 12
Training loss: 2.3853006348576575
Validation loss: 2.464841237159609

Epoch: 6| Step: 13
Training loss: 2.584832361566673
Validation loss: 2.450771699792558

Epoch: 103| Step: 0
Training loss: 2.721906824287216
Validation loss: 2.463771394578545

Epoch: 6| Step: 1
Training loss: 2.291715263082632
Validation loss: 2.4735802287790896

Epoch: 6| Step: 2
Training loss: 3.416908317642116
Validation loss: 2.4880575798568665

Epoch: 6| Step: 3
Training loss: 2.654100064131182
Validation loss: 2.443581652197426

Epoch: 6| Step: 4
Training loss: 2.447089089178401
Validation loss: 2.470972783521756

Epoch: 6| Step: 5
Training loss: 2.4277295628911983
Validation loss: 2.4783184409731795

Epoch: 6| Step: 6
Training loss: 2.4565813535096153
Validation loss: 2.4812674187055808

Epoch: 6| Step: 7
Training loss: 2.091890106830465
Validation loss: 2.4921852276650553

Epoch: 6| Step: 8
Training loss: 2.4075348631492446
Validation loss: 2.48113587464333

Epoch: 6| Step: 9
Training loss: 2.410387420696678
Validation loss: 2.483379983832003

Epoch: 6| Step: 10
Training loss: 2.3025914892851316
Validation loss: 2.4531592931075448

Epoch: 6| Step: 11
Training loss: 3.121229872999581
Validation loss: 2.470275512977987

Epoch: 6| Step: 12
Training loss: 2.8256782358981303
Validation loss: 2.4705693931951678

Epoch: 6| Step: 13
Training loss: 2.317714585427985
Validation loss: 2.4570075993761176

Epoch: 104| Step: 0
Training loss: 2.1583796502326864
Validation loss: 2.4709766648158555

Epoch: 6| Step: 1
Training loss: 2.448949674339244
Validation loss: 2.4641422071432495

Epoch: 6| Step: 2
Training loss: 2.484605886418938
Validation loss: 2.4709215542258596

Epoch: 6| Step: 3
Training loss: 2.8743097886569977
Validation loss: 2.4672109360802614

Epoch: 6| Step: 4
Training loss: 1.9984938195280701
Validation loss: 2.459052749354722

Epoch: 6| Step: 5
Training loss: 3.083276765321638
Validation loss: 2.4916397535865498

Epoch: 6| Step: 6
Training loss: 3.1478110321989776
Validation loss: 2.4851601520149775

Epoch: 6| Step: 7
Training loss: 2.3685747871920726
Validation loss: 2.47203026621971

Epoch: 6| Step: 8
Training loss: 2.7942459280723795
Validation loss: 2.48459542590944

Epoch: 6| Step: 9
Training loss: 2.973110971247302
Validation loss: 2.483786105225936

Epoch: 6| Step: 10
Training loss: 1.8565739923675928
Validation loss: 2.4601413150495635

Epoch: 6| Step: 11
Training loss: 2.5076813945784835
Validation loss: 2.4770461906947068

Epoch: 6| Step: 12
Training loss: 2.645136663876
Validation loss: 2.473061378108863

Epoch: 6| Step: 13
Training loss: 2.619452745926307
Validation loss: 2.4742183960954964

Epoch: 105| Step: 0
Training loss: 2.761043568566859
Validation loss: 2.4774881241972184

Epoch: 6| Step: 1
Training loss: 2.1155384581317525
Validation loss: 2.468298149373557

Epoch: 6| Step: 2
Training loss: 2.518401136447015
Validation loss: 2.485400761478111

Epoch: 6| Step: 3
Training loss: 2.408130752948668
Validation loss: 2.4328603801401605

Epoch: 6| Step: 4
Training loss: 2.608136002832529
Validation loss: 2.4544529713921124

Epoch: 6| Step: 5
Training loss: 2.744581085369401
Validation loss: 2.4718364800471084

Epoch: 6| Step: 6
Training loss: 2.852915320154913
Validation loss: 2.44991204792641

Epoch: 6| Step: 7
Training loss: 2.549971868322441
Validation loss: 2.4653283412457783

Epoch: 6| Step: 8
Training loss: 3.1603309762226584
Validation loss: 2.4654486553109476

Epoch: 6| Step: 9
Training loss: 2.422453386706667
Validation loss: 2.4518976212855836

Epoch: 6| Step: 10
Training loss: 2.65264126846389
Validation loss: 2.4745458531994835

Epoch: 6| Step: 11
Training loss: 2.6929426749184113
Validation loss: 2.4787239799027194

Epoch: 6| Step: 12
Training loss: 1.9320417861250128
Validation loss: 2.455089335715758

Epoch: 6| Step: 13
Training loss: 2.284962494289847
Validation loss: 2.471718062781401

Epoch: 106| Step: 0
Training loss: 2.4476378478214733
Validation loss: 2.4622718278484776

Epoch: 6| Step: 1
Training loss: 2.088884992911491
Validation loss: 2.493335567577774

Epoch: 6| Step: 2
Training loss: 2.796654378191837
Validation loss: 2.4701978000771847

Epoch: 6| Step: 3
Training loss: 2.2175313262274994
Validation loss: 2.483061507415246

Epoch: 6| Step: 4
Training loss: 2.1068439133035968
Validation loss: 2.4536887955925897

Epoch: 6| Step: 5
Training loss: 2.3313273480958205
Validation loss: 2.451910502724592

Epoch: 6| Step: 6
Training loss: 2.860734126697611
Validation loss: 2.468337920150998

Epoch: 6| Step: 7
Training loss: 2.0592113053554653
Validation loss: 2.4763430237447763

Epoch: 6| Step: 8
Training loss: 2.518356072832099
Validation loss: 2.4689746804812986

Epoch: 6| Step: 9
Training loss: 2.9016263544947742
Validation loss: 2.468950129795934

Epoch: 6| Step: 10
Training loss: 2.9715768305502857
Validation loss: 2.4710461079286

Epoch: 6| Step: 11
Training loss: 2.431669843260704
Validation loss: 2.470564850522478

Epoch: 6| Step: 12
Training loss: 3.125984952200941
Validation loss: 2.468003619821292

Epoch: 6| Step: 13
Training loss: 3.2029301281708946
Validation loss: 2.4547388158167673

Epoch: 107| Step: 0
Training loss: 2.8593241369174107
Validation loss: 2.4598108658548155

Epoch: 6| Step: 1
Training loss: 2.010909841920812
Validation loss: 2.458986180714585

Epoch: 6| Step: 2
Training loss: 2.450835015604306
Validation loss: 2.473072155889731

Epoch: 6| Step: 3
Training loss: 1.9432570540745373
Validation loss: 2.474105776336838

Epoch: 6| Step: 4
Training loss: 2.12395541378143
Validation loss: 2.4614506439287043

Epoch: 6| Step: 5
Training loss: 2.5071393116610357
Validation loss: 2.4698978018055535

Epoch: 6| Step: 6
Training loss: 2.943383513556046
Validation loss: 2.4888975101792

Epoch: 6| Step: 7
Training loss: 2.783459075402129
Validation loss: 2.4776239278546175

Epoch: 6| Step: 8
Training loss: 1.8565094609141493
Validation loss: 2.4823070682333928

Epoch: 6| Step: 9
Training loss: 3.169276182890582
Validation loss: 2.4436976173916762

Epoch: 6| Step: 10
Training loss: 2.5267183216857263
Validation loss: 2.464042020816109

Epoch: 6| Step: 11
Training loss: 3.343120765305378
Validation loss: 2.451494611884824

Epoch: 6| Step: 12
Training loss: 2.5929452038207614
Validation loss: 2.461507664195271

Epoch: 6| Step: 13
Training loss: 2.4127294322599577
Validation loss: 2.4708121988420197

Epoch: 108| Step: 0
Training loss: 2.7490388751231722
Validation loss: 2.4486647978390077

Epoch: 6| Step: 1
Training loss: 2.560250946798672
Validation loss: 2.474605986313953

Epoch: 6| Step: 2
Training loss: 2.7993373154771386
Validation loss: 2.445889964584199

Epoch: 6| Step: 3
Training loss: 2.527343183986123
Validation loss: 2.468357408553535

Epoch: 6| Step: 4
Training loss: 2.1150853605607733
Validation loss: 2.467805423411842

Epoch: 6| Step: 5
Training loss: 2.98101169745381
Validation loss: 2.462844453045615

Epoch: 6| Step: 6
Training loss: 2.6170810962512165
Validation loss: 2.4821283934038503

Epoch: 6| Step: 7
Training loss: 2.201223432043717
Validation loss: 2.469457926457439

Epoch: 6| Step: 8
Training loss: 2.6619784350248965
Validation loss: 2.4779729646731163

Epoch: 6| Step: 9
Training loss: 2.267583276971161
Validation loss: 2.498379847878956

Epoch: 6| Step: 10
Training loss: 2.552473035888526
Validation loss: 2.4556613630415707

Epoch: 6| Step: 11
Training loss: 2.689112778170883
Validation loss: 2.468581763366361

Epoch: 6| Step: 12
Training loss: 2.272692371447217
Validation loss: 2.455909805266649

Epoch: 6| Step: 13
Training loss: 3.113643151360032
Validation loss: 2.464325602406545

Epoch: 109| Step: 0
Training loss: 2.8391826127655775
Validation loss: 2.4608203167938125

Epoch: 6| Step: 1
Training loss: 2.6489611982799364
Validation loss: 2.4782419521580192

Epoch: 6| Step: 2
Training loss: 2.7713782173885826
Validation loss: 2.4789041576831257

Epoch: 6| Step: 3
Training loss: 2.626338889766076
Validation loss: 2.4658522239398146

Epoch: 6| Step: 4
Training loss: 2.066815571906784
Validation loss: 2.4689600086622248

Epoch: 6| Step: 5
Training loss: 2.351145761258973
Validation loss: 2.4892810207720073

Epoch: 6| Step: 6
Training loss: 2.251150896516428
Validation loss: 2.4900568301024877

Epoch: 6| Step: 7
Training loss: 2.07647846359008
Validation loss: 2.4718105721526333

Epoch: 6| Step: 8
Training loss: 2.7123534272844965
Validation loss: 2.4839030967099927

Epoch: 6| Step: 9
Training loss: 2.947813879227273
Validation loss: 2.4834395272849212

Epoch: 6| Step: 10
Training loss: 3.0992726057107784
Validation loss: 2.463750853289337

Epoch: 6| Step: 11
Training loss: 2.368673632354472
Validation loss: 2.481332033036543

Epoch: 6| Step: 12
Training loss: 2.4846565518894494
Validation loss: 2.457330966746426

Epoch: 6| Step: 13
Training loss: 2.27079246787535
Validation loss: 2.460770618036587

Epoch: 110| Step: 0
Training loss: 2.7415202054342402
Validation loss: 2.4662653854240566

Epoch: 6| Step: 1
Training loss: 1.9222468194814926
Validation loss: 2.464862933205379

Epoch: 6| Step: 2
Training loss: 2.7374436080907323
Validation loss: 2.4597842955976232

Epoch: 6| Step: 3
Training loss: 2.374803233779574
Validation loss: 2.4632872344058234

Epoch: 6| Step: 4
Training loss: 2.8459749006932538
Validation loss: 2.4685435932479494

Epoch: 6| Step: 5
Training loss: 2.7748583095908996
Validation loss: 2.456008022738163

Epoch: 6| Step: 6
Training loss: 1.6834458996492576
Validation loss: 2.450379973921559

Epoch: 6| Step: 7
Training loss: 2.014928889759173
Validation loss: 2.4798876847177236

Epoch: 6| Step: 8
Training loss: 2.9342627035637743
Validation loss: 2.4621582649472504

Epoch: 6| Step: 9
Training loss: 2.416769146116637
Validation loss: 2.4532636074632626

Epoch: 6| Step: 10
Training loss: 2.428337482596339
Validation loss: 2.4563307227568805

Epoch: 6| Step: 11
Training loss: 2.6718203890389374
Validation loss: 2.480859495118691

Epoch: 6| Step: 12
Training loss: 3.1745371804114146
Validation loss: 2.4583881664748106

Epoch: 6| Step: 13
Training loss: 3.00329472501822
Validation loss: 2.4664457046832147

Epoch: 111| Step: 0
Training loss: 2.3820784641990342
Validation loss: 2.4510198500483416

Epoch: 6| Step: 1
Training loss: 1.9259297466477916
Validation loss: 2.445557937746456

Epoch: 6| Step: 2
Training loss: 2.0549529741758614
Validation loss: 2.451602486052345

Epoch: 6| Step: 3
Training loss: 2.2576257965084796
Validation loss: 2.4658029281083

Epoch: 6| Step: 4
Training loss: 2.6964346940648665
Validation loss: 2.4630712178635785

Epoch: 6| Step: 5
Training loss: 3.050885656624142
Validation loss: 2.4726136829282894

Epoch: 6| Step: 6
Training loss: 2.472544687173929
Validation loss: 2.4520636131012283

Epoch: 6| Step: 7
Training loss: 2.005656944393774
Validation loss: 2.4546263686674634

Epoch: 6| Step: 8
Training loss: 2.8083639462063683
Validation loss: 2.4852872476303305

Epoch: 6| Step: 9
Training loss: 2.454432922410301
Validation loss: 2.436369263186224

Epoch: 6| Step: 10
Training loss: 2.654526095005001
Validation loss: 2.474623980173402

Epoch: 6| Step: 11
Training loss: 3.0407170594443187
Validation loss: 2.4927137211955137

Epoch: 6| Step: 12
Training loss: 2.6724897424770444
Validation loss: 2.480538994987321

Epoch: 6| Step: 13
Training loss: 3.365600353494294
Validation loss: 2.4709731290100905

Epoch: 112| Step: 0
Training loss: 2.3120654960911753
Validation loss: 2.462446706763696

Epoch: 6| Step: 1
Training loss: 2.591707459483418
Validation loss: 2.465725534315799

Epoch: 6| Step: 2
Training loss: 3.3856699374411807
Validation loss: 2.472763862957979

Epoch: 6| Step: 3
Training loss: 2.5355537467349785
Validation loss: 2.4749077486918774

Epoch: 6| Step: 4
Training loss: 2.3636199960608746
Validation loss: 2.4738738519117986

Epoch: 6| Step: 5
Training loss: 2.6716225488089522
Validation loss: 2.4700040486573966

Epoch: 6| Step: 6
Training loss: 1.9209783679989278
Validation loss: 2.4623359713412034

Epoch: 6| Step: 7
Training loss: 2.513002153765313
Validation loss: 2.4772527422556356

Epoch: 6| Step: 8
Training loss: 2.38482500981804
Validation loss: 2.480975187260926

Epoch: 6| Step: 9
Training loss: 2.4689900728182956
Validation loss: 2.4758079421982964

Epoch: 6| Step: 10
Training loss: 2.5215029076826676
Validation loss: 2.4781339863840253

Epoch: 6| Step: 11
Training loss: 2.830135579180865
Validation loss: 2.467245941030026

Epoch: 6| Step: 12
Training loss: 2.631137394251155
Validation loss: 2.4653068988687497

Epoch: 6| Step: 13
Training loss: 2.263057964504667
Validation loss: 2.482261441275312

Epoch: 113| Step: 0
Training loss: 3.2441917750708726
Validation loss: 2.4658124172295883

Epoch: 6| Step: 1
Training loss: 2.275014847927058
Validation loss: 2.459671191095502

Epoch: 6| Step: 2
Training loss: 2.85770555132372
Validation loss: 2.478026958380479

Epoch: 6| Step: 3
Training loss: 2.1017910857837485
Validation loss: 2.4829326706419477

Epoch: 6| Step: 4
Training loss: 1.5279574124857398
Validation loss: 2.457457024542318

Epoch: 6| Step: 5
Training loss: 2.56167365916019
Validation loss: 2.4919186470005075

Epoch: 6| Step: 6
Training loss: 2.829979725687577
Validation loss: 2.4852595499473566

Epoch: 6| Step: 7
Training loss: 2.1794687250198943
Validation loss: 2.4853825630136925

Epoch: 6| Step: 8
Training loss: 2.5428508022161944
Validation loss: 2.4547664766835253

Epoch: 6| Step: 9
Training loss: 3.1282293799607954
Validation loss: 2.4750062097409598

Epoch: 6| Step: 10
Training loss: 2.314143653492372
Validation loss: 2.475774295718045

Epoch: 6| Step: 11
Training loss: 2.91905802831051
Validation loss: 2.4642740726333967

Epoch: 6| Step: 12
Training loss: 1.8863648266281936
Validation loss: 2.499445320451035

Epoch: 6| Step: 13
Training loss: 3.014988649261516
Validation loss: 2.487872826676427

Epoch: 114| Step: 0
Training loss: 2.1542468510454547
Validation loss: 2.4664035568937983

Epoch: 6| Step: 1
Training loss: 2.458079201014376
Validation loss: 2.477129118481481

Epoch: 6| Step: 2
Training loss: 2.2803397256826377
Validation loss: 2.4500836948031197

Epoch: 6| Step: 3
Training loss: 3.069101031517633
Validation loss: 2.4888934961466522

Epoch: 6| Step: 4
Training loss: 2.081835882528848
Validation loss: 2.4558489283373492

Epoch: 6| Step: 5
Training loss: 3.0450227242359427
Validation loss: 2.465551405776792

Epoch: 6| Step: 6
Training loss: 2.8956680433638105
Validation loss: 2.4768210117285414

Epoch: 6| Step: 7
Training loss: 2.0604103368566142
Validation loss: 2.489763437097081

Epoch: 6| Step: 8
Training loss: 2.34401396218656
Validation loss: 2.451739598580448

Epoch: 6| Step: 9
Training loss: 2.610914495744615
Validation loss: 2.465258416779555

Epoch: 6| Step: 10
Training loss: 2.5765911741494487
Validation loss: 2.4690618996867

Epoch: 6| Step: 11
Training loss: 3.2962152625500463
Validation loss: 2.4453754696730137

Epoch: 6| Step: 12
Training loss: 1.9402584006087469
Validation loss: 2.459746807638676

Epoch: 6| Step: 13
Training loss: 2.2749690504379263
Validation loss: 2.450192025021553

Epoch: 115| Step: 0
Training loss: 1.9267662268569437
Validation loss: 2.4720244467576444

Epoch: 6| Step: 1
Training loss: 2.305241611916795
Validation loss: 2.451258841822002

Epoch: 6| Step: 2
Training loss: 2.7924023887629525
Validation loss: 2.4458137749847975

Epoch: 6| Step: 3
Training loss: 2.7811270697354225
Validation loss: 2.460618059866482

Epoch: 6| Step: 4
Training loss: 2.3563096299455366
Validation loss: 2.4482864578828107

Epoch: 6| Step: 5
Training loss: 2.688079061889503
Validation loss: 2.476778754300599

Epoch: 6| Step: 6
Training loss: 2.3980527687279953
Validation loss: 2.4839872187996552

Epoch: 6| Step: 7
Training loss: 2.537451599862166
Validation loss: 2.4544187287393284

Epoch: 6| Step: 8
Training loss: 2.6342822763363225
Validation loss: 2.443298450826953

Epoch: 6| Step: 9
Training loss: 3.4468824481624254
Validation loss: 2.4698252565687624

Epoch: 6| Step: 10
Training loss: 2.560911663267225
Validation loss: 2.4605289378563406

Epoch: 6| Step: 11
Training loss: 2.1831070523052576
Validation loss: 2.44199789958008

Epoch: 6| Step: 12
Training loss: 2.407246965240616
Validation loss: 2.4538200997256556

Epoch: 6| Step: 13
Training loss: 2.591924277582946
Validation loss: 2.4333015223907504

Epoch: 116| Step: 0
Training loss: 2.5327650645836632
Validation loss: 2.45287288208603

Epoch: 6| Step: 1
Training loss: 2.4279169334706943
Validation loss: 2.4499185399167827

Epoch: 6| Step: 2
Training loss: 2.6555494394413715
Validation loss: 2.483529760560886

Epoch: 6| Step: 3
Training loss: 1.7968960968105958
Validation loss: 2.447492911464616

Epoch: 6| Step: 4
Training loss: 2.9675023719887386
Validation loss: 2.4697693443752295

Epoch: 6| Step: 5
Training loss: 2.9963722547178233
Validation loss: 2.469336872327903

Epoch: 6| Step: 6
Training loss: 2.2408355996983556
Validation loss: 2.4704998456242038

Epoch: 6| Step: 7
Training loss: 2.829249037459728
Validation loss: 2.466284567966447

Epoch: 6| Step: 8
Training loss: 1.8375538305584942
Validation loss: 2.4553167092262638

Epoch: 6| Step: 9
Training loss: 3.0081373163189484
Validation loss: 2.4500233846439525

Epoch: 6| Step: 10
Training loss: 2.837229368772964
Validation loss: 2.457805882164498

Epoch: 6| Step: 11
Training loss: 3.0774191419823613
Validation loss: 2.4508866856762475

Epoch: 6| Step: 12
Training loss: 1.7134303913876927
Validation loss: 2.474567831937311

Epoch: 6| Step: 13
Training loss: 1.6024936853245715
Validation loss: 2.448913341646702

Epoch: 117| Step: 0
Training loss: 2.6337008010621443
Validation loss: 2.4847709890696286

Epoch: 6| Step: 1
Training loss: 3.142358102439906
Validation loss: 2.460006973908006

Epoch: 6| Step: 2
Training loss: 2.0624830071876334
Validation loss: 2.465667419014635

Epoch: 6| Step: 3
Training loss: 2.7138554153104697
Validation loss: 2.4482414052898616

Epoch: 6| Step: 4
Training loss: 2.2418698607556813
Validation loss: 2.456392040694761

Epoch: 6| Step: 5
Training loss: 2.1351781448263383
Validation loss: 2.469452356835308

Epoch: 6| Step: 6
Training loss: 1.8987159053913216
Validation loss: 2.445677618514895

Epoch: 6| Step: 7
Training loss: 1.862361272983413
Validation loss: 2.4564255294614563

Epoch: 6| Step: 8
Training loss: 3.3075351575394287
Validation loss: 2.4225305088928204

Epoch: 6| Step: 9
Training loss: 2.417455171881506
Validation loss: 2.46496571640691

Epoch: 6| Step: 10
Training loss: 2.745327534685994
Validation loss: 2.453610229784152

Epoch: 6| Step: 11
Training loss: 2.7096632895379598
Validation loss: 2.4895093432052673

Epoch: 6| Step: 12
Training loss: 2.983691232052187
Validation loss: 2.460533552455077

Epoch: 6| Step: 13
Training loss: 2.1468180153292877
Validation loss: 2.4708115347971247

Epoch: 118| Step: 0
Training loss: 2.7844872654332367
Validation loss: 2.457750216515669

Epoch: 6| Step: 1
Training loss: 2.0818789428197193
Validation loss: 2.446287436048061

Epoch: 6| Step: 2
Training loss: 2.9578593416127186
Validation loss: 2.4435188219988047

Epoch: 6| Step: 3
Training loss: 2.5211460350438033
Validation loss: 2.4807219107644265

Epoch: 6| Step: 4
Training loss: 1.7916711836765333
Validation loss: 2.471213382143812

Epoch: 6| Step: 5
Training loss: 3.7128897260075844
Validation loss: 2.4788694492231635

Epoch: 6| Step: 6
Training loss: 1.7715368631109092
Validation loss: 2.455416199136806

Epoch: 6| Step: 7
Training loss: 2.479139269081697
Validation loss: 2.468364065982583

Epoch: 6| Step: 8
Training loss: 2.3145825056136946
Validation loss: 2.450658440860516

Epoch: 6| Step: 9
Training loss: 2.6992590276028907
Validation loss: 2.4725519979430692

Epoch: 6| Step: 10
Training loss: 2.416933001169274
Validation loss: 2.476602860594126

Epoch: 6| Step: 11
Training loss: 1.9859361890162741
Validation loss: 2.470028639205514

Epoch: 6| Step: 12
Training loss: 2.582358843037479
Validation loss: 2.445409312686222

Epoch: 6| Step: 13
Training loss: 3.03299151859676
Validation loss: 2.456810955557123

Epoch: 119| Step: 0
Training loss: 2.415016751122676
Validation loss: 2.4628579631966536

Epoch: 6| Step: 1
Training loss: 2.675306113723068
Validation loss: 2.487316396113432

Epoch: 6| Step: 2
Training loss: 2.660485156279709
Validation loss: 2.4760951594366825

Epoch: 6| Step: 3
Training loss: 2.489669628057618
Validation loss: 2.453595348021816

Epoch: 6| Step: 4
Training loss: 2.8510892292404355
Validation loss: 2.472848640788498

Epoch: 6| Step: 5
Training loss: 2.526321699737863
Validation loss: 2.4671350952543953

Epoch: 6| Step: 6
Training loss: 2.005401469916184
Validation loss: 2.4529327333953312

Epoch: 6| Step: 7
Training loss: 1.9913991527647903
Validation loss: 2.447358198657157

Epoch: 6| Step: 8
Training loss: 2.562800599121624
Validation loss: 2.471628454185968

Epoch: 6| Step: 9
Training loss: 2.947627040982202
Validation loss: 2.4527407046611454

Epoch: 6| Step: 10
Training loss: 2.9360305682053998
Validation loss: 2.443342130879894

Epoch: 6| Step: 11
Training loss: 2.5895349655074074
Validation loss: 2.4639918064741106

Epoch: 6| Step: 12
Training loss: 2.5034021117019005
Validation loss: 2.4630180547698983

Epoch: 6| Step: 13
Training loss: 1.8244280480633992
Validation loss: 2.4691049557651943

Epoch: 120| Step: 0
Training loss: 2.2099136839706173
Validation loss: 2.4700657017873007

Epoch: 6| Step: 1
Training loss: 2.965061828071568
Validation loss: 2.445615943884859

Epoch: 6| Step: 2
Training loss: 2.5068707465566322
Validation loss: 2.448060019508092

Epoch: 6| Step: 3
Training loss: 2.719493369715625
Validation loss: 2.445883426264041

Epoch: 6| Step: 4
Training loss: 2.4648834080233746
Validation loss: 2.467958943785495

Epoch: 6| Step: 5
Training loss: 1.8958041290157752
Validation loss: 2.464773488311322

Epoch: 6| Step: 6
Training loss: 2.5853492090696206
Validation loss: 2.456988717945223

Epoch: 6| Step: 7
Training loss: 2.6591786115954488
Validation loss: 2.448635881831867

Epoch: 6| Step: 8
Training loss: 2.6909565542988654
Validation loss: 2.445108338535196

Epoch: 6| Step: 9
Training loss: 2.0542402469644427
Validation loss: 2.440133544487273

Epoch: 6| Step: 10
Training loss: 2.474706489807096
Validation loss: 2.4661947432350626

Epoch: 6| Step: 11
Training loss: 2.985523901480039
Validation loss: 2.45817547648158

Epoch: 6| Step: 12
Training loss: 2.754611397144756
Validation loss: 2.4582509367162597

Epoch: 6| Step: 13
Training loss: 2.118324565654211
Validation loss: 2.4423466739241855

Epoch: 121| Step: 0
Training loss: 3.3462080432540042
Validation loss: 2.4810617624447957

Epoch: 6| Step: 1
Training loss: 2.568362716846685
Validation loss: 2.463651597980652

Epoch: 6| Step: 2
Training loss: 2.6634171674740714
Validation loss: 2.450568728581375

Epoch: 6| Step: 3
Training loss: 2.2970907927369577
Validation loss: 2.478940371406088

Epoch: 6| Step: 4
Training loss: 2.582290890288201
Validation loss: 2.4747502121884306

Epoch: 6| Step: 5
Training loss: 2.7874479348832795
Validation loss: 2.457734669295177

Epoch: 6| Step: 6
Training loss: 2.4602449926250376
Validation loss: 2.4758254525596297

Epoch: 6| Step: 7
Training loss: 1.4357238245269635
Validation loss: 2.46995447033735

Epoch: 6| Step: 8
Training loss: 2.497181638907213
Validation loss: 2.462207461951188

Epoch: 6| Step: 9
Training loss: 2.4985684110639927
Validation loss: 2.427635996261077

Epoch: 6| Step: 10
Training loss: 2.3418414674001866
Validation loss: 2.4613973989634217

Epoch: 6| Step: 11
Training loss: 2.489425994710847
Validation loss: 2.449369567957678

Epoch: 6| Step: 12
Training loss: 2.4870363771472386
Validation loss: 2.4651341010267043

Epoch: 6| Step: 13
Training loss: 2.181659749629414
Validation loss: 2.476775781576325

Epoch: 122| Step: 0
Training loss: 2.5601498130831497
Validation loss: 2.4522047446686965

Epoch: 6| Step: 1
Training loss: 2.700832386983792
Validation loss: 2.4155855886645217

Epoch: 6| Step: 2
Training loss: 2.625884315853724
Validation loss: 2.4259914392800233

Epoch: 6| Step: 3
Training loss: 2.9637334903432575
Validation loss: 2.4588898879874863

Epoch: 6| Step: 4
Training loss: 2.5900204973624845
Validation loss: 2.486368493074801

Epoch: 6| Step: 5
Training loss: 2.5575040171005305
Validation loss: 2.4786153442106498

Epoch: 6| Step: 6
Training loss: 1.8669840171101233
Validation loss: 2.47015176367031

Epoch: 6| Step: 7
Training loss: 2.17393549596553
Validation loss: 2.4656863452376228

Epoch: 6| Step: 8
Training loss: 2.5246718845009637
Validation loss: 2.469904668900562

Epoch: 6| Step: 9
Training loss: 2.67833148244886
Validation loss: 2.467020793954771

Epoch: 6| Step: 10
Training loss: 2.76013846285045
Validation loss: 2.470171207665201

Epoch: 6| Step: 11
Training loss: 2.1612982878356854
Validation loss: 2.488689075786349

Epoch: 6| Step: 12
Training loss: 2.4205415069419103
Validation loss: 2.4560933705856187

Epoch: 6| Step: 13
Training loss: 2.858277490661648
Validation loss: 2.4457535440164433

Epoch: 123| Step: 0
Training loss: 1.7751376703090989
Validation loss: 2.470605854903582

Epoch: 6| Step: 1
Training loss: 2.7617025199531935
Validation loss: 2.431128298484047

Epoch: 6| Step: 2
Training loss: 2.3544350755205183
Validation loss: 2.4434611469299847

Epoch: 6| Step: 3
Training loss: 2.237441086659484
Validation loss: 2.4616088516593386

Epoch: 6| Step: 4
Training loss: 2.4769319565582406
Validation loss: 2.4625882270515285

Epoch: 6| Step: 5
Training loss: 2.6293623870046563
Validation loss: 2.4480809610634156

Epoch: 6| Step: 6
Training loss: 3.415900043606393
Validation loss: 2.4844937983949906

Epoch: 6| Step: 7
Training loss: 1.9527502081805845
Validation loss: 2.4342272026615017

Epoch: 6| Step: 8
Training loss: 2.7886730103784982
Validation loss: 2.453486022865203

Epoch: 6| Step: 9
Training loss: 2.473491605936817
Validation loss: 2.439793861252674

Epoch: 6| Step: 10
Training loss: 2.637957608267725
Validation loss: 2.470508145663248

Epoch: 6| Step: 11
Training loss: 2.956607601804366
Validation loss: 2.4524763942956973

Epoch: 6| Step: 12
Training loss: 2.418166440607172
Validation loss: 2.4405036028759923

Epoch: 6| Step: 13
Training loss: 1.964915279959628
Validation loss: 2.467702083217597

Epoch: 124| Step: 0
Training loss: 3.146659557312946
Validation loss: 2.45346545711264

Epoch: 6| Step: 1
Training loss: 2.633463249945261
Validation loss: 2.4678861758659987

Epoch: 6| Step: 2
Training loss: 2.646383833998875
Validation loss: 2.443252657806163

Epoch: 6| Step: 3
Training loss: 2.3589549922360766
Validation loss: 2.4600554802910573

Epoch: 6| Step: 4
Training loss: 2.7485865515130588
Validation loss: 2.467217950929731

Epoch: 6| Step: 5
Training loss: 2.609349233534367
Validation loss: 2.4477925440402712

Epoch: 6| Step: 6
Training loss: 1.6861862437508206
Validation loss: 2.4822915901313958

Epoch: 6| Step: 7
Training loss: 2.340602643424449
Validation loss: 2.4683343047466746

Epoch: 6| Step: 8
Training loss: 2.7959613693035346
Validation loss: 2.469314199194277

Epoch: 6| Step: 9
Training loss: 2.672397495512866
Validation loss: 2.436228020324744

Epoch: 6| Step: 10
Training loss: 2.416608831656306
Validation loss: 2.456476452113615

Epoch: 6| Step: 11
Training loss: 2.595383279238329
Validation loss: 2.4389764759231785

Epoch: 6| Step: 12
Training loss: 1.8884552414215539
Validation loss: 2.4468651844544898

Epoch: 6| Step: 13
Training loss: 2.3895630316521825
Validation loss: 2.443537804103027

Epoch: 125| Step: 0
Training loss: 2.369714477176232
Validation loss: 2.4766750680827365

Epoch: 6| Step: 1
Training loss: 2.628770209727689
Validation loss: 2.4558362481505376

Epoch: 6| Step: 2
Training loss: 1.9445478782693828
Validation loss: 2.456824395582288

Epoch: 6| Step: 3
Training loss: 2.4914982240147303
Validation loss: 2.4360403513304036

Epoch: 6| Step: 4
Training loss: 2.2639426463582852
Validation loss: 2.4760542501020026

Epoch: 6| Step: 5
Training loss: 2.1774148886303233
Validation loss: 2.4764352216279386

Epoch: 6| Step: 6
Training loss: 2.7175663969601933
Validation loss: 2.487100273645011

Epoch: 6| Step: 7
Training loss: 1.8458338454039862
Validation loss: 2.470329805687012

Epoch: 6| Step: 8
Training loss: 3.293410664112545
Validation loss: 2.468066486294096

Epoch: 6| Step: 9
Training loss: 3.0421202508657577
Validation loss: 2.4623517883149626

Epoch: 6| Step: 10
Training loss: 2.262933750620748
Validation loss: 2.468908940083838

Epoch: 6| Step: 11
Training loss: 2.809112034118086
Validation loss: 2.474554676834065

Epoch: 6| Step: 12
Training loss: 2.176690231923958
Validation loss: 2.477428436671231

Epoch: 6| Step: 13
Training loss: 2.7351601481580157
Validation loss: 2.4582967235772357

Epoch: 126| Step: 0
Training loss: 2.096958719279263
Validation loss: 2.4634397016851004

Epoch: 6| Step: 1
Training loss: 2.2886799046664805
Validation loss: 2.463374541026223

Epoch: 6| Step: 2
Training loss: 2.582390418298901
Validation loss: 2.4694094967971965

Epoch: 6| Step: 3
Training loss: 2.546019896202528
Validation loss: 2.437434535045372

Epoch: 6| Step: 4
Training loss: 1.9277782802355157
Validation loss: 2.4378904792928657

Epoch: 6| Step: 5
Training loss: 2.633605837504243
Validation loss: 2.440215496325594

Epoch: 6| Step: 6
Training loss: 2.2179161976564084
Validation loss: 2.4448863700054453

Epoch: 6| Step: 7
Training loss: 2.526236667512936
Validation loss: 2.4688753174387617

Epoch: 6| Step: 8
Training loss: 2.4764456255076936
Validation loss: 2.461160348964658

Epoch: 6| Step: 9
Training loss: 2.9433047790121503
Validation loss: 2.4391919110013056

Epoch: 6| Step: 10
Training loss: 2.941810043198104
Validation loss: 2.4591867339737603

Epoch: 6| Step: 11
Training loss: 2.652513456463275
Validation loss: 2.4457015170683416

Epoch: 6| Step: 12
Training loss: 2.6355141381695253
Validation loss: 2.446151733539164

Epoch: 6| Step: 13
Training loss: 2.49063741376935
Validation loss: 2.4656802628272447

Epoch: 127| Step: 0
Training loss: 3.2779373158855556
Validation loss: 2.487752175004959

Epoch: 6| Step: 1
Training loss: 2.2383813752420014
Validation loss: 2.4475849632912605

Epoch: 6| Step: 2
Training loss: 2.2909858617125716
Validation loss: 2.466001320807661

Epoch: 6| Step: 3
Training loss: 1.9736236315348064
Validation loss: 2.4291000001477583

Epoch: 6| Step: 4
Training loss: 2.8930246651129092
Validation loss: 2.482021739056742

Epoch: 6| Step: 5
Training loss: 2.387305754104472
Validation loss: 2.46144386416989

Epoch: 6| Step: 6
Training loss: 2.7435255997292294
Validation loss: 2.4555717155669563

Epoch: 6| Step: 7
Training loss: 2.235112955366751
Validation loss: 2.4455385852885563

Epoch: 6| Step: 8
Training loss: 2.442591801990485
Validation loss: 2.450690103049164

Epoch: 6| Step: 9
Training loss: 2.028556563862119
Validation loss: 2.4539628143221024

Epoch: 6| Step: 10
Training loss: 2.1664158113463277
Validation loss: 2.4645040231907878

Epoch: 6| Step: 11
Training loss: 2.7058653419355045
Validation loss: 2.427916503718829

Epoch: 6| Step: 12
Training loss: 2.779679615852278
Validation loss: 2.439514906569449

Epoch: 6| Step: 13
Training loss: 2.687430092545541
Validation loss: 2.451688687336395

Epoch: 128| Step: 0
Training loss: 2.427715715749392
Validation loss: 2.456709465341062

Epoch: 6| Step: 1
Training loss: 2.4626664158701015
Validation loss: 2.429755067593086

Epoch: 6| Step: 2
Training loss: 2.665999527767337
Validation loss: 2.476840017813491

Epoch: 6| Step: 3
Training loss: 2.5490721604020488
Validation loss: 2.455024588322902

Epoch: 6| Step: 4
Training loss: 2.6281700974086677
Validation loss: 2.4628921811558033

Epoch: 6| Step: 5
Training loss: 2.430694959972114
Validation loss: 2.4599546866950246

Epoch: 6| Step: 6
Training loss: 2.4061691468761928
Validation loss: 2.446066825907356

Epoch: 6| Step: 7
Training loss: 2.373416674022202
Validation loss: 2.457661504768271

Epoch: 6| Step: 8
Training loss: 2.3881533941973467
Validation loss: 2.4523570955016183

Epoch: 6| Step: 9
Training loss: 2.850698679896213
Validation loss: 2.448870752349186

Epoch: 6| Step: 10
Training loss: 2.5659649380959197
Validation loss: 2.4723353407478297

Epoch: 6| Step: 11
Training loss: 2.597502234919654
Validation loss: 2.465421992956883

Epoch: 6| Step: 12
Training loss: 2.17625227645939
Validation loss: 2.4495141410453196

Epoch: 6| Step: 13
Training loss: 2.6938565509726047
Validation loss: 2.4590289232180353

Epoch: 129| Step: 0
Training loss: 2.8726005492776836
Validation loss: 2.432812985959521

Epoch: 6| Step: 1
Training loss: 2.3825580398519026
Validation loss: 2.4644862758347457

Epoch: 6| Step: 2
Training loss: 3.196141813891686
Validation loss: 2.453408106779705

Epoch: 6| Step: 3
Training loss: 2.3463869646484814
Validation loss: 2.452698913485835

Epoch: 6| Step: 4
Training loss: 2.3345824939681568
Validation loss: 2.4430095846214552

Epoch: 6| Step: 5
Training loss: 2.443858534019872
Validation loss: 2.4477087176475996

Epoch: 6| Step: 6
Training loss: 1.9247707478140417
Validation loss: 2.4410550024546076

Epoch: 6| Step: 7
Training loss: 2.832150455465348
Validation loss: 2.441524373402478

Epoch: 6| Step: 8
Training loss: 2.752371112601932
Validation loss: 2.4517018610888126

Epoch: 6| Step: 9
Training loss: 2.196480762601511
Validation loss: 2.4710703535254486

Epoch: 6| Step: 10
Training loss: 2.3112009884809397
Validation loss: 2.4324646336870406

Epoch: 6| Step: 11
Training loss: 1.7941087742791162
Validation loss: 2.462751118663222

Epoch: 6| Step: 12
Training loss: 2.5508403216264925
Validation loss: 2.4356676171044818

Epoch: 6| Step: 13
Training loss: 2.8510582883102
Validation loss: 2.4440964313633478

Epoch: 130| Step: 0
Training loss: 2.224788990087608
Validation loss: 2.456421196236134

Epoch: 6| Step: 1
Training loss: 1.954139812043662
Validation loss: 2.455305948521469

Epoch: 6| Step: 2
Training loss: 2.4365015185637335
Validation loss: 2.459752266873222

Epoch: 6| Step: 3
Training loss: 2.8961090029862024
Validation loss: 2.467051944794817

Epoch: 6| Step: 4
Training loss: 1.736881403957557
Validation loss: 2.443596285452053

Epoch: 6| Step: 5
Training loss: 2.6214494762277596
Validation loss: 2.4551151621447245

Epoch: 6| Step: 6
Training loss: 2.951005124342634
Validation loss: 2.456443494731722

Epoch: 6| Step: 7
Training loss: 2.3692442768313993
Validation loss: 2.473326985876462

Epoch: 6| Step: 8
Training loss: 2.3669424402275485
Validation loss: 2.458451294471722

Epoch: 6| Step: 9
Training loss: 2.9565609919583804
Validation loss: 2.4722371362670525

Epoch: 6| Step: 10
Training loss: 2.502439453124238
Validation loss: 2.4577742761801

Epoch: 6| Step: 11
Training loss: 2.9668029825274527
Validation loss: 2.438693018338649

Epoch: 6| Step: 12
Training loss: 2.344374509896268
Validation loss: 2.466852159836811

Epoch: 6| Step: 13
Training loss: 2.293333996044477
Validation loss: 2.460454046574586

Epoch: 131| Step: 0
Training loss: 3.436206088599052
Validation loss: 2.475564294008376

Epoch: 6| Step: 1
Training loss: 2.09236486365458
Validation loss: 2.46848201374573

Epoch: 6| Step: 2
Training loss: 2.717202721893686
Validation loss: 2.469990259991372

Epoch: 6| Step: 3
Training loss: 2.5324515799198752
Validation loss: 2.4675672202224757

Epoch: 6| Step: 4
Training loss: 1.753171499251038
Validation loss: 2.4505647323191613

Epoch: 6| Step: 5
Training loss: 2.25060338300998
Validation loss: 2.4762451826736993

Epoch: 6| Step: 6
Training loss: 1.3793054278466947
Validation loss: 2.4559898726557243

Epoch: 6| Step: 7
Training loss: 2.821631463949034
Validation loss: 2.477786023969758

Epoch: 6| Step: 8
Training loss: 2.964550219896202
Validation loss: 2.4419931523220155

Epoch: 6| Step: 9
Training loss: 2.501246904316921
Validation loss: 2.454151357660845

Epoch: 6| Step: 10
Training loss: 2.454973435578677
Validation loss: 2.4359121922554223

Epoch: 6| Step: 11
Training loss: 2.2949740270005092
Validation loss: 2.4603130349767057

Epoch: 6| Step: 12
Training loss: 2.59622166536873
Validation loss: 2.433729811435499

Epoch: 6| Step: 13
Training loss: 2.6626534860991833
Validation loss: 2.436618721344396

Epoch: 132| Step: 0
Training loss: 2.0804567950510817
Validation loss: 2.4334493983485466

Epoch: 6| Step: 1
Training loss: 1.7471030644288894
Validation loss: 2.441936822807613

Epoch: 6| Step: 2
Training loss: 2.445328587488265
Validation loss: 2.4312145513690844

Epoch: 6| Step: 3
Training loss: 2.9498167530624593
Validation loss: 2.4750851528782563

Epoch: 6| Step: 4
Training loss: 2.424392769677855
Validation loss: 2.44636778064278

Epoch: 6| Step: 5
Training loss: 2.7094310785493656
Validation loss: 2.476004266948026

Epoch: 6| Step: 6
Training loss: 2.60310478431573
Validation loss: 2.4453062164677766

Epoch: 6| Step: 7
Training loss: 2.25553953867687
Validation loss: 2.4621548882787394

Epoch: 6| Step: 8
Training loss: 3.0362708599305304
Validation loss: 2.4259742672046842

Epoch: 6| Step: 9
Training loss: 2.310587736721312
Validation loss: 2.4497541179499702

Epoch: 6| Step: 10
Training loss: 2.5073929195036624
Validation loss: 2.436060127578874

Epoch: 6| Step: 11
Training loss: 2.3991674250656403
Validation loss: 2.4452663117036098

Epoch: 6| Step: 12
Training loss: 2.985988001294056
Validation loss: 2.40932781818671

Epoch: 6| Step: 13
Training loss: 1.803166264370907
Validation loss: 2.4355521237514757

Epoch: 133| Step: 0
Training loss: 2.678738261885565
Validation loss: 2.423540732448671

Epoch: 6| Step: 1
Training loss: 2.276809446494316
Validation loss: 2.4520066220532457

Epoch: 6| Step: 2
Training loss: 3.416587472013333
Validation loss: 2.4387716242563573

Epoch: 6| Step: 3
Training loss: 2.3702851728298664
Validation loss: 2.457373391161272

Epoch: 6| Step: 4
Training loss: 2.5698887438014855
Validation loss: 2.431847892685189

Epoch: 6| Step: 5
Training loss: 2.294484250162368
Validation loss: 2.4341580767294833

Epoch: 6| Step: 6
Training loss: 1.9164803317618548
Validation loss: 2.4432432961687174

Epoch: 6| Step: 7
Training loss: 2.7393545966636386
Validation loss: 2.453770005305152

Epoch: 6| Step: 8
Training loss: 3.004123714596744
Validation loss: 2.4439343282671717

Epoch: 6| Step: 9
Training loss: 2.0622131841811355
Validation loss: 2.4438864921682004

Epoch: 6| Step: 10
Training loss: 1.982617719024686
Validation loss: 2.4414451305287783

Epoch: 6| Step: 11
Training loss: 2.049867495464622
Validation loss: 2.4584466811784513

Epoch: 6| Step: 12
Training loss: 2.303564800366976
Validation loss: 2.452205997109262

Epoch: 6| Step: 13
Training loss: 2.7495528637898827
Validation loss: 2.4538817024041992

Epoch: 134| Step: 0
Training loss: 2.9220013106680667
Validation loss: 2.447025164138567

Epoch: 6| Step: 1
Training loss: 2.499926565999126
Validation loss: 2.4495438473178197

Epoch: 6| Step: 2
Training loss: 2.542465230428336
Validation loss: 2.456781890207794

Epoch: 6| Step: 3
Training loss: 2.7839640544236994
Validation loss: 2.4669009545843252

Epoch: 6| Step: 4
Training loss: 2.960605411476818
Validation loss: 2.4726046719608603

Epoch: 6| Step: 5
Training loss: 2.499046143715231
Validation loss: 2.4311462756446893

Epoch: 6| Step: 6
Training loss: 1.837540596234559
Validation loss: 2.4610274426544843

Epoch: 6| Step: 7
Training loss: 2.233171258805465
Validation loss: 2.436168310035565

Epoch: 6| Step: 8
Training loss: 2.886880624901494
Validation loss: 2.4421828401963674

Epoch: 6| Step: 9
Training loss: 2.2581366599991095
Validation loss: 2.4381712269871256

Epoch: 6| Step: 10
Training loss: 2.6691975702915824
Validation loss: 2.4725357661607172

Epoch: 6| Step: 11
Training loss: 1.6780388836635074
Validation loss: 2.460354284195665

Epoch: 6| Step: 12
Training loss: 2.377502728930972
Validation loss: 2.4522962161013573

Epoch: 6| Step: 13
Training loss: 1.6277971402529474
Validation loss: 2.442055120005787

Epoch: 135| Step: 0
Training loss: 2.171095893587013
Validation loss: 2.45369582141298

Epoch: 6| Step: 1
Training loss: 2.369021470107453
Validation loss: 2.4479107383877916

Epoch: 6| Step: 2
Training loss: 2.80038453595115
Validation loss: 2.44974588939347

Epoch: 6| Step: 3
Training loss: 2.3171366011417693
Validation loss: 2.4337132722707153

Epoch: 6| Step: 4
Training loss: 2.4079919430100505
Validation loss: 2.4193659334030895

Epoch: 6| Step: 5
Training loss: 2.47126487407154
Validation loss: 2.4597532168705123

Epoch: 6| Step: 6
Training loss: 2.320148911794325
Validation loss: 2.431085915915917

Epoch: 6| Step: 7
Training loss: 1.96073961209317
Validation loss: 2.4401184208390636

Epoch: 6| Step: 8
Training loss: 2.7207762084696907
Validation loss: 2.467212086346532

Epoch: 6| Step: 9
Training loss: 3.17159100844376
Validation loss: 2.4229381110822485

Epoch: 6| Step: 10
Training loss: 2.4850008194306095
Validation loss: 2.425615391625923

Epoch: 6| Step: 11
Training loss: 2.685103035056273
Validation loss: 2.4556521405794505

Epoch: 6| Step: 12
Training loss: 2.224344962920231
Validation loss: 2.456261320760465

Epoch: 6| Step: 13
Training loss: 2.2940230537060997
Validation loss: 2.4497343769027164

Epoch: 136| Step: 0
Training loss: 2.34545958157537
Validation loss: 2.4762400998948593

Epoch: 6| Step: 1
Training loss: 2.644781058611836
Validation loss: 2.4500679189606935

Epoch: 6| Step: 2
Training loss: 2.0481402730736082
Validation loss: 2.454997546474179

Epoch: 6| Step: 3
Training loss: 2.6852150895900424
Validation loss: 2.47058591209962

Epoch: 6| Step: 4
Training loss: 2.528572927432967
Validation loss: 2.4016927866115867

Epoch: 6| Step: 5
Training loss: 2.2309133751234467
Validation loss: 2.4588445182725494

Epoch: 6| Step: 6
Training loss: 2.9218085786338266
Validation loss: 2.403705338656646

Epoch: 6| Step: 7
Training loss: 2.188007731777945
Validation loss: 2.431948281553872

Epoch: 6| Step: 8
Training loss: 1.806720859704835
Validation loss: 2.4672139650097122

Epoch: 6| Step: 9
Training loss: 2.3310110138412408
Validation loss: 2.4469602180325922

Epoch: 6| Step: 10
Training loss: 2.8179812954294747
Validation loss: 2.4369250161819496

Epoch: 6| Step: 11
Training loss: 1.9592490659212352
Validation loss: 2.421213421285538

Epoch: 6| Step: 12
Training loss: 3.05017099370188
Validation loss: 2.4469473980159115

Epoch: 6| Step: 13
Training loss: 3.2259537166389993
Validation loss: 2.4378549807962187

Epoch: 137| Step: 0
Training loss: 2.0299029064918193
Validation loss: 2.4563120793038484

Epoch: 6| Step: 1
Training loss: 2.583975701811313
Validation loss: 2.430377154466047

Epoch: 6| Step: 2
Training loss: 2.3708407472875574
Validation loss: 2.418395144229131

Epoch: 6| Step: 3
Training loss: 1.9814561417736354
Validation loss: 2.4787771433075525

Epoch: 6| Step: 4
Training loss: 2.4634524135000255
Validation loss: 2.4665095707318097

Epoch: 6| Step: 5
Training loss: 2.8870216799147617
Validation loss: 2.4543205792794205

Epoch: 6| Step: 6
Training loss: 2.2788013223548815
Validation loss: 2.449485354377452

Epoch: 6| Step: 7
Training loss: 3.0416706729670926
Validation loss: 2.431679552029165

Epoch: 6| Step: 8
Training loss: 2.6407084254342017
Validation loss: 2.453139900291331

Epoch: 6| Step: 9
Training loss: 2.331467552363401
Validation loss: 2.4739331412638377

Epoch: 6| Step: 10
Training loss: 2.3760546300239813
Validation loss: 2.4266637546576373

Epoch: 6| Step: 11
Training loss: 2.8049702196359294
Validation loss: 2.447870526285845

Epoch: 6| Step: 12
Training loss: 1.696858347324552
Validation loss: 2.4462710635273637

Epoch: 6| Step: 13
Training loss: 2.8691073857843157
Validation loss: 2.465813986096896

Epoch: 138| Step: 0
Training loss: 2.5159477832391195
Validation loss: 2.446459556243167

Epoch: 6| Step: 1
Training loss: 2.3789481423984826
Validation loss: 2.4574300991773455

Epoch: 6| Step: 2
Training loss: 2.2203888549131894
Validation loss: 2.435534233320115

Epoch: 6| Step: 3
Training loss: 2.848011554587424
Validation loss: 2.4579176988533407

Epoch: 6| Step: 4
Training loss: 2.11654844880069
Validation loss: 2.458680201594079

Epoch: 6| Step: 5
Training loss: 2.4864102070602585
Validation loss: 2.457772106063524

Epoch: 6| Step: 6
Training loss: 2.2495227943447498
Validation loss: 2.4588831069023445

Epoch: 6| Step: 7
Training loss: 2.006880131812649
Validation loss: 2.446413032263139

Epoch: 6| Step: 8
Training loss: 2.156196704150562
Validation loss: 2.4568597890359363

Epoch: 6| Step: 9
Training loss: 3.431146611113487
Validation loss: 2.4547082836478853

Epoch: 6| Step: 10
Training loss: 2.674592716192461
Validation loss: 2.4532233634495317

Epoch: 6| Step: 11
Training loss: 2.0506455730788633
Validation loss: 2.46041012432695

Epoch: 6| Step: 12
Training loss: 2.414329538729548
Validation loss: 2.4460346280452696

Epoch: 6| Step: 13
Training loss: 2.3771371762337505
Validation loss: 2.4636526239979437

Epoch: 139| Step: 0
Training loss: 2.1078347693441146
Validation loss: 2.4333411687617197

Epoch: 6| Step: 1
Training loss: 2.2819334077739097
Validation loss: 2.437917252411976

Epoch: 6| Step: 2
Training loss: 2.354554259764789
Validation loss: 2.4456808596500035

Epoch: 6| Step: 3
Training loss: 2.1160547808819503
Validation loss: 2.4513734335973147

Epoch: 6| Step: 4
Training loss: 2.4753443854047825
Validation loss: 2.46304528022095

Epoch: 6| Step: 5
Training loss: 2.475302390689672
Validation loss: 2.444330501518806

Epoch: 6| Step: 6
Training loss: 2.4705410990906715
Validation loss: 2.451635652293813

Epoch: 6| Step: 7
Training loss: 2.3907650177286595
Validation loss: 2.461673130368196

Epoch: 6| Step: 8
Training loss: 2.9687442177164085
Validation loss: 2.4475723874539237

Epoch: 6| Step: 9
Training loss: 2.6112799172812715
Validation loss: 2.4182664359061192

Epoch: 6| Step: 10
Training loss: 2.8846259473949614
Validation loss: 2.4054621245749686

Epoch: 6| Step: 11
Training loss: 1.8733996873464576
Validation loss: 2.4514230164551996

Epoch: 6| Step: 12
Training loss: 2.6979251306663703
Validation loss: 2.4435479281289094

Epoch: 6| Step: 13
Training loss: 2.6786675917302776
Validation loss: 2.403967837469832

Epoch: 140| Step: 0
Training loss: 2.5927301263155123
Validation loss: 2.415015789365836

Epoch: 6| Step: 1
Training loss: 2.7362056162908486
Validation loss: 2.4214295092986666

Epoch: 6| Step: 2
Training loss: 2.3451447469452193
Validation loss: 2.4500984105998485

Epoch: 6| Step: 3
Training loss: 2.653514934951331
Validation loss: 2.441542144865387

Epoch: 6| Step: 4
Training loss: 2.2425509168273057
Validation loss: 2.424278974184721

Epoch: 6| Step: 5
Training loss: 2.4011675180371137
Validation loss: 2.4450242208983983

Epoch: 6| Step: 6
Training loss: 2.3198967249673337
Validation loss: 2.431410203402638

Epoch: 6| Step: 7
Training loss: 2.4802793896101507
Validation loss: 2.441256866019488

Epoch: 6| Step: 8
Training loss: 2.038931773003545
Validation loss: 2.446538989830937

Epoch: 6| Step: 9
Training loss: 2.590784238700047
Validation loss: 2.445048959398181

Epoch: 6| Step: 10
Training loss: 3.374390582412377
Validation loss: 2.444645350025633

Epoch: 6| Step: 11
Training loss: 1.9393528723184317
Validation loss: 2.4157136056912045

Epoch: 6| Step: 12
Training loss: 2.3153552393727765
Validation loss: 2.4436150364108555

Epoch: 6| Step: 13
Training loss: 1.8620399803065153
Validation loss: 2.4350359051810093

Epoch: 141| Step: 0
Training loss: 2.7338558903172303
Validation loss: 2.4324400933954107

Epoch: 6| Step: 1
Training loss: 2.6887176771362533
Validation loss: 2.4356085730349295

Epoch: 6| Step: 2
Training loss: 2.2504630142220394
Validation loss: 2.4283091089420403

Epoch: 6| Step: 3
Training loss: 2.4284959428740382
Validation loss: 2.4423692940544273

Epoch: 6| Step: 4
Training loss: 3.2237613517144252
Validation loss: 2.442583956010516

Epoch: 6| Step: 5
Training loss: 1.6241948994348239
Validation loss: 2.437125569274827

Epoch: 6| Step: 6
Training loss: 2.8393335946733735
Validation loss: 2.4290043364005167

Epoch: 6| Step: 7
Training loss: 1.8821521408253317
Validation loss: 2.4639232705640306

Epoch: 6| Step: 8
Training loss: 2.1842544456909105
Validation loss: 2.4625898573118628

Epoch: 6| Step: 9
Training loss: 2.8678325374452376
Validation loss: 2.4696091984042745

Epoch: 6| Step: 10
Training loss: 2.1753347818827895
Validation loss: 2.4565201310910054

Epoch: 6| Step: 11
Training loss: 2.3552295569692836
Validation loss: 2.4590282726718162

Epoch: 6| Step: 12
Training loss: 2.2482007568083904
Validation loss: 2.4262255464756333

Epoch: 6| Step: 13
Training loss: 2.7588283839841528
Validation loss: 2.4468693423456895

Epoch: 142| Step: 0
Training loss: 2.683064371059794
Validation loss: 2.446699557177053

Epoch: 6| Step: 1
Training loss: 1.7059164706371939
Validation loss: 2.42011128225246

Epoch: 6| Step: 2
Training loss: 3.019003917053451
Validation loss: 2.4542342975588545

Epoch: 6| Step: 3
Training loss: 1.7075297939220118
Validation loss: 2.455313781517345

Epoch: 6| Step: 4
Training loss: 2.5738456583055482
Validation loss: 2.4383404021571087

Epoch: 6| Step: 5
Training loss: 2.019383083788962
Validation loss: 2.4714975313635357

Epoch: 6| Step: 6
Training loss: 2.0452047041309376
Validation loss: 2.440547536734857

Epoch: 6| Step: 7
Training loss: 2.4716800733405466
Validation loss: 2.469164685641928

Epoch: 6| Step: 8
Training loss: 2.15059207038535
Validation loss: 2.4257055152570355

Epoch: 6| Step: 9
Training loss: 2.7431020923213385
Validation loss: 2.457004457698049

Epoch: 6| Step: 10
Training loss: 2.3116366862704707
Validation loss: 2.439691353144721

Epoch: 6| Step: 11
Training loss: 2.8992290392821323
Validation loss: 2.4723923982430267

Epoch: 6| Step: 12
Training loss: 2.5869077032233556
Validation loss: 2.4309416035907323

Epoch: 6| Step: 13
Training loss: 3.0778689205325134
Validation loss: 2.459154233559096

Epoch: 143| Step: 0
Training loss: 2.7919196019005565
Validation loss: 2.4528109514898606

Epoch: 6| Step: 1
Training loss: 2.9441712290684143
Validation loss: 2.4147176761788818

Epoch: 6| Step: 2
Training loss: 1.8399205930824507
Validation loss: 2.4531128549102075

Epoch: 6| Step: 3
Training loss: 2.8121154522263825
Validation loss: 2.419829559068333

Epoch: 6| Step: 4
Training loss: 2.4409409712890198
Validation loss: 2.429167824703761

Epoch: 6| Step: 5
Training loss: 2.3290310319181966
Validation loss: 2.4287158943863685

Epoch: 6| Step: 6
Training loss: 2.269570328971855
Validation loss: 2.4567763054139906

Epoch: 6| Step: 7
Training loss: 2.2135659489515254
Validation loss: 2.438980147459205

Epoch: 6| Step: 8
Training loss: 1.9557675604643245
Validation loss: 2.4338756158323704

Epoch: 6| Step: 9
Training loss: 2.5455998698154803
Validation loss: 2.472859282650707

Epoch: 6| Step: 10
Training loss: 3.0156422352668906
Validation loss: 2.446184367930626

Epoch: 6| Step: 11
Training loss: 1.9192559609598219
Validation loss: 2.4401497806357675

Epoch: 6| Step: 12
Training loss: 2.8832838712062343
Validation loss: 2.44871851020371

Epoch: 6| Step: 13
Training loss: 1.6423520398667926
Validation loss: 2.424522089616513

Epoch: 144| Step: 0
Training loss: 2.295688244711537
Validation loss: 2.4432432993165505

Epoch: 6| Step: 1
Training loss: 2.1338978894587997
Validation loss: 2.424121255619316

Epoch: 6| Step: 2
Training loss: 2.426959502590757
Validation loss: 2.449320584095455

Epoch: 6| Step: 3
Training loss: 2.85939200974705
Validation loss: 2.448065772366752

Epoch: 6| Step: 4
Training loss: 2.582755075359813
Validation loss: 2.444869692402805

Epoch: 6| Step: 5
Training loss: 2.9270377014150966
Validation loss: 2.449221607537675

Epoch: 6| Step: 6
Training loss: 1.5809182855720685
Validation loss: 2.447553006408217

Epoch: 6| Step: 7
Training loss: 2.5510448185278314
Validation loss: 2.433414520904555

Epoch: 6| Step: 8
Training loss: 2.395989078490469
Validation loss: 2.450261129150386

Epoch: 6| Step: 9
Training loss: 2.2560589062190015
Validation loss: 2.418148578454241

Epoch: 6| Step: 10
Training loss: 2.4298914980114144
Validation loss: 2.448417246020465

Epoch: 6| Step: 11
Training loss: 3.178732238791915
Validation loss: 2.446673635628386

Epoch: 6| Step: 12
Training loss: 2.2491860506914496
Validation loss: 2.477323244008383

Epoch: 6| Step: 13
Training loss: 1.7869995750507859
Validation loss: 2.4357309245327805

Epoch: 145| Step: 0
Training loss: 3.15228021834214
Validation loss: 2.453558247185285

Epoch: 6| Step: 1
Training loss: 2.781136071089789
Validation loss: 2.4287542449971666

Epoch: 6| Step: 2
Training loss: 2.1362527342589654
Validation loss: 2.419727573514732

Epoch: 6| Step: 3
Training loss: 2.633213454145481
Validation loss: 2.419036421177248

Epoch: 6| Step: 4
Training loss: 2.2968443784164676
Validation loss: 2.4248138443816796

Epoch: 6| Step: 5
Training loss: 2.2066556087612517
Validation loss: 2.437715943107714

Epoch: 6| Step: 6
Training loss: 2.0947783492651553
Validation loss: 2.450031066063045

Epoch: 6| Step: 7
Training loss: 1.8604292245108554
Validation loss: 2.4352713083451913

Epoch: 6| Step: 8
Training loss: 2.5546018253624223
Validation loss: 2.4084323489563784

Epoch: 6| Step: 9
Training loss: 1.8244231475090948
Validation loss: 2.4559238911534576

Epoch: 6| Step: 10
Training loss: 2.803529548158657
Validation loss: 2.4345906651013745

Epoch: 6| Step: 11
Training loss: 2.2343158847484736
Validation loss: 2.437131759766679

Epoch: 6| Step: 12
Training loss: 2.9754824143051755
Validation loss: 2.4174938660306164

Epoch: 6| Step: 13
Training loss: 1.6672182203642616
Validation loss: 2.4514340472811327

Epoch: 146| Step: 0
Training loss: 2.811675056696752
Validation loss: 2.436551270961052

Epoch: 6| Step: 1
Training loss: 2.6983415031034537
Validation loss: 2.431341255184238

Epoch: 6| Step: 2
Training loss: 2.821946788056356
Validation loss: 2.4333540968094076

Epoch: 6| Step: 3
Training loss: 2.6291015915190177
Validation loss: 2.4466202377766297

Epoch: 6| Step: 4
Training loss: 2.2993200872800488
Validation loss: 2.439876492762014

Epoch: 6| Step: 5
Training loss: 3.217140758410149
Validation loss: 2.4501769645053404

Epoch: 6| Step: 6
Training loss: 2.1371339049454146
Validation loss: 2.4576509900766284

Epoch: 6| Step: 7
Training loss: 1.6804393416367072
Validation loss: 2.432997580013177

Epoch: 6| Step: 8
Training loss: 2.072514237744947
Validation loss: 2.420286508578697

Epoch: 6| Step: 9
Training loss: 2.2563126277949435
Validation loss: 2.4233208602674776

Epoch: 6| Step: 10
Training loss: 3.1471776216344542
Validation loss: 2.424660265126271

Epoch: 6| Step: 11
Training loss: 1.6939704610778048
Validation loss: 2.419001771500152

Epoch: 6| Step: 12
Training loss: 2.0489663658378974
Validation loss: 2.434861814006695

Epoch: 6| Step: 13
Training loss: 1.298234433890877
Validation loss: 2.428419504198851

Epoch: 147| Step: 0
Training loss: 2.351553679288118
Validation loss: 2.4354557808085517

Epoch: 6| Step: 1
Training loss: 3.163060008287518
Validation loss: 2.4242359076922284

Epoch: 6| Step: 2
Training loss: 2.618407645414422
Validation loss: 2.4063629253872576

Epoch: 6| Step: 3
Training loss: 2.2582318929526775
Validation loss: 2.41803292475198

Epoch: 6| Step: 4
Training loss: 2.2952714369744744
Validation loss: 2.421958492664524

Epoch: 6| Step: 5
Training loss: 2.3130750198963406
Validation loss: 2.438457987552035

Epoch: 6| Step: 6
Training loss: 2.5717616300752857
Validation loss: 2.412415103735219

Epoch: 6| Step: 7
Training loss: 2.2766019944723213
Validation loss: 2.4419008004644183

Epoch: 6| Step: 8
Training loss: 2.144810614950683
Validation loss: 2.428838356667244

Epoch: 6| Step: 9
Training loss: 1.9433263727960968
Validation loss: 2.417332678037128

Epoch: 6| Step: 10
Training loss: 2.3861952486945777
Validation loss: 2.4407441264439615

Epoch: 6| Step: 11
Training loss: 2.3633815271210055
Validation loss: 2.4293731991573773

Epoch: 6| Step: 12
Training loss: 2.8275634039423783
Validation loss: 2.4353221801471605

Epoch: 6| Step: 13
Training loss: 2.0431754188232936
Validation loss: 2.4210921266985657

Epoch: 148| Step: 0
Training loss: 1.9873157247850748
Validation loss: 2.4404149049965462

Epoch: 6| Step: 1
Training loss: 2.7065495314252703
Validation loss: 2.4594748947037375

Epoch: 6| Step: 2
Training loss: 2.6956340211027014
Validation loss: 2.420030772527855

Epoch: 6| Step: 3
Training loss: 2.8063922259815723
Validation loss: 2.4567938042877944

Epoch: 6| Step: 4
Training loss: 2.2901128761091765
Validation loss: 2.446346369089249

Epoch: 6| Step: 5
Training loss: 2.1345815622844966
Validation loss: 2.42861804678716

Epoch: 6| Step: 6
Training loss: 2.892005879260322
Validation loss: 2.4461306565151046

Epoch: 6| Step: 7
Training loss: 1.7625152749556254
Validation loss: 2.4346468844877305

Epoch: 6| Step: 8
Training loss: 2.0421199165725086
Validation loss: 2.453366559996496

Epoch: 6| Step: 9
Training loss: 2.2335728626001763
Validation loss: 2.42342406770502

Epoch: 6| Step: 10
Training loss: 2.0905142305734206
Validation loss: 2.441237043132514

Epoch: 6| Step: 11
Training loss: 2.966723262232737
Validation loss: 2.4360524168395328

Epoch: 6| Step: 12
Training loss: 2.5055916242500906
Validation loss: 2.4324416205508483

Epoch: 6| Step: 13
Training loss: 2.36156084477315
Validation loss: 2.4326293722115717

Epoch: 149| Step: 0
Training loss: 2.67351334518318
Validation loss: 2.4281745217100315

Epoch: 6| Step: 1
Training loss: 1.7657525345644907
Validation loss: 2.4324325029233105

Epoch: 6| Step: 2
Training loss: 2.5741933725868797
Validation loss: 2.4266370834605935

Epoch: 6| Step: 3
Training loss: 1.992179302123911
Validation loss: 2.4035682938133935

Epoch: 6| Step: 4
Training loss: 2.4754591930079477
Validation loss: 2.415037302479722

Epoch: 6| Step: 5
Training loss: 3.214683704865326
Validation loss: 2.4363710677739467

Epoch: 6| Step: 6
Training loss: 2.946110220220469
Validation loss: 2.4062133858724666

Epoch: 6| Step: 7
Training loss: 2.431547967455277
Validation loss: 2.4445350708791342

Epoch: 6| Step: 8
Training loss: 2.810179961472759
Validation loss: 2.431810326174577

Epoch: 6| Step: 9
Training loss: 2.3066050682589703
Validation loss: 2.4135399898853374

Epoch: 6| Step: 10
Training loss: 2.0923758025324797
Validation loss: 2.429230362277229

Epoch: 6| Step: 11
Training loss: 1.8887264713258345
Validation loss: 2.4274332518774773

Epoch: 6| Step: 12
Training loss: 2.346294090413586
Validation loss: 2.3956263455882834

Epoch: 6| Step: 13
Training loss: 1.9303771728629868
Validation loss: 2.4237861981023476

Epoch: 150| Step: 0
Training loss: 2.2671445814890685
Validation loss: 2.4291063451262978

Epoch: 6| Step: 1
Training loss: 2.297537156760329
Validation loss: 2.430710359517908

Epoch: 6| Step: 2
Training loss: 2.420816694805419
Validation loss: 2.4082228416236746

Epoch: 6| Step: 3
Training loss: 2.737642091172685
Validation loss: 2.426354253119253

Epoch: 6| Step: 4
Training loss: 2.616816890154273
Validation loss: 2.4186508518332874

Epoch: 6| Step: 5
Training loss: 1.7425083839948192
Validation loss: 2.3960153301036264

Epoch: 6| Step: 6
Training loss: 2.492877541800946
Validation loss: 2.4201007749642818

Epoch: 6| Step: 7
Training loss: 2.7841741213279594
Validation loss: 2.4491030242496543

Epoch: 6| Step: 8
Training loss: 3.2346300402352637
Validation loss: 2.4439501258697267

Epoch: 6| Step: 9
Training loss: 1.910185831227045
Validation loss: 2.448528935495388

Epoch: 6| Step: 10
Training loss: 2.5736413056227017
Validation loss: 2.4458928668883955

Epoch: 6| Step: 11
Training loss: 2.290702883032573
Validation loss: 2.4336750277209998

Epoch: 6| Step: 12
Training loss: 2.127790750254281
Validation loss: 2.4560052232000347

Epoch: 6| Step: 13
Training loss: 1.9894683831313449
Validation loss: 2.4329182359121546

Epoch: 151| Step: 0
Training loss: 2.3580340686436823
Validation loss: 2.430969826297656

Epoch: 6| Step: 1
Training loss: 2.6312616234746886
Validation loss: 2.446159245807355

Epoch: 6| Step: 2
Training loss: 1.968858746144087
Validation loss: 2.4415624593003193

Epoch: 6| Step: 3
Training loss: 3.114876485613817
Validation loss: 2.4256529901369146

Epoch: 6| Step: 4
Training loss: 2.6707871213377645
Validation loss: 2.460917747614916

Epoch: 6| Step: 5
Training loss: 2.929876621499942
Validation loss: 2.4439339779074984

Epoch: 6| Step: 6
Training loss: 1.9193249664194938
Validation loss: 2.415213798104164

Epoch: 6| Step: 7
Training loss: 2.2845259881381335
Validation loss: 2.4267597457215477

Epoch: 6| Step: 8
Training loss: 2.750097793227443
Validation loss: 2.433303290271707

Epoch: 6| Step: 9
Training loss: 2.2017783520093372
Validation loss: 2.4279979556488076

Epoch: 6| Step: 10
Training loss: 1.5429279563436515
Validation loss: 2.4700370954743978

Epoch: 6| Step: 11
Training loss: 2.1044727014759124
Validation loss: 2.427400646322272

Epoch: 6| Step: 12
Training loss: 2.430467584622581
Validation loss: 2.396103278134059

Epoch: 6| Step: 13
Training loss: 2.435539141583803
Validation loss: 2.431800796617653

Epoch: 152| Step: 0
Training loss: 1.7105576603060089
Validation loss: 2.436314702976075

Epoch: 6| Step: 1
Training loss: 2.500090215962548
Validation loss: 2.4256043205397835

Epoch: 6| Step: 2
Training loss: 2.452836912696824
Validation loss: 2.4186941099852044

Epoch: 6| Step: 3
Training loss: 2.0433937345520903
Validation loss: 2.4104010621393206

Epoch: 6| Step: 4
Training loss: 2.2749892769026347
Validation loss: 2.3961731696882453

Epoch: 6| Step: 5
Training loss: 3.02788695353399
Validation loss: 2.4201317241414717

Epoch: 6| Step: 6
Training loss: 3.201648948920925
Validation loss: 2.448042930500717

Epoch: 6| Step: 7
Training loss: 2.4267582054828654
Validation loss: 2.4346386227727845

Epoch: 6| Step: 8
Training loss: 1.9425884615517461
Validation loss: 2.423825537907179

Epoch: 6| Step: 9
Training loss: 2.278234709935455
Validation loss: 2.4226840993508545

Epoch: 6| Step: 10
Training loss: 2.0672114341313326
Validation loss: 2.426222695666273

Epoch: 6| Step: 11
Training loss: 1.8109534670213912
Validation loss: 2.400500225398324

Epoch: 6| Step: 12
Training loss: 2.674653866914426
Validation loss: 2.414781780738128

Epoch: 6| Step: 13
Training loss: 2.7053428768229653
Validation loss: 2.393485539939953

Epoch: 153| Step: 0
Training loss: 2.37920379030712
Validation loss: 2.428691310410645

Epoch: 6| Step: 1
Training loss: 2.51826916215465
Validation loss: 2.4168712146093094

Epoch: 6| Step: 2
Training loss: 2.8304113767085815
Validation loss: 2.4366739544081155

Epoch: 6| Step: 3
Training loss: 2.4888095264989434
Validation loss: 2.4151566837224854

Epoch: 6| Step: 4
Training loss: 1.9811263036772355
Validation loss: 2.4105072412097033

Epoch: 6| Step: 5
Training loss: 2.075120288165885
Validation loss: 2.398130375227309

Epoch: 6| Step: 6
Training loss: 2.508528277488121
Validation loss: 2.4179010916033796

Epoch: 6| Step: 7
Training loss: 2.7478896626805454
Validation loss: 2.4040575015015606

Epoch: 6| Step: 8
Training loss: 2.287957351073667
Validation loss: 2.4374785063421474

Epoch: 6| Step: 9
Training loss: 1.9592524732034058
Validation loss: 2.4321126465975165

Epoch: 6| Step: 10
Training loss: 1.781319934743661
Validation loss: 2.4543562396801857

Epoch: 6| Step: 11
Training loss: 3.061275003626291
Validation loss: 2.412246708827422

Epoch: 6| Step: 12
Training loss: 2.16522538102216
Validation loss: 2.415030881791735

Epoch: 6| Step: 13
Training loss: 2.768578972281057
Validation loss: 2.3913529539929983

Epoch: 154| Step: 0
Training loss: 2.7740020607168496
Validation loss: 2.417654789845924

Epoch: 6| Step: 1
Training loss: 1.839483140727678
Validation loss: 2.4084212702008903

Epoch: 6| Step: 2
Training loss: 2.032538137605972
Validation loss: 2.426749929588325

Epoch: 6| Step: 3
Training loss: 2.3680378107454527
Validation loss: 2.4411776984754954

Epoch: 6| Step: 4
Training loss: 2.5351780683286855
Validation loss: 2.4130298383567537

Epoch: 6| Step: 5
Training loss: 2.896890643920138
Validation loss: 2.414618416734576

Epoch: 6| Step: 6
Training loss: 2.0532797280452466
Validation loss: 2.4553058057376878

Epoch: 6| Step: 7
Training loss: 2.805513818092561
Validation loss: 2.445526507876705

Epoch: 6| Step: 8
Training loss: 2.589457257230543
Validation loss: 2.4201892036152755

Epoch: 6| Step: 9
Training loss: 1.8714837482143205
Validation loss: 2.4226775830575136

Epoch: 6| Step: 10
Training loss: 2.1842009599194365
Validation loss: 2.4424803385359533

Epoch: 6| Step: 11
Training loss: 2.9509740999249274
Validation loss: 2.4226263409740114

Epoch: 6| Step: 12
Training loss: 1.7764003387763514
Validation loss: 2.4317924013627996

Epoch: 6| Step: 13
Training loss: 2.6597797950863544
Validation loss: 2.4067909214444314

Epoch: 155| Step: 0
Training loss: 2.265904271244236
Validation loss: 2.408166140293034

Epoch: 6| Step: 1
Training loss: 2.2779245045035563
Validation loss: 2.4292316919931616

Epoch: 6| Step: 2
Training loss: 2.462449157499802
Validation loss: 2.4260367919958568

Epoch: 6| Step: 3
Training loss: 2.0020324393587203
Validation loss: 2.4272934376731725

Epoch: 6| Step: 4
Training loss: 3.1826562917109023
Validation loss: 2.420186736567627

Epoch: 6| Step: 5
Training loss: 2.1905068576533866
Validation loss: 2.4105403789021866

Epoch: 6| Step: 6
Training loss: 2.5861230881583563
Validation loss: 2.430952429961929

Epoch: 6| Step: 7
Training loss: 2.265094668702572
Validation loss: 2.4122379670746903

Epoch: 6| Step: 8
Training loss: 2.277851656617626
Validation loss: 2.4427507155755315

Epoch: 6| Step: 9
Training loss: 2.659530409184202
Validation loss: 2.4366169190443503

Epoch: 6| Step: 10
Training loss: 1.993892523475656
Validation loss: 2.421897679016649

Epoch: 6| Step: 11
Training loss: 2.245783033025898
Validation loss: 2.4103895287119594

Epoch: 6| Step: 12
Training loss: 2.3014077853885904
Validation loss: 2.4126293169179767

Epoch: 6| Step: 13
Training loss: 2.7573974988740515
Validation loss: 2.4029645407001206

Epoch: 156| Step: 0
Training loss: 2.6568893560731954
Validation loss: 2.4199855223042714

Epoch: 6| Step: 1
Training loss: 2.405032754147633
Validation loss: 2.4145471261852003

Epoch: 6| Step: 2
Training loss: 2.443461244504106
Validation loss: 2.405794962301053

Epoch: 6| Step: 3
Training loss: 2.490785018777338
Validation loss: 2.419305677666468

Epoch: 6| Step: 4
Training loss: 1.745301478666172
Validation loss: 2.41121534598692

Epoch: 6| Step: 5
Training loss: 2.423491498393515
Validation loss: 2.41532746239406

Epoch: 6| Step: 6
Training loss: 2.521953890676191
Validation loss: 2.4332593372937157

Epoch: 6| Step: 7
Training loss: 1.5221599210317267
Validation loss: 2.435494574228765

Epoch: 6| Step: 8
Training loss: 3.2037396097182183
Validation loss: 2.4077523693585188

Epoch: 6| Step: 9
Training loss: 2.049315417355164
Validation loss: 2.457544795428291

Epoch: 6| Step: 10
Training loss: 2.592992832937461
Validation loss: 2.4002889184110767

Epoch: 6| Step: 11
Training loss: 2.798280160507424
Validation loss: 2.4173163830225914

Epoch: 6| Step: 12
Training loss: 1.9416961760454647
Validation loss: 2.4084855620378622

Epoch: 6| Step: 13
Training loss: 2.080661688240807
Validation loss: 2.428236775527025

Epoch: 157| Step: 0
Training loss: 2.2995721460526353
Validation loss: 2.4166140181082687

Epoch: 6| Step: 1
Training loss: 1.9350784920635073
Validation loss: 2.3965102574763772

Epoch: 6| Step: 2
Training loss: 2.1335019963865056
Validation loss: 2.4149099077864253

Epoch: 6| Step: 3
Training loss: 2.668983009761674
Validation loss: 2.431064355531442

Epoch: 6| Step: 4
Training loss: 2.2405584179124562
Validation loss: 2.411228442635313

Epoch: 6| Step: 5
Training loss: 2.7681335451843014
Validation loss: 2.4319873628328486

Epoch: 6| Step: 6
Training loss: 2.7880898711114983
Validation loss: 2.4204990083741684

Epoch: 6| Step: 7
Training loss: 2.7096286219386867
Validation loss: 2.392145454975657

Epoch: 6| Step: 8
Training loss: 2.4668676225751494
Validation loss: 2.4125474555659103

Epoch: 6| Step: 9
Training loss: 1.7364596648536281
Validation loss: 2.428844191468219

Epoch: 6| Step: 10
Training loss: 2.507173545938359
Validation loss: 2.409869185461258

Epoch: 6| Step: 11
Training loss: 2.0629837162486475
Validation loss: 2.4594768412968913

Epoch: 6| Step: 12
Training loss: 2.2756805366207793
Validation loss: 2.3980601579969067

Epoch: 6| Step: 13
Training loss: 2.614741397857011
Validation loss: 2.4355798777907567

Epoch: 158| Step: 0
Training loss: 3.1506035786577584
Validation loss: 2.404580019270803

Epoch: 6| Step: 1
Training loss: 2.780618488752579
Validation loss: 2.4483358655664733

Epoch: 6| Step: 2
Training loss: 2.3110780210245383
Validation loss: 2.4337946481752857

Epoch: 6| Step: 3
Training loss: 2.632486476012122
Validation loss: 2.409421538782694

Epoch: 6| Step: 4
Training loss: 2.008030029862621
Validation loss: 2.4131378804211407

Epoch: 6| Step: 5
Training loss: 2.0327681516813447
Validation loss: 2.42674707516934

Epoch: 6| Step: 6
Training loss: 2.6507935073708557
Validation loss: 2.4224162851458466

Epoch: 6| Step: 7
Training loss: 2.5533064629491293
Validation loss: 2.41081588317475

Epoch: 6| Step: 8
Training loss: 2.495427718873474
Validation loss: 2.4195008591028286

Epoch: 6| Step: 9
Training loss: 1.7570234774311186
Validation loss: 2.4096850410587494

Epoch: 6| Step: 10
Training loss: 2.2031827878474997
Validation loss: 2.4183910672402162

Epoch: 6| Step: 11
Training loss: 1.8983051897574539
Validation loss: 2.403000758920057

Epoch: 6| Step: 12
Training loss: 2.192541905941107
Validation loss: 2.4205520282036406

Epoch: 6| Step: 13
Training loss: 2.269875058840323
Validation loss: 2.411310991986152

Epoch: 159| Step: 0
Training loss: 2.5268702350866854
Validation loss: 2.4212412840978628

Epoch: 6| Step: 1
Training loss: 2.2134813966212765
Validation loss: 2.415504881398394

Epoch: 6| Step: 2
Training loss: 2.87291326672466
Validation loss: 2.432757951870449

Epoch: 6| Step: 3
Training loss: 2.829123979189322
Validation loss: 2.3944959480820205

Epoch: 6| Step: 4
Training loss: 1.9133689402325242
Validation loss: 2.4150632366414886

Epoch: 6| Step: 5
Training loss: 2.064073598111368
Validation loss: 2.408896634238309

Epoch: 6| Step: 6
Training loss: 2.842508904569798
Validation loss: 2.427779944363288

Epoch: 6| Step: 7
Training loss: 2.504858921821986
Validation loss: 2.408877030352525

Epoch: 6| Step: 8
Training loss: 2.0554296509385273
Validation loss: 2.4239761791078838

Epoch: 6| Step: 9
Training loss: 2.3110681173205405
Validation loss: 2.397317446120507

Epoch: 6| Step: 10
Training loss: 2.343027639332656
Validation loss: 2.4149435588464696

Epoch: 6| Step: 11
Training loss: 2.1211868181412155
Validation loss: 2.4344283397377113

Epoch: 6| Step: 12
Training loss: 2.1996331645998097
Validation loss: 2.4386516634352993

Epoch: 6| Step: 13
Training loss: 2.2527337950230635
Validation loss: 2.4093931392127685

Epoch: 160| Step: 0
Training loss: 2.4150549567625474
Validation loss: 2.4014236615767937

Epoch: 6| Step: 1
Training loss: 2.225119675407427
Validation loss: 2.396188849938193

Epoch: 6| Step: 2
Training loss: 2.459337471235763
Validation loss: 2.395638970993148

Epoch: 6| Step: 3
Training loss: 2.6322201931338496
Validation loss: 2.3908053566087832

Epoch: 6| Step: 4
Training loss: 2.1117550456222856
Validation loss: 2.425855837866114

Epoch: 6| Step: 5
Training loss: 2.3840746929193424
Validation loss: 2.406789714074334

Epoch: 6| Step: 6
Training loss: 2.4576153326281447
Validation loss: 2.442977982397062

Epoch: 6| Step: 7
Training loss: 1.93580922832526
Validation loss: 2.390476967254216

Epoch: 6| Step: 8
Training loss: 2.9534298371104697
Validation loss: 2.4178246731791306

Epoch: 6| Step: 9
Training loss: 2.7866990790543116
Validation loss: 2.4057388615108106

Epoch: 6| Step: 10
Training loss: 2.26726730279843
Validation loss: 2.4419525566947744

Epoch: 6| Step: 11
Training loss: 1.9299880191450876
Validation loss: 2.4201634589118006

Epoch: 6| Step: 12
Training loss: 2.2027721798881648
Validation loss: 2.422810555674272

Epoch: 6| Step: 13
Training loss: 1.8177852523254163
Validation loss: 2.3932704332593016

Epoch: 161| Step: 0
Training loss: 2.2137592762214777
Validation loss: 2.4213257779819415

Epoch: 6| Step: 1
Training loss: 2.2696184414054867
Validation loss: 2.4081931108042083

Epoch: 6| Step: 2
Training loss: 2.772065674976745
Validation loss: 2.4073323251606022

Epoch: 6| Step: 3
Training loss: 2.573091714646966
Validation loss: 2.417209508760294

Epoch: 6| Step: 4
Training loss: 2.2230066650057334
Validation loss: 2.42132568904479

Epoch: 6| Step: 5
Training loss: 2.276457573247125
Validation loss: 2.425001832986504

Epoch: 6| Step: 6
Training loss: 2.2139077874875013
Validation loss: 2.400005271095722

Epoch: 6| Step: 7
Training loss: 3.1375617275776984
Validation loss: 2.3968711987656857

Epoch: 6| Step: 8
Training loss: 2.358455251321371
Validation loss: 2.4012660021692134

Epoch: 6| Step: 9
Training loss: 2.094237541257301
Validation loss: 2.407347334238536

Epoch: 6| Step: 10
Training loss: 2.4394131512875306
Validation loss: 2.4295174147081093

Epoch: 6| Step: 11
Training loss: 2.661075293243052
Validation loss: 2.412956322324379

Epoch: 6| Step: 12
Training loss: 1.4679172671285514
Validation loss: 2.4118732077881537

Epoch: 6| Step: 13
Training loss: 2.0177931841758325
Validation loss: 2.4022754338332932

Epoch: 162| Step: 0
Training loss: 2.521702030872665
Validation loss: 2.391559950170002

Epoch: 6| Step: 1
Training loss: 2.3816417381880908
Validation loss: 2.3748774062393307

Epoch: 6| Step: 2
Training loss: 1.9486767582957785
Validation loss: 2.3826099559140235

Epoch: 6| Step: 3
Training loss: 2.4785011958430463
Validation loss: 2.4285915385039543

Epoch: 6| Step: 4
Training loss: 2.3814374114050736
Validation loss: 2.3942165742447563

Epoch: 6| Step: 5
Training loss: 2.0753227212726264
Validation loss: 2.4176820680510565

Epoch: 6| Step: 6
Training loss: 2.832441376553331
Validation loss: 2.40855411504394

Epoch: 6| Step: 7
Training loss: 2.1023977668936147
Validation loss: 2.4230076084234278

Epoch: 6| Step: 8
Training loss: 2.7046599688084636
Validation loss: 2.39784881078692

Epoch: 6| Step: 9
Training loss: 1.5709566531693626
Validation loss: 2.398687262753037

Epoch: 6| Step: 10
Training loss: 2.3856084710403778
Validation loss: 2.411821179167864

Epoch: 6| Step: 11
Training loss: 2.5817971635627224
Validation loss: 2.38240028929791

Epoch: 6| Step: 12
Training loss: 2.436079932080604
Validation loss: 2.401421428260454

Epoch: 6| Step: 13
Training loss: 2.1257033586514216
Validation loss: 2.4186379914675586

Epoch: 163| Step: 0
Training loss: 3.338984007352383
Validation loss: 2.4159183687381756

Epoch: 6| Step: 1
Training loss: 2.080727002298298
Validation loss: 2.4219382561961553

Epoch: 6| Step: 2
Training loss: 2.2141010849093536
Validation loss: 2.414518809199405

Epoch: 6| Step: 3
Training loss: 1.8484670138481751
Validation loss: 2.3827546745934756

Epoch: 6| Step: 4
Training loss: 2.3941112355304757
Validation loss: 2.408222805163306

Epoch: 6| Step: 5
Training loss: 2.850371647745858
Validation loss: 2.435105361508612

Epoch: 6| Step: 6
Training loss: 2.2606465329723253
Validation loss: 2.410844956649274

Epoch: 6| Step: 7
Training loss: 2.4084075568706087
Validation loss: 2.4249488190016812

Epoch: 6| Step: 8
Training loss: 1.7510389922161507
Validation loss: 2.3909367376786745

Epoch: 6| Step: 9
Training loss: 2.723510958304086
Validation loss: 2.38838519717772

Epoch: 6| Step: 10
Training loss: 1.6511462767119118
Validation loss: 2.4043331781764774

Epoch: 6| Step: 11
Training loss: 2.422341578670292
Validation loss: 2.365947047353755

Epoch: 6| Step: 12
Training loss: 1.9286352215161708
Validation loss: 2.409190869178736

Epoch: 6| Step: 13
Training loss: 2.399346691857909
Validation loss: 2.3986756029981695

Epoch: 164| Step: 0
Training loss: 1.9904722122173053
Validation loss: 2.427237143024864

Epoch: 6| Step: 1
Training loss: 2.7429819722238546
Validation loss: 2.3834316719426307

Epoch: 6| Step: 2
Training loss: 2.4728261398118585
Validation loss: 2.3604792945927295

Epoch: 6| Step: 3
Training loss: 2.1660822177897248
Validation loss: 2.4198409224905166

Epoch: 6| Step: 4
Training loss: 2.228484278064754
Validation loss: 2.389689377754786

Epoch: 6| Step: 5
Training loss: 2.5946549824585206
Validation loss: 2.3866867391697566

Epoch: 6| Step: 6
Training loss: 2.439578808249021
Validation loss: 2.365044267043237

Epoch: 6| Step: 7
Training loss: 2.989869816220154
Validation loss: 2.4017851026497214

Epoch: 6| Step: 8
Training loss: 2.399364279951357
Validation loss: 2.4016372262004877

Epoch: 6| Step: 9
Training loss: 1.9079807116735128
Validation loss: 2.376131449917048

Epoch: 6| Step: 10
Training loss: 2.4203184971202534
Validation loss: 2.412533915521105

Epoch: 6| Step: 11
Training loss: 2.2376620782723395
Validation loss: 2.438772027917739

Epoch: 6| Step: 12
Training loss: 1.8867681587652523
Validation loss: 2.3782626519270105

Epoch: 6| Step: 13
Training loss: 2.1991515344135513
Validation loss: 2.3900218365990145

Epoch: 165| Step: 0
Training loss: 1.9834890114835897
Validation loss: 2.394868513230657

Epoch: 6| Step: 1
Training loss: 2.069038661398293
Validation loss: 2.3839008236388852

Epoch: 6| Step: 2
Training loss: 2.444652529250227
Validation loss: 2.3669625219408075

Epoch: 6| Step: 3
Training loss: 2.6456159567458726
Validation loss: 2.410624392825175

Epoch: 6| Step: 4
Training loss: 2.122972194056498
Validation loss: 2.398401397254855

Epoch: 6| Step: 5
Training loss: 1.528745822354938
Validation loss: 2.4205730001594348

Epoch: 6| Step: 6
Training loss: 2.9147886133513112
Validation loss: 2.4264704383614766

Epoch: 6| Step: 7
Training loss: 2.2282057738142105
Validation loss: 2.4336646980290166

Epoch: 6| Step: 8
Training loss: 1.6662145319237984
Validation loss: 2.399039859800692

Epoch: 6| Step: 9
Training loss: 2.4030267504386993
Validation loss: 2.406869897684712

Epoch: 6| Step: 10
Training loss: 2.6254818791912133
Validation loss: 2.4033056142876346

Epoch: 6| Step: 11
Training loss: 2.3817715731937392
Validation loss: 2.4075101086747996

Epoch: 6| Step: 12
Training loss: 2.5721879511454966
Validation loss: 2.3784232557279434

Epoch: 6| Step: 13
Training loss: 3.247846476783558
Validation loss: 2.395724012565662

Epoch: 166| Step: 0
Training loss: 2.1371607907273527
Validation loss: 2.4198392613111146

Epoch: 6| Step: 1
Training loss: 1.5519100664273573
Validation loss: 2.4041881317268388

Epoch: 6| Step: 2
Training loss: 2.8228458428501435
Validation loss: 2.4076813413474247

Epoch: 6| Step: 3
Training loss: 2.5990914187760916
Validation loss: 2.4136163363167875

Epoch: 6| Step: 4
Training loss: 2.5443141677169923
Validation loss: 2.421862028671391

Epoch: 6| Step: 5
Training loss: 2.3598239294741665
Validation loss: 2.4207595929464993

Epoch: 6| Step: 6
Training loss: 2.3247592842432727
Validation loss: 2.409815771017173

Epoch: 6| Step: 7
Training loss: 1.7743166454322792
Validation loss: 2.4159349267940726

Epoch: 6| Step: 8
Training loss: 2.033463079450793
Validation loss: 2.4084952226960414

Epoch: 6| Step: 9
Training loss: 2.6765979272353944
Validation loss: 2.368980885824234

Epoch: 6| Step: 10
Training loss: 1.894419684517086
Validation loss: 2.4046021300337097

Epoch: 6| Step: 11
Training loss: 3.036149146084241
Validation loss: 2.379675772317421

Epoch: 6| Step: 12
Training loss: 2.294701202821294
Validation loss: 2.3917721990329834

Epoch: 6| Step: 13
Training loss: 1.7509039179236578
Validation loss: 2.3849659984943594

Epoch: 167| Step: 0
Training loss: 2.705953716595578
Validation loss: 2.3921234294818507

Epoch: 6| Step: 1
Training loss: 2.3503051640837724
Validation loss: 2.385783015336721

Epoch: 6| Step: 2
Training loss: 1.831145440459329
Validation loss: 2.3951869217407262

Epoch: 6| Step: 3
Training loss: 2.5731980842994737
Validation loss: 2.394363886478587

Epoch: 6| Step: 4
Training loss: 2.299037823313245
Validation loss: 2.375566910340739

Epoch: 6| Step: 5
Training loss: 2.4373859476647386
Validation loss: 2.3625800644880184

Epoch: 6| Step: 6
Training loss: 2.608781941341258
Validation loss: 2.417399588786137

Epoch: 6| Step: 7
Training loss: 1.4276680780926756
Validation loss: 2.4217642037316947

Epoch: 6| Step: 8
Training loss: 1.890475369672081
Validation loss: 2.4187682062686813

Epoch: 6| Step: 9
Training loss: 2.497742205570519
Validation loss: 2.4017956078759912

Epoch: 6| Step: 10
Training loss: 1.2618645267892732
Validation loss: 2.3922438384684983

Epoch: 6| Step: 11
Training loss: 2.088189670140197
Validation loss: 2.3876099591928988

Epoch: 6| Step: 12
Training loss: 2.6805359856698794
Validation loss: 2.3786192250920033

Epoch: 6| Step: 13
Training loss: 3.440308134783258
Validation loss: 2.4067270631443645

Epoch: 168| Step: 0
Training loss: 2.173856640788934
Validation loss: 2.3805413897115404

Epoch: 6| Step: 1
Training loss: 2.685586292324361
Validation loss: 2.386106450914445

Epoch: 6| Step: 2
Training loss: 1.9900809725864326
Validation loss: 2.3885026068411075

Epoch: 6| Step: 3
Training loss: 2.4399560145806682
Validation loss: 2.367804851650556

Epoch: 6| Step: 4
Training loss: 2.3644429527881923
Validation loss: 2.3995793579839684

Epoch: 6| Step: 5
Training loss: 2.7777386047991985
Validation loss: 2.3998461655652727

Epoch: 6| Step: 6
Training loss: 2.070317221582175
Validation loss: 2.4039327242512947

Epoch: 6| Step: 7
Training loss: 2.503752371929262
Validation loss: 2.383240191860306

Epoch: 6| Step: 8
Training loss: 2.0423599415527556
Validation loss: 2.377463721421263

Epoch: 6| Step: 9
Training loss: 2.014893154974813
Validation loss: 2.3892743330395634

Epoch: 6| Step: 10
Training loss: 2.3655494587173997
Validation loss: 2.4094694441436504

Epoch: 6| Step: 11
Training loss: 2.357449181374061
Validation loss: 2.3690543337447956

Epoch: 6| Step: 12
Training loss: 1.6721127064787602
Validation loss: 2.389999922398275

Epoch: 6| Step: 13
Training loss: 2.970602963055031
Validation loss: 2.381065134917925

Epoch: 169| Step: 0
Training loss: 2.474650803409628
Validation loss: 2.4046297700671606

Epoch: 6| Step: 1
Training loss: 1.8362656969577165
Validation loss: 2.3870212008900027

Epoch: 6| Step: 2
Training loss: 2.384426283378603
Validation loss: 2.3663008437334465

Epoch: 6| Step: 3
Training loss: 2.404641443596014
Validation loss: 2.4116699687380034

Epoch: 6| Step: 4
Training loss: 3.009225171757404
Validation loss: 2.392841226301934

Epoch: 6| Step: 5
Training loss: 2.2285920112483795
Validation loss: 2.3918284256413895

Epoch: 6| Step: 6
Training loss: 2.051353156862543
Validation loss: 2.3799352339532946

Epoch: 6| Step: 7
Training loss: 2.709384880355894
Validation loss: 2.402277410234682

Epoch: 6| Step: 8
Training loss: 2.3242443948821547
Validation loss: 2.4142219758129952

Epoch: 6| Step: 9
Training loss: 2.003495737602968
Validation loss: 2.3671798345836366

Epoch: 6| Step: 10
Training loss: 1.8562522759728655
Validation loss: 2.413748808679328

Epoch: 6| Step: 11
Training loss: 2.1027810346857287
Validation loss: 2.3917281889344255

Epoch: 6| Step: 12
Training loss: 2.0977326277994472
Validation loss: 2.4257030136588513

Epoch: 6| Step: 13
Training loss: 2.6512940791888857
Validation loss: 2.4096799583172936

Epoch: 170| Step: 0
Training loss: 2.3785414141934136
Validation loss: 2.380083385412094

Epoch: 6| Step: 1
Training loss: 2.1855912736707324
Validation loss: 2.404489969572122

Epoch: 6| Step: 2
Training loss: 1.741889278050854
Validation loss: 2.4119764873541407

Epoch: 6| Step: 3
Training loss: 2.297009107346638
Validation loss: 2.4024477812349243

Epoch: 6| Step: 4
Training loss: 2.4055544355691834
Validation loss: 2.4108721619707003

Epoch: 6| Step: 5
Training loss: 2.193710231148834
Validation loss: 2.402879000546643

Epoch: 6| Step: 6
Training loss: 2.0697663360515
Validation loss: 2.4021708519204505

Epoch: 6| Step: 7
Training loss: 1.7949665715709724
Validation loss: 2.37750109531901

Epoch: 6| Step: 8
Training loss: 2.436047341229673
Validation loss: 2.42103548136953

Epoch: 6| Step: 9
Training loss: 2.238700041945686
Validation loss: 2.3978567544980853

Epoch: 6| Step: 10
Training loss: 2.8544128386059087
Validation loss: 2.402717617398588

Epoch: 6| Step: 11
Training loss: 2.529341178123094
Validation loss: 2.4139324062513747

Epoch: 6| Step: 12
Training loss: 2.7885580167598616
Validation loss: 2.392107269250634

Epoch: 6| Step: 13
Training loss: 2.375346409480722
Validation loss: 2.371500744775144

Epoch: 171| Step: 0
Training loss: 2.117286820563002
Validation loss: 2.433150147824793

Epoch: 6| Step: 1
Training loss: 2.2815132511781546
Validation loss: 2.3808531103373336

Epoch: 6| Step: 2
Training loss: 2.1973570944502865
Validation loss: 2.4066537503142538

Epoch: 6| Step: 3
Training loss: 1.9600400048669189
Validation loss: 2.3743928792841382

Epoch: 6| Step: 4
Training loss: 2.9563071247412536
Validation loss: 2.4154242754490944

Epoch: 6| Step: 5
Training loss: 2.4562277639998698
Validation loss: 2.3717322502049987

Epoch: 6| Step: 6
Training loss: 1.653014495559893
Validation loss: 2.3827856800998126

Epoch: 6| Step: 7
Training loss: 2.115507353042955
Validation loss: 2.3790156337962967

Epoch: 6| Step: 8
Training loss: 2.3826697134792925
Validation loss: 2.3692962449561312

Epoch: 6| Step: 9
Training loss: 2.7039697462736947
Validation loss: 2.3785054944770603

Epoch: 6| Step: 10
Training loss: 2.319634232462547
Validation loss: 2.3635420297820997

Epoch: 6| Step: 11
Training loss: 2.257859490245496
Validation loss: 2.39396255309015

Epoch: 6| Step: 12
Training loss: 2.4450796583184076
Validation loss: 2.3746482251822782

Epoch: 6| Step: 13
Training loss: 2.1628489482902213
Validation loss: 2.367107170012067

Epoch: 172| Step: 0
Training loss: 2.019559347226571
Validation loss: 2.3611971007277113

Epoch: 6| Step: 1
Training loss: 2.741621692678956
Validation loss: 2.389309030775088

Epoch: 6| Step: 2
Training loss: 2.204072897153816
Validation loss: 2.3685305276267563

Epoch: 6| Step: 3
Training loss: 3.193078190267598
Validation loss: 2.373256514034098

Epoch: 6| Step: 4
Training loss: 2.651597200255413
Validation loss: 2.3948278659783617

Epoch: 6| Step: 5
Training loss: 1.687650885723988
Validation loss: 2.4028201814225643

Epoch: 6| Step: 6
Training loss: 2.1309417233171413
Validation loss: 2.390059006614274

Epoch: 6| Step: 7
Training loss: 2.214901232099649
Validation loss: 2.380568344201931

Epoch: 6| Step: 8
Training loss: 2.4568466820706703
Validation loss: 2.40569207113406

Epoch: 6| Step: 9
Training loss: 1.5076516811804899
Validation loss: 2.373563367592673

Epoch: 6| Step: 10
Training loss: 2.330313863284518
Validation loss: 2.3965844395230045

Epoch: 6| Step: 11
Training loss: 2.593387072806413
Validation loss: 2.3631174164808

Epoch: 6| Step: 12
Training loss: 2.1610880216636086
Validation loss: 2.384002877738627

Epoch: 6| Step: 13
Training loss: 1.151774999921439
Validation loss: 2.3931463678209406

Epoch: 173| Step: 0
Training loss: 2.812197690187133
Validation loss: 2.3910886896732353

Epoch: 6| Step: 1
Training loss: 1.9954850972803624
Validation loss: 2.3751486055506055

Epoch: 6| Step: 2
Training loss: 2.0698939638115137
Validation loss: 2.4095517941528057

Epoch: 6| Step: 3
Training loss: 2.3735576064337622
Validation loss: 2.363305311386456

Epoch: 6| Step: 4
Training loss: 2.438800367092351
Validation loss: 2.357773818075611

Epoch: 6| Step: 5
Training loss: 2.5433181546092865
Validation loss: 2.3975770216507586

Epoch: 6| Step: 6
Training loss: 2.269178668422483
Validation loss: 2.3874325944237196

Epoch: 6| Step: 7
Training loss: 1.6990102355002081
Validation loss: 2.359416280840464

Epoch: 6| Step: 8
Training loss: 1.8560788727559152
Validation loss: 2.383520980776418

Epoch: 6| Step: 9
Training loss: 1.9273283587870642
Validation loss: 2.4161642904603444

Epoch: 6| Step: 10
Training loss: 2.4651644780684845
Validation loss: 2.376668162864112

Epoch: 6| Step: 11
Training loss: 2.3239286353862427
Validation loss: 2.3776020989506024

Epoch: 6| Step: 12
Training loss: 2.3776206565750275
Validation loss: 2.372732907903084

Epoch: 6| Step: 13
Training loss: 2.529953989809253
Validation loss: 2.3748620386645367

Epoch: 174| Step: 0
Training loss: 2.1328677215693435
Validation loss: 2.3579402419295086

Epoch: 6| Step: 1
Training loss: 2.2549555565626465
Validation loss: 2.3755287721654157

Epoch: 6| Step: 2
Training loss: 2.4392081902030847
Validation loss: 2.4198559154305657

Epoch: 6| Step: 3
Training loss: 2.7876309693364387
Validation loss: 2.3984514189082424

Epoch: 6| Step: 4
Training loss: 2.1519307538204573
Validation loss: 2.364732771648836

Epoch: 6| Step: 5
Training loss: 2.558633445839489
Validation loss: 2.390246927680447

Epoch: 6| Step: 6
Training loss: 2.1543418070308613
Validation loss: 2.3803614261116404

Epoch: 6| Step: 7
Training loss: 2.1910314120361334
Validation loss: 2.412019591520252

Epoch: 6| Step: 8
Training loss: 2.921241405965743
Validation loss: 2.415736957000635

Epoch: 6| Step: 9
Training loss: 2.152978267016044
Validation loss: 2.386884282907532

Epoch: 6| Step: 10
Training loss: 2.4576448241487294
Validation loss: 2.3914027730649274

Epoch: 6| Step: 11
Training loss: 1.436427836086342
Validation loss: 2.38573371344691

Epoch: 6| Step: 12
Training loss: 2.155528956945027
Validation loss: 2.406068270569796

Epoch: 6| Step: 13
Training loss: 1.814578081802962
Validation loss: 2.3853498027576436

Epoch: 175| Step: 0
Training loss: 1.74024423923972
Validation loss: 2.3960428535973652

Epoch: 6| Step: 1
Training loss: 2.4819152939425937
Validation loss: 2.3986982485960677

Epoch: 6| Step: 2
Training loss: 1.8002339687875877
Validation loss: 2.395881742939786

Epoch: 6| Step: 3
Training loss: 1.5258539841714747
Validation loss: 2.3925295921159733

Epoch: 6| Step: 4
Training loss: 2.218398805144601
Validation loss: 2.3883178020289706

Epoch: 6| Step: 5
Training loss: 2.775591290687347
Validation loss: 2.378374297108195

Epoch: 6| Step: 6
Training loss: 2.4329505915518745
Validation loss: 2.3779637446334245

Epoch: 6| Step: 7
Training loss: 1.9074112528783118
Validation loss: 2.387554570357032

Epoch: 6| Step: 8
Training loss: 2.666354717446283
Validation loss: 2.372933269485396

Epoch: 6| Step: 9
Training loss: 2.328663398905654
Validation loss: 2.3684028725477138

Epoch: 6| Step: 10
Training loss: 2.9902795032008602
Validation loss: 2.3952068303328415

Epoch: 6| Step: 11
Training loss: 1.980193530941587
Validation loss: 2.3508299045950904

Epoch: 6| Step: 12
Training loss: 2.445878131029456
Validation loss: 2.3658149514556985

Epoch: 6| Step: 13
Training loss: 1.4166745671818657
Validation loss: 2.362417312011013

Epoch: 176| Step: 0
Training loss: 2.435208050027292
Validation loss: 2.3794986732054344

Epoch: 6| Step: 1
Training loss: 2.3564655478565486
Validation loss: 2.349849964895071

Epoch: 6| Step: 2
Training loss: 2.543619333421275
Validation loss: 2.3899471075979526

Epoch: 6| Step: 3
Training loss: 2.5476060999824375
Validation loss: 2.409818612512437

Epoch: 6| Step: 4
Training loss: 2.5630595829021594
Validation loss: 2.3907312038100725

Epoch: 6| Step: 5
Training loss: 1.8929195509439447
Validation loss: 2.371156810497609

Epoch: 6| Step: 6
Training loss: 2.414736459225103
Validation loss: 2.367052532842686

Epoch: 6| Step: 7
Training loss: 2.007198135844308
Validation loss: 2.4177746812257768

Epoch: 6| Step: 8
Training loss: 1.7165609117296066
Validation loss: 2.377241520067312

Epoch: 6| Step: 9
Training loss: 2.3802989271913066
Validation loss: 2.394260857417132

Epoch: 6| Step: 10
Training loss: 2.014547133753333
Validation loss: 2.4307392029495625

Epoch: 6| Step: 11
Training loss: 2.234812340250625
Validation loss: 2.3747353355031167

Epoch: 6| Step: 12
Training loss: 2.4258627271252826
Validation loss: 2.3811765803344698

Epoch: 6| Step: 13
Training loss: 1.287853760867117
Validation loss: 2.382031201526087

Epoch: 177| Step: 0
Training loss: 2.3662817704717343
Validation loss: 2.380301818462242

Epoch: 6| Step: 1
Training loss: 2.1502932769887435
Validation loss: 2.41323404193823

Epoch: 6| Step: 2
Training loss: 2.2155887487805908
Validation loss: 2.3887969825517485

Epoch: 6| Step: 3
Training loss: 1.8642259677986712
Validation loss: 2.37498654381697

Epoch: 6| Step: 4
Training loss: 2.410333116864333
Validation loss: 2.4002971947551797

Epoch: 6| Step: 5
Training loss: 2.506762418423057
Validation loss: 2.411652855469336

Epoch: 6| Step: 6
Training loss: 2.361500874929692
Validation loss: 2.392109864926142

Epoch: 6| Step: 7
Training loss: 2.050057535992321
Validation loss: 2.3347338395418773

Epoch: 6| Step: 8
Training loss: 2.6818972893319617
Validation loss: 2.3718261820081756

Epoch: 6| Step: 9
Training loss: 1.8712339726986749
Validation loss: 2.386778296746613

Epoch: 6| Step: 10
Training loss: 2.3439170269260323
Validation loss: 2.370033154674324

Epoch: 6| Step: 11
Training loss: 2.463506223868546
Validation loss: 2.3771835181651553

Epoch: 6| Step: 12
Training loss: 2.263000862785576
Validation loss: 2.3835890154432695

Epoch: 6| Step: 13
Training loss: 1.7240338342581534
Validation loss: 2.344403073783484

Epoch: 178| Step: 0
Training loss: 2.5666630121510567
Validation loss: 2.3703109303930106

Epoch: 6| Step: 1
Training loss: 1.825457068910965
Validation loss: 2.393997384198347

Epoch: 6| Step: 2
Training loss: 2.8757547134298442
Validation loss: 2.3713014702946262

Epoch: 6| Step: 3
Training loss: 1.8052342234884793
Validation loss: 2.352863123110414

Epoch: 6| Step: 4
Training loss: 2.231668714029039
Validation loss: 2.374181572958936

Epoch: 6| Step: 5
Training loss: 2.856160342355645
Validation loss: 2.4058936262298234

Epoch: 6| Step: 6
Training loss: 2.587026683621098
Validation loss: 2.37867431867864

Epoch: 6| Step: 7
Training loss: 1.93566087373594
Validation loss: 2.3645169721012445

Epoch: 6| Step: 8
Training loss: 1.615943762140602
Validation loss: 2.359283789947244

Epoch: 6| Step: 9
Training loss: 2.4162690284954627
Validation loss: 2.424193550032739

Epoch: 6| Step: 10
Training loss: 1.989542982348014
Validation loss: 2.3907814701205248

Epoch: 6| Step: 11
Training loss: 2.1135813276149045
Validation loss: 2.3692779142792033

Epoch: 6| Step: 12
Training loss: 2.19867597966085
Validation loss: 2.430376004698428

Epoch: 6| Step: 13
Training loss: 1.5356658788510231
Validation loss: 2.386252996098313

Epoch: 179| Step: 0
Training loss: 2.256656126207146
Validation loss: 2.382106055093008

Epoch: 6| Step: 1
Training loss: 2.0191581573286035
Validation loss: 2.418220220809171

Epoch: 6| Step: 2
Training loss: 2.685002341811084
Validation loss: 2.336533631196282

Epoch: 6| Step: 3
Training loss: 1.9450198646648933
Validation loss: 2.3778550226684185

Epoch: 6| Step: 4
Training loss: 2.695831160468317
Validation loss: 2.369380102667423

Epoch: 6| Step: 5
Training loss: 2.2731213956169225
Validation loss: 2.3849915894449305

Epoch: 6| Step: 6
Training loss: 1.647613898176572
Validation loss: 2.3853131730478605

Epoch: 6| Step: 7
Training loss: 2.147262085246707
Validation loss: 2.3559271672582476

Epoch: 6| Step: 8
Training loss: 1.9811776301406696
Validation loss: 2.375966408160114

Epoch: 6| Step: 9
Training loss: 2.398246434457515
Validation loss: 2.408481569394458

Epoch: 6| Step: 10
Training loss: 2.8103549830796126
Validation loss: 2.4147859248652344

Epoch: 6| Step: 11
Training loss: 2.0327736641929484
Validation loss: 2.393076612030868

Epoch: 6| Step: 12
Training loss: 2.3956760078411894
Validation loss: 2.3720185261996725

Epoch: 6| Step: 13
Training loss: 1.7919879300017545
Validation loss: 2.3965289810460417

Epoch: 180| Step: 0
Training loss: 2.1694766187812387
Validation loss: 2.3927903138144266

Epoch: 6| Step: 1
Training loss: 1.7302036469832618
Validation loss: 2.362995976819253

Epoch: 6| Step: 2
Training loss: 1.6224640351763344
Validation loss: 2.382038459687145

Epoch: 6| Step: 3
Training loss: 2.245811165987454
Validation loss: 2.3830925244194185

Epoch: 6| Step: 4
Training loss: 2.2730833216851067
Validation loss: 2.3740777841190215

Epoch: 6| Step: 5
Training loss: 2.505877547521548
Validation loss: 2.3553180777335307

Epoch: 6| Step: 6
Training loss: 1.8319253138514642
Validation loss: 2.3446063751608364

Epoch: 6| Step: 7
Training loss: 2.6340880431143856
Validation loss: 2.36988780248008

Epoch: 6| Step: 8
Training loss: 2.3687626096042593
Validation loss: 2.378599635187246

Epoch: 6| Step: 9
Training loss: 3.010869046092793
Validation loss: 2.40113597582601

Epoch: 6| Step: 10
Training loss: 2.367980622727783
Validation loss: 2.3500148520941795

Epoch: 6| Step: 11
Training loss: 2.039730035833073
Validation loss: 2.381939445873118

Epoch: 6| Step: 12
Training loss: 2.0967850962892576
Validation loss: 2.390263937066259

Epoch: 6| Step: 13
Training loss: 1.965036250063991
Validation loss: 2.4132503751411845

Epoch: 181| Step: 0
Training loss: 2.349551129590306
Validation loss: 2.393056341031508

Epoch: 6| Step: 1
Training loss: 2.0525966202439805
Validation loss: 2.3860465317646944

Epoch: 6| Step: 2
Training loss: 2.131245802710195
Validation loss: 2.3826275131528143

Epoch: 6| Step: 3
Training loss: 2.2091552236580334
Validation loss: 2.3836401180094544

Epoch: 6| Step: 4
Training loss: 2.7320405422682086
Validation loss: 2.4008378604869964

Epoch: 6| Step: 5
Training loss: 2.637411656640281
Validation loss: 2.3731930275385738

Epoch: 6| Step: 6
Training loss: 2.181275913554603
Validation loss: 2.387172987856416

Epoch: 6| Step: 7
Training loss: 1.6555766050265037
Validation loss: 2.3519217858834245

Epoch: 6| Step: 8
Training loss: 2.089437227728889
Validation loss: 2.381653998550853

Epoch: 6| Step: 9
Training loss: 2.2608415289323824
Validation loss: 2.365675776082414

Epoch: 6| Step: 10
Training loss: 1.7879116571350728
Validation loss: 2.3874799316401223

Epoch: 6| Step: 11
Training loss: 2.429794652606061
Validation loss: 2.356209361944303

Epoch: 6| Step: 12
Training loss: 2.450111627955126
Validation loss: 2.3820025431972423

Epoch: 6| Step: 13
Training loss: 2.0803480376156016
Validation loss: 2.353811269518202

Epoch: 182| Step: 0
Training loss: 1.726389811583675
Validation loss: 2.3740449506057795

Epoch: 6| Step: 1
Training loss: 2.1293646922532425
Validation loss: 2.370787859272115

Epoch: 6| Step: 2
Training loss: 2.270603891616345
Validation loss: 2.37738036774919

Epoch: 6| Step: 3
Training loss: 2.2785519883949017
Validation loss: 2.3665640000492285

Epoch: 6| Step: 4
Training loss: 2.4400063369230938
Validation loss: 2.378981645872012

Epoch: 6| Step: 5
Training loss: 2.8379017146419594
Validation loss: 2.3273229842467855

Epoch: 6| Step: 6
Training loss: 1.713332637880731
Validation loss: 2.369197780689093

Epoch: 6| Step: 7
Training loss: 2.4135205299353037
Validation loss: 2.3564321605129943

Epoch: 6| Step: 8
Training loss: 2.7290495539185287
Validation loss: 2.3565905354091723

Epoch: 6| Step: 9
Training loss: 2.2521326766017977
Validation loss: 2.331395545099406

Epoch: 6| Step: 10
Training loss: 2.0821967139706485
Validation loss: 2.3751580531707672

Epoch: 6| Step: 11
Training loss: 1.8662642107535576
Validation loss: 2.3732562893481974

Epoch: 6| Step: 12
Training loss: 2.254890213892682
Validation loss: 2.3509487116512844

Epoch: 6| Step: 13
Training loss: 2.519433402593722
Validation loss: 2.36776931583322

Epoch: 183| Step: 0
Training loss: 1.5350345631289903
Validation loss: 2.3615610287773317

Epoch: 6| Step: 1
Training loss: 1.9343888930898752
Validation loss: 2.3779601349416066

Epoch: 6| Step: 2
Training loss: 2.7224755028777636
Validation loss: 2.3686211148138945

Epoch: 6| Step: 3
Training loss: 1.845792253552367
Validation loss: 2.365645990890733

Epoch: 6| Step: 4
Training loss: 2.2813634974843024
Validation loss: 2.346136740382002

Epoch: 6| Step: 5
Training loss: 2.2104720309769688
Validation loss: 2.374471888522597

Epoch: 6| Step: 6
Training loss: 2.9206256337311065
Validation loss: 2.4215564593721264

Epoch: 6| Step: 7
Training loss: 2.438677185629629
Validation loss: 2.374793898097578

Epoch: 6| Step: 8
Training loss: 2.3608232310202726
Validation loss: 2.4600437774034414

Epoch: 6| Step: 9
Training loss: 1.9661661782801556
Validation loss: 2.38148374070531

Epoch: 6| Step: 10
Training loss: 2.0595747114254825
Validation loss: 2.3742901826710336

Epoch: 6| Step: 11
Training loss: 2.4776651232340954
Validation loss: 2.3805712125307217

Epoch: 6| Step: 12
Training loss: 2.3031186728733477
Validation loss: 2.39860944234149

Epoch: 6| Step: 13
Training loss: 1.7838264036222493
Validation loss: 2.384867592107151

Epoch: 184| Step: 0
Training loss: 1.8744162604511965
Validation loss: 2.372226917137352

Epoch: 6| Step: 1
Training loss: 1.6835745613438466
Validation loss: 2.3519005184165844

Epoch: 6| Step: 2
Training loss: 1.6446436755245037
Validation loss: 2.3410347450635127

Epoch: 6| Step: 3
Training loss: 3.047862044649149
Validation loss: 2.3692159788922877

Epoch: 6| Step: 4
Training loss: 1.9183922201089538
Validation loss: 2.355891974607895

Epoch: 6| Step: 5
Training loss: 1.722560888578996
Validation loss: 2.322480866658597

Epoch: 6| Step: 6
Training loss: 3.014857060980592
Validation loss: 2.3845574310588495

Epoch: 6| Step: 7
Training loss: 2.364272737199898
Validation loss: 2.3904861446330097

Epoch: 6| Step: 8
Training loss: 2.293623926507473
Validation loss: 2.3788236592288667

Epoch: 6| Step: 9
Training loss: 2.0763492885231134
Validation loss: 2.388522648963149

Epoch: 6| Step: 10
Training loss: 1.9475677776172735
Validation loss: 2.358763918442872

Epoch: 6| Step: 11
Training loss: 2.3864219468494126
Validation loss: 2.350390441059352

Epoch: 6| Step: 12
Training loss: 2.514496259806778
Validation loss: 2.3865204201984302

Epoch: 6| Step: 13
Training loss: 2.6999183995667067
Validation loss: 2.382367290970217

Epoch: 185| Step: 0
Training loss: 2.2538391843764636
Validation loss: 2.3920956937038946

Epoch: 6| Step: 1
Training loss: 1.4766806096063818
Validation loss: 2.356850508736404

Epoch: 6| Step: 2
Training loss: 2.6112561783048696
Validation loss: 2.34659491805939

Epoch: 6| Step: 3
Training loss: 2.285149572639817
Validation loss: 2.3541762919605347

Epoch: 6| Step: 4
Training loss: 2.541274108171921
Validation loss: 2.332725444252592

Epoch: 6| Step: 5
Training loss: 1.9077961389088454
Validation loss: 2.357246149665245

Epoch: 6| Step: 6
Training loss: 2.5343585294853885
Validation loss: 2.3645204068863315

Epoch: 6| Step: 7
Training loss: 2.2082044335899074
Validation loss: 2.351641500095377

Epoch: 6| Step: 8
Training loss: 2.207992479422104
Validation loss: 2.3759502567250705

Epoch: 6| Step: 9
Training loss: 1.8061473936088897
Validation loss: 2.3580857880723722

Epoch: 6| Step: 10
Training loss: 2.0841614666731174
Validation loss: 2.380149601654928

Epoch: 6| Step: 11
Training loss: 1.8538185893029793
Validation loss: 2.388786209814294

Epoch: 6| Step: 12
Training loss: 2.682075704133393
Validation loss: 2.4241552568194784

Epoch: 6| Step: 13
Training loss: 2.264931408178279
Validation loss: 2.3782198311824936

Epoch: 186| Step: 0
Training loss: 2.1732847180614137
Validation loss: 2.3773013645894365

Epoch: 6| Step: 1
Training loss: 1.7880156673538632
Validation loss: 2.3728776536613476

Epoch: 6| Step: 2
Training loss: 2.38962519064985
Validation loss: 2.4002115803690023

Epoch: 6| Step: 3
Training loss: 1.642343982968347
Validation loss: 2.357700808154975

Epoch: 6| Step: 4
Training loss: 1.8015734735900748
Validation loss: 2.3851150649458783

Epoch: 6| Step: 5
Training loss: 1.8447095023033258
Validation loss: 2.379520400767309

Epoch: 6| Step: 6
Training loss: 2.9310738907151475
Validation loss: 2.4097146122412245

Epoch: 6| Step: 7
Training loss: 2.2505986159117417
Validation loss: 2.3567818737887536

Epoch: 6| Step: 8
Training loss: 2.1651670205618574
Validation loss: 2.3530901415721415

Epoch: 6| Step: 9
Training loss: 2.9320943889126703
Validation loss: 2.336285238639811

Epoch: 6| Step: 10
Training loss: 1.8554756887205786
Validation loss: 2.336074051936915

Epoch: 6| Step: 11
Training loss: 2.458451241289593
Validation loss: 2.357857767012781

Epoch: 6| Step: 12
Training loss: 2.557471109117072
Validation loss: 2.35263978768066

Epoch: 6| Step: 13
Training loss: 1.758042790904385
Validation loss: 2.3533372849158143

Epoch: 187| Step: 0
Training loss: 2.590344134706054
Validation loss: 2.350786944574904

Epoch: 6| Step: 1
Training loss: 2.2567026122858658
Validation loss: 2.3878214976098384

Epoch: 6| Step: 2
Training loss: 1.6532141735348933
Validation loss: 2.40337510439067

Epoch: 6| Step: 3
Training loss: 2.097647498199562
Validation loss: 2.365374037510351

Epoch: 6| Step: 4
Training loss: 1.5023514277777275
Validation loss: 2.3775574418829906

Epoch: 6| Step: 5
Training loss: 2.0341604655836893
Validation loss: 2.3754945595212114

Epoch: 6| Step: 6
Training loss: 2.621176887478535
Validation loss: 2.3425620619984406

Epoch: 6| Step: 7
Training loss: 2.1072664247724218
Validation loss: 2.356981625623029

Epoch: 6| Step: 8
Training loss: 1.8351627094777097
Validation loss: 2.3650149942111063

Epoch: 6| Step: 9
Training loss: 2.0662669836178265
Validation loss: 2.385206801618732

Epoch: 6| Step: 10
Training loss: 2.849785739808764
Validation loss: 2.35498300247393

Epoch: 6| Step: 11
Training loss: 2.5722176120827513
Validation loss: 2.3857970091466645

Epoch: 6| Step: 12
Training loss: 2.5037493247432625
Validation loss: 2.348964471147112

Epoch: 6| Step: 13
Training loss: 1.3815694707053094
Validation loss: 2.39070624263655

Epoch: 188| Step: 0
Training loss: 2.427915067692388
Validation loss: 2.3766090391476107

Epoch: 6| Step: 1
Training loss: 2.0007599340552336
Validation loss: 2.365324725335773

Epoch: 6| Step: 2
Training loss: 2.6693304784050054
Validation loss: 2.3697802897093108

Epoch: 6| Step: 3
Training loss: 2.4621467646804516
Validation loss: 2.3354015354864557

Epoch: 6| Step: 4
Training loss: 1.8220995861101776
Validation loss: 2.387371058075442

Epoch: 6| Step: 5
Training loss: 1.9478691489667836
Validation loss: 2.349694940716911

Epoch: 6| Step: 6
Training loss: 1.818645647339065
Validation loss: 2.3374592856760907

Epoch: 6| Step: 7
Training loss: 2.590924389959793
Validation loss: 2.3519964521247525

Epoch: 6| Step: 8
Training loss: 2.059590454871277
Validation loss: 2.364681877896974

Epoch: 6| Step: 9
Training loss: 1.7164666006793021
Validation loss: 2.3471351924220256

Epoch: 6| Step: 10
Training loss: 2.012277470008172
Validation loss: 2.3474374925510624

Epoch: 6| Step: 11
Training loss: 2.3276596116223964
Validation loss: 2.3343891452022985

Epoch: 6| Step: 12
Training loss: 2.270918351661307
Validation loss: 2.373930246526025

Epoch: 6| Step: 13
Training loss: 2.032860103111383
Validation loss: 2.352318631777101

Epoch: 189| Step: 0
Training loss: 1.833007097117102
Validation loss: 2.347020153538362

Epoch: 6| Step: 1
Training loss: 2.1590072031541454
Validation loss: 2.3657428599335497

Epoch: 6| Step: 2
Training loss: 2.4985480860796234
Validation loss: 2.3467365425099525

Epoch: 6| Step: 3
Training loss: 2.105197301574926
Validation loss: 2.3667711565758256

Epoch: 6| Step: 4
Training loss: 2.819928763957552
Validation loss: 2.3471372130696433

Epoch: 6| Step: 5
Training loss: 1.964282219128162
Validation loss: 2.35837257809454

Epoch: 6| Step: 6
Training loss: 2.0036028359022766
Validation loss: 2.3787475901586914

Epoch: 6| Step: 7
Training loss: 2.2862854865455384
Validation loss: 2.393349827801471

Epoch: 6| Step: 8
Training loss: 1.9342228646299715
Validation loss: 2.351205115306196

Epoch: 6| Step: 9
Training loss: 2.195102124977517
Validation loss: 2.378745368962194

Epoch: 6| Step: 10
Training loss: 2.2138271252440442
Validation loss: 2.3635898682484964

Epoch: 6| Step: 11
Training loss: 1.853686438388444
Validation loss: 2.392280263468496

Epoch: 6| Step: 12
Training loss: 2.0343515046106275
Validation loss: 2.401774834339036

Epoch: 6| Step: 13
Training loss: 2.5952448386525093
Validation loss: 2.3775181462907558

Epoch: 190| Step: 0
Training loss: 1.7811427167741782
Validation loss: 2.3948738591638357

Epoch: 6| Step: 1
Training loss: 1.7120195564106715
Validation loss: 2.352151007996496

Epoch: 6| Step: 2
Training loss: 2.2851368438679196
Validation loss: 2.3654896430978076

Epoch: 6| Step: 3
Training loss: 1.981842888530144
Validation loss: 2.383414257230964

Epoch: 6| Step: 4
Training loss: 2.5534109490087613
Validation loss: 2.3669348536258195

Epoch: 6| Step: 5
Training loss: 2.178296154418067
Validation loss: 2.347702958743535

Epoch: 6| Step: 6
Training loss: 1.6957149467416472
Validation loss: 2.353441066868951

Epoch: 6| Step: 7
Training loss: 2.1959318868777875
Validation loss: 2.3480560441161686

Epoch: 6| Step: 8
Training loss: 1.6498199740370363
Validation loss: 2.3658800348494062

Epoch: 6| Step: 9
Training loss: 3.2012439694062924
Validation loss: 2.3526406218357945

Epoch: 6| Step: 10
Training loss: 2.3392214958669633
Validation loss: 2.3685252775560732

Epoch: 6| Step: 11
Training loss: 2.3639417497716555
Validation loss: 2.3864534096056444

Epoch: 6| Step: 12
Training loss: 2.0939195478882575
Validation loss: 2.3473576077698364

Epoch: 6| Step: 13
Training loss: 1.7109050312183867
Validation loss: 2.3600563527481446

Epoch: 191| Step: 0
Training loss: 2.3681253017124315
Validation loss: 2.3417057969767305

Epoch: 6| Step: 1
Training loss: 2.314289946779286
Validation loss: 2.30326589459298

Epoch: 6| Step: 2
Training loss: 2.0692096579862596
Validation loss: 2.36504090347721

Epoch: 6| Step: 3
Training loss: 2.3039804182147665
Validation loss: 2.3265051725178485

Epoch: 6| Step: 4
Training loss: 2.1538901200103893
Validation loss: 2.4057623000485497

Epoch: 6| Step: 5
Training loss: 2.769059543227044
Validation loss: 2.3773177893794166

Epoch: 6| Step: 6
Training loss: 2.4315326712670773
Validation loss: 2.365737792232205

Epoch: 6| Step: 7
Training loss: 1.7999150309111138
Validation loss: 2.3538125263906373

Epoch: 6| Step: 8
Training loss: 2.1001162178941692
Validation loss: 2.340430377408861

Epoch: 6| Step: 9
Training loss: 2.0463803691032783
Validation loss: 2.346305789216377

Epoch: 6| Step: 10
Training loss: 1.841089041848837
Validation loss: 2.3461494113811048

Epoch: 6| Step: 11
Training loss: 1.8366445275695689
Validation loss: 2.357528907434141

Epoch: 6| Step: 12
Training loss: 1.6495081601988952
Validation loss: 2.3511920092415135

Epoch: 6| Step: 13
Training loss: 2.9153293995383267
Validation loss: 2.3264856831908736

Epoch: 192| Step: 0
Training loss: 2.1560500784810097
Validation loss: 2.3625434116243107

Epoch: 6| Step: 1
Training loss: 2.491661087931466
Validation loss: 2.364837245437003

Epoch: 6| Step: 2
Training loss: 1.9270933683666789
Validation loss: 2.3600744481820755

Epoch: 6| Step: 3
Training loss: 2.6913620456559015
Validation loss: 2.3380687304921506

Epoch: 6| Step: 4
Training loss: 2.8923766731208898
Validation loss: 2.385181710081433

Epoch: 6| Step: 5
Training loss: 2.1857227189928023
Validation loss: 2.3877895976544012

Epoch: 6| Step: 6
Training loss: 2.4084959571429074
Validation loss: 2.329462755410305

Epoch: 6| Step: 7
Training loss: 1.9037266273591669
Validation loss: 2.371885419542187

Epoch: 6| Step: 8
Training loss: 1.8842090793016324
Validation loss: 2.3558878950078253

Epoch: 6| Step: 9
Training loss: 2.181567075577306
Validation loss: 2.37576980722679

Epoch: 6| Step: 10
Training loss: 2.0227520934346206
Validation loss: 2.3847957626413363

Epoch: 6| Step: 11
Training loss: 1.499319876022861
Validation loss: 2.353525866400803

Epoch: 6| Step: 12
Training loss: 1.9284325352865874
Validation loss: 2.362673701519846

Epoch: 6| Step: 13
Training loss: 2.0970854879553014
Validation loss: 2.40103871690991

Epoch: 193| Step: 0
Training loss: 1.9212276329868034
Validation loss: 2.3444203250174187

Epoch: 6| Step: 1
Training loss: 1.9916096765619071
Validation loss: 2.3826985224847825

Epoch: 6| Step: 2
Training loss: 1.941265876346472
Validation loss: 2.342774600715049

Epoch: 6| Step: 3
Training loss: 1.9640626359573838
Validation loss: 2.3653121142469806

Epoch: 6| Step: 4
Training loss: 2.39354412896743
Validation loss: 2.37236011161659

Epoch: 6| Step: 5
Training loss: 2.003167862217845
Validation loss: 2.3777740309653197

Epoch: 6| Step: 6
Training loss: 1.6176653169937734
Validation loss: 2.3638299060895394

Epoch: 6| Step: 7
Training loss: 1.9971920806397703
Validation loss: 2.336339112888975

Epoch: 6| Step: 8
Training loss: 2.3566430044897237
Validation loss: 2.367111228651729

Epoch: 6| Step: 9
Training loss: 2.4727650116779225
Validation loss: 2.355501934414938

Epoch: 6| Step: 10
Training loss: 2.425827640206582
Validation loss: 2.2847369351759887

Epoch: 6| Step: 11
Training loss: 2.358084218198058
Validation loss: 2.3307381248519663

Epoch: 6| Step: 12
Training loss: 2.3845459683019468
Validation loss: 2.3647829309177264

Epoch: 6| Step: 13
Training loss: 2.398468415002051
Validation loss: 2.3735663577949677

Epoch: 194| Step: 0
Training loss: 1.8736702336185374
Validation loss: 2.393318794194444

Epoch: 6| Step: 1
Training loss: 2.312724746917558
Validation loss: 2.334040760511304

Epoch: 6| Step: 2
Training loss: 1.8474531324169094
Validation loss: 2.345975230505188

Epoch: 6| Step: 3
Training loss: 2.387663359320959
Validation loss: 2.3166273224237686

Epoch: 6| Step: 4
Training loss: 2.372975339713969
Validation loss: 2.374281467990034

Epoch: 6| Step: 5
Training loss: 1.7911072086726088
Validation loss: 2.3753573403043324

Epoch: 6| Step: 6
Training loss: 2.454096899244475
Validation loss: 2.33498381620473

Epoch: 6| Step: 7
Training loss: 2.411394342242182
Validation loss: 2.329347877190125

Epoch: 6| Step: 8
Training loss: 1.9144687143690098
Validation loss: 2.3394595739887527

Epoch: 6| Step: 9
Training loss: 2.4096809796539573
Validation loss: 2.3452817373020913

Epoch: 6| Step: 10
Training loss: 2.1267578483733582
Validation loss: 2.3357068557508907

Epoch: 6| Step: 11
Training loss: 2.232886078398364
Validation loss: 2.3493333888224583

Epoch: 6| Step: 12
Training loss: 1.7718473859515649
Validation loss: 2.339107152813609

Epoch: 6| Step: 13
Training loss: 1.9196324484406704
Validation loss: 2.343351848514387

Epoch: 195| Step: 0
Training loss: 2.0214198595154853
Validation loss: 2.3603428365427046

Epoch: 6| Step: 1
Training loss: 2.184636994505039
Validation loss: 2.3396880261187434

Epoch: 6| Step: 2
Training loss: 2.1128585872241743
Validation loss: 2.3625606085269046

Epoch: 6| Step: 3
Training loss: 2.21994255146236
Validation loss: 2.3699100811426663

Epoch: 6| Step: 4
Training loss: 2.6569034445852333
Validation loss: 2.4068575154620264

Epoch: 6| Step: 5
Training loss: 2.484811036813841
Validation loss: 2.3399850095765347

Epoch: 6| Step: 6
Training loss: 2.2521083278721723
Validation loss: 2.3696450331545096

Epoch: 6| Step: 7
Training loss: 2.157882293743647
Validation loss: 2.4169765690257154

Epoch: 6| Step: 8
Training loss: 1.9888481126485116
Validation loss: 2.3637609328736966

Epoch: 6| Step: 9
Training loss: 2.1655098932674854
Validation loss: 2.343645516804633

Epoch: 6| Step: 10
Training loss: 2.073510000402998
Validation loss: 2.353326373277214

Epoch: 6| Step: 11
Training loss: 1.9074861239507288
Validation loss: 2.367636731486146

Epoch: 6| Step: 12
Training loss: 1.8367932212461933
Validation loss: 2.3705069480134364

Epoch: 6| Step: 13
Training loss: 1.9532497518752392
Validation loss: 2.3252490379658317

Epoch: 196| Step: 0
Training loss: 1.7530119725203135
Validation loss: 2.3783785720407127

Epoch: 6| Step: 1
Training loss: 2.3001214783142307
Validation loss: 2.3073920441968943

Epoch: 6| Step: 2
Training loss: 1.7873178829439273
Validation loss: 2.333930145428631

Epoch: 6| Step: 3
Training loss: 1.7717013830741182
Validation loss: 2.35560178305363

Epoch: 6| Step: 4
Training loss: 2.4538018331625486
Validation loss: 2.3430426708164873

Epoch: 6| Step: 5
Training loss: 1.9554761239498402
Validation loss: 2.313191766877589

Epoch: 6| Step: 6
Training loss: 1.4947715075614416
Validation loss: 2.3656353565599

Epoch: 6| Step: 7
Training loss: 2.3116696903325415
Validation loss: 2.338488886088863

Epoch: 6| Step: 8
Training loss: 1.9596278464001062
Validation loss: 2.3171174263379752

Epoch: 6| Step: 9
Training loss: 2.7756545111176734
Validation loss: 2.3543080722927883

Epoch: 6| Step: 10
Training loss: 2.3944975957948027
Validation loss: 2.38896135199391

Epoch: 6| Step: 11
Training loss: 2.2462210179636704
Validation loss: 2.372560868822483

Epoch: 6| Step: 12
Training loss: 2.1831370850323295
Validation loss: 2.3575150503108944

Epoch: 6| Step: 13
Training loss: 2.2981845988870266
Validation loss: 2.372052820321773

Epoch: 197| Step: 0
Training loss: 1.9444198092156475
Validation loss: 2.3387430296511575

Epoch: 6| Step: 1
Training loss: 2.2932866930469786
Validation loss: 2.3930753819402386

Epoch: 6| Step: 2
Training loss: 1.6571012504644282
Validation loss: 2.342262359808306

Epoch: 6| Step: 3
Training loss: 1.6615758234493945
Validation loss: 2.368004171921254

Epoch: 6| Step: 4
Training loss: 2.08014036273527
Validation loss: 2.3883928847001115

Epoch: 6| Step: 5
Training loss: 2.7069206270236035
Validation loss: 2.3677160603722567

Epoch: 6| Step: 6
Training loss: 2.1285832431278804
Validation loss: 2.370165937028417

Epoch: 6| Step: 7
Training loss: 2.296965512938092
Validation loss: 2.364090513655988

Epoch: 6| Step: 8
Training loss: 2.0437557535353004
Validation loss: 2.3728684130412017

Epoch: 6| Step: 9
Training loss: 1.6675917760022627
Validation loss: 2.404020247734691

Epoch: 6| Step: 10
Training loss: 2.3985498259146127
Validation loss: 2.364423381774293

Epoch: 6| Step: 11
Training loss: 2.0757648575049013
Validation loss: 2.3619883292305457

Epoch: 6| Step: 12
Training loss: 2.2616660419970187
Validation loss: 2.3678721756260206

Epoch: 6| Step: 13
Training loss: 2.576570354239185
Validation loss: 2.3653656015792244

Epoch: 198| Step: 0
Training loss: 2.264371854236091
Validation loss: 2.3529879070659616

Epoch: 6| Step: 1
Training loss: 1.850303125033976
Validation loss: 2.377103125861602

Epoch: 6| Step: 2
Training loss: 1.607605859880856
Validation loss: 2.3317304267982912

Epoch: 6| Step: 3
Training loss: 2.372615420204029
Validation loss: 2.373826521214901

Epoch: 6| Step: 4
Training loss: 2.1800093874597977
Validation loss: 2.355905178578465

Epoch: 6| Step: 5
Training loss: 2.474064767789988
Validation loss: 2.3528782263224395

Epoch: 6| Step: 6
Training loss: 1.6257016061158596
Validation loss: 2.3606054200819915

Epoch: 6| Step: 7
Training loss: 2.6696471803414177
Validation loss: 2.344539301055427

Epoch: 6| Step: 8
Training loss: 2.4352192111499447
Validation loss: 2.3484613118167927

Epoch: 6| Step: 9
Training loss: 1.8043935957539383
Validation loss: 2.3472687818836424

Epoch: 6| Step: 10
Training loss: 2.097500417025028
Validation loss: 2.357521702675408

Epoch: 6| Step: 11
Training loss: 1.9994125099395959
Validation loss: 2.352194555078749

Epoch: 6| Step: 12
Training loss: 1.9990775842233188
Validation loss: 2.3664135922255976

Epoch: 6| Step: 13
Training loss: 2.358405716215476
Validation loss: 2.361327276000102

Epoch: 199| Step: 0
Training loss: 1.6506149590969361
Validation loss: 2.317809662234824

Epoch: 6| Step: 1
Training loss: 2.0094540783641213
Validation loss: 2.35252197868583

Epoch: 6| Step: 2
Training loss: 2.271686312095383
Validation loss: 2.339140516736915

Epoch: 6| Step: 3
Training loss: 2.2839638231689294
Validation loss: 2.3272295860542505

Epoch: 6| Step: 4
Training loss: 2.6218224321262844
Validation loss: 2.337197871673918

Epoch: 6| Step: 5
Training loss: 1.9858313795499787
Validation loss: 2.3253495958153203

Epoch: 6| Step: 6
Training loss: 2.3333926420394464
Validation loss: 2.347403171910014

Epoch: 6| Step: 7
Training loss: 2.4046643469813134
Validation loss: 2.345628909823559

Epoch: 6| Step: 8
Training loss: 1.7637182421836202
Validation loss: 2.3667275419065232

Epoch: 6| Step: 9
Training loss: 2.1166897009049275
Validation loss: 2.3308433133995026

Epoch: 6| Step: 10
Training loss: 2.0097226804662305
Validation loss: 2.3792982147791792

Epoch: 6| Step: 11
Training loss: 2.484102438124423
Validation loss: 2.3587134942295735

Epoch: 6| Step: 12
Training loss: 1.7311391801861389
Validation loss: 2.3404757165851033

Epoch: 6| Step: 13
Training loss: 1.935182908651881
Validation loss: 2.345975456711151

Epoch: 200| Step: 0
Training loss: 2.3651012128016116
Validation loss: 2.3541296621062884

Epoch: 6| Step: 1
Training loss: 2.1429915885528805
Validation loss: 2.326599753462748

Epoch: 6| Step: 2
Training loss: 2.283959752030509
Validation loss: 2.3844598206200467

Epoch: 6| Step: 3
Training loss: 2.1565982703202606
Validation loss: 2.389078161397982

Epoch: 6| Step: 4
Training loss: 1.7571139155473339
Validation loss: 2.369117102252466

Epoch: 6| Step: 5
Training loss: 1.6007097160326167
Validation loss: 2.4106089574884138

Epoch: 6| Step: 6
Training loss: 2.070481318662445
Validation loss: 2.4075786724186408

Epoch: 6| Step: 7
Training loss: 2.2199032432503247
Validation loss: 2.370877156178004

Epoch: 6| Step: 8
Training loss: 2.4651772444259556
Validation loss: 2.378671889405789

Epoch: 6| Step: 9
Training loss: 2.3048551854052994
Validation loss: 2.3627707710843544

Epoch: 6| Step: 10
Training loss: 2.096815910586961
Validation loss: 2.331353029145585

Epoch: 6| Step: 11
Training loss: 2.0091768965057897
Validation loss: 2.3400041459930914

Epoch: 6| Step: 12
Training loss: 1.497983689946409
Validation loss: 2.3368716392682383

Epoch: 6| Step: 13
Training loss: 2.377116314466682
Validation loss: 2.3361643937095504

Epoch: 201| Step: 0
Training loss: 1.9839271580721851
Validation loss: 2.3417237512156017

Epoch: 6| Step: 1
Training loss: 2.189624735413261
Validation loss: 2.365150586000297

Epoch: 6| Step: 2
Training loss: 2.061385460468779
Validation loss: 2.408728070515945

Epoch: 6| Step: 3
Training loss: 2.1563820176552424
Validation loss: 2.362481964879348

Epoch: 6| Step: 4
Training loss: 1.413278183055985
Validation loss: 2.34445173908339

Epoch: 6| Step: 5
Training loss: 2.1781514542449507
Validation loss: 2.352726961013492

Epoch: 6| Step: 6
Training loss: 2.093021209047978
Validation loss: 2.3623493963252504

Epoch: 6| Step: 7
Training loss: 2.1542160835230244
Validation loss: 2.332224329270417

Epoch: 6| Step: 8
Training loss: 2.3045993594109717
Validation loss: 2.2976419322122945

Epoch: 6| Step: 9
Training loss: 2.1480879065713094
Validation loss: 2.377327614435902

Epoch: 6| Step: 10
Training loss: 2.287828965843628
Validation loss: 2.3725682721125905

Epoch: 6| Step: 11
Training loss: 1.4532026044570765
Validation loss: 2.384243547496414

Epoch: 6| Step: 12
Training loss: 2.851150106631005
Validation loss: 2.387679155583075

Epoch: 6| Step: 13
Training loss: 1.8914044247428976
Validation loss: 2.3509344024515006

Epoch: 202| Step: 0
Training loss: 1.750375775455346
Validation loss: 2.3398769872834553

Epoch: 6| Step: 1
Training loss: 2.065381897718398
Validation loss: 2.3440533595494624

Epoch: 6| Step: 2
Training loss: 2.4908708783669486
Validation loss: 2.3498747387510823

Epoch: 6| Step: 3
Training loss: 2.0887275923800304
Validation loss: 2.355200695515953

Epoch: 6| Step: 4
Training loss: 2.751162370034074
Validation loss: 2.3319210595971995

Epoch: 6| Step: 5
Training loss: 2.4260361886088884
Validation loss: 2.3741261483511544

Epoch: 6| Step: 6
Training loss: 1.9658313491291652
Validation loss: 2.3546056320939868

Epoch: 6| Step: 7
Training loss: 1.7910860436759677
Validation loss: 2.3296542670462834

Epoch: 6| Step: 8
Training loss: 1.730433340980491
Validation loss: 2.37158005413067

Epoch: 6| Step: 9
Training loss: 2.016513362553648
Validation loss: 2.3528759866970415

Epoch: 6| Step: 10
Training loss: 1.9145801077875384
Validation loss: 2.3703203053626813

Epoch: 6| Step: 11
Training loss: 1.9938352464968965
Validation loss: 2.3479231938804603

Epoch: 6| Step: 12
Training loss: 1.6813944105786633
Validation loss: 2.3028625070213216

Epoch: 6| Step: 13
Training loss: 2.7861787649831653
Validation loss: 2.330531110590575

Epoch: 203| Step: 0
Training loss: 2.4196372245759212
Validation loss: 2.3341912241304708

Epoch: 6| Step: 1
Training loss: 1.675270411740628
Validation loss: 2.3916072212364368

Epoch: 6| Step: 2
Training loss: 1.9019749340688088
Validation loss: 2.3263498373911395

Epoch: 6| Step: 3
Training loss: 1.7721278526561417
Validation loss: 2.3614780826896142

Epoch: 6| Step: 4
Training loss: 1.8804713212341555
Validation loss: 2.410109123625109

Epoch: 6| Step: 5
Training loss: 2.039630562297486
Validation loss: 2.4404235967664585

Epoch: 6| Step: 6
Training loss: 2.370062262767485
Validation loss: 2.3631756887688993

Epoch: 6| Step: 7
Training loss: 2.383749255543809
Validation loss: 2.3677544099251633

Epoch: 6| Step: 8
Training loss: 2.828119098804703
Validation loss: 2.411311038765762

Epoch: 6| Step: 9
Training loss: 2.0619450602866762
Validation loss: 2.361182900050605

Epoch: 6| Step: 10
Training loss: 2.027165458351199
Validation loss: 2.352223730246436

Epoch: 6| Step: 11
Training loss: 2.0217806244275236
Validation loss: 2.4207084638241794

Epoch: 6| Step: 12
Training loss: 2.196466217427283
Validation loss: 2.3469760243666506

Epoch: 6| Step: 13
Training loss: 1.709977320358948
Validation loss: 2.3799252327687443

Epoch: 204| Step: 0
Training loss: 2.1669483979774578
Validation loss: 2.3857041711537663

Epoch: 6| Step: 1
Training loss: 1.7845838033761774
Validation loss: 2.37907272896775

Epoch: 6| Step: 2
Training loss: 2.4848162181293043
Validation loss: 2.338840507091226

Epoch: 6| Step: 3
Training loss: 1.4813691875938262
Validation loss: 2.358218128307096

Epoch: 6| Step: 4
Training loss: 2.535440813971958
Validation loss: 2.3277047292677375

Epoch: 6| Step: 5
Training loss: 2.0832297362954932
Validation loss: 2.351263563976152

Epoch: 6| Step: 6
Training loss: 2.3631339539582994
Validation loss: 2.35892485048792

Epoch: 6| Step: 7
Training loss: 2.291878176089568
Validation loss: 2.3244037938153337

Epoch: 6| Step: 8
Training loss: 1.7570367754505438
Validation loss: 2.3437339842327733

Epoch: 6| Step: 9
Training loss: 2.1732764902267756
Validation loss: 2.382529883903646

Epoch: 6| Step: 10
Training loss: 2.093278063066731
Validation loss: 2.360631497205431

Epoch: 6| Step: 11
Training loss: 1.9716316205949103
Validation loss: 2.3649695043456314

Epoch: 6| Step: 12
Training loss: 1.366630440712572
Validation loss: 2.3447860320242353

Epoch: 6| Step: 13
Training loss: 2.3111432193498262
Validation loss: 2.382897029986489

Epoch: 205| Step: 0
Training loss: 2.353423741236722
Validation loss: 2.3373995661264626

Epoch: 6| Step: 1
Training loss: 1.9758824320655972
Validation loss: 2.343447295299138

Epoch: 6| Step: 2
Training loss: 1.888106757653258
Validation loss: 2.37628148106932

Epoch: 6| Step: 3
Training loss: 2.4280721808424186
Validation loss: 2.3568362462460177

Epoch: 6| Step: 4
Training loss: 1.9784111454783555
Validation loss: 2.3405269499364287

Epoch: 6| Step: 5
Training loss: 1.7651968918037149
Validation loss: 2.382282366349465

Epoch: 6| Step: 6
Training loss: 1.7432768969521226
Validation loss: 2.3330885561720778

Epoch: 6| Step: 7
Training loss: 1.8944792750199788
Validation loss: 2.3623239730189294

Epoch: 6| Step: 8
Training loss: 2.196808220620274
Validation loss: 2.330942252372809

Epoch: 6| Step: 9
Training loss: 1.6816382147830433
Validation loss: 2.3793587531679377

Epoch: 6| Step: 10
Training loss: 2.821881225173522
Validation loss: 2.3850753940566807

Epoch: 6| Step: 11
Training loss: 2.533345050115427
Validation loss: 2.3844076346491287

Epoch: 6| Step: 12
Training loss: 1.6318615055877719
Validation loss: 2.3672834141583676

Epoch: 6| Step: 13
Training loss: 1.5270428373302518
Validation loss: 2.3820885171494326

Epoch: 206| Step: 0
Training loss: 2.190788304313684
Validation loss: 2.3685413703036753

Epoch: 6| Step: 1
Training loss: 2.3423691814620478
Validation loss: 2.3429302824819835

Epoch: 6| Step: 2
Training loss: 2.687642382021633
Validation loss: 2.373206586791848

Epoch: 6| Step: 3
Training loss: 2.3465551247241434
Validation loss: 2.3600629555853123

Epoch: 6| Step: 4
Training loss: 2.1666252303440547
Validation loss: 2.331263128838216

Epoch: 6| Step: 5
Training loss: 2.151285066911736
Validation loss: 2.316448071913336

Epoch: 6| Step: 6
Training loss: 2.1608685772786513
Validation loss: 2.3277322443793627

Epoch: 6| Step: 7
Training loss: 1.8041517775393277
Validation loss: 2.3736260978667407

Epoch: 6| Step: 8
Training loss: 1.4887049915290769
Validation loss: 2.3859137102203527

Epoch: 6| Step: 9
Training loss: 2.170206650417784
Validation loss: 2.331901808475346

Epoch: 6| Step: 10
Training loss: 1.6326000312664044
Validation loss: 2.35958621008669

Epoch: 6| Step: 11
Training loss: 2.2783232426042024
Validation loss: 2.374161952916665

Epoch: 6| Step: 12
Training loss: 2.012331615535518
Validation loss: 2.308820297046713

Epoch: 6| Step: 13
Training loss: 1.4422102342592935
Validation loss: 2.348109130791776

Epoch: 207| Step: 0
Training loss: 2.198099559629124
Validation loss: 2.3435895157974245

Epoch: 6| Step: 1
Training loss: 1.88937002097435
Validation loss: 2.348763064158028

Epoch: 6| Step: 2
Training loss: 2.474169516668309
Validation loss: 2.3616533748132156

Epoch: 6| Step: 3
Training loss: 1.6487910176367038
Validation loss: 2.329423210877135

Epoch: 6| Step: 4
Training loss: 1.6684209492047015
Validation loss: 2.3524357556750513

Epoch: 6| Step: 5
Training loss: 1.5715970531161227
Validation loss: 2.3440890104614955

Epoch: 6| Step: 6
Training loss: 1.1549345214250446
Validation loss: 2.350864200835704

Epoch: 6| Step: 7
Training loss: 2.0673798140773014
Validation loss: 2.333840700295094

Epoch: 6| Step: 8
Training loss: 1.9144289249866875
Validation loss: 2.3209654186794446

Epoch: 6| Step: 9
Training loss: 2.6288043111504598
Validation loss: 2.395964068840177

Epoch: 6| Step: 10
Training loss: 1.9871268827860529
Validation loss: 2.3389740200812583

Epoch: 6| Step: 11
Training loss: 2.584050714703736
Validation loss: 2.368315745803916

Epoch: 6| Step: 12
Training loss: 2.614421145410132
Validation loss: 2.360629925766077

Epoch: 6| Step: 13
Training loss: 1.9661813964322181
Validation loss: 2.342094401049492

Epoch: 208| Step: 0
Training loss: 1.976597359692907
Validation loss: 2.3356725240861222

Epoch: 6| Step: 1
Training loss: 1.8654257790987154
Validation loss: 2.3512191753501015

Epoch: 6| Step: 2
Training loss: 2.358790445228646
Validation loss: 2.3513190793812546

Epoch: 6| Step: 3
Training loss: 2.281862568587641
Validation loss: 2.3727015468329964

Epoch: 6| Step: 4
Training loss: 1.8603445138071846
Validation loss: 2.363589869333135

Epoch: 6| Step: 5
Training loss: 2.1063968686478605
Validation loss: 2.2883320379676637

Epoch: 6| Step: 6
Training loss: 1.901218151801401
Validation loss: 2.346362487210789

Epoch: 6| Step: 7
Training loss: 2.2271648462245226
Validation loss: 2.341454776827102

Epoch: 6| Step: 8
Training loss: 2.1330378486719797
Validation loss: 2.3449369404335365

Epoch: 6| Step: 9
Training loss: 2.278572496959745
Validation loss: 2.347585335540671

Epoch: 6| Step: 10
Training loss: 1.7142741793289842
Validation loss: 2.3300270205821736

Epoch: 6| Step: 11
Training loss: 1.8482996524027215
Validation loss: 2.388759431227152

Epoch: 6| Step: 12
Training loss: 2.0812641040221007
Validation loss: 2.3206960267840597

Epoch: 6| Step: 13
Training loss: 2.150900133355101
Validation loss: 2.3800561889984624

Epoch: 209| Step: 0
Training loss: 2.213458130700083
Validation loss: 2.3563250195097556

Epoch: 6| Step: 1
Training loss: 1.6738829631569
Validation loss: 2.3727062820024445

Epoch: 6| Step: 2
Training loss: 1.5531231855232186
Validation loss: 2.3342376097922304

Epoch: 6| Step: 3
Training loss: 2.010974931701994
Validation loss: 2.2852223202605995

Epoch: 6| Step: 4
Training loss: 1.6195054695811983
Validation loss: 2.3622143090176015

Epoch: 6| Step: 5
Training loss: 1.7802328585354026
Validation loss: 2.3584138194125446

Epoch: 6| Step: 6
Training loss: 2.485175621535236
Validation loss: 2.3397903278785157

Epoch: 6| Step: 7
Training loss: 1.857225152958997
Validation loss: 2.3666545904730447

Epoch: 6| Step: 8
Training loss: 2.4398332823407576
Validation loss: 2.348099541585984

Epoch: 6| Step: 9
Training loss: 2.8679444355922468
Validation loss: 2.3636513349992745

Epoch: 6| Step: 10
Training loss: 1.8044749213188587
Validation loss: 2.3070492014388586

Epoch: 6| Step: 11
Training loss: 2.262454425500284
Validation loss: 2.3570177346748693

Epoch: 6| Step: 12
Training loss: 2.1780121083058748
Validation loss: 2.344583116351664

Epoch: 6| Step: 13
Training loss: 1.8290380822289887
Validation loss: 2.3536255625078812

Epoch: 210| Step: 0
Training loss: 1.5236872541669246
Validation loss: 2.3284027832436482

Epoch: 6| Step: 1
Training loss: 2.135583998163994
Validation loss: 2.3515959837359834

Epoch: 6| Step: 2
Training loss: 2.370635288416338
Validation loss: 2.363995251842732

Epoch: 6| Step: 3
Training loss: 1.95504410111035
Validation loss: 2.362028502378121

Epoch: 6| Step: 4
Training loss: 2.3794165253478914
Validation loss: 2.304397247151971

Epoch: 6| Step: 5
Training loss: 1.6648033534590434
Validation loss: 2.3776495768953247

Epoch: 6| Step: 6
Training loss: 2.347767552738016
Validation loss: 2.3512616929782983

Epoch: 6| Step: 7
Training loss: 1.4918540062643797
Validation loss: 2.365798806569923

Epoch: 6| Step: 8
Training loss: 2.1807534950733003
Validation loss: 2.389267963829094

Epoch: 6| Step: 9
Training loss: 2.1773821490309646
Validation loss: 2.358784758574746

Epoch: 6| Step: 10
Training loss: 1.9516578962529134
Validation loss: 2.387466625256741

Epoch: 6| Step: 11
Training loss: 1.5567818341888031
Validation loss: 2.3347144469051093

Epoch: 6| Step: 12
Training loss: 2.5447086411771083
Validation loss: 2.348145796614485

Epoch: 6| Step: 13
Training loss: 1.9630069223749238
Validation loss: 2.3688449342856748

Epoch: 211| Step: 0
Training loss: 2.3424167146808155
Validation loss: 2.3669128702688575

Epoch: 6| Step: 1
Training loss: 1.6325321230568481
Validation loss: 2.3434139894108656

Epoch: 6| Step: 2
Training loss: 2.394136629678558
Validation loss: 2.390197311364528

Epoch: 6| Step: 3
Training loss: 1.7499317428356285
Validation loss: 2.359306236112016

Epoch: 6| Step: 4
Training loss: 2.105137616731024
Validation loss: 2.3104884792525957

Epoch: 6| Step: 5
Training loss: 2.1292873216497643
Validation loss: 2.352083683089278

Epoch: 6| Step: 6
Training loss: 1.4474348002822495
Validation loss: 2.321734047121084

Epoch: 6| Step: 7
Training loss: 1.4863740009140571
Validation loss: 2.3453986726393716

Epoch: 6| Step: 8
Training loss: 2.4619144498710526
Validation loss: 2.325962399863937

Epoch: 6| Step: 9
Training loss: 1.8642640790639178
Validation loss: 2.3495508764506097

Epoch: 6| Step: 10
Training loss: 2.452449827157351
Validation loss: 2.3604761965821988

Epoch: 6| Step: 11
Training loss: 1.9441622355193018
Validation loss: 2.3389614921563275

Epoch: 6| Step: 12
Training loss: 2.134579775190047
Validation loss: 2.344992235006743

Epoch: 6| Step: 13
Training loss: 2.852668944695866
Validation loss: 2.3035747530232555

Epoch: 212| Step: 0
Training loss: 1.858923592789151
Validation loss: 2.342193317349326

Epoch: 6| Step: 1
Training loss: 2.3623740228236847
Validation loss: 2.3494979183717826

Epoch: 6| Step: 2
Training loss: 2.255583828037423
Validation loss: 2.354360953751703

Epoch: 6| Step: 3
Training loss: 2.071396914367057
Validation loss: 2.299184723182134

Epoch: 6| Step: 4
Training loss: 2.1022006629383174
Validation loss: 2.3383320874529154

Epoch: 6| Step: 5
Training loss: 2.4052105925229843
Validation loss: 2.369356466523542

Epoch: 6| Step: 6
Training loss: 2.0056553990433934
Validation loss: 2.3389761398477456

Epoch: 6| Step: 7
Training loss: 1.904523348912781
Validation loss: 2.363991059345527

Epoch: 6| Step: 8
Training loss: 2.3135989902705183
Validation loss: 2.3387510568298246

Epoch: 6| Step: 9
Training loss: 2.0819344846987575
Validation loss: 2.36531500703759

Epoch: 6| Step: 10
Training loss: 1.602068788473166
Validation loss: 2.3545255838426726

Epoch: 6| Step: 11
Training loss: 1.69625279942888
Validation loss: 2.3851120747116443

Epoch: 6| Step: 12
Training loss: 1.792478407087312
Validation loss: 2.359631333297008

Epoch: 6| Step: 13
Training loss: 2.2977901374333634
Validation loss: 2.3333893965506385

Epoch: 213| Step: 0
Training loss: 2.0189473767236352
Validation loss: 2.3408810990804856

Epoch: 6| Step: 1
Training loss: 2.0416389645104913
Validation loss: 2.336788825575584

Epoch: 6| Step: 2
Training loss: 1.8824889985430513
Validation loss: 2.320395027804117

Epoch: 6| Step: 3
Training loss: 2.32331125189615
Validation loss: 2.368124375039839

Epoch: 6| Step: 4
Training loss: 1.6193058311563306
Validation loss: 2.353747052136977

Epoch: 6| Step: 5
Training loss: 2.216658560181138
Validation loss: 2.324724646441073

Epoch: 6| Step: 6
Training loss: 1.7066624851970311
Validation loss: 2.325709196575607

Epoch: 6| Step: 7
Training loss: 2.0757468246919
Validation loss: 2.3243466462107887

Epoch: 6| Step: 8
Training loss: 2.390478191979196
Validation loss: 2.263324177750203

Epoch: 6| Step: 9
Training loss: 1.6382564340875776
Validation loss: 2.3237829323528256

Epoch: 6| Step: 10
Training loss: 2.640055126568303
Validation loss: 2.351788174036634

Epoch: 6| Step: 11
Training loss: 2.2735821130646263
Validation loss: 2.305232633981014

Epoch: 6| Step: 12
Training loss: 1.8288884321320094
Validation loss: 2.330215704057359

Epoch: 6| Step: 13
Training loss: 2.097448015444062
Validation loss: 2.4217758301309407

Epoch: 214| Step: 0
Training loss: 2.1515061536626026
Validation loss: 2.354282334564583

Epoch: 6| Step: 1
Training loss: 1.5092959049580519
Validation loss: 2.3361948313094363

Epoch: 6| Step: 2
Training loss: 1.6429314522493508
Validation loss: 2.303814377257941

Epoch: 6| Step: 3
Training loss: 2.037828093716095
Validation loss: 2.4203876851947386

Epoch: 6| Step: 4
Training loss: 2.08996034100883
Validation loss: 2.3514337280586166

Epoch: 6| Step: 5
Training loss: 1.8250129490223135
Validation loss: 2.3014597781626644

Epoch: 6| Step: 6
Training loss: 1.9023519590228104
Validation loss: 2.3564504757961995

Epoch: 6| Step: 7
Training loss: 2.09499970902689
Validation loss: 2.3845670951242544

Epoch: 6| Step: 8
Training loss: 3.0128844463018454
Validation loss: 2.3462639958030445

Epoch: 6| Step: 9
Training loss: 1.8371572784725663
Validation loss: 2.347177833178986

Epoch: 6| Step: 10
Training loss: 2.213787600748827
Validation loss: 2.3552070773944527

Epoch: 6| Step: 11
Training loss: 2.1398289446337717
Validation loss: 2.3752465187632135

Epoch: 6| Step: 12
Training loss: 2.016845806561892
Validation loss: 2.3754671065990163

Epoch: 6| Step: 13
Training loss: 1.0874606092488066
Validation loss: 2.376531726070265

Epoch: 215| Step: 0
Training loss: 1.8862875372587746
Validation loss: 2.3633401159475578

Epoch: 6| Step: 1
Training loss: 1.9943870818065952
Validation loss: 2.366988327574927

Epoch: 6| Step: 2
Training loss: 2.0409817487469755
Validation loss: 2.346580379105519

Epoch: 6| Step: 3
Training loss: 1.9112155839853933
Validation loss: 2.3105651623406285

Epoch: 6| Step: 4
Training loss: 1.8946927031317076
Validation loss: 2.3697128392771094

Epoch: 6| Step: 5
Training loss: 1.910983602695991
Validation loss: 2.3541004272501436

Epoch: 6| Step: 6
Training loss: 2.8012609775911983
Validation loss: 2.3423179851222526

Epoch: 6| Step: 7
Training loss: 1.9018713268554197
Validation loss: 2.3241567599118893

Epoch: 6| Step: 8
Training loss: 2.3282540304795645
Validation loss: 2.33714000032615

Epoch: 6| Step: 9
Training loss: 2.4106284595530942
Validation loss: 2.325729312450671

Epoch: 6| Step: 10
Training loss: 1.82894631219304
Validation loss: 2.3431841522030004

Epoch: 6| Step: 11
Training loss: 1.7151534858730688
Validation loss: 2.3283544211125204

Epoch: 6| Step: 12
Training loss: 1.3755580029947725
Validation loss: 2.346426341287815

Epoch: 6| Step: 13
Training loss: 2.002741841584482
Validation loss: 2.3628007829383653

Epoch: 216| Step: 0
Training loss: 1.8078212200406185
Validation loss: 2.3174370122376575

Epoch: 6| Step: 1
Training loss: 2.0008367933661515
Validation loss: 2.340165616628744

Epoch: 6| Step: 2
Training loss: 2.085131314394036
Validation loss: 2.345707970408141

Epoch: 6| Step: 3
Training loss: 2.02730047220185
Validation loss: 2.3520103919004267

Epoch: 6| Step: 4
Training loss: 2.0208417230281173
Validation loss: 2.314947410739557

Epoch: 6| Step: 5
Training loss: 2.0130372698574672
Validation loss: 2.3701287984587913

Epoch: 6| Step: 6
Training loss: 2.1454906992518454
Validation loss: 2.345166991745223

Epoch: 6| Step: 7
Training loss: 2.6307368487151086
Validation loss: 2.3742257741496693

Epoch: 6| Step: 8
Training loss: 1.6152466262666427
Validation loss: 2.307327552078757

Epoch: 6| Step: 9
Training loss: 1.801939949402602
Validation loss: 2.3687445908230162

Epoch: 6| Step: 10
Training loss: 2.0398866588297455
Validation loss: 2.351135772273118

Epoch: 6| Step: 11
Training loss: 1.8858256309218249
Validation loss: 2.3329390318644676

Epoch: 6| Step: 12
Training loss: 2.0197613288079115
Validation loss: 2.337286730948392

Epoch: 6| Step: 13
Training loss: 2.0944676094674164
Validation loss: 2.32672922110895

Epoch: 217| Step: 0
Training loss: 1.8788888656858842
Validation loss: 2.3271487294301214

Epoch: 6| Step: 1
Training loss: 2.10044110524644
Validation loss: 2.381771115203054

Epoch: 6| Step: 2
Training loss: 1.8578112141032859
Validation loss: 2.3957108493507313

Epoch: 6| Step: 3
Training loss: 2.080369468666484
Validation loss: 2.434537492413566

Epoch: 6| Step: 4
Training loss: 1.739808309782491
Validation loss: 2.3763016629468026

Epoch: 6| Step: 5
Training loss: 2.9494622338440055
Validation loss: 2.366350406410092

Epoch: 6| Step: 6
Training loss: 1.7135705761852562
Validation loss: 2.4054534130528515

Epoch: 6| Step: 7
Training loss: 1.957670491906851
Validation loss: 2.3718608847728837

Epoch: 6| Step: 8
Training loss: 1.8945433311470472
Validation loss: 2.3766411970399277

Epoch: 6| Step: 9
Training loss: 1.5596790025036658
Validation loss: 2.3860066378350115

Epoch: 6| Step: 10
Training loss: 2.2503686179098277
Validation loss: 2.380227212962724

Epoch: 6| Step: 11
Training loss: 1.799274865425324
Validation loss: 2.3779127117123022

Epoch: 6| Step: 12
Training loss: 1.9908373277809603
Validation loss: 2.369498459451241

Epoch: 6| Step: 13
Training loss: 2.3385787881625033
Validation loss: 2.3339055911700837

Epoch: 218| Step: 0
Training loss: 1.9578698468771591
Validation loss: 2.3155713913053213

Epoch: 6| Step: 1
Training loss: 2.2309864732716105
Validation loss: 2.3364085560245322

Epoch: 6| Step: 2
Training loss: 2.1905713998546883
Validation loss: 2.3090557788655373

Epoch: 6| Step: 3
Training loss: 1.7285830727042024
Validation loss: 2.338172392501969

Epoch: 6| Step: 4
Training loss: 1.9707683934271973
Validation loss: 2.346928432746553

Epoch: 6| Step: 5
Training loss: 1.8019740194634575
Validation loss: 2.337179855244824

Epoch: 6| Step: 6
Training loss: 2.3782894042604403
Validation loss: 2.267795177115019

Epoch: 6| Step: 7
Training loss: 2.1576186549510714
Validation loss: 2.3280128578078267

Epoch: 6| Step: 8
Training loss: 2.529485110786323
Validation loss: 2.3421275248477746

Epoch: 6| Step: 9
Training loss: 1.8206869894383635
Validation loss: 2.3833663740506044

Epoch: 6| Step: 10
Training loss: 2.2245315658720233
Validation loss: 2.366540549186523

Epoch: 6| Step: 11
Training loss: 1.6553515030448405
Validation loss: 2.3066189011322757

Epoch: 6| Step: 12
Training loss: 1.803636054698122
Validation loss: 2.342687385341514

Epoch: 6| Step: 13
Training loss: 1.8326960091673201
Validation loss: 2.373274377575348

Epoch: 219| Step: 0
Training loss: 2.1819874650855646
Validation loss: 2.3263203256080933

Epoch: 6| Step: 1
Training loss: 2.1510072078823486
Validation loss: 2.3478566398284437

Epoch: 6| Step: 2
Training loss: 2.657043518020138
Validation loss: 2.3381179782772863

Epoch: 6| Step: 3
Training loss: 1.9377728546964206
Validation loss: 2.299261617131117

Epoch: 6| Step: 4
Training loss: 1.982087145578427
Validation loss: 2.2928511399041294

Epoch: 6| Step: 5
Training loss: 1.7434438785395954
Validation loss: 2.3481680178977022

Epoch: 6| Step: 6
Training loss: 1.59245344791611
Validation loss: 2.36106641772551

Epoch: 6| Step: 7
Training loss: 1.5657141623929545
Validation loss: 2.301531980726943

Epoch: 6| Step: 8
Training loss: 2.0992775446356826
Validation loss: 2.3675264884519533

Epoch: 6| Step: 9
Training loss: 2.0497958477060463
Validation loss: 2.359507804120518

Epoch: 6| Step: 10
Training loss: 1.9634408967108505
Validation loss: 2.3266639493805394

Epoch: 6| Step: 11
Training loss: 1.4914901462015868
Validation loss: 2.331658819071744

Epoch: 6| Step: 12
Training loss: 2.0352837052219988
Validation loss: 2.3593691960462846

Epoch: 6| Step: 13
Training loss: 2.3650521193199125
Validation loss: 2.3295418622716557

Epoch: 220| Step: 0
Training loss: 1.82798570933693
Validation loss: 2.383887757525239

Epoch: 6| Step: 1
Training loss: 1.7022289053564679
Validation loss: 2.346597377261872

Epoch: 6| Step: 2
Training loss: 1.8822908430690544
Validation loss: 2.3618768972267072

Epoch: 6| Step: 3
Training loss: 2.2474106618333827
Validation loss: 2.3690105760611373

Epoch: 6| Step: 4
Training loss: 1.8723897566893493
Validation loss: 2.317029728713842

Epoch: 6| Step: 5
Training loss: 1.591818892437837
Validation loss: 2.3647265705068556

Epoch: 6| Step: 6
Training loss: 1.9251059069543999
Validation loss: 2.3369605603120918

Epoch: 6| Step: 7
Training loss: 2.2212025157208712
Validation loss: 2.3209422708968646

Epoch: 6| Step: 8
Training loss: 1.792682300698535
Validation loss: 2.323875835846651

Epoch: 6| Step: 9
Training loss: 1.8752548044639266
Validation loss: 2.347232465516779

Epoch: 6| Step: 10
Training loss: 2.0030899020972046
Validation loss: 2.335601793492575

Epoch: 6| Step: 11
Training loss: 2.8725935774817084
Validation loss: 2.3446444701676965

Epoch: 6| Step: 12
Training loss: 1.7285664523997735
Validation loss: 2.3425552834317895

Epoch: 6| Step: 13
Training loss: 2.3329801178570215
Validation loss: 2.322809365228361

Epoch: 221| Step: 0
Training loss: 1.6781264747314792
Validation loss: 2.363486420754366

Epoch: 6| Step: 1
Training loss: 1.4078530393599968
Validation loss: 2.304384633598856

Epoch: 6| Step: 2
Training loss: 2.1438961235047995
Validation loss: 2.3228262205839143

Epoch: 6| Step: 3
Training loss: 2.111856766684408
Validation loss: 2.3897143962157017

Epoch: 6| Step: 4
Training loss: 2.275569794112766
Validation loss: 2.3229540279221497

Epoch: 6| Step: 5
Training loss: 1.3459204067883441
Validation loss: 2.3615781465313765

Epoch: 6| Step: 6
Training loss: 1.9527354347819814
Validation loss: 2.3586460305675785

Epoch: 6| Step: 7
Training loss: 1.570116173157481
Validation loss: 2.3190137467658074

Epoch: 6| Step: 8
Training loss: 1.614240679733643
Validation loss: 2.335749362699426

Epoch: 6| Step: 9
Training loss: 2.008668590859142
Validation loss: 2.3289417872032807

Epoch: 6| Step: 10
Training loss: 2.6414645513798383
Validation loss: 2.364860261139067

Epoch: 6| Step: 11
Training loss: 2.2439856147849015
Validation loss: 2.3273653017452913

Epoch: 6| Step: 12
Training loss: 2.2632192532755675
Validation loss: 2.401789586749587

Epoch: 6| Step: 13
Training loss: 2.539754074987099
Validation loss: 2.3620204349168827

Epoch: 222| Step: 0
Training loss: 1.7221125222547569
Validation loss: 2.3601947651410446

Epoch: 6| Step: 1
Training loss: 2.12879447993581
Validation loss: 2.356861946295033

Epoch: 6| Step: 2
Training loss: 1.6352063021446959
Validation loss: 2.351741978111728

Epoch: 6| Step: 3
Training loss: 1.1774636332247521
Validation loss: 2.3502596545679073

Epoch: 6| Step: 4
Training loss: 1.9968433502984413
Validation loss: 2.327597292434679

Epoch: 6| Step: 5
Training loss: 2.2107835048788327
Validation loss: 2.3384229931986935

Epoch: 6| Step: 6
Training loss: 2.3070240654915857
Validation loss: 2.3000897352129206

Epoch: 6| Step: 7
Training loss: 1.6389327267891973
Validation loss: 2.340399240172662

Epoch: 6| Step: 8
Training loss: 2.2755519826102684
Validation loss: 2.361957609148786

Epoch: 6| Step: 9
Training loss: 2.3842756938127865
Validation loss: 2.347736674422767

Epoch: 6| Step: 10
Training loss: 1.357990700076118
Validation loss: 2.3361030586066858

Epoch: 6| Step: 11
Training loss: 2.0835864358379546
Validation loss: 2.379701659856432

Epoch: 6| Step: 12
Training loss: 2.3577029132592515
Validation loss: 2.329522304257537

Epoch: 6| Step: 13
Training loss: 2.7655310318494997
Validation loss: 2.3249718559732604

Epoch: 223| Step: 0
Training loss: 2.1460169247602456
Validation loss: 2.354436327704525

Epoch: 6| Step: 1
Training loss: 1.7749800506330384
Validation loss: 2.3244772181638633

Epoch: 6| Step: 2
Training loss: 1.9458032318444418
Validation loss: 2.346667683579951

Epoch: 6| Step: 3
Training loss: 1.8915341295818067
Validation loss: 2.332041564315072

Epoch: 6| Step: 4
Training loss: 1.439845121054946
Validation loss: 2.3216909572767364

Epoch: 6| Step: 5
Training loss: 2.2962347682391626
Validation loss: 2.3505997580364504

Epoch: 6| Step: 6
Training loss: 1.9358480240385794
Validation loss: 2.3885652152407033

Epoch: 6| Step: 7
Training loss: 1.610064756856305
Validation loss: 2.3511271920264094

Epoch: 6| Step: 8
Training loss: 2.6561452508355745
Validation loss: 2.3139667709404845

Epoch: 6| Step: 9
Training loss: 2.228762426593089
Validation loss: 2.367541907701977

Epoch: 6| Step: 10
Training loss: 1.9899485853636387
Validation loss: 2.325629941156566

Epoch: 6| Step: 11
Training loss: 2.235176422870781
Validation loss: 2.362794495893121

Epoch: 6| Step: 12
Training loss: 1.6531293728343335
Validation loss: 2.356967846858636

Epoch: 6| Step: 13
Training loss: 1.555631034965043
Validation loss: 2.3525315738394426

Epoch: 224| Step: 0
Training loss: 1.8977074494881379
Validation loss: 2.3542280509482305

Epoch: 6| Step: 1
Training loss: 2.2162855188715347
Validation loss: 2.326612656476493

Epoch: 6| Step: 2
Training loss: 1.526873582049979
Validation loss: 2.3638572338778725

Epoch: 6| Step: 3
Training loss: 2.6373711577127623
Validation loss: 2.319165593764002

Epoch: 6| Step: 4
Training loss: 1.8319767209785378
Validation loss: 2.366914460282261

Epoch: 6| Step: 5
Training loss: 2.2592968137094656
Validation loss: 2.3367875617408815

Epoch: 6| Step: 6
Training loss: 2.245942165401226
Validation loss: 2.3291080786311884

Epoch: 6| Step: 7
Training loss: 1.5146420624412502
Validation loss: 2.31418396205992

Epoch: 6| Step: 8
Training loss: 2.1630498947688475
Validation loss: 2.3470455744046084

Epoch: 6| Step: 9
Training loss: 2.0586437820058636
Validation loss: 2.3535647467183343

Epoch: 6| Step: 10
Training loss: 1.7573397530528672
Validation loss: 2.3359833390224294

Epoch: 6| Step: 11
Training loss: 1.6707668731992737
Validation loss: 2.3348174068859535

Epoch: 6| Step: 12
Training loss: 1.8516388567539472
Validation loss: 2.3308733931878436

Epoch: 6| Step: 13
Training loss: 1.2792519597912049
Validation loss: 2.3284104948429496

Epoch: 225| Step: 0
Training loss: 1.7852825896383246
Validation loss: 2.332242614816218

Epoch: 6| Step: 1
Training loss: 1.8086588705710136
Validation loss: 2.350747611533448

Epoch: 6| Step: 2
Training loss: 2.846617206915092
Validation loss: 2.2907219991577175

Epoch: 6| Step: 3
Training loss: 2.3801034004125268
Validation loss: 2.323420925985902

Epoch: 6| Step: 4
Training loss: 1.6894677310378377
Validation loss: 2.3419913658185467

Epoch: 6| Step: 5
Training loss: 1.6044626912373599
Validation loss: 2.312637034587796

Epoch: 6| Step: 6
Training loss: 1.9724919316812135
Validation loss: 2.3415941349422087

Epoch: 6| Step: 7
Training loss: 2.011024607184886
Validation loss: 2.3863054897907854

Epoch: 6| Step: 8
Training loss: 2.2510877734865047
Validation loss: 2.382581151217595

Epoch: 6| Step: 9
Training loss: 1.3438258925896693
Validation loss: 2.3707502486981147

Epoch: 6| Step: 10
Training loss: 2.3693732818057933
Validation loss: 2.337227960171972

Epoch: 6| Step: 11
Training loss: 1.7657853450378294
Validation loss: 2.330040072955991

Epoch: 6| Step: 12
Training loss: 1.4666239995963575
Validation loss: 2.305353501220701

Epoch: 6| Step: 13
Training loss: 2.1627384914241476
Validation loss: 2.3842723563018926

Epoch: 226| Step: 0
Training loss: 1.8813973327937359
Validation loss: 2.3843506166920947

Epoch: 6| Step: 1
Training loss: 1.598465022263134
Validation loss: 2.3324090852835573

Epoch: 6| Step: 2
Training loss: 2.0151638715951425
Validation loss: 2.362373271867407

Epoch: 6| Step: 3
Training loss: 2.1956083159514574
Validation loss: 2.3643873671181943

Epoch: 6| Step: 4
Training loss: 1.581327456058647
Validation loss: 2.347790576080676

Epoch: 6| Step: 5
Training loss: 2.279738251903578
Validation loss: 2.3361344122256122

Epoch: 6| Step: 6
Training loss: 2.022168914327512
Validation loss: 2.324399855270538

Epoch: 6| Step: 7
Training loss: 1.7396295354802793
Validation loss: 2.323925763886406

Epoch: 6| Step: 8
Training loss: 1.8063211684412492
Validation loss: 2.3429295285762035

Epoch: 6| Step: 9
Training loss: 1.6721720921735646
Validation loss: 2.283633183131788

Epoch: 6| Step: 10
Training loss: 1.8492185024556236
Validation loss: 2.305192572032579

Epoch: 6| Step: 11
Training loss: 2.875120740925908
Validation loss: 2.3615309566587777

Epoch: 6| Step: 12
Training loss: 1.8036238272904561
Validation loss: 2.338210237644599

Epoch: 6| Step: 13
Training loss: 1.9896239298195515
Validation loss: 2.3265138369596987

Epoch: 227| Step: 0
Training loss: 1.1690036437252747
Validation loss: 2.2898178593020595

Epoch: 6| Step: 1
Training loss: 1.6357056753154449
Validation loss: 2.374555913255417

Epoch: 6| Step: 2
Training loss: 1.703650927052531
Validation loss: 2.354784473268563

Epoch: 6| Step: 3
Training loss: 1.9264441658798002
Validation loss: 2.3239141741548854

Epoch: 6| Step: 4
Training loss: 2.0701717688754537
Validation loss: 2.301697291390656

Epoch: 6| Step: 5
Training loss: 1.79095245882256
Validation loss: 2.3124083168503975

Epoch: 6| Step: 6
Training loss: 2.1793456544423755
Validation loss: 2.327725232093241

Epoch: 6| Step: 7
Training loss: 2.291838541232425
Validation loss: 2.347595173645272

Epoch: 6| Step: 8
Training loss: 1.9964575389356392
Validation loss: 2.358859377393355

Epoch: 6| Step: 9
Training loss: 2.0870209926688164
Validation loss: 2.3231346645744195

Epoch: 6| Step: 10
Training loss: 2.253728638101854
Validation loss: 2.3441639054132613

Epoch: 6| Step: 11
Training loss: 2.1621059565874625
Validation loss: 2.3085157137852077

Epoch: 6| Step: 12
Training loss: 1.8133590241089552
Validation loss: 2.3732127139242247

Epoch: 6| Step: 13
Training loss: 2.305276258881079
Validation loss: 2.3071762360158834

Epoch: 228| Step: 0
Training loss: 1.2859985003366226
Validation loss: 2.347576419074367

Epoch: 6| Step: 1
Training loss: 2.3717364927920332
Validation loss: 2.377595596577476

Epoch: 6| Step: 2
Training loss: 1.9571983890391942
Validation loss: 2.342568113882671

Epoch: 6| Step: 3
Training loss: 1.9085546226410106
Validation loss: 2.3325689956612132

Epoch: 6| Step: 4
Training loss: 2.0078970449733946
Validation loss: 2.3504662542758963

Epoch: 6| Step: 5
Training loss: 1.5970446621520404
Validation loss: 2.325657101613892

Epoch: 6| Step: 6
Training loss: 2.012804882578242
Validation loss: 2.351062412279385

Epoch: 6| Step: 7
Training loss: 2.571156928307117
Validation loss: 2.354165180571364

Epoch: 6| Step: 8
Training loss: 2.0032940202601583
Validation loss: 2.3253105810899446

Epoch: 6| Step: 9
Training loss: 1.6745746955101453
Validation loss: 2.329860833254731

Epoch: 6| Step: 10
Training loss: 1.073562643649537
Validation loss: 2.3546029145048366

Epoch: 6| Step: 11
Training loss: 2.090794541308362
Validation loss: 2.3336763005381527

Epoch: 6| Step: 12
Training loss: 1.9435620379565306
Validation loss: 2.3472480401966256

Epoch: 6| Step: 13
Training loss: 2.016192215944636
Validation loss: 2.3119849928882528

Epoch: 229| Step: 0
Training loss: 2.103135211800756
Validation loss: 2.366394624957884

Epoch: 6| Step: 1
Training loss: 1.9091332939735572
Validation loss: 2.3497027859171093

Epoch: 6| Step: 2
Training loss: 1.0486974084191536
Validation loss: 2.359499417296283

Epoch: 6| Step: 3
Training loss: 1.6766668082831888
Validation loss: 2.3479872053215316

Epoch: 6| Step: 4
Training loss: 1.82377655093637
Validation loss: 2.33315597869493

Epoch: 6| Step: 5
Training loss: 2.2461457619657237
Validation loss: 2.3380053411503616

Epoch: 6| Step: 6
Training loss: 1.7245033378447108
Validation loss: 2.311800529723173

Epoch: 6| Step: 7
Training loss: 2.4799675382520014
Validation loss: 2.318712936276296

Epoch: 6| Step: 8
Training loss: 2.3794383689432097
Validation loss: 2.2999722005600627

Epoch: 6| Step: 9
Training loss: 1.8823539840383305
Validation loss: 2.3419122399724692

Epoch: 6| Step: 10
Training loss: 1.901331324697096
Validation loss: 2.3433213835353954

Epoch: 6| Step: 11
Training loss: 2.121910991560088
Validation loss: 2.337241050209483

Epoch: 6| Step: 12
Training loss: 2.0360534213389143
Validation loss: 2.341867296974072

Epoch: 6| Step: 13
Training loss: 1.4026115820521416
Validation loss: 2.331586734700486

Epoch: 230| Step: 0
Training loss: 1.3785309537498505
Validation loss: 2.2777862023334428

Epoch: 6| Step: 1
Training loss: 2.419365942939789
Validation loss: 2.3097829091338586

Epoch: 6| Step: 2
Training loss: 2.1708559348698655
Validation loss: 2.354005309497448

Epoch: 6| Step: 3
Training loss: 1.5675354500006267
Validation loss: 2.295511049050897

Epoch: 6| Step: 4
Training loss: 1.7920406158306292
Validation loss: 2.317302926032527

Epoch: 6| Step: 5
Training loss: 1.7829290139642266
Validation loss: 2.280906024239568

Epoch: 6| Step: 6
Training loss: 1.6165369171826105
Validation loss: 2.2974792583010943

Epoch: 6| Step: 7
Training loss: 2.497031738556187
Validation loss: 2.3158545786263054

Epoch: 6| Step: 8
Training loss: 1.6384699154822555
Validation loss: 2.317417303388813

Epoch: 6| Step: 9
Training loss: 2.1952158407740794
Validation loss: 2.3484962997960865

Epoch: 6| Step: 10
Training loss: 1.66344315012822
Validation loss: 2.3503957490893916

Epoch: 6| Step: 11
Training loss: 1.7793182472260265
Validation loss: 2.318762312120267

Epoch: 6| Step: 12
Training loss: 2.2868128844168605
Validation loss: 2.3463541998090482

Epoch: 6| Step: 13
Training loss: 2.209868910858726
Validation loss: 2.300546727866848

Epoch: 231| Step: 0
Training loss: 2.429291818665344
Validation loss: 2.3562324956524057

Epoch: 6| Step: 1
Training loss: 2.1952084553997806
Validation loss: 2.356076000860422

Epoch: 6| Step: 2
Training loss: 1.5866007052396078
Validation loss: 2.331315034336786

Epoch: 6| Step: 3
Training loss: 1.573705092464308
Validation loss: 2.32923473891418

Epoch: 6| Step: 4
Training loss: 2.189531527365197
Validation loss: 2.3036298513212228

Epoch: 6| Step: 5
Training loss: 1.963045970026742
Validation loss: 2.393322438296861

Epoch: 6| Step: 6
Training loss: 2.100505236747405
Validation loss: 2.331534607231284

Epoch: 6| Step: 7
Training loss: 1.413193620165502
Validation loss: 2.3977075248680126

Epoch: 6| Step: 8
Training loss: 1.7351704740735647
Validation loss: 2.3479631354512356

Epoch: 6| Step: 9
Training loss: 1.8690927911933812
Validation loss: 2.294018245246879

Epoch: 6| Step: 10
Training loss: 1.8713986460956529
Validation loss: 2.3198182031235657

Epoch: 6| Step: 11
Training loss: 1.7448951652537266
Validation loss: 2.336401244989724

Epoch: 6| Step: 12
Training loss: 1.5861592255239068
Validation loss: 2.340538631561863

Epoch: 6| Step: 13
Training loss: 2.8536917483934094
Validation loss: 2.355120411139321

Epoch: 232| Step: 0
Training loss: 2.076347106830752
Validation loss: 2.347094237342728

Epoch: 6| Step: 1
Training loss: 2.175604273722835
Validation loss: 2.3313516260091256

Epoch: 6| Step: 2
Training loss: 1.5578026927153363
Validation loss: 2.3383620703603856

Epoch: 6| Step: 3
Training loss: 1.8457972911246499
Validation loss: 2.377013681052086

Epoch: 6| Step: 4
Training loss: 2.2562962492960454
Validation loss: 2.382605371696868

Epoch: 6| Step: 5
Training loss: 1.5171167170535866
Validation loss: 2.332560717502854

Epoch: 6| Step: 6
Training loss: 1.8986120575452354
Validation loss: 2.3528793518546123

Epoch: 6| Step: 7
Training loss: 2.6925215714776205
Validation loss: 2.3453964302439356

Epoch: 6| Step: 8
Training loss: 1.6514815297123238
Validation loss: 2.3391006820731692

Epoch: 6| Step: 9
Training loss: 1.5988421900149425
Validation loss: 2.329247676859622

Epoch: 6| Step: 10
Training loss: 1.907625358831973
Validation loss: 2.3018757449011034

Epoch: 6| Step: 11
Training loss: 1.933085796798586
Validation loss: 2.332772462943043

Epoch: 6| Step: 12
Training loss: 2.1655706665797547
Validation loss: 2.3247664118912654

Epoch: 6| Step: 13
Training loss: 1.5651491976420384
Validation loss: 2.302346854011885

Epoch: 233| Step: 0
Training loss: 2.0281435173611753
Validation loss: 2.338318763420125

Epoch: 6| Step: 1
Training loss: 1.569265595469663
Validation loss: 2.3028975838604056

Epoch: 6| Step: 2
Training loss: 1.7580349929720631
Validation loss: 2.303427524332835

Epoch: 6| Step: 3
Training loss: 1.8837162239069034
Validation loss: 2.3220249923707557

Epoch: 6| Step: 4
Training loss: 1.6352251106704356
Validation loss: 2.297983991883408

Epoch: 6| Step: 5
Training loss: 1.698070760962163
Validation loss: 2.344602640580202

Epoch: 6| Step: 6
Training loss: 2.05430802586879
Validation loss: 2.3276130023536252

Epoch: 6| Step: 7
Training loss: 2.4837768602382697
Validation loss: 2.3193303591494354

Epoch: 6| Step: 8
Training loss: 2.614208473193119
Validation loss: 2.273908043117299

Epoch: 6| Step: 9
Training loss: 1.545403676674805
Validation loss: 2.356185192188387

Epoch: 6| Step: 10
Training loss: 1.5855425262955423
Validation loss: 2.353561990892469

Epoch: 6| Step: 11
Training loss: 1.9822306423312532
Validation loss: 2.3016775669435225

Epoch: 6| Step: 12
Training loss: 1.7749441863405235
Validation loss: 2.3806373112867827

Epoch: 6| Step: 13
Training loss: 1.989781561225305
Validation loss: 2.354236404281892

Epoch: 234| Step: 0
Training loss: 2.2279176035015174
Validation loss: 2.327411230291679

Epoch: 6| Step: 1
Training loss: 2.4669700676532873
Validation loss: 2.299323475628715

Epoch: 6| Step: 2
Training loss: 2.2688143676370136
Validation loss: 2.2836823306832033

Epoch: 6| Step: 3
Training loss: 1.775238198429532
Validation loss: 2.3026743276737265

Epoch: 6| Step: 4
Training loss: 0.9538440805932081
Validation loss: 2.3269297814676637

Epoch: 6| Step: 5
Training loss: 1.894867857298961
Validation loss: 2.3272408199884773

Epoch: 6| Step: 6
Training loss: 1.9328008702266704
Validation loss: 2.311050065802856

Epoch: 6| Step: 7
Training loss: 1.6871844102548936
Validation loss: 2.3633150672374486

Epoch: 6| Step: 8
Training loss: 2.4698146021526286
Validation loss: 2.3486625667625876

Epoch: 6| Step: 9
Training loss: 1.6582694787362748
Validation loss: 2.3172157238803224

Epoch: 6| Step: 10
Training loss: 1.830008490183162
Validation loss: 2.3635277718770684

Epoch: 6| Step: 11
Training loss: 1.5584158353674644
Validation loss: 2.327431407458907

Epoch: 6| Step: 12
Training loss: 2.152149447828513
Validation loss: 2.3231953124949856

Epoch: 6| Step: 13
Training loss: 1.1292215190857193
Validation loss: 2.333691568020192

Epoch: 235| Step: 0
Training loss: 2.2143165458782854
Validation loss: 2.3824503875801697

Epoch: 6| Step: 1
Training loss: 1.627153583463985
Validation loss: 2.3455621999555674

Epoch: 6| Step: 2
Training loss: 2.1322823448952652
Validation loss: 2.3169853768796194

Epoch: 6| Step: 3
Training loss: 2.007098950602527
Validation loss: 2.3147614968994654

Epoch: 6| Step: 4
Training loss: 1.7931784380465456
Validation loss: 2.283678633427611

Epoch: 6| Step: 5
Training loss: 1.785321918705087
Validation loss: 2.2922658429709792

Epoch: 6| Step: 6
Training loss: 1.8317539680347388
Validation loss: 2.325822422578412

Epoch: 6| Step: 7
Training loss: 1.972544087157813
Validation loss: 2.327513845859052

Epoch: 6| Step: 8
Training loss: 2.014299533529909
Validation loss: 2.2933697428922826

Epoch: 6| Step: 9
Training loss: 1.5970545150873112
Validation loss: 2.2826214290954927

Epoch: 6| Step: 10
Training loss: 1.8875865638537639
Validation loss: 2.304026079661124

Epoch: 6| Step: 11
Training loss: 2.041925634451671
Validation loss: 2.34024097016117

Epoch: 6| Step: 12
Training loss: 1.5938784977591285
Validation loss: 2.331954366927791

Epoch: 6| Step: 13
Training loss: 2.8005956697364724
Validation loss: 2.3413722100959187

Epoch: 236| Step: 0
Training loss: 1.4855544373698193
Validation loss: 2.317172146743419

Epoch: 6| Step: 1
Training loss: 1.0673647754258546
Validation loss: 2.357265384943673

Epoch: 6| Step: 2
Training loss: 1.9301003697836454
Validation loss: 2.3071432871255593

Epoch: 6| Step: 3
Training loss: 2.17446689868748
Validation loss: 2.359518315043273

Epoch: 6| Step: 4
Training loss: 2.069922529235955
Validation loss: 2.3464272688815906

Epoch: 6| Step: 5
Training loss: 1.8368555249261995
Validation loss: 2.3475894568695614

Epoch: 6| Step: 6
Training loss: 2.0199418084100325
Validation loss: 2.3301738305428454

Epoch: 6| Step: 7
Training loss: 1.8685784047422762
Validation loss: 2.3022891600218096

Epoch: 6| Step: 8
Training loss: 2.3012451325986194
Validation loss: 2.3154343045137877

Epoch: 6| Step: 9
Training loss: 1.9498984579400167
Validation loss: 2.335672247490207

Epoch: 6| Step: 10
Training loss: 1.7206380011264455
Validation loss: 2.3108998654517974

Epoch: 6| Step: 11
Training loss: 1.896300443457389
Validation loss: 2.3643834257837044

Epoch: 6| Step: 12
Training loss: 1.655217406638332
Validation loss: 2.329484612908421

Epoch: 6| Step: 13
Training loss: 2.804489256246727
Validation loss: 2.3728023955259925

Epoch: 237| Step: 0
Training loss: 1.862930680730409
Validation loss: 2.375747161590573

Epoch: 6| Step: 1
Training loss: 1.836748958389529
Validation loss: 2.3073124368076674

Epoch: 6| Step: 2
Training loss: 1.7315985648917889
Validation loss: 2.344713852103981

Epoch: 6| Step: 3
Training loss: 1.62555773040378
Validation loss: 2.281644808073975

Epoch: 6| Step: 4
Training loss: 1.5616309991927575
Validation loss: 2.3187806949806657

Epoch: 6| Step: 5
Training loss: 1.4656937637953282
Validation loss: 2.3848048226717897

Epoch: 6| Step: 6
Training loss: 1.9969263300021998
Validation loss: 2.3430872767077444

Epoch: 6| Step: 7
Training loss: 1.9404130386843959
Validation loss: 2.3467173976316986

Epoch: 6| Step: 8
Training loss: 2.2306508860070733
Validation loss: 2.3242235083879015

Epoch: 6| Step: 9
Training loss: 1.8956339664920052
Validation loss: 2.3319899043366292

Epoch: 6| Step: 10
Training loss: 2.1683342702845496
Validation loss: 2.357026589865358

Epoch: 6| Step: 11
Training loss: 1.52181035713284
Validation loss: 2.376631852397365

Epoch: 6| Step: 12
Training loss: 1.885081526614765
Validation loss: 2.3368437880104342

Epoch: 6| Step: 13
Training loss: 3.4085609925834
Validation loss: 2.43000708791122

Epoch: 238| Step: 0
Training loss: 1.8819357069062133
Validation loss: 2.3203366644573213

Epoch: 6| Step: 1
Training loss: 1.393358052314321
Validation loss: 2.29668152746097

Epoch: 6| Step: 2
Training loss: 1.7126947723781079
Validation loss: 2.327503658523681

Epoch: 6| Step: 3
Training loss: 1.9445645529874995
Validation loss: 2.332290075223969

Epoch: 6| Step: 4
Training loss: 1.7259941719195473
Validation loss: 2.3409895218448153

Epoch: 6| Step: 5
Training loss: 1.5199083973236291
Validation loss: 2.2999611421916692

Epoch: 6| Step: 6
Training loss: 2.4005059384489273
Validation loss: 2.356932301016196

Epoch: 6| Step: 7
Training loss: 1.8445956343740508
Validation loss: 2.3523739119495617

Epoch: 6| Step: 8
Training loss: 2.3504171528776556
Validation loss: 2.3395338281719975

Epoch: 6| Step: 9
Training loss: 2.3929721056360123
Validation loss: 2.3733936656838575

Epoch: 6| Step: 10
Training loss: 1.741895026730707
Validation loss: 2.304254019523619

Epoch: 6| Step: 11
Training loss: 1.6323128259679447
Validation loss: 2.3112843440856663

Epoch: 6| Step: 12
Training loss: 2.496691039831814
Validation loss: 2.307939186939904

Epoch: 6| Step: 13
Training loss: 1.4777246977579725
Validation loss: 2.3292253867875576

Epoch: 239| Step: 0
Training loss: 2.2432613127523195
Validation loss: 2.3082333786968574

Epoch: 6| Step: 1
Training loss: 1.5010713883615807
Validation loss: 2.318239959954055

Epoch: 6| Step: 2
Training loss: 1.5755859950018196
Validation loss: 2.3827994150077827

Epoch: 6| Step: 3
Training loss: 1.8670025338848881
Validation loss: 2.3269841058746707

Epoch: 6| Step: 4
Training loss: 1.7888310045285025
Validation loss: 2.3557302406390224

Epoch: 6| Step: 5
Training loss: 1.6482477304867396
Validation loss: 2.3495295045969464

Epoch: 6| Step: 6
Training loss: 2.8452305555196227
Validation loss: 2.319293307695735

Epoch: 6| Step: 7
Training loss: 2.0123377764222425
Validation loss: 2.3338588907926163

Epoch: 6| Step: 8
Training loss: 1.9903431451815763
Validation loss: 2.3532801160390484

Epoch: 6| Step: 9
Training loss: 1.972482805841927
Validation loss: 2.332485236752606

Epoch: 6| Step: 10
Training loss: 1.6800147868822661
Validation loss: 2.3503788149428404

Epoch: 6| Step: 11
Training loss: 1.7383658742129557
Validation loss: 2.322522980975129

Epoch: 6| Step: 12
Training loss: 2.151083464751347
Validation loss: 2.3708608857302056

Epoch: 6| Step: 13
Training loss: 1.4101194339923353
Validation loss: 2.292698603403569

Epoch: 240| Step: 0
Training loss: 2.4882025833510175
Validation loss: 2.319554058256489

Epoch: 6| Step: 1
Training loss: 1.7751162477493359
Validation loss: 2.3092143145009274

Epoch: 6| Step: 2
Training loss: 2.009273605992119
Validation loss: 2.276872284288015

Epoch: 6| Step: 3
Training loss: 2.2287659567167064
Validation loss: 2.304624150821888

Epoch: 6| Step: 4
Training loss: 1.9912028553393173
Validation loss: 2.309878648148631

Epoch: 6| Step: 5
Training loss: 1.6043068795627151
Validation loss: 2.3424202021195586

Epoch: 6| Step: 6
Training loss: 1.826337282574185
Validation loss: 2.316496059550761

Epoch: 6| Step: 7
Training loss: 1.5407656622812775
Validation loss: 2.3243061576270807

Epoch: 6| Step: 8
Training loss: 1.8408431074517029
Validation loss: 2.3201814091509854

Epoch: 6| Step: 9
Training loss: 1.9219952677490852
Validation loss: 2.3155670247769398

Epoch: 6| Step: 10
Training loss: 1.577881142688403
Validation loss: 2.3443443381538085

Epoch: 6| Step: 11
Training loss: 1.616744344686961
Validation loss: 2.339476455127432

Epoch: 6| Step: 12
Training loss: 1.6877168586696767
Validation loss: 2.312999045134237

Epoch: 6| Step: 13
Training loss: 1.8988775049509101
Validation loss: 2.2941879159331497

Epoch: 241| Step: 0
Training loss: 2.157838429841432
Validation loss: 2.3599654856866437

Epoch: 6| Step: 1
Training loss: 2.3837402538786447
Validation loss: 2.312849551064173

Epoch: 6| Step: 2
Training loss: 1.7472851676027124
Validation loss: 2.256841232699622

Epoch: 6| Step: 3
Training loss: 1.8170101351457932
Validation loss: 2.282653009677119

Epoch: 6| Step: 4
Training loss: 1.7841961906350534
Validation loss: 2.3518246576893067

Epoch: 6| Step: 5
Training loss: 1.8490523050274417
Validation loss: 2.3514414927760496

Epoch: 6| Step: 6
Training loss: 1.709800028569222
Validation loss: 2.3578161191062064

Epoch: 6| Step: 7
Training loss: 1.3485409693620634
Validation loss: 2.339079227889531

Epoch: 6| Step: 8
Training loss: 2.1532022802826614
Validation loss: 2.3329164506886833

Epoch: 6| Step: 9
Training loss: 1.5000499875958317
Validation loss: 2.4003673080974886

Epoch: 6| Step: 10
Training loss: 2.0757345347232095
Validation loss: 2.3341785552134273

Epoch: 6| Step: 11
Training loss: 1.957134434460127
Validation loss: 2.3622496625128746

Epoch: 6| Step: 12
Training loss: 1.743502407202496
Validation loss: 2.301153433287937

Epoch: 6| Step: 13
Training loss: 2.1579973079533796
Validation loss: 2.324302350170523

Epoch: 242| Step: 0
Training loss: 2.10756758503453
Validation loss: 2.36936654532007

Epoch: 6| Step: 1
Training loss: 2.18697263627797
Validation loss: 2.26507891282009

Epoch: 6| Step: 2
Training loss: 1.9193501829172046
Validation loss: 2.357928316536779

Epoch: 6| Step: 3
Training loss: 1.6665561957305346
Validation loss: 2.356417267749203

Epoch: 6| Step: 4
Training loss: 1.6110574760863319
Validation loss: 2.3947970142415502

Epoch: 6| Step: 5
Training loss: 1.9583792850162383
Validation loss: 2.306838334356497

Epoch: 6| Step: 6
Training loss: 1.7694927152433593
Validation loss: 2.2838563570495296

Epoch: 6| Step: 7
Training loss: 2.028448079712928
Validation loss: 2.3220144828583624

Epoch: 6| Step: 8
Training loss: 1.7895953455186187
Validation loss: 2.3507895651548028

Epoch: 6| Step: 9
Training loss: 1.7347665980438753
Validation loss: 2.3135917268290944

Epoch: 6| Step: 10
Training loss: 1.4780379094280847
Validation loss: 2.282324377960689

Epoch: 6| Step: 11
Training loss: 1.9409472654038948
Validation loss: 2.384082395416358

Epoch: 6| Step: 12
Training loss: 1.856245918140997
Validation loss: 2.3342934400610296

Epoch: 6| Step: 13
Training loss: 2.1298775513246
Validation loss: 2.3168984012257425

Epoch: 243| Step: 0
Training loss: 1.040218312751508
Validation loss: 2.3163781620814174

Epoch: 6| Step: 1
Training loss: 2.060642099214094
Validation loss: 2.321869462960234

Epoch: 6| Step: 2
Training loss: 1.7676972238449686
Validation loss: 2.322097073823855

Epoch: 6| Step: 3
Training loss: 2.1985137514122868
Validation loss: 2.321610234612566

Epoch: 6| Step: 4
Training loss: 2.2059626059799684
Validation loss: 2.3190603536491183

Epoch: 6| Step: 5
Training loss: 2.310034391138935
Validation loss: 2.324908180112968

Epoch: 6| Step: 6
Training loss: 1.5676292154449978
Validation loss: 2.299855153711197

Epoch: 6| Step: 7
Training loss: 1.549141350686876
Validation loss: 2.332717591959809

Epoch: 6| Step: 8
Training loss: 2.148375465191039
Validation loss: 2.3791484374399334

Epoch: 6| Step: 9
Training loss: 1.8831754469167867
Validation loss: 2.3544315628686108

Epoch: 6| Step: 10
Training loss: 1.3738702120610313
Validation loss: 2.35126758399972

Epoch: 6| Step: 11
Training loss: 1.7637486573125647
Validation loss: 2.3403100346157535

Epoch: 6| Step: 12
Training loss: 2.1931737072184183
Validation loss: 2.3501854632888044

Epoch: 6| Step: 13
Training loss: 1.8854004102255473
Validation loss: 2.3260718139410015

Epoch: 244| Step: 0
Training loss: 2.3727948843830755
Validation loss: 2.328729887203579

Epoch: 6| Step: 1
Training loss: 1.7915856838406374
Validation loss: 2.332946038369106

Epoch: 6| Step: 2
Training loss: 2.409047370929447
Validation loss: 2.3810171393554684

Epoch: 6| Step: 3
Training loss: 2.3637244951716996
Validation loss: 2.3355405188049514

Epoch: 6| Step: 4
Training loss: 1.611693110888454
Validation loss: 2.3104374436225865

Epoch: 6| Step: 5
Training loss: 2.1818090252611895
Validation loss: 2.3497349067226465

Epoch: 6| Step: 6
Training loss: 1.6722458757830698
Validation loss: 2.3229805354347217

Epoch: 6| Step: 7
Training loss: 1.681639207225738
Validation loss: 2.30682167113136

Epoch: 6| Step: 8
Training loss: 1.1295178086766928
Validation loss: 2.3376782377255103

Epoch: 6| Step: 9
Training loss: 1.0529926386663733
Validation loss: 2.357385937981228

Epoch: 6| Step: 10
Training loss: 1.6324033817832968
Validation loss: 2.337469531620683

Epoch: 6| Step: 11
Training loss: 2.019043618217096
Validation loss: 2.3324269945776033

Epoch: 6| Step: 12
Training loss: 1.3536408601762222
Validation loss: 2.3456597940268775

Epoch: 6| Step: 13
Training loss: 2.3477156595085384
Validation loss: 2.3663138357814297

Epoch: 245| Step: 0
Training loss: 2.1023855193151832
Validation loss: 2.291622692443222

Epoch: 6| Step: 1
Training loss: 1.5498071489032124
Validation loss: 2.2822083440758147

Epoch: 6| Step: 2
Training loss: 1.717316185500342
Validation loss: 2.311350948542551

Epoch: 6| Step: 3
Training loss: 1.955607979817143
Validation loss: 2.3084008609426006

Epoch: 6| Step: 4
Training loss: 1.7451806465142499
Validation loss: 2.335706537450744

Epoch: 6| Step: 5
Training loss: 1.5619238744983006
Validation loss: 2.3360269295970157

Epoch: 6| Step: 6
Training loss: 2.6303945242569537
Validation loss: 2.318545631703099

Epoch: 6| Step: 7
Training loss: 1.688911130546769
Validation loss: 2.307109963293222

Epoch: 6| Step: 8
Training loss: 1.5797668074896822
Validation loss: 2.3526608229015413

Epoch: 6| Step: 9
Training loss: 1.7669279304189391
Validation loss: 2.3480138986228614

Epoch: 6| Step: 10
Training loss: 1.6270389236596012
Validation loss: 2.3719983965046842

Epoch: 6| Step: 11
Training loss: 1.922996937849014
Validation loss: 2.327055136960293

Epoch: 6| Step: 12
Training loss: 1.8583289016647981
Validation loss: 2.2966449408312717

Epoch: 6| Step: 13
Training loss: 1.5226349110328918
Validation loss: 2.328664298346078

Epoch: 246| Step: 0
Training loss: 2.201475242688671
Validation loss: 2.334586704138223

Epoch: 6| Step: 1
Training loss: 1.9362562556008736
Validation loss: 2.3220277933536866

Epoch: 6| Step: 2
Training loss: 1.557343710685692
Validation loss: 2.321961247842639

Epoch: 6| Step: 3
Training loss: 1.5207671407987493
Validation loss: 2.361497081847221

Epoch: 6| Step: 4
Training loss: 1.706762506555666
Validation loss: 2.340538102521859

Epoch: 6| Step: 5
Training loss: 1.3360017459880817
Validation loss: 2.3532086825406147

Epoch: 6| Step: 6
Training loss: 1.9581752334516858
Validation loss: 2.346279753919417

Epoch: 6| Step: 7
Training loss: 2.0728079097978207
Validation loss: 2.31125696647853

Epoch: 6| Step: 8
Training loss: 1.8561705858088113
Validation loss: 2.3229042081215066

Epoch: 6| Step: 9
Training loss: 1.8993055454822132
Validation loss: 2.3855011025836528

Epoch: 6| Step: 10
Training loss: 2.2212024083832542
Validation loss: 2.340327888925102

Epoch: 6| Step: 11
Training loss: 1.8927629221166606
Validation loss: 2.339618067797262

Epoch: 6| Step: 12
Training loss: 2.016461457564952
Validation loss: 2.263758548053111

Epoch: 6| Step: 13
Training loss: 1.9836148585803612
Validation loss: 2.297374505559429

Epoch: 247| Step: 0
Training loss: 2.156084800694454
Validation loss: 2.2934624665765178

Epoch: 6| Step: 1
Training loss: 1.5155243987684028
Validation loss: 2.319353683567862

Epoch: 6| Step: 2
Training loss: 1.7268618501099717
Validation loss: 2.285480009005042

Epoch: 6| Step: 3
Training loss: 1.798276603388453
Validation loss: 2.3451703297041564

Epoch: 6| Step: 4
Training loss: 2.105578474536834
Validation loss: 2.382154707789247

Epoch: 6| Step: 5
Training loss: 1.7298114983721529
Validation loss: 2.3869289110107017

Epoch: 6| Step: 6
Training loss: 1.7739985582588813
Validation loss: 2.3357510271586785

Epoch: 6| Step: 7
Training loss: 2.4117091290844606
Validation loss: 2.33648797194175

Epoch: 6| Step: 8
Training loss: 1.8076633507240172
Validation loss: 2.360045556903926

Epoch: 6| Step: 9
Training loss: 1.372164229575985
Validation loss: 2.3345939187312474

Epoch: 6| Step: 10
Training loss: 1.77676227825233
Validation loss: 2.338423866959006

Epoch: 6| Step: 11
Training loss: 1.456276460333514
Validation loss: 2.3420071264119504

Epoch: 6| Step: 12
Training loss: 1.8324985843460422
Validation loss: 2.381380955334111

Epoch: 6| Step: 13
Training loss: 2.036808331812788
Validation loss: 2.2860526184344288

Epoch: 248| Step: 0
Training loss: 2.1622823837242238
Validation loss: 2.3533345228320757

Epoch: 6| Step: 1
Training loss: 1.618621779853787
Validation loss: 2.3785479349983456

Epoch: 6| Step: 2
Training loss: 2.477714583480095
Validation loss: 2.3502320203218106

Epoch: 6| Step: 3
Training loss: 1.648168822173532
Validation loss: 2.323726007228829

Epoch: 6| Step: 4
Training loss: 1.5376020754293036
Validation loss: 2.3386389917222634

Epoch: 6| Step: 5
Training loss: 1.6549676933477524
Validation loss: 2.350796592613069

Epoch: 6| Step: 6
Training loss: 1.7250018078338438
Validation loss: 2.3288052684027116

Epoch: 6| Step: 7
Training loss: 1.693328399550892
Validation loss: 2.301410315155249

Epoch: 6| Step: 8
Training loss: 1.9670285767465787
Validation loss: 2.3264750505765415

Epoch: 6| Step: 9
Training loss: 1.9277039499403748
Validation loss: 2.3878590448960635

Epoch: 6| Step: 10
Training loss: 1.4346399465634696
Validation loss: 2.38194544506631

Epoch: 6| Step: 11
Training loss: 2.0759630932623545
Validation loss: 2.3257976934405105

Epoch: 6| Step: 12
Training loss: 1.6863166757441925
Validation loss: 2.315760185962408

Epoch: 6| Step: 13
Training loss: 1.4185386332218348
Validation loss: 2.2823945154006067

Epoch: 249| Step: 0
Training loss: 1.9696064857115823
Validation loss: 2.3482315674126197

Epoch: 6| Step: 1
Training loss: 2.2524286514142715
Validation loss: 2.3370689993215197

Epoch: 6| Step: 2
Training loss: 1.592132270910794
Validation loss: 2.350356542026881

Epoch: 6| Step: 3
Training loss: 2.1285093164936795
Validation loss: 2.35526132211928

Epoch: 6| Step: 4
Training loss: 2.055958517917782
Validation loss: 2.329171995188091

Epoch: 6| Step: 5
Training loss: 1.9848625605395371
Validation loss: 2.3172886673943425

Epoch: 6| Step: 6
Training loss: 1.8695522640336888
Validation loss: 2.3343944714962985

Epoch: 6| Step: 7
Training loss: 1.4383542383707368
Validation loss: 2.359383742575613

Epoch: 6| Step: 8
Training loss: 1.7759102542471388
Validation loss: 2.324051682935975

Epoch: 6| Step: 9
Training loss: 1.1674927216656263
Validation loss: 2.325241625140364

Epoch: 6| Step: 10
Training loss: 1.9507632815778966
Validation loss: 2.3514185272580725

Epoch: 6| Step: 11
Training loss: 1.6067430029076144
Validation loss: 2.338718885467982

Epoch: 6| Step: 12
Training loss: 1.897054034712801
Validation loss: 2.3702163669115555

Epoch: 6| Step: 13
Training loss: 1.6465687215430136
Validation loss: 2.3486543453282547

Epoch: 250| Step: 0
Training loss: 1.7598885039212373
Validation loss: 2.3182691643333535

Epoch: 6| Step: 1
Training loss: 1.5565458146805262
Validation loss: 2.307399570474618

Epoch: 6| Step: 2
Training loss: 1.808192428982461
Validation loss: 2.3171912049269214

Epoch: 6| Step: 3
Training loss: 1.4090788045765996
Validation loss: 2.324471890100414

Epoch: 6| Step: 4
Training loss: 1.8353866075297955
Validation loss: 2.3467399836555325

Epoch: 6| Step: 5
Training loss: 2.094950659086645
Validation loss: 2.345747013638949

Epoch: 6| Step: 6
Training loss: 1.9955002710566363
Validation loss: 2.3498287512277765

Epoch: 6| Step: 7
Training loss: 1.9132873834127715
Validation loss: 2.3012632342915946

Epoch: 6| Step: 8
Training loss: 2.5078173485824915
Validation loss: 2.3511083609520087

Epoch: 6| Step: 9
Training loss: 1.9165281646553902
Validation loss: 2.32107792179991

Epoch: 6| Step: 10
Training loss: 1.9586684636890503
Validation loss: 2.3167652858383176

Epoch: 6| Step: 11
Training loss: 1.8803052234429614
Validation loss: 2.360249771777834

Epoch: 6| Step: 12
Training loss: 1.3714245780179941
Validation loss: 2.3077437653416872

Epoch: 6| Step: 13
Training loss: 1.4509577843527623
Validation loss: 2.328800782477764

Epoch: 251| Step: 0
Training loss: 1.6894877700340434
Validation loss: 2.3248958851462618

Epoch: 6| Step: 1
Training loss: 1.9980042155644238
Validation loss: 2.34896559146056

Epoch: 6| Step: 2
Training loss: 1.8967786535087572
Validation loss: 2.290219935590144

Epoch: 6| Step: 3
Training loss: 1.7213599069781447
Validation loss: 2.3872884573215885

Epoch: 6| Step: 4
Training loss: 1.6613142216125547
Validation loss: 2.332017597547338

Epoch: 6| Step: 5
Training loss: 1.9402417503233653
Validation loss: 2.328297292849243

Epoch: 6| Step: 6
Training loss: 1.761972751618909
Validation loss: 2.3628428225461633

Epoch: 6| Step: 7
Training loss: 1.8658858354935817
Validation loss: 2.258812088499629

Epoch: 6| Step: 8
Training loss: 1.3470229720328244
Validation loss: 2.3711295679196884

Epoch: 6| Step: 9
Training loss: 1.4514283150038692
Validation loss: 2.314657153590741

Epoch: 6| Step: 10
Training loss: 1.4542107576318863
Validation loss: 2.275421895831533

Epoch: 6| Step: 11
Training loss: 2.1200535368007496
Validation loss: 2.3359879565670547

Epoch: 6| Step: 12
Training loss: 2.6550036928542724
Validation loss: 2.3099668786246847

Epoch: 6| Step: 13
Training loss: 1.8066784334092816
Validation loss: 2.3913874146669536

Epoch: 252| Step: 0
Training loss: 1.725797872260375
Validation loss: 2.3519498286482086

Epoch: 6| Step: 1
Training loss: 1.5192031309962337
Validation loss: 2.3529340838841764

Epoch: 6| Step: 2
Training loss: 1.972507826254129
Validation loss: 2.3172293639709034

Epoch: 6| Step: 3
Training loss: 1.985155868079859
Validation loss: 2.3345768771019038

Epoch: 6| Step: 4
Training loss: 1.4160581385051205
Validation loss: 2.290682736001714

Epoch: 6| Step: 5
Training loss: 1.9432739239025727
Validation loss: 2.343386757981096

Epoch: 6| Step: 6
Training loss: 1.8609981344419677
Validation loss: 2.3348309880673783

Epoch: 6| Step: 7
Training loss: 1.2867571937918771
Validation loss: 2.364621954681963

Epoch: 6| Step: 8
Training loss: 1.5201584176279321
Validation loss: 2.374495358223372

Epoch: 6| Step: 9
Training loss: 2.6179553371667557
Validation loss: 2.3561916758525654

Epoch: 6| Step: 10
Training loss: 1.5756139134006029
Validation loss: 2.3219933317546455

Epoch: 6| Step: 11
Training loss: 1.483271298915105
Validation loss: 2.325279416687201

Epoch: 6| Step: 12
Training loss: 2.1603615302833736
Validation loss: 2.346441379406001

Epoch: 6| Step: 13
Training loss: 2.046667772825027
Validation loss: 2.3141104963831314

Epoch: 253| Step: 0
Training loss: 1.9752129934842233
Validation loss: 2.2867406201369302

Epoch: 6| Step: 1
Training loss: 1.5080152780431786
Validation loss: 2.2939219339689427

Epoch: 6| Step: 2
Training loss: 1.8395424371351807
Validation loss: 2.3133765147294607

Epoch: 6| Step: 3
Training loss: 1.9814721449252073
Validation loss: 2.3400925558054633

Epoch: 6| Step: 4
Training loss: 2.422731900133466
Validation loss: 2.4010529282408797

Epoch: 6| Step: 5
Training loss: 1.9806637037882713
Validation loss: 2.333365064030197

Epoch: 6| Step: 6
Training loss: 1.4972182547273523
Validation loss: 2.3467434826945786

Epoch: 6| Step: 7
Training loss: 2.0709805544350592
Validation loss: 2.3316917909598254

Epoch: 6| Step: 8
Training loss: 1.5743092399695775
Validation loss: 2.340634930185146

Epoch: 6| Step: 9
Training loss: 1.8078427166338165
Validation loss: 2.2610582333693365

Epoch: 6| Step: 10
Training loss: 1.816338059980954
Validation loss: 2.3052097958586897

Epoch: 6| Step: 11
Training loss: 1.6408362116416277
Validation loss: 2.3184479146751946

Epoch: 6| Step: 12
Training loss: 1.6960882003180309
Validation loss: 2.2978456840350865

Epoch: 6| Step: 13
Training loss: 1.5270762489782497
Validation loss: 2.3333513226965605

Epoch: 254| Step: 0
Training loss: 1.6681445562903572
Validation loss: 2.3480091868099247

Epoch: 6| Step: 1
Training loss: 1.3671752929142538
Validation loss: 2.353304163118642

Epoch: 6| Step: 2
Training loss: 1.53913244098199
Validation loss: 2.364433218125789

Epoch: 6| Step: 3
Training loss: 2.2901460862518164
Validation loss: 2.3055693132250563

Epoch: 6| Step: 4
Training loss: 2.0769374580646174
Validation loss: 2.3293879886921682

Epoch: 6| Step: 5
Training loss: 1.4547448922379174
Validation loss: 2.340206179184862

Epoch: 6| Step: 6
Training loss: 1.7680051846190852
Validation loss: 2.328211296944899

Epoch: 6| Step: 7
Training loss: 1.5900422143430484
Validation loss: 2.307019001598507

Epoch: 6| Step: 8
Training loss: 1.971063616836405
Validation loss: 2.339604417977663

Epoch: 6| Step: 9
Training loss: 2.6591606797888425
Validation loss: 2.299670313987482

Epoch: 6| Step: 10
Training loss: 1.3358572774078965
Validation loss: 2.321202927339297

Epoch: 6| Step: 11
Training loss: 1.4784801483937267
Validation loss: 2.348532668664844

Epoch: 6| Step: 12
Training loss: 2.2245962998271374
Validation loss: 2.3373225942054163

Epoch: 6| Step: 13
Training loss: 1.9422119433705456
Validation loss: 2.3452618552663407

Epoch: 255| Step: 0
Training loss: 2.5853608286501997
Validation loss: 2.3192386439695096

Epoch: 6| Step: 1
Training loss: 1.623006551634139
Validation loss: 2.346470332210151

Epoch: 6| Step: 2
Training loss: 1.9283379534526177
Validation loss: 2.311287282313385

Epoch: 6| Step: 3
Training loss: 1.8115433108327013
Validation loss: 2.3802559685981906

Epoch: 6| Step: 4
Training loss: 2.002352165832575
Validation loss: 2.3557022668189873

Epoch: 6| Step: 5
Training loss: 1.9562481133692604
Validation loss: 2.3273097469963746

Epoch: 6| Step: 6
Training loss: 1.6333952963357636
Validation loss: 2.331232759910723

Epoch: 6| Step: 7
Training loss: 1.621433452265159
Validation loss: 2.2951895751373645

Epoch: 6| Step: 8
Training loss: 1.4089897170466594
Validation loss: 2.3217133754468

Epoch: 6| Step: 9
Training loss: 1.733892837724172
Validation loss: 2.386308816937937

Epoch: 6| Step: 10
Training loss: 1.612008837630702
Validation loss: 2.332168297771972

Epoch: 6| Step: 11
Training loss: 1.5001808693241077
Validation loss: 2.3412906051208684

Epoch: 6| Step: 12
Training loss: 1.9573110658321418
Validation loss: 2.3800528434163506

Epoch: 6| Step: 13
Training loss: 1.4052436194526956
Validation loss: 2.3646019669294103

Epoch: 256| Step: 0
Training loss: 1.7865955385359749
Validation loss: 2.3459155151928335

Epoch: 6| Step: 1
Training loss: 2.253808083867446
Validation loss: 2.390314669556745

Epoch: 6| Step: 2
Training loss: 1.2550902673850466
Validation loss: 2.3535574279784375

Epoch: 6| Step: 3
Training loss: 1.7308703230001734
Validation loss: 2.2884063894755746

Epoch: 6| Step: 4
Training loss: 2.1056324854440587
Validation loss: 2.333375180729106

Epoch: 6| Step: 5
Training loss: 1.435944835490521
Validation loss: 2.3144304997072225

Epoch: 6| Step: 6
Training loss: 1.7582765771947317
Validation loss: 2.32839135122413

Epoch: 6| Step: 7
Training loss: 1.2722370597764459
Validation loss: 2.294078380854391

Epoch: 6| Step: 8
Training loss: 1.8329912285519439
Validation loss: 2.320969000757876

Epoch: 6| Step: 9
Training loss: 1.9036047044338795
Validation loss: 2.360523937531936

Epoch: 6| Step: 10
Training loss: 2.543598056163666
Validation loss: 2.344970617988108

Epoch: 6| Step: 11
Training loss: 1.6157940744736397
Validation loss: 2.338070529811653

Epoch: 6| Step: 12
Training loss: 1.6712568334583848
Validation loss: 2.3731396658529724

Epoch: 6| Step: 13
Training loss: 1.4714775731370286
Validation loss: 2.3197232440041113

Epoch: 257| Step: 0
Training loss: 1.079137133534201
Validation loss: 2.312818331815266

Epoch: 6| Step: 1
Training loss: 1.1578010774736238
Validation loss: 2.4019925600876064

Epoch: 6| Step: 2
Training loss: 1.5554831304417112
Validation loss: 2.310629110308599

Epoch: 6| Step: 3
Training loss: 1.529836897914075
Validation loss: 2.337007783397043

Epoch: 6| Step: 4
Training loss: 1.6631795483875338
Validation loss: 2.3734471023988455

Epoch: 6| Step: 5
Training loss: 1.8250595866887742
Validation loss: 2.3425620488659438

Epoch: 6| Step: 6
Training loss: 1.7041436744886156
Validation loss: 2.2746349198196194

Epoch: 6| Step: 7
Training loss: 2.560262400917913
Validation loss: 2.2893941940570803

Epoch: 6| Step: 8
Training loss: 1.9391286834070005
Validation loss: 2.333033506918406

Epoch: 6| Step: 9
Training loss: 1.9996561708543152
Validation loss: 2.345673694955183

Epoch: 6| Step: 10
Training loss: 1.9512505653864392
Validation loss: 2.342365106766025

Epoch: 6| Step: 11
Training loss: 1.9187426588682217
Validation loss: 2.338431910581575

Epoch: 6| Step: 12
Training loss: 1.6938729920723379
Validation loss: 2.3471744232576053

Epoch: 6| Step: 13
Training loss: 2.0278485502088732
Validation loss: 2.338083287287117

Epoch: 258| Step: 0
Training loss: 2.080039039208776
Validation loss: 2.2714476516950914

Epoch: 6| Step: 1
Training loss: 1.6278243828887378
Validation loss: 2.325877208779614

Epoch: 6| Step: 2
Training loss: 1.5624709317364476
Validation loss: 2.3987913809588277

Epoch: 6| Step: 3
Training loss: 1.8796397976042625
Validation loss: 2.311552996237

Epoch: 6| Step: 4
Training loss: 1.8831146757524624
Validation loss: 2.337023345590307

Epoch: 6| Step: 5
Training loss: 1.5874275761701921
Validation loss: 2.2941522544692816

Epoch: 6| Step: 6
Training loss: 1.8801219916838592
Validation loss: 2.380617160242272

Epoch: 6| Step: 7
Training loss: 2.2345892530034845
Validation loss: 2.324816115146072

Epoch: 6| Step: 8
Training loss: 2.0905687447179537
Validation loss: 2.3200366100393706

Epoch: 6| Step: 9
Training loss: 1.4124418634924312
Validation loss: 2.271508935875921

Epoch: 6| Step: 10
Training loss: 1.6842337894166355
Validation loss: 2.3568063819736498

Epoch: 6| Step: 11
Training loss: 1.7665007453353263
Validation loss: 2.33396275955209

Epoch: 6| Step: 12
Training loss: 1.7266299549579325
Validation loss: 2.305643798804681

Epoch: 6| Step: 13
Training loss: 1.3602716842827172
Validation loss: 2.27627756738765

Epoch: 259| Step: 0
Training loss: 1.919809860112927
Validation loss: 2.319167057885822

Epoch: 6| Step: 1
Training loss: 1.7442792301273924
Validation loss: 2.2962692217530556

Epoch: 6| Step: 2
Training loss: 1.5738807485743742
Validation loss: 2.3149804058072734

Epoch: 6| Step: 3
Training loss: 1.1028949984064986
Validation loss: 2.3509883989966203

Epoch: 6| Step: 4
Training loss: 1.7811435868450438
Validation loss: 2.373117887432972

Epoch: 6| Step: 5
Training loss: 1.591215024984777
Validation loss: 2.3083754331929107

Epoch: 6| Step: 6
Training loss: 1.5201897064834113
Validation loss: 2.297877619348214

Epoch: 6| Step: 7
Training loss: 1.7790654489401307
Validation loss: 2.3012101107824816

Epoch: 6| Step: 8
Training loss: 1.8144702068793612
Validation loss: 2.3316851160276424

Epoch: 6| Step: 9
Training loss: 2.5982978200616382
Validation loss: 2.331075825120614

Epoch: 6| Step: 10
Training loss: 1.8019619792437056
Validation loss: 2.4085817389961925

Epoch: 6| Step: 11
Training loss: 1.6485571072110556
Validation loss: 2.362680204270173

Epoch: 6| Step: 12
Training loss: 1.853465715707134
Validation loss: 2.3267450222796158

Epoch: 6| Step: 13
Training loss: 1.678684733720552
Validation loss: 2.3026132132949466

Epoch: 260| Step: 0
Training loss: 1.9577055662137692
Validation loss: 2.365375735314398

Epoch: 6| Step: 1
Training loss: 1.6539581564577104
Validation loss: 2.3433093153688738

Epoch: 6| Step: 2
Training loss: 2.048902599337574
Validation loss: 2.3366475329602348

Epoch: 6| Step: 3
Training loss: 1.2718138846445586
Validation loss: 2.312655208958627

Epoch: 6| Step: 4
Training loss: 1.741072635859815
Validation loss: 2.352610988170673

Epoch: 6| Step: 5
Training loss: 1.6709082116577434
Validation loss: 2.3142631037727566

Epoch: 6| Step: 6
Training loss: 1.8062712090642923
Validation loss: 2.350436792251191

Epoch: 6| Step: 7
Training loss: 1.4629018704194778
Validation loss: 2.29870117945495

Epoch: 6| Step: 8
Training loss: 1.9912261438467307
Validation loss: 2.349470848023505

Epoch: 6| Step: 9
Training loss: 1.3245028300789723
Validation loss: 2.3094445957209366

Epoch: 6| Step: 10
Training loss: 2.0923897039406256
Validation loss: 2.2726513788597202

Epoch: 6| Step: 11
Training loss: 2.4948231503299225
Validation loss: 2.301616285196732

Epoch: 6| Step: 12
Training loss: 1.5806926574345361
Validation loss: 2.3149281386206053

Epoch: 6| Step: 13
Training loss: 1.3330091092169747
Validation loss: 2.2879859951823227

Epoch: 261| Step: 0
Training loss: 1.941062482336221
Validation loss: 2.341796063803239

Epoch: 6| Step: 1
Training loss: 2.0245440782236406
Validation loss: 2.325034815589014

Epoch: 6| Step: 2
Training loss: 1.4495083501548307
Validation loss: 2.3256831919554073

Epoch: 6| Step: 3
Training loss: 1.855708377824116
Validation loss: 2.312907040931777

Epoch: 6| Step: 4
Training loss: 1.3789553971217785
Validation loss: 2.351907878283361

Epoch: 6| Step: 5
Training loss: 1.6447336973862952
Validation loss: 2.3147613136051852

Epoch: 6| Step: 6
Training loss: 1.7723790846070748
Validation loss: 2.328051223241105

Epoch: 6| Step: 7
Training loss: 1.6051671099789742
Validation loss: 2.3694089093385395

Epoch: 6| Step: 8
Training loss: 1.2271835795690338
Validation loss: 2.3254275836145886

Epoch: 6| Step: 9
Training loss: 2.2227434566934803
Validation loss: 2.3678363593188143

Epoch: 6| Step: 10
Training loss: 1.6001801270181455
Validation loss: 2.387949744292848

Epoch: 6| Step: 11
Training loss: 2.0649930740498923
Validation loss: 2.365663130561488

Epoch: 6| Step: 12
Training loss: 2.3473617191232528
Validation loss: 2.3192619496899973

Epoch: 6| Step: 13
Training loss: 1.5505591552973843
Validation loss: 2.335288187708776

Epoch: 262| Step: 0
Training loss: 1.7181444661968976
Validation loss: 2.3354402949180466

Epoch: 6| Step: 1
Training loss: 1.677532001764306
Validation loss: 2.3114721762840045

Epoch: 6| Step: 2
Training loss: 1.8618740950239991
Validation loss: 2.3449565644822954

Epoch: 6| Step: 3
Training loss: 1.955604078522906
Validation loss: 2.2902910087959443

Epoch: 6| Step: 4
Training loss: 2.1939706196934647
Validation loss: 2.3274396245540787

Epoch: 6| Step: 5
Training loss: 1.761850559353333
Validation loss: 2.2342760044193777

Epoch: 6| Step: 6
Training loss: 1.6738010613513654
Validation loss: 2.3605035827457863

Epoch: 6| Step: 7
Training loss: 1.4933744972095966
Validation loss: 2.3670128744007024

Epoch: 6| Step: 8
Training loss: 1.849102591318014
Validation loss: 2.341940449116412

Epoch: 6| Step: 9
Training loss: 1.29706824827669
Validation loss: 2.3002871327450216

Epoch: 6| Step: 10
Training loss: 1.8560098280769783
Validation loss: 2.3438345042755886

Epoch: 6| Step: 11
Training loss: 1.9008082276988252
Validation loss: 2.3328659150517144

Epoch: 6| Step: 12
Training loss: 1.704929340945597
Validation loss: 2.3141738439952735

Epoch: 6| Step: 13
Training loss: 1.8937491464140828
Validation loss: 2.273814071040024

Epoch: 263| Step: 0
Training loss: 1.0168289091594118
Validation loss: 2.3069852064672105

Epoch: 6| Step: 1
Training loss: 2.5725579468602087
Validation loss: 2.276566315409143

Epoch: 6| Step: 2
Training loss: 2.377392016023349
Validation loss: 2.305421182194382

Epoch: 6| Step: 3
Training loss: 2.0081503023606917
Validation loss: 2.330953153864055

Epoch: 6| Step: 4
Training loss: 1.4649947025086119
Validation loss: 2.311201178158312

Epoch: 6| Step: 5
Training loss: 1.5103305485170098
Validation loss: 2.3674632882121056

Epoch: 6| Step: 6
Training loss: 1.7484675236937468
Validation loss: 2.3097734183128704

Epoch: 6| Step: 7
Training loss: 1.0304367442218219
Validation loss: 2.302212303720186

Epoch: 6| Step: 8
Training loss: 1.8215476499362182
Validation loss: 2.308922799244458

Epoch: 6| Step: 9
Training loss: 1.5554149976684435
Validation loss: 2.325391823545657

Epoch: 6| Step: 10
Training loss: 1.5993334633552994
Validation loss: 2.3815322909329533

Epoch: 6| Step: 11
Training loss: 2.272867347562162
Validation loss: 2.335513211489047

Epoch: 6| Step: 12
Training loss: 1.6069537717606581
Validation loss: 2.3323877605251497

Epoch: 6| Step: 13
Training loss: 0.7802103754754497
Validation loss: 2.352385832261244

Epoch: 264| Step: 0
Training loss: 1.7492232642513768
Validation loss: 2.365304752734651

Epoch: 6| Step: 1
Training loss: 1.744269320363068
Validation loss: 2.3100745583342004

Epoch: 6| Step: 2
Training loss: 1.6502820583050344
Validation loss: 2.3391132903557508

Epoch: 6| Step: 3
Training loss: 1.8029831934657072
Validation loss: 2.335065129422196

Epoch: 6| Step: 4
Training loss: 2.2690046687677063
Validation loss: 2.2451077430414155

Epoch: 6| Step: 5
Training loss: 2.1396406374658143
Validation loss: 2.339607043412745

Epoch: 6| Step: 6
Training loss: 1.7465166437473754
Validation loss: 2.360908001032107

Epoch: 6| Step: 7
Training loss: 1.4335238156424321
Validation loss: 2.3440602737744003

Epoch: 6| Step: 8
Training loss: 1.4633397226621365
Validation loss: 2.2686261117389255

Epoch: 6| Step: 9
Training loss: 1.76737605673369
Validation loss: 2.352336824877677

Epoch: 6| Step: 10
Training loss: 2.0525053206826684
Validation loss: 2.3268764594885982

Epoch: 6| Step: 11
Training loss: 1.5408788506713593
Validation loss: 2.3220601219945123

Epoch: 6| Step: 12
Training loss: 1.971159716699386
Validation loss: 2.3045621298006966

Epoch: 6| Step: 13
Training loss: 1.4181063666701985
Validation loss: 2.310608918448481

Epoch: 265| Step: 0
Training loss: 1.5969989049211448
Validation loss: 2.2867457779831013

Epoch: 6| Step: 1
Training loss: 1.7200123399469267
Validation loss: 2.3168743879080407

Epoch: 6| Step: 2
Training loss: 1.340433863817168
Validation loss: 2.299726180259846

Epoch: 6| Step: 3
Training loss: 1.5683406006863918
Validation loss: 2.3265509197009964

Epoch: 6| Step: 4
Training loss: 1.4077161139920127
Validation loss: 2.340363810738695

Epoch: 6| Step: 5
Training loss: 1.637199604348648
Validation loss: 2.3001763043504826

Epoch: 6| Step: 6
Training loss: 2.0705497173944285
Validation loss: 2.2770257199840085

Epoch: 6| Step: 7
Training loss: 1.5954345327661976
Validation loss: 2.315901466607243

Epoch: 6| Step: 8
Training loss: 1.6896849721244471
Validation loss: 2.3734404441742165

Epoch: 6| Step: 9
Training loss: 1.7495604371749027
Validation loss: 2.352038485927124

Epoch: 6| Step: 10
Training loss: 2.508244272300608
Validation loss: 2.3165204276069984

Epoch: 6| Step: 11
Training loss: 1.8772518622825654
Validation loss: 2.3100185011881162

Epoch: 6| Step: 12
Training loss: 1.3527994834747772
Validation loss: 2.321530217543161

Epoch: 6| Step: 13
Training loss: 1.621288094878152
Validation loss: 2.3176044139859986

Epoch: 266| Step: 0
Training loss: 1.7536129440729613
Validation loss: 2.3368844438789047

Epoch: 6| Step: 1
Training loss: 1.6768576981614818
Validation loss: 2.3289229550703534

Epoch: 6| Step: 2
Training loss: 1.8212207280243509
Validation loss: 2.3358621305617002

Epoch: 6| Step: 3
Training loss: 1.6987165739407304
Validation loss: 2.334859885558836

Epoch: 6| Step: 4
Training loss: 1.5110379048610123
Validation loss: 2.3204259827076408

Epoch: 6| Step: 5
Training loss: 1.412711072021914
Validation loss: 2.3849361215250418

Epoch: 6| Step: 6
Training loss: 1.6757566365744143
Validation loss: 2.4112642693347626

Epoch: 6| Step: 7
Training loss: 1.4594305089159314
Validation loss: 2.29209203230984

Epoch: 6| Step: 8
Training loss: 1.7938793919910707
Validation loss: 2.3104487952656116

Epoch: 6| Step: 9
Training loss: 1.9791429886321767
Validation loss: 2.3285740718420502

Epoch: 6| Step: 10
Training loss: 1.8544690460641446
Validation loss: 2.3577783331429445

Epoch: 6| Step: 11
Training loss: 1.4779889517953197
Validation loss: 2.403682847419563

Epoch: 6| Step: 12
Training loss: 1.8680249494891825
Validation loss: 2.3114434511174684

Epoch: 6| Step: 13
Training loss: 2.6417210578333026
Validation loss: 2.3260404773318206

Epoch: 267| Step: 0
Training loss: 1.896312010423191
Validation loss: 2.2875341957854096

Epoch: 6| Step: 1
Training loss: 1.8699633024562163
Validation loss: 2.334509324304405

Epoch: 6| Step: 2
Training loss: 1.6948202095215112
Validation loss: 2.3335519181396784

Epoch: 6| Step: 3
Training loss: 1.81135733529256
Validation loss: 2.3580257021269415

Epoch: 6| Step: 4
Training loss: 2.0518243952264617
Validation loss: 2.3111364706497595

Epoch: 6| Step: 5
Training loss: 2.129861096075098
Validation loss: 2.3322106515664465

Epoch: 6| Step: 6
Training loss: 2.0003261300260125
Validation loss: 2.3030999434899098

Epoch: 6| Step: 7
Training loss: 1.5788634432690671
Validation loss: 2.3414854445575473

Epoch: 6| Step: 8
Training loss: 1.1539551411410272
Validation loss: 2.3730324516565333

Epoch: 6| Step: 9
Training loss: 1.6506058592085553
Validation loss: 2.348148722016653

Epoch: 6| Step: 10
Training loss: 1.7936674597487403
Validation loss: 2.3194810434057924

Epoch: 6| Step: 11
Training loss: 1.433911862536434
Validation loss: 2.3719883126791617

Epoch: 6| Step: 12
Training loss: 1.3577206948239384
Validation loss: 2.310903022713769

Epoch: 6| Step: 13
Training loss: 1.510193047467408
Validation loss: 2.2573391730157506

Epoch: 268| Step: 0
Training loss: 1.3854586611623805
Validation loss: 2.3072551486536215

Epoch: 6| Step: 1
Training loss: 1.6138630480657234
Validation loss: 2.3277008689981056

Epoch: 6| Step: 2
Training loss: 1.5680242919207952
Validation loss: 2.36489956813603

Epoch: 6| Step: 3
Training loss: 1.5099522720777092
Validation loss: 2.3453748030141726

Epoch: 6| Step: 4
Training loss: 1.8944370521644807
Validation loss: 2.399754517401899

Epoch: 6| Step: 5
Training loss: 1.1982310449257796
Validation loss: 2.308361586967976

Epoch: 6| Step: 6
Training loss: 1.616837763171368
Validation loss: 2.300695525413543

Epoch: 6| Step: 7
Training loss: 2.206838089583759
Validation loss: 2.3037629684323506

Epoch: 6| Step: 8
Training loss: 1.0383956031027342
Validation loss: 2.3595344333665276

Epoch: 6| Step: 9
Training loss: 1.669461085229001
Validation loss: 2.39251300494617

Epoch: 6| Step: 10
Training loss: 2.866425041247345
Validation loss: 2.3288887402572844

Epoch: 6| Step: 11
Training loss: 1.2577167735191248
Validation loss: 2.339865050906332

Epoch: 6| Step: 12
Training loss: 1.9179228176979923
Validation loss: 2.292340911241652

Epoch: 6| Step: 13
Training loss: 2.2381369126468105
Validation loss: 2.345042293411289

Epoch: 269| Step: 0
Training loss: 1.5331619159967553
Validation loss: 2.3991938972834816

Epoch: 6| Step: 1
Training loss: 1.8244013888890107
Validation loss: 2.3766859338858413

Epoch: 6| Step: 2
Training loss: 1.6921213237471435
Validation loss: 2.3579330987694793

Epoch: 6| Step: 3
Training loss: 1.939452264484011
Validation loss: 2.2784525673938023

Epoch: 6| Step: 4
Training loss: 2.2003634846126
Validation loss: 2.335863713175886

Epoch: 6| Step: 5
Training loss: 1.5954307968113002
Validation loss: 2.3186584225046984

Epoch: 6| Step: 6
Training loss: 1.729706400394987
Validation loss: 2.375153069779782

Epoch: 6| Step: 7
Training loss: 1.3129999026191717
Validation loss: 2.285213017992182

Epoch: 6| Step: 8
Training loss: 1.4105768395460319
Validation loss: 2.3084014428811828

Epoch: 6| Step: 9
Training loss: 1.7140324439558037
Validation loss: 2.320812624577167

Epoch: 6| Step: 10
Training loss: 1.798280514544513
Validation loss: 2.3351835534320715

Epoch: 6| Step: 11
Training loss: 2.4731517132638805
Validation loss: 2.3379372536157548

Epoch: 6| Step: 12
Training loss: 1.6346894204302171
Validation loss: 2.3525917494351947

Epoch: 6| Step: 13
Training loss: 1.541857355370166
Validation loss: 2.375060342476564

Epoch: 270| Step: 0
Training loss: 2.2156016618927983
Validation loss: 2.3072336611318294

Epoch: 6| Step: 1
Training loss: 2.0862321395520915
Validation loss: 2.3125409885089763

Epoch: 6| Step: 2
Training loss: 2.135784607489108
Validation loss: 2.389833112596449

Epoch: 6| Step: 3
Training loss: 1.4952612570150898
Validation loss: 2.329423354498565

Epoch: 6| Step: 4
Training loss: 1.680668602005781
Validation loss: 2.288278396909342

Epoch: 6| Step: 5
Training loss: 1.0542896226687912
Validation loss: 2.3302487612741096

Epoch: 6| Step: 6
Training loss: 1.5856128228742068
Validation loss: 2.3281594682889195

Epoch: 6| Step: 7
Training loss: 1.6810056260631483
Validation loss: 2.3665967309900116

Epoch: 6| Step: 8
Training loss: 1.515760435365105
Validation loss: 2.3089761111463956

Epoch: 6| Step: 9
Training loss: 1.3632662534572058
Validation loss: 2.3767704779041736

Epoch: 6| Step: 10
Training loss: 2.1882412335823713
Validation loss: 2.2505207792169615

Epoch: 6| Step: 11
Training loss: 1.7687097120246036
Validation loss: 2.387592980291737

Epoch: 6| Step: 12
Training loss: 1.7222479165460944
Validation loss: 2.2879120644925064

Epoch: 6| Step: 13
Training loss: 1.4373862180045671
Validation loss: 2.371384940342059

Epoch: 271| Step: 0
Training loss: 1.728052109462437
Validation loss: 2.3392143295204573

Epoch: 6| Step: 1
Training loss: 0.9818340082189463
Validation loss: 2.323418035652624

Epoch: 6| Step: 2
Training loss: 1.766785974192722
Validation loss: 2.3670653572249556

Epoch: 6| Step: 3
Training loss: 2.5400005779115515
Validation loss: 2.327851782601251

Epoch: 6| Step: 4
Training loss: 1.4164582922033517
Validation loss: 2.2926465036355728

Epoch: 6| Step: 5
Training loss: 1.1579385748006992
Validation loss: 2.32778882731476

Epoch: 6| Step: 6
Training loss: 2.1086414333180072
Validation loss: 2.341318395269191

Epoch: 6| Step: 7
Training loss: 1.61048080823253
Validation loss: 2.3261412026521437

Epoch: 6| Step: 8
Training loss: 1.37029027627216
Validation loss: 2.3261084821698037

Epoch: 6| Step: 9
Training loss: 1.8664505274276195
Validation loss: 2.3585220628242327

Epoch: 6| Step: 10
Training loss: 1.8024391602130518
Validation loss: 2.311352707657714

Epoch: 6| Step: 11
Training loss: 1.6318571225154619
Validation loss: 2.4099530068371573

Epoch: 6| Step: 12
Training loss: 1.4648739417461523
Validation loss: 2.349935019473325

Epoch: 6| Step: 13
Training loss: 2.7405481029757754
Validation loss: 2.3465271595168993

Epoch: 272| Step: 0
Training loss: 1.935175578113635
Validation loss: 2.3362576300334474

Epoch: 6| Step: 1
Training loss: 1.467330733875108
Validation loss: 2.3157080304765127

Epoch: 6| Step: 2
Training loss: 1.4828009039181222
Validation loss: 2.319558982603342

Epoch: 6| Step: 3
Training loss: 1.344319555539419
Validation loss: 2.2918389137247477

Epoch: 6| Step: 4
Training loss: 1.5705516879743242
Validation loss: 2.350151408582011

Epoch: 6| Step: 5
Training loss: 1.9173339290396907
Validation loss: 2.390595457025982

Epoch: 6| Step: 6
Training loss: 2.061799826406512
Validation loss: 2.354070474363839

Epoch: 6| Step: 7
Training loss: 2.350865460374277
Validation loss: 2.307083424557564

Epoch: 6| Step: 8
Training loss: 1.8121857206227658
Validation loss: 2.352657693346813

Epoch: 6| Step: 9
Training loss: 1.4214091114100513
Validation loss: 2.38761376662485

Epoch: 6| Step: 10
Training loss: 1.7103638405798591
Validation loss: 2.327586115291744

Epoch: 6| Step: 11
Training loss: 1.406350026281985
Validation loss: 2.3624436686399215

Epoch: 6| Step: 12
Training loss: 1.5259644507270844
Validation loss: 2.261691853202881

Epoch: 6| Step: 13
Training loss: 1.444645083178328
Validation loss: 2.305632612528122

Epoch: 273| Step: 0
Training loss: 1.710135284894798
Validation loss: 2.3380440946974415

Epoch: 6| Step: 1
Training loss: 1.389249399868429
Validation loss: 2.3628536918653453

Epoch: 6| Step: 2
Training loss: 2.5647180773377696
Validation loss: 2.3239472509589394

Epoch: 6| Step: 3
Training loss: 1.273274604348415
Validation loss: 2.348139987832555

Epoch: 6| Step: 4
Training loss: 1.7653975888877231
Validation loss: 2.2664503450637867

Epoch: 6| Step: 5
Training loss: 1.038447893832845
Validation loss: 2.295670559151127

Epoch: 6| Step: 6
Training loss: 1.7624303222302302
Validation loss: 2.308426035205025

Epoch: 6| Step: 7
Training loss: 1.4209961742856998
Validation loss: 2.3822464605318143

Epoch: 6| Step: 8
Training loss: 2.092962771781309
Validation loss: 2.2943467732928298

Epoch: 6| Step: 9
Training loss: 1.5089571862236373
Validation loss: 2.328637397551146

Epoch: 6| Step: 10
Training loss: 1.6573407881782127
Validation loss: 2.3286064813448237

Epoch: 6| Step: 11
Training loss: 1.6083587104231578
Validation loss: 2.322406187563976

Epoch: 6| Step: 12
Training loss: 2.047456615020955
Validation loss: 2.35831753745667

Epoch: 6| Step: 13
Training loss: 1.1180411858487547
Validation loss: 2.377224604070454

Epoch: 274| Step: 0
Training loss: 1.2718344117232816
Validation loss: 2.349883773048504

Epoch: 6| Step: 1
Training loss: 1.9889453910400428
Validation loss: 2.3335433748594796

Epoch: 6| Step: 2
Training loss: 1.2078165012308149
Validation loss: 2.3567488942235304

Epoch: 6| Step: 3
Training loss: 1.8121177007077276
Validation loss: 2.3998075575566316

Epoch: 6| Step: 4
Training loss: 1.6092098114272122
Validation loss: 2.325145134975735

Epoch: 6| Step: 5
Training loss: 2.3033740422708546
Validation loss: 2.3189506712150196

Epoch: 6| Step: 6
Training loss: 2.156563556374044
Validation loss: 2.32210293726444

Epoch: 6| Step: 7
Training loss: 1.9606401438397267
Validation loss: 2.297771692634423

Epoch: 6| Step: 8
Training loss: 1.93226445291143
Validation loss: 2.263386085110929

Epoch: 6| Step: 9
Training loss: 1.573844770588243
Validation loss: 2.3488776094851254

Epoch: 6| Step: 10
Training loss: 1.5512490131580985
Validation loss: 2.3424994497967995

Epoch: 6| Step: 11
Training loss: 1.6268009329842639
Validation loss: 2.3047947267199764

Epoch: 6| Step: 12
Training loss: 1.2363892550670141
Validation loss: 2.3283007276645

Epoch: 6| Step: 13
Training loss: 1.4488854037738952
Validation loss: 2.287003390633411

Epoch: 275| Step: 0
Training loss: 1.3116146007675635
Validation loss: 2.292832505546361

Epoch: 6| Step: 1
Training loss: 1.459359770538133
Validation loss: 2.3572636668881684

Epoch: 6| Step: 2
Training loss: 1.6118216573727322
Validation loss: 2.3032766833215153

Epoch: 6| Step: 3
Training loss: 1.722069257519773
Validation loss: 2.290415140392068

Epoch: 6| Step: 4
Training loss: 1.743190733120548
Validation loss: 2.3119126172266844

Epoch: 6| Step: 5
Training loss: 1.5292696700715211
Validation loss: 2.3805685471980937

Epoch: 6| Step: 6
Training loss: 2.112785238838558
Validation loss: 2.3230121141738618

Epoch: 6| Step: 7
Training loss: 1.5219959970739914
Validation loss: 2.2937791207162648

Epoch: 6| Step: 8
Training loss: 1.5032240868661175
Validation loss: 2.3228788133190585

Epoch: 6| Step: 9
Training loss: 1.4035009428509684
Validation loss: 2.3241036434595186

Epoch: 6| Step: 10
Training loss: 1.932755290412891
Validation loss: 2.313577681894844

Epoch: 6| Step: 11
Training loss: 2.5467549863283243
Validation loss: 2.2949525713869474

Epoch: 6| Step: 12
Training loss: 1.6614799697407892
Validation loss: 2.2843386331431517

Epoch: 6| Step: 13
Training loss: 1.340376856320124
Validation loss: 2.401979218298253

Epoch: 276| Step: 0
Training loss: 2.0653268342076974
Validation loss: 2.345477486858881

Epoch: 6| Step: 1
Training loss: 1.6471745140853458
Validation loss: 2.339079404346199

Epoch: 6| Step: 2
Training loss: 1.6604008034491198
Validation loss: 2.3012885000019963

Epoch: 6| Step: 3
Training loss: 1.8468479057687008
Validation loss: 2.3827952534444656

Epoch: 6| Step: 4
Training loss: 1.4759701948645643
Validation loss: 2.3005179515306113

Epoch: 6| Step: 5
Training loss: 1.8657368407600028
Validation loss: 2.321591248593792

Epoch: 6| Step: 6
Training loss: 1.0639401380901419
Validation loss: 2.290865028171431

Epoch: 6| Step: 7
Training loss: 1.2191035418140053
Validation loss: 2.3654174489961997

Epoch: 6| Step: 8
Training loss: 2.111354661857688
Validation loss: 2.3137602383382347

Epoch: 6| Step: 9
Training loss: 2.3713433073082695
Validation loss: 2.3276613710782663

Epoch: 6| Step: 10
Training loss: 1.3676315022620729
Validation loss: 2.3631556811898538

Epoch: 6| Step: 11
Training loss: 1.8695388098761954
Validation loss: 2.3548714262280774

Epoch: 6| Step: 12
Training loss: 1.328826225513099
Validation loss: 2.3333833582155092

Epoch: 6| Step: 13
Training loss: 1.3317397349574085
Validation loss: 2.3239315995469703

Epoch: 277| Step: 0
Training loss: 1.9608407167662345
Validation loss: 2.361135730779929

Epoch: 6| Step: 1
Training loss: 1.9766608654771218
Validation loss: 2.323322564362264

Epoch: 6| Step: 2
Training loss: 1.319490707434124
Validation loss: 2.3482949585483865

Epoch: 6| Step: 3
Training loss: 2.4362150864817576
Validation loss: 2.3650837866888144

Epoch: 6| Step: 4
Training loss: 1.4595427357505844
Validation loss: 2.3051910734563124

Epoch: 6| Step: 5
Training loss: 1.8020003488944645
Validation loss: 2.370876242475348

Epoch: 6| Step: 6
Training loss: 1.4725063257777762
Validation loss: 2.414496104406676

Epoch: 6| Step: 7
Training loss: 1.2755342785256576
Validation loss: 2.364060731264196

Epoch: 6| Step: 8
Training loss: 1.8067506828808262
Validation loss: 2.341829806504939

Epoch: 6| Step: 9
Training loss: 1.3516451859952587
Validation loss: 2.328081714056772

Epoch: 6| Step: 10
Training loss: 1.6571618934651358
Validation loss: 2.278104078638275

Epoch: 6| Step: 11
Training loss: 1.7635562220913663
Validation loss: 2.310579102429532

Epoch: 6| Step: 12
Training loss: 1.8497616665912147
Validation loss: 2.2876131119094727

Epoch: 6| Step: 13
Training loss: 1.7867507991743616
Validation loss: 2.3623444531973075

Epoch: 278| Step: 0
Training loss: 2.5056119872526277
Validation loss: 2.2873564065582728

Epoch: 6| Step: 1
Training loss: 1.4159661225183422
Validation loss: 2.2895506709582296

Epoch: 6| Step: 2
Training loss: 1.783000554322709
Validation loss: 2.2894545992098534

Epoch: 6| Step: 3
Training loss: 1.7514401368439625
Validation loss: 2.2988619820577316

Epoch: 6| Step: 4
Training loss: 1.3345974899733721
Validation loss: 2.350497692244159

Epoch: 6| Step: 5
Training loss: 1.6468757354329329
Validation loss: 2.3860648303165726

Epoch: 6| Step: 6
Training loss: 1.8584475087328816
Validation loss: 2.3156246564209257

Epoch: 6| Step: 7
Training loss: 1.6135561064666517
Validation loss: 2.311167439744086

Epoch: 6| Step: 8
Training loss: 1.7170160043067189
Validation loss: 2.3567645365476184

Epoch: 6| Step: 9
Training loss: 1.4790421912602196
Validation loss: 2.340410236727197

Epoch: 6| Step: 10
Training loss: 1.6288035701159864
Validation loss: 2.304379797532266

Epoch: 6| Step: 11
Training loss: 1.4713818122719682
Validation loss: 2.3190663474739623

Epoch: 6| Step: 12
Training loss: 1.7810129375983832
Validation loss: 2.299831077254106

Epoch: 6| Step: 13
Training loss: 2.0175254201882953
Validation loss: 2.356193623450839

Epoch: 279| Step: 0
Training loss: 1.7504997221121938
Validation loss: 2.352987824806775

Epoch: 6| Step: 1
Training loss: 1.5709010297655939
Validation loss: 2.3229999134611314

Epoch: 6| Step: 2
Training loss: 2.0792827392877338
Validation loss: 2.3676754049885207

Epoch: 6| Step: 3
Training loss: 1.262714524502795
Validation loss: 2.2626285549769287

Epoch: 6| Step: 4
Training loss: 2.2482670362164936
Validation loss: 2.285219082644701

Epoch: 6| Step: 5
Training loss: 1.2011279090340352
Validation loss: 2.275643789780567

Epoch: 6| Step: 6
Training loss: 1.83967994560089
Validation loss: 2.2717939944967114

Epoch: 6| Step: 7
Training loss: 1.775470794781299
Validation loss: 2.386329350178359

Epoch: 6| Step: 8
Training loss: 1.1567960944488358
Validation loss: 2.3517214263128747

Epoch: 6| Step: 9
Training loss: 1.763477065436646
Validation loss: 2.3018579654370073

Epoch: 6| Step: 10
Training loss: 1.8217369694710321
Validation loss: 2.2798704605259257

Epoch: 6| Step: 11
Training loss: 1.7468564546040821
Validation loss: 2.2880656262507797

Epoch: 6| Step: 12
Training loss: 1.3618123795431682
Validation loss: 2.3004223238747823

Epoch: 6| Step: 13
Training loss: 1.6226369842869597
Validation loss: 2.339055661488712

Epoch: 280| Step: 0
Training loss: 2.714865705003401
Validation loss: 2.3520354950600875

Epoch: 6| Step: 1
Training loss: 1.6160322107796818
Validation loss: 2.333213137974947

Epoch: 6| Step: 2
Training loss: 1.3643046912383514
Validation loss: 2.3782255713456735

Epoch: 6| Step: 3
Training loss: 1.049258692500201
Validation loss: 2.3636720368658324

Epoch: 6| Step: 4
Training loss: 1.739054784217848
Validation loss: 2.408202986609144

Epoch: 6| Step: 5
Training loss: 1.387630410122941
Validation loss: 2.298192954018057

Epoch: 6| Step: 6
Training loss: 1.436348329370321
Validation loss: 2.347494115160623

Epoch: 6| Step: 7
Training loss: 1.9723499626854195
Validation loss: 2.425321749236376

Epoch: 6| Step: 8
Training loss: 1.6676739827545273
Validation loss: 2.3743981698260823

Epoch: 6| Step: 9
Training loss: 1.716073744267466
Validation loss: 2.395281765558433

Epoch: 6| Step: 10
Training loss: 1.2462241364667825
Validation loss: 2.390087974862703

Epoch: 6| Step: 11
Training loss: 1.5197912939993716
Validation loss: 2.3485322931569956

Epoch: 6| Step: 12
Training loss: 1.6575697912652243
Validation loss: 2.3398816880814706

Epoch: 6| Step: 13
Training loss: 2.220270414980393
Validation loss: 2.352576289681412

Epoch: 281| Step: 0
Training loss: 0.9044787757454156
Validation loss: 2.390620201128007

Epoch: 6| Step: 1
Training loss: 1.1653247108955214
Validation loss: 2.3776089867779078

Epoch: 6| Step: 2
Training loss: 1.7503747538804988
Validation loss: 2.280006134758601

Epoch: 6| Step: 3
Training loss: 1.5793987459270267
Validation loss: 2.309281093839479

Epoch: 6| Step: 4
Training loss: 1.7644156981749473
Validation loss: 2.3666696787908448

Epoch: 6| Step: 5
Training loss: 2.0188501858726533
Validation loss: 2.343863356388721

Epoch: 6| Step: 6
Training loss: 1.386894451347054
Validation loss: 2.3244175262809867

Epoch: 6| Step: 7
Training loss: 1.5495357556521352
Validation loss: 2.3641681181004013

Epoch: 6| Step: 8
Training loss: 1.5067500190690557
Validation loss: 2.295255692778927

Epoch: 6| Step: 9
Training loss: 1.4840575029229195
Validation loss: 2.4094497337309955

Epoch: 6| Step: 10
Training loss: 2.041299228950586
Validation loss: 2.3272350234702537

Epoch: 6| Step: 11
Training loss: 1.7005708072752044
Validation loss: 2.3465198647131458

Epoch: 6| Step: 12
Training loss: 1.8330582788071463
Validation loss: 2.309975023557683

Epoch: 6| Step: 13
Training loss: 2.8660310913018012
Validation loss: 2.306913994153261

Epoch: 282| Step: 0
Training loss: 1.5784224428173537
Validation loss: 2.346488495269028

Epoch: 6| Step: 1
Training loss: 2.128961796867086
Validation loss: 2.284097787860584

Epoch: 6| Step: 2
Training loss: 1.8705880072925554
Validation loss: 2.3505505874437587

Epoch: 6| Step: 3
Training loss: 1.2637684709989467
Validation loss: 2.354884133509777

Epoch: 6| Step: 4
Training loss: 1.2951064402606507
Validation loss: 2.3100594932208343

Epoch: 6| Step: 5
Training loss: 1.584601680633682
Validation loss: 2.382857533040616

Epoch: 6| Step: 6
Training loss: 1.0562945520158125
Validation loss: 2.353881281409322

Epoch: 6| Step: 7
Training loss: 1.618025336940697
Validation loss: 2.3769678513488017

Epoch: 6| Step: 8
Training loss: 1.7952507307218195
Validation loss: 2.417198464930281

Epoch: 6| Step: 9
Training loss: 1.475619787185167
Validation loss: 2.3094527241798537

Epoch: 6| Step: 10
Training loss: 2.0703270101938447
Validation loss: 2.3388645831565067

Epoch: 6| Step: 11
Training loss: 2.2891933156413318
Validation loss: 2.3436651059981406

Epoch: 6| Step: 12
Training loss: 1.7587692030866222
Validation loss: 2.3010003352444697

Epoch: 6| Step: 13
Training loss: 1.2446101334279611
Validation loss: 2.292597291061751

Epoch: 283| Step: 0
Training loss: 2.4155865151718894
Validation loss: 2.3233428951044366

Epoch: 6| Step: 1
Training loss: 1.5602441907156281
Validation loss: 2.359144064098859

Epoch: 6| Step: 2
Training loss: 1.6988741119609232
Validation loss: 2.3448555934469706

Epoch: 6| Step: 3
Training loss: 1.5119696514878411
Validation loss: 2.323356309434839

Epoch: 6| Step: 4
Training loss: 1.6185463618914477
Validation loss: 2.327465987354997

Epoch: 6| Step: 5
Training loss: 2.136177287284452
Validation loss: 2.3515330691531977

Epoch: 6| Step: 6
Training loss: 2.0426705545773536
Validation loss: 2.3245473139822717

Epoch: 6| Step: 7
Training loss: 1.7335943578759425
Validation loss: 2.3458544508905996

Epoch: 6| Step: 8
Training loss: 1.4375096196391786
Validation loss: 2.312370511736289

Epoch: 6| Step: 9
Training loss: 1.5533598785560734
Validation loss: 2.3971870200555183

Epoch: 6| Step: 10
Training loss: 1.3032199578026813
Validation loss: 2.337605632154171

Epoch: 6| Step: 11
Training loss: 1.6856579086491585
Validation loss: 2.308622270208781

Epoch: 6| Step: 12
Training loss: 1.1944601972167115
Validation loss: 2.323396205493069

Epoch: 6| Step: 13
Training loss: 1.111298679705889
Validation loss: 2.3245956207728744

Epoch: 284| Step: 0
Training loss: 1.7671282285266987
Validation loss: 2.2558649639871358

Epoch: 6| Step: 1
Training loss: 2.45558956284754
Validation loss: 2.296681896935349

Epoch: 6| Step: 2
Training loss: 1.5958882368053784
Validation loss: 2.2683442665133113

Epoch: 6| Step: 3
Training loss: 1.6635944979914903
Validation loss: 2.2692642985414566

Epoch: 6| Step: 4
Training loss: 1.8815734078357684
Validation loss: 2.375530399579404

Epoch: 6| Step: 5
Training loss: 1.3375701743282262
Validation loss: 2.3840784355639224

Epoch: 6| Step: 6
Training loss: 1.9735936118965383
Validation loss: 2.390135405897486

Epoch: 6| Step: 7
Training loss: 1.5884438239644703
Validation loss: 2.3784239083805727

Epoch: 6| Step: 8
Training loss: 0.9241564693410035
Validation loss: 2.355141785051686

Epoch: 6| Step: 9
Training loss: 1.9161658116389855
Validation loss: 2.335736307107473

Epoch: 6| Step: 10
Training loss: 1.5187003798679433
Validation loss: 2.3418272892021044

Epoch: 6| Step: 11
Training loss: 1.6909659783963704
Validation loss: 2.3724403026431076

Epoch: 6| Step: 12
Training loss: 1.4405424015752135
Validation loss: 2.3309339167449754

Epoch: 6| Step: 13
Training loss: 1.0930047357182635
Validation loss: 2.356493453868851

Epoch: 285| Step: 0
Training loss: 1.566889205643022
Validation loss: 2.3822666112461377

Epoch: 6| Step: 1
Training loss: 1.8294109809863708
Validation loss: 2.3353360939366232

Epoch: 6| Step: 2
Training loss: 2.052418547488179
Validation loss: 2.3155290653042275

Epoch: 6| Step: 3
Training loss: 1.3707685383766373
Validation loss: 2.2880679802943624

Epoch: 6| Step: 4
Training loss: 1.4037207428353662
Validation loss: 2.3978985526324963

Epoch: 6| Step: 5
Training loss: 1.2149688558158258
Validation loss: 2.372863317882047

Epoch: 6| Step: 6
Training loss: 2.176713781309382
Validation loss: 2.4004505759116888

Epoch: 6| Step: 7
Training loss: 1.177759021608687
Validation loss: 2.307258685905976

Epoch: 6| Step: 8
Training loss: 1.9567560242238125
Validation loss: 2.366374038995284

Epoch: 6| Step: 9
Training loss: 1.4962891134887735
Validation loss: 2.370751759361175

Epoch: 6| Step: 10
Training loss: 1.898173247105066
Validation loss: 2.3277637933481725

Epoch: 6| Step: 11
Training loss: 1.555440059226742
Validation loss: 2.346426352213539

Epoch: 6| Step: 12
Training loss: 1.4846701880625803
Validation loss: 2.2935217272873407

Epoch: 6| Step: 13
Training loss: 1.9170489621026259
Validation loss: 2.3596224308423333

Epoch: 286| Step: 0
Training loss: 1.7088479995810035
Validation loss: 2.3121770485257924

Epoch: 6| Step: 1
Training loss: 1.3121629918083855
Validation loss: 2.308718981775755

Epoch: 6| Step: 2
Training loss: 1.7776385723025345
Validation loss: 2.345545277910474

Epoch: 6| Step: 3
Training loss: 2.334787347165033
Validation loss: 2.2699153409153423

Epoch: 6| Step: 4
Training loss: 1.3523709299407256
Validation loss: 2.401788316557902

Epoch: 6| Step: 5
Training loss: 1.5378023207013056
Validation loss: 2.3268366319171463

Epoch: 6| Step: 6
Training loss: 1.8314685730150138
Validation loss: 2.336843836829276

Epoch: 6| Step: 7
Training loss: 1.3942861047686694
Validation loss: 2.3553215455254732

Epoch: 6| Step: 8
Training loss: 1.8340486590379417
Validation loss: 2.281606221871153

Epoch: 6| Step: 9
Training loss: 1.867213101391073
Validation loss: 2.2924395823022317

Epoch: 6| Step: 10
Training loss: 1.625406801216144
Validation loss: 2.389960244633694

Epoch: 6| Step: 11
Training loss: 1.4656230023661259
Validation loss: 2.3572030134790194

Epoch: 6| Step: 12
Training loss: 1.8584576435450317
Validation loss: 2.3415104963244593

Epoch: 6| Step: 13
Training loss: 1.37116599911473
Validation loss: 2.4058193305610525

Epoch: 287| Step: 0
Training loss: 1.1752858686688321
Validation loss: 2.3559629197801293

Epoch: 6| Step: 1
Training loss: 1.8953734737944326
Validation loss: 2.3473595839944057

Epoch: 6| Step: 2
Training loss: 1.6123596958362996
Validation loss: 2.332492386953743

Epoch: 6| Step: 3
Training loss: 1.5835959902626606
Validation loss: 2.3087180690128615

Epoch: 6| Step: 4
Training loss: 1.9939544620728098
Validation loss: 2.377153653923765

Epoch: 6| Step: 5
Training loss: 1.4295645072021321
Validation loss: 2.3286598572868007

Epoch: 6| Step: 6
Training loss: 1.7407282033353062
Validation loss: 2.296915902923252

Epoch: 6| Step: 7
Training loss: 1.2204419642507578
Validation loss: 2.3294285683356697

Epoch: 6| Step: 8
Training loss: 1.744109457833229
Validation loss: 2.361230957042708

Epoch: 6| Step: 9
Training loss: 1.473462599927881
Validation loss: 2.302374229005457

Epoch: 6| Step: 10
Training loss: 1.8453209213852808
Validation loss: 2.316942016705542

Epoch: 6| Step: 11
Training loss: 2.0063144423928545
Validation loss: 2.430579281489472

Epoch: 6| Step: 12
Training loss: 1.866816144589551
Validation loss: 2.39707195763039

Epoch: 6| Step: 13
Training loss: 1.538353151391447
Validation loss: 2.3165908256021397

Epoch: 288| Step: 0
Training loss: 1.7590225462951388
Validation loss: 2.3069518675718284

Epoch: 6| Step: 1
Training loss: 1.971955550735497
Validation loss: 2.344043756486197

Epoch: 6| Step: 2
Training loss: 1.5041758109930456
Validation loss: 2.3532365356641884

Epoch: 6| Step: 3
Training loss: 1.616729302847924
Validation loss: 2.3557572722511795

Epoch: 6| Step: 4
Training loss: 1.939322014839991
Validation loss: 2.357029310098366

Epoch: 6| Step: 5
Training loss: 1.1641649546755137
Validation loss: 2.362334407383798

Epoch: 6| Step: 6
Training loss: 2.0516657783677847
Validation loss: 2.3523413754467137

Epoch: 6| Step: 7
Training loss: 1.2900669230615434
Validation loss: 2.3003912992789184

Epoch: 6| Step: 8
Training loss: 1.7317407208647453
Validation loss: 2.3919002298717134

Epoch: 6| Step: 9
Training loss: 1.3128439134790768
Validation loss: 2.2952542474706608

Epoch: 6| Step: 10
Training loss: 1.374850221625833
Validation loss: 2.341382951890262

Epoch: 6| Step: 11
Training loss: 1.0858063103998907
Validation loss: 2.260291064917026

Epoch: 6| Step: 12
Training loss: 2.06999290446664
Validation loss: 2.3665285409289196

Epoch: 6| Step: 13
Training loss: 1.654012356085792
Validation loss: 2.362925269933221

Epoch: 289| Step: 0
Training loss: 1.4729445602746976
Validation loss: 2.3361455001850095

Epoch: 6| Step: 1
Training loss: 1.536083300666241
Validation loss: 2.319335650665835

Epoch: 6| Step: 2
Training loss: 1.5894101463089059
Validation loss: 2.283220395126803

Epoch: 6| Step: 3
Training loss: 1.436648489814235
Validation loss: 2.3027505857450623

Epoch: 6| Step: 4
Training loss: 2.208274936503702
Validation loss: 2.228805998325404

Epoch: 6| Step: 5
Training loss: 1.9866042343779653
Validation loss: 2.3451317021176763

Epoch: 6| Step: 6
Training loss: 1.4723701502698014
Validation loss: 2.3749290632741

Epoch: 6| Step: 7
Training loss: 1.2899195278558313
Validation loss: 2.341530965852952

Epoch: 6| Step: 8
Training loss: 1.4223097251921681
Validation loss: 2.338239320875647

Epoch: 6| Step: 9
Training loss: 1.2000657858300203
Validation loss: 2.3679004019286625

Epoch: 6| Step: 10
Training loss: 1.618747861411549
Validation loss: 2.3798695732464563

Epoch: 6| Step: 11
Training loss: 1.9587677277698188
Validation loss: 2.3062702865368645

Epoch: 6| Step: 12
Training loss: 2.0508944816210444
Validation loss: 2.356716870646641

Epoch: 6| Step: 13
Training loss: 1.7113793904197547
Validation loss: 2.367277953937207

Epoch: 290| Step: 0
Training loss: 1.4711842756734765
Validation loss: 2.264588521973774

Epoch: 6| Step: 1
Training loss: 1.978397226509683
Validation loss: 2.3105539327634035

Epoch: 6| Step: 2
Training loss: 1.4019724744905393
Validation loss: 2.367104487353025

Epoch: 6| Step: 3
Training loss: 1.569330924025517
Validation loss: 2.39777561086938

Epoch: 6| Step: 4
Training loss: 2.5633433745162333
Validation loss: 2.3663757745411966

Epoch: 6| Step: 5
Training loss: 1.6235115129857383
Validation loss: 2.3197230865203236

Epoch: 6| Step: 6
Training loss: 1.3144490892368161
Validation loss: 2.362199228055704

Epoch: 6| Step: 7
Training loss: 1.344019840559516
Validation loss: 2.3737647163884334

Epoch: 6| Step: 8
Training loss: 1.4761267124928126
Validation loss: 2.316017694759639

Epoch: 6| Step: 9
Training loss: 1.6382199779398419
Validation loss: 2.317465567424994

Epoch: 6| Step: 10
Training loss: 1.694340721805205
Validation loss: 2.3326575754470222

Epoch: 6| Step: 11
Training loss: 1.781953237816963
Validation loss: 2.3629184152496494

Epoch: 6| Step: 12
Training loss: 1.5470841391626642
Validation loss: 2.2787994649869874

Epoch: 6| Step: 13
Training loss: 1.3208695991342883
Validation loss: 2.341706080523402

Epoch: 291| Step: 0
Training loss: 0.9570669984952802
Validation loss: 2.3549466689930427

Epoch: 6| Step: 1
Training loss: 1.7270181322233766
Validation loss: 2.318412451662585

Epoch: 6| Step: 2
Training loss: 1.4526761910340908
Validation loss: 2.3660516208418483

Epoch: 6| Step: 3
Training loss: 1.915313000808877
Validation loss: 2.293235318751274

Epoch: 6| Step: 4
Training loss: 1.5105451419604343
Validation loss: 2.312875729905696

Epoch: 6| Step: 5
Training loss: 1.6212319188811928
Validation loss: 2.372078126387796

Epoch: 6| Step: 6
Training loss: 1.5164339718453939
Validation loss: 2.2966950271901894

Epoch: 6| Step: 7
Training loss: 1.5820427034693425
Validation loss: 2.3391347409390386

Epoch: 6| Step: 8
Training loss: 2.2325061371687958
Validation loss: 2.2996280765816217

Epoch: 6| Step: 9
Training loss: 1.4327599701981306
Validation loss: 2.345033638941134

Epoch: 6| Step: 10
Training loss: 1.2639902176719895
Validation loss: 2.361444303740122

Epoch: 6| Step: 11
Training loss: 1.976129054615823
Validation loss: 2.368223765104531

Epoch: 6| Step: 12
Training loss: 1.2849270694535126
Validation loss: 2.354834850973681

Epoch: 6| Step: 13
Training loss: 1.009730030369525
Validation loss: 2.2827577641415573

Epoch: 292| Step: 0
Training loss: 1.6211020595843129
Validation loss: 2.3695156437445672

Epoch: 6| Step: 1
Training loss: 2.4251311040616357
Validation loss: 2.3826027129437146

Epoch: 6| Step: 2
Training loss: 1.6933564886752723
Validation loss: 2.3162952000750883

Epoch: 6| Step: 3
Training loss: 1.3892886566638083
Validation loss: 2.4231875109832384

Epoch: 6| Step: 4
Training loss: 1.479810502962986
Validation loss: 2.313382608610503

Epoch: 6| Step: 5
Training loss: 1.4759348993805494
Validation loss: 2.3203295988848653

Epoch: 6| Step: 6
Training loss: 1.644987138274677
Validation loss: 2.3341562194212013

Epoch: 6| Step: 7
Training loss: 1.77720966881357
Validation loss: 2.282561182300271

Epoch: 6| Step: 8
Training loss: 1.7522695674492172
Validation loss: 2.274138943131458

Epoch: 6| Step: 9
Training loss: 1.5390456145468872
Validation loss: 2.3314347131044073

Epoch: 6| Step: 10
Training loss: 1.4139801760151227
Validation loss: 2.271105875724328

Epoch: 6| Step: 11
Training loss: 1.4296584829919077
Validation loss: 2.338059028835776

Epoch: 6| Step: 12
Training loss: 1.7087385425867196
Validation loss: 2.3725381947183704

Epoch: 6| Step: 13
Training loss: 1.9234947264251725
Validation loss: 2.3617601210436843

Epoch: 293| Step: 0
Training loss: 1.5940971744357963
Validation loss: 2.3313151463640667

Epoch: 6| Step: 1
Training loss: 1.8214414312939842
Validation loss: 2.3786833405926084

Epoch: 6| Step: 2
Training loss: 1.4370164472558544
Validation loss: 2.431999684574291

Epoch: 6| Step: 3
Training loss: 1.4120517576500706
Validation loss: 2.330750249310275

Epoch: 6| Step: 4
Training loss: 1.3732647349915896
Validation loss: 2.3732652983719653

Epoch: 6| Step: 5
Training loss: 2.1184016613729018
Validation loss: 2.370523914110245

Epoch: 6| Step: 6
Training loss: 1.712792423090953
Validation loss: 2.3737349138949755

Epoch: 6| Step: 7
Training loss: 2.1189486790230423
Validation loss: 2.2762241901858706

Epoch: 6| Step: 8
Training loss: 1.2480767713616516
Validation loss: 2.3403416659746865

Epoch: 6| Step: 9
Training loss: 1.7430631207643486
Validation loss: 2.286409143793363

Epoch: 6| Step: 10
Training loss: 1.3697124598511574
Validation loss: 2.3385424640101555

Epoch: 6| Step: 11
Training loss: 1.5959430640254182
Validation loss: 2.324860506154664

Epoch: 6| Step: 12
Training loss: 1.109589623120528
Validation loss: 2.2988698696992036

Epoch: 6| Step: 13
Training loss: 2.373196670137169
Validation loss: 2.327281192524707

Epoch: 294| Step: 0
Training loss: 1.5284798925772427
Validation loss: 2.3699816267399423

Epoch: 6| Step: 1
Training loss: 1.8938561563985106
Validation loss: 2.3314094810454353

Epoch: 6| Step: 2
Training loss: 1.248500019365279
Validation loss: 2.3358368612701232

Epoch: 6| Step: 3
Training loss: 1.6948728914341293
Validation loss: 2.2742419648978474

Epoch: 6| Step: 4
Training loss: 1.6185800941878872
Validation loss: 2.3303015492581487

Epoch: 6| Step: 5
Training loss: 1.8237154345933198
Validation loss: 2.265939868154824

Epoch: 6| Step: 6
Training loss: 1.7935463633567925
Validation loss: 2.3269160572178693

Epoch: 6| Step: 7
Training loss: 1.4500499716730872
Validation loss: 2.3482717864921754

Epoch: 6| Step: 8
Training loss: 1.7354373599402801
Validation loss: 2.2886064481033563

Epoch: 6| Step: 9
Training loss: 1.1899266795803427
Validation loss: 2.366342742615595

Epoch: 6| Step: 10
Training loss: 1.6557136242922912
Validation loss: 2.348617683078624

Epoch: 6| Step: 11
Training loss: 2.4338773559101248
Validation loss: 2.3292933129484936

Epoch: 6| Step: 12
Training loss: 1.372253666366041
Validation loss: 2.3049482645436665

Epoch: 6| Step: 13
Training loss: 0.8100424794255027
Validation loss: 2.4151694734617335

Epoch: 295| Step: 0
Training loss: 1.954476034189738
Validation loss: 2.3446254284820474

Epoch: 6| Step: 1
Training loss: 1.556362227717364
Validation loss: 2.3378386803090336

Epoch: 6| Step: 2
Training loss: 1.494706987736062
Validation loss: 2.344878474007125

Epoch: 6| Step: 3
Training loss: 1.027808022841633
Validation loss: 2.347152602701716

Epoch: 6| Step: 4
Training loss: 1.6962693146833734
Validation loss: 2.3334335744731414

Epoch: 6| Step: 5
Training loss: 1.782450488929047
Validation loss: 2.343863168260772

Epoch: 6| Step: 6
Training loss: 1.2227549162714961
Validation loss: 2.322038364632497

Epoch: 6| Step: 7
Training loss: 1.6636608516617222
Validation loss: 2.3754848466751866

Epoch: 6| Step: 8
Training loss: 1.4470511211863457
Validation loss: 2.3494326048555427

Epoch: 6| Step: 9
Training loss: 2.3620139010453958
Validation loss: 2.373252430796622

Epoch: 6| Step: 10
Training loss: 1.1043019421801579
Validation loss: 2.320203845773759

Epoch: 6| Step: 11
Training loss: 1.5213441208722467
Validation loss: 2.3651754532263496

Epoch: 6| Step: 12
Training loss: 1.523373489991389
Validation loss: 2.33768116580864

Epoch: 6| Step: 13
Training loss: 1.0537926162301765
Validation loss: 2.3124598261551057

Epoch: 296| Step: 0
Training loss: 2.0276636007322257
Validation loss: 2.3430296897824108

Epoch: 6| Step: 1
Training loss: 1.9614112555279597
Validation loss: 2.315014830885327

Epoch: 6| Step: 2
Training loss: 1.3067630545104743
Validation loss: 2.289858657094761

Epoch: 6| Step: 3
Training loss: 1.4642630684992202
Validation loss: 2.3135143805673724

Epoch: 6| Step: 4
Training loss: 1.1742320452741364
Validation loss: 2.2973688579816516

Epoch: 6| Step: 5
Training loss: 1.4370445691008171
Validation loss: 2.357713656220814

Epoch: 6| Step: 6
Training loss: 1.6468821053107368
Validation loss: 2.366397630177103

Epoch: 6| Step: 7
Training loss: 1.5200017284082323
Validation loss: 2.2643064221279983

Epoch: 6| Step: 8
Training loss: 0.9142964381627866
Validation loss: 2.36652066646873

Epoch: 6| Step: 9
Training loss: 1.9837884711974234
Validation loss: 2.361178377107378

Epoch: 6| Step: 10
Training loss: 1.0509583277911356
Validation loss: 2.3423920217367606

Epoch: 6| Step: 11
Training loss: 1.5461846554763652
Validation loss: 2.3028773865505725

Epoch: 6| Step: 12
Training loss: 1.4513063432663018
Validation loss: 2.259538982449007

Epoch: 6| Step: 13
Training loss: 2.899725532697539
Validation loss: 2.334768231675745

Epoch: 297| Step: 0
Training loss: 2.3298309015954994
Validation loss: 2.30466270482105

Epoch: 6| Step: 1
Training loss: 1.3950976335548235
Validation loss: 2.35452708640564

Epoch: 6| Step: 2
Training loss: 1.6348480240303762
Validation loss: 2.3358295023497195

Epoch: 6| Step: 3
Training loss: 1.9314372049108073
Validation loss: 2.3028827890672168

Epoch: 6| Step: 4
Training loss: 1.8130697472985797
Validation loss: 2.344826834995069

Epoch: 6| Step: 5
Training loss: 1.605287564859815
Validation loss: 2.3531895777893728

Epoch: 6| Step: 6
Training loss: 1.2091339462518773
Validation loss: 2.328560283519503

Epoch: 6| Step: 7
Training loss: 1.315320299976919
Validation loss: 2.307355967942583

Epoch: 6| Step: 8
Training loss: 1.4237374484854461
Validation loss: 2.3007434131735427

Epoch: 6| Step: 9
Training loss: 1.6844960071927422
Validation loss: 2.303664244869369

Epoch: 6| Step: 10
Training loss: 1.6925775643723469
Validation loss: 2.3265987727867024

Epoch: 6| Step: 11
Training loss: 1.3917254262309868
Validation loss: 2.332246021287087

Epoch: 6| Step: 12
Training loss: 1.3946097215644877
Validation loss: 2.3214505069272815

Epoch: 6| Step: 13
Training loss: 1.6229051879294054
Validation loss: 2.3491877500271428

Epoch: 298| Step: 0
Training loss: 1.363338698786194
Validation loss: 2.395513133462435

Epoch: 6| Step: 1
Training loss: 1.4252940560493883
Validation loss: 2.253055043465949

Epoch: 6| Step: 2
Training loss: 1.258885275609337
Validation loss: 2.3551970947486294

Epoch: 6| Step: 3
Training loss: 1.7798420879954697
Validation loss: 2.300985512654335

Epoch: 6| Step: 4
Training loss: 1.769367538862219
Validation loss: 2.290977223483272

Epoch: 6| Step: 5
Training loss: 2.0601365390452346
Validation loss: 2.368211507741665

Epoch: 6| Step: 6
Training loss: 2.4637750645431393
Validation loss: 2.3275394995947285

Epoch: 6| Step: 7
Training loss: 1.273661775088574
Validation loss: 2.3425692750109315

Epoch: 6| Step: 8
Training loss: 1.2385691599873037
Validation loss: 2.35783748326019

Epoch: 6| Step: 9
Training loss: 1.090967726757215
Validation loss: 2.319475310390449

Epoch: 6| Step: 10
Training loss: 1.6718187411816177
Validation loss: 2.3316792200598746

Epoch: 6| Step: 11
Training loss: 1.269200959889277
Validation loss: 2.3025362859750946

Epoch: 6| Step: 12
Training loss: 1.5603694886569628
Validation loss: 2.3129321556185927

Epoch: 6| Step: 13
Training loss: 1.4786522826076176
Validation loss: 2.313364543015704

Epoch: 299| Step: 0
Training loss: 1.1824406209316025
Validation loss: 2.330567078904518

Epoch: 6| Step: 1
Training loss: 1.6315751201183204
Validation loss: 2.3453504024588643

Epoch: 6| Step: 2
Training loss: 1.2086127330864904
Validation loss: 2.35474995051653

Epoch: 6| Step: 3
Training loss: 1.4703381656753831
Validation loss: 2.3469697992466636

Epoch: 6| Step: 4
Training loss: 1.8108831626237836
Validation loss: 2.3072148407050475

Epoch: 6| Step: 5
Training loss: 2.1837244421211737
Validation loss: 2.31405398086212

Epoch: 6| Step: 6
Training loss: 1.8444877700172713
Validation loss: 2.381205279825786

Epoch: 6| Step: 7
Training loss: 2.0286357783083475
Validation loss: 2.368023648113872

Epoch: 6| Step: 8
Training loss: 1.2085326896289796
Validation loss: 2.362271231835466

Epoch: 6| Step: 9
Training loss: 1.172029866475971
Validation loss: 2.3431681052158617

Epoch: 6| Step: 10
Training loss: 1.5299950731734193
Validation loss: 2.4001950163808594

Epoch: 6| Step: 11
Training loss: 1.5320507991774868
Validation loss: 2.2946558965544503

Epoch: 6| Step: 12
Training loss: 1.5484360033753646
Validation loss: 2.34632611475049

Epoch: 6| Step: 13
Training loss: 0.9619606587698876
Validation loss: 2.368995211550677

Epoch: 300| Step: 0
Training loss: 1.6453947215171676
Validation loss: 2.2772227422435294

Epoch: 6| Step: 1
Training loss: 1.1684788639310046
Validation loss: 2.3060328729999373

Epoch: 6| Step: 2
Training loss: 1.34172348865682
Validation loss: 2.3968295158801016

Epoch: 6| Step: 3
Training loss: 1.8685019746340719
Validation loss: 2.3048091188227664

Epoch: 6| Step: 4
Training loss: 2.1865916954927482
Validation loss: 2.303851971141126

Epoch: 6| Step: 5
Training loss: 1.4703697850158306
Validation loss: 2.3217213532928014

Epoch: 6| Step: 6
Training loss: 1.8205225745532538
Validation loss: 2.3262761387822173

Epoch: 6| Step: 7
Training loss: 2.1200067534429117
Validation loss: 2.321670066030607

Epoch: 6| Step: 8
Training loss: 1.3797936974303684
Validation loss: 2.390984451559253

Epoch: 6| Step: 9
Training loss: 1.2861880071175502
Validation loss: 2.367419773736728

Epoch: 6| Step: 10
Training loss: 1.4037588306397217
Validation loss: 2.340057623488263

Epoch: 6| Step: 11
Training loss: 1.264495062640813
Validation loss: 2.3166117277939886

Epoch: 6| Step: 12
Training loss: 1.5323164982169994
Validation loss: 2.3026223756842326

Epoch: 6| Step: 13
Training loss: 1.3811808728487571
Validation loss: 2.3173837716319823

Epoch: 301| Step: 0
Training loss: 1.7135053203712773
Validation loss: 2.2771365594337603

Epoch: 6| Step: 1
Training loss: 1.608295263653516
Validation loss: 2.3765470963323456

Epoch: 6| Step: 2
Training loss: 1.624206055577346
Validation loss: 2.384302752853947

Epoch: 6| Step: 3
Training loss: 1.26658593890952
Validation loss: 2.3424967291070162

Epoch: 6| Step: 4
Training loss: 2.5492295690804356
Validation loss: 2.3413028161833265

Epoch: 6| Step: 5
Training loss: 1.5060875072917779
Validation loss: 2.3183388004032244

Epoch: 6| Step: 6
Training loss: 1.2449857275883944
Validation loss: 2.3241115761479847

Epoch: 6| Step: 7
Training loss: 1.2563859894438592
Validation loss: 2.349370463835893

Epoch: 6| Step: 8
Training loss: 2.0087647313715453
Validation loss: 2.2833603175237736

Epoch: 6| Step: 9
Training loss: 1.0793567200456327
Validation loss: 2.351832332821125

Epoch: 6| Step: 10
Training loss: 1.356923315030564
Validation loss: 2.276125181107716

Epoch: 6| Step: 11
Training loss: 1.4147295985310546
Validation loss: 2.3257537028122632

Epoch: 6| Step: 12
Training loss: 1.4997772210307698
Validation loss: 2.319275581062432

Epoch: 6| Step: 13
Training loss: 1.4069698610527834
Validation loss: 2.282469012026465

Epoch: 302| Step: 0
Training loss: 1.6779004904029857
Validation loss: 2.294591207356822

Epoch: 6| Step: 1
Training loss: 1.468630035046297
Validation loss: 2.2963310481025796

Epoch: 6| Step: 2
Training loss: 1.6356857791113366
Validation loss: 2.335820636493571

Epoch: 6| Step: 3
Training loss: 1.5433763183034468
Validation loss: 2.31761688313783

Epoch: 6| Step: 4
Training loss: 1.5561567102376377
Validation loss: 2.330316544841948

Epoch: 6| Step: 5
Training loss: 1.4386436225546912
Validation loss: 2.3413644377164666

Epoch: 6| Step: 6
Training loss: 1.1977859536326199
Validation loss: 2.3084346198011794

Epoch: 6| Step: 7
Training loss: 1.5097364099594912
Validation loss: 2.2956909633644056

Epoch: 6| Step: 8
Training loss: 2.3058844093076596
Validation loss: 2.3348206613698057

Epoch: 6| Step: 9
Training loss: 1.5189629990150217
Validation loss: 2.343434855832249

Epoch: 6| Step: 10
Training loss: 1.5360817485453406
Validation loss: 2.280526652093903

Epoch: 6| Step: 11
Training loss: 1.8421502365989753
Validation loss: 2.3708945056485944

Epoch: 6| Step: 12
Training loss: 1.2520949927541947
Validation loss: 2.3573250147503106

Epoch: 6| Step: 13
Training loss: 1.3198217800511598
Validation loss: 2.3345171359789867

Epoch: 303| Step: 0
Training loss: 2.2264497427246503
Validation loss: 2.2913453586292687

Epoch: 6| Step: 1
Training loss: 0.9419695803029228
Validation loss: 2.3201452765171857

Epoch: 6| Step: 2
Training loss: 1.5647731267996943
Validation loss: 2.3696591211840046

Epoch: 6| Step: 3
Training loss: 1.6951120847028998
Validation loss: 2.330131747785541

Epoch: 6| Step: 4
Training loss: 1.536182012333926
Validation loss: 2.3491635475878176

Epoch: 6| Step: 5
Training loss: 1.2495674338521208
Validation loss: 2.3220458025885455

Epoch: 6| Step: 6
Training loss: 1.073716479700823
Validation loss: 2.3157994877856614

Epoch: 6| Step: 7
Training loss: 1.9582571731800282
Validation loss: 2.3772907220068675

Epoch: 6| Step: 8
Training loss: 1.3283511698509307
Validation loss: 2.3507921322951586

Epoch: 6| Step: 9
Training loss: 1.996443447230169
Validation loss: 2.3366572711969793

Epoch: 6| Step: 10
Training loss: 1.3099369727690178
Validation loss: 2.3320050586352252

Epoch: 6| Step: 11
Training loss: 1.7558095413621404
Validation loss: 2.3270275664701954

Epoch: 6| Step: 12
Training loss: 1.5097685464729578
Validation loss: 2.2677583047610974

Epoch: 6| Step: 13
Training loss: 1.3991064251277021
Validation loss: 2.298154983105156

Epoch: 304| Step: 0
Training loss: 1.7258561704786408
Validation loss: 2.363271617132461

Epoch: 6| Step: 1
Training loss: 1.1183646342866371
Validation loss: 2.4051218433926165

Epoch: 6| Step: 2
Training loss: 1.472883050185148
Validation loss: 2.2792654391273786

Epoch: 6| Step: 3
Training loss: 1.3785177661579697
Validation loss: 2.2501722290407127

Epoch: 6| Step: 4
Training loss: 1.3690971770310605
Validation loss: 2.3654057124913694

Epoch: 6| Step: 5
Training loss: 1.4316073175695736
Validation loss: 2.309074808557167

Epoch: 6| Step: 6
Training loss: 1.5940759362927868
Validation loss: 2.3070551309044474

Epoch: 6| Step: 7
Training loss: 1.28757719530695
Validation loss: 2.2973853186067736

Epoch: 6| Step: 8
Training loss: 0.7862309933595396
Validation loss: 2.3233857948693752

Epoch: 6| Step: 9
Training loss: 1.567164896139294
Validation loss: 2.354540029094919

Epoch: 6| Step: 10
Training loss: 1.82237539338973
Validation loss: 2.4162151740943214

Epoch: 6| Step: 11
Training loss: 2.3569731960917006
Validation loss: 2.336183935622618

Epoch: 6| Step: 12
Training loss: 1.5805611267095945
Validation loss: 2.3547573036547322

Epoch: 6| Step: 13
Training loss: 2.303349303628602
Validation loss: 2.2778364346626105

Epoch: 305| Step: 0
Training loss: 0.9142159227253499
Validation loss: 2.3542400707663975

Epoch: 6| Step: 1
Training loss: 2.531575499904901
Validation loss: 2.3600652063137733

Epoch: 6| Step: 2
Training loss: 2.0239232485471184
Validation loss: 2.3199297651215396

Epoch: 6| Step: 3
Training loss: 1.3998194850620123
Validation loss: 2.3534318468816107

Epoch: 6| Step: 4
Training loss: 1.3026068080228097
Validation loss: 2.2893902025622843

Epoch: 6| Step: 5
Training loss: 1.8989017374209038
Validation loss: 2.357074355003808

Epoch: 6| Step: 6
Training loss: 1.2173591894229032
Validation loss: 2.329357937322304

Epoch: 6| Step: 7
Training loss: 0.9933417807343596
Validation loss: 2.314282242407445

Epoch: 6| Step: 8
Training loss: 1.5151733039965425
Validation loss: 2.282867850259781

Epoch: 6| Step: 9
Training loss: 1.655078473607653
Validation loss: 2.3618793144673265

Epoch: 6| Step: 10
Training loss: 1.4657088103254512
Validation loss: 2.3489568188408234

Epoch: 6| Step: 11
Training loss: 1.4279166338812708
Validation loss: 2.250259443704638

Epoch: 6| Step: 12
Training loss: 1.0882608821192483
Validation loss: 2.311073200628213

Epoch: 6| Step: 13
Training loss: 1.6854789782095558
Validation loss: 2.3110929896471424

Epoch: 306| Step: 0
Training loss: 2.1233086306194484
Validation loss: 2.3450322516429414

Epoch: 6| Step: 1
Training loss: 1.5535018463713126
Validation loss: 2.3370968895789592

Epoch: 6| Step: 2
Training loss: 1.3834074647795522
Validation loss: 2.2908785274852232

Epoch: 6| Step: 3
Training loss: 1.2765270737176246
Validation loss: 2.3762444688277418

Epoch: 6| Step: 4
Training loss: 1.8564469820563902
Validation loss: 2.2994468186016053

Epoch: 6| Step: 5
Training loss: 1.095435179453229
Validation loss: 2.361561300712689

Epoch: 6| Step: 6
Training loss: 1.5012673745908776
Validation loss: 2.3735927974566198

Epoch: 6| Step: 7
Training loss: 1.5730090924659237
Validation loss: 2.4570752994235363

Epoch: 6| Step: 8
Training loss: 1.6534521114588396
Validation loss: 2.2967420735840487

Epoch: 6| Step: 9
Training loss: 1.984443002571891
Validation loss: 2.302299678289691

Epoch: 6| Step: 10
Training loss: 1.1306570132285056
Validation loss: 2.3571450046514784

Epoch: 6| Step: 11
Training loss: 1.2920692288242859
Validation loss: 2.3429535724706456

Epoch: 6| Step: 12
Training loss: 1.874253187860976
Validation loss: 2.396231036105642

Epoch: 6| Step: 13
Training loss: 0.8554198020274333
Validation loss: 2.3363644886707027

Epoch: 307| Step: 0
Training loss: 1.5647636800650389
Validation loss: 2.3717005943211222

Epoch: 6| Step: 1
Training loss: 1.1094490886179909
Validation loss: 2.3523039102314747

Epoch: 6| Step: 2
Training loss: 1.5527577140541557
Validation loss: 2.351418317384399

Epoch: 6| Step: 3
Training loss: 1.8412527208897311
Validation loss: 2.368648715268245

Epoch: 6| Step: 4
Training loss: 0.9393841565485996
Validation loss: 2.362704245736497

Epoch: 6| Step: 5
Training loss: 1.7653361396469522
Validation loss: 2.3346917637612408

Epoch: 6| Step: 6
Training loss: 1.4832553053631938
Validation loss: 2.2684660515982107

Epoch: 6| Step: 7
Training loss: 1.1334146937917415
Validation loss: 2.3473292223612465

Epoch: 6| Step: 8
Training loss: 1.2778466310931569
Validation loss: 2.333867982692856

Epoch: 6| Step: 9
Training loss: 1.5945863212409268
Validation loss: 2.339750188719251

Epoch: 6| Step: 10
Training loss: 1.4276567221422929
Validation loss: 2.288952135007467

Epoch: 6| Step: 11
Training loss: 1.7604808306615989
Validation loss: 2.3417793526495494

Epoch: 6| Step: 12
Training loss: 1.5493306406679463
Validation loss: 2.3261795036243385

Epoch: 6| Step: 13
Training loss: 2.9460414318374797
Validation loss: 2.3385823213372543

Epoch: 308| Step: 0
Training loss: 1.0827353489901208
Validation loss: 2.3309156990215456

Epoch: 6| Step: 1
Training loss: 1.1826085185608157
Validation loss: 2.349373813827417

Epoch: 6| Step: 2
Training loss: 1.3857168097185117
Validation loss: 2.336161783060875

Epoch: 6| Step: 3
Training loss: 1.343509430753192
Validation loss: 2.340246726796979

Epoch: 6| Step: 4
Training loss: 1.2261331863837828
Validation loss: 2.3247046045811395

Epoch: 6| Step: 5
Training loss: 1.544064598614784
Validation loss: 2.343318821338979

Epoch: 6| Step: 6
Training loss: 2.378854735369469
Validation loss: 2.3244875351172487

Epoch: 6| Step: 7
Training loss: 1.8743204792840846
Validation loss: 2.3265388295559233

Epoch: 6| Step: 8
Training loss: 1.8627664106683133
Validation loss: 2.3400456283249906

Epoch: 6| Step: 9
Training loss: 1.231903305618802
Validation loss: 2.2862906580332236

Epoch: 6| Step: 10
Training loss: 1.8716242601590256
Validation loss: 2.3768950470320274

Epoch: 6| Step: 11
Training loss: 1.6581370561825013
Validation loss: 2.3071346693894212

Epoch: 6| Step: 12
Training loss: 1.2067264307793442
Validation loss: 2.2887735385676446

Epoch: 6| Step: 13
Training loss: 1.453151907722983
Validation loss: 2.3101023133981617

Epoch: 309| Step: 0
Training loss: 2.0103917754482072
Validation loss: 2.342605900049673

Epoch: 6| Step: 1
Training loss: 2.0635056789237782
Validation loss: 2.312208602957522

Epoch: 6| Step: 2
Training loss: 1.0646162275593618
Validation loss: 2.3645306244750985

Epoch: 6| Step: 3
Training loss: 0.8600125808682737
Validation loss: 2.328263025348519

Epoch: 6| Step: 4
Training loss: 1.3448706988044188
Validation loss: 2.307299919190511

Epoch: 6| Step: 5
Training loss: 1.455016842774113
Validation loss: 2.294755451745804

Epoch: 6| Step: 6
Training loss: 1.7919669749801628
Validation loss: 2.3499351143851968

Epoch: 6| Step: 7
Training loss: 1.3311978415000592
Validation loss: 2.3171899375946685

Epoch: 6| Step: 8
Training loss: 1.406197780063414
Validation loss: 2.3356517189329287

Epoch: 6| Step: 9
Training loss: 1.654025040848655
Validation loss: 2.3034793223842334

Epoch: 6| Step: 10
Training loss: 2.0038864997351524
Validation loss: 2.337079173482036

Epoch: 6| Step: 11
Training loss: 1.2318953222014262
Validation loss: 2.3250076991348614

Epoch: 6| Step: 12
Training loss: 1.8255916550884375
Validation loss: 2.2629212401520764

Epoch: 6| Step: 13
Training loss: 1.5229219004292798
Validation loss: 2.3328205829275346

Epoch: 310| Step: 0
Training loss: 1.2660311765342374
Validation loss: 2.3147082672983754

Epoch: 6| Step: 1
Training loss: 1.3079646178164208
Validation loss: 2.2754235024567753

Epoch: 6| Step: 2
Training loss: 1.0923545109400639
Validation loss: 2.33630019718883

Epoch: 6| Step: 3
Training loss: 2.0623589669761646
Validation loss: 2.29371112080708

Epoch: 6| Step: 4
Training loss: 1.1924497443431814
Validation loss: 2.368905649989473

Epoch: 6| Step: 5
Training loss: 1.6676422442799974
Validation loss: 2.2752428739446033

Epoch: 6| Step: 6
Training loss: 1.7768980704093613
Validation loss: 2.362267170848999

Epoch: 6| Step: 7
Training loss: 2.0408380604579266
Validation loss: 2.3242782622380953

Epoch: 6| Step: 8
Training loss: 1.294376310147995
Validation loss: 2.322942276628665

Epoch: 6| Step: 9
Training loss: 1.5324359894121216
Validation loss: 2.3974133610706496

Epoch: 6| Step: 10
Training loss: 1.5956424622228298
Validation loss: 2.352237911716916

Epoch: 6| Step: 11
Training loss: 1.8846148969239422
Validation loss: 2.384707342225434

Epoch: 6| Step: 12
Training loss: 1.2099591148184163
Validation loss: 2.320457566934094

Epoch: 6| Step: 13
Training loss: 0.9250017900707348
Validation loss: 2.3508207654259543

Epoch: 311| Step: 0
Training loss: 1.2170305104314036
Validation loss: 2.3103412250983144

Epoch: 6| Step: 1
Training loss: 1.3262527733287524
Validation loss: 2.298764868063448

Epoch: 6| Step: 2
Training loss: 2.3049901731203004
Validation loss: 2.263600091145425

Epoch: 6| Step: 3
Training loss: 1.4451531399687114
Validation loss: 2.334638030760803

Epoch: 6| Step: 4
Training loss: 1.76662673215296
Validation loss: 2.354607315342745

Epoch: 6| Step: 5
Training loss: 1.411826542009641
Validation loss: 2.3303660329116647

Epoch: 6| Step: 6
Training loss: 1.3618343949796798
Validation loss: 2.274430099751513

Epoch: 6| Step: 7
Training loss: 1.5683554225316012
Validation loss: 2.269985907505778

Epoch: 6| Step: 8
Training loss: 1.645677253307906
Validation loss: 2.3316315113743324

Epoch: 6| Step: 9
Training loss: 1.4521757737686345
Validation loss: 2.3218724402389537

Epoch: 6| Step: 10
Training loss: 1.5000577756563267
Validation loss: 2.2805531631927547

Epoch: 6| Step: 11
Training loss: 1.672823057805891
Validation loss: 2.3656075876507914

Epoch: 6| Step: 12
Training loss: 1.2456291552377197
Validation loss: 2.317133964629486

Epoch: 6| Step: 13
Training loss: 1.0502930822509817
Validation loss: 2.339089295214358

Epoch: 312| Step: 0
Training loss: 1.1000478083885066
Validation loss: 2.3133167619292814

Epoch: 6| Step: 1
Training loss: 1.5214539746441393
Validation loss: 2.3240248853903482

Epoch: 6| Step: 2
Training loss: 1.141022704303933
Validation loss: 2.3106093711279754

Epoch: 6| Step: 3
Training loss: 1.4629643705596447
Validation loss: 2.3093410046233176

Epoch: 6| Step: 4
Training loss: 0.7461717574796762
Validation loss: 2.363291683392642

Epoch: 6| Step: 5
Training loss: 1.4882426419594472
Validation loss: 2.374777523861798

Epoch: 6| Step: 6
Training loss: 1.9143467283387483
Validation loss: 2.335823393495276

Epoch: 6| Step: 7
Training loss: 1.5472165125694524
Validation loss: 2.3595947899949827

Epoch: 6| Step: 8
Training loss: 2.4222768142606625
Validation loss: 2.3776176720107265

Epoch: 6| Step: 9
Training loss: 1.571599252831992
Validation loss: 2.288103182536779

Epoch: 6| Step: 10
Training loss: 1.6459832746877345
Validation loss: 2.3334414128207137

Epoch: 6| Step: 11
Training loss: 1.479400490918709
Validation loss: 2.314943402395665

Epoch: 6| Step: 12
Training loss: 1.40500967640107
Validation loss: 2.291638177450375

Epoch: 6| Step: 13
Training loss: 1.4819487167164933
Validation loss: 2.2867086705478967

Epoch: 313| Step: 0
Training loss: 1.34587922072154
Validation loss: 2.242531695021026

Epoch: 6| Step: 1
Training loss: 2.0623670592957177
Validation loss: 2.313890973921602

Epoch: 6| Step: 2
Training loss: 1.538359583172303
Validation loss: 2.295726497631344

Epoch: 6| Step: 3
Training loss: 0.8749514634430844
Validation loss: 2.346637400392668

Epoch: 6| Step: 4
Training loss: 2.03760953269439
Validation loss: 2.2447940253575673

Epoch: 6| Step: 5
Training loss: 1.6064224566193226
Validation loss: 2.302190332056376

Epoch: 6| Step: 6
Training loss: 1.1746861627139318
Validation loss: 2.298330578399656

Epoch: 6| Step: 7
Training loss: 1.7898417279262435
Validation loss: 2.2912528636744787

Epoch: 6| Step: 8
Training loss: 1.2806901406382907
Validation loss: 2.2844110441073804

Epoch: 6| Step: 9
Training loss: 1.4906170954784603
Validation loss: 2.2899891009216695

Epoch: 6| Step: 10
Training loss: 1.685730819124604
Validation loss: 2.2759473978296905

Epoch: 6| Step: 11
Training loss: 1.5642380774971696
Validation loss: 2.371584935309931

Epoch: 6| Step: 12
Training loss: 1.4374941120856404
Validation loss: 2.311743690469772

Epoch: 6| Step: 13
Training loss: 1.0304200271529025
Validation loss: 2.3016352828352633

Epoch: 314| Step: 0
Training loss: 1.2868458039509074
Validation loss: 2.36929979616349

Epoch: 6| Step: 1
Training loss: 1.381079671032507
Validation loss: 2.3347411596411605

Epoch: 6| Step: 2
Training loss: 0.9864363507107801
Validation loss: 2.309200085296191

Epoch: 6| Step: 3
Training loss: 1.3564465428697623
Validation loss: 2.278792197500239

Epoch: 6| Step: 4
Training loss: 1.680347259825997
Validation loss: 2.338037469698923

Epoch: 6| Step: 5
Training loss: 1.3167057319270092
Validation loss: 2.3523361824244597

Epoch: 6| Step: 6
Training loss: 1.541495554251606
Validation loss: 2.304503143540006

Epoch: 6| Step: 7
Training loss: 1.8441372480888776
Validation loss: 2.3787965066090444

Epoch: 6| Step: 8
Training loss: 1.7028401687846795
Validation loss: 2.3439280441639014

Epoch: 6| Step: 9
Training loss: 1.742475408875864
Validation loss: 2.361786898569376

Epoch: 6| Step: 10
Training loss: 1.1087499657666395
Validation loss: 2.3078623671669867

Epoch: 6| Step: 11
Training loss: 1.2326965509577628
Validation loss: 2.4047014367190127

Epoch: 6| Step: 12
Training loss: 2.4297316568661325
Validation loss: 2.341217452383988

Epoch: 6| Step: 13
Training loss: 1.7149441283442108
Validation loss: 2.32078846728491

Epoch: 315| Step: 0
Training loss: 1.6396772281011638
Validation loss: 2.3147468083918805

Epoch: 6| Step: 1
Training loss: 1.4953892097209358
Validation loss: 2.3458958756703363

Epoch: 6| Step: 2
Training loss: 2.3288903738438544
Validation loss: 2.2638796376608177

Epoch: 6| Step: 3
Training loss: 1.6712100408965527
Validation loss: 2.327028683023002

Epoch: 6| Step: 4
Training loss: 1.9001569457233625
Validation loss: 2.2580155439823577

Epoch: 6| Step: 5
Training loss: 1.6057701106444644
Validation loss: 2.2994855474809657

Epoch: 6| Step: 6
Training loss: 0.9227669813360384
Validation loss: 2.310000667867576

Epoch: 6| Step: 7
Training loss: 1.049330266166027
Validation loss: 2.321947975056966

Epoch: 6| Step: 8
Training loss: 1.5502727453159282
Validation loss: 2.295299798257418

Epoch: 6| Step: 9
Training loss: 1.4873072523369217
Validation loss: 2.2878982319685663

Epoch: 6| Step: 10
Training loss: 1.4170537681527604
Validation loss: 2.350879357783653

Epoch: 6| Step: 11
Training loss: 1.4167183230836888
Validation loss: 2.2667512407696715

Epoch: 6| Step: 12
Training loss: 1.0790494189890496
Validation loss: 2.2610310724676954

Epoch: 6| Step: 13
Training loss: 0.958788228224024
Validation loss: 2.305433110644665

Epoch: 316| Step: 0
Training loss: 1.4867657331779518
Validation loss: 2.3470027553838007

Epoch: 6| Step: 1
Training loss: 1.4359660049282401
Validation loss: 2.3329020297864553

Epoch: 6| Step: 2
Training loss: 1.5413461386342269
Validation loss: 2.359982262510493

Epoch: 6| Step: 3
Training loss: 1.459203251732792
Validation loss: 2.3351371053195105

Epoch: 6| Step: 4
Training loss: 1.3036698809956118
Validation loss: 2.3175467082337993

Epoch: 6| Step: 5
Training loss: 1.5528750949648635
Validation loss: 2.2821799273797323

Epoch: 6| Step: 6
Training loss: 1.133028943660956
Validation loss: 2.2762297229753776

Epoch: 6| Step: 7
Training loss: 2.546370661128061
Validation loss: 2.275191627999684

Epoch: 6| Step: 8
Training loss: 1.323175610208195
Validation loss: 2.3187024653753587

Epoch: 6| Step: 9
Training loss: 1.0577193023331266
Validation loss: 2.3244386294075525

Epoch: 6| Step: 10
Training loss: 1.6658899722728504
Validation loss: 2.2623601487807714

Epoch: 6| Step: 11
Training loss: 1.4728378871945027
Validation loss: 2.294205005034678

Epoch: 6| Step: 12
Training loss: 1.5504937277737445
Validation loss: 2.3212244937338355

Epoch: 6| Step: 13
Training loss: 1.7119917734964532
Validation loss: 2.295008223529598

Epoch: 317| Step: 0
Training loss: 2.0717564567611686
Validation loss: 2.340622646635585

Epoch: 6| Step: 1
Training loss: 1.8525664106812736
Validation loss: 2.2935537697528834

Epoch: 6| Step: 2
Training loss: 1.4870157944354156
Validation loss: 2.341087063435401

Epoch: 6| Step: 3
Training loss: 1.0483034551352304
Validation loss: 2.2960306680164746

Epoch: 6| Step: 4
Training loss: 1.8677238428252345
Validation loss: 2.317928188653737

Epoch: 6| Step: 5
Training loss: 1.22463682591093
Validation loss: 2.318202538575275

Epoch: 6| Step: 6
Training loss: 1.4164564406796616
Validation loss: 2.305575396607296

Epoch: 6| Step: 7
Training loss: 1.713096197443552
Validation loss: 2.390751144144876

Epoch: 6| Step: 8
Training loss: 1.283298343742929
Validation loss: 2.3230537250142276

Epoch: 6| Step: 9
Training loss: 1.71330411089506
Validation loss: 2.415013821266209

Epoch: 6| Step: 10
Training loss: 1.101361357809956
Validation loss: 2.285917557652856

Epoch: 6| Step: 11
Training loss: 1.7516066124539724
Validation loss: 2.3350583049386833

Epoch: 6| Step: 12
Training loss: 1.2061900939296806
Validation loss: 2.3511569267163455

Epoch: 6| Step: 13
Training loss: 0.7383843001849877
Validation loss: 2.3236390361941766

Epoch: 318| Step: 0
Training loss: 1.6059424079839322
Validation loss: 2.334799006998622

Epoch: 6| Step: 1
Training loss: 1.5227752028418025
Validation loss: 2.2334242620249016

Epoch: 6| Step: 2
Training loss: 1.561186734483732
Validation loss: 2.3570221418806323

Epoch: 6| Step: 3
Training loss: 0.8414239610598429
Validation loss: 2.3337027159213917

Epoch: 6| Step: 4
Training loss: 1.746074155829832
Validation loss: 2.3097247349270025

Epoch: 6| Step: 5
Training loss: 1.4768311594212453
Validation loss: 2.322173719670255

Epoch: 6| Step: 6
Training loss: 1.5732291544890018
Validation loss: 2.3258643419173293

Epoch: 6| Step: 7
Training loss: 1.3426961980625953
Validation loss: 2.320249007299512

Epoch: 6| Step: 8
Training loss: 1.2052675466187974
Validation loss: 2.371378916054165

Epoch: 6| Step: 9
Training loss: 2.3786189966015265
Validation loss: 2.3070408050406024

Epoch: 6| Step: 10
Training loss: 1.3389890741895358
Validation loss: 2.29738863671796

Epoch: 6| Step: 11
Training loss: 0.9915422158461301
Validation loss: 2.309128130827348

Epoch: 6| Step: 12
Training loss: 1.3923323790306696
Validation loss: 2.3732161750124607

Epoch: 6| Step: 13
Training loss: 1.6321282664270196
Validation loss: 2.3515148038765656

Epoch: 319| Step: 0
Training loss: 1.2875083108281904
Validation loss: 2.343187666398647

Epoch: 6| Step: 1
Training loss: 2.009497028638129
Validation loss: 2.3310282278118435

Epoch: 6| Step: 2
Training loss: 1.0699329677868847
Validation loss: 2.3196144693393386

Epoch: 6| Step: 3
Training loss: 1.0399241495899254
Validation loss: 2.310264916859964

Epoch: 6| Step: 4
Training loss: 1.8516492219727525
Validation loss: 2.3780305888396653

Epoch: 6| Step: 5
Training loss: 1.34693668339292
Validation loss: 2.3384718607849426

Epoch: 6| Step: 6
Training loss: 1.5809299733182014
Validation loss: 2.313189487165435

Epoch: 6| Step: 7
Training loss: 1.136404669194228
Validation loss: 2.322348797620513

Epoch: 6| Step: 8
Training loss: 1.1425349822417068
Validation loss: 2.3480025555354502

Epoch: 6| Step: 9
Training loss: 1.1152570892532805
Validation loss: 2.310910656258709

Epoch: 6| Step: 10
Training loss: 1.3975120764331699
Validation loss: 2.278156170573479

Epoch: 6| Step: 11
Training loss: 1.7300843787150253
Validation loss: 2.315676740163783

Epoch: 6| Step: 12
Training loss: 2.1805396379779407
Validation loss: 2.428719524433661

Epoch: 6| Step: 13
Training loss: 0.9309676196657537
Validation loss: 2.3471726604071335

Epoch: 320| Step: 0
Training loss: 1.1778932783685583
Validation loss: 2.3071632365250685

Epoch: 6| Step: 1
Training loss: 2.3268888122984746
Validation loss: 2.336158027847786

Epoch: 6| Step: 2
Training loss: 1.132520598588437
Validation loss: 2.3041002885688324

Epoch: 6| Step: 3
Training loss: 1.4995682412875782
Validation loss: 2.3001069041834863

Epoch: 6| Step: 4
Training loss: 1.3317972464311156
Validation loss: 2.268146543951308

Epoch: 6| Step: 5
Training loss: 1.820663745702251
Validation loss: 2.3970871411090156

Epoch: 6| Step: 6
Training loss: 1.5415559505537721
Validation loss: 2.322130840017199

Epoch: 6| Step: 7
Training loss: 1.6238601061085327
Validation loss: 2.330813588487758

Epoch: 6| Step: 8
Training loss: 1.4697982618516026
Validation loss: 2.299356326408041

Epoch: 6| Step: 9
Training loss: 1.3330362505551714
Validation loss: 2.3027589911067166

Epoch: 6| Step: 10
Training loss: 1.3550203664593357
Validation loss: 2.306496576355262

Epoch: 6| Step: 11
Training loss: 1.2549504955756303
Validation loss: 2.3129797911407035

Epoch: 6| Step: 12
Training loss: 1.472476371484887
Validation loss: 2.2935163150156996

Epoch: 6| Step: 13
Training loss: 1.2573454090295662
Validation loss: 2.348902699194331

Epoch: 321| Step: 0
Training loss: 1.4905338411427622
Validation loss: 2.35480056302792

Epoch: 6| Step: 1
Training loss: 2.3403240341409632
Validation loss: 2.3270087981673955

Epoch: 6| Step: 2
Training loss: 1.8261515080749287
Validation loss: 2.370000974184972

Epoch: 6| Step: 3
Training loss: 1.914377116601604
Validation loss: 2.3137477910604707

Epoch: 6| Step: 4
Training loss: 1.4534698405304263
Validation loss: 2.3285670995233905

Epoch: 6| Step: 5
Training loss: 1.0441859425629993
Validation loss: 2.348638618425734

Epoch: 6| Step: 6
Training loss: 1.3608740948382967
Validation loss: 2.2777323964886627

Epoch: 6| Step: 7
Training loss: 1.0704463123291335
Validation loss: 2.362570521538155

Epoch: 6| Step: 8
Training loss: 1.2181558383347824
Validation loss: 2.293258814395438

Epoch: 6| Step: 9
Training loss: 1.1120659870973546
Validation loss: 2.3203232475853044

Epoch: 6| Step: 10
Training loss: 1.5311555638678749
Validation loss: 2.3216803849681895

Epoch: 6| Step: 11
Training loss: 1.578508462679595
Validation loss: 2.2727377918145404

Epoch: 6| Step: 12
Training loss: 1.2528323033842708
Validation loss: 2.2949606243868854

Epoch: 6| Step: 13
Training loss: 1.316634297073614
Validation loss: 2.3056528229508615

Epoch: 322| Step: 0
Training loss: 1.6025920257091943
Validation loss: 2.2652601294086363

Epoch: 6| Step: 1
Training loss: 1.1128568141376423
Validation loss: 2.3982147394465114

Epoch: 6| Step: 2
Training loss: 2.394832225011976
Validation loss: 2.3695087497019234

Epoch: 6| Step: 3
Training loss: 1.8303821030353697
Validation loss: 2.3360544860587424

Epoch: 6| Step: 4
Training loss: 1.2133226101439885
Validation loss: 2.3047408926292037

Epoch: 6| Step: 5
Training loss: 1.2048799670255852
Validation loss: 2.2971971643208966

Epoch: 6| Step: 6
Training loss: 1.1560092366057453
Validation loss: 2.3050006701651493

Epoch: 6| Step: 7
Training loss: 1.0875869957338997
Validation loss: 2.2524435841197423

Epoch: 6| Step: 8
Training loss: 1.6749934409852922
Validation loss: 2.3389421236111883

Epoch: 6| Step: 9
Training loss: 1.3421306611394956
Validation loss: 2.3296424989300495

Epoch: 6| Step: 10
Training loss: 1.7790478260930045
Validation loss: 2.3272629649345666

Epoch: 6| Step: 11
Training loss: 1.4701959513119012
Validation loss: 2.349888350732623

Epoch: 6| Step: 12
Training loss: 1.1648444295327285
Validation loss: 2.3603957815583763

Epoch: 6| Step: 13
Training loss: 1.3874205626696274
Validation loss: 2.3767410819944934

Epoch: 323| Step: 0
Training loss: 1.4656407337116901
Validation loss: 2.304427538087503

Epoch: 6| Step: 1
Training loss: 0.9320215370202909
Validation loss: 2.3374389285552915

Epoch: 6| Step: 2
Training loss: 1.2874553487497786
Validation loss: 2.2957069150748115

Epoch: 6| Step: 3
Training loss: 1.3816482038993787
Validation loss: 2.3795642312935708

Epoch: 6| Step: 4
Training loss: 1.5921854305534653
Validation loss: 2.316280064741635

Epoch: 6| Step: 5
Training loss: 1.4235407535358933
Validation loss: 2.4084587353066618

Epoch: 6| Step: 6
Training loss: 1.3229505829956472
Validation loss: 2.3006381003498224

Epoch: 6| Step: 7
Training loss: 1.0697372449919929
Validation loss: 2.271507106403416

Epoch: 6| Step: 8
Training loss: 1.6447936367468443
Validation loss: 2.3855351206705837

Epoch: 6| Step: 9
Training loss: 1.4946027452484243
Validation loss: 2.367808870658269

Epoch: 6| Step: 10
Training loss: 1.618872092219582
Validation loss: 2.2637942211709983

Epoch: 6| Step: 11
Training loss: 2.38438628707754
Validation loss: 2.305926575475659

Epoch: 6| Step: 12
Training loss: 1.6699145222106035
Validation loss: 2.3576005340764694

Epoch: 6| Step: 13
Training loss: 1.1865880877930928
Validation loss: 2.3523783333046153

Epoch: 324| Step: 0
Training loss: 1.5131527902792026
Validation loss: 2.3347857209984757

Epoch: 6| Step: 1
Training loss: 1.4471738634350475
Validation loss: 2.3130869606902054

Epoch: 6| Step: 2
Training loss: 1.1788247597895574
Validation loss: 2.300516049291

Epoch: 6| Step: 3
Training loss: 1.3251073775777196
Validation loss: 2.2571719555736247

Epoch: 6| Step: 4
Training loss: 1.1342339903567853
Validation loss: 2.360761343134474

Epoch: 6| Step: 5
Training loss: 1.3539941775677131
Validation loss: 2.3476686736511785

Epoch: 6| Step: 6
Training loss: 1.524514155306209
Validation loss: 2.3248898015947437

Epoch: 6| Step: 7
Training loss: 1.758717892915624
Validation loss: 2.3296445699643535

Epoch: 6| Step: 8
Training loss: 1.4974176908362835
Validation loss: 2.3043643881343856

Epoch: 6| Step: 9
Training loss: 1.1789282572356208
Validation loss: 2.2874650643326553

Epoch: 6| Step: 10
Training loss: 2.340751459145898
Validation loss: 2.369088922909721

Epoch: 6| Step: 11
Training loss: 1.3200307692207227
Validation loss: 2.299361741657414

Epoch: 6| Step: 12
Training loss: 1.4430530930319514
Validation loss: 2.289473959225718

Epoch: 6| Step: 13
Training loss: 1.5744813458672309
Validation loss: 2.3351878783396005

Epoch: 325| Step: 0
Training loss: 1.3806200481030693
Validation loss: 2.243639096753186

Epoch: 6| Step: 1
Training loss: 1.1172768617116564
Validation loss: 2.3751432594740156

Epoch: 6| Step: 2
Training loss: 1.2459568917148207
Validation loss: 2.295123674522035

Epoch: 6| Step: 3
Training loss: 1.3088580875158373
Validation loss: 2.3108007511919118

Epoch: 6| Step: 4
Training loss: 1.2719432278265579
Validation loss: 2.267702221277977

Epoch: 6| Step: 5
Training loss: 1.7832073366213612
Validation loss: 2.2773699581892646

Epoch: 6| Step: 6
Training loss: 1.4695471365768074
Validation loss: 2.3040916021499873

Epoch: 6| Step: 7
Training loss: 2.211097522781169
Validation loss: 2.366815335851209

Epoch: 6| Step: 8
Training loss: 1.5725520471350023
Validation loss: 2.354672180474779

Epoch: 6| Step: 9
Training loss: 1.4020343747407593
Validation loss: 2.285924529964465

Epoch: 6| Step: 10
Training loss: 1.238997868780069
Validation loss: 2.3107113449094667

Epoch: 6| Step: 11
Training loss: 1.3926522554887912
Validation loss: 2.3121139644269033

Epoch: 6| Step: 12
Training loss: 1.6397944209878954
Validation loss: 2.362510075178451

Epoch: 6| Step: 13
Training loss: 1.1798827155065346
Validation loss: 2.3196014931360556

Epoch: 326| Step: 0
Training loss: 2.191448462856575
Validation loss: 2.361425225992323

Epoch: 6| Step: 1
Training loss: 1.3986669597231471
Validation loss: 2.246394875392287

Epoch: 6| Step: 2
Training loss: 0.9656494421473438
Validation loss: 2.3091195299356406

Epoch: 6| Step: 3
Training loss: 1.3389896973946454
Validation loss: 2.2768812614566656

Epoch: 6| Step: 4
Training loss: 1.321583649472172
Validation loss: 2.2910044238081726

Epoch: 6| Step: 5
Training loss: 1.3233477673516105
Validation loss: 2.321522459898906

Epoch: 6| Step: 6
Training loss: 1.4439969235596155
Validation loss: 2.321935285158451

Epoch: 6| Step: 7
Training loss: 1.6076628827619912
Validation loss: 2.291418918145972

Epoch: 6| Step: 8
Training loss: 1.301949099933069
Validation loss: 2.261414853917826

Epoch: 6| Step: 9
Training loss: 1.3772435524554658
Validation loss: 2.3077817006817503

Epoch: 6| Step: 10
Training loss: 1.3953459681206046
Validation loss: 2.35921164935059

Epoch: 6| Step: 11
Training loss: 1.9517474390000644
Validation loss: 2.350371860405652

Epoch: 6| Step: 12
Training loss: 1.3211741598372424
Validation loss: 2.3622851836908834

Epoch: 6| Step: 13
Training loss: 1.1551836096569057
Validation loss: 2.332152583911878

Epoch: 327| Step: 0
Training loss: 1.366219401248131
Validation loss: 2.299481546188478

Epoch: 6| Step: 1
Training loss: 1.747514321810165
Validation loss: 2.3632093789665602

Epoch: 6| Step: 2
Training loss: 1.825482276005041
Validation loss: 2.349055108944307

Epoch: 6| Step: 3
Training loss: 1.4895080156113818
Validation loss: 2.3053697736149363

Epoch: 6| Step: 4
Training loss: 1.3102834695501875
Validation loss: 2.3269486826139145

Epoch: 6| Step: 5
Training loss: 0.9171547385088307
Validation loss: 2.2947559759795433

Epoch: 6| Step: 6
Training loss: 1.143086377425253
Validation loss: 2.321385097817795

Epoch: 6| Step: 7
Training loss: 0.9519011660590666
Validation loss: 2.3768351841900865

Epoch: 6| Step: 8
Training loss: 0.9957256759059321
Validation loss: 2.3476316143506395

Epoch: 6| Step: 9
Training loss: 1.473837138698666
Validation loss: 2.3204046353806485

Epoch: 6| Step: 10
Training loss: 1.6026728061097197
Validation loss: 2.3846454823744008

Epoch: 6| Step: 11
Training loss: 0.915568618861255
Validation loss: 2.3165598587379166

Epoch: 6| Step: 12
Training loss: 1.510562109247672
Validation loss: 2.3180312571990482

Epoch: 6| Step: 13
Training loss: 2.8652040860916093
Validation loss: 2.33654982030053

Epoch: 328| Step: 0
Training loss: 1.551483917551287
Validation loss: 2.345574701915763

Epoch: 6| Step: 1
Training loss: 1.403304172282356
Validation loss: 2.33818761198705

Epoch: 6| Step: 2
Training loss: 1.475554025987869
Validation loss: 2.303451356188784

Epoch: 6| Step: 3
Training loss: 1.4264355973855847
Validation loss: 2.320813373516591

Epoch: 6| Step: 4
Training loss: 1.9889881848329083
Validation loss: 2.3448225655856416

Epoch: 6| Step: 5
Training loss: 1.0437938840857586
Validation loss: 2.375651334471083

Epoch: 6| Step: 6
Training loss: 1.6074365589680912
Validation loss: 2.324891485406953

Epoch: 6| Step: 7
Training loss: 1.3998059870619535
Validation loss: 2.300020749300349

Epoch: 6| Step: 8
Training loss: 1.4349066519863063
Validation loss: 2.3556085540059217

Epoch: 6| Step: 9
Training loss: 1.156224379384509
Validation loss: 2.3115322945137597

Epoch: 6| Step: 10
Training loss: 1.752416917189229
Validation loss: 2.279343002806785

Epoch: 6| Step: 11
Training loss: 1.534855393298868
Validation loss: 2.3295945719088396

Epoch: 6| Step: 12
Training loss: 1.96328946896285
Validation loss: 2.376710131385728

Epoch: 6| Step: 13
Training loss: 1.583273543517255
Validation loss: 2.2970621840404766

Epoch: 329| Step: 0
Training loss: 1.7918645912083642
Validation loss: 2.3351246934931704

Epoch: 6| Step: 1
Training loss: 1.5630138315283164
Validation loss: 2.2342665118392353

Epoch: 6| Step: 2
Training loss: 1.1288846551750256
Validation loss: 2.3387575745760953

Epoch: 6| Step: 3
Training loss: 1.5382939467480077
Validation loss: 2.333861952186685

Epoch: 6| Step: 4
Training loss: 1.8980714421508658
Validation loss: 2.39066538413689

Epoch: 6| Step: 5
Training loss: 1.1627758006594315
Validation loss: 2.3288446863765597

Epoch: 6| Step: 6
Training loss: 1.3463761151392126
Validation loss: 2.274266829655812

Epoch: 6| Step: 7
Training loss: 0.956510316409258
Validation loss: 2.3358664580541193

Epoch: 6| Step: 8
Training loss: 1.0818826180844918
Validation loss: 2.280190204101625

Epoch: 6| Step: 9
Training loss: 1.6019997348808994
Validation loss: 2.352970193491569

Epoch: 6| Step: 10
Training loss: 1.2413542249856198
Validation loss: 2.3665072964007856

Epoch: 6| Step: 11
Training loss: 1.063833633882589
Validation loss: 2.3236835544996155

Epoch: 6| Step: 12
Training loss: 2.4192953830509536
Validation loss: 2.2743171095636137

Epoch: 6| Step: 13
Training loss: 0.8139798918707787
Validation loss: 2.297523130845206

Epoch: 330| Step: 0
Training loss: 1.0957212939600451
Validation loss: 2.3141891709045495

Epoch: 6| Step: 1
Training loss: 1.0093992295324425
Validation loss: 2.298540745931572

Epoch: 6| Step: 2
Training loss: 1.1360656330195347
Validation loss: 2.3572808370552205

Epoch: 6| Step: 3
Training loss: 0.6550424000797599
Validation loss: 2.309645537601033

Epoch: 6| Step: 4
Training loss: 1.6716261348710528
Validation loss: 2.293747746968119

Epoch: 6| Step: 5
Training loss: 1.49165982008629
Validation loss: 2.282459289694865

Epoch: 6| Step: 6
Training loss: 1.9011314963102415
Validation loss: 2.294066576075725

Epoch: 6| Step: 7
Training loss: 1.7526532903610397
Validation loss: 2.3530296257220824

Epoch: 6| Step: 8
Training loss: 1.587606219244953
Validation loss: 2.3450252899954895

Epoch: 6| Step: 9
Training loss: 1.1856845229052522
Validation loss: 2.3116317777631923

Epoch: 6| Step: 10
Training loss: 1.272007519615787
Validation loss: 2.312480385433025

Epoch: 6| Step: 11
Training loss: 1.2682330257453664
Validation loss: 2.308485559227355

Epoch: 6| Step: 12
Training loss: 2.425928182037357
Validation loss: 2.297855671503459

Epoch: 6| Step: 13
Training loss: 0.7243492708417506
Validation loss: 2.332840770178173

Epoch: 331| Step: 0
Training loss: 1.4664939435488489
Validation loss: 2.3690418707436556

Epoch: 6| Step: 1
Training loss: 1.131143115985034
Validation loss: 2.325631135544317

Epoch: 6| Step: 2
Training loss: 1.3633973255310867
Validation loss: 2.3403933776592796

Epoch: 6| Step: 3
Training loss: 1.6675857711763242
Validation loss: 2.325374489575727

Epoch: 6| Step: 4
Training loss: 1.3513348338045568
Validation loss: 2.326136936418439

Epoch: 6| Step: 5
Training loss: 1.4097186648611568
Validation loss: 2.276012147226882

Epoch: 6| Step: 6
Training loss: 1.4600108262535967
Validation loss: 2.329656395292863

Epoch: 6| Step: 7
Training loss: 1.4665056490654391
Validation loss: 2.3123953112956914

Epoch: 6| Step: 8
Training loss: 2.098555217744486
Validation loss: 2.2718654054781404

Epoch: 6| Step: 9
Training loss: 1.0663285558994409
Validation loss: 2.2831140281133995

Epoch: 6| Step: 10
Training loss: 1.713203218964468
Validation loss: 2.324736167068859

Epoch: 6| Step: 11
Training loss: 1.643747972262332
Validation loss: 2.3077615383411003

Epoch: 6| Step: 12
Training loss: 1.0007559779815558
Validation loss: 2.316795873177953

Epoch: 6| Step: 13
Training loss: 1.3161167992470326
Validation loss: 2.2900455386515857

Epoch: 332| Step: 0
Training loss: 1.2694513853334584
Validation loss: 2.3558389142271827

Epoch: 6| Step: 1
Training loss: 1.2953325313772435
Validation loss: 2.2847700192460607

Epoch: 6| Step: 2
Training loss: 1.6176292811146147
Validation loss: 2.3215131275013383

Epoch: 6| Step: 3
Training loss: 1.448258156151427
Validation loss: 2.3364586079635776

Epoch: 6| Step: 4
Training loss: 1.4668190620461203
Validation loss: 2.4230582330253796

Epoch: 6| Step: 5
Training loss: 2.308984507168834
Validation loss: 2.3643797099721042

Epoch: 6| Step: 6
Training loss: 1.1068699452022541
Validation loss: 2.289531688377755

Epoch: 6| Step: 7
Training loss: 1.3995082315091794
Validation loss: 2.3915880775238136

Epoch: 6| Step: 8
Training loss: 1.3395296401460604
Validation loss: 2.3728363142202014

Epoch: 6| Step: 9
Training loss: 1.7402731466202115
Validation loss: 2.3633347746170106

Epoch: 6| Step: 10
Training loss: 0.8756311728718011
Validation loss: 2.3608972834647584

Epoch: 6| Step: 11
Training loss: 0.9389814433883555
Validation loss: 2.284843105459496

Epoch: 6| Step: 12
Training loss: 1.515010040426189
Validation loss: 2.2826024158449743

Epoch: 6| Step: 13
Training loss: 1.5191509486794448
Validation loss: 2.308500615733231

Epoch: 333| Step: 0
Training loss: 1.4970384608076064
Validation loss: 2.3054421100396474

Epoch: 6| Step: 1
Training loss: 1.071013395159787
Validation loss: 2.351248366981991

Epoch: 6| Step: 2
Training loss: 1.937121938921244
Validation loss: 2.279020919844464

Epoch: 6| Step: 3
Training loss: 1.363647368054348
Validation loss: 2.362177714510559

Epoch: 6| Step: 4
Training loss: 0.9420467113365594
Validation loss: 2.349690615235131

Epoch: 6| Step: 5
Training loss: 1.0834840461848514
Validation loss: 2.308931525779405

Epoch: 6| Step: 6
Training loss: 1.1042422982470446
Validation loss: 2.3673091643136432

Epoch: 6| Step: 7
Training loss: 2.1503195547335476
Validation loss: 2.353733117200616

Epoch: 6| Step: 8
Training loss: 1.0225135767811806
Validation loss: 2.2885438305622405

Epoch: 6| Step: 9
Training loss: 1.423913186545227
Validation loss: 2.35214995786481

Epoch: 6| Step: 10
Training loss: 1.5302563771633966
Validation loss: 2.3152524915670094

Epoch: 6| Step: 11
Training loss: 1.4106150380105218
Validation loss: 2.353263616075051

Epoch: 6| Step: 12
Training loss: 1.5433592483261702
Validation loss: 2.2899327647972365

Epoch: 6| Step: 13
Training loss: 1.6625648170398544
Validation loss: 2.303783975883171

Epoch: 334| Step: 0
Training loss: 1.4665803508212698
Validation loss: 2.3081037554759742

Epoch: 6| Step: 1
Training loss: 1.0993641229192277
Validation loss: 2.3219043666621166

Epoch: 6| Step: 2
Training loss: 1.268564554576955
Validation loss: 2.270689231460149

Epoch: 6| Step: 3
Training loss: 2.577710482478964
Validation loss: 2.35380806797572

Epoch: 6| Step: 4
Training loss: 1.2522288478558317
Validation loss: 2.3411031268770612

Epoch: 6| Step: 5
Training loss: 0.9006694105583238
Validation loss: 2.2599047591592005

Epoch: 6| Step: 6
Training loss: 1.525084949691336
Validation loss: 2.3138211879257398

Epoch: 6| Step: 7
Training loss: 1.5901951506951313
Validation loss: 2.3154241083192564

Epoch: 6| Step: 8
Training loss: 1.5056679451828425
Validation loss: 2.38643409349051

Epoch: 6| Step: 9
Training loss: 1.344981139664139
Validation loss: 2.3614122276752605

Epoch: 6| Step: 10
Training loss: 1.277793641729055
Validation loss: 2.3092384180208207

Epoch: 6| Step: 11
Training loss: 1.2831082243642635
Validation loss: 2.352955547932197

Epoch: 6| Step: 12
Training loss: 0.9248508977573523
Validation loss: 2.375179470731467

Epoch: 6| Step: 13
Training loss: 0.7426664312954135
Validation loss: 2.429257363810627

Epoch: 335| Step: 0
Training loss: 1.4712424536862327
Validation loss: 2.3761902888229067

Epoch: 6| Step: 1
Training loss: 1.6490353047216004
Validation loss: 2.3303211703149884

Epoch: 6| Step: 2
Training loss: 1.2908703236033914
Validation loss: 2.4088378444518845

Epoch: 6| Step: 3
Training loss: 1.3983415112504463
Validation loss: 2.3455770179161104

Epoch: 6| Step: 4
Training loss: 1.3874065573904832
Validation loss: 2.3934250353911675

Epoch: 6| Step: 5
Training loss: 2.148366032191993
Validation loss: 2.283912459170332

Epoch: 6| Step: 6
Training loss: 1.1901001321514144
Validation loss: 2.3388741948795206

Epoch: 6| Step: 7
Training loss: 1.299873562312842
Validation loss: 2.3349978344883477

Epoch: 6| Step: 8
Training loss: 0.8340749222426014
Validation loss: 2.3416570587349383

Epoch: 6| Step: 9
Training loss: 1.6150972430357466
Validation loss: 2.3169015868278007

Epoch: 6| Step: 10
Training loss: 1.4645650776593093
Validation loss: 2.340654505966436

Epoch: 6| Step: 11
Training loss: 1.200023964801546
Validation loss: 2.3081796647907376

Epoch: 6| Step: 12
Training loss: 1.5862898411718704
Validation loss: 2.252132323723538

Epoch: 6| Step: 13
Training loss: 1.4700960524960447
Validation loss: 2.325871763780404

Epoch: 336| Step: 0
Training loss: 1.6497834843848818
Validation loss: 2.286599374207477

Epoch: 6| Step: 1
Training loss: 1.6174018459814732
Validation loss: 2.3368371842927664

Epoch: 6| Step: 2
Training loss: 1.3220378730300544
Validation loss: 2.2592726136768175

Epoch: 6| Step: 3
Training loss: 1.30940071390254
Validation loss: 2.289726376925779

Epoch: 6| Step: 4
Training loss: 1.0372116124682569
Validation loss: 2.214259049757987

Epoch: 6| Step: 5
Training loss: 0.8385677136153008
Validation loss: 2.3194311981931484

Epoch: 6| Step: 6
Training loss: 2.165731949800679
Validation loss: 2.352056319873849

Epoch: 6| Step: 7
Training loss: 0.8991345562532441
Validation loss: 2.232379643387248

Epoch: 6| Step: 8
Training loss: 0.8827308009330441
Validation loss: 2.29119757123604

Epoch: 6| Step: 9
Training loss: 1.7650736395195061
Validation loss: 2.294850908908867

Epoch: 6| Step: 10
Training loss: 1.4373514679175825
Validation loss: 2.3323151097960184

Epoch: 6| Step: 11
Training loss: 1.4056830216878724
Validation loss: 2.284714909907427

Epoch: 6| Step: 12
Training loss: 1.836565275607203
Validation loss: 2.3513729613361476

Epoch: 6| Step: 13
Training loss: 1.2966179650451524
Validation loss: 2.3920542298308423

Epoch: 337| Step: 0
Training loss: 1.59614047123535
Validation loss: 2.318608664094253

Epoch: 6| Step: 1
Training loss: 1.1387024445135407
Validation loss: 2.3820108077401767

Epoch: 6| Step: 2
Training loss: 1.412274784936926
Validation loss: 2.278900763014271

Epoch: 6| Step: 3
Training loss: 1.5929068036497067
Validation loss: 2.333074234129086

Epoch: 6| Step: 4
Training loss: 1.2790302027789127
Validation loss: 2.3408552827184472

Epoch: 6| Step: 5
Training loss: 0.9142052302634659
Validation loss: 2.275558679120668

Epoch: 6| Step: 6
Training loss: 2.019355456376613
Validation loss: 2.241190656698509

Epoch: 6| Step: 7
Training loss: 1.3828387069373986
Validation loss: 2.3107603775062286

Epoch: 6| Step: 8
Training loss: 1.855646321683957
Validation loss: 2.3095472214511457

Epoch: 6| Step: 9
Training loss: 1.012923712434564
Validation loss: 2.3832157648427987

Epoch: 6| Step: 10
Training loss: 1.6676746975780794
Validation loss: 2.2633354389084768

Epoch: 6| Step: 11
Training loss: 1.3076144525386821
Validation loss: 2.3450146583567593

Epoch: 6| Step: 12
Training loss: 1.2715918617111706
Validation loss: 2.2722270880913484

Epoch: 6| Step: 13
Training loss: 1.2279224510216276
Validation loss: 2.2593155589966494

Epoch: 338| Step: 0
Training loss: 1.365213855158067
Validation loss: 2.386242440710853

Epoch: 6| Step: 1
Training loss: 1.3560841507302173
Validation loss: 2.261724796606232

Epoch: 6| Step: 2
Training loss: 1.4659250566340287
Validation loss: 2.2984357643947666

Epoch: 6| Step: 3
Training loss: 1.190460129584101
Validation loss: 2.367099412277987

Epoch: 6| Step: 4
Training loss: 1.3128776461122316
Validation loss: 2.308754968997445

Epoch: 6| Step: 5
Training loss: 1.3687347376421035
Validation loss: 2.3652306973773802

Epoch: 6| Step: 6
Training loss: 1.4134154973498783
Validation loss: 2.3508565149095118

Epoch: 6| Step: 7
Training loss: 1.4929777120164522
Validation loss: 2.2900824954648753

Epoch: 6| Step: 8
Training loss: 2.0597771675919354
Validation loss: 2.3177376399042986

Epoch: 6| Step: 9
Training loss: 1.3940863661015437
Validation loss: 2.3358262141504986

Epoch: 6| Step: 10
Training loss: 1.5174808741060257
Validation loss: 2.342484609632318

Epoch: 6| Step: 11
Training loss: 1.1688841227719118
Validation loss: 2.344508594541896

Epoch: 6| Step: 12
Training loss: 1.3586930065958556
Validation loss: 2.2961146966059234

Epoch: 6| Step: 13
Training loss: 1.3644581608716204
Validation loss: 2.301062385420758

Epoch: 339| Step: 0
Training loss: 1.4947917641386028
Validation loss: 2.3183551154564164

Epoch: 6| Step: 1
Training loss: 1.2707188142968273
Validation loss: 2.342368128586666

Epoch: 6| Step: 2
Training loss: 1.7645252144650443
Validation loss: 2.4192946275102822

Epoch: 6| Step: 3
Training loss: 1.2891197423074063
Validation loss: 2.313632919270747

Epoch: 6| Step: 4
Training loss: 0.8807143199773911
Validation loss: 2.3223308337877526

Epoch: 6| Step: 5
Training loss: 1.494577620684757
Validation loss: 2.3348210917870333

Epoch: 6| Step: 6
Training loss: 0.9976857347545075
Validation loss: 2.33313951551651

Epoch: 6| Step: 7
Training loss: 1.497121592300969
Validation loss: 2.3471596912917727

Epoch: 6| Step: 8
Training loss: 1.1630307944395528
Validation loss: 2.3227949544204334

Epoch: 6| Step: 9
Training loss: 1.2102266747981576
Validation loss: 2.300487232452961

Epoch: 6| Step: 10
Training loss: 1.4399438070883257
Validation loss: 2.3769020922214374

Epoch: 6| Step: 11
Training loss: 1.1427308070228224
Validation loss: 2.3406617763346453

Epoch: 6| Step: 12
Training loss: 1.6233175077326232
Validation loss: 2.3209717124416946

Epoch: 6| Step: 13
Training loss: 2.563558592437542
Validation loss: 2.32332306035725

Epoch: 340| Step: 0
Training loss: 1.1553025358893545
Validation loss: 2.2870108926497537

Epoch: 6| Step: 1
Training loss: 1.1652121786982483
Validation loss: 2.3340913871362905

Epoch: 6| Step: 2
Training loss: 1.2824485104432737
Validation loss: 2.3255036318783726

Epoch: 6| Step: 3
Training loss: 2.2186224457516905
Validation loss: 2.319698575834306

Epoch: 6| Step: 4
Training loss: 1.4969853466032814
Validation loss: 2.408153239903849

Epoch: 6| Step: 5
Training loss: 1.4338309692028692
Validation loss: 2.304139679125772

Epoch: 6| Step: 6
Training loss: 1.5650811809897847
Validation loss: 2.3394278090647367

Epoch: 6| Step: 7
Training loss: 0.9929968168912581
Validation loss: 2.3417932886543

Epoch: 6| Step: 8
Training loss: 1.2771854594200116
Validation loss: 2.3101183614659226

Epoch: 6| Step: 9
Training loss: 1.599823095555491
Validation loss: 2.2883541583762637

Epoch: 6| Step: 10
Training loss: 0.974130241331971
Validation loss: 2.2929540605279435

Epoch: 6| Step: 11
Training loss: 1.0920163720444165
Validation loss: 2.264250676596882

Epoch: 6| Step: 12
Training loss: 1.5494788247329805
Validation loss: 2.318560711336129

Epoch: 6| Step: 13
Training loss: 1.596505270481221
Validation loss: 2.2597357813847454

Epoch: 341| Step: 0
Training loss: 0.9175973018949962
Validation loss: 2.332444560808163

Epoch: 6| Step: 1
Training loss: 1.1342512793631483
Validation loss: 2.3210757100289174

Epoch: 6| Step: 2
Training loss: 1.3368363061756205
Validation loss: 2.286714095008241

Epoch: 6| Step: 3
Training loss: 1.3697435735616859
Validation loss: 2.3553167117312226

Epoch: 6| Step: 4
Training loss: 1.2504806548112815
Validation loss: 2.342953939024877

Epoch: 6| Step: 5
Training loss: 1.8155631128685894
Validation loss: 2.3410822922358134

Epoch: 6| Step: 6
Training loss: 0.9861877945886771
Validation loss: 2.2774878786452755

Epoch: 6| Step: 7
Training loss: 1.7597442185330925
Validation loss: 2.3276389308949317

Epoch: 6| Step: 8
Training loss: 1.6815642761550027
Validation loss: 2.3246780571766736

Epoch: 6| Step: 9
Training loss: 1.6314165636870495
Validation loss: 2.2702883564787606

Epoch: 6| Step: 10
Training loss: 1.2156296913821347
Validation loss: 2.3145824502334986

Epoch: 6| Step: 11
Training loss: 1.5841526454818082
Validation loss: 2.3239636253692004

Epoch: 6| Step: 12
Training loss: 1.2412246715347066
Validation loss: 2.26956814889894

Epoch: 6| Step: 13
Training loss: 0.8068469432559444
Validation loss: 2.262432317016565

Epoch: 342| Step: 0
Training loss: 0.7760773891616064
Validation loss: 2.320754018213168

Epoch: 6| Step: 1
Training loss: 1.335133628586615
Validation loss: 2.3539563734032

Epoch: 6| Step: 2
Training loss: 1.4628723713814449
Validation loss: 2.327211943005923

Epoch: 6| Step: 3
Training loss: 1.3691496365804314
Validation loss: 2.291762981087502

Epoch: 6| Step: 4
Training loss: 1.7073430315646152
Validation loss: 2.260996941449412

Epoch: 6| Step: 5
Training loss: 1.3145929180023566
Validation loss: 2.3244648519867024

Epoch: 6| Step: 6
Training loss: 1.3915343579578394
Validation loss: 2.279368614966293

Epoch: 6| Step: 7
Training loss: 1.3914236711271435
Validation loss: 2.3246430415544315

Epoch: 6| Step: 8
Training loss: 1.2458378639691665
Validation loss: 2.372182422573461

Epoch: 6| Step: 9
Training loss: 1.3168034166633573
Validation loss: 2.3418274988406043

Epoch: 6| Step: 10
Training loss: 2.0191059660856623
Validation loss: 2.2636704219837624

Epoch: 6| Step: 11
Training loss: 1.291765927018157
Validation loss: 2.2818751055334054

Epoch: 6| Step: 12
Training loss: 1.4668106098776468
Validation loss: 2.3009801680755255

Epoch: 6| Step: 13
Training loss: 1.0779059367216601
Validation loss: 2.334770171890221

Epoch: 343| Step: 0
Training loss: 1.0251691306534265
Validation loss: 2.3211791695043926

Epoch: 6| Step: 1
Training loss: 1.1066016872031186
Validation loss: 2.3717980413373287

Epoch: 6| Step: 2
Training loss: 0.8933445417593022
Validation loss: 2.333974033023361

Epoch: 6| Step: 3
Training loss: 1.4718609592553662
Validation loss: 2.3215111287223986

Epoch: 6| Step: 4
Training loss: 2.1397722313786005
Validation loss: 2.390245700691885

Epoch: 6| Step: 5
Training loss: 1.1092387370925607
Validation loss: 2.3898175086456

Epoch: 6| Step: 6
Training loss: 1.5471847686404454
Validation loss: 2.290808092488253

Epoch: 6| Step: 7
Training loss: 1.5434787342026424
Validation loss: 2.278364849339641

Epoch: 6| Step: 8
Training loss: 1.1626556394842262
Validation loss: 2.3135975796909247

Epoch: 6| Step: 9
Training loss: 1.1839201322952198
Validation loss: 2.344063493552037

Epoch: 6| Step: 10
Training loss: 1.8460301023820702
Validation loss: 2.242164888111085

Epoch: 6| Step: 11
Training loss: 1.1721471851873704
Validation loss: 2.353712539220088

Epoch: 6| Step: 12
Training loss: 1.3570000082141087
Validation loss: 2.3122208838953457

Epoch: 6| Step: 13
Training loss: 1.6230019977484422
Validation loss: 2.3206143967786557

Epoch: 344| Step: 0
Training loss: 1.463790962825335
Validation loss: 2.258425791980044

Epoch: 6| Step: 1
Training loss: 1.2500975570756152
Validation loss: 2.3490687704203763

Epoch: 6| Step: 2
Training loss: 1.3418669703136286
Validation loss: 2.2822604142229146

Epoch: 6| Step: 3
Training loss: 0.9794642557590508
Validation loss: 2.340482446407296

Epoch: 6| Step: 4
Training loss: 1.0523562628123186
Validation loss: 2.273863077934688

Epoch: 6| Step: 5
Training loss: 1.3583558745746922
Validation loss: 2.2807400827893365

Epoch: 6| Step: 6
Training loss: 1.5777145456275483
Validation loss: 2.3483410148626267

Epoch: 6| Step: 7
Training loss: 1.4363134711760137
Validation loss: 2.377513274597021

Epoch: 6| Step: 8
Training loss: 2.0713630745779104
Validation loss: 2.2867970304168286

Epoch: 6| Step: 9
Training loss: 1.165020746693045
Validation loss: 2.3708776946676884

Epoch: 6| Step: 10
Training loss: 1.021193337053347
Validation loss: 2.3291258482044084

Epoch: 6| Step: 11
Training loss: 1.7599362577469666
Validation loss: 2.3130023724350712

Epoch: 6| Step: 12
Training loss: 1.3896462500120037
Validation loss: 2.361640451568172

Epoch: 6| Step: 13
Training loss: 1.3301242366645543
Validation loss: 2.3192132952506594

Epoch: 345| Step: 0
Training loss: 1.2525395345634929
Validation loss: 2.3238420255076675

Epoch: 6| Step: 1
Training loss: 1.106874522419616
Validation loss: 2.3423999959160198

Epoch: 6| Step: 2
Training loss: 2.2033838431166326
Validation loss: 2.305038690688735

Epoch: 6| Step: 3
Training loss: 1.3561349600244126
Validation loss: 2.29465930631424

Epoch: 6| Step: 4
Training loss: 1.4384086059346812
Validation loss: 2.3436448881034737

Epoch: 6| Step: 5
Training loss: 1.4404230667220723
Validation loss: 2.3757496467293078

Epoch: 6| Step: 6
Training loss: 1.072254173898611
Validation loss: 2.360285270917712

Epoch: 6| Step: 7
Training loss: 1.3910222718343281
Validation loss: 2.344810076561782

Epoch: 6| Step: 8
Training loss: 1.2936358157277188
Validation loss: 2.310662584205036

Epoch: 6| Step: 9
Training loss: 1.240226781626607
Validation loss: 2.3122139387677545

Epoch: 6| Step: 10
Training loss: 1.228615664243377
Validation loss: 2.3694915502114813

Epoch: 6| Step: 11
Training loss: 1.3372620379807718
Validation loss: 2.351673094593853

Epoch: 6| Step: 12
Training loss: 1.659008104816159
Validation loss: 2.3196779600674913

Epoch: 6| Step: 13
Training loss: 0.8925579911847275
Validation loss: 2.3368626983787184

Epoch: 346| Step: 0
Training loss: 1.0149484581850532
Validation loss: 2.287737081762401

Epoch: 6| Step: 1
Training loss: 1.2586620139440787
Validation loss: 2.3043821204475052

Epoch: 6| Step: 2
Training loss: 1.4124307227236068
Validation loss: 2.3875808642424063

Epoch: 6| Step: 3
Training loss: 1.984675647458144
Validation loss: 2.378197482681869

Epoch: 6| Step: 4
Training loss: 1.414943694487288
Validation loss: 2.264666035905919

Epoch: 6| Step: 5
Training loss: 1.2485325305658987
Validation loss: 2.2860313258049234

Epoch: 6| Step: 6
Training loss: 1.4936364613561852
Validation loss: 2.3677463414014657

Epoch: 6| Step: 7
Training loss: 1.4784113697298065
Validation loss: 2.3383618763081397

Epoch: 6| Step: 8
Training loss: 1.334415260082804
Validation loss: 2.2977985230067643

Epoch: 6| Step: 9
Training loss: 1.1210841799869193
Validation loss: 2.3770047250615876

Epoch: 6| Step: 10
Training loss: 1.3062330673799503
Validation loss: 2.246179649276295

Epoch: 6| Step: 11
Training loss: 1.3520092529002818
Validation loss: 2.285712576543591

Epoch: 6| Step: 12
Training loss: 1.2682122053804625
Validation loss: 2.2971242926056084

Epoch: 6| Step: 13
Training loss: 1.0677221653980495
Validation loss: 2.2810418459214703

Epoch: 347| Step: 0
Training loss: 1.4777894750210228
Validation loss: 2.325585797984894

Epoch: 6| Step: 1
Training loss: 1.0621724465300362
Validation loss: 2.3884889133157623

Epoch: 6| Step: 2
Training loss: 0.849089785893139
Validation loss: 2.328697382539944

Epoch: 6| Step: 3
Training loss: 1.4131498816626682
Validation loss: 2.3679568643509463

Epoch: 6| Step: 4
Training loss: 1.2035515759728004
Validation loss: 2.404730707250411

Epoch: 6| Step: 5
Training loss: 1.1771639680953467
Validation loss: 2.3642499228864864

Epoch: 6| Step: 6
Training loss: 1.1173087100985606
Validation loss: 2.3494676449311056

Epoch: 6| Step: 7
Training loss: 1.2258208152361765
Validation loss: 2.33099038979296

Epoch: 6| Step: 8
Training loss: 0.9412126777412775
Validation loss: 2.3048760349695865

Epoch: 6| Step: 9
Training loss: 1.3139198434439323
Validation loss: 2.3451113356221764

Epoch: 6| Step: 10
Training loss: 1.5660366468952587
Validation loss: 2.421772692501243

Epoch: 6| Step: 11
Training loss: 2.2289257691842703
Validation loss: 2.337499610041437

Epoch: 6| Step: 12
Training loss: 1.3928756503038857
Validation loss: 2.263979737121732

Epoch: 6| Step: 13
Training loss: 1.3613901657788297
Validation loss: 2.3890298154903844

Epoch: 348| Step: 0
Training loss: 1.3215495978352738
Validation loss: 2.2259075031099553

Epoch: 6| Step: 1
Training loss: 1.4631492477812915
Validation loss: 2.3198382109472333

Epoch: 6| Step: 2
Training loss: 1.2958497740427308
Validation loss: 2.3336103596434317

Epoch: 6| Step: 3
Training loss: 0.8066773487072123
Validation loss: 2.339126013648513

Epoch: 6| Step: 4
Training loss: 0.9491290140317039
Validation loss: 2.289208890993758

Epoch: 6| Step: 5
Training loss: 1.4164422175306084
Validation loss: 2.3379405432320537

Epoch: 6| Step: 6
Training loss: 1.332460664236536
Validation loss: 2.2722408865492305

Epoch: 6| Step: 7
Training loss: 1.1871536151240494
Validation loss: 2.338567847674409

Epoch: 6| Step: 8
Training loss: 1.6196460556212589
Validation loss: 2.3064106595995644

Epoch: 6| Step: 9
Training loss: 1.462967141038604
Validation loss: 2.250376682357313

Epoch: 6| Step: 10
Training loss: 0.9029413861592246
Validation loss: 2.3612976368097613

Epoch: 6| Step: 11
Training loss: 2.111823913913678
Validation loss: 2.311184035032331

Epoch: 6| Step: 12
Training loss: 1.2648459497518656
Validation loss: 2.3371818927261905

Epoch: 6| Step: 13
Training loss: 1.1389984657069616
Validation loss: 2.33246407673298

Epoch: 349| Step: 0
Training loss: 1.052548252277247
Validation loss: 2.28219990852041

Epoch: 6| Step: 1
Training loss: 1.6036702498530275
Validation loss: 2.2919378407326585

Epoch: 6| Step: 2
Training loss: 1.2054151561440583
Validation loss: 2.289587791396953

Epoch: 6| Step: 3
Training loss: 1.0773839200326965
Validation loss: 2.266904098295169

Epoch: 6| Step: 4
Training loss: 1.2093074533293244
Validation loss: 2.333199388055181

Epoch: 6| Step: 5
Training loss: 2.0286024004914776
Validation loss: 2.3747092977436473

Epoch: 6| Step: 6
Training loss: 1.8608141546745889
Validation loss: 2.268540025838427

Epoch: 6| Step: 7
Training loss: 1.2624068612972275
Validation loss: 2.354232073532369

Epoch: 6| Step: 8
Training loss: 1.517875102281508
Validation loss: 2.3296915605996498

Epoch: 6| Step: 9
Training loss: 1.3114800350139897
Validation loss: 2.2875345841080876

Epoch: 6| Step: 10
Training loss: 1.415402867823864
Validation loss: 2.342908563551971

Epoch: 6| Step: 11
Training loss: 1.3752001703385386
Validation loss: 2.339921221851867

Epoch: 6| Step: 12
Training loss: 1.0683734341939422
Validation loss: 2.3070752905289753

Epoch: 6| Step: 13
Training loss: 1.2096069901996045
Validation loss: 2.327040859307807

Epoch: 350| Step: 0
Training loss: 1.5942461326137065
Validation loss: 2.3503836850699473

Epoch: 6| Step: 1
Training loss: 0.8403250800936356
Validation loss: 2.330731860762113

Epoch: 6| Step: 2
Training loss: 1.3544464213609198
Validation loss: 2.3108358229116845

Epoch: 6| Step: 3
Training loss: 1.0957264617229898
Validation loss: 2.3427140558628565

Epoch: 6| Step: 4
Training loss: 1.3706480861516448
Validation loss: 2.292500178952286

Epoch: 6| Step: 5
Training loss: 1.1629324939124106
Validation loss: 2.2691185392261524

Epoch: 6| Step: 6
Training loss: 1.7730174638519565
Validation loss: 2.396111288617384

Epoch: 6| Step: 7
Training loss: 1.05332480100202
Validation loss: 2.3499232372801817

Epoch: 6| Step: 8
Training loss: 1.6559735193346754
Validation loss: 2.312996846142651

Epoch: 6| Step: 9
Training loss: 1.3554715203248662
Validation loss: 2.305301318248203

Epoch: 6| Step: 10
Training loss: 0.9739206208188262
Validation loss: 2.3654610238781086

Epoch: 6| Step: 11
Training loss: 2.2894079579140127
Validation loss: 2.295568990451311

Epoch: 6| Step: 12
Training loss: 0.9931035956446244
Validation loss: 2.308005240913575

Epoch: 6| Step: 13
Training loss: 1.5079854757282394
Validation loss: 2.295533595020785

Epoch: 351| Step: 0
Training loss: 1.4085434331809024
Validation loss: 2.2765659640660107

Epoch: 6| Step: 1
Training loss: 1.3515859612870693
Validation loss: 2.275666810840206

Epoch: 6| Step: 2
Training loss: 2.146687297583693
Validation loss: 2.266008033948106

Epoch: 6| Step: 3
Training loss: 1.0775210029342939
Validation loss: 2.3410836774944417

Epoch: 6| Step: 4
Training loss: 1.2511954313377718
Validation loss: 2.275941364791556

Epoch: 6| Step: 5
Training loss: 1.6587598964508052
Validation loss: 2.2868662840776293

Epoch: 6| Step: 6
Training loss: 1.0829018626143598
Validation loss: 2.3787422349269263

Epoch: 6| Step: 7
Training loss: 1.0639389616158388
Validation loss: 2.3572495890632035

Epoch: 6| Step: 8
Training loss: 1.4051628997146548
Validation loss: 2.4111029413266727

Epoch: 6| Step: 9
Training loss: 1.307275546558382
Validation loss: 2.262652400736493

Epoch: 6| Step: 10
Training loss: 1.3456722970208008
Validation loss: 2.2817909025376695

Epoch: 6| Step: 11
Training loss: 1.211120936128348
Validation loss: 2.313454455133159

Epoch: 6| Step: 12
Training loss: 1.150077168321934
Validation loss: 2.2568487685259506

Epoch: 6| Step: 13
Training loss: 1.4399480292425682
Validation loss: 2.340916936840044

Epoch: 352| Step: 0
Training loss: 1.1791372468511123
Validation loss: 2.377652523142646

Epoch: 6| Step: 1
Training loss: 1.3024758878881284
Validation loss: 2.2682314665131074

Epoch: 6| Step: 2
Training loss: 1.375449800613224
Validation loss: 2.3274833905612415

Epoch: 6| Step: 3
Training loss: 0.9617792799964454
Validation loss: 2.302069643962046

Epoch: 6| Step: 4
Training loss: 1.1803784904585921
Validation loss: 2.276531635778765

Epoch: 6| Step: 5
Training loss: 1.368201484685727
Validation loss: 2.331442373990154

Epoch: 6| Step: 6
Training loss: 1.6479033558432925
Validation loss: 2.3163632801829843

Epoch: 6| Step: 7
Training loss: 1.3579682711854002
Validation loss: 2.30098344145047

Epoch: 6| Step: 8
Training loss: 0.8267378074916621
Validation loss: 2.2364342606607184

Epoch: 6| Step: 9
Training loss: 1.1295459875004727
Validation loss: 2.261613069783181

Epoch: 6| Step: 10
Training loss: 1.264542905903903
Validation loss: 2.362050441652388

Epoch: 6| Step: 11
Training loss: 1.2360249369059348
Validation loss: 2.359595130061618

Epoch: 6| Step: 12
Training loss: 2.242550172616631
Validation loss: 2.310303791183121

Epoch: 6| Step: 13
Training loss: 1.4645224256950693
Validation loss: 2.2838866527026713

Epoch: 353| Step: 0
Training loss: 2.2178797559899475
Validation loss: 2.321845810765973

Epoch: 6| Step: 1
Training loss: 1.3161168445352955
Validation loss: 2.3609043383876642

Epoch: 6| Step: 2
Training loss: 1.2489308553329075
Validation loss: 2.3340482008586534

Epoch: 6| Step: 3
Training loss: 1.7606497014066236
Validation loss: 2.373364325165248

Epoch: 6| Step: 4
Training loss: 1.167112515043951
Validation loss: 2.3655819769262236

Epoch: 6| Step: 5
Training loss: 0.9263601304038199
Validation loss: 2.295824047229375

Epoch: 6| Step: 6
Training loss: 1.3549608493793575
Validation loss: 2.2878557716289047

Epoch: 6| Step: 7
Training loss: 0.7329645613186963
Validation loss: 2.3231781177305173

Epoch: 6| Step: 8
Training loss: 1.5952722348204669
Validation loss: 2.2398114266874547

Epoch: 6| Step: 9
Training loss: 1.0655850892409857
Validation loss: 2.303968576823435

Epoch: 6| Step: 10
Training loss: 1.8440136478523081
Validation loss: 2.329006390235065

Epoch: 6| Step: 11
Training loss: 1.2037632723004308
Validation loss: 2.2832727795930765

Epoch: 6| Step: 12
Training loss: 1.4140147838655996
Validation loss: 2.315487412796704

Epoch: 6| Step: 13
Training loss: 1.3643067009152643
Validation loss: 2.3213895577640447

Epoch: 354| Step: 0
Training loss: 2.1317740906268696
Validation loss: 2.3465083778367632

Epoch: 6| Step: 1
Training loss: 1.2566990633329287
Validation loss: 2.3524413113738607

Epoch: 6| Step: 2
Training loss: 1.2799330199866557
Validation loss: 2.2237411980535846

Epoch: 6| Step: 3
Training loss: 1.315641866109206
Validation loss: 2.3597803439291343

Epoch: 6| Step: 4
Training loss: 0.9330358394432375
Validation loss: 2.3467446177236075

Epoch: 6| Step: 5
Training loss: 1.3967688637506515
Validation loss: 2.389685921215129

Epoch: 6| Step: 6
Training loss: 1.2549790401152283
Validation loss: 2.3279063542008394

Epoch: 6| Step: 7
Training loss: 1.4754691137676765
Validation loss: 2.348512957150644

Epoch: 6| Step: 8
Training loss: 1.5732034670174944
Validation loss: 2.2741694138915465

Epoch: 6| Step: 9
Training loss: 1.3415443149403115
Validation loss: 2.347038984645195

Epoch: 6| Step: 10
Training loss: 1.1246257265365678
Validation loss: 2.3782566671587992

Epoch: 6| Step: 11
Training loss: 1.276511478221552
Validation loss: 2.334129771827109

Epoch: 6| Step: 12
Training loss: 1.4535218384017123
Validation loss: 2.2850957435637733

Epoch: 6| Step: 13
Training loss: 1.0683266810796752
Validation loss: 2.4166029959563042

Epoch: 355| Step: 0
Training loss: 1.4135953015483067
Validation loss: 2.3299518296513217

Epoch: 6| Step: 1
Training loss: 0.9289623926904865
Validation loss: 2.358196219693512

Epoch: 6| Step: 2
Training loss: 2.0614032719374547
Validation loss: 2.250043230541579

Epoch: 6| Step: 3
Training loss: 1.3977600673203139
Validation loss: 2.245103500958162

Epoch: 6| Step: 4
Training loss: 1.6867474891436975
Validation loss: 2.307650694532391

Epoch: 6| Step: 5
Training loss: 1.1225721865341678
Validation loss: 2.3418961005265477

Epoch: 6| Step: 6
Training loss: 1.4225599714083825
Validation loss: 2.3299716569314843

Epoch: 6| Step: 7
Training loss: 1.246035966161204
Validation loss: 2.2970299790208326

Epoch: 6| Step: 8
Training loss: 1.669876615569056
Validation loss: 2.331263837031254

Epoch: 6| Step: 9
Training loss: 1.6213642675973765
Validation loss: 2.344155738193566

Epoch: 6| Step: 10
Training loss: 1.1907773218314113
Validation loss: 2.325504875387875

Epoch: 6| Step: 11
Training loss: 1.2314137538704997
Validation loss: 2.2838629107867328

Epoch: 6| Step: 12
Training loss: 0.7128197203608718
Validation loss: 2.3320550445861423

Epoch: 6| Step: 13
Training loss: 1.210350435757201
Validation loss: 2.3356776224454308

Epoch: 356| Step: 0
Training loss: 1.0235762174523009
Validation loss: 2.3187671181903995

Epoch: 6| Step: 1
Training loss: 1.2159027194242689
Validation loss: 2.2937897294189162

Epoch: 6| Step: 2
Training loss: 2.3237755617374334
Validation loss: 2.31774511350728

Epoch: 6| Step: 3
Training loss: 0.9410437681456022
Validation loss: 2.3652667601602015

Epoch: 6| Step: 4
Training loss: 1.1961271215326943
Validation loss: 2.3227713265501566

Epoch: 6| Step: 5
Training loss: 1.028389981799773
Validation loss: 2.302991180710877

Epoch: 6| Step: 6
Training loss: 0.9488617653534975
Validation loss: 2.326057020513023

Epoch: 6| Step: 7
Training loss: 1.0534722002052188
Validation loss: 2.286134096488265

Epoch: 6| Step: 8
Training loss: 1.7080995198096551
Validation loss: 2.310167313986895

Epoch: 6| Step: 9
Training loss: 1.1677021245368826
Validation loss: 2.2805458754394747

Epoch: 6| Step: 10
Training loss: 1.5169149199122274
Validation loss: 2.329129908638527

Epoch: 6| Step: 11
Training loss: 1.736259879625855
Validation loss: 2.316909169627444

Epoch: 6| Step: 12
Training loss: 1.3073699238772807
Validation loss: 2.373482386060047

Epoch: 6| Step: 13
Training loss: 0.9769849245065991
Validation loss: 2.3125268346487236

Epoch: 357| Step: 0
Training loss: 2.225834670652585
Validation loss: 2.2965365884578595

Epoch: 6| Step: 1
Training loss: 0.8626107766703898
Validation loss: 2.3213603998199392

Epoch: 6| Step: 2
Training loss: 1.0860460625042483
Validation loss: 2.358375014145463

Epoch: 6| Step: 3
Training loss: 1.5543433340395687
Validation loss: 2.3545153816325284

Epoch: 6| Step: 4
Training loss: 1.2502150350623185
Validation loss: 2.3829664966318975

Epoch: 6| Step: 5
Training loss: 1.2564784966665563
Validation loss: 2.3228763963286068

Epoch: 6| Step: 6
Training loss: 1.1208571340499027
Validation loss: 2.3475459783417656

Epoch: 6| Step: 7
Training loss: 1.4809447959950397
Validation loss: 2.328163794132152

Epoch: 6| Step: 8
Training loss: 1.2586574204463572
Validation loss: 2.2798533359433932

Epoch: 6| Step: 9
Training loss: 0.8740517382595151
Validation loss: 2.2672155831533822

Epoch: 6| Step: 10
Training loss: 0.970211710586442
Validation loss: 2.3186968736151647

Epoch: 6| Step: 11
Training loss: 1.454009412480549
Validation loss: 2.231621731751733

Epoch: 6| Step: 12
Training loss: 1.6774545420642966
Validation loss: 2.260954105169864

Epoch: 6| Step: 13
Training loss: 0.655357958008737
Validation loss: 2.297071430511932

Epoch: 358| Step: 0
Training loss: 1.3014219155469644
Validation loss: 2.364438114872266

Epoch: 6| Step: 1
Training loss: 1.1406552036414688
Validation loss: 2.2891742393858494

Epoch: 6| Step: 2
Training loss: 1.357764155643333
Validation loss: 2.3811147692600434

Epoch: 6| Step: 3
Training loss: 2.0647951707094006
Validation loss: 2.346916188144516

Epoch: 6| Step: 4
Training loss: 0.9259460238200539
Validation loss: 2.3860141202808305

Epoch: 6| Step: 5
Training loss: 1.7322691083468844
Validation loss: 2.374238726071041

Epoch: 6| Step: 6
Training loss: 1.2976291715677815
Validation loss: 2.3166945866179893

Epoch: 6| Step: 7
Training loss: 0.9764200640754385
Validation loss: 2.380400262284239

Epoch: 6| Step: 8
Training loss: 1.4376069733995593
Validation loss: 2.313277861216806

Epoch: 6| Step: 9
Training loss: 0.8837569594480164
Validation loss: 2.3131538282738124

Epoch: 6| Step: 10
Training loss: 1.234179420911854
Validation loss: 2.3221713576971252

Epoch: 6| Step: 11
Training loss: 1.703230128412133
Validation loss: 2.373202925844309

Epoch: 6| Step: 12
Training loss: 1.4797801326126947
Validation loss: 2.3339937014673824

Epoch: 6| Step: 13
Training loss: 0.8701814398713115
Validation loss: 2.3215029530360405

Epoch: 359| Step: 0
Training loss: 1.148381549743862
Validation loss: 2.2675743771795234

Epoch: 6| Step: 1
Training loss: 1.2837838959049486
Validation loss: 2.293483711453622

Epoch: 6| Step: 2
Training loss: 1.5345070123695599
Validation loss: 2.3780545473466526

Epoch: 6| Step: 3
Training loss: 1.3748108560342729
Validation loss: 2.2896813333083013

Epoch: 6| Step: 4
Training loss: 1.2188203253385521
Validation loss: 2.309271596793025

Epoch: 6| Step: 5
Training loss: 1.4506757871455636
Validation loss: 2.3125437294756215

Epoch: 6| Step: 6
Training loss: 1.1390607899259229
Validation loss: 2.3001861669020207

Epoch: 6| Step: 7
Training loss: 1.1821892087572632
Validation loss: 2.3327851537828055

Epoch: 6| Step: 8
Training loss: 1.2384009559123714
Validation loss: 2.2778323877438487

Epoch: 6| Step: 9
Training loss: 1.073416226327531
Validation loss: 2.3291263748835083

Epoch: 6| Step: 10
Training loss: 1.022672177767006
Validation loss: 2.3501944713029066

Epoch: 6| Step: 11
Training loss: 2.30168002178821
Validation loss: 2.31705689151107

Epoch: 6| Step: 12
Training loss: 1.3516131264791174
Validation loss: 2.382212186169645

Epoch: 6| Step: 13
Training loss: 1.5907749757342304
Validation loss: 2.3433471399084693

Epoch: 360| Step: 0
Training loss: 1.5103765635811843
Validation loss: 2.2728770940048038

Epoch: 6| Step: 1
Training loss: 1.0817167740919094
Validation loss: 2.3492104312495132

Epoch: 6| Step: 2
Training loss: 1.3124860127021614
Validation loss: 2.322415854156514

Epoch: 6| Step: 3
Training loss: 1.2600978206325357
Validation loss: 2.305899828559793

Epoch: 6| Step: 4
Training loss: 1.1510390314730805
Validation loss: 2.2914852894651143

Epoch: 6| Step: 5
Training loss: 1.3846683441125012
Validation loss: 2.2791831666217517

Epoch: 6| Step: 6
Training loss: 1.1566234707164147
Validation loss: 2.2190965967850635

Epoch: 6| Step: 7
Training loss: 1.2159284061041822
Validation loss: 2.3369762780439722

Epoch: 6| Step: 8
Training loss: 1.4074360825845607
Validation loss: 2.3046177851618768

Epoch: 6| Step: 9
Training loss: 2.22124459166719
Validation loss: 2.265609562375349

Epoch: 6| Step: 10
Training loss: 1.2651994719818682
Validation loss: 2.365405443978446

Epoch: 6| Step: 11
Training loss: 1.377395537166087
Validation loss: 2.34063227413999

Epoch: 6| Step: 12
Training loss: 0.9038292353337448
Validation loss: 2.3756548826534245

Epoch: 6| Step: 13
Training loss: 1.0280468641464195
Validation loss: 2.271948331142608

Epoch: 361| Step: 0
Training loss: 1.3486361272220082
Validation loss: 2.3670128419086023

Epoch: 6| Step: 1
Training loss: 1.4773995585115465
Validation loss: 2.242303214214234

Epoch: 6| Step: 2
Training loss: 1.0908424969417698
Validation loss: 2.305273998031019

Epoch: 6| Step: 3
Training loss: 0.9687845470052063
Validation loss: 2.330657512044331

Epoch: 6| Step: 4
Training loss: 1.4203671855072018
Validation loss: 2.3194847460397496

Epoch: 6| Step: 5
Training loss: 1.3941869658006851
Validation loss: 2.2845914931110616

Epoch: 6| Step: 6
Training loss: 1.1801557811451782
Validation loss: 2.269350981680457

Epoch: 6| Step: 7
Training loss: 1.1768161616757937
Validation loss: 2.3300352939890328

Epoch: 6| Step: 8
Training loss: 1.1545977256884659
Validation loss: 2.3069397825061073

Epoch: 6| Step: 9
Training loss: 1.3374970017158914
Validation loss: 2.3385851627820173

Epoch: 6| Step: 10
Training loss: 1.1600604290678354
Validation loss: 2.3642155448569704

Epoch: 6| Step: 11
Training loss: 1.4352542916389732
Validation loss: 2.3178840829586513

Epoch: 6| Step: 12
Training loss: 1.3990926220317952
Validation loss: 2.337238076054975

Epoch: 6| Step: 13
Training loss: 2.6624033843227575
Validation loss: 2.329386351052314

Epoch: 362| Step: 0
Training loss: 1.2437209734572723
Validation loss: 2.3134101910064224

Epoch: 6| Step: 1
Training loss: 0.9304430800323326
Validation loss: 2.3447500511305277

Epoch: 6| Step: 2
Training loss: 0.7707190858529086
Validation loss: 2.3204093772839345

Epoch: 6| Step: 3
Training loss: 1.8230128744259806
Validation loss: 2.3114587628585155

Epoch: 6| Step: 4
Training loss: 1.3264541887294765
Validation loss: 2.3594040200976996

Epoch: 6| Step: 5
Training loss: 1.7398924486310483
Validation loss: 2.28366343291251

Epoch: 6| Step: 6
Training loss: 2.1495531549299125
Validation loss: 2.2885379998823434

Epoch: 6| Step: 7
Training loss: 1.2504746012924366
Validation loss: 2.333986985887394

Epoch: 6| Step: 8
Training loss: 1.3436035253845917
Validation loss: 2.3561221101770635

Epoch: 6| Step: 9
Training loss: 1.2270965385482073
Validation loss: 2.332160840434569

Epoch: 6| Step: 10
Training loss: 1.1500360690555684
Validation loss: 2.336334116924036

Epoch: 6| Step: 11
Training loss: 1.0555818509847628
Validation loss: 2.241249042147474

Epoch: 6| Step: 12
Training loss: 1.1401031031748117
Validation loss: 2.3477786687447333

Epoch: 6| Step: 13
Training loss: 1.4432504326327278
Validation loss: 2.3100051359213563

Epoch: 363| Step: 0
Training loss: 1.2817115882637178
Validation loss: 2.19238031244993

Epoch: 6| Step: 1
Training loss: 1.1346809500061614
Validation loss: 2.317098619807124

Epoch: 6| Step: 2
Training loss: 1.0049995969894892
Validation loss: 2.26797234048864

Epoch: 6| Step: 3
Training loss: 1.2452710344597784
Validation loss: 2.4105208708072916

Epoch: 6| Step: 4
Training loss: 1.2905887238435967
Validation loss: 2.225336248590613

Epoch: 6| Step: 5
Training loss: 1.090028753951295
Validation loss: 2.288417213530845

Epoch: 6| Step: 6
Training loss: 1.6984583062912786
Validation loss: 2.316984084539526

Epoch: 6| Step: 7
Training loss: 1.2937480041930796
Validation loss: 2.307095008831563

Epoch: 6| Step: 8
Training loss: 1.2301193467831981
Validation loss: 2.30063927985429

Epoch: 6| Step: 9
Training loss: 0.7819008976758601
Validation loss: 2.2784154871991906

Epoch: 6| Step: 10
Training loss: 1.2692718240793792
Validation loss: 2.3118940594404895

Epoch: 6| Step: 11
Training loss: 1.3896358272277898
Validation loss: 2.335448669347222

Epoch: 6| Step: 12
Training loss: 2.068600965588575
Validation loss: 2.351623890300663

Epoch: 6| Step: 13
Training loss: 1.4072916623371312
Validation loss: 2.3007733343694277

Epoch: 364| Step: 0
Training loss: 1.3606905217092702
Validation loss: 2.3416948918989604

Epoch: 6| Step: 1
Training loss: 2.0692687660537894
Validation loss: 2.3444430151831694

Epoch: 6| Step: 2
Training loss: 0.8724850888877247
Validation loss: 2.3408909598853227

Epoch: 6| Step: 3
Training loss: 1.1945966185004113
Validation loss: 2.3569308402315823

Epoch: 6| Step: 4
Training loss: 0.8530045295027116
Validation loss: 2.2936518023977523

Epoch: 6| Step: 5
Training loss: 1.6926914468558742
Validation loss: 2.276276855602252

Epoch: 6| Step: 6
Training loss: 1.3070754167444503
Validation loss: 2.300541644701383

Epoch: 6| Step: 7
Training loss: 1.3792576328638209
Validation loss: 2.359339748489472

Epoch: 6| Step: 8
Training loss: 1.4294703584461868
Validation loss: 2.2563423428491527

Epoch: 6| Step: 9
Training loss: 0.9657057027826345
Validation loss: 2.410104220480511

Epoch: 6| Step: 10
Training loss: 1.1889651946707644
Validation loss: 2.2887409604128837

Epoch: 6| Step: 11
Training loss: 1.1102445176729436
Validation loss: 2.3214066917851484

Epoch: 6| Step: 12
Training loss: 1.5622216548951808
Validation loss: 2.321487924539828

Epoch: 6| Step: 13
Training loss: 1.051589201408217
Validation loss: 2.317524744781743

Epoch: 365| Step: 0
Training loss: 1.4443101861294632
Validation loss: 2.318095902192205

Epoch: 6| Step: 1
Training loss: 1.2778921087687498
Validation loss: 2.307649761350183

Epoch: 6| Step: 2
Training loss: 2.325825829634481
Validation loss: 2.3225569744303933

Epoch: 6| Step: 3
Training loss: 0.9766235942803606
Validation loss: 2.3310269927477796

Epoch: 6| Step: 4
Training loss: 0.9603882126858164
Validation loss: 2.267566128560962

Epoch: 6| Step: 5
Training loss: 1.4441531093347735
Validation loss: 2.3393812934443425

Epoch: 6| Step: 6
Training loss: 1.5345076338552328
Validation loss: 2.2802254082244082

Epoch: 6| Step: 7
Training loss: 1.1997016655099788
Validation loss: 2.2868959474013537

Epoch: 6| Step: 8
Training loss: 1.0747261097664809
Validation loss: 2.2819645855763144

Epoch: 6| Step: 9
Training loss: 0.9815190377704027
Validation loss: 2.3392601076194612

Epoch: 6| Step: 10
Training loss: 0.9531872525756667
Validation loss: 2.3492328929082205

Epoch: 6| Step: 11
Training loss: 0.7897058262753432
Validation loss: 2.32050978359577

Epoch: 6| Step: 12
Training loss: 1.399921801631101
Validation loss: 2.295460195282357

Epoch: 6| Step: 13
Training loss: 1.3948199830755106
Validation loss: 2.271292959908357

Epoch: 366| Step: 0
Training loss: 1.1898421730236441
Validation loss: 2.3030115473375754

Epoch: 6| Step: 1
Training loss: 1.5166779625999476
Validation loss: 2.2987162019062506

Epoch: 6| Step: 2
Training loss: 1.4619037880087347
Validation loss: 2.3575915505539617

Epoch: 6| Step: 3
Training loss: 1.230159853960609
Validation loss: 2.2960940817858413

Epoch: 6| Step: 4
Training loss: 1.1182159811568275
Validation loss: 2.362681273592746

Epoch: 6| Step: 5
Training loss: 1.0713949924838335
Validation loss: 2.3297505203904842

Epoch: 6| Step: 6
Training loss: 1.1817431697014573
Validation loss: 2.3614544076211716

Epoch: 6| Step: 7
Training loss: 1.4126406945569474
Validation loss: 2.2763866745871915

Epoch: 6| Step: 8
Training loss: 1.268899472832358
Validation loss: 2.3540552214360027

Epoch: 6| Step: 9
Training loss: 1.6200624425651187
Validation loss: 2.2389324695277084

Epoch: 6| Step: 10
Training loss: 0.7221797299926536
Validation loss: 2.304751973669462

Epoch: 6| Step: 11
Training loss: 1.1390691100296355
Validation loss: 2.291557682686339

Epoch: 6| Step: 12
Training loss: 1.0326547014476208
Validation loss: 2.2939077831308654

Epoch: 6| Step: 13
Training loss: 2.822772699229843
Validation loss: 2.316619900269536

Epoch: 367| Step: 0
Training loss: 2.3920517198336007
Validation loss: 2.3594485426748655

Epoch: 6| Step: 1
Training loss: 1.315872763457073
Validation loss: 2.3166764450427557

Epoch: 6| Step: 2
Training loss: 1.4185345994550411
Validation loss: 2.3078193543532635

Epoch: 6| Step: 3
Training loss: 1.0590222606966877
Validation loss: 2.2683468286332347

Epoch: 6| Step: 4
Training loss: 1.0889450798057683
Validation loss: 2.3693442756127365

Epoch: 6| Step: 5
Training loss: 1.2836381938203136
Validation loss: 2.3054637649331062

Epoch: 6| Step: 6
Training loss: 1.269279478490057
Validation loss: 2.321377149186143

Epoch: 6| Step: 7
Training loss: 1.018582073951693
Validation loss: 2.2772746987041725

Epoch: 6| Step: 8
Training loss: 1.1477605160792506
Validation loss: 2.3061590620137156

Epoch: 6| Step: 9
Training loss: 1.1756380824122155
Validation loss: 2.2686953279574773

Epoch: 6| Step: 10
Training loss: 1.4352761357154917
Validation loss: 2.3579911371337783

Epoch: 6| Step: 11
Training loss: 0.8062381063367676
Validation loss: 2.3191050162261053

Epoch: 6| Step: 12
Training loss: 1.2229478872149233
Validation loss: 2.2562567864536027

Epoch: 6| Step: 13
Training loss: 1.139981597868983
Validation loss: 2.265639984907327

Epoch: 368| Step: 0
Training loss: 1.4135402326171318
Validation loss: 2.2913608147428484

Epoch: 6| Step: 1
Training loss: 2.295210254487525
Validation loss: 2.323567331365355

Epoch: 6| Step: 2
Training loss: 1.0625331536898623
Validation loss: 2.223436727899766

Epoch: 6| Step: 3
Training loss: 0.9001928679122061
Validation loss: 2.3360410656305923

Epoch: 6| Step: 4
Training loss: 1.326790711595732
Validation loss: 2.330319845766149

Epoch: 6| Step: 5
Training loss: 0.8601048578055736
Validation loss: 2.322435597304412

Epoch: 6| Step: 6
Training loss: 0.9820846069698844
Validation loss: 2.35144148296387

Epoch: 6| Step: 7
Training loss: 0.9496672398878006
Validation loss: 2.3482451567131464

Epoch: 6| Step: 8
Training loss: 0.6933484573579274
Validation loss: 2.3193748869288964

Epoch: 6| Step: 9
Training loss: 1.5753932007934792
Validation loss: 2.3179054125767036

Epoch: 6| Step: 10
Training loss: 1.395314314649882
Validation loss: 2.3076002188315194

Epoch: 6| Step: 11
Training loss: 1.0072684778794285
Validation loss: 2.305283288297917

Epoch: 6| Step: 12
Training loss: 1.510138738208008
Validation loss: 2.330536666806218

Epoch: 6| Step: 13
Training loss: 1.3243788900853803
Validation loss: 2.3106713529865344

Epoch: 369| Step: 0
Training loss: 1.0432399440036653
Validation loss: 2.316173078633066

Epoch: 6| Step: 1
Training loss: 1.5552940527289691
Validation loss: 2.3242085837940425

Epoch: 6| Step: 2
Training loss: 1.1711550726431819
Validation loss: 2.3178001976450155

Epoch: 6| Step: 3
Training loss: 1.1527948046324308
Validation loss: 2.2649410382306856

Epoch: 6| Step: 4
Training loss: 1.1590553480530876
Validation loss: 2.284661470061324

Epoch: 6| Step: 5
Training loss: 2.0939514291006995
Validation loss: 2.3325825976271393

Epoch: 6| Step: 6
Training loss: 1.3961955592129778
Validation loss: 2.3805219103940467

Epoch: 6| Step: 7
Training loss: 1.458289045842128
Validation loss: 2.317827144028052

Epoch: 6| Step: 8
Training loss: 1.277581242406085
Validation loss: 2.284031722671636

Epoch: 6| Step: 9
Training loss: 1.0141204253170766
Validation loss: 2.3059658319997327

Epoch: 6| Step: 10
Training loss: 1.1461333951223447
Validation loss: 2.3033514328072995

Epoch: 6| Step: 11
Training loss: 1.414533420781457
Validation loss: 2.303929511595123

Epoch: 6| Step: 12
Training loss: 1.1476006086038735
Validation loss: 2.2570859939028343

Epoch: 6| Step: 13
Training loss: 1.5893132404864367
Validation loss: 2.3302756324659466

Epoch: 370| Step: 0
Training loss: 1.6487351279929205
Validation loss: 2.2333097631428687

Epoch: 6| Step: 1
Training loss: 0.8956269462654811
Validation loss: 2.3887828796785104

Epoch: 6| Step: 2
Training loss: 0.8485293133201157
Validation loss: 2.2917071427455893

Epoch: 6| Step: 3
Training loss: 1.2833107448835823
Validation loss: 2.305750661953004

Epoch: 6| Step: 4
Training loss: 1.5510040046349973
Validation loss: 2.370870961375228

Epoch: 6| Step: 5
Training loss: 0.99020247248135
Validation loss: 2.2758905890906527

Epoch: 6| Step: 6
Training loss: 1.0887811327401786
Validation loss: 2.343266289677798

Epoch: 6| Step: 7
Training loss: 1.035484981521894
Validation loss: 2.2946597280649756

Epoch: 6| Step: 8
Training loss: 1.3340795435546127
Validation loss: 2.223142659671052

Epoch: 6| Step: 9
Training loss: 1.6138606104923923
Validation loss: 2.2826954017009946

Epoch: 6| Step: 10
Training loss: 1.9094151968712747
Validation loss: 2.263875081969569

Epoch: 6| Step: 11
Training loss: 1.3321535831780786
Validation loss: 2.345154684927796

Epoch: 6| Step: 12
Training loss: 1.2799135076089474
Validation loss: 2.342160332396375

Epoch: 6| Step: 13
Training loss: 1.3783291481689484
Validation loss: 2.3145472015773922

Epoch: 371| Step: 0
Training loss: 2.024686685506919
Validation loss: 2.329705619531092

Epoch: 6| Step: 1
Training loss: 1.2049282481567842
Validation loss: 2.3142060371865343

Epoch: 6| Step: 2
Training loss: 1.0658841374577013
Validation loss: 2.2862588798862586

Epoch: 6| Step: 3
Training loss: 1.2737692652360064
Validation loss: 2.297635883613519

Epoch: 6| Step: 4
Training loss: 1.2969325409039274
Validation loss: 2.3149599185662146

Epoch: 6| Step: 5
Training loss: 1.4065833226518494
Validation loss: 2.2274524153089352

Epoch: 6| Step: 6
Training loss: 1.2605050689129291
Validation loss: 2.3394009564256337

Epoch: 6| Step: 7
Training loss: 1.3241895374237949
Validation loss: 2.318468711664642

Epoch: 6| Step: 8
Training loss: 1.0970462719696044
Validation loss: 2.2807447677787724

Epoch: 6| Step: 9
Training loss: 1.0653499080393485
Validation loss: 2.322142533593105

Epoch: 6| Step: 10
Training loss: 0.9711936770374723
Validation loss: 2.3451246576838596

Epoch: 6| Step: 11
Training loss: 1.4426819653172898
Validation loss: 2.2927361447384365

Epoch: 6| Step: 12
Training loss: 1.043986420495592
Validation loss: 2.3063271250705224

Epoch: 6| Step: 13
Training loss: 1.0664647683656607
Validation loss: 2.3401560540299817

Epoch: 372| Step: 0
Training loss: 0.9603836200073542
Validation loss: 2.3125922964269208

Epoch: 6| Step: 1
Training loss: 0.8500158631022613
Validation loss: 2.3315212542486896

Epoch: 6| Step: 2
Training loss: 1.5209580026329839
Validation loss: 2.3745634625527603

Epoch: 6| Step: 3
Training loss: 1.759373628605635
Validation loss: 2.297918179216933

Epoch: 6| Step: 4
Training loss: 1.2900483032172823
Validation loss: 2.3077604291295346

Epoch: 6| Step: 5
Training loss: 2.349706176894638
Validation loss: 2.3082210132360115

Epoch: 6| Step: 6
Training loss: 1.102731611874693
Validation loss: 2.306860811849654

Epoch: 6| Step: 7
Training loss: 1.2859978978004893
Validation loss: 2.294270621397938

Epoch: 6| Step: 8
Training loss: 0.9234806560623939
Validation loss: 2.326269902350712

Epoch: 6| Step: 9
Training loss: 0.8768044666463658
Validation loss: 2.335318388632947

Epoch: 6| Step: 10
Training loss: 1.0281774814742075
Validation loss: 2.3349319265233097

Epoch: 6| Step: 11
Training loss: 1.2577595669999182
Validation loss: 2.3177611022966684

Epoch: 6| Step: 12
Training loss: 1.1190820915000714
Validation loss: 2.3174066114673084

Epoch: 6| Step: 13
Training loss: 1.3649264576422162
Validation loss: 2.308870968421036

Epoch: 373| Step: 0
Training loss: 1.2907613945442722
Validation loss: 2.2503615331566533

Epoch: 6| Step: 1
Training loss: 1.1829314440406296
Validation loss: 2.273980078230756

Epoch: 6| Step: 2
Training loss: 1.2456157568757553
Validation loss: 2.30874158753287

Epoch: 6| Step: 3
Training loss: 1.2347606104912168
Validation loss: 2.28050689405119

Epoch: 6| Step: 4
Training loss: 1.3258881525247035
Validation loss: 2.3304180253585147

Epoch: 6| Step: 5
Training loss: 1.8257094506643818
Validation loss: 2.325596062618913

Epoch: 6| Step: 6
Training loss: 1.0212315671417558
Validation loss: 2.3503299342324753

Epoch: 6| Step: 7
Training loss: 1.0513860387244172
Validation loss: 2.305023545949796

Epoch: 6| Step: 8
Training loss: 1.0036590509314718
Validation loss: 2.3072389101123685

Epoch: 6| Step: 9
Training loss: 0.9327812969158293
Validation loss: 2.2846267595804823

Epoch: 6| Step: 10
Training loss: 1.281394206049648
Validation loss: 2.357046799566274

Epoch: 6| Step: 11
Training loss: 1.1875029112127657
Validation loss: 2.2646885606697804

Epoch: 6| Step: 12
Training loss: 1.5641169002191841
Validation loss: 2.323923577440432

Epoch: 6| Step: 13
Training loss: 1.9505701674235159
Validation loss: 2.365058157013541

Epoch: 374| Step: 0
Training loss: 1.0574969137881722
Validation loss: 2.310592934811251

Epoch: 6| Step: 1
Training loss: 1.8789456496202024
Validation loss: 2.2656701337698517

Epoch: 6| Step: 2
Training loss: 1.484650034270172
Validation loss: 2.2823413245012634

Epoch: 6| Step: 3
Training loss: 1.3198789528051365
Validation loss: 2.3059638114065253

Epoch: 6| Step: 4
Training loss: 1.2034235497168577
Validation loss: 2.334890837544841

Epoch: 6| Step: 5
Training loss: 1.2646981130144765
Validation loss: 2.3177386962258626

Epoch: 6| Step: 6
Training loss: 1.641522915673514
Validation loss: 2.2546555199328315

Epoch: 6| Step: 7
Training loss: 0.9971848140956531
Validation loss: 2.2893222917744667

Epoch: 6| Step: 8
Training loss: 1.0661681751369554
Validation loss: 2.283080651676522

Epoch: 6| Step: 9
Training loss: 1.1227518506847105
Validation loss: 2.2735864835518393

Epoch: 6| Step: 10
Training loss: 1.0545823786588155
Validation loss: 2.302950770857827

Epoch: 6| Step: 11
Training loss: 1.105035595903087
Validation loss: 2.249080606845647

Epoch: 6| Step: 12
Training loss: 1.3554220054107762
Validation loss: 2.3888261506911723

Epoch: 6| Step: 13
Training loss: 1.005782989268142
Validation loss: 2.31335605096273

Epoch: 375| Step: 0
Training loss: 1.1332877379015673
Validation loss: 2.308250437115382

Epoch: 6| Step: 1
Training loss: 0.9760201130498699
Validation loss: 2.335212171556968

Epoch: 6| Step: 2
Training loss: 1.6869741256212993
Validation loss: 2.3578540941937782

Epoch: 6| Step: 3
Training loss: 1.1351693726927745
Validation loss: 2.280361234469584

Epoch: 6| Step: 4
Training loss: 1.1510834607207776
Validation loss: 2.3063870211626125

Epoch: 6| Step: 5
Training loss: 1.0509531100381697
Validation loss: 2.2525840673498947

Epoch: 6| Step: 6
Training loss: 1.376613190807684
Validation loss: 2.2763519471718032

Epoch: 6| Step: 7
Training loss: 2.030753676592786
Validation loss: 2.3329620095166783

Epoch: 6| Step: 8
Training loss: 1.638389735888949
Validation loss: 2.319196933175372

Epoch: 6| Step: 9
Training loss: 1.1842418444825573
Validation loss: 2.2846126398168645

Epoch: 6| Step: 10
Training loss: 0.8695212912867497
Validation loss: 2.2887607235406753

Epoch: 6| Step: 11
Training loss: 1.085039714490716
Validation loss: 2.4177711773605552

Epoch: 6| Step: 12
Training loss: 0.9729749165209842
Validation loss: 2.374833168599337

Epoch: 6| Step: 13
Training loss: 1.3272826272184344
Validation loss: 2.365180972496756

Epoch: 376| Step: 0
Training loss: 1.1203788578061087
Validation loss: 2.3505561061534843

Epoch: 6| Step: 1
Training loss: 1.0781007846932387
Validation loss: 2.238403262009632

Epoch: 6| Step: 2
Training loss: 1.545205650839865
Validation loss: 2.2678052777088906

Epoch: 6| Step: 3
Training loss: 1.253505702230587
Validation loss: 2.4224092384519715

Epoch: 6| Step: 4
Training loss: 1.0094922874499936
Validation loss: 2.248658607586282

Epoch: 6| Step: 5
Training loss: 0.8060836161956033
Validation loss: 2.304352149321084

Epoch: 6| Step: 6
Training loss: 1.6113532786862446
Validation loss: 2.311901871016402

Epoch: 6| Step: 7
Training loss: 1.0385650361753205
Validation loss: 2.319073034406341

Epoch: 6| Step: 8
Training loss: 1.2273178690337214
Validation loss: 2.317261886091421

Epoch: 6| Step: 9
Training loss: 0.9118214056673214
Validation loss: 2.359399285395553

Epoch: 6| Step: 10
Training loss: 1.2257658685773118
Validation loss: 2.300899632449178

Epoch: 6| Step: 11
Training loss: 1.323249124318764
Validation loss: 2.2723353422462367

Epoch: 6| Step: 12
Training loss: 1.9772583109929018
Validation loss: 2.251891528335576

Epoch: 6| Step: 13
Training loss: 1.2619649924336216
Validation loss: 2.2697417213319477

Epoch: 377| Step: 0
Training loss: 1.5163728107929975
Validation loss: 2.2935769055732687

Epoch: 6| Step: 1
Training loss: 1.053238388884872
Validation loss: 2.31944059810017

Epoch: 6| Step: 2
Training loss: 0.6550295471122681
Validation loss: 2.2818911409045506

Epoch: 6| Step: 3
Training loss: 1.0511962184688477
Validation loss: 2.3817006476316434

Epoch: 6| Step: 4
Training loss: 1.2825806848528687
Validation loss: 2.307633019552893

Epoch: 6| Step: 5
Training loss: 1.0465476819661215
Validation loss: 2.2707877846498317

Epoch: 6| Step: 6
Training loss: 1.2966348816441684
Validation loss: 2.2840989096856648

Epoch: 6| Step: 7
Training loss: 1.7777502915456311
Validation loss: 2.3498103401469668

Epoch: 6| Step: 8
Training loss: 1.1979175180625654
Validation loss: 2.3482451528921047

Epoch: 6| Step: 9
Training loss: 1.3409893154426957
Validation loss: 2.3225923195241305

Epoch: 6| Step: 10
Training loss: 1.043971290657683
Validation loss: 2.3516408601775756

Epoch: 6| Step: 11
Training loss: 2.3380376758395105
Validation loss: 2.293824769530165

Epoch: 6| Step: 12
Training loss: 1.0767343370136724
Validation loss: 2.2723905256125696

Epoch: 6| Step: 13
Training loss: 0.708402831277192
Validation loss: 2.341457311501236

Epoch: 378| Step: 0
Training loss: 0.9368297088038062
Validation loss: 2.292340989526187

Epoch: 6| Step: 1
Training loss: 1.4277505730207172
Validation loss: 2.3155163175309554

Epoch: 6| Step: 2
Training loss: 1.3833505047264782
Validation loss: 2.2008697974794016

Epoch: 6| Step: 3
Training loss: 1.1519898469232468
Validation loss: 2.2885858883117787

Epoch: 6| Step: 4
Training loss: 2.0686195217140475
Validation loss: 2.279101157735007

Epoch: 6| Step: 5
Training loss: 0.9641715731505563
Validation loss: 2.2820834678228628

Epoch: 6| Step: 6
Training loss: 1.1688820320662774
Validation loss: 2.3425925488902317

Epoch: 6| Step: 7
Training loss: 1.2420128273662414
Validation loss: 2.2641970651207144

Epoch: 6| Step: 8
Training loss: 1.6198589723919927
Validation loss: 2.2369965866056005

Epoch: 6| Step: 9
Training loss: 1.196817037110133
Validation loss: 2.3434861699852405

Epoch: 6| Step: 10
Training loss: 1.2719562082819709
Validation loss: 2.2577864962666916

Epoch: 6| Step: 11
Training loss: 1.3751933655456188
Validation loss: 2.2841758468277105

Epoch: 6| Step: 12
Training loss: 1.2234581216021785
Validation loss: 2.315740421881545

Epoch: 6| Step: 13
Training loss: 1.3066922620939339
Validation loss: 2.302381635842218

Epoch: 379| Step: 0
Training loss: 1.5294656282860757
Validation loss: 2.326228784904565

Epoch: 6| Step: 1
Training loss: 0.9799672094036349
Validation loss: 2.316841045808141

Epoch: 6| Step: 2
Training loss: 0.990056911720758
Validation loss: 2.3079547640804683

Epoch: 6| Step: 3
Training loss: 1.2381276898882019
Validation loss: 2.3490778154568384

Epoch: 6| Step: 4
Training loss: 0.8663874191563071
Validation loss: 2.315591277505132

Epoch: 6| Step: 5
Training loss: 2.0628600528750862
Validation loss: 2.297575901092695

Epoch: 6| Step: 6
Training loss: 1.2433285061296806
Validation loss: 2.3177380358866793

Epoch: 6| Step: 7
Training loss: 1.4417166853737282
Validation loss: 2.2760468387148425

Epoch: 6| Step: 8
Training loss: 1.3524486304944157
Validation loss: 2.275290219685108

Epoch: 6| Step: 9
Training loss: 0.7029240850981613
Validation loss: 2.3051302854883655

Epoch: 6| Step: 10
Training loss: 1.1457108287636817
Validation loss: 2.272978508217779

Epoch: 6| Step: 11
Training loss: 1.196034531276628
Validation loss: 2.336487135860188

Epoch: 6| Step: 12
Training loss: 1.1073057191135902
Validation loss: 2.3510807623060996

Epoch: 6| Step: 13
Training loss: 0.9535318663142579
Validation loss: 2.235442620945675

Epoch: 380| Step: 0
Training loss: 1.4957430356255839
Validation loss: 2.305814670619287

Epoch: 6| Step: 1
Training loss: 1.3021597674506156
Validation loss: 2.2896966640582073

Epoch: 6| Step: 2
Training loss: 1.2413496154580512
Validation loss: 2.3044665781863

Epoch: 6| Step: 3
Training loss: 1.1444424539433506
Validation loss: 2.3050715923662497

Epoch: 6| Step: 4
Training loss: 0.8605696264333859
Validation loss: 2.2748661855625754

Epoch: 6| Step: 5
Training loss: 1.2290191346332562
Validation loss: 2.34440935273994

Epoch: 6| Step: 6
Training loss: 1.1390056873276668
Validation loss: 2.3379555323101258

Epoch: 6| Step: 7
Training loss: 1.49595940287987
Validation loss: 2.3383849738939784

Epoch: 6| Step: 8
Training loss: 1.1496650726378832
Validation loss: 2.3334842318495803

Epoch: 6| Step: 9
Training loss: 1.284391227675341
Validation loss: 2.3090054637829884

Epoch: 6| Step: 10
Training loss: 2.0372748595745716
Validation loss: 2.323830964892575

Epoch: 6| Step: 11
Training loss: 1.360081675334922
Validation loss: 2.2166015324987405

Epoch: 6| Step: 12
Training loss: 0.9462126237449271
Validation loss: 2.3255182177179345

Epoch: 6| Step: 13
Training loss: 1.4193440642989696
Validation loss: 2.246598581558194

Epoch: 381| Step: 0
Training loss: 1.2990097033701358
Validation loss: 2.35086446473908

Epoch: 6| Step: 1
Training loss: 1.208953857036698
Validation loss: 2.3259977819344897

Epoch: 6| Step: 2
Training loss: 2.0883240495228295
Validation loss: 2.3100201925108896

Epoch: 6| Step: 3
Training loss: 0.8914007522721055
Validation loss: 2.287851999878255

Epoch: 6| Step: 4
Training loss: 1.3759227604090625
Validation loss: 2.2871295787283588

Epoch: 6| Step: 5
Training loss: 0.9966121745655677
Validation loss: 2.3168759419983638

Epoch: 6| Step: 6
Training loss: 1.0708353477983539
Validation loss: 2.300086320685741

Epoch: 6| Step: 7
Training loss: 1.2649180003492013
Validation loss: 2.2211945357896994

Epoch: 6| Step: 8
Training loss: 1.6861531569580157
Validation loss: 2.2837335960203657

Epoch: 6| Step: 9
Training loss: 0.946877594745971
Validation loss: 2.292764948300547

Epoch: 6| Step: 10
Training loss: 1.1959419338521908
Validation loss: 2.2779970146929656

Epoch: 6| Step: 11
Training loss: 1.2491550450784312
Validation loss: 2.289869113227927

Epoch: 6| Step: 12
Training loss: 1.156675724320213
Validation loss: 2.2809914512509506

Epoch: 6| Step: 13
Training loss: 0.9031507838175427
Validation loss: 2.3394495564738937

Epoch: 382| Step: 0
Training loss: 1.6785323318172005
Validation loss: 2.2946581633972865

Epoch: 6| Step: 1
Training loss: 1.1199583890542053
Validation loss: 2.2275017263364054

Epoch: 6| Step: 2
Training loss: 0.7663147602438427
Validation loss: 2.266165131260327

Epoch: 6| Step: 3
Training loss: 0.8260916452252953
Validation loss: 2.3537047057511216

Epoch: 6| Step: 4
Training loss: 1.0871985269740037
Validation loss: 2.29979032316003

Epoch: 6| Step: 5
Training loss: 1.2778640760544222
Validation loss: 2.3318904057029024

Epoch: 6| Step: 6
Training loss: 1.4592013727516275
Validation loss: 2.3122037682870413

Epoch: 6| Step: 7
Training loss: 1.7664616720758375
Validation loss: 2.3350929480986364

Epoch: 6| Step: 8
Training loss: 1.341208071946571
Validation loss: 2.2713950458638283

Epoch: 6| Step: 9
Training loss: 1.2892593695843972
Validation loss: 2.3498195928909227

Epoch: 6| Step: 10
Training loss: 1.3176236734849516
Validation loss: 2.2968525073789188

Epoch: 6| Step: 11
Training loss: 0.904618702382549
Validation loss: 2.2437785979245795

Epoch: 6| Step: 12
Training loss: 0.867274408882729
Validation loss: 2.2886006024605843

Epoch: 6| Step: 13
Training loss: 1.2562078819995723
Validation loss: 2.2630851860407177

Epoch: 383| Step: 0
Training loss: 1.3247178299066864
Validation loss: 2.308420773375974

Epoch: 6| Step: 1
Training loss: 1.9672364365942365
Validation loss: 2.31658854314839

Epoch: 6| Step: 2
Training loss: 1.383290870811437
Validation loss: 2.302215398288192

Epoch: 6| Step: 3
Training loss: 1.317798817459296
Validation loss: 2.2703265275319926

Epoch: 6| Step: 4
Training loss: 1.426857403693892
Validation loss: 2.2849082299629906

Epoch: 6| Step: 5
Training loss: 1.2875845094370546
Validation loss: 2.363271541197538

Epoch: 6| Step: 6
Training loss: 1.1575578046499264
Validation loss: 2.259991333932439

Epoch: 6| Step: 7
Training loss: 1.5709881444006546
Validation loss: 2.25976354607926

Epoch: 6| Step: 8
Training loss: 1.3161758085318764
Validation loss: 2.310751247385038

Epoch: 6| Step: 9
Training loss: 0.5386968284619793
Validation loss: 2.2745633934755007

Epoch: 6| Step: 10
Training loss: 1.1635132588351143
Validation loss: 2.308520321861357

Epoch: 6| Step: 11
Training loss: 1.2204083628495166
Validation loss: 2.3158621604261875

Epoch: 6| Step: 12
Training loss: 0.8074540661954108
Validation loss: 2.3493901185062334

Epoch: 6| Step: 13
Training loss: 1.312955096227273
Validation loss: 2.3006799247519125

Epoch: 384| Step: 0
Training loss: 1.2972128094929096
Validation loss: 2.3144685912862704

Epoch: 6| Step: 1
Training loss: 1.11201581812661
Validation loss: 2.307802223875138

Epoch: 6| Step: 2
Training loss: 0.8497946000163507
Validation loss: 2.2428445623995006

Epoch: 6| Step: 3
Training loss: 1.0751038390286838
Validation loss: 2.315332884205229

Epoch: 6| Step: 4
Training loss: 1.1176489563902225
Validation loss: 2.2947153722276434

Epoch: 6| Step: 5
Training loss: 1.1935643895634607
Validation loss: 2.2747153112941114

Epoch: 6| Step: 6
Training loss: 1.2826120998327555
Validation loss: 2.2965440375646153

Epoch: 6| Step: 7
Training loss: 1.390327121677453
Validation loss: 2.347298584017287

Epoch: 6| Step: 8
Training loss: 2.2010962702604786
Validation loss: 2.2933138464171057

Epoch: 6| Step: 9
Training loss: 1.159852472987077
Validation loss: 2.247417569953955

Epoch: 6| Step: 10
Training loss: 1.2332792609621752
Validation loss: 2.2712681379363855

Epoch: 6| Step: 11
Training loss: 1.048689337557092
Validation loss: 2.3073668853188525

Epoch: 6| Step: 12
Training loss: 0.9353729277468917
Validation loss: 2.369227104636567

Epoch: 6| Step: 13
Training loss: 0.9383140844083848
Validation loss: 2.291801875610732

Epoch: 385| Step: 0
Training loss: 0.803911408907368
Validation loss: 2.309009806080681

Epoch: 6| Step: 1
Training loss: 0.9053393425351108
Validation loss: 2.296149312696855

Epoch: 6| Step: 2
Training loss: 1.109194458790752
Validation loss: 2.317311893159238

Epoch: 6| Step: 3
Training loss: 1.1850076923040214
Validation loss: 2.2679193632517034

Epoch: 6| Step: 4
Training loss: 0.7808927100481367
Validation loss: 2.2584368525215783

Epoch: 6| Step: 5
Training loss: 1.207187926361222
Validation loss: 2.4010753917952607

Epoch: 6| Step: 6
Training loss: 2.3854848416066097
Validation loss: 2.298096094543569

Epoch: 6| Step: 7
Training loss: 1.520320108988619
Validation loss: 2.3029440181876915

Epoch: 6| Step: 8
Training loss: 0.8610595838108758
Validation loss: 2.2592172114538482

Epoch: 6| Step: 9
Training loss: 1.048216117305831
Validation loss: 2.329329331192445

Epoch: 6| Step: 10
Training loss: 1.234548484103543
Validation loss: 2.281947238538695

Epoch: 6| Step: 11
Training loss: 1.6082272186587059
Validation loss: 2.291035149743757

Epoch: 6| Step: 12
Training loss: 1.282503491818915
Validation loss: 2.3158864670731067

Epoch: 6| Step: 13
Training loss: 1.3826843029878968
Validation loss: 2.3116351048139996

Epoch: 386| Step: 0
Training loss: 1.1919605404063778
Validation loss: 2.30011343446655

Epoch: 6| Step: 1
Training loss: 1.2928593061981528
Validation loss: 2.354142935855867

Epoch: 6| Step: 2
Training loss: 1.196345661926376
Validation loss: 2.301286401220744

Epoch: 6| Step: 3
Training loss: 1.2597620291251974
Validation loss: 2.327723032695865

Epoch: 6| Step: 4
Training loss: 1.2169021879273205
Validation loss: 2.302187829315669

Epoch: 6| Step: 5
Training loss: 1.0401346511970695
Validation loss: 2.266086382310008

Epoch: 6| Step: 6
Training loss: 1.1674114415891457
Validation loss: 2.260728638644112

Epoch: 6| Step: 7
Training loss: 1.33731766286767
Validation loss: 2.3255806455327184

Epoch: 6| Step: 8
Training loss: 1.0709083179586487
Validation loss: 2.2953954421947746

Epoch: 6| Step: 9
Training loss: 1.1416480819321824
Validation loss: 2.2305706303977435

Epoch: 6| Step: 10
Training loss: 1.181982624594302
Validation loss: 2.292757603202951

Epoch: 6| Step: 11
Training loss: 1.2232032015619487
Validation loss: 2.3220896746728434

Epoch: 6| Step: 12
Training loss: 0.8861594431766098
Validation loss: 2.326448219235376

Epoch: 6| Step: 13
Training loss: 2.4658669163293974
Validation loss: 2.341298526113224

Epoch: 387| Step: 0
Training loss: 1.331302208391603
Validation loss: 2.2847789160132854

Epoch: 6| Step: 1
Training loss: 1.3848696132940441
Validation loss: 2.2980410554462893

Epoch: 6| Step: 2
Training loss: 1.0892817097395961
Validation loss: 2.423026686937991

Epoch: 6| Step: 3
Training loss: 1.0309173741129425
Validation loss: 2.3358516778180545

Epoch: 6| Step: 4
Training loss: 1.175247882505975
Validation loss: 2.335410916669321

Epoch: 6| Step: 5
Training loss: 1.0844086237814619
Validation loss: 2.3761317606441565

Epoch: 6| Step: 6
Training loss: 1.481386891409464
Validation loss: 2.343964629378295

Epoch: 6| Step: 7
Training loss: 1.8881846670340563
Validation loss: 2.3445377647551946

Epoch: 6| Step: 8
Training loss: 1.1043276879323385
Validation loss: 2.276034131122934

Epoch: 6| Step: 9
Training loss: 1.418248845119265
Validation loss: 2.3696540288610923

Epoch: 6| Step: 10
Training loss: 1.4422752014804316
Validation loss: 2.2689096207585986

Epoch: 6| Step: 11
Training loss: 1.0004144048340848
Validation loss: 2.30070359452608

Epoch: 6| Step: 12
Training loss: 1.0339830191747108
Validation loss: 2.2912085387517545

Epoch: 6| Step: 13
Training loss: 0.7699551262103289
Validation loss: 2.2490009091596463

Epoch: 388| Step: 0
Training loss: 1.4268186374782785
Validation loss: 2.306528530269635

Epoch: 6| Step: 1
Training loss: 0.9676229627474711
Validation loss: 2.3577616314280707

Epoch: 6| Step: 2
Training loss: 1.2485240328594986
Validation loss: 2.2240852257700796

Epoch: 6| Step: 3
Training loss: 2.135077646527559
Validation loss: 2.3648688858718

Epoch: 6| Step: 4
Training loss: 1.4865725663401423
Validation loss: 2.3134502729939848

Epoch: 6| Step: 5
Training loss: 0.8918936210351174
Validation loss: 2.3254508262069575

Epoch: 6| Step: 6
Training loss: 1.3403933095907903
Validation loss: 2.3165978771250444

Epoch: 6| Step: 7
Training loss: 1.2673941127480841
Validation loss: 2.305880295710823

Epoch: 6| Step: 8
Training loss: 0.7945707328236039
Validation loss: 2.315532171968232

Epoch: 6| Step: 9
Training loss: 1.1406532179594977
Validation loss: 2.361494367846293

Epoch: 6| Step: 10
Training loss: 1.0084827766857931
Validation loss: 2.3628478210504236

Epoch: 6| Step: 11
Training loss: 1.0603322748104769
Validation loss: 2.2547671111351275

Epoch: 6| Step: 12
Training loss: 1.0474833528566068
Validation loss: 2.3050762712774135

Epoch: 6| Step: 13
Training loss: 1.4988733670045484
Validation loss: 2.2936012745822496

Epoch: 389| Step: 0
Training loss: 1.0406455693775203
Validation loss: 2.2922965346637367

Epoch: 6| Step: 1
Training loss: 1.1914298133396029
Validation loss: 2.352312749926904

Epoch: 6| Step: 2
Training loss: 1.3665210080254002
Validation loss: 2.260435390569711

Epoch: 6| Step: 3
Training loss: 1.5686864072517057
Validation loss: 2.349720132439511

Epoch: 6| Step: 4
Training loss: 1.239634162865121
Validation loss: 2.290015504714423

Epoch: 6| Step: 5
Training loss: 1.3087613582027127
Validation loss: 2.2412486583875744

Epoch: 6| Step: 6
Training loss: 1.149361789911639
Validation loss: 2.2957116677909264

Epoch: 6| Step: 7
Training loss: 1.0651193756037391
Validation loss: 2.3537530228463917

Epoch: 6| Step: 8
Training loss: 0.9704392993777897
Validation loss: 2.3021093317970234

Epoch: 6| Step: 9
Training loss: 1.0002674698756848
Validation loss: 2.293658828320491

Epoch: 6| Step: 10
Training loss: 0.8014967908194125
Validation loss: 2.3343420261896894

Epoch: 6| Step: 11
Training loss: 1.955735438134051
Validation loss: 2.265458985987107

Epoch: 6| Step: 12
Training loss: 1.4195517539022084
Validation loss: 2.3189805995926656

Epoch: 6| Step: 13
Training loss: 1.174029493276627
Validation loss: 2.2912378543882976

Epoch: 390| Step: 0
Training loss: 0.6901369674852743
Validation loss: 2.2665574103860124

Epoch: 6| Step: 1
Training loss: 1.4310032361125276
Validation loss: 2.304168035281344

Epoch: 6| Step: 2
Training loss: 1.0659800365933347
Validation loss: 2.2822364790309586

Epoch: 6| Step: 3
Training loss: 0.7663888040748185
Validation loss: 2.2592145788385736

Epoch: 6| Step: 4
Training loss: 1.4616415194034058
Validation loss: 2.354587346011988

Epoch: 6| Step: 5
Training loss: 2.068247791194578
Validation loss: 2.250244489669499

Epoch: 6| Step: 6
Training loss: 1.3589889153483905
Validation loss: 2.315273623697312

Epoch: 6| Step: 7
Training loss: 0.6947284131136728
Validation loss: 2.346884459149906

Epoch: 6| Step: 8
Training loss: 0.8931734199292345
Validation loss: 2.3002799732679127

Epoch: 6| Step: 9
Training loss: 1.4471946214975562
Validation loss: 2.2348611791645108

Epoch: 6| Step: 10
Training loss: 1.232723241555458
Validation loss: 2.240748799658886

Epoch: 6| Step: 11
Training loss: 1.2239609846803343
Validation loss: 2.3074682780111044

Epoch: 6| Step: 12
Training loss: 0.8607595560993153
Validation loss: 2.28697329600685

Epoch: 6| Step: 13
Training loss: 1.5790617777967888
Validation loss: 2.2893291249372187

Epoch: 391| Step: 0
Training loss: 0.9138807458395608
Validation loss: 2.297880062075425

Epoch: 6| Step: 1
Training loss: 1.2105545915208136
Validation loss: 2.4066620383247814

Epoch: 6| Step: 2
Training loss: 1.2880642348999738
Validation loss: 2.3012451403967824

Epoch: 6| Step: 3
Training loss: 1.481198898270929
Validation loss: 2.3482264602825986

Epoch: 6| Step: 4
Training loss: 0.9274293418148593
Validation loss: 2.3279880225438663

Epoch: 6| Step: 5
Training loss: 1.215070010393422
Validation loss: 2.2902913205353106

Epoch: 6| Step: 6
Training loss: 1.4122208462901948
Validation loss: 2.2796939819876236

Epoch: 6| Step: 7
Training loss: 0.637717791361202
Validation loss: 2.338970446944155

Epoch: 6| Step: 8
Training loss: 1.0952735099437367
Validation loss: 2.371916022391755

Epoch: 6| Step: 9
Training loss: 1.8850943639393256
Validation loss: 2.289719472732347

Epoch: 6| Step: 10
Training loss: 1.0852683770821365
Validation loss: 2.266777841162724

Epoch: 6| Step: 11
Training loss: 1.099259044610875
Validation loss: 2.329554920665245

Epoch: 6| Step: 12
Training loss: 1.3094157811189395
Validation loss: 2.3170799768723267

Epoch: 6| Step: 13
Training loss: 0.8780702132649859
Validation loss: 2.239895358793847

Epoch: 392| Step: 0
Training loss: 0.9610219468638442
Validation loss: 2.2694726980576703

Epoch: 6| Step: 1
Training loss: 0.94561907628354
Validation loss: 2.2670492423333033

Epoch: 6| Step: 2
Training loss: 1.6531306708370215
Validation loss: 2.3134988691176837

Epoch: 6| Step: 3
Training loss: 0.9834611071531182
Validation loss: 2.262654697376016

Epoch: 6| Step: 4
Training loss: 0.9644902002401335
Validation loss: 2.307679898501063

Epoch: 6| Step: 5
Training loss: 1.485681139856585
Validation loss: 2.2224487874537537

Epoch: 6| Step: 6
Training loss: 1.0922933415330882
Validation loss: 2.315372891941225

Epoch: 6| Step: 7
Training loss: 1.5730542592210903
Validation loss: 2.340126743747605

Epoch: 6| Step: 8
Training loss: 1.1389557630138842
Validation loss: 2.3441733094918566

Epoch: 6| Step: 9
Training loss: 2.1132312705287317
Validation loss: 2.293414474293985

Epoch: 6| Step: 10
Training loss: 0.8086924469647104
Validation loss: 2.3088049530951738

Epoch: 6| Step: 11
Training loss: 0.8925023286719623
Validation loss: 2.36934569520192

Epoch: 6| Step: 12
Training loss: 1.0066949725329333
Validation loss: 2.2807461986769386

Epoch: 6| Step: 13
Training loss: 1.0891180322573726
Validation loss: 2.3187189155204124

Epoch: 393| Step: 0
Training loss: 1.9729861748390325
Validation loss: 2.3313738825568753

Epoch: 6| Step: 1
Training loss: 0.9318304288401875
Validation loss: 2.3230321353212777

Epoch: 6| Step: 2
Training loss: 0.6338238111471657
Validation loss: 2.291149231637359

Epoch: 6| Step: 3
Training loss: 0.8733067136510178
Validation loss: 2.2980712974110857

Epoch: 6| Step: 4
Training loss: 0.6750852937144464
Validation loss: 2.291118056855423

Epoch: 6| Step: 5
Training loss: 1.3896120647031862
Validation loss: 2.319324894082721

Epoch: 6| Step: 6
Training loss: 1.0455988607200482
Validation loss: 2.327624234988049

Epoch: 6| Step: 7
Training loss: 0.9847333951984876
Validation loss: 2.242095082119774

Epoch: 6| Step: 8
Training loss: 1.118478202835941
Validation loss: 2.3283961032868303

Epoch: 6| Step: 9
Training loss: 1.2542886121317927
Validation loss: 2.346097419528309

Epoch: 6| Step: 10
Training loss: 1.1923898107774769
Validation loss: 2.330566124098047

Epoch: 6| Step: 11
Training loss: 1.5960718333587656
Validation loss: 2.3568155593902143

Epoch: 6| Step: 12
Training loss: 1.2218350220991487
Validation loss: 2.3190154254479203

Epoch: 6| Step: 13
Training loss: 1.214203988057805
Validation loss: 2.288467873730788

Epoch: 394| Step: 0
Training loss: 0.8713819087040139
Validation loss: 2.2764932022123503

Epoch: 6| Step: 1
Training loss: 0.9873090643931945
Validation loss: 2.3273275457217246

Epoch: 6| Step: 2
Training loss: 1.1081958467972635
Validation loss: 2.338543800345539

Epoch: 6| Step: 3
Training loss: 0.8781397210784385
Validation loss: 2.2604338515469453

Epoch: 6| Step: 4
Training loss: 2.0538928449736695
Validation loss: 2.3554680958846625

Epoch: 6| Step: 5
Training loss: 0.9394509678298388
Validation loss: 2.3701396127320984

Epoch: 6| Step: 6
Training loss: 1.034417288108825
Validation loss: 2.37702447586621

Epoch: 6| Step: 7
Training loss: 1.2079526476958098
Validation loss: 2.265943417293302

Epoch: 6| Step: 8
Training loss: 1.2791572785835492
Validation loss: 2.3466974168760752

Epoch: 6| Step: 9
Training loss: 1.5295473870390541
Validation loss: 2.349187049420078

Epoch: 6| Step: 10
Training loss: 0.8985444046770094
Validation loss: 2.3097885319080165

Epoch: 6| Step: 11
Training loss: 1.3136049796366658
Validation loss: 2.2559379695701063

Epoch: 6| Step: 12
Training loss: 1.2863284623336466
Validation loss: 2.3454031011317853

Epoch: 6| Step: 13
Training loss: 1.9032416447313636
Validation loss: 2.3154340553945736

Epoch: 395| Step: 0
Training loss: 2.1888054358467843
Validation loss: 2.2562869118509545

Epoch: 6| Step: 1
Training loss: 0.7453580894362367
Validation loss: 2.327920832480244

Epoch: 6| Step: 2
Training loss: 1.3776985044814734
Validation loss: 2.360684019819202

Epoch: 6| Step: 3
Training loss: 1.243851033616705
Validation loss: 2.3427967837611274

Epoch: 6| Step: 4
Training loss: 1.1073190685098282
Validation loss: 2.323752998528796

Epoch: 6| Step: 5
Training loss: 1.1257909537432567
Validation loss: 2.313420973428558

Epoch: 6| Step: 6
Training loss: 0.9311114393750596
Validation loss: 2.201590547733996

Epoch: 6| Step: 7
Training loss: 1.0210168764324314
Validation loss: 2.3723964139823885

Epoch: 6| Step: 8
Training loss: 0.8320437864693383
Validation loss: 2.266203045963793

Epoch: 6| Step: 9
Training loss: 1.2568513028999566
Validation loss: 2.262049892516543

Epoch: 6| Step: 10
Training loss: 1.1496729012402578
Validation loss: 2.258954297900787

Epoch: 6| Step: 11
Training loss: 1.2416703689229844
Validation loss: 2.2809259603423997

Epoch: 6| Step: 12
Training loss: 1.1438253784355152
Validation loss: 2.3151365613528627

Epoch: 6| Step: 13
Training loss: 1.4514803860108207
Validation loss: 2.299149645449944

Epoch: 396| Step: 0
Training loss: 1.0365763010849158
Validation loss: 2.311189635540854

Epoch: 6| Step: 1
Training loss: 0.9486718505718633
Validation loss: 2.316176944833459

Epoch: 6| Step: 2
Training loss: 1.2849068443136833
Validation loss: 2.35330884472115

Epoch: 6| Step: 3
Training loss: 1.087526435092286
Validation loss: 2.318993082901989

Epoch: 6| Step: 4
Training loss: 2.245771885905911
Validation loss: 2.3434618318117266

Epoch: 6| Step: 5
Training loss: 0.9620379527906946
Validation loss: 2.3191462544464287

Epoch: 6| Step: 6
Training loss: 1.2693218351919917
Validation loss: 2.2520310362709153

Epoch: 6| Step: 7
Training loss: 1.5474229092723784
Validation loss: 2.377543335958275

Epoch: 6| Step: 8
Training loss: 1.2900350889712178
Validation loss: 2.267361999609369

Epoch: 6| Step: 9
Training loss: 1.2697753202133584
Validation loss: 2.3190386145730693

Epoch: 6| Step: 10
Training loss: 0.9966028744930372
Validation loss: 2.3354243747479

Epoch: 6| Step: 11
Training loss: 0.9415966173859918
Validation loss: 2.233560437319874

Epoch: 6| Step: 12
Training loss: 0.9489282548131578
Validation loss: 2.277858734651378

Epoch: 6| Step: 13
Training loss: 0.8354502889157012
Validation loss: 2.3338231094218815

Epoch: 397| Step: 0
Training loss: 1.1091719965492626
Validation loss: 2.2813398574166257

Epoch: 6| Step: 1
Training loss: 0.6617164458647947
Validation loss: 2.356967951820321

Epoch: 6| Step: 2
Training loss: 2.056758750428596
Validation loss: 2.2831484539303792

Epoch: 6| Step: 3
Training loss: 1.3184071624006923
Validation loss: 2.284506883008864

Epoch: 6| Step: 4
Training loss: 1.1530247631804993
Validation loss: 2.2341752258803402

Epoch: 6| Step: 5
Training loss: 1.3309232068912171
Validation loss: 2.3277888364006505

Epoch: 6| Step: 6
Training loss: 1.2551509110650496
Validation loss: 2.3496796762967556

Epoch: 6| Step: 7
Training loss: 0.959943086258312
Validation loss: 2.332260963972738

Epoch: 6| Step: 8
Training loss: 1.2688645240697725
Validation loss: 2.2638071429894704

Epoch: 6| Step: 9
Training loss: 1.2638331786419754
Validation loss: 2.272336527980382

Epoch: 6| Step: 10
Training loss: 0.807632686000397
Validation loss: 2.370757922034654

Epoch: 6| Step: 11
Training loss: 0.9502061958905076
Validation loss: 2.2961964333524776

Epoch: 6| Step: 12
Training loss: 0.873017039631949
Validation loss: 2.28221996418627

Epoch: 6| Step: 13
Training loss: 1.071946060005028
Validation loss: 2.2752323793269866

Epoch: 398| Step: 0
Training loss: 1.2852209474922924
Validation loss: 2.2775459172376245

Epoch: 6| Step: 1
Training loss: 1.147202171204852
Validation loss: 2.322016394535471

Epoch: 6| Step: 2
Training loss: 1.4740141014449437
Validation loss: 2.3170469171033816

Epoch: 6| Step: 3
Training loss: 1.0714271477281103
Validation loss: 2.2803015519204495

Epoch: 6| Step: 4
Training loss: 0.716140488113338
Validation loss: 2.286354762428669

Epoch: 6| Step: 5
Training loss: 1.3310089215410248
Validation loss: 2.362563972368782

Epoch: 6| Step: 6
Training loss: 0.8955536043363044
Validation loss: 2.316346471319818

Epoch: 6| Step: 7
Training loss: 0.9424456481540879
Validation loss: 2.2505067177254348

Epoch: 6| Step: 8
Training loss: 1.3033086834809897
Validation loss: 2.276987334163508

Epoch: 6| Step: 9
Training loss: 0.8398363334860576
Validation loss: 2.2994676982512035

Epoch: 6| Step: 10
Training loss: 1.1205775438207715
Validation loss: 2.2974055496928245

Epoch: 6| Step: 11
Training loss: 2.139558846823568
Validation loss: 2.289569056578934

Epoch: 6| Step: 12
Training loss: 0.7633079188362517
Validation loss: 2.3728752427629285

Epoch: 6| Step: 13
Training loss: 1.459018691551744
Validation loss: 2.284457509116148

Epoch: 399| Step: 0
Training loss: 0.8157540960930957
Validation loss: 2.2797979345807295

Epoch: 6| Step: 1
Training loss: 1.2270913897229903
Validation loss: 2.309648580030808

Epoch: 6| Step: 2
Training loss: 1.1567221012811526
Validation loss: 2.3888987351962094

Epoch: 6| Step: 3
Training loss: 1.0804915507814579
Validation loss: 2.3181157014862066

Epoch: 6| Step: 4
Training loss: 2.173145828037546
Validation loss: 2.388698493583085

Epoch: 6| Step: 5
Training loss: 1.4510200595639042
Validation loss: 2.3629758635662137

Epoch: 6| Step: 6
Training loss: 0.5397831067086626
Validation loss: 2.316955085256215

Epoch: 6| Step: 7
Training loss: 1.3296198790733946
Validation loss: 2.2976517381386796

Epoch: 6| Step: 8
Training loss: 1.2542585311821535
Validation loss: 2.2908214393814603

Epoch: 6| Step: 9
Training loss: 1.3729584015603535
Validation loss: 2.2875653829856866

Epoch: 6| Step: 10
Training loss: 0.8206667907021639
Validation loss: 2.3349013593698706

Epoch: 6| Step: 11
Training loss: 0.8488241842488267
Validation loss: 2.222723272666087

Epoch: 6| Step: 12
Training loss: 0.9339446681192457
Validation loss: 2.286298982623696

Epoch: 6| Step: 13
Training loss: 0.8063957082690975
Validation loss: 2.320939909879654

Epoch: 400| Step: 0
Training loss: 1.2448986864039981
Validation loss: 2.352576418267927

Epoch: 6| Step: 1
Training loss: 0.9673056448663796
Validation loss: 2.301296445052541

Epoch: 6| Step: 2
Training loss: 0.8076532395052692
Validation loss: 2.3552177623488864

Epoch: 6| Step: 3
Training loss: 1.1519714788641493
Validation loss: 2.2582615560746286

Epoch: 6| Step: 4
Training loss: 2.04644689378166
Validation loss: 2.293143843586411

Epoch: 6| Step: 5
Training loss: 0.8138405671239265
Validation loss: 2.2464163748158072

Epoch: 6| Step: 6
Training loss: 0.8018666796352947
Validation loss: 2.2374905086775936

Epoch: 6| Step: 7
Training loss: 1.243122732429872
Validation loss: 2.356382266283119

Epoch: 6| Step: 8
Training loss: 1.2426437403776989
Validation loss: 2.3223754665853815

Epoch: 6| Step: 9
Training loss: 0.798031211247443
Validation loss: 2.32261298613509

Epoch: 6| Step: 10
Training loss: 0.7631404813278699
Validation loss: 2.239725672058877

Epoch: 6| Step: 11
Training loss: 1.9202148586494938
Validation loss: 2.285466613531851

Epoch: 6| Step: 12
Training loss: 0.8775110317960493
Validation loss: 2.3456685942781874

Epoch: 6| Step: 13
Training loss: 0.6836418788860835
Validation loss: 2.3241687168476193

Epoch: 401| Step: 0
Training loss: 1.2471529007989324
Validation loss: 2.2803461518081223

Epoch: 6| Step: 1
Training loss: 1.0708628443845922
Validation loss: 2.30915184278808

Epoch: 6| Step: 2
Training loss: 1.1404032034329554
Validation loss: 2.2500458693300915

Epoch: 6| Step: 3
Training loss: 1.0256287507169346
Validation loss: 2.2496542385782243

Epoch: 6| Step: 4
Training loss: 1.1941285596642937
Validation loss: 2.2884324491252874

Epoch: 6| Step: 5
Training loss: 0.6414828023634563
Validation loss: 2.2998345198885675

Epoch: 6| Step: 6
Training loss: 0.7111676860033479
Validation loss: 2.3917476059241225

Epoch: 6| Step: 7
Training loss: 2.005275206668646
Validation loss: 2.191830251995625

Epoch: 6| Step: 8
Training loss: 1.0040407795698263
Validation loss: 2.281438063734606

Epoch: 6| Step: 9
Training loss: 1.515897824616126
Validation loss: 2.23952497409602

Epoch: 6| Step: 10
Training loss: 1.3026720572554984
Validation loss: 2.210072003792739

Epoch: 6| Step: 11
Training loss: 1.2340311464802656
Validation loss: 2.272315849184598

Epoch: 6| Step: 12
Training loss: 1.0772988291359507
Validation loss: 2.2919955251632467

Epoch: 6| Step: 13
Training loss: 1.180675219411331
Validation loss: 2.311253112568323

Epoch: 402| Step: 0
Training loss: 1.2720009593780066
Validation loss: 2.2474341420562354

Epoch: 6| Step: 1
Training loss: 0.8004645116613033
Validation loss: 2.287894558333763

Epoch: 6| Step: 2
Training loss: 1.1333456429112203
Validation loss: 2.3272086800848517

Epoch: 6| Step: 3
Training loss: 0.9611436886279603
Validation loss: 2.3884579582317236

Epoch: 6| Step: 4
Training loss: 1.209198866445456
Validation loss: 2.400321970748272

Epoch: 6| Step: 5
Training loss: 0.7277223906500291
Validation loss: 2.299027691557297

Epoch: 6| Step: 6
Training loss: 1.1268521004125713
Validation loss: 2.3461972548220142

Epoch: 6| Step: 7
Training loss: 1.1337924796224614
Validation loss: 2.318269462910817

Epoch: 6| Step: 8
Training loss: 1.2383816555002602
Validation loss: 2.3097003306923405

Epoch: 6| Step: 9
Training loss: 0.8845225625554083
Validation loss: 2.2153964936068333

Epoch: 6| Step: 10
Training loss: 1.2337644491538036
Validation loss: 2.3041233056958195

Epoch: 6| Step: 11
Training loss: 1.0868278530922366
Validation loss: 2.298092998333017

Epoch: 6| Step: 12
Training loss: 1.9449779421970148
Validation loss: 2.2609607394661184

Epoch: 6| Step: 13
Training loss: 1.6247811536876404
Validation loss: 2.301782393386142

Epoch: 403| Step: 0
Training loss: 0.9852125147241882
Validation loss: 2.3233101710738606

Epoch: 6| Step: 1
Training loss: 1.152482157008472
Validation loss: 2.362182571707288

Epoch: 6| Step: 2
Training loss: 1.659186297533184
Validation loss: 2.242188821730543

Epoch: 6| Step: 3
Training loss: 0.8914677831890787
Validation loss: 2.2917655405173156

Epoch: 6| Step: 4
Training loss: 2.0447744992261487
Validation loss: 2.3212057425675305

Epoch: 6| Step: 5
Training loss: 1.3485937865602773
Validation loss: 2.2972562282541573

Epoch: 6| Step: 6
Training loss: 0.761361414894476
Validation loss: 2.3015296827822196

Epoch: 6| Step: 7
Training loss: 0.7523702678186193
Validation loss: 2.3279575293998183

Epoch: 6| Step: 8
Training loss: 1.2003166814014687
Validation loss: 2.3022156209989353

Epoch: 6| Step: 9
Training loss: 1.140534593317571
Validation loss: 2.280274018746976

Epoch: 6| Step: 10
Training loss: 1.467684095230835
Validation loss: 2.2454586948569744

Epoch: 6| Step: 11
Training loss: 1.393147698513132
Validation loss: 2.3066176713369604

Epoch: 6| Step: 12
Training loss: 1.1985065942613904
Validation loss: 2.348087251230465

Epoch: 6| Step: 13
Training loss: 0.606054748476144
Validation loss: 2.3061447283601413

Epoch: 404| Step: 0
Training loss: 1.173974864248727
Validation loss: 2.332143198965921

Epoch: 6| Step: 1
Training loss: 0.6897219169059703
Validation loss: 2.245523438600092

Epoch: 6| Step: 2
Training loss: 0.8423053949108354
Validation loss: 2.2773415143283753

Epoch: 6| Step: 3
Training loss: 1.3133514004318247
Validation loss: 2.3221898515678605

Epoch: 6| Step: 4
Training loss: 2.003710166454306
Validation loss: 2.3477059032611165

Epoch: 6| Step: 5
Training loss: 0.8810962096408446
Validation loss: 2.285361331767823

Epoch: 6| Step: 6
Training loss: 1.2469051194915193
Validation loss: 2.3012930005668055

Epoch: 6| Step: 7
Training loss: 0.861352137362815
Validation loss: 2.3449226360930644

Epoch: 6| Step: 8
Training loss: 1.1845516948699257
Validation loss: 2.4066997758148356

Epoch: 6| Step: 9
Training loss: 1.1992154199013465
Validation loss: 2.2670615049888054

Epoch: 6| Step: 10
Training loss: 1.1802056797645324
Validation loss: 2.3250767405826904

Epoch: 6| Step: 11
Training loss: 1.1038380379737593
Validation loss: 2.287580727355783

Epoch: 6| Step: 12
Training loss: 0.9916905036967811
Validation loss: 2.328016143277842

Epoch: 6| Step: 13
Training loss: 1.0295733491317511
Validation loss: 2.3367909385477015

Epoch: 405| Step: 0
Training loss: 0.958016025146373
Validation loss: 2.4014592747919123

Epoch: 6| Step: 1
Training loss: 1.9698509891909843
Validation loss: 2.3090782503166185

Epoch: 6| Step: 2
Training loss: 0.8837163568591979
Validation loss: 2.257817029886364

Epoch: 6| Step: 3
Training loss: 0.779446847964359
Validation loss: 2.350383711247535

Epoch: 6| Step: 4
Training loss: 1.522971448769707
Validation loss: 2.294600296198093

Epoch: 6| Step: 5
Training loss: 1.0810476852507247
Validation loss: 2.299555688817951

Epoch: 6| Step: 6
Training loss: 0.7408301137833496
Validation loss: 2.252753429078021

Epoch: 6| Step: 7
Training loss: 1.1704116331114223
Validation loss: 2.317022564542156

Epoch: 6| Step: 8
Training loss: 0.8022203865042007
Validation loss: 2.293313598248608

Epoch: 6| Step: 9
Training loss: 1.3304433447248492
Validation loss: 2.2983676027681312

Epoch: 6| Step: 10
Training loss: 1.000789866830982
Validation loss: 2.238597908535649

Epoch: 6| Step: 11
Training loss: 1.0348215965723189
Validation loss: 2.3251586061651577

Epoch: 6| Step: 12
Training loss: 1.1718903604136541
Validation loss: 2.2839383955523322

Epoch: 6| Step: 13
Training loss: 1.0680236288842881
Validation loss: 2.227177135100203

Epoch: 406| Step: 0
Training loss: 1.2445857091795232
Validation loss: 2.359281198361484

Epoch: 6| Step: 1
Training loss: 1.1511778024573283
Validation loss: 2.3026370786292323

Epoch: 6| Step: 2
Training loss: 0.8760822279192683
Validation loss: 2.321835509677824

Epoch: 6| Step: 3
Training loss: 0.7930236947703544
Validation loss: 2.2894882449637386

Epoch: 6| Step: 4
Training loss: 1.1185164650057744
Validation loss: 2.260506362537982

Epoch: 6| Step: 5
Training loss: 0.7726175605182469
Validation loss: 2.328435987860808

Epoch: 6| Step: 6
Training loss: 0.891722321036103
Validation loss: 2.316865583405128

Epoch: 6| Step: 7
Training loss: 1.22613877673775
Validation loss: 2.2899725714584593

Epoch: 6| Step: 8
Training loss: 1.3918928303323774
Validation loss: 2.2904291202917175

Epoch: 6| Step: 9
Training loss: 1.3116164639587011
Validation loss: 2.3777579025907016

Epoch: 6| Step: 10
Training loss: 2.0185507897504094
Validation loss: 2.2913380011491657

Epoch: 6| Step: 11
Training loss: 1.3664766916184747
Validation loss: 2.3394899413218724

Epoch: 6| Step: 12
Training loss: 1.0486243136980404
Validation loss: 2.3132865535913294

Epoch: 6| Step: 13
Training loss: 0.7723486971904123
Validation loss: 2.353133184286953

Epoch: 407| Step: 0
Training loss: 0.7938213932039871
Validation loss: 2.3588821829813282

Epoch: 6| Step: 1
Training loss: 2.035454726343272
Validation loss: 2.2954744245002097

Epoch: 6| Step: 2
Training loss: 1.487329213571991
Validation loss: 2.3616970527955425

Epoch: 6| Step: 3
Training loss: 1.045345897739751
Validation loss: 2.3454352343676854

Epoch: 6| Step: 4
Training loss: 1.612985357531444
Validation loss: 2.2558278977658617

Epoch: 6| Step: 5
Training loss: 1.156407165155872
Validation loss: 2.2855833137105686

Epoch: 6| Step: 6
Training loss: 0.9561393474310805
Validation loss: 2.3489487894312404

Epoch: 6| Step: 7
Training loss: 0.9680846605953201
Validation loss: 2.2903068531613693

Epoch: 6| Step: 8
Training loss: 0.6676146254541386
Validation loss: 2.3581380934257035

Epoch: 6| Step: 9
Training loss: 1.079835999099056
Validation loss: 2.306044203524091

Epoch: 6| Step: 10
Training loss: 1.2207246580132054
Validation loss: 2.2346967159616735

Epoch: 6| Step: 11
Training loss: 1.1691933020677538
Validation loss: 2.312739282548768

Epoch: 6| Step: 12
Training loss: 1.0792930467657122
Validation loss: 2.2671370691429575

Epoch: 6| Step: 13
Training loss: 0.555323035205176
Validation loss: 2.2970830050105273

Epoch: 408| Step: 0
Training loss: 1.1291600770277095
Validation loss: 2.3096299135898795

Epoch: 6| Step: 1
Training loss: 1.399716948097021
Validation loss: 2.3144109098088235

Epoch: 6| Step: 2
Training loss: 0.7963685314877973
Validation loss: 2.315469136652016

Epoch: 6| Step: 3
Training loss: 0.8160620150749085
Validation loss: 2.343840623422989

Epoch: 6| Step: 4
Training loss: 1.090184749729926
Validation loss: 2.230926826962114

Epoch: 6| Step: 5
Training loss: 1.3429120134459829
Validation loss: 2.3012416969482796

Epoch: 6| Step: 6
Training loss: 1.1984045887074901
Validation loss: 2.2452783966026386

Epoch: 6| Step: 7
Training loss: 1.218763106838076
Validation loss: 2.2697960963773514

Epoch: 6| Step: 8
Training loss: 1.364562954155944
Validation loss: 2.3045407295246645

Epoch: 6| Step: 9
Training loss: 0.7820105093569331
Validation loss: 2.32575257517566

Epoch: 6| Step: 10
Training loss: 1.9934708594188917
Validation loss: 2.325207673138531

Epoch: 6| Step: 11
Training loss: 1.1421330555100169
Validation loss: 2.3257974145679663

Epoch: 6| Step: 12
Training loss: 1.0372606300072265
Validation loss: 2.355592379979028

Epoch: 6| Step: 13
Training loss: 0.928147876341978
Validation loss: 2.3648185051066264

Epoch: 409| Step: 0
Training loss: 1.3089685159631517
Validation loss: 2.3229503131601805

Epoch: 6| Step: 1
Training loss: 1.352080758459209
Validation loss: 2.345012176723094

Epoch: 6| Step: 2
Training loss: 1.246956075456077
Validation loss: 2.3182724940228168

Epoch: 6| Step: 3
Training loss: 1.2602132312546834
Validation loss: 2.368904393549578

Epoch: 6| Step: 4
Training loss: 1.1828725902859756
Validation loss: 2.3228534386566912

Epoch: 6| Step: 5
Training loss: 1.0533601673748225
Validation loss: 2.2438691675804154

Epoch: 6| Step: 6
Training loss: 0.8931186299934424
Validation loss: 2.2051960224684897

Epoch: 6| Step: 7
Training loss: 1.191116247684006
Validation loss: 2.2950657062408233

Epoch: 6| Step: 8
Training loss: 1.8460583218901359
Validation loss: 2.3101405984147605

Epoch: 6| Step: 9
Training loss: 1.2533681314960607
Validation loss: 2.2325288233447576

Epoch: 6| Step: 10
Training loss: 1.1009706571135365
Validation loss: 2.2780887554006575

Epoch: 6| Step: 11
Training loss: 1.139198508600132
Validation loss: 2.312253027013502

Epoch: 6| Step: 12
Training loss: 0.9174836520575763
Validation loss: 2.2143651885072937

Epoch: 6| Step: 13
Training loss: 0.7878010552803326
Validation loss: 2.270892662258502

Epoch: 410| Step: 0
Training loss: 1.1893897830527524
Validation loss: 2.305701555620784

Epoch: 6| Step: 1
Training loss: 1.1923855118404643
Validation loss: 2.314867094696048

Epoch: 6| Step: 2
Training loss: 1.170915032429055
Validation loss: 2.2895433166686083

Epoch: 6| Step: 3
Training loss: 1.133816083771728
Validation loss: 2.3215075215294205

Epoch: 6| Step: 4
Training loss: 1.0899858279575545
Validation loss: 2.2837957510671667

Epoch: 6| Step: 5
Training loss: 1.4819854777521642
Validation loss: 2.333407074192286

Epoch: 6| Step: 6
Training loss: 0.9510186794604556
Validation loss: 2.402060363473008

Epoch: 6| Step: 7
Training loss: 0.7466589100326958
Validation loss: 2.2585581119507308

Epoch: 6| Step: 8
Training loss: 1.9012231052159252
Validation loss: 2.255058226929925

Epoch: 6| Step: 9
Training loss: 1.50231945000336
Validation loss: 2.280312386903176

Epoch: 6| Step: 10
Training loss: 0.8018196258692142
Validation loss: 2.233725503516943

Epoch: 6| Step: 11
Training loss: 0.9430874892776907
Validation loss: 2.318077289396646

Epoch: 6| Step: 12
Training loss: 1.137281979637634
Validation loss: 2.3375206422226102

Epoch: 6| Step: 13
Training loss: 1.0736950516768535
Validation loss: 2.3379876324854867

Epoch: 411| Step: 0
Training loss: 1.08015609928827
Validation loss: 2.220387139190537

Epoch: 6| Step: 1
Training loss: 1.166844161473552
Validation loss: 2.313296810739654

Epoch: 6| Step: 2
Training loss: 1.2666729485623707
Validation loss: 2.305596224091803

Epoch: 6| Step: 3
Training loss: 1.0171101202296553
Validation loss: 2.3487946689971633

Epoch: 6| Step: 4
Training loss: 1.3438855479872038
Validation loss: 2.384858661848497

Epoch: 6| Step: 5
Training loss: 1.2707009428927862
Validation loss: 2.328758212546399

Epoch: 6| Step: 6
Training loss: 1.0653216537122603
Validation loss: 2.3728328860707064

Epoch: 6| Step: 7
Training loss: 1.896560431702574
Validation loss: 2.2914512708310886

Epoch: 6| Step: 8
Training loss: 0.7954680045339239
Validation loss: 2.2421365601856333

Epoch: 6| Step: 9
Training loss: 0.853577810156453
Validation loss: 2.345918904268325

Epoch: 6| Step: 10
Training loss: 1.1694148370755715
Validation loss: 2.2321794667325463

Epoch: 6| Step: 11
Training loss: 0.9650342498393708
Validation loss: 2.344900396627974

Epoch: 6| Step: 12
Training loss: 0.6537408088490205
Validation loss: 2.216002147384393

Epoch: 6| Step: 13
Training loss: 0.5150790069216111
Validation loss: 2.2849979984952067

Epoch: 412| Step: 0
Training loss: 1.0152623042469693
Validation loss: 2.242055478517776

Epoch: 6| Step: 1
Training loss: 1.031602279141095
Validation loss: 2.310865741009901

Epoch: 6| Step: 2
Training loss: 1.1702683688757207
Validation loss: 2.3111863755118947

Epoch: 6| Step: 3
Training loss: 1.577400721163057
Validation loss: 2.3245298887943155

Epoch: 6| Step: 4
Training loss: 1.1427943880869353
Validation loss: 2.3151172808423564

Epoch: 6| Step: 5
Training loss: 1.0156278170033048
Validation loss: 2.323781879882009

Epoch: 6| Step: 6
Training loss: 0.8998423332286664
Validation loss: 2.277156119306409

Epoch: 6| Step: 7
Training loss: 0.792679795107819
Validation loss: 2.2982260407079242

Epoch: 6| Step: 8
Training loss: 1.0241187936526568
Validation loss: 2.2274189391227153

Epoch: 6| Step: 9
Training loss: 1.5371302369385194
Validation loss: 2.313064649823097

Epoch: 6| Step: 10
Training loss: 1.8266422094438806
Validation loss: 2.270023175086433

Epoch: 6| Step: 11
Training loss: 1.0150792929960377
Validation loss: 2.3227492436334805

Epoch: 6| Step: 12
Training loss: 1.0036487768684672
Validation loss: 2.3209184678674397

Epoch: 6| Step: 13
Training loss: 0.9444235728488278
Validation loss: 2.3136504403795266

Epoch: 413| Step: 0
Training loss: 1.1723803638514916
Validation loss: 2.2618327685101867

Epoch: 6| Step: 1
Training loss: 0.8687554009358868
Validation loss: 2.28917018031356

Epoch: 6| Step: 2
Training loss: 1.72511202959799
Validation loss: 2.2394298133592585

Epoch: 6| Step: 3
Training loss: 0.8355678561065573
Validation loss: 2.300908659603336

Epoch: 6| Step: 4
Training loss: 1.9252916684824737
Validation loss: 2.2829963112302023

Epoch: 6| Step: 5
Training loss: 1.2727384930586711
Validation loss: 2.2737972063898653

Epoch: 6| Step: 6
Training loss: 1.1786086852720274
Validation loss: 2.2460409515438555

Epoch: 6| Step: 7
Training loss: 1.0525005130358824
Validation loss: 2.33128476271883

Epoch: 6| Step: 8
Training loss: 1.164268014674674
Validation loss: 2.251080036158527

Epoch: 6| Step: 9
Training loss: 0.7555148500186034
Validation loss: 2.325087536987589

Epoch: 6| Step: 10
Training loss: 0.6206696699956201
Validation loss: 2.319665687111909

Epoch: 6| Step: 11
Training loss: 1.1424780646958423
Validation loss: 2.2364513228047533

Epoch: 6| Step: 12
Training loss: 0.9459325790151251
Validation loss: 2.2996911615089393

Epoch: 6| Step: 13
Training loss: 1.1183644743978658
Validation loss: 2.3163321763578892

Epoch: 414| Step: 0
Training loss: 1.1222654061826765
Validation loss: 2.344758612072672

Epoch: 6| Step: 1
Training loss: 1.4837146293968413
Validation loss: 2.3531367653338795

Epoch: 6| Step: 2
Training loss: 0.8335999221358747
Validation loss: 2.250346452207237

Epoch: 6| Step: 3
Training loss: 0.9337258345248584
Validation loss: 2.2771590430279756

Epoch: 6| Step: 4
Training loss: 0.9085669988366127
Validation loss: 2.3070129753623494

Epoch: 6| Step: 5
Training loss: 1.0659438028319779
Validation loss: 2.318535180502325

Epoch: 6| Step: 6
Training loss: 1.7838905572079877
Validation loss: 2.3185759744166594

Epoch: 6| Step: 7
Training loss: 1.25685291530758
Validation loss: 2.316012204442077

Epoch: 6| Step: 8
Training loss: 0.8145563805715488
Validation loss: 2.308307868826244

Epoch: 6| Step: 9
Training loss: 1.1421759525242414
Validation loss: 2.2916545013671636

Epoch: 6| Step: 10
Training loss: 0.9699825936161612
Validation loss: 2.293446010212661

Epoch: 6| Step: 11
Training loss: 1.3645635220009222
Validation loss: 2.3257692163027617

Epoch: 6| Step: 12
Training loss: 1.0063699852151935
Validation loss: 2.284732370019193

Epoch: 6| Step: 13
Training loss: 1.7392262836663601
Validation loss: 2.3049838034661576

Epoch: 415| Step: 0
Training loss: 1.0280445450026494
Validation loss: 2.330200519968844

Epoch: 6| Step: 1
Training loss: 1.3587662660244533
Validation loss: 2.3265354962702807

Epoch: 6| Step: 2
Training loss: 0.9774296382058814
Validation loss: 2.3051912917091313

Epoch: 6| Step: 3
Training loss: 1.346439597434127
Validation loss: 2.342503782538005

Epoch: 6| Step: 4
Training loss: 1.0783487723501621
Validation loss: 2.275556983589531

Epoch: 6| Step: 5
Training loss: 0.871040239957164
Validation loss: 2.284799523526444

Epoch: 6| Step: 6
Training loss: 0.9100518883070148
Validation loss: 2.3262790476050843

Epoch: 6| Step: 7
Training loss: 1.1730683925914995
Validation loss: 2.247404255034484

Epoch: 6| Step: 8
Training loss: 1.2451550047872173
Validation loss: 2.2585930755015258

Epoch: 6| Step: 9
Training loss: 1.4209203344801167
Validation loss: 2.24937516883061

Epoch: 6| Step: 10
Training loss: 0.8577441606937133
Validation loss: 2.3064508015377134

Epoch: 6| Step: 11
Training loss: 0.8513946717795173
Validation loss: 2.2750238842607975

Epoch: 6| Step: 12
Training loss: 2.0672249280982538
Validation loss: 2.270915406922705

Epoch: 6| Step: 13
Training loss: 1.0222900014557592
Validation loss: 2.3609793666282632

Epoch: 416| Step: 0
Training loss: 1.9396045084069569
Validation loss: 2.3433840733291915

Epoch: 6| Step: 1
Training loss: 0.9616212350723784
Validation loss: 2.379814450505789

Epoch: 6| Step: 2
Training loss: 0.78955919854579
Validation loss: 2.37911005172778

Epoch: 6| Step: 3
Training loss: 1.1936763960431065
Validation loss: 2.355956159095575

Epoch: 6| Step: 4
Training loss: 1.6068425670008037
Validation loss: 2.33943915099038

Epoch: 6| Step: 5
Training loss: 1.0601901583776263
Validation loss: 2.3151597511267195

Epoch: 6| Step: 6
Training loss: 1.0244556633109032
Validation loss: 2.3302843312946977

Epoch: 6| Step: 7
Training loss: 1.4268349294428897
Validation loss: 2.303179766604798

Epoch: 6| Step: 8
Training loss: 1.1071430373301556
Validation loss: 2.285046509732784

Epoch: 6| Step: 9
Training loss: 1.0917495962971613
Validation loss: 2.284979116093473

Epoch: 6| Step: 10
Training loss: 1.039433807342633
Validation loss: 2.270266630868502

Epoch: 6| Step: 11
Training loss: 0.91677714173413
Validation loss: 2.363041237793222

Epoch: 6| Step: 12
Training loss: 1.2939931263276774
Validation loss: 2.261979034713134

Epoch: 6| Step: 13
Training loss: 1.442334710870668
Validation loss: 2.2490920213908168

Epoch: 417| Step: 0
Training loss: 1.2272739169567777
Validation loss: 2.237770644686459

Epoch: 6| Step: 1
Training loss: 0.957515640678847
Validation loss: 2.3486679491013143

Epoch: 6| Step: 2
Training loss: 1.9567844136220125
Validation loss: 2.2826149636085127

Epoch: 6| Step: 3
Training loss: 1.0156938969645002
Validation loss: 2.305045533982723

Epoch: 6| Step: 4
Training loss: 0.9823779784571341
Validation loss: 2.269118764055509

Epoch: 6| Step: 5
Training loss: 1.3076937640945816
Validation loss: 2.3339174904724005

Epoch: 6| Step: 6
Training loss: 0.7237317716447548
Validation loss: 2.32088102560965

Epoch: 6| Step: 7
Training loss: 1.2746076765642416
Validation loss: 2.265190375892184

Epoch: 6| Step: 8
Training loss: 0.9669681281801059
Validation loss: 2.3725021030708846

Epoch: 6| Step: 9
Training loss: 1.195826251754439
Validation loss: 2.3449753673374034

Epoch: 6| Step: 10
Training loss: 1.112421500190325
Validation loss: 2.314867325049327

Epoch: 6| Step: 11
Training loss: 0.6235727464641377
Validation loss: 2.325844953586755

Epoch: 6| Step: 12
Training loss: 1.2362124131277334
Validation loss: 2.254959451550823

Epoch: 6| Step: 13
Training loss: 1.1210438787021069
Validation loss: 2.291822107884732

Epoch: 418| Step: 0
Training loss: 1.0277901611498552
Validation loss: 2.30990381462939

Epoch: 6| Step: 1
Training loss: 0.8822049776535728
Validation loss: 2.2584296049287165

Epoch: 6| Step: 2
Training loss: 1.1119413644885272
Validation loss: 2.2591304209088623

Epoch: 6| Step: 3
Training loss: 0.8669088792403159
Validation loss: 2.3478453183654695

Epoch: 6| Step: 4
Training loss: 1.0371569031710435
Validation loss: 2.249420172771402

Epoch: 6| Step: 5
Training loss: 0.9310758146174027
Validation loss: 2.3209599566343155

Epoch: 6| Step: 6
Training loss: 1.9589709873825947
Validation loss: 2.350574668991109

Epoch: 6| Step: 7
Training loss: 1.3686867041736848
Validation loss: 2.228969709795844

Epoch: 6| Step: 8
Training loss: 0.7940322058917872
Validation loss: 2.250934562836709

Epoch: 6| Step: 9
Training loss: 1.2028947089613322
Validation loss: 2.36695486500217

Epoch: 6| Step: 10
Training loss: 1.0696955663993728
Validation loss: 2.321662350814244

Epoch: 6| Step: 11
Training loss: 0.9186348628865428
Validation loss: 2.2444157304288908

Epoch: 6| Step: 12
Training loss: 1.3448940109127518
Validation loss: 2.3902444940810157

Epoch: 6| Step: 13
Training loss: 0.9555955043255046
Validation loss: 2.218870489282586

Epoch: 419| Step: 0
Training loss: 1.2586875383322234
Validation loss: 2.358882181894525

Epoch: 6| Step: 1
Training loss: 1.0629272723793466
Validation loss: 2.2778644418557707

Epoch: 6| Step: 2
Training loss: 1.1471173750129406
Validation loss: 2.2790714143303368

Epoch: 6| Step: 3
Training loss: 2.0897017100897677
Validation loss: 2.36705784845522

Epoch: 6| Step: 4
Training loss: 1.165684127330682
Validation loss: 2.302704868668431

Epoch: 6| Step: 5
Training loss: 0.9400309413525032
Validation loss: 2.310296059092688

Epoch: 6| Step: 6
Training loss: 1.348602581859314
Validation loss: 2.2723899000427514

Epoch: 6| Step: 7
Training loss: 1.2065781418765316
Validation loss: 2.302282372005507

Epoch: 6| Step: 8
Training loss: 1.0834788200304564
Validation loss: 2.3256794165158574

Epoch: 6| Step: 9
Training loss: 1.136973139557159
Validation loss: 2.3062874600740533

Epoch: 6| Step: 10
Training loss: 0.8687054519758008
Validation loss: 2.279195959013145

Epoch: 6| Step: 11
Training loss: 0.9100776933159314
Validation loss: 2.3302223028862707

Epoch: 6| Step: 12
Training loss: 1.048011618244038
Validation loss: 2.2688973045343532

Epoch: 6| Step: 13
Training loss: 0.7027892264672096
Validation loss: 2.3031305075032904

Epoch: 420| Step: 0
Training loss: 0.7637301761782822
Validation loss: 2.3236231664604308

Epoch: 6| Step: 1
Training loss: 0.808590801436351
Validation loss: 2.332444649837026

Epoch: 6| Step: 2
Training loss: 1.0923868676800401
Validation loss: 2.309794589749263

Epoch: 6| Step: 3
Training loss: 1.2560120010774523
Validation loss: 2.3042832887920772

Epoch: 6| Step: 4
Training loss: 1.0806579688951978
Validation loss: 2.2953712748426476

Epoch: 6| Step: 5
Training loss: 1.224139499107494
Validation loss: 2.314486972804847

Epoch: 6| Step: 6
Training loss: 1.038307661491284
Validation loss: 2.2637056304677907

Epoch: 6| Step: 7
Training loss: 0.9717259995048545
Validation loss: 2.3033019224935884

Epoch: 6| Step: 8
Training loss: 1.8758579198761653
Validation loss: 2.3129259752041573

Epoch: 6| Step: 9
Training loss: 1.5387528780949788
Validation loss: 2.3143137540123915

Epoch: 6| Step: 10
Training loss: 1.0200948509357846
Validation loss: 2.2740523974078983

Epoch: 6| Step: 11
Training loss: 1.1145818240907142
Validation loss: 2.3074567100543706

Epoch: 6| Step: 12
Training loss: 0.7435002011656088
Validation loss: 2.2362197659858296

Epoch: 6| Step: 13
Training loss: 1.0847590796905409
Validation loss: 2.2188254850061364

Epoch: 421| Step: 0
Training loss: 0.898366311611562
Validation loss: 2.254727479971951

Epoch: 6| Step: 1
Training loss: 1.2323603546699347
Validation loss: 2.2349222678877836

Epoch: 6| Step: 2
Training loss: 1.8741644587093162
Validation loss: 2.3205513371167066

Epoch: 6| Step: 3
Training loss: 1.3225957326005973
Validation loss: 2.283583159986618

Epoch: 6| Step: 4
Training loss: 0.8164273492012273
Validation loss: 2.346781861446669

Epoch: 6| Step: 5
Training loss: 1.07803178467187
Validation loss: 2.3098083513563297

Epoch: 6| Step: 6
Training loss: 0.7877787732384219
Validation loss: 2.3564122969460355

Epoch: 6| Step: 7
Training loss: 1.0001866047321286
Validation loss: 2.291168764193936

Epoch: 6| Step: 8
Training loss: 1.143176895139964
Validation loss: 2.348540161343778

Epoch: 6| Step: 9
Training loss: 1.0656531612668838
Validation loss: 2.367398872903307

Epoch: 6| Step: 10
Training loss: 0.8870271658925171
Validation loss: 2.2816736971581464

Epoch: 6| Step: 11
Training loss: 1.2182783534685953
Validation loss: 2.3132595753729905

Epoch: 6| Step: 12
Training loss: 0.7832444862612418
Validation loss: 2.3208696355189957

Epoch: 6| Step: 13
Training loss: 1.1293220150398044
Validation loss: 2.2805914429063354

Epoch: 422| Step: 0
Training loss: 1.1119643068176854
Validation loss: 2.254557047570754

Epoch: 6| Step: 1
Training loss: 2.1012830583920854
Validation loss: 2.3416656884614806

Epoch: 6| Step: 2
Training loss: 0.9270091866549324
Validation loss: 2.2785790214529444

Epoch: 6| Step: 3
Training loss: 1.068735227426973
Validation loss: 2.3690335274111254

Epoch: 6| Step: 4
Training loss: 1.1356724908752354
Validation loss: 2.369554183799912

Epoch: 6| Step: 5
Training loss: 1.3319631430478345
Validation loss: 2.3083700363124677

Epoch: 6| Step: 6
Training loss: 0.9910496472453102
Validation loss: 2.4196509971652334

Epoch: 6| Step: 7
Training loss: 0.8445244519774385
Validation loss: 2.3667674872986497

Epoch: 6| Step: 8
Training loss: 1.2000064809942073
Validation loss: 2.3455908980222304

Epoch: 6| Step: 9
Training loss: 0.9518515412513874
Validation loss: 2.3358557817108303

Epoch: 6| Step: 10
Training loss: 1.0052653808745242
Validation loss: 2.297197710038148

Epoch: 6| Step: 11
Training loss: 0.7772219001694216
Validation loss: 2.290176220902297

Epoch: 6| Step: 12
Training loss: 1.1908046516788902
Validation loss: 2.287688739641824

Epoch: 6| Step: 13
Training loss: 1.0570594394756592
Validation loss: 2.2648715533378114

Epoch: 423| Step: 0
Training loss: 0.9984331969644535
Validation loss: 2.2877659135258064

Epoch: 6| Step: 1
Training loss: 0.9789133082300533
Validation loss: 2.247133134253962

Epoch: 6| Step: 2
Training loss: 1.2349579315897063
Validation loss: 2.3086501143564773

Epoch: 6| Step: 3
Training loss: 1.9065148841803135
Validation loss: 2.335930748852695

Epoch: 6| Step: 4
Training loss: 0.8456684836677736
Validation loss: 2.3551967867020758

Epoch: 6| Step: 5
Training loss: 1.1814693106056866
Validation loss: 2.2956126649845783

Epoch: 6| Step: 6
Training loss: 1.0360910477341971
Validation loss: 2.28461305556733

Epoch: 6| Step: 7
Training loss: 1.0276579285814271
Validation loss: 2.264965970572117

Epoch: 6| Step: 8
Training loss: 0.9271192900867692
Validation loss: 2.32310169207252

Epoch: 6| Step: 9
Training loss: 1.4413573714241772
Validation loss: 2.342288462197209

Epoch: 6| Step: 10
Training loss: 0.961932806616628
Validation loss: 2.3274691067240676

Epoch: 6| Step: 11
Training loss: 1.0749169872080484
Validation loss: 2.2869739259948965

Epoch: 6| Step: 12
Training loss: 1.1448762653575826
Validation loss: 2.3296241137429985

Epoch: 6| Step: 13
Training loss: 0.5846228538018668
Validation loss: 2.3210503311175397

Epoch: 424| Step: 0
Training loss: 1.200084212447713
Validation loss: 2.3721490608293694

Epoch: 6| Step: 1
Training loss: 1.3564762471724547
Validation loss: 2.3481426048158744

Epoch: 6| Step: 2
Training loss: 1.9190903625801274
Validation loss: 2.2485387358532813

Epoch: 6| Step: 3
Training loss: 1.2756029685406072
Validation loss: 2.2784899170207447

Epoch: 6| Step: 4
Training loss: 1.1074805942152737
Validation loss: 2.2505901410454974

Epoch: 6| Step: 5
Training loss: 1.3389795035032077
Validation loss: 2.2939845756921766

Epoch: 6| Step: 6
Training loss: 0.9405117613094033
Validation loss: 2.3006990805511256

Epoch: 6| Step: 7
Training loss: 1.0479512162829834
Validation loss: 2.312143906456727

Epoch: 6| Step: 8
Training loss: 1.305526509311315
Validation loss: 2.3077769594926383

Epoch: 6| Step: 9
Training loss: 0.7417457872328329
Validation loss: 2.296773816072436

Epoch: 6| Step: 10
Training loss: 0.916336881673952
Validation loss: 2.2946277211534194

Epoch: 6| Step: 11
Training loss: 1.06248973392688
Validation loss: 2.2451810464585327

Epoch: 6| Step: 12
Training loss: 0.9598800299108187
Validation loss: 2.2802563496721215

Epoch: 6| Step: 13
Training loss: 1.0561068556359439
Validation loss: 2.243403892548704

Epoch: 425| Step: 0
Training loss: 0.8177856036243107
Validation loss: 2.324283795899863

Epoch: 6| Step: 1
Training loss: 0.9640946047489987
Validation loss: 2.349538265258282

Epoch: 6| Step: 2
Training loss: 1.7535565883706645
Validation loss: 2.3199908360645747

Epoch: 6| Step: 3
Training loss: 0.987767564764625
Validation loss: 2.345246233509538

Epoch: 6| Step: 4
Training loss: 1.2387576465389933
Validation loss: 2.265024019334143

Epoch: 6| Step: 5
Training loss: 1.2151144529523972
Validation loss: 2.2984588616700354

Epoch: 6| Step: 6
Training loss: 0.9542749378182839
Validation loss: 2.305553112291482

Epoch: 6| Step: 7
Training loss: 1.3101200141968372
Validation loss: 2.283687932404121

Epoch: 6| Step: 8
Training loss: 1.2993760408853285
Validation loss: 2.275901797081773

Epoch: 6| Step: 9
Training loss: 1.0408799188561115
Validation loss: 2.2906754939054976

Epoch: 6| Step: 10
Training loss: 1.0011696531559122
Validation loss: 2.3142192306497615

Epoch: 6| Step: 11
Training loss: 0.9199467552367926
Validation loss: 2.3284700882169096

Epoch: 6| Step: 12
Training loss: 1.1484448698676686
Validation loss: 2.3294884999361005

Epoch: 6| Step: 13
Training loss: 0.9518440581694778
Validation loss: 2.2888742574099408

Epoch: 426| Step: 0
Training loss: 0.975066358802309
Validation loss: 2.3473012914962217

Epoch: 6| Step: 1
Training loss: 0.9840766818011047
Validation loss: 2.31776680471053

Epoch: 6| Step: 2
Training loss: 1.0442056928883139
Validation loss: 2.325668630299317

Epoch: 6| Step: 3
Training loss: 1.1501180069956143
Validation loss: 2.2796710600734573

Epoch: 6| Step: 4
Training loss: 0.9921954297327068
Validation loss: 2.3053565760036467

Epoch: 6| Step: 5
Training loss: 1.0589013585302307
Validation loss: 2.3703793144728507

Epoch: 6| Step: 6
Training loss: 1.1707851173726975
Validation loss: 2.39219729532027

Epoch: 6| Step: 7
Training loss: 0.7517026013273369
Validation loss: 2.2527415437411342

Epoch: 6| Step: 8
Training loss: 2.1042998117554226
Validation loss: 2.2364154279008748

Epoch: 6| Step: 9
Training loss: 0.9574823678686506
Validation loss: 2.373950653034231

Epoch: 6| Step: 10
Training loss: 0.8597896615896901
Validation loss: 2.2854164701081006

Epoch: 6| Step: 11
Training loss: 1.1437634180668106
Validation loss: 2.2549992673575443

Epoch: 6| Step: 12
Training loss: 0.9241945858502708
Validation loss: 2.218081885429295

Epoch: 6| Step: 13
Training loss: 0.7155887078157096
Validation loss: 2.2945631238946573

Epoch: 427| Step: 0
Training loss: 0.9814021010873715
Validation loss: 2.240301347825338

Epoch: 6| Step: 1
Training loss: 0.9131305867258563
Validation loss: 2.255385194251137

Epoch: 6| Step: 2
Training loss: 0.7985522999508773
Validation loss: 2.258714867654982

Epoch: 6| Step: 3
Training loss: 1.0683046985980316
Validation loss: 2.218622324423127

Epoch: 6| Step: 4
Training loss: 0.8071784565618745
Validation loss: 2.3330225102078797

Epoch: 6| Step: 5
Training loss: 0.9951812453985881
Validation loss: 2.347364091789732

Epoch: 6| Step: 6
Training loss: 1.3141246005340437
Validation loss: 2.3150017389233235

Epoch: 6| Step: 7
Training loss: 0.9732715238635443
Validation loss: 2.183547347666496

Epoch: 6| Step: 8
Training loss: 1.4684846516613366
Validation loss: 2.3088374824289652

Epoch: 6| Step: 9
Training loss: 0.9613846149611045
Validation loss: 2.2367421017584714

Epoch: 6| Step: 10
Training loss: 1.4023419648480542
Validation loss: 2.237473538672449

Epoch: 6| Step: 11
Training loss: 0.9761678890224743
Validation loss: 2.243718779798558

Epoch: 6| Step: 12
Training loss: 2.066950418107388
Validation loss: 2.2897713438039005

Epoch: 6| Step: 13
Training loss: 0.5721015825252719
Validation loss: 2.272792464027008

Epoch: 428| Step: 0
Training loss: 1.0364518604683473
Validation loss: 2.347944963600255

Epoch: 6| Step: 1
Training loss: 1.283339169517887
Validation loss: 2.3622716138413162

Epoch: 6| Step: 2
Training loss: 0.8618232878067147
Validation loss: 2.3641549743758565

Epoch: 6| Step: 3
Training loss: 0.9436773550103575
Validation loss: 2.4085427952309213

Epoch: 6| Step: 4
Training loss: 1.208543934501296
Validation loss: 2.355201466175233

Epoch: 6| Step: 5
Training loss: 1.0647861344779588
Validation loss: 2.338695286387211

Epoch: 6| Step: 6
Training loss: 0.8701199275700403
Validation loss: 2.260376406801084

Epoch: 6| Step: 7
Training loss: 1.0095843921697283
Validation loss: 2.2684052841896736

Epoch: 6| Step: 8
Training loss: 1.2202316472307388
Validation loss: 2.275284451940434

Epoch: 6| Step: 9
Training loss: 1.138611309344855
Validation loss: 2.3213635732247804

Epoch: 6| Step: 10
Training loss: 1.3794857028774743
Validation loss: 2.1992603419666605

Epoch: 6| Step: 11
Training loss: 1.2748871024019537
Validation loss: 2.264077417504311

Epoch: 6| Step: 12
Training loss: 0.9052757419528045
Validation loss: 2.253323984637633

Epoch: 6| Step: 13
Training loss: 2.2494183954248665
Validation loss: 2.2089156611450624

Epoch: 429| Step: 0
Training loss: 1.1373057209988273
Validation loss: 2.2767491157163655

Epoch: 6| Step: 1
Training loss: 1.1183671392077346
Validation loss: 2.2906374090111217

Epoch: 6| Step: 2
Training loss: 1.054307205019558
Validation loss: 2.23315447237409

Epoch: 6| Step: 3
Training loss: 0.8508078704956872
Validation loss: 2.3437964491531287

Epoch: 6| Step: 4
Training loss: 0.9151132201411104
Validation loss: 2.2871857714935353

Epoch: 6| Step: 5
Training loss: 0.9424252515338809
Validation loss: 2.2513756096117077

Epoch: 6| Step: 6
Training loss: 1.2512437354968524
Validation loss: 2.274054090678821

Epoch: 6| Step: 7
Training loss: 1.3630911358418394
Validation loss: 2.359453624427709

Epoch: 6| Step: 8
Training loss: 1.15966771175984
Validation loss: 2.3188996145365266

Epoch: 6| Step: 9
Training loss: 0.6303082116377828
Validation loss: 2.3567210662940914

Epoch: 6| Step: 10
Training loss: 0.9544985520205498
Validation loss: 2.2149716109741693

Epoch: 6| Step: 11
Training loss: 1.0645382348428745
Validation loss: 2.2669987899225044

Epoch: 6| Step: 12
Training loss: 1.0061303227497451
Validation loss: 2.2361927573816742

Epoch: 6| Step: 13
Training loss: 2.400207462880691
Validation loss: 2.3054453292635984

Epoch: 430| Step: 0
Training loss: 1.0282876207855423
Validation loss: 2.2751876803222015

Epoch: 6| Step: 1
Training loss: 0.828402130972066
Validation loss: 2.245800976747784

Epoch: 6| Step: 2
Training loss: 0.9421507554615095
Validation loss: 2.33344142325791

Epoch: 6| Step: 3
Training loss: 0.9807464084875511
Validation loss: 2.267969642584077

Epoch: 6| Step: 4
Training loss: 1.4504107485442865
Validation loss: 2.2741664885810193

Epoch: 6| Step: 5
Training loss: 0.9122260792994401
Validation loss: 2.267275188414157

Epoch: 6| Step: 6
Training loss: 1.0943889931176853
Validation loss: 2.311152423906019

Epoch: 6| Step: 7
Training loss: 1.100150860931846
Validation loss: 2.2602241893115567

Epoch: 6| Step: 8
Training loss: 1.0125393871605453
Validation loss: 2.327693710135909

Epoch: 6| Step: 9
Training loss: 1.9598661132743378
Validation loss: 2.3110037122584193

Epoch: 6| Step: 10
Training loss: 0.7947655976412742
Validation loss: 2.306373170225372

Epoch: 6| Step: 11
Training loss: 0.595288992590363
Validation loss: 2.3000375721427595

Epoch: 6| Step: 12
Training loss: 0.847255559345285
Validation loss: 2.2791281314120817

Epoch: 6| Step: 13
Training loss: 1.440183042972533
Validation loss: 2.2339305061232717

Epoch: 431| Step: 0
Training loss: 1.1687264934766646
Validation loss: 2.2989545890461325

Epoch: 6| Step: 1
Training loss: 0.8309979895717755
Validation loss: 2.26319685661498

Epoch: 6| Step: 2
Training loss: 2.1456122670294477
Validation loss: 2.2396320903380524

Epoch: 6| Step: 3
Training loss: 0.9836888419581513
Validation loss: 2.2967451649185278

Epoch: 6| Step: 4
Training loss: 0.7766670079974078
Validation loss: 2.304030658885571

Epoch: 6| Step: 5
Training loss: 0.9571682267548006
Validation loss: 2.3222564391016736

Epoch: 6| Step: 6
Training loss: 1.1741315351166457
Validation loss: 2.2204172010919905

Epoch: 6| Step: 7
Training loss: 0.9463908452743206
Validation loss: 2.253022671376209

Epoch: 6| Step: 8
Training loss: 1.1310083689729933
Validation loss: 2.321604919293853

Epoch: 6| Step: 9
Training loss: 0.6858160245904417
Validation loss: 2.2793844880173095

Epoch: 6| Step: 10
Training loss: 1.1924923308343816
Validation loss: 2.2721622319602943

Epoch: 6| Step: 11
Training loss: 1.3732513232111045
Validation loss: 2.2954167593673147

Epoch: 6| Step: 12
Training loss: 1.1068173866205027
Validation loss: 2.2128330188423555

Epoch: 6| Step: 13
Training loss: 0.6547131025820833
Validation loss: 2.2060661596519333

Epoch: 432| Step: 0
Training loss: 1.3371592506514633
Validation loss: 2.2299057269465896

Epoch: 6| Step: 1
Training loss: 0.5947776734887896
Validation loss: 2.2808914161217047

Epoch: 6| Step: 2
Training loss: 1.0026805832050107
Validation loss: 2.217914074307426

Epoch: 6| Step: 3
Training loss: 0.9207142132887273
Validation loss: 2.308005686328419

Epoch: 6| Step: 4
Training loss: 1.1321622889820786
Validation loss: 2.3410711367674804

Epoch: 6| Step: 5
Training loss: 1.8418071661587818
Validation loss: 2.2637255476111258

Epoch: 6| Step: 6
Training loss: 0.9330128734084827
Validation loss: 2.2311344204000045

Epoch: 6| Step: 7
Training loss: 1.00023034542255
Validation loss: 2.361399021928496

Epoch: 6| Step: 8
Training loss: 0.9308066804212535
Validation loss: 2.298263385784513

Epoch: 6| Step: 9
Training loss: 1.442204282917143
Validation loss: 2.265350783475046

Epoch: 6| Step: 10
Training loss: 1.345279887265991
Validation loss: 2.265104823215115

Epoch: 6| Step: 11
Training loss: 1.0192607067594683
Validation loss: 2.258020884100367

Epoch: 6| Step: 12
Training loss: 0.86914213373289
Validation loss: 2.280964791830021

Epoch: 6| Step: 13
Training loss: 0.7811845370522674
Validation loss: 2.295115667332637

Epoch: 433| Step: 0
Training loss: 2.121299888190542
Validation loss: 2.2668329285436473

Epoch: 6| Step: 1
Training loss: 0.9805325795100287
Validation loss: 2.3002156239038554

Epoch: 6| Step: 2
Training loss: 0.9920922181042559
Validation loss: 2.308916431001593

Epoch: 6| Step: 3
Training loss: 0.6090923534140679
Validation loss: 2.249163988456315

Epoch: 6| Step: 4
Training loss: 0.9811315841658003
Validation loss: 2.2848040257148456

Epoch: 6| Step: 5
Training loss: 0.6199097774601594
Validation loss: 2.2520403244829263

Epoch: 6| Step: 6
Training loss: 1.0360393284251521
Validation loss: 2.2491740148548796

Epoch: 6| Step: 7
Training loss: 1.1436807121593668
Validation loss: 2.2906418986061534

Epoch: 6| Step: 8
Training loss: 0.7619785354900201
Validation loss: 2.2766081090896284

Epoch: 6| Step: 9
Training loss: 1.0106073114454905
Validation loss: 2.230676942312606

Epoch: 6| Step: 10
Training loss: 1.079901737758631
Validation loss: 2.3070309351220546

Epoch: 6| Step: 11
Training loss: 1.3875939414724803
Validation loss: 2.2733600359262542

Epoch: 6| Step: 12
Training loss: 1.0765668694527903
Validation loss: 2.315125383293952

Epoch: 6| Step: 13
Training loss: 1.2240836004990598
Validation loss: 2.316240732334397

Epoch: 434| Step: 0
Training loss: 1.9854065624298838
Validation loss: 2.3383532031430128

Epoch: 6| Step: 1
Training loss: 0.5531137734690889
Validation loss: 2.275730788673734

Epoch: 6| Step: 2
Training loss: 1.2498961405522293
Validation loss: 2.2619348343043555

Epoch: 6| Step: 3
Training loss: 1.0931064347205919
Validation loss: 2.2816504850216535

Epoch: 6| Step: 4
Training loss: 1.0105545238298301
Validation loss: 2.2377924549433286

Epoch: 6| Step: 5
Training loss: 0.9109196551556036
Validation loss: 2.2898039691562198

Epoch: 6| Step: 6
Training loss: 1.254279583170548
Validation loss: 2.2701792531851117

Epoch: 6| Step: 7
Training loss: 0.8042683296640596
Validation loss: 2.296140005012308

Epoch: 6| Step: 8
Training loss: 0.8994308619219462
Validation loss: 2.2761769838226047

Epoch: 6| Step: 9
Training loss: 0.7843935854104356
Validation loss: 2.239772574768302

Epoch: 6| Step: 10
Training loss: 0.9761194673768063
Validation loss: 2.2706258155343453

Epoch: 6| Step: 11
Training loss: 1.3200710459576532
Validation loss: 2.288369897401317

Epoch: 6| Step: 12
Training loss: 1.0023541753974523
Validation loss: 2.333029769745854

Epoch: 6| Step: 13
Training loss: 1.2185017259512767
Validation loss: 2.307404590757086

Epoch: 435| Step: 0
Training loss: 0.7467835118909644
Validation loss: 2.289881034247462

Epoch: 6| Step: 1
Training loss: 1.3587243287750552
Validation loss: 2.348111915944858

Epoch: 6| Step: 2
Training loss: 1.3098598447473186
Validation loss: 2.357055014568191

Epoch: 6| Step: 3
Training loss: 1.1856573766652398
Validation loss: 2.302794661784248

Epoch: 6| Step: 4
Training loss: 1.0533129742220158
Validation loss: 2.3233008563400483

Epoch: 6| Step: 5
Training loss: 1.060052633598226
Validation loss: 2.2840691651406444

Epoch: 6| Step: 6
Training loss: 1.841806389469559
Validation loss: 2.3351944933083204

Epoch: 6| Step: 7
Training loss: 1.0483184655918751
Validation loss: 2.3299488390402585

Epoch: 6| Step: 8
Training loss: 0.9633149919996783
Validation loss: 2.2929563206678565

Epoch: 6| Step: 9
Training loss: 0.8966840799997239
Validation loss: 2.3032778497878477

Epoch: 6| Step: 10
Training loss: 0.7160708208968272
Validation loss: 2.279855466543528

Epoch: 6| Step: 11
Training loss: 0.8825419188531614
Validation loss: 2.338788613093011

Epoch: 6| Step: 12
Training loss: 0.9919543255127745
Validation loss: 2.337013096592571

Epoch: 6| Step: 13
Training loss: 0.3265350855038845
Validation loss: 2.2895253025902127

Epoch: 436| Step: 0
Training loss: 1.2062117377819348
Validation loss: 2.2945455659698797

Epoch: 6| Step: 1
Training loss: 1.189163949576154
Validation loss: 2.243565594981438

Epoch: 6| Step: 2
Training loss: 1.0877655888858297
Validation loss: 2.25619040371771

Epoch: 6| Step: 3
Training loss: 0.9755638509547088
Validation loss: 2.2068362006905606

Epoch: 6| Step: 4
Training loss: 1.011387951356958
Validation loss: 2.290219342875064

Epoch: 6| Step: 5
Training loss: 0.7474297350771933
Validation loss: 2.2545403549863323

Epoch: 6| Step: 6
Training loss: 0.9214397631458734
Validation loss: 2.3063438107652594

Epoch: 6| Step: 7
Training loss: 0.7746907878650543
Validation loss: 2.2563042059208955

Epoch: 6| Step: 8
Training loss: 1.1607578143666668
Validation loss: 2.327346023954845

Epoch: 6| Step: 9
Training loss: 1.1184414315507658
Validation loss: 2.233765942263782

Epoch: 6| Step: 10
Training loss: 0.783429272505381
Validation loss: 2.311975637516194

Epoch: 6| Step: 11
Training loss: 1.1487080780781371
Validation loss: 2.2398991992807447

Epoch: 6| Step: 12
Training loss: 1.8276660701790857
Validation loss: 2.2789530105391944

Epoch: 6| Step: 13
Training loss: 0.8808832271078598
Validation loss: 2.311999227130098

Epoch: 437| Step: 0
Training loss: 1.0995013927608757
Validation loss: 2.2955698302681116

Epoch: 6| Step: 1
Training loss: 0.8687172533628437
Validation loss: 2.2454769654109046

Epoch: 6| Step: 2
Training loss: 0.6926132055564745
Validation loss: 2.1886029862837777

Epoch: 6| Step: 3
Training loss: 1.1433376298458533
Validation loss: 2.2766882524121814

Epoch: 6| Step: 4
Training loss: 1.1535379719596082
Validation loss: 2.257013583158958

Epoch: 6| Step: 5
Training loss: 1.6452140930829815
Validation loss: 2.295082460404086

Epoch: 6| Step: 6
Training loss: 0.9418917152121428
Validation loss: 2.2724005476801272

Epoch: 6| Step: 7
Training loss: 1.0343112015425302
Validation loss: 2.3178465347224435

Epoch: 6| Step: 8
Training loss: 1.2819732857478325
Validation loss: 2.303602620899807

Epoch: 6| Step: 9
Training loss: 0.8399059183930716
Validation loss: 2.2486787030376747

Epoch: 6| Step: 10
Training loss: 0.9931005346934993
Validation loss: 2.2284205264897947

Epoch: 6| Step: 11
Training loss: 1.0226715949344714
Validation loss: 2.2752619227800714

Epoch: 6| Step: 12
Training loss: 1.1280313024945956
Validation loss: 2.3075801548920296

Epoch: 6| Step: 13
Training loss: 1.1335229684616948
Validation loss: 2.1951011567954306

Epoch: 438| Step: 0
Training loss: 1.0626842114696562
Validation loss: 2.2587981143744136

Epoch: 6| Step: 1
Training loss: 0.9184432406406691
Validation loss: 2.2642301113394088

Epoch: 6| Step: 2
Training loss: 1.0459019138196488
Validation loss: 2.305126826712778

Epoch: 6| Step: 3
Training loss: 0.8069249130164355
Validation loss: 2.358907043472852

Epoch: 6| Step: 4
Training loss: 0.8701706515583048
Validation loss: 2.2650146629746066

Epoch: 6| Step: 5
Training loss: 1.0711951966661617
Validation loss: 2.27800300908795

Epoch: 6| Step: 6
Training loss: 1.9406127536159992
Validation loss: 2.296676235375798

Epoch: 6| Step: 7
Training loss: 1.0168112063194794
Validation loss: 2.2930657774214995

Epoch: 6| Step: 8
Training loss: 1.2844527153764846
Validation loss: 2.2945732150318605

Epoch: 6| Step: 9
Training loss: 0.6125343293670712
Validation loss: 2.2674466355439145

Epoch: 6| Step: 10
Training loss: 0.9790430227631957
Validation loss: 2.258136611181626

Epoch: 6| Step: 11
Training loss: 1.0059935841327334
Validation loss: 2.277708024841855

Epoch: 6| Step: 12
Training loss: 1.008770864051122
Validation loss: 2.2636094307010155

Epoch: 6| Step: 13
Training loss: 1.1728035363521316
Validation loss: 2.295395307054432

Epoch: 439| Step: 0
Training loss: 0.9346139991299562
Validation loss: 2.2654744891397796

Epoch: 6| Step: 1
Training loss: 1.776236790950876
Validation loss: 2.2592123206876824

Epoch: 6| Step: 2
Training loss: 1.0295078705555818
Validation loss: 2.3347226663677603

Epoch: 6| Step: 3
Training loss: 1.211833105833742
Validation loss: 2.25592003943052

Epoch: 6| Step: 4
Training loss: 1.0814702201125819
Validation loss: 2.244332099876209

Epoch: 6| Step: 5
Training loss: 0.6713155146901283
Validation loss: 2.2916662229237357

Epoch: 6| Step: 6
Training loss: 1.0245461319701685
Validation loss: 2.3564839836381832

Epoch: 6| Step: 7
Training loss: 1.274847548851191
Validation loss: 2.298976901638471

Epoch: 6| Step: 8
Training loss: 0.7012999053781496
Validation loss: 2.272781856576844

Epoch: 6| Step: 9
Training loss: 1.1226699860116753
Validation loss: 2.3431384277921814

Epoch: 6| Step: 10
Training loss: 0.916535089904281
Validation loss: 2.2389111455674904

Epoch: 6| Step: 11
Training loss: 1.2281825064282483
Validation loss: 2.2926627644633344

Epoch: 6| Step: 12
Training loss: 0.7391387964590332
Validation loss: 2.284177255374259

Epoch: 6| Step: 13
Training loss: 1.1653215396824081
Validation loss: 2.280905347617263

Epoch: 440| Step: 0
Training loss: 1.1624513267253882
Validation loss: 2.248235773104567

Epoch: 6| Step: 1
Training loss: 1.2917381492441757
Validation loss: 2.2852649989237377

Epoch: 6| Step: 2
Training loss: 1.9970499573955014
Validation loss: 2.1558025128208462

Epoch: 6| Step: 3
Training loss: 0.8032188716903622
Validation loss: 2.2662295577675797

Epoch: 6| Step: 4
Training loss: 0.7641957235133284
Validation loss: 2.2849183233487627

Epoch: 6| Step: 5
Training loss: 0.6542819348807357
Validation loss: 2.2552050791533187

Epoch: 6| Step: 6
Training loss: 1.0445670122459878
Validation loss: 2.2221414902166803

Epoch: 6| Step: 7
Training loss: 0.9805259535922697
Validation loss: 2.2602313299192023

Epoch: 6| Step: 8
Training loss: 0.851775466466576
Validation loss: 2.209950057468457

Epoch: 6| Step: 9
Training loss: 1.2412109375
Validation loss: 2.2877294986423515

Epoch: 6| Step: 10
Training loss: 1.1169747636893195
Validation loss: 2.3362302778785615

Epoch: 6| Step: 11
Training loss: 0.9184255559092045
Validation loss: 2.321170632042564

Epoch: 6| Step: 12
Training loss: 0.8982115088140655
Validation loss: 2.2874739909642083

Epoch: 6| Step: 13
Training loss: 0.59547950424617
Validation loss: 2.287498052349547

Epoch: 441| Step: 0
Training loss: 1.8739267456491147
Validation loss: 2.2604740086969812

Epoch: 6| Step: 1
Training loss: 1.0257611867623313
Validation loss: 2.290070132188155

Epoch: 6| Step: 2
Training loss: 1.1188280557861903
Validation loss: 2.3064820258348915

Epoch: 6| Step: 3
Training loss: 0.9565416290289399
Validation loss: 2.3526939837215117

Epoch: 6| Step: 4
Training loss: 1.1220009884447446
Validation loss: 2.334985169947726

Epoch: 6| Step: 5
Training loss: 1.2744738334582628
Validation loss: 2.3274805669549457

Epoch: 6| Step: 6
Training loss: 0.7721801324583198
Validation loss: 2.2345325389477595

Epoch: 6| Step: 7
Training loss: 0.6664238179474951
Validation loss: 2.386986680135002

Epoch: 6| Step: 8
Training loss: 1.2628656613177276
Validation loss: 2.3363698697143116

Epoch: 6| Step: 9
Training loss: 0.822918268194129
Validation loss: 2.274417529657856

Epoch: 6| Step: 10
Training loss: 1.0766924310461565
Validation loss: 2.2596061103498495

Epoch: 6| Step: 11
Training loss: 1.1912543027946203
Validation loss: 2.2505850344675387

Epoch: 6| Step: 12
Training loss: 1.2468298289594766
Validation loss: 2.285322076070894

Epoch: 6| Step: 13
Training loss: 1.006058164045118
Validation loss: 2.2510457200937117

Epoch: 442| Step: 0
Training loss: 1.1725865556209374
Validation loss: 2.289947653333049

Epoch: 6| Step: 1
Training loss: 0.8697465477546232
Validation loss: 2.253820524350045

Epoch: 6| Step: 2
Training loss: 0.8035733185094982
Validation loss: 2.243519593160489

Epoch: 6| Step: 3
Training loss: 0.8548085003269988
Validation loss: 2.239672994190128

Epoch: 6| Step: 4
Training loss: 1.9241737945918043
Validation loss: 2.3014625417949723

Epoch: 6| Step: 5
Training loss: 0.8865688382104709
Validation loss: 2.3048754393498148

Epoch: 6| Step: 6
Training loss: 1.1434579966361273
Validation loss: 2.2416382415176344

Epoch: 6| Step: 7
Training loss: 1.449886692487046
Validation loss: 2.2983116516039095

Epoch: 6| Step: 8
Training loss: 0.971781448326455
Validation loss: 2.3404617875223406

Epoch: 6| Step: 9
Training loss: 1.016065355350274
Validation loss: 2.1444385876962495

Epoch: 6| Step: 10
Training loss: 0.859422162235705
Validation loss: 2.232928175289189

Epoch: 6| Step: 11
Training loss: 0.7830180189609803
Validation loss: 2.3691425987446237

Epoch: 6| Step: 12
Training loss: 1.211188062771159
Validation loss: 2.3326588302543887

Epoch: 6| Step: 13
Training loss: 1.0985373222390082
Validation loss: 2.30662408371482

Epoch: 443| Step: 0
Training loss: 0.9341276868559242
Validation loss: 2.3562683925986314

Epoch: 6| Step: 1
Training loss: 1.3038882245737198
Validation loss: 2.3554503612357975

Epoch: 6| Step: 2
Training loss: 1.1441840468658953
Validation loss: 2.3509799076294624

Epoch: 6| Step: 3
Training loss: 1.035399786173854
Validation loss: 2.3044111845027455

Epoch: 6| Step: 4
Training loss: 0.7954542921734692
Validation loss: 2.303160850717946

Epoch: 6| Step: 5
Training loss: 0.7168475972453221
Validation loss: 2.2616006115203664

Epoch: 6| Step: 6
Training loss: 0.8101402641639465
Validation loss: 2.2827678434518845

Epoch: 6| Step: 7
Training loss: 1.2289421178163238
Validation loss: 2.237125160514563

Epoch: 6| Step: 8
Training loss: 1.0610446499409891
Validation loss: 2.2832231098180675

Epoch: 6| Step: 9
Training loss: 1.83149200506858
Validation loss: 2.2292666830174737

Epoch: 6| Step: 10
Training loss: 1.299741908276246
Validation loss: 2.29189821138159

Epoch: 6| Step: 11
Training loss: 1.1525149460690198
Validation loss: 2.303299359187575

Epoch: 6| Step: 12
Training loss: 0.8477776084550872
Validation loss: 2.2307207426993

Epoch: 6| Step: 13
Training loss: 0.6695691840198635
Validation loss: 2.227325200592407

Epoch: 444| Step: 0
Training loss: 1.0556869292627773
Validation loss: 2.2936871776889465

Epoch: 6| Step: 1
Training loss: 1.0456108317581012
Validation loss: 2.2221998443254423

Epoch: 6| Step: 2
Training loss: 0.5847080301730588
Validation loss: 2.3852078957735725

Epoch: 6| Step: 3
Training loss: 1.0451104395061654
Validation loss: 2.3197660311243213

Epoch: 6| Step: 4
Training loss: 1.463904321160106
Validation loss: 2.325443363864125

Epoch: 6| Step: 5
Training loss: 0.9061551866590581
Validation loss: 2.2627064476263383

Epoch: 6| Step: 6
Training loss: 1.072288082144728
Validation loss: 2.2797808330681684

Epoch: 6| Step: 7
Training loss: 0.9786630241558396
Validation loss: 2.2785193782940802

Epoch: 6| Step: 8
Training loss: 1.0798547662110418
Validation loss: 2.304130101640234

Epoch: 6| Step: 9
Training loss: 0.8536431677735757
Validation loss: 2.202921556376785

Epoch: 6| Step: 10
Training loss: 1.8578733262611031
Validation loss: 2.3476997057379894

Epoch: 6| Step: 11
Training loss: 0.7912680140850733
Validation loss: 2.2843784912732703

Epoch: 6| Step: 12
Training loss: 0.8256281513208837
Validation loss: 2.2394436370329287

Epoch: 6| Step: 13
Training loss: 1.0047283443139843
Validation loss: 2.2095927893744562

Epoch: 445| Step: 0
Training loss: 0.7718699590232658
Validation loss: 2.2283415343017827

Epoch: 6| Step: 1
Training loss: 0.9762376779127869
Validation loss: 2.2683135411920414

Epoch: 6| Step: 2
Training loss: 1.742306281860216
Validation loss: 2.2676927216544462

Epoch: 6| Step: 3
Training loss: 1.1006863403556806
Validation loss: 2.311890295303813

Epoch: 6| Step: 4
Training loss: 1.035685738513064
Validation loss: 2.231633664089419

Epoch: 6| Step: 5
Training loss: 1.1908727232974445
Validation loss: 2.287348403000212

Epoch: 6| Step: 6
Training loss: 1.0762388897365547
Validation loss: 2.338219390470035

Epoch: 6| Step: 7
Training loss: 1.2305836941755186
Validation loss: 2.201638738524265

Epoch: 6| Step: 8
Training loss: 0.6698955386131547
Validation loss: 2.285212572622134

Epoch: 6| Step: 9
Training loss: 1.072015896536977
Validation loss: 2.239868020814936

Epoch: 6| Step: 10
Training loss: 0.9867985878099682
Validation loss: 2.3324245391197445

Epoch: 6| Step: 11
Training loss: 0.9142580067797974
Validation loss: 2.3070814732822824

Epoch: 6| Step: 12
Training loss: 1.0406197373082426
Validation loss: 2.2581562232367354

Epoch: 6| Step: 13
Training loss: 0.9636205108276737
Validation loss: 2.2765652321009777

Epoch: 446| Step: 0
Training loss: 0.8954707380334967
Validation loss: 2.326856030714592

Epoch: 6| Step: 1
Training loss: 0.8742925986017599
Validation loss: 2.3254083514973907

Epoch: 6| Step: 2
Training loss: 0.9972549551465112
Validation loss: 2.310785833928608

Epoch: 6| Step: 3
Training loss: 1.1726123778734665
Validation loss: 2.258596917679324

Epoch: 6| Step: 4
Training loss: 0.9254990803586738
Validation loss: 2.29742454923202

Epoch: 6| Step: 5
Training loss: 0.7972948800699949
Validation loss: 2.3772927385906666

Epoch: 6| Step: 6
Training loss: 1.798693524521857
Validation loss: 2.276114439951294

Epoch: 6| Step: 7
Training loss: 1.2288482652335846
Validation loss: 2.249732041439991

Epoch: 6| Step: 8
Training loss: 0.6829735476522344
Validation loss: 2.2912263356776923

Epoch: 6| Step: 9
Training loss: 1.3182892053085347
Validation loss: 2.308878620342865

Epoch: 6| Step: 10
Training loss: 1.0018054042733604
Validation loss: 2.3383344314574135

Epoch: 6| Step: 11
Training loss: 0.9945099450022171
Validation loss: 2.235941480561092

Epoch: 6| Step: 12
Training loss: 0.9690888027741322
Validation loss: 2.3102843898899894

Epoch: 6| Step: 13
Training loss: 1.0487754993271399
Validation loss: 2.3357060204873097

Epoch: 447| Step: 0
Training loss: 0.7833744537098394
Validation loss: 2.3400976193377443

Epoch: 6| Step: 1
Training loss: 1.1015351204141144
Validation loss: 2.2916552184444496

Epoch: 6| Step: 2
Training loss: 0.7675060209230724
Validation loss: 2.221279924412854

Epoch: 6| Step: 3
Training loss: 0.7425270909848374
Validation loss: 2.319370275548725

Epoch: 6| Step: 4
Training loss: 0.8601471639737102
Validation loss: 2.2561323793629176

Epoch: 6| Step: 5
Training loss: 0.5864250697656488
Validation loss: 2.2802211415298617

Epoch: 6| Step: 6
Training loss: 2.0661445552923583
Validation loss: 2.3067177705292115

Epoch: 6| Step: 7
Training loss: 1.0104727713093595
Validation loss: 2.265395993436419

Epoch: 6| Step: 8
Training loss: 0.8989883724305108
Validation loss: 2.3610704025999385

Epoch: 6| Step: 9
Training loss: 1.03719569419941
Validation loss: 2.3080155654076386

Epoch: 6| Step: 10
Training loss: 1.0277082717578951
Validation loss: 2.3077513337967606

Epoch: 6| Step: 11
Training loss: 1.010800921074312
Validation loss: 2.301694126513197

Epoch: 6| Step: 12
Training loss: 0.9895951052852272
Validation loss: 2.3558787041838096

Epoch: 6| Step: 13
Training loss: 1.3165821897391203
Validation loss: 2.338740809922575

Epoch: 448| Step: 0
Training loss: 1.0029308166794701
Validation loss: 2.296968266352378

Epoch: 6| Step: 1
Training loss: 0.9557722568759267
Validation loss: 2.3226861812257815

Epoch: 6| Step: 2
Training loss: 1.131737508106157
Validation loss: 2.2389517517182114

Epoch: 6| Step: 3
Training loss: 0.8770943848615136
Validation loss: 2.299500992917499

Epoch: 6| Step: 4
Training loss: 0.9404143493605764
Validation loss: 2.284448997699961

Epoch: 6| Step: 5
Training loss: 1.1529767383071758
Validation loss: 2.3607901431225673

Epoch: 6| Step: 6
Training loss: 1.881472922262835
Validation loss: 2.2805427076258358

Epoch: 6| Step: 7
Training loss: 0.6497627182831626
Validation loss: 2.2173209793004367

Epoch: 6| Step: 8
Training loss: 0.864583134172409
Validation loss: 2.2456216478093722

Epoch: 6| Step: 9
Training loss: 1.2528288303375685
Validation loss: 2.3615573893999247

Epoch: 6| Step: 10
Training loss: 0.6116818023475528
Validation loss: 2.3028646477824983

Epoch: 6| Step: 11
Training loss: 0.8469771728254452
Validation loss: 2.282268289596545

Epoch: 6| Step: 12
Training loss: 0.5505278525240336
Validation loss: 2.339148499808642

Epoch: 6| Step: 13
Training loss: 1.268888105195318
Validation loss: 2.2241928343139774

Epoch: 449| Step: 0
Training loss: 0.7151445683464334
Validation loss: 2.3138024681708176

Epoch: 6| Step: 1
Training loss: 1.0709235681496412
Validation loss: 2.1977410708265133

Epoch: 6| Step: 2
Training loss: 0.9246975314004545
Validation loss: 2.2433653342560302

Epoch: 6| Step: 3
Training loss: 1.1778145884563405
Validation loss: 2.287758488504603

Epoch: 6| Step: 4
Training loss: 0.7391087975225267
Validation loss: 2.3060022318354236

Epoch: 6| Step: 5
Training loss: 0.8737537841824077
Validation loss: 2.2502035620884535

Epoch: 6| Step: 6
Training loss: 1.8666920024424012
Validation loss: 2.21436645159215

Epoch: 6| Step: 7
Training loss: 0.8598065766456803
Validation loss: 2.374761876040869

Epoch: 6| Step: 8
Training loss: 0.9445332239223455
Validation loss: 2.291460405690002

Epoch: 6| Step: 9
Training loss: 0.7914802222970863
Validation loss: 2.280743086219372

Epoch: 6| Step: 10
Training loss: 1.3811470390368459
Validation loss: 2.2342220001305955

Epoch: 6| Step: 11
Training loss: 1.2399984300511173
Validation loss: 2.3031815519964747

Epoch: 6| Step: 12
Training loss: 0.6692694553900361
Validation loss: 2.2887710934019685

Epoch: 6| Step: 13
Training loss: 0.6090646833964906
Validation loss: 2.3089256399936304

Epoch: 450| Step: 0
Training loss: 0.6877856528117714
Validation loss: 2.309351680601856

Epoch: 6| Step: 1
Training loss: 0.676055455667226
Validation loss: 2.321437567490946

Epoch: 6| Step: 2
Training loss: 0.9837902996819604
Validation loss: 2.3715462498914426

Epoch: 6| Step: 3
Training loss: 1.1050331686401367
Validation loss: 2.285423898251252

Epoch: 6| Step: 4
Training loss: 1.0119884234659633
Validation loss: 2.331138361441454

Epoch: 6| Step: 5
Training loss: 1.0650418114849678
Validation loss: 2.369441911502828

Epoch: 6| Step: 6
Training loss: 0.6629476276586862
Validation loss: 2.3472652961877447

Epoch: 6| Step: 7
Training loss: 1.0118290314532399
Validation loss: 2.360766602326727

Epoch: 6| Step: 8
Training loss: 0.9365806204131483
Validation loss: 2.3055041429711305

Epoch: 6| Step: 9
Training loss: 1.0765251230691553
Validation loss: 2.288233551661034

Epoch: 6| Step: 10
Training loss: 1.8464564486547101
Validation loss: 2.2478507805378363

Epoch: 6| Step: 11
Training loss: 0.8348546724570586
Validation loss: 2.2685604022903183

Epoch: 6| Step: 12
Training loss: 1.3354430147964897
Validation loss: 2.2813154360940815

Epoch: 6| Step: 13
Training loss: 0.9761142770200465
Validation loss: 2.329654237334451

Epoch: 451| Step: 0
Training loss: 0.9084077666055205
Validation loss: 2.286395320957946

Epoch: 6| Step: 1
Training loss: 0.9907676269191454
Validation loss: 2.2955232939590107

Epoch: 6| Step: 2
Training loss: 0.976551361020457
Validation loss: 2.297227276224724

Epoch: 6| Step: 3
Training loss: 0.9204306197990414
Validation loss: 2.303474090434375

Epoch: 6| Step: 4
Training loss: 0.9625247469111069
Validation loss: 2.293628841138711

Epoch: 6| Step: 5
Training loss: 0.9348238259356448
Validation loss: 2.281059562296247

Epoch: 6| Step: 6
Training loss: 0.8016553248741877
Validation loss: 2.275652915994097

Epoch: 6| Step: 7
Training loss: 0.8161468093629286
Validation loss: 2.17477631263183

Epoch: 6| Step: 8
Training loss: 1.128843734752616
Validation loss: 2.3434937302141337

Epoch: 6| Step: 9
Training loss: 2.0303576343246768
Validation loss: 2.3016198829088417

Epoch: 6| Step: 10
Training loss: 0.910108900680417
Validation loss: 2.272631079133363

Epoch: 6| Step: 11
Training loss: 0.7964590146235383
Validation loss: 2.288744673573071

Epoch: 6| Step: 12
Training loss: 0.8193113848493627
Validation loss: 2.291714514701761

Epoch: 6| Step: 13
Training loss: 1.26112323324303
Validation loss: 2.2520059055131525

Epoch: 452| Step: 0
Training loss: 0.7099508628497699
Validation loss: 2.314124685424081

Epoch: 6| Step: 1
Training loss: 0.7984662343806305
Validation loss: 2.323309788730786

Epoch: 6| Step: 2
Training loss: 1.019216554678249
Validation loss: 2.2960917583014058

Epoch: 6| Step: 3
Training loss: 1.0297038307110535
Validation loss: 2.2709423248636633

Epoch: 6| Step: 4
Training loss: 1.1223153825266028
Validation loss: 2.3087067727093684

Epoch: 6| Step: 5
Training loss: 0.5898803042775352
Validation loss: 2.285060792858658

Epoch: 6| Step: 6
Training loss: 0.936790261231351
Validation loss: 2.339440958022537

Epoch: 6| Step: 7
Training loss: 0.9316290448826625
Validation loss: 2.276368646489304

Epoch: 6| Step: 8
Training loss: 0.8823101336015169
Validation loss: 2.299293844411857

Epoch: 6| Step: 9
Training loss: 0.8434254763955694
Validation loss: 2.266793842528562

Epoch: 6| Step: 10
Training loss: 1.1085837322747585
Validation loss: 2.2805036379372003

Epoch: 6| Step: 11
Training loss: 1.3193583906565762
Validation loss: 2.2084854375039336

Epoch: 6| Step: 12
Training loss: 1.768660914465768
Validation loss: 2.2654843929960826

Epoch: 6| Step: 13
Training loss: 0.8560687186474886
Validation loss: 2.241088426311087

Epoch: 453| Step: 0
Training loss: 1.0650829446756724
Validation loss: 2.359429218441007

Epoch: 6| Step: 1
Training loss: 1.2791071860352456
Validation loss: 2.329230725990256

Epoch: 6| Step: 2
Training loss: 0.9111277098681475
Validation loss: 2.2674644671870787

Epoch: 6| Step: 3
Training loss: 0.9082924419496422
Validation loss: 2.3180945595986437

Epoch: 6| Step: 4
Training loss: 0.8362105805895272
Validation loss: 2.2464049866176823

Epoch: 6| Step: 5
Training loss: 0.9822559861262663
Validation loss: 2.2388653881954275

Epoch: 6| Step: 6
Training loss: 0.6433874905805859
Validation loss: 2.342341451937548

Epoch: 6| Step: 7
Training loss: 0.9409930956888224
Validation loss: 2.2987758820016784

Epoch: 6| Step: 8
Training loss: 1.079812650148523
Validation loss: 2.370150647880258

Epoch: 6| Step: 9
Training loss: 0.8143911360974013
Validation loss: 2.27256480919988

Epoch: 6| Step: 10
Training loss: 1.701432393181732
Validation loss: 2.3364598867888615

Epoch: 6| Step: 11
Training loss: 1.2991257405436327
Validation loss: 2.26297234763737

Epoch: 6| Step: 12
Training loss: 1.1739016492416583
Validation loss: 2.271532350962383

Epoch: 6| Step: 13
Training loss: 1.0223678357019876
Validation loss: 2.268036662534053

Epoch: 454| Step: 0
Training loss: 0.7670761680233837
Validation loss: 2.376950537579505

Epoch: 6| Step: 1
Training loss: 0.9279529835982974
Validation loss: 2.275939707843444

Epoch: 6| Step: 2
Training loss: 1.061619337535055
Validation loss: 2.286418522485787

Epoch: 6| Step: 3
Training loss: 0.8172872070403459
Validation loss: 2.343644694488642

Epoch: 6| Step: 4
Training loss: 1.02558632572583
Validation loss: 2.31937674385792

Epoch: 6| Step: 5
Training loss: 1.204986618252604
Validation loss: 2.374285309212866

Epoch: 6| Step: 6
Training loss: 1.052421112728572
Validation loss: 2.343859881214614

Epoch: 6| Step: 7
Training loss: 0.7530748991704136
Validation loss: 2.2494824177637978

Epoch: 6| Step: 8
Training loss: 1.9821102404764501
Validation loss: 2.4065443641164626

Epoch: 6| Step: 9
Training loss: 0.6587792204396793
Validation loss: 2.312700979583645

Epoch: 6| Step: 10
Training loss: 1.1979317982035864
Validation loss: 2.293473461825418

Epoch: 6| Step: 11
Training loss: 0.8581184911515788
Validation loss: 2.265756964031622

Epoch: 6| Step: 12
Training loss: 1.431631382265739
Validation loss: 2.3949263865510044

Epoch: 6| Step: 13
Training loss: 0.8749823568472718
Validation loss: 2.3512565019327525

Epoch: 455| Step: 0
Training loss: 1.1777938903650131
Validation loss: 2.2555318708928485

Epoch: 6| Step: 1
Training loss: 0.6937731086043984
Validation loss: 2.3029906341400905

Epoch: 6| Step: 2
Training loss: 1.3391156679011835
Validation loss: 2.333105482858726

Epoch: 6| Step: 3
Training loss: 1.7035444950420682
Validation loss: 2.3146317391915168

Epoch: 6| Step: 4
Training loss: 1.0568407472082617
Validation loss: 2.3149057184188147

Epoch: 6| Step: 5
Training loss: 1.182225408952126
Validation loss: 2.2547815650345835

Epoch: 6| Step: 6
Training loss: 1.0112703132239576
Validation loss: 2.3233952212580404

Epoch: 6| Step: 7
Training loss: 0.7280670912476113
Validation loss: 2.3134157218522557

Epoch: 6| Step: 8
Training loss: 0.5456290083450656
Validation loss: 2.2985633723221537

Epoch: 6| Step: 9
Training loss: 1.0118917074349822
Validation loss: 2.338860483721059

Epoch: 6| Step: 10
Training loss: 0.88196218944997
Validation loss: 2.2819496017025727

Epoch: 6| Step: 11
Training loss: 1.0841324988534338
Validation loss: 2.2341297444457004

Epoch: 6| Step: 12
Training loss: 0.81528757650136
Validation loss: 2.384367669215662

Epoch: 6| Step: 13
Training loss: 0.89058196649821
Validation loss: 2.3016305685261877

Epoch: 456| Step: 0
Training loss: 0.818325797691792
Validation loss: 2.238987229827859

Epoch: 6| Step: 1
Training loss: 1.1046007610621638
Validation loss: 2.3636648253439616

Epoch: 6| Step: 2
Training loss: 0.6516202923875241
Validation loss: 2.2568627263229186

Epoch: 6| Step: 3
Training loss: 1.2773209316070382
Validation loss: 2.2875024976738567

Epoch: 6| Step: 4
Training loss: 1.1713098816439098
Validation loss: 2.2485580141928234

Epoch: 6| Step: 5
Training loss: 0.8400878196745102
Validation loss: 2.370096206614427

Epoch: 6| Step: 6
Training loss: 0.9542935196844475
Validation loss: 2.2888141516818403

Epoch: 6| Step: 7
Training loss: 1.985542194391708
Validation loss: 2.351743624166457

Epoch: 6| Step: 8
Training loss: 1.148646744330788
Validation loss: 2.2521398946575495

Epoch: 6| Step: 9
Training loss: 0.60174037731038
Validation loss: 2.278441086718935

Epoch: 6| Step: 10
Training loss: 0.539166730672409
Validation loss: 2.3283462182563723

Epoch: 6| Step: 11
Training loss: 0.9913452658748542
Validation loss: 2.2463403287687953

Epoch: 6| Step: 12
Training loss: 0.9184284763470486
Validation loss: 2.351088703199368

Epoch: 6| Step: 13
Training loss: 0.8583277476848099
Validation loss: 2.357831899502969

Epoch: 457| Step: 0
Training loss: 0.9692107304805985
Validation loss: 2.3398380592073336

Epoch: 6| Step: 1
Training loss: 0.748673139521516
Validation loss: 2.354065537810192

Epoch: 6| Step: 2
Training loss: 0.9367777585492228
Validation loss: 2.2644866346571733

Epoch: 6| Step: 3
Training loss: 0.9425148352611472
Validation loss: 2.283838089326856

Epoch: 6| Step: 4
Training loss: 0.68842678025359
Validation loss: 2.299088332004091

Epoch: 6| Step: 5
Training loss: 1.0200713031754258
Validation loss: 2.311520282194513

Epoch: 6| Step: 6
Training loss: 0.84042664637493
Validation loss: 2.3487458322687758

Epoch: 6| Step: 7
Training loss: 0.933021721308007
Validation loss: 2.3685644517540823

Epoch: 6| Step: 8
Training loss: 0.7147062409099233
Validation loss: 2.2981642826289366

Epoch: 6| Step: 9
Training loss: 0.8692027209098455
Validation loss: 2.289445160169965

Epoch: 6| Step: 10
Training loss: 1.0950423643548
Validation loss: 2.3440438603860727

Epoch: 6| Step: 11
Training loss: 1.0867234822985399
Validation loss: 2.326766023864728

Epoch: 6| Step: 12
Training loss: 1.9931942060434982
Validation loss: 2.299788175635562

Epoch: 6| Step: 13
Training loss: 0.7434023501411628
Validation loss: 2.2690025536828093

Epoch: 458| Step: 0
Training loss: 0.9407978862158878
Validation loss: 2.31943689207988

Epoch: 6| Step: 1
Training loss: 0.6455052270419099
Validation loss: 2.3018868079930677

Epoch: 6| Step: 2
Training loss: 0.9131998409277785
Validation loss: 2.320536837162352

Epoch: 6| Step: 3
Training loss: 0.892633348755789
Validation loss: 2.2910210207993353

Epoch: 6| Step: 4
Training loss: 0.8156808066733238
Validation loss: 2.3217608313568903

Epoch: 6| Step: 5
Training loss: 1.092538435061294
Validation loss: 2.312408116185588

Epoch: 6| Step: 6
Training loss: 0.8960073361224187
Validation loss: 2.278041917409067

Epoch: 6| Step: 7
Training loss: 0.8518529274222668
Validation loss: 2.2806354930652044

Epoch: 6| Step: 8
Training loss: 1.409090437147895
Validation loss: 2.2900286446453832

Epoch: 6| Step: 9
Training loss: 2.01227711456226
Validation loss: 2.2537984688071973

Epoch: 6| Step: 10
Training loss: 0.8534942554443692
Validation loss: 2.3237438990464607

Epoch: 6| Step: 11
Training loss: 0.8655420105190846
Validation loss: 2.217626215133429

Epoch: 6| Step: 12
Training loss: 0.7069930809213895
Validation loss: 2.313669020089246

Epoch: 6| Step: 13
Training loss: 0.9289081737090934
Validation loss: 2.292860668346565

Epoch: 459| Step: 0
Training loss: 1.3485089244469424
Validation loss: 2.336776285935389

Epoch: 6| Step: 1
Training loss: 0.8814819909851027
Validation loss: 2.268740871285311

Epoch: 6| Step: 2
Training loss: 0.889271091870601
Validation loss: 2.2578990266955667

Epoch: 6| Step: 3
Training loss: 1.182603982462662
Validation loss: 2.2736701419203005

Epoch: 6| Step: 4
Training loss: 0.9262434694829577
Validation loss: 2.2964607547741815

Epoch: 6| Step: 5
Training loss: 0.9990148460041127
Validation loss: 2.2880042645221548

Epoch: 6| Step: 6
Training loss: 0.9799633167174251
Validation loss: 2.2114467355443557

Epoch: 6| Step: 7
Training loss: 0.7329657811169987
Validation loss: 2.3395818167606586

Epoch: 6| Step: 8
Training loss: 1.1929610316458426
Validation loss: 2.3032463650070127

Epoch: 6| Step: 9
Training loss: 0.7956235446002651
Validation loss: 2.284574721485282

Epoch: 6| Step: 10
Training loss: 0.9500136951664029
Validation loss: 2.2257191023340237

Epoch: 6| Step: 11
Training loss: 0.8609624938660009
Validation loss: 2.365357784483793

Epoch: 6| Step: 12
Training loss: 1.78624012970383
Validation loss: 2.2882016111535095

Epoch: 6| Step: 13
Training loss: 0.9487035789743111
Validation loss: 2.233068902375532

Epoch: 460| Step: 0
Training loss: 0.9738607952759942
Validation loss: 2.3273610080143468

Epoch: 6| Step: 1
Training loss: 0.9954704578524519
Validation loss: 2.23327513728985

Epoch: 6| Step: 2
Training loss: 1.17036661346374
Validation loss: 2.2662878371696835

Epoch: 6| Step: 3
Training loss: 1.9096223986189016
Validation loss: 2.279225543322521

Epoch: 6| Step: 4
Training loss: 0.824769690184617
Validation loss: 2.247953711535981

Epoch: 6| Step: 5
Training loss: 1.1076517825171757
Validation loss: 2.3209067642581935

Epoch: 6| Step: 6
Training loss: 1.0738811725434174
Validation loss: 2.33043578604346

Epoch: 6| Step: 7
Training loss: 1.070127429415335
Validation loss: 2.358425085794077

Epoch: 6| Step: 8
Training loss: 0.7274487330538484
Validation loss: 2.331218183432799

Epoch: 6| Step: 9
Training loss: 0.9988196082082144
Validation loss: 2.325517730459107

Epoch: 6| Step: 10
Training loss: 0.9627544314496189
Validation loss: 2.282167843689488

Epoch: 6| Step: 11
Training loss: 0.7829329103006594
Validation loss: 2.2889718649520603

Epoch: 6| Step: 12
Training loss: 0.964440759677655
Validation loss: 2.317594183645305

Epoch: 6| Step: 13
Training loss: 1.0934476707053071
Validation loss: 2.3198673034847492

Epoch: 461| Step: 0
Training loss: 1.150552165115824
Validation loss: 2.2347151215380006

Epoch: 6| Step: 1
Training loss: 0.960430973191909
Validation loss: 2.287668211945446

Epoch: 6| Step: 2
Training loss: 1.0417272486553883
Validation loss: 2.2675985649272787

Epoch: 6| Step: 3
Training loss: 1.0770031717797401
Validation loss: 2.3300979093967986

Epoch: 6| Step: 4
Training loss: 0.7582664703054405
Validation loss: 2.2806391508526778

Epoch: 6| Step: 5
Training loss: 0.8715091279471574
Validation loss: 2.3374862177889266

Epoch: 6| Step: 6
Training loss: 0.7412287894651078
Validation loss: 2.3015291564712412

Epoch: 6| Step: 7
Training loss: 1.0987958863346958
Validation loss: 2.256155581898042

Epoch: 6| Step: 8
Training loss: 0.8092576033830453
Validation loss: 2.330907950066863

Epoch: 6| Step: 9
Training loss: 2.049344734975899
Validation loss: 2.2300733312007877

Epoch: 6| Step: 10
Training loss: 1.013301421518363
Validation loss: 2.354179836029089

Epoch: 6| Step: 11
Training loss: 0.6803358646808627
Validation loss: 2.32740706882556

Epoch: 6| Step: 12
Training loss: 0.8972120469155729
Validation loss: 2.2869576807672525

Epoch: 6| Step: 13
Training loss: 0.9102715349654281
Validation loss: 2.2784105296253885

Epoch: 462| Step: 0
Training loss: 1.099092839884939
Validation loss: 2.333471911207592

Epoch: 6| Step: 1
Training loss: 0.5672801937727435
Validation loss: 2.304976985569948

Epoch: 6| Step: 2
Training loss: 0.7870464441780256
Validation loss: 2.299504464614592

Epoch: 6| Step: 3
Training loss: 0.8219690218329937
Validation loss: 2.2449291175651185

Epoch: 6| Step: 4
Training loss: 1.0410608564502297
Validation loss: 2.2932754062499767

Epoch: 6| Step: 5
Training loss: 1.8165816683818543
Validation loss: 2.3365647102275098

Epoch: 6| Step: 6
Training loss: 0.6969225384017352
Validation loss: 2.2920147658470205

Epoch: 6| Step: 7
Training loss: 0.7168976923336732
Validation loss: 2.3433140382731006

Epoch: 6| Step: 8
Training loss: 1.2351989893120994
Validation loss: 2.3479151565685643

Epoch: 6| Step: 9
Training loss: 0.9437963764846223
Validation loss: 2.291971494774209

Epoch: 6| Step: 10
Training loss: 0.9369307061061593
Validation loss: 2.2996687917464786

Epoch: 6| Step: 11
Training loss: 1.2317301264267384
Validation loss: 2.25629957954364

Epoch: 6| Step: 12
Training loss: 0.9069184436027656
Validation loss: 2.2500821853996

Epoch: 6| Step: 13
Training loss: 1.1001337403577731
Validation loss: 2.2577313465593134

Epoch: 463| Step: 0
Training loss: 1.1744889162368022
Validation loss: 2.226545665470795

Epoch: 6| Step: 1
Training loss: 1.9000134618181872
Validation loss: 2.2807042886128652

Epoch: 6| Step: 2
Training loss: 0.9509573504594637
Validation loss: 2.1910561001863624

Epoch: 6| Step: 3
Training loss: 0.8867893274930584
Validation loss: 2.29089741777417

Epoch: 6| Step: 4
Training loss: 0.968095188950172
Validation loss: 2.290680180957865

Epoch: 6| Step: 5
Training loss: 1.1824083088656439
Validation loss: 2.3196772367330083

Epoch: 6| Step: 6
Training loss: 0.8120886421584643
Validation loss: 2.317549400138925

Epoch: 6| Step: 7
Training loss: 0.7451176674617557
Validation loss: 2.283571789023567

Epoch: 6| Step: 8
Training loss: 1.2828750074725395
Validation loss: 2.3366549090529256

Epoch: 6| Step: 9
Training loss: 0.8805579369636796
Validation loss: 2.223683945042989

Epoch: 6| Step: 10
Training loss: 0.8155605919206329
Validation loss: 2.2379785091131987

Epoch: 6| Step: 11
Training loss: 0.9020618807655016
Validation loss: 2.3485635790861115

Epoch: 6| Step: 12
Training loss: 0.7006096458624254
Validation loss: 2.3290702385865334

Epoch: 6| Step: 13
Training loss: 0.8929872806258371
Validation loss: 2.2533818719741157

Epoch: 464| Step: 0
Training loss: 0.8549968166738221
Validation loss: 2.3298792226256433

Epoch: 6| Step: 1
Training loss: 1.0433166152378421
Validation loss: 2.3097936063777995

Epoch: 6| Step: 2
Training loss: 0.8563739046538863
Validation loss: 2.3464468793737168

Epoch: 6| Step: 3
Training loss: 0.8089162211165579
Validation loss: 2.337791074842777

Epoch: 6| Step: 4
Training loss: 1.005609040450775
Validation loss: 2.26001713647334

Epoch: 6| Step: 5
Training loss: 0.6563816846697116
Validation loss: 2.267825293369505

Epoch: 6| Step: 6
Training loss: 2.0134612305335238
Validation loss: 2.277473269990193

Epoch: 6| Step: 7
Training loss: 0.6577015672234389
Validation loss: 2.3242978478340657

Epoch: 6| Step: 8
Training loss: 0.9969060839168611
Validation loss: 2.3407503956858657

Epoch: 6| Step: 9
Training loss: 0.8243242892270383
Validation loss: 2.2712644117248257

Epoch: 6| Step: 10
Training loss: 0.6516518950028015
Validation loss: 2.323921709803569

Epoch: 6| Step: 11
Training loss: 1.1068083393997332
Validation loss: 2.2635909101089693

Epoch: 6| Step: 12
Training loss: 0.9549206875026971
Validation loss: 2.230443985471121

Epoch: 6| Step: 13
Training loss: 0.6817634275154136
Validation loss: 2.2720121778586133

Epoch: 465| Step: 0
Training loss: 0.7730786810948748
Validation loss: 2.2775698859646782

Epoch: 6| Step: 1
Training loss: 0.6020179114607841
Validation loss: 2.3346773219807697

Epoch: 6| Step: 2
Training loss: 0.9574171884049284
Validation loss: 2.2728833021094235

Epoch: 6| Step: 3
Training loss: 0.9286548425077326
Validation loss: 2.2480039111262733

Epoch: 6| Step: 4
Training loss: 1.082140314547921
Validation loss: 2.2799211467485203

Epoch: 6| Step: 5
Training loss: 1.85622671607214
Validation loss: 2.3174259735993377

Epoch: 6| Step: 6
Training loss: 1.110911420255812
Validation loss: 2.265956675884176

Epoch: 6| Step: 7
Training loss: 0.9577714198701232
Validation loss: 2.3370457889064298

Epoch: 6| Step: 8
Training loss: 0.7425480819957874
Validation loss: 2.287142360861285

Epoch: 6| Step: 9
Training loss: 0.5935800208672716
Validation loss: 2.3030206697379487

Epoch: 6| Step: 10
Training loss: 1.030089679258293
Validation loss: 2.2704363300257575

Epoch: 6| Step: 11
Training loss: 0.9620953229341855
Validation loss: 2.2769434476166457

Epoch: 6| Step: 12
Training loss: 0.8173051475899553
Validation loss: 2.2983887509964505

Epoch: 6| Step: 13
Training loss: 0.7032257855555895
Validation loss: 2.3034703398057004

Epoch: 466| Step: 0
Training loss: 1.0162872502818527
Validation loss: 2.268298551342764

Epoch: 6| Step: 1
Training loss: 0.7900539250620304
Validation loss: 2.3115923917718626

Epoch: 6| Step: 2
Training loss: 0.6289421687323901
Validation loss: 2.2319419522325394

Epoch: 6| Step: 3
Training loss: 0.7081222126056593
Validation loss: 2.3456021740793145

Epoch: 6| Step: 4
Training loss: 0.5943301277992394
Validation loss: 2.2920830106973704

Epoch: 6| Step: 5
Training loss: 2.014369839937736
Validation loss: 2.2469024666108552

Epoch: 6| Step: 6
Training loss: 0.7202330506173249
Validation loss: 2.278772040790705

Epoch: 6| Step: 7
Training loss: 0.775660700810201
Validation loss: 2.233017233327092

Epoch: 6| Step: 8
Training loss: 1.136775903477538
Validation loss: 2.262831834679499

Epoch: 6| Step: 9
Training loss: 0.8881812449503371
Validation loss: 2.231264702822689

Epoch: 6| Step: 10
Training loss: 1.3281346040266264
Validation loss: 2.250807561392177

Epoch: 6| Step: 11
Training loss: 0.8945992123302503
Validation loss: 2.302983879360475

Epoch: 6| Step: 12
Training loss: 1.127618127373778
Validation loss: 2.261816647605402

Epoch: 6| Step: 13
Training loss: 0.6870439273791559
Validation loss: 2.267278235687335

Epoch: 467| Step: 0
Training loss: 1.8472205005086397
Validation loss: 2.2288081607576933

Epoch: 6| Step: 1
Training loss: 0.914508743256851
Validation loss: 2.2925089618501744

Epoch: 6| Step: 2
Training loss: 1.0521578368947377
Validation loss: 2.250995705075405

Epoch: 6| Step: 3
Training loss: 0.9149340525557692
Validation loss: 2.2677127179595904

Epoch: 6| Step: 4
Training loss: 0.707917264212509
Validation loss: 2.304086921239255

Epoch: 6| Step: 5
Training loss: 1.161025829215154
Validation loss: 2.2463058832335765

Epoch: 6| Step: 6
Training loss: 0.9059155274457321
Validation loss: 2.3446566462687435

Epoch: 6| Step: 7
Training loss: 1.0512991270726615
Validation loss: 2.2892957987982214

Epoch: 6| Step: 8
Training loss: 0.8587930963355129
Validation loss: 2.2690982525217644

Epoch: 6| Step: 9
Training loss: 0.9570082058370392
Validation loss: 2.2803472063385315

Epoch: 6| Step: 10
Training loss: 0.6199726567083992
Validation loss: 2.3145626041010625

Epoch: 6| Step: 11
Training loss: 1.1488979739914784
Validation loss: 2.3024153871995763

Epoch: 6| Step: 12
Training loss: 0.8243331468208905
Validation loss: 2.3335879947932177

Epoch: 6| Step: 13
Training loss: 0.788017222683424
Validation loss: 2.2853615294790717

Epoch: 468| Step: 0
Training loss: 0.6059084126581781
Validation loss: 2.3419268560722384

Epoch: 6| Step: 1
Training loss: 1.0958739774779054
Validation loss: 2.2901905268865668

Epoch: 6| Step: 2
Training loss: 0.7106780532451947
Validation loss: 2.2869497363470765

Epoch: 6| Step: 3
Training loss: 1.162291953225906
Validation loss: 2.2707912638360113

Epoch: 6| Step: 4
Training loss: 1.0067566064315177
Validation loss: 2.271622351265326

Epoch: 6| Step: 5
Training loss: 0.7725396001721051
Validation loss: 2.323648162290121

Epoch: 6| Step: 6
Training loss: 0.9822720968994587
Validation loss: 2.3311880074695055

Epoch: 6| Step: 7
Training loss: 1.1600109998411663
Validation loss: 2.242683360673942

Epoch: 6| Step: 8
Training loss: 1.0657153563912287
Validation loss: 2.284631029268501

Epoch: 6| Step: 9
Training loss: 0.7812371062168424
Validation loss: 2.2898364286266886

Epoch: 6| Step: 10
Training loss: 0.9138779413120887
Validation loss: 2.2744925411580335

Epoch: 6| Step: 11
Training loss: 0.8911195352413247
Validation loss: 2.3331350566045717

Epoch: 6| Step: 12
Training loss: 1.7200652205499525
Validation loss: 2.2986501168848177

Epoch: 6| Step: 13
Training loss: 0.6800088232533852
Validation loss: 2.2972549616418885

Epoch: 469| Step: 0
Training loss: 0.8035998354538046
Validation loss: 2.3365616150703366

Epoch: 6| Step: 1
Training loss: 0.8668349640614605
Validation loss: 2.280628183093128

Epoch: 6| Step: 2
Training loss: 1.0636574667502157
Validation loss: 2.3226961060307465

Epoch: 6| Step: 3
Training loss: 0.9978173994307834
Validation loss: 2.206678229595588

Epoch: 6| Step: 4
Training loss: 0.9284414066731972
Validation loss: 2.3186781938458214

Epoch: 6| Step: 5
Training loss: 1.991921081680218
Validation loss: 2.296665826419267

Epoch: 6| Step: 6
Training loss: 0.707477154986347
Validation loss: 2.3359560725508515

Epoch: 6| Step: 7
Training loss: 0.8816116740654125
Validation loss: 2.2657368571186653

Epoch: 6| Step: 8
Training loss: 0.7563924166669924
Validation loss: 2.3213442157743005

Epoch: 6| Step: 9
Training loss: 0.8688630421594525
Validation loss: 2.3294978201920746

Epoch: 6| Step: 10
Training loss: 0.9928196072466623
Validation loss: 2.260171297298613

Epoch: 6| Step: 11
Training loss: 0.8611863207702071
Validation loss: 2.3389826449102618

Epoch: 6| Step: 12
Training loss: 1.064214109131458
Validation loss: 2.3133405531350375

Epoch: 6| Step: 13
Training loss: 0.5459960686416361
Validation loss: 2.357236439932243

Epoch: 470| Step: 0
Training loss: 1.8998184518912549
Validation loss: 2.240380717042749

Epoch: 6| Step: 1
Training loss: 0.7159460771730397
Validation loss: 2.2592566713792968

Epoch: 6| Step: 2
Training loss: 0.9917158973452078
Validation loss: 2.2844820508712895

Epoch: 6| Step: 3
Training loss: 0.7118638260310208
Validation loss: 2.3243491201287365

Epoch: 6| Step: 4
Training loss: 0.6809025788510884
Validation loss: 2.2575200496062107

Epoch: 6| Step: 5
Training loss: 1.1563213429478583
Validation loss: 2.272844865503135

Epoch: 6| Step: 6
Training loss: 0.6780256365568175
Validation loss: 2.272324882713002

Epoch: 6| Step: 7
Training loss: 1.1829420253126754
Validation loss: 2.2378764327005816

Epoch: 6| Step: 8
Training loss: 1.0588761969865688
Validation loss: 2.2722699431422946

Epoch: 6| Step: 9
Training loss: 0.9396378619039558
Validation loss: 2.2242809627533355

Epoch: 6| Step: 10
Training loss: 1.0663398470483396
Validation loss: 2.204667057223309

Epoch: 6| Step: 11
Training loss: 0.973029865375027
Validation loss: 2.3167193277174847

Epoch: 6| Step: 12
Training loss: 0.9153163168252255
Validation loss: 2.392241134701903

Epoch: 6| Step: 13
Training loss: 0.9250336537811727
Validation loss: 2.3067043186209566

Epoch: 471| Step: 0
Training loss: 0.8149989652334559
Validation loss: 2.2178753670445603

Epoch: 6| Step: 1
Training loss: 0.7281005740673357
Validation loss: 2.2723826870805675

Epoch: 6| Step: 2
Training loss: 1.1826109378060503
Validation loss: 2.2441276127881125

Epoch: 6| Step: 3
Training loss: 1.3096935603939768
Validation loss: 2.349080225132492

Epoch: 6| Step: 4
Training loss: 0.8375011686060709
Validation loss: 2.22665278898086

Epoch: 6| Step: 5
Training loss: 1.0488393772310165
Validation loss: 2.317902832792784

Epoch: 6| Step: 6
Training loss: 1.7482028316209968
Validation loss: 2.2598208742413233

Epoch: 6| Step: 7
Training loss: 0.9486076994115178
Validation loss: 2.2999412523768097

Epoch: 6| Step: 8
Training loss: 0.872511458444637
Validation loss: 2.3412321231910855

Epoch: 6| Step: 9
Training loss: 0.7191467848497899
Validation loss: 2.276591200387265

Epoch: 6| Step: 10
Training loss: 0.7796091395812688
Validation loss: 2.2738364823519945

Epoch: 6| Step: 11
Training loss: 0.9196897890229018
Validation loss: 2.3596845066747

Epoch: 6| Step: 12
Training loss: 0.817132216383318
Validation loss: 2.273918172928781

Epoch: 6| Step: 13
Training loss: 0.9656397204218414
Validation loss: 2.2832862968471375

Epoch: 472| Step: 0
Training loss: 0.9132296036082904
Validation loss: 2.335259091327061

Epoch: 6| Step: 1
Training loss: 0.6822882693451221
Validation loss: 2.3265700586292146

Epoch: 6| Step: 2
Training loss: 0.8837625573330403
Validation loss: 2.2783095214923517

Epoch: 6| Step: 3
Training loss: 0.7597278889598346
Validation loss: 2.2054794427213804

Epoch: 6| Step: 4
Training loss: 0.6379885269601332
Validation loss: 2.3286067257520244

Epoch: 6| Step: 5
Training loss: 0.7535214010109226
Validation loss: 2.298124968695389

Epoch: 6| Step: 6
Training loss: 1.1184335975120572
Validation loss: 2.3353024270140055

Epoch: 6| Step: 7
Training loss: 0.8758172918520865
Validation loss: 2.3487552927689936

Epoch: 6| Step: 8
Training loss: 1.8578683855972964
Validation loss: 2.2932538849973865

Epoch: 6| Step: 9
Training loss: 0.8687429139651012
Validation loss: 2.312849998871388

Epoch: 6| Step: 10
Training loss: 0.9435049383037248
Validation loss: 2.31479135595305

Epoch: 6| Step: 11
Training loss: 1.1282500897742855
Validation loss: 2.3156348434291503

Epoch: 6| Step: 12
Training loss: 0.8694513001406952
Validation loss: 2.256093619876096

Epoch: 6| Step: 13
Training loss: 0.4757147894481887
Validation loss: 2.3351358883475486

Epoch: 473| Step: 0
Training loss: 1.7189019569500792
Validation loss: 2.311853749204543

Epoch: 6| Step: 1
Training loss: 0.7936204759544236
Validation loss: 2.2859461919946082

Epoch: 6| Step: 2
Training loss: 0.7760730114096167
Validation loss: 2.29686622040347

Epoch: 6| Step: 3
Training loss: 0.8633787695577492
Validation loss: 2.224624532470243

Epoch: 6| Step: 4
Training loss: 0.8698431026455646
Validation loss: 2.3353341163195376

Epoch: 6| Step: 5
Training loss: 1.109081551868375
Validation loss: 2.227515939955394

Epoch: 6| Step: 6
Training loss: 1.0494086507703495
Validation loss: 2.210487166512322

Epoch: 6| Step: 7
Training loss: 0.9882052546898992
Validation loss: 2.3221708134328196

Epoch: 6| Step: 8
Training loss: 0.6723723234345691
Validation loss: 2.3578737846988718

Epoch: 6| Step: 9
Training loss: 0.829884477354675
Validation loss: 2.250781508621405

Epoch: 6| Step: 10
Training loss: 0.971823830192768
Validation loss: 2.3096934656715047

Epoch: 6| Step: 11
Training loss: 0.8914768094112935
Validation loss: 2.3141557419266867

Epoch: 6| Step: 12
Training loss: 0.9486934322837934
Validation loss: 2.29697079096363

Epoch: 6| Step: 13
Training loss: 1.0064838729983878
Validation loss: 2.3017927513610466

Epoch: 474| Step: 0
Training loss: 1.1203548109505506
Validation loss: 2.3265680355453897

Epoch: 6| Step: 1
Training loss: 0.6276475144818967
Validation loss: 2.291907643674467

Epoch: 6| Step: 2
Training loss: 0.8868064668936657
Validation loss: 2.3071555372451384

Epoch: 6| Step: 3
Training loss: 0.8632837355910201
Validation loss: 2.294076761591238

Epoch: 6| Step: 4
Training loss: 1.7660590794445759
Validation loss: 2.3680276748697886

Epoch: 6| Step: 5
Training loss: 1.1139210786446465
Validation loss: 2.4058375421257754

Epoch: 6| Step: 6
Training loss: 0.8302254579725159
Validation loss: 2.2698604531433126

Epoch: 6| Step: 7
Training loss: 1.1593464295190679
Validation loss: 2.300338599189564

Epoch: 6| Step: 8
Training loss: 0.7507379398298228
Validation loss: 2.297677438538424

Epoch: 6| Step: 9
Training loss: 0.7738649747529103
Validation loss: 2.3224430753828336

Epoch: 6| Step: 10
Training loss: 0.9924704981630278
Validation loss: 2.2227819073351966

Epoch: 6| Step: 11
Training loss: 0.9830913954591743
Validation loss: 2.272357141153221

Epoch: 6| Step: 12
Training loss: 0.4529765806807517
Validation loss: 2.317092582168046

Epoch: 6| Step: 13
Training loss: 0.8212021136439233
Validation loss: 2.2653840748428147

Epoch: 475| Step: 0
Training loss: 0.8894060057907168
Validation loss: 2.318977650108066

Epoch: 6| Step: 1
Training loss: 1.126954658811375
Validation loss: 2.2896032033907168

Epoch: 6| Step: 2
Training loss: 0.7197240780253081
Validation loss: 2.215331075959429

Epoch: 6| Step: 3
Training loss: 0.9159367248781765
Validation loss: 2.3383733593494767

Epoch: 6| Step: 4
Training loss: 1.0631253141462162
Validation loss: 2.355295839552799

Epoch: 6| Step: 5
Training loss: 1.7731822498156813
Validation loss: 2.3188793564986607

Epoch: 6| Step: 6
Training loss: 1.1107954146334853
Validation loss: 2.27959903385505

Epoch: 6| Step: 7
Training loss: 0.8195227317985574
Validation loss: 2.272404836955848

Epoch: 6| Step: 8
Training loss: 0.9288294703496057
Validation loss: 2.27146970403303

Epoch: 6| Step: 9
Training loss: 1.0942516811219363
Validation loss: 2.2681296394208985

Epoch: 6| Step: 10
Training loss: 0.8658918031538247
Validation loss: 2.295034658383128

Epoch: 6| Step: 11
Training loss: 0.7994552426481164
Validation loss: 2.3177111553872267

Epoch: 6| Step: 12
Training loss: 0.8888247850933227
Validation loss: 2.255406838149951

Epoch: 6| Step: 13
Training loss: 0.9612302256758938
Validation loss: 2.261794011498544

Epoch: 476| Step: 0
Training loss: 0.9338476242854644
Validation loss: 2.322343193113892

Epoch: 6| Step: 1
Training loss: 1.027169448512879
Validation loss: 2.2777165085478845

Epoch: 6| Step: 2
Training loss: 0.7077536922723688
Validation loss: 2.2817728491645632

Epoch: 6| Step: 3
Training loss: 0.8815495732606118
Validation loss: 2.2647809576281377

Epoch: 6| Step: 4
Training loss: 1.813075336037794
Validation loss: 2.337903695975444

Epoch: 6| Step: 5
Training loss: 1.04950588498367
Validation loss: 2.333226223617246

Epoch: 6| Step: 6
Training loss: 0.7143456229563286
Validation loss: 2.2966316891757517

Epoch: 6| Step: 7
Training loss: 0.6430594082555118
Validation loss: 2.2971303648718355

Epoch: 6| Step: 8
Training loss: 0.6687673067366893
Validation loss: 2.3045242821859095

Epoch: 6| Step: 9
Training loss: 1.0169466076229063
Validation loss: 2.2697781079842803

Epoch: 6| Step: 10
Training loss: 0.9836579996444839
Validation loss: 2.334624895656246

Epoch: 6| Step: 11
Training loss: 0.8602637117285844
Validation loss: 2.308376491577492

Epoch: 6| Step: 12
Training loss: 1.1954294783254829
Validation loss: 2.233815096132802

Epoch: 6| Step: 13
Training loss: 1.189219885697635
Validation loss: 2.2807538196276953

Epoch: 477| Step: 0
Training loss: 1.025577433690166
Validation loss: 2.275083680469299

Epoch: 6| Step: 1
Training loss: 1.1220398741893869
Validation loss: 2.2945183031568392

Epoch: 6| Step: 2
Training loss: 0.8431148611014767
Validation loss: 2.267384575606382

Epoch: 6| Step: 3
Training loss: 0.9189884122983429
Validation loss: 2.2656206435747595

Epoch: 6| Step: 4
Training loss: 0.8688071307600984
Validation loss: 2.2294377631817803

Epoch: 6| Step: 5
Training loss: 1.7295747604776437
Validation loss: 2.2899348359205045

Epoch: 6| Step: 6
Training loss: 0.8724686929064726
Validation loss: 2.341857717787715

Epoch: 6| Step: 7
Training loss: 0.802908625566581
Validation loss: 2.296584041076053

Epoch: 6| Step: 8
Training loss: 0.786151577743328
Validation loss: 2.3382550555027883

Epoch: 6| Step: 9
Training loss: 1.031560908758074
Validation loss: 2.360989876428914

Epoch: 6| Step: 10
Training loss: 0.9314457271652594
Validation loss: 2.2257989719558564

Epoch: 6| Step: 11
Training loss: 0.9078882471415689
Validation loss: 2.2897435043635124

Epoch: 6| Step: 12
Training loss: 1.018244139162051
Validation loss: 2.3023864961483413

Epoch: 6| Step: 13
Training loss: 1.1485560349515316
Validation loss: 2.2582030280944707

Epoch: 478| Step: 0
Training loss: 0.7058215462069365
Validation loss: 2.3197364703938264

Epoch: 6| Step: 1
Training loss: 0.8214611911812654
Validation loss: 2.289810943628809

Epoch: 6| Step: 2
Training loss: 1.81215276351662
Validation loss: 2.186200909653221

Epoch: 6| Step: 3
Training loss: 0.7039751211804273
Validation loss: 2.2722047520126276

Epoch: 6| Step: 4
Training loss: 0.9030181874400616
Validation loss: 2.307826711499668

Epoch: 6| Step: 5
Training loss: 1.0351065569771936
Validation loss: 2.2451896878975037

Epoch: 6| Step: 6
Training loss: 1.0632869386766048
Validation loss: 2.282416959555183

Epoch: 6| Step: 7
Training loss: 1.1138437556612022
Validation loss: 2.299736355200818

Epoch: 6| Step: 8
Training loss: 0.8872478771727128
Validation loss: 2.341528962264514

Epoch: 6| Step: 9
Training loss: 0.8255680122893233
Validation loss: 2.331055016333339

Epoch: 6| Step: 10
Training loss: 0.9791925643309781
Validation loss: 2.34023622790954

Epoch: 6| Step: 11
Training loss: 0.985952143250556
Validation loss: 2.2696553366278565

Epoch: 6| Step: 12
Training loss: 1.0282490154014008
Validation loss: 2.35607819664035

Epoch: 6| Step: 13
Training loss: 0.8012208429824974
Validation loss: 2.333864405033789

Epoch: 479| Step: 0
Training loss: 0.9570959575342515
Validation loss: 2.316230912686718

Epoch: 6| Step: 1
Training loss: 0.8749362377367739
Validation loss: 2.3533366438250836

Epoch: 6| Step: 2
Training loss: 0.8072212844849603
Validation loss: 2.3135957292042146

Epoch: 6| Step: 3
Training loss: 0.867081300573305
Validation loss: 2.270051121700087

Epoch: 6| Step: 4
Training loss: 0.8315358007618243
Validation loss: 2.2727784297868507

Epoch: 6| Step: 5
Training loss: 0.7704458852425975
Validation loss: 2.2743653774547963

Epoch: 6| Step: 6
Training loss: 0.6113359737197088
Validation loss: 2.2197214946379757

Epoch: 6| Step: 7
Training loss: 0.6868468997195281
Validation loss: 2.254931836325949

Epoch: 6| Step: 8
Training loss: 1.8319991054032987
Validation loss: 2.221284913701191

Epoch: 6| Step: 9
Training loss: 1.2408665285010554
Validation loss: 2.251258088184959

Epoch: 6| Step: 10
Training loss: 0.8795975064849899
Validation loss: 2.29018031233337

Epoch: 6| Step: 11
Training loss: 0.6395542220988425
Validation loss: 2.2641985472375077

Epoch: 6| Step: 12
Training loss: 0.8957811310809802
Validation loss: 2.2560723149422928

Epoch: 6| Step: 13
Training loss: 0.9445257144131562
Validation loss: 2.269009796032634

Epoch: 480| Step: 0
Training loss: 1.0212640761825937
Validation loss: 2.225829842444389

Epoch: 6| Step: 1
Training loss: 0.6028657148335482
Validation loss: 2.3137176830856503

Epoch: 6| Step: 2
Training loss: 1.025860139438204
Validation loss: 2.295470768295146

Epoch: 6| Step: 3
Training loss: 0.6208454091435904
Validation loss: 2.297623447171322

Epoch: 6| Step: 4
Training loss: 0.5509965624554917
Validation loss: 2.2692256594179474

Epoch: 6| Step: 5
Training loss: 0.8186830959211804
Validation loss: 2.29075665421209

Epoch: 6| Step: 6
Training loss: 1.794561140237472
Validation loss: 2.3319818868648294

Epoch: 6| Step: 7
Training loss: 0.9014463379598657
Validation loss: 2.23780507725457

Epoch: 6| Step: 8
Training loss: 0.8874555039332884
Validation loss: 2.310508375358783

Epoch: 6| Step: 9
Training loss: 0.890311537340741
Validation loss: 2.344801469887697

Epoch: 6| Step: 10
Training loss: 0.6900174908217902
Validation loss: 2.2114080994062553

Epoch: 6| Step: 11
Training loss: 0.9796035718483563
Validation loss: 2.2964120476021956

Epoch: 6| Step: 12
Training loss: 1.120554352302979
Validation loss: 2.2396813930402915

Epoch: 6| Step: 13
Training loss: 0.6376425004153005
Validation loss: 2.3006161727112127

Epoch: 481| Step: 0
Training loss: 0.918624578725272
Validation loss: 2.341829787347393

Epoch: 6| Step: 1
Training loss: 1.723200359612926
Validation loss: 2.2834577796049746

Epoch: 6| Step: 2
Training loss: 1.0095180894271059
Validation loss: 2.26877534570189

Epoch: 6| Step: 3
Training loss: 0.8904107823323978
Validation loss: 2.341176230625094

Epoch: 6| Step: 4
Training loss: 0.8151077091680375
Validation loss: 2.2357623618262874

Epoch: 6| Step: 5
Training loss: 0.9471206711439469
Validation loss: 2.2869450371652738

Epoch: 6| Step: 6
Training loss: 1.095697358740119
Validation loss: 2.2526553879680056

Epoch: 6| Step: 7
Training loss: 1.001306574314928
Validation loss: 2.2432217640250363

Epoch: 6| Step: 8
Training loss: 0.6835757007940858
Validation loss: 2.3259853968381927

Epoch: 6| Step: 9
Training loss: 0.7268880299444179
Validation loss: 2.2755833289588865

Epoch: 6| Step: 10
Training loss: 0.8012601583375473
Validation loss: 2.280203276416458

Epoch: 6| Step: 11
Training loss: 0.6153455845669529
Validation loss: 2.40530574400962

Epoch: 6| Step: 12
Training loss: 0.6755746073460649
Validation loss: 2.250053906450131

Epoch: 6| Step: 13
Training loss: 1.0358399058957215
Validation loss: 2.356708183990098

Epoch: 482| Step: 0
Training loss: 0.7665030057690158
Validation loss: 2.319385118810405

Epoch: 6| Step: 1
Training loss: 0.9258223898716132
Validation loss: 2.343493173398802

Epoch: 6| Step: 2
Training loss: 1.0345937100055365
Validation loss: 2.390701856777832

Epoch: 6| Step: 3
Training loss: 0.9210259358402219
Validation loss: 2.357905890416077

Epoch: 6| Step: 4
Training loss: 0.9533420690778707
Validation loss: 2.348807276541746

Epoch: 6| Step: 5
Training loss: 0.8324318579545504
Validation loss: 2.2812416002335527

Epoch: 6| Step: 6
Training loss: 0.7114162300426974
Validation loss: 2.35046217671094

Epoch: 6| Step: 7
Training loss: 0.8070459709782063
Validation loss: 2.2290405507639326

Epoch: 6| Step: 8
Training loss: 1.0227329070966784
Validation loss: 2.2547183787820892

Epoch: 6| Step: 9
Training loss: 0.722619957914712
Validation loss: 2.2181665891852096

Epoch: 6| Step: 10
Training loss: 0.8396357788920614
Validation loss: 2.264315007560559

Epoch: 6| Step: 11
Training loss: 1.6926018627623025
Validation loss: 2.3595630038697

Epoch: 6| Step: 12
Training loss: 0.821378650836555
Validation loss: 2.2591278619539414

Epoch: 6| Step: 13
Training loss: 0.8470339974220021
Validation loss: 2.2701349560889494

Epoch: 483| Step: 0
Training loss: 0.8607501731382667
Validation loss: 2.2980990078000216

Epoch: 6| Step: 1
Training loss: 0.7238906627469673
Validation loss: 2.3216680395051332

Epoch: 6| Step: 2
Training loss: 0.8019693260581741
Validation loss: 2.313503909962398

Epoch: 6| Step: 3
Training loss: 0.9179271932082903
Validation loss: 2.230071901701539

Epoch: 6| Step: 4
Training loss: 0.6795208386825096
Validation loss: 2.305388180976094

Epoch: 6| Step: 5
Training loss: 1.1243336081400344
Validation loss: 2.2994497006021093

Epoch: 6| Step: 6
Training loss: 1.0169348852792037
Validation loss: 2.2480258912339597

Epoch: 6| Step: 7
Training loss: 0.5556046868162988
Validation loss: 2.2546230116345503

Epoch: 6| Step: 8
Training loss: 1.8090627898352585
Validation loss: 2.3438822194202937

Epoch: 6| Step: 9
Training loss: 0.7350572298436886
Validation loss: 2.327497835123599

Epoch: 6| Step: 10
Training loss: 0.9439574373659557
Validation loss: 2.411630967741962

Epoch: 6| Step: 11
Training loss: 0.8363937131276006
Validation loss: 2.2688785285264954

Epoch: 6| Step: 12
Training loss: 0.8706750590548896
Validation loss: 2.263305253848989

Epoch: 6| Step: 13
Training loss: 0.9603463812628752
Validation loss: 2.3250542150856877

Epoch: 484| Step: 0
Training loss: 0.5172369930407467
Validation loss: 2.295056357858284

Epoch: 6| Step: 1
Training loss: 1.070386452451998
Validation loss: 2.32937797573909

Epoch: 6| Step: 2
Training loss: 0.9513920836538119
Validation loss: 2.2806674293760936

Epoch: 6| Step: 3
Training loss: 1.038016631862306
Validation loss: 2.375182021224869

Epoch: 6| Step: 4
Training loss: 0.9286454716180912
Validation loss: 2.2733638554020086

Epoch: 6| Step: 5
Training loss: 0.777084805859627
Validation loss: 2.300789592358771

Epoch: 6| Step: 6
Training loss: 0.6982832463070119
Validation loss: 2.3506887465158646

Epoch: 6| Step: 7
Training loss: 0.8790827595111641
Validation loss: 2.3294706819548354

Epoch: 6| Step: 8
Training loss: 1.058904735873129
Validation loss: 2.3253616326101603

Epoch: 6| Step: 9
Training loss: 0.8597390877468503
Validation loss: 2.2721161716213945

Epoch: 6| Step: 10
Training loss: 1.8683690757746867
Validation loss: 2.3130382237425087

Epoch: 6| Step: 11
Training loss: 0.580209787756183
Validation loss: 2.3571665760930323

Epoch: 6| Step: 12
Training loss: 0.8389114883324671
Validation loss: 2.2928042026346667

Epoch: 6| Step: 13
Training loss: 1.1622141558428218
Validation loss: 2.2426366628762144

Epoch: 485| Step: 0
Training loss: 0.9923070400044817
Validation loss: 2.3206557771970866

Epoch: 6| Step: 1
Training loss: 0.7775427022166993
Validation loss: 2.2874538578024146

Epoch: 6| Step: 2
Training loss: 0.8263021596352901
Validation loss: 2.298870278968141

Epoch: 6| Step: 3
Training loss: 0.7839565696024022
Validation loss: 2.239796414914128

Epoch: 6| Step: 4
Training loss: 0.6073328179822397
Validation loss: 2.3123536666426947

Epoch: 6| Step: 5
Training loss: 0.9483085004128463
Validation loss: 2.236423572467095

Epoch: 6| Step: 6
Training loss: 0.8399761006951774
Validation loss: 2.279764208223886

Epoch: 6| Step: 7
Training loss: 1.955119647977045
Validation loss: 2.289127312957487

Epoch: 6| Step: 8
Training loss: 0.9098685141299626
Validation loss: 2.366240404637838

Epoch: 6| Step: 9
Training loss: 0.6290133841111011
Validation loss: 2.2874478906956206

Epoch: 6| Step: 10
Training loss: 0.9169316703481581
Validation loss: 2.3038195177435723

Epoch: 6| Step: 11
Training loss: 1.106065892131299
Validation loss: 2.2891971355768748

Epoch: 6| Step: 12
Training loss: 0.8917129965062316
Validation loss: 2.2797192219163906

Epoch: 6| Step: 13
Training loss: 0.4625282317643561
Validation loss: 2.300896843628532

Epoch: 486| Step: 0
Training loss: 1.1791754615554555
Validation loss: 2.4233977665462487

Epoch: 6| Step: 1
Training loss: 0.6792479880818774
Validation loss: 2.3257782593611775

Epoch: 6| Step: 2
Training loss: 0.9538350821525738
Validation loss: 2.323920887954622

Epoch: 6| Step: 3
Training loss: 0.8089114684477627
Validation loss: 2.280162667897131

Epoch: 6| Step: 4
Training loss: 1.1416409292359673
Validation loss: 2.3225829417548907

Epoch: 6| Step: 5
Training loss: 0.4911677984326676
Validation loss: 2.2498448340032424

Epoch: 6| Step: 6
Training loss: 0.8342047585533873
Validation loss: 2.280469485557299

Epoch: 6| Step: 7
Training loss: 0.7501327873935649
Validation loss: 2.2338907417087652

Epoch: 6| Step: 8
Training loss: 1.903908839672082
Validation loss: 2.2988975888624847

Epoch: 6| Step: 9
Training loss: 0.9550572180458698
Validation loss: 2.2162022236000727

Epoch: 6| Step: 10
Training loss: 0.6557017943042537
Validation loss: 2.2054554821210446

Epoch: 6| Step: 11
Training loss: 0.7768914138275289
Validation loss: 2.1966719056264807

Epoch: 6| Step: 12
Training loss: 1.0336179423366327
Validation loss: 2.1917922619325774

Epoch: 6| Step: 13
Training loss: 1.0554795293589316
Validation loss: 2.3082293420339606

Epoch: 487| Step: 0
Training loss: 1.2048651261252066
Validation loss: 2.234764717983849

Epoch: 6| Step: 1
Training loss: 0.8629313316431434
Validation loss: 2.2090825340251468

Epoch: 6| Step: 2
Training loss: 0.7591554991664572
Validation loss: 2.202334162342198

Epoch: 6| Step: 3
Training loss: 1.078120079582154
Validation loss: 2.259377249410218

Epoch: 6| Step: 4
Training loss: 1.1882484486684337
Validation loss: 2.269208487267201

Epoch: 6| Step: 5
Training loss: 0.6309381677889491
Validation loss: 2.3291555775948147

Epoch: 6| Step: 6
Training loss: 0.7317205300921419
Validation loss: 2.283783536731302

Epoch: 6| Step: 7
Training loss: 0.6629638559492093
Validation loss: 2.295439612556935

Epoch: 6| Step: 8
Training loss: 0.7769159644720869
Validation loss: 2.281112665640792

Epoch: 6| Step: 9
Training loss: 0.9365687831684448
Validation loss: 2.2666024481123013

Epoch: 6| Step: 10
Training loss: 0.7338429410647579
Validation loss: 2.36909458510056

Epoch: 6| Step: 11
Training loss: 0.8236530405500094
Validation loss: 2.272144930812244

Epoch: 6| Step: 12
Training loss: 0.48537771971925714
Validation loss: 2.2623741547294656

Epoch: 6| Step: 13
Training loss: 2.2358085461850465
Validation loss: 2.3461895694511847

Epoch: 488| Step: 0
Training loss: 0.6627393443137038
Validation loss: 2.227359826287644

Epoch: 6| Step: 1
Training loss: 0.6850169598087901
Validation loss: 2.2532660468909955

Epoch: 6| Step: 2
Training loss: 0.85206127433546
Validation loss: 2.2906851175730907

Epoch: 6| Step: 3
Training loss: 0.9438141226300159
Validation loss: 2.2271293685644413

Epoch: 6| Step: 4
Training loss: 0.4922296415180761
Validation loss: 2.350353022188772

Epoch: 6| Step: 5
Training loss: 1.2830399361577074
Validation loss: 2.2792434090697133

Epoch: 6| Step: 6
Training loss: 0.9928350663254577
Validation loss: 2.3110227486510047

Epoch: 6| Step: 7
Training loss: 0.9674215745313169
Validation loss: 2.2783282886984018

Epoch: 6| Step: 8
Training loss: 0.9332731965536767
Validation loss: 2.263170864906033

Epoch: 6| Step: 9
Training loss: 0.8013722913497254
Validation loss: 2.205726126568146

Epoch: 6| Step: 10
Training loss: 0.9856975088014689
Validation loss: 2.1928944968430297

Epoch: 6| Step: 11
Training loss: 0.9624448289788485
Validation loss: 2.3506696861748897

Epoch: 6| Step: 12
Training loss: 0.8836019244098386
Validation loss: 2.295939214896526

Epoch: 6| Step: 13
Training loss: 2.2690980796614526
Validation loss: 2.280511122552027

Epoch: 489| Step: 0
Training loss: 0.8021386527929216
Validation loss: 2.278925394702015

Epoch: 6| Step: 1
Training loss: 0.9805200570956941
Validation loss: 2.261296426905763

Epoch: 6| Step: 2
Training loss: 0.7727075850941757
Validation loss: 2.2759138577197104

Epoch: 6| Step: 3
Training loss: 0.9758795219151465
Validation loss: 2.2487946441231177

Epoch: 6| Step: 4
Training loss: 0.7263015770776479
Validation loss: 2.2367445043728775

Epoch: 6| Step: 5
Training loss: 0.700547984753986
Validation loss: 2.3192033958883385

Epoch: 6| Step: 6
Training loss: 0.7101279879444866
Validation loss: 2.373915543990613

Epoch: 6| Step: 7
Training loss: 1.034081588573543
Validation loss: 2.2524347593808027

Epoch: 6| Step: 8
Training loss: 0.946914167192119
Validation loss: 2.2127135818467565

Epoch: 6| Step: 9
Training loss: 0.7506252702367902
Validation loss: 2.311119401364462

Epoch: 6| Step: 10
Training loss: 0.7267071979779872
Validation loss: 2.2891262882299883

Epoch: 6| Step: 11
Training loss: 1.8728293888292322
Validation loss: 2.236670031009135

Epoch: 6| Step: 12
Training loss: 1.1237002918252195
Validation loss: 2.1808460015077156

Epoch: 6| Step: 13
Training loss: 0.5926583946746391
Validation loss: 2.21542947798182

Epoch: 490| Step: 0
Training loss: 1.0485313180258287
Validation loss: 2.2684533540905916

Epoch: 6| Step: 1
Training loss: 0.7338491139577533
Validation loss: 2.3174570937184393

Epoch: 6| Step: 2
Training loss: 0.5808544936035932
Validation loss: 2.31179352012316

Epoch: 6| Step: 3
Training loss: 1.1006337572623452
Validation loss: 2.216581099395542

Epoch: 6| Step: 4
Training loss: 0.4562256388496568
Validation loss: 2.2863712574984474

Epoch: 6| Step: 5
Training loss: 0.7615441146591114
Validation loss: 2.2521933674249874

Epoch: 6| Step: 6
Training loss: 0.8457827277305403
Validation loss: 2.291899536323265

Epoch: 6| Step: 7
Training loss: 0.7299879807305791
Validation loss: 2.27544445946096

Epoch: 6| Step: 8
Training loss: 1.0411068302015865
Validation loss: 2.307915436416233

Epoch: 6| Step: 9
Training loss: 0.8423645159058625
Validation loss: 2.290235568884728

Epoch: 6| Step: 10
Training loss: 0.8008676621869127
Validation loss: 2.270101788600248

Epoch: 6| Step: 11
Training loss: 1.7028215470461356
Validation loss: 2.304843273429004

Epoch: 6| Step: 12
Training loss: 0.869073209398243
Validation loss: 2.2533684216431946

Epoch: 6| Step: 13
Training loss: 1.0443002152847904
Validation loss: 2.2777046853763663

Epoch: 491| Step: 0
Training loss: 0.8558200480672132
Validation loss: 2.335220026439758

Epoch: 6| Step: 1
Training loss: 1.011204887298652
Validation loss: 2.1889372245596466

Epoch: 6| Step: 2
Training loss: 0.6631768098342928
Validation loss: 2.252030547910882

Epoch: 6| Step: 3
Training loss: 1.1199197503699436
Validation loss: 2.2198681068614508

Epoch: 6| Step: 4
Training loss: 0.6306688239424963
Validation loss: 2.255156911586622

Epoch: 6| Step: 5
Training loss: 0.726974083599863
Validation loss: 2.2713386520573455

Epoch: 6| Step: 6
Training loss: 0.6720247323616607
Validation loss: 2.250698164723677

Epoch: 6| Step: 7
Training loss: 0.6171491586871835
Validation loss: 2.305206969436261

Epoch: 6| Step: 8
Training loss: 0.6424148027359438
Validation loss: 2.2515501871358934

Epoch: 6| Step: 9
Training loss: 2.0135794025430083
Validation loss: 2.309395143325399

Epoch: 6| Step: 10
Training loss: 0.8470942308507076
Validation loss: 2.2962757517856036

Epoch: 6| Step: 11
Training loss: 0.8688918196919253
Validation loss: 2.230982241109054

Epoch: 6| Step: 12
Training loss: 0.7223158988559096
Validation loss: 2.3224925650951342

Epoch: 6| Step: 13
Training loss: 0.5604453709376047
Validation loss: 2.356279486997767

Epoch: 492| Step: 0
Training loss: 1.040958367181219
Validation loss: 2.2864694203806324

Epoch: 6| Step: 1
Training loss: 1.0683391785325358
Validation loss: 2.2558570782609304

Epoch: 6| Step: 2
Training loss: 1.803732681349887
Validation loss: 2.2736029133964926

Epoch: 6| Step: 3
Training loss: 0.6369411337584778
Validation loss: 2.2705805911527785

Epoch: 6| Step: 4
Training loss: 0.8365775180590088
Validation loss: 2.249762266171735

Epoch: 6| Step: 5
Training loss: 0.8476763252658583
Validation loss: 2.253566196276156

Epoch: 6| Step: 6
Training loss: 0.6281860445260199
Validation loss: 2.313423837466361

Epoch: 6| Step: 7
Training loss: 0.45056033282870667
Validation loss: 2.2789975125164967

Epoch: 6| Step: 8
Training loss: 1.035372499154587
Validation loss: 2.301719467129995

Epoch: 6| Step: 9
Training loss: 0.914295003941719
Validation loss: 2.251096721375911

Epoch: 6| Step: 10
Training loss: 0.566591114262131
Validation loss: 2.295132447380462

Epoch: 6| Step: 11
Training loss: 0.8289256633818592
Validation loss: 2.2593070067623393

Epoch: 6| Step: 12
Training loss: 1.2504814174572463
Validation loss: 2.2805146411443813

Epoch: 6| Step: 13
Training loss: 1.1228181556327772
Validation loss: 2.2511601003868984

Epoch: 493| Step: 0
Training loss: 0.6577726139108981
Validation loss: 2.3009059120185698

Epoch: 6| Step: 1
Training loss: 1.0193439764731684
Validation loss: 2.189636000359499

Epoch: 6| Step: 2
Training loss: 0.961154386033695
Validation loss: 2.2513933220152045

Epoch: 6| Step: 3
Training loss: 1.9491052384283283
Validation loss: 2.32842436772999

Epoch: 6| Step: 4
Training loss: 0.5746694340233578
Validation loss: 2.240913943259965

Epoch: 6| Step: 5
Training loss: 0.8903327596280063
Validation loss: 2.2099950725407873

Epoch: 6| Step: 6
Training loss: 1.268629581393153
Validation loss: 2.209322045372991

Epoch: 6| Step: 7
Training loss: 0.9133248572466725
Validation loss: 2.2838228157866207

Epoch: 6| Step: 8
Training loss: 0.6103830558281181
Validation loss: 2.321582772277621

Epoch: 6| Step: 9
Training loss: 0.697978021762086
Validation loss: 2.2483743220452603

Epoch: 6| Step: 10
Training loss: 0.8270339256025687
Validation loss: 2.281424573735772

Epoch: 6| Step: 11
Training loss: 0.7901011514490909
Validation loss: 2.2764944803761953

Epoch: 6| Step: 12
Training loss: 0.9004670811958213
Validation loss: 2.260469235196031

Epoch: 6| Step: 13
Training loss: 0.5504485945161209
Validation loss: 2.2591899382051954

Epoch: 494| Step: 0
Training loss: 0.7360283927105656
Validation loss: 2.2567700949176177

Epoch: 6| Step: 1
Training loss: 1.636172620023339
Validation loss: 2.296567483171814

Epoch: 6| Step: 2
Training loss: 0.7729879671988656
Validation loss: 2.247276334820348

Epoch: 6| Step: 3
Training loss: 0.7814848737515825
Validation loss: 2.2859412137439334

Epoch: 6| Step: 4
Training loss: 0.9680564612796827
Validation loss: 2.2594723160458097

Epoch: 6| Step: 5
Training loss: 0.7169217201048006
Validation loss: 2.295751683573043

Epoch: 6| Step: 6
Training loss: 0.57764043347284
Validation loss: 2.2999043547765146

Epoch: 6| Step: 7
Training loss: 0.653292690998978
Validation loss: 2.3655697191504514

Epoch: 6| Step: 8
Training loss: 0.9564459431673245
Validation loss: 2.3052255910645174

Epoch: 6| Step: 9
Training loss: 0.8481201449475234
Validation loss: 2.277896474414594

Epoch: 6| Step: 10
Training loss: 1.1161275250097322
Validation loss: 2.2697172339516123

Epoch: 6| Step: 11
Training loss: 0.9308150690302369
Validation loss: 2.267811135128365

Epoch: 6| Step: 12
Training loss: 0.834742503008861
Validation loss: 2.2313640077847534

Epoch: 6| Step: 13
Training loss: 0.5644426443849523
Validation loss: 2.2530305146812792

Epoch: 495| Step: 0
Training loss: 0.7283939536099806
Validation loss: 2.388187040119175

Epoch: 6| Step: 1
Training loss: 0.9203037514133132
Validation loss: 2.230575839112337

Epoch: 6| Step: 2
Training loss: 0.810718527393276
Validation loss: 2.323258254046478

Epoch: 6| Step: 3
Training loss: 0.8219852649129106
Validation loss: 2.3157776859947026

Epoch: 6| Step: 4
Training loss: 1.0366327084767948
Validation loss: 2.2637894835487704

Epoch: 6| Step: 5
Training loss: 0.8543757593671972
Validation loss: 2.223880597491547

Epoch: 6| Step: 6
Training loss: 0.8891918631299333
Validation loss: 2.215287566116493

Epoch: 6| Step: 7
Training loss: 0.7123431886477056
Validation loss: 2.375155977568645

Epoch: 6| Step: 8
Training loss: 0.5694427651739817
Validation loss: 2.286160960833682

Epoch: 6| Step: 9
Training loss: 0.9647521311392159
Validation loss: 2.244015648443412

Epoch: 6| Step: 10
Training loss: 1.847937016194089
Validation loss: 2.2443230382038215

Epoch: 6| Step: 11
Training loss: 0.6570242900683871
Validation loss: 2.308930192013476

Epoch: 6| Step: 12
Training loss: 0.6999552380350916
Validation loss: 2.2840808397608043

Epoch: 6| Step: 13
Training loss: 0.8633613376665887
Validation loss: 2.3357153927641607

Epoch: 496| Step: 0
Training loss: 0.8703602666433744
Validation loss: 2.312782456592581

Epoch: 6| Step: 1
Training loss: 1.890829658465501
Validation loss: 2.258752661692888

Epoch: 6| Step: 2
Training loss: 0.863715153390097
Validation loss: 2.244448138136525

Epoch: 6| Step: 3
Training loss: 0.915225080311852
Validation loss: 2.310734067914966

Epoch: 6| Step: 4
Training loss: 0.7425927110069239
Validation loss: 2.2529744779171508

Epoch: 6| Step: 5
Training loss: 1.012951074599292
Validation loss: 2.2509577466292963

Epoch: 6| Step: 6
Training loss: 0.7071348504305387
Validation loss: 2.151597532172018

Epoch: 6| Step: 7
Training loss: 0.9499479405042541
Validation loss: 2.275131426159761

Epoch: 6| Step: 8
Training loss: 0.7534550715153329
Validation loss: 2.3465703717780464

Epoch: 6| Step: 9
Training loss: 0.823284758963775
Validation loss: 2.3244036879346313

Epoch: 6| Step: 10
Training loss: 0.6483028915592042
Validation loss: 2.276798212569685

Epoch: 6| Step: 11
Training loss: 0.6725553793599792
Validation loss: 2.3845638534361946

Epoch: 6| Step: 12
Training loss: 0.9271966600624536
Validation loss: 2.2430709316743807

Epoch: 6| Step: 13
Training loss: 1.0032784246604833
Validation loss: 2.2604693043772763

Epoch: 497| Step: 0
Training loss: 0.9261398586626374
Validation loss: 2.253773874176827

Epoch: 6| Step: 1
Training loss: 0.7030247086948377
Validation loss: 2.32265775203182

Epoch: 6| Step: 2
Training loss: 0.779137157622574
Validation loss: 2.2575007829278784

Epoch: 6| Step: 3
Training loss: 0.5953821036431407
Validation loss: 2.2782679553810605

Epoch: 6| Step: 4
Training loss: 0.7152422018576052
Validation loss: 2.2266669867192164

Epoch: 6| Step: 5
Training loss: 1.7911756936930783
Validation loss: 2.264138038945797

Epoch: 6| Step: 6
Training loss: 0.8465366616711737
Validation loss: 2.3084412142597013

Epoch: 6| Step: 7
Training loss: 1.0672843587549348
Validation loss: 2.2781012090205963

Epoch: 6| Step: 8
Training loss: 0.927572585604788
Validation loss: 2.323727998034772

Epoch: 6| Step: 9
Training loss: 0.7648423534844248
Validation loss: 2.23640889388542

Epoch: 6| Step: 10
Training loss: 0.9732315629397938
Validation loss: 2.225087637729119

Epoch: 6| Step: 11
Training loss: 1.0822889110736935
Validation loss: 2.2500005161462555

Epoch: 6| Step: 12
Training loss: 0.8459298620594353
Validation loss: 2.22975936081568

Epoch: 6| Step: 13
Training loss: 0.4101332703465451
Validation loss: 2.281584628751108

Epoch: 498| Step: 0
Training loss: 0.8806599393347494
Validation loss: 2.321803286669202

Epoch: 6| Step: 1
Training loss: 0.8134969317208957
Validation loss: 2.2730965927654094

Epoch: 6| Step: 2
Training loss: 0.6308201166462452
Validation loss: 2.347583191332914

Epoch: 6| Step: 3
Training loss: 0.5121316772539601
Validation loss: 2.2421694095924107

Epoch: 6| Step: 4
Training loss: 0.7755410459269977
Validation loss: 2.301360917922763

Epoch: 6| Step: 5
Training loss: 0.9466939872730472
Validation loss: 2.28533003175816

Epoch: 6| Step: 6
Training loss: 0.8848122759176968
Validation loss: 2.2539718822256596

Epoch: 6| Step: 7
Training loss: 1.8538672673386485
Validation loss: 2.2520583683268

Epoch: 6| Step: 8
Training loss: 0.8423680184557999
Validation loss: 2.2945172389385813

Epoch: 6| Step: 9
Training loss: 0.9851730381550883
Validation loss: 2.3046137582957873

Epoch: 6| Step: 10
Training loss: 0.7837723259430538
Validation loss: 2.258702988717171

Epoch: 6| Step: 11
Training loss: 0.6764270585230655
Validation loss: 2.2821445382861794

Epoch: 6| Step: 12
Training loss: 0.8515867527299138
Validation loss: 2.2700199666133773

Epoch: 6| Step: 13
Training loss: 0.5084513826825415
Validation loss: 2.258236596257119

Epoch: 499| Step: 0
Training loss: 0.6359466833252928
Validation loss: 2.2303794741110043

Epoch: 6| Step: 1
Training loss: 0.775806536459277
Validation loss: 2.2604729361061455

Epoch: 6| Step: 2
Training loss: 0.764138159877107
Validation loss: 2.3000677856275833

Epoch: 6| Step: 3
Training loss: 0.8974543624155567
Validation loss: 2.3185136123125254

Epoch: 6| Step: 4
Training loss: 1.215821243959859
Validation loss: 2.281492410597892

Epoch: 6| Step: 5
Training loss: 1.8141049481139746
Validation loss: 2.3041029925674517

Epoch: 6| Step: 6
Training loss: 0.5908462897020316
Validation loss: 2.2641462094712366

Epoch: 6| Step: 7
Training loss: 0.9647067818353556
Validation loss: 2.2351246580222544

Epoch: 6| Step: 8
Training loss: 0.7698021426453756
Validation loss: 2.3069792768219

Epoch: 6| Step: 9
Training loss: 0.9874651105970549
Validation loss: 2.2353799987720895

Epoch: 6| Step: 10
Training loss: 0.6682779589169057
Validation loss: 2.2836412603317027

Epoch: 6| Step: 11
Training loss: 0.8167184844088665
Validation loss: 2.2729385798863215

Epoch: 6| Step: 12
Training loss: 0.8542137869576812
Validation loss: 2.2987502189754383

Epoch: 6| Step: 13
Training loss: 0.8891381015378107
Validation loss: 2.2145164004622218

Epoch: 500| Step: 0
Training loss: 0.8775854061547658
Validation loss: 2.3643170461097043

Epoch: 6| Step: 1
Training loss: 0.955596471127381
Validation loss: 2.2170174567778322

Epoch: 6| Step: 2
Training loss: 0.5651436775798179
Validation loss: 2.1781568942395837

Epoch: 6| Step: 3
Training loss: 0.5941397241188057
Validation loss: 2.2550606302086305

Epoch: 6| Step: 4
Training loss: 0.6798677095940057
Validation loss: 2.2261882923044407

Epoch: 6| Step: 5
Training loss: 0.96894013169512
Validation loss: 2.23859598460009

Epoch: 6| Step: 6
Training loss: 0.8777981024077793
Validation loss: 2.2875325472344326

Epoch: 6| Step: 7
Training loss: 0.9310649956880165
Validation loss: 2.2535242795739365

Epoch: 6| Step: 8
Training loss: 1.6794226859065653
Validation loss: 2.3273246574862765

Epoch: 6| Step: 9
Training loss: 0.724627019045315
Validation loss: 2.2699320841971584

Epoch: 6| Step: 10
Training loss: 0.7766365399745842
Validation loss: 2.273413378321809

Epoch: 6| Step: 11
Training loss: 0.7024157443716161
Validation loss: 2.254237921489343

Epoch: 6| Step: 12
Training loss: 0.9474174771065665
Validation loss: 2.202994353290408

Epoch: 6| Step: 13
Training loss: 0.7865550169136029
Validation loss: 2.253167348823287

Epoch: 501| Step: 0
Training loss: 1.0747673159879445
Validation loss: 2.260220522872132

Epoch: 6| Step: 1
Training loss: 0.9630534129239194
Validation loss: 2.2915305801063868

Epoch: 6| Step: 2
Training loss: 0.6526423701627132
Validation loss: 2.232361199032379

Epoch: 6| Step: 3
Training loss: 0.47706700807927993
Validation loss: 2.264455656607908

Epoch: 6| Step: 4
Training loss: 1.7724511852994456
Validation loss: 2.293204820727513

Epoch: 6| Step: 5
Training loss: 0.678401519720944
Validation loss: 2.3122509270973115

Epoch: 6| Step: 6
Training loss: 0.7241491208147589
Validation loss: 2.235308381567084

Epoch: 6| Step: 7
Training loss: 0.7778622991943198
Validation loss: 2.259738795714421

Epoch: 6| Step: 8
Training loss: 1.164224907727328
Validation loss: 2.282918032818496

Epoch: 6| Step: 9
Training loss: 0.8253062517882211
Validation loss: 2.235791470535972

Epoch: 6| Step: 10
Training loss: 0.7527785489671549
Validation loss: 2.331141571573459

Epoch: 6| Step: 11
Training loss: 0.7654659728891237
Validation loss: 2.153578654013963

Epoch: 6| Step: 12
Training loss: 0.821484192155717
Validation loss: 2.2593763643698432

Epoch: 6| Step: 13
Training loss: 1.2101778662606009
Validation loss: 2.2230414715572073

Epoch: 502| Step: 0
Training loss: 1.1689734586993645
Validation loss: 2.2920167690969295

Epoch: 6| Step: 1
Training loss: 0.8710075301535737
Validation loss: 2.239532965408264

Epoch: 6| Step: 2
Training loss: 1.7924637093587936
Validation loss: 2.2748333270980545

Epoch: 6| Step: 3
Training loss: 0.691253903948778
Validation loss: 2.278736979593877

Epoch: 6| Step: 4
Training loss: 0.830843547890895
Validation loss: 2.2711157990466315

Epoch: 6| Step: 5
Training loss: 0.5778437781030398
Validation loss: 2.2458218648676564

Epoch: 6| Step: 6
Training loss: 0.7721235114600921
Validation loss: 2.2514449234702627

Epoch: 6| Step: 7
Training loss: 1.0543986737409363
Validation loss: 2.3012740535750873

Epoch: 6| Step: 8
Training loss: 0.9684488997599346
Validation loss: 2.3167050262035103

Epoch: 6| Step: 9
Training loss: 0.5565457982722477
Validation loss: 2.2643945245775443

Epoch: 6| Step: 10
Training loss: 0.6471154397277076
Validation loss: 2.286799757958392

Epoch: 6| Step: 11
Training loss: 0.832495331622257
Validation loss: 2.2806568900270294

Epoch: 6| Step: 12
Training loss: 0.6870015678387872
Validation loss: 2.288464066020892

Epoch: 6| Step: 13
Training loss: 0.8436016729455841
Validation loss: 2.3107164506364093

Epoch: 503| Step: 0
Training loss: 0.8195833507809995
Validation loss: 2.2346016731367833

Epoch: 6| Step: 1
Training loss: 0.8862343696109053
Validation loss: 2.278602975937449

Epoch: 6| Step: 2
Training loss: 0.6351140166595963
Validation loss: 2.2584609482806943

Epoch: 6| Step: 3
Training loss: 0.48057117765988533
Validation loss: 2.2046804564080866

Epoch: 6| Step: 4
Training loss: 1.707139978503293
Validation loss: 2.315580788613321

Epoch: 6| Step: 5
Training loss: 0.5961795090246695
Validation loss: 2.295030268420085

Epoch: 6| Step: 6
Training loss: 0.8737380600796991
Validation loss: 2.222597539348968

Epoch: 6| Step: 7
Training loss: 0.9578741293366447
Validation loss: 2.260520704323155

Epoch: 6| Step: 8
Training loss: 0.9492738809783972
Validation loss: 2.2736104415880973

Epoch: 6| Step: 9
Training loss: 0.7967583065982436
Validation loss: 2.19325232841544

Epoch: 6| Step: 10
Training loss: 0.8800274627366726
Validation loss: 2.266006589217952

Epoch: 6| Step: 11
Training loss: 0.6864545632945274
Validation loss: 2.23521155374223

Epoch: 6| Step: 12
Training loss: 1.0055633405579603
Validation loss: 2.2601692306608414

Epoch: 6| Step: 13
Training loss: 1.0490900774556229
Validation loss: 2.283994091019324

Epoch: 504| Step: 0
Training loss: 0.7734639327031131
Validation loss: 2.336989690907591

Epoch: 6| Step: 1
Training loss: 0.8273408163881388
Validation loss: 2.3588932585664386

Epoch: 6| Step: 2
Training loss: 0.9110129912357715
Validation loss: 2.3327571872476747

Epoch: 6| Step: 3
Training loss: 0.96940775045512
Validation loss: 2.3093874481561487

Epoch: 6| Step: 4
Training loss: 1.6313057842435743
Validation loss: 2.2699204983110617

Epoch: 6| Step: 5
Training loss: 0.7203294565848773
Validation loss: 2.287606875418036

Epoch: 6| Step: 6
Training loss: 0.7883516263217135
Validation loss: 2.2545848368109676

Epoch: 6| Step: 7
Training loss: 0.9388686997282619
Validation loss: 2.261800825816826

Epoch: 6| Step: 8
Training loss: 0.7115141657252152
Validation loss: 2.270980981062973

Epoch: 6| Step: 9
Training loss: 0.7603003966045838
Validation loss: 2.2923275525058426

Epoch: 6| Step: 10
Training loss: 0.6071180460772939
Validation loss: 2.3060407527895066

Epoch: 6| Step: 11
Training loss: 0.6936177806468236
Validation loss: 2.2918895463895645

Epoch: 6| Step: 12
Training loss: 0.5610470019385603
Validation loss: 2.214669043271375

Epoch: 6| Step: 13
Training loss: 0.6097515605548378
Validation loss: 2.205952621999968

Epoch: 505| Step: 0
Training loss: 1.8251029573427147
Validation loss: 2.2689510747104795

Epoch: 6| Step: 1
Training loss: 0.7661291914601315
Validation loss: 2.3097898499171516

Epoch: 6| Step: 2
Training loss: 0.9290863144918242
Validation loss: 2.2323140981123673

Epoch: 6| Step: 3
Training loss: 0.8289444665611038
Validation loss: 2.3244530107245005

Epoch: 6| Step: 4
Training loss: 0.8948464650318914
Validation loss: 2.2995872865599307

Epoch: 6| Step: 5
Training loss: 0.8554168406723398
Validation loss: 2.276965328508231

Epoch: 6| Step: 6
Training loss: 0.7320695767297941
Validation loss: 2.2526453025220508

Epoch: 6| Step: 7
Training loss: 1.0569692160707962
Validation loss: 2.2864807859031244

Epoch: 6| Step: 8
Training loss: 0.970842623904938
Validation loss: 2.322724098785301

Epoch: 6| Step: 9
Training loss: 0.7100633130253148
Validation loss: 2.28900921429293

Epoch: 6| Step: 10
Training loss: 0.7440434990723394
Validation loss: 2.3325349068693613

Epoch: 6| Step: 11
Training loss: 0.8933225236305116
Validation loss: 2.314501305192838

Epoch: 6| Step: 12
Training loss: 0.9459125726475853
Validation loss: 2.240187289702302

Epoch: 6| Step: 13
Training loss: 0.47879860743285874
Validation loss: 2.295258798959997

Epoch: 506| Step: 0
Training loss: 1.1158355856073359
Validation loss: 2.2545004457908475

Epoch: 6| Step: 1
Training loss: 0.927234040915692
Validation loss: 2.296644258799568

Epoch: 6| Step: 2
Training loss: 0.8910782313312434
Validation loss: 2.2379646927132932

Epoch: 6| Step: 3
Training loss: 0.9143704930661793
Validation loss: 2.2655159861441354

Epoch: 6| Step: 4
Training loss: 0.941594148617359
Validation loss: 2.310624976311711

Epoch: 6| Step: 5
Training loss: 0.8795982180019194
Validation loss: 2.2960248663981613

Epoch: 6| Step: 6
Training loss: 0.5504147006550093
Validation loss: 2.2426858812368193

Epoch: 6| Step: 7
Training loss: 0.93102514381341
Validation loss: 2.3376458772277084

Epoch: 6| Step: 8
Training loss: 0.8594319411400307
Validation loss: 2.256858601753203

Epoch: 6| Step: 9
Training loss: 1.6814314194826567
Validation loss: 2.215154976062649

Epoch: 6| Step: 10
Training loss: 0.5185534805887262
Validation loss: 2.2763077527401396

Epoch: 6| Step: 11
Training loss: 0.9319083990588615
Validation loss: 2.22654963663959

Epoch: 6| Step: 12
Training loss: 0.7213230103375756
Validation loss: 2.276705792097071

Epoch: 6| Step: 13
Training loss: 0.6125859978696209
Validation loss: 2.263207055890488

Epoch: 507| Step: 0
Training loss: 0.7254120116401264
Validation loss: 2.287557741580987

Epoch: 6| Step: 1
Training loss: 0.7843978027433582
Validation loss: 2.2639285765080936

Epoch: 6| Step: 2
Training loss: 0.534522746669972
Validation loss: 2.2838761433629697

Epoch: 6| Step: 3
Training loss: 0.8711583750748444
Validation loss: 2.2373906145542906

Epoch: 6| Step: 4
Training loss: 0.6891516439683263
Validation loss: 2.2336559083664405

Epoch: 6| Step: 5
Training loss: 0.8555462249092932
Validation loss: 2.291037121399607

Epoch: 6| Step: 6
Training loss: 0.832528265854106
Validation loss: 2.214270582445579

Epoch: 6| Step: 7
Training loss: 0.8081392863132668
Validation loss: 2.257488483669447

Epoch: 6| Step: 8
Training loss: 0.9797400087828788
Validation loss: 2.2299517699090403

Epoch: 6| Step: 9
Training loss: 0.5216178580333843
Validation loss: 2.24956049209924

Epoch: 6| Step: 10
Training loss: 0.8849186712277575
Validation loss: 2.257283151504157

Epoch: 6| Step: 11
Training loss: 0.9111133503854055
Validation loss: 2.320250409968274

Epoch: 6| Step: 12
Training loss: 1.636846787718271
Validation loss: 2.2454315901598454

Epoch: 6| Step: 13
Training loss: 0.6062211806536018
Validation loss: 2.255978106747179

Epoch: 508| Step: 0
Training loss: 0.8354181120012548
Validation loss: 2.234820294785831

Epoch: 6| Step: 1
Training loss: 0.7741115599798676
Validation loss: 2.218757401759783

Epoch: 6| Step: 2
Training loss: 0.901745585556372
Validation loss: 2.2031738967025025

Epoch: 6| Step: 3
Training loss: 0.7972483788680458
Validation loss: 2.2935641229733332

Epoch: 6| Step: 4
Training loss: 0.7820935844707463
Validation loss: 2.2898327978463113

Epoch: 6| Step: 5
Training loss: 0.8216180131279421
Validation loss: 2.2942141635696225

Epoch: 6| Step: 6
Training loss: 0.7682872340784087
Validation loss: 2.262052688430798

Epoch: 6| Step: 7
Training loss: 0.7059268228872579
Validation loss: 2.2855343461258717

Epoch: 6| Step: 8
Training loss: 1.7066510997126838
Validation loss: 2.263723401546506

Epoch: 6| Step: 9
Training loss: 0.8658664022475625
Validation loss: 2.2310316028164046

Epoch: 6| Step: 10
Training loss: 0.7583726209028183
Validation loss: 2.274215225229

Epoch: 6| Step: 11
Training loss: 0.8742635897812022
Validation loss: 2.1951610378787443

Epoch: 6| Step: 12
Training loss: 0.8022147397155848
Validation loss: 2.2272803182330074

Epoch: 6| Step: 13
Training loss: 0.7941281716889713
Validation loss: 2.2470818353721977

Epoch: 509| Step: 0
Training loss: 1.0911459304457494
Validation loss: 2.2567516442914295

Epoch: 6| Step: 1
Training loss: 0.6202144516487306
Validation loss: 2.2507110381440465

Epoch: 6| Step: 2
Training loss: 1.7971583930736106
Validation loss: 2.3074346050076415

Epoch: 6| Step: 3
Training loss: 0.3211092460215903
Validation loss: 2.310766342380917

Epoch: 6| Step: 4
Training loss: 0.5500669785377827
Validation loss: 2.2614858132854474

Epoch: 6| Step: 5
Training loss: 0.6703935747534042
Validation loss: 2.2610978267011994

Epoch: 6| Step: 6
Training loss: 0.6072701513057184
Validation loss: 2.331562801741246

Epoch: 6| Step: 7
Training loss: 1.243814997675942
Validation loss: 2.272116989642563

Epoch: 6| Step: 8
Training loss: 0.8025087285384132
Validation loss: 2.265516929891987

Epoch: 6| Step: 9
Training loss: 0.7315594694848009
Validation loss: 2.177318868973213

Epoch: 6| Step: 10
Training loss: 0.8056073163017565
Validation loss: 2.2143684336266958

Epoch: 6| Step: 11
Training loss: 0.6832094692766646
Validation loss: 2.248507819562302

Epoch: 6| Step: 12
Training loss: 0.7977771514221869
Validation loss: 2.2978838552981915

Epoch: 6| Step: 13
Training loss: 0.8329111380788782
Validation loss: 2.29852147399466

Epoch: 510| Step: 0
Training loss: 0.9215426735024258
Validation loss: 2.245803235256218

Epoch: 6| Step: 1
Training loss: 0.5975244663528377
Validation loss: 2.32534407295844

Epoch: 6| Step: 2
Training loss: 0.853414498979172
Validation loss: 2.241719426906066

Epoch: 6| Step: 3
Training loss: 0.7359248506467273
Validation loss: 2.270560227185066

Epoch: 6| Step: 4
Training loss: 1.08044592887736
Validation loss: 2.2615506512473447

Epoch: 6| Step: 5
Training loss: 0.8549463079001451
Validation loss: 2.2846652807424475

Epoch: 6| Step: 6
Training loss: 0.9544336996157081
Validation loss: 2.200062217524808

Epoch: 6| Step: 7
Training loss: 0.8356304139423387
Validation loss: 2.2680701018279628

Epoch: 6| Step: 8
Training loss: 1.861550220796726
Validation loss: 2.219612867754138

Epoch: 6| Step: 9
Training loss: 0.7863141531918179
Validation loss: 2.2812284231745834

Epoch: 6| Step: 10
Training loss: 0.810537609369104
Validation loss: 2.2809020600392538

Epoch: 6| Step: 11
Training loss: 0.9162949906735667
Validation loss: 2.3109570083416533

Epoch: 6| Step: 12
Training loss: 0.6440821614751011
Validation loss: 2.2682801899703997

Epoch: 6| Step: 13
Training loss: 1.063320740492663
Validation loss: 2.2526506610609927

Epoch: 511| Step: 0
Training loss: 0.7772908791816081
Validation loss: 2.3219262138838377

Epoch: 6| Step: 1
Training loss: 0.8470233013186146
Validation loss: 2.2401526316817013

Epoch: 6| Step: 2
Training loss: 0.7635920646310109
Validation loss: 2.2417345292974646

Epoch: 6| Step: 3
Training loss: 0.776757599176191
Validation loss: 2.2346788585990662

Epoch: 6| Step: 4
Training loss: 0.7306272773282966
Validation loss: 2.245999562133132

Epoch: 6| Step: 5
Training loss: 0.9908390644208254
Validation loss: 2.250650227613842

Epoch: 6| Step: 6
Training loss: 0.7964869657720363
Validation loss: 2.2818098528924073

Epoch: 6| Step: 7
Training loss: 1.0052203176044263
Validation loss: 2.24105268060801

Epoch: 6| Step: 8
Training loss: 0.80082951842189
Validation loss: 2.341645423196649

Epoch: 6| Step: 9
Training loss: 0.6028072063476626
Validation loss: 2.3192505013533413

Epoch: 6| Step: 10
Training loss: 0.5973737460384869
Validation loss: 2.2812980324271717

Epoch: 6| Step: 11
Training loss: 1.7494899823996837
Validation loss: 2.316136160687679

Epoch: 6| Step: 12
Training loss: 0.5968324306546546
Validation loss: 2.1755191498344963

Epoch: 6| Step: 13
Training loss: 1.0507902123731985
Validation loss: 2.2850594729270006

Epoch: 512| Step: 0
Training loss: 0.6951122638541951
Validation loss: 2.2678471966709726

Epoch: 6| Step: 1
Training loss: 0.5410835967073789
Validation loss: 2.2995775017077267

Epoch: 6| Step: 2
Training loss: 0.9726924966086825
Validation loss: 2.357998873734882

Epoch: 6| Step: 3
Training loss: 1.165920336741931
Validation loss: 2.350062829562973

Epoch: 6| Step: 4
Training loss: 0.5892050613597699
Validation loss: 2.297952994611136

Epoch: 6| Step: 5
Training loss: 0.9574361761947954
Validation loss: 2.3241661886888463

Epoch: 6| Step: 6
Training loss: 1.0332270080459762
Validation loss: 2.2795373430015915

Epoch: 6| Step: 7
Training loss: 0.8953632666556495
Validation loss: 2.2242949347454157

Epoch: 6| Step: 8
Training loss: 0.6383523404185837
Validation loss: 2.2931243116427797

Epoch: 6| Step: 9
Training loss: 0.8389871886710853
Validation loss: 2.274975848957159

Epoch: 6| Step: 10
Training loss: 1.6703905306825397
Validation loss: 2.251380627855505

Epoch: 6| Step: 11
Training loss: 0.7118063846572968
Validation loss: 2.2576271239627577

Epoch: 6| Step: 12
Training loss: 0.7339043021871648
Validation loss: 2.2575999791276598

Epoch: 6| Step: 13
Training loss: 1.368749979097549
Validation loss: 2.2505310137267376

Epoch: 513| Step: 0
Training loss: 0.6536745670482468
Validation loss: 2.308421399731939

Epoch: 6| Step: 1
Training loss: 0.5986954374678227
Validation loss: 2.2738130800000627

Epoch: 6| Step: 2
Training loss: 1.1232100127773723
Validation loss: 2.2637355066833207

Epoch: 6| Step: 3
Training loss: 1.6870371572340384
Validation loss: 2.2560469780699552

Epoch: 6| Step: 4
Training loss: 0.8199639442704566
Validation loss: 2.273205196847295

Epoch: 6| Step: 5
Training loss: 0.9619924445579267
Validation loss: 2.3472644131585247

Epoch: 6| Step: 6
Training loss: 0.6903483168849954
Validation loss: 2.253254073238009

Epoch: 6| Step: 7
Training loss: 0.39418441332625753
Validation loss: 2.260864620206419

Epoch: 6| Step: 8
Training loss: 0.602622942905361
Validation loss: 2.298098170023032

Epoch: 6| Step: 9
Training loss: 0.8633320996252349
Validation loss: 2.2822506314680604

Epoch: 6| Step: 10
Training loss: 0.789785375050975
Validation loss: 2.246892962339096

Epoch: 6| Step: 11
Training loss: 0.8162949773714078
Validation loss: 2.236087746424759

Epoch: 6| Step: 12
Training loss: 0.8473805976972025
Validation loss: 2.227957395128007

Epoch: 6| Step: 13
Training loss: 0.6970604346193512
Validation loss: 2.3080497108852516

Epoch: 514| Step: 0
Training loss: 1.1894623453819557
Validation loss: 2.302094914185369

Epoch: 6| Step: 1
Training loss: 0.563772034817107
Validation loss: 2.2447636115309564

Epoch: 6| Step: 2
Training loss: 0.7504881224076767
Validation loss: 2.234320426129302

Epoch: 6| Step: 3
Training loss: 0.6929467061180364
Validation loss: 2.2989024459405236

Epoch: 6| Step: 4
Training loss: 0.6343443896044563
Validation loss: 2.24715181102295

Epoch: 6| Step: 5
Training loss: 0.6683767087952726
Validation loss: 2.2339413232986756

Epoch: 6| Step: 6
Training loss: 0.747417733185055
Validation loss: 2.310044687697678

Epoch: 6| Step: 7
Training loss: 0.8152167676149277
Validation loss: 2.1953072625033037

Epoch: 6| Step: 8
Training loss: 0.9469532559730471
Validation loss: 2.328852643646009

Epoch: 6| Step: 9
Training loss: 0.8972580839246258
Validation loss: 2.259023979554391

Epoch: 6| Step: 10
Training loss: 1.6884156321469106
Validation loss: 2.2752631954385105

Epoch: 6| Step: 11
Training loss: 0.7180605359604669
Validation loss: 2.1953281890596963

Epoch: 6| Step: 12
Training loss: 0.549978306732648
Validation loss: 2.2978645789676726

Epoch: 6| Step: 13
Training loss: 0.9613873119029638
Validation loss: 2.2489005368388537

Epoch: 515| Step: 0
Training loss: 1.7179082022800816
Validation loss: 2.2814246243023475

Epoch: 6| Step: 1
Training loss: 0.8047909716403089
Validation loss: 2.2668226641545988

Epoch: 6| Step: 2
Training loss: 0.7486180448083216
Validation loss: 2.202918294394986

Epoch: 6| Step: 3
Training loss: 0.743557198161763
Validation loss: 2.239027089217063

Epoch: 6| Step: 4
Training loss: 0.6032759304646967
Validation loss: 2.246400365816148

Epoch: 6| Step: 5
Training loss: 0.6087286529087996
Validation loss: 2.3009328874543167

Epoch: 6| Step: 6
Training loss: 0.8147175677464567
Validation loss: 2.20793670395968

Epoch: 6| Step: 7
Training loss: 0.736013006074678
Validation loss: 2.2755527126480253

Epoch: 6| Step: 8
Training loss: 1.0404336243575203
Validation loss: 2.2953758590476503

Epoch: 6| Step: 9
Training loss: 0.9955772107778679
Validation loss: 2.2112964811347244

Epoch: 6| Step: 10
Training loss: 0.9197537213825946
Validation loss: 2.3390040462738626

Epoch: 6| Step: 11
Training loss: 0.7620270716396381
Validation loss: 2.2842442630266335

Epoch: 6| Step: 12
Training loss: 0.8209691643679917
Validation loss: 2.3384751129235655

Epoch: 6| Step: 13
Training loss: 0.7913500043759473
Validation loss: 2.3006831250105426

Epoch: 516| Step: 0
Training loss: 0.7816036568306229
Validation loss: 2.2441698169525828

Epoch: 6| Step: 1
Training loss: 0.7003083929156789
Validation loss: 2.292569949168252

Epoch: 6| Step: 2
Training loss: 0.8559737435084126
Validation loss: 2.2398706212307142

Epoch: 6| Step: 3
Training loss: 0.6511670767476327
Validation loss: 2.2397600367997432

Epoch: 6| Step: 4
Training loss: 0.9169992724907672
Validation loss: 2.298509391448418

Epoch: 6| Step: 5
Training loss: 0.4266767795892864
Validation loss: 2.2366426163562574

Epoch: 6| Step: 6
Training loss: 0.909727855273433
Validation loss: 2.1474518651914787

Epoch: 6| Step: 7
Training loss: 0.8209167434862216
Validation loss: 2.2319176904933014

Epoch: 6| Step: 8
Training loss: 1.12457553485335
Validation loss: 2.2723197753384854

Epoch: 6| Step: 9
Training loss: 0.6834127786052309
Validation loss: 2.2368470375848353

Epoch: 6| Step: 10
Training loss: 1.7669705015698391
Validation loss: 2.2581249063080935

Epoch: 6| Step: 11
Training loss: 0.7497137636113717
Validation loss: 2.238821817001036

Epoch: 6| Step: 12
Training loss: 0.5588097321501819
Validation loss: 2.3041876761037856

Epoch: 6| Step: 13
Training loss: 0.8013308244190939
Validation loss: 2.243958020457021

Epoch: 517| Step: 0
Training loss: 0.7749604153521997
Validation loss: 2.2662433916113476

Epoch: 6| Step: 1
Training loss: 0.9219837771103508
Validation loss: 2.223773458028627

Epoch: 6| Step: 2
Training loss: 0.8407326186258169
Validation loss: 2.165533164689689

Epoch: 6| Step: 3
Training loss: 0.5379834917028048
Validation loss: 2.2804203527964315

Epoch: 6| Step: 4
Training loss: 0.5497378754209018
Validation loss: 2.2765516220128936

Epoch: 6| Step: 5
Training loss: 0.5422690844099162
Validation loss: 2.2439490241083964

Epoch: 6| Step: 6
Training loss: 1.0724432681713494
Validation loss: 2.2780800716430027

Epoch: 6| Step: 7
Training loss: 0.8774286353063376
Validation loss: 2.2121346015479246

Epoch: 6| Step: 8
Training loss: 1.814259234397151
Validation loss: 2.2771747873785753

Epoch: 6| Step: 9
Training loss: 0.8525574147979044
Validation loss: 2.2734436163626017

Epoch: 6| Step: 10
Training loss: 0.6967801025164924
Validation loss: 2.3018256047670484

Epoch: 6| Step: 11
Training loss: 0.8091527876824249
Validation loss: 2.237827023501513

Epoch: 6| Step: 12
Training loss: 0.5737871896828906
Validation loss: 2.3356933597865974

Epoch: 6| Step: 13
Training loss: 0.5679579952853638
Validation loss: 2.2497124875634174

Epoch: 518| Step: 0
Training loss: 0.6872898127297747
Validation loss: 2.1942316643304935

Epoch: 6| Step: 1
Training loss: 0.683028025187606
Validation loss: 2.2935571593549

Epoch: 6| Step: 2
Training loss: 0.7715084023898838
Validation loss: 2.304837995078538

Epoch: 6| Step: 3
Training loss: 0.5509106098608199
Validation loss: 2.3325154943019375

Epoch: 6| Step: 4
Training loss: 1.0865360504082089
Validation loss: 2.243128816171088

Epoch: 6| Step: 5
Training loss: 0.7043041726071226
Validation loss: 2.2143805492373816

Epoch: 6| Step: 6
Training loss: 1.000532544908318
Validation loss: 2.284661282669008

Epoch: 6| Step: 7
Training loss: 1.7977418218518693
Validation loss: 2.182506040811833

Epoch: 6| Step: 8
Training loss: 0.4468583330634265
Validation loss: 2.2438909208456246

Epoch: 6| Step: 9
Training loss: 0.8386681423806013
Validation loss: 2.2515276550428167

Epoch: 6| Step: 10
Training loss: 0.8131939052323369
Validation loss: 2.203430155811256

Epoch: 6| Step: 11
Training loss: 0.6857970995580527
Validation loss: 2.256537400596705

Epoch: 6| Step: 12
Training loss: 0.6404115740048858
Validation loss: 2.3243492193942257

Epoch: 6| Step: 13
Training loss: 0.6441073092698714
Validation loss: 2.287961669450354

Epoch: 519| Step: 0
Training loss: 0.8108231039339641
Validation loss: 2.1978495906953674

Epoch: 6| Step: 1
Training loss: 0.665966490781764
Validation loss: 2.235450402076479

Epoch: 6| Step: 2
Training loss: 0.827536427770746
Validation loss: 2.2599615874507593

Epoch: 6| Step: 3
Training loss: 1.0403456831429951
Validation loss: 2.1693245316148944

Epoch: 6| Step: 4
Training loss: 0.7512817159676415
Validation loss: 2.2493873523225214

Epoch: 6| Step: 5
Training loss: 0.7626748369230562
Validation loss: 2.307403880240844

Epoch: 6| Step: 6
Training loss: 1.1651023981828132
Validation loss: 2.2555211666398085

Epoch: 6| Step: 7
Training loss: 0.7747418358179681
Validation loss: 2.2519002191604223

Epoch: 6| Step: 8
Training loss: 0.6675156288960434
Validation loss: 2.165295330100397

Epoch: 6| Step: 9
Training loss: 1.669844490622935
Validation loss: 2.294921018748232

Epoch: 6| Step: 10
Training loss: 0.719351226785019
Validation loss: 2.2304652547538635

Epoch: 6| Step: 11
Training loss: 0.6233175042721403
Validation loss: 2.228342175401236

Epoch: 6| Step: 12
Training loss: 0.7436743048608074
Validation loss: 2.2056490693062694

Epoch: 6| Step: 13
Training loss: 0.8613258413686776
Validation loss: 2.24262481880392

Epoch: 520| Step: 0
Training loss: 0.5404088442649772
Validation loss: 2.2379635741095396

Epoch: 6| Step: 1
Training loss: 0.7093064598547649
Validation loss: 2.1474503030959333

Epoch: 6| Step: 2
Training loss: 0.8445434371817012
Validation loss: 2.3202046368966536

Epoch: 6| Step: 3
Training loss: 0.4593354688230508
Validation loss: 2.2883170302493787

Epoch: 6| Step: 4
Training loss: 1.819719930311013
Validation loss: 2.2773457717837284

Epoch: 6| Step: 5
Training loss: 0.7540602452623447
Validation loss: 2.285481536770485

Epoch: 6| Step: 6
Training loss: 1.0969211927289313
Validation loss: 2.322339896858458

Epoch: 6| Step: 7
Training loss: 0.8583633710796484
Validation loss: 2.3012146722156728

Epoch: 6| Step: 8
Training loss: 0.6258864315566816
Validation loss: 2.2984630359524325

Epoch: 6| Step: 9
Training loss: 0.9847826038124077
Validation loss: 2.2794479127601597

Epoch: 6| Step: 10
Training loss: 0.9541304241332597
Validation loss: 2.184129338342817

Epoch: 6| Step: 11
Training loss: 0.6407090806445868
Validation loss: 2.294360061610151

Epoch: 6| Step: 12
Training loss: 0.9915897040327712
Validation loss: 2.3158744610106807

Epoch: 6| Step: 13
Training loss: 0.822147170570765
Validation loss: 2.2199314463682636

Epoch: 521| Step: 0
Training loss: 0.9532765752618025
Validation loss: 2.294291813536941

Epoch: 6| Step: 1
Training loss: 0.6458274984608889
Validation loss: 2.307618209571111

Epoch: 6| Step: 2
Training loss: 0.8144099821011991
Validation loss: 2.2364566857555186

Epoch: 6| Step: 3
Training loss: 1.1047175250903278
Validation loss: 2.4051057513130165

Epoch: 6| Step: 4
Training loss: 0.491108544297053
Validation loss: 2.27516751646809

Epoch: 6| Step: 5
Training loss: 0.9802063974705281
Validation loss: 2.231460020860041

Epoch: 6| Step: 6
Training loss: 0.7907184183771092
Validation loss: 2.2754857408484526

Epoch: 6| Step: 7
Training loss: 0.7054946598943106
Validation loss: 2.263379342392338

Epoch: 6| Step: 8
Training loss: 0.8149189885954801
Validation loss: 2.342024851753282

Epoch: 6| Step: 9
Training loss: 0.7015890299107435
Validation loss: 2.2634443850598585

Epoch: 6| Step: 10
Training loss: 0.5966116059416451
Validation loss: 2.2850803443622167

Epoch: 6| Step: 11
Training loss: 0.7918376654274457
Validation loss: 2.187076116179923

Epoch: 6| Step: 12
Training loss: 1.7829036732796222
Validation loss: 2.2436990815373656

Epoch: 6| Step: 13
Training loss: 0.7175021742412309
Validation loss: 2.267443146420526

Epoch: 522| Step: 0
Training loss: 0.691138544358025
Validation loss: 2.3233923755806507

Epoch: 6| Step: 1
Training loss: 0.5437089005645959
Validation loss: 2.258856085574689

Epoch: 6| Step: 2
Training loss: 0.5502494517249531
Validation loss: 2.3126570457870614

Epoch: 6| Step: 3
Training loss: 0.7582384465837555
Validation loss: 2.2751724461779017

Epoch: 6| Step: 4
Training loss: 0.7511986849201542
Validation loss: 2.2995291922219714

Epoch: 6| Step: 5
Training loss: 0.8647227959965064
Validation loss: 2.3044004789605634

Epoch: 6| Step: 6
Training loss: 1.0004037995459614
Validation loss: 2.3164193710992813

Epoch: 6| Step: 7
Training loss: 0.7665089545227678
Validation loss: 2.247698352938965

Epoch: 6| Step: 8
Training loss: 0.809559489547114
Validation loss: 2.336473712430995

Epoch: 6| Step: 9
Training loss: 1.6378974403114004
Validation loss: 2.268120078291117

Epoch: 6| Step: 10
Training loss: 0.8120796510101754
Validation loss: 2.266253932380259

Epoch: 6| Step: 11
Training loss: 0.7893444728309611
Validation loss: 2.2158027658029136

Epoch: 6| Step: 12
Training loss: 0.9059541153477921
Validation loss: 2.2482243770180204

Epoch: 6| Step: 13
Training loss: 0.45437423559069445
Validation loss: 2.276417332048878

Epoch: 523| Step: 0
Training loss: 0.7794848146140094
Validation loss: 2.264453244054106

Epoch: 6| Step: 1
Training loss: 0.6692164407637267
Validation loss: 2.24721651397196

Epoch: 6| Step: 2
Training loss: 1.0235782555618766
Validation loss: 2.269442522331105

Epoch: 6| Step: 3
Training loss: 0.9470855856411478
Validation loss: 2.2573275128422603

Epoch: 6| Step: 4
Training loss: 0.7895465159492667
Validation loss: 2.1917322110255784

Epoch: 6| Step: 5
Training loss: 0.7113382237161112
Validation loss: 2.2725556175649237

Epoch: 6| Step: 6
Training loss: 1.6872423469798334
Validation loss: 2.2093960533897494

Epoch: 6| Step: 7
Training loss: 1.049007123452029
Validation loss: 2.2081413611262555

Epoch: 6| Step: 8
Training loss: 0.695726335792667
Validation loss: 2.2689635725524107

Epoch: 6| Step: 9
Training loss: 0.6661442383564895
Validation loss: 2.2596422591565752

Epoch: 6| Step: 10
Training loss: 0.7867040608160761
Validation loss: 2.2786332632441786

Epoch: 6| Step: 11
Training loss: 1.068773151169264
Validation loss: 2.2658919559383754

Epoch: 6| Step: 12
Training loss: 0.49745931935880294
Validation loss: 2.2556616815265933

Epoch: 6| Step: 13
Training loss: 0.706308617311396
Validation loss: 2.3325379864872904

Epoch: 524| Step: 0
Training loss: 0.7440136578393253
Validation loss: 2.3077310967610183

Epoch: 6| Step: 1
Training loss: 1.7156061723853777
Validation loss: 2.3793836329798417

Epoch: 6| Step: 2
Training loss: 1.1065271924690057
Validation loss: 2.254082866030367

Epoch: 6| Step: 3
Training loss: 1.0391911018351836
Validation loss: 2.3203221018414957

Epoch: 6| Step: 4
Training loss: 0.9581614146619222
Validation loss: 2.304162901692609

Epoch: 6| Step: 5
Training loss: 0.5546948069776203
Validation loss: 2.268329624400146

Epoch: 6| Step: 6
Training loss: 0.7703318812038722
Validation loss: 2.1880173231134514

Epoch: 6| Step: 7
Training loss: 0.4916669423970026
Validation loss: 2.24894293926625

Epoch: 6| Step: 8
Training loss: 0.6869988348755264
Validation loss: 2.3479015396987277

Epoch: 6| Step: 9
Training loss: 0.5914911166416441
Validation loss: 2.1816206259224904

Epoch: 6| Step: 10
Training loss: 0.7845583484849481
Validation loss: 2.2990367372125537

Epoch: 6| Step: 11
Training loss: 0.6448006500415389
Validation loss: 2.307213425111183

Epoch: 6| Step: 12
Training loss: 0.48137216998952126
Validation loss: 2.261117780987894

Epoch: 6| Step: 13
Training loss: 1.2094752681674714
Validation loss: 2.263131662403435

Epoch: 525| Step: 0
Training loss: 0.8657379751469152
Validation loss: 2.3194451286549556

Epoch: 6| Step: 1
Training loss: 0.78575096571132
Validation loss: 2.3407094526548535

Epoch: 6| Step: 2
Training loss: 0.819471527629073
Validation loss: 2.278135258208019

Epoch: 6| Step: 3
Training loss: 0.8580092935703485
Validation loss: 2.3273204870530235

Epoch: 6| Step: 4
Training loss: 0.9222400395141676
Validation loss: 2.329906537656947

Epoch: 6| Step: 5
Training loss: 0.7352388860490962
Validation loss: 2.3384277950392875

Epoch: 6| Step: 6
Training loss: 0.762069386694761
Validation loss: 2.405821317903888

Epoch: 6| Step: 7
Training loss: 1.7697690420817036
Validation loss: 2.3078240410237507

Epoch: 6| Step: 8
Training loss: 0.7017961873264844
Validation loss: 2.3636567992597604

Epoch: 6| Step: 9
Training loss: 0.8544218721069048
Validation loss: 2.3138854863133838

Epoch: 6| Step: 10
Training loss: 0.7341131189788868
Validation loss: 2.2948234000424077

Epoch: 6| Step: 11
Training loss: 1.0832490643713595
Validation loss: 2.3410432265099312

Epoch: 6| Step: 12
Training loss: 0.6083618202028065
Validation loss: 2.283791731265838

Epoch: 6| Step: 13
Training loss: 1.1657184880378588
Validation loss: 2.349346676576289

Epoch: 526| Step: 0
Training loss: 0.6698972736434705
Validation loss: 2.303925036209657

Epoch: 6| Step: 1
Training loss: 0.8465212065355001
Validation loss: 2.2380330524887415

Epoch: 6| Step: 2
Training loss: 1.7307070875830646
Validation loss: 2.213687627758642

Epoch: 6| Step: 3
Training loss: 0.8821260602354662
Validation loss: 2.3050410329593687

Epoch: 6| Step: 4
Training loss: 0.9993801281900623
Validation loss: 2.2291699366238378

Epoch: 6| Step: 5
Training loss: 0.7266001947940824
Validation loss: 2.234860705406362

Epoch: 6| Step: 6
Training loss: 0.7777770861743698
Validation loss: 2.2638489607408583

Epoch: 6| Step: 7
Training loss: 0.8944533534886421
Validation loss: 2.1963860515036466

Epoch: 6| Step: 8
Training loss: 0.8266750814281336
Validation loss: 2.216985314734276

Epoch: 6| Step: 9
Training loss: 0.7752338702588378
Validation loss: 2.254323875767104

Epoch: 6| Step: 10
Training loss: 0.7553905837165237
Validation loss: 2.2241078502998755

Epoch: 6| Step: 11
Training loss: 0.6631032410556387
Validation loss: 2.302162910332922

Epoch: 6| Step: 12
Training loss: 0.7276726721642336
Validation loss: 2.26910280619995

Epoch: 6| Step: 13
Training loss: 0.5652317893305904
Validation loss: 2.3270567486990488

Epoch: 527| Step: 0
Training loss: 0.6357295537534166
Validation loss: 2.3383985639560625

Epoch: 6| Step: 1
Training loss: 0.9280311511336057
Validation loss: 2.3120856087027373

Epoch: 6| Step: 2
Training loss: 0.9088642626240805
Validation loss: 2.2971047144319083

Epoch: 6| Step: 3
Training loss: 0.7026918560606595
Validation loss: 2.2893355527052623

Epoch: 6| Step: 4
Training loss: 0.7507354785887974
Validation loss: 2.251973605998661

Epoch: 6| Step: 5
Training loss: 0.8579157143566397
Validation loss: 2.2508825368126315

Epoch: 6| Step: 6
Training loss: 0.8656676781114386
Validation loss: 2.2581853634275597

Epoch: 6| Step: 7
Training loss: 1.7690017952314188
Validation loss: 2.301294818057253

Epoch: 6| Step: 8
Training loss: 0.6207095223271796
Validation loss: 2.2788996616917254

Epoch: 6| Step: 9
Training loss: 0.7313029376047777
Validation loss: 2.228202904364747

Epoch: 6| Step: 10
Training loss: 0.5990032897884353
Validation loss: 2.2360822157751947

Epoch: 6| Step: 11
Training loss: 1.0770166754002795
Validation loss: 2.2759493127189585

Epoch: 6| Step: 12
Training loss: 0.8206761598582849
Validation loss: 2.2539180893856394

Epoch: 6| Step: 13
Training loss: 0.7603612296045734
Validation loss: 2.2930081227099484

Epoch: 528| Step: 0
Training loss: 0.48871410257556913
Validation loss: 2.2608420981661923

Epoch: 6| Step: 1
Training loss: 0.8187809406869733
Validation loss: 2.2662296703255667

Epoch: 6| Step: 2
Training loss: 0.6290580139909817
Validation loss: 2.263574384376022

Epoch: 6| Step: 3
Training loss: 0.9037887430922106
Validation loss: 2.2684642959548915

Epoch: 6| Step: 4
Training loss: 1.8907874802058915
Validation loss: 2.2749140130116574

Epoch: 6| Step: 5
Training loss: 0.9293210886317801
Validation loss: 2.2542987535114016

Epoch: 6| Step: 6
Training loss: 0.7511249291503589
Validation loss: 2.2717636481700785

Epoch: 6| Step: 7
Training loss: 0.8135747037489365
Validation loss: 2.3178143154319795

Epoch: 6| Step: 8
Training loss: 0.709829997878946
Validation loss: 2.303024386034319

Epoch: 6| Step: 9
Training loss: 0.8226930861816306
Validation loss: 2.273509331547226

Epoch: 6| Step: 10
Training loss: 0.8724272233620243
Validation loss: 2.2531257927842154

Epoch: 6| Step: 11
Training loss: 0.5618512067753494
Validation loss: 2.308774163285453

Epoch: 6| Step: 12
Training loss: 0.8191034762463709
Validation loss: 2.2843434835812184

Epoch: 6| Step: 13
Training loss: 0.7970328081239518
Validation loss: 2.2826348480040726

Epoch: 529| Step: 0
Training loss: 1.6364544129238685
Validation loss: 2.2937232990425853

Epoch: 6| Step: 1
Training loss: 0.7929446212029039
Validation loss: 2.2173009679025553

Epoch: 6| Step: 2
Training loss: 0.75825770563423
Validation loss: 2.261165711599959

Epoch: 6| Step: 3
Training loss: 0.687443102302825
Validation loss: 2.2491998058543796

Epoch: 6| Step: 4
Training loss: 0.8890173942507683
Validation loss: 2.285047535167936

Epoch: 6| Step: 5
Training loss: 0.4428108956705669
Validation loss: 2.3151849670568954

Epoch: 6| Step: 6
Training loss: 0.7641359368041912
Validation loss: 2.2912410202822935

Epoch: 6| Step: 7
Training loss: 0.9697318177786697
Validation loss: 2.3279616194026795

Epoch: 6| Step: 8
Training loss: 0.5802793314405579
Validation loss: 2.3208402688978502

Epoch: 6| Step: 9
Training loss: 0.692039329221535
Validation loss: 2.3129488402166274

Epoch: 6| Step: 10
Training loss: 0.7633054981265063
Validation loss: 2.251299531802193

Epoch: 6| Step: 11
Training loss: 0.7980319581432541
Validation loss: 2.2617153982609848

Epoch: 6| Step: 12
Training loss: 0.9176908356423366
Validation loss: 2.2391120393767117

Epoch: 6| Step: 13
Training loss: 0.6338452048335546
Validation loss: 2.28492754603444

Epoch: 530| Step: 0
Training loss: 1.7245689378708862
Validation loss: 2.2848693684406784

Epoch: 6| Step: 1
Training loss: 0.971191866545187
Validation loss: 2.289630306951565

Epoch: 6| Step: 2
Training loss: 0.6172113776115047
Validation loss: 2.3450825097952173

Epoch: 6| Step: 3
Training loss: 0.7394449256728539
Validation loss: 2.3913213069823804

Epoch: 6| Step: 4
Training loss: 0.5595726026451554
Validation loss: 2.2668274197527034

Epoch: 6| Step: 5
Training loss: 0.6400209696135783
Validation loss: 2.2136340378387187

Epoch: 6| Step: 6
Training loss: 0.861985005861233
Validation loss: 2.2908443649916213

Epoch: 6| Step: 7
Training loss: 0.6950951997474041
Validation loss: 2.2519303134722346

Epoch: 6| Step: 8
Training loss: 0.8966240535121098
Validation loss: 2.3667186163169505

Epoch: 6| Step: 9
Training loss: 0.8009173021809813
Validation loss: 2.261280137789095

Epoch: 6| Step: 10
Training loss: 0.6804290978915155
Validation loss: 2.2851704668111674

Epoch: 6| Step: 11
Training loss: 0.9670559622657562
Validation loss: 2.2614417029960787

Epoch: 6| Step: 12
Training loss: 0.9445262823613163
Validation loss: 2.3012265249926545

Epoch: 6| Step: 13
Training loss: 0.8257829187930306
Validation loss: 2.264498036075689

Epoch: 531| Step: 0
Training loss: 0.6413786107379668
Validation loss: 2.262193202754183

Epoch: 6| Step: 1
Training loss: 0.9645665809269662
Validation loss: 2.2285042718671817

Epoch: 6| Step: 2
Training loss: 0.5535283939932039
Validation loss: 2.2742948120467954

Epoch: 6| Step: 3
Training loss: 0.7132110293733116
Validation loss: 2.2806254088272553

Epoch: 6| Step: 4
Training loss: 0.8145840400113864
Validation loss: 2.20975602627066

Epoch: 6| Step: 5
Training loss: 0.8230989270436506
Validation loss: 2.259298241170825

Epoch: 6| Step: 6
Training loss: 0.9174856659811551
Validation loss: 2.250522919645305

Epoch: 6| Step: 7
Training loss: 0.792798554895895
Validation loss: 2.275221078460384

Epoch: 6| Step: 8
Training loss: 0.6095628693336127
Validation loss: 2.2165680688133875

Epoch: 6| Step: 9
Training loss: 0.9999245972815741
Validation loss: 2.26086796753712

Epoch: 6| Step: 10
Training loss: 1.8420213257158804
Validation loss: 2.222597842704582

Epoch: 6| Step: 11
Training loss: 0.5220083397568139
Validation loss: 2.2325462736066553

Epoch: 6| Step: 12
Training loss: 0.8902638690342732
Validation loss: 2.2463613687941244

Epoch: 6| Step: 13
Training loss: 0.4034660020802183
Validation loss: 2.277772463636338

Epoch: 532| Step: 0
Training loss: 0.7745266576357245
Validation loss: 2.2849906609672583

Epoch: 6| Step: 1
Training loss: 0.9811173683479149
Validation loss: 2.2294466381274587

Epoch: 6| Step: 2
Training loss: 0.4704140372944757
Validation loss: 2.256812809265094

Epoch: 6| Step: 3
Training loss: 0.7072362444535418
Validation loss: 2.3168984687220457

Epoch: 6| Step: 4
Training loss: 0.6910343570876577
Validation loss: 2.2378237516833916

Epoch: 6| Step: 5
Training loss: 1.6330207801379708
Validation loss: 2.304320105706213

Epoch: 6| Step: 6
Training loss: 0.6109764623291293
Validation loss: 2.232008777042847

Epoch: 6| Step: 7
Training loss: 0.6567907829995859
Validation loss: 2.2219714262725483

Epoch: 6| Step: 8
Training loss: 0.6210315121350839
Validation loss: 2.268395367092448

Epoch: 6| Step: 9
Training loss: 0.5183241739516625
Validation loss: 2.2673224037278255

Epoch: 6| Step: 10
Training loss: 1.0164945547930944
Validation loss: 2.2886404012078976

Epoch: 6| Step: 11
Training loss: 0.5607881990195103
Validation loss: 2.286286850061207

Epoch: 6| Step: 12
Training loss: 0.914535269781364
Validation loss: 2.384594880841141

Epoch: 6| Step: 13
Training loss: 0.6682467411987901
Validation loss: 2.285809870475941

Epoch: 533| Step: 0
Training loss: 0.7033430397198578
Validation loss: 2.2630587433192892

Epoch: 6| Step: 1
Training loss: 0.8340787811805532
Validation loss: 2.3137848701002737

Epoch: 6| Step: 2
Training loss: 0.5364447348145794
Validation loss: 2.307433426199192

Epoch: 6| Step: 3
Training loss: 0.8971383362802392
Validation loss: 2.2284343790555416

Epoch: 6| Step: 4
Training loss: 0.5570244787374427
Validation loss: 2.2705099329573

Epoch: 6| Step: 5
Training loss: 1.0110460792024416
Validation loss: 2.268269650706084

Epoch: 6| Step: 6
Training loss: 0.8369740984291839
Validation loss: 2.296184800793934

Epoch: 6| Step: 7
Training loss: 1.7364468957638357
Validation loss: 2.3261982356372246

Epoch: 6| Step: 8
Training loss: 0.8219467595904228
Validation loss: 2.2837117502292044

Epoch: 6| Step: 9
Training loss: 0.8017437988246026
Validation loss: 2.297565317682841

Epoch: 6| Step: 10
Training loss: 0.8380424166393918
Validation loss: 2.3041634969402636

Epoch: 6| Step: 11
Training loss: 0.6728939491507867
Validation loss: 2.2758161046736434

Epoch: 6| Step: 12
Training loss: 0.6097016315005415
Validation loss: 2.2617292614157933

Epoch: 6| Step: 13
Training loss: 0.6922582560040382
Validation loss: 2.199024425359431

Epoch: 534| Step: 0
Training loss: 0.6981567117084978
Validation loss: 2.175690778796705

Epoch: 6| Step: 1
Training loss: 0.7751835467271513
Validation loss: 2.2668263430997375

Epoch: 6| Step: 2
Training loss: 0.8633808406501383
Validation loss: 2.2869040562362493

Epoch: 6| Step: 3
Training loss: 0.7939834491724714
Validation loss: 2.338227112453376

Epoch: 6| Step: 4
Training loss: 0.5368153825194611
Validation loss: 2.2853944973802305

Epoch: 6| Step: 5
Training loss: 0.9435884185807163
Validation loss: 2.2309958378938353

Epoch: 6| Step: 6
Training loss: 1.7944480760470012
Validation loss: 2.28459727214535

Epoch: 6| Step: 7
Training loss: 0.579059206875507
Validation loss: 2.23434354136223

Epoch: 6| Step: 8
Training loss: 0.6674308618893603
Validation loss: 2.2908382033227896

Epoch: 6| Step: 9
Training loss: 0.480793416808723
Validation loss: 2.3381585588130216

Epoch: 6| Step: 10
Training loss: 0.9735595308233944
Validation loss: 2.2484030736407146

Epoch: 6| Step: 11
Training loss: 0.7730721275364798
Validation loss: 2.2467999187578838

Epoch: 6| Step: 12
Training loss: 0.7376657978483112
Validation loss: 2.29134809194501

Epoch: 6| Step: 13
Training loss: 0.5902345385952009
Validation loss: 2.232131348986046

Epoch: 535| Step: 0
Training loss: 0.8164522440972769
Validation loss: 2.249572310481305

Epoch: 6| Step: 1
Training loss: 0.7135379308523873
Validation loss: 2.2447702705508132

Epoch: 6| Step: 2
Training loss: 0.6356189098460242
Validation loss: 2.291356609620675

Epoch: 6| Step: 3
Training loss: 0.7707259300945235
Validation loss: 2.2908349551788527

Epoch: 6| Step: 4
Training loss: 0.9100751717927473
Validation loss: 2.2567122882450206

Epoch: 6| Step: 5
Training loss: 0.8481024345707547
Validation loss: 2.282656246440237

Epoch: 6| Step: 6
Training loss: 0.6943018565552395
Validation loss: 2.263621761822645

Epoch: 6| Step: 7
Training loss: 0.669778302436579
Validation loss: 2.2978500931640986

Epoch: 6| Step: 8
Training loss: 0.5699366023126345
Validation loss: 2.223355096307793

Epoch: 6| Step: 9
Training loss: 0.6082175829472978
Validation loss: 2.359857279694396

Epoch: 6| Step: 10
Training loss: 1.675049735512298
Validation loss: 2.370851063070464

Epoch: 6| Step: 11
Training loss: 0.6097427627803388
Validation loss: 2.268627018031667

Epoch: 6| Step: 12
Training loss: 0.6920231798484797
Validation loss: 2.3173314502365776

Epoch: 6| Step: 13
Training loss: 0.8796825456225661
Validation loss: 2.2942953853018158

Epoch: 536| Step: 0
Training loss: 0.7499175423752208
Validation loss: 2.2671360599186774

Epoch: 6| Step: 1
Training loss: 0.8228024793826751
Validation loss: 2.2844438057710144

Epoch: 6| Step: 2
Training loss: 0.9823385700072874
Validation loss: 2.2806026322915995

Epoch: 6| Step: 3
Training loss: 0.729107409294632
Validation loss: 2.2263454882008733

Epoch: 6| Step: 4
Training loss: 0.781258163409498
Validation loss: 2.2711483376673436

Epoch: 6| Step: 5
Training loss: 0.7210959834335968
Validation loss: 2.2761840130020645

Epoch: 6| Step: 6
Training loss: 0.7922370428661067
Validation loss: 2.2621258796353585

Epoch: 6| Step: 7
Training loss: 1.6452540895358752
Validation loss: 2.23755824075753

Epoch: 6| Step: 8
Training loss: 0.6607123521275745
Validation loss: 2.255726283010805

Epoch: 6| Step: 9
Training loss: 1.0043563130793953
Validation loss: 2.262636915637479

Epoch: 6| Step: 10
Training loss: 0.5305228024614772
Validation loss: 2.2503093144542476

Epoch: 6| Step: 11
Training loss: 0.7189323774405817
Validation loss: 2.2494944906984338

Epoch: 6| Step: 12
Training loss: 0.6657206309935317
Validation loss: 2.3073296909193957

Epoch: 6| Step: 13
Training loss: 0.6453534748286194
Validation loss: 2.261667671996248

Epoch: 537| Step: 0
Training loss: 0.8033225695956051
Validation loss: 2.255834451392215

Epoch: 6| Step: 1
Training loss: 0.6680687277410193
Validation loss: 2.2150802710277464

Epoch: 6| Step: 2
Training loss: 0.5860934240777074
Validation loss: 2.2435256745323713

Epoch: 6| Step: 3
Training loss: 0.7931646471507519
Validation loss: 2.231451939172474

Epoch: 6| Step: 4
Training loss: 1.7656915702760758
Validation loss: 2.2321825033437737

Epoch: 6| Step: 5
Training loss: 0.682354026351916
Validation loss: 2.246946624436223

Epoch: 6| Step: 6
Training loss: 0.72162277967758
Validation loss: 2.278572285439391

Epoch: 6| Step: 7
Training loss: 0.8483938356969647
Validation loss: 2.222828452505264

Epoch: 6| Step: 8
Training loss: 0.833822480329781
Validation loss: 2.2383619947944626

Epoch: 6| Step: 9
Training loss: 0.648566727228092
Validation loss: 2.2300733513183824

Epoch: 6| Step: 10
Training loss: 0.5595604061827636
Validation loss: 2.2372080961908787

Epoch: 6| Step: 11
Training loss: 0.6963259993462617
Validation loss: 2.234072931513491

Epoch: 6| Step: 12
Training loss: 0.6129628709622498
Validation loss: 2.2447854840372616

Epoch: 6| Step: 13
Training loss: 0.9528301283174314
Validation loss: 2.297297011679998

Epoch: 538| Step: 0
Training loss: 0.7445669880122296
Validation loss: 2.239212232799813

Epoch: 6| Step: 1
Training loss: 0.6455132603956473
Validation loss: 2.246606903737634

Epoch: 6| Step: 2
Training loss: 1.7979321894264753
Validation loss: 2.2870759021815554

Epoch: 6| Step: 3
Training loss: 0.9074129666610825
Validation loss: 2.319032222704262

Epoch: 6| Step: 4
Training loss: 0.755403760858354
Validation loss: 2.3121638409842293

Epoch: 6| Step: 5
Training loss: 0.6242890128646804
Validation loss: 2.2744676608333547

Epoch: 6| Step: 6
Training loss: 0.5556087097594814
Validation loss: 2.2882618326818274

Epoch: 6| Step: 7
Training loss: 0.8908772696879219
Validation loss: 2.27148424633742

Epoch: 6| Step: 8
Training loss: 0.7947868213697524
Validation loss: 2.347386770428569

Epoch: 6| Step: 9
Training loss: 0.9089088897115887
Validation loss: 2.240578997348522

Epoch: 6| Step: 10
Training loss: 0.837963963569089
Validation loss: 2.344864687534263

Epoch: 6| Step: 11
Training loss: 0.5792377176773083
Validation loss: 2.2682012872713355

Epoch: 6| Step: 12
Training loss: 0.9365042802842183
Validation loss: 2.2328994850571813

Epoch: 6| Step: 13
Training loss: 0.532085911075658
Validation loss: 2.250053251882809

Epoch: 539| Step: 0
Training loss: 0.5442271298714279
Validation loss: 2.22417123302936

Epoch: 6| Step: 1
Training loss: 0.7699187024659355
Validation loss: 2.2716766587253416

Epoch: 6| Step: 2
Training loss: 0.7164550298725747
Validation loss: 2.2397595114259663

Epoch: 6| Step: 3
Training loss: 0.4148093272150047
Validation loss: 2.2421226467789217

Epoch: 6| Step: 4
Training loss: 0.9808449194544427
Validation loss: 2.250113422857445

Epoch: 6| Step: 5
Training loss: 1.6253217231945
Validation loss: 2.242983003172301

Epoch: 6| Step: 6
Training loss: 0.9134847983591974
Validation loss: 2.254159752131537

Epoch: 6| Step: 7
Training loss: 1.0341486795619956
Validation loss: 2.3588850097546814

Epoch: 6| Step: 8
Training loss: 0.586214839149313
Validation loss: 2.258731824486442

Epoch: 6| Step: 9
Training loss: 0.6569319769106617
Validation loss: 2.266139247129579

Epoch: 6| Step: 10
Training loss: 0.7615085018206851
Validation loss: 2.2353022778392035

Epoch: 6| Step: 11
Training loss: 0.7107956713380962
Validation loss: 2.2645434532507167

Epoch: 6| Step: 12
Training loss: 1.0399939585473574
Validation loss: 2.2790830374988653

Epoch: 6| Step: 13
Training loss: 0.4693761458300384
Validation loss: 2.2998601642667906

Epoch: 540| Step: 0
Training loss: 0.6188791968585309
Validation loss: 2.30337750534793

Epoch: 6| Step: 1
Training loss: 0.7136880673396983
Validation loss: 2.2760595794631397

Epoch: 6| Step: 2
Training loss: 0.6515159608608754
Validation loss: 2.315608451108461

Epoch: 6| Step: 3
Training loss: 0.4436436216692296
Validation loss: 2.242587203371386

Epoch: 6| Step: 4
Training loss: 0.717141757079775
Validation loss: 2.2926694557235643

Epoch: 6| Step: 5
Training loss: 1.00500618017014
Validation loss: 2.261609037759317

Epoch: 6| Step: 6
Training loss: 0.6317951831910544
Validation loss: 2.225814131691107

Epoch: 6| Step: 7
Training loss: 0.8986015501763333
Validation loss: 2.275525009353519

Epoch: 6| Step: 8
Training loss: 0.4987409953210367
Validation loss: 2.2511906606794767

Epoch: 6| Step: 9
Training loss: 0.6301209938332115
Validation loss: 2.204323785668872

Epoch: 6| Step: 10
Training loss: 1.6367448973103476
Validation loss: 2.2588613153201553

Epoch: 6| Step: 11
Training loss: 0.628897767572479
Validation loss: 2.207990576422501

Epoch: 6| Step: 12
Training loss: 0.9265103587617806
Validation loss: 2.2241949781790282

Epoch: 6| Step: 13
Training loss: 0.7242047601725113
Validation loss: 2.2122318600106685

Epoch: 541| Step: 0
Training loss: 0.6595256886341526
Validation loss: 2.2178211096225646

Epoch: 6| Step: 1
Training loss: 0.6183155229819062
Validation loss: 2.283300402918583

Epoch: 6| Step: 2
Training loss: 0.6421924813627299
Validation loss: 2.223763020249228

Epoch: 6| Step: 3
Training loss: 0.5774864588219196
Validation loss: 2.2930721706783705

Epoch: 6| Step: 4
Training loss: 0.5689983904954911
Validation loss: 2.2839910710992126

Epoch: 6| Step: 5
Training loss: 1.102639611848288
Validation loss: 2.284743895381514

Epoch: 6| Step: 6
Training loss: 0.7335068055001653
Validation loss: 2.2626922273306573

Epoch: 6| Step: 7
Training loss: 0.8497287710197331
Validation loss: 2.275242095638651

Epoch: 6| Step: 8
Training loss: 0.6721988163788671
Validation loss: 2.2618749307692627

Epoch: 6| Step: 9
Training loss: 0.8096037375770962
Validation loss: 2.300376714041532

Epoch: 6| Step: 10
Training loss: 0.5540739615298922
Validation loss: 2.209616816491817

Epoch: 6| Step: 11
Training loss: 0.6686217033460429
Validation loss: 2.225650720266708

Epoch: 6| Step: 12
Training loss: 0.9560064005517774
Validation loss: 2.1926106371818084

Epoch: 6| Step: 13
Training loss: 2.351927060481925
Validation loss: 2.291203259760232

Epoch: 542| Step: 0
Training loss: 0.5610846355720945
Validation loss: 2.306871635996946

Epoch: 6| Step: 1
Training loss: 1.0632837994816113
Validation loss: 2.321850786011217

Epoch: 6| Step: 2
Training loss: 1.0579880110993432
Validation loss: 2.2883479149420034

Epoch: 6| Step: 3
Training loss: 0.9418994039248314
Validation loss: 2.275949228238584

Epoch: 6| Step: 4
Training loss: 0.8160348074609087
Validation loss: 2.229302895996628

Epoch: 6| Step: 5
Training loss: 0.8118381004963622
Validation loss: 2.23449656560758

Epoch: 6| Step: 6
Training loss: 0.3544815524268803
Validation loss: 2.2538539723803237

Epoch: 6| Step: 7
Training loss: 0.7577133507117129
Validation loss: 2.174801281969546

Epoch: 6| Step: 8
Training loss: 0.8025879366696502
Validation loss: 2.215909196198825

Epoch: 6| Step: 9
Training loss: 0.705360968753586
Validation loss: 2.2501146311254976

Epoch: 6| Step: 10
Training loss: 0.5716689973854101
Validation loss: 2.2642430669016114

Epoch: 6| Step: 11
Training loss: 0.6912224735484119
Validation loss: 2.2672776570449606

Epoch: 6| Step: 12
Training loss: 1.7937486070368338
Validation loss: 2.2776598322898884

Epoch: 6| Step: 13
Training loss: 0.4063058778040968
Validation loss: 2.2532949394382067

Epoch: 543| Step: 0
Training loss: 0.4662802642685039
Validation loss: 2.2596337932491157

Epoch: 6| Step: 1
Training loss: 0.7213603178971618
Validation loss: 2.301472478479365

Epoch: 6| Step: 2
Training loss: 0.5914471288383182
Validation loss: 2.249035545385172

Epoch: 6| Step: 3
Training loss: 0.8386898186322769
Validation loss: 2.272147813593875

Epoch: 6| Step: 4
Training loss: 0.7314869113801957
Validation loss: 2.2903573607519694

Epoch: 6| Step: 5
Training loss: 1.6700534344878908
Validation loss: 2.2936712566400224

Epoch: 6| Step: 6
Training loss: 0.7026031889082711
Validation loss: 2.2348592110027306

Epoch: 6| Step: 7
Training loss: 0.616275886703806
Validation loss: 2.2083196066880393

Epoch: 6| Step: 8
Training loss: 0.7412747442351503
Validation loss: 2.254115155010771

Epoch: 6| Step: 9
Training loss: 0.6195771997640308
Validation loss: 2.268158546362683

Epoch: 6| Step: 10
Training loss: 0.9922223122564543
Validation loss: 2.25240998766957

Epoch: 6| Step: 11
Training loss: 0.7850971484358781
Validation loss: 2.264270090063648

Epoch: 6| Step: 12
Training loss: 0.9110650367510464
Validation loss: 2.280794635118172

Epoch: 6| Step: 13
Training loss: 0.44227351171014445
Validation loss: 2.2941527316278636

Epoch: 544| Step: 0
Training loss: 0.5643017839864937
Validation loss: 2.272299441623836

Epoch: 6| Step: 1
Training loss: 0.7339106776018858
Validation loss: 2.274515587395188

Epoch: 6| Step: 2
Training loss: 0.7107824638592813
Validation loss: 2.2466580719684677

Epoch: 6| Step: 3
Training loss: 0.7646370176824244
Validation loss: 2.2658791642415945

Epoch: 6| Step: 4
Training loss: 0.85143615065289
Validation loss: 2.216480545127227

Epoch: 6| Step: 5
Training loss: 0.5620476970540927
Validation loss: 2.243653522361574

Epoch: 6| Step: 6
Training loss: 0.94873960984362
Validation loss: 2.245840128471823

Epoch: 6| Step: 7
Training loss: 0.7735297408153369
Validation loss: 2.233332326939625

Epoch: 6| Step: 8
Training loss: 0.5727541664168474
Validation loss: 2.2128705329896294

Epoch: 6| Step: 9
Training loss: 0.8700177513701242
Validation loss: 2.2164749331672495

Epoch: 6| Step: 10
Training loss: 1.7091941835496862
Validation loss: 2.2048101764928343

Epoch: 6| Step: 11
Training loss: 0.5840944422462185
Validation loss: 2.294932679495843

Epoch: 6| Step: 12
Training loss: 0.6204298777953141
Validation loss: 2.2402931372534503

Epoch: 6| Step: 13
Training loss: 0.502184120788789
Validation loss: 2.279954950336984

Epoch: 545| Step: 0
Training loss: 0.7884405725565162
Validation loss: 2.2647240159465896

Epoch: 6| Step: 1
Training loss: 0.6807929071667668
Validation loss: 2.1848796215309285

Epoch: 6| Step: 2
Training loss: 0.9012296991270783
Validation loss: 2.214671191725442

Epoch: 6| Step: 3
Training loss: 0.513821221169377
Validation loss: 2.2570464909161756

Epoch: 6| Step: 4
Training loss: 0.8142826624624289
Validation loss: 2.2504931858490687

Epoch: 6| Step: 5
Training loss: 0.632617684976842
Validation loss: 2.271218906019329

Epoch: 6| Step: 6
Training loss: 0.7504026603627171
Validation loss: 2.206983366880686

Epoch: 6| Step: 7
Training loss: 0.5833034564496089
Validation loss: 2.2418909130046663

Epoch: 6| Step: 8
Training loss: 1.6489761701797139
Validation loss: 2.249150028190545

Epoch: 6| Step: 9
Training loss: 0.6890401062386508
Validation loss: 2.227506043373107

Epoch: 6| Step: 10
Training loss: 0.7663051153526732
Validation loss: 2.278515418942529

Epoch: 6| Step: 11
Training loss: 0.5413335974360669
Validation loss: 2.2599615193883453

Epoch: 6| Step: 12
Training loss: 0.8804374073207512
Validation loss: 2.2801301089405133

Epoch: 6| Step: 13
Training loss: 0.5700071379565981
Validation loss: 2.258587196729831

Epoch: 546| Step: 0
Training loss: 0.4669985953816318
Validation loss: 2.260585923367795

Epoch: 6| Step: 1
Training loss: 0.783953946544232
Validation loss: 2.29093422488213

Epoch: 6| Step: 2
Training loss: 1.0117748348052618
Validation loss: 2.225599754433982

Epoch: 6| Step: 3
Training loss: 0.6783697354681968
Validation loss: 2.2640158534634702

Epoch: 6| Step: 4
Training loss: 0.7154196831964147
Validation loss: 2.3223941431784336

Epoch: 6| Step: 5
Training loss: 0.6275324536476277
Validation loss: 2.26170378445254

Epoch: 6| Step: 6
Training loss: 0.5902283027583987
Validation loss: 2.2956934614623954

Epoch: 6| Step: 7
Training loss: 0.7407038666788135
Validation loss: 2.260275824510209

Epoch: 6| Step: 8
Training loss: 0.6449074312067932
Validation loss: 2.2489098935525975

Epoch: 6| Step: 9
Training loss: 0.9416419402958112
Validation loss: 2.2921293828169165

Epoch: 6| Step: 10
Training loss: 1.585276574032862
Validation loss: 2.1874317539427435

Epoch: 6| Step: 11
Training loss: 0.6777028452989825
Validation loss: 2.318661405012212

Epoch: 6| Step: 12
Training loss: 0.7570479163824273
Validation loss: 2.360418176963223

Epoch: 6| Step: 13
Training loss: 0.9019196739949078
Validation loss: 2.25176194352107

Epoch: 547| Step: 0
Training loss: 1.6358626500652615
Validation loss: 2.339259617743419

Epoch: 6| Step: 1
Training loss: 0.6755876208612756
Validation loss: 2.256208975968374

Epoch: 6| Step: 2
Training loss: 0.45190920999701245
Validation loss: 2.265083112965844

Epoch: 6| Step: 3
Training loss: 0.6022490757261716
Validation loss: 2.31806582193798

Epoch: 6| Step: 4
Training loss: 0.8064722804528336
Validation loss: 2.3139926136398232

Epoch: 6| Step: 5
Training loss: 0.555903699854125
Validation loss: 2.2829406829418732

Epoch: 6| Step: 6
Training loss: 0.7696782470345189
Validation loss: 2.261233400591967

Epoch: 6| Step: 7
Training loss: 0.7751161103793093
Validation loss: 2.298073231794495

Epoch: 6| Step: 8
Training loss: 0.5646623797758757
Validation loss: 2.2090918835749056

Epoch: 6| Step: 9
Training loss: 0.4993408746243263
Validation loss: 2.262342985709555

Epoch: 6| Step: 10
Training loss: 1.1876096172936539
Validation loss: 2.3825824854485385

Epoch: 6| Step: 11
Training loss: 0.7687152467020786
Validation loss: 2.2630017022273057

Epoch: 6| Step: 12
Training loss: 0.7335794075730799
Validation loss: 2.345047594415636

Epoch: 6| Step: 13
Training loss: 0.5992080389107474
Validation loss: 2.233434009563307

Epoch: 548| Step: 0
Training loss: 0.9324338083578314
Validation loss: 2.262825568409169

Epoch: 6| Step: 1
Training loss: 0.7069950832158207
Validation loss: 2.3143009676973816

Epoch: 6| Step: 2
Training loss: 1.6289771634041441
Validation loss: 2.291644943857762

Epoch: 6| Step: 3
Training loss: 0.8856325260399835
Validation loss: 2.289598309790221

Epoch: 6| Step: 4
Training loss: 0.6381139388886459
Validation loss: 2.192836453066352

Epoch: 6| Step: 5
Training loss: 0.6357956496112973
Validation loss: 2.274276906016499

Epoch: 6| Step: 6
Training loss: 0.753991710187232
Validation loss: 2.339249323199318

Epoch: 6| Step: 7
Training loss: 0.8362373456011759
Validation loss: 2.274741439883851

Epoch: 6| Step: 8
Training loss: 0.6259451633618451
Validation loss: 2.211415559358884

Epoch: 6| Step: 9
Training loss: 0.6749681641877128
Validation loss: 2.2091282856899537

Epoch: 6| Step: 10
Training loss: 0.7826446673083934
Validation loss: 2.2513148466393114

Epoch: 6| Step: 11
Training loss: 0.6025401259154792
Validation loss: 2.22621683525818

Epoch: 6| Step: 12
Training loss: 0.6660183545725087
Validation loss: 2.2947127859237004

Epoch: 6| Step: 13
Training loss: 0.41733929662067243
Validation loss: 2.253063623983001

Epoch: 549| Step: 0
Training loss: 0.5700901852336153
Validation loss: 2.31843984705612

Epoch: 6| Step: 1
Training loss: 1.6977534147387483
Validation loss: 2.3089444864466295

Epoch: 6| Step: 2
Training loss: 0.873518882331203
Validation loss: 2.266791646779389

Epoch: 6| Step: 3
Training loss: 0.7258889142058217
Validation loss: 2.2889648677628

Epoch: 6| Step: 4
Training loss: 0.7787742296248922
Validation loss: 2.283378301647291

Epoch: 6| Step: 5
Training loss: 0.6491567919530595
Validation loss: 2.3197469454685646

Epoch: 6| Step: 6
Training loss: 0.7534985403415082
Validation loss: 2.2013091725954292

Epoch: 6| Step: 7
Training loss: 0.7966644906635441
Validation loss: 2.1582472059909477

Epoch: 6| Step: 8
Training loss: 0.6446687031611507
Validation loss: 2.3169580876598443

Epoch: 6| Step: 9
Training loss: 0.4645702936141529
Validation loss: 2.246541894520303

Epoch: 6| Step: 10
Training loss: 0.7510836243428027
Validation loss: 2.246960840555521

Epoch: 6| Step: 11
Training loss: 0.8833726776705723
Validation loss: 2.267297746053616

Epoch: 6| Step: 12
Training loss: 0.6929413945971237
Validation loss: 2.2912646443484004

Epoch: 6| Step: 13
Training loss: 0.6420746892148765
Validation loss: 2.2719092219849166

Epoch: 550| Step: 0
Training loss: 0.6657818470656559
Validation loss: 2.293177124982215

Epoch: 6| Step: 1
Training loss: 0.7631848042991639
Validation loss: 2.189461482900756

Epoch: 6| Step: 2
Training loss: 0.46418210231939694
Validation loss: 2.310970827368056

Epoch: 6| Step: 3
Training loss: 1.6639490223191795
Validation loss: 2.2818065048243423

Epoch: 6| Step: 4
Training loss: 0.7230100848020897
Validation loss: 2.311795886600213

Epoch: 6| Step: 5
Training loss: 1.0029412169569165
Validation loss: 2.30786545971308

Epoch: 6| Step: 6
Training loss: 0.6303005046015128
Validation loss: 2.2485372786161

Epoch: 6| Step: 7
Training loss: 0.6230799268607563
Validation loss: 2.310544453431029

Epoch: 6| Step: 8
Training loss: 0.7496785428655782
Validation loss: 2.3327576378271715

Epoch: 6| Step: 9
Training loss: 0.6219922170918731
Validation loss: 2.2683833139466807

Epoch: 6| Step: 10
Training loss: 0.7561503793975921
Validation loss: 2.2733461563010455

Epoch: 6| Step: 11
Training loss: 0.7911364051067872
Validation loss: 2.273531573339936

Epoch: 6| Step: 12
Training loss: 0.7904790871813866
Validation loss: 2.315645553495215

Epoch: 6| Step: 13
Training loss: 0.3888573898698237
Validation loss: 2.304023928852283

Epoch: 551| Step: 0
Training loss: 0.8170413234817033
Validation loss: 2.255831808294581

Epoch: 6| Step: 1
Training loss: 0.7847148356657365
Validation loss: 2.2740455645621585

Epoch: 6| Step: 2
Training loss: 0.7197810117500641
Validation loss: 2.305163583444908

Epoch: 6| Step: 3
Training loss: 0.6232611786887614
Validation loss: 2.2562389707677797

Epoch: 6| Step: 4
Training loss: 0.5617475244953937
Validation loss: 2.2959241787415543

Epoch: 6| Step: 5
Training loss: 0.810983416189023
Validation loss: 2.2463931070643888

Epoch: 6| Step: 6
Training loss: 1.7233667270934694
Validation loss: 2.2858633518869684

Epoch: 6| Step: 7
Training loss: 0.627647229586361
Validation loss: 2.27792359740819

Epoch: 6| Step: 8
Training loss: 0.5873115196629853
Validation loss: 2.165367564862297

Epoch: 6| Step: 9
Training loss: 0.6800787665524598
Validation loss: 2.2729015631328195

Epoch: 6| Step: 10
Training loss: 0.8076014672886224
Validation loss: 2.270399964649448

Epoch: 6| Step: 11
Training loss: 0.5268852218414691
Validation loss: 2.2865441015398424

Epoch: 6| Step: 12
Training loss: 0.6504919757861228
Validation loss: 2.2743521735193712

Epoch: 6| Step: 13
Training loss: 0.8449023466282847
Validation loss: 2.2876566973937797

Epoch: 552| Step: 0
Training loss: 0.816939294002496
Validation loss: 2.339296509396471

Epoch: 6| Step: 1
Training loss: 0.6398243902349363
Validation loss: 2.254528665555271

Epoch: 6| Step: 2
Training loss: 0.5283918631962412
Validation loss: 2.2358665487556424

Epoch: 6| Step: 3
Training loss: 0.736934381928252
Validation loss: 2.2516170140918006

Epoch: 6| Step: 4
Training loss: 0.8281601952325349
Validation loss: 2.3222583908735204

Epoch: 6| Step: 5
Training loss: 0.9002818540463641
Validation loss: 2.2980743487495716

Epoch: 6| Step: 6
Training loss: 0.6169251475874769
Validation loss: 2.2769805135027172

Epoch: 6| Step: 7
Training loss: 0.5445496029271727
Validation loss: 2.2614232247337265

Epoch: 6| Step: 8
Training loss: 0.7538108172323973
Validation loss: 2.2756388848903764

Epoch: 6| Step: 9
Training loss: 1.70262187560744
Validation loss: 2.203978281999982

Epoch: 6| Step: 10
Training loss: 0.7122939866028106
Validation loss: 2.2401281252708105

Epoch: 6| Step: 11
Training loss: 0.3764613209521257
Validation loss: 2.1266573228459453

Epoch: 6| Step: 12
Training loss: 0.7461622116873834
Validation loss: 2.1950434761975046

Epoch: 6| Step: 13
Training loss: 0.7758958837477403
Validation loss: 2.203382040851911

Epoch: 553| Step: 0
Training loss: 1.0152095825408904
Validation loss: 2.228063583775964

Epoch: 6| Step: 1
Training loss: 0.5760675626823871
Validation loss: 2.2464895950202446

Epoch: 6| Step: 2
Training loss: 0.7292084863568578
Validation loss: 2.2554409310039585

Epoch: 6| Step: 3
Training loss: 0.654902801072099
Validation loss: 2.2412880577755914

Epoch: 6| Step: 4
Training loss: 0.5462162955424466
Validation loss: 2.2111746707451214

Epoch: 6| Step: 5
Training loss: 0.5699991122874659
Validation loss: 2.1702445316538355

Epoch: 6| Step: 6
Training loss: 0.48320576845153734
Validation loss: 2.280796547061854

Epoch: 6| Step: 7
Training loss: 0.8961904538430021
Validation loss: 2.2828786309503877

Epoch: 6| Step: 8
Training loss: 0.752120675580306
Validation loss: 2.247907230426921

Epoch: 6| Step: 9
Training loss: 0.8477705777324854
Validation loss: 2.2730555849109146

Epoch: 6| Step: 10
Training loss: 0.5926674711983966
Validation loss: 2.2778168046619083

Epoch: 6| Step: 11
Training loss: 0.6149645258976847
Validation loss: 2.3899372818589564

Epoch: 6| Step: 12
Training loss: 1.6582875224675697
Validation loss: 2.207984537667933

Epoch: 6| Step: 13
Training loss: 1.1115520767868592
Validation loss: 2.3184826208188434

Epoch: 554| Step: 0
Training loss: 0.5285587019750628
Validation loss: 2.2812995652407726

Epoch: 6| Step: 1
Training loss: 0.6113137435440225
Validation loss: 2.295829595317053

Epoch: 6| Step: 2
Training loss: 0.7671287716142997
Validation loss: 2.2578277706596808

Epoch: 6| Step: 3
Training loss: 0.6141170953062913
Validation loss: 2.3163951383853103

Epoch: 6| Step: 4
Training loss: 0.7164683407632468
Validation loss: 2.3561664249319962

Epoch: 6| Step: 5
Training loss: 1.6463383330424803
Validation loss: 2.2371217971395247

Epoch: 6| Step: 6
Training loss: 0.8500358826412264
Validation loss: 2.3090950526905587

Epoch: 6| Step: 7
Training loss: 0.7335298016740699
Validation loss: 2.331863238691703

Epoch: 6| Step: 8
Training loss: 0.6735603132025709
Validation loss: 2.3188596377976163

Epoch: 6| Step: 9
Training loss: 0.7055803026988998
Validation loss: 2.2548398515402734

Epoch: 6| Step: 10
Training loss: 0.90549532939353
Validation loss: 2.284361714716875

Epoch: 6| Step: 11
Training loss: 0.8276379430531137
Validation loss: 2.321120047213126

Epoch: 6| Step: 12
Training loss: 0.77415710265374
Validation loss: 2.31666635169665

Epoch: 6| Step: 13
Training loss: 0.5821169591687881
Validation loss: 2.2863648897944295

Epoch: 555| Step: 0
Training loss: 0.5872341051431196
Validation loss: 2.280287789872316

Epoch: 6| Step: 1
Training loss: 0.6555060529494864
Validation loss: 2.212970095726736

Epoch: 6| Step: 2
Training loss: 0.7279542698252114
Validation loss: 2.2812034837062716

Epoch: 6| Step: 3
Training loss: 0.5853705906185668
Validation loss: 2.332693439262493

Epoch: 6| Step: 4
Training loss: 0.788153285064269
Validation loss: 2.2523356839906654

Epoch: 6| Step: 5
Training loss: 0.7369588482934878
Validation loss: 2.236694751819492

Epoch: 6| Step: 6
Training loss: 1.65780739167745
Validation loss: 2.4086070965964796

Epoch: 6| Step: 7
Training loss: 0.7971754442691836
Validation loss: 2.29807039826807

Epoch: 6| Step: 8
Training loss: 0.5426896290353487
Validation loss: 2.2681576737909865

Epoch: 6| Step: 9
Training loss: 0.6724980370943147
Validation loss: 2.250645076748515

Epoch: 6| Step: 10
Training loss: 0.628257819979021
Validation loss: 2.2307138024088435

Epoch: 6| Step: 11
Training loss: 0.6101956343791912
Validation loss: 2.2733070886706055

Epoch: 6| Step: 12
Training loss: 1.0977737526770488
Validation loss: 2.221049201153864

Epoch: 6| Step: 13
Training loss: 0.5752182131808444
Validation loss: 2.2866837734719914

Epoch: 556| Step: 0
Training loss: 0.6211163018888708
Validation loss: 2.3121733541471863

Epoch: 6| Step: 1
Training loss: 0.5513783187904701
Validation loss: 2.2728219275279877

Epoch: 6| Step: 2
Training loss: 0.4536331878663184
Validation loss: 2.330976676803225

Epoch: 6| Step: 3
Training loss: 0.8893991030913923
Validation loss: 2.2828484617334044

Epoch: 6| Step: 4
Training loss: 0.8271695509268518
Validation loss: 2.2525844451953354

Epoch: 6| Step: 5
Training loss: 0.6942993454874726
Validation loss: 2.274964208185003

Epoch: 6| Step: 6
Training loss: 0.6122990171422427
Validation loss: 2.2682612328220473

Epoch: 6| Step: 7
Training loss: 0.8874659142194516
Validation loss: 2.311542795121717

Epoch: 6| Step: 8
Training loss: 0.6407693839770927
Validation loss: 2.280822837529957

Epoch: 6| Step: 9
Training loss: 1.7744784891948147
Validation loss: 2.2463059425795957

Epoch: 6| Step: 10
Training loss: 0.6405203198761577
Validation loss: 2.3002625648573196

Epoch: 6| Step: 11
Training loss: 0.4750073808799305
Validation loss: 2.2767727494025065

Epoch: 6| Step: 12
Training loss: 0.988898163893657
Validation loss: 2.260247581225202

Epoch: 6| Step: 13
Training loss: 0.6490615461596853
Validation loss: 2.20433288093444

Epoch: 557| Step: 0
Training loss: 0.4972786157773549
Validation loss: 2.280861271198664

Epoch: 6| Step: 1
Training loss: 0.6669746497153852
Validation loss: 2.247933808040622

Epoch: 6| Step: 2
Training loss: 0.5406683072070355
Validation loss: 2.265460230769706

Epoch: 6| Step: 3
Training loss: 0.819007926092116
Validation loss: 2.26372305500501

Epoch: 6| Step: 4
Training loss: 0.43176371342671344
Validation loss: 2.240163732377342

Epoch: 6| Step: 5
Training loss: 1.7166504954838708
Validation loss: 2.231651623935187

Epoch: 6| Step: 6
Training loss: 0.7298457298831794
Validation loss: 2.258427801185714

Epoch: 6| Step: 7
Training loss: 0.5481696471905232
Validation loss: 2.2508164614192894

Epoch: 6| Step: 8
Training loss: 0.5422966729000336
Validation loss: 2.2594240562053582

Epoch: 6| Step: 9
Training loss: 0.7954406919759268
Validation loss: 2.3169102318591785

Epoch: 6| Step: 10
Training loss: 0.6939013444932841
Validation loss: 2.2594698011609884

Epoch: 6| Step: 11
Training loss: 0.7726470298718396
Validation loss: 2.264339201254409

Epoch: 6| Step: 12
Training loss: 0.9289228356038114
Validation loss: 2.258646209346275

Epoch: 6| Step: 13
Training loss: 0.9455515661677192
Validation loss: 2.287020244774031

Epoch: 558| Step: 0
Training loss: 1.7234197122826604
Validation loss: 2.143444870141735

Epoch: 6| Step: 1
Training loss: 0.831799255407816
Validation loss: 2.2973285858079007

Epoch: 6| Step: 2
Training loss: 0.731201171875
Validation loss: 2.2379660083463833

Epoch: 6| Step: 3
Training loss: 0.7646630140842026
Validation loss: 2.2090300828569536

Epoch: 6| Step: 4
Training loss: 0.6454054250614459
Validation loss: 2.357369185092495

Epoch: 6| Step: 5
Training loss: 0.8410169347176141
Validation loss: 2.2370530943707303

Epoch: 6| Step: 6
Training loss: 0.38088856120641357
Validation loss: 2.3396537616388446

Epoch: 6| Step: 7
Training loss: 0.7826079202155174
Validation loss: 2.20145173342884

Epoch: 6| Step: 8
Training loss: 0.6629319833903763
Validation loss: 2.274377928674575

Epoch: 6| Step: 9
Training loss: 0.44788540871545474
Validation loss: 2.298996915768152

Epoch: 6| Step: 10
Training loss: 0.5024635599218128
Validation loss: 2.201902937428168

Epoch: 6| Step: 11
Training loss: 0.7384728077225772
Validation loss: 2.267743260370047

Epoch: 6| Step: 12
Training loss: 0.4002473528319961
Validation loss: 2.280319113841645

Epoch: 6| Step: 13
Training loss: 0.6468472571574391
Validation loss: 2.249133090021136

Epoch: 559| Step: 0
Training loss: 0.5547727331305912
Validation loss: 2.285256750776675

Epoch: 6| Step: 1
Training loss: 0.7142462395931883
Validation loss: 2.2759825904211417

Epoch: 6| Step: 2
Training loss: 0.8001375169578014
Validation loss: 2.275315833522863

Epoch: 6| Step: 3
Training loss: 0.8848589580562053
Validation loss: 2.2967209023795836

Epoch: 6| Step: 4
Training loss: 0.32638961696656277
Validation loss: 2.308632365409872

Epoch: 6| Step: 5
Training loss: 0.5737982527278439
Validation loss: 2.229195000513761

Epoch: 6| Step: 6
Training loss: 0.7595393375859977
Validation loss: 2.2648799136418467

Epoch: 6| Step: 7
Training loss: 0.6625896051377341
Validation loss: 2.2433611545871126

Epoch: 6| Step: 8
Training loss: 0.6646238759110067
Validation loss: 2.2602311263234425

Epoch: 6| Step: 9
Training loss: 0.6653694082982251
Validation loss: 2.2602484432398446

Epoch: 6| Step: 10
Training loss: 1.7227483538790123
Validation loss: 2.2459872874976945

Epoch: 6| Step: 11
Training loss: 0.5332806988413455
Validation loss: 2.182797613066804

Epoch: 6| Step: 12
Training loss: 0.9420225413393346
Validation loss: 2.260185653686781

Epoch: 6| Step: 13
Training loss: 0.9948905110142774
Validation loss: 2.214442216842045

Epoch: 560| Step: 0
Training loss: 0.6589528463494804
Validation loss: 2.2806676553151037

Epoch: 6| Step: 1
Training loss: 0.6772106466663583
Validation loss: 2.238213136047436

Epoch: 6| Step: 2
Training loss: 0.5229291582578605
Validation loss: 2.255589254040891

Epoch: 6| Step: 3
Training loss: 0.6988271117269677
Validation loss: 2.3092781056003413

Epoch: 6| Step: 4
Training loss: 0.9941119656431993
Validation loss: 2.252527296490374

Epoch: 6| Step: 5
Training loss: 0.615255833811656
Validation loss: 2.3041703717613755

Epoch: 6| Step: 6
Training loss: 0.6250568364049562
Validation loss: 2.273399615454021

Epoch: 6| Step: 7
Training loss: 0.6483500777912248
Validation loss: 2.2845419420611095

Epoch: 6| Step: 8
Training loss: 0.6955132569654588
Validation loss: 2.210729966322286

Epoch: 6| Step: 9
Training loss: 0.7190663429366452
Validation loss: 2.1972631071707496

Epoch: 6| Step: 10
Training loss: 1.7059806191885285
Validation loss: 2.288480005932776

Epoch: 6| Step: 11
Training loss: 0.5519003354885259
Validation loss: 2.29814067761659

Epoch: 6| Step: 12
Training loss: 0.8043279492682447
Validation loss: 2.2107227058333883

Epoch: 6| Step: 13
Training loss: 0.6435769617049383
Validation loss: 2.3737286104495703

Epoch: 561| Step: 0
Training loss: 0.6840160700209725
Validation loss: 2.265878300974829

Epoch: 6| Step: 1
Training loss: 0.6823551400825768
Validation loss: 2.2316931140266267

Epoch: 6| Step: 2
Training loss: 0.71058755163664
Validation loss: 2.2555796482782604

Epoch: 6| Step: 3
Training loss: 1.0033017130607946
Validation loss: 2.232108322251423

Epoch: 6| Step: 4
Training loss: 0.8898445859508255
Validation loss: 2.3255638729761516

Epoch: 6| Step: 5
Training loss: 0.7883729471156046
Validation loss: 2.227123082418039

Epoch: 6| Step: 6
Training loss: 0.6507754633578687
Validation loss: 2.2315331303968082

Epoch: 6| Step: 7
Training loss: 0.6414807117279975
Validation loss: 2.2321626952384084

Epoch: 6| Step: 8
Training loss: 0.42233523237112053
Validation loss: 2.2829737211745083

Epoch: 6| Step: 9
Training loss: 0.9160644583302796
Validation loss: 2.22655485965416

Epoch: 6| Step: 10
Training loss: 0.6056875756357862
Validation loss: 2.2606332069483495

Epoch: 6| Step: 11
Training loss: 0.8159213291466557
Validation loss: 2.334688566197109

Epoch: 6| Step: 12
Training loss: 1.599172306551123
Validation loss: 2.2671051208985373

Epoch: 6| Step: 13
Training loss: 0.6198145330575948
Validation loss: 2.224063171588475

Epoch: 562| Step: 0
Training loss: 0.6444408237718218
Validation loss: 2.2477213904742035

Epoch: 6| Step: 1
Training loss: 0.4569869875870879
Validation loss: 2.2549411958672847

Epoch: 6| Step: 2
Training loss: 0.45316186294567706
Validation loss: 2.280900213373698

Epoch: 6| Step: 3
Training loss: 0.5715323688121313
Validation loss: 2.2204369396372865

Epoch: 6| Step: 4
Training loss: 0.9183212901939429
Validation loss: 2.2604371632232265

Epoch: 6| Step: 5
Training loss: 1.7056868996855523
Validation loss: 2.2438719381629397

Epoch: 6| Step: 6
Training loss: 0.6494569004242328
Validation loss: 2.1927961994848446

Epoch: 6| Step: 7
Training loss: 0.8285827091581338
Validation loss: 2.271189293043513

Epoch: 6| Step: 8
Training loss: 0.6910345511596753
Validation loss: 2.264090769680787

Epoch: 6| Step: 9
Training loss: 0.7996255490037429
Validation loss: 2.284780405536762

Epoch: 6| Step: 10
Training loss: 0.5900306405581062
Validation loss: 2.3120737470065893

Epoch: 6| Step: 11
Training loss: 0.9505226379098702
Validation loss: 2.2485104282285118

Epoch: 6| Step: 12
Training loss: 0.7360848751031095
Validation loss: 2.2117075355848708

Epoch: 6| Step: 13
Training loss: 0.7191738040197123
Validation loss: 2.2791892315717375

Epoch: 563| Step: 0
Training loss: 0.6668630673271363
Validation loss: 2.207332103949458

Epoch: 6| Step: 1
Training loss: 0.6536140636813867
Validation loss: 2.2598460831520324

Epoch: 6| Step: 2
Training loss: 0.6867682290506381
Validation loss: 2.3181394232574

Epoch: 6| Step: 3
Training loss: 0.7262596401553084
Validation loss: 2.268503106260939

Epoch: 6| Step: 4
Training loss: 0.5162865989218172
Validation loss: 2.2388801067794852

Epoch: 6| Step: 5
Training loss: 0.8450157067571527
Validation loss: 2.195701128264825

Epoch: 6| Step: 6
Training loss: 0.8505943464351853
Validation loss: 2.2903753070038904

Epoch: 6| Step: 7
Training loss: 0.5648307724935262
Validation loss: 2.2568718875889187

Epoch: 6| Step: 8
Training loss: 0.4760925915425112
Validation loss: 2.2346846319140026

Epoch: 6| Step: 9
Training loss: 0.7450074281258184
Validation loss: 2.260164847839907

Epoch: 6| Step: 10
Training loss: 0.9997016342418363
Validation loss: 2.269062454338852

Epoch: 6| Step: 11
Training loss: 0.6909098594378345
Validation loss: 2.3021491598164125

Epoch: 6| Step: 12
Training loss: 1.6257564544620002
Validation loss: 2.2405678140400407

Epoch: 6| Step: 13
Training loss: 0.7276116866148905
Validation loss: 2.2781399361757306

Epoch: 564| Step: 0
Training loss: 0.6140199088354333
Validation loss: 2.2062054058091625

Epoch: 6| Step: 1
Training loss: 0.6106958501625767
Validation loss: 2.222342486827414

Epoch: 6| Step: 2
Training loss: 1.6512184730309647
Validation loss: 2.2043269943986474

Epoch: 6| Step: 3
Training loss: 0.7853769779717739
Validation loss: 2.268898859284451

Epoch: 6| Step: 4
Training loss: 0.5320035414685421
Validation loss: 2.214940692740308

Epoch: 6| Step: 5
Training loss: 0.6661190724509105
Validation loss: 2.1890521284069386

Epoch: 6| Step: 6
Training loss: 0.6531801629384865
Validation loss: 2.2578565097406686

Epoch: 6| Step: 7
Training loss: 0.6294195556400921
Validation loss: 2.2242783227890244

Epoch: 6| Step: 8
Training loss: 0.6673892446492103
Validation loss: 2.242670678370256

Epoch: 6| Step: 9
Training loss: 0.7718443211933655
Validation loss: 2.2174132696794646

Epoch: 6| Step: 10
Training loss: 0.7287467201381572
Validation loss: 2.2612772320831365

Epoch: 6| Step: 11
Training loss: 0.4664282360677613
Validation loss: 2.241579560272679

Epoch: 6| Step: 12
Training loss: 0.789899853865449
Validation loss: 2.2406635843286233

Epoch: 6| Step: 13
Training loss: 0.6060894645427304
Validation loss: 2.268695368637714

Epoch: 565| Step: 0
Training loss: 0.44044614706135105
Validation loss: 2.233444112890174

Epoch: 6| Step: 1
Training loss: 0.5773444189911762
Validation loss: 2.2675231563455136

Epoch: 6| Step: 2
Training loss: 0.886825857541638
Validation loss: 2.278994591153502

Epoch: 6| Step: 3
Training loss: 1.7326595311112718
Validation loss: 2.232507471521019

Epoch: 6| Step: 4
Training loss: 0.5534242294762469
Validation loss: 2.2251017128135264

Epoch: 6| Step: 5
Training loss: 0.6454723769718345
Validation loss: 2.2888005909088527

Epoch: 6| Step: 6
Training loss: 0.8131769001587805
Validation loss: 2.2163518123041457

Epoch: 6| Step: 7
Training loss: 0.655555766607599
Validation loss: 2.220421797454693

Epoch: 6| Step: 8
Training loss: 0.717899192122119
Validation loss: 2.26269105183811

Epoch: 6| Step: 9
Training loss: 0.5362423922036889
Validation loss: 2.229851141992526

Epoch: 6| Step: 10
Training loss: 0.6034392768442554
Validation loss: 2.322073447684657

Epoch: 6| Step: 11
Training loss: 0.8971806566913485
Validation loss: 2.154419365474697

Epoch: 6| Step: 12
Training loss: 0.5662298519768941
Validation loss: 2.2558955650940726

Epoch: 6| Step: 13
Training loss: 0.6959809294272064
Validation loss: 2.2487449808991617

Epoch: 566| Step: 0
Training loss: 0.7012338637469104
Validation loss: 2.2542263840200474

Epoch: 6| Step: 1
Training loss: 0.5566507438944578
Validation loss: 2.269693417800677

Epoch: 6| Step: 2
Training loss: 1.6868820471826647
Validation loss: 2.2647296985197216

Epoch: 6| Step: 3
Training loss: 0.7206514748360966
Validation loss: 2.3114509985857112

Epoch: 6| Step: 4
Training loss: 0.7304683420108737
Validation loss: 2.3308343928311213

Epoch: 6| Step: 5
Training loss: 0.814132151488679
Validation loss: 2.297187295632572

Epoch: 6| Step: 6
Training loss: 0.47277338767538
Validation loss: 2.2802007399862414

Epoch: 6| Step: 7
Training loss: 0.6629811626911299
Validation loss: 2.254010013405472

Epoch: 6| Step: 8
Training loss: 0.744556821241892
Validation loss: 2.283191132621654

Epoch: 6| Step: 9
Training loss: 0.549409253221083
Validation loss: 2.2638172126819804

Epoch: 6| Step: 10
Training loss: 0.6992464752667609
Validation loss: 2.2485395566087507

Epoch: 6| Step: 11
Training loss: 0.7139019624978334
Validation loss: 2.366947866834276

Epoch: 6| Step: 12
Training loss: 0.6883644391467707
Validation loss: 2.2404464145133436

Epoch: 6| Step: 13
Training loss: 0.809325214460218
Validation loss: 2.269490636344584

Epoch: 567| Step: 0
Training loss: 0.47051608853090404
Validation loss: 2.186384425803616

Epoch: 6| Step: 1
Training loss: 0.7370670567237984
Validation loss: 2.2665779369958257

Epoch: 6| Step: 2
Training loss: 0.6718089936236149
Validation loss: 2.2419107941051255

Epoch: 6| Step: 3
Training loss: 0.6268915401646118
Validation loss: 2.2557502040079562

Epoch: 6| Step: 4
Training loss: 0.6850303595142834
Validation loss: 2.2271346060469783

Epoch: 6| Step: 5
Training loss: 0.5188602617578847
Validation loss: 2.2467295710035673

Epoch: 6| Step: 6
Training loss: 0.4839414994750598
Validation loss: 2.241650471062905

Epoch: 6| Step: 7
Training loss: 0.8470920847565632
Validation loss: 2.201529917515939

Epoch: 6| Step: 8
Training loss: 0.920764383407222
Validation loss: 2.298451761747587

Epoch: 6| Step: 9
Training loss: 0.761990894706272
Validation loss: 2.318535868810215

Epoch: 6| Step: 10
Training loss: 0.936904272903469
Validation loss: 2.259993024126141

Epoch: 6| Step: 11
Training loss: 0.640530393174164
Validation loss: 2.2484732795330244

Epoch: 6| Step: 12
Training loss: 0.6685264222580558
Validation loss: 2.2528010804669956

Epoch: 6| Step: 13
Training loss: 2.1296112293179497
Validation loss: 2.2406080949709417

Epoch: 568| Step: 0
Training loss: 0.3726179843025874
Validation loss: 2.2543804504234393

Epoch: 6| Step: 1
Training loss: 0.6043552619527639
Validation loss: 2.240042254586665

Epoch: 6| Step: 2
Training loss: 0.5944522920528236
Validation loss: 2.1989884563858717

Epoch: 6| Step: 3
Training loss: 0.6017222997282845
Validation loss: 2.290294755262291

Epoch: 6| Step: 4
Training loss: 0.5934846184592464
Validation loss: 2.2833259027604336

Epoch: 6| Step: 5
Training loss: 0.5940560004106012
Validation loss: 2.1913328856208216

Epoch: 6| Step: 6
Training loss: 0.6964319411570031
Validation loss: 2.1990139447190296

Epoch: 6| Step: 7
Training loss: 0.7246721348484554
Validation loss: 2.273096998780072

Epoch: 6| Step: 8
Training loss: 0.5360870619745547
Validation loss: 2.2429495256138523

Epoch: 6| Step: 9
Training loss: 0.6740552878668239
Validation loss: 2.260260908104967

Epoch: 6| Step: 10
Training loss: 0.7468329956501143
Validation loss: 2.180711303844055

Epoch: 6| Step: 11
Training loss: 1.5913274716489174
Validation loss: 2.217110487536655

Epoch: 6| Step: 12
Training loss: 0.6884020609485114
Validation loss: 2.2549492240660487

Epoch: 6| Step: 13
Training loss: 0.7199605615728801
Validation loss: 2.1893907980343505

Epoch: 569| Step: 0
Training loss: 0.7517216710168878
Validation loss: 2.216870265156215

Epoch: 6| Step: 1
Training loss: 0.6910001779989408
Validation loss: 2.311633159598876

Epoch: 6| Step: 2
Training loss: 0.5826427652318217
Validation loss: 2.2597171172964763

Epoch: 6| Step: 3
Training loss: 1.6539710578600362
Validation loss: 2.1920130652871466

Epoch: 6| Step: 4
Training loss: 0.4964048356422397
Validation loss: 2.258250669784215

Epoch: 6| Step: 5
Training loss: 0.6279465834745721
Validation loss: 2.288617536692744

Epoch: 6| Step: 6
Training loss: 0.9429556731144578
Validation loss: 2.2351576807321654

Epoch: 6| Step: 7
Training loss: 0.6256568318289942
Validation loss: 2.293166477671185

Epoch: 6| Step: 8
Training loss: 0.5581864158953859
Validation loss: 2.247964534219269

Epoch: 6| Step: 9
Training loss: 0.7005818469244777
Validation loss: 2.295901535832634

Epoch: 6| Step: 10
Training loss: 0.5794054748849287
Validation loss: 2.2717637745598744

Epoch: 6| Step: 11
Training loss: 0.6018510597039033
Validation loss: 2.267810395250584

Epoch: 6| Step: 12
Training loss: 0.4732523068091207
Validation loss: 2.2080970373829656

Epoch: 6| Step: 13
Training loss: 0.8553518624772738
Validation loss: 2.304270296344539

Epoch: 570| Step: 0
Training loss: 0.5163040602506452
Validation loss: 2.2444561079222694

Epoch: 6| Step: 1
Training loss: 0.5488560353848996
Validation loss: 2.3097780433032473

Epoch: 6| Step: 2
Training loss: 1.5713052221288764
Validation loss: 2.2770632298061373

Epoch: 6| Step: 3
Training loss: 0.6883191950164239
Validation loss: 2.296995032447674

Epoch: 6| Step: 4
Training loss: 0.7842691068866312
Validation loss: 2.1523324095778236

Epoch: 6| Step: 5
Training loss: 0.5687042448482057
Validation loss: 2.300659536927333

Epoch: 6| Step: 6
Training loss: 0.7079884493580658
Validation loss: 2.1869637999707248

Epoch: 6| Step: 7
Training loss: 0.5965360477951404
Validation loss: 2.2268982256181533

Epoch: 6| Step: 8
Training loss: 0.4741471162641752
Validation loss: 2.2418361287172095

Epoch: 6| Step: 9
Training loss: 0.686128700910759
Validation loss: 2.261818157351203

Epoch: 6| Step: 10
Training loss: 0.8277894545875804
Validation loss: 2.2171048575140766

Epoch: 6| Step: 11
Training loss: 0.7328734773102462
Validation loss: 2.2759998640865646

Epoch: 6| Step: 12
Training loss: 0.7299967173933664
Validation loss: 2.2847964053700744

Epoch: 6| Step: 13
Training loss: 0.44334433441865717
Validation loss: 2.2164047026586253

Epoch: 571| Step: 0
Training loss: 0.6309747029521943
Validation loss: 2.2410254271005825

Epoch: 6| Step: 1
Training loss: 1.6066011393838036
Validation loss: 2.242813558615119

Epoch: 6| Step: 2
Training loss: 0.4087931553052064
Validation loss: 2.2502032795438303

Epoch: 6| Step: 3
Training loss: 0.5707758758567608
Validation loss: 2.2575000243402203

Epoch: 6| Step: 4
Training loss: 0.7935828475969355
Validation loss: 2.2895608726445644

Epoch: 6| Step: 5
Training loss: 0.8049188299898082
Validation loss: 2.2560647986809044

Epoch: 6| Step: 6
Training loss: 0.7584195409408118
Validation loss: 2.287611063338779

Epoch: 6| Step: 7
Training loss: 0.9667842054981882
Validation loss: 2.2852383164389836

Epoch: 6| Step: 8
Training loss: 0.7738764509490295
Validation loss: 2.288349453676217

Epoch: 6| Step: 9
Training loss: 0.4877180742689418
Validation loss: 2.233124145123021

Epoch: 6| Step: 10
Training loss: 0.6373652353146614
Validation loss: 2.3138667720644106

Epoch: 6| Step: 11
Training loss: 0.7543291872236211
Validation loss: 2.3186747253580693

Epoch: 6| Step: 12
Training loss: 0.9356878568625552
Validation loss: 2.336349525046889

Epoch: 6| Step: 13
Training loss: 0.6321439861760129
Validation loss: 2.3182669349537433

Epoch: 572| Step: 0
Training loss: 0.6523327855085289
Validation loss: 2.2488691919061488

Epoch: 6| Step: 1
Training loss: 0.8257769639581556
Validation loss: 2.2709529262306596

Epoch: 6| Step: 2
Training loss: 0.6670560568840834
Validation loss: 2.234167420801374

Epoch: 6| Step: 3
Training loss: 0.6661958870016691
Validation loss: 2.2376318739815755

Epoch: 6| Step: 4
Training loss: 0.6739623668575504
Validation loss: 2.263667791716221

Epoch: 6| Step: 5
Training loss: 0.6556109541269382
Validation loss: 2.1873216266245983

Epoch: 6| Step: 6
Training loss: 0.5885842119441073
Validation loss: 2.2399905037587096

Epoch: 6| Step: 7
Training loss: 0.618227529054919
Validation loss: 2.190099931979395

Epoch: 6| Step: 8
Training loss: 1.6993656489573399
Validation loss: 2.240495726471606

Epoch: 6| Step: 9
Training loss: 0.6602327652328055
Validation loss: 2.2930195802025475

Epoch: 6| Step: 10
Training loss: 0.7231468803372759
Validation loss: 2.2804024403407546

Epoch: 6| Step: 11
Training loss: 0.763885663247282
Validation loss: 2.2978587864422653

Epoch: 6| Step: 12
Training loss: 0.5874357523181388
Validation loss: 2.192714498728159

Epoch: 6| Step: 13
Training loss: 0.7598855284388031
Validation loss: 2.2443224664936534

Epoch: 573| Step: 0
Training loss: 0.8006949029285022
Validation loss: 2.2760288586116166

Epoch: 6| Step: 1
Training loss: 0.8178334150602575
Validation loss: 2.3171594909874127

Epoch: 6| Step: 2
Training loss: 0.7956514127292196
Validation loss: 2.3287414078325

Epoch: 6| Step: 3
Training loss: 1.6550863964890594
Validation loss: 2.2533744041919235

Epoch: 6| Step: 4
Training loss: 0.6201150969222265
Validation loss: 2.2628379219292873

Epoch: 6| Step: 5
Training loss: 0.5987003655457548
Validation loss: 2.2606430390236754

Epoch: 6| Step: 6
Training loss: 0.6056686317544584
Validation loss: 2.2011101646343176

Epoch: 6| Step: 7
Training loss: 0.5197591066833318
Validation loss: 2.309241290576537

Epoch: 6| Step: 8
Training loss: 0.6964784126646982
Validation loss: 2.2376640614404044

Epoch: 6| Step: 9
Training loss: 0.6812249695265473
Validation loss: 2.234043200825462

Epoch: 6| Step: 10
Training loss: 0.7994840955219902
Validation loss: 2.2064584534519316

Epoch: 6| Step: 11
Training loss: 0.7359558297565562
Validation loss: 2.242863876109436

Epoch: 6| Step: 12
Training loss: 0.8723582852761901
Validation loss: 2.201288384419925

Epoch: 6| Step: 13
Training loss: 0.6507847367979797
Validation loss: 2.235122014234518

Epoch: 574| Step: 0
Training loss: 1.0028652032998677
Validation loss: 2.2914375142130545

Epoch: 6| Step: 1
Training loss: 0.7357651154277524
Validation loss: 2.2836662337978644

Epoch: 6| Step: 2
Training loss: 0.7190537018384819
Validation loss: 2.25335541095277

Epoch: 6| Step: 3
Training loss: 0.6408587936292702
Validation loss: 2.2131900094460595

Epoch: 6| Step: 4
Training loss: 0.5001328411064447
Validation loss: 2.2427002432471568

Epoch: 6| Step: 5
Training loss: 0.6918497764310801
Validation loss: 2.22962428657133

Epoch: 6| Step: 6
Training loss: 0.7554797813769919
Validation loss: 2.2570853567084153

Epoch: 6| Step: 7
Training loss: 0.49295597029623595
Validation loss: 2.2393474396436184

Epoch: 6| Step: 8
Training loss: 0.4903512944470179
Validation loss: 2.258982926186424

Epoch: 6| Step: 9
Training loss: 0.6448930591820783
Validation loss: 2.2634518054604666

Epoch: 6| Step: 10
Training loss: 0.6944255100424019
Validation loss: 2.2759864668838925

Epoch: 6| Step: 11
Training loss: 0.7172365009796664
Validation loss: 2.2392146714036665

Epoch: 6| Step: 12
Training loss: 0.6164534344037492
Validation loss: 2.2413601942069463

Epoch: 6| Step: 13
Training loss: 2.0627932484547165
Validation loss: 2.250138924524425

Epoch: 575| Step: 0
Training loss: 0.6931806307070435
Validation loss: 2.2515142283631824

Epoch: 6| Step: 1
Training loss: 0.7060624962423695
Validation loss: 2.2984276750512596

Epoch: 6| Step: 2
Training loss: 0.6872786902638143
Validation loss: 2.202157093552497

Epoch: 6| Step: 3
Training loss: 0.4653023773383497
Validation loss: 2.1729922811069637

Epoch: 6| Step: 4
Training loss: 0.8181681625835363
Validation loss: 2.24303469753021

Epoch: 6| Step: 5
Training loss: 0.7551643271066558
Validation loss: 2.271236464802177

Epoch: 6| Step: 6
Training loss: 0.4974225188548165
Validation loss: 2.119541381305172

Epoch: 6| Step: 7
Training loss: 0.5881582772451217
Validation loss: 2.2180391345938704

Epoch: 6| Step: 8
Training loss: 0.7230165974992548
Validation loss: 2.2091958232076494

Epoch: 6| Step: 9
Training loss: 0.5825480528481595
Validation loss: 2.174969940086262

Epoch: 6| Step: 10
Training loss: 0.7619001514892788
Validation loss: 2.2106621057388933

Epoch: 6| Step: 11
Training loss: 0.6705320376679429
Validation loss: 2.2186430374237998

Epoch: 6| Step: 12
Training loss: 0.5377146691421149
Validation loss: 2.3219791085434136

Epoch: 6| Step: 13
Training loss: 2.1967586220619495
Validation loss: 2.2570916610634684

Epoch: 576| Step: 0
Training loss: 0.9017205336187395
Validation loss: 2.269409703951467

Epoch: 6| Step: 1
Training loss: 0.4527262380031667
Validation loss: 2.2790334004297543

Epoch: 6| Step: 2
Training loss: 0.6964658536817839
Validation loss: 2.2147942381760197

Epoch: 6| Step: 3
Training loss: 0.692261635489334
Validation loss: 2.2131415048974046

Epoch: 6| Step: 4
Training loss: 0.7095559918580527
Validation loss: 2.2902425213345263

Epoch: 6| Step: 5
Training loss: 0.6722750249157846
Validation loss: 2.254067222329464

Epoch: 6| Step: 6
Training loss: 0.364003560612105
Validation loss: 2.1798803001838354

Epoch: 6| Step: 7
Training loss: 0.7729752825971239
Validation loss: 2.1783351212876823

Epoch: 6| Step: 8
Training loss: 0.6127829501484312
Validation loss: 2.184460896905636

Epoch: 6| Step: 9
Training loss: 0.572938803042843
Validation loss: 2.24654729614597

Epoch: 6| Step: 10
Training loss: 0.6852175799316459
Validation loss: 2.2779423278413486

Epoch: 6| Step: 11
Training loss: 1.7645606149459303
Validation loss: 2.264402925701924

Epoch: 6| Step: 12
Training loss: 0.825182960914402
Validation loss: 2.1602577390797135

Epoch: 6| Step: 13
Training loss: 0.8174824898853957
Validation loss: 2.245807121289485

Epoch: 577| Step: 0
Training loss: 0.954993589439646
Validation loss: 2.267185315193372

Epoch: 6| Step: 1
Training loss: 1.6312601111087723
Validation loss: 2.235513936547712

Epoch: 6| Step: 2
Training loss: 0.6979198218506809
Validation loss: 2.2484863754816646

Epoch: 6| Step: 3
Training loss: 0.6991072198157502
Validation loss: 2.2119350023171966

Epoch: 6| Step: 4
Training loss: 0.7035075948152066
Validation loss: 2.2014534115054887

Epoch: 6| Step: 5
Training loss: 0.6843688711998043
Validation loss: 2.274034152390091

Epoch: 6| Step: 6
Training loss: 0.39323200031126904
Validation loss: 2.3259100025057857

Epoch: 6| Step: 7
Training loss: 0.796661497947919
Validation loss: 2.238745786665505

Epoch: 6| Step: 8
Training loss: 0.7750274038084413
Validation loss: 2.2587399158238717

Epoch: 6| Step: 9
Training loss: 0.5681310503126554
Validation loss: 2.236596608545678

Epoch: 6| Step: 10
Training loss: 0.5737045217287636
Validation loss: 2.2325824603748226

Epoch: 6| Step: 11
Training loss: 0.6208207112081033
Validation loss: 2.2364782520584434

Epoch: 6| Step: 12
Training loss: 0.7552852372223623
Validation loss: 2.274244442593332

Epoch: 6| Step: 13
Training loss: 0.6069883657892768
Validation loss: 2.2357517197268533

Epoch: 578| Step: 0
Training loss: 0.5836152661300869
Validation loss: 2.3496487281865717

Epoch: 6| Step: 1
Training loss: 1.5324068176167662
Validation loss: 2.2686853906579003

Epoch: 6| Step: 2
Training loss: 0.48509627138866207
Validation loss: 2.1807447346662063

Epoch: 6| Step: 3
Training loss: 0.5488927402674391
Validation loss: 2.2315498962831746

Epoch: 6| Step: 4
Training loss: 0.686727827096779
Validation loss: 2.2725651783648546

Epoch: 6| Step: 5
Training loss: 0.6642333988861725
Validation loss: 2.297972420807321

Epoch: 6| Step: 6
Training loss: 0.5821068733805638
Validation loss: 2.308116796319393

Epoch: 6| Step: 7
Training loss: 0.7606231635517403
Validation loss: 2.285613508518883

Epoch: 6| Step: 8
Training loss: 0.5667204675892943
Validation loss: 2.348296161058926

Epoch: 6| Step: 9
Training loss: 0.7719942749779657
Validation loss: 2.365824059250901

Epoch: 6| Step: 10
Training loss: 0.825315712717051
Validation loss: 2.3005211074396077

Epoch: 6| Step: 11
Training loss: 0.8008376311015843
Validation loss: 2.225105219509214

Epoch: 6| Step: 12
Training loss: 0.6429173464059688
Validation loss: 2.290510099056594

Epoch: 6| Step: 13
Training loss: 0.8899561729784157
Validation loss: 2.215093366493597

Epoch: 579| Step: 0
Training loss: 0.621188606360245
Validation loss: 2.2378105349100283

Epoch: 6| Step: 1
Training loss: 0.6717064890127389
Validation loss: 2.2532376952620385

Epoch: 6| Step: 2
Training loss: 0.5349855359519787
Validation loss: 2.22041012006547

Epoch: 6| Step: 3
Training loss: 1.6523200139354175
Validation loss: 2.27512668341191

Epoch: 6| Step: 4
Training loss: 0.6796964885950412
Validation loss: 2.249935326962768

Epoch: 6| Step: 5
Training loss: 0.6314030008626561
Validation loss: 2.2273206587606804

Epoch: 6| Step: 6
Training loss: 0.8639885606913575
Validation loss: 2.223205856012532

Epoch: 6| Step: 7
Training loss: 0.7952863527807525
Validation loss: 2.262870913224064

Epoch: 6| Step: 8
Training loss: 0.3916445206745744
Validation loss: 2.2303482372804164

Epoch: 6| Step: 9
Training loss: 0.6760703554419131
Validation loss: 2.3058912011735115

Epoch: 6| Step: 10
Training loss: 0.4680442901932185
Validation loss: 2.2557119527936624

Epoch: 6| Step: 11
Training loss: 0.8022477282869076
Validation loss: 2.2741156647964194

Epoch: 6| Step: 12
Training loss: 1.0075985585320897
Validation loss: 2.300110126973562

Epoch: 6| Step: 13
Training loss: 0.8403196184304396
Validation loss: 2.2365095757859037

Epoch: 580| Step: 0
Training loss: 0.769951255543548
Validation loss: 2.2580441183203157

Epoch: 6| Step: 1
Training loss: 0.678759544333555
Validation loss: 2.2618295206495946

Epoch: 6| Step: 2
Training loss: 0.5181765569567335
Validation loss: 2.2696483075604372

Epoch: 6| Step: 3
Training loss: 0.6042914727529894
Validation loss: 2.310964458667511

Epoch: 6| Step: 4
Training loss: 1.7380582859331568
Validation loss: 2.3077514848767793

Epoch: 6| Step: 5
Training loss: 0.6180797597762882
Validation loss: 2.2594322687394977

Epoch: 6| Step: 6
Training loss: 0.5248760837817195
Validation loss: 2.226319954655548

Epoch: 6| Step: 7
Training loss: 0.7215952326973426
Validation loss: 2.220478714900016

Epoch: 6| Step: 8
Training loss: 0.5283693301436103
Validation loss: 2.2808200657488507

Epoch: 6| Step: 9
Training loss: 0.5642186770231781
Validation loss: 2.2490943204788354

Epoch: 6| Step: 10
Training loss: 0.7885501822478362
Validation loss: 2.2330418797707545

Epoch: 6| Step: 11
Training loss: 0.7246396863000881
Validation loss: 2.1887171753238737

Epoch: 6| Step: 12
Training loss: 0.5399507584902888
Validation loss: 2.2540015689950925

Epoch: 6| Step: 13
Training loss: 0.5942494149211207
Validation loss: 2.271601064445268

Epoch: 581| Step: 0
Training loss: 0.6692147262348959
Validation loss: 2.238281445570427

Epoch: 6| Step: 1
Training loss: 0.6852839038899601
Validation loss: 2.2721856798039552

Epoch: 6| Step: 2
Training loss: 0.5782250240504874
Validation loss: 2.25194583234887

Epoch: 6| Step: 3
Training loss: 0.8765979548881047
Validation loss: 2.2930831253151616

Epoch: 6| Step: 4
Training loss: 1.6348104710050606
Validation loss: 2.298137701385539

Epoch: 6| Step: 5
Training loss: 0.6064709644144519
Validation loss: 2.304975789933542

Epoch: 6| Step: 6
Training loss: 0.9219729161390939
Validation loss: 2.265510189554733

Epoch: 6| Step: 7
Training loss: 0.5756578124196847
Validation loss: 2.2936893627798796

Epoch: 6| Step: 8
Training loss: 0.7500100135134753
Validation loss: 2.2266071504362728

Epoch: 6| Step: 9
Training loss: 0.7870613632515037
Validation loss: 2.2108214390760677

Epoch: 6| Step: 10
Training loss: 0.6770226647021734
Validation loss: 2.257554908294273

Epoch: 6| Step: 11
Training loss: 0.7111932483148792
Validation loss: 2.271560132857613

Epoch: 6| Step: 12
Training loss: 0.5294346647631353
Validation loss: 2.1771865288797874

Epoch: 6| Step: 13
Training loss: 0.9134544567266079
Validation loss: 2.210669934663648

Epoch: 582| Step: 0
Training loss: 0.7255372638215731
Validation loss: 2.2468169940372658

Epoch: 6| Step: 1
Training loss: 0.7993024989125918
Validation loss: 2.226708610560669

Epoch: 6| Step: 2
Training loss: 0.9393065530557121
Validation loss: 2.325386699327587

Epoch: 6| Step: 3
Training loss: 0.7486992523623729
Validation loss: 2.1905528714788525

Epoch: 6| Step: 4
Training loss: 1.6339660658096695
Validation loss: 2.174008945090351

Epoch: 6| Step: 5
Training loss: 0.6634428162256205
Validation loss: 2.25029990488821

Epoch: 6| Step: 6
Training loss: 0.5532889936627572
Validation loss: 2.1794330273279403

Epoch: 6| Step: 7
Training loss: 0.7239850174265133
Validation loss: 2.1980964164519086

Epoch: 6| Step: 8
Training loss: 0.6936830866393411
Validation loss: 2.237948311097799

Epoch: 6| Step: 9
Training loss: 0.5592069128232722
Validation loss: 2.263783074974565

Epoch: 6| Step: 10
Training loss: 0.6981572452977066
Validation loss: 2.2959883189920918

Epoch: 6| Step: 11
Training loss: 0.3700924263675788
Validation loss: 2.23332818818483

Epoch: 6| Step: 12
Training loss: 0.41781251429441507
Validation loss: 2.2833310293041245

Epoch: 6| Step: 13
Training loss: 0.5714553460592288
Validation loss: 2.3247121365648336

Epoch: 583| Step: 0
Training loss: 0.41891369111204757
Validation loss: 2.2205552171389225

Epoch: 6| Step: 1
Training loss: 1.0142672339430994
Validation loss: 2.34379854760428

Epoch: 6| Step: 2
Training loss: 0.6914737474501694
Validation loss: 2.329610228742442

Epoch: 6| Step: 3
Training loss: 0.8768960641083342
Validation loss: 2.224224555237511

Epoch: 6| Step: 4
Training loss: 0.5433260339069144
Validation loss: 2.1820487217249376

Epoch: 6| Step: 5
Training loss: 0.5075924910276273
Validation loss: 2.2864837153604025

Epoch: 6| Step: 6
Training loss: 0.80717022300245
Validation loss: 2.203642470854136

Epoch: 6| Step: 7
Training loss: 1.4182252257879921
Validation loss: 2.2537848782084415

Epoch: 6| Step: 8
Training loss: 0.6773126042826988
Validation loss: 2.234157773424468

Epoch: 6| Step: 9
Training loss: 0.7628959753236604
Validation loss: 2.1386348184546247

Epoch: 6| Step: 10
Training loss: 0.7221625213727105
Validation loss: 2.2819903019995627

Epoch: 6| Step: 11
Training loss: 0.5775031792359138
Validation loss: 2.290193233595603

Epoch: 6| Step: 12
Training loss: 0.807994823429786
Validation loss: 2.219671033669593

Epoch: 6| Step: 13
Training loss: 0.5204104105153664
Validation loss: 2.2712433760806685

Epoch: 584| Step: 0
Training loss: 0.6458747963259941
Validation loss: 2.300717338082282

Epoch: 6| Step: 1
Training loss: 1.5731003340377583
Validation loss: 2.3048415860933344

Epoch: 6| Step: 2
Training loss: 0.746345677208829
Validation loss: 2.2648817971396062

Epoch: 6| Step: 3
Training loss: 0.7391739549531979
Validation loss: 2.3166150952779265

Epoch: 6| Step: 4
Training loss: 0.7228753247564577
Validation loss: 2.2696691315188366

Epoch: 6| Step: 5
Training loss: 0.6076707483446802
Validation loss: 2.3248913365434474

Epoch: 6| Step: 6
Training loss: 0.570447670581872
Validation loss: 2.2631766425662945

Epoch: 6| Step: 7
Training loss: 0.751692650008264
Validation loss: 2.3162863269632585

Epoch: 6| Step: 8
Training loss: 0.4269726384930995
Validation loss: 2.257154404650333

Epoch: 6| Step: 9
Training loss: 0.5468781607400289
Validation loss: 2.2300186802233286

Epoch: 6| Step: 10
Training loss: 0.6188765001550413
Validation loss: 2.233029604801234

Epoch: 6| Step: 11
Training loss: 0.6987823317798194
Validation loss: 2.175848682074648

Epoch: 6| Step: 12
Training loss: 0.5913586646504698
Validation loss: 2.3494873287950724

Epoch: 6| Step: 13
Training loss: 0.7500976260542445
Validation loss: 2.209573673886664

Epoch: 585| Step: 0
Training loss: 0.7572564119915722
Validation loss: 2.20961883295248

Epoch: 6| Step: 1
Training loss: 0.47817596525440964
Validation loss: 2.2062339083655766

Epoch: 6| Step: 2
Training loss: 0.5072224637035971
Validation loss: 2.2062168829874107

Epoch: 6| Step: 3
Training loss: 0.47308528753637114
Validation loss: 2.2554967771998014

Epoch: 6| Step: 4
Training loss: 1.662341450179494
Validation loss: 2.256368963696803

Epoch: 6| Step: 5
Training loss: 0.7118171866689113
Validation loss: 2.284877713356441

Epoch: 6| Step: 6
Training loss: 0.6872128190272139
Validation loss: 2.0868111059566967

Epoch: 6| Step: 7
Training loss: 0.8120527503679721
Validation loss: 2.215329565777856

Epoch: 6| Step: 8
Training loss: 0.43232894836278996
Validation loss: 2.1786430468440483

Epoch: 6| Step: 9
Training loss: 0.8542285447076343
Validation loss: 2.2088637079804436

Epoch: 6| Step: 10
Training loss: 0.8529371313246777
Validation loss: 2.207427686782637

Epoch: 6| Step: 11
Training loss: 0.5424176994425641
Validation loss: 2.2458547488368104

Epoch: 6| Step: 12
Training loss: 0.7945103060232168
Validation loss: 2.286210357369508

Epoch: 6| Step: 13
Training loss: 0.54217196395558
Validation loss: 2.2073366343556113

Epoch: 586| Step: 0
Training loss: 0.5257086659815619
Validation loss: 2.261033591852054

Epoch: 6| Step: 1
Training loss: 1.5986165562608865
Validation loss: 2.315517885265064

Epoch: 6| Step: 2
Training loss: 0.6757236522318024
Validation loss: 2.1935647935437736

Epoch: 6| Step: 3
Training loss: 0.5607771981795242
Validation loss: 2.305066561997872

Epoch: 6| Step: 4
Training loss: 0.7807943922963214
Validation loss: 2.2248315559127594

Epoch: 6| Step: 5
Training loss: 0.7576436906758176
Validation loss: 2.2810491865986693

Epoch: 6| Step: 6
Training loss: 0.6813148222714768
Validation loss: 2.237462821069973

Epoch: 6| Step: 7
Training loss: 0.8161901160526218
Validation loss: 2.2920793186039714

Epoch: 6| Step: 8
Training loss: 0.8215627679138792
Validation loss: 2.247222742770291

Epoch: 6| Step: 9
Training loss: 0.7508823846663766
Validation loss: 2.2155992933374407

Epoch: 6| Step: 10
Training loss: 0.7669763900027531
Validation loss: 2.2586069578209096

Epoch: 6| Step: 11
Training loss: 0.5127287935496341
Validation loss: 2.3130787516261733

Epoch: 6| Step: 12
Training loss: 0.48370123733273923
Validation loss: 2.247912996568092

Epoch: 6| Step: 13
Training loss: 0.8633499808590432
Validation loss: 2.3123542439833127

Epoch: 587| Step: 0
Training loss: 1.5163042571698067
Validation loss: 2.182793537635689

Epoch: 6| Step: 1
Training loss: 0.7815141612726633
Validation loss: 2.1918265945449864

Epoch: 6| Step: 2
Training loss: 0.6925790398382436
Validation loss: 2.287107202117589

Epoch: 6| Step: 3
Training loss: 0.5245063459014286
Validation loss: 2.21410965399721

Epoch: 6| Step: 4
Training loss: 0.5139893105764665
Validation loss: 2.1855280881941166

Epoch: 6| Step: 5
Training loss: 0.7115085530092025
Validation loss: 2.259118033497475

Epoch: 6| Step: 6
Training loss: 0.4907415889295143
Validation loss: 2.215552251475305

Epoch: 6| Step: 7
Training loss: 0.6561918914136396
Validation loss: 2.2527348806873273

Epoch: 6| Step: 8
Training loss: 0.3386641891997749
Validation loss: 2.261477383186524

Epoch: 6| Step: 9
Training loss: 0.8456473387187393
Validation loss: 2.27756670388136

Epoch: 6| Step: 10
Training loss: 0.6762781686609961
Validation loss: 2.24278884123709

Epoch: 6| Step: 11
Training loss: 0.5322226427966328
Validation loss: 2.2777722649849803

Epoch: 6| Step: 12
Training loss: 0.5889056242233276
Validation loss: 2.1537842130559595

Epoch: 6| Step: 13
Training loss: 0.5423930017807542
Validation loss: 2.2717798192359306

Epoch: 588| Step: 0
Training loss: 0.8462780766640152
Validation loss: 2.276741189723238

Epoch: 6| Step: 1
Training loss: 0.7021164336358542
Validation loss: 2.217042349311706

Epoch: 6| Step: 2
Training loss: 0.5084070686372665
Validation loss: 2.277213356355826

Epoch: 6| Step: 3
Training loss: 0.5791969156484781
Validation loss: 2.2305992758788804

Epoch: 6| Step: 4
Training loss: 0.5490422764344584
Validation loss: 2.2460145826686224

Epoch: 6| Step: 5
Training loss: 0.5750508410326333
Validation loss: 2.3085262947450214

Epoch: 6| Step: 6
Training loss: 0.6483941580753383
Validation loss: 2.328438625888873

Epoch: 6| Step: 7
Training loss: 0.7034371848595014
Validation loss: 2.2218468969094967

Epoch: 6| Step: 8
Training loss: 0.6465213914859239
Validation loss: 2.240146234451704

Epoch: 6| Step: 9
Training loss: 1.6414078071074838
Validation loss: 2.2301339527362845

Epoch: 6| Step: 10
Training loss: 0.9322760312493708
Validation loss: 2.228818481166938

Epoch: 6| Step: 11
Training loss: 0.6886268397604588
Validation loss: 2.270213614289771

Epoch: 6| Step: 12
Training loss: 0.6266903906078637
Validation loss: 2.2516903970670112

Epoch: 6| Step: 13
Training loss: 0.5517046877511995
Validation loss: 2.213916271923506

Epoch: 589| Step: 0
Training loss: 0.7333600761854803
Validation loss: 2.3119132847741635

Epoch: 6| Step: 1
Training loss: 0.6199345597602105
Validation loss: 2.2604863762024445

Epoch: 6| Step: 2
Training loss: 1.0142019425784468
Validation loss: 2.323873628117572

Epoch: 6| Step: 3
Training loss: 0.7255706580133305
Validation loss: 2.3471607158042502

Epoch: 6| Step: 4
Training loss: 0.631998456898749
Validation loss: 2.2810590447487584

Epoch: 6| Step: 5
Training loss: 0.7728099010653667
Validation loss: 2.374240657785481

Epoch: 6| Step: 6
Training loss: 0.5811177708337583
Validation loss: 2.216796673775659

Epoch: 6| Step: 7
Training loss: 0.5986137200402183
Validation loss: 2.2231106569263366

Epoch: 6| Step: 8
Training loss: 0.8643210177828365
Validation loss: 2.2744905123295727

Epoch: 6| Step: 9
Training loss: 0.6500970447062361
Validation loss: 2.3087962702194162

Epoch: 6| Step: 10
Training loss: 0.6532636084703034
Validation loss: 2.2139432329803146

Epoch: 6| Step: 11
Training loss: 1.5694005035430696
Validation loss: 2.2665938917031125

Epoch: 6| Step: 12
Training loss: 0.711568154441136
Validation loss: 2.315750482730881

Epoch: 6| Step: 13
Training loss: 0.4954593085884469
Validation loss: 2.32575483044832

Epoch: 590| Step: 0
Training loss: 0.6976658503265939
Validation loss: 2.215479641548877

Epoch: 6| Step: 1
Training loss: 0.6146429701065868
Validation loss: 2.221615334757162

Epoch: 6| Step: 2
Training loss: 0.7200837407157507
Validation loss: 2.1795565846323837

Epoch: 6| Step: 3
Training loss: 0.5058032266098346
Validation loss: 2.2797077116348983

Epoch: 6| Step: 4
Training loss: 0.8895620394145175
Validation loss: 2.1889730623901658

Epoch: 6| Step: 5
Training loss: 0.49791666460502765
Validation loss: 2.2318177990706367

Epoch: 6| Step: 6
Training loss: 0.5651116143598693
Validation loss: 2.2937555795481934

Epoch: 6| Step: 7
Training loss: 0.47328505186138864
Validation loss: 2.2088579373944883

Epoch: 6| Step: 8
Training loss: 0.6066432267505983
Validation loss: 2.201740004972334

Epoch: 6| Step: 9
Training loss: 0.6773119222693617
Validation loss: 2.214778254099183

Epoch: 6| Step: 10
Training loss: 0.5591493257893234
Validation loss: 2.3147462535216423

Epoch: 6| Step: 11
Training loss: 0.5667416861840985
Validation loss: 2.2886951620349887

Epoch: 6| Step: 12
Training loss: 1.5936358541863604
Validation loss: 2.2789942002507764

Epoch: 6| Step: 13
Training loss: 0.7471071321477096
Validation loss: 2.1591076087531533

Epoch: 591| Step: 0
Training loss: 0.5839241022244765
Validation loss: 2.279317093990332

Epoch: 6| Step: 1
Training loss: 0.668763206921946
Validation loss: 2.208633279039864

Epoch: 6| Step: 2
Training loss: 0.753880752369486
Validation loss: 2.216648366468438

Epoch: 6| Step: 3
Training loss: 0.6244430444582174
Validation loss: 2.2165439412446837

Epoch: 6| Step: 4
Training loss: 0.49589396381200723
Validation loss: 2.1763566124032643

Epoch: 6| Step: 5
Training loss: 0.9037822470181504
Validation loss: 2.2264763588569454

Epoch: 6| Step: 6
Training loss: 1.563489295578811
Validation loss: 2.3230828710849143

Epoch: 6| Step: 7
Training loss: 0.4359390990251864
Validation loss: 2.2893058230069405

Epoch: 6| Step: 8
Training loss: 0.7745139597551427
Validation loss: 2.212427586586585

Epoch: 6| Step: 9
Training loss: 0.8393499297646645
Validation loss: 2.282019565860443

Epoch: 6| Step: 10
Training loss: 0.8315852944605522
Validation loss: 2.2200223032584763

Epoch: 6| Step: 11
Training loss: 0.6443534374606852
Validation loss: 2.2316919593965636

Epoch: 6| Step: 12
Training loss: 0.4256865719863663
Validation loss: 2.2958449051108674

Epoch: 6| Step: 13
Training loss: 0.45699368836032284
Validation loss: 2.23177742151509

Epoch: 592| Step: 0
Training loss: 0.4707170381507929
Validation loss: 2.243038500354162

Epoch: 6| Step: 1
Training loss: 0.5280542179505215
Validation loss: 2.2554657745651436

Epoch: 6| Step: 2
Training loss: 0.6142717854134117
Validation loss: 2.293594002580529

Epoch: 6| Step: 3
Training loss: 0.7899941713383689
Validation loss: 2.225323512353485

Epoch: 6| Step: 4
Training loss: 0.5970318593129671
Validation loss: 2.3404109246262914

Epoch: 6| Step: 5
Training loss: 0.6405877590985152
Validation loss: 2.213294507197746

Epoch: 6| Step: 6
Training loss: 0.6179488833545973
Validation loss: 2.2380026911158946

Epoch: 6| Step: 7
Training loss: 0.40964159693080476
Validation loss: 2.228473300953794

Epoch: 6| Step: 8
Training loss: 0.655847925809858
Validation loss: 2.246236835361063

Epoch: 6| Step: 9
Training loss: 1.541499188923135
Validation loss: 2.242933070107743

Epoch: 6| Step: 10
Training loss: 0.7657281455801758
Validation loss: 2.229122903405962

Epoch: 6| Step: 11
Training loss: 0.737447116054881
Validation loss: 2.264499761397053

Epoch: 6| Step: 12
Training loss: 0.5702101733236437
Validation loss: 2.2275427657561795

Epoch: 6| Step: 13
Training loss: 0.8149640427011756
Validation loss: 2.303500947595265

Epoch: 593| Step: 0
Training loss: 0.7564201935868051
Validation loss: 2.287063483419377

Epoch: 6| Step: 1
Training loss: 0.7656758349922483
Validation loss: 2.2692157498601033

Epoch: 6| Step: 2
Training loss: 0.518754507527818
Validation loss: 2.255877737179998

Epoch: 6| Step: 3
Training loss: 0.5782669254024382
Validation loss: 2.2235580152824714

Epoch: 6| Step: 4
Training loss: 0.5757702219513846
Validation loss: 2.1907089896760916

Epoch: 6| Step: 5
Training loss: 0.6864711041533647
Validation loss: 2.206132670694348

Epoch: 6| Step: 6
Training loss: 0.5353139102113301
Validation loss: 2.241964571449774

Epoch: 6| Step: 7
Training loss: 0.503484327528841
Validation loss: 2.321039997229102

Epoch: 6| Step: 8
Training loss: 1.665205084167057
Validation loss: 2.320747045598288

Epoch: 6| Step: 9
Training loss: 0.7057305907250332
Validation loss: 2.2963270736893224

Epoch: 6| Step: 10
Training loss: 0.3768502129521628
Validation loss: 2.3100104762664

Epoch: 6| Step: 11
Training loss: 0.7151083951428213
Validation loss: 2.3287976593882265

Epoch: 6| Step: 12
Training loss: 0.6402951298410657
Validation loss: 2.162410619314608

Epoch: 6| Step: 13
Training loss: 0.47429184829443466
Validation loss: 2.245524883950403

Epoch: 594| Step: 0
Training loss: 0.6349874725007172
Validation loss: 2.2364209898231997

Epoch: 6| Step: 1
Training loss: 0.531094107474835
Validation loss: 2.269816698737483

Epoch: 6| Step: 2
Training loss: 0.5105312050222025
Validation loss: 2.206963279752663

Epoch: 6| Step: 3
Training loss: 0.5593926645398756
Validation loss: 2.2500951022213282

Epoch: 6| Step: 4
Training loss: 0.4387017502297
Validation loss: 2.2619175563667517

Epoch: 6| Step: 5
Training loss: 1.5705810620878857
Validation loss: 2.355965324590012

Epoch: 6| Step: 6
Training loss: 0.8925659379189711
Validation loss: 2.238501188643964

Epoch: 6| Step: 7
Training loss: 0.531657119035445
Validation loss: 2.3061717308927765

Epoch: 6| Step: 8
Training loss: 0.6600081825110364
Validation loss: 2.2058550890034523

Epoch: 6| Step: 9
Training loss: 0.7982977339811681
Validation loss: 2.1859635889056794

Epoch: 6| Step: 10
Training loss: 0.7667230789189857
Validation loss: 2.209214361169243

Epoch: 6| Step: 11
Training loss: 0.6336536233366584
Validation loss: 2.2964143350388304

Epoch: 6| Step: 12
Training loss: 0.767639895373054
Validation loss: 2.317698961612069

Epoch: 6| Step: 13
Training loss: 0.6230720347523371
Validation loss: 2.325847435831163

Epoch: 595| Step: 0
Training loss: 0.8568366971348425
Validation loss: 2.2227704580220418

Epoch: 6| Step: 1
Training loss: 0.49405079805436897
Validation loss: 2.1975093239165955

Epoch: 6| Step: 2
Training loss: 0.5228582564884806
Validation loss: 2.241492065639337

Epoch: 6| Step: 3
Training loss: 0.8070529872038533
Validation loss: 2.151192311492667

Epoch: 6| Step: 4
Training loss: 0.4713974892393632
Validation loss: 2.3048572842736825

Epoch: 6| Step: 5
Training loss: 0.7186484472431184
Validation loss: 2.2617967895938556

Epoch: 6| Step: 6
Training loss: 0.7311423149047781
Validation loss: 2.2450006916479834

Epoch: 6| Step: 7
Training loss: 0.6199864527545107
Validation loss: 2.2495967692807692

Epoch: 6| Step: 8
Training loss: 0.551846495396597
Validation loss: 2.2559399582635877

Epoch: 6| Step: 9
Training loss: 0.411288053149212
Validation loss: 2.1778116277332273

Epoch: 6| Step: 10
Training loss: 1.6436739972895613
Validation loss: 2.2550173037252788

Epoch: 6| Step: 11
Training loss: 0.7271893985921863
Validation loss: 2.179232757469015

Epoch: 6| Step: 12
Training loss: 0.4622414781415188
Validation loss: 2.2592088699110313

Epoch: 6| Step: 13
Training loss: 0.40603094430619974
Validation loss: 2.2794297512772297

Epoch: 596| Step: 0
Training loss: 0.7749489936656191
Validation loss: 2.258775817450062

Epoch: 6| Step: 1
Training loss: 0.7750478991196079
Validation loss: 2.2370664915275444

Epoch: 6| Step: 2
Training loss: 0.5685418743758931
Validation loss: 2.2034821219053224

Epoch: 6| Step: 3
Training loss: 0.8187676551604257
Validation loss: 2.217117306216042

Epoch: 6| Step: 4
Training loss: 0.49459245251821443
Validation loss: 2.274355836903368

Epoch: 6| Step: 5
Training loss: 1.6097349486544155
Validation loss: 2.2396031391463285

Epoch: 6| Step: 6
Training loss: 0.5518744151370447
Validation loss: 2.21073944632101

Epoch: 6| Step: 7
Training loss: 0.7222290838559559
Validation loss: 2.1989056134736127

Epoch: 6| Step: 8
Training loss: 0.6138964683353456
Validation loss: 2.2308301203881853

Epoch: 6| Step: 9
Training loss: 0.6418658079623913
Validation loss: 2.2777313261158563

Epoch: 6| Step: 10
Training loss: 0.7918259602621414
Validation loss: 2.3104567432133543

Epoch: 6| Step: 11
Training loss: 0.40006477308350147
Validation loss: 2.253118028320333

Epoch: 6| Step: 12
Training loss: 0.6312710862367629
Validation loss: 2.306747719810501

Epoch: 6| Step: 13
Training loss: 0.46486817624324633
Validation loss: 2.2617050998785975

Epoch: 597| Step: 0
Training loss: 0.79600170378287
Validation loss: 2.3126156552701187

Epoch: 6| Step: 1
Training loss: 0.4525389992784267
Validation loss: 2.2132999210464845

Epoch: 6| Step: 2
Training loss: 0.5993946697519972
Validation loss: 2.3335431425046718

Epoch: 6| Step: 3
Training loss: 0.6519745107243667
Validation loss: 2.253385356703132

Epoch: 6| Step: 4
Training loss: 0.6671269337949696
Validation loss: 2.24558638611202

Epoch: 6| Step: 5
Training loss: 0.43288960716790187
Validation loss: 2.2139966229112344

Epoch: 6| Step: 6
Training loss: 0.5532741270169684
Validation loss: 2.220164280255995

Epoch: 6| Step: 7
Training loss: 0.8080228181275053
Validation loss: 2.151078898997457

Epoch: 6| Step: 8
Training loss: 1.6451899643178038
Validation loss: 2.265523841644845

Epoch: 6| Step: 9
Training loss: 0.6606014939730431
Validation loss: 2.1679301774247213

Epoch: 6| Step: 10
Training loss: 0.6984743599264654
Validation loss: 2.2529309892734446

Epoch: 6| Step: 11
Training loss: 0.6950913195340102
Validation loss: 2.2361285654973706

Epoch: 6| Step: 12
Training loss: 0.6360592146859192
Validation loss: 2.2113891624904074

Epoch: 6| Step: 13
Training loss: 0.531672898433401
Validation loss: 2.2494763513560785

Epoch: 598| Step: 0
Training loss: 0.5705341274274373
Validation loss: 2.23245884753254

Epoch: 6| Step: 1
Training loss: 0.6395608623628686
Validation loss: 2.2557643191865857

Epoch: 6| Step: 2
Training loss: 0.6094791616768958
Validation loss: 2.3024239179349295

Epoch: 6| Step: 3
Training loss: 0.502053306467873
Validation loss: 2.2664698150498888

Epoch: 6| Step: 4
Training loss: 0.721324993512225
Validation loss: 2.2497822623138277

Epoch: 6| Step: 5
Training loss: 0.6615754171560065
Validation loss: 2.2252833136129477

Epoch: 6| Step: 6
Training loss: 0.5582519232293572
Validation loss: 2.2379412695036294

Epoch: 6| Step: 7
Training loss: 1.6762093661828688
Validation loss: 2.311665939693037

Epoch: 6| Step: 8
Training loss: 0.8309889161097184
Validation loss: 2.2913824494346087

Epoch: 6| Step: 9
Training loss: 0.6787808389138658
Validation loss: 2.2209307600759103

Epoch: 6| Step: 10
Training loss: 0.4528006017265601
Validation loss: 2.30504017101295

Epoch: 6| Step: 11
Training loss: 0.4600414035656899
Validation loss: 2.2357426989570652

Epoch: 6| Step: 12
Training loss: 0.7106695823138452
Validation loss: 2.2898812195332923

Epoch: 6| Step: 13
Training loss: 0.6218341516852159
Validation loss: 2.2659314880024786

Epoch: 599| Step: 0
Training loss: 0.4867405808452904
Validation loss: 2.2615238942914306

Epoch: 6| Step: 1
Training loss: 0.5656891328060839
Validation loss: 2.240812852324347

Epoch: 6| Step: 2
Training loss: 0.7371444831254099
Validation loss: 2.261212669576002

Epoch: 6| Step: 3
Training loss: 1.597990714508121
Validation loss: 2.255509269461183

Epoch: 6| Step: 4
Training loss: 0.7807821017068489
Validation loss: 2.250575974050648

Epoch: 6| Step: 5
Training loss: 0.6958770388927435
Validation loss: 2.1992226656001326

Epoch: 6| Step: 6
Training loss: 0.5887558612005291
Validation loss: 2.254808888194223

Epoch: 6| Step: 7
Training loss: 0.5999301710820689
Validation loss: 2.26575031040057

Epoch: 6| Step: 8
Training loss: 0.5386536747967754
Validation loss: 2.210471081124583

Epoch: 6| Step: 9
Training loss: 0.6998749749043469
Validation loss: 2.2085311992165395

Epoch: 6| Step: 10
Training loss: 0.5006185520247404
Validation loss: 2.2211384123108884

Epoch: 6| Step: 11
Training loss: 0.6494979460039911
Validation loss: 2.2657821832713845

Epoch: 6| Step: 12
Training loss: 0.693253543997399
Validation loss: 2.2952349937332253

Epoch: 6| Step: 13
Training loss: 0.6288191456626979
Validation loss: 2.267841385692354

Epoch: 600| Step: 0
Training loss: 1.5840781451032335
Validation loss: 2.2667177297111314

Epoch: 6| Step: 1
Training loss: 0.6379084559492966
Validation loss: 2.238554243952976

Epoch: 6| Step: 2
Training loss: 0.6089570005673957
Validation loss: 2.273964414353131

Epoch: 6| Step: 3
Training loss: 0.5869428275322215
Validation loss: 2.233150759194983

Epoch: 6| Step: 4
Training loss: 0.7101191747070925
Validation loss: 2.2527470869772

Epoch: 6| Step: 5
Training loss: 0.7191314514337578
Validation loss: 2.3035918236817845

Epoch: 6| Step: 6
Training loss: 0.655669932357608
Validation loss: 2.333214159821271

Epoch: 6| Step: 7
Training loss: 0.434016082182238
Validation loss: 2.1637671567376096

Epoch: 6| Step: 8
Training loss: 0.3995896305639484
Validation loss: 2.240986571060991

Epoch: 6| Step: 9
Training loss: 0.805102528327627
Validation loss: 2.3061599291001853

Epoch: 6| Step: 10
Training loss: 0.6866147019999329
Validation loss: 2.2199237346972494

Epoch: 6| Step: 11
Training loss: 0.7844332882322299
Validation loss: 2.291734689018083

Epoch: 6| Step: 12
Training loss: 0.6505133481558403
Validation loss: 2.2415651321822847

Epoch: 6| Step: 13
Training loss: 0.5897403399026809
Validation loss: 2.280130430501624

Epoch: 601| Step: 0
Training loss: 0.766755884272954
Validation loss: 2.230749025395057

Epoch: 6| Step: 1
Training loss: 0.7217673531069106
Validation loss: 2.222177054431566

Epoch: 6| Step: 2
Training loss: 1.515924325860978
Validation loss: 2.2633203418982935

Epoch: 6| Step: 3
Training loss: 0.56035073600381
Validation loss: 2.233595176395923

Epoch: 6| Step: 4
Training loss: 0.6787611030316814
Validation loss: 2.3016402750357883

Epoch: 6| Step: 5
Training loss: 0.5607664362794107
Validation loss: 2.281517577257385

Epoch: 6| Step: 6
Training loss: 0.654720203611621
Validation loss: 2.1879974455921536

Epoch: 6| Step: 7
Training loss: 0.5611508402067867
Validation loss: 2.2353588209802817

Epoch: 6| Step: 8
Training loss: 0.4976372024987131
Validation loss: 2.331449878708852

Epoch: 6| Step: 9
Training loss: 0.6168475120008802
Validation loss: 2.2121384971835707

Epoch: 6| Step: 10
Training loss: 0.8230153921919761
Validation loss: 2.2460218363659297

Epoch: 6| Step: 11
Training loss: 0.5040351643632346
Validation loss: 2.260989613338536

Epoch: 6| Step: 12
Training loss: 0.6522318578458182
Validation loss: 2.3069492972086683

Epoch: 6| Step: 13
Training loss: 0.40980425671642173
Validation loss: 2.2322347452731157

Epoch: 602| Step: 0
Training loss: 0.8231176098815485
Validation loss: 2.312940744549466

Epoch: 6| Step: 1
Training loss: 0.491761643993794
Validation loss: 2.18094298492789

Epoch: 6| Step: 2
Training loss: 0.44300508837866803
Validation loss: 2.222570835818598

Epoch: 6| Step: 3
Training loss: 0.5989069101124467
Validation loss: 2.2670602288570088

Epoch: 6| Step: 4
Training loss: 0.7165429187732737
Validation loss: 2.24527075686019

Epoch: 6| Step: 5
Training loss: 1.5471696669310333
Validation loss: 2.3129177830260694

Epoch: 6| Step: 6
Training loss: 0.5520132638142812
Validation loss: 2.313099643438746

Epoch: 6| Step: 7
Training loss: 0.6779780760486511
Validation loss: 2.1761071764875295

Epoch: 6| Step: 8
Training loss: 0.7614723785260085
Validation loss: 2.2960914345095387

Epoch: 6| Step: 9
Training loss: 0.6587404044825961
Validation loss: 2.2726198837772893

Epoch: 6| Step: 10
Training loss: 0.5068893551469417
Validation loss: 2.2107877907831663

Epoch: 6| Step: 11
Training loss: 0.45808468561919563
Validation loss: 2.200289465812314

Epoch: 6| Step: 12
Training loss: 0.5413609583462101
Validation loss: 2.2473853870111467

Epoch: 6| Step: 13
Training loss: 0.614926676023243
Validation loss: 2.1912318056728695

Epoch: 603| Step: 0
Training loss: 0.5646468097527396
Validation loss: 2.187242704339876

Epoch: 6| Step: 1
Training loss: 0.6013532497553858
Validation loss: 2.1966978012946607

Epoch: 6| Step: 2
Training loss: 0.5064827160423421
Validation loss: 2.2785859411194247

Epoch: 6| Step: 3
Training loss: 0.3934256671098719
Validation loss: 2.2326496087670056

Epoch: 6| Step: 4
Training loss: 0.7881252274297376
Validation loss: 2.1836400442179844

Epoch: 6| Step: 5
Training loss: 0.5642053396849231
Validation loss: 2.1991932920177537

Epoch: 6| Step: 6
Training loss: 0.7771796815338577
Validation loss: 2.2360956147361675

Epoch: 6| Step: 7
Training loss: 0.5906034213367785
Validation loss: 2.297541582102891

Epoch: 6| Step: 8
Training loss: 0.7819252910342344
Validation loss: 2.31204759983345

Epoch: 6| Step: 9
Training loss: 0.5176442230052585
Validation loss: 2.238042990723007

Epoch: 6| Step: 10
Training loss: 1.6793062708951858
Validation loss: 2.260925086839936

Epoch: 6| Step: 11
Training loss: 0.5285223329601911
Validation loss: 2.2342387515766604

Epoch: 6| Step: 12
Training loss: 0.5114315770512633
Validation loss: 2.175361246206539

Epoch: 6| Step: 13
Training loss: 0.7385724416830193
Validation loss: 2.3077658440987223

Epoch: 604| Step: 0
Training loss: 0.6483970077924504
Validation loss: 2.2420450526697597

Epoch: 6| Step: 1
Training loss: 0.5499598011585208
Validation loss: 2.2019652001343264

Epoch: 6| Step: 2
Training loss: 0.7127333794231124
Validation loss: 2.253562707845194

Epoch: 6| Step: 3
Training loss: 1.5103252602465773
Validation loss: 2.265599449729343

Epoch: 6| Step: 4
Training loss: 0.4602988716692607
Validation loss: 2.218590024790284

Epoch: 6| Step: 5
Training loss: 0.6059716873794159
Validation loss: 2.2282823271525074

Epoch: 6| Step: 6
Training loss: 0.8634467678283708
Validation loss: 2.3077858780967464

Epoch: 6| Step: 7
Training loss: 0.5273599692782085
Validation loss: 2.20121463780283

Epoch: 6| Step: 8
Training loss: 0.7189494146609827
Validation loss: 2.2421245007995205

Epoch: 6| Step: 9
Training loss: 0.7995753442690844
Validation loss: 2.14977402745596

Epoch: 6| Step: 10
Training loss: 0.7081633719193086
Validation loss: 2.207926123969141

Epoch: 6| Step: 11
Training loss: 0.8023623975984453
Validation loss: 2.1889071519508754

Epoch: 6| Step: 12
Training loss: 0.48428176167083153
Validation loss: 2.3145129027373987

Epoch: 6| Step: 13
Training loss: 0.5654876363045245
Validation loss: 2.2158720435564567

Epoch: 605| Step: 0
Training loss: 0.510672453282707
Validation loss: 2.2181425024083548

Epoch: 6| Step: 1
Training loss: 0.6138867104776011
Validation loss: 2.21795288029865

Epoch: 6| Step: 2
Training loss: 0.6604295424480778
Validation loss: 2.2479893167132614

Epoch: 6| Step: 3
Training loss: 1.5509195338170727
Validation loss: 2.218912886158225

Epoch: 6| Step: 4
Training loss: 0.6928155835142846
Validation loss: 2.252954038731826

Epoch: 6| Step: 5
Training loss: 0.6605520923843837
Validation loss: 2.221645043089579

Epoch: 6| Step: 6
Training loss: 0.5978308030081932
Validation loss: 2.2601727820553186

Epoch: 6| Step: 7
Training loss: 0.8091212961249732
Validation loss: 2.21536567619387

Epoch: 6| Step: 8
Training loss: 0.6853860954570689
Validation loss: 2.269871527143514

Epoch: 6| Step: 9
Training loss: 0.6215909970723908
Validation loss: 2.2370541945209284

Epoch: 6| Step: 10
Training loss: 0.765047673129956
Validation loss: 2.2591912335345063

Epoch: 6| Step: 11
Training loss: 0.7113072199004158
Validation loss: 2.1717879663821527

Epoch: 6| Step: 12
Training loss: 0.6486013504204232
Validation loss: 2.23672937745809

Epoch: 6| Step: 13
Training loss: 0.6366354530939858
Validation loss: 2.2192525853371876

Epoch: 606| Step: 0
Training loss: 1.5275248154342953
Validation loss: 2.263142034155226

Epoch: 6| Step: 1
Training loss: 0.7372797071254582
Validation loss: 2.1567623729901273

Epoch: 6| Step: 2
Training loss: 0.7633964646842952
Validation loss: 2.1994204529133565

Epoch: 6| Step: 3
Training loss: 0.5888859886596847
Validation loss: 2.1682369392593883

Epoch: 6| Step: 4
Training loss: 0.594491445484647
Validation loss: 2.2148691646751804

Epoch: 6| Step: 5
Training loss: 0.6750729327183717
Validation loss: 2.2302552184515307

Epoch: 6| Step: 6
Training loss: 0.5236479208167089
Validation loss: 2.2217702822202945

Epoch: 6| Step: 7
Training loss: 0.7047141448606267
Validation loss: 2.2428873479239977

Epoch: 6| Step: 8
Training loss: 0.5785999924304697
Validation loss: 2.1757664014900553

Epoch: 6| Step: 9
Training loss: 0.44627111553275045
Validation loss: 2.222847696780469

Epoch: 6| Step: 10
Training loss: 0.5543502534592046
Validation loss: 2.252599536199373

Epoch: 6| Step: 11
Training loss: 0.5168848829235583
Validation loss: 2.2319711584337547

Epoch: 6| Step: 12
Training loss: 0.6464882473094942
Validation loss: 2.2149302214388733

Epoch: 6| Step: 13
Training loss: 0.560534859239411
Validation loss: 2.1963581947271185

Epoch: 607| Step: 0
Training loss: 0.5542681814970392
Validation loss: 2.25805964967464

Epoch: 6| Step: 1
Training loss: 0.6330012287290679
Validation loss: 2.3009952948614845

Epoch: 6| Step: 2
Training loss: 0.4602473474816715
Validation loss: 2.249392009157096

Epoch: 6| Step: 3
Training loss: 0.6781746041925661
Validation loss: 2.2448345193845216

Epoch: 6| Step: 4
Training loss: 0.88266016903394
Validation loss: 2.2429389756218185

Epoch: 6| Step: 5
Training loss: 0.7473616287609949
Validation loss: 2.2540708788743427

Epoch: 6| Step: 6
Training loss: 1.525980777849395
Validation loss: 2.1548359832576947

Epoch: 6| Step: 7
Training loss: 0.6118685250334215
Validation loss: 2.2391147774901796

Epoch: 6| Step: 8
Training loss: 0.5377372262555733
Validation loss: 2.2321940413377024

Epoch: 6| Step: 9
Training loss: 0.503199058910727
Validation loss: 2.2168764774539818

Epoch: 6| Step: 10
Training loss: 0.39102188928485154
Validation loss: 2.271557226194221

Epoch: 6| Step: 11
Training loss: 0.6085383711998485
Validation loss: 2.1940272231304365

Epoch: 6| Step: 12
Training loss: 0.6631194880091964
Validation loss: 2.2362497824239664

Epoch: 6| Step: 13
Training loss: 0.7777700357581632
Validation loss: 2.217832626099356

Epoch: 608| Step: 0
Training loss: 0.6872793407053756
Validation loss: 2.231586610997563

Epoch: 6| Step: 1
Training loss: 0.452152095639815
Validation loss: 2.2151732911365807

Epoch: 6| Step: 2
Training loss: 0.5630403148893011
Validation loss: 2.2268427760385827

Epoch: 6| Step: 3
Training loss: 0.629700816276352
Validation loss: 2.282716641498038

Epoch: 6| Step: 4
Training loss: 0.5456657391400261
Validation loss: 2.29408310341935

Epoch: 6| Step: 5
Training loss: 1.5396468703907888
Validation loss: 2.2168165480605535

Epoch: 6| Step: 6
Training loss: 0.5228253101117941
Validation loss: 2.241280099029213

Epoch: 6| Step: 7
Training loss: 0.6223632745459973
Validation loss: 2.257537559360629

Epoch: 6| Step: 8
Training loss: 0.7074433701028414
Validation loss: 2.2469130735816822

Epoch: 6| Step: 9
Training loss: 0.710572243227676
Validation loss: 2.1861119074974056

Epoch: 6| Step: 10
Training loss: 0.49176273484993244
Validation loss: 2.223123876046154

Epoch: 6| Step: 11
Training loss: 0.5928982849872869
Validation loss: 2.1941779497391303

Epoch: 6| Step: 12
Training loss: 0.6044691879506742
Validation loss: 2.261570391403781

Epoch: 6| Step: 13
Training loss: 0.4492400952119245
Validation loss: 2.2288675974934287

Epoch: 609| Step: 0
Training loss: 0.7890604604562518
Validation loss: 2.3474775753470123

Epoch: 6| Step: 1
Training loss: 0.8031393918184001
Validation loss: 2.196947747830445

Epoch: 6| Step: 2
Training loss: 0.6177413001009426
Validation loss: 2.159073418416234

Epoch: 6| Step: 3
Training loss: 0.57664108567839
Validation loss: 2.322766167854809

Epoch: 6| Step: 4
Training loss: 0.49242865997002444
Validation loss: 2.1917876257079256

Epoch: 6| Step: 5
Training loss: 0.6121524213834454
Validation loss: 2.2923644669374936

Epoch: 6| Step: 6
Training loss: 0.6005383728545052
Validation loss: 2.354769346900185

Epoch: 6| Step: 7
Training loss: 0.3535216947424365
Validation loss: 2.2144177419536177

Epoch: 6| Step: 8
Training loss: 0.571504966171928
Validation loss: 2.2053357472877035

Epoch: 6| Step: 9
Training loss: 1.641677591445641
Validation loss: 2.2735116530210773

Epoch: 6| Step: 10
Training loss: 0.5969890785048969
Validation loss: 2.219975863813027

Epoch: 6| Step: 11
Training loss: 0.9150245364083464
Validation loss: 2.2855176044135836

Epoch: 6| Step: 12
Training loss: 0.5400821054699032
Validation loss: 2.2113096326289434

Epoch: 6| Step: 13
Training loss: 0.6401126021927884
Validation loss: 2.2608378198376538

Epoch: 610| Step: 0
Training loss: 0.805292883246597
Validation loss: 2.3100504896185163

Epoch: 6| Step: 1
Training loss: 0.5597556241746625
Validation loss: 2.208535850496636

Epoch: 6| Step: 2
Training loss: 1.6223366993454507
Validation loss: 2.183587025051198

Epoch: 6| Step: 3
Training loss: 0.6500207347497103
Validation loss: 2.302472627087878

Epoch: 6| Step: 4
Training loss: 0.6480030994679653
Validation loss: 2.2474208340791666

Epoch: 6| Step: 5
Training loss: 0.7241410955546281
Validation loss: 2.2231487973601416

Epoch: 6| Step: 6
Training loss: 0.6067664237673955
Validation loss: 2.2365246806889907

Epoch: 6| Step: 7
Training loss: 0.7458905647383769
Validation loss: 2.2569979179574777

Epoch: 6| Step: 8
Training loss: 0.5569564458796467
Validation loss: 2.2130222316719736

Epoch: 6| Step: 9
Training loss: 0.5527808773038005
Validation loss: 2.2022778271240897

Epoch: 6| Step: 10
Training loss: 0.6598078468594458
Validation loss: 2.2155476993946155

Epoch: 6| Step: 11
Training loss: 0.3716413172422116
Validation loss: 2.210593159906136

Epoch: 6| Step: 12
Training loss: 0.6435663572419755
Validation loss: 2.270142572007729

Epoch: 6| Step: 13
Training loss: 0.5491443958117729
Validation loss: 2.225377073064559

Epoch: 611| Step: 0
Training loss: 0.6888900705446172
Validation loss: 2.317473440421973

Epoch: 6| Step: 1
Training loss: 0.6237591346423507
Validation loss: 2.273805784173808

Epoch: 6| Step: 2
Training loss: 0.34807876029848983
Validation loss: 2.2587592950777413

Epoch: 6| Step: 3
Training loss: 0.7939433605737845
Validation loss: 2.234490842288115

Epoch: 6| Step: 4
Training loss: 0.6733082189180394
Validation loss: 2.262129366760556

Epoch: 6| Step: 5
Training loss: 0.45725492562987974
Validation loss: 2.276870143859159

Epoch: 6| Step: 6
Training loss: 1.5458133021013933
Validation loss: 2.2156222498200777

Epoch: 6| Step: 7
Training loss: 0.550374956632184
Validation loss: 2.285146880150352

Epoch: 6| Step: 8
Training loss: 0.5445529139846287
Validation loss: 2.2693485822386643

Epoch: 6| Step: 9
Training loss: 0.6016921857281113
Validation loss: 2.212501437133022

Epoch: 6| Step: 10
Training loss: 0.590171924773763
Validation loss: 2.225333007944907

Epoch: 6| Step: 11
Training loss: 0.7318092734307832
Validation loss: 2.2032880074776

Epoch: 6| Step: 12
Training loss: 0.7261510935288104
Validation loss: 2.2138424069101217

Epoch: 6| Step: 13
Training loss: 0.42000415794267165
Validation loss: 2.169318396747532

Epoch: 612| Step: 0
Training loss: 0.7346773134058391
Validation loss: 2.2101547564190174

Epoch: 6| Step: 1
Training loss: 0.6668893670605395
Validation loss: 2.295990723253587

Epoch: 6| Step: 2
Training loss: 0.680655218036826
Validation loss: 2.305188442187575

Epoch: 6| Step: 3
Training loss: 0.4634516571465124
Validation loss: 2.222121180737656

Epoch: 6| Step: 4
Training loss: 0.5401099987935214
Validation loss: 2.1673634412899294

Epoch: 6| Step: 5
Training loss: 1.5024833784913636
Validation loss: 2.2011076750792533

Epoch: 6| Step: 6
Training loss: 0.6408968790500033
Validation loss: 2.2694442664861483

Epoch: 6| Step: 7
Training loss: 0.6936504129294034
Validation loss: 2.298441316216597

Epoch: 6| Step: 8
Training loss: 0.445839553266733
Validation loss: 2.220168156606127

Epoch: 6| Step: 9
Training loss: 1.010739828650629
Validation loss: 2.190248394766255

Epoch: 6| Step: 10
Training loss: 0.6967345707789518
Validation loss: 2.1577924888702134

Epoch: 6| Step: 11
Training loss: 0.7205281859423445
Validation loss: 2.221180465233756

Epoch: 6| Step: 12
Training loss: 0.667550117525695
Validation loss: 2.2104053153219687

Epoch: 6| Step: 13
Training loss: 0.7557018027071711
Validation loss: 2.2608767950775475

Epoch: 613| Step: 0
Training loss: 0.7250300417628139
Validation loss: 2.2161633163897547

Epoch: 6| Step: 1
Training loss: 0.3486376315940512
Validation loss: 2.2644279545390997

Epoch: 6| Step: 2
Training loss: 0.6996839669919146
Validation loss: 2.2190032056533098

Epoch: 6| Step: 3
Training loss: 0.5603760781414987
Validation loss: 2.29213657166693

Epoch: 6| Step: 4
Training loss: 0.5602846495923998
Validation loss: 2.3600176635638737

Epoch: 6| Step: 5
Training loss: 0.6375782320227928
Validation loss: 2.265393666758051

Epoch: 6| Step: 6
Training loss: 0.5322904495951952
Validation loss: 2.2542898137828216

Epoch: 6| Step: 7
Training loss: 0.5821429663849443
Validation loss: 2.1753449629545982

Epoch: 6| Step: 8
Training loss: 0.5648104846492471
Validation loss: 2.15309364469496

Epoch: 6| Step: 9
Training loss: 0.7005619807490285
Validation loss: 2.2566722044550622

Epoch: 6| Step: 10
Training loss: 0.5468248071797419
Validation loss: 2.284941866929028

Epoch: 6| Step: 11
Training loss: 0.5492184157390853
Validation loss: 2.2887098065935967

Epoch: 6| Step: 12
Training loss: 1.6203591762135874
Validation loss: 2.277977437281826

Epoch: 6| Step: 13
Training loss: 0.811496738770443
Validation loss: 2.212571231610071

Epoch: 614| Step: 0
Training loss: 0.5493680531276288
Validation loss: 2.27134574587236

Epoch: 6| Step: 1
Training loss: 0.644710238486105
Validation loss: 2.231962974648339

Epoch: 6| Step: 2
Training loss: 0.46305533589162934
Validation loss: 2.2436027369528073

Epoch: 6| Step: 3
Training loss: 0.47241904872164314
Validation loss: 2.263463678730412

Epoch: 6| Step: 4
Training loss: 1.6565564429894366
Validation loss: 2.243246486918308

Epoch: 6| Step: 5
Training loss: 0.4787391607586372
Validation loss: 2.251113874529647

Epoch: 6| Step: 6
Training loss: 0.5934664400505799
Validation loss: 2.170580113426067

Epoch: 6| Step: 7
Training loss: 0.5493809640883981
Validation loss: 2.195859583175337

Epoch: 6| Step: 8
Training loss: 0.6415740171235814
Validation loss: 2.267745885345376

Epoch: 6| Step: 9
Training loss: 0.6400100501210157
Validation loss: 2.2237765937336547

Epoch: 6| Step: 10
Training loss: 0.47837296519707695
Validation loss: 2.256667005705351

Epoch: 6| Step: 11
Training loss: 0.5718625051665555
Validation loss: 2.278263348005018

Epoch: 6| Step: 12
Training loss: 0.5922847033921136
Validation loss: 2.252601251286722

Epoch: 6| Step: 13
Training loss: 0.6879544490078973
Validation loss: 2.220276218544597

Epoch: 615| Step: 0
Training loss: 0.5120992047007783
Validation loss: 2.2644309241301457

Epoch: 6| Step: 1
Training loss: 0.4953607415373945
Validation loss: 2.2718427656781657

Epoch: 6| Step: 2
Training loss: 0.7568239666391995
Validation loss: 2.216874784454231

Epoch: 6| Step: 3
Training loss: 0.538584179064176
Validation loss: 2.165627261791301

Epoch: 6| Step: 4
Training loss: 0.6364628564285745
Validation loss: 2.185272019752082

Epoch: 6| Step: 5
Training loss: 0.5032354814052544
Validation loss: 2.2466892976985164

Epoch: 6| Step: 6
Training loss: 0.45825156291605657
Validation loss: 2.2372888883099806

Epoch: 6| Step: 7
Training loss: 1.4792522172858051
Validation loss: 2.2167216158222875

Epoch: 6| Step: 8
Training loss: 0.7383359454850029
Validation loss: 2.2344285261674526

Epoch: 6| Step: 9
Training loss: 0.6074140002362715
Validation loss: 2.174501516045429

Epoch: 6| Step: 10
Training loss: 0.4137210157562735
Validation loss: 2.2262427859854386

Epoch: 6| Step: 11
Training loss: 0.5427944260280113
Validation loss: 2.2438669922422956

Epoch: 6| Step: 12
Training loss: 0.763831704821825
Validation loss: 2.3160028443061593

Epoch: 6| Step: 13
Training loss: 0.4805886033840076
Validation loss: 2.2192650670435756

Epoch: 616| Step: 0
Training loss: 0.560842084074785
Validation loss: 2.228811238194283

Epoch: 6| Step: 1
Training loss: 0.4946599952439811
Validation loss: 2.219939258482238

Epoch: 6| Step: 2
Training loss: 0.5479928172852023
Validation loss: 2.2643420745851124

Epoch: 6| Step: 3
Training loss: 0.46794708150839465
Validation loss: 2.2124637020733235

Epoch: 6| Step: 4
Training loss: 0.5362619824615746
Validation loss: 2.295610508526537

Epoch: 6| Step: 5
Training loss: 0.8944591843007222
Validation loss: 2.2227838501487263

Epoch: 6| Step: 6
Training loss: 0.40290053276468
Validation loss: 2.2423680839351867

Epoch: 6| Step: 7
Training loss: 0.5400467608215284
Validation loss: 2.2242462591609495

Epoch: 6| Step: 8
Training loss: 0.6411435889280459
Validation loss: 2.2422445555171353

Epoch: 6| Step: 9
Training loss: 0.6187721864980433
Validation loss: 2.2551371836404397

Epoch: 6| Step: 10
Training loss: 0.6057599997661332
Validation loss: 2.2345964302106776

Epoch: 6| Step: 11
Training loss: 0.6731703934377048
Validation loss: 2.2322886316892463

Epoch: 6| Step: 12
Training loss: 0.46732696059208606
Validation loss: 2.227066600694533

Epoch: 6| Step: 13
Training loss: 1.9478796753116419
Validation loss: 2.2325077970706877

Epoch: 617| Step: 0
Training loss: 0.6037998456103749
Validation loss: 2.217574318063816

Epoch: 6| Step: 1
Training loss: 0.6390628143160544
Validation loss: 2.224532690653827

Epoch: 6| Step: 2
Training loss: 0.47690002808193827
Validation loss: 2.177384662769584

Epoch: 6| Step: 3
Training loss: 0.5650634370063378
Validation loss: 2.123754711924132

Epoch: 6| Step: 4
Training loss: 0.5528173485473751
Validation loss: 2.193135195701675

Epoch: 6| Step: 5
Training loss: 0.6146986793855128
Validation loss: 2.2554255941710455

Epoch: 6| Step: 6
Training loss: 1.4873475677861216
Validation loss: 2.2427136381051396

Epoch: 6| Step: 7
Training loss: 0.7987502976537875
Validation loss: 2.19079936200511

Epoch: 6| Step: 8
Training loss: 0.5229309819707637
Validation loss: 2.195320165874252

Epoch: 6| Step: 9
Training loss: 0.566931697865813
Validation loss: 2.193729488955996

Epoch: 6| Step: 10
Training loss: 0.6482676547875923
Validation loss: 2.327868266656403

Epoch: 6| Step: 11
Training loss: 0.6648965198270862
Validation loss: 2.29501782456063

Epoch: 6| Step: 12
Training loss: 0.519747954182454
Validation loss: 2.2829889678302955

Epoch: 6| Step: 13
Training loss: 0.6145399746444031
Validation loss: 2.256147453453147

Epoch: 618| Step: 0
Training loss: 1.610310699148002
Validation loss: 2.2882733464291403

Epoch: 6| Step: 1
Training loss: 0.48169035024506235
Validation loss: 2.2529744901494846

Epoch: 6| Step: 2
Training loss: 0.8017080758543447
Validation loss: 2.2447463344757765

Epoch: 6| Step: 3
Training loss: 0.5337931683435126
Validation loss: 2.269289027483769

Epoch: 6| Step: 4
Training loss: 0.4623169059734279
Validation loss: 2.226280130307506

Epoch: 6| Step: 5
Training loss: 0.5391693562180633
Validation loss: 2.266877603427635

Epoch: 6| Step: 6
Training loss: 0.692701150861709
Validation loss: 2.1678372014414307

Epoch: 6| Step: 7
Training loss: 0.4100590545295585
Validation loss: 2.179095144793584

Epoch: 6| Step: 8
Training loss: 0.48559469047429293
Validation loss: 2.1862844215897734

Epoch: 6| Step: 9
Training loss: 0.5906824124401404
Validation loss: 2.221690862033223

Epoch: 6| Step: 10
Training loss: 0.5991652393943047
Validation loss: 2.2218051733336024

Epoch: 6| Step: 11
Training loss: 0.5930882832264008
Validation loss: 2.2767041942589348

Epoch: 6| Step: 12
Training loss: 0.39145971759160925
Validation loss: 2.2046909508094874

Epoch: 6| Step: 13
Training loss: 0.6622304664991326
Validation loss: 2.2425754836431935

Epoch: 619| Step: 0
Training loss: 0.7495096511066758
Validation loss: 2.197952124616731

Epoch: 6| Step: 1
Training loss: 0.3920996107735291
Validation loss: 2.20051797069449

Epoch: 6| Step: 2
Training loss: 0.5864186155467437
Validation loss: 2.2913994671572917

Epoch: 6| Step: 3
Training loss: 0.4154077844266418
Validation loss: 2.275891132876622

Epoch: 6| Step: 4
Training loss: 0.7468644400771847
Validation loss: 2.289136589240304

Epoch: 6| Step: 5
Training loss: 0.5113757199487721
Validation loss: 2.213072171786007

Epoch: 6| Step: 6
Training loss: 0.5440744900683205
Validation loss: 2.296789774214495

Epoch: 6| Step: 7
Training loss: 0.5483783766131923
Validation loss: 2.1785360026242806

Epoch: 6| Step: 8
Training loss: 0.47657616392464847
Validation loss: 2.154969852371679

Epoch: 6| Step: 9
Training loss: 0.8223173437820311
Validation loss: 2.2184710167633597

Epoch: 6| Step: 10
Training loss: 0.6466444572177554
Validation loss: 2.2299403022255513

Epoch: 6| Step: 11
Training loss: 0.9286565433782473
Validation loss: 2.265607651193947

Epoch: 6| Step: 12
Training loss: 0.4640016541585129
Validation loss: 2.2130661457390883

Epoch: 6| Step: 13
Training loss: 1.940979509637566
Validation loss: 2.2149117394189597

Epoch: 620| Step: 0
Training loss: 0.4255226469837823
Validation loss: 2.164488972554394

Epoch: 6| Step: 1
Training loss: 0.6265857130968485
Validation loss: 2.180632383322378

Epoch: 6| Step: 2
Training loss: 0.6003735422596815
Validation loss: 2.182153078926319

Epoch: 6| Step: 3
Training loss: 0.5452099930569501
Validation loss: 2.28566903474307

Epoch: 6| Step: 4
Training loss: 0.6850796055307398
Validation loss: 2.275266736230822

Epoch: 6| Step: 5
Training loss: 0.6278420679355536
Validation loss: 2.1479024468057033

Epoch: 6| Step: 6
Training loss: 0.6830561240358777
Validation loss: 2.2528448316416445

Epoch: 6| Step: 7
Training loss: 1.483831768016353
Validation loss: 2.1776496663617646

Epoch: 6| Step: 8
Training loss: 0.581716337073458
Validation loss: 2.1743024842078635

Epoch: 6| Step: 9
Training loss: 0.5547643796269941
Validation loss: 2.252524460299889

Epoch: 6| Step: 10
Training loss: 0.7135396432963917
Validation loss: 2.2422565776709855

Epoch: 6| Step: 11
Training loss: 0.4887197737847406
Validation loss: 2.2768174262966543

Epoch: 6| Step: 12
Training loss: 0.5099758723105414
Validation loss: 2.2913604494451927

Epoch: 6| Step: 13
Training loss: 0.5318568634276039
Validation loss: 2.3073858367214317

Epoch: 621| Step: 0
Training loss: 0.5790726395536036
Validation loss: 2.2319454216195966

Epoch: 6| Step: 1
Training loss: 0.5990406283911569
Validation loss: 2.256099152035321

Epoch: 6| Step: 2
Training loss: 0.7009233337072867
Validation loss: 2.2104837440498497

Epoch: 6| Step: 3
Training loss: 0.6553407455418395
Validation loss: 2.227831878961942

Epoch: 6| Step: 4
Training loss: 0.511913553679387
Validation loss: 2.312887340589273

Epoch: 6| Step: 5
Training loss: 0.744907574648887
Validation loss: 2.2382803085128455

Epoch: 6| Step: 6
Training loss: 0.529354303489106
Validation loss: 2.1900188985509152

Epoch: 6| Step: 7
Training loss: 0.5852649643755751
Validation loss: 2.270572000055605

Epoch: 6| Step: 8
Training loss: 0.5810873070544561
Validation loss: 2.2547537674175535

Epoch: 6| Step: 9
Training loss: 0.8153179160625778
Validation loss: 2.287121986308223

Epoch: 6| Step: 10
Training loss: 1.4951522693467427
Validation loss: 2.2288492436970446

Epoch: 6| Step: 11
Training loss: 0.5831220505323976
Validation loss: 2.239506872483548

Epoch: 6| Step: 12
Training loss: 0.4710225331389409
Validation loss: 2.175829619479039

Epoch: 6| Step: 13
Training loss: 0.7934074503739929
Validation loss: 2.2520781027528516

Epoch: 622| Step: 0
Training loss: 0.47646099322796565
Validation loss: 2.2864154878279077

Epoch: 6| Step: 1
Training loss: 0.7425633733529293
Validation loss: 2.1618239183419266

Epoch: 6| Step: 2
Training loss: 0.7441420267247092
Validation loss: 2.2139405821364493

Epoch: 6| Step: 3
Training loss: 0.6586286035548823
Validation loss: 2.1723282214913167

Epoch: 6| Step: 4
Training loss: 0.5759575914096071
Validation loss: 2.2059367720047915

Epoch: 6| Step: 5
Training loss: 0.5723661783558686
Validation loss: 2.2063563136752866

Epoch: 6| Step: 6
Training loss: 0.6253164920555541
Validation loss: 2.2050871131012086

Epoch: 6| Step: 7
Training loss: 0.5388357265976581
Validation loss: 2.2457407878312683

Epoch: 6| Step: 8
Training loss: 0.545231502168463
Validation loss: 2.2385714955044316

Epoch: 6| Step: 9
Training loss: 1.516698476786165
Validation loss: 2.2460354214335694

Epoch: 6| Step: 10
Training loss: 0.4683568100147149
Validation loss: 2.1846987506728377

Epoch: 6| Step: 11
Training loss: 0.4909777685122216
Validation loss: 2.225472578383925

Epoch: 6| Step: 12
Training loss: 0.8030913364465125
Validation loss: 2.1663659323267144

Epoch: 6| Step: 13
Training loss: 0.4893470880677279
Validation loss: 2.2277981829306084

Epoch: 623| Step: 0
Training loss: 0.4266132659885561
Validation loss: 2.2501364288305523

Epoch: 6| Step: 1
Training loss: 0.5164233010113001
Validation loss: 2.2412504856789064

Epoch: 6| Step: 2
Training loss: 0.6586859316135306
Validation loss: 2.241767197048193

Epoch: 6| Step: 3
Training loss: 0.6956304187683562
Validation loss: 2.1799157923907715

Epoch: 6| Step: 4
Training loss: 0.7081887901778517
Validation loss: 2.229986135817776

Epoch: 6| Step: 5
Training loss: 0.5331030671414465
Validation loss: 2.264657661228069

Epoch: 6| Step: 6
Training loss: 0.6520078330973629
Validation loss: 2.2561423821795485

Epoch: 6| Step: 7
Training loss: 0.5255943385558142
Validation loss: 2.2457097760855023

Epoch: 6| Step: 8
Training loss: 0.4182794788481271
Validation loss: 2.221069338065625

Epoch: 6| Step: 9
Training loss: 0.550655134114732
Validation loss: 2.201442339786003

Epoch: 6| Step: 10
Training loss: 0.5006274518299427
Validation loss: 2.2507668855195666

Epoch: 6| Step: 11
Training loss: 0.6663784034697903
Validation loss: 2.257180102476676

Epoch: 6| Step: 12
Training loss: 1.5733071993957997
Validation loss: 2.2847042590671287

Epoch: 6| Step: 13
Training loss: 0.558845996589584
Validation loss: 2.149381464726998

Epoch: 624| Step: 0
Training loss: 0.562817457474856
Validation loss: 2.213406343226393

Epoch: 6| Step: 1
Training loss: 0.5632877926175353
Validation loss: 2.175931616383725

Epoch: 6| Step: 2
Training loss: 0.5912129760344098
Validation loss: 2.2516226785081015

Epoch: 6| Step: 3
Training loss: 0.6832715828449636
Validation loss: 2.256679705629114

Epoch: 6| Step: 4
Training loss: 0.5754591073008501
Validation loss: 2.214591472959873

Epoch: 6| Step: 5
Training loss: 0.6148518659935771
Validation loss: 2.2858204096182493

Epoch: 6| Step: 6
Training loss: 0.6504777500575489
Validation loss: 2.1560150203922452

Epoch: 6| Step: 7
Training loss: 0.47128860973173575
Validation loss: 2.1677105044098965

Epoch: 6| Step: 8
Training loss: 0.398058729959185
Validation loss: 2.1861457851960795

Epoch: 6| Step: 9
Training loss: 1.5549413579205023
Validation loss: 2.227854557501092

Epoch: 6| Step: 10
Training loss: 0.5347107752555941
Validation loss: 2.2031717056191185

Epoch: 6| Step: 11
Training loss: 0.6858920236514997
Validation loss: 2.187288178532213

Epoch: 6| Step: 12
Training loss: 0.7390756521203969
Validation loss: 2.239273396304021

Epoch: 6| Step: 13
Training loss: 0.6528129260991716
Validation loss: 2.1736536879108055

Epoch: 625| Step: 0
Training loss: 0.5165830727857726
Validation loss: 2.2178028493590736

Epoch: 6| Step: 1
Training loss: 0.31820597785253396
Validation loss: 2.2042442521045236

Epoch: 6| Step: 2
Training loss: 0.5393463161616769
Validation loss: 2.1838406714817524

Epoch: 6| Step: 3
Training loss: 0.3670393665272107
Validation loss: 2.215981899062309

Epoch: 6| Step: 4
Training loss: 0.6498465797122397
Validation loss: 2.2632171044653773

Epoch: 6| Step: 5
Training loss: 0.5266072817360913
Validation loss: 2.2551872409494567

Epoch: 6| Step: 6
Training loss: 0.5329942958036298
Validation loss: 2.244558729163997

Epoch: 6| Step: 7
Training loss: 1.592704130590901
Validation loss: 2.2231441553199125

Epoch: 6| Step: 8
Training loss: 0.44996420333793813
Validation loss: 2.2746251718925237

Epoch: 6| Step: 9
Training loss: 0.5216892140160274
Validation loss: 2.195078310377198

Epoch: 6| Step: 10
Training loss: 0.7615187162227011
Validation loss: 2.2335217423814564

Epoch: 6| Step: 11
Training loss: 0.5233046519667
Validation loss: 2.241486422514826

Epoch: 6| Step: 12
Training loss: 0.6486607822084002
Validation loss: 2.1832354978866153

Epoch: 6| Step: 13
Training loss: 0.6783538318000294
Validation loss: 2.2080407946276943

Epoch: 626| Step: 0
Training loss: 0.6218814533224684
Validation loss: 2.2408749560112655

Epoch: 6| Step: 1
Training loss: 0.36460614360115484
Validation loss: 2.2659527534129866

Epoch: 6| Step: 2
Training loss: 0.3805918218374488
Validation loss: 2.2857901300617227

Epoch: 6| Step: 3
Training loss: 0.4554434689135492
Validation loss: 2.281929337506883

Epoch: 6| Step: 4
Training loss: 0.6539260952398088
Validation loss: 2.2204092356571796

Epoch: 6| Step: 5
Training loss: 0.5425785226731186
Validation loss: 2.20064798332284

Epoch: 6| Step: 6
Training loss: 0.5605100293959389
Validation loss: 2.2453029918067573

Epoch: 6| Step: 7
Training loss: 0.4447083976698142
Validation loss: 2.2623296141522404

Epoch: 6| Step: 8
Training loss: 0.6939959974860607
Validation loss: 2.1923910493145797

Epoch: 6| Step: 9
Training loss: 0.5158026418147154
Validation loss: 2.206897663237495

Epoch: 6| Step: 10
Training loss: 0.6412769582260992
Validation loss: 2.2614184084575344

Epoch: 6| Step: 11
Training loss: 0.6445757763827936
Validation loss: 2.1870395685633826

Epoch: 6| Step: 12
Training loss: 1.5582643701045888
Validation loss: 2.2363211459398307

Epoch: 6| Step: 13
Training loss: 0.8700571778022773
Validation loss: 2.221951155981897

Epoch: 627| Step: 0
Training loss: 0.5764582035665179
Validation loss: 2.2007846979649073

Epoch: 6| Step: 1
Training loss: 0.7907397884224524
Validation loss: 2.271669871774499

Epoch: 6| Step: 2
Training loss: 0.8286513689017286
Validation loss: 2.248078915049882

Epoch: 6| Step: 3
Training loss: 0.5161301132821002
Validation loss: 2.2402474092531204

Epoch: 6| Step: 4
Training loss: 0.7480437674594804
Validation loss: 2.242009724715483

Epoch: 6| Step: 5
Training loss: 0.5003373378995374
Validation loss: 2.2451970944109236

Epoch: 6| Step: 6
Training loss: 0.5138639663833118
Validation loss: 2.2006126513289916

Epoch: 6| Step: 7
Training loss: 0.5940038238877541
Validation loss: 2.179493123340789

Epoch: 6| Step: 8
Training loss: 0.5322497161588544
Validation loss: 2.1950381679833835

Epoch: 6| Step: 9
Training loss: 1.582985823123801
Validation loss: 2.1191778608513387

Epoch: 6| Step: 10
Training loss: 0.4306035767030625
Validation loss: 2.2322978329395458

Epoch: 6| Step: 11
Training loss: 0.7567255148781186
Validation loss: 2.1982121121519933

Epoch: 6| Step: 12
Training loss: 0.4470947138975299
Validation loss: 2.2083006171668353

Epoch: 6| Step: 13
Training loss: 0.6823976133561408
Validation loss: 2.2466493300555954

Epoch: 628| Step: 0
Training loss: 1.5338540025936571
Validation loss: 2.2760260236884045

Epoch: 6| Step: 1
Training loss: 0.6599501338818432
Validation loss: 2.223527475859162

Epoch: 6| Step: 2
Training loss: 0.698880332160904
Validation loss: 2.255169945987212

Epoch: 6| Step: 3
Training loss: 0.6588697142645007
Validation loss: 2.257717955637617

Epoch: 6| Step: 4
Training loss: 0.5734305649008005
Validation loss: 2.2207055319799194

Epoch: 6| Step: 5
Training loss: 0.4660824851638731
Validation loss: 2.315693774749261

Epoch: 6| Step: 6
Training loss: 0.6431906427335
Validation loss: 2.2820275993419212

Epoch: 6| Step: 7
Training loss: 0.5540334041763798
Validation loss: 2.2237606984303615

Epoch: 6| Step: 8
Training loss: 0.7122144444763858
Validation loss: 2.2217823620833954

Epoch: 6| Step: 9
Training loss: 0.6570554966937524
Validation loss: 2.2059681621713607

Epoch: 6| Step: 10
Training loss: 0.4536192434717744
Validation loss: 2.1832617513680934

Epoch: 6| Step: 11
Training loss: 0.44844290035598117
Validation loss: 2.25644829377816

Epoch: 6| Step: 12
Training loss: 0.39809850221302806
Validation loss: 2.3203635730980356

Epoch: 6| Step: 13
Training loss: 0.6593895246162507
Validation loss: 2.2110299842188907

Epoch: 629| Step: 0
Training loss: 0.591074386065727
Validation loss: 2.24555286602307

Epoch: 6| Step: 1
Training loss: 0.42164570263753887
Validation loss: 2.243943522545535

Epoch: 6| Step: 2
Training loss: 0.3877485800790275
Validation loss: 2.193200170197621

Epoch: 6| Step: 3
Training loss: 1.5738089432710833
Validation loss: 2.251162537436129

Epoch: 6| Step: 4
Training loss: 0.5363456706534042
Validation loss: 2.1996309804788328

Epoch: 6| Step: 5
Training loss: 0.7240042820535136
Validation loss: 2.306357289508265

Epoch: 6| Step: 6
Training loss: 0.5407432118208892
Validation loss: 2.196549725981776

Epoch: 6| Step: 7
Training loss: 0.5897045350153807
Validation loss: 2.243476819693591

Epoch: 6| Step: 8
Training loss: 0.5546371007239335
Validation loss: 2.2287823741911

Epoch: 6| Step: 9
Training loss: 0.6555162369414236
Validation loss: 2.16168120967661

Epoch: 6| Step: 10
Training loss: 0.5419339260370176
Validation loss: 2.196679769240359

Epoch: 6| Step: 11
Training loss: 0.7457045893307551
Validation loss: 2.223563105529891

Epoch: 6| Step: 12
Training loss: 0.4810838716043491
Validation loss: 2.1721048316860974

Epoch: 6| Step: 13
Training loss: 0.7973105044631883
Validation loss: 2.2548466885799767

Epoch: 630| Step: 0
Training loss: 1.4909086489359586
Validation loss: 2.2470582236885854

Epoch: 6| Step: 1
Training loss: 0.49643386235705955
Validation loss: 2.231967856208163

Epoch: 6| Step: 2
Training loss: 0.5019767844713624
Validation loss: 2.2086490458439805

Epoch: 6| Step: 3
Training loss: 0.4125260330423989
Validation loss: 2.1884453706897538

Epoch: 6| Step: 4
Training loss: 0.5785346770513972
Validation loss: 2.3126195529142684

Epoch: 6| Step: 5
Training loss: 0.6903806072741601
Validation loss: 2.2226631577797824

Epoch: 6| Step: 6
Training loss: 0.5770857981917237
Validation loss: 2.2301266381657427

Epoch: 6| Step: 7
Training loss: 0.7769524821206373
Validation loss: 2.2076783949415577

Epoch: 6| Step: 8
Training loss: 0.4059436633469555
Validation loss: 2.3000831937167106

Epoch: 6| Step: 9
Training loss: 0.5243298340397929
Validation loss: 2.241333403103204

Epoch: 6| Step: 10
Training loss: 0.5570697134469593
Validation loss: 2.2018138900133923

Epoch: 6| Step: 11
Training loss: 0.6010226019133654
Validation loss: 2.153008759309213

Epoch: 6| Step: 12
Training loss: 0.45131383866989977
Validation loss: 2.268516368538011

Epoch: 6| Step: 13
Training loss: 0.8774616491734916
Validation loss: 2.2041151942562887

Epoch: 631| Step: 0
Training loss: 0.5097021304521049
Validation loss: 2.2820584893931537

Epoch: 6| Step: 1
Training loss: 0.5030802973441384
Validation loss: 2.242100737433277

Epoch: 6| Step: 2
Training loss: 0.5483330499460866
Validation loss: 2.2625499231467447

Epoch: 6| Step: 3
Training loss: 0.5784248914534609
Validation loss: 2.1896264330911417

Epoch: 6| Step: 4
Training loss: 0.6827037794558648
Validation loss: 2.214985134165888

Epoch: 6| Step: 5
Training loss: 1.4940966630838535
Validation loss: 2.259571864772725

Epoch: 6| Step: 6
Training loss: 0.5829782909797563
Validation loss: 2.1991885067374892

Epoch: 6| Step: 7
Training loss: 0.5023967400540749
Validation loss: 2.2083497783012205

Epoch: 6| Step: 8
Training loss: 0.27624041072462097
Validation loss: 2.169859704176395

Epoch: 6| Step: 9
Training loss: 0.5510259585193823
Validation loss: 2.2446087619782773

Epoch: 6| Step: 10
Training loss: 0.6661975645648367
Validation loss: 2.294999541794822

Epoch: 6| Step: 11
Training loss: 0.4571832094493112
Validation loss: 2.2012022692043423

Epoch: 6| Step: 12
Training loss: 0.4908627438220918
Validation loss: 2.180562378072985

Epoch: 6| Step: 13
Training loss: 0.6950187276814392
Validation loss: 2.2567760724246706

Epoch: 632| Step: 0
Training loss: 0.46087413287617923
Validation loss: 2.191860869893132

Epoch: 6| Step: 1
Training loss: 0.5624503802560434
Validation loss: 2.228975644541395

Epoch: 6| Step: 2
Training loss: 0.6212322152737125
Validation loss: 2.2681100604806193

Epoch: 6| Step: 3
Training loss: 0.47241141543472936
Validation loss: 2.1666981215201266

Epoch: 6| Step: 4
Training loss: 0.621108384829668
Validation loss: 2.2174565654068585

Epoch: 6| Step: 5
Training loss: 0.44071342311513273
Validation loss: 2.2178255368208593

Epoch: 6| Step: 6
Training loss: 0.5604652850488224
Validation loss: 2.2422176252012602

Epoch: 6| Step: 7
Training loss: 0.7008050580695702
Validation loss: 2.2368300861930517

Epoch: 6| Step: 8
Training loss: 0.6411313172800986
Validation loss: 2.190154027513318

Epoch: 6| Step: 9
Training loss: 0.552589586253142
Validation loss: 2.2392298628154763

Epoch: 6| Step: 10
Training loss: 0.6037297779353391
Validation loss: 2.2276551871924584

Epoch: 6| Step: 11
Training loss: 0.5665071068778369
Validation loss: 2.244220756880006

Epoch: 6| Step: 12
Training loss: 0.5718249293852845
Validation loss: 2.2782140835507514

Epoch: 6| Step: 13
Training loss: 1.8953815243221348
Validation loss: 2.186351295062938

Epoch: 633| Step: 0
Training loss: 0.7879550829928893
Validation loss: 2.203169652421904

Epoch: 6| Step: 1
Training loss: 0.5732290861072052
Validation loss: 2.295907076754226

Epoch: 6| Step: 2
Training loss: 0.46586600665333855
Validation loss: 2.233526488537522

Epoch: 6| Step: 3
Training loss: 0.5529558796070647
Validation loss: 2.2611939241432824

Epoch: 6| Step: 4
Training loss: 0.5989652522696433
Validation loss: 2.277237989971732

Epoch: 6| Step: 5
Training loss: 0.6674086023471332
Validation loss: 2.210519190228795

Epoch: 6| Step: 6
Training loss: 0.6908667663365184
Validation loss: 2.2072330941201996

Epoch: 6| Step: 7
Training loss: 0.663589331403572
Validation loss: 2.2149842001377555

Epoch: 6| Step: 8
Training loss: 0.6101797609769367
Validation loss: 2.2778982965046564

Epoch: 6| Step: 9
Training loss: 0.6220720851040531
Validation loss: 2.305846517244341

Epoch: 6| Step: 10
Training loss: 1.5129822963024255
Validation loss: 2.187257788179645

Epoch: 6| Step: 11
Training loss: 0.4815502555325242
Validation loss: 2.2041512912515064

Epoch: 6| Step: 12
Training loss: 0.36997932946614176
Validation loss: 2.260713068359222

Epoch: 6| Step: 13
Training loss: 0.6778926609558714
Validation loss: 2.297446567031397

Epoch: 634| Step: 0
Training loss: 0.4784693637206396
Validation loss: 2.2452567104447847

Epoch: 6| Step: 1
Training loss: 0.45619630758947766
Validation loss: 2.244545644849727

Epoch: 6| Step: 2
Training loss: 0.5845316488248825
Validation loss: 2.1241167876300824

Epoch: 6| Step: 3
Training loss: 0.583626168408984
Validation loss: 2.216459050271931

Epoch: 6| Step: 4
Training loss: 0.5346242111624784
Validation loss: 2.2000912669297246

Epoch: 6| Step: 5
Training loss: 0.4071529148019957
Validation loss: 2.198735025915684

Epoch: 6| Step: 6
Training loss: 0.530667546681692
Validation loss: 2.2811945269182767

Epoch: 6| Step: 7
Training loss: 1.4545668964810456
Validation loss: 2.231332426271276

Epoch: 6| Step: 8
Training loss: 0.607958933393902
Validation loss: 2.2534559523072137

Epoch: 6| Step: 9
Training loss: 0.6138294952404473
Validation loss: 2.1696949408696216

Epoch: 6| Step: 10
Training loss: 0.5910721675553722
Validation loss: 2.2456370036518494

Epoch: 6| Step: 11
Training loss: 0.5309205997464861
Validation loss: 2.203777802700013

Epoch: 6| Step: 12
Training loss: 0.6367420824140517
Validation loss: 2.1749971555475067

Epoch: 6| Step: 13
Training loss: 0.5788625445837093
Validation loss: 2.197417816469894

Epoch: 635| Step: 0
Training loss: 0.4470609504782714
Validation loss: 2.2616682070166014

Epoch: 6| Step: 1
Training loss: 0.45580956612692425
Validation loss: 2.2186486641208543

Epoch: 6| Step: 2
Training loss: 0.5343454163153506
Validation loss: 2.3312944227375736

Epoch: 6| Step: 3
Training loss: 1.5405894029694838
Validation loss: 2.298971032741799

Epoch: 6| Step: 4
Training loss: 0.5068221485415807
Validation loss: 2.274296730581938

Epoch: 6| Step: 5
Training loss: 0.5457655961712894
Validation loss: 2.24968589677625

Epoch: 6| Step: 6
Training loss: 0.5050960658546115
Validation loss: 2.245009749443188

Epoch: 6| Step: 7
Training loss: 0.49493832338815963
Validation loss: 2.2010985344571425

Epoch: 6| Step: 8
Training loss: 0.576080547788818
Validation loss: 2.298644290649866

Epoch: 6| Step: 9
Training loss: 0.6166958842787674
Validation loss: 2.2326445547374862

Epoch: 6| Step: 10
Training loss: 0.5923511691623747
Validation loss: 2.208578824170076

Epoch: 6| Step: 11
Training loss: 0.8061578150840224
Validation loss: 2.2409353065065

Epoch: 6| Step: 12
Training loss: 0.4874390930861916
Validation loss: 2.2195936681976685

Epoch: 6| Step: 13
Training loss: 0.46282863604268604
Validation loss: 2.1970525747032643

Epoch: 636| Step: 0
Training loss: 0.4519692512872882
Validation loss: 2.1829198149161746

Epoch: 6| Step: 1
Training loss: 0.4603581424416064
Validation loss: 2.2873802948998634

Epoch: 6| Step: 2
Training loss: 0.5566767898322477
Validation loss: 2.2279349851688184

Epoch: 6| Step: 3
Training loss: 0.6107004374015145
Validation loss: 2.237761225357576

Epoch: 6| Step: 4
Training loss: 0.5501037380614366
Validation loss: 2.288619278556383

Epoch: 6| Step: 5
Training loss: 1.4659404260674889
Validation loss: 2.2842841446881543

Epoch: 6| Step: 6
Training loss: 0.5799123610680067
Validation loss: 2.2112012020545713

Epoch: 6| Step: 7
Training loss: 0.6190606917037627
Validation loss: 2.202029259214404

Epoch: 6| Step: 8
Training loss: 0.6666151016876719
Validation loss: 2.1305361570534487

Epoch: 6| Step: 9
Training loss: 0.5634316041355484
Validation loss: 2.191824930151453

Epoch: 6| Step: 10
Training loss: 0.7387112369469171
Validation loss: 2.214533577644659

Epoch: 6| Step: 11
Training loss: 0.7066673902142018
Validation loss: 2.195755459419398

Epoch: 6| Step: 12
Training loss: 0.41968689487439215
Validation loss: 2.2809821660078136

Epoch: 6| Step: 13
Training loss: 0.41845551783177865
Validation loss: 2.227586717248648

Epoch: 637| Step: 0
Training loss: 0.4771095325600261
Validation loss: 2.161690889359223

Epoch: 6| Step: 1
Training loss: 0.5916019534150346
Validation loss: 2.216877681287034

Epoch: 6| Step: 2
Training loss: 0.550326924262263
Validation loss: 2.236790484213226

Epoch: 6| Step: 3
Training loss: 0.5979750287972556
Validation loss: 2.1692287506625503

Epoch: 6| Step: 4
Training loss: 0.5985486218740671
Validation loss: 2.1606629678597633

Epoch: 6| Step: 5
Training loss: 0.42289895723719023
Validation loss: 2.2546074611544658

Epoch: 6| Step: 6
Training loss: 0.5223489516555813
Validation loss: 2.241555399416166

Epoch: 6| Step: 7
Training loss: 0.4315134612002698
Validation loss: 2.2328688874008598

Epoch: 6| Step: 8
Training loss: 0.6666794765751693
Validation loss: 2.263108364303185

Epoch: 6| Step: 9
Training loss: 0.5094777606213384
Validation loss: 2.260746760277234

Epoch: 6| Step: 10
Training loss: 1.5209523594234042
Validation loss: 2.2026108189962392

Epoch: 6| Step: 11
Training loss: 0.4369852068653728
Validation loss: 2.164251130713347

Epoch: 6| Step: 12
Training loss: 0.6473133039669309
Validation loss: 2.179540904959436

Epoch: 6| Step: 13
Training loss: 0.5048568394250087
Validation loss: 2.2091806643194394

Epoch: 638| Step: 0
Training loss: 0.4661757514630057
Validation loss: 2.2386723944909606

Epoch: 6| Step: 1
Training loss: 0.5380269760810238
Validation loss: 2.272332508215021

Epoch: 6| Step: 2
Training loss: 0.6142353484347463
Validation loss: 2.269029414662588

Epoch: 6| Step: 3
Training loss: 1.4249495915649004
Validation loss: 2.208795480166418

Epoch: 6| Step: 4
Training loss: 0.7127242220709806
Validation loss: 2.213783587579419

Epoch: 6| Step: 5
Training loss: 0.5998894351177096
Validation loss: 2.2527347253486045

Epoch: 6| Step: 6
Training loss: 0.5873101495831962
Validation loss: 2.202253298532832

Epoch: 6| Step: 7
Training loss: 0.5850965950763307
Validation loss: 2.1693417457857613

Epoch: 6| Step: 8
Training loss: 0.43362756545714665
Validation loss: 2.2442909588127957

Epoch: 6| Step: 9
Training loss: 0.5172661758924626
Validation loss: 2.1873323988689606

Epoch: 6| Step: 10
Training loss: 0.4213623181259142
Validation loss: 2.2131630293673137

Epoch: 6| Step: 11
Training loss: 0.7538110544456371
Validation loss: 2.173672442009043

Epoch: 6| Step: 12
Training loss: 0.6418601665992938
Validation loss: 2.320485323753707

Epoch: 6| Step: 13
Training loss: 0.6958309555203438
Validation loss: 2.2601998676348933

Epoch: 639| Step: 0
Training loss: 0.5558813974035096
Validation loss: 2.2251971506007293

Epoch: 6| Step: 1
Training loss: 0.6168775142166243
Validation loss: 2.1948654075124168

Epoch: 6| Step: 2
Training loss: 0.3613123916087362
Validation loss: 2.2076999300002034

Epoch: 6| Step: 3
Training loss: 0.6978012079605642
Validation loss: 2.1834307111178606

Epoch: 6| Step: 4
Training loss: 0.573400836157081
Validation loss: 2.1842058191153715

Epoch: 6| Step: 5
Training loss: 0.3585815377742686
Validation loss: 2.2200873476818925

Epoch: 6| Step: 6
Training loss: 0.7073476936798344
Validation loss: 2.259006020003489

Epoch: 6| Step: 7
Training loss: 0.5731298021304625
Validation loss: 2.226558946233539

Epoch: 6| Step: 8
Training loss: 0.5388482815342275
Validation loss: 2.2162141921090517

Epoch: 6| Step: 9
Training loss: 0.5160973437256615
Validation loss: 2.221566678931935

Epoch: 6| Step: 10
Training loss: 1.5067511267043099
Validation loss: 2.1551043781380304

Epoch: 6| Step: 11
Training loss: 0.5278515948852629
Validation loss: 2.300193284318865

Epoch: 6| Step: 12
Training loss: 0.6484158983424184
Validation loss: 2.22166643007351

Epoch: 6| Step: 13
Training loss: 0.5343499339510132
Validation loss: 2.1939605922426906

Epoch: 640| Step: 0
Training loss: 0.6495543134869554
Validation loss: 2.2777107947823825

Epoch: 6| Step: 1
Training loss: 0.5949043797345707
Validation loss: 2.277284082931872

Epoch: 6| Step: 2
Training loss: 0.31844560356423507
Validation loss: 2.2399265900993046

Epoch: 6| Step: 3
Training loss: 0.47248238132063375
Validation loss: 2.2265334948708793

Epoch: 6| Step: 4
Training loss: 0.44053643533723974
Validation loss: 2.257794217992531

Epoch: 6| Step: 5
Training loss: 1.588795534287253
Validation loss: 2.293925425285335

Epoch: 6| Step: 6
Training loss: 0.6495268300750089
Validation loss: 2.1727325111138662

Epoch: 6| Step: 7
Training loss: 0.5542461358599416
Validation loss: 2.208376555697983

Epoch: 6| Step: 8
Training loss: 0.5071598554070883
Validation loss: 2.214264999618066

Epoch: 6| Step: 9
Training loss: 0.7375746883138121
Validation loss: 2.219598287055787

Epoch: 6| Step: 10
Training loss: 0.7116924092582504
Validation loss: 2.2615454913430004

Epoch: 6| Step: 11
Training loss: 0.35728952427584143
Validation loss: 2.2446322041255984

Epoch: 6| Step: 12
Training loss: 0.5306863880480522
Validation loss: 2.215425223043551

Epoch: 6| Step: 13
Training loss: 0.5872673456659823
Validation loss: 2.2397083761722065

Epoch: 641| Step: 0
Training loss: 0.5545894374936606
Validation loss: 2.2000863262944597

Epoch: 6| Step: 1
Training loss: 0.4651723709875172
Validation loss: 2.270145543157727

Epoch: 6| Step: 2
Training loss: 1.4919488526288271
Validation loss: 2.2510199360077294

Epoch: 6| Step: 3
Training loss: 0.7125321832716582
Validation loss: 2.258303594860751

Epoch: 6| Step: 4
Training loss: 0.4631529438993913
Validation loss: 2.185130515130289

Epoch: 6| Step: 5
Training loss: 0.6454310753898657
Validation loss: 2.280595310973092

Epoch: 6| Step: 6
Training loss: 0.717205710585029
Validation loss: 2.273611922924445

Epoch: 6| Step: 7
Training loss: 0.5135879157895225
Validation loss: 2.211123832695859

Epoch: 6| Step: 8
Training loss: 0.4293851135206688
Validation loss: 2.3584578188137506

Epoch: 6| Step: 9
Training loss: 0.502798681881299
Validation loss: 2.182212901198509

Epoch: 6| Step: 10
Training loss: 0.5981179492259822
Validation loss: 2.1665246714246975

Epoch: 6| Step: 11
Training loss: 0.5570440068864063
Validation loss: 2.2709640739250254

Epoch: 6| Step: 12
Training loss: 0.5504822155975417
Validation loss: 2.2887129804650432

Epoch: 6| Step: 13
Training loss: 0.56758581525157
Validation loss: 2.2105175619449087

Epoch: 642| Step: 0
Training loss: 0.5667609321034601
Validation loss: 2.2826948266859617

Epoch: 6| Step: 1
Training loss: 0.6446828028202212
Validation loss: 2.1666720400507757

Epoch: 6| Step: 2
Training loss: 0.6325421638909805
Validation loss: 2.183707805640338

Epoch: 6| Step: 3
Training loss: 0.6769062886707198
Validation loss: 2.1046633719464096

Epoch: 6| Step: 4
Training loss: 0.463151415664855
Validation loss: 2.188779608437799

Epoch: 6| Step: 5
Training loss: 0.6502934976172599
Validation loss: 2.2280526270294176

Epoch: 6| Step: 6
Training loss: 1.5147113209010796
Validation loss: 2.1907246186713327

Epoch: 6| Step: 7
Training loss: 0.3978230094869939
Validation loss: 2.2782263913245964

Epoch: 6| Step: 8
Training loss: 0.616201603209686
Validation loss: 2.1793149271784436

Epoch: 6| Step: 9
Training loss: 0.5054711284316175
Validation loss: 2.26720619682721

Epoch: 6| Step: 10
Training loss: 0.4751789301859994
Validation loss: 2.2386357043724754

Epoch: 6| Step: 11
Training loss: 0.3936332075293632
Validation loss: 2.2774383058682983

Epoch: 6| Step: 12
Training loss: 0.6319490358048466
Validation loss: 2.1273686094631175

Epoch: 6| Step: 13
Training loss: 0.5136479999520007
Validation loss: 2.218371594016328

Epoch: 643| Step: 0
Training loss: 0.48974253386005223
Validation loss: 2.2207753846330975

Epoch: 6| Step: 1
Training loss: 0.5029603226599455
Validation loss: 2.2462471972424454

Epoch: 6| Step: 2
Training loss: 1.4867931545800934
Validation loss: 2.216509945226982

Epoch: 6| Step: 3
Training loss: 0.5486690793080934
Validation loss: 2.1702581126506932

Epoch: 6| Step: 4
Training loss: 0.6696819398464948
Validation loss: 2.284589580976886

Epoch: 6| Step: 5
Training loss: 0.24472660694898246
Validation loss: 2.266284561191882

Epoch: 6| Step: 6
Training loss: 0.6844010735687852
Validation loss: 2.2486711768837813

Epoch: 6| Step: 7
Training loss: 0.5203818335174945
Validation loss: 2.235542780435972

Epoch: 6| Step: 8
Training loss: 0.719245822553599
Validation loss: 2.2532514100472776

Epoch: 6| Step: 9
Training loss: 0.4150277887944965
Validation loss: 2.2882171596452543

Epoch: 6| Step: 10
Training loss: 0.5913528942394382
Validation loss: 2.223356127711198

Epoch: 6| Step: 11
Training loss: 0.493702781206039
Validation loss: 2.2157101822875065

Epoch: 6| Step: 12
Training loss: 0.7005233528252618
Validation loss: 2.2652321021846205

Epoch: 6| Step: 13
Training loss: 0.6489764581989338
Validation loss: 2.2751053516290485

Epoch: 644| Step: 0
Training loss: 0.48683995961839693
Validation loss: 2.2470003074996896

Epoch: 6| Step: 1
Training loss: 0.48294294070514826
Validation loss: 2.344544770494773

Epoch: 6| Step: 2
Training loss: 0.4659513213309923
Validation loss: 2.2167690283843378

Epoch: 6| Step: 3
Training loss: 0.4823105563947275
Validation loss: 2.3513772853585717

Epoch: 6| Step: 4
Training loss: 0.780021770124582
Validation loss: 2.2754186408909405

Epoch: 6| Step: 5
Training loss: 1.4123726964652064
Validation loss: 2.171723485692914

Epoch: 6| Step: 6
Training loss: 0.4665925923663267
Validation loss: 2.2849758691573334

Epoch: 6| Step: 7
Training loss: 0.7347969304036756
Validation loss: 2.1982575127832424

Epoch: 6| Step: 8
Training loss: 0.6220354822010525
Validation loss: 2.274927063243471

Epoch: 6| Step: 9
Training loss: 0.4771773952171195
Validation loss: 2.2353521152876037

Epoch: 6| Step: 10
Training loss: 0.5030430934412555
Validation loss: 2.217676226415286

Epoch: 6| Step: 11
Training loss: 0.5743999065689978
Validation loss: 2.2674859765649096

Epoch: 6| Step: 12
Training loss: 0.5003353722685597
Validation loss: 2.3121977638794378

Epoch: 6| Step: 13
Training loss: 0.31986153654242394
Validation loss: 2.275179836778841

Epoch: 645| Step: 0
Training loss: 0.6931306273607745
Validation loss: 2.2515341121632364

Epoch: 6| Step: 1
Training loss: 0.31671624245236724
Validation loss: 2.240164390406542

Epoch: 6| Step: 2
Training loss: 0.6077491148624855
Validation loss: 2.2602767659091576

Epoch: 6| Step: 3
Training loss: 0.45337043889383144
Validation loss: 2.2215212163217606

Epoch: 6| Step: 4
Training loss: 1.4625337417492306
Validation loss: 2.2408518120523677

Epoch: 6| Step: 5
Training loss: 0.5099655285573452
Validation loss: 2.194786603478602

Epoch: 6| Step: 6
Training loss: 0.40919825982891883
Validation loss: 2.1992800955439327

Epoch: 6| Step: 7
Training loss: 0.5312349092920715
Validation loss: 2.2748284191925485

Epoch: 6| Step: 8
Training loss: 0.5350883050931281
Validation loss: 2.1474495486099445

Epoch: 6| Step: 9
Training loss: 0.46491878769390693
Validation loss: 2.354916693122708

Epoch: 6| Step: 10
Training loss: 0.6032320115418613
Validation loss: 2.2869657249269677

Epoch: 6| Step: 11
Training loss: 0.5681416727101859
Validation loss: 2.255381106194726

Epoch: 6| Step: 12
Training loss: 0.7056499708908293
Validation loss: 2.2597814394831546

Epoch: 6| Step: 13
Training loss: 0.5283375735468744
Validation loss: 2.25246602624197

Epoch: 646| Step: 0
Training loss: 0.4229783535428303
Validation loss: 2.213938678459787

Epoch: 6| Step: 1
Training loss: 0.41726148785066997
Validation loss: 2.1889621096618677

Epoch: 6| Step: 2
Training loss: 0.6381587262259462
Validation loss: 2.2256272725693185

Epoch: 6| Step: 3
Training loss: 0.49358916137726394
Validation loss: 2.226046205457143

Epoch: 6| Step: 4
Training loss: 0.5712690300974972
Validation loss: 2.2037709014498668

Epoch: 6| Step: 5
Training loss: 1.4865123419071273
Validation loss: 2.219049761920702

Epoch: 6| Step: 6
Training loss: 0.4298852985454048
Validation loss: 2.2352780244739345

Epoch: 6| Step: 7
Training loss: 0.529193431698007
Validation loss: 2.272761880055536

Epoch: 6| Step: 8
Training loss: 0.6945430055187692
Validation loss: 2.270551239138227

Epoch: 6| Step: 9
Training loss: 0.8522061356625096
Validation loss: 2.2557381918304573

Epoch: 6| Step: 10
Training loss: 0.6287954481622602
Validation loss: 2.268191392452466

Epoch: 6| Step: 11
Training loss: 0.5555556045638169
Validation loss: 2.2340079626458014

Epoch: 6| Step: 12
Training loss: 0.5652754973642318
Validation loss: 2.2350546751611313

Epoch: 6| Step: 13
Training loss: 0.6787870076314089
Validation loss: 2.2701656307851503

Epoch: 647| Step: 0
Training loss: 0.5020288788745115
Validation loss: 2.2284996300538955

Epoch: 6| Step: 1
Training loss: 0.38486940175290585
Validation loss: 2.2726939303692197

Epoch: 6| Step: 2
Training loss: 0.6465094063053172
Validation loss: 2.202798039920841

Epoch: 6| Step: 3
Training loss: 0.5737826449429885
Validation loss: 2.2591212211403326

Epoch: 6| Step: 4
Training loss: 0.5279744650381013
Validation loss: 2.150059576799755

Epoch: 6| Step: 5
Training loss: 0.6442124242886064
Validation loss: 2.2727527506930025

Epoch: 6| Step: 6
Training loss: 0.71258404553947
Validation loss: 2.1806858643349285

Epoch: 6| Step: 7
Training loss: 0.39135091089649765
Validation loss: 2.251541868425882

Epoch: 6| Step: 8
Training loss: 0.49481715755720757
Validation loss: 2.1675234261028975

Epoch: 6| Step: 9
Training loss: 1.4903797963634797
Validation loss: 2.2300788060537307

Epoch: 6| Step: 10
Training loss: 0.7550857882991476
Validation loss: 2.2530005647834748

Epoch: 6| Step: 11
Training loss: 0.5583067737022208
Validation loss: 2.2926830819494772

Epoch: 6| Step: 12
Training loss: 0.6506280093531128
Validation loss: 2.244058846898986

Epoch: 6| Step: 13
Training loss: 0.5276895872547184
Validation loss: 2.2530312577058624

Epoch: 648| Step: 0
Training loss: 0.47901342539996666
Validation loss: 2.24310571203913

Epoch: 6| Step: 1
Training loss: 0.31812922812164635
Validation loss: 2.1792919839368947

Epoch: 6| Step: 2
Training loss: 1.4694142564261874
Validation loss: 2.26681498845119

Epoch: 6| Step: 3
Training loss: 0.7277062550393202
Validation loss: 2.228535488529372

Epoch: 6| Step: 4
Training loss: 0.47186744696528
Validation loss: 2.236541729534456

Epoch: 6| Step: 5
Training loss: 0.5493281520011595
Validation loss: 2.2621716628832815

Epoch: 6| Step: 6
Training loss: 0.45058619478943435
Validation loss: 2.2318512454599007

Epoch: 6| Step: 7
Training loss: 0.6276821758071427
Validation loss: 2.3008377873571475

Epoch: 6| Step: 8
Training loss: 0.6129969770207628
Validation loss: 2.2597305582010336

Epoch: 6| Step: 9
Training loss: 0.8246028782431855
Validation loss: 2.150808628668887

Epoch: 6| Step: 10
Training loss: 0.5495373904460278
Validation loss: 2.249949303150435

Epoch: 6| Step: 11
Training loss: 0.7090006004137259
Validation loss: 2.2455301299020487

Epoch: 6| Step: 12
Training loss: 0.6713644128041729
Validation loss: 2.3206791736317736

Epoch: 6| Step: 13
Training loss: 0.5373006029434839
Validation loss: 2.1530345847816013

Epoch: 649| Step: 0
Training loss: 0.5791627745417532
Validation loss: 2.1644076240257895

Epoch: 6| Step: 1
Training loss: 0.4030924192466213
Validation loss: 2.2972264766308594

Epoch: 6| Step: 2
Training loss: 0.5104940187139319
Validation loss: 2.1527924467582267

Epoch: 6| Step: 3
Training loss: 0.7236468562154669
Validation loss: 2.2427949468800126

Epoch: 6| Step: 4
Training loss: 0.48810007930447047
Validation loss: 2.2191657936613525

Epoch: 6| Step: 5
Training loss: 0.4454062681022142
Validation loss: 2.2526175143925053

Epoch: 6| Step: 6
Training loss: 0.7091610690955732
Validation loss: 2.268831968757603

Epoch: 6| Step: 7
Training loss: 0.5471530479944448
Validation loss: 2.164000092127746

Epoch: 6| Step: 8
Training loss: 1.5315469726323356
Validation loss: 2.2110317002456723

Epoch: 6| Step: 9
Training loss: 0.5501110788363862
Validation loss: 2.2660226772035337

Epoch: 6| Step: 10
Training loss: 0.4366033084176111
Validation loss: 2.260986261085561

Epoch: 6| Step: 11
Training loss: 0.3125121591109838
Validation loss: 2.2286328151935892

Epoch: 6| Step: 12
Training loss: 0.6896452595506002
Validation loss: 2.228412814860136

Epoch: 6| Step: 13
Training loss: 0.4850869330431161
Validation loss: 2.2490914947773653

Epoch: 650| Step: 0
Training loss: 0.494871646707866
Validation loss: 2.1866690116450065

Epoch: 6| Step: 1
Training loss: 0.5696563604217578
Validation loss: 2.261636323209834

Epoch: 6| Step: 2
Training loss: 1.4701125946520524
Validation loss: 2.17471429709086

Epoch: 6| Step: 3
Training loss: 0.5131441894269922
Validation loss: 2.2689453846316705

Epoch: 6| Step: 4
Training loss: 0.5033759350252904
Validation loss: 2.1775794115871814

Epoch: 6| Step: 5
Training loss: 0.7256392488879528
Validation loss: 2.2664619549100586

Epoch: 6| Step: 6
Training loss: 0.4260473732072579
Validation loss: 2.252254830626387

Epoch: 6| Step: 7
Training loss: 0.6244683627184813
Validation loss: 2.226692332649209

Epoch: 6| Step: 8
Training loss: 0.6959353882269814
Validation loss: 2.2961034443659245

Epoch: 6| Step: 9
Training loss: 0.4894767621567074
Validation loss: 2.2630665031303407

Epoch: 6| Step: 10
Training loss: 0.4675911247466787
Validation loss: 2.2007712034208837

Epoch: 6| Step: 11
Training loss: 0.6448563651645751
Validation loss: 2.2333459668115156

Epoch: 6| Step: 12
Training loss: 0.40004197734869307
Validation loss: 2.2353102905555935

Epoch: 6| Step: 13
Training loss: 0.5775069980279903
Validation loss: 2.1925701572989476

Epoch: 651| Step: 0
Training loss: 0.4829602345728214
Validation loss: 2.2019754559992992

Epoch: 6| Step: 1
Training loss: 0.6094187696338815
Validation loss: 2.235907535827021

Epoch: 6| Step: 2
Training loss: 0.617830545087597
Validation loss: 2.228105202813163

Epoch: 6| Step: 3
Training loss: 0.677995439097725
Validation loss: 2.195969596939497

Epoch: 6| Step: 4
Training loss: 0.5221863782814712
Validation loss: 2.208611279496791

Epoch: 6| Step: 5
Training loss: 0.3542922115334449
Validation loss: 2.215256570126533

Epoch: 6| Step: 6
Training loss: 0.4734562180850732
Validation loss: 2.179414359559481

Epoch: 6| Step: 7
Training loss: 0.4494501595918994
Validation loss: 2.2233301862424524

Epoch: 6| Step: 8
Training loss: 0.8038887578101038
Validation loss: 2.2306251190188915

Epoch: 6| Step: 9
Training loss: 0.5471604828234794
Validation loss: 2.2528973227124527

Epoch: 6| Step: 10
Training loss: 0.6525435684171843
Validation loss: 2.2078250765254492

Epoch: 6| Step: 11
Training loss: 0.6504844162589491
Validation loss: 2.2636172608238043

Epoch: 6| Step: 12
Training loss: 1.4919410222390568
Validation loss: 2.120389466807399

Epoch: 6| Step: 13
Training loss: 0.47201025773778565
Validation loss: 2.228687506481277

Epoch: 652| Step: 0
Training loss: 0.42658511231122215
Validation loss: 2.2658477277685876

Epoch: 6| Step: 1
Training loss: 0.5162369535704999
Validation loss: 2.1921788163461504

Epoch: 6| Step: 2
Training loss: 0.525156926362074
Validation loss: 2.2246847395542884

Epoch: 6| Step: 3
Training loss: 0.7194256302211706
Validation loss: 2.2293312711399564

Epoch: 6| Step: 4
Training loss: 0.33068355360904517
Validation loss: 2.255993288686907

Epoch: 6| Step: 5
Training loss: 1.4229404523806042
Validation loss: 2.22811181410657

Epoch: 6| Step: 6
Training loss: 0.5193353154414347
Validation loss: 2.1614721264913657

Epoch: 6| Step: 7
Training loss: 0.44151640673725223
Validation loss: 2.276887300448925

Epoch: 6| Step: 8
Training loss: 0.5020778219097278
Validation loss: 2.193400060051552

Epoch: 6| Step: 9
Training loss: 0.5456219349935643
Validation loss: 2.24133025535911

Epoch: 6| Step: 10
Training loss: 0.6122983113858858
Validation loss: 2.1946283356821055

Epoch: 6| Step: 11
Training loss: 0.7885113292453486
Validation loss: 2.207713942481227

Epoch: 6| Step: 12
Training loss: 0.5788581426608755
Validation loss: 2.230482290722618

Epoch: 6| Step: 13
Training loss: 0.39639830007313703
Validation loss: 2.29026960949401

Epoch: 653| Step: 0
Training loss: 0.47942269437384405
Validation loss: 2.368283439141782

Epoch: 6| Step: 1
Training loss: 0.624924941324255
Validation loss: 2.1359777482281608

Epoch: 6| Step: 2
Training loss: 0.5997984150167589
Validation loss: 2.201241051865213

Epoch: 6| Step: 3
Training loss: 0.595673106953722
Validation loss: 2.2014019250626635

Epoch: 6| Step: 4
Training loss: 0.48215943893296803
Validation loss: 2.278635418330473

Epoch: 6| Step: 5
Training loss: 0.5820475326411074
Validation loss: 2.230122702105282

Epoch: 6| Step: 6
Training loss: 0.4689466540767445
Validation loss: 2.230616758475207

Epoch: 6| Step: 7
Training loss: 0.5860413777142394
Validation loss: 2.275826040688604

Epoch: 6| Step: 8
Training loss: 0.5225033181372603
Validation loss: 2.215326654191166

Epoch: 6| Step: 9
Training loss: 0.6542186861149785
Validation loss: 2.2054658205597732

Epoch: 6| Step: 10
Training loss: 0.3553438071865713
Validation loss: 2.2370576032641223

Epoch: 6| Step: 11
Training loss: 0.4881597138783727
Validation loss: 2.22208174031591

Epoch: 6| Step: 12
Training loss: 1.4496870492423415
Validation loss: 2.2195879393680435

Epoch: 6| Step: 13
Training loss: 0.44000451993246276
Validation loss: 2.243387268390901

Epoch: 654| Step: 0
Training loss: 0.461012720985491
Validation loss: 2.1921349452091694

Epoch: 6| Step: 1
Training loss: 0.5740057621610162
Validation loss: 2.2326582389997567

Epoch: 6| Step: 2
Training loss: 0.5085673077766149
Validation loss: 2.2500380327116307

Epoch: 6| Step: 3
Training loss: 0.49106698932127424
Validation loss: 2.187380424723752

Epoch: 6| Step: 4
Training loss: 0.4741746143497378
Validation loss: 2.251959985033971

Epoch: 6| Step: 5
Training loss: 0.5145990395047372
Validation loss: 2.2944990063730493

Epoch: 6| Step: 6
Training loss: 0.6418084169674553
Validation loss: 2.1782393469819037

Epoch: 6| Step: 7
Training loss: 0.6702190663058645
Validation loss: 2.1681474338024125

Epoch: 6| Step: 8
Training loss: 0.46006318593916606
Validation loss: 2.207397794073807

Epoch: 6| Step: 9
Training loss: 1.4897060032554255
Validation loss: 2.2316414717118707

Epoch: 6| Step: 10
Training loss: 0.6244313991455924
Validation loss: 2.210483864085475

Epoch: 6| Step: 11
Training loss: 0.45832693211102404
Validation loss: 2.2844645554607004

Epoch: 6| Step: 12
Training loss: 0.48069832132172147
Validation loss: 2.2675452598516324

Epoch: 6| Step: 13
Training loss: 0.43683089452502044
Validation loss: 2.2187840367984624

Epoch: 655| Step: 0
Training loss: 0.5107444923596864
Validation loss: 2.2034322291265593

Epoch: 6| Step: 1
Training loss: 0.5034683749903287
Validation loss: 2.2299247043568844

Epoch: 6| Step: 2
Training loss: 0.4861952971796685
Validation loss: 2.2419924035692236

Epoch: 6| Step: 3
Training loss: 0.5650937889540847
Validation loss: 2.207406008540871

Epoch: 6| Step: 4
Training loss: 0.4888655409135571
Validation loss: 2.2392490199444377

Epoch: 6| Step: 5
Training loss: 0.48600553054763185
Validation loss: 2.1692352223060665

Epoch: 6| Step: 6
Training loss: 0.6511854063938242
Validation loss: 2.1901090611480476

Epoch: 6| Step: 7
Training loss: 0.35353160000108275
Validation loss: 2.1993221403713314

Epoch: 6| Step: 8
Training loss: 1.4532636350723436
Validation loss: 2.195155248205462

Epoch: 6| Step: 9
Training loss: 0.6008628640962014
Validation loss: 2.284228182446762

Epoch: 6| Step: 10
Training loss: 0.5309770107106029
Validation loss: 2.198360353037429

Epoch: 6| Step: 11
Training loss: 0.6265225224096115
Validation loss: 2.222517457785942

Epoch: 6| Step: 12
Training loss: 0.3655411762756191
Validation loss: 2.2114988552372643

Epoch: 6| Step: 13
Training loss: 0.7592633702994737
Validation loss: 2.2446046023278274

Epoch: 656| Step: 0
Training loss: 0.5690030782009591
Validation loss: 2.1858542326445756

Epoch: 6| Step: 1
Training loss: 0.5635104375801704
Validation loss: 2.205055621452038

Epoch: 6| Step: 2
Training loss: 0.7433526380096344
Validation loss: 2.348629272613815

Epoch: 6| Step: 3
Training loss: 0.5724862880813817
Validation loss: 2.2162335105909854

Epoch: 6| Step: 4
Training loss: 0.4669923891635844
Validation loss: 2.225957512317992

Epoch: 6| Step: 5
Training loss: 0.5153059694930084
Validation loss: 2.282911049078708

Epoch: 6| Step: 6
Training loss: 0.6046499314577125
Validation loss: 2.207740515669948

Epoch: 6| Step: 7
Training loss: 0.4590749448331964
Validation loss: 2.2520381590298078

Epoch: 6| Step: 8
Training loss: 0.6888336770516544
Validation loss: 2.2030416836675872

Epoch: 6| Step: 9
Training loss: 0.6364194482473908
Validation loss: 2.2057038516264504

Epoch: 6| Step: 10
Training loss: 1.4828442360121767
Validation loss: 2.275586881645501

Epoch: 6| Step: 11
Training loss: 0.49041711205478733
Validation loss: 2.291309849842704

Epoch: 6| Step: 12
Training loss: 0.7523243965995061
Validation loss: 2.2206786977581228

Epoch: 6| Step: 13
Training loss: 0.579958405647499
Validation loss: 2.251166281831862

Epoch: 657| Step: 0
Training loss: 1.4616637031470037
Validation loss: 2.207920201439683

Epoch: 6| Step: 1
Training loss: 0.4445405090923126
Validation loss: 2.171577244931971

Epoch: 6| Step: 2
Training loss: 0.798703806560745
Validation loss: 2.242165592431446

Epoch: 6| Step: 3
Training loss: 0.5507912601075347
Validation loss: 2.253144850538275

Epoch: 6| Step: 4
Training loss: 0.5831491883587628
Validation loss: 2.2203796712786477

Epoch: 6| Step: 5
Training loss: 0.461630962307498
Validation loss: 2.1507415266120997

Epoch: 6| Step: 6
Training loss: 0.4945536157934996
Validation loss: 2.222728528316126

Epoch: 6| Step: 7
Training loss: 0.5913646869844678
Validation loss: 2.2079673048920023

Epoch: 6| Step: 8
Training loss: 0.4406311521709385
Validation loss: 2.1954548383478385

Epoch: 6| Step: 9
Training loss: 0.6072649247010744
Validation loss: 2.229287166595127

Epoch: 6| Step: 10
Training loss: 0.47529398830062275
Validation loss: 2.1989711012302275

Epoch: 6| Step: 11
Training loss: 0.6116716681006545
Validation loss: 2.2513750835324045

Epoch: 6| Step: 12
Training loss: 0.4106673371539949
Validation loss: 2.1966311183672085

Epoch: 6| Step: 13
Training loss: 0.48682805298979387
Validation loss: 2.2708317080316283

Epoch: 658| Step: 0
Training loss: 0.6627423122209063
Validation loss: 2.287192832410692

Epoch: 6| Step: 1
Training loss: 0.522190458927412
Validation loss: 2.1889138488428457

Epoch: 6| Step: 2
Training loss: 0.5035167045966413
Validation loss: 2.2074478103322774

Epoch: 6| Step: 3
Training loss: 0.5322027078584739
Validation loss: 2.2804077567016825

Epoch: 6| Step: 4
Training loss: 0.6259816090682399
Validation loss: 2.2581912236620663

Epoch: 6| Step: 5
Training loss: 0.742195731669503
Validation loss: 2.1994351420248774

Epoch: 6| Step: 6
Training loss: 0.311004301783503
Validation loss: 2.216620368791685

Epoch: 6| Step: 7
Training loss: 0.6309924147780229
Validation loss: 2.2123450890276395

Epoch: 6| Step: 8
Training loss: 1.5013285157875655
Validation loss: 2.21382520409961

Epoch: 6| Step: 9
Training loss: 0.6000727251800951
Validation loss: 2.24123672691065

Epoch: 6| Step: 10
Training loss: 0.4824507855235293
Validation loss: 2.2500248774311964

Epoch: 6| Step: 11
Training loss: 0.5044365687176783
Validation loss: 2.2271660617626434

Epoch: 6| Step: 12
Training loss: 0.6477071716757887
Validation loss: 2.1768159646711305

Epoch: 6| Step: 13
Training loss: 0.4748882369264837
Validation loss: 2.245065889372535

Epoch: 659| Step: 0
Training loss: 0.5475794750604629
Validation loss: 2.2256112871021942

Epoch: 6| Step: 1
Training loss: 0.5655505326288869
Validation loss: 2.2128438499432295

Epoch: 6| Step: 2
Training loss: 0.6579401186925999
Validation loss: 2.198024118636394

Epoch: 6| Step: 3
Training loss: 1.5052285462532553
Validation loss: 2.2244546783119135

Epoch: 6| Step: 4
Training loss: 0.6471725903483171
Validation loss: 2.238502252579778

Epoch: 6| Step: 5
Training loss: 0.4734820725764196
Validation loss: 2.20642250458224

Epoch: 6| Step: 6
Training loss: 0.3917280073863712
Validation loss: 2.2417647760875496

Epoch: 6| Step: 7
Training loss: 0.46596001983194557
Validation loss: 2.228719337699726

Epoch: 6| Step: 8
Training loss: 0.43058847122948846
Validation loss: 2.185096660407774

Epoch: 6| Step: 9
Training loss: 0.4969154221508856
Validation loss: 2.257250733860016

Epoch: 6| Step: 10
Training loss: 0.6074841335563717
Validation loss: 2.2790151502925706

Epoch: 6| Step: 11
Training loss: 0.561694336468079
Validation loss: 2.2473780687010025

Epoch: 6| Step: 12
Training loss: 0.6710053071438936
Validation loss: 2.2395970860426497

Epoch: 6| Step: 13
Training loss: 0.6072167543911766
Validation loss: 2.2530960034491523

Epoch: 660| Step: 0
Training loss: 0.4206846185295637
Validation loss: 2.2107849509086317

Epoch: 6| Step: 1
Training loss: 0.7134233966090067
Validation loss: 2.2511394571075223

Epoch: 6| Step: 2
Training loss: 0.6376667337600359
Validation loss: 2.177820904940015

Epoch: 6| Step: 3
Training loss: 0.7823015003288947
Validation loss: 2.209716748002962

Epoch: 6| Step: 4
Training loss: 1.4204131775814377
Validation loss: 2.271207637105659

Epoch: 6| Step: 5
Training loss: 0.5581951453117068
Validation loss: 2.2385823028511376

Epoch: 6| Step: 6
Training loss: 0.5261141818333033
Validation loss: 2.1921899418679898

Epoch: 6| Step: 7
Training loss: 0.5617861456622968
Validation loss: 2.2907189517350726

Epoch: 6| Step: 8
Training loss: 0.5607695452939913
Validation loss: 2.2208553391230406

Epoch: 6| Step: 9
Training loss: 0.6758441124051388
Validation loss: 2.2277720216073513

Epoch: 6| Step: 10
Training loss: 0.4970995401659266
Validation loss: 2.241213591263041

Epoch: 6| Step: 11
Training loss: 0.484804270861481
Validation loss: 2.2396069148873785

Epoch: 6| Step: 12
Training loss: 0.47504408280453825
Validation loss: 2.175044990850269

Epoch: 6| Step: 13
Training loss: 0.4117942979616554
Validation loss: 2.1765615708731265

Epoch: 661| Step: 0
Training loss: 0.7284207116037145
Validation loss: 2.1589938375533864

Epoch: 6| Step: 1
Training loss: 0.47940003544811677
Validation loss: 2.2398639794057247

Epoch: 6| Step: 2
Training loss: 0.6315590489070022
Validation loss: 2.2407122407901925

Epoch: 6| Step: 3
Training loss: 0.5308564074435457
Validation loss: 2.2832345549389146

Epoch: 6| Step: 4
Training loss: 0.2638420403594684
Validation loss: 2.228358624759382

Epoch: 6| Step: 5
Training loss: 0.4491207679370777
Validation loss: 2.203285534345985

Epoch: 6| Step: 6
Training loss: 0.723980983315778
Validation loss: 2.253369603705522

Epoch: 6| Step: 7
Training loss: 0.4878450657972987
Validation loss: 2.230909709351195

Epoch: 6| Step: 8
Training loss: 0.5336057100310067
Validation loss: 2.2899140876588517

Epoch: 6| Step: 9
Training loss: 0.5175804857883954
Validation loss: 2.1865029824328532

Epoch: 6| Step: 10
Training loss: 0.40796756792426847
Validation loss: 2.28553362264146

Epoch: 6| Step: 11
Training loss: 0.37067831778453636
Validation loss: 2.203881765542655

Epoch: 6| Step: 12
Training loss: 0.5055154345502039
Validation loss: 2.1903413206662807

Epoch: 6| Step: 13
Training loss: 1.925114885840503
Validation loss: 2.211547510574638

Epoch: 662| Step: 0
Training loss: 0.4649348450205559
Validation loss: 2.156287395241603

Epoch: 6| Step: 1
Training loss: 0.5326120363048624
Validation loss: 2.2496493771632657

Epoch: 6| Step: 2
Training loss: 0.5015962868597166
Validation loss: 2.14341981539988

Epoch: 6| Step: 3
Training loss: 0.5689016161035552
Validation loss: 2.2565195842861288

Epoch: 6| Step: 4
Training loss: 0.4964292998421276
Validation loss: 2.209069982600003

Epoch: 6| Step: 5
Training loss: 0.5668146436917637
Validation loss: 2.246872326635381

Epoch: 6| Step: 6
Training loss: 0.6705176593025263
Validation loss: 2.2325421747336525

Epoch: 6| Step: 7
Training loss: 0.5251958833565806
Validation loss: 2.257562141945435

Epoch: 6| Step: 8
Training loss: 0.35000910363959986
Validation loss: 2.267157398273179

Epoch: 6| Step: 9
Training loss: 1.5001784059604655
Validation loss: 2.256007145526845

Epoch: 6| Step: 10
Training loss: 0.6745254004893961
Validation loss: 2.2457395697898477

Epoch: 6| Step: 11
Training loss: 0.5818967727865333
Validation loss: 2.2405439300408543

Epoch: 6| Step: 12
Training loss: 0.4093181585205304
Validation loss: 2.1820469429592

Epoch: 6| Step: 13
Training loss: 0.4720751129651259
Validation loss: 2.2206629883696887

Epoch: 663| Step: 0
Training loss: 0.6360176064090582
Validation loss: 2.1939093652351773

Epoch: 6| Step: 1
Training loss: 1.505294278165018
Validation loss: 2.175446891253297

Epoch: 6| Step: 2
Training loss: 0.376193333347495
Validation loss: 2.277783311774955

Epoch: 6| Step: 3
Training loss: 0.33656696739880076
Validation loss: 2.2395379174662597

Epoch: 6| Step: 4
Training loss: 0.3740833523323211
Validation loss: 2.226162201310867

Epoch: 6| Step: 5
Training loss: 0.7158859243676772
Validation loss: 2.2412050643223043

Epoch: 6| Step: 6
Training loss: 0.6320842272761173
Validation loss: 2.185231823920098

Epoch: 6| Step: 7
Training loss: 0.4497660909799054
Validation loss: 2.231248369248207

Epoch: 6| Step: 8
Training loss: 0.4441015946039864
Validation loss: 2.195607265675192

Epoch: 6| Step: 9
Training loss: 0.43083464343144184
Validation loss: 2.202384550264528

Epoch: 6| Step: 10
Training loss: 0.505747779113449
Validation loss: 2.272977849537399

Epoch: 6| Step: 11
Training loss: 0.5280974476867265
Validation loss: 2.201403812795949

Epoch: 6| Step: 12
Training loss: 0.5148556489394309
Validation loss: 2.2803790134671265

Epoch: 6| Step: 13
Training loss: 0.49136269805480326
Validation loss: 2.1567958689528828

Epoch: 664| Step: 0
Training loss: 0.4738949866108765
Validation loss: 2.3329322692928267

Epoch: 6| Step: 1
Training loss: 0.8166187137681208
Validation loss: 2.3650776379551037

Epoch: 6| Step: 2
Training loss: 0.4786352825420171
Validation loss: 2.1222914747023744

Epoch: 6| Step: 3
Training loss: 0.6679258723188775
Validation loss: 2.2712366860356537

Epoch: 6| Step: 4
Training loss: 1.4211621016914495
Validation loss: 2.2425868078372737

Epoch: 6| Step: 5
Training loss: 0.470201121731162
Validation loss: 2.248586205354627

Epoch: 6| Step: 6
Training loss: 0.48159029559222744
Validation loss: 2.237523201154004

Epoch: 6| Step: 7
Training loss: 0.40383283733763065
Validation loss: 2.210246185994708

Epoch: 6| Step: 8
Training loss: 0.4834067295788958
Validation loss: 2.2103068479462906

Epoch: 6| Step: 9
Training loss: 0.5336503050561743
Validation loss: 2.2087834691371095

Epoch: 6| Step: 10
Training loss: 0.49202713548836385
Validation loss: 2.2133253511322457

Epoch: 6| Step: 11
Training loss: 0.593244211699954
Validation loss: 2.182133037552113

Epoch: 6| Step: 12
Training loss: 0.5287223034000943
Validation loss: 2.1983183901066825

Epoch: 6| Step: 13
Training loss: 0.702182392259669
Validation loss: 2.2352846822192185

Epoch: 665| Step: 0
Training loss: 0.5699645248048164
Validation loss: 2.161737913831282

Epoch: 6| Step: 1
Training loss: 0.5972213159845066
Validation loss: 2.2194818921344552

Epoch: 6| Step: 2
Training loss: 1.4051779157185036
Validation loss: 2.1652906353657304

Epoch: 6| Step: 3
Training loss: 0.5148273135442845
Validation loss: 2.2238835416846197

Epoch: 6| Step: 4
Training loss: 0.4055236044291837
Validation loss: 2.2453590496195877

Epoch: 6| Step: 5
Training loss: 0.6156862083253447
Validation loss: 2.2442528207109516

Epoch: 6| Step: 6
Training loss: 0.5201449104280828
Validation loss: 2.242400649852333

Epoch: 6| Step: 7
Training loss: 0.5155450007483642
Validation loss: 2.2527713343493834

Epoch: 6| Step: 8
Training loss: 0.7261789601653917
Validation loss: 2.2896166205695883

Epoch: 6| Step: 9
Training loss: 0.7682881650522323
Validation loss: 2.2651866703109325

Epoch: 6| Step: 10
Training loss: 0.6065363669723287
Validation loss: 2.196145279360929

Epoch: 6| Step: 11
Training loss: 0.5234406029908172
Validation loss: 2.17653189205485

Epoch: 6| Step: 12
Training loss: 0.5130657202226566
Validation loss: 2.176010803413144

Epoch: 6| Step: 13
Training loss: 0.6341240560358031
Validation loss: 2.2354579486580137

Epoch: 666| Step: 0
Training loss: 0.4583116836925537
Validation loss: 2.179087672429904

Epoch: 6| Step: 1
Training loss: 0.6162775308986079
Validation loss: 2.181485147585972

Epoch: 6| Step: 2
Training loss: 0.5714056173252758
Validation loss: 2.2078099738317047

Epoch: 6| Step: 3
Training loss: 0.5815024309738921
Validation loss: 2.234925476849291

Epoch: 6| Step: 4
Training loss: 0.6369349106900799
Validation loss: 2.212095805903932

Epoch: 6| Step: 5
Training loss: 0.5366012111378586
Validation loss: 2.288955681224424

Epoch: 6| Step: 6
Training loss: 1.4199415202926582
Validation loss: 2.244822648079693

Epoch: 6| Step: 7
Training loss: 0.5168151990621884
Validation loss: 2.206047706796507

Epoch: 6| Step: 8
Training loss: 0.49301241818818564
Validation loss: 2.1768826604498748

Epoch: 6| Step: 9
Training loss: 0.46535383815844583
Validation loss: 2.2447598655916257

Epoch: 6| Step: 10
Training loss: 0.5645594249275455
Validation loss: 2.250502762630328

Epoch: 6| Step: 11
Training loss: 0.6610328226813312
Validation loss: 2.262169075637135

Epoch: 6| Step: 12
Training loss: 0.7917180839371651
Validation loss: 2.195312063250474

Epoch: 6| Step: 13
Training loss: 0.3769881671963489
Validation loss: 2.2671721791257813

Epoch: 667| Step: 0
Training loss: 0.6164801926737473
Validation loss: 2.1813799651452643

Epoch: 6| Step: 1
Training loss: 0.5772868085767155
Validation loss: 2.197535245881215

Epoch: 6| Step: 2
Training loss: 0.4048950635102712
Validation loss: 2.213076134986025

Epoch: 6| Step: 3
Training loss: 1.3296746133433133
Validation loss: 2.257627942691654

Epoch: 6| Step: 4
Training loss: 0.635389449886416
Validation loss: 2.187254452145016

Epoch: 6| Step: 5
Training loss: 0.6563434534288796
Validation loss: 2.226654714025173

Epoch: 6| Step: 6
Training loss: 0.5391746072710162
Validation loss: 2.1471782029765905

Epoch: 6| Step: 7
Training loss: 0.5762178564312468
Validation loss: 2.1935968895857516

Epoch: 6| Step: 8
Training loss: 0.5317790258401095
Validation loss: 2.195967464627692

Epoch: 6| Step: 9
Training loss: 0.46627195523909115
Validation loss: 2.195094512064992

Epoch: 6| Step: 10
Training loss: 0.570621041224641
Validation loss: 2.252174812145164

Epoch: 6| Step: 11
Training loss: 0.4604061587962834
Validation loss: 2.2855581189110623

Epoch: 6| Step: 12
Training loss: 0.45419026810744917
Validation loss: 2.1907136085821026

Epoch: 6| Step: 13
Training loss: 0.5426489347826511
Validation loss: 2.226449597354362

Epoch: 668| Step: 0
Training loss: 0.5957383192328366
Validation loss: 2.21267937809685

Epoch: 6| Step: 1
Training loss: 0.7453555704463584
Validation loss: 2.2267504633068853

Epoch: 6| Step: 2
Training loss: 0.5253953330811066
Validation loss: 2.2408235859377377

Epoch: 6| Step: 3
Training loss: 0.4888872734573556
Validation loss: 2.2653304720827716

Epoch: 6| Step: 4
Training loss: 0.7295512184454465
Validation loss: 2.263231248968138

Epoch: 6| Step: 5
Training loss: 1.5597443504420723
Validation loss: 2.1842944400325472

Epoch: 6| Step: 6
Training loss: 0.7225213002163725
Validation loss: 2.222659585667922

Epoch: 6| Step: 7
Training loss: 0.4825001085607377
Validation loss: 2.201532236579421

Epoch: 6| Step: 8
Training loss: 0.7722537296905305
Validation loss: 2.200168001494718

Epoch: 6| Step: 9
Training loss: 0.6810732778512228
Validation loss: 2.2127517717308463

Epoch: 6| Step: 10
Training loss: 0.8945966138654963
Validation loss: 2.221887302625673

Epoch: 6| Step: 11
Training loss: 0.5422779051853904
Validation loss: 2.1527824132761126

Epoch: 6| Step: 12
Training loss: 0.5442593556582581
Validation loss: 2.161428787339861

Epoch: 6| Step: 13
Training loss: 0.5272359949859249
Validation loss: 2.226125546267782

Epoch: 669| Step: 0
Training loss: 0.6510465138572812
Validation loss: 2.2144234193275487

Epoch: 6| Step: 1
Training loss: 1.4016706291003622
Validation loss: 2.1908689652607976

Epoch: 6| Step: 2
Training loss: 0.600644687167187
Validation loss: 2.237019381380776

Epoch: 6| Step: 3
Training loss: 0.6453234803233118
Validation loss: 2.335810070517814

Epoch: 6| Step: 4
Training loss: 0.6574896955951802
Validation loss: 2.2738918353250654

Epoch: 6| Step: 5
Training loss: 0.7218285847063399
Validation loss: 2.2971649578455984

Epoch: 6| Step: 6
Training loss: 0.4227222130259168
Validation loss: 2.240048106207286

Epoch: 6| Step: 7
Training loss: 0.44682106679626904
Validation loss: 2.335821391047506

Epoch: 6| Step: 8
Training loss: 0.48880295920221556
Validation loss: 2.247631684926817

Epoch: 6| Step: 9
Training loss: 0.5364053446947921
Validation loss: 2.2097184505475016

Epoch: 6| Step: 10
Training loss: 0.5233058479202476
Validation loss: 2.27995328955917

Epoch: 6| Step: 11
Training loss: 0.5764892221420989
Validation loss: 2.227131370895758

Epoch: 6| Step: 12
Training loss: 0.6346722812978578
Validation loss: 2.215567912343392

Epoch: 6| Step: 13
Training loss: 0.4661321176255063
Validation loss: 2.1341034635795837

Epoch: 670| Step: 0
Training loss: 0.587823452074314
Validation loss: 2.23852197595708

Epoch: 6| Step: 1
Training loss: 0.5907906516960723
Validation loss: 2.2259689809410643

Epoch: 6| Step: 2
Training loss: 0.5198975039300948
Validation loss: 2.2790045481826247

Epoch: 6| Step: 3
Training loss: 0.4716607952875772
Validation loss: 2.252736413589752

Epoch: 6| Step: 4
Training loss: 0.8001784498147924
Validation loss: 2.157928323982752

Epoch: 6| Step: 5
Training loss: 0.5284652934105444
Validation loss: 2.180520384778568

Epoch: 6| Step: 6
Training loss: 1.4449931848754678
Validation loss: 2.223126045446899

Epoch: 6| Step: 7
Training loss: 0.472219501827233
Validation loss: 2.2250220591138437

Epoch: 6| Step: 8
Training loss: 0.5372829642249909
Validation loss: 2.243447049647216

Epoch: 6| Step: 9
Training loss: 0.3839666523534988
Validation loss: 2.253312897577084

Epoch: 6| Step: 10
Training loss: 0.7495858320442299
Validation loss: 2.2745995536585784

Epoch: 6| Step: 11
Training loss: 0.5580241627178761
Validation loss: 2.278936048926923

Epoch: 6| Step: 12
Training loss: 0.41958164359961214
Validation loss: 2.304049294471593

Epoch: 6| Step: 13
Training loss: 0.35734111102705585
Validation loss: 2.290948978780672

Epoch: 671| Step: 0
Training loss: 0.309562093342838
Validation loss: 2.255557092220593

Epoch: 6| Step: 1
Training loss: 0.3518770929616474
Validation loss: 2.1973862052837823

Epoch: 6| Step: 2
Training loss: 0.6168655328304357
Validation loss: 2.207935965788697

Epoch: 6| Step: 3
Training loss: 0.41711731223845994
Validation loss: 2.25982340178154

Epoch: 6| Step: 4
Training loss: 0.5946564781849669
Validation loss: 2.2291519585086736

Epoch: 6| Step: 5
Training loss: 0.45104258612817283
Validation loss: 2.198231822085389

Epoch: 6| Step: 6
Training loss: 0.5951727835836629
Validation loss: 2.210869282263914

Epoch: 6| Step: 7
Training loss: 0.5007047454907757
Validation loss: 2.231194396667724

Epoch: 6| Step: 8
Training loss: 1.4618070737821296
Validation loss: 2.178584276815969

Epoch: 6| Step: 9
Training loss: 0.5689753442309765
Validation loss: 2.2374577085928062

Epoch: 6| Step: 10
Training loss: 0.5457529546314316
Validation loss: 2.2429290325067925

Epoch: 6| Step: 11
Training loss: 0.6027582348039913
Validation loss: 2.2927804591372025

Epoch: 6| Step: 12
Training loss: 0.8675957826949806
Validation loss: 2.2413818494383557

Epoch: 6| Step: 13
Training loss: 0.5697306709023722
Validation loss: 2.2294468405098455

Epoch: 672| Step: 0
Training loss: 1.434870097165505
Validation loss: 2.205031348148787

Epoch: 6| Step: 1
Training loss: 0.6392135422969324
Validation loss: 2.207594724977589

Epoch: 6| Step: 2
Training loss: 0.3811053533222629
Validation loss: 2.21595515167361

Epoch: 6| Step: 3
Training loss: 0.5216687051694648
Validation loss: 2.2523877805939088

Epoch: 6| Step: 4
Training loss: 0.5597873286893245
Validation loss: 2.1914201537534894

Epoch: 6| Step: 5
Training loss: 0.35377686684963494
Validation loss: 2.240585062101791

Epoch: 6| Step: 6
Training loss: 0.6051996679117914
Validation loss: 2.2065315600737785

Epoch: 6| Step: 7
Training loss: 0.4779285488574982
Validation loss: 2.170431986080642

Epoch: 6| Step: 8
Training loss: 0.4977644175496784
Validation loss: 2.1690242434004743

Epoch: 6| Step: 9
Training loss: 0.6507229800658157
Validation loss: 2.2297908962006936

Epoch: 6| Step: 10
Training loss: 0.6038266217043624
Validation loss: 2.2095809143662923

Epoch: 6| Step: 11
Training loss: 0.4640161696660532
Validation loss: 2.251166083679689

Epoch: 6| Step: 12
Training loss: 0.5169691425832298
Validation loss: 2.1854593922817136

Epoch: 6| Step: 13
Training loss: 0.7059395723958392
Validation loss: 2.2453249212851367

Epoch: 673| Step: 0
Training loss: 0.6565434163228362
Validation loss: 2.1727705341461543

Epoch: 6| Step: 1
Training loss: 0.5158880891944128
Validation loss: 2.1489720954907874

Epoch: 6| Step: 2
Training loss: 0.4433546696215755
Validation loss: 2.198133061886814

Epoch: 6| Step: 3
Training loss: 0.5444670115251937
Validation loss: 2.2331020665563

Epoch: 6| Step: 4
Training loss: 0.8035740973413141
Validation loss: 2.3141013501219883

Epoch: 6| Step: 5
Training loss: 0.7294948838272207
Validation loss: 2.208753835616725

Epoch: 6| Step: 6
Training loss: 1.4657968904274619
Validation loss: 2.301090246958666

Epoch: 6| Step: 7
Training loss: 0.6249255135973093
Validation loss: 2.2018098055357114

Epoch: 6| Step: 8
Training loss: 0.6239610619928456
Validation loss: 2.259495787223651

Epoch: 6| Step: 9
Training loss: 0.5572625149621767
Validation loss: 2.265368977339453

Epoch: 6| Step: 10
Training loss: 0.5044002920377553
Validation loss: 2.226092262028404

Epoch: 6| Step: 11
Training loss: 0.4791173615865615
Validation loss: 2.1989892963642355

Epoch: 6| Step: 12
Training loss: 0.5248486300642173
Validation loss: 2.190087092082844

Epoch: 6| Step: 13
Training loss: 0.4561456593648691
Validation loss: 2.1703687230847124

Epoch: 674| Step: 0
Training loss: 0.6231038417304078
Validation loss: 2.212705416627877

Epoch: 6| Step: 1
Training loss: 0.44139180117564547
Validation loss: 2.2097056068903704

Epoch: 6| Step: 2
Training loss: 0.45210134042601485
Validation loss: 2.300922722818353

Epoch: 6| Step: 3
Training loss: 0.641301100704403
Validation loss: 2.1866836090910944

Epoch: 6| Step: 4
Training loss: 0.5735735220006484
Validation loss: 2.309880334579443

Epoch: 6| Step: 5
Training loss: 0.38632895350970076
Validation loss: 2.2182378609700057

Epoch: 6| Step: 6
Training loss: 0.44977087837134316
Validation loss: 2.189695055641605

Epoch: 6| Step: 7
Training loss: 0.4394631617777449
Validation loss: 2.3434918005038536

Epoch: 6| Step: 8
Training loss: 0.6112511193278855
Validation loss: 2.2405414494039424

Epoch: 6| Step: 9
Training loss: 0.560536347931693
Validation loss: 2.26125711651417

Epoch: 6| Step: 10
Training loss: 0.6034153234593913
Validation loss: 2.176928122003542

Epoch: 6| Step: 11
Training loss: 0.546979430990519
Validation loss: 2.1804631426583745

Epoch: 6| Step: 12
Training loss: 0.32882659699675676
Validation loss: 2.191017470128677

Epoch: 6| Step: 13
Training loss: 1.8607388150915434
Validation loss: 2.205070011146477

Epoch: 675| Step: 0
Training loss: 0.44128225492318823
Validation loss: 2.1926461955279297

Epoch: 6| Step: 1
Training loss: 1.3760748476835507
Validation loss: 2.1591421767171894

Epoch: 6| Step: 2
Training loss: 0.5649660940883819
Validation loss: 2.266996178783203

Epoch: 6| Step: 3
Training loss: 0.791075339241535
Validation loss: 2.2386158789300783

Epoch: 6| Step: 4
Training loss: 0.5629843110393672
Validation loss: 2.2336252269567005

Epoch: 6| Step: 5
Training loss: 0.7579804853680142
Validation loss: 2.216969117493222

Epoch: 6| Step: 6
Training loss: 0.5793153519362172
Validation loss: 2.234627250150928

Epoch: 6| Step: 7
Training loss: 0.4564095205198316
Validation loss: 2.1642458239705364

Epoch: 6| Step: 8
Training loss: 0.5077191193626771
Validation loss: 2.2476346504755322

Epoch: 6| Step: 9
Training loss: 0.4310849613401323
Validation loss: 2.2134841230080213

Epoch: 6| Step: 10
Training loss: 0.638922755811135
Validation loss: 2.259992384348271

Epoch: 6| Step: 11
Training loss: 0.49839132029264266
Validation loss: 2.2790278423875496

Epoch: 6| Step: 12
Training loss: 0.5475563164927788
Validation loss: 2.245446527725005

Epoch: 6| Step: 13
Training loss: 0.5205202942115669
Validation loss: 2.2631535658199584

Epoch: 676| Step: 0
Training loss: 0.5178093735503234
Validation loss: 2.1913551393481647

Epoch: 6| Step: 1
Training loss: 0.6233791792511278
Validation loss: 2.224526706600655

Epoch: 6| Step: 2
Training loss: 0.4598243980470557
Validation loss: 2.2302229499290975

Epoch: 6| Step: 3
Training loss: 0.5886361600474483
Validation loss: 2.158455683457304

Epoch: 6| Step: 4
Training loss: 0.3727365771076474
Validation loss: 2.237847528389973

Epoch: 6| Step: 5
Training loss: 0.43143183634042753
Validation loss: 2.161480096222402

Epoch: 6| Step: 6
Training loss: 0.5850552083316888
Validation loss: 2.232038970709597

Epoch: 6| Step: 7
Training loss: 0.4918339079835526
Validation loss: 2.203028702171331

Epoch: 6| Step: 8
Training loss: 0.523912584293253
Validation loss: 2.191449504012533

Epoch: 6| Step: 9
Training loss: 0.5091731110189448
Validation loss: 2.1681049765671836

Epoch: 6| Step: 10
Training loss: 1.347567923042408
Validation loss: 2.2844392490061876

Epoch: 6| Step: 11
Training loss: 0.6827798412203184
Validation loss: 2.1431252088478376

Epoch: 6| Step: 12
Training loss: 0.5924230605280455
Validation loss: 2.1856644366679285

Epoch: 6| Step: 13
Training loss: 0.44337317155386247
Validation loss: 2.3002343464020476

Epoch: 677| Step: 0
Training loss: 0.6018009951560761
Validation loss: 2.226294705244805

Epoch: 6| Step: 1
Training loss: 0.3843180187757794
Validation loss: 2.310704049647059

Epoch: 6| Step: 2
Training loss: 0.626709341027545
Validation loss: 2.200501937673436

Epoch: 6| Step: 3
Training loss: 0.393122888143959
Validation loss: 2.324718709110461

Epoch: 6| Step: 4
Training loss: 0.518135289134902
Validation loss: 2.2422383574799682

Epoch: 6| Step: 5
Training loss: 1.3829493050872415
Validation loss: 2.2423158254250324

Epoch: 6| Step: 6
Training loss: 0.5216715616031076
Validation loss: 2.201218573436695

Epoch: 6| Step: 7
Training loss: 0.43812985720914605
Validation loss: 2.238661257771155

Epoch: 6| Step: 8
Training loss: 0.47330419407337715
Validation loss: 2.2899122639344247

Epoch: 6| Step: 9
Training loss: 0.5587196208282021
Validation loss: 2.2277950897101966

Epoch: 6| Step: 10
Training loss: 0.5733073780742173
Validation loss: 2.2322280772827563

Epoch: 6| Step: 11
Training loss: 0.5309150425212453
Validation loss: 2.2439592240422312

Epoch: 6| Step: 12
Training loss: 0.6127127423906585
Validation loss: 2.200296216610919

Epoch: 6| Step: 13
Training loss: 0.5958136033968611
Validation loss: 2.158283132936236

Epoch: 678| Step: 0
Training loss: 0.5549365814163574
Validation loss: 2.214567460456144

Epoch: 6| Step: 1
Training loss: 0.45216105960505476
Validation loss: 2.2532107233945013

Epoch: 6| Step: 2
Training loss: 0.5560427483207137
Validation loss: 2.26470709832125

Epoch: 6| Step: 3
Training loss: 0.4638081081312499
Validation loss: 2.20730534117589

Epoch: 6| Step: 4
Training loss: 0.8670076750841281
Validation loss: 2.2562084123832062

Epoch: 6| Step: 5
Training loss: 0.5901530383332972
Validation loss: 2.17236025779074

Epoch: 6| Step: 6
Training loss: 0.5174184300916942
Validation loss: 2.189844780961208

Epoch: 6| Step: 7
Training loss: 0.5222861880103972
Validation loss: 2.245143303716157

Epoch: 6| Step: 8
Training loss: 0.4063841891580141
Validation loss: 2.3058680849556925

Epoch: 6| Step: 9
Training loss: 0.373538786427928
Validation loss: 2.1695501290541928

Epoch: 6| Step: 10
Training loss: 0.6680927050058778
Validation loss: 2.2385645085504935

Epoch: 6| Step: 11
Training loss: 0.5178942308862879
Validation loss: 2.1082835212559865

Epoch: 6| Step: 12
Training loss: 1.4690192767099617
Validation loss: 2.203318066480409

Epoch: 6| Step: 13
Training loss: 0.37430707171967986
Validation loss: 2.251905087100581

Epoch: 679| Step: 0
Training loss: 0.5240261127575673
Validation loss: 2.1933016462580825

Epoch: 6| Step: 1
Training loss: 0.5441743105000513
Validation loss: 2.2065913215029194

Epoch: 6| Step: 2
Training loss: 0.46199425289575813
Validation loss: 2.1904119268731304

Epoch: 6| Step: 3
Training loss: 0.512047785613326
Validation loss: 2.187899038363737

Epoch: 6| Step: 4
Training loss: 0.3393572471078066
Validation loss: 2.2734305423920054

Epoch: 6| Step: 5
Training loss: 0.47628655808975395
Validation loss: 2.2244570766225373

Epoch: 6| Step: 6
Training loss: 0.469001082885769
Validation loss: 2.200731145064807

Epoch: 6| Step: 7
Training loss: 0.44876355867968387
Validation loss: 2.2677171706971704

Epoch: 6| Step: 8
Training loss: 0.42886436688709706
Validation loss: 2.2372455674425633

Epoch: 6| Step: 9
Training loss: 0.6331168255367691
Validation loss: 2.3103759392834107

Epoch: 6| Step: 10
Training loss: 0.4441631274532618
Validation loss: 2.182793925213039

Epoch: 6| Step: 11
Training loss: 1.424223082384644
Validation loss: 2.265869897966469

Epoch: 6| Step: 12
Training loss: 0.5723884112287922
Validation loss: 2.1712217035214376

Epoch: 6| Step: 13
Training loss: 0.6102260857349848
Validation loss: 2.239706647205741

Epoch: 680| Step: 0
Training loss: 0.6903974425732619
Validation loss: 2.2491352260709285

Epoch: 6| Step: 1
Training loss: 0.5355632376031941
Validation loss: 2.1983407346346535

Epoch: 6| Step: 2
Training loss: 0.3821626324177978
Validation loss: 2.2320482200800305

Epoch: 6| Step: 3
Training loss: 0.38685420582834257
Validation loss: 2.271219223198341

Epoch: 6| Step: 4
Training loss: 0.6288649977902933
Validation loss: 2.2395784195323554

Epoch: 6| Step: 5
Training loss: 0.422757356294304
Validation loss: 2.2085059228725585

Epoch: 6| Step: 6
Training loss: 0.5822471883729669
Validation loss: 2.2231582209429877

Epoch: 6| Step: 7
Training loss: 1.4380681117749619
Validation loss: 2.2026560614569877

Epoch: 6| Step: 8
Training loss: 0.4534957947120714
Validation loss: 2.196078308242394

Epoch: 6| Step: 9
Training loss: 0.4400784430425664
Validation loss: 2.1833467735870054

Epoch: 6| Step: 10
Training loss: 0.4530572511734928
Validation loss: 2.2067794285887827

Epoch: 6| Step: 11
Training loss: 0.35226237251775133
Validation loss: 2.251499267859805

Epoch: 6| Step: 12
Training loss: 0.5282931787993866
Validation loss: 2.2533453240891372

Epoch: 6| Step: 13
Training loss: 0.5624367360460536
Validation loss: 2.234767172338924

Epoch: 681| Step: 0
Training loss: 0.5796053722843427
Validation loss: 2.189409006628249

Epoch: 6| Step: 1
Training loss: 1.4972575867454787
Validation loss: 2.2728153199585646

Epoch: 6| Step: 2
Training loss: 0.5465067850007579
Validation loss: 2.188457705957599

Epoch: 6| Step: 3
Training loss: 0.5323080857861915
Validation loss: 2.148422722639795

Epoch: 6| Step: 4
Training loss: 0.5158669742045879
Validation loss: 2.177009710413467

Epoch: 6| Step: 5
Training loss: 0.5939077619469638
Validation loss: 2.1826795689986596

Epoch: 6| Step: 6
Training loss: 0.4058901586964955
Validation loss: 2.1752436521559515

Epoch: 6| Step: 7
Training loss: 0.500574913900734
Validation loss: 2.1667494408017913

Epoch: 6| Step: 8
Training loss: 0.5273007410666027
Validation loss: 2.233703062479731

Epoch: 6| Step: 9
Training loss: 0.3775881226737576
Validation loss: 2.2224016910124345

Epoch: 6| Step: 10
Training loss: 0.39812023022248233
Validation loss: 2.297725818755433

Epoch: 6| Step: 11
Training loss: 0.47659509578607623
Validation loss: 2.17179402315287

Epoch: 6| Step: 12
Training loss: 0.6017392877180726
Validation loss: 2.1569495796886233

Epoch: 6| Step: 13
Training loss: 0.3742039098166333
Validation loss: 2.3218480731457913

Epoch: 682| Step: 0
Training loss: 0.3917330475956979
Validation loss: 2.195727263056001

Epoch: 6| Step: 1
Training loss: 0.457789582600023
Validation loss: 2.2812424571246495

Epoch: 6| Step: 2
Training loss: 0.6549080342965953
Validation loss: 2.2565708640239004

Epoch: 6| Step: 3
Training loss: 0.5559089268615596
Validation loss: 2.26369229074216

Epoch: 6| Step: 4
Training loss: 0.5217868056555849
Validation loss: 2.257385729067998

Epoch: 6| Step: 5
Training loss: 0.4175023837221361
Validation loss: 2.2183889499391927

Epoch: 6| Step: 6
Training loss: 1.4766951405526172
Validation loss: 2.166898033135404

Epoch: 6| Step: 7
Training loss: 0.4567889035636697
Validation loss: 2.16972442904483

Epoch: 6| Step: 8
Training loss: 0.49470233278092723
Validation loss: 2.151117163552901

Epoch: 6| Step: 9
Training loss: 0.5999609944460087
Validation loss: 2.2728477868749715

Epoch: 6| Step: 10
Training loss: 0.6850970496044403
Validation loss: 2.2423448079034958

Epoch: 6| Step: 11
Training loss: 0.5604912866549782
Validation loss: 2.2547532517908904

Epoch: 6| Step: 12
Training loss: 0.5206318147540723
Validation loss: 2.1869071790018255

Epoch: 6| Step: 13
Training loss: 0.4677821658281776
Validation loss: 2.1466313907202133

Epoch: 683| Step: 0
Training loss: 1.3927283934939103
Validation loss: 2.1561397710383634

Epoch: 6| Step: 1
Training loss: 0.41159812347287406
Validation loss: 2.2022930137367878

Epoch: 6| Step: 2
Training loss: 0.6098398489684376
Validation loss: 2.1726661882346776

Epoch: 6| Step: 3
Training loss: 0.5529338355466317
Validation loss: 2.228683100284745

Epoch: 6| Step: 4
Training loss: 0.45523633376132683
Validation loss: 2.2043086677088364

Epoch: 6| Step: 5
Training loss: 0.5938997832650995
Validation loss: 2.2206281765738565

Epoch: 6| Step: 6
Training loss: 0.5607451775981673
Validation loss: 2.1956960843450846

Epoch: 6| Step: 7
Training loss: 0.6268092908488975
Validation loss: 2.2045207853417326

Epoch: 6| Step: 8
Training loss: 0.5650922331597407
Validation loss: 2.1660535434328163

Epoch: 6| Step: 9
Training loss: 0.6407902899780936
Validation loss: 2.2132063965116293

Epoch: 6| Step: 10
Training loss: 0.6091103101180609
Validation loss: 2.279409340541575

Epoch: 6| Step: 11
Training loss: 0.4946520123069779
Validation loss: 2.235463626496273

Epoch: 6| Step: 12
Training loss: 0.4360930093658511
Validation loss: 2.2635534720695816

Epoch: 6| Step: 13
Training loss: 0.3824572764016795
Validation loss: 2.2224575622682403

Epoch: 684| Step: 0
Training loss: 0.4800640976348702
Validation loss: 2.237805871731481

Epoch: 6| Step: 1
Training loss: 0.6801645862674032
Validation loss: 2.174996956938757

Epoch: 6| Step: 2
Training loss: 0.5042991289462211
Validation loss: 2.2438345835675926

Epoch: 6| Step: 3
Training loss: 0.6943097974790041
Validation loss: 2.1981261569098196

Epoch: 6| Step: 4
Training loss: 0.6075352014146561
Validation loss: 2.2814665222576855

Epoch: 6| Step: 5
Training loss: 0.7816918458794154
Validation loss: 2.1663382534130045

Epoch: 6| Step: 6
Training loss: 0.4501758827766444
Validation loss: 2.1800206709287497

Epoch: 6| Step: 7
Training loss: 0.41519431408101637
Validation loss: 2.2798785353139985

Epoch: 6| Step: 8
Training loss: 0.30410231122835535
Validation loss: 2.2395782089079384

Epoch: 6| Step: 9
Training loss: 0.6403267096175728
Validation loss: 2.201365851694114

Epoch: 6| Step: 10
Training loss: 0.5354800393367396
Validation loss: 2.2649274635575445

Epoch: 6| Step: 11
Training loss: 0.7248262558947738
Validation loss: 2.2742632396808578

Epoch: 6| Step: 12
Training loss: 1.3901843540831942
Validation loss: 2.2276155363250085

Epoch: 6| Step: 13
Training loss: 0.41558950387346133
Validation loss: 2.26898652213387

Epoch: 685| Step: 0
Training loss: 0.47874744016197035
Validation loss: 2.2800561408097173

Epoch: 6| Step: 1
Training loss: 0.6233523346517349
Validation loss: 2.2206825368455028

Epoch: 6| Step: 2
Training loss: 0.41901868342212195
Validation loss: 2.167500635552855

Epoch: 6| Step: 3
Training loss: 0.5107138281218987
Validation loss: 2.1995281308666623

Epoch: 6| Step: 4
Training loss: 0.47791903927831314
Validation loss: 2.2806469076133715

Epoch: 6| Step: 5
Training loss: 1.4514354605049968
Validation loss: 2.1586288894120305

Epoch: 6| Step: 6
Training loss: 0.6413488950187959
Validation loss: 2.2385025532074057

Epoch: 6| Step: 7
Training loss: 0.5589181451595452
Validation loss: 2.1878786922407225

Epoch: 6| Step: 8
Training loss: 0.6070644394136561
Validation loss: 2.192471163701745

Epoch: 6| Step: 9
Training loss: 0.3738289668632762
Validation loss: 2.2028928192332575

Epoch: 6| Step: 10
Training loss: 0.3886012871060772
Validation loss: 2.232126263347304

Epoch: 6| Step: 11
Training loss: 0.3609064476890594
Validation loss: 2.190870966212728

Epoch: 6| Step: 12
Training loss: 0.6737451253442169
Validation loss: 2.208330369956253

Epoch: 6| Step: 13
Training loss: 0.4867819082267069
Validation loss: 2.2917688969680334

Epoch: 686| Step: 0
Training loss: 0.46921574978118546
Validation loss: 2.2644332382121193

Epoch: 6| Step: 1
Training loss: 1.372199457681602
Validation loss: 2.1869163390824014

Epoch: 6| Step: 2
Training loss: 0.5247708319990197
Validation loss: 2.1461575871733287

Epoch: 6| Step: 3
Training loss: 0.35224862432245074
Validation loss: 2.2597231045925965

Epoch: 6| Step: 4
Training loss: 0.42337592124106654
Validation loss: 2.192852099633149

Epoch: 6| Step: 5
Training loss: 0.299291861742811
Validation loss: 2.2402295114532884

Epoch: 6| Step: 6
Training loss: 0.4542315881448183
Validation loss: 2.260442503291011

Epoch: 6| Step: 7
Training loss: 0.44636716931283704
Validation loss: 2.287029625444232

Epoch: 6| Step: 8
Training loss: 0.6176857446160984
Validation loss: 2.2164506819806196

Epoch: 6| Step: 9
Training loss: 0.5252984402129237
Validation loss: 2.2304783498302685

Epoch: 6| Step: 10
Training loss: 0.5540391329481487
Validation loss: 2.227121232600108

Epoch: 6| Step: 11
Training loss: 0.8485450128541925
Validation loss: 2.2345854739468267

Epoch: 6| Step: 12
Training loss: 0.46186162154936916
Validation loss: 2.183408174670034

Epoch: 6| Step: 13
Training loss: 0.4145845864467117
Validation loss: 2.191656024479217

Epoch: 687| Step: 0
Training loss: 0.5930366497341735
Validation loss: 2.1985893131966616

Epoch: 6| Step: 1
Training loss: 0.5021850406417968
Validation loss: 2.2115801425813846

Epoch: 6| Step: 2
Training loss: 0.5204675311735937
Validation loss: 2.2408243009762403

Epoch: 6| Step: 3
Training loss: 0.7113287132298458
Validation loss: 2.2506232418238388

Epoch: 6| Step: 4
Training loss: 0.4270404778665375
Validation loss: 2.1846790923181296

Epoch: 6| Step: 5
Training loss: 0.4600592991971895
Validation loss: 2.2201790085029702

Epoch: 6| Step: 6
Training loss: 0.6296068400175641
Validation loss: 2.1571087487778744

Epoch: 6| Step: 7
Training loss: 0.43814441360365264
Validation loss: 2.171461058669955

Epoch: 6| Step: 8
Training loss: 0.6809781415767082
Validation loss: 2.2866089376706427

Epoch: 6| Step: 9
Training loss: 0.47360885402213704
Validation loss: 2.1462653044188413

Epoch: 6| Step: 10
Training loss: 0.4833740536483446
Validation loss: 2.223626655970978

Epoch: 6| Step: 11
Training loss: 0.4581289883449085
Validation loss: 2.2123260288982154

Epoch: 6| Step: 12
Training loss: 0.3086382314758853
Validation loss: 2.230986581862154

Epoch: 6| Step: 13
Training loss: 1.7648334585618413
Validation loss: 2.136094355902747

Epoch: 688| Step: 0
Training loss: 0.5619546047590552
Validation loss: 2.1946222309561354

Epoch: 6| Step: 1
Training loss: 0.3568928456562833
Validation loss: 2.2135354575565316

Epoch: 6| Step: 2
Training loss: 0.4372301291132246
Validation loss: 2.1860840335525564

Epoch: 6| Step: 3
Training loss: 0.4952187819522711
Validation loss: 2.2594498833785637

Epoch: 6| Step: 4
Training loss: 0.3937503148637754
Validation loss: 2.2097731505461593

Epoch: 6| Step: 5
Training loss: 0.4859030524306937
Validation loss: 2.1843996634597547

Epoch: 6| Step: 6
Training loss: 0.5494700577208382
Validation loss: 2.1854077413587407

Epoch: 6| Step: 7
Training loss: 0.4747165982668036
Validation loss: 2.182218775725113

Epoch: 6| Step: 8
Training loss: 1.4254854078238406
Validation loss: 2.2083053304607554

Epoch: 6| Step: 9
Training loss: 0.5438244615192208
Validation loss: 2.283462340573771

Epoch: 6| Step: 10
Training loss: 0.5348494269704696
Validation loss: 2.202523425084294

Epoch: 6| Step: 11
Training loss: 0.46026957335699875
Validation loss: 2.2297557808139197

Epoch: 6| Step: 12
Training loss: 0.6322805971394807
Validation loss: 2.261957356798065

Epoch: 6| Step: 13
Training loss: 0.5927655441035155
Validation loss: 2.201482391605907

Epoch: 689| Step: 0
Training loss: 0.48151075371055985
Validation loss: 2.2129868087875484

Epoch: 6| Step: 1
Training loss: 0.3474582687026698
Validation loss: 2.195857486657006

Epoch: 6| Step: 2
Training loss: 0.36048803872305274
Validation loss: 2.200249701626936

Epoch: 6| Step: 3
Training loss: 0.667196999153929
Validation loss: 2.206334598182045

Epoch: 6| Step: 4
Training loss: 0.4425132508637653
Validation loss: 2.2204112338017143

Epoch: 6| Step: 5
Training loss: 0.46489984510455684
Validation loss: 2.2187162342127973

Epoch: 6| Step: 6
Training loss: 0.4425667723422681
Validation loss: 2.2351836199845856

Epoch: 6| Step: 7
Training loss: 0.7277582644822502
Validation loss: 2.285852497794157

Epoch: 6| Step: 8
Training loss: 0.5397591167084633
Validation loss: 2.168246385718799

Epoch: 6| Step: 9
Training loss: 0.4220965298299658
Validation loss: 2.2499512037047134

Epoch: 6| Step: 10
Training loss: 1.4794643084728898
Validation loss: 2.197624600819359

Epoch: 6| Step: 11
Training loss: 0.4457571252712311
Validation loss: 2.2475327770733022

Epoch: 6| Step: 12
Training loss: 0.5010689692946221
Validation loss: 2.1999348077036345

Epoch: 6| Step: 13
Training loss: 0.3803948136696622
Validation loss: 2.162394817686207

Epoch: 690| Step: 0
Training loss: 0.6868399789714382
Validation loss: 2.1625386896323153

Epoch: 6| Step: 1
Training loss: 1.3232202056522884
Validation loss: 2.1915037814781857

Epoch: 6| Step: 2
Training loss: 0.46482094139752744
Validation loss: 2.239844297604303

Epoch: 6| Step: 3
Training loss: 0.48583404690912013
Validation loss: 2.268900545949822

Epoch: 6| Step: 4
Training loss: 0.5091185866358666
Validation loss: 2.2388386073152073

Epoch: 6| Step: 5
Training loss: 0.763869082068852
Validation loss: 2.214837263464253

Epoch: 6| Step: 6
Training loss: 0.5515263975177342
Validation loss: 2.158025753164319

Epoch: 6| Step: 7
Training loss: 0.5375162698811664
Validation loss: 2.218587233613103

Epoch: 6| Step: 8
Training loss: 0.3748002911300404
Validation loss: 2.1541480897146186

Epoch: 6| Step: 9
Training loss: 0.4107348947063529
Validation loss: 2.251552655643983

Epoch: 6| Step: 10
Training loss: 0.5422855442457221
Validation loss: 2.221180456000321

Epoch: 6| Step: 11
Training loss: 0.5256823329070659
Validation loss: 2.248132496953179

Epoch: 6| Step: 12
Training loss: 0.478617038490229
Validation loss: 2.226238596337132

Epoch: 6| Step: 13
Training loss: 0.4755769450690694
Validation loss: 2.2452486327455996

Epoch: 691| Step: 0
Training loss: 0.4505843593667334
Validation loss: 2.274314990401506

Epoch: 6| Step: 1
Training loss: 1.4272424186896748
Validation loss: 2.1481055827218585

Epoch: 6| Step: 2
Training loss: 0.5411538728980204
Validation loss: 2.2087099547826243

Epoch: 6| Step: 3
Training loss: 0.5229561713546346
Validation loss: 2.2271843891424257

Epoch: 6| Step: 4
Training loss: 0.4954743611220432
Validation loss: 2.338262613184406

Epoch: 6| Step: 5
Training loss: 0.6396984051705249
Validation loss: 2.251629864610909

Epoch: 6| Step: 6
Training loss: 0.5273368552428324
Validation loss: 2.2164025258115725

Epoch: 6| Step: 7
Training loss: 0.2999389298188933
Validation loss: 2.2357111712699558

Epoch: 6| Step: 8
Training loss: 0.42608379848988776
Validation loss: 2.176728314786453

Epoch: 6| Step: 9
Training loss: 0.5268841754209418
Validation loss: 2.2244283981438775

Epoch: 6| Step: 10
Training loss: 0.5304455275923166
Validation loss: 2.288390210431018

Epoch: 6| Step: 11
Training loss: 0.6834051471477857
Validation loss: 2.2756153282865776

Epoch: 6| Step: 12
Training loss: 0.416160271799537
Validation loss: 2.282984805680232

Epoch: 6| Step: 13
Training loss: 0.42410880784016236
Validation loss: 2.186373912713178

Epoch: 692| Step: 0
Training loss: 0.3779356214269396
Validation loss: 2.2192751846251375

Epoch: 6| Step: 1
Training loss: 0.5931063978536069
Validation loss: 2.2084246988216187

Epoch: 6| Step: 2
Training loss: 0.46847262122968525
Validation loss: 2.306528369106268

Epoch: 6| Step: 3
Training loss: 0.6493615380177736
Validation loss: 2.193657061240677

Epoch: 6| Step: 4
Training loss: 0.640798847521473
Validation loss: 2.184810230528347

Epoch: 6| Step: 5
Training loss: 0.46018178056185516
Validation loss: 2.2154477728503768

Epoch: 6| Step: 6
Training loss: 0.5629765822823661
Validation loss: 2.179884040008553

Epoch: 6| Step: 7
Training loss: 0.4307517656565748
Validation loss: 2.166453594383011

Epoch: 6| Step: 8
Training loss: 0.25752294058598896
Validation loss: 2.291248399892048

Epoch: 6| Step: 9
Training loss: 0.5187881145493048
Validation loss: 2.24434878956935

Epoch: 6| Step: 10
Training loss: 0.5025066485368432
Validation loss: 2.245013812421146

Epoch: 6| Step: 11
Training loss: 0.5090450294639386
Validation loss: 2.1452170933840793

Epoch: 6| Step: 12
Training loss: 1.354574386643796
Validation loss: 2.219252587647552

Epoch: 6| Step: 13
Training loss: 0.23209705415096724
Validation loss: 2.2058024442870434

Epoch: 693| Step: 0
Training loss: 0.3485336697013109
Validation loss: 2.161177703830238

Epoch: 6| Step: 1
Training loss: 0.37223888193081045
Validation loss: 2.223462500941239

Epoch: 6| Step: 2
Training loss: 0.4997885674235697
Validation loss: 2.228668031383358

Epoch: 6| Step: 3
Training loss: 1.4182077421862245
Validation loss: 2.2364837175368595

Epoch: 6| Step: 4
Training loss: 0.3914708325980873
Validation loss: 2.2372698897164454

Epoch: 6| Step: 5
Training loss: 0.4516708125326515
Validation loss: 2.2216824880620862

Epoch: 6| Step: 6
Training loss: 0.5211037378912438
Validation loss: 2.181130558037721

Epoch: 6| Step: 7
Training loss: 0.5385177181484906
Validation loss: 2.208686666456888

Epoch: 6| Step: 8
Training loss: 0.6789305846107835
Validation loss: 2.2157054662328375

Epoch: 6| Step: 9
Training loss: 0.5154042783012648
Validation loss: 2.151189383707744

Epoch: 6| Step: 10
Training loss: 0.5683661916002846
Validation loss: 2.186228010516292

Epoch: 6| Step: 11
Training loss: 0.5944488578580065
Validation loss: 2.2220000041412558

Epoch: 6| Step: 12
Training loss: 0.5840965852134403
Validation loss: 2.180422839363261

Epoch: 6| Step: 13
Training loss: 0.3938344524278587
Validation loss: 2.190391385226502

Epoch: 694| Step: 0
Training loss: 0.6368549645878419
Validation loss: 2.23556028171072

Epoch: 6| Step: 1
Training loss: 0.5584534155355335
Validation loss: 2.2266956162181124

Epoch: 6| Step: 2
Training loss: 0.4703454205723668
Validation loss: 2.194791255853376

Epoch: 6| Step: 3
Training loss: 0.5139731912226783
Validation loss: 2.2472515558715473

Epoch: 6| Step: 4
Training loss: 0.4334264380893722
Validation loss: 2.254701581080715

Epoch: 6| Step: 5
Training loss: 0.3836453001108572
Validation loss: 2.2039339943429517

Epoch: 6| Step: 6
Training loss: 0.43597069890755125
Validation loss: 2.2146150163748706

Epoch: 6| Step: 7
Training loss: 0.5485972668984032
Validation loss: 2.272317375082856

Epoch: 6| Step: 8
Training loss: 0.48085209820073316
Validation loss: 2.1861508183155616

Epoch: 6| Step: 9
Training loss: 0.3271194217397225
Validation loss: 2.2059701796429563

Epoch: 6| Step: 10
Training loss: 1.3480236050352978
Validation loss: 2.272932815197376

Epoch: 6| Step: 11
Training loss: 0.5822122791563986
Validation loss: 2.200416364311889

Epoch: 6| Step: 12
Training loss: 0.4531098560564981
Validation loss: 2.2508338593102484

Epoch: 6| Step: 13
Training loss: 0.6333904452882755
Validation loss: 2.1988283539151983

Epoch: 695| Step: 0
Training loss: 0.4382008490704816
Validation loss: 2.2201705676301406

Epoch: 6| Step: 1
Training loss: 0.5051343575290294
Validation loss: 2.2760072035665493

Epoch: 6| Step: 2
Training loss: 0.43794017174549416
Validation loss: 2.1421529360142766

Epoch: 6| Step: 3
Training loss: 0.43494620193303624
Validation loss: 2.289186950187819

Epoch: 6| Step: 4
Training loss: 0.6149718678250636
Validation loss: 2.265697187575658

Epoch: 6| Step: 5
Training loss: 0.5273581891378977
Validation loss: 2.2285146431501355

Epoch: 6| Step: 6
Training loss: 0.6117362223306421
Validation loss: 2.2545015914403366

Epoch: 6| Step: 7
Training loss: 0.41321686097075133
Validation loss: 2.2836730838845645

Epoch: 6| Step: 8
Training loss: 0.36988195024608006
Validation loss: 2.2012291917807754

Epoch: 6| Step: 9
Training loss: 0.5383349221632259
Validation loss: 2.2224252566608427

Epoch: 6| Step: 10
Training loss: 1.3954704818911319
Validation loss: 2.2443823010840496

Epoch: 6| Step: 11
Training loss: 0.3728765927880822
Validation loss: 2.2689325977206143

Epoch: 6| Step: 12
Training loss: 0.7006283196635213
Validation loss: 2.255769067412813

Epoch: 6| Step: 13
Training loss: 0.3821049983761163
Validation loss: 2.2547194350654878

Epoch: 696| Step: 0
Training loss: 0.6869391190831962
Validation loss: 2.2303096688002975

Epoch: 6| Step: 1
Training loss: 0.432947932238123
Validation loss: 2.225844131238183

Epoch: 6| Step: 2
Training loss: 1.3261836505080575
Validation loss: 2.176560064415624

Epoch: 6| Step: 3
Training loss: 0.45173401924539675
Validation loss: 2.1861998859326706

Epoch: 6| Step: 4
Training loss: 0.7153281149903463
Validation loss: 2.2268598287833585

Epoch: 6| Step: 5
Training loss: 0.4884633602049733
Validation loss: 2.208871431860617

Epoch: 6| Step: 6
Training loss: 0.6987700061288418
Validation loss: 2.2079996827077615

Epoch: 6| Step: 7
Training loss: 0.4574551043343345
Validation loss: 2.172074881293128

Epoch: 6| Step: 8
Training loss: 0.4689376614354387
Validation loss: 2.193573342639182

Epoch: 6| Step: 9
Training loss: 0.5377053578218203
Validation loss: 2.243862912335125

Epoch: 6| Step: 10
Training loss: 0.6427515601692271
Validation loss: 2.188261672400984

Epoch: 6| Step: 11
Training loss: 0.6937606295209489
Validation loss: 2.1770575368225957

Epoch: 6| Step: 12
Training loss: 0.3244484237304576
Validation loss: 2.2686246472052507

Epoch: 6| Step: 13
Training loss: 0.4093844827616558
Validation loss: 2.187465188120059

Epoch: 697| Step: 0
Training loss: 0.5389784318911741
Validation loss: 2.2046017968081753

Epoch: 6| Step: 1
Training loss: 1.4056184410121981
Validation loss: 2.2113621404421484

Epoch: 6| Step: 2
Training loss: 0.6324344965975308
Validation loss: 2.169198702649136

Epoch: 6| Step: 3
Training loss: 0.42115874770815687
Validation loss: 2.233173656938788

Epoch: 6| Step: 4
Training loss: 0.4870185394146056
Validation loss: 2.1644877425450986

Epoch: 6| Step: 5
Training loss: 0.6129979250594302
Validation loss: 2.21586997956678

Epoch: 6| Step: 6
Training loss: 0.41003038200761605
Validation loss: 2.243490888108494

Epoch: 6| Step: 7
Training loss: 0.44723558949731196
Validation loss: 2.206064830224093

Epoch: 6| Step: 8
Training loss: 0.4738196879340974
Validation loss: 2.1981917267833464

Epoch: 6| Step: 9
Training loss: 0.4867623317304526
Validation loss: 2.2680245800712298

Epoch: 6| Step: 10
Training loss: 0.3632533360083258
Validation loss: 2.2322740332972497

Epoch: 6| Step: 11
Training loss: 0.37779750040094773
Validation loss: 2.241657123605592

Epoch: 6| Step: 12
Training loss: 0.4342770047419164
Validation loss: 2.2621010502872494

Epoch: 6| Step: 13
Training loss: 0.5637072747020136
Validation loss: 2.1956147200570384

Epoch: 698| Step: 0
Training loss: 0.6056144292989539
Validation loss: 2.2514780834165786

Epoch: 6| Step: 1
Training loss: 0.3697230673905389
Validation loss: 2.213615246200714

Epoch: 6| Step: 2
Training loss: 0.46364067570424417
Validation loss: 2.1166867468942994

Epoch: 6| Step: 3
Training loss: 0.6158002884619131
Validation loss: 2.2267681551451917

Epoch: 6| Step: 4
Training loss: 0.48610887602640424
Validation loss: 2.2513389113000484

Epoch: 6| Step: 5
Training loss: 0.48249487382507905
Validation loss: 2.2512453955402436

Epoch: 6| Step: 6
Training loss: 1.292226388108556
Validation loss: 2.1873565240032367

Epoch: 6| Step: 7
Training loss: 0.5118918672048617
Validation loss: 2.219175773646495

Epoch: 6| Step: 8
Training loss: 0.2839980052631132
Validation loss: 2.146631477304218

Epoch: 6| Step: 9
Training loss: 0.6396095788232449
Validation loss: 2.165115148407472

Epoch: 6| Step: 10
Training loss: 0.37052311440874675
Validation loss: 2.17607376690014

Epoch: 6| Step: 11
Training loss: 0.48778357511072906
Validation loss: 2.2283785242017724

Epoch: 6| Step: 12
Training loss: 0.47363572267247855
Validation loss: 2.0986291954087117

Epoch: 6| Step: 13
Training loss: 0.49425561042017124
Validation loss: 2.2541876179181304

Epoch: 699| Step: 0
Training loss: 0.47810155898332496
Validation loss: 2.2286661724950285

Epoch: 6| Step: 1
Training loss: 0.4607766404152572
Validation loss: 2.29358749397413

Epoch: 6| Step: 2
Training loss: 0.39298604771669604
Validation loss: 2.2402058401345952

Epoch: 6| Step: 3
Training loss: 0.4745540037154464
Validation loss: 2.2028276203069463

Epoch: 6| Step: 4
Training loss: 0.5439350668252136
Validation loss: 2.2067997429054342

Epoch: 6| Step: 5
Training loss: 0.7058848154268135
Validation loss: 2.200725218024992

Epoch: 6| Step: 6
Training loss: 0.6199439820624618
Validation loss: 2.2265894193232767

Epoch: 6| Step: 7
Training loss: 0.41167922870810586
Validation loss: 2.1847281442916455

Epoch: 6| Step: 8
Training loss: 0.36873513612046704
Validation loss: 2.210202880527998

Epoch: 6| Step: 9
Training loss: 0.43222506902534075
Validation loss: 2.180872544717662

Epoch: 6| Step: 10
Training loss: 0.5056618264253108
Validation loss: 2.1798471871665916

Epoch: 6| Step: 11
Training loss: 0.5645071353613441
Validation loss: 2.1897526898039654

Epoch: 6| Step: 12
Training loss: 0.45485868607021024
Validation loss: 2.2265346799536223

Epoch: 6| Step: 13
Training loss: 1.7512432859021148
Validation loss: 2.21026757714739

Epoch: 700| Step: 0
Training loss: 0.42367397968346976
Validation loss: 2.2620537639558718

Epoch: 6| Step: 1
Training loss: 0.41751906902485547
Validation loss: 2.1694115577071904

Epoch: 6| Step: 2
Training loss: 0.3197607778279209
Validation loss: 2.203034134265666

Epoch: 6| Step: 3
Training loss: 0.5080654394660955
Validation loss: 2.260090025514344

Epoch: 6| Step: 4
Training loss: 0.581519445909259
Validation loss: 2.240557375548578

Epoch: 6| Step: 5
Training loss: 0.6233670598823451
Validation loss: 2.204218945209993

Epoch: 6| Step: 6
Training loss: 0.6396890176029215
Validation loss: 2.111140145738301

Epoch: 6| Step: 7
Training loss: 0.3428177981458417
Validation loss: 2.261460144831547

Epoch: 6| Step: 8
Training loss: 1.3773952342519655
Validation loss: 2.213494200996824

Epoch: 6| Step: 9
Training loss: 0.4769120575941363
Validation loss: 2.193050523744832

Epoch: 6| Step: 10
Training loss: 0.6224675609378669
Validation loss: 2.1699744314794347

Epoch: 6| Step: 11
Training loss: 0.3414216516019256
Validation loss: 2.2366042286296244

Epoch: 6| Step: 12
Training loss: 0.5110135934611746
Validation loss: 2.178909671069391

Epoch: 6| Step: 13
Training loss: 0.5444143522822497
Validation loss: 2.2593354575388647

Testing loss: 3.117558543962389
