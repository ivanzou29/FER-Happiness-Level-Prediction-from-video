Epoch: 1| Step: 0
Training loss: 4.332095972098796
Validation loss: 4.70333302470166

Epoch: 6| Step: 1
Training loss: 4.4039722805138295
Validation loss: 4.695161969754407

Epoch: 6| Step: 2
Training loss: 4.769714002052634
Validation loss: 4.690614029373326

Epoch: 6| Step: 3
Training loss: 5.324355954188666
Validation loss: 4.683824071629895

Epoch: 6| Step: 4
Training loss: 6.096378952642996
Validation loss: 4.677905986593223

Epoch: 6| Step: 5
Training loss: 5.047312620103751
Validation loss: 4.6748495251765325

Epoch: 6| Step: 6
Training loss: 4.583278632560063
Validation loss: 4.669314821161671

Epoch: 6| Step: 7
Training loss: 3.584901215324184
Validation loss: 4.663693235933729

Epoch: 6| Step: 8
Training loss: 5.288797436697308
Validation loss: 4.65866995334193

Epoch: 6| Step: 9
Training loss: 5.45671247726782
Validation loss: 4.6524132800638895

Epoch: 6| Step: 10
Training loss: 4.673832614002232
Validation loss: 4.650807076413204

Epoch: 6| Step: 11
Training loss: 3.657712725321857
Validation loss: 4.643902432224569

Epoch: 6| Step: 12
Training loss: 4.596386211452861
Validation loss: 4.636868640910938

Epoch: 6| Step: 13
Training loss: 3.77730802501365
Validation loss: 4.632469956034106

Epoch: 2| Step: 0
Training loss: 5.31904575767278
Validation loss: 4.628025191888352

Epoch: 6| Step: 1
Training loss: 4.132179485798801
Validation loss: 4.624044384463702

Epoch: 6| Step: 2
Training loss: 3.848970914759052
Validation loss: 4.621306785351263

Epoch: 6| Step: 3
Training loss: 5.142696067770191
Validation loss: 4.615219151666704

Epoch: 6| Step: 4
Training loss: 5.226670154323841
Validation loss: 4.60965992426006

Epoch: 6| Step: 5
Training loss: 5.0468436319893994
Validation loss: 4.604283397558799

Epoch: 6| Step: 6
Training loss: 4.218694841942659
Validation loss: 4.5995157865296115

Epoch: 6| Step: 7
Training loss: 5.562294431166806
Validation loss: 4.596701131620367

Epoch: 6| Step: 8
Training loss: 4.750079907196915
Validation loss: 4.590037132558198

Epoch: 6| Step: 9
Training loss: 4.934613120268753
Validation loss: 4.583313213464572

Epoch: 6| Step: 10
Training loss: 4.5500162816018355
Validation loss: 4.58007170145006

Epoch: 6| Step: 11
Training loss: 3.5195225790681204
Validation loss: 4.573127704524996

Epoch: 6| Step: 12
Training loss: 4.238472957933873
Validation loss: 4.564626070532994

Epoch: 6| Step: 13
Training loss: 4.836036101832022
Validation loss: 4.564264430268648

Epoch: 3| Step: 0
Training loss: 4.491583476714632
Validation loss: 4.558933475022667

Epoch: 6| Step: 1
Training loss: 4.908424235842284
Validation loss: 4.553854815602003

Epoch: 6| Step: 2
Training loss: 5.157256057155054
Validation loss: 4.546316131886102

Epoch: 6| Step: 3
Training loss: 4.401295141862365
Validation loss: 4.540630864075919

Epoch: 6| Step: 4
Training loss: 4.339134783309296
Validation loss: 4.535082938029472

Epoch: 6| Step: 5
Training loss: 4.267189717021577
Validation loss: 4.535483314694886

Epoch: 6| Step: 6
Training loss: 4.940050070196143
Validation loss: 4.526538091489932

Epoch: 6| Step: 7
Training loss: 5.367503594164984
Validation loss: 4.518827139613095

Epoch: 6| Step: 8
Training loss: 4.382303735371698
Validation loss: 4.515361973668185

Epoch: 6| Step: 9
Training loss: 3.640734756845402
Validation loss: 4.511686722836594

Epoch: 6| Step: 10
Training loss: 6.166255352977608
Validation loss: 4.50795272819746

Epoch: 6| Step: 11
Training loss: 4.185247698054129
Validation loss: 4.499189634290005

Epoch: 6| Step: 12
Training loss: 4.170580488093476
Validation loss: 4.494420132241554

Epoch: 6| Step: 13
Training loss: 2.9470439648049305
Validation loss: 4.487504786541599

Epoch: 4| Step: 0
Training loss: 3.4450208752446745
Validation loss: 4.482031830126859

Epoch: 6| Step: 1
Training loss: 4.144146727935817
Validation loss: 4.47730338434423

Epoch: 6| Step: 2
Training loss: 4.459766454697413
Validation loss: 4.4712147110415925

Epoch: 6| Step: 3
Training loss: 4.833461540538746
Validation loss: 4.4657535180361885

Epoch: 6| Step: 4
Training loss: 4.668524622041362
Validation loss: 4.4632034467493

Epoch: 6| Step: 5
Training loss: 4.4751698722777205
Validation loss: 4.457220993150994

Epoch: 6| Step: 6
Training loss: 4.168400263949954
Validation loss: 4.45079500517714

Epoch: 6| Step: 7
Training loss: 3.92405816216095
Validation loss: 4.443197269360712

Epoch: 6| Step: 8
Training loss: 4.654789842887143
Validation loss: 4.438752541385168

Epoch: 6| Step: 9
Training loss: 5.121095984696309
Validation loss: 4.430330202844459

Epoch: 6| Step: 10
Training loss: 5.523885015463528
Validation loss: 4.425853922302432

Epoch: 6| Step: 11
Training loss: 5.438068930140997
Validation loss: 4.419586843070445

Epoch: 6| Step: 12
Training loss: 4.161647189187295
Validation loss: 4.413094076152339

Epoch: 6| Step: 13
Training loss: 4.081478683817908
Validation loss: 4.408387634276639

Epoch: 5| Step: 0
Training loss: 3.4345185268078446
Validation loss: 4.4036347369002815

Epoch: 6| Step: 1
Training loss: 3.9920226658424185
Validation loss: 4.392253528315984

Epoch: 6| Step: 2
Training loss: 3.279403021379919
Validation loss: 4.390896710495166

Epoch: 6| Step: 3
Training loss: 4.127390082390071
Validation loss: 4.382496759529896

Epoch: 6| Step: 4
Training loss: 5.213081067673862
Validation loss: 4.3743113642342975

Epoch: 6| Step: 5
Training loss: 3.7628411730828684
Validation loss: 4.373300023446034

Epoch: 6| Step: 6
Training loss: 4.412426238483607
Validation loss: 4.3594225773821185

Epoch: 6| Step: 7
Training loss: 5.182726950711361
Validation loss: 4.35775838124654

Epoch: 6| Step: 8
Training loss: 4.37499215261573
Validation loss: 4.350944848865328

Epoch: 6| Step: 9
Training loss: 4.34966089965834
Validation loss: 4.344591756939708

Epoch: 6| Step: 10
Training loss: 5.153178091799349
Validation loss: 4.341010942168303

Epoch: 6| Step: 11
Training loss: 5.26502258295938
Validation loss: 4.332280273996914

Epoch: 6| Step: 12
Training loss: 4.842047607528176
Validation loss: 4.322661327535969

Epoch: 6| Step: 13
Training loss: 4.684835668590652
Validation loss: 4.320675543583431

Epoch: 6| Step: 0
Training loss: 4.179609693712137
Validation loss: 4.310066517425883

Epoch: 6| Step: 1
Training loss: 3.835279109103608
Validation loss: 4.3066402618815065

Epoch: 6| Step: 2
Training loss: 4.920482038749084
Validation loss: 4.2955925787242375

Epoch: 6| Step: 3
Training loss: 4.137867596019416
Validation loss: 4.283715288240205

Epoch: 6| Step: 4
Training loss: 4.942462600157444
Validation loss: 4.284022933319113

Epoch: 6| Step: 5
Training loss: 4.206678965490613
Validation loss: 4.272397782991374

Epoch: 6| Step: 6
Training loss: 5.032914164859632
Validation loss: 4.267766863798398

Epoch: 6| Step: 7
Training loss: 3.9336105997885764
Validation loss: 4.262084727461826

Epoch: 6| Step: 8
Training loss: 5.121187047741383
Validation loss: 4.243965513137285

Epoch: 6| Step: 9
Training loss: 3.5945744107894257
Validation loss: 4.245541627022

Epoch: 6| Step: 10
Training loss: 3.6755464420054422
Validation loss: 4.233225307308771

Epoch: 6| Step: 11
Training loss: 5.360541302976135
Validation loss: 4.229115385460635

Epoch: 6| Step: 12
Training loss: 4.019083989860589
Validation loss: 4.2221879630290164

Epoch: 6| Step: 13
Training loss: 3.4315364085804316
Validation loss: 4.210057967122087

Epoch: 7| Step: 0
Training loss: 3.802874311273481
Validation loss: 4.2099632027800675

Epoch: 6| Step: 1
Training loss: 4.57061401415944
Validation loss: 4.197807505810804

Epoch: 6| Step: 2
Training loss: 4.507687042976364
Validation loss: 4.19234365554835

Epoch: 6| Step: 3
Training loss: 4.821735981824178
Validation loss: 4.183837939874666

Epoch: 6| Step: 4
Training loss: 4.710210285392488
Validation loss: 4.175926326690076

Epoch: 6| Step: 5
Training loss: 3.787051329775321
Validation loss: 4.167990644384975

Epoch: 6| Step: 6
Training loss: 3.699561098202858
Validation loss: 4.161904954269489

Epoch: 6| Step: 7
Training loss: 4.793705293727935
Validation loss: 4.153125954166487

Epoch: 6| Step: 8
Training loss: 4.94311165914304
Validation loss: 4.142453776066568

Epoch: 6| Step: 9
Training loss: 4.238479708055201
Validation loss: 4.133411121496493

Epoch: 6| Step: 10
Training loss: 4.171388061909022
Validation loss: 4.123422176112815

Epoch: 6| Step: 11
Training loss: 3.8537376096255924
Validation loss: 4.114694837079858

Epoch: 6| Step: 12
Training loss: 2.7155319988098205
Validation loss: 4.108669368119775

Epoch: 6| Step: 13
Training loss: 5.17330958819757
Validation loss: 4.101605855045598

Epoch: 8| Step: 0
Training loss: 3.3021575405956325
Validation loss: 4.094071427681515

Epoch: 6| Step: 1
Training loss: 4.284939477909309
Validation loss: 4.087461356762183

Epoch: 6| Step: 2
Training loss: 3.084426394017978
Validation loss: 4.0777925104262165

Epoch: 6| Step: 3
Training loss: 3.4455724086169575
Validation loss: 4.063531380887375

Epoch: 6| Step: 4
Training loss: 3.9707288239299943
Validation loss: 4.056746086625765

Epoch: 6| Step: 5
Training loss: 4.690008687415953
Validation loss: 4.050561431148946

Epoch: 6| Step: 6
Training loss: 3.65689759347391
Validation loss: 4.040155501015343

Epoch: 6| Step: 7
Training loss: 4.902050383403437
Validation loss: 4.032070769851591

Epoch: 6| Step: 8
Training loss: 4.578953794900639
Validation loss: 4.025558927740835

Epoch: 6| Step: 9
Training loss: 4.705778976314738
Validation loss: 4.014037194894721

Epoch: 6| Step: 10
Training loss: 4.524679958764824
Validation loss: 4.0096648418328344

Epoch: 6| Step: 11
Training loss: 4.814400433915519
Validation loss: 4.001183510348951

Epoch: 6| Step: 12
Training loss: 3.9016592897532547
Validation loss: 3.986650355529945

Epoch: 6| Step: 13
Training loss: 3.809683588060522
Validation loss: 3.977073717320284

Epoch: 9| Step: 0
Training loss: 3.4703214367884985
Validation loss: 3.970511360433191

Epoch: 6| Step: 1
Training loss: 3.783537621941337
Validation loss: 3.9608376957575855

Epoch: 6| Step: 2
Training loss: 4.346440860835251
Validation loss: 3.950027122939233

Epoch: 6| Step: 3
Training loss: 3.5518779676627363
Validation loss: 3.941465127213447

Epoch: 6| Step: 4
Training loss: 3.9625035186655686
Validation loss: 3.9270762368432375

Epoch: 6| Step: 5
Training loss: 4.748729736734743
Validation loss: 3.9199362211833852

Epoch: 6| Step: 6
Training loss: 4.383088400685373
Validation loss: 3.912060609218603

Epoch: 6| Step: 7
Training loss: 3.692436534669355
Validation loss: 3.898592321338507

Epoch: 6| Step: 8
Training loss: 4.12509617548867
Validation loss: 3.8884820829835025

Epoch: 6| Step: 9
Training loss: 3.3674540049152455
Validation loss: 3.8794617333169223

Epoch: 6| Step: 10
Training loss: 4.0036985464419335
Validation loss: 3.865304859919444

Epoch: 6| Step: 11
Training loss: 4.24650295219467
Validation loss: 3.8607052685924907

Epoch: 6| Step: 12
Training loss: 3.8635037843121163
Validation loss: 3.8531196939313936

Epoch: 6| Step: 13
Training loss: 5.336523691263993
Validation loss: 3.839890439250566

Epoch: 10| Step: 0
Training loss: 4.186608062949517
Validation loss: 3.8262346855487688

Epoch: 6| Step: 1
Training loss: 3.6731970172473254
Validation loss: 3.8164239355842486

Epoch: 6| Step: 2
Training loss: 3.2538375206108046
Validation loss: 3.8012368822476224

Epoch: 6| Step: 3
Training loss: 4.0391980264678145
Validation loss: 3.7907327698387987

Epoch: 6| Step: 4
Training loss: 4.409518281053756
Validation loss: 3.784795410365805

Epoch: 6| Step: 5
Training loss: 2.674023394702724
Validation loss: 3.777509583951129

Epoch: 6| Step: 6
Training loss: 4.114776194756474
Validation loss: 3.765072567213499

Epoch: 6| Step: 7
Training loss: 4.217958503226001
Validation loss: 3.750371749116802

Epoch: 6| Step: 8
Training loss: 4.358904194446947
Validation loss: 3.740358541329637

Epoch: 6| Step: 9
Training loss: 4.093261223653868
Validation loss: 3.723994795453451

Epoch: 6| Step: 10
Training loss: 3.687413101465494
Validation loss: 3.7121988267086614

Epoch: 6| Step: 11
Training loss: 4.6494039091926
Validation loss: 3.703871917892533

Epoch: 6| Step: 12
Training loss: 3.037891466322855
Validation loss: 3.690454969330465

Epoch: 6| Step: 13
Training loss: 3.903486693508003
Validation loss: 3.6734722321150297

Epoch: 11| Step: 0
Training loss: 3.5147556162457656
Validation loss: 3.663104227547858

Epoch: 6| Step: 1
Training loss: 4.525724633295854
Validation loss: 3.656540663399824

Epoch: 6| Step: 2
Training loss: 3.6868241547465295
Validation loss: 3.6446507564930526

Epoch: 6| Step: 3
Training loss: 3.968755646949415
Validation loss: 3.6320415912499366

Epoch: 6| Step: 4
Training loss: 3.8818558372131444
Validation loss: 3.615291528327629

Epoch: 6| Step: 5
Training loss: 3.588471358911143
Validation loss: 3.6024060994495253

Epoch: 6| Step: 6
Training loss: 3.4506694641730844
Validation loss: 3.5995384719750168

Epoch: 6| Step: 7
Training loss: 4.268488219962656
Validation loss: 3.5810391097033927

Epoch: 6| Step: 8
Training loss: 3.418741263146543
Validation loss: 3.569246029929658

Epoch: 6| Step: 9
Training loss: 3.554098160065965
Validation loss: 3.55784371722657

Epoch: 6| Step: 10
Training loss: 4.504020590211681
Validation loss: 3.546824621280338

Epoch: 6| Step: 11
Training loss: 3.870905528030049
Validation loss: 3.525968260078297

Epoch: 6| Step: 12
Training loss: 2.4781277400382864
Validation loss: 3.5140411944033394

Epoch: 6| Step: 13
Training loss: 3.3108664749398113
Validation loss: 3.4981754985389992

Epoch: 12| Step: 0
Training loss: 4.299683031331714
Validation loss: 3.493830471626219

Epoch: 6| Step: 1
Training loss: 3.5989708171063035
Validation loss: 3.4750202522150984

Epoch: 6| Step: 2
Training loss: 3.138376370413626
Validation loss: 3.458982449480974

Epoch: 6| Step: 3
Training loss: 3.2174854942771365
Validation loss: 3.451100133033005

Epoch: 6| Step: 4
Training loss: 2.2629407042498766
Validation loss: 3.4386901793773377

Epoch: 6| Step: 5
Training loss: 4.21732922401031
Validation loss: 3.42392601256667

Epoch: 6| Step: 6
Training loss: 3.3147644364332995
Validation loss: 3.4181623994081853

Epoch: 6| Step: 7
Training loss: 4.3100990577873555
Validation loss: 3.4027840083047565

Epoch: 6| Step: 8
Training loss: 3.8668035143170854
Validation loss: 3.383257386705805

Epoch: 6| Step: 9
Training loss: 3.160560006847642
Validation loss: 3.377170811065886

Epoch: 6| Step: 10
Training loss: 3.245417665661072
Validation loss: 3.3612317550889435

Epoch: 6| Step: 11
Training loss: 4.648488174290493
Validation loss: 3.34810981966449

Epoch: 6| Step: 12
Training loss: 3.351629367685956
Validation loss: 3.3281513671200273

Epoch: 6| Step: 13
Training loss: 2.511671288310328
Validation loss: 3.321630495867915

Epoch: 13| Step: 0
Training loss: 4.339298959181462
Validation loss: 3.305873431825088

Epoch: 6| Step: 1
Training loss: 3.5976819628729615
Validation loss: 3.289360500748127

Epoch: 6| Step: 2
Training loss: 3.4588604414291844
Validation loss: 3.2718616455274456

Epoch: 6| Step: 3
Training loss: 3.6987323703068546
Validation loss: 3.264288759460466

Epoch: 6| Step: 4
Training loss: 3.4324652126741593
Validation loss: 3.250424922870989

Epoch: 6| Step: 5
Training loss: 3.2803644347679017
Validation loss: 3.2329963233373453

Epoch: 6| Step: 6
Training loss: 2.9341593475236065
Validation loss: 3.220724333231106

Epoch: 6| Step: 7
Training loss: 3.0102079290512553
Validation loss: 3.199528053722701

Epoch: 6| Step: 8
Training loss: 3.2114211412013196
Validation loss: 3.1878627688895325

Epoch: 6| Step: 9
Training loss: 2.2757623589854883
Validation loss: 3.1669508021803963

Epoch: 6| Step: 10
Training loss: 3.9320319824703147
Validation loss: 3.1677227215802084

Epoch: 6| Step: 11
Training loss: 3.414109707643443
Validation loss: 3.149386957625403

Epoch: 6| Step: 12
Training loss: 3.640250911239134
Validation loss: 3.1318899989592173

Epoch: 6| Step: 13
Training loss: 3.440219704908684
Validation loss: 3.1161917065013247

Epoch: 14| Step: 0
Training loss: 3.7621025610596583
Validation loss: 3.1106483909607685

Epoch: 6| Step: 1
Training loss: 3.235710715944841
Validation loss: 3.089785181813846

Epoch: 6| Step: 2
Training loss: 3.1916218454850878
Validation loss: 3.0774334337361284

Epoch: 6| Step: 3
Training loss: 2.7258938294611967
Validation loss: 3.068513321952079

Epoch: 6| Step: 4
Training loss: 2.8315432634532742
Validation loss: 3.058478605885008

Epoch: 6| Step: 5
Training loss: 3.374065411054043
Validation loss: 3.0417864044486316

Epoch: 6| Step: 6
Training loss: 2.9007486758161285
Validation loss: 3.0245169551296414

Epoch: 6| Step: 7
Training loss: 3.8871694638952956
Validation loss: 3.015316460665562

Epoch: 6| Step: 8
Training loss: 3.31350807829287
Validation loss: 3.0049684820200726

Epoch: 6| Step: 9
Training loss: 3.239649061576777
Validation loss: 2.9937078280093297

Epoch: 6| Step: 10
Training loss: 3.2816318834694904
Validation loss: 2.9812342219142547

Epoch: 6| Step: 11
Training loss: 3.3307971524877504
Validation loss: 2.962272022731845

Epoch: 6| Step: 12
Training loss: 3.1706910578070544
Validation loss: 2.952514664365205

Epoch: 6| Step: 13
Training loss: 3.361952533611508
Validation loss: 2.933507687970068

Epoch: 15| Step: 0
Training loss: 2.8436148475138077
Validation loss: 2.9249876020849075

Epoch: 6| Step: 1
Training loss: 3.135304209233298
Validation loss: 2.9046024561972663

Epoch: 6| Step: 2
Training loss: 3.1066124687324277
Validation loss: 2.8970722565005924

Epoch: 6| Step: 3
Training loss: 3.221842493139313
Validation loss: 2.8907087984052864

Epoch: 6| Step: 4
Training loss: 3.0986157310729157
Validation loss: 2.873072505519917

Epoch: 6| Step: 5
Training loss: 2.639606256744235
Validation loss: 2.863016683157947

Epoch: 6| Step: 6
Training loss: 3.088223540126113
Validation loss: 2.8439878968017247

Epoch: 6| Step: 7
Training loss: 3.159916174295872
Validation loss: 2.843202897336834

Epoch: 6| Step: 8
Training loss: 3.5139450467480198
Validation loss: 2.8227648351197816

Epoch: 6| Step: 9
Training loss: 3.0914189968660946
Validation loss: 2.8151299043057327

Epoch: 6| Step: 10
Training loss: 3.8930818085441743
Validation loss: 2.812455887716316

Epoch: 6| Step: 11
Training loss: 2.798579543708447
Validation loss: 2.7962508369907466

Epoch: 6| Step: 12
Training loss: 3.0834225993938356
Validation loss: 2.7925810390120853

Epoch: 6| Step: 13
Training loss: 2.717551306948223
Validation loss: 2.771590332451521

Epoch: 16| Step: 0
Training loss: 2.890034878266215
Validation loss: 2.7732508627616994

Epoch: 6| Step: 1
Training loss: 2.7061464038781073
Validation loss: 2.760165326653939

Epoch: 6| Step: 2
Training loss: 3.3887458903119962
Validation loss: 2.75342721571305

Epoch: 6| Step: 3
Training loss: 3.0652322842321147
Validation loss: 2.734184441789712

Epoch: 6| Step: 4
Training loss: 3.070742356200543
Validation loss: 2.7305025915484302

Epoch: 6| Step: 5
Training loss: 3.2132643091008872
Validation loss: 2.7258635365265245

Epoch: 6| Step: 6
Training loss: 2.677803467152025
Validation loss: 2.708222428757517

Epoch: 6| Step: 7
Training loss: 3.463341009690189
Validation loss: 2.6979298960493256

Epoch: 6| Step: 8
Training loss: 3.164038537959034
Validation loss: 2.685786312105376

Epoch: 6| Step: 9
Training loss: 2.662989425449097
Validation loss: 2.6861895890940133

Epoch: 6| Step: 10
Training loss: 2.53666240228937
Validation loss: 2.6761090827428564

Epoch: 6| Step: 11
Training loss: 3.2595510257870597
Validation loss: 2.6731550893090605

Epoch: 6| Step: 12
Training loss: 2.7064578287083396
Validation loss: 2.662362130278632

Epoch: 6| Step: 13
Training loss: 3.394156028105874
Validation loss: 2.6492935497427803

Epoch: 17| Step: 0
Training loss: 3.2236072223783596
Validation loss: 2.638123698134643

Epoch: 6| Step: 1
Training loss: 3.0837004846773333
Validation loss: 2.6378624840439984

Epoch: 6| Step: 2
Training loss: 2.9280047250511525
Validation loss: 2.624879671181848

Epoch: 6| Step: 3
Training loss: 2.561662118279368
Validation loss: 2.625125298974194

Epoch: 6| Step: 4
Training loss: 3.601711443885005
Validation loss: 2.6249744005805704

Epoch: 6| Step: 5
Training loss: 2.703589162500217
Validation loss: 2.608318418281741

Epoch: 6| Step: 6
Training loss: 2.7211383545401655
Validation loss: 2.6087875122412303

Epoch: 6| Step: 7
Training loss: 3.274628270142611
Validation loss: 2.6057518021228137

Epoch: 6| Step: 8
Training loss: 3.2842352956283114
Validation loss: 2.5954349301831563

Epoch: 6| Step: 9
Training loss: 2.152981478443555
Validation loss: 2.588642215383219

Epoch: 6| Step: 10
Training loss: 2.462879589276921
Validation loss: 2.5884262048976177

Epoch: 6| Step: 11
Training loss: 3.1675915287706604
Validation loss: 2.587881103052324

Epoch: 6| Step: 12
Training loss: 2.7186557271112743
Validation loss: 2.5695921744467043

Epoch: 6| Step: 13
Training loss: 3.035665069309344
Validation loss: 2.5659072537459604

Epoch: 18| Step: 0
Training loss: 2.9652634877662867
Validation loss: 2.5695482280923074

Epoch: 6| Step: 1
Training loss: 2.082715693153605
Validation loss: 2.56812701715716

Epoch: 6| Step: 2
Training loss: 3.376751198145165
Validation loss: 2.5699849166050828

Epoch: 6| Step: 3
Training loss: 2.809820467009188
Validation loss: 2.563738842369302

Epoch: 6| Step: 4
Training loss: 3.0626103906782416
Validation loss: 2.564482210616959

Epoch: 6| Step: 5
Training loss: 2.43008331312991
Validation loss: 2.559216645082878

Epoch: 6| Step: 6
Training loss: 2.456427228517854
Validation loss: 2.5498693416225047

Epoch: 6| Step: 7
Training loss: 3.2570067948530212
Validation loss: 2.5513186784436006

Epoch: 6| Step: 8
Training loss: 3.3743826690094916
Validation loss: 2.5495557740320343

Epoch: 6| Step: 9
Training loss: 3.1882242614094825
Validation loss: 2.5515764112626886

Epoch: 6| Step: 10
Training loss: 2.775196474010507
Validation loss: 2.5395221344030885

Epoch: 6| Step: 11
Training loss: 3.008594916498735
Validation loss: 2.5439621800303236

Epoch: 6| Step: 12
Training loss: 3.041936540171197
Validation loss: 2.543212169251812

Epoch: 6| Step: 13
Training loss: 2.610385539200875
Validation loss: 2.5311559297316215

Epoch: 19| Step: 0
Training loss: 2.906315464389963
Validation loss: 2.5367019835131313

Epoch: 6| Step: 1
Training loss: 2.7966265008593547
Validation loss: 2.5332605622962636

Epoch: 6| Step: 2
Training loss: 2.820210209309729
Validation loss: 2.541412324315174

Epoch: 6| Step: 3
Training loss: 3.2799060794130233
Validation loss: 2.5333782704787495

Epoch: 6| Step: 4
Training loss: 2.2358805245978326
Validation loss: 2.532393735536962

Epoch: 6| Step: 5
Training loss: 3.1006005474557363
Validation loss: 2.530614700512608

Epoch: 6| Step: 6
Training loss: 2.927403243605395
Validation loss: 2.534574184645145

Epoch: 6| Step: 7
Training loss: 3.4704128094585807
Validation loss: 2.5334291262992648

Epoch: 6| Step: 8
Training loss: 3.0383147665751444
Validation loss: 2.530047470455472

Epoch: 6| Step: 9
Training loss: 2.796276007076459
Validation loss: 2.540711140739824

Epoch: 6| Step: 10
Training loss: 2.3734314406758976
Validation loss: 2.5300591859449035

Epoch: 6| Step: 11
Training loss: 2.696442032909445
Validation loss: 2.525071960661663

Epoch: 6| Step: 12
Training loss: 3.2238557190143426
Validation loss: 2.5448107945247336

Epoch: 6| Step: 13
Training loss: 2.465965922371567
Validation loss: 2.5194022695487144

Epoch: 20| Step: 0
Training loss: 2.7393535522484695
Validation loss: 2.5319403235349753

Epoch: 6| Step: 1
Training loss: 2.9161343406636555
Validation loss: 2.516793973745598

Epoch: 6| Step: 2
Training loss: 2.753439313112761
Validation loss: 2.530508870986194

Epoch: 6| Step: 3
Training loss: 2.423352092563619
Validation loss: 2.518715877225992

Epoch: 6| Step: 4
Training loss: 2.471179973437913
Validation loss: 2.5332001729492872

Epoch: 6| Step: 5
Training loss: 2.6658537539572182
Validation loss: 2.532417722793095

Epoch: 6| Step: 6
Training loss: 2.6115313545753525
Validation loss: 2.5273451974936934

Epoch: 6| Step: 7
Training loss: 3.046488732526695
Validation loss: 2.525802286009716

Epoch: 6| Step: 8
Training loss: 2.8341263801861745
Validation loss: 2.5276776963746244

Epoch: 6| Step: 9
Training loss: 3.0614855896284943
Validation loss: 2.5272706986739766

Epoch: 6| Step: 10
Training loss: 3.2943409224983773
Validation loss: 2.513932305916297

Epoch: 6| Step: 11
Training loss: 3.682063864100731
Validation loss: 2.516271721172992

Epoch: 6| Step: 12
Training loss: 2.662550511127291
Validation loss: 2.524185210594925

Epoch: 6| Step: 13
Training loss: 3.0722671770696968
Validation loss: 2.520604780130227

Epoch: 21| Step: 0
Training loss: 2.6338943386855176
Validation loss: 2.512158990471181

Epoch: 6| Step: 1
Training loss: 2.676881616812684
Validation loss: 2.5097941176151113

Epoch: 6| Step: 2
Training loss: 2.2289057665108025
Validation loss: 2.5176403360290536

Epoch: 6| Step: 3
Training loss: 3.0315839445863495
Validation loss: 2.513447763472886

Epoch: 6| Step: 4
Training loss: 2.5509270572320095
Validation loss: 2.5268311846878335

Epoch: 6| Step: 5
Training loss: 3.103793094011676
Validation loss: 2.51403170123909

Epoch: 6| Step: 6
Training loss: 3.7138878588285484
Validation loss: 2.5178489772614645

Epoch: 6| Step: 7
Training loss: 2.934339730697754
Validation loss: 2.5109636679859766

Epoch: 6| Step: 8
Training loss: 3.1774342494257577
Validation loss: 2.512216824204602

Epoch: 6| Step: 9
Training loss: 3.4297820406246524
Validation loss: 2.5189613175267462

Epoch: 6| Step: 10
Training loss: 2.584266606817316
Validation loss: 2.5095564016248524

Epoch: 6| Step: 11
Training loss: 2.5830666086467478
Validation loss: 2.5220242975791196

Epoch: 6| Step: 12
Training loss: 2.770694891738437
Validation loss: 2.5202773079367726

Epoch: 6| Step: 13
Training loss: 2.3848367066533345
Validation loss: 2.5169489765010282

Epoch: 22| Step: 0
Training loss: 3.02027652914431
Validation loss: 2.5078994183381598

Epoch: 6| Step: 1
Training loss: 2.5454865397882513
Validation loss: 2.513495834696528

Epoch: 6| Step: 2
Training loss: 3.0002790957008667
Validation loss: 2.516264934770253

Epoch: 6| Step: 3
Training loss: 2.943217293715315
Validation loss: 2.520205679356954

Epoch: 6| Step: 4
Training loss: 3.2683771391219767
Validation loss: 2.5066571701721263

Epoch: 6| Step: 5
Training loss: 3.353957949634652
Validation loss: 2.517434154144339

Epoch: 6| Step: 6
Training loss: 3.2203467399187273
Validation loss: 2.5047375848144178

Epoch: 6| Step: 7
Training loss: 2.426442128454845
Validation loss: 2.5213939962270238

Epoch: 6| Step: 8
Training loss: 3.0797893846013915
Validation loss: 2.5259867408564953

Epoch: 6| Step: 9
Training loss: 1.7634536760268684
Validation loss: 2.5022448049451382

Epoch: 6| Step: 10
Training loss: 1.922418408987775
Validation loss: 2.5154026284540434

Epoch: 6| Step: 11
Training loss: 2.978732381969477
Validation loss: 2.5150361760163347

Epoch: 6| Step: 12
Training loss: 3.107864089468585
Validation loss: 2.506328810510722

Epoch: 6| Step: 13
Training loss: 3.3563810980000777
Validation loss: 2.512726761265015

Epoch: 23| Step: 0
Training loss: 2.8864095106691376
Validation loss: 2.5160321738156024

Epoch: 6| Step: 1
Training loss: 2.6412944058080834
Validation loss: 2.5124404287135422

Epoch: 6| Step: 2
Training loss: 2.2828724983158595
Validation loss: 2.5154710723961484

Epoch: 6| Step: 3
Training loss: 2.1668678581531604
Validation loss: 2.508540608547794

Epoch: 6| Step: 4
Training loss: 3.0970549222259813
Validation loss: 2.50973862239701

Epoch: 6| Step: 5
Training loss: 3.205297561377136
Validation loss: 2.515609323336437

Epoch: 6| Step: 6
Training loss: 3.1287533916800965
Validation loss: 2.5077721724744833

Epoch: 6| Step: 7
Training loss: 2.471522452463709
Validation loss: 2.505211272148527

Epoch: 6| Step: 8
Training loss: 3.469096398455561
Validation loss: 2.494305550815324

Epoch: 6| Step: 9
Training loss: 2.265829774218457
Validation loss: 2.4972360129046334

Epoch: 6| Step: 10
Training loss: 2.996313373021204
Validation loss: 2.508771055152118

Epoch: 6| Step: 11
Training loss: 3.035921410298573
Validation loss: 2.5061077848120297

Epoch: 6| Step: 12
Training loss: 3.184460256406694
Validation loss: 2.4947445553485808

Epoch: 6| Step: 13
Training loss: 3.129881441351104
Validation loss: 2.499116690262977

Epoch: 24| Step: 0
Training loss: 2.9668098936617753
Validation loss: 2.503509762950779

Epoch: 6| Step: 1
Training loss: 2.6596620075347412
Validation loss: 2.5035381347621617

Epoch: 6| Step: 2
Training loss: 2.8158437561342002
Validation loss: 2.5080764754758405

Epoch: 6| Step: 3
Training loss: 3.191655162129862
Validation loss: 2.4997541378497847

Epoch: 6| Step: 4
Training loss: 3.2698245264504417
Validation loss: 2.494520038789079

Epoch: 6| Step: 5
Training loss: 2.7748715413921468
Validation loss: 2.4991761060016304

Epoch: 6| Step: 6
Training loss: 2.723458170634542
Validation loss: 2.501912310579585

Epoch: 6| Step: 7
Training loss: 2.9426552196649354
Validation loss: 2.493743331636678

Epoch: 6| Step: 8
Training loss: 2.7040997109453304
Validation loss: 2.5058763904505525

Epoch: 6| Step: 9
Training loss: 2.716134314849413
Validation loss: 2.502089252959975

Epoch: 6| Step: 10
Training loss: 3.073958001717929
Validation loss: 2.498347823455831

Epoch: 6| Step: 11
Training loss: 2.664863801521188
Validation loss: 2.5078971500170693

Epoch: 6| Step: 12
Training loss: 3.0179120024131056
Validation loss: 2.5075638521637362

Epoch: 6| Step: 13
Training loss: 2.0674024174643177
Validation loss: 2.512411139593336

Epoch: 25| Step: 0
Training loss: 2.8732108478445983
Validation loss: 2.5122011609694845

Epoch: 6| Step: 1
Training loss: 2.8401456354974055
Validation loss: 2.505860942325072

Epoch: 6| Step: 2
Training loss: 3.429861285905271
Validation loss: 2.50625882703006

Epoch: 6| Step: 3
Training loss: 2.6375109125426834
Validation loss: 2.490824720752822

Epoch: 6| Step: 4
Training loss: 3.101005907827468
Validation loss: 2.5060822721332516

Epoch: 6| Step: 5
Training loss: 2.8942132896170416
Validation loss: 2.503420179174283

Epoch: 6| Step: 6
Training loss: 2.850622069079852
Validation loss: 2.510449116488231

Epoch: 6| Step: 7
Training loss: 2.1420888976840002
Validation loss: 2.502688969629761

Epoch: 6| Step: 8
Training loss: 2.6002130531170597
Validation loss: 2.509831869270113

Epoch: 6| Step: 9
Training loss: 2.8853887196276506
Validation loss: 2.5145309077656988

Epoch: 6| Step: 10
Training loss: 2.9591791976395543
Validation loss: 2.5032330291498166

Epoch: 6| Step: 11
Training loss: 2.9206835923785976
Validation loss: 2.5020136650274076

Epoch: 6| Step: 12
Training loss: 3.0557450515094056
Validation loss: 2.51028294531168

Epoch: 6| Step: 13
Training loss: 2.463358629670638
Validation loss: 2.5097954945354743

Epoch: 26| Step: 0
Training loss: 1.940092137105288
Validation loss: 2.498191173998512

Epoch: 6| Step: 1
Training loss: 3.0357839752660962
Validation loss: 2.496940606119712

Epoch: 6| Step: 2
Training loss: 2.5142108425380885
Validation loss: 2.5005101801098286

Epoch: 6| Step: 3
Training loss: 2.4957018143057383
Validation loss: 2.4963610976441943

Epoch: 6| Step: 4
Training loss: 2.607010369564456
Validation loss: 2.50276863753071

Epoch: 6| Step: 5
Training loss: 3.262769554958212
Validation loss: 2.495507389498015

Epoch: 6| Step: 6
Training loss: 2.653250223356572
Validation loss: 2.504207742223906

Epoch: 6| Step: 7
Training loss: 3.2839402568926013
Validation loss: 2.5009427118518537

Epoch: 6| Step: 8
Training loss: 2.7625076052185595
Validation loss: 2.4925973597428497

Epoch: 6| Step: 9
Training loss: 3.3188648613487577
Validation loss: 2.4950912305667625

Epoch: 6| Step: 10
Training loss: 3.154980999244024
Validation loss: 2.506683909379913

Epoch: 6| Step: 11
Training loss: 1.9979719369805757
Validation loss: 2.49103718565815

Epoch: 6| Step: 12
Training loss: 3.4351687762735
Validation loss: 2.487124027740068

Epoch: 6| Step: 13
Training loss: 3.0502854260576866
Validation loss: 2.501667062675569

Epoch: 27| Step: 0
Training loss: 3.0577739138110585
Validation loss: 2.4759684063254226

Epoch: 6| Step: 1
Training loss: 2.810969805359543
Validation loss: 2.4925127835842344

Epoch: 6| Step: 2
Training loss: 2.69784038146189
Validation loss: 2.4944601822447443

Epoch: 6| Step: 3
Training loss: 3.60732194383109
Validation loss: 2.499527133808001

Epoch: 6| Step: 4
Training loss: 2.8713418658734757
Validation loss: 2.5005065609851935

Epoch: 6| Step: 5
Training loss: 2.4918545587264322
Validation loss: 2.506222988610447

Epoch: 6| Step: 6
Training loss: 2.4332241800291072
Validation loss: 2.495514742917488

Epoch: 6| Step: 7
Training loss: 2.7233742159977443
Validation loss: 2.4983959599827625

Epoch: 6| Step: 8
Training loss: 2.1610894558673377
Validation loss: 2.500065496058465

Epoch: 6| Step: 9
Training loss: 2.8755539070267484
Validation loss: 2.4987403711140432

Epoch: 6| Step: 10
Training loss: 3.048923527595276
Validation loss: 2.491391246880918

Epoch: 6| Step: 11
Training loss: 2.890099884999804
Validation loss: 2.5020649329363054

Epoch: 6| Step: 12
Training loss: 3.3708909063212555
Validation loss: 2.502999272433741

Epoch: 6| Step: 13
Training loss: 2.154682418894707
Validation loss: 2.48732553312251

Epoch: 28| Step: 0
Training loss: 2.2410208295256697
Validation loss: 2.4986373930887327

Epoch: 6| Step: 1
Training loss: 3.0709021392801894
Validation loss: 2.503392045145674

Epoch: 6| Step: 2
Training loss: 2.726170727584298
Validation loss: 2.5004668866287068

Epoch: 6| Step: 3
Training loss: 3.4746327048296313
Validation loss: 2.495921344661477

Epoch: 6| Step: 4
Training loss: 2.5670461568156355
Validation loss: 2.4863216187816883

Epoch: 6| Step: 5
Training loss: 3.482504440929158
Validation loss: 2.505267179248824

Epoch: 6| Step: 6
Training loss: 2.25381231525444
Validation loss: 2.4826214468732655

Epoch: 6| Step: 7
Training loss: 2.2963081750368812
Validation loss: 2.5092981840953184

Epoch: 6| Step: 8
Training loss: 2.4351593908510583
Validation loss: 2.4869562413536057

Epoch: 6| Step: 9
Training loss: 2.9358070852113474
Validation loss: 2.4836063383877858

Epoch: 6| Step: 10
Training loss: 3.404181736166076
Validation loss: 2.4936915174052823

Epoch: 6| Step: 11
Training loss: 2.7443081298965692
Validation loss: 2.4871819519408476

Epoch: 6| Step: 12
Training loss: 2.820017284042742
Validation loss: 2.499140076768285

Epoch: 6| Step: 13
Training loss: 2.6092561249295128
Validation loss: 2.4930478675734333

Epoch: 29| Step: 0
Training loss: 2.6880826096783332
Validation loss: 2.493514375968485

Epoch: 6| Step: 1
Training loss: 2.084055533798594
Validation loss: 2.4936591377187356

Epoch: 6| Step: 2
Training loss: 2.3986593634660505
Validation loss: 2.4939434921717765

Epoch: 6| Step: 3
Training loss: 2.7521584449777245
Validation loss: 2.495759319603769

Epoch: 6| Step: 4
Training loss: 2.64499379653059
Validation loss: 2.5117193404585985

Epoch: 6| Step: 5
Training loss: 3.3149291434561996
Validation loss: 2.502986932510652

Epoch: 6| Step: 6
Training loss: 3.444896716159973
Validation loss: 2.498461092785747

Epoch: 6| Step: 7
Training loss: 2.5717804493911616
Validation loss: 2.4936825867152095

Epoch: 6| Step: 8
Training loss: 3.089670593579687
Validation loss: 2.488344078090494

Epoch: 6| Step: 9
Training loss: 2.932506944106678
Validation loss: 2.479503657979144

Epoch: 6| Step: 10
Training loss: 3.227473465199504
Validation loss: 2.508961732118703

Epoch: 6| Step: 11
Training loss: 2.5210237562489435
Validation loss: 2.488090753181517

Epoch: 6| Step: 12
Training loss: 2.8202852792033837
Validation loss: 2.49955726030772

Epoch: 6| Step: 13
Training loss: 3.0946056069077184
Validation loss: 2.508989623859162

Epoch: 30| Step: 0
Training loss: 3.2167584822864486
Validation loss: 2.4995827152284997

Epoch: 6| Step: 1
Training loss: 3.151143692929018
Validation loss: 2.4923941226057567

Epoch: 6| Step: 2
Training loss: 2.209731133447892
Validation loss: 2.495015820049412

Epoch: 6| Step: 3
Training loss: 2.6447676267028397
Validation loss: 2.4974933958378407

Epoch: 6| Step: 4
Training loss: 2.922448576253681
Validation loss: 2.4963564090948

Epoch: 6| Step: 5
Training loss: 2.185843576263539
Validation loss: 2.490924051141688

Epoch: 6| Step: 6
Training loss: 3.2870838438550973
Validation loss: 2.4843593521332226

Epoch: 6| Step: 7
Training loss: 2.819124769515349
Validation loss: 2.4893490428832346

Epoch: 6| Step: 8
Training loss: 3.4924783265541097
Validation loss: 2.4976213049674625

Epoch: 6| Step: 9
Training loss: 3.0667424303177357
Validation loss: 2.4904427943234846

Epoch: 6| Step: 10
Training loss: 2.4945148375485275
Validation loss: 2.4886900039214885

Epoch: 6| Step: 11
Training loss: 2.6312963268705114
Validation loss: 2.494205771280635

Epoch: 6| Step: 12
Training loss: 2.260710549184664
Validation loss: 2.4870897267334615

Epoch: 6| Step: 13
Training loss: 2.9145842793272028
Validation loss: 2.488437792869568

Epoch: 31| Step: 0
Training loss: 3.040083137680414
Validation loss: 2.476070560802679

Epoch: 6| Step: 1
Training loss: 3.4601254856088195
Validation loss: 2.4889223652088726

Epoch: 6| Step: 2
Training loss: 2.013515344228315
Validation loss: 2.4982589617151905

Epoch: 6| Step: 3
Training loss: 2.541723552963607
Validation loss: 2.49478417889803

Epoch: 6| Step: 4
Training loss: 2.50280356563822
Validation loss: 2.484129057876987

Epoch: 6| Step: 5
Training loss: 2.48113879668058
Validation loss: 2.493699629738026

Epoch: 6| Step: 6
Training loss: 2.9708491884497765
Validation loss: 2.5020646439962815

Epoch: 6| Step: 7
Training loss: 3.4135479222832963
Validation loss: 2.502792427292932

Epoch: 6| Step: 8
Training loss: 3.4773180194246445
Validation loss: 2.4948764115011706

Epoch: 6| Step: 9
Training loss: 2.995272567395282
Validation loss: 2.5022411063663594

Epoch: 6| Step: 10
Training loss: 2.914842925509968
Validation loss: 2.4911222657527095

Epoch: 6| Step: 11
Training loss: 2.3645371307923053
Validation loss: 2.4954881110674254

Epoch: 6| Step: 12
Training loss: 2.5129484545047
Validation loss: 2.4955124325202145

Epoch: 6| Step: 13
Training loss: 2.3218818263984233
Validation loss: 2.496870925236516

Epoch: 32| Step: 0
Training loss: 3.1894507329292927
Validation loss: 2.4903153817345975

Epoch: 6| Step: 1
Training loss: 2.2269374598614746
Validation loss: 2.498730771577429

Epoch: 6| Step: 2
Training loss: 2.88945684800186
Validation loss: 2.4845649428379857

Epoch: 6| Step: 3
Training loss: 2.5738155529683753
Validation loss: 2.4941370480261438

Epoch: 6| Step: 4
Training loss: 3.0454514528049206
Validation loss: 2.497522743910943

Epoch: 6| Step: 5
Training loss: 3.052324009976241
Validation loss: 2.495982809536671

Epoch: 6| Step: 6
Training loss: 2.0685719208840956
Validation loss: 2.5049051800597337

Epoch: 6| Step: 7
Training loss: 2.7200561542885304
Validation loss: 2.4945067890159134

Epoch: 6| Step: 8
Training loss: 2.8584529870200606
Validation loss: 2.4787813050698495

Epoch: 6| Step: 9
Training loss: 2.952133254385369
Validation loss: 2.4846498019183896

Epoch: 6| Step: 10
Training loss: 3.425297249473893
Validation loss: 2.491021322353176

Epoch: 6| Step: 11
Training loss: 2.7040964486792562
Validation loss: 2.4929541543604317

Epoch: 6| Step: 12
Training loss: 2.204253861181532
Validation loss: 2.490953915044748

Epoch: 6| Step: 13
Training loss: 3.440016224401494
Validation loss: 2.4971296455201006

Epoch: 33| Step: 0
Training loss: 3.092662273272566
Validation loss: 2.4798256648057624

Epoch: 6| Step: 1
Training loss: 3.041054511633195
Validation loss: 2.4933280722660096

Epoch: 6| Step: 2
Training loss: 2.7745290408131305
Validation loss: 2.4971056211194433

Epoch: 6| Step: 3
Training loss: 3.068764643430248
Validation loss: 2.480863514916673

Epoch: 6| Step: 4
Training loss: 2.3412272800172085
Validation loss: 2.4930818428975887

Epoch: 6| Step: 5
Training loss: 3.1969504786555696
Validation loss: 2.4963906310410953

Epoch: 6| Step: 6
Training loss: 2.565650213120012
Validation loss: 2.4911831132392948

Epoch: 6| Step: 7
Training loss: 2.5357216790780366
Validation loss: 2.490841127712507

Epoch: 6| Step: 8
Training loss: 2.2131553282837144
Validation loss: 2.5039933448843157

Epoch: 6| Step: 9
Training loss: 2.597255039064427
Validation loss: 2.483621576046984

Epoch: 6| Step: 10
Training loss: 2.621941555847085
Validation loss: 2.4818190396820223

Epoch: 6| Step: 11
Training loss: 3.283810443067775
Validation loss: 2.494256777243013

Epoch: 6| Step: 12
Training loss: 3.3718004955584404
Validation loss: 2.4839878690016275

Epoch: 6| Step: 13
Training loss: 2.409867675915751
Validation loss: 2.4887802070133547

Epoch: 34| Step: 0
Training loss: 2.973657346727607
Validation loss: 2.4850854717474116

Epoch: 6| Step: 1
Training loss: 2.524765562750448
Validation loss: 2.4906261499929547

Epoch: 6| Step: 2
Training loss: 2.596956408311453
Validation loss: 2.487542097725144

Epoch: 6| Step: 3
Training loss: 2.4108834182102568
Validation loss: 2.4856516606548253

Epoch: 6| Step: 4
Training loss: 2.638239669133252
Validation loss: 2.4963085485196594

Epoch: 6| Step: 5
Training loss: 2.4831453555175576
Validation loss: 2.481102601612967

Epoch: 6| Step: 6
Training loss: 2.834577249967825
Validation loss: 2.4982141781897553

Epoch: 6| Step: 7
Training loss: 2.9460354431257816
Validation loss: 2.4893217034701993

Epoch: 6| Step: 8
Training loss: 3.3560710894815395
Validation loss: 2.4966019342878054

Epoch: 6| Step: 9
Training loss: 2.767884102263759
Validation loss: 2.5066159414263556

Epoch: 6| Step: 10
Training loss: 2.2988913891172675
Validation loss: 2.482066902533272

Epoch: 6| Step: 11
Training loss: 3.9053355863318733
Validation loss: 2.4927780393455476

Epoch: 6| Step: 12
Training loss: 2.4586577982601225
Validation loss: 2.488542626970851

Epoch: 6| Step: 13
Training loss: 2.7277918451606427
Validation loss: 2.480868004888981

Epoch: 35| Step: 0
Training loss: 2.737028915771005
Validation loss: 2.5040355853293343

Epoch: 6| Step: 1
Training loss: 3.060998509623212
Validation loss: 2.501017891385002

Epoch: 6| Step: 2
Training loss: 3.345534089333945
Validation loss: 2.4919996637960953

Epoch: 6| Step: 3
Training loss: 2.740320423213516
Validation loss: 2.4886317079158844

Epoch: 6| Step: 4
Training loss: 2.0047803017357135
Validation loss: 2.482905238895022

Epoch: 6| Step: 5
Training loss: 3.189815801964726
Validation loss: 2.4779807446398836

Epoch: 6| Step: 6
Training loss: 2.730532665896229
Validation loss: 2.4954146316165495

Epoch: 6| Step: 7
Training loss: 2.4825438462733005
Validation loss: 2.487554959478297

Epoch: 6| Step: 8
Training loss: 2.7522260152911873
Validation loss: 2.494197570144027

Epoch: 6| Step: 9
Training loss: 2.7979168363350033
Validation loss: 2.504602233361866

Epoch: 6| Step: 10
Training loss: 2.61102726871623
Validation loss: 2.4877950642463302

Epoch: 6| Step: 11
Training loss: 2.7648555741349665
Validation loss: 2.490083495332028

Epoch: 6| Step: 12
Training loss: 2.781528930392922
Validation loss: 2.4896095745776754

Epoch: 6| Step: 13
Training loss: 3.285747824077151
Validation loss: 2.481202592947289

Epoch: 36| Step: 0
Training loss: 1.9025109940159832
Validation loss: 2.4891564597956486

Epoch: 6| Step: 1
Training loss: 3.5478043872018414
Validation loss: 2.477561982687249

Epoch: 6| Step: 2
Training loss: 3.0412484669710897
Validation loss: 2.4893850243351276

Epoch: 6| Step: 3
Training loss: 2.7600285863087017
Validation loss: 2.4754617509935994

Epoch: 6| Step: 4
Training loss: 2.450987157662722
Validation loss: 2.4840638527025716

Epoch: 6| Step: 5
Training loss: 2.859508573820411
Validation loss: 2.4866287968220804

Epoch: 6| Step: 6
Training loss: 2.2654305210172834
Validation loss: 2.486097874937213

Epoch: 6| Step: 7
Training loss: 3.2265834853849946
Validation loss: 2.489299732444677

Epoch: 6| Step: 8
Training loss: 3.0171476482997357
Validation loss: 2.481161878380745

Epoch: 6| Step: 9
Training loss: 2.6493371206402725
Validation loss: 2.4874066722072685

Epoch: 6| Step: 10
Training loss: 2.4942672804873998
Validation loss: 2.484279244532309

Epoch: 6| Step: 11
Training loss: 2.936106574533118
Validation loss: 2.4798777914915218

Epoch: 6| Step: 12
Training loss: 2.9019407092609453
Validation loss: 2.4959076683616788

Epoch: 6| Step: 13
Training loss: 2.8060436317330666
Validation loss: 2.4838513703299623

Epoch: 37| Step: 0
Training loss: 2.992505567094537
Validation loss: 2.481203484620334

Epoch: 6| Step: 1
Training loss: 2.5778764084695274
Validation loss: 2.48229130456999

Epoch: 6| Step: 2
Training loss: 2.5981777958280934
Validation loss: 2.483973597545238

Epoch: 6| Step: 3
Training loss: 2.613894722725167
Validation loss: 2.490512677702319

Epoch: 6| Step: 4
Training loss: 3.1255294351322194
Validation loss: 2.479086147568099

Epoch: 6| Step: 5
Training loss: 2.3669119192930284
Validation loss: 2.48210523135008

Epoch: 6| Step: 6
Training loss: 2.6810110843803523
Validation loss: 2.4923986380923293

Epoch: 6| Step: 7
Training loss: 3.1738294771631734
Validation loss: 2.4832530125607573

Epoch: 6| Step: 8
Training loss: 2.613864896229288
Validation loss: 2.4967806987097942

Epoch: 6| Step: 9
Training loss: 2.651560154982942
Validation loss: 2.4750736992102045

Epoch: 6| Step: 10
Training loss: 3.225732728977084
Validation loss: 2.490891352448528

Epoch: 6| Step: 11
Training loss: 1.6423117549793076
Validation loss: 2.495971548313546

Epoch: 6| Step: 12
Training loss: 3.5268938320481187
Validation loss: 2.4828673514453783

Epoch: 6| Step: 13
Training loss: 3.0071985980648375
Validation loss: 2.4933954079364056

Epoch: 38| Step: 0
Training loss: 2.8296963030690305
Validation loss: 2.4677347484325525

Epoch: 6| Step: 1
Training loss: 3.176046100003226
Validation loss: 2.479368279368876

Epoch: 6| Step: 2
Training loss: 3.1162236379892394
Validation loss: 2.4791071439901433

Epoch: 6| Step: 3
Training loss: 2.7015459156134067
Validation loss: 2.4784590446397003

Epoch: 6| Step: 4
Training loss: 2.8232609350056372
Validation loss: 2.496173302826098

Epoch: 6| Step: 5
Training loss: 2.8182184365206373
Validation loss: 2.4860069862031087

Epoch: 6| Step: 6
Training loss: 3.0971556135084835
Validation loss: 2.481584008099879

Epoch: 6| Step: 7
Training loss: 3.4004294685191656
Validation loss: 2.480431510575345

Epoch: 6| Step: 8
Training loss: 2.357853683203019
Validation loss: 2.4844328778826386

Epoch: 6| Step: 9
Training loss: 2.542030266774427
Validation loss: 2.480276544081237

Epoch: 6| Step: 10
Training loss: 2.641663747679565
Validation loss: 2.485002173981164

Epoch: 6| Step: 11
Training loss: 2.0271596953647917
Validation loss: 2.4866912305735345

Epoch: 6| Step: 12
Training loss: 2.64556548998126
Validation loss: 2.477865030632677

Epoch: 6| Step: 13
Training loss: 2.8299285027736207
Validation loss: 2.492502111465577

Epoch: 39| Step: 0
Training loss: 2.9508083076640377
Validation loss: 2.4843995422071523

Epoch: 6| Step: 1
Training loss: 2.586672767684401
Validation loss: 2.486967511443161

Epoch: 6| Step: 2
Training loss: 2.6284376976694324
Validation loss: 2.479364034321568

Epoch: 6| Step: 3
Training loss: 2.5573671618555496
Validation loss: 2.483055729809801

Epoch: 6| Step: 4
Training loss: 2.956154858467535
Validation loss: 2.491209583238126

Epoch: 6| Step: 5
Training loss: 3.3365592287838406
Validation loss: 2.4908987266994944

Epoch: 6| Step: 6
Training loss: 2.5162627554966726
Validation loss: 2.466941585999926

Epoch: 6| Step: 7
Training loss: 2.619792677851963
Validation loss: 2.4714378609790972

Epoch: 6| Step: 8
Training loss: 3.3021683707052745
Validation loss: 2.4830414560932548

Epoch: 6| Step: 9
Training loss: 2.875697839051147
Validation loss: 2.4741969737749447

Epoch: 6| Step: 10
Training loss: 2.8568714626025806
Validation loss: 2.476798475420413

Epoch: 6| Step: 11
Training loss: 1.927819463674305
Validation loss: 2.477806647556955

Epoch: 6| Step: 12
Training loss: 2.7882023187454616
Validation loss: 2.4801689976461603

Epoch: 6| Step: 13
Training loss: 2.977729148214618
Validation loss: 2.4798262912877167

Epoch: 40| Step: 0
Training loss: 2.8901657152018334
Validation loss: 2.4681382372096667

Epoch: 6| Step: 1
Training loss: 3.0052109602063277
Validation loss: 2.476176212528299

Epoch: 6| Step: 2
Training loss: 2.477876717635789
Validation loss: 2.4891086832476415

Epoch: 6| Step: 3
Training loss: 3.136565208240057
Validation loss: 2.485704933473352

Epoch: 6| Step: 4
Training loss: 2.683535201809696
Validation loss: 2.4686922258974464

Epoch: 6| Step: 5
Training loss: 3.2496996520716057
Validation loss: 2.4829391496029722

Epoch: 6| Step: 6
Training loss: 2.1552634815838245
Validation loss: 2.4841614916072974

Epoch: 6| Step: 7
Training loss: 2.3739965226261215
Validation loss: 2.491246718149253

Epoch: 6| Step: 8
Training loss: 2.8862089499308836
Validation loss: 2.480413150592173

Epoch: 6| Step: 9
Training loss: 3.1063487599444146
Validation loss: 2.4794132543999248

Epoch: 6| Step: 10
Training loss: 2.776384705801221
Validation loss: 2.487055128385228

Epoch: 6| Step: 11
Training loss: 2.760054932890732
Validation loss: 2.4716043291972594

Epoch: 6| Step: 12
Training loss: 3.030688990953657
Validation loss: 2.5015159502221835

Epoch: 6| Step: 13
Training loss: 1.758647059374453
Validation loss: 2.4952034158438026

Epoch: 41| Step: 0
Training loss: 2.6980210115930903
Validation loss: 2.479553431013807

Epoch: 6| Step: 1
Training loss: 2.2683357596215084
Validation loss: 2.4923222501811817

Epoch: 6| Step: 2
Training loss: 2.2188868950533625
Validation loss: 2.4728169813664067

Epoch: 6| Step: 3
Training loss: 2.9106171313427867
Validation loss: 2.4868732644814586

Epoch: 6| Step: 4
Training loss: 2.661600894183005
Validation loss: 2.48140937605557

Epoch: 6| Step: 5
Training loss: 2.9846291958068094
Validation loss: 2.480480714122679

Epoch: 6| Step: 6
Training loss: 3.1737770428581524
Validation loss: 2.476842936120875

Epoch: 6| Step: 7
Training loss: 3.0281828474221757
Validation loss: 2.480015920927989

Epoch: 6| Step: 8
Training loss: 2.5020642341522192
Validation loss: 2.4760700829809696

Epoch: 6| Step: 9
Training loss: 2.7352335426721766
Validation loss: 2.473675420071169

Epoch: 6| Step: 10
Training loss: 2.8457249082256526
Validation loss: 2.4869831547541126

Epoch: 6| Step: 11
Training loss: 2.7104899891800582
Validation loss: 2.4808515423063717

Epoch: 6| Step: 12
Training loss: 2.8420462063087477
Validation loss: 2.489968642345277

Epoch: 6| Step: 13
Training loss: 3.5527877929429685
Validation loss: 2.4883565380201693

Epoch: 42| Step: 0
Training loss: 2.179532609584044
Validation loss: 2.483971204168149

Epoch: 6| Step: 1
Training loss: 3.300568450749582
Validation loss: 2.485666805071117

Epoch: 6| Step: 2
Training loss: 2.552770893095481
Validation loss: 2.4819611100889976

Epoch: 6| Step: 3
Training loss: 3.1396387174227454
Validation loss: 2.4760811096123088

Epoch: 6| Step: 4
Training loss: 2.7542569417389045
Validation loss: 2.4746387779502133

Epoch: 6| Step: 5
Training loss: 2.5870679706599233
Validation loss: 2.474294470515353

Epoch: 6| Step: 6
Training loss: 3.2230285059620774
Validation loss: 2.4753713623974742

Epoch: 6| Step: 7
Training loss: 2.242103282662722
Validation loss: 2.4905350909429824

Epoch: 6| Step: 8
Training loss: 3.2719732027518758
Validation loss: 2.467521246424556

Epoch: 6| Step: 9
Training loss: 2.559431052613028
Validation loss: 2.475424665121115

Epoch: 6| Step: 10
Training loss: 2.1604899860865983
Validation loss: 2.48633677999683

Epoch: 6| Step: 11
Training loss: 2.707749660883218
Validation loss: 2.479958559173635

Epoch: 6| Step: 12
Training loss: 2.6277994033572405
Validation loss: 2.47390949367291

Epoch: 6| Step: 13
Training loss: 3.5096142735695564
Validation loss: 2.478874059671418

Epoch: 43| Step: 0
Training loss: 2.58342997052323
Validation loss: 2.4714918735007725

Epoch: 6| Step: 1
Training loss: 2.9927229041224943
Validation loss: 2.47279473099233

Epoch: 6| Step: 2
Training loss: 2.533389752997845
Validation loss: 2.4773509828198925

Epoch: 6| Step: 3
Training loss: 3.125750642267665
Validation loss: 2.4863631458969113

Epoch: 6| Step: 4
Training loss: 2.7976899904263406
Validation loss: 2.480975955017374

Epoch: 6| Step: 5
Training loss: 2.4960580265073755
Validation loss: 2.4682247194430307

Epoch: 6| Step: 6
Training loss: 3.226050384742914
Validation loss: 2.4730182831019887

Epoch: 6| Step: 7
Training loss: 2.8692556297151954
Validation loss: 2.4735836914188973

Epoch: 6| Step: 8
Training loss: 3.120543697619054
Validation loss: 2.485244948478549

Epoch: 6| Step: 9
Training loss: 2.0768444733811364
Validation loss: 2.480745937784895

Epoch: 6| Step: 10
Training loss: 2.8339017597042395
Validation loss: 2.4856388403643987

Epoch: 6| Step: 11
Training loss: 2.6365652082030766
Validation loss: 2.4884007231848475

Epoch: 6| Step: 12
Training loss: 2.8595260830346807
Validation loss: 2.487114686929234

Epoch: 6| Step: 13
Training loss: 2.3279657501441027
Validation loss: 2.479735161311593

Epoch: 44| Step: 0
Training loss: 3.2366199902810364
Validation loss: 2.4793632221213344

Epoch: 6| Step: 1
Training loss: 2.824768435009458
Validation loss: 2.492030205091067

Epoch: 6| Step: 2
Training loss: 2.9572676409186256
Validation loss: 2.478464888816365

Epoch: 6| Step: 3
Training loss: 2.5312187287082635
Validation loss: 2.477313761723761

Epoch: 6| Step: 4
Training loss: 3.1847438490071793
Validation loss: 2.4772154224039284

Epoch: 6| Step: 5
Training loss: 2.1248444892976828
Validation loss: 2.4849294579191508

Epoch: 6| Step: 6
Training loss: 2.668154351186256
Validation loss: 2.4764360259891562

Epoch: 6| Step: 7
Training loss: 1.655318160001481
Validation loss: 2.4807511410251246

Epoch: 6| Step: 8
Training loss: 3.3875721490925645
Validation loss: 2.485224764166315

Epoch: 6| Step: 9
Training loss: 2.3216865144726957
Validation loss: 2.4816261077743067

Epoch: 6| Step: 10
Training loss: 3.198698082965061
Validation loss: 2.4922508740623273

Epoch: 6| Step: 11
Training loss: 3.0627738674480294
Validation loss: 2.4707900819007196

Epoch: 6| Step: 12
Training loss: 2.3354475343168972
Validation loss: 2.4871699314092117

Epoch: 6| Step: 13
Training loss: 2.8838647922244105
Validation loss: 2.478244965536364

Epoch: 45| Step: 0
Training loss: 2.9078295937291427
Validation loss: 2.49845597773245

Epoch: 6| Step: 1
Training loss: 3.107122937970134
Validation loss: 2.47466955422475

Epoch: 6| Step: 2
Training loss: 3.241901283959233
Validation loss: 2.4804681712227334

Epoch: 6| Step: 3
Training loss: 2.607120842290152
Validation loss: 2.4820667579321336

Epoch: 6| Step: 4
Training loss: 2.670218684924024
Validation loss: 2.4662335240286213

Epoch: 6| Step: 5
Training loss: 2.6508115857201697
Validation loss: 2.472856663917114

Epoch: 6| Step: 6
Training loss: 2.78200675013016
Validation loss: 2.486944872252402

Epoch: 6| Step: 7
Training loss: 2.552203075687901
Validation loss: 2.4706118307610967

Epoch: 6| Step: 8
Training loss: 3.089852700781125
Validation loss: 2.4923213059122173

Epoch: 6| Step: 9
Training loss: 2.7839597724222473
Validation loss: 2.4825337013338262

Epoch: 6| Step: 10
Training loss: 2.5508520984011365
Validation loss: 2.4819119441537385

Epoch: 6| Step: 11
Training loss: 2.2089975425806707
Validation loss: 2.4742998634607463

Epoch: 6| Step: 12
Training loss: 2.4487082209389395
Validation loss: 2.4806396487514135

Epoch: 6| Step: 13
Training loss: 3.2280828482432216
Validation loss: 2.476109896653899

Epoch: 46| Step: 0
Training loss: 2.9041533752166444
Validation loss: 2.4802025002659995

Epoch: 6| Step: 1
Training loss: 2.6589538276568634
Validation loss: 2.4840315756008

Epoch: 6| Step: 2
Training loss: 3.1017116251342847
Validation loss: 2.4946081591665115

Epoch: 6| Step: 3
Training loss: 2.4622688688449337
Validation loss: 2.482011536207247

Epoch: 6| Step: 4
Training loss: 2.553170876808695
Validation loss: 2.4850799350868926

Epoch: 6| Step: 5
Training loss: 2.566202048157029
Validation loss: 2.4783511889197682

Epoch: 6| Step: 6
Training loss: 2.731897245136317
Validation loss: 2.4992150438246084

Epoch: 6| Step: 7
Training loss: 2.053855234283754
Validation loss: 2.4810717222462246

Epoch: 6| Step: 8
Training loss: 3.2456959321138257
Validation loss: 2.474321414402806

Epoch: 6| Step: 9
Training loss: 2.6976295131813344
Validation loss: 2.4926399156946384

Epoch: 6| Step: 10
Training loss: 2.6615037012183773
Validation loss: 2.4796086837020765

Epoch: 6| Step: 11
Training loss: 3.353675443010367
Validation loss: 2.485374141936826

Epoch: 6| Step: 12
Training loss: 2.9841404368307662
Validation loss: 2.478493203398595

Epoch: 6| Step: 13
Training loss: 2.1363358790957396
Validation loss: 2.4694533970527344

Epoch: 47| Step: 0
Training loss: 2.6485073564256933
Validation loss: 2.4883353033531166

Epoch: 6| Step: 1
Training loss: 2.625572596269711
Validation loss: 2.4764428345806584

Epoch: 6| Step: 2
Training loss: 3.123448558976717
Validation loss: 2.473975726046517

Epoch: 6| Step: 3
Training loss: 2.844722371960954
Validation loss: 2.483321153333247

Epoch: 6| Step: 4
Training loss: 2.4872706590293525
Validation loss: 2.4751330571824144

Epoch: 6| Step: 5
Training loss: 2.861117139725573
Validation loss: 2.4762943322289868

Epoch: 6| Step: 6
Training loss: 2.303335847351793
Validation loss: 2.467307819455657

Epoch: 6| Step: 7
Training loss: 3.1504605516689255
Validation loss: 2.4730190522920386

Epoch: 6| Step: 8
Training loss: 3.1226378096016214
Validation loss: 2.487182153966093

Epoch: 6| Step: 9
Training loss: 3.585929255590332
Validation loss: 2.4653795370263936

Epoch: 6| Step: 10
Training loss: 2.7174252318876517
Validation loss: 2.4683277801799957

Epoch: 6| Step: 11
Training loss: 2.076375813125838
Validation loss: 2.4725316519494513

Epoch: 6| Step: 12
Training loss: 2.4383693025256177
Validation loss: 2.4872867812542148

Epoch: 6| Step: 13
Training loss: 2.0757892072968014
Validation loss: 2.4743322840879958

Epoch: 48| Step: 0
Training loss: 3.4429650992453555
Validation loss: 2.4910690200239802

Epoch: 6| Step: 1
Training loss: 2.765315755160435
Validation loss: 2.4746395860032457

Epoch: 6| Step: 2
Training loss: 2.825821249090523
Validation loss: 2.4647271217597018

Epoch: 6| Step: 3
Training loss: 2.579692387244102
Validation loss: 2.497811129587122

Epoch: 6| Step: 4
Training loss: 2.9702690655112716
Validation loss: 2.481781096913301

Epoch: 6| Step: 5
Training loss: 2.4328030056238346
Validation loss: 2.4719014549807654

Epoch: 6| Step: 6
Training loss: 2.9728395904265867
Validation loss: 2.4792635681484354

Epoch: 6| Step: 7
Training loss: 2.6175686231360147
Validation loss: 2.493388112013542

Epoch: 6| Step: 8
Training loss: 2.5605820712326457
Validation loss: 2.4754634670173106

Epoch: 6| Step: 9
Training loss: 2.7913962465710767
Validation loss: 2.4801038237690256

Epoch: 6| Step: 10
Training loss: 2.935813257208498
Validation loss: 2.4824418827891743

Epoch: 6| Step: 11
Training loss: 2.8712515236199088
Validation loss: 2.4866619325048025

Epoch: 6| Step: 12
Training loss: 2.1431989578831194
Validation loss: 2.4834807072304015

Epoch: 6| Step: 13
Training loss: 2.6295163493862237
Validation loss: 2.4681181191809163

Epoch: 49| Step: 0
Training loss: 2.795167113820451
Validation loss: 2.4817479136238396

Epoch: 6| Step: 1
Training loss: 2.522304599479157
Validation loss: 2.4976605913770626

Epoch: 6| Step: 2
Training loss: 2.4005376213636045
Validation loss: 2.4871511367143344

Epoch: 6| Step: 3
Training loss: 3.0808214489273635
Validation loss: 2.477648249285531

Epoch: 6| Step: 4
Training loss: 3.3988523734283995
Validation loss: 2.486504524671038

Epoch: 6| Step: 5
Training loss: 2.182084054714295
Validation loss: 2.485250755035479

Epoch: 6| Step: 6
Training loss: 2.5615948264630295
Validation loss: 2.486226510568038

Epoch: 6| Step: 7
Training loss: 2.6381601420476946
Validation loss: 2.479070501478005

Epoch: 6| Step: 8
Training loss: 2.5253519171796683
Validation loss: 2.472499732363576

Epoch: 6| Step: 9
Training loss: 3.2054490009083465
Validation loss: 2.483155828330077

Epoch: 6| Step: 10
Training loss: 3.2194196874723358
Validation loss: 2.4851048313932407

Epoch: 6| Step: 11
Training loss: 2.3548841367757225
Validation loss: 2.4773039316929077

Epoch: 6| Step: 12
Training loss: 2.434844698173506
Validation loss: 2.478496972583582

Epoch: 6| Step: 13
Training loss: 3.2361815194332335
Validation loss: 2.4782593444625602

Epoch: 50| Step: 0
Training loss: 2.8660736830956726
Validation loss: 2.479497020120451

Epoch: 6| Step: 1
Training loss: 2.875153247231938
Validation loss: 2.482574360357351

Epoch: 6| Step: 2
Training loss: 2.1815792064849444
Validation loss: 2.477255000346311

Epoch: 6| Step: 3
Training loss: 2.9947497201829143
Validation loss: 2.4626387531689007

Epoch: 6| Step: 4
Training loss: 2.733956790004966
Validation loss: 2.476837717425126

Epoch: 6| Step: 5
Training loss: 2.7994482893312913
Validation loss: 2.4830687283707

Epoch: 6| Step: 6
Training loss: 3.097031519501874
Validation loss: 2.4745193303061788

Epoch: 6| Step: 7
Training loss: 3.052190125629182
Validation loss: 2.47143354888872

Epoch: 6| Step: 8
Training loss: 2.2658489248177287
Validation loss: 2.476397038497062

Epoch: 6| Step: 9
Training loss: 3.3224728725408026
Validation loss: 2.4850837468938085

Epoch: 6| Step: 10
Training loss: 2.913467796533957
Validation loss: 2.4859595987508922

Epoch: 6| Step: 11
Training loss: 2.237089522233534
Validation loss: 2.4806714615315144

Epoch: 6| Step: 12
Training loss: 2.5542895272489514
Validation loss: 2.4760691055945645

Epoch: 6| Step: 13
Training loss: 2.436471868974572
Validation loss: 2.4834952808778596

Epoch: 51| Step: 0
Training loss: 3.268297771731797
Validation loss: 2.472366662080841

Epoch: 6| Step: 1
Training loss: 2.398842246233473
Validation loss: 2.4663639139587623

Epoch: 6| Step: 2
Training loss: 2.982684710299546
Validation loss: 2.4821511901360465

Epoch: 6| Step: 3
Training loss: 2.5054353755182825
Validation loss: 2.477919859540101

Epoch: 6| Step: 4
Training loss: 2.2292848240800858
Validation loss: 2.4673153473157496

Epoch: 6| Step: 5
Training loss: 2.928843465657679
Validation loss: 2.479532688579742

Epoch: 6| Step: 6
Training loss: 2.5765757211654803
Validation loss: 2.482375336180111

Epoch: 6| Step: 7
Training loss: 3.5237471281637376
Validation loss: 2.484328484352894

Epoch: 6| Step: 8
Training loss: 2.40410954778332
Validation loss: 2.4704164836055784

Epoch: 6| Step: 9
Training loss: 2.72461725049265
Validation loss: 2.48011605323994

Epoch: 6| Step: 10
Training loss: 2.4587397374150837
Validation loss: 2.4848752618709606

Epoch: 6| Step: 11
Training loss: 3.2587589197362314
Validation loss: 2.4903032306607664

Epoch: 6| Step: 12
Training loss: 2.414492078169741
Validation loss: 2.474309301345926

Epoch: 6| Step: 13
Training loss: 2.3285235377476274
Validation loss: 2.485966712288784

Epoch: 52| Step: 0
Training loss: 2.098699839335058
Validation loss: 2.4785955537676245

Epoch: 6| Step: 1
Training loss: 2.950210020703571
Validation loss: 2.4862764521654466

Epoch: 6| Step: 2
Training loss: 3.6228227324955364
Validation loss: 2.474120570995944

Epoch: 6| Step: 3
Training loss: 2.2102992346295567
Validation loss: 2.4871603732825265

Epoch: 6| Step: 4
Training loss: 3.5996774634939896
Validation loss: 2.4794309114545396

Epoch: 6| Step: 5
Training loss: 1.7127907527050348
Validation loss: 2.474564376890584

Epoch: 6| Step: 6
Training loss: 2.989370907847104
Validation loss: 2.4831290061134985

Epoch: 6| Step: 7
Training loss: 2.2708038071512275
Validation loss: 2.478256121107655

Epoch: 6| Step: 8
Training loss: 3.4452958917541876
Validation loss: 2.4664223745657416

Epoch: 6| Step: 9
Training loss: 2.0250098993506827
Validation loss: 2.480130669399423

Epoch: 6| Step: 10
Training loss: 2.030478815257072
Validation loss: 2.4799793745421037

Epoch: 6| Step: 11
Training loss: 2.7669383233533953
Validation loss: 2.491221541056886

Epoch: 6| Step: 12
Training loss: 3.2735629182883708
Validation loss: 2.473866188565566

Epoch: 6| Step: 13
Training loss: 2.627993738477613
Validation loss: 2.4762283006020787

Epoch: 53| Step: 0
Training loss: 3.2658498586236733
Validation loss: 2.4712329381233764

Epoch: 6| Step: 1
Training loss: 2.4161092729235727
Validation loss: 2.4829925056563042

Epoch: 6| Step: 2
Training loss: 2.6319082274974464
Validation loss: 2.475640813776681

Epoch: 6| Step: 3
Training loss: 3.1759007655478504
Validation loss: 2.483876423962272

Epoch: 6| Step: 4
Training loss: 2.611928820798337
Validation loss: 2.4813473290880665

Epoch: 6| Step: 5
Training loss: 2.5546408366103344
Validation loss: 2.4771585111866012

Epoch: 6| Step: 6
Training loss: 1.8809270004838816
Validation loss: 2.4759240733275956

Epoch: 6| Step: 7
Training loss: 3.252137288328811
Validation loss: 2.4812052937960605

Epoch: 6| Step: 8
Training loss: 3.169156868901347
Validation loss: 2.4839514223382957

Epoch: 6| Step: 9
Training loss: 2.639866466034995
Validation loss: 2.473787073879611

Epoch: 6| Step: 10
Training loss: 2.423649095045132
Validation loss: 2.470995163388539

Epoch: 6| Step: 11
Training loss: 2.71422217409435
Validation loss: 2.4866112032503067

Epoch: 6| Step: 12
Training loss: 2.3814623400112986
Validation loss: 2.4810388410069764

Epoch: 6| Step: 13
Training loss: 3.266661703015144
Validation loss: 2.4691003852197033

Epoch: 54| Step: 0
Training loss: 2.193683603700249
Validation loss: 2.4828698429444698

Epoch: 6| Step: 1
Training loss: 2.5172461741432866
Validation loss: 2.4838749268822133

Epoch: 6| Step: 2
Training loss: 2.731732819434826
Validation loss: 2.4666500971364265

Epoch: 6| Step: 3
Training loss: 2.3340526107964705
Validation loss: 2.4772642500106445

Epoch: 6| Step: 4
Training loss: 2.5990294992696277
Validation loss: 2.474367516210908

Epoch: 6| Step: 5
Training loss: 2.927605379913428
Validation loss: 2.476329447404532

Epoch: 6| Step: 6
Training loss: 3.3483236531152034
Validation loss: 2.488056039955963

Epoch: 6| Step: 7
Training loss: 2.7300689797542312
Validation loss: 2.4901032490382233

Epoch: 6| Step: 8
Training loss: 3.0204066183440794
Validation loss: 2.477733440443323

Epoch: 6| Step: 9
Training loss: 2.4865063815407984
Validation loss: 2.4869740262800137

Epoch: 6| Step: 10
Training loss: 2.792912836115359
Validation loss: 2.4688308679729887

Epoch: 6| Step: 11
Training loss: 3.1346740519140366
Validation loss: 2.479073208786053

Epoch: 6| Step: 12
Training loss: 2.9482619192367197
Validation loss: 2.4723087194803597

Epoch: 6| Step: 13
Training loss: 2.278869955030813
Validation loss: 2.477553257199097

Epoch: 55| Step: 0
Training loss: 3.446448867478318
Validation loss: 2.4693522790181666

Epoch: 6| Step: 1
Training loss: 2.8111190796623156
Validation loss: 2.4692210294182284

Epoch: 6| Step: 2
Training loss: 3.1958055185817638
Validation loss: 2.4785583679107464

Epoch: 6| Step: 3
Training loss: 2.6829538262567403
Validation loss: 2.48183081755974

Epoch: 6| Step: 4
Training loss: 2.7084807331371037
Validation loss: 2.4711345062064796

Epoch: 6| Step: 5
Training loss: 2.930775514114949
Validation loss: 2.468395792903224

Epoch: 6| Step: 6
Training loss: 2.4916388885412575
Validation loss: 2.4790372089997295

Epoch: 6| Step: 7
Training loss: 2.7813464373038785
Validation loss: 2.4839979491745603

Epoch: 6| Step: 8
Training loss: 3.0054533983576768
Validation loss: 2.4738665719925135

Epoch: 6| Step: 9
Training loss: 2.655422755059382
Validation loss: 2.4885402658028886

Epoch: 6| Step: 10
Training loss: 1.5981914491232072
Validation loss: 2.4831994607880348

Epoch: 6| Step: 11
Training loss: 2.6268776127622773
Validation loss: 2.4773784739988627

Epoch: 6| Step: 12
Training loss: 2.2064758141992495
Validation loss: 2.4853888674562854

Epoch: 6| Step: 13
Training loss: 2.863420636582127
Validation loss: 2.4739782762398295

Epoch: 56| Step: 0
Training loss: 2.688896969405644
Validation loss: 2.467558168489327

Epoch: 6| Step: 1
Training loss: 3.0937848329991384
Validation loss: 2.4632028804944253

Epoch: 6| Step: 2
Training loss: 2.799542737135538
Validation loss: 2.4774682595584734

Epoch: 6| Step: 3
Training loss: 3.5268275832714058
Validation loss: 2.4794381491872683

Epoch: 6| Step: 4
Training loss: 2.6829903491995095
Validation loss: 2.4766553651300125

Epoch: 6| Step: 5
Training loss: 2.585055566777085
Validation loss: 2.4664267619397817

Epoch: 6| Step: 6
Training loss: 2.9640203445807147
Validation loss: 2.4632017158666266

Epoch: 6| Step: 7
Training loss: 2.8840288113597996
Validation loss: 2.4762567815576846

Epoch: 6| Step: 8
Training loss: 3.023237828011829
Validation loss: 2.4710671664413173

Epoch: 6| Step: 9
Training loss: 2.337648715424033
Validation loss: 2.486701314221197

Epoch: 6| Step: 10
Training loss: 1.9327361083295664
Validation loss: 2.4789480180319776

Epoch: 6| Step: 11
Training loss: 2.3321777502206533
Validation loss: 2.497177266556057

Epoch: 6| Step: 12
Training loss: 2.8575069808540947
Validation loss: 2.469178084380712

Epoch: 6| Step: 13
Training loss: 2.1328491654929893
Validation loss: 2.4792327211976035

Epoch: 57| Step: 0
Training loss: 2.263300051362514
Validation loss: 2.471161187326256

Epoch: 6| Step: 1
Training loss: 3.1330618057559163
Validation loss: 2.4859385117042354

Epoch: 6| Step: 2
Training loss: 2.689954302374809
Validation loss: 2.482858234168791

Epoch: 6| Step: 3
Training loss: 3.408593028153932
Validation loss: 2.4715981057645697

Epoch: 6| Step: 4
Training loss: 2.3985695072589293
Validation loss: 2.474634646515969

Epoch: 6| Step: 5
Training loss: 2.782984589145112
Validation loss: 2.4892487845421685

Epoch: 6| Step: 6
Training loss: 2.4909383579071296
Validation loss: 2.4907021854134825

Epoch: 6| Step: 7
Training loss: 2.0199852438661554
Validation loss: 2.47891122579703

Epoch: 6| Step: 8
Training loss: 2.2466456523029437
Validation loss: 2.475638381277274

Epoch: 6| Step: 9
Training loss: 2.70358872157043
Validation loss: 2.4785441448349523

Epoch: 6| Step: 10
Training loss: 2.4522747339974362
Validation loss: 2.476201581420143

Epoch: 6| Step: 11
Training loss: 2.7721689681206807
Validation loss: 2.4797660542204327

Epoch: 6| Step: 12
Training loss: 3.7551056754814773
Validation loss: 2.4735613816109154

Epoch: 6| Step: 13
Training loss: 2.5616897604634965
Validation loss: 2.471348674277966

Epoch: 58| Step: 0
Training loss: 3.030034558945782
Validation loss: 2.4719078041771634

Epoch: 6| Step: 1
Training loss: 2.4936792578737754
Validation loss: 2.4694112035306297

Epoch: 6| Step: 2
Training loss: 3.320189278503979
Validation loss: 2.4758703651046807

Epoch: 6| Step: 3
Training loss: 2.5535460555638587
Validation loss: 2.4850843421334945

Epoch: 6| Step: 4
Training loss: 3.3689249251604267
Validation loss: 2.483332305715838

Epoch: 6| Step: 5
Training loss: 2.594548481668914
Validation loss: 2.473561901892107

Epoch: 6| Step: 6
Training loss: 2.8041405954797503
Validation loss: 2.473081148567937

Epoch: 6| Step: 7
Training loss: 2.6875541149280147
Validation loss: 2.4849990718220254

Epoch: 6| Step: 8
Training loss: 2.822828528423026
Validation loss: 2.482179056770435

Epoch: 6| Step: 9
Training loss: 2.7424916155816494
Validation loss: 2.470744283763689

Epoch: 6| Step: 10
Training loss: 1.9473172929924394
Validation loss: 2.48103527717607

Epoch: 6| Step: 11
Training loss: 2.7067207719847826
Validation loss: 2.483013991476613

Epoch: 6| Step: 12
Training loss: 2.4219969687974454
Validation loss: 2.476285687684438

Epoch: 6| Step: 13
Training loss: 2.590774023833808
Validation loss: 2.49261956396727

Epoch: 59| Step: 0
Training loss: 2.339654217464582
Validation loss: 2.483749316019449

Epoch: 6| Step: 1
Training loss: 3.2356573686312546
Validation loss: 2.46864583013869

Epoch: 6| Step: 2
Training loss: 2.237385995187505
Validation loss: 2.4790728892452645

Epoch: 6| Step: 3
Training loss: 3.458962042470961
Validation loss: 2.466194016615612

Epoch: 6| Step: 4
Training loss: 1.8134472443527374
Validation loss: 2.4822482009453237

Epoch: 6| Step: 5
Training loss: 2.943526558788781
Validation loss: 2.470973850592928

Epoch: 6| Step: 6
Training loss: 2.393531179760123
Validation loss: 2.484011932547298

Epoch: 6| Step: 7
Training loss: 3.07990132310017
Validation loss: 2.4736242954578156

Epoch: 6| Step: 8
Training loss: 2.9474672080457287
Validation loss: 2.479979192604797

Epoch: 6| Step: 9
Training loss: 2.6579744014956854
Validation loss: 2.462700812417588

Epoch: 6| Step: 10
Training loss: 2.5386814242275975
Validation loss: 2.477509914375169

Epoch: 6| Step: 11
Training loss: 3.2751850570926715
Validation loss: 2.474804951094119

Epoch: 6| Step: 12
Training loss: 2.1768740198974856
Validation loss: 2.4690936280233635

Epoch: 6| Step: 13
Training loss: 2.8992111119606845
Validation loss: 2.4838803181207902

Epoch: 60| Step: 0
Training loss: 2.686106830827138
Validation loss: 2.4677491740550135

Epoch: 6| Step: 1
Training loss: 2.197704925703222
Validation loss: 2.4773194482013245

Epoch: 6| Step: 2
Training loss: 2.7858393662007295
Validation loss: 2.4824275404820115

Epoch: 6| Step: 3
Training loss: 2.8702236803461374
Validation loss: 2.4792872618700628

Epoch: 6| Step: 4
Training loss: 2.271754110234143
Validation loss: 2.4667589313653173

Epoch: 6| Step: 5
Training loss: 2.788381113971935
Validation loss: 2.467582825488297

Epoch: 6| Step: 6
Training loss: 2.9076018112082513
Validation loss: 2.477618871702791

Epoch: 6| Step: 7
Training loss: 2.5644302541463957
Validation loss: 2.471107559731184

Epoch: 6| Step: 8
Training loss: 3.23866378310185
Validation loss: 2.472098035006457

Epoch: 6| Step: 9
Training loss: 3.063066079896817
Validation loss: 2.4793906785810815

Epoch: 6| Step: 10
Training loss: 2.580108342076791
Validation loss: 2.4698159505001014

Epoch: 6| Step: 11
Training loss: 2.951458657630602
Validation loss: 2.486383546772624

Epoch: 6| Step: 12
Training loss: 2.845779030441418
Validation loss: 2.478873672882235

Epoch: 6| Step: 13
Training loss: 2.105284277596698
Validation loss: 2.4864186720567942

Epoch: 61| Step: 0
Training loss: 2.896635991743621
Validation loss: 2.478262397646115

Epoch: 6| Step: 1
Training loss: 2.521515956122424
Validation loss: 2.4672448245493217

Epoch: 6| Step: 2
Training loss: 3.51956769477697
Validation loss: 2.481486141223451

Epoch: 6| Step: 3
Training loss: 2.5906215322584036
Validation loss: 2.4843007801083314

Epoch: 6| Step: 4
Training loss: 3.3836189700666246
Validation loss: 2.4701759620022337

Epoch: 6| Step: 5
Training loss: 1.7553439290752768
Validation loss: 2.4677493620882798

Epoch: 6| Step: 6
Training loss: 3.2577419502065754
Validation loss: 2.4826648316014035

Epoch: 6| Step: 7
Training loss: 2.5095098817900197
Validation loss: 2.475980772705134

Epoch: 6| Step: 8
Training loss: 2.429824874281629
Validation loss: 2.4768642413684203

Epoch: 6| Step: 9
Training loss: 2.506335147162798
Validation loss: 2.479657217087767

Epoch: 6| Step: 10
Training loss: 2.6527947785352577
Validation loss: 2.4736731100034866

Epoch: 6| Step: 11
Training loss: 2.8893693825949547
Validation loss: 2.485860219528591

Epoch: 6| Step: 12
Training loss: 2.4134107777865803
Validation loss: 2.486652344074068

Epoch: 6| Step: 13
Training loss: 2.269554676453696
Validation loss: 2.465214370065395

Epoch: 62| Step: 0
Training loss: 2.8949312044445543
Validation loss: 2.488905046901806

Epoch: 6| Step: 1
Training loss: 2.317800992906532
Validation loss: 2.475378649283489

Epoch: 6| Step: 2
Training loss: 2.684220997275212
Validation loss: 2.473321685132835

Epoch: 6| Step: 3
Training loss: 2.772960439136372
Validation loss: 2.481090275744184

Epoch: 6| Step: 4
Training loss: 2.774404179986139
Validation loss: 2.4781172087340675

Epoch: 6| Step: 5
Training loss: 2.343944490628241
Validation loss: 2.474622933841672

Epoch: 6| Step: 6
Training loss: 2.29546723074717
Validation loss: 2.47299422557762

Epoch: 6| Step: 7
Training loss: 2.6873135169334925
Validation loss: 2.4750766004382423

Epoch: 6| Step: 8
Training loss: 2.464793644560557
Validation loss: 2.47578012086271

Epoch: 6| Step: 9
Training loss: 3.2117776258932493
Validation loss: 2.485323047544873

Epoch: 6| Step: 10
Training loss: 2.660038658377449
Validation loss: 2.4747848603269245

Epoch: 6| Step: 11
Training loss: 3.2691549542642107
Validation loss: 2.486148850288268

Epoch: 6| Step: 12
Training loss: 2.9282654426302344
Validation loss: 2.4761413566022603

Epoch: 6| Step: 13
Training loss: 2.996857905015926
Validation loss: 2.476671413093077

Epoch: 63| Step: 0
Training loss: 2.2827517648250786
Validation loss: 2.471579445744956

Epoch: 6| Step: 1
Training loss: 3.19740730395851
Validation loss: 2.475249533795399

Epoch: 6| Step: 2
Training loss: 2.7223712000228977
Validation loss: 2.4699493709804203

Epoch: 6| Step: 3
Training loss: 2.785767304960426
Validation loss: 2.4871932725444728

Epoch: 6| Step: 4
Training loss: 2.7647234638022713
Validation loss: 2.4769190251534736

Epoch: 6| Step: 5
Training loss: 2.947782982984078
Validation loss: 2.4727098118674267

Epoch: 6| Step: 6
Training loss: 2.566267546878514
Validation loss: 2.473278302358634

Epoch: 6| Step: 7
Training loss: 2.420041380757035
Validation loss: 2.4826781182421813

Epoch: 6| Step: 8
Training loss: 2.625867791013818
Validation loss: 2.482873606517925

Epoch: 6| Step: 9
Training loss: 2.4312946854826647
Validation loss: 2.4766392373580435

Epoch: 6| Step: 10
Training loss: 3.0259255120487967
Validation loss: 2.468808627363814

Epoch: 6| Step: 11
Training loss: 3.2499097664851266
Validation loss: 2.4825819591310463

Epoch: 6| Step: 12
Training loss: 2.7327260304157845
Validation loss: 2.464086015658414

Epoch: 6| Step: 13
Training loss: 1.8169847449091094
Validation loss: 2.470913168941941

Epoch: 64| Step: 0
Training loss: 3.4576794722419937
Validation loss: 2.4753004363459086

Epoch: 6| Step: 1
Training loss: 2.459626541942918
Validation loss: 2.469638645314496

Epoch: 6| Step: 2
Training loss: 2.5217489255946544
Validation loss: 2.4912981613222134

Epoch: 6| Step: 3
Training loss: 2.8823999456028186
Validation loss: 2.479263595033296

Epoch: 6| Step: 4
Training loss: 2.8698051623092287
Validation loss: 2.463865146048644

Epoch: 6| Step: 5
Training loss: 1.8582807895547888
Validation loss: 2.478559722879166

Epoch: 6| Step: 6
Training loss: 3.064105800106786
Validation loss: 2.4584034926586447

Epoch: 6| Step: 7
Training loss: 2.7106657304225843
Validation loss: 2.4878522885959176

Epoch: 6| Step: 8
Training loss: 2.4125024390331844
Validation loss: 2.48004182786894

Epoch: 6| Step: 9
Training loss: 2.195780422531121
Validation loss: 2.4794982205195777

Epoch: 6| Step: 10
Training loss: 2.6122949218567464
Validation loss: 2.4861085394870095

Epoch: 6| Step: 11
Training loss: 3.1006269989899193
Validation loss: 2.456500727236753

Epoch: 6| Step: 12
Training loss: 3.2702889606997436
Validation loss: 2.4673268598579154

Epoch: 6| Step: 13
Training loss: 2.153827578076756
Validation loss: 2.4662319793366283

Epoch: 65| Step: 0
Training loss: 2.9291220157380016
Validation loss: 2.4789467801364733

Epoch: 6| Step: 1
Training loss: 2.4414737295361957
Validation loss: 2.4817507244098103

Epoch: 6| Step: 2
Training loss: 2.3993806755155793
Validation loss: 2.4708702896288055

Epoch: 6| Step: 3
Training loss: 1.6448032036494067
Validation loss: 2.468913888949641

Epoch: 6| Step: 4
Training loss: 3.2929486220933635
Validation loss: 2.4701192601509545

Epoch: 6| Step: 5
Training loss: 2.594842611696108
Validation loss: 2.48267025076681

Epoch: 6| Step: 6
Training loss: 3.2033861007340305
Validation loss: 2.461450251277079

Epoch: 6| Step: 7
Training loss: 2.525366078646175
Validation loss: 2.4630701952470058

Epoch: 6| Step: 8
Training loss: 2.940247407481164
Validation loss: 2.490216658656079

Epoch: 6| Step: 9
Training loss: 2.5172479737095865
Validation loss: 2.47467582691047

Epoch: 6| Step: 10
Training loss: 2.449446136773194
Validation loss: 2.4610230013827117

Epoch: 6| Step: 11
Training loss: 2.7956032019178334
Validation loss: 2.4895064989582676

Epoch: 6| Step: 12
Training loss: 2.8681454422488875
Validation loss: 2.480147239099809

Epoch: 6| Step: 13
Training loss: 3.5111759771989335
Validation loss: 2.48058575531946

Epoch: 66| Step: 0
Training loss: 2.6829453841432653
Validation loss: 2.461130865195807

Epoch: 6| Step: 1
Training loss: 2.8410806389079037
Validation loss: 2.4736561041494722

Epoch: 6| Step: 2
Training loss: 2.6954516388735494
Validation loss: 2.4860502597731764

Epoch: 6| Step: 3
Training loss: 2.247974755847958
Validation loss: 2.4828541360298235

Epoch: 6| Step: 4
Training loss: 2.512973596527525
Validation loss: 2.4765833584040453

Epoch: 6| Step: 5
Training loss: 2.5167643176537675
Validation loss: 2.4860183549529626

Epoch: 6| Step: 6
Training loss: 3.339721249124032
Validation loss: 2.481004683714222

Epoch: 6| Step: 7
Training loss: 2.9073717147065294
Validation loss: 2.4811451449702986

Epoch: 6| Step: 8
Training loss: 2.3453239750692587
Validation loss: 2.4765928134659094

Epoch: 6| Step: 9
Training loss: 2.4838750564124434
Validation loss: 2.4730086889391525

Epoch: 6| Step: 10
Training loss: 2.7773470120739456
Validation loss: 2.483814499519074

Epoch: 6| Step: 11
Training loss: 2.5522083070219095
Validation loss: 2.4741392014885797

Epoch: 6| Step: 12
Training loss: 3.0308746420102985
Validation loss: 2.48132829605373

Epoch: 6| Step: 13
Training loss: 3.1153548357881564
Validation loss: 2.46712299159642

Epoch: 67| Step: 0
Training loss: 2.2360349238061907
Validation loss: 2.480724165697275

Epoch: 6| Step: 1
Training loss: 2.640680075528178
Validation loss: 2.4766858860338328

Epoch: 6| Step: 2
Training loss: 2.9629385836799216
Validation loss: 2.4820148569408578

Epoch: 6| Step: 3
Training loss: 2.313844547658455
Validation loss: 2.4833536884602054

Epoch: 6| Step: 4
Training loss: 2.7941501066371526
Validation loss: 2.48819952124317

Epoch: 6| Step: 5
Training loss: 2.9071509492707293
Validation loss: 2.475639318447401

Epoch: 6| Step: 6
Training loss: 3.415521305670592
Validation loss: 2.4877187369594704

Epoch: 6| Step: 7
Training loss: 2.860628947479678
Validation loss: 2.467740384782404

Epoch: 6| Step: 8
Training loss: 2.5897322640797213
Validation loss: 2.4609734416211526

Epoch: 6| Step: 9
Training loss: 2.797462444309009
Validation loss: 2.4811510303493827

Epoch: 6| Step: 10
Training loss: 2.9424604373369183
Validation loss: 2.4781044707618034

Epoch: 6| Step: 11
Training loss: 2.934493291418532
Validation loss: 2.479006269779103

Epoch: 6| Step: 12
Training loss: 2.2543126207673323
Validation loss: 2.487027857558889

Epoch: 6| Step: 13
Training loss: 1.5574495709676053
Validation loss: 2.4855887982866522

Epoch: 68| Step: 0
Training loss: 2.8013194483498096
Validation loss: 2.4967081773208655

Epoch: 6| Step: 1
Training loss: 3.284413874112086
Validation loss: 2.4748216211949132

Epoch: 6| Step: 2
Training loss: 2.7376918185540324
Validation loss: 2.4847846696625226

Epoch: 6| Step: 3
Training loss: 2.639069951409977
Validation loss: 2.470942613800081

Epoch: 6| Step: 4
Training loss: 2.5736296331301034
Validation loss: 2.479137670385831

Epoch: 6| Step: 5
Training loss: 2.860139504878341
Validation loss: 2.4899840469860766

Epoch: 6| Step: 6
Training loss: 2.9901450733726036
Validation loss: 2.467432002833014

Epoch: 6| Step: 7
Training loss: 2.778251145613115
Validation loss: 2.4784586153766233

Epoch: 6| Step: 8
Training loss: 3.046949493280059
Validation loss: 2.4819154871001854

Epoch: 6| Step: 9
Training loss: 2.2302342172967986
Validation loss: 2.478652663670184

Epoch: 6| Step: 10
Training loss: 2.4445559760379614
Validation loss: 2.4828179298294577

Epoch: 6| Step: 11
Training loss: 2.289744929638224
Validation loss: 2.4764205060159212

Epoch: 6| Step: 12
Training loss: 2.900107506699543
Validation loss: 2.4686535128057128

Epoch: 6| Step: 13
Training loss: 1.975725139818224
Validation loss: 2.4817216701708493

Epoch: 69| Step: 0
Training loss: 2.779499746224834
Validation loss: 2.4777568890967796

Epoch: 6| Step: 1
Training loss: 3.116834883476655
Validation loss: 2.4799013036042576

Epoch: 6| Step: 2
Training loss: 3.308402640307783
Validation loss: 2.482487513659656

Epoch: 6| Step: 3
Training loss: 2.734417985850736
Validation loss: 2.4796843384239518

Epoch: 6| Step: 4
Training loss: 2.634646357162025
Validation loss: 2.4632113919398533

Epoch: 6| Step: 5
Training loss: 2.8470490152248473
Validation loss: 2.4702434288050488

Epoch: 6| Step: 6
Training loss: 2.7144220038307183
Validation loss: 2.493868332726455

Epoch: 6| Step: 7
Training loss: 2.1771701509483403
Validation loss: 2.462808193136802

Epoch: 6| Step: 8
Training loss: 2.8381275306527405
Validation loss: 2.4822554252994973

Epoch: 6| Step: 9
Training loss: 2.4136919150729805
Validation loss: 2.4779354208172637

Epoch: 6| Step: 10
Training loss: 2.8203302525519014
Validation loss: 2.476512008477846

Epoch: 6| Step: 11
Training loss: 2.4161784457186055
Validation loss: 2.4727186954473845

Epoch: 6| Step: 12
Training loss: 2.5006851211181487
Validation loss: 2.4763195720558344

Epoch: 6| Step: 13
Training loss: 2.449653647717247
Validation loss: 2.4801708360020083

Epoch: 70| Step: 0
Training loss: 3.166765278401797
Validation loss: 2.4701994751311354

Epoch: 6| Step: 1
Training loss: 3.0441713515387563
Validation loss: 2.472223189991572

Epoch: 6| Step: 2
Training loss: 2.0060771166506086
Validation loss: 2.488705936682387

Epoch: 6| Step: 3
Training loss: 2.3841752954847113
Validation loss: 2.4870919892930208

Epoch: 6| Step: 4
Training loss: 3.0563981907651847
Validation loss: 2.4684504551418875

Epoch: 6| Step: 5
Training loss: 2.2051335911494507
Validation loss: 2.482510191433826

Epoch: 6| Step: 6
Training loss: 2.459750612845249
Validation loss: 2.484812931059457

Epoch: 6| Step: 7
Training loss: 2.9391408355186357
Validation loss: 2.480083126252193

Epoch: 6| Step: 8
Training loss: 3.0634267533606163
Validation loss: 2.466417927937038

Epoch: 6| Step: 9
Training loss: 3.1319414483220744
Validation loss: 2.475292962805129

Epoch: 6| Step: 10
Training loss: 2.4757084381673438
Validation loss: 2.4739642879671324

Epoch: 6| Step: 11
Training loss: 2.5059536613631086
Validation loss: 2.473670320612021

Epoch: 6| Step: 12
Training loss: 1.919818801674316
Validation loss: 2.4792865670063513

Epoch: 6| Step: 13
Training loss: 3.385687401534318
Validation loss: 2.469153606319938

Epoch: 71| Step: 0
Training loss: 2.2064815410548135
Validation loss: 2.464666384605147

Epoch: 6| Step: 1
Training loss: 1.365882817772889
Validation loss: 2.4778817323943922

Epoch: 6| Step: 2
Training loss: 3.208534696791153
Validation loss: 2.484130934066511

Epoch: 6| Step: 3
Training loss: 2.635916038113762
Validation loss: 2.4726834076908584

Epoch: 6| Step: 4
Training loss: 3.1519654152129797
Validation loss: 2.4840475526895913

Epoch: 6| Step: 5
Training loss: 3.3689385129594696
Validation loss: 2.4756562485458704

Epoch: 6| Step: 6
Training loss: 2.692566907896128
Validation loss: 2.475819151204692

Epoch: 6| Step: 7
Training loss: 3.326300035607113
Validation loss: 2.459088316111656

Epoch: 6| Step: 8
Training loss: 2.692343140463068
Validation loss: 2.470578771916145

Epoch: 6| Step: 9
Training loss: 2.729607311134341
Validation loss: 2.485448615490423

Epoch: 6| Step: 10
Training loss: 1.5836283592955105
Validation loss: 2.4746626723813168

Epoch: 6| Step: 11
Training loss: 2.613051514156812
Validation loss: 2.481597573771998

Epoch: 6| Step: 12
Training loss: 2.9680162024865457
Validation loss: 2.475701322077462

Epoch: 6| Step: 13
Training loss: 2.673656026179449
Validation loss: 2.4765263757270457

Epoch: 72| Step: 0
Training loss: 2.4207964064319913
Validation loss: 2.4776454731643924

Epoch: 6| Step: 1
Training loss: 3.040804562260498
Validation loss: 2.459596726055318

Epoch: 6| Step: 2
Training loss: 3.093206030292422
Validation loss: 2.4726353522472264

Epoch: 6| Step: 3
Training loss: 2.786209998547464
Validation loss: 2.4883927388410823

Epoch: 6| Step: 4
Training loss: 2.738425344901407
Validation loss: 2.4712747525023855

Epoch: 6| Step: 5
Training loss: 2.4337743995199697
Validation loss: 2.472896427211635

Epoch: 6| Step: 6
Training loss: 3.063392353450932
Validation loss: 2.460010067982267

Epoch: 6| Step: 7
Training loss: 2.559241479318216
Validation loss: 2.4613626509041966

Epoch: 6| Step: 8
Training loss: 2.685687318770847
Validation loss: 2.4741704720095634

Epoch: 6| Step: 9
Training loss: 2.9411111914178294
Validation loss: 2.482051795800249

Epoch: 6| Step: 10
Training loss: 2.3752945165225654
Validation loss: 2.4833893820474735

Epoch: 6| Step: 11
Training loss: 2.5435464088640902
Validation loss: 2.463626719531998

Epoch: 6| Step: 12
Training loss: 2.6302015449260066
Validation loss: 2.479058891456913

Epoch: 6| Step: 13
Training loss: 2.166821975521361
Validation loss: 2.4815407506571474

Epoch: 73| Step: 0
Training loss: 2.588648639722615
Validation loss: 2.4689829757833093

Epoch: 6| Step: 1
Training loss: 3.043760302015099
Validation loss: 2.4816990151487017

Epoch: 6| Step: 2
Training loss: 2.0363030598040135
Validation loss: 2.4883568924277077

Epoch: 6| Step: 3
Training loss: 2.4207367221728537
Validation loss: 2.486300025438768

Epoch: 6| Step: 4
Training loss: 2.3751231713730374
Validation loss: 2.4767701197273966

Epoch: 6| Step: 5
Training loss: 2.306026263872376
Validation loss: 2.492926505867889

Epoch: 6| Step: 6
Training loss: 3.3396958346266006
Validation loss: 2.4871816035503347

Epoch: 6| Step: 7
Training loss: 2.9546982545621634
Validation loss: 2.4829257538806755

Epoch: 6| Step: 8
Training loss: 2.809600182866067
Validation loss: 2.4832399323743113

Epoch: 6| Step: 9
Training loss: 3.2902554412279716
Validation loss: 2.482873781015431

Epoch: 6| Step: 10
Training loss: 2.4774049114375396
Validation loss: 2.461545847080248

Epoch: 6| Step: 11
Training loss: 2.2770979210426154
Validation loss: 2.4668663318522612

Epoch: 6| Step: 12
Training loss: 2.7847818815880787
Validation loss: 2.4683690574846904

Epoch: 6| Step: 13
Training loss: 2.6940108984972433
Validation loss: 2.4609625681433585

Epoch: 74| Step: 0
Training loss: 2.388633946065386
Validation loss: 2.4713589491566066

Epoch: 6| Step: 1
Training loss: 3.47753714283154
Validation loss: 2.475996578098224

Epoch: 6| Step: 2
Training loss: 2.243772896567487
Validation loss: 2.4868700486834334

Epoch: 6| Step: 3
Training loss: 2.449325145497322
Validation loss: 2.478793253549862

Epoch: 6| Step: 4
Training loss: 2.7722884255834606
Validation loss: 2.475716109272758

Epoch: 6| Step: 5
Training loss: 2.89349288951685
Validation loss: 2.458141849903179

Epoch: 6| Step: 6
Training loss: 2.763459473121059
Validation loss: 2.467025473308452

Epoch: 6| Step: 7
Training loss: 2.412402325960536
Validation loss: 2.496908158707378

Epoch: 6| Step: 8
Training loss: 3.0415603061700645
Validation loss: 2.466178459215623

Epoch: 6| Step: 9
Training loss: 2.585424643193517
Validation loss: 2.467073422922893

Epoch: 6| Step: 10
Training loss: 2.3870335947204886
Validation loss: 2.4505002440903967

Epoch: 6| Step: 11
Training loss: 2.434050246234923
Validation loss: 2.4831460141992996

Epoch: 6| Step: 12
Training loss: 2.617134207567258
Validation loss: 2.477291522762595

Epoch: 6| Step: 13
Training loss: 3.4863718922322766
Validation loss: 2.467636178534194

Epoch: 75| Step: 0
Training loss: 2.4789655801554034
Validation loss: 2.4654508992570796

Epoch: 6| Step: 1
Training loss: 3.366468454575485
Validation loss: 2.4771025083699705

Epoch: 6| Step: 2
Training loss: 2.605865128090074
Validation loss: 2.492467773387477

Epoch: 6| Step: 3
Training loss: 2.765621724099843
Validation loss: 2.4602919698601045

Epoch: 6| Step: 4
Training loss: 2.036035856504538
Validation loss: 2.4843804515516448

Epoch: 6| Step: 5
Training loss: 2.6673208765382443
Validation loss: 2.4793134463021773

Epoch: 6| Step: 6
Training loss: 2.831191955375614
Validation loss: 2.4731983126610784

Epoch: 6| Step: 7
Training loss: 3.194955521394845
Validation loss: 2.4682284814583904

Epoch: 6| Step: 8
Training loss: 2.719238149732332
Validation loss: 2.474044909859449

Epoch: 6| Step: 9
Training loss: 2.9925994191111114
Validation loss: 2.4861508486937756

Epoch: 6| Step: 10
Training loss: 2.285131522802915
Validation loss: 2.472641313868648

Epoch: 6| Step: 11
Training loss: 2.7983110885993145
Validation loss: 2.467841686769131

Epoch: 6| Step: 12
Training loss: 2.540265640425383
Validation loss: 2.470003723791706

Epoch: 6| Step: 13
Training loss: 1.7298547072946935
Validation loss: 2.470699248464276

Epoch: 76| Step: 0
Training loss: 3.214042851189104
Validation loss: 2.4769708145368754

Epoch: 6| Step: 1
Training loss: 2.9012546061652227
Validation loss: 2.4744771744722205

Epoch: 6| Step: 2
Training loss: 2.8815339517415133
Validation loss: 2.4699321708227115

Epoch: 6| Step: 3
Training loss: 2.5696593965081247
Validation loss: 2.4764163899768183

Epoch: 6| Step: 4
Training loss: 2.6862493754475376
Validation loss: 2.471807714800168

Epoch: 6| Step: 5
Training loss: 2.7241357535258217
Validation loss: 2.480372049948065

Epoch: 6| Step: 6
Training loss: 2.6148096014550606
Validation loss: 2.4737975635113867

Epoch: 6| Step: 7
Training loss: 2.9349662729434267
Validation loss: 2.47572356082594

Epoch: 6| Step: 8
Training loss: 2.678128336633943
Validation loss: 2.47670103998787

Epoch: 6| Step: 9
Training loss: 2.408490611641903
Validation loss: 2.4830488392027408

Epoch: 6| Step: 10
Training loss: 2.653557164161745
Validation loss: 2.4954368076910853

Epoch: 6| Step: 11
Training loss: 2.1966136185410843
Validation loss: 2.476766242854271

Epoch: 6| Step: 12
Training loss: 2.9006594138394144
Validation loss: 2.4630037523622548

Epoch: 6| Step: 13
Training loss: 1.8140516545302547
Validation loss: 2.4762501049719323

Epoch: 77| Step: 0
Training loss: 2.02059041034651
Validation loss: 2.4788567078769783

Epoch: 6| Step: 1
Training loss: 2.5031760068880415
Validation loss: 2.4885039486558314

Epoch: 6| Step: 2
Training loss: 2.5460929371966237
Validation loss: 2.4836231739210186

Epoch: 6| Step: 3
Training loss: 2.5036256249055766
Validation loss: 2.4808270636876637

Epoch: 6| Step: 4
Training loss: 2.3925635761675004
Validation loss: 2.4814130034037127

Epoch: 6| Step: 5
Training loss: 3.119620308391756
Validation loss: 2.4829776564814536

Epoch: 6| Step: 6
Training loss: 2.465002474986724
Validation loss: 2.4897318033013645

Epoch: 6| Step: 7
Training loss: 3.167774876543002
Validation loss: 2.4705497751502294

Epoch: 6| Step: 8
Training loss: 2.3468399024909186
Validation loss: 2.474108723255961

Epoch: 6| Step: 9
Training loss: 3.01284836143863
Validation loss: 2.497804421066046

Epoch: 6| Step: 10
Training loss: 3.0320993393700997
Validation loss: 2.4738696445873942

Epoch: 6| Step: 11
Training loss: 2.888670554428366
Validation loss: 2.4762862912506245

Epoch: 6| Step: 12
Training loss: 2.9617599915108674
Validation loss: 2.4811301132189247

Epoch: 6| Step: 13
Training loss: 2.7355952564598307
Validation loss: 2.4745808274281904

Epoch: 78| Step: 0
Training loss: 2.7193502881543337
Validation loss: 2.4737866686775707

Epoch: 6| Step: 1
Training loss: 1.9773841326270138
Validation loss: 2.487959442112502

Epoch: 6| Step: 2
Training loss: 2.9860584244528114
Validation loss: 2.4732738369598892

Epoch: 6| Step: 3
Training loss: 3.249403238527834
Validation loss: 2.469545017518641

Epoch: 6| Step: 4
Training loss: 3.0507531158673933
Validation loss: 2.485809683784721

Epoch: 6| Step: 5
Training loss: 3.6301024470309295
Validation loss: 2.4770434159687373

Epoch: 6| Step: 6
Training loss: 2.861873014990474
Validation loss: 2.474563366793553

Epoch: 6| Step: 7
Training loss: 2.1997301716492332
Validation loss: 2.4720857803887

Epoch: 6| Step: 8
Training loss: 1.7761057136450185
Validation loss: 2.4773373871673896

Epoch: 6| Step: 9
Training loss: 2.592314357309278
Validation loss: 2.465834610007256

Epoch: 6| Step: 10
Training loss: 2.3925619817695187
Validation loss: 2.4626464014845446

Epoch: 6| Step: 11
Training loss: 2.5572806446798713
Validation loss: 2.4699447210386065

Epoch: 6| Step: 12
Training loss: 2.188390060274494
Validation loss: 2.478300533934827

Epoch: 6| Step: 13
Training loss: 3.1858140563248587
Validation loss: 2.464847198910869

Epoch: 79| Step: 0
Training loss: 3.534293424573903
Validation loss: 2.469097241277548

Epoch: 6| Step: 1
Training loss: 3.182498223842895
Validation loss: 2.4894196654785627

Epoch: 6| Step: 2
Training loss: 2.87349462488673
Validation loss: 2.494416018083933

Epoch: 6| Step: 3
Training loss: 1.8390168034427328
Validation loss: 2.4750605499030423

Epoch: 6| Step: 4
Training loss: 2.349531443533027
Validation loss: 2.485624322087564

Epoch: 6| Step: 5
Training loss: 2.5443181033837052
Validation loss: 2.4852491396401186

Epoch: 6| Step: 6
Training loss: 2.4394505839033003
Validation loss: 2.4732065492244244

Epoch: 6| Step: 7
Training loss: 2.8014723006374727
Validation loss: 2.4846014155831693

Epoch: 6| Step: 8
Training loss: 2.905426400910193
Validation loss: 2.4848317661377344

Epoch: 6| Step: 9
Training loss: 2.3517301886198423
Validation loss: 2.4847988149743507

Epoch: 6| Step: 10
Training loss: 2.7937719083946804
Validation loss: 2.4746493737836404

Epoch: 6| Step: 11
Training loss: 2.5213480232183363
Validation loss: 2.489810725381575

Epoch: 6| Step: 12
Training loss: 2.419688954816615
Validation loss: 2.5013145487506336

Epoch: 6| Step: 13
Training loss: 3.141539786801317
Validation loss: 2.476441969144188

Epoch: 80| Step: 0
Training loss: 2.322559437560946
Validation loss: 2.4857531828187334

Epoch: 6| Step: 1
Training loss: 1.570856635867777
Validation loss: 2.4852639659592817

Epoch: 6| Step: 2
Training loss: 2.8531593345757194
Validation loss: 2.4725050867123484

Epoch: 6| Step: 3
Training loss: 2.8330212776524197
Validation loss: 2.486997557893509

Epoch: 6| Step: 4
Training loss: 3.2088225516010658
Validation loss: 2.4821624138761273

Epoch: 6| Step: 5
Training loss: 3.5815967225537566
Validation loss: 2.486189884305013

Epoch: 6| Step: 6
Training loss: 1.923273771554885
Validation loss: 2.4667781713864607

Epoch: 6| Step: 7
Training loss: 2.835025693316146
Validation loss: 2.4739187568819303

Epoch: 6| Step: 8
Training loss: 2.87049811795626
Validation loss: 2.495028051436113

Epoch: 6| Step: 9
Training loss: 2.604860065970407
Validation loss: 2.474372716286784

Epoch: 6| Step: 10
Training loss: 2.613730171088263
Validation loss: 2.4584705703107326

Epoch: 6| Step: 11
Training loss: 2.431794752269008
Validation loss: 2.468386682412427

Epoch: 6| Step: 12
Training loss: 2.8142413364753844
Validation loss: 2.4576639957422004

Epoch: 6| Step: 13
Training loss: 2.6094070706709465
Validation loss: 2.486983576876293

Epoch: 81| Step: 0
Training loss: 3.45902049273563
Validation loss: 2.484789172410243

Epoch: 6| Step: 1
Training loss: 2.5122339363992934
Validation loss: 2.491621637988666

Epoch: 6| Step: 2
Training loss: 2.434004992276967
Validation loss: 2.484971864059504

Epoch: 6| Step: 3
Training loss: 2.94918932363217
Validation loss: 2.4815593388722235

Epoch: 6| Step: 4
Training loss: 2.3394629370763407
Validation loss: 2.485280269341095

Epoch: 6| Step: 5
Training loss: 3.0445511783753254
Validation loss: 2.4851557523238834

Epoch: 6| Step: 6
Training loss: 2.1949020490754023
Validation loss: 2.4708443830165185

Epoch: 6| Step: 7
Training loss: 2.350849842048275
Validation loss: 2.4606362122757353

Epoch: 6| Step: 8
Training loss: 3.063114805206538
Validation loss: 2.4758248846047892

Epoch: 6| Step: 9
Training loss: 2.06163145330769
Validation loss: 2.5005437423713617

Epoch: 6| Step: 10
Training loss: 3.084657659594025
Validation loss: 2.4725840319419707

Epoch: 6| Step: 11
Training loss: 3.0160537968297407
Validation loss: 2.4882687010883053

Epoch: 6| Step: 12
Training loss: 2.2055207341304226
Validation loss: 2.479450338515392

Epoch: 6| Step: 13
Training loss: 2.346585707225236
Validation loss: 2.477713946634744

Epoch: 82| Step: 0
Training loss: 2.6117206926079
Validation loss: 2.4802310368808476

Epoch: 6| Step: 1
Training loss: 2.229578378275374
Validation loss: 2.4670795663252036

Epoch: 6| Step: 2
Training loss: 3.034110695576662
Validation loss: 2.4703819604750334

Epoch: 6| Step: 3
Training loss: 2.9628136963686473
Validation loss: 2.4793334791758297

Epoch: 6| Step: 4
Training loss: 2.7678793646979543
Validation loss: 2.4697708920448522

Epoch: 6| Step: 5
Training loss: 1.8700426051952297
Validation loss: 2.479804656892682

Epoch: 6| Step: 6
Training loss: 3.602938110057172
Validation loss: 2.473635575505925

Epoch: 6| Step: 7
Training loss: 1.7543977927972048
Validation loss: 2.4786674394641035

Epoch: 6| Step: 8
Training loss: 2.9489128307810186
Validation loss: 2.4598778936656758

Epoch: 6| Step: 9
Training loss: 2.626545314970876
Validation loss: 2.4682076095752663

Epoch: 6| Step: 10
Training loss: 2.667449498507404
Validation loss: 2.478963038195175

Epoch: 6| Step: 11
Training loss: 2.3034146172092407
Validation loss: 2.478336906468872

Epoch: 6| Step: 12
Training loss: 2.9071270019377393
Validation loss: 2.481373122945578

Epoch: 6| Step: 13
Training loss: 2.709689421927477
Validation loss: 2.4680947529366275

Epoch: 83| Step: 0
Training loss: 2.614859476489532
Validation loss: 2.474429244001651

Epoch: 6| Step: 1
Training loss: 2.2891601958274226
Validation loss: 2.4815063373494777

Epoch: 6| Step: 2
Training loss: 2.948702452479612
Validation loss: 2.4768838448495787

Epoch: 6| Step: 3
Training loss: 3.147400337319963
Validation loss: 2.4885492108265788

Epoch: 6| Step: 4
Training loss: 3.161323925766394
Validation loss: 2.4771947162773063

Epoch: 6| Step: 5
Training loss: 2.287509534638759
Validation loss: 2.472788315648334

Epoch: 6| Step: 6
Training loss: 2.622641093892385
Validation loss: 2.482150176929443

Epoch: 6| Step: 7
Training loss: 2.5822423251353106
Validation loss: 2.478477058106383

Epoch: 6| Step: 8
Training loss: 1.6534715775918414
Validation loss: 2.470010330077626

Epoch: 6| Step: 9
Training loss: 3.460467924549502
Validation loss: 2.470623080981848

Epoch: 6| Step: 10
Training loss: 2.8150114925820713
Validation loss: 2.4756291752446815

Epoch: 6| Step: 11
Training loss: 2.546286672965723
Validation loss: 2.46143606578377

Epoch: 6| Step: 12
Training loss: 2.488762585901752
Validation loss: 2.484801753338684

Epoch: 6| Step: 13
Training loss: 2.418285145804199
Validation loss: 2.483630431435428

Epoch: 84| Step: 0
Training loss: 2.176716957718613
Validation loss: 2.469541103869452

Epoch: 6| Step: 1
Training loss: 3.451192461782472
Validation loss: 2.4731837177268714

Epoch: 6| Step: 2
Training loss: 3.019547831303519
Validation loss: 2.465159161853207

Epoch: 6| Step: 3
Training loss: 3.185188053394311
Validation loss: 2.462533562735852

Epoch: 6| Step: 4
Training loss: 2.8867124730352933
Validation loss: 2.4765744043215956

Epoch: 6| Step: 5
Training loss: 1.8762793944392488
Validation loss: 2.4800815963884273

Epoch: 6| Step: 6
Training loss: 1.9742560518618117
Validation loss: 2.4837199383480306

Epoch: 6| Step: 7
Training loss: 2.6181417519039614
Validation loss: 2.4821296173185408

Epoch: 6| Step: 8
Training loss: 2.0561536772177167
Validation loss: 2.491898751823593

Epoch: 6| Step: 9
Training loss: 2.6391658927579886
Validation loss: 2.474589937906215

Epoch: 6| Step: 10
Training loss: 3.188248789481136
Validation loss: 2.4929483986536227

Epoch: 6| Step: 11
Training loss: 2.4368147253549637
Validation loss: 2.482237965977255

Epoch: 6| Step: 12
Training loss: 2.9720841808488125
Validation loss: 2.485102137361559

Epoch: 6| Step: 13
Training loss: 2.2940960116394686
Validation loss: 2.465572084912107

Epoch: 85| Step: 0
Training loss: 2.8438846430500786
Validation loss: 2.4742011214822495

Epoch: 6| Step: 1
Training loss: 3.1619060938750816
Validation loss: 2.487392899620326

Epoch: 6| Step: 2
Training loss: 1.7067161286657064
Validation loss: 2.50034822479365

Epoch: 6| Step: 3
Training loss: 2.321462224360082
Validation loss: 2.4706030739821507

Epoch: 6| Step: 4
Training loss: 2.8018795823300784
Validation loss: 2.4856504382165174

Epoch: 6| Step: 5
Training loss: 2.6822842397247504
Validation loss: 2.4788052867786727

Epoch: 6| Step: 6
Training loss: 2.746089235304788
Validation loss: 2.4704424081955167

Epoch: 6| Step: 7
Training loss: 2.7679033108565645
Validation loss: 2.484456801942927

Epoch: 6| Step: 8
Training loss: 1.9657257102795902
Validation loss: 2.4807604458588948

Epoch: 6| Step: 9
Training loss: 3.3277126289603767
Validation loss: 2.4778537625961614

Epoch: 6| Step: 10
Training loss: 2.4220254174559637
Validation loss: 2.492627229824656

Epoch: 6| Step: 11
Training loss: 2.7255114958987283
Validation loss: 2.4840456268990505

Epoch: 6| Step: 12
Training loss: 2.7806276632387523
Validation loss: 2.467294429263214

Epoch: 6| Step: 13
Training loss: 3.040644608970526
Validation loss: 2.4794016046247824

Epoch: 86| Step: 0
Training loss: 2.538654752416195
Validation loss: 2.4717747279565754

Epoch: 6| Step: 1
Training loss: 2.444521742619685
Validation loss: 2.474863423108885

Epoch: 6| Step: 2
Training loss: 2.268410069244213
Validation loss: 2.4845870145465203

Epoch: 6| Step: 3
Training loss: 3.133065458440043
Validation loss: 2.4672260006813134

Epoch: 6| Step: 4
Training loss: 2.101745824369328
Validation loss: 2.4685614573460146

Epoch: 6| Step: 5
Training loss: 2.494681422930893
Validation loss: 2.4746239739575713

Epoch: 6| Step: 6
Training loss: 3.545553490562984
Validation loss: 2.468663862248794

Epoch: 6| Step: 7
Training loss: 3.073764248784297
Validation loss: 2.45886572194542

Epoch: 6| Step: 8
Training loss: 2.801965779576802
Validation loss: 2.478881119080504

Epoch: 6| Step: 9
Training loss: 2.5271676192310033
Validation loss: 2.471419472044801

Epoch: 6| Step: 10
Training loss: 2.659075322731654
Validation loss: 2.474649634845839

Epoch: 6| Step: 11
Training loss: 2.4719758988535747
Validation loss: 2.4751842790639125

Epoch: 6| Step: 12
Training loss: 3.023019372381437
Validation loss: 2.4698254724695543

Epoch: 6| Step: 13
Training loss: 1.5399858832021922
Validation loss: 2.465789854124938

Epoch: 87| Step: 0
Training loss: 2.3740462345612032
Validation loss: 2.4647309712838537

Epoch: 6| Step: 1
Training loss: 2.728986913764976
Validation loss: 2.4882070075338296

Epoch: 6| Step: 2
Training loss: 2.8550138306825543
Validation loss: 2.4756985499862725

Epoch: 6| Step: 3
Training loss: 2.5402115789285458
Validation loss: 2.4670931291409537

Epoch: 6| Step: 4
Training loss: 2.601962405332684
Validation loss: 2.4709987759371588

Epoch: 6| Step: 5
Training loss: 2.6561568299951315
Validation loss: 2.4810646101729916

Epoch: 6| Step: 6
Training loss: 2.469671149969011
Validation loss: 2.4576147901944854

Epoch: 6| Step: 7
Training loss: 2.6516541158913403
Validation loss: 2.4720051516402126

Epoch: 6| Step: 8
Training loss: 2.5477119428015507
Validation loss: 2.458852309238654

Epoch: 6| Step: 9
Training loss: 2.3018560052772115
Validation loss: 2.470293332380129

Epoch: 6| Step: 10
Training loss: 3.0800954640444105
Validation loss: 2.473924294687157

Epoch: 6| Step: 11
Training loss: 3.245197268751216
Validation loss: 2.4774248428114634

Epoch: 6| Step: 12
Training loss: 2.73122315906456
Validation loss: 2.4680495124419273

Epoch: 6| Step: 13
Training loss: 2.494655427550962
Validation loss: 2.4792617699641926

Epoch: 88| Step: 0
Training loss: 1.8773645114901596
Validation loss: 2.4789492435168934

Epoch: 6| Step: 1
Training loss: 2.895168383614746
Validation loss: 2.4861093376249435

Epoch: 6| Step: 2
Training loss: 2.0405975059538153
Validation loss: 2.4644164294218123

Epoch: 6| Step: 3
Training loss: 2.0829421121114304
Validation loss: 2.4593821047884727

Epoch: 6| Step: 4
Training loss: 3.1459226953475095
Validation loss: 2.464920317077822

Epoch: 6| Step: 5
Training loss: 2.5930608730151534
Validation loss: 2.481015539101942

Epoch: 6| Step: 6
Training loss: 3.0238976732127565
Validation loss: 2.4712683679647474

Epoch: 6| Step: 7
Training loss: 2.6469804474815004
Validation loss: 2.4904320299533405

Epoch: 6| Step: 8
Training loss: 2.6281416122510235
Validation loss: 2.481850893124071

Epoch: 6| Step: 9
Training loss: 3.272394637822494
Validation loss: 2.4796238435730573

Epoch: 6| Step: 10
Training loss: 2.2214313477274095
Validation loss: 2.498187038414166

Epoch: 6| Step: 11
Training loss: 3.4769980854229927
Validation loss: 2.49811168337943

Epoch: 6| Step: 12
Training loss: 2.2058720337869464
Validation loss: 2.459484582311931

Epoch: 6| Step: 13
Training loss: 2.823268619758011
Validation loss: 2.484818493076229

Epoch: 89| Step: 0
Training loss: 3.295621950208532
Validation loss: 2.483986300260071

Epoch: 6| Step: 1
Training loss: 2.5144098794610144
Validation loss: 2.4611205153248292

Epoch: 6| Step: 2
Training loss: 2.550082848642888
Validation loss: 2.4656052919881124

Epoch: 6| Step: 3
Training loss: 2.923127421047145
Validation loss: 2.481714274848934

Epoch: 6| Step: 4
Training loss: 2.4613067834289413
Validation loss: 2.4762874549009695

Epoch: 6| Step: 5
Training loss: 2.8092850005571646
Validation loss: 2.4736876357229534

Epoch: 6| Step: 6
Training loss: 2.4987563854782855
Validation loss: 2.4596259942202128

Epoch: 6| Step: 7
Training loss: 2.4578151695591033
Validation loss: 2.4830943541269774

Epoch: 6| Step: 8
Training loss: 2.3395429363709157
Validation loss: 2.4739484633727584

Epoch: 6| Step: 9
Training loss: 3.3896484375
Validation loss: 2.481303570041668

Epoch: 6| Step: 10
Training loss: 2.163696037690615
Validation loss: 2.4700014372757466

Epoch: 6| Step: 11
Training loss: 2.935517311581841
Validation loss: 2.4787224771250798

Epoch: 6| Step: 12
Training loss: 2.5392059755136023
Validation loss: 2.4664497474529625

Epoch: 6| Step: 13
Training loss: 1.870704562620167
Validation loss: 2.4765760222697573

Epoch: 90| Step: 0
Training loss: 2.2385982269010167
Validation loss: 2.4609183346362933

Epoch: 6| Step: 1
Training loss: 2.649706781107749
Validation loss: 2.484405546283695

Epoch: 6| Step: 2
Training loss: 2.5105270002714164
Validation loss: 2.4828302295680897

Epoch: 6| Step: 3
Training loss: 2.976805349140236
Validation loss: 2.4599101406519237

Epoch: 6| Step: 4
Training loss: 2.5521547787585277
Validation loss: 2.4759685787210595

Epoch: 6| Step: 5
Training loss: 2.3943857767992247
Validation loss: 2.4769008161224044

Epoch: 6| Step: 6
Training loss: 2.238987569892867
Validation loss: 2.479586552171119

Epoch: 6| Step: 7
Training loss: 2.155292464234095
Validation loss: 2.4760696284549244

Epoch: 6| Step: 8
Training loss: 2.835437236620649
Validation loss: 2.464929356656737

Epoch: 6| Step: 9
Training loss: 2.444610397408386
Validation loss: 2.468651163768942

Epoch: 6| Step: 10
Training loss: 2.956312286172424
Validation loss: 2.4642750255689463

Epoch: 6| Step: 11
Training loss: 3.566097250313548
Validation loss: 2.463130279104963

Epoch: 6| Step: 12
Training loss: 2.8505984832393505
Validation loss: 2.4577081068422073

Epoch: 6| Step: 13
Training loss: 2.5877726056520562
Validation loss: 2.4702025408712966

Epoch: 91| Step: 0
Training loss: 2.711182684900322
Validation loss: 2.4612993627021287

Epoch: 6| Step: 1
Training loss: 2.273340806510627
Validation loss: 2.4662455364186675

Epoch: 6| Step: 2
Training loss: 2.7725114162750066
Validation loss: 2.4700868039461272

Epoch: 6| Step: 3
Training loss: 2.7126243246390636
Validation loss: 2.4748136717695224

Epoch: 6| Step: 4
Training loss: 2.5274854381530436
Validation loss: 2.4660918407704364

Epoch: 6| Step: 5
Training loss: 2.4407395574081985
Validation loss: 2.4870138282639

Epoch: 6| Step: 6
Training loss: 2.7847736625539343
Validation loss: 2.4903567110012093

Epoch: 6| Step: 7
Training loss: 2.263401913940505
Validation loss: 2.4701442797412256

Epoch: 6| Step: 8
Training loss: 3.0117735307315256
Validation loss: 2.4635117210807778

Epoch: 6| Step: 9
Training loss: 2.4183712132872297
Validation loss: 2.473964297293365

Epoch: 6| Step: 10
Training loss: 2.6973070808556145
Validation loss: 2.4948097716626836

Epoch: 6| Step: 11
Training loss: 2.7916816786936525
Validation loss: 2.4668517929866094

Epoch: 6| Step: 12
Training loss: 2.979652222943131
Validation loss: 2.4786425710676108

Epoch: 6| Step: 13
Training loss: 2.8556497623457866
Validation loss: 2.480570255108553

Epoch: 92| Step: 0
Training loss: 2.715006827526746
Validation loss: 2.487153235328309

Epoch: 6| Step: 1
Training loss: 2.1004416727904345
Validation loss: 2.4754136350478495

Epoch: 6| Step: 2
Training loss: 3.4322509917577944
Validation loss: 2.4720949187283585

Epoch: 6| Step: 3
Training loss: 2.5006020774639244
Validation loss: 2.4901186008552663

Epoch: 6| Step: 4
Training loss: 2.809727637507354
Validation loss: 2.4866604845257774

Epoch: 6| Step: 5
Training loss: 2.822938494345721
Validation loss: 2.4724882558316037

Epoch: 6| Step: 6
Training loss: 2.652434177570711
Validation loss: 2.4772928287508487

Epoch: 6| Step: 7
Training loss: 2.771843078498285
Validation loss: 2.488948192319631

Epoch: 6| Step: 8
Training loss: 2.1314346278253224
Validation loss: 2.4750109392531163

Epoch: 6| Step: 9
Training loss: 2.5917082874190176
Validation loss: 2.4878361349997995

Epoch: 6| Step: 10
Training loss: 3.2519991668099513
Validation loss: 2.480750822217174

Epoch: 6| Step: 11
Training loss: 2.0937379295798295
Validation loss: 2.478743406298621

Epoch: 6| Step: 12
Training loss: 2.2792761637474825
Validation loss: 2.4926540141154443

Epoch: 6| Step: 13
Training loss: 3.104545638400351
Validation loss: 2.4740168464273697

Epoch: 93| Step: 0
Training loss: 2.9780063281277043
Validation loss: 2.476681370882877

Epoch: 6| Step: 1
Training loss: 2.536013700664828
Validation loss: 2.473976931197118

Epoch: 6| Step: 2
Training loss: 2.5352049648030457
Validation loss: 2.4624777884548963

Epoch: 6| Step: 3
Training loss: 2.524830436678525
Validation loss: 2.4746782044147753

Epoch: 6| Step: 4
Training loss: 1.8920023291252914
Validation loss: 2.475765086566615

Epoch: 6| Step: 5
Training loss: 2.859055965114659
Validation loss: 2.4719467157245956

Epoch: 6| Step: 6
Training loss: 2.830305239118571
Validation loss: 2.467941810260836

Epoch: 6| Step: 7
Training loss: 2.9652102599446724
Validation loss: 2.4795725283332

Epoch: 6| Step: 8
Training loss: 2.6249375108819555
Validation loss: 2.4716127302879163

Epoch: 6| Step: 9
Training loss: 3.0747910467345747
Validation loss: 2.4761180029142578

Epoch: 6| Step: 10
Training loss: 2.0091380927407414
Validation loss: 2.4747488043741805

Epoch: 6| Step: 11
Training loss: 2.8452717827905887
Validation loss: 2.4784672120020574

Epoch: 6| Step: 12
Training loss: 2.5549601838057123
Validation loss: 2.463158864674344

Epoch: 6| Step: 13
Training loss: 2.942890172870894
Validation loss: 2.47814263172263

Epoch: 94| Step: 0
Training loss: 2.885798202977912
Validation loss: 2.480046501778098

Epoch: 6| Step: 1
Training loss: 3.215396801086911
Validation loss: 2.4792230140719376

Epoch: 6| Step: 2
Training loss: 2.1895894561982017
Validation loss: 2.463709047007035

Epoch: 6| Step: 3
Training loss: 2.914351298157912
Validation loss: 2.472228217254974

Epoch: 6| Step: 4
Training loss: 3.2687831373704976
Validation loss: 2.476911304987773

Epoch: 6| Step: 5
Training loss: 2.6538372975247366
Validation loss: 2.481739386210685

Epoch: 6| Step: 6
Training loss: 1.8750612884677273
Validation loss: 2.4923085489886

Epoch: 6| Step: 7
Training loss: 2.408983733670561
Validation loss: 2.466632009771053

Epoch: 6| Step: 8
Training loss: 2.7882144611084048
Validation loss: 2.484046308047001

Epoch: 6| Step: 9
Training loss: 2.1593321733878916
Validation loss: 2.4829608426417953

Epoch: 6| Step: 10
Training loss: 2.485100310390681
Validation loss: 2.4791226326670173

Epoch: 6| Step: 11
Training loss: 2.9912633838346174
Validation loss: 2.4932712077719312

Epoch: 6| Step: 12
Training loss: 2.742561162720388
Validation loss: 2.488393044822212

Epoch: 6| Step: 13
Training loss: 1.963359901926335
Validation loss: 2.465469035840335

Epoch: 95| Step: 0
Training loss: 2.093396171165282
Validation loss: 2.4699330971837123

Epoch: 6| Step: 1
Training loss: 2.4810792186779262
Validation loss: 2.490422953752746

Epoch: 6| Step: 2
Training loss: 2.238846792304382
Validation loss: 2.4652627885466694

Epoch: 6| Step: 3
Training loss: 3.270695304792917
Validation loss: 2.4741407930525257

Epoch: 6| Step: 4
Training loss: 2.3012353937865564
Validation loss: 2.47006136861955

Epoch: 6| Step: 5
Training loss: 2.937630508445606
Validation loss: 2.4767037881847664

Epoch: 6| Step: 6
Training loss: 2.443953066142649
Validation loss: 2.469309390249757

Epoch: 6| Step: 7
Training loss: 2.697785677485428
Validation loss: 2.489566203778534

Epoch: 6| Step: 8
Training loss: 2.8871762709363638
Validation loss: 2.4811903109709026

Epoch: 6| Step: 9
Training loss: 2.054029235988359
Validation loss: 2.4910822361113083

Epoch: 6| Step: 10
Training loss: 2.511592879634314
Validation loss: 2.476150186975346

Epoch: 6| Step: 11
Training loss: 2.4735169562411534
Validation loss: 2.4751787388989954

Epoch: 6| Step: 12
Training loss: 3.0972820118453663
Validation loss: 2.4880366739077338

Epoch: 6| Step: 13
Training loss: 3.9155364468753295
Validation loss: 2.477360637778227

Epoch: 96| Step: 0
Training loss: 2.555807632186053
Validation loss: 2.4818089269008103

Epoch: 6| Step: 1
Training loss: 2.9828076465980846
Validation loss: 2.4697864226637902

Epoch: 6| Step: 2
Training loss: 2.219689613501321
Validation loss: 2.4772255891232593

Epoch: 6| Step: 3
Training loss: 2.850773783261323
Validation loss: 2.4692214509430723

Epoch: 6| Step: 4
Training loss: 2.570651046580164
Validation loss: 2.4940054498531645

Epoch: 6| Step: 5
Training loss: 3.011846992345038
Validation loss: 2.463592874948281

Epoch: 6| Step: 6
Training loss: 2.2469302535392637
Validation loss: 2.465366221629517

Epoch: 6| Step: 7
Training loss: 2.806486864862197
Validation loss: 2.4814079689199438

Epoch: 6| Step: 8
Training loss: 2.1128546377605812
Validation loss: 2.467828774216175

Epoch: 6| Step: 9
Training loss: 2.596444442439657
Validation loss: 2.4730569786626413

Epoch: 6| Step: 10
Training loss: 2.6051471746242356
Validation loss: 2.4753028225714715

Epoch: 6| Step: 11
Training loss: 2.577151582924852
Validation loss: 2.4824601606424777

Epoch: 6| Step: 12
Training loss: 3.2748048971752484
Validation loss: 2.487391071240033

Epoch: 6| Step: 13
Training loss: 2.3743883650389264
Validation loss: 2.483394567361368

Epoch: 97| Step: 0
Training loss: 2.3937526015623614
Validation loss: 2.482683603981847

Epoch: 6| Step: 1
Training loss: 2.344964996759878
Validation loss: 2.4924051634188373

Epoch: 6| Step: 2
Training loss: 2.376112827794622
Validation loss: 2.4709743532626596

Epoch: 6| Step: 3
Training loss: 2.7318656524309772
Validation loss: 2.4649597195811586

Epoch: 6| Step: 4
Training loss: 2.7104813689460787
Validation loss: 2.4659195823997337

Epoch: 6| Step: 5
Training loss: 3.134191195422336
Validation loss: 2.4778964077731382

Epoch: 6| Step: 6
Training loss: 2.2619785825017296
Validation loss: 2.482749770082747

Epoch: 6| Step: 7
Training loss: 3.129933239892129
Validation loss: 2.4699656000391035

Epoch: 6| Step: 8
Training loss: 3.086942330472041
Validation loss: 2.481924842313768

Epoch: 6| Step: 9
Training loss: 2.470885403509562
Validation loss: 2.4923881403448873

Epoch: 6| Step: 10
Training loss: 2.7694792534126353
Validation loss: 2.489220458416768

Epoch: 6| Step: 11
Training loss: 2.4586888287939037
Validation loss: 2.4745263441218697

Epoch: 6| Step: 12
Training loss: 2.5911780785067036
Validation loss: 2.4806934314681937

Epoch: 6| Step: 13
Training loss: 2.341249072578275
Validation loss: 2.479522209769415

Epoch: 98| Step: 0
Training loss: 2.8184657932633153
Validation loss: 2.4799987828344006

Epoch: 6| Step: 1
Training loss: 2.522062133501655
Validation loss: 2.4631709586693677

Epoch: 6| Step: 2
Training loss: 2.6385242299436085
Validation loss: 2.486300668849271

Epoch: 6| Step: 3
Training loss: 2.613432510628477
Validation loss: 2.479904848389465

Epoch: 6| Step: 4
Training loss: 2.570212133239409
Validation loss: 2.4898824221641207

Epoch: 6| Step: 5
Training loss: 3.2027697854678934
Validation loss: 2.470970132701245

Epoch: 6| Step: 6
Training loss: 2.514537599954165
Validation loss: 2.475368106283429

Epoch: 6| Step: 7
Training loss: 2.5546077984150806
Validation loss: 2.471980500380199

Epoch: 6| Step: 8
Training loss: 2.74014440865989
Validation loss: 2.4755808259249785

Epoch: 6| Step: 9
Training loss: 2.7409040702613963
Validation loss: 2.474719683468741

Epoch: 6| Step: 10
Training loss: 2.683058861699959
Validation loss: 2.468694392126174

Epoch: 6| Step: 11
Training loss: 2.1002842302070093
Validation loss: 2.4712810633700366

Epoch: 6| Step: 12
Training loss: 2.1155673088197813
Validation loss: 2.4824796383513656

Epoch: 6| Step: 13
Training loss: 3.5225134608469766
Validation loss: 2.4558896189038406

Epoch: 99| Step: 0
Training loss: 2.9689600819993958
Validation loss: 2.4812121306292543

Epoch: 6| Step: 1
Training loss: 3.1425280522541246
Validation loss: 2.4802916605931955

Epoch: 6| Step: 2
Training loss: 2.8007424323931365
Validation loss: 2.4824212522712394

Epoch: 6| Step: 3
Training loss: 2.287254478744573
Validation loss: 2.468575045771562

Epoch: 6| Step: 4
Training loss: 2.501899379179754
Validation loss: 2.469252103704613

Epoch: 6| Step: 5
Training loss: 2.9884717693555936
Validation loss: 2.4566849360922967

Epoch: 6| Step: 6
Training loss: 2.5356683669355573
Validation loss: 2.467964889695316

Epoch: 6| Step: 7
Training loss: 2.2368431064733385
Validation loss: 2.460323315304984

Epoch: 6| Step: 8
Training loss: 2.5683406234462813
Validation loss: 2.4756354361790076

Epoch: 6| Step: 9
Training loss: 2.4772234013779366
Validation loss: 2.466975910988969

Epoch: 6| Step: 10
Training loss: 1.4714098444393766
Validation loss: 2.4733228895656065

Epoch: 6| Step: 11
Training loss: 2.858975241811054
Validation loss: 2.4624883710279404

Epoch: 6| Step: 12
Training loss: 2.3685389522854914
Validation loss: 2.466137545467179

Epoch: 6| Step: 13
Training loss: 3.802943901320312
Validation loss: 2.489563240144898

Epoch: 100| Step: 0
Training loss: 2.1283736656428087
Validation loss: 2.4719415266202747

Epoch: 6| Step: 1
Training loss: 2.258248574143163
Validation loss: 2.4759701898172444

Epoch: 6| Step: 2
Training loss: 3.0895051445116364
Validation loss: 2.4671115113549664

Epoch: 6| Step: 3
Training loss: 2.455528685287056
Validation loss: 2.471653847974152

Epoch: 6| Step: 4
Training loss: 2.652639380989695
Validation loss: 2.481731255442157

Epoch: 6| Step: 5
Training loss: 2.399985444501608
Validation loss: 2.472271395509916

Epoch: 6| Step: 6
Training loss: 3.099148134889216
Validation loss: 2.473406315319847

Epoch: 6| Step: 7
Training loss: 2.693192950577988
Validation loss: 2.4789255362227243

Epoch: 6| Step: 8
Training loss: 2.606001815139478
Validation loss: 2.475226248854194

Epoch: 6| Step: 9
Training loss: 3.1698621555045423
Validation loss: 2.4758483150930144

Epoch: 6| Step: 10
Training loss: 2.956130501588087
Validation loss: 2.482399887313278

Epoch: 6| Step: 11
Training loss: 1.8411981412443517
Validation loss: 2.479506544718377

Epoch: 6| Step: 12
Training loss: 2.951968496418147
Validation loss: 2.482417813318555

Epoch: 6| Step: 13
Training loss: 2.4448678584362886
Validation loss: 2.4594818982624815

Epoch: 101| Step: 0
Training loss: 2.452539070277037
Validation loss: 2.470967418590096

Epoch: 6| Step: 1
Training loss: 2.950489462640535
Validation loss: 2.4794197332518086

Epoch: 6| Step: 2
Training loss: 2.6124768123784072
Validation loss: 2.4745744591903502

Epoch: 6| Step: 3
Training loss: 2.174586298391681
Validation loss: 2.475498237730344

Epoch: 6| Step: 4
Training loss: 2.8839562274293478
Validation loss: 2.4907923202665776

Epoch: 6| Step: 5
Training loss: 2.421907486236253
Validation loss: 2.4588808027470783

Epoch: 6| Step: 6
Training loss: 3.0614943118132114
Validation loss: 2.4686715957447154

Epoch: 6| Step: 7
Training loss: 1.856004753994608
Validation loss: 2.488266975865571

Epoch: 6| Step: 8
Training loss: 3.129016278983781
Validation loss: 2.4679061867123853

Epoch: 6| Step: 9
Training loss: 3.3925532470212625
Validation loss: 2.4926387967036363

Epoch: 6| Step: 10
Training loss: 2.1144244756049124
Validation loss: 2.465824190467913

Epoch: 6| Step: 11
Training loss: 2.6385795300389057
Validation loss: 2.4795992396232047

Epoch: 6| Step: 12
Training loss: 2.3152082925443684
Validation loss: 2.466784204322808

Epoch: 6| Step: 13
Training loss: 2.792481109090786
Validation loss: 2.4654585346896254

Epoch: 102| Step: 0
Training loss: 1.639243425214997
Validation loss: 2.464254170136512

Epoch: 6| Step: 1
Training loss: 2.6153940005371377
Validation loss: 2.4824470969325807

Epoch: 6| Step: 2
Training loss: 2.7179985323264093
Validation loss: 2.4866177128348226

Epoch: 6| Step: 3
Training loss: 3.0546378597509123
Validation loss: 2.494175726353457

Epoch: 6| Step: 4
Training loss: 3.0610905732167617
Validation loss: 2.4630648438068916

Epoch: 6| Step: 5
Training loss: 2.575445088557472
Validation loss: 2.4740784042227224

Epoch: 6| Step: 6
Training loss: 2.8575972570386923
Validation loss: 2.4663767094485856

Epoch: 6| Step: 7
Training loss: 2.8984282871315847
Validation loss: 2.4866906016973127

Epoch: 6| Step: 8
Training loss: 2.5521765451860596
Validation loss: 2.4705011769944747

Epoch: 6| Step: 9
Training loss: 2.5121363742037683
Validation loss: 2.4741299463581607

Epoch: 6| Step: 10
Training loss: 2.8521704456817973
Validation loss: 2.467749259241357

Epoch: 6| Step: 11
Training loss: 2.412846231075336
Validation loss: 2.4665519240624407

Epoch: 6| Step: 12
Training loss: 2.5320288319445217
Validation loss: 2.4832602752864665

Epoch: 6| Step: 13
Training loss: 2.28424001730664
Validation loss: 2.4635395524481294

Epoch: 103| Step: 0
Training loss: 2.8263092113097907
Validation loss: 2.467683225437746

Epoch: 6| Step: 1
Training loss: 3.2855180865405176
Validation loss: 2.4763391606965635

Epoch: 6| Step: 2
Training loss: 2.7636752394800634
Validation loss: 2.492577291536787

Epoch: 6| Step: 3
Training loss: 2.5847988791226904
Validation loss: 2.4726715748373316

Epoch: 6| Step: 4
Training loss: 2.171418286062562
Validation loss: 2.491348436527596

Epoch: 6| Step: 5
Training loss: 2.7757633396540373
Validation loss: 2.482463709002716

Epoch: 6| Step: 6
Training loss: 2.596080606193687
Validation loss: 2.4609057873494056

Epoch: 6| Step: 7
Training loss: 3.1885996399005974
Validation loss: 2.489005494186405

Epoch: 6| Step: 8
Training loss: 2.8678757675589535
Validation loss: 2.485981892941635

Epoch: 6| Step: 9
Training loss: 2.1665693285669536
Validation loss: 2.491860547412311

Epoch: 6| Step: 10
Training loss: 2.092051144202674
Validation loss: 2.4909961934116582

Epoch: 6| Step: 11
Training loss: 2.1407005129672534
Validation loss: 2.482095235930913

Epoch: 6| Step: 12
Training loss: 2.5915688225367624
Validation loss: 2.4803074540197576

Epoch: 6| Step: 13
Training loss: 2.632121734105517
Validation loss: 2.463438260349509

Epoch: 104| Step: 0
Training loss: 2.930579454064413
Validation loss: 2.4763568484698477

Epoch: 6| Step: 1
Training loss: 2.2276011403559517
Validation loss: 2.486378367692212

Epoch: 6| Step: 2
Training loss: 2.597753812635684
Validation loss: 2.472494415330315

Epoch: 6| Step: 3
Training loss: 2.511027239446281
Validation loss: 2.492351783606809

Epoch: 6| Step: 4
Training loss: 2.1628553418283185
Validation loss: 2.4661782403967556

Epoch: 6| Step: 5
Training loss: 2.884238616595537
Validation loss: 2.483809488481477

Epoch: 6| Step: 6
Training loss: 2.2196500859845965
Validation loss: 2.4883163392235903

Epoch: 6| Step: 7
Training loss: 1.935772094557115
Validation loss: 2.4612003152874258

Epoch: 6| Step: 8
Training loss: 2.8450229017680106
Validation loss: 2.4635081584307663

Epoch: 6| Step: 9
Training loss: 2.6382332528323
Validation loss: 2.477074476990867

Epoch: 6| Step: 10
Training loss: 2.562381276427482
Validation loss: 2.478652717453158

Epoch: 6| Step: 11
Training loss: 3.0577857654242955
Validation loss: 2.4797272131641055

Epoch: 6| Step: 12
Training loss: 3.265172607626245
Validation loss: 2.472384534328903

Epoch: 6| Step: 13
Training loss: 3.1976640997109245
Validation loss: 2.474459238599549

Epoch: 105| Step: 0
Training loss: 1.8712122487430953
Validation loss: 2.4712985855778915

Epoch: 6| Step: 1
Training loss: 2.170862414652769
Validation loss: 2.461183286790463

Epoch: 6| Step: 2
Training loss: 2.658923430603908
Validation loss: 2.4793581141977867

Epoch: 6| Step: 3
Training loss: 2.925454461420852
Validation loss: 2.4584825528510597

Epoch: 6| Step: 4
Training loss: 2.5078378836514714
Validation loss: 2.4760076091984806

Epoch: 6| Step: 5
Training loss: 3.027321698508397
Validation loss: 2.474647042869933

Epoch: 6| Step: 6
Training loss: 2.558537187023873
Validation loss: 2.4659603438227777

Epoch: 6| Step: 7
Training loss: 3.107735206252717
Validation loss: 2.474407193580574

Epoch: 6| Step: 8
Training loss: 2.6639583265235403
Validation loss: 2.479274167999259

Epoch: 6| Step: 9
Training loss: 2.8823878691435745
Validation loss: 2.457620343874979

Epoch: 6| Step: 10
Training loss: 2.4241752283760998
Validation loss: 2.4840975122933875

Epoch: 6| Step: 11
Training loss: 2.7847567963349844
Validation loss: 2.4631532818497237

Epoch: 6| Step: 12
Training loss: 2.5117083085052214
Validation loss: 2.459685270033663

Epoch: 6| Step: 13
Training loss: 2.534976241623038
Validation loss: 2.458494321044051

Epoch: 106| Step: 0
Training loss: 2.7489932558289882
Validation loss: 2.4493347361362767

Epoch: 6| Step: 1
Training loss: 2.2010455768031134
Validation loss: 2.4712623096669692

Epoch: 6| Step: 2
Training loss: 2.155018994099402
Validation loss: 2.4712726647826964

Epoch: 6| Step: 3
Training loss: 2.1471868030389847
Validation loss: 2.4740629813702837

Epoch: 6| Step: 4
Training loss: 2.154226708328644
Validation loss: 2.4718990665088367

Epoch: 6| Step: 5
Training loss: 2.795055458187415
Validation loss: 2.477047670685281

Epoch: 6| Step: 6
Training loss: 2.80743358774689
Validation loss: 2.476700410645176

Epoch: 6| Step: 7
Training loss: 2.063651023815728
Validation loss: 2.465316755938072

Epoch: 6| Step: 8
Training loss: 2.9304243864943755
Validation loss: 2.465049158757765

Epoch: 6| Step: 9
Training loss: 2.923805292788273
Validation loss: 2.480371224641479

Epoch: 6| Step: 10
Training loss: 2.800400882361079
Validation loss: 2.45196217731706

Epoch: 6| Step: 11
Training loss: 3.0155465703855517
Validation loss: 2.4723760648322344

Epoch: 6| Step: 12
Training loss: 2.7195366784589243
Validation loss: 2.483586957254938

Epoch: 6| Step: 13
Training loss: 3.2564921459288954
Validation loss: 2.45809446237656

Epoch: 107| Step: 0
Training loss: 2.371817715522271
Validation loss: 2.4753826344843906

Epoch: 6| Step: 1
Training loss: 2.6329678905599527
Validation loss: 2.4760611705279425

Epoch: 6| Step: 2
Training loss: 2.557339006802839
Validation loss: 2.4712671490447264

Epoch: 6| Step: 3
Training loss: 2.9486925881017125
Validation loss: 2.471883305440162

Epoch: 6| Step: 4
Training loss: 1.974994082381642
Validation loss: 2.4728317712955485

Epoch: 6| Step: 5
Training loss: 2.2776058824801546
Validation loss: 2.4679808866562127

Epoch: 6| Step: 6
Training loss: 3.406162365827256
Validation loss: 2.4667554321242555

Epoch: 6| Step: 7
Training loss: 1.9776074206935208
Validation loss: 2.469136981533233

Epoch: 6| Step: 8
Training loss: 2.674152496702938
Validation loss: 2.479130575514183

Epoch: 6| Step: 9
Training loss: 2.2465871783079217
Validation loss: 2.458635454156422

Epoch: 6| Step: 10
Training loss: 2.5986282251110393
Validation loss: 2.462668203269867

Epoch: 6| Step: 11
Training loss: 3.5790679888432138
Validation loss: 2.4742574686871412

Epoch: 6| Step: 12
Training loss: 2.617201528938613
Validation loss: 2.4660178898041325

Epoch: 6| Step: 13
Training loss: 2.4755045559540125
Validation loss: 2.4801619656769742

Epoch: 108| Step: 0
Training loss: 2.6236208971454844
Validation loss: 2.471120469675395

Epoch: 6| Step: 1
Training loss: 2.434029088645022
Validation loss: 2.4951714184636606

Epoch: 6| Step: 2
Training loss: 2.920406686601872
Validation loss: 2.4724431636447486

Epoch: 6| Step: 3
Training loss: 2.5038993942476346
Validation loss: 2.4777112497403095

Epoch: 6| Step: 4
Training loss: 3.0057886225631822
Validation loss: 2.4783185982061475

Epoch: 6| Step: 5
Training loss: 2.5857746729916093
Validation loss: 2.4785518123355192

Epoch: 6| Step: 6
Training loss: 2.8725768119030697
Validation loss: 2.4820804123738887

Epoch: 6| Step: 7
Training loss: 1.88808642744802
Validation loss: 2.459552117243748

Epoch: 6| Step: 8
Training loss: 3.0023473457197762
Validation loss: 2.493363394551364

Epoch: 6| Step: 9
Training loss: 2.987308358785338
Validation loss: 2.4653296556511846

Epoch: 6| Step: 10
Training loss: 2.323694506593572
Validation loss: 2.472295312821481

Epoch: 6| Step: 11
Training loss: 2.232599046139717
Validation loss: 2.4680893059227675

Epoch: 6| Step: 12
Training loss: 2.680469632350117
Validation loss: 2.470143112159065

Epoch: 6| Step: 13
Training loss: 2.511303334863645
Validation loss: 2.4752110351204832

Epoch: 109| Step: 0
Training loss: 2.312517320722718
Validation loss: 2.4640129627315104

Epoch: 6| Step: 1
Training loss: 2.534039502685756
Validation loss: 2.4868508300929526

Epoch: 6| Step: 2
Training loss: 3.0381711618651543
Validation loss: 2.4805046732003913

Epoch: 6| Step: 3
Training loss: 2.3010021680069865
Validation loss: 2.463656101631468

Epoch: 6| Step: 4
Training loss: 2.808492730330773
Validation loss: 2.4662330697686943

Epoch: 6| Step: 5
Training loss: 2.5147187869407146
Validation loss: 2.479494977062548

Epoch: 6| Step: 6
Training loss: 2.2674180926383496
Validation loss: 2.4889560842409932

Epoch: 6| Step: 7
Training loss: 2.3006372066672443
Validation loss: 2.4835179071270614

Epoch: 6| Step: 8
Training loss: 2.6340530144433214
Validation loss: 2.460234742188377

Epoch: 6| Step: 9
Training loss: 2.3742187620503765
Validation loss: 2.470392905088661

Epoch: 6| Step: 10
Training loss: 2.812982644948029
Validation loss: 2.5022034604656995

Epoch: 6| Step: 11
Training loss: 2.9457780788766548
Validation loss: 2.47230055873371

Epoch: 6| Step: 12
Training loss: 2.296355623443919
Validation loss: 2.4722467666070638

Epoch: 6| Step: 13
Training loss: 3.799597623502376
Validation loss: 2.4660610582848115

Epoch: 110| Step: 0
Training loss: 3.0107120954140014
Validation loss: 2.4688823659793138

Epoch: 6| Step: 1
Training loss: 2.6555518635343303
Validation loss: 2.4599984545018794

Epoch: 6| Step: 2
Training loss: 2.517677938466964
Validation loss: 2.485859573941509

Epoch: 6| Step: 3
Training loss: 2.184663513951165
Validation loss: 2.481912942996587

Epoch: 6| Step: 4
Training loss: 2.6159612259514002
Validation loss: 2.488671430851695

Epoch: 6| Step: 5
Training loss: 3.0652778638931797
Validation loss: 2.4782735929651163

Epoch: 6| Step: 6
Training loss: 2.491666446375332
Validation loss: 2.47667070403895

Epoch: 6| Step: 7
Training loss: 3.0351439958126174
Validation loss: 2.4778575493077493

Epoch: 6| Step: 8
Training loss: 2.5836849486084352
Validation loss: 2.471949885599791

Epoch: 6| Step: 9
Training loss: 2.408353406389087
Validation loss: 2.4778460091309364

Epoch: 6| Step: 10
Training loss: 2.0628535805691453
Validation loss: 2.470048920190675

Epoch: 6| Step: 11
Training loss: 2.679068980554547
Validation loss: 2.4719440109824613

Epoch: 6| Step: 12
Training loss: 2.479246015374137
Validation loss: 2.474977919487412

Epoch: 6| Step: 13
Training loss: 3.0340734487153913
Validation loss: 2.467883640153425

Epoch: 111| Step: 0
Training loss: 2.9828877363113286
Validation loss: 2.4778672902346024

Epoch: 6| Step: 1
Training loss: 3.088574945914896
Validation loss: 2.4654242941183457

Epoch: 6| Step: 2
Training loss: 2.367446633435336
Validation loss: 2.473579236935546

Epoch: 6| Step: 3
Training loss: 3.2797455744806174
Validation loss: 2.4603042457100233

Epoch: 6| Step: 4
Training loss: 2.195445209442398
Validation loss: 2.4840466909346306

Epoch: 6| Step: 5
Training loss: 3.001294174790737
Validation loss: 2.4678587887857506

Epoch: 6| Step: 6
Training loss: 2.478490902993086
Validation loss: 2.4807090766231745

Epoch: 6| Step: 7
Training loss: 2.5169102009882804
Validation loss: 2.475387664652148

Epoch: 6| Step: 8
Training loss: 2.257685885459615
Validation loss: 2.48611104836159

Epoch: 6| Step: 9
Training loss: 2.3267417741291756
Validation loss: 2.4738999620339994

Epoch: 6| Step: 10
Training loss: 2.432190712597404
Validation loss: 2.4733805244086957

Epoch: 6| Step: 11
Training loss: 2.2119834771116933
Validation loss: 2.4746804244526808

Epoch: 6| Step: 12
Training loss: 2.3015017458063567
Validation loss: 2.474385807084921

Epoch: 6| Step: 13
Training loss: 3.250273619651136
Validation loss: 2.467269992260417

Epoch: 112| Step: 0
Training loss: 3.1414100083426133
Validation loss: 2.4732634943688816

Epoch: 6| Step: 1
Training loss: 2.2706384371027326
Validation loss: 2.4710303632065136

Epoch: 6| Step: 2
Training loss: 2.555752033706359
Validation loss: 2.4764235754420363

Epoch: 6| Step: 3
Training loss: 2.4396763402430253
Validation loss: 2.47751253336409

Epoch: 6| Step: 4
Training loss: 2.3643997950190307
Validation loss: 2.480923645770234

Epoch: 6| Step: 5
Training loss: 2.962240370306672
Validation loss: 2.4691233925662304

Epoch: 6| Step: 6
Training loss: 2.6022730134885843
Validation loss: 2.4600480260895585

Epoch: 6| Step: 7
Training loss: 2.8088140281913647
Validation loss: 2.4802937267677416

Epoch: 6| Step: 8
Training loss: 2.8656776880976245
Validation loss: 2.482439243182989

Epoch: 6| Step: 9
Training loss: 2.0740198876982525
Validation loss: 2.500032698509739

Epoch: 6| Step: 10
Training loss: 2.95419066239598
Validation loss: 2.483801829986359

Epoch: 6| Step: 11
Training loss: 2.80714423665963
Validation loss: 2.467495305689115

Epoch: 6| Step: 12
Training loss: 2.142642441847439
Validation loss: 2.481225697817942

Epoch: 6| Step: 13
Training loss: 2.592535814793842
Validation loss: 2.4985193903143603

Epoch: 113| Step: 0
Training loss: 2.8463176830823618
Validation loss: 2.4745832858308976

Epoch: 6| Step: 1
Training loss: 1.9401340422580886
Validation loss: 2.4817121272160496

Epoch: 6| Step: 2
Training loss: 2.471310410482361
Validation loss: 2.4518772868762713

Epoch: 6| Step: 3
Training loss: 1.8920669101432714
Validation loss: 2.476043141556187

Epoch: 6| Step: 4
Training loss: 2.4924444466754285
Validation loss: 2.4697221238964016

Epoch: 6| Step: 5
Training loss: 2.678201068523411
Validation loss: 2.468956550959684

Epoch: 6| Step: 6
Training loss: 2.9486224045259943
Validation loss: 2.470502062671806

Epoch: 6| Step: 7
Training loss: 2.418128777109343
Validation loss: 2.475199375924482

Epoch: 6| Step: 8
Training loss: 2.7738085861173283
Validation loss: 2.481180885827579

Epoch: 6| Step: 9
Training loss: 2.340389130833145
Validation loss: 2.472836337017757

Epoch: 6| Step: 10
Training loss: 3.5624670729872245
Validation loss: 2.4705517830606403

Epoch: 6| Step: 11
Training loss: 2.553323177270968
Validation loss: 2.486321549698138

Epoch: 6| Step: 12
Training loss: 2.4524891023072937
Validation loss: 2.4702613392462545

Epoch: 6| Step: 13
Training loss: 3.0530148973398257
Validation loss: 2.4822104780110554

Epoch: 114| Step: 0
Training loss: 2.7342432480814423
Validation loss: 2.485054214779795

Epoch: 6| Step: 1
Training loss: 2.8003769586766807
Validation loss: 2.465973669526478

Epoch: 6| Step: 2
Training loss: 2.8077077091385516
Validation loss: 2.4850695591022096

Epoch: 6| Step: 3
Training loss: 2.1143662916021615
Validation loss: 2.468692731627909

Epoch: 6| Step: 4
Training loss: 2.7298924788935515
Validation loss: 2.459829545322122

Epoch: 6| Step: 5
Training loss: 2.537899748785932
Validation loss: 2.4840538754849613

Epoch: 6| Step: 6
Training loss: 2.7384913387053658
Validation loss: 2.4617308770633057

Epoch: 6| Step: 7
Training loss: 2.8780327433194106
Validation loss: 2.468616548967949

Epoch: 6| Step: 8
Training loss: 1.9683305808276064
Validation loss: 2.454790310772473

Epoch: 6| Step: 9
Training loss: 2.6606202918152824
Validation loss: 2.48349031255164

Epoch: 6| Step: 10
Training loss: 2.418471079276659
Validation loss: 2.4809448426078684

Epoch: 6| Step: 11
Training loss: 3.1031333346989656
Validation loss: 2.4653711006571655

Epoch: 6| Step: 12
Training loss: 2.404205642816192
Validation loss: 2.4782306310086963

Epoch: 6| Step: 13
Training loss: 2.3621264449988884
Validation loss: 2.4785332077709725

Epoch: 115| Step: 0
Training loss: 2.315377378415877
Validation loss: 2.4743453668113364

Epoch: 6| Step: 1
Training loss: 2.1592437306761725
Validation loss: 2.4859130477844804

Epoch: 6| Step: 2
Training loss: 3.2304306673805785
Validation loss: 2.4670049944458534

Epoch: 6| Step: 3
Training loss: 2.4082532198383575
Validation loss: 2.4722304483072284

Epoch: 6| Step: 4
Training loss: 2.9794334523361004
Validation loss: 2.482307865528086

Epoch: 6| Step: 5
Training loss: 2.180964926205458
Validation loss: 2.470725809252802

Epoch: 6| Step: 6
Training loss: 2.0363936808308054
Validation loss: 2.4901717027003794

Epoch: 6| Step: 7
Training loss: 2.9352234480118033
Validation loss: 2.4607777522999332

Epoch: 6| Step: 8
Training loss: 2.5193929944807
Validation loss: 2.461069170529675

Epoch: 6| Step: 9
Training loss: 2.6395985792322407
Validation loss: 2.4696101544715625

Epoch: 6| Step: 10
Training loss: 3.0692160009775686
Validation loss: 2.4670083062823673

Epoch: 6| Step: 11
Training loss: 3.203338169354914
Validation loss: 2.466653561190063

Epoch: 6| Step: 12
Training loss: 2.084016179393558
Validation loss: 2.478406008882267

Epoch: 6| Step: 13
Training loss: 2.582338161955252
Validation loss: 2.4578875712320505

Epoch: 116| Step: 0
Training loss: 1.930073255522375
Validation loss: 2.4695454659788414

Epoch: 6| Step: 1
Training loss: 2.7437807329059867
Validation loss: 2.4621877187129027

Epoch: 6| Step: 2
Training loss: 3.109361198049613
Validation loss: 2.482122802636497

Epoch: 6| Step: 3
Training loss: 2.312532166953221
Validation loss: 2.4800924439291028

Epoch: 6| Step: 4
Training loss: 2.652343300551094
Validation loss: 2.4586208301230856

Epoch: 6| Step: 5
Training loss: 2.7101212297751784
Validation loss: 2.4594301356656145

Epoch: 6| Step: 6
Training loss: 2.6335339562331095
Validation loss: 2.4785229822861883

Epoch: 6| Step: 7
Training loss: 3.4126546300710694
Validation loss: 2.479582984185081

Epoch: 6| Step: 8
Training loss: 2.5203152168765386
Validation loss: 2.486583796619754

Epoch: 6| Step: 9
Training loss: 3.1327427882479175
Validation loss: 2.4696423729961112

Epoch: 6| Step: 10
Training loss: 1.8986084158610919
Validation loss: 2.4624275640779043

Epoch: 6| Step: 11
Training loss: 1.953369979753327
Validation loss: 2.4711351805389294

Epoch: 6| Step: 12
Training loss: 2.431603170206018
Validation loss: 2.4667761687185408

Epoch: 6| Step: 13
Training loss: 2.6902456230990803
Validation loss: 2.4645535540841017

Epoch: 117| Step: 0
Training loss: 2.3249094217355872
Validation loss: 2.472355128418889

Epoch: 6| Step: 1
Training loss: 2.674249497419918
Validation loss: 2.479878090253058

Epoch: 6| Step: 2
Training loss: 2.546961589815665
Validation loss: 2.466182117282083

Epoch: 6| Step: 3
Training loss: 2.5902783243578167
Validation loss: 2.4714820970734097

Epoch: 6| Step: 4
Training loss: 2.0034212414098604
Validation loss: 2.4665247965619472

Epoch: 6| Step: 5
Training loss: 2.6014348362480413
Validation loss: 2.4854156683792157

Epoch: 6| Step: 6
Training loss: 2.8939905317951746
Validation loss: 2.478525851032308

Epoch: 6| Step: 7
Training loss: 3.164204158673026
Validation loss: 2.468030329075055

Epoch: 6| Step: 8
Training loss: 2.154348225815913
Validation loss: 2.462780148957076

Epoch: 6| Step: 9
Training loss: 3.0844169637034233
Validation loss: 2.4745118274698092

Epoch: 6| Step: 10
Training loss: 2.68215419577498
Validation loss: 2.472198019300601

Epoch: 6| Step: 11
Training loss: 2.2647789789618242
Validation loss: 2.465195682523495

Epoch: 6| Step: 12
Training loss: 2.4893068508557326
Validation loss: 2.4596296781872313

Epoch: 6| Step: 13
Training loss: 3.1031622232315548
Validation loss: 2.488748951640055

Epoch: 118| Step: 0
Training loss: 2.926454270576993
Validation loss: 2.4847583966362095

Epoch: 6| Step: 1
Training loss: 3.092839579090274
Validation loss: 2.4658669137302702

Epoch: 6| Step: 2
Training loss: 2.3048672880747834
Validation loss: 2.4737676717779893

Epoch: 6| Step: 3
Training loss: 2.958999039516055
Validation loss: 2.4539698545059876

Epoch: 6| Step: 4
Training loss: 2.873207528649044
Validation loss: 2.458380972093197

Epoch: 6| Step: 5
Training loss: 2.7848331643886683
Validation loss: 2.4801031560098545

Epoch: 6| Step: 6
Training loss: 2.2438759643559414
Validation loss: 2.4609106866795503

Epoch: 6| Step: 7
Training loss: 2.262079029014747
Validation loss: 2.454484142820609

Epoch: 6| Step: 8
Training loss: 1.9235511231814015
Validation loss: 2.464761238881128

Epoch: 6| Step: 9
Training loss: 2.862910851724495
Validation loss: 2.471049717290331

Epoch: 6| Step: 10
Training loss: 2.774686977843124
Validation loss: 2.458907087713206

Epoch: 6| Step: 11
Training loss: 2.1969167474765667
Validation loss: 2.475904380447803

Epoch: 6| Step: 12
Training loss: 2.795383503216278
Validation loss: 2.469815278921429

Epoch: 6| Step: 13
Training loss: 1.4827508975900838
Validation loss: 2.4799643341740607

Epoch: 119| Step: 0
Training loss: 2.2957487913467296
Validation loss: 2.4638094539372477

Epoch: 6| Step: 1
Training loss: 2.762782041901508
Validation loss: 2.4943210016450332

Epoch: 6| Step: 2
Training loss: 2.4620242671064982
Validation loss: 2.4706422722335475

Epoch: 6| Step: 3
Training loss: 2.8126260517271486
Validation loss: 2.4713385767432934

Epoch: 6| Step: 4
Training loss: 1.9729686527459116
Validation loss: 2.4587353488362926

Epoch: 6| Step: 5
Training loss: 3.0272240399718675
Validation loss: 2.4865889154750573

Epoch: 6| Step: 6
Training loss: 2.8858960209102924
Validation loss: 2.4573557247998115

Epoch: 6| Step: 7
Training loss: 2.1176455519552415
Validation loss: 2.4837462566786876

Epoch: 6| Step: 8
Training loss: 2.2794558642064633
Validation loss: 2.453364848893446

Epoch: 6| Step: 9
Training loss: 2.7162216531930716
Validation loss: 2.456041081472245

Epoch: 6| Step: 10
Training loss: 2.757846648353338
Validation loss: 2.4707758582039894

Epoch: 6| Step: 11
Training loss: 3.1390960159904986
Validation loss: 2.4641054976337355

Epoch: 6| Step: 12
Training loss: 1.9481323517167148
Validation loss: 2.476159800025968

Epoch: 6| Step: 13
Training loss: 3.2660504661721026
Validation loss: 2.4578030679852154

Epoch: 120| Step: 0
Training loss: 2.065092134059825
Validation loss: 2.4626900006982138

Epoch: 6| Step: 1
Training loss: 2.808812415427309
Validation loss: 2.484912824676566

Epoch: 6| Step: 2
Training loss: 2.3831642766717724
Validation loss: 2.4618384281755734

Epoch: 6| Step: 3
Training loss: 2.722446077791877
Validation loss: 2.4889366397046797

Epoch: 6| Step: 4
Training loss: 2.5563835090524316
Validation loss: 2.4759544784784784

Epoch: 6| Step: 5
Training loss: 2.6339816884741785
Validation loss: 2.4833979843152334

Epoch: 6| Step: 6
Training loss: 2.8554188192988357
Validation loss: 2.4737146556557232

Epoch: 6| Step: 7
Training loss: 2.7499094861480144
Validation loss: 2.4793367590342212

Epoch: 6| Step: 8
Training loss: 2.4267976016921677
Validation loss: 2.4771166538242024

Epoch: 6| Step: 9
Training loss: 2.9946177202653668
Validation loss: 2.486074873094392

Epoch: 6| Step: 10
Training loss: 2.685036173031619
Validation loss: 2.477847580725328

Epoch: 6| Step: 11
Training loss: 2.5301450978765216
Validation loss: 2.459515951596969

Epoch: 6| Step: 12
Training loss: 2.367656598334978
Validation loss: 2.4708374204838552

Epoch: 6| Step: 13
Training loss: 2.5294236552745666
Validation loss: 2.4809776527606004

Epoch: 121| Step: 0
Training loss: 2.1761886242708286
Validation loss: 2.4790010065157446

Epoch: 6| Step: 1
Training loss: 1.4924726762938216
Validation loss: 2.4806913769943804

Epoch: 6| Step: 2
Training loss: 2.9350081893052806
Validation loss: 2.482475250432722

Epoch: 6| Step: 3
Training loss: 3.095657069107326
Validation loss: 2.4615506857724463

Epoch: 6| Step: 4
Training loss: 2.5779219113901775
Validation loss: 2.480146433874882

Epoch: 6| Step: 5
Training loss: 2.873427417067427
Validation loss: 2.4613418697430505

Epoch: 6| Step: 6
Training loss: 2.4668401743032806
Validation loss: 2.470885494813016

Epoch: 6| Step: 7
Training loss: 2.9931664521299597
Validation loss: 2.488916708845804

Epoch: 6| Step: 8
Training loss: 2.672370552375112
Validation loss: 2.4709166327254404

Epoch: 6| Step: 9
Training loss: 2.8415730286624132
Validation loss: 2.4531771464435956

Epoch: 6| Step: 10
Training loss: 2.440420504121877
Validation loss: 2.4688277008427266

Epoch: 6| Step: 11
Training loss: 2.8638304304719355
Validation loss: 2.4704365855118913

Epoch: 6| Step: 12
Training loss: 2.2884007040813867
Validation loss: 2.432826062234325

Epoch: 6| Step: 13
Training loss: 1.8263712238703258
Validation loss: 2.476731316565076

Epoch: 122| Step: 0
Training loss: 2.6823517925350537
Validation loss: 2.459902754793327

Epoch: 6| Step: 1
Training loss: 2.561797161943953
Validation loss: 2.4597545441562927

Epoch: 6| Step: 2
Training loss: 2.6085561963828763
Validation loss: 2.477278696720929

Epoch: 6| Step: 3
Training loss: 1.8948116763503486
Validation loss: 2.485147196372405

Epoch: 6| Step: 4
Training loss: 2.799625685058706
Validation loss: 2.4630683014536667

Epoch: 6| Step: 5
Training loss: 2.4363373159749275
Validation loss: 2.480690168905111

Epoch: 6| Step: 6
Training loss: 2.8349977728079736
Validation loss: 2.4758485294331196

Epoch: 6| Step: 7
Training loss: 2.856854104028433
Validation loss: 2.4899814544993943

Epoch: 6| Step: 8
Training loss: 2.1088966109725447
Validation loss: 2.4793890583337266

Epoch: 6| Step: 9
Training loss: 2.627103779950439
Validation loss: 2.4825781512277225

Epoch: 6| Step: 10
Training loss: 2.7446155720827803
Validation loss: 2.465864405571317

Epoch: 6| Step: 11
Training loss: 2.96351660174255
Validation loss: 2.473532737993256

Epoch: 6| Step: 12
Training loss: 2.4707589003709383
Validation loss: 2.463778660624494

Epoch: 6| Step: 13
Training loss: 2.7643129501606327
Validation loss: 2.4745672476358944

Epoch: 123| Step: 0
Training loss: 2.487316860952493
Validation loss: 2.459026473243398

Epoch: 6| Step: 1
Training loss: 2.3261135552027543
Validation loss: 2.4667661272942114

Epoch: 6| Step: 2
Training loss: 2.115398707042788
Validation loss: 2.461982992240732

Epoch: 6| Step: 3
Training loss: 3.163573578158698
Validation loss: 2.4545792109348743

Epoch: 6| Step: 4
Training loss: 3.0363745091658423
Validation loss: 2.4871163474974844

Epoch: 6| Step: 5
Training loss: 2.3670702612521035
Validation loss: 2.4764279450974067

Epoch: 6| Step: 6
Training loss: 2.7542208444534677
Validation loss: 2.449807070242224

Epoch: 6| Step: 7
Training loss: 2.9087598894096227
Validation loss: 2.486240954695937

Epoch: 6| Step: 8
Training loss: 2.6026543969226026
Validation loss: 2.4691009832742967

Epoch: 6| Step: 9
Training loss: 2.310374752543921
Validation loss: 2.478337806413889

Epoch: 6| Step: 10
Training loss: 2.714086984228579
Validation loss: 2.477280166223988

Epoch: 6| Step: 11
Training loss: 2.6282021201631225
Validation loss: 2.4921356061013156

Epoch: 6| Step: 12
Training loss: 2.45254393092015
Validation loss: 2.4730567910329277

Epoch: 6| Step: 13
Training loss: 1.8877727336765013
Validation loss: 2.4777258500802106

Epoch: 124| Step: 0
Training loss: 1.8788048603832326
Validation loss: 2.4741706134456285

Epoch: 6| Step: 1
Training loss: 3.126173333193072
Validation loss: 2.4642330648459465

Epoch: 6| Step: 2
Training loss: 2.088396887069688
Validation loss: 2.457940702402101

Epoch: 6| Step: 3
Training loss: 2.831845697046342
Validation loss: 2.466622403240187

Epoch: 6| Step: 4
Training loss: 1.82818303464407
Validation loss: 2.46740700769026

Epoch: 6| Step: 5
Training loss: 2.315555924635012
Validation loss: 2.472651395715367

Epoch: 6| Step: 6
Training loss: 2.9156287026662917
Validation loss: 2.463046508414041

Epoch: 6| Step: 7
Training loss: 2.9064225996714343
Validation loss: 2.4690490225878814

Epoch: 6| Step: 8
Training loss: 2.793384014282895
Validation loss: 2.463532109309119

Epoch: 6| Step: 9
Training loss: 2.6703973443049533
Validation loss: 2.4532125146640102

Epoch: 6| Step: 10
Training loss: 3.0487400704472787
Validation loss: 2.484779898139035

Epoch: 6| Step: 11
Training loss: 2.457640749683402
Validation loss: 2.467694027227414

Epoch: 6| Step: 12
Training loss: 2.5426859661797447
Validation loss: 2.4580008266436937

Epoch: 6| Step: 13
Training loss: 2.4773076136902943
Validation loss: 2.4742590197661527

Epoch: 125| Step: 0
Training loss: 2.482121627262043
Validation loss: 2.463098885075205

Epoch: 6| Step: 1
Training loss: 2.7315884587758963
Validation loss: 2.4709272274010674

Epoch: 6| Step: 2
Training loss: 2.251681758943921
Validation loss: 2.4780609482590545

Epoch: 6| Step: 3
Training loss: 2.707191363466974
Validation loss: 2.4608944208242356

Epoch: 6| Step: 4
Training loss: 2.5142253512406736
Validation loss: 2.4693144919665038

Epoch: 6| Step: 5
Training loss: 2.272981053835194
Validation loss: 2.4680979750204033

Epoch: 6| Step: 6
Training loss: 2.6367362014758124
Validation loss: 2.450450934448382

Epoch: 6| Step: 7
Training loss: 2.842253909769086
Validation loss: 2.4690070614900654

Epoch: 6| Step: 8
Training loss: 2.7453957941818565
Validation loss: 2.472578112692425

Epoch: 6| Step: 9
Training loss: 2.3573630135179524
Validation loss: 2.4403370663693664

Epoch: 6| Step: 10
Training loss: 2.528025327398687
Validation loss: 2.476783230976486

Epoch: 6| Step: 11
Training loss: 2.8095736220164294
Validation loss: 2.480837302409811

Epoch: 6| Step: 12
Training loss: 2.902315491324408
Validation loss: 2.4778818937935103

Epoch: 6| Step: 13
Training loss: 2.324828713783318
Validation loss: 2.4578830752643768

Epoch: 126| Step: 0
Training loss: 1.816357815004435
Validation loss: 2.4732210300023616

Epoch: 6| Step: 1
Training loss: 2.124213914771012
Validation loss: 2.451080491302667

Epoch: 6| Step: 2
Training loss: 3.1803241814009637
Validation loss: 2.4622459338439517

Epoch: 6| Step: 3
Training loss: 3.2667114786720446
Validation loss: 2.4714189201931283

Epoch: 6| Step: 4
Training loss: 2.7614861677722313
Validation loss: 2.462499412668559

Epoch: 6| Step: 5
Training loss: 2.5058198897476123
Validation loss: 2.4781271493346866

Epoch: 6| Step: 6
Training loss: 2.413376596530199
Validation loss: 2.464046175212966

Epoch: 6| Step: 7
Training loss: 2.2851226543337058
Validation loss: 2.473802040400558

Epoch: 6| Step: 8
Training loss: 2.78373590021284
Validation loss: 2.462458282670353

Epoch: 6| Step: 9
Training loss: 2.734824269034707
Validation loss: 2.487197571742274

Epoch: 6| Step: 10
Training loss: 2.3388304896651246
Validation loss: 2.4617024634071183

Epoch: 6| Step: 11
Training loss: 1.714575118658968
Validation loss: 2.495699620157875

Epoch: 6| Step: 12
Training loss: 2.995291352533182
Validation loss: 2.4567242791940025

Epoch: 6| Step: 13
Training loss: 2.877762006800709
Validation loss: 2.47538500147113

Epoch: 127| Step: 0
Training loss: 2.517823768866061
Validation loss: 2.4737290536606085

Epoch: 6| Step: 1
Training loss: 2.557055947394
Validation loss: 2.48500104226609

Epoch: 6| Step: 2
Training loss: 2.4322495276471923
Validation loss: 2.4790445998981974

Epoch: 6| Step: 3
Training loss: 3.105695838542552
Validation loss: 2.4821241649546977

Epoch: 6| Step: 4
Training loss: 1.8686753733351933
Validation loss: 2.477849801027489

Epoch: 6| Step: 5
Training loss: 2.839238539147025
Validation loss: 2.479118834444556

Epoch: 6| Step: 6
Training loss: 2.437896011657094
Validation loss: 2.456597545131008

Epoch: 6| Step: 7
Training loss: 2.427420094802379
Validation loss: 2.4615684886618223

Epoch: 6| Step: 8
Training loss: 3.2000136732762994
Validation loss: 2.45988156839691

Epoch: 6| Step: 9
Training loss: 2.4757981910980615
Validation loss: 2.4588470231659834

Epoch: 6| Step: 10
Training loss: 2.496128708858773
Validation loss: 2.4575491903057967

Epoch: 6| Step: 11
Training loss: 2.320804222741636
Validation loss: 2.464056550250112

Epoch: 6| Step: 12
Training loss: 2.4347348301061715
Validation loss: 2.4764555640188726

Epoch: 6| Step: 13
Training loss: 3.1829475355459578
Validation loss: 2.47171889357025

Epoch: 128| Step: 0
Training loss: 2.6230692347683435
Validation loss: 2.4793730801772296

Epoch: 6| Step: 1
Training loss: 2.7759985046657527
Validation loss: 2.4821764272129507

Epoch: 6| Step: 2
Training loss: 2.419959313547158
Validation loss: 2.4809519539911062

Epoch: 6| Step: 3
Training loss: 2.5586140639102943
Validation loss: 2.4688881829830396

Epoch: 6| Step: 4
Training loss: 2.4432573060840133
Validation loss: 2.475756207187069

Epoch: 6| Step: 5
Training loss: 2.253191380045442
Validation loss: 2.49536629374825

Epoch: 6| Step: 6
Training loss: 2.653202687486391
Validation loss: 2.486972424373927

Epoch: 6| Step: 7
Training loss: 2.673063225914252
Validation loss: 2.485020756937182

Epoch: 6| Step: 8
Training loss: 2.653335228668507
Validation loss: 2.46965284701431

Epoch: 6| Step: 9
Training loss: 2.375449188318487
Validation loss: 2.4815059106797337

Epoch: 6| Step: 10
Training loss: 2.5274632704242226
Validation loss: 2.4685450684702

Epoch: 6| Step: 11
Training loss: 3.1572458943307007
Validation loss: 2.4787201334934386

Epoch: 6| Step: 12
Training loss: 2.6349829717733746
Validation loss: 2.4852873590352327

Epoch: 6| Step: 13
Training loss: 2.016088979384747
Validation loss: 2.477149594370269

Epoch: 129| Step: 0
Training loss: 2.0029323062665716
Validation loss: 2.46914251760379

Epoch: 6| Step: 1
Training loss: 2.6824890261636263
Validation loss: 2.4727743393055728

Epoch: 6| Step: 2
Training loss: 3.583959229092644
Validation loss: 2.4678505935864767

Epoch: 6| Step: 3
Training loss: 2.319728379627456
Validation loss: 2.4744913680870733

Epoch: 6| Step: 4
Training loss: 2.4946472083671205
Validation loss: 2.4595173504107284

Epoch: 6| Step: 5
Training loss: 2.622353900370864
Validation loss: 2.473514138171586

Epoch: 6| Step: 6
Training loss: 2.785991869709888
Validation loss: 2.470746731457407

Epoch: 6| Step: 7
Training loss: 2.5340734676378243
Validation loss: 2.4653049521994865

Epoch: 6| Step: 8
Training loss: 2.4254334917671603
Validation loss: 2.458058643445746

Epoch: 6| Step: 9
Training loss: 2.2488784113846383
Validation loss: 2.4585432425666864

Epoch: 6| Step: 10
Training loss: 2.6756511573074295
Validation loss: 2.4596725262425636

Epoch: 6| Step: 11
Training loss: 2.444548758775984
Validation loss: 2.4709697311872834

Epoch: 6| Step: 12
Training loss: 2.252686803694817
Validation loss: 2.458328998604261

Epoch: 6| Step: 13
Training loss: 2.880634260272393
Validation loss: 2.465336082085248

Epoch: 130| Step: 0
Training loss: 2.8782179694221206
Validation loss: 2.4544180331021557

Epoch: 6| Step: 1
Training loss: 2.413863683124378
Validation loss: 2.4719057610693542

Epoch: 6| Step: 2
Training loss: 2.0242813295020183
Validation loss: 2.487914904944632

Epoch: 6| Step: 3
Training loss: 1.9789981837252262
Validation loss: 2.4673887274226414

Epoch: 6| Step: 4
Training loss: 2.7995359240552147
Validation loss: 2.482480549186883

Epoch: 6| Step: 5
Training loss: 2.387490205594889
Validation loss: 2.4794676944270733

Epoch: 6| Step: 6
Training loss: 2.6197399844664275
Validation loss: 2.4717392701092065

Epoch: 6| Step: 7
Training loss: 2.0871511064998445
Validation loss: 2.482342997878593

Epoch: 6| Step: 8
Training loss: 2.7433175478265164
Validation loss: 2.4624183263539776

Epoch: 6| Step: 9
Training loss: 2.6102754786599456
Validation loss: 2.4769024473125936

Epoch: 6| Step: 10
Training loss: 3.285433472901011
Validation loss: 2.4651273371181763

Epoch: 6| Step: 11
Training loss: 2.4451552270398027
Validation loss: 2.4766876571052405

Epoch: 6| Step: 12
Training loss: 3.0039430772287394
Validation loss: 2.4906669929056275

Epoch: 6| Step: 13
Training loss: 2.325392585342173
Validation loss: 2.4686130201667225

Epoch: 131| Step: 0
Training loss: 2.4191522860080448
Validation loss: 2.4723153071638198

Epoch: 6| Step: 1
Training loss: 3.142281015029845
Validation loss: 2.4810400489264675

Epoch: 6| Step: 2
Training loss: 2.3962282822748597
Validation loss: 2.463631197213435

Epoch: 6| Step: 3
Training loss: 2.1156296294709667
Validation loss: 2.460406092993455

Epoch: 6| Step: 4
Training loss: 2.4752645370446427
Validation loss: 2.4764161249599814

Epoch: 6| Step: 5
Training loss: 2.407797674867414
Validation loss: 2.4586277078611136

Epoch: 6| Step: 6
Training loss: 3.1792282785134214
Validation loss: 2.47042838018483

Epoch: 6| Step: 7
Training loss: 2.7468642650129755
Validation loss: 2.4520171484026787

Epoch: 6| Step: 8
Training loss: 2.9048025156676824
Validation loss: 2.4696404847615434

Epoch: 6| Step: 9
Training loss: 2.7110367902442527
Validation loss: 2.4592107722867835

Epoch: 6| Step: 10
Training loss: 2.0494232622509254
Validation loss: 2.480959031254187

Epoch: 6| Step: 11
Training loss: 2.1660150746378357
Validation loss: 2.4616692942871494

Epoch: 6| Step: 12
Training loss: 2.2396235144507464
Validation loss: 2.471379414761854

Epoch: 6| Step: 13
Training loss: 2.890067381815785
Validation loss: 2.466840805641907

Epoch: 132| Step: 0
Training loss: 3.4583664551646356
Validation loss: 2.47964657338395

Epoch: 6| Step: 1
Training loss: 1.6310888802771508
Validation loss: 2.4471513101956948

Epoch: 6| Step: 2
Training loss: 2.121307755663539
Validation loss: 2.4513589618063816

Epoch: 6| Step: 3
Training loss: 2.7729846853334754
Validation loss: 2.4905239430212682

Epoch: 6| Step: 4
Training loss: 2.7714693204808265
Validation loss: 2.469272172523034

Epoch: 6| Step: 5
Training loss: 1.5545273894862985
Validation loss: 2.4786190852837464

Epoch: 6| Step: 6
Training loss: 2.0572922589908824
Validation loss: 2.439033715729002

Epoch: 6| Step: 7
Training loss: 2.3109711413098166
Validation loss: 2.457752548851031

Epoch: 6| Step: 8
Training loss: 3.4250946922856085
Validation loss: 2.4549228999857458

Epoch: 6| Step: 9
Training loss: 3.0020740015615957
Validation loss: 2.4533979118953892

Epoch: 6| Step: 10
Training loss: 2.1993187022829197
Validation loss: 2.478688424953109

Epoch: 6| Step: 11
Training loss: 2.4439995991882895
Validation loss: 2.464021955698565

Epoch: 6| Step: 12
Training loss: 2.7926925842759305
Validation loss: 2.4602333953630633

Epoch: 6| Step: 13
Training loss: 2.717179908325049
Validation loss: 2.4733964625042097

Epoch: 133| Step: 0
Training loss: 2.889488367905169
Validation loss: 2.4636476260618134

Epoch: 6| Step: 1
Training loss: 2.140180778354503
Validation loss: 2.465068586841711

Epoch: 6| Step: 2
Training loss: 1.8452554795695884
Validation loss: 2.457842764512846

Epoch: 6| Step: 3
Training loss: 3.0618151463399035
Validation loss: 2.4724032535971014

Epoch: 6| Step: 4
Training loss: 2.579968619784172
Validation loss: 2.4697349445465457

Epoch: 6| Step: 5
Training loss: 2.5908579501895317
Validation loss: 2.48298505630038

Epoch: 6| Step: 6
Training loss: 2.7947284836842146
Validation loss: 2.458150103543191

Epoch: 6| Step: 7
Training loss: 2.4226823014990186
Validation loss: 2.480958626190178

Epoch: 6| Step: 8
Training loss: 3.0138096855136034
Validation loss: 2.4799626341865197

Epoch: 6| Step: 9
Training loss: 2.256402337592797
Validation loss: 2.46704875251946

Epoch: 6| Step: 10
Training loss: 2.5168963708531527
Validation loss: 2.4727872965318785

Epoch: 6| Step: 11
Training loss: 2.642966592208789
Validation loss: 2.458820307994102

Epoch: 6| Step: 12
Training loss: 2.5719065259852973
Validation loss: 2.4645085793755204

Epoch: 6| Step: 13
Training loss: 2.32367439627202
Validation loss: 2.4719044263071472

Epoch: 134| Step: 0
Training loss: 2.7680037446465273
Validation loss: 2.4827414789584856

Epoch: 6| Step: 1
Training loss: 2.8943843006305032
Validation loss: 2.4934279062015747

Epoch: 6| Step: 2
Training loss: 2.320579950094168
Validation loss: 2.4876544410374692

Epoch: 6| Step: 3
Training loss: 2.4285295186313403
Validation loss: 2.4611888449181563

Epoch: 6| Step: 4
Training loss: 2.73702290527549
Validation loss: 2.4667530043734565

Epoch: 6| Step: 5
Training loss: 2.4389725174272425
Validation loss: 2.453813013142763

Epoch: 6| Step: 6
Training loss: 2.233631250334191
Validation loss: 2.4573135551594043

Epoch: 6| Step: 7
Training loss: 2.6943120454155434
Validation loss: 2.4697261420993932

Epoch: 6| Step: 8
Training loss: 2.6979841619073364
Validation loss: 2.4518352028543573

Epoch: 6| Step: 9
Training loss: 2.5927221260812523
Validation loss: 2.475623734452969

Epoch: 6| Step: 10
Training loss: 2.4528684056686254
Validation loss: 2.4679609153693396

Epoch: 6| Step: 11
Training loss: 2.722882342152621
Validation loss: 2.4786216110479025

Epoch: 6| Step: 12
Training loss: 2.34485193415472
Validation loss: 2.4635587156308927

Epoch: 6| Step: 13
Training loss: 2.4400421970658446
Validation loss: 2.4858756176589756

Epoch: 135| Step: 0
Training loss: 2.6138009551019463
Validation loss: 2.4478582734365384

Epoch: 6| Step: 1
Training loss: 2.5839053002769976
Validation loss: 2.459966479630907

Epoch: 6| Step: 2
Training loss: 2.5464476244364036
Validation loss: 2.4607369060705206

Epoch: 6| Step: 3
Training loss: 2.1325166937296514
Validation loss: 2.490483436426934

Epoch: 6| Step: 4
Training loss: 3.3818081604854777
Validation loss: 2.439174976900666

Epoch: 6| Step: 5
Training loss: 2.562454409310043
Validation loss: 2.4690832139307144

Epoch: 6| Step: 6
Training loss: 2.356049372785548
Validation loss: 2.464997908274693

Epoch: 6| Step: 7
Training loss: 3.051586870212388
Validation loss: 2.4509218824582293

Epoch: 6| Step: 8
Training loss: 2.243514037409498
Validation loss: 2.4662707481103827

Epoch: 6| Step: 9
Training loss: 2.2932599742193838
Validation loss: 2.4590177951008334

Epoch: 6| Step: 10
Training loss: 2.7091348684653314
Validation loss: 2.468719206005655

Epoch: 6| Step: 11
Training loss: 2.069262198574109
Validation loss: 2.4630715321944905

Epoch: 6| Step: 12
Training loss: 2.7789493431973322
Validation loss: 2.46832899328125

Epoch: 6| Step: 13
Training loss: 2.0013258830640672
Validation loss: 2.464285274804423

Epoch: 136| Step: 0
Training loss: 3.2280485781166095
Validation loss: 2.4797319791609094

Epoch: 6| Step: 1
Training loss: 1.842982633569937
Validation loss: 2.4822660826036

Epoch: 6| Step: 2
Training loss: 2.905869325707186
Validation loss: 2.452023119377985

Epoch: 6| Step: 3
Training loss: 2.7318214918493626
Validation loss: 2.441691833725336

Epoch: 6| Step: 4
Training loss: 2.6808343774162853
Validation loss: 2.4614329995401096

Epoch: 6| Step: 5
Training loss: 1.9988535336893636
Validation loss: 2.464815586487518

Epoch: 6| Step: 6
Training loss: 2.5295632476168386
Validation loss: 2.4636684054636313

Epoch: 6| Step: 7
Training loss: 2.820934618019465
Validation loss: 2.4627696956756866

Epoch: 6| Step: 8
Training loss: 1.921251273319217
Validation loss: 2.4756764622007092

Epoch: 6| Step: 9
Training loss: 2.4862373137689806
Validation loss: 2.461725630496589

Epoch: 6| Step: 10
Training loss: 3.017652235386462
Validation loss: 2.4939219432349264

Epoch: 6| Step: 11
Training loss: 2.305110879577114
Validation loss: 2.468246420023176

Epoch: 6| Step: 12
Training loss: 2.662245413200331
Validation loss: 2.4723419688005484

Epoch: 6| Step: 13
Training loss: 2.2628164839291336
Validation loss: 2.473865165747985

Epoch: 137| Step: 0
Training loss: 2.340025523771973
Validation loss: 2.4621240794788073

Epoch: 6| Step: 1
Training loss: 2.168687196201486
Validation loss: 2.449202999988012

Epoch: 6| Step: 2
Training loss: 2.6216010840624704
Validation loss: 2.4549880453121546

Epoch: 6| Step: 3
Training loss: 2.037427458612671
Validation loss: 2.465968062925793

Epoch: 6| Step: 4
Training loss: 2.637975864962289
Validation loss: 2.452496697604657

Epoch: 6| Step: 5
Training loss: 2.9295984686992815
Validation loss: 2.487004746804449

Epoch: 6| Step: 6
Training loss: 2.5588896835060155
Validation loss: 2.4815873288890526

Epoch: 6| Step: 7
Training loss: 2.7739463661691106
Validation loss: 2.4784582099039616

Epoch: 6| Step: 8
Training loss: 2.3881763558754816
Validation loss: 2.460423179487879

Epoch: 6| Step: 9
Training loss: 2.3224592456999136
Validation loss: 2.461924434026502

Epoch: 6| Step: 10
Training loss: 2.8007846550275675
Validation loss: 2.469489120780804

Epoch: 6| Step: 11
Training loss: 2.5740370273846427
Validation loss: 2.4555571912613647

Epoch: 6| Step: 12
Training loss: 2.9144820251381747
Validation loss: 2.453804794018262

Epoch: 6| Step: 13
Training loss: 2.748106477981694
Validation loss: 2.461250752195848

Epoch: 138| Step: 0
Training loss: 2.18681324669102
Validation loss: 2.46009666296644

Epoch: 6| Step: 1
Training loss: 2.4426713519086145
Validation loss: 2.4752815018130865

Epoch: 6| Step: 2
Training loss: 2.5002318274775224
Validation loss: 2.4417070085244057

Epoch: 6| Step: 3
Training loss: 3.0898306324290927
Validation loss: 2.4526312504713785

Epoch: 6| Step: 4
Training loss: 2.4387667372152184
Validation loss: 2.4711166487788114

Epoch: 6| Step: 5
Training loss: 1.3884543290063855
Validation loss: 2.442132180591939

Epoch: 6| Step: 6
Training loss: 3.1253358279024046
Validation loss: 2.46442185022509

Epoch: 6| Step: 7
Training loss: 2.6018489645563196
Validation loss: 2.465967580027734

Epoch: 6| Step: 8
Training loss: 2.075571542181837
Validation loss: 2.4723671888349523

Epoch: 6| Step: 9
Training loss: 2.4116849085661185
Validation loss: 2.461215894779833

Epoch: 6| Step: 10
Training loss: 3.1474747238780445
Validation loss: 2.474736559774962

Epoch: 6| Step: 11
Training loss: 2.9991340977019574
Validation loss: 2.473205572779511

Epoch: 6| Step: 12
Training loss: 2.3872064819460146
Validation loss: 2.474425833311768

Epoch: 6| Step: 13
Training loss: 2.328861196978575
Validation loss: 2.4737452226870498

Epoch: 139| Step: 0
Training loss: 2.3271808117764903
Validation loss: 2.483101092323566

Epoch: 6| Step: 1
Training loss: 3.421690217346019
Validation loss: 2.483762509641356

Epoch: 6| Step: 2
Training loss: 1.9721508020653584
Validation loss: 2.447636156803646

Epoch: 6| Step: 3
Training loss: 2.503839310392511
Validation loss: 2.475750479840929

Epoch: 6| Step: 4
Training loss: 2.788276967787935
Validation loss: 2.4728836483513494

Epoch: 6| Step: 5
Training loss: 3.2110710023474565
Validation loss: 2.4625178489539983

Epoch: 6| Step: 6
Training loss: 2.7925681940698017
Validation loss: 2.4705549355285767

Epoch: 6| Step: 7
Training loss: 1.9905439590893281
Validation loss: 2.467465512156166

Epoch: 6| Step: 8
Training loss: 2.5808632844987986
Validation loss: 2.463946898505999

Epoch: 6| Step: 9
Training loss: 2.2030769505232355
Validation loss: 2.473104556330057

Epoch: 6| Step: 10
Training loss: 2.2835001886850925
Validation loss: 2.471224104703148

Epoch: 6| Step: 11
Training loss: 2.4989041787804833
Validation loss: 2.4673321204899423

Epoch: 6| Step: 12
Training loss: 1.8631721640589725
Validation loss: 2.4767653883991056

Epoch: 6| Step: 13
Training loss: 2.818158708964265
Validation loss: 2.4629559722883974

Epoch: 140| Step: 0
Training loss: 2.0315220577273374
Validation loss: 2.4690924557912

Epoch: 6| Step: 1
Training loss: 3.0263985419580193
Validation loss: 2.4744755116382913

Epoch: 6| Step: 2
Training loss: 2.928577263590353
Validation loss: 2.4804510073147954

Epoch: 6| Step: 3
Training loss: 2.4584636545929635
Validation loss: 2.473444416097444

Epoch: 6| Step: 4
Training loss: 2.664645223567383
Validation loss: 2.4636867872161354

Epoch: 6| Step: 5
Training loss: 2.5945736599895977
Validation loss: 2.4556510047338596

Epoch: 6| Step: 6
Training loss: 2.1579351060247305
Validation loss: 2.491677342253875

Epoch: 6| Step: 7
Training loss: 2.2710917847804963
Validation loss: 2.4628522006511178

Epoch: 6| Step: 8
Training loss: 2.55403245466458
Validation loss: 2.460929999508539

Epoch: 6| Step: 9
Training loss: 3.0947160850051416
Validation loss: 2.4758749832085734

Epoch: 6| Step: 10
Training loss: 2.5145907912081844
Validation loss: 2.4780764734762726

Epoch: 6| Step: 11
Training loss: 2.4829923032901737
Validation loss: 2.451706648627369

Epoch: 6| Step: 12
Training loss: 2.07550629563228
Validation loss: 2.468403933844009

Epoch: 6| Step: 13
Training loss: 2.639849848089657
Validation loss: 2.470775952105454

Epoch: 141| Step: 0
Training loss: 2.5093559672962837
Validation loss: 2.4605523962651694

Epoch: 6| Step: 1
Training loss: 2.913119329656923
Validation loss: 2.465890433119485

Epoch: 6| Step: 2
Training loss: 2.19616074651564
Validation loss: 2.477194378900959

Epoch: 6| Step: 3
Training loss: 2.4146191594052757
Validation loss: 2.468812751933043

Epoch: 6| Step: 4
Training loss: 2.9765269359957096
Validation loss: 2.5003128594324266

Epoch: 6| Step: 5
Training loss: 2.625866792256425
Validation loss: 2.4675785866588367

Epoch: 6| Step: 6
Training loss: 2.401659463328515
Validation loss: 2.455162298096965

Epoch: 6| Step: 7
Training loss: 2.5518370425175942
Validation loss: 2.47222787816389

Epoch: 6| Step: 8
Training loss: 2.550897148735663
Validation loss: 2.452125991217581

Epoch: 6| Step: 9
Training loss: 2.8910363806721833
Validation loss: 2.4816276604460237

Epoch: 6| Step: 10
Training loss: 2.6283337450077537
Validation loss: 2.452958041157302

Epoch: 6| Step: 11
Training loss: 2.1836310914042163
Validation loss: 2.4506862471610598

Epoch: 6| Step: 12
Training loss: 1.9267297850018958
Validation loss: 2.477363765024617

Epoch: 6| Step: 13
Training loss: 2.8003981579660504
Validation loss: 2.459477021102607

Epoch: 142| Step: 0
Training loss: 1.569990590061246
Validation loss: 2.4632985310881925

Epoch: 6| Step: 1
Training loss: 2.5213415931325636
Validation loss: 2.4620155547556752

Epoch: 6| Step: 2
Training loss: 3.104050567981918
Validation loss: 2.4525934712996813

Epoch: 6| Step: 3
Training loss: 2.5305613770216158
Validation loss: 2.4504099234032504

Epoch: 6| Step: 4
Training loss: 3.0485622331605966
Validation loss: 2.4636599767625027

Epoch: 6| Step: 5
Training loss: 2.6311168247327683
Validation loss: 2.463593061217555

Epoch: 6| Step: 6
Training loss: 2.6777790714153507
Validation loss: 2.4619085804641494

Epoch: 6| Step: 7
Training loss: 2.339244122483841
Validation loss: 2.4950329526049853

Epoch: 6| Step: 8
Training loss: 1.82168828357506
Validation loss: 2.4676140557229838

Epoch: 6| Step: 9
Training loss: 2.392955965063382
Validation loss: 2.4788407314600946

Epoch: 6| Step: 10
Training loss: 2.5951362490303844
Validation loss: 2.4694390696282564

Epoch: 6| Step: 11
Training loss: 2.5390264420516577
Validation loss: 2.4689402176627016

Epoch: 6| Step: 12
Training loss: 2.6361712756279325
Validation loss: 2.490850239955997

Epoch: 6| Step: 13
Training loss: 2.8505608458556524
Validation loss: 2.4722391687312957

Epoch: 143| Step: 0
Training loss: 3.4415412036358424
Validation loss: 2.482449809852537

Epoch: 6| Step: 1
Training loss: 2.782396744477099
Validation loss: 2.4648022982069553

Epoch: 6| Step: 2
Training loss: 2.2000275610151054
Validation loss: 2.468645329591023

Epoch: 6| Step: 3
Training loss: 1.981647930436342
Validation loss: 2.458140829929062

Epoch: 6| Step: 4
Training loss: 2.0685529032971366
Validation loss: 2.482099912686943

Epoch: 6| Step: 5
Training loss: 2.1758700066754235
Validation loss: 2.466688209773305

Epoch: 6| Step: 6
Training loss: 2.4934939604373025
Validation loss: 2.4759694350043167

Epoch: 6| Step: 7
Training loss: 2.384577663303131
Validation loss: 2.4732211782303586

Epoch: 6| Step: 8
Training loss: 2.7559609397810996
Validation loss: 2.4776380439467913

Epoch: 6| Step: 9
Training loss: 2.6312909809464085
Validation loss: 2.4657008836972256

Epoch: 6| Step: 10
Training loss: 2.109520575127146
Validation loss: 2.451393327725746

Epoch: 6| Step: 11
Training loss: 2.6156549777884677
Validation loss: 2.459198571248642

Epoch: 6| Step: 12
Training loss: 2.9019929614832862
Validation loss: 2.455135675443108

Epoch: 6| Step: 13
Training loss: 2.7183218432506577
Validation loss: 2.451586794228441

Epoch: 144| Step: 0
Training loss: 2.125432475343518
Validation loss: 2.45933305609966

Epoch: 6| Step: 1
Training loss: 2.962797602260068
Validation loss: 2.4780505315048456

Epoch: 6| Step: 2
Training loss: 2.3061603559734043
Validation loss: 2.465972557147975

Epoch: 6| Step: 3
Training loss: 2.576183998709863
Validation loss: 2.465935401338465

Epoch: 6| Step: 4
Training loss: 2.7513769343903456
Validation loss: 2.474691956600742

Epoch: 6| Step: 5
Training loss: 2.323880211032723
Validation loss: 2.481045994485689

Epoch: 6| Step: 6
Training loss: 2.055024674167682
Validation loss: 2.4611223100972413

Epoch: 6| Step: 7
Training loss: 2.925472879902482
Validation loss: 2.444045756878862

Epoch: 6| Step: 8
Training loss: 3.09988411717551
Validation loss: 2.467866466631237

Epoch: 6| Step: 9
Training loss: 2.4540370533453433
Validation loss: 2.4535711047553943

Epoch: 6| Step: 10
Training loss: 2.439281106324941
Validation loss: 2.469224958110043

Epoch: 6| Step: 11
Training loss: 2.5361991817822296
Validation loss: 2.447574788667185

Epoch: 6| Step: 12
Training loss: 1.9687430972023705
Validation loss: 2.46238663485693

Epoch: 6| Step: 13
Training loss: 2.829893623482524
Validation loss: 2.4577306346163152

Epoch: 145| Step: 0
Training loss: 2.8742644986293544
Validation loss: 2.4566939303177526

Epoch: 6| Step: 1
Training loss: 2.7804218730956847
Validation loss: 2.452651978961484

Epoch: 6| Step: 2
Training loss: 2.8510363785835557
Validation loss: 2.4553038049366642

Epoch: 6| Step: 3
Training loss: 1.6052919462171737
Validation loss: 2.4691108625753104

Epoch: 6| Step: 4
Training loss: 2.687983092425169
Validation loss: 2.4786440263162848

Epoch: 6| Step: 5
Training loss: 1.6030617744217797
Validation loss: 2.4492312184695963

Epoch: 6| Step: 6
Training loss: 2.6172098187306285
Validation loss: 2.45482241259147

Epoch: 6| Step: 7
Training loss: 3.217043526138909
Validation loss: 2.445992922479586

Epoch: 6| Step: 8
Training loss: 2.3928928962265066
Validation loss: 2.4458079093909633

Epoch: 6| Step: 9
Training loss: 2.260505944054983
Validation loss: 2.4704507286631108

Epoch: 6| Step: 10
Training loss: 2.2526725155966223
Validation loss: 2.4660109832968917

Epoch: 6| Step: 11
Training loss: 2.4470422251573187
Validation loss: 2.4406590653507525

Epoch: 6| Step: 12
Training loss: 2.5915196032569274
Validation loss: 2.4619959630474173

Epoch: 6| Step: 13
Training loss: 2.9672513692770557
Validation loss: 2.466179312660997

Epoch: 146| Step: 0
Training loss: 2.930210239822485
Validation loss: 2.470082995980866

Epoch: 6| Step: 1
Training loss: 2.7341795061254315
Validation loss: 2.4526677758117854

Epoch: 6| Step: 2
Training loss: 2.6227478174991923
Validation loss: 2.4669378090320904

Epoch: 6| Step: 3
Training loss: 2.2859893062872083
Validation loss: 2.455174685217834

Epoch: 6| Step: 4
Training loss: 2.414087980561824
Validation loss: 2.446390076460294

Epoch: 6| Step: 5
Training loss: 1.4277136679842437
Validation loss: 2.4785509538414243

Epoch: 6| Step: 6
Training loss: 2.5827395669432676
Validation loss: 2.443638342457137

Epoch: 6| Step: 7
Training loss: 2.1682339892645692
Validation loss: 2.4902171528088184

Epoch: 6| Step: 8
Training loss: 2.8829168698819436
Validation loss: 2.4718118312535426

Epoch: 6| Step: 9
Training loss: 2.4991882913825623
Validation loss: 2.4657428807841377

Epoch: 6| Step: 10
Training loss: 2.5593789795785225
Validation loss: 2.4690044121932315

Epoch: 6| Step: 11
Training loss: 2.8516186852341536
Validation loss: 2.484524482516991

Epoch: 6| Step: 12
Training loss: 2.6087603730313993
Validation loss: 2.451639661449966

Epoch: 6| Step: 13
Training loss: 2.6954299680018297
Validation loss: 2.464735739235181

Epoch: 147| Step: 0
Training loss: 2.3210094702386503
Validation loss: 2.460510803410123

Epoch: 6| Step: 1
Training loss: 2.4348470482384372
Validation loss: 2.460410907878209

Epoch: 6| Step: 2
Training loss: 1.8701069883860264
Validation loss: 2.4639145170662102

Epoch: 6| Step: 3
Training loss: 3.009073047799709
Validation loss: 2.4579627451382

Epoch: 6| Step: 4
Training loss: 2.980347957138172
Validation loss: 2.4582064880744494

Epoch: 6| Step: 5
Training loss: 2.638289281975762
Validation loss: 2.4713921822095593

Epoch: 6| Step: 6
Training loss: 2.446408839539001
Validation loss: 2.4765396135221884

Epoch: 6| Step: 7
Training loss: 2.000586185382685
Validation loss: 2.468968516874224

Epoch: 6| Step: 8
Training loss: 2.905178569879687
Validation loss: 2.468015009697092

Epoch: 6| Step: 9
Training loss: 2.7136342819331354
Validation loss: 2.460526899886747

Epoch: 6| Step: 10
Training loss: 3.1045949414321687
Validation loss: 2.462450121552504

Epoch: 6| Step: 11
Training loss: 2.205095748898515
Validation loss: 2.460194717455732

Epoch: 6| Step: 12
Training loss: 2.179501323884202
Validation loss: 2.478832336767362

Epoch: 6| Step: 13
Training loss: 2.053584858157393
Validation loss: 2.468903005792945

Epoch: 148| Step: 0
Training loss: 2.42884483321103
Validation loss: 2.465067055979565

Epoch: 6| Step: 1
Training loss: 2.870973005805007
Validation loss: 2.465381056256094

Epoch: 6| Step: 2
Training loss: 2.455406148842575
Validation loss: 2.460825359018098

Epoch: 6| Step: 3
Training loss: 2.117811498147796
Validation loss: 2.4837684409424625

Epoch: 6| Step: 4
Training loss: 2.3602751978751524
Validation loss: 2.475480266795545

Epoch: 6| Step: 5
Training loss: 3.29932590882391
Validation loss: 2.459350587859435

Epoch: 6| Step: 6
Training loss: 2.814547662252466
Validation loss: 2.4550218879107097

Epoch: 6| Step: 7
Training loss: 2.227744233927148
Validation loss: 2.462246789693567

Epoch: 6| Step: 8
Training loss: 2.1143898585713896
Validation loss: 2.4659980455640036

Epoch: 6| Step: 9
Training loss: 2.5277341750393503
Validation loss: 2.4608524482953955

Epoch: 6| Step: 10
Training loss: 2.17200881216464
Validation loss: 2.4641464258745582

Epoch: 6| Step: 11
Training loss: 2.6094276285860323
Validation loss: 2.4603152981947676

Epoch: 6| Step: 12
Training loss: 2.8646052319238726
Validation loss: 2.466140522698664

Epoch: 6| Step: 13
Training loss: 1.878727450359193
Validation loss: 2.4715676646550193

Epoch: 149| Step: 0
Training loss: 2.3230018315006284
Validation loss: 2.4505439359583203

Epoch: 6| Step: 1
Training loss: 2.4702761797614605
Validation loss: 2.450944976770342

Epoch: 6| Step: 2
Training loss: 2.853098834315773
Validation loss: 2.463924890576798

Epoch: 6| Step: 3
Training loss: 2.893697229814639
Validation loss: 2.457406189498051

Epoch: 6| Step: 4
Training loss: 2.299332530154896
Validation loss: 2.466382729854301

Epoch: 6| Step: 5
Training loss: 2.3159780379919273
Validation loss: 2.4556365571079333

Epoch: 6| Step: 6
Training loss: 2.7537609738387965
Validation loss: 2.450898447978413

Epoch: 6| Step: 7
Training loss: 2.401700065410566
Validation loss: 2.4530575765657274

Epoch: 6| Step: 8
Training loss: 2.876712289170665
Validation loss: 2.4532425048057673

Epoch: 6| Step: 9
Training loss: 3.1144416972502937
Validation loss: 2.448157318336788

Epoch: 6| Step: 10
Training loss: 2.0018362913697683
Validation loss: 2.432853540201916

Epoch: 6| Step: 11
Training loss: 2.246094599184622
Validation loss: 2.460013494490414

Epoch: 6| Step: 12
Training loss: 2.2675369088093142
Validation loss: 2.4616186128832265

Epoch: 6| Step: 13
Training loss: 1.75195087955803
Validation loss: 2.448003906566584

Epoch: 150| Step: 0
Training loss: 2.8726460315314077
Validation loss: 2.4481320818965187

Epoch: 6| Step: 1
Training loss: 2.7618335662240714
Validation loss: 2.4679919608552243

Epoch: 6| Step: 2
Training loss: 2.848012559155836
Validation loss: 2.4500481521900532

Epoch: 6| Step: 3
Training loss: 2.6653366845252817
Validation loss: 2.485384860134925

Epoch: 6| Step: 4
Training loss: 2.0973861776211296
Validation loss: 2.443009371597702

Epoch: 6| Step: 5
Training loss: 2.366702291283208
Validation loss: 2.472303694973014

Epoch: 6| Step: 6
Training loss: 2.4722601164962725
Validation loss: 2.468038678968549

Epoch: 6| Step: 7
Training loss: 2.6611862093266696
Validation loss: 2.4709339277071685

Epoch: 6| Step: 8
Training loss: 2.158794505020055
Validation loss: 2.473045878422829

Epoch: 6| Step: 9
Training loss: 2.4004747517232685
Validation loss: 2.464880612325244

Epoch: 6| Step: 10
Training loss: 2.415159106018743
Validation loss: 2.4701146416648445

Epoch: 6| Step: 11
Training loss: 2.398952565508551
Validation loss: 2.455620532974237

Epoch: 6| Step: 12
Training loss: 2.1820255988321358
Validation loss: 2.4790360259575484

Epoch: 6| Step: 13
Training loss: 2.886396294574939
Validation loss: 2.48501728856944

Epoch: 151| Step: 0
Training loss: 2.7347200884363225
Validation loss: 2.4415081190944847

Epoch: 6| Step: 1
Training loss: 3.079535766146116
Validation loss: 2.4588718775135066

Epoch: 6| Step: 2
Training loss: 2.24367790000067
Validation loss: 2.463317971938537

Epoch: 6| Step: 3
Training loss: 2.2377586087430026
Validation loss: 2.4632370176866303

Epoch: 6| Step: 4
Training loss: 2.0797937333096312
Validation loss: 2.468883316097781

Epoch: 6| Step: 5
Training loss: 2.4138179519389067
Validation loss: 2.4550244985180583

Epoch: 6| Step: 6
Training loss: 1.8120192843962577
Validation loss: 2.4955991361854397

Epoch: 6| Step: 7
Training loss: 2.5602428450736334
Validation loss: 2.4514496846572236

Epoch: 6| Step: 8
Training loss: 2.457425375471895
Validation loss: 2.4673112379070483

Epoch: 6| Step: 9
Training loss: 2.2743427794486424
Validation loss: 2.4468635369071374

Epoch: 6| Step: 10
Training loss: 2.3193032481248963
Validation loss: 2.4319395236518595

Epoch: 6| Step: 11
Training loss: 2.8328642363329277
Validation loss: 2.4593756648812493

Epoch: 6| Step: 12
Training loss: 2.797817902420778
Validation loss: 2.4476705021992484

Epoch: 6| Step: 13
Training loss: 3.3933685032109295
Validation loss: 2.4483990380966856

Epoch: 152| Step: 0
Training loss: 2.34873757237775
Validation loss: 2.4569950347265515

Epoch: 6| Step: 1
Training loss: 2.0127699392551404
Validation loss: 2.4391774930598484

Epoch: 6| Step: 2
Training loss: 2.7386216674433395
Validation loss: 2.4488482739295665

Epoch: 6| Step: 3
Training loss: 2.6834348939745483
Validation loss: 2.4405521649544513

Epoch: 6| Step: 4
Training loss: 2.095154248661323
Validation loss: 2.454372553044047

Epoch: 6| Step: 5
Training loss: 3.041694188102339
Validation loss: 2.460693592095261

Epoch: 6| Step: 6
Training loss: 1.951716044534566
Validation loss: 2.464494733957009

Epoch: 6| Step: 7
Training loss: 2.2329643438134403
Validation loss: 2.4425174995336483

Epoch: 6| Step: 8
Training loss: 2.920141021772088
Validation loss: 2.46499055950102

Epoch: 6| Step: 9
Training loss: 2.400124916163677
Validation loss: 2.4555021877141385

Epoch: 6| Step: 10
Training loss: 1.9990869464485679
Validation loss: 2.467753680616312

Epoch: 6| Step: 11
Training loss: 3.2011300177918587
Validation loss: 2.4645188609267383

Epoch: 6| Step: 12
Training loss: 2.587746900490095
Validation loss: 2.4512441811010355

Epoch: 6| Step: 13
Training loss: 2.521023188816117
Validation loss: 2.4677185296354747

Epoch: 153| Step: 0
Training loss: 2.636244532008354
Validation loss: 2.4436376857154145

Epoch: 6| Step: 1
Training loss: 2.2155607701126168
Validation loss: 2.4693790229977646

Epoch: 6| Step: 2
Training loss: 2.211867174068424
Validation loss: 2.4461537247955354

Epoch: 6| Step: 3
Training loss: 1.7778391388727737
Validation loss: 2.4549248935261483

Epoch: 6| Step: 4
Training loss: 1.8130057056924258
Validation loss: 2.4545659737702796

Epoch: 6| Step: 5
Training loss: 2.2508498811966793
Validation loss: 2.4482325433655765

Epoch: 6| Step: 6
Training loss: 2.8483263020198932
Validation loss: 2.4367978399617782

Epoch: 6| Step: 7
Training loss: 2.1072141529056925
Validation loss: 2.455511813998063

Epoch: 6| Step: 8
Training loss: 2.592158737161005
Validation loss: 2.4573595003249578

Epoch: 6| Step: 9
Training loss: 2.772587519675484
Validation loss: 2.444160699418328

Epoch: 6| Step: 10
Training loss: 2.099190887618349
Validation loss: 2.4472965747599518

Epoch: 6| Step: 11
Training loss: 3.206502185444256
Validation loss: 2.457765598831532

Epoch: 6| Step: 12
Training loss: 2.9214549043130154
Validation loss: 2.4587272483480005

Epoch: 6| Step: 13
Training loss: 3.377799250788224
Validation loss: 2.4591646876141113

Epoch: 154| Step: 0
Training loss: 2.9497727840011487
Validation loss: 2.4640372608862307

Epoch: 6| Step: 1
Training loss: 2.135126332960801
Validation loss: 2.464034835659406

Epoch: 6| Step: 2
Training loss: 2.2210305542061515
Validation loss: 2.4522572326708385

Epoch: 6| Step: 3
Training loss: 2.5878908092570687
Validation loss: 2.4501256226626253

Epoch: 6| Step: 4
Training loss: 2.192800802303197
Validation loss: 2.4455898745754365

Epoch: 6| Step: 5
Training loss: 2.021622834554673
Validation loss: 2.453154234081354

Epoch: 6| Step: 6
Training loss: 2.4493275790090703
Validation loss: 2.4691838425455344

Epoch: 6| Step: 7
Training loss: 2.4863432758645803
Validation loss: 2.462580740957171

Epoch: 6| Step: 8
Training loss: 2.2231491963525896
Validation loss: 2.4663641280836712

Epoch: 6| Step: 9
Training loss: 3.3555812972248424
Validation loss: 2.481953295085166

Epoch: 6| Step: 10
Training loss: 2.6311016013733237
Validation loss: 2.470014514914491

Epoch: 6| Step: 11
Training loss: 2.8401731696188617
Validation loss: 2.4557988753017472

Epoch: 6| Step: 12
Training loss: 2.4797525648535883
Validation loss: 2.4645308483873754

Epoch: 6| Step: 13
Training loss: 2.11409587283976
Validation loss: 2.448819981940581

Epoch: 155| Step: 0
Training loss: 2.180009606191486
Validation loss: 2.441385485882803

Epoch: 6| Step: 1
Training loss: 2.525984951575511
Validation loss: 2.4328008379961537

Epoch: 6| Step: 2
Training loss: 1.9884893462097362
Validation loss: 2.467079083125136

Epoch: 6| Step: 3
Training loss: 3.0074529259502367
Validation loss: 2.4601600222276545

Epoch: 6| Step: 4
Training loss: 2.300930258001111
Validation loss: 2.454626161873927

Epoch: 6| Step: 5
Training loss: 2.8678140813135826
Validation loss: 2.4605267071339116

Epoch: 6| Step: 6
Training loss: 2.503228010898795
Validation loss: 2.4708324085480045

Epoch: 6| Step: 7
Training loss: 2.60297875331278
Validation loss: 2.4606774446168798

Epoch: 6| Step: 8
Training loss: 2.4136155588173898
Validation loss: 2.4785392027857283

Epoch: 6| Step: 9
Training loss: 2.291649928176323
Validation loss: 2.451727337357732

Epoch: 6| Step: 10
Training loss: 2.73223584014214
Validation loss: 2.446844904090895

Epoch: 6| Step: 11
Training loss: 2.2741432798568595
Validation loss: 2.4564023927466567

Epoch: 6| Step: 12
Training loss: 2.1571011176532746
Validation loss: 2.4605052541699397

Epoch: 6| Step: 13
Training loss: 3.3108487602032586
Validation loss: 2.439356580381602

Epoch: 156| Step: 0
Training loss: 2.340709494274006
Validation loss: 2.462570032814908

Epoch: 6| Step: 1
Training loss: 2.477997854273424
Validation loss: 2.4631721649432397

Epoch: 6| Step: 2
Training loss: 2.1049874344765573
Validation loss: 2.459894027633393

Epoch: 6| Step: 3
Training loss: 2.6542208831216225
Validation loss: 2.457952537855269

Epoch: 6| Step: 4
Training loss: 3.011276034459958
Validation loss: 2.45342540240619

Epoch: 6| Step: 5
Training loss: 1.8800375976252435
Validation loss: 2.432704621622942

Epoch: 6| Step: 6
Training loss: 2.560476108623557
Validation loss: 2.4611063341809367

Epoch: 6| Step: 7
Training loss: 3.0896823228414765
Validation loss: 2.450048532019926

Epoch: 6| Step: 8
Training loss: 2.2933282781515665
Validation loss: 2.4583770656988833

Epoch: 6| Step: 9
Training loss: 2.5223598009511057
Validation loss: 2.456026784362863

Epoch: 6| Step: 10
Training loss: 2.7958916155391798
Validation loss: 2.466189872073969

Epoch: 6| Step: 11
Training loss: 2.2797954572982904
Validation loss: 2.4590996743048676

Epoch: 6| Step: 12
Training loss: 2.4780783842495997
Validation loss: 2.4329920897222235

Epoch: 6| Step: 13
Training loss: 2.112567661262731
Validation loss: 2.45610945634886

Epoch: 157| Step: 0
Training loss: 2.387434282446939
Validation loss: 2.457896770704132

Epoch: 6| Step: 1
Training loss: 2.45949199548494
Validation loss: 2.44677317941588

Epoch: 6| Step: 2
Training loss: 2.04706473599535
Validation loss: 2.435183013638716

Epoch: 6| Step: 3
Training loss: 2.559612135561828
Validation loss: 2.4622317341934123

Epoch: 6| Step: 4
Training loss: 2.4970898856841894
Validation loss: 2.4524353225177715

Epoch: 6| Step: 5
Training loss: 2.742842549827334
Validation loss: 2.4307966657275726

Epoch: 6| Step: 6
Training loss: 3.2958317412233105
Validation loss: 2.4559174463535562

Epoch: 6| Step: 7
Training loss: 2.7799223399121034
Validation loss: 2.460944670240117

Epoch: 6| Step: 8
Training loss: 2.4629176332715694
Validation loss: 2.472228344802984

Epoch: 6| Step: 9
Training loss: 2.8637908024172725
Validation loss: 2.4455117027187256

Epoch: 6| Step: 10
Training loss: 1.8584612356170849
Validation loss: 2.458168450949845

Epoch: 6| Step: 11
Training loss: 2.1949060681519503
Validation loss: 2.452054681350143

Epoch: 6| Step: 12
Training loss: 2.116103904985371
Validation loss: 2.42778281763113

Epoch: 6| Step: 13
Training loss: 2.134451882358618
Validation loss: 2.4481104009377415

Epoch: 158| Step: 0
Training loss: 2.5328586317658437
Validation loss: 2.4659461988286724

Epoch: 6| Step: 1
Training loss: 1.9820934004732125
Validation loss: 2.4529087286660425

Epoch: 6| Step: 2
Training loss: 2.886100568640942
Validation loss: 2.480108164199255

Epoch: 6| Step: 3
Training loss: 2.268222766491999
Validation loss: 2.445125158150498

Epoch: 6| Step: 4
Training loss: 2.218278001897231
Validation loss: 2.4492970505599363

Epoch: 6| Step: 5
Training loss: 2.572725317219335
Validation loss: 2.452941487412657

Epoch: 6| Step: 6
Training loss: 2.4853707483296796
Validation loss: 2.4346569730924457

Epoch: 6| Step: 7
Training loss: 2.893068672533395
Validation loss: 2.447525463031917

Epoch: 6| Step: 8
Training loss: 2.569107561680255
Validation loss: 2.456032563966566

Epoch: 6| Step: 9
Training loss: 2.0738038763459787
Validation loss: 2.459513532856397

Epoch: 6| Step: 10
Training loss: 3.1331426203970567
Validation loss: 2.441471986472192

Epoch: 6| Step: 11
Training loss: 2.5948950756227527
Validation loss: 2.455985603379442

Epoch: 6| Step: 12
Training loss: 2.3049405233856284
Validation loss: 2.4462503302235103

Epoch: 6| Step: 13
Training loss: 1.8833875608936173
Validation loss: 2.4410836690450077

Epoch: 159| Step: 0
Training loss: 2.9103256688311063
Validation loss: 2.4421175112705487

Epoch: 6| Step: 1
Training loss: 2.5509287395745117
Validation loss: 2.4582431360226478

Epoch: 6| Step: 2
Training loss: 2.3702320625874544
Validation loss: 2.450978317171795

Epoch: 6| Step: 3
Training loss: 2.8270400690316366
Validation loss: 2.4289731329813793

Epoch: 6| Step: 4
Training loss: 2.2856648197100777
Validation loss: 2.443409898994173

Epoch: 6| Step: 5
Training loss: 2.5249165549511834
Validation loss: 2.4607645755660568

Epoch: 6| Step: 6
Training loss: 1.9106027280278688
Validation loss: 2.4472357648411505

Epoch: 6| Step: 7
Training loss: 2.7141859835752373
Validation loss: 2.4623999028578916

Epoch: 6| Step: 8
Training loss: 2.098168678135864
Validation loss: 2.4751186455936933

Epoch: 6| Step: 9
Training loss: 2.9216976009921125
Validation loss: 2.4292417524314693

Epoch: 6| Step: 10
Training loss: 2.2936082302426173
Validation loss: 2.451543532962265

Epoch: 6| Step: 11
Training loss: 2.1384590495917863
Validation loss: 2.458443957412628

Epoch: 6| Step: 12
Training loss: 2.7787856424630943
Validation loss: 2.45740054561556

Epoch: 6| Step: 13
Training loss: 2.359833123400952
Validation loss: 2.466321403559529

Epoch: 160| Step: 0
Training loss: 2.2132557284105334
Validation loss: 2.4487224278183906

Epoch: 6| Step: 1
Training loss: 2.468183235105462
Validation loss: 2.459104973387067

Epoch: 6| Step: 2
Training loss: 2.8312254713061193
Validation loss: 2.4322983915423935

Epoch: 6| Step: 3
Training loss: 2.3989035684747866
Validation loss: 2.4431269584096404

Epoch: 6| Step: 4
Training loss: 3.145012367357642
Validation loss: 2.4549152798218903

Epoch: 6| Step: 5
Training loss: 2.7141678002924823
Validation loss: 2.4640184322822254

Epoch: 6| Step: 6
Training loss: 2.7617548356133446
Validation loss: 2.4616383867218663

Epoch: 6| Step: 7
Training loss: 2.823928163808886
Validation loss: 2.459111914406441

Epoch: 6| Step: 8
Training loss: 2.219631181271245
Validation loss: 2.4449521135692645

Epoch: 6| Step: 9
Training loss: 1.984771328493515
Validation loss: 2.4385999643519654

Epoch: 6| Step: 10
Training loss: 2.4192579342293254
Validation loss: 2.454316422521483

Epoch: 6| Step: 11
Training loss: 2.492583718687404
Validation loss: 2.4570277050815776

Epoch: 6| Step: 12
Training loss: 1.8261524219802803
Validation loss: 2.4583921270777065

Epoch: 6| Step: 13
Training loss: 1.9661291328040897
Validation loss: 2.4443147525225983

Epoch: 161| Step: 0
Training loss: 1.638965021222172
Validation loss: 2.434882614804411

Epoch: 6| Step: 1
Training loss: 2.1259138722741993
Validation loss: 2.4431512549455734

Epoch: 6| Step: 2
Training loss: 2.4346432695960223
Validation loss: 2.467443245733359

Epoch: 6| Step: 3
Training loss: 2.7643543492580176
Validation loss: 2.460116907553758

Epoch: 6| Step: 4
Training loss: 2.8715303465342124
Validation loss: 2.4654832428413456

Epoch: 6| Step: 5
Training loss: 2.7633338532794363
Validation loss: 2.4383579129531534

Epoch: 6| Step: 6
Training loss: 3.2079687200338816
Validation loss: 2.4524373886409983

Epoch: 6| Step: 7
Training loss: 2.4188958333529587
Validation loss: 2.445722607224613

Epoch: 6| Step: 8
Training loss: 2.190054355800299
Validation loss: 2.445825719956913

Epoch: 6| Step: 9
Training loss: 2.988451664871206
Validation loss: 2.442391417493779

Epoch: 6| Step: 10
Training loss: 1.7688251627665628
Validation loss: 2.453088382186126

Epoch: 6| Step: 11
Training loss: 1.9877527280185936
Validation loss: 2.458964299367924

Epoch: 6| Step: 12
Training loss: 2.5197388556062035
Validation loss: 2.4396003012669003

Epoch: 6| Step: 13
Training loss: 2.477579287156217
Validation loss: 2.439857907457224

Epoch: 162| Step: 0
Training loss: 2.53704105605307
Validation loss: 2.460595239713231

Epoch: 6| Step: 1
Training loss: 2.055639706283857
Validation loss: 2.44804361433558

Epoch: 6| Step: 2
Training loss: 1.9949989974705369
Validation loss: 2.454582177119454

Epoch: 6| Step: 3
Training loss: 1.796561835821868
Validation loss: 2.4501240667690007

Epoch: 6| Step: 4
Training loss: 2.5034864909952486
Validation loss: 2.4505999264023086

Epoch: 6| Step: 5
Training loss: 2.5386936330618606
Validation loss: 2.435417890996213

Epoch: 6| Step: 6
Training loss: 3.4303453375019672
Validation loss: 2.4442427574672947

Epoch: 6| Step: 7
Training loss: 2.379679837530753
Validation loss: 2.446717724834711

Epoch: 6| Step: 8
Training loss: 2.9500123427827893
Validation loss: 2.4390935009182235

Epoch: 6| Step: 9
Training loss: 2.344222161099152
Validation loss: 2.4511222295371002

Epoch: 6| Step: 10
Training loss: 2.57965772901578
Validation loss: 2.4474540505460745

Epoch: 6| Step: 11
Training loss: 1.8572765658526544
Validation loss: 2.43367272287409

Epoch: 6| Step: 12
Training loss: 2.639719610351989
Validation loss: 2.445885040406904

Epoch: 6| Step: 13
Training loss: 2.7075032845122333
Validation loss: 2.44889100337353

Epoch: 163| Step: 0
Training loss: 1.995063889324187
Validation loss: 2.4521158437995516

Epoch: 6| Step: 1
Training loss: 2.6736852748432405
Validation loss: 2.4398223703379878

Epoch: 6| Step: 2
Training loss: 2.381495677859981
Validation loss: 2.4545185245181385

Epoch: 6| Step: 3
Training loss: 2.235550471197472
Validation loss: 2.4284212967475374

Epoch: 6| Step: 4
Training loss: 2.439709957581848
Validation loss: 2.453976671106396

Epoch: 6| Step: 5
Training loss: 2.6140806973879087
Validation loss: 2.4684798618703336

Epoch: 6| Step: 6
Training loss: 2.0425519645738808
Validation loss: 2.442223960002756

Epoch: 6| Step: 7
Training loss: 2.8579781877927997
Validation loss: 2.471687084841065

Epoch: 6| Step: 8
Training loss: 2.7662554523398772
Validation loss: 2.441284979977037

Epoch: 6| Step: 9
Training loss: 2.437656299763937
Validation loss: 2.4376888386053976

Epoch: 6| Step: 10
Training loss: 2.532353196102066
Validation loss: 2.4458187045464355

Epoch: 6| Step: 11
Training loss: 2.6919478050148586
Validation loss: 2.451870749884104

Epoch: 6| Step: 12
Training loss: 2.2240501819616267
Validation loss: 2.461791962606034

Epoch: 6| Step: 13
Training loss: 2.6382843116966153
Validation loss: 2.4525372148677165

Epoch: 164| Step: 0
Training loss: 3.233382657910379
Validation loss: 2.4642128010168785

Epoch: 6| Step: 1
Training loss: 2.7824380458847617
Validation loss: 2.4694707090301287

Epoch: 6| Step: 2
Training loss: 1.900602134860587
Validation loss: 2.454535377828824

Epoch: 6| Step: 3
Training loss: 2.080510999742623
Validation loss: 2.4415228624284095

Epoch: 6| Step: 4
Training loss: 2.0105944408291703
Validation loss: 2.4500960040122877

Epoch: 6| Step: 5
Training loss: 2.321868477525958
Validation loss: 2.449019332737883

Epoch: 6| Step: 6
Training loss: 2.307053621870235
Validation loss: 2.436419556492989

Epoch: 6| Step: 7
Training loss: 3.319501854166443
Validation loss: 2.4376974622720833

Epoch: 6| Step: 8
Training loss: 2.4644814782742013
Validation loss: 2.4314905324489033

Epoch: 6| Step: 9
Training loss: 1.9133696878725455
Validation loss: 2.44696514528465

Epoch: 6| Step: 10
Training loss: 2.125989347041831
Validation loss: 2.4488720232447285

Epoch: 6| Step: 11
Training loss: 2.7520765787215486
Validation loss: 2.447162608557309

Epoch: 6| Step: 12
Training loss: 2.2609701812006104
Validation loss: 2.426903120970785

Epoch: 6| Step: 13
Training loss: 2.0562699754666496
Validation loss: 2.436666553879382

Epoch: 165| Step: 0
Training loss: 2.345096252353044
Validation loss: 2.4434343862932555

Epoch: 6| Step: 1
Training loss: 2.4709850768592343
Validation loss: 2.4274756475269053

Epoch: 6| Step: 2
Training loss: 2.943217455727527
Validation loss: 2.428930213046989

Epoch: 6| Step: 3
Training loss: 2.9636810395106754
Validation loss: 2.444912210889799

Epoch: 6| Step: 4
Training loss: 1.8006177981125702
Validation loss: 2.4492307244213034

Epoch: 6| Step: 5
Training loss: 1.9462339983939538
Validation loss: 2.4426479731392132

Epoch: 6| Step: 6
Training loss: 2.7620719888795313
Validation loss: 2.454855861156258

Epoch: 6| Step: 7
Training loss: 2.3265918573560196
Validation loss: 2.447950446620792

Epoch: 6| Step: 8
Training loss: 2.128950821996137
Validation loss: 2.4390058748597054

Epoch: 6| Step: 9
Training loss: 2.532453651117065
Validation loss: 2.4277986791488537

Epoch: 6| Step: 10
Training loss: 2.2049063116398235
Validation loss: 2.4537660257491716

Epoch: 6| Step: 11
Training loss: 3.081098021188926
Validation loss: 2.4536164549585275

Epoch: 6| Step: 12
Training loss: 2.338487540951846
Validation loss: 2.4660903864311265

Epoch: 6| Step: 13
Training loss: 2.3993198623144805
Validation loss: 2.4597998017235967

Epoch: 166| Step: 0
Training loss: 3.002247921845982
Validation loss: 2.4541758088167356

Epoch: 6| Step: 1
Training loss: 3.174089983188018
Validation loss: 2.418087797802503

Epoch: 6| Step: 2
Training loss: 2.3883051368484676
Validation loss: 2.4507133972544537

Epoch: 6| Step: 3
Training loss: 2.623651612333076
Validation loss: 2.4590985442217255

Epoch: 6| Step: 4
Training loss: 2.343555696698466
Validation loss: 2.449217287734926

Epoch: 6| Step: 5
Training loss: 2.2070044591847404
Validation loss: 2.4382002281970037

Epoch: 6| Step: 6
Training loss: 2.682017389490019
Validation loss: 2.427436862720662

Epoch: 6| Step: 7
Training loss: 2.245491278744199
Validation loss: 2.4293751113028663

Epoch: 6| Step: 8
Training loss: 2.2858679030091227
Validation loss: 2.4463103362241125

Epoch: 6| Step: 9
Training loss: 2.332068566003004
Validation loss: 2.4524176346964435

Epoch: 6| Step: 10
Training loss: 2.249454856105853
Validation loss: 2.4348730862164585

Epoch: 6| Step: 11
Training loss: 2.1570449690501676
Validation loss: 2.4524321451900404

Epoch: 6| Step: 12
Training loss: 2.321020564180892
Validation loss: 2.444455851142623

Epoch: 6| Step: 13
Training loss: 1.994872434357122
Validation loss: 2.4301578570409728

Epoch: 167| Step: 0
Training loss: 1.5480193712022965
Validation loss: 2.461173391292176

Epoch: 6| Step: 1
Training loss: 2.7836081119823155
Validation loss: 2.434265513309515

Epoch: 6| Step: 2
Training loss: 2.8936474643939194
Validation loss: 2.4440530312194912

Epoch: 6| Step: 3
Training loss: 1.890113319955756
Validation loss: 2.4540968887981043

Epoch: 6| Step: 4
Training loss: 1.7921845626474402
Validation loss: 2.4277669502019608

Epoch: 6| Step: 5
Training loss: 2.2821766264728383
Validation loss: 2.448813027452685

Epoch: 6| Step: 6
Training loss: 2.5021289343785127
Validation loss: 2.4461154295072487

Epoch: 6| Step: 7
Training loss: 2.380305337633433
Validation loss: 2.449942513252484

Epoch: 6| Step: 8
Training loss: 2.396429457653159
Validation loss: 2.4337492704337453

Epoch: 6| Step: 9
Training loss: 2.6667198732154356
Validation loss: 2.4560873520969926

Epoch: 6| Step: 10
Training loss: 2.584672047750234
Validation loss: 2.4432710425852613

Epoch: 6| Step: 11
Training loss: 2.9268713678650657
Validation loss: 2.458023409098286

Epoch: 6| Step: 12
Training loss: 2.1555191128174753
Validation loss: 2.4524585400396712

Epoch: 6| Step: 13
Training loss: 3.2525045574604916
Validation loss: 2.4435197043416643

Epoch: 168| Step: 0
Training loss: 2.9079050253322474
Validation loss: 2.4438705389010735

Epoch: 6| Step: 1
Training loss: 3.0293985592016717
Validation loss: 2.4229412747125787

Epoch: 6| Step: 2
Training loss: 2.483743839342668
Validation loss: 2.4510468447855738

Epoch: 6| Step: 3
Training loss: 2.63473449643398
Validation loss: 2.4690743655514784

Epoch: 6| Step: 4
Training loss: 1.7361272260129914
Validation loss: 2.4558762322203114

Epoch: 6| Step: 5
Training loss: 2.40941540477632
Validation loss: 2.449299560507471

Epoch: 6| Step: 6
Training loss: 2.424849424898164
Validation loss: 2.4196969603235043

Epoch: 6| Step: 7
Training loss: 2.0433404121255565
Validation loss: 2.4179881269702443

Epoch: 6| Step: 8
Training loss: 2.8226390763137
Validation loss: 2.434641740662639

Epoch: 6| Step: 9
Training loss: 2.2436361384922114
Validation loss: 2.4307598386391907

Epoch: 6| Step: 10
Training loss: 2.4861020017583697
Validation loss: 2.450383504917161

Epoch: 6| Step: 11
Training loss: 1.7136576728240989
Validation loss: 2.4208566060023413

Epoch: 6| Step: 12
Training loss: 2.7023809213720327
Validation loss: 2.4236690633683717

Epoch: 6| Step: 13
Training loss: 1.9765743210028188
Validation loss: 2.448186397593784

Epoch: 169| Step: 0
Training loss: 1.7589816803967675
Validation loss: 2.436353540593366

Epoch: 6| Step: 1
Training loss: 2.3807279880687395
Validation loss: 2.41433955614233

Epoch: 6| Step: 2
Training loss: 2.901523807988691
Validation loss: 2.4506973283771423

Epoch: 6| Step: 3
Training loss: 2.5776973485274546
Validation loss: 2.459256135766087

Epoch: 6| Step: 4
Training loss: 2.3323713658424774
Validation loss: 2.4709336600272795

Epoch: 6| Step: 5
Training loss: 2.846771982047989
Validation loss: 2.4409825447182563

Epoch: 6| Step: 6
Training loss: 2.5625090249995894
Validation loss: 2.418099728128991

Epoch: 6| Step: 7
Training loss: 2.387775493125874
Validation loss: 2.449580215660788

Epoch: 6| Step: 8
Training loss: 2.548468904284201
Validation loss: 2.432373397187217

Epoch: 6| Step: 9
Training loss: 2.355495674143904
Validation loss: 2.4347463271799645

Epoch: 6| Step: 10
Training loss: 2.5123493358171083
Validation loss: 2.456066018492288

Epoch: 6| Step: 11
Training loss: 2.397167155179848
Validation loss: 2.4423463894655293

Epoch: 6| Step: 12
Training loss: 2.2583209986426103
Validation loss: 2.448359238713074

Epoch: 6| Step: 13
Training loss: 2.5636701935799375
Validation loss: 2.4438872757722074

Epoch: 170| Step: 0
Training loss: 2.1229181750750463
Validation loss: 2.457131999712399

Epoch: 6| Step: 1
Training loss: 2.0520754844657425
Validation loss: 2.424874729206137

Epoch: 6| Step: 2
Training loss: 2.161038375563178
Validation loss: 2.4500129282068017

Epoch: 6| Step: 3
Training loss: 2.5968001482260163
Validation loss: 2.45626850882595

Epoch: 6| Step: 4
Training loss: 3.4945865728210834
Validation loss: 2.4454612127135413

Epoch: 6| Step: 5
Training loss: 2.42038429897488
Validation loss: 2.4343611303789983

Epoch: 6| Step: 6
Training loss: 2.128675087793938
Validation loss: 2.4595008335173194

Epoch: 6| Step: 7
Training loss: 1.915999199566445
Validation loss: 2.4131566948863363

Epoch: 6| Step: 8
Training loss: 1.9900846864901167
Validation loss: 2.421827994216947

Epoch: 6| Step: 9
Training loss: 2.4314302039353066
Validation loss: 2.455388618675542

Epoch: 6| Step: 10
Training loss: 2.3621746908991947
Validation loss: 2.44390081519293

Epoch: 6| Step: 11
Training loss: 3.115033698718656
Validation loss: 2.4336371639081293

Epoch: 6| Step: 12
Training loss: 2.491675058135975
Validation loss: 2.432424694787994

Epoch: 6| Step: 13
Training loss: 2.3133566017336515
Validation loss: 2.445431487248405

Epoch: 171| Step: 0
Training loss: 2.76386114220507
Validation loss: 2.442319560981589

Epoch: 6| Step: 1
Training loss: 2.6682584501962054
Validation loss: 2.4394275720398344

Epoch: 6| Step: 2
Training loss: 2.1028556390499284
Validation loss: 2.4434529360012585

Epoch: 6| Step: 3
Training loss: 2.6530077725270362
Validation loss: 2.4392474620558247

Epoch: 6| Step: 4
Training loss: 2.4041996927709075
Validation loss: 2.439445385050812

Epoch: 6| Step: 5
Training loss: 1.9318609931608335
Validation loss: 2.4291038185350327

Epoch: 6| Step: 6
Training loss: 2.1114557247086156
Validation loss: 2.4322247506633

Epoch: 6| Step: 7
Training loss: 2.350578431710596
Validation loss: 2.43198865098429

Epoch: 6| Step: 8
Training loss: 2.2095460860553664
Validation loss: 2.4241394301561225

Epoch: 6| Step: 9
Training loss: 2.707359217033032
Validation loss: 2.4441649243187435

Epoch: 6| Step: 10
Training loss: 2.2367641240513194
Validation loss: 2.42384352903925

Epoch: 6| Step: 11
Training loss: 2.4610885331567998
Validation loss: 2.437699920537334

Epoch: 6| Step: 12
Training loss: 2.2496232671055365
Validation loss: 2.4367416523159666

Epoch: 6| Step: 13
Training loss: 3.5334409145555656
Validation loss: 2.4595016715600195

Epoch: 172| Step: 0
Training loss: 1.9994170412185062
Validation loss: 2.433442971985814

Epoch: 6| Step: 1
Training loss: 2.587903983603493
Validation loss: 2.4499417106570442

Epoch: 6| Step: 2
Training loss: 2.0460825543645353
Validation loss: 2.4485400730665403

Epoch: 6| Step: 3
Training loss: 2.3514459017111826
Validation loss: 2.455478309376601

Epoch: 6| Step: 4
Training loss: 2.5563322133318693
Validation loss: 2.4342803789676357

Epoch: 6| Step: 5
Training loss: 2.4346728435276446
Validation loss: 2.4570937638873116

Epoch: 6| Step: 6
Training loss: 2.6301098090625517
Validation loss: 2.419378016371095

Epoch: 6| Step: 7
Training loss: 2.960770977239389
Validation loss: 2.451804055256881

Epoch: 6| Step: 8
Training loss: 2.9709474160937845
Validation loss: 2.4699464408953378

Epoch: 6| Step: 9
Training loss: 1.409779083449847
Validation loss: 2.438466868703542

Epoch: 6| Step: 10
Training loss: 2.5931978672148857
Validation loss: 2.4317508869365465

Epoch: 6| Step: 11
Training loss: 2.0626507328324633
Validation loss: 2.4416240714742155

Epoch: 6| Step: 12
Training loss: 2.5800279472375123
Validation loss: 2.4530865209218775

Epoch: 6| Step: 13
Training loss: 2.680817924489221
Validation loss: 2.44990046087376

Epoch: 173| Step: 0
Training loss: 1.7694139589085272
Validation loss: 2.4342406099298115

Epoch: 6| Step: 1
Training loss: 2.6536636326984984
Validation loss: 2.442570080251115

Epoch: 6| Step: 2
Training loss: 2.0237710449557094
Validation loss: 2.4416966120175654

Epoch: 6| Step: 3
Training loss: 2.3043348139504243
Validation loss: 2.457565961286425

Epoch: 6| Step: 4
Training loss: 2.1639767846714917
Validation loss: 2.415802384885438

Epoch: 6| Step: 5
Training loss: 2.2875964576937897
Validation loss: 2.4682461935977753

Epoch: 6| Step: 6
Training loss: 2.1277423441797017
Validation loss: 2.4129734839860055

Epoch: 6| Step: 7
Training loss: 2.548104954580581
Validation loss: 2.425270398119527

Epoch: 6| Step: 8
Training loss: 2.7637667690201426
Validation loss: 2.444861684386812

Epoch: 6| Step: 9
Training loss: 3.227155801752779
Validation loss: 2.4246073636814613

Epoch: 6| Step: 10
Training loss: 1.6661753248120965
Validation loss: 2.4435110398468836

Epoch: 6| Step: 11
Training loss: 2.4416037029528255
Validation loss: 2.456549075349691

Epoch: 6| Step: 12
Training loss: 2.871732430556503
Validation loss: 2.45067313542237

Epoch: 6| Step: 13
Training loss: 3.1193155085600686
Validation loss: 2.4349326534929974

Epoch: 174| Step: 0
Training loss: 2.3946143877989337
Validation loss: 2.438289027668161

Epoch: 6| Step: 1
Training loss: 2.072346390023082
Validation loss: 2.432049827904895

Epoch: 6| Step: 2
Training loss: 2.41543204460976
Validation loss: 2.41284249427231

Epoch: 6| Step: 3
Training loss: 2.664798400009898
Validation loss: 2.4235258501030352

Epoch: 6| Step: 4
Training loss: 2.66085765851
Validation loss: 2.4526000899875275

Epoch: 6| Step: 5
Training loss: 2.3966572768337358
Validation loss: 2.434452635157298

Epoch: 6| Step: 6
Training loss: 2.275869111271429
Validation loss: 2.405425513375648

Epoch: 6| Step: 7
Training loss: 3.0889578030199587
Validation loss: 2.430913908910561

Epoch: 6| Step: 8
Training loss: 2.381912611837321
Validation loss: 2.402927197440541

Epoch: 6| Step: 9
Training loss: 1.6762158379426777
Validation loss: 2.4109716203074725

Epoch: 6| Step: 10
Training loss: 2.065073084426955
Validation loss: 2.4225579491355544

Epoch: 6| Step: 11
Training loss: 2.237419455160086
Validation loss: 2.4552579137096124

Epoch: 6| Step: 12
Training loss: 2.321519531312441
Validation loss: 2.4648522141761453

Epoch: 6| Step: 13
Training loss: 3.1733823304707927
Validation loss: 2.432511518767484

Epoch: 175| Step: 0
Training loss: 2.9498304932597135
Validation loss: 2.4351483010422976

Epoch: 6| Step: 1
Training loss: 2.28493400862412
Validation loss: 2.434513676447612

Epoch: 6| Step: 2
Training loss: 2.1721293348510713
Validation loss: 2.4247000104987126

Epoch: 6| Step: 3
Training loss: 1.6698793997019516
Validation loss: 2.4439518682152572

Epoch: 6| Step: 4
Training loss: 2.825854659979202
Validation loss: 2.409462378205352

Epoch: 6| Step: 5
Training loss: 2.1963854573944013
Validation loss: 2.4254856427205977

Epoch: 6| Step: 6
Training loss: 2.270662272131911
Validation loss: 2.4309448116437995

Epoch: 6| Step: 7
Training loss: 2.2599768379172303
Validation loss: 2.418514692566126

Epoch: 6| Step: 8
Training loss: 2.871742061157358
Validation loss: 2.4565534787919323

Epoch: 6| Step: 9
Training loss: 2.7548897360113282
Validation loss: 2.4522421367485077

Epoch: 6| Step: 10
Training loss: 2.1393792084438825
Validation loss: 2.4303772494009634

Epoch: 6| Step: 11
Training loss: 2.336213774913055
Validation loss: 2.4467050476189907

Epoch: 6| Step: 12
Training loss: 1.9826836173614146
Validation loss: 2.4100747987441506

Epoch: 6| Step: 13
Training loss: 2.9432607126691477
Validation loss: 2.4307952192741413

Epoch: 176| Step: 0
Training loss: 2.1020041076228027
Validation loss: 2.452913818507664

Epoch: 6| Step: 1
Training loss: 2.679282288456704
Validation loss: 2.426373787116492

Epoch: 6| Step: 2
Training loss: 2.2690015164769948
Validation loss: 2.4285795552124734

Epoch: 6| Step: 3
Training loss: 2.661353201883083
Validation loss: 2.433300644771181

Epoch: 6| Step: 4
Training loss: 2.2146282326664535
Validation loss: 2.4360849744731916

Epoch: 6| Step: 5
Training loss: 2.412569936420521
Validation loss: 2.4453588887110067

Epoch: 6| Step: 6
Training loss: 2.546441913127247
Validation loss: 2.4512785350336825

Epoch: 6| Step: 7
Training loss: 2.520923224073348
Validation loss: 2.4414681685276527

Epoch: 6| Step: 8
Training loss: 1.9859231031422737
Validation loss: 2.4554266461370493

Epoch: 6| Step: 9
Training loss: 2.0513266573848865
Validation loss: 2.438677201923885

Epoch: 6| Step: 10
Training loss: 3.063754856163357
Validation loss: 2.4369321497710383

Epoch: 6| Step: 11
Training loss: 2.3010755263312976
Validation loss: 2.4453869853869006

Epoch: 6| Step: 12
Training loss: 2.4137571073770214
Validation loss: 2.449182762534104

Epoch: 6| Step: 13
Training loss: 2.689231758177088
Validation loss: 2.4380573385420776

Epoch: 177| Step: 0
Training loss: 2.8549383377925444
Validation loss: 2.421760846959769

Epoch: 6| Step: 1
Training loss: 2.587785964864786
Validation loss: 2.4402133321306456

Epoch: 6| Step: 2
Training loss: 2.526795128733058
Validation loss: 2.4439504615414487

Epoch: 6| Step: 3
Training loss: 1.7252256992133865
Validation loss: 2.4247289074527227

Epoch: 6| Step: 4
Training loss: 2.502015731707178
Validation loss: 2.451285047459261

Epoch: 6| Step: 5
Training loss: 2.116341171869392
Validation loss: 2.458996570845606

Epoch: 6| Step: 6
Training loss: 2.6274816498991274
Validation loss: 2.4341591762637513

Epoch: 6| Step: 7
Training loss: 2.630208434051411
Validation loss: 2.4350333857950726

Epoch: 6| Step: 8
Training loss: 2.270975674242348
Validation loss: 2.434786041628978

Epoch: 6| Step: 9
Training loss: 2.142315385091093
Validation loss: 2.4255714673887137

Epoch: 6| Step: 10
Training loss: 2.487800300145601
Validation loss: 2.4411450507116457

Epoch: 6| Step: 11
Training loss: 2.3700085439407284
Validation loss: 2.445395948830066

Epoch: 6| Step: 12
Training loss: 2.5304137367329145
Validation loss: 2.4359598208139266

Epoch: 6| Step: 13
Training loss: 2.177069948389501
Validation loss: 2.4140282759347973

Epoch: 178| Step: 0
Training loss: 2.0629639537212054
Validation loss: 2.437013948379755

Epoch: 6| Step: 1
Training loss: 2.610451847295004
Validation loss: 2.4190921786140227

Epoch: 6| Step: 2
Training loss: 2.546227776604116
Validation loss: 2.4463230249168975

Epoch: 6| Step: 3
Training loss: 2.297025403139294
Validation loss: 2.4481428500486433

Epoch: 6| Step: 4
Training loss: 3.0008311709716033
Validation loss: 2.427732371803793

Epoch: 6| Step: 5
Training loss: 2.4265911820307666
Validation loss: 2.424598304353205

Epoch: 6| Step: 6
Training loss: 2.2348076461524635
Validation loss: 2.4512226406217423

Epoch: 6| Step: 7
Training loss: 2.4347046693772536
Validation loss: 2.443951191627285

Epoch: 6| Step: 8
Training loss: 2.3694934252076014
Validation loss: 2.413196548984692

Epoch: 6| Step: 9
Training loss: 3.101398300321377
Validation loss: 2.4388460198125226

Epoch: 6| Step: 10
Training loss: 1.805014906739791
Validation loss: 2.438386236964665

Epoch: 6| Step: 11
Training loss: 2.260656973960989
Validation loss: 2.447199608362224

Epoch: 6| Step: 12
Training loss: 2.4908556593243976
Validation loss: 2.444754604930411

Epoch: 6| Step: 13
Training loss: 1.7283912053561374
Validation loss: 2.4288831031526077

Epoch: 179| Step: 0
Training loss: 2.4579240059461456
Validation loss: 2.4350233313872947

Epoch: 6| Step: 1
Training loss: 2.022794525618233
Validation loss: 2.442922578088556

Epoch: 6| Step: 2
Training loss: 2.1840195351589817
Validation loss: 2.424757901331836

Epoch: 6| Step: 3
Training loss: 2.2622889720651167
Validation loss: 2.4416677646815788

Epoch: 6| Step: 4
Training loss: 1.742277818742081
Validation loss: 2.4130451673720983

Epoch: 6| Step: 5
Training loss: 2.194326484771863
Validation loss: 2.4588132910819516

Epoch: 6| Step: 6
Training loss: 2.394241091399853
Validation loss: 2.4273980788789085

Epoch: 6| Step: 7
Training loss: 2.076974650772409
Validation loss: 2.4158071231224247

Epoch: 6| Step: 8
Training loss: 2.3396330214738588
Validation loss: 2.3964789064286136

Epoch: 6| Step: 9
Training loss: 2.7493148296940966
Validation loss: 2.436021148473183

Epoch: 6| Step: 10
Training loss: 2.8799021847326567
Validation loss: 2.4219347403598084

Epoch: 6| Step: 11
Training loss: 3.3951057325480547
Validation loss: 2.424136048648216

Epoch: 6| Step: 12
Training loss: 2.141749845242709
Validation loss: 2.404144416359633

Epoch: 6| Step: 13
Training loss: 2.1357633975998707
Validation loss: 2.434165615480326

Epoch: 180| Step: 0
Training loss: 2.462567470807411
Validation loss: 2.4177827715352147

Epoch: 6| Step: 1
Training loss: 2.8306185862476325
Validation loss: 2.431934994998775

Epoch: 6| Step: 2
Training loss: 2.3284702941035045
Validation loss: 2.423736882300175

Epoch: 6| Step: 3
Training loss: 2.146002370849039
Validation loss: 2.456484513582952

Epoch: 6| Step: 4
Training loss: 1.9241375514565087
Validation loss: 2.418597261401763

Epoch: 6| Step: 5
Training loss: 2.8957925331662837
Validation loss: 2.381068733173346

Epoch: 6| Step: 6
Training loss: 1.973600074915581
Validation loss: 2.434030820187067

Epoch: 6| Step: 7
Training loss: 2.609349781759689
Validation loss: 2.431906494650493

Epoch: 6| Step: 8
Training loss: 2.1265029080440785
Validation loss: 2.4409345614988918

Epoch: 6| Step: 9
Training loss: 2.7838969118829113
Validation loss: 2.42385802338503

Epoch: 6| Step: 10
Training loss: 2.222718356962632
Validation loss: 2.4387565447227733

Epoch: 6| Step: 11
Training loss: 2.479056561586862
Validation loss: 2.4127857981747907

Epoch: 6| Step: 12
Training loss: 2.149786175585499
Validation loss: 2.4285414224696726

Epoch: 6| Step: 13
Training loss: 2.2761795968192664
Validation loss: 2.4381689379566334

Epoch: 181| Step: 0
Training loss: 1.6383577939235479
Validation loss: 2.432906391950258

Epoch: 6| Step: 1
Training loss: 2.553807938376436
Validation loss: 2.442648562452147

Epoch: 6| Step: 2
Training loss: 2.0616187322538995
Validation loss: 2.3998316340883608

Epoch: 6| Step: 3
Training loss: 1.8618443864890353
Validation loss: 2.430507119004271

Epoch: 6| Step: 4
Training loss: 1.9099567831852253
Validation loss: 2.404689319450552

Epoch: 6| Step: 5
Training loss: 3.1193576992795626
Validation loss: 2.4115110382852913

Epoch: 6| Step: 6
Training loss: 2.3253651075919146
Validation loss: 2.3964326851625537

Epoch: 6| Step: 7
Training loss: 2.362713605316885
Validation loss: 2.4441380864272313

Epoch: 6| Step: 8
Training loss: 2.3654601590210764
Validation loss: 2.443331903962733

Epoch: 6| Step: 9
Training loss: 2.76184996815215
Validation loss: 2.4133734054900726

Epoch: 6| Step: 10
Training loss: 2.158745910605316
Validation loss: 2.447901949623358

Epoch: 6| Step: 11
Training loss: 2.7994730726072237
Validation loss: 2.443045381267948

Epoch: 6| Step: 12
Training loss: 2.4497684914336486
Validation loss: 2.4513848850551

Epoch: 6| Step: 13
Training loss: 2.7021944064857943
Validation loss: 2.4092416838171693

Epoch: 182| Step: 0
Training loss: 2.565222712583652
Validation loss: 2.4463550492164705

Epoch: 6| Step: 1
Training loss: 2.7246420143934325
Validation loss: 2.4306522771651404

Epoch: 6| Step: 2
Training loss: 2.276379755837247
Validation loss: 2.4319973802478883

Epoch: 6| Step: 3
Training loss: 2.2693201909108667
Validation loss: 2.442301114981428

Epoch: 6| Step: 4
Training loss: 1.9853321080115445
Validation loss: 2.447862681515975

Epoch: 6| Step: 5
Training loss: 2.0451852361079417
Validation loss: 2.4312994378136437

Epoch: 6| Step: 6
Training loss: 1.9018418043475747
Validation loss: 2.4612796626965383

Epoch: 6| Step: 7
Training loss: 2.9003396591692163
Validation loss: 2.42935513395141

Epoch: 6| Step: 8
Training loss: 3.090054240815465
Validation loss: 2.436312896242077

Epoch: 6| Step: 9
Training loss: 2.2855245179351105
Validation loss: 2.473254746978387

Epoch: 6| Step: 10
Training loss: 2.705358916214178
Validation loss: 2.4514795421160605

Epoch: 6| Step: 11
Training loss: 2.288332774011035
Validation loss: 2.4300653892938042

Epoch: 6| Step: 12
Training loss: 1.6602327216992219
Validation loss: 2.4591732265883794

Epoch: 6| Step: 13
Training loss: 2.891763493861687
Validation loss: 2.4399399767754653

Epoch: 183| Step: 0
Training loss: 2.1873410848386996
Validation loss: 2.4152575986454097

Epoch: 6| Step: 1
Training loss: 2.919273483089137
Validation loss: 2.411704646420081

Epoch: 6| Step: 2
Training loss: 2.0828033790474523
Validation loss: 2.4231058291108485

Epoch: 6| Step: 3
Training loss: 2.6670766654336235
Validation loss: 2.456132738819774

Epoch: 6| Step: 4
Training loss: 2.4561243855045927
Validation loss: 2.445988196600502

Epoch: 6| Step: 5
Training loss: 2.4023129841144804
Validation loss: 2.425547811237872

Epoch: 6| Step: 6
Training loss: 1.9776177284700667
Validation loss: 2.424935794340211

Epoch: 6| Step: 7
Training loss: 1.8889924874911102
Validation loss: 2.423418536683629

Epoch: 6| Step: 8
Training loss: 2.0708092435462855
Validation loss: 2.4294055587456627

Epoch: 6| Step: 9
Training loss: 2.6782486058023856
Validation loss: 2.4066058714617182

Epoch: 6| Step: 10
Training loss: 1.5614118220057032
Validation loss: 2.3990792495512636

Epoch: 6| Step: 11
Training loss: 2.6130342694680273
Validation loss: 2.416823534458804

Epoch: 6| Step: 12
Training loss: 3.2076531386891087
Validation loss: 2.4118598531598865

Epoch: 6| Step: 13
Training loss: 2.0930282715311006
Validation loss: 2.3902200871618513

Epoch: 184| Step: 0
Training loss: 1.9107380548483368
Validation loss: 2.4427504406093306

Epoch: 6| Step: 1
Training loss: 3.0193218439879854
Validation loss: 2.4096169899481388

Epoch: 6| Step: 2
Training loss: 2.8771110745104718
Validation loss: 2.4221516028154184

Epoch: 6| Step: 3
Training loss: 2.260272418457485
Validation loss: 2.3945325026287803

Epoch: 6| Step: 4
Training loss: 2.603155982667746
Validation loss: 2.4488806787167645

Epoch: 6| Step: 5
Training loss: 2.115386083909172
Validation loss: 2.4024629584828414

Epoch: 6| Step: 6
Training loss: 2.561721683557523
Validation loss: 2.4279847720693883

Epoch: 6| Step: 7
Training loss: 2.189009663218521
Validation loss: 2.420760669972881

Epoch: 6| Step: 8
Training loss: 2.6470156653632073
Validation loss: 2.4580197399328694

Epoch: 6| Step: 9
Training loss: 2.117055290570494
Validation loss: 2.4402020572742633

Epoch: 6| Step: 10
Training loss: 1.6449883702339527
Validation loss: 2.42077491060999

Epoch: 6| Step: 11
Training loss: 1.8483033932094615
Validation loss: 2.409396152513347

Epoch: 6| Step: 12
Training loss: 2.643557934288734
Validation loss: 2.4338925899638797

Epoch: 6| Step: 13
Training loss: 2.5332120661404947
Validation loss: 2.42471647792443

Epoch: 185| Step: 0
Training loss: 2.1127279124813336
Validation loss: 2.4392194360211645

Epoch: 6| Step: 1
Training loss: 2.0874249016507727
Validation loss: 2.4307907148555

Epoch: 6| Step: 2
Training loss: 2.7119545911233813
Validation loss: 2.427806200688476

Epoch: 6| Step: 3
Training loss: 2.467664455819736
Validation loss: 2.4011971498069267

Epoch: 6| Step: 4
Training loss: 2.267705659130262
Validation loss: 2.41744886419292

Epoch: 6| Step: 5
Training loss: 2.275058653358349
Validation loss: 2.4342754186681566

Epoch: 6| Step: 6
Training loss: 2.079043995430718
Validation loss: 2.4246650621802024

Epoch: 6| Step: 7
Training loss: 1.9986228373753991
Validation loss: 2.432188083014987

Epoch: 6| Step: 8
Training loss: 2.414500767698026
Validation loss: 2.3933095200251686

Epoch: 6| Step: 9
Training loss: 2.978748550062511
Validation loss: 2.403027752199522

Epoch: 6| Step: 10
Training loss: 2.956859991841436
Validation loss: 2.4098689796141994

Epoch: 6| Step: 11
Training loss: 2.145126843736802
Validation loss: 2.4211146055104216

Epoch: 6| Step: 12
Training loss: 2.3276884962676467
Validation loss: 2.4148552937474443

Epoch: 6| Step: 13
Training loss: 2.0401637585678465
Validation loss: 2.421072973641677

Epoch: 186| Step: 0
Training loss: 2.113672132180092
Validation loss: 2.433238953538329

Epoch: 6| Step: 1
Training loss: 2.8005021939193284
Validation loss: 2.4180371666781677

Epoch: 6| Step: 2
Training loss: 2.763672047537539
Validation loss: 2.4310608934930227

Epoch: 6| Step: 3
Training loss: 2.3438109326389283
Validation loss: 2.4207638650424266

Epoch: 6| Step: 4
Training loss: 2.3877979591944345
Validation loss: 2.4263724611172193

Epoch: 6| Step: 5
Training loss: 2.797955948778052
Validation loss: 2.3980899767583037

Epoch: 6| Step: 6
Training loss: 1.976791911325305
Validation loss: 2.3922625064842356

Epoch: 6| Step: 7
Training loss: 1.933655955537431
Validation loss: 2.441336619050716

Epoch: 6| Step: 8
Training loss: 1.9771939200159458
Validation loss: 2.4002351273532274

Epoch: 6| Step: 9
Training loss: 2.2433735438687696
Validation loss: 2.4064301901552203

Epoch: 6| Step: 10
Training loss: 2.8631848244869493
Validation loss: 2.3822970527603715

Epoch: 6| Step: 11
Training loss: 1.7546821356374618
Validation loss: 2.4237538830116483

Epoch: 6| Step: 12
Training loss: 2.5289497755922836
Validation loss: 2.4503776832181354

Epoch: 6| Step: 13
Training loss: 2.3949437245106613
Validation loss: 2.4464004027209136

Epoch: 187| Step: 0
Training loss: 2.8739202379110163
Validation loss: 2.408058727913987

Epoch: 6| Step: 1
Training loss: 2.7749181958762192
Validation loss: 2.4049209031879

Epoch: 6| Step: 2
Training loss: 2.3283829514120984
Validation loss: 2.4097100418200808

Epoch: 6| Step: 3
Training loss: 2.500167650323498
Validation loss: 2.438492615186592

Epoch: 6| Step: 4
Training loss: 1.99675523282358
Validation loss: 2.410986075071699

Epoch: 6| Step: 5
Training loss: 2.5258390260147925
Validation loss: 2.4130081846352684

Epoch: 6| Step: 6
Training loss: 2.1278050925834173
Validation loss: 2.4058423260951782

Epoch: 6| Step: 7
Training loss: 2.6341301312115806
Validation loss: 2.416710778563286

Epoch: 6| Step: 8
Training loss: 2.141246844554921
Validation loss: 2.4216226785712034

Epoch: 6| Step: 9
Training loss: 1.7718877532876778
Validation loss: 2.449034962502692

Epoch: 6| Step: 10
Training loss: 2.126171910883244
Validation loss: 2.4532519348758015

Epoch: 6| Step: 11
Training loss: 2.572333657212991
Validation loss: 2.438927144574441

Epoch: 6| Step: 12
Training loss: 2.218180838640113
Validation loss: 2.423501456779329

Epoch: 6| Step: 13
Training loss: 2.4299682258757764
Validation loss: 2.4327183186517796

Epoch: 188| Step: 0
Training loss: 2.527765112159307
Validation loss: 2.4494690492828664

Epoch: 6| Step: 1
Training loss: 1.9968106350502433
Validation loss: 2.427529896846615

Epoch: 6| Step: 2
Training loss: 2.343027842845892
Validation loss: 2.4314580667047814

Epoch: 6| Step: 3
Training loss: 2.098004473831454
Validation loss: 2.419192127170683

Epoch: 6| Step: 4
Training loss: 2.764926110879024
Validation loss: 2.430135598493795

Epoch: 6| Step: 5
Training loss: 2.5152434065565252
Validation loss: 2.4176719075520765

Epoch: 6| Step: 6
Training loss: 1.8700581593572596
Validation loss: 2.4302453337567482

Epoch: 6| Step: 7
Training loss: 2.42328942127487
Validation loss: 2.418637475270787

Epoch: 6| Step: 8
Training loss: 2.388503984990588
Validation loss: 2.4286323131315406

Epoch: 6| Step: 9
Training loss: 2.8633048979028572
Validation loss: 2.400465613066568

Epoch: 6| Step: 10
Training loss: 2.3979355476314375
Validation loss: 2.4259748145994844

Epoch: 6| Step: 11
Training loss: 2.439283158892003
Validation loss: 2.4451742459796857

Epoch: 6| Step: 12
Training loss: 1.7219294876920763
Validation loss: 2.4138347315049016

Epoch: 6| Step: 13
Training loss: 2.586136916847104
Validation loss: 2.4041836872892737

Epoch: 189| Step: 0
Training loss: 2.216873234849501
Validation loss: 2.3816496191651315

Epoch: 6| Step: 1
Training loss: 2.6613234593406374
Validation loss: 2.4039175381532853

Epoch: 6| Step: 2
Training loss: 2.554204959385276
Validation loss: 2.428164470575261

Epoch: 6| Step: 3
Training loss: 2.197564649791821
Validation loss: 2.399664954329705

Epoch: 6| Step: 4
Training loss: 2.0472665659729996
Validation loss: 2.419827754857944

Epoch: 6| Step: 5
Training loss: 2.2943044797845538
Validation loss: 2.392954601798163

Epoch: 6| Step: 6
Training loss: 2.514689585524991
Validation loss: 2.413817626945845

Epoch: 6| Step: 7
Training loss: 2.6493591685360913
Validation loss: 2.402895413737999

Epoch: 6| Step: 8
Training loss: 2.7270038761213486
Validation loss: 2.4042470346770934

Epoch: 6| Step: 9
Training loss: 2.181490026345843
Validation loss: 2.424493668138801

Epoch: 6| Step: 10
Training loss: 2.1773843389860836
Validation loss: 2.4141523763485475

Epoch: 6| Step: 11
Training loss: 2.0984467166064817
Validation loss: 2.4113275391532656

Epoch: 6| Step: 12
Training loss: 1.7690160814053535
Validation loss: 2.4349943713024382

Epoch: 6| Step: 13
Training loss: 2.897648542018007
Validation loss: 2.4175039477441813

Epoch: 190| Step: 0
Training loss: 2.2252270357691084
Validation loss: 2.401761323224682

Epoch: 6| Step: 1
Training loss: 2.2439833835795775
Validation loss: 2.406591811165433

Epoch: 6| Step: 2
Training loss: 2.319594763518697
Validation loss: 2.4329506916549577

Epoch: 6| Step: 3
Training loss: 1.8815144223145257
Validation loss: 2.4390230744843793

Epoch: 6| Step: 4
Training loss: 2.3942105201381083
Validation loss: 2.4018294416078194

Epoch: 6| Step: 5
Training loss: 2.5148292372807113
Validation loss: 2.4209124771839714

Epoch: 6| Step: 6
Training loss: 2.1057564675065246
Validation loss: 2.400330634141659

Epoch: 6| Step: 7
Training loss: 2.42429324597132
Validation loss: 2.4257856379580205

Epoch: 6| Step: 8
Training loss: 2.524221481562618
Validation loss: 2.407122679218604

Epoch: 6| Step: 9
Training loss: 2.6454034491111815
Validation loss: 2.4186759681964194

Epoch: 6| Step: 10
Training loss: 2.253256877790904
Validation loss: 2.4046274922858237

Epoch: 6| Step: 11
Training loss: 2.014058768755029
Validation loss: 2.4082826148613026

Epoch: 6| Step: 12
Training loss: 2.7666294838425145
Validation loss: 2.4216341923753624

Epoch: 6| Step: 13
Training loss: 2.3370969822698657
Validation loss: 2.4350642794140427

Epoch: 191| Step: 0
Training loss: 2.052880830921058
Validation loss: 2.4091615059880898

Epoch: 6| Step: 1
Training loss: 2.6591370096189655
Validation loss: 2.4233437912843354

Epoch: 6| Step: 2
Training loss: 2.7232671460062168
Validation loss: 2.4291275075995675

Epoch: 6| Step: 3
Training loss: 2.7877887627581286
Validation loss: 2.4270137882704037

Epoch: 6| Step: 4
Training loss: 2.6090378229361164
Validation loss: 2.4014308931518777

Epoch: 6| Step: 5
Training loss: 2.300540205499913
Validation loss: 2.392590677288279

Epoch: 6| Step: 6
Training loss: 2.4818425736894336
Validation loss: 2.4222182428575603

Epoch: 6| Step: 7
Training loss: 2.1756165474648292
Validation loss: 2.4394252652716726

Epoch: 6| Step: 8
Training loss: 2.0506723138849674
Validation loss: 2.429691511607933

Epoch: 6| Step: 9
Training loss: 1.8427160564438307
Validation loss: 2.4335778619931054

Epoch: 6| Step: 10
Training loss: 2.1842138402861693
Validation loss: 2.427257415585792

Epoch: 6| Step: 11
Training loss: 2.4383744847477082
Validation loss: 2.421322285608131

Epoch: 6| Step: 12
Training loss: 2.29727812881842
Validation loss: 2.436663612178749

Epoch: 6| Step: 13
Training loss: 1.8086200489743898
Validation loss: 2.4304745557407186

Epoch: 192| Step: 0
Training loss: 2.257946709996568
Validation loss: 2.416084930988072

Epoch: 6| Step: 1
Training loss: 2.568585496818779
Validation loss: 2.419971324163789

Epoch: 6| Step: 2
Training loss: 2.056308121714901
Validation loss: 2.4209185185223983

Epoch: 6| Step: 3
Training loss: 2.7739062275841144
Validation loss: 2.407970817298054

Epoch: 6| Step: 4
Training loss: 1.950559594482675
Validation loss: 2.421142488519334

Epoch: 6| Step: 5
Training loss: 1.7323263630132524
Validation loss: 2.4226343526474707

Epoch: 6| Step: 6
Training loss: 2.629181029879536
Validation loss: 2.415508338138076

Epoch: 6| Step: 7
Training loss: 2.2973429923220734
Validation loss: 2.402545002316754

Epoch: 6| Step: 8
Training loss: 2.7552405621687415
Validation loss: 2.390526762221433

Epoch: 6| Step: 9
Training loss: 2.086933598228345
Validation loss: 2.404815073384705

Epoch: 6| Step: 10
Training loss: 2.2245411046029506
Validation loss: 2.393950459639989

Epoch: 6| Step: 11
Training loss: 2.570676273471773
Validation loss: 2.4259452709549136

Epoch: 6| Step: 12
Training loss: 2.349962368115983
Validation loss: 2.402884433214437

Epoch: 6| Step: 13
Training loss: 2.082181255955833
Validation loss: 2.4389318883401425

Epoch: 193| Step: 0
Training loss: 1.835437008430721
Validation loss: 2.409875743835093

Epoch: 6| Step: 1
Training loss: 2.0993836179501315
Validation loss: 2.3985797347819866

Epoch: 6| Step: 2
Training loss: 1.7979052699830333
Validation loss: 2.4405555799152108

Epoch: 6| Step: 3
Training loss: 2.666034404981932
Validation loss: 2.4244170810712338

Epoch: 6| Step: 4
Training loss: 2.414687881203107
Validation loss: 2.415996898587469

Epoch: 6| Step: 5
Training loss: 2.469198644892106
Validation loss: 2.392796605615155

Epoch: 6| Step: 6
Training loss: 2.499189149968068
Validation loss: 2.4090761438387713

Epoch: 6| Step: 7
Training loss: 2.594471934397766
Validation loss: 2.3951757811840673

Epoch: 6| Step: 8
Training loss: 1.5656341400184257
Validation loss: 2.413049094563361

Epoch: 6| Step: 9
Training loss: 2.7645421036321958
Validation loss: 2.415340711876284

Epoch: 6| Step: 10
Training loss: 2.842496826384827
Validation loss: 2.3659117556094427

Epoch: 6| Step: 11
Training loss: 2.4878945042607925
Validation loss: 2.4223362753648456

Epoch: 6| Step: 12
Training loss: 2.2323199872172426
Validation loss: 2.4287789840260365

Epoch: 6| Step: 13
Training loss: 1.7447336519379781
Validation loss: 2.4032299478460377

Epoch: 194| Step: 0
Training loss: 2.2036666745311018
Validation loss: 2.410482191285594

Epoch: 6| Step: 1
Training loss: 2.270953522280918
Validation loss: 2.416605801889077

Epoch: 6| Step: 2
Training loss: 2.747177583001577
Validation loss: 2.418422334580055

Epoch: 6| Step: 3
Training loss: 2.4435304235754303
Validation loss: 2.41376188467799

Epoch: 6| Step: 4
Training loss: 2.497063247020215
Validation loss: 2.4214134991271115

Epoch: 6| Step: 5
Training loss: 3.005947257994837
Validation loss: 2.4343144594271355

Epoch: 6| Step: 6
Training loss: 2.3494247909429062
Validation loss: 2.4072390301520548

Epoch: 6| Step: 7
Training loss: 1.8104818881818985
Validation loss: 2.435885321848475

Epoch: 6| Step: 8
Training loss: 2.5808177410570727
Validation loss: 2.426271164781245

Epoch: 6| Step: 9
Training loss: 2.30580282864132
Validation loss: 2.4027517294275453

Epoch: 6| Step: 10
Training loss: 2.2388876847399852
Validation loss: 2.408881930141652

Epoch: 6| Step: 11
Training loss: 1.7625859530437276
Validation loss: 2.4082692892897675

Epoch: 6| Step: 12
Training loss: 1.7647455776649335
Validation loss: 2.416108158278164

Epoch: 6| Step: 13
Training loss: 2.0247465045643027
Validation loss: 2.4529544668371495

Epoch: 195| Step: 0
Training loss: 2.6539954996135533
Validation loss: 2.444818845197671

Epoch: 6| Step: 1
Training loss: 2.297540581212997
Validation loss: 2.4278780348112625

Epoch: 6| Step: 2
Training loss: 2.583272984527875
Validation loss: 2.4146293407127293

Epoch: 6| Step: 3
Training loss: 1.9992297596719613
Validation loss: 2.43015539009149

Epoch: 6| Step: 4
Training loss: 2.1568067633491674
Validation loss: 2.4088598373776478

Epoch: 6| Step: 5
Training loss: 2.45924808703076
Validation loss: 2.3914505896714817

Epoch: 6| Step: 6
Training loss: 2.232599046139717
Validation loss: 2.4239397576460777

Epoch: 6| Step: 7
Training loss: 2.1457674948459013
Validation loss: 2.4050455604167125

Epoch: 6| Step: 8
Training loss: 1.8462388003041246
Validation loss: 2.386247073269348

Epoch: 6| Step: 9
Training loss: 2.989656418672384
Validation loss: 2.4195337872655105

Epoch: 6| Step: 10
Training loss: 1.9855189592949563
Validation loss: 2.401371350506826

Epoch: 6| Step: 11
Training loss: 2.272645373169228
Validation loss: 2.3979095565219937

Epoch: 6| Step: 12
Training loss: 2.223978142274162
Validation loss: 2.395353942533562

Epoch: 6| Step: 13
Training loss: 2.4221597811712754
Validation loss: 2.4079343475143005

Epoch: 196| Step: 0
Training loss: 2.1608641638899786
Validation loss: 2.3778620391385066

Epoch: 6| Step: 1
Training loss: 2.227363736729644
Validation loss: 2.4138657806695254

Epoch: 6| Step: 2
Training loss: 2.9463348637992035
Validation loss: 2.4156256451909877

Epoch: 6| Step: 3
Training loss: 1.9463388577305696
Validation loss: 2.4136654616622693

Epoch: 6| Step: 4
Training loss: 2.1459159341364273
Validation loss: 2.3878682323364115

Epoch: 6| Step: 5
Training loss: 1.9496073669900185
Validation loss: 2.411021866030505

Epoch: 6| Step: 6
Training loss: 2.139151852889186
Validation loss: 2.431999793149543

Epoch: 6| Step: 7
Training loss: 2.0761765832569496
Validation loss: 2.4154866445470966

Epoch: 6| Step: 8
Training loss: 1.9052377733639911
Validation loss: 2.3905033094272787

Epoch: 6| Step: 9
Training loss: 2.3111056686402494
Validation loss: 2.420010958510906

Epoch: 6| Step: 10
Training loss: 2.544478429773721
Validation loss: 2.4013654655001955

Epoch: 6| Step: 11
Training loss: 2.723091955363109
Validation loss: 2.4095851508563486

Epoch: 6| Step: 12
Training loss: 2.713962768760339
Validation loss: 2.3932109950218847

Epoch: 6| Step: 13
Training loss: 2.2928130894712573
Validation loss: 2.39360356803625

Epoch: 197| Step: 0
Training loss: 2.4203165269772624
Validation loss: 2.419418762962239

Epoch: 6| Step: 1
Training loss: 2.9800962762833634
Validation loss: 2.391822997872922

Epoch: 6| Step: 2
Training loss: 2.224252781073354
Validation loss: 2.4190525975685913

Epoch: 6| Step: 3
Training loss: 1.8246318341267211
Validation loss: 2.432082895015238

Epoch: 6| Step: 4
Training loss: 1.9230069184399519
Validation loss: 2.398769042431812

Epoch: 6| Step: 5
Training loss: 2.1564353089246957
Validation loss: 2.3950132666971453

Epoch: 6| Step: 6
Training loss: 2.1943161627808356
Validation loss: 2.426846389439817

Epoch: 6| Step: 7
Training loss: 2.5180317993034693
Validation loss: 2.3857622259475955

Epoch: 6| Step: 8
Training loss: 2.1119793673576766
Validation loss: 2.390347235082528

Epoch: 6| Step: 9
Training loss: 2.615559450191831
Validation loss: 2.4098904849518195

Epoch: 6| Step: 10
Training loss: 1.9318060114676066
Validation loss: 2.375122290605601

Epoch: 6| Step: 11
Training loss: 2.3260611788837706
Validation loss: 2.4406094644432383

Epoch: 6| Step: 12
Training loss: 2.286121653546292
Validation loss: 2.398078796770679

Epoch: 6| Step: 13
Training loss: 2.6694496256177858
Validation loss: 2.387262489897681

Epoch: 198| Step: 0
Training loss: 2.829078134341638
Validation loss: 2.416987038983194

Epoch: 6| Step: 1
Training loss: 2.52330040337842
Validation loss: 2.3885921956362615

Epoch: 6| Step: 2
Training loss: 2.7009194256805507
Validation loss: 2.428034022709675

Epoch: 6| Step: 3
Training loss: 2.048926337463731
Validation loss: 2.3934440937178514

Epoch: 6| Step: 4
Training loss: 2.2123848319386674
Validation loss: 2.404390473959373

Epoch: 6| Step: 5
Training loss: 2.6541001539614704
Validation loss: 2.423242055723206

Epoch: 6| Step: 6
Training loss: 2.482073407510051
Validation loss: 2.44625565609199

Epoch: 6| Step: 7
Training loss: 1.81762116522857
Validation loss: 2.4402485368305293

Epoch: 6| Step: 8
Training loss: 2.292595022181192
Validation loss: 2.427978903526869

Epoch: 6| Step: 9
Training loss: 2.344487595525148
Validation loss: 2.428680035898702

Epoch: 6| Step: 10
Training loss: 2.2244374624916143
Validation loss: 2.4391473263053802

Epoch: 6| Step: 11
Training loss: 1.9840270811240008
Validation loss: 2.3882921790938636

Epoch: 6| Step: 12
Training loss: 2.27253007640177
Validation loss: 2.406617878947238

Epoch: 6| Step: 13
Training loss: 1.7020817632523964
Validation loss: 2.412367054955448

Epoch: 199| Step: 0
Training loss: 1.8673562967145274
Validation loss: 2.415410398625833

Epoch: 6| Step: 1
Training loss: 2.3390345631003253
Validation loss: 2.433549005854281

Epoch: 6| Step: 2
Training loss: 2.239365240315861
Validation loss: 2.447265967549832

Epoch: 6| Step: 3
Training loss: 2.675741688233997
Validation loss: 2.4015660482868473

Epoch: 6| Step: 4
Training loss: 2.5456960558884605
Validation loss: 2.427266623417036

Epoch: 6| Step: 5
Training loss: 2.388946542364519
Validation loss: 2.3994790112905626

Epoch: 6| Step: 6
Training loss: 2.241875071806065
Validation loss: 2.416835578161141

Epoch: 6| Step: 7
Training loss: 2.3592361510390667
Validation loss: 2.4349046767642704

Epoch: 6| Step: 8
Training loss: 2.058949738328592
Validation loss: 2.4308331526657225

Epoch: 6| Step: 9
Training loss: 2.781151416188638
Validation loss: 2.3888087200367467

Epoch: 6| Step: 10
Training loss: 2.222307603573345
Validation loss: 2.3871212658087178

Epoch: 6| Step: 11
Training loss: 2.0121305470138657
Validation loss: 2.4172357473320276

Epoch: 6| Step: 12
Training loss: 1.9003237548856164
Validation loss: 2.399097776754864

Epoch: 6| Step: 13
Training loss: 1.8601912301726613
Validation loss: 2.403161129883303

Epoch: 200| Step: 0
Training loss: 1.9106216331804164
Validation loss: 2.398116077090697

Epoch: 6| Step: 1
Training loss: 1.957732115097687
Validation loss: 2.4101356166016816

Epoch: 6| Step: 2
Training loss: 2.2472434642381396
Validation loss: 2.4018351498956725

Epoch: 6| Step: 3
Training loss: 2.6949292781234377
Validation loss: 2.413773956401711

Epoch: 6| Step: 4
Training loss: 2.3200611530662902
Validation loss: 2.3945420274038787

Epoch: 6| Step: 5
Training loss: 2.675285170854099
Validation loss: 2.4059061178382724

Epoch: 6| Step: 6
Training loss: 2.2289966863074473
Validation loss: 2.405821853900093

Epoch: 6| Step: 7
Training loss: 2.1695665125167025
Validation loss: 2.411353280382839

Epoch: 6| Step: 8
Training loss: 2.8574921292307565
Validation loss: 2.4043630854745235

Epoch: 6| Step: 9
Training loss: 2.418520665693842
Validation loss: 2.402163290667064

Epoch: 6| Step: 10
Training loss: 2.2529061940013673
Validation loss: 2.390481672039309

Epoch: 6| Step: 11
Training loss: 2.377112001674692
Validation loss: 2.4156014878212932

Epoch: 6| Step: 12
Training loss: 1.9091432221581497
Validation loss: 2.377391390585157

Epoch: 6| Step: 13
Training loss: 1.8627160452662554
Validation loss: 2.426777333741271

Epoch: 201| Step: 0
Training loss: 2.9554353587568176
Validation loss: 2.423463338810433

Epoch: 6| Step: 1
Training loss: 1.990468439146617
Validation loss: 2.4021720066503476

Epoch: 6| Step: 2
Training loss: 2.2707103614291517
Validation loss: 2.4101004937861075

Epoch: 6| Step: 3
Training loss: 2.3260816785619967
Validation loss: 2.392386623651973

Epoch: 6| Step: 4
Training loss: 2.482734186318985
Validation loss: 2.415897941603093

Epoch: 6| Step: 5
Training loss: 2.642232010893375
Validation loss: 2.3988314363173577

Epoch: 6| Step: 6
Training loss: 2.254863674500584
Validation loss: 2.404996755737343

Epoch: 6| Step: 7
Training loss: 2.107740206712321
Validation loss: 2.397004213139335

Epoch: 6| Step: 8
Training loss: 1.9406562446376416
Validation loss: 2.442155225756234

Epoch: 6| Step: 9
Training loss: 1.6362552396196441
Validation loss: 2.3983119974385443

Epoch: 6| Step: 10
Training loss: 2.173542288387033
Validation loss: 2.4222724072460498

Epoch: 6| Step: 11
Training loss: 2.7212698648101816
Validation loss: 2.4337034367813604

Epoch: 6| Step: 12
Training loss: 2.1704317415792502
Validation loss: 2.412674348615811

Epoch: 6| Step: 13
Training loss: 2.174799754253217
Validation loss: 2.3977229705522554

Epoch: 202| Step: 0
Training loss: 2.5378843420443236
Validation loss: 2.4161493228901416

Epoch: 6| Step: 1
Training loss: 2.470251568326905
Validation loss: 2.414098451365726

Epoch: 6| Step: 2
Training loss: 3.0725971292859864
Validation loss: 2.389790453045649

Epoch: 6| Step: 3
Training loss: 2.195521443153911
Validation loss: 2.4201538829647258

Epoch: 6| Step: 4
Training loss: 2.1717413991549424
Validation loss: 2.4053099359049157

Epoch: 6| Step: 5
Training loss: 2.1639181701785777
Validation loss: 2.410418048424701

Epoch: 6| Step: 6
Training loss: 2.4872032716981725
Validation loss: 2.3731972653536677

Epoch: 6| Step: 7
Training loss: 1.6287565825791157
Validation loss: 2.430173710968941

Epoch: 6| Step: 8
Training loss: 1.924905140508819
Validation loss: 2.408860823941642

Epoch: 6| Step: 9
Training loss: 2.186719918804395
Validation loss: 2.4105580033724805

Epoch: 6| Step: 10
Training loss: 2.125336115565248
Validation loss: 2.3871793237268553

Epoch: 6| Step: 11
Training loss: 2.278343543936958
Validation loss: 2.4434213898726505

Epoch: 6| Step: 12
Training loss: 2.3458811925022838
Validation loss: 2.3976423377667158

Epoch: 6| Step: 13
Training loss: 1.9487838106972182
Validation loss: 2.396680916500189

Epoch: 203| Step: 0
Training loss: 1.9226617210834263
Validation loss: 2.3971288376957105

Epoch: 6| Step: 1
Training loss: 1.8119793505849926
Validation loss: 2.381420388495269

Epoch: 6| Step: 2
Training loss: 2.3212259979732677
Validation loss: 2.3853698670709282

Epoch: 6| Step: 3
Training loss: 2.0097679975994254
Validation loss: 2.4017061347955173

Epoch: 6| Step: 4
Training loss: 2.3187812864758284
Validation loss: 2.392818135823153

Epoch: 6| Step: 5
Training loss: 2.3090543077772443
Validation loss: 2.3909263525459736

Epoch: 6| Step: 6
Training loss: 2.3086925814623873
Validation loss: 2.390926077517067

Epoch: 6| Step: 7
Training loss: 2.9480636254513697
Validation loss: 2.416705804478916

Epoch: 6| Step: 8
Training loss: 1.353090117535706
Validation loss: 2.3799412737457217

Epoch: 6| Step: 9
Training loss: 2.4425740371150124
Validation loss: 2.3933562054299435

Epoch: 6| Step: 10
Training loss: 2.2224517889125353
Validation loss: 2.4149368252749284

Epoch: 6| Step: 11
Training loss: 1.7920303049633006
Validation loss: 2.4098019922176324

Epoch: 6| Step: 12
Training loss: 2.1365142110668436
Validation loss: 2.426657055192374

Epoch: 6| Step: 13
Training loss: 3.8237472726713033
Validation loss: 2.400141832047262

Epoch: 204| Step: 0
Training loss: 1.7207383878560762
Validation loss: 2.363160484846797

Epoch: 6| Step: 1
Training loss: 2.9421557602509973
Validation loss: 2.406764233470967

Epoch: 6| Step: 2
Training loss: 2.606665020655172
Validation loss: 2.3918175647329476

Epoch: 6| Step: 3
Training loss: 2.558651709446103
Validation loss: 2.4270979058591666

Epoch: 6| Step: 4
Training loss: 2.645293673849965
Validation loss: 2.372819520237903

Epoch: 6| Step: 5
Training loss: 2.8717045348407284
Validation loss: 2.3855624185059634

Epoch: 6| Step: 6
Training loss: 2.070328046632371
Validation loss: 2.397269197398858

Epoch: 6| Step: 7
Training loss: 1.9548187236206884
Validation loss: 2.4093722588088995

Epoch: 6| Step: 8
Training loss: 1.7757708957435703
Validation loss: 2.40477218388732

Epoch: 6| Step: 9
Training loss: 1.4264275745039339
Validation loss: 2.4306433679878228

Epoch: 6| Step: 10
Training loss: 1.5825328643905696
Validation loss: 2.3856188390246484

Epoch: 6| Step: 11
Training loss: 1.9011801542936957
Validation loss: 2.3616289313121634

Epoch: 6| Step: 12
Training loss: 2.4056115232284903
Validation loss: 2.400688998239013

Epoch: 6| Step: 13
Training loss: 2.839238539147025
Validation loss: 2.414905186897662

Epoch: 205| Step: 0
Training loss: 2.2509680890567196
Validation loss: 2.37653317534616

Epoch: 6| Step: 1
Training loss: 1.9108499776739443
Validation loss: 2.4017810081394133

Epoch: 6| Step: 2
Training loss: 1.8492623379223425
Validation loss: 2.405032445022599

Epoch: 6| Step: 3
Training loss: 2.700863989593553
Validation loss: 2.4043998098780053

Epoch: 6| Step: 4
Training loss: 2.434958184135816
Validation loss: 2.437499256149696

Epoch: 6| Step: 5
Training loss: 1.8207195301704064
Validation loss: 2.433035541761765

Epoch: 6| Step: 6
Training loss: 2.252225199373688
Validation loss: 2.4061178451575698

Epoch: 6| Step: 7
Training loss: 2.4049887386066295
Validation loss: 2.395378787314963

Epoch: 6| Step: 8
Training loss: 2.2163249988205087
Validation loss: 2.3801543322392886

Epoch: 6| Step: 9
Training loss: 1.9268358913712946
Validation loss: 2.416707153815675

Epoch: 6| Step: 10
Training loss: 2.464483509852909
Validation loss: 2.369371942300521

Epoch: 6| Step: 11
Training loss: 3.0290925518415692
Validation loss: 2.384567581067993

Epoch: 6| Step: 12
Training loss: 1.8899081423805635
Validation loss: 2.3998176099492827

Epoch: 6| Step: 13
Training loss: 2.10068967484142
Validation loss: 2.3925249513631917

Epoch: 206| Step: 0
Training loss: 1.5708298471481263
Validation loss: 2.390805698669797

Epoch: 6| Step: 1
Training loss: 1.8636497277163397
Validation loss: 2.3851213984903725

Epoch: 6| Step: 2
Training loss: 2.0230670133193462
Validation loss: 2.394183795796394

Epoch: 6| Step: 3
Training loss: 2.0725045745026063
Validation loss: 2.4102072594104214

Epoch: 6| Step: 4
Training loss: 1.840152722634129
Validation loss: 2.417278399781602

Epoch: 6| Step: 5
Training loss: 2.6257058057584355
Validation loss: 2.417596892227391

Epoch: 6| Step: 6
Training loss: 2.3159389185254478
Validation loss: 2.38983010252009

Epoch: 6| Step: 7
Training loss: 2.8633353734332965
Validation loss: 2.4248345521704517

Epoch: 6| Step: 8
Training loss: 2.4762946624810485
Validation loss: 2.392904995021464

Epoch: 6| Step: 9
Training loss: 2.3823243688672067
Validation loss: 2.395846193411948

Epoch: 6| Step: 10
Training loss: 2.0417481490503158
Validation loss: 2.4095704174471373

Epoch: 6| Step: 11
Training loss: 2.7871751570340084
Validation loss: 2.387174753117148

Epoch: 6| Step: 12
Training loss: 2.106113766755454
Validation loss: 2.41328276926558

Epoch: 6| Step: 13
Training loss: 2.89133885822233
Validation loss: 2.378596776875595

Epoch: 207| Step: 0
Training loss: 2.040637931373831
Validation loss: 2.400715816218995

Epoch: 6| Step: 1
Training loss: 2.2095606530301324
Validation loss: 2.3958248974694842

Epoch: 6| Step: 2
Training loss: 1.9316844414504024
Validation loss: 2.401046180271523

Epoch: 6| Step: 3
Training loss: 2.4685289308097795
Validation loss: 2.4004471305957513

Epoch: 6| Step: 4
Training loss: 2.2379512310560856
Validation loss: 2.402225104416094

Epoch: 6| Step: 5
Training loss: 2.0743293229855655
Validation loss: 2.386193751031648

Epoch: 6| Step: 6
Training loss: 2.663265075365916
Validation loss: 2.4103308407500843

Epoch: 6| Step: 7
Training loss: 2.10496795303705
Validation loss: 2.431758905446432

Epoch: 6| Step: 8
Training loss: 2.074815682187521
Validation loss: 2.3901778699824625

Epoch: 6| Step: 9
Training loss: 2.02998747102977
Validation loss: 2.3883697104266495

Epoch: 6| Step: 10
Training loss: 2.1480864636868913
Validation loss: 2.4130124964839768

Epoch: 6| Step: 11
Training loss: 2.7485620033469638
Validation loss: 2.3922583796007615

Epoch: 6| Step: 12
Training loss: 2.4104387559815517
Validation loss: 2.404399758699016

Epoch: 6| Step: 13
Training loss: 1.8600885640870863
Validation loss: 2.380745757860205

Epoch: 208| Step: 0
Training loss: 2.931794164450342
Validation loss: 2.4406418940615255

Epoch: 6| Step: 1
Training loss: 1.996436640184272
Validation loss: 2.405279022503819

Epoch: 6| Step: 2
Training loss: 2.4405920517342263
Validation loss: 2.423867676715077

Epoch: 6| Step: 3
Training loss: 1.874010715173074
Validation loss: 2.4012485854802086

Epoch: 6| Step: 4
Training loss: 2.143685596266026
Validation loss: 2.3922551486028887

Epoch: 6| Step: 5
Training loss: 1.7115705877798686
Validation loss: 2.394794718008606

Epoch: 6| Step: 6
Training loss: 2.1735713563749552
Validation loss: 2.415926960817106

Epoch: 6| Step: 7
Training loss: 2.372772979628267
Validation loss: 2.3987642171031096

Epoch: 6| Step: 8
Training loss: 1.9172222603753355
Validation loss: 2.371392521355548

Epoch: 6| Step: 9
Training loss: 2.1595208611475476
Validation loss: 2.4086549282185694

Epoch: 6| Step: 10
Training loss: 2.170649779815659
Validation loss: 2.3763218219975104

Epoch: 6| Step: 11
Training loss: 1.8038303602139436
Validation loss: 2.3587474372757202

Epoch: 6| Step: 12
Training loss: 2.586552204011577
Validation loss: 2.3838525378087225

Epoch: 6| Step: 13
Training loss: 3.13441802857702
Validation loss: 2.3958661334417255

Epoch: 209| Step: 0
Training loss: 2.390466024062008
Validation loss: 2.379085544589394

Epoch: 6| Step: 1
Training loss: 2.958123392168741
Validation loss: 2.3755550588658068

Epoch: 6| Step: 2
Training loss: 2.3119070994182125
Validation loss: 2.392859835017199

Epoch: 6| Step: 3
Training loss: 1.6036234179379016
Validation loss: 2.4239937799213447

Epoch: 6| Step: 4
Training loss: 2.6272379100396877
Validation loss: 2.418009993200608

Epoch: 6| Step: 5
Training loss: 2.251861861564091
Validation loss: 2.383051989358483

Epoch: 6| Step: 6
Training loss: 2.1985319701545176
Validation loss: 2.4119370026476483

Epoch: 6| Step: 7
Training loss: 1.790163725712248
Validation loss: 2.367191672757191

Epoch: 6| Step: 8
Training loss: 1.90171236373911
Validation loss: 2.4049573552428756

Epoch: 6| Step: 9
Training loss: 2.06104435271358
Validation loss: 2.4048069703644295

Epoch: 6| Step: 10
Training loss: 2.5579569482767024
Validation loss: 2.3854354088883416

Epoch: 6| Step: 11
Training loss: 2.413367902954244
Validation loss: 2.379402329166004

Epoch: 6| Step: 12
Training loss: 1.9661030004690419
Validation loss: 2.4246147449788635

Epoch: 6| Step: 13
Training loss: 1.8721753778958223
Validation loss: 2.381694754384791

Epoch: 210| Step: 0
Training loss: 2.0945731295788668
Validation loss: 2.40644474783633

Epoch: 6| Step: 1
Training loss: 3.0919931991620793
Validation loss: 2.4118474721076755

Epoch: 6| Step: 2
Training loss: 2.4716968573460334
Validation loss: 2.3936158099705134

Epoch: 6| Step: 3
Training loss: 2.311018185499832
Validation loss: 2.389671061899716

Epoch: 6| Step: 4
Training loss: 1.6171669336752716
Validation loss: 2.4181429399509917

Epoch: 6| Step: 5
Training loss: 2.4142274275553346
Validation loss: 2.3972454352042307

Epoch: 6| Step: 6
Training loss: 2.4234859892115708
Validation loss: 2.3759175192237896

Epoch: 6| Step: 7
Training loss: 1.9349520757689223
Validation loss: 2.395533813615307

Epoch: 6| Step: 8
Training loss: 1.7826388114820535
Validation loss: 2.384078383411036

Epoch: 6| Step: 9
Training loss: 2.6388184275896327
Validation loss: 2.4204240467753535

Epoch: 6| Step: 10
Training loss: 1.8801851420852327
Validation loss: 2.383707315237745

Epoch: 6| Step: 11
Training loss: 1.743851213696706
Validation loss: 2.4113919570949216

Epoch: 6| Step: 12
Training loss: 2.184630555578603
Validation loss: 2.385136125461397

Epoch: 6| Step: 13
Training loss: 2.3329033682538913
Validation loss: 2.4103398122440183

Epoch: 211| Step: 0
Training loss: 2.073454692800917
Validation loss: 2.3935879822389676

Epoch: 6| Step: 1
Training loss: 2.10332712729738
Validation loss: 2.39069114945814

Epoch: 6| Step: 2
Training loss: 2.98909302699388
Validation loss: 2.3918550090957127

Epoch: 6| Step: 3
Training loss: 1.7845157333967325
Validation loss: 2.3763991456795863

Epoch: 6| Step: 4
Training loss: 2.4900464274969027
Validation loss: 2.4071401007991993

Epoch: 6| Step: 5
Training loss: 2.2211880250956626
Validation loss: 2.382732425112819

Epoch: 6| Step: 6
Training loss: 2.4838815834887695
Validation loss: 2.4026305826373453

Epoch: 6| Step: 7
Training loss: 2.6556568156594693
Validation loss: 2.4040540059029287

Epoch: 6| Step: 8
Training loss: 1.9330611911606321
Validation loss: 2.383093883644453

Epoch: 6| Step: 9
Training loss: 2.3829752882085553
Validation loss: 2.3605289615813727

Epoch: 6| Step: 10
Training loss: 1.6039298076729838
Validation loss: 2.379205617781028

Epoch: 6| Step: 11
Training loss: 2.1263522165387596
Validation loss: 2.376850685156034

Epoch: 6| Step: 12
Training loss: 1.9633143636610673
Validation loss: 2.3782604809411474

Epoch: 6| Step: 13
Training loss: 1.8260263640014067
Validation loss: 2.3894848561482194

Epoch: 212| Step: 0
Training loss: 1.719816397249015
Validation loss: 2.3968971583520604

Epoch: 6| Step: 1
Training loss: 2.682307438973779
Validation loss: 2.3804596149233452

Epoch: 6| Step: 2
Training loss: 2.3533513055318656
Validation loss: 2.3979462089724066

Epoch: 6| Step: 3
Training loss: 1.8181016454576853
Validation loss: 2.3916077834647758

Epoch: 6| Step: 4
Training loss: 2.3702501684856085
Validation loss: 2.3653915308488305

Epoch: 6| Step: 5
Training loss: 2.3901635017491993
Validation loss: 2.3962980428728984

Epoch: 6| Step: 6
Training loss: 2.6514540515812235
Validation loss: 2.4333288548667555

Epoch: 6| Step: 7
Training loss: 2.2243873009766295
Validation loss: 2.4002316037581566

Epoch: 6| Step: 8
Training loss: 2.2169274379915604
Validation loss: 2.4009725823977544

Epoch: 6| Step: 9
Training loss: 2.2711346161022705
Validation loss: 2.408506708248538

Epoch: 6| Step: 10
Training loss: 2.3980590322894413
Validation loss: 2.418869251379815

Epoch: 6| Step: 11
Training loss: 2.100925958940184
Validation loss: 2.3688439765098455

Epoch: 6| Step: 12
Training loss: 1.8044623692775286
Validation loss: 2.396305846227913

Epoch: 6| Step: 13
Training loss: 1.9705844990893304
Validation loss: 2.3884100468274623

Epoch: 213| Step: 0
Training loss: 2.335187402430001
Validation loss: 2.391906985422762

Epoch: 6| Step: 1
Training loss: 2.0982374242185067
Validation loss: 2.4225209729917663

Epoch: 6| Step: 2
Training loss: 1.8076895972885565
Validation loss: 2.398202978513277

Epoch: 6| Step: 3
Training loss: 1.6635718540167006
Validation loss: 2.391546074229959

Epoch: 6| Step: 4
Training loss: 1.857663111860533
Validation loss: 2.415384950588707

Epoch: 6| Step: 5
Training loss: 2.0777798703070363
Validation loss: 2.379471964634951

Epoch: 6| Step: 6
Training loss: 1.4252222925104867
Validation loss: 2.3687663629135374

Epoch: 6| Step: 7
Training loss: 2.787147184889384
Validation loss: 2.3979220768929226

Epoch: 6| Step: 8
Training loss: 2.6287190567640604
Validation loss: 2.378690348152873

Epoch: 6| Step: 9
Training loss: 2.38233237510453
Validation loss: 2.3852330740939447

Epoch: 6| Step: 10
Training loss: 1.9547446897390433
Validation loss: 2.377679770231464

Epoch: 6| Step: 11
Training loss: 2.1842150409944523
Validation loss: 2.418603557615604

Epoch: 6| Step: 12
Training loss: 2.724012696481656
Validation loss: 2.3905981980425306

Epoch: 6| Step: 13
Training loss: 2.6047597489522833
Validation loss: 2.391464814028269

Epoch: 214| Step: 0
Training loss: 2.496954588880844
Validation loss: 2.3839989500147043

Epoch: 6| Step: 1
Training loss: 2.1459644857776072
Validation loss: 2.3667802206138506

Epoch: 6| Step: 2
Training loss: 1.9476711574065033
Validation loss: 2.3705812786901648

Epoch: 6| Step: 3
Training loss: 2.3825851582121493
Validation loss: 2.411122886494974

Epoch: 6| Step: 4
Training loss: 2.107253979207476
Validation loss: 2.437308958953219

Epoch: 6| Step: 5
Training loss: 1.6337182120256606
Validation loss: 2.3888247099464825

Epoch: 6| Step: 6
Training loss: 1.8729893394122024
Validation loss: 2.3722676015047277

Epoch: 6| Step: 7
Training loss: 2.120203101667804
Validation loss: 2.385868164299724

Epoch: 6| Step: 8
Training loss: 2.2543389551270394
Validation loss: 2.3840799103610566

Epoch: 6| Step: 9
Training loss: 3.0937990126917776
Validation loss: 2.3865209293771996

Epoch: 6| Step: 10
Training loss: 2.067723566442792
Validation loss: 2.411045525944382

Epoch: 6| Step: 11
Training loss: 2.1032859797318624
Validation loss: 2.4239390564347616

Epoch: 6| Step: 12
Training loss: 2.4113892997818787
Validation loss: 2.356766490199161

Epoch: 6| Step: 13
Training loss: 1.6045321588999368
Validation loss: 2.397726245503532

Epoch: 215| Step: 0
Training loss: 1.9696097540275332
Validation loss: 2.4318522454503197

Epoch: 6| Step: 1
Training loss: 1.6254249163922445
Validation loss: 2.4128569835157894

Epoch: 6| Step: 2
Training loss: 1.7593247076133638
Validation loss: 2.3932556668983036

Epoch: 6| Step: 3
Training loss: 2.8110945686872193
Validation loss: 2.3463490590922698

Epoch: 6| Step: 4
Training loss: 2.7096899498519407
Validation loss: 2.359152636921746

Epoch: 6| Step: 5
Training loss: 2.848241926333304
Validation loss: 2.405900309456196

Epoch: 6| Step: 6
Training loss: 2.4470298513470956
Validation loss: 2.3748448110156746

Epoch: 6| Step: 7
Training loss: 2.219504429602451
Validation loss: 2.3818512008818282

Epoch: 6| Step: 8
Training loss: 2.2120117165943283
Validation loss: 2.365923016084404

Epoch: 6| Step: 9
Training loss: 2.2820447817528238
Validation loss: 2.381998798905362

Epoch: 6| Step: 10
Training loss: 1.6979405298096826
Validation loss: 2.3988383091426253

Epoch: 6| Step: 11
Training loss: 1.9329577083825786
Validation loss: 2.3761562993261043

Epoch: 6| Step: 12
Training loss: 1.8064967742561704
Validation loss: 2.4065104347482533

Epoch: 6| Step: 13
Training loss: 2.2484645902845406
Validation loss: 2.3983185553483626

Epoch: 216| Step: 0
Training loss: 2.3544426702785044
Validation loss: 2.361976868196368

Epoch: 6| Step: 1
Training loss: 2.5406755693383625
Validation loss: 2.3956608764156764

Epoch: 6| Step: 2
Training loss: 2.035763230846817
Validation loss: 2.4059050895713243

Epoch: 6| Step: 3
Training loss: 2.118008387584126
Validation loss: 2.4063920244297177

Epoch: 6| Step: 4
Training loss: 1.7025596310203575
Validation loss: 2.39317266882779

Epoch: 6| Step: 5
Training loss: 1.7139105897282156
Validation loss: 2.3821386424361743

Epoch: 6| Step: 6
Training loss: 2.5530619918164184
Validation loss: 2.4457078095430487

Epoch: 6| Step: 7
Training loss: 2.923630783566585
Validation loss: 2.3774999027276547

Epoch: 6| Step: 8
Training loss: 1.9292912250072285
Validation loss: 2.402873672423369

Epoch: 6| Step: 9
Training loss: 2.6334512088645603
Validation loss: 2.385759668497437

Epoch: 6| Step: 10
Training loss: 1.4561715133538016
Validation loss: 2.371276192698366

Epoch: 6| Step: 11
Training loss: 2.046681868199525
Validation loss: 2.3846749679048624

Epoch: 6| Step: 12
Training loss: 2.1121217151956526
Validation loss: 2.377193740639419

Epoch: 6| Step: 13
Training loss: 1.5297812599695035
Validation loss: 2.400417128584095

Epoch: 217| Step: 0
Training loss: 2.022577640660551
Validation loss: 2.404871718074771

Epoch: 6| Step: 1
Training loss: 2.092413518433391
Validation loss: 2.365019090586645

Epoch: 6| Step: 2
Training loss: 1.5034137662585385
Validation loss: 2.375860221441513

Epoch: 6| Step: 3
Training loss: 2.0309418664648473
Validation loss: 2.396067573007458

Epoch: 6| Step: 4
Training loss: 2.1982786293347667
Validation loss: 2.4041351348992466

Epoch: 6| Step: 5
Training loss: 1.642240110765061
Validation loss: 2.392710220879246

Epoch: 6| Step: 6
Training loss: 2.198603759204972
Validation loss: 2.3918501848241354

Epoch: 6| Step: 7
Training loss: 2.202277703730977
Validation loss: 2.4027747319139143

Epoch: 6| Step: 8
Training loss: 2.7082489489589676
Validation loss: 2.36507596974588

Epoch: 6| Step: 9
Training loss: 2.007605159755779
Validation loss: 2.4024642806051504

Epoch: 6| Step: 10
Training loss: 2.143227436224114
Validation loss: 2.39702468577731

Epoch: 6| Step: 11
Training loss: 3.0100444488792046
Validation loss: 2.422866905029478

Epoch: 6| Step: 12
Training loss: 1.7466773779494542
Validation loss: 2.3695717225524855

Epoch: 6| Step: 13
Training loss: 2.8637731527710475
Validation loss: 2.418916669701975

Epoch: 218| Step: 0
Training loss: 1.650498967875031
Validation loss: 2.402417332545872

Epoch: 6| Step: 1
Training loss: 1.9725906210076023
Validation loss: 2.362825672182116

Epoch: 6| Step: 2
Training loss: 2.2420948820224926
Validation loss: 2.3713736209384133

Epoch: 6| Step: 3
Training loss: 2.5323333305803106
Validation loss: 2.388449427266341

Epoch: 6| Step: 4
Training loss: 2.3338911093747927
Validation loss: 2.3696589058937523

Epoch: 6| Step: 5
Training loss: 2.030216834603588
Validation loss: 2.3772971157578495

Epoch: 6| Step: 6
Training loss: 2.9273533996308965
Validation loss: 2.3819984405120684

Epoch: 6| Step: 7
Training loss: 1.999855036250284
Validation loss: 2.3984565601832095

Epoch: 6| Step: 8
Training loss: 1.5851926510815935
Validation loss: 2.3977677620462368

Epoch: 6| Step: 9
Training loss: 1.895933595737897
Validation loss: 2.403165289249092

Epoch: 6| Step: 10
Training loss: 2.082639680462094
Validation loss: 2.398140311713909

Epoch: 6| Step: 11
Training loss: 2.4252382613651897
Validation loss: 2.3785267967472232

Epoch: 6| Step: 12
Training loss: 2.235922324331034
Validation loss: 2.425795456408072

Epoch: 6| Step: 13
Training loss: 2.4535098411808915
Validation loss: 2.3592926703175294

Epoch: 219| Step: 0
Training loss: 1.6882040886146032
Validation loss: 2.3967378919516267

Epoch: 6| Step: 1
Training loss: 2.1592716661562945
Validation loss: 2.3891856636476074

Epoch: 6| Step: 2
Training loss: 1.738136131143986
Validation loss: 2.3725051200039755

Epoch: 6| Step: 3
Training loss: 2.4260739258952295
Validation loss: 2.382338034335891

Epoch: 6| Step: 4
Training loss: 1.930799279810627
Validation loss: 2.389834768351376

Epoch: 6| Step: 5
Training loss: 2.9824640836895333
Validation loss: 2.357095827030261

Epoch: 6| Step: 6
Training loss: 2.613299679085336
Validation loss: 2.3687212903410177

Epoch: 6| Step: 7
Training loss: 2.3861187119733573
Validation loss: 2.3706877202443257

Epoch: 6| Step: 8
Training loss: 2.1636249637012015
Validation loss: 2.368286585935047

Epoch: 6| Step: 9
Training loss: 1.5936198461905409
Validation loss: 2.3826374465061733

Epoch: 6| Step: 10
Training loss: 2.0550513579919056
Validation loss: 2.4077150018669893

Epoch: 6| Step: 11
Training loss: 1.83415271770483
Validation loss: 2.4008196638539183

Epoch: 6| Step: 12
Training loss: 2.1583068546551294
Validation loss: 2.408862480985111

Epoch: 6| Step: 13
Training loss: 2.1384695297043343
Validation loss: 2.3950819505629966

Epoch: 220| Step: 0
Training loss: 2.0069438079281525
Validation loss: 2.3872719937434286

Epoch: 6| Step: 1
Training loss: 2.4552216529619764
Validation loss: 2.3786587784027886

Epoch: 6| Step: 2
Training loss: 2.113968658056134
Validation loss: 2.378011080330629

Epoch: 6| Step: 3
Training loss: 2.3142413207409898
Validation loss: 2.3748274796092597

Epoch: 6| Step: 4
Training loss: 1.812262026192904
Validation loss: 2.3575751242606358

Epoch: 6| Step: 5
Training loss: 2.33727437934724
Validation loss: 2.3919446127320314

Epoch: 6| Step: 6
Training loss: 2.017886172446293
Validation loss: 2.3359259040158658

Epoch: 6| Step: 7
Training loss: 2.13296362931817
Validation loss: 2.3488162631005856

Epoch: 6| Step: 8
Training loss: 2.4491729975416616
Validation loss: 2.4106923075581985

Epoch: 6| Step: 9
Training loss: 2.0132105360835104
Validation loss: 2.3560601064211566

Epoch: 6| Step: 10
Training loss: 2.21451906653452
Validation loss: 2.384268269350005

Epoch: 6| Step: 11
Training loss: 1.5573842032846696
Validation loss: 2.3960237068060617

Epoch: 6| Step: 12
Training loss: 2.494431014993602
Validation loss: 2.398008895543952

Epoch: 6| Step: 13
Training loss: 2.5481242293131423
Validation loss: 2.3918877851599807

Epoch: 221| Step: 0
Training loss: 1.8847054111171686
Validation loss: 2.4143622549744417

Epoch: 6| Step: 1
Training loss: 2.168227721546824
Validation loss: 2.39478387804657

Epoch: 6| Step: 2
Training loss: 2.0866998429550483
Validation loss: 2.3933492001065173

Epoch: 6| Step: 3
Training loss: 1.7918679176086818
Validation loss: 2.4097837090162564

Epoch: 6| Step: 4
Training loss: 1.5524307817886351
Validation loss: 2.379818649598865

Epoch: 6| Step: 5
Training loss: 2.106807474227171
Validation loss: 2.355336870797211

Epoch: 6| Step: 6
Training loss: 2.681716906746894
Validation loss: 2.3833133751389015

Epoch: 6| Step: 7
Training loss: 2.6717034000370954
Validation loss: 2.4016520541777298

Epoch: 6| Step: 8
Training loss: 2.448365472003122
Validation loss: 2.3824425323872185

Epoch: 6| Step: 9
Training loss: 2.2827344271385908
Validation loss: 2.403045621664803

Epoch: 6| Step: 10
Training loss: 2.504972091184312
Validation loss: 2.398243558940911

Epoch: 6| Step: 11
Training loss: 1.9678245670311487
Validation loss: 2.3924683015223436

Epoch: 6| Step: 12
Training loss: 2.0561369798204487
Validation loss: 2.361087793729313

Epoch: 6| Step: 13
Training loss: 1.6987934851957809
Validation loss: 2.402030665507714

Epoch: 222| Step: 0
Training loss: 1.9226562648805745
Validation loss: 2.3836556414042596

Epoch: 6| Step: 1
Training loss: 2.128246072022362
Validation loss: 2.343285244491591

Epoch: 6| Step: 2
Training loss: 2.157800531595836
Validation loss: 2.4040372135222334

Epoch: 6| Step: 3
Training loss: 1.6932053369421314
Validation loss: 2.411684781536645

Epoch: 6| Step: 4
Training loss: 2.1662736193849033
Validation loss: 2.3774271783251844

Epoch: 6| Step: 5
Training loss: 3.127012901521082
Validation loss: 2.3675649103758434

Epoch: 6| Step: 6
Training loss: 1.8851991461226005
Validation loss: 2.396778075220123

Epoch: 6| Step: 7
Training loss: 1.8240536731469148
Validation loss: 2.3647129160119005

Epoch: 6| Step: 8
Training loss: 2.1234508926609252
Validation loss: 2.3810793437961384

Epoch: 6| Step: 9
Training loss: 2.6937655667521225
Validation loss: 2.3442163409543615

Epoch: 6| Step: 10
Training loss: 2.173768240625628
Validation loss: 2.3818283644325593

Epoch: 6| Step: 11
Training loss: 2.3752778543265007
Validation loss: 2.3921960971954523

Epoch: 6| Step: 12
Training loss: 1.865360084012396
Validation loss: 2.3736568040987445

Epoch: 6| Step: 13
Training loss: 1.3202391835459284
Validation loss: 2.4004633692470922

Epoch: 223| Step: 0
Training loss: 2.635840149479786
Validation loss: 2.376824009388645

Epoch: 6| Step: 1
Training loss: 2.6400190933577465
Validation loss: 2.378836288674828

Epoch: 6| Step: 2
Training loss: 2.1558041318909575
Validation loss: 2.3695629683390877

Epoch: 6| Step: 3
Training loss: 2.1637484876956865
Validation loss: 2.416067176001141

Epoch: 6| Step: 4
Training loss: 1.7116782618460795
Validation loss: 2.3909352236855743

Epoch: 6| Step: 5
Training loss: 2.0738152580271634
Validation loss: 2.3671862870507736

Epoch: 6| Step: 6
Training loss: 2.3979564271265867
Validation loss: 2.3487935153123165

Epoch: 6| Step: 7
Training loss: 1.9721751617882257
Validation loss: 2.389358564680184

Epoch: 6| Step: 8
Training loss: 1.89753130096633
Validation loss: 2.356652949463652

Epoch: 6| Step: 9
Training loss: 1.7787315902775958
Validation loss: 2.3785571530148193

Epoch: 6| Step: 10
Training loss: 1.696778538106594
Validation loss: 2.405499804155897

Epoch: 6| Step: 11
Training loss: 2.4728678873377605
Validation loss: 2.36220969335922

Epoch: 6| Step: 12
Training loss: 2.306837210809487
Validation loss: 2.39469459582924

Epoch: 6| Step: 13
Training loss: 1.8055134654233607
Validation loss: 2.402726360712747

Epoch: 224| Step: 0
Training loss: 2.1460120364346658
Validation loss: 2.3636278498152987

Epoch: 6| Step: 1
Training loss: 2.3993366556564157
Validation loss: 2.3779254667435796

Epoch: 6| Step: 2
Training loss: 2.221499177076147
Validation loss: 2.3985474488367897

Epoch: 6| Step: 3
Training loss: 2.2367613526876204
Validation loss: 2.3876773775424773

Epoch: 6| Step: 4
Training loss: 2.0834654829710257
Validation loss: 2.3847131732008164

Epoch: 6| Step: 5
Training loss: 2.1950935444634956
Validation loss: 2.40891275899457

Epoch: 6| Step: 6
Training loss: 2.233820492956177
Validation loss: 2.397877816431256

Epoch: 6| Step: 7
Training loss: 1.6835475127559987
Validation loss: 2.381382035098761

Epoch: 6| Step: 8
Training loss: 1.963420132249503
Validation loss: 2.430328586331264

Epoch: 6| Step: 9
Training loss: 1.9421506256752252
Validation loss: 2.452092897474207

Epoch: 6| Step: 10
Training loss: 2.2016454828568195
Validation loss: 2.415122551590317

Epoch: 6| Step: 11
Training loss: 2.380892220599933
Validation loss: 2.399051428022318

Epoch: 6| Step: 12
Training loss: 2.275085690739476
Validation loss: 2.4411357072462185

Epoch: 6| Step: 13
Training loss: 2.3016453206893055
Validation loss: 2.4218243813625095

Epoch: 225| Step: 0
Training loss: 1.6019308271439887
Validation loss: 2.3991576958591367

Epoch: 6| Step: 1
Training loss: 1.7699290116940163
Validation loss: 2.383266108449917

Epoch: 6| Step: 2
Training loss: 2.7285914700670126
Validation loss: 2.3894765466453594

Epoch: 6| Step: 3
Training loss: 1.7885433593220625
Validation loss: 2.391721480041117

Epoch: 6| Step: 4
Training loss: 2.4021443602151042
Validation loss: 2.390980604461881

Epoch: 6| Step: 5
Training loss: 2.101115920255606
Validation loss: 2.349564625606438

Epoch: 6| Step: 6
Training loss: 2.5691384645939865
Validation loss: 2.361285737601579

Epoch: 6| Step: 7
Training loss: 1.948650697792564
Validation loss: 2.39161011437952

Epoch: 6| Step: 8
Training loss: 2.144576275462273
Validation loss: 2.3636782093210544

Epoch: 6| Step: 9
Training loss: 1.7925970485916194
Validation loss: 2.3653380646958255

Epoch: 6| Step: 10
Training loss: 1.9701945742258145
Validation loss: 2.3785781018415997

Epoch: 6| Step: 11
Training loss: 1.5286286941771914
Validation loss: 2.3652859088061535

Epoch: 6| Step: 12
Training loss: 2.6922614921546293
Validation loss: 2.4002739271439615

Epoch: 6| Step: 13
Training loss: 2.1362326450881772
Validation loss: 2.379518615552891

Epoch: 226| Step: 0
Training loss: 1.7916319274491623
Validation loss: 2.3688890857076688

Epoch: 6| Step: 1
Training loss: 1.5289959568845934
Validation loss: 2.389487541575954

Epoch: 6| Step: 2
Training loss: 2.2987624736735794
Validation loss: 2.380154916022044

Epoch: 6| Step: 3
Training loss: 2.1026611859635786
Validation loss: 2.3568200991361627

Epoch: 6| Step: 4
Training loss: 1.6215964399672256
Validation loss: 2.3646984873693877

Epoch: 6| Step: 5
Training loss: 1.7132118471963773
Validation loss: 2.3567463934000603

Epoch: 6| Step: 6
Training loss: 2.4355889678474676
Validation loss: 2.398394617240653

Epoch: 6| Step: 7
Training loss: 2.5867644771127676
Validation loss: 2.407470998492988

Epoch: 6| Step: 8
Training loss: 1.999740822211235
Validation loss: 2.36092350612778

Epoch: 6| Step: 9
Training loss: 1.7891027454363897
Validation loss: 2.372131891290218

Epoch: 6| Step: 10
Training loss: 2.930296974364747
Validation loss: 2.3529884017105465

Epoch: 6| Step: 11
Training loss: 2.183700094891959
Validation loss: 2.3774747632802447

Epoch: 6| Step: 12
Training loss: 2.1815777857515015
Validation loss: 2.3680482275115318

Epoch: 6| Step: 13
Training loss: 2.2337640313816247
Validation loss: 2.380424487453018

Epoch: 227| Step: 0
Training loss: 1.5167939702079125
Validation loss: 2.3315460216397215

Epoch: 6| Step: 1
Training loss: 1.8501388291514205
Validation loss: 2.3795939704756286

Epoch: 6| Step: 2
Training loss: 1.7138337308655738
Validation loss: 2.426174309587453

Epoch: 6| Step: 3
Training loss: 2.3173206705216383
Validation loss: 2.4017151118211153

Epoch: 6| Step: 4
Training loss: 1.9541728756391823
Validation loss: 2.406270664586079

Epoch: 6| Step: 5
Training loss: 2.436438696234283
Validation loss: 2.421794075727

Epoch: 6| Step: 6
Training loss: 1.823457873703761
Validation loss: 2.4129772551154383

Epoch: 6| Step: 7
Training loss: 1.7977969250931851
Validation loss: 2.397160650800934

Epoch: 6| Step: 8
Training loss: 2.7797660726471456
Validation loss: 2.384517651981413

Epoch: 6| Step: 9
Training loss: 2.224825104258165
Validation loss: 2.4001401924817714

Epoch: 6| Step: 10
Training loss: 2.184266670826213
Validation loss: 2.3760337609099866

Epoch: 6| Step: 11
Training loss: 2.624194612020109
Validation loss: 2.4358457089932295

Epoch: 6| Step: 12
Training loss: 1.7788530250464194
Validation loss: 2.39723632915228

Epoch: 6| Step: 13
Training loss: 2.138629400798264
Validation loss: 2.433045064902024

Epoch: 228| Step: 0
Training loss: 1.8684091442130208
Validation loss: 2.467043804068832

Epoch: 6| Step: 1
Training loss: 1.9672375273460023
Validation loss: 2.401569899777004

Epoch: 6| Step: 2
Training loss: 2.4489714818612582
Validation loss: 2.387875246760936

Epoch: 6| Step: 3
Training loss: 2.221457427927769
Validation loss: 2.418537341613137

Epoch: 6| Step: 4
Training loss: 2.3846959409288164
Validation loss: 2.39243980143477

Epoch: 6| Step: 5
Training loss: 2.1118723461702307
Validation loss: 2.3981037768834295

Epoch: 6| Step: 6
Training loss: 1.7514713096871517
Validation loss: 2.3809215060369566

Epoch: 6| Step: 7
Training loss: 1.708519188920245
Validation loss: 2.3650688307943524

Epoch: 6| Step: 8
Training loss: 2.830686305100892
Validation loss: 2.36829617891988

Epoch: 6| Step: 9
Training loss: 1.7437515422855243
Validation loss: 2.3690794251155505

Epoch: 6| Step: 10
Training loss: 1.8435147668812497
Validation loss: 2.3841714126687577

Epoch: 6| Step: 11
Training loss: 1.4716294652802568
Validation loss: 2.3929257694942816

Epoch: 6| Step: 12
Training loss: 2.692534410970499
Validation loss: 2.350039034039044

Epoch: 6| Step: 13
Training loss: 2.0246594837368206
Validation loss: 2.394538173710025

Epoch: 229| Step: 0
Training loss: 2.5650809711369287
Validation loss: 2.4104908378381635

Epoch: 6| Step: 1
Training loss: 2.1429035840224495
Validation loss: 2.372511753569369

Epoch: 6| Step: 2
Training loss: 1.624566827406304
Validation loss: 2.365423608226474

Epoch: 6| Step: 3
Training loss: 2.046387243031876
Validation loss: 2.3266274006439644

Epoch: 6| Step: 4
Training loss: 2.324550983180834
Validation loss: 2.376515779662135

Epoch: 6| Step: 5
Training loss: 1.862791432871254
Validation loss: 2.3600714354543006

Epoch: 6| Step: 6
Training loss: 2.1408722449310726
Validation loss: 2.3939358730994287

Epoch: 6| Step: 7
Training loss: 2.0524254011938705
Validation loss: 2.3817343610288866

Epoch: 6| Step: 8
Training loss: 2.099722698613266
Validation loss: 2.4125045547642134

Epoch: 6| Step: 9
Training loss: 2.6693040402215455
Validation loss: 2.3942869812886407

Epoch: 6| Step: 10
Training loss: 1.8060738659155295
Validation loss: 2.3576602491918917

Epoch: 6| Step: 11
Training loss: 1.6652209051179356
Validation loss: 2.419998921077403

Epoch: 6| Step: 12
Training loss: 1.8055920336372233
Validation loss: 2.4014680691250523

Epoch: 6| Step: 13
Training loss: 2.496329760549872
Validation loss: 2.35262955331952

Epoch: 230| Step: 0
Training loss: 1.5820360725235139
Validation loss: 2.3907875157536407

Epoch: 6| Step: 1
Training loss: 2.3225331581467072
Validation loss: 2.3994099169319574

Epoch: 6| Step: 2
Training loss: 2.17322317310338
Validation loss: 2.396772409438782

Epoch: 6| Step: 3
Training loss: 1.893624692491409
Validation loss: 2.404640631211074

Epoch: 6| Step: 4
Training loss: 1.99210408354006
Validation loss: 2.392721760238599

Epoch: 6| Step: 5
Training loss: 2.3389367079307757
Validation loss: 2.4274083613095407

Epoch: 6| Step: 6
Training loss: 2.5508025608078007
Validation loss: 2.3636987233184237

Epoch: 6| Step: 7
Training loss: 2.203727693839734
Validation loss: 2.3716839133616836

Epoch: 6| Step: 8
Training loss: 1.4358695361768263
Validation loss: 2.383078000510952

Epoch: 6| Step: 9
Training loss: 1.6902501337609634
Validation loss: 2.378194167902291

Epoch: 6| Step: 10
Training loss: 2.746746653052645
Validation loss: 2.3912241270298837

Epoch: 6| Step: 11
Training loss: 2.0837109287125304
Validation loss: 2.4021912154260647

Epoch: 6| Step: 12
Training loss: 2.323198674849981
Validation loss: 2.367458180066651

Epoch: 6| Step: 13
Training loss: 1.590589568637222
Validation loss: 2.3818841522749

Epoch: 231| Step: 0
Training loss: 2.1232013944458856
Validation loss: 2.397256453320432

Epoch: 6| Step: 1
Training loss: 1.895792433189232
Validation loss: 2.4005816725967017

Epoch: 6| Step: 2
Training loss: 2.251602238152863
Validation loss: 2.3775061665213215

Epoch: 6| Step: 3
Training loss: 1.977396611863933
Validation loss: 2.40799207236361

Epoch: 6| Step: 4
Training loss: 1.9451885260484978
Validation loss: 2.4052388091210095

Epoch: 6| Step: 5
Training loss: 3.0487738536669498
Validation loss: 2.417115875887777

Epoch: 6| Step: 6
Training loss: 1.8454118771324728
Validation loss: 2.418779944578731

Epoch: 6| Step: 7
Training loss: 1.4616411931693702
Validation loss: 2.4363664189849006

Epoch: 6| Step: 8
Training loss: 2.162218981879066
Validation loss: 2.3921719885568136

Epoch: 6| Step: 9
Training loss: 2.175385745689166
Validation loss: 2.3994217339188793

Epoch: 6| Step: 10
Training loss: 2.273988217902884
Validation loss: 2.3823139456528697

Epoch: 6| Step: 11
Training loss: 1.8949522199621105
Validation loss: 2.405645761533142

Epoch: 6| Step: 12
Training loss: 1.8748762089872733
Validation loss: 2.411134775261513

Epoch: 6| Step: 13
Training loss: 2.1220977261805003
Validation loss: 2.451935989372362

Epoch: 232| Step: 0
Training loss: 2.0209533288730124
Validation loss: 2.4165425429612775

Epoch: 6| Step: 1
Training loss: 1.437304276120168
Validation loss: 2.4061486252545468

Epoch: 6| Step: 2
Training loss: 1.6712148914059006
Validation loss: 2.3667850158312085

Epoch: 6| Step: 3
Training loss: 2.0922653856088953
Validation loss: 2.383291902668922

Epoch: 6| Step: 4
Training loss: 2.1552809597172766
Validation loss: 2.4205560507154193

Epoch: 6| Step: 5
Training loss: 1.9896763551812415
Validation loss: 2.393410479924415

Epoch: 6| Step: 6
Training loss: 1.4142583216179083
Validation loss: 2.396536084047394

Epoch: 6| Step: 7
Training loss: 2.130971036759833
Validation loss: 2.4124411117811007

Epoch: 6| Step: 8
Training loss: 1.6740056659279012
Validation loss: 2.3784120657524834

Epoch: 6| Step: 9
Training loss: 1.7233578038399782
Validation loss: 2.3720960020453767

Epoch: 6| Step: 10
Training loss: 2.0699834598120015
Validation loss: 2.3836993684683954

Epoch: 6| Step: 11
Training loss: 2.625608101299836
Validation loss: 2.421961391891542

Epoch: 6| Step: 12
Training loss: 1.999657720840944
Validation loss: 2.3787221696748118

Epoch: 6| Step: 13
Training loss: 3.3111258481556116
Validation loss: 2.3773593053851765

Epoch: 233| Step: 0
Training loss: 2.1806486464902357
Validation loss: 2.4184123616400584

Epoch: 6| Step: 1
Training loss: 1.936541166238817
Validation loss: 2.358141227665832

Epoch: 6| Step: 2
Training loss: 2.0287891446683584
Validation loss: 2.3739227772887226

Epoch: 6| Step: 3
Training loss: 1.729384450717769
Validation loss: 2.407213112869402

Epoch: 6| Step: 4
Training loss: 2.30746819801775
Validation loss: 2.3808501470535472

Epoch: 6| Step: 5
Training loss: 2.421657823238866
Validation loss: 2.406040412651097

Epoch: 6| Step: 6
Training loss: 1.5992625772334357
Validation loss: 2.3555639006231526

Epoch: 6| Step: 7
Training loss: 2.250523188480227
Validation loss: 2.372693319554901

Epoch: 6| Step: 8
Training loss: 1.9030600575859216
Validation loss: 2.3855120825224443

Epoch: 6| Step: 9
Training loss: 2.1362915727868144
Validation loss: 2.4007460430182306

Epoch: 6| Step: 10
Training loss: 2.025074418195775
Validation loss: 2.374689126083576

Epoch: 6| Step: 11
Training loss: 2.3011016363569703
Validation loss: 2.3648547682216208

Epoch: 6| Step: 12
Training loss: 1.6615164895078882
Validation loss: 2.3788084599428365

Epoch: 6| Step: 13
Training loss: 2.565685989825854
Validation loss: 2.3921597105661987

Epoch: 234| Step: 0
Training loss: 2.080713022970722
Validation loss: 2.3669237885921075

Epoch: 6| Step: 1
Training loss: 1.2904043900412174
Validation loss: 2.36891025909446

Epoch: 6| Step: 2
Training loss: 2.1220442467048475
Validation loss: 2.373376887527195

Epoch: 6| Step: 3
Training loss: 2.7180937928780757
Validation loss: 2.358677717643241

Epoch: 6| Step: 4
Training loss: 2.049579842472639
Validation loss: 2.381740558791246

Epoch: 6| Step: 5
Training loss: 2.258199374834717
Validation loss: 2.359855397041987

Epoch: 6| Step: 6
Training loss: 2.13797646281719
Validation loss: 2.4061388880508976

Epoch: 6| Step: 7
Training loss: 2.4716221965854346
Validation loss: 2.388962495402296

Epoch: 6| Step: 8
Training loss: 2.12742095370089
Validation loss: 2.388730715709776

Epoch: 6| Step: 9
Training loss: 1.8608270953504207
Validation loss: 2.3572040499400178

Epoch: 6| Step: 10
Training loss: 1.8797946661558436
Validation loss: 2.386862238401403

Epoch: 6| Step: 11
Training loss: 2.3602737836921324
Validation loss: 2.391907493454864

Epoch: 6| Step: 12
Training loss: 1.4630993845643394
Validation loss: 2.3821828455722254

Epoch: 6| Step: 13
Training loss: 2.047970776960377
Validation loss: 2.405123514737098

Epoch: 235| Step: 0
Training loss: 2.142220563793376
Validation loss: 2.4152067160663706

Epoch: 6| Step: 1
Training loss: 2.0445366235122355
Validation loss: 2.400817499384013

Epoch: 6| Step: 2
Training loss: 2.3675420010958885
Validation loss: 2.381849785516991

Epoch: 6| Step: 3
Training loss: 1.5812490531104348
Validation loss: 2.3674046425523585

Epoch: 6| Step: 4
Training loss: 2.044146867301882
Validation loss: 2.41205894786502

Epoch: 6| Step: 5
Training loss: 2.0187554704810506
Validation loss: 2.401697093690638

Epoch: 6| Step: 6
Training loss: 1.7392173046983048
Validation loss: 2.3837378652590395

Epoch: 6| Step: 7
Training loss: 1.8982574000702293
Validation loss: 2.3569496530667804

Epoch: 6| Step: 8
Training loss: 2.197147240734458
Validation loss: 2.3451426781210882

Epoch: 6| Step: 9
Training loss: 1.818287258992203
Validation loss: 2.387283741947913

Epoch: 6| Step: 10
Training loss: 1.5193407581633898
Validation loss: 2.375933143788135

Epoch: 6| Step: 11
Training loss: 2.5921239696809133
Validation loss: 2.3736807241299775

Epoch: 6| Step: 12
Training loss: 2.35061078757767
Validation loss: 2.3847891148704727

Epoch: 6| Step: 13
Training loss: 2.7585684196888676
Validation loss: 2.3842314585113074

Epoch: 236| Step: 0
Training loss: 1.9358669289695138
Validation loss: 2.400047022733157

Epoch: 6| Step: 1
Training loss: 2.571042591978131
Validation loss: 2.414652506623775

Epoch: 6| Step: 2
Training loss: 1.5722170235840331
Validation loss: 2.362041566223517

Epoch: 6| Step: 3
Training loss: 2.637325324470978
Validation loss: 2.3463829040315374

Epoch: 6| Step: 4
Training loss: 2.235335563712406
Validation loss: 2.3530773984547584

Epoch: 6| Step: 5
Training loss: 1.6900381144903731
Validation loss: 2.3951640331575366

Epoch: 6| Step: 6
Training loss: 2.181855685460827
Validation loss: 2.4181140204829705

Epoch: 6| Step: 7
Training loss: 1.5617671010641467
Validation loss: 2.3740265993621215

Epoch: 6| Step: 8
Training loss: 1.9891391544599548
Validation loss: 2.3820888357092054

Epoch: 6| Step: 9
Training loss: 1.739087618554734
Validation loss: 2.4378508858746186

Epoch: 6| Step: 10
Training loss: 1.978753003174171
Validation loss: 2.404495618234543

Epoch: 6| Step: 11
Training loss: 1.779726079266433
Validation loss: 2.4012710263856887

Epoch: 6| Step: 12
Training loss: 2.796451472602921
Validation loss: 2.3861900305062553

Epoch: 6| Step: 13
Training loss: 1.704616908107438
Validation loss: 2.370322933548955

Epoch: 237| Step: 0
Training loss: 2.162052805090739
Validation loss: 2.4152861128856875

Epoch: 6| Step: 1
Training loss: 2.85095793703668
Validation loss: 2.4127696323629952

Epoch: 6| Step: 2
Training loss: 1.5376563450166207
Validation loss: 2.3961043309358536

Epoch: 6| Step: 3
Training loss: 1.9740950672095565
Validation loss: 2.350289627115012

Epoch: 6| Step: 4
Training loss: 2.04598164172993
Validation loss: 2.390773175847309

Epoch: 6| Step: 5
Training loss: 2.0215052506847817
Validation loss: 2.386204056308772

Epoch: 6| Step: 6
Training loss: 2.1983785159095435
Validation loss: 2.3910955777847516

Epoch: 6| Step: 7
Training loss: 1.4235189806065014
Validation loss: 2.365718082655656

Epoch: 6| Step: 8
Training loss: 2.628510443945518
Validation loss: 2.3553028024084326

Epoch: 6| Step: 9
Training loss: 1.7245420483832354
Validation loss: 2.3588951870888213

Epoch: 6| Step: 10
Training loss: 2.5935107201199683
Validation loss: 2.3752246279832203

Epoch: 6| Step: 11
Training loss: 1.4634507536791985
Validation loss: 2.3593600095476286

Epoch: 6| Step: 12
Training loss: 2.1162433841824977
Validation loss: 2.343063741866528

Epoch: 6| Step: 13
Training loss: 1.1454007227955811
Validation loss: 2.3984212871812014

Epoch: 238| Step: 0
Training loss: 1.4538601892094254
Validation loss: 2.3883952310961805

Epoch: 6| Step: 1
Training loss: 2.1498618103683826
Validation loss: 2.3444042482186243

Epoch: 6| Step: 2
Training loss: 1.506915364177737
Validation loss: 2.392124180744006

Epoch: 6| Step: 3
Training loss: 1.8948410567406593
Validation loss: 2.4247045568938748

Epoch: 6| Step: 4
Training loss: 2.0694817945735324
Validation loss: 2.362821522094296

Epoch: 6| Step: 5
Training loss: 2.980862612716922
Validation loss: 2.3895044662458256

Epoch: 6| Step: 6
Training loss: 1.6712347926130562
Validation loss: 2.3536544356516047

Epoch: 6| Step: 7
Training loss: 2.05300056626228
Validation loss: 2.357114957220743

Epoch: 6| Step: 8
Training loss: 2.512982040395745
Validation loss: 2.397697342808126

Epoch: 6| Step: 9
Training loss: 1.7310024153297539
Validation loss: 2.3289614475101885

Epoch: 6| Step: 10
Training loss: 1.9093887878020046
Validation loss: 2.365194804217403

Epoch: 6| Step: 11
Training loss: 1.9461011398708048
Validation loss: 2.3849377726177554

Epoch: 6| Step: 12
Training loss: 2.2504959619465104
Validation loss: 2.3790949916615594

Epoch: 6| Step: 13
Training loss: 2.0579924601054373
Validation loss: 2.4071736038121148

Epoch: 239| Step: 0
Training loss: 1.8957563391620624
Validation loss: 2.3461604203214046

Epoch: 6| Step: 1
Training loss: 2.48763430822268
Validation loss: 2.452977038267976

Epoch: 6| Step: 2
Training loss: 1.9092089716623992
Validation loss: 2.364457312514417

Epoch: 6| Step: 3
Training loss: 2.4159742766583534
Validation loss: 2.3763898486310433

Epoch: 6| Step: 4
Training loss: 1.923191271096603
Validation loss: 2.3437098520866932

Epoch: 6| Step: 5
Training loss: 1.8592402946338882
Validation loss: 2.3410402380218587

Epoch: 6| Step: 6
Training loss: 2.047916991607961
Validation loss: 2.413347205658871

Epoch: 6| Step: 7
Training loss: 2.282560311864952
Validation loss: 2.3888417450199904

Epoch: 6| Step: 8
Training loss: 1.3561345205058086
Validation loss: 2.3618445220282362

Epoch: 6| Step: 9
Training loss: 1.9415189836955735
Validation loss: 2.398630519041317

Epoch: 6| Step: 10
Training loss: 2.1009954091548013
Validation loss: 2.3934983201627222

Epoch: 6| Step: 11
Training loss: 2.2325309132724325
Validation loss: 2.4106951512106196

Epoch: 6| Step: 12
Training loss: 1.8965018494544452
Validation loss: 2.403136907488513

Epoch: 6| Step: 13
Training loss: 2.284936095498133
Validation loss: 2.4066459762505468

Epoch: 240| Step: 0
Training loss: 2.037366139513953
Validation loss: 2.4029240202627773

Epoch: 6| Step: 1
Training loss: 1.9475155041607584
Validation loss: 2.354361066996284

Epoch: 6| Step: 2
Training loss: 1.905200481728848
Validation loss: 2.3629914983018647

Epoch: 6| Step: 3
Training loss: 2.0014523954579033
Validation loss: 2.3884045672824095

Epoch: 6| Step: 4
Training loss: 1.054286852432446
Validation loss: 2.3892991251584004

Epoch: 6| Step: 5
Training loss: 1.9450831143976015
Validation loss: 2.371675766326344

Epoch: 6| Step: 6
Training loss: 1.6171771800131165
Validation loss: 2.364087847093163

Epoch: 6| Step: 7
Training loss: 2.736332394408027
Validation loss: 2.3595547009016618

Epoch: 6| Step: 8
Training loss: 1.8247985571899463
Validation loss: 2.3432850125557465

Epoch: 6| Step: 9
Training loss: 2.0431538310194544
Validation loss: 2.385186488725676

Epoch: 6| Step: 10
Training loss: 1.7836009790288236
Validation loss: 2.3490275456540664

Epoch: 6| Step: 11
Training loss: 2.111409880037165
Validation loss: 2.3724933607508043

Epoch: 6| Step: 12
Training loss: 2.372529803170268
Validation loss: 2.4015474168294992

Epoch: 6| Step: 13
Training loss: 2.3618507784963962
Validation loss: 2.37696990703371

Epoch: 241| Step: 0
Training loss: 1.8038150280223342
Validation loss: 2.3466123574747244

Epoch: 6| Step: 1
Training loss: 2.2432266645120116
Validation loss: 2.3690997689826663

Epoch: 6| Step: 2
Training loss: 2.2740353981155006
Validation loss: 2.3733726241088013

Epoch: 6| Step: 3
Training loss: 1.7558356125425594
Validation loss: 2.40379971679437

Epoch: 6| Step: 4
Training loss: 2.1796116969555874
Validation loss: 2.3641393278156526

Epoch: 6| Step: 5
Training loss: 1.3733868239148894
Validation loss: 2.353124747506237

Epoch: 6| Step: 6
Training loss: 1.767141652882742
Validation loss: 2.354144695664779

Epoch: 6| Step: 7
Training loss: 2.1641360934857885
Validation loss: 2.3228929609401225

Epoch: 6| Step: 8
Training loss: 2.391836719470759
Validation loss: 2.4000363581733675

Epoch: 6| Step: 9
Training loss: 2.395869467642477
Validation loss: 2.36467656832691

Epoch: 6| Step: 10
Training loss: 2.023603395709001
Validation loss: 2.38690111487247

Epoch: 6| Step: 11
Training loss: 1.963882059261971
Validation loss: 2.3764321888520192

Epoch: 6| Step: 12
Training loss: 1.5248218995201859
Validation loss: 2.417039252326671

Epoch: 6| Step: 13
Training loss: 2.378135117698531
Validation loss: 2.3176837259396366

Epoch: 242| Step: 0
Training loss: 2.152252583035472
Validation loss: 2.387012952620532

Epoch: 6| Step: 1
Training loss: 2.112478502152887
Validation loss: 2.369493679462587

Epoch: 6| Step: 2
Training loss: 2.2485650042976846
Validation loss: 2.3714894405180917

Epoch: 6| Step: 3
Training loss: 2.8107172083982297
Validation loss: 2.4041900212501086

Epoch: 6| Step: 4
Training loss: 2.097632495028144
Validation loss: 2.356571816527402

Epoch: 6| Step: 5
Training loss: 1.8794013816369697
Validation loss: 2.45004955640929

Epoch: 6| Step: 6
Training loss: 1.6167661698516222
Validation loss: 2.424310196252462

Epoch: 6| Step: 7
Training loss: 1.6622882392651313
Validation loss: 2.4008815650520043

Epoch: 6| Step: 8
Training loss: 1.6740806504832764
Validation loss: 2.417286841731783

Epoch: 6| Step: 9
Training loss: 1.0990257001480341
Validation loss: 2.347783427427788

Epoch: 6| Step: 10
Training loss: 1.5272088735203757
Validation loss: 2.409296190214029

Epoch: 6| Step: 11
Training loss: 2.0008955381045603
Validation loss: 2.4140021225046318

Epoch: 6| Step: 12
Training loss: 2.010349200076942
Validation loss: 2.3766585287035245

Epoch: 6| Step: 13
Training loss: 2.604427375459052
Validation loss: 2.399056329712813

Epoch: 243| Step: 0
Training loss: 2.429979509180903
Validation loss: 2.421698822589289

Epoch: 6| Step: 1
Training loss: 2.4859993860392837
Validation loss: 2.4146491325334623

Epoch: 6| Step: 2
Training loss: 1.3913455767846052
Validation loss: 2.374961088473818

Epoch: 6| Step: 3
Training loss: 1.7358715714399984
Validation loss: 2.392321763073562

Epoch: 6| Step: 4
Training loss: 2.1134411086790985
Validation loss: 2.3989782621285882

Epoch: 6| Step: 5
Training loss: 1.425810429522687
Validation loss: 2.379588822921736

Epoch: 6| Step: 6
Training loss: 2.080661459065066
Validation loss: 2.3713984726368573

Epoch: 6| Step: 7
Training loss: 1.939921619267324
Validation loss: 2.3655018224448523

Epoch: 6| Step: 8
Training loss: 1.8005756252501235
Validation loss: 2.3849452460553424

Epoch: 6| Step: 9
Training loss: 2.4022752705559998
Validation loss: 2.3802905113057595

Epoch: 6| Step: 10
Training loss: 1.771078952883985
Validation loss: 2.3964304841021766

Epoch: 6| Step: 11
Training loss: 1.955642603462457
Validation loss: 2.3774539147194256

Epoch: 6| Step: 12
Training loss: 2.195855667415685
Validation loss: 2.3727910250811792

Epoch: 6| Step: 13
Training loss: 2.088941261579615
Validation loss: 2.3463703790626536

Epoch: 244| Step: 0
Training loss: 1.8298860854250802
Validation loss: 2.365714914023563

Epoch: 6| Step: 1
Training loss: 2.2454032566361235
Validation loss: 2.383420273686455

Epoch: 6| Step: 2
Training loss: 1.7861101869679947
Validation loss: 2.417382384311453

Epoch: 6| Step: 3
Training loss: 1.9312601823754376
Validation loss: 2.3461915499376516

Epoch: 6| Step: 4
Training loss: 1.8238602149086458
Validation loss: 2.3747041503970605

Epoch: 6| Step: 5
Training loss: 3.072579747927309
Validation loss: 2.383607541513852

Epoch: 6| Step: 6
Training loss: 2.0348701495608337
Validation loss: 2.3579653015293935

Epoch: 6| Step: 7
Training loss: 1.8011708531142054
Validation loss: 2.318706733678736

Epoch: 6| Step: 8
Training loss: 1.0364567486672611
Validation loss: 2.3691875724075993

Epoch: 6| Step: 9
Training loss: 1.979659236715239
Validation loss: 2.3165449724734075

Epoch: 6| Step: 10
Training loss: 1.7705125256332055
Validation loss: 2.3562680085315106

Epoch: 6| Step: 11
Training loss: 2.1264466242223206
Validation loss: 2.3646990218454307

Epoch: 6| Step: 12
Training loss: 2.1241836101604004
Validation loss: 2.400612254563601

Epoch: 6| Step: 13
Training loss: 1.8965657115587897
Validation loss: 2.3622079048298703

Epoch: 245| Step: 0
Training loss: 2.4448525480652212
Validation loss: 2.3725548199666826

Epoch: 6| Step: 1
Training loss: 1.653204727413637
Validation loss: 2.399741631618731

Epoch: 6| Step: 2
Training loss: 1.8501526821125591
Validation loss: 2.40375764212769

Epoch: 6| Step: 3
Training loss: 1.8288712893749455
Validation loss: 2.3563938094698544

Epoch: 6| Step: 4
Training loss: 1.5812039696548779
Validation loss: 2.389903884771161

Epoch: 6| Step: 5
Training loss: 1.793192731044144
Validation loss: 2.34314369590423

Epoch: 6| Step: 6
Training loss: 2.1913594667605394
Validation loss: 2.3915955253563097

Epoch: 6| Step: 7
Training loss: 2.2325579317272073
Validation loss: 2.3816657938429215

Epoch: 6| Step: 8
Training loss: 2.5541107739985973
Validation loss: 2.3686994096063265

Epoch: 6| Step: 9
Training loss: 1.6420590627225808
Validation loss: 2.4603215512095398

Epoch: 6| Step: 10
Training loss: 2.031498937758164
Validation loss: 2.407364034310199

Epoch: 6| Step: 11
Training loss: 1.858511844608555
Validation loss: 2.395155066899901

Epoch: 6| Step: 12
Training loss: 1.9067616635890254
Validation loss: 2.4023187179321748

Epoch: 6| Step: 13
Training loss: 2.6686923161510565
Validation loss: 2.3987641038173138

Epoch: 246| Step: 0
Training loss: 2.2233595983887895
Validation loss: 2.377931890591723

Epoch: 6| Step: 1
Training loss: 1.3671486113330806
Validation loss: 2.3957823103669833

Epoch: 6| Step: 2
Training loss: 2.597638627759775
Validation loss: 2.38846052459947

Epoch: 6| Step: 3
Training loss: 1.7111837828191845
Validation loss: 2.3629580480217465

Epoch: 6| Step: 4
Training loss: 1.7620368890180755
Validation loss: 2.3877784059427705

Epoch: 6| Step: 5
Training loss: 1.5518765749176306
Validation loss: 2.3839402269476486

Epoch: 6| Step: 6
Training loss: 1.9941268158228098
Validation loss: 2.3745519844803824

Epoch: 6| Step: 7
Training loss: 1.8636084695111437
Validation loss: 2.414982531026689

Epoch: 6| Step: 8
Training loss: 2.3525603448990635
Validation loss: 2.3842205920280177

Epoch: 6| Step: 9
Training loss: 1.8625339632969957
Validation loss: 2.4189859243666607

Epoch: 6| Step: 10
Training loss: 1.9909950427420429
Validation loss: 2.356969072680299

Epoch: 6| Step: 11
Training loss: 2.5962111963963843
Validation loss: 2.4437953658055624

Epoch: 6| Step: 12
Training loss: 1.680098159624464
Validation loss: 2.3757647959838524

Epoch: 6| Step: 13
Training loss: 2.068924578996107
Validation loss: 2.38996411965392

Epoch: 247| Step: 0
Training loss: 1.9740436169830973
Validation loss: 2.3441374952691962

Epoch: 6| Step: 1
Training loss: 1.579894556196888
Validation loss: 2.3264846842847757

Epoch: 6| Step: 2
Training loss: 1.8973726025259672
Validation loss: 2.3460041273207852

Epoch: 6| Step: 3
Training loss: 2.2485645801718954
Validation loss: 2.326825911111771

Epoch: 6| Step: 4
Training loss: 1.7991630913311818
Validation loss: 2.3522799989667895

Epoch: 6| Step: 5
Training loss: 1.723319827616518
Validation loss: 2.3983849629291165

Epoch: 6| Step: 6
Training loss: 2.0555615324786927
Validation loss: 2.4083804727340725

Epoch: 6| Step: 7
Training loss: 2.3598081683734837
Validation loss: 2.357129909745464

Epoch: 6| Step: 8
Training loss: 1.9255356080658927
Validation loss: 2.353348018393646

Epoch: 6| Step: 9
Training loss: 1.1277539665441623
Validation loss: 2.3618605029080233

Epoch: 6| Step: 10
Training loss: 2.691995276675112
Validation loss: 2.3737817877188525

Epoch: 6| Step: 11
Training loss: 1.6250224478711686
Validation loss: 2.3473709847954534

Epoch: 6| Step: 12
Training loss: 2.096735178440115
Validation loss: 2.3560659718435226

Epoch: 6| Step: 13
Training loss: 1.9603353236879726
Validation loss: 2.3782368015441055

Epoch: 248| Step: 0
Training loss: 2.0621480930550136
Validation loss: 2.3705144956055357

Epoch: 6| Step: 1
Training loss: 2.314677476270254
Validation loss: 2.3628461990060283

Epoch: 6| Step: 2
Training loss: 1.6416554439309532
Validation loss: 2.388305712198407

Epoch: 6| Step: 3
Training loss: 1.4768441552271978
Validation loss: 2.396981417311096

Epoch: 6| Step: 4
Training loss: 1.8616914824787263
Validation loss: 2.34932379915758

Epoch: 6| Step: 5
Training loss: 2.23745366053839
Validation loss: 2.3835467453483234

Epoch: 6| Step: 6
Training loss: 1.571036252677373
Validation loss: 2.373026397520848

Epoch: 6| Step: 7
Training loss: 2.1400838571678564
Validation loss: 2.3368509479134887

Epoch: 6| Step: 8
Training loss: 1.361841485362587
Validation loss: 2.338256267836272

Epoch: 6| Step: 9
Training loss: 2.0144773069435233
Validation loss: 2.3895821025423345

Epoch: 6| Step: 10
Training loss: 2.0722322596129907
Validation loss: 2.334698364213736

Epoch: 6| Step: 11
Training loss: 2.659018117624157
Validation loss: 2.372513579174313

Epoch: 6| Step: 12
Training loss: 1.6971803562531624
Validation loss: 2.4111137642737206

Epoch: 6| Step: 13
Training loss: 1.965985976703726
Validation loss: 2.406515665335106

Epoch: 249| Step: 0
Training loss: 2.0193151952399733
Validation loss: 2.3704091602368433

Epoch: 6| Step: 1
Training loss: 2.702044144118059
Validation loss: 2.3866856462299495

Epoch: 6| Step: 2
Training loss: 1.6102305240149188
Validation loss: 2.412295798300432

Epoch: 6| Step: 3
Training loss: 2.4092246160813695
Validation loss: 2.3602772409445167

Epoch: 6| Step: 4
Training loss: 1.5612752310406892
Validation loss: 2.3842709359229337

Epoch: 6| Step: 5
Training loss: 2.0521275342902516
Validation loss: 2.3915026637623424

Epoch: 6| Step: 6
Training loss: 2.047390705400785
Validation loss: 2.3941391921007193

Epoch: 6| Step: 7
Training loss: 2.2471384289300946
Validation loss: 2.3518579289485197

Epoch: 6| Step: 8
Training loss: 2.283468448047566
Validation loss: 2.3708200106980053

Epoch: 6| Step: 9
Training loss: 1.9584422859022634
Validation loss: 2.3935833081936684

Epoch: 6| Step: 10
Training loss: 1.5108392409335216
Validation loss: 2.352554323078491

Epoch: 6| Step: 11
Training loss: 1.7635673077952385
Validation loss: 2.3835596304876057

Epoch: 6| Step: 12
Training loss: 1.0200048640079087
Validation loss: 2.3513636056769567

Epoch: 6| Step: 13
Training loss: 1.5809303503408314
Validation loss: 2.4144191280067155

Epoch: 250| Step: 0
Training loss: 1.6131891773911706
Validation loss: 2.3731578403100078

Epoch: 6| Step: 1
Training loss: 1.6992834320034707
Validation loss: 2.3230992697962383

Epoch: 6| Step: 2
Training loss: 2.309221159852885
Validation loss: 2.3864721787770273

Epoch: 6| Step: 3
Training loss: 1.961323977376552
Validation loss: 2.376798625497937

Epoch: 6| Step: 4
Training loss: 1.8726434521800779
Validation loss: 2.3236986040998917

Epoch: 6| Step: 5
Training loss: 1.7725240901068609
Validation loss: 2.3975112626722894

Epoch: 6| Step: 6
Training loss: 2.0565782557464907
Validation loss: 2.3827039102482144

Epoch: 6| Step: 7
Training loss: 2.2433953305085916
Validation loss: 2.3969103685301127

Epoch: 6| Step: 8
Training loss: 1.5972164080232953
Validation loss: 2.389398284623809

Epoch: 6| Step: 9
Training loss: 1.1733457872333082
Validation loss: 2.335989547326898

Epoch: 6| Step: 10
Training loss: 2.571164995641947
Validation loss: 2.3536534183226228

Epoch: 6| Step: 11
Training loss: 2.191569221950804
Validation loss: 2.372967435870296

Epoch: 6| Step: 12
Training loss: 2.246974712594538
Validation loss: 2.354222962271442

Epoch: 6| Step: 13
Training loss: 1.680804355934523
Validation loss: 2.35380799010178

Epoch: 251| Step: 0
Training loss: 2.0295460523223694
Validation loss: 2.400822238363929

Epoch: 6| Step: 1
Training loss: 1.5546250067184313
Validation loss: 2.3938623880739565

Epoch: 6| Step: 2
Training loss: 2.08778648009671
Validation loss: 2.3599350830925974

Epoch: 6| Step: 3
Training loss: 2.2455400132644874
Validation loss: 2.4102496543909293

Epoch: 6| Step: 4
Training loss: 2.6027903365740643
Validation loss: 2.4111665088318146

Epoch: 6| Step: 5
Training loss: 2.366994717745574
Validation loss: 2.4190236815570594

Epoch: 6| Step: 6
Training loss: 1.3953721532426113
Validation loss: 2.416162204459949

Epoch: 6| Step: 7
Training loss: 1.763241670001198
Validation loss: 2.4114246313340706

Epoch: 6| Step: 8
Training loss: 1.9470105707227436
Validation loss: 2.396601332794686

Epoch: 6| Step: 9
Training loss: 1.6488316503151352
Validation loss: 2.3877517298614066

Epoch: 6| Step: 10
Training loss: 1.8795527815007658
Validation loss: 2.3738289262873655

Epoch: 6| Step: 11
Training loss: 1.4779038568283378
Validation loss: 2.400374156232876

Epoch: 6| Step: 12
Training loss: 1.9951526789932386
Validation loss: 2.390661293101207

Epoch: 6| Step: 13
Training loss: 2.29715898276324
Validation loss: 2.4150861813115356

Epoch: 252| Step: 0
Training loss: 1.7929251339330017
Validation loss: 2.4120487413594405

Epoch: 6| Step: 1
Training loss: 1.9457117000468227
Validation loss: 2.3733619552676717

Epoch: 6| Step: 2
Training loss: 1.576319048319834
Validation loss: 2.3236144355230843

Epoch: 6| Step: 3
Training loss: 2.002075310676794
Validation loss: 2.417571360633721

Epoch: 6| Step: 4
Training loss: 1.5677547595816113
Validation loss: 2.3466179499027766

Epoch: 6| Step: 5
Training loss: 2.6645924329167356
Validation loss: 2.3275043381213414

Epoch: 6| Step: 6
Training loss: 1.8940268562813631
Validation loss: 2.3849470191457995

Epoch: 6| Step: 7
Training loss: 1.92907408566984
Validation loss: 2.3668175195015593

Epoch: 6| Step: 8
Training loss: 1.8773586061471659
Validation loss: 2.3660058339742167

Epoch: 6| Step: 9
Training loss: 1.937063044836125
Validation loss: 2.3589600891801177

Epoch: 6| Step: 10
Training loss: 2.046177286523463
Validation loss: 2.3593731213090656

Epoch: 6| Step: 11
Training loss: 2.115813988678182
Validation loss: 2.3744518487255957

Epoch: 6| Step: 12
Training loss: 1.711533673377828
Validation loss: 2.356773195258175

Epoch: 6| Step: 13
Training loss: 2.0443373229923294
Validation loss: 2.4336907307492286

Epoch: 253| Step: 0
Training loss: 1.4358687059529027
Validation loss: 2.2998894922398225

Epoch: 6| Step: 1
Training loss: 2.5224871189177955
Validation loss: 2.3411607557160616

Epoch: 6| Step: 2
Training loss: 1.363347617558743
Validation loss: 2.3743361758109804

Epoch: 6| Step: 3
Training loss: 1.9841152231382544
Validation loss: 2.3631708818883688

Epoch: 6| Step: 4
Training loss: 1.7305769014683374
Validation loss: 2.3749833303405166

Epoch: 6| Step: 5
Training loss: 1.5663497800470267
Validation loss: 2.3874826279132577

Epoch: 6| Step: 6
Training loss: 2.0234201791382813
Validation loss: 2.379518011143844

Epoch: 6| Step: 7
Training loss: 2.0936115276038256
Validation loss: 2.3966907488213054

Epoch: 6| Step: 8
Training loss: 1.7257580846679743
Validation loss: 2.3845790888748444

Epoch: 6| Step: 9
Training loss: 2.0459889831171783
Validation loss: 2.3897883579697607

Epoch: 6| Step: 10
Training loss: 2.0302123720674645
Validation loss: 2.339224340919069

Epoch: 6| Step: 11
Training loss: 2.3467959130342124
Validation loss: 2.3807519172770255

Epoch: 6| Step: 12
Training loss: 1.9614896566841256
Validation loss: 2.3877686045628197

Epoch: 6| Step: 13
Training loss: 2.1224404796436875
Validation loss: 2.3883813104720475

Epoch: 254| Step: 0
Training loss: 2.15811772932722
Validation loss: 2.4166027169541153

Epoch: 6| Step: 1
Training loss: 1.7207117156248382
Validation loss: 2.3956519302096666

Epoch: 6| Step: 2
Training loss: 1.797522983642836
Validation loss: 2.39050483763547

Epoch: 6| Step: 3
Training loss: 2.050735560316929
Validation loss: 2.378012247870238

Epoch: 6| Step: 4
Training loss: 2.1299526617673052
Validation loss: 2.392881982831709

Epoch: 6| Step: 5
Training loss: 2.0270970071277183
Validation loss: 2.3431357822435945

Epoch: 6| Step: 6
Training loss: 2.028667745280076
Validation loss: 2.3540972620383154

Epoch: 6| Step: 7
Training loss: 1.8473824102535878
Validation loss: 2.376246138906036

Epoch: 6| Step: 8
Training loss: 1.3675083328913735
Validation loss: 2.3688273133129076

Epoch: 6| Step: 9
Training loss: 1.6018820839203216
Validation loss: 2.332373602624436

Epoch: 6| Step: 10
Training loss: 2.7048713467335874
Validation loss: 2.4059907123343214

Epoch: 6| Step: 11
Training loss: 2.0852200420822182
Validation loss: 2.413357576636444

Epoch: 6| Step: 12
Training loss: 1.718925952574799
Validation loss: 2.3341707264802514

Epoch: 6| Step: 13
Training loss: 1.7904814045102089
Validation loss: 2.350743288533917

Epoch: 255| Step: 0
Training loss: 1.6362741089422415
Validation loss: 2.3803672074211795

Epoch: 6| Step: 1
Training loss: 2.116349283087483
Validation loss: 2.339003014900542

Epoch: 6| Step: 2
Training loss: 1.7496703382339565
Validation loss: 2.3608754561794334

Epoch: 6| Step: 3
Training loss: 1.4945300822594922
Validation loss: 2.34109316567271

Epoch: 6| Step: 4
Training loss: 1.9130544070828797
Validation loss: 2.3871636954487037

Epoch: 6| Step: 5
Training loss: 2.085451333757854
Validation loss: 2.379554518898675

Epoch: 6| Step: 6
Training loss: 2.1099807434649653
Validation loss: 2.3954773248268677

Epoch: 6| Step: 7
Training loss: 1.6751964767005472
Validation loss: 2.339638484850879

Epoch: 6| Step: 8
Training loss: 1.9600454786435009
Validation loss: 2.362182969464102

Epoch: 6| Step: 9
Training loss: 1.9115219382809014
Validation loss: 2.3757959013446657

Epoch: 6| Step: 10
Training loss: 1.6419476218657036
Validation loss: 2.3366104579498144

Epoch: 6| Step: 11
Training loss: 2.7195370291341927
Validation loss: 2.4200440852442133

Epoch: 6| Step: 12
Training loss: 1.6918046935699471
Validation loss: 2.3702963314104806

Epoch: 6| Step: 13
Training loss: 1.6286794381069674
Validation loss: 2.3688393283154343

Epoch: 256| Step: 0
Training loss: 2.6988173543803753
Validation loss: 2.375404799440357

Epoch: 6| Step: 1
Training loss: 1.510635342607931
Validation loss: 2.3727671206609156

Epoch: 6| Step: 2
Training loss: 2.2818803308320708
Validation loss: 2.3488607937291675

Epoch: 6| Step: 3
Training loss: 1.8482973305188681
Validation loss: 2.4265872941879496

Epoch: 6| Step: 4
Training loss: 2.1980486885905304
Validation loss: 2.399258442793264

Epoch: 6| Step: 5
Training loss: 1.831160804216729
Validation loss: 2.387252862517057

Epoch: 6| Step: 6
Training loss: 1.4941682301882073
Validation loss: 2.39404275832963

Epoch: 6| Step: 7
Training loss: 1.949396404357988
Validation loss: 2.374093019090721

Epoch: 6| Step: 8
Training loss: 2.0866359727123434
Validation loss: 2.419470035893636

Epoch: 6| Step: 9
Training loss: 1.7965323743485726
Validation loss: 2.4978381767141777

Epoch: 6| Step: 10
Training loss: 1.5711836794359075
Validation loss: 2.3775378178901168

Epoch: 6| Step: 11
Training loss: 1.7672315732011727
Validation loss: 2.400638981027615

Epoch: 6| Step: 12
Training loss: 1.5899188799527861
Validation loss: 2.398318682551326

Epoch: 6| Step: 13
Training loss: 1.886653733169833
Validation loss: 2.3863891784333777

Epoch: 257| Step: 0
Training loss: 1.6926082014153585
Validation loss: 2.403544303242825

Epoch: 6| Step: 1
Training loss: 1.5909571392680688
Validation loss: 2.4015791036178777

Epoch: 6| Step: 2
Training loss: 1.5690335811524811
Validation loss: 2.384905096678454

Epoch: 6| Step: 3
Training loss: 1.8091510219005889
Validation loss: 2.3897503373333793

Epoch: 6| Step: 4
Training loss: 2.085398515081787
Validation loss: 2.3825549301999454

Epoch: 6| Step: 5
Training loss: 2.555726846077545
Validation loss: 2.359574811265753

Epoch: 6| Step: 6
Training loss: 1.623146173444096
Validation loss: 2.343686979806999

Epoch: 6| Step: 7
Training loss: 1.4131078290001549
Validation loss: 2.389356935955275

Epoch: 6| Step: 8
Training loss: 1.3278346922490711
Validation loss: 2.3635251697594444

Epoch: 6| Step: 9
Training loss: 1.6806622183222741
Validation loss: 2.3746040890743076

Epoch: 6| Step: 10
Training loss: 2.3268444456624735
Validation loss: 2.365563338135215

Epoch: 6| Step: 11
Training loss: 2.245669754478427
Validation loss: 2.378019966230545

Epoch: 6| Step: 12
Training loss: 2.2028553033340064
Validation loss: 2.3882780823638656

Epoch: 6| Step: 13
Training loss: 2.6426883739358753
Validation loss: 2.371279940407413

Epoch: 258| Step: 0
Training loss: 1.7468555674555395
Validation loss: 2.420425382388406

Epoch: 6| Step: 1
Training loss: 1.5528593576861422
Validation loss: 2.38293549347825

Epoch: 6| Step: 2
Training loss: 1.648265377658582
Validation loss: 2.4228614864824056

Epoch: 6| Step: 3
Training loss: 1.5332039802694668
Validation loss: 2.363660356770715

Epoch: 6| Step: 4
Training loss: 1.6685979938211992
Validation loss: 2.361822611776484

Epoch: 6| Step: 5
Training loss: 2.524669618048637
Validation loss: 2.392898191130818

Epoch: 6| Step: 6
Training loss: 1.9590351254097287
Validation loss: 2.3639528038206414

Epoch: 6| Step: 7
Training loss: 1.7130417795158117
Validation loss: 2.3818631857055017

Epoch: 6| Step: 8
Training loss: 1.9361185255536566
Validation loss: 2.3979942780980745

Epoch: 6| Step: 9
Training loss: 1.8322311975485357
Validation loss: 2.38666131140614

Epoch: 6| Step: 10
Training loss: 1.5958054695319648
Validation loss: 2.3864556918425004

Epoch: 6| Step: 11
Training loss: 1.849914074526134
Validation loss: 2.416789397226842

Epoch: 6| Step: 12
Training loss: 2.264606220465437
Validation loss: 2.4067024633381306

Epoch: 6| Step: 13
Training loss: 3.1766666993831327
Validation loss: 2.4380917731344613

Epoch: 259| Step: 0
Training loss: 1.5728363707133353
Validation loss: 2.3682947208146694

Epoch: 6| Step: 1
Training loss: 2.1327685676493537
Validation loss: 2.371741340681558

Epoch: 6| Step: 2
Training loss: 2.034978525671725
Validation loss: 2.425436601407536

Epoch: 6| Step: 3
Training loss: 1.7495317513854485
Validation loss: 2.3904579099379113

Epoch: 6| Step: 4
Training loss: 2.0737353550058693
Validation loss: 2.4557473430344303

Epoch: 6| Step: 5
Training loss: 1.8146304402184101
Validation loss: 2.3741800482812194

Epoch: 6| Step: 6
Training loss: 2.726784246221078
Validation loss: 2.3680611937338716

Epoch: 6| Step: 7
Training loss: 1.7490299806200893
Validation loss: 2.3704460581059124

Epoch: 6| Step: 8
Training loss: 1.927110379690817
Validation loss: 2.373774333674197

Epoch: 6| Step: 9
Training loss: 1.6679114302852305
Validation loss: 2.3885273232516884

Epoch: 6| Step: 10
Training loss: 1.5956565822130981
Validation loss: 2.388129736675053

Epoch: 6| Step: 11
Training loss: 1.916938334022911
Validation loss: 2.385876613698875

Epoch: 6| Step: 12
Training loss: 1.6595095104003632
Validation loss: 2.3911501753778657

Epoch: 6| Step: 13
Training loss: 1.5489215606175946
Validation loss: 2.393961206996753

Epoch: 260| Step: 0
Training loss: 2.0634765625
Validation loss: 2.387960493427813

Epoch: 6| Step: 1
Training loss: 1.47284258162003
Validation loss: 2.387708289062111

Epoch: 6| Step: 2
Training loss: 1.2452766824929684
Validation loss: 2.407982138735272

Epoch: 6| Step: 3
Training loss: 2.2132738258029936
Validation loss: 2.387581581500495

Epoch: 6| Step: 4
Training loss: 2.545263517785434
Validation loss: 2.373046657856463

Epoch: 6| Step: 5
Training loss: 2.3187246316103014
Validation loss: 2.4230588540822073

Epoch: 6| Step: 6
Training loss: 1.7215929967007482
Validation loss: 2.406552306821912

Epoch: 6| Step: 7
Training loss: 1.3533277064630826
Validation loss: 2.4129561395833146

Epoch: 6| Step: 8
Training loss: 1.5647447864246318
Validation loss: 2.4169309773529837

Epoch: 6| Step: 9
Training loss: 2.4538561466400837
Validation loss: 2.38972035497135

Epoch: 6| Step: 10
Training loss: 2.1503487148930263
Validation loss: 2.4135082519384468

Epoch: 6| Step: 11
Training loss: 1.8071326663151575
Validation loss: 2.3799642419442586

Epoch: 6| Step: 12
Training loss: 1.764194009911652
Validation loss: 2.4027158323480493

Epoch: 6| Step: 13
Training loss: 1.6611718515768292
Validation loss: 2.415821135090706

Epoch: 261| Step: 0
Training loss: 1.884457324809214
Validation loss: 2.398956469283789

Epoch: 6| Step: 1
Training loss: 1.5358148380324306
Validation loss: 2.3774160138546656

Epoch: 6| Step: 2
Training loss: 2.1216013039436765
Validation loss: 2.396682144472872

Epoch: 6| Step: 3
Training loss: 1.8146875269071807
Validation loss: 2.360365084737532

Epoch: 6| Step: 4
Training loss: 2.423592924130567
Validation loss: 2.397301034306723

Epoch: 6| Step: 5
Training loss: 2.254257730088947
Validation loss: 2.371450538414199

Epoch: 6| Step: 6
Training loss: 1.2628449884552886
Validation loss: 2.392836791055232

Epoch: 6| Step: 7
Training loss: 2.2161998869194397
Validation loss: 2.344634801187528

Epoch: 6| Step: 8
Training loss: 2.1157123451853233
Validation loss: 2.3125556023411478

Epoch: 6| Step: 9
Training loss: 2.0510135192127947
Validation loss: 2.3936732616133587

Epoch: 6| Step: 10
Training loss: 1.349728657686043
Validation loss: 2.346238875691316

Epoch: 6| Step: 11
Training loss: 1.944033405213171
Validation loss: 2.4376762522039472

Epoch: 6| Step: 12
Training loss: 1.3729651306042123
Validation loss: 2.360813499078284

Epoch: 6| Step: 13
Training loss: 1.8010993064304215
Validation loss: 2.359578157091324

Epoch: 262| Step: 0
Training loss: 1.6346296210553681
Validation loss: 2.3919916977486744

Epoch: 6| Step: 1
Training loss: 1.3840964870280692
Validation loss: 2.4049441125152113

Epoch: 6| Step: 2
Training loss: 1.6693094837239024
Validation loss: 2.373653055822315

Epoch: 6| Step: 3
Training loss: 1.4531863620066656
Validation loss: 2.360374811468602

Epoch: 6| Step: 4
Training loss: 1.4157106689400327
Validation loss: 2.39657126605802

Epoch: 6| Step: 5
Training loss: 2.3927827957738796
Validation loss: 2.3885049949890402

Epoch: 6| Step: 6
Training loss: 1.7662321414031168
Validation loss: 2.398527448797351

Epoch: 6| Step: 7
Training loss: 1.8502254889938903
Validation loss: 2.3647285663656907

Epoch: 6| Step: 8
Training loss: 2.2060209679527896
Validation loss: 2.4123847319677436

Epoch: 6| Step: 9
Training loss: 1.8332208541120112
Validation loss: 2.3690589696138766

Epoch: 6| Step: 10
Training loss: 2.241713417255868
Validation loss: 2.398281760271788

Epoch: 6| Step: 11
Training loss: 1.8622653839012593
Validation loss: 2.376505172396304

Epoch: 6| Step: 12
Training loss: 2.4139783529782246
Validation loss: 2.3700531809942538

Epoch: 6| Step: 13
Training loss: 1.985442707842326
Validation loss: 2.421031242578927

Epoch: 263| Step: 0
Training loss: 1.8076291900516561
Validation loss: 2.3882089569999723

Epoch: 6| Step: 1
Training loss: 2.4189352590500612
Validation loss: 2.3870633718702856

Epoch: 6| Step: 2
Training loss: 1.6927002500683401
Validation loss: 2.4212937926894162

Epoch: 6| Step: 3
Training loss: 2.0708471219725
Validation loss: 2.3844907071925734

Epoch: 6| Step: 4
Training loss: 1.7212067818462176
Validation loss: 2.397061979282916

Epoch: 6| Step: 5
Training loss: 1.5082422148157257
Validation loss: 2.37759562622933

Epoch: 6| Step: 6
Training loss: 1.6959742647638651
Validation loss: 2.3828676268146527

Epoch: 6| Step: 7
Training loss: 2.4862788361056167
Validation loss: 2.410373054342629

Epoch: 6| Step: 8
Training loss: 1.494651477721799
Validation loss: 2.393841129636275

Epoch: 6| Step: 9
Training loss: 1.890289844409337
Validation loss: 2.351437741249809

Epoch: 6| Step: 10
Training loss: 2.100011089840626
Validation loss: 2.421581190946246

Epoch: 6| Step: 11
Training loss: 1.5549218849358843
Validation loss: 2.3497513458196884

Epoch: 6| Step: 12
Training loss: 1.7920172666203182
Validation loss: 2.411565552124126

Epoch: 6| Step: 13
Training loss: 1.8559087934199268
Validation loss: 2.374908087117128

Epoch: 264| Step: 0
Training loss: 1.5988969159419997
Validation loss: 2.3993123679391855

Epoch: 6| Step: 1
Training loss: 2.0254900916164886
Validation loss: 2.378452078443528

Epoch: 6| Step: 2
Training loss: 1.1428701174374194
Validation loss: 2.4065463268918075

Epoch: 6| Step: 3
Training loss: 2.085192829610181
Validation loss: 2.401835173377756

Epoch: 6| Step: 4
Training loss: 1.0695838397007154
Validation loss: 2.385005699688011

Epoch: 6| Step: 5
Training loss: 2.033391322679597
Validation loss: 2.3681527239121363

Epoch: 6| Step: 6
Training loss: 1.6425374827760306
Validation loss: 2.400694652641224

Epoch: 6| Step: 7
Training loss: 2.456988165982555
Validation loss: 2.445229789034605

Epoch: 6| Step: 8
Training loss: 1.4691940610296665
Validation loss: 2.366710256128614

Epoch: 6| Step: 9
Training loss: 2.219900128635458
Validation loss: 2.364706751678144

Epoch: 6| Step: 10
Training loss: 1.9517307034918103
Validation loss: 2.412256241770706

Epoch: 6| Step: 11
Training loss: 1.8494622918271086
Validation loss: 2.368135643397265

Epoch: 6| Step: 12
Training loss: 1.915509669455486
Validation loss: 2.3655632991208027

Epoch: 6| Step: 13
Training loss: 1.9662441473289927
Validation loss: 2.350964768777182

Epoch: 265| Step: 0
Training loss: 1.9812961031486562
Validation loss: 2.420304542965405

Epoch: 6| Step: 1
Training loss: 2.3891162973537923
Validation loss: 2.39825770345627

Epoch: 6| Step: 2
Training loss: 1.8549514209936109
Validation loss: 2.4039413079801264

Epoch: 6| Step: 3
Training loss: 1.3313436663275502
Validation loss: 2.349379318933406

Epoch: 6| Step: 4
Training loss: 1.743621099486416
Validation loss: 2.3661629548361582

Epoch: 6| Step: 5
Training loss: 2.629305895601587
Validation loss: 2.350215383332343

Epoch: 6| Step: 6
Training loss: 2.0786427017936417
Validation loss: 2.3704302032429525

Epoch: 6| Step: 7
Training loss: 1.3215487859974608
Validation loss: 2.4319699526929197

Epoch: 6| Step: 8
Training loss: 1.598646980646975
Validation loss: 2.4002638830707808

Epoch: 6| Step: 9
Training loss: 1.6803760625371487
Validation loss: 2.328061955472335

Epoch: 6| Step: 10
Training loss: 1.8246927891135385
Validation loss: 2.355384992373084

Epoch: 6| Step: 11
Training loss: 1.3962755593988811
Validation loss: 2.426634719105999

Epoch: 6| Step: 12
Training loss: 1.747209094587348
Validation loss: 2.3313578334520355

Epoch: 6| Step: 13
Training loss: 2.23576685096305
Validation loss: 2.3379167734571045

Epoch: 266| Step: 0
Training loss: 1.9137857042366897
Validation loss: 2.3927846578759056

Epoch: 6| Step: 1
Training loss: 2.4363216584159413
Validation loss: 2.3781667536895865

Epoch: 6| Step: 2
Training loss: 1.651991209112982
Validation loss: 2.342543472876163

Epoch: 6| Step: 3
Training loss: 1.5818695362468456
Validation loss: 2.3621162555392723

Epoch: 6| Step: 4
Training loss: 2.470859929714116
Validation loss: 2.3418976801577656

Epoch: 6| Step: 5
Training loss: 1.418914311510753
Validation loss: 2.365024831353974

Epoch: 6| Step: 6
Training loss: 1.460194934477443
Validation loss: 2.3891390340966647

Epoch: 6| Step: 7
Training loss: 1.9285345919184214
Validation loss: 2.394309410885806

Epoch: 6| Step: 8
Training loss: 1.86885181774779
Validation loss: 2.3818399166873836

Epoch: 6| Step: 9
Training loss: 1.9856103971362806
Validation loss: 2.3960685830274913

Epoch: 6| Step: 10
Training loss: 1.7496690437173323
Validation loss: 2.406255889574271

Epoch: 6| Step: 11
Training loss: 1.6682142304859338
Validation loss: 2.3718979378566227

Epoch: 6| Step: 12
Training loss: 1.5921554068044061
Validation loss: 2.341155986856721

Epoch: 6| Step: 13
Training loss: 1.7486243290494607
Validation loss: 2.3552138946540544

Epoch: 267| Step: 0
Training loss: 1.5690724805109162
Validation loss: 2.4113207646521615

Epoch: 6| Step: 1
Training loss: 1.3131838787955414
Validation loss: 2.40341590895596

Epoch: 6| Step: 2
Training loss: 2.4424871630609504
Validation loss: 2.414717525421307

Epoch: 6| Step: 3
Training loss: 1.6288411884441778
Validation loss: 2.409516119672991

Epoch: 6| Step: 4
Training loss: 1.9435243776135596
Validation loss: 2.386957239539397

Epoch: 6| Step: 5
Training loss: 2.63067585532312
Validation loss: 2.383105192560321

Epoch: 6| Step: 6
Training loss: 2.088823814708661
Validation loss: 2.431356087055712

Epoch: 6| Step: 7
Training loss: 1.3783806509654704
Validation loss: 2.4445477929071364

Epoch: 6| Step: 8
Training loss: 1.8739757283286755
Validation loss: 2.458316036084952

Epoch: 6| Step: 9
Training loss: 1.4673841090801456
Validation loss: 2.3999610517231558

Epoch: 6| Step: 10
Training loss: 1.7718388414141528
Validation loss: 2.4273401443413105

Epoch: 6| Step: 11
Training loss: 1.3285060560313096
Validation loss: 2.4264003587212706

Epoch: 6| Step: 12
Training loss: 2.320299039345689
Validation loss: 2.4199902046796584

Epoch: 6| Step: 13
Training loss: 1.7061067430211256
Validation loss: 2.3733644321022296

Epoch: 268| Step: 0
Training loss: 2.2967885319010577
Validation loss: 2.3359547544895625

Epoch: 6| Step: 1
Training loss: 1.7334188626657536
Validation loss: 2.401209312456777

Epoch: 6| Step: 2
Training loss: 1.334818454999751
Validation loss: 2.383334664016629

Epoch: 6| Step: 3
Training loss: 2.106438747744175
Validation loss: 2.3720523318142335

Epoch: 6| Step: 4
Training loss: 1.1365159630550157
Validation loss: 2.4093158135663812

Epoch: 6| Step: 5
Training loss: 2.2642662446335486
Validation loss: 2.3655420806037863

Epoch: 6| Step: 6
Training loss: 1.4737756658621262
Validation loss: 2.3956949080773424

Epoch: 6| Step: 7
Training loss: 2.3270119688269686
Validation loss: 2.3664820174279155

Epoch: 6| Step: 8
Training loss: 1.9745459239813226
Validation loss: 2.3955438603980657

Epoch: 6| Step: 9
Training loss: 2.1098253687688087
Validation loss: 2.361141445158887

Epoch: 6| Step: 10
Training loss: 1.9020063347776157
Validation loss: 2.387983206821575

Epoch: 6| Step: 11
Training loss: 1.3697979664627467
Validation loss: 2.4098939146394254

Epoch: 6| Step: 12
Training loss: 1.729786482186833
Validation loss: 2.356725136837318

Epoch: 6| Step: 13
Training loss: 2.371427258033192
Validation loss: 2.381831873275783

Epoch: 269| Step: 0
Training loss: 1.830352013610671
Validation loss: 2.370700567135955

Epoch: 6| Step: 1
Training loss: 2.1696603584817122
Validation loss: 2.4049914013928038

Epoch: 6| Step: 2
Training loss: 1.8489829334897014
Validation loss: 2.3940411349331776

Epoch: 6| Step: 3
Training loss: 2.326381978140162
Validation loss: 2.3873082878841774

Epoch: 6| Step: 4
Training loss: 1.4211615145204306
Validation loss: 2.355768833735717

Epoch: 6| Step: 5
Training loss: 1.728349684169214
Validation loss: 2.3480971385464935

Epoch: 6| Step: 6
Training loss: 1.9060257951806217
Validation loss: 2.3575938754100103

Epoch: 6| Step: 7
Training loss: 2.270311861504126
Validation loss: 2.3915338913787285

Epoch: 6| Step: 8
Training loss: 2.0784243031129983
Validation loss: 2.4008200888458067

Epoch: 6| Step: 9
Training loss: 2.10646862853635
Validation loss: 2.3407774217682085

Epoch: 6| Step: 10
Training loss: 1.306820160031235
Validation loss: 2.387242879639436

Epoch: 6| Step: 11
Training loss: 1.7682638113441669
Validation loss: 2.4017384156386847

Epoch: 6| Step: 12
Training loss: 1.5306913952895682
Validation loss: 2.3794846380452435

Epoch: 6| Step: 13
Training loss: 0.9435678887396248
Validation loss: 2.3925253789000167

Epoch: 270| Step: 0
Training loss: 1.5603176898743925
Validation loss: 2.3285179514059062

Epoch: 6| Step: 1
Training loss: 1.750275726395188
Validation loss: 2.4072150884117423

Epoch: 6| Step: 2
Training loss: 1.6686029948087315
Validation loss: 2.4490721318621738

Epoch: 6| Step: 3
Training loss: 0.9186994525732152
Validation loss: 2.393802478323958

Epoch: 6| Step: 4
Training loss: 1.9168331101613132
Validation loss: 2.4165878173417497

Epoch: 6| Step: 5
Training loss: 1.632097735769523
Validation loss: 2.4583933763660797

Epoch: 6| Step: 6
Training loss: 2.2326563914713633
Validation loss: 2.4431365644605987

Epoch: 6| Step: 7
Training loss: 1.6505360917308658
Validation loss: 2.4488987391169865

Epoch: 6| Step: 8
Training loss: 2.076733115874621
Validation loss: 2.427985552358518

Epoch: 6| Step: 9
Training loss: 1.8508084206219104
Validation loss: 2.4059550894751887

Epoch: 6| Step: 10
Training loss: 1.3748283712604525
Validation loss: 2.3765510342144944

Epoch: 6| Step: 11
Training loss: 1.5487586218691687
Validation loss: 2.4274870665082666

Epoch: 6| Step: 12
Training loss: 2.9024492247195637
Validation loss: 2.4178997598973244

Epoch: 6| Step: 13
Training loss: 2.0319132968997877
Validation loss: 2.3937209311213508

Epoch: 271| Step: 0
Training loss: 2.25093610152085
Validation loss: 2.347093346057188

Epoch: 6| Step: 1
Training loss: 2.269303486043147
Validation loss: 2.3913385209926443

Epoch: 6| Step: 2
Training loss: 1.8266351611954366
Validation loss: 2.4235612739340513

Epoch: 6| Step: 3
Training loss: 1.9190422829546252
Validation loss: 2.385752805276256

Epoch: 6| Step: 4
Training loss: 1.9057052959717051
Validation loss: 2.384747957188338

Epoch: 6| Step: 5
Training loss: 1.4773824524311039
Validation loss: 2.3654570431488207

Epoch: 6| Step: 6
Training loss: 1.6106509733640797
Validation loss: 2.3823447169249223

Epoch: 6| Step: 7
Training loss: 1.4778485223062654
Validation loss: 2.3863664154905213

Epoch: 6| Step: 8
Training loss: 1.6274989793484207
Validation loss: 2.379622664275439

Epoch: 6| Step: 9
Training loss: 2.24660076223921
Validation loss: 2.374654303252349

Epoch: 6| Step: 10
Training loss: 2.0766727277607075
Validation loss: 2.3372522941575298

Epoch: 6| Step: 11
Training loss: 1.578203482612013
Validation loss: 2.358341035301647

Epoch: 6| Step: 12
Training loss: 1.3791470411965325
Validation loss: 2.3418731256935708

Epoch: 6| Step: 13
Training loss: 1.4283969244642645
Validation loss: 2.37390708009671

Epoch: 272| Step: 0
Training loss: 1.7530244849454086
Validation loss: 2.317518927833626

Epoch: 6| Step: 1
Training loss: 1.5371186039222229
Validation loss: 2.3544641314621946

Epoch: 6| Step: 2
Training loss: 1.4528469516987756
Validation loss: 2.3513078318307707

Epoch: 6| Step: 3
Training loss: 2.5953628856675865
Validation loss: 2.403603939780584

Epoch: 6| Step: 4
Training loss: 1.5101226345056675
Validation loss: 2.3400357146579367

Epoch: 6| Step: 5
Training loss: 1.907384066077124
Validation loss: 2.3960329351612892

Epoch: 6| Step: 6
Training loss: 1.3757849533490447
Validation loss: 2.33749317049524

Epoch: 6| Step: 7
Training loss: 1.8100680116131103
Validation loss: 2.357313061775865

Epoch: 6| Step: 8
Training loss: 2.1685089812898664
Validation loss: 2.362256610298061

Epoch: 6| Step: 9
Training loss: 1.3905079395872706
Validation loss: 2.3429945736677986

Epoch: 6| Step: 10
Training loss: 2.0465639766234034
Validation loss: 2.3327678143067674

Epoch: 6| Step: 11
Training loss: 2.0446898466292365
Validation loss: 2.392405711682316

Epoch: 6| Step: 12
Training loss: 1.9309290548258131
Validation loss: 2.397450335219601

Epoch: 6| Step: 13
Training loss: 1.4226536557521137
Validation loss: 2.3709017124807947

Epoch: 273| Step: 0
Training loss: 1.6977683706602702
Validation loss: 2.356654600790854

Epoch: 6| Step: 1
Training loss: 1.5478557213567945
Validation loss: 2.3936376685756464

Epoch: 6| Step: 2
Training loss: 2.2714778673729867
Validation loss: 2.4281134984342962

Epoch: 6| Step: 3
Training loss: 1.7646746483076938
Validation loss: 2.3503499451893175

Epoch: 6| Step: 4
Training loss: 1.6796414391168173
Validation loss: 2.4191770622949584

Epoch: 6| Step: 5
Training loss: 1.8397023010954472
Validation loss: 2.4048245345138106

Epoch: 6| Step: 6
Training loss: 2.271281370241295
Validation loss: 2.442450457136071

Epoch: 6| Step: 7
Training loss: 1.623960896364171
Validation loss: 2.3946267310883917

Epoch: 6| Step: 8
Training loss: 2.046837260356998
Validation loss: 2.4248245405822004

Epoch: 6| Step: 9
Training loss: 1.2758208829910547
Validation loss: 2.3996310163635677

Epoch: 6| Step: 10
Training loss: 1.7537043737782976
Validation loss: 2.3981002298451397

Epoch: 6| Step: 11
Training loss: 2.0443208789571505
Validation loss: 2.403832852568952

Epoch: 6| Step: 12
Training loss: 1.441488124103828
Validation loss: 2.3926232238898817

Epoch: 6| Step: 13
Training loss: 1.3464383579200596
Validation loss: 2.403559738083976

Epoch: 274| Step: 0
Training loss: 2.4320918020815827
Validation loss: 2.3757454121182477

Epoch: 6| Step: 1
Training loss: 2.037225473081914
Validation loss: 2.382388114557841

Epoch: 6| Step: 2
Training loss: 1.7801058256644673
Validation loss: 2.3647407181933713

Epoch: 6| Step: 3
Training loss: 1.8536242502457836
Validation loss: 2.3733837951776793

Epoch: 6| Step: 4
Training loss: 1.8738530147602035
Validation loss: 2.3844284100448587

Epoch: 6| Step: 5
Training loss: 1.5566962219035603
Validation loss: 2.389690256371611

Epoch: 6| Step: 6
Training loss: 1.5636282852581136
Validation loss: 2.3964072741584928

Epoch: 6| Step: 7
Training loss: 1.6179411233249936
Validation loss: 2.349145381475894

Epoch: 6| Step: 8
Training loss: 1.4334320891905863
Validation loss: 2.389994700717667

Epoch: 6| Step: 9
Training loss: 1.4628812537510671
Validation loss: 2.405814588637199

Epoch: 6| Step: 10
Training loss: 2.2826574503981436
Validation loss: 2.3883321132049535

Epoch: 6| Step: 11
Training loss: 1.9516766480414043
Validation loss: 2.37626843131805

Epoch: 6| Step: 12
Training loss: 1.4206532689582658
Validation loss: 2.355322534922803

Epoch: 6| Step: 13
Training loss: 1.8556992558300978
Validation loss: 2.342681503384834

Epoch: 275| Step: 0
Training loss: 2.000217902710901
Validation loss: 2.3796709411306547

Epoch: 6| Step: 1
Training loss: 1.762969661929804
Validation loss: 2.3837986877381243

Epoch: 6| Step: 2
Training loss: 1.444444963055705
Validation loss: 2.333402177422053

Epoch: 6| Step: 3
Training loss: 1.4229412063709204
Validation loss: 2.3801227474400273

Epoch: 6| Step: 4
Training loss: 1.5970727279288401
Validation loss: 2.3387513133307785

Epoch: 6| Step: 5
Training loss: 2.0699436075020317
Validation loss: 2.36886894132439

Epoch: 6| Step: 6
Training loss: 1.8209312598856553
Validation loss: 2.381211050473648

Epoch: 6| Step: 7
Training loss: 1.6563973271324186
Validation loss: 2.442140862050928

Epoch: 6| Step: 8
Training loss: 1.6673375527838075
Validation loss: 2.3646930385255933

Epoch: 6| Step: 9
Training loss: 1.9416334913418436
Validation loss: 2.4045865227710412

Epoch: 6| Step: 10
Training loss: 2.435889274310649
Validation loss: 2.397540089018872

Epoch: 6| Step: 11
Training loss: 1.8038312854282335
Validation loss: 2.38739946028356

Epoch: 6| Step: 12
Training loss: 2.0951223857520347
Validation loss: 2.35052048516262

Epoch: 6| Step: 13
Training loss: 1.6376522925225072
Validation loss: 2.3895687284743077

Epoch: 276| Step: 0
Training loss: 1.529784766622397
Validation loss: 2.4548728938604465

Epoch: 6| Step: 1
Training loss: 1.5181849774777885
Validation loss: 2.390809113915794

Epoch: 6| Step: 2
Training loss: 1.9491948984403056
Validation loss: 2.3417130137214857

Epoch: 6| Step: 3
Training loss: 1.8935667748776144
Validation loss: 2.443087865920469

Epoch: 6| Step: 4
Training loss: 1.8599847386872328
Validation loss: 2.3874045109971815

Epoch: 6| Step: 5
Training loss: 1.7972991442772612
Validation loss: 2.4156199710830055

Epoch: 6| Step: 6
Training loss: 1.5490510065830931
Validation loss: 2.405627435021133

Epoch: 6| Step: 7
Training loss: 1.871539737692297
Validation loss: 2.4250769961225216

Epoch: 6| Step: 8
Training loss: 2.3309121058326476
Validation loss: 2.4160331999796347

Epoch: 6| Step: 9
Training loss: 1.931546879143433
Validation loss: 2.403365566087635

Epoch: 6| Step: 10
Training loss: 1.7562218823337195
Validation loss: 2.308390487640648

Epoch: 6| Step: 11
Training loss: 1.7188095082471673
Validation loss: 2.3874940593903067

Epoch: 6| Step: 12
Training loss: 1.774592221122794
Validation loss: 2.394011008200359

Epoch: 6| Step: 13
Training loss: 1.498784287850309
Validation loss: 2.386360707800832

Epoch: 277| Step: 0
Training loss: 1.4412932726409327
Validation loss: 2.4233886413394576

Epoch: 6| Step: 1
Training loss: 1.428304034139941
Validation loss: 2.372854816202179

Epoch: 6| Step: 2
Training loss: 2.0807320439999533
Validation loss: 2.3593311714567866

Epoch: 6| Step: 3
Training loss: 1.6966543205176765
Validation loss: 2.4236536243719913

Epoch: 6| Step: 4
Training loss: 1.8427769307647732
Validation loss: 2.4137851582190852

Epoch: 6| Step: 5
Training loss: 1.3052582548823342
Validation loss: 2.3865873698294195

Epoch: 6| Step: 6
Training loss: 1.963328571713194
Validation loss: 2.404988801498731

Epoch: 6| Step: 7
Training loss: 1.9396783212033106
Validation loss: 2.4341494184063657

Epoch: 6| Step: 8
Training loss: 1.7318126549128543
Validation loss: 2.333844162651924

Epoch: 6| Step: 9
Training loss: 1.2520248701989185
Validation loss: 2.360745253278111

Epoch: 6| Step: 10
Training loss: 1.6165112541979814
Validation loss: 2.3661113491194876

Epoch: 6| Step: 11
Training loss: 1.6233526830022627
Validation loss: 2.3645947772167406

Epoch: 6| Step: 12
Training loss: 2.7326733335085
Validation loss: 2.401122099171811

Epoch: 6| Step: 13
Training loss: 2.0355699817881074
Validation loss: 2.380936681604852

Epoch: 278| Step: 0
Training loss: 1.5173710469440242
Validation loss: 2.375153029843533

Epoch: 6| Step: 1
Training loss: 1.5228862058391162
Validation loss: 2.392485150993325

Epoch: 6| Step: 2
Training loss: 2.236026393741429
Validation loss: 2.359227337284654

Epoch: 6| Step: 3
Training loss: 1.9985210195451948
Validation loss: 2.3791932219635004

Epoch: 6| Step: 4
Training loss: 1.7890705624860974
Validation loss: 2.3535943057432793

Epoch: 6| Step: 5
Training loss: 2.0214689244956046
Validation loss: 2.3590082919785647

Epoch: 6| Step: 6
Training loss: 1.5037433486499645
Validation loss: 2.431207954601405

Epoch: 6| Step: 7
Training loss: 2.0146411002502114
Validation loss: 2.3674908380055775

Epoch: 6| Step: 8
Training loss: 2.0295621461753734
Validation loss: 2.379381069751167

Epoch: 6| Step: 9
Training loss: 1.207207527991877
Validation loss: 2.4170329191575783

Epoch: 6| Step: 10
Training loss: 1.8504835759742808
Validation loss: 2.402333329340966

Epoch: 6| Step: 11
Training loss: 1.5389497202491957
Validation loss: 2.409821913578916

Epoch: 6| Step: 12
Training loss: 1.474501852195407
Validation loss: 2.4036745869991583

Epoch: 6| Step: 13
Training loss: 2.254201463112294
Validation loss: 2.4362354064011673

Epoch: 279| Step: 0
Training loss: 1.6127748595193188
Validation loss: 2.384361487958758

Epoch: 6| Step: 1
Training loss: 1.3639874309844446
Validation loss: 2.3644264353087543

Epoch: 6| Step: 2
Training loss: 1.9469498327578023
Validation loss: 2.3773510645712417

Epoch: 6| Step: 3
Training loss: 1.8258532241000154
Validation loss: 2.3623458585442845

Epoch: 6| Step: 4
Training loss: 1.7213372611073172
Validation loss: 2.3962592001023966

Epoch: 6| Step: 5
Training loss: 2.040319764002663
Validation loss: 2.3798407749697437

Epoch: 6| Step: 6
Training loss: 1.9945944214621503
Validation loss: 2.3752679430813686

Epoch: 6| Step: 7
Training loss: 2.491454491996042
Validation loss: 2.3879866336191395

Epoch: 6| Step: 8
Training loss: 1.2938621177559044
Validation loss: 2.3940694392708606

Epoch: 6| Step: 9
Training loss: 1.7454033837352172
Validation loss: 2.4060629990543974

Epoch: 6| Step: 10
Training loss: 1.4350890798533231
Validation loss: 2.4251077892948953

Epoch: 6| Step: 11
Training loss: 1.52693252686206
Validation loss: 2.4173141606774076

Epoch: 6| Step: 12
Training loss: 1.97408395600657
Validation loss: 2.383155123270023

Epoch: 6| Step: 13
Training loss: 1.848528021226787
Validation loss: 2.4140856644478492

Epoch: 280| Step: 0
Training loss: 1.892624357463883
Validation loss: 2.3767172547859117

Epoch: 6| Step: 1
Training loss: 2.3600260865660916
Validation loss: 2.4173117972792024

Epoch: 6| Step: 2
Training loss: 1.611762045030539
Validation loss: 2.366244749704091

Epoch: 6| Step: 3
Training loss: 1.571663801744155
Validation loss: 2.3755881024478556

Epoch: 6| Step: 4
Training loss: 1.588098491280822
Validation loss: 2.44791557051914

Epoch: 6| Step: 5
Training loss: 1.690280107726253
Validation loss: 2.325445642587692

Epoch: 6| Step: 6
Training loss: 1.7678266993291747
Validation loss: 2.36791741268509

Epoch: 6| Step: 7
Training loss: 1.5250482113831179
Validation loss: 2.384943899709632

Epoch: 6| Step: 8
Training loss: 2.7314742914980448
Validation loss: 2.3991682307554365

Epoch: 6| Step: 9
Training loss: 1.2387254562025098
Validation loss: 2.3879006744810103

Epoch: 6| Step: 10
Training loss: 1.622394820978901
Validation loss: 2.324020634576045

Epoch: 6| Step: 11
Training loss: 1.509897085686917
Validation loss: 2.3602732558171473

Epoch: 6| Step: 12
Training loss: 1.2774492972627236
Validation loss: 2.3777939101497294

Epoch: 6| Step: 13
Training loss: 1.971449923152884
Validation loss: 2.398161435296882

Epoch: 281| Step: 0
Training loss: 1.612097354268244
Validation loss: 2.445138637245037

Epoch: 6| Step: 1
Training loss: 2.049587170971543
Validation loss: 2.3375142959570816

Epoch: 6| Step: 2
Training loss: 2.0252404152653143
Validation loss: 2.3573620869647494

Epoch: 6| Step: 3
Training loss: 1.5842844799901303
Validation loss: 2.4354218268483008

Epoch: 6| Step: 4
Training loss: 2.1825994913292686
Validation loss: 2.394692265775726

Epoch: 6| Step: 5
Training loss: 1.3449764864401323
Validation loss: 2.4491614959656296

Epoch: 6| Step: 6
Training loss: 2.198176785906536
Validation loss: 2.3861569065085764

Epoch: 6| Step: 7
Training loss: 2.0116715805301317
Validation loss: 2.4251511341796266

Epoch: 6| Step: 8
Training loss: 1.3650234425107215
Validation loss: 2.4282608457304544

Epoch: 6| Step: 9
Training loss: 1.6849245268448465
Validation loss: 2.4242204765359228

Epoch: 6| Step: 10
Training loss: 1.511866047309524
Validation loss: 2.4184160771162393

Epoch: 6| Step: 11
Training loss: 1.9542044746412506
Validation loss: 2.441280034959934

Epoch: 6| Step: 12
Training loss: 1.6506653686810033
Validation loss: 2.4018083908448866

Epoch: 6| Step: 13
Training loss: 1.4713455965135733
Validation loss: 2.389984797942832

Epoch: 282| Step: 0
Training loss: 1.644451148467675
Validation loss: 2.349716538548224

Epoch: 6| Step: 1
Training loss: 1.4982422225090841
Validation loss: 2.3865483142263964

Epoch: 6| Step: 2
Training loss: 1.8145118597110306
Validation loss: 2.3417398398483185

Epoch: 6| Step: 3
Training loss: 1.9679288816937823
Validation loss: 2.349575482156249

Epoch: 6| Step: 4
Training loss: 1.757569359812059
Validation loss: 2.385173013698215

Epoch: 6| Step: 5
Training loss: 1.4305550699737284
Validation loss: 2.4026976147271544

Epoch: 6| Step: 6
Training loss: 2.001528156113922
Validation loss: 2.399719987791405

Epoch: 6| Step: 7
Training loss: 1.2246151183265939
Validation loss: 2.4811532089486863

Epoch: 6| Step: 8
Training loss: 1.6179698581222062
Validation loss: 2.3557466890465872

Epoch: 6| Step: 9
Training loss: 1.7966526723232932
Validation loss: 2.4032961077103625

Epoch: 6| Step: 10
Training loss: 1.3543793535712685
Validation loss: 2.4316521483005507

Epoch: 6| Step: 11
Training loss: 2.1662199097759594
Validation loss: 2.365059901112835

Epoch: 6| Step: 12
Training loss: 1.8347562195583722
Validation loss: 2.3825011971403574

Epoch: 6| Step: 13
Training loss: 2.2108001127118433
Validation loss: 2.3796284344518632

Epoch: 283| Step: 0
Training loss: 1.362934669664171
Validation loss: 2.3583193800283806

Epoch: 6| Step: 1
Training loss: 1.5017424635363847
Validation loss: 2.3759968699706064

Epoch: 6| Step: 2
Training loss: 1.0736266012638402
Validation loss: 2.403580948429586

Epoch: 6| Step: 3
Training loss: 1.7750660816840294
Validation loss: 2.3656598589052957

Epoch: 6| Step: 4
Training loss: 1.3409281532390347
Validation loss: 2.3549978150430166

Epoch: 6| Step: 5
Training loss: 2.2716230250098994
Validation loss: 2.4218999876598297

Epoch: 6| Step: 6
Training loss: 1.7638469959734229
Validation loss: 2.3654496875064526

Epoch: 6| Step: 7
Training loss: 2.425022368966982
Validation loss: 2.400491145042697

Epoch: 6| Step: 8
Training loss: 1.6183271584882442
Validation loss: 2.397332866514301

Epoch: 6| Step: 9
Training loss: 1.8868438489679489
Validation loss: 2.4217719213254405

Epoch: 6| Step: 10
Training loss: 1.5128281733838242
Validation loss: 2.3630723723138227

Epoch: 6| Step: 11
Training loss: 1.4726973712552915
Validation loss: 2.366027163185547

Epoch: 6| Step: 12
Training loss: 1.8673818319537745
Validation loss: 2.3928831136530664

Epoch: 6| Step: 13
Training loss: 1.8916259511971583
Validation loss: 2.329801290859436

Epoch: 284| Step: 0
Training loss: 2.162622516667476
Validation loss: 2.3770962904923105

Epoch: 6| Step: 1
Training loss: 1.8833013509324714
Validation loss: 2.3500613775989243

Epoch: 6| Step: 2
Training loss: 1.6174808549411255
Validation loss: 2.3407671382801682

Epoch: 6| Step: 3
Training loss: 1.1552867485562925
Validation loss: 2.39980638993805

Epoch: 6| Step: 4
Training loss: 2.357481544074493
Validation loss: 2.369920579463872

Epoch: 6| Step: 5
Training loss: 1.2325085883005766
Validation loss: 2.3577545540536162

Epoch: 6| Step: 6
Training loss: 1.8434589608872403
Validation loss: 2.376510152952016

Epoch: 6| Step: 7
Training loss: 1.4614137903314874
Validation loss: 2.4172897481526583

Epoch: 6| Step: 8
Training loss: 2.0487133826753383
Validation loss: 2.401781833232902

Epoch: 6| Step: 9
Training loss: 1.4990317875632664
Validation loss: 2.382770901482807

Epoch: 6| Step: 10
Training loss: 1.1117047843136325
Validation loss: 2.438202276416753

Epoch: 6| Step: 11
Training loss: 1.6384982902604077
Validation loss: 2.3976207776360074

Epoch: 6| Step: 12
Training loss: 1.4860044670859307
Validation loss: 2.463210089934149

Epoch: 6| Step: 13
Training loss: 1.8596155347635137
Validation loss: 2.396754285694119

Epoch: 285| Step: 0
Training loss: 1.8969188628553595
Validation loss: 2.3497241316463198

Epoch: 6| Step: 1
Training loss: 1.7573203521117853
Validation loss: 2.394051183696703

Epoch: 6| Step: 2
Training loss: 1.9412875532557403
Validation loss: 2.4395009114173782

Epoch: 6| Step: 3
Training loss: 1.8105090815314517
Validation loss: 2.4162836595224357

Epoch: 6| Step: 4
Training loss: 1.5083638502514847
Validation loss: 2.3921265534876945

Epoch: 6| Step: 5
Training loss: 1.4481076816647764
Validation loss: 2.380972422516908

Epoch: 6| Step: 6
Training loss: 2.1912404369922442
Validation loss: 2.4046533297584523

Epoch: 6| Step: 7
Training loss: 1.6578832526753333
Validation loss: 2.337596019601882

Epoch: 6| Step: 8
Training loss: 1.3677692156700247
Validation loss: 2.3957650587314916

Epoch: 6| Step: 9
Training loss: 1.8446515998532917
Validation loss: 2.4214273876023444

Epoch: 6| Step: 10
Training loss: 1.4012589788361904
Validation loss: 2.40385247306214

Epoch: 6| Step: 11
Training loss: 1.413437088555785
Validation loss: 2.3898671457192

Epoch: 6| Step: 12
Training loss: 1.8383138657775793
Validation loss: 2.4128659732417277

Epoch: 6| Step: 13
Training loss: 2.327976913350783
Validation loss: 2.397062740761701

Epoch: 286| Step: 0
Training loss: 1.8708423294270224
Validation loss: 2.403912861796903

Epoch: 6| Step: 1
Training loss: 1.6194065368007828
Validation loss: 2.384032671236061

Epoch: 6| Step: 2
Training loss: 1.9750415242332702
Validation loss: 2.3806346304135033

Epoch: 6| Step: 3
Training loss: 1.4364876707021275
Validation loss: 2.418566807210814

Epoch: 6| Step: 4
Training loss: 1.5762168754951145
Validation loss: 2.37858339708602

Epoch: 6| Step: 5
Training loss: 2.4983634360418874
Validation loss: 2.406860571347249

Epoch: 6| Step: 6
Training loss: 1.372387007142651
Validation loss: 2.3651814158154423

Epoch: 6| Step: 7
Training loss: 1.5005965636012548
Validation loss: 2.3912049234282917

Epoch: 6| Step: 8
Training loss: 1.2811504418374766
Validation loss: 2.4185025544043546

Epoch: 6| Step: 9
Training loss: 1.4453520898294017
Validation loss: 2.388116012027181

Epoch: 6| Step: 10
Training loss: 1.7261667617960377
Validation loss: 2.4080934562688947

Epoch: 6| Step: 11
Training loss: 2.0653309899955707
Validation loss: 2.415134634558254

Epoch: 6| Step: 12
Training loss: 2.0589008717475004
Validation loss: 2.441900589443647

Epoch: 6| Step: 13
Training loss: 1.8693713580892857
Validation loss: 2.3696616256897713

Epoch: 287| Step: 0
Training loss: 1.5056605820115192
Validation loss: 2.3648391241233546

Epoch: 6| Step: 1
Training loss: 1.8579004675954671
Validation loss: 2.331886784332537

Epoch: 6| Step: 2
Training loss: 2.396438610631695
Validation loss: 2.402820977885584

Epoch: 6| Step: 3
Training loss: 1.6343280384326249
Validation loss: 2.415449122877693

Epoch: 6| Step: 4
Training loss: 1.3948544253341082
Validation loss: 2.399936041270283

Epoch: 6| Step: 5
Training loss: 1.8187762805835896
Validation loss: 2.368462289871441

Epoch: 6| Step: 6
Training loss: 1.4244537444231808
Validation loss: 2.383019399981931

Epoch: 6| Step: 7
Training loss: 1.8606386779138893
Validation loss: 2.3763595655464504

Epoch: 6| Step: 8
Training loss: 1.7382166475442722
Validation loss: 2.462204224870601

Epoch: 6| Step: 9
Training loss: 1.8989920100666235
Validation loss: 2.37525486509613

Epoch: 6| Step: 10
Training loss: 1.427442779195866
Validation loss: 2.4055257814613085

Epoch: 6| Step: 11
Training loss: 1.6941919798804272
Validation loss: 2.374576291174966

Epoch: 6| Step: 12
Training loss: 1.2933110363175466
Validation loss: 2.3908922771349697

Epoch: 6| Step: 13
Training loss: 2.388614681928495
Validation loss: 2.4077475897165668

Epoch: 288| Step: 0
Training loss: 1.5323823906729375
Validation loss: 2.4076246669278842

Epoch: 6| Step: 1
Training loss: 1.4792275572946056
Validation loss: 2.3898878210927084

Epoch: 6| Step: 2
Training loss: 1.4214509604170251
Validation loss: 2.434679100275085

Epoch: 6| Step: 3
Training loss: 1.7579068306937602
Validation loss: 2.3776119573359678

Epoch: 6| Step: 4
Training loss: 2.3500363286233705
Validation loss: 2.3682308804729484

Epoch: 6| Step: 5
Training loss: 1.48840547779083
Validation loss: 2.430300007544559

Epoch: 6| Step: 6
Training loss: 1.6615682184918406
Validation loss: 2.3953379946038638

Epoch: 6| Step: 7
Training loss: 1.8517001459006177
Validation loss: 2.4245945412539376

Epoch: 6| Step: 8
Training loss: 1.1205809480398659
Validation loss: 2.3970648230627036

Epoch: 6| Step: 9
Training loss: 1.6155674878034978
Validation loss: 2.4254596255174534

Epoch: 6| Step: 10
Training loss: 1.7572143893463121
Validation loss: 2.4214826305055657

Epoch: 6| Step: 11
Training loss: 1.7954808673311984
Validation loss: 2.4256526852250526

Epoch: 6| Step: 12
Training loss: 1.8467785805256356
Validation loss: 2.4174360260657517

Epoch: 6| Step: 13
Training loss: 2.088251894463751
Validation loss: 2.404649514124406

Epoch: 289| Step: 0
Training loss: 1.5365594173305048
Validation loss: 2.3873267083119902

Epoch: 6| Step: 1
Training loss: 1.5955891189097076
Validation loss: 2.3906136006525793

Epoch: 6| Step: 2
Training loss: 1.875846353884224
Validation loss: 2.3441953316643556

Epoch: 6| Step: 3
Training loss: 1.8491071041233742
Validation loss: 2.376813668834974

Epoch: 6| Step: 4
Training loss: 1.26402247192229
Validation loss: 2.3043879121503044

Epoch: 6| Step: 5
Training loss: 1.6036652693810114
Validation loss: 2.3694640504585722

Epoch: 6| Step: 6
Training loss: 1.952798190431487
Validation loss: 2.372759343346283

Epoch: 6| Step: 7
Training loss: 1.5806141475789122
Validation loss: 2.393864871006042

Epoch: 6| Step: 8
Training loss: 1.9239667968343541
Validation loss: 2.3378753498496847

Epoch: 6| Step: 9
Training loss: 1.513611074887783
Validation loss: 2.377517003309058

Epoch: 6| Step: 10
Training loss: 1.060385282510469
Validation loss: 2.342461876419275

Epoch: 6| Step: 11
Training loss: 1.7571861677115563
Validation loss: 2.3990645381786204

Epoch: 6| Step: 12
Training loss: 1.922573985944378
Validation loss: 2.34188319523894

Epoch: 6| Step: 13
Training loss: 2.674988031806198
Validation loss: 2.306140647465745

Epoch: 290| Step: 0
Training loss: 1.1871666691401772
Validation loss: 2.407232944897985

Epoch: 6| Step: 1
Training loss: 1.909384417471629
Validation loss: 2.413112577868137

Epoch: 6| Step: 2
Training loss: 1.084759903900588
Validation loss: 2.4029926913890933

Epoch: 6| Step: 3
Training loss: 1.6768971531357624
Validation loss: 2.4184685097738625

Epoch: 6| Step: 4
Training loss: 2.1461111339507974
Validation loss: 2.416485980884953

Epoch: 6| Step: 5
Training loss: 2.6084804257811385
Validation loss: 2.439378662833036

Epoch: 6| Step: 6
Training loss: 1.88470471535728
Validation loss: 2.415391157529414

Epoch: 6| Step: 7
Training loss: 1.595972867132741
Validation loss: 2.431393469212543

Epoch: 6| Step: 8
Training loss: 1.842196310991307
Validation loss: 2.3331487574579093

Epoch: 6| Step: 9
Training loss: 1.4663241217594802
Validation loss: 2.3795729535614014

Epoch: 6| Step: 10
Training loss: 1.3496095074930967
Validation loss: 2.3399667856288544

Epoch: 6| Step: 11
Training loss: 1.308562685469668
Validation loss: 2.427018116960255

Epoch: 6| Step: 12
Training loss: 1.2211725659844663
Validation loss: 2.3794896188289245

Epoch: 6| Step: 13
Training loss: 2.1536690565807546
Validation loss: 2.3703288539875227

Epoch: 291| Step: 0
Training loss: 1.5696826639619241
Validation loss: 2.390979969711664

Epoch: 6| Step: 1
Training loss: 1.6486766334388738
Validation loss: 2.36332766864357

Epoch: 6| Step: 2
Training loss: 1.798869543603136
Validation loss: 2.355614095147688

Epoch: 6| Step: 3
Training loss: 1.4716638109835392
Validation loss: 2.3586863013996937

Epoch: 6| Step: 4
Training loss: 1.6191314218441328
Validation loss: 2.3861055011417425

Epoch: 6| Step: 5
Training loss: 1.7530843937432972
Validation loss: 2.3731471521386878

Epoch: 6| Step: 6
Training loss: 1.6491796621716894
Validation loss: 2.4064070106082625

Epoch: 6| Step: 7
Training loss: 1.4855984113381744
Validation loss: 2.375695078829587

Epoch: 6| Step: 8
Training loss: 1.8593816676941899
Validation loss: 2.3535779866193485

Epoch: 6| Step: 9
Training loss: 1.7613381526591352
Validation loss: 2.389756969157704

Epoch: 6| Step: 10
Training loss: 1.6535821697165203
Validation loss: 2.3895734876169925

Epoch: 6| Step: 11
Training loss: 2.119569234089357
Validation loss: 2.399762922715463

Epoch: 6| Step: 12
Training loss: 2.2581417279293006
Validation loss: 2.3576109208409166

Epoch: 6| Step: 13
Training loss: 1.3303363118136358
Validation loss: 2.3879927179977485

Epoch: 292| Step: 0
Training loss: 1.6301851443590436
Validation loss: 2.352486113932659

Epoch: 6| Step: 1
Training loss: 2.0674383978563093
Validation loss: 2.435090324544368

Epoch: 6| Step: 2
Training loss: 1.6901215570512238
Validation loss: 2.3524707264989373

Epoch: 6| Step: 3
Training loss: 2.156494126805198
Validation loss: 2.3454068819854075

Epoch: 6| Step: 4
Training loss: 1.7879299260346184
Validation loss: 2.4029898791622006

Epoch: 6| Step: 5
Training loss: 1.2964246956243006
Validation loss: 2.386809432579432

Epoch: 6| Step: 6
Training loss: 1.7857772448203852
Validation loss: 2.4262280316855085

Epoch: 6| Step: 7
Training loss: 1.160368209639832
Validation loss: 2.422365575162102

Epoch: 6| Step: 8
Training loss: 1.6681828595929018
Validation loss: 2.3815670788590433

Epoch: 6| Step: 9
Training loss: 1.7217353556478112
Validation loss: 2.401621333871851

Epoch: 6| Step: 10
Training loss: 1.4724579128604198
Validation loss: 2.4111022491412566

Epoch: 6| Step: 11
Training loss: 1.670671404113101
Validation loss: 2.3521656994367603

Epoch: 6| Step: 12
Training loss: 1.7422671449528986
Validation loss: 2.404990259742247

Epoch: 6| Step: 13
Training loss: 2.4499430824986344
Validation loss: 2.3738099232325625

Epoch: 293| Step: 0
Training loss: 2.447721714346087
Validation loss: 2.4398606561747225

Epoch: 6| Step: 1
Training loss: 1.7055502606011843
Validation loss: 2.3941169665040647

Epoch: 6| Step: 2
Training loss: 1.252613958477786
Validation loss: 2.4130227159118043

Epoch: 6| Step: 3
Training loss: 1.9893341574160086
Validation loss: 2.4753867232441356

Epoch: 6| Step: 4
Training loss: 2.1739825444928864
Validation loss: 2.381040897694331

Epoch: 6| Step: 5
Training loss: 1.4144534418905852
Validation loss: 2.372897924450234

Epoch: 6| Step: 6
Training loss: 1.5246317559568188
Validation loss: 2.379166326782669

Epoch: 6| Step: 7
Training loss: 1.4749619624518904
Validation loss: 2.367087061367025

Epoch: 6| Step: 8
Training loss: 1.7099396046909592
Validation loss: 2.439870548800185

Epoch: 6| Step: 9
Training loss: 1.4699318371753747
Validation loss: 2.380573063723627

Epoch: 6| Step: 10
Training loss: 1.4684737737104185
Validation loss: 2.3801052530463984

Epoch: 6| Step: 11
Training loss: 1.2255401238013373
Validation loss: 2.4337817056140603

Epoch: 6| Step: 12
Training loss: 1.9502820495663487
Validation loss: 2.3780065147385665

Epoch: 6| Step: 13
Training loss: 1.4023616013944742
Validation loss: 2.4288684171417434

Epoch: 294| Step: 0
Training loss: 1.9370802763107027
Validation loss: 2.3581250508978533

Epoch: 6| Step: 1
Training loss: 1.5187919014382014
Validation loss: 2.3742182545523955

Epoch: 6| Step: 2
Training loss: 1.2689070355427357
Validation loss: 2.325565967485389

Epoch: 6| Step: 3
Training loss: 1.3882889575132487
Validation loss: 2.3811828667552395

Epoch: 6| Step: 4
Training loss: 1.6557691343878838
Validation loss: 2.3904961102130247

Epoch: 6| Step: 5
Training loss: 1.451786696548143
Validation loss: 2.4122955506822503

Epoch: 6| Step: 6
Training loss: 1.2121721434007697
Validation loss: 2.4176549139107606

Epoch: 6| Step: 7
Training loss: 1.5759721934387636
Validation loss: 2.4139647859132545

Epoch: 6| Step: 8
Training loss: 2.1986352068422157
Validation loss: 2.372635639748414

Epoch: 6| Step: 9
Training loss: 1.9793343389325893
Validation loss: 2.3614134110212093

Epoch: 6| Step: 10
Training loss: 1.81733007421129
Validation loss: 2.4408994045037007

Epoch: 6| Step: 11
Training loss: 1.9070793598987386
Validation loss: 2.3535263478610076

Epoch: 6| Step: 12
Training loss: 1.3861825685465408
Validation loss: 2.3631495903601163

Epoch: 6| Step: 13
Training loss: 2.443207928959559
Validation loss: 2.375804445374075

Epoch: 295| Step: 0
Training loss: 1.3422226320582586
Validation loss: 2.354868942462242

Epoch: 6| Step: 1
Training loss: 1.7652965679047388
Validation loss: 2.4233293123761

Epoch: 6| Step: 2
Training loss: 1.870448054832592
Validation loss: 2.4281352291381872

Epoch: 6| Step: 3
Training loss: 1.8274360075678084
Validation loss: 2.4065169681862337

Epoch: 6| Step: 4
Training loss: 1.646866904425222
Validation loss: 2.387069802809501

Epoch: 6| Step: 5
Training loss: 1.418309698808197
Validation loss: 2.39758340728148

Epoch: 6| Step: 6
Training loss: 1.2832037288484357
Validation loss: 2.3919667674131553

Epoch: 6| Step: 7
Training loss: 1.8162774153108567
Validation loss: 2.374578591844592

Epoch: 6| Step: 8
Training loss: 2.473594162221487
Validation loss: 2.400648439392891

Epoch: 6| Step: 9
Training loss: 1.0213624141087136
Validation loss: 2.3633965983691345

Epoch: 6| Step: 10
Training loss: 1.7765222013091715
Validation loss: 2.3929046318335216

Epoch: 6| Step: 11
Training loss: 2.06806080566086
Validation loss: 2.4112852790111132

Epoch: 6| Step: 12
Training loss: 1.087866079166536
Validation loss: 2.3554060727356565

Epoch: 6| Step: 13
Training loss: 1.6369054137059356
Validation loss: 2.4056496981396496

Epoch: 296| Step: 0
Training loss: 1.553272619466171
Validation loss: 2.3856038737792016

Epoch: 6| Step: 1
Training loss: 1.6146346135353473
Validation loss: 2.431908539737651

Epoch: 6| Step: 2
Training loss: 2.2073458016996907
Validation loss: 2.3555703109025736

Epoch: 6| Step: 3
Training loss: 1.5906797268489352
Validation loss: 2.474146276479842

Epoch: 6| Step: 4
Training loss: 1.8979164318945774
Validation loss: 2.4110558595062566

Epoch: 6| Step: 5
Training loss: 1.8711848545392777
Validation loss: 2.398044274033952

Epoch: 6| Step: 6
Training loss: 2.177444999867393
Validation loss: 2.425801227192663

Epoch: 6| Step: 7
Training loss: 1.4469251553965097
Validation loss: 2.4080745692415846

Epoch: 6| Step: 8
Training loss: 0.8821207898139349
Validation loss: 2.4482964620114176

Epoch: 6| Step: 9
Training loss: 1.9895768356882881
Validation loss: 2.455857613502029

Epoch: 6| Step: 10
Training loss: 1.4880265145554428
Validation loss: 2.4342355826736064

Epoch: 6| Step: 11
Training loss: 1.2346876690014081
Validation loss: 2.3776412680808354

Epoch: 6| Step: 12
Training loss: 1.6851833123804911
Validation loss: 2.4419851611184247

Epoch: 6| Step: 13
Training loss: 1.2720521751925304
Validation loss: 2.3412338708046123

Epoch: 297| Step: 0
Training loss: 1.6433224256100625
Validation loss: 2.3417451570864753

Epoch: 6| Step: 1
Training loss: 0.951694540750202
Validation loss: 2.3740682981846075

Epoch: 6| Step: 2
Training loss: 1.880186283338034
Validation loss: 2.4318433701866455

Epoch: 6| Step: 3
Training loss: 1.6867083352612406
Validation loss: 2.3927394763147776

Epoch: 6| Step: 4
Training loss: 1.2163544121331713
Validation loss: 2.404112080381432

Epoch: 6| Step: 5
Training loss: 1.7518920207345066
Validation loss: 2.3471201805941235

Epoch: 6| Step: 6
Training loss: 1.4462639228856202
Validation loss: 2.35270762733668

Epoch: 6| Step: 7
Training loss: 1.6205798701936538
Validation loss: 2.431915095600819

Epoch: 6| Step: 8
Training loss: 1.9134972808236448
Validation loss: 2.3473238358607076

Epoch: 6| Step: 9
Training loss: 2.268128478614408
Validation loss: 2.3857843628207247

Epoch: 6| Step: 10
Training loss: 1.6049075294309925
Validation loss: 2.4377448140718636

Epoch: 6| Step: 11
Training loss: 1.7140008684064876
Validation loss: 2.3694867869789467

Epoch: 6| Step: 12
Training loss: 2.0123375394654097
Validation loss: 2.3792710417153016

Epoch: 6| Step: 13
Training loss: 1.5825408491554351
Validation loss: 2.3538862521117947

Epoch: 298| Step: 0
Training loss: 1.758747648930283
Validation loss: 2.367386902569303

Epoch: 6| Step: 1
Training loss: 1.5832996699452169
Validation loss: 2.4431679888743223

Epoch: 6| Step: 2
Training loss: 2.293385144561455
Validation loss: 2.3563362398476575

Epoch: 6| Step: 3
Training loss: 1.5755747215786333
Validation loss: 2.3603492631688514

Epoch: 6| Step: 4
Training loss: 1.3473217535230697
Validation loss: 2.3607201629174535

Epoch: 6| Step: 5
Training loss: 1.565472636166139
Validation loss: 2.4596453098404827

Epoch: 6| Step: 6
Training loss: 1.5761792869346327
Validation loss: 2.3560429202850353

Epoch: 6| Step: 7
Training loss: 2.0615160357813593
Validation loss: 2.4281889828127685

Epoch: 6| Step: 8
Training loss: 2.0710110619441577
Validation loss: 2.440341721251259

Epoch: 6| Step: 9
Training loss: 1.6145392955393871
Validation loss: 2.409678209809199

Epoch: 6| Step: 10
Training loss: 1.9150833832836625
Validation loss: 2.431093821676247

Epoch: 6| Step: 11
Training loss: 1.136876989932256
Validation loss: 2.3961812671336267

Epoch: 6| Step: 12
Training loss: 1.2335336449483671
Validation loss: 2.4583781116454335

Epoch: 6| Step: 13
Training loss: 1.3080244961261718
Validation loss: 2.4779983756922546

Epoch: 299| Step: 0
Training loss: 1.2489041293071457
Validation loss: 2.4404790630597364

Epoch: 6| Step: 1
Training loss: 2.132004245854027
Validation loss: 2.4189147217335125

Epoch: 6| Step: 2
Training loss: 2.0423786193565303
Validation loss: 2.387897593258475

Epoch: 6| Step: 3
Training loss: 1.6946703841836184
Validation loss: 2.41165795371864

Epoch: 6| Step: 4
Training loss: 1.4868020544001497
Validation loss: 2.3677185149614726

Epoch: 6| Step: 5
Training loss: 1.4468385630029972
Validation loss: 2.4148604123068282

Epoch: 6| Step: 6
Training loss: 1.343661504980829
Validation loss: 2.3765603554430186

Epoch: 6| Step: 7
Training loss: 1.5951164222249297
Validation loss: 2.3395097874848307

Epoch: 6| Step: 8
Training loss: 2.309836425934788
Validation loss: 2.3614508771843563

Epoch: 6| Step: 9
Training loss: 1.4536350954653072
Validation loss: 2.4199409502981846

Epoch: 6| Step: 10
Training loss: 1.8876465595262812
Validation loss: 2.418025493676646

Epoch: 6| Step: 11
Training loss: 1.493896783615808
Validation loss: 2.379695492873368

Epoch: 6| Step: 12
Training loss: 1.2277391948842014
Validation loss: 2.395727630537681

Epoch: 6| Step: 13
Training loss: 2.0175160844390954
Validation loss: 2.3555489294510097

Epoch: 300| Step: 0
Training loss: 1.3939602321250175
Validation loss: 2.394217119263511

Epoch: 6| Step: 1
Training loss: 1.7724899247586632
Validation loss: 2.4151748455778392

Epoch: 6| Step: 2
Training loss: 1.9665949091778405
Validation loss: 2.4016675796368143

Epoch: 6| Step: 3
Training loss: 1.9249893014783939
Validation loss: 2.4078419488899216

Epoch: 6| Step: 4
Training loss: 2.244993998768013
Validation loss: 2.364925362133906

Epoch: 6| Step: 5
Training loss: 1.298065466436273
Validation loss: 2.4084634507359657

Epoch: 6| Step: 6
Training loss: 1.5554748535036502
Validation loss: 2.3876220783157502

Epoch: 6| Step: 7
Training loss: 1.377144441773295
Validation loss: 2.440538085937809

Epoch: 6| Step: 8
Training loss: 1.598449659254675
Validation loss: 2.4393412979512363

Epoch: 6| Step: 9
Training loss: 1.450672171440853
Validation loss: 2.402364305191014

Epoch: 6| Step: 10
Training loss: 1.4782467878627086
Validation loss: 2.4494283274133615

Epoch: 6| Step: 11
Training loss: 1.7134084756060257
Validation loss: 2.428691122520134

Epoch: 6| Step: 12
Training loss: 2.175266499470693
Validation loss: 2.391386992286835

Epoch: 6| Step: 13
Training loss: 1.592200329909514
Validation loss: 2.39634444111551

Epoch: 301| Step: 0
Training loss: 1.3407759468090208
Validation loss: 2.4613505771875817

Epoch: 6| Step: 1
Training loss: 1.6682436714252407
Validation loss: 2.384561132091974

Epoch: 6| Step: 2
Training loss: 1.2465480825222086
Validation loss: 2.4003354477771617

Epoch: 6| Step: 3
Training loss: 1.4831028355591211
Validation loss: 2.404282174227452

Epoch: 6| Step: 4
Training loss: 1.5947667786665933
Validation loss: 2.384976719155546

Epoch: 6| Step: 5
Training loss: 2.049029199499214
Validation loss: 2.4102959872163088

Epoch: 6| Step: 6
Training loss: 1.5104925026983775
Validation loss: 2.39932076945926

Epoch: 6| Step: 7
Training loss: 1.1030725180269179
Validation loss: 2.4121607682275306

Epoch: 6| Step: 8
Training loss: 1.409293166869996
Validation loss: 2.3541361503427285

Epoch: 6| Step: 9
Training loss: 2.0272575462992113
Validation loss: 2.4176295451701693

Epoch: 6| Step: 10
Training loss: 1.4691303653455159
Validation loss: 2.408584828882606

Epoch: 6| Step: 11
Training loss: 2.161412568737714
Validation loss: 2.3355864100732218

Epoch: 6| Step: 12
Training loss: 2.4374985328083025
Validation loss: 2.407907753129312

Epoch: 6| Step: 13
Training loss: 1.3556576028353116
Validation loss: 2.4096993822578447

Epoch: 302| Step: 0
Training loss: 1.5544125107678437
Validation loss: 2.374606067994225

Epoch: 6| Step: 1
Training loss: 1.694573869956257
Validation loss: 2.343725150465405

Epoch: 6| Step: 2
Training loss: 1.5780958418465802
Validation loss: 2.297233959211546

Epoch: 6| Step: 3
Training loss: 1.3255363368518558
Validation loss: 2.40531172222777

Epoch: 6| Step: 4
Training loss: 1.3946012591571997
Validation loss: 2.382562156099488

Epoch: 6| Step: 5
Training loss: 2.180364360107817
Validation loss: 2.403815305702797

Epoch: 6| Step: 6
Training loss: 1.5435030627725388
Validation loss: 2.3276970913243367

Epoch: 6| Step: 7
Training loss: 1.461237096411363
Validation loss: 2.404997940023367

Epoch: 6| Step: 8
Training loss: 2.4640738710130186
Validation loss: 2.4078137872859684

Epoch: 6| Step: 9
Training loss: 1.3581710833592646
Validation loss: 2.405565692713179

Epoch: 6| Step: 10
Training loss: 1.3945506973406554
Validation loss: 2.3850527550845704

Epoch: 6| Step: 11
Training loss: 1.5411179657230305
Validation loss: 2.406423367776591

Epoch: 6| Step: 12
Training loss: 1.5289533090342116
Validation loss: 2.371725916035455

Epoch: 6| Step: 13
Training loss: 1.787708286341265
Validation loss: 2.389876022399604

Epoch: 303| Step: 0
Training loss: 1.7659375749573483
Validation loss: 2.375921446819813

Epoch: 6| Step: 1
Training loss: 1.9521023934274166
Validation loss: 2.4066604170492143

Epoch: 6| Step: 2
Training loss: 1.50456417604327
Validation loss: 2.3786915067370553

Epoch: 6| Step: 3
Training loss: 1.182882567412837
Validation loss: 2.4072090888284117

Epoch: 6| Step: 4
Training loss: 1.60383377914848
Validation loss: 2.380617565149375

Epoch: 6| Step: 5
Training loss: 1.4363826057698141
Validation loss: 2.4134192762862887

Epoch: 6| Step: 6
Training loss: 1.7081663778955356
Validation loss: 2.440156463543465

Epoch: 6| Step: 7
Training loss: 1.3497463659162328
Validation loss: 2.475889553476984

Epoch: 6| Step: 8
Training loss: 2.4452860772896035
Validation loss: 2.445601640339425

Epoch: 6| Step: 9
Training loss: 1.645260393235947
Validation loss: 2.389359409084558

Epoch: 6| Step: 10
Training loss: 1.7167382691397672
Validation loss: 2.397605045803531

Epoch: 6| Step: 11
Training loss: 1.5777401596533749
Validation loss: 2.4457630207808285

Epoch: 6| Step: 12
Training loss: 1.5980681469009017
Validation loss: 2.458655779593551

Epoch: 6| Step: 13
Training loss: 1.2779216800504707
Validation loss: 2.4502014469522835

Epoch: 304| Step: 0
Training loss: 1.9018365391387857
Validation loss: 2.408298998144872

Epoch: 6| Step: 1
Training loss: 2.1387651815048403
Validation loss: 2.3847872164253916

Epoch: 6| Step: 2
Training loss: 1.4560546875
Validation loss: 2.331947430001108

Epoch: 6| Step: 3
Training loss: 1.7760439636871908
Validation loss: 2.375709801106503

Epoch: 6| Step: 4
Training loss: 1.2691877164407985
Validation loss: 2.4015474408481436

Epoch: 6| Step: 5
Training loss: 1.8355153998651415
Validation loss: 2.3500664174702863

Epoch: 6| Step: 6
Training loss: 1.907574303056027
Validation loss: 2.339170924926767

Epoch: 6| Step: 7
Training loss: 1.1611114576989183
Validation loss: 2.372096078778562

Epoch: 6| Step: 8
Training loss: 1.6170914478617715
Validation loss: 2.382338165082378

Epoch: 6| Step: 9
Training loss: 1.9275910267196938
Validation loss: 2.410390703966904

Epoch: 6| Step: 10
Training loss: 1.2124804603339343
Validation loss: 2.3270713490403496

Epoch: 6| Step: 11
Training loss: 1.7088265831172609
Validation loss: 2.3577247916619988

Epoch: 6| Step: 12
Training loss: 1.7207392884696555
Validation loss: 2.401735579527497

Epoch: 6| Step: 13
Training loss: 1.1091667302162922
Validation loss: 2.3484844361551676

Epoch: 305| Step: 0
Training loss: 1.551936644037679
Validation loss: 2.377347922766887

Epoch: 6| Step: 1
Training loss: 1.4007092569618997
Validation loss: 2.347325352863022

Epoch: 6| Step: 2
Training loss: 1.7005524410875767
Validation loss: 2.3520680717626306

Epoch: 6| Step: 3
Training loss: 1.5028492569548146
Validation loss: 2.442777374556187

Epoch: 6| Step: 4
Training loss: 1.8941206339612915
Validation loss: 2.453528682511652

Epoch: 6| Step: 5
Training loss: 1.565540407373876
Validation loss: 2.3874417110234885

Epoch: 6| Step: 6
Training loss: 1.496159405176548
Validation loss: 2.4488053495411073

Epoch: 6| Step: 7
Training loss: 1.8816801599582467
Validation loss: 2.402985466647818

Epoch: 6| Step: 8
Training loss: 2.3523184236184886
Validation loss: 2.3362143521182843

Epoch: 6| Step: 9
Training loss: 1.6558632309084247
Validation loss: 2.3443669842201884

Epoch: 6| Step: 10
Training loss: 1.2931182406116526
Validation loss: 2.4220334406433714

Epoch: 6| Step: 11
Training loss: 1.440100349664947
Validation loss: 2.4523478271610215

Epoch: 6| Step: 12
Training loss: 1.2074949491091147
Validation loss: 2.4051122677814853

Epoch: 6| Step: 13
Training loss: 1.3409840705374925
Validation loss: 2.4223499606420518

Epoch: 306| Step: 0
Training loss: 1.6292408112469792
Validation loss: 2.329397679688588

Epoch: 6| Step: 1
Training loss: 2.3085248649634558
Validation loss: 2.412270027806667

Epoch: 6| Step: 2
Training loss: 1.4969669512895647
Validation loss: 2.3786417889573728

Epoch: 6| Step: 3
Training loss: 2.1980697313377577
Validation loss: 2.3460167006874575

Epoch: 6| Step: 4
Training loss: 1.3288389194482273
Validation loss: 2.3452805398045844

Epoch: 6| Step: 5
Training loss: 1.6874641132070975
Validation loss: 2.381904513779972

Epoch: 6| Step: 6
Training loss: 1.4545800092504906
Validation loss: 2.3709458201953857

Epoch: 6| Step: 7
Training loss: 1.7006863975447029
Validation loss: 2.4222865966614218

Epoch: 6| Step: 8
Training loss: 1.2997359466145175
Validation loss: 2.4186038491065887

Epoch: 6| Step: 9
Training loss: 1.4980736920320117
Validation loss: 2.3730290216297356

Epoch: 6| Step: 10
Training loss: 1.365710436071088
Validation loss: 2.4225215941863305

Epoch: 6| Step: 11
Training loss: 1.8411473800746208
Validation loss: 2.4295690184674505

Epoch: 6| Step: 12
Training loss: 1.6272164414485728
Validation loss: 2.339212235176478

Epoch: 6| Step: 13
Training loss: 1.52584539025691
Validation loss: 2.39701525054607

Epoch: 307| Step: 0
Training loss: 1.8503297975772444
Validation loss: 2.434494388887908

Epoch: 6| Step: 1
Training loss: 1.5332914484909987
Validation loss: 2.4006746881102328

Epoch: 6| Step: 2
Training loss: 1.717003715475569
Validation loss: 2.4432976838221703

Epoch: 6| Step: 3
Training loss: 1.396604135353186
Validation loss: 2.434835753797212

Epoch: 6| Step: 4
Training loss: 1.5794370126267996
Validation loss: 2.362828407438626

Epoch: 6| Step: 5
Training loss: 1.4029117379679301
Validation loss: 2.4066989587986374

Epoch: 6| Step: 6
Training loss: 2.442998504213491
Validation loss: 2.422452681890252

Epoch: 6| Step: 7
Training loss: 1.8452527662359077
Validation loss: 2.4331718114202348

Epoch: 6| Step: 8
Training loss: 1.3778769133564128
Validation loss: 2.415287679015063

Epoch: 6| Step: 9
Training loss: 1.578055578536702
Validation loss: 2.468685335698994

Epoch: 6| Step: 10
Training loss: 1.2780157065821813
Validation loss: 2.44282048462503

Epoch: 6| Step: 11
Training loss: 1.8851323062595027
Validation loss: 2.4692066352360373

Epoch: 6| Step: 12
Training loss: 1.5440900760080476
Validation loss: 2.4898283653312046

Epoch: 6| Step: 13
Training loss: 1.335753221796753
Validation loss: 2.4049290553930325

Epoch: 308| Step: 0
Training loss: 1.3164555118750096
Validation loss: 2.3477368163778998

Epoch: 6| Step: 1
Training loss: 1.3692693064862378
Validation loss: 2.4397439800595913

Epoch: 6| Step: 2
Training loss: 1.791610435963731
Validation loss: 2.4223095210648746

Epoch: 6| Step: 3
Training loss: 0.9800178433273032
Validation loss: 2.457548384978724

Epoch: 6| Step: 4
Training loss: 1.6678634717534724
Validation loss: 2.4272406073486144

Epoch: 6| Step: 5
Training loss: 1.5552350330892735
Validation loss: 2.3383710888385196

Epoch: 6| Step: 6
Training loss: 2.386725642667267
Validation loss: 2.4392352904345618

Epoch: 6| Step: 7
Training loss: 1.2674811139477276
Validation loss: 2.397015583164806

Epoch: 6| Step: 8
Training loss: 1.9699239712291172
Validation loss: 2.395397992772999

Epoch: 6| Step: 9
Training loss: 1.7451371339619726
Validation loss: 2.4177617080452856

Epoch: 6| Step: 10
Training loss: 1.6168374682517337
Validation loss: 2.39233683524843

Epoch: 6| Step: 11
Training loss: 1.3691558619371038
Validation loss: 2.380756933098042

Epoch: 6| Step: 12
Training loss: 1.2357097603993044
Validation loss: 2.383876121633706

Epoch: 6| Step: 13
Training loss: 1.8754703567550122
Validation loss: 2.3792015921644754

Epoch: 309| Step: 0
Training loss: 1.9251010149919339
Validation loss: 2.377573481582796

Epoch: 6| Step: 1
Training loss: 2.4353447213055026
Validation loss: 2.409682061632013

Epoch: 6| Step: 2
Training loss: 1.3456472266204662
Validation loss: 2.391142112893845

Epoch: 6| Step: 3
Training loss: 1.4219224523653784
Validation loss: 2.323949916145174

Epoch: 6| Step: 4
Training loss: 1.372245283271966
Validation loss: 2.373174449874691

Epoch: 6| Step: 5
Training loss: 1.7177104233574243
Validation loss: 2.333484924537004

Epoch: 6| Step: 6
Training loss: 1.6657899298968206
Validation loss: 2.3891640862193158

Epoch: 6| Step: 7
Training loss: 1.8470878775302857
Validation loss: 2.3705963966278243

Epoch: 6| Step: 8
Training loss: 1.2919909880179146
Validation loss: 2.391669108437547

Epoch: 6| Step: 9
Training loss: 1.4137750828792015
Validation loss: 2.3665867498071935

Epoch: 6| Step: 10
Training loss: 1.1278001058546985
Validation loss: 2.3972480531209266

Epoch: 6| Step: 11
Training loss: 1.3362658359313628
Validation loss: 2.4038326062119655

Epoch: 6| Step: 12
Training loss: 1.4069962534769873
Validation loss: 2.4381328925403816

Epoch: 6| Step: 13
Training loss: 2.2636508101371056
Validation loss: 2.4622355126536597

Epoch: 310| Step: 0
Training loss: 2.160048966735775
Validation loss: 2.4303865951979438

Epoch: 6| Step: 1
Training loss: 1.92859720788105
Validation loss: 2.493635941407813

Epoch: 6| Step: 2
Training loss: 1.3222729275613063
Validation loss: 2.502737523560695

Epoch: 6| Step: 3
Training loss: 2.0191034863776527
Validation loss: 2.4350635624557495

Epoch: 6| Step: 4
Training loss: 1.5154136431690701
Validation loss: 2.4652151905669095

Epoch: 6| Step: 5
Training loss: 1.2030177873674237
Validation loss: 2.416274998686639

Epoch: 6| Step: 6
Training loss: 0.9326017528275312
Validation loss: 2.3734617838032137

Epoch: 6| Step: 7
Training loss: 1.3219474285655202
Validation loss: 2.404751443526142

Epoch: 6| Step: 8
Training loss: 1.6293957018369334
Validation loss: 2.4389013296239153

Epoch: 6| Step: 9
Training loss: 2.265160874807201
Validation loss: 2.424632226436375

Epoch: 6| Step: 10
Training loss: 1.2208509187874808
Validation loss: 2.3656672290657763

Epoch: 6| Step: 11
Training loss: 1.3378276281073977
Validation loss: 2.4448434662362164

Epoch: 6| Step: 12
Training loss: 1.5981845122271334
Validation loss: 2.424535724490446

Epoch: 6| Step: 13
Training loss: 1.6284798262942088
Validation loss: 2.403713125430533

Epoch: 311| Step: 0
Training loss: 1.380693914058631
Validation loss: 2.3927064901292483

Epoch: 6| Step: 1
Training loss: 1.459646133623983
Validation loss: 2.435241681676069

Epoch: 6| Step: 2
Training loss: 1.346896015189154
Validation loss: 2.3667362486567343

Epoch: 6| Step: 3
Training loss: 1.650239944351089
Validation loss: 2.3930440630252634

Epoch: 6| Step: 4
Training loss: 1.7458351848413427
Validation loss: 2.3710262666524415

Epoch: 6| Step: 5
Training loss: 1.4472206510281875
Validation loss: 2.3616192054042253

Epoch: 6| Step: 6
Training loss: 1.379958445642083
Validation loss: 2.4305887741733105

Epoch: 6| Step: 7
Training loss: 1.6690160246411756
Validation loss: 2.390279269970884

Epoch: 6| Step: 8
Training loss: 1.2909127568108627
Validation loss: 2.42591984043339

Epoch: 6| Step: 9
Training loss: 1.7692595351154805
Validation loss: 2.367973476293725

Epoch: 6| Step: 10
Training loss: 1.3282949451099062
Validation loss: 2.4495664449428167

Epoch: 6| Step: 11
Training loss: 1.4352470655785048
Validation loss: 2.4133086511084803

Epoch: 6| Step: 12
Training loss: 2.6172335948016374
Validation loss: 2.3903871016147344

Epoch: 6| Step: 13
Training loss: 1.5138107925165387
Validation loss: 2.365296707286478

Epoch: 312| Step: 0
Training loss: 1.1577605098114716
Validation loss: 2.4536534911805425

Epoch: 6| Step: 1
Training loss: 1.9204655262723953
Validation loss: 2.464947986935547

Epoch: 6| Step: 2
Training loss: 1.4279089532619165
Validation loss: 2.3808052978630316

Epoch: 6| Step: 3
Training loss: 2.202255726841792
Validation loss: 2.4166888528412946

Epoch: 6| Step: 4
Training loss: 1.7213498652679056
Validation loss: 2.4082933179520998

Epoch: 6| Step: 5
Training loss: 0.7186928187305441
Validation loss: 2.350383217145519

Epoch: 6| Step: 6
Training loss: 1.648786101159304
Validation loss: 2.37809514818548

Epoch: 6| Step: 7
Training loss: 1.5111673616165298
Validation loss: 2.4005164973310413

Epoch: 6| Step: 8
Training loss: 1.4082302985036421
Validation loss: 2.4528944362924956

Epoch: 6| Step: 9
Training loss: 1.7931849530084176
Validation loss: 2.4132121026873534

Epoch: 6| Step: 10
Training loss: 1.631331872164362
Validation loss: 2.4054760390718917

Epoch: 6| Step: 11
Training loss: 1.201221694533413
Validation loss: 2.3851910437987027

Epoch: 6| Step: 12
Training loss: 2.012631344507494
Validation loss: 2.441488809612969

Epoch: 6| Step: 13
Training loss: 1.2865880625355564
Validation loss: 2.4029930834576416

Epoch: 313| Step: 0
Training loss: 1.4058430400725084
Validation loss: 2.4652361075437237

Epoch: 6| Step: 1
Training loss: 1.6296172934283593
Validation loss: 2.423163315268386

Epoch: 6| Step: 2
Training loss: 1.7810380374545585
Validation loss: 2.3964850136410325

Epoch: 6| Step: 3
Training loss: 1.4913334024901381
Validation loss: 2.4850095662240532

Epoch: 6| Step: 4
Training loss: 0.8064367299860046
Validation loss: 2.4753485653665406

Epoch: 6| Step: 5
Training loss: 1.7588051260935293
Validation loss: 2.411035865403589

Epoch: 6| Step: 6
Training loss: 0.9634413624010792
Validation loss: 2.4603815401647466

Epoch: 6| Step: 7
Training loss: 1.6811698582490575
Validation loss: 2.3890317019793805

Epoch: 6| Step: 8
Training loss: 1.1311420621011938
Validation loss: 2.4354270090263044

Epoch: 6| Step: 9
Training loss: 2.2177662347485967
Validation loss: 2.426831613988482

Epoch: 6| Step: 10
Training loss: 1.5692124190559367
Validation loss: 2.3784406520120664

Epoch: 6| Step: 11
Training loss: 1.1377497451268956
Validation loss: 2.382209724991251

Epoch: 6| Step: 12
Training loss: 2.1971689431854533
Validation loss: 2.357305527923374

Epoch: 6| Step: 13
Training loss: 1.8065897506561648
Validation loss: 2.4040708450868227

Epoch: 314| Step: 0
Training loss: 1.9799982298255483
Validation loss: 2.4270191975470743

Epoch: 6| Step: 1
Training loss: 1.4666114822033935
Validation loss: 2.392051360803037

Epoch: 6| Step: 2
Training loss: 1.508389456461796
Validation loss: 2.357822493361937

Epoch: 6| Step: 3
Training loss: 1.7828975887872167
Validation loss: 2.386387367203344

Epoch: 6| Step: 4
Training loss: 1.7526298925392572
Validation loss: 2.4292633369069216

Epoch: 6| Step: 5
Training loss: 1.1384733102188866
Validation loss: 2.3840989218822393

Epoch: 6| Step: 6
Training loss: 1.4004227595985084
Validation loss: 2.3934773600045984

Epoch: 6| Step: 7
Training loss: 0.8356030945057267
Validation loss: 2.4138046792291408

Epoch: 6| Step: 8
Training loss: 1.3872652937870498
Validation loss: 2.3494569248239623

Epoch: 6| Step: 9
Training loss: 2.3625579988333754
Validation loss: 2.37767284918457

Epoch: 6| Step: 10
Training loss: 1.5584825366121524
Validation loss: 2.3731150754527657

Epoch: 6| Step: 11
Training loss: 1.0834487829069241
Validation loss: 2.390074183694798

Epoch: 6| Step: 12
Training loss: 1.3901764221202793
Validation loss: 2.43060226004907

Epoch: 6| Step: 13
Training loss: 1.3928760782289171
Validation loss: 2.335612257233227

Epoch: 315| Step: 0
Training loss: 1.5765433364172272
Validation loss: 2.3232821009663547

Epoch: 6| Step: 1
Training loss: 1.6007675058604243
Validation loss: 2.3753194761397554

Epoch: 6| Step: 2
Training loss: 1.6608982716733907
Validation loss: 2.383882127782592

Epoch: 6| Step: 3
Training loss: 1.6769716529702352
Validation loss: 2.393303815504144

Epoch: 6| Step: 4
Training loss: 1.5436516518095653
Validation loss: 2.3765974959848055

Epoch: 6| Step: 5
Training loss: 1.947806601721213
Validation loss: 2.3633129622507125

Epoch: 6| Step: 6
Training loss: 1.464675446060485
Validation loss: 2.380208242141773

Epoch: 6| Step: 7
Training loss: 1.1147109104240254
Validation loss: 2.3845816035124647

Epoch: 6| Step: 8
Training loss: 1.8324937704274455
Validation loss: 2.3284350464936425

Epoch: 6| Step: 9
Training loss: 1.3532253466040722
Validation loss: 2.4029037003085953

Epoch: 6| Step: 10
Training loss: 2.1591968026727253
Validation loss: 2.4290825154878997

Epoch: 6| Step: 11
Training loss: 1.6644692080655588
Validation loss: 2.407050454676104

Epoch: 6| Step: 12
Training loss: 1.2413210936256012
Validation loss: 2.4346560454185044

Epoch: 6| Step: 13
Training loss: 1.2531076425315812
Validation loss: 2.4457074405694663

Epoch: 316| Step: 0
Training loss: 1.5734838090614534
Validation loss: 2.376178298043361

Epoch: 6| Step: 1
Training loss: 1.5763137545537722
Validation loss: 2.3887665787954107

Epoch: 6| Step: 2
Training loss: 1.522705684855629
Validation loss: 2.452563450747751

Epoch: 6| Step: 3
Training loss: 1.546089975006445
Validation loss: 2.387755936469253

Epoch: 6| Step: 4
Training loss: 1.1922006428845302
Validation loss: 2.422288019620136

Epoch: 6| Step: 5
Training loss: 1.6189669342198716
Validation loss: 2.3834135855081198

Epoch: 6| Step: 6
Training loss: 1.5220515279982594
Validation loss: 2.391408698669019

Epoch: 6| Step: 7
Training loss: 1.879045001515812
Validation loss: 2.4114561293322665

Epoch: 6| Step: 8
Training loss: 1.2256385579154434
Validation loss: 2.371947007455732

Epoch: 6| Step: 9
Training loss: 0.7813716412259846
Validation loss: 2.4566229904572094

Epoch: 6| Step: 10
Training loss: 1.250921958428459
Validation loss: 2.416854811470789

Epoch: 6| Step: 11
Training loss: 1.755982187832492
Validation loss: 2.396889232852024

Epoch: 6| Step: 12
Training loss: 2.438284625411944
Validation loss: 2.350458685389169

Epoch: 6| Step: 13
Training loss: 1.5800865748383457
Validation loss: 2.336206072611375

Epoch: 317| Step: 0
Training loss: 1.0667930153183622
Validation loss: 2.4224088844499136

Epoch: 6| Step: 1
Training loss: 1.3954820570494397
Validation loss: 2.4170984859051594

Epoch: 6| Step: 2
Training loss: 0.8361457137583036
Validation loss: 2.3604783556869

Epoch: 6| Step: 3
Training loss: 2.1253992715360672
Validation loss: 2.4825398002814403

Epoch: 6| Step: 4
Training loss: 1.661181467679191
Validation loss: 2.425205465623112

Epoch: 6| Step: 5
Training loss: 1.5807709371545782
Validation loss: 2.437345121736149

Epoch: 6| Step: 6
Training loss: 1.304607457429612
Validation loss: 2.4043004555473666

Epoch: 6| Step: 7
Training loss: 1.6602058672502702
Validation loss: 2.374349773884429

Epoch: 6| Step: 8
Training loss: 2.2657675862661564
Validation loss: 2.4236060776533708

Epoch: 6| Step: 9
Training loss: 1.4721031060804268
Validation loss: 2.3393102716982015

Epoch: 6| Step: 10
Training loss: 1.0780362078826395
Validation loss: 2.3882389921498346

Epoch: 6| Step: 11
Training loss: 1.814968926870477
Validation loss: 2.4400293803639967

Epoch: 6| Step: 12
Training loss: 1.4815322156448885
Validation loss: 2.3979074268443332

Epoch: 6| Step: 13
Training loss: 1.7307416644713223
Validation loss: 2.413735185625725

Epoch: 318| Step: 0
Training loss: 1.5234001741971865
Validation loss: 2.434349956897288

Epoch: 6| Step: 1
Training loss: 1.8380852656008029
Validation loss: 2.3874484995926

Epoch: 6| Step: 2
Training loss: 1.1548939562911003
Validation loss: 2.389135326742199

Epoch: 6| Step: 3
Training loss: 1.4535776889327456
Validation loss: 2.3690513286492774

Epoch: 6| Step: 4
Training loss: 1.917813110252011
Validation loss: 2.4332069146540194

Epoch: 6| Step: 5
Training loss: 1.1699302813143575
Validation loss: 2.3951181536506874

Epoch: 6| Step: 6
Training loss: 1.7289947363010503
Validation loss: 2.403449585480605

Epoch: 6| Step: 7
Training loss: 0.8924337725283326
Validation loss: 2.436423874785303

Epoch: 6| Step: 8
Training loss: 1.647510430588069
Validation loss: 2.388046005971067

Epoch: 6| Step: 9
Training loss: 2.358042561788393
Validation loss: 2.4077094182546968

Epoch: 6| Step: 10
Training loss: 0.948754342211209
Validation loss: 2.4035907029285437

Epoch: 6| Step: 11
Training loss: 1.4738495947241876
Validation loss: 2.4518135713713907

Epoch: 6| Step: 12
Training loss: 1.5282120443879197
Validation loss: 2.4368735371602033

Epoch: 6| Step: 13
Training loss: 1.3650468471019668
Validation loss: 2.382136958193729

Epoch: 319| Step: 0
Training loss: 1.3714541752162255
Validation loss: 2.374346883463551

Epoch: 6| Step: 1
Training loss: 1.2454174442656816
Validation loss: 2.3894956954730757

Epoch: 6| Step: 2
Training loss: 2.137846319686399
Validation loss: 2.407563467789756

Epoch: 6| Step: 3
Training loss: 2.0936131219105025
Validation loss: 2.3688498670956197

Epoch: 6| Step: 4
Training loss: 1.2459627279918861
Validation loss: 2.341104087241579

Epoch: 6| Step: 5
Training loss: 1.512272065697736
Validation loss: 2.368419542519331

Epoch: 6| Step: 6
Training loss: 1.452110264371962
Validation loss: 2.4070326021613777

Epoch: 6| Step: 7
Training loss: 1.2489310462310343
Validation loss: 2.4361095801258794

Epoch: 6| Step: 8
Training loss: 1.2599209475317235
Validation loss: 2.411082209702504

Epoch: 6| Step: 9
Training loss: 1.484492889541449
Validation loss: 2.410952824943759

Epoch: 6| Step: 10
Training loss: 1.6233635511986684
Validation loss: 2.3843579129507124

Epoch: 6| Step: 11
Training loss: 1.6799707218298312
Validation loss: 2.363784248088021

Epoch: 6| Step: 12
Training loss: 1.4562735952667825
Validation loss: 2.407862332575089

Epoch: 6| Step: 13
Training loss: 1.9804317312900273
Validation loss: 2.3761257705088514

Epoch: 320| Step: 0
Training loss: 1.1565516310405044
Validation loss: 2.434230379528855

Epoch: 6| Step: 1
Training loss: 1.420623647854485
Validation loss: 2.403666004450948

Epoch: 6| Step: 2
Training loss: 2.214581294042367
Validation loss: 2.4417757070921415

Epoch: 6| Step: 3
Training loss: 1.6178854205722795
Validation loss: 2.4456756457390947

Epoch: 6| Step: 4
Training loss: 1.8090368926765814
Validation loss: 2.432954625702864

Epoch: 6| Step: 5
Training loss: 1.6044438935880927
Validation loss: 2.37565847723299

Epoch: 6| Step: 6
Training loss: 1.943117059523934
Validation loss: 2.419558266150784

Epoch: 6| Step: 7
Training loss: 1.1193553458937244
Validation loss: 2.426393804862885

Epoch: 6| Step: 8
Training loss: 1.3465172418622966
Validation loss: 2.433074964348834

Epoch: 6| Step: 9
Training loss: 1.0903752169361225
Validation loss: 2.4048211114549467

Epoch: 6| Step: 10
Training loss: 1.6006114089549677
Validation loss: 2.389265069459393

Epoch: 6| Step: 11
Training loss: 1.4602977147365097
Validation loss: 2.336225828157669

Epoch: 6| Step: 12
Training loss: 1.6483155698111587
Validation loss: 2.4487779532080003

Epoch: 6| Step: 13
Training loss: 1.1636407075199413
Validation loss: 2.4076958941256072

Epoch: 321| Step: 0
Training loss: 0.8543252487598855
Validation loss: 2.45040291902475

Epoch: 6| Step: 1
Training loss: 1.06112862889297
Validation loss: 2.4041771603064506

Epoch: 6| Step: 2
Training loss: 2.548162591211079
Validation loss: 2.4687578173391995

Epoch: 6| Step: 3
Training loss: 1.6662375692489093
Validation loss: 2.3696141456518927

Epoch: 6| Step: 4
Training loss: 1.6419357150337728
Validation loss: 2.453119739207828

Epoch: 6| Step: 5
Training loss: 1.479885741411291
Validation loss: 2.4125103100532934

Epoch: 6| Step: 6
Training loss: 1.7619517779122074
Validation loss: 2.411457380079642

Epoch: 6| Step: 7
Training loss: 1.6470316455906815
Validation loss: 2.4021140432198815

Epoch: 6| Step: 8
Training loss: 1.5997970154272911
Validation loss: 2.4234034092201084

Epoch: 6| Step: 9
Training loss: 1.2693153549899283
Validation loss: 2.4403140071868514

Epoch: 6| Step: 10
Training loss: 0.8283405743121903
Validation loss: 2.405750450268513

Epoch: 6| Step: 11
Training loss: 1.5957247150132525
Validation loss: 2.353680251044283

Epoch: 6| Step: 12
Training loss: 1.3017306142542673
Validation loss: 2.409006486160411

Epoch: 6| Step: 13
Training loss: 2.1062712263628125
Validation loss: 2.3980312742928875

Epoch: 322| Step: 0
Training loss: 1.498584079037062
Validation loss: 2.412895029982852

Epoch: 6| Step: 1
Training loss: 0.9813226879434815
Validation loss: 2.4047400834252004

Epoch: 6| Step: 2
Training loss: 2.1887023890974238
Validation loss: 2.382829021286976

Epoch: 6| Step: 3
Training loss: 1.4338875035647072
Validation loss: 2.430458394192217

Epoch: 6| Step: 4
Training loss: 1.2019994350533578
Validation loss: 2.3735793116944697

Epoch: 6| Step: 5
Training loss: 1.5750553000293783
Validation loss: 2.4241587255475

Epoch: 6| Step: 6
Training loss: 1.449304624414117
Validation loss: 2.356588579436038

Epoch: 6| Step: 7
Training loss: 1.585058485450292
Validation loss: 2.4016589584267307

Epoch: 6| Step: 8
Training loss: 1.9137541853487081
Validation loss: 2.3626312107653527

Epoch: 6| Step: 9
Training loss: 1.678252134710733
Validation loss: 2.37751342124399

Epoch: 6| Step: 10
Training loss: 1.5583970177569044
Validation loss: 2.4080107242224273

Epoch: 6| Step: 11
Training loss: 1.4008867350665697
Validation loss: 2.4242626243413468

Epoch: 6| Step: 12
Training loss: 1.2100897990551542
Validation loss: 2.4199796343632674

Epoch: 6| Step: 13
Training loss: 1.9983727868931005
Validation loss: 2.414722245615286

Epoch: 323| Step: 0
Training loss: 1.1616366923737256
Validation loss: 2.416849085620615

Epoch: 6| Step: 1
Training loss: 1.4070650493792067
Validation loss: 2.416894198333402

Epoch: 6| Step: 2
Training loss: 1.4180027140603504
Validation loss: 2.4136234246142942

Epoch: 6| Step: 3
Training loss: 1.491342754820825
Validation loss: 2.419395204535471

Epoch: 6| Step: 4
Training loss: 1.5027882569551538
Validation loss: 2.383811734982103

Epoch: 6| Step: 5
Training loss: 1.3760373797218757
Validation loss: 2.3418103549471496

Epoch: 6| Step: 6
Training loss: 1.7781632431020675
Validation loss: 2.417534750421962

Epoch: 6| Step: 7
Training loss: 1.4327009783725162
Validation loss: 2.3644083899877937

Epoch: 6| Step: 8
Training loss: 2.2047281046588063
Validation loss: 2.4044635780522112

Epoch: 6| Step: 9
Training loss: 1.78869865082533
Validation loss: 2.366959804458808

Epoch: 6| Step: 10
Training loss: 1.3518319274841104
Validation loss: 2.3858214140344614

Epoch: 6| Step: 11
Training loss: 1.6336098508255743
Validation loss: 2.3335006349181997

Epoch: 6| Step: 12
Training loss: 0.9505498524595137
Validation loss: 2.3678368941692596

Epoch: 6| Step: 13
Training loss: 1.6476224357712945
Validation loss: 2.3981878790666094

Epoch: 324| Step: 0
Training loss: 2.020992023752395
Validation loss: 2.4068403985985474

Epoch: 6| Step: 1
Training loss: 1.1521148971639459
Validation loss: 2.436802099720914

Epoch: 6| Step: 2
Training loss: 1.2027190873703635
Validation loss: 2.404838657378462

Epoch: 6| Step: 3
Training loss: 1.505033630299509
Validation loss: 2.3591518387561945

Epoch: 6| Step: 4
Training loss: 1.2272123328353906
Validation loss: 2.397962440772343

Epoch: 6| Step: 5
Training loss: 1.5775782327250976
Validation loss: 2.392543471459804

Epoch: 6| Step: 6
Training loss: 1.554907241704133
Validation loss: 2.344612335388314

Epoch: 6| Step: 7
Training loss: 1.32999261925736
Validation loss: 2.435615993619316

Epoch: 6| Step: 8
Training loss: 1.6275726640831516
Validation loss: 2.3594881473524114

Epoch: 6| Step: 9
Training loss: 1.8248399089462837
Validation loss: 2.390962383203672

Epoch: 6| Step: 10
Training loss: 1.7056667015538385
Validation loss: 2.4043182377162617

Epoch: 6| Step: 11
Training loss: 1.63900844313918
Validation loss: 2.4069027973403316

Epoch: 6| Step: 12
Training loss: 1.3587273118020826
Validation loss: 2.3699964126328537

Epoch: 6| Step: 13
Training loss: 1.5566703381927345
Validation loss: 2.3919259186558977

Epoch: 325| Step: 0
Training loss: 1.6407943638167721
Validation loss: 2.4149854184589046

Epoch: 6| Step: 1
Training loss: 1.4163482906646763
Validation loss: 2.3529017959215133

Epoch: 6| Step: 2
Training loss: 2.481340102089996
Validation loss: 2.3975372789505154

Epoch: 6| Step: 3
Training loss: 1.0471184290934428
Validation loss: 2.417182632223861

Epoch: 6| Step: 4
Training loss: 1.8005445080621294
Validation loss: 2.433562403690845

Epoch: 6| Step: 5
Training loss: 1.4493835849022445
Validation loss: 2.4269904894769696

Epoch: 6| Step: 6
Training loss: 0.8970638887028805
Validation loss: 2.454047660826073

Epoch: 6| Step: 7
Training loss: 1.219018564222142
Validation loss: 2.4618249441908824

Epoch: 6| Step: 8
Training loss: 1.077123204175203
Validation loss: 2.4812878759424555

Epoch: 6| Step: 9
Training loss: 1.491140107856584
Validation loss: 2.491412514668698

Epoch: 6| Step: 10
Training loss: 1.8689446261812606
Validation loss: 2.357732005042466

Epoch: 6| Step: 11
Training loss: 1.6353987512599362
Validation loss: 2.4493888608411796

Epoch: 6| Step: 12
Training loss: 1.4830023592764878
Validation loss: 2.39070411833777

Epoch: 6| Step: 13
Training loss: 1.461723972721036
Validation loss: 2.4162159263538667

Epoch: 326| Step: 0
Training loss: 1.8365025726142477
Validation loss: 2.4040001060718277

Epoch: 6| Step: 1
Training loss: 1.860670648078299
Validation loss: 2.3411102578753504

Epoch: 6| Step: 2
Training loss: 1.589865944447354
Validation loss: 2.3714123156594034

Epoch: 6| Step: 3
Training loss: 1.2138093426671543
Validation loss: 2.3001598469802476

Epoch: 6| Step: 4
Training loss: 1.1444488599891622
Validation loss: 2.377868172603159

Epoch: 6| Step: 5
Training loss: 1.4859580984202145
Validation loss: 2.483982476448376

Epoch: 6| Step: 6
Training loss: 1.6781717247735972
Validation loss: 2.3328531982769953

Epoch: 6| Step: 7
Training loss: 1.0699184834098192
Validation loss: 2.3431374452852385

Epoch: 6| Step: 8
Training loss: 2.0496497529583553
Validation loss: 2.3622822394395175

Epoch: 6| Step: 9
Training loss: 2.328667699042411
Validation loss: 2.3577450269106857

Epoch: 6| Step: 10
Training loss: 1.06539617637849
Validation loss: 2.3975196464449007

Epoch: 6| Step: 11
Training loss: 1.2492541949293523
Validation loss: 2.3816313980999873

Epoch: 6| Step: 12
Training loss: 1.5408443457273708
Validation loss: 2.3457093414595587

Epoch: 6| Step: 13
Training loss: 1.344700765258408
Validation loss: 2.408704289388539

Epoch: 327| Step: 0
Training loss: 1.5143293368027688
Validation loss: 2.3774571426486757

Epoch: 6| Step: 1
Training loss: 1.407187806124551
Validation loss: 2.428239786558994

Epoch: 6| Step: 2
Training loss: 1.5150173581579913
Validation loss: 2.4241795579044547

Epoch: 6| Step: 3
Training loss: 1.457687189373076
Validation loss: 2.3623284294696365

Epoch: 6| Step: 4
Training loss: 1.8098646275599657
Validation loss: 2.3985432419163075

Epoch: 6| Step: 5
Training loss: 0.9388086086827695
Validation loss: 2.426387461243615

Epoch: 6| Step: 6
Training loss: 1.651758834443414
Validation loss: 2.3583252898364284

Epoch: 6| Step: 7
Training loss: 1.2171388883273342
Validation loss: 2.4237318189780668

Epoch: 6| Step: 8
Training loss: 1.4967109861091892
Validation loss: 2.423358165904134

Epoch: 6| Step: 9
Training loss: 1.5357585628121149
Validation loss: 2.3826746273515944

Epoch: 6| Step: 10
Training loss: 2.497911152795131
Validation loss: 2.387794242242272

Epoch: 6| Step: 11
Training loss: 1.1013304012708296
Validation loss: 2.386259302450016

Epoch: 6| Step: 12
Training loss: 1.444444302819726
Validation loss: 2.3987203783067

Epoch: 6| Step: 13
Training loss: 0.9838210469708242
Validation loss: 2.4108583440154256

Epoch: 328| Step: 0
Training loss: 2.3418178477871323
Validation loss: 2.3908488237005145

Epoch: 6| Step: 1
Training loss: 1.6072394266331091
Validation loss: 2.351203855949576

Epoch: 6| Step: 2
Training loss: 1.3631835727621964
Validation loss: 2.3870552289962084

Epoch: 6| Step: 3
Training loss: 1.337640847606587
Validation loss: 2.36443409555628

Epoch: 6| Step: 4
Training loss: 1.4518541911453062
Validation loss: 2.360738325478761

Epoch: 6| Step: 5
Training loss: 1.223818242057202
Validation loss: 2.4010795440971187

Epoch: 6| Step: 6
Training loss: 1.1850605553232374
Validation loss: 2.4350862481350664

Epoch: 6| Step: 7
Training loss: 1.5680177537438498
Validation loss: 2.4180898349631925

Epoch: 6| Step: 8
Training loss: 1.4223937880246311
Validation loss: 2.438344792747383

Epoch: 6| Step: 9
Training loss: 1.599890901899169
Validation loss: 2.441764189570685

Epoch: 6| Step: 10
Training loss: 1.3152555875820842
Validation loss: 2.3637973591685766

Epoch: 6| Step: 11
Training loss: 1.8038177376001592
Validation loss: 2.405471209079476

Epoch: 6| Step: 12
Training loss: 1.3066900269616257
Validation loss: 2.4252868785851183

Epoch: 6| Step: 13
Training loss: 1.0322595914033394
Validation loss: 2.30140644754081

Epoch: 329| Step: 0
Training loss: 1.7766338565557085
Validation loss: 2.387642686159354

Epoch: 6| Step: 1
Training loss: 1.0033582089488717
Validation loss: 2.3535658299857607

Epoch: 6| Step: 2
Training loss: 1.1258714267847234
Validation loss: 2.3943294954116943

Epoch: 6| Step: 3
Training loss: 1.787996132562709
Validation loss: 2.3558433040505387

Epoch: 6| Step: 4
Training loss: 1.2501041368975543
Validation loss: 2.446851244963991

Epoch: 6| Step: 5
Training loss: 1.837079930459869
Validation loss: 2.386202940049148

Epoch: 6| Step: 6
Training loss: 1.508288530699481
Validation loss: 2.3979868554846666

Epoch: 6| Step: 7
Training loss: 1.2825808242701597
Validation loss: 2.4100956746569713

Epoch: 6| Step: 8
Training loss: 2.302301756104023
Validation loss: 2.3578216724566223

Epoch: 6| Step: 9
Training loss: 1.5230615396471168
Validation loss: 2.3978421061886865

Epoch: 6| Step: 10
Training loss: 1.6914068138350677
Validation loss: 2.372458173410646

Epoch: 6| Step: 11
Training loss: 1.1217525022141714
Validation loss: 2.394706013219268

Epoch: 6| Step: 12
Training loss: 1.3938283564689944
Validation loss: 2.3577888457954184

Epoch: 6| Step: 13
Training loss: 1.0468820600129245
Validation loss: 2.419409217975339

Epoch: 330| Step: 0
Training loss: 1.631529235325385
Validation loss: 2.3740419637059498

Epoch: 6| Step: 1
Training loss: 1.1287847011297223
Validation loss: 2.418431266517126

Epoch: 6| Step: 2
Training loss: 1.0972573312274163
Validation loss: 2.3900342888813126

Epoch: 6| Step: 3
Training loss: 1.0867472860839036
Validation loss: 2.4402908710965003

Epoch: 6| Step: 4
Training loss: 1.6434032350004848
Validation loss: 2.4091886877551927

Epoch: 6| Step: 5
Training loss: 1.5610965529351666
Validation loss: 2.4883851315405576

Epoch: 6| Step: 6
Training loss: 1.7243095647128817
Validation loss: 2.445527868567177

Epoch: 6| Step: 7
Training loss: 1.6572577811308946
Validation loss: 2.5006340248336745

Epoch: 6| Step: 8
Training loss: 1.4565637569753531
Validation loss: 2.5096677564197747

Epoch: 6| Step: 9
Training loss: 2.5080662298933603
Validation loss: 2.5121947023694764

Epoch: 6| Step: 10
Training loss: 1.1493928011189378
Validation loss: 2.4746909703824915

Epoch: 6| Step: 11
Training loss: 1.1583197343608922
Validation loss: 2.4807785087523144

Epoch: 6| Step: 12
Training loss: 1.4620655620919414
Validation loss: 2.383050890448546

Epoch: 6| Step: 13
Training loss: 1.219474968109415
Validation loss: 2.414316360151291

Epoch: 331| Step: 0
Training loss: 1.1620508002898253
Validation loss: 2.4276920720447484

Epoch: 6| Step: 1
Training loss: 2.2396401213314143
Validation loss: 2.4319235731838122

Epoch: 6| Step: 2
Training loss: 1.6320702722978142
Validation loss: 2.38661018759622

Epoch: 6| Step: 3
Training loss: 1.6158041819631062
Validation loss: 2.336801556039106

Epoch: 6| Step: 4
Training loss: 1.1712775169568121
Validation loss: 2.3783800783974787

Epoch: 6| Step: 5
Training loss: 1.4517888314618026
Validation loss: 2.356299500739547

Epoch: 6| Step: 6
Training loss: 1.0068424494742731
Validation loss: 2.3597932621515594

Epoch: 6| Step: 7
Training loss: 1.7840045577833517
Validation loss: 2.372578278916667

Epoch: 6| Step: 8
Training loss: 1.4483939648847783
Validation loss: 2.401923482533337

Epoch: 6| Step: 9
Training loss: 1.2877927595447762
Validation loss: 2.4099572991535316

Epoch: 6| Step: 10
Training loss: 1.6713424975434714
Validation loss: 2.354347367084681

Epoch: 6| Step: 11
Training loss: 1.1253165753308512
Validation loss: 2.3714479482331186

Epoch: 6| Step: 12
Training loss: 1.7402088921219243
Validation loss: 2.3833456657682066

Epoch: 6| Step: 13
Training loss: 1.6407225806871597
Validation loss: 2.4260888126874574

Epoch: 332| Step: 0
Training loss: 1.2606164232755657
Validation loss: 2.394153463660478

Epoch: 6| Step: 1
Training loss: 1.9773173342130603
Validation loss: 2.391338384841963

Epoch: 6| Step: 2
Training loss: 1.2340938392769147
Validation loss: 2.3606674304274735

Epoch: 6| Step: 3
Training loss: 1.583618422825571
Validation loss: 2.4708906264767223

Epoch: 6| Step: 4
Training loss: 1.1774088597915082
Validation loss: 2.4309915272504856

Epoch: 6| Step: 5
Training loss: 1.1713142579323328
Validation loss: 2.4654306339994343

Epoch: 6| Step: 6
Training loss: 0.751996323967126
Validation loss: 2.375079455339202

Epoch: 6| Step: 7
Training loss: 1.384359841016177
Validation loss: 2.4488395126081377

Epoch: 6| Step: 8
Training loss: 1.234204920386887
Validation loss: 2.4732368862014704

Epoch: 6| Step: 9
Training loss: 1.5780955396867296
Validation loss: 2.3815492021675992

Epoch: 6| Step: 10
Training loss: 2.4969673836701
Validation loss: 2.4228212781778673

Epoch: 6| Step: 11
Training loss: 1.6189036086559516
Validation loss: 2.359105944054479

Epoch: 6| Step: 12
Training loss: 1.2104073625339393
Validation loss: 2.3828933408927377

Epoch: 6| Step: 13
Training loss: 1.8404403334824546
Validation loss: 2.4044680374323044

Epoch: 333| Step: 0
Training loss: 1.1504589118832182
Validation loss: 2.4810353732724764

Epoch: 6| Step: 1
Training loss: 1.1247879464251107
Validation loss: 2.3788552073926112

Epoch: 6| Step: 2
Training loss: 1.598048378872123
Validation loss: 2.413947274463207

Epoch: 6| Step: 3
Training loss: 1.378742154220987
Validation loss: 2.3954937994341736

Epoch: 6| Step: 4
Training loss: 1.3042558881243946
Validation loss: 2.4042164221707636

Epoch: 6| Step: 5
Training loss: 1.4368357574958088
Validation loss: 2.38631589019887

Epoch: 6| Step: 6
Training loss: 0.9594514723130576
Validation loss: 2.4255215177822382

Epoch: 6| Step: 7
Training loss: 1.3921782145420651
Validation loss: 2.4300785647504157

Epoch: 6| Step: 8
Training loss: 2.3335718532540017
Validation loss: 2.379992825717993

Epoch: 6| Step: 9
Training loss: 1.1667242149510104
Validation loss: 2.3850966322741023

Epoch: 6| Step: 10
Training loss: 1.755076742097406
Validation loss: 2.4467063395475264

Epoch: 6| Step: 11
Training loss: 1.4852039632502412
Validation loss: 2.4054560199050825

Epoch: 6| Step: 12
Training loss: 1.697708054659275
Validation loss: 2.4356773362509823

Epoch: 6| Step: 13
Training loss: 1.9534440047101334
Validation loss: 2.4034980285235803

Epoch: 334| Step: 0
Training loss: 0.9417094142179535
Validation loss: 2.421185073734635

Epoch: 6| Step: 1
Training loss: 1.8898983654568813
Validation loss: 2.383511964266696

Epoch: 6| Step: 2
Training loss: 1.316175853818109
Validation loss: 2.4119890489641365

Epoch: 6| Step: 3
Training loss: 1.305941270547587
Validation loss: 2.34587639061866

Epoch: 6| Step: 4
Training loss: 2.233648435464264
Validation loss: 2.3823891454424326

Epoch: 6| Step: 5
Training loss: 0.9869963544625591
Validation loss: 2.323465894783271

Epoch: 6| Step: 6
Training loss: 1.1783189224394306
Validation loss: 2.314880545406436

Epoch: 6| Step: 7
Training loss: 1.1880927363333948
Validation loss: 2.3594377891412623

Epoch: 6| Step: 8
Training loss: 1.2914422465786726
Validation loss: 2.334851170837313

Epoch: 6| Step: 9
Training loss: 1.8169109996776154
Validation loss: 2.3580463897817876

Epoch: 6| Step: 10
Training loss: 1.5045577582558458
Validation loss: 2.420029192518502

Epoch: 6| Step: 11
Training loss: 1.3923581499346762
Validation loss: 2.4428964160219215

Epoch: 6| Step: 12
Training loss: 1.7978092584393441
Validation loss: 2.372445168545078

Epoch: 6| Step: 13
Training loss: 1.6093670742987867
Validation loss: 2.390172670142117

Epoch: 335| Step: 0
Training loss: 1.2031815750890082
Validation loss: 2.35491185359858

Epoch: 6| Step: 1
Training loss: 1.4727350917120523
Validation loss: 2.362111724886697

Epoch: 6| Step: 2
Training loss: 1.951144259298441
Validation loss: 2.3919681982270244

Epoch: 6| Step: 3
Training loss: 1.3939751550110517
Validation loss: 2.4493616740860946

Epoch: 6| Step: 4
Training loss: 1.506702627340816
Validation loss: 2.4789384923222446

Epoch: 6| Step: 5
Training loss: 1.3136651453259272
Validation loss: 2.5016176425138426

Epoch: 6| Step: 6
Training loss: 1.681443684705987
Validation loss: 2.4542233618410894

Epoch: 6| Step: 7
Training loss: 2.1281565614844244
Validation loss: 2.4917120996851208

Epoch: 6| Step: 8
Training loss: 1.8397913315872454
Validation loss: 2.4021321265259377

Epoch: 6| Step: 9
Training loss: 1.0614964851109174
Validation loss: 2.439485753371224

Epoch: 6| Step: 10
Training loss: 1.4260201867963282
Validation loss: 2.405794506219669

Epoch: 6| Step: 11
Training loss: 1.1292314951868747
Validation loss: 2.440421829316358

Epoch: 6| Step: 12
Training loss: 1.3813105470669347
Validation loss: 2.4057305356865637

Epoch: 6| Step: 13
Training loss: 0.84959113441267
Validation loss: 2.412982590145925

Epoch: 336| Step: 0
Training loss: 1.1625482836304717
Validation loss: 2.3671808764232605

Epoch: 6| Step: 1
Training loss: 1.1865158520365813
Validation loss: 2.392999306314885

Epoch: 6| Step: 2
Training loss: 1.0069041927374998
Validation loss: 2.3579273255147393

Epoch: 6| Step: 3
Training loss: 1.2637499824923883
Validation loss: 2.370880661765282

Epoch: 6| Step: 4
Training loss: 2.4210798373319604
Validation loss: 2.3497771615433813

Epoch: 6| Step: 5
Training loss: 1.5071075847271616
Validation loss: 2.3478982509360296

Epoch: 6| Step: 6
Training loss: 1.8685174778219624
Validation loss: 2.3928671267571184

Epoch: 6| Step: 7
Training loss: 1.5792797132036558
Validation loss: 2.29633079021249

Epoch: 6| Step: 8
Training loss: 1.1034143992220342
Validation loss: 2.364139740966851

Epoch: 6| Step: 9
Training loss: 1.2739293371452864
Validation loss: 2.4450186637711138

Epoch: 6| Step: 10
Training loss: 1.2704386593341441
Validation loss: 2.433389007778782

Epoch: 6| Step: 11
Training loss: 1.8356452222261561
Validation loss: 2.3692637439119535

Epoch: 6| Step: 12
Training loss: 1.4828692378131785
Validation loss: 2.4468101693933852

Epoch: 6| Step: 13
Training loss: 1.7421010085733448
Validation loss: 2.308013511620084

Epoch: 337| Step: 0
Training loss: 1.3702936690982037
Validation loss: 2.3500500313035158

Epoch: 6| Step: 1
Training loss: 1.6371246781358695
Validation loss: 2.3787651969204333

Epoch: 6| Step: 2
Training loss: 1.3809232143984822
Validation loss: 2.4810129372437904

Epoch: 6| Step: 3
Training loss: 1.6526448581934452
Validation loss: 2.432402596106248

Epoch: 6| Step: 4
Training loss: 1.6395054948580312
Validation loss: 2.4395150931008756

Epoch: 6| Step: 5
Training loss: 1.341554578201929
Validation loss: 2.3654775146253852

Epoch: 6| Step: 6
Training loss: 1.6248328783222004
Validation loss: 2.350393298769401

Epoch: 6| Step: 7
Training loss: 1.3376009216736626
Validation loss: 2.397428807580744

Epoch: 6| Step: 8
Training loss: 1.0930849505722235
Validation loss: 2.43121924375208

Epoch: 6| Step: 9
Training loss: 1.266637185448
Validation loss: 2.4341712331931404

Epoch: 6| Step: 10
Training loss: 1.366702533266792
Validation loss: 2.4383974098240766

Epoch: 6| Step: 11
Training loss: 0.6587660106037934
Validation loss: 2.4468773930339283

Epoch: 6| Step: 12
Training loss: 2.3638861772596638
Validation loss: 2.4100248327189817

Epoch: 6| Step: 13
Training loss: 1.2547859599814288
Validation loss: 2.4229829379631265

Epoch: 338| Step: 0
Training loss: 1.6962193467611022
Validation loss: 2.4425785596871448

Epoch: 6| Step: 1
Training loss: 1.4358149064192103
Validation loss: 2.3938045002750257

Epoch: 6| Step: 2
Training loss: 0.9750102409411839
Validation loss: 2.439165392034089

Epoch: 6| Step: 3
Training loss: 1.1896081081200003
Validation loss: 2.355328576877017

Epoch: 6| Step: 4
Training loss: 1.2283240140063634
Validation loss: 2.4125433113128953

Epoch: 6| Step: 5
Training loss: 1.0427988892725277
Validation loss: 2.4570809889179546

Epoch: 6| Step: 6
Training loss: 1.420532766789354
Validation loss: 2.42769941333937

Epoch: 6| Step: 7
Training loss: 1.6010742932058155
Validation loss: 2.3573685054044606

Epoch: 6| Step: 8
Training loss: 1.7403684279746465
Validation loss: 2.3785423303406406

Epoch: 6| Step: 9
Training loss: 1.7762573275324358
Validation loss: 2.355499651028717

Epoch: 6| Step: 10
Training loss: 1.4333765348680887
Validation loss: 2.4552498576102253

Epoch: 6| Step: 11
Training loss: 1.125189341400306
Validation loss: 2.3859312017803993

Epoch: 6| Step: 12
Training loss: 2.1861014118596076
Validation loss: 2.4380030905595893

Epoch: 6| Step: 13
Training loss: 1.3200013736515412
Validation loss: 2.347498687675978

Epoch: 339| Step: 0
Training loss: 1.5799504665867459
Validation loss: 2.3565202770979425

Epoch: 6| Step: 1
Training loss: 0.908251426806958
Validation loss: 2.3738452325496158

Epoch: 6| Step: 2
Training loss: 1.0675243622369568
Validation loss: 2.3358656168112932

Epoch: 6| Step: 3
Training loss: 1.2711118747237238
Validation loss: 2.3336812066200463

Epoch: 6| Step: 4
Training loss: 1.3967896881336814
Validation loss: 2.415690684225787

Epoch: 6| Step: 5
Training loss: 1.510703522200344
Validation loss: 2.374172286663046

Epoch: 6| Step: 6
Training loss: 1.4843194248436762
Validation loss: 2.4019205996781743

Epoch: 6| Step: 7
Training loss: 1.2525357751819532
Validation loss: 2.3651925263951363

Epoch: 6| Step: 8
Training loss: 1.7040944271430127
Validation loss: 2.4126803537349972

Epoch: 6| Step: 9
Training loss: 1.0701460882977951
Validation loss: 2.3701826773440957

Epoch: 6| Step: 10
Training loss: 1.1652307984121064
Validation loss: 2.413484567836405

Epoch: 6| Step: 11
Training loss: 1.4606651827533195
Validation loss: 2.39119308834936

Epoch: 6| Step: 12
Training loss: 2.3594257273494366
Validation loss: 2.364962231739605

Epoch: 6| Step: 13
Training loss: 1.6309741316754782
Validation loss: 2.406782861824805

Epoch: 340| Step: 0
Training loss: 1.5125780448009185
Validation loss: 2.3817818889935074

Epoch: 6| Step: 1
Training loss: 1.6455192588159013
Validation loss: 2.420518116193668

Epoch: 6| Step: 2
Training loss: 1.3121297404874193
Validation loss: 2.3993023209091744

Epoch: 6| Step: 3
Training loss: 1.3458945881433262
Validation loss: 2.3767765181884375

Epoch: 6| Step: 4
Training loss: 1.3665516273804004
Validation loss: 2.3787253684007443

Epoch: 6| Step: 5
Training loss: 1.5433230995157499
Validation loss: 2.38145707808082

Epoch: 6| Step: 6
Training loss: 2.0426179136047455
Validation loss: 2.3680309362176937

Epoch: 6| Step: 7
Training loss: 1.1918232672615716
Validation loss: 2.415050337533133

Epoch: 6| Step: 8
Training loss: 1.3827810768824425
Validation loss: 2.390272100112714

Epoch: 6| Step: 9
Training loss: 1.3860587255193695
Validation loss: 2.3687949865713755

Epoch: 6| Step: 10
Training loss: 1.7693921975580476
Validation loss: 2.3660606307522527

Epoch: 6| Step: 11
Training loss: 1.2871176642699456
Validation loss: 2.391262567005096

Epoch: 6| Step: 12
Training loss: 1.0408209928316
Validation loss: 2.3566444850337867

Epoch: 6| Step: 13
Training loss: 1.1607888292123465
Validation loss: 2.379176965285375

Epoch: 341| Step: 0
Training loss: 1.6275236633736876
Validation loss: 2.3625002175269327

Epoch: 6| Step: 1
Training loss: 1.549406581001295
Validation loss: 2.3614793713065305

Epoch: 6| Step: 2
Training loss: 1.2691392029119986
Validation loss: 2.397676457849157

Epoch: 6| Step: 3
Training loss: 1.5897684665260676
Validation loss: 2.40058920252246

Epoch: 6| Step: 4
Training loss: 1.244729422232735
Validation loss: 2.452558821152913

Epoch: 6| Step: 5
Training loss: 1.1230624786619814
Validation loss: 2.3526468858900818

Epoch: 6| Step: 6
Training loss: 1.4495054717103728
Validation loss: 2.353440350099018

Epoch: 6| Step: 7
Training loss: 2.110455723583429
Validation loss: 2.367560461074697

Epoch: 6| Step: 8
Training loss: 1.0363429339141987
Validation loss: 2.3917948438059367

Epoch: 6| Step: 9
Training loss: 1.147769604013009
Validation loss: 2.4637989946177066

Epoch: 6| Step: 10
Training loss: 1.5428955060740743
Validation loss: 2.4303100683073766

Epoch: 6| Step: 11
Training loss: 1.5175468608527491
Validation loss: 2.4066333249680834

Epoch: 6| Step: 12
Training loss: 1.0632079514710606
Validation loss: 2.37423793567653

Epoch: 6| Step: 13
Training loss: 1.4816565265601755
Validation loss: 2.370345399555661

Epoch: 342| Step: 0
Training loss: 1.64825944707273
Validation loss: 2.4017498614534545

Epoch: 6| Step: 1
Training loss: 1.3618190323567365
Validation loss: 2.383674950458357

Epoch: 6| Step: 2
Training loss: 1.312595273147621
Validation loss: 2.4154733581877488

Epoch: 6| Step: 3
Training loss: 1.3089547186087234
Validation loss: 2.4255766721971206

Epoch: 6| Step: 4
Training loss: 1.287881113329061
Validation loss: 2.4493277538031544

Epoch: 6| Step: 5
Training loss: 1.6409028317580185
Validation loss: 2.374200118446968

Epoch: 6| Step: 6
Training loss: 1.1194851063857414
Validation loss: 2.3779165023280155

Epoch: 6| Step: 7
Training loss: 1.2585702828812955
Validation loss: 2.3012944944404565

Epoch: 6| Step: 8
Training loss: 2.2423963283360417
Validation loss: 2.373398765105253

Epoch: 6| Step: 9
Training loss: 1.554782346966481
Validation loss: 2.39782134971995

Epoch: 6| Step: 10
Training loss: 1.5473219100703606
Validation loss: 2.4024401429549234

Epoch: 6| Step: 11
Training loss: 1.132700105550348
Validation loss: 2.3339296209319813

Epoch: 6| Step: 12
Training loss: 1.4506924685755964
Validation loss: 2.403111798872

Epoch: 6| Step: 13
Training loss: 1.2192914200318132
Validation loss: 2.4050398011216845

Epoch: 343| Step: 0
Training loss: 1.4743469408962488
Validation loss: 2.3392202201953274

Epoch: 6| Step: 1
Training loss: 1.1082973350090155
Validation loss: 2.421198039689896

Epoch: 6| Step: 2
Training loss: 1.788506500603452
Validation loss: 2.3742577991178235

Epoch: 6| Step: 3
Training loss: 0.6959971796559598
Validation loss: 2.262704223551251

Epoch: 6| Step: 4
Training loss: 1.5632139482170668
Validation loss: 2.4870830338743883

Epoch: 6| Step: 5
Training loss: 1.4328507413097669
Validation loss: 2.3898683793383886

Epoch: 6| Step: 6
Training loss: 1.191962690643174
Validation loss: 2.3546064443215453

Epoch: 6| Step: 7
Training loss: 1.9076336701080305
Validation loss: 2.3890202649828463

Epoch: 6| Step: 8
Training loss: 1.9380259261508188
Validation loss: 2.366472985830546

Epoch: 6| Step: 9
Training loss: 1.7506444289447982
Validation loss: 2.3973608667871584

Epoch: 6| Step: 10
Training loss: 1.314400432375084
Validation loss: 2.4040294096694

Epoch: 6| Step: 11
Training loss: 1.270642261003225
Validation loss: 2.4053270428760722

Epoch: 6| Step: 12
Training loss: 1.188419086756011
Validation loss: 2.415280011817617

Epoch: 6| Step: 13
Training loss: 1.302077097559938
Validation loss: 2.3956690082311254

Epoch: 344| Step: 0
Training loss: 1.0672125929288219
Validation loss: 2.398693943613666

Epoch: 6| Step: 1
Training loss: 1.3170468274497666
Validation loss: 2.377602102185341

Epoch: 6| Step: 2
Training loss: 1.6345097240113236
Validation loss: 2.4151858416073173

Epoch: 6| Step: 3
Training loss: 1.133568084236958
Validation loss: 2.457068603060579

Epoch: 6| Step: 4
Training loss: 1.60222139528394
Validation loss: 2.391174479528571

Epoch: 6| Step: 5
Training loss: 2.2294348677202342
Validation loss: 2.37077976214365

Epoch: 6| Step: 6
Training loss: 1.5234169983095651
Validation loss: 2.4268034340050604

Epoch: 6| Step: 7
Training loss: 1.435511748215007
Validation loss: 2.3581903573953724

Epoch: 6| Step: 8
Training loss: 1.1723203702840301
Validation loss: 2.4308879814431545

Epoch: 6| Step: 9
Training loss: 1.2557069202394935
Validation loss: 2.4211368786950938

Epoch: 6| Step: 10
Training loss: 1.263746869604986
Validation loss: 2.3394472196137674

Epoch: 6| Step: 11
Training loss: 1.33148571488628
Validation loss: 2.4120736001779277

Epoch: 6| Step: 12
Training loss: 1.6600109081599317
Validation loss: 2.4074388605395707

Epoch: 6| Step: 13
Training loss: 1.6321739883053479
Validation loss: 2.3548209567678424

Epoch: 345| Step: 0
Training loss: 0.7588838692330446
Validation loss: 2.311482051638634

Epoch: 6| Step: 1
Training loss: 1.2467829314159176
Validation loss: 2.3571247087834832

Epoch: 6| Step: 2
Training loss: 1.21328168821112
Validation loss: 2.415639770175688

Epoch: 6| Step: 3
Training loss: 1.4296411392116097
Validation loss: 2.3807099629338793

Epoch: 6| Step: 4
Training loss: 1.5937136477644147
Validation loss: 2.422788887787058

Epoch: 6| Step: 5
Training loss: 1.024594824655282
Validation loss: 2.414039251434132

Epoch: 6| Step: 6
Training loss: 1.2330787709576192
Validation loss: 2.422437383302037

Epoch: 6| Step: 7
Training loss: 1.6001407173981492
Validation loss: 2.3778718457743633

Epoch: 6| Step: 8
Training loss: 1.2090929318500425
Validation loss: 2.459889828705789

Epoch: 6| Step: 9
Training loss: 1.6188936677901622
Validation loss: 2.3792369146701136

Epoch: 6| Step: 10
Training loss: 0.9914623223598771
Validation loss: 2.4051943603414445

Epoch: 6| Step: 11
Training loss: 2.384654449445814
Validation loss: 2.4074929964511464

Epoch: 6| Step: 12
Training loss: 1.354264397640217
Validation loss: 2.4426990633661236

Epoch: 6| Step: 13
Training loss: 1.5985878464439989
Validation loss: 2.4009723912703356

Epoch: 346| Step: 0
Training loss: 0.9615696014350342
Validation loss: 2.3803100345206785

Epoch: 6| Step: 1
Training loss: 1.0495718764381097
Validation loss: 2.428110996149522

Epoch: 6| Step: 2
Training loss: 1.356376585788167
Validation loss: 2.3655818926665932

Epoch: 6| Step: 3
Training loss: 1.0845221757639703
Validation loss: 2.3671175583828714

Epoch: 6| Step: 4
Training loss: 1.8609236991364178
Validation loss: 2.3428642759628646

Epoch: 6| Step: 5
Training loss: 1.3518739021850588
Validation loss: 2.3607923877281247

Epoch: 6| Step: 6
Training loss: 1.784399093224766
Validation loss: 2.400538033590095

Epoch: 6| Step: 7
Training loss: 1.239900799444116
Validation loss: 2.3943721158493076

Epoch: 6| Step: 8
Training loss: 1.042567086474002
Validation loss: 2.362918252507632

Epoch: 6| Step: 9
Training loss: 0.7995656160383202
Validation loss: 2.384249379606064

Epoch: 6| Step: 10
Training loss: 2.3562578236579017
Validation loss: 2.473634289350888

Epoch: 6| Step: 11
Training loss: 1.4750355894030127
Validation loss: 2.484003130637931

Epoch: 6| Step: 12
Training loss: 1.6182128309545285
Validation loss: 2.36404128098232

Epoch: 6| Step: 13
Training loss: 1.4942425861350233
Validation loss: 2.4216912270327176

Epoch: 347| Step: 0
Training loss: 1.215967082161566
Validation loss: 2.414595120965787

Epoch: 6| Step: 1
Training loss: 1.6421565581944657
Validation loss: 2.415291139780576

Epoch: 6| Step: 2
Training loss: 1.3702281164723138
Validation loss: 2.475392354080785

Epoch: 6| Step: 3
Training loss: 0.7648962016526644
Validation loss: 2.3801171066377065

Epoch: 6| Step: 4
Training loss: 1.4102758636889066
Validation loss: 2.398892576091291

Epoch: 6| Step: 5
Training loss: 1.585765359490523
Validation loss: 2.3693802898513248

Epoch: 6| Step: 6
Training loss: 1.1042074279938825
Validation loss: 2.384835561804329

Epoch: 6| Step: 7
Training loss: 1.5198326302285625
Validation loss: 2.425262867658488

Epoch: 6| Step: 8
Training loss: 1.2187724478194868
Validation loss: 2.5034071306279855

Epoch: 6| Step: 9
Training loss: 1.504023084189421
Validation loss: 2.454102315681793

Epoch: 6| Step: 10
Training loss: 2.359867372988771
Validation loss: 2.431542905638004

Epoch: 6| Step: 11
Training loss: 1.463093844102001
Validation loss: 2.4041368410527406

Epoch: 6| Step: 12
Training loss: 1.0095754772725007
Validation loss: 2.375803082518198

Epoch: 6| Step: 13
Training loss: 1.4816408374081216
Validation loss: 2.3582981485145047

Epoch: 348| Step: 0
Training loss: 2.0768514760763273
Validation loss: 2.4271787752915

Epoch: 6| Step: 1
Training loss: 1.6344820822652335
Validation loss: 2.4038922825213884

Epoch: 6| Step: 2
Training loss: 1.3241629799770906
Validation loss: 2.4145652905020385

Epoch: 6| Step: 3
Training loss: 1.1011933594252301
Validation loss: 2.3556735183531736

Epoch: 6| Step: 4
Training loss: 1.094516648951421
Validation loss: 2.381860402347248

Epoch: 6| Step: 5
Training loss: 1.3574543681475202
Validation loss: 2.3855390028788896

Epoch: 6| Step: 6
Training loss: 1.6208091394078266
Validation loss: 2.4366881262421756

Epoch: 6| Step: 7
Training loss: 1.2541705652136212
Validation loss: 2.341758594088699

Epoch: 6| Step: 8
Training loss: 1.8942290074832921
Validation loss: 2.3771010498009026

Epoch: 6| Step: 9
Training loss: 1.5959248382920603
Validation loss: 2.4535890653269576

Epoch: 6| Step: 10
Training loss: 1.154259798903552
Validation loss: 2.4532780659287945

Epoch: 6| Step: 11
Training loss: 1.391546351358161
Validation loss: 2.4187783748811564

Epoch: 6| Step: 12
Training loss: 0.8603830840520617
Validation loss: 2.4669411032924318

Epoch: 6| Step: 13
Training loss: 1.2705107680806083
Validation loss: 2.4522408864172553

Epoch: 349| Step: 0
Training loss: 1.2964826243067797
Validation loss: 2.3568130537425747

Epoch: 6| Step: 1
Training loss: 1.1606240918675137
Validation loss: 2.3235246914790206

Epoch: 6| Step: 2
Training loss: 2.0670366966042577
Validation loss: 2.3764474383962386

Epoch: 6| Step: 3
Training loss: 0.9353125802450148
Validation loss: 2.3368619902368652

Epoch: 6| Step: 4
Training loss: 1.0519786379752036
Validation loss: 2.4324281227400735

Epoch: 6| Step: 5
Training loss: 1.0533709185168008
Validation loss: 2.3466119051855676

Epoch: 6| Step: 6
Training loss: 1.4006195945243927
Validation loss: 2.343609923411957

Epoch: 6| Step: 7
Training loss: 1.6470576291821262
Validation loss: 2.398436758197524

Epoch: 6| Step: 8
Training loss: 1.461932328083955
Validation loss: 2.3758201521507045

Epoch: 6| Step: 9
Training loss: 1.507249559061679
Validation loss: 2.4003046561502446

Epoch: 6| Step: 10
Training loss: 1.0562346237237175
Validation loss: 2.369037253237571

Epoch: 6| Step: 11
Training loss: 1.0939302568399112
Validation loss: 2.4155905093379

Epoch: 6| Step: 12
Training loss: 1.3419371063827386
Validation loss: 2.4382966093714256

Epoch: 6| Step: 13
Training loss: 2.108525536060273
Validation loss: 2.406124853793316

Epoch: 350| Step: 0
Training loss: 2.4192864150964564
Validation loss: 2.3844717987831237

Epoch: 6| Step: 1
Training loss: 1.4370074879684152
Validation loss: 2.40265783188813

Epoch: 6| Step: 2
Training loss: 1.318227713333026
Validation loss: 2.3867707114342442

Epoch: 6| Step: 3
Training loss: 1.437327913681622
Validation loss: 2.3986887301713082

Epoch: 6| Step: 4
Training loss: 1.2676672764536852
Validation loss: 2.438751068973629

Epoch: 6| Step: 5
Training loss: 1.532693921712293
Validation loss: 2.4008589336409716

Epoch: 6| Step: 6
Training loss: 1.1309502915910432
Validation loss: 2.390782731147779

Epoch: 6| Step: 7
Training loss: 0.9686154918196601
Validation loss: 2.4527563128025727

Epoch: 6| Step: 8
Training loss: 1.1343865344089035
Validation loss: 2.3712337977124776

Epoch: 6| Step: 9
Training loss: 1.2271352026209152
Validation loss: 2.4004448141359758

Epoch: 6| Step: 10
Training loss: 1.0551285563240544
Validation loss: 2.41935984951102

Epoch: 6| Step: 11
Training loss: 1.6650599682521878
Validation loss: 2.422824422914581

Epoch: 6| Step: 12
Training loss: 1.025354468298544
Validation loss: 2.4105548128551875

Epoch: 6| Step: 13
Training loss: 1.6214991051232959
Validation loss: 2.377218814579008

Epoch: 351| Step: 0
Training loss: 1.3437798518923654
Validation loss: 2.3573138437073533

Epoch: 6| Step: 1
Training loss: 1.572401488695044
Validation loss: 2.3508780884379945

Epoch: 6| Step: 2
Training loss: 1.813099268796762
Validation loss: 2.366895109269965

Epoch: 6| Step: 3
Training loss: 1.2266585197039974
Validation loss: 2.3950000299989838

Epoch: 6| Step: 4
Training loss: 1.0488498337415246
Validation loss: 2.4032608107997353

Epoch: 6| Step: 5
Training loss: 1.1623810779081578
Validation loss: 2.3291845372444313

Epoch: 6| Step: 6
Training loss: 0.8315535055804452
Validation loss: 2.3072633248261623

Epoch: 6| Step: 7
Training loss: 2.146418729269441
Validation loss: 2.4260853583426867

Epoch: 6| Step: 8
Training loss: 1.2388885645350405
Validation loss: 2.347996467979515

Epoch: 6| Step: 9
Training loss: 1.098929647399724
Validation loss: 2.4636393393302534

Epoch: 6| Step: 10
Training loss: 1.0682561569982743
Validation loss: 2.4453276921691187

Epoch: 6| Step: 11
Training loss: 1.6772292490284049
Validation loss: 2.4713460124498385

Epoch: 6| Step: 12
Training loss: 1.2207620102984709
Validation loss: 2.368893203521457

Epoch: 6| Step: 13
Training loss: 0.9361680105187368
Validation loss: 2.380508967350505

Epoch: 352| Step: 0
Training loss: 1.3706120788827958
Validation loss: 2.387600583392678

Epoch: 6| Step: 1
Training loss: 1.0094787071971474
Validation loss: 2.4402757662827375

Epoch: 6| Step: 2
Training loss: 1.584757473919719
Validation loss: 2.3852441503856134

Epoch: 6| Step: 3
Training loss: 0.9288402511468663
Validation loss: 2.384839638109269

Epoch: 6| Step: 4
Training loss: 1.4246067173658203
Validation loss: 2.4440133320419752

Epoch: 6| Step: 5
Training loss: 1.6140423104130408
Validation loss: 2.339356969550016

Epoch: 6| Step: 6
Training loss: 1.4423552079810265
Validation loss: 2.3819077168426293

Epoch: 6| Step: 7
Training loss: 1.2209075024222045
Validation loss: 2.4371252510715498

Epoch: 6| Step: 8
Training loss: 1.3091832896892577
Validation loss: 2.4066280435053504

Epoch: 6| Step: 9
Training loss: 1.1360978465923877
Validation loss: 2.4084986213736457

Epoch: 6| Step: 10
Training loss: 1.57400912647437
Validation loss: 2.4245583712174623

Epoch: 6| Step: 11
Training loss: 1.4132395504629771
Validation loss: 2.4286823507615702

Epoch: 6| Step: 12
Training loss: 2.038736953179054
Validation loss: 2.4135798859834523

Epoch: 6| Step: 13
Training loss: 1.496683587118109
Validation loss: 2.4050553137721735

Epoch: 353| Step: 0
Training loss: 1.2571058479967496
Validation loss: 2.4430164685317686

Epoch: 6| Step: 1
Training loss: 1.2238580811478235
Validation loss: 2.361755706397118

Epoch: 6| Step: 2
Training loss: 1.2354909946324955
Validation loss: 2.334198533850153

Epoch: 6| Step: 3
Training loss: 1.3316564843779586
Validation loss: 2.4200598936687308

Epoch: 6| Step: 4
Training loss: 2.31925164320504
Validation loss: 2.3552943244187543

Epoch: 6| Step: 5
Training loss: 1.3392573816844775
Validation loss: 2.419379876017482

Epoch: 6| Step: 6
Training loss: 1.3126024024615897
Validation loss: 2.4292890432150376

Epoch: 6| Step: 7
Training loss: 1.1007910116830908
Validation loss: 2.3709794378281663

Epoch: 6| Step: 8
Training loss: 1.5658511274516729
Validation loss: 2.3648676473421673

Epoch: 6| Step: 9
Training loss: 1.1611006774818888
Validation loss: 2.4169563417582625

Epoch: 6| Step: 10
Training loss: 1.4134780772033562
Validation loss: 2.4290194168451915

Epoch: 6| Step: 11
Training loss: 1.3860478887280236
Validation loss: 2.4072901727286395

Epoch: 6| Step: 12
Training loss: 1.1550889242710418
Validation loss: 2.411002797788129

Epoch: 6| Step: 13
Training loss: 1.3016242883860363
Validation loss: 2.393630007536947

Epoch: 354| Step: 0
Training loss: 1.7184572143866754
Validation loss: 2.319816790800081

Epoch: 6| Step: 1
Training loss: 1.1745657991090868
Validation loss: 2.446357971927736

Epoch: 6| Step: 2
Training loss: 1.4432011209124085
Validation loss: 2.3044859461373592

Epoch: 6| Step: 3
Training loss: 1.4923605294293278
Validation loss: 2.406747653331871

Epoch: 6| Step: 4
Training loss: 0.9746718759314908
Validation loss: 2.4531054302976703

Epoch: 6| Step: 5
Training loss: 1.5745222305564954
Validation loss: 2.3904434929825475

Epoch: 6| Step: 6
Training loss: 0.633286781126876
Validation loss: 2.4080845551862096

Epoch: 6| Step: 7
Training loss: 1.1599449710289835
Validation loss: 2.3891927836518616

Epoch: 6| Step: 8
Training loss: 1.6024124495325003
Validation loss: 2.3705019916148378

Epoch: 6| Step: 9
Training loss: 1.9976063351741151
Validation loss: 2.392700645418748

Epoch: 6| Step: 10
Training loss: 0.9803786521336785
Validation loss: 2.3769642846342003

Epoch: 6| Step: 11
Training loss: 1.6518225603154875
Validation loss: 2.4106498108255794

Epoch: 6| Step: 12
Training loss: 1.2415269738968429
Validation loss: 2.4280701821482453

Epoch: 6| Step: 13
Training loss: 1.5379922311484933
Validation loss: 2.4466062921752934

Epoch: 355| Step: 0
Training loss: 1.4044922757722298
Validation loss: 2.3947587990721386

Epoch: 6| Step: 1
Training loss: 1.540929291486103
Validation loss: 2.379157835773012

Epoch: 6| Step: 2
Training loss: 1.4709067235400988
Validation loss: 2.4177575313767776

Epoch: 6| Step: 3
Training loss: 1.1625347993625843
Validation loss: 2.4786692204967333

Epoch: 6| Step: 4
Training loss: 1.0888160043498765
Validation loss: 2.3705724827842913

Epoch: 6| Step: 5
Training loss: 1.2891989895780263
Validation loss: 2.3986783652413837

Epoch: 6| Step: 6
Training loss: 1.1954283315347167
Validation loss: 2.3494308131465487

Epoch: 6| Step: 7
Training loss: 1.2153422323421816
Validation loss: 2.4204242533135023

Epoch: 6| Step: 8
Training loss: 1.3780149437519
Validation loss: 2.413542829651505

Epoch: 6| Step: 9
Training loss: 1.0840009808342357
Validation loss: 2.3987152712629913

Epoch: 6| Step: 10
Training loss: 1.2243233427295628
Validation loss: 2.3837571731093714

Epoch: 6| Step: 11
Training loss: 0.9532632571143171
Validation loss: 2.4307629535942943

Epoch: 6| Step: 12
Training loss: 1.719590969686496
Validation loss: 2.4169765658436733

Epoch: 6| Step: 13
Training loss: 2.5549902313702613
Validation loss: 2.4131552984139906

Epoch: 356| Step: 0
Training loss: 0.8118020507835466
Validation loss: 2.3736108382969294

Epoch: 6| Step: 1
Training loss: 1.1587197500846118
Validation loss: 2.412045021389363

Epoch: 6| Step: 2
Training loss: 1.5134108582915853
Validation loss: 2.3913347377160905

Epoch: 6| Step: 3
Training loss: 1.616840417445655
Validation loss: 2.4163246524508253

Epoch: 6| Step: 4
Training loss: 1.1734450948294188
Validation loss: 2.3798941706064647

Epoch: 6| Step: 5
Training loss: 1.169301220244842
Validation loss: 2.4104718026190524

Epoch: 6| Step: 6
Training loss: 1.3745076858705267
Validation loss: 2.387292834417125

Epoch: 6| Step: 7
Training loss: 1.3343400830026595
Validation loss: 2.4628574802092507

Epoch: 6| Step: 8
Training loss: 1.1088204945686273
Validation loss: 2.358499882571695

Epoch: 6| Step: 9
Training loss: 1.5482456800590574
Validation loss: 2.388781589692341

Epoch: 6| Step: 10
Training loss: 2.3021165894282594
Validation loss: 2.382577355111274

Epoch: 6| Step: 11
Training loss: 1.3691418874955172
Validation loss: 2.42281987404949

Epoch: 6| Step: 12
Training loss: 1.3373165931801256
Validation loss: 2.342082130080133

Epoch: 6| Step: 13
Training loss: 1.2675875294576016
Validation loss: 2.3962579558651984

Epoch: 357| Step: 0
Training loss: 1.5699097985275126
Validation loss: 2.4299316547359706

Epoch: 6| Step: 1
Training loss: 1.4764494676064968
Validation loss: 2.452455919383541

Epoch: 6| Step: 2
Training loss: 1.1087002918751214
Validation loss: 2.3934712986726767

Epoch: 6| Step: 3
Training loss: 1.1661385067290337
Validation loss: 2.3923533529142356

Epoch: 6| Step: 4
Training loss: 1.258625312849842
Validation loss: 2.4402718865849904

Epoch: 6| Step: 5
Training loss: 1.2205265985643408
Validation loss: 2.3239171758413253

Epoch: 6| Step: 6
Training loss: 1.1719908593443025
Validation loss: 2.4304883143845686

Epoch: 6| Step: 7
Training loss: 1.3472814066275869
Validation loss: 2.415857256602329

Epoch: 6| Step: 8
Training loss: 0.8507108366721199
Validation loss: 2.403357065637832

Epoch: 6| Step: 9
Training loss: 2.2730627635945275
Validation loss: 2.4163161148345664

Epoch: 6| Step: 10
Training loss: 0.9205294018307385
Validation loss: 2.3844295346613333

Epoch: 6| Step: 11
Training loss: 1.3516853144418077
Validation loss: 2.345994842590418

Epoch: 6| Step: 12
Training loss: 1.149574028817204
Validation loss: 2.3071867470045855

Epoch: 6| Step: 13
Training loss: 1.7054651963690144
Validation loss: 2.4609358363512976

Epoch: 358| Step: 0
Training loss: 1.123844400923808
Validation loss: 2.3836649784083974

Epoch: 6| Step: 1
Training loss: 1.1622147199823396
Validation loss: 2.4495677829810902

Epoch: 6| Step: 2
Training loss: 1.209357824868958
Validation loss: 2.379484661747895

Epoch: 6| Step: 3
Training loss: 1.1103162936041948
Validation loss: 2.3258167581024223

Epoch: 6| Step: 4
Training loss: 1.5697021057190605
Validation loss: 2.304051036908149

Epoch: 6| Step: 5
Training loss: 1.1079459859166152
Validation loss: 2.468605069441294

Epoch: 6| Step: 6
Training loss: 1.4891538289773936
Validation loss: 2.323437922551383

Epoch: 6| Step: 7
Training loss: 1.4638425126391474
Validation loss: 2.420646004745382

Epoch: 6| Step: 8
Training loss: 1.6493766965636922
Validation loss: 2.4157809931950185

Epoch: 6| Step: 9
Training loss: 1.59095129477268
Validation loss: 2.3870843942542077

Epoch: 6| Step: 10
Training loss: 1.540151220675099
Validation loss: 2.4390699590982643

Epoch: 6| Step: 11
Training loss: 0.9592417198819964
Validation loss: 2.3638033501782836

Epoch: 6| Step: 12
Training loss: 1.244135307168899
Validation loss: 2.403779010702693

Epoch: 6| Step: 13
Training loss: 2.5976942475486906
Validation loss: 2.433741941068055

Epoch: 359| Step: 0
Training loss: 0.9797894681829766
Validation loss: 2.3886654011508996

Epoch: 6| Step: 1
Training loss: 1.2434894768147315
Validation loss: 2.377634340452475

Epoch: 6| Step: 2
Training loss: 1.5859739553085714
Validation loss: 2.3680055555048702

Epoch: 6| Step: 3
Training loss: 1.2545116068491995
Validation loss: 2.4070054567553476

Epoch: 6| Step: 4
Training loss: 1.3349194133023898
Validation loss: 2.3366460298714076

Epoch: 6| Step: 5
Training loss: 1.4260501137764945
Validation loss: 2.336824750229982

Epoch: 6| Step: 6
Training loss: 2.1374379957698184
Validation loss: 2.333367016398291

Epoch: 6| Step: 7
Training loss: 1.2112567111716146
Validation loss: 2.3404914326175668

Epoch: 6| Step: 8
Training loss: 1.1538857181197157
Validation loss: 2.3604960161769135

Epoch: 6| Step: 9
Training loss: 1.310975870109701
Validation loss: 2.3328302041678666

Epoch: 6| Step: 10
Training loss: 0.9092375412182595
Validation loss: 2.447610350438347

Epoch: 6| Step: 11
Training loss: 1.2638054472006455
Validation loss: 2.3492907337190974

Epoch: 6| Step: 12
Training loss: 1.5091618642128515
Validation loss: 2.3915294759508043

Epoch: 6| Step: 13
Training loss: 1.584657725853921
Validation loss: 2.3210701394492914

Epoch: 360| Step: 0
Training loss: 1.148333174968943
Validation loss: 2.39679225833311

Epoch: 6| Step: 1
Training loss: 1.4774144858255742
Validation loss: 2.3263255430937697

Epoch: 6| Step: 2
Training loss: 2.126095657622518
Validation loss: 2.3599058690972576

Epoch: 6| Step: 3
Training loss: 1.4699113191078093
Validation loss: 2.4247630692960542

Epoch: 6| Step: 4
Training loss: 1.1619153285504586
Validation loss: 2.3568386403750887

Epoch: 6| Step: 5
Training loss: 1.2732283063501406
Validation loss: 2.4219974747518753

Epoch: 6| Step: 6
Training loss: 1.4638828228401164
Validation loss: 2.417695731956793

Epoch: 6| Step: 7
Training loss: 0.8588548993781677
Validation loss: 2.378810689163162

Epoch: 6| Step: 8
Training loss: 1.3406601801171076
Validation loss: 2.473418957256082

Epoch: 6| Step: 9
Training loss: 1.4263577066686488
Validation loss: 2.4345768864678154

Epoch: 6| Step: 10
Training loss: 1.217819053939635
Validation loss: 2.4029403307264827

Epoch: 6| Step: 11
Training loss: 1.5226865042219855
Validation loss: 2.4840233738991935

Epoch: 6| Step: 12
Training loss: 0.9441806543250656
Validation loss: 2.3836558366089475

Epoch: 6| Step: 13
Training loss: 1.3350143812597943
Validation loss: 2.4298597800390263

Epoch: 361| Step: 0
Training loss: 1.332222843654326
Validation loss: 2.442252137881415

Epoch: 6| Step: 1
Training loss: 0.924787801167441
Validation loss: 2.373630915435717

Epoch: 6| Step: 2
Training loss: 1.5093289196491297
Validation loss: 2.3133196089188717

Epoch: 6| Step: 3
Training loss: 1.665242381281334
Validation loss: 2.43261287193495

Epoch: 6| Step: 4
Training loss: 1.174701740069995
Validation loss: 2.322888239005969

Epoch: 6| Step: 5
Training loss: 0.9700491408062369
Validation loss: 2.408428905478554

Epoch: 6| Step: 6
Training loss: 1.5483129734196726
Validation loss: 2.3311266426075443

Epoch: 6| Step: 7
Training loss: 1.399553503634907
Validation loss: 2.415666174373536

Epoch: 6| Step: 8
Training loss: 1.1444349541368366
Validation loss: 2.305177953226577

Epoch: 6| Step: 9
Training loss: 1.0161084125041033
Validation loss: 2.377709310874694

Epoch: 6| Step: 10
Training loss: 1.7620008965878582
Validation loss: 2.3182198697726943

Epoch: 6| Step: 11
Training loss: 1.4554878630844648
Validation loss: 2.3525147956443115

Epoch: 6| Step: 12
Training loss: 2.0290299240921335
Validation loss: 2.3850049881046576

Epoch: 6| Step: 13
Training loss: 0.9518573648643844
Validation loss: 2.32443788659928

Epoch: 362| Step: 0
Training loss: 0.9494697960945526
Validation loss: 2.4205688733538184

Epoch: 6| Step: 1
Training loss: 1.6233786784320061
Validation loss: 2.3712201569036444

Epoch: 6| Step: 2
Training loss: 1.4735507828498653
Validation loss: 2.426112430277559

Epoch: 6| Step: 3
Training loss: 1.2890982882993687
Validation loss: 2.374459081469637

Epoch: 6| Step: 4
Training loss: 1.2779086202627883
Validation loss: 2.331184547765956

Epoch: 6| Step: 5
Training loss: 2.065517414655849
Validation loss: 2.3866589482672387

Epoch: 6| Step: 6
Training loss: 0.9205759561894087
Validation loss: 2.3971712351125642

Epoch: 6| Step: 7
Training loss: 1.2547548933919923
Validation loss: 2.2817278597642345

Epoch: 6| Step: 8
Training loss: 1.6748117341096294
Validation loss: 2.3691981134259574

Epoch: 6| Step: 9
Training loss: 1.059141573324818
Validation loss: 2.3883321115948504

Epoch: 6| Step: 10
Training loss: 1.2762589354020137
Validation loss: 2.360591453954566

Epoch: 6| Step: 11
Training loss: 1.1556064773816415
Validation loss: 2.328043946526733

Epoch: 6| Step: 12
Training loss: 1.0549768121711254
Validation loss: 2.4277782421537597

Epoch: 6| Step: 13
Training loss: 1.1905176069230554
Validation loss: 2.371100464279351

Epoch: 363| Step: 0
Training loss: 1.6245360078821773
Validation loss: 2.4260153230570505

Epoch: 6| Step: 1
Training loss: 1.2879474788169423
Validation loss: 2.377424389773496

Epoch: 6| Step: 2
Training loss: 1.0498906441917428
Validation loss: 2.425381436936839

Epoch: 6| Step: 3
Training loss: 1.2716453438633972
Validation loss: 2.41043901548961

Epoch: 6| Step: 4
Training loss: 1.411656815015217
Validation loss: 2.419022638730175

Epoch: 6| Step: 5
Training loss: 1.447516909881014
Validation loss: 2.4334129005967218

Epoch: 6| Step: 6
Training loss: 1.1561685997430475
Validation loss: 2.398671400577552

Epoch: 6| Step: 7
Training loss: 1.0700258859729617
Validation loss: 2.4004405379175906

Epoch: 6| Step: 8
Training loss: 2.2077811528468954
Validation loss: 2.4612700675644104

Epoch: 6| Step: 9
Training loss: 1.0717884106596909
Validation loss: 2.350795178180653

Epoch: 6| Step: 10
Training loss: 0.9700197389403312
Validation loss: 2.346799528876527

Epoch: 6| Step: 11
Training loss: 1.2731642634723699
Validation loss: 2.35391316821803

Epoch: 6| Step: 12
Training loss: 1.0911757556876047
Validation loss: 2.358270141016986

Epoch: 6| Step: 13
Training loss: 0.7964174415560926
Validation loss: 2.42588016524394

Epoch: 364| Step: 0
Training loss: 1.2419619565410855
Validation loss: 2.317436656581593

Epoch: 6| Step: 1
Training loss: 1.3191113397286247
Validation loss: 2.3737240414806924

Epoch: 6| Step: 2
Training loss: 1.3240407188268
Validation loss: 2.343802913492328

Epoch: 6| Step: 3
Training loss: 0.9864983137998946
Validation loss: 2.342087002682281

Epoch: 6| Step: 4
Training loss: 1.4812676279813741
Validation loss: 2.4272763867640634

Epoch: 6| Step: 5
Training loss: 1.3865477550548808
Validation loss: 2.3415069872757464

Epoch: 6| Step: 6
Training loss: 1.6561200072899738
Validation loss: 2.41996246729985

Epoch: 6| Step: 7
Training loss: 1.3203836455729758
Validation loss: 2.3771238022487444

Epoch: 6| Step: 8
Training loss: 1.370787714089937
Validation loss: 2.3625307580183024

Epoch: 6| Step: 9
Training loss: 0.8811304051837793
Validation loss: 2.386716978762825

Epoch: 6| Step: 10
Training loss: 1.0073076506605236
Validation loss: 2.3749367727640314

Epoch: 6| Step: 11
Training loss: 1.006027237301599
Validation loss: 2.364420750554173

Epoch: 6| Step: 12
Training loss: 1.2781811690171616
Validation loss: 2.4196121907684374

Epoch: 6| Step: 13
Training loss: 2.5640025502041945
Validation loss: 2.358927439204827

Epoch: 365| Step: 0
Training loss: 1.2159364943547968
Validation loss: 2.4384785064061743

Epoch: 6| Step: 1
Training loss: 1.0272172044916072
Validation loss: 2.3934757405090403

Epoch: 6| Step: 2
Training loss: 1.188022950117719
Validation loss: 2.34058462910668

Epoch: 6| Step: 3
Training loss: 1.1828460849846651
Validation loss: 2.3280836664508455

Epoch: 6| Step: 4
Training loss: 1.1790627347256901
Validation loss: 2.4095690928402926

Epoch: 6| Step: 5
Training loss: 1.6925187537817938
Validation loss: 2.3723014322073035

Epoch: 6| Step: 6
Training loss: 1.6348733991785274
Validation loss: 2.3816831842034842

Epoch: 6| Step: 7
Training loss: 1.1199229969222613
Validation loss: 2.4271775759506475

Epoch: 6| Step: 8
Training loss: 1.056624886612371
Validation loss: 2.4333421253827106

Epoch: 6| Step: 9
Training loss: 1.3832102920014742
Validation loss: 2.39173566527123

Epoch: 6| Step: 10
Training loss: 1.1554444058364026
Validation loss: 2.4412485720671326

Epoch: 6| Step: 11
Training loss: 1.161709448976616
Validation loss: 2.4652022600968304

Epoch: 6| Step: 12
Training loss: 0.9500077975103707
Validation loss: 2.343534034978819

Epoch: 6| Step: 13
Training loss: 2.54551182874405
Validation loss: 2.3770620669758986

Epoch: 366| Step: 0
Training loss: 1.0963905068700146
Validation loss: 2.355939192553746

Epoch: 6| Step: 1
Training loss: 1.3662781225103977
Validation loss: 2.38180215988349

Epoch: 6| Step: 2
Training loss: 1.48209229676878
Validation loss: 2.4096523873832707

Epoch: 6| Step: 3
Training loss: 1.143425312753989
Validation loss: 2.365729206427946

Epoch: 6| Step: 4
Training loss: 1.2199930551987894
Validation loss: 2.4842876373303873

Epoch: 6| Step: 5
Training loss: 1.168230314533397
Validation loss: 2.384438118714539

Epoch: 6| Step: 6
Training loss: 1.2887499343620454
Validation loss: 2.3824428024771596

Epoch: 6| Step: 7
Training loss: 1.281951526159856
Validation loss: 2.329837390378769

Epoch: 6| Step: 8
Training loss: 1.1313593521797787
Validation loss: 2.349823834674345

Epoch: 6| Step: 9
Training loss: 1.3984779053716738
Validation loss: 2.3919107474300683

Epoch: 6| Step: 10
Training loss: 1.2329992522727018
Validation loss: 2.395706521878534

Epoch: 6| Step: 11
Training loss: 1.2345650442113902
Validation loss: 2.40080045371488

Epoch: 6| Step: 12
Training loss: 2.1375045865550666
Validation loss: 2.4380041694321797

Epoch: 6| Step: 13
Training loss: 1.1309664713428766
Validation loss: 2.365788639970779

Epoch: 367| Step: 0
Training loss: 1.068948642496212
Validation loss: 2.393923109134221

Epoch: 6| Step: 1
Training loss: 1.1690472882628933
Validation loss: 2.440402836894364

Epoch: 6| Step: 2
Training loss: 1.5142674609521067
Validation loss: 2.4338725801731647

Epoch: 6| Step: 3
Training loss: 0.8946443844345192
Validation loss: 2.3931649880895414

Epoch: 6| Step: 4
Training loss: 2.3329665259009014
Validation loss: 2.385892635078662

Epoch: 6| Step: 5
Training loss: 1.3992597411012409
Validation loss: 2.436556826883106

Epoch: 6| Step: 6
Training loss: 1.2312075864196252
Validation loss: 2.452760068232211

Epoch: 6| Step: 7
Training loss: 0.8098918060169893
Validation loss: 2.3764632606658256

Epoch: 6| Step: 8
Training loss: 1.6597787944067441
Validation loss: 2.435745522856717

Epoch: 6| Step: 9
Training loss: 1.3643075746869118
Validation loss: 2.4002798463345685

Epoch: 6| Step: 10
Training loss: 1.1422174911631937
Validation loss: 2.3982360793746955

Epoch: 6| Step: 11
Training loss: 0.9358825081541532
Validation loss: 2.4082108791334167

Epoch: 6| Step: 12
Training loss: 1.5339239479171627
Validation loss: 2.3662102148473667

Epoch: 6| Step: 13
Training loss: 1.2423692006548532
Validation loss: 2.446265816291021

Epoch: 368| Step: 0
Training loss: 1.2388425210839322
Validation loss: 2.344341555085987

Epoch: 6| Step: 1
Training loss: 1.0414691101928861
Validation loss: 2.5104521606479593

Epoch: 6| Step: 2
Training loss: 1.348155584293471
Validation loss: 2.3837360993352172

Epoch: 6| Step: 3
Training loss: 1.2674671001039381
Validation loss: 2.3687053773946407

Epoch: 6| Step: 4
Training loss: 1.6322759449422184
Validation loss: 2.4543217648341695

Epoch: 6| Step: 5
Training loss: 1.875049081795745
Validation loss: 2.4351547871232126

Epoch: 6| Step: 6
Training loss: 1.1521634235561762
Validation loss: 2.365090654065673

Epoch: 6| Step: 7
Training loss: 1.3626188838784037
Validation loss: 2.423813486894164

Epoch: 6| Step: 8
Training loss: 1.164827799288085
Validation loss: 2.344998327628496

Epoch: 6| Step: 9
Training loss: 0.953760810530804
Validation loss: 2.3899135304352486

Epoch: 6| Step: 10
Training loss: 1.590630114234242
Validation loss: 2.358053857666947

Epoch: 6| Step: 11
Training loss: 1.4072840809235272
Validation loss: 2.3781996062943245

Epoch: 6| Step: 12
Training loss: 1.1313619336975398
Validation loss: 2.363164292616705

Epoch: 6| Step: 13
Training loss: 0.9775948217992325
Validation loss: 2.3700198325455832

Epoch: 369| Step: 0
Training loss: 1.839269593018713
Validation loss: 2.372030574753638

Epoch: 6| Step: 1
Training loss: 0.7073936587372203
Validation loss: 2.421550830392034

Epoch: 6| Step: 2
Training loss: 1.0214113169231205
Validation loss: 2.3482790856790703

Epoch: 6| Step: 3
Training loss: 1.2277674496668438
Validation loss: 2.444402026233822

Epoch: 6| Step: 4
Training loss: 1.180546933809599
Validation loss: 2.3482742690479665

Epoch: 6| Step: 5
Training loss: 0.9956457589206991
Validation loss: 2.386149910131998

Epoch: 6| Step: 6
Training loss: 1.640706232875476
Validation loss: 2.422774592324774

Epoch: 6| Step: 7
Training loss: 1.28946258809553
Validation loss: 2.3714906826161033

Epoch: 6| Step: 8
Training loss: 1.0167484818562826
Validation loss: 2.440940599494345

Epoch: 6| Step: 9
Training loss: 1.3577188949014176
Validation loss: 2.395705874469187

Epoch: 6| Step: 10
Training loss: 1.5058515377805541
Validation loss: 2.3535046869560845

Epoch: 6| Step: 11
Training loss: 1.934780612011817
Validation loss: 2.371236098922274

Epoch: 6| Step: 12
Training loss: 0.9528024471624674
Validation loss: 2.447745482970505

Epoch: 6| Step: 13
Training loss: 1.5684466308036111
Validation loss: 2.3467387350118623

Epoch: 370| Step: 0
Training loss: 1.0929145892277785
Validation loss: 2.338238379069678

Epoch: 6| Step: 1
Training loss: 1.228218709850318
Validation loss: 2.415632570524398

Epoch: 6| Step: 2
Training loss: 1.3229963123446025
Validation loss: 2.4145865804193565

Epoch: 6| Step: 3
Training loss: 1.6722103745106636
Validation loss: 2.4181168882732185

Epoch: 6| Step: 4
Training loss: 1.157625977682482
Validation loss: 2.301288585223169

Epoch: 6| Step: 5
Training loss: 1.4301637783829715
Validation loss: 2.300310435440488

Epoch: 6| Step: 6
Training loss: 1.5705718020907102
Validation loss: 2.406231792089673

Epoch: 6| Step: 7
Training loss: 1.4273931719195072
Validation loss: 2.401241812437539

Epoch: 6| Step: 8
Training loss: 2.2775587762310354
Validation loss: 2.401039820933676

Epoch: 6| Step: 9
Training loss: 1.1992269509497935
Validation loss: 2.3709421790044334

Epoch: 6| Step: 10
Training loss: 1.1979661793082297
Validation loss: 2.3582060738658637

Epoch: 6| Step: 11
Training loss: 1.0888039061628312
Validation loss: 2.3520500678712484

Epoch: 6| Step: 12
Training loss: 0.9400875621960127
Validation loss: 2.4376903787734725

Epoch: 6| Step: 13
Training loss: 1.4570504767655277
Validation loss: 2.3630155029690965

Epoch: 371| Step: 0
Training loss: 0.9446873449892654
Validation loss: 2.4233458922607274

Epoch: 6| Step: 1
Training loss: 1.4437760718167263
Validation loss: 2.3588166228426166

Epoch: 6| Step: 2
Training loss: 1.2383647132447062
Validation loss: 2.3891574173392343

Epoch: 6| Step: 3
Training loss: 1.2398556108394156
Validation loss: 2.4219783341469507

Epoch: 6| Step: 4
Training loss: 1.3934047219971868
Validation loss: 2.362822444336664

Epoch: 6| Step: 5
Training loss: 1.0553948185212139
Validation loss: 2.4293352134210546

Epoch: 6| Step: 6
Training loss: 1.221719791476797
Validation loss: 2.3718382758547474

Epoch: 6| Step: 7
Training loss: 1.0509801059585893
Validation loss: 2.4572010036094634

Epoch: 6| Step: 8
Training loss: 1.88643124366266
Validation loss: 2.361773837657209

Epoch: 6| Step: 9
Training loss: 1.2406543411129123
Validation loss: 2.258734290253374

Epoch: 6| Step: 10
Training loss: 1.4322648294419904
Validation loss: 2.4117393222748076

Epoch: 6| Step: 11
Training loss: 1.2587583314682411
Validation loss: 2.349464656792767

Epoch: 6| Step: 12
Training loss: 1.0933933221440397
Validation loss: 2.37443059735153

Epoch: 6| Step: 13
Training loss: 1.2987712187956633
Validation loss: 2.3682869068925703

Epoch: 372| Step: 0
Training loss: 1.0792399736247522
Validation loss: 2.301388369253365

Epoch: 6| Step: 1
Training loss: 1.4208318216235638
Validation loss: 2.405808022389231

Epoch: 6| Step: 2
Training loss: 1.4265418963077765
Validation loss: 2.4280931031545157

Epoch: 6| Step: 3
Training loss: 1.0907242475674441
Validation loss: 2.3664913723584777

Epoch: 6| Step: 4
Training loss: 1.1443130753917978
Validation loss: 2.454757305165854

Epoch: 6| Step: 5
Training loss: 1.3409013938976788
Validation loss: 2.3278168472075595

Epoch: 6| Step: 6
Training loss: 1.5388782991273697
Validation loss: 2.381861069664682

Epoch: 6| Step: 7
Training loss: 1.030899855385183
Validation loss: 2.351481549021815

Epoch: 6| Step: 8
Training loss: 0.9382578647567485
Validation loss: 2.3720934276996073

Epoch: 6| Step: 9
Training loss: 1.5637080291067667
Validation loss: 2.331341399362087

Epoch: 6| Step: 10
Training loss: 1.8607458622907058
Validation loss: 2.3699909716426775

Epoch: 6| Step: 11
Training loss: 1.1130370825993225
Validation loss: 2.2947242483112325

Epoch: 6| Step: 12
Training loss: 1.4317359632360507
Validation loss: 2.3985523665208146

Epoch: 6| Step: 13
Training loss: 1.481954428009437
Validation loss: 2.3459567339959784

Epoch: 373| Step: 0
Training loss: 1.4672457519927338
Validation loss: 2.4072055227247997

Epoch: 6| Step: 1
Training loss: 1.5050225412702114
Validation loss: 2.347055204507892

Epoch: 6| Step: 2
Training loss: 1.1927627095760855
Validation loss: 2.376729056241259

Epoch: 6| Step: 3
Training loss: 1.0027946522409203
Validation loss: 2.338984695617879

Epoch: 6| Step: 4
Training loss: 1.3171018126865894
Validation loss: 2.39478936654622

Epoch: 6| Step: 5
Training loss: 1.0899187834693584
Validation loss: 2.326204630958969

Epoch: 6| Step: 6
Training loss: 1.0894238609960178
Validation loss: 2.3943210892261626

Epoch: 6| Step: 7
Training loss: 1.3403211805116342
Validation loss: 2.3545089837245095

Epoch: 6| Step: 8
Training loss: 1.0881093214593731
Validation loss: 2.35997684948848

Epoch: 6| Step: 9
Training loss: 2.0755161746430293
Validation loss: 2.412197416426794

Epoch: 6| Step: 10
Training loss: 1.520018276430979
Validation loss: 2.446788090098663

Epoch: 6| Step: 11
Training loss: 1.3234137054430086
Validation loss: 2.4069295412932528

Epoch: 6| Step: 12
Training loss: 1.2460686851539677
Validation loss: 2.369786831376314

Epoch: 6| Step: 13
Training loss: 0.8596062089098486
Validation loss: 2.3739232805302017

Epoch: 374| Step: 0
Training loss: 1.257341758827898
Validation loss: 2.4342294632771346

Epoch: 6| Step: 1
Training loss: 1.2120096689977933
Validation loss: 2.438576480844588

Epoch: 6| Step: 2
Training loss: 0.7676929650047349
Validation loss: 2.405409690838704

Epoch: 6| Step: 3
Training loss: 1.235193681240226
Validation loss: 2.434046791603177

Epoch: 6| Step: 4
Training loss: 1.2559771682765797
Validation loss: 2.351892611330258

Epoch: 6| Step: 5
Training loss: 1.1979171200074155
Validation loss: 2.3878986426996978

Epoch: 6| Step: 6
Training loss: 1.1966935201959572
Validation loss: 2.332749992250606

Epoch: 6| Step: 7
Training loss: 1.3531413475969678
Validation loss: 2.3906040178665418

Epoch: 6| Step: 8
Training loss: 1.1815844309662475
Validation loss: 2.35758531703596

Epoch: 6| Step: 9
Training loss: 2.1939288900530425
Validation loss: 2.31662448005247

Epoch: 6| Step: 10
Training loss: 1.292541341065123
Validation loss: 2.280496742919211

Epoch: 6| Step: 11
Training loss: 1.3549133394125674
Validation loss: 2.357606214615794

Epoch: 6| Step: 12
Training loss: 0.7856426725015885
Validation loss: 2.37266906380203

Epoch: 6| Step: 13
Training loss: 1.7803173635214473
Validation loss: 2.4488199599559297

Epoch: 375| Step: 0
Training loss: 0.8288428955603001
Validation loss: 2.3658757611721066

Epoch: 6| Step: 1
Training loss: 1.2997702028671185
Validation loss: 2.4150666557986007

Epoch: 6| Step: 2
Training loss: 1.517248640782968
Validation loss: 2.39835874473555

Epoch: 6| Step: 3
Training loss: 0.9873303448732504
Validation loss: 2.380902647884854

Epoch: 6| Step: 4
Training loss: 1.105470367538293
Validation loss: 2.342958589334773

Epoch: 6| Step: 5
Training loss: 1.5025726350311028
Validation loss: 2.3530518580829067

Epoch: 6| Step: 6
Training loss: 1.0241861880878267
Validation loss: 2.38377878980075

Epoch: 6| Step: 7
Training loss: 1.6957267571529078
Validation loss: 2.412148677802488

Epoch: 6| Step: 8
Training loss: 1.0960076056933505
Validation loss: 2.4161578382834037

Epoch: 6| Step: 9
Training loss: 1.399111622554449
Validation loss: 2.3588527445601537

Epoch: 6| Step: 10
Training loss: 0.9042028786106945
Validation loss: 2.3443029100161414

Epoch: 6| Step: 11
Training loss: 1.1219368665207932
Validation loss: 2.434860527375287

Epoch: 6| Step: 12
Training loss: 2.060304687151914
Validation loss: 2.414217740987895

Epoch: 6| Step: 13
Training loss: 1.4603707749379844
Validation loss: 2.4279176958313102

Epoch: 376| Step: 0
Training loss: 1.253803189519518
Validation loss: 2.3711533345104248

Epoch: 6| Step: 1
Training loss: 1.333566535980429
Validation loss: 2.383937415903774

Epoch: 6| Step: 2
Training loss: 1.0573179996512283
Validation loss: 2.3573387229136107

Epoch: 6| Step: 3
Training loss: 1.23405606942181
Validation loss: 2.4089314361835075

Epoch: 6| Step: 4
Training loss: 1.199641348966391
Validation loss: 2.426412417225039

Epoch: 6| Step: 5
Training loss: 0.669731090727255
Validation loss: 2.3364775664355393

Epoch: 6| Step: 6
Training loss: 1.2102397754428773
Validation loss: 2.4609376979293263

Epoch: 6| Step: 7
Training loss: 1.1106634046003683
Validation loss: 2.346069588189374

Epoch: 6| Step: 8
Training loss: 1.3908580627589493
Validation loss: 2.4485322707517385

Epoch: 6| Step: 9
Training loss: 1.1456585432886903
Validation loss: 2.3729946800361645

Epoch: 6| Step: 10
Training loss: 1.2612979529709953
Validation loss: 2.378056351447816

Epoch: 6| Step: 11
Training loss: 1.0799234289823074
Validation loss: 2.470369978057391

Epoch: 6| Step: 12
Training loss: 1.7572467486918175
Validation loss: 2.4435160008076657

Epoch: 6| Step: 13
Training loss: 2.3772900232116547
Validation loss: 2.434235659027738

Epoch: 377| Step: 0
Training loss: 0.9930564799597171
Validation loss: 2.497682177854186

Epoch: 6| Step: 1
Training loss: 1.4745803526997072
Validation loss: 2.4489986022881385

Epoch: 6| Step: 2
Training loss: 1.1462437443786115
Validation loss: 2.386289947644144

Epoch: 6| Step: 3
Training loss: 1.2238918313431506
Validation loss: 2.376783113945596

Epoch: 6| Step: 4
Training loss: 1.2031615610884052
Validation loss: 2.3484260056484096

Epoch: 6| Step: 5
Training loss: 1.194073951664281
Validation loss: 2.380892396111199

Epoch: 6| Step: 6
Training loss: 1.4578076459634153
Validation loss: 2.4438689517509036

Epoch: 6| Step: 7
Training loss: 0.9272691704729444
Validation loss: 2.418307441868574

Epoch: 6| Step: 8
Training loss: 2.0663295219613103
Validation loss: 2.398793601761694

Epoch: 6| Step: 9
Training loss: 1.4310539677731233
Validation loss: 2.3606840263350435

Epoch: 6| Step: 10
Training loss: 1.3318247704989479
Validation loss: 2.457530002169043

Epoch: 6| Step: 11
Training loss: 1.4579108398239655
Validation loss: 2.3715157157791267

Epoch: 6| Step: 12
Training loss: 1.0193491806044195
Validation loss: 2.3722884648459623

Epoch: 6| Step: 13
Training loss: 1.5679788282191212
Validation loss: 2.442238521614409

Epoch: 378| Step: 0
Training loss: 1.2254400280426216
Validation loss: 2.3715098685695977

Epoch: 6| Step: 1
Training loss: 1.0411936766925947
Validation loss: 2.3491720703473993

Epoch: 6| Step: 2
Training loss: 1.4965916693969825
Validation loss: 2.402959122616156

Epoch: 6| Step: 3
Training loss: 1.3040410798921422
Validation loss: 2.3627062226878195

Epoch: 6| Step: 4
Training loss: 1.2502865939613563
Validation loss: 2.4105072779014

Epoch: 6| Step: 5
Training loss: 1.3787404249728612
Validation loss: 2.4162534233837047

Epoch: 6| Step: 6
Training loss: 0.8131937952868828
Validation loss: 2.414266301391969

Epoch: 6| Step: 7
Training loss: 1.1567123107442363
Validation loss: 2.413382118166896

Epoch: 6| Step: 8
Training loss: 1.411710648547741
Validation loss: 2.367097781233635

Epoch: 6| Step: 9
Training loss: 1.0811337491203106
Validation loss: 2.424964904150612

Epoch: 6| Step: 10
Training loss: 2.145751717012197
Validation loss: 2.450528377541267

Epoch: 6| Step: 11
Training loss: 0.8846235013752084
Validation loss: 2.4005490163029775

Epoch: 6| Step: 12
Training loss: 1.4775494703088905
Validation loss: 2.4357150294161176

Epoch: 6| Step: 13
Training loss: 0.939891530484766
Validation loss: 2.3920048632102984

Epoch: 379| Step: 0
Training loss: 1.1559371009366022
Validation loss: 2.4600597529253787

Epoch: 6| Step: 1
Training loss: 0.9752621347219548
Validation loss: 2.3749207492595716

Epoch: 6| Step: 2
Training loss: 2.1532414774401074
Validation loss: 2.3959030918774875

Epoch: 6| Step: 3
Training loss: 0.814129808685519
Validation loss: 2.419694209890297

Epoch: 6| Step: 4
Training loss: 0.9025973669560184
Validation loss: 2.41100424069782

Epoch: 6| Step: 5
Training loss: 0.7882450893187433
Validation loss: 2.4091984775429527

Epoch: 6| Step: 6
Training loss: 1.4119539082949821
Validation loss: 2.336022979371891

Epoch: 6| Step: 7
Training loss: 0.9707968530363419
Validation loss: 2.45752837689756

Epoch: 6| Step: 8
Training loss: 1.3028398782768145
Validation loss: 2.343069499226095

Epoch: 6| Step: 9
Training loss: 1.4783722620285793
Validation loss: 2.3232857269214424

Epoch: 6| Step: 10
Training loss: 1.6769324130119432
Validation loss: 2.4164672708482975

Epoch: 6| Step: 11
Training loss: 0.8315684862863933
Validation loss: 2.364991250485802

Epoch: 6| Step: 12
Training loss: 1.7128205410094004
Validation loss: 2.402338896635702

Epoch: 6| Step: 13
Training loss: 1.8849435989077319
Validation loss: 2.416231882901372

Epoch: 380| Step: 0
Training loss: 0.9327533402844496
Validation loss: 2.3685886856819978

Epoch: 6| Step: 1
Training loss: 2.3011967489451997
Validation loss: 2.4518945922555604

Epoch: 6| Step: 2
Training loss: 1.1634148966078997
Validation loss: 2.384833474200314

Epoch: 6| Step: 3
Training loss: 1.378343202439524
Validation loss: 2.4077863695985133

Epoch: 6| Step: 4
Training loss: 0.9690356294953165
Validation loss: 2.454827614385461

Epoch: 6| Step: 5
Training loss: 1.1070967908583778
Validation loss: 2.368540155883034

Epoch: 6| Step: 6
Training loss: 0.9479136344665545
Validation loss: 2.3605285554005144

Epoch: 6| Step: 7
Training loss: 1.2732440825002196
Validation loss: 2.396115858229307

Epoch: 6| Step: 8
Training loss: 0.9172187500914977
Validation loss: 2.318904367256191

Epoch: 6| Step: 9
Training loss: 0.9371849802357939
Validation loss: 2.3827963508584555

Epoch: 6| Step: 10
Training loss: 1.1615673179413655
Validation loss: 2.4573147173615117

Epoch: 6| Step: 11
Training loss: 1.0499988465075742
Validation loss: 2.3999055756688072

Epoch: 6| Step: 12
Training loss: 1.603366041001863
Validation loss: 2.405287921178722

Epoch: 6| Step: 13
Training loss: 1.026783257238635
Validation loss: 2.423529395894438

Epoch: 381| Step: 0
Training loss: 0.7362402096989565
Validation loss: 2.342369635664899

Epoch: 6| Step: 1
Training loss: 1.349510664028167
Validation loss: 2.2959290164280315

Epoch: 6| Step: 2
Training loss: 1.2196344931849676
Validation loss: 2.391930050400128

Epoch: 6| Step: 3
Training loss: 1.0746948296956151
Validation loss: 2.4380324060710645

Epoch: 6| Step: 4
Training loss: 1.2303264717314473
Validation loss: 2.3984130546016424

Epoch: 6| Step: 5
Training loss: 1.3166805174054794
Validation loss: 2.3676248955378947

Epoch: 6| Step: 6
Training loss: 1.920083986968682
Validation loss: 2.3779289010275644

Epoch: 6| Step: 7
Training loss: 1.1849495452891576
Validation loss: 2.375812977503117

Epoch: 6| Step: 8
Training loss: 1.4609277082308891
Validation loss: 2.3049397470439197

Epoch: 6| Step: 9
Training loss: 1.4598276747290364
Validation loss: 2.430923362322255

Epoch: 6| Step: 10
Training loss: 1.2905323318575563
Validation loss: 2.384491973696929

Epoch: 6| Step: 11
Training loss: 1.058010095259704
Validation loss: 2.3828644067526064

Epoch: 6| Step: 12
Training loss: 0.8337495638547383
Validation loss: 2.4018441541905187

Epoch: 6| Step: 13
Training loss: 1.375481347881443
Validation loss: 2.3761570227300255

Epoch: 382| Step: 0
Training loss: 1.3746770999807285
Validation loss: 2.362033371277893

Epoch: 6| Step: 1
Training loss: 1.2739588132635393
Validation loss: 2.419689571440771

Epoch: 6| Step: 2
Training loss: 1.5098673205157873
Validation loss: 2.4215191693849256

Epoch: 6| Step: 3
Training loss: 1.8103698183004107
Validation loss: 2.427126149495221

Epoch: 6| Step: 4
Training loss: 1.0883071074799362
Validation loss: 2.3861902206689707

Epoch: 6| Step: 5
Training loss: 1.145884680319988
Validation loss: 2.2774688776947762

Epoch: 6| Step: 6
Training loss: 1.0482268074830692
Validation loss: 2.4330187478902108

Epoch: 6| Step: 7
Training loss: 1.4243785908659212
Validation loss: 2.3922365673333963

Epoch: 6| Step: 8
Training loss: 1.3419934702059162
Validation loss: 2.4083546771100672

Epoch: 6| Step: 9
Training loss: 1.1952772945629926
Validation loss: 2.393066002377964

Epoch: 6| Step: 10
Training loss: 1.5684977051192506
Validation loss: 2.3335817932826473

Epoch: 6| Step: 11
Training loss: 0.7053520114498185
Validation loss: 2.387195110304914

Epoch: 6| Step: 12
Training loss: 0.9767897684765833
Validation loss: 2.3820535721751335

Epoch: 6| Step: 13
Training loss: 1.0137496065828098
Validation loss: 2.3777955489513123

Epoch: 383| Step: 0
Training loss: 1.322625566229155
Validation loss: 2.3708623725339186

Epoch: 6| Step: 1
Training loss: 1.264008561198902
Validation loss: 2.4472486985788477

Epoch: 6| Step: 2
Training loss: 0.7888275778776955
Validation loss: 2.3794584012207047

Epoch: 6| Step: 3
Training loss: 2.1111072350628164
Validation loss: 2.4120065905741255

Epoch: 6| Step: 4
Training loss: 1.4289774147528642
Validation loss: 2.479672161618592

Epoch: 6| Step: 5
Training loss: 1.071970469947011
Validation loss: 2.4028778728291065

Epoch: 6| Step: 6
Training loss: 0.897045350594355
Validation loss: 2.4598905332173495

Epoch: 6| Step: 7
Training loss: 1.3230769543400387
Validation loss: 2.3840278881283785

Epoch: 6| Step: 8
Training loss: 1.1415519083546217
Validation loss: 2.317046671476827

Epoch: 6| Step: 9
Training loss: 1.3169113684268468
Validation loss: 2.3588982665266185

Epoch: 6| Step: 10
Training loss: 0.9705390407722329
Validation loss: 2.419783594190939

Epoch: 6| Step: 11
Training loss: 1.2902756040235663
Validation loss: 2.4465705743499515

Epoch: 6| Step: 12
Training loss: 0.9193948908766996
Validation loss: 2.3922081598630043

Epoch: 6| Step: 13
Training loss: 1.1197442096442107
Validation loss: 2.356080280344385

Epoch: 384| Step: 0
Training loss: 0.6709736611118715
Validation loss: 2.3747387269005436

Epoch: 6| Step: 1
Training loss: 1.1306685581536335
Validation loss: 2.3625361185285643

Epoch: 6| Step: 2
Training loss: 1.1371487462924357
Validation loss: 2.3529911658348692

Epoch: 6| Step: 3
Training loss: 1.1410250027697906
Validation loss: 2.373731170601907

Epoch: 6| Step: 4
Training loss: 1.3853301496906676
Validation loss: 2.3823871450094005

Epoch: 6| Step: 5
Training loss: 1.2565669177171472
Validation loss: 2.355233840168218

Epoch: 6| Step: 6
Training loss: 1.2895903460302194
Validation loss: 2.351081877249478

Epoch: 6| Step: 7
Training loss: 1.2666919120146694
Validation loss: 2.339402522399706

Epoch: 6| Step: 8
Training loss: 0.9860767006280416
Validation loss: 2.4029554451187116

Epoch: 6| Step: 9
Training loss: 0.892165374481512
Validation loss: 2.4055564423137543

Epoch: 6| Step: 10
Training loss: 2.2593090548988854
Validation loss: 2.4229704063692257

Epoch: 6| Step: 11
Training loss: 0.9212643815552358
Validation loss: 2.3578247342688985

Epoch: 6| Step: 12
Training loss: 1.3339082352676086
Validation loss: 2.3908117908862083

Epoch: 6| Step: 13
Training loss: 1.199519862043539
Validation loss: 2.382484296967263

Epoch: 385| Step: 0
Training loss: 1.0970214963282954
Validation loss: 2.3533212107521875

Epoch: 6| Step: 1
Training loss: 1.240293198039097
Validation loss: 2.3570917522328627

Epoch: 6| Step: 2
Training loss: 1.5398403467675879
Validation loss: 2.388241969881424

Epoch: 6| Step: 3
Training loss: 1.097587990589865
Validation loss: 2.38219529578404

Epoch: 6| Step: 4
Training loss: 0.833844103842797
Validation loss: 2.403505105063089

Epoch: 6| Step: 5
Training loss: 1.1879199439924228
Validation loss: 2.4031630170137364

Epoch: 6| Step: 6
Training loss: 1.1527633161799469
Validation loss: 2.3064979823857104

Epoch: 6| Step: 7
Training loss: 2.0981935633415825
Validation loss: 2.407102475650515

Epoch: 6| Step: 8
Training loss: 1.2194827395754717
Validation loss: 2.357616476305756

Epoch: 6| Step: 9
Training loss: 1.2944958016072217
Validation loss: 2.36028793960423

Epoch: 6| Step: 10
Training loss: 1.424261919247271
Validation loss: 2.4061985764151252

Epoch: 6| Step: 11
Training loss: 0.6240499905711172
Validation loss: 2.349451526834044

Epoch: 6| Step: 12
Training loss: 1.175034041621787
Validation loss: 2.3805084138086117

Epoch: 6| Step: 13
Training loss: 1.4983902877036637
Validation loss: 2.391960929469346

Epoch: 386| Step: 0
Training loss: 0.6871804448381846
Validation loss: 2.3729189340420938

Epoch: 6| Step: 1
Training loss: 1.4030381717451244
Validation loss: 2.3234272461982335

Epoch: 6| Step: 2
Training loss: 1.2728627317815677
Validation loss: 2.3867009999743494

Epoch: 6| Step: 3
Training loss: 1.152419679370811
Validation loss: 2.3518828241758025

Epoch: 6| Step: 4
Training loss: 1.838024235894576
Validation loss: 2.406408724739037

Epoch: 6| Step: 5
Training loss: 1.2515565717273378
Validation loss: 2.3205451526901126

Epoch: 6| Step: 6
Training loss: 1.4061782818626094
Validation loss: 2.4180235598333506

Epoch: 6| Step: 7
Training loss: 1.161314312454648
Validation loss: 2.3628413252712854

Epoch: 6| Step: 8
Training loss: 1.513963555566318
Validation loss: 2.453420386770656

Epoch: 6| Step: 9
Training loss: 1.2368044545785548
Validation loss: 2.3356073469753693

Epoch: 6| Step: 10
Training loss: 0.9977549743795974
Validation loss: 2.32988680225021

Epoch: 6| Step: 11
Training loss: 1.414134408376454
Validation loss: 2.344795719514103

Epoch: 6| Step: 12
Training loss: 1.3211565649077017
Validation loss: 2.3227950537523405

Epoch: 6| Step: 13
Training loss: 0.7057107639142132
Validation loss: 2.3422050711126405

Epoch: 387| Step: 0
Training loss: 1.0813012259812682
Validation loss: 2.3297142577648287

Epoch: 6| Step: 1
Training loss: 1.8493565806573524
Validation loss: 2.3727786962334285

Epoch: 6| Step: 2
Training loss: 1.1121202806662274
Validation loss: 2.317483920747675

Epoch: 6| Step: 3
Training loss: 1.2722342487573752
Validation loss: 2.387034183264738

Epoch: 6| Step: 4
Training loss: 1.0924986083766008
Validation loss: 2.3839875324259387

Epoch: 6| Step: 5
Training loss: 0.8853890956999085
Validation loss: 2.4675430144890655

Epoch: 6| Step: 6
Training loss: 1.1472311625826312
Validation loss: 2.440471596334949

Epoch: 6| Step: 7
Training loss: 1.5273727843507912
Validation loss: 2.480533639377052

Epoch: 6| Step: 8
Training loss: 1.359010230923416
Validation loss: 2.439038920714402

Epoch: 6| Step: 9
Training loss: 1.400404755801701
Validation loss: 2.3936238619802803

Epoch: 6| Step: 10
Training loss: 1.2771920863648594
Validation loss: 2.4475256117686572

Epoch: 6| Step: 11
Training loss: 1.1207259900807731
Validation loss: 2.4668891542690408

Epoch: 6| Step: 12
Training loss: 1.166116476889176
Validation loss: 2.398957060246199

Epoch: 6| Step: 13
Training loss: 0.7554392275323002
Validation loss: 2.398255833845172

Epoch: 388| Step: 0
Training loss: 0.8254347955932819
Validation loss: 2.4006889074694637

Epoch: 6| Step: 1
Training loss: 1.0042342900554233
Validation loss: 2.373792412553982

Epoch: 6| Step: 2
Training loss: 1.1239587945851726
Validation loss: 2.369182772314305

Epoch: 6| Step: 3
Training loss: 1.2155848753909266
Validation loss: 2.2892080936386288

Epoch: 6| Step: 4
Training loss: 1.4181063666701985
Validation loss: 2.3782727080715267

Epoch: 6| Step: 5
Training loss: 1.1059457134147714
Validation loss: 2.369416248902955

Epoch: 6| Step: 6
Training loss: 1.4401395861205943
Validation loss: 2.400953545391489

Epoch: 6| Step: 7
Training loss: 1.337763915361529
Validation loss: 2.3745887013772444

Epoch: 6| Step: 8
Training loss: 1.3694934254377418
Validation loss: 2.4392894805354683

Epoch: 6| Step: 9
Training loss: 1.4305399036888633
Validation loss: 2.3279545681627827

Epoch: 6| Step: 10
Training loss: 0.9785083458300391
Validation loss: 2.361483415192455

Epoch: 6| Step: 11
Training loss: 2.234368811111949
Validation loss: 2.3464623456421214

Epoch: 6| Step: 12
Training loss: 1.2080678099995583
Validation loss: 2.4073464854943945

Epoch: 6| Step: 13
Training loss: 0.5461574751928654
Validation loss: 2.3777216357203

Epoch: 389| Step: 0
Training loss: 1.9593302914813349
Validation loss: 2.3705138175236633

Epoch: 6| Step: 1
Training loss: 0.8283692845334019
Validation loss: 2.391805463652824

Epoch: 6| Step: 2
Training loss: 1.014285216245011
Validation loss: 2.3598226345214215

Epoch: 6| Step: 3
Training loss: 1.4551476788378466
Validation loss: 2.424101317460053

Epoch: 6| Step: 4
Training loss: 0.775082082400905
Validation loss: 2.387391333589358

Epoch: 6| Step: 5
Training loss: 0.9150817274897006
Validation loss: 2.3843216217460967

Epoch: 6| Step: 6
Training loss: 1.328712243793456
Validation loss: 2.447088180884194

Epoch: 6| Step: 7
Training loss: 1.3768266335683654
Validation loss: 2.375186092510397

Epoch: 6| Step: 8
Training loss: 0.977904839159048
Validation loss: 2.3999876962452324

Epoch: 6| Step: 9
Training loss: 1.6247757243397276
Validation loss: 2.431871871274715

Epoch: 6| Step: 10
Training loss: 0.9623809146285626
Validation loss: 2.380770598410809

Epoch: 6| Step: 11
Training loss: 0.9292935089524998
Validation loss: 2.404222142918496

Epoch: 6| Step: 12
Training loss: 1.5726715132630686
Validation loss: 2.4691179094051745

Epoch: 6| Step: 13
Training loss: 1.3227162346979677
Validation loss: 2.367153379609392

Epoch: 390| Step: 0
Training loss: 1.4103043074299102
Validation loss: 2.436314150538623

Epoch: 6| Step: 1
Training loss: 0.9694968082971549
Validation loss: 2.437503496014507

Epoch: 6| Step: 2
Training loss: 1.4065798054825343
Validation loss: 2.382005619130233

Epoch: 6| Step: 3
Training loss: 1.1250623049967108
Validation loss: 2.3349627260391266

Epoch: 6| Step: 4
Training loss: 1.3871956448488827
Validation loss: 2.436571206672155

Epoch: 6| Step: 5
Training loss: 1.0501750346023286
Validation loss: 2.3720061371356644

Epoch: 6| Step: 6
Training loss: 1.0118303274245004
Validation loss: 2.42938713868459

Epoch: 6| Step: 7
Training loss: 1.952557290539603
Validation loss: 2.3447460396131663

Epoch: 6| Step: 8
Training loss: 1.100873366346779
Validation loss: 2.3859922584508704

Epoch: 6| Step: 9
Training loss: 1.4720061711461865
Validation loss: 2.409421616455181

Epoch: 6| Step: 10
Training loss: 1.1036083081238606
Validation loss: 2.4567353196095705

Epoch: 6| Step: 11
Training loss: 1.5626864512778385
Validation loss: 2.321851682570034

Epoch: 6| Step: 12
Training loss: 1.1676822170543766
Validation loss: 2.365069258958618

Epoch: 6| Step: 13
Training loss: 1.0944261912993056
Validation loss: 2.407570631940884

Epoch: 391| Step: 0
Training loss: 1.391645035984872
Validation loss: 2.3284833287797935

Epoch: 6| Step: 1
Training loss: 0.9636997746146598
Validation loss: 2.3349340850938027

Epoch: 6| Step: 2
Training loss: 0.821955534031636
Validation loss: 2.4011987737036105

Epoch: 6| Step: 3
Training loss: 1.1207266282880959
Validation loss: 2.324373624237556

Epoch: 6| Step: 4
Training loss: 1.0011809052094705
Validation loss: 2.43994630722414

Epoch: 6| Step: 5
Training loss: 1.3432419725892109
Validation loss: 2.4105515712852927

Epoch: 6| Step: 6
Training loss: 1.4317010760067264
Validation loss: 2.381698752106712

Epoch: 6| Step: 7
Training loss: 1.412275755644874
Validation loss: 2.3988303066970147

Epoch: 6| Step: 8
Training loss: 1.205993107138653
Validation loss: 2.2651745622481516

Epoch: 6| Step: 9
Training loss: 1.2655582645859125
Validation loss: 2.3932749649124276

Epoch: 6| Step: 10
Training loss: 1.0447479959009085
Validation loss: 2.372632632705828

Epoch: 6| Step: 11
Training loss: 2.0833167139026236
Validation loss: 2.441379412234882

Epoch: 6| Step: 12
Training loss: 0.9289155207268402
Validation loss: 2.317081634274029

Epoch: 6| Step: 13
Training loss: 0.9520960084223086
Validation loss: 2.3861806759860866

Epoch: 392| Step: 0
Training loss: 0.9722375236548404
Validation loss: 2.4182332922421748

Epoch: 6| Step: 1
Training loss: 1.189135028166056
Validation loss: 2.4571342637737588

Epoch: 6| Step: 2
Training loss: 1.1181939133570047
Validation loss: 2.3501135348356947

Epoch: 6| Step: 3
Training loss: 1.18503696593238
Validation loss: 2.4713664112539586

Epoch: 6| Step: 4
Training loss: 1.8246516953535787
Validation loss: 2.3612204320292043

Epoch: 6| Step: 5
Training loss: 1.3962232225491986
Validation loss: 2.450119496391161

Epoch: 6| Step: 6
Training loss: 1.4649205709023048
Validation loss: 2.3383270162602128

Epoch: 6| Step: 7
Training loss: 1.1055405664199953
Validation loss: 2.3905076012768545

Epoch: 6| Step: 8
Training loss: 0.8365759505970759
Validation loss: 2.438900148135867

Epoch: 6| Step: 9
Training loss: 1.0745430751525396
Validation loss: 2.4199824231388374

Epoch: 6| Step: 10
Training loss: 1.4794504493390648
Validation loss: 2.389087844197302

Epoch: 6| Step: 11
Training loss: 1.1691058183326386
Validation loss: 2.335871708543921

Epoch: 6| Step: 12
Training loss: 0.9415084973284559
Validation loss: 2.470400702181778

Epoch: 6| Step: 13
Training loss: 0.7278922433436984
Validation loss: 2.328246152095358

Epoch: 393| Step: 0
Training loss: 1.3893514223281818
Validation loss: 2.439430093193066

Epoch: 6| Step: 1
Training loss: 1.3197506945160737
Validation loss: 2.3849924171220405

Epoch: 6| Step: 2
Training loss: 1.344213804887497
Validation loss: 2.325737988601286

Epoch: 6| Step: 3
Training loss: 1.032743182142955
Validation loss: 2.396007532222235

Epoch: 6| Step: 4
Training loss: 1.0505683995329234
Validation loss: 2.417149996842253

Epoch: 6| Step: 5
Training loss: 1.332481330611969
Validation loss: 2.3525055823793255

Epoch: 6| Step: 6
Training loss: 1.3441246308913604
Validation loss: 2.4033290861560244

Epoch: 6| Step: 7
Training loss: 1.036803234484125
Validation loss: 2.343784073339281

Epoch: 6| Step: 8
Training loss: 0.8670639774912386
Validation loss: 2.3984595979126366

Epoch: 6| Step: 9
Training loss: 0.9427120602079175
Validation loss: 2.3559262531983474

Epoch: 6| Step: 10
Training loss: 1.9907282253072398
Validation loss: 2.4116399131387602

Epoch: 6| Step: 11
Training loss: 1.2854561962972044
Validation loss: 2.3607044968494875

Epoch: 6| Step: 12
Training loss: 1.3688093756073152
Validation loss: 2.4170754680619453

Epoch: 6| Step: 13
Training loss: 1.3184765572921295
Validation loss: 2.3925332534931942

Epoch: 394| Step: 0
Training loss: 0.7499957084532979
Validation loss: 2.3830174049190505

Epoch: 6| Step: 1
Training loss: 1.3902848931502148
Validation loss: 2.3306964229653833

Epoch: 6| Step: 2
Training loss: 0.9329156368114199
Validation loss: 2.355163729698397

Epoch: 6| Step: 3
Training loss: 0.8837925694854453
Validation loss: 2.3317458433531995

Epoch: 6| Step: 4
Training loss: 0.975283769736237
Validation loss: 2.4190796618368005

Epoch: 6| Step: 5
Training loss: 1.4361753580137993
Validation loss: 2.3927663142863898

Epoch: 6| Step: 6
Training loss: 1.1680886197535345
Validation loss: 2.4171801517668476

Epoch: 6| Step: 7
Training loss: 1.1374440189880939
Validation loss: 2.3646707627496744

Epoch: 6| Step: 8
Training loss: 0.948591048303262
Validation loss: 2.4187398279401244

Epoch: 6| Step: 9
Training loss: 1.1830673809903038
Validation loss: 2.382819308212885

Epoch: 6| Step: 10
Training loss: 1.4439033856181347
Validation loss: 2.3820931168901303

Epoch: 6| Step: 11
Training loss: 1.1364684992870793
Validation loss: 2.406996891409301

Epoch: 6| Step: 12
Training loss: 2.098142883570013
Validation loss: 2.4118114393551537

Epoch: 6| Step: 13
Training loss: 1.0230924301229831
Validation loss: 2.4537010464914335

Epoch: 395| Step: 0
Training loss: 1.2779643099999574
Validation loss: 2.384274314294514

Epoch: 6| Step: 1
Training loss: 1.5422262602382812
Validation loss: 2.375379664801137

Epoch: 6| Step: 2
Training loss: 0.670163881058759
Validation loss: 2.3826932573666015

Epoch: 6| Step: 3
Training loss: 1.0774876465941163
Validation loss: 2.3788998034579976

Epoch: 6| Step: 4
Training loss: 1.4666723612472494
Validation loss: 2.3388997437411616

Epoch: 6| Step: 5
Training loss: 0.8914340844852842
Validation loss: 2.367549931714462

Epoch: 6| Step: 6
Training loss: 1.120699610526796
Validation loss: 2.3913189956192586

Epoch: 6| Step: 7
Training loss: 0.8673738846365573
Validation loss: 2.302742983041188

Epoch: 6| Step: 8
Training loss: 1.201842280679959
Validation loss: 2.366806982503497

Epoch: 6| Step: 9
Training loss: 1.1800983042098132
Validation loss: 2.4062493160072638

Epoch: 6| Step: 10
Training loss: 1.898491627113861
Validation loss: 2.3720211352117953

Epoch: 6| Step: 11
Training loss: 1.2496395545074488
Validation loss: 2.3789934781214224

Epoch: 6| Step: 12
Training loss: 1.0477603186479492
Validation loss: 2.332724793650751

Epoch: 6| Step: 13
Training loss: 0.7289282318104296
Validation loss: 2.3534717951789097

Epoch: 396| Step: 0
Training loss: 1.2726670257130899
Validation loss: 2.412771316472798

Epoch: 6| Step: 1
Training loss: 1.311407770096666
Validation loss: 2.312389695968796

Epoch: 6| Step: 2
Training loss: 1.8421212453794193
Validation loss: 2.3519298585540707

Epoch: 6| Step: 3
Training loss: 1.3251904998444528
Validation loss: 2.4101127465952707

Epoch: 6| Step: 4
Training loss: 1.5259049997768919
Validation loss: 2.3412452247857862

Epoch: 6| Step: 5
Training loss: 0.8364658646741331
Validation loss: 2.3979912248120914

Epoch: 6| Step: 6
Training loss: 0.9115985035970641
Validation loss: 2.408941522869541

Epoch: 6| Step: 7
Training loss: 0.9273824887752952
Validation loss: 2.4248227707485825

Epoch: 6| Step: 8
Training loss: 1.0955200042291047
Validation loss: 2.3292649528395044

Epoch: 6| Step: 9
Training loss: 1.2074631594137988
Validation loss: 2.327038224652714

Epoch: 6| Step: 10
Training loss: 1.052336552176891
Validation loss: 2.3817958255852614

Epoch: 6| Step: 11
Training loss: 1.216889354932665
Validation loss: 2.345349468427277

Epoch: 6| Step: 12
Training loss: 0.986997199921274
Validation loss: 2.352441304835188

Epoch: 6| Step: 13
Training loss: 1.4344979327011769
Validation loss: 2.3445144730082026

Epoch: 397| Step: 0
Training loss: 1.0719847597917753
Validation loss: 2.339263335099996

Epoch: 6| Step: 1
Training loss: 1.413185479929508
Validation loss: 2.339031844956451

Epoch: 6| Step: 2
Training loss: 0.9695979683272475
Validation loss: 2.459528570598571

Epoch: 6| Step: 3
Training loss: 1.104476915113934
Validation loss: 2.4072162098374816

Epoch: 6| Step: 4
Training loss: 0.6985883374944096
Validation loss: 2.377475000507121

Epoch: 6| Step: 5
Training loss: 0.8175042904149199
Validation loss: 2.342815187038427

Epoch: 6| Step: 6
Training loss: 1.1329749681446553
Validation loss: 2.3503654484917393

Epoch: 6| Step: 7
Training loss: 1.875127724429836
Validation loss: 2.4360349536663706

Epoch: 6| Step: 8
Training loss: 1.15018076512573
Validation loss: 2.386905460457004

Epoch: 6| Step: 9
Training loss: 1.2738723480493468
Validation loss: 2.385376602426062

Epoch: 6| Step: 10
Training loss: 1.7999486756954877
Validation loss: 2.351520766762555

Epoch: 6| Step: 11
Training loss: 1.152796252356691
Validation loss: 2.412154619930878

Epoch: 6| Step: 12
Training loss: 0.7782936618123868
Validation loss: 2.340516493928575

Epoch: 6| Step: 13
Training loss: 0.9424761948247987
Validation loss: 2.401633374818302

Epoch: 398| Step: 0
Training loss: 0.6057521525969379
Validation loss: 2.3742613412844893

Epoch: 6| Step: 1
Training loss: 1.1520281343302832
Validation loss: 2.4138637075514966

Epoch: 6| Step: 2
Training loss: 0.8180732317837047
Validation loss: 2.4255293867182304

Epoch: 6| Step: 3
Training loss: 1.1168853778068784
Validation loss: 2.4349962874564035

Epoch: 6| Step: 4
Training loss: 1.369502042991003
Validation loss: 2.328947812837224

Epoch: 6| Step: 5
Training loss: 0.8509956362978878
Validation loss: 2.3683342917613586

Epoch: 6| Step: 6
Training loss: 0.9435805541251409
Validation loss: 2.3955174976701876

Epoch: 6| Step: 7
Training loss: 1.8428780385033552
Validation loss: 2.3857149309437298

Epoch: 6| Step: 8
Training loss: 0.8490068776736129
Validation loss: 2.3570679422889453

Epoch: 6| Step: 9
Training loss: 1.5435941949591374
Validation loss: 2.3567959818735886

Epoch: 6| Step: 10
Training loss: 1.066668188322492
Validation loss: 2.3402108634372514

Epoch: 6| Step: 11
Training loss: 1.5468509556606675
Validation loss: 2.3439958319041243

Epoch: 6| Step: 12
Training loss: 1.7889788079155378
Validation loss: 2.393516235602331

Epoch: 6| Step: 13
Training loss: 0.7277293935575573
Validation loss: 2.428563744186497

Epoch: 399| Step: 0
Training loss: 2.196108527797075
Validation loss: 2.384278573809975

Epoch: 6| Step: 1
Training loss: 1.1775936213407407
Validation loss: 2.2937766641217814

Epoch: 6| Step: 2
Training loss: 0.9315301281801552
Validation loss: 2.3383415478757583

Epoch: 6| Step: 3
Training loss: 1.1011900576537919
Validation loss: 2.3785744744899766

Epoch: 6| Step: 4
Training loss: 1.4412373596325267
Validation loss: 2.3642329551402987

Epoch: 6| Step: 5
Training loss: 1.2751475828437375
Validation loss: 2.389614646939543

Epoch: 6| Step: 6
Training loss: 1.406343414594803
Validation loss: 2.325556191622972

Epoch: 6| Step: 7
Training loss: 1.1266290737591842
Validation loss: 2.4153591398184373

Epoch: 6| Step: 8
Training loss: 1.0258679250921978
Validation loss: 2.3435538622095162

Epoch: 6| Step: 9
Training loss: 0.8148142062250748
Validation loss: 2.4012963699064365

Epoch: 6| Step: 10
Training loss: 0.9589960287904905
Validation loss: 2.376312107138648

Epoch: 6| Step: 11
Training loss: 1.3054511753362623
Validation loss: 2.4169297936105942

Epoch: 6| Step: 12
Training loss: 0.8378789585252778
Validation loss: 2.3891235951539675

Epoch: 6| Step: 13
Training loss: 1.1366347449025576
Validation loss: 2.389775756366006

Epoch: 400| Step: 0
Training loss: 1.873059731161888
Validation loss: 2.432817789067096

Epoch: 6| Step: 1
Training loss: 1.2890974560246213
Validation loss: 2.4283921111877658

Epoch: 6| Step: 2
Training loss: 1.1354026910230883
Validation loss: 2.435195094975843

Epoch: 6| Step: 3
Training loss: 1.0954455720655556
Validation loss: 2.364545047094622

Epoch: 6| Step: 4
Training loss: 1.3039774075903003
Validation loss: 2.390063012870907

Epoch: 6| Step: 5
Training loss: 1.1738115712552089
Validation loss: 2.3920571385092355

Epoch: 6| Step: 6
Training loss: 0.980470239402582
Validation loss: 2.3773887804572706

Epoch: 6| Step: 7
Training loss: 1.6937045721176716
Validation loss: 2.3403744667910624

Epoch: 6| Step: 8
Training loss: 0.8259821825068544
Validation loss: 2.3634743926406885

Epoch: 6| Step: 9
Training loss: 1.3185341048128048
Validation loss: 2.4160141139893225

Epoch: 6| Step: 10
Training loss: 0.8904296259159402
Validation loss: 2.3680238738375667

Epoch: 6| Step: 11
Training loss: 1.0202231562288488
Validation loss: 2.4250681198484796

Epoch: 6| Step: 12
Training loss: 1.0260506966801874
Validation loss: 2.3736253677511856

Epoch: 6| Step: 13
Training loss: 1.2882999823638577
Validation loss: 2.2748705231554682

Epoch: 401| Step: 0
Training loss: 0.9980818113419625
Validation loss: 2.3696173512632703

Epoch: 6| Step: 1
Training loss: 1.2198429097988341
Validation loss: 2.250157449880653

Epoch: 6| Step: 2
Training loss: 1.2121807484292464
Validation loss: 2.3769666477045575

Epoch: 6| Step: 3
Training loss: 1.3937654502936025
Validation loss: 2.3983806370751903

Epoch: 6| Step: 4
Training loss: 1.002903299996708
Validation loss: 2.3596387222871513

Epoch: 6| Step: 5
Training loss: 1.3187987549072164
Validation loss: 2.360303670347489

Epoch: 6| Step: 6
Training loss: 1.0026966927510077
Validation loss: 2.2992681275153055

Epoch: 6| Step: 7
Training loss: 1.3285289823179718
Validation loss: 2.326632155207603

Epoch: 6| Step: 8
Training loss: 1.3667800732212507
Validation loss: 2.391435441158393

Epoch: 6| Step: 9
Training loss: 1.1257255651612235
Validation loss: 2.3440700408206037

Epoch: 6| Step: 10
Training loss: 2.191888059256846
Validation loss: 2.345811742363646

Epoch: 6| Step: 11
Training loss: 0.8032850989097599
Validation loss: 2.3279183645605324

Epoch: 6| Step: 12
Training loss: 0.9038922123325894
Validation loss: 2.430118790647475

Epoch: 6| Step: 13
Training loss: 0.5352615197219116
Validation loss: 2.490328584835719

Epoch: 402| Step: 0
Training loss: 1.2658087043718484
Validation loss: 2.4584546584997384

Epoch: 6| Step: 1
Training loss: 0.7891778389510149
Validation loss: 2.4221455507931378

Epoch: 6| Step: 2
Training loss: 0.9332807327389142
Validation loss: 2.3418554402552694

Epoch: 6| Step: 3
Training loss: 1.3169304231442036
Validation loss: 2.4492253621068336

Epoch: 6| Step: 4
Training loss: 1.2852467792012807
Validation loss: 2.4369048682298806

Epoch: 6| Step: 5
Training loss: 0.6333293923037867
Validation loss: 2.367855040035861

Epoch: 6| Step: 6
Training loss: 1.3474411944861515
Validation loss: 2.3780192477055677

Epoch: 6| Step: 7
Training loss: 0.8071083763174721
Validation loss: 2.355093442701027

Epoch: 6| Step: 8
Training loss: 1.0466572549319848
Validation loss: 2.3861240925513494

Epoch: 6| Step: 9
Training loss: 1.0701221937301624
Validation loss: 2.388455465385466

Epoch: 6| Step: 10
Training loss: 1.3785016814489006
Validation loss: 2.3525070769696215

Epoch: 6| Step: 11
Training loss: 1.2191853845966822
Validation loss: 2.347249261264632

Epoch: 6| Step: 12
Training loss: 2.042589666669916
Validation loss: 2.303290413750363

Epoch: 6| Step: 13
Training loss: 1.1144698908226969
Validation loss: 2.465425020964651

Epoch: 403| Step: 0
Training loss: 1.225196271859804
Validation loss: 2.3244307105187145

Epoch: 6| Step: 1
Training loss: 1.2028326695000642
Validation loss: 2.3911484642465615

Epoch: 6| Step: 2
Training loss: 1.010859710200362
Validation loss: 2.409839364581614

Epoch: 6| Step: 3
Training loss: 1.2010872167511575
Validation loss: 2.3779975872828083

Epoch: 6| Step: 4
Training loss: 1.1045558651377507
Validation loss: 2.3728266164229996

Epoch: 6| Step: 5
Training loss: 1.0816445882000683
Validation loss: 2.369854784889764

Epoch: 6| Step: 6
Training loss: 1.059595176299576
Validation loss: 2.338153122678248

Epoch: 6| Step: 7
Training loss: 0.9795790507326956
Validation loss: 2.3206502732727956

Epoch: 6| Step: 8
Training loss: 0.9067715426637057
Validation loss: 2.420423553202064

Epoch: 6| Step: 9
Training loss: 1.9055371436825836
Validation loss: 2.383221858712203

Epoch: 6| Step: 10
Training loss: 0.9231609491930046
Validation loss: 2.3439166900534536

Epoch: 6| Step: 11
Training loss: 1.0630712656371464
Validation loss: 2.4627949044346047

Epoch: 6| Step: 12
Training loss: 1.104182920996068
Validation loss: 2.382674444439954

Epoch: 6| Step: 13
Training loss: 0.8658202450350153
Validation loss: 2.3583050514136232

Epoch: 404| Step: 0
Training loss: 1.1649111528039389
Validation loss: 2.4190722281482153

Epoch: 6| Step: 1
Training loss: 1.9823403327595526
Validation loss: 2.395463600538457

Epoch: 6| Step: 2
Training loss: 0.9597573515582398
Validation loss: 2.3213217548332916

Epoch: 6| Step: 3
Training loss: 1.297581951074393
Validation loss: 2.364374438215367

Epoch: 6| Step: 4
Training loss: 1.1629227556602046
Validation loss: 2.2919174523230352

Epoch: 6| Step: 5
Training loss: 1.0495071912231073
Validation loss: 2.3963511616718765

Epoch: 6| Step: 6
Training loss: 0.9548133842023194
Validation loss: 2.391873541882327

Epoch: 6| Step: 7
Training loss: 1.4064178366639912
Validation loss: 2.4102164472864906

Epoch: 6| Step: 8
Training loss: 1.3068199775894553
Validation loss: 2.3364333829780635

Epoch: 6| Step: 9
Training loss: 0.7945520538937274
Validation loss: 2.4055653458238426

Epoch: 6| Step: 10
Training loss: 1.1309453374839333
Validation loss: 2.427026442642165

Epoch: 6| Step: 11
Training loss: 0.9182061720269853
Validation loss: 2.3892366250490853

Epoch: 6| Step: 12
Training loss: 0.964147277764567
Validation loss: 2.3872579323338234

Epoch: 6| Step: 13
Training loss: 0.48118550252345
Validation loss: 2.358617401132179

Epoch: 405| Step: 0
Training loss: 0.9316768679176923
Validation loss: 2.4158829262222286

Epoch: 6| Step: 1
Training loss: 1.0415051080667292
Validation loss: 2.3980789859906397

Epoch: 6| Step: 2
Training loss: 1.2779515771333512
Validation loss: 2.320373735434319

Epoch: 6| Step: 3
Training loss: 0.8936728144041404
Validation loss: 2.4005361844440256

Epoch: 6| Step: 4
Training loss: 1.0800380595883192
Validation loss: 2.4206483082278893

Epoch: 6| Step: 5
Training loss: 1.9921773274479866
Validation loss: 2.3875781326467544

Epoch: 6| Step: 6
Training loss: 0.9639720917634924
Validation loss: 2.3547523467667846

Epoch: 6| Step: 7
Training loss: 1.3944460631779516
Validation loss: 2.3133626978835244

Epoch: 6| Step: 8
Training loss: 0.9098032647516019
Validation loss: 2.3717747000539875

Epoch: 6| Step: 9
Training loss: 0.753854502745093
Validation loss: 2.3755774845648325

Epoch: 6| Step: 10
Training loss: 1.2538715963833698
Validation loss: 2.3933278321366824

Epoch: 6| Step: 11
Training loss: 1.732955007652528
Validation loss: 2.376785567799884

Epoch: 6| Step: 12
Training loss: 0.9145835956118359
Validation loss: 2.3876397495551918

Epoch: 6| Step: 13
Training loss: 1.0726891186839818
Validation loss: 2.393507009861205

Epoch: 406| Step: 0
Training loss: 1.4059207530824982
Validation loss: 2.3700606510689632

Epoch: 6| Step: 1
Training loss: 1.1578191471295147
Validation loss: 2.402595210860568

Epoch: 6| Step: 2
Training loss: 0.9358068435488823
Validation loss: 2.407511528121367

Epoch: 6| Step: 3
Training loss: 0.8439859131093952
Validation loss: 2.3227149698864467

Epoch: 6| Step: 4
Training loss: 1.0276428483480953
Validation loss: 2.405541698083993

Epoch: 6| Step: 5
Training loss: 0.6969469555027017
Validation loss: 2.432439829910939

Epoch: 6| Step: 6
Training loss: 1.9871827934054629
Validation loss: 2.3766188455602557

Epoch: 6| Step: 7
Training loss: 0.9673229597196203
Validation loss: 2.3948885341921926

Epoch: 6| Step: 8
Training loss: 1.0013613970600088
Validation loss: 2.289979060112628

Epoch: 6| Step: 9
Training loss: 1.1300487083301087
Validation loss: 2.4240177949580297

Epoch: 6| Step: 10
Training loss: 1.226798551162695
Validation loss: 2.327544204382728

Epoch: 6| Step: 11
Training loss: 1.1904394510821665
Validation loss: 2.34257059126567

Epoch: 6| Step: 12
Training loss: 1.0446837537163727
Validation loss: 2.424584280725448

Epoch: 6| Step: 13
Training loss: 0.8724159845710303
Validation loss: 2.3756864556313997

Epoch: 407| Step: 0
Training loss: 1.1255256696270868
Validation loss: 2.382075805933995

Epoch: 6| Step: 1
Training loss: 2.161280968677517
Validation loss: 2.3375874247512627

Epoch: 6| Step: 2
Training loss: 1.2528760248884303
Validation loss: 2.3585403988349305

Epoch: 6| Step: 3
Training loss: 0.6470241770833312
Validation loss: 2.441322137117913

Epoch: 6| Step: 4
Training loss: 0.8476918999694787
Validation loss: 2.440071507515952

Epoch: 6| Step: 5
Training loss: 1.0810547977712794
Validation loss: 2.369847330392756

Epoch: 6| Step: 6
Training loss: 0.9201197320315458
Validation loss: 2.4053388888800344

Epoch: 6| Step: 7
Training loss: 1.2455348372761519
Validation loss: 2.4204516528258573

Epoch: 6| Step: 8
Training loss: 1.0522328386998663
Validation loss: 2.4179028612020907

Epoch: 6| Step: 9
Training loss: 1.252125696913807
Validation loss: 2.3974973228010468

Epoch: 6| Step: 10
Training loss: 0.9029832035669724
Validation loss: 2.3689875454905867

Epoch: 6| Step: 11
Training loss: 1.0323602883902334
Validation loss: 2.3903598422534684

Epoch: 6| Step: 12
Training loss: 0.9053197229562717
Validation loss: 2.334284669410251

Epoch: 6| Step: 13
Training loss: 0.8810143175899368
Validation loss: 2.410114078881079

Epoch: 408| Step: 0
Training loss: 1.2333932183307033
Validation loss: 2.3856668494688558

Epoch: 6| Step: 1
Training loss: 1.9814201642918037
Validation loss: 2.4261749404132162

Epoch: 6| Step: 2
Training loss: 1.0656726255989062
Validation loss: 2.4709121853655707

Epoch: 6| Step: 3
Training loss: 1.1149292643737023
Validation loss: 2.4346833532115326

Epoch: 6| Step: 4
Training loss: 1.1451854723838657
Validation loss: 2.307960173595186

Epoch: 6| Step: 5
Training loss: 0.8513923615043753
Validation loss: 2.3311660779648067

Epoch: 6| Step: 6
Training loss: 0.9315526508884284
Validation loss: 2.390959090409997

Epoch: 6| Step: 7
Training loss: 1.3747904791289476
Validation loss: 2.419338484507151

Epoch: 6| Step: 8
Training loss: 1.2552372888203718
Validation loss: 2.4139567486524203

Epoch: 6| Step: 9
Training loss: 1.0065611530000047
Validation loss: 2.3300617412974507

Epoch: 6| Step: 10
Training loss: 0.9754508443322796
Validation loss: 2.315327428249327

Epoch: 6| Step: 11
Training loss: 0.9525726156013629
Validation loss: 2.3385071714341805

Epoch: 6| Step: 12
Training loss: 0.9399596056476728
Validation loss: 2.311020357532072

Epoch: 6| Step: 13
Training loss: 1.16617244515744
Validation loss: 2.3593032457653655

Epoch: 409| Step: 0
Training loss: 1.074344308624482
Validation loss: 2.3015180342946984

Epoch: 6| Step: 1
Training loss: 1.8733025178490303
Validation loss: 2.3578910047860466

Epoch: 6| Step: 2
Training loss: 1.206098968063633
Validation loss: 2.2836088200132876

Epoch: 6| Step: 3
Training loss: 0.9265703467926164
Validation loss: 2.3578357202273796

Epoch: 6| Step: 4
Training loss: 1.3013144651745956
Validation loss: 2.440045349026474

Epoch: 6| Step: 5
Training loss: 1.3607582858981166
Validation loss: 2.3353905405955735

Epoch: 6| Step: 6
Training loss: 0.9297978632198569
Validation loss: 2.4305427469676837

Epoch: 6| Step: 7
Training loss: 0.7522781264224777
Validation loss: 2.3110802140769082

Epoch: 6| Step: 8
Training loss: 1.289101709867685
Validation loss: 2.4796546013979115

Epoch: 6| Step: 9
Training loss: 0.8690157339824859
Validation loss: 2.351407586000634

Epoch: 6| Step: 10
Training loss: 1.3381745642757104
Validation loss: 2.406121865696246

Epoch: 6| Step: 11
Training loss: 1.0932726772179957
Validation loss: 2.4296588477260213

Epoch: 6| Step: 12
Training loss: 0.6080229015052664
Validation loss: 2.4288970460202366

Epoch: 6| Step: 13
Training loss: 1.016942153148217
Validation loss: 2.3667987244450885

Epoch: 410| Step: 0
Training loss: 1.1474270689815504
Validation loss: 2.3255316371386803

Epoch: 6| Step: 1
Training loss: 1.0617331935413803
Validation loss: 2.3803956926587735

Epoch: 6| Step: 2
Training loss: 1.0521291716507537
Validation loss: 2.3289254626544755

Epoch: 6| Step: 3
Training loss: 0.9070086756483733
Validation loss: 2.4085843786513843

Epoch: 6| Step: 4
Training loss: 0.7431457757893039
Validation loss: 2.365716294611392

Epoch: 6| Step: 5
Training loss: 1.1301552486111985
Validation loss: 2.375376414082529

Epoch: 6| Step: 6
Training loss: 1.3255055794528303
Validation loss: 2.3739691096149196

Epoch: 6| Step: 7
Training loss: 0.9757581220929461
Validation loss: 2.329325557260291

Epoch: 6| Step: 8
Training loss: 1.353450140531811
Validation loss: 2.3689899533113983

Epoch: 6| Step: 9
Training loss: 1.225384188760691
Validation loss: 2.3198633876279047

Epoch: 6| Step: 10
Training loss: 1.211590301769303
Validation loss: 2.3524197238468463

Epoch: 6| Step: 11
Training loss: 0.8996598925632883
Validation loss: 2.368704153317415

Epoch: 6| Step: 12
Training loss: 2.0666039990593803
Validation loss: 2.331312119013919

Epoch: 6| Step: 13
Training loss: 0.6380311277428365
Validation loss: 2.32905175201853

Epoch: 411| Step: 0
Training loss: 0.9934227530556955
Validation loss: 2.326155441742874

Epoch: 6| Step: 1
Training loss: 1.162670711575553
Validation loss: 2.4314231227385887

Epoch: 6| Step: 2
Training loss: 1.105374605193645
Validation loss: 2.4166744247611853

Epoch: 6| Step: 3
Training loss: 1.0611176193219687
Validation loss: 2.362333308603397

Epoch: 6| Step: 4
Training loss: 1.321535976934843
Validation loss: 2.3712532960296886

Epoch: 6| Step: 5
Training loss: 1.2811445797605663
Validation loss: 2.336721386093753

Epoch: 6| Step: 6
Training loss: 0.6007915362009547
Validation loss: 2.3551577286851124

Epoch: 6| Step: 7
Training loss: 1.0005689433000762
Validation loss: 2.397477069129887

Epoch: 6| Step: 8
Training loss: 1.0478393895276736
Validation loss: 2.316862352386493

Epoch: 6| Step: 9
Training loss: 0.8625189751458949
Validation loss: 2.3479002338028025

Epoch: 6| Step: 10
Training loss: 1.1293120925178872
Validation loss: 2.3958762130716558

Epoch: 6| Step: 11
Training loss: 0.7148832716725925
Validation loss: 2.3837352593916976

Epoch: 6| Step: 12
Training loss: 1.94333857999631
Validation loss: 2.328376867062162

Epoch: 6| Step: 13
Training loss: 0.730513301041574
Validation loss: 2.2861544518111296

Epoch: 412| Step: 0
Training loss: 1.1187789359160016
Validation loss: 2.2831387996178227

Epoch: 6| Step: 1
Training loss: 0.8137799232008899
Validation loss: 2.383464912332389

Epoch: 6| Step: 2
Training loss: 1.2308114679590143
Validation loss: 2.411841967153421

Epoch: 6| Step: 3
Training loss: 1.0969132593334747
Validation loss: 2.390985639569119

Epoch: 6| Step: 4
Training loss: 1.954032504011486
Validation loss: 2.369052932377356

Epoch: 6| Step: 5
Training loss: 0.8482480773791564
Validation loss: 2.4051001936207155

Epoch: 6| Step: 6
Training loss: 1.1379418363875629
Validation loss: 2.4220669181115637

Epoch: 6| Step: 7
Training loss: 0.6865380232714434
Validation loss: 2.3707404893806285

Epoch: 6| Step: 8
Training loss: 1.1192940545221288
Validation loss: 2.3270501056401263

Epoch: 6| Step: 9
Training loss: 1.1490231532294768
Validation loss: 2.408676560408183

Epoch: 6| Step: 10
Training loss: 1.222787575783346
Validation loss: 2.387628618343113

Epoch: 6| Step: 11
Training loss: 0.911331204222355
Validation loss: 2.3498337015915527

Epoch: 6| Step: 12
Training loss: 1.3750880386604625
Validation loss: 2.3705640058728297

Epoch: 6| Step: 13
Training loss: 0.9145096231416234
Validation loss: 2.3862236933681444

Epoch: 413| Step: 0
Training loss: 0.959213602363232
Validation loss: 2.3863972516039076

Epoch: 6| Step: 1
Training loss: 0.7803126624874485
Validation loss: 2.3072441146358966

Epoch: 6| Step: 2
Training loss: 1.1436938975598379
Validation loss: 2.3584162320499846

Epoch: 6| Step: 3
Training loss: 0.8910437151784467
Validation loss: 2.411522581763539

Epoch: 6| Step: 4
Training loss: 0.7415043145978314
Validation loss: 2.3033285203815788

Epoch: 6| Step: 5
Training loss: 1.307651282870932
Validation loss: 2.40453278307443

Epoch: 6| Step: 6
Training loss: 0.9629808735676195
Validation loss: 2.305531067941992

Epoch: 6| Step: 7
Training loss: 1.2083585780345754
Validation loss: 2.372280544665149

Epoch: 6| Step: 8
Training loss: 1.2210546857036424
Validation loss: 2.3768509084235663

Epoch: 6| Step: 9
Training loss: 1.1617537779872826
Validation loss: 2.40550060879049

Epoch: 6| Step: 10
Training loss: 1.344875130795287
Validation loss: 2.416918119503613

Epoch: 6| Step: 11
Training loss: 1.9467053922737927
Validation loss: 2.313137545249171

Epoch: 6| Step: 12
Training loss: 1.0159066616647632
Validation loss: 2.358025657008228

Epoch: 6| Step: 13
Training loss: 0.9694472849080744
Validation loss: 2.4531004202782865

Epoch: 414| Step: 0
Training loss: 0.9340672908084512
Validation loss: 2.3707563227040165

Epoch: 6| Step: 1
Training loss: 1.5273114369284067
Validation loss: 2.3038920046584517

Epoch: 6| Step: 2
Training loss: 0.5785946871188221
Validation loss: 2.2996977526129054

Epoch: 6| Step: 3
Training loss: 1.1093158974820898
Validation loss: 2.2953537415282486

Epoch: 6| Step: 4
Training loss: 0.8070061619746703
Validation loss: 2.3420741104872107

Epoch: 6| Step: 5
Training loss: 1.0806148361337011
Validation loss: 2.4260796458241454

Epoch: 6| Step: 6
Training loss: 1.406439238637007
Validation loss: 2.4189188985235957

Epoch: 6| Step: 7
Training loss: 1.2483669580957053
Validation loss: 2.443805121863968

Epoch: 6| Step: 8
Training loss: 1.010484509632007
Validation loss: 2.308977553416902

Epoch: 6| Step: 9
Training loss: 0.7892425256205435
Validation loss: 2.354936995501165

Epoch: 6| Step: 10
Training loss: 0.7724177255612603
Validation loss: 2.3761842249312037

Epoch: 6| Step: 11
Training loss: 1.2071996775029474
Validation loss: 2.3341312490781188

Epoch: 6| Step: 12
Training loss: 1.8704454417772476
Validation loss: 2.3474128174740336

Epoch: 6| Step: 13
Training loss: 0.8594191799945146
Validation loss: 2.398756892524147

Epoch: 415| Step: 0
Training loss: 1.27306763127868
Validation loss: 2.3323733492691425

Epoch: 6| Step: 1
Training loss: 1.3543529480184981
Validation loss: 2.3303907350240105

Epoch: 6| Step: 2
Training loss: 1.31345151288846
Validation loss: 2.391645619145178

Epoch: 6| Step: 3
Training loss: 1.0226727605992088
Validation loss: 2.3288728732725885

Epoch: 6| Step: 4
Training loss: 1.737524729490965
Validation loss: 2.2984825849891726

Epoch: 6| Step: 5
Training loss: 1.0186023792428558
Validation loss: 2.3627095646215297

Epoch: 6| Step: 6
Training loss: 1.3763003269594571
Validation loss: 2.3369318538968797

Epoch: 6| Step: 7
Training loss: 0.6022353187266423
Validation loss: 2.345629267216163

Epoch: 6| Step: 8
Training loss: 0.9872674378443866
Validation loss: 2.3667089454459824

Epoch: 6| Step: 9
Training loss: 1.1533872373383824
Validation loss: 2.3895675875016984

Epoch: 6| Step: 10
Training loss: 0.8210895309557623
Validation loss: 2.3817459293470282

Epoch: 6| Step: 11
Training loss: 0.8243048021855314
Validation loss: 2.3899570904430414

Epoch: 6| Step: 12
Training loss: 0.9412450691995741
Validation loss: 2.2881443246147843

Epoch: 6| Step: 13
Training loss: 0.9796837023307045
Validation loss: 2.4217611433636583

Epoch: 416| Step: 0
Training loss: 1.9145249411471918
Validation loss: 2.3813104681428636

Epoch: 6| Step: 1
Training loss: 1.3017487922693625
Validation loss: 2.358524657418079

Epoch: 6| Step: 2
Training loss: 0.8727208153754903
Validation loss: 2.3819384061836337

Epoch: 6| Step: 3
Training loss: 1.062323667816425
Validation loss: 2.296171679902786

Epoch: 6| Step: 4
Training loss: 1.064798337621559
Validation loss: 2.3264124671411768

Epoch: 6| Step: 5
Training loss: 1.3539894232541096
Validation loss: 2.373173383119697

Epoch: 6| Step: 6
Training loss: 1.0118918252433224
Validation loss: 2.330265657981708

Epoch: 6| Step: 7
Training loss: 0.7888889688467902
Validation loss: 2.2530815791297636

Epoch: 6| Step: 8
Training loss: 0.86051573902656
Validation loss: 2.32491989059479

Epoch: 6| Step: 9
Training loss: 1.0592538950067232
Validation loss: 2.252122675896669

Epoch: 6| Step: 10
Training loss: 1.302803643942947
Validation loss: 2.4287889349819443

Epoch: 6| Step: 11
Training loss: 1.0580899774801908
Validation loss: 2.3648101761436866

Epoch: 6| Step: 12
Training loss: 0.9064514988476678
Validation loss: 2.3356040414500434

Epoch: 6| Step: 13
Training loss: 1.0475510648967352
Validation loss: 2.3117147940130334

Epoch: 417| Step: 0
Training loss: 0.955117815749277
Validation loss: 2.3790919259738366

Epoch: 6| Step: 1
Training loss: 1.8525116495649039
Validation loss: 2.3732943819462253

Epoch: 6| Step: 2
Training loss: 1.2065321004417422
Validation loss: 2.3451095783265625

Epoch: 6| Step: 3
Training loss: 1.2730136938414869
Validation loss: 2.3390210337271276

Epoch: 6| Step: 4
Training loss: 1.139616638106054
Validation loss: 2.334946597297291

Epoch: 6| Step: 5
Training loss: 0.7394642711671908
Validation loss: 2.386489999255345

Epoch: 6| Step: 6
Training loss: 0.6851398096319635
Validation loss: 2.335739666775394

Epoch: 6| Step: 7
Training loss: 1.210987311538513
Validation loss: 2.371190850035638

Epoch: 6| Step: 8
Training loss: 0.7245295807122207
Validation loss: 2.334306602564879

Epoch: 6| Step: 9
Training loss: 1.2118263182125957
Validation loss: 2.3125679728931496

Epoch: 6| Step: 10
Training loss: 0.77855714188663
Validation loss: 2.4383164240957376

Epoch: 6| Step: 11
Training loss: 1.1047173092717164
Validation loss: 2.3969104081038504

Epoch: 6| Step: 12
Training loss: 1.1870199036090447
Validation loss: 2.330100780991983

Epoch: 6| Step: 13
Training loss: 1.03631941025654
Validation loss: 2.3973147555617453

Epoch: 418| Step: 0
Training loss: 1.2341655118852288
Validation loss: 2.310550737300172

Epoch: 6| Step: 1
Training loss: 1.1914853929591969
Validation loss: 2.3675394277538833

Epoch: 6| Step: 2
Training loss: 0.8232273448904788
Validation loss: 2.3602823458947944

Epoch: 6| Step: 3
Training loss: 2.011660202803995
Validation loss: 2.387989093137794

Epoch: 6| Step: 4
Training loss: 1.0831483658583194
Validation loss: 2.362048446243985

Epoch: 6| Step: 5
Training loss: 0.7868123594504075
Validation loss: 2.4315025498939082

Epoch: 6| Step: 6
Training loss: 0.9772712272003468
Validation loss: 2.3438413803170435

Epoch: 6| Step: 7
Training loss: 1.0537736112182499
Validation loss: 2.38210571178276

Epoch: 6| Step: 8
Training loss: 0.6455837095486114
Validation loss: 2.4275101070768788

Epoch: 6| Step: 9
Training loss: 1.0724810607945203
Validation loss: 2.4092800988819905

Epoch: 6| Step: 10
Training loss: 1.4716109960329256
Validation loss: 2.4003781719737978

Epoch: 6| Step: 11
Training loss: 1.0625473460699908
Validation loss: 2.4244449943022657

Epoch: 6| Step: 12
Training loss: 1.012449729519183
Validation loss: 2.3964335506093124

Epoch: 6| Step: 13
Training loss: 0.765023287001076
Validation loss: 2.3615709372999256

Epoch: 419| Step: 0
Training loss: 0.8286619065358489
Validation loss: 2.313084815812851

Epoch: 6| Step: 1
Training loss: 1.0599893189737815
Validation loss: 2.354599926895196

Epoch: 6| Step: 2
Training loss: 1.044538138687141
Validation loss: 2.4080325894956163

Epoch: 6| Step: 3
Training loss: 1.8659693363446428
Validation loss: 2.342754643235125

Epoch: 6| Step: 4
Training loss: 1.6497155609027774
Validation loss: 2.358579949740954

Epoch: 6| Step: 5
Training loss: 1.0219917277357795
Validation loss: 2.453351376854154

Epoch: 6| Step: 6
Training loss: 1.0526095795842212
Validation loss: 2.420753813849852

Epoch: 6| Step: 7
Training loss: 0.7964928776697374
Validation loss: 2.368342362611861

Epoch: 6| Step: 8
Training loss: 0.8538649343981536
Validation loss: 2.327311901620944

Epoch: 6| Step: 9
Training loss: 1.118802164236191
Validation loss: 2.364586324953246

Epoch: 6| Step: 10
Training loss: 1.244340578117573
Validation loss: 2.4281327501035714

Epoch: 6| Step: 11
Training loss: 0.7197407652490058
Validation loss: 2.336058744057287

Epoch: 6| Step: 12
Training loss: 0.9601684221903768
Validation loss: 2.2989809422809295

Epoch: 6| Step: 13
Training loss: 1.1393155459210982
Validation loss: 2.3612053903202606

Epoch: 420| Step: 0
Training loss: 1.3204697735355568
Validation loss: 2.3032102805837105

Epoch: 6| Step: 1
Training loss: 0.9686294296051123
Validation loss: 2.3147297950795798

Epoch: 6| Step: 2
Training loss: 1.0468907710922881
Validation loss: 2.3506266179817166

Epoch: 6| Step: 3
Training loss: 1.00093624871182
Validation loss: 2.411094414992001

Epoch: 6| Step: 4
Training loss: 0.8503966443852405
Validation loss: 2.3702249532265465

Epoch: 6| Step: 5
Training loss: 1.3718735088783451
Validation loss: 2.3577899450626756

Epoch: 6| Step: 6
Training loss: 1.051876135840797
Validation loss: 2.3771875817090864

Epoch: 6| Step: 7
Training loss: 0.8688960384872592
Validation loss: 2.305886340472076

Epoch: 6| Step: 8
Training loss: 0.9633967247623572
Validation loss: 2.4136694637868636

Epoch: 6| Step: 9
Training loss: 1.9654298670329964
Validation loss: 2.3866096838073774

Epoch: 6| Step: 10
Training loss: 0.766079047892735
Validation loss: 2.4388659667240393

Epoch: 6| Step: 11
Training loss: 1.1042950873399264
Validation loss: 2.389702415365424

Epoch: 6| Step: 12
Training loss: 0.7219129296448664
Validation loss: 2.4324723510567057

Epoch: 6| Step: 13
Training loss: 1.1241872288656987
Validation loss: 2.390026358858405

Epoch: 421| Step: 0
Training loss: 1.1491325506872878
Validation loss: 2.3486918742172103

Epoch: 6| Step: 1
Training loss: 2.005912267476021
Validation loss: 2.377678813858058

Epoch: 6| Step: 2
Training loss: 1.0400651382257866
Validation loss: 2.4497483685328856

Epoch: 6| Step: 3
Training loss: 1.0704749882006395
Validation loss: 2.3598650096343476

Epoch: 6| Step: 4
Training loss: 0.9407595870852176
Validation loss: 2.3317621575019314

Epoch: 6| Step: 5
Training loss: 1.3218069252900557
Validation loss: 2.32426672279579

Epoch: 6| Step: 6
Training loss: 0.7824849857925216
Validation loss: 2.3328483486971363

Epoch: 6| Step: 7
Training loss: 1.164059018123463
Validation loss: 2.336088913620278

Epoch: 6| Step: 8
Training loss: 1.2932641651315069
Validation loss: 2.3650417879990653

Epoch: 6| Step: 9
Training loss: 0.9549709018049017
Validation loss: 2.3596425585556617

Epoch: 6| Step: 10
Training loss: 1.1534399476047323
Validation loss: 2.3831550727105313

Epoch: 6| Step: 11
Training loss: 1.0935293792559477
Validation loss: 2.3614882320214976

Epoch: 6| Step: 12
Training loss: 0.8334463201856382
Validation loss: 2.4203816234659423

Epoch: 6| Step: 13
Training loss: 0.46097747176828757
Validation loss: 2.370970784504093

Epoch: 422| Step: 0
Training loss: 1.9647165791971792
Validation loss: 2.3982026920255457

Epoch: 6| Step: 1
Training loss: 0.9684357287183617
Validation loss: 2.4034353152548977

Epoch: 6| Step: 2
Training loss: 1.2466913303104699
Validation loss: 2.3526831121411473

Epoch: 6| Step: 3
Training loss: 0.7393335583279161
Validation loss: 2.417147069571522

Epoch: 6| Step: 4
Training loss: 0.696058623073016
Validation loss: 2.3193045104336574

Epoch: 6| Step: 5
Training loss: 1.2702414066930214
Validation loss: 2.3563206996708583

Epoch: 6| Step: 6
Training loss: 1.181195438477221
Validation loss: 2.377106832569106

Epoch: 6| Step: 7
Training loss: 1.0064649222070179
Validation loss: 2.4331264146873224

Epoch: 6| Step: 8
Training loss: 0.7512313351081804
Validation loss: 2.360225294732237

Epoch: 6| Step: 9
Training loss: 1.0411110095328606
Validation loss: 2.4124153694067956

Epoch: 6| Step: 10
Training loss: 1.3212620407465312
Validation loss: 2.3571397373788052

Epoch: 6| Step: 11
Training loss: 0.866871956817852
Validation loss: 2.386969060178034

Epoch: 6| Step: 12
Training loss: 1.1209284962998927
Validation loss: 2.3177389616887973

Epoch: 6| Step: 13
Training loss: 1.313262400131606
Validation loss: 2.3230918989429554

Epoch: 423| Step: 0
Training loss: 0.7207241313736564
Validation loss: 2.3567074230698766

Epoch: 6| Step: 1
Training loss: 0.8324327887934431
Validation loss: 2.4177837671821725

Epoch: 6| Step: 2
Training loss: 0.9011248658564173
Validation loss: 2.365195723366571

Epoch: 6| Step: 3
Training loss: 1.3688267063612287
Validation loss: 2.442530644031944

Epoch: 6| Step: 4
Training loss: 0.8045871635028448
Validation loss: 2.391533988391559

Epoch: 6| Step: 5
Training loss: 1.9248463680838812
Validation loss: 2.3291860203835304

Epoch: 6| Step: 6
Training loss: 1.4097220050746873
Validation loss: 2.3599446057394835

Epoch: 6| Step: 7
Training loss: 0.8856058404824662
Validation loss: 2.3828713008861464

Epoch: 6| Step: 8
Training loss: 1.030845620604556
Validation loss: 2.3100371678183813

Epoch: 6| Step: 9
Training loss: 1.004730657952773
Validation loss: 2.3294395919171675

Epoch: 6| Step: 10
Training loss: 0.950755786162952
Validation loss: 2.3692236463773586

Epoch: 6| Step: 11
Training loss: 1.3319331158149712
Validation loss: 2.3103047904274203

Epoch: 6| Step: 12
Training loss: 1.065859028911863
Validation loss: 2.310958778850093

Epoch: 6| Step: 13
Training loss: 0.5587861590025001
Validation loss: 2.398806562103917

Epoch: 424| Step: 0
Training loss: 1.0480741209397852
Validation loss: 2.2792954735602624

Epoch: 6| Step: 1
Training loss: 0.8214872395551206
Validation loss: 2.3080242270615994

Epoch: 6| Step: 2
Training loss: 0.6530884928744296
Validation loss: 2.404972740508173

Epoch: 6| Step: 3
Training loss: 1.1605167021628082
Validation loss: 2.308861047477595

Epoch: 6| Step: 4
Training loss: 1.0169814807964892
Validation loss: 2.402967924262555

Epoch: 6| Step: 5
Training loss: 0.6747765100450711
Validation loss: 2.3374769303448684

Epoch: 6| Step: 6
Training loss: 1.0155232305156388
Validation loss: 2.3677837398382495

Epoch: 6| Step: 7
Training loss: 1.4075331026456661
Validation loss: 2.3589767720856134

Epoch: 6| Step: 8
Training loss: 1.3329299177389777
Validation loss: 2.3688711966726905

Epoch: 6| Step: 9
Training loss: 1.9546210700806306
Validation loss: 2.3834277201517677

Epoch: 6| Step: 10
Training loss: 0.7112182230630453
Validation loss: 2.351622019044413

Epoch: 6| Step: 11
Training loss: 1.3489931413831047
Validation loss: 2.3417420611131634

Epoch: 6| Step: 12
Training loss: 1.2527478532865999
Validation loss: 2.351245070361777

Epoch: 6| Step: 13
Training loss: 1.3182268090178668
Validation loss: 2.387133392782298

Epoch: 425| Step: 0
Training loss: 0.8048464423675028
Validation loss: 2.437302579581106

Epoch: 6| Step: 1
Training loss: 1.2997805208385682
Validation loss: 2.403179801101541

Epoch: 6| Step: 2
Training loss: 1.8247203586531622
Validation loss: 2.3323739444616867

Epoch: 6| Step: 3
Training loss: 1.126461668964967
Validation loss: 2.357560752519357

Epoch: 6| Step: 4
Training loss: 1.0488325008819621
Validation loss: 2.385560295537271

Epoch: 6| Step: 5
Training loss: 0.7270619306356332
Validation loss: 2.3596553699741527

Epoch: 6| Step: 6
Training loss: 0.9008706689473508
Validation loss: 2.3346099818272332

Epoch: 6| Step: 7
Training loss: 1.2090681845067204
Validation loss: 2.363762028821356

Epoch: 6| Step: 8
Training loss: 0.837692272832705
Validation loss: 2.307120878500036

Epoch: 6| Step: 9
Training loss: 1.035127920086983
Validation loss: 2.3152420274384737

Epoch: 6| Step: 10
Training loss: 1.4026052077164761
Validation loss: 2.3697512419799125

Epoch: 6| Step: 11
Training loss: 0.7522522170495946
Validation loss: 2.3376374788661587

Epoch: 6| Step: 12
Training loss: 1.2244145726677336
Validation loss: 2.416092501726601

Epoch: 6| Step: 13
Training loss: 0.8541613826743341
Validation loss: 2.3456952003016656

Epoch: 426| Step: 0
Training loss: 1.3296652445740522
Validation loss: 2.3219806939955316

Epoch: 6| Step: 1
Training loss: 1.263464366731916
Validation loss: 2.281228987883162

Epoch: 6| Step: 2
Training loss: 1.1463131102449104
Validation loss: 2.431158683899461

Epoch: 6| Step: 3
Training loss: 0.9532150788812553
Validation loss: 2.418407571264484

Epoch: 6| Step: 4
Training loss: 0.9606594210571396
Validation loss: 2.3460762691832397

Epoch: 6| Step: 5
Training loss: 0.9223921666789543
Validation loss: 2.4465594922560805

Epoch: 6| Step: 6
Training loss: 1.9334890626253225
Validation loss: 2.3400988233218474

Epoch: 6| Step: 7
Training loss: 0.7645388313945101
Validation loss: 2.339863081499601

Epoch: 6| Step: 8
Training loss: 1.1603762228656356
Validation loss: 2.4082941285726336

Epoch: 6| Step: 9
Training loss: 0.8931281400589305
Validation loss: 2.3835757841376934

Epoch: 6| Step: 10
Training loss: 0.9198735704313694
Validation loss: 2.3207602313565427

Epoch: 6| Step: 11
Training loss: 0.8379127837409963
Validation loss: 2.3897047679851937

Epoch: 6| Step: 12
Training loss: 0.6162427117185617
Validation loss: 2.3628112678199065

Epoch: 6| Step: 13
Training loss: 1.4882634679978548
Validation loss: 2.3274260652299965

Epoch: 427| Step: 0
Training loss: 1.1139031530329973
Validation loss: 2.4401638261723524

Epoch: 6| Step: 1
Training loss: 0.7837255547709995
Validation loss: 2.335294132198388

Epoch: 6| Step: 2
Training loss: 1.2189484948127574
Validation loss: 2.4156040731091717

Epoch: 6| Step: 3
Training loss: 0.8151216027748134
Validation loss: 2.310863940476751

Epoch: 6| Step: 4
Training loss: 1.0995033985517366
Validation loss: 2.337889899076235

Epoch: 6| Step: 5
Training loss: 0.9811587394505142
Validation loss: 2.406990121760843

Epoch: 6| Step: 6
Training loss: 1.3546836844173846
Validation loss: 2.3294797387074104

Epoch: 6| Step: 7
Training loss: 0.7601836165297838
Validation loss: 2.297504513737545

Epoch: 6| Step: 8
Training loss: 0.9927117171868649
Validation loss: 2.4000814867542517

Epoch: 6| Step: 9
Training loss: 1.8084325862782828
Validation loss: 2.355832544398305

Epoch: 6| Step: 10
Training loss: 1.0705330057699627
Validation loss: 2.3442324748151675

Epoch: 6| Step: 11
Training loss: 1.1588175335640987
Validation loss: 2.324767422563185

Epoch: 6| Step: 12
Training loss: 1.0155056223035173
Validation loss: 2.373738203041586

Epoch: 6| Step: 13
Training loss: 1.0236684524046877
Validation loss: 2.4149097474865537

Epoch: 428| Step: 0
Training loss: 1.3881224928433493
Validation loss: 2.361903646835861

Epoch: 6| Step: 1
Training loss: 0.9796604000644806
Validation loss: 2.278515375062209

Epoch: 6| Step: 2
Training loss: 0.8700378244771693
Validation loss: 2.246802169986575

Epoch: 6| Step: 3
Training loss: 0.8918770472096056
Validation loss: 2.351256675294887

Epoch: 6| Step: 4
Training loss: 0.9718276021506331
Validation loss: 2.348822624670643

Epoch: 6| Step: 5
Training loss: 0.9160746411017845
Validation loss: 2.392411067405006

Epoch: 6| Step: 6
Training loss: 0.8879278400910919
Validation loss: 2.301766145750531

Epoch: 6| Step: 7
Training loss: 1.2519022295957205
Validation loss: 2.385392937222239

Epoch: 6| Step: 8
Training loss: 0.8058143799165979
Validation loss: 2.4234532258224544

Epoch: 6| Step: 9
Training loss: 0.5872054305087294
Validation loss: 2.389264529212426

Epoch: 6| Step: 10
Training loss: 0.9841818847147221
Validation loss: 2.3204700798608395

Epoch: 6| Step: 11
Training loss: 2.0697840753987875
Validation loss: 2.4122287236636124

Epoch: 6| Step: 12
Training loss: 1.37883509811669
Validation loss: 2.347403874141613

Epoch: 6| Step: 13
Training loss: 0.6284989169254849
Validation loss: 2.3208598205441757

Epoch: 429| Step: 0
Training loss: 1.0677089908256678
Validation loss: 2.3072570786707347

Epoch: 6| Step: 1
Training loss: 1.0038826193792885
Validation loss: 2.3569641432853214

Epoch: 6| Step: 2
Training loss: 0.5796875329030483
Validation loss: 2.240952229704869

Epoch: 6| Step: 3
Training loss: 0.9476428981510264
Validation loss: 2.299927530934869

Epoch: 6| Step: 4
Training loss: 0.7836843329850192
Validation loss: 2.30062013414325

Epoch: 6| Step: 5
Training loss: 0.9509925751621886
Validation loss: 2.2896188560119692

Epoch: 6| Step: 6
Training loss: 0.7754724108709301
Validation loss: 2.240218469446508

Epoch: 6| Step: 7
Training loss: 1.0801985330360875
Validation loss: 2.363414547282382

Epoch: 6| Step: 8
Training loss: 1.3374936148232608
Validation loss: 2.3339436197346033

Epoch: 6| Step: 9
Training loss: 1.1072594794364783
Validation loss: 2.301809718848363

Epoch: 6| Step: 10
Training loss: 0.9343005581293621
Validation loss: 2.351094896695858

Epoch: 6| Step: 11
Training loss: 1.115200703608648
Validation loss: 2.3877601371645625

Epoch: 6| Step: 12
Training loss: 2.1236835216515377
Validation loss: 2.2724253220279107

Epoch: 6| Step: 13
Training loss: 1.5128255730158475
Validation loss: 2.3368204409681517

Epoch: 430| Step: 0
Training loss: 1.1690413739116492
Validation loss: 2.318182379504805

Epoch: 6| Step: 1
Training loss: 0.6351522823270812
Validation loss: 2.3055871268929873

Epoch: 6| Step: 2
Training loss: 1.1522951277480455
Validation loss: 2.4143609765316003

Epoch: 6| Step: 3
Training loss: 1.1094671399174378
Validation loss: 2.318896813091715

Epoch: 6| Step: 4
Training loss: 0.7278999406464735
Validation loss: 2.361644583106365

Epoch: 6| Step: 5
Training loss: 1.0677151873608925
Validation loss: 2.3753749635612365

Epoch: 6| Step: 6
Training loss: 1.80251442341318
Validation loss: 2.3797160928720644

Epoch: 6| Step: 7
Training loss: 0.9672133656434139
Validation loss: 2.375264794744057

Epoch: 6| Step: 8
Training loss: 1.1165803980360394
Validation loss: 2.3776731365286374

Epoch: 6| Step: 9
Training loss: 1.0188168181991355
Validation loss: 2.349250048656121

Epoch: 6| Step: 10
Training loss: 0.9159528308159346
Validation loss: 2.3454895826713957

Epoch: 6| Step: 11
Training loss: 0.9705682733764339
Validation loss: 2.3534649892125565

Epoch: 6| Step: 12
Training loss: 0.8859817197821217
Validation loss: 2.2704510246070697

Epoch: 6| Step: 13
Training loss: 1.3250450774388292
Validation loss: 2.3317364364302344

Epoch: 431| Step: 0
Training loss: 1.1762678083800686
Validation loss: 2.30479789345747

Epoch: 6| Step: 1
Training loss: 0.7141534359246826
Validation loss: 2.4289961446776585

Epoch: 6| Step: 2
Training loss: 2.028590412549968
Validation loss: 2.377867882587345

Epoch: 6| Step: 3
Training loss: 1.1526283042139696
Validation loss: 2.380819107726368

Epoch: 6| Step: 4
Training loss: 1.0102977420520745
Validation loss: 2.307357354561118

Epoch: 6| Step: 5
Training loss: 1.0209798642824763
Validation loss: 2.3651813919694513

Epoch: 6| Step: 6
Training loss: 1.4012007877035102
Validation loss: 2.362946660584306

Epoch: 6| Step: 7
Training loss: 0.7425000787343199
Validation loss: 2.325779437689823

Epoch: 6| Step: 8
Training loss: 0.9549194079241389
Validation loss: 2.329050460870192

Epoch: 6| Step: 9
Training loss: 1.2734410572587394
Validation loss: 2.3478603970767433

Epoch: 6| Step: 10
Training loss: 0.807814217718722
Validation loss: 2.304418887389371

Epoch: 6| Step: 11
Training loss: 0.927668840201771
Validation loss: 2.2394514323086105

Epoch: 6| Step: 12
Training loss: 0.8119774385099064
Validation loss: 2.392295160158513

Epoch: 6| Step: 13
Training loss: 0.9590538605729391
Validation loss: 2.3016479303905264

Epoch: 432| Step: 0
Training loss: 1.0443745257994639
Validation loss: 2.357694438463334

Epoch: 6| Step: 1
Training loss: 1.5527225517926437
Validation loss: 2.3809345184409105

Epoch: 6| Step: 2
Training loss: 1.2327227580352773
Validation loss: 2.4109011528883157

Epoch: 6| Step: 3
Training loss: 0.7769078321570073
Validation loss: 2.322884216773548

Epoch: 6| Step: 4
Training loss: 2.0810533127048485
Validation loss: 2.40340839535301

Epoch: 6| Step: 5
Training loss: 0.8967336004888333
Validation loss: 2.327903083993599

Epoch: 6| Step: 6
Training loss: 0.6732283203184213
Validation loss: 2.31845953477278

Epoch: 6| Step: 7
Training loss: 1.0458461203433007
Validation loss: 2.27092856480026

Epoch: 6| Step: 8
Training loss: 1.3147333761797404
Validation loss: 2.3838891394180113

Epoch: 6| Step: 9
Training loss: 0.8110660958173278
Validation loss: 2.3676589891021482

Epoch: 6| Step: 10
Training loss: 0.796078152639465
Validation loss: 2.386900242747285

Epoch: 6| Step: 11
Training loss: 0.7639111390389449
Validation loss: 2.2995746839702633

Epoch: 6| Step: 12
Training loss: 0.6825940042250843
Validation loss: 2.3332716511412346

Epoch: 6| Step: 13
Training loss: 0.7274822443338912
Validation loss: 2.369990125746065

Epoch: 433| Step: 0
Training loss: 0.994415425090888
Validation loss: 2.336763565208011

Epoch: 6| Step: 1
Training loss: 1.1265859022103926
Validation loss: 2.3225915534977903

Epoch: 6| Step: 2
Training loss: 1.1355957566623074
Validation loss: 2.3320861844014766

Epoch: 6| Step: 3
Training loss: 1.0078574473685793
Validation loss: 2.3974563715211485

Epoch: 6| Step: 4
Training loss: 1.1637966185184172
Validation loss: 2.348655952068613

Epoch: 6| Step: 5
Training loss: 1.8583885589513458
Validation loss: 2.36602713934808

Epoch: 6| Step: 6
Training loss: 1.0002274850543826
Validation loss: 2.3393625891854795

Epoch: 6| Step: 7
Training loss: 1.0221423041563165
Validation loss: 2.4145830915698436

Epoch: 6| Step: 8
Training loss: 0.853117616502719
Validation loss: 2.311138518334341

Epoch: 6| Step: 9
Training loss: 1.1695243147222039
Validation loss: 2.3754670796186312

Epoch: 6| Step: 10
Training loss: 1.0767811679088897
Validation loss: 2.330829986703374

Epoch: 6| Step: 11
Training loss: 1.2391722929945874
Validation loss: 2.388254438957949

Epoch: 6| Step: 12
Training loss: 0.900020564692047
Validation loss: 2.339014707424993

Epoch: 6| Step: 13
Training loss: 1.172506442021809
Validation loss: 2.305987225720767

Epoch: 434| Step: 0
Training loss: 0.8563386857264075
Validation loss: 2.2832843712692763

Epoch: 6| Step: 1
Training loss: 0.8868914532630604
Validation loss: 2.3536952232105643

Epoch: 6| Step: 2
Training loss: 0.9116393681529861
Validation loss: 2.3126633854389893

Epoch: 6| Step: 3
Training loss: 1.1183461403338455
Validation loss: 2.3273921522545815

Epoch: 6| Step: 4
Training loss: 0.7881243577027331
Validation loss: 2.295935565852074

Epoch: 6| Step: 5
Training loss: 1.2601220388196994
Validation loss: 2.3473569967180232

Epoch: 6| Step: 6
Training loss: 0.7132537752941404
Validation loss: 2.373114807542069

Epoch: 6| Step: 7
Training loss: 0.5691181374782729
Validation loss: 2.3684011341575015

Epoch: 6| Step: 8
Training loss: 2.0052802002814034
Validation loss: 2.201106622185878

Epoch: 6| Step: 9
Training loss: 0.6493128647509028
Validation loss: 2.3825683527845074

Epoch: 6| Step: 10
Training loss: 0.9059192119540759
Validation loss: 2.291850223815676

Epoch: 6| Step: 11
Training loss: 1.4892914314852912
Validation loss: 2.344111236845134

Epoch: 6| Step: 12
Training loss: 0.9246679444612486
Validation loss: 2.3235843731990515

Epoch: 6| Step: 13
Training loss: 0.5433134453103857
Validation loss: 2.352614634849525

Epoch: 435| Step: 0
Training loss: 1.8920398808927554
Validation loss: 2.326359353153239

Epoch: 6| Step: 1
Training loss: 1.185339518328887
Validation loss: 2.380128624114268

Epoch: 6| Step: 2
Training loss: 0.8215961403849873
Validation loss: 2.3574674920183463

Epoch: 6| Step: 3
Training loss: 0.6496364585566148
Validation loss: 2.356970444251075

Epoch: 6| Step: 4
Training loss: 1.022919268841098
Validation loss: 2.2959958798598175

Epoch: 6| Step: 5
Training loss: 0.8824496578522163
Validation loss: 2.3018069394834937

Epoch: 6| Step: 6
Training loss: 1.109423031908865
Validation loss: 2.3468802022225663

Epoch: 6| Step: 7
Training loss: 0.8836668488530974
Validation loss: 2.3782529059204585

Epoch: 6| Step: 8
Training loss: 0.7701400439986875
Validation loss: 2.343763622394748

Epoch: 6| Step: 9
Training loss: 1.383418494594428
Validation loss: 2.3176543239279606

Epoch: 6| Step: 10
Training loss: 0.8626594202625604
Validation loss: 2.2919060430117875

Epoch: 6| Step: 11
Training loss: 0.60978894968039
Validation loss: 2.3152188517763093

Epoch: 6| Step: 12
Training loss: 1.22455267037215
Validation loss: 2.380258329477676

Epoch: 6| Step: 13
Training loss: 1.0579416441300737
Validation loss: 2.355378010168856

Epoch: 436| Step: 0
Training loss: 1.1877453199265087
Validation loss: 2.3407597641935682

Epoch: 6| Step: 1
Training loss: 0.7385953204882932
Validation loss: 2.4268137189552084

Epoch: 6| Step: 2
Training loss: 1.817546855527181
Validation loss: 2.3892215311708336

Epoch: 6| Step: 3
Training loss: 0.8920940864683421
Validation loss: 2.3688911294645

Epoch: 6| Step: 4
Training loss: 1.2275191542923731
Validation loss: 2.3568616634839814

Epoch: 6| Step: 5
Training loss: 1.1980931469937097
Validation loss: 2.3548656275044166

Epoch: 6| Step: 6
Training loss: 0.8542556871376146
Validation loss: 2.338724669417977

Epoch: 6| Step: 7
Training loss: 0.9631940816157241
Validation loss: 2.320171880205467

Epoch: 6| Step: 8
Training loss: 1.0882557884463726
Validation loss: 2.3668148473458204

Epoch: 6| Step: 9
Training loss: 0.9347650052111205
Validation loss: 2.304805558345699

Epoch: 6| Step: 10
Training loss: 0.572202763668961
Validation loss: 2.3029211328784367

Epoch: 6| Step: 11
Training loss: 1.062360025049216
Validation loss: 2.4033180350776684

Epoch: 6| Step: 12
Training loss: 1.2038550205705745
Validation loss: 2.284649102135512

Epoch: 6| Step: 13
Training loss: 0.6055999121572665
Validation loss: 2.3702427509247017

Epoch: 437| Step: 0
Training loss: 1.103193225858055
Validation loss: 2.3068519502358167

Epoch: 6| Step: 1
Training loss: 0.676303948032735
Validation loss: 2.274546050291844

Epoch: 6| Step: 2
Training loss: 0.9710681620362366
Validation loss: 2.3493741493719074

Epoch: 6| Step: 3
Training loss: 1.1352886629424106
Validation loss: 2.3347000964039255

Epoch: 6| Step: 4
Training loss: 0.8369102166353438
Validation loss: 2.3927782797954573

Epoch: 6| Step: 5
Training loss: 1.282472074178605
Validation loss: 2.360424041874097

Epoch: 6| Step: 6
Training loss: 0.6717525636761054
Validation loss: 2.2655375315606743

Epoch: 6| Step: 7
Training loss: 1.8622580863991132
Validation loss: 2.3089519549245194

Epoch: 6| Step: 8
Training loss: 1.071482554846875
Validation loss: 2.361475367581241

Epoch: 6| Step: 9
Training loss: 0.8431436691309817
Validation loss: 2.3884228966064818

Epoch: 6| Step: 10
Training loss: 0.7456254537985508
Validation loss: 2.369661410399747

Epoch: 6| Step: 11
Training loss: 1.41198476661051
Validation loss: 2.279318320519703

Epoch: 6| Step: 12
Training loss: 1.0294625946927163
Validation loss: 2.383741443347938

Epoch: 6| Step: 13
Training loss: 1.3100622335604486
Validation loss: 2.309700965580868

Epoch: 438| Step: 0
Training loss: 0.9139580300125327
Validation loss: 2.3520716947593505

Epoch: 6| Step: 1
Training loss: 0.8939113551318947
Validation loss: 2.3646889269494165

Epoch: 6| Step: 2
Training loss: 0.7212256628125286
Validation loss: 2.359805631682501

Epoch: 6| Step: 3
Training loss: 0.83094483847532
Validation loss: 2.3440468089532573

Epoch: 6| Step: 4
Training loss: 0.6841573952787381
Validation loss: 2.3326096683367235

Epoch: 6| Step: 5
Training loss: 0.7652788742236041
Validation loss: 2.327824533215365

Epoch: 6| Step: 6
Training loss: 1.2915193668586655
Validation loss: 2.450908681501477

Epoch: 6| Step: 7
Training loss: 0.7181822981190806
Validation loss: 2.3430663098125755

Epoch: 6| Step: 8
Training loss: 1.1648657158994253
Validation loss: 2.3485268799427086

Epoch: 6| Step: 9
Training loss: 1.140550689366877
Validation loss: 2.348634152372272

Epoch: 6| Step: 10
Training loss: 0.9785330460571846
Validation loss: 2.4624121463358444

Epoch: 6| Step: 11
Training loss: 1.0315477346006658
Validation loss: 2.3104025395090724

Epoch: 6| Step: 12
Training loss: 1.1428092527147806
Validation loss: 2.3162623139408214

Epoch: 6| Step: 13
Training loss: 2.473909226314981
Validation loss: 2.3101889306913717

Epoch: 439| Step: 0
Training loss: 0.9611940429135404
Validation loss: 2.3301374457803563

Epoch: 6| Step: 1
Training loss: 1.1968522968579205
Validation loss: 2.3359032112348963

Epoch: 6| Step: 2
Training loss: 1.0506078867792186
Validation loss: 2.329027476548835

Epoch: 6| Step: 3
Training loss: 1.1872519685813663
Validation loss: 2.3005774428070302

Epoch: 6| Step: 4
Training loss: 1.1547925888370743
Validation loss: 2.3607658932106355

Epoch: 6| Step: 5
Training loss: 0.5567216245377359
Validation loss: 2.2827755823105362

Epoch: 6| Step: 6
Training loss: 0.8352035080873507
Validation loss: 2.3354540042018996

Epoch: 6| Step: 7
Training loss: 0.7302379141424171
Validation loss: 2.333494508980742

Epoch: 6| Step: 8
Training loss: 0.7721416522455626
Validation loss: 2.30276430706464

Epoch: 6| Step: 9
Training loss: 1.0410182015277978
Validation loss: 2.3550200124945393

Epoch: 6| Step: 10
Training loss: 0.8931603734223644
Validation loss: 2.3700426432380572

Epoch: 6| Step: 11
Training loss: 0.9322059563533854
Validation loss: 2.2482346955303147

Epoch: 6| Step: 12
Training loss: 1.9289726137755416
Validation loss: 2.385020201108562

Epoch: 6| Step: 13
Training loss: 0.6748579255452583
Validation loss: 2.298374014181954

Epoch: 440| Step: 0
Training loss: 0.5775538793836292
Validation loss: 2.3873958248584355

Epoch: 6| Step: 1
Training loss: 0.8755214363624059
Validation loss: 2.312670331433897

Epoch: 6| Step: 2
Training loss: 1.1285042756573862
Validation loss: 2.370263917627227

Epoch: 6| Step: 3
Training loss: 1.0383573161233857
Validation loss: 2.341201418197016

Epoch: 6| Step: 4
Training loss: 1.0044175564023425
Validation loss: 2.374148103250404

Epoch: 6| Step: 5
Training loss: 0.8473463766573276
Validation loss: 2.336370789230719

Epoch: 6| Step: 6
Training loss: 1.0459786748517528
Validation loss: 2.3663785977798315

Epoch: 6| Step: 7
Training loss: 1.0998201591691952
Validation loss: 2.371356595515205

Epoch: 6| Step: 8
Training loss: 0.7366694461186075
Validation loss: 2.3562617785841393

Epoch: 6| Step: 9
Training loss: 1.1820020390927046
Validation loss: 2.369483770530541

Epoch: 6| Step: 10
Training loss: 0.8786461678447588
Validation loss: 2.3275356676884966

Epoch: 6| Step: 11
Training loss: 1.9359204406232957
Validation loss: 2.3158020416836633

Epoch: 6| Step: 12
Training loss: 1.1677026860250577
Validation loss: 2.415353589532778

Epoch: 6| Step: 13
Training loss: 1.1680779549568603
Validation loss: 2.3487112900680667

Epoch: 441| Step: 0
Training loss: 0.9813894379306494
Validation loss: 2.2805712762445287

Epoch: 6| Step: 1
Training loss: 2.0203952379979047
Validation loss: 2.36299297486825

Epoch: 6| Step: 2
Training loss: 0.9729856369981458
Validation loss: 2.2952440867268096

Epoch: 6| Step: 3
Training loss: 0.7410004609707571
Validation loss: 2.3158523851136508

Epoch: 6| Step: 4
Training loss: 1.058823338910628
Validation loss: 2.234168443770862

Epoch: 6| Step: 5
Training loss: 0.7431427279604392
Validation loss: 2.324546230426133

Epoch: 6| Step: 6
Training loss: 1.2810203532523508
Validation loss: 2.330328592285069

Epoch: 6| Step: 7
Training loss: 0.9248103914014472
Validation loss: 2.3218936780129362

Epoch: 6| Step: 8
Training loss: 0.8828384260573604
Validation loss: 2.3065425686672025

Epoch: 6| Step: 9
Training loss: 1.0408984721324746
Validation loss: 2.306853867254487

Epoch: 6| Step: 10
Training loss: 1.1137490878973757
Validation loss: 2.306403834250163

Epoch: 6| Step: 11
Training loss: 1.0689106692181114
Validation loss: 2.2383384222679035

Epoch: 6| Step: 12
Training loss: 0.7047774077786747
Validation loss: 2.3047516850202734

Epoch: 6| Step: 13
Training loss: 0.4963860289069618
Validation loss: 2.3198850808502147

Epoch: 442| Step: 0
Training loss: 1.0174706927678456
Validation loss: 2.3207947239693048

Epoch: 6| Step: 1
Training loss: 0.8599791050745687
Validation loss: 2.356727539781636

Epoch: 6| Step: 2
Training loss: 0.8919638224736509
Validation loss: 2.329470036496855

Epoch: 6| Step: 3
Training loss: 0.8113707250689048
Validation loss: 2.3396226600884167

Epoch: 6| Step: 4
Training loss: 0.9544977089987787
Validation loss: 2.355071751306382

Epoch: 6| Step: 5
Training loss: 1.269793204644857
Validation loss: 2.353438580231901

Epoch: 6| Step: 6
Training loss: 1.1439039574902221
Validation loss: 2.376567582848837

Epoch: 6| Step: 7
Training loss: 0.6648737720206349
Validation loss: 2.4005951326827932

Epoch: 6| Step: 8
Training loss: 1.863003628119613
Validation loss: 2.307338678472754

Epoch: 6| Step: 9
Training loss: 0.816867241913804
Validation loss: 2.3420661275361443

Epoch: 6| Step: 10
Training loss: 0.6579391901156327
Validation loss: 2.3344106457842932

Epoch: 6| Step: 11
Training loss: 1.1304474971647867
Validation loss: 2.3874249725330237

Epoch: 6| Step: 12
Training loss: 1.0421682421779472
Validation loss: 2.3339156253406825

Epoch: 6| Step: 13
Training loss: 1.1091937602111477
Validation loss: 2.3888414370192987

Epoch: 443| Step: 0
Training loss: 0.9898799585525788
Validation loss: 2.3842066610078674

Epoch: 6| Step: 1
Training loss: 2.054869553075686
Validation loss: 2.3174001122151795

Epoch: 6| Step: 2
Training loss: 1.0748137334865442
Validation loss: 2.3352822377151012

Epoch: 6| Step: 3
Training loss: 1.214097704677676
Validation loss: 2.367322937033848

Epoch: 6| Step: 4
Training loss: 0.9086735645246012
Validation loss: 2.322454888258154

Epoch: 6| Step: 5
Training loss: 0.8255979018633819
Validation loss: 2.311987395206853

Epoch: 6| Step: 6
Training loss: 0.965084555533543
Validation loss: 2.3631169348049634

Epoch: 6| Step: 7
Training loss: 0.8877563455581009
Validation loss: 2.413280347741739

Epoch: 6| Step: 8
Training loss: 1.3382236929306184
Validation loss: 2.3763025119908656

Epoch: 6| Step: 9
Training loss: 1.0559043928309142
Validation loss: 2.3197740018532955

Epoch: 6| Step: 10
Training loss: 0.6044002087058762
Validation loss: 2.312911152561132

Epoch: 6| Step: 11
Training loss: 0.9978030031865157
Validation loss: 2.328537074166515

Epoch: 6| Step: 12
Training loss: 0.86243248550878
Validation loss: 2.339146370334595

Epoch: 6| Step: 13
Training loss: 0.7008802184578575
Validation loss: 2.328939930195304

Epoch: 444| Step: 0
Training loss: 0.801633948400636
Validation loss: 2.294164919811218

Epoch: 6| Step: 1
Training loss: 1.0701059852232375
Validation loss: 2.2766913236825275

Epoch: 6| Step: 2
Training loss: 0.8343867954749108
Validation loss: 2.2837928897236908

Epoch: 6| Step: 3
Training loss: 1.0552214789568086
Validation loss: 2.2925833456297613

Epoch: 6| Step: 4
Training loss: 0.8213721561014011
Validation loss: 2.3204396680064368

Epoch: 6| Step: 5
Training loss: 1.1226510320554137
Validation loss: 2.2964995803389487

Epoch: 6| Step: 6
Training loss: 1.950275998268293
Validation loss: 2.3142443571289015

Epoch: 6| Step: 7
Training loss: 0.9566103885680719
Validation loss: 2.31138350193858

Epoch: 6| Step: 8
Training loss: 1.2898113503132822
Validation loss: 2.3136781985304564

Epoch: 6| Step: 9
Training loss: 0.7449666242355932
Validation loss: 2.344014282639709

Epoch: 6| Step: 10
Training loss: 1.0433969368809053
Validation loss: 2.3264400278404183

Epoch: 6| Step: 11
Training loss: 0.9542292467498484
Validation loss: 2.296036250776223

Epoch: 6| Step: 12
Training loss: 0.8865409034139687
Validation loss: 2.273028877527561

Epoch: 6| Step: 13
Training loss: 0.7737969998334795
Validation loss: 2.337985003038857

Epoch: 445| Step: 0
Training loss: 1.132456756507235
Validation loss: 2.334892877023657

Epoch: 6| Step: 1
Training loss: 0.827622315047967
Validation loss: 2.3984372969128898

Epoch: 6| Step: 2
Training loss: 0.740973956153634
Validation loss: 2.3729234132697195

Epoch: 6| Step: 3
Training loss: 0.9343481168420031
Validation loss: 2.3915192922427897

Epoch: 6| Step: 4
Training loss: 1.058165685386361
Validation loss: 2.401125674844243

Epoch: 6| Step: 5
Training loss: 1.1503130072167937
Validation loss: 2.344978340971244

Epoch: 6| Step: 6
Training loss: 1.7330040539464624
Validation loss: 2.366859159573517

Epoch: 6| Step: 7
Training loss: 0.6877500989477765
Validation loss: 2.3697384364602208

Epoch: 6| Step: 8
Training loss: 1.0271818084141318
Validation loss: 2.389566371429211

Epoch: 6| Step: 9
Training loss: 1.5058335674365224
Validation loss: 2.3598355731532568

Epoch: 6| Step: 10
Training loss: 0.7540094176546644
Validation loss: 2.353778217562096

Epoch: 6| Step: 11
Training loss: 0.6093656343571776
Validation loss: 2.3627112201247655

Epoch: 6| Step: 12
Training loss: 0.6495233200062674
Validation loss: 2.255672291064915

Epoch: 6| Step: 13
Training loss: 0.6577712093632462
Validation loss: 2.388801536106081

Epoch: 446| Step: 0
Training loss: 1.118881381967341
Validation loss: 2.3378006328594627

Epoch: 6| Step: 1
Training loss: 0.8517455857870441
Validation loss: 2.3553195961176367

Epoch: 6| Step: 2
Training loss: 0.9804864707044492
Validation loss: 2.362021006901118

Epoch: 6| Step: 3
Training loss: 1.0415471707786015
Validation loss: 2.2421520027825745

Epoch: 6| Step: 4
Training loss: 1.0045505934677585
Validation loss: 2.300088498025594

Epoch: 6| Step: 5
Training loss: 0.8692109154556104
Validation loss: 2.261492765982062

Epoch: 6| Step: 6
Training loss: 0.9858792029313338
Validation loss: 2.3569469903897

Epoch: 6| Step: 7
Training loss: 0.6225337004827083
Validation loss: 2.3314414921153963

Epoch: 6| Step: 8
Training loss: 1.0580179260119817
Validation loss: 2.3526157087471504

Epoch: 6| Step: 9
Training loss: 0.8063255969542827
Validation loss: 2.309048784248684

Epoch: 6| Step: 10
Training loss: 0.9555488783642501
Validation loss: 2.2960682737821685

Epoch: 6| Step: 11
Training loss: 1.0929043906992861
Validation loss: 2.3206474129061636

Epoch: 6| Step: 12
Training loss: 0.9321136873020952
Validation loss: 2.3067640223785157

Epoch: 6| Step: 13
Training loss: 2.2925325202923297
Validation loss: 2.3557985794856915

Epoch: 447| Step: 0
Training loss: 0.6060065065607444
Validation loss: 2.3284941118667652

Epoch: 6| Step: 1
Training loss: 1.0534837423046892
Validation loss: 2.345364414527638

Epoch: 6| Step: 2
Training loss: 0.9439247601112918
Validation loss: 2.331386261020165

Epoch: 6| Step: 3
Training loss: 1.1360115919126172
Validation loss: 2.2972102235558247

Epoch: 6| Step: 4
Training loss: 1.1035662884180266
Validation loss: 2.2859496495117315

Epoch: 6| Step: 5
Training loss: 1.0370817306483693
Validation loss: 2.3273704028812254

Epoch: 6| Step: 6
Training loss: 0.6671654851707475
Validation loss: 2.3493569765252724

Epoch: 6| Step: 7
Training loss: 1.139810872535236
Validation loss: 2.381693269499563

Epoch: 6| Step: 8
Training loss: 0.7383300119272216
Validation loss: 2.3530762915385557

Epoch: 6| Step: 9
Training loss: 0.8927884845220874
Validation loss: 2.3416894814901577

Epoch: 6| Step: 10
Training loss: 0.8133544463859407
Validation loss: 2.2288430538431205

Epoch: 6| Step: 11
Training loss: 0.9329900026368418
Validation loss: 2.318107572991285

Epoch: 6| Step: 12
Training loss: 1.9201219208074733
Validation loss: 2.3553919005444888

Epoch: 6| Step: 13
Training loss: 0.844890847520427
Validation loss: 2.3863044933646376

Epoch: 448| Step: 0
Training loss: 0.7986134284902665
Validation loss: 2.341052276272457

Epoch: 6| Step: 1
Training loss: 0.8605428909438103
Validation loss: 2.2454075620897385

Epoch: 6| Step: 2
Training loss: 0.8321234781790856
Validation loss: 2.3564929711110283

Epoch: 6| Step: 3
Training loss: 0.742385998332417
Validation loss: 2.3094345790002566

Epoch: 6| Step: 4
Training loss: 0.7920471247611516
Validation loss: 2.373477856041561

Epoch: 6| Step: 5
Training loss: 1.3283150032115718
Validation loss: 2.3101823550931586

Epoch: 6| Step: 6
Training loss: 0.8637780878603885
Validation loss: 2.312349502468747

Epoch: 6| Step: 7
Training loss: 1.0184883834895524
Validation loss: 2.326715824020907

Epoch: 6| Step: 8
Training loss: 1.9454011092629795
Validation loss: 2.3499201760821844

Epoch: 6| Step: 9
Training loss: 1.3237469037877976
Validation loss: 2.2903377770620668

Epoch: 6| Step: 10
Training loss: 0.6230403218178832
Validation loss: 2.328441869470202

Epoch: 6| Step: 11
Training loss: 0.7070113964349325
Validation loss: 2.294811954907324

Epoch: 6| Step: 12
Training loss: 0.8344847989077777
Validation loss: 2.2933827479084514

Epoch: 6| Step: 13
Training loss: 1.0108567619805895
Validation loss: 2.294256102845566

Epoch: 449| Step: 0
Training loss: 1.056366156787847
Validation loss: 2.3817296117861257

Epoch: 6| Step: 1
Training loss: 0.9015310681977697
Validation loss: 2.3198048003821774

Epoch: 6| Step: 2
Training loss: 1.0043679448504859
Validation loss: 2.276671757564523

Epoch: 6| Step: 3
Training loss: 0.8286381337311428
Validation loss: 2.3317260591956535

Epoch: 6| Step: 4
Training loss: 0.8668842988454032
Validation loss: 2.333395853464856

Epoch: 6| Step: 5
Training loss: 1.2030311646963228
Validation loss: 2.3650609070315447

Epoch: 6| Step: 6
Training loss: 1.7897909089192923
Validation loss: 2.378783148419384

Epoch: 6| Step: 7
Training loss: 0.6335377951866142
Validation loss: 2.2331338342753555

Epoch: 6| Step: 8
Training loss: 0.8156157321330304
Validation loss: 2.3076669507280863

Epoch: 6| Step: 9
Training loss: 0.8726887149628851
Validation loss: 2.3269025289967837

Epoch: 6| Step: 10
Training loss: 0.9025294125273645
Validation loss: 2.390531282453222

Epoch: 6| Step: 11
Training loss: 1.2129141149534437
Validation loss: 2.302108730171803

Epoch: 6| Step: 12
Training loss: 0.7176466226461478
Validation loss: 2.329987309580764

Epoch: 6| Step: 13
Training loss: 0.9043956727338993
Validation loss: 2.2897919766411627

Epoch: 450| Step: 0
Training loss: 1.7720391226081418
Validation loss: 2.3179312240830274

Epoch: 6| Step: 1
Training loss: 0.695998635520913
Validation loss: 2.376886506922929

Epoch: 6| Step: 2
Training loss: 1.189761568113015
Validation loss: 2.397105211002335

Epoch: 6| Step: 3
Training loss: 0.6688304719013736
Validation loss: 2.30800269393876

Epoch: 6| Step: 4
Training loss: 0.9103780975435759
Validation loss: 2.3954710020749443

Epoch: 6| Step: 5
Training loss: 0.8539536528417583
Validation loss: 2.3331317272487992

Epoch: 6| Step: 6
Training loss: 1.0125645228419229
Validation loss: 2.314008339477985

Epoch: 6| Step: 7
Training loss: 1.0745159500983157
Validation loss: 2.3485282968328325

Epoch: 6| Step: 8
Training loss: 0.8716732543735277
Validation loss: 2.3725221766255298

Epoch: 6| Step: 9
Training loss: 0.8713826269292902
Validation loss: 2.305655132908674

Epoch: 6| Step: 10
Training loss: 1.0583854554825545
Validation loss: 2.3073980805535634

Epoch: 6| Step: 11
Training loss: 0.7532302909473049
Validation loss: 2.285558185089557

Epoch: 6| Step: 12
Training loss: 0.9967380310002067
Validation loss: 2.3020821009294687

Epoch: 6| Step: 13
Training loss: 0.881752018616077
Validation loss: 2.3401216999976295

Testing loss: 3.1167767646369082
