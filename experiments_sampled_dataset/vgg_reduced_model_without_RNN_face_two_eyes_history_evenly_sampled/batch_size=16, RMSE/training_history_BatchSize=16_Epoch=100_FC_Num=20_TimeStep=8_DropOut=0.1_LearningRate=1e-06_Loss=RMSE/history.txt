Epoch: 1| Step: 0
Training loss: 5.289327369717992
Validation loss: 6.298048545937209

Epoch: 6| Step: 1
Training loss: 5.5850607444034805
Validation loss: 6.294166788061136

Epoch: 6| Step: 2
Training loss: 6.736848806076733
Validation loss: 6.290023150073495

Epoch: 6| Step: 3
Training loss: 6.458179037240357
Validation loss: 6.284830877373695

Epoch: 6| Step: 4
Training loss: 5.227255098215163
Validation loss: 6.283103392304963

Epoch: 6| Step: 5
Training loss: 6.178923240114459
Validation loss: 6.27621593074269

Epoch: 6| Step: 6
Training loss: 6.6307167004164524
Validation loss: 6.27266032693789

Epoch: 6| Step: 7
Training loss: 5.907398899293249
Validation loss: 6.267334916339742

Epoch: 6| Step: 8
Training loss: 6.639938498522419
Validation loss: 6.26368950543001

Epoch: 6| Step: 9
Training loss: 6.335437759653654
Validation loss: 6.260281158919568

Epoch: 6| Step: 10
Training loss: 6.625132145553394
Validation loss: 6.256291044931055

Epoch: 6| Step: 11
Training loss: 6.498685850665851
Validation loss: 6.2520437791605925

Epoch: 6| Step: 12
Training loss: 5.991544805922506
Validation loss: 6.244717061310775

Epoch: 6| Step: 13
Training loss: 8.324963855378556
Validation loss: 6.241610784072511

Epoch: 2| Step: 0
Training loss: 7.442350969395367
Validation loss: 6.237562339932008

Epoch: 6| Step: 1
Training loss: 5.913858669704102
Validation loss: 6.233699630723677

Epoch: 6| Step: 2
Training loss: 6.403898375067593
Validation loss: 6.229442799247634

Epoch: 6| Step: 3
Training loss: 5.578811218623293
Validation loss: 6.223825702720609

Epoch: 6| Step: 4
Training loss: 6.5323111662231215
Validation loss: 6.223814385139187

Epoch: 6| Step: 5
Training loss: 7.06308008022892
Validation loss: 6.217659585720595

Epoch: 6| Step: 6
Training loss: 6.226787338122222
Validation loss: 6.212682737264841

Epoch: 6| Step: 7
Training loss: 6.347694110464014
Validation loss: 6.207786380151057

Epoch: 6| Step: 8
Training loss: 7.282184851886212
Validation loss: 6.203843050997945

Epoch: 6| Step: 9
Training loss: 5.285309264229927
Validation loss: 6.198792396143697

Epoch: 6| Step: 10
Training loss: 6.034303830881295
Validation loss: 6.194411932398874

Epoch: 6| Step: 11
Training loss: 4.9262443403450105
Validation loss: 6.189907013078086

Epoch: 6| Step: 12
Training loss: 5.73600093231832
Validation loss: 6.186959652526058

Epoch: 6| Step: 13
Training loss: 5.5629478017170815
Validation loss: 6.1830544642388725

Epoch: 3| Step: 0
Training loss: 5.725028172053023
Validation loss: 6.178109097861647

Epoch: 6| Step: 1
Training loss: 6.529884889297856
Validation loss: 6.174144515661928

Epoch: 6| Step: 2
Training loss: 5.240734461788215
Validation loss: 6.168555506162035

Epoch: 6| Step: 3
Training loss: 6.751129338486318
Validation loss: 6.166120787152948

Epoch: 6| Step: 4
Training loss: 6.441317713252207
Validation loss: 6.160670877959906

Epoch: 6| Step: 5
Training loss: 6.494708328099873
Validation loss: 6.157236617655542

Epoch: 6| Step: 6
Training loss: 5.615893982997853
Validation loss: 6.152881170923984

Epoch: 6| Step: 7
Training loss: 5.531114479603058
Validation loss: 6.147984673531843

Epoch: 6| Step: 8
Training loss: 5.609073896482046
Validation loss: 6.144278874882825

Epoch: 6| Step: 9
Training loss: 6.333600423434563
Validation loss: 6.138634135274891

Epoch: 6| Step: 10
Training loss: 6.3193014536273235
Validation loss: 6.1349661290640265

Epoch: 6| Step: 11
Training loss: 7.4389303418803205
Validation loss: 6.128685303578857

Epoch: 6| Step: 12
Training loss: 5.444618914310745
Validation loss: 6.125385465666291

Epoch: 6| Step: 13
Training loss: 6.712834650715863
Validation loss: 6.120358725837254

Epoch: 4| Step: 0
Training loss: 5.835040941527886
Validation loss: 6.11484208635363

Epoch: 6| Step: 1
Training loss: 5.866297343217694
Validation loss: 6.109042940792455

Epoch: 6| Step: 2
Training loss: 7.21434196871093
Validation loss: 6.10502318411329

Epoch: 6| Step: 3
Training loss: 7.440923335708454
Validation loss: 6.100275285689812

Epoch: 6| Step: 4
Training loss: 5.865283804528645
Validation loss: 6.094612151884732

Epoch: 6| Step: 5
Training loss: 6.347988573031606
Validation loss: 6.089474821051291

Epoch: 6| Step: 6
Training loss: 6.386153095172435
Validation loss: 6.084530560721621

Epoch: 6| Step: 7
Training loss: 5.678060894248919
Validation loss: 6.080376796513006

Epoch: 6| Step: 8
Training loss: 6.486381937163863
Validation loss: 6.073330321420559

Epoch: 6| Step: 9
Training loss: 4.8686579997976995
Validation loss: 6.067440023400237

Epoch: 6| Step: 10
Training loss: 5.882892906987014
Validation loss: 6.063780838432044

Epoch: 6| Step: 11
Training loss: 6.138478610145742
Validation loss: 6.055737970625286

Epoch: 6| Step: 12
Training loss: 4.9159739162538365
Validation loss: 6.0528974686716035

Epoch: 6| Step: 13
Training loss: 5.843628254810526
Validation loss: 6.0422793928084735

Epoch: 5| Step: 0
Training loss: 6.026303491424238
Validation loss: 6.038305375140532

Epoch: 6| Step: 1
Training loss: 6.161617514541763
Validation loss: 6.031869552035411

Epoch: 6| Step: 2
Training loss: 5.430369294536867
Validation loss: 6.027071253782583

Epoch: 6| Step: 3
Training loss: 6.261098239587962
Validation loss: 6.022298767446349

Epoch: 6| Step: 4
Training loss: 6.077175350580171
Validation loss: 6.01650398522363

Epoch: 6| Step: 5
Training loss: 6.367372025700389
Validation loss: 6.009648734354354

Epoch: 6| Step: 6
Training loss: 5.897498373085564
Validation loss: 6.004148768268175

Epoch: 6| Step: 7
Training loss: 5.580371735471991
Validation loss: 5.9979520775619415

Epoch: 6| Step: 8
Training loss: 6.259834791447051
Validation loss: 5.9891634229907345

Epoch: 6| Step: 9
Training loss: 5.758326596791163
Validation loss: 5.984812376076563

Epoch: 6| Step: 10
Training loss: 6.191103107720763
Validation loss: 5.977989413886558

Epoch: 6| Step: 11
Training loss: 6.565650401731264
Validation loss: 5.9717780710319515

Epoch: 6| Step: 12
Training loss: 5.813084070537155
Validation loss: 5.965923557328767

Epoch: 6| Step: 13
Training loss: 5.639642603487242
Validation loss: 5.957884797087677

Epoch: 6| Step: 0
Training loss: 5.639826245167806
Validation loss: 5.951796440947029

Epoch: 6| Step: 1
Training loss: 6.615352876208329
Validation loss: 5.9452261620472475

Epoch: 6| Step: 2
Training loss: 6.5889116949780675
Validation loss: 5.937447451503061

Epoch: 6| Step: 3
Training loss: 6.358375564508276
Validation loss: 5.9303710626510515

Epoch: 6| Step: 4
Training loss: 5.675669008052253
Validation loss: 5.922537267228813

Epoch: 6| Step: 5
Training loss: 6.037037340843299
Validation loss: 5.916329546551411

Epoch: 6| Step: 6
Training loss: 6.195720105995423
Validation loss: 5.9089509025639835

Epoch: 6| Step: 7
Training loss: 5.710335633256034
Validation loss: 5.901660701178782

Epoch: 6| Step: 8
Training loss: 5.7365738397535955
Validation loss: 5.892065207322313

Epoch: 6| Step: 9
Training loss: 5.61708427408629
Validation loss: 5.886021548052859

Epoch: 6| Step: 10
Training loss: 6.233238632924338
Validation loss: 5.878460003342017

Epoch: 6| Step: 11
Training loss: 4.747261462574288
Validation loss: 5.87138882334642

Epoch: 6| Step: 12
Training loss: 5.77840110073763
Validation loss: 5.86385066169302

Epoch: 6| Step: 13
Training loss: 5.751935881765325
Validation loss: 5.855615603454482

Epoch: 7| Step: 0
Training loss: 7.13181607994377
Validation loss: 5.8516294291343725

Epoch: 6| Step: 1
Training loss: 5.274767988987429
Validation loss: 5.838864035892529

Epoch: 6| Step: 2
Training loss: 5.791240905188095
Validation loss: 5.833392398142598

Epoch: 6| Step: 3
Training loss: 5.751528329496431
Validation loss: 5.8257679195386

Epoch: 6| Step: 4
Training loss: 5.914673948741543
Validation loss: 5.814989163655256

Epoch: 6| Step: 5
Training loss: 5.73828125
Validation loss: 5.808443924591997

Epoch: 6| Step: 6
Training loss: 5.910528016232058
Validation loss: 5.801382331066332

Epoch: 6| Step: 7
Training loss: 6.12299547675796
Validation loss: 5.793100541493934

Epoch: 6| Step: 8
Training loss: 5.61978382278569
Validation loss: 5.78411193800112

Epoch: 6| Step: 9
Training loss: 5.792135681628542
Validation loss: 5.777594915787749

Epoch: 6| Step: 10
Training loss: 4.607782431446484
Validation loss: 5.766944533057721

Epoch: 6| Step: 11
Training loss: 5.122867047334721
Validation loss: 5.761946777369939

Epoch: 6| Step: 12
Training loss: 6.748561564579371
Validation loss: 5.748921125939474

Epoch: 6| Step: 13
Training loss: 5.387889931147095
Validation loss: 5.741490384500131

Epoch: 8| Step: 0
Training loss: 5.272315780583097
Validation loss: 5.73433412377094

Epoch: 6| Step: 1
Training loss: 6.078657818267288
Validation loss: 5.726555419562939

Epoch: 6| Step: 2
Training loss: 6.073770959177732
Validation loss: 5.715829782472913

Epoch: 6| Step: 3
Training loss: 6.147741954582733
Validation loss: 5.707471215512119

Epoch: 6| Step: 4
Training loss: 6.131573322259957
Validation loss: 5.69826081603967

Epoch: 6| Step: 5
Training loss: 5.281699979674439
Validation loss: 5.688093019058244

Epoch: 6| Step: 6
Training loss: 5.533918696008571
Validation loss: 5.67633495457622

Epoch: 6| Step: 7
Training loss: 6.693711008052721
Validation loss: 5.668135560599055

Epoch: 6| Step: 8
Training loss: 5.929276403116217
Validation loss: 5.656272201480917

Epoch: 6| Step: 9
Training loss: 4.615074435839561
Validation loss: 5.648398997404616

Epoch: 6| Step: 10
Training loss: 5.281076101114866
Validation loss: 5.637266348365677

Epoch: 6| Step: 11
Training loss: 5.316851281256329
Validation loss: 5.6279171797881595

Epoch: 6| Step: 12
Training loss: 4.939785971387347
Validation loss: 5.61771460462402

Epoch: 6| Step: 13
Training loss: 6.500284335446442
Validation loss: 5.605108409869175

Epoch: 9| Step: 0
Training loss: 5.495434339884735
Validation loss: 5.596343308672949

Epoch: 6| Step: 1
Training loss: 6.157253745107524
Validation loss: 5.587235294721164

Epoch: 6| Step: 2
Training loss: 6.445629727041804
Validation loss: 5.573933565203239

Epoch: 6| Step: 3
Training loss: 5.197270762868562
Validation loss: 5.565541446952208

Epoch: 6| Step: 4
Training loss: 5.846039838490061
Validation loss: 5.554312549847028

Epoch: 6| Step: 5
Training loss: 5.231134943454514
Validation loss: 5.542304252210888

Epoch: 6| Step: 6
Training loss: 5.096025017381999
Validation loss: 5.531596750465894

Epoch: 6| Step: 7
Training loss: 5.457462017994852
Validation loss: 5.52351830779845

Epoch: 6| Step: 8
Training loss: 5.66665956085358
Validation loss: 5.5090010590035865

Epoch: 6| Step: 9
Training loss: 5.832748747098347
Validation loss: 5.496216207965697

Epoch: 6| Step: 10
Training loss: 5.710826950986287
Validation loss: 5.486641801648105

Epoch: 6| Step: 11
Training loss: 5.35047409238711
Validation loss: 5.472204198384749

Epoch: 6| Step: 12
Training loss: 5.067952551712205
Validation loss: 5.460117150369514

Epoch: 6| Step: 13
Training loss: 4.6379855577804125
Validation loss: 5.452095475900529

Epoch: 10| Step: 0
Training loss: 5.415296449727174
Validation loss: 5.437714073333932

Epoch: 6| Step: 1
Training loss: 4.683209299275478
Validation loss: 5.4228078681445036

Epoch: 6| Step: 2
Training loss: 4.736009775061443
Validation loss: 5.413341277018821

Epoch: 6| Step: 3
Training loss: 5.413478010590103
Validation loss: 5.402066190670488

Epoch: 6| Step: 4
Training loss: 6.1639130432807825
Validation loss: 5.383844015990525

Epoch: 6| Step: 5
Training loss: 5.049876734673866
Validation loss: 5.37191711904447

Epoch: 6| Step: 6
Training loss: 5.47976377688081
Validation loss: 5.360156986623394

Epoch: 6| Step: 7
Training loss: 6.547678167563395
Validation loss: 5.349369629202294

Epoch: 6| Step: 8
Training loss: 4.966886158814597
Validation loss: 5.334294390546783

Epoch: 6| Step: 9
Training loss: 4.791598222768932
Validation loss: 5.319958105934675

Epoch: 6| Step: 10
Training loss: 6.38237291220738
Validation loss: 5.3064787703439205

Epoch: 6| Step: 11
Training loss: 5.160382828224849
Validation loss: 5.290623897444827

Epoch: 6| Step: 12
Training loss: 4.8240570411915655
Validation loss: 5.2796967555931245

Epoch: 6| Step: 13
Training loss: 5.428125477880304
Validation loss: 5.260439344430551

Epoch: 11| Step: 0
Training loss: 4.475403001423055
Validation loss: 5.25207714783614

Epoch: 6| Step: 1
Training loss: 6.208025248348371
Validation loss: 5.23495933370163

Epoch: 6| Step: 2
Training loss: 5.833300708497867
Validation loss: 5.221378408498531

Epoch: 6| Step: 3
Training loss: 4.103936022685526
Validation loss: 5.207685212530367

Epoch: 6| Step: 4
Training loss: 4.851605941897394
Validation loss: 5.19143304086671

Epoch: 6| Step: 5
Training loss: 5.153878331220804
Validation loss: 5.1798609561608515

Epoch: 6| Step: 6
Training loss: 5.183365610559839
Validation loss: 5.166638799321617

Epoch: 6| Step: 7
Training loss: 5.10171316955435
Validation loss: 5.146878017587505

Epoch: 6| Step: 8
Training loss: 5.459655349249875
Validation loss: 5.131985453501937

Epoch: 6| Step: 9
Training loss: 5.63933313850763
Validation loss: 5.116080691631337

Epoch: 6| Step: 10
Training loss: 5.387328093368335
Validation loss: 5.0975836298925525

Epoch: 6| Step: 11
Training loss: 5.452651213692172
Validation loss: 5.084562633446678

Epoch: 6| Step: 12
Training loss: 3.5269667042652397
Validation loss: 5.066448133097232

Epoch: 6| Step: 13
Training loss: 5.999420773839924
Validation loss: 5.04934288963499

Epoch: 12| Step: 0
Training loss: 5.0956140395624105
Validation loss: 5.033895172357342

Epoch: 6| Step: 1
Training loss: 5.002043878520707
Validation loss: 5.012242258502532

Epoch: 6| Step: 2
Training loss: 5.606004983062109
Validation loss: 4.994262890421132

Epoch: 6| Step: 3
Training loss: 4.955969923074389
Validation loss: 4.978575959213749

Epoch: 6| Step: 4
Training loss: 4.666286634684077
Validation loss: 4.963066071144129

Epoch: 6| Step: 5
Training loss: 4.063270378428304
Validation loss: 4.941644240133055

Epoch: 6| Step: 6
Training loss: 4.711429804293092
Validation loss: 4.923934373910301

Epoch: 6| Step: 7
Training loss: 4.295713177445727
Validation loss: 4.903389128958719

Epoch: 6| Step: 8
Training loss: 4.631446263817481
Validation loss: 4.888514221836945

Epoch: 6| Step: 9
Training loss: 4.662915470542524
Validation loss: 4.873362032274136

Epoch: 6| Step: 10
Training loss: 5.538432140557608
Validation loss: 4.851330589820633

Epoch: 6| Step: 11
Training loss: 5.6754875343393545
Validation loss: 4.831951140328603

Epoch: 6| Step: 12
Training loss: 5.717765014537989
Validation loss: 4.813816733694161

Epoch: 6| Step: 13
Training loss: 4.206772140131821
Validation loss: 4.792906284715007

Epoch: 13| Step: 0
Training loss: 4.947200083458469
Validation loss: 4.77612745442579

Epoch: 6| Step: 1
Training loss: 5.345830857991661
Validation loss: 4.754429895800937

Epoch: 6| Step: 2
Training loss: 4.5309065063772005
Validation loss: 4.736241561864854

Epoch: 6| Step: 3
Training loss: 3.9331747852849817
Validation loss: 4.715741328475485

Epoch: 6| Step: 4
Training loss: 4.535106832808391
Validation loss: 4.6901755689439035

Epoch: 6| Step: 5
Training loss: 4.8197683957754665
Validation loss: 4.677487278234015

Epoch: 6| Step: 6
Training loss: 4.363373047657895
Validation loss: 4.654696447417006

Epoch: 6| Step: 7
Training loss: 4.220940367435818
Validation loss: 4.635854403087767

Epoch: 6| Step: 8
Training loss: 4.6192962942849345
Validation loss: 4.618660368558868

Epoch: 6| Step: 9
Training loss: 4.878033207891775
Validation loss: 4.590312775416557

Epoch: 6| Step: 10
Training loss: 4.880100614104609
Validation loss: 4.576558568430542

Epoch: 6| Step: 11
Training loss: 4.596555514873976
Validation loss: 4.553508755103313

Epoch: 6| Step: 12
Training loss: 4.980262327217352
Validation loss: 4.528160013065623

Epoch: 6| Step: 13
Training loss: 5.049928101887048
Validation loss: 4.510627623235747

Epoch: 14| Step: 0
Training loss: 3.6581350830397996
Validation loss: 4.4826024806329325

Epoch: 6| Step: 1
Training loss: 3.8956991298360144
Validation loss: 4.4682192118250885

Epoch: 6| Step: 2
Training loss: 4.017843027241449
Validation loss: 4.439598803842774

Epoch: 6| Step: 3
Training loss: 5.4538748589019255
Validation loss: 4.412896499590882

Epoch: 6| Step: 4
Training loss: 4.148199559516308
Validation loss: 4.398343118835159

Epoch: 6| Step: 5
Training loss: 4.507255215633726
Validation loss: 4.369901871488422

Epoch: 6| Step: 6
Training loss: 3.3707901872121995
Validation loss: 4.344425355776495

Epoch: 6| Step: 7
Training loss: 4.6482918339834205
Validation loss: 4.324227065395465

Epoch: 6| Step: 8
Training loss: 4.4991327085777915
Validation loss: 4.301200139414727

Epoch: 6| Step: 9
Training loss: 4.9361066180048745
Validation loss: 4.272579223833007

Epoch: 6| Step: 10
Training loss: 4.4322177448974225
Validation loss: 4.251410094157332

Epoch: 6| Step: 11
Training loss: 5.029654492746619
Validation loss: 4.235650905816249

Epoch: 6| Step: 12
Training loss: 4.148582326656291
Validation loss: 4.205569993947605

Epoch: 6| Step: 13
Training loss: 4.367731432402934
Validation loss: 4.185457659986714

Epoch: 15| Step: 0
Training loss: 4.54259213225547
Validation loss: 4.1524764485173575

Epoch: 6| Step: 1
Training loss: 4.636809247747852
Validation loss: 4.12820823407725

Epoch: 6| Step: 2
Training loss: 4.0050908118154664
Validation loss: 4.109805151940454

Epoch: 6| Step: 3
Training loss: 3.0027194413188067
Validation loss: 4.078232898258376

Epoch: 6| Step: 4
Training loss: 4.005328920266285
Validation loss: 4.058345028554517

Epoch: 6| Step: 5
Training loss: 2.529347210828764
Validation loss: 4.03738261310335

Epoch: 6| Step: 6
Training loss: 4.586973005163389
Validation loss: 4.009198525590793

Epoch: 6| Step: 7
Training loss: 4.461755787744624
Validation loss: 3.9847773883396482

Epoch: 6| Step: 8
Training loss: 4.131108933433911
Validation loss: 3.9620679071704776

Epoch: 6| Step: 9
Training loss: 3.9410316735412656
Validation loss: 3.9360117511190347

Epoch: 6| Step: 10
Training loss: 3.8769403337320476
Validation loss: 3.9150790520713756

Epoch: 6| Step: 11
Training loss: 4.072059300453658
Validation loss: 3.87931123702943

Epoch: 6| Step: 12
Training loss: 3.6680360895542536
Validation loss: 3.857237428279605

Epoch: 6| Step: 13
Training loss: 5.584131250254453
Validation loss: 3.829829162359875

Epoch: 16| Step: 0
Training loss: 3.7669917115479037
Validation loss: 3.80237833997764

Epoch: 6| Step: 1
Training loss: 3.750427603184212
Validation loss: 3.7729629316351896

Epoch: 6| Step: 2
Training loss: 3.7398442396072378
Validation loss: 3.7496381797019276

Epoch: 6| Step: 3
Training loss: 3.828965698104482
Validation loss: 3.728644062123732

Epoch: 6| Step: 4
Training loss: 3.795718044256789
Validation loss: 3.7017243311998302

Epoch: 6| Step: 5
Training loss: 4.221860290095118
Validation loss: 3.675496448689141

Epoch: 6| Step: 6
Training loss: 2.803134498877788
Validation loss: 3.650759617326833

Epoch: 6| Step: 7
Training loss: 3.431650351704343
Validation loss: 3.6294775760931213

Epoch: 6| Step: 8
Training loss: 4.688579994400395
Validation loss: 3.5910411796474806

Epoch: 6| Step: 9
Training loss: 3.6496282100752873
Validation loss: 3.564711945661583

Epoch: 6| Step: 10
Training loss: 3.70277937551777
Validation loss: 3.543535306839944

Epoch: 6| Step: 11
Training loss: 3.920839818988967
Validation loss: 3.5233663941913225

Epoch: 6| Step: 12
Training loss: 3.41329758933346
Validation loss: 3.5002079607449255

Epoch: 6| Step: 13
Training loss: 3.503445155872299
Validation loss: 3.474100553917252

Epoch: 17| Step: 0
Training loss: 3.0832484637428044
Validation loss: 3.454462516487944

Epoch: 6| Step: 1
Training loss: 3.5310178697296473
Validation loss: 3.416901758681248

Epoch: 6| Step: 2
Training loss: 2.789049335523466
Validation loss: 3.3928321749255557

Epoch: 6| Step: 3
Training loss: 4.206001970480232
Validation loss: 3.3839263791082983

Epoch: 6| Step: 4
Training loss: 3.654565145818213
Validation loss: 3.3596668060391326

Epoch: 6| Step: 5
Training loss: 3.5139166856419366
Validation loss: 3.333113662085346

Epoch: 6| Step: 6
Training loss: 2.276948924051762
Validation loss: 3.3025881711741243

Epoch: 6| Step: 7
Training loss: 3.0297445117766326
Validation loss: 3.294997367555956

Epoch: 6| Step: 8
Training loss: 3.9902756026458626
Validation loss: 3.256585144402377

Epoch: 6| Step: 9
Training loss: 3.3188576776022933
Validation loss: 3.2542970173029464

Epoch: 6| Step: 10
Training loss: 4.23886107244957
Validation loss: 3.232045971911213

Epoch: 6| Step: 11
Training loss: 3.463822447598365
Validation loss: 3.2049790373736027

Epoch: 6| Step: 12
Training loss: 3.3884734609599474
Validation loss: 3.18264333113394

Epoch: 6| Step: 13
Training loss: 3.50648497203836
Validation loss: 3.164562786682353

Epoch: 18| Step: 0
Training loss: 2.7068108803362563
Validation loss: 3.147159208723138

Epoch: 6| Step: 1
Training loss: 3.5862552942480908
Validation loss: 3.1257915831454928

Epoch: 6| Step: 2
Training loss: 3.623390629750223
Validation loss: 3.0983599981270107

Epoch: 6| Step: 3
Training loss: 3.4094836084005666
Validation loss: 3.0782320386982707

Epoch: 6| Step: 4
Training loss: 3.295158192334961
Validation loss: 3.064055615485811

Epoch: 6| Step: 5
Training loss: 3.4881691567586155
Validation loss: 3.040725208876407

Epoch: 6| Step: 6
Training loss: 3.588739235601754
Validation loss: 3.024759674899004

Epoch: 6| Step: 7
Training loss: 3.142696930777491
Validation loss: 3.0074941678961067

Epoch: 6| Step: 8
Training loss: 3.0854216711882487
Validation loss: 3.0017064003075316

Epoch: 6| Step: 9
Training loss: 2.6507560011484483
Validation loss: 2.9676797320349535

Epoch: 6| Step: 10
Training loss: 2.837953465731464
Validation loss: 2.960493611597262

Epoch: 6| Step: 11
Training loss: 2.177829182703649
Validation loss: 2.9497781202559783

Epoch: 6| Step: 12
Training loss: 4.133530091145375
Validation loss: 2.925897638311592

Epoch: 6| Step: 13
Training loss: 3.253776996513743
Validation loss: 2.922904730220398

Epoch: 19| Step: 0
Training loss: 2.82295707495415
Validation loss: 2.907929415875871

Epoch: 6| Step: 1
Training loss: 3.837929140630527
Validation loss: 2.9019478967800816

Epoch: 6| Step: 2
Training loss: 3.3673204718795855
Validation loss: 2.893303896449113

Epoch: 6| Step: 3
Training loss: 2.8900904805628223
Validation loss: 2.8766158451010417

Epoch: 6| Step: 4
Training loss: 2.8306697966740546
Validation loss: 2.865739599246273

Epoch: 6| Step: 5
Training loss: 3.5685538002502866
Validation loss: 2.846503748075972

Epoch: 6| Step: 6
Training loss: 3.2993344358251084
Validation loss: 2.849386869379634

Epoch: 6| Step: 7
Training loss: 2.929835119978807
Validation loss: 2.841872722398818

Epoch: 6| Step: 8
Training loss: 2.9591145804685897
Validation loss: 2.8290546425564655

Epoch: 6| Step: 9
Training loss: 3.238458092511862
Validation loss: 2.825191798964964

Epoch: 6| Step: 10
Training loss: 2.3700776538923227
Validation loss: 2.8012701439569168

Epoch: 6| Step: 11
Training loss: 2.9796938307504357
Validation loss: 2.807182398618559

Epoch: 6| Step: 12
Training loss: 3.347780027293463
Validation loss: 2.79650900618402

Epoch: 6| Step: 13
Training loss: 2.4071554486833575
Validation loss: 2.7977667201816963

Epoch: 20| Step: 0
Training loss: 3.4395618150770786
Validation loss: 2.778560747186157

Epoch: 6| Step: 1
Training loss: 3.21813129293301
Validation loss: 2.77485541044881

Epoch: 6| Step: 2
Training loss: 3.2223940470984287
Validation loss: 2.7772180289292225

Epoch: 6| Step: 3
Training loss: 3.0875697201412957
Validation loss: 2.772066781976935

Epoch: 6| Step: 4
Training loss: 3.0308110814033307
Validation loss: 2.7699830678752018

Epoch: 6| Step: 5
Training loss: 2.89532171619511
Validation loss: 2.757003582345907

Epoch: 6| Step: 6
Training loss: 3.262480613680129
Validation loss: 2.7552907190792255

Epoch: 6| Step: 7
Training loss: 3.6774102228695704
Validation loss: 2.7419651342051945

Epoch: 6| Step: 8
Training loss: 2.7151504014088257
Validation loss: 2.739442825847233

Epoch: 6| Step: 9
Training loss: 3.109540465279782
Validation loss: 2.7268731002363085

Epoch: 6| Step: 10
Training loss: 2.6938458418999915
Validation loss: 2.7281020949370687

Epoch: 6| Step: 11
Training loss: 2.7591146793458474
Validation loss: 2.7395625022215677

Epoch: 6| Step: 12
Training loss: 2.6807618948450136
Validation loss: 2.718975131838853

Epoch: 6| Step: 13
Training loss: 2.504425518686851
Validation loss: 2.724236863599055

Epoch: 21| Step: 0
Training loss: 2.5809951988982545
Validation loss: 2.7234326579689383

Epoch: 6| Step: 1
Training loss: 2.3534436986545515
Validation loss: 2.717199259300685

Epoch: 6| Step: 2
Training loss: 3.4419393830090317
Validation loss: 2.7220002838627924

Epoch: 6| Step: 3
Training loss: 2.300003308832857
Validation loss: 2.717371139166202

Epoch: 6| Step: 4
Training loss: 3.1986561933851916
Validation loss: 2.707578355678761

Epoch: 6| Step: 5
Training loss: 2.678860639671692
Validation loss: 2.7181972667395877

Epoch: 6| Step: 6
Training loss: 4.194478610968364
Validation loss: 2.7110608933275877

Epoch: 6| Step: 7
Training loss: 2.3106001189184378
Validation loss: 2.708892604234197

Epoch: 6| Step: 8
Training loss: 2.662767291196174
Validation loss: 2.7232265847542623

Epoch: 6| Step: 9
Training loss: 2.55160831520076
Validation loss: 2.712262577716388

Epoch: 6| Step: 10
Training loss: 3.2136002612014374
Validation loss: 2.7069709708498286

Epoch: 6| Step: 11
Training loss: 3.78228922032885
Validation loss: 2.7067683401992144

Epoch: 6| Step: 12
Training loss: 3.0594420444206727
Validation loss: 2.7022264210368467

Epoch: 6| Step: 13
Training loss: 3.267448536730999
Validation loss: 2.695112981748893

Epoch: 22| Step: 0
Training loss: 3.0291687417493285
Validation loss: 2.699428645106512

Epoch: 6| Step: 1
Training loss: 4.046334366789444
Validation loss: 2.7039950036079

Epoch: 6| Step: 2
Training loss: 3.090229844615722
Validation loss: 2.690127159660242

Epoch: 6| Step: 3
Training loss: 2.799128471705227
Validation loss: 2.703110398411902

Epoch: 6| Step: 4
Training loss: 3.2062343485489238
Validation loss: 2.693840753338794

Epoch: 6| Step: 5
Training loss: 2.668124237668073
Validation loss: 2.682022326516806

Epoch: 6| Step: 6
Training loss: 2.7721358562497205
Validation loss: 2.6948736274884135

Epoch: 6| Step: 7
Training loss: 2.838095440335753
Validation loss: 2.7030774563476503

Epoch: 6| Step: 8
Training loss: 2.94068849274117
Validation loss: 2.691093882601237

Epoch: 6| Step: 9
Training loss: 3.5660660948134604
Validation loss: 2.689767003952084

Epoch: 6| Step: 10
Training loss: 2.1811258362678787
Validation loss: 2.699506521077577

Epoch: 6| Step: 11
Training loss: 2.7780776201119184
Validation loss: 2.68368604102826

Epoch: 6| Step: 12
Training loss: 2.7692183948713134
Validation loss: 2.698328886009881

Epoch: 6| Step: 13
Training loss: 3.196417060338123
Validation loss: 2.689104488860794

Epoch: 23| Step: 0
Training loss: 2.8862102716288125
Validation loss: 2.6845450949164227

Epoch: 6| Step: 1
Training loss: 2.4542143522939504
Validation loss: 2.687091859359421

Epoch: 6| Step: 2
Training loss: 2.6034918152277737
Validation loss: 2.69122813464844

Epoch: 6| Step: 3
Training loss: 2.9250557462156577
Validation loss: 2.6758883441727

Epoch: 6| Step: 4
Training loss: 3.5034210651663145
Validation loss: 2.6787278091518845

Epoch: 6| Step: 5
Training loss: 3.130955628589035
Validation loss: 2.675908513969025

Epoch: 6| Step: 6
Training loss: 3.009229767048963
Validation loss: 2.680244278177231

Epoch: 6| Step: 7
Training loss: 2.6727837695777894
Validation loss: 2.6828397412928293

Epoch: 6| Step: 8
Training loss: 2.4926569864160433
Validation loss: 2.6894417101657075

Epoch: 6| Step: 9
Training loss: 3.551627718137444
Validation loss: 2.66952710033754

Epoch: 6| Step: 10
Training loss: 2.885359138071352
Validation loss: 2.6760672879640977

Epoch: 6| Step: 11
Training loss: 3.254211924324088
Validation loss: 2.6655749411459793

Epoch: 6| Step: 12
Training loss: 3.458211751125862
Validation loss: 2.6694660525762597

Epoch: 6| Step: 13
Training loss: 2.7816173868021568
Validation loss: 2.6698007870998235

Epoch: 24| Step: 0
Training loss: 3.2714763584323423
Validation loss: 2.6673168618975285

Epoch: 6| Step: 1
Training loss: 3.6777737899507668
Validation loss: 2.673954803134531

Epoch: 6| Step: 2
Training loss: 3.3202395442352524
Validation loss: 2.657908158181666

Epoch: 6| Step: 3
Training loss: 3.1403181391113133
Validation loss: 2.680897178759356

Epoch: 6| Step: 4
Training loss: 2.3224389193646595
Validation loss: 2.6677559876000254

Epoch: 6| Step: 5
Training loss: 2.808354437849697
Validation loss: 2.679900200962618

Epoch: 6| Step: 6
Training loss: 2.716754136890882
Validation loss: 2.6638079581700462

Epoch: 6| Step: 7
Training loss: 3.7413940862815167
Validation loss: 2.6788619316067677

Epoch: 6| Step: 8
Training loss: 2.5964837432534584
Validation loss: 2.668577014342367

Epoch: 6| Step: 9
Training loss: 2.8194460396430685
Validation loss: 2.669304335069049

Epoch: 6| Step: 10
Training loss: 2.334630287847011
Validation loss: 2.6737157610377333

Epoch: 6| Step: 11
Training loss: 3.2080091502565704
Validation loss: 2.6627795886681804

Epoch: 6| Step: 12
Training loss: 2.87593046970704
Validation loss: 2.6744543359319928

Epoch: 6| Step: 13
Training loss: 2.35797704245123
Validation loss: 2.667356950365791

Epoch: 25| Step: 0
Training loss: 3.253664005416669
Validation loss: 2.669759703057497

Epoch: 6| Step: 1
Training loss: 2.7672012923256117
Validation loss: 2.660620171371532

Epoch: 6| Step: 2
Training loss: 3.0382399046388104
Validation loss: 2.6630232792874504

Epoch: 6| Step: 3
Training loss: 3.000342667400871
Validation loss: 2.6511338109122935

Epoch: 6| Step: 4
Training loss: 2.1489763173768304
Validation loss: 2.665292917335081

Epoch: 6| Step: 5
Training loss: 2.8108720094304647
Validation loss: 2.670204049326884

Epoch: 6| Step: 6
Training loss: 2.8991718030421527
Validation loss: 2.671012984513813

Epoch: 6| Step: 7
Training loss: 2.912852345384287
Validation loss: 2.6636981136925946

Epoch: 6| Step: 8
Training loss: 2.7202085769846813
Validation loss: 2.659502275341067

Epoch: 6| Step: 9
Training loss: 3.086790792579854
Validation loss: 2.6649093208261063

Epoch: 6| Step: 10
Training loss: 3.043840824471884
Validation loss: 2.6592617972072117

Epoch: 6| Step: 11
Training loss: 3.0213320791753113
Validation loss: 2.6583480039007803

Epoch: 6| Step: 12
Training loss: 3.9149953373945783
Validation loss: 2.664289690520596

Epoch: 6| Step: 13
Training loss: 2.7116480179301536
Validation loss: 2.648093368644682

Epoch: 26| Step: 0
Training loss: 3.30311002123422
Validation loss: 2.6674825653276186

Epoch: 6| Step: 1
Training loss: 2.570090982926959
Validation loss: 2.6574716754137366

Epoch: 6| Step: 2
Training loss: 3.2356482317103197
Validation loss: 2.6582799982977483

Epoch: 6| Step: 3
Training loss: 2.921808252235179
Validation loss: 2.6697716226321817

Epoch: 6| Step: 4
Training loss: 2.7325387947420814
Validation loss: 2.666816900588503

Epoch: 6| Step: 5
Training loss: 2.589700041821467
Validation loss: 2.660371722850506

Epoch: 6| Step: 6
Training loss: 3.504065060285883
Validation loss: 2.653739780611169

Epoch: 6| Step: 7
Training loss: 2.582372784209274
Validation loss: 2.665183418782133

Epoch: 6| Step: 8
Training loss: 3.1832423478417056
Validation loss: 2.661052695983133

Epoch: 6| Step: 9
Training loss: 2.7065210783691027
Validation loss: 2.6653390083416726

Epoch: 6| Step: 10
Training loss: 3.1013912278552946
Validation loss: 2.6542107085945563

Epoch: 6| Step: 11
Training loss: 2.71381034668007
Validation loss: 2.6761954694508523

Epoch: 6| Step: 12
Training loss: 3.75602111626845
Validation loss: 2.663630916481941

Epoch: 6| Step: 13
Training loss: 1.9690027226109084
Validation loss: 2.655632002164608

Epoch: 27| Step: 0
Training loss: 2.952167658565032
Validation loss: 2.651157698552008

Epoch: 6| Step: 1
Training loss: 2.9281262115834275
Validation loss: 2.654402255342427

Epoch: 6| Step: 2
Training loss: 3.2068766139637335
Validation loss: 2.654725760736849

Epoch: 6| Step: 3
Training loss: 2.616351093611854
Validation loss: 2.665524036680645

Epoch: 6| Step: 4
Training loss: 3.394885221403502
Validation loss: 2.653298244378281

Epoch: 6| Step: 5
Training loss: 3.2108011704065063
Validation loss: 2.6433625651571733

Epoch: 6| Step: 6
Training loss: 2.9440954309420984
Validation loss: 2.6556092794261446

Epoch: 6| Step: 7
Training loss: 3.0336674754231767
Validation loss: 2.6516072359197427

Epoch: 6| Step: 8
Training loss: 2.7286085960806963
Validation loss: 2.658615059289714

Epoch: 6| Step: 9
Training loss: 2.906689846430521
Validation loss: 2.655048549847733

Epoch: 6| Step: 10
Training loss: 2.633756836102435
Validation loss: 2.6597870548282887

Epoch: 6| Step: 11
Training loss: 2.7115337144942284
Validation loss: 2.645215482097899

Epoch: 6| Step: 12
Training loss: 3.4186737554162256
Validation loss: 2.6527355863421587

Epoch: 6| Step: 13
Training loss: 2.6355978158404203
Validation loss: 2.6472496480715866

Epoch: 28| Step: 0
Training loss: 2.2906608339345715
Validation loss: 2.653515406422775

Epoch: 6| Step: 1
Training loss: 2.372914050745227
Validation loss: 2.6584854525166803

Epoch: 6| Step: 2
Training loss: 2.458792002502909
Validation loss: 2.654386746366157

Epoch: 6| Step: 3
Training loss: 2.7655823267861126
Validation loss: 2.6594741493940166

Epoch: 6| Step: 4
Training loss: 2.419594460075243
Validation loss: 2.6447952310096534

Epoch: 6| Step: 5
Training loss: 3.0808790250538243
Validation loss: 2.645696219012314

Epoch: 6| Step: 6
Training loss: 3.116417505297032
Validation loss: 2.6412625330494315

Epoch: 6| Step: 7
Training loss: 2.91322785152356
Validation loss: 2.6483571620581023

Epoch: 6| Step: 8
Training loss: 2.6022997662031853
Validation loss: 2.6539925795295116

Epoch: 6| Step: 9
Training loss: 3.0586573568577693
Validation loss: 2.6379443369534052

Epoch: 6| Step: 10
Training loss: 3.9022467279449202
Validation loss: 2.636760936112455

Epoch: 6| Step: 11
Training loss: 3.265649530784061
Validation loss: 2.653968845879108

Epoch: 6| Step: 12
Training loss: 3.7342986414297115
Validation loss: 2.645371137431797

Epoch: 6| Step: 13
Training loss: 2.844534629478218
Validation loss: 2.637595595051522

Epoch: 29| Step: 0
Training loss: 2.5171851775562977
Validation loss: 2.646893147961346

Epoch: 6| Step: 1
Training loss: 3.353542214467608
Validation loss: 2.6518781042624493

Epoch: 6| Step: 2
Training loss: 2.527852922470776
Validation loss: 2.644563430408814

Epoch: 6| Step: 3
Training loss: 2.230843480794478
Validation loss: 2.639404163200499

Epoch: 6| Step: 4
Training loss: 3.0664301974582413
Validation loss: 2.6379335009962572

Epoch: 6| Step: 5
Training loss: 2.7490933397529136
Validation loss: 2.639512150564782

Epoch: 6| Step: 6
Training loss: 2.2139330947953195
Validation loss: 2.6503298304801097

Epoch: 6| Step: 7
Training loss: 3.2543360322128816
Validation loss: 2.637861343076728

Epoch: 6| Step: 8
Training loss: 1.921030618903152
Validation loss: 2.6548854239933726

Epoch: 6| Step: 9
Training loss: 3.6306030117268078
Validation loss: 2.6384959508170787

Epoch: 6| Step: 10
Training loss: 3.401504710963378
Validation loss: 2.6457842508274947

Epoch: 6| Step: 11
Training loss: 3.260285461190806
Validation loss: 2.647865533964751

Epoch: 6| Step: 12
Training loss: 3.38538697841049
Validation loss: 2.6432995111810085

Epoch: 6| Step: 13
Training loss: 3.377972459480941
Validation loss: 2.651713717489677

Epoch: 30| Step: 0
Training loss: 2.8207239923364327
Validation loss: 2.6361750819368384

Epoch: 6| Step: 1
Training loss: 2.944650590825808
Validation loss: 2.637549216542142

Epoch: 6| Step: 2
Training loss: 2.676025023111033
Validation loss: 2.6380934138248544

Epoch: 6| Step: 3
Training loss: 2.693602530919136
Validation loss: 2.634430045274361

Epoch: 6| Step: 4
Training loss: 3.0781671356570395
Validation loss: 2.646556706108525

Epoch: 6| Step: 5
Training loss: 3.6410710794142265
Validation loss: 2.6405745679438968

Epoch: 6| Step: 6
Training loss: 3.4240843725415417
Validation loss: 2.628269514061963

Epoch: 6| Step: 7
Training loss: 3.2999871918400827
Validation loss: 2.622954196917671

Epoch: 6| Step: 8
Training loss: 3.0017416984447762
Validation loss: 2.6282499638445715

Epoch: 6| Step: 9
Training loss: 2.527806329624145
Validation loss: 2.6467358715820546

Epoch: 6| Step: 10
Training loss: 2.4006216436202252
Validation loss: 2.640241058741537

Epoch: 6| Step: 11
Training loss: 2.611012202163872
Validation loss: 2.6268282186835044

Epoch: 6| Step: 12
Training loss: 2.8296393455144764
Validation loss: 2.637479307047532

Epoch: 6| Step: 13
Training loss: 3.079763373413331
Validation loss: 2.6340420700171165

Epoch: 31| Step: 0
Training loss: 2.8768392567524335
Validation loss: 2.6285100957560066

Epoch: 6| Step: 1
Training loss: 2.8345415867614427
Validation loss: 2.632930891831138

Epoch: 6| Step: 2
Training loss: 3.01369370992171
Validation loss: 2.6289456857348084

Epoch: 6| Step: 3
Training loss: 2.4815766511078166
Validation loss: 2.6381635198597544

Epoch: 6| Step: 4
Training loss: 3.0868975341122677
Validation loss: 2.6308903516052724

Epoch: 6| Step: 5
Training loss: 2.7462948200525488
Validation loss: 2.633842525056447

Epoch: 6| Step: 6
Training loss: 3.180570212769549
Validation loss: 2.6185485219996942

Epoch: 6| Step: 7
Training loss: 2.8833921929968622
Validation loss: 2.6218867926568468

Epoch: 6| Step: 8
Training loss: 2.542145814184578
Validation loss: 2.644907738019573

Epoch: 6| Step: 9
Training loss: 2.7984618049047483
Validation loss: 2.6381737902864857

Epoch: 6| Step: 10
Training loss: 3.578814177795412
Validation loss: 2.624493564246256

Epoch: 6| Step: 11
Training loss: 2.3916642666404813
Validation loss: 2.6330851898112924

Epoch: 6| Step: 12
Training loss: 2.32565709334642
Validation loss: 2.6466479043529816

Epoch: 6| Step: 13
Training loss: 4.438285435757026
Validation loss: 2.6285281459565413

Epoch: 32| Step: 0
Training loss: 1.9002952747790687
Validation loss: 2.6189110233407895

Epoch: 6| Step: 1
Training loss: 4.053006862074556
Validation loss: 2.6300671546366705

Epoch: 6| Step: 2
Training loss: 3.520945816199504
Validation loss: 2.6346172482332055

Epoch: 6| Step: 3
Training loss: 2.72435367163693
Validation loss: 2.628172156576477

Epoch: 6| Step: 4
Training loss: 3.3124545112221564
Validation loss: 2.6327945775197077

Epoch: 6| Step: 5
Training loss: 2.1404727408284687
Validation loss: 2.632536354065952

Epoch: 6| Step: 6
Training loss: 2.6696872789502737
Validation loss: 2.6393228412270817

Epoch: 6| Step: 7
Training loss: 3.352506206828153
Validation loss: 2.63423468138316

Epoch: 6| Step: 8
Training loss: 3.118584112063305
Validation loss: 2.6257912966182606

Epoch: 6| Step: 9
Training loss: 2.056585675236362
Validation loss: 2.6299926402956246

Epoch: 6| Step: 10
Training loss: 2.7695886689382387
Validation loss: 2.6236109576752016

Epoch: 6| Step: 11
Training loss: 2.7857574627223527
Validation loss: 2.6356881798777776

Epoch: 6| Step: 12
Training loss: 2.8641667473483823
Validation loss: 2.6135489092534776

Epoch: 6| Step: 13
Training loss: 3.0703713603116753
Validation loss: 2.617239402387362

Epoch: 33| Step: 0
Training loss: 3.043969280012716
Validation loss: 2.6170073083378522

Epoch: 6| Step: 1
Training loss: 3.679112869393559
Validation loss: 2.6365513036891124

Epoch: 6| Step: 2
Training loss: 2.6671878682847487
Validation loss: 2.6347287322768107

Epoch: 6| Step: 3
Training loss: 2.9417327253869114
Validation loss: 2.622196784862742

Epoch: 6| Step: 4
Training loss: 2.737224293241687
Validation loss: 2.62377831136813

Epoch: 6| Step: 5
Training loss: 2.4662401019524673
Validation loss: 2.635837259858234

Epoch: 6| Step: 6
Training loss: 2.5615522911666004
Validation loss: 2.625456796132844

Epoch: 6| Step: 7
Training loss: 2.5527380174933367
Validation loss: 2.616095982208743

Epoch: 6| Step: 8
Training loss: 3.115955845628943
Validation loss: 2.6215085973927366

Epoch: 6| Step: 9
Training loss: 3.4415585227644745
Validation loss: 2.628088565357456

Epoch: 6| Step: 10
Training loss: 2.011227090253444
Validation loss: 2.6224506018606046

Epoch: 6| Step: 11
Training loss: 3.476033305492563
Validation loss: 2.6275814067647136

Epoch: 6| Step: 12
Training loss: 2.937265102653174
Validation loss: 2.617381303689099

Epoch: 6| Step: 13
Training loss: 2.904814334786318
Validation loss: 2.640267411206359

Epoch: 34| Step: 0
Training loss: 2.4091328777563863
Validation loss: 2.619016831993076

Epoch: 6| Step: 1
Training loss: 2.9195890409176903
Validation loss: 2.6143031293519465

Epoch: 6| Step: 2
Training loss: 2.4907104515819145
Validation loss: 2.630242241968093

Epoch: 6| Step: 3
Training loss: 2.9491576333692238
Validation loss: 2.6129002599257523

Epoch: 6| Step: 4
Training loss: 3.1021810918860733
Validation loss: 2.6145248491522985

Epoch: 6| Step: 5
Training loss: 3.255489115494554
Validation loss: 2.610748356981221

Epoch: 6| Step: 6
Training loss: 2.6716967071475217
Validation loss: 2.600615040917767

Epoch: 6| Step: 7
Training loss: 2.491512099440116
Validation loss: 2.626858712893129

Epoch: 6| Step: 8
Training loss: 2.812423026832975
Validation loss: 2.618609519826576

Epoch: 6| Step: 9
Training loss: 3.2582266930758026
Validation loss: 2.61224966781526

Epoch: 6| Step: 10
Training loss: 3.2579585712718973
Validation loss: 2.6163995900288572

Epoch: 6| Step: 11
Training loss: 3.391925333892703
Validation loss: 2.622946149102958

Epoch: 6| Step: 12
Training loss: 2.4930410806795895
Validation loss: 2.6206678982875564

Epoch: 6| Step: 13
Training loss: 3.3212451298182297
Validation loss: 2.621413584321419

Epoch: 35| Step: 0
Training loss: 3.2993618955097217
Validation loss: 2.609295180703015

Epoch: 6| Step: 1
Training loss: 2.7770985684235687
Validation loss: 2.613171966757989

Epoch: 6| Step: 2
Training loss: 3.1430915522165805
Validation loss: 2.6036150722636378

Epoch: 6| Step: 3
Training loss: 2.475570624490362
Validation loss: 2.619062140403484

Epoch: 6| Step: 4
Training loss: 2.798161216230509
Validation loss: 2.6003109792508634

Epoch: 6| Step: 5
Training loss: 2.6577531936909073
Validation loss: 2.6150816412452165

Epoch: 6| Step: 6
Training loss: 2.9946107140757747
Validation loss: 2.622891816422375

Epoch: 6| Step: 7
Training loss: 3.03027390957336
Validation loss: 2.616951081187919

Epoch: 6| Step: 8
Training loss: 3.481187260334628
Validation loss: 2.601527397009844

Epoch: 6| Step: 9
Training loss: 3.1388174140766987
Validation loss: 2.605871360432581

Epoch: 6| Step: 10
Training loss: 2.627605235336182
Validation loss: 2.609945933196441

Epoch: 6| Step: 11
Training loss: 2.8749747897162345
Validation loss: 2.6075234090157986

Epoch: 6| Step: 12
Training loss: 2.5433791806482917
Validation loss: 2.614517017584574

Epoch: 6| Step: 13
Training loss: 2.707274851221455
Validation loss: 2.6123428841513325

Epoch: 36| Step: 0
Training loss: 2.6773735710377813
Validation loss: 2.620089672992115

Epoch: 6| Step: 1
Training loss: 3.151888411487894
Validation loss: 2.613333654734324

Epoch: 6| Step: 2
Training loss: 2.856535622236908
Validation loss: 2.6048273763610394

Epoch: 6| Step: 3
Training loss: 1.9139334498906568
Validation loss: 2.6188903666031003

Epoch: 6| Step: 4
Training loss: 3.378118698862359
Validation loss: 2.6035666153859935

Epoch: 6| Step: 5
Training loss: 2.4180097684323725
Validation loss: 2.6133856375837246

Epoch: 6| Step: 6
Training loss: 2.752304152226331
Validation loss: 2.598404105019983

Epoch: 6| Step: 7
Training loss: 3.1089406692571244
Validation loss: 2.6092849528255724

Epoch: 6| Step: 8
Training loss: 3.3075696132539667
Validation loss: 2.602540197281572

Epoch: 6| Step: 9
Training loss: 2.998266354954794
Validation loss: 2.601579845365347

Epoch: 6| Step: 10
Training loss: 3.4472957793475767
Validation loss: 2.6094866085174586

Epoch: 6| Step: 11
Training loss: 2.4852005648506883
Validation loss: 2.611039246293315

Epoch: 6| Step: 12
Training loss: 2.7813572380736913
Validation loss: 2.6036275073354016

Epoch: 6| Step: 13
Training loss: 2.9449171210707417
Validation loss: 2.6059776404835673

Epoch: 37| Step: 0
Training loss: 3.3995614834900834
Validation loss: 2.6056095734699922

Epoch: 6| Step: 1
Training loss: 2.4576762555113514
Validation loss: 2.610380802563387

Epoch: 6| Step: 2
Training loss: 2.648382495770312
Validation loss: 2.603768753333085

Epoch: 6| Step: 3
Training loss: 3.489891987525506
Validation loss: 2.6122330709536086

Epoch: 6| Step: 4
Training loss: 3.069992553503095
Validation loss: 2.5970791226412957

Epoch: 6| Step: 5
Training loss: 3.4951186882243914
Validation loss: 2.6085051973894524

Epoch: 6| Step: 6
Training loss: 2.2073193387404304
Validation loss: 2.602656849596374

Epoch: 6| Step: 7
Training loss: 2.286309367014446
Validation loss: 2.616013091909599

Epoch: 6| Step: 8
Training loss: 2.859407185024208
Validation loss: 2.612577468941064

Epoch: 6| Step: 9
Training loss: 3.3447624884019493
Validation loss: 2.6102421467790364

Epoch: 6| Step: 10
Training loss: 3.0705640849929883
Validation loss: 2.6106195260538825

Epoch: 6| Step: 11
Training loss: 2.44042343499099
Validation loss: 2.617291658324972

Epoch: 6| Step: 12
Training loss: 2.0885032846882976
Validation loss: 2.6084420330089335

Epoch: 6| Step: 13
Training loss: 3.3573565429580112
Validation loss: 2.6146718403945126

Epoch: 38| Step: 0
Training loss: 2.4662545061722825
Validation loss: 2.6238950365801825

Epoch: 6| Step: 1
Training loss: 2.352469741351027
Validation loss: 2.6134304163042774

Epoch: 6| Step: 2
Training loss: 3.1683984505030143
Validation loss: 2.6129686332402224

Epoch: 6| Step: 3
Training loss: 2.2219391589552204
Validation loss: 2.615385161950422

Epoch: 6| Step: 4
Training loss: 2.9313323832893468
Validation loss: 2.614367067022688

Epoch: 6| Step: 5
Training loss: 3.488943073502576
Validation loss: 2.6372555704077114

Epoch: 6| Step: 6
Training loss: 3.5297137944633974
Validation loss: 2.6215834770722513

Epoch: 6| Step: 7
Training loss: 2.8599135928672728
Validation loss: 2.6103510832324703

Epoch: 6| Step: 8
Training loss: 3.1865005422196946
Validation loss: 2.627962521893504

Epoch: 6| Step: 9
Training loss: 2.6400010314130213
Validation loss: 2.620873126837722

Epoch: 6| Step: 10
Training loss: 2.572250238718694
Validation loss: 2.6158451208766955

Epoch: 6| Step: 11
Training loss: 3.595729912736311
Validation loss: 2.6049564649593107

Epoch: 6| Step: 12
Training loss: 2.669593952749855
Validation loss: 2.6059339683312848

Epoch: 6| Step: 13
Training loss: 2.2664948996741696
Validation loss: 2.6064995670468494

Epoch: 39| Step: 0
Training loss: 2.5416812479403457
Validation loss: 2.612790264104376

Epoch: 6| Step: 1
Training loss: 3.899993280258258
Validation loss: 2.619082351886287

Epoch: 6| Step: 2
Training loss: 3.131012739683761
Validation loss: 2.6128136653532965

Epoch: 6| Step: 3
Training loss: 3.4241619393477056
Validation loss: 2.6042723649426955

Epoch: 6| Step: 4
Training loss: 3.0247758766566335
Validation loss: 2.625976900286565

Epoch: 6| Step: 5
Training loss: 2.696798075510457
Validation loss: 2.623145934616496

Epoch: 6| Step: 6
Training loss: 2.517917512519724
Validation loss: 2.602973241877788

Epoch: 6| Step: 7
Training loss: 2.448481252506985
Validation loss: 2.606612121884801

Epoch: 6| Step: 8
Training loss: 3.0714789351582885
Validation loss: 2.6075860873614434

Epoch: 6| Step: 9
Training loss: 2.5314907383350955
Validation loss: 2.6133590130687967

Epoch: 6| Step: 10
Training loss: 2.818817926167813
Validation loss: 2.599100207231657

Epoch: 6| Step: 11
Training loss: 2.708405997450823
Validation loss: 2.592419412142988

Epoch: 6| Step: 12
Training loss: 2.38488899180546
Validation loss: 2.602191826635518

Epoch: 6| Step: 13
Training loss: 2.9539874396861
Validation loss: 2.6104209689374196

Epoch: 40| Step: 0
Training loss: 2.9396116093592015
Validation loss: 2.6016583089848035

Epoch: 6| Step: 1
Training loss: 2.4754153702642667
Validation loss: 2.601700215191512

Epoch: 6| Step: 2
Training loss: 2.89522800476663
Validation loss: 2.608476238024386

Epoch: 6| Step: 3
Training loss: 2.9017979145841566
Validation loss: 2.604823715177979

Epoch: 6| Step: 4
Training loss: 3.6615404505992437
Validation loss: 2.6132613276849126

Epoch: 6| Step: 5
Training loss: 2.95566429481513
Validation loss: 2.6060442141938105

Epoch: 6| Step: 6
Training loss: 2.9302248856101514
Validation loss: 2.6003451719303774

Epoch: 6| Step: 7
Training loss: 2.646651844764672
Validation loss: 2.605875213950869

Epoch: 6| Step: 8
Training loss: 2.4274105675484825
Validation loss: 2.6043676676960326

Epoch: 6| Step: 9
Training loss: 3.5743382835203303
Validation loss: 2.6095745945402404

Epoch: 6| Step: 10
Training loss: 2.77624386927148
Validation loss: 2.596030768350752

Epoch: 6| Step: 11
Training loss: 2.6423123177362
Validation loss: 2.5952026770679324

Epoch: 6| Step: 12
Training loss: 2.766936772348232
Validation loss: 2.588665628938575

Epoch: 6| Step: 13
Training loss: 2.0658067724262588
Validation loss: 2.605010047115214

Epoch: 41| Step: 0
Training loss: 3.1413757034330723
Validation loss: 2.5885536475993836

Epoch: 6| Step: 1
Training loss: 3.045346076979866
Validation loss: 2.595797848577864

Epoch: 6| Step: 2
Training loss: 2.3891244804171397
Validation loss: 2.590635514069464

Epoch: 6| Step: 3
Training loss: 2.472613727511294
Validation loss: 2.602899420419209

Epoch: 6| Step: 4
Training loss: 2.7499432991424633
Validation loss: 2.596965958188312

Epoch: 6| Step: 5
Training loss: 3.183158460943405
Validation loss: 2.5979783341996385

Epoch: 6| Step: 6
Training loss: 2.2215486525574746
Validation loss: 2.5980051321250706

Epoch: 6| Step: 7
Training loss: 2.7145061475115377
Validation loss: 2.5973990714684234

Epoch: 6| Step: 8
Training loss: 3.2596456735345005
Validation loss: 2.5933485445677906

Epoch: 6| Step: 9
Training loss: 3.3646182283810306
Validation loss: 2.5870527883555257

Epoch: 6| Step: 10
Training loss: 2.927194251586908
Validation loss: 2.5978032098539052

Epoch: 6| Step: 11
Training loss: 3.095758113914219
Validation loss: 2.6166091879974482

Epoch: 6| Step: 12
Training loss: 2.5734835372169966
Validation loss: 2.6092608046576853

Epoch: 6| Step: 13
Training loss: 3.078233745997064
Validation loss: 2.602370211929417

Epoch: 42| Step: 0
Training loss: 2.567994066374154
Validation loss: 2.5996056177132423

Epoch: 6| Step: 1
Training loss: 2.911534253235512
Validation loss: 2.603600544747699

Epoch: 6| Step: 2
Training loss: 2.834915187044723
Validation loss: 2.593332379836517

Epoch: 6| Step: 3
Training loss: 3.072043515741576
Validation loss: 2.595730641711165

Epoch: 6| Step: 4
Training loss: 3.291985524503788
Validation loss: 2.602143580688347

Epoch: 6| Step: 5
Training loss: 2.9593172899558837
Validation loss: 2.5908862891674547

Epoch: 6| Step: 6
Training loss: 2.2333500785579443
Validation loss: 2.5890114696847197

Epoch: 6| Step: 7
Training loss: 2.5267950343769385
Validation loss: 2.6023652868294347

Epoch: 6| Step: 8
Training loss: 2.5283106939634536
Validation loss: 2.603200394726145

Epoch: 6| Step: 9
Training loss: 3.144432075784693
Validation loss: 2.5994158272340284

Epoch: 6| Step: 10
Training loss: 2.966371567297083
Validation loss: 2.597970474461826

Epoch: 6| Step: 11
Training loss: 3.142928915318965
Validation loss: 2.59928818823818

Epoch: 6| Step: 12
Training loss: 2.827750502602424
Validation loss: 2.6056150468601813

Epoch: 6| Step: 13
Training loss: 3.2727908130700505
Validation loss: 2.5937070322857565

Epoch: 43| Step: 0
Training loss: 2.298542170212644
Validation loss: 2.593988428129581

Epoch: 6| Step: 1
Training loss: 3.2712327911658967
Validation loss: 2.5988858008755855

Epoch: 6| Step: 2
Training loss: 3.9718879849561546
Validation loss: 2.5830314041667877

Epoch: 6| Step: 3
Training loss: 2.3610292408032
Validation loss: 2.568401038973066

Epoch: 6| Step: 4
Training loss: 2.4584639455290094
Validation loss: 2.5855787728750816

Epoch: 6| Step: 5
Training loss: 2.5335426779465475
Validation loss: 2.586645217055348

Epoch: 6| Step: 6
Training loss: 2.5193767174932806
Validation loss: 2.5749761190640146

Epoch: 6| Step: 7
Training loss: 2.94374945573741
Validation loss: 2.594927216577143

Epoch: 6| Step: 8
Training loss: 2.4953140211011138
Validation loss: 2.5787528368929946

Epoch: 6| Step: 9
Training loss: 2.845442551181231
Validation loss: 2.5682855448316455

Epoch: 6| Step: 10
Training loss: 2.73614627688595
Validation loss: 2.5942878926464354

Epoch: 6| Step: 11
Training loss: 3.008179639727828
Validation loss: 2.5837692838302497

Epoch: 6| Step: 12
Training loss: 2.6231318592838955
Validation loss: 2.5848290628327506

Epoch: 6| Step: 13
Training loss: 4.0027530256134485
Validation loss: 2.5851107194752414

Epoch: 44| Step: 0
Training loss: 2.754001134225339
Validation loss: 2.5931869451168286

Epoch: 6| Step: 1
Training loss: 2.8834065804705347
Validation loss: 2.5872749221207982

Epoch: 6| Step: 2
Training loss: 2.8248924201128762
Validation loss: 2.583114684898419

Epoch: 6| Step: 3
Training loss: 2.126543157911383
Validation loss: 2.5680053022693636

Epoch: 6| Step: 4
Training loss: 3.1561264164968392
Validation loss: 2.572840115841246

Epoch: 6| Step: 5
Training loss: 2.7994391765251776
Validation loss: 2.584892303371226

Epoch: 6| Step: 6
Training loss: 3.1148777102840515
Validation loss: 2.6089143592692676

Epoch: 6| Step: 7
Training loss: 3.097684266010603
Validation loss: 2.5854626499571487

Epoch: 6| Step: 8
Training loss: 2.2203520243144874
Validation loss: 2.5956918717158945

Epoch: 6| Step: 9
Training loss: 2.200071775826103
Validation loss: 2.587775071440004

Epoch: 6| Step: 10
Training loss: 2.5855907196140397
Validation loss: 2.596722752140501

Epoch: 6| Step: 11
Training loss: 3.4815802206943163
Validation loss: 2.5871741501602097

Epoch: 6| Step: 12
Training loss: 3.425602245982546
Validation loss: 2.583308408010263

Epoch: 6| Step: 13
Training loss: 3.1687138782978006
Validation loss: 2.585390481249975

Epoch: 45| Step: 0
Training loss: 2.30968840541107
Validation loss: 2.5948391498280396

Epoch: 6| Step: 1
Training loss: 2.769027944008458
Validation loss: 2.584529470450985

Epoch: 6| Step: 2
Training loss: 3.121337728310149
Validation loss: 2.5783940845718827

Epoch: 6| Step: 3
Training loss: 3.1249971008287334
Validation loss: 2.590669271386055

Epoch: 6| Step: 4
Training loss: 2.8572433113422386
Validation loss: 2.5947832919878078

Epoch: 6| Step: 5
Training loss: 2.7012679054694186
Validation loss: 2.5882337444032735

Epoch: 6| Step: 6
Training loss: 2.9966472328356444
Validation loss: 2.5811392258620653

Epoch: 6| Step: 7
Training loss: 2.40649710042887
Validation loss: 2.5960135320634388

Epoch: 6| Step: 8
Training loss: 3.040244218402814
Validation loss: 2.5869128614035986

Epoch: 6| Step: 9
Training loss: 3.1425910223962346
Validation loss: 2.5754649729214867

Epoch: 6| Step: 10
Training loss: 2.165657529820564
Validation loss: 2.5968632571641486

Epoch: 6| Step: 11
Training loss: 3.0414814478947894
Validation loss: 2.5856131930958925

Epoch: 6| Step: 12
Training loss: 3.3927266863071885
Validation loss: 2.59474223441917

Epoch: 6| Step: 13
Training loss: 2.3694646476946652
Validation loss: 2.6033219776859404

Epoch: 46| Step: 0
Training loss: 2.914993587375608
Validation loss: 2.5932123758974632

Epoch: 6| Step: 1
Training loss: 2.7771209756217905
Validation loss: 2.5870773073216404

Epoch: 6| Step: 2
Training loss: 3.0036286026087957
Validation loss: 2.593485539387891

Epoch: 6| Step: 3
Training loss: 2.9038018200405484
Validation loss: 2.594177151617532

Epoch: 6| Step: 4
Training loss: 2.688521257687867
Validation loss: 2.592053412634173

Epoch: 6| Step: 5
Training loss: 3.3590049362396193
Validation loss: 2.586784543041106

Epoch: 6| Step: 6
Training loss: 2.5107518733404186
Validation loss: 2.590041912907085

Epoch: 6| Step: 7
Training loss: 2.9132141023704388
Validation loss: 2.583693812290722

Epoch: 6| Step: 8
Training loss: 2.0228018332933413
Validation loss: 2.595320186665468

Epoch: 6| Step: 9
Training loss: 2.7193569514333866
Validation loss: 2.583959167906662

Epoch: 6| Step: 10
Training loss: 3.2611526454841755
Validation loss: 2.5926670522377258

Epoch: 6| Step: 11
Training loss: 2.9203033300167025
Validation loss: 2.5715248651561784

Epoch: 6| Step: 12
Training loss: 2.3960212191563968
Validation loss: 2.58244031488304

Epoch: 6| Step: 13
Training loss: 3.598950015701126
Validation loss: 2.580391543273735

Epoch: 47| Step: 0
Training loss: 2.987121277111112
Validation loss: 2.592766237311677

Epoch: 6| Step: 1
Training loss: 2.7901209257437998
Validation loss: 2.5828719651675485

Epoch: 6| Step: 2
Training loss: 2.705475948014627
Validation loss: 2.5765336610387077

Epoch: 6| Step: 3
Training loss: 2.6204767765966044
Validation loss: 2.5838775425417206

Epoch: 6| Step: 4
Training loss: 3.409986214260303
Validation loss: 2.569210401313551

Epoch: 6| Step: 5
Training loss: 3.0191790731920785
Validation loss: 2.5904092436884008

Epoch: 6| Step: 6
Training loss: 2.8621155992963234
Validation loss: 2.574246510304907

Epoch: 6| Step: 7
Training loss: 2.9951555556211376
Validation loss: 2.5848655321552902

Epoch: 6| Step: 8
Training loss: 2.4755173652978306
Validation loss: 2.5955246420066147

Epoch: 6| Step: 9
Training loss: 2.6006889824214996
Validation loss: 2.590226563658482

Epoch: 6| Step: 10
Training loss: 2.7199266014293633
Validation loss: 2.580675934279942

Epoch: 6| Step: 11
Training loss: 2.865829437185177
Validation loss: 2.588746935970154

Epoch: 6| Step: 12
Training loss: 2.6439841308810057
Validation loss: 2.595259030656191

Epoch: 6| Step: 13
Training loss: 3.261600186140379
Validation loss: 2.591641939461562

Epoch: 48| Step: 0
Training loss: 3.18853533516851
Validation loss: 2.5705355298641703

Epoch: 6| Step: 1
Training loss: 2.116152126619929
Validation loss: 2.589390664969478

Epoch: 6| Step: 2
Training loss: 2.931888008227061
Validation loss: 2.5921218522062452

Epoch: 6| Step: 3
Training loss: 2.9584575322545716
Validation loss: 2.5846862353200026

Epoch: 6| Step: 4
Training loss: 2.3476692491320645
Validation loss: 2.588836740917473

Epoch: 6| Step: 5
Training loss: 2.8315075620334373
Validation loss: 2.58469444094474

Epoch: 6| Step: 6
Training loss: 2.712843343214233
Validation loss: 2.591154218686831

Epoch: 6| Step: 7
Training loss: 3.16376605116843
Validation loss: 2.586868462067573

Epoch: 6| Step: 8
Training loss: 2.128275198544527
Validation loss: 2.5954453153650006

Epoch: 6| Step: 9
Training loss: 3.2039941120355535
Validation loss: 2.603283503913982

Epoch: 6| Step: 10
Training loss: 2.6165120178331556
Validation loss: 2.592723861395563

Epoch: 6| Step: 11
Training loss: 3.4542037176546323
Validation loss: 2.6057177590982015

Epoch: 6| Step: 12
Training loss: 3.0347772899280256
Validation loss: 2.591874037371222

Epoch: 6| Step: 13
Training loss: 2.7228058126738075
Validation loss: 2.573396190091565

Epoch: 49| Step: 0
Training loss: 2.821376272341106
Validation loss: 2.57336067200434

Epoch: 6| Step: 1
Training loss: 3.3419528302756754
Validation loss: 2.6094832987051952

Epoch: 6| Step: 2
Training loss: 3.1969932854957457
Validation loss: 2.594683136700249

Epoch: 6| Step: 3
Training loss: 2.6593466267489787
Validation loss: 2.5911597018345596

Epoch: 6| Step: 4
Training loss: 3.6385278514589228
Validation loss: 2.595484243129266

Epoch: 6| Step: 5
Training loss: 2.247106068578242
Validation loss: 2.5862752125540323

Epoch: 6| Step: 6
Training loss: 3.2405538464701613
Validation loss: 2.574412455413108

Epoch: 6| Step: 7
Training loss: 2.418634326150109
Validation loss: 2.600182925731677

Epoch: 6| Step: 8
Training loss: 2.923818992136705
Validation loss: 2.5896447809525918

Epoch: 6| Step: 9
Training loss: 2.13906803729481
Validation loss: 2.5824251619576306

Epoch: 6| Step: 10
Training loss: 3.2984323303673664
Validation loss: 2.5886542252305755

Epoch: 6| Step: 11
Training loss: 2.751265148102075
Validation loss: 2.58310572295986

Epoch: 6| Step: 12
Training loss: 2.17891315665643
Validation loss: 2.5827671076193535

Epoch: 6| Step: 13
Training loss: 2.3947372472375514
Validation loss: 2.59734825413565

Epoch: 50| Step: 0
Training loss: 3.0044874960857704
Validation loss: 2.5741195454192867

Epoch: 6| Step: 1
Training loss: 3.459367589761711
Validation loss: 2.575640138019336

Epoch: 6| Step: 2
Training loss: 2.668203407792218
Validation loss: 2.5786902977869897

Epoch: 6| Step: 3
Training loss: 3.0295255809559527
Validation loss: 2.5795354311900662

Epoch: 6| Step: 4
Training loss: 2.682789955644302
Validation loss: 2.5836885742580384

Epoch: 6| Step: 5
Training loss: 2.276103445883404
Validation loss: 2.6039710587080824

Epoch: 6| Step: 6
Training loss: 2.6641331996094397
Validation loss: 2.5858992840920574

Epoch: 6| Step: 7
Training loss: 2.6967923289830127
Validation loss: 2.5773860947699707

Epoch: 6| Step: 8
Training loss: 3.2900313810109942
Validation loss: 2.5729610021972036

Epoch: 6| Step: 9
Training loss: 2.4612017777244164
Validation loss: 2.5736183440919804

Epoch: 6| Step: 10
Training loss: 3.1518714673901664
Validation loss: 2.568251901567139

Epoch: 6| Step: 11
Training loss: 2.5979780184290866
Validation loss: 2.5715936397241195

Epoch: 6| Step: 12
Training loss: 2.5746458680418933
Validation loss: 2.567252955764602

Epoch: 6| Step: 13
Training loss: 3.0112294790440446
Validation loss: 2.5733692225706313

Epoch: 51| Step: 0
Training loss: 2.4481660323591354
Validation loss: 2.5715331227474536

Epoch: 6| Step: 1
Training loss: 3.144971127278986
Validation loss: 2.573254276195947

Epoch: 6| Step: 2
Training loss: 2.7292816681449836
Validation loss: 2.5779787998503743

Epoch: 6| Step: 3
Training loss: 2.264403651975144
Validation loss: 2.5584198397345

Epoch: 6| Step: 4
Training loss: 2.638893778835473
Validation loss: 2.577124047892629

Epoch: 6| Step: 5
Training loss: 3.4501089327656334
Validation loss: 2.564379229354597

Epoch: 6| Step: 6
Training loss: 2.9598687892906494
Validation loss: 2.5771115913771396

Epoch: 6| Step: 7
Training loss: 2.958344222214409
Validation loss: 2.580370179774491

Epoch: 6| Step: 8
Training loss: 3.1698171771064807
Validation loss: 2.5696944479767776

Epoch: 6| Step: 9
Training loss: 3.2176791882062035
Validation loss: 2.567184901753426

Epoch: 6| Step: 10
Training loss: 2.049889361489577
Validation loss: 2.577501967377753

Epoch: 6| Step: 11
Training loss: 3.0927501565570714
Validation loss: 2.5788160206574275

Epoch: 6| Step: 12
Training loss: 2.204241746898913
Validation loss: 2.5724096633578593

Epoch: 6| Step: 13
Training loss: 3.0531743587381244
Validation loss: 2.568170990825923

Epoch: 52| Step: 0
Training loss: 2.2921783800730298
Validation loss: 2.5672703641760215

Epoch: 6| Step: 1
Training loss: 2.434515470827358
Validation loss: 2.5712925869825516

Epoch: 6| Step: 2
Training loss: 2.7017863051297053
Validation loss: 2.5727471477662576

Epoch: 6| Step: 3
Training loss: 3.1951302847170284
Validation loss: 2.5904683241112267

Epoch: 6| Step: 4
Training loss: 3.186095582820172
Validation loss: 2.5777368337218776

Epoch: 6| Step: 5
Training loss: 2.6026671301158637
Validation loss: 2.5757599394715434

Epoch: 6| Step: 6
Training loss: 2.259849395122439
Validation loss: 2.5845689107832945

Epoch: 6| Step: 7
Training loss: 2.885782175061357
Validation loss: 2.5775658601203104

Epoch: 6| Step: 8
Training loss: 3.1628610095813845
Validation loss: 2.583510500627904

Epoch: 6| Step: 9
Training loss: 3.0346955842091243
Validation loss: 2.5720682534297388

Epoch: 6| Step: 10
Training loss: 3.333565576727973
Validation loss: 2.5870987630843683

Epoch: 6| Step: 11
Training loss: 2.110207061551271
Validation loss: 2.5704184321234633

Epoch: 6| Step: 12
Training loss: 2.9405933082486264
Validation loss: 2.5776669758839548

Epoch: 6| Step: 13
Training loss: 3.390920599783794
Validation loss: 2.588771783512257

Epoch: 53| Step: 0
Training loss: 2.5641375635888424
Validation loss: 2.575684592557806

Epoch: 6| Step: 1
Training loss: 2.5460260766754867
Validation loss: 2.565044062607641

Epoch: 6| Step: 2
Training loss: 2.450158335960526
Validation loss: 2.58890183334633

Epoch: 6| Step: 3
Training loss: 2.2289506920503093
Validation loss: 2.5857613752674116

Epoch: 6| Step: 4
Training loss: 3.1875746475155506
Validation loss: 2.586106660174806

Epoch: 6| Step: 5
Training loss: 2.9120409296743466
Validation loss: 2.5719884495320238

Epoch: 6| Step: 6
Training loss: 3.7641502436651977
Validation loss: 2.5885567138007404

Epoch: 6| Step: 7
Training loss: 2.612804968158883
Validation loss: 2.582859117512936

Epoch: 6| Step: 8
Training loss: 3.171972263893194
Validation loss: 2.59598119223723

Epoch: 6| Step: 9
Training loss: 2.5764030485858007
Validation loss: 2.568859976696287

Epoch: 6| Step: 10
Training loss: 2.415901051844522
Validation loss: 2.5767455954210496

Epoch: 6| Step: 11
Training loss: 3.127388156077204
Validation loss: 2.580794167895435

Epoch: 6| Step: 12
Training loss: 2.7264306328919647
Validation loss: 2.584419945532868

Epoch: 6| Step: 13
Training loss: 3.071554539400722
Validation loss: 2.5758151598291996

Epoch: 54| Step: 0
Training loss: 2.6675084891358485
Validation loss: 2.585242265423819

Epoch: 6| Step: 1
Training loss: 2.610140842276948
Validation loss: 2.5921931560520197

Epoch: 6| Step: 2
Training loss: 2.6034301835368154
Validation loss: 2.5857544078770673

Epoch: 6| Step: 3
Training loss: 2.790392817527819
Validation loss: 2.584575075450633

Epoch: 6| Step: 4
Training loss: 3.0691869482909593
Validation loss: 2.5745906783668486

Epoch: 6| Step: 5
Training loss: 3.509446475081562
Validation loss: 2.5635506411707505

Epoch: 6| Step: 6
Training loss: 2.692397955020666
Validation loss: 2.562188857682809

Epoch: 6| Step: 7
Training loss: 2.9869281173551983
Validation loss: 2.5774741884250885

Epoch: 6| Step: 8
Training loss: 2.110410873942382
Validation loss: 2.581147058387787

Epoch: 6| Step: 9
Training loss: 3.4347252484068442
Validation loss: 2.5759703959253906

Epoch: 6| Step: 10
Training loss: 2.758690021728851
Validation loss: 2.5865647756266976

Epoch: 6| Step: 11
Training loss: 3.1566929270354604
Validation loss: 2.5761367156202

Epoch: 6| Step: 12
Training loss: 2.1342687979731965
Validation loss: 2.5733106212829364

Epoch: 6| Step: 13
Training loss: 2.516324342936049
Validation loss: 2.5887767354639193

Epoch: 55| Step: 0
Training loss: 2.200412460156507
Validation loss: 2.563428385964029

Epoch: 6| Step: 1
Training loss: 2.493359615965982
Validation loss: 2.5828135010734026

Epoch: 6| Step: 2
Training loss: 3.326271938178517
Validation loss: 2.5700004331590693

Epoch: 6| Step: 3
Training loss: 2.9280568378539247
Validation loss: 2.5882271338104363

Epoch: 6| Step: 4
Training loss: 3.062656320747346
Validation loss: 2.5787185477917807

Epoch: 6| Step: 5
Training loss: 3.5980533210912835
Validation loss: 2.5904665328555256

Epoch: 6| Step: 6
Training loss: 2.8868018359046945
Validation loss: 2.5790109573249373

Epoch: 6| Step: 7
Training loss: 1.8155275906352368
Validation loss: 2.567956820352695

Epoch: 6| Step: 8
Training loss: 2.535930121617328
Validation loss: 2.573381907900543

Epoch: 6| Step: 9
Training loss: 2.3480703588468583
Validation loss: 2.594614772593076

Epoch: 6| Step: 10
Training loss: 3.144255707793762
Validation loss: 2.590312117999863

Epoch: 6| Step: 11
Training loss: 2.604517818935557
Validation loss: 2.5751742095271126

Epoch: 6| Step: 12
Training loss: 3.110337458268649
Validation loss: 2.5866720194069286

Epoch: 6| Step: 13
Training loss: 2.9827216396810776
Validation loss: 2.578598053639866

Epoch: 56| Step: 0
Training loss: 3.1615549959910205
Validation loss: 2.5966234150959386

Epoch: 6| Step: 1
Training loss: 2.9837585132031554
Validation loss: 2.5922376916504253

Epoch: 6| Step: 2
Training loss: 3.242044836375545
Validation loss: 2.5670756604534493

Epoch: 6| Step: 3
Training loss: 2.3631262862417155
Validation loss: 2.5696527251620287

Epoch: 6| Step: 4
Training loss: 3.0599597594164614
Validation loss: 2.553530857675674

Epoch: 6| Step: 5
Training loss: 2.713183261585864
Validation loss: 2.5630213969628715

Epoch: 6| Step: 6
Training loss: 2.759296655460756
Validation loss: 2.5802772723765997

Epoch: 6| Step: 7
Training loss: 3.9422861710581847
Validation loss: 2.5472210628159937

Epoch: 6| Step: 8
Training loss: 2.511743999253436
Validation loss: 2.555104203910415

Epoch: 6| Step: 9
Training loss: 2.0049934040826765
Validation loss: 2.558194935857658

Epoch: 6| Step: 10
Training loss: 2.0134036813323566
Validation loss: 2.572612693844932

Epoch: 6| Step: 11
Training loss: 2.654793553201384
Validation loss: 2.568429244443397

Epoch: 6| Step: 12
Training loss: 2.851062135038723
Validation loss: 2.574281800066984

Epoch: 6| Step: 13
Training loss: 2.642056590604013
Validation loss: 2.5588028130454035

Epoch: 57| Step: 0
Training loss: 3.1434994728569703
Validation loss: 2.5678621040687943

Epoch: 6| Step: 1
Training loss: 2.767676675424263
Validation loss: 2.560436512440722

Epoch: 6| Step: 2
Training loss: 2.5032451548413746
Validation loss: 2.571139009779512

Epoch: 6| Step: 3
Training loss: 2.736343459985581
Validation loss: 2.5548194032592986

Epoch: 6| Step: 4
Training loss: 2.8882977989492424
Validation loss: 2.5805734740767687

Epoch: 6| Step: 5
Training loss: 1.8693529923194814
Validation loss: 2.5748080775747804

Epoch: 6| Step: 6
Training loss: 2.907767279189784
Validation loss: 2.573535920559987

Epoch: 6| Step: 7
Training loss: 2.6386124203955985
Validation loss: 2.5660878976669417

Epoch: 6| Step: 8
Training loss: 2.703790924425665
Validation loss: 2.559580317365322

Epoch: 6| Step: 9
Training loss: 2.8031415583739183
Validation loss: 2.5712880335695294

Epoch: 6| Step: 10
Training loss: 3.490912219519369
Validation loss: 2.5722514765612865

Epoch: 6| Step: 11
Training loss: 2.7301910652120074
Validation loss: 2.5655295698507374

Epoch: 6| Step: 12
Training loss: 3.1357694070466855
Validation loss: 2.5624861988223206

Epoch: 6| Step: 13
Training loss: 2.8757838963478553
Validation loss: 2.5625009944422623

Epoch: 58| Step: 0
Training loss: 3.0991972160697094
Validation loss: 2.5793504036995945

Epoch: 6| Step: 1
Training loss: 2.5031207633488646
Validation loss: 2.5665700410725036

Epoch: 6| Step: 2
Training loss: 2.8927116492012828
Validation loss: 2.576720127980423

Epoch: 6| Step: 3
Training loss: 2.5812179046187222
Validation loss: 2.563051770119477

Epoch: 6| Step: 4
Training loss: 2.7617002753647446
Validation loss: 2.5737121811600456

Epoch: 6| Step: 5
Training loss: 2.9035880090176085
Validation loss: 2.570843289673252

Epoch: 6| Step: 6
Training loss: 2.4140054146643517
Validation loss: 2.586160262876347

Epoch: 6| Step: 7
Training loss: 3.069709388571766
Validation loss: 2.5733598421505937

Epoch: 6| Step: 8
Training loss: 3.105223678419572
Validation loss: 2.564515203573945

Epoch: 6| Step: 9
Training loss: 2.311103089585607
Validation loss: 2.5696160538989017

Epoch: 6| Step: 10
Training loss: 2.6563510651154782
Validation loss: 2.5879480174707155

Epoch: 6| Step: 11
Training loss: 3.453872530707238
Validation loss: 2.5762696213461704

Epoch: 6| Step: 12
Training loss: 2.5538346386447475
Validation loss: 2.5749472913674896

Epoch: 6| Step: 13
Training loss: 2.6929455080238425
Validation loss: 2.5737166207149196

Epoch: 59| Step: 0
Training loss: 2.5621032407686894
Validation loss: 2.577728636779724

Epoch: 6| Step: 1
Training loss: 2.602192020716977
Validation loss: 2.570763490629996

Epoch: 6| Step: 2
Training loss: 2.501818472390178
Validation loss: 2.5729541894565378

Epoch: 6| Step: 3
Training loss: 2.9315043194703367
Validation loss: 2.575493239391579

Epoch: 6| Step: 4
Training loss: 3.422353214657848
Validation loss: 2.581046372964694

Epoch: 6| Step: 5
Training loss: 2.1501040012134145
Validation loss: 2.5699009041354635

Epoch: 6| Step: 6
Training loss: 2.380329376637649
Validation loss: 2.5734416208091577

Epoch: 6| Step: 7
Training loss: 2.7678354341560967
Validation loss: 2.5576068712404902

Epoch: 6| Step: 8
Training loss: 2.6613257885878854
Validation loss: 2.565975978062858

Epoch: 6| Step: 9
Training loss: 2.937602102250238
Validation loss: 2.568633393985208

Epoch: 6| Step: 10
Training loss: 3.3984925013508978
Validation loss: 2.571079411405614

Epoch: 6| Step: 11
Training loss: 1.8979906725840205
Validation loss: 2.56237776770146

Epoch: 6| Step: 12
Training loss: 3.786950094759982
Validation loss: 2.5540873698913114

Epoch: 6| Step: 13
Training loss: 2.793583899559083
Validation loss: 2.5586470443634597

Epoch: 60| Step: 0
Training loss: 3.224287288483574
Validation loss: 2.563924641018971

Epoch: 6| Step: 1
Training loss: 2.962505157079916
Validation loss: 2.569955074282648

Epoch: 6| Step: 2
Training loss: 2.6947374697969986
Validation loss: 2.5630436282363664

Epoch: 6| Step: 3
Training loss: 2.54690561100637
Validation loss: 2.5720996280978223

Epoch: 6| Step: 4
Training loss: 2.9047151840228618
Validation loss: 2.561893038094172

Epoch: 6| Step: 5
Training loss: 2.8296305827120154
Validation loss: 2.578188928014763

Epoch: 6| Step: 6
Training loss: 3.3349156121096346
Validation loss: 2.564733238920856

Epoch: 6| Step: 7
Training loss: 2.629253392872331
Validation loss: 2.5807717497987626

Epoch: 6| Step: 8
Training loss: 3.0217179329575785
Validation loss: 2.553142683513899

Epoch: 6| Step: 9
Training loss: 1.9069800933014924
Validation loss: 2.5726618045003424

Epoch: 6| Step: 10
Training loss: 2.5321216730710883
Validation loss: 2.5605960248420954

Epoch: 6| Step: 11
Training loss: 2.5859712442922005
Validation loss: 2.5576036135711955

Epoch: 6| Step: 12
Training loss: 2.992168376652337
Validation loss: 2.5616067879805264

Epoch: 6| Step: 13
Training loss: 2.8010022277060505
Validation loss: 2.5643764781457534

Epoch: 61| Step: 0
Training loss: 3.4019271998524165
Validation loss: 2.573611387158976

Epoch: 6| Step: 1
Training loss: 1.9587084498864282
Validation loss: 2.5665235787427694

Epoch: 6| Step: 2
Training loss: 2.713550989839105
Validation loss: 2.576677199140553

Epoch: 6| Step: 3
Training loss: 2.916972080770592
Validation loss: 2.5695899441234706

Epoch: 6| Step: 4
Training loss: 2.2502606558817093
Validation loss: 2.5726183261272597

Epoch: 6| Step: 5
Training loss: 2.5818103690035294
Validation loss: 2.567403350438258

Epoch: 6| Step: 6
Training loss: 2.9463325980272903
Validation loss: 2.56674295865243

Epoch: 6| Step: 7
Training loss: 2.651874663680876
Validation loss: 2.57844789433831

Epoch: 6| Step: 8
Training loss: 3.3193179806534734
Validation loss: 2.58497510364927

Epoch: 6| Step: 9
Training loss: 2.380625537282373
Validation loss: 2.5699098762104526

Epoch: 6| Step: 10
Training loss: 3.2765118494516647
Validation loss: 2.5644913885876464

Epoch: 6| Step: 11
Training loss: 2.4954968904457906
Validation loss: 2.566114933715655

Epoch: 6| Step: 12
Training loss: 2.3337116161881997
Validation loss: 2.5641300330374808

Epoch: 6| Step: 13
Training loss: 3.909630495256046
Validation loss: 2.56373655995572

Epoch: 62| Step: 0
Training loss: 3.0912957523352182
Validation loss: 2.5649376836361215

Epoch: 6| Step: 1
Training loss: 3.199170309033067
Validation loss: 2.568455718855303

Epoch: 6| Step: 2
Training loss: 2.744171207569797
Validation loss: 2.5560395312470456

Epoch: 6| Step: 3
Training loss: 2.2905377005768037
Validation loss: 2.5686208204416854

Epoch: 6| Step: 4
Training loss: 3.126990332968823
Validation loss: 2.5565469805940073

Epoch: 6| Step: 5
Training loss: 2.3029209414058753
Validation loss: 2.5730680876410563

Epoch: 6| Step: 6
Training loss: 2.7051040372743573
Validation loss: 2.5711800289745983

Epoch: 6| Step: 7
Training loss: 2.9818353682062892
Validation loss: 2.569033102382308

Epoch: 6| Step: 8
Training loss: 2.892056002685366
Validation loss: 2.5653389771979094

Epoch: 6| Step: 9
Training loss: 2.280285670637689
Validation loss: 2.583552237798218

Epoch: 6| Step: 10
Training loss: 2.4740998451851763
Validation loss: 2.574117889188613

Epoch: 6| Step: 11
Training loss: 3.414483435059526
Validation loss: 2.5633645058793815

Epoch: 6| Step: 12
Training loss: 2.8430657873656497
Validation loss: 2.571252264021362

Epoch: 6| Step: 13
Training loss: 1.9122216539470136
Validation loss: 2.5666382472277824

Epoch: 63| Step: 0
Training loss: 2.66217278274174
Validation loss: 2.5657238453440203

Epoch: 6| Step: 1
Training loss: 2.259432201795778
Validation loss: 2.5738679853316664

Epoch: 6| Step: 2
Training loss: 3.1828287340517045
Validation loss: 2.577063271822645

Epoch: 6| Step: 3
Training loss: 2.7977573984754067
Validation loss: 2.5797951418065344

Epoch: 6| Step: 4
Training loss: 2.7344921849889468
Validation loss: 2.5768037305833538

Epoch: 6| Step: 5
Training loss: 2.336948035854442
Validation loss: 2.5678386835277016

Epoch: 6| Step: 6
Training loss: 2.307123790916948
Validation loss: 2.5702336330378355

Epoch: 6| Step: 7
Training loss: 3.5319688453553137
Validation loss: 2.5685289173274035

Epoch: 6| Step: 8
Training loss: 2.962589336609544
Validation loss: 2.563953422668915

Epoch: 6| Step: 9
Training loss: 2.942361906922497
Validation loss: 2.5655773342121773

Epoch: 6| Step: 10
Training loss: 2.8518061285587515
Validation loss: 2.5667487746078055

Epoch: 6| Step: 11
Training loss: 2.532478222918105
Validation loss: 2.563462929591245

Epoch: 6| Step: 12
Training loss: 2.8245937156533327
Validation loss: 2.560237216607615

Epoch: 6| Step: 13
Training loss: 3.108390307138676
Validation loss: 2.5644677333285903

Epoch: 64| Step: 0
Training loss: 2.7303433587311656
Validation loss: 2.5695145684358507

Epoch: 6| Step: 1
Training loss: 2.6359238168014185
Validation loss: 2.563134847856225

Epoch: 6| Step: 2
Training loss: 2.291597700526235
Validation loss: 2.571355402720639

Epoch: 6| Step: 3
Training loss: 3.457482260039986
Validation loss: 2.568277712011504

Epoch: 6| Step: 4
Training loss: 2.4337900734665063
Validation loss: 2.5702632078088494

Epoch: 6| Step: 5
Training loss: 3.2756890540291708
Validation loss: 2.58149656984149

Epoch: 6| Step: 6
Training loss: 3.3032057305668543
Validation loss: 2.5703174939982754

Epoch: 6| Step: 7
Training loss: 3.1541831926108586
Validation loss: 2.568633796201849

Epoch: 6| Step: 8
Training loss: 1.8301234611180117
Validation loss: 2.5798879185053565

Epoch: 6| Step: 9
Training loss: 2.4233002437482023
Validation loss: 2.5628948852828346

Epoch: 6| Step: 10
Training loss: 2.544921500263787
Validation loss: 2.5747497679136244

Epoch: 6| Step: 11
Training loss: 2.297472817609873
Validation loss: 2.570669110120817

Epoch: 6| Step: 12
Training loss: 2.738401576294865
Validation loss: 2.5680284332838403

Epoch: 6| Step: 13
Training loss: 4.025198719497624
Validation loss: 2.5639386464291656

Epoch: 65| Step: 0
Training loss: 2.408810033995356
Validation loss: 2.570677747426239

Epoch: 6| Step: 1
Training loss: 2.4218425133279813
Validation loss: 2.5655679173088686

Epoch: 6| Step: 2
Training loss: 2.7107531570068595
Validation loss: 2.561383426047388

Epoch: 6| Step: 3
Training loss: 2.7520823830760053
Validation loss: 2.5675745304782973

Epoch: 6| Step: 4
Training loss: 3.057164429459901
Validation loss: 2.566764848070069

Epoch: 6| Step: 5
Training loss: 3.2870429355845014
Validation loss: 2.5646593833336766

Epoch: 6| Step: 6
Training loss: 3.44213055924165
Validation loss: 2.5600396406978256

Epoch: 6| Step: 7
Training loss: 3.097592982142751
Validation loss: 2.574924363386308

Epoch: 6| Step: 8
Training loss: 3.0648441296221565
Validation loss: 2.5722315135360305

Epoch: 6| Step: 9
Training loss: 2.7347288938119894
Validation loss: 2.5706735215227265

Epoch: 6| Step: 10
Training loss: 1.9341383658325546
Validation loss: 2.5742467841718946

Epoch: 6| Step: 11
Training loss: 2.5156497361761816
Validation loss: 2.57387166564683

Epoch: 6| Step: 12
Training loss: 2.475145771087991
Validation loss: 2.578864024053502

Epoch: 6| Step: 13
Training loss: 2.6623771460042844
Validation loss: 2.589592243326726

Epoch: 66| Step: 0
Training loss: 3.277157220090368
Validation loss: 2.5656475182310556

Epoch: 6| Step: 1
Training loss: 3.251455421279428
Validation loss: 2.566097204765452

Epoch: 6| Step: 2
Training loss: 3.0230166908785137
Validation loss: 2.5621153389953526

Epoch: 6| Step: 3
Training loss: 2.2310084877416956
Validation loss: 2.565703509788003

Epoch: 6| Step: 4
Training loss: 2.484395344968779
Validation loss: 2.562115234933436

Epoch: 6| Step: 5
Training loss: 1.9373163936125561
Validation loss: 2.5606030291509287

Epoch: 6| Step: 6
Training loss: 2.8561626796605175
Validation loss: 2.561591493801368

Epoch: 6| Step: 7
Training loss: 3.083810425697109
Validation loss: 2.573404835179388

Epoch: 6| Step: 8
Training loss: 2.49755186376476
Validation loss: 2.568749429377194

Epoch: 6| Step: 9
Training loss: 2.68123393020616
Validation loss: 2.5603816838277935

Epoch: 6| Step: 10
Training loss: 2.8576498194923614
Validation loss: 2.5523476692073017

Epoch: 6| Step: 11
Training loss: 2.92291029269846
Validation loss: 2.5647887096795317

Epoch: 6| Step: 12
Training loss: 2.837969259707189
Validation loss: 2.564921499773101

Epoch: 6| Step: 13
Training loss: 2.5867223556986536
Validation loss: 2.5630933833402527

Epoch: 67| Step: 0
Training loss: 2.7794045315531726
Validation loss: 2.562034380548964

Epoch: 6| Step: 1
Training loss: 2.1790081319040113
Validation loss: 2.5717632858297206

Epoch: 6| Step: 2
Training loss: 2.9142946861567087
Validation loss: 2.561281506284108

Epoch: 6| Step: 3
Training loss: 2.843329765374232
Validation loss: 2.5559319720815488

Epoch: 6| Step: 4
Training loss: 3.120066601458081
Validation loss: 2.5656435793115158

Epoch: 6| Step: 5
Training loss: 3.058999065178301
Validation loss: 2.5717644102668027

Epoch: 6| Step: 6
Training loss: 2.779994209612847
Validation loss: 2.569101666245405

Epoch: 6| Step: 7
Training loss: 2.4843845967041456
Validation loss: 2.5667268381096022

Epoch: 6| Step: 8
Training loss: 3.341857089152869
Validation loss: 2.5579696554174163

Epoch: 6| Step: 9
Training loss: 2.424928180378272
Validation loss: 2.5536248646709083

Epoch: 6| Step: 10
Training loss: 2.719192644237368
Validation loss: 2.564490458895999

Epoch: 6| Step: 11
Training loss: 2.5876387333189235
Validation loss: 2.571686940585549

Epoch: 6| Step: 12
Training loss: 2.724576122668951
Validation loss: 2.5612238886153444

Epoch: 6| Step: 13
Training loss: 2.9462338734162357
Validation loss: 2.5702778798650026

Epoch: 68| Step: 0
Training loss: 2.601247499199856
Validation loss: 2.5611040268194554

Epoch: 6| Step: 1
Training loss: 2.553516364480446
Validation loss: 2.5678859387102224

Epoch: 6| Step: 2
Training loss: 3.309296408378352
Validation loss: 2.5582067008218643

Epoch: 6| Step: 3
Training loss: 3.4563842857721445
Validation loss: 2.5534784384231917

Epoch: 6| Step: 4
Training loss: 2.3809525031135164
Validation loss: 2.577242427544243

Epoch: 6| Step: 5
Training loss: 2.631380591696947
Validation loss: 2.555942791592125

Epoch: 6| Step: 6
Training loss: 3.0541809130271758
Validation loss: 2.563149038616683

Epoch: 6| Step: 7
Training loss: 2.4190356931099206
Validation loss: 2.563254550678108

Epoch: 6| Step: 8
Training loss: 2.229325784964004
Validation loss: 2.5569903300166

Epoch: 6| Step: 9
Training loss: 3.363107710026291
Validation loss: 2.55491243167292

Epoch: 6| Step: 10
Training loss: 2.672013485537551
Validation loss: 2.55934264091357

Epoch: 6| Step: 11
Training loss: 2.3133449557266186
Validation loss: 2.5621460108107676

Epoch: 6| Step: 12
Training loss: 3.161673691949059
Validation loss: 2.5573055132542897

Epoch: 6| Step: 13
Training loss: 1.8612895052927196
Validation loss: 2.5659153625638025

Epoch: 69| Step: 0
Training loss: 2.5751980899800153
Validation loss: 2.557229560438908

Epoch: 6| Step: 1
Training loss: 2.8448490911326667
Validation loss: 2.565814432132904

Epoch: 6| Step: 2
Training loss: 2.3914739559924003
Validation loss: 2.5508758668581932

Epoch: 6| Step: 3
Training loss: 2.6509345332134373
Validation loss: 2.5580021250372162

Epoch: 6| Step: 4
Training loss: 2.7091762307016913
Validation loss: 2.5549180608318465

Epoch: 6| Step: 5
Training loss: 3.082545789887464
Validation loss: 2.555778909766047

Epoch: 6| Step: 6
Training loss: 3.019724850783342
Validation loss: 2.544306671192125

Epoch: 6| Step: 7
Training loss: 3.0159080253965582
Validation loss: 2.5632215634980033

Epoch: 6| Step: 8
Training loss: 2.890315188739593
Validation loss: 2.562327148266218

Epoch: 6| Step: 9
Training loss: 2.194180994543615
Validation loss: 2.5693523539771177

Epoch: 6| Step: 10
Training loss: 2.5626519320967773
Validation loss: 2.562849469669385

Epoch: 6| Step: 11
Training loss: 2.82360537715475
Validation loss: 2.5651877689099853

Epoch: 6| Step: 12
Training loss: 2.9337874956827084
Validation loss: 2.5552002825334115

Epoch: 6| Step: 13
Training loss: 3.0530800260669304
Validation loss: 2.5640985528537494

Epoch: 70| Step: 0
Training loss: 2.9490745256539936
Validation loss: 2.5663734182081783

Epoch: 6| Step: 1
Training loss: 1.9378039829145106
Validation loss: 2.5632374390439843

Epoch: 6| Step: 2
Training loss: 2.029891865861594
Validation loss: 2.563335166551358

Epoch: 6| Step: 3
Training loss: 3.0737602153668826
Validation loss: 2.551697777526789

Epoch: 6| Step: 4
Training loss: 2.30978956411734
Validation loss: 2.569497728963928

Epoch: 6| Step: 5
Training loss: 3.078758523102957
Validation loss: 2.5449256284032216

Epoch: 6| Step: 6
Training loss: 2.674209734683898
Validation loss: 2.564899765539982

Epoch: 6| Step: 7
Training loss: 2.5123157414677517
Validation loss: 2.5492189885821444

Epoch: 6| Step: 8
Training loss: 3.3314186955263283
Validation loss: 2.5629423586530455

Epoch: 6| Step: 9
Training loss: 3.1029026777794684
Validation loss: 2.5659311205332727

Epoch: 6| Step: 10
Training loss: 3.3535612677532383
Validation loss: 2.5545283281746114

Epoch: 6| Step: 11
Training loss: 2.280119733510832
Validation loss: 2.5718246426921243

Epoch: 6| Step: 12
Training loss: 2.8792202699329845
Validation loss: 2.5616123874166874

Epoch: 6| Step: 13
Training loss: 2.8698289226091416
Validation loss: 2.561324707675153

Epoch: 71| Step: 0
Training loss: 2.892328203880888
Validation loss: 2.566694806470328

Epoch: 6| Step: 1
Training loss: 2.7055563163190532
Validation loss: 2.576072383390782

Epoch: 6| Step: 2
Training loss: 1.9735295241790523
Validation loss: 2.567710173246638

Epoch: 6| Step: 3
Training loss: 3.4906886082166784
Validation loss: 2.559897955766102

Epoch: 6| Step: 4
Training loss: 3.428927465526615
Validation loss: 2.556317325847428

Epoch: 6| Step: 5
Training loss: 2.615641031706068
Validation loss: 2.5701788862473656

Epoch: 6| Step: 6
Training loss: 2.5204585298540643
Validation loss: 2.576284337807816

Epoch: 6| Step: 7
Training loss: 2.939535855874807
Validation loss: 2.5768334965761053

Epoch: 6| Step: 8
Training loss: 2.6958721077521837
Validation loss: 2.555901179305189

Epoch: 6| Step: 9
Training loss: 3.2784900502025844
Validation loss: 2.566668278936427

Epoch: 6| Step: 10
Training loss: 2.3580312375886474
Validation loss: 2.563791385318064

Epoch: 6| Step: 11
Training loss: 2.0984361502273092
Validation loss: 2.560302502448017

Epoch: 6| Step: 12
Training loss: 3.0241587958851452
Validation loss: 2.574944138271933

Epoch: 6| Step: 13
Training loss: 1.3098794570819354
Validation loss: 2.554717425335145

Epoch: 72| Step: 0
Training loss: 2.512095563990277
Validation loss: 2.567278805210892

Epoch: 6| Step: 1
Training loss: 2.473200588965496
Validation loss: 2.5640324168138866

Epoch: 6| Step: 2
Training loss: 2.7638580367402046
Validation loss: 2.5696445652850755

Epoch: 6| Step: 3
Training loss: 2.5600886280394177
Validation loss: 2.5740829811155375

Epoch: 6| Step: 4
Training loss: 2.9277070128808114
Validation loss: 2.562494558573182

Epoch: 6| Step: 5
Training loss: 3.0660389285369014
Validation loss: 2.5495517318205914

Epoch: 6| Step: 6
Training loss: 2.2729401454068365
Validation loss: 2.5579365740252635

Epoch: 6| Step: 7
Training loss: 3.5387500347109153
Validation loss: 2.5662550736292595

Epoch: 6| Step: 8
Training loss: 2.3003065982966255
Validation loss: 2.5624765394543996

Epoch: 6| Step: 9
Training loss: 3.135729870197313
Validation loss: 2.5646327487794442

Epoch: 6| Step: 10
Training loss: 3.0041662532754967
Validation loss: 2.5396985379224293

Epoch: 6| Step: 11
Training loss: 2.4180584769170754
Validation loss: 2.572326181551233

Epoch: 6| Step: 12
Training loss: 2.556053053303806
Validation loss: 2.5396748995523346

Epoch: 6| Step: 13
Training loss: 3.204010185187411
Validation loss: 2.5528103711771353

Epoch: 73| Step: 0
Training loss: 2.7012056802329227
Validation loss: 2.562763420669656

Epoch: 6| Step: 1
Training loss: 3.4013824681594023
Validation loss: 2.566182129481014

Epoch: 6| Step: 2
Training loss: 2.41042263345686
Validation loss: 2.5681409926618763

Epoch: 6| Step: 3
Training loss: 2.978154114844075
Validation loss: 2.5660229443488127

Epoch: 6| Step: 4
Training loss: 2.9784046790300125
Validation loss: 2.5542362092122004

Epoch: 6| Step: 5
Training loss: 2.82135421661852
Validation loss: 2.574351686031624

Epoch: 6| Step: 6
Training loss: 3.1700432660733284
Validation loss: 2.5476044728045815

Epoch: 6| Step: 7
Training loss: 3.490033537258134
Validation loss: 2.5470645677216694

Epoch: 6| Step: 8
Training loss: 2.7759882842484527
Validation loss: 2.5519713963430357

Epoch: 6| Step: 9
Training loss: 2.299190781086522
Validation loss: 2.5687209449823283

Epoch: 6| Step: 10
Training loss: 2.5131125846808473
Validation loss: 2.553017279926727

Epoch: 6| Step: 11
Training loss: 2.1231468198214807
Validation loss: 2.5573176051064674

Epoch: 6| Step: 12
Training loss: 2.1851236787618213
Validation loss: 2.5685411379962293

Epoch: 6| Step: 13
Training loss: 2.3585544194988484
Validation loss: 2.5693148602379265

Epoch: 74| Step: 0
Training loss: 2.4157552864106084
Validation loss: 2.5503534102277494

Epoch: 6| Step: 1
Training loss: 2.2194185995741087
Validation loss: 2.5699051348009214

Epoch: 6| Step: 2
Training loss: 2.5599351467918146
Validation loss: 2.572035531788832

Epoch: 6| Step: 3
Training loss: 2.8484890195003154
Validation loss: 2.56028324930608

Epoch: 6| Step: 4
Training loss: 3.140061664826207
Validation loss: 2.5640458827206305

Epoch: 6| Step: 5
Training loss: 2.9529194432324455
Validation loss: 2.5481819691325263

Epoch: 6| Step: 6
Training loss: 3.1929272093846284
Validation loss: 2.5590202020612307

Epoch: 6| Step: 7
Training loss: 2.5311787913160932
Validation loss: 2.5593628902820686

Epoch: 6| Step: 8
Training loss: 2.198088713024551
Validation loss: 2.548707871363719

Epoch: 6| Step: 9
Training loss: 2.564233333236325
Validation loss: 2.5582346198474637

Epoch: 6| Step: 10
Training loss: 3.249338669615089
Validation loss: 2.56287576064824

Epoch: 6| Step: 11
Training loss: 3.4127624969689547
Validation loss: 2.5470570802983192

Epoch: 6| Step: 12
Training loss: 2.152844047210031
Validation loss: 2.5574374448814154

Epoch: 6| Step: 13
Training loss: 2.943227014432269
Validation loss: 2.555616404773631

Epoch: 75| Step: 0
Training loss: 3.2424033954850118
Validation loss: 2.551998446578216

Epoch: 6| Step: 1
Training loss: 3.2267956961167434
Validation loss: 2.5701227627690773

Epoch: 6| Step: 2
Training loss: 3.00336426606445
Validation loss: 2.560293991351535

Epoch: 6| Step: 3
Training loss: 2.5795042105705264
Validation loss: 2.5620576009926257

Epoch: 6| Step: 4
Training loss: 2.9005976028315694
Validation loss: 2.5543560118955435

Epoch: 6| Step: 5
Training loss: 1.9125923583225386
Validation loss: 2.5513727447392998

Epoch: 6| Step: 6
Training loss: 3.1908290158914476
Validation loss: 2.5631801703974046

Epoch: 6| Step: 7
Training loss: 2.675060670824184
Validation loss: 2.5483981485725575

Epoch: 6| Step: 8
Training loss: 2.6301012879800236
Validation loss: 2.5459342299591556

Epoch: 6| Step: 9
Training loss: 2.157522738128048
Validation loss: 2.558536584825003

Epoch: 6| Step: 10
Training loss: 2.2429806040972458
Validation loss: 2.5623211812020346

Epoch: 6| Step: 11
Training loss: 2.651322585375305
Validation loss: 2.5463019855751012

Epoch: 6| Step: 12
Training loss: 3.060290415327843
Validation loss: 2.568221884383848

Epoch: 6| Step: 13
Training loss: 2.5296509955106723
Validation loss: 2.5535505743530407

Epoch: 76| Step: 0
Training loss: 2.201127790603632
Validation loss: 2.559989754139742

Epoch: 6| Step: 1
Training loss: 3.5750851440960987
Validation loss: 2.5582187413148154

Epoch: 6| Step: 2
Training loss: 3.2704783609453254
Validation loss: 2.550867500185566

Epoch: 6| Step: 3
Training loss: 2.6467973249583614
Validation loss: 2.547251337540399

Epoch: 6| Step: 4
Training loss: 3.0932080343235104
Validation loss: 2.563791187329698

Epoch: 6| Step: 5
Training loss: 2.3253442940052644
Validation loss: 2.560730763318384

Epoch: 6| Step: 6
Training loss: 2.2942492988837255
Validation loss: 2.568527506018062

Epoch: 6| Step: 7
Training loss: 2.6634403520296037
Validation loss: 2.5511767965722916

Epoch: 6| Step: 8
Training loss: 2.646294731299052
Validation loss: 2.539486268731182

Epoch: 6| Step: 9
Training loss: 3.101424437556091
Validation loss: 2.557672140025733

Epoch: 6| Step: 10
Training loss: 2.662266995975672
Validation loss: 2.5552891987329867

Epoch: 6| Step: 11
Training loss: 2.2330039559588517
Validation loss: 2.565396098720092

Epoch: 6| Step: 12
Training loss: 2.4073431331118487
Validation loss: 2.5642327158789797

Epoch: 6| Step: 13
Training loss: 3.393810972786544
Validation loss: 2.5644726587347937

Epoch: 77| Step: 0
Training loss: 2.868777964337253
Validation loss: 2.563393326821678

Epoch: 6| Step: 1
Training loss: 2.774505581499385
Validation loss: 2.5540725937863877

Epoch: 6| Step: 2
Training loss: 2.5570698400394933
Validation loss: 2.562195608496875

Epoch: 6| Step: 3
Training loss: 2.769676215462915
Validation loss: 2.56946495962189

Epoch: 6| Step: 4
Training loss: 2.8289687441855227
Validation loss: 2.5605373564955505

Epoch: 6| Step: 5
Training loss: 2.3311248500254655
Validation loss: 2.5620844394247313

Epoch: 6| Step: 6
Training loss: 2.3477428756701637
Validation loss: 2.5577177498056285

Epoch: 6| Step: 7
Training loss: 2.669314311844197
Validation loss: 2.5664905446784094

Epoch: 6| Step: 8
Training loss: 2.266837381030261
Validation loss: 2.5763248775480236

Epoch: 6| Step: 9
Training loss: 3.315556393703642
Validation loss: 2.5601989054605268

Epoch: 6| Step: 10
Training loss: 3.5067751567675494
Validation loss: 2.5626339320916354

Epoch: 6| Step: 11
Training loss: 2.3473529841951057
Validation loss: 2.5739587157674833

Epoch: 6| Step: 12
Training loss: 2.2698826214191676
Validation loss: 2.561830043377604

Epoch: 6| Step: 13
Training loss: 3.7314017362428733
Validation loss: 2.5606304665140858

Epoch: 78| Step: 0
Training loss: 2.569949417210199
Validation loss: 2.5701103201997344

Epoch: 6| Step: 1
Training loss: 3.135601067849936
Validation loss: 2.5716063642182267

Epoch: 6| Step: 2
Training loss: 2.4608125200779045
Validation loss: 2.574245261471074

Epoch: 6| Step: 3
Training loss: 2.651458637494003
Validation loss: 2.559839392600361

Epoch: 6| Step: 4
Training loss: 2.749131325591617
Validation loss: 2.559270751381376

Epoch: 6| Step: 5
Training loss: 2.4390149421625202
Validation loss: 2.5634900198259483

Epoch: 6| Step: 6
Training loss: 2.8971869143363125
Validation loss: 2.575344828252168

Epoch: 6| Step: 7
Training loss: 2.3026813633635115
Validation loss: 2.5778476599474933

Epoch: 6| Step: 8
Training loss: 3.257615630058384
Validation loss: 2.580895451199704

Epoch: 6| Step: 9
Training loss: 2.878177711095253
Validation loss: 2.5662887930199783

Epoch: 6| Step: 10
Training loss: 3.2737690250154166
Validation loss: 2.5688651431726015

Epoch: 6| Step: 11
Training loss: 2.2785720784194505
Validation loss: 2.5668538200992956

Epoch: 6| Step: 12
Training loss: 2.8758777439517034
Validation loss: 2.5683419240615004

Epoch: 6| Step: 13
Training loss: 2.4391154291444828
Validation loss: 2.5533977894645017

Epoch: 79| Step: 0
Training loss: 3.4169044101775827
Validation loss: 2.5669835442251356

Epoch: 6| Step: 1
Training loss: 2.6495225872193555
Validation loss: 2.561274615934168

Epoch: 6| Step: 2
Training loss: 2.684917983892751
Validation loss: 2.555478761252417

Epoch: 6| Step: 3
Training loss: 2.570779775332628
Validation loss: 2.5700982546204196

Epoch: 6| Step: 4
Training loss: 3.3363169827245596
Validation loss: 2.5717750923945615

Epoch: 6| Step: 5
Training loss: 2.350261138042364
Validation loss: 2.5696442081215114

Epoch: 6| Step: 6
Training loss: 2.1781503596533027
Validation loss: 2.5583351839371575

Epoch: 6| Step: 7
Training loss: 2.419612787810941
Validation loss: 2.5637795959842045

Epoch: 6| Step: 8
Training loss: 1.3929964483206245
Validation loss: 2.5746710776975794

Epoch: 6| Step: 9
Training loss: 3.701277775117547
Validation loss: 2.5572436295839958

Epoch: 6| Step: 10
Training loss: 2.372452122131838
Validation loss: 2.5497181580409056

Epoch: 6| Step: 11
Training loss: 2.9655617710202593
Validation loss: 2.567847800582006

Epoch: 6| Step: 12
Training loss: 3.139665599437931
Validation loss: 2.534166257883824

Epoch: 6| Step: 13
Training loss: 2.42078951228581
Validation loss: 2.5437855753331218

Epoch: 80| Step: 0
Training loss: 2.773059915978633
Validation loss: 2.5647045389918914

Epoch: 6| Step: 1
Training loss: 2.420179401084775
Validation loss: 2.56395394060567

Epoch: 6| Step: 2
Training loss: 2.157038668820432
Validation loss: 2.563289355683486

Epoch: 6| Step: 3
Training loss: 2.962715360000404
Validation loss: 2.5576865134486746

Epoch: 6| Step: 4
Training loss: 3.016734813391156
Validation loss: 2.5614750380721714

Epoch: 6| Step: 5
Training loss: 2.4755208324772404
Validation loss: 2.5649656548317843

Epoch: 6| Step: 6
Training loss: 2.7117587997393624
Validation loss: 2.5570497494671884

Epoch: 6| Step: 7
Training loss: 2.9227982148802587
Validation loss: 2.562867955307596

Epoch: 6| Step: 8
Training loss: 2.619055784303562
Validation loss: 2.555799183357396

Epoch: 6| Step: 9
Training loss: 3.5718955906285337
Validation loss: 2.56272557444025

Epoch: 6| Step: 10
Training loss: 3.4060097705927164
Validation loss: 2.565229587331881

Epoch: 6| Step: 11
Training loss: 2.107444388310875
Validation loss: 2.555968296047489

Epoch: 6| Step: 12
Training loss: 1.7709741499019604
Validation loss: 2.551212912907314

Epoch: 6| Step: 13
Training loss: 3.1107518200567412
Validation loss: 2.548026392288757

Epoch: 81| Step: 0
Training loss: 2.667036706363604
Validation loss: 2.560001366150111

Epoch: 6| Step: 1
Training loss: 2.9589398975617622
Validation loss: 2.5852555316066

Epoch: 6| Step: 2
Training loss: 3.9731821857949776
Validation loss: 2.546625878698332

Epoch: 6| Step: 3
Training loss: 3.4026551481887077
Validation loss: 2.552272293565709

Epoch: 6| Step: 4
Training loss: 2.285700284966096
Validation loss: 2.567334520537513

Epoch: 6| Step: 5
Training loss: 2.639124246330047
Validation loss: 2.556425444419636

Epoch: 6| Step: 6
Training loss: 3.2039875636913098
Validation loss: 2.5432485367899464

Epoch: 6| Step: 7
Training loss: 1.8672252954464488
Validation loss: 2.56469373595236

Epoch: 6| Step: 8
Training loss: 2.623486945644534
Validation loss: 2.5683555200925983

Epoch: 6| Step: 9
Training loss: 2.8512591474989235
Validation loss: 2.563463755648373

Epoch: 6| Step: 10
Training loss: 2.4473813601175003
Validation loss: 2.5419239019590534

Epoch: 6| Step: 11
Training loss: 1.7623013296500136
Validation loss: 2.554807233354983

Epoch: 6| Step: 12
Training loss: 1.8499098214517544
Validation loss: 2.5560197043844264

Epoch: 6| Step: 13
Training loss: 3.155037373171804
Validation loss: 2.5551480630778554

Epoch: 82| Step: 0
Training loss: 3.1253516952975575
Validation loss: 2.562429751782139

Epoch: 6| Step: 1
Training loss: 3.5331589931686205
Validation loss: 2.563667473609855

Epoch: 6| Step: 2
Training loss: 3.4609990857158115
Validation loss: 2.5589020679269745

Epoch: 6| Step: 3
Training loss: 2.8077365803418672
Validation loss: 2.5626756781447932

Epoch: 6| Step: 4
Training loss: 2.548293578704982
Validation loss: 2.551990471850406

Epoch: 6| Step: 5
Training loss: 2.5008901918534896
Validation loss: 2.5716791290909957

Epoch: 6| Step: 6
Training loss: 2.246991795673001
Validation loss: 2.5735629211992057

Epoch: 6| Step: 7
Training loss: 2.1163132329913448
Validation loss: 2.5690474511603445

Epoch: 6| Step: 8
Training loss: 2.1531969653589194
Validation loss: 2.5441048698435544

Epoch: 6| Step: 9
Training loss: 2.703183388492858
Validation loss: 2.5573126889764817

Epoch: 6| Step: 10
Training loss: 2.733399571414779
Validation loss: 2.5753339797575574

Epoch: 6| Step: 11
Training loss: 3.1907563872751257
Validation loss: 2.5442756389715657

Epoch: 6| Step: 12
Training loss: 2.332304818674419
Validation loss: 2.5493069468787275

Epoch: 6| Step: 13
Training loss: 2.178312024880843
Validation loss: 2.5739501442515884

Epoch: 83| Step: 0
Training loss: 2.5186597632816206
Validation loss: 2.559971791496207

Epoch: 6| Step: 1
Training loss: 1.9927141877118457
Validation loss: 2.559445872905602

Epoch: 6| Step: 2
Training loss: 2.861951657210165
Validation loss: 2.5431064506493812

Epoch: 6| Step: 3
Training loss: 3.038041205522907
Validation loss: 2.5719991935245554

Epoch: 6| Step: 4
Training loss: 3.1164097018735584
Validation loss: 2.5608940594677

Epoch: 6| Step: 5
Training loss: 2.506623648856045
Validation loss: 2.5656385602279563

Epoch: 6| Step: 6
Training loss: 2.4517323616850475
Validation loss: 2.548483295411092

Epoch: 6| Step: 7
Training loss: 2.7007834816576692
Validation loss: 2.5448101165449084

Epoch: 6| Step: 8
Training loss: 2.6708067604524417
Validation loss: 2.5529825638332047

Epoch: 6| Step: 9
Training loss: 2.4632179956272515
Validation loss: 2.555605954041393

Epoch: 6| Step: 10
Training loss: 3.2029983123288934
Validation loss: 2.5504419103922467

Epoch: 6| Step: 11
Training loss: 3.100702969001955
Validation loss: 2.5502058039421684

Epoch: 6| Step: 12
Training loss: 3.056402559119717
Validation loss: 2.5482030883939686

Epoch: 6| Step: 13
Training loss: 2.1036814391398693
Validation loss: 2.5560568796256784

Epoch: 84| Step: 0
Training loss: 2.252343970175371
Validation loss: 2.5444299932723475

Epoch: 6| Step: 1
Training loss: 2.603378898996829
Validation loss: 2.5551078294803036

Epoch: 6| Step: 2
Training loss: 2.6377994385454557
Validation loss: 2.5463499434798362

Epoch: 6| Step: 3
Training loss: 2.6029411992903126
Validation loss: 2.550188379570037

Epoch: 6| Step: 4
Training loss: 2.1500420144877403
Validation loss: 2.5628050735838808

Epoch: 6| Step: 5
Training loss: 2.2228905096782383
Validation loss: 2.557341729493981

Epoch: 6| Step: 6
Training loss: 2.693768664514442
Validation loss: 2.558293071439501

Epoch: 6| Step: 7
Training loss: 2.825076319921093
Validation loss: 2.5546210480652047

Epoch: 6| Step: 8
Training loss: 3.1145337121045022
Validation loss: 2.568497363299597

Epoch: 6| Step: 9
Training loss: 2.2424402393556218
Validation loss: 2.563402940731084

Epoch: 6| Step: 10
Training loss: 3.3557063452697395
Validation loss: 2.561355792567999

Epoch: 6| Step: 11
Training loss: 3.2108228528422407
Validation loss: 2.550264873819009

Epoch: 6| Step: 12
Training loss: 3.1396005962043203
Validation loss: 2.5758426650615003

Epoch: 6| Step: 13
Training loss: 3.2868134336477666
Validation loss: 2.563478869646619

Epoch: 85| Step: 0
Training loss: 2.8172467336071256
Validation loss: 2.5491469835095915

Epoch: 6| Step: 1
Training loss: 2.537897306259964
Validation loss: 2.5612982496371037

Epoch: 6| Step: 2
Training loss: 2.52390060663168
Validation loss: 2.552478931564186

Epoch: 6| Step: 3
Training loss: 2.7993511129264195
Validation loss: 2.554249567179595

Epoch: 6| Step: 4
Training loss: 2.1296140281670914
Validation loss: 2.557336774314236

Epoch: 6| Step: 5
Training loss: 2.7952118942383253
Validation loss: 2.5585249275896613

Epoch: 6| Step: 6
Training loss: 2.5266211300607346
Validation loss: 2.5524050769485296

Epoch: 6| Step: 7
Training loss: 2.969071862692124
Validation loss: 2.5736001020253383

Epoch: 6| Step: 8
Training loss: 2.850769936143708
Validation loss: 2.5408933388662676

Epoch: 6| Step: 9
Training loss: 2.174513826074983
Validation loss: 2.5373394436700294

Epoch: 6| Step: 10
Training loss: 3.2188483658361564
Validation loss: 2.5494591010798135

Epoch: 6| Step: 11
Training loss: 2.774898176644878
Validation loss: 2.536654929640758

Epoch: 6| Step: 12
Training loss: 3.3517005020575996
Validation loss: 2.564674858137544

Epoch: 6| Step: 13
Training loss: 2.624406838384044
Validation loss: 2.553854426256548

Epoch: 86| Step: 0
Training loss: 2.7976449940105352
Validation loss: 2.5567435479647096

Epoch: 6| Step: 1
Training loss: 2.279121137184021
Validation loss: 2.5498153892348405

Epoch: 6| Step: 2
Training loss: 3.207492288771984
Validation loss: 2.558515783326107

Epoch: 6| Step: 3
Training loss: 2.5205741202593974
Validation loss: 2.557774649632223

Epoch: 6| Step: 4
Training loss: 2.4882613200732466
Validation loss: 2.560835671248123

Epoch: 6| Step: 5
Training loss: 2.918217782420422
Validation loss: 2.5570199747461935

Epoch: 6| Step: 6
Training loss: 2.479078488958941
Validation loss: 2.532794894673042

Epoch: 6| Step: 7
Training loss: 2.7753055782294083
Validation loss: 2.578725059485341

Epoch: 6| Step: 8
Training loss: 2.902507382037676
Validation loss: 2.555745249822633

Epoch: 6| Step: 9
Training loss: 3.31616382589003
Validation loss: 2.552124205599568

Epoch: 6| Step: 10
Training loss: 2.080696981003676
Validation loss: 2.5630150584239835

Epoch: 6| Step: 11
Training loss: 2.2190787917971955
Validation loss: 2.5603634781196862

Epoch: 6| Step: 12
Training loss: 2.9471009185049195
Validation loss: 2.563194032849812

Epoch: 6| Step: 13
Training loss: 3.160220679532866
Validation loss: 2.5515535314907813

Epoch: 87| Step: 0
Training loss: 2.334876186184092
Validation loss: 2.566485078748864

Epoch: 6| Step: 1
Training loss: 2.6265948763910734
Validation loss: 2.5563534447704996

Epoch: 6| Step: 2
Training loss: 2.5610701130389555
Validation loss: 2.5605045290478494

Epoch: 6| Step: 3
Training loss: 2.519375676519577
Validation loss: 2.5484454131551013

Epoch: 6| Step: 4
Training loss: 2.7383643122766714
Validation loss: 2.5587584609653495

Epoch: 6| Step: 5
Training loss: 2.380006933282322
Validation loss: 2.546645404213862

Epoch: 6| Step: 6
Training loss: 2.7135092549697784
Validation loss: 2.555563443456921

Epoch: 6| Step: 7
Training loss: 2.349464672069
Validation loss: 2.5625510402011282

Epoch: 6| Step: 8
Training loss: 3.5422082524308007
Validation loss: 2.5615513504000784

Epoch: 6| Step: 9
Training loss: 2.54978411639538
Validation loss: 2.555974550257156

Epoch: 6| Step: 10
Training loss: 3.1032356726511523
Validation loss: 2.5628794832561956

Epoch: 6| Step: 11
Training loss: 3.1515204620205433
Validation loss: 2.5609752721892156

Epoch: 6| Step: 12
Training loss: 2.3858680020486176
Validation loss: 2.5490825071790995

Epoch: 6| Step: 13
Training loss: 3.2203258619628174
Validation loss: 2.568600610622068

Epoch: 88| Step: 0
Training loss: 2.3610130838227943
Validation loss: 2.5539822530240444

Epoch: 6| Step: 1
Training loss: 2.572111572657708
Validation loss: 2.549922213090796

Epoch: 6| Step: 2
Training loss: 3.137321898736096
Validation loss: 2.5576940594633846

Epoch: 6| Step: 3
Training loss: 2.6780993145453205
Validation loss: 2.5549483898443937

Epoch: 6| Step: 4
Training loss: 3.2738765158136154
Validation loss: 2.5417189818804165

Epoch: 6| Step: 5
Training loss: 2.7485050993343445
Validation loss: 2.5570677356449147

Epoch: 6| Step: 6
Training loss: 3.2985507268007614
Validation loss: 2.5490131835743326

Epoch: 6| Step: 7
Training loss: 3.0712215252411363
Validation loss: 2.5562156584077362

Epoch: 6| Step: 8
Training loss: 2.3142205101327407
Validation loss: 2.55337340893789

Epoch: 6| Step: 9
Training loss: 2.5880366446127927
Validation loss: 2.54627087396945

Epoch: 6| Step: 10
Training loss: 3.211477712217436
Validation loss: 2.546008134332372

Epoch: 6| Step: 11
Training loss: 2.17380509274355
Validation loss: 2.5578858697075053

Epoch: 6| Step: 12
Training loss: 2.302948065784631
Validation loss: 2.5497582645353125

Epoch: 6| Step: 13
Training loss: 1.3176822986468462
Validation loss: 2.57229156360219

Epoch: 89| Step: 0
Training loss: 2.3551315648287225
Validation loss: 2.5436208976368757

Epoch: 6| Step: 1
Training loss: 2.616795570292349
Validation loss: 2.561919372410645

Epoch: 6| Step: 2
Training loss: 3.123750513144669
Validation loss: 2.551387224991327

Epoch: 6| Step: 3
Training loss: 3.2206533785575955
Validation loss: 2.5522760256125765

Epoch: 6| Step: 4
Training loss: 3.3161879828240677
Validation loss: 2.5573914030614877

Epoch: 6| Step: 5
Training loss: 2.7303211788962116
Validation loss: 2.56007767183583

Epoch: 6| Step: 6
Training loss: 2.448214140869467
Validation loss: 2.562845940577842

Epoch: 6| Step: 7
Training loss: 2.057228750562541
Validation loss: 2.561354657556169

Epoch: 6| Step: 8
Training loss: 2.454425442776861
Validation loss: 2.5581490429609377

Epoch: 6| Step: 9
Training loss: 2.908630708576968
Validation loss: 2.571288940862892

Epoch: 6| Step: 10
Training loss: 2.345524434089452
Validation loss: 2.5703519370618695

Epoch: 6| Step: 11
Training loss: 3.1607434607784155
Validation loss: 2.575031473708359

Epoch: 6| Step: 12
Training loss: 2.7264409516357304
Validation loss: 2.561838786537623

Epoch: 6| Step: 13
Training loss: 2.25815334189309
Validation loss: 2.5639760868035046

Epoch: 90| Step: 0
Training loss: 2.629057065086864
Validation loss: 2.553328984636328

Epoch: 6| Step: 1
Training loss: 2.5043211785081625
Validation loss: 2.555695176118855

Epoch: 6| Step: 2
Training loss: 2.470540230549124
Validation loss: 2.580554464564064

Epoch: 6| Step: 3
Training loss: 2.49453643788731
Validation loss: 2.566767270117267

Epoch: 6| Step: 4
Training loss: 2.6058435356380403
Validation loss: 2.542303315414021

Epoch: 6| Step: 5
Training loss: 2.8825223616487823
Validation loss: 2.5483190319527265

Epoch: 6| Step: 6
Training loss: 2.2637320141048827
Validation loss: 2.5722550086950053

Epoch: 6| Step: 7
Training loss: 2.5064409254605398
Validation loss: 2.5817461851017316

Epoch: 6| Step: 8
Training loss: 3.281661234925907
Validation loss: 2.5697744428278897

Epoch: 6| Step: 9
Training loss: 1.9792133392720186
Validation loss: 2.554266712930171

Epoch: 6| Step: 10
Training loss: 3.8314807119181458
Validation loss: 2.5673448935702865

Epoch: 6| Step: 11
Training loss: 2.160559287248517
Validation loss: 2.543843025634443

Epoch: 6| Step: 12
Training loss: 3.2056993513582692
Validation loss: 2.5583047227167235

Epoch: 6| Step: 13
Training loss: 2.9347043633588346
Validation loss: 2.5475741464267307

Epoch: 91| Step: 0
Training loss: 3.125161433818541
Validation loss: 2.535961692676009

Epoch: 6| Step: 1
Training loss: 3.218750592574278
Validation loss: 2.561065726637026

Epoch: 6| Step: 2
Training loss: 2.902659834108852
Validation loss: 2.5475048064310983

Epoch: 6| Step: 3
Training loss: 3.041214443364253
Validation loss: 2.5475422971274293

Epoch: 6| Step: 4
Training loss: 2.9179115545139163
Validation loss: 2.5544184352113106

Epoch: 6| Step: 5
Training loss: 2.1146406219188605
Validation loss: 2.569380781483828

Epoch: 6| Step: 6
Training loss: 2.373944901454455
Validation loss: 2.5524463936927244

Epoch: 6| Step: 7
Training loss: 2.4751161027899355
Validation loss: 2.556143769189713

Epoch: 6| Step: 8
Training loss: 1.995716096571204
Validation loss: 2.5420773275441753

Epoch: 6| Step: 9
Training loss: 3.1576695035620155
Validation loss: 2.5573406057326347

Epoch: 6| Step: 10
Training loss: 1.9978329123509322
Validation loss: 2.5510442497331356

Epoch: 6| Step: 11
Training loss: 3.1150627830387223
Validation loss: 2.567447006990805

Epoch: 6| Step: 12
Training loss: 2.9390339194433723
Validation loss: 2.55187435403692

Epoch: 6| Step: 13
Training loss: 1.8488602374923182
Validation loss: 2.5554068688602416

Epoch: 92| Step: 0
Training loss: 2.3314534402804523
Validation loss: 2.549916168739448

Epoch: 6| Step: 1
Training loss: 2.9197538295602823
Validation loss: 2.547807269322415

Epoch: 6| Step: 2
Training loss: 2.7433244136172426
Validation loss: 2.5519926351804925

Epoch: 6| Step: 3
Training loss: 2.9247376805241747
Validation loss: 2.5550504167452233

Epoch: 6| Step: 4
Training loss: 2.3417840468919913
Validation loss: 2.5453389856560475

Epoch: 6| Step: 5
Training loss: 2.79363399665876
Validation loss: 2.5449483179402446

Epoch: 6| Step: 6
Training loss: 3.115362794913797
Validation loss: 2.553071427233496

Epoch: 6| Step: 7
Training loss: 2.7091625900339578
Validation loss: 2.570293033088648

Epoch: 6| Step: 8
Training loss: 2.1762312418629373
Validation loss: 2.5558189838450263

Epoch: 6| Step: 9
Training loss: 2.2470467577399735
Validation loss: 2.5426207623882147

Epoch: 6| Step: 10
Training loss: 2.7985249346477103
Validation loss: 2.5618222268451976

Epoch: 6| Step: 11
Training loss: 3.000191364542761
Validation loss: 2.551220413255669

Epoch: 6| Step: 12
Training loss: 3.115688795471565
Validation loss: 2.562430176982939

Epoch: 6| Step: 13
Training loss: 2.874590471373756
Validation loss: 2.5427441712754346

Epoch: 93| Step: 0
Training loss: 3.7905554907354575
Validation loss: 2.5560239630405905

Epoch: 6| Step: 1
Training loss: 2.9304829649248676
Validation loss: 2.557874233059578

Epoch: 6| Step: 2
Training loss: 2.491445018219064
Validation loss: 2.553663557044393

Epoch: 6| Step: 3
Training loss: 2.7677674696499066
Validation loss: 2.5626319132980906

Epoch: 6| Step: 4
Training loss: 1.618428808919254
Validation loss: 2.5657303350622724

Epoch: 6| Step: 5
Training loss: 2.8297185465364403
Validation loss: 2.559056373497605

Epoch: 6| Step: 6
Training loss: 2.64279690419774
Validation loss: 2.565001263680025

Epoch: 6| Step: 7
Training loss: 2.76340063266994
Validation loss: 2.5409597422060473

Epoch: 6| Step: 8
Training loss: 2.9965831053571685
Validation loss: 2.5515013027094553

Epoch: 6| Step: 9
Training loss: 2.7647909857335873
Validation loss: 2.546984724223738

Epoch: 6| Step: 10
Training loss: 2.086523423788086
Validation loss: 2.561423826300278

Epoch: 6| Step: 11
Training loss: 2.605198607387841
Validation loss: 2.560175958551223

Epoch: 6| Step: 12
Training loss: 2.6107550529322228
Validation loss: 2.5552146849103448

Epoch: 6| Step: 13
Training loss: 2.6748214448178995
Validation loss: 2.560350990125597

Epoch: 94| Step: 0
Training loss: 2.4313509726456726
Validation loss: 2.547610219746586

Epoch: 6| Step: 1
Training loss: 2.443128494100153
Validation loss: 2.5521640111055075

Epoch: 6| Step: 2
Training loss: 2.4416902178603896
Validation loss: 2.5513783937655847

Epoch: 6| Step: 3
Training loss: 3.1426101407920894
Validation loss: 2.5392686521329892

Epoch: 6| Step: 4
Training loss: 1.920996550481937
Validation loss: 2.549797417252222

Epoch: 6| Step: 5
Training loss: 3.1511149416303765
Validation loss: 2.5568650750344766

Epoch: 6| Step: 6
Training loss: 3.335321088029443
Validation loss: 2.548737620474546

Epoch: 6| Step: 7
Training loss: 1.8139106259772566
Validation loss: 2.542204661917435

Epoch: 6| Step: 8
Training loss: 2.4346517892754136
Validation loss: 2.5521758219517983

Epoch: 6| Step: 9
Training loss: 2.761078626807039
Validation loss: 2.546639754755488

Epoch: 6| Step: 10
Training loss: 3.3748779274798406
Validation loss: 2.552871536845753

Epoch: 6| Step: 11
Training loss: 2.6782328491573355
Validation loss: 2.5538620633985056

Epoch: 6| Step: 12
Training loss: 3.1115529469443683
Validation loss: 2.54790513287207

Epoch: 6| Step: 13
Training loss: 2.64323116108235
Validation loss: 2.555947765522521

Epoch: 95| Step: 0
Training loss: 3.7897840304477146
Validation loss: 2.551059751855566

Epoch: 6| Step: 1
Training loss: 2.0104457345814577
Validation loss: 2.5554987347643694

Epoch: 6| Step: 2
Training loss: 3.072872424480683
Validation loss: 2.5377925208944996

Epoch: 6| Step: 3
Training loss: 1.8166591673296673
Validation loss: 2.5609079983633487

Epoch: 6| Step: 4
Training loss: 2.9048685051314274
Validation loss: 2.555255196741005

Epoch: 6| Step: 5
Training loss: 2.814475827784041
Validation loss: 2.5518939483937997

Epoch: 6| Step: 6
Training loss: 2.428384216690108
Validation loss: 2.5491777552945143

Epoch: 6| Step: 7
Training loss: 2.6164434029967483
Validation loss: 2.5459962253960655

Epoch: 6| Step: 8
Training loss: 2.6174234312384375
Validation loss: 2.554155961576844

Epoch: 6| Step: 9
Training loss: 2.473166462837727
Validation loss: 2.542767099059326

Epoch: 6| Step: 10
Training loss: 2.7488021842856827
Validation loss: 2.5573133646441732

Epoch: 6| Step: 11
Training loss: 2.446196667416819
Validation loss: 2.5477772698664864

Epoch: 6| Step: 12
Training loss: 3.1023752219093503
Validation loss: 2.55045125046193

Epoch: 6| Step: 13
Training loss: 2.74426781844903
Validation loss: 2.562667584085402

Epoch: 96| Step: 0
Training loss: 3.2077765208668616
Validation loss: 2.541389117997363

Epoch: 6| Step: 1
Training loss: 2.905094532306683
Validation loss: 2.5709044411363586

Epoch: 6| Step: 2
Training loss: 3.2918750037082303
Validation loss: 2.5422376132292497

Epoch: 6| Step: 3
Training loss: 2.4682013952352846
Validation loss: 2.5593749468715994

Epoch: 6| Step: 4
Training loss: 3.0943935765259907
Validation loss: 2.550984617035774

Epoch: 6| Step: 5
Training loss: 2.986668369627649
Validation loss: 2.5627900006268733

Epoch: 6| Step: 6
Training loss: 2.639276013226529
Validation loss: 2.543285723818937

Epoch: 6| Step: 7
Training loss: 2.525174042397271
Validation loss: 2.5648755902996454

Epoch: 6| Step: 8
Training loss: 2.6170013817042665
Validation loss: 2.5373845075989143

Epoch: 6| Step: 9
Training loss: 1.9741894495261185
Validation loss: 2.548419029638843

Epoch: 6| Step: 10
Training loss: 2.174942485005025
Validation loss: 2.5517963588779162

Epoch: 6| Step: 11
Training loss: 2.802754450603188
Validation loss: 2.5544535653444576

Epoch: 6| Step: 12
Training loss: 2.474788571969765
Validation loss: 2.5577206966120642

Epoch: 6| Step: 13
Training loss: 2.263974766054827
Validation loss: 2.5594237916800533

Epoch: 97| Step: 0
Training loss: 2.271077507493733
Validation loss: 2.5546885637146453

Epoch: 6| Step: 1
Training loss: 1.9544705448151238
Validation loss: 2.5427806785898817

Epoch: 6| Step: 2
Training loss: 2.495320709348777
Validation loss: 2.5540677256127258

Epoch: 6| Step: 3
Training loss: 2.954922890730168
Validation loss: 2.554045238544973

Epoch: 6| Step: 4
Training loss: 2.795843349690884
Validation loss: 2.5650140268743087

Epoch: 6| Step: 5
Training loss: 3.1367350158649705
Validation loss: 2.5613676140766546

Epoch: 6| Step: 6
Training loss: 2.930460184563262
Validation loss: 2.5675006208269173

Epoch: 6| Step: 7
Training loss: 2.4528060025350102
Validation loss: 2.5460823758844247

Epoch: 6| Step: 8
Training loss: 3.264755644365966
Validation loss: 2.55979301441351

Epoch: 6| Step: 9
Training loss: 2.230348279809516
Validation loss: 2.551677970176663

Epoch: 6| Step: 10
Training loss: 2.954565917791181
Validation loss: 2.559931818979632

Epoch: 6| Step: 11
Training loss: 2.920828728846804
Validation loss: 2.551847758835597

Epoch: 6| Step: 12
Training loss: 2.4541487774631405
Validation loss: 2.55369985454867

Epoch: 6| Step: 13
Training loss: 3.0081374748346996
Validation loss: 2.5508571114032357

Epoch: 98| Step: 0
Training loss: 2.6981103501088954
Validation loss: 2.5601117970361207

Epoch: 6| Step: 1
Training loss: 3.0421224452950555
Validation loss: 2.546305993679951

Epoch: 6| Step: 2
Training loss: 2.42189252293308
Validation loss: 2.56843933357811

Epoch: 6| Step: 3
Training loss: 2.427421076991376
Validation loss: 2.554767880456723

Epoch: 6| Step: 4
Training loss: 2.5859221950665856
Validation loss: 2.55842850837333

Epoch: 6| Step: 5
Training loss: 2.3383880315552004
Validation loss: 2.554641030792012

Epoch: 6| Step: 6
Training loss: 3.101366012844966
Validation loss: 2.5629141698200777

Epoch: 6| Step: 7
Training loss: 2.828386579187312
Validation loss: 2.5696623695265273

Epoch: 6| Step: 8
Training loss: 2.67016207570984
Validation loss: 2.56487755935036

Epoch: 6| Step: 9
Training loss: 2.736541587241753
Validation loss: 2.559205823886256

Epoch: 6| Step: 10
Training loss: 3.121916203040785
Validation loss: 2.5618117513934826

Epoch: 6| Step: 11
Training loss: 2.0798033626848724
Validation loss: 2.5670077425570486

Epoch: 6| Step: 12
Training loss: 3.080494235129489
Validation loss: 2.56889668420032

Epoch: 6| Step: 13
Training loss: 2.8472312327503406
Validation loss: 2.562849589706427

Epoch: 99| Step: 0
Training loss: 2.718401305539523
Validation loss: 2.58055706043627

Epoch: 6| Step: 1
Training loss: 3.1247811813037845
Validation loss: 2.552751441547837

Epoch: 6| Step: 2
Training loss: 2.977628261772718
Validation loss: 2.5712634268538275

Epoch: 6| Step: 3
Training loss: 2.398757962864177
Validation loss: 2.549880662410203

Epoch: 6| Step: 4
Training loss: 2.4211894387867363
Validation loss: 2.5508235709351994

Epoch: 6| Step: 5
Training loss: 2.6461884167712704
Validation loss: 2.5806175873293355

Epoch: 6| Step: 6
Training loss: 2.047734553278256
Validation loss: 2.539628049656377

Epoch: 6| Step: 7
Training loss: 2.4339885360836484
Validation loss: 2.5539464448686062

Epoch: 6| Step: 8
Training loss: 2.8759037753416603
Validation loss: 2.5361717510139177

Epoch: 6| Step: 9
Training loss: 3.042197838654508
Validation loss: 2.5575701004333045

Epoch: 6| Step: 10
Training loss: 3.4944842336465194
Validation loss: 2.5520287851745116

Epoch: 6| Step: 11
Training loss: 3.061499918918836
Validation loss: 2.558689451615741

Epoch: 6| Step: 12
Training loss: 2.1822173501215194
Validation loss: 2.566530421039131

Epoch: 6| Step: 13
Training loss: 2.0752613730294165
Validation loss: 2.5627205946579394

Epoch: 100| Step: 0
Training loss: 2.0872439747123823
Validation loss: 2.5545827129050283

Epoch: 6| Step: 1
Training loss: 3.2099480136928
Validation loss: 2.569094061433787

Epoch: 6| Step: 2
Training loss: 2.0186398455443424
Validation loss: 2.546220320952712

Epoch: 6| Step: 3
Training loss: 3.1642347500856984
Validation loss: 2.5551422819200953

Epoch: 6| Step: 4
Training loss: 3.0249812795516906
Validation loss: 2.5527450423589704

Epoch: 6| Step: 5
Training loss: 1.7808184184531428
Validation loss: 2.5562060084407334

Epoch: 6| Step: 6
Training loss: 2.4845030169822784
Validation loss: 2.543601693598604

Epoch: 6| Step: 7
Training loss: 3.3226338966778357
Validation loss: 2.552941989829892

Epoch: 6| Step: 8
Training loss: 2.9287723179942504
Validation loss: 2.5591460127219166

Epoch: 6| Step: 9
Training loss: 2.713502050148418
Validation loss: 2.546464504587267

Epoch: 6| Step: 10
Training loss: 2.852221101972737
Validation loss: 2.563245039228037

Epoch: 6| Step: 11
Training loss: 2.701326334102911
Validation loss: 2.5345544811722713

Epoch: 6| Step: 12
Training loss: 2.8805423885458574
Validation loss: 2.5523061695633835

Epoch: 6| Step: 13
Training loss: 1.7104034983987242
Validation loss: 2.55647643642602

Testing loss: 2.471008437386491
