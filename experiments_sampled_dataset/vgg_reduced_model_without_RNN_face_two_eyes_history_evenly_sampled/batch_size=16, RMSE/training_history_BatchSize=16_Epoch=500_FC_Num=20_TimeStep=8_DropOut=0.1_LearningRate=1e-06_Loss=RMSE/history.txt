Epoch: 1| Step: 0
Training loss: 4.984342473321574
Validation loss: 4.639640979165693

Epoch: 6| Step: 1
Training loss: 5.0130875012477105
Validation loss: 4.635398463008026

Epoch: 6| Step: 2
Training loss: 3.970679467426757
Validation loss: 4.629589988201519

Epoch: 6| Step: 3
Training loss: 5.05545759746587
Validation loss: 4.6252720460975585

Epoch: 6| Step: 4
Training loss: 4.396349233332232
Validation loss: 4.621438969998847

Epoch: 6| Step: 5
Training loss: 5.838007589159505
Validation loss: 4.616327310891741

Epoch: 6| Step: 6
Training loss: 4.201549816289776
Validation loss: 4.615439851202636

Epoch: 6| Step: 7
Training loss: 4.586243601368526
Validation loss: 4.608765400126885

Epoch: 6| Step: 8
Training loss: 5.150910543297061
Validation loss: 4.602060359134185

Epoch: 6| Step: 9
Training loss: 4.569981541836314
Validation loss: 4.601321294667642

Epoch: 6| Step: 10
Training loss: 4.029346578553111
Validation loss: 4.59477113713445

Epoch: 6| Step: 11
Training loss: 4.942139389474473
Validation loss: 4.591026272720924

Epoch: 6| Step: 12
Training loss: 4.174520846527862
Validation loss: 4.58844307505392

Epoch: 6| Step: 13
Training loss: 4.782870946637333
Validation loss: 4.581696858981153

Epoch: 2| Step: 0
Training loss: 3.5399110968250733
Validation loss: 4.580888915577651

Epoch: 6| Step: 1
Training loss: 4.242307994950795
Validation loss: 4.574789102248956

Epoch: 6| Step: 2
Training loss: 4.676758934047944
Validation loss: 4.574442995725582

Epoch: 6| Step: 3
Training loss: 5.346430234620303
Validation loss: 4.57071490707807

Epoch: 6| Step: 4
Training loss: 5.9535241981886635
Validation loss: 4.564188425801801

Epoch: 6| Step: 5
Training loss: 4.882287862439956
Validation loss: 4.560442094178203

Epoch: 6| Step: 6
Training loss: 4.18211109093002
Validation loss: 4.554273517406967

Epoch: 6| Step: 7
Training loss: 4.692588993746778
Validation loss: 4.551129689970082

Epoch: 6| Step: 8
Training loss: 4.597795638286386
Validation loss: 4.54757014953695

Epoch: 6| Step: 9
Training loss: 4.777796476657757
Validation loss: 4.543342121354625

Epoch: 6| Step: 10
Training loss: 4.865867668475404
Validation loss: 4.538384272643146

Epoch: 6| Step: 11
Training loss: 4.445790886907235
Validation loss: 4.53311931678277

Epoch: 6| Step: 12
Training loss: 3.5898074873627532
Validation loss: 4.5299903734103015

Epoch: 6| Step: 13
Training loss: 5.072378434199909
Validation loss: 4.521726276343801

Epoch: 3| Step: 0
Training loss: 4.560989338814474
Validation loss: 4.5205538811566335

Epoch: 6| Step: 1
Training loss: 4.891903646123764
Validation loss: 4.515339633403582

Epoch: 6| Step: 2
Training loss: 4.645249858989439
Validation loss: 4.510749638447001

Epoch: 6| Step: 3
Training loss: 4.6938157322086775
Validation loss: 4.5058851873713

Epoch: 6| Step: 4
Training loss: 5.041271015542454
Validation loss: 4.502629130745775

Epoch: 6| Step: 5
Training loss: 4.913218609226622
Validation loss: 4.4970919066640604

Epoch: 6| Step: 6
Training loss: 4.787583687551333
Validation loss: 4.4936103668236385

Epoch: 6| Step: 7
Training loss: 4.722606573482529
Validation loss: 4.490228827773348

Epoch: 6| Step: 8
Training loss: 4.404168252695039
Validation loss: 4.485287665238293

Epoch: 6| Step: 9
Training loss: 4.3488807290590366
Validation loss: 4.480257710817433

Epoch: 6| Step: 10
Training loss: 4.058567667520257
Validation loss: 4.475190614302641

Epoch: 6| Step: 11
Training loss: 4.082161144763446
Validation loss: 4.467669851473021

Epoch: 6| Step: 12
Training loss: 4.3906176149570895
Validation loss: 4.463265623399289

Epoch: 6| Step: 13
Training loss: 4.868815485032774
Validation loss: 4.458781483877642

Epoch: 4| Step: 0
Training loss: 3.3444012159283503
Validation loss: 4.455027732077327

Epoch: 6| Step: 1
Training loss: 5.146046478346246
Validation loss: 4.45069355497703

Epoch: 6| Step: 2
Training loss: 4.670989395969109
Validation loss: 4.441626848679824

Epoch: 6| Step: 3
Training loss: 5.172444753006105
Validation loss: 4.4419531240248595

Epoch: 6| Step: 4
Training loss: 3.922289457876564
Validation loss: 4.4321890996104765

Epoch: 6| Step: 5
Training loss: 4.752703650143146
Validation loss: 4.428454885045159

Epoch: 6| Step: 6
Training loss: 4.401098391677088
Validation loss: 4.424143131627955

Epoch: 6| Step: 7
Training loss: 4.440112137624199
Validation loss: 4.419047109831524

Epoch: 6| Step: 8
Training loss: 4.581190313390178
Validation loss: 4.410490068518732

Epoch: 6| Step: 9
Training loss: 3.828907540194067
Validation loss: 4.407927637750995

Epoch: 6| Step: 10
Training loss: 3.597587062903537
Validation loss: 4.405357780762738

Epoch: 6| Step: 11
Training loss: 4.359332997109478
Validation loss: 4.399229171032867

Epoch: 6| Step: 12
Training loss: 5.383787733963875
Validation loss: 4.3933661533293575

Epoch: 6| Step: 13
Training loss: 5.822520816384134
Validation loss: 4.385460422106523

Epoch: 5| Step: 0
Training loss: 4.743408247105245
Validation loss: 4.381003254783778

Epoch: 6| Step: 1
Training loss: 4.243999059276135
Validation loss: 4.377854421886603

Epoch: 6| Step: 2
Training loss: 3.2273693045844363
Validation loss: 4.370697873628494

Epoch: 6| Step: 3
Training loss: 5.033316051798747
Validation loss: 4.360683633314648

Epoch: 6| Step: 4
Training loss: 4.408594468187851
Validation loss: 4.3620335492298095

Epoch: 6| Step: 5
Training loss: 4.084286066092547
Validation loss: 4.3557265456413825

Epoch: 6| Step: 6
Training loss: 4.723326226127911
Validation loss: 4.349163137202546

Epoch: 6| Step: 7
Training loss: 4.13238003925321
Validation loss: 4.342177811144923

Epoch: 6| Step: 8
Training loss: 3.5152571422129144
Validation loss: 4.337483185936522

Epoch: 6| Step: 9
Training loss: 4.593858367264529
Validation loss: 4.333849652927534

Epoch: 6| Step: 10
Training loss: 5.684799391562947
Validation loss: 4.3247435134326855

Epoch: 6| Step: 11
Training loss: 3.9570378777014463
Validation loss: 4.318290070483317

Epoch: 6| Step: 12
Training loss: 4.629892596653077
Validation loss: 4.311664461716509

Epoch: 6| Step: 13
Training loss: 5.239186549346429
Validation loss: 4.3083908766191525

Epoch: 6| Step: 0
Training loss: 4.6411196255627996
Validation loss: 4.29965694935421

Epoch: 6| Step: 1
Training loss: 3.677391421169325
Validation loss: 4.295263422160686

Epoch: 6| Step: 2
Training loss: 5.533721199382925
Validation loss: 4.286571690129787

Epoch: 6| Step: 3
Training loss: 4.345027159506106
Validation loss: 4.279381430694451

Epoch: 6| Step: 4
Training loss: 4.308097250475628
Validation loss: 4.272689795617819

Epoch: 6| Step: 5
Training loss: 4.58702830870205
Validation loss: 4.267333531627738

Epoch: 6| Step: 6
Training loss: 4.349609594255158
Validation loss: 4.259245901506437

Epoch: 6| Step: 7
Training loss: 4.107029931073832
Validation loss: 4.2518002595750035

Epoch: 6| Step: 8
Training loss: 4.380964083191937
Validation loss: 4.246599290555123

Epoch: 6| Step: 9
Training loss: 4.136068118244641
Validation loss: 4.239813998378471

Epoch: 6| Step: 10
Training loss: 3.769738700574016
Validation loss: 4.233679871590112

Epoch: 6| Step: 11
Training loss: 3.382731870610981
Validation loss: 4.228327801879797

Epoch: 6| Step: 12
Training loss: 4.434749556806088
Validation loss: 4.221451599600355

Epoch: 6| Step: 13
Training loss: 5.745436142583595
Validation loss: 4.212241444077976

Epoch: 7| Step: 0
Training loss: 5.023079439635089
Validation loss: 4.206903121812591

Epoch: 6| Step: 1
Training loss: 4.375947250271443
Validation loss: 4.19651652161452

Epoch: 6| Step: 2
Training loss: 4.6310146503649205
Validation loss: 4.192366811969544

Epoch: 6| Step: 3
Training loss: 3.7907758791238333
Validation loss: 4.184124989243266

Epoch: 6| Step: 4
Training loss: 4.3447290867673605
Validation loss: 4.176305076911016

Epoch: 6| Step: 5
Training loss: 4.544531778824428
Validation loss: 4.168671760895543

Epoch: 6| Step: 6
Training loss: 3.661298347693112
Validation loss: 4.160241617615869

Epoch: 6| Step: 7
Training loss: 3.8772007015172933
Validation loss: 4.155870093192587

Epoch: 6| Step: 8
Training loss: 4.611298757715678
Validation loss: 4.146036249567401

Epoch: 6| Step: 9
Training loss: 4.963084703874399
Validation loss: 4.139565804882947

Epoch: 6| Step: 10
Training loss: 4.100649777538002
Validation loss: 4.133661900208852

Epoch: 6| Step: 11
Training loss: 3.690080935616639
Validation loss: 4.124497831472855

Epoch: 6| Step: 12
Training loss: 4.016455657186143
Validation loss: 4.113167772867418

Epoch: 6| Step: 13
Training loss: 4.030562704477091
Validation loss: 4.107497211512998

Epoch: 8| Step: 0
Training loss: 3.261254118759227
Validation loss: 4.099127056113557

Epoch: 6| Step: 1
Training loss: 3.2265150607041466
Validation loss: 4.092735318204261

Epoch: 6| Step: 2
Training loss: 4.4382125927073846
Validation loss: 4.084139752863826

Epoch: 6| Step: 3
Training loss: 3.840296861180738
Validation loss: 4.0803327143709005

Epoch: 6| Step: 4
Training loss: 3.8825332264850925
Validation loss: 4.068655957763505

Epoch: 6| Step: 5
Training loss: 5.008606179792719
Validation loss: 4.067285767736543

Epoch: 6| Step: 6
Training loss: 4.569538279107476
Validation loss: 4.059727308025519

Epoch: 6| Step: 7
Training loss: 4.0541751956882655
Validation loss: 4.0434145639177155

Epoch: 6| Step: 8
Training loss: 3.713615398914471
Validation loss: 4.038944295891582

Epoch: 6| Step: 9
Training loss: 3.8566029589596904
Validation loss: 4.031120074983669

Epoch: 6| Step: 10
Training loss: 5.06460885287715
Validation loss: 4.020860096271057

Epoch: 6| Step: 11
Training loss: 4.537461857070549
Validation loss: 4.01457463837444

Epoch: 6| Step: 12
Training loss: 4.479164419247558
Validation loss: 4.00433290798977

Epoch: 6| Step: 13
Training loss: 4.095420671218424
Validation loss: 3.993281124402395

Epoch: 9| Step: 0
Training loss: 4.821656075413334
Validation loss: 3.9867112524966495

Epoch: 6| Step: 1
Training loss: 4.606649336462551
Validation loss: 3.9739914527174953

Epoch: 6| Step: 2
Training loss: 3.235630842015322
Validation loss: 3.9674878789836234

Epoch: 6| Step: 3
Training loss: 4.023000630484163
Validation loss: 3.950868296331493

Epoch: 6| Step: 4
Training loss: 4.194655496594139
Validation loss: 3.9488036238146678

Epoch: 6| Step: 5
Training loss: 5.007302863839459
Validation loss: 3.934194586039854

Epoch: 6| Step: 6
Training loss: 4.30714592769742
Validation loss: 3.925619051753896

Epoch: 6| Step: 7
Training loss: 3.796647430005013
Validation loss: 3.913685665453064

Epoch: 6| Step: 8
Training loss: 4.480238013075711
Validation loss: 3.9069458333117466

Epoch: 6| Step: 9
Training loss: 3.739679758569612
Validation loss: 3.8944813425242804

Epoch: 6| Step: 10
Training loss: 3.1147338082357843
Validation loss: 3.8834791971425116

Epoch: 6| Step: 11
Training loss: 4.112041580019656
Validation loss: 3.873504379151701

Epoch: 6| Step: 12
Training loss: 2.1009384419911337
Validation loss: 3.8648096156604295

Epoch: 6| Step: 13
Training loss: 4.941484605974604
Validation loss: 3.8558193921355435

Epoch: 10| Step: 0
Training loss: 3.144849678170805
Validation loss: 3.8413666076229025

Epoch: 6| Step: 1
Training loss: 5.007761843420663
Validation loss: 3.835517281684202

Epoch: 6| Step: 2
Training loss: 3.414828077152463
Validation loss: 3.8240600996813705

Epoch: 6| Step: 3
Training loss: 3.313408349209442
Validation loss: 3.8155820973969585

Epoch: 6| Step: 4
Training loss: 4.387859518857294
Validation loss: 3.8015361307270834

Epoch: 6| Step: 5
Training loss: 4.6657728065743145
Validation loss: 3.7876112673680242

Epoch: 6| Step: 6
Training loss: 3.121130722266152
Validation loss: 3.780378935094506

Epoch: 6| Step: 7
Training loss: 3.086528943520448
Validation loss: 3.7682136818627265

Epoch: 6| Step: 8
Training loss: 4.361771994458287
Validation loss: 3.7593178387687374

Epoch: 6| Step: 9
Training loss: 3.386340409455815
Validation loss: 3.7444486936629473

Epoch: 6| Step: 10
Training loss: 4.2831278671284
Validation loss: 3.739165740574472

Epoch: 6| Step: 11
Training loss: 4.216643082825419
Validation loss: 3.726208578075048

Epoch: 6| Step: 12
Training loss: 4.022264031695809
Validation loss: 3.7133533438258293

Epoch: 6| Step: 13
Training loss: 3.845652535853138
Validation loss: 3.7068224768743696

Epoch: 11| Step: 0
Training loss: 3.23136902226543
Validation loss: 3.691133468297154

Epoch: 6| Step: 1
Training loss: 3.7720990383863873
Validation loss: 3.677963207805447

Epoch: 6| Step: 2
Training loss: 4.225026978175239
Validation loss: 3.6669149319416268

Epoch: 6| Step: 3
Training loss: 4.454572475825577
Validation loss: 3.654506154248217

Epoch: 6| Step: 4
Training loss: 3.137560359784574
Validation loss: 3.6371216077943336

Epoch: 6| Step: 5
Training loss: 4.296939807749904
Validation loss: 3.621536416323698

Epoch: 6| Step: 6
Training loss: 2.8830941742366116
Validation loss: 3.6135882794440315

Epoch: 6| Step: 7
Training loss: 3.4603062865681116
Validation loss: 3.6073824347263956

Epoch: 6| Step: 8
Training loss: 3.6950966124750924
Validation loss: 3.5915727723045108

Epoch: 6| Step: 9
Training loss: 3.788045278647162
Validation loss: 3.5806243374004763

Epoch: 6| Step: 10
Training loss: 3.919289150596558
Validation loss: 3.5624008179296873

Epoch: 6| Step: 11
Training loss: 4.135432604447536
Validation loss: 3.5561136205988677

Epoch: 6| Step: 12
Training loss: 3.9712916368241546
Validation loss: 3.5358566784127485

Epoch: 6| Step: 13
Training loss: 3.3570185003466873
Validation loss: 3.5252294898139414

Epoch: 12| Step: 0
Training loss: 4.309365944303053
Validation loss: 3.507262288286077

Epoch: 6| Step: 1
Training loss: 4.090213092205397
Validation loss: 3.4913231151849633

Epoch: 6| Step: 2
Training loss: 4.171550152307625
Validation loss: 3.478405852626676

Epoch: 6| Step: 3
Training loss: 3.669997234291469
Validation loss: 3.4646952724065034

Epoch: 6| Step: 4
Training loss: 3.6331424686334137
Validation loss: 3.4473143523846734

Epoch: 6| Step: 5
Training loss: 3.686544391496741
Validation loss: 3.4254422363303396

Epoch: 6| Step: 6
Training loss: 2.0846376405156457
Validation loss: 3.413773336310896

Epoch: 6| Step: 7
Training loss: 3.5079503361525926
Validation loss: 3.4011265905955734

Epoch: 6| Step: 8
Training loss: 3.4842919309832436
Validation loss: 3.389553706258751

Epoch: 6| Step: 9
Training loss: 3.526630722420386
Validation loss: 3.377416729125119

Epoch: 6| Step: 10
Training loss: 3.3210834640311337
Validation loss: 3.3629029042017144

Epoch: 6| Step: 11
Training loss: 3.397505849534277
Validation loss: 3.3410826962184585

Epoch: 6| Step: 12
Training loss: 4.010525207371828
Validation loss: 3.3268205195945826

Epoch: 6| Step: 13
Training loss: 2.6309166486434674
Validation loss: 3.3187099268897278

Epoch: 13| Step: 0
Training loss: 3.3139137274241253
Validation loss: 3.3068356174437676

Epoch: 6| Step: 1
Training loss: 3.741420468143857
Validation loss: 3.2863243076608786

Epoch: 6| Step: 2
Training loss: 3.6091253020873344
Validation loss: 3.2658587728924195

Epoch: 6| Step: 3
Training loss: 3.0422019139180074
Validation loss: 3.263745480990329

Epoch: 6| Step: 4
Training loss: 4.185587204148335
Validation loss: 3.242168178073295

Epoch: 6| Step: 5
Training loss: 3.7596230695376898
Validation loss: 3.2277423433901333

Epoch: 6| Step: 6
Training loss: 3.449599870338862
Validation loss: 3.2166503810730656

Epoch: 6| Step: 7
Training loss: 3.2258781834287062
Validation loss: 3.2031902787794713

Epoch: 6| Step: 8
Training loss: 3.0952622541944987
Validation loss: 3.179113720018982

Epoch: 6| Step: 9
Training loss: 3.0306260558110982
Validation loss: 3.1673031044873237

Epoch: 6| Step: 10
Training loss: 3.262044888026752
Validation loss: 3.1550564437743853

Epoch: 6| Step: 11
Training loss: 3.2655297954498446
Validation loss: 3.1396445916060953

Epoch: 6| Step: 12
Training loss: 2.977702886041363
Validation loss: 3.1213207719570453

Epoch: 6| Step: 13
Training loss: 4.030657347651225
Validation loss: 3.09783492758609

Epoch: 14| Step: 0
Training loss: 2.405259262829985
Validation loss: 3.085372932559902

Epoch: 6| Step: 1
Training loss: 3.658198171796567
Validation loss: 3.070165520472439

Epoch: 6| Step: 2
Training loss: 3.184367417016701
Validation loss: 3.057043062763607

Epoch: 6| Step: 3
Training loss: 2.9932696823228744
Validation loss: 3.039277239929581

Epoch: 6| Step: 4
Training loss: 2.5669260645325114
Validation loss: 3.0258606596463764

Epoch: 6| Step: 5
Training loss: 3.3204958876285784
Validation loss: 3.01317959792769

Epoch: 6| Step: 6
Training loss: 3.1617910261402407
Validation loss: 3.004220648622433

Epoch: 6| Step: 7
Training loss: 3.389008026599806
Validation loss: 2.9923416149841313

Epoch: 6| Step: 8
Training loss: 2.944596666523858
Validation loss: 2.9651372389418276

Epoch: 6| Step: 9
Training loss: 2.8598412305604786
Validation loss: 2.9598783254018546

Epoch: 6| Step: 10
Training loss: 3.7140552795108874
Validation loss: 2.935426098194075

Epoch: 6| Step: 11
Training loss: 3.230234638112337
Validation loss: 2.930150733776708

Epoch: 6| Step: 12
Training loss: 3.8284170856761377
Validation loss: 2.91695481970341

Epoch: 6| Step: 13
Training loss: 3.967450266996897
Validation loss: 2.899116228125628

Epoch: 15| Step: 0
Training loss: 3.419391584431099
Validation loss: 2.888740753333539

Epoch: 6| Step: 1
Training loss: 3.1736658612367017
Validation loss: 2.8638615753676104

Epoch: 6| Step: 2
Training loss: 2.6970296945772394
Validation loss: 2.856941532954137

Epoch: 6| Step: 3
Training loss: 2.7567523074733287
Validation loss: 2.8480222447614154

Epoch: 6| Step: 4
Training loss: 3.4202266537700656
Validation loss: 2.8292383270947985

Epoch: 6| Step: 5
Training loss: 3.5384113984398953
Validation loss: 2.813008314204401

Epoch: 6| Step: 6
Training loss: 2.9592944092940305
Validation loss: 2.796709789191192

Epoch: 6| Step: 7
Training loss: 2.596242878683257
Validation loss: 2.7894913180105165

Epoch: 6| Step: 8
Training loss: 2.980900204528476
Validation loss: 2.780182666246905

Epoch: 6| Step: 9
Training loss: 3.326339457619576
Validation loss: 2.773516998931004

Epoch: 6| Step: 10
Training loss: 3.3040915238124824
Validation loss: 2.74309770354336

Epoch: 6| Step: 11
Training loss: 2.7793443988053026
Validation loss: 2.7427388065240916

Epoch: 6| Step: 12
Training loss: 2.460574362468508
Validation loss: 2.7288219444295327

Epoch: 6| Step: 13
Training loss: 3.8833584622291815
Validation loss: 2.7170313474930827

Epoch: 16| Step: 0
Training loss: 2.900775799077073
Validation loss: 2.7088032351902247

Epoch: 6| Step: 1
Training loss: 3.277748201168551
Validation loss: 2.7016756989269366

Epoch: 6| Step: 2
Training loss: 2.8112319630900386
Validation loss: 2.6892320527463123

Epoch: 6| Step: 3
Training loss: 3.0859989981016165
Validation loss: 2.679906771006643

Epoch: 6| Step: 4
Training loss: 2.9496612418980535
Validation loss: 2.6612151788821645

Epoch: 6| Step: 5
Training loss: 2.822582821032129
Validation loss: 2.663513581250518

Epoch: 6| Step: 6
Training loss: 2.798064506376156
Validation loss: 2.6333687782108823

Epoch: 6| Step: 7
Training loss: 3.110740783388347
Validation loss: 2.6368967206620395

Epoch: 6| Step: 8
Training loss: 3.3326667278045856
Validation loss: 2.633861716453721

Epoch: 6| Step: 9
Training loss: 3.236178719865326
Validation loss: 2.6294072729120335

Epoch: 6| Step: 10
Training loss: 2.356377725149672
Validation loss: 2.606521609939119

Epoch: 6| Step: 11
Training loss: 3.071104457140773
Validation loss: 2.616458075743282

Epoch: 6| Step: 12
Training loss: 3.059701224557249
Validation loss: 2.6060869155418525

Epoch: 6| Step: 13
Training loss: 2.547665338812943
Validation loss: 2.5997091590542545

Epoch: 17| Step: 0
Training loss: 3.644892732902135
Validation loss: 2.596255104180431

Epoch: 6| Step: 1
Training loss: 2.957085753811598
Validation loss: 2.588118351772492

Epoch: 6| Step: 2
Training loss: 3.1261362680325684
Validation loss: 2.580473704115669

Epoch: 6| Step: 3
Training loss: 3.2378216498998302
Validation loss: 2.5820919448787913

Epoch: 6| Step: 4
Training loss: 2.8509300053038134
Validation loss: 2.5862645080426248

Epoch: 6| Step: 5
Training loss: 3.2920746047510936
Validation loss: 2.570392578345755

Epoch: 6| Step: 6
Training loss: 2.579864839665517
Validation loss: 2.580198647404328

Epoch: 6| Step: 7
Training loss: 2.5974056725359955
Validation loss: 2.564442470354615

Epoch: 6| Step: 8
Training loss: 2.9287514780767783
Validation loss: 2.5672244747378357

Epoch: 6| Step: 9
Training loss: 2.190494993871538
Validation loss: 2.557053389823628

Epoch: 6| Step: 10
Training loss: 3.147008680517724
Validation loss: 2.553923390587126

Epoch: 6| Step: 11
Training loss: 2.93988978795669
Validation loss: 2.541918940424837

Epoch: 6| Step: 12
Training loss: 2.9417704930412274
Validation loss: 2.5545352377248833

Epoch: 6| Step: 13
Training loss: 1.8678763806692118
Validation loss: 2.553487646908823

Epoch: 18| Step: 0
Training loss: 2.445474930021123
Validation loss: 2.5422262725242177

Epoch: 6| Step: 1
Training loss: 2.072194636618392
Validation loss: 2.5463994378208477

Epoch: 6| Step: 2
Training loss: 3.4981437938049704
Validation loss: 2.5511283254585124

Epoch: 6| Step: 3
Training loss: 3.157564097378347
Validation loss: 2.53798264781441

Epoch: 6| Step: 4
Training loss: 3.0181115527711535
Validation loss: 2.538804830724061

Epoch: 6| Step: 5
Training loss: 3.397529147418187
Validation loss: 2.526557312730872

Epoch: 6| Step: 6
Training loss: 2.59422325504718
Validation loss: 2.542441115125016

Epoch: 6| Step: 7
Training loss: 3.2396102037368264
Validation loss: 2.5401973851728257

Epoch: 6| Step: 8
Training loss: 2.8325215092891947
Validation loss: 2.538987291861363

Epoch: 6| Step: 9
Training loss: 2.842771424660057
Validation loss: 2.549304747581191

Epoch: 6| Step: 10
Training loss: 2.7262331700844036
Validation loss: 2.5264233068193604

Epoch: 6| Step: 11
Training loss: 3.015994192659165
Validation loss: 2.5308525774102404

Epoch: 6| Step: 12
Training loss: 2.8345308204222843
Validation loss: 2.5298943696982485

Epoch: 6| Step: 13
Training loss: 2.7445785661718434
Validation loss: 2.53980195263702

Epoch: 19| Step: 0
Training loss: 2.8198238382710783
Validation loss: 2.5403083353575866

Epoch: 6| Step: 1
Training loss: 2.606369297581361
Validation loss: 2.519343142567459

Epoch: 6| Step: 2
Training loss: 2.54228498931944
Validation loss: 2.534382141575814

Epoch: 6| Step: 3
Training loss: 2.967070094191854
Validation loss: 2.5115921855425736

Epoch: 6| Step: 4
Training loss: 3.1161076484664414
Validation loss: 2.5386631159153077

Epoch: 6| Step: 5
Training loss: 2.1172379491221873
Validation loss: 2.5406304315975823

Epoch: 6| Step: 6
Training loss: 3.1357919124152276
Validation loss: 2.5246172651752588

Epoch: 6| Step: 7
Training loss: 3.0344278254364863
Validation loss: 2.53546504944548

Epoch: 6| Step: 8
Training loss: 2.6627543977080252
Validation loss: 2.5377838403575863

Epoch: 6| Step: 9
Training loss: 3.2095411099809446
Validation loss: 2.531677329532498

Epoch: 6| Step: 10
Training loss: 3.05957701408658
Validation loss: 2.5312573387113546

Epoch: 6| Step: 11
Training loss: 2.7124075737601467
Validation loss: 2.5394353297834162

Epoch: 6| Step: 12
Training loss: 3.0641142035931255
Validation loss: 2.5490105344578096

Epoch: 6| Step: 13
Training loss: 3.7555692643010063
Validation loss: 2.52612578025011

Epoch: 20| Step: 0
Training loss: 3.080901776613645
Validation loss: 2.5309897121472638

Epoch: 6| Step: 1
Training loss: 3.1120452916396952
Validation loss: 2.5412650107854726

Epoch: 6| Step: 2
Training loss: 2.917179026333435
Validation loss: 2.5348646428943558

Epoch: 6| Step: 3
Training loss: 3.3298803723816506
Validation loss: 2.529149328145586

Epoch: 6| Step: 4
Training loss: 2.7870390575068815
Validation loss: 2.536593626612411

Epoch: 6| Step: 5
Training loss: 2.479180621794418
Validation loss: 2.5340950211295286

Epoch: 6| Step: 6
Training loss: 2.488853209198171
Validation loss: 2.5365512461381825

Epoch: 6| Step: 7
Training loss: 3.2191538140770044
Validation loss: 2.5396233142978133

Epoch: 6| Step: 8
Training loss: 2.8192019825511636
Validation loss: 2.537245894715184

Epoch: 6| Step: 9
Training loss: 3.6678865888694805
Validation loss: 2.538617723253284

Epoch: 6| Step: 10
Training loss: 2.3332548014731294
Validation loss: 2.5404051849795164

Epoch: 6| Step: 11
Training loss: 2.730152379209335
Validation loss: 2.5422910548392745

Epoch: 6| Step: 12
Training loss: 2.686904841326312
Validation loss: 2.534137700650011

Epoch: 6| Step: 13
Training loss: 2.718658007238322
Validation loss: 2.546341120960424

Epoch: 21| Step: 0
Training loss: 2.3940747869883596
Validation loss: 2.528530469302108

Epoch: 6| Step: 1
Training loss: 2.561141793910127
Validation loss: 2.5335595727411473

Epoch: 6| Step: 2
Training loss: 3.6501993830322026
Validation loss: 2.529479447325468

Epoch: 6| Step: 3
Training loss: 2.6320736354858365
Validation loss: 2.5213926185232554

Epoch: 6| Step: 4
Training loss: 1.7778208333338292
Validation loss: 2.538544640876868

Epoch: 6| Step: 5
Training loss: 4.0733371267181395
Validation loss: 2.52195609959392

Epoch: 6| Step: 6
Training loss: 3.120901853847323
Validation loss: 2.519703910948492

Epoch: 6| Step: 7
Training loss: 2.870761898870208
Validation loss: 2.5219934272663225

Epoch: 6| Step: 8
Training loss: 2.5774020944347207
Validation loss: 2.5193598552944505

Epoch: 6| Step: 9
Training loss: 2.708182658381304
Validation loss: 2.5105148566505084

Epoch: 6| Step: 10
Training loss: 2.351837243540671
Validation loss: 2.5208914606085573

Epoch: 6| Step: 11
Training loss: 3.1741753115393974
Validation loss: 2.5243150353612798

Epoch: 6| Step: 12
Training loss: 2.8040612671888834
Validation loss: 2.5272319790731395

Epoch: 6| Step: 13
Training loss: 3.295004074256242
Validation loss: 2.5165853214489147

Epoch: 22| Step: 0
Training loss: 2.4790288635764837
Validation loss: 2.508755257486123

Epoch: 6| Step: 1
Training loss: 3.0097713284744794
Validation loss: 2.500468046202905

Epoch: 6| Step: 2
Training loss: 2.7625473052932783
Validation loss: 2.510012200945276

Epoch: 6| Step: 3
Training loss: 2.322140368652083
Validation loss: 2.5110660476094377

Epoch: 6| Step: 4
Training loss: 2.37502911198492
Validation loss: 2.5251175480962003

Epoch: 6| Step: 5
Training loss: 3.477485996988763
Validation loss: 2.5236094863288625

Epoch: 6| Step: 6
Training loss: 3.304883153006971
Validation loss: 2.5216156208343286

Epoch: 6| Step: 7
Training loss: 2.959388508911881
Validation loss: 2.514564406252047

Epoch: 6| Step: 8
Training loss: 3.5109391243442367
Validation loss: 2.5265891531074316

Epoch: 6| Step: 9
Training loss: 2.7219949408994997
Validation loss: 2.521820933239468

Epoch: 6| Step: 10
Training loss: 3.0460864489405
Validation loss: 2.509284659370992

Epoch: 6| Step: 11
Training loss: 2.9235968590693813
Validation loss: 2.5169475291397885

Epoch: 6| Step: 12
Training loss: 2.549880051129167
Validation loss: 2.511864345640933

Epoch: 6| Step: 13
Training loss: 2.81060142013502
Validation loss: 2.500486154355505

Epoch: 23| Step: 0
Training loss: 2.4737610962528755
Validation loss: 2.5101629142657065

Epoch: 6| Step: 1
Training loss: 3.4527891522199123
Validation loss: 2.522524261896169

Epoch: 6| Step: 2
Training loss: 2.285125158375558
Validation loss: 2.516140325989999

Epoch: 6| Step: 3
Training loss: 3.4939681256330104
Validation loss: 2.5217886783751275

Epoch: 6| Step: 4
Training loss: 2.623666151941451
Validation loss: 2.526636375157787

Epoch: 6| Step: 5
Training loss: 2.2474312424034366
Validation loss: 2.5132096672914286

Epoch: 6| Step: 6
Training loss: 2.6122021007894185
Validation loss: 2.5157310592396955

Epoch: 6| Step: 7
Training loss: 3.157265981185644
Validation loss: 2.527263137392198

Epoch: 6| Step: 8
Training loss: 2.6708666588603074
Validation loss: 2.5191644873344776

Epoch: 6| Step: 9
Training loss: 2.8685625401501933
Validation loss: 2.5096011513026593

Epoch: 6| Step: 10
Training loss: 2.6725653041072763
Validation loss: 2.526723117755664

Epoch: 6| Step: 11
Training loss: 3.510249253685277
Validation loss: 2.5144821747611408

Epoch: 6| Step: 12
Training loss: 3.215097818265887
Validation loss: 2.5077943343440396

Epoch: 6| Step: 13
Training loss: 2.232229416395061
Validation loss: 2.5188857259975572

Epoch: 24| Step: 0
Training loss: 2.929761880566209
Validation loss: 2.507425506268485

Epoch: 6| Step: 1
Training loss: 3.1439390394886786
Validation loss: 2.5250950529697382

Epoch: 6| Step: 2
Training loss: 2.632586551558473
Validation loss: 2.5182605945096124

Epoch: 6| Step: 3
Training loss: 3.61701889139462
Validation loss: 2.5144430247508076

Epoch: 6| Step: 4
Training loss: 2.7072429711802526
Validation loss: 2.521551130857773

Epoch: 6| Step: 5
Training loss: 2.591935775702911
Validation loss: 2.5215602561594994

Epoch: 6| Step: 6
Training loss: 3.291436650090294
Validation loss: 2.516628607595468

Epoch: 6| Step: 7
Training loss: 2.8758517123261176
Validation loss: 2.5216714682158963

Epoch: 6| Step: 8
Training loss: 2.7963554709626797
Validation loss: 2.514372040543846

Epoch: 6| Step: 9
Training loss: 2.74495381425869
Validation loss: 2.515165180588163

Epoch: 6| Step: 10
Training loss: 2.776145279449522
Validation loss: 2.5302433760574803

Epoch: 6| Step: 11
Training loss: 2.6624118915718697
Validation loss: 2.5131190633642095

Epoch: 6| Step: 12
Training loss: 2.5784749111503182
Validation loss: 2.5218092323404147

Epoch: 6| Step: 13
Training loss: 2.604787666028695
Validation loss: 2.5174215835438476

Epoch: 25| Step: 0
Training loss: 2.0435027086628734
Validation loss: 2.5094695560019984

Epoch: 6| Step: 1
Training loss: 2.49459320956734
Validation loss: 2.523391886277624

Epoch: 6| Step: 2
Training loss: 2.9670826295275865
Validation loss: 2.5213869012987615

Epoch: 6| Step: 3
Training loss: 2.679949600258243
Validation loss: 2.4994249082338933

Epoch: 6| Step: 4
Training loss: 2.60839651801104
Validation loss: 2.5038269981589307

Epoch: 6| Step: 5
Training loss: 2.841796707205751
Validation loss: 2.5206321331598254

Epoch: 6| Step: 6
Training loss: 2.9473866411950964
Validation loss: 2.513695808381675

Epoch: 6| Step: 7
Training loss: 2.630889461942845
Validation loss: 2.520915229854882

Epoch: 6| Step: 8
Training loss: 3.1581215927555584
Validation loss: 2.5277882153608338

Epoch: 6| Step: 9
Training loss: 3.073484379110734
Validation loss: 2.499198275369984

Epoch: 6| Step: 10
Training loss: 2.8431050334236865
Validation loss: 2.5146716092160424

Epoch: 6| Step: 11
Training loss: 3.5452347378295666
Validation loss: 2.515929765990777

Epoch: 6| Step: 12
Training loss: 3.1027230270353034
Validation loss: 2.5119994058113213

Epoch: 6| Step: 13
Training loss: 3.0869346070081134
Validation loss: 2.516026128034414

Epoch: 26| Step: 0
Training loss: 2.818418421559655
Validation loss: 2.521297447365009

Epoch: 6| Step: 1
Training loss: 3.2206735141149414
Validation loss: 2.5071949758672547

Epoch: 6| Step: 2
Training loss: 2.691226681946243
Validation loss: 2.5087336206688566

Epoch: 6| Step: 3
Training loss: 3.154614015113511
Validation loss: 2.509204092881926

Epoch: 6| Step: 4
Training loss: 2.3891962307113275
Validation loss: 2.518987050880377

Epoch: 6| Step: 5
Training loss: 2.5745391877807853
Validation loss: 2.5135345190708724

Epoch: 6| Step: 6
Training loss: 3.2579243226836905
Validation loss: 2.5046568618255796

Epoch: 6| Step: 7
Training loss: 2.9961653679714417
Validation loss: 2.5285967826341844

Epoch: 6| Step: 8
Training loss: 2.965279568491228
Validation loss: 2.507706772400904

Epoch: 6| Step: 9
Training loss: 2.8337440940953567
Validation loss: 2.498609422724274

Epoch: 6| Step: 10
Training loss: 3.2045045440541613
Validation loss: 2.506767838673727

Epoch: 6| Step: 11
Training loss: 2.746052422897596
Validation loss: 2.505214756049694

Epoch: 6| Step: 12
Training loss: 2.476518407964656
Validation loss: 2.5136415298531967

Epoch: 6| Step: 13
Training loss: 2.48432778367573
Validation loss: 2.514338616984848

Epoch: 27| Step: 0
Training loss: 3.109593369373488
Validation loss: 2.5015509726819776

Epoch: 6| Step: 1
Training loss: 2.9171276999720694
Validation loss: 2.5138002642623025

Epoch: 6| Step: 2
Training loss: 3.087260365935733
Validation loss: 2.5004230807819448

Epoch: 6| Step: 3
Training loss: 3.0005702430450225
Validation loss: 2.507547771363713

Epoch: 6| Step: 4
Training loss: 2.530408460341091
Validation loss: 2.5146470530420815

Epoch: 6| Step: 5
Training loss: 2.356946086514566
Validation loss: 2.5094099763604074

Epoch: 6| Step: 6
Training loss: 2.7720628367261186
Validation loss: 2.5039750870202435

Epoch: 6| Step: 7
Training loss: 3.2435658661723274
Validation loss: 2.5109404569469933

Epoch: 6| Step: 8
Training loss: 3.2181597418436887
Validation loss: 2.502095876990173

Epoch: 6| Step: 9
Training loss: 3.2462168462482928
Validation loss: 2.5045642227284266

Epoch: 6| Step: 10
Training loss: 3.010587447622998
Validation loss: 2.5089574875851692

Epoch: 6| Step: 11
Training loss: 2.1945502970579507
Validation loss: 2.514486018462204

Epoch: 6| Step: 12
Training loss: 2.524905695901009
Validation loss: 2.5077437652490397

Epoch: 6| Step: 13
Training loss: 2.6053964584821983
Validation loss: 2.5043520701154276

Epoch: 28| Step: 0
Training loss: 2.9163145306867246
Validation loss: 2.504041761928808

Epoch: 6| Step: 1
Training loss: 2.3985396869772413
Validation loss: 2.4927744470468953

Epoch: 6| Step: 2
Training loss: 2.510758710381747
Validation loss: 2.5090653367688773

Epoch: 6| Step: 3
Training loss: 3.0687565634476655
Validation loss: 2.51128058634662

Epoch: 6| Step: 4
Training loss: 2.640796362378453
Validation loss: 2.498618694912726

Epoch: 6| Step: 5
Training loss: 3.1209310362681983
Validation loss: 2.5009196938054536

Epoch: 6| Step: 6
Training loss: 3.05795261878761
Validation loss: 2.500179642201453

Epoch: 6| Step: 7
Training loss: 2.444168164313146
Validation loss: 2.5004730484624496

Epoch: 6| Step: 8
Training loss: 2.8824290612417194
Validation loss: 2.503186797363599

Epoch: 6| Step: 9
Training loss: 3.235025091766732
Validation loss: 2.523525453786739

Epoch: 6| Step: 10
Training loss: 2.976558655263265
Validation loss: 2.500952733938387

Epoch: 6| Step: 11
Training loss: 3.4156074432731534
Validation loss: 2.502958317338692

Epoch: 6| Step: 12
Training loss: 2.6817273975400253
Validation loss: 2.5032898432427593

Epoch: 6| Step: 13
Training loss: 2.1730017723711756
Validation loss: 2.50794517532357

Epoch: 29| Step: 0
Training loss: 2.7612326705478623
Validation loss: 2.505678287109186

Epoch: 6| Step: 1
Training loss: 2.62250009207639
Validation loss: 2.5036866231532318

Epoch: 6| Step: 2
Training loss: 2.6284255428584213
Validation loss: 2.5019232643041764

Epoch: 6| Step: 3
Training loss: 2.8150458787123473
Validation loss: 2.5120595067628795

Epoch: 6| Step: 4
Training loss: 2.775731644964253
Validation loss: 2.508042147728931

Epoch: 6| Step: 5
Training loss: 2.7218657431023523
Validation loss: 2.509607713622693

Epoch: 6| Step: 6
Training loss: 3.364352065760612
Validation loss: 2.5022463519944735

Epoch: 6| Step: 7
Training loss: 3.5407010426313903
Validation loss: 2.5050790384256714

Epoch: 6| Step: 8
Training loss: 2.850054114647808
Validation loss: 2.5126095354821327

Epoch: 6| Step: 9
Training loss: 1.9669294265281254
Validation loss: 2.4992373605583307

Epoch: 6| Step: 10
Training loss: 3.2031227670057003
Validation loss: 2.4980938392042185

Epoch: 6| Step: 11
Training loss: 2.515035524667223
Validation loss: 2.507335706070365

Epoch: 6| Step: 12
Training loss: 3.1325342525670585
Validation loss: 2.4860717733049853

Epoch: 6| Step: 13
Training loss: 2.6947606503107804
Validation loss: 2.507432418836935

Epoch: 30| Step: 0
Training loss: 2.522649116305191
Validation loss: 2.5050865827506277

Epoch: 6| Step: 1
Training loss: 3.230729116812597
Validation loss: 2.5002881325015376

Epoch: 6| Step: 2
Training loss: 2.4322412936258404
Validation loss: 2.4979371286618224

Epoch: 6| Step: 3
Training loss: 2.2166845889789104
Validation loss: 2.495840290306473

Epoch: 6| Step: 4
Training loss: 2.9445866264546883
Validation loss: 2.5101502572073473

Epoch: 6| Step: 5
Training loss: 2.9724438625261103
Validation loss: 2.495466714156804

Epoch: 6| Step: 6
Training loss: 3.0288167409435203
Validation loss: 2.504395158239747

Epoch: 6| Step: 7
Training loss: 3.57171349615055
Validation loss: 2.491578343370323

Epoch: 6| Step: 8
Training loss: 2.3792898686227084
Validation loss: 2.486823951856952

Epoch: 6| Step: 9
Training loss: 2.722415864203115
Validation loss: 2.503882335670032

Epoch: 6| Step: 10
Training loss: 3.007779524981583
Validation loss: 2.492558324711971

Epoch: 6| Step: 11
Training loss: 2.6357698668771703
Validation loss: 2.5099811481685803

Epoch: 6| Step: 12
Training loss: 3.0181241920961464
Validation loss: 2.4914008932191405

Epoch: 6| Step: 13
Training loss: 3.0101322096877747
Validation loss: 2.5002198604586514

Epoch: 31| Step: 0
Training loss: 2.6156506025549353
Validation loss: 2.4992887674774096

Epoch: 6| Step: 1
Training loss: 2.6281938650427854
Validation loss: 2.485812180585221

Epoch: 6| Step: 2
Training loss: 2.5094619032846195
Validation loss: 2.498216228515117

Epoch: 6| Step: 3
Training loss: 2.3390128518379782
Validation loss: 2.5056930089180183

Epoch: 6| Step: 4
Training loss: 2.913708703702925
Validation loss: 2.4994030280720896

Epoch: 6| Step: 5
Training loss: 2.8607247924067467
Validation loss: 2.50053948457397

Epoch: 6| Step: 6
Training loss: 3.730009072627675
Validation loss: 2.496377734709144

Epoch: 6| Step: 7
Training loss: 3.045066727281389
Validation loss: 2.504816447066494

Epoch: 6| Step: 8
Training loss: 2.5229370754769938
Validation loss: 2.4894208858085256

Epoch: 6| Step: 9
Training loss: 3.2028906759755285
Validation loss: 2.501788843724037

Epoch: 6| Step: 10
Training loss: 2.6039831681769616
Validation loss: 2.502040862683489

Epoch: 6| Step: 11
Training loss: 2.54208110077885
Validation loss: 2.503888547458909

Epoch: 6| Step: 12
Training loss: 2.9307716093124943
Validation loss: 2.4824941848296667

Epoch: 6| Step: 13
Training loss: 3.2199232315010637
Validation loss: 2.497645633361157

Epoch: 32| Step: 0
Training loss: 2.6806072291618763
Validation loss: 2.4916709209963748

Epoch: 6| Step: 1
Training loss: 3.004921690671061
Validation loss: 2.503612167839375

Epoch: 6| Step: 2
Training loss: 2.866301105907075
Validation loss: 2.502377360038829

Epoch: 6| Step: 3
Training loss: 2.580352375895405
Validation loss: 2.5055797820781476

Epoch: 6| Step: 4
Training loss: 2.4060353765510873
Validation loss: 2.491946737215766

Epoch: 6| Step: 5
Training loss: 2.799852374136102
Validation loss: 2.491488470527084

Epoch: 6| Step: 6
Training loss: 2.1836509628853142
Validation loss: 2.4991349548981954

Epoch: 6| Step: 7
Training loss: 2.7559239131905313
Validation loss: 2.496950585747229

Epoch: 6| Step: 8
Training loss: 3.186055024183742
Validation loss: 2.5080047933403122

Epoch: 6| Step: 9
Training loss: 2.695080821819434
Validation loss: 2.5052287253753414

Epoch: 6| Step: 10
Training loss: 3.784040446026967
Validation loss: 2.4970213044340204

Epoch: 6| Step: 11
Training loss: 2.695719900992485
Validation loss: 2.495266483684538

Epoch: 6| Step: 12
Training loss: 3.0037868758790336
Validation loss: 2.4961530856920477

Epoch: 6| Step: 13
Training loss: 3.0642782225820526
Validation loss: 2.50573546676868

Epoch: 33| Step: 0
Training loss: 3.0511368118164395
Validation loss: 2.497905204273384

Epoch: 6| Step: 1
Training loss: 2.8359267389603
Validation loss: 2.5081677986817614

Epoch: 6| Step: 2
Training loss: 1.8776809599079731
Validation loss: 2.4989595565694076

Epoch: 6| Step: 3
Training loss: 2.80641006658917
Validation loss: 2.5051434080211124

Epoch: 6| Step: 4
Training loss: 3.677563615218904
Validation loss: 2.493441293311426

Epoch: 6| Step: 5
Training loss: 2.9006352485224167
Validation loss: 2.501668998470847

Epoch: 6| Step: 6
Training loss: 3.310036372880957
Validation loss: 2.501401498151141

Epoch: 6| Step: 7
Training loss: 2.9166729154973985
Validation loss: 2.4934960567973263

Epoch: 6| Step: 8
Training loss: 2.710386104738857
Validation loss: 2.501918107144962

Epoch: 6| Step: 9
Training loss: 2.8234549897100285
Validation loss: 2.4974883024118375

Epoch: 6| Step: 10
Training loss: 2.6802053590637698
Validation loss: 2.498964406940487

Epoch: 6| Step: 11
Training loss: 2.6163810740159765
Validation loss: 2.49401840265235

Epoch: 6| Step: 12
Training loss: 2.578390581727943
Validation loss: 2.4962871535065054

Epoch: 6| Step: 13
Training loss: 2.3127847444651994
Validation loss: 2.5032988062251063

Epoch: 34| Step: 0
Training loss: 2.984825699412209
Validation loss: 2.505607856754439

Epoch: 6| Step: 1
Training loss: 3.316326881779962
Validation loss: 2.496991300571452

Epoch: 6| Step: 2
Training loss: 2.8745534798887
Validation loss: 2.4966421896413746

Epoch: 6| Step: 3
Training loss: 2.2999541734193536
Validation loss: 2.4957633451920818

Epoch: 6| Step: 4
Training loss: 2.9237279881190625
Validation loss: 2.490011419280046

Epoch: 6| Step: 5
Training loss: 2.9695859033402106
Validation loss: 2.503578928309638

Epoch: 6| Step: 6
Training loss: 3.038429959327155
Validation loss: 2.498644131949295

Epoch: 6| Step: 7
Training loss: 2.9883067809366874
Validation loss: 2.5035270001970225

Epoch: 6| Step: 8
Training loss: 2.5881203833738975
Validation loss: 2.5041057271788785

Epoch: 6| Step: 9
Training loss: 2.581757269792839
Validation loss: 2.5020903390357336

Epoch: 6| Step: 10
Training loss: 2.2668910205360153
Validation loss: 2.4955307522989703

Epoch: 6| Step: 11
Training loss: 3.3904416083036155
Validation loss: 2.499517108569505

Epoch: 6| Step: 12
Training loss: 2.5709255612078645
Validation loss: 2.4844088421476775

Epoch: 6| Step: 13
Training loss: 2.459233447876302
Validation loss: 2.4786351220841163

Epoch: 35| Step: 0
Training loss: 3.184269483500837
Validation loss: 2.494515391484759

Epoch: 6| Step: 1
Training loss: 2.59827194374616
Validation loss: 2.4932771190231806

Epoch: 6| Step: 2
Training loss: 2.362080721510258
Validation loss: 2.480439776864315

Epoch: 6| Step: 3
Training loss: 3.327681247695922
Validation loss: 2.4794965331366603

Epoch: 6| Step: 4
Training loss: 2.9732715105320935
Validation loss: 2.4957824437929363

Epoch: 6| Step: 5
Training loss: 3.263068115346449
Validation loss: 2.4952929021479626

Epoch: 6| Step: 6
Training loss: 2.9328378244403104
Validation loss: 2.476598192090205

Epoch: 6| Step: 7
Training loss: 2.9244376791335016
Validation loss: 2.481074071922775

Epoch: 6| Step: 8
Training loss: 2.781993209463096
Validation loss: 2.4891909949495608

Epoch: 6| Step: 9
Training loss: 2.6258469078256264
Validation loss: 2.4956031640866656

Epoch: 6| Step: 10
Training loss: 2.731939309994578
Validation loss: 2.4985965091155578

Epoch: 6| Step: 11
Training loss: 2.570904138992434
Validation loss: 2.4964114007938405

Epoch: 6| Step: 12
Training loss: 2.4172397679384487
Validation loss: 2.479941127098484

Epoch: 6| Step: 13
Training loss: 2.685756827730578
Validation loss: 2.4777227967528312

Epoch: 36| Step: 0
Training loss: 3.0301130856602776
Validation loss: 2.4853743069753533

Epoch: 6| Step: 1
Training loss: 2.64597153991018
Validation loss: 2.4848270099225243

Epoch: 6| Step: 2
Training loss: 3.008849760270993
Validation loss: 2.503057313707815

Epoch: 6| Step: 3
Training loss: 3.098062919100903
Validation loss: 2.498318424532404

Epoch: 6| Step: 4
Training loss: 2.149992889569967
Validation loss: 2.4936957796987205

Epoch: 6| Step: 5
Training loss: 2.131614152779951
Validation loss: 2.490579058353816

Epoch: 6| Step: 6
Training loss: 3.3394021260928457
Validation loss: 2.485417471394406

Epoch: 6| Step: 7
Training loss: 2.1857382082943406
Validation loss: 2.4832919708736227

Epoch: 6| Step: 8
Training loss: 2.6671188587011283
Validation loss: 2.5008075148279434

Epoch: 6| Step: 9
Training loss: 3.047737508129109
Validation loss: 2.4894418547941513

Epoch: 6| Step: 10
Training loss: 2.7098307260383883
Validation loss: 2.4791026963291007

Epoch: 6| Step: 11
Training loss: 3.0956188683821675
Validation loss: 2.491198516544735

Epoch: 6| Step: 12
Training loss: 3.0636681644836004
Validation loss: 2.472908539414023

Epoch: 6| Step: 13
Training loss: 3.3780133958531717
Validation loss: 2.482486594565169

Epoch: 37| Step: 0
Training loss: 2.348203369977239
Validation loss: 2.474851299238448

Epoch: 6| Step: 1
Training loss: 2.930454326727369
Validation loss: 2.4865492747431794

Epoch: 6| Step: 2
Training loss: 2.8823283132620627
Validation loss: 2.4817702459071587

Epoch: 6| Step: 3
Training loss: 2.5733014847294973
Validation loss: 2.4874802903023023

Epoch: 6| Step: 4
Training loss: 2.9408962015242306
Validation loss: 2.490821440582998

Epoch: 6| Step: 5
Training loss: 2.7996218528166104
Validation loss: 2.4841103681448997

Epoch: 6| Step: 6
Training loss: 3.0772445116507825
Validation loss: 2.4905850706933266

Epoch: 6| Step: 7
Training loss: 2.7086233326121945
Validation loss: 2.4912096521861264

Epoch: 6| Step: 8
Training loss: 2.6142009946956497
Validation loss: 2.4813201815021384

Epoch: 6| Step: 9
Training loss: 3.4253397083968067
Validation loss: 2.50032909237169

Epoch: 6| Step: 10
Training loss: 3.3931689585186717
Validation loss: 2.4897671325884985

Epoch: 6| Step: 11
Training loss: 2.564194281967306
Validation loss: 2.490019018523371

Epoch: 6| Step: 12
Training loss: 2.0836762591096294
Validation loss: 2.4899627067661587

Epoch: 6| Step: 13
Training loss: 2.9520802743950187
Validation loss: 2.48981154704439

Epoch: 38| Step: 0
Training loss: 2.7390479566728763
Validation loss: 2.490975244714628

Epoch: 6| Step: 1
Training loss: 3.002937785812251
Validation loss: 2.4914296071767708

Epoch: 6| Step: 2
Training loss: 2.1361394511860246
Validation loss: 2.4971322418786066

Epoch: 6| Step: 3
Training loss: 2.9247807216776884
Validation loss: 2.481856505162999

Epoch: 6| Step: 4
Training loss: 2.9824124419157467
Validation loss: 2.4866128198227746

Epoch: 6| Step: 5
Training loss: 2.6279698783100485
Validation loss: 2.4835978813536883

Epoch: 6| Step: 6
Training loss: 2.254703056932102
Validation loss: 2.496643164108

Epoch: 6| Step: 7
Training loss: 2.738836343745691
Validation loss: 2.4978613699228727

Epoch: 6| Step: 8
Training loss: 3.4936654123292437
Validation loss: 2.4914198174059274

Epoch: 6| Step: 9
Training loss: 3.1583835453547864
Validation loss: 2.4910058953105496

Epoch: 6| Step: 10
Training loss: 2.9477082483238277
Validation loss: 2.490383420372979

Epoch: 6| Step: 11
Training loss: 2.8728624773528124
Validation loss: 2.494964392906084

Epoch: 6| Step: 12
Training loss: 2.763689473773472
Validation loss: 2.500566298426782

Epoch: 6| Step: 13
Training loss: 2.6563511548696446
Validation loss: 2.4876045858470746

Epoch: 39| Step: 0
Training loss: 2.9105706041531194
Validation loss: 2.494285141759846

Epoch: 6| Step: 1
Training loss: 2.4988255603199283
Validation loss: 2.493549139664811

Epoch: 6| Step: 2
Training loss: 2.63493257280685
Validation loss: 2.4880530487639962

Epoch: 6| Step: 3
Training loss: 2.842537086801815
Validation loss: 2.495211782685712

Epoch: 6| Step: 4
Training loss: 2.692445684396945
Validation loss: 2.4899044282029124

Epoch: 6| Step: 5
Training loss: 2.2364170373291197
Validation loss: 2.506194279453077

Epoch: 6| Step: 6
Training loss: 2.9815791750062677
Validation loss: 2.473438134588266

Epoch: 6| Step: 7
Training loss: 2.0761721046713184
Validation loss: 2.4914179395024565

Epoch: 6| Step: 8
Training loss: 2.5903984384896073
Validation loss: 2.5007625626868664

Epoch: 6| Step: 9
Training loss: 3.1194981780330413
Validation loss: 2.499883173191996

Epoch: 6| Step: 10
Training loss: 3.4680272629578117
Validation loss: 2.4910460733460416

Epoch: 6| Step: 11
Training loss: 2.7965380076692368
Validation loss: 2.490975098572276

Epoch: 6| Step: 12
Training loss: 3.5559432609760186
Validation loss: 2.487757432635053

Epoch: 6| Step: 13
Training loss: 2.2742402537307824
Validation loss: 2.4878521824581887

Epoch: 40| Step: 0
Training loss: 3.0583679973359823
Validation loss: 2.488926300398432

Epoch: 6| Step: 1
Training loss: 2.3786232064272594
Validation loss: 2.4806683343211713

Epoch: 6| Step: 2
Training loss: 3.1093989232355437
Validation loss: 2.4905917757574567

Epoch: 6| Step: 3
Training loss: 2.452406079343902
Validation loss: 2.4780569704690163

Epoch: 6| Step: 4
Training loss: 2.747131585645751
Validation loss: 2.4727753252514875

Epoch: 6| Step: 5
Training loss: 3.0311383098986675
Validation loss: 2.4852785002668747

Epoch: 6| Step: 6
Training loss: 3.310986731011553
Validation loss: 2.4927287196048433

Epoch: 6| Step: 7
Training loss: 3.4514622892629294
Validation loss: 2.486847205522096

Epoch: 6| Step: 8
Training loss: 3.1004944314745178
Validation loss: 2.486272770045753

Epoch: 6| Step: 9
Training loss: 2.177940954152378
Validation loss: 2.487262595816318

Epoch: 6| Step: 10
Training loss: 2.878550451852012
Validation loss: 2.4810613243324755

Epoch: 6| Step: 11
Training loss: 2.064790551968537
Validation loss: 2.4912593693723197

Epoch: 6| Step: 12
Training loss: 2.6563198304814657
Validation loss: 2.485791985924736

Epoch: 6| Step: 13
Training loss: 2.516310320082387
Validation loss: 2.4879090788445932

Epoch: 41| Step: 0
Training loss: 3.28477346977561
Validation loss: 2.482128562789548

Epoch: 6| Step: 1
Training loss: 2.9097048006064745
Validation loss: 2.483457330169768

Epoch: 6| Step: 2
Training loss: 2.6338432852397258
Validation loss: 2.482772914248974

Epoch: 6| Step: 3
Training loss: 3.2760500440303426
Validation loss: 2.4953122560582646

Epoch: 6| Step: 4
Training loss: 2.6061775581665887
Validation loss: 2.4721693909964513

Epoch: 6| Step: 5
Training loss: 2.743658817661765
Validation loss: 2.486245697894963

Epoch: 6| Step: 6
Training loss: 2.4261603066926045
Validation loss: 2.4837118811548864

Epoch: 6| Step: 7
Training loss: 2.2052317617328394
Validation loss: 2.4840795540321974

Epoch: 6| Step: 8
Training loss: 2.77212828776654
Validation loss: 2.477166081555033

Epoch: 6| Step: 9
Training loss: 2.1619472701341103
Validation loss: 2.4863155548884057

Epoch: 6| Step: 10
Training loss: 3.548466128087264
Validation loss: 2.4953381264478507

Epoch: 6| Step: 11
Training loss: 2.4928056195525072
Validation loss: 2.488696259811128

Epoch: 6| Step: 12
Training loss: 2.6678666951221333
Validation loss: 2.480741853724542

Epoch: 6| Step: 13
Training loss: 3.5328357478123023
Validation loss: 2.496971040778846

Epoch: 42| Step: 0
Training loss: 2.72222651807831
Validation loss: 2.477334102592259

Epoch: 6| Step: 1
Training loss: 2.867407517475822
Validation loss: 2.484219852266508

Epoch: 6| Step: 2
Training loss: 3.083355173256997
Validation loss: 2.4854862531780055

Epoch: 6| Step: 3
Training loss: 2.6625265129094586
Validation loss: 2.482074193518317

Epoch: 6| Step: 4
Training loss: 2.9699645118006006
Validation loss: 2.4859797038788063

Epoch: 6| Step: 5
Training loss: 2.752831821657487
Validation loss: 2.4894225952992826

Epoch: 6| Step: 6
Training loss: 2.582456614304373
Validation loss: 2.4810757799316407

Epoch: 6| Step: 7
Training loss: 2.157565061399341
Validation loss: 2.493237485918247

Epoch: 6| Step: 8
Training loss: 2.8119234129839064
Validation loss: 2.486952371597366

Epoch: 6| Step: 9
Training loss: 3.2016336085929438
Validation loss: 2.497924496891246

Epoch: 6| Step: 10
Training loss: 2.8881894960447934
Validation loss: 2.4734990092599616

Epoch: 6| Step: 11
Training loss: 2.966970291744959
Validation loss: 2.4853967376722244

Epoch: 6| Step: 12
Training loss: 2.911916315752197
Validation loss: 2.495286074100257

Epoch: 6| Step: 13
Training loss: 2.1408799291132903
Validation loss: 2.4912980563603284

Epoch: 43| Step: 0
Training loss: 3.1167407946687424
Validation loss: 2.4758758768003277

Epoch: 6| Step: 1
Training loss: 2.7714107361164855
Validation loss: 2.486450937761042

Epoch: 6| Step: 2
Training loss: 1.8590350441340808
Validation loss: 2.484890889981886

Epoch: 6| Step: 3
Training loss: 2.9145733178498134
Validation loss: 2.482031085606801

Epoch: 6| Step: 4
Training loss: 2.1433891771238875
Validation loss: 2.4794435526579566

Epoch: 6| Step: 5
Training loss: 3.0924720051145154
Validation loss: 2.483037457372995

Epoch: 6| Step: 6
Training loss: 2.9007172782700814
Validation loss: 2.4802102561840864

Epoch: 6| Step: 7
Training loss: 2.4275339278611017
Validation loss: 2.48235183510773

Epoch: 6| Step: 8
Training loss: 2.6696713824691525
Validation loss: 2.479519342176059

Epoch: 6| Step: 9
Training loss: 2.596337923224222
Validation loss: 2.4909656363513237

Epoch: 6| Step: 10
Training loss: 3.2695146238936585
Validation loss: 2.4759737184869737

Epoch: 6| Step: 11
Training loss: 3.5728751903977374
Validation loss: 2.4982056059028084

Epoch: 6| Step: 12
Training loss: 3.1521061047834333
Validation loss: 2.482087147642343

Epoch: 6| Step: 13
Training loss: 1.5524906758936017
Validation loss: 2.4757248117237194

Epoch: 44| Step: 0
Training loss: 3.5689408820790787
Validation loss: 2.486956594929861

Epoch: 6| Step: 1
Training loss: 2.5352073158799
Validation loss: 2.5060881930619594

Epoch: 6| Step: 2
Training loss: 3.0164866427102597
Validation loss: 2.488237714896118

Epoch: 6| Step: 3
Training loss: 2.1671171698128724
Validation loss: 2.4957039144609108

Epoch: 6| Step: 4
Training loss: 1.8436806229292058
Validation loss: 2.4942993778568003

Epoch: 6| Step: 5
Training loss: 3.1221425534631675
Validation loss: 2.4927433996213213

Epoch: 6| Step: 6
Training loss: 2.722207512675224
Validation loss: 2.490942377907147

Epoch: 6| Step: 7
Training loss: 2.500739179052944
Validation loss: 2.4744196511653587

Epoch: 6| Step: 8
Training loss: 2.716617054476506
Validation loss: 2.470153720011923

Epoch: 6| Step: 9
Training loss: 2.853063904023514
Validation loss: 2.4835469888681443

Epoch: 6| Step: 10
Training loss: 2.812849913128865
Validation loss: 2.4688796288053787

Epoch: 6| Step: 11
Training loss: 3.0530081813488974
Validation loss: 2.4806346726388826

Epoch: 6| Step: 12
Training loss: 3.311859356810309
Validation loss: 2.4832713701300624

Epoch: 6| Step: 13
Training loss: 2.186510461698043
Validation loss: 2.4811141979377607

Epoch: 45| Step: 0
Training loss: 2.027091243946705
Validation loss: 2.4907344501792035

Epoch: 6| Step: 1
Training loss: 2.8400207212524973
Validation loss: 2.4840807738894606

Epoch: 6| Step: 2
Training loss: 3.4730192837870395
Validation loss: 2.481954678154646

Epoch: 6| Step: 3
Training loss: 3.074702805214362
Validation loss: 2.478818093544961

Epoch: 6| Step: 4
Training loss: 2.94474677766947
Validation loss: 2.4848375452880638

Epoch: 6| Step: 5
Training loss: 2.5974217359190734
Validation loss: 2.4841523408965003

Epoch: 6| Step: 6
Training loss: 2.633993274549792
Validation loss: 2.49186561530463

Epoch: 6| Step: 7
Training loss: 2.8897834171330232
Validation loss: 2.4716764970527407

Epoch: 6| Step: 8
Training loss: 3.0705129931655932
Validation loss: 2.4808290860143116

Epoch: 6| Step: 9
Training loss: 2.1897449418040105
Validation loss: 2.496483847111559

Epoch: 6| Step: 10
Training loss: 2.8433217155812494
Validation loss: 2.4950708043058607

Epoch: 6| Step: 11
Training loss: 3.171109412493656
Validation loss: 2.4930216680045567

Epoch: 6| Step: 12
Training loss: 2.6123261352799445
Validation loss: 2.4803531220900084

Epoch: 6| Step: 13
Training loss: 2.307952120411579
Validation loss: 2.492556227563269

Epoch: 46| Step: 0
Training loss: 2.7834633581738393
Validation loss: 2.4825432462938113

Epoch: 6| Step: 1
Training loss: 2.798660134852933
Validation loss: 2.4829415119673435

Epoch: 6| Step: 2
Training loss: 2.8410638552038394
Validation loss: 2.4886591919161294

Epoch: 6| Step: 3
Training loss: 3.1138380981380545
Validation loss: 2.490079796191954

Epoch: 6| Step: 4
Training loss: 2.832437336187287
Validation loss: 2.4830125243344896

Epoch: 6| Step: 5
Training loss: 2.42521545396877
Validation loss: 2.4858622460109157

Epoch: 6| Step: 6
Training loss: 2.2441735593073977
Validation loss: 2.488410528954178

Epoch: 6| Step: 7
Training loss: 2.6142132156438436
Validation loss: 2.4764986240561053

Epoch: 6| Step: 8
Training loss: 2.985824951733611
Validation loss: 2.4840162568602255

Epoch: 6| Step: 9
Training loss: 3.3446381717335125
Validation loss: 2.485425882009771

Epoch: 6| Step: 10
Training loss: 2.791989540293647
Validation loss: 2.4791219315526094

Epoch: 6| Step: 11
Training loss: 2.223257617013851
Validation loss: 2.4792359313912784

Epoch: 6| Step: 12
Training loss: 3.1807495143188116
Validation loss: 2.485319007108946

Epoch: 6| Step: 13
Training loss: 2.643356806236745
Validation loss: 2.4894659922856257

Epoch: 47| Step: 0
Training loss: 2.501290560445435
Validation loss: 2.483409495595605

Epoch: 6| Step: 1
Training loss: 2.3845004747405874
Validation loss: 2.4937683157019874

Epoch: 6| Step: 2
Training loss: 2.8688717087003814
Validation loss: 2.4745244067774252

Epoch: 6| Step: 3
Training loss: 3.0208577823745704
Validation loss: 2.467531725290577

Epoch: 6| Step: 4
Training loss: 3.023314165463262
Validation loss: 2.4752225223318387

Epoch: 6| Step: 5
Training loss: 2.685667167050234
Validation loss: 2.4778254427761865

Epoch: 6| Step: 6
Training loss: 2.305416909865957
Validation loss: 2.4787023503663277

Epoch: 6| Step: 7
Training loss: 2.887697459153328
Validation loss: 2.474963212819688

Epoch: 6| Step: 8
Training loss: 2.8143040275392828
Validation loss: 2.481219384347125

Epoch: 6| Step: 9
Training loss: 3.3219698012309697
Validation loss: 2.4850325474943564

Epoch: 6| Step: 10
Training loss: 2.9582978009163057
Validation loss: 2.47713773213983

Epoch: 6| Step: 11
Training loss: 2.8311882500725085
Validation loss: 2.4815873841580216

Epoch: 6| Step: 12
Training loss: 2.5674829184197026
Validation loss: 2.4796540627515546

Epoch: 6| Step: 13
Training loss: 2.6297789169623385
Validation loss: 2.4839569790595823

Epoch: 48| Step: 0
Training loss: 2.723645592868455
Validation loss: 2.4926041118474007

Epoch: 6| Step: 1
Training loss: 2.3931767427156316
Validation loss: 2.4723978565147067

Epoch: 6| Step: 2
Training loss: 3.2337266944897745
Validation loss: 2.4735465867164814

Epoch: 6| Step: 3
Training loss: 2.438383675831497
Validation loss: 2.490256805158049

Epoch: 6| Step: 4
Training loss: 2.901635721543052
Validation loss: 2.4788866975093855

Epoch: 6| Step: 5
Training loss: 3.5659599233826085
Validation loss: 2.4975357041303283

Epoch: 6| Step: 6
Training loss: 2.973145774205788
Validation loss: 2.4807426618564508

Epoch: 6| Step: 7
Training loss: 3.107343000157833
Validation loss: 2.488871837563723

Epoch: 6| Step: 8
Training loss: 2.0607039983784925
Validation loss: 2.492646756133309

Epoch: 6| Step: 9
Training loss: 2.361280467622884
Validation loss: 2.471417646369623

Epoch: 6| Step: 10
Training loss: 2.5485965082741724
Validation loss: 2.4648913229104843

Epoch: 6| Step: 11
Training loss: 3.0225445515494185
Validation loss: 2.4726916356015445

Epoch: 6| Step: 12
Training loss: 2.356326325088521
Validation loss: 2.4753818504939717

Epoch: 6| Step: 13
Training loss: 3.009159727705677
Validation loss: 2.493013825973143

Epoch: 49| Step: 0
Training loss: 2.313571887711327
Validation loss: 2.4820707633805488

Epoch: 6| Step: 1
Training loss: 3.352110491149277
Validation loss: 2.4772997374379524

Epoch: 6| Step: 2
Training loss: 2.1938719452006485
Validation loss: 2.490747025780031

Epoch: 6| Step: 3
Training loss: 2.9956039963448906
Validation loss: 2.4739871246959577

Epoch: 6| Step: 4
Training loss: 2.7836091397930938
Validation loss: 2.4789576440186996

Epoch: 6| Step: 5
Training loss: 2.178112267521295
Validation loss: 2.472395460745538

Epoch: 6| Step: 6
Training loss: 2.655409376979487
Validation loss: 2.4755674421643725

Epoch: 6| Step: 7
Training loss: 3.081048032629501
Validation loss: 2.4751659956440304

Epoch: 6| Step: 8
Training loss: 2.389878499282549
Validation loss: 2.4810540283043743

Epoch: 6| Step: 9
Training loss: 2.594114255031563
Validation loss: 2.4736785043035274

Epoch: 6| Step: 10
Training loss: 3.315682663627342
Validation loss: 2.4941579968911656

Epoch: 6| Step: 11
Training loss: 3.1342380543207535
Validation loss: 2.473615780459094

Epoch: 6| Step: 12
Training loss: 2.7473379602107104
Validation loss: 2.4713273463773526

Epoch: 6| Step: 13
Training loss: 2.8056429029995265
Validation loss: 2.458881605552552

Epoch: 50| Step: 0
Training loss: 2.7292395623253762
Validation loss: 2.49594483711359

Epoch: 6| Step: 1
Training loss: 2.8686825546946415
Validation loss: 2.459296044428024

Epoch: 6| Step: 2
Training loss: 2.2395175894616903
Validation loss: 2.47882198117093

Epoch: 6| Step: 3
Training loss: 2.719940626393966
Validation loss: 2.477719586150718

Epoch: 6| Step: 4
Training loss: 2.5164459973867257
Validation loss: 2.469134096168208

Epoch: 6| Step: 5
Training loss: 2.5799127102656656
Validation loss: 2.4749071240724345

Epoch: 6| Step: 6
Training loss: 2.631554368054897
Validation loss: 2.480211926026408

Epoch: 6| Step: 7
Training loss: 3.72640383080711
Validation loss: 2.4867053338542355

Epoch: 6| Step: 8
Training loss: 2.3247414393884247
Validation loss: 2.4809474951706667

Epoch: 6| Step: 9
Training loss: 3.283364622738329
Validation loss: 2.4716813874798063

Epoch: 6| Step: 10
Training loss: 2.6682739976825816
Validation loss: 2.4713146615834143

Epoch: 6| Step: 11
Training loss: 2.6894564936775383
Validation loss: 2.4817092492404482

Epoch: 6| Step: 12
Training loss: 2.761711757278762
Validation loss: 2.4747029178928805

Epoch: 6| Step: 13
Training loss: 3.0043913173053873
Validation loss: 2.470205870215138

Epoch: 51| Step: 0
Training loss: 3.006917448757138
Validation loss: 2.477897246836546

Epoch: 6| Step: 1
Training loss: 2.3920158379454626
Validation loss: 2.467883698326295

Epoch: 6| Step: 2
Training loss: 3.6613559120724886
Validation loss: 2.4729408113767635

Epoch: 6| Step: 3
Training loss: 2.6333315193395364
Validation loss: 2.4766057972959628

Epoch: 6| Step: 4
Training loss: 2.6510607126047687
Validation loss: 2.4856567151639783

Epoch: 6| Step: 5
Training loss: 2.3005930592071833
Validation loss: 2.482365572666158

Epoch: 6| Step: 6
Training loss: 2.4041828342293003
Validation loss: 2.4850876597926344

Epoch: 6| Step: 7
Training loss: 2.6421127191447575
Validation loss: 2.4703689174707923

Epoch: 6| Step: 8
Training loss: 2.3986306376773894
Validation loss: 2.486408709959212

Epoch: 6| Step: 9
Training loss: 2.8343477863994706
Validation loss: 2.483430702700844

Epoch: 6| Step: 10
Training loss: 3.1324324151349514
Validation loss: 2.4792959311057103

Epoch: 6| Step: 11
Training loss: 3.259220102786211
Validation loss: 2.4776167039644266

Epoch: 6| Step: 12
Training loss: 1.8483148735690815
Validation loss: 2.4664008242448996

Epoch: 6| Step: 13
Training loss: 3.476029601670131
Validation loss: 2.4784339238324247

Epoch: 52| Step: 0
Training loss: 2.245290489858739
Validation loss: 2.462640208505598

Epoch: 6| Step: 1
Training loss: 3.2170365596895842
Validation loss: 2.4709746717757284

Epoch: 6| Step: 2
Training loss: 2.4233924295844727
Validation loss: 2.477897448066877

Epoch: 6| Step: 3
Training loss: 2.920519999096824
Validation loss: 2.477199294656073

Epoch: 6| Step: 4
Training loss: 2.6931198268087315
Validation loss: 2.4832879033888102

Epoch: 6| Step: 5
Training loss: 2.828875194548711
Validation loss: 2.478184792445745

Epoch: 6| Step: 6
Training loss: 2.7494690122354832
Validation loss: 2.4856768268671945

Epoch: 6| Step: 7
Training loss: 2.9947253587541605
Validation loss: 2.485315892967097

Epoch: 6| Step: 8
Training loss: 2.7172177260978754
Validation loss: 2.4893751358984124

Epoch: 6| Step: 9
Training loss: 2.3894351167173284
Validation loss: 2.4760202440654893

Epoch: 6| Step: 10
Training loss: 2.951300163182024
Validation loss: 2.4912072750226115

Epoch: 6| Step: 11
Training loss: 3.039475753654841
Validation loss: 2.4897665106672284

Epoch: 6| Step: 12
Training loss: 2.3554693573149095
Validation loss: 2.48900445081044

Epoch: 6| Step: 13
Training loss: 3.4250067049503827
Validation loss: 2.4829745166883583

Epoch: 53| Step: 0
Training loss: 2.9854619308699664
Validation loss: 2.473544462048368

Epoch: 6| Step: 1
Training loss: 2.9995569855697317
Validation loss: 2.4819935762807925

Epoch: 6| Step: 2
Training loss: 2.702854561921146
Validation loss: 2.4713409616075253

Epoch: 6| Step: 3
Training loss: 2.357142826179405
Validation loss: 2.4649428678610765

Epoch: 6| Step: 4
Training loss: 2.5518548876184473
Validation loss: 2.4812020164076527

Epoch: 6| Step: 5
Training loss: 3.070904468418122
Validation loss: 2.4909789507583073

Epoch: 6| Step: 6
Training loss: 2.6344679882792863
Validation loss: 2.463308699046724

Epoch: 6| Step: 7
Training loss: 2.999625977406766
Validation loss: 2.4688505477024947

Epoch: 6| Step: 8
Training loss: 2.6283059873188424
Validation loss: 2.4801307913726687

Epoch: 6| Step: 9
Training loss: 2.5686101870762434
Validation loss: 2.46453605985633

Epoch: 6| Step: 10
Training loss: 2.653913929242873
Validation loss: 2.475168506806344

Epoch: 6| Step: 11
Training loss: 3.025739557327169
Validation loss: 2.4649433431595806

Epoch: 6| Step: 12
Training loss: 2.8006196766832323
Validation loss: 2.485009741087393

Epoch: 6| Step: 13
Training loss: 2.7629134684324463
Validation loss: 2.4674026012791535

Epoch: 54| Step: 0
Training loss: 2.3396894757545375
Validation loss: 2.473503130153739

Epoch: 6| Step: 1
Training loss: 3.1473112529369844
Validation loss: 2.4647955760321043

Epoch: 6| Step: 2
Training loss: 3.297899566111245
Validation loss: 2.474844675834382

Epoch: 6| Step: 3
Training loss: 2.774241672035513
Validation loss: 2.4724047840644316

Epoch: 6| Step: 4
Training loss: 1.754654280907727
Validation loss: 2.4951369532415173

Epoch: 6| Step: 5
Training loss: 2.7719122332595676
Validation loss: 2.4745010611396

Epoch: 6| Step: 6
Training loss: 2.271008954271127
Validation loss: 2.4780492414340163

Epoch: 6| Step: 7
Training loss: 3.352163123174366
Validation loss: 2.4872992310199478

Epoch: 6| Step: 8
Training loss: 3.245293951371824
Validation loss: 2.465986818426124

Epoch: 6| Step: 9
Training loss: 2.496675378795273
Validation loss: 2.4860226381362245

Epoch: 6| Step: 10
Training loss: 2.514967743683807
Validation loss: 2.4847926297473437

Epoch: 6| Step: 11
Training loss: 2.6587161116419873
Validation loss: 2.465851622498141

Epoch: 6| Step: 12
Training loss: 2.6350036920742395
Validation loss: 2.480451158211354

Epoch: 6| Step: 13
Training loss: 2.9690183819374907
Validation loss: 2.4788208228472564

Epoch: 55| Step: 0
Training loss: 2.542319594352827
Validation loss: 2.471157184424521

Epoch: 6| Step: 1
Training loss: 2.6554232039870684
Validation loss: 2.486118110938213

Epoch: 6| Step: 2
Training loss: 2.5090437388980713
Validation loss: 2.4872121411334076

Epoch: 6| Step: 3
Training loss: 2.7399917897567816
Validation loss: 2.4787270040718914

Epoch: 6| Step: 4
Training loss: 3.1732681296833034
Validation loss: 2.481843828733818

Epoch: 6| Step: 5
Training loss: 2.5119013742171377
Validation loss: 2.471607042609006

Epoch: 6| Step: 6
Training loss: 2.5692389660945674
Validation loss: 2.467220502912681

Epoch: 6| Step: 7
Training loss: 2.4931825188126595
Validation loss: 2.4877644627142215

Epoch: 6| Step: 8
Training loss: 2.675562672841451
Validation loss: 2.477354673025988

Epoch: 6| Step: 9
Training loss: 2.5283142773440908
Validation loss: 2.4808420042714876

Epoch: 6| Step: 10
Training loss: 2.8948903549592906
Validation loss: 2.4718573461799065

Epoch: 6| Step: 11
Training loss: 2.388357246245494
Validation loss: 2.4741679551715596

Epoch: 6| Step: 12
Training loss: 3.626803508542363
Validation loss: 2.4758987880514165

Epoch: 6| Step: 13
Training loss: 3.306503049688982
Validation loss: 2.467698366110429

Epoch: 56| Step: 0
Training loss: 2.3573004083700306
Validation loss: 2.489570851568655

Epoch: 6| Step: 1
Training loss: 2.9127423361619402
Validation loss: 2.459128114907123

Epoch: 6| Step: 2
Training loss: 2.7187025570292556
Validation loss: 2.470803218657272

Epoch: 6| Step: 3
Training loss: 1.8877457692388493
Validation loss: 2.476605659621968

Epoch: 6| Step: 4
Training loss: 2.2365093574217303
Validation loss: 2.478748302433796

Epoch: 6| Step: 5
Training loss: 3.0699835448181316
Validation loss: 2.4746526277355043

Epoch: 6| Step: 6
Training loss: 2.467005632496911
Validation loss: 2.480002914636059

Epoch: 6| Step: 7
Training loss: 3.200205742659231
Validation loss: 2.4697692187762437

Epoch: 6| Step: 8
Training loss: 2.83435905813762
Validation loss: 2.475871780564794

Epoch: 6| Step: 9
Training loss: 2.7451022489365853
Validation loss: 2.488422529069823

Epoch: 6| Step: 10
Training loss: 3.446216836520007
Validation loss: 2.4723980804860837

Epoch: 6| Step: 11
Training loss: 3.264229508250261
Validation loss: 2.4718113697215705

Epoch: 6| Step: 12
Training loss: 2.225024311061444
Validation loss: 2.473729887919462

Epoch: 6| Step: 13
Training loss: 2.831592436370038
Validation loss: 2.4736774275171967

Epoch: 57| Step: 0
Training loss: 2.164639062197734
Validation loss: 2.472865385761346

Epoch: 6| Step: 1
Training loss: 2.769675010318135
Validation loss: 2.4785268569286196

Epoch: 6| Step: 2
Training loss: 2.945636114256944
Validation loss: 2.4763884605659925

Epoch: 6| Step: 3
Training loss: 2.903716593109697
Validation loss: 2.488823504469279

Epoch: 6| Step: 4
Training loss: 2.7674385633257024
Validation loss: 2.4696325425342587

Epoch: 6| Step: 5
Training loss: 2.7847672414166302
Validation loss: 2.468985209248897

Epoch: 6| Step: 6
Training loss: 2.9515499375228953
Validation loss: 2.4644087044184526

Epoch: 6| Step: 7
Training loss: 2.9668782005188326
Validation loss: 2.466845108613047

Epoch: 6| Step: 8
Training loss: 2.67455028425761
Validation loss: 2.4695928310147006

Epoch: 6| Step: 9
Training loss: 3.2019442731402896
Validation loss: 2.462340205660817

Epoch: 6| Step: 10
Training loss: 3.0727934386982048
Validation loss: 2.47308058879411

Epoch: 6| Step: 11
Training loss: 1.7735350997888668
Validation loss: 2.4710999967383236

Epoch: 6| Step: 12
Training loss: 2.66266655915855
Validation loss: 2.4651020846130347

Epoch: 6| Step: 13
Training loss: 2.5361836707032377
Validation loss: 2.4736335991175302

Epoch: 58| Step: 0
Training loss: 2.6618299330590784
Validation loss: 2.475163396440759

Epoch: 6| Step: 1
Training loss: 3.0229018572272133
Validation loss: 2.463800954963111

Epoch: 6| Step: 2
Training loss: 2.8070359452694347
Validation loss: 2.463431100489452

Epoch: 6| Step: 3
Training loss: 2.921124040518515
Validation loss: 2.474122606575784

Epoch: 6| Step: 4
Training loss: 2.97003274610558
Validation loss: 2.462084795591243

Epoch: 6| Step: 5
Training loss: 2.1413754449498414
Validation loss: 2.481319277472912

Epoch: 6| Step: 6
Training loss: 2.2239736397162146
Validation loss: 2.477613927807942

Epoch: 6| Step: 7
Training loss: 3.588025650698216
Validation loss: 2.480198274735284

Epoch: 6| Step: 8
Training loss: 2.8358675525120396
Validation loss: 2.471335631189013

Epoch: 6| Step: 9
Training loss: 2.556978184481261
Validation loss: 2.4782486440667193

Epoch: 6| Step: 10
Training loss: 2.5662056715342403
Validation loss: 2.4682916818359315

Epoch: 6| Step: 11
Training loss: 2.514197471698828
Validation loss: 2.4792834845803076

Epoch: 6| Step: 12
Training loss: 2.552319283509723
Validation loss: 2.4685962505032495

Epoch: 6| Step: 13
Training loss: 2.9779389170165067
Validation loss: 2.4717103761562242

Epoch: 59| Step: 0
Training loss: 2.7927590031327187
Validation loss: 2.4739242884695685

Epoch: 6| Step: 1
Training loss: 2.8875790605827096
Validation loss: 2.492541340225208

Epoch: 6| Step: 2
Training loss: 2.5956736405809924
Validation loss: 2.468900678799394

Epoch: 6| Step: 3
Training loss: 2.7558053901516106
Validation loss: 2.462679242022199

Epoch: 6| Step: 4
Training loss: 2.3554638914750887
Validation loss: 2.4659564255240687

Epoch: 6| Step: 5
Training loss: 2.250815031995756
Validation loss: 2.4730106917431556

Epoch: 6| Step: 6
Training loss: 2.906702806207281
Validation loss: 2.470536707608653

Epoch: 6| Step: 7
Training loss: 3.133444705634137
Validation loss: 2.4852688296493906

Epoch: 6| Step: 8
Training loss: 2.671561596431082
Validation loss: 2.4702202097972257

Epoch: 6| Step: 9
Training loss: 2.771292187167877
Validation loss: 2.4693121871629296

Epoch: 6| Step: 10
Training loss: 2.7138257210533046
Validation loss: 2.4578993699138145

Epoch: 6| Step: 11
Training loss: 3.0736156293702983
Validation loss: 2.482177623217839

Epoch: 6| Step: 12
Training loss: 2.8169510270839386
Validation loss: 2.46358328154132

Epoch: 6| Step: 13
Training loss: 2.8154058915216633
Validation loss: 2.474352433960505

Epoch: 60| Step: 0
Training loss: 2.7566098624868847
Validation loss: 2.461401872368053

Epoch: 6| Step: 1
Training loss: 2.6837772934071693
Validation loss: 2.4763856933849318

Epoch: 6| Step: 2
Training loss: 2.5798606809807123
Validation loss: 2.4767697533111335

Epoch: 6| Step: 3
Training loss: 2.6021320991028953
Validation loss: 2.476549390687824

Epoch: 6| Step: 4
Training loss: 2.8279552935691075
Validation loss: 2.467277486466588

Epoch: 6| Step: 5
Training loss: 2.789260130646838
Validation loss: 2.4587569105607345

Epoch: 6| Step: 6
Training loss: 2.4036020348644227
Validation loss: 2.4684732842029

Epoch: 6| Step: 7
Training loss: 3.245715177749841
Validation loss: 2.4673511045972965

Epoch: 6| Step: 8
Training loss: 2.2511561919921568
Validation loss: 2.4582082130150287

Epoch: 6| Step: 9
Training loss: 1.7816363802346797
Validation loss: 2.4715547653447576

Epoch: 6| Step: 10
Training loss: 2.9240672001663826
Validation loss: 2.4631668818964405

Epoch: 6| Step: 11
Training loss: 2.736425361294287
Validation loss: 2.4694353769367985

Epoch: 6| Step: 12
Training loss: 3.4885387774129257
Validation loss: 2.4666144762390703

Epoch: 6| Step: 13
Training loss: 3.2419379080792567
Validation loss: 2.4706171933519583

Epoch: 61| Step: 0
Training loss: 3.108363001241224
Validation loss: 2.46678656760858

Epoch: 6| Step: 1
Training loss: 3.0784383701427402
Validation loss: 2.469028156602867

Epoch: 6| Step: 2
Training loss: 2.814256246909048
Validation loss: 2.4757923395911

Epoch: 6| Step: 3
Training loss: 2.2313353663764737
Validation loss: 2.4737953209184878

Epoch: 6| Step: 4
Training loss: 3.228602025698466
Validation loss: 2.478615028748049

Epoch: 6| Step: 5
Training loss: 2.448083252345107
Validation loss: 2.477523656016736

Epoch: 6| Step: 6
Training loss: 2.315128791143179
Validation loss: 2.4614201627278827

Epoch: 6| Step: 7
Training loss: 2.338645972380356
Validation loss: 2.4828670582061996

Epoch: 6| Step: 8
Training loss: 2.1608390074024175
Validation loss: 2.4660367124981573

Epoch: 6| Step: 9
Training loss: 2.168057276662431
Validation loss: 2.455216058354191

Epoch: 6| Step: 10
Training loss: 3.269612337517475
Validation loss: 2.47838417434566

Epoch: 6| Step: 11
Training loss: 3.059922048037086
Validation loss: 2.4774784976747197

Epoch: 6| Step: 12
Training loss: 2.5875476998617937
Validation loss: 2.479219082610601

Epoch: 6| Step: 13
Training loss: 3.4568955216999573
Validation loss: 2.466360117916032

Epoch: 62| Step: 0
Training loss: 2.4397203163196375
Validation loss: 2.469821430035489

Epoch: 6| Step: 1
Training loss: 3.1594735482049283
Validation loss: 2.4742960588710963

Epoch: 6| Step: 2
Training loss: 2.3220970407032673
Validation loss: 2.467685680323262

Epoch: 6| Step: 3
Training loss: 2.874534237493012
Validation loss: 2.478637807113238

Epoch: 6| Step: 4
Training loss: 2.4318587730021233
Validation loss: 2.4723042284806764

Epoch: 6| Step: 5
Training loss: 3.1601678685374335
Validation loss: 2.486751407106546

Epoch: 6| Step: 6
Training loss: 2.942294489474663
Validation loss: 2.4834817374428835

Epoch: 6| Step: 7
Training loss: 2.644929345959394
Validation loss: 2.4738275243160546

Epoch: 6| Step: 8
Training loss: 2.760838045791149
Validation loss: 2.4968786658275888

Epoch: 6| Step: 9
Training loss: 2.6932540330763692
Validation loss: 2.463640773784368

Epoch: 6| Step: 10
Training loss: 3.24506605201586
Validation loss: 2.473320597825982

Epoch: 6| Step: 11
Training loss: 2.554527814348195
Validation loss: 2.4888176004087397

Epoch: 6| Step: 12
Training loss: 2.583558800815361
Validation loss: 2.4726089394994077

Epoch: 6| Step: 13
Training loss: 2.063439357582838
Validation loss: 2.4769125273403207

Epoch: 63| Step: 0
Training loss: 3.004935654952577
Validation loss: 2.4572768787413986

Epoch: 6| Step: 1
Training loss: 1.9416765297351326
Validation loss: 2.4782836953458576

Epoch: 6| Step: 2
Training loss: 2.689498158550891
Validation loss: 2.4721097855691747

Epoch: 6| Step: 3
Training loss: 2.7821400107742207
Validation loss: 2.4658447124062266

Epoch: 6| Step: 4
Training loss: 2.9800316326331404
Validation loss: 2.4670688590051832

Epoch: 6| Step: 5
Training loss: 2.9686908916813084
Validation loss: 2.4680327908864856

Epoch: 6| Step: 6
Training loss: 2.5885054178341482
Validation loss: 2.479769443091833

Epoch: 6| Step: 7
Training loss: 2.890047582742813
Validation loss: 2.4853838544355

Epoch: 6| Step: 8
Training loss: 2.4092940854983813
Validation loss: 2.4834461731871653

Epoch: 6| Step: 9
Training loss: 3.3851517480731808
Validation loss: 2.4773071159276174

Epoch: 6| Step: 10
Training loss: 3.079330595519732
Validation loss: 2.4680901389718137

Epoch: 6| Step: 11
Training loss: 2.3449340880999103
Validation loss: 2.456899718884371

Epoch: 6| Step: 12
Training loss: 2.5445567620801857
Validation loss: 2.4748590206508383

Epoch: 6| Step: 13
Training loss: 2.4571775747615665
Validation loss: 2.4664537553960675

Epoch: 64| Step: 0
Training loss: 2.8989143904657673
Validation loss: 2.475382738049817

Epoch: 6| Step: 1
Training loss: 2.921778386604584
Validation loss: 2.4844546515213977

Epoch: 6| Step: 2
Training loss: 2.942555723481038
Validation loss: 2.4792023060995265

Epoch: 6| Step: 3
Training loss: 2.261967726000802
Validation loss: 2.4750267570543323

Epoch: 6| Step: 4
Training loss: 2.829785275889604
Validation loss: 2.4631279799635597

Epoch: 6| Step: 5
Training loss: 3.081162865820775
Validation loss: 2.4769576411459795

Epoch: 6| Step: 6
Training loss: 3.0413473998127305
Validation loss: 2.4636554856057797

Epoch: 6| Step: 7
Training loss: 2.6517957253241917
Validation loss: 2.4729859934903957

Epoch: 6| Step: 8
Training loss: 2.333040207661494
Validation loss: 2.468709254522446

Epoch: 6| Step: 9
Training loss: 2.1907281217369583
Validation loss: 2.4772501022945876

Epoch: 6| Step: 10
Training loss: 2.9273874434831297
Validation loss: 2.472287492150482

Epoch: 6| Step: 11
Training loss: 3.1588166631163705
Validation loss: 2.469996659249749

Epoch: 6| Step: 12
Training loss: 2.6899951618533957
Validation loss: 2.470527607088222

Epoch: 6| Step: 13
Training loss: 1.2113918313524252
Validation loss: 2.452561873404273

Epoch: 65| Step: 0
Training loss: 2.898277422245218
Validation loss: 2.4560539568368265

Epoch: 6| Step: 1
Training loss: 2.5606388683655825
Validation loss: 2.4798933151553264

Epoch: 6| Step: 2
Training loss: 2.221507762921988
Validation loss: 2.461003957522664

Epoch: 6| Step: 3
Training loss: 2.629606473947139
Validation loss: 2.4727732569417813

Epoch: 6| Step: 4
Training loss: 2.8691389630483615
Validation loss: 2.465094710150512

Epoch: 6| Step: 5
Training loss: 2.2415789798570587
Validation loss: 2.469694830876255

Epoch: 6| Step: 6
Training loss: 2.9878880460261454
Validation loss: 2.4544805372996694

Epoch: 6| Step: 7
Training loss: 2.9199849099592363
Validation loss: 2.4709392356481286

Epoch: 6| Step: 8
Training loss: 2.8214453115535743
Validation loss: 2.46958346645641

Epoch: 6| Step: 9
Training loss: 2.688401093343437
Validation loss: 2.468668284062641

Epoch: 6| Step: 10
Training loss: 2.51262243930957
Validation loss: 2.4512490788248913

Epoch: 6| Step: 11
Training loss: 2.7972290837863416
Validation loss: 2.4621329221196726

Epoch: 6| Step: 12
Training loss: 3.107058942065666
Validation loss: 2.4766015894369455

Epoch: 6| Step: 13
Training loss: 2.9214710629564506
Validation loss: 2.4683358574705245

Epoch: 66| Step: 0
Training loss: 2.6237821024347903
Validation loss: 2.4636057264545466

Epoch: 6| Step: 1
Training loss: 3.4899480069285347
Validation loss: 2.4530208406947063

Epoch: 6| Step: 2
Training loss: 2.1754606000400605
Validation loss: 2.4703360836845016

Epoch: 6| Step: 3
Training loss: 2.6841455861159655
Validation loss: 2.4659298372753704

Epoch: 6| Step: 4
Training loss: 2.877416341644292
Validation loss: 2.4503077746695885

Epoch: 6| Step: 5
Training loss: 2.566414425167725
Validation loss: 2.4570160258564733

Epoch: 6| Step: 6
Training loss: 2.466196405415231
Validation loss: 2.4673211306085374

Epoch: 6| Step: 7
Training loss: 2.6719431729013
Validation loss: 2.4731598442507425

Epoch: 6| Step: 8
Training loss: 3.0074199469892506
Validation loss: 2.4663168631972767

Epoch: 6| Step: 9
Training loss: 2.54969117033552
Validation loss: 2.4773621227550824

Epoch: 6| Step: 10
Training loss: 2.8778654000072836
Validation loss: 2.4609567511567807

Epoch: 6| Step: 11
Training loss: 2.867683388550377
Validation loss: 2.4749781691208965

Epoch: 6| Step: 12
Training loss: 2.622255525494247
Validation loss: 2.463147119287571

Epoch: 6| Step: 13
Training loss: 2.5416272165540854
Validation loss: 2.479989091628871

Epoch: 67| Step: 0
Training loss: 2.4149771627290155
Validation loss: 2.4739823445232725

Epoch: 6| Step: 1
Training loss: 3.1024122635503075
Validation loss: 2.458863339056652

Epoch: 6| Step: 2
Training loss: 2.410770381295022
Validation loss: 2.463102500878486

Epoch: 6| Step: 3
Training loss: 2.741997954074978
Validation loss: 2.472911334329863

Epoch: 6| Step: 4
Training loss: 2.519792031683284
Validation loss: 2.460776394832902

Epoch: 6| Step: 5
Training loss: 2.2168123622807023
Validation loss: 2.4766589875370575

Epoch: 6| Step: 6
Training loss: 3.1316201849697793
Validation loss: 2.4702516280007196

Epoch: 6| Step: 7
Training loss: 2.4239240284650556
Validation loss: 2.4692696828771328

Epoch: 6| Step: 8
Training loss: 3.3091448220235087
Validation loss: 2.4663887289369875

Epoch: 6| Step: 9
Training loss: 3.048082317892742
Validation loss: 2.460582938226112

Epoch: 6| Step: 10
Training loss: 3.0469912775789316
Validation loss: 2.454301449464852

Epoch: 6| Step: 11
Training loss: 2.2586072954994196
Validation loss: 2.4703268236455878

Epoch: 6| Step: 12
Training loss: 2.872946793857219
Validation loss: 2.4818095280907944

Epoch: 6| Step: 13
Training loss: 2.203712439170974
Validation loss: 2.4637731270688916

Epoch: 68| Step: 0
Training loss: 2.7349008109118187
Validation loss: 2.4744553555157256

Epoch: 6| Step: 1
Training loss: 2.6890866231418156
Validation loss: 2.4584383398967837

Epoch: 6| Step: 2
Training loss: 2.6189106748539115
Validation loss: 2.487621607646981

Epoch: 6| Step: 3
Training loss: 3.0283769973129178
Validation loss: 2.4609850150822905

Epoch: 6| Step: 4
Training loss: 2.929740396657882
Validation loss: 2.4748050303401645

Epoch: 6| Step: 5
Training loss: 2.700327754437279
Validation loss: 2.4740014827745482

Epoch: 6| Step: 6
Training loss: 2.5867237382504853
Validation loss: 2.4621086806610806

Epoch: 6| Step: 7
Training loss: 2.715880710515917
Validation loss: 2.4751016714228307

Epoch: 6| Step: 8
Training loss: 3.123342608584294
Validation loss: 2.474207804115204

Epoch: 6| Step: 9
Training loss: 2.6281187513279423
Validation loss: 2.48543320646288

Epoch: 6| Step: 10
Training loss: 2.712474552158224
Validation loss: 2.503383407127466

Epoch: 6| Step: 11
Training loss: 2.839651654868268
Validation loss: 2.4815099779861494

Epoch: 6| Step: 12
Training loss: 2.352263184646597
Validation loss: 2.4668207404262015

Epoch: 6| Step: 13
Training loss: 2.24824699352958
Validation loss: 2.478287351061037

Epoch: 69| Step: 0
Training loss: 2.715278250414283
Validation loss: 2.4773383236947875

Epoch: 6| Step: 1
Training loss: 2.670129573978292
Validation loss: 2.4654673180593596

Epoch: 6| Step: 2
Training loss: 3.197248175683524
Validation loss: 2.46785603073909

Epoch: 6| Step: 3
Training loss: 2.1936651273214918
Validation loss: 2.471951340640111

Epoch: 6| Step: 4
Training loss: 2.1990539597452115
Validation loss: 2.48201641350093

Epoch: 6| Step: 5
Training loss: 2.8911412783251103
Validation loss: 2.4639680130106814

Epoch: 6| Step: 6
Training loss: 3.461527410310238
Validation loss: 2.4747807571060187

Epoch: 6| Step: 7
Training loss: 2.5236188038039424
Validation loss: 2.474522819604269

Epoch: 6| Step: 8
Training loss: 2.518811310809945
Validation loss: 2.466396330803098

Epoch: 6| Step: 9
Training loss: 3.0622176993911383
Validation loss: 2.474653335295945

Epoch: 6| Step: 10
Training loss: 2.5881520725834237
Validation loss: 2.4698901603753938

Epoch: 6| Step: 11
Training loss: 2.8558501316359783
Validation loss: 2.464404105398085

Epoch: 6| Step: 12
Training loss: 2.5898706311057813
Validation loss: 2.4784446048095954

Epoch: 6| Step: 13
Training loss: 1.8549052778259112
Validation loss: 2.4539299354870527

Epoch: 70| Step: 0
Training loss: 2.5698308522412248
Validation loss: 2.4657217684816284

Epoch: 6| Step: 1
Training loss: 2.937604537077747
Validation loss: 2.478972881295999

Epoch: 6| Step: 2
Training loss: 2.9795345977295487
Validation loss: 2.4630136488336545

Epoch: 6| Step: 3
Training loss: 2.9560212964231543
Validation loss: 2.47737710907099

Epoch: 6| Step: 4
Training loss: 2.0581841830476826
Validation loss: 2.471054239100398

Epoch: 6| Step: 5
Training loss: 2.006165062363087
Validation loss: 2.4732342543924943

Epoch: 6| Step: 6
Training loss: 2.922161231071273
Validation loss: 2.4686520070131683

Epoch: 6| Step: 7
Training loss: 2.9787311013246938
Validation loss: 2.4673252732499256

Epoch: 6| Step: 8
Training loss: 2.8236444715122095
Validation loss: 2.4789178512629246

Epoch: 6| Step: 9
Training loss: 3.1348000022453024
Validation loss: 2.4552995250703185

Epoch: 6| Step: 10
Training loss: 2.353042896961074
Validation loss: 2.451137517480662

Epoch: 6| Step: 11
Training loss: 2.4357482288522125
Validation loss: 2.4539551337185745

Epoch: 6| Step: 12
Training loss: 2.6166554379880327
Validation loss: 2.4687185247825796

Epoch: 6| Step: 13
Training loss: 3.2329508276614956
Validation loss: 2.478769109349041

Epoch: 71| Step: 0
Training loss: 2.691540187387561
Validation loss: 2.463693973387892

Epoch: 6| Step: 1
Training loss: 2.5402870394500403
Validation loss: 2.461620436452916

Epoch: 6| Step: 2
Training loss: 2.1240978569936946
Validation loss: 2.4535231195694642

Epoch: 6| Step: 3
Training loss: 2.2710811818040506
Validation loss: 2.4764501804263666

Epoch: 6| Step: 4
Training loss: 2.163771516813047
Validation loss: 2.4553252354799247

Epoch: 6| Step: 5
Training loss: 2.7881066316548115
Validation loss: 2.4735921909820227

Epoch: 6| Step: 6
Training loss: 2.916869092910373
Validation loss: 2.4778274209942053

Epoch: 6| Step: 7
Training loss: 2.8429688439260428
Validation loss: 2.4566166158449065

Epoch: 6| Step: 8
Training loss: 3.134260874959167
Validation loss: 2.4685563436878044

Epoch: 6| Step: 9
Training loss: 2.5712127500366297
Validation loss: 2.463745996026166

Epoch: 6| Step: 10
Training loss: 2.9373888035282736
Validation loss: 2.46156707955751

Epoch: 6| Step: 11
Training loss: 2.892556694615921
Validation loss: 2.4576918802914363

Epoch: 6| Step: 12
Training loss: 3.0882074819642797
Validation loss: 2.4739925628694768

Epoch: 6| Step: 13
Training loss: 2.8950997024787384
Validation loss: 2.459329851198945

Epoch: 72| Step: 0
Training loss: 2.6400078046567743
Validation loss: 2.4700679835732995

Epoch: 6| Step: 1
Training loss: 2.4521272416074176
Validation loss: 2.4693639928141

Epoch: 6| Step: 2
Training loss: 1.9484408552176091
Validation loss: 2.4807409205488766

Epoch: 6| Step: 3
Training loss: 2.4075571448336692
Validation loss: 2.463054212709612

Epoch: 6| Step: 4
Training loss: 3.396495606292529
Validation loss: 2.445954171888156

Epoch: 6| Step: 5
Training loss: 2.101128288706286
Validation loss: 2.4544756554242317

Epoch: 6| Step: 6
Training loss: 2.557128673157928
Validation loss: 2.4739728142012836

Epoch: 6| Step: 7
Training loss: 3.159173197201602
Validation loss: 2.4646597671157697

Epoch: 6| Step: 8
Training loss: 3.178429507030878
Validation loss: 2.47156204273811

Epoch: 6| Step: 9
Training loss: 2.405733127319573
Validation loss: 2.477001149915261

Epoch: 6| Step: 10
Training loss: 2.956850799738888
Validation loss: 2.45060216616084

Epoch: 6| Step: 11
Training loss: 2.6782278639847954
Validation loss: 2.4677151501865637

Epoch: 6| Step: 12
Training loss: 3.044376855488233
Validation loss: 2.4740725206707657

Epoch: 6| Step: 13
Training loss: 2.5314753867694586
Validation loss: 2.470532887884605

Epoch: 73| Step: 0
Training loss: 2.598456742702304
Validation loss: 2.472284777411646

Epoch: 6| Step: 1
Training loss: 2.6533576926194686
Validation loss: 2.465956813299729

Epoch: 6| Step: 2
Training loss: 2.734066319072191
Validation loss: 2.4823168526326818

Epoch: 6| Step: 3
Training loss: 2.641497586331699
Validation loss: 2.468462442203774

Epoch: 6| Step: 4
Training loss: 2.1191706642096175
Validation loss: 2.469211794268428

Epoch: 6| Step: 5
Training loss: 2.9177180620435545
Validation loss: 2.458266266884255

Epoch: 6| Step: 6
Training loss: 2.7490370538350613
Validation loss: 2.450960716634263

Epoch: 6| Step: 7
Training loss: 2.6280892677009904
Validation loss: 2.4710239277195982

Epoch: 6| Step: 8
Training loss: 2.4282911403379233
Validation loss: 2.464127185071934

Epoch: 6| Step: 9
Training loss: 2.9302274892980726
Validation loss: 2.465736114386766

Epoch: 6| Step: 10
Training loss: 2.684685142284269
Validation loss: 2.443942657686478

Epoch: 6| Step: 11
Training loss: 2.585245737168018
Validation loss: 2.469401713704049

Epoch: 6| Step: 12
Training loss: 3.1497233678056826
Validation loss: 2.4591998529651233

Epoch: 6| Step: 13
Training loss: 3.2891600678168875
Validation loss: 2.456446943956738

Epoch: 74| Step: 0
Training loss: 2.449331667303364
Validation loss: 2.4704731423151047

Epoch: 6| Step: 1
Training loss: 2.8663555050317093
Validation loss: 2.4533105355113483

Epoch: 6| Step: 2
Training loss: 2.5076858631139434
Validation loss: 2.4672435018125705

Epoch: 6| Step: 3
Training loss: 2.698164517323346
Validation loss: 2.4499515280450037

Epoch: 6| Step: 4
Training loss: 3.3816868977500065
Validation loss: 2.4825901712741976

Epoch: 6| Step: 5
Training loss: 2.3679918993476257
Validation loss: 2.4613318436449605

Epoch: 6| Step: 6
Training loss: 3.1393150520410784
Validation loss: 2.4742522367671658

Epoch: 6| Step: 7
Training loss: 2.8200742668490903
Validation loss: 2.474183948291686

Epoch: 6| Step: 8
Training loss: 2.776533263422325
Validation loss: 2.453486211991586

Epoch: 6| Step: 9
Training loss: 2.8590146030454697
Validation loss: 2.4619938783930144

Epoch: 6| Step: 10
Training loss: 2.2789257175580473
Validation loss: 2.4588623204244326

Epoch: 6| Step: 11
Training loss: 2.6106111259721936
Validation loss: 2.4919377128269065

Epoch: 6| Step: 12
Training loss: 2.391735741374323
Validation loss: 2.4700761127755597

Epoch: 6| Step: 13
Training loss: 2.605107455389504
Validation loss: 2.4758287862499997

Epoch: 75| Step: 0
Training loss: 2.6707470392419475
Validation loss: 2.4610187476087417

Epoch: 6| Step: 1
Training loss: 2.873943964189587
Validation loss: 2.4848250372770155

Epoch: 6| Step: 2
Training loss: 3.0901614868533236
Validation loss: 2.472791919356868

Epoch: 6| Step: 3
Training loss: 3.1733343966933747
Validation loss: 2.4692980613693436

Epoch: 6| Step: 4
Training loss: 2.6073242169211626
Validation loss: 2.471059564938581

Epoch: 6| Step: 5
Training loss: 3.0070533488000004
Validation loss: 2.4703203837314245

Epoch: 6| Step: 6
Training loss: 2.5864551406412524
Validation loss: 2.470920904735694

Epoch: 6| Step: 7
Training loss: 2.23588457664699
Validation loss: 2.478193619675518

Epoch: 6| Step: 8
Training loss: 1.9001020504499286
Validation loss: 2.469509254631648

Epoch: 6| Step: 9
Training loss: 2.9299335834149307
Validation loss: 2.469755370670379

Epoch: 6| Step: 10
Training loss: 2.558457884930374
Validation loss: 2.46336624114771

Epoch: 6| Step: 11
Training loss: 3.136595917193336
Validation loss: 2.4623107485134272

Epoch: 6| Step: 12
Training loss: 2.440582673588644
Validation loss: 2.470943920031431

Epoch: 6| Step: 13
Training loss: 2.0131430315348884
Validation loss: 2.4716326373203366

Epoch: 76| Step: 0
Training loss: 3.146229615840723
Validation loss: 2.4500473716028566

Epoch: 6| Step: 1
Training loss: 2.367560731779557
Validation loss: 2.471255259615446

Epoch: 6| Step: 2
Training loss: 2.928408412184381
Validation loss: 2.4661686097485513

Epoch: 6| Step: 3
Training loss: 2.8750223905271963
Validation loss: 2.4777686221348763

Epoch: 6| Step: 4
Training loss: 2.3477180967896056
Validation loss: 2.477406651985487

Epoch: 6| Step: 5
Training loss: 2.1904996740867304
Validation loss: 2.470030215254877

Epoch: 6| Step: 6
Training loss: 2.7098327496427483
Validation loss: 2.463250163501762

Epoch: 6| Step: 7
Training loss: 3.1713265381727487
Validation loss: 2.468501389886756

Epoch: 6| Step: 8
Training loss: 2.8240426458429324
Validation loss: 2.470726149587641

Epoch: 6| Step: 9
Training loss: 2.9498447183376766
Validation loss: 2.4664310931777136

Epoch: 6| Step: 10
Training loss: 2.6291237184268135
Validation loss: 2.473129324924028

Epoch: 6| Step: 11
Training loss: 2.5599526560399064
Validation loss: 2.466671144331194

Epoch: 6| Step: 12
Training loss: 2.544734874772958
Validation loss: 2.4687247741664855

Epoch: 6| Step: 13
Training loss: 2.481988012065109
Validation loss: 2.452606605175602

Epoch: 77| Step: 0
Training loss: 2.5959489991537343
Validation loss: 2.4552105326484335

Epoch: 6| Step: 1
Training loss: 2.923488395896235
Validation loss: 2.4694088001921535

Epoch: 6| Step: 2
Training loss: 2.350079344363651
Validation loss: 2.4752923424256603

Epoch: 6| Step: 3
Training loss: 2.1999521336983596
Validation loss: 2.486948187429542

Epoch: 6| Step: 4
Training loss: 2.3721793641629416
Validation loss: 2.4723785160950276

Epoch: 6| Step: 5
Training loss: 2.426670863476293
Validation loss: 2.4663465146886376

Epoch: 6| Step: 6
Training loss: 2.229410912748769
Validation loss: 2.445016772247927

Epoch: 6| Step: 7
Training loss: 2.919462789213128
Validation loss: 2.4553756698678644

Epoch: 6| Step: 8
Training loss: 3.073403236962279
Validation loss: 2.461700553461128

Epoch: 6| Step: 9
Training loss: 2.771018077074143
Validation loss: 2.46561923202667

Epoch: 6| Step: 10
Training loss: 3.004572562540192
Validation loss: 2.4539774264158973

Epoch: 6| Step: 11
Training loss: 3.2303843181605463
Validation loss: 2.472007985948966

Epoch: 6| Step: 12
Training loss: 3.0197608534754234
Validation loss: 2.4584345962694822

Epoch: 6| Step: 13
Training loss: 2.255771757463782
Validation loss: 2.445583126846511

Epoch: 78| Step: 0
Training loss: 3.478581286008234
Validation loss: 2.448866826596845

Epoch: 6| Step: 1
Training loss: 2.7237581625645855
Validation loss: 2.446101511421419

Epoch: 6| Step: 2
Training loss: 2.744407515935888
Validation loss: 2.4724149902664476

Epoch: 6| Step: 3
Training loss: 2.8518121479439427
Validation loss: 2.457976600232744

Epoch: 6| Step: 4
Training loss: 2.6491066416511684
Validation loss: 2.4630742310671945

Epoch: 6| Step: 5
Training loss: 2.4752197476329783
Validation loss: 2.4591412117975797

Epoch: 6| Step: 6
Training loss: 2.6519987306088364
Validation loss: 2.4660775031720377

Epoch: 6| Step: 7
Training loss: 2.060216390855203
Validation loss: 2.46373877046529

Epoch: 6| Step: 8
Training loss: 3.0630179765144514
Validation loss: 2.463019002987133

Epoch: 6| Step: 9
Training loss: 2.766836472168296
Validation loss: 2.4669192686034327

Epoch: 6| Step: 10
Training loss: 2.9110333855358137
Validation loss: 2.464894222602581

Epoch: 6| Step: 11
Training loss: 2.3192685023091273
Validation loss: 2.479080210752016

Epoch: 6| Step: 12
Training loss: 2.681583189991724
Validation loss: 2.475025235458963

Epoch: 6| Step: 13
Training loss: 1.8422249127731238
Validation loss: 2.4716491613060723

Epoch: 79| Step: 0
Training loss: 2.8552075643630013
Validation loss: 2.471532414402359

Epoch: 6| Step: 1
Training loss: 2.860771130193848
Validation loss: 2.4481001494341577

Epoch: 6| Step: 2
Training loss: 2.4915826236836076
Validation loss: 2.464787043014444

Epoch: 6| Step: 3
Training loss: 2.514652798843305
Validation loss: 2.472293263812219

Epoch: 6| Step: 4
Training loss: 2.115007580321956
Validation loss: 2.4688560688394587

Epoch: 6| Step: 5
Training loss: 2.5171824307808013
Validation loss: 2.486521976717604

Epoch: 6| Step: 6
Training loss: 3.2804360969737125
Validation loss: 2.461481164329193

Epoch: 6| Step: 7
Training loss: 2.458320315913849
Validation loss: 2.4744770004186276

Epoch: 6| Step: 8
Training loss: 2.536580630467094
Validation loss: 2.4767927111519614

Epoch: 6| Step: 9
Training loss: 2.270966855477904
Validation loss: 2.4671781911931996

Epoch: 6| Step: 10
Training loss: 3.104913933094022
Validation loss: 2.464252901972385

Epoch: 6| Step: 11
Training loss: 2.693801677588744
Validation loss: 2.4646253812648493

Epoch: 6| Step: 12
Training loss: 2.715412063942037
Validation loss: 2.474097242271362

Epoch: 6| Step: 13
Training loss: 3.4182393866068526
Validation loss: 2.459153809266136

Epoch: 80| Step: 0
Training loss: 3.378190969269428
Validation loss: 2.4669377155041303

Epoch: 6| Step: 1
Training loss: 2.6529272502266465
Validation loss: 2.449145391784295

Epoch: 6| Step: 2
Training loss: 2.7075382434965416
Validation loss: 2.4647161847513597

Epoch: 6| Step: 3
Training loss: 2.8654933154551188
Validation loss: 2.473072693896413

Epoch: 6| Step: 4
Training loss: 2.2138232482130578
Validation loss: 2.460025625833238

Epoch: 6| Step: 5
Training loss: 2.394546384281292
Validation loss: 2.4755904297952656

Epoch: 6| Step: 6
Training loss: 1.6797740825250145
Validation loss: 2.46901539873545

Epoch: 6| Step: 7
Training loss: 2.327087785744456
Validation loss: 2.4628055330079293

Epoch: 6| Step: 8
Training loss: 3.3582844228156685
Validation loss: 2.4655718020932444

Epoch: 6| Step: 9
Training loss: 2.1532135744520535
Validation loss: 2.463173159416207

Epoch: 6| Step: 10
Training loss: 2.798895250089163
Validation loss: 2.463894756292102

Epoch: 6| Step: 11
Training loss: 2.918232161596231
Validation loss: 2.4717633616285672

Epoch: 6| Step: 12
Training loss: 2.9450633300293054
Validation loss: 2.470818231785472

Epoch: 6| Step: 13
Training loss: 3.0802504274194455
Validation loss: 2.4689723784755375

Epoch: 81| Step: 0
Training loss: 2.8267194089677368
Validation loss: 2.4600656772853244

Epoch: 6| Step: 1
Training loss: 2.8131850362023108
Validation loss: 2.4633653994763893

Epoch: 6| Step: 2
Training loss: 2.313906061730296
Validation loss: 2.476093315984167

Epoch: 6| Step: 3
Training loss: 2.5071931353423325
Validation loss: 2.4612685176741658

Epoch: 6| Step: 4
Training loss: 3.0358367510544326
Validation loss: 2.465831658398056

Epoch: 6| Step: 5
Training loss: 2.457725729990021
Validation loss: 2.4597213195858543

Epoch: 6| Step: 6
Training loss: 3.2260407771863853
Validation loss: 2.4591629654294063

Epoch: 6| Step: 7
Training loss: 3.8038444446643846
Validation loss: 2.4682271519781893

Epoch: 6| Step: 8
Training loss: 2.809437334601796
Validation loss: 2.461550484767988

Epoch: 6| Step: 9
Training loss: 2.096898231434507
Validation loss: 2.4686600713003912

Epoch: 6| Step: 10
Training loss: 2.0131728759302683
Validation loss: 2.4676400853349865

Epoch: 6| Step: 11
Training loss: 2.3730574242628175
Validation loss: 2.46349828163699

Epoch: 6| Step: 12
Training loss: 2.3242916833029037
Validation loss: 2.462514274975969

Epoch: 6| Step: 13
Training loss: 2.8711635036169487
Validation loss: 2.4572890804533305

Epoch: 82| Step: 0
Training loss: 2.844897698840877
Validation loss: 2.4462014337654967

Epoch: 6| Step: 1
Training loss: 2.4588805306272414
Validation loss: 2.4633799110465104

Epoch: 6| Step: 2
Training loss: 2.435976285790833
Validation loss: 2.483442392932431

Epoch: 6| Step: 3
Training loss: 2.4830852495569666
Validation loss: 2.454031465438937

Epoch: 6| Step: 4
Training loss: 3.024457892401168
Validation loss: 2.4522685775507527

Epoch: 6| Step: 5
Training loss: 2.587431784205149
Validation loss: 2.457090649446886

Epoch: 6| Step: 6
Training loss: 2.4105307413295978
Validation loss: 2.4700208212177626

Epoch: 6| Step: 7
Training loss: 2.8815296492500013
Validation loss: 2.463209577874163

Epoch: 6| Step: 8
Training loss: 2.9852570034296675
Validation loss: 2.471510517585131

Epoch: 6| Step: 9
Training loss: 2.3361189653725973
Validation loss: 2.4741737887608815

Epoch: 6| Step: 10
Training loss: 3.167863837032461
Validation loss: 2.455920649966117

Epoch: 6| Step: 11
Training loss: 2.631743533860231
Validation loss: 2.4643483620089164

Epoch: 6| Step: 12
Training loss: 2.6820682370852067
Validation loss: 2.471041601147023

Epoch: 6| Step: 13
Training loss: 2.506665118839246
Validation loss: 2.4647557595374634

Epoch: 83| Step: 0
Training loss: 3.0121528520440575
Validation loss: 2.455631938526733

Epoch: 6| Step: 1
Training loss: 2.249634607103677
Validation loss: 2.4529383865125287

Epoch: 6| Step: 2
Training loss: 2.9272646231299495
Validation loss: 2.4703042664896957

Epoch: 6| Step: 3
Training loss: 2.336847746721515
Validation loss: 2.454924657517783

Epoch: 6| Step: 4
Training loss: 2.389098633816631
Validation loss: 2.463109819897552

Epoch: 6| Step: 5
Training loss: 2.7479104860210732
Validation loss: 2.459330216043927

Epoch: 6| Step: 6
Training loss: 1.9807166070478892
Validation loss: 2.4680023037237286

Epoch: 6| Step: 7
Training loss: 3.045173991827549
Validation loss: 2.4698170476537373

Epoch: 6| Step: 8
Training loss: 2.5570691873665625
Validation loss: 2.4659481179616907

Epoch: 6| Step: 9
Training loss: 1.8075355416545706
Validation loss: 2.460430577850533

Epoch: 6| Step: 10
Training loss: 2.587011569451059
Validation loss: 2.473943066552578

Epoch: 6| Step: 11
Training loss: 2.903201565590019
Validation loss: 2.46624652497464

Epoch: 6| Step: 12
Training loss: 3.5291420375380422
Validation loss: 2.4789164437471842

Epoch: 6| Step: 13
Training loss: 3.112211074594258
Validation loss: 2.4482007132638217

Epoch: 84| Step: 0
Training loss: 2.6132507778609235
Validation loss: 2.4605256725197866

Epoch: 6| Step: 1
Training loss: 2.0788880288272784
Validation loss: 2.4580528456609216

Epoch: 6| Step: 2
Training loss: 2.2594755706985947
Validation loss: 2.469666060407598

Epoch: 6| Step: 3
Training loss: 2.9091165823237097
Validation loss: 2.45453423415529

Epoch: 6| Step: 4
Training loss: 2.349324222552805
Validation loss: 2.472659182057951

Epoch: 6| Step: 5
Training loss: 3.127546112428044
Validation loss: 2.458759004215533

Epoch: 6| Step: 6
Training loss: 3.0742330199398795
Validation loss: 2.4864293620380393

Epoch: 6| Step: 7
Training loss: 2.3792242329364504
Validation loss: 2.4731065860082166

Epoch: 6| Step: 8
Training loss: 2.3652081665300644
Validation loss: 2.4585597252264115

Epoch: 6| Step: 9
Training loss: 2.7817765498261795
Validation loss: 2.454199358245017

Epoch: 6| Step: 10
Training loss: 3.1705217152351035
Validation loss: 2.4561274270623534

Epoch: 6| Step: 11
Training loss: 2.499056828921601
Validation loss: 2.4650002566327904

Epoch: 6| Step: 12
Training loss: 2.9058347015625605
Validation loss: 2.468161240022108

Epoch: 6| Step: 13
Training loss: 3.0042011726362374
Validation loss: 2.466447784015802

Epoch: 85| Step: 0
Training loss: 2.8418858045578577
Validation loss: 2.459455057606886

Epoch: 6| Step: 1
Training loss: 3.0576737970346453
Validation loss: 2.467300713425588

Epoch: 6| Step: 2
Training loss: 2.554313702315682
Validation loss: 2.4661934448834195

Epoch: 6| Step: 3
Training loss: 2.717194561677677
Validation loss: 2.4603798740561786

Epoch: 6| Step: 4
Training loss: 3.3801449307851863
Validation loss: 2.4725254614379715

Epoch: 6| Step: 5
Training loss: 2.482099726773665
Validation loss: 2.483161430192932

Epoch: 6| Step: 6
Training loss: 2.98010171652659
Validation loss: 2.479447423793896

Epoch: 6| Step: 7
Training loss: 2.1979588750128056
Validation loss: 2.4602378682791066

Epoch: 6| Step: 8
Training loss: 2.3080270139346295
Validation loss: 2.455582776824579

Epoch: 6| Step: 9
Training loss: 2.3755288790049622
Validation loss: 2.4823453473845603

Epoch: 6| Step: 10
Training loss: 2.499899385334957
Validation loss: 2.4560784861245177

Epoch: 6| Step: 11
Training loss: 2.7354565906347017
Validation loss: 2.4634813205369768

Epoch: 6| Step: 12
Training loss: 2.2845290146452735
Validation loss: 2.4602890215004733

Epoch: 6| Step: 13
Training loss: 3.1793457147484228
Validation loss: 2.4715490749393036

Epoch: 86| Step: 0
Training loss: 3.3717425132086256
Validation loss: 2.4687757967100485

Epoch: 6| Step: 1
Training loss: 2.7097916613798
Validation loss: 2.4592371110610607

Epoch: 6| Step: 2
Training loss: 2.349344925176721
Validation loss: 2.46492371439915

Epoch: 6| Step: 3
Training loss: 2.651267191369391
Validation loss: 2.4624028762795627

Epoch: 6| Step: 4
Training loss: 2.4011161831251986
Validation loss: 2.4647903359889236

Epoch: 6| Step: 5
Training loss: 2.2511252662378505
Validation loss: 2.466990839853807

Epoch: 6| Step: 6
Training loss: 2.668675788365725
Validation loss: 2.4576138993512546

Epoch: 6| Step: 7
Training loss: 3.3216165293118727
Validation loss: 2.459893918204991

Epoch: 6| Step: 8
Training loss: 2.8861896200295143
Validation loss: 2.4572259523325055

Epoch: 6| Step: 9
Training loss: 2.7316325358441915
Validation loss: 2.4510059577204526

Epoch: 6| Step: 10
Training loss: 2.904848150332347
Validation loss: 2.4584036923561974

Epoch: 6| Step: 11
Training loss: 2.383265217783602
Validation loss: 2.467160444369705

Epoch: 6| Step: 12
Training loss: 2.0955405478863187
Validation loss: 2.4573525199283766

Epoch: 6| Step: 13
Training loss: 2.6604797793922765
Validation loss: 2.4680670820024107

Epoch: 87| Step: 0
Training loss: 2.358414005836296
Validation loss: 2.437606757649801

Epoch: 6| Step: 1
Training loss: 2.751869779777211
Validation loss: 2.4594251083012497

Epoch: 6| Step: 2
Training loss: 2.874992204738498
Validation loss: 2.466372409298282

Epoch: 6| Step: 3
Training loss: 2.299239206952189
Validation loss: 2.450710627234815

Epoch: 6| Step: 4
Training loss: 2.5665374211389254
Validation loss: 2.4581224067040854

Epoch: 6| Step: 5
Training loss: 3.2550181747843236
Validation loss: 2.45528728788996

Epoch: 6| Step: 6
Training loss: 2.25479156190553
Validation loss: 2.4582191596849947

Epoch: 6| Step: 7
Training loss: 2.7195738497857485
Validation loss: 2.4713800994007946

Epoch: 6| Step: 8
Training loss: 1.950815773545009
Validation loss: 2.467590078233287

Epoch: 6| Step: 9
Training loss: 2.8857534237302396
Validation loss: 2.4456995579387284

Epoch: 6| Step: 10
Training loss: 2.6520535699373387
Validation loss: 2.464437352137878

Epoch: 6| Step: 11
Training loss: 3.2723952206826548
Validation loss: 2.471802927819878

Epoch: 6| Step: 12
Training loss: 2.949081963404863
Validation loss: 2.4513260700088852

Epoch: 6| Step: 13
Training loss: 2.3488636434772907
Validation loss: 2.4607086809684167

Epoch: 88| Step: 0
Training loss: 2.2689512893875183
Validation loss: 2.4526535476236857

Epoch: 6| Step: 1
Training loss: 2.927342323076864
Validation loss: 2.4628354927319793

Epoch: 6| Step: 2
Training loss: 2.788068920290668
Validation loss: 2.470845280502723

Epoch: 6| Step: 3
Training loss: 2.35855290319725
Validation loss: 2.4785622869738657

Epoch: 6| Step: 4
Training loss: 2.82103519215179
Validation loss: 2.4666484893066984

Epoch: 6| Step: 5
Training loss: 2.739005043484744
Validation loss: 2.478797571453469

Epoch: 6| Step: 6
Training loss: 2.678524020547492
Validation loss: 2.461813342916851

Epoch: 6| Step: 7
Training loss: 2.357503186382515
Validation loss: 2.4701500283888143

Epoch: 6| Step: 8
Training loss: 2.8083404299441663
Validation loss: 2.472492064758339

Epoch: 6| Step: 9
Training loss: 2.639945941718374
Validation loss: 2.453663175652389

Epoch: 6| Step: 10
Training loss: 2.2067625709314793
Validation loss: 2.459512852731761

Epoch: 6| Step: 11
Training loss: 3.3128597136185376
Validation loss: 2.4556878776882263

Epoch: 6| Step: 12
Training loss: 2.55105958503691
Validation loss: 2.4748001491933915

Epoch: 6| Step: 13
Training loss: 3.0900493027787626
Validation loss: 2.469413208214196

Epoch: 89| Step: 0
Training loss: 3.0200851741678605
Validation loss: 2.4618516428983503

Epoch: 6| Step: 1
Training loss: 2.8996107497912846
Validation loss: 2.4583001639448923

Epoch: 6| Step: 2
Training loss: 2.8506858000557775
Validation loss: 2.47048200540089

Epoch: 6| Step: 3
Training loss: 2.773887490315612
Validation loss: 2.4705590265709136

Epoch: 6| Step: 4
Training loss: 2.5646329237117405
Validation loss: 2.4579096926708814

Epoch: 6| Step: 5
Training loss: 2.018417907421311
Validation loss: 2.4652189675741627

Epoch: 6| Step: 6
Training loss: 2.6861426895881992
Validation loss: 2.465126714180403

Epoch: 6| Step: 7
Training loss: 2.3554572109869727
Validation loss: 2.461043308663931

Epoch: 6| Step: 8
Training loss: 2.3311178952338496
Validation loss: 2.4570832050314153

Epoch: 6| Step: 9
Training loss: 2.691181500134969
Validation loss: 2.4784080114622506

Epoch: 6| Step: 10
Training loss: 2.6146909734648855
Validation loss: 2.4768902785664957

Epoch: 6| Step: 11
Training loss: 3.072807560077515
Validation loss: 2.4757069273461294

Epoch: 6| Step: 12
Training loss: 2.7825858519163273
Validation loss: 2.4664477019027267

Epoch: 6| Step: 13
Training loss: 2.596720821059124
Validation loss: 2.4678050941013834

Epoch: 90| Step: 0
Training loss: 2.8232722510073494
Validation loss: 2.4775149422933764

Epoch: 6| Step: 1
Training loss: 2.816155241258015
Validation loss: 2.4660524412822915

Epoch: 6| Step: 2
Training loss: 2.7533088198379527
Validation loss: 2.472352095418746

Epoch: 6| Step: 3
Training loss: 3.0870835119875446
Validation loss: 2.4824232629719982

Epoch: 6| Step: 4
Training loss: 2.630288564131895
Validation loss: 2.452170570985118

Epoch: 6| Step: 5
Training loss: 2.860425078807296
Validation loss: 2.4705487426581945

Epoch: 6| Step: 6
Training loss: 2.6653326592011175
Validation loss: 2.486108828219108

Epoch: 6| Step: 7
Training loss: 1.9387836510930891
Validation loss: 2.465105716197528

Epoch: 6| Step: 8
Training loss: 2.5647861238362446
Validation loss: 2.464772762312996

Epoch: 6| Step: 9
Training loss: 2.240885180233742
Validation loss: 2.4764526556070687

Epoch: 6| Step: 10
Training loss: 2.4161065099177326
Validation loss: 2.4822421570520268

Epoch: 6| Step: 11
Training loss: 3.224695584619478
Validation loss: 2.4628495671133543

Epoch: 6| Step: 12
Training loss: 2.383487993392968
Validation loss: 2.461332304017282

Epoch: 6| Step: 13
Training loss: 2.992048056119653
Validation loss: 2.4648313625873324

Epoch: 91| Step: 0
Training loss: 2.762797316349947
Validation loss: 2.4790806523167745

Epoch: 6| Step: 1
Training loss: 3.2362202710981225
Validation loss: 2.480681412565559

Epoch: 6| Step: 2
Training loss: 2.7094155912427564
Validation loss: 2.465373233408972

Epoch: 6| Step: 3
Training loss: 2.800294714131431
Validation loss: 2.4710048473309265

Epoch: 6| Step: 4
Training loss: 1.934782398812749
Validation loss: 2.46931590391718

Epoch: 6| Step: 5
Training loss: 2.312055596617033
Validation loss: 2.474021584566319

Epoch: 6| Step: 6
Training loss: 2.668882512324869
Validation loss: 2.4686659503573884

Epoch: 6| Step: 7
Training loss: 2.881332389663102
Validation loss: 2.461751772617535

Epoch: 6| Step: 8
Training loss: 2.6676096639641456
Validation loss: 2.4703585300283706

Epoch: 6| Step: 9
Training loss: 2.4761492748465797
Validation loss: 2.4532952391646083

Epoch: 6| Step: 10
Training loss: 2.5350499770074144
Validation loss: 2.4539155832443362

Epoch: 6| Step: 11
Training loss: 2.3561448981929183
Validation loss: 2.468724142790432

Epoch: 6| Step: 12
Training loss: 3.00058581672484
Validation loss: 2.4566485195257983

Epoch: 6| Step: 13
Training loss: 3.1439669464062776
Validation loss: 2.468457378191316

Epoch: 92| Step: 0
Training loss: 2.2842904300925597
Validation loss: 2.4593673319623495

Epoch: 6| Step: 1
Training loss: 2.268638133083775
Validation loss: 2.4633634554356885

Epoch: 6| Step: 2
Training loss: 2.8195220600421287
Validation loss: 2.4669951015158267

Epoch: 6| Step: 3
Training loss: 2.315912152193966
Validation loss: 2.4673888957421948

Epoch: 6| Step: 4
Training loss: 2.4014769936642395
Validation loss: 2.440950774990026

Epoch: 6| Step: 5
Training loss: 1.9669486387884754
Validation loss: 2.454708146834507

Epoch: 6| Step: 6
Training loss: 2.7563004711832613
Validation loss: 2.445826198970461

Epoch: 6| Step: 7
Training loss: 3.2515938591899927
Validation loss: 2.4659129350052145

Epoch: 6| Step: 8
Training loss: 2.850557333007819
Validation loss: 2.4639335233436377

Epoch: 6| Step: 9
Training loss: 2.991928368246435
Validation loss: 2.459431120706775

Epoch: 6| Step: 10
Training loss: 3.6608109677403884
Validation loss: 2.458235249788248

Epoch: 6| Step: 11
Training loss: 2.1619852059675972
Validation loss: 2.45861273864195

Epoch: 6| Step: 12
Training loss: 2.4422803122858965
Validation loss: 2.459085725456293

Epoch: 6| Step: 13
Training loss: 2.914069863481397
Validation loss: 2.459521095516974

Epoch: 93| Step: 0
Training loss: 2.715847000161035
Validation loss: 2.4535820606204255

Epoch: 6| Step: 1
Training loss: 1.9001544362597407
Validation loss: 2.4595233407017862

Epoch: 6| Step: 2
Training loss: 2.6618815245484577
Validation loss: 2.4478313765441664

Epoch: 6| Step: 3
Training loss: 2.9904423098833113
Validation loss: 2.457183548325206

Epoch: 6| Step: 4
Training loss: 3.1526604815905275
Validation loss: 2.4707694007836243

Epoch: 6| Step: 5
Training loss: 2.1642384371524086
Validation loss: 2.454855556216516

Epoch: 6| Step: 6
Training loss: 2.7513026706726826
Validation loss: 2.4566982150595917

Epoch: 6| Step: 7
Training loss: 2.6984022923455
Validation loss: 2.4592374295306216

Epoch: 6| Step: 8
Training loss: 3.1601695283250084
Validation loss: 2.453032587538137

Epoch: 6| Step: 9
Training loss: 2.530690072377817
Validation loss: 2.4679767586192165

Epoch: 6| Step: 10
Training loss: 2.893631809531631
Validation loss: 2.458149107559545

Epoch: 6| Step: 11
Training loss: 2.5071324647494757
Validation loss: 2.4714763587852477

Epoch: 6| Step: 12
Training loss: 2.465880935981255
Validation loss: 2.462648428331054

Epoch: 6| Step: 13
Training loss: 2.0359958081155427
Validation loss: 2.465297279895083

Epoch: 94| Step: 0
Training loss: 2.7969490766039122
Validation loss: 2.443982593503594

Epoch: 6| Step: 1
Training loss: 2.173025800598308
Validation loss: 2.456845797209736

Epoch: 6| Step: 2
Training loss: 2.2484452916183293
Validation loss: 2.460370060768438

Epoch: 6| Step: 3
Training loss: 3.143763553901106
Validation loss: 2.4639965477638768

Epoch: 6| Step: 4
Training loss: 2.8148776706384915
Validation loss: 2.46543583940708

Epoch: 6| Step: 5
Training loss: 1.8590830084791188
Validation loss: 2.462283828330969

Epoch: 6| Step: 6
Training loss: 2.9630592816203465
Validation loss: 2.4558280973875073

Epoch: 6| Step: 7
Training loss: 2.7699545898571345
Validation loss: 2.461164289481888

Epoch: 6| Step: 8
Training loss: 3.4005337969302616
Validation loss: 2.463039267270174

Epoch: 6| Step: 9
Training loss: 2.5990595877473877
Validation loss: 2.4615387962784196

Epoch: 6| Step: 10
Training loss: 2.74467889794191
Validation loss: 2.470079072805283

Epoch: 6| Step: 11
Training loss: 2.30183383976318
Validation loss: 2.467156752424167

Epoch: 6| Step: 12
Training loss: 2.40189165032656
Validation loss: 2.45352244039647

Epoch: 6| Step: 13
Training loss: 2.7879055840036266
Validation loss: 2.466403230514439

Epoch: 95| Step: 0
Training loss: 2.949305087208938
Validation loss: 2.473230805775233

Epoch: 6| Step: 1
Training loss: 2.5215910306161056
Validation loss: 2.469498290010862

Epoch: 6| Step: 2
Training loss: 2.801413747962655
Validation loss: 2.459847355457098

Epoch: 6| Step: 3
Training loss: 2.359778363440208
Validation loss: 2.452726579589041

Epoch: 6| Step: 4
Training loss: 2.13052793559784
Validation loss: 2.453396468317663

Epoch: 6| Step: 5
Training loss: 3.157330016622004
Validation loss: 2.4647809958287525

Epoch: 6| Step: 6
Training loss: 2.5427469136271217
Validation loss: 2.4710439790355645

Epoch: 6| Step: 7
Training loss: 2.8629265080172104
Validation loss: 2.46794176039955

Epoch: 6| Step: 8
Training loss: 3.219848593475287
Validation loss: 2.459567351747307

Epoch: 6| Step: 9
Training loss: 2.3298545403979283
Validation loss: 2.458616830265378

Epoch: 6| Step: 10
Training loss: 2.6463775275363703
Validation loss: 2.4554296280030403

Epoch: 6| Step: 11
Training loss: 2.4418857927476867
Validation loss: 2.453392701322925

Epoch: 6| Step: 12
Training loss: 2.514073811772932
Validation loss: 2.4519212908776895

Epoch: 6| Step: 13
Training loss: 2.528294002886721
Validation loss: 2.457602997448513

Epoch: 96| Step: 0
Training loss: 1.9620182660970344
Validation loss: 2.465825537878393

Epoch: 6| Step: 1
Training loss: 2.5797735318880375
Validation loss: 2.457148875787792

Epoch: 6| Step: 2
Training loss: 2.219018409504795
Validation loss: 2.4733801927310384

Epoch: 6| Step: 3
Training loss: 2.783745663951688
Validation loss: 2.4432161302187887

Epoch: 6| Step: 4
Training loss: 2.7671804418317665
Validation loss: 2.463953812879823

Epoch: 6| Step: 5
Training loss: 2.527509869594906
Validation loss: 2.4482315559129697

Epoch: 6| Step: 6
Training loss: 2.902482574962583
Validation loss: 2.4647083140278325

Epoch: 6| Step: 7
Training loss: 2.961043464153548
Validation loss: 2.463188232579765

Epoch: 6| Step: 8
Training loss: 2.523833725000075
Validation loss: 2.4600044462267348

Epoch: 6| Step: 9
Training loss: 2.329495941617091
Validation loss: 2.4422327534546646

Epoch: 6| Step: 10
Training loss: 3.0750230369635356
Validation loss: 2.4664993390541956

Epoch: 6| Step: 11
Training loss: 3.2241281558139567
Validation loss: 2.4701744187377557

Epoch: 6| Step: 12
Training loss: 2.536913058795946
Validation loss: 2.4651083930837037

Epoch: 6| Step: 13
Training loss: 2.395554689429997
Validation loss: 2.4631431975544644

Epoch: 97| Step: 0
Training loss: 2.759750074597909
Validation loss: 2.453536579694546

Epoch: 6| Step: 1
Training loss: 2.387983271235109
Validation loss: 2.4536820753601063

Epoch: 6| Step: 2
Training loss: 3.0160686581636096
Validation loss: 2.4488967961542865

Epoch: 6| Step: 3
Training loss: 2.561527160572018
Validation loss: 2.453195408252949

Epoch: 6| Step: 4
Training loss: 2.5204073543400725
Validation loss: 2.452719361284144

Epoch: 6| Step: 5
Training loss: 3.2176662953994786
Validation loss: 2.4742594072767226

Epoch: 6| Step: 6
Training loss: 3.097789862542439
Validation loss: 2.448846694193081

Epoch: 6| Step: 7
Training loss: 2.0389412445613027
Validation loss: 2.4639094416255594

Epoch: 6| Step: 8
Training loss: 2.513283344584533
Validation loss: 2.4583533967375897

Epoch: 6| Step: 9
Training loss: 3.2525375436760853
Validation loss: 2.463578979636968

Epoch: 6| Step: 10
Training loss: 2.37270605834491
Validation loss: 2.4747702447079614

Epoch: 6| Step: 11
Training loss: 2.1761880764814356
Validation loss: 2.4651611533553828

Epoch: 6| Step: 12
Training loss: 2.2897162952176955
Validation loss: 2.451272691928912

Epoch: 6| Step: 13
Training loss: 2.8959474792670776
Validation loss: 2.462419992124406

Epoch: 98| Step: 0
Training loss: 2.6885571729254005
Validation loss: 2.464097904306248

Epoch: 6| Step: 1
Training loss: 2.436880668795954
Validation loss: 2.4472523713225818

Epoch: 6| Step: 2
Training loss: 2.419459067017137
Validation loss: 2.4419716551690414

Epoch: 6| Step: 3
Training loss: 2.820095318069378
Validation loss: 2.4651534109266664

Epoch: 6| Step: 4
Training loss: 2.516240299393763
Validation loss: 2.4722726844478884

Epoch: 6| Step: 5
Training loss: 2.8061378575540696
Validation loss: 2.451555548314357

Epoch: 6| Step: 6
Training loss: 2.2222151226354145
Validation loss: 2.4610214289403682

Epoch: 6| Step: 7
Training loss: 2.8478042710586284
Validation loss: 2.4481303482855727

Epoch: 6| Step: 8
Training loss: 3.056951985938925
Validation loss: 2.4596441628103944

Epoch: 6| Step: 9
Training loss: 2.44791943705517
Validation loss: 2.4557758944910724

Epoch: 6| Step: 10
Training loss: 3.466900031475824
Validation loss: 2.4547174146181674

Epoch: 6| Step: 11
Training loss: 2.3109903305029693
Validation loss: 2.459913838262657

Epoch: 6| Step: 12
Training loss: 2.2277125550655827
Validation loss: 2.4646337796199838

Epoch: 6| Step: 13
Training loss: 2.5305913374327833
Validation loss: 2.457164885781236

Epoch: 99| Step: 0
Training loss: 2.2464618414417172
Validation loss: 2.4592115030544908

Epoch: 6| Step: 1
Training loss: 2.8486015101018416
Validation loss: 2.457342679945431

Epoch: 6| Step: 2
Training loss: 2.9799836290153037
Validation loss: 2.4569458846475754

Epoch: 6| Step: 3
Training loss: 2.0839459345095745
Validation loss: 2.4614128293108264

Epoch: 6| Step: 4
Training loss: 2.688468935865953
Validation loss: 2.450009202050446

Epoch: 6| Step: 5
Training loss: 2.564681915280841
Validation loss: 2.4474741147981796

Epoch: 6| Step: 6
Training loss: 2.640607483935526
Validation loss: 2.4571999884613946

Epoch: 6| Step: 7
Training loss: 2.586968530446544
Validation loss: 2.468588719279687

Epoch: 6| Step: 8
Training loss: 2.261955499199506
Validation loss: 2.4639661136646835

Epoch: 6| Step: 9
Training loss: 3.3552508921836997
Validation loss: 2.4680974826713173

Epoch: 6| Step: 10
Training loss: 2.7961165609225995
Validation loss: 2.4504268646051743

Epoch: 6| Step: 11
Training loss: 2.617069708607452
Validation loss: 2.4618114965800584

Epoch: 6| Step: 12
Training loss: 2.2212580085743117
Validation loss: 2.4587971969415365

Epoch: 6| Step: 13
Training loss: 3.0701721003999465
Validation loss: 2.4570840063374852

Epoch: 100| Step: 0
Training loss: 3.0828022542436178
Validation loss: 2.453210381267657

Epoch: 6| Step: 1
Training loss: 2.48553689142021
Validation loss: 2.4769211696971762

Epoch: 6| Step: 2
Training loss: 1.9423891338784456
Validation loss: 2.466083612670759

Epoch: 6| Step: 3
Training loss: 1.9455906925675224
Validation loss: 2.459185116052063

Epoch: 6| Step: 4
Training loss: 1.5859500527472359
Validation loss: 2.4630066168056888

Epoch: 6| Step: 5
Training loss: 2.9731954920112167
Validation loss: 2.449879476794345

Epoch: 6| Step: 6
Training loss: 2.62292289298856
Validation loss: 2.4502495416559613

Epoch: 6| Step: 7
Training loss: 2.5338394671670765
Validation loss: 2.4603390285151505

Epoch: 6| Step: 8
Training loss: 3.3019376094845754
Validation loss: 2.4481461507505755

Epoch: 6| Step: 9
Training loss: 2.840830551448977
Validation loss: 2.4699736782011787

Epoch: 6| Step: 10
Training loss: 2.5892057021232815
Validation loss: 2.4615533498610773

Epoch: 6| Step: 11
Training loss: 2.9835787205144007
Validation loss: 2.4499078936295398

Epoch: 6| Step: 12
Training loss: 2.8889878044148296
Validation loss: 2.4648192268148703

Epoch: 6| Step: 13
Training loss: 2.903504418092693
Validation loss: 2.473417826459957

Epoch: 101| Step: 0
Training loss: 2.671178805125905
Validation loss: 2.46601403397219

Epoch: 6| Step: 1
Training loss: 2.9944560960375077
Validation loss: 2.4541379385139215

Epoch: 6| Step: 2
Training loss: 2.851344771760562
Validation loss: 2.4598434368007447

Epoch: 6| Step: 3
Training loss: 3.200419553432513
Validation loss: 2.4696432605385237

Epoch: 6| Step: 4
Training loss: 2.446382038839407
Validation loss: 2.4731374290330397

Epoch: 6| Step: 5
Training loss: 3.010567807602068
Validation loss: 2.463616184513409

Epoch: 6| Step: 6
Training loss: 1.966671952008834
Validation loss: 2.443044382799159

Epoch: 6| Step: 7
Training loss: 2.482184734167647
Validation loss: 2.461584917737939

Epoch: 6| Step: 8
Training loss: 2.5571353862010935
Validation loss: 2.4555792520002524

Epoch: 6| Step: 9
Training loss: 2.470118662342902
Validation loss: 2.4518970692223996

Epoch: 6| Step: 10
Training loss: 2.9142930499553517
Validation loss: 2.446630391222526

Epoch: 6| Step: 11
Training loss: 2.4915079846668546
Validation loss: 2.4584734462925817

Epoch: 6| Step: 12
Training loss: 2.3280344695852655
Validation loss: 2.4774973098702033

Epoch: 6| Step: 13
Training loss: 2.2114096632740896
Validation loss: 2.454322189962473

Epoch: 102| Step: 0
Training loss: 2.0040233198625046
Validation loss: 2.4778048079643673

Epoch: 6| Step: 1
Training loss: 2.4981119655930475
Validation loss: 2.4601078487285424

Epoch: 6| Step: 2
Training loss: 2.426076677549397
Validation loss: 2.441948973614553

Epoch: 6| Step: 3
Training loss: 2.592407614552587
Validation loss: 2.459179230227423

Epoch: 6| Step: 4
Training loss: 2.552860645069474
Validation loss: 2.4480670248304115

Epoch: 6| Step: 5
Training loss: 2.6410337955575924
Validation loss: 2.4529809318370797

Epoch: 6| Step: 6
Training loss: 2.2571809406758234
Validation loss: 2.4376911375517185

Epoch: 6| Step: 7
Training loss: 3.124150122470419
Validation loss: 2.457724962272216

Epoch: 6| Step: 8
Training loss: 3.0136272553202046
Validation loss: 2.460446350808281

Epoch: 6| Step: 9
Training loss: 2.487508465163046
Validation loss: 2.463614072093157

Epoch: 6| Step: 10
Training loss: 2.861159804669506
Validation loss: 2.471368267568414

Epoch: 6| Step: 11
Training loss: 2.5723595163969404
Validation loss: 2.4499334597095372

Epoch: 6| Step: 12
Training loss: 3.3172606321333067
Validation loss: 2.4707806658506595

Epoch: 6| Step: 13
Training loss: 2.321073054244185
Validation loss: 2.4762299286117306

Epoch: 103| Step: 0
Training loss: 2.253295709965532
Validation loss: 2.446246562180277

Epoch: 6| Step: 1
Training loss: 2.4168363270453534
Validation loss: 2.4552566957163715

Epoch: 6| Step: 2
Training loss: 2.4732391489952117
Validation loss: 2.477134426601528

Epoch: 6| Step: 3
Training loss: 2.800203101421432
Validation loss: 2.456725558549047

Epoch: 6| Step: 4
Training loss: 2.3558723774460866
Validation loss: 2.461932378211378

Epoch: 6| Step: 5
Training loss: 2.5120957538067583
Validation loss: 2.457719233587764

Epoch: 6| Step: 6
Training loss: 3.099897038380399
Validation loss: 2.442867696193596

Epoch: 6| Step: 7
Training loss: 3.3757242909070957
Validation loss: 2.458001427398913

Epoch: 6| Step: 8
Training loss: 2.702244080345664
Validation loss: 2.449938280526503

Epoch: 6| Step: 9
Training loss: 2.5397059168241145
Validation loss: 2.45872356407152

Epoch: 6| Step: 10
Training loss: 2.91764713338023
Validation loss: 2.45592241722274

Epoch: 6| Step: 11
Training loss: 1.8930410915253506
Validation loss: 2.4514278918604955

Epoch: 6| Step: 12
Training loss: 2.4796368022271875
Validation loss: 2.458694894091394

Epoch: 6| Step: 13
Training loss: 3.3209146110770362
Validation loss: 2.458138296678633

Epoch: 104| Step: 0
Training loss: 2.9875937475075967
Validation loss: 2.447498887192636

Epoch: 6| Step: 1
Training loss: 2.939579653630611
Validation loss: 2.4495464428318434

Epoch: 6| Step: 2
Training loss: 3.0433440264722544
Validation loss: 2.4507613061735323

Epoch: 6| Step: 3
Training loss: 2.5094094584036175
Validation loss: 2.457377699756205

Epoch: 6| Step: 4
Training loss: 1.701915766647667
Validation loss: 2.4687188591634417

Epoch: 6| Step: 5
Training loss: 2.634426448586617
Validation loss: 2.4524466765045823

Epoch: 6| Step: 6
Training loss: 2.3571031761132173
Validation loss: 2.4431171094005975

Epoch: 6| Step: 7
Training loss: 2.393048024646936
Validation loss: 2.4708572424582433

Epoch: 6| Step: 8
Training loss: 2.6007260189225025
Validation loss: 2.4633594674416126

Epoch: 6| Step: 9
Training loss: 2.7462243256651484
Validation loss: 2.4690040404711673

Epoch: 6| Step: 10
Training loss: 2.4327561604095758
Validation loss: 2.479091025446584

Epoch: 6| Step: 11
Training loss: 3.1639145051229716
Validation loss: 2.4383548260996486

Epoch: 6| Step: 12
Training loss: 2.3670051932557947
Validation loss: 2.453877671837573

Epoch: 6| Step: 13
Training loss: 2.881354730982354
Validation loss: 2.456379821481086

Epoch: 105| Step: 0
Training loss: 2.9115876434671892
Validation loss: 2.46562898907099

Epoch: 6| Step: 1
Training loss: 2.773000591411452
Validation loss: 2.4698500533779124

Epoch: 6| Step: 2
Training loss: 2.9277669486179945
Validation loss: 2.4476466249655373

Epoch: 6| Step: 3
Training loss: 2.7012569609927013
Validation loss: 2.4649090803508713

Epoch: 6| Step: 4
Training loss: 2.3223854335618506
Validation loss: 2.454721016658065

Epoch: 6| Step: 5
Training loss: 2.226543868137505
Validation loss: 2.4489180179133507

Epoch: 6| Step: 6
Training loss: 2.786970192548979
Validation loss: 2.44749437371247

Epoch: 6| Step: 7
Training loss: 2.3393698898695816
Validation loss: 2.4707314040195723

Epoch: 6| Step: 8
Training loss: 2.7785515714111653
Validation loss: 2.457490577035831

Epoch: 6| Step: 9
Training loss: 2.504778872112497
Validation loss: 2.4485939818593976

Epoch: 6| Step: 10
Training loss: 2.384866398362204
Validation loss: 2.448195713103308

Epoch: 6| Step: 11
Training loss: 2.4037960469819066
Validation loss: 2.459783543113421

Epoch: 6| Step: 12
Training loss: 2.9109783470740194
Validation loss: 2.4647353096622826

Epoch: 6| Step: 13
Training loss: 3.0412117779043215
Validation loss: 2.4591140317366276

Epoch: 106| Step: 0
Training loss: 3.027762855314138
Validation loss: 2.4556796084648256

Epoch: 6| Step: 1
Training loss: 2.8435937188770675
Validation loss: 2.450311052576479

Epoch: 6| Step: 2
Training loss: 2.374008071956393
Validation loss: 2.467398729948023

Epoch: 6| Step: 3
Training loss: 2.3655764696996338
Validation loss: 2.441475234765465

Epoch: 6| Step: 4
Training loss: 2.9003103945132294
Validation loss: 2.4589796970253897

Epoch: 6| Step: 5
Training loss: 2.436975471595419
Validation loss: 2.4508210458682584

Epoch: 6| Step: 6
Training loss: 2.3754157656101547
Validation loss: 2.4573601700914542

Epoch: 6| Step: 7
Training loss: 2.992174273030899
Validation loss: 2.4611435201872367

Epoch: 6| Step: 8
Training loss: 2.618438512808985
Validation loss: 2.4651777872754677

Epoch: 6| Step: 9
Training loss: 3.07796822550474
Validation loss: 2.449548505635584

Epoch: 6| Step: 10
Training loss: 2.231268584016401
Validation loss: 2.448449764881549

Epoch: 6| Step: 11
Training loss: 2.5714749661302023
Validation loss: 2.4569155103358478

Epoch: 6| Step: 12
Training loss: 2.684593936043295
Validation loss: 2.4538538711962277

Epoch: 6| Step: 13
Training loss: 1.66529113114431
Validation loss: 2.46216300872658

Epoch: 107| Step: 0
Training loss: 2.5601159147007584
Validation loss: 2.4579251824617487

Epoch: 6| Step: 1
Training loss: 2.508679296602478
Validation loss: 2.4657889111319666

Epoch: 6| Step: 2
Training loss: 2.346554921516823
Validation loss: 2.4628786170650288

Epoch: 6| Step: 3
Training loss: 3.444937964601983
Validation loss: 2.4596127732723474

Epoch: 6| Step: 4
Training loss: 2.4702063019501703
Validation loss: 2.4609300146137185

Epoch: 6| Step: 5
Training loss: 2.0793428222808283
Validation loss: 2.448441918302876

Epoch: 6| Step: 6
Training loss: 2.1649087841737638
Validation loss: 2.453481546521585

Epoch: 6| Step: 7
Training loss: 2.5754356460188768
Validation loss: 2.461855603135972

Epoch: 6| Step: 8
Training loss: 3.3261629867210956
Validation loss: 2.4449745806250434

Epoch: 6| Step: 9
Training loss: 3.0031370609291335
Validation loss: 2.4608397220082083

Epoch: 6| Step: 10
Training loss: 2.8314863430517674
Validation loss: 2.4609957197041044

Epoch: 6| Step: 11
Training loss: 1.8318560746307613
Validation loss: 2.4558614195152373

Epoch: 6| Step: 12
Training loss: 2.865295950365112
Validation loss: 2.4521950769141743

Epoch: 6| Step: 13
Training loss: 2.2936927393280664
Validation loss: 2.4662909492939327

Epoch: 108| Step: 0
Training loss: 1.9848357138883583
Validation loss: 2.4710824668975553

Epoch: 6| Step: 1
Training loss: 3.1925710095758375
Validation loss: 2.4710032547846197

Epoch: 6| Step: 2
Training loss: 2.298175988273612
Validation loss: 2.4602560276615995

Epoch: 6| Step: 3
Training loss: 2.297615814112589
Validation loss: 2.4415734128759765

Epoch: 6| Step: 4
Training loss: 2.585072168047475
Validation loss: 2.4676850050481836

Epoch: 6| Step: 5
Training loss: 2.37192275812169
Validation loss: 2.4555262088514556

Epoch: 6| Step: 6
Training loss: 2.5052121189482723
Validation loss: 2.467023254695277

Epoch: 6| Step: 7
Training loss: 2.6048660153072434
Validation loss: 2.4592670053219026

Epoch: 6| Step: 8
Training loss: 2.4605214569576357
Validation loss: 2.4520034645578153

Epoch: 6| Step: 9
Training loss: 3.4933146251536664
Validation loss: 2.4744873037485986

Epoch: 6| Step: 10
Training loss: 3.2570508620050727
Validation loss: 2.462158253493865

Epoch: 6| Step: 11
Training loss: 2.1709895902056395
Validation loss: 2.4625266927835368

Epoch: 6| Step: 12
Training loss: 2.8726375659109884
Validation loss: 2.476887719986094

Epoch: 6| Step: 13
Training loss: 2.2660975522475835
Validation loss: 2.4473950897078725

Epoch: 109| Step: 0
Training loss: 2.2486926625243218
Validation loss: 2.4483872323749045

Epoch: 6| Step: 1
Training loss: 2.2923127621863943
Validation loss: 2.459936085297626

Epoch: 6| Step: 2
Training loss: 2.4337941878607454
Validation loss: 2.44821651684536

Epoch: 6| Step: 3
Training loss: 3.151607309229974
Validation loss: 2.4684016068992687

Epoch: 6| Step: 4
Training loss: 3.1985828480309486
Validation loss: 2.445790129092681

Epoch: 6| Step: 5
Training loss: 2.794967597678068
Validation loss: 2.461184395083793

Epoch: 6| Step: 6
Training loss: 2.8014543434792283
Validation loss: 2.462203675118313

Epoch: 6| Step: 7
Training loss: 2.5608062729138688
Validation loss: 2.4568385649205062

Epoch: 6| Step: 8
Training loss: 2.520957082017661
Validation loss: 2.477074087850789

Epoch: 6| Step: 9
Training loss: 2.489169694276937
Validation loss: 2.4580900528298586

Epoch: 6| Step: 10
Training loss: 1.9318432831790886
Validation loss: 2.449133751907093

Epoch: 6| Step: 11
Training loss: 3.0370745199969407
Validation loss: 2.452595664290779

Epoch: 6| Step: 12
Training loss: 2.5933263041965704
Validation loss: 2.4523757460230864

Epoch: 6| Step: 13
Training loss: 2.5645643153493882
Validation loss: 2.456103012035881

Epoch: 110| Step: 0
Training loss: 2.633663685112531
Validation loss: 2.4390287009799367

Epoch: 6| Step: 1
Training loss: 3.177813453370318
Validation loss: 2.4564121483076047

Epoch: 6| Step: 2
Training loss: 2.373368355281901
Validation loss: 2.4710613545670292

Epoch: 6| Step: 3
Training loss: 2.7961629461960347
Validation loss: 2.4498437166960794

Epoch: 6| Step: 4
Training loss: 2.819979745778604
Validation loss: 2.4507421313161566

Epoch: 6| Step: 5
Training loss: 2.3840336906561523
Validation loss: 2.4560045969047146

Epoch: 6| Step: 6
Training loss: 2.434694191374242
Validation loss: 2.4640577529692016

Epoch: 6| Step: 7
Training loss: 2.274956159902863
Validation loss: 2.452092586963411

Epoch: 6| Step: 8
Training loss: 2.9419282042289696
Validation loss: 2.4581271113403593

Epoch: 6| Step: 9
Training loss: 2.855301086262689
Validation loss: 2.461297718567264

Epoch: 6| Step: 10
Training loss: 1.9507683536223948
Validation loss: 2.4585227504008946

Epoch: 6| Step: 11
Training loss: 2.665409497117281
Validation loss: 2.4630812873615495

Epoch: 6| Step: 12
Training loss: 3.0014587670372235
Validation loss: 2.4573760994218263

Epoch: 6| Step: 13
Training loss: 2.100051847453631
Validation loss: 2.4539751469057416

Epoch: 111| Step: 0
Training loss: 2.0352380190657033
Validation loss: 2.445877696048275

Epoch: 6| Step: 1
Training loss: 2.591297506880489
Validation loss: 2.4545982759192984

Epoch: 6| Step: 2
Training loss: 2.4942966254071663
Validation loss: 2.454327033495219

Epoch: 6| Step: 3
Training loss: 2.7097365827737687
Validation loss: 2.454093344341894

Epoch: 6| Step: 4
Training loss: 2.7158811494500696
Validation loss: 2.47325394676527

Epoch: 6| Step: 5
Training loss: 2.6971530987513943
Validation loss: 2.458204284445455

Epoch: 6| Step: 6
Training loss: 3.6890521904471307
Validation loss: 2.452628087508514

Epoch: 6| Step: 7
Training loss: 2.683860265832346
Validation loss: 2.4394437445777757

Epoch: 6| Step: 8
Training loss: 2.569564756950315
Validation loss: 2.4502633169050347

Epoch: 6| Step: 9
Training loss: 2.4044158682982877
Validation loss: 2.460378437179904

Epoch: 6| Step: 10
Training loss: 1.6069515462572084
Validation loss: 2.4468861110905773

Epoch: 6| Step: 11
Training loss: 2.598870428174788
Validation loss: 2.467182217695781

Epoch: 6| Step: 12
Training loss: 2.6067277648802825
Validation loss: 2.4444833819124336

Epoch: 6| Step: 13
Training loss: 2.974715333029538
Validation loss: 2.4505065514431656

Epoch: 112| Step: 0
Training loss: 2.3211097246799657
Validation loss: 2.472088878011704

Epoch: 6| Step: 1
Training loss: 2.3270334846897214
Validation loss: 2.449655806711563

Epoch: 6| Step: 2
Training loss: 2.5029685515661986
Validation loss: 2.4609212166123284

Epoch: 6| Step: 3
Training loss: 2.3215135747416946
Validation loss: 2.4550989205447564

Epoch: 6| Step: 4
Training loss: 3.411189007016374
Validation loss: 2.4583285188984085

Epoch: 6| Step: 5
Training loss: 2.845387752235412
Validation loss: 2.4486320771513195

Epoch: 6| Step: 6
Training loss: 2.5526646996396964
Validation loss: 2.4568477234514083

Epoch: 6| Step: 7
Training loss: 2.6947291530755106
Validation loss: 2.4507081490688214

Epoch: 6| Step: 8
Training loss: 2.527643059248485
Validation loss: 2.444290526810758

Epoch: 6| Step: 9
Training loss: 2.502215929247432
Validation loss: 2.452663188223779

Epoch: 6| Step: 10
Training loss: 2.836823632379713
Validation loss: 2.464559563340371

Epoch: 6| Step: 11
Training loss: 2.772045377120465
Validation loss: 2.4482385874464474

Epoch: 6| Step: 12
Training loss: 2.5459107053729646
Validation loss: 2.4471816098011008

Epoch: 6| Step: 13
Training loss: 1.8511745513233384
Validation loss: 2.444460384915726

Epoch: 113| Step: 0
Training loss: 2.4091531653890748
Validation loss: 2.452593425307473

Epoch: 6| Step: 1
Training loss: 2.8963842805530424
Validation loss: 2.449703840441757

Epoch: 6| Step: 2
Training loss: 2.4369087480280873
Validation loss: 2.4682137875464214

Epoch: 6| Step: 3
Training loss: 3.029786690735409
Validation loss: 2.463034723459742

Epoch: 6| Step: 4
Training loss: 2.3386618761008484
Validation loss: 2.451474866552583

Epoch: 6| Step: 5
Training loss: 3.106096849561356
Validation loss: 2.4383279200526826

Epoch: 6| Step: 6
Training loss: 2.930306412490261
Validation loss: 2.465020172865947

Epoch: 6| Step: 7
Training loss: 1.9830549159561557
Validation loss: 2.4463708621011775

Epoch: 6| Step: 8
Training loss: 2.372665161075884
Validation loss: 2.4491192093101177

Epoch: 6| Step: 9
Training loss: 2.4592678642930963
Validation loss: 2.454027968942889

Epoch: 6| Step: 10
Training loss: 1.9560754082620684
Validation loss: 2.4349308488920895

Epoch: 6| Step: 11
Training loss: 3.187682202685422
Validation loss: 2.4523776172351117

Epoch: 6| Step: 12
Training loss: 2.0389925773002817
Validation loss: 2.475251670464157

Epoch: 6| Step: 13
Training loss: 3.7277915735142657
Validation loss: 2.4579041594615365

Epoch: 114| Step: 0
Training loss: 2.357693508778325
Validation loss: 2.444986275952874

Epoch: 6| Step: 1
Training loss: 2.2732835435682035
Validation loss: 2.463087798244029

Epoch: 6| Step: 2
Training loss: 2.2290381872877285
Validation loss: 2.454186528514424

Epoch: 6| Step: 3
Training loss: 2.604086811112873
Validation loss: 2.452017384690894

Epoch: 6| Step: 4
Training loss: 3.0569092458843525
Validation loss: 2.44651027346778

Epoch: 6| Step: 5
Training loss: 2.4436098453692434
Validation loss: 2.44863260691732

Epoch: 6| Step: 6
Training loss: 2.3697019008081686
Validation loss: 2.4639619476878365

Epoch: 6| Step: 7
Training loss: 2.66920132182103
Validation loss: 2.462063899739612

Epoch: 6| Step: 8
Training loss: 2.2492930043277215
Validation loss: 2.430818845451272

Epoch: 6| Step: 9
Training loss: 2.9227420927858794
Validation loss: 2.4776823095450586

Epoch: 6| Step: 10
Training loss: 3.092654409909601
Validation loss: 2.4494572581377922

Epoch: 6| Step: 11
Training loss: 2.9161523274638204
Validation loss: 2.455618793688075

Epoch: 6| Step: 12
Training loss: 2.0849286901048356
Validation loss: 2.4555777175712583

Epoch: 6| Step: 13
Training loss: 3.318881383906616
Validation loss: 2.4526725588517984

Epoch: 115| Step: 0
Training loss: 1.7714146576172365
Validation loss: 2.4889823163051337

Epoch: 6| Step: 1
Training loss: 2.800996950321519
Validation loss: 2.443964117047598

Epoch: 6| Step: 2
Training loss: 1.9998077061717254
Validation loss: 2.450363202407636

Epoch: 6| Step: 3
Training loss: 3.027937662256479
Validation loss: 2.4619478031231687

Epoch: 6| Step: 4
Training loss: 3.280263407295249
Validation loss: 2.4435035178633417

Epoch: 6| Step: 5
Training loss: 2.0910410650919506
Validation loss: 2.455212914905757

Epoch: 6| Step: 6
Training loss: 2.590348368601284
Validation loss: 2.4494405682222875

Epoch: 6| Step: 7
Training loss: 2.5290291545087946
Validation loss: 2.4498133746705704

Epoch: 6| Step: 8
Training loss: 2.4354109003430042
Validation loss: 2.4750906580362537

Epoch: 6| Step: 9
Training loss: 1.8981947253059797
Validation loss: 2.4544344599050927

Epoch: 6| Step: 10
Training loss: 2.7648110781482997
Validation loss: 2.4612512698713678

Epoch: 6| Step: 11
Training loss: 2.913686774118965
Validation loss: 2.464575595926956

Epoch: 6| Step: 12
Training loss: 2.745151406926081
Validation loss: 2.473531431056159

Epoch: 6| Step: 13
Training loss: 3.677631946014538
Validation loss: 2.4561047227970003

Epoch: 116| Step: 0
Training loss: 1.8754386388777962
Validation loss: 2.4454630273652196

Epoch: 6| Step: 1
Training loss: 3.305745417665803
Validation loss: 2.4398105273185604

Epoch: 6| Step: 2
Training loss: 2.5898925408417837
Validation loss: 2.4601655253538457

Epoch: 6| Step: 3
Training loss: 2.8554343496773624
Validation loss: 2.45722062833195

Epoch: 6| Step: 4
Training loss: 2.3243705635818275
Validation loss: 2.447052850387488

Epoch: 6| Step: 5
Training loss: 2.3935088671154845
Validation loss: 2.459317606969953

Epoch: 6| Step: 6
Training loss: 2.3516074141461907
Validation loss: 2.4486383893162276

Epoch: 6| Step: 7
Training loss: 2.715651489409562
Validation loss: 2.4690528736801904

Epoch: 6| Step: 8
Training loss: 2.6191722119821153
Validation loss: 2.466998373357422

Epoch: 6| Step: 9
Training loss: 2.7208725985331856
Validation loss: 2.472508373555096

Epoch: 6| Step: 10
Training loss: 2.4522063849684392
Validation loss: 2.4783439715456734

Epoch: 6| Step: 11
Training loss: 2.7765066438551127
Validation loss: 2.4625124328084547

Epoch: 6| Step: 12
Training loss: 2.37345534839662
Validation loss: 2.4702790720948467

Epoch: 6| Step: 13
Training loss: 3.060382967651501
Validation loss: 2.468771472700971

Epoch: 117| Step: 0
Training loss: 2.8540842271765334
Validation loss: 2.467216453612773

Epoch: 6| Step: 1
Training loss: 2.837405998924788
Validation loss: 2.4613596960154296

Epoch: 6| Step: 2
Training loss: 3.0333609555282797
Validation loss: 2.4653929480176235

Epoch: 6| Step: 3
Training loss: 3.1059952199669465
Validation loss: 2.469910882068923

Epoch: 6| Step: 4
Training loss: 2.569198691727057
Validation loss: 2.4589089977438223

Epoch: 6| Step: 5
Training loss: 2.014275150599892
Validation loss: 2.4612851060321126

Epoch: 6| Step: 6
Training loss: 2.3108179315529958
Validation loss: 2.444700853712998

Epoch: 6| Step: 7
Training loss: 1.589970164229011
Validation loss: 2.4634692129760136

Epoch: 6| Step: 8
Training loss: 2.552213725177971
Validation loss: 2.434392717039417

Epoch: 6| Step: 9
Training loss: 2.7316921478566396
Validation loss: 2.44900568186611

Epoch: 6| Step: 10
Training loss: 3.3771282126386035
Validation loss: 2.4606606911965287

Epoch: 6| Step: 11
Training loss: 2.0247774731851322
Validation loss: 2.4667425357100465

Epoch: 6| Step: 12
Training loss: 2.6969875272434862
Validation loss: 2.449750629999788

Epoch: 6| Step: 13
Training loss: 2.029735998641727
Validation loss: 2.4559271907926012

Epoch: 118| Step: 0
Training loss: 2.607726530071673
Validation loss: 2.4624223408587946

Epoch: 6| Step: 1
Training loss: 2.9368321085588645
Validation loss: 2.442536425657555

Epoch: 6| Step: 2
Training loss: 3.406473414942348
Validation loss: 2.44876168423279

Epoch: 6| Step: 3
Training loss: 2.244362231701336
Validation loss: 2.474925240043957

Epoch: 6| Step: 4
Training loss: 2.596323781551504
Validation loss: 2.44371414563205

Epoch: 6| Step: 5
Training loss: 2.7220898864221885
Validation loss: 2.446554513889893

Epoch: 6| Step: 6
Training loss: 1.9435467040287369
Validation loss: 2.445428762614426

Epoch: 6| Step: 7
Training loss: 2.4534987632634846
Validation loss: 2.451206487229788

Epoch: 6| Step: 8
Training loss: 2.1084407291526146
Validation loss: 2.4593931030436083

Epoch: 6| Step: 9
Training loss: 2.9428496650357414
Validation loss: 2.464198807766677

Epoch: 6| Step: 10
Training loss: 2.516407530961041
Validation loss: 2.4528765955309253

Epoch: 6| Step: 11
Training loss: 2.649258016679468
Validation loss: 2.457143872969492

Epoch: 6| Step: 12
Training loss: 2.750455645180179
Validation loss: 2.455528977614871

Epoch: 6| Step: 13
Training loss: 2.1775837251703902
Validation loss: 2.443378157155053

Epoch: 119| Step: 0
Training loss: 2.7590616223213646
Validation loss: 2.444307249793495

Epoch: 6| Step: 1
Training loss: 2.412883384166325
Validation loss: 2.4581889382474427

Epoch: 6| Step: 2
Training loss: 2.653955613093548
Validation loss: 2.4561646790548264

Epoch: 6| Step: 3
Training loss: 2.260711392878819
Validation loss: 2.4434708571097303

Epoch: 6| Step: 4
Training loss: 2.2737625781063158
Validation loss: 2.445963060933164

Epoch: 6| Step: 5
Training loss: 2.891788722676946
Validation loss: 2.471130604411568

Epoch: 6| Step: 6
Training loss: 2.511828098319591
Validation loss: 2.45643787159747

Epoch: 6| Step: 7
Training loss: 2.5356319786391346
Validation loss: 2.445093542378502

Epoch: 6| Step: 8
Training loss: 2.7487722603944764
Validation loss: 2.445474243371331

Epoch: 6| Step: 9
Training loss: 2.266057045618354
Validation loss: 2.4558364840712983

Epoch: 6| Step: 10
Training loss: 2.1149417466963354
Validation loss: 2.44464100745492

Epoch: 6| Step: 11
Training loss: 3.046610815870466
Validation loss: 2.4646903767557506

Epoch: 6| Step: 12
Training loss: 3.002966685493625
Validation loss: 2.4475915206328605

Epoch: 6| Step: 13
Training loss: 2.9063408950209695
Validation loss: 2.4514090673253772

Epoch: 120| Step: 0
Training loss: 2.8160259609109457
Validation loss: 2.468805705270567

Epoch: 6| Step: 1
Training loss: 2.965987998686038
Validation loss: 2.446556697624067

Epoch: 6| Step: 2
Training loss: 3.0771137261014285
Validation loss: 2.4676066157835272

Epoch: 6| Step: 3
Training loss: 2.678819254355109
Validation loss: 2.4505222083379246

Epoch: 6| Step: 4
Training loss: 2.659347881891609
Validation loss: 2.4402461247312206

Epoch: 6| Step: 5
Training loss: 2.481844687121834
Validation loss: 2.45665032695731

Epoch: 6| Step: 6
Training loss: 2.0063680358579528
Validation loss: 2.440152514841294

Epoch: 6| Step: 7
Training loss: 2.717552359742475
Validation loss: 2.4478244454304026

Epoch: 6| Step: 8
Training loss: 2.0475548932701635
Validation loss: 2.4502790224359394

Epoch: 6| Step: 9
Training loss: 2.2536857933508316
Validation loss: 2.464901272126743

Epoch: 6| Step: 10
Training loss: 2.2739469082018604
Validation loss: 2.456868175328355

Epoch: 6| Step: 11
Training loss: 2.2280409873328972
Validation loss: 2.4549422745400444

Epoch: 6| Step: 12
Training loss: 3.239362474049678
Validation loss: 2.4422489200131925

Epoch: 6| Step: 13
Training loss: 2.441325096307453
Validation loss: 2.465454288048595

Epoch: 121| Step: 0
Training loss: 2.291610913609948
Validation loss: 2.464598881635152

Epoch: 6| Step: 1
Training loss: 2.929602537830531
Validation loss: 2.4510879199571263

Epoch: 6| Step: 2
Training loss: 2.2984331516040615
Validation loss: 2.4523843337246163

Epoch: 6| Step: 3
Training loss: 2.597796764732236
Validation loss: 2.450217260647756

Epoch: 6| Step: 4
Training loss: 2.5350383149210343
Validation loss: 2.4618190631156187

Epoch: 6| Step: 5
Training loss: 3.5022295253965825
Validation loss: 2.45467868582801

Epoch: 6| Step: 6
Training loss: 2.2785572201891857
Validation loss: 2.460491363302049

Epoch: 6| Step: 7
Training loss: 2.1176766256375132
Validation loss: 2.4714808201705982

Epoch: 6| Step: 8
Training loss: 2.443602332607398
Validation loss: 2.439834626767573

Epoch: 6| Step: 9
Training loss: 2.2093198000474796
Validation loss: 2.4483421219520625

Epoch: 6| Step: 10
Training loss: 2.7886654012818384
Validation loss: 2.4664779224481608

Epoch: 6| Step: 11
Training loss: 2.6412943155422717
Validation loss: 2.465625733607916

Epoch: 6| Step: 12
Training loss: 2.8887552348625527
Validation loss: 2.4545464197343847

Epoch: 6| Step: 13
Training loss: 2.5411489511825054
Validation loss: 2.454784645210557

Epoch: 122| Step: 0
Training loss: 2.7389196503334423
Validation loss: 2.459623818441372

Epoch: 6| Step: 1
Training loss: 2.396874331557518
Validation loss: 2.4730159672372416

Epoch: 6| Step: 2
Training loss: 2.4430517891927166
Validation loss: 2.461806642780002

Epoch: 6| Step: 3
Training loss: 2.8325211726017696
Validation loss: 2.4264023384521356

Epoch: 6| Step: 4
Training loss: 3.054586813747838
Validation loss: 2.4522251197481846

Epoch: 6| Step: 5
Training loss: 2.238036243816819
Validation loss: 2.457749297558239

Epoch: 6| Step: 6
Training loss: 2.4096330912654493
Validation loss: 2.4379169916226027

Epoch: 6| Step: 7
Training loss: 2.441911861706773
Validation loss: 2.446642041437713

Epoch: 6| Step: 8
Training loss: 2.350672962335359
Validation loss: 2.446130421754329

Epoch: 6| Step: 9
Training loss: 2.5882664821398045
Validation loss: 2.4425985810732085

Epoch: 6| Step: 10
Training loss: 2.4372083049247633
Validation loss: 2.456486537164667

Epoch: 6| Step: 11
Training loss: 2.4867937321792994
Validation loss: 2.439464283514887

Epoch: 6| Step: 12
Training loss: 3.04659093853125
Validation loss: 2.4667885816999444

Epoch: 6| Step: 13
Training loss: 2.810387814323965
Validation loss: 2.4476344092253077

Epoch: 123| Step: 0
Training loss: 2.0795535576819315
Validation loss: 2.4677363223109143

Epoch: 6| Step: 1
Training loss: 2.682728279404786
Validation loss: 2.4576778660814314

Epoch: 6| Step: 2
Training loss: 2.1313686304272967
Validation loss: 2.4494459546612135

Epoch: 6| Step: 3
Training loss: 1.6731539673946323
Validation loss: 2.464952172046638

Epoch: 6| Step: 4
Training loss: 1.886536583487851
Validation loss: 2.451482275711332

Epoch: 6| Step: 5
Training loss: 3.1038898796919177
Validation loss: 2.44168349295288

Epoch: 6| Step: 6
Training loss: 2.44682260508364
Validation loss: 2.4639587165538406

Epoch: 6| Step: 7
Training loss: 2.5578833139692043
Validation loss: 2.460218935570798

Epoch: 6| Step: 8
Training loss: 2.380444359850025
Validation loss: 2.45806469256806

Epoch: 6| Step: 9
Training loss: 2.894159743629067
Validation loss: 2.4408622235976134

Epoch: 6| Step: 10
Training loss: 2.9885876068452575
Validation loss: 2.448869151689858

Epoch: 6| Step: 11
Training loss: 2.448246959290573
Validation loss: 2.4488541814440543

Epoch: 6| Step: 12
Training loss: 3.4548817304361186
Validation loss: 2.4423978082407642

Epoch: 6| Step: 13
Training loss: 3.4072553918241506
Validation loss: 2.438519852681686

Epoch: 124| Step: 0
Training loss: 2.449278226918131
Validation loss: 2.4487118873058455

Epoch: 6| Step: 1
Training loss: 2.29125996072938
Validation loss: 2.4542116112958885

Epoch: 6| Step: 2
Training loss: 2.3123768954115387
Validation loss: 2.47028240029775

Epoch: 6| Step: 3
Training loss: 2.733247099268187
Validation loss: 2.459123092137825

Epoch: 6| Step: 4
Training loss: 2.8039512411713243
Validation loss: 2.4556027913623892

Epoch: 6| Step: 5
Training loss: 2.029350213973574
Validation loss: 2.4602259745247173

Epoch: 6| Step: 6
Training loss: 2.80664725093816
Validation loss: 2.4535684481949906

Epoch: 6| Step: 7
Training loss: 2.555139997345816
Validation loss: 2.443711283752414

Epoch: 6| Step: 8
Training loss: 3.512824133853806
Validation loss: 2.452502252421886

Epoch: 6| Step: 9
Training loss: 2.4467390975140177
Validation loss: 2.44348250297944

Epoch: 6| Step: 10
Training loss: 2.8235039657259584
Validation loss: 2.4453995169003173

Epoch: 6| Step: 11
Training loss: 2.6866622328741374
Validation loss: 2.4515074640692296

Epoch: 6| Step: 12
Training loss: 2.224011696764149
Validation loss: 2.4497692700167417

Epoch: 6| Step: 13
Training loss: 2.3146933386682553
Validation loss: 2.447354864419567

Epoch: 125| Step: 0
Training loss: 2.1108673468057026
Validation loss: 2.4609893652728716

Epoch: 6| Step: 1
Training loss: 2.5554962278012456
Validation loss: 2.4504217842446825

Epoch: 6| Step: 2
Training loss: 2.408761237474091
Validation loss: 2.466729403310199

Epoch: 6| Step: 3
Training loss: 2.543346933584318
Validation loss: 2.4539919255970566

Epoch: 6| Step: 4
Training loss: 2.8358588089547356
Validation loss: 2.457228633629613

Epoch: 6| Step: 5
Training loss: 2.5099356627102662
Validation loss: 2.452387553451584

Epoch: 6| Step: 6
Training loss: 2.151155063943755
Validation loss: 2.4428602850441266

Epoch: 6| Step: 7
Training loss: 1.7805922783000458
Validation loss: 2.4542574254647422

Epoch: 6| Step: 8
Training loss: 2.923124811035046
Validation loss: 2.458093060667208

Epoch: 6| Step: 9
Training loss: 2.8921486627824438
Validation loss: 2.4465975961740147

Epoch: 6| Step: 10
Training loss: 3.045573264594002
Validation loss: 2.451650814691305

Epoch: 6| Step: 11
Training loss: 2.7659704132759484
Validation loss: 2.4507382153609596

Epoch: 6| Step: 12
Training loss: 3.011813269887172
Validation loss: 2.429007125368979

Epoch: 6| Step: 13
Training loss: 2.41516117908631
Validation loss: 2.457119690276853

Epoch: 126| Step: 0
Training loss: 2.9029336691757663
Validation loss: 2.4410671923079823

Epoch: 6| Step: 1
Training loss: 2.5855537429444024
Validation loss: 2.446795091204434

Epoch: 6| Step: 2
Training loss: 2.784635733267852
Validation loss: 2.4318009763612873

Epoch: 6| Step: 3
Training loss: 2.8173841664858097
Validation loss: 2.4762953561137615

Epoch: 6| Step: 4
Training loss: 1.6321355703274096
Validation loss: 2.449387939793395

Epoch: 6| Step: 5
Training loss: 2.251769429743592
Validation loss: 2.451674836965371

Epoch: 6| Step: 6
Training loss: 2.740625006959539
Validation loss: 2.4458545193005556

Epoch: 6| Step: 7
Training loss: 2.2985859421667514
Validation loss: 2.454561144286743

Epoch: 6| Step: 8
Training loss: 2.3520958381187524
Validation loss: 2.461390052980042

Epoch: 6| Step: 9
Training loss: 2.815968896184719
Validation loss: 2.4590634384098125

Epoch: 6| Step: 10
Training loss: 3.238865338373108
Validation loss: 2.467346833159901

Epoch: 6| Step: 11
Training loss: 1.909342024747861
Validation loss: 2.4569181168442453

Epoch: 6| Step: 12
Training loss: 3.1237856222001463
Validation loss: 2.4446166664744444

Epoch: 6| Step: 13
Training loss: 1.55655883421023
Validation loss: 2.4544326424858744

Epoch: 127| Step: 0
Training loss: 2.6361719087164834
Validation loss: 2.4427753501126634

Epoch: 6| Step: 1
Training loss: 2.9133731957450193
Validation loss: 2.453385022069414

Epoch: 6| Step: 2
Training loss: 2.944152765602041
Validation loss: 2.450995078723875

Epoch: 6| Step: 3
Training loss: 2.9137774371504546
Validation loss: 2.4541991566384675

Epoch: 6| Step: 4
Training loss: 2.87019145047893
Validation loss: 2.45430918068967

Epoch: 6| Step: 5
Training loss: 1.9668041482921623
Validation loss: 2.448798953007898

Epoch: 6| Step: 6
Training loss: 2.662507170904828
Validation loss: 2.464301607744853

Epoch: 6| Step: 7
Training loss: 2.2359201917105027
Validation loss: 2.468965829117231

Epoch: 6| Step: 8
Training loss: 2.1481483958537715
Validation loss: 2.4465945480081595

Epoch: 6| Step: 9
Training loss: 3.0911456619344064
Validation loss: 2.4567038981226017

Epoch: 6| Step: 10
Training loss: 2.3529846352182155
Validation loss: 2.4437884242938406

Epoch: 6| Step: 11
Training loss: 2.529946733449259
Validation loss: 2.451384025413277

Epoch: 6| Step: 12
Training loss: 2.249052059970385
Validation loss: 2.4561626009324966

Epoch: 6| Step: 13
Training loss: 2.2620735483127143
Validation loss: 2.466450098771887

Epoch: 128| Step: 0
Training loss: 2.4828194600722537
Validation loss: 2.4491361207103273

Epoch: 6| Step: 1
Training loss: 2.7403223372987684
Validation loss: 2.453435893410695

Epoch: 6| Step: 2
Training loss: 2.689093361410919
Validation loss: 2.4486793224574837

Epoch: 6| Step: 3
Training loss: 2.7083412952795127
Validation loss: 2.4369459761031713

Epoch: 6| Step: 4
Training loss: 2.4589046741079854
Validation loss: 2.4461558423377037

Epoch: 6| Step: 5
Training loss: 2.0489475153637615
Validation loss: 2.4417120266972594

Epoch: 6| Step: 6
Training loss: 2.3953144230246988
Validation loss: 2.45806189745822

Epoch: 6| Step: 7
Training loss: 2.2698552069509765
Validation loss: 2.464448023559693

Epoch: 6| Step: 8
Training loss: 2.990241391443434
Validation loss: 2.4384965692049687

Epoch: 6| Step: 9
Training loss: 2.861327791702199
Validation loss: 2.442909353319574

Epoch: 6| Step: 10
Training loss: 2.8957167860403845
Validation loss: 2.449056619574725

Epoch: 6| Step: 11
Training loss: 2.603679906494068
Validation loss: 2.4494421910105846

Epoch: 6| Step: 12
Training loss: 2.188088909985819
Validation loss: 2.4563011977156757

Epoch: 6| Step: 13
Training loss: 2.858582934129494
Validation loss: 2.4517295886340746

Epoch: 129| Step: 0
Training loss: 2.47646873128133
Validation loss: 2.4731491746573306

Epoch: 6| Step: 1
Training loss: 2.0406739163341108
Validation loss: 2.4475580707274034

Epoch: 6| Step: 2
Training loss: 2.922227644421761
Validation loss: 2.4396814766055943

Epoch: 6| Step: 3
Training loss: 1.9521551547142437
Validation loss: 2.4451099877894626

Epoch: 6| Step: 4
Training loss: 2.693156388941539
Validation loss: 2.4447409790069

Epoch: 6| Step: 5
Training loss: 2.8996477505080454
Validation loss: 2.4530512465099177

Epoch: 6| Step: 6
Training loss: 2.0586835056260275
Validation loss: 2.441791361175045

Epoch: 6| Step: 7
Training loss: 2.7812667160389077
Validation loss: 2.4505401896863197

Epoch: 6| Step: 8
Training loss: 3.1193115340425894
Validation loss: 2.4540080455062085

Epoch: 6| Step: 9
Training loss: 2.8155913423988497
Validation loss: 2.4387288536417735

Epoch: 6| Step: 10
Training loss: 2.3861470887986607
Validation loss: 2.4629676217853675

Epoch: 6| Step: 11
Training loss: 2.3194346196111844
Validation loss: 2.4664780211905226

Epoch: 6| Step: 12
Training loss: 2.815275052389281
Validation loss: 2.464399093381949

Epoch: 6| Step: 13
Training loss: 2.465632631316662
Validation loss: 2.441815015343323

Epoch: 130| Step: 0
Training loss: 2.3711124526265066
Validation loss: 2.446730044690981

Epoch: 6| Step: 1
Training loss: 2.631323509367426
Validation loss: 2.439553705324544

Epoch: 6| Step: 2
Training loss: 1.892716881986917
Validation loss: 2.4474503613454046

Epoch: 6| Step: 3
Training loss: 2.395856730028988
Validation loss: 2.4537096447041926

Epoch: 6| Step: 4
Training loss: 2.2018585893992335
Validation loss: 2.4459635074283828

Epoch: 6| Step: 5
Training loss: 1.9753420231825742
Validation loss: 2.45678104080238

Epoch: 6| Step: 6
Training loss: 2.7519608356051046
Validation loss: 2.437463889999629

Epoch: 6| Step: 7
Training loss: 2.83763706363577
Validation loss: 2.447994260446186

Epoch: 6| Step: 8
Training loss: 2.550158110560006
Validation loss: 2.45804132097158

Epoch: 6| Step: 9
Training loss: 2.539162595683249
Validation loss: 2.4359147465152104

Epoch: 6| Step: 10
Training loss: 2.619872216464579
Validation loss: 2.468265964196099

Epoch: 6| Step: 11
Training loss: 3.031357124244762
Validation loss: 2.4365297168517035

Epoch: 6| Step: 12
Training loss: 3.113369163889689
Validation loss: 2.4632799549417523

Epoch: 6| Step: 13
Training loss: 2.5554380101891883
Validation loss: 2.416387521352458

Epoch: 131| Step: 0
Training loss: 2.336410015375882
Validation loss: 2.463749633771721

Epoch: 6| Step: 1
Training loss: 2.694792058704074
Validation loss: 2.453293178988746

Epoch: 6| Step: 2
Training loss: 1.9287753401035468
Validation loss: 2.442855066162565

Epoch: 6| Step: 3
Training loss: 3.751731091531815
Validation loss: 2.455228951619263

Epoch: 6| Step: 4
Training loss: 1.911137054079989
Validation loss: 2.443015365638296

Epoch: 6| Step: 5
Training loss: 2.1152384327350275
Validation loss: 2.4415256124215166

Epoch: 6| Step: 6
Training loss: 3.0145736205588896
Validation loss: 2.456136074710289

Epoch: 6| Step: 7
Training loss: 2.679663477308958
Validation loss: 2.436212151602125

Epoch: 6| Step: 8
Training loss: 2.6348280620034394
Validation loss: 2.4480782603223243

Epoch: 6| Step: 9
Training loss: 2.625371452571436
Validation loss: 2.448830137781524

Epoch: 6| Step: 10
Training loss: 2.2762685236420666
Validation loss: 2.453296499930774

Epoch: 6| Step: 11
Training loss: 2.592580232767384
Validation loss: 2.4398258375441575

Epoch: 6| Step: 12
Training loss: 2.447165862391971
Validation loss: 2.4457851617387107

Epoch: 6| Step: 13
Training loss: 2.289633305437873
Validation loss: 2.4500337280285702

Epoch: 132| Step: 0
Training loss: 2.602478965652287
Validation loss: 2.4444704209583845

Epoch: 6| Step: 1
Training loss: 2.4531978912215076
Validation loss: 2.446711650278221

Epoch: 6| Step: 2
Training loss: 2.3137856080186574
Validation loss: 2.4594781718588754

Epoch: 6| Step: 3
Training loss: 2.926549100259633
Validation loss: 2.4492553335573786

Epoch: 6| Step: 4
Training loss: 2.7445453820433467
Validation loss: 2.4463162718745197

Epoch: 6| Step: 5
Training loss: 2.663974346592966
Validation loss: 2.45902803809982

Epoch: 6| Step: 6
Training loss: 2.4931562209164775
Validation loss: 2.448470835553654

Epoch: 6| Step: 7
Training loss: 2.5604660521902933
Validation loss: 2.439257362948607

Epoch: 6| Step: 8
Training loss: 2.888516373540223
Validation loss: 2.470828351679121

Epoch: 6| Step: 9
Training loss: 1.7739472853861062
Validation loss: 2.462930198413242

Epoch: 6| Step: 10
Training loss: 2.7731574978320257
Validation loss: 2.4556247224982113

Epoch: 6| Step: 11
Training loss: 2.2210603961727977
Validation loss: 2.44829211125714

Epoch: 6| Step: 12
Training loss: 2.734665337543484
Validation loss: 2.452790747985165

Epoch: 6| Step: 13
Training loss: 2.673638102297483
Validation loss: 2.4410626081236892

Epoch: 133| Step: 0
Training loss: 2.345315639181152
Validation loss: 2.447083997697872

Epoch: 6| Step: 1
Training loss: 1.8348473741634779
Validation loss: 2.46194108044346

Epoch: 6| Step: 2
Training loss: 2.683149053828776
Validation loss: 2.4589753307687157

Epoch: 6| Step: 3
Training loss: 2.8886365495008723
Validation loss: 2.4451330803777904

Epoch: 6| Step: 4
Training loss: 2.9668727360281415
Validation loss: 2.449088483563766

Epoch: 6| Step: 5
Training loss: 2.480081555040745
Validation loss: 2.447178992398482

Epoch: 6| Step: 6
Training loss: 2.7747524529094045
Validation loss: 2.4548693442588188

Epoch: 6| Step: 7
Training loss: 2.7942587267686583
Validation loss: 2.4455184543137816

Epoch: 6| Step: 8
Training loss: 2.557317191085281
Validation loss: 2.460095555225167

Epoch: 6| Step: 9
Training loss: 3.10939784976097
Validation loss: 2.4403484866245932

Epoch: 6| Step: 10
Training loss: 1.6576244481290556
Validation loss: 2.441252742149764

Epoch: 6| Step: 11
Training loss: 2.6468921755398966
Validation loss: 2.4556866124080257

Epoch: 6| Step: 12
Training loss: 2.090834338280548
Validation loss: 2.4474476630508764

Epoch: 6| Step: 13
Training loss: 2.7278074029408788
Validation loss: 2.4379513456502133

Epoch: 134| Step: 0
Training loss: 2.3633191822885555
Validation loss: 2.451612822774714

Epoch: 6| Step: 1
Training loss: 2.3455907078469154
Validation loss: 2.463699674652311

Epoch: 6| Step: 2
Training loss: 2.5470728885089726
Validation loss: 2.441508408900923

Epoch: 6| Step: 3
Training loss: 2.3670125462304696
Validation loss: 2.4382684336201974

Epoch: 6| Step: 4
Training loss: 2.4546162148753727
Validation loss: 2.4421131998967778

Epoch: 6| Step: 5
Training loss: 1.9801699320765132
Validation loss: 2.4265235168293566

Epoch: 6| Step: 6
Training loss: 2.817131298348771
Validation loss: 2.4458031978289014

Epoch: 6| Step: 7
Training loss: 2.639687636998524
Validation loss: 2.4494398528554187

Epoch: 6| Step: 8
Training loss: 2.33516698268799
Validation loss: 2.444006438352077

Epoch: 6| Step: 9
Training loss: 2.2062632617065567
Validation loss: 2.4275798779962177

Epoch: 6| Step: 10
Training loss: 3.1546799182092213
Validation loss: 2.432014421248694

Epoch: 6| Step: 11
Training loss: 2.569968528109563
Validation loss: 2.4438190163121734

Epoch: 6| Step: 12
Training loss: 3.2411298750314357
Validation loss: 2.4569157216321678

Epoch: 6| Step: 13
Training loss: 2.7773633223862038
Validation loss: 2.4480491457462374

Epoch: 135| Step: 0
Training loss: 2.8145901013304018
Validation loss: 2.4448433105204614

Epoch: 6| Step: 1
Training loss: 2.5610341787563673
Validation loss: 2.433510985219916

Epoch: 6| Step: 2
Training loss: 2.083484593304474
Validation loss: 2.4421747467392656

Epoch: 6| Step: 3
Training loss: 2.592008442641272
Validation loss: 2.4485247825164067

Epoch: 6| Step: 4
Training loss: 2.705459116192375
Validation loss: 2.4329159677557657

Epoch: 6| Step: 5
Training loss: 3.0784809661916217
Validation loss: 2.4471518455202643

Epoch: 6| Step: 6
Training loss: 2.1056730210220107
Validation loss: 2.461047155616739

Epoch: 6| Step: 7
Training loss: 2.82257496547567
Validation loss: 2.4452503831649275

Epoch: 6| Step: 8
Training loss: 2.1315194147036967
Validation loss: 2.4442637836450807

Epoch: 6| Step: 9
Training loss: 2.820661951115068
Validation loss: 2.4507424341525543

Epoch: 6| Step: 10
Training loss: 2.849377440334178
Validation loss: 2.442685048150016

Epoch: 6| Step: 11
Training loss: 2.9055279891110692
Validation loss: 2.434197977446327

Epoch: 6| Step: 12
Training loss: 2.017907321658076
Validation loss: 2.4403427455131785

Epoch: 6| Step: 13
Training loss: 1.5664047279255386
Validation loss: 2.440845426597137

Epoch: 136| Step: 0
Training loss: 2.3783190774612875
Validation loss: 2.446208169308798

Epoch: 6| Step: 1
Training loss: 2.559906181762103
Validation loss: 2.4531235055766722

Epoch: 6| Step: 2
Training loss: 2.603152593899179
Validation loss: 2.451623328855461

Epoch: 6| Step: 3
Training loss: 2.434205886000745
Validation loss: 2.4548343210387413

Epoch: 6| Step: 4
Training loss: 1.8950078934880024
Validation loss: 2.4491544063706057

Epoch: 6| Step: 5
Training loss: 2.0558614531862953
Validation loss: 2.4451450706136835

Epoch: 6| Step: 6
Training loss: 3.156998347333029
Validation loss: 2.4616938196920684

Epoch: 6| Step: 7
Training loss: 2.5985809745334616
Validation loss: 2.449797995792561

Epoch: 6| Step: 8
Training loss: 2.6428036702759483
Validation loss: 2.4565380497510705

Epoch: 6| Step: 9
Training loss: 2.4232155320063637
Validation loss: 2.445216822076819

Epoch: 6| Step: 10
Training loss: 3.155241247949778
Validation loss: 2.4511695384947685

Epoch: 6| Step: 11
Training loss: 3.089181165871262
Validation loss: 2.4469198724436496

Epoch: 6| Step: 12
Training loss: 2.3190992889138706
Validation loss: 2.457420634022553

Epoch: 6| Step: 13
Training loss: 1.9217561514477952
Validation loss: 2.443796881144286

Epoch: 137| Step: 0
Training loss: 2.5528922116109807
Validation loss: 2.461755533329836

Epoch: 6| Step: 1
Training loss: 2.4739424748498027
Validation loss: 2.4387519803729285

Epoch: 6| Step: 2
Training loss: 1.8318899136746056
Validation loss: 2.45188827383536

Epoch: 6| Step: 3
Training loss: 2.830299510944959
Validation loss: 2.4387722686428535

Epoch: 6| Step: 4
Training loss: 3.2632408382515408
Validation loss: 2.438024924492451

Epoch: 6| Step: 5
Training loss: 2.4955592769735837
Validation loss: 2.4441101668196743

Epoch: 6| Step: 6
Training loss: 2.4925797013345194
Validation loss: 2.446471897309479

Epoch: 6| Step: 7
Training loss: 2.673866288419211
Validation loss: 2.4353630557780237

Epoch: 6| Step: 8
Training loss: 2.5273483724419186
Validation loss: 2.455388637469117

Epoch: 6| Step: 9
Training loss: 2.809684955272046
Validation loss: 2.4487454716831736

Epoch: 6| Step: 10
Training loss: 2.577804453024835
Validation loss: 2.437287518832326

Epoch: 6| Step: 11
Training loss: 2.662187559752694
Validation loss: 2.449149887567379

Epoch: 6| Step: 12
Training loss: 1.791172299453446
Validation loss: 2.4497201036832115

Epoch: 6| Step: 13
Training loss: 2.221657687906187
Validation loss: 2.4566781003963145

Epoch: 138| Step: 0
Training loss: 3.1314810113722484
Validation loss: 2.445917778977205

Epoch: 6| Step: 1
Training loss: 2.320419463187193
Validation loss: 2.446637859060328

Epoch: 6| Step: 2
Training loss: 2.8085750743685414
Validation loss: 2.4565395055712345

Epoch: 6| Step: 3
Training loss: 2.488218393534977
Validation loss: 2.434729965497746

Epoch: 6| Step: 4
Training loss: 2.6504230089675955
Validation loss: 2.447259443381486

Epoch: 6| Step: 5
Training loss: 2.5566439821645264
Validation loss: 2.447541839730686

Epoch: 6| Step: 6
Training loss: 3.16732777838627
Validation loss: 2.4467551127560636

Epoch: 6| Step: 7
Training loss: 2.5996366136873585
Validation loss: 2.4624350943641287

Epoch: 6| Step: 8
Training loss: 2.8247996639008432
Validation loss: 2.4356181566364667

Epoch: 6| Step: 9
Training loss: 1.6219893222273931
Validation loss: 2.4504498621019866

Epoch: 6| Step: 10
Training loss: 2.5721456837189307
Validation loss: 2.440282542344431

Epoch: 6| Step: 11
Training loss: 2.3100247925918276
Validation loss: 2.443466452648324

Epoch: 6| Step: 12
Training loss: 1.9545348915153393
Validation loss: 2.428504780755942

Epoch: 6| Step: 13
Training loss: 1.8599888405413825
Validation loss: 2.447701276642692

Epoch: 139| Step: 0
Training loss: 3.3994666634917023
Validation loss: 2.4518783638262835

Epoch: 6| Step: 1
Training loss: 2.792042740120339
Validation loss: 2.443016300631748

Epoch: 6| Step: 2
Training loss: 2.5534786432350516
Validation loss: 2.4366235485139

Epoch: 6| Step: 3
Training loss: 1.8477463811137793
Validation loss: 2.440541819201347

Epoch: 6| Step: 4
Training loss: 2.2762343778288865
Validation loss: 2.4556866479026938

Epoch: 6| Step: 5
Training loss: 2.325080570752752
Validation loss: 2.4546501101206806

Epoch: 6| Step: 6
Training loss: 2.302524184970809
Validation loss: 2.44216184544026

Epoch: 6| Step: 7
Training loss: 1.7187829447970076
Validation loss: 2.444080260242633

Epoch: 6| Step: 8
Training loss: 3.192703786393496
Validation loss: 2.444871265271792

Epoch: 6| Step: 9
Training loss: 2.34788656771124
Validation loss: 2.446874262446699

Epoch: 6| Step: 10
Training loss: 3.0001085579622124
Validation loss: 2.45157391422569

Epoch: 6| Step: 11
Training loss: 2.1278732173266603
Validation loss: 2.4518713009076287

Epoch: 6| Step: 12
Training loss: 2.8534432675524033
Validation loss: 2.441254229400503

Epoch: 6| Step: 13
Training loss: 2.13983596404805
Validation loss: 2.4324219466261505

Epoch: 140| Step: 0
Training loss: 2.525759263655322
Validation loss: 2.4481898071414006

Epoch: 6| Step: 1
Training loss: 2.4233682274525297
Validation loss: 2.4391704280482376

Epoch: 6| Step: 2
Training loss: 2.4793037141591703
Validation loss: 2.449088715947446

Epoch: 6| Step: 3
Training loss: 1.5659934092026109
Validation loss: 2.4432128008214513

Epoch: 6| Step: 4
Training loss: 2.9876379579748495
Validation loss: 2.4654359465098388

Epoch: 6| Step: 5
Training loss: 2.945136998459879
Validation loss: 2.444433610047835

Epoch: 6| Step: 6
Training loss: 2.097662160286134
Validation loss: 2.4310543943804754

Epoch: 6| Step: 7
Training loss: 2.656927224388316
Validation loss: 2.4422313972265917

Epoch: 6| Step: 8
Training loss: 2.398044218443104
Validation loss: 2.4374459352431894

Epoch: 6| Step: 9
Training loss: 2.658904062388916
Validation loss: 2.439968213076542

Epoch: 6| Step: 10
Training loss: 2.782285347582288
Validation loss: 2.4374878385843615

Epoch: 6| Step: 11
Training loss: 3.013359523366807
Validation loss: 2.4546520203305633

Epoch: 6| Step: 12
Training loss: 2.3922658039136677
Validation loss: 2.461420881382831

Epoch: 6| Step: 13
Training loss: 1.9879708338196398
Validation loss: 2.4457574684768053

Epoch: 141| Step: 0
Training loss: 1.8860744221183434
Validation loss: 2.4405470277982357

Epoch: 6| Step: 1
Training loss: 2.182169277306822
Validation loss: 2.4428139380892477

Epoch: 6| Step: 2
Training loss: 2.7924396147043216
Validation loss: 2.452421064495237

Epoch: 6| Step: 3
Training loss: 2.826284747713629
Validation loss: 2.456141885369838

Epoch: 6| Step: 4
Training loss: 2.706421622457343
Validation loss: 2.4461631937214157

Epoch: 6| Step: 5
Training loss: 2.591668730200368
Validation loss: 2.430718117789207

Epoch: 6| Step: 6
Training loss: 2.64578267046465
Validation loss: 2.42916808748778

Epoch: 6| Step: 7
Training loss: 2.077562298993985
Validation loss: 2.4248813225871864

Epoch: 6| Step: 8
Training loss: 2.5470541674541987
Validation loss: 2.4285143132179274

Epoch: 6| Step: 9
Training loss: 2.4453088924881037
Validation loss: 2.439782592863938

Epoch: 6| Step: 10
Training loss: 2.59188003234154
Validation loss: 2.442658884588849

Epoch: 6| Step: 11
Training loss: 2.3358453330544795
Validation loss: 2.4353168451056297

Epoch: 6| Step: 12
Training loss: 2.7427611009211272
Validation loss: 2.4487331399813166

Epoch: 6| Step: 13
Training loss: 3.113836413654149
Validation loss: 2.4391237944643787

Epoch: 142| Step: 0
Training loss: 2.4767334695520264
Validation loss: 2.4428416762644223

Epoch: 6| Step: 1
Training loss: 2.265922369021958
Validation loss: 2.4487424398009456

Epoch: 6| Step: 2
Training loss: 2.176703704394246
Validation loss: 2.452630880448835

Epoch: 6| Step: 3
Training loss: 2.772410801793296
Validation loss: 2.425150102444426

Epoch: 6| Step: 4
Training loss: 2.013952463250053
Validation loss: 2.447702823079032

Epoch: 6| Step: 5
Training loss: 1.9524803013119258
Validation loss: 2.453864950644715

Epoch: 6| Step: 6
Training loss: 2.521520683801323
Validation loss: 2.447878021235404

Epoch: 6| Step: 7
Training loss: 2.9925538478713576
Validation loss: 2.453920029021899

Epoch: 6| Step: 8
Training loss: 3.084059363450645
Validation loss: 2.4444528401588927

Epoch: 6| Step: 9
Training loss: 2.709421926969797
Validation loss: 2.4463144547118887

Epoch: 6| Step: 10
Training loss: 2.5808526608469404
Validation loss: 2.4414213719709768

Epoch: 6| Step: 11
Training loss: 2.040444092377003
Validation loss: 2.43850928699194

Epoch: 6| Step: 12
Training loss: 2.372550102323892
Validation loss: 2.424207968259568

Epoch: 6| Step: 13
Training loss: 3.6037249579272412
Validation loss: 2.4483121487462225

Epoch: 143| Step: 0
Training loss: 1.4170827908932235
Validation loss: 2.4321759074237077

Epoch: 6| Step: 1
Training loss: 2.7380145455943046
Validation loss: 2.46138213829115

Epoch: 6| Step: 2
Training loss: 2.387175221347304
Validation loss: 2.428573315474833

Epoch: 6| Step: 3
Training loss: 3.4800703203835486
Validation loss: 2.444898831209387

Epoch: 6| Step: 4
Training loss: 2.340144728724998
Validation loss: 2.4443059833418777

Epoch: 6| Step: 5
Training loss: 2.588523654887871
Validation loss: 2.4529302930088583

Epoch: 6| Step: 6
Training loss: 2.141926613356395
Validation loss: 2.4475980926206438

Epoch: 6| Step: 7
Training loss: 2.686667024913729
Validation loss: 2.442454617819369

Epoch: 6| Step: 8
Training loss: 2.389125877522715
Validation loss: 2.464062155998093

Epoch: 6| Step: 9
Training loss: 2.278580867749491
Validation loss: 2.450211352234508

Epoch: 6| Step: 10
Training loss: 2.259116776141917
Validation loss: 2.4474867744134134

Epoch: 6| Step: 11
Training loss: 2.5554276540327097
Validation loss: 2.4612858674315174

Epoch: 6| Step: 12
Training loss: 2.4554993625423323
Validation loss: 2.468047670770389

Epoch: 6| Step: 13
Training loss: 3.2245144382413233
Validation loss: 2.4470529949623785

Epoch: 144| Step: 0
Training loss: 2.551900667672956
Validation loss: 2.4445335670096067

Epoch: 6| Step: 1
Training loss: 3.0005591189385217
Validation loss: 2.443789719862358

Epoch: 6| Step: 2
Training loss: 2.5978776192095054
Validation loss: 2.4363135539060345

Epoch: 6| Step: 3
Training loss: 2.2675976813998426
Validation loss: 2.446536968500049

Epoch: 6| Step: 4
Training loss: 1.8517513259341154
Validation loss: 2.4377129343156496

Epoch: 6| Step: 5
Training loss: 2.784427413703988
Validation loss: 2.4449436675302305

Epoch: 6| Step: 6
Training loss: 2.345160403266079
Validation loss: 2.458651954966597

Epoch: 6| Step: 7
Training loss: 2.2472060128177365
Validation loss: 2.4481535856910375

Epoch: 6| Step: 8
Training loss: 2.7929868470786077
Validation loss: 2.467811793534842

Epoch: 6| Step: 9
Training loss: 2.589627770441327
Validation loss: 2.445723979336332

Epoch: 6| Step: 10
Training loss: 2.3178598304412192
Validation loss: 2.44574922228104

Epoch: 6| Step: 11
Training loss: 2.8344273605473185
Validation loss: 2.4471190155553866

Epoch: 6| Step: 12
Training loss: 2.356275632197752
Validation loss: 2.4294676206234396

Epoch: 6| Step: 13
Training loss: 2.6010297166709986
Validation loss: 2.4303618424702833

Epoch: 145| Step: 0
Training loss: 2.0989733775114807
Validation loss: 2.4324282713460343

Epoch: 6| Step: 1
Training loss: 2.334017675952287
Validation loss: 2.4387916348479357

Epoch: 6| Step: 2
Training loss: 2.8244514000172796
Validation loss: 2.4478074663181113

Epoch: 6| Step: 3
Training loss: 2.2658227242318105
Validation loss: 2.4519034257832995

Epoch: 6| Step: 4
Training loss: 2.1710181432780296
Validation loss: 2.4639986640179834

Epoch: 6| Step: 5
Training loss: 2.5756226388670056
Validation loss: 2.457626809244538

Epoch: 6| Step: 6
Training loss: 2.485666383241004
Validation loss: 2.4485076051383796

Epoch: 6| Step: 7
Training loss: 2.020767866299891
Validation loss: 2.4276073245260164

Epoch: 6| Step: 8
Training loss: 3.0294538072362522
Validation loss: 2.4433883104335425

Epoch: 6| Step: 9
Training loss: 2.320034742588487
Validation loss: 2.4380448276490565

Epoch: 6| Step: 10
Training loss: 3.0805778219023905
Validation loss: 2.451436626153075

Epoch: 6| Step: 11
Training loss: 3.0181452048568005
Validation loss: 2.441798101533957

Epoch: 6| Step: 12
Training loss: 2.6471939993607316
Validation loss: 2.448162845825449

Epoch: 6| Step: 13
Training loss: 1.7228791315432863
Validation loss: 2.4562177692131346

Epoch: 146| Step: 0
Training loss: 2.7892025183143994
Validation loss: 2.445119024592681

Epoch: 6| Step: 1
Training loss: 1.8986383025795663
Validation loss: 2.4454052828321315

Epoch: 6| Step: 2
Training loss: 3.133756043618898
Validation loss: 2.450515114310271

Epoch: 6| Step: 3
Training loss: 2.120654206371347
Validation loss: 2.4342373209143044

Epoch: 6| Step: 4
Training loss: 2.3408724604381157
Validation loss: 2.4482120580927575

Epoch: 6| Step: 5
Training loss: 2.393263513915631
Validation loss: 2.4375581852710213

Epoch: 6| Step: 6
Training loss: 2.3817946964961787
Validation loss: 2.4383280346545044

Epoch: 6| Step: 7
Training loss: 2.1455611516184927
Validation loss: 2.425387277940187

Epoch: 6| Step: 8
Training loss: 2.8151171904811667
Validation loss: 2.4592105846431145

Epoch: 6| Step: 9
Training loss: 2.6756545433617918
Validation loss: 2.425137008037506

Epoch: 6| Step: 10
Training loss: 2.6631439504819805
Validation loss: 2.434616876406666

Epoch: 6| Step: 11
Training loss: 3.174765486579346
Validation loss: 2.4502359295496245

Epoch: 6| Step: 12
Training loss: 1.94544388047814
Validation loss: 2.4483824744696956

Epoch: 6| Step: 13
Training loss: 2.235767810708361
Validation loss: 2.46615074546964

Epoch: 147| Step: 0
Training loss: 2.7731311037840265
Validation loss: 2.4551113925660335

Epoch: 6| Step: 1
Training loss: 3.21010755222098
Validation loss: 2.4512795024337906

Epoch: 6| Step: 2
Training loss: 2.9595462479636043
Validation loss: 2.4484148770452614

Epoch: 6| Step: 3
Training loss: 2.3918727037245846
Validation loss: 2.4622849684049983

Epoch: 6| Step: 4
Training loss: 2.3333699586809433
Validation loss: 2.475534308139628

Epoch: 6| Step: 5
Training loss: 2.533195219123168
Validation loss: 2.464910648233054

Epoch: 6| Step: 6
Training loss: 2.1859190541294193
Validation loss: 2.4429991579788943

Epoch: 6| Step: 7
Training loss: 2.266102602373971
Validation loss: 2.459926075355274

Epoch: 6| Step: 8
Training loss: 2.523284246083989
Validation loss: 2.4631292330947674

Epoch: 6| Step: 9
Training loss: 2.1520060916516615
Validation loss: 2.4639516742173266

Epoch: 6| Step: 10
Training loss: 2.450238807872957
Validation loss: 2.4603598389862444

Epoch: 6| Step: 11
Training loss: 2.7403561815853656
Validation loss: 2.4598900913343824

Epoch: 6| Step: 12
Training loss: 2.345629841011514
Validation loss: 2.4210054867102033

Epoch: 6| Step: 13
Training loss: 2.0447916392013643
Validation loss: 2.448027010603571

Epoch: 148| Step: 0
Training loss: 2.4885822874585917
Validation loss: 2.4527393741024737

Epoch: 6| Step: 1
Training loss: 2.5244119847065916
Validation loss: 2.4363168211779436

Epoch: 6| Step: 2
Training loss: 2.046977965116589
Validation loss: 2.4426843817063304

Epoch: 6| Step: 3
Training loss: 2.8560523233936737
Validation loss: 2.448220631602916

Epoch: 6| Step: 4
Training loss: 2.903569451711649
Validation loss: 2.4408863672781047

Epoch: 6| Step: 5
Training loss: 2.7612331022727274
Validation loss: 2.4399600460799795

Epoch: 6| Step: 6
Training loss: 2.412876269788931
Validation loss: 2.4461446949589147

Epoch: 6| Step: 7
Training loss: 2.3425684684591284
Validation loss: 2.4617675475239875

Epoch: 6| Step: 8
Training loss: 2.4788370848347125
Validation loss: 2.448839168184657

Epoch: 6| Step: 9
Training loss: 2.888054441916332
Validation loss: 2.4380255217577567

Epoch: 6| Step: 10
Training loss: 2.2321119251832804
Validation loss: 2.4452746360615336

Epoch: 6| Step: 11
Training loss: 1.4384369491851237
Validation loss: 2.446168840474599

Epoch: 6| Step: 12
Training loss: 2.2050846123409884
Validation loss: 2.44146088753546

Epoch: 6| Step: 13
Training loss: 3.131892271281625
Validation loss: 2.446554905788588

Epoch: 149| Step: 0
Training loss: 3.075964774774623
Validation loss: 2.4370551553995305

Epoch: 6| Step: 1
Training loss: 2.379108088407436
Validation loss: 2.4160012756659532

Epoch: 6| Step: 2
Training loss: 2.6379644771379316
Validation loss: 2.435194401216471

Epoch: 6| Step: 3
Training loss: 2.7947039995769614
Validation loss: 2.4329855262240825

Epoch: 6| Step: 4
Training loss: 2.307725978874658
Validation loss: 2.4417126015369894

Epoch: 6| Step: 5
Training loss: 2.2002298798535667
Validation loss: 2.4235021983146003

Epoch: 6| Step: 6
Training loss: 2.5675885918626036
Validation loss: 2.4230276529213404

Epoch: 6| Step: 7
Training loss: 1.5602262356132126
Validation loss: 2.4365091731685777

Epoch: 6| Step: 8
Training loss: 2.5891496237333156
Validation loss: 2.4456525111028524

Epoch: 6| Step: 9
Training loss: 2.7410359369237254
Validation loss: 2.4453647029635186

Epoch: 6| Step: 10
Training loss: 2.5991149019364297
Validation loss: 2.4236701084270558

Epoch: 6| Step: 11
Training loss: 2.370223411942843
Validation loss: 2.4311439220024074

Epoch: 6| Step: 12
Training loss: 2.6299299539731424
Validation loss: 2.430040338955275

Epoch: 6| Step: 13
Training loss: 2.0388569344566894
Validation loss: 2.4278037677797117

Epoch: 150| Step: 0
Training loss: 2.7496363659506864
Validation loss: 2.428899439836848

Epoch: 6| Step: 1
Training loss: 3.020605846038841
Validation loss: 2.4243561715353357

Epoch: 6| Step: 2
Training loss: 1.8203509412643988
Validation loss: 2.4615068257940367

Epoch: 6| Step: 3
Training loss: 2.459542015056487
Validation loss: 2.4424846786505663

Epoch: 6| Step: 4
Training loss: 2.8581340160515456
Validation loss: 2.437490171376394

Epoch: 6| Step: 5
Training loss: 1.9628323826286167
Validation loss: 2.4130227222863168

Epoch: 6| Step: 6
Training loss: 2.0519602265844177
Validation loss: 2.433668258543748

Epoch: 6| Step: 7
Training loss: 3.265120617915383
Validation loss: 2.4466315846949773

Epoch: 6| Step: 8
Training loss: 2.397158303359619
Validation loss: 2.4340946375532484

Epoch: 6| Step: 9
Training loss: 2.362992500761436
Validation loss: 2.44456681447549

Epoch: 6| Step: 10
Training loss: 1.9936903128464054
Validation loss: 2.4451474464264433

Epoch: 6| Step: 11
Training loss: 2.86335785517408
Validation loss: 2.4495922532017307

Epoch: 6| Step: 12
Training loss: 2.19987366920499
Validation loss: 2.4402285066687557

Epoch: 6| Step: 13
Training loss: 2.558233384241612
Validation loss: 2.4354421860180087

Epoch: 151| Step: 0
Training loss: 2.282475808423835
Validation loss: 2.4276473445269744

Epoch: 6| Step: 1
Training loss: 2.523239175189538
Validation loss: 2.44660157953113

Epoch: 6| Step: 2
Training loss: 2.6315226578966477
Validation loss: 2.443479317682212

Epoch: 6| Step: 3
Training loss: 2.5744485246050393
Validation loss: 2.4244220721148286

Epoch: 6| Step: 4
Training loss: 2.006173619037415
Validation loss: 2.434426178822628

Epoch: 6| Step: 5
Training loss: 1.870504139042904
Validation loss: 2.4308535940339993

Epoch: 6| Step: 6
Training loss: 3.013328982690467
Validation loss: 2.4426215053377334

Epoch: 6| Step: 7
Training loss: 2.633750137307372
Validation loss: 2.460971069106983

Epoch: 6| Step: 8
Training loss: 2.8149728712058666
Validation loss: 2.432415260385481

Epoch: 6| Step: 9
Training loss: 2.2739989121702036
Validation loss: 2.456676719532284

Epoch: 6| Step: 10
Training loss: 2.484845003018474
Validation loss: 2.435501493064118

Epoch: 6| Step: 11
Training loss: 2.331329802509994
Validation loss: 2.4474615619593254

Epoch: 6| Step: 12
Training loss: 2.662600835045897
Validation loss: 2.4475877284689993

Epoch: 6| Step: 13
Training loss: 2.4969162041196955
Validation loss: 2.419705524152334

Epoch: 152| Step: 0
Training loss: 2.7637580561595945
Validation loss: 2.4467754415371177

Epoch: 6| Step: 1
Training loss: 2.409130007784798
Validation loss: 2.4314751958338547

Epoch: 6| Step: 2
Training loss: 1.7153431506275667
Validation loss: 2.427545231985487

Epoch: 6| Step: 3
Training loss: 2.611290873659131
Validation loss: 2.423992248501238

Epoch: 6| Step: 4
Training loss: 2.3913289947144274
Validation loss: 2.440752698352119

Epoch: 6| Step: 5
Training loss: 2.189371779578582
Validation loss: 2.441769586118952

Epoch: 6| Step: 6
Training loss: 2.22792776981705
Validation loss: 2.4456397801460152

Epoch: 6| Step: 7
Training loss: 3.125629819344915
Validation loss: 2.4491830618997485

Epoch: 6| Step: 8
Training loss: 2.569551859721096
Validation loss: 2.4335396416518758

Epoch: 6| Step: 9
Training loss: 3.00935177739612
Validation loss: 2.425415108658717

Epoch: 6| Step: 10
Training loss: 1.9912621237558759
Validation loss: 2.4247761540923793

Epoch: 6| Step: 11
Training loss: 2.801611188134642
Validation loss: 2.4432837056162118

Epoch: 6| Step: 12
Training loss: 2.0559112037824336
Validation loss: 2.4378862161775565

Epoch: 6| Step: 13
Training loss: 2.5616526249352005
Validation loss: 2.4389280306807226

Epoch: 153| Step: 0
Training loss: 2.2590461713269634
Validation loss: 2.4238200062153914

Epoch: 6| Step: 1
Training loss: 2.2708265905250977
Validation loss: 2.4487118831181083

Epoch: 6| Step: 2
Training loss: 3.173609968463925
Validation loss: 2.4314569364268475

Epoch: 6| Step: 3
Training loss: 1.8819167669621941
Validation loss: 2.439486503709335

Epoch: 6| Step: 4
Training loss: 2.78417891679992
Validation loss: 2.417227143996641

Epoch: 6| Step: 5
Training loss: 2.2836057440135757
Validation loss: 2.440981752830024

Epoch: 6| Step: 6
Training loss: 2.961738095714647
Validation loss: 2.44824668075313

Epoch: 6| Step: 7
Training loss: 2.556119465001656
Validation loss: 2.4459062033983283

Epoch: 6| Step: 8
Training loss: 2.1342687979731965
Validation loss: 2.4375500617343673

Epoch: 6| Step: 9
Training loss: 2.158908476719671
Validation loss: 2.446973119177177

Epoch: 6| Step: 10
Training loss: 2.4861891738409168
Validation loss: 2.429029367343832

Epoch: 6| Step: 11
Training loss: 2.7823173960690144
Validation loss: 2.4573521203624065

Epoch: 6| Step: 12
Training loss: 2.530870385608959
Validation loss: 2.44201810944253

Epoch: 6| Step: 13
Training loss: 1.943851765118271
Validation loss: 2.4562380843886054

Epoch: 154| Step: 0
Training loss: 2.543094754942723
Validation loss: 2.432445264008913

Epoch: 6| Step: 1
Training loss: 2.6521542555881945
Validation loss: 2.431446023735069

Epoch: 6| Step: 2
Training loss: 2.0226019235021484
Validation loss: 2.427050513229975

Epoch: 6| Step: 3
Training loss: 2.263922953073088
Validation loss: 2.445386168191822

Epoch: 6| Step: 4
Training loss: 2.776627632025492
Validation loss: 2.4343052213855016

Epoch: 6| Step: 5
Training loss: 2.6916555170196363
Validation loss: 2.4490948793407807

Epoch: 6| Step: 6
Training loss: 2.6840097696265803
Validation loss: 2.444219068057636

Epoch: 6| Step: 7
Training loss: 3.1721344639682467
Validation loss: 2.437475819095709

Epoch: 6| Step: 8
Training loss: 1.9314062209662064
Validation loss: 2.428083621830334

Epoch: 6| Step: 9
Training loss: 2.6158075594799444
Validation loss: 2.4737640021293283

Epoch: 6| Step: 10
Training loss: 2.5073350113113633
Validation loss: 2.443909372882161

Epoch: 6| Step: 11
Training loss: 2.327941477665944
Validation loss: 2.4289868521074744

Epoch: 6| Step: 12
Training loss: 1.7332340646096789
Validation loss: 2.440935880637806

Epoch: 6| Step: 13
Training loss: 2.0752342597448132
Validation loss: 2.449453517530114

Epoch: 155| Step: 0
Training loss: 2.2329572968352407
Validation loss: 2.434286145961287

Epoch: 6| Step: 1
Training loss: 2.7017720094350666
Validation loss: 2.4309350313925298

Epoch: 6| Step: 2
Training loss: 3.305134195209
Validation loss: 2.4268167444293707

Epoch: 6| Step: 3
Training loss: 2.685393461527173
Validation loss: 2.442374282001127

Epoch: 6| Step: 4
Training loss: 2.3425286734830135
Validation loss: 2.432872043080941

Epoch: 6| Step: 5
Training loss: 3.241895400527887
Validation loss: 2.4405097033891674

Epoch: 6| Step: 6
Training loss: 2.145329005656472
Validation loss: 2.4343769985304875

Epoch: 6| Step: 7
Training loss: 2.0019274007493615
Validation loss: 2.455487342475324

Epoch: 6| Step: 8
Training loss: 2.3723668006993663
Validation loss: 2.42075290626461

Epoch: 6| Step: 9
Training loss: 1.9570727924498643
Validation loss: 2.4189274841838855

Epoch: 6| Step: 10
Training loss: 1.6826655756744822
Validation loss: 2.449610959309941

Epoch: 6| Step: 11
Training loss: 2.4289173733323723
Validation loss: 2.433514441665768

Epoch: 6| Step: 12
Training loss: 2.5255684845285713
Validation loss: 2.4267222039739083

Epoch: 6| Step: 13
Training loss: 2.7232478852175834
Validation loss: 2.4326482751500724

Epoch: 156| Step: 0
Training loss: 2.842249380049385
Validation loss: 2.4356405266471635

Epoch: 6| Step: 1
Training loss: 2.505231723689424
Validation loss: 2.4603637943312617

Epoch: 6| Step: 2
Training loss: 2.1241032447291253
Validation loss: 2.421917429964834

Epoch: 6| Step: 3
Training loss: 2.0113034310365054
Validation loss: 2.4327010428366296

Epoch: 6| Step: 4
Training loss: 2.741451153695901
Validation loss: 2.4299430785286913

Epoch: 6| Step: 5
Training loss: 2.227685691894195
Validation loss: 2.40930854713489

Epoch: 6| Step: 6
Training loss: 2.7821712039837463
Validation loss: 2.437682793607197

Epoch: 6| Step: 7
Training loss: 2.240268856671203
Validation loss: 2.433726705017924

Epoch: 6| Step: 8
Training loss: 2.6128677474377815
Validation loss: 2.4297834000952125

Epoch: 6| Step: 9
Training loss: 2.4412297787783497
Validation loss: 2.454522937347718

Epoch: 6| Step: 10
Training loss: 2.296745037112942
Validation loss: 2.420951033477569

Epoch: 6| Step: 11
Training loss: 2.59222440779557
Validation loss: 2.437326208944233

Epoch: 6| Step: 12
Training loss: 2.472233692480712
Validation loss: 2.4336618980702815

Epoch: 6| Step: 13
Training loss: 2.6217171258874186
Validation loss: 2.4589894731168647

Epoch: 157| Step: 0
Training loss: 3.075808045200547
Validation loss: 2.4356189492159928

Epoch: 6| Step: 1
Training loss: 2.2145452281392597
Validation loss: 2.4517145542933205

Epoch: 6| Step: 2
Training loss: 2.2414624041932134
Validation loss: 2.441024723423001

Epoch: 6| Step: 3
Training loss: 3.0361973610559647
Validation loss: 2.4329704592988755

Epoch: 6| Step: 4
Training loss: 2.329178130292803
Validation loss: 2.445849499669378

Epoch: 6| Step: 5
Training loss: 2.1520371123449884
Validation loss: 2.4234728498467066

Epoch: 6| Step: 6
Training loss: 2.409902797337425
Validation loss: 2.4401961729383865

Epoch: 6| Step: 7
Training loss: 2.396552820945949
Validation loss: 2.445842101747726

Epoch: 6| Step: 8
Training loss: 2.2969426774415047
Validation loss: 2.421748076152027

Epoch: 6| Step: 9
Training loss: 2.5705903897319438
Validation loss: 2.4332587235815497

Epoch: 6| Step: 10
Training loss: 2.0915265019885614
Validation loss: 2.440835721727543

Epoch: 6| Step: 11
Training loss: 2.627137812251997
Validation loss: 2.4261859317597354

Epoch: 6| Step: 12
Training loss: 2.4738176700690966
Validation loss: 2.4316782141633846

Epoch: 6| Step: 13
Training loss: 2.4651505510576595
Validation loss: 2.437682764160405

Epoch: 158| Step: 0
Training loss: 2.0798891080126456
Validation loss: 2.4392197523747368

Epoch: 6| Step: 1
Training loss: 2.348775130498333
Validation loss: 2.406541426608444

Epoch: 6| Step: 2
Training loss: 2.4469651557614673
Validation loss: 2.4339952538134844

Epoch: 6| Step: 3
Training loss: 2.768470894758204
Validation loss: 2.4408417599675

Epoch: 6| Step: 4
Training loss: 2.4780139219925927
Validation loss: 2.434121686499034

Epoch: 6| Step: 5
Training loss: 2.60043209593546
Validation loss: 2.417418378566884

Epoch: 6| Step: 6
Training loss: 2.2013953162365882
Validation loss: 2.4310032816766243

Epoch: 6| Step: 7
Training loss: 2.512673963151383
Validation loss: 2.412741564401585

Epoch: 6| Step: 8
Training loss: 2.4195338593155733
Validation loss: 2.4471840454444087

Epoch: 6| Step: 9
Training loss: 3.0310126142852893
Validation loss: 2.4212597761882684

Epoch: 6| Step: 10
Training loss: 2.665365040525476
Validation loss: 2.413683847163944

Epoch: 6| Step: 11
Training loss: 1.7288066381966924
Validation loss: 2.4271140966499525

Epoch: 6| Step: 12
Training loss: 2.5076888104414845
Validation loss: 2.436798436475793

Epoch: 6| Step: 13
Training loss: 2.4216993698918876
Validation loss: 2.41371457007621

Epoch: 159| Step: 0
Training loss: 2.172716375710319
Validation loss: 2.4394132647874445

Epoch: 6| Step: 1
Training loss: 2.3874178048410015
Validation loss: 2.45509985093634

Epoch: 6| Step: 2
Training loss: 2.4954216041671087
Validation loss: 2.4187791803979324

Epoch: 6| Step: 3
Training loss: 2.0798078334510794
Validation loss: 2.4176118259161625

Epoch: 6| Step: 4
Training loss: 2.9766666263980444
Validation loss: 2.4361647342328436

Epoch: 6| Step: 5
Training loss: 2.4374851324165965
Validation loss: 2.4330789171617035

Epoch: 6| Step: 6
Training loss: 3.1165848916761316
Validation loss: 2.439564533409381

Epoch: 6| Step: 7
Training loss: 2.7910444126019303
Validation loss: 2.416472605069474

Epoch: 6| Step: 8
Training loss: 2.6294806251138496
Validation loss: 2.4457241774486556

Epoch: 6| Step: 9
Training loss: 2.6643544146221068
Validation loss: 2.4185987559590574

Epoch: 6| Step: 10
Training loss: 2.021415023719799
Validation loss: 2.4448221912826726

Epoch: 6| Step: 11
Training loss: 1.7188040984916517
Validation loss: 2.4294796185285787

Epoch: 6| Step: 12
Training loss: 2.1377673600952636
Validation loss: 2.4220279048585964

Epoch: 6| Step: 13
Training loss: 2.348717473461123
Validation loss: 2.436664087732883

Epoch: 160| Step: 0
Training loss: 2.671165862983038
Validation loss: 2.430553430086565

Epoch: 6| Step: 1
Training loss: 2.1987080768797904
Validation loss: 2.427754892618226

Epoch: 6| Step: 2
Training loss: 2.120657579175675
Validation loss: 2.415934608452617

Epoch: 6| Step: 3
Training loss: 2.3184986153031444
Validation loss: 2.423169128821399

Epoch: 6| Step: 4
Training loss: 1.9467698731672562
Validation loss: 2.4427552037122195

Epoch: 6| Step: 5
Training loss: 2.556419508707108
Validation loss: 2.4217654655633942

Epoch: 6| Step: 6
Training loss: 2.0412641894097874
Validation loss: 2.4447158986780972

Epoch: 6| Step: 7
Training loss: 2.9688609855385004
Validation loss: 2.4402496262665867

Epoch: 6| Step: 8
Training loss: 2.316140582592892
Validation loss: 2.4236226032849366

Epoch: 6| Step: 9
Training loss: 2.324452620849103
Validation loss: 2.445868524740301

Epoch: 6| Step: 10
Training loss: 2.7071656473108514
Validation loss: 2.4605368740439335

Epoch: 6| Step: 11
Training loss: 2.6418227690133183
Validation loss: 2.457195192324508

Epoch: 6| Step: 12
Training loss: 2.4714242478387187
Validation loss: 2.449820681068849

Epoch: 6| Step: 13
Training loss: 2.9847097159217797
Validation loss: 2.4388083939599623

Epoch: 161| Step: 0
Training loss: 2.064522185384035
Validation loss: 2.4326129451784255

Epoch: 6| Step: 1
Training loss: 1.9032801647854931
Validation loss: 2.4324016728423006

Epoch: 6| Step: 2
Training loss: 2.6917743846334066
Validation loss: 2.4299602542075838

Epoch: 6| Step: 3
Training loss: 3.0276039454715282
Validation loss: 2.4448885122381427

Epoch: 6| Step: 4
Training loss: 2.2303704074751836
Validation loss: 2.4311500180577656

Epoch: 6| Step: 5
Training loss: 2.442306474654173
Validation loss: 2.406003437852746

Epoch: 6| Step: 6
Training loss: 2.4324421369800064
Validation loss: 2.4230365181547033

Epoch: 6| Step: 7
Training loss: 2.3880828106130365
Validation loss: 2.44585406020755

Epoch: 6| Step: 8
Training loss: 1.6854075421753147
Validation loss: 2.4339362228924024

Epoch: 6| Step: 9
Training loss: 2.2408734767727982
Validation loss: 2.4569194816601896

Epoch: 6| Step: 10
Training loss: 2.8152410078122747
Validation loss: 2.4230914598711273

Epoch: 6| Step: 11
Training loss: 2.6274934461168895
Validation loss: 2.447259933637515

Epoch: 6| Step: 12
Training loss: 2.233893602704557
Validation loss: 2.4148682432623523

Epoch: 6| Step: 13
Training loss: 3.0952091051497717
Validation loss: 2.4154618611852334

Epoch: 162| Step: 0
Training loss: 1.771161269695923
Validation loss: 2.4327772574121513

Epoch: 6| Step: 1
Training loss: 2.376195606650613
Validation loss: 2.42331443878218

Epoch: 6| Step: 2
Training loss: 1.9141544242116424
Validation loss: 2.4153559131874123

Epoch: 6| Step: 3
Training loss: 2.654180910161085
Validation loss: 2.425349366131973

Epoch: 6| Step: 4
Training loss: 2.2668246546082895
Validation loss: 2.431948717972334

Epoch: 6| Step: 5
Training loss: 2.7522786843337275
Validation loss: 2.4258051120680286

Epoch: 6| Step: 6
Training loss: 2.7888651973060865
Validation loss: 2.440076318924421

Epoch: 6| Step: 7
Training loss: 2.211473056374652
Validation loss: 2.4326698072696904

Epoch: 6| Step: 8
Training loss: 2.701484138053884
Validation loss: 2.4229778487302585

Epoch: 6| Step: 9
Training loss: 2.474333039400348
Validation loss: 2.4080414641549757

Epoch: 6| Step: 10
Training loss: 2.749927606496742
Validation loss: 2.408836357673901

Epoch: 6| Step: 11
Training loss: 2.403093720270968
Validation loss: 2.402075037287194

Epoch: 6| Step: 12
Training loss: 2.207646053057658
Validation loss: 2.4247819891529145

Epoch: 6| Step: 13
Training loss: 2.806704165403744
Validation loss: 2.4350528449042637

Epoch: 163| Step: 0
Training loss: 1.9460440489595097
Validation loss: 2.422724486645506

Epoch: 6| Step: 1
Training loss: 2.358984302230811
Validation loss: 2.417342578013472

Epoch: 6| Step: 2
Training loss: 2.248307969402938
Validation loss: 2.4167703866889765

Epoch: 6| Step: 3
Training loss: 3.073229309384759
Validation loss: 2.4054767573885583

Epoch: 6| Step: 4
Training loss: 2.1016507608818675
Validation loss: 2.430306886842872

Epoch: 6| Step: 5
Training loss: 2.1857632963667726
Validation loss: 2.426100987919102

Epoch: 6| Step: 6
Training loss: 2.2491317769308226
Validation loss: 2.42595004750301

Epoch: 6| Step: 7
Training loss: 2.5760328647223028
Validation loss: 2.4183887939395903

Epoch: 6| Step: 8
Training loss: 1.887944362450983
Validation loss: 2.4241133599036573

Epoch: 6| Step: 9
Training loss: 2.6495695592269564
Validation loss: 2.4318051573736805

Epoch: 6| Step: 10
Training loss: 3.203395925089632
Validation loss: 2.422808663213858

Epoch: 6| Step: 11
Training loss: 2.4078489663483613
Validation loss: 2.4209407527417706

Epoch: 6| Step: 12
Training loss: 2.591769093966125
Validation loss: 2.4415950678832425

Epoch: 6| Step: 13
Training loss: 2.1917692757532636
Validation loss: 2.4411885949685628

Epoch: 164| Step: 0
Training loss: 3.3971339038491184
Validation loss: 2.4353009157052945

Epoch: 6| Step: 1
Training loss: 2.4471824248252387
Validation loss: 2.4347489463656182

Epoch: 6| Step: 2
Training loss: 2.1973116314628016
Validation loss: 2.432443037041991

Epoch: 6| Step: 3
Training loss: 2.1695688202530494
Validation loss: 2.4224471237812475

Epoch: 6| Step: 4
Training loss: 1.5565859451167199
Validation loss: 2.4309604932886932

Epoch: 6| Step: 5
Training loss: 2.1083421226991734
Validation loss: 2.4011324695681058

Epoch: 6| Step: 6
Training loss: 2.3242103384170267
Validation loss: 2.4282123946878067

Epoch: 6| Step: 7
Training loss: 2.2461552089078043
Validation loss: 2.416707809654594

Epoch: 6| Step: 8
Training loss: 2.5610207730917605
Validation loss: 2.4306795466176414

Epoch: 6| Step: 9
Training loss: 2.24577538929244
Validation loss: 2.4192797126864485

Epoch: 6| Step: 10
Training loss: 2.8728316049429155
Validation loss: 2.420676217789128

Epoch: 6| Step: 11
Training loss: 2.125679580629309
Validation loss: 2.429905628164645

Epoch: 6| Step: 12
Training loss: 2.8496478616103893
Validation loss: 2.4213847362417877

Epoch: 6| Step: 13
Training loss: 1.9919621957271008
Validation loss: 2.4195432469965428

Epoch: 165| Step: 0
Training loss: 3.14792312698829
Validation loss: 2.4094359347501983

Epoch: 6| Step: 1
Training loss: 2.920432647633777
Validation loss: 2.4257263480691336

Epoch: 6| Step: 2
Training loss: 1.7263089507338452
Validation loss: 2.4310418885753546

Epoch: 6| Step: 3
Training loss: 2.2524722610103534
Validation loss: 2.42452446237558

Epoch: 6| Step: 4
Training loss: 2.4918344660194585
Validation loss: 2.4427528733244928

Epoch: 6| Step: 5
Training loss: 3.116073065002736
Validation loss: 2.424004927107609

Epoch: 6| Step: 6
Training loss: 2.067090330485634
Validation loss: 2.437338704593181

Epoch: 6| Step: 7
Training loss: 2.6141363321606925
Validation loss: 2.4566434655979488

Epoch: 6| Step: 8
Training loss: 2.0835479880057366
Validation loss: 2.432330730658829

Epoch: 6| Step: 9
Training loss: 2.1135135318493474
Validation loss: 2.4297847938689574

Epoch: 6| Step: 10
Training loss: 2.148522503645106
Validation loss: 2.4103130832625355

Epoch: 6| Step: 11
Training loss: 2.297348285103155
Validation loss: 2.4130599401224813

Epoch: 6| Step: 12
Training loss: 2.3172813679465905
Validation loss: 2.4391056322557962

Epoch: 6| Step: 13
Training loss: 1.393600409652549
Validation loss: 2.4360398619735606

Epoch: 166| Step: 0
Training loss: 2.614896859346841
Validation loss: 2.441014018391608

Epoch: 6| Step: 1
Training loss: 2.5350520460816526
Validation loss: 2.436273096193435

Epoch: 6| Step: 2
Training loss: 2.978369937523076
Validation loss: 2.4386664818569486

Epoch: 6| Step: 3
Training loss: 2.4240370421396285
Validation loss: 2.431880210910751

Epoch: 6| Step: 4
Training loss: 2.1511198188186893
Validation loss: 2.4315282757565435

Epoch: 6| Step: 5
Training loss: 2.496199771259237
Validation loss: 2.454124782016879

Epoch: 6| Step: 6
Training loss: 2.2242966215211166
Validation loss: 2.420446405222055

Epoch: 6| Step: 7
Training loss: 2.2752510519156264
Validation loss: 2.4501048230978144

Epoch: 6| Step: 8
Training loss: 2.3328976451463728
Validation loss: 2.4406366331471765

Epoch: 6| Step: 9
Training loss: 2.0377601176658793
Validation loss: 2.4476539928195096

Epoch: 6| Step: 10
Training loss: 2.4755279594418877
Validation loss: 2.4387618291401703

Epoch: 6| Step: 11
Training loss: 2.7244020663459545
Validation loss: 2.432900032646215

Epoch: 6| Step: 12
Training loss: 2.2698363002282753
Validation loss: 2.435992587534328

Epoch: 6| Step: 13
Training loss: 1.6757724290451117
Validation loss: 2.4319253378498216

Epoch: 167| Step: 0
Training loss: 2.640609560588416
Validation loss: 2.428027445808776

Epoch: 6| Step: 1
Training loss: 2.2856845342879675
Validation loss: 2.4330366723600303

Epoch: 6| Step: 2
Training loss: 2.8245866253643226
Validation loss: 2.4278860006451923

Epoch: 6| Step: 3
Training loss: 1.9119815647321845
Validation loss: 2.4365682206660155

Epoch: 6| Step: 4
Training loss: 2.7250621788560334
Validation loss: 2.442460623717523

Epoch: 6| Step: 5
Training loss: 2.7677366309585185
Validation loss: 2.4195109928490512

Epoch: 6| Step: 6
Training loss: 2.718757453995933
Validation loss: 2.406829777986898

Epoch: 6| Step: 7
Training loss: 1.6941864211542403
Validation loss: 2.425234439005964

Epoch: 6| Step: 8
Training loss: 2.1463147583191438
Validation loss: 2.421988073296855

Epoch: 6| Step: 9
Training loss: 1.6662710515013857
Validation loss: 2.450101261879877

Epoch: 6| Step: 10
Training loss: 2.0078742466794366
Validation loss: 2.4324932692474204

Epoch: 6| Step: 11
Training loss: 2.5330517796443432
Validation loss: 2.4121338420794625

Epoch: 6| Step: 12
Training loss: 3.0385021487440755
Validation loss: 2.414156124929004

Epoch: 6| Step: 13
Training loss: 2.0078618974954585
Validation loss: 2.4291697950555315

Epoch: 168| Step: 0
Training loss: 2.540496327425144
Validation loss: 2.4323173012690997

Epoch: 6| Step: 1
Training loss: 2.064660876601742
Validation loss: 2.4165039746772923

Epoch: 6| Step: 2
Training loss: 2.4007459832185374
Validation loss: 2.4329540677607397

Epoch: 6| Step: 3
Training loss: 2.1289475743193957
Validation loss: 2.421119315879872

Epoch: 6| Step: 4
Training loss: 2.6592604687567065
Validation loss: 2.4306930130052646

Epoch: 6| Step: 5
Training loss: 2.5054848585095666
Validation loss: 2.4204123429181097

Epoch: 6| Step: 6
Training loss: 2.3447672353042526
Validation loss: 2.4030056616228457

Epoch: 6| Step: 7
Training loss: 2.5797953425416162
Validation loss: 2.4500692970097435

Epoch: 6| Step: 8
Training loss: 2.5423058086642656
Validation loss: 2.4281195176328048

Epoch: 6| Step: 9
Training loss: 3.1669640317801
Validation loss: 2.4149584059709825

Epoch: 6| Step: 10
Training loss: 1.4982715821120844
Validation loss: 2.4237830482672758

Epoch: 6| Step: 11
Training loss: 2.1477082835610743
Validation loss: 2.4224131038970835

Epoch: 6| Step: 12
Training loss: 2.4745564805108082
Validation loss: 2.4046367270685978

Epoch: 6| Step: 13
Training loss: 2.0063932278569023
Validation loss: 2.444262842835783

Epoch: 169| Step: 0
Training loss: 1.812082900363534
Validation loss: 2.4103161884790594

Epoch: 6| Step: 1
Training loss: 2.2598719724327547
Validation loss: 2.4434229878055436

Epoch: 6| Step: 2
Training loss: 3.068489756688436
Validation loss: 2.453805344607481

Epoch: 6| Step: 3
Training loss: 2.495424852606731
Validation loss: 2.438467097368454

Epoch: 6| Step: 4
Training loss: 3.216339097284474
Validation loss: 2.454788062303106

Epoch: 6| Step: 5
Training loss: 2.2957718464209576
Validation loss: 2.453711356089199

Epoch: 6| Step: 6
Training loss: 2.1975364416440324
Validation loss: 2.4243349758718726

Epoch: 6| Step: 7
Training loss: 1.951371527338533
Validation loss: 2.4564639958939116

Epoch: 6| Step: 8
Training loss: 2.1263817053746266
Validation loss: 2.4293676363039274

Epoch: 6| Step: 9
Training loss: 2.5121451056052098
Validation loss: 2.4421932850203

Epoch: 6| Step: 10
Training loss: 1.7459742699351657
Validation loss: 2.4445361363816707

Epoch: 6| Step: 11
Training loss: 2.5854974931311197
Validation loss: 2.4171183821307505

Epoch: 6| Step: 12
Training loss: 2.464863192183871
Validation loss: 2.432516880512848

Epoch: 6| Step: 13
Training loss: 2.348311093317347
Validation loss: 2.428654384368174

Epoch: 170| Step: 0
Training loss: 2.894286769575713
Validation loss: 2.4201297141227287

Epoch: 6| Step: 1
Training loss: 1.7458256936038918
Validation loss: 2.434489415334818

Epoch: 6| Step: 2
Training loss: 1.9505528106580805
Validation loss: 2.440935476283995

Epoch: 6| Step: 3
Training loss: 3.8312280651167816
Validation loss: 2.406667898129666

Epoch: 6| Step: 4
Training loss: 2.226399947808142
Validation loss: 2.416430346851252

Epoch: 6| Step: 5
Training loss: 2.220604135257994
Validation loss: 2.4408197989358302

Epoch: 6| Step: 6
Training loss: 2.2168071998658236
Validation loss: 2.431415769490748

Epoch: 6| Step: 7
Training loss: 2.1151482590099384
Validation loss: 2.429013434705685

Epoch: 6| Step: 8
Training loss: 1.7920798631055177
Validation loss: 2.4121144584677587

Epoch: 6| Step: 9
Training loss: 2.507151103520446
Validation loss: 2.418831869091574

Epoch: 6| Step: 10
Training loss: 2.0454329441355634
Validation loss: 2.409471721071619

Epoch: 6| Step: 11
Training loss: 2.4067820171422984
Validation loss: 2.3991537496689093

Epoch: 6| Step: 12
Training loss: 2.268950133520907
Validation loss: 2.4451153916319486

Epoch: 6| Step: 13
Training loss: 2.697108369810564
Validation loss: 2.4382420271005847

Epoch: 171| Step: 0
Training loss: 3.046465254399703
Validation loss: 2.443958322540404

Epoch: 6| Step: 1
Training loss: 1.7843668922467264
Validation loss: 2.420547747260909

Epoch: 6| Step: 2
Training loss: 1.495776349454858
Validation loss: 2.4056181219834802

Epoch: 6| Step: 3
Training loss: 1.9367146284606582
Validation loss: 2.4162646375786045

Epoch: 6| Step: 4
Training loss: 2.515000733817204
Validation loss: 2.4272528792532433

Epoch: 6| Step: 5
Training loss: 2.5523568350669903
Validation loss: 2.4156173422997593

Epoch: 6| Step: 6
Training loss: 2.7392001929657415
Validation loss: 2.4212157898752897

Epoch: 6| Step: 7
Training loss: 1.704893121809462
Validation loss: 2.413929013100197

Epoch: 6| Step: 8
Training loss: 2.8777548818115206
Validation loss: 2.4249502969580354

Epoch: 6| Step: 9
Training loss: 2.7378937668849677
Validation loss: 2.423797530811229

Epoch: 6| Step: 10
Training loss: 1.8256194069478606
Validation loss: 2.4162105936880596

Epoch: 6| Step: 11
Training loss: 2.6805982460044127
Validation loss: 2.442232769200342

Epoch: 6| Step: 12
Training loss: 2.4551337697863156
Validation loss: 2.422428195213065

Epoch: 6| Step: 13
Training loss: 2.639809747834253
Validation loss: 2.4442145013222314

Epoch: 172| Step: 0
Training loss: 2.351421770212793
Validation loss: 2.4299461328121605

Epoch: 6| Step: 1
Training loss: 2.5031813406824566
Validation loss: 2.4480488232031345

Epoch: 6| Step: 2
Training loss: 2.4545152940085195
Validation loss: 2.446622816483444

Epoch: 6| Step: 3
Training loss: 2.8398304851070013
Validation loss: 2.430472667665606

Epoch: 6| Step: 4
Training loss: 2.239824917796932
Validation loss: 2.44215573383284

Epoch: 6| Step: 5
Training loss: 2.9699749477370254
Validation loss: 2.4486785191862745

Epoch: 6| Step: 6
Training loss: 2.476857068567008
Validation loss: 2.476159083578033

Epoch: 6| Step: 7
Training loss: 1.8817941277951467
Validation loss: 2.4303609068278442

Epoch: 6| Step: 8
Training loss: 2.644321089582502
Validation loss: 2.439314982393835

Epoch: 6| Step: 9
Training loss: 2.2316335652949335
Validation loss: 2.4370627293700466

Epoch: 6| Step: 10
Training loss: 2.568443105514913
Validation loss: 2.47927235948241

Epoch: 6| Step: 11
Training loss: 1.8991085169572821
Validation loss: 2.4453844520288506

Epoch: 6| Step: 12
Training loss: 1.7730511483970657
Validation loss: 2.4375120998278925

Epoch: 6| Step: 13
Training loss: 2.075216337209671
Validation loss: 2.449781847657451

Epoch: 173| Step: 0
Training loss: 2.0632242029487005
Validation loss: 2.4104417530852125

Epoch: 6| Step: 1
Training loss: 2.4898531992277846
Validation loss: 2.424963357485982

Epoch: 6| Step: 2
Training loss: 2.35546085489193
Validation loss: 2.4252306927498153

Epoch: 6| Step: 3
Training loss: 2.4639218596849912
Validation loss: 2.412326312530096

Epoch: 6| Step: 4
Training loss: 2.2377794911667293
Validation loss: 2.3984593873453095

Epoch: 6| Step: 5
Training loss: 2.193049122717245
Validation loss: 2.4215514423073743

Epoch: 6| Step: 6
Training loss: 2.728497100308447
Validation loss: 2.410965514701316

Epoch: 6| Step: 7
Training loss: 2.4040003577436795
Validation loss: 2.4217779938651116

Epoch: 6| Step: 8
Training loss: 2.5209178332413664
Validation loss: 2.430121291392304

Epoch: 6| Step: 9
Training loss: 2.490409767107708
Validation loss: 2.441819683156118

Epoch: 6| Step: 10
Training loss: 2.8024779730823606
Validation loss: 2.416764372638677

Epoch: 6| Step: 11
Training loss: 2.3403499100382437
Validation loss: 2.428371252682674

Epoch: 6| Step: 12
Training loss: 1.9024343606099643
Validation loss: 2.418349539016947

Epoch: 6| Step: 13
Training loss: 2.1256294440223296
Validation loss: 2.4175697784868015

Epoch: 174| Step: 0
Training loss: 2.358038416328725
Validation loss: 2.417250663101289

Epoch: 6| Step: 1
Training loss: 2.2124728745344058
Validation loss: 2.4365823615506694

Epoch: 6| Step: 2
Training loss: 2.391602459709152
Validation loss: 2.4125974984530103

Epoch: 6| Step: 3
Training loss: 1.5046535468306284
Validation loss: 2.4416697086720003

Epoch: 6| Step: 4
Training loss: 2.3878187276386815
Validation loss: 2.3971396221365007

Epoch: 6| Step: 5
Training loss: 2.1934278550501856
Validation loss: 2.4405249711499195

Epoch: 6| Step: 6
Training loss: 2.367393862350202
Validation loss: 2.4023389627986056

Epoch: 6| Step: 7
Training loss: 2.6906824121320123
Validation loss: 2.4217954222287585

Epoch: 6| Step: 8
Training loss: 2.601216977747113
Validation loss: 2.4179751623566546

Epoch: 6| Step: 9
Training loss: 2.805963677495457
Validation loss: 2.4131656144426348

Epoch: 6| Step: 10
Training loss: 2.1107970918821506
Validation loss: 2.416263916103041

Epoch: 6| Step: 11
Training loss: 2.483289661492835
Validation loss: 2.423066636852402

Epoch: 6| Step: 12
Training loss: 2.8936642726780923
Validation loss: 2.4111347359212383

Epoch: 6| Step: 13
Training loss: 1.9286424532936333
Validation loss: 2.4116026553158174

Epoch: 175| Step: 0
Training loss: 2.5252654361009483
Validation loss: 2.4271712924722433

Epoch: 6| Step: 1
Training loss: 2.000401218224612
Validation loss: 2.402218692704942

Epoch: 6| Step: 2
Training loss: 2.243765989793848
Validation loss: 2.426135502392683

Epoch: 6| Step: 3
Training loss: 2.657037326589319
Validation loss: 2.4425689876517582

Epoch: 6| Step: 4
Training loss: 2.2384922533955667
Validation loss: 2.4474554588723483

Epoch: 6| Step: 5
Training loss: 2.6145958665848807
Validation loss: 2.4345380426215972

Epoch: 6| Step: 6
Training loss: 2.13208968102387
Validation loss: 2.426981411580323

Epoch: 6| Step: 7
Training loss: 2.6388941402271513
Validation loss: 2.4421692030730804

Epoch: 6| Step: 8
Training loss: 2.7623623498652607
Validation loss: 2.43233111483641

Epoch: 6| Step: 9
Training loss: 2.8126702151183087
Validation loss: 2.429752986930074

Epoch: 6| Step: 10
Training loss: 1.6990860108893553
Validation loss: 2.4208356423278996

Epoch: 6| Step: 11
Training loss: 2.192672499653075
Validation loss: 2.4446657844386004

Epoch: 6| Step: 12
Training loss: 1.7482324938547447
Validation loss: 2.4064644210734323

Epoch: 6| Step: 13
Training loss: 2.9441885587078276
Validation loss: 2.4147245367002657

Epoch: 176| Step: 0
Training loss: 2.519368484325874
Validation loss: 2.424545181623576

Epoch: 6| Step: 1
Training loss: 2.693695998922862
Validation loss: 2.4273373191325294

Epoch: 6| Step: 2
Training loss: 2.554227268398243
Validation loss: 2.4111232581028825

Epoch: 6| Step: 3
Training loss: 1.866924506783531
Validation loss: 2.429129965566883

Epoch: 6| Step: 4
Training loss: 1.9419080979811167
Validation loss: 2.4361329442950903

Epoch: 6| Step: 5
Training loss: 2.0438984201650348
Validation loss: 2.4010970746541704

Epoch: 6| Step: 6
Training loss: 2.2053987930450916
Validation loss: 2.4171486148739403

Epoch: 6| Step: 7
Training loss: 2.6614116109689774
Validation loss: 2.3998289538261894

Epoch: 6| Step: 8
Training loss: 1.9042699567408377
Validation loss: 2.409089742691303

Epoch: 6| Step: 9
Training loss: 2.8559469717536334
Validation loss: 2.4100995922943023

Epoch: 6| Step: 10
Training loss: 1.637362333145496
Validation loss: 2.410945854799639

Epoch: 6| Step: 11
Training loss: 2.408127881782762
Validation loss: 2.410306481938623

Epoch: 6| Step: 12
Training loss: 2.951627159723031
Validation loss: 2.424421966372486

Epoch: 6| Step: 13
Training loss: 2.1597971833342196
Validation loss: 2.4039998629312

Epoch: 177| Step: 0
Training loss: 2.456876959148549
Validation loss: 2.4396952432228876

Epoch: 6| Step: 1
Training loss: 2.7407056494300197
Validation loss: 2.3990337890133233

Epoch: 6| Step: 2
Training loss: 2.3052409913694043
Validation loss: 2.409337703173082

Epoch: 6| Step: 3
Training loss: 2.3349128440585027
Validation loss: 2.408691447758839

Epoch: 6| Step: 4
Training loss: 2.5987414395043174
Validation loss: 2.4323205328034736

Epoch: 6| Step: 5
Training loss: 2.2338701224622572
Validation loss: 2.417428967505857

Epoch: 6| Step: 6
Training loss: 2.140139448132386
Validation loss: 2.4320936762506786

Epoch: 6| Step: 7
Training loss: 2.119009100001095
Validation loss: 2.4308209937535517

Epoch: 6| Step: 8
Training loss: 2.2593146478340462
Validation loss: 2.4058092169319427

Epoch: 6| Step: 9
Training loss: 3.1928640372231434
Validation loss: 2.4081649884373606

Epoch: 6| Step: 10
Training loss: 2.1523649072732254
Validation loss: 2.4255503151099878

Epoch: 6| Step: 11
Training loss: 2.473391840809125
Validation loss: 2.42099727798205

Epoch: 6| Step: 12
Training loss: 1.5020426511435991
Validation loss: 2.4149653443642407

Epoch: 6| Step: 13
Training loss: 2.097059452682135
Validation loss: 2.443900490004344

Epoch: 178| Step: 0
Training loss: 2.3971474623217746
Validation loss: 2.42432927720574

Epoch: 6| Step: 1
Training loss: 1.759726740908155
Validation loss: 2.397935052636592

Epoch: 6| Step: 2
Training loss: 2.3540116543218006
Validation loss: 2.4303025439683226

Epoch: 6| Step: 3
Training loss: 2.7456271343539855
Validation loss: 2.4066878709985837

Epoch: 6| Step: 4
Training loss: 1.9761944454523124
Validation loss: 2.4141413291525162

Epoch: 6| Step: 5
Training loss: 2.1848411750246304
Validation loss: 2.435991747718316

Epoch: 6| Step: 6
Training loss: 2.4660183243515443
Validation loss: 2.395617919875285

Epoch: 6| Step: 7
Training loss: 2.240056849848181
Validation loss: 2.4662755047690927

Epoch: 6| Step: 8
Training loss: 2.4700379693823393
Validation loss: 2.387311332819104

Epoch: 6| Step: 9
Training loss: 1.9563966129438226
Validation loss: 2.4167411203623277

Epoch: 6| Step: 10
Training loss: 3.259378546240131
Validation loss: 2.4343313536209847

Epoch: 6| Step: 11
Training loss: 2.245658819133464
Validation loss: 2.4233799519441317

Epoch: 6| Step: 12
Training loss: 2.232616879948146
Validation loss: 2.43473094368494

Epoch: 6| Step: 13
Training loss: 1.9029755532102146
Validation loss: 2.405506801803496

Epoch: 179| Step: 0
Training loss: 2.851465510979001
Validation loss: 2.4130214165732937

Epoch: 6| Step: 1
Training loss: 2.076566183231896
Validation loss: 2.400159819128674

Epoch: 6| Step: 2
Training loss: 3.0533436504617266
Validation loss: 2.415272137086411

Epoch: 6| Step: 3
Training loss: 2.0481804332152027
Validation loss: 2.4017555640597315

Epoch: 6| Step: 4
Training loss: 2.751218439152526
Validation loss: 2.4244042914751223

Epoch: 6| Step: 5
Training loss: 2.2123947463350295
Validation loss: 2.3950459331764726

Epoch: 6| Step: 6
Training loss: 1.733151803536777
Validation loss: 2.436522042320129

Epoch: 6| Step: 7
Training loss: 2.420849195243446
Validation loss: 2.3946167934044644

Epoch: 6| Step: 8
Training loss: 2.4564046136469546
Validation loss: 2.4025855798304843

Epoch: 6| Step: 9
Training loss: 2.1520535088165373
Validation loss: 2.4072975496172564

Epoch: 6| Step: 10
Training loss: 2.1214410486996593
Validation loss: 2.4198461094311052

Epoch: 6| Step: 11
Training loss: 2.16671623271098
Validation loss: 2.4163972809139413

Epoch: 6| Step: 12
Training loss: 1.8597970691851853
Validation loss: 2.40194457818231

Epoch: 6| Step: 13
Training loss: 2.5542002922031055
Validation loss: 2.4310632693609184

Epoch: 180| Step: 0
Training loss: 1.7749488205314488
Validation loss: 2.4270989272600616

Epoch: 6| Step: 1
Training loss: 2.4540283095041215
Validation loss: 2.436553069627102

Epoch: 6| Step: 2
Training loss: 2.7531134580268493
Validation loss: 2.4263984495143114

Epoch: 6| Step: 3
Training loss: 2.7827543840546003
Validation loss: 2.392330988563217

Epoch: 6| Step: 4
Training loss: 2.1631988013726926
Validation loss: 2.413458450472315

Epoch: 6| Step: 5
Training loss: 2.4356995804673987
Validation loss: 2.4350304410686325

Epoch: 6| Step: 6
Training loss: 2.477488732644336
Validation loss: 2.4211687119987224

Epoch: 6| Step: 7
Training loss: 2.0268089456349143
Validation loss: 2.4124031421078485

Epoch: 6| Step: 8
Training loss: 2.5353774340145407
Validation loss: 2.4116129067624508

Epoch: 6| Step: 9
Training loss: 2.6648245250195197
Validation loss: 2.424943708521908

Epoch: 6| Step: 10
Training loss: 1.6217351540782312
Validation loss: 2.4357823287688474

Epoch: 6| Step: 11
Training loss: 1.9450211517439087
Validation loss: 2.437804127145007

Epoch: 6| Step: 12
Training loss: 2.136835238055271
Validation loss: 2.4185020964793225

Epoch: 6| Step: 13
Training loss: 2.505385415737543
Validation loss: 2.4027026274141727

Epoch: 181| Step: 0
Training loss: 2.5400552070805644
Validation loss: 2.4315587710945983

Epoch: 6| Step: 1
Training loss: 2.764361594036317
Validation loss: 2.3967042254108795

Epoch: 6| Step: 2
Training loss: 2.6025677362691058
Validation loss: 2.409550557843551

Epoch: 6| Step: 3
Training loss: 1.7737964149300371
Validation loss: 2.4103714180139915

Epoch: 6| Step: 4
Training loss: 2.333111741125128
Validation loss: 2.402493386319215

Epoch: 6| Step: 5
Training loss: 2.8277769770326544
Validation loss: 2.432708236760837

Epoch: 6| Step: 6
Training loss: 2.512738390188938
Validation loss: 2.3965734225960995

Epoch: 6| Step: 7
Training loss: 2.6076810900821483
Validation loss: 2.4076877992035106

Epoch: 6| Step: 8
Training loss: 1.7976894357362698
Validation loss: 2.391536195030411

Epoch: 6| Step: 9
Training loss: 2.342336915322822
Validation loss: 2.400298712455654

Epoch: 6| Step: 10
Training loss: 1.8929275489319106
Validation loss: 2.4293951919054093

Epoch: 6| Step: 11
Training loss: 2.0880394107343925
Validation loss: 2.405069065936171

Epoch: 6| Step: 12
Training loss: 1.6143167419200632
Validation loss: 2.418304020932907

Epoch: 6| Step: 13
Training loss: 2.1818055284378852
Validation loss: 2.431789571838592

Epoch: 182| Step: 0
Training loss: 2.2328757211051578
Validation loss: 2.406383492056754

Epoch: 6| Step: 1
Training loss: 2.7119331400402524
Validation loss: 2.3954040856175367

Epoch: 6| Step: 2
Training loss: 2.2843686042414313
Validation loss: 2.412787212923878

Epoch: 6| Step: 3
Training loss: 2.808233543079494
Validation loss: 2.4325423627377614

Epoch: 6| Step: 4
Training loss: 2.340612116575754
Validation loss: 2.4152613964593517

Epoch: 6| Step: 5
Training loss: 2.379533255995373
Validation loss: 2.4269514059009576

Epoch: 6| Step: 6
Training loss: 1.7980687695549433
Validation loss: 2.410398086256577

Epoch: 6| Step: 7
Training loss: 1.9722560363282582
Validation loss: 2.4020148611651786

Epoch: 6| Step: 8
Training loss: 1.8745031334257354
Validation loss: 2.418918787241538

Epoch: 6| Step: 9
Training loss: 2.992400557699
Validation loss: 2.426683320497729

Epoch: 6| Step: 10
Training loss: 2.2031495654312514
Validation loss: 2.417936418125556

Epoch: 6| Step: 11
Training loss: 2.1182398134002614
Validation loss: 2.40044316302958

Epoch: 6| Step: 12
Training loss: 2.6087084621308425
Validation loss: 2.410742575585853

Epoch: 6| Step: 13
Training loss: 1.3005817707142246
Validation loss: 2.4136074088666923

Epoch: 183| Step: 0
Training loss: 2.4835944719004535
Validation loss: 2.4122668034201773

Epoch: 6| Step: 1
Training loss: 2.791380359904337
Validation loss: 2.391279791086919

Epoch: 6| Step: 2
Training loss: 1.9035439592300119
Validation loss: 2.4515453692548737

Epoch: 6| Step: 3
Training loss: 2.418095747119276
Validation loss: 2.4153880269959056

Epoch: 6| Step: 4
Training loss: 1.8307855270920503
Validation loss: 2.4290483130734293

Epoch: 6| Step: 5
Training loss: 2.8623286766522873
Validation loss: 2.4163756021997984

Epoch: 6| Step: 6
Training loss: 1.6954823070515306
Validation loss: 2.4211502901559

Epoch: 6| Step: 7
Training loss: 2.028175139431927
Validation loss: 2.4291638982427743

Epoch: 6| Step: 8
Training loss: 1.9498870865824878
Validation loss: 2.432767692125512

Epoch: 6| Step: 9
Training loss: 1.786596339227079
Validation loss: 2.4343894503443884

Epoch: 6| Step: 10
Training loss: 2.914709106378317
Validation loss: 2.405996346818169

Epoch: 6| Step: 11
Training loss: 2.020443147829416
Validation loss: 2.4371249928272065

Epoch: 6| Step: 12
Training loss: 2.752669339354309
Validation loss: 2.4161855217250956

Epoch: 6| Step: 13
Training loss: 2.7697309629156392
Validation loss: 2.3924986828826222

Epoch: 184| Step: 0
Training loss: 2.929687337239579
Validation loss: 2.4214574246778846

Epoch: 6| Step: 1
Training loss: 2.3023734161671396
Validation loss: 2.406869039185994

Epoch: 6| Step: 2
Training loss: 2.3706045133076086
Validation loss: 2.398829546848027

Epoch: 6| Step: 3
Training loss: 1.9560737018546623
Validation loss: 2.4283248698954965

Epoch: 6| Step: 4
Training loss: 2.556240344787122
Validation loss: 2.425723435375441

Epoch: 6| Step: 5
Training loss: 2.5276515484360735
Validation loss: 2.4226953604972183

Epoch: 6| Step: 6
Training loss: 2.355993006930635
Validation loss: 2.408511635933456

Epoch: 6| Step: 7
Training loss: 2.0316076110610153
Validation loss: 2.412161883102808

Epoch: 6| Step: 8
Training loss: 2.328854644930498
Validation loss: 2.399152854215146

Epoch: 6| Step: 9
Training loss: 1.793507480508961
Validation loss: 2.4064830991542023

Epoch: 6| Step: 10
Training loss: 2.448025304669759
Validation loss: 2.431692630445457

Epoch: 6| Step: 11
Training loss: 2.3681328525649614
Validation loss: 2.4207109960008726

Epoch: 6| Step: 12
Training loss: 2.146303205680435
Validation loss: 2.4014396995988156

Epoch: 6| Step: 13
Training loss: 1.9405367034138115
Validation loss: 2.4095987500280245

Epoch: 185| Step: 0
Training loss: 2.5569859235821415
Validation loss: 2.434132532428633

Epoch: 6| Step: 1
Training loss: 2.59447956165814
Validation loss: 2.425381208623719

Epoch: 6| Step: 2
Training loss: 2.303748298267682
Validation loss: 2.416203970810559

Epoch: 6| Step: 3
Training loss: 2.7510786542003265
Validation loss: 2.4235012103060716

Epoch: 6| Step: 4
Training loss: 2.569381777254045
Validation loss: 2.4012330541091615

Epoch: 6| Step: 5
Training loss: 2.660841171662489
Validation loss: 2.431004838998708

Epoch: 6| Step: 6
Training loss: 2.539254800410201
Validation loss: 2.4053188419262033

Epoch: 6| Step: 7
Training loss: 1.873496724545558
Validation loss: 2.3946737606917714

Epoch: 6| Step: 8
Training loss: 2.1446906692368075
Validation loss: 2.4060269750363377

Epoch: 6| Step: 9
Training loss: 1.4867843348860401
Validation loss: 2.4050245378039103

Epoch: 6| Step: 10
Training loss: 2.133406895124222
Validation loss: 2.419085255236573

Epoch: 6| Step: 11
Training loss: 1.2667174157634036
Validation loss: 2.4020365067271205

Epoch: 6| Step: 12
Training loss: 2.4426141543150757
Validation loss: 2.3933180743710882

Epoch: 6| Step: 13
Training loss: 2.2675974711168703
Validation loss: 2.4139347989776474

Epoch: 186| Step: 0
Training loss: 2.96949549901608
Validation loss: 2.416981139494952

Epoch: 6| Step: 1
Training loss: 2.195375597715609
Validation loss: 2.399096685729017

Epoch: 6| Step: 2
Training loss: 2.1918206188633818
Validation loss: 2.4316036035235182

Epoch: 6| Step: 3
Training loss: 2.8377639311662834
Validation loss: 2.425025981285631

Epoch: 6| Step: 4
Training loss: 2.2711186594297446
Validation loss: 2.4043659696661006

Epoch: 6| Step: 5
Training loss: 1.9836878149889956
Validation loss: 2.425971894806873

Epoch: 6| Step: 6
Training loss: 2.468448958572545
Validation loss: 2.431804815808641

Epoch: 6| Step: 7
Training loss: 1.8491018821618845
Validation loss: 2.4171341609016754

Epoch: 6| Step: 8
Training loss: 2.1870954956987836
Validation loss: 2.423615427876533

Epoch: 6| Step: 9
Training loss: 2.0069635281064313
Validation loss: 2.421559504118741

Epoch: 6| Step: 10
Training loss: 2.5974154023684655
Validation loss: 2.408410618772478

Epoch: 6| Step: 11
Training loss: 1.780997275108896
Validation loss: 2.424413086114105

Epoch: 6| Step: 12
Training loss: 2.310826701409111
Validation loss: 2.4154924341228488

Epoch: 6| Step: 13
Training loss: 2.5432721263208364
Validation loss: 2.455163683728443

Epoch: 187| Step: 0
Training loss: 3.2771196800264706
Validation loss: 2.422734520138916

Epoch: 6| Step: 1
Training loss: 2.3964105546520518
Validation loss: 2.40936495317847

Epoch: 6| Step: 2
Training loss: 2.471643032373401
Validation loss: 2.3929919046326127

Epoch: 6| Step: 3
Training loss: 1.949466727771936
Validation loss: 2.4536356778796797

Epoch: 6| Step: 4
Training loss: 2.1330926173222546
Validation loss: 2.4165087369998846

Epoch: 6| Step: 5
Training loss: 2.3316335163209403
Validation loss: 2.397123831534107

Epoch: 6| Step: 6
Training loss: 2.490371185733306
Validation loss: 2.399713542679141

Epoch: 6| Step: 7
Training loss: 2.113214911302809
Validation loss: 2.4443963921796783

Epoch: 6| Step: 8
Training loss: 2.0133493277985988
Validation loss: 2.418613099422241

Epoch: 6| Step: 9
Training loss: 2.1889094580357855
Validation loss: 2.405204269776741

Epoch: 6| Step: 10
Training loss: 1.892395073666608
Validation loss: 2.4476713128710776

Epoch: 6| Step: 11
Training loss: 2.593063907193251
Validation loss: 2.4138420841446067

Epoch: 6| Step: 12
Training loss: 1.908711454530646
Validation loss: 2.4253202260540117

Epoch: 6| Step: 13
Training loss: 1.3941787145899327
Validation loss: 2.402700851955344

Epoch: 188| Step: 0
Training loss: 2.5097067265705677
Validation loss: 2.4261322721301393

Epoch: 6| Step: 1
Training loss: 2.3686186741480677
Validation loss: 2.4021456771766196

Epoch: 6| Step: 2
Training loss: 2.3412928607559245
Validation loss: 2.4148953055921822

Epoch: 6| Step: 3
Training loss: 2.37402393964027
Validation loss: 2.4192335826471854

Epoch: 6| Step: 4
Training loss: 2.8297411268472428
Validation loss: 2.4199199755132805

Epoch: 6| Step: 5
Training loss: 2.3951821368252757
Validation loss: 2.3829063715768832

Epoch: 6| Step: 6
Training loss: 2.06530986465376
Validation loss: 2.407330940751084

Epoch: 6| Step: 7
Training loss: 1.727742892025907
Validation loss: 2.4000131435786387

Epoch: 6| Step: 8
Training loss: 1.8614459005523054
Validation loss: 2.424418311914295

Epoch: 6| Step: 9
Training loss: 1.8190200867301423
Validation loss: 2.4446350069134604

Epoch: 6| Step: 10
Training loss: 2.154081608798065
Validation loss: 2.4061031118263183

Epoch: 6| Step: 11
Training loss: 2.115251845748199
Validation loss: 2.4026032669218886

Epoch: 6| Step: 12
Training loss: 2.280754558116703
Validation loss: 2.436140259100855

Epoch: 6| Step: 13
Training loss: 3.1879134564493037
Validation loss: 2.3992279108871086

Epoch: 189| Step: 0
Training loss: 2.0022636954222235
Validation loss: 2.4279259223417835

Epoch: 6| Step: 1
Training loss: 2.478113308622819
Validation loss: 2.4051553148291216

Epoch: 6| Step: 2
Training loss: 2.6625739718625
Validation loss: 2.4028318664101413

Epoch: 6| Step: 3
Training loss: 1.926676884308399
Validation loss: 2.4360152698239443

Epoch: 6| Step: 4
Training loss: 2.203441191364378
Validation loss: 2.4063847651496584

Epoch: 6| Step: 5
Training loss: 1.921112405469988
Validation loss: 2.4272015927571493

Epoch: 6| Step: 6
Training loss: 2.2512042743417253
Validation loss: 2.3983528560778877

Epoch: 6| Step: 7
Training loss: 2.1915015541609018
Validation loss: 2.4002720441504573

Epoch: 6| Step: 8
Training loss: 2.0843801792886834
Validation loss: 2.4134477033671082

Epoch: 6| Step: 9
Training loss: 2.5596686747839867
Validation loss: 2.4065078972170943

Epoch: 6| Step: 10
Training loss: 1.8967485489402922
Validation loss: 2.3971351785335435

Epoch: 6| Step: 11
Training loss: 1.8054714069157078
Validation loss: 2.4052952285340465

Epoch: 6| Step: 12
Training loss: 3.322651692092894
Validation loss: 2.415803356941085

Epoch: 6| Step: 13
Training loss: 2.10013438203545
Validation loss: 2.432282600474647

Epoch: 190| Step: 0
Training loss: 2.25953898698735
Validation loss: 2.389930498213833

Epoch: 6| Step: 1
Training loss: 2.6281915971480427
Validation loss: 2.4340709654965798

Epoch: 6| Step: 2
Training loss: 1.5790873699694612
Validation loss: 2.408302848447834

Epoch: 6| Step: 3
Training loss: 2.40682619800685
Validation loss: 2.4251493947118803

Epoch: 6| Step: 4
Training loss: 2.42701205911615
Validation loss: 2.4052857927048

Epoch: 6| Step: 5
Training loss: 2.932524017469782
Validation loss: 2.3934884907936262

Epoch: 6| Step: 6
Training loss: 2.3979512569828185
Validation loss: 2.4102266094323115

Epoch: 6| Step: 7
Training loss: 2.644506006388011
Validation loss: 2.421271480713816

Epoch: 6| Step: 8
Training loss: 2.241389860436985
Validation loss: 2.407244002498222

Epoch: 6| Step: 9
Training loss: 1.776814342084674
Validation loss: 2.4133410338278543

Epoch: 6| Step: 10
Training loss: 2.373119010927782
Validation loss: 2.394623914389492

Epoch: 6| Step: 11
Training loss: 1.9451303664893929
Validation loss: 2.3969452434353946

Epoch: 6| Step: 12
Training loss: 2.0165069779573983
Validation loss: 2.4073278407358063

Epoch: 6| Step: 13
Training loss: 2.305528597182598
Validation loss: 2.406082742538293

Epoch: 191| Step: 0
Training loss: 2.3369426287169635
Validation loss: 2.3875846803106593

Epoch: 6| Step: 1
Training loss: 2.3290258111371096
Validation loss: 2.382278932960771

Epoch: 6| Step: 2
Training loss: 2.4562098065453473
Validation loss: 2.414057352668724

Epoch: 6| Step: 3
Training loss: 1.9573676454077145
Validation loss: 2.4080527820662136

Epoch: 6| Step: 4
Training loss: 2.6936414763148386
Validation loss: 2.406226368044812

Epoch: 6| Step: 5
Training loss: 2.0511961308390743
Validation loss: 2.4234433910069537

Epoch: 6| Step: 6
Training loss: 2.9682507546911547
Validation loss: 2.4195916766799535

Epoch: 6| Step: 7
Training loss: 2.0383519363282208
Validation loss: 2.411626258506073

Epoch: 6| Step: 8
Training loss: 2.1324227783961494
Validation loss: 2.4169506278162314

Epoch: 6| Step: 9
Training loss: 1.6174342754990332
Validation loss: 2.409731562938363

Epoch: 6| Step: 10
Training loss: 1.9499676628365914
Validation loss: 2.41490609243427

Epoch: 6| Step: 11
Training loss: 2.5002128510463084
Validation loss: 2.388896406465063

Epoch: 6| Step: 12
Training loss: 2.46930697954477
Validation loss: 2.4107093130601784

Epoch: 6| Step: 13
Training loss: 2.1086351015347726
Validation loss: 2.4432330216201597

Epoch: 192| Step: 0
Training loss: 1.9612922499550869
Validation loss: 2.402777568932439

Epoch: 6| Step: 1
Training loss: 2.2115926142668076
Validation loss: 2.4075380491499225

Epoch: 6| Step: 2
Training loss: 1.6095943856935817
Validation loss: 2.415768345712006

Epoch: 6| Step: 3
Training loss: 2.2087147461301897
Validation loss: 2.379810688767065

Epoch: 6| Step: 4
Training loss: 2.0975022357114894
Validation loss: 2.4032090074924235

Epoch: 6| Step: 5
Training loss: 2.7588633839546466
Validation loss: 2.4014888922865496

Epoch: 6| Step: 6
Training loss: 1.987405040559752
Validation loss: 2.409253081482662

Epoch: 6| Step: 7
Training loss: 2.2031681787033697
Validation loss: 2.3818003187948067

Epoch: 6| Step: 8
Training loss: 2.2484601367608863
Validation loss: 2.386474091995284

Epoch: 6| Step: 9
Training loss: 1.9864041024139973
Validation loss: 2.4291163332625283

Epoch: 6| Step: 10
Training loss: 2.7759779779071887
Validation loss: 2.391844431805929

Epoch: 6| Step: 11
Training loss: 2.9611394405699683
Validation loss: 2.417893532889452

Epoch: 6| Step: 12
Training loss: 2.158337895254766
Validation loss: 2.403852545048979

Epoch: 6| Step: 13
Training loss: 2.5886170486946267
Validation loss: 2.4072042085314838

Epoch: 193| Step: 0
Training loss: 2.2727155555076264
Validation loss: 2.412974822660602

Epoch: 6| Step: 1
Training loss: 2.2443511837551067
Validation loss: 2.360901584613893

Epoch: 6| Step: 2
Training loss: 2.2550511353101883
Validation loss: 2.408069884988899

Epoch: 6| Step: 3
Training loss: 1.772116955042712
Validation loss: 2.404859142207449

Epoch: 6| Step: 4
Training loss: 1.9570930151415316
Validation loss: 2.406696532248241

Epoch: 6| Step: 5
Training loss: 1.8698536500424048
Validation loss: 2.4248143740651527

Epoch: 6| Step: 6
Training loss: 2.055258783906115
Validation loss: 2.401193300921841

Epoch: 6| Step: 7
Training loss: 2.637912417886249
Validation loss: 2.445803468259183

Epoch: 6| Step: 8
Training loss: 2.4469715864233454
Validation loss: 2.4232161889931643

Epoch: 6| Step: 9
Training loss: 2.662430696973449
Validation loss: 2.4311575176295497

Epoch: 6| Step: 10
Training loss: 1.833837598750917
Validation loss: 2.4101138065736203

Epoch: 6| Step: 11
Training loss: 2.7652818714798952
Validation loss: 2.4358698829256547

Epoch: 6| Step: 12
Training loss: 2.657917531498682
Validation loss: 2.4404376354747206

Epoch: 6| Step: 13
Training loss: 2.213029390783741
Validation loss: 2.4047690752431934

Epoch: 194| Step: 0
Training loss: 1.5088606437813583
Validation loss: 2.444074020219399

Epoch: 6| Step: 1
Training loss: 2.612488767608881
Validation loss: 2.3966041113346956

Epoch: 6| Step: 2
Training loss: 2.9633383164365714
Validation loss: 2.429611037613154

Epoch: 6| Step: 3
Training loss: 2.1534763132621184
Validation loss: 2.4488761049715047

Epoch: 6| Step: 4
Training loss: 1.6697733852109946
Validation loss: 2.4142613642152724

Epoch: 6| Step: 5
Training loss: 2.380058422974369
Validation loss: 2.396224447875835

Epoch: 6| Step: 6
Training loss: 2.3594424004432746
Validation loss: 2.4205824161129046

Epoch: 6| Step: 7
Training loss: 2.6867409454786615
Validation loss: 2.4018026888977273

Epoch: 6| Step: 8
Training loss: 1.3482784880308003
Validation loss: 2.425125366038727

Epoch: 6| Step: 9
Training loss: 1.8227111991254896
Validation loss: 2.4218430341343717

Epoch: 6| Step: 10
Training loss: 2.546635341484917
Validation loss: 2.4303792947201015

Epoch: 6| Step: 11
Training loss: 2.227060041552634
Validation loss: 2.42706193157085

Epoch: 6| Step: 12
Training loss: 2.539067382807805
Validation loss: 2.4250322502367414

Epoch: 6| Step: 13
Training loss: 2.135068154777082
Validation loss: 2.3928525453978082

Epoch: 195| Step: 0
Training loss: 2.425169248672057
Validation loss: 2.3743660582145223

Epoch: 6| Step: 1
Training loss: 2.1968127788560996
Validation loss: 2.3996078496628006

Epoch: 6| Step: 2
Training loss: 2.7064828468567077
Validation loss: 2.372450994539161

Epoch: 6| Step: 3
Training loss: 2.224667033452198
Validation loss: 2.3812626680814426

Epoch: 6| Step: 4
Training loss: 2.4164618262810476
Validation loss: 2.3823664572696632

Epoch: 6| Step: 5
Training loss: 2.0990022287125227
Validation loss: 2.4255325649367183

Epoch: 6| Step: 6
Training loss: 1.1792690722387191
Validation loss: 2.394070668583029

Epoch: 6| Step: 7
Training loss: 1.7347924357324316
Validation loss: 2.4135359073504894

Epoch: 6| Step: 8
Training loss: 2.1890299215349907
Validation loss: 2.3763779225077446

Epoch: 6| Step: 9
Training loss: 2.2944042384966403
Validation loss: 2.3435759809966563

Epoch: 6| Step: 10
Training loss: 1.8742661629547623
Validation loss: 2.3926968953678283

Epoch: 6| Step: 11
Training loss: 2.6163191080602948
Validation loss: 2.399353257624417

Epoch: 6| Step: 12
Training loss: 2.930316989663765
Validation loss: 2.393036456864675

Epoch: 6| Step: 13
Training loss: 2.267587587795178
Validation loss: 2.393228417179654

Epoch: 196| Step: 0
Training loss: 2.9190454500952328
Validation loss: 2.4144380025663494

Epoch: 6| Step: 1
Training loss: 1.5769314926738796
Validation loss: 2.391761048198208

Epoch: 6| Step: 2
Training loss: 2.3531527290888827
Validation loss: 2.435699590992673

Epoch: 6| Step: 3
Training loss: 2.057318218075961
Validation loss: 2.4101230245894674

Epoch: 6| Step: 4
Training loss: 2.793560600261169
Validation loss: 2.398172586036322

Epoch: 6| Step: 5
Training loss: 1.9446578552056055
Validation loss: 2.393070284810735

Epoch: 6| Step: 6
Training loss: 2.168267636702757
Validation loss: 2.4044099656871105

Epoch: 6| Step: 7
Training loss: 2.3939886427365344
Validation loss: 2.3972666693349822

Epoch: 6| Step: 8
Training loss: 2.0538188998459086
Validation loss: 2.407352900586989

Epoch: 6| Step: 9
Training loss: 2.379333557938365
Validation loss: 2.388971392613939

Epoch: 6| Step: 10
Training loss: 1.9950269621745633
Validation loss: 2.415074447340033

Epoch: 6| Step: 11
Training loss: 2.476720185178654
Validation loss: 2.4003868976430143

Epoch: 6| Step: 12
Training loss: 2.1572776225425083
Validation loss: 2.407007318505218

Epoch: 6| Step: 13
Training loss: 1.8575893771821508
Validation loss: 2.3795261808880843

Epoch: 197| Step: 0
Training loss: 3.0684852501432496
Validation loss: 2.4039082910096736

Epoch: 6| Step: 1
Training loss: 2.2501943292409536
Validation loss: 2.413547969582594

Epoch: 6| Step: 2
Training loss: 1.9636055474721068
Validation loss: 2.4274406404236206

Epoch: 6| Step: 3
Training loss: 1.4578117346071644
Validation loss: 2.4020250804220473

Epoch: 6| Step: 4
Training loss: 2.2741481024391073
Validation loss: 2.418460061878161

Epoch: 6| Step: 5
Training loss: 2.1379973162071293
Validation loss: 2.399871879323106

Epoch: 6| Step: 6
Training loss: 1.8154516849754903
Validation loss: 2.4085885616474374

Epoch: 6| Step: 7
Training loss: 2.6957423655173574
Validation loss: 2.400689488928458

Epoch: 6| Step: 8
Training loss: 2.2455801467811556
Validation loss: 2.4021745679716138

Epoch: 6| Step: 9
Training loss: 2.043247415417514
Validation loss: 2.4246760751735565

Epoch: 6| Step: 10
Training loss: 2.3709187827999907
Validation loss: 2.3834272716220153

Epoch: 6| Step: 11
Training loss: 2.246126231083078
Validation loss: 2.4036399643833835

Epoch: 6| Step: 12
Training loss: 2.0934045990680277
Validation loss: 2.3992155565421096

Epoch: 6| Step: 13
Training loss: 2.4055104295738006
Validation loss: 2.3959725067106428

Epoch: 198| Step: 0
Training loss: 2.3390558664435517
Validation loss: 2.4086933438605582

Epoch: 6| Step: 1
Training loss: 2.3578910961158868
Validation loss: 2.3947836671560454

Epoch: 6| Step: 2
Training loss: 2.1756203829950023
Validation loss: 2.3946064536729543

Epoch: 6| Step: 3
Training loss: 3.0814790218888897
Validation loss: 2.3889338719322946

Epoch: 6| Step: 4
Training loss: 2.7677784956908122
Validation loss: 2.4171196591151687

Epoch: 6| Step: 5
Training loss: 2.215973419642871
Validation loss: 2.411997521118529

Epoch: 6| Step: 6
Training loss: 1.867838279287099
Validation loss: 2.3933717863097215

Epoch: 6| Step: 7
Training loss: 2.559869951729831
Validation loss: 2.4063504515979295

Epoch: 6| Step: 8
Training loss: 2.189123150940328
Validation loss: 2.424348802140132

Epoch: 6| Step: 9
Training loss: 2.153556246818092
Validation loss: 2.398550148701078

Epoch: 6| Step: 10
Training loss: 2.2106970127187164
Validation loss: 2.362946114862555

Epoch: 6| Step: 11
Training loss: 1.5397119071795853
Validation loss: 2.4009753638872375

Epoch: 6| Step: 12
Training loss: 2.011495574127039
Validation loss: 2.3902559595410278

Epoch: 6| Step: 13
Training loss: 1.5341779003460707
Validation loss: 2.3918804239823004

Epoch: 199| Step: 0
Training loss: 2.382022013635391
Validation loss: 2.402253721057415

Epoch: 6| Step: 1
Training loss: 2.515236771285161
Validation loss: 2.3787392787131214

Epoch: 6| Step: 2
Training loss: 2.093749430642122
Validation loss: 2.412432999307216

Epoch: 6| Step: 3
Training loss: 2.546355024745831
Validation loss: 2.442007866482397

Epoch: 6| Step: 4
Training loss: 2.281564769192518
Validation loss: 2.3874275453802225

Epoch: 6| Step: 5
Training loss: 2.7465512585081666
Validation loss: 2.407099752362712

Epoch: 6| Step: 6
Training loss: 1.7168356204298956
Validation loss: 2.437898464990035

Epoch: 6| Step: 7
Training loss: 1.9378336957471471
Validation loss: 2.4189468699013523

Epoch: 6| Step: 8
Training loss: 2.247788826244885
Validation loss: 2.4100336925959898

Epoch: 6| Step: 9
Training loss: 1.9376074238191572
Validation loss: 2.40560004996249

Epoch: 6| Step: 10
Training loss: 2.0290453170220357
Validation loss: 2.4368976262039044

Epoch: 6| Step: 11
Training loss: 2.498359714272918
Validation loss: 2.4229353304699726

Epoch: 6| Step: 12
Training loss: 1.8823269419767914
Validation loss: 2.437917649905402

Epoch: 6| Step: 13
Training loss: 1.966916396023927
Validation loss: 2.3877294748714633

Epoch: 200| Step: 0
Training loss: 1.7611426788185702
Validation loss: 2.413480288166497

Epoch: 6| Step: 1
Training loss: 2.8461494802651655
Validation loss: 2.38369302200385

Epoch: 6| Step: 2
Training loss: 1.6444148296547698
Validation loss: 2.395899005505226

Epoch: 6| Step: 3
Training loss: 2.519603923370509
Validation loss: 2.3928388285537867

Epoch: 6| Step: 4
Training loss: 1.7732592925889468
Validation loss: 2.419877133375494

Epoch: 6| Step: 5
Training loss: 1.6741263659145604
Validation loss: 2.3951587499518947

Epoch: 6| Step: 6
Training loss: 2.3779399143132243
Validation loss: 2.4161732806133647

Epoch: 6| Step: 7
Training loss: 3.0702078221460827
Validation loss: 2.388476359596336

Epoch: 6| Step: 8
Training loss: 2.501550575051605
Validation loss: 2.4083278348164283

Epoch: 6| Step: 9
Training loss: 2.4514835964947954
Validation loss: 2.415845806526819

Epoch: 6| Step: 10
Training loss: 2.0907705943411443
Validation loss: 2.38605150099955

Epoch: 6| Step: 11
Training loss: 2.155633589499889
Validation loss: 2.3672524904269516

Epoch: 6| Step: 12
Training loss: 2.0332859106735226
Validation loss: 2.366215020970778

Epoch: 6| Step: 13
Training loss: 1.4633112100364067
Validation loss: 2.397433362384157

Epoch: 201| Step: 0
Training loss: 1.8022284329897011
Validation loss: 2.4136810197781715

Epoch: 6| Step: 1
Training loss: 2.994182509236971
Validation loss: 2.388119180994726

Epoch: 6| Step: 2
Training loss: 1.8913802222722529
Validation loss: 2.377454280806828

Epoch: 6| Step: 3
Training loss: 2.579630464215598
Validation loss: 2.392402242993576

Epoch: 6| Step: 4
Training loss: 2.2104547735219855
Validation loss: 2.39054422753474

Epoch: 6| Step: 5
Training loss: 2.8801122905774785
Validation loss: 2.397261540479775

Epoch: 6| Step: 6
Training loss: 1.6941165485214897
Validation loss: 2.406812636427474

Epoch: 6| Step: 7
Training loss: 2.223659188537573
Validation loss: 2.4040245010564503

Epoch: 6| Step: 8
Training loss: 2.156930788347233
Validation loss: 2.411949178102201

Epoch: 6| Step: 9
Training loss: 1.5048742572558569
Validation loss: 2.416390226746317

Epoch: 6| Step: 10
Training loss: 1.9130796439207032
Validation loss: 2.411744268334912

Epoch: 6| Step: 11
Training loss: 2.406006837919163
Validation loss: 2.3934623967664974

Epoch: 6| Step: 12
Training loss: 1.9654361142858319
Validation loss: 2.4254212127709516

Epoch: 6| Step: 13
Training loss: 2.6148363170854356
Validation loss: 2.4149500163908204

Epoch: 202| Step: 0
Training loss: 2.327623146806588
Validation loss: 2.426008431589387

Epoch: 6| Step: 1
Training loss: 1.6568416762193583
Validation loss: 2.4333181191391735

Epoch: 6| Step: 2
Training loss: 2.241389541324366
Validation loss: 2.390115271111567

Epoch: 6| Step: 3
Training loss: 2.5564919727959667
Validation loss: 2.3967896516843257

Epoch: 6| Step: 4
Training loss: 2.1347155901043973
Validation loss: 2.397421872970835

Epoch: 6| Step: 5
Training loss: 1.8595186065867122
Validation loss: 2.423692325337239

Epoch: 6| Step: 6
Training loss: 2.408129267863282
Validation loss: 2.412017779342216

Epoch: 6| Step: 7
Training loss: 2.086881502546363
Validation loss: 2.414471343792627

Epoch: 6| Step: 8
Training loss: 2.13950702960809
Validation loss: 2.431072491249595

Epoch: 6| Step: 9
Training loss: 2.1746902332927345
Validation loss: 2.3939111450637625

Epoch: 6| Step: 10
Training loss: 2.956825158459694
Validation loss: 2.3914620439890864

Epoch: 6| Step: 11
Training loss: 1.6731246128587698
Validation loss: 2.415266407484205

Epoch: 6| Step: 12
Training loss: 2.2714056524541117
Validation loss: 2.3774487576795513

Epoch: 6| Step: 13
Training loss: 2.3628405451689987
Validation loss: 2.3851197727836952

Epoch: 203| Step: 0
Training loss: 2.139518507508109
Validation loss: 2.418670432146721

Epoch: 6| Step: 1
Training loss: 2.66438877647108
Validation loss: 2.400960427090741

Epoch: 6| Step: 2
Training loss: 1.5704740374780406
Validation loss: 2.413052636626233

Epoch: 6| Step: 3
Training loss: 2.4352508340530057
Validation loss: 2.3939622575279413

Epoch: 6| Step: 4
Training loss: 2.622677638580587
Validation loss: 2.399242519214266

Epoch: 6| Step: 5
Training loss: 1.8204401323490205
Validation loss: 2.4083245391534693

Epoch: 6| Step: 6
Training loss: 1.9546722996987487
Validation loss: 2.394687316077221

Epoch: 6| Step: 7
Training loss: 1.760356367835378
Validation loss: 2.3902924571983677

Epoch: 6| Step: 8
Training loss: 2.3265333431305035
Validation loss: 2.4016389586799836

Epoch: 6| Step: 9
Training loss: 2.037990127307462
Validation loss: 2.3993714846109397

Epoch: 6| Step: 10
Training loss: 2.004418737007465
Validation loss: 2.4045056062484167

Epoch: 6| Step: 11
Training loss: 2.417771930726467
Validation loss: 2.407473528619811

Epoch: 6| Step: 12
Training loss: 2.1235180343390274
Validation loss: 2.4298960178125153

Epoch: 6| Step: 13
Training loss: 3.2469366748815593
Validation loss: 2.400590691204461

Epoch: 204| Step: 0
Training loss: 2.6336942831771477
Validation loss: 2.4060518673020255

Epoch: 6| Step: 1
Training loss: 1.8771251714731365
Validation loss: 2.4166404265130863

Epoch: 6| Step: 2
Training loss: 1.9983278675444713
Validation loss: 2.4065674294219948

Epoch: 6| Step: 3
Training loss: 2.3387454708020847
Validation loss: 2.4114240912676004

Epoch: 6| Step: 4
Training loss: 2.3090368578229565
Validation loss: 2.3721196443950174

Epoch: 6| Step: 5
Training loss: 2.020625572405096
Validation loss: 2.366294889382081

Epoch: 6| Step: 6
Training loss: 2.5848094865554616
Validation loss: 2.3942908102246263

Epoch: 6| Step: 7
Training loss: 2.1442879849787935
Validation loss: 2.399637391186717

Epoch: 6| Step: 8
Training loss: 1.986285513961891
Validation loss: 2.3701717929615556

Epoch: 6| Step: 9
Training loss: 1.8318199572693326
Validation loss: 2.356380213308924

Epoch: 6| Step: 10
Training loss: 2.6831075569401563
Validation loss: 2.371735011400404

Epoch: 6| Step: 11
Training loss: 2.0881217350458985
Validation loss: 2.4053054839477337

Epoch: 6| Step: 12
Training loss: 1.8195102217078678
Validation loss: 2.3761501196350845

Epoch: 6| Step: 13
Training loss: 2.378654880115291
Validation loss: 2.3822132095972535

Epoch: 205| Step: 0
Training loss: 2.3913601013137424
Validation loss: 2.4013797293435353

Epoch: 6| Step: 1
Training loss: 1.8578237906995994
Validation loss: 2.3614743992171636

Epoch: 6| Step: 2
Training loss: 2.4043134352534374
Validation loss: 2.4461317632441713

Epoch: 6| Step: 3
Training loss: 1.7908032207108149
Validation loss: 2.3919575512364957

Epoch: 6| Step: 4
Training loss: 1.9109314513715085
Validation loss: 2.4122198846020337

Epoch: 6| Step: 5
Training loss: 2.4558924718112896
Validation loss: 2.4167825627215316

Epoch: 6| Step: 6
Training loss: 2.079758998407046
Validation loss: 2.389683230646349

Epoch: 6| Step: 7
Training loss: 1.613086605568408
Validation loss: 2.4042366659858003

Epoch: 6| Step: 8
Training loss: 2.072139524026133
Validation loss: 2.389728127775385

Epoch: 6| Step: 9
Training loss: 2.5773548247396287
Validation loss: 2.40189703292791

Epoch: 6| Step: 10
Training loss: 2.3803960836027986
Validation loss: 2.4346290490043128

Epoch: 6| Step: 11
Training loss: 2.2649633033255476
Validation loss: 2.4101559878022893

Epoch: 6| Step: 12
Training loss: 2.515157051870708
Validation loss: 2.405148102979459

Epoch: 6| Step: 13
Training loss: 2.7473518452429895
Validation loss: 2.4259129761705935

Epoch: 206| Step: 0
Training loss: 2.0438698409755367
Validation loss: 2.4037237875425466

Epoch: 6| Step: 1
Training loss: 2.680851541713658
Validation loss: 2.3974355839103256

Epoch: 6| Step: 2
Training loss: 2.11954516228041
Validation loss: 2.4226204531019992

Epoch: 6| Step: 3
Training loss: 1.3775963113004366
Validation loss: 2.4074253854728007

Epoch: 6| Step: 4
Training loss: 1.71993090202463
Validation loss: 2.416046536845292

Epoch: 6| Step: 5
Training loss: 2.2998308119535316
Validation loss: 2.407656523427017

Epoch: 6| Step: 6
Training loss: 2.1795850066558575
Validation loss: 2.4118540357314395

Epoch: 6| Step: 7
Training loss: 2.9422145913163744
Validation loss: 2.3961156185683037

Epoch: 6| Step: 8
Training loss: 2.0883683460138953
Validation loss: 2.429494339887784

Epoch: 6| Step: 9
Training loss: 2.239889103324187
Validation loss: 2.4097636511656204

Epoch: 6| Step: 10
Training loss: 1.8861584828638467
Validation loss: 2.4281727194770575

Epoch: 6| Step: 11
Training loss: 2.0216130459879658
Validation loss: 2.385935175212311

Epoch: 6| Step: 12
Training loss: 2.5368733050295367
Validation loss: 2.394902535813149

Epoch: 6| Step: 13
Training loss: 2.3377560072458508
Validation loss: 2.3972461292518688

Epoch: 207| Step: 0
Training loss: 2.1894915642881823
Validation loss: 2.4168672803695372

Epoch: 6| Step: 1
Training loss: 2.2465991703765105
Validation loss: 2.3835284382205453

Epoch: 6| Step: 2
Training loss: 1.9954587519852756
Validation loss: 2.4293910025243926

Epoch: 6| Step: 3
Training loss: 2.2929943284747742
Validation loss: 2.392572069961959

Epoch: 6| Step: 4
Training loss: 2.125133173640369
Validation loss: 2.3993150220662187

Epoch: 6| Step: 5
Training loss: 2.1608354766438844
Validation loss: 2.4120477592878973

Epoch: 6| Step: 6
Training loss: 1.2854267056081894
Validation loss: 2.372983454198586

Epoch: 6| Step: 7
Training loss: 1.8453402369366396
Validation loss: 2.383276222007118

Epoch: 6| Step: 8
Training loss: 2.0738863058977075
Validation loss: 2.4098478847186224

Epoch: 6| Step: 9
Training loss: 2.89332528674271
Validation loss: 2.391221244140845

Epoch: 6| Step: 10
Training loss: 2.3923847976739867
Validation loss: 2.408135811813304

Epoch: 6| Step: 11
Training loss: 2.2014171934129947
Validation loss: 2.3995781955962032

Epoch: 6| Step: 12
Training loss: 2.356849986621133
Validation loss: 2.401906153330383

Epoch: 6| Step: 13
Training loss: 2.1796492159636327
Validation loss: 2.3901080417681864

Epoch: 208| Step: 0
Training loss: 1.668015919360115
Validation loss: 2.3973413797696552

Epoch: 6| Step: 1
Training loss: 2.1416612330663405
Validation loss: 2.41097026669741

Epoch: 6| Step: 2
Training loss: 2.358815107796403
Validation loss: 2.4110857004279884

Epoch: 6| Step: 3
Training loss: 2.5710598401198386
Validation loss: 2.409026795076947

Epoch: 6| Step: 4
Training loss: 1.6127241525916003
Validation loss: 2.3906561393514014

Epoch: 6| Step: 5
Training loss: 1.96899999817499
Validation loss: 2.402708220527701

Epoch: 6| Step: 6
Training loss: 2.3458388112231767
Validation loss: 2.3861356723563603

Epoch: 6| Step: 7
Training loss: 3.2912688839867243
Validation loss: 2.424234210396744

Epoch: 6| Step: 8
Training loss: 1.7365360714773863
Validation loss: 2.376449749120845

Epoch: 6| Step: 9
Training loss: 2.081116552341832
Validation loss: 2.4002251979366496

Epoch: 6| Step: 10
Training loss: 1.9162505430655012
Validation loss: 2.4122467152039855

Epoch: 6| Step: 11
Training loss: 2.428108020855663
Validation loss: 2.3936662518627814

Epoch: 6| Step: 12
Training loss: 1.9882140982029497
Validation loss: 2.427917384340506

Epoch: 6| Step: 13
Training loss: 2.3275512397936047
Validation loss: 2.420702785215038

Epoch: 209| Step: 0
Training loss: 2.0531117013532514
Validation loss: 2.3926078610040444

Epoch: 6| Step: 1
Training loss: 2.3602813596627077
Validation loss: 2.424552508127227

Epoch: 6| Step: 2
Training loss: 2.165690226487734
Validation loss: 2.436902867312014

Epoch: 6| Step: 3
Training loss: 2.0024711124846344
Validation loss: 2.408643529585237

Epoch: 6| Step: 4
Training loss: 2.398277948397002
Validation loss: 2.4123746022925228

Epoch: 6| Step: 5
Training loss: 1.6372104534383038
Validation loss: 2.4015355782771874

Epoch: 6| Step: 6
Training loss: 2.002989085045346
Validation loss: 2.408385010018791

Epoch: 6| Step: 7
Training loss: 2.1535782778445065
Validation loss: 2.3819176233306445

Epoch: 6| Step: 8
Training loss: 2.871086608462632
Validation loss: 2.4134077397555496

Epoch: 6| Step: 9
Training loss: 1.9064623604977438
Validation loss: 2.420414706995917

Epoch: 6| Step: 10
Training loss: 1.5298204560990711
Validation loss: 2.3874141651485523

Epoch: 6| Step: 11
Training loss: 2.556540281047448
Validation loss: 2.380415912888818

Epoch: 6| Step: 12
Training loss: 2.9032066571892785
Validation loss: 2.3893305253499553

Epoch: 6| Step: 13
Training loss: 1.2715112826873942
Validation loss: 2.4153358421719666

Epoch: 210| Step: 0
Training loss: 1.6126912587611415
Validation loss: 2.3734963497822292

Epoch: 6| Step: 1
Training loss: 2.3878596649084876
Validation loss: 2.416510922954795

Epoch: 6| Step: 2
Training loss: 1.8786948356727593
Validation loss: 2.3868916664746433

Epoch: 6| Step: 3
Training loss: 1.6938714437829556
Validation loss: 2.4340430652296567

Epoch: 6| Step: 4
Training loss: 2.1588788799962013
Validation loss: 2.4055785227877844

Epoch: 6| Step: 5
Training loss: 2.376608253856189
Validation loss: 2.3724167131967295

Epoch: 6| Step: 6
Training loss: 2.1746057043358076
Validation loss: 2.3988575141550887

Epoch: 6| Step: 7
Training loss: 2.370276924726336
Validation loss: 2.3721088499559646

Epoch: 6| Step: 8
Training loss: 2.2970915192775867
Validation loss: 2.3883205145307165

Epoch: 6| Step: 9
Training loss: 2.656156650473663
Validation loss: 2.4209126286147242

Epoch: 6| Step: 10
Training loss: 1.7720566806123834
Validation loss: 2.387337293268643

Epoch: 6| Step: 11
Training loss: 2.757716363630663
Validation loss: 2.388131638903951

Epoch: 6| Step: 12
Training loss: 2.274054689298266
Validation loss: 2.3885017170541434

Epoch: 6| Step: 13
Training loss: 1.7476545010704188
Validation loss: 2.386583163310227

Epoch: 211| Step: 0
Training loss: 2.1752975172686733
Validation loss: 2.4144682306477105

Epoch: 6| Step: 1
Training loss: 2.0008640806903832
Validation loss: 2.388762487727427

Epoch: 6| Step: 2
Training loss: 1.970105567369165
Validation loss: 2.3842629781293283

Epoch: 6| Step: 3
Training loss: 2.1576241799838036
Validation loss: 2.390160440605033

Epoch: 6| Step: 4
Training loss: 2.181255036706219
Validation loss: 2.3746835727744275

Epoch: 6| Step: 5
Training loss: 2.712261920799734
Validation loss: 2.3945064178374555

Epoch: 6| Step: 6
Training loss: 2.517344390696686
Validation loss: 2.406583942093392

Epoch: 6| Step: 7
Training loss: 2.0509887590328124
Validation loss: 2.3855437319105346

Epoch: 6| Step: 8
Training loss: 2.460694994406919
Validation loss: 2.395534044773117

Epoch: 6| Step: 9
Training loss: 2.5028193788485114
Validation loss: 2.4075036918713972

Epoch: 6| Step: 10
Training loss: 2.085901267204922
Validation loss: 2.4232065415314157

Epoch: 6| Step: 11
Training loss: 1.8199621690234762
Validation loss: 2.406511539990313

Epoch: 6| Step: 12
Training loss: 1.7518747369587075
Validation loss: 2.411036615025937

Epoch: 6| Step: 13
Training loss: 1.4994051866565565
Validation loss: 2.389030422858449

Epoch: 212| Step: 0
Training loss: 2.7591047420329198
Validation loss: 2.3790967211602716

Epoch: 6| Step: 1
Training loss: 1.6271872838509014
Validation loss: 2.405598208437456

Epoch: 6| Step: 2
Training loss: 2.3670350079157534
Validation loss: 2.384805675138474

Epoch: 6| Step: 3
Training loss: 2.111713610666494
Validation loss: 2.374252171375616

Epoch: 6| Step: 4
Training loss: 1.94293416801204
Validation loss: 2.3686891331565

Epoch: 6| Step: 5
Training loss: 1.8215863923478863
Validation loss: 2.4286343409196

Epoch: 6| Step: 6
Training loss: 2.2074035870589883
Validation loss: 2.4263182519560664

Epoch: 6| Step: 7
Training loss: 1.518338870692005
Validation loss: 2.4142801667395717

Epoch: 6| Step: 8
Training loss: 2.2221576151463096
Validation loss: 2.400445050160795

Epoch: 6| Step: 9
Training loss: 2.3879731872752994
Validation loss: 2.4196945054878523

Epoch: 6| Step: 10
Training loss: 2.2338934959767416
Validation loss: 2.401069999878043

Epoch: 6| Step: 11
Training loss: 2.1026906668882366
Validation loss: 2.40944872825623

Epoch: 6| Step: 12
Training loss: 2.0967663345946894
Validation loss: 2.3594681199127248

Epoch: 6| Step: 13
Training loss: 3.090737311286802
Validation loss: 2.3831409192379405

Epoch: 213| Step: 0
Training loss: 1.6541008591073307
Validation loss: 2.388530538899296

Epoch: 6| Step: 1
Training loss: 2.071260170597943
Validation loss: 2.400806979199582

Epoch: 6| Step: 2
Training loss: 2.2985592849384924
Validation loss: 2.419571542263819

Epoch: 6| Step: 3
Training loss: 2.484465687374149
Validation loss: 2.3928753537758185

Epoch: 6| Step: 4
Training loss: 2.474480268065579
Validation loss: 2.3847558354252425

Epoch: 6| Step: 5
Training loss: 1.4277485691518266
Validation loss: 2.3949387972758944

Epoch: 6| Step: 6
Training loss: 2.258275918359757
Validation loss: 2.3891743953162963

Epoch: 6| Step: 7
Training loss: 2.9190857982042653
Validation loss: 2.4058239659157854

Epoch: 6| Step: 8
Training loss: 1.6547832111922398
Validation loss: 2.434231658068035

Epoch: 6| Step: 9
Training loss: 1.7493685536812666
Validation loss: 2.380950827722585

Epoch: 6| Step: 10
Training loss: 2.2752663508847184
Validation loss: 2.368211216543277

Epoch: 6| Step: 11
Training loss: 2.1216267009286205
Validation loss: 2.417643078944984

Epoch: 6| Step: 12
Training loss: 2.1118599277487964
Validation loss: 2.4195743140273085

Epoch: 6| Step: 13
Training loss: 2.730722571105578
Validation loss: 2.3883684406116523

Epoch: 214| Step: 0
Training loss: 2.3258250095606194
Validation loss: 2.37785610834669

Epoch: 6| Step: 1
Training loss: 1.7745777111348056
Validation loss: 2.386320870690192

Epoch: 6| Step: 2
Training loss: 2.202635257477763
Validation loss: 2.3950546086968165

Epoch: 6| Step: 3
Training loss: 2.0557147457009055
Validation loss: 2.363456501671014

Epoch: 6| Step: 4
Training loss: 1.5769524325524473
Validation loss: 2.3902532074066247

Epoch: 6| Step: 5
Training loss: 1.8402114792243425
Validation loss: 2.3695194813330613

Epoch: 6| Step: 6
Training loss: 2.643173162058064
Validation loss: 2.365579917034786

Epoch: 6| Step: 7
Training loss: 1.80991672714212
Validation loss: 2.3968652952227996

Epoch: 6| Step: 8
Training loss: 2.58769364668978
Validation loss: 2.379287836491875

Epoch: 6| Step: 9
Training loss: 2.223667444387483
Validation loss: 2.371880149335826

Epoch: 6| Step: 10
Training loss: 2.081517941751523
Validation loss: 2.357776904958222

Epoch: 6| Step: 11
Training loss: 2.71088886492194
Validation loss: 2.3870496872722997

Epoch: 6| Step: 12
Training loss: 2.119824333470335
Validation loss: 2.4515631527783066

Epoch: 6| Step: 13
Training loss: 1.6911041483329858
Validation loss: 2.380350426722213

Epoch: 215| Step: 0
Training loss: 2.419379148053511
Validation loss: 2.392508908497574

Epoch: 6| Step: 1
Training loss: 1.641475638621018
Validation loss: 2.4156816187852264

Epoch: 6| Step: 2
Training loss: 2.31895360746774
Validation loss: 2.3851028546200146

Epoch: 6| Step: 3
Training loss: 2.426609555173237
Validation loss: 2.433647605378963

Epoch: 6| Step: 4
Training loss: 1.8374589824639758
Validation loss: 2.448685557811838

Epoch: 6| Step: 5
Training loss: 1.880542573957591
Validation loss: 2.3706272113137064

Epoch: 6| Step: 6
Training loss: 2.1993227132884066
Validation loss: 2.396138518924832

Epoch: 6| Step: 7
Training loss: 2.521830611092363
Validation loss: 2.4058843760257007

Epoch: 6| Step: 8
Training loss: 1.5243060643748731
Validation loss: 2.3657816006968293

Epoch: 6| Step: 9
Training loss: 2.2825294982407907
Validation loss: 2.400275296398662

Epoch: 6| Step: 10
Training loss: 2.2562913885573654
Validation loss: 2.4163649677982457

Epoch: 6| Step: 11
Training loss: 2.411785249130018
Validation loss: 2.3813706668641266

Epoch: 6| Step: 12
Training loss: 1.714752264341402
Validation loss: 2.395813057391457

Epoch: 6| Step: 13
Training loss: 2.9747023489655913
Validation loss: 2.42822972091366

Epoch: 216| Step: 0
Training loss: 1.9206259165202126
Validation loss: 2.4052982405734062

Epoch: 6| Step: 1
Training loss: 2.3551423968050247
Validation loss: 2.3832665290422277

Epoch: 6| Step: 2
Training loss: 2.194703258537675
Validation loss: 2.40649247276253

Epoch: 6| Step: 3
Training loss: 1.572820681575882
Validation loss: 2.3761564163870075

Epoch: 6| Step: 4
Training loss: 2.0876871264983583
Validation loss: 2.400014278784272

Epoch: 6| Step: 5
Training loss: 2.3144243842163275
Validation loss: 2.3587608013330406

Epoch: 6| Step: 6
Training loss: 2.3550661669788364
Validation loss: 2.350956310583923

Epoch: 6| Step: 7
Training loss: 2.2339499542791637
Validation loss: 2.359958464891563

Epoch: 6| Step: 8
Training loss: 2.295952644178778
Validation loss: 2.3640831017099937

Epoch: 6| Step: 9
Training loss: 2.4750388479555547
Validation loss: 2.4055945328430544

Epoch: 6| Step: 10
Training loss: 2.4649079763324044
Validation loss: 2.3900148590449097

Epoch: 6| Step: 11
Training loss: 1.619686830650396
Validation loss: 2.3793635968405153

Epoch: 6| Step: 12
Training loss: 2.283338035337336
Validation loss: 2.369848214202435

Epoch: 6| Step: 13
Training loss: 1.5632773945011176
Validation loss: 2.368291871715631

Epoch: 217| Step: 0
Training loss: 1.8967879550324547
Validation loss: 2.3872418862892824

Epoch: 6| Step: 1
Training loss: 2.274441002718561
Validation loss: 2.336370817759862

Epoch: 6| Step: 2
Training loss: 2.0727237119598465
Validation loss: 2.4304570029143515

Epoch: 6| Step: 3
Training loss: 1.9139345710198077
Validation loss: 2.3949188516660405

Epoch: 6| Step: 4
Training loss: 1.9850027338004324
Validation loss: 2.4121038355702904

Epoch: 6| Step: 5
Training loss: 1.8280111424129473
Validation loss: 2.41278619715218

Epoch: 6| Step: 6
Training loss: 3.0280833269997554
Validation loss: 2.432713412073511

Epoch: 6| Step: 7
Training loss: 1.7554727538147628
Validation loss: 2.411913914288226

Epoch: 6| Step: 8
Training loss: 2.395405894310719
Validation loss: 2.449225371527268

Epoch: 6| Step: 9
Training loss: 1.8882865631066645
Validation loss: 2.4495424522278952

Epoch: 6| Step: 10
Training loss: 2.1905748826849973
Validation loss: 2.4270231058238294

Epoch: 6| Step: 11
Training loss: 2.393572517369077
Validation loss: 2.397216364159366

Epoch: 6| Step: 12
Training loss: 1.8535898432931228
Validation loss: 2.4455918264550256

Epoch: 6| Step: 13
Training loss: 2.666102458951035
Validation loss: 2.400511884834291

Epoch: 218| Step: 0
Training loss: 2.567193640656885
Validation loss: 2.4118490335608427

Epoch: 6| Step: 1
Training loss: 2.1769534228927214
Validation loss: 2.39937498275759

Epoch: 6| Step: 2
Training loss: 2.482833864133323
Validation loss: 2.4352052034169867

Epoch: 6| Step: 3
Training loss: 1.2230062258071448
Validation loss: 2.4270986352049375

Epoch: 6| Step: 4
Training loss: 1.891291729352608
Validation loss: 2.396855696252428

Epoch: 6| Step: 5
Training loss: 2.3197922042985377
Validation loss: 2.373694904849674

Epoch: 6| Step: 6
Training loss: 2.2066639282271034
Validation loss: 2.3704229717247105

Epoch: 6| Step: 7
Training loss: 2.247264470710637
Validation loss: 2.381901817650304

Epoch: 6| Step: 8
Training loss: 1.6966501048290872
Validation loss: 2.371693527194906

Epoch: 6| Step: 9
Training loss: 2.187444413705024
Validation loss: 2.3969087599105916

Epoch: 6| Step: 10
Training loss: 2.8085056338859014
Validation loss: 2.3531364646438084

Epoch: 6| Step: 11
Training loss: 2.2597829278994004
Validation loss: 2.3359593320331102

Epoch: 6| Step: 12
Training loss: 1.5745164007675534
Validation loss: 2.3756483226126313

Epoch: 6| Step: 13
Training loss: 1.776560986198646
Validation loss: 2.366538450860291

Epoch: 219| Step: 0
Training loss: 2.318378708717826
Validation loss: 2.4016791704268567

Epoch: 6| Step: 1
Training loss: 2.007908444023302
Validation loss: 2.378267273080489

Epoch: 6| Step: 2
Training loss: 1.9414476355702661
Validation loss: 2.3755318856189223

Epoch: 6| Step: 3
Training loss: 3.1066130826965006
Validation loss: 2.3755172118822356

Epoch: 6| Step: 4
Training loss: 1.8578737754117067
Validation loss: 2.402109852150941

Epoch: 6| Step: 5
Training loss: 2.5647744110430093
Validation loss: 2.393023927001502

Epoch: 6| Step: 6
Training loss: 2.0180682374515344
Validation loss: 2.3570881287950676

Epoch: 6| Step: 7
Training loss: 2.093661975433644
Validation loss: 2.3862737425360065

Epoch: 6| Step: 8
Training loss: 1.4899856539810086
Validation loss: 2.3932091814562404

Epoch: 6| Step: 9
Training loss: 2.677185402988803
Validation loss: 2.37412575475493

Epoch: 6| Step: 10
Training loss: 1.745230100593949
Validation loss: 2.3813849320521485

Epoch: 6| Step: 11
Training loss: 2.0507028909880956
Validation loss: 2.395147376463573

Epoch: 6| Step: 12
Training loss: 1.7970636683389838
Validation loss: 2.399352507557289

Epoch: 6| Step: 13
Training loss: 2.2046683026078835
Validation loss: 2.392728889541997

Epoch: 220| Step: 0
Training loss: 2.8602425348374325
Validation loss: 2.358727986654916

Epoch: 6| Step: 1
Training loss: 1.986083189079627
Validation loss: 2.412468858063378

Epoch: 6| Step: 2
Training loss: 1.6110110809068214
Validation loss: 2.397186051145347

Epoch: 6| Step: 3
Training loss: 1.5471425451236356
Validation loss: 2.409674301061842

Epoch: 6| Step: 4
Training loss: 1.5929431742981195
Validation loss: 2.36431632016744

Epoch: 6| Step: 5
Training loss: 1.5851874621511277
Validation loss: 2.3870229676054735

Epoch: 6| Step: 6
Training loss: 2.1561588876243887
Validation loss: 2.4121942121361344

Epoch: 6| Step: 7
Training loss: 2.466820554400649
Validation loss: 2.379616156111565

Epoch: 6| Step: 8
Training loss: 2.5513188261535538
Validation loss: 2.3785014148614576

Epoch: 6| Step: 9
Training loss: 2.3885135676154543
Validation loss: 2.3838434053319304

Epoch: 6| Step: 10
Training loss: 2.0165258952208354
Validation loss: 2.4009729609154187

Epoch: 6| Step: 11
Training loss: 2.0706866232202428
Validation loss: 2.3874845252888237

Epoch: 6| Step: 12
Training loss: 2.4536093458457247
Validation loss: 2.3847422273496934

Epoch: 6| Step: 13
Training loss: 2.2112587200055396
Validation loss: 2.365138462292754

Epoch: 221| Step: 0
Training loss: 2.47550638586433
Validation loss: 2.375952195140452

Epoch: 6| Step: 1
Training loss: 2.419109710047398
Validation loss: 2.377339040825234

Epoch: 6| Step: 2
Training loss: 1.7701773232468279
Validation loss: 2.4174330217262967

Epoch: 6| Step: 3
Training loss: 1.5488853876946052
Validation loss: 2.4081162863682324

Epoch: 6| Step: 4
Training loss: 2.2563623965685204
Validation loss: 2.3809604030611693

Epoch: 6| Step: 5
Training loss: 1.7063623859435855
Validation loss: 2.38276406408203

Epoch: 6| Step: 6
Training loss: 2.1937693537975074
Validation loss: 2.3899682338726707

Epoch: 6| Step: 7
Training loss: 2.0440883158138448
Validation loss: 2.399218052633548

Epoch: 6| Step: 8
Training loss: 2.1199284789778745
Validation loss: 2.39997774924796

Epoch: 6| Step: 9
Training loss: 2.394486941850208
Validation loss: 2.386402039631065

Epoch: 6| Step: 10
Training loss: 1.730301067417179
Validation loss: 2.382223013387291

Epoch: 6| Step: 11
Training loss: 2.218112585356004
Validation loss: 2.4247994614752475

Epoch: 6| Step: 12
Training loss: 2.8749484181959852
Validation loss: 2.375948603702745

Epoch: 6| Step: 13
Training loss: 1.8368851833314335
Validation loss: 2.410602942423432

Epoch: 222| Step: 0
Training loss: 1.9821496936380718
Validation loss: 2.416713452832182

Epoch: 6| Step: 1
Training loss: 1.8788990805760761
Validation loss: 2.3774880177565225

Epoch: 6| Step: 2
Training loss: 2.4419819633698827
Validation loss: 2.3903131530246107

Epoch: 6| Step: 3
Training loss: 1.9913209114930317
Validation loss: 2.4245178696101353

Epoch: 6| Step: 4
Training loss: 2.631302307043926
Validation loss: 2.366826518372716

Epoch: 6| Step: 5
Training loss: 2.5972569667874374
Validation loss: 2.3745470160119617

Epoch: 6| Step: 6
Training loss: 1.670796340507498
Validation loss: 2.4060000138073296

Epoch: 6| Step: 7
Training loss: 1.7247429144752893
Validation loss: 2.383354225758406

Epoch: 6| Step: 8
Training loss: 2.920050882915138
Validation loss: 2.4091229472357667

Epoch: 6| Step: 9
Training loss: 1.3648255790806627
Validation loss: 2.3818114605617127

Epoch: 6| Step: 10
Training loss: 1.9419613817816508
Validation loss: 2.3576381380353024

Epoch: 6| Step: 11
Training loss: 1.437162774377827
Validation loss: 2.360780527238612

Epoch: 6| Step: 12
Training loss: 2.8829160428771283
Validation loss: 2.3966132433220375

Epoch: 6| Step: 13
Training loss: 1.367210605971045
Validation loss: 2.3939709209123157

Epoch: 223| Step: 0
Training loss: 2.033613854219859
Validation loss: 2.3888133401062275

Epoch: 6| Step: 1
Training loss: 2.090613107690216
Validation loss: 2.3510831802877687

Epoch: 6| Step: 2
Training loss: 2.7436625542750255
Validation loss: 2.4016076713808654

Epoch: 6| Step: 3
Training loss: 2.008684733291307
Validation loss: 2.4157997425051203

Epoch: 6| Step: 4
Training loss: 1.4518878551608672
Validation loss: 2.4270590225925295

Epoch: 6| Step: 5
Training loss: 2.112887925865465
Validation loss: 2.364240190953396

Epoch: 6| Step: 6
Training loss: 2.6364429470916004
Validation loss: 2.385360818859268

Epoch: 6| Step: 7
Training loss: 1.9743343656053
Validation loss: 2.398532470199589

Epoch: 6| Step: 8
Training loss: 2.3746233189671204
Validation loss: 2.382987110310615

Epoch: 6| Step: 9
Training loss: 1.7746204346487036
Validation loss: 2.377177156461808

Epoch: 6| Step: 10
Training loss: 1.6796634406207496
Validation loss: 2.3957895108174743

Epoch: 6| Step: 11
Training loss: 2.0120872974758264
Validation loss: 2.409412299994895

Epoch: 6| Step: 12
Training loss: 2.3982093528564543
Validation loss: 2.42935223088487

Epoch: 6| Step: 13
Training loss: 1.8003811008948836
Validation loss: 2.354424502705527

Epoch: 224| Step: 0
Training loss: 2.3530369188660494
Validation loss: 2.3842080072322624

Epoch: 6| Step: 1
Training loss: 1.7522254825704964
Validation loss: 2.3868851856490525

Epoch: 6| Step: 2
Training loss: 1.4905942229926354
Validation loss: 2.40306711392147

Epoch: 6| Step: 3
Training loss: 2.267557937571638
Validation loss: 2.373459118047782

Epoch: 6| Step: 4
Training loss: 2.8799160929218943
Validation loss: 2.4053121730715743

Epoch: 6| Step: 5
Training loss: 1.3258643264232992
Validation loss: 2.3460696592173775

Epoch: 6| Step: 6
Training loss: 2.4163376047008325
Validation loss: 2.3742736780898244

Epoch: 6| Step: 7
Training loss: 1.8713095904833754
Validation loss: 2.4092198313794833

Epoch: 6| Step: 8
Training loss: 2.3373500673892247
Validation loss: 2.385841704329446

Epoch: 6| Step: 9
Training loss: 2.2119094275958613
Validation loss: 2.3604269297943006

Epoch: 6| Step: 10
Training loss: 2.1224590143890247
Validation loss: 2.396632910618567

Epoch: 6| Step: 11
Training loss: 2.4325137857201358
Validation loss: 2.4013227343147396

Epoch: 6| Step: 12
Training loss: 1.4961753404645
Validation loss: 2.3971774368108814

Epoch: 6| Step: 13
Training loss: 2.3242552682267674
Validation loss: 2.3751972626055045

Epoch: 225| Step: 0
Training loss: 2.1894897131197997
Validation loss: 2.4033098918084534

Epoch: 6| Step: 1
Training loss: 2.03122805070022
Validation loss: 2.366171923693065

Epoch: 6| Step: 2
Training loss: 2.9320322648129737
Validation loss: 2.413575563995543

Epoch: 6| Step: 3
Training loss: 2.7213050850027125
Validation loss: 2.418527439107422

Epoch: 6| Step: 4
Training loss: 1.7353670187172192
Validation loss: 2.393757836464964

Epoch: 6| Step: 5
Training loss: 2.7552717137873852
Validation loss: 2.4277477352310064

Epoch: 6| Step: 6
Training loss: 2.286114457556602
Validation loss: 2.3989040044928482

Epoch: 6| Step: 7
Training loss: 1.5510753285495857
Validation loss: 2.3960940853572725

Epoch: 6| Step: 8
Training loss: 1.6901484298983598
Validation loss: 2.3954354796282846

Epoch: 6| Step: 9
Training loss: 1.8703781384109877
Validation loss: 2.345262945648182

Epoch: 6| Step: 10
Training loss: 2.1146610289583103
Validation loss: 2.4168219645513123

Epoch: 6| Step: 11
Training loss: 1.7329922224289604
Validation loss: 2.3528931861591333

Epoch: 6| Step: 12
Training loss: 1.659892557183025
Validation loss: 2.3762707821341906

Epoch: 6| Step: 13
Training loss: 1.241867072085382
Validation loss: 2.3925835456979274

Epoch: 226| Step: 0
Training loss: 3.060336536027552
Validation loss: 2.3713283665676834

Epoch: 6| Step: 1
Training loss: 1.8884874350463339
Validation loss: 2.3946259404645764

Epoch: 6| Step: 2
Training loss: 1.1841683079070373
Validation loss: 2.3830955935667335

Epoch: 6| Step: 3
Training loss: 1.9728351776255366
Validation loss: 2.3888389976953444

Epoch: 6| Step: 4
Training loss: 2.1569159764675616
Validation loss: 2.3930782861636484

Epoch: 6| Step: 5
Training loss: 1.6662457252441885
Validation loss: 2.3540712475711714

Epoch: 6| Step: 6
Training loss: 2.1064674966958856
Validation loss: 2.3899553403776346

Epoch: 6| Step: 7
Training loss: 1.7364931661052327
Validation loss: 2.3820658261133056

Epoch: 6| Step: 8
Training loss: 1.9589006400349398
Validation loss: 2.402216083406805

Epoch: 6| Step: 9
Training loss: 2.6913526554612552
Validation loss: 2.3902379322523095

Epoch: 6| Step: 10
Training loss: 2.456862014740074
Validation loss: 2.3755349645344435

Epoch: 6| Step: 11
Training loss: 1.9018728938547056
Validation loss: 2.3852865242097305

Epoch: 6| Step: 12
Training loss: 1.818229039619359
Validation loss: 2.4011869248911415

Epoch: 6| Step: 13
Training loss: 2.4736415834267618
Validation loss: 2.363307765132944

Epoch: 227| Step: 0
Training loss: 1.865137099680409
Validation loss: 2.39565977847401

Epoch: 6| Step: 1
Training loss: 2.5991094898206355
Validation loss: 2.377334377967817

Epoch: 6| Step: 2
Training loss: 1.9699457563881226
Validation loss: 2.403508072414325

Epoch: 6| Step: 3
Training loss: 1.4946921533651332
Validation loss: 2.405973749133847

Epoch: 6| Step: 4
Training loss: 1.7457980389847427
Validation loss: 2.375037884369588

Epoch: 6| Step: 5
Training loss: 2.399170207579388
Validation loss: 2.376452808508137

Epoch: 6| Step: 6
Training loss: 1.857230480453526
Validation loss: 2.3894991190286916

Epoch: 6| Step: 7
Training loss: 2.2002953287783877
Validation loss: 2.4292781988776606

Epoch: 6| Step: 8
Training loss: 2.3919277256919953
Validation loss: 2.378735214586724

Epoch: 6| Step: 9
Training loss: 1.7674201683997668
Validation loss: 2.3605985315117377

Epoch: 6| Step: 10
Training loss: 2.2779547524383563
Validation loss: 2.376399883573271

Epoch: 6| Step: 11
Training loss: 1.91589342635617
Validation loss: 2.3852601228117143

Epoch: 6| Step: 12
Training loss: 2.5838238240230056
Validation loss: 2.3622178562203655

Epoch: 6| Step: 13
Training loss: 1.9903527880661067
Validation loss: 2.413301315964887

Epoch: 228| Step: 0
Training loss: 2.3240009622555444
Validation loss: 2.355743858507408

Epoch: 6| Step: 1
Training loss: 2.6455844151308057
Validation loss: 2.398295791253929

Epoch: 6| Step: 2
Training loss: 2.167655083587185
Validation loss: 2.3822169137343017

Epoch: 6| Step: 3
Training loss: 2.236608709199355
Validation loss: 2.37923593360124

Epoch: 6| Step: 4
Training loss: 1.306717441279481
Validation loss: 2.3853859203345533

Epoch: 6| Step: 5
Training loss: 1.93958576282823
Validation loss: 2.374055532148726

Epoch: 6| Step: 6
Training loss: 1.9986293387478362
Validation loss: 2.3724510998964297

Epoch: 6| Step: 7
Training loss: 1.968081406188961
Validation loss: 2.3813682220406673

Epoch: 6| Step: 8
Training loss: 2.712370743726255
Validation loss: 2.3742880982120846

Epoch: 6| Step: 9
Training loss: 1.949923217924591
Validation loss: 2.3942662389708227

Epoch: 6| Step: 10
Training loss: 2.4736388846833783
Validation loss: 2.39666280276036

Epoch: 6| Step: 11
Training loss: 1.997286923326843
Validation loss: 2.3876606310407973

Epoch: 6| Step: 12
Training loss: 1.3590297918359466
Validation loss: 2.3679665398690677

Epoch: 6| Step: 13
Training loss: 1.7567739173582368
Validation loss: 2.374764532777167

Epoch: 229| Step: 0
Training loss: 2.312814227225828
Validation loss: 2.4086982599882343

Epoch: 6| Step: 1
Training loss: 2.0056676429406766
Validation loss: 2.3721207024376114

Epoch: 6| Step: 2
Training loss: 2.2743314578172393
Validation loss: 2.40434545824401

Epoch: 6| Step: 3
Training loss: 1.9187130853040641
Validation loss: 2.426037466711229

Epoch: 6| Step: 4
Training loss: 1.686740704420503
Validation loss: 2.3931407780698755

Epoch: 6| Step: 5
Training loss: 2.5253543718395526
Validation loss: 2.3748754329429342

Epoch: 6| Step: 6
Training loss: 1.0696814131389445
Validation loss: 2.3806330484868625

Epoch: 6| Step: 7
Training loss: 1.870150652952039
Validation loss: 2.3796762802674722

Epoch: 6| Step: 8
Training loss: 2.1611732999695374
Validation loss: 2.3412430862689

Epoch: 6| Step: 9
Training loss: 2.177619198888137
Validation loss: 2.3935165681717745

Epoch: 6| Step: 10
Training loss: 2.825580274012348
Validation loss: 2.37778101586853

Epoch: 6| Step: 11
Training loss: 1.6411334748460078
Validation loss: 2.4040434860185416

Epoch: 6| Step: 12
Training loss: 2.2537926392375036
Validation loss: 2.3606107035137875

Epoch: 6| Step: 13
Training loss: 2.3025534884756227
Validation loss: 2.3996255720567516

Epoch: 230| Step: 0
Training loss: 2.36036641089015
Validation loss: 2.3991851587270348

Epoch: 6| Step: 1
Training loss: 2.0255219905265025
Validation loss: 2.3848819621480204

Epoch: 6| Step: 2
Training loss: 2.382597766643532
Validation loss: 2.412650708925486

Epoch: 6| Step: 3
Training loss: 2.3754926471728894
Validation loss: 2.405067609339336

Epoch: 6| Step: 4
Training loss: 1.3883708729578295
Validation loss: 2.3888447499027037

Epoch: 6| Step: 5
Training loss: 1.8538001337558172
Validation loss: 2.399688811149531

Epoch: 6| Step: 6
Training loss: 1.3857598226337784
Validation loss: 2.40570680378571

Epoch: 6| Step: 7
Training loss: 2.267474241941066
Validation loss: 2.3855810420885826

Epoch: 6| Step: 8
Training loss: 2.1611031359166093
Validation loss: 2.3716513207285987

Epoch: 6| Step: 9
Training loss: 1.923323852751498
Validation loss: 2.4147663045607697

Epoch: 6| Step: 10
Training loss: 2.402255619572484
Validation loss: 2.3864534015487915

Epoch: 6| Step: 11
Training loss: 2.713119903608877
Validation loss: 2.410661329182689

Epoch: 6| Step: 12
Training loss: 1.6456791366904153
Validation loss: 2.401091071528498

Epoch: 6| Step: 13
Training loss: 2.1652252709095654
Validation loss: 2.3893601773098796

Epoch: 231| Step: 0
Training loss: 2.0561347766815166
Validation loss: 2.3947176360985196

Epoch: 6| Step: 1
Training loss: 2.2273123565998336
Validation loss: 2.399929439710639

Epoch: 6| Step: 2
Training loss: 1.85796232012431
Validation loss: 2.3943254887988603

Epoch: 6| Step: 3
Training loss: 2.631004187910806
Validation loss: 2.3822056646332315

Epoch: 6| Step: 4
Training loss: 2.263075874341137
Validation loss: 2.372035245875518

Epoch: 6| Step: 5
Training loss: 1.8179182425098757
Validation loss: 2.4040399413456583

Epoch: 6| Step: 6
Training loss: 2.179291610588338
Validation loss: 2.354008476466496

Epoch: 6| Step: 7
Training loss: 1.333271780182699
Validation loss: 2.3609188890317103

Epoch: 6| Step: 8
Training loss: 1.8873949438504558
Validation loss: 2.3882009371860904

Epoch: 6| Step: 9
Training loss: 1.8176254938553997
Validation loss: 2.37860143186932

Epoch: 6| Step: 10
Training loss: 2.7370964240530893
Validation loss: 2.378209065509514

Epoch: 6| Step: 11
Training loss: 1.904168102116395
Validation loss: 2.362587867444474

Epoch: 6| Step: 12
Training loss: 2.1147631739417894
Validation loss: 2.374070558312212

Epoch: 6| Step: 13
Training loss: 2.450781608000253
Validation loss: 2.369927340336475

Epoch: 232| Step: 0
Training loss: 2.131499952050964
Validation loss: 2.3662396364903993

Epoch: 6| Step: 1
Training loss: 2.335324618464936
Validation loss: 2.377430661314385

Epoch: 6| Step: 2
Training loss: 2.2319640910907275
Validation loss: 2.3978547081663932

Epoch: 6| Step: 3
Training loss: 2.9380818866097513
Validation loss: 2.3808808521800544

Epoch: 6| Step: 4
Training loss: 1.7696774319189394
Validation loss: 2.4053354473684982

Epoch: 6| Step: 5
Training loss: 1.6141699312984845
Validation loss: 2.3593219951327793

Epoch: 6| Step: 6
Training loss: 1.9934193112682312
Validation loss: 2.363629835755696

Epoch: 6| Step: 7
Training loss: 1.5106051974089607
Validation loss: 2.3643685147938864

Epoch: 6| Step: 8
Training loss: 2.0363257739801552
Validation loss: 2.371308340205949

Epoch: 6| Step: 9
Training loss: 2.1095454394393998
Validation loss: 2.3806390068204637

Epoch: 6| Step: 10
Training loss: 2.211329556808183
Validation loss: 2.393834491991658

Epoch: 6| Step: 11
Training loss: 1.8067840684186247
Validation loss: 2.4103481838355667

Epoch: 6| Step: 12
Training loss: 2.1420517225245086
Validation loss: 2.3977500200402058

Epoch: 6| Step: 13
Training loss: 1.8870302184110708
Validation loss: 2.3886862790366497

Epoch: 233| Step: 0
Training loss: 2.0233909572123623
Validation loss: 2.3650359703106494

Epoch: 6| Step: 1
Training loss: 1.9980793910210064
Validation loss: 2.3438795768987473

Epoch: 6| Step: 2
Training loss: 1.898263617193544
Validation loss: 2.395791363092144

Epoch: 6| Step: 3
Training loss: 1.8331525742401027
Validation loss: 2.406303971421372

Epoch: 6| Step: 4
Training loss: 2.2630312048378443
Validation loss: 2.385649119556555

Epoch: 6| Step: 5
Training loss: 1.5665733647802038
Validation loss: 2.3495493870721025

Epoch: 6| Step: 6
Training loss: 2.0504212853727806
Validation loss: 2.371322785928275

Epoch: 6| Step: 7
Training loss: 2.962211395241342
Validation loss: 2.4038153942213154

Epoch: 6| Step: 8
Training loss: 2.1758000973992933
Validation loss: 2.360967281222645

Epoch: 6| Step: 9
Training loss: 2.0513229381325577
Validation loss: 2.32963082649346

Epoch: 6| Step: 10
Training loss: 1.3171852591462718
Validation loss: 2.3640112528856827

Epoch: 6| Step: 11
Training loss: 2.518361942508289
Validation loss: 2.3774680599937477

Epoch: 6| Step: 12
Training loss: 2.101284079561833
Validation loss: 2.3617339619442594

Epoch: 6| Step: 13
Training loss: 1.4698016682948467
Validation loss: 2.3844262253199426

Epoch: 234| Step: 0
Training loss: 2.1957012660383963
Validation loss: 2.3915095855207325

Epoch: 6| Step: 1
Training loss: 1.99188469474164
Validation loss: 2.4158971308810253

Epoch: 6| Step: 2
Training loss: 2.3265242225669858
Validation loss: 2.392043103085199

Epoch: 6| Step: 3
Training loss: 1.998767950133643
Validation loss: 2.36249325797903

Epoch: 6| Step: 4
Training loss: 2.4828670891821707
Validation loss: 2.3831685473149267

Epoch: 6| Step: 5
Training loss: 2.276303087900607
Validation loss: 2.3816498812718896

Epoch: 6| Step: 6
Training loss: 1.743288590286774
Validation loss: 2.3627285880551203

Epoch: 6| Step: 7
Training loss: 2.0109935453321763
Validation loss: 2.348556913900603

Epoch: 6| Step: 8
Training loss: 2.360555290423058
Validation loss: 2.3549341150006318

Epoch: 6| Step: 9
Training loss: 2.1831260548787554
Validation loss: 2.3840764521404543

Epoch: 6| Step: 10
Training loss: 1.6578774283994688
Validation loss: 2.3644805926720376

Epoch: 6| Step: 11
Training loss: 2.3773790791243523
Validation loss: 2.392120855255101

Epoch: 6| Step: 12
Training loss: 1.5799241338695884
Validation loss: 2.3514939034029827

Epoch: 6| Step: 13
Training loss: 1.452693505980358
Validation loss: 2.367773549280227

Epoch: 235| Step: 0
Training loss: 2.286914950738842
Validation loss: 2.346718971286499

Epoch: 6| Step: 1
Training loss: 1.8310132156761827
Validation loss: 2.342605362721693

Epoch: 6| Step: 2
Training loss: 2.2785710320683776
Validation loss: 2.381673355586858

Epoch: 6| Step: 3
Training loss: 1.7474924241803593
Validation loss: 2.3682025162983447

Epoch: 6| Step: 4
Training loss: 2.656430855372257
Validation loss: 2.3539070409482643

Epoch: 6| Step: 5
Training loss: 1.6412922546804538
Validation loss: 2.3572227485752197

Epoch: 6| Step: 6
Training loss: 1.8329945453535585
Validation loss: 2.4387168486794044

Epoch: 6| Step: 7
Training loss: 2.260030534757415
Validation loss: 2.3832853781707932

Epoch: 6| Step: 8
Training loss: 2.7147042876723857
Validation loss: 2.382109435458675

Epoch: 6| Step: 9
Training loss: 1.6151847785614142
Validation loss: 2.406570238533565

Epoch: 6| Step: 10
Training loss: 1.5978482977387654
Validation loss: 2.3985447350746507

Epoch: 6| Step: 11
Training loss: 2.0732995706775537
Validation loss: 2.3824422709056927

Epoch: 6| Step: 12
Training loss: 2.1284111917225497
Validation loss: 2.3680623742985563

Epoch: 6| Step: 13
Training loss: 1.7119520132033095
Validation loss: 2.3560279728310562

Epoch: 236| Step: 0
Training loss: 2.17459430199414
Validation loss: 2.4100176088475047

Epoch: 6| Step: 1
Training loss: 1.8750811877157514
Validation loss: 2.3603597757751174

Epoch: 6| Step: 2
Training loss: 1.8311810503272905
Validation loss: 2.390396375325072

Epoch: 6| Step: 3
Training loss: 2.635572758048992
Validation loss: 2.37642765960203

Epoch: 6| Step: 4
Training loss: 2.0289061888943363
Validation loss: 2.405750549372131

Epoch: 6| Step: 5
Training loss: 2.426319793530629
Validation loss: 2.445805893744945

Epoch: 6| Step: 6
Training loss: 1.453875112225759
Validation loss: 2.4215491460360345

Epoch: 6| Step: 7
Training loss: 2.18391604424943
Validation loss: 2.3766305159044463

Epoch: 6| Step: 8
Training loss: 1.2860945780638688
Validation loss: 2.383476566365236

Epoch: 6| Step: 9
Training loss: 2.2201290948809738
Validation loss: 2.361655895407661

Epoch: 6| Step: 10
Training loss: 2.1340039177798746
Validation loss: 2.3925370391606187

Epoch: 6| Step: 11
Training loss: 1.9569687519258974
Validation loss: 2.3686247157384397

Epoch: 6| Step: 12
Training loss: 2.282456170587794
Validation loss: 2.3934337553469156

Epoch: 6| Step: 13
Training loss: 2.3338458542837865
Validation loss: 2.3672513240783446

Epoch: 237| Step: 0
Training loss: 1.8891525209242512
Validation loss: 2.3902080788146662

Epoch: 6| Step: 1
Training loss: 1.9890180919931018
Validation loss: 2.4121907782796286

Epoch: 6| Step: 2
Training loss: 2.0764602073348923
Validation loss: 2.3411609068301598

Epoch: 6| Step: 3
Training loss: 1.9530507188023134
Validation loss: 2.3923138299170006

Epoch: 6| Step: 4
Training loss: 2.335816549276458
Validation loss: 2.385078635855628

Epoch: 6| Step: 5
Training loss: 2.6059722642630243
Validation loss: 2.3842122136409687

Epoch: 6| Step: 6
Training loss: 2.208063313032566
Validation loss: 2.3763464574285105

Epoch: 6| Step: 7
Training loss: 1.389468794662749
Validation loss: 2.374371420077314

Epoch: 6| Step: 8
Training loss: 2.0258427173308764
Validation loss: 2.368692685274057

Epoch: 6| Step: 9
Training loss: 1.9386107429552266
Validation loss: 2.3594018719620684

Epoch: 6| Step: 10
Training loss: 1.7233061310682916
Validation loss: 2.344551522533944

Epoch: 6| Step: 11
Training loss: 2.3924909303307897
Validation loss: 2.369747657912649

Epoch: 6| Step: 12
Training loss: 1.6169269738914325
Validation loss: 2.388421347208985

Epoch: 6| Step: 13
Training loss: 2.3138213635387164
Validation loss: 2.378002324304323

Epoch: 238| Step: 0
Training loss: 1.5039951843123749
Validation loss: 2.3379110977118485

Epoch: 6| Step: 1
Training loss: 2.4789855848157165
Validation loss: 2.366786629760323

Epoch: 6| Step: 2
Training loss: 1.9441289403563122
Validation loss: 2.3928173317450696

Epoch: 6| Step: 3
Training loss: 1.6064988889717084
Validation loss: 2.337118770564046

Epoch: 6| Step: 4
Training loss: 3.048585695138089
Validation loss: 2.3705239779167293

Epoch: 6| Step: 5
Training loss: 2.321770309614082
Validation loss: 2.3772963447127244

Epoch: 6| Step: 6
Training loss: 2.082468183807922
Validation loss: 2.393264311952264

Epoch: 6| Step: 7
Training loss: 1.8935114367199846
Validation loss: 2.401933624798019

Epoch: 6| Step: 8
Training loss: 2.688737451301493
Validation loss: 2.32015476579399

Epoch: 6| Step: 9
Training loss: 1.5527124175432543
Validation loss: 2.377039762593753

Epoch: 6| Step: 10
Training loss: 1.7689435711405943
Validation loss: 2.4245769553751626

Epoch: 6| Step: 11
Training loss: 1.6145672048768118
Validation loss: 2.432570273366702

Epoch: 6| Step: 12
Training loss: 2.0453344473597457
Validation loss: 2.3557476260293955

Epoch: 6| Step: 13
Training loss: 1.8215827930031445
Validation loss: 2.3999162771292673

Epoch: 239| Step: 0
Training loss: 1.8060271340124052
Validation loss: 2.3752426925863093

Epoch: 6| Step: 1
Training loss: 2.1071451339524647
Validation loss: 2.4170402387340295

Epoch: 6| Step: 2
Training loss: 2.134931915591269
Validation loss: 2.3867526062638382

Epoch: 6| Step: 3
Training loss: 1.8448769955867559
Validation loss: 2.3898571024262383

Epoch: 6| Step: 4
Training loss: 1.5941721787118945
Validation loss: 2.3871692739583574

Epoch: 6| Step: 5
Training loss: 2.057405132271206
Validation loss: 2.4192167578708603

Epoch: 6| Step: 6
Training loss: 2.7786871428250817
Validation loss: 2.3756550466811905

Epoch: 6| Step: 7
Training loss: 2.07803092112588
Validation loss: 2.390822898163635

Epoch: 6| Step: 8
Training loss: 2.3153604909788963
Validation loss: 2.394083394282709

Epoch: 6| Step: 9
Training loss: 2.2426996476896575
Validation loss: 2.411654332006784

Epoch: 6| Step: 10
Training loss: 2.0003901339535743
Validation loss: 2.3554785062012082

Epoch: 6| Step: 11
Training loss: 1.9818554599921099
Validation loss: 2.4130408672682884

Epoch: 6| Step: 12
Training loss: 1.9160738594934643
Validation loss: 2.361451734824781

Epoch: 6| Step: 13
Training loss: 1.8658174731778943
Validation loss: 2.401041608297963

Epoch: 240| Step: 0
Training loss: 1.661597920675726
Validation loss: 2.3799002395876414

Epoch: 6| Step: 1
Training loss: 1.980561624790836
Validation loss: 2.3929405400336803

Epoch: 6| Step: 2
Training loss: 2.158153191588646
Validation loss: 2.387126038422392

Epoch: 6| Step: 3
Training loss: 2.4009547241975397
Validation loss: 2.370680331087326

Epoch: 6| Step: 4
Training loss: 1.918041593019106
Validation loss: 2.3994373694340094

Epoch: 6| Step: 5
Training loss: 1.8178698477995663
Validation loss: 2.377551020797077

Epoch: 6| Step: 6
Training loss: 2.087951373794671
Validation loss: 2.377412465604903

Epoch: 6| Step: 7
Training loss: 2.3653172321753555
Validation loss: 2.374703597661193

Epoch: 6| Step: 8
Training loss: 2.7204113849719693
Validation loss: 2.337271435398571

Epoch: 6| Step: 9
Training loss: 1.5342755691414136
Validation loss: 2.3939788346563033

Epoch: 6| Step: 10
Training loss: 1.7596172647037218
Validation loss: 2.35932905096306

Epoch: 6| Step: 11
Training loss: 1.9753305568995272
Validation loss: 2.357268406967368

Epoch: 6| Step: 12
Training loss: 2.3877066957167306
Validation loss: 2.3629868895861548

Epoch: 6| Step: 13
Training loss: 2.1106614322697856
Validation loss: 2.3878777251824297

Epoch: 241| Step: 0
Training loss: 1.8053042856445225
Validation loss: 2.408302880382862

Epoch: 6| Step: 1
Training loss: 2.1405113914024456
Validation loss: 2.3725278949155535

Epoch: 6| Step: 2
Training loss: 2.0939790970452177
Validation loss: 2.4013946806129627

Epoch: 6| Step: 3
Training loss: 2.4835943759030648
Validation loss: 2.3500293010734272

Epoch: 6| Step: 4
Training loss: 1.5038722443141996
Validation loss: 2.386319390295022

Epoch: 6| Step: 5
Training loss: 2.1174586498992616
Validation loss: 2.4260144813722926

Epoch: 6| Step: 6
Training loss: 2.457909843908285
Validation loss: 2.3876949936145393

Epoch: 6| Step: 7
Training loss: 2.2433107333960276
Validation loss: 2.4244379101508122

Epoch: 6| Step: 8
Training loss: 1.7828385480738083
Validation loss: 2.3639552493037463

Epoch: 6| Step: 9
Training loss: 1.9595378120591724
Validation loss: 2.3776098655459235

Epoch: 6| Step: 10
Training loss: 1.9184437957874123
Validation loss: 2.4033007404647337

Epoch: 6| Step: 11
Training loss: 2.221984547249722
Validation loss: 2.390915187848067

Epoch: 6| Step: 12
Training loss: 1.894406406969113
Validation loss: 2.3881526695966175

Epoch: 6| Step: 13
Training loss: 2.275245079002512
Validation loss: 2.4205689612596704

Epoch: 242| Step: 0
Training loss: 2.285346755213515
Validation loss: 2.4255932441185486

Epoch: 6| Step: 1
Training loss: 2.080950200479925
Validation loss: 2.3961560594185194

Epoch: 6| Step: 2
Training loss: 2.577238728169181
Validation loss: 2.408224871427411

Epoch: 6| Step: 3
Training loss: 2.160510291115869
Validation loss: 2.4295159722414827

Epoch: 6| Step: 4
Training loss: 1.6767147994037115
Validation loss: 2.422620215004789

Epoch: 6| Step: 5
Training loss: 2.2361566869331013
Validation loss: 2.405470137996437

Epoch: 6| Step: 6
Training loss: 1.223560133204188
Validation loss: 2.4094418410088045

Epoch: 6| Step: 7
Training loss: 2.362843673171468
Validation loss: 2.384600762620361

Epoch: 6| Step: 8
Training loss: 1.8225141316979265
Validation loss: 2.4106162923166146

Epoch: 6| Step: 9
Training loss: 2.0237061311185855
Validation loss: 2.38640292160675

Epoch: 6| Step: 10
Training loss: 2.324170742019941
Validation loss: 2.3941811681044083

Epoch: 6| Step: 11
Training loss: 1.7617620560087528
Validation loss: 2.355313999316323

Epoch: 6| Step: 12
Training loss: 2.003372686489381
Validation loss: 2.356225145485834

Epoch: 6| Step: 13
Training loss: 1.6506202312315374
Validation loss: 2.406758760029821

Epoch: 243| Step: 0
Training loss: 1.8169894030928022
Validation loss: 2.370837430332102

Epoch: 6| Step: 1
Training loss: 2.1748322038489962
Validation loss: 2.3933659914254046

Epoch: 6| Step: 2
Training loss: 1.9768828482989167
Validation loss: 2.388365717430467

Epoch: 6| Step: 3
Training loss: 1.833788454033542
Validation loss: 2.4409072322670995

Epoch: 6| Step: 4
Training loss: 1.852713054395167
Validation loss: 2.399950660776082

Epoch: 6| Step: 5
Training loss: 2.246732670675674
Validation loss: 2.3796849676509293

Epoch: 6| Step: 6
Training loss: 1.7932330832178707
Validation loss: 2.387363342564412

Epoch: 6| Step: 7
Training loss: 1.9426890995276898
Validation loss: 2.4070158561223374

Epoch: 6| Step: 8
Training loss: 1.6139191850994599
Validation loss: 2.35025242479811

Epoch: 6| Step: 9
Training loss: 2.444095979282488
Validation loss: 2.3776508152361346

Epoch: 6| Step: 10
Training loss: 1.711114743601809
Validation loss: 2.3807712051938883

Epoch: 6| Step: 11
Training loss: 2.445575346546241
Validation loss: 2.367058131131102

Epoch: 6| Step: 12
Training loss: 2.142409089339663
Validation loss: 2.358739599877344

Epoch: 6| Step: 13
Training loss: 2.8405668447855303
Validation loss: 2.3801675685625567

Epoch: 244| Step: 0
Training loss: 2.5323792752471284
Validation loss: 2.3858085985982442

Epoch: 6| Step: 1
Training loss: 1.9088738315986624
Validation loss: 2.396280834534475

Epoch: 6| Step: 2
Training loss: 1.522285377897007
Validation loss: 2.3841865594861833

Epoch: 6| Step: 3
Training loss: 2.2172408008150195
Validation loss: 2.3787297396984997

Epoch: 6| Step: 4
Training loss: 2.0390412194321765
Validation loss: 2.409140854492982

Epoch: 6| Step: 5
Training loss: 1.523307129587946
Validation loss: 2.349434326728063

Epoch: 6| Step: 6
Training loss: 2.5401483180078337
Validation loss: 2.3668049266569176

Epoch: 6| Step: 7
Training loss: 2.0991370517064682
Validation loss: 2.3848381164830683

Epoch: 6| Step: 8
Training loss: 2.549385284679903
Validation loss: 2.3843030990734966

Epoch: 6| Step: 9
Training loss: 2.106674160682451
Validation loss: 2.371524166047034

Epoch: 6| Step: 10
Training loss: 2.2455456404939222
Validation loss: 2.3511879356611023

Epoch: 6| Step: 11
Training loss: 1.9799160458847318
Validation loss: 2.3817656672060425

Epoch: 6| Step: 12
Training loss: 1.6369358546949433
Validation loss: 2.3895341053186794

Epoch: 6| Step: 13
Training loss: 1.1183049941890075
Validation loss: 2.3796657894340156

Epoch: 245| Step: 0
Training loss: 1.8483102298366998
Validation loss: 2.376464290884267

Epoch: 6| Step: 1
Training loss: 1.8395946682342814
Validation loss: 2.3745169123987373

Epoch: 6| Step: 2
Training loss: 1.7955677750707257
Validation loss: 2.4073433173439205

Epoch: 6| Step: 3
Training loss: 1.8227713681398043
Validation loss: 2.409894825250451

Epoch: 6| Step: 4
Training loss: 1.9087218220947297
Validation loss: 2.3790360769648253

Epoch: 6| Step: 5
Training loss: 1.1646953117204846
Validation loss: 2.384734103425414

Epoch: 6| Step: 6
Training loss: 2.174016541629527
Validation loss: 2.390488338297476

Epoch: 6| Step: 7
Training loss: 2.300419570137029
Validation loss: 2.4060083669352426

Epoch: 6| Step: 8
Training loss: 2.324791589235501
Validation loss: 2.385872447295136

Epoch: 6| Step: 9
Training loss: 2.0326563734872214
Validation loss: 2.407912784780948

Epoch: 6| Step: 10
Training loss: 2.6148370465186144
Validation loss: 2.3883522506796027

Epoch: 6| Step: 11
Training loss: 2.495968428974513
Validation loss: 2.384841370966748

Epoch: 6| Step: 12
Training loss: 1.87439959767818
Validation loss: 2.3808422284348096

Epoch: 6| Step: 13
Training loss: 1.9768588480981526
Validation loss: 2.387682582817013

Epoch: 246| Step: 0
Training loss: 1.4825087208997947
Validation loss: 2.424240753173485

Epoch: 6| Step: 1
Training loss: 2.131347824044237
Validation loss: 2.3859558180408915

Epoch: 6| Step: 2
Training loss: 2.1790097731449443
Validation loss: 2.4070124926285894

Epoch: 6| Step: 3
Training loss: 1.7164589611184584
Validation loss: 2.3596023268596857

Epoch: 6| Step: 4
Training loss: 1.6818702177719007
Validation loss: 2.3595998279739554

Epoch: 6| Step: 5
Training loss: 1.820285387614948
Validation loss: 2.401843014246096

Epoch: 6| Step: 6
Training loss: 1.6440083811933812
Validation loss: 2.405303016555897

Epoch: 6| Step: 7
Training loss: 2.021224885217153
Validation loss: 2.3830761921431427

Epoch: 6| Step: 8
Training loss: 2.1774280281304335
Validation loss: 2.3856914168766825

Epoch: 6| Step: 9
Training loss: 1.9468137777386083
Validation loss: 2.341841351360771

Epoch: 6| Step: 10
Training loss: 2.1704113096699693
Validation loss: 2.3887342986619218

Epoch: 6| Step: 11
Training loss: 2.354981936731737
Validation loss: 2.4137623897033627

Epoch: 6| Step: 12
Training loss: 2.2907845851373563
Validation loss: 2.3993882829338498

Epoch: 6| Step: 13
Training loss: 2.6180338387863276
Validation loss: 2.4135566253335226

Epoch: 247| Step: 0
Training loss: 2.60600821931001
Validation loss: 2.4049921347777494

Epoch: 6| Step: 1
Training loss: 1.3304206306325987
Validation loss: 2.3889338815904795

Epoch: 6| Step: 2
Training loss: 2.428868195489325
Validation loss: 2.3888151108621964

Epoch: 6| Step: 3
Training loss: 1.9645344242333354
Validation loss: 2.330698431466249

Epoch: 6| Step: 4
Training loss: 2.402230410499666
Validation loss: 2.4016570935982906

Epoch: 6| Step: 5
Training loss: 2.5033368729398298
Validation loss: 2.371332465550855

Epoch: 6| Step: 6
Training loss: 1.5913188567625092
Validation loss: 2.3513169058693677

Epoch: 6| Step: 7
Training loss: 1.8474706189577108
Validation loss: 2.359421439808184

Epoch: 6| Step: 8
Training loss: 2.437648768653439
Validation loss: 2.3814474315369147

Epoch: 6| Step: 9
Training loss: 1.9426986721367896
Validation loss: 2.368029810308883

Epoch: 6| Step: 10
Training loss: 1.624441784567916
Validation loss: 2.338629247486764

Epoch: 6| Step: 11
Training loss: 1.512159337544024
Validation loss: 2.3613642310980416

Epoch: 6| Step: 12
Training loss: 1.7235784505857243
Validation loss: 2.3856363768059152

Epoch: 6| Step: 13
Training loss: 1.6420674114073261
Validation loss: 2.3912266904288577

Epoch: 248| Step: 0
Training loss: 2.026382718313977
Validation loss: 2.3796376466668145

Epoch: 6| Step: 1
Training loss: 2.394227548478641
Validation loss: 2.3785889930245685

Epoch: 6| Step: 2
Training loss: 1.9535769740713638
Validation loss: 2.3459914047229504

Epoch: 6| Step: 3
Training loss: 2.364129335173466
Validation loss: 2.363769417913886

Epoch: 6| Step: 4
Training loss: 1.7758092942647776
Validation loss: 2.375822738104626

Epoch: 6| Step: 5
Training loss: 1.850790257107937
Validation loss: 2.3638733985313363

Epoch: 6| Step: 6
Training loss: 1.6270602444008986
Validation loss: 2.4183576327036467

Epoch: 6| Step: 7
Training loss: 1.8061708241569419
Validation loss: 2.3432033106321843

Epoch: 6| Step: 8
Training loss: 1.5982773746298427
Validation loss: 2.4133938295611324

Epoch: 6| Step: 9
Training loss: 2.0429783195431948
Validation loss: 2.3505699672192493

Epoch: 6| Step: 10
Training loss: 2.691476851424539
Validation loss: 2.366913789292403

Epoch: 6| Step: 11
Training loss: 1.6925531952019284
Validation loss: 2.4122914814510694

Epoch: 6| Step: 12
Training loss: 1.820848836185385
Validation loss: 2.362884375885396

Epoch: 6| Step: 13
Training loss: 2.706647749429125
Validation loss: 2.3835965495752673

Epoch: 249| Step: 0
Training loss: 1.479282437302672
Validation loss: 2.40447027165059

Epoch: 6| Step: 1
Training loss: 2.7181676482089054
Validation loss: 2.392228622106116

Epoch: 6| Step: 2
Training loss: 1.5990008453118796
Validation loss: 2.376464094549478

Epoch: 6| Step: 3
Training loss: 1.808078502976241
Validation loss: 2.363915155532979

Epoch: 6| Step: 4
Training loss: 1.9876455553605394
Validation loss: 2.4162533300158575

Epoch: 6| Step: 5
Training loss: 1.9280395884584647
Validation loss: 2.3593561456550782

Epoch: 6| Step: 6
Training loss: 2.1500471154306777
Validation loss: 2.3600579381476825

Epoch: 6| Step: 7
Training loss: 1.906953650508897
Validation loss: 2.3438335904217458

Epoch: 6| Step: 8
Training loss: 1.7961230487599176
Validation loss: 2.3623824059537815

Epoch: 6| Step: 9
Training loss: 2.1165015879660456
Validation loss: 2.358805373003506

Epoch: 6| Step: 10
Training loss: 1.8684802189148142
Validation loss: 2.360081106910548

Epoch: 6| Step: 11
Training loss: 2.4856894992193896
Validation loss: 2.360686551222417

Epoch: 6| Step: 12
Training loss: 2.088942060515308
Validation loss: 2.327997001922293

Epoch: 6| Step: 13
Training loss: 1.7939754145074163
Validation loss: 2.3840848858456414

Epoch: 250| Step: 0
Training loss: 1.5363882619968048
Validation loss: 2.402038792034977

Epoch: 6| Step: 1
Training loss: 1.9747368745929046
Validation loss: 2.3675515602816732

Epoch: 6| Step: 2
Training loss: 2.174580377899674
Validation loss: 2.4004740821045187

Epoch: 6| Step: 3
Training loss: 2.9906747843745154
Validation loss: 2.37356358576902

Epoch: 6| Step: 4
Training loss: 0.8363026685907285
Validation loss: 2.3533209558392847

Epoch: 6| Step: 5
Training loss: 1.9331123138021333
Validation loss: 2.339492189378658

Epoch: 6| Step: 6
Training loss: 1.7282376685500642
Validation loss: 2.3556827567737404

Epoch: 6| Step: 7
Training loss: 1.7094181229697938
Validation loss: 2.3963429626333728

Epoch: 6| Step: 8
Training loss: 1.897756069631447
Validation loss: 2.3390980812776343

Epoch: 6| Step: 9
Training loss: 1.832581004477011
Validation loss: 2.3624586286740454

Epoch: 6| Step: 10
Training loss: 2.6817161955051962
Validation loss: 2.3454841263653723

Epoch: 6| Step: 11
Training loss: 1.782345886416462
Validation loss: 2.394090386749614

Epoch: 6| Step: 12
Training loss: 2.2716802248569996
Validation loss: 2.3657326112779424

Epoch: 6| Step: 13
Training loss: 1.8283105739729022
Validation loss: 2.4116237901399318

Epoch: 251| Step: 0
Training loss: 1.9933099912894912
Validation loss: 2.4122853834365166

Epoch: 6| Step: 1
Training loss: 2.6074477519490755
Validation loss: 2.3512389061547725

Epoch: 6| Step: 2
Training loss: 2.1881065617612316
Validation loss: 2.345166316172803

Epoch: 6| Step: 3
Training loss: 1.510163761757661
Validation loss: 2.3804678740535583

Epoch: 6| Step: 4
Training loss: 1.381486806808581
Validation loss: 2.3262693766779514

Epoch: 6| Step: 5
Training loss: 1.699264139906519
Validation loss: 2.401243216905949

Epoch: 6| Step: 6
Training loss: 2.108995982839594
Validation loss: 2.386173256376192

Epoch: 6| Step: 7
Training loss: 1.4458841379054486
Validation loss: 2.426890162784131

Epoch: 6| Step: 8
Training loss: 2.001210561598411
Validation loss: 2.3970394225031937

Epoch: 6| Step: 9
Training loss: 1.56926232897048
Validation loss: 2.3882498467901283

Epoch: 6| Step: 10
Training loss: 1.8510981754170546
Validation loss: 2.3769075540624214

Epoch: 6| Step: 11
Training loss: 2.30695854405731
Validation loss: 2.349792425875769

Epoch: 6| Step: 12
Training loss: 2.4475743372287972
Validation loss: 2.3645567363721116

Epoch: 6| Step: 13
Training loss: 2.801397832997946
Validation loss: 2.3991579170507604

Epoch: 252| Step: 0
Training loss: 1.8759343044718315
Validation loss: 2.351559263235387

Epoch: 6| Step: 1
Training loss: 1.9517446293992131
Validation loss: 2.366137664600171

Epoch: 6| Step: 2
Training loss: 2.6324718039833
Validation loss: 2.3878143321817316

Epoch: 6| Step: 3
Training loss: 1.8979790530400509
Validation loss: 2.3773330591237385

Epoch: 6| Step: 4
Training loss: 1.9383973535454317
Validation loss: 2.397778620593821

Epoch: 6| Step: 5
Training loss: 1.5376431654357996
Validation loss: 2.4208440782272076

Epoch: 6| Step: 6
Training loss: 2.045572813063598
Validation loss: 2.3547102601576237

Epoch: 6| Step: 7
Training loss: 1.673694796688135
Validation loss: 2.3511527036936344

Epoch: 6| Step: 8
Training loss: 1.944502451197952
Validation loss: 2.354103149230901

Epoch: 6| Step: 9
Training loss: 2.4672158218507305
Validation loss: 2.341177101167815

Epoch: 6| Step: 10
Training loss: 2.1537879487965728
Validation loss: 2.3760611425483456

Epoch: 6| Step: 11
Training loss: 1.6618827190126653
Validation loss: 2.3902573988867526

Epoch: 6| Step: 12
Training loss: 2.039466320989558
Validation loss: 2.336961237708146

Epoch: 6| Step: 13
Training loss: 1.8505908331894345
Validation loss: 2.3714218241096443

Epoch: 253| Step: 0
Training loss: 2.1623272600805596
Validation loss: 2.396634490541781

Epoch: 6| Step: 1
Training loss: 1.820560814943627
Validation loss: 2.3774179942081415

Epoch: 6| Step: 2
Training loss: 1.535303317492306
Validation loss: 2.4119743982633564

Epoch: 6| Step: 3
Training loss: 2.1135168032423803
Validation loss: 2.3941574984017433

Epoch: 6| Step: 4
Training loss: 2.2413645440280514
Validation loss: 2.3570420911271386

Epoch: 6| Step: 5
Training loss: 1.5122468405470004
Validation loss: 2.4004761529025687

Epoch: 6| Step: 6
Training loss: 2.040357390494328
Validation loss: 2.366876228179024

Epoch: 6| Step: 7
Training loss: 1.295163875653569
Validation loss: 2.3863164617311887

Epoch: 6| Step: 8
Training loss: 2.192837225839971
Validation loss: 2.4036938818890907

Epoch: 6| Step: 9
Training loss: 1.3223938647337308
Validation loss: 2.382021749955212

Epoch: 6| Step: 10
Training loss: 2.427193591406251
Validation loss: 2.3588740134677484

Epoch: 6| Step: 11
Training loss: 2.2918914915832937
Validation loss: 2.354369774834914

Epoch: 6| Step: 12
Training loss: 2.229864730153539
Validation loss: 2.3494755116222086

Epoch: 6| Step: 13
Training loss: 2.3580576269341127
Validation loss: 2.3370493441439946

Epoch: 254| Step: 0
Training loss: 1.8662789660260795
Validation loss: 2.4034800914905126

Epoch: 6| Step: 1
Training loss: 1.5495872994098885
Validation loss: 2.4232390702194206

Epoch: 6| Step: 2
Training loss: 1.6021620209827383
Validation loss: 2.3827314153572874

Epoch: 6| Step: 3
Training loss: 2.0898512795571134
Validation loss: 2.35451431894513

Epoch: 6| Step: 4
Training loss: 1.859678804598085
Validation loss: 2.388271694395087

Epoch: 6| Step: 5
Training loss: 1.643793443461077
Validation loss: 2.440361665391933

Epoch: 6| Step: 6
Training loss: 2.1732318399676145
Validation loss: 2.374311655568975

Epoch: 6| Step: 7
Training loss: 1.964695706866856
Validation loss: 2.4148287012687875

Epoch: 6| Step: 8
Training loss: 2.0183120677698168
Validation loss: 2.382477367280581

Epoch: 6| Step: 9
Training loss: 2.6416188914634935
Validation loss: 2.3935095172612497

Epoch: 6| Step: 10
Training loss: 2.0811692505714006
Validation loss: 2.386934923440371

Epoch: 6| Step: 11
Training loss: 1.8946302250443197
Validation loss: 2.428494384734811

Epoch: 6| Step: 12
Training loss: 2.0932437797188808
Validation loss: 2.440207321751985

Epoch: 6| Step: 13
Training loss: 2.5720790369576862
Validation loss: 2.3576741326457396

Epoch: 255| Step: 0
Training loss: 2.7309149076097152
Validation loss: 2.3712148084569846

Epoch: 6| Step: 1
Training loss: 1.8933106570609655
Validation loss: 2.349777464845355

Epoch: 6| Step: 2
Training loss: 1.7185992781703396
Validation loss: 2.370711858933888

Epoch: 6| Step: 3
Training loss: 2.3153546215359793
Validation loss: 2.4083360404227774

Epoch: 6| Step: 4
Training loss: 2.20742173242982
Validation loss: 2.3839221497484013

Epoch: 6| Step: 5
Training loss: 1.8431881193915576
Validation loss: 2.3688286563728718

Epoch: 6| Step: 6
Training loss: 1.8961886048609373
Validation loss: 2.338136362462321

Epoch: 6| Step: 7
Training loss: 1.5609807830399904
Validation loss: 2.3854468888652347

Epoch: 6| Step: 8
Training loss: 1.9724673341238863
Validation loss: 2.3248815247633647

Epoch: 6| Step: 9
Training loss: 1.7714410374901557
Validation loss: 2.37629454477384

Epoch: 6| Step: 10
Training loss: 1.936542028048373
Validation loss: 2.3723527071365695

Epoch: 6| Step: 11
Training loss: 2.1129660098026997
Validation loss: 2.345169927968725

Epoch: 6| Step: 12
Training loss: 1.4330652078565274
Validation loss: 2.386498055971408

Epoch: 6| Step: 13
Training loss: 2.434093344460294
Validation loss: 2.3952568876617097

Epoch: 256| Step: 0
Training loss: 1.9909404965738748
Validation loss: 2.3911822781613066

Epoch: 6| Step: 1
Training loss: 1.5988509880423851
Validation loss: 2.3646757671472582

Epoch: 6| Step: 2
Training loss: 1.519726346002065
Validation loss: 2.3835182257055227

Epoch: 6| Step: 3
Training loss: 2.6294788116860643
Validation loss: 2.3906574937399108

Epoch: 6| Step: 4
Training loss: 2.005569927425909
Validation loss: 2.3949726588312847

Epoch: 6| Step: 5
Training loss: 2.422103083545487
Validation loss: 2.399907928968707

Epoch: 6| Step: 6
Training loss: 2.308547482615895
Validation loss: 2.3510513445112298

Epoch: 6| Step: 7
Training loss: 1.506245010810915
Validation loss: 2.392814879867727

Epoch: 6| Step: 8
Training loss: 1.7579931547793286
Validation loss: 2.379587646459551

Epoch: 6| Step: 9
Training loss: 1.8168270813114937
Validation loss: 2.350433052209867

Epoch: 6| Step: 10
Training loss: 1.913943415460083
Validation loss: 2.38642899399284

Epoch: 6| Step: 11
Training loss: 2.3219653064524666
Validation loss: 2.359501503411587

Epoch: 6| Step: 12
Training loss: 1.8470015222680511
Validation loss: 2.367475986652815

Epoch: 6| Step: 13
Training loss: 1.5010348564944709
Validation loss: 2.3977485253177804

Epoch: 257| Step: 0
Training loss: 2.0279268517704456
Validation loss: 2.4042643853940935

Epoch: 6| Step: 1
Training loss: 1.4329656321523163
Validation loss: 2.341939803263874

Epoch: 6| Step: 2
Training loss: 1.781476391242135
Validation loss: 2.3843110470562845

Epoch: 6| Step: 3
Training loss: 1.9649702452331153
Validation loss: 2.399476314608254

Epoch: 6| Step: 4
Training loss: 1.5819996018246465
Validation loss: 2.3193806588784063

Epoch: 6| Step: 5
Training loss: 1.3051654602624563
Validation loss: 2.374525733100321

Epoch: 6| Step: 6
Training loss: 1.7921905490945755
Validation loss: 2.339820675579754

Epoch: 6| Step: 7
Training loss: 2.589462689520021
Validation loss: 2.3869513635668627

Epoch: 6| Step: 8
Training loss: 1.9844696743225037
Validation loss: 2.3940119082545115

Epoch: 6| Step: 9
Training loss: 2.8691095463450367
Validation loss: 2.387460677519915

Epoch: 6| Step: 10
Training loss: 1.9633125421084867
Validation loss: 2.376349080568224

Epoch: 6| Step: 11
Training loss: 2.192060892985669
Validation loss: 2.432978475896754

Epoch: 6| Step: 12
Training loss: 1.7192358544031083
Validation loss: 2.381813346309888

Epoch: 6| Step: 13
Training loss: 1.833735277445745
Validation loss: 2.3901391862457677

Epoch: 258| Step: 0
Training loss: 2.2696448082672718
Validation loss: 2.410753886664823

Epoch: 6| Step: 1
Training loss: 1.6473769984543978
Validation loss: 2.3782871400575605

Epoch: 6| Step: 2
Training loss: 2.2777870754372658
Validation loss: 2.3735940179326747

Epoch: 6| Step: 3
Training loss: 2.0517434033882425
Validation loss: 2.399169576064454

Epoch: 6| Step: 4
Training loss: 2.3219879985436744
Validation loss: 2.3734124657629105

Epoch: 6| Step: 5
Training loss: 1.907157556835365
Validation loss: 2.4391655291937484

Epoch: 6| Step: 6
Training loss: 2.085997848495003
Validation loss: 2.3452850816563355

Epoch: 6| Step: 7
Training loss: 2.078168481357553
Validation loss: 2.3767937253640814

Epoch: 6| Step: 8
Training loss: 1.5198865931015684
Validation loss: 2.363411620708741

Epoch: 6| Step: 9
Training loss: 1.8762134440175529
Validation loss: 2.39199329520618

Epoch: 6| Step: 10
Training loss: 2.383521002825577
Validation loss: 2.3689508846284455

Epoch: 6| Step: 11
Training loss: 1.8015794288389084
Validation loss: 2.396758604856755

Epoch: 6| Step: 12
Training loss: 1.9751991123316437
Validation loss: 2.384211694291829

Epoch: 6| Step: 13
Training loss: 1.7264422206495806
Validation loss: 2.3497474203035997

Epoch: 259| Step: 0
Training loss: 1.4546184453748536
Validation loss: 2.3989416689941794

Epoch: 6| Step: 1
Training loss: 2.1096729209462834
Validation loss: 2.3920038198576106

Epoch: 6| Step: 2
Training loss: 2.365431534025681
Validation loss: 2.4090991258441514

Epoch: 6| Step: 3
Training loss: 1.8655702618055956
Validation loss: 2.365208292803992

Epoch: 6| Step: 4
Training loss: 2.2024872851140067
Validation loss: 2.3880930079019644

Epoch: 6| Step: 5
Training loss: 1.6748721629082504
Validation loss: 2.3683501519956796

Epoch: 6| Step: 6
Training loss: 1.8208458900746134
Validation loss: 2.4040444788246003

Epoch: 6| Step: 7
Training loss: 2.0182980105235817
Validation loss: 2.394609607627679

Epoch: 6| Step: 8
Training loss: 1.7132225628432534
Validation loss: 2.3584140797535813

Epoch: 6| Step: 9
Training loss: 1.832508992775453
Validation loss: 2.3265575410452906

Epoch: 6| Step: 10
Training loss: 2.3070150744900997
Validation loss: 2.3681605204149876

Epoch: 6| Step: 11
Training loss: 2.0103253622190618
Validation loss: 2.315803910333733

Epoch: 6| Step: 12
Training loss: 2.5843008342096665
Validation loss: 2.375833762232549

Epoch: 6| Step: 13
Training loss: 1.8200997158652459
Validation loss: 2.3731963136553467

Epoch: 260| Step: 0
Training loss: 1.340972024957208
Validation loss: 2.377755661062501

Epoch: 6| Step: 1
Training loss: 1.6644407746815402
Validation loss: 2.3659017043549984

Epoch: 6| Step: 2
Training loss: 1.8673439119977469
Validation loss: 2.369565543811146

Epoch: 6| Step: 3
Training loss: 2.389492190373604
Validation loss: 2.3908547528220785

Epoch: 6| Step: 4
Training loss: 1.852893785330116
Validation loss: 2.400438904964054

Epoch: 6| Step: 5
Training loss: 1.237732245105061
Validation loss: 2.421545592051618

Epoch: 6| Step: 6
Training loss: 2.311280728141557
Validation loss: 2.3751689384491304

Epoch: 6| Step: 7
Training loss: 2.333299250580866
Validation loss: 2.3911777795305147

Epoch: 6| Step: 8
Training loss: 2.3469248313032613
Validation loss: 2.3774016412807044

Epoch: 6| Step: 9
Training loss: 1.422218365134201
Validation loss: 2.3930895944968382

Epoch: 6| Step: 10
Training loss: 1.656218762373096
Validation loss: 2.4099753193524855

Epoch: 6| Step: 11
Training loss: 1.8837646356227988
Validation loss: 2.423704772810548

Epoch: 6| Step: 12
Training loss: 2.775695741057335
Validation loss: 2.362556714060117

Epoch: 6| Step: 13
Training loss: 1.7944519955476521
Validation loss: 2.369071607829938

Epoch: 261| Step: 0
Training loss: 1.9007356022795356
Validation loss: 2.4048969698169294

Epoch: 6| Step: 1
Training loss: 1.6791027381913268
Validation loss: 2.3994063942619372

Epoch: 6| Step: 2
Training loss: 2.598428390587892
Validation loss: 2.3875748802829184

Epoch: 6| Step: 3
Training loss: 1.8882335955123013
Validation loss: 2.4088050510462233

Epoch: 6| Step: 4
Training loss: 2.075367525023488
Validation loss: 2.3776924898533665

Epoch: 6| Step: 5
Training loss: 1.7960123396281773
Validation loss: 2.3749944949126762

Epoch: 6| Step: 6
Training loss: 1.9007593093276827
Validation loss: 2.340909950907413

Epoch: 6| Step: 7
Training loss: 1.8894032716039746
Validation loss: 2.345651340202457

Epoch: 6| Step: 8
Training loss: 1.895936550921694
Validation loss: 2.367536902053613

Epoch: 6| Step: 9
Training loss: 2.045037296393427
Validation loss: 2.3825544481497283

Epoch: 6| Step: 10
Training loss: 2.3861857566758187
Validation loss: 2.375494991202335

Epoch: 6| Step: 11
Training loss: 1.808021141679761
Validation loss: 2.397792907912698

Epoch: 6| Step: 12
Training loss: 1.552932976071658
Validation loss: 2.36100654824938

Epoch: 6| Step: 13
Training loss: 1.7902686039022306
Validation loss: 2.348844249623314

Epoch: 262| Step: 0
Training loss: 1.67519612089362
Validation loss: 2.3693740965448984

Epoch: 6| Step: 1
Training loss: 1.8733037269307184
Validation loss: 2.365213714989268

Epoch: 6| Step: 2
Training loss: 2.03125305175552
Validation loss: 2.373233131463255

Epoch: 6| Step: 3
Training loss: 2.6565462732576726
Validation loss: 2.3665853729769566

Epoch: 6| Step: 4
Training loss: 1.9148197466724393
Validation loss: 2.409298250237271

Epoch: 6| Step: 5
Training loss: 2.1883572669752955
Validation loss: 2.416011096209551

Epoch: 6| Step: 6
Training loss: 2.009353936590733
Validation loss: 2.3890505657143297

Epoch: 6| Step: 7
Training loss: 1.8915084162098061
Validation loss: 2.3506629887900283

Epoch: 6| Step: 8
Training loss: 1.6666586239938597
Validation loss: 2.3663061339497196

Epoch: 6| Step: 9
Training loss: 1.4355204677099214
Validation loss: 2.344386724032433

Epoch: 6| Step: 10
Training loss: 2.0682132082147113
Validation loss: 2.4202563256250857

Epoch: 6| Step: 11
Training loss: 2.159150867450977
Validation loss: 2.4071386289478354

Epoch: 6| Step: 12
Training loss: 1.1776323922762126
Validation loss: 2.362104597597469

Epoch: 6| Step: 13
Training loss: 2.386187655082591
Validation loss: 2.3828460610304263

Epoch: 263| Step: 0
Training loss: 2.0488773481858145
Validation loss: 2.4011864156193727

Epoch: 6| Step: 1
Training loss: 2.4108296200244244
Validation loss: 2.3607368789946945

Epoch: 6| Step: 2
Training loss: 1.8147285835420233
Validation loss: 2.3387578749225257

Epoch: 6| Step: 3
Training loss: 1.7073031630098927
Validation loss: 2.350478134090459

Epoch: 6| Step: 4
Training loss: 1.9739016991964975
Validation loss: 2.3661809889430976

Epoch: 6| Step: 5
Training loss: 1.5568097069401408
Validation loss: 2.39058839642741

Epoch: 6| Step: 6
Training loss: 1.8379184505938573
Validation loss: 2.3791927661703

Epoch: 6| Step: 7
Training loss: 2.1101475184068237
Validation loss: 2.3381066244604636

Epoch: 6| Step: 8
Training loss: 2.616506186097638
Validation loss: 2.359322117918641

Epoch: 6| Step: 9
Training loss: 1.6687710907135507
Validation loss: 2.366614616635686

Epoch: 6| Step: 10
Training loss: 1.9679619559200656
Validation loss: 2.4097559360722167

Epoch: 6| Step: 11
Training loss: 1.529420655211763
Validation loss: 2.342488849376218

Epoch: 6| Step: 12
Training loss: 2.0368619422927146
Validation loss: 2.406741719157772

Epoch: 6| Step: 13
Training loss: 2.0004227906620504
Validation loss: 2.4228403888449748

Epoch: 264| Step: 0
Training loss: 2.493739968951326
Validation loss: 2.342038081362347

Epoch: 6| Step: 1
Training loss: 2.1353306698734387
Validation loss: 2.359920556799764

Epoch: 6| Step: 2
Training loss: 2.2965770709865057
Validation loss: 2.3800168269469015

Epoch: 6| Step: 3
Training loss: 1.9538934035338384
Validation loss: 2.357788446753666

Epoch: 6| Step: 4
Training loss: 1.2487687245627126
Validation loss: 2.3421804946962883

Epoch: 6| Step: 5
Training loss: 2.3591944139098184
Validation loss: 2.3984402010569332

Epoch: 6| Step: 6
Training loss: 1.266202629988269
Validation loss: 2.4257409283947102

Epoch: 6| Step: 7
Training loss: 1.710784905304585
Validation loss: 2.4135112303595485

Epoch: 6| Step: 8
Training loss: 1.8443674896201077
Validation loss: 2.365735213134869

Epoch: 6| Step: 9
Training loss: 2.2780004899021926
Validation loss: 2.3284078501768493

Epoch: 6| Step: 10
Training loss: 1.9807011996459871
Validation loss: 2.4042580857505063

Epoch: 6| Step: 11
Training loss: 1.5265315010726408
Validation loss: 2.3891686068831923

Epoch: 6| Step: 12
Training loss: 2.15615490689884
Validation loss: 2.3428580574254885

Epoch: 6| Step: 13
Training loss: 2.2028235912436123
Validation loss: 2.37585899565538

Epoch: 265| Step: 0
Training loss: 0.8975746987584818
Validation loss: 2.374827898457571

Epoch: 6| Step: 1
Training loss: 1.1178310114837038
Validation loss: 2.3727376511133724

Epoch: 6| Step: 2
Training loss: 1.8425195111674104
Validation loss: 2.3600890072013816

Epoch: 6| Step: 3
Training loss: 2.233532513329086
Validation loss: 2.3811154486296524

Epoch: 6| Step: 4
Training loss: 1.5541920855014202
Validation loss: 2.38636297025202

Epoch: 6| Step: 5
Training loss: 2.54747535790981
Validation loss: 2.381999785831962

Epoch: 6| Step: 6
Training loss: 2.834114939273577
Validation loss: 2.3520459543583807

Epoch: 6| Step: 7
Training loss: 1.7827294881151796
Validation loss: 2.400257434078626

Epoch: 6| Step: 8
Training loss: 1.6818220193570756
Validation loss: 2.3561787933742786

Epoch: 6| Step: 9
Training loss: 1.9616616420416815
Validation loss: 2.389632491187166

Epoch: 6| Step: 10
Training loss: 1.7218207238257204
Validation loss: 2.406492784895922

Epoch: 6| Step: 11
Training loss: 2.493512414308146
Validation loss: 2.3688151737911576

Epoch: 6| Step: 12
Training loss: 1.8675623561350594
Validation loss: 2.367343200698561

Epoch: 6| Step: 13
Training loss: 2.191493394720318
Validation loss: 2.391440693997379

Epoch: 266| Step: 0
Training loss: 1.5020038412631678
Validation loss: 2.361724438913723

Epoch: 6| Step: 1
Training loss: 1.5682029408576557
Validation loss: 2.4136474413980373

Epoch: 6| Step: 2
Training loss: 2.324470878197106
Validation loss: 2.375288273879046

Epoch: 6| Step: 3
Training loss: 1.9478088661868667
Validation loss: 2.356958498179998

Epoch: 6| Step: 4
Training loss: 2.3043940987764193
Validation loss: 2.359165189112621

Epoch: 6| Step: 5
Training loss: 2.355778561488287
Validation loss: 2.385844573302844

Epoch: 6| Step: 6
Training loss: 1.8496580349121596
Validation loss: 2.389005970269831

Epoch: 6| Step: 7
Training loss: 2.11645720439192
Validation loss: 2.3924318172346086

Epoch: 6| Step: 8
Training loss: 2.246775011323468
Validation loss: 2.34462371264527

Epoch: 6| Step: 9
Training loss: 1.860363865608924
Validation loss: 2.3898852112040694

Epoch: 6| Step: 10
Training loss: 1.5734806270806825
Validation loss: 2.3910184039623847

Epoch: 6| Step: 11
Training loss: 1.7351870311220756
Validation loss: 2.388085111152704

Epoch: 6| Step: 12
Training loss: 2.2538480701573587
Validation loss: 2.353233673781015

Epoch: 6| Step: 13
Training loss: 1.4848075637976188
Validation loss: 2.3597513751747687

Epoch: 267| Step: 0
Training loss: 1.936762084722332
Validation loss: 2.393879875635923

Epoch: 6| Step: 1
Training loss: 1.7962022268251114
Validation loss: 2.353634757773396

Epoch: 6| Step: 2
Training loss: 2.042912032031158
Validation loss: 2.398106096673566

Epoch: 6| Step: 3
Training loss: 1.4235724911710743
Validation loss: 2.3636088699544877

Epoch: 6| Step: 4
Training loss: 1.9514643208445228
Validation loss: 2.3947228244642345

Epoch: 6| Step: 5
Training loss: 2.13826794576635
Validation loss: 2.407858091888442

Epoch: 6| Step: 6
Training loss: 1.161713297048058
Validation loss: 2.3635618502422973

Epoch: 6| Step: 7
Training loss: 2.431935144689026
Validation loss: 2.375586275968156

Epoch: 6| Step: 8
Training loss: 1.6385444164152003
Validation loss: 2.320091938943536

Epoch: 6| Step: 9
Training loss: 2.405515880810607
Validation loss: 2.364776042591483

Epoch: 6| Step: 10
Training loss: 2.226214893713256
Validation loss: 2.347936310002486

Epoch: 6| Step: 11
Training loss: 2.0633247344906565
Validation loss: 2.413968146623067

Epoch: 6| Step: 12
Training loss: 1.6336442207118147
Validation loss: 2.3976573123417038

Epoch: 6| Step: 13
Training loss: 1.8969140238887683
Validation loss: 2.4020698802772524

Epoch: 268| Step: 0
Training loss: 1.292767558046288
Validation loss: 2.3757632048796364

Epoch: 6| Step: 1
Training loss: 1.8322414773729034
Validation loss: 2.3624495860359898

Epoch: 6| Step: 2
Training loss: 2.0476599200236567
Validation loss: 2.3764786124924866

Epoch: 6| Step: 3
Training loss: 1.9824836307922578
Validation loss: 2.393478547848196

Epoch: 6| Step: 4
Training loss: 1.7221463718255257
Validation loss: 2.374736991529077

Epoch: 6| Step: 5
Training loss: 2.1655129760127934
Validation loss: 2.3506520772794413

Epoch: 6| Step: 6
Training loss: 1.9742196412531687
Validation loss: 2.356943167136916

Epoch: 6| Step: 7
Training loss: 1.7912451078104534
Validation loss: 2.3605097167858284

Epoch: 6| Step: 8
Training loss: 1.8241989494082314
Validation loss: 2.3416626460280585

Epoch: 6| Step: 9
Training loss: 2.604213154695739
Validation loss: 2.3438190075412706

Epoch: 6| Step: 10
Training loss: 1.7780244634595224
Validation loss: 2.3353497599219923

Epoch: 6| Step: 11
Training loss: 2.322709922542491
Validation loss: 2.356117186082608

Epoch: 6| Step: 12
Training loss: 1.5029996442965698
Validation loss: 2.3862803303060507

Epoch: 6| Step: 13
Training loss: 1.808973037792933
Validation loss: 2.356176362669041

Epoch: 269| Step: 0
Training loss: 1.7947722363282756
Validation loss: 2.3940418952311253

Epoch: 6| Step: 1
Training loss: 1.3809379328675033
Validation loss: 2.343595015894563

Epoch: 6| Step: 2
Training loss: 2.0825775174188235
Validation loss: 2.3611234073049303

Epoch: 6| Step: 3
Training loss: 2.0767618168340496
Validation loss: 2.386366456313399

Epoch: 6| Step: 4
Training loss: 1.8098149636037744
Validation loss: 2.3469151870107066

Epoch: 6| Step: 5
Training loss: 2.9532812975338603
Validation loss: 2.382463222694508

Epoch: 6| Step: 6
Training loss: 1.7425917083819669
Validation loss: 2.3611609367004984

Epoch: 6| Step: 7
Training loss: 1.9070715462796342
Validation loss: 2.388954824736592

Epoch: 6| Step: 8
Training loss: 1.7623079587594666
Validation loss: 2.349477639372403

Epoch: 6| Step: 9
Training loss: 1.9641198707522818
Validation loss: 2.3752419381433656

Epoch: 6| Step: 10
Training loss: 1.6674204155090204
Validation loss: 2.402699804177943

Epoch: 6| Step: 11
Training loss: 1.6140327088966269
Validation loss: 2.375313822851529

Epoch: 6| Step: 12
Training loss: 1.9140632473691144
Validation loss: 2.357825293136193

Epoch: 6| Step: 13
Training loss: 1.9156099875828005
Validation loss: 2.3924238297931026

Epoch: 270| Step: 0
Training loss: 1.4406798478482206
Validation loss: 2.327985124666186

Epoch: 6| Step: 1
Training loss: 1.6367311317867728
Validation loss: 2.385253134015191

Epoch: 6| Step: 2
Training loss: 2.2777486608034683
Validation loss: 2.4070967889066055

Epoch: 6| Step: 3
Training loss: 2.287678791834237
Validation loss: 2.375381392687936

Epoch: 6| Step: 4
Training loss: 2.577093021885498
Validation loss: 2.399720568951017

Epoch: 6| Step: 5
Training loss: 1.8204278868421642
Validation loss: 2.3952970813265964

Epoch: 6| Step: 6
Training loss: 1.770847260663484
Validation loss: 2.3839996334014946

Epoch: 6| Step: 7
Training loss: 1.9856895838276267
Validation loss: 2.3721276796709305

Epoch: 6| Step: 8
Training loss: 2.3242380349777654
Validation loss: 2.409551290904795

Epoch: 6| Step: 9
Training loss: 1.997962748526792
Validation loss: 2.396035611110169

Epoch: 6| Step: 10
Training loss: 1.34053106445721
Validation loss: 2.4360276143395283

Epoch: 6| Step: 11
Training loss: 1.7526781161966822
Validation loss: 2.3509057761572136

Epoch: 6| Step: 12
Training loss: 1.856479859168631
Validation loss: 2.3854952719222244

Epoch: 6| Step: 13
Training loss: 1.3807283633400178
Validation loss: 2.3738845770613626

Epoch: 271| Step: 0
Training loss: 1.2686025655989646
Validation loss: 2.3973847315645025

Epoch: 6| Step: 1
Training loss: 1.462863570448259
Validation loss: 2.3243208314974924

Epoch: 6| Step: 2
Training loss: 2.224537782128281
Validation loss: 2.373885988535765

Epoch: 6| Step: 3
Training loss: 2.1010605450149122
Validation loss: 2.323907596024369

Epoch: 6| Step: 4
Training loss: 2.2953510029305
Validation loss: 2.3815584435522132

Epoch: 6| Step: 5
Training loss: 2.3670414542793408
Validation loss: 2.406522877347621

Epoch: 6| Step: 6
Training loss: 1.9767945044136614
Validation loss: 2.3253300207316525

Epoch: 6| Step: 7
Training loss: 1.5423369454090854
Validation loss: 2.3406033641257107

Epoch: 6| Step: 8
Training loss: 2.2678611506457793
Validation loss: 2.324080596978989

Epoch: 6| Step: 9
Training loss: 1.8884681189373242
Validation loss: 2.3474500582403715

Epoch: 6| Step: 10
Training loss: 1.8283519766989211
Validation loss: 2.394960953160835

Epoch: 6| Step: 11
Training loss: 1.596585313533578
Validation loss: 2.336720971386098

Epoch: 6| Step: 12
Training loss: 1.9045694165947782
Validation loss: 2.3181005785921256

Epoch: 6| Step: 13
Training loss: 2.1889975734887197
Validation loss: 2.3669546066836302

Epoch: 272| Step: 0
Training loss: 1.606190243214312
Validation loss: 2.356395347831847

Epoch: 6| Step: 1
Training loss: 2.2173162851708565
Validation loss: 2.4094014800450845

Epoch: 6| Step: 2
Training loss: 1.3708356739399106
Validation loss: 2.3675471434402064

Epoch: 6| Step: 3
Training loss: 2.367574729344259
Validation loss: 2.3766219187528557

Epoch: 6| Step: 4
Training loss: 2.1387325191173576
Validation loss: 2.355074833022209

Epoch: 6| Step: 5
Training loss: 2.1121034283816207
Validation loss: 2.307142072055048

Epoch: 6| Step: 6
Training loss: 1.7309661908035159
Validation loss: 2.3760570188148122

Epoch: 6| Step: 7
Training loss: 1.4414701783598258
Validation loss: 2.371441752218777

Epoch: 6| Step: 8
Training loss: 1.815491411084256
Validation loss: 2.3739306649926837

Epoch: 6| Step: 9
Training loss: 1.6156156705664433
Validation loss: 2.412966120200007

Epoch: 6| Step: 10
Training loss: 2.262619866836716
Validation loss: 2.3006212473545697

Epoch: 6| Step: 11
Training loss: 2.3201276403699524
Validation loss: 2.400072505754685

Epoch: 6| Step: 12
Training loss: 1.9420825540142328
Validation loss: 2.3312255206196504

Epoch: 6| Step: 13
Training loss: 1.0426035609595925
Validation loss: 2.3460508651326726

Epoch: 273| Step: 0
Training loss: 1.8414971116784153
Validation loss: 2.366892189166159

Epoch: 6| Step: 1
Training loss: 1.6292552985678386
Validation loss: 2.37895816439403

Epoch: 6| Step: 2
Training loss: 1.5099324557374354
Validation loss: 2.4012742842203965

Epoch: 6| Step: 3
Training loss: 1.3916753167132943
Validation loss: 2.388761507887702

Epoch: 6| Step: 4
Training loss: 2.484308973670577
Validation loss: 2.37379967268664

Epoch: 6| Step: 5
Training loss: 2.6211365925091688
Validation loss: 2.401968425168165

Epoch: 6| Step: 6
Training loss: 1.8109530062336634
Validation loss: 2.3578743576890204

Epoch: 6| Step: 7
Training loss: 1.2066929908027266
Validation loss: 2.439752557057865

Epoch: 6| Step: 8
Training loss: 1.9661736964257766
Validation loss: 2.4227673355730053

Epoch: 6| Step: 9
Training loss: 2.0466385333501975
Validation loss: 2.3689127735906648

Epoch: 6| Step: 10
Training loss: 2.2016319464295258
Validation loss: 2.3666960183934362

Epoch: 6| Step: 11
Training loss: 2.209988771297876
Validation loss: 2.387258942859454

Epoch: 6| Step: 12
Training loss: 2.1110932310362216
Validation loss: 2.390073644167032

Epoch: 6| Step: 13
Training loss: 1.5142366008042905
Validation loss: 2.3324139374254416

Epoch: 274| Step: 0
Training loss: 1.7940651194811303
Validation loss: 2.3752476347752878

Epoch: 6| Step: 1
Training loss: 1.5156926405452482
Validation loss: 2.3572064491334026

Epoch: 6| Step: 2
Training loss: 1.9966523644832512
Validation loss: 2.361954880481576

Epoch: 6| Step: 3
Training loss: 1.9034333604070242
Validation loss: 2.3713532419837757

Epoch: 6| Step: 4
Training loss: 1.8378836198890145
Validation loss: 2.3677201588418657

Epoch: 6| Step: 5
Training loss: 1.9140886577453702
Validation loss: 2.397105081596031

Epoch: 6| Step: 6
Training loss: 1.612412262533086
Validation loss: 2.3677798777821626

Epoch: 6| Step: 7
Training loss: 2.1190043744001112
Validation loss: 2.429270997434189

Epoch: 6| Step: 8
Training loss: 1.4862141509099933
Validation loss: 2.386870039308891

Epoch: 6| Step: 9
Training loss: 1.9786619714084006
Validation loss: 2.3801603510110816

Epoch: 6| Step: 10
Training loss: 1.2574193588852631
Validation loss: 2.4063954559074303

Epoch: 6| Step: 11
Training loss: 2.060398302552478
Validation loss: 2.3820031889497737

Epoch: 6| Step: 12
Training loss: 2.2871871400768478
Validation loss: 2.3531925862546306

Epoch: 6| Step: 13
Training loss: 2.793113181908002
Validation loss: 2.3823570124093263

Epoch: 275| Step: 0
Training loss: 2.581951284396659
Validation loss: 2.323369186324702

Epoch: 6| Step: 1
Training loss: 1.3183578378173908
Validation loss: 2.359788532032742

Epoch: 6| Step: 2
Training loss: 1.6196250052947068
Validation loss: 2.3913510039403265

Epoch: 6| Step: 3
Training loss: 1.1922449880515826
Validation loss: 2.37804587341182

Epoch: 6| Step: 4
Training loss: 1.7689272626604793
Validation loss: 2.3637244935448347

Epoch: 6| Step: 5
Training loss: 2.149695898328819
Validation loss: 2.3583378045792567

Epoch: 6| Step: 6
Training loss: 1.9994312908313132
Validation loss: 2.3211174814946944

Epoch: 6| Step: 7
Training loss: 2.3615123844116797
Validation loss: 2.3133764210881376

Epoch: 6| Step: 8
Training loss: 1.9313902967534953
Validation loss: 2.3696657389155296

Epoch: 6| Step: 9
Training loss: 1.9542257640282998
Validation loss: 2.3548399459488936

Epoch: 6| Step: 10
Training loss: 2.2839492087921496
Validation loss: 2.3741210807272837

Epoch: 6| Step: 11
Training loss: 1.6997811625379307
Validation loss: 2.310468450380734

Epoch: 6| Step: 12
Training loss: 1.912450368399289
Validation loss: 2.34569879707539

Epoch: 6| Step: 13
Training loss: 1.8045909905328084
Validation loss: 2.3393595717015394

Epoch: 276| Step: 0
Training loss: 1.6212141245076332
Validation loss: 2.3551722282957117

Epoch: 6| Step: 1
Training loss: 1.5285390094125497
Validation loss: 2.3515464349634776

Epoch: 6| Step: 2
Training loss: 2.513865833165036
Validation loss: 2.3978255600452774

Epoch: 6| Step: 3
Training loss: 2.7467147971383645
Validation loss: 2.427324239693213

Epoch: 6| Step: 4
Training loss: 1.505364204264765
Validation loss: 2.3530916733781257

Epoch: 6| Step: 5
Training loss: 1.647293489332225
Validation loss: 2.4244475008994453

Epoch: 6| Step: 6
Training loss: 1.6300834957338735
Validation loss: 2.3742515494293808

Epoch: 6| Step: 7
Training loss: 1.4429159554415405
Validation loss: 2.4182167022175283

Epoch: 6| Step: 8
Training loss: 2.5340579435472432
Validation loss: 2.3547898927829785

Epoch: 6| Step: 9
Training loss: 1.8783549493303517
Validation loss: 2.392210373917446

Epoch: 6| Step: 10
Training loss: 1.9925707878451833
Validation loss: 2.3729642304630962

Epoch: 6| Step: 11
Training loss: 1.5028120543887182
Validation loss: 2.354302399040438

Epoch: 6| Step: 12
Training loss: 1.9850923938531901
Validation loss: 2.3837193703147412

Epoch: 6| Step: 13
Training loss: 1.5537240575096194
Validation loss: 2.4349067193332443

Epoch: 277| Step: 0
Training loss: 1.5130839331945871
Validation loss: 2.3368626885053243

Epoch: 6| Step: 1
Training loss: 1.9936753644695573
Validation loss: 2.3934769369222004

Epoch: 6| Step: 2
Training loss: 2.7514720791414407
Validation loss: 2.39457883230337

Epoch: 6| Step: 3
Training loss: 1.5554744703110066
Validation loss: 2.370426858134512

Epoch: 6| Step: 4
Training loss: 1.7724371285849259
Validation loss: 2.3515739294827824

Epoch: 6| Step: 5
Training loss: 1.3541228898626279
Validation loss: 2.3486289647973733

Epoch: 6| Step: 6
Training loss: 2.162512489238682
Validation loss: 2.3328525015557413

Epoch: 6| Step: 7
Training loss: 1.4964839735157547
Validation loss: 2.3569119326153065

Epoch: 6| Step: 8
Training loss: 1.6794125354065959
Validation loss: 2.32537754339778

Epoch: 6| Step: 9
Training loss: 2.2705779559057677
Validation loss: 2.4248469937803647

Epoch: 6| Step: 10
Training loss: 1.9260514323219255
Validation loss: 2.3471842423323523

Epoch: 6| Step: 11
Training loss: 1.6573920720837538
Validation loss: 2.319569864648885

Epoch: 6| Step: 12
Training loss: 2.2587426193614935
Validation loss: 2.368799648922086

Epoch: 6| Step: 13
Training loss: 1.9579098493846085
Validation loss: 2.303046531463092

Epoch: 278| Step: 0
Training loss: 1.8715183357687881
Validation loss: 2.3828296248561793

Epoch: 6| Step: 1
Training loss: 2.351257507214889
Validation loss: 2.2978726128370806

Epoch: 6| Step: 2
Training loss: 1.7328140520204107
Validation loss: 2.372851241144322

Epoch: 6| Step: 3
Training loss: 1.4269470465337704
Validation loss: 2.3356104241885816

Epoch: 6| Step: 4
Training loss: 2.0546197336139502
Validation loss: 2.3687307278809677

Epoch: 6| Step: 5
Training loss: 1.873134256975824
Validation loss: 2.41504062348193

Epoch: 6| Step: 6
Training loss: 1.5008705315153654
Validation loss: 2.386071581975101

Epoch: 6| Step: 7
Training loss: 2.047411549838684
Validation loss: 2.366946232706969

Epoch: 6| Step: 8
Training loss: 1.8731509946458336
Validation loss: 2.379830835329331

Epoch: 6| Step: 9
Training loss: 1.2981497692523902
Validation loss: 2.4209116268418747

Epoch: 6| Step: 10
Training loss: 2.2497871086280963
Validation loss: 2.3948010703791205

Epoch: 6| Step: 11
Training loss: 1.8373887839363123
Validation loss: 2.4135098755183084

Epoch: 6| Step: 12
Training loss: 2.669238836825506
Validation loss: 2.408810243657877

Epoch: 6| Step: 13
Training loss: 2.066969796479108
Validation loss: 2.372302984568449

Epoch: 279| Step: 0
Training loss: 2.0545090282369007
Validation loss: 2.3888885123715298

Epoch: 6| Step: 1
Training loss: 2.273097376599207
Validation loss: 2.3659988164753756

Epoch: 6| Step: 2
Training loss: 2.624512854287545
Validation loss: 2.3490489089783653

Epoch: 6| Step: 3
Training loss: 1.9352904610878094
Validation loss: 2.3828520665480415

Epoch: 6| Step: 4
Training loss: 1.397015578601566
Validation loss: 2.3656745211781396

Epoch: 6| Step: 5
Training loss: 1.6280380606548848
Validation loss: 2.3585897773105127

Epoch: 6| Step: 6
Training loss: 1.7815799742120897
Validation loss: 2.3530549413546247

Epoch: 6| Step: 7
Training loss: 2.1902123121004538
Validation loss: 2.3483362611303638

Epoch: 6| Step: 8
Training loss: 1.6165573440372194
Validation loss: 2.3213361571167086

Epoch: 6| Step: 9
Training loss: 2.0307480411935703
Validation loss: 2.3393044502917104

Epoch: 6| Step: 10
Training loss: 2.032147018731003
Validation loss: 2.3801349359219794

Epoch: 6| Step: 11
Training loss: 1.4099855610263732
Validation loss: 2.3686419085353516

Epoch: 6| Step: 12
Training loss: 1.4866023969799533
Validation loss: 2.357375098913876

Epoch: 6| Step: 13
Training loss: 2.174630372658864
Validation loss: 2.3645754701036323

Epoch: 280| Step: 0
Training loss: 1.6951073025748051
Validation loss: 2.4077487513546347

Epoch: 6| Step: 1
Training loss: 1.6169698080335833
Validation loss: 2.3610286892091863

Epoch: 6| Step: 2
Training loss: 1.8745446605922873
Validation loss: 2.374949574002662

Epoch: 6| Step: 3
Training loss: 1.9190294242459718
Validation loss: 2.343372466057973

Epoch: 6| Step: 4
Training loss: 2.127355168004097
Validation loss: 2.329730467846684

Epoch: 6| Step: 5
Training loss: 1.8341024115037277
Validation loss: 2.3846761225063964

Epoch: 6| Step: 6
Training loss: 2.2502994338107722
Validation loss: 2.3709749322215345

Epoch: 6| Step: 7
Training loss: 1.890858785503642
Validation loss: 2.3323916715672146

Epoch: 6| Step: 8
Training loss: 2.2759251568360157
Validation loss: 2.3746459915146074

Epoch: 6| Step: 9
Training loss: 1.4406888670428093
Validation loss: 2.343217144078205

Epoch: 6| Step: 10
Training loss: 2.2126480871954706
Validation loss: 2.4010741233611705

Epoch: 6| Step: 11
Training loss: 1.7024448681613829
Validation loss: 2.348230832676556

Epoch: 6| Step: 12
Training loss: 1.6104084141344213
Validation loss: 2.3696559610673353

Epoch: 6| Step: 13
Training loss: 1.6941770627512323
Validation loss: 2.3448392769172597

Epoch: 281| Step: 0
Training loss: 2.1343387271150256
Validation loss: 2.3598877843204167

Epoch: 6| Step: 1
Training loss: 1.4437414755301219
Validation loss: 2.374784078211619

Epoch: 6| Step: 2
Training loss: 1.9225578025591086
Validation loss: 2.3992051399270125

Epoch: 6| Step: 3
Training loss: 1.574563719859552
Validation loss: 2.381207726969768

Epoch: 6| Step: 4
Training loss: 1.659698782329247
Validation loss: 2.372317739243039

Epoch: 6| Step: 5
Training loss: 1.4697417299622266
Validation loss: 2.297761063266456

Epoch: 6| Step: 6
Training loss: 2.1447324675779287
Validation loss: 2.2849847359523423

Epoch: 6| Step: 7
Training loss: 1.6401303953575261
Validation loss: 2.369350251514812

Epoch: 6| Step: 8
Training loss: 2.712550230484068
Validation loss: 2.3838126641599593

Epoch: 6| Step: 9
Training loss: 1.6045657400498883
Validation loss: 2.3586243172269388

Epoch: 6| Step: 10
Training loss: 1.5826943597264174
Validation loss: 2.3916550396509466

Epoch: 6| Step: 11
Training loss: 2.146931956506004
Validation loss: 2.34973077988298

Epoch: 6| Step: 12
Training loss: 2.047202397145116
Validation loss: 2.41070976927517

Epoch: 6| Step: 13
Training loss: 2.1496202577082895
Validation loss: 2.3631849379996646

Epoch: 282| Step: 0
Training loss: 1.745744777002433
Validation loss: 2.378192506737844

Epoch: 6| Step: 1
Training loss: 2.0027966020357577
Validation loss: 2.331519538939059

Epoch: 6| Step: 2
Training loss: 1.7795848090039834
Validation loss: 2.3425752349495723

Epoch: 6| Step: 3
Training loss: 2.772278277489357
Validation loss: 2.393111374350254

Epoch: 6| Step: 4
Training loss: 1.794890925459164
Validation loss: 2.331178784147973

Epoch: 6| Step: 5
Training loss: 1.6795880665290905
Validation loss: 2.3874795085687124

Epoch: 6| Step: 6
Training loss: 1.4304349852597473
Validation loss: 2.366427950827158

Epoch: 6| Step: 7
Training loss: 1.5263904611249484
Validation loss: 2.352037648833526

Epoch: 6| Step: 8
Training loss: 2.34198694674717
Validation loss: 2.3558196670295612

Epoch: 6| Step: 9
Training loss: 2.02387530329468
Validation loss: 2.358578803016406

Epoch: 6| Step: 10
Training loss: 1.4328882627934123
Validation loss: 2.360797244245834

Epoch: 6| Step: 11
Training loss: 2.6378952453383016
Validation loss: 2.3486752197688636

Epoch: 6| Step: 12
Training loss: 1.5514586384134652
Validation loss: 2.3173797370798934

Epoch: 6| Step: 13
Training loss: 1.5729649096368465
Validation loss: 2.35691070893935

Epoch: 283| Step: 0
Training loss: 1.4497935345423856
Validation loss: 2.3531657365330627

Epoch: 6| Step: 1
Training loss: 2.018635475524106
Validation loss: 2.399420662272284

Epoch: 6| Step: 2
Training loss: 1.586613102470912
Validation loss: 2.32959257126

Epoch: 6| Step: 3
Training loss: 2.289197585771145
Validation loss: 2.3503167305725934

Epoch: 6| Step: 4
Training loss: 1.5113035908450598
Validation loss: 2.3719042499500524

Epoch: 6| Step: 5
Training loss: 1.5825116217067456
Validation loss: 2.3873013619985066

Epoch: 6| Step: 6
Training loss: 2.2908596236116248
Validation loss: 2.377742668998362

Epoch: 6| Step: 7
Training loss: 2.4031487829571776
Validation loss: 2.415611664457794

Epoch: 6| Step: 8
Training loss: 1.558256107939548
Validation loss: 2.4144279855620194

Epoch: 6| Step: 9
Training loss: 1.844597896291242
Validation loss: 2.4479285954429337

Epoch: 6| Step: 10
Training loss: 1.8384219626847014
Validation loss: 2.383587411815527

Epoch: 6| Step: 11
Training loss: 1.7888038814807947
Validation loss: 2.371416348012351

Epoch: 6| Step: 12
Training loss: 1.7667509556702021
Validation loss: 2.36442680937662

Epoch: 6| Step: 13
Training loss: 2.580399221095114
Validation loss: 2.365800754386505

Epoch: 284| Step: 0
Training loss: 2.2211726756636336
Validation loss: 2.3597699982190554

Epoch: 6| Step: 1
Training loss: 1.5069004126628514
Validation loss: 2.3052760386901716

Epoch: 6| Step: 2
Training loss: 1.8483618262078114
Validation loss: 2.372738880132715

Epoch: 6| Step: 3
Training loss: 1.9336193352750146
Validation loss: 2.3726490995398284

Epoch: 6| Step: 4
Training loss: 2.395178951514444
Validation loss: 2.3054317651247884

Epoch: 6| Step: 5
Training loss: 2.028374147320596
Validation loss: 2.3390685484003204

Epoch: 6| Step: 6
Training loss: 2.0100373880505518
Validation loss: 2.369290789373701

Epoch: 6| Step: 7
Training loss: 1.862815174855355
Validation loss: 2.370957431961936

Epoch: 6| Step: 8
Training loss: 1.6437632745127015
Validation loss: 2.348073182805047

Epoch: 6| Step: 9
Training loss: 1.901471386421612
Validation loss: 2.3991687671694484

Epoch: 6| Step: 10
Training loss: 1.6204083935752105
Validation loss: 2.396415193229117

Epoch: 6| Step: 11
Training loss: 1.7423266710195717
Validation loss: 2.305078386070964

Epoch: 6| Step: 12
Training loss: 1.5233317020554993
Validation loss: 2.324376401434473

Epoch: 6| Step: 13
Training loss: 1.3046136709556342
Validation loss: 2.407069469024309

Epoch: 285| Step: 0
Training loss: 2.159039006681687
Validation loss: 2.360376994017513

Epoch: 6| Step: 1
Training loss: 1.0866584305850933
Validation loss: 2.3770241803549164

Epoch: 6| Step: 2
Training loss: 2.01465636643344
Validation loss: 2.3679940710867937

Epoch: 6| Step: 3
Training loss: 2.0003208856655683
Validation loss: 2.36950900936491

Epoch: 6| Step: 4
Training loss: 1.2287906405615254
Validation loss: 2.3220027201856004

Epoch: 6| Step: 5
Training loss: 1.5714042246777895
Validation loss: 2.3410960341841514

Epoch: 6| Step: 6
Training loss: 2.0371828733445216
Validation loss: 2.3389511124511597

Epoch: 6| Step: 7
Training loss: 2.1925088485139046
Validation loss: 2.375609920273297

Epoch: 6| Step: 8
Training loss: 1.2822410658214416
Validation loss: 2.3236264057307943

Epoch: 6| Step: 9
Training loss: 1.6612371538640032
Validation loss: 2.3657249660716237

Epoch: 6| Step: 10
Training loss: 1.4393741166728693
Validation loss: 2.3349793185444443

Epoch: 6| Step: 11
Training loss: 2.219737947823309
Validation loss: 2.3833037882782913

Epoch: 6| Step: 12
Training loss: 2.5589597483931796
Validation loss: 2.3574333891719217

Epoch: 6| Step: 13
Training loss: 2.6620647737344982
Validation loss: 2.3472327669631756

Epoch: 286| Step: 0
Training loss: 2.4847116302251204
Validation loss: 2.3336498332238658

Epoch: 6| Step: 1
Training loss: 1.7153201473355417
Validation loss: 2.329381212509571

Epoch: 6| Step: 2
Training loss: 1.5692595942217484
Validation loss: 2.3469815176198985

Epoch: 6| Step: 3
Training loss: 1.8747231596976104
Validation loss: 2.3591391066479575

Epoch: 6| Step: 4
Training loss: 2.673468755810222
Validation loss: 2.3511128283027607

Epoch: 6| Step: 5
Training loss: 1.099451301013174
Validation loss: 2.340150313603661

Epoch: 6| Step: 6
Training loss: 1.915807994671094
Validation loss: 2.3409782958470395

Epoch: 6| Step: 7
Training loss: 1.2120054396516706
Validation loss: 2.4035255233946864

Epoch: 6| Step: 8
Training loss: 2.5736410277068265
Validation loss: 2.3687735783849964

Epoch: 6| Step: 9
Training loss: 1.3877650222611224
Validation loss: 2.3808599112319615

Epoch: 6| Step: 10
Training loss: 1.829662752187726
Validation loss: 2.301929556902309

Epoch: 6| Step: 11
Training loss: 1.6486980358897603
Validation loss: 2.3471683908957646

Epoch: 6| Step: 12
Training loss: 1.9984291583521665
Validation loss: 2.375063032340367

Epoch: 6| Step: 13
Training loss: 1.7319890011532888
Validation loss: 2.3515650226891687

Epoch: 287| Step: 0
Training loss: 1.5845353265485507
Validation loss: 2.3491448598307163

Epoch: 6| Step: 1
Training loss: 1.59154477609727
Validation loss: 2.350357321909727

Epoch: 6| Step: 2
Training loss: 2.2544295895076987
Validation loss: 2.339215634785694

Epoch: 6| Step: 3
Training loss: 1.983953115716838
Validation loss: 2.341648680780965

Epoch: 6| Step: 4
Training loss: 1.3687497178168855
Validation loss: 2.37405627832984

Epoch: 6| Step: 5
Training loss: 1.5415933007318923
Validation loss: 2.37399421383321

Epoch: 6| Step: 6
Training loss: 1.562037590268123
Validation loss: 2.3684046120190834

Epoch: 6| Step: 7
Training loss: 2.0616457933105763
Validation loss: 2.354948633950244

Epoch: 6| Step: 8
Training loss: 1.8895365206279728
Validation loss: 2.3648654125669255

Epoch: 6| Step: 9
Training loss: 2.00412896240467
Validation loss: 2.361427549245332

Epoch: 6| Step: 10
Training loss: 1.602796125977273
Validation loss: 2.4054752376263364

Epoch: 6| Step: 11
Training loss: 1.607445161634559
Validation loss: 2.376751341427236

Epoch: 6| Step: 12
Training loss: 2.158937520871009
Validation loss: 2.3834780539040445

Epoch: 6| Step: 13
Training loss: 2.7246292386988733
Validation loss: 2.3576402399334095

Epoch: 288| Step: 0
Training loss: 1.4112245523271854
Validation loss: 2.3413876425477524

Epoch: 6| Step: 1
Training loss: 1.8569450849508042
Validation loss: 2.325769942702829

Epoch: 6| Step: 2
Training loss: 1.4333420202450362
Validation loss: 2.3807281915897054

Epoch: 6| Step: 3
Training loss: 1.9256465470130901
Validation loss: 2.3686381517818846

Epoch: 6| Step: 4
Training loss: 1.8437756682080126
Validation loss: 2.348522719869772

Epoch: 6| Step: 5
Training loss: 1.6202564696995194
Validation loss: 2.373578452225652

Epoch: 6| Step: 6
Training loss: 1.9743501245876398
Validation loss: 2.3765558895424665

Epoch: 6| Step: 7
Training loss: 1.777761556961975
Validation loss: 2.3728271339423674

Epoch: 6| Step: 8
Training loss: 1.6248048518451654
Validation loss: 2.3793792267891205

Epoch: 6| Step: 9
Training loss: 2.4575327738907804
Validation loss: 2.3598448409071477

Epoch: 6| Step: 10
Training loss: 2.2959266832854164
Validation loss: 2.3402249709115432

Epoch: 6| Step: 11
Training loss: 1.6112917994248208
Validation loss: 2.3856866268860224

Epoch: 6| Step: 12
Training loss: 1.77228673493978
Validation loss: 2.2990103372253143

Epoch: 6| Step: 13
Training loss: 2.2256799923220445
Validation loss: 2.3771449475834254

Epoch: 289| Step: 0
Training loss: 1.6299116293232208
Validation loss: 2.2988322612529277

Epoch: 6| Step: 1
Training loss: 1.9559641839514232
Validation loss: 2.393998169140006

Epoch: 6| Step: 2
Training loss: 1.710092205104838
Validation loss: 2.3589901794006054

Epoch: 6| Step: 3
Training loss: 1.6337552793923895
Validation loss: 2.369569457051928

Epoch: 6| Step: 4
Training loss: 1.3244916696542106
Validation loss: 2.3585764378273297

Epoch: 6| Step: 5
Training loss: 2.3844968752129643
Validation loss: 2.368878146681637

Epoch: 6| Step: 6
Training loss: 2.2041766314891222
Validation loss: 2.370783936147621

Epoch: 6| Step: 7
Training loss: 1.5631910703195115
Validation loss: 2.32677949889138

Epoch: 6| Step: 8
Training loss: 1.9399575060683552
Validation loss: 2.3676455442537563

Epoch: 6| Step: 9
Training loss: 1.6357749093042422
Validation loss: 2.2990476316490187

Epoch: 6| Step: 10
Training loss: 1.6619111961620672
Validation loss: 2.3521269164298335

Epoch: 6| Step: 11
Training loss: 1.9967028142154502
Validation loss: 2.36287597826172

Epoch: 6| Step: 12
Training loss: 1.7545476135855143
Validation loss: 2.3648185235359014

Epoch: 6| Step: 13
Training loss: 1.9332889201006622
Validation loss: 2.333920954912166

Epoch: 290| Step: 0
Training loss: 1.7770378771830835
Validation loss: 2.353405087581007

Epoch: 6| Step: 1
Training loss: 1.6740078734984098
Validation loss: 2.3295275131960604

Epoch: 6| Step: 2
Training loss: 1.445425080734634
Validation loss: 2.33567427695709

Epoch: 6| Step: 3
Training loss: 1.8371552669463662
Validation loss: 2.337579615111603

Epoch: 6| Step: 4
Training loss: 1.8543165624942333
Validation loss: 2.3455768217283453

Epoch: 6| Step: 5
Training loss: 1.5684201049448112
Validation loss: 2.33101731347416

Epoch: 6| Step: 6
Training loss: 1.3070497884307815
Validation loss: 2.3592511248922916

Epoch: 6| Step: 7
Training loss: 2.156724518241263
Validation loss: 2.3873975794846336

Epoch: 6| Step: 8
Training loss: 2.370746015159784
Validation loss: 2.3540836406343244

Epoch: 6| Step: 9
Training loss: 1.9762383598549438
Validation loss: 2.3544508333910614

Epoch: 6| Step: 10
Training loss: 1.6998344621282733
Validation loss: 2.3313731144675987

Epoch: 6| Step: 11
Training loss: 1.912694823869666
Validation loss: 2.347976329963425

Epoch: 6| Step: 12
Training loss: 2.1837712797493927
Validation loss: 2.4034600300993354

Epoch: 6| Step: 13
Training loss: 1.6645835096655965
Validation loss: 2.385626663341154

Epoch: 291| Step: 0
Training loss: 2.270958036679214
Validation loss: 2.33165959311411

Epoch: 6| Step: 1
Training loss: 1.6244810449463591
Validation loss: 2.3420060525757473

Epoch: 6| Step: 2
Training loss: 1.734483870104965
Validation loss: 2.3331385386880834

Epoch: 6| Step: 3
Training loss: 1.6818271227840293
Validation loss: 2.3755877716851663

Epoch: 6| Step: 4
Training loss: 1.358063119601215
Validation loss: 2.3938030255788916

Epoch: 6| Step: 5
Training loss: 1.3998126722075883
Validation loss: 2.3280302660108863

Epoch: 6| Step: 6
Training loss: 2.0141108540367467
Validation loss: 2.3686885638647692

Epoch: 6| Step: 7
Training loss: 1.6484278818726736
Validation loss: 2.40180167915427

Epoch: 6| Step: 8
Training loss: 1.653027187979995
Validation loss: 2.384859528270482

Epoch: 6| Step: 9
Training loss: 2.445242688824767
Validation loss: 2.3745319896246047

Epoch: 6| Step: 10
Training loss: 2.1892550376284383
Validation loss: 2.3794480570317793

Epoch: 6| Step: 11
Training loss: 1.8054853384922227
Validation loss: 2.408120437175351

Epoch: 6| Step: 12
Training loss: 1.3816436310256297
Validation loss: 2.343688146944036

Epoch: 6| Step: 13
Training loss: 2.3438437888135515
Validation loss: 2.3643684226299717

Epoch: 292| Step: 0
Training loss: 1.989109908360788
Validation loss: 2.374071899485817

Epoch: 6| Step: 1
Training loss: 1.49786535006266
Validation loss: 2.359544392229659

Epoch: 6| Step: 2
Training loss: 1.6527044385066467
Validation loss: 2.3390883400506217

Epoch: 6| Step: 3
Training loss: 2.131526797042728
Validation loss: 2.3674164503638644

Epoch: 6| Step: 4
Training loss: 2.5244620401630367
Validation loss: 2.3467171862451526

Epoch: 6| Step: 5
Training loss: 1.8071849106214832
Validation loss: 2.3411278443661296

Epoch: 6| Step: 6
Training loss: 2.0037080246591557
Validation loss: 2.322958524034305

Epoch: 6| Step: 7
Training loss: 1.6927151802120137
Validation loss: 2.3238998396973023

Epoch: 6| Step: 8
Training loss: 1.4831193933971738
Validation loss: 2.3588100561862135

Epoch: 6| Step: 9
Training loss: 1.857697764223253
Validation loss: 2.311885116764329

Epoch: 6| Step: 10
Training loss: 1.5657280193249616
Validation loss: 2.3375454063670946

Epoch: 6| Step: 11
Training loss: 2.3204273747736903
Validation loss: 2.3780718627804056

Epoch: 6| Step: 12
Training loss: 1.5409430618510678
Validation loss: 2.3148275212129445

Epoch: 6| Step: 13
Training loss: 1.666017771604347
Validation loss: 2.3026955638238964

Epoch: 293| Step: 0
Training loss: 1.6828810738960622
Validation loss: 2.3335071936963963

Epoch: 6| Step: 1
Training loss: 2.3041445334982784
Validation loss: 2.397543715477791

Epoch: 6| Step: 2
Training loss: 1.6484635337473275
Validation loss: 2.318260784243523

Epoch: 6| Step: 3
Training loss: 2.3536835796528472
Validation loss: 2.304824863384411

Epoch: 6| Step: 4
Training loss: 1.776707931645305
Validation loss: 2.3621958409035684

Epoch: 6| Step: 5
Training loss: 1.8615078273939583
Validation loss: 2.3375338287783487

Epoch: 6| Step: 6
Training loss: 1.6024104409030517
Validation loss: 2.3281066722028707

Epoch: 6| Step: 7
Training loss: 2.2637753006328545
Validation loss: 2.3338394205838613

Epoch: 6| Step: 8
Training loss: 2.052218385954551
Validation loss: 2.339666262846652

Epoch: 6| Step: 9
Training loss: 1.6943453653826317
Validation loss: 2.3902367224198784

Epoch: 6| Step: 10
Training loss: 1.2490166610999232
Validation loss: 2.382877737759678

Epoch: 6| Step: 11
Training loss: 1.935814277970055
Validation loss: 2.4064578874927887

Epoch: 6| Step: 12
Training loss: 1.4508849074596557
Validation loss: 2.433337646749699

Epoch: 6| Step: 13
Training loss: 1.3596669026180013
Validation loss: 2.3533960973027543

Epoch: 294| Step: 0
Training loss: 1.2118764866883247
Validation loss: 2.392395549921015

Epoch: 6| Step: 1
Training loss: 1.5325954520788145
Validation loss: 2.345779142163825

Epoch: 6| Step: 2
Training loss: 1.8042764567152896
Validation loss: 2.4008779938210836

Epoch: 6| Step: 3
Training loss: 1.8210634966300723
Validation loss: 2.377009787076982

Epoch: 6| Step: 4
Training loss: 1.2178588935094747
Validation loss: 2.341370513499971

Epoch: 6| Step: 5
Training loss: 1.852255067991124
Validation loss: 2.3916132208330727

Epoch: 6| Step: 6
Training loss: 1.6805864634268202
Validation loss: 2.378077704635632

Epoch: 6| Step: 7
Training loss: 1.2696285269221512
Validation loss: 2.4177657701904467

Epoch: 6| Step: 8
Training loss: 2.335286027270021
Validation loss: 2.401301629999999

Epoch: 6| Step: 9
Training loss: 2.71692666484886
Validation loss: 2.371495648839599

Epoch: 6| Step: 10
Training loss: 1.9977996166045955
Validation loss: 2.375258198008671

Epoch: 6| Step: 11
Training loss: 1.3277646641813023
Validation loss: 2.401035934426096

Epoch: 6| Step: 12
Training loss: 2.227613555719548
Validation loss: 2.366996882818123

Epoch: 6| Step: 13
Training loss: 1.6800823368604203
Validation loss: 2.4217318796560856

Epoch: 295| Step: 0
Training loss: 1.855368521141599
Validation loss: 2.3677688610891017

Epoch: 6| Step: 1
Training loss: 1.283365271323635
Validation loss: 2.3359444722690146

Epoch: 6| Step: 2
Training loss: 1.7241549038873731
Validation loss: 2.36902986055588

Epoch: 6| Step: 3
Training loss: 2.074863829223633
Validation loss: 2.3446912782708025

Epoch: 6| Step: 4
Training loss: 1.3301040265982491
Validation loss: 2.3598086648475882

Epoch: 6| Step: 5
Training loss: 2.107131782484162
Validation loss: 2.3364092922838613

Epoch: 6| Step: 6
Training loss: 1.725667246709329
Validation loss: 2.35158681102327

Epoch: 6| Step: 7
Training loss: 2.66275780016235
Validation loss: 2.3733462343830842

Epoch: 6| Step: 8
Training loss: 1.7846805264178578
Validation loss: 2.366473543738783

Epoch: 6| Step: 9
Training loss: 2.181724772115449
Validation loss: 2.3378165675523506

Epoch: 6| Step: 10
Training loss: 1.655979350306814
Validation loss: 2.3880778123260265

Epoch: 6| Step: 11
Training loss: 1.9907227161324188
Validation loss: 2.4066910666422285

Epoch: 6| Step: 12
Training loss: 1.1406995670557558
Validation loss: 2.401967654571509

Epoch: 6| Step: 13
Training loss: 1.4901401394987852
Validation loss: 2.373235754263325

Epoch: 296| Step: 0
Training loss: 1.7560381941497583
Validation loss: 2.361492590716795

Epoch: 6| Step: 1
Training loss: 1.5428870843449471
Validation loss: 2.3786979484548176

Epoch: 6| Step: 2
Training loss: 2.3106075482048634
Validation loss: 2.3591693956192694

Epoch: 6| Step: 3
Training loss: 1.9262825891707285
Validation loss: 2.370147278310829

Epoch: 6| Step: 4
Training loss: 1.5956837012090457
Validation loss: 2.3738947759439815

Epoch: 6| Step: 5
Training loss: 1.8321858485209703
Validation loss: 2.3437331477280594

Epoch: 6| Step: 6
Training loss: 1.539464210716199
Validation loss: 2.3427660817654976

Epoch: 6| Step: 7
Training loss: 1.8994703583599846
Validation loss: 2.336825404078588

Epoch: 6| Step: 8
Training loss: 1.8354739638819786
Validation loss: 2.3748011513902276

Epoch: 6| Step: 9
Training loss: 2.185747698164296
Validation loss: 2.398901404413381

Epoch: 6| Step: 10
Training loss: 1.7690019300071835
Validation loss: 2.3028737963692008

Epoch: 6| Step: 11
Training loss: 1.4422010592632242
Validation loss: 2.3102268985651584

Epoch: 6| Step: 12
Training loss: 1.8976285490336147
Validation loss: 2.3698726199842945

Epoch: 6| Step: 13
Training loss: 2.0381833808536554
Validation loss: 2.355033532687627

Epoch: 297| Step: 0
Training loss: 1.3148555508025657
Validation loss: 2.3199582089591178

Epoch: 6| Step: 1
Training loss: 1.695606962024374
Validation loss: 2.3169295782226818

Epoch: 6| Step: 2
Training loss: 1.9226987360507641
Validation loss: 2.3576129934038064

Epoch: 6| Step: 3
Training loss: 1.874387005102591
Validation loss: 2.3696915032116634

Epoch: 6| Step: 4
Training loss: 1.8526440129692734
Validation loss: 2.3763462055249556

Epoch: 6| Step: 5
Training loss: 1.7145849914666367
Validation loss: 2.343398524903202

Epoch: 6| Step: 6
Training loss: 1.4581474549043867
Validation loss: 2.3775742067120413

Epoch: 6| Step: 7
Training loss: 2.135179149785438
Validation loss: 2.375909363506748

Epoch: 6| Step: 8
Training loss: 2.088608307064624
Validation loss: 2.344564860351101

Epoch: 6| Step: 9
Training loss: 1.8893362649927612
Validation loss: 2.3395540591299846

Epoch: 6| Step: 10
Training loss: 2.2556773719193455
Validation loss: 2.335983077827713

Epoch: 6| Step: 11
Training loss: 2.073251847304392
Validation loss: 2.3799232830472206

Epoch: 6| Step: 12
Training loss: 1.3446011619855633
Validation loss: 2.361989737502844

Epoch: 6| Step: 13
Training loss: 1.5493293326458077
Validation loss: 2.397107087927692

Epoch: 298| Step: 0
Training loss: 1.4477162759917719
Validation loss: 2.3817262968096053

Epoch: 6| Step: 1
Training loss: 2.4894313579657
Validation loss: 2.3795700447058707

Epoch: 6| Step: 2
Training loss: 1.6924016899733376
Validation loss: 2.3607352104329573

Epoch: 6| Step: 3
Training loss: 1.6298569208080531
Validation loss: 2.3790571654322767

Epoch: 6| Step: 4
Training loss: 2.0249916500343255
Validation loss: 2.3372770271429135

Epoch: 6| Step: 5
Training loss: 2.4174315020572292
Validation loss: 2.385260924063433

Epoch: 6| Step: 6
Training loss: 1.6384496890583609
Validation loss: 2.372232191976761

Epoch: 6| Step: 7
Training loss: 1.4608040815008079
Validation loss: 2.3329560612824616

Epoch: 6| Step: 8
Training loss: 1.5559631941298664
Validation loss: 2.3682516505581543

Epoch: 6| Step: 9
Training loss: 1.6996840267493083
Validation loss: 2.3885240142212756

Epoch: 6| Step: 10
Training loss: 1.2811831014892547
Validation loss: 2.329042491067866

Epoch: 6| Step: 11
Training loss: 2.223754611425995
Validation loss: 2.3552854665250695

Epoch: 6| Step: 12
Training loss: 1.5250393784238518
Validation loss: 2.323639663964369

Epoch: 6| Step: 13
Training loss: 1.7100275833849874
Validation loss: 2.3914457978162074

Epoch: 299| Step: 0
Training loss: 1.7403528791809684
Validation loss: 2.3932724444124096

Epoch: 6| Step: 1
Training loss: 1.9357186403864017
Validation loss: 2.3757558932861533

Epoch: 6| Step: 2
Training loss: 1.5816099006078603
Validation loss: 2.3736832006319144

Epoch: 6| Step: 3
Training loss: 1.6654621381026256
Validation loss: 2.362385624633757

Epoch: 6| Step: 4
Training loss: 1.3989264629688565
Validation loss: 2.3284045503956583

Epoch: 6| Step: 5
Training loss: 1.5995713673083014
Validation loss: 2.3382261596784493

Epoch: 6| Step: 6
Training loss: 1.7959033495123826
Validation loss: 2.371504328354995

Epoch: 6| Step: 7
Training loss: 2.003573086948937
Validation loss: 2.3834157249097605

Epoch: 6| Step: 8
Training loss: 2.107643490541376
Validation loss: 2.374366682290194

Epoch: 6| Step: 9
Training loss: 1.9361459245779398
Validation loss: 2.3331246147180607

Epoch: 6| Step: 10
Training loss: 1.3737221328505216
Validation loss: 2.376747180599708

Epoch: 6| Step: 11
Training loss: 2.160717965295174
Validation loss: 2.3527511477719343

Epoch: 6| Step: 12
Training loss: 1.963574099757699
Validation loss: 2.3703754360965994

Epoch: 6| Step: 13
Training loss: 1.6009891134889112
Validation loss: 2.3261270207838107

Epoch: 300| Step: 0
Training loss: 1.6552590338606359
Validation loss: 2.294385063662474

Epoch: 6| Step: 1
Training loss: 1.643209837141372
Validation loss: 2.3646002588122146

Epoch: 6| Step: 2
Training loss: 2.478001702838402
Validation loss: 2.3409685416366934

Epoch: 6| Step: 3
Training loss: 1.7199589032431022
Validation loss: 2.3608834732591255

Epoch: 6| Step: 4
Training loss: 1.320421564236136
Validation loss: 2.344201813494958

Epoch: 6| Step: 5
Training loss: 1.6030283848610691
Validation loss: 2.3550783098807915

Epoch: 6| Step: 6
Training loss: 1.3573222830484344
Validation loss: 2.3309021258231617

Epoch: 6| Step: 7
Training loss: 1.7880966044534368
Validation loss: 2.358179812288322

Epoch: 6| Step: 8
Training loss: 1.625297079073657
Validation loss: 2.386681704660562

Epoch: 6| Step: 9
Training loss: 2.3122205823193576
Validation loss: 2.3738149796410615

Epoch: 6| Step: 10
Training loss: 1.441249601127523
Validation loss: 2.3846708375659342

Epoch: 6| Step: 11
Training loss: 2.1176059210901665
Validation loss: 2.3741420854340136

Epoch: 6| Step: 12
Training loss: 2.018648939880451
Validation loss: 2.3939158082954357

Epoch: 6| Step: 13
Training loss: 1.6424601146204119
Validation loss: 2.3926585459383025

Epoch: 301| Step: 0
Training loss: 1.74332401172244
Validation loss: 2.3422841553258147

Epoch: 6| Step: 1
Training loss: 1.9562067971623451
Validation loss: 2.3812134340916495

Epoch: 6| Step: 2
Training loss: 1.742336591832965
Validation loss: 2.3424481506918466

Epoch: 6| Step: 3
Training loss: 1.8639040371992586
Validation loss: 2.3651526855578204

Epoch: 6| Step: 4
Training loss: 2.665187027829482
Validation loss: 2.362946625866425

Epoch: 6| Step: 5
Training loss: 1.5610263741884265
Validation loss: 2.346164409751932

Epoch: 6| Step: 6
Training loss: 1.504920359940819
Validation loss: 2.3834411168468344

Epoch: 6| Step: 7
Training loss: 2.2809346647358626
Validation loss: 2.3262170969918197

Epoch: 6| Step: 8
Training loss: 1.3789883770138198
Validation loss: 2.280607849264698

Epoch: 6| Step: 9
Training loss: 1.5335162772355522
Validation loss: 2.3448383016828607

Epoch: 6| Step: 10
Training loss: 1.6893365544140664
Validation loss: 2.3516109942460783

Epoch: 6| Step: 11
Training loss: 1.6356486097300114
Validation loss: 2.3285801699890056

Epoch: 6| Step: 12
Training loss: 1.6034287163139405
Validation loss: 2.356505465395584

Epoch: 6| Step: 13
Training loss: 1.2880668725489213
Validation loss: 2.307060226943468

Epoch: 302| Step: 0
Training loss: 1.1937213355013199
Validation loss: 2.352808966377899

Epoch: 6| Step: 1
Training loss: 1.9846660971204517
Validation loss: 2.3376001154971497

Epoch: 6| Step: 2
Training loss: 1.7930178832924446
Validation loss: 2.4139797314514784

Epoch: 6| Step: 3
Training loss: 2.1574265960194134
Validation loss: 2.374555771284132

Epoch: 6| Step: 4
Training loss: 2.1911844015448554
Validation loss: 2.3455108066192656

Epoch: 6| Step: 5
Training loss: 1.7137632680834254
Validation loss: 2.3817413639179272

Epoch: 6| Step: 6
Training loss: 1.8204483178023227
Validation loss: 2.3556780379902382

Epoch: 6| Step: 7
Training loss: 1.5935760103882743
Validation loss: 2.3353814030290607

Epoch: 6| Step: 8
Training loss: 1.904514460726335
Validation loss: 2.3315529498648107

Epoch: 6| Step: 9
Training loss: 1.396470119163468
Validation loss: 2.3807215238461548

Epoch: 6| Step: 10
Training loss: 2.0427500387081357
Validation loss: 2.368785520066434

Epoch: 6| Step: 11
Training loss: 1.8358026982592752
Validation loss: 2.4053646739474717

Epoch: 6| Step: 12
Training loss: 1.650263060205008
Validation loss: 2.328605041873967

Epoch: 6| Step: 13
Training loss: 1.8942103792587885
Validation loss: 2.367501340557466

Epoch: 303| Step: 0
Training loss: 1.448514124418584
Validation loss: 2.3415705807142535

Epoch: 6| Step: 1
Training loss: 1.3070215602225996
Validation loss: 2.363046506014889

Epoch: 6| Step: 2
Training loss: 1.1547778268464548
Validation loss: 2.364360587599801

Epoch: 6| Step: 3
Training loss: 1.7227705660234442
Validation loss: 2.3714523675386996

Epoch: 6| Step: 4
Training loss: 1.9298912280566818
Validation loss: 2.338255392916941

Epoch: 6| Step: 5
Training loss: 2.195894320351028
Validation loss: 2.35841533852111

Epoch: 6| Step: 6
Training loss: 1.9871079256094821
Validation loss: 2.32995614721549

Epoch: 6| Step: 7
Training loss: 2.1366894038275555
Validation loss: 2.443896960131911

Epoch: 6| Step: 8
Training loss: 1.225874592501422
Validation loss: 2.3403928606357205

Epoch: 6| Step: 9
Training loss: 1.4914548982865847
Validation loss: 2.3869993031755405

Epoch: 6| Step: 10
Training loss: 2.1115883976442174
Validation loss: 2.3631515832114705

Epoch: 6| Step: 11
Training loss: 1.8887419347382581
Validation loss: 2.370957643890474

Epoch: 6| Step: 12
Training loss: 1.747606138790749
Validation loss: 2.396681023466476

Epoch: 6| Step: 13
Training loss: 2.906710024285739
Validation loss: 2.361475387122216

Epoch: 304| Step: 0
Training loss: 1.5139951299238805
Validation loss: 2.3463114823504037

Epoch: 6| Step: 1
Training loss: 2.4843943853041845
Validation loss: 2.3880755225145016

Epoch: 6| Step: 2
Training loss: 2.237500545565576
Validation loss: 2.4207551799926907

Epoch: 6| Step: 3
Training loss: 1.620345639337799
Validation loss: 2.4238357794362995

Epoch: 6| Step: 4
Training loss: 1.5025395512254665
Validation loss: 2.432192239909426

Epoch: 6| Step: 5
Training loss: 1.8656232977624536
Validation loss: 2.414326007034784

Epoch: 6| Step: 6
Training loss: 1.595218131835837
Validation loss: 2.4069448367324164

Epoch: 6| Step: 7
Training loss: 1.220788180630515
Validation loss: 2.4721552690847344

Epoch: 6| Step: 8
Training loss: 1.9941824106290233
Validation loss: 2.4845078924805306

Epoch: 6| Step: 9
Training loss: 1.8971274294365437
Validation loss: 2.4623486732370647

Epoch: 6| Step: 10
Training loss: 1.7532804260442347
Validation loss: 2.393556478847146

Epoch: 6| Step: 11
Training loss: 2.262549476714823
Validation loss: 2.3671095689153367

Epoch: 6| Step: 12
Training loss: 1.7198675510509405
Validation loss: 2.393457373296225

Epoch: 6| Step: 13
Training loss: 0.8056742719523579
Validation loss: 2.3798157205760258

Epoch: 305| Step: 0
Training loss: 1.860788080861335
Validation loss: 2.3889642134649236

Epoch: 6| Step: 1
Training loss: 1.9822644401387086
Validation loss: 2.3273460735236786

Epoch: 6| Step: 2
Training loss: 1.8038118558284888
Validation loss: 2.3611408729615793

Epoch: 6| Step: 3
Training loss: 1.692145628688493
Validation loss: 2.324737652494552

Epoch: 6| Step: 4
Training loss: 1.4682892421607603
Validation loss: 2.3603885676295704

Epoch: 6| Step: 5
Training loss: 1.0764852022676827
Validation loss: 2.3529285369757655

Epoch: 6| Step: 6
Training loss: 2.7908450288737296
Validation loss: 2.332268059351594

Epoch: 6| Step: 7
Training loss: 1.025587371842604
Validation loss: 2.3853312074626825

Epoch: 6| Step: 8
Training loss: 1.1773394021989902
Validation loss: 2.322237388265095

Epoch: 6| Step: 9
Training loss: 1.7206279552031114
Validation loss: 2.364575445438391

Epoch: 6| Step: 10
Training loss: 1.5369086516218768
Validation loss: 2.3558560120751104

Epoch: 6| Step: 11
Training loss: 2.0553599370487876
Validation loss: 2.35815050099152

Epoch: 6| Step: 12
Training loss: 2.1234858110895587
Validation loss: 2.3549162788977163

Epoch: 6| Step: 13
Training loss: 1.8865442925902014
Validation loss: 2.3275408279286727

Epoch: 306| Step: 0
Training loss: 2.276599690507286
Validation loss: 2.3313969647036683

Epoch: 6| Step: 1
Training loss: 1.581489074485975
Validation loss: 2.375310291428306

Epoch: 6| Step: 2
Training loss: 1.794454121374933
Validation loss: 2.404607270951525

Epoch: 6| Step: 3
Training loss: 1.5830013362086062
Validation loss: 2.273155939497578

Epoch: 6| Step: 4
Training loss: 0.9166447607948652
Validation loss: 2.3096440485738357

Epoch: 6| Step: 5
Training loss: 2.4232458357338844
Validation loss: 2.327114682419684

Epoch: 6| Step: 6
Training loss: 1.443256792648192
Validation loss: 2.3478549517399205

Epoch: 6| Step: 7
Training loss: 1.5130383156200313
Validation loss: 2.3310984846130074

Epoch: 6| Step: 8
Training loss: 2.0911467581082235
Validation loss: 2.372167261248149

Epoch: 6| Step: 9
Training loss: 1.9032583681676973
Validation loss: 2.318193200553784

Epoch: 6| Step: 10
Training loss: 1.8257329566324085
Validation loss: 2.371574395171481

Epoch: 6| Step: 11
Training loss: 1.5804546270715307
Validation loss: 2.4108014677991925

Epoch: 6| Step: 12
Training loss: 1.6949998417857048
Validation loss: 2.426669822879232

Epoch: 6| Step: 13
Training loss: 1.534755431209585
Validation loss: 2.4034107750898195

Epoch: 307| Step: 0
Training loss: 1.7249510827246577
Validation loss: 2.4014884652779767

Epoch: 6| Step: 1
Training loss: 2.038916454712074
Validation loss: 2.344336522044336

Epoch: 6| Step: 2
Training loss: 1.5897611179481943
Validation loss: 2.3839837579155305

Epoch: 6| Step: 3
Training loss: 1.101672444369295
Validation loss: 2.4390532658993864

Epoch: 6| Step: 4
Training loss: 1.696250761365052
Validation loss: 2.3770215617349866

Epoch: 6| Step: 5
Training loss: 2.3063281410439282
Validation loss: 2.4011521361494865

Epoch: 6| Step: 6
Training loss: 2.3158174380754066
Validation loss: 2.3438701224222607

Epoch: 6| Step: 7
Training loss: 1.4965629140805914
Validation loss: 2.3590020391108206

Epoch: 6| Step: 8
Training loss: 1.8941886041425111
Validation loss: 2.3516634774051446

Epoch: 6| Step: 9
Training loss: 1.2589597031474717
Validation loss: 2.2988600271496162

Epoch: 6| Step: 10
Training loss: 1.9722781583826363
Validation loss: 2.352733858465557

Epoch: 6| Step: 11
Training loss: 2.000478687221472
Validation loss: 2.3293157977267263

Epoch: 6| Step: 12
Training loss: 1.887858739449853
Validation loss: 2.3318737524648228

Epoch: 6| Step: 13
Training loss: 1.2244410543650617
Validation loss: 2.3668579838243855

Epoch: 308| Step: 0
Training loss: 1.4045229160860684
Validation loss: 2.364190927239229

Epoch: 6| Step: 1
Training loss: 1.290410949099845
Validation loss: 2.3248560214397775

Epoch: 6| Step: 2
Training loss: 1.509765625
Validation loss: 2.3462504217978184

Epoch: 6| Step: 3
Training loss: 1.8183267920306783
Validation loss: 2.314788677453129

Epoch: 6| Step: 4
Training loss: 1.3446462880139483
Validation loss: 2.355966413826622

Epoch: 6| Step: 5
Training loss: 1.9905472529153552
Validation loss: 2.422591573326996

Epoch: 6| Step: 6
Training loss: 1.666110144524405
Validation loss: 2.397064974930503

Epoch: 6| Step: 7
Training loss: 2.1895014734570304
Validation loss: 2.3146825599580314

Epoch: 6| Step: 8
Training loss: 1.7947518451839006
Validation loss: 2.37871582178615

Epoch: 6| Step: 9
Training loss: 1.8175163568445432
Validation loss: 2.3895314414005404

Epoch: 6| Step: 10
Training loss: 2.4803466766836535
Validation loss: 2.3407938843452762

Epoch: 6| Step: 11
Training loss: 1.8114569721213154
Validation loss: 2.3505699105056364

Epoch: 6| Step: 12
Training loss: 1.5398890410739274
Validation loss: 2.3237207188147337

Epoch: 6| Step: 13
Training loss: 1.6991159693008535
Validation loss: 2.3295369958938865

Epoch: 309| Step: 0
Training loss: 1.5140466238474823
Validation loss: 2.3439766444068786

Epoch: 6| Step: 1
Training loss: 1.278433238870685
Validation loss: 2.316719666331648

Epoch: 6| Step: 2
Training loss: 1.8144795361455759
Validation loss: 2.3558985461334028

Epoch: 6| Step: 3
Training loss: 2.0482953217934083
Validation loss: 2.353147717616684

Epoch: 6| Step: 4
Training loss: 1.6960581181392933
Validation loss: 2.3740313804827236

Epoch: 6| Step: 5
Training loss: 1.1560178987707943
Validation loss: 2.343158154431265

Epoch: 6| Step: 6
Training loss: 2.116444362270463
Validation loss: 2.3130926898664828

Epoch: 6| Step: 7
Training loss: 2.5132751863197176
Validation loss: 2.3437890271728277

Epoch: 6| Step: 8
Training loss: 1.6338939097269436
Validation loss: 2.3401958488196293

Epoch: 6| Step: 9
Training loss: 1.8665175253461501
Validation loss: 2.335223964300474

Epoch: 6| Step: 10
Training loss: 1.600850537849896
Validation loss: 2.321361146097803

Epoch: 6| Step: 11
Training loss: 1.6848628312602643
Validation loss: 2.331694021247105

Epoch: 6| Step: 12
Training loss: 1.5191897128573948
Validation loss: 2.325284089114101

Epoch: 6| Step: 13
Training loss: 1.8278241032169986
Validation loss: 2.3839350930800145

Epoch: 310| Step: 0
Training loss: 1.3680591529415917
Validation loss: 2.320367429001691

Epoch: 6| Step: 1
Training loss: 1.3561759225330157
Validation loss: 2.3293379565139887

Epoch: 6| Step: 2
Training loss: 1.422853740829235
Validation loss: 2.3413543347342918

Epoch: 6| Step: 3
Training loss: 1.7895704322974606
Validation loss: 2.320234185585533

Epoch: 6| Step: 4
Training loss: 2.2427599239365805
Validation loss: 2.3814199298987857

Epoch: 6| Step: 5
Training loss: 1.394998680442268
Validation loss: 2.3813910785121863

Epoch: 6| Step: 6
Training loss: 2.3924948167894238
Validation loss: 2.3012867922358673

Epoch: 6| Step: 7
Training loss: 1.6813590315736253
Validation loss: 2.340830675155293

Epoch: 6| Step: 8
Training loss: 2.005830848141842
Validation loss: 2.325578737336686

Epoch: 6| Step: 9
Training loss: 1.431215147568583
Validation loss: 2.363893432570726

Epoch: 6| Step: 10
Training loss: 1.622838416639123
Validation loss: 2.3656639552478764

Epoch: 6| Step: 11
Training loss: 2.593196947814849
Validation loss: 2.317258780225185

Epoch: 6| Step: 12
Training loss: 1.9227931612909324
Validation loss: 2.329411306225595

Epoch: 6| Step: 13
Training loss: 1.1728181222790544
Validation loss: 2.3679978169532596

Epoch: 311| Step: 0
Training loss: 1.800427714499852
Validation loss: 2.3316384574871774

Epoch: 6| Step: 1
Training loss: 1.712743354825676
Validation loss: 2.319799414067363

Epoch: 6| Step: 2
Training loss: 2.068556245794782
Validation loss: 2.360536785436463

Epoch: 6| Step: 3
Training loss: 1.8361018979753099
Validation loss: 2.3273593028568125

Epoch: 6| Step: 4
Training loss: 2.288379971037525
Validation loss: 2.3285028823088885

Epoch: 6| Step: 5
Training loss: 1.1815349437019549
Validation loss: 2.344431068154836

Epoch: 6| Step: 6
Training loss: 1.5372217469298335
Validation loss: 2.3959014119609576

Epoch: 6| Step: 7
Training loss: 1.764607228999683
Validation loss: 2.3411517370338157

Epoch: 6| Step: 8
Training loss: 1.620101588325294
Validation loss: 2.37015188473088

Epoch: 6| Step: 9
Training loss: 1.6463077038591944
Validation loss: 2.3279359036930867

Epoch: 6| Step: 10
Training loss: 1.644612507386994
Validation loss: 2.3405807490057997

Epoch: 6| Step: 11
Training loss: 2.280592627720273
Validation loss: 2.412595321172285

Epoch: 6| Step: 12
Training loss: 1.7370054213461772
Validation loss: 2.3496859738844935

Epoch: 6| Step: 13
Training loss: 1.208793366215426
Validation loss: 2.2703299128551175

Epoch: 312| Step: 0
Training loss: 2.002198917838035
Validation loss: 2.3719538663104616

Epoch: 6| Step: 1
Training loss: 2.3639409429205736
Validation loss: 2.3821218397775494

Epoch: 6| Step: 2
Training loss: 1.7634765246445476
Validation loss: 2.325944346005206

Epoch: 6| Step: 3
Training loss: 1.1249513615584419
Validation loss: 2.353796444036363

Epoch: 6| Step: 4
Training loss: 1.6149411287000124
Validation loss: 2.35978968849009

Epoch: 6| Step: 5
Training loss: 2.1476382346731557
Validation loss: 2.3605610996057282

Epoch: 6| Step: 6
Training loss: 1.64311588660637
Validation loss: 2.359283895349204

Epoch: 6| Step: 7
Training loss: 1.232699210372948
Validation loss: 2.337301467010898

Epoch: 6| Step: 8
Training loss: 1.7560963030587062
Validation loss: 2.356767307664791

Epoch: 6| Step: 9
Training loss: 1.5610754003697735
Validation loss: 2.3286224690446793

Epoch: 6| Step: 10
Training loss: 1.8438874532896985
Validation loss: 2.3998559710309966

Epoch: 6| Step: 11
Training loss: 1.3443975440865772
Validation loss: 2.338902080600242

Epoch: 6| Step: 12
Training loss: 1.80708747904927
Validation loss: 2.3553197332619593

Epoch: 6| Step: 13
Training loss: 2.4357349167147015
Validation loss: 2.362563469963025

Epoch: 313| Step: 0
Training loss: 1.4339957440205389
Validation loss: 2.3706349910271856

Epoch: 6| Step: 1
Training loss: 0.9007418727291058
Validation loss: 2.36616421652387

Epoch: 6| Step: 2
Training loss: 1.9511245859275084
Validation loss: 2.3014528406623467

Epoch: 6| Step: 3
Training loss: 1.0314835370664306
Validation loss: 2.3347247427781004

Epoch: 6| Step: 4
Training loss: 1.5500695735944883
Validation loss: 2.3001512961451653

Epoch: 6| Step: 5
Training loss: 1.7123731051021767
Validation loss: 2.3733236180109856

Epoch: 6| Step: 6
Training loss: 1.4360456158238597
Validation loss: 2.313801746600482

Epoch: 6| Step: 7
Training loss: 2.29755417520203
Validation loss: 2.357575424384591

Epoch: 6| Step: 8
Training loss: 1.4530274553271347
Validation loss: 2.3360827933726838

Epoch: 6| Step: 9
Training loss: 1.8090265468886912
Validation loss: 2.2784310113340758

Epoch: 6| Step: 10
Training loss: 1.9107974483793173
Validation loss: 2.4038309265045674

Epoch: 6| Step: 11
Training loss: 2.4642994033243717
Validation loss: 2.358483372928271

Epoch: 6| Step: 12
Training loss: 1.9698459057642186
Validation loss: 2.398515449976252

Epoch: 6| Step: 13
Training loss: 1.7206633581617181
Validation loss: 2.3479879204806076

Epoch: 314| Step: 0
Training loss: 2.0381287523204112
Validation loss: 2.3697872954694175

Epoch: 6| Step: 1
Training loss: 1.812461589537777
Validation loss: 2.3665446437338624

Epoch: 6| Step: 2
Training loss: 2.332281102481262
Validation loss: 2.379919048591272

Epoch: 6| Step: 3
Training loss: 1.719393037668819
Validation loss: 2.3512354541481777

Epoch: 6| Step: 4
Training loss: 1.7719941840883657
Validation loss: 2.3247711575793297

Epoch: 6| Step: 5
Training loss: 2.0392109900883644
Validation loss: 2.3452093720473948

Epoch: 6| Step: 6
Training loss: 1.5654118680266986
Validation loss: 2.3772891518741264

Epoch: 6| Step: 7
Training loss: 1.2913552903622827
Validation loss: 2.362326446233449

Epoch: 6| Step: 8
Training loss: 1.8121708538187495
Validation loss: 2.339944880330411

Epoch: 6| Step: 9
Training loss: 1.8289641712114526
Validation loss: 2.36808512535932

Epoch: 6| Step: 10
Training loss: 1.4436377642714056
Validation loss: 2.3522439299880307

Epoch: 6| Step: 11
Training loss: 1.4848959560744353
Validation loss: 2.3366714681480922

Epoch: 6| Step: 12
Training loss: 1.4210777982264238
Validation loss: 2.347932188736492

Epoch: 6| Step: 13
Training loss: 1.8841225905776602
Validation loss: 2.3470532979329897

Epoch: 315| Step: 0
Training loss: 1.56922654896452
Validation loss: 2.3987296026998313

Epoch: 6| Step: 1
Training loss: 1.2262691462866222
Validation loss: 2.3472758794063506

Epoch: 6| Step: 2
Training loss: 1.4784997412610723
Validation loss: 2.3237834045303534

Epoch: 6| Step: 3
Training loss: 1.535744590713734
Validation loss: 2.3723783568829107

Epoch: 6| Step: 4
Training loss: 1.843373017645598
Validation loss: 2.3689349981147303

Epoch: 6| Step: 5
Training loss: 1.789536059476451
Validation loss: 2.3171771972990127

Epoch: 6| Step: 6
Training loss: 1.8338764715494966
Validation loss: 2.347962741290725

Epoch: 6| Step: 7
Training loss: 1.9111118539665808
Validation loss: 2.3443606395381504

Epoch: 6| Step: 8
Training loss: 1.5287154104416643
Validation loss: 2.369974178591343

Epoch: 6| Step: 9
Training loss: 2.0121764023580395
Validation loss: 2.321886888791938

Epoch: 6| Step: 10
Training loss: 1.7164379868765922
Validation loss: 2.3208267555210615

Epoch: 6| Step: 11
Training loss: 1.8101188540557511
Validation loss: 2.331566530269784

Epoch: 6| Step: 12
Training loss: 2.285327037721744
Validation loss: 2.358722456632413

Epoch: 6| Step: 13
Training loss: 1.2813022416792088
Validation loss: 2.3610749390509795

Epoch: 316| Step: 0
Training loss: 1.7796471059500276
Validation loss: 2.3437113079856062

Epoch: 6| Step: 1
Training loss: 1.6255170293060872
Validation loss: 2.3624350242015644

Epoch: 6| Step: 2
Training loss: 2.312574643141825
Validation loss: 2.315798379656523

Epoch: 6| Step: 3
Training loss: 1.5039780636770366
Validation loss: 2.342427174245375

Epoch: 6| Step: 4
Training loss: 2.130327614675642
Validation loss: 2.3587842915017467

Epoch: 6| Step: 5
Training loss: 1.8607274113854508
Validation loss: 2.3529280801805745

Epoch: 6| Step: 6
Training loss: 1.7220097926943545
Validation loss: 2.3380752589123097

Epoch: 6| Step: 7
Training loss: 1.2071192440809408
Validation loss: 2.33268831569779

Epoch: 6| Step: 8
Training loss: 1.869071807710592
Validation loss: 2.414277943192348

Epoch: 6| Step: 9
Training loss: 1.7533105463038758
Validation loss: 2.333297735446627

Epoch: 6| Step: 10
Training loss: 1.7936428024745206
Validation loss: 2.3377426196149793

Epoch: 6| Step: 11
Training loss: 1.7911392219187017
Validation loss: 2.3910998959113177

Epoch: 6| Step: 12
Training loss: 1.289110402459861
Validation loss: 2.381498136546866

Epoch: 6| Step: 13
Training loss: 1.3843812826113084
Validation loss: 2.373922260548166

Epoch: 317| Step: 0
Training loss: 1.6400261648928662
Validation loss: 2.3828977217581726

Epoch: 6| Step: 1
Training loss: 1.5777255015301968
Validation loss: 2.3125079813616884

Epoch: 6| Step: 2
Training loss: 1.4100931845640743
Validation loss: 2.355960542171565

Epoch: 6| Step: 3
Training loss: 2.3233264396306152
Validation loss: 2.3498055953877026

Epoch: 6| Step: 4
Training loss: 1.6241725135229546
Validation loss: 2.3666940686056273

Epoch: 6| Step: 5
Training loss: 1.551431591584985
Validation loss: 2.366185167809062

Epoch: 6| Step: 6
Training loss: 2.1774391966431863
Validation loss: 2.333397724505402

Epoch: 6| Step: 7
Training loss: 1.8511394548605875
Validation loss: 2.346123326269402

Epoch: 6| Step: 8
Training loss: 1.5269837406394497
Validation loss: 2.338206065795052

Epoch: 6| Step: 9
Training loss: 1.534189011747604
Validation loss: 2.3162908138822327

Epoch: 6| Step: 10
Training loss: 1.703025744984448
Validation loss: 2.3455973557765883

Epoch: 6| Step: 11
Training loss: 1.5063249434825363
Validation loss: 2.323400342144478

Epoch: 6| Step: 12
Training loss: 1.7437094981094177
Validation loss: 2.333867134962807

Epoch: 6| Step: 13
Training loss: 1.3991798689406605
Validation loss: 2.349738654421391

Epoch: 318| Step: 0
Training loss: 1.6354137671702087
Validation loss: 2.3146564840656727

Epoch: 6| Step: 1
Training loss: 1.9192623585100232
Validation loss: 2.3527292536285547

Epoch: 6| Step: 2
Training loss: 1.6095250624535984
Validation loss: 2.334416349807798

Epoch: 6| Step: 3
Training loss: 1.3239077762742184
Validation loss: 2.331282830600311

Epoch: 6| Step: 4
Training loss: 1.2564542082500259
Validation loss: 2.3782058563873925

Epoch: 6| Step: 5
Training loss: 1.9201573084920591
Validation loss: 2.4107110166877477

Epoch: 6| Step: 6
Training loss: 1.864030027786174
Validation loss: 2.3926348472436074

Epoch: 6| Step: 7
Training loss: 1.2998941965330009
Validation loss: 2.3735586368332893

Epoch: 6| Step: 8
Training loss: 1.5054476678596511
Validation loss: 2.3504749656367907

Epoch: 6| Step: 9
Training loss: 1.7595835262331299
Validation loss: 2.338314113750065

Epoch: 6| Step: 10
Training loss: 1.6078627805568029
Validation loss: 2.392351550486025

Epoch: 6| Step: 11
Training loss: 1.7412691989122315
Validation loss: 2.428214193724017

Epoch: 6| Step: 12
Training loss: 2.4267116365702437
Validation loss: 2.4203171858102044

Epoch: 6| Step: 13
Training loss: 2.624649569417535
Validation loss: 2.4142255788065365

Epoch: 319| Step: 0
Training loss: 1.5674626695486138
Validation loss: 2.3922166602776977

Epoch: 6| Step: 1
Training loss: 2.5438036038986027
Validation loss: 2.377347859682734

Epoch: 6| Step: 2
Training loss: 1.7113786241942843
Validation loss: 2.346203608742205

Epoch: 6| Step: 3
Training loss: 1.4107264583745394
Validation loss: 2.3199779050624967

Epoch: 6| Step: 4
Training loss: 1.7178766285760134
Validation loss: 2.367448283189587

Epoch: 6| Step: 5
Training loss: 1.4322748171653323
Validation loss: 2.3191133236225947

Epoch: 6| Step: 6
Training loss: 1.5401352759805556
Validation loss: 2.2852300261269733

Epoch: 6| Step: 7
Training loss: 1.4471227907439226
Validation loss: 2.369933791813564

Epoch: 6| Step: 8
Training loss: 1.9238490069655083
Validation loss: 2.291563498411177

Epoch: 6| Step: 9
Training loss: 1.727943524011729
Validation loss: 2.3732304568091274

Epoch: 6| Step: 10
Training loss: 1.9380240808295872
Validation loss: 2.3362438662092875

Epoch: 6| Step: 11
Training loss: 1.8770850350572985
Validation loss: 2.320712398174267

Epoch: 6| Step: 12
Training loss: 1.906585226131411
Validation loss: 2.3420866556951103

Epoch: 6| Step: 13
Training loss: 1.2992563101178702
Validation loss: 2.376269289004796

Epoch: 320| Step: 0
Training loss: 1.7973984992347327
Validation loss: 2.346468444279697

Epoch: 6| Step: 1
Training loss: 1.997634800455276
Validation loss: 2.3477740629243673

Epoch: 6| Step: 2
Training loss: 1.5319687071410513
Validation loss: 2.318846833155483

Epoch: 6| Step: 3
Training loss: 1.9118867925783414
Validation loss: 2.4010090586269186

Epoch: 6| Step: 4
Training loss: 2.0715008474058663
Validation loss: 2.352612921298012

Epoch: 6| Step: 5
Training loss: 1.4254312163971445
Validation loss: 2.347670352045703

Epoch: 6| Step: 6
Training loss: 2.2689476116280747
Validation loss: 2.3921158793376747

Epoch: 6| Step: 7
Training loss: 1.8760503370164814
Validation loss: 2.3492754148383566

Epoch: 6| Step: 8
Training loss: 1.3888702894660858
Validation loss: 2.356584528238465

Epoch: 6| Step: 9
Training loss: 1.84680614310803
Validation loss: 2.3807029397814805

Epoch: 6| Step: 10
Training loss: 1.3609404921909378
Validation loss: 2.3110654639015977

Epoch: 6| Step: 11
Training loss: 1.6237619525566414
Validation loss: 2.2809843964252323

Epoch: 6| Step: 12
Training loss: 1.4704845007605245
Validation loss: 2.2877079156922777

Epoch: 6| Step: 13
Training loss: 1.197128860602836
Validation loss: 2.3048190839025704

Epoch: 321| Step: 0
Training loss: 1.8157390722791296
Validation loss: 2.3483397244946413

Epoch: 6| Step: 1
Training loss: 1.7255777165595414
Validation loss: 2.306936487578355

Epoch: 6| Step: 2
Training loss: 2.1720833438317393
Validation loss: 2.3034990770335217

Epoch: 6| Step: 3
Training loss: 1.4595304843323536
Validation loss: 2.371553814714838

Epoch: 6| Step: 4
Training loss: 1.6513173768637208
Validation loss: 2.3787444766031913

Epoch: 6| Step: 5
Training loss: 1.8400422655309931
Validation loss: 2.296690248603199

Epoch: 6| Step: 6
Training loss: 1.4222549098616213
Validation loss: 2.3582595805038866

Epoch: 6| Step: 7
Training loss: 1.968481136310122
Validation loss: 2.3717261868053354

Epoch: 6| Step: 8
Training loss: 1.8382200296553586
Validation loss: 2.3582498118920454

Epoch: 6| Step: 9
Training loss: 1.735789229329767
Validation loss: 2.355258174250463

Epoch: 6| Step: 10
Training loss: 1.6405844547166297
Validation loss: 2.339754953869746

Epoch: 6| Step: 11
Training loss: 0.9679188085054196
Validation loss: 2.318186364001173

Epoch: 6| Step: 12
Training loss: 1.4077023529758232
Validation loss: 2.3365491586944693

Epoch: 6| Step: 13
Training loss: 1.9991418070146583
Validation loss: 2.4044874832182055

Epoch: 322| Step: 0
Training loss: 2.3474571918000944
Validation loss: 2.360778046974894

Epoch: 6| Step: 1
Training loss: 1.3922642679166657
Validation loss: 2.336085215904019

Epoch: 6| Step: 2
Training loss: 1.9696684617422622
Validation loss: 2.366029242461852

Epoch: 6| Step: 3
Training loss: 1.7705646385840583
Validation loss: 2.291469930965216

Epoch: 6| Step: 4
Training loss: 1.4414261813969613
Validation loss: 2.3727314341565444

Epoch: 6| Step: 5
Training loss: 1.7258905682665955
Validation loss: 2.3250212808323796

Epoch: 6| Step: 6
Training loss: 1.9397223862881279
Validation loss: 2.3743401114214753

Epoch: 6| Step: 7
Training loss: 2.1991790713699646
Validation loss: 2.325056684942922

Epoch: 6| Step: 8
Training loss: 1.6078791657353593
Validation loss: 2.3490173381181845

Epoch: 6| Step: 9
Training loss: 1.6360010289606342
Validation loss: 2.346156884353755

Epoch: 6| Step: 10
Training loss: 1.7569607175627098
Validation loss: 2.333472873614177

Epoch: 6| Step: 11
Training loss: 1.4998348463056281
Validation loss: 2.391266149915941

Epoch: 6| Step: 12
Training loss: 1.2977662758112478
Validation loss: 2.347022605741515

Epoch: 6| Step: 13
Training loss: 1.1740655389197636
Validation loss: 2.324249165350525

Epoch: 323| Step: 0
Training loss: 1.7687405131055278
Validation loss: 2.3247605358702077

Epoch: 6| Step: 1
Training loss: 1.6451475750896156
Validation loss: 2.327110056081484

Epoch: 6| Step: 2
Training loss: 1.6096139378624867
Validation loss: 2.287297678777106

Epoch: 6| Step: 3
Training loss: 1.4704414530036296
Validation loss: 2.316596876721971

Epoch: 6| Step: 4
Training loss: 1.7339903258831486
Validation loss: 2.30436668213979

Epoch: 6| Step: 5
Training loss: 1.4820265010260958
Validation loss: 2.308714191987375

Epoch: 6| Step: 6
Training loss: 1.630197429518954
Validation loss: 2.341511456521896

Epoch: 6| Step: 7
Training loss: 1.417278447539762
Validation loss: 2.3577558044746763

Epoch: 6| Step: 8
Training loss: 1.7735627924146624
Validation loss: 2.3345436368367167

Epoch: 6| Step: 9
Training loss: 2.0539310353707307
Validation loss: 2.3542472017193896

Epoch: 6| Step: 10
Training loss: 1.50374501342454
Validation loss: 2.3323237773858234

Epoch: 6| Step: 11
Training loss: 1.3201685719790341
Validation loss: 2.3206145580684936

Epoch: 6| Step: 12
Training loss: 2.118799925809502
Validation loss: 2.372244388579577

Epoch: 6| Step: 13
Training loss: 1.2632135565366727
Validation loss: 2.3792098341114043

Epoch: 324| Step: 0
Training loss: 1.899265877795285
Validation loss: 2.35242274147006

Epoch: 6| Step: 1
Training loss: 2.2230450603536016
Validation loss: 2.3483235200542585

Epoch: 6| Step: 2
Training loss: 1.2469426913518307
Validation loss: 2.408559093190284

Epoch: 6| Step: 3
Training loss: 1.3793680428181279
Validation loss: 2.3679613854438912

Epoch: 6| Step: 4
Training loss: 1.590163590034846
Validation loss: 2.337212625846752

Epoch: 6| Step: 5
Training loss: 1.610514265346028
Validation loss: 2.3894511984597893

Epoch: 6| Step: 6
Training loss: 1.6643568324874862
Validation loss: 2.375176598589829

Epoch: 6| Step: 7
Training loss: 1.4389051121435803
Validation loss: 2.3515473725296996

Epoch: 6| Step: 8
Training loss: 2.2415915305250596
Validation loss: 2.286929543921375

Epoch: 6| Step: 9
Training loss: 2.0268850524257833
Validation loss: 2.34018143662414

Epoch: 6| Step: 10
Training loss: 1.6364965902608237
Validation loss: 2.348937134351151

Epoch: 6| Step: 11
Training loss: 1.5297587392737855
Validation loss: 2.371224133363748

Epoch: 6| Step: 12
Training loss: 1.5567401007023116
Validation loss: 2.336927663309982

Epoch: 6| Step: 13
Training loss: 1.944303074496259
Validation loss: 2.370312332098263

Epoch: 325| Step: 0
Training loss: 1.2899604213172835
Validation loss: 2.398027617033953

Epoch: 6| Step: 1
Training loss: 1.8668985183097757
Validation loss: 2.319127951863997

Epoch: 6| Step: 2
Training loss: 1.655676544527607
Validation loss: 2.3102373440736765

Epoch: 6| Step: 3
Training loss: 1.264459992143511
Validation loss: 2.343780654105162

Epoch: 6| Step: 4
Training loss: 1.6301022902378839
Validation loss: 2.3880876108266342

Epoch: 6| Step: 5
Training loss: 1.6878205454111415
Validation loss: 2.36851602861446

Epoch: 6| Step: 6
Training loss: 1.5399390498398564
Validation loss: 2.3520904287460143

Epoch: 6| Step: 7
Training loss: 1.467778797863216
Validation loss: 2.390646592123853

Epoch: 6| Step: 8
Training loss: 1.7250320763300826
Validation loss: 2.4032861968075063

Epoch: 6| Step: 9
Training loss: 1.8113014599299881
Validation loss: 2.3719814614896464

Epoch: 6| Step: 10
Training loss: 1.6875346851316386
Validation loss: 2.407635461854043

Epoch: 6| Step: 11
Training loss: 2.069575801267589
Validation loss: 2.3537763158883

Epoch: 6| Step: 12
Training loss: 2.5027426933720722
Validation loss: 2.384319935820045

Epoch: 6| Step: 13
Training loss: 1.4168850879957904
Validation loss: 2.3320203205688768

Epoch: 326| Step: 0
Training loss: 1.6560902068590329
Validation loss: 2.2872413559412546

Epoch: 6| Step: 1
Training loss: 2.0438428945165574
Validation loss: 2.3249569667821266

Epoch: 6| Step: 2
Training loss: 1.3282076192851262
Validation loss: 2.3031033529926

Epoch: 6| Step: 3
Training loss: 1.9070349156064346
Validation loss: 2.3450832673816415

Epoch: 6| Step: 4
Training loss: 1.5973023113497906
Validation loss: 2.331593748017622

Epoch: 6| Step: 5
Training loss: 1.6210229329646721
Validation loss: 2.3461655592661246

Epoch: 6| Step: 6
Training loss: 1.7907257344669376
Validation loss: 2.3316472183009056

Epoch: 6| Step: 7
Training loss: 2.175151411902944
Validation loss: 2.298563264414649

Epoch: 6| Step: 8
Training loss: 1.4742935751972603
Validation loss: 2.3268772670726245

Epoch: 6| Step: 9
Training loss: 1.3662250728025904
Validation loss: 2.3808907949742

Epoch: 6| Step: 10
Training loss: 1.525521129930684
Validation loss: 2.3307885515369278

Epoch: 6| Step: 11
Training loss: 1.8997983725125074
Validation loss: 2.315424160357718

Epoch: 6| Step: 12
Training loss: 1.8023941859747945
Validation loss: 2.3803102353848313

Epoch: 6| Step: 13
Training loss: 1.3362536140014765
Validation loss: 2.357818975970927

Epoch: 327| Step: 0
Training loss: 2.4602696072533914
Validation loss: 2.317576691798528

Epoch: 6| Step: 1
Training loss: 1.7444994857363108
Validation loss: 2.3547599121951333

Epoch: 6| Step: 2
Training loss: 1.719399208222904
Validation loss: 2.362645711169117

Epoch: 6| Step: 3
Training loss: 1.7176050707620965
Validation loss: 2.310863932711047

Epoch: 6| Step: 4
Training loss: 1.5424482409234141
Validation loss: 2.3598266394212155

Epoch: 6| Step: 5
Training loss: 1.277047779196116
Validation loss: 2.3034644445173655

Epoch: 6| Step: 6
Training loss: 1.2193855193684977
Validation loss: 2.3622644034704696

Epoch: 6| Step: 7
Training loss: 1.9661996459333566
Validation loss: 2.2813044873185397

Epoch: 6| Step: 8
Training loss: 1.5782898165307282
Validation loss: 2.369299169130158

Epoch: 6| Step: 9
Training loss: 1.575777176949604
Validation loss: 2.3943243056582992

Epoch: 6| Step: 10
Training loss: 1.4509274673525856
Validation loss: 2.3253236632452734

Epoch: 6| Step: 11
Training loss: 1.4660510974945886
Validation loss: 2.3979584530587084

Epoch: 6| Step: 12
Training loss: 1.1377472828795097
Validation loss: 2.2860875539760817

Epoch: 6| Step: 13
Training loss: 2.246321107718559
Validation loss: 2.33318175773544

Epoch: 328| Step: 0
Training loss: 2.690542849395336
Validation loss: 2.356020778172097

Epoch: 6| Step: 1
Training loss: 1.545798418348216
Validation loss: 2.2911266022409227

Epoch: 6| Step: 2
Training loss: 1.4801481599364164
Validation loss: 2.3502615427253066

Epoch: 6| Step: 3
Training loss: 1.801358078858402
Validation loss: 2.3801215496996555

Epoch: 6| Step: 4
Training loss: 1.5633451846201543
Validation loss: 2.345111854338422

Epoch: 6| Step: 5
Training loss: 1.259945973343067
Validation loss: 2.294111790613453

Epoch: 6| Step: 6
Training loss: 1.4370849673662918
Validation loss: 2.3430564297150083

Epoch: 6| Step: 7
Training loss: 1.5112250258635829
Validation loss: 2.383528111517543

Epoch: 6| Step: 8
Training loss: 1.8826105159827713
Validation loss: 2.3856608306195284

Epoch: 6| Step: 9
Training loss: 1.6314073567112213
Validation loss: 2.3750447699186634

Epoch: 6| Step: 10
Training loss: 1.320519515743001
Validation loss: 2.378624258343637

Epoch: 6| Step: 11
Training loss: 1.8381957105974827
Validation loss: 2.321083667700495

Epoch: 6| Step: 12
Training loss: 1.4487656041671721
Validation loss: 2.3067532732989577

Epoch: 6| Step: 13
Training loss: 2.2366865245697474
Validation loss: 2.287194787203176

Epoch: 329| Step: 0
Training loss: 1.4645196581582918
Validation loss: 2.3800331435942423

Epoch: 6| Step: 1
Training loss: 1.9757169943090438
Validation loss: 2.355540153052295

Epoch: 6| Step: 2
Training loss: 0.9931144289350776
Validation loss: 2.2792082721703877

Epoch: 6| Step: 3
Training loss: 2.1121393245706366
Validation loss: 2.3177406407411585

Epoch: 6| Step: 4
Training loss: 1.4454174106772297
Validation loss: 2.3651241814936035

Epoch: 6| Step: 5
Training loss: 1.538186535648693
Validation loss: 2.4084836471451974

Epoch: 6| Step: 6
Training loss: 1.7946350067661045
Validation loss: 2.288837058195348

Epoch: 6| Step: 7
Training loss: 1.969037110722421
Validation loss: 2.3337721441327064

Epoch: 6| Step: 8
Training loss: 1.865144385918223
Validation loss: 2.3386725651204814

Epoch: 6| Step: 9
Training loss: 1.6376747853420612
Validation loss: 2.334912069996656

Epoch: 6| Step: 10
Training loss: 1.5473393985810757
Validation loss: 2.353952124908514

Epoch: 6| Step: 11
Training loss: 1.7117523621846065
Validation loss: 2.343280758935814

Epoch: 6| Step: 12
Training loss: 1.3041137987253797
Validation loss: 2.3029317606938324

Epoch: 6| Step: 13
Training loss: 1.557876460102471
Validation loss: 2.3387844093908816

Epoch: 330| Step: 0
Training loss: 1.6073913200505736
Validation loss: 2.3388536133142024

Epoch: 6| Step: 1
Training loss: 1.3742311235296942
Validation loss: 2.3396484779984594

Epoch: 6| Step: 2
Training loss: 2.3446578238570592
Validation loss: 2.3498571118978644

Epoch: 6| Step: 3
Training loss: 1.1597302614848362
Validation loss: 2.351367620078106

Epoch: 6| Step: 4
Training loss: 1.8141299843865224
Validation loss: 2.3385132151755608

Epoch: 6| Step: 5
Training loss: 1.6029009180937255
Validation loss: 2.3178298864858804

Epoch: 6| Step: 6
Training loss: 1.4141092872255847
Validation loss: 2.323682542804641

Epoch: 6| Step: 7
Training loss: 1.5933289065093363
Validation loss: 2.353481870108014

Epoch: 6| Step: 8
Training loss: 1.4627855005932515
Validation loss: 2.3254219269963428

Epoch: 6| Step: 9
Training loss: 1.0817822882618677
Validation loss: 2.299937580700855

Epoch: 6| Step: 10
Training loss: 1.8538793562695872
Validation loss: 2.355023903095899

Epoch: 6| Step: 11
Training loss: 1.5654737022527936
Validation loss: 2.343287637149173

Epoch: 6| Step: 12
Training loss: 2.356547296928006
Validation loss: 2.3677080057936504

Epoch: 6| Step: 13
Training loss: 2.2124184544940055
Validation loss: 2.309926598573344

Epoch: 331| Step: 0
Training loss: 1.7611638652242183
Validation loss: 2.3518083426369256

Epoch: 6| Step: 1
Training loss: 1.604027762736403
Validation loss: 2.327916880613797

Epoch: 6| Step: 2
Training loss: 1.9015794663937917
Validation loss: 2.3206057114148044

Epoch: 6| Step: 3
Training loss: 1.7174424486360034
Validation loss: 2.2987540057438034

Epoch: 6| Step: 4
Training loss: 1.6835218091140653
Validation loss: 2.321902356350764

Epoch: 6| Step: 5
Training loss: 1.3074824382703953
Validation loss: 2.3293586172044063

Epoch: 6| Step: 6
Training loss: 1.3754216327980122
Validation loss: 2.336826614685381

Epoch: 6| Step: 7
Training loss: 1.241030219943515
Validation loss: 2.2919600029602925

Epoch: 6| Step: 8
Training loss: 1.1930056483190186
Validation loss: 2.3520256242999054

Epoch: 6| Step: 9
Training loss: 1.6555708446408315
Validation loss: 2.3736215913436975

Epoch: 6| Step: 10
Training loss: 2.720892314261872
Validation loss: 2.3028551184298873

Epoch: 6| Step: 11
Training loss: 1.4099328030475413
Validation loss: 2.3001625642488697

Epoch: 6| Step: 12
Training loss: 1.958847330154651
Validation loss: 2.314680257347892

Epoch: 6| Step: 13
Training loss: 1.219879458444592
Validation loss: 2.3247183170740744

Epoch: 332| Step: 0
Training loss: 2.084455213476007
Validation loss: 2.3236982499538312

Epoch: 6| Step: 1
Training loss: 1.9228860320202734
Validation loss: 2.347207336656081

Epoch: 6| Step: 2
Training loss: 1.5282552589489515
Validation loss: 2.3699191439929184

Epoch: 6| Step: 3
Training loss: 1.6340606153677546
Validation loss: 2.322427423768616

Epoch: 6| Step: 4
Training loss: 1.2597015601139776
Validation loss: 2.3279970316552765

Epoch: 6| Step: 5
Training loss: 1.7851870344249725
Validation loss: 2.320428871796169

Epoch: 6| Step: 6
Training loss: 2.317226528422955
Validation loss: 2.3212022116589193

Epoch: 6| Step: 7
Training loss: 1.308031923761925
Validation loss: 2.3395465458903684

Epoch: 6| Step: 8
Training loss: 1.4834616812709367
Validation loss: 2.339083743422437

Epoch: 6| Step: 9
Training loss: 1.3274282535195197
Validation loss: 2.288685168755743

Epoch: 6| Step: 10
Training loss: 1.5617971746953812
Validation loss: 2.367450721271956

Epoch: 6| Step: 11
Training loss: 1.3439280369827311
Validation loss: 2.316165175758478

Epoch: 6| Step: 12
Training loss: 1.6124905549001936
Validation loss: 2.332010335408139

Epoch: 6| Step: 13
Training loss: 1.9556232801303635
Validation loss: 2.3354950119228275

Epoch: 333| Step: 0
Training loss: 1.6207678042046876
Validation loss: 2.27957288784338

Epoch: 6| Step: 1
Training loss: 1.7018282091738988
Validation loss: 2.3547718879278334

Epoch: 6| Step: 2
Training loss: 1.868443214470291
Validation loss: 2.3514238662199776

Epoch: 6| Step: 3
Training loss: 1.9768851397601337
Validation loss: 2.3140099447937175

Epoch: 6| Step: 4
Training loss: 1.673322745982463
Validation loss: 2.311725081978191

Epoch: 6| Step: 5
Training loss: 1.5718534889038558
Validation loss: 2.3611119871320874

Epoch: 6| Step: 6
Training loss: 1.6828964453314494
Validation loss: 2.277048599849964

Epoch: 6| Step: 7
Training loss: 1.6281642916399097
Validation loss: 2.2984963563252307

Epoch: 6| Step: 8
Training loss: 1.293620518641147
Validation loss: 2.2838460019155895

Epoch: 6| Step: 9
Training loss: 2.176171533176804
Validation loss: 2.370577075130441

Epoch: 6| Step: 10
Training loss: 2.3667346281940795
Validation loss: 2.296984042336954

Epoch: 6| Step: 11
Training loss: 1.0221323325076215
Validation loss: 2.3282448175571964

Epoch: 6| Step: 12
Training loss: 1.0587907445964952
Validation loss: 2.2727932682691367

Epoch: 6| Step: 13
Training loss: 1.2711189553564142
Validation loss: 2.4027703531468934

Epoch: 334| Step: 0
Training loss: 1.103549598913555
Validation loss: 2.27770398810616

Epoch: 6| Step: 1
Training loss: 1.8548618970601363
Validation loss: 2.3582287444481453

Epoch: 6| Step: 2
Training loss: 0.873509090540049
Validation loss: 2.3050503313944057

Epoch: 6| Step: 3
Training loss: 1.5946888122014966
Validation loss: 2.320649915623593

Epoch: 6| Step: 4
Training loss: 2.028556563862119
Validation loss: 2.3558085432594305

Epoch: 6| Step: 5
Training loss: 1.7173887931435867
Validation loss: 2.3443968232416843

Epoch: 6| Step: 6
Training loss: 1.5041323008886751
Validation loss: 2.3156430902065486

Epoch: 6| Step: 7
Training loss: 1.896622154817488
Validation loss: 2.3822750007803353

Epoch: 6| Step: 8
Training loss: 1.9512090211679294
Validation loss: 2.336286876381746

Epoch: 6| Step: 9
Training loss: 2.2917484500047918
Validation loss: 2.31823451581631

Epoch: 6| Step: 10
Training loss: 1.3909656664589674
Validation loss: 2.312529210352641

Epoch: 6| Step: 11
Training loss: 1.753850923273034
Validation loss: 2.3521562744516005

Epoch: 6| Step: 12
Training loss: 1.151970651001067
Validation loss: 2.346007210566554

Epoch: 6| Step: 13
Training loss: 1.8146731404425638
Validation loss: 2.3468622524763547

Epoch: 335| Step: 0
Training loss: 1.550753192023215
Validation loss: 2.376952423948456

Epoch: 6| Step: 1
Training loss: 1.3595285438551876
Validation loss: 2.3364064427066005

Epoch: 6| Step: 2
Training loss: 1.7875798507674763
Validation loss: 2.3395282357948055

Epoch: 6| Step: 3
Training loss: 1.3988735009455444
Validation loss: 2.3735297228318584

Epoch: 6| Step: 4
Training loss: 1.3955683338023361
Validation loss: 2.3368436240010597

Epoch: 6| Step: 5
Training loss: 1.3951741934959747
Validation loss: 2.3146220744251913

Epoch: 6| Step: 6
Training loss: 1.405895612355112
Validation loss: 2.2957792991257446

Epoch: 6| Step: 7
Training loss: 2.123658036996391
Validation loss: 2.3264301752075607

Epoch: 6| Step: 8
Training loss: 1.839581772604511
Validation loss: 2.370831513866865

Epoch: 6| Step: 9
Training loss: 2.046672082991169
Validation loss: 2.3387108888718435

Epoch: 6| Step: 10
Training loss: 1.0830888227704383
Validation loss: 2.387073869929283

Epoch: 6| Step: 11
Training loss: 1.5800375349680649
Validation loss: 2.347755779322626

Epoch: 6| Step: 12
Training loss: 2.314537285027078
Validation loss: 2.3306915864969957

Epoch: 6| Step: 13
Training loss: 1.6146211763274516
Validation loss: 2.3735466889236627

Epoch: 336| Step: 0
Training loss: 2.351599810231424
Validation loss: 2.3801695913256307

Epoch: 6| Step: 1
Training loss: 1.8968994440706464
Validation loss: 2.3714966250028984

Epoch: 6| Step: 2
Training loss: 2.4361470698166743
Validation loss: 2.3467277560953472

Epoch: 6| Step: 3
Training loss: 1.6051642878697014
Validation loss: 2.3626218546563473

Epoch: 6| Step: 4
Training loss: 1.1865562905366869
Validation loss: 2.291710457332156

Epoch: 6| Step: 5
Training loss: 1.8238736792206598
Validation loss: 2.3958980350041648

Epoch: 6| Step: 6
Training loss: 1.624552738553537
Validation loss: 2.344614653979408

Epoch: 6| Step: 7
Training loss: 1.1559801044434985
Validation loss: 2.3917728493828556

Epoch: 6| Step: 8
Training loss: 1.2195451538935547
Validation loss: 2.3937284928032003

Epoch: 6| Step: 9
Training loss: 1.7499626700643223
Validation loss: 2.3749096232016043

Epoch: 6| Step: 10
Training loss: 1.4142117079105447
Validation loss: 2.336981831002982

Epoch: 6| Step: 11
Training loss: 1.397529349795137
Validation loss: 2.3464000661404385

Epoch: 6| Step: 12
Training loss: 1.4129892143464202
Validation loss: 2.310737613432553

Epoch: 6| Step: 13
Training loss: 1.2023093691465492
Validation loss: 2.3283414914162086

Epoch: 337| Step: 0
Training loss: 1.553577582812217
Validation loss: 2.3563920828912313

Epoch: 6| Step: 1
Training loss: 2.0421705856731873
Validation loss: 2.3317044915295417

Epoch: 6| Step: 2
Training loss: 1.4814134467362237
Validation loss: 2.3228529580126724

Epoch: 6| Step: 3
Training loss: 2.0105164129255613
Validation loss: 2.3709325605026694

Epoch: 6| Step: 4
Training loss: 1.373551125540388
Validation loss: 2.3906139180763475

Epoch: 6| Step: 5
Training loss: 2.3883225067738034
Validation loss: 2.3889222488147195

Epoch: 6| Step: 6
Training loss: 2.093397423963783
Validation loss: 2.4050881988106507

Epoch: 6| Step: 7
Training loss: 1.5385009980643243
Validation loss: 2.3084376560530306

Epoch: 6| Step: 8
Training loss: 2.078186722606059
Validation loss: 2.333477762545609

Epoch: 6| Step: 9
Training loss: 1.5604381690519507
Validation loss: 2.3428869790100437

Epoch: 6| Step: 10
Training loss: 1.0821265443780064
Validation loss: 2.352082729387661

Epoch: 6| Step: 11
Training loss: 1.0275781168328992
Validation loss: 2.3591367528874816

Epoch: 6| Step: 12
Training loss: 1.2122231826191785
Validation loss: 2.3622558742266606

Epoch: 6| Step: 13
Training loss: 1.4075695628428593
Validation loss: 2.3075194848548852

Epoch: 338| Step: 0
Training loss: 2.1063540831977208
Validation loss: 2.3126316271444947

Epoch: 6| Step: 1
Training loss: 1.3943382578428525
Validation loss: 2.389945881528142

Epoch: 6| Step: 2
Training loss: 1.7264962852519816
Validation loss: 2.3468838588984946

Epoch: 6| Step: 3
Training loss: 1.169336698017985
Validation loss: 2.3287555957967583

Epoch: 6| Step: 4
Training loss: 1.7439150605646927
Validation loss: 2.3576162425176186

Epoch: 6| Step: 5
Training loss: 1.886951124204201
Validation loss: 2.317226972065294

Epoch: 6| Step: 6
Training loss: 2.186084289203125
Validation loss: 2.317065065735741

Epoch: 6| Step: 7
Training loss: 1.6364085920978746
Validation loss: 2.2871119486047657

Epoch: 6| Step: 8
Training loss: 1.38884994717153
Validation loss: 2.3239759291289603

Epoch: 6| Step: 9
Training loss: 1.3917201155641596
Validation loss: 2.3261174103918068

Epoch: 6| Step: 10
Training loss: 1.1352611516905886
Validation loss: 2.3608744875692893

Epoch: 6| Step: 11
Training loss: 2.2575425775342275
Validation loss: 2.308948021666113

Epoch: 6| Step: 12
Training loss: 1.1918786284977092
Validation loss: 2.3184776018562965

Epoch: 6| Step: 13
Training loss: 1.3967197886692602
Validation loss: 2.2851121243140593

Epoch: 339| Step: 0
Training loss: 1.332718926171433
Validation loss: 2.332670623817064

Epoch: 6| Step: 1
Training loss: 1.5445286073020512
Validation loss: 2.3455454118008627

Epoch: 6| Step: 2
Training loss: 1.1847318207407977
Validation loss: 2.3296106771794576

Epoch: 6| Step: 3
Training loss: 1.4404470668972738
Validation loss: 2.3680464325659156

Epoch: 6| Step: 4
Training loss: 1.5229335636118257
Validation loss: 2.363754993273213

Epoch: 6| Step: 5
Training loss: 1.6207030043713426
Validation loss: 2.327488223783027

Epoch: 6| Step: 6
Training loss: 2.03669970188518
Validation loss: 2.3637042200069422

Epoch: 6| Step: 7
Training loss: 1.6699899046130187
Validation loss: 2.3199877839921346

Epoch: 6| Step: 8
Training loss: 1.5771074697175265
Validation loss: 2.334223458443807

Epoch: 6| Step: 9
Training loss: 1.328935622620074
Validation loss: 2.3405397958875787

Epoch: 6| Step: 10
Training loss: 1.6137718212209546
Validation loss: 2.307435371621673

Epoch: 6| Step: 11
Training loss: 2.78918337092561
Validation loss: 2.3782348353469422

Epoch: 6| Step: 12
Training loss: 1.3954430599152285
Validation loss: 2.3602156521077458

Epoch: 6| Step: 13
Training loss: 1.0778976421842508
Validation loss: 2.2881761482814365

Epoch: 340| Step: 0
Training loss: 1.4723534715475841
Validation loss: 2.361291734983709

Epoch: 6| Step: 1
Training loss: 1.8691344385632667
Validation loss: 2.350000274298623

Epoch: 6| Step: 2
Training loss: 1.190775619952031
Validation loss: 2.358217708139351

Epoch: 6| Step: 3
Training loss: 1.78588518414838
Validation loss: 2.348342378918368

Epoch: 6| Step: 4
Training loss: 1.3034371420714153
Validation loss: 2.3633618911819765

Epoch: 6| Step: 5
Training loss: 2.0546588388046745
Validation loss: 2.3687259766470916

Epoch: 6| Step: 6
Training loss: 2.1563635533604892
Validation loss: 2.335007450051208

Epoch: 6| Step: 7
Training loss: 1.8406771900180605
Validation loss: 2.357263943669469

Epoch: 6| Step: 8
Training loss: 1.3292728176400568
Validation loss: 2.308521749979968

Epoch: 6| Step: 9
Training loss: 1.6729250311098058
Validation loss: 2.2946688931641392

Epoch: 6| Step: 10
Training loss: 1.9083727914431723
Validation loss: 2.3547605708620143

Epoch: 6| Step: 11
Training loss: 1.35751838615429
Validation loss: 2.340148996809226

Epoch: 6| Step: 12
Training loss: 1.3277387169466461
Validation loss: 2.353061047963894

Epoch: 6| Step: 13
Training loss: 1.5512669953207554
Validation loss: 2.394671613148542

Epoch: 341| Step: 0
Training loss: 1.6306250855053623
Validation loss: 2.331916205880073

Epoch: 6| Step: 1
Training loss: 2.5660392696262777
Validation loss: 2.333002701713147

Epoch: 6| Step: 2
Training loss: 1.3084748626906575
Validation loss: 2.3479258007326074

Epoch: 6| Step: 3
Training loss: 1.666459841610887
Validation loss: 2.3714831748858276

Epoch: 6| Step: 4
Training loss: 1.4150879234792295
Validation loss: 2.3086253273126163

Epoch: 6| Step: 5
Training loss: 1.804471750285081
Validation loss: 2.306245919114024

Epoch: 6| Step: 6
Training loss: 1.9383878826929226
Validation loss: 2.3235755058562773

Epoch: 6| Step: 7
Training loss: 1.0958454223275427
Validation loss: 2.3075093136810776

Epoch: 6| Step: 8
Training loss: 1.8430467331167353
Validation loss: 2.320930471861955

Epoch: 6| Step: 9
Training loss: 1.207810875421495
Validation loss: 2.363521669532511

Epoch: 6| Step: 10
Training loss: 1.6125411213207679
Validation loss: 2.338090380347576

Epoch: 6| Step: 11
Training loss: 1.282781848239255
Validation loss: 2.385148382909671

Epoch: 6| Step: 12
Training loss: 1.3229833821372496
Validation loss: 2.3268784046308215

Epoch: 6| Step: 13
Training loss: 1.7589894741322452
Validation loss: 2.3516535827355187

Epoch: 342| Step: 0
Training loss: 1.185039078434286
Validation loss: 2.3423725852451263

Epoch: 6| Step: 1
Training loss: 1.2604219841122446
Validation loss: 2.339124807519715

Epoch: 6| Step: 2
Training loss: 2.0383724053361036
Validation loss: 2.3052931267765193

Epoch: 6| Step: 3
Training loss: 1.505768017403447
Validation loss: 2.3220144144067127

Epoch: 6| Step: 4
Training loss: 1.4215637537090537
Validation loss: 2.3497584789391412

Epoch: 6| Step: 5
Training loss: 2.0227249835179655
Validation loss: 2.343436783674979

Epoch: 6| Step: 6
Training loss: 2.057125371336418
Validation loss: 2.3020554875267503

Epoch: 6| Step: 7
Training loss: 1.7495791065334287
Validation loss: 2.2725157641550364

Epoch: 6| Step: 8
Training loss: 1.444218236784249
Validation loss: 2.3080814766889324

Epoch: 6| Step: 9
Training loss: 1.6332338510436355
Validation loss: 2.2895201591238035

Epoch: 6| Step: 10
Training loss: 1.3715400078251019
Validation loss: 2.3116919057046874

Epoch: 6| Step: 11
Training loss: 1.6011587238725595
Validation loss: 2.325580926635988

Epoch: 6| Step: 12
Training loss: 1.8505881276784533
Validation loss: 2.36481619494166

Epoch: 6| Step: 13
Training loss: 1.4070418777360982
Validation loss: 2.3515767187085834

Epoch: 343| Step: 0
Training loss: 1.4085218515945617
Validation loss: 2.353731090234499

Epoch: 6| Step: 1
Training loss: 1.9540085281880966
Validation loss: 2.3459153474464465

Epoch: 6| Step: 2
Training loss: 1.7035603098179446
Validation loss: 2.296399233895988

Epoch: 6| Step: 3
Training loss: 2.1160194018074794
Validation loss: 2.2726086144780853

Epoch: 6| Step: 4
Training loss: 2.013960750072362
Validation loss: 2.3572848870561263

Epoch: 6| Step: 5
Training loss: 1.3939282906257187
Validation loss: 2.3407117833262445

Epoch: 6| Step: 6
Training loss: 1.1636462395422336
Validation loss: 2.3490969072667114

Epoch: 6| Step: 7
Training loss: 2.258843737516515
Validation loss: 2.358460312387501

Epoch: 6| Step: 8
Training loss: 1.4958455250844458
Validation loss: 2.329981398864038

Epoch: 6| Step: 9
Training loss: 1.168167709704613
Validation loss: 2.350652166709319

Epoch: 6| Step: 10
Training loss: 1.5577834085485758
Validation loss: 2.2949500155114517

Epoch: 6| Step: 11
Training loss: 1.2940975920122784
Validation loss: 2.3093310457347496

Epoch: 6| Step: 12
Training loss: 1.1346671345657866
Validation loss: 2.317207547974418

Epoch: 6| Step: 13
Training loss: 1.590688570022598
Validation loss: 2.3888361387572803

Epoch: 344| Step: 0
Training loss: 1.7557638479689104
Validation loss: 2.2998073165680317

Epoch: 6| Step: 1
Training loss: 1.013816396888377
Validation loss: 2.3424701841581337

Epoch: 6| Step: 2
Training loss: 1.4476321190080175
Validation loss: 2.36673467260517

Epoch: 6| Step: 3
Training loss: 1.2765873994114862
Validation loss: 2.345189187142535

Epoch: 6| Step: 4
Training loss: 1.7321409666475251
Validation loss: 2.3175223172295305

Epoch: 6| Step: 5
Training loss: 1.372778745601417
Validation loss: 2.30357524937511

Epoch: 6| Step: 6
Training loss: 1.4891970562658077
Validation loss: 2.363038005360213

Epoch: 6| Step: 7
Training loss: 2.3923329753233213
Validation loss: 2.3599413022565923

Epoch: 6| Step: 8
Training loss: 1.5574732986047302
Validation loss: 2.335758260655421

Epoch: 6| Step: 9
Training loss: 1.6427385068197342
Validation loss: 2.3404764110370517

Epoch: 6| Step: 10
Training loss: 2.049912855575598
Validation loss: 2.389386323110591

Epoch: 6| Step: 11
Training loss: 1.3741357861795365
Validation loss: 2.337408094215406

Epoch: 6| Step: 12
Training loss: 1.5718732830060982
Validation loss: 2.333726756011126

Epoch: 6| Step: 13
Training loss: 1.6270728462197128
Validation loss: 2.31784761200921

Epoch: 345| Step: 0
Training loss: 1.5054603374505482
Validation loss: 2.341898818630055

Epoch: 6| Step: 1
Training loss: 1.3262512452949338
Validation loss: 2.2632457315016783

Epoch: 6| Step: 2
Training loss: 2.124344219670499
Validation loss: 2.317810182083793

Epoch: 6| Step: 3
Training loss: 1.4075879407956375
Validation loss: 2.3340116392425827

Epoch: 6| Step: 4
Training loss: 1.1085192106214363
Validation loss: 2.3845120721063995

Epoch: 6| Step: 5
Training loss: 1.6298020641696285
Validation loss: 2.3755696406393687

Epoch: 6| Step: 6
Training loss: 2.5553892145984216
Validation loss: 2.3587427550555535

Epoch: 6| Step: 7
Training loss: 1.8802605900851077
Validation loss: 2.31522031728671

Epoch: 6| Step: 8
Training loss: 1.55408907160546
Validation loss: 2.3091226652069623

Epoch: 6| Step: 9
Training loss: 1.4608629993067557
Validation loss: 2.2862197422037958

Epoch: 6| Step: 10
Training loss: 1.8201089507808048
Validation loss: 2.301215803521003

Epoch: 6| Step: 11
Training loss: 1.2537323067539563
Validation loss: 2.3498511606094628

Epoch: 6| Step: 12
Training loss: 1.3448873630142997
Validation loss: 2.316664679611934

Epoch: 6| Step: 13
Training loss: 1.4109164062139867
Validation loss: 2.342192337729569

Epoch: 346| Step: 0
Training loss: 1.7372874644531682
Validation loss: 2.3307038893881176

Epoch: 6| Step: 1
Training loss: 1.5378813883082807
Validation loss: 2.2946733743128482

Epoch: 6| Step: 2
Training loss: 1.619266592539423
Validation loss: 2.324677897271562

Epoch: 6| Step: 3
Training loss: 1.227602038289252
Validation loss: 2.370472104841563

Epoch: 6| Step: 4
Training loss: 2.132546991722695
Validation loss: 2.343796183907019

Epoch: 6| Step: 5
Training loss: 1.7650635763502542
Validation loss: 2.3247420288155856

Epoch: 6| Step: 6
Training loss: 1.5199786706732952
Validation loss: 2.318074199414814

Epoch: 6| Step: 7
Training loss: 1.3011022864646133
Validation loss: 2.3676895339720665

Epoch: 6| Step: 8
Training loss: 1.2920762407406912
Validation loss: 2.3388855789492156

Epoch: 6| Step: 9
Training loss: 1.4059471652005453
Validation loss: 2.3480522683471112

Epoch: 6| Step: 10
Training loss: 1.4495855725738842
Validation loss: 2.3424171852910853

Epoch: 6| Step: 11
Training loss: 1.7203626523169644
Validation loss: 2.362885509670802

Epoch: 6| Step: 12
Training loss: 2.035194323397763
Validation loss: 2.374690974304891

Epoch: 6| Step: 13
Training loss: 1.8508001118025323
Validation loss: 2.3497695964376035

Epoch: 347| Step: 0
Training loss: 1.122172936111569
Validation loss: 2.324925574898741

Epoch: 6| Step: 1
Training loss: 1.2533282792889033
Validation loss: 2.3500586885722283

Epoch: 6| Step: 2
Training loss: 2.121621531655442
Validation loss: 2.348466467559138

Epoch: 6| Step: 3
Training loss: 1.601626436771602
Validation loss: 2.2900152903328155

Epoch: 6| Step: 4
Training loss: 1.5076100109694055
Validation loss: 2.32041708893261

Epoch: 6| Step: 5
Training loss: 1.6467920561140446
Validation loss: 2.3720093632917747

Epoch: 6| Step: 6
Training loss: 2.1014864883006634
Validation loss: 2.343906850727824

Epoch: 6| Step: 7
Training loss: 1.669646515926027
Validation loss: 2.330452070310963

Epoch: 6| Step: 8
Training loss: 1.8866188544133664
Validation loss: 2.3683280946371217

Epoch: 6| Step: 9
Training loss: 1.5080106140592906
Validation loss: 2.308024172634791

Epoch: 6| Step: 10
Training loss: 1.6531704757579373
Validation loss: 2.3388670482948446

Epoch: 6| Step: 11
Training loss: 1.673862025163564
Validation loss: 2.278360597726831

Epoch: 6| Step: 12
Training loss: 1.311975192550732
Validation loss: 2.3259162007739427

Epoch: 6| Step: 13
Training loss: 1.3736252414468144
Validation loss: 2.355770174446367

Epoch: 348| Step: 0
Training loss: 1.3334949762988497
Validation loss: 2.3244536807365224

Epoch: 6| Step: 1
Training loss: 1.0434682842784946
Validation loss: 2.3353685133351654

Epoch: 6| Step: 2
Training loss: 1.5593800485410745
Validation loss: 2.3283294237816787

Epoch: 6| Step: 3
Training loss: 1.300498679688754
Validation loss: 2.322555940720557

Epoch: 6| Step: 4
Training loss: 1.406868184165086
Validation loss: 2.346296920880188

Epoch: 6| Step: 5
Training loss: 1.6052101093986268
Validation loss: 2.346784449357125

Epoch: 6| Step: 6
Training loss: 2.401704929672641
Validation loss: 2.300182936973989

Epoch: 6| Step: 7
Training loss: 1.3498168874108405
Validation loss: 2.3334680494922453

Epoch: 6| Step: 8
Training loss: 1.757026191320808
Validation loss: 2.355332066422327

Epoch: 6| Step: 9
Training loss: 1.435595037988828
Validation loss: 2.35915428758593

Epoch: 6| Step: 10
Training loss: 1.2520425321222286
Validation loss: 2.3911348094606506

Epoch: 6| Step: 11
Training loss: 1.1099870632036353
Validation loss: 2.3406633359888787

Epoch: 6| Step: 12
Training loss: 2.2124637148193167
Validation loss: 2.274831387603252

Epoch: 6| Step: 13
Training loss: 1.7790934575166684
Validation loss: 2.3228251378804265

Epoch: 349| Step: 0
Training loss: 2.3526309808150683
Validation loss: 2.3137755502594737

Epoch: 6| Step: 1
Training loss: 1.4399720373352725
Validation loss: 2.3424421679940326

Epoch: 6| Step: 2
Training loss: 1.3941674706334548
Validation loss: 2.3364230156324926

Epoch: 6| Step: 3
Training loss: 1.541592836760075
Validation loss: 2.36584540310427

Epoch: 6| Step: 4
Training loss: 1.2442656593433405
Validation loss: 2.2742351292398935

Epoch: 6| Step: 5
Training loss: 1.4386243983774687
Validation loss: 2.3251004120077083

Epoch: 6| Step: 6
Training loss: 1.7119022244937958
Validation loss: 2.32440679486949

Epoch: 6| Step: 7
Training loss: 1.3074588238156912
Validation loss: 2.3691496886295127

Epoch: 6| Step: 8
Training loss: 1.3458240825622525
Validation loss: 2.2936465089107254

Epoch: 6| Step: 9
Training loss: 2.325290464899984
Validation loss: 2.380057702910522

Epoch: 6| Step: 10
Training loss: 1.0623393217775225
Validation loss: 2.2563714337501413

Epoch: 6| Step: 11
Training loss: 1.4059486914072907
Validation loss: 2.309221788767191

Epoch: 6| Step: 12
Training loss: 1.877700260011958
Validation loss: 2.346282502455362

Epoch: 6| Step: 13
Training loss: 1.4326617046114654
Validation loss: 2.377839815573601

Epoch: 350| Step: 0
Training loss: 1.983262238176585
Validation loss: 2.3341732399589654

Epoch: 6| Step: 1
Training loss: 1.368824529142889
Validation loss: 2.310923852103478

Epoch: 6| Step: 2
Training loss: 1.5738446191002466
Validation loss: 2.3185984155180552

Epoch: 6| Step: 3
Training loss: 1.7318812131959553
Validation loss: 2.321154204795298

Epoch: 6| Step: 4
Training loss: 1.4271188810427329
Validation loss: 2.304235002310309

Epoch: 6| Step: 5
Training loss: 1.287400069571495
Validation loss: 2.27305181341432

Epoch: 6| Step: 6
Training loss: 1.7114853352022343
Validation loss: 2.31123583783184

Epoch: 6| Step: 7
Training loss: 1.2240745435155842
Validation loss: 2.368971938423717

Epoch: 6| Step: 8
Training loss: 1.4806838873202888
Validation loss: 2.3249132949102354

Epoch: 6| Step: 9
Training loss: 1.8488970535940659
Validation loss: 2.2924946247640383

Epoch: 6| Step: 10
Training loss: 1.6357282677812586
Validation loss: 2.358229062426135

Epoch: 6| Step: 11
Training loss: 1.5814972152757807
Validation loss: 2.342040805868785

Epoch: 6| Step: 12
Training loss: 1.4749246222422305
Validation loss: 2.3454742083599385

Epoch: 6| Step: 13
Training loss: 2.8817455932975324
Validation loss: 2.3046607442658105

Epoch: 351| Step: 0
Training loss: 1.4448589541226333
Validation loss: 2.284991060380701

Epoch: 6| Step: 1
Training loss: 1.3020277494646482
Validation loss: 2.349390561530996

Epoch: 6| Step: 2
Training loss: 1.580651027333925
Validation loss: 2.289869270525781

Epoch: 6| Step: 3
Training loss: 1.7738885515980423
Validation loss: 2.3787708676020345

Epoch: 6| Step: 4
Training loss: 1.3017462739196983
Validation loss: 2.3180820238955357

Epoch: 6| Step: 5
Training loss: 1.469814320729205
Validation loss: 2.3769190461058924

Epoch: 6| Step: 6
Training loss: 2.6790332940949315
Validation loss: 2.2930996345923735

Epoch: 6| Step: 7
Training loss: 1.7139169886817147
Validation loss: 2.3447639109849936

Epoch: 6| Step: 8
Training loss: 0.9450514566954302
Validation loss: 2.295740892702772

Epoch: 6| Step: 9
Training loss: 1.5076151506212758
Validation loss: 2.3100082222694054

Epoch: 6| Step: 10
Training loss: 1.7381616444104413
Validation loss: 2.3604766690222796

Epoch: 6| Step: 11
Training loss: 0.9757088554165787
Validation loss: 2.3159274925056574

Epoch: 6| Step: 12
Training loss: 1.5528519879788363
Validation loss: 2.3686607571523046

Epoch: 6| Step: 13
Training loss: 1.1307340825959604
Validation loss: 2.331512457775685

Epoch: 352| Step: 0
Training loss: 2.7124703330953435
Validation loss: 2.338680704352488

Epoch: 6| Step: 1
Training loss: 1.0972297355673606
Validation loss: 2.2972714152714597

Epoch: 6| Step: 2
Training loss: 1.5643382893490652
Validation loss: 2.3669610175240954

Epoch: 6| Step: 3
Training loss: 1.5412441997929418
Validation loss: 2.2771233141500415

Epoch: 6| Step: 4
Training loss: 1.5241570754016223
Validation loss: 2.330895973259104

Epoch: 6| Step: 5
Training loss: 1.7391911900315613
Validation loss: 2.387520493531801

Epoch: 6| Step: 6
Training loss: 1.2621597605842527
Validation loss: 2.3313980175854345

Epoch: 6| Step: 7
Training loss: 1.5894572470052075
Validation loss: 2.397037699533388

Epoch: 6| Step: 8
Training loss: 1.4885098339367189
Validation loss: 2.3585457847188662

Epoch: 6| Step: 9
Training loss: 1.6490838108127917
Validation loss: 2.3065981356753587

Epoch: 6| Step: 10
Training loss: 1.250211650096221
Validation loss: 2.3414690443242456

Epoch: 6| Step: 11
Training loss: 1.4020059332756059
Validation loss: 2.295410917386653

Epoch: 6| Step: 12
Training loss: 1.3646017854719406
Validation loss: 2.3231421354367248

Epoch: 6| Step: 13
Training loss: 1.7226704361173608
Validation loss: 2.3499328539542943

Epoch: 353| Step: 0
Training loss: 1.5717707453408796
Validation loss: 2.304632009286959

Epoch: 6| Step: 1
Training loss: 1.5532399248244309
Validation loss: 2.3027348804394174

Epoch: 6| Step: 2
Training loss: 1.5654357795810967
Validation loss: 2.333066887372594

Epoch: 6| Step: 3
Training loss: 2.1461997845773406
Validation loss: 2.312033680795724

Epoch: 6| Step: 4
Training loss: 1.6558255785431077
Validation loss: 2.341424929874756

Epoch: 6| Step: 5
Training loss: 1.622892113019562
Validation loss: 2.345689930269553

Epoch: 6| Step: 6
Training loss: 1.1892104629510543
Validation loss: 2.2926935123424257

Epoch: 6| Step: 7
Training loss: 1.8315076262710759
Validation loss: 2.322697799711255

Epoch: 6| Step: 8
Training loss: 1.4112174566417537
Validation loss: 2.352382214107564

Epoch: 6| Step: 9
Training loss: 1.5295607143147423
Validation loss: 2.3712240079507527

Epoch: 6| Step: 10
Training loss: 1.3065924528676205
Validation loss: 2.304818517743928

Epoch: 6| Step: 11
Training loss: 2.4965961171645707
Validation loss: 2.334076064056782

Epoch: 6| Step: 12
Training loss: 1.3241382225555443
Validation loss: 2.3449988130259953

Epoch: 6| Step: 13
Training loss: 1.3753962812710971
Validation loss: 2.3143655102977085

Epoch: 354| Step: 0
Training loss: 1.4612771521689683
Validation loss: 2.367879424137136

Epoch: 6| Step: 1
Training loss: 1.9251841766632893
Validation loss: 2.282954773743119

Epoch: 6| Step: 2
Training loss: 2.2182986377932856
Validation loss: 2.4092084694700904

Epoch: 6| Step: 3
Training loss: 1.6276058430980949
Validation loss: 2.32545120213466

Epoch: 6| Step: 4
Training loss: 1.5816464556631074
Validation loss: 2.3004190385571643

Epoch: 6| Step: 5
Training loss: 1.073886778427535
Validation loss: 2.3092258336867912

Epoch: 6| Step: 6
Training loss: 1.8425153057233883
Validation loss: 2.3528444230607506

Epoch: 6| Step: 7
Training loss: 1.3003684182074282
Validation loss: 2.3737870634230696

Epoch: 6| Step: 8
Training loss: 1.7478069460429508
Validation loss: 2.262796029695416

Epoch: 6| Step: 9
Training loss: 1.338228146935274
Validation loss: 2.3651592757933866

Epoch: 6| Step: 10
Training loss: 1.476523101119535
Validation loss: 2.3011324630967023

Epoch: 6| Step: 11
Training loss: 1.8696310103597131
Validation loss: 2.338112665947838

Epoch: 6| Step: 12
Training loss: 1.2218269241123974
Validation loss: 2.3189106234964183

Epoch: 6| Step: 13
Training loss: 1.2159256119687392
Validation loss: 2.279852530818349

Epoch: 355| Step: 0
Training loss: 1.529081950669153
Validation loss: 2.3609585564551607

Epoch: 6| Step: 1
Training loss: 1.6105388395972693
Validation loss: 2.3334872069433565

Epoch: 6| Step: 2
Training loss: 1.2173952251054285
Validation loss: 2.2727999052297814

Epoch: 6| Step: 3
Training loss: 1.6895101372244499
Validation loss: 2.3383643682885804

Epoch: 6| Step: 4
Training loss: 1.2904022190778492
Validation loss: 2.3693470276890123

Epoch: 6| Step: 5
Training loss: 1.5904868884728898
Validation loss: 2.3359989865080717

Epoch: 6| Step: 6
Training loss: 1.128070191718921
Validation loss: 2.325240617982139

Epoch: 6| Step: 7
Training loss: 1.7249759617111902
Validation loss: 2.309655481813959

Epoch: 6| Step: 8
Training loss: 1.7415875141586388
Validation loss: 2.334041503009389

Epoch: 6| Step: 9
Training loss: 2.2369123870035965
Validation loss: 2.370556668239849

Epoch: 6| Step: 10
Training loss: 1.6157298129705129
Validation loss: 2.282265935187308

Epoch: 6| Step: 11
Training loss: 1.85994756522154
Validation loss: 2.3259697988194037

Epoch: 6| Step: 12
Training loss: 1.253336363967992
Validation loss: 2.3381846384883502

Epoch: 6| Step: 13
Training loss: 0.7631726596705545
Validation loss: 2.3212061578382563

Epoch: 356| Step: 0
Training loss: 1.6046263626472028
Validation loss: 2.3617873740036694

Epoch: 6| Step: 1
Training loss: 1.7483058631031052
Validation loss: 2.3202870956151065

Epoch: 6| Step: 2
Training loss: 1.3616285389418485
Validation loss: 2.325736751279028

Epoch: 6| Step: 3
Training loss: 1.4012716546542034
Validation loss: 2.3271986930063093

Epoch: 6| Step: 4
Training loss: 1.821911416581329
Validation loss: 2.3317638970956844

Epoch: 6| Step: 5
Training loss: 1.3135935904969116
Validation loss: 2.330644089138305

Epoch: 6| Step: 6
Training loss: 1.310750203626094
Validation loss: 2.355216472210903

Epoch: 6| Step: 7
Training loss: 1.2695175404908803
Validation loss: 2.2917305942094757

Epoch: 6| Step: 8
Training loss: 2.175261567271247
Validation loss: 2.2795251688277096

Epoch: 6| Step: 9
Training loss: 1.5339762493915965
Validation loss: 2.3150853352913714

Epoch: 6| Step: 10
Training loss: 1.368302027235402
Validation loss: 2.2956839799544633

Epoch: 6| Step: 11
Training loss: 2.0377567246538706
Validation loss: 2.265139068893801

Epoch: 6| Step: 12
Training loss: 1.6237778836411776
Validation loss: 2.3146993703824688

Epoch: 6| Step: 13
Training loss: 1.3582016715304452
Validation loss: 2.276152467685841

Epoch: 357| Step: 0
Training loss: 2.3043150520028113
Validation loss: 2.3056555865607673

Epoch: 6| Step: 1
Training loss: 1.391810180018038
Validation loss: 2.316158084178452

Epoch: 6| Step: 2
Training loss: 1.908740371150204
Validation loss: 2.296012780204539

Epoch: 6| Step: 3
Training loss: 1.4816839620627058
Validation loss: 2.3384534233263183

Epoch: 6| Step: 4
Training loss: 1.1789094493865528
Validation loss: 2.387883870497142

Epoch: 6| Step: 5
Training loss: 1.2275533379427988
Validation loss: 2.3749822196014234

Epoch: 6| Step: 6
Training loss: 2.110722429344174
Validation loss: 2.3573486442898104

Epoch: 6| Step: 7
Training loss: 1.282605361477335
Validation loss: 2.383023756410277

Epoch: 6| Step: 8
Training loss: 1.8675823352848444
Validation loss: 2.4227962270086487

Epoch: 6| Step: 9
Training loss: 1.1781201592707664
Validation loss: 2.3328070199883095

Epoch: 6| Step: 10
Training loss: 1.3021258944866942
Validation loss: 2.3275432268582037

Epoch: 6| Step: 11
Training loss: 1.586813848999224
Validation loss: 2.313823680299193

Epoch: 6| Step: 12
Training loss: 1.718211974117422
Validation loss: 2.370751633923191

Epoch: 6| Step: 13
Training loss: 1.6631513079856548
Validation loss: 2.3968178064430194

Epoch: 358| Step: 0
Training loss: 1.5486521675054052
Validation loss: 2.3541469019580044

Epoch: 6| Step: 1
Training loss: 1.3863585528154023
Validation loss: 2.314014030090118

Epoch: 6| Step: 2
Training loss: 2.3467971321526666
Validation loss: 2.2736415920136706

Epoch: 6| Step: 3
Training loss: 1.5235986868854932
Validation loss: 2.2867945321293983

Epoch: 6| Step: 4
Training loss: 1.4229944035680744
Validation loss: 2.327123397470663

Epoch: 6| Step: 5
Training loss: 1.4883205779078315
Validation loss: 2.3621410109062126

Epoch: 6| Step: 6
Training loss: 1.3513018406355424
Validation loss: 2.305284455417021

Epoch: 6| Step: 7
Training loss: 0.9917628062685679
Validation loss: 2.3887847143123824

Epoch: 6| Step: 8
Training loss: 1.7280583870657484
Validation loss: 2.316509496929248

Epoch: 6| Step: 9
Training loss: 1.2347706028018237
Validation loss: 2.345619217850921

Epoch: 6| Step: 10
Training loss: 1.8704427649850612
Validation loss: 2.3587571190515444

Epoch: 6| Step: 11
Training loss: 0.9704329116485808
Validation loss: 2.3478538849459656

Epoch: 6| Step: 12
Training loss: 1.6324513597237786
Validation loss: 2.340017903037448

Epoch: 6| Step: 13
Training loss: 1.8726625495712383
Validation loss: 2.3401855151223363

Epoch: 359| Step: 0
Training loss: 2.475006192132159
Validation loss: 2.376337595477762

Epoch: 6| Step: 1
Training loss: 1.1043900257895376
Validation loss: 2.341397808891501

Epoch: 6| Step: 2
Training loss: 1.300624803637481
Validation loss: 2.312994765189767

Epoch: 6| Step: 3
Training loss: 1.0762142996898023
Validation loss: 2.3646364764870165

Epoch: 6| Step: 4
Training loss: 1.266355703899512
Validation loss: 2.372719987739132

Epoch: 6| Step: 5
Training loss: 1.19383447557908
Validation loss: 2.353606393063091

Epoch: 6| Step: 6
Training loss: 1.7327552999234606
Validation loss: 2.3937544827229305

Epoch: 6| Step: 7
Training loss: 1.7686253264468201
Validation loss: 2.3437927307827655

Epoch: 6| Step: 8
Training loss: 1.5601254539907812
Validation loss: 2.314817565993813

Epoch: 6| Step: 9
Training loss: 1.9979737269341875
Validation loss: 2.277306347802999

Epoch: 6| Step: 10
Training loss: 0.9836058563626636
Validation loss: 2.297811063376089

Epoch: 6| Step: 11
Training loss: 2.0856526498216352
Validation loss: 2.3206793382311917

Epoch: 6| Step: 12
Training loss: 1.4701547600901488
Validation loss: 2.285451663274454

Epoch: 6| Step: 13
Training loss: 1.3113044561636937
Validation loss: 2.331599772295611

Epoch: 360| Step: 0
Training loss: 1.4753245659326495
Validation loss: 2.355891167176273

Epoch: 6| Step: 1
Training loss: 1.7617773481887729
Validation loss: 2.303916639553002

Epoch: 6| Step: 2
Training loss: 1.1661111099277897
Validation loss: 2.3054017920759535

Epoch: 6| Step: 3
Training loss: 1.383547485198404
Validation loss: 2.3365762158156995

Epoch: 6| Step: 4
Training loss: 1.31406509090717
Validation loss: 2.3845561893166014

Epoch: 6| Step: 5
Training loss: 2.090989755876314
Validation loss: 2.3038105615290756

Epoch: 6| Step: 6
Training loss: 1.8683362164618338
Validation loss: 2.306346358460475

Epoch: 6| Step: 7
Training loss: 0.958365899375773
Validation loss: 2.361545800890133

Epoch: 6| Step: 8
Training loss: 1.1497110584330748
Validation loss: 2.315059200261601

Epoch: 6| Step: 9
Training loss: 1.765255509596318
Validation loss: 2.3191071618918415

Epoch: 6| Step: 10
Training loss: 1.3581107388207143
Validation loss: 2.336931264801741

Epoch: 6| Step: 11
Training loss: 1.7715917720855971
Validation loss: 2.3522290739199976

Epoch: 6| Step: 12
Training loss: 1.7912260075497677
Validation loss: 2.2963101935204113

Epoch: 6| Step: 13
Training loss: 1.0669239171081792
Validation loss: 2.2935248402878585

Epoch: 361| Step: 0
Training loss: 1.0994296697802137
Validation loss: 2.314867858848664

Epoch: 6| Step: 1
Training loss: 1.5850696162149096
Validation loss: 2.3165375810420628

Epoch: 6| Step: 2
Training loss: 1.177769902390915
Validation loss: 2.3222001085813107

Epoch: 6| Step: 3
Training loss: 1.353414380358973
Validation loss: 2.2889383364892084

Epoch: 6| Step: 4
Training loss: 1.6429876844300948
Validation loss: 2.318631577000261

Epoch: 6| Step: 5
Training loss: 1.727823547780564
Validation loss: 2.3665411179116913

Epoch: 6| Step: 6
Training loss: 1.5437323503605023
Validation loss: 2.3377117975056083

Epoch: 6| Step: 7
Training loss: 1.6931065565353047
Validation loss: 2.332909989150891

Epoch: 6| Step: 8
Training loss: 1.5914399103678931
Validation loss: 2.32642404387577

Epoch: 6| Step: 9
Training loss: 2.2092609856308547
Validation loss: 2.3565351175361724

Epoch: 6| Step: 10
Training loss: 1.502718131659555
Validation loss: 2.3037426173512423

Epoch: 6| Step: 11
Training loss: 1.213402681482363
Validation loss: 2.404126612644413

Epoch: 6| Step: 12
Training loss: 1.798500983926495
Validation loss: 2.353709580977641

Epoch: 6| Step: 13
Training loss: 1.2313110375161138
Validation loss: 2.3231984055969215

Epoch: 362| Step: 0
Training loss: 1.6768806603585338
Validation loss: 2.2923464582534883

Epoch: 6| Step: 1
Training loss: 1.2575982900622442
Validation loss: 2.2821449674047627

Epoch: 6| Step: 2
Training loss: 1.44465836852266
Validation loss: 2.337367667365006

Epoch: 6| Step: 3
Training loss: 1.3106764887063036
Validation loss: 2.3745644164022077

Epoch: 6| Step: 4
Training loss: 1.6118250594994545
Validation loss: 2.2788862506002774

Epoch: 6| Step: 5
Training loss: 1.3348373434008363
Validation loss: 2.3337700992804935

Epoch: 6| Step: 6
Training loss: 1.446452747795525
Validation loss: 2.371603217888091

Epoch: 6| Step: 7
Training loss: 1.7061579585139925
Validation loss: 2.398073262347497

Epoch: 6| Step: 8
Training loss: 1.3157847490978747
Validation loss: 2.4069601299441934

Epoch: 6| Step: 9
Training loss: 1.677292362557771
Validation loss: 2.3228936661668143

Epoch: 6| Step: 10
Training loss: 2.59408741790013
Validation loss: 2.3332768267134036

Epoch: 6| Step: 11
Training loss: 1.2506516188686878
Validation loss: 2.3739528668379783

Epoch: 6| Step: 12
Training loss: 1.4914980588843425
Validation loss: 2.3480184100752575

Epoch: 6| Step: 13
Training loss: 1.4827061155723475
Validation loss: 2.3382543825930204

Epoch: 363| Step: 0
Training loss: 1.2090515216675048
Validation loss: 2.350413332091871

Epoch: 6| Step: 1
Training loss: 1.7537627639360402
Validation loss: 2.2871419360430023

Epoch: 6| Step: 2
Training loss: 1.1609117507646112
Validation loss: 2.3136610039511782

Epoch: 6| Step: 3
Training loss: 2.1068133588411904
Validation loss: 2.2989823668468476

Epoch: 6| Step: 4
Training loss: 1.6390493910622561
Validation loss: 2.305700623317511

Epoch: 6| Step: 5
Training loss: 1.4437448608835415
Validation loss: 2.349606094083242

Epoch: 6| Step: 6
Training loss: 1.007832253432564
Validation loss: 2.313026050497893

Epoch: 6| Step: 7
Training loss: 1.6866283284731711
Validation loss: 2.350923565262964

Epoch: 6| Step: 8
Training loss: 1.7060479795589363
Validation loss: 2.334594265733942

Epoch: 6| Step: 9
Training loss: 1.610841841868456
Validation loss: 2.3104288992011517

Epoch: 6| Step: 10
Training loss: 1.5647321397475467
Validation loss: 2.321973802901729

Epoch: 6| Step: 11
Training loss: 1.148643111941847
Validation loss: 2.328783579563508

Epoch: 6| Step: 12
Training loss: 1.8359701600111964
Validation loss: 2.3264954556985615

Epoch: 6| Step: 13
Training loss: 0.8361716254532527
Validation loss: 2.308361422045526

Epoch: 364| Step: 0
Training loss: 1.5440788814476314
Validation loss: 2.352697198221468

Epoch: 6| Step: 1
Training loss: 1.1065327945612156
Validation loss: 2.329362262865876

Epoch: 6| Step: 2
Training loss: 1.252111511209605
Validation loss: 2.285871921402448

Epoch: 6| Step: 3
Training loss: 1.3261796504426193
Validation loss: 2.3622468050376537

Epoch: 6| Step: 4
Training loss: 1.453264455358856
Validation loss: 2.3491641126079843

Epoch: 6| Step: 5
Training loss: 1.51923075158733
Validation loss: 2.3196171395038387

Epoch: 6| Step: 6
Training loss: 1.500475410781118
Validation loss: 2.3056970019522636

Epoch: 6| Step: 7
Training loss: 1.8538302927254924
Validation loss: 2.312891230016686

Epoch: 6| Step: 8
Training loss: 1.4904712973629983
Validation loss: 2.379333081700273

Epoch: 6| Step: 9
Training loss: 2.3589331611068034
Validation loss: 2.3151452893811513

Epoch: 6| Step: 10
Training loss: 0.9600682242310817
Validation loss: 2.335511060039877

Epoch: 6| Step: 11
Training loss: 2.2604189285290444
Validation loss: 2.35073434478538

Epoch: 6| Step: 12
Training loss: 1.4037157747846942
Validation loss: 2.338365338000445

Epoch: 6| Step: 13
Training loss: 0.778811693334839
Validation loss: 2.301594548435671

Epoch: 365| Step: 0
Training loss: 1.145711869246432
Validation loss: 2.3444971852889984

Epoch: 6| Step: 1
Training loss: 0.977704654353143
Validation loss: 2.295492764629368

Epoch: 6| Step: 2
Training loss: 1.1635200209327419
Validation loss: 2.3865501811928667

Epoch: 6| Step: 3
Training loss: 1.4735354118946113
Validation loss: 2.319827661690378

Epoch: 6| Step: 4
Training loss: 1.3777428925534574
Validation loss: 2.378514272363367

Epoch: 6| Step: 5
Training loss: 1.5548851615965642
Validation loss: 2.3449781693314518

Epoch: 6| Step: 6
Training loss: 2.106143086150801
Validation loss: 2.3083883775472906

Epoch: 6| Step: 7
Training loss: 1.5933649682584854
Validation loss: 2.341599633157277

Epoch: 6| Step: 8
Training loss: 1.452681689167353
Validation loss: 2.3097221099330123

Epoch: 6| Step: 9
Training loss: 2.0921741077772227
Validation loss: 2.337256858191244

Epoch: 6| Step: 10
Training loss: 1.6178401790945771
Validation loss: 2.3414847394560816

Epoch: 6| Step: 11
Training loss: 1.4055272258237257
Validation loss: 2.332981969451351

Epoch: 6| Step: 12
Training loss: 1.1365326404608653
Validation loss: 2.3204529234566498

Epoch: 6| Step: 13
Training loss: 1.8601560474893908
Validation loss: 2.3368910918927566

Epoch: 366| Step: 0
Training loss: 1.2320034568230325
Validation loss: 2.3332303203163236

Epoch: 6| Step: 1
Training loss: 1.482680628613615
Validation loss: 2.290925340269

Epoch: 6| Step: 2
Training loss: 2.328973705053225
Validation loss: 2.2805645506119214

Epoch: 6| Step: 3
Training loss: 1.808799122299528
Validation loss: 2.3710581456212347

Epoch: 6| Step: 4
Training loss: 1.3228440252269862
Validation loss: 2.3217489923144687

Epoch: 6| Step: 5
Training loss: 1.520750992866981
Validation loss: 2.302356682768811

Epoch: 6| Step: 6
Training loss: 1.5938215052701545
Validation loss: 2.3551370847778506

Epoch: 6| Step: 7
Training loss: 1.6457846751042073
Validation loss: 2.3036322796023616

Epoch: 6| Step: 8
Training loss: 1.625186029202996
Validation loss: 2.3520247604974216

Epoch: 6| Step: 9
Training loss: 1.1332437680887495
Validation loss: 2.3165107513535776

Epoch: 6| Step: 10
Training loss: 1.3211353604504836
Validation loss: 2.334082542960552

Epoch: 6| Step: 11
Training loss: 1.1931566731169019
Validation loss: 2.3216739749754405

Epoch: 6| Step: 12
Training loss: 1.115846749714844
Validation loss: 2.314853796185197

Epoch: 6| Step: 13
Training loss: 1.830117533614678
Validation loss: 2.289460273028853

Epoch: 367| Step: 0
Training loss: 1.434220927821026
Validation loss: 2.3428482987311274

Epoch: 6| Step: 1
Training loss: 0.821945236743979
Validation loss: 2.329188905760527

Epoch: 6| Step: 2
Training loss: 2.540595428182084
Validation loss: 2.329196379217036

Epoch: 6| Step: 3
Training loss: 1.3517858949061106
Validation loss: 2.414015195538196

Epoch: 6| Step: 4
Training loss: 1.2477423306785298
Validation loss: 2.3618928225311295

Epoch: 6| Step: 5
Training loss: 2.072458673486182
Validation loss: 2.377024408998694

Epoch: 6| Step: 6
Training loss: 1.56789542398788
Validation loss: 2.3472616007874283

Epoch: 6| Step: 7
Training loss: 1.3383558814800525
Validation loss: 2.3087460424776594

Epoch: 6| Step: 8
Training loss: 1.3988787418465758
Validation loss: 2.262356467105594

Epoch: 6| Step: 9
Training loss: 1.4916371234262704
Validation loss: 2.358946395872669

Epoch: 6| Step: 10
Training loss: 1.240619461469995
Validation loss: 2.3608986038890576

Epoch: 6| Step: 11
Training loss: 1.7318320662684403
Validation loss: 2.313409670168726

Epoch: 6| Step: 12
Training loss: 1.5085241190063556
Validation loss: 2.2921700768350637

Epoch: 6| Step: 13
Training loss: 1.2804226879239395
Validation loss: 2.338029117700355

Epoch: 368| Step: 0
Training loss: 1.1952774940301458
Validation loss: 2.320292901756385

Epoch: 6| Step: 1
Training loss: 1.7078425314898686
Validation loss: 2.3229832105588684

Epoch: 6| Step: 2
Training loss: 1.094227713755588
Validation loss: 2.3208743085392394

Epoch: 6| Step: 3
Training loss: 1.618852578230626
Validation loss: 2.312283421811761

Epoch: 6| Step: 4
Training loss: 1.8674641807215677
Validation loss: 2.319750347633583

Epoch: 6| Step: 5
Training loss: 1.6254431780455851
Validation loss: 2.3598104649727323

Epoch: 6| Step: 6
Training loss: 0.9530342559141627
Validation loss: 2.3232232275080644

Epoch: 6| Step: 7
Training loss: 1.371008932853885
Validation loss: 2.3359926300726244

Epoch: 6| Step: 8
Training loss: 1.7412923386267398
Validation loss: 2.305591612951207

Epoch: 6| Step: 9
Training loss: 1.2332692082376753
Validation loss: 2.309054375502839

Epoch: 6| Step: 10
Training loss: 2.353668790399861
Validation loss: 2.3339595093640177

Epoch: 6| Step: 11
Training loss: 1.8368699972494091
Validation loss: 2.279905018529061

Epoch: 6| Step: 12
Training loss: 1.3792901733892482
Validation loss: 2.355594663275362

Epoch: 6| Step: 13
Training loss: 1.4486095865318214
Validation loss: 2.340719889455557

Epoch: 369| Step: 0
Training loss: 1.6023241418525012
Validation loss: 2.314783575724528

Epoch: 6| Step: 1
Training loss: 1.3271900700992698
Validation loss: 2.355941916218611

Epoch: 6| Step: 2
Training loss: 1.3634235122036589
Validation loss: 2.3566674692460317

Epoch: 6| Step: 3
Training loss: 2.348032992532472
Validation loss: 2.345075247119868

Epoch: 6| Step: 4
Training loss: 1.069753849112657
Validation loss: 2.3458779730338306

Epoch: 6| Step: 5
Training loss: 1.238133129803744
Validation loss: 2.3513097169658526

Epoch: 6| Step: 6
Training loss: 1.3044750474653928
Validation loss: 2.340841141806742

Epoch: 6| Step: 7
Training loss: 2.0910668332453253
Validation loss: 2.410390644406486

Epoch: 6| Step: 8
Training loss: 1.5643453001280878
Validation loss: 2.3806630392248396

Epoch: 6| Step: 9
Training loss: 1.4706325235429714
Validation loss: 2.372877566149505

Epoch: 6| Step: 10
Training loss: 1.537884333885683
Validation loss: 2.2949864811509944

Epoch: 6| Step: 11
Training loss: 1.1211387279672496
Validation loss: 2.338354456264422

Epoch: 6| Step: 12
Training loss: 1.403519076803089
Validation loss: 2.321168458463826

Epoch: 6| Step: 13
Training loss: 1.9022372174835582
Validation loss: 2.3238148317007203

Epoch: 370| Step: 0
Training loss: 1.280849859511201
Validation loss: 2.296864230312279

Epoch: 6| Step: 1
Training loss: 1.1967131442994494
Validation loss: 2.286885202464206

Epoch: 6| Step: 2
Training loss: 1.3736789599612724
Validation loss: 2.369804319726339

Epoch: 6| Step: 3
Training loss: 1.344397366744246
Validation loss: 2.3266993957074766

Epoch: 6| Step: 4
Training loss: 1.2130319018559854
Validation loss: 2.3183187132900374

Epoch: 6| Step: 5
Training loss: 1.1587027232907083
Validation loss: 2.3787616673878333

Epoch: 6| Step: 6
Training loss: 1.725000149270756
Validation loss: 2.3282322263942246

Epoch: 6| Step: 7
Training loss: 1.3924368723834477
Validation loss: 2.360405614057873

Epoch: 6| Step: 8
Training loss: 1.315812517516478
Validation loss: 2.3576316436693787

Epoch: 6| Step: 9
Training loss: 1.5192492696569815
Validation loss: 2.3480223745123543

Epoch: 6| Step: 10
Training loss: 2.3388535278176272
Validation loss: 2.4018341316269187

Epoch: 6| Step: 11
Training loss: 1.7575602032482394
Validation loss: 2.2767249615631457

Epoch: 6| Step: 12
Training loss: 1.0956227210152267
Validation loss: 2.350303126525903

Epoch: 6| Step: 13
Training loss: 2.538144740986276
Validation loss: 2.360264840213994

Epoch: 371| Step: 0
Training loss: 2.115166068625291
Validation loss: 2.278428117374211

Epoch: 6| Step: 1
Training loss: 1.0356342867318038
Validation loss: 2.3267782009731577

Epoch: 6| Step: 2
Training loss: 1.2295065372226543
Validation loss: 2.3351596644724704

Epoch: 6| Step: 3
Training loss: 1.2179178184445538
Validation loss: 2.3196606883919846

Epoch: 6| Step: 4
Training loss: 1.8127620113018534
Validation loss: 2.398203454211114

Epoch: 6| Step: 5
Training loss: 1.634632246439689
Validation loss: 2.2972326630138182

Epoch: 6| Step: 6
Training loss: 1.3595751910950307
Validation loss: 2.333733700831012

Epoch: 6| Step: 7
Training loss: 1.2567999418923979
Validation loss: 2.318756150562366

Epoch: 6| Step: 8
Training loss: 1.31119154240695
Validation loss: 2.2849784827505557

Epoch: 6| Step: 9
Training loss: 1.3439660453111908
Validation loss: 2.280391487181674

Epoch: 6| Step: 10
Training loss: 1.601343949455584
Validation loss: 2.318980178395882

Epoch: 6| Step: 11
Training loss: 1.257843064594312
Validation loss: 2.3549194021850157

Epoch: 6| Step: 12
Training loss: 1.6188055964168393
Validation loss: 2.2997493420499437

Epoch: 6| Step: 13
Training loss: 1.7106646315834346
Validation loss: 2.2650239582148814

Epoch: 372| Step: 0
Training loss: 0.8373255747313662
Validation loss: 2.2837530797460333

Epoch: 6| Step: 1
Training loss: 1.9504890048830206
Validation loss: 2.3375979618560785

Epoch: 6| Step: 2
Training loss: 1.2639156147759287
Validation loss: 2.3114708037793896

Epoch: 6| Step: 3
Training loss: 1.0670430165193825
Validation loss: 2.366457545261648

Epoch: 6| Step: 4
Training loss: 2.0710365037118565
Validation loss: 2.3227058067360757

Epoch: 6| Step: 5
Training loss: 1.1095268253076491
Validation loss: 2.3114592159261256

Epoch: 6| Step: 6
Training loss: 1.0784894907602474
Validation loss: 2.3158039684522684

Epoch: 6| Step: 7
Training loss: 2.0111714924247854
Validation loss: 2.3076987090250753

Epoch: 6| Step: 8
Training loss: 1.703496909875197
Validation loss: 2.307914214532016

Epoch: 6| Step: 9
Training loss: 1.2376454643527945
Validation loss: 2.291197282557607

Epoch: 6| Step: 10
Training loss: 1.8265713341518084
Validation loss: 2.2712981914926886

Epoch: 6| Step: 11
Training loss: 1.4510233457804875
Validation loss: 2.273386478926349

Epoch: 6| Step: 12
Training loss: 1.6212853743577043
Validation loss: 2.3326338131091644

Epoch: 6| Step: 13
Training loss: 1.680095179563702
Validation loss: 2.3169475258427825

Epoch: 373| Step: 0
Training loss: 2.1123594293718577
Validation loss: 2.3529546572325755

Epoch: 6| Step: 1
Training loss: 0.8854189180831709
Validation loss: 2.3342658748907192

Epoch: 6| Step: 2
Training loss: 1.3509157430435315
Validation loss: 2.336475151991585

Epoch: 6| Step: 3
Training loss: 1.4631748305369379
Validation loss: 2.325918399675454

Epoch: 6| Step: 4
Training loss: 1.8491631264614732
Validation loss: 2.3734611875729232

Epoch: 6| Step: 5
Training loss: 1.8039859217202252
Validation loss: 2.3814303354958555

Epoch: 6| Step: 6
Training loss: 1.5503780888295455
Validation loss: 2.348537706904601

Epoch: 6| Step: 7
Training loss: 1.3160943813655335
Validation loss: 2.3708154159839308

Epoch: 6| Step: 8
Training loss: 1.248412602526078
Validation loss: 2.347681889747094

Epoch: 6| Step: 9
Training loss: 0.9467929880109797
Validation loss: 2.3877973472183065

Epoch: 6| Step: 10
Training loss: 1.4150210340574274
Validation loss: 2.323890402117508

Epoch: 6| Step: 11
Training loss: 1.3501329745041353
Validation loss: 2.3352563638485977

Epoch: 6| Step: 12
Training loss: 1.9403495752838453
Validation loss: 2.3545972942243756

Epoch: 6| Step: 13
Training loss: 1.2936391331443124
Validation loss: 2.292164872756388

Epoch: 374| Step: 0
Training loss: 1.73065873388364
Validation loss: 2.3264052932945334

Epoch: 6| Step: 1
Training loss: 1.3815086812959128
Validation loss: 2.3412303788612463

Epoch: 6| Step: 2
Training loss: 1.091722734967334
Validation loss: 2.287409089692222

Epoch: 6| Step: 3
Training loss: 1.238367601145563
Validation loss: 2.3064837942209624

Epoch: 6| Step: 4
Training loss: 0.839332034331456
Validation loss: 2.3516407260891556

Epoch: 6| Step: 5
Training loss: 2.4127458358189573
Validation loss: 2.3228770320304486

Epoch: 6| Step: 6
Training loss: 1.350958275653983
Validation loss: 2.3162547539266414

Epoch: 6| Step: 7
Training loss: 1.3755416236855633
Validation loss: 2.3502436531638704

Epoch: 6| Step: 8
Training loss: 1.8043042721444966
Validation loss: 2.3518901195134254

Epoch: 6| Step: 9
Training loss: 1.8921224795572495
Validation loss: 2.3110436252161763

Epoch: 6| Step: 10
Training loss: 1.1725043577751726
Validation loss: 2.310261765938831

Epoch: 6| Step: 11
Training loss: 1.5766014071636218
Validation loss: 2.2936430082280497

Epoch: 6| Step: 12
Training loss: 1.3648944917361845
Validation loss: 2.3287931574863667

Epoch: 6| Step: 13
Training loss: 1.2269335143117004
Validation loss: 2.321674219008219

Epoch: 375| Step: 0
Training loss: 1.5989291243313475
Validation loss: 2.2801058455622734

Epoch: 6| Step: 1
Training loss: 0.9886734677968483
Validation loss: 2.3117540503886724

Epoch: 6| Step: 2
Training loss: 1.1395729124904996
Validation loss: 2.3493005068465544

Epoch: 6| Step: 3
Training loss: 2.6737371725993655
Validation loss: 2.304073603901632

Epoch: 6| Step: 4
Training loss: 1.576292579311741
Validation loss: 2.371239931023554

Epoch: 6| Step: 5
Training loss: 1.4759465300222983
Validation loss: 2.322901737079259

Epoch: 6| Step: 6
Training loss: 1.4018062741036195
Validation loss: 2.3578756406645605

Epoch: 6| Step: 7
Training loss: 1.2945081875668505
Validation loss: 2.364053779021361

Epoch: 6| Step: 8
Training loss: 1.4520321910431888
Validation loss: 2.329306435194679

Epoch: 6| Step: 9
Training loss: 1.4168607728409586
Validation loss: 2.3108983819476476

Epoch: 6| Step: 10
Training loss: 1.5890789019883138
Validation loss: 2.297383351562139

Epoch: 6| Step: 11
Training loss: 1.2711835701689127
Validation loss: 2.3020869362548226

Epoch: 6| Step: 12
Training loss: 1.2234265518185807
Validation loss: 2.2784602421479643

Epoch: 6| Step: 13
Training loss: 0.8691221085194024
Validation loss: 2.324515128013922

Epoch: 376| Step: 0
Training loss: 1.3214825744346013
Validation loss: 2.3376430280611626

Epoch: 6| Step: 1
Training loss: 1.1798764513283455
Validation loss: 2.3098420396996553

Epoch: 6| Step: 2
Training loss: 2.573838433056741
Validation loss: 2.3335350369877377

Epoch: 6| Step: 3
Training loss: 1.8519159937276033
Validation loss: 2.32898480729013

Epoch: 6| Step: 4
Training loss: 1.4862986096773778
Validation loss: 2.3256091900183073

Epoch: 6| Step: 5
Training loss: 0.7465334889590213
Validation loss: 2.344360114641246

Epoch: 6| Step: 6
Training loss: 1.195438552891881
Validation loss: 2.3081895597854016

Epoch: 6| Step: 7
Training loss: 1.6082042398511438
Validation loss: 2.3326610085126496

Epoch: 6| Step: 8
Training loss: 0.892624033742696
Validation loss: 2.303953596408151

Epoch: 6| Step: 9
Training loss: 1.213260760014547
Validation loss: 2.3214022511979424

Epoch: 6| Step: 10
Training loss: 1.3637898105925987
Validation loss: 2.347321833940386

Epoch: 6| Step: 11
Training loss: 1.4251058572635011
Validation loss: 2.332639093954894

Epoch: 6| Step: 12
Training loss: 1.6701734922141618
Validation loss: 2.261575058292615

Epoch: 6| Step: 13
Training loss: 0.7138323690583227
Validation loss: 2.3512916658358898

Epoch: 377| Step: 0
Training loss: 1.214101141237364
Validation loss: 2.2696356002886584

Epoch: 6| Step: 1
Training loss: 1.7608388661581849
Validation loss: 2.33365817453038

Epoch: 6| Step: 2
Training loss: 1.5046899908407636
Validation loss: 2.310121920413084

Epoch: 6| Step: 3
Training loss: 1.6079895574505816
Validation loss: 2.2994883101413723

Epoch: 6| Step: 4
Training loss: 1.808149180140179
Validation loss: 2.2881753830576366

Epoch: 6| Step: 5
Training loss: 1.3052703103920344
Validation loss: 2.3082396794087394

Epoch: 6| Step: 6
Training loss: 1.226513661183703
Validation loss: 2.271831175430578

Epoch: 6| Step: 7
Training loss: 2.0397259447727416
Validation loss: 2.3512453227739063

Epoch: 6| Step: 8
Training loss: 1.4284484163183055
Validation loss: 2.345528319674602

Epoch: 6| Step: 9
Training loss: 0.9313641983775902
Validation loss: 2.299101706094995

Epoch: 6| Step: 10
Training loss: 1.5417323313294935
Validation loss: 2.321212326146003

Epoch: 6| Step: 11
Training loss: 1.4707088799636323
Validation loss: 2.3456777169082237

Epoch: 6| Step: 12
Training loss: 1.2918912425724922
Validation loss: 2.342189571806546

Epoch: 6| Step: 13
Training loss: 1.869388320758055
Validation loss: 2.327731937103564

Epoch: 378| Step: 0
Training loss: 2.33541486628313
Validation loss: 2.26851697313914

Epoch: 6| Step: 1
Training loss: 1.228567392201621
Validation loss: 2.3336434901637646

Epoch: 6| Step: 2
Training loss: 1.2210608850743658
Validation loss: 2.3135661472556883

Epoch: 6| Step: 3
Training loss: 1.6052666232916724
Validation loss: 2.303716095465285

Epoch: 6| Step: 4
Training loss: 1.169309580046945
Validation loss: 2.330386957860326

Epoch: 6| Step: 5
Training loss: 1.1421826843911662
Validation loss: 2.3080518723821712

Epoch: 6| Step: 6
Training loss: 1.4637336288305443
Validation loss: 2.3134589173476408

Epoch: 6| Step: 7
Training loss: 1.0781540244798116
Validation loss: 2.303196131159259

Epoch: 6| Step: 8
Training loss: 1.7871616710244504
Validation loss: 2.308644864697896

Epoch: 6| Step: 9
Training loss: 1.696127770221952
Validation loss: 2.3293565321586254

Epoch: 6| Step: 10
Training loss: 1.5911221250109053
Validation loss: 2.310225181870777

Epoch: 6| Step: 11
Training loss: 1.3161114552210564
Validation loss: 2.3085799439514023

Epoch: 6| Step: 12
Training loss: 1.4819537040439439
Validation loss: 2.299259555524197

Epoch: 6| Step: 13
Training loss: 0.9828098206112095
Validation loss: 2.3201750845166527

Epoch: 379| Step: 0
Training loss: 1.6679480236472068
Validation loss: 2.3506762537596213

Epoch: 6| Step: 1
Training loss: 1.4229897122416697
Validation loss: 2.3494831104094387

Epoch: 6| Step: 2
Training loss: 1.9756541219156096
Validation loss: 2.3304639454447638

Epoch: 6| Step: 3
Training loss: 1.26082175289634
Validation loss: 2.30832261329982

Epoch: 6| Step: 4
Training loss: 1.363816557885041
Validation loss: 2.2992963045889456

Epoch: 6| Step: 5
Training loss: 1.3779339266467836
Validation loss: 2.3481325211711668

Epoch: 6| Step: 6
Training loss: 1.5149112869324695
Validation loss: 2.2916885494257606

Epoch: 6| Step: 7
Training loss: 1.6167200859656399
Validation loss: 2.275891039664225

Epoch: 6| Step: 8
Training loss: 1.3644219902498702
Validation loss: 2.320074989689635

Epoch: 6| Step: 9
Training loss: 2.1645056756205796
Validation loss: 2.3320880553934837

Epoch: 6| Step: 10
Training loss: 1.7095338123477706
Validation loss: 2.2989759487661843

Epoch: 6| Step: 11
Training loss: 1.180477660856817
Validation loss: 2.3205309885455963

Epoch: 6| Step: 12
Training loss: 1.508314454327593
Validation loss: 2.310667924694826

Epoch: 6| Step: 13
Training loss: 0.9334282508905261
Validation loss: 2.3306547236325352

Epoch: 380| Step: 0
Training loss: 1.436796928631021
Validation loss: 2.360714337836806

Epoch: 6| Step: 1
Training loss: 1.5118731437126076
Validation loss: 2.3924541002766433

Epoch: 6| Step: 2
Training loss: 1.5899299766908068
Validation loss: 2.349802522035419

Epoch: 6| Step: 3
Training loss: 2.268621738475843
Validation loss: 2.3864165516347264

Epoch: 6| Step: 4
Training loss: 1.1366327521969
Validation loss: 2.368276724453353

Epoch: 6| Step: 5
Training loss: 1.2883676216592992
Validation loss: 2.352836272897919

Epoch: 6| Step: 6
Training loss: 1.6297913120520842
Validation loss: 2.4100771437099726

Epoch: 6| Step: 7
Training loss: 1.1547994019998682
Validation loss: 2.4091109543642903

Epoch: 6| Step: 8
Training loss: 1.3088875511922156
Validation loss: 2.4062123204469237

Epoch: 6| Step: 9
Training loss: 1.7065859984292588
Validation loss: 2.3322239852127855

Epoch: 6| Step: 10
Training loss: 1.1673970433976582
Validation loss: 2.3708405164254454

Epoch: 6| Step: 11
Training loss: 1.4385553715205202
Validation loss: 2.325932469840406

Epoch: 6| Step: 12
Training loss: 1.5049085571542604
Validation loss: 2.4006141458335337

Epoch: 6| Step: 13
Training loss: 1.2729745503119385
Validation loss: 2.334340209719261

Epoch: 381| Step: 0
Training loss: 1.4792455285052937
Validation loss: 2.3639352114503254

Epoch: 6| Step: 1
Training loss: 2.4312027012163866
Validation loss: 2.3294233869647107

Epoch: 6| Step: 2
Training loss: 1.0767162905221965
Validation loss: 2.3293102391491853

Epoch: 6| Step: 3
Training loss: 1.210319312027471
Validation loss: 2.3552732474098765

Epoch: 6| Step: 4
Training loss: 1.7321394525643374
Validation loss: 2.306984368027846

Epoch: 6| Step: 5
Training loss: 1.73220613979198
Validation loss: 2.375801321487118

Epoch: 6| Step: 6
Training loss: 1.6018932466215647
Validation loss: 2.3093584289671156

Epoch: 6| Step: 7
Training loss: 1.2234825778807337
Validation loss: 2.2942042820497006

Epoch: 6| Step: 8
Training loss: 1.2979211379576807
Validation loss: 2.3303852175137343

Epoch: 6| Step: 9
Training loss: 1.7026691351633443
Validation loss: 2.271428076524718

Epoch: 6| Step: 10
Training loss: 1.6420546342725735
Validation loss: 2.3040108848713303

Epoch: 6| Step: 11
Training loss: 0.7844123542675481
Validation loss: 2.30218398472203

Epoch: 6| Step: 12
Training loss: 1.376985676698566
Validation loss: 2.2733313259383774

Epoch: 6| Step: 13
Training loss: 1.2467587409637664
Validation loss: 2.260483315236967

Epoch: 382| Step: 0
Training loss: 1.1856375192997757
Validation loss: 2.284432771550185

Epoch: 6| Step: 1
Training loss: 1.6481338148926508
Validation loss: 2.334628516622704

Epoch: 6| Step: 2
Training loss: 1.2606741534491066
Validation loss: 2.2960885616921143

Epoch: 6| Step: 3
Training loss: 1.3583358212703707
Validation loss: 2.3633797405631967

Epoch: 6| Step: 4
Training loss: 1.8946786724818003
Validation loss: 2.335359485457459

Epoch: 6| Step: 5
Training loss: 1.377711050962595
Validation loss: 2.3116730835914097

Epoch: 6| Step: 6
Training loss: 1.5402738190257905
Validation loss: 2.343535461451113

Epoch: 6| Step: 7
Training loss: 1.059835458796454
Validation loss: 2.335929872513603

Epoch: 6| Step: 8
Training loss: 1.1453227668499795
Validation loss: 2.31679749758655

Epoch: 6| Step: 9
Training loss: 2.320964272148085
Validation loss: 2.344845888164871

Epoch: 6| Step: 10
Training loss: 1.4763793831765761
Validation loss: 2.2855699031395447

Epoch: 6| Step: 11
Training loss: 1.5461940615256602
Validation loss: 2.3676981862951827

Epoch: 6| Step: 12
Training loss: 1.1643744441147286
Validation loss: 2.383471425045356

Epoch: 6| Step: 13
Training loss: 0.9438277635683375
Validation loss: 2.277115151909638

Epoch: 383| Step: 0
Training loss: 1.6596290379554335
Validation loss: 2.320067900115582

Epoch: 6| Step: 1
Training loss: 1.3795922061761954
Validation loss: 2.3059132409683882

Epoch: 6| Step: 2
Training loss: 1.6444639794732983
Validation loss: 2.3425721849424708

Epoch: 6| Step: 3
Training loss: 1.4737538262108079
Validation loss: 2.347817668259328

Epoch: 6| Step: 4
Training loss: 0.9790764760354032
Validation loss: 2.306439908724592

Epoch: 6| Step: 5
Training loss: 1.0987271552374542
Validation loss: 2.295519211213428

Epoch: 6| Step: 6
Training loss: 1.2033010576909102
Validation loss: 2.3454379920910395

Epoch: 6| Step: 7
Training loss: 1.2662575165505732
Validation loss: 2.339325127616429

Epoch: 6| Step: 8
Training loss: 1.4365114876712353
Validation loss: 2.3197674158505026

Epoch: 6| Step: 9
Training loss: 1.4174488470142326
Validation loss: 2.348415199458657

Epoch: 6| Step: 10
Training loss: 2.5618664958633097
Validation loss: 2.35490114684413

Epoch: 6| Step: 11
Training loss: 1.2867493190967396
Validation loss: 2.3011075661079583

Epoch: 6| Step: 12
Training loss: 1.009147764911453
Validation loss: 2.3497970091928693

Epoch: 6| Step: 13
Training loss: 1.0591801782121881
Validation loss: 2.3049900174104385

Epoch: 384| Step: 0
Training loss: 1.1158284811171275
Validation loss: 2.3656177878102245

Epoch: 6| Step: 1
Training loss: 1.4717838526403333
Validation loss: 2.3329679742188567

Epoch: 6| Step: 2
Training loss: 1.4205279834143387
Validation loss: 2.3028113908867325

Epoch: 6| Step: 3
Training loss: 1.2660228904414423
Validation loss: 2.323428856040073

Epoch: 6| Step: 4
Training loss: 2.2922855119611887
Validation loss: 2.3187631529344976

Epoch: 6| Step: 5
Training loss: 1.5001175357546126
Validation loss: 2.3388242834211916

Epoch: 6| Step: 6
Training loss: 1.4485852278317906
Validation loss: 2.3884086074418205

Epoch: 6| Step: 7
Training loss: 1.7232289994837788
Validation loss: 2.314264762084057

Epoch: 6| Step: 8
Training loss: 1.1383212091033903
Validation loss: 2.273976202293539

Epoch: 6| Step: 9
Training loss: 1.592717303626491
Validation loss: 2.359625494935433

Epoch: 6| Step: 10
Training loss: 1.2736863905247953
Validation loss: 2.3106652624952155

Epoch: 6| Step: 11
Training loss: 1.4457586476204074
Validation loss: 2.2974032967196907

Epoch: 6| Step: 12
Training loss: 1.8620428612402957
Validation loss: 2.301622054899498

Epoch: 6| Step: 13
Training loss: 0.712127235008671
Validation loss: 2.2997687129417588

Epoch: 385| Step: 0
Training loss: 0.9051407569680097
Validation loss: 2.238283186805055

Epoch: 6| Step: 1
Training loss: 1.183661783107508
Validation loss: 2.2618794859554043

Epoch: 6| Step: 2
Training loss: 1.2934632061774558
Validation loss: 2.3026821137467537

Epoch: 6| Step: 3
Training loss: 1.7619077999746673
Validation loss: 2.2898745117288724

Epoch: 6| Step: 4
Training loss: 1.42225197625991
Validation loss: 2.364785415653713

Epoch: 6| Step: 5
Training loss: 1.2820590186496974
Validation loss: 2.366333817741357

Epoch: 6| Step: 6
Training loss: 1.5452284092872115
Validation loss: 2.337662296606354

Epoch: 6| Step: 7
Training loss: 1.5985386284154208
Validation loss: 2.294590324167561

Epoch: 6| Step: 8
Training loss: 1.7294293935567226
Validation loss: 2.3836698703322083

Epoch: 6| Step: 9
Training loss: 1.2015269181200399
Validation loss: 2.3875941689153843

Epoch: 6| Step: 10
Training loss: 1.0815370167725615
Validation loss: 2.291791566445054

Epoch: 6| Step: 11
Training loss: 2.165260506654113
Validation loss: 2.312317551386166

Epoch: 6| Step: 12
Training loss: 1.2524681995641624
Validation loss: 2.346962905608826

Epoch: 6| Step: 13
Training loss: 1.5181527050343857
Validation loss: 2.3212279969977296

Epoch: 386| Step: 0
Training loss: 2.2216707803736284
Validation loss: 2.265809545189758

Epoch: 6| Step: 1
Training loss: 1.5237600131875448
Validation loss: 2.34618478622801

Epoch: 6| Step: 2
Training loss: 1.8627600750699969
Validation loss: 2.344453544438983

Epoch: 6| Step: 3
Training loss: 1.0784740712175296
Validation loss: 2.3776850224613097

Epoch: 6| Step: 4
Training loss: 1.0441028843604843
Validation loss: 2.3511866893796043

Epoch: 6| Step: 5
Training loss: 1.5046396028019695
Validation loss: 2.311908146206041

Epoch: 6| Step: 6
Training loss: 1.3488276601216664
Validation loss: 2.28449629291919

Epoch: 6| Step: 7
Training loss: 1.5466345397857255
Validation loss: 2.3140637144722422

Epoch: 6| Step: 8
Training loss: 1.8058227667376896
Validation loss: 2.2847048560181933

Epoch: 6| Step: 9
Training loss: 1.365411356749855
Validation loss: 2.3261091555623876

Epoch: 6| Step: 10
Training loss: 0.645177205383597
Validation loss: 2.330562217417497

Epoch: 6| Step: 11
Training loss: 1.5076936665091687
Validation loss: 2.2912243913178814

Epoch: 6| Step: 12
Training loss: 0.937667990574296
Validation loss: 2.3604814227416915

Epoch: 6| Step: 13
Training loss: 1.650749790453345
Validation loss: 2.294097817510546

Epoch: 387| Step: 0
Training loss: 1.2537534626602018
Validation loss: 2.3062589371146194

Epoch: 6| Step: 1
Training loss: 1.2230074929470243
Validation loss: 2.312612268659872

Epoch: 6| Step: 2
Training loss: 1.4879806895900138
Validation loss: 2.3957050269512323

Epoch: 6| Step: 3
Training loss: 1.8402674484762769
Validation loss: 2.363675565069675

Epoch: 6| Step: 4
Training loss: 1.2543690620589731
Validation loss: 2.3111511039008144

Epoch: 6| Step: 5
Training loss: 1.186542124659942
Validation loss: 2.299852583776835

Epoch: 6| Step: 6
Training loss: 1.2655051374779531
Validation loss: 2.3118007548373285

Epoch: 6| Step: 7
Training loss: 1.7168310376827078
Validation loss: 2.3120611451178417

Epoch: 6| Step: 8
Training loss: 2.241839870393531
Validation loss: 2.3094614348366767

Epoch: 6| Step: 9
Training loss: 0.6742175096697134
Validation loss: 2.356494791991425

Epoch: 6| Step: 10
Training loss: 1.5068027099585006
Validation loss: 2.292765786908153

Epoch: 6| Step: 11
Training loss: 1.211974555141898
Validation loss: 2.311065906508063

Epoch: 6| Step: 12
Training loss: 1.3887030789803554
Validation loss: 2.270132703154342

Epoch: 6| Step: 13
Training loss: 0.9505803581655629
Validation loss: 2.266878683448991

Epoch: 388| Step: 0
Training loss: 2.449476115988448
Validation loss: 2.358820018107642

Epoch: 6| Step: 1
Training loss: 1.4887003471236249
Validation loss: 2.326022155152911

Epoch: 6| Step: 2
Training loss: 1.9320831871841613
Validation loss: 2.2862570201669765

Epoch: 6| Step: 3
Training loss: 0.8969551130395207
Validation loss: 2.342830417397356

Epoch: 6| Step: 4
Training loss: 1.419014873230446
Validation loss: 2.3179960239372086

Epoch: 6| Step: 5
Training loss: 1.0671898055714937
Validation loss: 2.326964205765044

Epoch: 6| Step: 6
Training loss: 1.2226429898941493
Validation loss: 2.2816596040633104

Epoch: 6| Step: 7
Training loss: 1.294717395684993
Validation loss: 2.3479539845775648

Epoch: 6| Step: 8
Training loss: 1.3007411549663543
Validation loss: 2.302292888634126

Epoch: 6| Step: 9
Training loss: 1.0392639423799674
Validation loss: 2.30258826050439

Epoch: 6| Step: 10
Training loss: 1.779208837481375
Validation loss: 2.2968452612970722

Epoch: 6| Step: 11
Training loss: 0.778643035033098
Validation loss: 2.2869653168905617

Epoch: 6| Step: 12
Training loss: 1.485577467694419
Validation loss: 2.253052297830133

Epoch: 6| Step: 13
Training loss: 1.701162064498836
Validation loss: 2.343237644648634

Epoch: 389| Step: 0
Training loss: 1.3254186544650266
Validation loss: 2.336804675014033

Epoch: 6| Step: 1
Training loss: 1.1917562002057132
Validation loss: 2.3355432443050796

Epoch: 6| Step: 2
Training loss: 1.7294473841511107
Validation loss: 2.341064105301848

Epoch: 6| Step: 3
Training loss: 1.6989284223507595
Validation loss: 2.3123780506353606

Epoch: 6| Step: 4
Training loss: 1.568317265497504
Validation loss: 2.3354109144738695

Epoch: 6| Step: 5
Training loss: 0.9684316665852856
Validation loss: 2.3285597748781286

Epoch: 6| Step: 6
Training loss: 0.9295100836204323
Validation loss: 2.345555020192392

Epoch: 6| Step: 7
Training loss: 1.4999787011223862
Validation loss: 2.3205994884674976

Epoch: 6| Step: 8
Training loss: 1.2464360451601106
Validation loss: 2.330254114634322

Epoch: 6| Step: 9
Training loss: 1.4396054977867419
Validation loss: 2.288681606157663

Epoch: 6| Step: 10
Training loss: 1.2125846243360285
Validation loss: 2.356978526822049

Epoch: 6| Step: 11
Training loss: 2.11997290234072
Validation loss: 2.338542437700017

Epoch: 6| Step: 12
Training loss: 1.5963058920733568
Validation loss: 2.310942579645707

Epoch: 6| Step: 13
Training loss: 1.351280844563105
Validation loss: 2.3193986842460257

Epoch: 390| Step: 0
Training loss: 1.2863174340724495
Validation loss: 2.2559201939817046

Epoch: 6| Step: 1
Training loss: 1.3133703706492192
Validation loss: 2.2862802298262066

Epoch: 6| Step: 2
Training loss: 2.4833539868035714
Validation loss: 2.273563115555088

Epoch: 6| Step: 3
Training loss: 1.2855723904465635
Validation loss: 2.294842673990085

Epoch: 6| Step: 4
Training loss: 1.504231365781387
Validation loss: 2.291251927170401

Epoch: 6| Step: 5
Training loss: 1.5194920238148708
Validation loss: 2.3283543363314703

Epoch: 6| Step: 6
Training loss: 1.1387888094237983
Validation loss: 2.2869998573629498

Epoch: 6| Step: 7
Training loss: 1.0868050382624415
Validation loss: 2.300086803858085

Epoch: 6| Step: 8
Training loss: 1.3428334503634616
Validation loss: 2.267301999754763

Epoch: 6| Step: 9
Training loss: 1.144054847489547
Validation loss: 2.294165125424098

Epoch: 6| Step: 10
Training loss: 1.123725434014613
Validation loss: 2.318482845284198

Epoch: 6| Step: 11
Training loss: 1.4135923921408424
Validation loss: 2.3616743720861004

Epoch: 6| Step: 12
Training loss: 1.3061830092778715
Validation loss: 2.35301807529254

Epoch: 6| Step: 13
Training loss: 2.229127711255768
Validation loss: 2.2935247642792786

Epoch: 391| Step: 0
Training loss: 1.2972065145688327
Validation loss: 2.2639309347003524

Epoch: 6| Step: 1
Training loss: 1.246466075795172
Validation loss: 2.3269985601464422

Epoch: 6| Step: 2
Training loss: 1.1788245575384615
Validation loss: 2.2834254781422216

Epoch: 6| Step: 3
Training loss: 1.4686454573416
Validation loss: 2.2421134235324818

Epoch: 6| Step: 4
Training loss: 1.4516671363721774
Validation loss: 2.3855622820256235

Epoch: 6| Step: 5
Training loss: 1.1839561788787831
Validation loss: 2.3250931177888696

Epoch: 6| Step: 6
Training loss: 1.9281266421120944
Validation loss: 2.3007697136056278

Epoch: 6| Step: 7
Training loss: 1.1032500090833535
Validation loss: 2.3714768714009153

Epoch: 6| Step: 8
Training loss: 1.625438410967112
Validation loss: 2.2985406081878192

Epoch: 6| Step: 9
Training loss: 1.5528113004234934
Validation loss: 2.313898148897088

Epoch: 6| Step: 10
Training loss: 1.8063630751752786
Validation loss: 2.327500021516297

Epoch: 6| Step: 11
Training loss: 1.1418519410392605
Validation loss: 2.3243535506742727

Epoch: 6| Step: 12
Training loss: 1.4492901478579858
Validation loss: 2.2617804088699995

Epoch: 6| Step: 13
Training loss: 1.8348174879066916
Validation loss: 2.3536339430320594

Epoch: 392| Step: 0
Training loss: 1.3686782992321243
Validation loss: 2.3343459622368448

Epoch: 6| Step: 1
Training loss: 1.3521712150677472
Validation loss: 2.296159258976485

Epoch: 6| Step: 2
Training loss: 1.690504296131198
Validation loss: 2.3820797911780027

Epoch: 6| Step: 3
Training loss: 1.270022910354501
Validation loss: 2.3415967165430063

Epoch: 6| Step: 4
Training loss: 1.6496086118797075
Validation loss: 2.338243205410111

Epoch: 6| Step: 5
Training loss: 1.019721294828588
Validation loss: 2.3197547134709717

Epoch: 6| Step: 6
Training loss: 1.7387531454358147
Validation loss: 2.3371160830997857

Epoch: 6| Step: 7
Training loss: 1.172102435612123
Validation loss: 2.3736707694949484

Epoch: 6| Step: 8
Training loss: 1.4274798582563395
Validation loss: 2.3356940501724797

Epoch: 6| Step: 9
Training loss: 1.1095529332988094
Validation loss: 2.2956816180863746

Epoch: 6| Step: 10
Training loss: 1.9808424497380412
Validation loss: 2.328033511537676

Epoch: 6| Step: 11
Training loss: 1.4034696431833351
Validation loss: 2.3393861141392702

Epoch: 6| Step: 12
Training loss: 1.0936794803228784
Validation loss: 2.3031379608846176

Epoch: 6| Step: 13
Training loss: 1.6866299540905594
Validation loss: 2.305212432663583

Epoch: 393| Step: 0
Training loss: 1.227860656710428
Validation loss: 2.2730389875722583

Epoch: 6| Step: 1
Training loss: 1.2120232913262625
Validation loss: 2.3152726016838425

Epoch: 6| Step: 2
Training loss: 1.7434093484419375
Validation loss: 2.342217549399692

Epoch: 6| Step: 3
Training loss: 1.5464118495352972
Validation loss: 2.263797510378448

Epoch: 6| Step: 4
Training loss: 1.259552977601339
Validation loss: 2.259710083975919

Epoch: 6| Step: 5
Training loss: 1.2530910420751573
Validation loss: 2.2774773617288147

Epoch: 6| Step: 6
Training loss: 0.9828048172060665
Validation loss: 2.3575753194499516

Epoch: 6| Step: 7
Training loss: 2.1336615692389267
Validation loss: 2.313422278840695

Epoch: 6| Step: 8
Training loss: 1.6436949572031925
Validation loss: 2.296050455488917

Epoch: 6| Step: 9
Training loss: 1.3802759213962987
Validation loss: 2.360282779815059

Epoch: 6| Step: 10
Training loss: 1.1623332344950736
Validation loss: 2.3705800836990285

Epoch: 6| Step: 11
Training loss: 1.3766495606758227
Validation loss: 2.2627522803080016

Epoch: 6| Step: 12
Training loss: 1.7147201458781605
Validation loss: 2.3295867299718194

Epoch: 6| Step: 13
Training loss: 1.3720816072155224
Validation loss: 2.291243817499007

Epoch: 394| Step: 0
Training loss: 1.2954940797471017
Validation loss: 2.2655619181449675

Epoch: 6| Step: 1
Training loss: 2.4277858345059062
Validation loss: 2.371408781669373

Epoch: 6| Step: 2
Training loss: 0.867848565324425
Validation loss: 2.281586209126107

Epoch: 6| Step: 3
Training loss: 1.5309767187280652
Validation loss: 2.3413717398230767

Epoch: 6| Step: 4
Training loss: 1.5498912188597178
Validation loss: 2.354829027664794

Epoch: 6| Step: 5
Training loss: 1.7787606764021953
Validation loss: 2.4237798000616775

Epoch: 6| Step: 6
Training loss: 1.5333057539297827
Validation loss: 2.3235239638253526

Epoch: 6| Step: 7
Training loss: 1.5017005499694553
Validation loss: 2.311087741100461

Epoch: 6| Step: 8
Training loss: 1.0937104354241969
Validation loss: 2.286962040826396

Epoch: 6| Step: 9
Training loss: 1.1372415186041014
Validation loss: 2.279180191505927

Epoch: 6| Step: 10
Training loss: 1.0796208715789433
Validation loss: 2.2707866729009707

Epoch: 6| Step: 11
Training loss: 1.495266439113106
Validation loss: 2.292501504105192

Epoch: 6| Step: 12
Training loss: 1.4524958899697542
Validation loss: 2.2806916283286

Epoch: 6| Step: 13
Training loss: 1.0502817320920885
Validation loss: 2.3090472376583193

Epoch: 395| Step: 0
Training loss: 1.1288756264093591
Validation loss: 2.3166501033199998

Epoch: 6| Step: 1
Training loss: 0.9687172053538997
Validation loss: 2.2795197649356957

Epoch: 6| Step: 2
Training loss: 1.2628910535486582
Validation loss: 2.303574267800263

Epoch: 6| Step: 3
Training loss: 1.598380300145376
Validation loss: 2.319814506547366

Epoch: 6| Step: 4
Training loss: 1.4486014395797635
Validation loss: 2.2941167539276264

Epoch: 6| Step: 5
Training loss: 1.507178534018977
Validation loss: 2.3211298748935647

Epoch: 6| Step: 6
Training loss: 1.9579197737766618
Validation loss: 2.3285194520346892

Epoch: 6| Step: 7
Training loss: 1.1861709385081596
Validation loss: 2.292612776195474

Epoch: 6| Step: 8
Training loss: 1.2865059209302625
Validation loss: 2.3106607285941334

Epoch: 6| Step: 9
Training loss: 1.1461786905652502
Validation loss: 2.200518448933878

Epoch: 6| Step: 10
Training loss: 1.4571834208615233
Validation loss: 2.2653687996679124

Epoch: 6| Step: 11
Training loss: 1.3490506684308237
Validation loss: 2.287875410180206

Epoch: 6| Step: 12
Training loss: 2.0856236139509505
Validation loss: 2.29043368192906

Epoch: 6| Step: 13
Training loss: 1.362217135333454
Validation loss: 2.2905994012679782

Epoch: 396| Step: 0
Training loss: 1.594233271311998
Validation loss: 2.3791738361287758

Epoch: 6| Step: 1
Training loss: 1.0625430827662354
Validation loss: 2.341944233370841

Epoch: 6| Step: 2
Training loss: 1.6031685568560452
Validation loss: 2.3694083131703723

Epoch: 6| Step: 3
Training loss: 1.4470633958797197
Validation loss: 2.242538562440854

Epoch: 6| Step: 4
Training loss: 1.3597908260965688
Validation loss: 2.3987460378705943

Epoch: 6| Step: 5
Training loss: 1.3114698999857852
Validation loss: 2.290517149166313

Epoch: 6| Step: 6
Training loss: 1.2021633615194927
Validation loss: 2.348355631887685

Epoch: 6| Step: 7
Training loss: 2.3174349734371447
Validation loss: 2.3911350447962287

Epoch: 6| Step: 8
Training loss: 1.069874471984084
Validation loss: 2.2890138409185883

Epoch: 6| Step: 9
Training loss: 1.265573100215043
Validation loss: 2.289864945670535

Epoch: 6| Step: 10
Training loss: 1.2537598331328237
Validation loss: 2.326341065443944

Epoch: 6| Step: 11
Training loss: 1.2347276401198277
Validation loss: 2.289883215133502

Epoch: 6| Step: 12
Training loss: 1.261390761506323
Validation loss: 2.2867540025417608

Epoch: 6| Step: 13
Training loss: 1.6856641319748178
Validation loss: 2.3347328650275663

Epoch: 397| Step: 0
Training loss: 1.1157354775658288
Validation loss: 2.3538183810765747

Epoch: 6| Step: 1
Training loss: 1.106914047250365
Validation loss: 2.32823171658007

Epoch: 6| Step: 2
Training loss: 1.867135785396225
Validation loss: 2.27656269386964

Epoch: 6| Step: 3
Training loss: 1.2566921860323934
Validation loss: 2.38706050865764

Epoch: 6| Step: 4
Training loss: 1.0733518674584994
Validation loss: 2.354807811494456

Epoch: 6| Step: 5
Training loss: 1.4680099246030014
Validation loss: 2.3536818086071225

Epoch: 6| Step: 6
Training loss: 1.8790651123394135
Validation loss: 2.342268790620727

Epoch: 6| Step: 7
Training loss: 1.2124630578302533
Validation loss: 2.323792370369085

Epoch: 6| Step: 8
Training loss: 0.9933147484899063
Validation loss: 2.2518603024511075

Epoch: 6| Step: 9
Training loss: 1.3529213485581937
Validation loss: 2.2713505190888004

Epoch: 6| Step: 10
Training loss: 1.7652861683577166
Validation loss: 2.3275968408562355

Epoch: 6| Step: 11
Training loss: 1.566290720344083
Validation loss: 2.364689211534682

Epoch: 6| Step: 12
Training loss: 1.872386000337279
Validation loss: 2.3240979444599836

Epoch: 6| Step: 13
Training loss: 1.5555599199339782
Validation loss: 2.267107862519517

Epoch: 398| Step: 0
Training loss: 1.4832125478851572
Validation loss: 2.270817389596416

Epoch: 6| Step: 1
Training loss: 1.591084364116294
Validation loss: 2.2887019477844426

Epoch: 6| Step: 2
Training loss: 1.1888292803235108
Validation loss: 2.34807661271142

Epoch: 6| Step: 3
Training loss: 1.0252979636331805
Validation loss: 2.2356675236955468

Epoch: 6| Step: 4
Training loss: 1.1351686375907561
Validation loss: 2.338203020504645

Epoch: 6| Step: 5
Training loss: 0.8007361794790713
Validation loss: 2.3388500542426

Epoch: 6| Step: 6
Training loss: 2.102895207767685
Validation loss: 2.2807104697915572

Epoch: 6| Step: 7
Training loss: 0.8950360135872375
Validation loss: 2.2842706888928235

Epoch: 6| Step: 8
Training loss: 1.7812633848523975
Validation loss: 2.329276736620908

Epoch: 6| Step: 9
Training loss: 1.7595112370107542
Validation loss: 2.31330537947696

Epoch: 6| Step: 10
Training loss: 1.1046577417231442
Validation loss: 2.2983816859928754

Epoch: 6| Step: 11
Training loss: 1.4851967394194294
Validation loss: 2.32416102867737

Epoch: 6| Step: 12
Training loss: 1.5882871163293195
Validation loss: 2.2697586884015153

Epoch: 6| Step: 13
Training loss: 1.4480304627559932
Validation loss: 2.338123322391781

Epoch: 399| Step: 0
Training loss: 1.5089826243659759
Validation loss: 2.2863118596648757

Epoch: 6| Step: 1
Training loss: 1.1106469290762881
Validation loss: 2.2986982368497055

Epoch: 6| Step: 2
Training loss: 1.4164610694843491
Validation loss: 2.370443211592624

Epoch: 6| Step: 3
Training loss: 1.2559893171560739
Validation loss: 2.2732229432837485

Epoch: 6| Step: 4
Training loss: 1.590618572709264
Validation loss: 2.3288108546056367

Epoch: 6| Step: 5
Training loss: 1.1435598475912347
Validation loss: 2.3068988867297393

Epoch: 6| Step: 6
Training loss: 1.7503977732224048
Validation loss: 2.3015416453248974

Epoch: 6| Step: 7
Training loss: 1.5505587708899147
Validation loss: 2.3570076710528314

Epoch: 6| Step: 8
Training loss: 1.0915433149074258
Validation loss: 2.3739436692798064

Epoch: 6| Step: 9
Training loss: 1.270399248790519
Validation loss: 2.302160852437718

Epoch: 6| Step: 10
Training loss: 0.9791124849682352
Validation loss: 2.2670883516499223

Epoch: 6| Step: 11
Training loss: 1.604151870196912
Validation loss: 2.34588278966736

Epoch: 6| Step: 12
Training loss: 1.0088013521758659
Validation loss: 2.3336108726768265

Epoch: 6| Step: 13
Training loss: 2.4567577895195014
Validation loss: 2.3149713692951877

Epoch: 400| Step: 0
Training loss: 1.2832096744178607
Validation loss: 2.3043683041849095

Epoch: 6| Step: 1
Training loss: 1.5451744056458205
Validation loss: 2.308778371661182

Epoch: 6| Step: 2
Training loss: 1.558411857680106
Validation loss: 2.347335057722882

Epoch: 6| Step: 3
Training loss: 1.076296264327507
Validation loss: 2.238248363000502

Epoch: 6| Step: 4
Training loss: 1.6765991917956449
Validation loss: 2.3093663862180063

Epoch: 6| Step: 5
Training loss: 1.362883763994401
Validation loss: 2.339573140447633

Epoch: 6| Step: 6
Training loss: 0.9819996648912188
Validation loss: 2.3151436325310644

Epoch: 6| Step: 7
Training loss: 1.5743484632944396
Validation loss: 2.3846698334689242

Epoch: 6| Step: 8
Training loss: 1.2619704712890785
Validation loss: 2.323899280393525

Epoch: 6| Step: 9
Training loss: 1.0350600863720485
Validation loss: 2.3366050697801115

Epoch: 6| Step: 10
Training loss: 1.1770568214514086
Validation loss: 2.3401329081944215

Epoch: 6| Step: 11
Training loss: 2.1215665792554383
Validation loss: 2.3246847312753975

Epoch: 6| Step: 12
Training loss: 1.6776432816419087
Validation loss: 2.3283508063541043

Epoch: 6| Step: 13
Training loss: 0.8478836246835233
Validation loss: 2.2920178070727433

Epoch: 401| Step: 0
Training loss: 1.6584141824972458
Validation loss: 2.2932278633684575

Epoch: 6| Step: 1
Training loss: 0.7287347786100559
Validation loss: 2.251273793895688

Epoch: 6| Step: 2
Training loss: 2.2433970309203595
Validation loss: 2.314378038992418

Epoch: 6| Step: 3
Training loss: 1.1152543101224237
Validation loss: 2.30121471287806

Epoch: 6| Step: 4
Training loss: 1.1188371123597618
Validation loss: 2.334313957500289

Epoch: 6| Step: 5
Training loss: 1.546891799989658
Validation loss: 2.2225770690933015

Epoch: 6| Step: 6
Training loss: 1.6891890655723734
Validation loss: 2.2840439098647822

Epoch: 6| Step: 7
Training loss: 1.3215769294172934
Validation loss: 2.2454785158266226

Epoch: 6| Step: 8
Training loss: 1.3978245420084343
Validation loss: 2.334434658816415

Epoch: 6| Step: 9
Training loss: 1.2566216085250261
Validation loss: 2.2537711203168054

Epoch: 6| Step: 10
Training loss: 1.4683964080483967
Validation loss: 2.3124512298948763

Epoch: 6| Step: 11
Training loss: 1.3018671492084868
Validation loss: 2.3029076050801724

Epoch: 6| Step: 12
Training loss: 1.4192310945972915
Validation loss: 2.290520777742663

Epoch: 6| Step: 13
Training loss: 1.1681708221673677
Validation loss: 2.384911081961963

Epoch: 402| Step: 0
Training loss: 1.5406909982654635
Validation loss: 2.287971539834962

Epoch: 6| Step: 1
Training loss: 1.6765567434590711
Validation loss: 2.276674592950467

Epoch: 6| Step: 2
Training loss: 2.103159131344224
Validation loss: 2.31492369003572

Epoch: 6| Step: 3
Training loss: 1.1185306930832626
Validation loss: 2.2638733369211015

Epoch: 6| Step: 4
Training loss: 1.2464820950259232
Validation loss: 2.3496490860588164

Epoch: 6| Step: 5
Training loss: 1.0459594138898318
Validation loss: 2.2760781833167942

Epoch: 6| Step: 6
Training loss: 1.06209679975287
Validation loss: 2.3481044994166163

Epoch: 6| Step: 7
Training loss: 1.6563418380898713
Validation loss: 2.2843416385754485

Epoch: 6| Step: 8
Training loss: 1.5036425074386504
Validation loss: 2.3200854019097608

Epoch: 6| Step: 9
Training loss: 0.8342498428257699
Validation loss: 2.3302010084488325

Epoch: 6| Step: 10
Training loss: 1.5452261720309723
Validation loss: 2.2697631577383035

Epoch: 6| Step: 11
Training loss: 1.0944183487424766
Validation loss: 2.3075036720210487

Epoch: 6| Step: 12
Training loss: 1.4727481236624758
Validation loss: 2.303457923734386

Epoch: 6| Step: 13
Training loss: 0.6864852786142314
Validation loss: 2.359871708605465

Epoch: 403| Step: 0
Training loss: 1.5672068844753548
Validation loss: 2.27339837135365

Epoch: 6| Step: 1
Training loss: 1.413188685416636
Validation loss: 2.335349289534155

Epoch: 6| Step: 2
Training loss: 1.490258612879358
Validation loss: 2.2998686938904913

Epoch: 6| Step: 3
Training loss: 1.5342472870112613
Validation loss: 2.3455769616282574

Epoch: 6| Step: 4
Training loss: 1.456685288497183
Validation loss: 2.334386586380447

Epoch: 6| Step: 5
Training loss: 0.6202610119415236
Validation loss: 2.3221956220404785

Epoch: 6| Step: 6
Training loss: 0.893950794579047
Validation loss: 2.334032672099709

Epoch: 6| Step: 7
Training loss: 0.9913251839178582
Validation loss: 2.280388065081568

Epoch: 6| Step: 8
Training loss: 1.0412943110934938
Validation loss: 2.3273888603961597

Epoch: 6| Step: 9
Training loss: 2.173298431049922
Validation loss: 2.281871103694773

Epoch: 6| Step: 10
Training loss: 1.7709473591912577
Validation loss: 2.353001122974758

Epoch: 6| Step: 11
Training loss: 1.1982580057979426
Validation loss: 2.298792769157159

Epoch: 6| Step: 12
Training loss: 1.610966460358926
Validation loss: 2.3059778582448205

Epoch: 6| Step: 13
Training loss: 1.2599332949223179
Validation loss: 2.2831898874003493

Epoch: 404| Step: 0
Training loss: 0.5562413975768388
Validation loss: 2.3262902337831703

Epoch: 6| Step: 1
Training loss: 1.2799517869809978
Validation loss: 2.274058880757312

Epoch: 6| Step: 2
Training loss: 1.4994936724278376
Validation loss: 2.2973591886624316

Epoch: 6| Step: 3
Training loss: 2.011992500715898
Validation loss: 2.2573798701494128

Epoch: 6| Step: 4
Training loss: 1.2314153027791643
Validation loss: 2.299202505477892

Epoch: 6| Step: 5
Training loss: 1.405678102975201
Validation loss: 2.31734619261037

Epoch: 6| Step: 6
Training loss: 1.1529587995474857
Validation loss: 2.3261983193947833

Epoch: 6| Step: 7
Training loss: 1.376761088947105
Validation loss: 2.247353500199262

Epoch: 6| Step: 8
Training loss: 1.2512959914467696
Validation loss: 2.270993145725614

Epoch: 6| Step: 9
Training loss: 1.5285153785508443
Validation loss: 2.2844742473753024

Epoch: 6| Step: 10
Training loss: 0.9710100022752521
Validation loss: 2.3340920878811233

Epoch: 6| Step: 11
Training loss: 0.8805081159833917
Validation loss: 2.2433563646712433

Epoch: 6| Step: 12
Training loss: 1.5546309110991179
Validation loss: 2.284107752947828

Epoch: 6| Step: 13
Training loss: 2.9464648190865517
Validation loss: 2.287367077551864

Epoch: 405| Step: 0
Training loss: 1.458952672325408
Validation loss: 2.2795564695377326

Epoch: 6| Step: 1
Training loss: 1.9682473646098086
Validation loss: 2.2968923247041615

Epoch: 6| Step: 2
Training loss: 0.9993503069376674
Validation loss: 2.30294431429926

Epoch: 6| Step: 3
Training loss: 2.2427672590306673
Validation loss: 2.2955668696891665

Epoch: 6| Step: 4
Training loss: 0.6572738109003144
Validation loss: 2.2657855108911478

Epoch: 6| Step: 5
Training loss: 1.458700497137895
Validation loss: 2.3312433488317614

Epoch: 6| Step: 6
Training loss: 1.280539943910671
Validation loss: 2.316229784841291

Epoch: 6| Step: 7
Training loss: 1.3096566964716039
Validation loss: 2.3354296185475705

Epoch: 6| Step: 8
Training loss: 1.3395104174349477
Validation loss: 2.324699353130925

Epoch: 6| Step: 9
Training loss: 1.0723801848702748
Validation loss: 2.266421699119908

Epoch: 6| Step: 10
Training loss: 1.5926555540805054
Validation loss: 2.315093806605444

Epoch: 6| Step: 11
Training loss: 1.0669838595148236
Validation loss: 2.2681186332108374

Epoch: 6| Step: 12
Training loss: 1.1544486267204597
Validation loss: 2.2780215762507177

Epoch: 6| Step: 13
Training loss: 1.0433123876116495
Validation loss: 2.298754280648111

Epoch: 406| Step: 0
Training loss: 1.0343254930340648
Validation loss: 2.35204391285873

Epoch: 6| Step: 1
Training loss: 1.6489471081728964
Validation loss: 2.288398634930479

Epoch: 6| Step: 2
Training loss: 2.099322859266231
Validation loss: 2.2971089199127994

Epoch: 6| Step: 3
Training loss: 1.5005556507919515
Validation loss: 2.299914717865415

Epoch: 6| Step: 4
Training loss: 1.5487316818323957
Validation loss: 2.2866145591296227

Epoch: 6| Step: 5
Training loss: 1.5719633771498438
Validation loss: 2.3260693771235395

Epoch: 6| Step: 6
Training loss: 1.3740323736771867
Validation loss: 2.29362188386426

Epoch: 6| Step: 7
Training loss: 1.757107063309915
Validation loss: 2.314344714652645

Epoch: 6| Step: 8
Training loss: 1.5438289514036252
Validation loss: 2.3223300742986135

Epoch: 6| Step: 9
Training loss: 0.7278361897853283
Validation loss: 2.3123363613243115

Epoch: 6| Step: 10
Training loss: 0.9333036602503139
Validation loss: 2.249342008085812

Epoch: 6| Step: 11
Training loss: 1.2991909810927658
Validation loss: 2.2788279564614897

Epoch: 6| Step: 12
Training loss: 0.9409038421884864
Validation loss: 2.3413270897512017

Epoch: 6| Step: 13
Training loss: 1.0308463144577211
Validation loss: 2.360039355394987

Epoch: 407| Step: 0
Training loss: 1.2079215608734288
Validation loss: 2.295946491752741

Epoch: 6| Step: 1
Training loss: 1.3161754009557132
Validation loss: 2.246356642908438

Epoch: 6| Step: 2
Training loss: 1.1638829649655866
Validation loss: 2.2588460028454787

Epoch: 6| Step: 3
Training loss: 1.0383977269268285
Validation loss: 2.344182456532459

Epoch: 6| Step: 4
Training loss: 2.0831972332049746
Validation loss: 2.3210577125960428

Epoch: 6| Step: 5
Training loss: 0.716328896908922
Validation loss: 2.300356851780624

Epoch: 6| Step: 6
Training loss: 0.8292422405543463
Validation loss: 2.2868791226122513

Epoch: 6| Step: 7
Training loss: 1.716899083277233
Validation loss: 2.3087844971104583

Epoch: 6| Step: 8
Training loss: 1.3829303411068403
Validation loss: 2.2580204804839368

Epoch: 6| Step: 9
Training loss: 1.3620161509795596
Validation loss: 2.3277397720730884

Epoch: 6| Step: 10
Training loss: 2.1893539202059458
Validation loss: 2.2677915698299094

Epoch: 6| Step: 11
Training loss: 1.2322559758894889
Validation loss: 2.2545150074358045

Epoch: 6| Step: 12
Training loss: 1.1589218919944861
Validation loss: 2.300066712273779

Epoch: 6| Step: 13
Training loss: 0.8678988039690856
Validation loss: 2.361790072471385

Epoch: 408| Step: 0
Training loss: 1.131863216041802
Validation loss: 2.305644453156537

Epoch: 6| Step: 1
Training loss: 1.5880686905271193
Validation loss: 2.307021462983079

Epoch: 6| Step: 2
Training loss: 1.3345433595744611
Validation loss: 2.3138294084822832

Epoch: 6| Step: 3
Training loss: 1.225445475641218
Validation loss: 2.296343451911855

Epoch: 6| Step: 4
Training loss: 1.4600270744321666
Validation loss: 2.268745628512501

Epoch: 6| Step: 5
Training loss: 1.3297117739836433
Validation loss: 2.271967532850562

Epoch: 6| Step: 6
Training loss: 1.1626492824891652
Validation loss: 2.2690423253097616

Epoch: 6| Step: 7
Training loss: 1.2312105879309156
Validation loss: 2.3062949571647073

Epoch: 6| Step: 8
Training loss: 0.9141517008759298
Validation loss: 2.2946375907947827

Epoch: 6| Step: 9
Training loss: 1.135229386915994
Validation loss: 2.320241544247716

Epoch: 6| Step: 10
Training loss: 1.5040558183285044
Validation loss: 2.235147662857994

Epoch: 6| Step: 11
Training loss: 0.9559899094859106
Validation loss: 2.3047898770538433

Epoch: 6| Step: 12
Training loss: 2.0521231194010205
Validation loss: 2.295722938701721

Epoch: 6| Step: 13
Training loss: 2.003380184017164
Validation loss: 2.2493607240700424

Epoch: 409| Step: 0
Training loss: 1.1728311325695153
Validation loss: 2.3203145688657023

Epoch: 6| Step: 1
Training loss: 1.0990312320099964
Validation loss: 2.3030105911253647

Epoch: 6| Step: 2
Training loss: 1.121308256356119
Validation loss: 2.2901451627282197

Epoch: 6| Step: 3
Training loss: 1.176447682648555
Validation loss: 2.319302100771854

Epoch: 6| Step: 4
Training loss: 1.672202033740941
Validation loss: 2.300476935463631

Epoch: 6| Step: 5
Training loss: 1.3268321308069362
Validation loss: 2.2769075813698474

Epoch: 6| Step: 6
Training loss: 1.270326711427367
Validation loss: 2.253545098950489

Epoch: 6| Step: 7
Training loss: 0.9780639397815748
Validation loss: 2.2700233602991005

Epoch: 6| Step: 8
Training loss: 1.6529056684805892
Validation loss: 2.3349528215336006

Epoch: 6| Step: 9
Training loss: 1.23616569138992
Validation loss: 2.258217628586639

Epoch: 6| Step: 10
Training loss: 1.1589082626689433
Validation loss: 2.311698789188466

Epoch: 6| Step: 11
Training loss: 1.981010588612341
Validation loss: 2.3394004216490836

Epoch: 6| Step: 12
Training loss: 1.3098658058360027
Validation loss: 2.314863028347793

Epoch: 6| Step: 13
Training loss: 1.7503407010444183
Validation loss: 2.3701558248556553

Epoch: 410| Step: 0
Training loss: 0.910118429683383
Validation loss: 2.3558050990370356

Epoch: 6| Step: 1
Training loss: 1.5626226758482662
Validation loss: 2.325677121486543

Epoch: 6| Step: 2
Training loss: 1.3305935526187205
Validation loss: 2.3359297561805237

Epoch: 6| Step: 3
Training loss: 1.8808174168233411
Validation loss: 2.2996158103315136

Epoch: 6| Step: 4
Training loss: 1.3802261735254984
Validation loss: 2.304458004395159

Epoch: 6| Step: 5
Training loss: 1.2010156049103693
Validation loss: 2.3092857916977234

Epoch: 6| Step: 6
Training loss: 1.1532894069009505
Validation loss: 2.32541036566811

Epoch: 6| Step: 7
Training loss: 1.1509075978538015
Validation loss: 2.3167494365200256

Epoch: 6| Step: 8
Training loss: 1.196250198667185
Validation loss: 2.3171352120774467

Epoch: 6| Step: 9
Training loss: 1.3353821788188878
Validation loss: 2.2724939678977614

Epoch: 6| Step: 10
Training loss: 1.404787617171767
Validation loss: 2.322287960899465

Epoch: 6| Step: 11
Training loss: 1.9528934799303488
Validation loss: 2.28706153636119

Epoch: 6| Step: 12
Training loss: 1.285942602321287
Validation loss: 2.37333459001639

Epoch: 6| Step: 13
Training loss: 1.103881397224026
Validation loss: 2.3019483403557035

Epoch: 411| Step: 0
Training loss: 2.212102252962886
Validation loss: 2.2848747832426

Epoch: 6| Step: 1
Training loss: 1.3691000503862123
Validation loss: 2.220756945486953

Epoch: 6| Step: 2
Training loss: 1.451511430611906
Validation loss: 2.369294104707322

Epoch: 6| Step: 3
Training loss: 1.5807381325414573
Validation loss: 2.286561909263572

Epoch: 6| Step: 4
Training loss: 1.2931163507672865
Validation loss: 2.2754584366986426

Epoch: 6| Step: 5
Training loss: 1.3907564079689738
Validation loss: 2.3310104040033166

Epoch: 6| Step: 6
Training loss: 1.5007349439047155
Validation loss: 2.3296294828444655

Epoch: 6| Step: 7
Training loss: 1.1147049216621991
Validation loss: 2.3289662561997297

Epoch: 6| Step: 8
Training loss: 0.820216472999725
Validation loss: 2.2472668960135422

Epoch: 6| Step: 9
Training loss: 0.9491284488377685
Validation loss: 2.301537221547213

Epoch: 6| Step: 10
Training loss: 1.146314046187419
Validation loss: 2.2572102922147246

Epoch: 6| Step: 11
Training loss: 1.0914401595924215
Validation loss: 2.3156277480107805

Epoch: 6| Step: 12
Training loss: 1.4830837857788948
Validation loss: 2.295032245580052

Epoch: 6| Step: 13
Training loss: 1.4935928836695886
Validation loss: 2.2980320716910416

Epoch: 412| Step: 0
Training loss: 1.2052005353239574
Validation loss: 2.3173479128797543

Epoch: 6| Step: 1
Training loss: 1.5317543911778344
Validation loss: 2.3442626058944986

Epoch: 6| Step: 2
Training loss: 2.153829902676696
Validation loss: 2.315826192319802

Epoch: 6| Step: 3
Training loss: 1.535864746605945
Validation loss: 2.386593363784203

Epoch: 6| Step: 4
Training loss: 1.2771231084523789
Validation loss: 2.314676452886005

Epoch: 6| Step: 5
Training loss: 1.007949228400762
Validation loss: 2.375524304325524

Epoch: 6| Step: 6
Training loss: 1.468740503808023
Validation loss: 2.302685049591005

Epoch: 6| Step: 7
Training loss: 1.4056118258838006
Validation loss: 2.257879487344131

Epoch: 6| Step: 8
Training loss: 0.9829302888524345
Validation loss: 2.3092843246414634

Epoch: 6| Step: 9
Training loss: 1.1433817327911502
Validation loss: 2.254603741803945

Epoch: 6| Step: 10
Training loss: 0.8362540599342405
Validation loss: 2.295497745618638

Epoch: 6| Step: 11
Training loss: 1.1672770004989645
Validation loss: 2.305609375854733

Epoch: 6| Step: 12
Training loss: 1.3236938156293547
Validation loss: 2.268390865676632

Epoch: 6| Step: 13
Training loss: 1.4643833912028175
Validation loss: 2.3183453766418802

Epoch: 413| Step: 0
Training loss: 2.164111415709573
Validation loss: 2.312005230390055

Epoch: 6| Step: 1
Training loss: 1.0549972079452523
Validation loss: 2.258090852841668

Epoch: 6| Step: 2
Training loss: 1.3416632484408286
Validation loss: 2.3089521414557326

Epoch: 6| Step: 3
Training loss: 1.0276128032235678
Validation loss: 2.259541900601563

Epoch: 6| Step: 4
Training loss: 1.5232299663328819
Validation loss: 2.2971153365137362

Epoch: 6| Step: 5
Training loss: 1.2268228922664235
Validation loss: 2.2387504828124642

Epoch: 6| Step: 6
Training loss: 1.0826317398219139
Validation loss: 2.279767790379794

Epoch: 6| Step: 7
Training loss: 1.2891408260708948
Validation loss: 2.3512397102775013

Epoch: 6| Step: 8
Training loss: 1.294947144965183
Validation loss: 2.3413644946530585

Epoch: 6| Step: 9
Training loss: 1.1739095700868338
Validation loss: 2.316501215608929

Epoch: 6| Step: 10
Training loss: 1.8998592374760033
Validation loss: 2.223068575360406

Epoch: 6| Step: 11
Training loss: 1.6249002279316789
Validation loss: 2.320902951777202

Epoch: 6| Step: 12
Training loss: 1.2234799471491349
Validation loss: 2.345504730630738

Epoch: 6| Step: 13
Training loss: 0.9595933522805521
Validation loss: 2.2618217560280094

Epoch: 414| Step: 0
Training loss: 1.9536012602924653
Validation loss: 2.35019374645248

Epoch: 6| Step: 1
Training loss: 1.1449059403611155
Validation loss: 2.3113746975934313

Epoch: 6| Step: 2
Training loss: 0.9841397927857529
Validation loss: 2.3650446561889815

Epoch: 6| Step: 3
Training loss: 1.2643474205882337
Validation loss: 2.3614160914604354

Epoch: 6| Step: 4
Training loss: 1.141262555591253
Validation loss: 2.306476233833057

Epoch: 6| Step: 5
Training loss: 2.007285201005036
Validation loss: 2.2783433796546455

Epoch: 6| Step: 6
Training loss: 1.4439528384709777
Validation loss: 2.248802172713806

Epoch: 6| Step: 7
Training loss: 1.6081490152450937
Validation loss: 2.306941093808254

Epoch: 6| Step: 8
Training loss: 1.2878165957620162
Validation loss: 2.2424599788273714

Epoch: 6| Step: 9
Training loss: 1.1659889409831445
Validation loss: 2.2491644848475874

Epoch: 6| Step: 10
Training loss: 1.108789692526271
Validation loss: 2.3322842659733203

Epoch: 6| Step: 11
Training loss: 1.1403227105053368
Validation loss: 2.301194607746454

Epoch: 6| Step: 12
Training loss: 1.3590368091350522
Validation loss: 2.3005375154221226

Epoch: 6| Step: 13
Training loss: 1.4155962303219218
Validation loss: 2.2844753056111577

Epoch: 415| Step: 0
Training loss: 1.1609963608782476
Validation loss: 2.3251077420378405

Epoch: 6| Step: 1
Training loss: 1.1151147567813933
Validation loss: 2.328437522673827

Epoch: 6| Step: 2
Training loss: 2.066391596895412
Validation loss: 2.2531177927917754

Epoch: 6| Step: 3
Training loss: 1.620186866885212
Validation loss: 2.2631323919165833

Epoch: 6| Step: 4
Training loss: 1.0353992680725905
Validation loss: 2.351790794045912

Epoch: 6| Step: 5
Training loss: 1.106502036570706
Validation loss: 2.36535454383631

Epoch: 6| Step: 6
Training loss: 1.5639778015190655
Validation loss: 2.3580607254041954

Epoch: 6| Step: 7
Training loss: 1.421384957514582
Validation loss: 2.305599257410031

Epoch: 6| Step: 8
Training loss: 1.6671574426317206
Validation loss: 2.3000992080332896

Epoch: 6| Step: 9
Training loss: 1.37434779217874
Validation loss: 2.336512540756136

Epoch: 6| Step: 10
Training loss: 1.1757048521853644
Validation loss: 2.2809584832123524

Epoch: 6| Step: 11
Training loss: 0.8272279883528818
Validation loss: 2.326339624020311

Epoch: 6| Step: 12
Training loss: 1.375155960254619
Validation loss: 2.2418690053966817

Epoch: 6| Step: 13
Training loss: 1.0872761550813332
Validation loss: 2.269542304144402

Epoch: 416| Step: 0
Training loss: 1.943844283291943
Validation loss: 2.3213987504057214

Epoch: 6| Step: 1
Training loss: 1.0947142029472068
Validation loss: 2.2973844147317006

Epoch: 6| Step: 2
Training loss: 0.7069159144965241
Validation loss: 2.3501847651608156

Epoch: 6| Step: 3
Training loss: 1.2725373813856808
Validation loss: 2.2449308893301354

Epoch: 6| Step: 4
Training loss: 1.826255690339275
Validation loss: 2.342528026698263

Epoch: 6| Step: 5
Training loss: 1.1502951823669167
Validation loss: 2.3126525496009345

Epoch: 6| Step: 6
Training loss: 1.081587827970645
Validation loss: 2.2264662636362442

Epoch: 6| Step: 7
Training loss: 1.2339909595918814
Validation loss: 2.3182475571754866

Epoch: 6| Step: 8
Training loss: 1.1388860537072432
Validation loss: 2.281894322574827

Epoch: 6| Step: 9
Training loss: 1.1281490756606871
Validation loss: 2.3042229219092385

Epoch: 6| Step: 10
Training loss: 1.4195757710388195
Validation loss: 2.304318055856472

Epoch: 6| Step: 11
Training loss: 1.8762669415506448
Validation loss: 2.292073744102094

Epoch: 6| Step: 12
Training loss: 1.2280388954787196
Validation loss: 2.3109039090982058

Epoch: 6| Step: 13
Training loss: 0.8096070137493799
Validation loss: 2.3549940604732487

Epoch: 417| Step: 0
Training loss: 1.0751865535590666
Validation loss: 2.3043054440949584

Epoch: 6| Step: 1
Training loss: 1.191182600198127
Validation loss: 2.294854226216033

Epoch: 6| Step: 2
Training loss: 1.6435490300426248
Validation loss: 2.291015208732912

Epoch: 6| Step: 3
Training loss: 1.0626655898365929
Validation loss: 2.320647914996458

Epoch: 6| Step: 4
Training loss: 1.3050854470059867
Validation loss: 2.310034841711446

Epoch: 6| Step: 5
Training loss: 1.5601641934134836
Validation loss: 2.3341231071618562

Epoch: 6| Step: 6
Training loss: 1.184837317506498
Validation loss: 2.3304900738262595

Epoch: 6| Step: 7
Training loss: 0.8764322683927247
Validation loss: 2.3028765338134263

Epoch: 6| Step: 8
Training loss: 2.2165710065273205
Validation loss: 2.3256575100269687

Epoch: 6| Step: 9
Training loss: 1.3706813094109016
Validation loss: 2.327892600467824

Epoch: 6| Step: 10
Training loss: 0.8044595488104435
Validation loss: 2.263845954998076

Epoch: 6| Step: 11
Training loss: 0.9253956760382972
Validation loss: 2.3176561435207903

Epoch: 6| Step: 12
Training loss: 1.5375317547007792
Validation loss: 2.297953927268654

Epoch: 6| Step: 13
Training loss: 1.747320849140566
Validation loss: 2.286343091010075

Epoch: 418| Step: 0
Training loss: 0.7870486404045629
Validation loss: 2.343374255288119

Epoch: 6| Step: 1
Training loss: 1.020089533747088
Validation loss: 2.3302155263793964

Epoch: 6| Step: 2
Training loss: 2.2397860649672077
Validation loss: 2.236486456575601

Epoch: 6| Step: 3
Training loss: 1.3092248106699083
Validation loss: 2.2944180007912167

Epoch: 6| Step: 4
Training loss: 1.3779567659070826
Validation loss: 2.285216523735751

Epoch: 6| Step: 5
Training loss: 1.2295724662284169
Validation loss: 2.3309708169872048

Epoch: 6| Step: 6
Training loss: 1.364698706061789
Validation loss: 2.2835657578855675

Epoch: 6| Step: 7
Training loss: 1.843099447016964
Validation loss: 2.279878599408428

Epoch: 6| Step: 8
Training loss: 1.7122194547642522
Validation loss: 2.33158628004637

Epoch: 6| Step: 9
Training loss: 1.4497192834559298
Validation loss: 2.2822251729690555

Epoch: 6| Step: 10
Training loss: 1.2552247527804237
Validation loss: 2.3001910753139896

Epoch: 6| Step: 11
Training loss: 1.2936882944180639
Validation loss: 2.3370175382326646

Epoch: 6| Step: 12
Training loss: 0.9703802112781915
Validation loss: 2.3057225292871557

Epoch: 6| Step: 13
Training loss: 0.914126467300504
Validation loss: 2.343825705341293

Epoch: 419| Step: 0
Training loss: 0.8680251260298275
Validation loss: 2.299708672344508

Epoch: 6| Step: 1
Training loss: 1.2940134858220211
Validation loss: 2.3400229190743143

Epoch: 6| Step: 2
Training loss: 1.9006399557622216
Validation loss: 2.317413823126763

Epoch: 6| Step: 3
Training loss: 1.2523421755737383
Validation loss: 2.3013605926443104

Epoch: 6| Step: 4
Training loss: 1.030742578224851
Validation loss: 2.3547917266837364

Epoch: 6| Step: 5
Training loss: 1.1709025098970047
Validation loss: 2.3445110734282015

Epoch: 6| Step: 6
Training loss: 1.5854129017581757
Validation loss: 2.302574149566047

Epoch: 6| Step: 7
Training loss: 2.1029232115392067
Validation loss: 2.1890270827117893

Epoch: 6| Step: 8
Training loss: 1.115304547188265
Validation loss: 2.2606823952476627

Epoch: 6| Step: 9
Training loss: 1.265413525656699
Validation loss: 2.2863174964311526

Epoch: 6| Step: 10
Training loss: 1.090811515096435
Validation loss: 2.3140344669886654

Epoch: 6| Step: 11
Training loss: 1.396728750334548
Validation loss: 2.3079012258628033

Epoch: 6| Step: 12
Training loss: 1.0853468571702147
Validation loss: 2.318217395949035

Epoch: 6| Step: 13
Training loss: 2.243296491859831
Validation loss: 2.2566715830481883

Epoch: 420| Step: 0
Training loss: 1.24423437798312
Validation loss: 2.323038055442853

Epoch: 6| Step: 1
Training loss: 1.3140097517931963
Validation loss: 2.2937261636456734

Epoch: 6| Step: 2
Training loss: 1.0770522599500232
Validation loss: 2.271402151353649

Epoch: 6| Step: 3
Training loss: 0.9548517750755662
Validation loss: 2.339251192845761

Epoch: 6| Step: 4
Training loss: 1.555984646032526
Validation loss: 2.3336100410573266

Epoch: 6| Step: 5
Training loss: 0.9566234108874158
Validation loss: 2.2951656876535025

Epoch: 6| Step: 6
Training loss: 1.0752376648533055
Validation loss: 2.3480569863515255

Epoch: 6| Step: 7
Training loss: 1.3591534664246674
Validation loss: 2.300848108358513

Epoch: 6| Step: 8
Training loss: 2.032467873144614
Validation loss: 2.374608236383304

Epoch: 6| Step: 9
Training loss: 1.3264455161841704
Validation loss: 2.3224127699471637

Epoch: 6| Step: 10
Training loss: 1.2007691739529294
Validation loss: 2.230727052035523

Epoch: 6| Step: 11
Training loss: 1.496613813003688
Validation loss: 2.3539047478466704

Epoch: 6| Step: 12
Training loss: 1.5265099476384876
Validation loss: 2.253881885169885

Epoch: 6| Step: 13
Training loss: 1.3476277666260783
Validation loss: 2.3123456775419795

Epoch: 421| Step: 0
Training loss: 1.0155352039254903
Validation loss: 2.1986774021717577

Epoch: 6| Step: 1
Training loss: 1.1999853212730363
Validation loss: 2.2986578323853286

Epoch: 6| Step: 2
Training loss: 1.751002229075862
Validation loss: 2.2879550876762997

Epoch: 6| Step: 3
Training loss: 1.5715167993077872
Validation loss: 2.282103645835704

Epoch: 6| Step: 4
Training loss: 1.1177186570249227
Validation loss: 2.297283479778052

Epoch: 6| Step: 5
Training loss: 1.5403472650048304
Validation loss: 2.2449199623767773

Epoch: 6| Step: 6
Training loss: 1.8577018069567992
Validation loss: 2.297979957855013

Epoch: 6| Step: 7
Training loss: 1.1643881630268673
Validation loss: 2.2456626343522554

Epoch: 6| Step: 8
Training loss: 1.2351704219654136
Validation loss: 2.2770211185384595

Epoch: 6| Step: 9
Training loss: 0.8876610676923945
Validation loss: 2.2770176756108

Epoch: 6| Step: 10
Training loss: 1.067984729750546
Validation loss: 2.2787339015179167

Epoch: 6| Step: 11
Training loss: 1.4107200362034842
Validation loss: 2.2817635547423083

Epoch: 6| Step: 12
Training loss: 1.1171508996476789
Validation loss: 2.3252467590495938

Epoch: 6| Step: 13
Training loss: 1.7808438557498554
Validation loss: 2.2764312042104917

Epoch: 422| Step: 0
Training loss: 1.689675518238219
Validation loss: 2.328202486314444

Epoch: 6| Step: 1
Training loss: 2.041725028105662
Validation loss: 2.3115894550410014

Epoch: 6| Step: 2
Training loss: 1.2678578777810006
Validation loss: 2.3063829373623017

Epoch: 6| Step: 3
Training loss: 1.1922452380196644
Validation loss: 2.305714622837189

Epoch: 6| Step: 4
Training loss: 1.119043635614411
Validation loss: 2.3485840482699696

Epoch: 6| Step: 5
Training loss: 0.9832245295077418
Validation loss: 2.2915883609299112

Epoch: 6| Step: 6
Training loss: 1.0380635443036852
Validation loss: 2.3005547345400834

Epoch: 6| Step: 7
Training loss: 1.277026775823214
Validation loss: 2.271701702782189

Epoch: 6| Step: 8
Training loss: 1.0760189993219709
Validation loss: 2.3183659683201374

Epoch: 6| Step: 9
Training loss: 1.1813104341578808
Validation loss: 2.3678910097994152

Epoch: 6| Step: 10
Training loss: 1.126212314563722
Validation loss: 2.3471136074279624

Epoch: 6| Step: 11
Training loss: 1.1822570201933968
Validation loss: 2.3173865848622546

Epoch: 6| Step: 12
Training loss: 1.8377205489269814
Validation loss: 2.3324964464732942

Epoch: 6| Step: 13
Training loss: 0.7834915429165831
Validation loss: 2.231060548031082

Epoch: 423| Step: 0
Training loss: 1.7583723744883766
Validation loss: 2.334400145907897

Epoch: 6| Step: 1
Training loss: 0.9845149833813812
Validation loss: 2.300237807240334

Epoch: 6| Step: 2
Training loss: 1.2295064887441436
Validation loss: 2.322644627818805

Epoch: 6| Step: 3
Training loss: 1.3948122911397964
Validation loss: 2.2787075194463333

Epoch: 6| Step: 4
Training loss: 1.5261378686502796
Validation loss: 2.289663362862777

Epoch: 6| Step: 5
Training loss: 1.8812128133045023
Validation loss: 2.323079589121653

Epoch: 6| Step: 6
Training loss: 1.3150150180727815
Validation loss: 2.2728252516086545

Epoch: 6| Step: 7
Training loss: 1.2511330237953122
Validation loss: 2.2888196265957514

Epoch: 6| Step: 8
Training loss: 0.9678581193045284
Validation loss: 2.2091238892217744

Epoch: 6| Step: 9
Training loss: 1.09406003645026
Validation loss: 2.283342189545594

Epoch: 6| Step: 10
Training loss: 1.794018141213577
Validation loss: 2.3294962481099497

Epoch: 6| Step: 11
Training loss: 1.0446518023134705
Validation loss: 2.28782839772163

Epoch: 6| Step: 12
Training loss: 0.9034146316362772
Validation loss: 2.265863929175411

Epoch: 6| Step: 13
Training loss: 1.2124921110230833
Validation loss: 2.2740424327873603

Epoch: 424| Step: 0
Training loss: 0.9350950229012589
Validation loss: 2.247639841316961

Epoch: 6| Step: 1
Training loss: 1.6462503540687499
Validation loss: 2.2812901862933286

Epoch: 6| Step: 2
Training loss: 0.8014586026262572
Validation loss: 2.2290561277920995

Epoch: 6| Step: 3
Training loss: 1.2530959889390425
Validation loss: 2.3261846756895674

Epoch: 6| Step: 4
Training loss: 1.0244158080225239
Validation loss: 2.2882790018906944

Epoch: 6| Step: 5
Training loss: 0.929420240438846
Validation loss: 2.2520573130719903

Epoch: 6| Step: 6
Training loss: 1.3473260889728422
Validation loss: 2.2638964244489714

Epoch: 6| Step: 7
Training loss: 0.904945355235621
Validation loss: 2.260566755400199

Epoch: 6| Step: 8
Training loss: 2.4083131144729766
Validation loss: 2.346528881336373

Epoch: 6| Step: 9
Training loss: 1.02361709533166
Validation loss: 2.3306886782314367

Epoch: 6| Step: 10
Training loss: 1.4330265263872786
Validation loss: 2.2618866060363922

Epoch: 6| Step: 11
Training loss: 1.8845224806734395
Validation loss: 2.3044686017610014

Epoch: 6| Step: 12
Training loss: 1.0318184644067
Validation loss: 2.2930935158770307

Epoch: 6| Step: 13
Training loss: 1.0213466573332488
Validation loss: 2.348675217585811

Epoch: 425| Step: 0
Training loss: 1.3262529980394595
Validation loss: 2.3020204886186133

Epoch: 6| Step: 1
Training loss: 1.0389792043240433
Validation loss: 2.297109268671899

Epoch: 6| Step: 2
Training loss: 1.473460981843309
Validation loss: 2.3350111928418023

Epoch: 6| Step: 3
Training loss: 1.5975953629137496
Validation loss: 2.2122658962756883

Epoch: 6| Step: 4
Training loss: 0.9239770232972782
Validation loss: 2.2919076660457054

Epoch: 6| Step: 5
Training loss: 1.564235486383157
Validation loss: 2.284614536221883

Epoch: 6| Step: 6
Training loss: 0.9029723120845381
Validation loss: 2.310025477331681

Epoch: 6| Step: 7
Training loss: 1.123488523467951
Validation loss: 2.2679579025501475

Epoch: 6| Step: 8
Training loss: 1.3463729276647354
Validation loss: 2.267361279371778

Epoch: 6| Step: 9
Training loss: 2.0025719556131927
Validation loss: 2.292515455626353

Epoch: 6| Step: 10
Training loss: 1.2056870861688507
Validation loss: 2.3030479320860513

Epoch: 6| Step: 11
Training loss: 0.991298367257122
Validation loss: 2.2795451625544585

Epoch: 6| Step: 12
Training loss: 0.9741370025330007
Validation loss: 2.2671047969245457

Epoch: 6| Step: 13
Training loss: 1.458507699987299
Validation loss: 2.3438878457062446

Epoch: 426| Step: 0
Training loss: 1.4529886489393278
Validation loss: 2.340629319080848

Epoch: 6| Step: 1
Training loss: 1.0527199937053988
Validation loss: 2.29740059794733

Epoch: 6| Step: 2
Training loss: 1.1803325380094432
Validation loss: 2.3103062707063544

Epoch: 6| Step: 3
Training loss: 0.8864934021542339
Validation loss: 2.260779365923627

Epoch: 6| Step: 4
Training loss: 1.2750751753691671
Validation loss: 2.3125253934832357

Epoch: 6| Step: 5
Training loss: 1.5705267157506346
Validation loss: 2.277493137648115

Epoch: 6| Step: 6
Training loss: 1.3501594625884434
Validation loss: 2.2461940714085546

Epoch: 6| Step: 7
Training loss: 1.6575216054299386
Validation loss: 2.3060213184093628

Epoch: 6| Step: 8
Training loss: 1.072394413674619
Validation loss: 2.2010527620579

Epoch: 6| Step: 9
Training loss: 1.6106724370233063
Validation loss: 2.313999667540925

Epoch: 6| Step: 10
Training loss: 0.9278692850098538
Validation loss: 2.346765293945549

Epoch: 6| Step: 11
Training loss: 0.911570093478333
Validation loss: 2.329037219128532

Epoch: 6| Step: 12
Training loss: 2.0070484652139142
Validation loss: 2.323523220172999

Epoch: 6| Step: 13
Training loss: 1.247742426218516
Validation loss: 2.3082122484737253

Epoch: 427| Step: 0
Training loss: 1.567964991178697
Validation loss: 2.2829776680215748

Epoch: 6| Step: 1
Training loss: 1.1949396486884047
Validation loss: 2.3220820348204403

Epoch: 6| Step: 2
Training loss: 1.422618964773458
Validation loss: 2.28589167568991

Epoch: 6| Step: 3
Training loss: 1.1010611184434094
Validation loss: 2.2294437081803946

Epoch: 6| Step: 4
Training loss: 1.1604723258969463
Validation loss: 2.285590586803718

Epoch: 6| Step: 5
Training loss: 1.0111892080247193
Validation loss: 2.2709988600240454

Epoch: 6| Step: 6
Training loss: 1.2444671250350363
Validation loss: 2.275088920239304

Epoch: 6| Step: 7
Training loss: 0.9747785218872993
Validation loss: 2.2731094701618013

Epoch: 6| Step: 8
Training loss: 1.0943938403901545
Validation loss: 2.2609511525559394

Epoch: 6| Step: 9
Training loss: 2.0041807109422636
Validation loss: 2.2174285808249103

Epoch: 6| Step: 10
Training loss: 1.5381515828005226
Validation loss: 2.2708093356486128

Epoch: 6| Step: 11
Training loss: 1.2928513303609495
Validation loss: 2.2720012891883608

Epoch: 6| Step: 12
Training loss: 1.1664904166104697
Validation loss: 2.3045283347943784

Epoch: 6| Step: 13
Training loss: 1.2031130108917154
Validation loss: 2.2658648326129973

Epoch: 428| Step: 0
Training loss: 1.1462255442432596
Validation loss: 2.282429851758769

Epoch: 6| Step: 1
Training loss: 1.1311626126589696
Validation loss: 2.34084987146423

Epoch: 6| Step: 2
Training loss: 1.096788056234413
Validation loss: 2.3710853576646787

Epoch: 6| Step: 3
Training loss: 1.2586531584231686
Validation loss: 2.342316121207205

Epoch: 6| Step: 4
Training loss: 1.025152211401528
Validation loss: 2.2085292096218128

Epoch: 6| Step: 5
Training loss: 0.985924908395879
Validation loss: 2.356838877503597

Epoch: 6| Step: 6
Training loss: 1.6266614783053177
Validation loss: 2.239433800030559

Epoch: 6| Step: 7
Training loss: 1.8762967393963592
Validation loss: 2.338347201745607

Epoch: 6| Step: 8
Training loss: 1.248952044846858
Validation loss: 2.337618199149507

Epoch: 6| Step: 9
Training loss: 1.2132023949675876
Validation loss: 2.3736842450172597

Epoch: 6| Step: 10
Training loss: 1.3217887525626257
Validation loss: 2.2639451664658807

Epoch: 6| Step: 11
Training loss: 1.7907281975692404
Validation loss: 2.3018517909279983

Epoch: 6| Step: 12
Training loss: 1.303921868908991
Validation loss: 2.2555970685313285

Epoch: 6| Step: 13
Training loss: 0.9138082819145278
Validation loss: 2.247524337413214

Epoch: 429| Step: 0
Training loss: 1.1354066807485663
Validation loss: 2.3200881278860233

Epoch: 6| Step: 1
Training loss: 1.640425897051818
Validation loss: 2.289324768266405

Epoch: 6| Step: 2
Training loss: 1.0583567899572586
Validation loss: 2.284055844451303

Epoch: 6| Step: 3
Training loss: 0.7727207754749357
Validation loss: 2.2996531958249116

Epoch: 6| Step: 4
Training loss: 1.153307495562779
Validation loss: 2.278607360983843

Epoch: 6| Step: 5
Training loss: 1.5591146798423463
Validation loss: 2.3195391215781234

Epoch: 6| Step: 6
Training loss: 1.5597561204230435
Validation loss: 2.3132173777432063

Epoch: 6| Step: 7
Training loss: 0.9948134627958589
Validation loss: 2.331709944897552

Epoch: 6| Step: 8
Training loss: 2.1263306883090696
Validation loss: 2.267294313236345

Epoch: 6| Step: 9
Training loss: 1.5999492428596518
Validation loss: 2.309779237563717

Epoch: 6| Step: 10
Training loss: 1.1950105273210023
Validation loss: 2.338240388766939

Epoch: 6| Step: 11
Training loss: 0.966248019316347
Validation loss: 2.313067514302099

Epoch: 6| Step: 12
Training loss: 1.0758751877360968
Validation loss: 2.2494374840190137

Epoch: 6| Step: 13
Training loss: 0.7511820220658662
Validation loss: 2.328475615219718

Epoch: 430| Step: 0
Training loss: 1.3673495823288204
Validation loss: 2.297042927600125

Epoch: 6| Step: 1
Training loss: 1.363256022484952
Validation loss: 2.2143724243182055

Epoch: 6| Step: 2
Training loss: 1.4034301035279906
Validation loss: 2.2968815481218

Epoch: 6| Step: 3
Training loss: 2.070915969131146
Validation loss: 2.3239903932854027

Epoch: 6| Step: 4
Training loss: 1.3566433876596007
Validation loss: 2.3297275275700318

Epoch: 6| Step: 5
Training loss: 0.8500476276854425
Validation loss: 2.30539319062636

Epoch: 6| Step: 6
Training loss: 1.4916435168865672
Validation loss: 2.341690361695112

Epoch: 6| Step: 7
Training loss: 0.9571537795745017
Validation loss: 2.3239905741971003

Epoch: 6| Step: 8
Training loss: 1.1511095064404455
Validation loss: 2.256269466245839

Epoch: 6| Step: 9
Training loss: 1.1494879557047841
Validation loss: 2.285734271846554

Epoch: 6| Step: 10
Training loss: 1.3534877053115648
Validation loss: 2.332910712228628

Epoch: 6| Step: 11
Training loss: 1.2623095000415958
Validation loss: 2.363852002167626

Epoch: 6| Step: 12
Training loss: 1.2837674135477568
Validation loss: 2.279398365739858

Epoch: 6| Step: 13
Training loss: 0.5502774795748803
Validation loss: 2.359317145629431

Epoch: 431| Step: 0
Training loss: 0.9655268177869446
Validation loss: 2.3398975456041806

Epoch: 6| Step: 1
Training loss: 0.8753387272373939
Validation loss: 2.318707644444435

Epoch: 6| Step: 2
Training loss: 1.4264660170686025
Validation loss: 2.3231697796253776

Epoch: 6| Step: 3
Training loss: 1.4357777105012348
Validation loss: 2.3562822614053904

Epoch: 6| Step: 4
Training loss: 1.5904608051563696
Validation loss: 2.350367291298422

Epoch: 6| Step: 5
Training loss: 1.0590797800661875
Validation loss: 2.297299147584006

Epoch: 6| Step: 6
Training loss: 0.7899719888815477
Validation loss: 2.3290291584703735

Epoch: 6| Step: 7
Training loss: 1.6189923373836825
Validation loss: 2.262880198577204

Epoch: 6| Step: 8
Training loss: 1.0885004221328807
Validation loss: 2.2858685108714747

Epoch: 6| Step: 9
Training loss: 1.3114546291227298
Validation loss: 2.292537991917508

Epoch: 6| Step: 10
Training loss: 0.9176206537478165
Validation loss: 2.258201612428636

Epoch: 6| Step: 11
Training loss: 2.0371332505492035
Validation loss: 2.3249912989984285

Epoch: 6| Step: 12
Training loss: 1.302014839914017
Validation loss: 2.303090666121825

Epoch: 6| Step: 13
Training loss: 1.5449437888576985
Validation loss: 2.332028331312634

Epoch: 432| Step: 0
Training loss: 1.2388831760481953
Validation loss: 2.341151553068105

Epoch: 6| Step: 1
Training loss: 1.5934920008649804
Validation loss: 2.2535595623940914

Epoch: 6| Step: 2
Training loss: 0.7227659812303079
Validation loss: 2.324140872755347

Epoch: 6| Step: 3
Training loss: 1.1617955914181757
Validation loss: 2.3279989152940757

Epoch: 6| Step: 4
Training loss: 1.38703747162536
Validation loss: 2.3210828854371015

Epoch: 6| Step: 5
Training loss: 1.4122044279363235
Validation loss: 2.3073243221478625

Epoch: 6| Step: 6
Training loss: 1.2640324686865922
Validation loss: 2.3213968006719923

Epoch: 6| Step: 7
Training loss: 1.147869826167154
Validation loss: 2.264467704620854

Epoch: 6| Step: 8
Training loss: 1.1515905472589083
Validation loss: 2.280143250184201

Epoch: 6| Step: 9
Training loss: 1.960698208133752
Validation loss: 2.3260389640822567

Epoch: 6| Step: 10
Training loss: 0.9401169808624849
Validation loss: 2.297720235637891

Epoch: 6| Step: 11
Training loss: 0.8242712501329743
Validation loss: 2.2626038297203266

Epoch: 6| Step: 12
Training loss: 1.2400146289700837
Validation loss: 2.360859286201751

Epoch: 6| Step: 13
Training loss: 1.7477936460043164
Validation loss: 2.303724873438772

Epoch: 433| Step: 0
Training loss: 1.3325925746200735
Validation loss: 2.3535222107857203

Epoch: 6| Step: 1
Training loss: 1.4711679886588385
Validation loss: 2.3047165824511007

Epoch: 6| Step: 2
Training loss: 1.7065016145293375
Validation loss: 2.322049070556358

Epoch: 6| Step: 3
Training loss: 1.0351031595686957
Validation loss: 2.308849569497982

Epoch: 6| Step: 4
Training loss: 1.2319073698841376
Validation loss: 2.268491830636965

Epoch: 6| Step: 5
Training loss: 0.9374492313625808
Validation loss: 2.3265172209647886

Epoch: 6| Step: 6
Training loss: 1.1674660714098146
Validation loss: 2.2170290098067786

Epoch: 6| Step: 7
Training loss: 0.8917210510341861
Validation loss: 2.287142462582274

Epoch: 6| Step: 8
Training loss: 2.0696984874048368
Validation loss: 2.322301872568933

Epoch: 6| Step: 9
Training loss: 1.035224653179226
Validation loss: 2.2872951759928273

Epoch: 6| Step: 10
Training loss: 1.0023165335643331
Validation loss: 2.325149996211955

Epoch: 6| Step: 11
Training loss: 0.9993678419418637
Validation loss: 2.358258466236274

Epoch: 6| Step: 12
Training loss: 1.7318935341257997
Validation loss: 2.225217323709453

Epoch: 6| Step: 13
Training loss: 0.6527284184748533
Validation loss: 2.2940095784842516

Epoch: 434| Step: 0
Training loss: 1.1685988343749598
Validation loss: 2.3207007073343315

Epoch: 6| Step: 1
Training loss: 1.3724984040798227
Validation loss: 2.2936714717976208

Epoch: 6| Step: 2
Training loss: 1.1780939012060536
Validation loss: 2.2829333306600974

Epoch: 6| Step: 3
Training loss: 1.201852844240375
Validation loss: 2.257820023500977

Epoch: 6| Step: 4
Training loss: 1.2456709284911536
Validation loss: 2.249952119798648

Epoch: 6| Step: 5
Training loss: 0.8707267090592786
Validation loss: 2.2696599439703764

Epoch: 6| Step: 6
Training loss: 1.2578380890132907
Validation loss: 2.2451357474410516

Epoch: 6| Step: 7
Training loss: 0.7685058268001653
Validation loss: 2.374056052639774

Epoch: 6| Step: 8
Training loss: 1.632340796566469
Validation loss: 2.278115721371584

Epoch: 6| Step: 9
Training loss: 1.0264088833630376
Validation loss: 2.292053675671228

Epoch: 6| Step: 10
Training loss: 1.240354757398852
Validation loss: 2.305019225476864

Epoch: 6| Step: 11
Training loss: 1.1032974432575493
Validation loss: 2.334169001585384

Epoch: 6| Step: 12
Training loss: 2.196970140722184
Validation loss: 2.366629996601319

Epoch: 6| Step: 13
Training loss: 0.9769355976739529
Validation loss: 2.2709225195577596

Epoch: 435| Step: 0
Training loss: 1.236417697837588
Validation loss: 2.3156288728281247

Epoch: 6| Step: 1
Training loss: 0.9990796085500037
Validation loss: 2.3513957239650454

Epoch: 6| Step: 2
Training loss: 1.3934480964512679
Validation loss: 2.2941892294954274

Epoch: 6| Step: 3
Training loss: 0.7896806920267218
Validation loss: 2.285087019680894

Epoch: 6| Step: 4
Training loss: 1.6171344987965213
Validation loss: 2.291616726962287

Epoch: 6| Step: 5
Training loss: 0.8253162904801833
Validation loss: 2.3120280751243825

Epoch: 6| Step: 6
Training loss: 1.6594886065600856
Validation loss: 2.2681692398598003

Epoch: 6| Step: 7
Training loss: 1.9856001908887022
Validation loss: 2.3042431141005357

Epoch: 6| Step: 8
Training loss: 1.120360450303712
Validation loss: 2.3209829114966225

Epoch: 6| Step: 9
Training loss: 1.5736097951765506
Validation loss: 2.310142026086592

Epoch: 6| Step: 10
Training loss: 0.8582772613160478
Validation loss: 2.284582431780295

Epoch: 6| Step: 11
Training loss: 0.9463623459413002
Validation loss: 2.309085839933203

Epoch: 6| Step: 12
Training loss: 1.3276230256138049
Validation loss: 2.3493736217759147

Epoch: 6| Step: 13
Training loss: 1.0645147183297992
Validation loss: 2.2733148670658427

Epoch: 436| Step: 0
Training loss: 1.9609431536467614
Validation loss: 2.296426984555772

Epoch: 6| Step: 1
Training loss: 1.0363443717732672
Validation loss: 2.3197041767840116

Epoch: 6| Step: 2
Training loss: 1.3579568590831528
Validation loss: 2.295619258306181

Epoch: 6| Step: 3
Training loss: 1.0042142284309916
Validation loss: 2.276416455885808

Epoch: 6| Step: 4
Training loss: 1.109229602150734
Validation loss: 2.2774173503264885

Epoch: 6| Step: 5
Training loss: 1.0048794908533536
Validation loss: 2.352755156536683

Epoch: 6| Step: 6
Training loss: 1.3560921941968702
Validation loss: 2.323142999495025

Epoch: 6| Step: 7
Training loss: 1.0964153511329602
Validation loss: 2.3106360363455867

Epoch: 6| Step: 8
Training loss: 1.066224694080287
Validation loss: 2.3164384706143926

Epoch: 6| Step: 9
Training loss: 1.5208940450316613
Validation loss: 2.2879207095323886

Epoch: 6| Step: 10
Training loss: 1.8752677726274656
Validation loss: 2.2842111713416102

Epoch: 6| Step: 11
Training loss: 1.2537659183301757
Validation loss: 2.312654564627245

Epoch: 6| Step: 12
Training loss: 1.0769891698960414
Validation loss: 2.365805684332908

Epoch: 6| Step: 13
Training loss: 0.883508458561715
Validation loss: 2.276927761340203

Epoch: 437| Step: 0
Training loss: 1.560945806013429
Validation loss: 2.299000235456234

Epoch: 6| Step: 1
Training loss: 1.1843972075702869
Validation loss: 2.2867020520946637

Epoch: 6| Step: 2
Training loss: 1.0357621632864729
Validation loss: 2.323551777797138

Epoch: 6| Step: 3
Training loss: 1.6917171060468352
Validation loss: 2.248124626866857

Epoch: 6| Step: 4
Training loss: 1.0444950551143775
Validation loss: 2.2764171574919954

Epoch: 6| Step: 5
Training loss: 0.8371432156471367
Validation loss: 2.27304257750703

Epoch: 6| Step: 6
Training loss: 1.2926077900696211
Validation loss: 2.2753295617023626

Epoch: 6| Step: 7
Training loss: 1.5186126207297237
Validation loss: 2.2810398083075807

Epoch: 6| Step: 8
Training loss: 0.8864525550866139
Validation loss: 2.2723131581293696

Epoch: 6| Step: 9
Training loss: 2.0987573216613327
Validation loss: 2.278795197872577

Epoch: 6| Step: 10
Training loss: 1.1766762606271992
Validation loss: 2.2889644752027687

Epoch: 6| Step: 11
Training loss: 0.7560512092291551
Validation loss: 2.2948795312078887

Epoch: 6| Step: 12
Training loss: 1.035160280615679
Validation loss: 2.270184426355624

Epoch: 6| Step: 13
Training loss: 1.0153810648311437
Validation loss: 2.2918615081233473

Epoch: 438| Step: 0
Training loss: 1.9931127456570625
Validation loss: 2.2333916983724773

Epoch: 6| Step: 1
Training loss: 1.0462654958509467
Validation loss: 2.3570136445151593

Epoch: 6| Step: 2
Training loss: 1.4212159526306483
Validation loss: 2.2253350775579688

Epoch: 6| Step: 3
Training loss: 0.9360552145371396
Validation loss: 2.2827729386807385

Epoch: 6| Step: 4
Training loss: 1.6997246350935915
Validation loss: 2.308972786925954

Epoch: 6| Step: 5
Training loss: 0.759048162382241
Validation loss: 2.3024653964662267

Epoch: 6| Step: 6
Training loss: 1.6742684175829157
Validation loss: 2.252864420348963

Epoch: 6| Step: 7
Training loss: 0.5335824755794254
Validation loss: 2.251514511881923

Epoch: 6| Step: 8
Training loss: 1.5612102526086427
Validation loss: 2.3010931982030582

Epoch: 6| Step: 9
Training loss: 1.3007388179605615
Validation loss: 2.2908862713978753

Epoch: 6| Step: 10
Training loss: 0.9677517577667553
Validation loss: 2.268525161795755

Epoch: 6| Step: 11
Training loss: 0.7423199184143715
Validation loss: 2.32018125114583

Epoch: 6| Step: 12
Training loss: 1.1166215009712444
Validation loss: 2.3023371577188945

Epoch: 6| Step: 13
Training loss: 1.1646582084065489
Validation loss: 2.3081387115679286

Epoch: 439| Step: 0
Training loss: 1.684480579584712
Validation loss: 2.294186331388287

Epoch: 6| Step: 1
Training loss: 0.8710390766588554
Validation loss: 2.2250834300636346

Epoch: 6| Step: 2
Training loss: 1.2461630583714243
Validation loss: 2.2642214185883223

Epoch: 6| Step: 3
Training loss: 1.5574341095385702
Validation loss: 2.2819624240848744

Epoch: 6| Step: 4
Training loss: 1.1245824250797893
Validation loss: 2.3047371031837423

Epoch: 6| Step: 5
Training loss: 2.0873481466831127
Validation loss: 2.224459866773065

Epoch: 6| Step: 6
Training loss: 1.3830523094385514
Validation loss: 2.3237728638061372

Epoch: 6| Step: 7
Training loss: 0.7962897900710666
Validation loss: 2.3285963373224416

Epoch: 6| Step: 8
Training loss: 1.293926702401548
Validation loss: 2.183787928660035

Epoch: 6| Step: 9
Training loss: 0.8381601891466142
Validation loss: 2.279974112724427

Epoch: 6| Step: 10
Training loss: 1.388241214207114
Validation loss: 2.263796576388972

Epoch: 6| Step: 11
Training loss: 0.8803530504490263
Validation loss: 2.3255868551511414

Epoch: 6| Step: 12
Training loss: 1.3642783467215824
Validation loss: 2.339945872942648

Epoch: 6| Step: 13
Training loss: 0.7403951988549887
Validation loss: 2.194692688343329

Epoch: 440| Step: 0
Training loss: 0.8284077431577067
Validation loss: 2.2483122385073298

Epoch: 6| Step: 1
Training loss: 1.1195402114413666
Validation loss: 2.2577163772908975

Epoch: 6| Step: 2
Training loss: 1.4251353852056166
Validation loss: 2.3005238710851734

Epoch: 6| Step: 3
Training loss: 0.8261794502506211
Validation loss: 2.2628413371490828

Epoch: 6| Step: 4
Training loss: 1.2844259395846669
Validation loss: 2.2472279653648153

Epoch: 6| Step: 5
Training loss: 1.141283655077762
Validation loss: 2.2055087790782713

Epoch: 6| Step: 6
Training loss: 1.1466385641831294
Validation loss: 2.3409091246188156

Epoch: 6| Step: 7
Training loss: 1.6559373092579268
Validation loss: 2.350911302757046

Epoch: 6| Step: 8
Training loss: 1.316585268248869
Validation loss: 2.2589420888355067

Epoch: 6| Step: 9
Training loss: 1.3497430097607734
Validation loss: 2.348016283186389

Epoch: 6| Step: 10
Training loss: 1.3129240894904795
Validation loss: 2.252755020005948

Epoch: 6| Step: 11
Training loss: 1.8311581350986361
Validation loss: 2.300482450042058

Epoch: 6| Step: 12
Training loss: 1.1032443362950097
Validation loss: 2.2659861156974586

Epoch: 6| Step: 13
Training loss: 0.9239974078517736
Validation loss: 2.198265370141997

Epoch: 441| Step: 0
Training loss: 1.1210986413084716
Validation loss: 2.233452302152881

Epoch: 6| Step: 1
Training loss: 1.3115575222150875
Validation loss: 2.2969176418422057

Epoch: 6| Step: 2
Training loss: 1.1867783009779025
Validation loss: 2.256991735446196

Epoch: 6| Step: 3
Training loss: 1.3170012535836546
Validation loss: 2.339552602287698

Epoch: 6| Step: 4
Training loss: 0.9621656679388013
Validation loss: 2.272657947424519

Epoch: 6| Step: 5
Training loss: 1.1708243173996495
Validation loss: 2.2413350333057798

Epoch: 6| Step: 6
Training loss: 1.205157013077694
Validation loss: 2.3140555828226215

Epoch: 6| Step: 7
Training loss: 2.1420297955560863
Validation loss: 2.3135854395846502

Epoch: 6| Step: 8
Training loss: 1.7203827472033657
Validation loss: 2.235887006267737

Epoch: 6| Step: 9
Training loss: 1.0215913268019101
Validation loss: 2.2423424664532674

Epoch: 6| Step: 10
Training loss: 1.1098674701925457
Validation loss: 2.344659938484918

Epoch: 6| Step: 11
Training loss: 1.0756241915764617
Validation loss: 2.2458238482500907

Epoch: 6| Step: 12
Training loss: 0.7715992516084387
Validation loss: 2.3169944143884793

Epoch: 6| Step: 13
Training loss: 0.9397453440504939
Validation loss: 2.2306942605311444

Epoch: 442| Step: 0
Training loss: 1.3129602261145943
Validation loss: 2.313505469087128

Epoch: 6| Step: 1
Training loss: 0.8708928992845394
Validation loss: 2.300575068133215

Epoch: 6| Step: 2
Training loss: 1.1991861941612347
Validation loss: 2.3089761877566297

Epoch: 6| Step: 3
Training loss: 1.1794955874332622
Validation loss: 2.330669168339492

Epoch: 6| Step: 4
Training loss: 1.46828282819669
Validation loss: 2.247922610857116

Epoch: 6| Step: 5
Training loss: 1.291530766054579
Validation loss: 2.2168511956524344

Epoch: 6| Step: 6
Training loss: 1.0463467304173732
Validation loss: 2.224464555047855

Epoch: 6| Step: 7
Training loss: 0.8299249485278195
Validation loss: 2.244555354084666

Epoch: 6| Step: 8
Training loss: 1.1275544306099095
Validation loss: 2.2992683192920564

Epoch: 6| Step: 9
Training loss: 2.0800707893063137
Validation loss: 2.314365892456854

Epoch: 6| Step: 10
Training loss: 1.7359694291688403
Validation loss: 2.324473394995582

Epoch: 6| Step: 11
Training loss: 1.149642986359731
Validation loss: 2.299891777889863

Epoch: 6| Step: 12
Training loss: 0.7323955480294415
Validation loss: 2.2139476867498287

Epoch: 6| Step: 13
Training loss: 1.6925234727908136
Validation loss: 2.316445669240566

Epoch: 443| Step: 0
Training loss: 1.2382981452631652
Validation loss: 2.3135858002650673

Epoch: 6| Step: 1
Training loss: 0.7688866253530422
Validation loss: 2.2780312089231445

Epoch: 6| Step: 2
Training loss: 1.3397836032190384
Validation loss: 2.326001607556938

Epoch: 6| Step: 3
Training loss: 2.313569414458178
Validation loss: 2.202890680821478

Epoch: 6| Step: 4
Training loss: 1.0166914402700176
Validation loss: 2.2268474886532093

Epoch: 6| Step: 5
Training loss: 1.3434802827059023
Validation loss: 2.1916809687792496

Epoch: 6| Step: 6
Training loss: 0.9676897338021453
Validation loss: 2.3294390477002467

Epoch: 6| Step: 7
Training loss: 1.0673410978132134
Validation loss: 2.274204210707142

Epoch: 6| Step: 8
Training loss: 0.9864593116462688
Validation loss: 2.283530362763669

Epoch: 6| Step: 9
Training loss: 1.2452731883737624
Validation loss: 2.2540975618050014

Epoch: 6| Step: 10
Training loss: 1.1671122596930292
Validation loss: 2.2844926053973706

Epoch: 6| Step: 11
Training loss: 0.962904614700921
Validation loss: 2.2629900774609952

Epoch: 6| Step: 12
Training loss: 1.1660377078624973
Validation loss: 2.219189613162685

Epoch: 6| Step: 13
Training loss: 1.6606097151828505
Validation loss: 2.2837725728471217

Epoch: 444| Step: 0
Training loss: 1.1445942623772491
Validation loss: 2.245766745541003

Epoch: 6| Step: 1
Training loss: 0.9689126032064412
Validation loss: 2.3182972492459424

Epoch: 6| Step: 2
Training loss: 1.2879662678666999
Validation loss: 2.262746666412385

Epoch: 6| Step: 3
Training loss: 2.116383530110031
Validation loss: 2.257143826214108

Epoch: 6| Step: 4
Training loss: 1.2828900145367854
Validation loss: 2.26052751680935

Epoch: 6| Step: 5
Training loss: 0.9621410741009698
Validation loss: 2.2622977441998566

Epoch: 6| Step: 6
Training loss: 0.8471575557717392
Validation loss: 2.3321827210126944

Epoch: 6| Step: 7
Training loss: 1.2543817016848295
Validation loss: 2.2759584771314088

Epoch: 6| Step: 8
Training loss: 0.9799186105406901
Validation loss: 2.268030914492023

Epoch: 6| Step: 9
Training loss: 0.9879686969574264
Validation loss: 2.3005413649960187

Epoch: 6| Step: 10
Training loss: 1.3678303978114845
Validation loss: 2.317812290236077

Epoch: 6| Step: 11
Training loss: 1.4040970321881463
Validation loss: 2.2399268647840724

Epoch: 6| Step: 12
Training loss: 1.4611846388401257
Validation loss: 2.2921310588192036

Epoch: 6| Step: 13
Training loss: 0.7769096734433482
Validation loss: 2.3145188717866763

Epoch: 445| Step: 0
Training loss: 1.7944771731527906
Validation loss: 2.187689687705276

Epoch: 6| Step: 1
Training loss: 1.0775171307753106
Validation loss: 2.2618943755356793

Epoch: 6| Step: 2
Training loss: 1.4853212251894508
Validation loss: 2.2562099361081036

Epoch: 6| Step: 3
Training loss: 1.4012856064287187
Validation loss: 2.309277401766357

Epoch: 6| Step: 4
Training loss: 0.8840480024673456
Validation loss: 2.339546053882732

Epoch: 6| Step: 5
Training loss: 1.2853508428024691
Validation loss: 2.308869145235746

Epoch: 6| Step: 6
Training loss: 1.08795691789852
Validation loss: 2.2897970450440708

Epoch: 6| Step: 7
Training loss: 0.9023729459985178
Validation loss: 2.288529940385195

Epoch: 6| Step: 8
Training loss: 1.4523506972878821
Validation loss: 2.2987638331341786

Epoch: 6| Step: 9
Training loss: 1.2574991345260402
Validation loss: 2.2926116702777084

Epoch: 6| Step: 10
Training loss: 0.9359548551195396
Validation loss: 2.290314504982384

Epoch: 6| Step: 11
Training loss: 2.0242487043537007
Validation loss: 2.2959068623644407

Epoch: 6| Step: 12
Training loss: 1.0115765799413687
Validation loss: 2.3049144968877853

Epoch: 6| Step: 13
Training loss: 1.2597024591267934
Validation loss: 2.3438559146589735

Epoch: 446| Step: 0
Training loss: 2.062561034253176
Validation loss: 2.287729355204934

Epoch: 6| Step: 1
Training loss: 1.2284313955376103
Validation loss: 2.2406588498578923

Epoch: 6| Step: 2
Training loss: 1.122153123898988
Validation loss: 2.254406002471544

Epoch: 6| Step: 3
Training loss: 0.7167686020267059
Validation loss: 2.3081791036214283

Epoch: 6| Step: 4
Training loss: 0.9435435997815473
Validation loss: 2.303236312982422

Epoch: 6| Step: 5
Training loss: 1.3671277278368235
Validation loss: 2.2949250497754576

Epoch: 6| Step: 6
Training loss: 1.356025339671894
Validation loss: 2.28327616761572

Epoch: 6| Step: 7
Training loss: 0.9597857636577322
Validation loss: 2.3040957767977925

Epoch: 6| Step: 8
Training loss: 1.25122468082447
Validation loss: 2.316279942994493

Epoch: 6| Step: 9
Training loss: 1.3714975485173093
Validation loss: 2.274153248544696

Epoch: 6| Step: 10
Training loss: 1.2455992479815752
Validation loss: 2.2952066679505196

Epoch: 6| Step: 11
Training loss: 1.5469472078366535
Validation loss: 2.3072542292004568

Epoch: 6| Step: 12
Training loss: 0.7581200123219531
Validation loss: 2.2338219780127826

Epoch: 6| Step: 13
Training loss: 0.936602862573127
Validation loss: 2.2909439699969165

Epoch: 447| Step: 0
Training loss: 1.4185520790283053
Validation loss: 2.287579969497384

Epoch: 6| Step: 1
Training loss: 1.2413904283882529
Validation loss: 2.315881376065232

Epoch: 6| Step: 2
Training loss: 1.0859355240399065
Validation loss: 2.2854430220753037

Epoch: 6| Step: 3
Training loss: 0.878899197020312
Validation loss: 2.297097005712153

Epoch: 6| Step: 4
Training loss: 1.2526849045247208
Validation loss: 2.2686219497939173

Epoch: 6| Step: 5
Training loss: 0.6331169902901141
Validation loss: 2.2897116722506965

Epoch: 6| Step: 6
Training loss: 1.2427199080451252
Validation loss: 2.289720185377293

Epoch: 6| Step: 7
Training loss: 1.0033468625010913
Validation loss: 2.318880186767716

Epoch: 6| Step: 8
Training loss: 0.8715837409165654
Validation loss: 2.349229997774742

Epoch: 6| Step: 9
Training loss: 0.9207188743697652
Validation loss: 2.2800403545145986

Epoch: 6| Step: 10
Training loss: 2.199278591825713
Validation loss: 2.3270583328950427

Epoch: 6| Step: 11
Training loss: 1.2893705057869276
Validation loss: 2.3128057431283233

Epoch: 6| Step: 12
Training loss: 0.9937396786711569
Validation loss: 2.3145288681652123

Epoch: 6| Step: 13
Training loss: 1.6251646105215016
Validation loss: 2.3231965142036475

Epoch: 448| Step: 0
Training loss: 0.971068653080075
Validation loss: 2.2988989644130062

Epoch: 6| Step: 1
Training loss: 0.9759868909080517
Validation loss: 2.3050985018145904

Epoch: 6| Step: 2
Training loss: 1.4888154920750754
Validation loss: 2.2918457371469803

Epoch: 6| Step: 3
Training loss: 1.2916920977314201
Validation loss: 2.228121493701989

Epoch: 6| Step: 4
Training loss: 0.9736434645151386
Validation loss: 2.2869461973887777

Epoch: 6| Step: 5
Training loss: 0.8839473350812279
Validation loss: 2.2229856092108347

Epoch: 6| Step: 6
Training loss: 1.3873237686960993
Validation loss: 2.295748682748586

Epoch: 6| Step: 7
Training loss: 0.9789833275969978
Validation loss: 2.2587693537920948

Epoch: 6| Step: 8
Training loss: 2.053703855900475
Validation loss: 2.2846700822364974

Epoch: 6| Step: 9
Training loss: 1.2232003753157565
Validation loss: 2.2771867996200537

Epoch: 6| Step: 10
Training loss: 1.2371986060669007
Validation loss: 2.2804697798093803

Epoch: 6| Step: 11
Training loss: 1.0717077141391156
Validation loss: 2.2563899914448093

Epoch: 6| Step: 12
Training loss: 1.5980252536979191
Validation loss: 2.2347723907741055

Epoch: 6| Step: 13
Training loss: 1.605501049301579
Validation loss: 2.330735494926213

Epoch: 449| Step: 0
Training loss: 1.2324182960712198
Validation loss: 2.2740683154575976

Epoch: 6| Step: 1
Training loss: 1.1021147621927918
Validation loss: 2.2734283051274713

Epoch: 6| Step: 2
Training loss: 0.9362113042660317
Validation loss: 2.2727129678565006

Epoch: 6| Step: 3
Training loss: 1.0408801479109222
Validation loss: 2.3303120788782334

Epoch: 6| Step: 4
Training loss: 1.5416855510208034
Validation loss: 2.260876651637378

Epoch: 6| Step: 5
Training loss: 0.605644692729685
Validation loss: 2.3411226680820962

Epoch: 6| Step: 6
Training loss: 1.1463875152899683
Validation loss: 2.298156805866096

Epoch: 6| Step: 7
Training loss: 1.3494867691459955
Validation loss: 2.277762401051029

Epoch: 6| Step: 8
Training loss: 1.1816038015633745
Validation loss: 2.31911543059028

Epoch: 6| Step: 9
Training loss: 1.5496627656101603
Validation loss: 2.3225539516694766

Epoch: 6| Step: 10
Training loss: 1.054985512909699
Validation loss: 2.251079845970707

Epoch: 6| Step: 11
Training loss: 0.9800610549553148
Validation loss: 2.2577915576023595

Epoch: 6| Step: 12
Training loss: 1.857942430012886
Validation loss: 2.364318070235491

Epoch: 6| Step: 13
Training loss: 1.0904122787307613
Validation loss: 2.3261464982374753

Epoch: 450| Step: 0
Training loss: 0.9282916513453237
Validation loss: 2.3065002820494738

Epoch: 6| Step: 1
Training loss: 1.3756321840908918
Validation loss: 2.2895732145975916

Epoch: 6| Step: 2
Training loss: 1.1042315565991105
Validation loss: 2.341057935641504

Epoch: 6| Step: 3
Training loss: 1.3532359176881184
Validation loss: 2.2627624923506215

Epoch: 6| Step: 4
Training loss: 1.4270095342038251
Validation loss: 2.273431917282437

Epoch: 6| Step: 5
Training loss: 1.0230328873897605
Validation loss: 2.276618827084541

Epoch: 6| Step: 6
Training loss: 0.9385647131954796
Validation loss: 2.3158706648757854

Epoch: 6| Step: 7
Training loss: 1.2531704749325023
Validation loss: 2.2885966935952156

Epoch: 6| Step: 8
Training loss: 0.7260983122552386
Validation loss: 2.185992021446678

Epoch: 6| Step: 9
Training loss: 1.1858869438804345
Validation loss: 2.2362403876419954

Epoch: 6| Step: 10
Training loss: 2.0873353539141015
Validation loss: 2.312412776926179

Epoch: 6| Step: 11
Training loss: 0.7684760435163989
Validation loss: 2.284069994594548

Epoch: 6| Step: 12
Training loss: 1.2015575751115646
Validation loss: 2.2506223613145817

Epoch: 6| Step: 13
Training loss: 1.2725821588819861
Validation loss: 2.2840093972274174

Epoch: 451| Step: 0
Training loss: 0.7249962116010935
Validation loss: 2.334441188064953

Epoch: 6| Step: 1
Training loss: 1.0329533006317424
Validation loss: 2.3177426958641973

Epoch: 6| Step: 2
Training loss: 0.7262209427842844
Validation loss: 2.272412441882719

Epoch: 6| Step: 3
Training loss: 0.8088838360993094
Validation loss: 2.2873138532206636

Epoch: 6| Step: 4
Training loss: 2.105778206074878
Validation loss: 2.2667142677406025

Epoch: 6| Step: 5
Training loss: 0.9316142336388227
Validation loss: 2.337052273015062

Epoch: 6| Step: 6
Training loss: 1.6332728270916848
Validation loss: 2.326623069740403

Epoch: 6| Step: 7
Training loss: 1.0415712630769967
Validation loss: 2.276150159886869

Epoch: 6| Step: 8
Training loss: 1.4150024999050528
Validation loss: 2.2931108490271694

Epoch: 6| Step: 9
Training loss: 1.366738905199289
Validation loss: 2.2140117661943024

Epoch: 6| Step: 10
Training loss: 1.1979518498215889
Validation loss: 2.277186962860012

Epoch: 6| Step: 11
Training loss: 1.2128229045544487
Validation loss: 2.3281430512635763

Epoch: 6| Step: 12
Training loss: 1.227339480251216
Validation loss: 2.2389185986141

Epoch: 6| Step: 13
Training loss: 1.5307032329088317
Validation loss: 2.340083040016107

Epoch: 452| Step: 0
Training loss: 1.2782796994628753
Validation loss: 2.2540595629007556

Epoch: 6| Step: 1
Training loss: 0.9224522609815524
Validation loss: 2.2075333956472036

Epoch: 6| Step: 2
Training loss: 1.60502124498989
Validation loss: 2.3046783335847403

Epoch: 6| Step: 3
Training loss: 1.2818478840787526
Validation loss: 2.267389278015696

Epoch: 6| Step: 4
Training loss: 1.3480076428488204
Validation loss: 2.19711940994434

Epoch: 6| Step: 5
Training loss: 0.6100268423318782
Validation loss: 2.281469014580833

Epoch: 6| Step: 6
Training loss: 1.2250287130455146
Validation loss: 2.2675209946550283

Epoch: 6| Step: 7
Training loss: 1.0568189206125431
Validation loss: 2.2951314733647314

Epoch: 6| Step: 8
Training loss: 1.1280946553130304
Validation loss: 2.274473590702587

Epoch: 6| Step: 9
Training loss: 1.0102700720296136
Validation loss: 2.2648953324698633

Epoch: 6| Step: 10
Training loss: 1.0190875377696713
Validation loss: 2.264253024263665

Epoch: 6| Step: 11
Training loss: 1.1292648010027104
Validation loss: 2.3291673877952768

Epoch: 6| Step: 12
Training loss: 1.082525147460905
Validation loss: 2.294673994366393

Epoch: 6| Step: 13
Training loss: 2.489263367674755
Validation loss: 2.2396519983577496

Epoch: 453| Step: 0
Training loss: 0.9879034473677607
Validation loss: 2.2818051127905705

Epoch: 6| Step: 1
Training loss: 1.4116750553126567
Validation loss: 2.2828086526926508

Epoch: 6| Step: 2
Training loss: 0.8411584189844382
Validation loss: 2.267037382188047

Epoch: 6| Step: 3
Training loss: 1.4557835040474727
Validation loss: 2.26935895494857

Epoch: 6| Step: 4
Training loss: 0.9047157520369562
Validation loss: 2.2884409300422033

Epoch: 6| Step: 5
Training loss: 1.07757344166002
Validation loss: 2.2865183825155593

Epoch: 6| Step: 6
Training loss: 1.4808106040319362
Validation loss: 2.2610673810376722

Epoch: 6| Step: 7
Training loss: 1.027237571189929
Validation loss: 2.267441778357071

Epoch: 6| Step: 8
Training loss: 1.1057146425711308
Validation loss: 2.292461505956361

Epoch: 6| Step: 9
Training loss: 1.1099315912628693
Validation loss: 2.258580284464291

Epoch: 6| Step: 10
Training loss: 0.9060658234859418
Validation loss: 2.3083026386580747

Epoch: 6| Step: 11
Training loss: 1.7988009538783283
Validation loss: 2.320049337395361

Epoch: 6| Step: 12
Training loss: 1.8473800872168964
Validation loss: 2.2751669339165335

Epoch: 6| Step: 13
Training loss: 1.4257666182093827
Validation loss: 2.2779604121349446

Epoch: 454| Step: 0
Training loss: 0.8587247989738154
Validation loss: 2.2467076712104936

Epoch: 6| Step: 1
Training loss: 1.9668553030205398
Validation loss: 2.281215717475563

Epoch: 6| Step: 2
Training loss: 1.3915287467243374
Validation loss: 2.305040079257344

Epoch: 6| Step: 3
Training loss: 1.1626906536001906
Validation loss: 2.307482868974863

Epoch: 6| Step: 4
Training loss: 1.3256371028047305
Validation loss: 2.2975489386860244

Epoch: 6| Step: 5
Training loss: 0.7346642107336923
Validation loss: 2.2353316712302065

Epoch: 6| Step: 6
Training loss: 1.6419194519043094
Validation loss: 2.244929220342373

Epoch: 6| Step: 7
Training loss: 0.9564287741603981
Validation loss: 2.2902025883962023

Epoch: 6| Step: 8
Training loss: 1.0725327456083669
Validation loss: 2.2227041611066416

Epoch: 6| Step: 9
Training loss: 0.9405191127451392
Validation loss: 2.24764643393063

Epoch: 6| Step: 10
Training loss: 0.7058465843540666
Validation loss: 2.261011247241241

Epoch: 6| Step: 11
Training loss: 1.1462948592132516
Validation loss: 2.3129349498787364

Epoch: 6| Step: 12
Training loss: 1.5204265085189113
Validation loss: 2.3154292172173236

Epoch: 6| Step: 13
Training loss: 1.0539645507613027
Validation loss: 2.2567736028142122

Epoch: 455| Step: 0
Training loss: 1.122778606715445
Validation loss: 2.2818007715272506

Epoch: 6| Step: 1
Training loss: 1.2211114551434559
Validation loss: 2.314369665305787

Epoch: 6| Step: 2
Training loss: 1.0292597552271068
Validation loss: 2.305047580961156

Epoch: 6| Step: 3
Training loss: 1.5199179659841953
Validation loss: 2.317622493542923

Epoch: 6| Step: 4
Training loss: 1.8582129172868431
Validation loss: 2.2197225104056875

Epoch: 6| Step: 5
Training loss: 1.2612369904919942
Validation loss: 2.2647238702031176

Epoch: 6| Step: 6
Training loss: 1.0585526461908688
Validation loss: 2.2485859055050903

Epoch: 6| Step: 7
Training loss: 1.1123792775692682
Validation loss: 2.2749367501509505

Epoch: 6| Step: 8
Training loss: 1.2201737133236543
Validation loss: 2.2587405264468416

Epoch: 6| Step: 9
Training loss: 0.7267975785802416
Validation loss: 2.235867092243139

Epoch: 6| Step: 10
Training loss: 1.4200553568943315
Validation loss: 2.2560585806587548

Epoch: 6| Step: 11
Training loss: 1.914904101886407
Validation loss: 2.2889463899283364

Epoch: 6| Step: 12
Training loss: 0.883653088642197
Validation loss: 2.234264710390125

Epoch: 6| Step: 13
Training loss: 0.846354984380865
Validation loss: 2.2904562739602614

Epoch: 456| Step: 0
Training loss: 1.1065894064208146
Validation loss: 2.2013701559339194

Epoch: 6| Step: 1
Training loss: 1.1218225854727084
Validation loss: 2.2407279963925535

Epoch: 6| Step: 2
Training loss: 0.7378256466771549
Validation loss: 2.2446098595673494

Epoch: 6| Step: 3
Training loss: 1.0837305820049852
Validation loss: 2.2736443691633546

Epoch: 6| Step: 4
Training loss: 1.0210865770597333
Validation loss: 2.3028119864837353

Epoch: 6| Step: 5
Training loss: 0.9813494431468675
Validation loss: 2.373272069700232

Epoch: 6| Step: 6
Training loss: 1.2699238800906003
Validation loss: 2.191307454184147

Epoch: 6| Step: 7
Training loss: 1.2217047648367942
Validation loss: 2.293049783300791

Epoch: 6| Step: 8
Training loss: 1.371114181844514
Validation loss: 2.2641714285359926

Epoch: 6| Step: 9
Training loss: 1.9583686933639306
Validation loss: 2.338198101434013

Epoch: 6| Step: 10
Training loss: 1.3180054139994217
Validation loss: 2.248302988770902

Epoch: 6| Step: 11
Training loss: 1.149739260761681
Validation loss: 2.283618812493248

Epoch: 6| Step: 12
Training loss: 1.2469661134399872
Validation loss: 2.2125973988660323

Epoch: 6| Step: 13
Training loss: 1.1536866203084455
Validation loss: 2.343433676535417

Epoch: 457| Step: 0
Training loss: 1.1930142916697075
Validation loss: 2.302747639964698

Epoch: 6| Step: 1
Training loss: 0.9336598584379604
Validation loss: 2.244170826794973

Epoch: 6| Step: 2
Training loss: 1.0716546546733499
Validation loss: 2.2896984638820737

Epoch: 6| Step: 3
Training loss: 1.5036147590635396
Validation loss: 2.273524180763766

Epoch: 6| Step: 4
Training loss: 1.197327355540532
Validation loss: 2.219056555001291

Epoch: 6| Step: 5
Training loss: 1.012635393862327
Validation loss: 2.2362571142242578

Epoch: 6| Step: 6
Training loss: 1.1117831138481344
Validation loss: 2.2340647697712894

Epoch: 6| Step: 7
Training loss: 1.178012644219017
Validation loss: 2.255218563432237

Epoch: 6| Step: 8
Training loss: 1.8973768748668622
Validation loss: 2.330751348680837

Epoch: 6| Step: 9
Training loss: 1.0731633220710737
Validation loss: 2.2889373867180085

Epoch: 6| Step: 10
Training loss: 1.3130383976698827
Validation loss: 2.23036023964984

Epoch: 6| Step: 11
Training loss: 1.0441693885343553
Validation loss: 2.2053465140753157

Epoch: 6| Step: 12
Training loss: 0.8290940858393745
Validation loss: 2.266006361251442

Epoch: 6| Step: 13
Training loss: 1.3296620170401674
Validation loss: 2.33409889102614

Epoch: 458| Step: 0
Training loss: 1.2420490115718488
Validation loss: 2.3023876819946696

Epoch: 6| Step: 1
Training loss: 1.9780225224037142
Validation loss: 2.2384971802698326

Epoch: 6| Step: 2
Training loss: 1.2576915611744066
Validation loss: 2.3069479925788

Epoch: 6| Step: 3
Training loss: 0.8240744297175249
Validation loss: 2.283452210439215

Epoch: 6| Step: 4
Training loss: 1.534613360441692
Validation loss: 2.275306870458868

Epoch: 6| Step: 5
Training loss: 1.1478868059450353
Validation loss: 2.311770020453163

Epoch: 6| Step: 6
Training loss: 0.9264939538518575
Validation loss: 2.2684709065919084

Epoch: 6| Step: 7
Training loss: 1.1740743217045706
Validation loss: 2.2647093940091017

Epoch: 6| Step: 8
Training loss: 0.9649665846993534
Validation loss: 2.2972078688368454

Epoch: 6| Step: 9
Training loss: 0.9223104838440814
Validation loss: 2.1862815627851755

Epoch: 6| Step: 10
Training loss: 1.2328479834261956
Validation loss: 2.278145316895777

Epoch: 6| Step: 11
Training loss: 1.1971075504366
Validation loss: 2.2642691453715327

Epoch: 6| Step: 12
Training loss: 0.9290874051099408
Validation loss: 2.3034200674365883

Epoch: 6| Step: 13
Training loss: 1.4345992301586792
Validation loss: 2.257681484759309

Epoch: 459| Step: 0
Training loss: 1.047459794868445
Validation loss: 2.327010390107853

Epoch: 6| Step: 1
Training loss: 1.1041952825233028
Validation loss: 2.3392040243655643

Epoch: 6| Step: 2
Training loss: 1.3041885244144558
Validation loss: 2.2674565483108955

Epoch: 6| Step: 3
Training loss: 1.1273009822819862
Validation loss: 2.275172910415167

Epoch: 6| Step: 4
Training loss: 1.065362999889335
Validation loss: 2.27428713901727

Epoch: 6| Step: 5
Training loss: 1.1644198490009152
Validation loss: 2.3036428301314555

Epoch: 6| Step: 6
Training loss: 1.1033893884343189
Validation loss: 2.2712410057278474

Epoch: 6| Step: 7
Training loss: 0.9308340231660377
Validation loss: 2.322241524220849

Epoch: 6| Step: 8
Training loss: 0.7504324461022623
Validation loss: 2.324706610539357

Epoch: 6| Step: 9
Training loss: 2.147600378459429
Validation loss: 2.259938650301299

Epoch: 6| Step: 10
Training loss: 1.762202498846866
Validation loss: 2.271428076524718

Epoch: 6| Step: 11
Training loss: 0.8673783856875713
Validation loss: 2.286873386898618

Epoch: 6| Step: 12
Training loss: 1.0317421519057481
Validation loss: 2.264506454363551

Epoch: 6| Step: 13
Training loss: 0.8661478701300117
Validation loss: 2.2079074251168196

Epoch: 460| Step: 0
Training loss: 1.0807083801966855
Validation loss: 2.272517049068393

Epoch: 6| Step: 1
Training loss: 0.900233588105374
Validation loss: 2.236574611539927

Epoch: 6| Step: 2
Training loss: 1.9817918199053723
Validation loss: 2.3092076351008846

Epoch: 6| Step: 3
Training loss: 1.2299301664175557
Validation loss: 2.293618306579656

Epoch: 6| Step: 4
Training loss: 1.3214802290050522
Validation loss: 2.2322620291591413

Epoch: 6| Step: 5
Training loss: 0.7423550466851409
Validation loss: 2.2749883844132492

Epoch: 6| Step: 6
Training loss: 0.8407014946717477
Validation loss: 2.268162020822302

Epoch: 6| Step: 7
Training loss: 1.1918701269393224
Validation loss: 2.265373453073339

Epoch: 6| Step: 8
Training loss: 1.156536582279135
Validation loss: 2.274046125981375

Epoch: 6| Step: 9
Training loss: 0.9878742148777437
Validation loss: 2.2424487684589858

Epoch: 6| Step: 10
Training loss: 1.3108403748462383
Validation loss: 2.3336159217103876

Epoch: 6| Step: 11
Training loss: 0.947747239841637
Validation loss: 2.257961164546943

Epoch: 6| Step: 12
Training loss: 1.1345336992210826
Validation loss: 2.28504452505447

Epoch: 6| Step: 13
Training loss: 1.0978610027662694
Validation loss: 2.30520367703622

Epoch: 461| Step: 0
Training loss: 0.782992555845982
Validation loss: 2.2595329748096984

Epoch: 6| Step: 1
Training loss: 1.4294801989074921
Validation loss: 2.3259802761321384

Epoch: 6| Step: 2
Training loss: 1.2572747259676411
Validation loss: 2.2709134674684743

Epoch: 6| Step: 3
Training loss: 1.009707716677748
Validation loss: 2.2956597413771007

Epoch: 6| Step: 4
Training loss: 1.3910380403704603
Validation loss: 2.306461409754434

Epoch: 6| Step: 5
Training loss: 1.2311034488114372
Validation loss: 2.2278023992777047

Epoch: 6| Step: 6
Training loss: 1.0879287576070493
Validation loss: 2.300141421183972

Epoch: 6| Step: 7
Training loss: 0.7626282568453899
Validation loss: 2.3601144437205424

Epoch: 6| Step: 8
Training loss: 1.1816225665265248
Validation loss: 2.3095404764125838

Epoch: 6| Step: 9
Training loss: 2.1120720469367082
Validation loss: 2.314842186505045

Epoch: 6| Step: 10
Training loss: 1.086830266171227
Validation loss: 2.204352971098105

Epoch: 6| Step: 11
Training loss: 1.3180379292004363
Validation loss: 2.2468586382339417

Epoch: 6| Step: 12
Training loss: 0.7607855925217671
Validation loss: 2.278172763828064

Epoch: 6| Step: 13
Training loss: 0.551164723545237
Validation loss: 2.2829207790315937

Epoch: 462| Step: 0
Training loss: 1.2809597710122602
Validation loss: 2.328829165302182

Epoch: 6| Step: 1
Training loss: 1.2137891110562717
Validation loss: 2.2816366575142033

Epoch: 6| Step: 2
Training loss: 1.2616283750497417
Validation loss: 2.33810357355823

Epoch: 6| Step: 3
Training loss: 1.162744787551853
Validation loss: 2.2858266891160355

Epoch: 6| Step: 4
Training loss: 1.0500263210812284
Validation loss: 2.2476604745364734

Epoch: 6| Step: 5
Training loss: 0.7907394492198943
Validation loss: 2.326390414930551

Epoch: 6| Step: 6
Training loss: 0.9271449736487657
Validation loss: 2.2223361686834724

Epoch: 6| Step: 7
Training loss: 1.784919439255612
Validation loss: 2.289796663262842

Epoch: 6| Step: 8
Training loss: 1.976386805027125
Validation loss: 2.227460981660534

Epoch: 6| Step: 9
Training loss: 1.1935658377749396
Validation loss: 2.28454061341341

Epoch: 6| Step: 10
Training loss: 0.8945805898327298
Validation loss: 2.2771711994549837

Epoch: 6| Step: 11
Training loss: 0.7856218466319891
Validation loss: 2.1488905085088033

Epoch: 6| Step: 12
Training loss: 0.845740548730825
Validation loss: 2.2496120170780296

Epoch: 6| Step: 13
Training loss: 0.9830196071427256
Validation loss: 2.331035092688507

Epoch: 463| Step: 0
Training loss: 1.0870015262533386
Validation loss: 2.2679603622426274

Epoch: 6| Step: 1
Training loss: 1.2478985287850615
Validation loss: 2.2141531386471165

Epoch: 6| Step: 2
Training loss: 1.8965549632645693
Validation loss: 2.22460032345299

Epoch: 6| Step: 3
Training loss: 1.1850393299223574
Validation loss: 2.2177271364973055

Epoch: 6| Step: 4
Training loss: 0.8670075375890374
Validation loss: 2.2732607385815085

Epoch: 6| Step: 5
Training loss: 1.4374407880446838
Validation loss: 2.2458609757044594

Epoch: 6| Step: 6
Training loss: 1.2854062564784843
Validation loss: 2.2672813768054567

Epoch: 6| Step: 7
Training loss: 1.0255335535617038
Validation loss: 2.2555113577020256

Epoch: 6| Step: 8
Training loss: 1.0860832171477504
Validation loss: 2.3402273809390253

Epoch: 6| Step: 9
Training loss: 1.1750577303725345
Validation loss: 2.2792897058280994

Epoch: 6| Step: 10
Training loss: 0.9443815391914988
Validation loss: 2.249862623407545

Epoch: 6| Step: 11
Training loss: 0.9943417868351295
Validation loss: 2.2744038971369207

Epoch: 6| Step: 12
Training loss: 1.0769776583296136
Validation loss: 2.257100135938025

Epoch: 6| Step: 13
Training loss: 1.2416452147830377
Validation loss: 2.262860039478772

Epoch: 464| Step: 0
Training loss: 1.2457080590959921
Validation loss: 2.33916384500653

Epoch: 6| Step: 1
Training loss: 0.7924958872161909
Validation loss: 2.241130680273039

Epoch: 6| Step: 2
Training loss: 1.0734325514322571
Validation loss: 2.2481947633431267

Epoch: 6| Step: 3
Training loss: 0.7511393317335906
Validation loss: 2.2319306573043933

Epoch: 6| Step: 4
Training loss: 1.085120298423113
Validation loss: 2.328004113050059

Epoch: 6| Step: 5
Training loss: 1.5469164601944594
Validation loss: 2.3014030351064427

Epoch: 6| Step: 6
Training loss: 1.3957995035807138
Validation loss: 2.278699234625312

Epoch: 6| Step: 7
Training loss: 1.1639189151561846
Validation loss: 2.3179659755664788

Epoch: 6| Step: 8
Training loss: 1.1496038417961685
Validation loss: 2.196283414121014

Epoch: 6| Step: 9
Training loss: 2.029255283726215
Validation loss: 2.253220792656419

Epoch: 6| Step: 10
Training loss: 1.3430712116560173
Validation loss: 2.220313114194088

Epoch: 6| Step: 11
Training loss: 1.2399308441474175
Validation loss: 2.352246160951336

Epoch: 6| Step: 12
Training loss: 1.05359372537956
Validation loss: 2.27263882487291

Epoch: 6| Step: 13
Training loss: 0.70856452890055
Validation loss: 2.2420070718947898

Epoch: 465| Step: 0
Training loss: 1.1760387962358088
Validation loss: 2.2910970440454896

Epoch: 6| Step: 1
Training loss: 2.211892504723865
Validation loss: 2.1935535224776626

Epoch: 6| Step: 2
Training loss: 1.1243527987940467
Validation loss: 2.2653371444880177

Epoch: 6| Step: 3
Training loss: 1.4251935191677083
Validation loss: 2.3013449279816656

Epoch: 6| Step: 4
Training loss: 0.9658429612762433
Validation loss: 2.3232315676283397

Epoch: 6| Step: 5
Training loss: 1.0976347463001526
Validation loss: 2.228531178088367

Epoch: 6| Step: 6
Training loss: 1.2425174874623617
Validation loss: 2.2968018468319156

Epoch: 6| Step: 7
Training loss: 1.141488466950619
Validation loss: 2.3206025110124244

Epoch: 6| Step: 8
Training loss: 0.8821571415681781
Validation loss: 2.2735295504195596

Epoch: 6| Step: 9
Training loss: 1.261691066568154
Validation loss: 2.285883905884938

Epoch: 6| Step: 10
Training loss: 1.1274861309949393
Validation loss: 2.251354441085557

Epoch: 6| Step: 11
Training loss: 0.7541771831797869
Validation loss: 2.198201077754258

Epoch: 6| Step: 12
Training loss: 0.7859498752962042
Validation loss: 2.206669163746963

Epoch: 6| Step: 13
Training loss: 1.1060546292994258
Validation loss: 2.2695825678397306

Epoch: 466| Step: 0
Training loss: 1.0400754537170578
Validation loss: 2.2724992931710566

Epoch: 6| Step: 1
Training loss: 1.964779862261996
Validation loss: 2.2664394726557737

Epoch: 6| Step: 2
Training loss: 1.1356829876284456
Validation loss: 2.2819248672825374

Epoch: 6| Step: 3
Training loss: 1.0427947167059681
Validation loss: 2.2614442978761677

Epoch: 6| Step: 4
Training loss: 0.7792444809053339
Validation loss: 2.245243241126409

Epoch: 6| Step: 5
Training loss: 1.1303599676322034
Validation loss: 2.2449791067244567

Epoch: 6| Step: 6
Training loss: 1.593429084332169
Validation loss: 2.3809122115729844

Epoch: 6| Step: 7
Training loss: 1.1264277511197676
Validation loss: 2.3040184310953657

Epoch: 6| Step: 8
Training loss: 0.721817519636617
Validation loss: 2.2293913646251826

Epoch: 6| Step: 9
Training loss: 1.5585342434109433
Validation loss: 2.2744335601219876

Epoch: 6| Step: 10
Training loss: 1.1770795073770555
Validation loss: 2.2610762905680084

Epoch: 6| Step: 11
Training loss: 0.6711801440014087
Validation loss: 2.265761235334516

Epoch: 6| Step: 12
Training loss: 0.9164002999635337
Validation loss: 2.243230351869978

Epoch: 6| Step: 13
Training loss: 1.3900451737205615
Validation loss: 2.262769096986028

Epoch: 467| Step: 0
Training loss: 1.3076127203935553
Validation loss: 2.2521231147197307

Epoch: 6| Step: 1
Training loss: 0.6983712883955286
Validation loss: 2.3015680396681373

Epoch: 6| Step: 2
Training loss: 1.0210502679464228
Validation loss: 2.286123757839137

Epoch: 6| Step: 3
Training loss: 0.9924497483068998
Validation loss: 2.2491864769796646

Epoch: 6| Step: 4
Training loss: 1.300143752953188
Validation loss: 2.26668426905257

Epoch: 6| Step: 5
Training loss: 0.8208165391343201
Validation loss: 2.254493040844325

Epoch: 6| Step: 6
Training loss: 1.9340416591776959
Validation loss: 2.2882987656472604

Epoch: 6| Step: 7
Training loss: 1.0609736979942967
Validation loss: 2.289405084548444

Epoch: 6| Step: 8
Training loss: 1.048768679392241
Validation loss: 2.2985121798197534

Epoch: 6| Step: 9
Training loss: 1.632478962831348
Validation loss: 2.2290057527803375

Epoch: 6| Step: 10
Training loss: 1.2400737027599096
Validation loss: 2.3130547618293402

Epoch: 6| Step: 11
Training loss: 1.4743483962973443
Validation loss: 2.2425229327355285

Epoch: 6| Step: 12
Training loss: 0.7439150731237137
Validation loss: 2.273468875502881

Epoch: 6| Step: 13
Training loss: 1.0181904595994544
Validation loss: 2.2303555499747807

Epoch: 468| Step: 0
Training loss: 1.0536321375445914
Validation loss: 2.243944630742233

Epoch: 6| Step: 1
Training loss: 1.1790696604066664
Validation loss: 2.2496261286057866

Epoch: 6| Step: 2
Training loss: 1.4617497435260127
Validation loss: 2.2846182695542634

Epoch: 6| Step: 3
Training loss: 0.981336870417967
Validation loss: 2.2330507398183577

Epoch: 6| Step: 4
Training loss: 1.1432353419989405
Validation loss: 2.3198621084944566

Epoch: 6| Step: 5
Training loss: 0.5685505234235931
Validation loss: 2.2902120562169905

Epoch: 6| Step: 6
Training loss: 0.8061934148167942
Validation loss: 2.238204224847905

Epoch: 6| Step: 7
Training loss: 1.1736454115350223
Validation loss: 2.3199557853345287

Epoch: 6| Step: 8
Training loss: 1.3055371470314634
Validation loss: 2.230877891573988

Epoch: 6| Step: 9
Training loss: 0.9035687079299816
Validation loss: 2.295492149264249

Epoch: 6| Step: 10
Training loss: 0.9056229230542321
Validation loss: 2.3344260034569477

Epoch: 6| Step: 11
Training loss: 2.025992294010672
Validation loss: 2.2421605770024953

Epoch: 6| Step: 12
Training loss: 0.9897136635870805
Validation loss: 2.2069740171105456

Epoch: 6| Step: 13
Training loss: 0.6425791221541346
Validation loss: 2.254532531716221

Epoch: 469| Step: 0
Training loss: 0.8588710694570797
Validation loss: 2.249909966557731

Epoch: 6| Step: 1
Training loss: 2.1480022197548534
Validation loss: 2.305859000503276

Epoch: 6| Step: 2
Training loss: 0.7381356716434333
Validation loss: 2.236877777377804

Epoch: 6| Step: 3
Training loss: 0.8909653130575035
Validation loss: 2.3196397816237266

Epoch: 6| Step: 4
Training loss: 1.2659787284184933
Validation loss: 2.386370748083048

Epoch: 6| Step: 5
Training loss: 1.2454809996213454
Validation loss: 2.3541924593818666

Epoch: 6| Step: 6
Training loss: 1.2312817990606861
Validation loss: 2.1996559707025285

Epoch: 6| Step: 7
Training loss: 1.0852201548710148
Validation loss: 2.253855325942479

Epoch: 6| Step: 8
Training loss: 0.784360073905057
Validation loss: 2.2693733130867253

Epoch: 6| Step: 9
Training loss: 1.2535371326231186
Validation loss: 2.191970729681463

Epoch: 6| Step: 10
Training loss: 0.8495672105871734
Validation loss: 2.2726932865526104

Epoch: 6| Step: 11
Training loss: 0.8295029386430393
Validation loss: 2.285871821587572

Epoch: 6| Step: 12
Training loss: 1.0881095405720582
Validation loss: 2.242984035265258

Epoch: 6| Step: 13
Training loss: 1.3213853709328403
Validation loss: 2.2582595819131317

Epoch: 470| Step: 0
Training loss: 1.4199756050700802
Validation loss: 2.2815744054456535

Epoch: 6| Step: 1
Training loss: 0.9613740751157623
Validation loss: 2.209100742777872

Epoch: 6| Step: 2
Training loss: 0.9473742550571289
Validation loss: 2.2692232010969686

Epoch: 6| Step: 3
Training loss: 1.0076698971186662
Validation loss: 2.2976993144466777

Epoch: 6| Step: 4
Training loss: 0.7949954287079675
Validation loss: 2.3605172203198634

Epoch: 6| Step: 5
Training loss: 1.8830310488920008
Validation loss: 2.3083106531356004

Epoch: 6| Step: 6
Training loss: 1.1594765467013397
Validation loss: 2.2406352952024493

Epoch: 6| Step: 7
Training loss: 0.93783747638822
Validation loss: 2.298102188226265

Epoch: 6| Step: 8
Training loss: 1.1383482798762874
Validation loss: 2.257879420354373

Epoch: 6| Step: 9
Training loss: 1.1732327542942624
Validation loss: 2.3199405393434707

Epoch: 6| Step: 10
Training loss: 1.2456675311769407
Validation loss: 2.237076836867038

Epoch: 6| Step: 11
Training loss: 0.9622224729648741
Validation loss: 2.2569579755463183

Epoch: 6| Step: 12
Training loss: 1.2256199805406403
Validation loss: 2.2583825834092837

Epoch: 6| Step: 13
Training loss: 0.978057784674715
Validation loss: 2.2431518252065095

Epoch: 471| Step: 0
Training loss: 0.9182945160413016
Validation loss: 2.3065282379526226

Epoch: 6| Step: 1
Training loss: 1.0566918436494637
Validation loss: 2.2886439008612847

Epoch: 6| Step: 2
Training loss: 1.2788816753769163
Validation loss: 2.286980834553491

Epoch: 6| Step: 3
Training loss: 0.6932111984740652
Validation loss: 2.334632104640789

Epoch: 6| Step: 4
Training loss: 2.097969472221193
Validation loss: 2.301671096789059

Epoch: 6| Step: 5
Training loss: 1.0708931788681189
Validation loss: 2.265384581825665

Epoch: 6| Step: 6
Training loss: 1.1621610742176653
Validation loss: 2.319040700604614

Epoch: 6| Step: 7
Training loss: 1.4532498541897028
Validation loss: 2.297611463670605

Epoch: 6| Step: 8
Training loss: 1.0520938205511052
Validation loss: 2.2712814289347327

Epoch: 6| Step: 9
Training loss: 1.1777912587967767
Validation loss: 2.2571102826886165

Epoch: 6| Step: 10
Training loss: 0.8229474935109519
Validation loss: 2.231665171265749

Epoch: 6| Step: 11
Training loss: 1.106527407934615
Validation loss: 2.3097682894130243

Epoch: 6| Step: 12
Training loss: 1.0215389900851364
Validation loss: 2.2322668916898327

Epoch: 6| Step: 13
Training loss: 0.8475440166374484
Validation loss: 2.231068947703509

Epoch: 472| Step: 0
Training loss: 1.2381123809710564
Validation loss: 2.261965468331678

Epoch: 6| Step: 1
Training loss: 1.0791384591401427
Validation loss: 2.303389093234533

Epoch: 6| Step: 2
Training loss: 1.4124703902120241
Validation loss: 2.1923157615264577

Epoch: 6| Step: 3
Training loss: 1.856755117926806
Validation loss: 2.3032358048703916

Epoch: 6| Step: 4
Training loss: 1.2308092403098476
Validation loss: 2.2698940657576667

Epoch: 6| Step: 5
Training loss: 0.8249772906790274
Validation loss: 2.3085496436467507

Epoch: 6| Step: 6
Training loss: 1.121883844962358
Validation loss: 2.2847983263074996

Epoch: 6| Step: 7
Training loss: 1.1581002972969323
Validation loss: 2.282509069595115

Epoch: 6| Step: 8
Training loss: 0.700705710670106
Validation loss: 2.295195644703445

Epoch: 6| Step: 9
Training loss: 1.3274439692481281
Validation loss: 2.229662039059275

Epoch: 6| Step: 10
Training loss: 0.8263202290546788
Validation loss: 2.2689247212548667

Epoch: 6| Step: 11
Training loss: 0.9409821690827014
Validation loss: 2.2583000382563805

Epoch: 6| Step: 12
Training loss: 1.1146900030888163
Validation loss: 2.2930140214027888

Epoch: 6| Step: 13
Training loss: 1.1362318326632876
Validation loss: 2.236907462369086

Epoch: 473| Step: 0
Training loss: 1.4279700631334833
Validation loss: 2.254504574674761

Epoch: 6| Step: 1
Training loss: 2.1778985889599967
Validation loss: 2.3287933044491886

Epoch: 6| Step: 2
Training loss: 0.8215963580270889
Validation loss: 2.2641324924601944

Epoch: 6| Step: 3
Training loss: 0.969730035289681
Validation loss: 2.282785001199462

Epoch: 6| Step: 4
Training loss: 0.7427803883815373
Validation loss: 2.273565076428359

Epoch: 6| Step: 5
Training loss: 1.1287936250149762
Validation loss: 2.2770316668347776

Epoch: 6| Step: 6
Training loss: 1.072478837735905
Validation loss: 2.2663709816204456

Epoch: 6| Step: 7
Training loss: 0.8453925357518867
Validation loss: 2.2842180265280754

Epoch: 6| Step: 8
Training loss: 1.2393490011515214
Validation loss: 2.299803997487583

Epoch: 6| Step: 9
Training loss: 1.0386252953398896
Validation loss: 2.2834970384420488

Epoch: 6| Step: 10
Training loss: 0.7178059888452243
Validation loss: 2.2364857430159257

Epoch: 6| Step: 11
Training loss: 1.2012169310020266
Validation loss: 2.291938306048243

Epoch: 6| Step: 12
Training loss: 1.0374982718947392
Validation loss: 2.2320704721647515

Epoch: 6| Step: 13
Training loss: 1.4740754834675471
Validation loss: 2.324967695654181

Epoch: 474| Step: 0
Training loss: 1.01371350506098
Validation loss: 2.2173956874630507

Epoch: 6| Step: 1
Training loss: 1.48132709994637
Validation loss: 2.2372594816730693

Epoch: 6| Step: 2
Training loss: 0.9842473507419905
Validation loss: 2.167160539527174

Epoch: 6| Step: 3
Training loss: 2.037357830868146
Validation loss: 2.1903655484280278

Epoch: 6| Step: 4
Training loss: 0.8456762719241014
Validation loss: 2.2323984435874036

Epoch: 6| Step: 5
Training loss: 1.7346132132034986
Validation loss: 2.2339759893190596

Epoch: 6| Step: 6
Training loss: 1.008881467739638
Validation loss: 2.243616728592763

Epoch: 6| Step: 7
Training loss: 1.0607036664356886
Validation loss: 2.2210073973763405

Epoch: 6| Step: 8
Training loss: 0.7960785644400656
Validation loss: 2.2500620073458713

Epoch: 6| Step: 9
Training loss: 0.7750052159656845
Validation loss: 2.2582716408456656

Epoch: 6| Step: 10
Training loss: 0.8894493642399977
Validation loss: 2.3285486183190853

Epoch: 6| Step: 11
Training loss: 0.9347039170068544
Validation loss: 2.268109475551244

Epoch: 6| Step: 12
Training loss: 1.0176252182150924
Validation loss: 2.1971129854296265

Epoch: 6| Step: 13
Training loss: 1.7328508570616266
Validation loss: 2.2670680275546387

Epoch: 475| Step: 0
Training loss: 1.0898610322190443
Validation loss: 2.2221598769187754

Epoch: 6| Step: 1
Training loss: 0.9939347149461444
Validation loss: 2.249928378716502

Epoch: 6| Step: 2
Training loss: 1.0084116138201047
Validation loss: 2.2863165848166216

Epoch: 6| Step: 3
Training loss: 1.4215372543793494
Validation loss: 2.270764022345898

Epoch: 6| Step: 4
Training loss: 1.1688325679397054
Validation loss: 2.306918597094222

Epoch: 6| Step: 5
Training loss: 1.21638856653236
Validation loss: 2.247285945844072

Epoch: 6| Step: 6
Training loss: 1.5161546391299434
Validation loss: 2.2306983185533533

Epoch: 6| Step: 7
Training loss: 1.8654770298844447
Validation loss: 2.283806913527806

Epoch: 6| Step: 8
Training loss: 0.6749790479799119
Validation loss: 2.3177672924927344

Epoch: 6| Step: 9
Training loss: 0.7716331628181978
Validation loss: 2.2986565202613467

Epoch: 6| Step: 10
Training loss: 0.6988031441502621
Validation loss: 2.2213220964148483

Epoch: 6| Step: 11
Training loss: 1.348379985692249
Validation loss: 2.2779314078701076

Epoch: 6| Step: 12
Training loss: 1.442761205629371
Validation loss: 2.2858349828717244

Epoch: 6| Step: 13
Training loss: 0.8599156499682235
Validation loss: 2.2799713860126523

Epoch: 476| Step: 0
Training loss: 0.9857416203215471
Validation loss: 2.287567843448688

Epoch: 6| Step: 1
Training loss: 1.0540887899368903
Validation loss: 2.2612348699127294

Epoch: 6| Step: 2
Training loss: 1.6138320979976026
Validation loss: 2.2684031809775766

Epoch: 6| Step: 3
Training loss: 1.0421624084837922
Validation loss: 2.3018302468404412

Epoch: 6| Step: 4
Training loss: 1.0757102460845063
Validation loss: 2.3186946004212037

Epoch: 6| Step: 5
Training loss: 1.2735154765775882
Validation loss: 2.3245787264135918

Epoch: 6| Step: 6
Training loss: 1.822048031162337
Validation loss: 2.2150547939619316

Epoch: 6| Step: 7
Training loss: 1.31789931570606
Validation loss: 2.2661773721152385

Epoch: 6| Step: 8
Training loss: 0.715969429253221
Validation loss: 2.3053486218709196

Epoch: 6| Step: 9
Training loss: 0.8648489272213348
Validation loss: 2.1984786649823924

Epoch: 6| Step: 10
Training loss: 1.219909067908153
Validation loss: 2.3390421256614213

Epoch: 6| Step: 11
Training loss: 1.1097721946921983
Validation loss: 2.2639476005100727

Epoch: 6| Step: 12
Training loss: 0.8170409222466405
Validation loss: 2.223296950094958

Epoch: 6| Step: 13
Training loss: 1.0323445840020706
Validation loss: 2.2223447991690137

Epoch: 477| Step: 0
Training loss: 0.8525552474994861
Validation loss: 2.269039099632067

Epoch: 6| Step: 1
Training loss: 1.5805932562111609
Validation loss: 2.2550331799295935

Epoch: 6| Step: 2
Training loss: 2.208532852180691
Validation loss: 2.1809140645621654

Epoch: 6| Step: 3
Training loss: 1.267624582341551
Validation loss: 2.2688430144447116

Epoch: 6| Step: 4
Training loss: 1.1249930063666083
Validation loss: 2.257689852384664

Epoch: 6| Step: 5
Training loss: 0.8627408092299956
Validation loss: 2.3004545811429282

Epoch: 6| Step: 6
Training loss: 1.3197207958981234
Validation loss: 2.2770714108091807

Epoch: 6| Step: 7
Training loss: 0.9148535932342005
Validation loss: 2.278771882164333

Epoch: 6| Step: 8
Training loss: 0.8209449146808625
Validation loss: 2.266712186144866

Epoch: 6| Step: 9
Training loss: 0.9093207261187145
Validation loss: 2.333382214489792

Epoch: 6| Step: 10
Training loss: 0.86570231095885
Validation loss: 2.2210009767441248

Epoch: 6| Step: 11
Training loss: 1.2388559445865277
Validation loss: 2.2480343848903077

Epoch: 6| Step: 12
Training loss: 0.8833828661784192
Validation loss: 2.2903016067912576

Epoch: 6| Step: 13
Training loss: 0.7368115929913405
Validation loss: 2.257259954880744

Epoch: 478| Step: 0
Training loss: 1.0144149026878633
Validation loss: 2.229581953675208

Epoch: 6| Step: 1
Training loss: 0.8778295406807407
Validation loss: 2.2432945125282733

Epoch: 6| Step: 2
Training loss: 1.068095507630336
Validation loss: 2.311973437551212

Epoch: 6| Step: 3
Training loss: 1.2006918343365547
Validation loss: 2.2594616818024824

Epoch: 6| Step: 4
Training loss: 1.8155427582542805
Validation loss: 2.314324920206314

Epoch: 6| Step: 5
Training loss: 1.0831683962537608
Validation loss: 2.2543875916301417

Epoch: 6| Step: 6
Training loss: 0.9735671224979674
Validation loss: 2.2742913469563093

Epoch: 6| Step: 7
Training loss: 1.2771755189382672
Validation loss: 2.2719646554820847

Epoch: 6| Step: 8
Training loss: 0.75982916794249
Validation loss: 2.2136970036029897

Epoch: 6| Step: 9
Training loss: 0.937963688938582
Validation loss: 2.2387243206481418

Epoch: 6| Step: 10
Training loss: 1.3479771770984599
Validation loss: 2.2141630404941517

Epoch: 6| Step: 11
Training loss: 1.171550298847556
Validation loss: 2.2939133375296197

Epoch: 6| Step: 12
Training loss: 1.3632660348474903
Validation loss: 2.2888115676702547

Epoch: 6| Step: 13
Training loss: 0.9990867975005071
Validation loss: 2.2434857613718915

Epoch: 479| Step: 0
Training loss: 1.155181597350679
Validation loss: 2.2975800066838468

Epoch: 6| Step: 1
Training loss: 0.8224875180187237
Validation loss: 2.268317262926949

Epoch: 6| Step: 2
Training loss: 1.0688622666672167
Validation loss: 2.30018375783087

Epoch: 6| Step: 3
Training loss: 0.8012561413415036
Validation loss: 2.2109487317249763

Epoch: 6| Step: 4
Training loss: 1.2170252210688368
Validation loss: 2.269156622064002

Epoch: 6| Step: 5
Training loss: 1.1522180521023155
Validation loss: 2.2790885616608616

Epoch: 6| Step: 6
Training loss: 2.0161406574529384
Validation loss: 2.301625032194129

Epoch: 6| Step: 7
Training loss: 1.4146208108797986
Validation loss: 2.292514832752459

Epoch: 6| Step: 8
Training loss: 0.9132262749356197
Validation loss: 2.3426832958784995

Epoch: 6| Step: 9
Training loss: 1.1672962000223983
Validation loss: 2.2851861991563998

Epoch: 6| Step: 10
Training loss: 1.3614683147474116
Validation loss: 2.2827865060618633

Epoch: 6| Step: 11
Training loss: 1.0728638027957533
Validation loss: 2.2446395639385517

Epoch: 6| Step: 12
Training loss: 1.2487968376471528
Validation loss: 2.2638890060719032

Epoch: 6| Step: 13
Training loss: 0.8774973109060095
Validation loss: 2.277956899725971

Epoch: 480| Step: 0
Training loss: 1.2975174564958651
Validation loss: 2.2673066452350574

Epoch: 6| Step: 1
Training loss: 0.8758108605339742
Validation loss: 2.256097620849546

Epoch: 6| Step: 2
Training loss: 0.9994118570255339
Validation loss: 2.268190994036615

Epoch: 6| Step: 3
Training loss: 1.5584614250590922
Validation loss: 2.258681810547613

Epoch: 6| Step: 4
Training loss: 2.001336604763528
Validation loss: 2.2625743390995594

Epoch: 6| Step: 5
Training loss: 0.8740078546424248
Validation loss: 2.2330342205512896

Epoch: 6| Step: 6
Training loss: 1.24290426435857
Validation loss: 2.2604185667370693

Epoch: 6| Step: 7
Training loss: 1.1158245816408683
Validation loss: 2.2187337405371457

Epoch: 6| Step: 8
Training loss: 0.9738614991272742
Validation loss: 2.2435729400107376

Epoch: 6| Step: 9
Training loss: 1.0868406313814116
Validation loss: 2.272094499030533

Epoch: 6| Step: 10
Training loss: 1.1962809908847594
Validation loss: 2.294544984427661

Epoch: 6| Step: 11
Training loss: 0.898363690868918
Validation loss: 2.242534754482164

Epoch: 6| Step: 12
Training loss: 0.7690378921583435
Validation loss: 2.307726392127462

Epoch: 6| Step: 13
Training loss: 0.917460621552643
Validation loss: 2.2134718513457274

Epoch: 481| Step: 0
Training loss: 0.8890563468519052
Validation loss: 2.2433082878168804

Epoch: 6| Step: 1
Training loss: 0.7559134688230013
Validation loss: 2.264846813516475

Epoch: 6| Step: 2
Training loss: 1.211178860145027
Validation loss: 2.2466241219814003

Epoch: 6| Step: 3
Training loss: 0.9713680822008047
Validation loss: 2.228093834932481

Epoch: 6| Step: 4
Training loss: 0.63173461290286
Validation loss: 2.2886992953182497

Epoch: 6| Step: 5
Training loss: 1.000569836860963
Validation loss: 2.3484708476934077

Epoch: 6| Step: 6
Training loss: 1.4309847423505135
Validation loss: 2.254373213101939

Epoch: 6| Step: 7
Training loss: 1.3210731437064107
Validation loss: 2.30513045675879

Epoch: 6| Step: 8
Training loss: 2.0045473140424046
Validation loss: 2.1757973579618617

Epoch: 6| Step: 9
Training loss: 0.9905844225831096
Validation loss: 2.2519939581733284

Epoch: 6| Step: 10
Training loss: 1.698535439791667
Validation loss: 2.265957427115264

Epoch: 6| Step: 11
Training loss: 0.9852696546342731
Validation loss: 2.232271173958179

Epoch: 6| Step: 12
Training loss: 0.8142920318755209
Validation loss: 2.2597626736693863

Epoch: 6| Step: 13
Training loss: 0.8665337718957329
Validation loss: 2.2651357256112052

Epoch: 482| Step: 0
Training loss: 0.9785527509700853
Validation loss: 2.2749998380004435

Epoch: 6| Step: 1
Training loss: 0.8808445220845358
Validation loss: 2.2761562836020928

Epoch: 6| Step: 2
Training loss: 1.1610981107487963
Validation loss: 2.249830383142249

Epoch: 6| Step: 3
Training loss: 1.2609638991304541
Validation loss: 2.2668508662322733

Epoch: 6| Step: 4
Training loss: 1.1324886516819295
Validation loss: 2.276780766491253

Epoch: 6| Step: 5
Training loss: 1.5464435322439645
Validation loss: 2.23687957271123

Epoch: 6| Step: 6
Training loss: 0.8674186879508066
Validation loss: 2.2510001376380737

Epoch: 6| Step: 7
Training loss: 0.6585485531105862
Validation loss: 2.2727146485892584

Epoch: 6| Step: 8
Training loss: 0.9692661387093953
Validation loss: 2.2302147953632425

Epoch: 6| Step: 9
Training loss: 1.0453699024901313
Validation loss: 2.356115693238327

Epoch: 6| Step: 10
Training loss: 1.2564083815605072
Validation loss: 2.2586742808370337

Epoch: 6| Step: 11
Training loss: 1.891902901551162
Validation loss: 2.2448984566159904

Epoch: 6| Step: 12
Training loss: 1.1335424767853368
Validation loss: 2.2940511024316086

Epoch: 6| Step: 13
Training loss: 0.7644106128471901
Validation loss: 2.2887218803870684

Epoch: 483| Step: 0
Training loss: 0.7863454590358808
Validation loss: 2.277496755456802

Epoch: 6| Step: 1
Training loss: 1.2056176756799
Validation loss: 2.2425504435504995

Epoch: 6| Step: 2
Training loss: 0.8856958211015702
Validation loss: 2.216024503330043

Epoch: 6| Step: 3
Training loss: 1.1625176233576007
Validation loss: 2.27959321290993

Epoch: 6| Step: 4
Training loss: 1.0104241649441226
Validation loss: 2.291376865965039

Epoch: 6| Step: 5
Training loss: 0.76896445221707
Validation loss: 2.286972698526923

Epoch: 6| Step: 6
Training loss: 1.3573778323705954
Validation loss: 2.299386814753594

Epoch: 6| Step: 7
Training loss: 0.5389102223140126
Validation loss: 2.247881960047553

Epoch: 6| Step: 8
Training loss: 0.8956416538604163
Validation loss: 2.246740207316867

Epoch: 6| Step: 9
Training loss: 2.159131543447879
Validation loss: 2.2948369051166755

Epoch: 6| Step: 10
Training loss: 0.8942588824608725
Validation loss: 2.2277615956578907

Epoch: 6| Step: 11
Training loss: 1.3654933350944105
Validation loss: 2.1910037837940948

Epoch: 6| Step: 12
Training loss: 1.3848917786633417
Validation loss: 2.259445920678246

Epoch: 6| Step: 13
Training loss: 0.5144407081119305
Validation loss: 2.3053279186451774

Epoch: 484| Step: 0
Training loss: 0.7694639379814644
Validation loss: 2.2769314143877484

Epoch: 6| Step: 1
Training loss: 1.411132009961385
Validation loss: 2.26197553148909

Epoch: 6| Step: 2
Training loss: 1.0930864773784312
Validation loss: 2.2795986784809283

Epoch: 6| Step: 3
Training loss: 1.0296902854777563
Validation loss: 2.279402382042046

Epoch: 6| Step: 4
Training loss: 1.2208074174198182
Validation loss: 2.304315891969692

Epoch: 6| Step: 5
Training loss: 0.9691893288960479
Validation loss: 2.281071355716248

Epoch: 6| Step: 6
Training loss: 0.5482031090388324
Validation loss: 2.2431139077444477

Epoch: 6| Step: 7
Training loss: 0.9297762916542225
Validation loss: 2.2168878646939834

Epoch: 6| Step: 8
Training loss: 1.4764158791704327
Validation loss: 2.237657004057891

Epoch: 6| Step: 9
Training loss: 0.8414161334435778
Validation loss: 2.27399007356367

Epoch: 6| Step: 10
Training loss: 2.1152864486751506
Validation loss: 2.2481791145192935

Epoch: 6| Step: 11
Training loss: 0.8775763728931602
Validation loss: 2.2652878014959668

Epoch: 6| Step: 12
Training loss: 1.1333651016962631
Validation loss: 2.2530063241475395

Epoch: 6| Step: 13
Training loss: 1.3967948941809287
Validation loss: 2.1980434821065202

Epoch: 485| Step: 0
Training loss: 0.8853013056980813
Validation loss: 2.261558062699949

Epoch: 6| Step: 1
Training loss: 1.0288047699931908
Validation loss: 2.1961318537823256

Epoch: 6| Step: 2
Training loss: 1.2190377800417043
Validation loss: 2.2695056759300223

Epoch: 6| Step: 3
Training loss: 0.7297673657511597
Validation loss: 2.277588690219125

Epoch: 6| Step: 4
Training loss: 0.966473951258071
Validation loss: 2.290039512528758

Epoch: 6| Step: 5
Training loss: 1.0476409615148572
Validation loss: 2.234170640600558

Epoch: 6| Step: 6
Training loss: 1.379593675129727
Validation loss: 2.249796532303595

Epoch: 6| Step: 7
Training loss: 0.887395390537577
Validation loss: 2.270644141567974

Epoch: 6| Step: 8
Training loss: 0.7939453125
Validation loss: 2.2275674120625233

Epoch: 6| Step: 9
Training loss: 1.2590157102827226
Validation loss: 2.3184020651024144

Epoch: 6| Step: 10
Training loss: 1.2665107359192058
Validation loss: 2.226950310621031

Epoch: 6| Step: 11
Training loss: 1.0488159633620437
Validation loss: 2.231416842170249

Epoch: 6| Step: 12
Training loss: 2.1862585632261204
Validation loss: 2.2809340319558444

Epoch: 6| Step: 13
Training loss: 0.9220295792632229
Validation loss: 2.2225003596114457

Epoch: 486| Step: 0
Training loss: 0.89735237602327
Validation loss: 2.3199814223640796

Epoch: 6| Step: 1
Training loss: 1.908214369929124
Validation loss: 2.2453693852954983

Epoch: 6| Step: 2
Training loss: 1.232536588671237
Validation loss: 2.2097486430862423

Epoch: 6| Step: 3
Training loss: 0.7044267472262236
Validation loss: 2.2572769203701712

Epoch: 6| Step: 4
Training loss: 1.1050033398400836
Validation loss: 2.2747129310349963

Epoch: 6| Step: 5
Training loss: 0.6991216069941762
Validation loss: 2.1880745128927104

Epoch: 6| Step: 6
Training loss: 0.7574930992693424
Validation loss: 2.299536297179188

Epoch: 6| Step: 7
Training loss: 1.085410944117558
Validation loss: 2.268501035347483

Epoch: 6| Step: 8
Training loss: 0.9415457847673858
Validation loss: 2.239121452736882

Epoch: 6| Step: 9
Training loss: 1.3694606086021162
Validation loss: 2.2603239828015966

Epoch: 6| Step: 10
Training loss: 1.552868876839647
Validation loss: 2.174982143739456

Epoch: 6| Step: 11
Training loss: 1.038451165503403
Validation loss: 2.3069490096678638

Epoch: 6| Step: 12
Training loss: 1.0383430227212307
Validation loss: 2.2695238692445465

Epoch: 6| Step: 13
Training loss: 1.0634376091386737
Validation loss: 2.264260695065337

Epoch: 487| Step: 0
Training loss: 0.9158008705983103
Validation loss: 2.2284931084912114

Epoch: 6| Step: 1
Training loss: 0.8649336246977287
Validation loss: 2.240731622076088

Epoch: 6| Step: 2
Training loss: 0.7949428696167982
Validation loss: 2.247822019597074

Epoch: 6| Step: 3
Training loss: 0.680052166157962
Validation loss: 2.308150890318394

Epoch: 6| Step: 4
Training loss: 0.8967479243620052
Validation loss: 2.2701242419250796

Epoch: 6| Step: 5
Training loss: 2.0110212876204705
Validation loss: 2.2623048618312747

Epoch: 6| Step: 6
Training loss: 1.3891302926820785
Validation loss: 2.237274568335604

Epoch: 6| Step: 7
Training loss: 0.9630907945543338
Validation loss: 2.2890470322875887

Epoch: 6| Step: 8
Training loss: 1.3044764182378021
Validation loss: 2.3211508588069587

Epoch: 6| Step: 9
Training loss: 0.9074317199199251
Validation loss: 2.2497717343922385

Epoch: 6| Step: 10
Training loss: 1.2150853152992223
Validation loss: 2.2301771235028163

Epoch: 6| Step: 11
Training loss: 1.2729584430554977
Validation loss: 2.2058871073292585

Epoch: 6| Step: 12
Training loss: 1.1758883101175441
Validation loss: 2.19707824010103

Epoch: 6| Step: 13
Training loss: 0.7176631505407276
Validation loss: 2.2509993882485952

Epoch: 488| Step: 0
Training loss: 0.9429605403059216
Validation loss: 2.2288927671496856

Epoch: 6| Step: 1
Training loss: 0.8850553934897454
Validation loss: 2.277039619963444

Epoch: 6| Step: 2
Training loss: 1.6467439892538849
Validation loss: 2.2348170699001644

Epoch: 6| Step: 3
Training loss: 1.1829809736558223
Validation loss: 2.2184634522650706

Epoch: 6| Step: 4
Training loss: 1.3686242973401785
Validation loss: 2.2289955764296963

Epoch: 6| Step: 5
Training loss: 1.1195729537405115
Validation loss: 2.215861992001168

Epoch: 6| Step: 6
Training loss: 0.798454663713666
Validation loss: 2.211080074260807

Epoch: 6| Step: 7
Training loss: 1.0695296160042473
Validation loss: 2.2266631786739617

Epoch: 6| Step: 8
Training loss: 0.7401835643068103
Validation loss: 2.2423542479932155

Epoch: 6| Step: 9
Training loss: 1.0092580910642541
Validation loss: 2.2044022417851448

Epoch: 6| Step: 10
Training loss: 1.8782351875670584
Validation loss: 2.2278933917193435

Epoch: 6| Step: 11
Training loss: 0.884233933915163
Validation loss: 2.2085140856252354

Epoch: 6| Step: 12
Training loss: 1.0745328131982335
Validation loss: 2.238782023808564

Epoch: 6| Step: 13
Training loss: 1.155403239551273
Validation loss: 2.278605446640701

Epoch: 489| Step: 0
Training loss: 1.984926702745985
Validation loss: 2.302057437494019

Epoch: 6| Step: 1
Training loss: 0.7830748036730483
Validation loss: 2.22998933406328

Epoch: 6| Step: 2
Training loss: 1.038525894540127
Validation loss: 2.2831465765189924

Epoch: 6| Step: 3
Training loss: 0.8695623167782587
Validation loss: 2.2212029987400834

Epoch: 6| Step: 4
Training loss: 1.1755201994094637
Validation loss: 2.2220866216627204

Epoch: 6| Step: 5
Training loss: 1.1555280235619556
Validation loss: 2.2258141483918674

Epoch: 6| Step: 6
Training loss: 0.9557333105068474
Validation loss: 2.2950962029936677

Epoch: 6| Step: 7
Training loss: 1.0346528754724402
Validation loss: 2.2110382976605583

Epoch: 6| Step: 8
Training loss: 1.0995374964365454
Validation loss: 2.291350049905571

Epoch: 6| Step: 9
Training loss: 1.2398112859483956
Validation loss: 2.2531175982246876

Epoch: 6| Step: 10
Training loss: 1.3305406032475142
Validation loss: 2.241056570017069

Epoch: 6| Step: 11
Training loss: 1.0384583975806925
Validation loss: 2.2978878761074877

Epoch: 6| Step: 12
Training loss: 0.8210807472600476
Validation loss: 2.2552406187279845

Epoch: 6| Step: 13
Training loss: 0.6695207779731953
Validation loss: 2.260883749363544

Epoch: 490| Step: 0
Training loss: 0.8160381673764296
Validation loss: 2.2428459614688845

Epoch: 6| Step: 1
Training loss: 1.711389003037418
Validation loss: 2.2678349733073624

Epoch: 6| Step: 2
Training loss: 1.350545952922899
Validation loss: 2.270327174560452

Epoch: 6| Step: 3
Training loss: 0.9642248601229961
Validation loss: 2.2745226138192427

Epoch: 6| Step: 4
Training loss: 0.9804279577272743
Validation loss: 2.1816319298480726

Epoch: 6| Step: 5
Training loss: 0.9876348922440723
Validation loss: 2.2289154003893987

Epoch: 6| Step: 6
Training loss: 1.3110435215631628
Validation loss: 2.255241151862811

Epoch: 6| Step: 7
Training loss: 1.4756735088384219
Validation loss: 2.225732113319977

Epoch: 6| Step: 8
Training loss: 0.587766412432006
Validation loss: 2.2145596759871404

Epoch: 6| Step: 9
Training loss: 0.918645795764541
Validation loss: 2.215271277768582

Epoch: 6| Step: 10
Training loss: 0.932890495477266
Validation loss: 2.2550523199009938

Epoch: 6| Step: 11
Training loss: 0.649927403907631
Validation loss: 2.1847703116333097

Epoch: 6| Step: 12
Training loss: 1.1854045348839979
Validation loss: 2.238121047168654

Epoch: 6| Step: 13
Training loss: 1.0760802075899403
Validation loss: 2.2606464309096372

Epoch: 491| Step: 0
Training loss: 0.7659968037800053
Validation loss: 2.2986604320949757

Epoch: 6| Step: 1
Training loss: 1.2380352558113836
Validation loss: 2.3187989074344926

Epoch: 6| Step: 2
Training loss: 0.8458307535542451
Validation loss: 2.274408228284864

Epoch: 6| Step: 3
Training loss: 1.435898261628944
Validation loss: 2.274957819821126

Epoch: 6| Step: 4
Training loss: 0.8820151044585932
Validation loss: 2.291584595882142

Epoch: 6| Step: 5
Training loss: 0.9407215398375727
Validation loss: 2.2588094826510394

Epoch: 6| Step: 6
Training loss: 0.8140398252993903
Validation loss: 2.2107195232014054

Epoch: 6| Step: 7
Training loss: 1.1690705884762258
Validation loss: 2.305634835221856

Epoch: 6| Step: 8
Training loss: 0.9923234981535975
Validation loss: 2.1891655647428734

Epoch: 6| Step: 9
Training loss: 1.2974841973549676
Validation loss: 2.283493824201705

Epoch: 6| Step: 10
Training loss: 1.0101550179670924
Validation loss: 2.2503636623443466

Epoch: 6| Step: 11
Training loss: 1.815969697728863
Validation loss: 2.1542094947605537

Epoch: 6| Step: 12
Training loss: 0.9471170210535583
Validation loss: 2.2581583189634915

Epoch: 6| Step: 13
Training loss: 0.6844540876911466
Validation loss: 2.2198990673326198

Epoch: 492| Step: 0
Training loss: 1.0225572367646305
Validation loss: 2.151417918303464

Epoch: 6| Step: 1
Training loss: 1.9583029507924763
Validation loss: 2.274552753708647

Epoch: 6| Step: 2
Training loss: 0.8320414941004856
Validation loss: 2.2218223951271554

Epoch: 6| Step: 3
Training loss: 1.1244556381546291
Validation loss: 2.2237876041158366

Epoch: 6| Step: 4
Training loss: 1.5376990615874608
Validation loss: 2.242367846134228

Epoch: 6| Step: 5
Training loss: 0.8704506591494621
Validation loss: 2.2551472670365915

Epoch: 6| Step: 6
Training loss: 0.9679119422875028
Validation loss: 2.226981485751331

Epoch: 6| Step: 7
Training loss: 1.0498224017400812
Validation loss: 2.2378315531745874

Epoch: 6| Step: 8
Training loss: 0.8930621347799709
Validation loss: 2.268631897541728

Epoch: 6| Step: 9
Training loss: 1.303988012238263
Validation loss: 2.2178667104976357

Epoch: 6| Step: 10
Training loss: 1.138469488305511
Validation loss: 2.2969917053972617

Epoch: 6| Step: 11
Training loss: 0.9557502737321794
Validation loss: 2.3282998710256826

Epoch: 6| Step: 12
Training loss: 0.6829665658357771
Validation loss: 2.277606701906404

Epoch: 6| Step: 13
Training loss: 0.7278687824453427
Validation loss: 2.2540964449519554

Epoch: 493| Step: 0
Training loss: 0.7494286109003302
Validation loss: 2.2460726424086372

Epoch: 6| Step: 1
Training loss: 1.1443066685858383
Validation loss: 2.303448559884452

Epoch: 6| Step: 2
Training loss: 1.0302483867474344
Validation loss: 2.3203254854853936

Epoch: 6| Step: 3
Training loss: 1.0192094784715087
Validation loss: 2.2738229362622415

Epoch: 6| Step: 4
Training loss: 0.7103275994618832
Validation loss: 2.3005091379186102

Epoch: 6| Step: 5
Training loss: 1.3767309564229646
Validation loss: 2.2893660569218217

Epoch: 6| Step: 6
Training loss: 1.1015227831450967
Validation loss: 2.3519912725107686

Epoch: 6| Step: 7
Training loss: 1.0148463859259576
Validation loss: 2.2705117937190495

Epoch: 6| Step: 8
Training loss: 1.7687623498707887
Validation loss: 2.2833100784419353

Epoch: 6| Step: 9
Training loss: 1.1281717940582319
Validation loss: 2.3145775557265234

Epoch: 6| Step: 10
Training loss: 1.2123439865416896
Validation loss: 2.3131055673692993

Epoch: 6| Step: 11
Training loss: 0.847573342202126
Validation loss: 2.288387916093877

Epoch: 6| Step: 12
Training loss: 1.0305128641931245
Validation loss: 2.2016411418937603

Epoch: 6| Step: 13
Training loss: 0.9336883943858473
Validation loss: 2.222603853866317

Epoch: 494| Step: 0
Training loss: 0.8928081458135438
Validation loss: 2.3120862462626772

Epoch: 6| Step: 1
Training loss: 0.6916275101420846
Validation loss: 2.2559111436283144

Epoch: 6| Step: 2
Training loss: 1.1688043163550152
Validation loss: 2.1672899195413255

Epoch: 6| Step: 3
Training loss: 1.500108555998216
Validation loss: 2.229718423418494

Epoch: 6| Step: 4
Training loss: 1.030526977004565
Validation loss: 2.2130955489163417

Epoch: 6| Step: 5
Training loss: 0.597251630460702
Validation loss: 2.2149604326350825

Epoch: 6| Step: 6
Training loss: 0.5725084121785707
Validation loss: 2.1593882548020664

Epoch: 6| Step: 7
Training loss: 1.9306124428006972
Validation loss: 2.238367734558005

Epoch: 6| Step: 8
Training loss: 0.9313496709135636
Validation loss: 2.2734304476691563

Epoch: 6| Step: 9
Training loss: 1.1031376284127714
Validation loss: 2.251235529254151

Epoch: 6| Step: 10
Training loss: 1.244445619672455
Validation loss: 2.2042400773417827

Epoch: 6| Step: 11
Training loss: 1.3267412943593047
Validation loss: 2.200982372572225

Epoch: 6| Step: 12
Training loss: 0.9163419878217804
Validation loss: 2.313283751444201

Epoch: 6| Step: 13
Training loss: 1.025895000115461
Validation loss: 2.322310190055995

Epoch: 495| Step: 0
Training loss: 0.6214779319405224
Validation loss: 2.2192451009004026

Epoch: 6| Step: 1
Training loss: 0.8197281709063995
Validation loss: 2.2687624925765353

Epoch: 6| Step: 2
Training loss: 1.1440679764792379
Validation loss: 2.1911594164920873

Epoch: 6| Step: 3
Training loss: 0.99271348843165
Validation loss: 2.255879106858366

Epoch: 6| Step: 4
Training loss: 1.9054934767103682
Validation loss: 2.2945179098709896

Epoch: 6| Step: 5
Training loss: 1.3258611795477084
Validation loss: 2.266484291028284

Epoch: 6| Step: 6
Training loss: 0.8136358391395377
Validation loss: 2.2510050115108196

Epoch: 6| Step: 7
Training loss: 1.0564206047645712
Validation loss: 2.181677315938541

Epoch: 6| Step: 8
Training loss: 1.1196512651768775
Validation loss: 2.200800509348546

Epoch: 6| Step: 9
Training loss: 0.7975176669349299
Validation loss: 2.241013012825895

Epoch: 6| Step: 10
Training loss: 1.3315555920228104
Validation loss: 2.24707587428975

Epoch: 6| Step: 11
Training loss: 1.1975734495442116
Validation loss: 2.234333618799726

Epoch: 6| Step: 12
Training loss: 1.224805703616675
Validation loss: 2.236440874843327

Epoch: 6| Step: 13
Training loss: 0.8645737237664363
Validation loss: 2.2595742689235743

Epoch: 496| Step: 0
Training loss: 0.8919012061307562
Validation loss: 2.236667871879576

Epoch: 6| Step: 1
Training loss: 0.9147549476166543
Validation loss: 2.205382775745769

Epoch: 6| Step: 2
Training loss: 1.8980650987867034
Validation loss: 2.264095361737869

Epoch: 6| Step: 3
Training loss: 1.1438553933535176
Validation loss: 2.3445328321858643

Epoch: 6| Step: 4
Training loss: 0.9228003109218337
Validation loss: 2.3225243579865817

Epoch: 6| Step: 5
Training loss: 1.2371074998104818
Validation loss: 2.2502053336880037

Epoch: 6| Step: 6
Training loss: 0.7808325605955205
Validation loss: 2.328057018828305

Epoch: 6| Step: 7
Training loss: 0.9998071007644493
Validation loss: 2.341606382193149

Epoch: 6| Step: 8
Training loss: 1.1569953784108484
Validation loss: 2.2452200348650178

Epoch: 6| Step: 9
Training loss: 1.2731451155244307
Validation loss: 2.2974138239659863

Epoch: 6| Step: 10
Training loss: 1.0706400126547615
Validation loss: 2.2219411826936333

Epoch: 6| Step: 11
Training loss: 0.8282513072299745
Validation loss: 2.278782000479758

Epoch: 6| Step: 12
Training loss: 0.7210225790326854
Validation loss: 2.2090619820519515

Epoch: 6| Step: 13
Training loss: 1.3597001750112405
Validation loss: 2.3071693101487494

Epoch: 497| Step: 0
Training loss: 1.207772629093339
Validation loss: 2.279413758339852

Epoch: 6| Step: 1
Training loss: 0.8648326621512161
Validation loss: 2.233001556495209

Epoch: 6| Step: 2
Training loss: 2.048316506217619
Validation loss: 2.3072260698670473

Epoch: 6| Step: 3
Training loss: 1.222380341912653
Validation loss: 2.2007376312410285

Epoch: 6| Step: 4
Training loss: 1.0972323973837121
Validation loss: 2.3193756960195824

Epoch: 6| Step: 5
Training loss: 1.6020270441465718
Validation loss: 2.213362122600635

Epoch: 6| Step: 6
Training loss: 1.0755230008427514
Validation loss: 2.2406569368451317

Epoch: 6| Step: 7
Training loss: 0.7952953464179566
Validation loss: 2.258687641118739

Epoch: 6| Step: 8
Training loss: 0.9624341768818906
Validation loss: 2.2627366706979735

Epoch: 6| Step: 9
Training loss: 1.0055292569252239
Validation loss: 2.234485743088964

Epoch: 6| Step: 10
Training loss: 1.4476335189195804
Validation loss: 2.2262157735119956

Epoch: 6| Step: 11
Training loss: 0.7453376173989289
Validation loss: 2.2183903944783707

Epoch: 6| Step: 12
Training loss: 0.8972294522385533
Validation loss: 2.245663281637386

Epoch: 6| Step: 13
Training loss: 0.8828709675830331
Validation loss: 2.207646626137064

Epoch: 498| Step: 0
Training loss: 0.942452573417774
Validation loss: 2.2327293975338933

Epoch: 6| Step: 1
Training loss: 0.78911250494206
Validation loss: 2.358946912090066

Epoch: 6| Step: 2
Training loss: 0.8911661879628155
Validation loss: 2.274990507455607

Epoch: 6| Step: 3
Training loss: 0.9200094387876374
Validation loss: 2.2759019615403275

Epoch: 6| Step: 4
Training loss: 1.683415025044451
Validation loss: 2.3221586000199346

Epoch: 6| Step: 5
Training loss: 1.0829313094668376
Validation loss: 2.2230396638948755

Epoch: 6| Step: 6
Training loss: 1.2239601568113772
Validation loss: 2.2439926579760923

Epoch: 6| Step: 7
Training loss: 1.0893911426812315
Validation loss: 2.3227518152754216

Epoch: 6| Step: 8
Training loss: 1.8652212731665176
Validation loss: 2.2436203164716804

Epoch: 6| Step: 9
Training loss: 1.1459438212906687
Validation loss: 2.306053510142863

Epoch: 6| Step: 10
Training loss: 0.8632695469127726
Validation loss: 2.2423117426954993

Epoch: 6| Step: 11
Training loss: 0.6766360835350314
Validation loss: 2.1527859119901582

Epoch: 6| Step: 12
Training loss: 0.8038386339643893
Validation loss: 2.2624205057558626

Epoch: 6| Step: 13
Training loss: 1.3401527159765345
Validation loss: 2.2624054355016368

Epoch: 499| Step: 0
Training loss: 1.1787710103400555
Validation loss: 2.1587450092469678

Epoch: 6| Step: 1
Training loss: 1.0439907024853792
Validation loss: 2.1935210015510482

Epoch: 6| Step: 2
Training loss: 0.9436686070187679
Validation loss: 2.2609926390359645

Epoch: 6| Step: 3
Training loss: 1.1473725240206702
Validation loss: 2.2273823064876557

Epoch: 6| Step: 4
Training loss: 1.3548921353526826
Validation loss: 2.220405038754029

Epoch: 6| Step: 5
Training loss: 0.7605832366009859
Validation loss: 2.2080812672177457

Epoch: 6| Step: 6
Training loss: 0.6924456526159884
Validation loss: 2.2565335475275576

Epoch: 6| Step: 7
Training loss: 0.8199571475601585
Validation loss: 2.206129157808693

Epoch: 6| Step: 8
Training loss: 0.9948844000981801
Validation loss: 2.1981041271416206

Epoch: 6| Step: 9
Training loss: 2.0205499378236147
Validation loss: 2.3009626891995216

Epoch: 6| Step: 10
Training loss: 1.1495984495928988
Validation loss: 2.2434856368171285

Epoch: 6| Step: 11
Training loss: 1.3924239449131697
Validation loss: 2.199079710202304

Epoch: 6| Step: 12
Training loss: 0.7383062772192333
Validation loss: 2.2597701401937096

Epoch: 6| Step: 13
Training loss: 0.5498237674309229
Validation loss: 2.2373479141232777

Epoch: 500| Step: 0
Training loss: 0.9673109441070457
Validation loss: 2.192533715294376

Epoch: 6| Step: 1
Training loss: 0.9810400890165648
Validation loss: 2.1975853332036013

Epoch: 6| Step: 2
Training loss: 2.005600954400814
Validation loss: 2.2466415854295203

Epoch: 6| Step: 3
Training loss: 0.9263007078821014
Validation loss: 2.242529741593633

Epoch: 6| Step: 4
Training loss: 0.9099632353220412
Validation loss: 2.231751595164598

Epoch: 6| Step: 5
Training loss: 0.9548656016542827
Validation loss: 2.229662369623556

Epoch: 6| Step: 6
Training loss: 1.1062747995646445
Validation loss: 2.2285562014222955

Epoch: 6| Step: 7
Training loss: 1.0777805165018983
Validation loss: 2.184078080876233

Epoch: 6| Step: 8
Training loss: 1.1301614192009553
Validation loss: 2.260105119714855

Epoch: 6| Step: 9
Training loss: 1.1036514063657379
Validation loss: 2.282591234016502

Epoch: 6| Step: 10
Training loss: 1.0074590018665248
Validation loss: 2.2728166960671294

Epoch: 6| Step: 11
Training loss: 0.9172589743739993
Validation loss: 2.2168232930531744

Epoch: 6| Step: 12
Training loss: 0.886901164512373
Validation loss: 2.2523731127180096

Epoch: 6| Step: 13
Training loss: 0.2938409791227721
Validation loss: 2.204759010877369

Testing loss: 2.814364646399161
