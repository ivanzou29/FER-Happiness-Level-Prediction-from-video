Epoch: 1| Step: 0
Training loss: 4.381298436048128
Validation loss: 4.281008089681829

Epoch: 6| Step: 1
Training loss: 4.330288232808437
Validation loss: 4.274745434983152

Epoch: 6| Step: 2
Training loss: 4.398783532958199
Validation loss: 4.271132157038898

Epoch: 6| Step: 3
Training loss: 5.197731865889449
Validation loss: 4.26360764749

Epoch: 6| Step: 4
Training loss: 3.9168352672460185
Validation loss: 4.25798421865134

Epoch: 6| Step: 5
Training loss: 4.621939806583767
Validation loss: 4.254045850480031

Epoch: 6| Step: 6
Training loss: 4.241610155809606
Validation loss: 4.248169103478097

Epoch: 6| Step: 7
Training loss: 3.9054896720971395
Validation loss: 4.241709496691872

Epoch: 6| Step: 8
Training loss: 4.3248560710618325
Validation loss: 4.235669324837062

Epoch: 6| Step: 9
Training loss: 4.790211376392234
Validation loss: 4.234460067666458

Epoch: 6| Step: 10
Training loss: 4.375363144108414
Validation loss: 4.226270776022391

Epoch: 6| Step: 11
Training loss: 4.350091490386316
Validation loss: 4.221859726585549

Epoch: 6| Step: 12
Training loss: 4.201678512861194
Validation loss: 4.216315606454128

Epoch: 6| Step: 13
Training loss: 3.916046309886015
Validation loss: 4.21137994176247

Epoch: 2| Step: 0
Training loss: 4.770252619997577
Validation loss: 4.204565614150749

Epoch: 6| Step: 1
Training loss: 4.756998628306196
Validation loss: 4.199244823331939

Epoch: 6| Step: 2
Training loss: 4.015569901737758
Validation loss: 4.1954686530376275

Epoch: 6| Step: 3
Training loss: 4.771270309936694
Validation loss: 4.187684462966894

Epoch: 6| Step: 4
Training loss: 4.2204369457077915
Validation loss: 4.184274583766046

Epoch: 6| Step: 5
Training loss: 4.102534297076796
Validation loss: 4.174778305552764

Epoch: 6| Step: 6
Training loss: 5.218803725280157
Validation loss: 4.172184223745385

Epoch: 6| Step: 7
Training loss: 3.456534519177146
Validation loss: 4.166551973958842

Epoch: 6| Step: 8
Training loss: 4.114544420018061
Validation loss: 4.162560428583667

Epoch: 6| Step: 9
Training loss: 3.311902262180797
Validation loss: 4.156888831431101

Epoch: 6| Step: 10
Training loss: 4.323332519139018
Validation loss: 4.154105762816064

Epoch: 6| Step: 11
Training loss: 4.3911486547575125
Validation loss: 4.148025627277226

Epoch: 6| Step: 12
Training loss: 4.093329255125849
Validation loss: 4.140961904318812

Epoch: 6| Step: 13
Training loss: 4.51480654786812
Validation loss: 4.139616622001146

Epoch: 3| Step: 0
Training loss: 4.5934896589972265
Validation loss: 4.13565872057211

Epoch: 6| Step: 1
Training loss: 3.6539445439114795
Validation loss: 4.130385820919388

Epoch: 6| Step: 2
Training loss: 4.0406583072148115
Validation loss: 4.122641997258186

Epoch: 6| Step: 3
Training loss: 4.812862630285436
Validation loss: 4.118983109418173

Epoch: 6| Step: 4
Training loss: 4.062450936828129
Validation loss: 4.115192562726232

Epoch: 6| Step: 5
Training loss: 4.508901058042936
Validation loss: 4.107582629378808

Epoch: 6| Step: 6
Training loss: 4.396509537355804
Validation loss: 4.101912753712203

Epoch: 6| Step: 7
Training loss: 5.397870223055227
Validation loss: 4.100623342378717

Epoch: 6| Step: 8
Training loss: 3.882591809269894
Validation loss: 4.093345000207079

Epoch: 6| Step: 9
Training loss: 3.833040157108754
Validation loss: 4.086228632305191

Epoch: 6| Step: 10
Training loss: 4.410788937538689
Validation loss: 4.084850227085565

Epoch: 6| Step: 11
Training loss: 4.038846687144222
Validation loss: 4.075076218846043

Epoch: 6| Step: 12
Training loss: 3.045455367141261
Validation loss: 4.072892476947271

Epoch: 6| Step: 13
Training loss: 4.2944757595019905
Validation loss: 4.066486545052235

Epoch: 4| Step: 0
Training loss: 5.05980469338059
Validation loss: 4.06302951236305

Epoch: 6| Step: 1
Training loss: 4.62276858550605
Validation loss: 4.054635747441397

Epoch: 6| Step: 2
Training loss: 3.49417678873998
Validation loss: 4.054355238243896

Epoch: 6| Step: 3
Training loss: 4.234511031890131
Validation loss: 4.047757130083476

Epoch: 6| Step: 4
Training loss: 4.039144194199213
Validation loss: 4.043086203637136

Epoch: 6| Step: 5
Training loss: 3.9790474972014787
Validation loss: 4.03880442301428

Epoch: 6| Step: 6
Training loss: 3.918091670320659
Validation loss: 4.031149026430171

Epoch: 6| Step: 7
Training loss: 4.727229905101252
Validation loss: 4.025972742256602

Epoch: 6| Step: 8
Training loss: 3.9350194232078386
Validation loss: 4.016182490295849

Epoch: 6| Step: 9
Training loss: 4.452724505702283
Validation loss: 4.016900078900832

Epoch: 6| Step: 10
Training loss: 4.039248316491606
Validation loss: 4.013475418203039

Epoch: 6| Step: 11
Training loss: 4.1160657827683185
Validation loss: 4.004605807687054

Epoch: 6| Step: 12
Training loss: 4.179593493393769
Validation loss: 4.0028513185189425

Epoch: 6| Step: 13
Training loss: 2.722538905850947
Validation loss: 3.998074850190346

Epoch: 5| Step: 0
Training loss: 4.9053763808442
Validation loss: 3.990321167790019

Epoch: 6| Step: 1
Training loss: 3.8760218349743276
Validation loss: 3.9885151016467835

Epoch: 6| Step: 2
Training loss: 3.100523190802104
Validation loss: 3.9777746774022007

Epoch: 6| Step: 3
Training loss: 3.926722596832889
Validation loss: 3.9750611646025935

Epoch: 6| Step: 4
Training loss: 4.292904326603733
Validation loss: 3.970677892057996

Epoch: 6| Step: 5
Training loss: 3.343178673536381
Validation loss: 3.9662059316438913

Epoch: 6| Step: 6
Training loss: 4.245034627065526
Validation loss: 3.957597400967305

Epoch: 6| Step: 7
Training loss: 4.649224017625356
Validation loss: 3.9549983787219567

Epoch: 6| Step: 8
Training loss: 3.8214192103842968
Validation loss: 3.9504513531602874

Epoch: 6| Step: 9
Training loss: 4.16587758539765
Validation loss: 3.9419461832790312

Epoch: 6| Step: 10
Training loss: 4.02847194316895
Validation loss: 3.937903729100265

Epoch: 6| Step: 11
Training loss: 4.246312505145779
Validation loss: 3.935091880374758

Epoch: 6| Step: 12
Training loss: 5.067211831193512
Validation loss: 3.926673791861745

Epoch: 6| Step: 13
Training loss: 2.5397438426273093
Validation loss: 3.9159797353191577

Epoch: 6| Step: 0
Training loss: 4.80028003034729
Validation loss: 3.9165641930099255

Epoch: 6| Step: 1
Training loss: 3.6265765740854112
Validation loss: 3.9029158711807033

Epoch: 6| Step: 2
Training loss: 4.3269067695506
Validation loss: 3.9044557817613614

Epoch: 6| Step: 3
Training loss: 3.6481146659397545
Validation loss: 3.897842243740935

Epoch: 6| Step: 4
Training loss: 3.168313267574218
Validation loss: 3.89118308228976

Epoch: 6| Step: 5
Training loss: 4.453910035655513
Validation loss: 3.882683732581583

Epoch: 6| Step: 6
Training loss: 3.7602666823186572
Validation loss: 3.8784769412154136

Epoch: 6| Step: 7
Training loss: 3.920569457127888
Validation loss: 3.87351513271518

Epoch: 6| Step: 8
Training loss: 3.501280414159114
Validation loss: 3.867850865487434

Epoch: 6| Step: 9
Training loss: 3.8345348023285113
Validation loss: 3.855923220387164

Epoch: 6| Step: 10
Training loss: 4.402681677913048
Validation loss: 3.8523350379567116

Epoch: 6| Step: 11
Training loss: 3.9047831718627726
Validation loss: 3.8485959027671943

Epoch: 6| Step: 12
Training loss: 4.2755724161185285
Validation loss: 3.8404134065908333

Epoch: 6| Step: 13
Training loss: 4.810175544882225
Validation loss: 3.831525565388813

Epoch: 7| Step: 0
Training loss: 4.769678411939354
Validation loss: 3.833192587770322

Epoch: 6| Step: 1
Training loss: 4.371547099340009
Validation loss: 3.8177383265658533

Epoch: 6| Step: 2
Training loss: 4.31138109812466
Validation loss: 3.8105846040346543

Epoch: 6| Step: 3
Training loss: 3.934592126940644
Validation loss: 3.804397105985234

Epoch: 6| Step: 4
Training loss: 4.037696828857102
Validation loss: 3.801499240504472

Epoch: 6| Step: 5
Training loss: 3.404633864828939
Validation loss: 3.7896202259646596

Epoch: 6| Step: 6
Training loss: 3.6418451057439216
Validation loss: 3.777388839095412

Epoch: 6| Step: 7
Training loss: 3.7436765125430385
Validation loss: 3.7756866747615656

Epoch: 6| Step: 8
Training loss: 4.299467435282047
Validation loss: 3.7679985298905607

Epoch: 6| Step: 9
Training loss: 3.549124118048009
Validation loss: 3.7584926162107615

Epoch: 6| Step: 10
Training loss: 4.5718711868656134
Validation loss: 3.74887028566691

Epoch: 6| Step: 11
Training loss: 3.2878203957503387
Validation loss: 3.74230874764074

Epoch: 6| Step: 12
Training loss: 2.9770517022330254
Validation loss: 3.7365461434396288

Epoch: 6| Step: 13
Training loss: 3.9980870679541103
Validation loss: 3.7259129605915025

Epoch: 8| Step: 0
Training loss: 4.313015229780026
Validation loss: 3.7215745236159896

Epoch: 6| Step: 1
Training loss: 4.490458651695603
Validation loss: 3.712765819018026

Epoch: 6| Step: 2
Training loss: 3.025216458985747
Validation loss: 3.7057408424657994

Epoch: 6| Step: 3
Training loss: 4.452212163155744
Validation loss: 3.6988618235868005

Epoch: 6| Step: 4
Training loss: 3.769490770508042
Validation loss: 3.6941214530348687

Epoch: 6| Step: 5
Training loss: 3.2312400478305694
Validation loss: 3.684621183215338

Epoch: 6| Step: 6
Training loss: 3.4404255295532638
Validation loss: 3.676388827144051

Epoch: 6| Step: 7
Training loss: 4.060300495696894
Validation loss: 3.6687944932533614

Epoch: 6| Step: 8
Training loss: 4.5157529819396105
Validation loss: 3.659258231515766

Epoch: 6| Step: 9
Training loss: 3.711573239129713
Validation loss: 3.6476536626145992

Epoch: 6| Step: 10
Training loss: 3.479708433323807
Validation loss: 3.642795440200904

Epoch: 6| Step: 11
Training loss: 3.5969857948665407
Validation loss: 3.6367293014118642

Epoch: 6| Step: 12
Training loss: 4.291099634333529
Validation loss: 3.6213036341707596

Epoch: 6| Step: 13
Training loss: 2.003063597310836
Validation loss: 3.6098998065159242

Epoch: 9| Step: 0
Training loss: 3.7239104296753203
Validation loss: 3.606140396261939

Epoch: 6| Step: 1
Training loss: 2.9478075705965954
Validation loss: 3.600036997018208

Epoch: 6| Step: 2
Training loss: 3.6596955586539233
Validation loss: 3.5849550893274307

Epoch: 6| Step: 3
Training loss: 3.6390196572087596
Validation loss: 3.5778619290064198

Epoch: 6| Step: 4
Training loss: 3.8279919659601007
Validation loss: 3.5669109107514423

Epoch: 6| Step: 5
Training loss: 4.346064767255735
Validation loss: 3.5617385076310564

Epoch: 6| Step: 6
Training loss: 3.4513973557496085
Validation loss: 3.5537623785897674

Epoch: 6| Step: 7
Training loss: 3.7433690254590988
Validation loss: 3.5441236038708794

Epoch: 6| Step: 8
Training loss: 4.664114231353082
Validation loss: 3.5318322078809135

Epoch: 6| Step: 9
Training loss: 3.370010361018794
Validation loss: 3.5226858825436462

Epoch: 6| Step: 10
Training loss: 2.8209808487591976
Validation loss: 3.510577661919384

Epoch: 6| Step: 11
Training loss: 4.541557217366987
Validation loss: 3.5042648641327196

Epoch: 6| Step: 12
Training loss: 3.465019350644639
Validation loss: 3.4908606086918574

Epoch: 6| Step: 13
Training loss: 3.2980308495276445
Validation loss: 3.478513467084694

Epoch: 10| Step: 0
Training loss: 3.7292957958404873
Validation loss: 3.4694929109856942

Epoch: 6| Step: 1
Training loss: 3.535636945046498
Validation loss: 3.458749603490028

Epoch: 6| Step: 2
Training loss: 3.3181336198681506
Validation loss: 3.448621311993986

Epoch: 6| Step: 3
Training loss: 3.732512835757139
Validation loss: 3.439512601460935

Epoch: 6| Step: 4
Training loss: 3.3460710972302614
Validation loss: 3.4270751431384707

Epoch: 6| Step: 5
Training loss: 3.9007639699102783
Validation loss: 3.4170977477840556

Epoch: 6| Step: 6
Training loss: 3.320448497904144
Validation loss: 3.405546453062828

Epoch: 6| Step: 7
Training loss: 3.7248801346509244
Validation loss: 3.3924914374291695

Epoch: 6| Step: 8
Training loss: 3.2601169696254226
Validation loss: 3.381124186603692

Epoch: 6| Step: 9
Training loss: 3.1788223926792796
Validation loss: 3.3714558486010815

Epoch: 6| Step: 10
Training loss: 3.5652206472460866
Validation loss: 3.3595195001811424

Epoch: 6| Step: 11
Training loss: 3.438995174873785
Validation loss: 3.3507871321094598

Epoch: 6| Step: 12
Training loss: 4.936533579830085
Validation loss: 3.3402222670314705

Epoch: 6| Step: 13
Training loss: 2.4909815247109757
Validation loss: 3.3318927341162445

Epoch: 11| Step: 0
Training loss: 3.5199386242370756
Validation loss: 3.317887700455598

Epoch: 6| Step: 1
Training loss: 3.541813267684299
Validation loss: 3.304086173210052

Epoch: 6| Step: 2
Training loss: 4.312035798230312
Validation loss: 3.2920882621075034

Epoch: 6| Step: 3
Training loss: 4.14062868513987
Validation loss: 3.285293748490995

Epoch: 6| Step: 4
Training loss: 3.9861925953427697
Validation loss: 3.27108239554869

Epoch: 6| Step: 5
Training loss: 3.7177220053656095
Validation loss: 3.263006675099006

Epoch: 6| Step: 6
Training loss: 3.249412777008446
Validation loss: 3.2419915078883874

Epoch: 6| Step: 7
Training loss: 3.0087562566675508
Validation loss: 3.231278376380206

Epoch: 6| Step: 8
Training loss: 3.478129721584354
Validation loss: 3.2165452714171767

Epoch: 6| Step: 9
Training loss: 2.605591091961108
Validation loss: 3.209270499166103

Epoch: 6| Step: 10
Training loss: 3.191002809758206
Validation loss: 3.192920156594904

Epoch: 6| Step: 11
Training loss: 3.3361741993748195
Validation loss: 3.186054019987646

Epoch: 6| Step: 12
Training loss: 2.98036699633809
Validation loss: 3.1679080937956794

Epoch: 6| Step: 13
Training loss: 2.471948121504854
Validation loss: 3.161389673578165

Epoch: 12| Step: 0
Training loss: 2.7740084208255453
Validation loss: 3.1455720889312415

Epoch: 6| Step: 1
Training loss: 3.6479823872157775
Validation loss: 3.135115928782401

Epoch: 6| Step: 2
Training loss: 3.5872600834070925
Validation loss: 3.127833980097932

Epoch: 6| Step: 3
Training loss: 3.2992152003333084
Validation loss: 3.107701120268888

Epoch: 6| Step: 4
Training loss: 3.270313164883622
Validation loss: 3.099515087522169

Epoch: 6| Step: 5
Training loss: 3.6876952556058336
Validation loss: 3.095704607350036

Epoch: 6| Step: 6
Training loss: 2.911738310006913
Validation loss: 3.07545015248429

Epoch: 6| Step: 7
Training loss: 2.9300999058690853
Validation loss: 3.0653584968671175

Epoch: 6| Step: 8
Training loss: 3.2999233236941645
Validation loss: 3.0411200187382175

Epoch: 6| Step: 9
Training loss: 3.87630317678576
Validation loss: 3.04459507877204

Epoch: 6| Step: 10
Training loss: 3.6372932611292224
Validation loss: 3.028294565257403

Epoch: 6| Step: 11
Training loss: 3.181254982335474
Validation loss: 3.009185589257659

Epoch: 6| Step: 12
Training loss: 3.1299157198933094
Validation loss: 2.9955349580896815

Epoch: 6| Step: 13
Training loss: 2.4083848870731246
Validation loss: 2.9875735358587288

Epoch: 13| Step: 0
Training loss: 2.7325988232331784
Validation loss: 2.9855439277897746

Epoch: 6| Step: 1
Training loss: 3.6770799472926528
Validation loss: 2.965746312438498

Epoch: 6| Step: 2
Training loss: 2.838478988282095
Validation loss: 2.9557666785761034

Epoch: 6| Step: 3
Training loss: 2.8393871669689137
Validation loss: 2.93640452467197

Epoch: 6| Step: 4
Training loss: 3.681719241327406
Validation loss: 2.933278676215521

Epoch: 6| Step: 5
Training loss: 2.8317444965278424
Validation loss: 2.9168850783271423

Epoch: 6| Step: 6
Training loss: 3.5251401183504614
Validation loss: 2.9048794996995255

Epoch: 6| Step: 7
Training loss: 3.2896827964571527
Validation loss: 2.890003602058683

Epoch: 6| Step: 8
Training loss: 3.0108505165193287
Validation loss: 2.8849772267539247

Epoch: 6| Step: 9
Training loss: 3.5415338977536255
Validation loss: 2.871497633157054

Epoch: 6| Step: 10
Training loss: 3.416801558522213
Validation loss: 2.8683657884395157

Epoch: 6| Step: 11
Training loss: 2.9176533437929013
Validation loss: 2.850728231724634

Epoch: 6| Step: 12
Training loss: 2.9857946085213065
Validation loss: 2.832534745055609

Epoch: 6| Step: 13
Training loss: 2.5172653063086083
Validation loss: 2.820144869678086

Epoch: 14| Step: 0
Training loss: 2.7179290584375484
Validation loss: 2.8132675946462373

Epoch: 6| Step: 1
Training loss: 3.9031380426388993
Validation loss: 2.7995193271756365

Epoch: 6| Step: 2
Training loss: 3.244453686072485
Validation loss: 2.7881895115570505

Epoch: 6| Step: 3
Training loss: 3.4260777135297893
Validation loss: 2.7793718840590085

Epoch: 6| Step: 4
Training loss: 3.170934077169207
Validation loss: 2.771885114277396

Epoch: 6| Step: 5
Training loss: 2.6396818564639046
Validation loss: 2.762573215826781

Epoch: 6| Step: 6
Training loss: 2.78388475068828
Validation loss: 2.7489150648846277

Epoch: 6| Step: 7
Training loss: 2.9675798218041747
Validation loss: 2.7375220246140035

Epoch: 6| Step: 8
Training loss: 3.3516797309771365
Validation loss: 2.717417728010257

Epoch: 6| Step: 9
Training loss: 2.615666098140757
Validation loss: 2.7215229509431462

Epoch: 6| Step: 10
Training loss: 3.494519575113588
Validation loss: 2.6984106975019304

Epoch: 6| Step: 11
Training loss: 2.88921787964402
Validation loss: 2.7053847452525406

Epoch: 6| Step: 12
Training loss: 2.1194919558635883
Validation loss: 2.69757982277284

Epoch: 6| Step: 13
Training loss: 2.4416203031163226
Validation loss: 2.6827033684606265

Epoch: 15| Step: 0
Training loss: 2.8066875159183144
Validation loss: 2.681359125485744

Epoch: 6| Step: 1
Training loss: 3.0653977989441246
Validation loss: 2.6739286772073023

Epoch: 6| Step: 2
Training loss: 2.6025799202350997
Validation loss: 2.6717796536550504

Epoch: 6| Step: 3
Training loss: 3.630855303798484
Validation loss: 2.655195333982404

Epoch: 6| Step: 4
Training loss: 2.7165832654948567
Validation loss: 2.657635379020535

Epoch: 6| Step: 5
Training loss: 2.755231216614467
Validation loss: 2.6439237058652694

Epoch: 6| Step: 6
Training loss: 2.7388026547822024
Validation loss: 2.6470077623730255

Epoch: 6| Step: 7
Training loss: 2.902716508753135
Validation loss: 2.627515059694601

Epoch: 6| Step: 8
Training loss: 2.719270152177319
Validation loss: 2.6347387679737815

Epoch: 6| Step: 9
Training loss: 2.9748305841500504
Validation loss: 2.6311246595059967

Epoch: 6| Step: 10
Training loss: 3.0219710389017527
Validation loss: 2.611820176889609

Epoch: 6| Step: 11
Training loss: 3.1063578166709758
Validation loss: 2.6133659014682578

Epoch: 6| Step: 12
Training loss: 2.934276679101104
Validation loss: 2.608973775297618

Epoch: 6| Step: 13
Training loss: 3.239972711613027
Validation loss: 2.594312576937172

Epoch: 16| Step: 0
Training loss: 2.80983998287627
Validation loss: 2.5938369246168773

Epoch: 6| Step: 1
Training loss: 3.7445990769793305
Validation loss: 2.57925106849265

Epoch: 6| Step: 2
Training loss: 2.4860329523948526
Validation loss: 2.59013881118315

Epoch: 6| Step: 3
Training loss: 2.8788910118745297
Validation loss: 2.5891031368699813

Epoch: 6| Step: 4
Training loss: 2.5331361125002987
Validation loss: 2.574640372626799

Epoch: 6| Step: 5
Training loss: 2.8289358757467293
Validation loss: 2.5705176229621243

Epoch: 6| Step: 6
Training loss: 2.546691607091852
Validation loss: 2.5709178331565017

Epoch: 6| Step: 7
Training loss: 3.0158531616548534
Validation loss: 2.5701703988793065

Epoch: 6| Step: 8
Training loss: 2.6228530823563063
Validation loss: 2.5633980402720415

Epoch: 6| Step: 9
Training loss: 2.3649521146608175
Validation loss: 2.557080260727287

Epoch: 6| Step: 10
Training loss: 2.629620436630935
Validation loss: 2.558082729051775

Epoch: 6| Step: 11
Training loss: 2.8503308288232496
Validation loss: 2.5515254007048513

Epoch: 6| Step: 12
Training loss: 3.778546967145223
Validation loss: 2.5421213943201444

Epoch: 6| Step: 13
Training loss: 3.0490223677913537
Validation loss: 2.545140648065713

Epoch: 17| Step: 0
Training loss: 2.6205075286366957
Validation loss: 2.547085410402198

Epoch: 6| Step: 1
Training loss: 2.62980393929952
Validation loss: 2.545091806142719

Epoch: 6| Step: 2
Training loss: 2.1006860429860263
Validation loss: 2.543016458250994

Epoch: 6| Step: 3
Training loss: 2.73746581731209
Validation loss: 2.543624001876327

Epoch: 6| Step: 4
Training loss: 2.2208927177615205
Validation loss: 2.554245021524026

Epoch: 6| Step: 5
Training loss: 3.5995944059560565
Validation loss: 2.5468550494502447

Epoch: 6| Step: 6
Training loss: 2.2003531909415077
Validation loss: 2.540581091263849

Epoch: 6| Step: 7
Training loss: 3.416029304664576
Validation loss: 2.540579071091924

Epoch: 6| Step: 8
Training loss: 3.4807406917557975
Validation loss: 2.5419473908268713

Epoch: 6| Step: 9
Training loss: 2.924131287253569
Validation loss: 2.5350104792092463

Epoch: 6| Step: 10
Training loss: 3.270734230694526
Validation loss: 2.542082246413073

Epoch: 6| Step: 11
Training loss: 3.2276588775510313
Validation loss: 2.5429115904574937

Epoch: 6| Step: 12
Training loss: 2.762425614127933
Validation loss: 2.5277723220441177

Epoch: 6| Step: 13
Training loss: 2.1656366125018405
Validation loss: 2.5428221920424625

Epoch: 18| Step: 0
Training loss: 2.414752947884401
Validation loss: 2.5410436471519815

Epoch: 6| Step: 1
Training loss: 2.7959889974527714
Validation loss: 2.532999714889236

Epoch: 6| Step: 2
Training loss: 2.6048467943238838
Validation loss: 2.536182765002895

Epoch: 6| Step: 3
Training loss: 3.2924317706083643
Validation loss: 2.539100433899227

Epoch: 6| Step: 4
Training loss: 3.4942720408751935
Validation loss: 2.533715957446987

Epoch: 6| Step: 5
Training loss: 2.872467916258011
Validation loss: 2.5450277438292366

Epoch: 6| Step: 6
Training loss: 2.8737943028456923
Validation loss: 2.5310436100324867

Epoch: 6| Step: 7
Training loss: 2.5009144064416056
Validation loss: 2.527101579835333

Epoch: 6| Step: 8
Training loss: 2.572283977191081
Validation loss: 2.528631876106497

Epoch: 6| Step: 9
Training loss: 2.317079803165938
Validation loss: 2.525065162375883

Epoch: 6| Step: 10
Training loss: 3.1100883240745625
Validation loss: 2.5281529350080505

Epoch: 6| Step: 11
Training loss: 2.6383254291787934
Validation loss: 2.5370606765545274

Epoch: 6| Step: 12
Training loss: 3.2814362972597277
Validation loss: 2.5248941108319882

Epoch: 6| Step: 13
Training loss: 3.2780030670617157
Validation loss: 2.5191851965310224

Epoch: 19| Step: 0
Training loss: 2.8310223485778017
Validation loss: 2.5231758992167364

Epoch: 6| Step: 1
Training loss: 2.683818246926912
Validation loss: 2.540179814436752

Epoch: 6| Step: 2
Training loss: 2.5183113871067735
Validation loss: 2.538431060499623

Epoch: 6| Step: 3
Training loss: 3.2589674258668695
Validation loss: 2.529043002430942

Epoch: 6| Step: 4
Training loss: 2.6121728938716955
Validation loss: 2.531277283572497

Epoch: 6| Step: 5
Training loss: 3.2792848060844766
Validation loss: 2.5286419983141295

Epoch: 6| Step: 6
Training loss: 2.902236957048545
Validation loss: 2.527993647085042

Epoch: 6| Step: 7
Training loss: 2.500912023126406
Validation loss: 2.526879209795586

Epoch: 6| Step: 8
Training loss: 1.9505045898195745
Validation loss: 2.5377756770093267

Epoch: 6| Step: 9
Training loss: 3.493904664466723
Validation loss: 2.547005270630914

Epoch: 6| Step: 10
Training loss: 3.217706307389665
Validation loss: 2.5360765956780242

Epoch: 6| Step: 11
Training loss: 2.8441408328933964
Validation loss: 2.535924564544641

Epoch: 6| Step: 12
Training loss: 2.6032700991633577
Validation loss: 2.5266555305806127

Epoch: 6| Step: 13
Training loss: 3.1440427791703818
Validation loss: 2.5314693277414473

Epoch: 20| Step: 0
Training loss: 2.4893301245810546
Validation loss: 2.5323468152199253

Epoch: 6| Step: 1
Training loss: 2.9293782388853575
Validation loss: 2.522768395757832

Epoch: 6| Step: 2
Training loss: 2.7222658422007195
Validation loss: 2.5318362338161005

Epoch: 6| Step: 3
Training loss: 3.1393779347410007
Validation loss: 2.54112460850037

Epoch: 6| Step: 4
Training loss: 3.2383684208713612
Validation loss: 2.532345465746837

Epoch: 6| Step: 5
Training loss: 2.3407352640539036
Validation loss: 2.5268919900263516

Epoch: 6| Step: 6
Training loss: 2.7718270797629896
Validation loss: 2.528588454275616

Epoch: 6| Step: 7
Training loss: 2.740979311581416
Validation loss: 2.530176897156403

Epoch: 6| Step: 8
Training loss: 2.2994855720082317
Validation loss: 2.531088722243219

Epoch: 6| Step: 9
Training loss: 2.6780598760496432
Validation loss: 2.5398779370720987

Epoch: 6| Step: 10
Training loss: 2.75680783048349
Validation loss: 2.54000551341851

Epoch: 6| Step: 11
Training loss: 3.9310470261809254
Validation loss: 2.531161802135999

Epoch: 6| Step: 12
Training loss: 2.915587816072845
Validation loss: 2.529233346149885

Epoch: 6| Step: 13
Training loss: 2.4641900744942715
Validation loss: 2.535515494361938

Epoch: 21| Step: 0
Training loss: 3.04490981671562
Validation loss: 2.537288085253515

Epoch: 6| Step: 1
Training loss: 3.096652432324476
Validation loss: 2.5285222882459553

Epoch: 6| Step: 2
Training loss: 3.409474377883967
Validation loss: 2.531540019887527

Epoch: 6| Step: 3
Training loss: 2.3366555223548393
Validation loss: 2.520183163783814

Epoch: 6| Step: 4
Training loss: 2.525451517809228
Validation loss: 2.539267275040899

Epoch: 6| Step: 5
Training loss: 2.526729172945832
Validation loss: 2.51879515321789

Epoch: 6| Step: 6
Training loss: 2.7352447870259056
Validation loss: 2.5324591844244164

Epoch: 6| Step: 7
Training loss: 3.3430833954218246
Validation loss: 2.5217936469838658

Epoch: 6| Step: 8
Training loss: 2.4873451376397755
Validation loss: 2.5304474018394423

Epoch: 6| Step: 9
Training loss: 2.6444515514901594
Validation loss: 2.542147752435089

Epoch: 6| Step: 10
Training loss: 2.833409214873606
Validation loss: 2.531890777907215

Epoch: 6| Step: 11
Training loss: 2.486726811306345
Validation loss: 2.5417189586820474

Epoch: 6| Step: 12
Training loss: 3.2740795443594477
Validation loss: 2.5250998886723153

Epoch: 6| Step: 13
Training loss: 2.8958308999762616
Validation loss: 2.5290647934187835

Epoch: 22| Step: 0
Training loss: 2.969925497128858
Validation loss: 2.534413564509047

Epoch: 6| Step: 1
Training loss: 3.314667478428826
Validation loss: 2.532713529394285

Epoch: 6| Step: 2
Training loss: 2.325492958394464
Validation loss: 2.5341557543523816

Epoch: 6| Step: 3
Training loss: 3.488953597149719
Validation loss: 2.5359406190632288

Epoch: 6| Step: 4
Training loss: 3.0440361687394977
Validation loss: 2.5162284981682905

Epoch: 6| Step: 5
Training loss: 2.7049482073382336
Validation loss: 2.5227036283499533

Epoch: 6| Step: 6
Training loss: 3.2663104784359565
Validation loss: 2.536076242884798

Epoch: 6| Step: 7
Training loss: 2.0529888369205187
Validation loss: 2.524751688320913

Epoch: 6| Step: 8
Training loss: 2.512685539265146
Validation loss: 2.5291063769185302

Epoch: 6| Step: 9
Training loss: 3.0290210827068242
Validation loss: 2.5184080728412934

Epoch: 6| Step: 10
Training loss: 3.128804446884737
Validation loss: 2.5288325496252075

Epoch: 6| Step: 11
Training loss: 2.4615792542754633
Validation loss: 2.5297407053452745

Epoch: 6| Step: 12
Training loss: 1.993320756104935
Validation loss: 2.525971203603446

Epoch: 6| Step: 13
Training loss: 3.1901494403143698
Validation loss: 2.527788304608964

Epoch: 23| Step: 0
Training loss: 3.470914423171997
Validation loss: 2.5305076998505007

Epoch: 6| Step: 1
Training loss: 3.1424444441637727
Validation loss: 2.5264209252440355

Epoch: 6| Step: 2
Training loss: 2.3651827641974394
Validation loss: 2.527017903852769

Epoch: 6| Step: 3
Training loss: 3.183196509917657
Validation loss: 2.5280517716381805

Epoch: 6| Step: 4
Training loss: 2.4224633271361573
Validation loss: 2.5290591046885207

Epoch: 6| Step: 5
Training loss: 3.1617150157984653
Validation loss: 2.542607552039523

Epoch: 6| Step: 6
Training loss: 3.039788245304917
Validation loss: 2.5275992892750603

Epoch: 6| Step: 7
Training loss: 2.2837235091854375
Validation loss: 2.5244932128674176

Epoch: 6| Step: 8
Training loss: 2.5458599478354893
Validation loss: 2.531021582859475

Epoch: 6| Step: 9
Training loss: 2.5912241759349866
Validation loss: 2.544863665313439

Epoch: 6| Step: 10
Training loss: 2.9693270473827647
Validation loss: 2.5279203498516143

Epoch: 6| Step: 11
Training loss: 2.9884523031108845
Validation loss: 2.5381786600938736

Epoch: 6| Step: 12
Training loss: 2.5551314128666305
Validation loss: 2.532051131823434

Epoch: 6| Step: 13
Training loss: 2.7760093262430563
Validation loss: 2.5349823165402667

Epoch: 24| Step: 0
Training loss: 3.1730831457401605
Validation loss: 2.5264531757639848

Epoch: 6| Step: 1
Training loss: 2.4854582338355864
Validation loss: 2.534733804438522

Epoch: 6| Step: 2
Training loss: 2.9984718245250703
Validation loss: 2.529271027605597

Epoch: 6| Step: 3
Training loss: 2.5542809399114885
Validation loss: 2.530629543685859

Epoch: 6| Step: 4
Training loss: 2.7985005689507596
Validation loss: 2.5331669897195295

Epoch: 6| Step: 5
Training loss: 2.936839577314508
Validation loss: 2.52701481776479

Epoch: 6| Step: 6
Training loss: 2.6370486808915468
Validation loss: 2.5489542043762694

Epoch: 6| Step: 7
Training loss: 2.9695610143248197
Validation loss: 2.5403728668618917

Epoch: 6| Step: 8
Training loss: 1.9955380257787878
Validation loss: 2.532358851111258

Epoch: 6| Step: 9
Training loss: 2.643269134870748
Validation loss: 2.531167295728588

Epoch: 6| Step: 10
Training loss: 2.6693525397968645
Validation loss: 2.5321408467320765

Epoch: 6| Step: 11
Training loss: 3.345064421804601
Validation loss: 2.5307621173622055

Epoch: 6| Step: 12
Training loss: 3.38731426560335
Validation loss: 2.537823444497731

Epoch: 6| Step: 13
Training loss: 2.7770735854721598
Validation loss: 2.5453373932877477

Epoch: 25| Step: 0
Training loss: 2.595683285053975
Validation loss: 2.54340848407728

Epoch: 6| Step: 1
Training loss: 2.06625648345207
Validation loss: 2.534705889526496

Epoch: 6| Step: 2
Training loss: 3.584587291759833
Validation loss: 2.5305986962892786

Epoch: 6| Step: 3
Training loss: 2.8788187953134527
Validation loss: 2.5294967457734927

Epoch: 6| Step: 4
Training loss: 3.3418188490108935
Validation loss: 2.543050332541749

Epoch: 6| Step: 5
Training loss: 2.8871158228685947
Validation loss: 2.528568374145088

Epoch: 6| Step: 6
Training loss: 2.614634894562997
Validation loss: 2.5290586794523784

Epoch: 6| Step: 7
Training loss: 2.796219818266119
Validation loss: 2.5366486616542536

Epoch: 6| Step: 8
Training loss: 2.673650140738919
Validation loss: 2.5415245297484805

Epoch: 6| Step: 9
Training loss: 2.952078497610571
Validation loss: 2.5291342847065135

Epoch: 6| Step: 10
Training loss: 2.8344517538661895
Validation loss: 2.529303560554175

Epoch: 6| Step: 11
Training loss: 2.46351164355274
Validation loss: 2.538777485667267

Epoch: 6| Step: 12
Training loss: 2.937493831546881
Validation loss: 2.5349054329240355

Epoch: 6| Step: 13
Training loss: 2.7734117963432596
Validation loss: 2.530590478357833

Epoch: 26| Step: 0
Training loss: 3.144311970712359
Validation loss: 2.521565206917979

Epoch: 6| Step: 1
Training loss: 2.543501790751897
Validation loss: 2.5418983130665023

Epoch: 6| Step: 2
Training loss: 2.967403226847603
Validation loss: 2.5296169630708465

Epoch: 6| Step: 3
Training loss: 2.9700412552148534
Validation loss: 2.5216772310523803

Epoch: 6| Step: 4
Training loss: 3.058645040927299
Validation loss: 2.5349853312390835

Epoch: 6| Step: 5
Training loss: 2.616880302050285
Validation loss: 2.530894513920388

Epoch: 6| Step: 6
Training loss: 2.4369429905562403
Validation loss: 2.530316028491472

Epoch: 6| Step: 7
Training loss: 2.9220781714644333
Validation loss: 2.5296443321569493

Epoch: 6| Step: 8
Training loss: 2.6343598389104437
Validation loss: 2.536109657442029

Epoch: 6| Step: 9
Training loss: 3.3042026461694394
Validation loss: 2.519101764398041

Epoch: 6| Step: 10
Training loss: 2.383090744032466
Validation loss: 2.5242465732557227

Epoch: 6| Step: 11
Training loss: 2.594397774203296
Validation loss: 2.5283935119537095

Epoch: 6| Step: 12
Training loss: 3.081146306581535
Validation loss: 2.530814077217279

Epoch: 6| Step: 13
Training loss: 2.7734850382424523
Validation loss: 2.5170653228808266

Epoch: 27| Step: 0
Training loss: 2.7724975712510145
Validation loss: 2.5179015395890554

Epoch: 6| Step: 1
Training loss: 2.4587311072658826
Validation loss: 2.522044306308672

Epoch: 6| Step: 2
Training loss: 2.6549976762664453
Validation loss: 2.536951199149565

Epoch: 6| Step: 3
Training loss: 2.8673395017823484
Validation loss: 2.524777645444064

Epoch: 6| Step: 4
Training loss: 2.685797484755668
Validation loss: 2.527694708972143

Epoch: 6| Step: 5
Training loss: 3.2897555601918187
Validation loss: 2.532300229130079

Epoch: 6| Step: 6
Training loss: 2.913725559912733
Validation loss: 2.518455155122986

Epoch: 6| Step: 7
Training loss: 3.3779439448871567
Validation loss: 2.53023643107384

Epoch: 6| Step: 8
Training loss: 2.7752026595612334
Validation loss: 2.516058778748329

Epoch: 6| Step: 9
Training loss: 2.368276817547664
Validation loss: 2.52670659882277

Epoch: 6| Step: 10
Training loss: 2.375174465798451
Validation loss: 2.5335573440897887

Epoch: 6| Step: 11
Training loss: 2.9408050773850736
Validation loss: 2.5377140717240776

Epoch: 6| Step: 12
Training loss: 2.988343640841742
Validation loss: 2.53621099015296

Epoch: 6| Step: 13
Training loss: 2.912491525793231
Validation loss: 2.527525931919565

Epoch: 28| Step: 0
Training loss: 3.101258539251882
Validation loss: 2.5367796514689593

Epoch: 6| Step: 1
Training loss: 2.1580150953866157
Validation loss: 2.5230327395747816

Epoch: 6| Step: 2
Training loss: 3.112056170459213
Validation loss: 2.5223247015249024

Epoch: 6| Step: 3
Training loss: 3.354083911198677
Validation loss: 2.5287349293171277

Epoch: 6| Step: 4
Training loss: 2.3649171321940172
Validation loss: 2.5242503218556656

Epoch: 6| Step: 5
Training loss: 2.924748603907202
Validation loss: 2.537962441501548

Epoch: 6| Step: 6
Training loss: 3.3016913790085285
Validation loss: 2.525982981132167

Epoch: 6| Step: 7
Training loss: 2.7402199318601013
Validation loss: 2.5264008760858947

Epoch: 6| Step: 8
Training loss: 2.9807759097949753
Validation loss: 2.529365773065739

Epoch: 6| Step: 9
Training loss: 2.4152154730794906
Validation loss: 2.520155726535357

Epoch: 6| Step: 10
Training loss: 2.7844689418645
Validation loss: 2.519584823207991

Epoch: 6| Step: 11
Training loss: 2.177998972329422
Validation loss: 2.5274603000047904

Epoch: 6| Step: 12
Training loss: 2.722228707632354
Validation loss: 2.520116249617202

Epoch: 6| Step: 13
Training loss: 3.365453145094457
Validation loss: 2.534357459260977

Epoch: 29| Step: 0
Training loss: 2.8834993531458064
Validation loss: 2.5300866313082433

Epoch: 6| Step: 1
Training loss: 2.9542218144429615
Validation loss: 2.520883458662154

Epoch: 6| Step: 2
Training loss: 2.4485808641519307
Validation loss: 2.5240010882689368

Epoch: 6| Step: 3
Training loss: 3.4694361652417673
Validation loss: 2.524916842291475

Epoch: 6| Step: 4
Training loss: 3.4481079109989516
Validation loss: 2.5402349221555185

Epoch: 6| Step: 5
Training loss: 2.4403564149039165
Validation loss: 2.5256146700044675

Epoch: 6| Step: 6
Training loss: 2.766366115775573
Validation loss: 2.5280769865515857

Epoch: 6| Step: 7
Training loss: 2.7300787607646098
Validation loss: 2.5417898105569616

Epoch: 6| Step: 8
Training loss: 2.1104190079530745
Validation loss: 2.5222972021949794

Epoch: 6| Step: 9
Training loss: 2.078724710077813
Validation loss: 2.5374199341838297

Epoch: 6| Step: 10
Training loss: 2.880990959653802
Validation loss: 2.5439726080544243

Epoch: 6| Step: 11
Training loss: 3.0120119578008895
Validation loss: 2.536421851590884

Epoch: 6| Step: 12
Training loss: 3.299966673249241
Validation loss: 2.521709972782083

Epoch: 6| Step: 13
Training loss: 2.3483398254752412
Validation loss: 2.5292857803466915

Epoch: 30| Step: 0
Training loss: 2.822841281986962
Validation loss: 2.5288493334543776

Epoch: 6| Step: 1
Training loss: 2.676739909388095
Validation loss: 2.529506943066019

Epoch: 6| Step: 2
Training loss: 2.7095344716519234
Validation loss: 2.5202555650695144

Epoch: 6| Step: 3
Training loss: 2.5622825530298723
Validation loss: 2.5229329997626233

Epoch: 6| Step: 4
Training loss: 3.250256748328309
Validation loss: 2.5371013206322446

Epoch: 6| Step: 5
Training loss: 2.87155442467016
Validation loss: 2.5425247443160646

Epoch: 6| Step: 6
Training loss: 2.3070114574106526
Validation loss: 2.5148207083772656

Epoch: 6| Step: 7
Training loss: 2.381622617708854
Validation loss: 2.5267193931165677

Epoch: 6| Step: 8
Training loss: 2.992560699535646
Validation loss: 2.5370052694924907

Epoch: 6| Step: 9
Training loss: 3.3240434575734588
Validation loss: 2.5224111167463312

Epoch: 6| Step: 10
Training loss: 2.9073295639084793
Validation loss: 2.5189358485245856

Epoch: 6| Step: 11
Training loss: 2.693250138001884
Validation loss: 2.518153690937255

Epoch: 6| Step: 12
Training loss: 2.8937496308888804
Validation loss: 2.5354618189386935

Epoch: 6| Step: 13
Training loss: 3.0076880491197673
Validation loss: 2.514137013979735

Epoch: 31| Step: 0
Training loss: 3.1096746405756437
Validation loss: 2.5260836027009486

Epoch: 6| Step: 1
Training loss: 2.666123921077699
Validation loss: 2.520695673344019

Epoch: 6| Step: 2
Training loss: 2.6629844117404917
Validation loss: 2.5228658292936172

Epoch: 6| Step: 3
Training loss: 2.7876433707688566
Validation loss: 2.5201114206281585

Epoch: 6| Step: 4
Training loss: 2.6252197900219425
Validation loss: 2.5186261553872624

Epoch: 6| Step: 5
Training loss: 3.3271864163062066
Validation loss: 2.527236931908194

Epoch: 6| Step: 6
Training loss: 3.246717996628871
Validation loss: 2.537702368338902

Epoch: 6| Step: 7
Training loss: 2.4476208014284913
Validation loss: 2.5386196248131228

Epoch: 6| Step: 8
Training loss: 2.5594591846524164
Validation loss: 2.536753622615046

Epoch: 6| Step: 9
Training loss: 2.4523971352504015
Validation loss: 2.525362011927792

Epoch: 6| Step: 10
Training loss: 2.66974282658486
Validation loss: 2.516348382514116

Epoch: 6| Step: 11
Training loss: 2.5121680728423597
Validation loss: 2.519465269913405

Epoch: 6| Step: 12
Training loss: 2.9862157128123323
Validation loss: 2.5240060748679225

Epoch: 6| Step: 13
Training loss: 3.3744259098774774
Validation loss: 2.520676780794866

Epoch: 32| Step: 0
Training loss: 2.811566346223021
Validation loss: 2.527697540675125

Epoch: 6| Step: 1
Training loss: 2.9854021950952423
Validation loss: 2.523921180472541

Epoch: 6| Step: 2
Training loss: 2.4635408709298288
Validation loss: 2.5276026987047993

Epoch: 6| Step: 3
Training loss: 2.3504652333856146
Validation loss: 2.5283137622461114

Epoch: 6| Step: 4
Training loss: 2.3187163029198965
Validation loss: 2.5263525095514114

Epoch: 6| Step: 5
Training loss: 3.0707249643432126
Validation loss: 2.5264891660768476

Epoch: 6| Step: 6
Training loss: 3.041053257233434
Validation loss: 2.5269389933673945

Epoch: 6| Step: 7
Training loss: 2.157164890967144
Validation loss: 2.527551933326607

Epoch: 6| Step: 8
Training loss: 3.525109818283259
Validation loss: 2.5338121595832694

Epoch: 6| Step: 9
Training loss: 3.149373637095204
Validation loss: 2.526286674637963

Epoch: 6| Step: 10
Training loss: 2.8755132797483784
Validation loss: 2.5290302269880156

Epoch: 6| Step: 11
Training loss: 2.7865238550391327
Validation loss: 2.5251103834247397

Epoch: 6| Step: 12
Training loss: 2.6147845268096312
Validation loss: 2.5286007326258098

Epoch: 6| Step: 13
Training loss: 2.7597746096368256
Validation loss: 2.5095502580077396

Epoch: 33| Step: 0
Training loss: 3.017367951317455
Validation loss: 2.5260540171047396

Epoch: 6| Step: 1
Training loss: 3.3972146125043508
Validation loss: 2.5204709581671363

Epoch: 6| Step: 2
Training loss: 2.8303160215315675
Validation loss: 2.520112971968601

Epoch: 6| Step: 3
Training loss: 2.4332931602332044
Validation loss: 2.5167547593620294

Epoch: 6| Step: 4
Training loss: 2.36909684834993
Validation loss: 2.5312070590982225

Epoch: 6| Step: 5
Training loss: 3.0790846824485767
Validation loss: 2.532272567822446

Epoch: 6| Step: 6
Training loss: 2.0405742551327184
Validation loss: 2.524977906945848

Epoch: 6| Step: 7
Training loss: 2.9194609925776738
Validation loss: 2.5149830787878993

Epoch: 6| Step: 8
Training loss: 2.5355837421854663
Validation loss: 2.5213862231209965

Epoch: 6| Step: 9
Training loss: 3.247743997312984
Validation loss: 2.5191834563544737

Epoch: 6| Step: 10
Training loss: 2.4409322782105822
Validation loss: 2.521549242860189

Epoch: 6| Step: 11
Training loss: 2.4191489351494195
Validation loss: 2.529794526476233

Epoch: 6| Step: 12
Training loss: 3.3742576065175585
Validation loss: 2.5330744227170374

Epoch: 6| Step: 13
Training loss: 2.87797657669853
Validation loss: 2.5389294388631196

Epoch: 34| Step: 0
Training loss: 2.0429232357053615
Validation loss: 2.524507625409972

Epoch: 6| Step: 1
Training loss: 2.810805764114465
Validation loss: 2.527782532885325

Epoch: 6| Step: 2
Training loss: 2.7586067936193768
Validation loss: 2.527272591526862

Epoch: 6| Step: 3
Training loss: 2.8289131204500078
Validation loss: 2.5270718884784413

Epoch: 6| Step: 4
Training loss: 3.0439454691510224
Validation loss: 2.5286271485431175

Epoch: 6| Step: 5
Training loss: 3.0434132791180706
Validation loss: 2.536603922212731

Epoch: 6| Step: 6
Training loss: 2.288472591070154
Validation loss: 2.515532887119554

Epoch: 6| Step: 7
Training loss: 2.65873772306706
Validation loss: 2.5167736161606427

Epoch: 6| Step: 8
Training loss: 3.98731329788747
Validation loss: 2.516014267215949

Epoch: 6| Step: 9
Training loss: 2.5701863452133376
Validation loss: 2.5194255450874126

Epoch: 6| Step: 10
Training loss: 2.7806133441676466
Validation loss: 2.5182009408622

Epoch: 6| Step: 11
Training loss: 2.140988061564273
Validation loss: 2.5132656264888396

Epoch: 6| Step: 12
Training loss: 3.1808336146568337
Validation loss: 2.533728690039448

Epoch: 6| Step: 13
Training loss: 2.380082564644842
Validation loss: 2.5321876412756983

Epoch: 35| Step: 0
Training loss: 3.0438785784311326
Validation loss: 2.517733603869914

Epoch: 6| Step: 1
Training loss: 2.234072364639144
Validation loss: 2.532233707037029

Epoch: 6| Step: 2
Training loss: 2.2785383856735426
Validation loss: 2.5248848021245176

Epoch: 6| Step: 3
Training loss: 2.885025126382507
Validation loss: 2.5232065721780446

Epoch: 6| Step: 4
Training loss: 2.476958811725898
Validation loss: 2.5176984094021138

Epoch: 6| Step: 5
Training loss: 3.0774521455367667
Validation loss: 2.5286434440508145

Epoch: 6| Step: 6
Training loss: 2.8465659483602797
Validation loss: 2.528122240935558

Epoch: 6| Step: 7
Training loss: 2.9485316808847677
Validation loss: 2.536363004117819

Epoch: 6| Step: 8
Training loss: 2.689676512372991
Validation loss: 2.52178125568749

Epoch: 6| Step: 9
Training loss: 3.170686846911369
Validation loss: 2.520561798232457

Epoch: 6| Step: 10
Training loss: 2.2591472758951707
Validation loss: 2.539582784274216

Epoch: 6| Step: 11
Training loss: 2.5313073610941332
Validation loss: 2.526809163405684

Epoch: 6| Step: 12
Training loss: 3.1974253489330304
Validation loss: 2.530327563407182

Epoch: 6| Step: 13
Training loss: 3.43485977042092
Validation loss: 2.529637472177951

Epoch: 36| Step: 0
Training loss: 3.528675862802726
Validation loss: 2.5345534626158908

Epoch: 6| Step: 1
Training loss: 3.1290007349576054
Validation loss: 2.5289904456112233

Epoch: 6| Step: 2
Training loss: 2.9531721484744824
Validation loss: 2.5202175596128624

Epoch: 6| Step: 3
Training loss: 2.550738814791067
Validation loss: 2.5360558171852823

Epoch: 6| Step: 4
Training loss: 2.8828442579551536
Validation loss: 2.5209434769630428

Epoch: 6| Step: 5
Training loss: 2.257765403177153
Validation loss: 2.52719848264016

Epoch: 6| Step: 6
Training loss: 2.410763062886861
Validation loss: 2.5078875512854646

Epoch: 6| Step: 7
Training loss: 3.2818844136510092
Validation loss: 2.522425216465009

Epoch: 6| Step: 8
Training loss: 2.6875587279534434
Validation loss: 2.531825241421417

Epoch: 6| Step: 9
Training loss: 2.0394536954874942
Validation loss: 2.5176294761433287

Epoch: 6| Step: 10
Training loss: 3.3140019304710755
Validation loss: 2.521531994610029

Epoch: 6| Step: 11
Training loss: 2.418684106367858
Validation loss: 2.522078048571412

Epoch: 6| Step: 12
Training loss: 2.4726953970415146
Validation loss: 2.5181684986289152

Epoch: 6| Step: 13
Training loss: 2.5541841436869936
Validation loss: 2.5275230482955466

Epoch: 37| Step: 0
Training loss: 3.319759547247072
Validation loss: 2.5199469375183625

Epoch: 6| Step: 1
Training loss: 2.095693113617746
Validation loss: 2.5185923475387373

Epoch: 6| Step: 2
Training loss: 2.501086952427587
Validation loss: 2.511068928692447

Epoch: 6| Step: 3
Training loss: 2.3512153242475606
Validation loss: 2.5347776575376413

Epoch: 6| Step: 4
Training loss: 3.070088075001928
Validation loss: 2.521708405141422

Epoch: 6| Step: 5
Training loss: 3.11515539182789
Validation loss: 2.50518976538569

Epoch: 6| Step: 6
Training loss: 2.586658020136169
Validation loss: 2.5162783425082114

Epoch: 6| Step: 7
Training loss: 2.802289782627391
Validation loss: 2.509790513920851

Epoch: 6| Step: 8
Training loss: 2.6410645790567657
Validation loss: 2.523001948663907

Epoch: 6| Step: 9
Training loss: 2.652497097520741
Validation loss: 2.534681599257252

Epoch: 6| Step: 10
Training loss: 3.284101863577621
Validation loss: 2.5198792255678883

Epoch: 6| Step: 11
Training loss: 3.2373848147135056
Validation loss: 2.51686245115226

Epoch: 6| Step: 12
Training loss: 2.381620315232412
Validation loss: 2.523423149921213

Epoch: 6| Step: 13
Training loss: 2.7888204004693846
Validation loss: 2.5196043435887363

Epoch: 38| Step: 0
Training loss: 2.8763394759881753
Validation loss: 2.521509638302849

Epoch: 6| Step: 1
Training loss: 3.1084415434000605
Validation loss: 2.523322799698452

Epoch: 6| Step: 2
Training loss: 2.64152222688744
Validation loss: 2.535789056961687

Epoch: 6| Step: 3
Training loss: 2.307329738696073
Validation loss: 2.5184666843048014

Epoch: 6| Step: 4
Training loss: 2.943307047114893
Validation loss: 2.5141685731904047

Epoch: 6| Step: 5
Training loss: 2.366377185077574
Validation loss: 2.5125799672345046

Epoch: 6| Step: 6
Training loss: 2.9140649544958666
Validation loss: 2.513341776693656

Epoch: 6| Step: 7
Training loss: 2.792087826820321
Validation loss: 2.5230209213476145

Epoch: 6| Step: 8
Training loss: 2.7672008615318737
Validation loss: 2.536587286717193

Epoch: 6| Step: 9
Training loss: 2.6905959283939564
Validation loss: 2.5105419111524343

Epoch: 6| Step: 10
Training loss: 2.648637162055827
Validation loss: 2.529423715579457

Epoch: 6| Step: 11
Training loss: 3.265903296772896
Validation loss: 2.532516727674696

Epoch: 6| Step: 12
Training loss: 2.936459620866677
Validation loss: 2.522993717165442

Epoch: 6| Step: 13
Training loss: 2.5093518817829565
Validation loss: 2.514963356383434

Epoch: 39| Step: 0
Training loss: 2.7248333801285707
Validation loss: 2.519409148238651

Epoch: 6| Step: 1
Training loss: 3.181221856552974
Validation loss: 2.5111697497123107

Epoch: 6| Step: 2
Training loss: 2.754085453777087
Validation loss: 2.5093054506161865

Epoch: 6| Step: 3
Training loss: 2.2317021528883605
Validation loss: 2.5113097753393157

Epoch: 6| Step: 4
Training loss: 2.56443583242218
Validation loss: 2.5174585741690567

Epoch: 6| Step: 5
Training loss: 3.07892547887931
Validation loss: 2.520649248230916

Epoch: 6| Step: 6
Training loss: 2.778976539921853
Validation loss: 2.5229878079673838

Epoch: 6| Step: 7
Training loss: 3.1984072297587507
Validation loss: 2.525042245438974

Epoch: 6| Step: 8
Training loss: 3.2998166813650776
Validation loss: 2.5166752087435142

Epoch: 6| Step: 9
Training loss: 2.6719184559639997
Validation loss: 2.5230389976953536

Epoch: 6| Step: 10
Training loss: 1.9897027770400013
Validation loss: 2.517586463815065

Epoch: 6| Step: 11
Training loss: 2.5233477408209035
Validation loss: 2.5208068767621357

Epoch: 6| Step: 12
Training loss: 2.9871273430829737
Validation loss: 2.518225714853416

Epoch: 6| Step: 13
Training loss: 2.4949902884804613
Validation loss: 2.5285928407472738

Epoch: 40| Step: 0
Training loss: 2.574865974716013
Validation loss: 2.5178925033534805

Epoch: 6| Step: 1
Training loss: 2.200466635373305
Validation loss: 2.524128391497295

Epoch: 6| Step: 2
Training loss: 2.973770554332404
Validation loss: 2.5146445150371655

Epoch: 6| Step: 3
Training loss: 2.3891445387831323
Validation loss: 2.5249018802461105

Epoch: 6| Step: 4
Training loss: 2.7348800628697543
Validation loss: 2.5230313404117513

Epoch: 6| Step: 5
Training loss: 2.970966676035311
Validation loss: 2.5283728923751907

Epoch: 6| Step: 6
Training loss: 2.871025655548786
Validation loss: 2.5182609976456547

Epoch: 6| Step: 7
Training loss: 2.7102940040255477
Validation loss: 2.5218708957725586

Epoch: 6| Step: 8
Training loss: 2.424663882213662
Validation loss: 2.5169460277944564

Epoch: 6| Step: 9
Training loss: 2.655663459195894
Validation loss: 2.509912292017803

Epoch: 6| Step: 10
Training loss: 2.8784338305993193
Validation loss: 2.5134035142465914

Epoch: 6| Step: 11
Training loss: 2.609898132148623
Validation loss: 2.5156846291286215

Epoch: 6| Step: 12
Training loss: 3.7287013156026005
Validation loss: 2.5165813760281575

Epoch: 6| Step: 13
Training loss: 2.900912562202191
Validation loss: 2.5211381035602107

Epoch: 41| Step: 0
Training loss: 2.6450299422474868
Validation loss: 2.5116641240689845

Epoch: 6| Step: 1
Training loss: 2.81807672956306
Validation loss: 2.519901251455727

Epoch: 6| Step: 2
Training loss: 3.1891798193143446
Validation loss: 2.516540665403669

Epoch: 6| Step: 3
Training loss: 2.418737335566207
Validation loss: 2.5222620002571263

Epoch: 6| Step: 4
Training loss: 2.5998321368975277
Validation loss: 2.499450957602978

Epoch: 6| Step: 5
Training loss: 2.9738237892799733
Validation loss: 2.49788679517145

Epoch: 6| Step: 6
Training loss: 2.859674323419181
Validation loss: 2.5178475762360146

Epoch: 6| Step: 7
Training loss: 1.8126001001537522
Validation loss: 2.5346989835725635

Epoch: 6| Step: 8
Training loss: 2.644993435972322
Validation loss: 2.5114511094561682

Epoch: 6| Step: 9
Training loss: 2.0145039360971784
Validation loss: 2.5216134085683417

Epoch: 6| Step: 10
Training loss: 3.3908708193220924
Validation loss: 2.5144547038522984

Epoch: 6| Step: 11
Training loss: 2.851525209784001
Validation loss: 2.517702642254279

Epoch: 6| Step: 12
Training loss: 2.930975953653246
Validation loss: 2.510195778607502

Epoch: 6| Step: 13
Training loss: 3.5658871794187172
Validation loss: 2.5226992860063895

Epoch: 42| Step: 0
Training loss: 2.471515313948615
Validation loss: 2.491864411603977

Epoch: 6| Step: 1
Training loss: 3.1529777862995543
Validation loss: 2.5000400017029927

Epoch: 6| Step: 2
Training loss: 2.8304983054841477
Validation loss: 2.509196066435173

Epoch: 6| Step: 3
Training loss: 2.4791746593528154
Validation loss: 2.5131825190987116

Epoch: 6| Step: 4
Training loss: 2.7528649058979466
Validation loss: 2.513969188800578

Epoch: 6| Step: 5
Training loss: 3.1773691184328126
Validation loss: 2.511168846730523

Epoch: 6| Step: 6
Training loss: 3.3020213669860206
Validation loss: 2.523894142419161

Epoch: 6| Step: 7
Training loss: 2.889247586731127
Validation loss: 2.513217204550455

Epoch: 6| Step: 8
Training loss: 1.7974357725083598
Validation loss: 2.520247426322743

Epoch: 6| Step: 9
Training loss: 2.8901069795548198
Validation loss: 2.520568408297981

Epoch: 6| Step: 10
Training loss: 2.6494922619368473
Validation loss: 2.5205670321771363

Epoch: 6| Step: 11
Training loss: 2.659713820357591
Validation loss: 2.5101698090827966

Epoch: 6| Step: 12
Training loss: 2.7527701557292135
Validation loss: 2.503274318732482

Epoch: 6| Step: 13
Training loss: 2.755367848923196
Validation loss: 2.509417691043414

Epoch: 43| Step: 0
Training loss: 2.637345845567255
Validation loss: 2.5017048088761684

Epoch: 6| Step: 1
Training loss: 2.706792559428563
Validation loss: 2.511775901870295

Epoch: 6| Step: 2
Training loss: 2.45708170779867
Validation loss: 2.50242907125943

Epoch: 6| Step: 3
Training loss: 2.893012303357511
Validation loss: 2.512978071975046

Epoch: 6| Step: 4
Training loss: 2.8325204992267996
Validation loss: 2.5052068672502497

Epoch: 6| Step: 5
Training loss: 2.6336535460304566
Validation loss: 2.511305227501576

Epoch: 6| Step: 6
Training loss: 2.6043942364759713
Validation loss: 2.5107020836796

Epoch: 6| Step: 7
Training loss: 3.325643411207934
Validation loss: 2.5067025545542925

Epoch: 6| Step: 8
Training loss: 2.548121235189494
Validation loss: 2.5242583075432403

Epoch: 6| Step: 9
Training loss: 3.5095197095783557
Validation loss: 2.5144046592088243

Epoch: 6| Step: 10
Training loss: 2.538674474557255
Validation loss: 2.511328906792797

Epoch: 6| Step: 11
Training loss: 3.2043655598343093
Validation loss: 2.5116909814480173

Epoch: 6| Step: 12
Training loss: 2.2656304721108484
Validation loss: 2.524397562985859

Epoch: 6| Step: 13
Training loss: 1.9895833067036839
Validation loss: 2.516081818264389

Epoch: 44| Step: 0
Training loss: 2.442154475188327
Validation loss: 2.5109340635106006

Epoch: 6| Step: 1
Training loss: 2.4129152009863253
Validation loss: 2.5144859685043235

Epoch: 6| Step: 2
Training loss: 2.738993553429796
Validation loss: 2.512416982342948

Epoch: 6| Step: 3
Training loss: 2.469543715737875
Validation loss: 2.5309314788171844

Epoch: 6| Step: 4
Training loss: 2.8146676081745134
Validation loss: 2.522643258636884

Epoch: 6| Step: 5
Training loss: 2.703366836578564
Validation loss: 2.5191418484769823

Epoch: 6| Step: 6
Training loss: 3.074558728818353
Validation loss: 2.5180605811904124

Epoch: 6| Step: 7
Training loss: 2.914660026917336
Validation loss: 2.5173530989422637

Epoch: 6| Step: 8
Training loss: 3.1031616085847253
Validation loss: 2.5149160578636525

Epoch: 6| Step: 9
Training loss: 2.947249769568849
Validation loss: 2.4973270852865443

Epoch: 6| Step: 10
Training loss: 3.145671983501014
Validation loss: 2.5107511463420975

Epoch: 6| Step: 11
Training loss: 3.0599276580237755
Validation loss: 2.5113446275301756

Epoch: 6| Step: 12
Training loss: 2.435908066704496
Validation loss: 2.5288203124444615

Epoch: 6| Step: 13
Training loss: 1.9688027389970784
Validation loss: 2.507786062128909

Epoch: 45| Step: 0
Training loss: 2.6120483044455898
Validation loss: 2.5142251753503047

Epoch: 6| Step: 1
Training loss: 3.2537797809400075
Validation loss: 2.5168832699436146

Epoch: 6| Step: 2
Training loss: 3.032058607969286
Validation loss: 2.5028766888630454

Epoch: 6| Step: 3
Training loss: 2.8634276307121302
Validation loss: 2.5073900515781613

Epoch: 6| Step: 4
Training loss: 2.779142974645772
Validation loss: 2.510157401258057

Epoch: 6| Step: 5
Training loss: 2.2822856903578286
Validation loss: 2.5004575833587745

Epoch: 6| Step: 6
Training loss: 2.2541531273887117
Validation loss: 2.505444180410686

Epoch: 6| Step: 7
Training loss: 2.5075634033463157
Validation loss: 2.5166775679628954

Epoch: 6| Step: 8
Training loss: 2.9398781098510276
Validation loss: 2.51511569030696

Epoch: 6| Step: 9
Training loss: 2.6477843973142234
Validation loss: 2.5049118232530296

Epoch: 6| Step: 10
Training loss: 2.182916799031828
Validation loss: 2.50631558071607

Epoch: 6| Step: 11
Training loss: 3.1268315860495415
Validation loss: 2.511529293910443

Epoch: 6| Step: 12
Training loss: 3.058077363018
Validation loss: 2.5029758779445572

Epoch: 6| Step: 13
Training loss: 3.03443693967984
Validation loss: 2.5113540834042283

Epoch: 46| Step: 0
Training loss: 2.472077264238764
Validation loss: 2.5154354691818086

Epoch: 6| Step: 1
Training loss: 2.4770849982390546
Validation loss: 2.5205113388274416

Epoch: 6| Step: 2
Training loss: 2.8059132057410214
Validation loss: 2.512836305471313

Epoch: 6| Step: 3
Training loss: 2.937137175533828
Validation loss: 2.5041886607878694

Epoch: 6| Step: 4
Training loss: 2.179960172271881
Validation loss: 2.5171852855125594

Epoch: 6| Step: 5
Training loss: 3.2901006586972916
Validation loss: 2.5158498769639412

Epoch: 6| Step: 6
Training loss: 2.6807514002735053
Validation loss: 2.510249774709083

Epoch: 6| Step: 7
Training loss: 2.874881741952598
Validation loss: 2.5110371906548417

Epoch: 6| Step: 8
Training loss: 3.1775337441946396
Validation loss: 2.520230678284018

Epoch: 6| Step: 9
Training loss: 2.663368291263382
Validation loss: 2.514328805274602

Epoch: 6| Step: 10
Training loss: 2.6206822989104404
Validation loss: 2.509562104939348

Epoch: 6| Step: 11
Training loss: 1.9195269375396715
Validation loss: 2.5029769595386506

Epoch: 6| Step: 12
Training loss: 2.9426082267725566
Validation loss: 2.5062706670163943

Epoch: 6| Step: 13
Training loss: 3.4162591985864115
Validation loss: 2.5138891507862478

Epoch: 47| Step: 0
Training loss: 2.7786947792459133
Validation loss: 2.517211782524024

Epoch: 6| Step: 1
Training loss: 2.6858639727565072
Validation loss: 2.520282783549518

Epoch: 6| Step: 2
Training loss: 3.0590053003769664
Validation loss: 2.5137355105516175

Epoch: 6| Step: 3
Training loss: 3.290242542961858
Validation loss: 2.517864820198491

Epoch: 6| Step: 4
Training loss: 2.9316811250637707
Validation loss: 2.5072424404932607

Epoch: 6| Step: 5
Training loss: 2.995447360143412
Validation loss: 2.5167655318552242

Epoch: 6| Step: 6
Training loss: 2.5448358715921713
Validation loss: 2.509828305466243

Epoch: 6| Step: 7
Training loss: 2.7038954149595105
Validation loss: 2.5108599180623274

Epoch: 6| Step: 8
Training loss: 2.7026382625475494
Validation loss: 2.513636376848111

Epoch: 6| Step: 9
Training loss: 2.8277360005801553
Validation loss: 2.5254990037407476

Epoch: 6| Step: 10
Training loss: 2.5315772892852304
Validation loss: 2.506005599548672

Epoch: 6| Step: 11
Training loss: 2.9405430392154637
Validation loss: 2.511644747648682

Epoch: 6| Step: 12
Training loss: 1.8406524500718668
Validation loss: 2.514958006802364

Epoch: 6| Step: 13
Training loss: 2.0991254665828785
Validation loss: 2.501349641673931

Epoch: 48| Step: 0
Training loss: 2.722526996012814
Validation loss: 2.5080385139187618

Epoch: 6| Step: 1
Training loss: 2.597090259356918
Validation loss: 2.4856557415471396

Epoch: 6| Step: 2
Training loss: 2.4630913890838486
Validation loss: 2.5101683588339965

Epoch: 6| Step: 3
Training loss: 2.4904202979001098
Validation loss: 2.5245824423710186

Epoch: 6| Step: 4
Training loss: 2.6577509510195387
Validation loss: 2.5097736332818554

Epoch: 6| Step: 5
Training loss: 2.3437628173477654
Validation loss: 2.5078195842634807

Epoch: 6| Step: 6
Training loss: 3.07314086785835
Validation loss: 2.508044430229223

Epoch: 6| Step: 7
Training loss: 2.8478364194118515
Validation loss: 2.5195165123857857

Epoch: 6| Step: 8
Training loss: 3.070211238986978
Validation loss: 2.497826051459523

Epoch: 6| Step: 9
Training loss: 2.626667401399203
Validation loss: 2.505221616389011

Epoch: 6| Step: 10
Training loss: 2.570608011899575
Validation loss: 2.497915862544624

Epoch: 6| Step: 11
Training loss: 3.0035017557229526
Validation loss: 2.50208553365923

Epoch: 6| Step: 12
Training loss: 3.31002585663161
Validation loss: 2.512113178082223

Epoch: 6| Step: 13
Training loss: 2.356711494724472
Validation loss: 2.4953318810453697

Epoch: 49| Step: 0
Training loss: 2.7788161869377674
Validation loss: 2.5097715760547463

Epoch: 6| Step: 1
Training loss: 2.731884939733753
Validation loss: 2.5126112842928645

Epoch: 6| Step: 2
Training loss: 2.697324317111253
Validation loss: 2.518839320449935

Epoch: 6| Step: 3
Training loss: 2.550107998524412
Validation loss: 2.5110488753877145

Epoch: 6| Step: 4
Training loss: 2.6497446620933105
Validation loss: 2.493644846563199

Epoch: 6| Step: 5
Training loss: 2.747182269481392
Validation loss: 2.506810203153721

Epoch: 6| Step: 6
Training loss: 3.0518842161321844
Validation loss: 2.511308318602961

Epoch: 6| Step: 7
Training loss: 2.668695889712805
Validation loss: 2.5106255184836987

Epoch: 6| Step: 8
Training loss: 2.1091839739168408
Validation loss: 2.505846194903186

Epoch: 6| Step: 9
Training loss: 2.832799094452992
Validation loss: 2.508769297533212

Epoch: 6| Step: 10
Training loss: 2.9812784957323615
Validation loss: 2.5201063627430482

Epoch: 6| Step: 11
Training loss: 2.4721002179543334
Validation loss: 2.513518192925911

Epoch: 6| Step: 12
Training loss: 2.6559672485653243
Validation loss: 2.5091758704492717

Epoch: 6| Step: 13
Training loss: 3.593280131265249
Validation loss: 2.5157187359104496

Epoch: 50| Step: 0
Training loss: 1.864386144969851
Validation loss: 2.5227155029395747

Epoch: 6| Step: 1
Training loss: 2.5199237369926077
Validation loss: 2.512958286906977

Epoch: 6| Step: 2
Training loss: 3.181518927038698
Validation loss: 2.5126031360896626

Epoch: 6| Step: 3
Training loss: 2.448205181461445
Validation loss: 2.5000749269147735

Epoch: 6| Step: 4
Training loss: 2.9058614491607733
Validation loss: 2.5060944750824623

Epoch: 6| Step: 5
Training loss: 1.8386415737192736
Validation loss: 2.5182416307543622

Epoch: 6| Step: 6
Training loss: 3.112291817807561
Validation loss: 2.511604134100969

Epoch: 6| Step: 7
Training loss: 2.846874993300202
Validation loss: 2.5123759593413375

Epoch: 6| Step: 8
Training loss: 2.899926638497428
Validation loss: 2.5185880846273223

Epoch: 6| Step: 9
Training loss: 2.5831286339003956
Validation loss: 2.495428336301829

Epoch: 6| Step: 10
Training loss: 2.3494176873634123
Validation loss: 2.5231312470337666

Epoch: 6| Step: 11
Training loss: 2.2083263277146643
Validation loss: 2.5100804691287455

Epoch: 6| Step: 12
Training loss: 3.5635013176979955
Validation loss: 2.504555699300797

Epoch: 6| Step: 13
Training loss: 3.678144840261512
Validation loss: 2.498866759607139

Epoch: 51| Step: 0
Training loss: 2.930371827628149
Validation loss: 2.5115798225116728

Epoch: 6| Step: 1
Training loss: 3.2247749900686506
Validation loss: 2.5046656019007276

Epoch: 6| Step: 2
Training loss: 2.376061252600791
Validation loss: 2.506796943174026

Epoch: 6| Step: 3
Training loss: 3.2093602968527306
Validation loss: 2.512522441331366

Epoch: 6| Step: 4
Training loss: 3.2121367430979433
Validation loss: 2.5117825177060076

Epoch: 6| Step: 5
Training loss: 2.4903216896457216
Validation loss: 2.4997188445909475

Epoch: 6| Step: 6
Training loss: 2.940059115276147
Validation loss: 2.513401109114476

Epoch: 6| Step: 7
Training loss: 2.7078345401877293
Validation loss: 2.5150683069911026

Epoch: 6| Step: 8
Training loss: 2.147446282351085
Validation loss: 2.50274882399447

Epoch: 6| Step: 9
Training loss: 2.4463510471189016
Validation loss: 2.500962927170023

Epoch: 6| Step: 10
Training loss: 2.699896058095167
Validation loss: 2.502674794572448

Epoch: 6| Step: 11
Training loss: 2.6633880745995673
Validation loss: 2.507952977310993

Epoch: 6| Step: 12
Training loss: 2.70352064114863
Validation loss: 2.5066427168698

Epoch: 6| Step: 13
Training loss: 2.0335439786561444
Validation loss: 2.50569880799167

Epoch: 52| Step: 0
Training loss: 3.3417035551881074
Validation loss: 2.501679023796379

Epoch: 6| Step: 1
Training loss: 2.233436440702032
Validation loss: 2.499500375475339

Epoch: 6| Step: 2
Training loss: 2.519215929275502
Validation loss: 2.5115565926692955

Epoch: 6| Step: 3
Training loss: 2.7905339652289114
Validation loss: 2.5006604055571335

Epoch: 6| Step: 4
Training loss: 3.0235488437387006
Validation loss: 2.5086110659114307

Epoch: 6| Step: 5
Training loss: 2.5327202565400277
Validation loss: 2.508491161307195

Epoch: 6| Step: 6
Training loss: 2.7523164529608093
Validation loss: 2.485540064076222

Epoch: 6| Step: 7
Training loss: 3.5205613130903592
Validation loss: 2.4965021633560265

Epoch: 6| Step: 8
Training loss: 2.536709396396753
Validation loss: 2.4970851209908527

Epoch: 6| Step: 9
Training loss: 2.467363088687937
Validation loss: 2.509522273406549

Epoch: 6| Step: 10
Training loss: 2.9297945943967547
Validation loss: 2.5119303733113263

Epoch: 6| Step: 11
Training loss: 1.9739125094634968
Validation loss: 2.4931800993149706

Epoch: 6| Step: 12
Training loss: 3.0126992693956995
Validation loss: 2.4992437131387333

Epoch: 6| Step: 13
Training loss: 1.901886934110698
Validation loss: 2.5038954421476878

Epoch: 53| Step: 0
Training loss: 2.613632748718174
Validation loss: 2.4959777808172636

Epoch: 6| Step: 1
Training loss: 1.710741841873324
Validation loss: 2.506923452140259

Epoch: 6| Step: 2
Training loss: 3.0385245898872713
Validation loss: 2.506566493037407

Epoch: 6| Step: 3
Training loss: 2.987972308376535
Validation loss: 2.49366692888791

Epoch: 6| Step: 4
Training loss: 2.495607236153625
Validation loss: 2.5038512508975104

Epoch: 6| Step: 5
Training loss: 2.85787874690422
Validation loss: 2.4996485981032865

Epoch: 6| Step: 6
Training loss: 2.3808949243334014
Validation loss: 2.4971903322560567

Epoch: 6| Step: 7
Training loss: 2.5797832358032893
Validation loss: 2.4861744788406117

Epoch: 6| Step: 8
Training loss: 2.7762302146182556
Validation loss: 2.5112054394373597

Epoch: 6| Step: 9
Training loss: 2.5119832850282813
Validation loss: 2.501782918768482

Epoch: 6| Step: 10
Training loss: 3.3020212225783636
Validation loss: 2.50471541534555

Epoch: 6| Step: 11
Training loss: 2.610422803461077
Validation loss: 2.493000442223688

Epoch: 6| Step: 12
Training loss: 3.2273790559335778
Validation loss: 2.502840375908624

Epoch: 6| Step: 13
Training loss: 2.9258539371603427
Validation loss: 2.5061028306261224

Epoch: 54| Step: 0
Training loss: 3.047921494962284
Validation loss: 2.5047650548272973

Epoch: 6| Step: 1
Training loss: 2.49698418866683
Validation loss: 2.5110475787883213

Epoch: 6| Step: 2
Training loss: 2.9980595989143675
Validation loss: 2.5181738179743762

Epoch: 6| Step: 3
Training loss: 3.08797262180624
Validation loss: 2.498692170941566

Epoch: 6| Step: 4
Training loss: 2.329884114146359
Validation loss: 2.490034113984402

Epoch: 6| Step: 5
Training loss: 3.292049256958604
Validation loss: 2.4996839036353857

Epoch: 6| Step: 6
Training loss: 2.613249318108816
Validation loss: 2.495633257572957

Epoch: 6| Step: 7
Training loss: 2.50238038225899
Validation loss: 2.51068835821538

Epoch: 6| Step: 8
Training loss: 2.4681945369040856
Validation loss: 2.511839578310595

Epoch: 6| Step: 9
Training loss: 2.212994161474884
Validation loss: 2.4993715214103585

Epoch: 6| Step: 10
Training loss: 3.4734591573914333
Validation loss: 2.5006018560186947

Epoch: 6| Step: 11
Training loss: 2.418173638015126
Validation loss: 2.497140935399418

Epoch: 6| Step: 12
Training loss: 2.3171910312288713
Validation loss: 2.501378097942571

Epoch: 6| Step: 13
Training loss: 2.3791590964959046
Validation loss: 2.4932880294555018

Epoch: 55| Step: 0
Training loss: 2.6948945979241747
Validation loss: 2.500757096615432

Epoch: 6| Step: 1
Training loss: 2.875242803520986
Validation loss: 2.5042912498208496

Epoch: 6| Step: 2
Training loss: 2.695183350053438
Validation loss: 2.5047437576357603

Epoch: 6| Step: 3
Training loss: 3.0539193907206412
Validation loss: 2.495439401701569

Epoch: 6| Step: 4
Training loss: 2.9374110431593685
Validation loss: 2.502951672033251

Epoch: 6| Step: 5
Training loss: 2.0167091470242817
Validation loss: 2.498078544095443

Epoch: 6| Step: 6
Training loss: 2.600599964317457
Validation loss: 2.5020237437894357

Epoch: 6| Step: 7
Training loss: 2.6276701108271237
Validation loss: 2.485419718972724

Epoch: 6| Step: 8
Training loss: 3.238646704065586
Validation loss: 2.4946458333622283

Epoch: 6| Step: 9
Training loss: 2.50223003108807
Validation loss: 2.491832029780585

Epoch: 6| Step: 10
Training loss: 2.4607906237171853
Validation loss: 2.4935525175150683

Epoch: 6| Step: 11
Training loss: 2.8488395336052927
Validation loss: 2.498286602501518

Epoch: 6| Step: 12
Training loss: 2.7306348234433444
Validation loss: 2.497323349654434

Epoch: 6| Step: 13
Training loss: 2.676167213837898
Validation loss: 2.4961006415700453

Epoch: 56| Step: 0
Training loss: 2.844438741929908
Validation loss: 2.4852619276422088

Epoch: 6| Step: 1
Training loss: 2.9140962082291364
Validation loss: 2.488543567522736

Epoch: 6| Step: 2
Training loss: 2.127641158480789
Validation loss: 2.500391902764625

Epoch: 6| Step: 3
Training loss: 3.256266494679912
Validation loss: 2.5092702937413187

Epoch: 6| Step: 4
Training loss: 2.4261175589008324
Validation loss: 2.502371147572093

Epoch: 6| Step: 5
Training loss: 1.9776173667946062
Validation loss: 2.506244663980277

Epoch: 6| Step: 6
Training loss: 2.364932758431896
Validation loss: 2.4938465117517334

Epoch: 6| Step: 7
Training loss: 2.507190567807809
Validation loss: 2.4974174563161204

Epoch: 6| Step: 8
Training loss: 2.6874588364398426
Validation loss: 2.5115603632717285

Epoch: 6| Step: 9
Training loss: 2.695646226650328
Validation loss: 2.4980111691758475

Epoch: 6| Step: 10
Training loss: 3.12087679647239
Validation loss: 2.5046002855036544

Epoch: 6| Step: 11
Training loss: 2.547311195512285
Validation loss: 2.502886981807915

Epoch: 6| Step: 12
Training loss: 3.543924188117326
Validation loss: 2.509367944891918

Epoch: 6| Step: 13
Training loss: 2.7572960734767498
Validation loss: 2.502709432051021

Epoch: 57| Step: 0
Training loss: 2.5218949932832686
Validation loss: 2.493618308859588

Epoch: 6| Step: 1
Training loss: 2.45929413678287
Validation loss: 2.477395330123466

Epoch: 6| Step: 2
Training loss: 3.0405189926941882
Validation loss: 2.4997018236340685

Epoch: 6| Step: 3
Training loss: 3.4231037041581702
Validation loss: 2.4982627139062514

Epoch: 6| Step: 4
Training loss: 2.0269979722286218
Validation loss: 2.489244380748895

Epoch: 6| Step: 5
Training loss: 2.8160870883111264
Validation loss: 2.490713769981248

Epoch: 6| Step: 6
Training loss: 2.541487442534931
Validation loss: 2.4997365033330348

Epoch: 6| Step: 7
Training loss: 2.9169518104315477
Validation loss: 2.4966592073268195

Epoch: 6| Step: 8
Training loss: 2.920195887540157
Validation loss: 2.5039396623093895

Epoch: 6| Step: 9
Training loss: 2.150887496879127
Validation loss: 2.5049617914558286

Epoch: 6| Step: 10
Training loss: 2.474135982091453
Validation loss: 2.495124817428705

Epoch: 6| Step: 11
Training loss: 2.924646379010759
Validation loss: 2.4919442568494903

Epoch: 6| Step: 12
Training loss: 2.308604283962325
Validation loss: 2.502774811110969

Epoch: 6| Step: 13
Training loss: 3.350929324933345
Validation loss: 2.479854712312496

Epoch: 58| Step: 0
Training loss: 2.748356414691831
Validation loss: 2.4995137449337483

Epoch: 6| Step: 1
Training loss: 3.364670664753235
Validation loss: 2.4805816389573865

Epoch: 6| Step: 2
Training loss: 2.7778063253419267
Validation loss: 2.500319367180398

Epoch: 6| Step: 3
Training loss: 2.6387625903864205
Validation loss: 2.4980176911302614

Epoch: 6| Step: 4
Training loss: 2.546592369077624
Validation loss: 2.4843130539306637

Epoch: 6| Step: 5
Training loss: 2.0259724060092448
Validation loss: 2.491138329090192

Epoch: 6| Step: 6
Training loss: 2.4328247618810286
Validation loss: 2.5051912758231385

Epoch: 6| Step: 7
Training loss: 2.422878328273156
Validation loss: 2.5069798144630853

Epoch: 6| Step: 8
Training loss: 3.3272489012477697
Validation loss: 2.5050003435806296

Epoch: 6| Step: 9
Training loss: 2.1414129658607295
Validation loss: 2.5065876213279163

Epoch: 6| Step: 10
Training loss: 2.751289065550328
Validation loss: 2.4916972757236544

Epoch: 6| Step: 11
Training loss: 2.9105497977396073
Validation loss: 2.499340865704753

Epoch: 6| Step: 12
Training loss: 2.7508223777844822
Validation loss: 2.4916960024927013

Epoch: 6| Step: 13
Training loss: 2.734619304097425
Validation loss: 2.4998745691971465

Epoch: 59| Step: 0
Training loss: 2.3043644048221155
Validation loss: 2.485461707776733

Epoch: 6| Step: 1
Training loss: 2.7516456361826105
Validation loss: 2.4873340444765186

Epoch: 6| Step: 2
Training loss: 2.768789431461245
Validation loss: 2.4947064726185255

Epoch: 6| Step: 3
Training loss: 2.4595583002788737
Validation loss: 2.4908430070800756

Epoch: 6| Step: 4
Training loss: 2.6202408473136414
Validation loss: 2.501770085073988

Epoch: 6| Step: 5
Training loss: 2.5079363735895273
Validation loss: 2.496845059434341

Epoch: 6| Step: 6
Training loss: 2.449186236638758
Validation loss: 2.496713178899

Epoch: 6| Step: 7
Training loss: 2.4248237624476268
Validation loss: 2.503516051441283

Epoch: 6| Step: 8
Training loss: 2.5800322904710025
Validation loss: 2.504536699332863

Epoch: 6| Step: 9
Training loss: 2.6213631640716364
Validation loss: 2.5090855162748484

Epoch: 6| Step: 10
Training loss: 3.2254496357063194
Validation loss: 2.48745341062292

Epoch: 6| Step: 11
Training loss: 3.0514392021181798
Validation loss: 2.4982025534904246

Epoch: 6| Step: 12
Training loss: 2.7864679829558137
Validation loss: 2.5029655566864992

Epoch: 6| Step: 13
Training loss: 3.3810195928963247
Validation loss: 2.4920980045434233

Epoch: 60| Step: 0
Training loss: 2.5591315483218544
Validation loss: 2.496936223079342

Epoch: 6| Step: 1
Training loss: 2.645530703400873
Validation loss: 2.5121179214156557

Epoch: 6| Step: 2
Training loss: 3.2971006198717374
Validation loss: 2.4773771556379125

Epoch: 6| Step: 3
Training loss: 2.957672976726105
Validation loss: 2.502945521422713

Epoch: 6| Step: 4
Training loss: 2.8487585208057356
Validation loss: 2.4954516628591814

Epoch: 6| Step: 5
Training loss: 2.097791159498688
Validation loss: 2.4872263641164003

Epoch: 6| Step: 6
Training loss: 2.191294077349947
Validation loss: 2.4901656502415888

Epoch: 6| Step: 7
Training loss: 3.042564433786117
Validation loss: 2.476616168369864

Epoch: 6| Step: 8
Training loss: 2.6454175086677747
Validation loss: 2.4920306381887927

Epoch: 6| Step: 9
Training loss: 2.7671304689342877
Validation loss: 2.505235742243319

Epoch: 6| Step: 10
Training loss: 2.4442047437512717
Validation loss: 2.5070702230526165

Epoch: 6| Step: 11
Training loss: 2.8666379646224676
Validation loss: 2.4901931821700387

Epoch: 6| Step: 12
Training loss: 2.5650644263789184
Validation loss: 2.4970961544093013

Epoch: 6| Step: 13
Training loss: 2.7225433720268146
Validation loss: 2.4946368177097313

Epoch: 61| Step: 0
Training loss: 1.931733193797488
Validation loss: 2.500068837930612

Epoch: 6| Step: 1
Training loss: 2.660933550452607
Validation loss: 2.497050455802162

Epoch: 6| Step: 2
Training loss: 2.7071645024078097
Validation loss: 2.5001189777816637

Epoch: 6| Step: 3
Training loss: 2.706135302925646
Validation loss: 2.494033628093007

Epoch: 6| Step: 4
Training loss: 2.836944485368285
Validation loss: 2.499979005745956

Epoch: 6| Step: 5
Training loss: 2.190302878734364
Validation loss: 2.5160583986943985

Epoch: 6| Step: 6
Training loss: 3.182327711501616
Validation loss: 2.491587157103554

Epoch: 6| Step: 7
Training loss: 2.8908008418855644
Validation loss: 2.492829765609662

Epoch: 6| Step: 8
Training loss: 2.5990711460334355
Validation loss: 2.4979274957622892

Epoch: 6| Step: 9
Training loss: 2.5873722579309764
Validation loss: 2.472488761304048

Epoch: 6| Step: 10
Training loss: 3.0571870455585084
Validation loss: 2.485005576344798

Epoch: 6| Step: 11
Training loss: 2.8749147485449664
Validation loss: 2.504690550711947

Epoch: 6| Step: 12
Training loss: 2.7397714605875434
Validation loss: 2.475833271891832

Epoch: 6| Step: 13
Training loss: 2.358091497883434
Validation loss: 2.500147525987596

Epoch: 62| Step: 0
Training loss: 2.738942718062864
Validation loss: 2.486385697588036

Epoch: 6| Step: 1
Training loss: 2.1478334999695177
Validation loss: 2.4907631687319296

Epoch: 6| Step: 2
Training loss: 2.8170526744127913
Validation loss: 2.492585752045574

Epoch: 6| Step: 3
Training loss: 2.8251287279085444
Validation loss: 2.479423930124324

Epoch: 6| Step: 4
Training loss: 3.0143730450520434
Validation loss: 2.495737345673242

Epoch: 6| Step: 5
Training loss: 3.2770885418177347
Validation loss: 2.4930634778733127

Epoch: 6| Step: 6
Training loss: 2.3530587033764467
Validation loss: 2.47602171845698

Epoch: 6| Step: 7
Training loss: 2.5875983767766337
Validation loss: 2.4822762038501436

Epoch: 6| Step: 8
Training loss: 2.593257351704452
Validation loss: 2.4905940104317126

Epoch: 6| Step: 9
Training loss: 2.4217167956455534
Validation loss: 2.490712940381829

Epoch: 6| Step: 10
Training loss: 2.2035413849097014
Validation loss: 2.484481463553885

Epoch: 6| Step: 11
Training loss: 2.9515567228180952
Validation loss: 2.496690197843101

Epoch: 6| Step: 12
Training loss: 2.530907878596415
Validation loss: 2.502216070635069

Epoch: 6| Step: 13
Training loss: 3.262912043132745
Validation loss: 2.4993065990182886

Epoch: 63| Step: 0
Training loss: 3.340020069130547
Validation loss: 2.5056644573903912

Epoch: 6| Step: 1
Training loss: 2.6074130968953364
Validation loss: 2.4890028007717437

Epoch: 6| Step: 2
Training loss: 2.5030532312284204
Validation loss: 2.5008616531504497

Epoch: 6| Step: 3
Training loss: 2.4971056395990505
Validation loss: 2.498193799526609

Epoch: 6| Step: 4
Training loss: 2.4963575531201494
Validation loss: 2.5126864820028927

Epoch: 6| Step: 5
Training loss: 3.280437405194157
Validation loss: 2.4992098123496467

Epoch: 6| Step: 6
Training loss: 2.068813486652122
Validation loss: 2.498787867065611

Epoch: 6| Step: 7
Training loss: 2.383730051950365
Validation loss: 2.4979611081188127

Epoch: 6| Step: 8
Training loss: 2.76535067302279
Validation loss: 2.4974382154763357

Epoch: 6| Step: 9
Training loss: 1.9351854342930803
Validation loss: 2.4869123634901884

Epoch: 6| Step: 10
Training loss: 3.570125783633108
Validation loss: 2.500448747578404

Epoch: 6| Step: 11
Training loss: 2.5598551429057723
Validation loss: 2.497680677245434

Epoch: 6| Step: 12
Training loss: 2.5879534559000064
Validation loss: 2.497391157847244

Epoch: 6| Step: 13
Training loss: 2.5710634566510064
Validation loss: 2.4934875623643995

Epoch: 64| Step: 0
Training loss: 2.5739625563072925
Validation loss: 2.4803332194149834

Epoch: 6| Step: 1
Training loss: 3.039564860973916
Validation loss: 2.4849185205881437

Epoch: 6| Step: 2
Training loss: 2.9617952498425253
Validation loss: 2.4824213276596385

Epoch: 6| Step: 3
Training loss: 2.526119826113759
Validation loss: 2.489983782383707

Epoch: 6| Step: 4
Training loss: 2.5320561385115887
Validation loss: 2.495240909474274

Epoch: 6| Step: 5
Training loss: 2.694426813974631
Validation loss: 2.4796346031688237

Epoch: 6| Step: 6
Training loss: 2.7499788456883443
Validation loss: 2.490824486087537

Epoch: 6| Step: 7
Training loss: 2.463584033905533
Validation loss: 2.5000821274424156

Epoch: 6| Step: 8
Training loss: 2.382227591345242
Validation loss: 2.497339192432838

Epoch: 6| Step: 9
Training loss: 2.1984125695784043
Validation loss: 2.494968881135357

Epoch: 6| Step: 10
Training loss: 2.8916508684267272
Validation loss: 2.49193122639863

Epoch: 6| Step: 11
Training loss: 2.886382087206184
Validation loss: 2.494588205794089

Epoch: 6| Step: 12
Training loss: 2.858605286438613
Validation loss: 2.4872483472726716

Epoch: 6| Step: 13
Training loss: 2.768534622254228
Validation loss: 2.492625738000363

Epoch: 65| Step: 0
Training loss: 2.0487854174007474
Validation loss: 2.491852041231267

Epoch: 6| Step: 1
Training loss: 2.2967545873517885
Validation loss: 2.5048728583343842

Epoch: 6| Step: 2
Training loss: 2.7924820482570065
Validation loss: 2.4947506121128016

Epoch: 6| Step: 3
Training loss: 2.7689402908825347
Validation loss: 2.482943451004252

Epoch: 6| Step: 4
Training loss: 2.3861551821271263
Validation loss: 2.4975826789729827

Epoch: 6| Step: 5
Training loss: 2.9053366261510702
Validation loss: 2.495674440734938

Epoch: 6| Step: 6
Training loss: 2.9262072427486485
Validation loss: 2.492531897835205

Epoch: 6| Step: 7
Training loss: 2.2866268805480106
Validation loss: 2.4762709535839855

Epoch: 6| Step: 8
Training loss: 2.4353790837225127
Validation loss: 2.491553766409941

Epoch: 6| Step: 9
Training loss: 2.9871496912940674
Validation loss: 2.48014467302588

Epoch: 6| Step: 10
Training loss: 2.563471168149086
Validation loss: 2.4879115230466953

Epoch: 6| Step: 11
Training loss: 3.19407066332975
Validation loss: 2.4813909406559644

Epoch: 6| Step: 12
Training loss: 2.8332116343971205
Validation loss: 2.4727442485862747

Epoch: 6| Step: 13
Training loss: 3.1231624541327956
Validation loss: 2.4929260204791324

Epoch: 66| Step: 0
Training loss: 2.0374721595406697
Validation loss: 2.489382377673454

Epoch: 6| Step: 1
Training loss: 2.3914364702869397
Validation loss: 2.4849565732962033

Epoch: 6| Step: 2
Training loss: 3.201289548916339
Validation loss: 2.4982347737239237

Epoch: 6| Step: 3
Training loss: 2.7511798755074994
Validation loss: 2.4857878982946886

Epoch: 6| Step: 4
Training loss: 2.5416982263158676
Validation loss: 2.5034791077414127

Epoch: 6| Step: 5
Training loss: 2.341398763660558
Validation loss: 2.5056926042714993

Epoch: 6| Step: 6
Training loss: 2.4140741539337434
Validation loss: 2.505669581260484

Epoch: 6| Step: 7
Training loss: 2.8049846693629767
Validation loss: 2.491741994268637

Epoch: 6| Step: 8
Training loss: 3.0772375386278883
Validation loss: 2.4972602136494535

Epoch: 6| Step: 9
Training loss: 2.230306482508718
Validation loss: 2.4896267010881235

Epoch: 6| Step: 10
Training loss: 2.312769075152751
Validation loss: 2.483524712819705

Epoch: 6| Step: 11
Training loss: 2.556391996063323
Validation loss: 2.4877955197215718

Epoch: 6| Step: 12
Training loss: 3.2125618717157884
Validation loss: 2.4702332406139886

Epoch: 6| Step: 13
Training loss: 3.523680549578596
Validation loss: 2.4981516794016065

Epoch: 67| Step: 0
Training loss: 3.415251431012969
Validation loss: 2.4790334271924532

Epoch: 6| Step: 1
Training loss: 2.129076469685749
Validation loss: 2.496870007329577

Epoch: 6| Step: 2
Training loss: 2.8809532227828334
Validation loss: 2.5011465130342945

Epoch: 6| Step: 3
Training loss: 3.336552654786683
Validation loss: 2.489114241845044

Epoch: 6| Step: 4
Training loss: 2.0606536692926563
Validation loss: 2.4929077288640182

Epoch: 6| Step: 5
Training loss: 2.557008767779449
Validation loss: 2.4890696233741405

Epoch: 6| Step: 6
Training loss: 2.686090853997261
Validation loss: 2.4878998306298317

Epoch: 6| Step: 7
Training loss: 2.2354232356628807
Validation loss: 2.4691975692669095

Epoch: 6| Step: 8
Training loss: 2.161325976137837
Validation loss: 2.4934747939291166

Epoch: 6| Step: 9
Training loss: 3.340129996185546
Validation loss: 2.4744230535753156

Epoch: 6| Step: 10
Training loss: 2.6931794945370653
Validation loss: 2.480913217785524

Epoch: 6| Step: 11
Training loss: 2.827191615063205
Validation loss: 2.4734252300039343

Epoch: 6| Step: 12
Training loss: 2.028774219869002
Validation loss: 2.4856693876187066

Epoch: 6| Step: 13
Training loss: 2.180299515753181
Validation loss: 2.487135995924794

Epoch: 68| Step: 0
Training loss: 2.5307074071233027
Validation loss: 2.498308436002685

Epoch: 6| Step: 1
Training loss: 2.7113436084168367
Validation loss: 2.5108452827050534

Epoch: 6| Step: 2
Training loss: 2.256937035442483
Validation loss: 2.4875802427291656

Epoch: 6| Step: 3
Training loss: 2.6963322134133123
Validation loss: 2.4793966953040147

Epoch: 6| Step: 4
Training loss: 2.3953350267638753
Validation loss: 2.488387969857598

Epoch: 6| Step: 5
Training loss: 2.6317833040597374
Validation loss: 2.4870358627772755

Epoch: 6| Step: 6
Training loss: 2.243486194456747
Validation loss: 2.486026195848744

Epoch: 6| Step: 7
Training loss: 2.626964742074685
Validation loss: 2.4925078682029542

Epoch: 6| Step: 8
Training loss: 2.812817280145149
Validation loss: 2.4951459008162846

Epoch: 6| Step: 9
Training loss: 2.9641936020319504
Validation loss: 2.4855449488858836

Epoch: 6| Step: 10
Training loss: 2.5405211029767907
Validation loss: 2.5008604250768247

Epoch: 6| Step: 11
Training loss: 2.979850814976582
Validation loss: 2.4770535492405075

Epoch: 6| Step: 12
Training loss: 2.832668301194096
Validation loss: 2.485998645615026

Epoch: 6| Step: 13
Training loss: 3.326095607060129
Validation loss: 2.489159118026681

Epoch: 69| Step: 0
Training loss: 2.905886719671549
Validation loss: 2.474467248217718

Epoch: 6| Step: 1
Training loss: 1.9467261513130645
Validation loss: 2.4908151169550568

Epoch: 6| Step: 2
Training loss: 2.4145355254984433
Validation loss: 2.4879099361703934

Epoch: 6| Step: 3
Training loss: 2.3958967338687187
Validation loss: 2.4791200370949875

Epoch: 6| Step: 4
Training loss: 2.119091908822241
Validation loss: 2.490790471738199

Epoch: 6| Step: 5
Training loss: 2.8108858350805437
Validation loss: 2.478195428979601

Epoch: 6| Step: 6
Training loss: 2.9643433642403374
Validation loss: 2.5015176104540324

Epoch: 6| Step: 7
Training loss: 2.789213203184038
Validation loss: 2.4820294340308946

Epoch: 6| Step: 8
Training loss: 2.833816954533111
Validation loss: 2.4974425406646015

Epoch: 6| Step: 9
Training loss: 2.726653701437397
Validation loss: 2.4918657377322706

Epoch: 6| Step: 10
Training loss: 3.4604307195449686
Validation loss: 2.464077279385232

Epoch: 6| Step: 11
Training loss: 2.2884964487166184
Validation loss: 2.4895577844959917

Epoch: 6| Step: 12
Training loss: 2.9159291197713912
Validation loss: 2.480531945463948

Epoch: 6| Step: 13
Training loss: 1.9761786408543252
Validation loss: 2.4821204797737924

Epoch: 70| Step: 0
Training loss: 2.3067794357510336
Validation loss: 2.483141120024596

Epoch: 6| Step: 1
Training loss: 2.7039206331670145
Validation loss: 2.4936978943939425

Epoch: 6| Step: 2
Training loss: 2.0980568615141792
Validation loss: 2.48076734592244

Epoch: 6| Step: 3
Training loss: 2.5244561846703366
Validation loss: 2.4654858912427127

Epoch: 6| Step: 4
Training loss: 2.9827217995475364
Validation loss: 2.4856641028818687

Epoch: 6| Step: 5
Training loss: 2.162176418901815
Validation loss: 2.497658413319796

Epoch: 6| Step: 6
Training loss: 2.6606733404942617
Validation loss: 2.479674152320484

Epoch: 6| Step: 7
Training loss: 2.512083510614354
Validation loss: 2.494223214666257

Epoch: 6| Step: 8
Training loss: 2.7155161951039037
Validation loss: 2.4871569439748042

Epoch: 6| Step: 9
Training loss: 2.674944803969732
Validation loss: 2.4677826634887308

Epoch: 6| Step: 10
Training loss: 2.8132487677870874
Validation loss: 2.4713306949529175

Epoch: 6| Step: 11
Training loss: 3.2839311091065704
Validation loss: 2.4924498445776786

Epoch: 6| Step: 12
Training loss: 2.6754097562315597
Validation loss: 2.4843338266228003

Epoch: 6| Step: 13
Training loss: 3.0043424331807698
Validation loss: 2.484251533546885

Epoch: 71| Step: 0
Training loss: 2.5338843495112395
Validation loss: 2.4760055425534406

Epoch: 6| Step: 1
Training loss: 3.2035584691455803
Validation loss: 2.4820888115741204

Epoch: 6| Step: 2
Training loss: 2.940175887056108
Validation loss: 2.4845975875590747

Epoch: 6| Step: 3
Training loss: 2.653210325632602
Validation loss: 2.4765675060329926

Epoch: 6| Step: 4
Training loss: 2.6165410851960265
Validation loss: 2.480273903204224

Epoch: 6| Step: 5
Training loss: 2.6411538582024625
Validation loss: 2.4903199704777292

Epoch: 6| Step: 6
Training loss: 2.4630453135278896
Validation loss: 2.494102482682295

Epoch: 6| Step: 7
Training loss: 2.4990917463309725
Validation loss: 2.4731499189285286

Epoch: 6| Step: 8
Training loss: 2.793968779256352
Validation loss: 2.4877465752354033

Epoch: 6| Step: 9
Training loss: 2.4275223385444016
Validation loss: 2.4818941136566828

Epoch: 6| Step: 10
Training loss: 2.2093137568034504
Validation loss: 2.465443766038484

Epoch: 6| Step: 11
Training loss: 2.6386926566886113
Validation loss: 2.4878379383217397

Epoch: 6| Step: 12
Training loss: 2.607039085607325
Validation loss: 2.4694691632486427

Epoch: 6| Step: 13
Training loss: 3.032087230091877
Validation loss: 2.476692716710795

Epoch: 72| Step: 0
Training loss: 2.102011366772611
Validation loss: 2.4900914711658637

Epoch: 6| Step: 1
Training loss: 2.453193906557361
Validation loss: 2.502804516195463

Epoch: 6| Step: 2
Training loss: 2.773855774191958
Validation loss: 2.48172280441439

Epoch: 6| Step: 3
Training loss: 2.774575099548078
Validation loss: 2.4973307480278546

Epoch: 6| Step: 4
Training loss: 2.5793900593862675
Validation loss: 2.480951968457718

Epoch: 6| Step: 5
Training loss: 2.6731616040038815
Validation loss: 2.491784758250173

Epoch: 6| Step: 6
Training loss: 2.5657725952664077
Validation loss: 2.4977247282562582

Epoch: 6| Step: 7
Training loss: 3.077949015432446
Validation loss: 2.5081069748353078

Epoch: 6| Step: 8
Training loss: 2.9007095521202597
Validation loss: 2.4734326780939946

Epoch: 6| Step: 9
Training loss: 2.6165282372792182
Validation loss: 2.4738799960433764

Epoch: 6| Step: 10
Training loss: 2.304675086036482
Validation loss: 2.4834550942351905

Epoch: 6| Step: 11
Training loss: 2.8070123329448853
Validation loss: 2.4854109308164767

Epoch: 6| Step: 12
Training loss: 2.232034377595595
Validation loss: 2.4936297462301598

Epoch: 6| Step: 13
Training loss: 3.402282504068084
Validation loss: 2.489811104293784

Epoch: 73| Step: 0
Training loss: 2.7907982134913505
Validation loss: 2.4836525424149483

Epoch: 6| Step: 1
Training loss: 2.573706800293727
Validation loss: 2.476818989234456

Epoch: 6| Step: 2
Training loss: 2.5838097984063806
Validation loss: 2.4878383185648847

Epoch: 6| Step: 3
Training loss: 2.5799201033293624
Validation loss: 2.4793121134599456

Epoch: 6| Step: 4
Training loss: 2.676059591476578
Validation loss: 2.476664235592731

Epoch: 6| Step: 5
Training loss: 3.1377823903941735
Validation loss: 2.473250344766491

Epoch: 6| Step: 6
Training loss: 2.113935499753751
Validation loss: 2.467063964630498

Epoch: 6| Step: 7
Training loss: 2.398725063717168
Validation loss: 2.4785787213201913

Epoch: 6| Step: 8
Training loss: 2.6067685569628756
Validation loss: 2.4859038470591424

Epoch: 6| Step: 9
Training loss: 3.0729450461591186
Validation loss: 2.489008601652012

Epoch: 6| Step: 10
Training loss: 2.9662162810353037
Validation loss: 2.475238945709667

Epoch: 6| Step: 11
Training loss: 2.545319251700779
Validation loss: 2.4606934410289494

Epoch: 6| Step: 12
Training loss: 2.2634314079365954
Validation loss: 2.4790980263281237

Epoch: 6| Step: 13
Training loss: 2.6242724727436273
Validation loss: 2.4702062272268046

Epoch: 74| Step: 0
Training loss: 2.2637635048727267
Validation loss: 2.4895641803111976

Epoch: 6| Step: 1
Training loss: 1.9571171359101365
Validation loss: 2.4720644453659415

Epoch: 6| Step: 2
Training loss: 2.3778813601993676
Validation loss: 2.4712512968054363

Epoch: 6| Step: 3
Training loss: 2.8508654434847447
Validation loss: 2.492175792669551

Epoch: 6| Step: 4
Training loss: 2.871822259561886
Validation loss: 2.4747015193751793

Epoch: 6| Step: 5
Training loss: 2.6841718781152313
Validation loss: 2.4891351526478975

Epoch: 6| Step: 6
Training loss: 2.9634055769545604
Validation loss: 2.466021312122823

Epoch: 6| Step: 7
Training loss: 2.41405104353572
Validation loss: 2.4901086540746347

Epoch: 6| Step: 8
Training loss: 2.4646895612802613
Validation loss: 2.5025541824632125

Epoch: 6| Step: 9
Training loss: 2.4904968841416832
Validation loss: 2.4756484913048964

Epoch: 6| Step: 10
Training loss: 2.8125016106494956
Validation loss: 2.4776251260570987

Epoch: 6| Step: 11
Training loss: 3.209279024198983
Validation loss: 2.4853252312548926

Epoch: 6| Step: 12
Training loss: 2.1635360352821387
Validation loss: 2.4924645313794462

Epoch: 6| Step: 13
Training loss: 3.5164848123930543
Validation loss: 2.486294115643645

Epoch: 75| Step: 0
Training loss: 2.424056123127872
Validation loss: 2.4750128047458992

Epoch: 6| Step: 1
Training loss: 2.719602341614467
Validation loss: 2.477001814370773

Epoch: 6| Step: 2
Training loss: 2.3634673746761234
Validation loss: 2.4732343932907144

Epoch: 6| Step: 3
Training loss: 2.5545900658741876
Validation loss: 2.47065589850246

Epoch: 6| Step: 4
Training loss: 3.214309444037143
Validation loss: 2.478355052193643

Epoch: 6| Step: 5
Training loss: 3.54738448596768
Validation loss: 2.4814439095172505

Epoch: 6| Step: 6
Training loss: 2.157256402931344
Validation loss: 2.4887104609209767

Epoch: 6| Step: 7
Training loss: 2.4164010482914633
Validation loss: 2.46126210145148

Epoch: 6| Step: 8
Training loss: 3.1110703336980055
Validation loss: 2.479112847036047

Epoch: 6| Step: 9
Training loss: 2.041282760441324
Validation loss: 2.484725129812979

Epoch: 6| Step: 10
Training loss: 2.493592060795354
Validation loss: 2.4780827716775278

Epoch: 6| Step: 11
Training loss: 2.4518935885029842
Validation loss: 2.475265925922913

Epoch: 6| Step: 12
Training loss: 2.4993775546534716
Validation loss: 2.4801880116684982

Epoch: 6| Step: 13
Training loss: 2.573340397793786
Validation loss: 2.4728790910101153

Epoch: 76| Step: 0
Training loss: 3.309972986762234
Validation loss: 2.4686349852626717

Epoch: 6| Step: 1
Training loss: 2.4945260200481503
Validation loss: 2.4901286392235686

Epoch: 6| Step: 2
Training loss: 2.81948891235596
Validation loss: 2.4658973716733232

Epoch: 6| Step: 3
Training loss: 3.037369675842816
Validation loss: 2.482657062182802

Epoch: 6| Step: 4
Training loss: 2.4159572042249597
Validation loss: 2.482819569522782

Epoch: 6| Step: 5
Training loss: 2.1301473097388697
Validation loss: 2.4604315051840477

Epoch: 6| Step: 6
Training loss: 2.1307169362266305
Validation loss: 2.4774583608099356

Epoch: 6| Step: 7
Training loss: 2.8818763101839933
Validation loss: 2.4767417740606015

Epoch: 6| Step: 8
Training loss: 2.891076130073432
Validation loss: 2.479220081504314

Epoch: 6| Step: 9
Training loss: 1.8838126664094372
Validation loss: 2.461523063648385

Epoch: 6| Step: 10
Training loss: 2.253350412465816
Validation loss: 2.477998405694525

Epoch: 6| Step: 11
Training loss: 3.377942674429357
Validation loss: 2.4819270940878564

Epoch: 6| Step: 12
Training loss: 2.763198218852111
Validation loss: 2.4682829433108915

Epoch: 6| Step: 13
Training loss: 1.4138160195691116
Validation loss: 2.4886071554229927

Epoch: 77| Step: 0
Training loss: 2.1868775708362507
Validation loss: 2.4806246821456424

Epoch: 6| Step: 1
Training loss: 3.518629223121164
Validation loss: 2.4787512593472507

Epoch: 6| Step: 2
Training loss: 2.1981941397528337
Validation loss: 2.476961240858588

Epoch: 6| Step: 3
Training loss: 2.9695884725170183
Validation loss: 2.472583604769418

Epoch: 6| Step: 4
Training loss: 2.4169316201375866
Validation loss: 2.4769145228476708

Epoch: 6| Step: 5
Training loss: 2.7133888792246315
Validation loss: 2.4831192589845

Epoch: 6| Step: 6
Training loss: 2.4269606814411877
Validation loss: 2.4767548606178136

Epoch: 6| Step: 7
Training loss: 2.703501239678261
Validation loss: 2.4813468874100892

Epoch: 6| Step: 8
Training loss: 1.8427873458297008
Validation loss: 2.4754316018060236

Epoch: 6| Step: 9
Training loss: 2.8312389449352153
Validation loss: 2.47328041999965

Epoch: 6| Step: 10
Training loss: 2.696981339109683
Validation loss: 2.4824757265052306

Epoch: 6| Step: 11
Training loss: 2.3067544235595543
Validation loss: 2.483769926216899

Epoch: 6| Step: 12
Training loss: 2.9848153153990977
Validation loss: 2.4733814303030712

Epoch: 6| Step: 13
Training loss: 2.576710353331278
Validation loss: 2.461192992673185

Epoch: 78| Step: 0
Training loss: 3.3426219427765895
Validation loss: 2.47769338590927

Epoch: 6| Step: 1
Training loss: 1.9598475614941162
Validation loss: 2.4852197327622996

Epoch: 6| Step: 2
Training loss: 2.8093624840310136
Validation loss: 2.49102253572359

Epoch: 6| Step: 3
Training loss: 2.81781157035935
Validation loss: 2.470938137955253

Epoch: 6| Step: 4
Training loss: 3.1436416030913135
Validation loss: 2.4743484750747093

Epoch: 6| Step: 5
Training loss: 1.858796101699396
Validation loss: 2.4685568909868234

Epoch: 6| Step: 6
Training loss: 2.2493709108612805
Validation loss: 2.4817617800337772

Epoch: 6| Step: 7
Training loss: 2.391624491072716
Validation loss: 2.4649227336330575

Epoch: 6| Step: 8
Training loss: 2.786872409939979
Validation loss: 2.4744201184271737

Epoch: 6| Step: 9
Training loss: 2.514907260648608
Validation loss: 2.474750824416453

Epoch: 6| Step: 10
Training loss: 3.0540090134243463
Validation loss: 2.4784110225699143

Epoch: 6| Step: 11
Training loss: 2.146454162662718
Validation loss: 2.463605413232397

Epoch: 6| Step: 12
Training loss: 2.5381072609663615
Validation loss: 2.4749091336269613

Epoch: 6| Step: 13
Training loss: 2.604897775383236
Validation loss: 2.4729561982059103

Epoch: 79| Step: 0
Training loss: 2.2824411287267665
Validation loss: 2.4737535859351185

Epoch: 6| Step: 1
Training loss: 2.3954843239268335
Validation loss: 2.467836143625149

Epoch: 6| Step: 2
Training loss: 1.9288668103548838
Validation loss: 2.477479147515318

Epoch: 6| Step: 3
Training loss: 2.776871910737436
Validation loss: 2.4671861195004006

Epoch: 6| Step: 4
Training loss: 2.3329603941654535
Validation loss: 2.4828680163960644

Epoch: 6| Step: 5
Training loss: 2.0642467384788468
Validation loss: 2.4590291265136934

Epoch: 6| Step: 6
Training loss: 2.765001819465135
Validation loss: 2.4935546338739463

Epoch: 6| Step: 7
Training loss: 3.0465790433685904
Validation loss: 2.456440736391863

Epoch: 6| Step: 8
Training loss: 2.7760574216318044
Validation loss: 2.482832992664189

Epoch: 6| Step: 9
Training loss: 3.432856249454519
Validation loss: 2.471197449679183

Epoch: 6| Step: 10
Training loss: 2.3635523112564387
Validation loss: 2.4762600541030664

Epoch: 6| Step: 11
Training loss: 2.666228278206191
Validation loss: 2.463600475555714

Epoch: 6| Step: 12
Training loss: 2.9007873058384304
Validation loss: 2.4622621366300974

Epoch: 6| Step: 13
Training loss: 2.489745471308635
Validation loss: 2.4880215467502524

Epoch: 80| Step: 0
Training loss: 2.2771592760699257
Validation loss: 2.4698919669394934

Epoch: 6| Step: 1
Training loss: 2.820137673662952
Validation loss: 2.4795988265828623

Epoch: 6| Step: 2
Training loss: 2.6085055610256718
Validation loss: 2.465839526575638

Epoch: 6| Step: 3
Training loss: 1.9203446040251781
Validation loss: 2.4813755797846393

Epoch: 6| Step: 4
Training loss: 2.704382631429083
Validation loss: 2.470042222673345

Epoch: 6| Step: 5
Training loss: 1.8092965064539868
Validation loss: 2.4730324804250663

Epoch: 6| Step: 6
Training loss: 2.2221356202840776
Validation loss: 2.492124037401188

Epoch: 6| Step: 7
Training loss: 2.8490838971034838
Validation loss: 2.4792531978086148

Epoch: 6| Step: 8
Training loss: 3.395193932995782
Validation loss: 2.4842810514681157

Epoch: 6| Step: 9
Training loss: 2.6668012306912026
Validation loss: 2.474337193096119

Epoch: 6| Step: 10
Training loss: 2.6750070161816573
Validation loss: 2.478508708324278

Epoch: 6| Step: 11
Training loss: 2.7817243535860086
Validation loss: 2.4725093751599356

Epoch: 6| Step: 12
Training loss: 2.7910562009110973
Validation loss: 2.487512340237811

Epoch: 6| Step: 13
Training loss: 2.699167872168835
Validation loss: 2.489381198517833

Epoch: 81| Step: 0
Training loss: 2.520443111093231
Validation loss: 2.4734090132805067

Epoch: 6| Step: 1
Training loss: 2.1883251268862938
Validation loss: 2.4790511510679374

Epoch: 6| Step: 2
Training loss: 2.1858024549999793
Validation loss: 2.4750621444997836

Epoch: 6| Step: 3
Training loss: 2.572778880848249
Validation loss: 2.4737615936927386

Epoch: 6| Step: 4
Training loss: 2.4633413049192927
Validation loss: 2.4745819286851622

Epoch: 6| Step: 5
Training loss: 2.605205562630245
Validation loss: 2.4548200628515615

Epoch: 6| Step: 6
Training loss: 2.5571381832972113
Validation loss: 2.487193955922611

Epoch: 6| Step: 7
Training loss: 2.9474604133361306
Validation loss: 2.4700134567700256

Epoch: 6| Step: 8
Training loss: 2.442848597378551
Validation loss: 2.472890286338126

Epoch: 6| Step: 9
Training loss: 2.7037655286479687
Validation loss: 2.4555296938178706

Epoch: 6| Step: 10
Training loss: 2.2779458560286385
Validation loss: 2.463876319904649

Epoch: 6| Step: 11
Training loss: 2.9784083612857972
Validation loss: 2.47931241332366

Epoch: 6| Step: 12
Training loss: 3.162892217024423
Validation loss: 2.4823533893910086

Epoch: 6| Step: 13
Training loss: 2.5864902608567535
Validation loss: 2.4573411933033604

Epoch: 82| Step: 0
Training loss: 2.3191653925784474
Validation loss: 2.469124895994743

Epoch: 6| Step: 1
Training loss: 2.596923265800476
Validation loss: 2.462123015340197

Epoch: 6| Step: 2
Training loss: 2.2428813219719594
Validation loss: 2.4831806432682786

Epoch: 6| Step: 3
Training loss: 2.109507125672473
Validation loss: 2.4690317419182723

Epoch: 6| Step: 4
Training loss: 2.0806513753074656
Validation loss: 2.4942100470849917

Epoch: 6| Step: 5
Training loss: 2.1912169349208193
Validation loss: 2.467025282102524

Epoch: 6| Step: 6
Training loss: 2.684623598393501
Validation loss: 2.4762866805145016

Epoch: 6| Step: 7
Training loss: 2.993824802172959
Validation loss: 2.4735889884918465

Epoch: 6| Step: 8
Training loss: 2.402159049524541
Validation loss: 2.478826608254918

Epoch: 6| Step: 9
Training loss: 2.6959263199379504
Validation loss: 2.462518655779081

Epoch: 6| Step: 10
Training loss: 3.0868318831001997
Validation loss: 2.489198152808012

Epoch: 6| Step: 11
Training loss: 2.4743865167938024
Validation loss: 2.479661755768361

Epoch: 6| Step: 12
Training loss: 3.5246224113222424
Validation loss: 2.464861296127858

Epoch: 6| Step: 13
Training loss: 2.545033543933379
Validation loss: 2.4720923448145

Epoch: 83| Step: 0
Training loss: 3.3448270685173145
Validation loss: 2.482812943626921

Epoch: 6| Step: 1
Training loss: 2.133956099547538
Validation loss: 2.4735650194312986

Epoch: 6| Step: 2
Training loss: 2.998746292092884
Validation loss: 2.4817754970996915

Epoch: 6| Step: 3
Training loss: 2.6706798178066014
Validation loss: 2.4907948604469894

Epoch: 6| Step: 4
Training loss: 2.763332472809894
Validation loss: 2.481631362887502

Epoch: 6| Step: 5
Training loss: 2.14223692410561
Validation loss: 2.47813815543345

Epoch: 6| Step: 6
Training loss: 2.5474878053682133
Validation loss: 2.4623716135278726

Epoch: 6| Step: 7
Training loss: 2.45031236876001
Validation loss: 2.474507687535445

Epoch: 6| Step: 8
Training loss: 2.825492096973087
Validation loss: 2.461398683180298

Epoch: 6| Step: 9
Training loss: 2.197632564846927
Validation loss: 2.4874038245252996

Epoch: 6| Step: 10
Training loss: 2.744621826553647
Validation loss: 2.4733533090725035

Epoch: 6| Step: 11
Training loss: 1.8527901358178787
Validation loss: 2.4730503566727537

Epoch: 6| Step: 12
Training loss: 2.8618966745296017
Validation loss: 2.4779909061501164

Epoch: 6| Step: 13
Training loss: 2.54881802260929
Validation loss: 2.469730453018764

Epoch: 84| Step: 0
Training loss: 3.315663680301297
Validation loss: 2.476962544950996

Epoch: 6| Step: 1
Training loss: 2.2250869948278433
Validation loss: 2.473322199245346

Epoch: 6| Step: 2
Training loss: 2.4420079336701406
Validation loss: 2.4783699052735297

Epoch: 6| Step: 3
Training loss: 3.2198063866829956
Validation loss: 2.464995974881649

Epoch: 6| Step: 4
Training loss: 2.493919798918951
Validation loss: 2.498503221546567

Epoch: 6| Step: 5
Training loss: 2.5230222189065135
Validation loss: 2.466098125918165

Epoch: 6| Step: 6
Training loss: 3.4325631496902322
Validation loss: 2.4713796761694717

Epoch: 6| Step: 7
Training loss: 2.505939675618093
Validation loss: 2.4652417178888943

Epoch: 6| Step: 8
Training loss: 2.15243458080235
Validation loss: 2.473609683345482

Epoch: 6| Step: 9
Training loss: 1.9529429236420455
Validation loss: 2.4753299336193804

Epoch: 6| Step: 10
Training loss: 2.188766657723959
Validation loss: 2.48773299414459

Epoch: 6| Step: 11
Training loss: 2.4323999896764166
Validation loss: 2.481704472578673

Epoch: 6| Step: 12
Training loss: 2.739720639654636
Validation loss: 2.4681702651345656

Epoch: 6| Step: 13
Training loss: 2.301929647111363
Validation loss: 2.482409593892523

Epoch: 85| Step: 0
Training loss: 2.103700139162589
Validation loss: 2.4736505657438426

Epoch: 6| Step: 1
Training loss: 2.335842781315437
Validation loss: 2.489412710101259

Epoch: 6| Step: 2
Training loss: 2.086704298945539
Validation loss: 2.4737790724224253

Epoch: 6| Step: 3
Training loss: 2.9251833866373205
Validation loss: 2.46720889635655

Epoch: 6| Step: 4
Training loss: 2.4658964058494233
Validation loss: 2.4682888183326495

Epoch: 6| Step: 5
Training loss: 3.0897415857991426
Validation loss: 2.4742665212968804

Epoch: 6| Step: 6
Training loss: 2.9807295178969704
Validation loss: 2.466249794171119

Epoch: 6| Step: 7
Training loss: 2.0278625412502826
Validation loss: 2.4829789904535104

Epoch: 6| Step: 8
Training loss: 2.7687106403110686
Validation loss: 2.4667590498426524

Epoch: 6| Step: 9
Training loss: 2.1432835018521286
Validation loss: 2.4598555199992447

Epoch: 6| Step: 10
Training loss: 2.3849180830476966
Validation loss: 2.46533645540024

Epoch: 6| Step: 11
Training loss: 2.467965496335205
Validation loss: 2.4596921343727196

Epoch: 6| Step: 12
Training loss: 3.1721048506716776
Validation loss: 2.4894617330481945

Epoch: 6| Step: 13
Training loss: 3.0349474507390664
Validation loss: 2.449770067436266

Epoch: 86| Step: 0
Training loss: 2.6283950648761745
Validation loss: 2.46634797199526

Epoch: 6| Step: 1
Training loss: 2.687159139619048
Validation loss: 2.4611568688462566

Epoch: 6| Step: 2
Training loss: 2.291818359440747
Validation loss: 2.464536899307484

Epoch: 6| Step: 3
Training loss: 2.7276409825323134
Validation loss: 2.4625450934689272

Epoch: 6| Step: 4
Training loss: 2.3402267422819842
Validation loss: 2.4680220378422915

Epoch: 6| Step: 5
Training loss: 2.8114996932611462
Validation loss: 2.4846158124091264

Epoch: 6| Step: 6
Training loss: 2.9612610169669122
Validation loss: 2.4575398518336864

Epoch: 6| Step: 7
Training loss: 3.0322326954950056
Validation loss: 2.4780571008206245

Epoch: 6| Step: 8
Training loss: 2.5593587648950407
Validation loss: 2.4591240501969365

Epoch: 6| Step: 9
Training loss: 2.4267484791382388
Validation loss: 2.4546920967968933

Epoch: 6| Step: 10
Training loss: 2.722243771716436
Validation loss: 2.471325406006443

Epoch: 6| Step: 11
Training loss: 2.5101436820073246
Validation loss: 2.4766102266680017

Epoch: 6| Step: 12
Training loss: 2.31622169621442
Validation loss: 2.4514463026504107

Epoch: 6| Step: 13
Training loss: 1.8006694370070981
Validation loss: 2.4664146849489175

Epoch: 87| Step: 0
Training loss: 3.174155932590492
Validation loss: 2.447005624228191

Epoch: 6| Step: 1
Training loss: 2.835851746831079
Validation loss: 2.4605747271289586

Epoch: 6| Step: 2
Training loss: 2.8947579195998303
Validation loss: 2.4903092580784607

Epoch: 6| Step: 3
Training loss: 2.867677568759553
Validation loss: 2.4612182457049037

Epoch: 6| Step: 4
Training loss: 1.821111937390747
Validation loss: 2.467501975833774

Epoch: 6| Step: 5
Training loss: 2.477242746402393
Validation loss: 2.4591154985418475

Epoch: 6| Step: 6
Training loss: 2.1994596251163805
Validation loss: 2.4620716888483516

Epoch: 6| Step: 7
Training loss: 2.453925907089069
Validation loss: 2.46889381202697

Epoch: 6| Step: 8
Training loss: 2.015006983439647
Validation loss: 2.4650680689278577

Epoch: 6| Step: 9
Training loss: 2.7077057233516424
Validation loss: 2.4694226377836808

Epoch: 6| Step: 10
Training loss: 3.1168685405718577
Validation loss: 2.5037749512981384

Epoch: 6| Step: 11
Training loss: 2.3903916188931897
Validation loss: 2.4821288313278256

Epoch: 6| Step: 12
Training loss: 2.7256066688178335
Validation loss: 2.476093550492524

Epoch: 6| Step: 13
Training loss: 1.9557135556373002
Validation loss: 2.479353648375035

Epoch: 88| Step: 0
Training loss: 2.3080300096250026
Validation loss: 2.47724056384661

Epoch: 6| Step: 1
Training loss: 1.9166167985261369
Validation loss: 2.4831891770884567

Epoch: 6| Step: 2
Training loss: 2.8367955614772784
Validation loss: 2.466229378513873

Epoch: 6| Step: 3
Training loss: 3.291341322904299
Validation loss: 2.476082666796477

Epoch: 6| Step: 4
Training loss: 2.323835786956555
Validation loss: 2.47094418563518

Epoch: 6| Step: 5
Training loss: 3.019724061245811
Validation loss: 2.45304275311071

Epoch: 6| Step: 6
Training loss: 2.9883704477598547
Validation loss: 2.4616376275143717

Epoch: 6| Step: 7
Training loss: 2.1244012325650323
Validation loss: 2.4595745030508955

Epoch: 6| Step: 8
Training loss: 2.356766224781118
Validation loss: 2.488673143947629

Epoch: 6| Step: 9
Training loss: 2.1821964822797626
Validation loss: 2.4631279466577385

Epoch: 6| Step: 10
Training loss: 2.448688747853084
Validation loss: 2.470214726995144

Epoch: 6| Step: 11
Training loss: 2.995483813811818
Validation loss: 2.4761907965539764

Epoch: 6| Step: 12
Training loss: 2.448574048235001
Validation loss: 2.472102869637118

Epoch: 6| Step: 13
Training loss: 2.6091543321329116
Validation loss: 2.4632967712049267

Epoch: 89| Step: 0
Training loss: 2.4979764378141183
Validation loss: 2.4777223477033496

Epoch: 6| Step: 1
Training loss: 2.3613353946848394
Validation loss: 2.4608573539823366

Epoch: 6| Step: 2
Training loss: 2.8278257095714685
Validation loss: 2.4590795224675714

Epoch: 6| Step: 3
Training loss: 2.55239896314654
Validation loss: 2.4751045974765753

Epoch: 6| Step: 4
Training loss: 2.4361928711755163
Validation loss: 2.452537928808483

Epoch: 6| Step: 5
Training loss: 2.2354601379130523
Validation loss: 2.4640871944338816

Epoch: 6| Step: 6
Training loss: 2.8964527666009663
Validation loss: 2.471879542764439

Epoch: 6| Step: 7
Training loss: 2.830604098919405
Validation loss: 2.4594871110486545

Epoch: 6| Step: 8
Training loss: 2.744573440900709
Validation loss: 2.4579698818149525

Epoch: 6| Step: 9
Training loss: 2.81685436985205
Validation loss: 2.4601109979063502

Epoch: 6| Step: 10
Training loss: 2.337367305967154
Validation loss: 2.469049049583966

Epoch: 6| Step: 11
Training loss: 2.820106984943064
Validation loss: 2.4641072647423523

Epoch: 6| Step: 12
Training loss: 2.535465826990943
Validation loss: 2.456580035466968

Epoch: 6| Step: 13
Training loss: 1.4820076787237448
Validation loss: 2.4720514978324686

Epoch: 90| Step: 0
Training loss: 3.1979888675918198
Validation loss: 2.4741070456677625

Epoch: 6| Step: 1
Training loss: 2.124034550078689
Validation loss: 2.4686139091177126

Epoch: 6| Step: 2
Training loss: 2.278415015746313
Validation loss: 2.4882109897037603

Epoch: 6| Step: 3
Training loss: 2.6795299250146605
Validation loss: 2.4600891130172107

Epoch: 6| Step: 4
Training loss: 2.2709312651162668
Validation loss: 2.484326747622536

Epoch: 6| Step: 5
Training loss: 2.728107703155183
Validation loss: 2.48591236817929

Epoch: 6| Step: 6
Training loss: 3.1720176627111125
Validation loss: 2.4699737685004126

Epoch: 6| Step: 7
Training loss: 1.8426377772625824
Validation loss: 2.471636110986417

Epoch: 6| Step: 8
Training loss: 2.6474350013714814
Validation loss: 2.4674306438318863

Epoch: 6| Step: 9
Training loss: 2.533926408344906
Validation loss: 2.481156169712186

Epoch: 6| Step: 10
Training loss: 2.5169441129158
Validation loss: 2.4815847707609056

Epoch: 6| Step: 11
Training loss: 2.6950415433608206
Validation loss: 2.478487977316898

Epoch: 6| Step: 12
Training loss: 2.580631494197495
Validation loss: 2.4738572982251616

Epoch: 6| Step: 13
Training loss: 2.4069202034706603
Validation loss: 2.469447712186482

Epoch: 91| Step: 0
Training loss: 3.136680441274474
Validation loss: 2.4721219736986377

Epoch: 6| Step: 1
Training loss: 1.7949776625239549
Validation loss: 2.4750199590685935

Epoch: 6| Step: 2
Training loss: 3.017577966980174
Validation loss: 2.46933970035561

Epoch: 6| Step: 3
Training loss: 2.713935711171611
Validation loss: 2.4744408197983283

Epoch: 6| Step: 4
Training loss: 2.2754050847850635
Validation loss: 2.4779973845825576

Epoch: 6| Step: 5
Training loss: 2.473435217446041
Validation loss: 2.4848893352224146

Epoch: 6| Step: 6
Training loss: 2.862024799199495
Validation loss: 2.4779652669306276

Epoch: 6| Step: 7
Training loss: 2.1036589988931826
Validation loss: 2.462561298450894

Epoch: 6| Step: 8
Training loss: 2.3009174092907902
Validation loss: 2.4736371736122194

Epoch: 6| Step: 9
Training loss: 2.6421365418305447
Validation loss: 2.4721513834190034

Epoch: 6| Step: 10
Training loss: 3.117936964453682
Validation loss: 2.46319348956129

Epoch: 6| Step: 11
Training loss: 2.177947741264234
Validation loss: 2.466535482338274

Epoch: 6| Step: 12
Training loss: 2.2092358406410018
Validation loss: 2.4662312475306627

Epoch: 6| Step: 13
Training loss: 2.968640937809617
Validation loss: 2.4778620436923533

Epoch: 92| Step: 0
Training loss: 1.9944977174383889
Validation loss: 2.4847024474919857

Epoch: 6| Step: 1
Training loss: 2.746330934702749
Validation loss: 2.4801405595495654

Epoch: 6| Step: 2
Training loss: 2.3523669720291838
Validation loss: 2.46625730603017

Epoch: 6| Step: 3
Training loss: 2.5598752605326895
Validation loss: 2.447182065502291

Epoch: 6| Step: 4
Training loss: 2.5808213439143946
Validation loss: 2.4768757633487937

Epoch: 6| Step: 5
Training loss: 2.629393669843754
Validation loss: 2.468838610291369

Epoch: 6| Step: 6
Training loss: 2.629311064207368
Validation loss: 2.465155923448845

Epoch: 6| Step: 7
Training loss: 2.0722630938515407
Validation loss: 2.458529468871994

Epoch: 6| Step: 8
Training loss: 3.6260300849891047
Validation loss: 2.4594062318791656

Epoch: 6| Step: 9
Training loss: 2.718985711764821
Validation loss: 2.467340574051709

Epoch: 6| Step: 10
Training loss: 2.6002295576138694
Validation loss: 2.4605456937366257

Epoch: 6| Step: 11
Training loss: 2.501312864810889
Validation loss: 2.471268289123981

Epoch: 6| Step: 12
Training loss: 2.358516511666438
Validation loss: 2.4383074751065514

Epoch: 6| Step: 13
Training loss: 1.8246952716957838
Validation loss: 2.4780468552667547

Epoch: 93| Step: 0
Training loss: 2.756309207617688
Validation loss: 2.469963812730498

Epoch: 6| Step: 1
Training loss: 2.5274583651983824
Validation loss: 2.4621734536509803

Epoch: 6| Step: 2
Training loss: 2.822497591299781
Validation loss: 2.459492318612052

Epoch: 6| Step: 3
Training loss: 2.0230132729759136
Validation loss: 2.4643795819991396

Epoch: 6| Step: 4
Training loss: 2.721048633027267
Validation loss: 2.4666639741080814

Epoch: 6| Step: 5
Training loss: 2.776159535685607
Validation loss: 2.465049626755806

Epoch: 6| Step: 6
Training loss: 2.9394268452936547
Validation loss: 2.453595973887261

Epoch: 6| Step: 7
Training loss: 2.3096142883630466
Validation loss: 2.4690421853008107

Epoch: 6| Step: 8
Training loss: 2.3600519484928633
Validation loss: 2.4549375648446365

Epoch: 6| Step: 9
Training loss: 1.9960050619172027
Validation loss: 2.4542871892265095

Epoch: 6| Step: 10
Training loss: 2.6950931183363416
Validation loss: 2.4676721685532437

Epoch: 6| Step: 11
Training loss: 2.2842644410313047
Validation loss: 2.467081040864178

Epoch: 6| Step: 12
Training loss: 2.9592475194976227
Validation loss: 2.44794018240381

Epoch: 6| Step: 13
Training loss: 2.5000819192816257
Validation loss: 2.447822492189147

Epoch: 94| Step: 0
Training loss: 2.2400391817072074
Validation loss: 2.472238193978245

Epoch: 6| Step: 1
Training loss: 3.005637911147929
Validation loss: 2.4555861834104493

Epoch: 6| Step: 2
Training loss: 3.134344549211817
Validation loss: 2.458784281724294

Epoch: 6| Step: 3
Training loss: 2.366918768909944
Validation loss: 2.4524652636248794

Epoch: 6| Step: 4
Training loss: 2.231167284717257
Validation loss: 2.478819858956073

Epoch: 6| Step: 5
Training loss: 2.7876449957800506
Validation loss: 2.46335484981097

Epoch: 6| Step: 6
Training loss: 2.7126677430492085
Validation loss: 2.4808857135912112

Epoch: 6| Step: 7
Training loss: 2.296283983239736
Validation loss: 2.4716507565478594

Epoch: 6| Step: 8
Training loss: 2.5181405894425835
Validation loss: 2.460211834074303

Epoch: 6| Step: 9
Training loss: 2.3804395523008357
Validation loss: 2.4518914680743156

Epoch: 6| Step: 10
Training loss: 2.050024739558109
Validation loss: 2.463381219206656

Epoch: 6| Step: 11
Training loss: 2.46981315415741
Validation loss: 2.469914978848798

Epoch: 6| Step: 12
Training loss: 2.432629536613075
Validation loss: 2.4470204407768588

Epoch: 6| Step: 13
Training loss: 2.931713166886472
Validation loss: 2.47482878850092

Epoch: 95| Step: 0
Training loss: 3.037994589393323
Validation loss: 2.4772967487811863

Epoch: 6| Step: 1
Training loss: 2.3163043509548658
Validation loss: 2.460268687152969

Epoch: 6| Step: 2
Training loss: 1.8305650386973087
Validation loss: 2.4565744335169297

Epoch: 6| Step: 3
Training loss: 2.233582682947399
Validation loss: 2.479019735285206

Epoch: 6| Step: 4
Training loss: 2.117503575453729
Validation loss: 2.465307518641334

Epoch: 6| Step: 5
Training loss: 2.3113839833039265
Validation loss: 2.458489791774545

Epoch: 6| Step: 6
Training loss: 2.4667261253957564
Validation loss: 2.4811035584177232

Epoch: 6| Step: 7
Training loss: 2.5956090676149146
Validation loss: 2.4665004106591537

Epoch: 6| Step: 8
Training loss: 2.898933635519194
Validation loss: 2.466046061416775

Epoch: 6| Step: 9
Training loss: 3.1146673661104924
Validation loss: 2.4663174234667884

Epoch: 6| Step: 10
Training loss: 2.410015776016708
Validation loss: 2.450788326771594

Epoch: 6| Step: 11
Training loss: 3.023493014671214
Validation loss: 2.4690311137356717

Epoch: 6| Step: 12
Training loss: 2.390429220722389
Validation loss: 2.4468552682457365

Epoch: 6| Step: 13
Training loss: 2.695209357458115
Validation loss: 2.4724044009292365

Epoch: 96| Step: 0
Training loss: 2.618241829377036
Validation loss: 2.4600741276801252

Epoch: 6| Step: 1
Training loss: 1.8097776818074531
Validation loss: 2.4651687647266796

Epoch: 6| Step: 2
Training loss: 3.437097699292591
Validation loss: 2.4659254344624357

Epoch: 6| Step: 3
Training loss: 2.9062596802909177
Validation loss: 2.4497286692992937

Epoch: 6| Step: 4
Training loss: 1.9394185196631055
Validation loss: 2.474047245485307

Epoch: 6| Step: 5
Training loss: 2.8960014861614143
Validation loss: 2.4642500348163003

Epoch: 6| Step: 6
Training loss: 2.349998790659492
Validation loss: 2.4363780262096046

Epoch: 6| Step: 7
Training loss: 2.8299803996671073
Validation loss: 2.4713120069801735

Epoch: 6| Step: 8
Training loss: 2.7585901131250807
Validation loss: 2.4684120259447373

Epoch: 6| Step: 9
Training loss: 2.3726601367927396
Validation loss: 2.440906254454474

Epoch: 6| Step: 10
Training loss: 2.4035421220275794
Validation loss: 2.4564591430075065

Epoch: 6| Step: 11
Training loss: 2.53312942997686
Validation loss: 2.451058544609168

Epoch: 6| Step: 12
Training loss: 2.26775055196068
Validation loss: 2.4760591298118912

Epoch: 6| Step: 13
Training loss: 1.601963867508673
Validation loss: 2.4556366025211545

Epoch: 97| Step: 0
Training loss: 1.9142709423930833
Validation loss: 2.4782799568698057

Epoch: 6| Step: 1
Training loss: 2.3787027907786022
Validation loss: 2.4518478964141512

Epoch: 6| Step: 2
Training loss: 2.083825116923184
Validation loss: 2.4634959006275725

Epoch: 6| Step: 3
Training loss: 2.2582723287903574
Validation loss: 2.4478972043895957

Epoch: 6| Step: 4
Training loss: 2.6917446239350786
Validation loss: 2.4763156370201838

Epoch: 6| Step: 5
Training loss: 2.007011283398031
Validation loss: 2.472030453408809

Epoch: 6| Step: 6
Training loss: 3.4094385744316122
Validation loss: 2.4325078638156636

Epoch: 6| Step: 7
Training loss: 2.9347830036795775
Validation loss: 2.466530622243819

Epoch: 6| Step: 8
Training loss: 2.6184363275186837
Validation loss: 2.4670985793933666

Epoch: 6| Step: 9
Training loss: 2.7085699907245004
Validation loss: 2.467226067182314

Epoch: 6| Step: 10
Training loss: 2.9245009428568336
Validation loss: 2.4628687367056985

Epoch: 6| Step: 11
Training loss: 2.0007599340552336
Validation loss: 2.4663987537078484

Epoch: 6| Step: 12
Training loss: 2.302672976645148
Validation loss: 2.4710838954747807

Epoch: 6| Step: 13
Training loss: 3.2657914552747704
Validation loss: 2.465941331335088

Epoch: 98| Step: 0
Training loss: 2.394994893078546
Validation loss: 2.465002773471137

Epoch: 6| Step: 1
Training loss: 2.5763027340129723
Validation loss: 2.4621907642338288

Epoch: 6| Step: 2
Training loss: 2.6216776576926324
Validation loss: 2.452867451437102

Epoch: 6| Step: 3
Training loss: 2.3341769214837496
Validation loss: 2.467022861891425

Epoch: 6| Step: 4
Training loss: 2.2886802171853637
Validation loss: 2.4536651597680765

Epoch: 6| Step: 5
Training loss: 2.2865985198844365
Validation loss: 2.452388659447729

Epoch: 6| Step: 6
Training loss: 2.1916341680092275
Validation loss: 2.4667275679280767

Epoch: 6| Step: 7
Training loss: 3.1944241582991135
Validation loss: 2.482636492312804

Epoch: 6| Step: 8
Training loss: 2.2076986468440616
Validation loss: 2.46515886234778

Epoch: 6| Step: 9
Training loss: 2.2083307542126067
Validation loss: 2.4908754779226787

Epoch: 6| Step: 10
Training loss: 2.2247474098417683
Validation loss: 2.45790114722094

Epoch: 6| Step: 11
Training loss: 3.320202060433511
Validation loss: 2.4752367789941805

Epoch: 6| Step: 12
Training loss: 2.8001295366296035
Validation loss: 2.486437108327713

Epoch: 6| Step: 13
Training loss: 2.5447430258708845
Validation loss: 2.4810939676216077

Epoch: 99| Step: 0
Training loss: 3.0686900581674426
Validation loss: 2.466986625986659

Epoch: 6| Step: 1
Training loss: 2.775336161004571
Validation loss: 2.4655774678222895

Epoch: 6| Step: 2
Training loss: 2.204198913722925
Validation loss: 2.4561832933579457

Epoch: 6| Step: 3
Training loss: 2.4622660608076705
Validation loss: 2.4746480622564646

Epoch: 6| Step: 4
Training loss: 2.1189993112445054
Validation loss: 2.449621555083682

Epoch: 6| Step: 5
Training loss: 2.8628027543459096
Validation loss: 2.4542323462852473

Epoch: 6| Step: 6
Training loss: 2.95036970505128
Validation loss: 2.4739674516303647

Epoch: 6| Step: 7
Training loss: 3.008678757410869
Validation loss: 2.471980396672233

Epoch: 6| Step: 8
Training loss: 2.214725121175475
Validation loss: 2.4772061404756274

Epoch: 6| Step: 9
Training loss: 2.793902645165293
Validation loss: 2.4553979152133008

Epoch: 6| Step: 10
Training loss: 1.6400500061971124
Validation loss: 2.4583289355125184

Epoch: 6| Step: 11
Training loss: 2.6981013368616473
Validation loss: 2.465665904120321

Epoch: 6| Step: 12
Training loss: 1.9374040764474458
Validation loss: 2.467599504380387

Epoch: 6| Step: 13
Training loss: 2.1896344262092415
Validation loss: 2.476093751351762

Epoch: 100| Step: 0
Training loss: 2.6308488626135555
Validation loss: 2.477029092082142

Epoch: 6| Step: 1
Training loss: 1.9905944438607275
Validation loss: 2.472586009169306

Epoch: 6| Step: 2
Training loss: 2.5247270342138055
Validation loss: 2.4770657037301698

Epoch: 6| Step: 3
Training loss: 2.6954942724881383
Validation loss: 2.466011065944304

Epoch: 6| Step: 4
Training loss: 2.3083999991401565
Validation loss: 2.4651366749261356

Epoch: 6| Step: 5
Training loss: 3.218314428394119
Validation loss: 2.4795641361180034

Epoch: 6| Step: 6
Training loss: 3.1601378413207644
Validation loss: 2.4533751996118713

Epoch: 6| Step: 7
Training loss: 2.3058979541072193
Validation loss: 2.46556495100434

Epoch: 6| Step: 8
Training loss: 1.8932105425968484
Validation loss: 2.467830850825188

Epoch: 6| Step: 9
Training loss: 2.5140262048731836
Validation loss: 2.4639206740673565

Epoch: 6| Step: 10
Training loss: 2.517485315759255
Validation loss: 2.467342851084689

Epoch: 6| Step: 11
Training loss: 2.1883233836815306
Validation loss: 2.4695031198689925

Epoch: 6| Step: 12
Training loss: 2.8684438504685805
Validation loss: 2.45736477499199

Epoch: 6| Step: 13
Training loss: 2.2158143945836026
Validation loss: 2.468950318776089

Epoch: 101| Step: 0
Training loss: 2.325298975108129
Validation loss: 2.47717122918537

Epoch: 6| Step: 1
Training loss: 2.0634063116591044
Validation loss: 2.446826698611125

Epoch: 6| Step: 2
Training loss: 2.7236374519557565
Validation loss: 2.451393004576866

Epoch: 6| Step: 3
Training loss: 2.9940472990796216
Validation loss: 2.4643623206006304

Epoch: 6| Step: 4
Training loss: 2.440308151485493
Validation loss: 2.4755777233512

Epoch: 6| Step: 5
Training loss: 2.2767215880010494
Validation loss: 2.464693593928741

Epoch: 6| Step: 6
Training loss: 1.9877026508589788
Validation loss: 2.4628765284736214

Epoch: 6| Step: 7
Training loss: 2.682600123375833
Validation loss: 2.45723828992653

Epoch: 6| Step: 8
Training loss: 2.7147524152801727
Validation loss: 2.474516687428965

Epoch: 6| Step: 9
Training loss: 2.7540507393666704
Validation loss: 2.474264475474216

Epoch: 6| Step: 10
Training loss: 2.2869530029004936
Validation loss: 2.4610928737893953

Epoch: 6| Step: 11
Training loss: 2.67353510452718
Validation loss: 2.4658308599346572

Epoch: 6| Step: 12
Training loss: 2.674714481410655
Validation loss: 2.474333603035204

Epoch: 6| Step: 13
Training loss: 2.7238520837974955
Validation loss: 2.449428891545869

Epoch: 102| Step: 0
Training loss: 2.0271873340280253
Validation loss: 2.465323266636053

Epoch: 6| Step: 1
Training loss: 2.738192960918413
Validation loss: 2.4811744947499816

Epoch: 6| Step: 2
Training loss: 2.6719474559574445
Validation loss: 2.4656292931981896

Epoch: 6| Step: 3
Training loss: 2.4104894967205412
Validation loss: 2.4615416863805777

Epoch: 6| Step: 4
Training loss: 2.5191095516768636
Validation loss: 2.480968929468688

Epoch: 6| Step: 5
Training loss: 2.0615329209131708
Validation loss: 2.4741460692454704

Epoch: 6| Step: 6
Training loss: 2.349509321890403
Validation loss: 2.449408599963261

Epoch: 6| Step: 7
Training loss: 2.5226710428068233
Validation loss: 2.4636487009883457

Epoch: 6| Step: 8
Training loss: 2.8458321462901495
Validation loss: 2.4581944583010222

Epoch: 6| Step: 9
Training loss: 1.9263556128777535
Validation loss: 2.46166876107818

Epoch: 6| Step: 10
Training loss: 2.9333783717021276
Validation loss: 2.4592884419841883

Epoch: 6| Step: 11
Training loss: 3.129629901540704
Validation loss: 2.4752071625376213

Epoch: 6| Step: 12
Training loss: 2.34572701040998
Validation loss: 2.481673965360175

Epoch: 6| Step: 13
Training loss: 2.6446973108981626
Validation loss: 2.449384860560674

Epoch: 103| Step: 0
Training loss: 2.4717428680869538
Validation loss: 2.460619388248559

Epoch: 6| Step: 1
Training loss: 2.1658349886285264
Validation loss: 2.457868976094228

Epoch: 6| Step: 2
Training loss: 2.6463011280539024
Validation loss: 2.4634968538641364

Epoch: 6| Step: 3
Training loss: 2.5238583807230635
Validation loss: 2.4589406355378607

Epoch: 6| Step: 4
Training loss: 1.7802603130515948
Validation loss: 2.4609990427525927

Epoch: 6| Step: 5
Training loss: 2.8463873737674863
Validation loss: 2.476342156202918

Epoch: 6| Step: 6
Training loss: 2.7812234255774846
Validation loss: 2.4461357091065135

Epoch: 6| Step: 7
Training loss: 3.1668773045671688
Validation loss: 2.472970954647523

Epoch: 6| Step: 8
Training loss: 2.6105915819786802
Validation loss: 2.463884842550026

Epoch: 6| Step: 9
Training loss: 2.154017854883969
Validation loss: 2.4586028244558213

Epoch: 6| Step: 10
Training loss: 2.6385020011473546
Validation loss: 2.4838921667288276

Epoch: 6| Step: 11
Training loss: 2.6264209534438154
Validation loss: 2.453780480209521

Epoch: 6| Step: 12
Training loss: 2.2288975300636693
Validation loss: 2.477828557020366

Epoch: 6| Step: 13
Training loss: 2.773814946669644
Validation loss: 2.4770222944168045

Epoch: 104| Step: 0
Training loss: 2.6110295515196094
Validation loss: 2.4715536253976493

Epoch: 6| Step: 1
Training loss: 3.1700521408269493
Validation loss: 2.472539143168226

Epoch: 6| Step: 2
Training loss: 2.6445987754776823
Validation loss: 2.4666465904657144

Epoch: 6| Step: 3
Training loss: 2.786722350165007
Validation loss: 2.4921172027286422

Epoch: 6| Step: 4
Training loss: 2.3056616841699404
Validation loss: 2.471612389037923

Epoch: 6| Step: 5
Training loss: 2.761717973031848
Validation loss: 2.459517046048935

Epoch: 6| Step: 6
Training loss: 1.6831333743516357
Validation loss: 2.4676125064408794

Epoch: 6| Step: 7
Training loss: 2.530050582229319
Validation loss: 2.447333912984784

Epoch: 6| Step: 8
Training loss: 1.9096859468039586
Validation loss: 2.4781129951653353

Epoch: 6| Step: 9
Training loss: 2.26478034750181
Validation loss: 2.473353102289944

Epoch: 6| Step: 10
Training loss: 2.600311803461217
Validation loss: 2.479006091906941

Epoch: 6| Step: 11
Training loss: 2.5659842645009543
Validation loss: 2.4518927509966137

Epoch: 6| Step: 12
Training loss: 2.7669850254349853
Validation loss: 2.480215528251296

Epoch: 6| Step: 13
Training loss: 2.0620903995578095
Validation loss: 2.4662376009297597

Epoch: 105| Step: 0
Training loss: 2.5979804962401074
Validation loss: 2.476330186578854

Epoch: 6| Step: 1
Training loss: 1.9103136368331135
Validation loss: 2.4745730274482702

Epoch: 6| Step: 2
Training loss: 2.642670240016155
Validation loss: 2.4661632489191767

Epoch: 6| Step: 3
Training loss: 2.4041792641700277
Validation loss: 2.444493558916346

Epoch: 6| Step: 4
Training loss: 2.3638125492335087
Validation loss: 2.4601575431595895

Epoch: 6| Step: 5
Training loss: 2.950996075587829
Validation loss: 2.4565651685648198

Epoch: 6| Step: 6
Training loss: 2.547867657576606
Validation loss: 2.4653662902604077

Epoch: 6| Step: 7
Training loss: 1.9831142475499108
Validation loss: 2.4499708184385134

Epoch: 6| Step: 8
Training loss: 3.389486235900564
Validation loss: 2.4598525601734638

Epoch: 6| Step: 9
Training loss: 1.8882553130370174
Validation loss: 2.461797893731763

Epoch: 6| Step: 10
Training loss: 1.899275355435051
Validation loss: 2.4581745493398945

Epoch: 6| Step: 11
Training loss: 2.5075603607914796
Validation loss: 2.460146345118617

Epoch: 6| Step: 12
Training loss: 2.661020460644332
Validation loss: 2.4612037974276353

Epoch: 6| Step: 13
Training loss: 3.3121724956484644
Validation loss: 2.4837617845487583

Epoch: 106| Step: 0
Training loss: 2.2964186442104886
Validation loss: 2.463885257704383

Epoch: 6| Step: 1
Training loss: 2.6783713620264806
Validation loss: 2.480781687493792

Epoch: 6| Step: 2
Training loss: 3.0695656991735767
Validation loss: 2.480717497001301

Epoch: 6| Step: 3
Training loss: 1.9593322384197287
Validation loss: 2.4805716337817234

Epoch: 6| Step: 4
Training loss: 3.1670959248639816
Validation loss: 2.459009177395558

Epoch: 6| Step: 5
Training loss: 2.4838329179627743
Validation loss: 2.4670429488442083

Epoch: 6| Step: 6
Training loss: 2.4504013978322097
Validation loss: 2.461044175348652

Epoch: 6| Step: 7
Training loss: 2.067863426509546
Validation loss: 2.456743544060811

Epoch: 6| Step: 8
Training loss: 2.649635966506509
Validation loss: 2.460564680192832

Epoch: 6| Step: 9
Training loss: 2.3565286810521915
Validation loss: 2.4612147281701917

Epoch: 6| Step: 10
Training loss: 2.400278186570216
Validation loss: 2.471095250403822

Epoch: 6| Step: 11
Training loss: 2.498137543250483
Validation loss: 2.4547323720829652

Epoch: 6| Step: 12
Training loss: 2.5499928119034525
Validation loss: 2.459620224623772

Epoch: 6| Step: 13
Training loss: 2.2019598294369724
Validation loss: 2.4622689167387564

Epoch: 107| Step: 0
Training loss: 2.407702515384301
Validation loss: 2.4520501971659923

Epoch: 6| Step: 1
Training loss: 2.7460249869146796
Validation loss: 2.4650195239008856

Epoch: 6| Step: 2
Training loss: 2.1270084986909237
Validation loss: 2.4644046234514754

Epoch: 6| Step: 3
Training loss: 2.993697221326585
Validation loss: 2.4639922247317707

Epoch: 6| Step: 4
Training loss: 2.6084532794449977
Validation loss: 2.4758967026776366

Epoch: 6| Step: 5
Training loss: 2.558262740993021
Validation loss: 2.4569767980281934

Epoch: 6| Step: 6
Training loss: 2.694668988793889
Validation loss: 2.473553377350819

Epoch: 6| Step: 7
Training loss: 2.6207524402872324
Validation loss: 2.4764813223879276

Epoch: 6| Step: 8
Training loss: 2.3569990915159953
Validation loss: 2.4538434007841277

Epoch: 6| Step: 9
Training loss: 2.088525887776145
Validation loss: 2.458516865597413

Epoch: 6| Step: 10
Training loss: 2.720209278161938
Validation loss: 2.4465179308133584

Epoch: 6| Step: 11
Training loss: 2.019925992006537
Validation loss: 2.456166012976721

Epoch: 6| Step: 12
Training loss: 2.681734065395684
Validation loss: 2.4669607741958237

Epoch: 6| Step: 13
Training loss: 2.079447848686693
Validation loss: 2.442200999465094

Epoch: 108| Step: 0
Training loss: 2.437041802011401
Validation loss: 2.4579545847388333

Epoch: 6| Step: 1
Training loss: 2.359701576115148
Validation loss: 2.4822757773127293

Epoch: 6| Step: 2
Training loss: 3.0995053788870894
Validation loss: 2.468968165913655

Epoch: 6| Step: 3
Training loss: 2.2637887814263107
Validation loss: 2.4389934671106426

Epoch: 6| Step: 4
Training loss: 2.924944076655569
Validation loss: 2.445581101580756

Epoch: 6| Step: 5
Training loss: 2.1133577399945387
Validation loss: 2.45791908918956

Epoch: 6| Step: 6
Training loss: 2.3600239650673336
Validation loss: 2.469530761217088

Epoch: 6| Step: 7
Training loss: 2.761515522214415
Validation loss: 2.4443678168793497

Epoch: 6| Step: 8
Training loss: 2.208577760328848
Validation loss: 2.4511789116952287

Epoch: 6| Step: 9
Training loss: 2.179692312802706
Validation loss: 2.459926531822038

Epoch: 6| Step: 10
Training loss: 2.418645366603651
Validation loss: 2.4695243758040437

Epoch: 6| Step: 11
Training loss: 2.814910025640893
Validation loss: 2.4670988256675956

Epoch: 6| Step: 12
Training loss: 2.1603573365802955
Validation loss: 2.4753087705186667

Epoch: 6| Step: 13
Training loss: 2.598615013385586
Validation loss: 2.4490388356457857

Epoch: 109| Step: 0
Training loss: 2.5240570347141023
Validation loss: 2.4703455159578698

Epoch: 6| Step: 1
Training loss: 3.158350783595959
Validation loss: 2.457365370686467

Epoch: 6| Step: 2
Training loss: 2.476672437857077
Validation loss: 2.447631407388702

Epoch: 6| Step: 3
Training loss: 2.643138795006185
Validation loss: 2.4570799653733504

Epoch: 6| Step: 4
Training loss: 2.466409080390164
Validation loss: 2.469225834381889

Epoch: 6| Step: 5
Training loss: 2.9206721640039306
Validation loss: 2.4658078561762857

Epoch: 6| Step: 6
Training loss: 1.648545103493366
Validation loss: 2.454051876539999

Epoch: 6| Step: 7
Training loss: 2.3813706334913882
Validation loss: 2.480848017474567

Epoch: 6| Step: 8
Training loss: 2.767295203759616
Validation loss: 2.470452516657166

Epoch: 6| Step: 9
Training loss: 2.530115226413501
Validation loss: 2.468288769517004

Epoch: 6| Step: 10
Training loss: 2.307056722167731
Validation loss: 2.4679490598733036

Epoch: 6| Step: 11
Training loss: 2.472785837836485
Validation loss: 2.4642616750747637

Epoch: 6| Step: 12
Training loss: 2.2501424108577273
Validation loss: 2.4697764806707485

Epoch: 6| Step: 13
Training loss: 2.021427408051481
Validation loss: 2.4577573178232446

Epoch: 110| Step: 0
Training loss: 2.1278808364057586
Validation loss: 2.486953939498795

Epoch: 6| Step: 1
Training loss: 1.7911931972188773
Validation loss: 2.4637789270006816

Epoch: 6| Step: 2
Training loss: 3.1300726346494185
Validation loss: 2.4786700717099017

Epoch: 6| Step: 3
Training loss: 2.8686803938123293
Validation loss: 2.4642737168429547

Epoch: 6| Step: 4
Training loss: 2.512823974067025
Validation loss: 2.467331632144167

Epoch: 6| Step: 5
Training loss: 2.917510664396563
Validation loss: 2.4713719309197297

Epoch: 6| Step: 6
Training loss: 2.495031856264692
Validation loss: 2.476763326526675

Epoch: 6| Step: 7
Training loss: 2.2905287489503525
Validation loss: 2.489174143518655

Epoch: 6| Step: 8
Training loss: 2.6700938573335233
Validation loss: 2.455851067792726

Epoch: 6| Step: 9
Training loss: 2.467457493316398
Validation loss: 2.463749271662278

Epoch: 6| Step: 10
Training loss: 2.254655260686976
Validation loss: 2.4608178571430512

Epoch: 6| Step: 11
Training loss: 2.5750347690642252
Validation loss: 2.446242322535207

Epoch: 6| Step: 12
Training loss: 2.1281955477634718
Validation loss: 2.4624914937371885

Epoch: 6| Step: 13
Training loss: 2.5866107352426666
Validation loss: 2.4387496550951493

Epoch: 111| Step: 0
Training loss: 2.4212217372806486
Validation loss: 2.4558683258587553

Epoch: 6| Step: 1
Training loss: 2.123349390173804
Validation loss: 2.4559735178426756

Epoch: 6| Step: 2
Training loss: 2.4799050479062417
Validation loss: 2.4733377179299687

Epoch: 6| Step: 3
Training loss: 2.4749706459231295
Validation loss: 2.462562151067768

Epoch: 6| Step: 4
Training loss: 2.1327507932350938
Validation loss: 2.4689146983571932

Epoch: 6| Step: 5
Training loss: 2.8796567934896364
Validation loss: 2.466395192629517

Epoch: 6| Step: 6
Training loss: 2.363922687841245
Validation loss: 2.4755628027751913

Epoch: 6| Step: 7
Training loss: 2.3236201180557563
Validation loss: 2.467936195146589

Epoch: 6| Step: 8
Training loss: 2.6186548475217615
Validation loss: 2.4690188231292214

Epoch: 6| Step: 9
Training loss: 2.1857392990860864
Validation loss: 2.456510950988346

Epoch: 6| Step: 10
Training loss: 2.8621265950758072
Validation loss: 2.4809305495132348

Epoch: 6| Step: 11
Training loss: 2.4538942333705696
Validation loss: 2.4395903507997394

Epoch: 6| Step: 12
Training loss: 2.115653407752754
Validation loss: 2.479313224506526

Epoch: 6| Step: 13
Training loss: 3.4115369171332284
Validation loss: 2.4620451882848506

Epoch: 112| Step: 0
Training loss: 2.79152077440734
Validation loss: 2.454965236003238

Epoch: 6| Step: 1
Training loss: 1.5026180943240823
Validation loss: 2.4544347763865773

Epoch: 6| Step: 2
Training loss: 2.830037687340502
Validation loss: 2.465091410302783

Epoch: 6| Step: 3
Training loss: 2.410162185340139
Validation loss: 2.4604725638275267

Epoch: 6| Step: 4
Training loss: 2.246819897905813
Validation loss: 2.471462266107059

Epoch: 6| Step: 5
Training loss: 2.3103518431925605
Validation loss: 2.460150933341271

Epoch: 6| Step: 6
Training loss: 2.3569619679091485
Validation loss: 2.460889596467969

Epoch: 6| Step: 7
Training loss: 2.4732409805816666
Validation loss: 2.4494718050074176

Epoch: 6| Step: 8
Training loss: 2.6230721433420863
Validation loss: 2.459440528090577

Epoch: 6| Step: 9
Training loss: 2.7808786208554057
Validation loss: 2.4738089329286725

Epoch: 6| Step: 10
Training loss: 2.7099173877412883
Validation loss: 2.483356015331046

Epoch: 6| Step: 11
Training loss: 2.577683289575626
Validation loss: 2.452214211138084

Epoch: 6| Step: 12
Training loss: 2.630549060670738
Validation loss: 2.4784339124542525

Epoch: 6| Step: 13
Training loss: 1.9948950226968862
Validation loss: 2.464236296140383

Epoch: 113| Step: 0
Training loss: 3.075671772344424
Validation loss: 2.480542124427722

Epoch: 6| Step: 1
Training loss: 2.9992864077966366
Validation loss: 2.474596602395449

Epoch: 6| Step: 2
Training loss: 2.6578916974072673
Validation loss: 2.464396078677421

Epoch: 6| Step: 3
Training loss: 2.2444651662018953
Validation loss: 2.444501659378459

Epoch: 6| Step: 4
Training loss: 1.958681427340182
Validation loss: 2.44301124368759

Epoch: 6| Step: 5
Training loss: 2.3245209313145856
Validation loss: 2.4561987011430504

Epoch: 6| Step: 6
Training loss: 2.0078246119983656
Validation loss: 2.454634479555758

Epoch: 6| Step: 7
Training loss: 2.9505882064700515
Validation loss: 2.4486057677387203

Epoch: 6| Step: 8
Training loss: 2.5523975620020796
Validation loss: 2.469111119031678

Epoch: 6| Step: 9
Training loss: 1.4926245883078215
Validation loss: 2.479910261180898

Epoch: 6| Step: 10
Training loss: 1.9470001621334438
Validation loss: 2.463750855370425

Epoch: 6| Step: 11
Training loss: 1.8224677559468823
Validation loss: 2.4567084708604146

Epoch: 6| Step: 12
Training loss: 3.1277225079197564
Validation loss: 2.480879981553272

Epoch: 6| Step: 13
Training loss: 3.230173524145994
Validation loss: 2.4147401909738972

Epoch: 114| Step: 0
Training loss: 2.4557956809255606
Validation loss: 2.4456223235850714

Epoch: 6| Step: 1
Training loss: 2.8029412488982697
Validation loss: 2.4576923757681834

Epoch: 6| Step: 2
Training loss: 3.0501844381629653
Validation loss: 2.4506125050103296

Epoch: 6| Step: 3
Training loss: 2.8422106254857367
Validation loss: 2.4563175305167846

Epoch: 6| Step: 4
Training loss: 2.487154958746712
Validation loss: 2.464689998142164

Epoch: 6| Step: 5
Training loss: 2.4212915517602354
Validation loss: 2.467921078266873

Epoch: 6| Step: 6
Training loss: 2.332520093432657
Validation loss: 2.459481960803473

Epoch: 6| Step: 7
Training loss: 1.963874471642384
Validation loss: 2.45577952316431

Epoch: 6| Step: 8
Training loss: 2.486402344176514
Validation loss: 2.4525443563566265

Epoch: 6| Step: 9
Training loss: 2.4894658357567194
Validation loss: 2.472004475470941

Epoch: 6| Step: 10
Training loss: 2.299295305020371
Validation loss: 2.470867551544409

Epoch: 6| Step: 11
Training loss: 2.6683813979589095
Validation loss: 2.487366585862141

Epoch: 6| Step: 12
Training loss: 2.309409060504491
Validation loss: 2.466287174967845

Epoch: 6| Step: 13
Training loss: 1.7899099949633166
Validation loss: 2.4461498858614075

Epoch: 115| Step: 0
Training loss: 2.865970696383991
Validation loss: 2.4635556790854527

Epoch: 6| Step: 1
Training loss: 2.8752900682156217
Validation loss: 2.4506938255550255

Epoch: 6| Step: 2
Training loss: 2.0186857892385897
Validation loss: 2.47325275681057

Epoch: 6| Step: 3
Training loss: 2.224782453038586
Validation loss: 2.4695294044090317

Epoch: 6| Step: 4
Training loss: 2.766394728965437
Validation loss: 2.4649914539184605

Epoch: 6| Step: 5
Training loss: 2.095285564252319
Validation loss: 2.4556588616844275

Epoch: 6| Step: 6
Training loss: 1.823480035829994
Validation loss: 2.4590714627289367

Epoch: 6| Step: 7
Training loss: 2.612216156502179
Validation loss: 2.4570330331520283

Epoch: 6| Step: 8
Training loss: 2.4152636456370122
Validation loss: 2.4524301747116524

Epoch: 6| Step: 9
Training loss: 2.389828418334586
Validation loss: 2.4756594017626257

Epoch: 6| Step: 10
Training loss: 2.5376726777652627
Validation loss: 2.4581613211070485

Epoch: 6| Step: 11
Training loss: 2.65625915525766
Validation loss: 2.4635509463128553

Epoch: 6| Step: 12
Training loss: 2.5953880560875917
Validation loss: 2.4596755644550723

Epoch: 6| Step: 13
Training loss: 2.337028427290648
Validation loss: 2.47919316707217

Epoch: 116| Step: 0
Training loss: 2.6163562878098165
Validation loss: 2.4767885160312924

Epoch: 6| Step: 1
Training loss: 2.6255401782141883
Validation loss: 2.4495374317814362

Epoch: 6| Step: 2
Training loss: 3.0050345138624275
Validation loss: 2.425132043836017

Epoch: 6| Step: 3
Training loss: 2.79503515668401
Validation loss: 2.4578062274175534

Epoch: 6| Step: 4
Training loss: 2.2919544270496757
Validation loss: 2.4621992396124064

Epoch: 6| Step: 5
Training loss: 2.694182228053664
Validation loss: 2.4602782851484872

Epoch: 6| Step: 6
Training loss: 2.2069333755261464
Validation loss: 2.4490633441251908

Epoch: 6| Step: 7
Training loss: 2.2987268987908522
Validation loss: 2.4474103653186114

Epoch: 6| Step: 8
Training loss: 1.9001305961900394
Validation loss: 2.4664535402395362

Epoch: 6| Step: 9
Training loss: 2.326682443902301
Validation loss: 2.46337849361206

Epoch: 6| Step: 10
Training loss: 2.59072258078718
Validation loss: 2.471277740661585

Epoch: 6| Step: 11
Training loss: 2.4930445234880483
Validation loss: 2.466031345144566

Epoch: 6| Step: 12
Training loss: 2.0685766464391895
Validation loss: 2.469843924132651

Epoch: 6| Step: 13
Training loss: 2.5942456794402085
Validation loss: 2.4497634892406692

Epoch: 117| Step: 0
Training loss: 2.4421187436900915
Validation loss: 2.4840232701779916

Epoch: 6| Step: 1
Training loss: 2.0846945956565013
Validation loss: 2.464380693536267

Epoch: 6| Step: 2
Training loss: 2.7857239132669385
Validation loss: 2.4445558837511077

Epoch: 6| Step: 3
Training loss: 2.9111385454174514
Validation loss: 2.4519505790415677

Epoch: 6| Step: 4
Training loss: 1.8150791365340255
Validation loss: 2.4485229313942987

Epoch: 6| Step: 5
Training loss: 1.9675767218088913
Validation loss: 2.4353105363091956

Epoch: 6| Step: 6
Training loss: 1.9836197264308735
Validation loss: 2.438414653166457

Epoch: 6| Step: 7
Training loss: 2.465338655773804
Validation loss: 2.4487577038660278

Epoch: 6| Step: 8
Training loss: 3.089742820432007
Validation loss: 2.4630746297049098

Epoch: 6| Step: 9
Training loss: 2.4875450781950157
Validation loss: 2.480409268560762

Epoch: 6| Step: 10
Training loss: 2.644664496216181
Validation loss: 2.4660508548939393

Epoch: 6| Step: 11
Training loss: 2.287004085628862
Validation loss: 2.4603521033299813

Epoch: 6| Step: 12
Training loss: 2.5647628841149035
Validation loss: 2.456204043014821

Epoch: 6| Step: 13
Training loss: 2.6685171164181156
Validation loss: 2.467397318978269

Epoch: 118| Step: 0
Training loss: 2.8024133159424545
Validation loss: 2.4384012735797684

Epoch: 6| Step: 1
Training loss: 2.603334940015596
Validation loss: 2.4526154972870824

Epoch: 6| Step: 2
Training loss: 2.725974995185657
Validation loss: 2.468310970149615

Epoch: 6| Step: 3
Training loss: 2.1834821587233955
Validation loss: 2.4441221557803168

Epoch: 6| Step: 4
Training loss: 2.2529504293041724
Validation loss: 2.4726430950946594

Epoch: 6| Step: 5
Training loss: 2.216326182132375
Validation loss: 2.4462279073726063

Epoch: 6| Step: 6
Training loss: 1.7390096788361868
Validation loss: 2.4651889666210245

Epoch: 6| Step: 7
Training loss: 2.431774359399774
Validation loss: 2.468046240435708

Epoch: 6| Step: 8
Training loss: 2.756111636332736
Validation loss: 2.4429875591262635

Epoch: 6| Step: 9
Training loss: 2.365957614186887
Validation loss: 2.4510009737423397

Epoch: 6| Step: 10
Training loss: 3.1640371816116657
Validation loss: 2.4595752232874317

Epoch: 6| Step: 11
Training loss: 1.7733620110800612
Validation loss: 2.4540990219461176

Epoch: 6| Step: 12
Training loss: 2.32596195788775
Validation loss: 2.4459088677568133

Epoch: 6| Step: 13
Training loss: 2.975738170949914
Validation loss: 2.451746921196835

Epoch: 119| Step: 0
Training loss: 2.585276354953554
Validation loss: 2.448913880773489

Epoch: 6| Step: 1
Training loss: 2.0533236194149627
Validation loss: 2.4559791483031166

Epoch: 6| Step: 2
Training loss: 2.712700965573885
Validation loss: 2.4507594410498332

Epoch: 6| Step: 3
Training loss: 2.8234139505321516
Validation loss: 2.438383560180921

Epoch: 6| Step: 4
Training loss: 2.3398266315630063
Validation loss: 2.4513499804264804

Epoch: 6| Step: 5
Training loss: 1.9397139666770389
Validation loss: 2.4381886864255216

Epoch: 6| Step: 6
Training loss: 1.3641334646321173
Validation loss: 2.457486464759701

Epoch: 6| Step: 7
Training loss: 3.0850323472266963
Validation loss: 2.4505095895120848

Epoch: 6| Step: 8
Training loss: 2.436638606527858
Validation loss: 2.4395455411437843

Epoch: 6| Step: 9
Training loss: 2.8267167942832563
Validation loss: 2.4614758339097813

Epoch: 6| Step: 10
Training loss: 1.95351448753185
Validation loss: 2.441253039337451

Epoch: 6| Step: 11
Training loss: 2.5903748763097774
Validation loss: 2.4688041803601912

Epoch: 6| Step: 12
Training loss: 2.3117913887392234
Validation loss: 2.4512665005444205

Epoch: 6| Step: 13
Training loss: 3.091592980780859
Validation loss: 2.45528866092134

Epoch: 120| Step: 0
Training loss: 1.8087085662714868
Validation loss: 2.451165459541175

Epoch: 6| Step: 1
Training loss: 2.271311601675723
Validation loss: 2.4501234672212946

Epoch: 6| Step: 2
Training loss: 2.2711627499623197
Validation loss: 2.457916991690281

Epoch: 6| Step: 3
Training loss: 2.2227201804568995
Validation loss: 2.4643169252397916

Epoch: 6| Step: 4
Training loss: 2.952653635341506
Validation loss: 2.453547465707385

Epoch: 6| Step: 5
Training loss: 2.223907065117008
Validation loss: 2.4666279449544337

Epoch: 6| Step: 6
Training loss: 2.4325342704029
Validation loss: 2.4667631383465145

Epoch: 6| Step: 7
Training loss: 2.4269279681292137
Validation loss: 2.4640616628426018

Epoch: 6| Step: 8
Training loss: 2.6863999000358447
Validation loss: 2.4622346692943387

Epoch: 6| Step: 9
Training loss: 2.703430687703188
Validation loss: 2.4563817814854594

Epoch: 6| Step: 10
Training loss: 1.963089146230495
Validation loss: 2.460125085790412

Epoch: 6| Step: 11
Training loss: 2.857780470546062
Validation loss: 2.456979749840765

Epoch: 6| Step: 12
Training loss: 2.4656443315915757
Validation loss: 2.437217544584997

Epoch: 6| Step: 13
Training loss: 2.8978116164282732
Validation loss: 2.4422497555781426

Epoch: 121| Step: 0
Training loss: 1.7435791205353
Validation loss: 2.449602090828198

Epoch: 6| Step: 1
Training loss: 2.0252593686751568
Validation loss: 2.4452292113522276

Epoch: 6| Step: 2
Training loss: 2.357247207858416
Validation loss: 2.4292911633216603

Epoch: 6| Step: 3
Training loss: 3.007049384474985
Validation loss: 2.4583194044694303

Epoch: 6| Step: 4
Training loss: 2.440418940990244
Validation loss: 2.4783749417910994

Epoch: 6| Step: 5
Training loss: 2.8077052465809986
Validation loss: 2.445380216130912

Epoch: 6| Step: 6
Training loss: 2.7144551170518576
Validation loss: 2.45523068700497

Epoch: 6| Step: 7
Training loss: 1.7746683966133596
Validation loss: 2.4543421280838356

Epoch: 6| Step: 8
Training loss: 2.5620834198055933
Validation loss: 2.448317658608129

Epoch: 6| Step: 9
Training loss: 2.1961755108346073
Validation loss: 2.4493272168608082

Epoch: 6| Step: 10
Training loss: 2.2790390169520562
Validation loss: 2.4583076463889957

Epoch: 6| Step: 11
Training loss: 2.6096035977126535
Validation loss: 2.4483158984274427

Epoch: 6| Step: 12
Training loss: 2.1456767151598126
Validation loss: 2.446539011836085

Epoch: 6| Step: 13
Training loss: 3.6840480876190593
Validation loss: 2.4631401740271985

Epoch: 122| Step: 0
Training loss: 2.628068946485554
Validation loss: 2.440856725789548

Epoch: 6| Step: 1
Training loss: 2.8140803665364946
Validation loss: 2.454551746402053

Epoch: 6| Step: 2
Training loss: 2.8981587977739003
Validation loss: 2.4509451702767255

Epoch: 6| Step: 3
Training loss: 2.2078636557665496
Validation loss: 2.4659878756994025

Epoch: 6| Step: 4
Training loss: 2.3111695251153734
Validation loss: 2.457405945382144

Epoch: 6| Step: 5
Training loss: 2.6304726546518857
Validation loss: 2.4528249015312364

Epoch: 6| Step: 6
Training loss: 2.7976242851896256
Validation loss: 2.456614286605344

Epoch: 6| Step: 7
Training loss: 2.530618282656847
Validation loss: 2.4711175575779913

Epoch: 6| Step: 8
Training loss: 2.3895677210711574
Validation loss: 2.4485056828057536

Epoch: 6| Step: 9
Training loss: 2.0261706888913533
Validation loss: 2.460652121961031

Epoch: 6| Step: 10
Training loss: 1.958387320024605
Validation loss: 2.472287308610173

Epoch: 6| Step: 11
Training loss: 2.429250892587961
Validation loss: 2.4589020415553136

Epoch: 6| Step: 12
Training loss: 2.52011976835439
Validation loss: 2.4363584545721855

Epoch: 6| Step: 13
Training loss: 1.584333463647282
Validation loss: 2.4503951184565844

Epoch: 123| Step: 0
Training loss: 2.8476009912977007
Validation loss: 2.4684747116937533

Epoch: 6| Step: 1
Training loss: 2.339201315186179
Validation loss: 2.4567356441427743

Epoch: 6| Step: 2
Training loss: 2.3396619621056005
Validation loss: 2.448304104870067

Epoch: 6| Step: 3
Training loss: 2.3671051111771186
Validation loss: 2.4393100554534755

Epoch: 6| Step: 4
Training loss: 1.8969944622499901
Validation loss: 2.467215916407231

Epoch: 6| Step: 5
Training loss: 2.415969638494743
Validation loss: 2.460533232590418

Epoch: 6| Step: 6
Training loss: 2.2552185998085337
Validation loss: 2.4529017889060336

Epoch: 6| Step: 7
Training loss: 2.585072998108196
Validation loss: 2.469848614745251

Epoch: 6| Step: 8
Training loss: 2.893082022966817
Validation loss: 2.4565913196841005

Epoch: 6| Step: 9
Training loss: 2.2224876192346645
Validation loss: 2.4725715791059937

Epoch: 6| Step: 10
Training loss: 2.798502869217932
Validation loss: 2.460839462606287

Epoch: 6| Step: 11
Training loss: 2.3058133753537926
Validation loss: 2.4639467705292937

Epoch: 6| Step: 12
Training loss: 2.325422318362889
Validation loss: 2.4539701303044406

Epoch: 6| Step: 13
Training loss: 2.437197642035622
Validation loss: 2.451909057748359

Epoch: 124| Step: 0
Training loss: 2.5108643023225556
Validation loss: 2.458345052010908

Epoch: 6| Step: 1
Training loss: 2.356923225210905
Validation loss: 2.440358707660427

Epoch: 6| Step: 2
Training loss: 2.3892499172828967
Validation loss: 2.4549799778845722

Epoch: 6| Step: 3
Training loss: 2.1463958472062075
Validation loss: 2.4628489841955243

Epoch: 6| Step: 4
Training loss: 2.30257191946428
Validation loss: 2.4483112429999676

Epoch: 6| Step: 5
Training loss: 1.823549396968172
Validation loss: 2.4514130658713995

Epoch: 6| Step: 6
Training loss: 2.427768452313881
Validation loss: 2.4534376833554896

Epoch: 6| Step: 7
Training loss: 2.5228285866778166
Validation loss: 2.4528490795337086

Epoch: 6| Step: 8
Training loss: 2.508320694529311
Validation loss: 2.4849515805524858

Epoch: 6| Step: 9
Training loss: 2.6302133289453384
Validation loss: 2.4556060361012606

Epoch: 6| Step: 10
Training loss: 2.6833931349572766
Validation loss: 2.4550726710351034

Epoch: 6| Step: 11
Training loss: 2.52621033619921
Validation loss: 2.4541715207156285

Epoch: 6| Step: 12
Training loss: 2.830456020696173
Validation loss: 2.4517085846578337

Epoch: 6| Step: 13
Training loss: 2.599881107106178
Validation loss: 2.4284472062124856

Epoch: 125| Step: 0
Training loss: 2.533167548359951
Validation loss: 2.4383325135838865

Epoch: 6| Step: 1
Training loss: 2.577255657317498
Validation loss: 2.4396091378025617

Epoch: 6| Step: 2
Training loss: 2.4979808282658595
Validation loss: 2.448863745662

Epoch: 6| Step: 3
Training loss: 2.032330739010521
Validation loss: 2.4752646499363435

Epoch: 6| Step: 4
Training loss: 2.2116353042475474
Validation loss: 2.4522533102489863

Epoch: 6| Step: 5
Training loss: 2.4313303799323194
Validation loss: 2.444342100291764

Epoch: 6| Step: 6
Training loss: 2.2973489077824802
Validation loss: 2.451683170933983

Epoch: 6| Step: 7
Training loss: 2.8851213177803365
Validation loss: 2.446753690929525

Epoch: 6| Step: 8
Training loss: 1.9292379620136826
Validation loss: 2.46915748632056

Epoch: 6| Step: 9
Training loss: 1.9858964509120602
Validation loss: 2.4478765236088074

Epoch: 6| Step: 10
Training loss: 2.7298206875499234
Validation loss: 2.448554837926482

Epoch: 6| Step: 11
Training loss: 3.045748614912948
Validation loss: 2.450447510261615

Epoch: 6| Step: 12
Training loss: 2.3744178861684686
Validation loss: 2.477331990486039

Epoch: 6| Step: 13
Training loss: 1.9330085870795786
Validation loss: 2.4608589051733056

Epoch: 126| Step: 0
Training loss: 2.420446848480582
Validation loss: 2.4523061450685

Epoch: 6| Step: 1
Training loss: 2.8458244386890494
Validation loss: 2.4620372751813826

Epoch: 6| Step: 2
Training loss: 1.9748437819687263
Validation loss: 2.4635976284525

Epoch: 6| Step: 3
Training loss: 2.088916380286522
Validation loss: 2.456695590056071

Epoch: 6| Step: 4
Training loss: 2.306670496373314
Validation loss: 2.453219599324018

Epoch: 6| Step: 5
Training loss: 2.4244101760723704
Validation loss: 2.4528824651244503

Epoch: 6| Step: 6
Training loss: 2.9215195383505255
Validation loss: 2.4476843841317217

Epoch: 6| Step: 7
Training loss: 2.4612646460690697
Validation loss: 2.453090476498617

Epoch: 6| Step: 8
Training loss: 2.561856072628834
Validation loss: 2.4537471475837926

Epoch: 6| Step: 9
Training loss: 2.396214949580844
Validation loss: 2.44756254952505

Epoch: 6| Step: 10
Training loss: 1.8142636367518743
Validation loss: 2.454334251250026

Epoch: 6| Step: 11
Training loss: 2.1330665744455435
Validation loss: 2.4711746359289273

Epoch: 6| Step: 12
Training loss: 2.784820322373649
Validation loss: 2.452008542686722

Epoch: 6| Step: 13
Training loss: 2.918720357936339
Validation loss: 2.4602443752242213

Epoch: 127| Step: 0
Training loss: 2.1435640304466093
Validation loss: 2.445966475676213

Epoch: 6| Step: 1
Training loss: 2.781630072180604
Validation loss: 2.4631865303811056

Epoch: 6| Step: 2
Training loss: 2.442453388718153
Validation loss: 2.4434254953934667

Epoch: 6| Step: 3
Training loss: 2.626152602962949
Validation loss: 2.44580782448859

Epoch: 6| Step: 4
Training loss: 2.99302530138185
Validation loss: 2.440025267815642

Epoch: 6| Step: 5
Training loss: 2.005573850403267
Validation loss: 2.456232390854268

Epoch: 6| Step: 6
Training loss: 2.5113152970463903
Validation loss: 2.4544638904196527

Epoch: 6| Step: 7
Training loss: 2.6948871663948397
Validation loss: 2.4560706566112644

Epoch: 6| Step: 8
Training loss: 2.6444861719524004
Validation loss: 2.4463024324808216

Epoch: 6| Step: 9
Training loss: 2.537443331381638
Validation loss: 2.4457313739465483

Epoch: 6| Step: 10
Training loss: 2.2423374245526286
Validation loss: 2.423970635068427

Epoch: 6| Step: 11
Training loss: 1.7170934149780868
Validation loss: 2.42820471920731

Epoch: 6| Step: 12
Training loss: 1.9891246513251806
Validation loss: 2.441041553322005

Epoch: 6| Step: 13
Training loss: 2.519296371985619
Validation loss: 2.4735064208524666

Epoch: 128| Step: 0
Training loss: 2.8831638029089324
Validation loss: 2.455763434196009

Epoch: 6| Step: 1
Training loss: 2.819200798577532
Validation loss: 2.452446712046142

Epoch: 6| Step: 2
Training loss: 2.0712966595069306
Validation loss: 2.4498246345935217

Epoch: 6| Step: 3
Training loss: 2.575800917425673
Validation loss: 2.4437554222080142

Epoch: 6| Step: 4
Training loss: 2.4373920123314887
Validation loss: 2.4467544725675032

Epoch: 6| Step: 5
Training loss: 2.9087287422718133
Validation loss: 2.435231365998581

Epoch: 6| Step: 6
Training loss: 2.4219860420612362
Validation loss: 2.434741213047332

Epoch: 6| Step: 7
Training loss: 1.976631796605943
Validation loss: 2.440005778492104

Epoch: 6| Step: 8
Training loss: 1.9635331805490182
Validation loss: 2.430905149391186

Epoch: 6| Step: 9
Training loss: 2.1765271317455728
Validation loss: 2.443713252868638

Epoch: 6| Step: 10
Training loss: 2.3818852856268076
Validation loss: 2.44260613575571

Epoch: 6| Step: 11
Training loss: 2.596073810180534
Validation loss: 2.4650624353076886

Epoch: 6| Step: 12
Training loss: 2.172971599563548
Validation loss: 2.4604562231821623

Epoch: 6| Step: 13
Training loss: 2.270456988678483
Validation loss: 2.42178362125863

Epoch: 129| Step: 0
Training loss: 2.299062712050907
Validation loss: 2.4464553290180606

Epoch: 6| Step: 1
Training loss: 2.5066683527081817
Validation loss: 2.4593600633073844

Epoch: 6| Step: 2
Training loss: 1.7229470766544241
Validation loss: 2.4484864981366226

Epoch: 6| Step: 3
Training loss: 2.7194165695194
Validation loss: 2.4461335407170792

Epoch: 6| Step: 4
Training loss: 1.9039174802352674
Validation loss: 2.442195333040337

Epoch: 6| Step: 5
Training loss: 2.9832684927203927
Validation loss: 2.484069613514806

Epoch: 6| Step: 6
Training loss: 2.6404358384135307
Validation loss: 2.4420598304008734

Epoch: 6| Step: 7
Training loss: 2.817964543359809
Validation loss: 2.4543631293686605

Epoch: 6| Step: 8
Training loss: 2.6688991281621965
Validation loss: 2.4341245175251323

Epoch: 6| Step: 9
Training loss: 2.0264503700923715
Validation loss: 2.446148722546846

Epoch: 6| Step: 10
Training loss: 2.4128644124466594
Validation loss: 2.4479193187132857

Epoch: 6| Step: 11
Training loss: 2.5365774347331604
Validation loss: 2.4614298010189604

Epoch: 6| Step: 12
Training loss: 1.9332628988173346
Validation loss: 2.4522119529885726

Epoch: 6| Step: 13
Training loss: 2.1591843251731064
Validation loss: 2.467715853502934

Epoch: 130| Step: 0
Training loss: 2.8053013546877263
Validation loss: 2.4335449542530725

Epoch: 6| Step: 1
Training loss: 2.4021295715628375
Validation loss: 2.452093405582697

Epoch: 6| Step: 2
Training loss: 2.8379680835630894
Validation loss: 2.4492341534493485

Epoch: 6| Step: 3
Training loss: 2.6556274582116863
Validation loss: 2.4451863733598684

Epoch: 6| Step: 4
Training loss: 2.4020792497620578
Validation loss: 2.4504384664309367

Epoch: 6| Step: 5
Training loss: 2.1208026046875075
Validation loss: 2.4512152913383876

Epoch: 6| Step: 6
Training loss: 2.2483122111413016
Validation loss: 2.4471568038144778

Epoch: 6| Step: 7
Training loss: 1.994700145032922
Validation loss: 2.4468352240647344

Epoch: 6| Step: 8
Training loss: 1.923772975692718
Validation loss: 2.429185821649615

Epoch: 6| Step: 9
Training loss: 2.1248837607511857
Validation loss: 2.472045360563837

Epoch: 6| Step: 10
Training loss: 2.422477991655683
Validation loss: 2.457555715323058

Epoch: 6| Step: 11
Training loss: 2.1643606042562196
Validation loss: 2.447712090679251

Epoch: 6| Step: 12
Training loss: 3.0956649248431742
Validation loss: 2.46398617247408

Epoch: 6| Step: 13
Training loss: 2.292724700365541
Validation loss: 2.4409651924347577

Epoch: 131| Step: 0
Training loss: 2.453161834634633
Validation loss: 2.437459041355457

Epoch: 6| Step: 1
Training loss: 2.2857450329892353
Validation loss: 2.4652693919385302

Epoch: 6| Step: 2
Training loss: 2.5067193331495146
Validation loss: 2.4536312665888795

Epoch: 6| Step: 3
Training loss: 2.3321151846089094
Validation loss: 2.433825345797176

Epoch: 6| Step: 4
Training loss: 2.042979253154765
Validation loss: 2.4460893277910714

Epoch: 6| Step: 5
Training loss: 2.1587330991683116
Validation loss: 2.455301573643528

Epoch: 6| Step: 6
Training loss: 2.3067551470565055
Validation loss: 2.459731873370617

Epoch: 6| Step: 7
Training loss: 2.4311046331335993
Validation loss: 2.4554171236657543

Epoch: 6| Step: 8
Training loss: 1.6356879655192287
Validation loss: 2.4356076509862694

Epoch: 6| Step: 9
Training loss: 3.1367248307070574
Validation loss: 2.466962451447697

Epoch: 6| Step: 10
Training loss: 2.357196838206668
Validation loss: 2.45343832806967

Epoch: 6| Step: 11
Training loss: 3.080920349190982
Validation loss: 2.437748268721206

Epoch: 6| Step: 12
Training loss: 2.1424726322878755
Validation loss: 2.4357598127102675

Epoch: 6| Step: 13
Training loss: 2.3725207589369823
Validation loss: 2.444320660505698

Epoch: 132| Step: 0
Training loss: 3.0536686205394625
Validation loss: 2.448518044969658

Epoch: 6| Step: 1
Training loss: 1.6948347693059678
Validation loss: 2.444503316383197

Epoch: 6| Step: 2
Training loss: 2.746919119939511
Validation loss: 2.4623338630283773

Epoch: 6| Step: 3
Training loss: 2.841375344595809
Validation loss: 2.458712542489236

Epoch: 6| Step: 4
Training loss: 2.2001714726293877
Validation loss: 2.4298661309465004

Epoch: 6| Step: 5
Training loss: 2.1870213666167806
Validation loss: 2.435144661628511

Epoch: 6| Step: 6
Training loss: 2.3404780628241393
Validation loss: 2.4347805200979247

Epoch: 6| Step: 7
Training loss: 2.695435009812027
Validation loss: 2.4658395837570692

Epoch: 6| Step: 8
Training loss: 1.913042879033843
Validation loss: 2.4407958158224963

Epoch: 6| Step: 9
Training loss: 2.3377621264028456
Validation loss: 2.4354217205309037

Epoch: 6| Step: 10
Training loss: 2.0884998599566775
Validation loss: 2.460625481085162

Epoch: 6| Step: 11
Training loss: 2.2327445957544283
Validation loss: 2.444623304661696

Epoch: 6| Step: 12
Training loss: 2.5337684253536454
Validation loss: 2.4571344755729405

Epoch: 6| Step: 13
Training loss: 2.3590961822073973
Validation loss: 2.4238740121217024

Epoch: 133| Step: 0
Training loss: 2.4614493670295547
Validation loss: 2.4435516174510568

Epoch: 6| Step: 1
Training loss: 2.435224987500353
Validation loss: 2.447922953796342

Epoch: 6| Step: 2
Training loss: 1.7538758001254322
Validation loss: 2.4430597915983774

Epoch: 6| Step: 3
Training loss: 2.4354652323801145
Validation loss: 2.4454833176162265

Epoch: 6| Step: 4
Training loss: 2.0858925803844923
Validation loss: 2.4632067615423385

Epoch: 6| Step: 5
Training loss: 2.772003920867481
Validation loss: 2.4268385913254997

Epoch: 6| Step: 6
Training loss: 2.449877587977701
Validation loss: 2.441267976647578

Epoch: 6| Step: 7
Training loss: 2.6248589432373906
Validation loss: 2.42600508703044

Epoch: 6| Step: 8
Training loss: 1.9297741704465654
Validation loss: 2.441133202557096

Epoch: 6| Step: 9
Training loss: 2.4766619448747287
Validation loss: 2.4321343890028677

Epoch: 6| Step: 10
Training loss: 2.5805454798258656
Validation loss: 2.4426335509334023

Epoch: 6| Step: 11
Training loss: 2.182485445898235
Validation loss: 2.4438350716709283

Epoch: 6| Step: 12
Training loss: 3.132450986632478
Validation loss: 2.448341169097716

Epoch: 6| Step: 13
Training loss: 1.9349955091991111
Validation loss: 2.4471879120886553

Epoch: 134| Step: 0
Training loss: 2.1151191771637734
Validation loss: 2.4555136021686086

Epoch: 6| Step: 1
Training loss: 2.628482325299453
Validation loss: 2.448252159348446

Epoch: 6| Step: 2
Training loss: 2.7952066912170834
Validation loss: 2.4737023199198696

Epoch: 6| Step: 3
Training loss: 1.6841394376496197
Validation loss: 2.4402099944339932

Epoch: 6| Step: 4
Training loss: 2.8548127345785255
Validation loss: 2.4211972106247273

Epoch: 6| Step: 5
Training loss: 2.2483107265337847
Validation loss: 2.450386109480878

Epoch: 6| Step: 6
Training loss: 1.859966985245438
Validation loss: 2.443021498181415

Epoch: 6| Step: 7
Training loss: 2.7228520458427052
Validation loss: 2.45757370884205

Epoch: 6| Step: 8
Training loss: 2.864221519971231
Validation loss: 2.4430801553254553

Epoch: 6| Step: 9
Training loss: 2.635408202950579
Validation loss: 2.4367287922148684

Epoch: 6| Step: 10
Training loss: 2.329603915950607
Validation loss: 2.438975205126856

Epoch: 6| Step: 11
Training loss: 2.527863485911722
Validation loss: 2.423996873429313

Epoch: 6| Step: 12
Training loss: 2.0771057382776257
Validation loss: 2.4430557085488824

Epoch: 6| Step: 13
Training loss: 1.9124960581420967
Validation loss: 2.446800264486946

Epoch: 135| Step: 0
Training loss: 2.52416528180566
Validation loss: 2.4591717744123307

Epoch: 6| Step: 1
Training loss: 2.22558754439252
Validation loss: 2.4308861854403574

Epoch: 6| Step: 2
Training loss: 2.2276270412947095
Validation loss: 2.43130638545808

Epoch: 6| Step: 3
Training loss: 2.385526318646593
Validation loss: 2.4460144220222695

Epoch: 6| Step: 4
Training loss: 2.729754484126662
Validation loss: 2.45256148612396

Epoch: 6| Step: 5
Training loss: 2.887368176906726
Validation loss: 2.45103181253261

Epoch: 6| Step: 6
Training loss: 2.1658630592544097
Validation loss: 2.4415583065467015

Epoch: 6| Step: 7
Training loss: 1.549256774158697
Validation loss: 2.4624783589676182

Epoch: 6| Step: 8
Training loss: 2.6487460786539296
Validation loss: 2.4554295632706937

Epoch: 6| Step: 9
Training loss: 2.0001829778892333
Validation loss: 2.4418879418121873

Epoch: 6| Step: 10
Training loss: 2.87603691309769
Validation loss: 2.459456873399504

Epoch: 6| Step: 11
Training loss: 2.021040863182706
Validation loss: 2.462078965116695

Epoch: 6| Step: 12
Training loss: 2.5110730042656
Validation loss: 2.4558150407649695

Epoch: 6| Step: 13
Training loss: 2.4349078553798855
Validation loss: 2.4461984196903237

Epoch: 136| Step: 0
Training loss: 2.4425858478433207
Validation loss: 2.4500858440013564

Epoch: 6| Step: 1
Training loss: 2.1676458444773856
Validation loss: 2.4420563272619127

Epoch: 6| Step: 2
Training loss: 2.244266410204168
Validation loss: 2.4328216522002704

Epoch: 6| Step: 3
Training loss: 2.4245696796986196
Validation loss: 2.429998542452335

Epoch: 6| Step: 4
Training loss: 2.4581113057709243
Validation loss: 2.451545910940016

Epoch: 6| Step: 5
Training loss: 1.9410682552861678
Validation loss: 2.4520837316389805

Epoch: 6| Step: 6
Training loss: 2.2888632417474417
Validation loss: 2.4489147109238245

Epoch: 6| Step: 7
Training loss: 2.358197253000185
Validation loss: 2.4467174880346887

Epoch: 6| Step: 8
Training loss: 2.5726118846766775
Validation loss: 2.422930711980202

Epoch: 6| Step: 9
Training loss: 2.346460631421719
Validation loss: 2.4538956928486737

Epoch: 6| Step: 10
Training loss: 2.5519773707806586
Validation loss: 2.4615829228217407

Epoch: 6| Step: 11
Training loss: 2.023134422433505
Validation loss: 2.4499726370747754

Epoch: 6| Step: 12
Training loss: 3.1448542269110833
Validation loss: 2.4438018184459724

Epoch: 6| Step: 13
Training loss: 2.1905074018620216
Validation loss: 2.438065399401153

Epoch: 137| Step: 0
Training loss: 2.095019738370643
Validation loss: 2.4463151044472404

Epoch: 6| Step: 1
Training loss: 2.914248054058037
Validation loss: 2.465939703810261

Epoch: 6| Step: 2
Training loss: 2.4084763569145546
Validation loss: 2.4467254952156465

Epoch: 6| Step: 3
Training loss: 1.890235419370643
Validation loss: 2.4612056900515817

Epoch: 6| Step: 4
Training loss: 2.204549558826977
Validation loss: 2.453670633578655

Epoch: 6| Step: 5
Training loss: 2.5053912206394098
Validation loss: 2.4437833364270265

Epoch: 6| Step: 6
Training loss: 2.6567798759178434
Validation loss: 2.445194404426634

Epoch: 6| Step: 7
Training loss: 2.140986725254233
Validation loss: 2.4305447446833686

Epoch: 6| Step: 8
Training loss: 2.394702899001733
Validation loss: 2.428096314971083

Epoch: 6| Step: 9
Training loss: 2.0435552101750742
Validation loss: 2.459206649335092

Epoch: 6| Step: 10
Training loss: 2.6611036050576056
Validation loss: 2.454458181280453

Epoch: 6| Step: 11
Training loss: 2.460361861464562
Validation loss: 2.43427001814377

Epoch: 6| Step: 12
Training loss: 2.8452139638883356
Validation loss: 2.4323830599350047

Epoch: 6| Step: 13
Training loss: 1.2301503571822572
Validation loss: 2.440608173488983

Epoch: 138| Step: 0
Training loss: 1.5796720268178426
Validation loss: 2.43867022954935

Epoch: 6| Step: 1
Training loss: 2.5416921291222394
Validation loss: 2.4197571692354085

Epoch: 6| Step: 2
Training loss: 2.859244922118111
Validation loss: 2.4532552130288465

Epoch: 6| Step: 3
Training loss: 2.7551186348075856
Validation loss: 2.426482388751378

Epoch: 6| Step: 4
Training loss: 1.7953911002991652
Validation loss: 2.438125410218638

Epoch: 6| Step: 5
Training loss: 2.6337777470963366
Validation loss: 2.434256285087069

Epoch: 6| Step: 6
Training loss: 1.8084053617040594
Validation loss: 2.4348943775579106

Epoch: 6| Step: 7
Training loss: 2.4133493302097864
Validation loss: 2.438040290357736

Epoch: 6| Step: 8
Training loss: 2.8681668887775484
Validation loss: 2.435323733917911

Epoch: 6| Step: 9
Training loss: 2.7375122383575694
Validation loss: 2.4640442181839144

Epoch: 6| Step: 10
Training loss: 1.6913352052775725
Validation loss: 2.438502412435491

Epoch: 6| Step: 11
Training loss: 2.289965246511552
Validation loss: 2.4527009370551345

Epoch: 6| Step: 12
Training loss: 2.48550581237936
Validation loss: 2.435611042355308

Epoch: 6| Step: 13
Training loss: 2.298553268867567
Validation loss: 2.429762417425954

Epoch: 139| Step: 0
Training loss: 1.8081235995453713
Validation loss: 2.424741065195253

Epoch: 6| Step: 1
Training loss: 2.6846408272727955
Validation loss: 2.4395085376949193

Epoch: 6| Step: 2
Training loss: 2.186343295951362
Validation loss: 2.4420276888861983

Epoch: 6| Step: 3
Training loss: 2.3363986883715224
Validation loss: 2.4597583087038215

Epoch: 6| Step: 4
Training loss: 2.25558234821603
Validation loss: 2.4453511475354666

Epoch: 6| Step: 5
Training loss: 1.8396524058500767
Validation loss: 2.426165096553974

Epoch: 6| Step: 6
Training loss: 2.310415204537574
Validation loss: 2.425709173060299

Epoch: 6| Step: 7
Training loss: 2.8664446707828115
Validation loss: 2.431952986225092

Epoch: 6| Step: 8
Training loss: 2.3362508200066903
Validation loss: 2.4532866368869968

Epoch: 6| Step: 9
Training loss: 2.66566253671457
Validation loss: 2.4355777999985975

Epoch: 6| Step: 10
Training loss: 1.9375990565419754
Validation loss: 2.4614070810880904

Epoch: 6| Step: 11
Training loss: 2.5792467855685075
Validation loss: 2.432046633958728

Epoch: 6| Step: 12
Training loss: 2.9401241512424674
Validation loss: 2.4302255302327698

Epoch: 6| Step: 13
Training loss: 2.200937903492349
Validation loss: 2.4504229465768526

Epoch: 140| Step: 0
Training loss: 2.3164183952437716
Validation loss: 2.446204161730889

Epoch: 6| Step: 1
Training loss: 1.8703089204911705
Validation loss: 2.441403087195532

Epoch: 6| Step: 2
Training loss: 2.568876474056069
Validation loss: 2.4392624234711433

Epoch: 6| Step: 3
Training loss: 3.0360283697157295
Validation loss: 2.440411008712071

Epoch: 6| Step: 4
Training loss: 2.8182331567154537
Validation loss: 2.4469133243030297

Epoch: 6| Step: 5
Training loss: 2.1782678062002763
Validation loss: 2.449406284278737

Epoch: 6| Step: 6
Training loss: 2.6074025814185533
Validation loss: 2.450820654651741

Epoch: 6| Step: 7
Training loss: 1.660047173002143
Validation loss: 2.4474576381365094

Epoch: 6| Step: 8
Training loss: 1.6403149266369472
Validation loss: 2.4323861111546528

Epoch: 6| Step: 9
Training loss: 2.5907551584344266
Validation loss: 2.4432319628943078

Epoch: 6| Step: 10
Training loss: 2.3622784465264335
Validation loss: 2.4522642359345523

Epoch: 6| Step: 11
Training loss: 2.107247756397439
Validation loss: 2.445161623668894

Epoch: 6| Step: 12
Training loss: 2.620809661887714
Validation loss: 2.4272736787171794

Epoch: 6| Step: 13
Training loss: 2.2591876953489636
Validation loss: 2.4632917184284215

Epoch: 141| Step: 0
Training loss: 1.9586139910716784
Validation loss: 2.449208571695862

Epoch: 6| Step: 1
Training loss: 2.330217892850714
Validation loss: 2.464413640475776

Epoch: 6| Step: 2
Training loss: 2.5211027227383322
Validation loss: 2.4412745386178516

Epoch: 6| Step: 3
Training loss: 2.5971776535734308
Validation loss: 2.4456497091449645

Epoch: 6| Step: 4
Training loss: 2.1652558819953316
Validation loss: 2.455012672966698

Epoch: 6| Step: 5
Training loss: 2.8443983407887057
Validation loss: 2.4355642816753256

Epoch: 6| Step: 6
Training loss: 1.6558588393764615
Validation loss: 2.4774670457583814

Epoch: 6| Step: 7
Training loss: 2.214118098581865
Validation loss: 2.443479389026201

Epoch: 6| Step: 8
Training loss: 2.508368409715252
Validation loss: 2.448831109289511

Epoch: 6| Step: 9
Training loss: 1.9587173355972125
Validation loss: 2.4452402832245546

Epoch: 6| Step: 10
Training loss: 2.9130811905446574
Validation loss: 2.4349021814586114

Epoch: 6| Step: 11
Training loss: 2.34288191931779
Validation loss: 2.4756546134279485

Epoch: 6| Step: 12
Training loss: 2.4370134308154925
Validation loss: 2.464898046904337

Epoch: 6| Step: 13
Training loss: 2.1977106754142115
Validation loss: 2.4482620589045334

Epoch: 142| Step: 0
Training loss: 2.200369660792141
Validation loss: 2.4613559609976225

Epoch: 6| Step: 1
Training loss: 2.6909455678843464
Validation loss: 2.4364757084267845

Epoch: 6| Step: 2
Training loss: 2.4204307926199404
Validation loss: 2.4820341945741

Epoch: 6| Step: 3
Training loss: 2.3067270338652226
Validation loss: 2.43339712940365

Epoch: 6| Step: 4
Training loss: 2.2258220311369086
Validation loss: 2.469913660655863

Epoch: 6| Step: 5
Training loss: 1.8007055171507278
Validation loss: 2.4384020074298176

Epoch: 6| Step: 6
Training loss: 2.0479016241049566
Validation loss: 2.438331180419851

Epoch: 6| Step: 7
Training loss: 1.8231108934381774
Validation loss: 2.456136679052923

Epoch: 6| Step: 8
Training loss: 1.9349310671925724
Validation loss: 2.4611381140378583

Epoch: 6| Step: 9
Training loss: 2.828409001543268
Validation loss: 2.4310672692078388

Epoch: 6| Step: 10
Training loss: 2.027106298752399
Validation loss: 2.4433915441132554

Epoch: 6| Step: 11
Training loss: 2.3528003159601596
Validation loss: 2.4427197407531915

Epoch: 6| Step: 12
Training loss: 3.1774309478868092
Validation loss: 2.4385225408802196

Epoch: 6| Step: 13
Training loss: 2.8986054651993087
Validation loss: 2.4365088732979125

Epoch: 143| Step: 0
Training loss: 2.8555574207654404
Validation loss: 2.441194905901899

Epoch: 6| Step: 1
Training loss: 1.9430303093729882
Validation loss: 2.448992430801394

Epoch: 6| Step: 2
Training loss: 2.2783815299654373
Validation loss: 2.4497703709160694

Epoch: 6| Step: 3
Training loss: 2.1989039031399575
Validation loss: 2.4357615556519776

Epoch: 6| Step: 4
Training loss: 1.9492586242633727
Validation loss: 2.443282611237456

Epoch: 6| Step: 5
Training loss: 2.3549984388083045
Validation loss: 2.4366318887208025

Epoch: 6| Step: 6
Training loss: 1.9212135479260548
Validation loss: 2.4451943257936017

Epoch: 6| Step: 7
Training loss: 2.7357435888636914
Validation loss: 2.4074730962835136

Epoch: 6| Step: 8
Training loss: 2.655678451980533
Validation loss: 2.450850779186875

Epoch: 6| Step: 9
Training loss: 2.32316809235827
Validation loss: 2.453425459876954

Epoch: 6| Step: 10
Training loss: 2.4868846189624936
Validation loss: 2.4558327103803066

Epoch: 6| Step: 11
Training loss: 2.390665290842052
Validation loss: 2.4382311000905883

Epoch: 6| Step: 12
Training loss: 1.8078536626536088
Validation loss: 2.455322234171013

Epoch: 6| Step: 13
Training loss: 2.8318946963307017
Validation loss: 2.4387326926943267

Epoch: 144| Step: 0
Training loss: 3.057656330843744
Validation loss: 2.440238785988458

Epoch: 6| Step: 1
Training loss: 2.026596607871225
Validation loss: 2.4464902584207184

Epoch: 6| Step: 2
Training loss: 2.495453706208372
Validation loss: 2.4532902765569706

Epoch: 6| Step: 3
Training loss: 2.626454994593101
Validation loss: 2.427766431194357

Epoch: 6| Step: 4
Training loss: 2.193787068545605
Validation loss: 2.4510884957357395

Epoch: 6| Step: 5
Training loss: 2.622709364775071
Validation loss: 2.4490633964643966

Epoch: 6| Step: 6
Training loss: 2.0056140307598715
Validation loss: 2.457858153029255

Epoch: 6| Step: 7
Training loss: 2.594450890394431
Validation loss: 2.4277868376660967

Epoch: 6| Step: 8
Training loss: 1.9929190096747347
Validation loss: 2.418741393953041

Epoch: 6| Step: 9
Training loss: 2.3101375988029007
Validation loss: 2.4428542182113206

Epoch: 6| Step: 10
Training loss: 2.4545245217866043
Validation loss: 2.45586725170231

Epoch: 6| Step: 11
Training loss: 2.0506802197956375
Validation loss: 2.4429438811287985

Epoch: 6| Step: 12
Training loss: 2.3864772942959642
Validation loss: 2.4466699263904244

Epoch: 6| Step: 13
Training loss: 1.6306813034332304
Validation loss: 2.4409440464699195

Epoch: 145| Step: 0
Training loss: 2.804905959948182
Validation loss: 2.4418180274799512

Epoch: 6| Step: 1
Training loss: 1.9748985312749077
Validation loss: 2.4488587185897552

Epoch: 6| Step: 2
Training loss: 2.2134472516437627
Validation loss: 2.468306835394294

Epoch: 6| Step: 3
Training loss: 2.5402207769727734
Validation loss: 2.431054204563525

Epoch: 6| Step: 4
Training loss: 2.3055658250858313
Validation loss: 2.4297321303478934

Epoch: 6| Step: 5
Training loss: 1.9342247135777026
Validation loss: 2.4560184494760695

Epoch: 6| Step: 6
Training loss: 2.6388558324338445
Validation loss: 2.4464667584370914

Epoch: 6| Step: 7
Training loss: 2.556829645150429
Validation loss: 2.4677773477194553

Epoch: 6| Step: 8
Training loss: 2.099050616057062
Validation loss: 2.457872823843231

Epoch: 6| Step: 9
Training loss: 1.8170760693747885
Validation loss: 2.450434225145847

Epoch: 6| Step: 10
Training loss: 3.289283436945569
Validation loss: 2.455951803810394

Epoch: 6| Step: 11
Training loss: 1.8681824399579623
Validation loss: 2.4603464943387916

Epoch: 6| Step: 12
Training loss: 2.267947460131139
Validation loss: 2.442295550608384

Epoch: 6| Step: 13
Training loss: 1.8745989052602765
Validation loss: 2.4462526777151785

Epoch: 146| Step: 0
Training loss: 1.7317942758756562
Validation loss: 2.4388693188739645

Epoch: 6| Step: 1
Training loss: 1.833348823250732
Validation loss: 2.4587281257544764

Epoch: 6| Step: 2
Training loss: 2.6434359965966694
Validation loss: 2.438038678381753

Epoch: 6| Step: 3
Training loss: 2.426573594774771
Validation loss: 2.4317262883109985

Epoch: 6| Step: 4
Training loss: 2.397835422954664
Validation loss: 2.424425424144696

Epoch: 6| Step: 5
Training loss: 2.2158844401804636
Validation loss: 2.447883838406385

Epoch: 6| Step: 6
Training loss: 2.1304639244794314
Validation loss: 2.4421182613249357

Epoch: 6| Step: 7
Training loss: 2.695757931377549
Validation loss: 2.4412578919977084

Epoch: 6| Step: 8
Training loss: 1.9896848030245804
Validation loss: 2.433705864845778

Epoch: 6| Step: 9
Training loss: 2.2409788057209354
Validation loss: 2.455903978399973

Epoch: 6| Step: 10
Training loss: 2.2898869510715465
Validation loss: 2.452540209654459

Epoch: 6| Step: 11
Training loss: 2.5442577558250994
Validation loss: 2.4328000234228804

Epoch: 6| Step: 12
Training loss: 2.892529659135666
Validation loss: 2.4402884096632715

Epoch: 6| Step: 13
Training loss: 2.3839799866252314
Validation loss: 2.4524253337047104

Epoch: 147| Step: 0
Training loss: 2.031578272189259
Validation loss: 2.422561274114159

Epoch: 6| Step: 1
Training loss: 3.058351782414835
Validation loss: 2.442479420131026

Epoch: 6| Step: 2
Training loss: 2.4832174615474636
Validation loss: 2.4530127067042335

Epoch: 6| Step: 3
Training loss: 2.1581372833565236
Validation loss: 2.4197585719626162

Epoch: 6| Step: 4
Training loss: 2.2665255105253195
Validation loss: 2.443684930802935

Epoch: 6| Step: 5
Training loss: 2.209012436962561
Validation loss: 2.453953953732537

Epoch: 6| Step: 6
Training loss: 2.4270128449994823
Validation loss: 2.4489053018389777

Epoch: 6| Step: 7
Training loss: 1.732419879486414
Validation loss: 2.440622230042822

Epoch: 6| Step: 8
Training loss: 2.4882785671345427
Validation loss: 2.441012774911946

Epoch: 6| Step: 9
Training loss: 2.05849541966742
Validation loss: 2.414520548362435

Epoch: 6| Step: 10
Training loss: 1.9249257630735053
Validation loss: 2.429766959624212

Epoch: 6| Step: 11
Training loss: 2.300905389464567
Validation loss: 2.4514223633676746

Epoch: 6| Step: 12
Training loss: 2.787733258122955
Validation loss: 2.45490607961995

Epoch: 6| Step: 13
Training loss: 1.5409381880842787
Validation loss: 2.431425863067162

Epoch: 148| Step: 0
Training loss: 2.5532545451399535
Validation loss: 2.4345898258547742

Epoch: 6| Step: 1
Training loss: 1.928680836889325
Validation loss: 2.4414529659929

Epoch: 6| Step: 2
Training loss: 1.9882977378176578
Validation loss: 2.482382616964653

Epoch: 6| Step: 3
Training loss: 2.3414533425178448
Validation loss: 2.453625731045054

Epoch: 6| Step: 4
Training loss: 1.769641190707217
Validation loss: 2.451867052690799

Epoch: 6| Step: 5
Training loss: 1.964535091720729
Validation loss: 2.461386807533642

Epoch: 6| Step: 6
Training loss: 3.0243842641109535
Validation loss: 2.4289375189356868

Epoch: 6| Step: 7
Training loss: 2.500520651961065
Validation loss: 2.4407597377767907

Epoch: 6| Step: 8
Training loss: 2.2556253683418106
Validation loss: 2.431188739937282

Epoch: 6| Step: 9
Training loss: 2.144355363703107
Validation loss: 2.4321536552235803

Epoch: 6| Step: 10
Training loss: 2.4955521116783057
Validation loss: 2.4338511008274724

Epoch: 6| Step: 11
Training loss: 2.392436618902132
Validation loss: 2.399947668730448

Epoch: 6| Step: 12
Training loss: 3.0800361703012142
Validation loss: 2.4463727038483922

Epoch: 6| Step: 13
Training loss: 1.2058485835722892
Validation loss: 2.4453867793845747

Epoch: 149| Step: 0
Training loss: 2.0534415873357825
Validation loss: 2.465662749560471

Epoch: 6| Step: 1
Training loss: 2.2873343235741235
Validation loss: 2.4496691509914483

Epoch: 6| Step: 2
Training loss: 2.6639243171182594
Validation loss: 2.444869059584897

Epoch: 6| Step: 3
Training loss: 1.925766145906159
Validation loss: 2.4528782771876285

Epoch: 6| Step: 4
Training loss: 2.4927063404866496
Validation loss: 2.4415461632455977

Epoch: 6| Step: 5
Training loss: 2.424993660515433
Validation loss: 2.4497216697751822

Epoch: 6| Step: 6
Training loss: 1.908245980319369
Validation loss: 2.4644029122104443

Epoch: 6| Step: 7
Training loss: 1.937411275493393
Validation loss: 2.4913051865551674

Epoch: 6| Step: 8
Training loss: 1.955604017565122
Validation loss: 2.4832277348060843

Epoch: 6| Step: 9
Training loss: 3.010143298416531
Validation loss: 2.466033602075032

Epoch: 6| Step: 10
Training loss: 3.1510808937006076
Validation loss: 2.4431174047875

Epoch: 6| Step: 11
Training loss: 2.1026271689984184
Validation loss: 2.4657725131855055

Epoch: 6| Step: 12
Training loss: 2.364170985181502
Validation loss: 2.468655811993385

Epoch: 6| Step: 13
Training loss: 1.5422374682462245
Validation loss: 2.4634241758026763

Epoch: 150| Step: 0
Training loss: 1.837439778697015
Validation loss: 2.463873474160676

Epoch: 6| Step: 1
Training loss: 2.7206358233779224
Validation loss: 2.4243055042437724

Epoch: 6| Step: 2
Training loss: 2.3467267270241217
Validation loss: 2.4355526116274295

Epoch: 6| Step: 3
Training loss: 3.06585105194781
Validation loss: 2.414529271764448

Epoch: 6| Step: 4
Training loss: 2.544990638161099
Validation loss: 2.419887849278072

Epoch: 6| Step: 5
Training loss: 2.7223683099624654
Validation loss: 2.459901209252452

Epoch: 6| Step: 6
Training loss: 1.6688144514231678
Validation loss: 2.445279222833545

Epoch: 6| Step: 7
Training loss: 2.3647897997103176
Validation loss: 2.446058680321151

Epoch: 6| Step: 8
Training loss: 2.3935629549977064
Validation loss: 2.434259407679236

Epoch: 6| Step: 9
Training loss: 2.0279018097079784
Validation loss: 2.4192416214515773

Epoch: 6| Step: 10
Training loss: 2.6518039968795226
Validation loss: 2.4624918221966245

Epoch: 6| Step: 11
Training loss: 1.7589763941913108
Validation loss: 2.4404114740815066

Epoch: 6| Step: 12
Training loss: 1.7481407097719879
Validation loss: 2.446130067517045

Epoch: 6| Step: 13
Training loss: 2.3733028572068857
Validation loss: 2.440931904314041

Epoch: 151| Step: 0
Training loss: 1.7297398946075175
Validation loss: 2.43149309873404

Epoch: 6| Step: 1
Training loss: 2.4487093893191663
Validation loss: 2.425716989601458

Epoch: 6| Step: 2
Training loss: 2.31607758375943
Validation loss: 2.4088238940322517

Epoch: 6| Step: 3
Training loss: 2.9092422995947698
Validation loss: 2.456522449983788

Epoch: 6| Step: 4
Training loss: 3.0642033725006623
Validation loss: 2.4037799844209156

Epoch: 6| Step: 5
Training loss: 2.649685096024292
Validation loss: 2.452369384936893

Epoch: 6| Step: 6
Training loss: 1.9482868543203615
Validation loss: 2.4330626506870936

Epoch: 6| Step: 7
Training loss: 2.1155852276037304
Validation loss: 2.4389231019075344

Epoch: 6| Step: 8
Training loss: 2.1530455952523617
Validation loss: 2.432948790749391

Epoch: 6| Step: 9
Training loss: 1.8908985034689574
Validation loss: 2.419658020106687

Epoch: 6| Step: 10
Training loss: 2.3328545169917327
Validation loss: 2.4287453336073805

Epoch: 6| Step: 11
Training loss: 2.1122148400332157
Validation loss: 2.407058396776629

Epoch: 6| Step: 12
Training loss: 2.270791312945926
Validation loss: 2.412714518291283

Epoch: 6| Step: 13
Training loss: 2.062206247391615
Validation loss: 2.4317840234736288

Epoch: 152| Step: 0
Training loss: 2.0355391773641274
Validation loss: 2.4321972887808503

Epoch: 6| Step: 1
Training loss: 2.6130395615010276
Validation loss: 2.4556576632035583

Epoch: 6| Step: 2
Training loss: 2.319288650833749
Validation loss: 2.449066192423145

Epoch: 6| Step: 3
Training loss: 1.8720066336326766
Validation loss: 2.4377705518805683

Epoch: 6| Step: 4
Training loss: 2.347727135018141
Validation loss: 2.4368201160315506

Epoch: 6| Step: 5
Training loss: 1.9129700949365895
Validation loss: 2.440401887243122

Epoch: 6| Step: 6
Training loss: 2.5027269749407726
Validation loss: 2.4253015926256345

Epoch: 6| Step: 7
Training loss: 3.0415637551930907
Validation loss: 2.4491511394766365

Epoch: 6| Step: 8
Training loss: 2.8944286168650697
Validation loss: 2.4435289348249176

Epoch: 6| Step: 9
Training loss: 2.2327914728839002
Validation loss: 2.4465723735089044

Epoch: 6| Step: 10
Training loss: 2.107508759214541
Validation loss: 2.4437498149877523

Epoch: 6| Step: 11
Training loss: 1.9772423340266212
Validation loss: 2.4217079171121663

Epoch: 6| Step: 12
Training loss: 1.6380566793703177
Validation loss: 2.4160021330418524

Epoch: 6| Step: 13
Training loss: 2.666113100610434
Validation loss: 2.4313309071416978

Epoch: 153| Step: 0
Training loss: 1.9307455644785043
Validation loss: 2.4560963892184815

Epoch: 6| Step: 1
Training loss: 2.389888076396088
Validation loss: 2.4266574709052167

Epoch: 6| Step: 2
Training loss: 2.1391298961958976
Validation loss: 2.4292651678796116

Epoch: 6| Step: 3
Training loss: 1.7169453249687028
Validation loss: 2.4430524807208074

Epoch: 6| Step: 4
Training loss: 2.2852590162856576
Validation loss: 2.4379220546645257

Epoch: 6| Step: 5
Training loss: 2.1121730754623322
Validation loss: 2.4376759135649086

Epoch: 6| Step: 6
Training loss: 2.5582293767859223
Validation loss: 2.469275010487892

Epoch: 6| Step: 7
Training loss: 2.6338485354624264
Validation loss: 2.446974284719007

Epoch: 6| Step: 8
Training loss: 2.3146565665795253
Validation loss: 2.465823899360614

Epoch: 6| Step: 9
Training loss: 2.813496222488582
Validation loss: 2.4419040266652807

Epoch: 6| Step: 10
Training loss: 2.3665834165983894
Validation loss: 2.44921504775667

Epoch: 6| Step: 11
Training loss: 2.1686620205230307
Validation loss: 2.4524940236779904

Epoch: 6| Step: 12
Training loss: 2.4983773687688022
Validation loss: 2.436780271664321

Epoch: 6| Step: 13
Training loss: 1.9979980701441031
Validation loss: 2.4335937310381124

Epoch: 154| Step: 0
Training loss: 2.227380649096431
Validation loss: 2.458005649368951

Epoch: 6| Step: 1
Training loss: 2.3568444228230963
Validation loss: 2.4160022667415317

Epoch: 6| Step: 2
Training loss: 2.0150021322537257
Validation loss: 2.4549820215031275

Epoch: 6| Step: 3
Training loss: 2.3578083824490843
Validation loss: 2.4304045725706978

Epoch: 6| Step: 4
Training loss: 2.186317996433904
Validation loss: 2.4435971520300557

Epoch: 6| Step: 5
Training loss: 2.1587768344503497
Validation loss: 2.4478630375971226

Epoch: 6| Step: 6
Training loss: 2.575108468447024
Validation loss: 2.441003955010152

Epoch: 6| Step: 7
Training loss: 2.0222820974691897
Validation loss: 2.4129036477021493

Epoch: 6| Step: 8
Training loss: 2.324308608425772
Validation loss: 2.4274623042801196

Epoch: 6| Step: 9
Training loss: 2.3092426349868935
Validation loss: 2.4430544587629

Epoch: 6| Step: 10
Training loss: 2.6207809147851338
Validation loss: 2.43161576115811

Epoch: 6| Step: 11
Training loss: 2.1340762017184884
Validation loss: 2.439263117649999

Epoch: 6| Step: 12
Training loss: 2.610571124557711
Validation loss: 2.4158943209417014

Epoch: 6| Step: 13
Training loss: 2.249106017636909
Validation loss: 2.4279168648371092

Epoch: 155| Step: 0
Training loss: 2.569232563069129
Validation loss: 2.4079491590721265

Epoch: 6| Step: 1
Training loss: 2.76070246146692
Validation loss: 2.42327564503215

Epoch: 6| Step: 2
Training loss: 2.6976878438602525
Validation loss: 2.4441895760684687

Epoch: 6| Step: 3
Training loss: 1.7363612855162722
Validation loss: 2.430239352525105

Epoch: 6| Step: 4
Training loss: 1.767176663663173
Validation loss: 2.4493059327063387

Epoch: 6| Step: 5
Training loss: 2.61361587275136
Validation loss: 2.4216296158670794

Epoch: 6| Step: 6
Training loss: 1.9246318861502527
Validation loss: 2.4249244516214588

Epoch: 6| Step: 7
Training loss: 2.817270429409345
Validation loss: 2.4162947101860754

Epoch: 6| Step: 8
Training loss: 2.653365060753963
Validation loss: 2.418454177113501

Epoch: 6| Step: 9
Training loss: 2.3397468457669968
Validation loss: 2.4354546092279645

Epoch: 6| Step: 10
Training loss: 2.210166769855553
Validation loss: 2.443372255286794

Epoch: 6| Step: 11
Training loss: 1.679192332536222
Validation loss: 2.4402970062841813

Epoch: 6| Step: 12
Training loss: 2.1160270635680543
Validation loss: 2.444998227064762

Epoch: 6| Step: 13
Training loss: 1.7773672249050696
Validation loss: 2.4361171223087688

Epoch: 156| Step: 0
Training loss: 2.526648778155907
Validation loss: 2.4632603420674575

Epoch: 6| Step: 1
Training loss: 2.6905643824041485
Validation loss: 2.420869232197346

Epoch: 6| Step: 2
Training loss: 2.308201687176951
Validation loss: 2.4356933579172457

Epoch: 6| Step: 3
Training loss: 2.0849275465710275
Validation loss: 2.4292077358882067

Epoch: 6| Step: 4
Training loss: 1.902164897304991
Validation loss: 2.453215556174438

Epoch: 6| Step: 5
Training loss: 2.2296910842620763
Validation loss: 2.442430212014879

Epoch: 6| Step: 6
Training loss: 2.063029134673152
Validation loss: 2.4350478861783316

Epoch: 6| Step: 7
Training loss: 2.417960565950659
Validation loss: 2.437876595222198

Epoch: 6| Step: 8
Training loss: 1.8216435228129961
Validation loss: 2.4331968147689715

Epoch: 6| Step: 9
Training loss: 2.3611344604334974
Validation loss: 2.443736542242235

Epoch: 6| Step: 10
Training loss: 2.6737155932423633
Validation loss: 2.4418223813704203

Epoch: 6| Step: 11
Training loss: 2.359626503985698
Validation loss: 2.4498516702316

Epoch: 6| Step: 12
Training loss: 2.3446129799579616
Validation loss: 2.449833641448166

Epoch: 6| Step: 13
Training loss: 2.0788358462116205
Validation loss: 2.4140469018639514

Epoch: 157| Step: 0
Training loss: 1.9053289971396825
Validation loss: 2.4261059902921756

Epoch: 6| Step: 1
Training loss: 2.5748806972087848
Validation loss: 2.41221277305026

Epoch: 6| Step: 2
Training loss: 2.159606974130905
Validation loss: 2.421020430081953

Epoch: 6| Step: 3
Training loss: 2.304971140848415
Validation loss: 2.4212806356049654

Epoch: 6| Step: 4
Training loss: 2.2315970271182186
Validation loss: 2.422491366060332

Epoch: 6| Step: 5
Training loss: 2.874368515322529
Validation loss: 2.45233855251308

Epoch: 6| Step: 6
Training loss: 1.768381313544331
Validation loss: 2.409044317818191

Epoch: 6| Step: 7
Training loss: 2.3112292535654313
Validation loss: 2.4331889516644085

Epoch: 6| Step: 8
Training loss: 2.3688125320273126
Validation loss: 2.3899375682648025

Epoch: 6| Step: 9
Training loss: 2.3809119477698975
Validation loss: 2.4764696774540247

Epoch: 6| Step: 10
Training loss: 1.9809310945237901
Validation loss: 2.4464905256313987

Epoch: 6| Step: 11
Training loss: 2.272664361429803
Validation loss: 2.43287785977789

Epoch: 6| Step: 12
Training loss: 2.1617741243020636
Validation loss: 2.458610065631988

Epoch: 6| Step: 13
Training loss: 2.676773310619581
Validation loss: 2.449957503008186

Epoch: 158| Step: 0
Training loss: 2.127107809027456
Validation loss: 2.42887414632199

Epoch: 6| Step: 1
Training loss: 1.9927623443010603
Validation loss: 2.4424654183491397

Epoch: 6| Step: 2
Training loss: 2.36050125423916
Validation loss: 2.4391278042161626

Epoch: 6| Step: 3
Training loss: 2.7553997778527557
Validation loss: 2.4448609818360367

Epoch: 6| Step: 4
Training loss: 2.001878809596262
Validation loss: 2.4221895636162265

Epoch: 6| Step: 5
Training loss: 3.0890291203502875
Validation loss: 2.439694561776634

Epoch: 6| Step: 6
Training loss: 1.792242031714506
Validation loss: 2.4476205050139717

Epoch: 6| Step: 7
Training loss: 2.2080462527060787
Validation loss: 2.4144116114823073

Epoch: 6| Step: 8
Training loss: 2.168430918326081
Validation loss: 2.4240826027473146

Epoch: 6| Step: 9
Training loss: 2.5824313178443017
Validation loss: 2.440571903592726

Epoch: 6| Step: 10
Training loss: 1.8785987015422312
Validation loss: 2.4376005262959812

Epoch: 6| Step: 11
Training loss: 2.3286768112107263
Validation loss: 2.4255955217646417

Epoch: 6| Step: 12
Training loss: 2.4098933986972777
Validation loss: 2.4450242156558315

Epoch: 6| Step: 13
Training loss: 1.8860304309416611
Validation loss: 2.418611340942821

Epoch: 159| Step: 0
Training loss: 2.6168191679070287
Validation loss: 2.4281176171683025

Epoch: 6| Step: 1
Training loss: 2.120910411800563
Validation loss: 2.4282713203488426

Epoch: 6| Step: 2
Training loss: 2.1634917350031078
Validation loss: 2.4438127410037853

Epoch: 6| Step: 3
Training loss: 1.9933276933996391
Validation loss: 2.428382688038759

Epoch: 6| Step: 4
Training loss: 2.240520003451042
Validation loss: 2.4259127944055385

Epoch: 6| Step: 5
Training loss: 3.0565311107577937
Validation loss: 2.424604255092247

Epoch: 6| Step: 6
Training loss: 2.6794136285544456
Validation loss: 2.4347807633235266

Epoch: 6| Step: 7
Training loss: 1.71182931449794
Validation loss: 2.448020174818043

Epoch: 6| Step: 8
Training loss: 2.2645948501570135
Validation loss: 2.4299399018588064

Epoch: 6| Step: 9
Training loss: 2.3025916963722937
Validation loss: 2.463679177509813

Epoch: 6| Step: 10
Training loss: 2.5092414753924808
Validation loss: 2.408817538199386

Epoch: 6| Step: 11
Training loss: 2.005577178984099
Validation loss: 2.432654101866677

Epoch: 6| Step: 12
Training loss: 1.680494247803495
Validation loss: 2.4100807380078852

Epoch: 6| Step: 13
Training loss: 2.043040753877214
Validation loss: 2.4425370144726113

Epoch: 160| Step: 0
Training loss: 2.370945732612239
Validation loss: 2.447111883376375

Epoch: 6| Step: 1
Training loss: 2.695809581087906
Validation loss: 2.442075082696502

Epoch: 6| Step: 2
Training loss: 2.5033098245457426
Validation loss: 2.4213428390317335

Epoch: 6| Step: 3
Training loss: 2.357380914845847
Validation loss: 2.4191224433859726

Epoch: 6| Step: 4
Training loss: 1.6475190410758225
Validation loss: 2.4179644210134965

Epoch: 6| Step: 5
Training loss: 1.7715374014424512
Validation loss: 2.437438797898901

Epoch: 6| Step: 6
Training loss: 1.7593843341261333
Validation loss: 2.423710313227207

Epoch: 6| Step: 7
Training loss: 2.314510811517384
Validation loss: 2.4283585778703856

Epoch: 6| Step: 8
Training loss: 2.252314013424767
Validation loss: 2.4402842431854896

Epoch: 6| Step: 9
Training loss: 2.1565329324607685
Validation loss: 2.4398678000938308

Epoch: 6| Step: 10
Training loss: 2.349886781927678
Validation loss: 2.4607916764513282

Epoch: 6| Step: 11
Training loss: 2.5805294037821347
Validation loss: 2.419428295196211

Epoch: 6| Step: 12
Training loss: 2.6944286721763113
Validation loss: 2.398573720546257

Epoch: 6| Step: 13
Training loss: 2.057224694300692
Validation loss: 2.4478869818408513

Epoch: 161| Step: 0
Training loss: 1.46504124645197
Validation loss: 2.4386413190807796

Epoch: 6| Step: 1
Training loss: 2.0442208124022216
Validation loss: 2.4343653533309273

Epoch: 6| Step: 2
Training loss: 1.9993450761411824
Validation loss: 2.456507776844943

Epoch: 6| Step: 3
Training loss: 2.717465941523659
Validation loss: 2.435116211479191

Epoch: 6| Step: 4
Training loss: 2.582036420900647
Validation loss: 2.4101868511488416

Epoch: 6| Step: 5
Training loss: 2.6967019742800535
Validation loss: 2.445216707797859

Epoch: 6| Step: 6
Training loss: 1.8695192979876125
Validation loss: 2.4184394828948608

Epoch: 6| Step: 7
Training loss: 2.8759516923797337
Validation loss: 2.435010593287918

Epoch: 6| Step: 8
Training loss: 2.243903908724015
Validation loss: 2.454917140743902

Epoch: 6| Step: 9
Training loss: 2.427521651040825
Validation loss: 2.4369088584886294

Epoch: 6| Step: 10
Training loss: 1.6673425575518765
Validation loss: 2.425426227115899

Epoch: 6| Step: 11
Training loss: 1.9154949200074165
Validation loss: 2.415487397033529

Epoch: 6| Step: 12
Training loss: 2.2692812126949007
Validation loss: 2.4261077095253225

Epoch: 6| Step: 13
Training loss: 2.7451236145313413
Validation loss: 2.40190537951174

Epoch: 162| Step: 0
Training loss: 1.7011498713685334
Validation loss: 2.4307124114122156

Epoch: 6| Step: 1
Training loss: 2.023368922658489
Validation loss: 2.4488376606770594

Epoch: 6| Step: 2
Training loss: 1.8926042017601736
Validation loss: 2.4340707000821835

Epoch: 6| Step: 3
Training loss: 3.2010311074811524
Validation loss: 2.438582444781194

Epoch: 6| Step: 4
Training loss: 2.3856933189005924
Validation loss: 2.4393654629908013

Epoch: 6| Step: 5
Training loss: 2.2546587502701327
Validation loss: 2.438431502131348

Epoch: 6| Step: 6
Training loss: 1.724789637025973
Validation loss: 2.430047541283731

Epoch: 6| Step: 7
Training loss: 2.126424536339425
Validation loss: 2.427910288674749

Epoch: 6| Step: 8
Training loss: 2.429089831472437
Validation loss: 2.41097971643223

Epoch: 6| Step: 9
Training loss: 2.6407934733261906
Validation loss: 2.4145928690419445

Epoch: 6| Step: 10
Training loss: 2.273127898538759
Validation loss: 2.4165192455847326

Epoch: 6| Step: 11
Training loss: 2.3556460793013314
Validation loss: 2.4203577333490527

Epoch: 6| Step: 12
Training loss: 1.9432595078768078
Validation loss: 2.4189653917195018

Epoch: 6| Step: 13
Training loss: 2.560453947171942
Validation loss: 2.4326395692991682

Epoch: 163| Step: 0
Training loss: 2.4875055897712204
Validation loss: 2.4397210481967395

Epoch: 6| Step: 1
Training loss: 2.305115533941172
Validation loss: 2.4108359131300645

Epoch: 6| Step: 2
Training loss: 1.5443473741197877
Validation loss: 2.4267128472338393

Epoch: 6| Step: 3
Training loss: 2.555509289262816
Validation loss: 2.436886256053459

Epoch: 6| Step: 4
Training loss: 2.323918478666905
Validation loss: 2.427675051391639

Epoch: 6| Step: 5
Training loss: 2.5025633068632644
Validation loss: 2.4306545437423916

Epoch: 6| Step: 6
Training loss: 2.1763927210022307
Validation loss: 2.425509301591672

Epoch: 6| Step: 7
Training loss: 2.175984070123538
Validation loss: 2.431982073182542

Epoch: 6| Step: 8
Training loss: 2.060928208197875
Validation loss: 2.441829745275527

Epoch: 6| Step: 9
Training loss: 2.3718133930955614
Validation loss: 2.435315745041351

Epoch: 6| Step: 10
Training loss: 1.9760222167762278
Validation loss: 2.461835366598474

Epoch: 6| Step: 11
Training loss: 1.941865862777915
Validation loss: 2.4379188844480635

Epoch: 6| Step: 12
Training loss: 2.618305935229683
Validation loss: 2.445830056231497

Epoch: 6| Step: 13
Training loss: 2.2025075277141397
Validation loss: 2.4114468744193913

Epoch: 164| Step: 0
Training loss: 1.93700334889955
Validation loss: 2.398069423415203

Epoch: 6| Step: 1
Training loss: 1.5701353058550804
Validation loss: 2.4127000887582106

Epoch: 6| Step: 2
Training loss: 2.312550724607319
Validation loss: 2.435815893549757

Epoch: 6| Step: 3
Training loss: 1.933372777777623
Validation loss: 2.4194793289895125

Epoch: 6| Step: 4
Training loss: 2.208653432810836
Validation loss: 2.4335122904738946

Epoch: 6| Step: 5
Training loss: 2.5871230804573364
Validation loss: 2.405533632680317

Epoch: 6| Step: 6
Training loss: 2.0438290128687364
Validation loss: 2.4417674978451713

Epoch: 6| Step: 7
Training loss: 2.3291060665574896
Validation loss: 2.4550335708791287

Epoch: 6| Step: 8
Training loss: 2.4160053619931574
Validation loss: 2.4335424923173745

Epoch: 6| Step: 9
Training loss: 1.868074405989458
Validation loss: 2.4413472775135623

Epoch: 6| Step: 10
Training loss: 2.070349811721562
Validation loss: 2.4074565258182896

Epoch: 6| Step: 11
Training loss: 2.73076936870587
Validation loss: 2.432990567127106

Epoch: 6| Step: 12
Training loss: 2.888669563999245
Validation loss: 2.42897881336441

Epoch: 6| Step: 13
Training loss: 2.0800438533341583
Validation loss: 2.4223463432744636

Epoch: 165| Step: 0
Training loss: 1.7527827889353513
Validation loss: 2.431156772102288

Epoch: 6| Step: 1
Training loss: 2.0301486037034078
Validation loss: 2.421768660365882

Epoch: 6| Step: 2
Training loss: 1.6335650448350036
Validation loss: 2.4187022793633606

Epoch: 6| Step: 3
Training loss: 2.131662918318176
Validation loss: 2.4293486650997385

Epoch: 6| Step: 4
Training loss: 2.158580018702933
Validation loss: 2.4401730651475506

Epoch: 6| Step: 5
Training loss: 1.7188236567580182
Validation loss: 2.399380588970373

Epoch: 6| Step: 6
Training loss: 2.7761645167628846
Validation loss: 2.4004117629562653

Epoch: 6| Step: 7
Training loss: 2.9030952969480044
Validation loss: 2.4069863013104915

Epoch: 6| Step: 8
Training loss: 2.912280645009655
Validation loss: 2.4231371567521816

Epoch: 6| Step: 9
Training loss: 1.9911779501045466
Validation loss: 2.4024718014291073

Epoch: 6| Step: 10
Training loss: 2.2384071514410775
Validation loss: 2.4027623221857626

Epoch: 6| Step: 11
Training loss: 1.7344966536462414
Validation loss: 2.413216728091236

Epoch: 6| Step: 12
Training loss: 2.5745423363934656
Validation loss: 2.39477270189371

Epoch: 6| Step: 13
Training loss: 2.3786755279253367
Validation loss: 2.425042638899639

Epoch: 166| Step: 0
Training loss: 2.4473258313249606
Validation loss: 2.4218359328449095

Epoch: 6| Step: 1
Training loss: 2.1385336356578177
Validation loss: 2.413349337645711

Epoch: 6| Step: 2
Training loss: 2.683168158176313
Validation loss: 2.4238942260830214

Epoch: 6| Step: 3
Training loss: 2.3278263591753747
Validation loss: 2.42086751665681

Epoch: 6| Step: 4
Training loss: 1.7466513065701363
Validation loss: 2.411066784473771

Epoch: 6| Step: 5
Training loss: 2.183088049566353
Validation loss: 2.437456745345535

Epoch: 6| Step: 6
Training loss: 2.1778878606926577
Validation loss: 2.413590361115943

Epoch: 6| Step: 7
Training loss: 1.4537577738271148
Validation loss: 2.3979722582170893

Epoch: 6| Step: 8
Training loss: 2.3728916447106982
Validation loss: 2.43922487813769

Epoch: 6| Step: 9
Training loss: 2.732384005891532
Validation loss: 2.4534553319531662

Epoch: 6| Step: 10
Training loss: 2.4453692444868778
Validation loss: 2.4345698323248173

Epoch: 6| Step: 11
Training loss: 1.7607480100343966
Validation loss: 2.43584289470208

Epoch: 6| Step: 12
Training loss: 2.058717669642523
Validation loss: 2.461485977111012

Epoch: 6| Step: 13
Training loss: 2.4786063343761
Validation loss: 2.42813517001303

Epoch: 167| Step: 0
Training loss: 1.8477223164721106
Validation loss: 2.443958211349509

Epoch: 6| Step: 1
Training loss: 2.5499151140931753
Validation loss: 2.4631881649289693

Epoch: 6| Step: 2
Training loss: 1.9109703154721165
Validation loss: 2.4317307867796485

Epoch: 6| Step: 3
Training loss: 2.2190310877736388
Validation loss: 2.402983968780842

Epoch: 6| Step: 4
Training loss: 2.160611923747595
Validation loss: 2.4273126324767205

Epoch: 6| Step: 5
Training loss: 2.69768616466137
Validation loss: 2.4418870284337593

Epoch: 6| Step: 6
Training loss: 2.1181388491180333
Validation loss: 2.432149425269279

Epoch: 6| Step: 7
Training loss: 1.9640214841409542
Validation loss: 2.422820578230025

Epoch: 6| Step: 8
Training loss: 2.591515371275205
Validation loss: 2.4435950821041224

Epoch: 6| Step: 9
Training loss: 2.3468036341070606
Validation loss: 2.431992814280866

Epoch: 6| Step: 10
Training loss: 2.2987445307257404
Validation loss: 2.412519770758075

Epoch: 6| Step: 11
Training loss: 2.050755091909067
Validation loss: 2.430012445687615

Epoch: 6| Step: 12
Training loss: 2.3189770487134442
Validation loss: 2.4235516616956883

Epoch: 6| Step: 13
Training loss: 1.9371907387300393
Validation loss: 2.415444883835941

Epoch: 168| Step: 0
Training loss: 2.9746157870909222
Validation loss: 2.4447325458707407

Epoch: 6| Step: 1
Training loss: 2.333664416484223
Validation loss: 2.4175722874404832

Epoch: 6| Step: 2
Training loss: 2.082137285863989
Validation loss: 2.455718976546447

Epoch: 6| Step: 3
Training loss: 1.9316077928674622
Validation loss: 2.4100688562746164

Epoch: 6| Step: 4
Training loss: 2.4765150384536847
Validation loss: 2.4003530991154514

Epoch: 6| Step: 5
Training loss: 2.00659463364507
Validation loss: 2.39360618350988

Epoch: 6| Step: 6
Training loss: 2.8820609583658734
Validation loss: 2.4047569988262363

Epoch: 6| Step: 7
Training loss: 1.6148440570950966
Validation loss: 2.414264120306875

Epoch: 6| Step: 8
Training loss: 1.6926875734278852
Validation loss: 2.403506031960759

Epoch: 6| Step: 9
Training loss: 1.8744783311569784
Validation loss: 2.4155380709894385

Epoch: 6| Step: 10
Training loss: 2.0427760658790697
Validation loss: 2.415272788803919

Epoch: 6| Step: 11
Training loss: 2.499275865584854
Validation loss: 2.429823615580188

Epoch: 6| Step: 12
Training loss: 1.8987761144493431
Validation loss: 2.4553400274052297

Epoch: 6| Step: 13
Training loss: 2.052455952179834
Validation loss: 2.4089440195253364

Epoch: 169| Step: 0
Training loss: 2.5038715901706055
Validation loss: 2.4066047593388427

Epoch: 6| Step: 1
Training loss: 2.469308910600632
Validation loss: 2.4326867128850975

Epoch: 6| Step: 2
Training loss: 2.052162155987029
Validation loss: 2.4297110704757805

Epoch: 6| Step: 3
Training loss: 2.0816853935594564
Validation loss: 2.4395408059274417

Epoch: 6| Step: 4
Training loss: 2.805262344658192
Validation loss: 2.4443474743677474

Epoch: 6| Step: 5
Training loss: 1.9879455882633588
Validation loss: 2.4447486193486143

Epoch: 6| Step: 6
Training loss: 2.078908442768831
Validation loss: 2.419356317212053

Epoch: 6| Step: 7
Training loss: 2.4591543367654807
Validation loss: 2.447110637757198

Epoch: 6| Step: 8
Training loss: 2.6711171285583
Validation loss: 2.4315686526871465

Epoch: 6| Step: 9
Training loss: 2.1013691752970662
Validation loss: 2.412950571286464

Epoch: 6| Step: 10
Training loss: 1.842620244857918
Validation loss: 2.411961997604293

Epoch: 6| Step: 11
Training loss: 1.709695164686484
Validation loss: 2.437304429758513

Epoch: 6| Step: 12
Training loss: 1.818305353822952
Validation loss: 2.4025520139057224

Epoch: 6| Step: 13
Training loss: 2.190338364158747
Validation loss: 2.3852345637617045

Epoch: 170| Step: 0
Training loss: 2.4183400597753733
Validation loss: 2.3842156931697605

Epoch: 6| Step: 1
Training loss: 1.8113160706152496
Validation loss: 2.432105573712261

Epoch: 6| Step: 2
Training loss: 2.8575436924007813
Validation loss: 2.3935472714692105

Epoch: 6| Step: 3
Training loss: 1.9832437249251123
Validation loss: 2.4317805339957355

Epoch: 6| Step: 4
Training loss: 1.9786852267779511
Validation loss: 2.4077133908833073

Epoch: 6| Step: 5
Training loss: 2.3054353179627616
Validation loss: 2.4423730922214157

Epoch: 6| Step: 6
Training loss: 1.9997505986159971
Validation loss: 2.3977168713044335

Epoch: 6| Step: 7
Training loss: 2.440015912707611
Validation loss: 2.391582991695681

Epoch: 6| Step: 8
Training loss: 2.541399165183792
Validation loss: 2.403900059091667

Epoch: 6| Step: 9
Training loss: 1.7759262301013414
Validation loss: 2.412964706618259

Epoch: 6| Step: 10
Training loss: 2.3216865144726957
Validation loss: 2.4220441787595997

Epoch: 6| Step: 11
Training loss: 2.1020679645965785
Validation loss: 2.4181846424065516

Epoch: 6| Step: 12
Training loss: 1.8784524920875447
Validation loss: 2.3876882680203573

Epoch: 6| Step: 13
Training loss: 2.4881869647070114
Validation loss: 2.414819443887848

Epoch: 171| Step: 0
Training loss: 1.4614521282967918
Validation loss: 2.4248231217551135

Epoch: 6| Step: 1
Training loss: 1.859945450157188
Validation loss: 2.4338878416428957

Epoch: 6| Step: 2
Training loss: 2.282569503645168
Validation loss: 2.4278195087829886

Epoch: 6| Step: 3
Training loss: 2.339186943989181
Validation loss: 2.4352064003833376

Epoch: 6| Step: 4
Training loss: 2.155635469742476
Validation loss: 2.4251251170877204

Epoch: 6| Step: 5
Training loss: 2.370437053508487
Validation loss: 2.405148043289215

Epoch: 6| Step: 6
Training loss: 2.427631845557204
Validation loss: 2.40045951491355

Epoch: 6| Step: 7
Training loss: 2.3354691766376225
Validation loss: 2.408171355573518

Epoch: 6| Step: 8
Training loss: 2.5596997847953284
Validation loss: 2.4318816351081556

Epoch: 6| Step: 9
Training loss: 2.1422108811007483
Validation loss: 2.4394985931587945

Epoch: 6| Step: 10
Training loss: 1.943314472235641
Validation loss: 2.4073803296006817

Epoch: 6| Step: 11
Training loss: 2.6332726684857835
Validation loss: 2.3984239145032924

Epoch: 6| Step: 12
Training loss: 1.9521103321381024
Validation loss: 2.397433037843338

Epoch: 6| Step: 13
Training loss: 1.6766920482289276
Validation loss: 2.4355954348611393

Epoch: 172| Step: 0
Training loss: 2.2412616798790124
Validation loss: 2.456412598643609

Epoch: 6| Step: 1
Training loss: 2.1153459598770743
Validation loss: 2.435346337169998

Epoch: 6| Step: 2
Training loss: 2.720089637176934
Validation loss: 2.4255021291223424

Epoch: 6| Step: 3
Training loss: 1.5712257879875693
Validation loss: 2.4085086513297327

Epoch: 6| Step: 4
Training loss: 1.8226541675305559
Validation loss: 2.4492354136892183

Epoch: 6| Step: 5
Training loss: 2.472840023593843
Validation loss: 2.4267846302653497

Epoch: 6| Step: 6
Training loss: 1.9826815129775825
Validation loss: 2.4165453680599054

Epoch: 6| Step: 7
Training loss: 2.442684333428513
Validation loss: 2.4390027504610523

Epoch: 6| Step: 8
Training loss: 3.103491195476931
Validation loss: 2.417875857981515

Epoch: 6| Step: 9
Training loss: 1.9607488533861999
Validation loss: 2.4348971202970433

Epoch: 6| Step: 10
Training loss: 2.0634821085171566
Validation loss: 2.410089467906539

Epoch: 6| Step: 11
Training loss: 2.158218038516063
Validation loss: 2.3909415101818112

Epoch: 6| Step: 12
Training loss: 1.2876008040585338
Validation loss: 2.417611128171486

Epoch: 6| Step: 13
Training loss: 2.486577143638594
Validation loss: 2.4243311335828643

Epoch: 173| Step: 0
Training loss: 1.3025820069663316
Validation loss: 2.4130110197151744

Epoch: 6| Step: 1
Training loss: 2.294639277813226
Validation loss: 2.4288671326129245

Epoch: 6| Step: 2
Training loss: 2.711862719513077
Validation loss: 2.4393400194627963

Epoch: 6| Step: 3
Training loss: 2.5531223180376252
Validation loss: 2.430666083319533

Epoch: 6| Step: 4
Training loss: 2.2378593966009297
Validation loss: 2.4279607033525616

Epoch: 6| Step: 5
Training loss: 2.1726581067321153
Validation loss: 2.3873291942829975

Epoch: 6| Step: 6
Training loss: 2.3299512420922768
Validation loss: 2.424676314126199

Epoch: 6| Step: 7
Training loss: 1.969194755574491
Validation loss: 2.396531280965953

Epoch: 6| Step: 8
Training loss: 1.6973205487283474
Validation loss: 2.415925412610995

Epoch: 6| Step: 9
Training loss: 2.8996609062046685
Validation loss: 2.447779308402226

Epoch: 6| Step: 10
Training loss: 1.726350935319897
Validation loss: 2.411760273601089

Epoch: 6| Step: 11
Training loss: 2.244478231853488
Validation loss: 2.4383539849944738

Epoch: 6| Step: 12
Training loss: 1.9203027636511654
Validation loss: 2.4221248078430317

Epoch: 6| Step: 13
Training loss: 1.7915584028787042
Validation loss: 2.448724883914617

Epoch: 174| Step: 0
Training loss: 1.3744359159826056
Validation loss: 2.421500847608562

Epoch: 6| Step: 1
Training loss: 2.2045149510569426
Validation loss: 2.451745939342216

Epoch: 6| Step: 2
Training loss: 2.297924087618491
Validation loss: 2.408996299712103

Epoch: 6| Step: 3
Training loss: 2.422127888920076
Validation loss: 2.417650839915103

Epoch: 6| Step: 4
Training loss: 1.9048157596354345
Validation loss: 2.3921840446479736

Epoch: 6| Step: 5
Training loss: 1.8145840600673244
Validation loss: 2.413025956286889

Epoch: 6| Step: 6
Training loss: 2.483170511254486
Validation loss: 2.401601284708096

Epoch: 6| Step: 7
Training loss: 2.852217591169708
Validation loss: 2.414936616144312

Epoch: 6| Step: 8
Training loss: 2.0740148296800847
Validation loss: 2.405485916440131

Epoch: 6| Step: 9
Training loss: 2.339599494731064
Validation loss: 2.439203637734042

Epoch: 6| Step: 10
Training loss: 1.9847512676918717
Validation loss: 2.386150867407707

Epoch: 6| Step: 11
Training loss: 1.8209569878858607
Validation loss: 2.4273536873432007

Epoch: 6| Step: 12
Training loss: 2.6302604644947207
Validation loss: 2.3977202130889945

Epoch: 6| Step: 13
Training loss: 2.183710248702164
Validation loss: 2.394777682995867

Epoch: 175| Step: 0
Training loss: 2.503434492353919
Validation loss: 2.4182008388077527

Epoch: 6| Step: 1
Training loss: 2.1365755859617015
Validation loss: 2.4152502609292816

Epoch: 6| Step: 2
Training loss: 2.2866474209560366
Validation loss: 2.429900242194179

Epoch: 6| Step: 3
Training loss: 2.355599521530551
Validation loss: 2.443775972114442

Epoch: 6| Step: 4
Training loss: 2.4864976559936105
Validation loss: 2.4333261556627668

Epoch: 6| Step: 5
Training loss: 1.916620281598055
Validation loss: 2.4398094114175723

Epoch: 6| Step: 6
Training loss: 2.541785742883501
Validation loss: 2.396391325215251

Epoch: 6| Step: 7
Training loss: 1.9510356867003222
Validation loss: 2.4447284456908225

Epoch: 6| Step: 8
Training loss: 1.7866874154983219
Validation loss: 2.4372792424018948

Epoch: 6| Step: 9
Training loss: 2.5183301324863994
Validation loss: 2.4697269839385614

Epoch: 6| Step: 10
Training loss: 1.8774205160776989
Validation loss: 2.4235866260695254

Epoch: 6| Step: 11
Training loss: 2.595630561497492
Validation loss: 2.4295682186383836

Epoch: 6| Step: 12
Training loss: 1.8852743302320576
Validation loss: 2.419571522662269

Epoch: 6| Step: 13
Training loss: 0.9575985842319051
Validation loss: 2.4503127171614145

Epoch: 176| Step: 0
Training loss: 1.8580345643506682
Validation loss: 2.3988120413996366

Epoch: 6| Step: 1
Training loss: 2.934398230967514
Validation loss: 2.445345879454405

Epoch: 6| Step: 2
Training loss: 1.9858086881123445
Validation loss: 2.4208626908983

Epoch: 6| Step: 3
Training loss: 1.991162503913012
Validation loss: 2.4748521486571424

Epoch: 6| Step: 4
Training loss: 2.487653572287615
Validation loss: 2.4655257167421385

Epoch: 6| Step: 5
Training loss: 2.0675065513055
Validation loss: 2.4194901171159597

Epoch: 6| Step: 6
Training loss: 2.222316829998708
Validation loss: 2.4118025891976558

Epoch: 6| Step: 7
Training loss: 1.8206478350301107
Validation loss: 2.4219082907122997

Epoch: 6| Step: 8
Training loss: 2.0738711308288074
Validation loss: 2.400629146723017

Epoch: 6| Step: 9
Training loss: 2.063940181183235
Validation loss: 2.4048352172831264

Epoch: 6| Step: 10
Training loss: 2.4026577379919547
Validation loss: 2.4219254254593694

Epoch: 6| Step: 11
Training loss: 2.5589862085695994
Validation loss: 2.406844562790074

Epoch: 6| Step: 12
Training loss: 2.010613176561857
Validation loss: 2.383547237953426

Epoch: 6| Step: 13
Training loss: 1.8796762645255636
Validation loss: 2.426584405770259

Epoch: 177| Step: 0
Training loss: 2.321096679521302
Validation loss: 2.424690400660048

Epoch: 6| Step: 1
Training loss: 1.6601649385112716
Validation loss: 2.420445216314375

Epoch: 6| Step: 2
Training loss: 2.98655165939064
Validation loss: 2.4209304942002317

Epoch: 6| Step: 3
Training loss: 2.1540408773483946
Validation loss: 2.410969602120314

Epoch: 6| Step: 4
Training loss: 1.7108039978059122
Validation loss: 2.402711899470516

Epoch: 6| Step: 5
Training loss: 1.4650756652352472
Validation loss: 2.352627489442746

Epoch: 6| Step: 6
Training loss: 2.194791793159393
Validation loss: 2.4370390753613127

Epoch: 6| Step: 7
Training loss: 2.089531363553776
Validation loss: 2.4194168620209147

Epoch: 6| Step: 8
Training loss: 1.8772593555062373
Validation loss: 2.4003355065190486

Epoch: 6| Step: 9
Training loss: 2.9811498981040554
Validation loss: 2.4298647113705663

Epoch: 6| Step: 10
Training loss: 2.260791120555743
Validation loss: 2.405156564056573

Epoch: 6| Step: 11
Training loss: 1.7895297310750355
Validation loss: 2.4122402854941147

Epoch: 6| Step: 12
Training loss: 2.278063913790063
Validation loss: 2.4435435935748138

Epoch: 6| Step: 13
Training loss: 2.636883494563954
Validation loss: 2.407193562900188

Epoch: 178| Step: 0
Training loss: 1.8329946754240878
Validation loss: 2.4018341161500842

Epoch: 6| Step: 1
Training loss: 2.1846936344130996
Validation loss: 2.425472701271212

Epoch: 6| Step: 2
Training loss: 2.6175641600169843
Validation loss: 2.4101218843060113

Epoch: 6| Step: 3
Training loss: 2.1741665613543115
Validation loss: 2.4205639421481466

Epoch: 6| Step: 4
Training loss: 1.819657367481053
Validation loss: 2.3959402091721977

Epoch: 6| Step: 5
Training loss: 2.275403303512156
Validation loss: 2.419580040315333

Epoch: 6| Step: 6
Training loss: 2.6165788996205435
Validation loss: 2.4473666311259197

Epoch: 6| Step: 7
Training loss: 1.686575601076985
Validation loss: 2.4209767210952653

Epoch: 6| Step: 8
Training loss: 2.776314631933103
Validation loss: 2.38801852235416

Epoch: 6| Step: 9
Training loss: 1.7905281426828732
Validation loss: 2.42087609222939

Epoch: 6| Step: 10
Training loss: 2.046397262615255
Validation loss: 2.4241366514505964

Epoch: 6| Step: 11
Training loss: 2.5742687631475065
Validation loss: 2.4298096885802396

Epoch: 6| Step: 12
Training loss: 1.7805546524328573
Validation loss: 2.4076331512455904

Epoch: 6| Step: 13
Training loss: 2.0617198046428244
Validation loss: 2.4259195323847558

Epoch: 179| Step: 0
Training loss: 1.8183340691629954
Validation loss: 2.4135145794855912

Epoch: 6| Step: 1
Training loss: 2.034108190429185
Validation loss: 2.4291554801549804

Epoch: 6| Step: 2
Training loss: 2.499602095409583
Validation loss: 2.4175319423860717

Epoch: 6| Step: 3
Training loss: 2.6421223745773834
Validation loss: 2.430742899583732

Epoch: 6| Step: 4
Training loss: 1.6524206553929859
Validation loss: 2.4263917234306756

Epoch: 6| Step: 5
Training loss: 2.3384657226555956
Validation loss: 2.401800078080264

Epoch: 6| Step: 6
Training loss: 1.970507488237472
Validation loss: 2.4381116683849555

Epoch: 6| Step: 7
Training loss: 2.423339204252006
Validation loss: 2.435809192418353

Epoch: 6| Step: 8
Training loss: 2.689032184401131
Validation loss: 2.4003665177624525

Epoch: 6| Step: 9
Training loss: 1.8391595365970588
Validation loss: 2.4095817803096757

Epoch: 6| Step: 10
Training loss: 1.710979025698268
Validation loss: 2.4216830809703094

Epoch: 6| Step: 11
Training loss: 2.1894202387277066
Validation loss: 2.4245691901413413

Epoch: 6| Step: 12
Training loss: 1.8279194512515238
Validation loss: 2.417051554812875

Epoch: 6| Step: 13
Training loss: 2.563959961862735
Validation loss: 2.4272691867747143

Epoch: 180| Step: 0
Training loss: 2.346773359228573
Validation loss: 2.4209530369902414

Epoch: 6| Step: 1
Training loss: 2.4653540323370886
Validation loss: 2.3968253337538536

Epoch: 6| Step: 2
Training loss: 2.431131994526581
Validation loss: 2.403835699003469

Epoch: 6| Step: 3
Training loss: 2.410088289313563
Validation loss: 2.4209167659533817

Epoch: 6| Step: 4
Training loss: 2.523607844694276
Validation loss: 2.4263175038852607

Epoch: 6| Step: 5
Training loss: 1.9624263385141971
Validation loss: 2.4010124337338654

Epoch: 6| Step: 6
Training loss: 1.5888691382229112
Validation loss: 2.3730197319039155

Epoch: 6| Step: 7
Training loss: 1.724173710057195
Validation loss: 2.4244079776773337

Epoch: 6| Step: 8
Training loss: 2.6515205914990654
Validation loss: 2.4277296526497336

Epoch: 6| Step: 9
Training loss: 2.0228923519832693
Validation loss: 2.405190823759943

Epoch: 6| Step: 10
Training loss: 2.015057624390493
Validation loss: 2.4134357043680965

Epoch: 6| Step: 11
Training loss: 1.7914271157567996
Validation loss: 2.441441172885305

Epoch: 6| Step: 12
Training loss: 2.1571722960651263
Validation loss: 2.4038782778061454

Epoch: 6| Step: 13
Training loss: 1.9129173122707643
Validation loss: 2.3878489362552093

Epoch: 181| Step: 0
Training loss: 1.7185978215212108
Validation loss: 2.443792116924565

Epoch: 6| Step: 1
Training loss: 2.3338690437967013
Validation loss: 2.3985908675446392

Epoch: 6| Step: 2
Training loss: 1.4920713369481489
Validation loss: 2.3918997518484986

Epoch: 6| Step: 3
Training loss: 2.845088936969306
Validation loss: 2.4119567745768427

Epoch: 6| Step: 4
Training loss: 2.442138366790725
Validation loss: 2.3760526900737435

Epoch: 6| Step: 5
Training loss: 2.2225987539246184
Validation loss: 2.4231888545947786

Epoch: 6| Step: 6
Training loss: 2.6878809104492194
Validation loss: 2.4054143024699113

Epoch: 6| Step: 7
Training loss: 1.3515259842542806
Validation loss: 2.3978222349794187

Epoch: 6| Step: 8
Training loss: 1.7488131585757776
Validation loss: 2.423321626189794

Epoch: 6| Step: 9
Training loss: 2.2671578319246275
Validation loss: 2.400971085410526

Epoch: 6| Step: 10
Training loss: 2.0107306859417897
Validation loss: 2.4080978807154065

Epoch: 6| Step: 11
Training loss: 2.6934806458942915
Validation loss: 2.3990292751843474

Epoch: 6| Step: 12
Training loss: 1.7641932666246587
Validation loss: 2.395763030409531

Epoch: 6| Step: 13
Training loss: 2.0036455546267256
Validation loss: 2.4108612948725043

Epoch: 182| Step: 0
Training loss: 2.140097225868356
Validation loss: 2.4027946475211293

Epoch: 6| Step: 1
Training loss: 2.664547336346156
Validation loss: 2.402686154221443

Epoch: 6| Step: 2
Training loss: 1.5593374672082385
Validation loss: 2.420317547003108

Epoch: 6| Step: 3
Training loss: 2.2576887367409255
Validation loss: 2.4149329781179483

Epoch: 6| Step: 4
Training loss: 1.8026089939808534
Validation loss: 2.4362674622815983

Epoch: 6| Step: 5
Training loss: 2.3827321523658953
Validation loss: 2.4104488321058906

Epoch: 6| Step: 6
Training loss: 2.0925185724343445
Validation loss: 2.4661157462849608

Epoch: 6| Step: 7
Training loss: 2.7950036805321443
Validation loss: 2.4250786790853645

Epoch: 6| Step: 8
Training loss: 1.7003265628187576
Validation loss: 2.4359266905646826

Epoch: 6| Step: 9
Training loss: 1.9611022393683648
Validation loss: 2.405577132040418

Epoch: 6| Step: 10
Training loss: 2.3169643508150912
Validation loss: 2.4389432657720618

Epoch: 6| Step: 11
Training loss: 2.1194463975107714
Validation loss: 2.4457078409896584

Epoch: 6| Step: 12
Training loss: 2.008345596254933
Validation loss: 2.444273037539305

Epoch: 6| Step: 13
Training loss: 2.11489000273379
Validation loss: 2.4262072845428477

Epoch: 183| Step: 0
Training loss: 2.281277904601112
Validation loss: 2.425230603955863

Epoch: 6| Step: 1
Training loss: 2.2778322929226804
Validation loss: 2.4221495875931693

Epoch: 6| Step: 2
Training loss: 2.1039546696091196
Validation loss: 2.397838816962176

Epoch: 6| Step: 3
Training loss: 2.1079622412019745
Validation loss: 2.427605875644245

Epoch: 6| Step: 4
Training loss: 2.300075455132766
Validation loss: 2.3945981640837535

Epoch: 6| Step: 5
Training loss: 1.8078811592904978
Validation loss: 2.4205223580011057

Epoch: 6| Step: 6
Training loss: 1.932544030283811
Validation loss: 2.379267824328136

Epoch: 6| Step: 7
Training loss: 1.7108894933645624
Validation loss: 2.4011863419511204

Epoch: 6| Step: 8
Training loss: 2.297016995770258
Validation loss: 2.4168754490279203

Epoch: 6| Step: 9
Training loss: 2.0886318222209352
Validation loss: 2.44703673547191

Epoch: 6| Step: 10
Training loss: 2.5716814378506614
Validation loss: 2.4331306703377518

Epoch: 6| Step: 11
Training loss: 2.4338970454562903
Validation loss: 2.3899710619581827

Epoch: 6| Step: 12
Training loss: 1.6685838480895914
Validation loss: 2.395053078039742

Epoch: 6| Step: 13
Training loss: 2.5100455636376138
Validation loss: 2.4353563255046824

Epoch: 184| Step: 0
Training loss: 2.504530425688265
Validation loss: 2.4099162819550677

Epoch: 6| Step: 1
Training loss: 2.3167892062301947
Validation loss: 2.426193550227768

Epoch: 6| Step: 2
Training loss: 1.9105113816849482
Validation loss: 2.3939762784877296

Epoch: 6| Step: 3
Training loss: 2.435999090310414
Validation loss: 2.388996920806291

Epoch: 6| Step: 4
Training loss: 3.0053443988076203
Validation loss: 2.390293889550728

Epoch: 6| Step: 5
Training loss: 1.594764087653649
Validation loss: 2.419451098868559

Epoch: 6| Step: 6
Training loss: 1.3625935128695157
Validation loss: 2.399151013084223

Epoch: 6| Step: 7
Training loss: 2.2915382927282266
Validation loss: 2.407834538533819

Epoch: 6| Step: 8
Training loss: 2.0804907161227724
Validation loss: 2.3947514370848872

Epoch: 6| Step: 9
Training loss: 1.945736023173493
Validation loss: 2.393928476454671

Epoch: 6| Step: 10
Training loss: 1.7911189225254995
Validation loss: 2.398624167193315

Epoch: 6| Step: 11
Training loss: 1.7109759600771468
Validation loss: 2.426517182001275

Epoch: 6| Step: 12
Training loss: 2.0342692311064594
Validation loss: 2.4227174360863097

Epoch: 6| Step: 13
Training loss: 2.697355076924568
Validation loss: 2.429251232401452

Epoch: 185| Step: 0
Training loss: 2.291592498503872
Validation loss: 2.444759669803351

Epoch: 6| Step: 1
Training loss: 2.39373128699416
Validation loss: 2.377565969877758

Epoch: 6| Step: 2
Training loss: 1.9695724101685357
Validation loss: 2.433492474557255

Epoch: 6| Step: 3
Training loss: 1.910071497872172
Validation loss: 2.423965652085096

Epoch: 6| Step: 4
Training loss: 1.7913799352164639
Validation loss: 2.4740964091725726

Epoch: 6| Step: 5
Training loss: 2.057429467587922
Validation loss: 2.3921923870770496

Epoch: 6| Step: 6
Training loss: 1.5100417976404952
Validation loss: 2.418508805284372

Epoch: 6| Step: 7
Training loss: 2.45989822968035
Validation loss: 2.4104507943607967

Epoch: 6| Step: 8
Training loss: 2.191817790672515
Validation loss: 2.3832953442793605

Epoch: 6| Step: 9
Training loss: 2.15043574951945
Validation loss: 2.4337760353875217

Epoch: 6| Step: 10
Training loss: 2.4376101346688186
Validation loss: 2.4258338225413687

Epoch: 6| Step: 11
Training loss: 2.103528772736302
Validation loss: 2.40053051738715

Epoch: 6| Step: 12
Training loss: 2.491965735443314
Validation loss: 2.376002145072317

Epoch: 6| Step: 13
Training loss: 1.797951616262116
Validation loss: 2.3960560631357475

Epoch: 186| Step: 0
Training loss: 2.0651870332489994
Validation loss: 2.4148799782358066

Epoch: 6| Step: 1
Training loss: 2.670311989290335
Validation loss: 2.3754027866500267

Epoch: 6| Step: 2
Training loss: 2.279216330183019
Validation loss: 2.4244913556210093

Epoch: 6| Step: 3
Training loss: 2.1777015307220546
Validation loss: 2.396272843875135

Epoch: 6| Step: 4
Training loss: 2.2398435456269525
Validation loss: 2.444340371858882

Epoch: 6| Step: 5
Training loss: 1.9156225580943538
Validation loss: 2.4501755498960325

Epoch: 6| Step: 6
Training loss: 2.1741333341937183
Validation loss: 2.452315307197589

Epoch: 6| Step: 7
Training loss: 2.4902420343019465
Validation loss: 2.46613812344955

Epoch: 6| Step: 8
Training loss: 1.861672208510813
Validation loss: 2.431109062100051

Epoch: 6| Step: 9
Training loss: 1.9097431882998217
Validation loss: 2.431612139124521

Epoch: 6| Step: 10
Training loss: 2.145371791745406
Validation loss: 2.4463262651969075

Epoch: 6| Step: 11
Training loss: 1.9183741372235088
Validation loss: 2.4170806057840415

Epoch: 6| Step: 12
Training loss: 1.4536339473568733
Validation loss: 2.4355159559243726

Epoch: 6| Step: 13
Training loss: 2.714581330055401
Validation loss: 2.435714908376227

Epoch: 187| Step: 0
Training loss: 2.2707211761308352
Validation loss: 2.3948150211276245

Epoch: 6| Step: 1
Training loss: 1.8842278064029623
Validation loss: 2.415655326188594

Epoch: 6| Step: 2
Training loss: 2.178367187521014
Validation loss: 2.418683100492199

Epoch: 6| Step: 3
Training loss: 2.270827430460779
Validation loss: 2.399767031351925

Epoch: 6| Step: 4
Training loss: 2.482502165425596
Validation loss: 2.41403912479404

Epoch: 6| Step: 5
Training loss: 1.9631221198225102
Validation loss: 2.44034143550837

Epoch: 6| Step: 6
Training loss: 2.6725944754991824
Validation loss: 2.414915212538435

Epoch: 6| Step: 7
Training loss: 1.7931539734885957
Validation loss: 2.4184443590702287

Epoch: 6| Step: 8
Training loss: 1.9404740426878837
Validation loss: 2.3935618721595624

Epoch: 6| Step: 9
Training loss: 1.8551378456988552
Validation loss: 2.4248310595639433

Epoch: 6| Step: 10
Training loss: 2.076619915423216
Validation loss: 2.39549673818228

Epoch: 6| Step: 11
Training loss: 1.9162339952252145
Validation loss: 2.4200586828549047

Epoch: 6| Step: 12
Training loss: 1.8103312967919123
Validation loss: 2.402901815108294

Epoch: 6| Step: 13
Training loss: 1.989032955504633
Validation loss: 2.4035475595961815

Epoch: 188| Step: 0
Training loss: 1.734788312722828
Validation loss: 2.3857902416674697

Epoch: 6| Step: 1
Training loss: 2.027694877544069
Validation loss: 2.3872593015368864

Epoch: 6| Step: 2
Training loss: 2.2376931900929318
Validation loss: 2.3720159020536813

Epoch: 6| Step: 3
Training loss: 1.930530564705202
Validation loss: 2.373626439163284

Epoch: 6| Step: 4
Training loss: 2.032592329905297
Validation loss: 2.3999148259507868

Epoch: 6| Step: 5
Training loss: 1.6355026935215844
Validation loss: 2.3827065054082

Epoch: 6| Step: 6
Training loss: 2.285000578965796
Validation loss: 2.3944324872583977

Epoch: 6| Step: 7
Training loss: 1.9657841094957182
Validation loss: 2.411842648497156

Epoch: 6| Step: 8
Training loss: 1.349728304402279
Validation loss: 2.4123077934048185

Epoch: 6| Step: 9
Training loss: 2.0404331087843435
Validation loss: 2.4347775655893242

Epoch: 6| Step: 10
Training loss: 2.5296620226891267
Validation loss: 2.4064480940131516

Epoch: 6| Step: 11
Training loss: 2.608109584226192
Validation loss: 2.4303264091126473

Epoch: 6| Step: 12
Training loss: 2.3111227934900724
Validation loss: 2.4000624181123396

Epoch: 6| Step: 13
Training loss: 2.853922497034492
Validation loss: 2.4407530922327285

Epoch: 189| Step: 0
Training loss: 2.152434470035413
Validation loss: 2.422014060048929

Epoch: 6| Step: 1
Training loss: 0.9953050370587834
Validation loss: 2.3875727628617573

Epoch: 6| Step: 2
Training loss: 2.265824513036469
Validation loss: 2.4146298657291925

Epoch: 6| Step: 3
Training loss: 1.9725303080929364
Validation loss: 2.4153478529593673

Epoch: 6| Step: 4
Training loss: 2.2264138690797504
Validation loss: 2.40692682846088

Epoch: 6| Step: 5
Training loss: 1.6225955487111585
Validation loss: 2.4466478856471743

Epoch: 6| Step: 6
Training loss: 1.7523156240776714
Validation loss: 2.377530818254798

Epoch: 6| Step: 7
Training loss: 2.4401817241598684
Validation loss: 2.4537328621834082

Epoch: 6| Step: 8
Training loss: 2.1540892458591347
Validation loss: 2.408309811338389

Epoch: 6| Step: 9
Training loss: 2.259899297006635
Validation loss: 2.4162819195064653

Epoch: 6| Step: 10
Training loss: 2.408563071868161
Validation loss: 2.4181827214123497

Epoch: 6| Step: 11
Training loss: 2.4657783489622376
Validation loss: 2.428654083527663

Epoch: 6| Step: 12
Training loss: 2.4261683648126575
Validation loss: 2.4097896080394223

Epoch: 6| Step: 13
Training loss: 1.4335177450794823
Validation loss: 2.405768521159704

Epoch: 190| Step: 0
Training loss: 2.033178030659861
Validation loss: 2.389494756703443

Epoch: 6| Step: 1
Training loss: 1.364434920920424
Validation loss: 2.4197853846614095

Epoch: 6| Step: 2
Training loss: 2.547566045142699
Validation loss: 2.414119229299114

Epoch: 6| Step: 3
Training loss: 1.8479005035186664
Validation loss: 2.378280897184706

Epoch: 6| Step: 4
Training loss: 1.83739663436696
Validation loss: 2.407306125607901

Epoch: 6| Step: 5
Training loss: 3.116358596617206
Validation loss: 2.379993954584736

Epoch: 6| Step: 6
Training loss: 2.0249617443474226
Validation loss: 2.3854432853921983

Epoch: 6| Step: 7
Training loss: 2.16458134680159
Validation loss: 2.3799606344787163

Epoch: 6| Step: 8
Training loss: 2.354627265995104
Validation loss: 2.4279785572000585

Epoch: 6| Step: 9
Training loss: 2.0481157109757384
Validation loss: 2.3967259542330037

Epoch: 6| Step: 10
Training loss: 2.0299793670808395
Validation loss: 2.4039902044698014

Epoch: 6| Step: 11
Training loss: 1.600042077345697
Validation loss: 2.404351459108587

Epoch: 6| Step: 12
Training loss: 2.163767439905819
Validation loss: 2.4018969040466085

Epoch: 6| Step: 13
Training loss: 1.7749711182084746
Validation loss: 2.4170881421153054

Epoch: 191| Step: 0
Training loss: 1.8886935874850708
Validation loss: 2.4048924989730827

Epoch: 6| Step: 1
Training loss: 2.381038217813805
Validation loss: 2.4075501936091617

Epoch: 6| Step: 2
Training loss: 2.167538051953192
Validation loss: 2.402478309569202

Epoch: 6| Step: 3
Training loss: 2.0697999715678437
Validation loss: 2.4181484146584777

Epoch: 6| Step: 4
Training loss: 1.336982006411279
Validation loss: 2.3916107296677422

Epoch: 6| Step: 5
Training loss: 1.591119203068907
Validation loss: 2.401084942399109

Epoch: 6| Step: 6
Training loss: 2.0273969051617815
Validation loss: 2.4007253009780785

Epoch: 6| Step: 7
Training loss: 2.3236228884302026
Validation loss: 2.3936596148042395

Epoch: 6| Step: 8
Training loss: 1.9863274648359583
Validation loss: 2.3959923354822723

Epoch: 6| Step: 9
Training loss: 1.9109583381770554
Validation loss: 2.4149644749430443

Epoch: 6| Step: 10
Training loss: 1.7734326602012704
Validation loss: 2.40273671724964

Epoch: 6| Step: 11
Training loss: 2.295167041425716
Validation loss: 2.411890075288011

Epoch: 6| Step: 12
Training loss: 2.517870735819725
Validation loss: 2.440900256284888

Epoch: 6| Step: 13
Training loss: 2.9302323712066896
Validation loss: 2.413038399286779

Epoch: 192| Step: 0
Training loss: 2.660178297850537
Validation loss: 2.399238682687117

Epoch: 6| Step: 1
Training loss: 2.1955173166105113
Validation loss: 2.407514881334278

Epoch: 6| Step: 2
Training loss: 1.4781208191504034
Validation loss: 2.3817932848649854

Epoch: 6| Step: 3
Training loss: 1.8947680138580876
Validation loss: 2.400465691562832

Epoch: 6| Step: 4
Training loss: 1.5687526718056104
Validation loss: 2.416219899850681

Epoch: 6| Step: 5
Training loss: 2.0813261917418577
Validation loss: 2.3994680087222267

Epoch: 6| Step: 6
Training loss: 2.0805140938367424
Validation loss: 2.4169592141041942

Epoch: 6| Step: 7
Training loss: 2.278484601810703
Validation loss: 2.4111942836032196

Epoch: 6| Step: 8
Training loss: 1.9890345137695709
Validation loss: 2.4099926107449323

Epoch: 6| Step: 9
Training loss: 2.836312093244184
Validation loss: 2.3762308869911015

Epoch: 6| Step: 10
Training loss: 2.198394349846666
Validation loss: 2.4039317345983915

Epoch: 6| Step: 11
Training loss: 1.903214774183227
Validation loss: 2.4029503550774245

Epoch: 6| Step: 12
Training loss: 1.7269573882058327
Validation loss: 2.426472997277607

Epoch: 6| Step: 13
Training loss: 1.7786021043383033
Validation loss: 2.3911969158067867

Epoch: 193| Step: 0
Training loss: 1.9662046175288939
Validation loss: 2.4030638355806357

Epoch: 6| Step: 1
Training loss: 2.812715818813693
Validation loss: 2.386384293695379

Epoch: 6| Step: 2
Training loss: 2.472796829349456
Validation loss: 2.419598693966164

Epoch: 6| Step: 3
Training loss: 2.251908234862644
Validation loss: 2.4285634676140226

Epoch: 6| Step: 4
Training loss: 1.8210945905096798
Validation loss: 2.436977929536992

Epoch: 6| Step: 5
Training loss: 2.278716051745461
Validation loss: 2.3812435477882095

Epoch: 6| Step: 6
Training loss: 1.764159007511562
Validation loss: 2.408990478561103

Epoch: 6| Step: 7
Training loss: 1.6684534588050721
Validation loss: 2.4306567153935315

Epoch: 6| Step: 8
Training loss: 2.1895404563453824
Validation loss: 2.445796924466885

Epoch: 6| Step: 9
Training loss: 1.6839079596857767
Validation loss: 2.4335023583057565

Epoch: 6| Step: 10
Training loss: 1.9596118473566175
Validation loss: 2.445380132786231

Epoch: 6| Step: 11
Training loss: 1.7392251870009912
Validation loss: 2.4450119606005853

Epoch: 6| Step: 12
Training loss: 2.3997351897695016
Validation loss: 2.4023186229555926

Epoch: 6| Step: 13
Training loss: 1.383456279660781
Validation loss: 2.4203540378007116

Epoch: 194| Step: 0
Training loss: 1.7805733315659489
Validation loss: 2.41160356793924

Epoch: 6| Step: 1
Training loss: 1.6430120632032934
Validation loss: 2.379993267354855

Epoch: 6| Step: 2
Training loss: 1.9895602985533236
Validation loss: 2.4221432995385985

Epoch: 6| Step: 3
Training loss: 2.118480554962771
Validation loss: 2.4129236337651316

Epoch: 6| Step: 4
Training loss: 2.5428973069241336
Validation loss: 2.4133119909550333

Epoch: 6| Step: 5
Training loss: 1.6982256212353284
Validation loss: 2.462011364652702

Epoch: 6| Step: 6
Training loss: 1.8978254171378162
Validation loss: 2.454020588363468

Epoch: 6| Step: 7
Training loss: 2.2765751845530713
Validation loss: 2.4298425825486283

Epoch: 6| Step: 8
Training loss: 2.1379347554271
Validation loss: 2.4188290164572397

Epoch: 6| Step: 9
Training loss: 1.4250930588435746
Validation loss: 2.375938430900346

Epoch: 6| Step: 10
Training loss: 2.1069393082736814
Validation loss: 2.362672703265249

Epoch: 6| Step: 11
Training loss: 1.8260218594382271
Validation loss: 2.405727174658347

Epoch: 6| Step: 12
Training loss: 2.8301431610237757
Validation loss: 2.4052700609112483

Epoch: 6| Step: 13
Training loss: 2.0558578581082307
Validation loss: 2.4148360792804366

Epoch: 195| Step: 0
Training loss: 2.145872270051841
Validation loss: 2.35989417199132

Epoch: 6| Step: 1
Training loss: 1.927431525314137
Validation loss: 2.3799060823408404

Epoch: 6| Step: 2
Training loss: 2.832158368644919
Validation loss: 2.35863931235504

Epoch: 6| Step: 3
Training loss: 1.99249013958146
Validation loss: 2.408091289820152

Epoch: 6| Step: 4
Training loss: 2.2124433477875063
Validation loss: 2.4004619755361767

Epoch: 6| Step: 5
Training loss: 1.8748082380780786
Validation loss: 2.433464781517091

Epoch: 6| Step: 6
Training loss: 1.7846446566748644
Validation loss: 2.375993571003009

Epoch: 6| Step: 7
Training loss: 2.178383276361272
Validation loss: 2.4047073663331497

Epoch: 6| Step: 8
Training loss: 2.095015755277764
Validation loss: 2.3831735327701566

Epoch: 6| Step: 9
Training loss: 1.5683207619974324
Validation loss: 2.4132963125449534

Epoch: 6| Step: 10
Training loss: 1.1168515427169532
Validation loss: 2.4253880812620223

Epoch: 6| Step: 11
Training loss: 2.672845764488368
Validation loss: 2.371649132881256

Epoch: 6| Step: 12
Training loss: 2.209217062650754
Validation loss: 2.3973799815121497

Epoch: 6| Step: 13
Training loss: 2.288789283669487
Validation loss: 2.4003200477409132

Epoch: 196| Step: 0
Training loss: 1.3990416686837819
Validation loss: 2.386521165704862

Epoch: 6| Step: 1
Training loss: 1.4735520772387778
Validation loss: 2.429123538330652

Epoch: 6| Step: 2
Training loss: 1.5598089313872077
Validation loss: 2.4161490698311447

Epoch: 6| Step: 3
Training loss: 1.99653175759034
Validation loss: 2.4049604567147598

Epoch: 6| Step: 4
Training loss: 2.741061683236288
Validation loss: 2.38314096011607

Epoch: 6| Step: 5
Training loss: 2.456013916162585
Validation loss: 2.3956926747710554

Epoch: 6| Step: 6
Training loss: 2.025295744598398
Validation loss: 2.418310006242029

Epoch: 6| Step: 7
Training loss: 2.2400042707538765
Validation loss: 2.4123686692076465

Epoch: 6| Step: 8
Training loss: 2.2930282247131313
Validation loss: 2.422738498817056

Epoch: 6| Step: 9
Training loss: 2.311905449395758
Validation loss: 2.4309344935513897

Epoch: 6| Step: 10
Training loss: 1.909260732974486
Validation loss: 2.4455512958064416

Epoch: 6| Step: 11
Training loss: 1.854549397032588
Validation loss: 2.407249921057081

Epoch: 6| Step: 12
Training loss: 2.1016406643877663
Validation loss: 2.4172007982126975

Epoch: 6| Step: 13
Training loss: 1.608568007720353
Validation loss: 2.4244524490553063

Epoch: 197| Step: 0
Training loss: 1.2886605300704583
Validation loss: 2.394218928853377

Epoch: 6| Step: 1
Training loss: 1.7355467128989697
Validation loss: 2.414393461936523

Epoch: 6| Step: 2
Training loss: 1.8803037652676138
Validation loss: 2.40878488606757

Epoch: 6| Step: 3
Training loss: 2.0208804200444765
Validation loss: 2.4121011816985565

Epoch: 6| Step: 4
Training loss: 2.098067884352428
Validation loss: 2.4039536396382895

Epoch: 6| Step: 5
Training loss: 1.7072001707530986
Validation loss: 2.395644330188794

Epoch: 6| Step: 6
Training loss: 1.6988572010070335
Validation loss: 2.438435654953307

Epoch: 6| Step: 7
Training loss: 2.777496977494567
Validation loss: 2.410709889443673

Epoch: 6| Step: 8
Training loss: 1.9358212981860548
Validation loss: 2.4053642348373234

Epoch: 6| Step: 9
Training loss: 2.5427971707308963
Validation loss: 2.423252630851603

Epoch: 6| Step: 10
Training loss: 2.617886578013925
Validation loss: 2.3777505871577675

Epoch: 6| Step: 11
Training loss: 1.7232569471114347
Validation loss: 2.3783154955263286

Epoch: 6| Step: 12
Training loss: 1.9765855991385868
Validation loss: 2.4111990861831263

Epoch: 6| Step: 13
Training loss: 2.0696266045785046
Validation loss: 2.3627500059848887

Epoch: 198| Step: 0
Training loss: 1.563567826647121
Validation loss: 2.409705577778398

Epoch: 6| Step: 1
Training loss: 1.8464909239689766
Validation loss: 2.415126470626865

Epoch: 6| Step: 2
Training loss: 1.9887636570008997
Validation loss: 2.4078227282316425

Epoch: 6| Step: 3
Training loss: 2.816123662519986
Validation loss: 2.417958192051646

Epoch: 6| Step: 4
Training loss: 1.5253672579686308
Validation loss: 2.4026757926651285

Epoch: 6| Step: 5
Training loss: 1.831119399898147
Validation loss: 2.3913876590899323

Epoch: 6| Step: 6
Training loss: 2.150032699691149
Validation loss: 2.4332966854703164

Epoch: 6| Step: 7
Training loss: 1.7940387400396178
Validation loss: 2.4116953355902053

Epoch: 6| Step: 8
Training loss: 2.2255426580916935
Validation loss: 2.4303682769801167

Epoch: 6| Step: 9
Training loss: 2.36969063232569
Validation loss: 2.433789681619073

Epoch: 6| Step: 10
Training loss: 2.9177644752585934
Validation loss: 2.4279856452752044

Epoch: 6| Step: 11
Training loss: 1.661800369245392
Validation loss: 2.415331283449023

Epoch: 6| Step: 12
Training loss: 1.9614501526172905
Validation loss: 2.386052828992237

Epoch: 6| Step: 13
Training loss: 1.9337143985600262
Validation loss: 2.3860568075937345

Epoch: 199| Step: 0
Training loss: 1.6394452894458484
Validation loss: 2.4089547936402775

Epoch: 6| Step: 1
Training loss: 1.9970677457387234
Validation loss: 2.4261958785578503

Epoch: 6| Step: 2
Training loss: 1.801208974885956
Validation loss: 2.4119102004876534

Epoch: 6| Step: 3
Training loss: 2.1658170452535326
Validation loss: 2.4432594340060017

Epoch: 6| Step: 4
Training loss: 2.1473035004391083
Validation loss: 2.4101440904846774

Epoch: 6| Step: 5
Training loss: 2.749571333333588
Validation loss: 2.4404855790925404

Epoch: 6| Step: 6
Training loss: 1.710533477598325
Validation loss: 2.3940944462260076

Epoch: 6| Step: 7
Training loss: 2.552642657172618
Validation loss: 2.3921129160737253

Epoch: 6| Step: 8
Training loss: 1.4976073096392417
Validation loss: 2.427025893900117

Epoch: 6| Step: 9
Training loss: 2.0401629405303816
Validation loss: 2.377069943184435

Epoch: 6| Step: 10
Training loss: 1.8772893281018324
Validation loss: 2.3928812002023094

Epoch: 6| Step: 11
Training loss: 1.9880750507986444
Validation loss: 2.4127208904221225

Epoch: 6| Step: 12
Training loss: 2.0920526257345378
Validation loss: 2.3885206026844727

Epoch: 6| Step: 13
Training loss: 2.340204940200728
Validation loss: 2.4270095446046662

Epoch: 200| Step: 0
Training loss: 2.3092839327602164
Validation loss: 2.420014555004327

Epoch: 6| Step: 1
Training loss: 1.9547594479523895
Validation loss: 2.43195507660152

Epoch: 6| Step: 2
Training loss: 1.9194890540472425
Validation loss: 2.404955253125958

Epoch: 6| Step: 3
Training loss: 2.108232768177099
Validation loss: 2.380579405582998

Epoch: 6| Step: 4
Training loss: 1.9467831609872015
Validation loss: 2.401541095647625

Epoch: 6| Step: 5
Training loss: 2.0256323968975316
Validation loss: 2.4253465565735435

Epoch: 6| Step: 6
Training loss: 2.119183377304925
Validation loss: 2.3753304567340714

Epoch: 6| Step: 7
Training loss: 1.7478837432609913
Validation loss: 2.4347494028143677

Epoch: 6| Step: 8
Training loss: 2.0704693428944374
Validation loss: 2.4317412364361317

Epoch: 6| Step: 9
Training loss: 1.712989030053532
Validation loss: 2.431029176014205

Epoch: 6| Step: 10
Training loss: 1.7204200260606584
Validation loss: 2.4412876819326703

Epoch: 6| Step: 11
Training loss: 1.753685816312898
Validation loss: 2.4517145030563636

Epoch: 6| Step: 12
Training loss: 2.3361086575372636
Validation loss: 2.4203907292932514

Epoch: 6| Step: 13
Training loss: 3.1428642830210243
Validation loss: 2.3958209479298516

Epoch: 201| Step: 0
Training loss: 2.1694258458567757
Validation loss: 2.4098808511630043

Epoch: 6| Step: 1
Training loss: 1.805670994548788
Validation loss: 2.455449398434693

Epoch: 6| Step: 2
Training loss: 1.7766385534375153
Validation loss: 2.421272409810055

Epoch: 6| Step: 3
Training loss: 2.4966029929719706
Validation loss: 2.42763214969247

Epoch: 6| Step: 4
Training loss: 1.875133891093537
Validation loss: 2.425824768850178

Epoch: 6| Step: 5
Training loss: 2.366583013623201
Validation loss: 2.4473624950298096

Epoch: 6| Step: 6
Training loss: 1.841489408198981
Validation loss: 2.418573884709532

Epoch: 6| Step: 7
Training loss: 1.7215826101300504
Validation loss: 2.41877029426118

Epoch: 6| Step: 8
Training loss: 1.705552217657666
Validation loss: 2.424194404511239

Epoch: 6| Step: 9
Training loss: 1.4785729501715097
Validation loss: 2.4008748406263822

Epoch: 6| Step: 10
Training loss: 2.780563869923311
Validation loss: 2.450139927002165

Epoch: 6| Step: 11
Training loss: 2.0545736651198596
Validation loss: 2.386080308927444

Epoch: 6| Step: 12
Training loss: 2.1531392754467684
Validation loss: 2.3635744207761014

Epoch: 6| Step: 13
Training loss: 2.219038608746349
Validation loss: 2.3861566905580704

Epoch: 202| Step: 0
Training loss: 2.2932235862103196
Validation loss: 2.417160321806908

Epoch: 6| Step: 1
Training loss: 2.1113109605569638
Validation loss: 2.389107472576385

Epoch: 6| Step: 2
Training loss: 2.168574837858398
Validation loss: 2.3888623004885856

Epoch: 6| Step: 3
Training loss: 1.5121151899631473
Validation loss: 2.3969995650069107

Epoch: 6| Step: 4
Training loss: 1.9499211393206912
Validation loss: 2.3879041872845703

Epoch: 6| Step: 5
Training loss: 2.469867501662598
Validation loss: 2.4194605896510533

Epoch: 6| Step: 6
Training loss: 2.043270052396169
Validation loss: 2.394417110284844

Epoch: 6| Step: 7
Training loss: 1.7002170480284258
Validation loss: 2.4064079758057293

Epoch: 6| Step: 8
Training loss: 2.4117796143518433
Validation loss: 2.367090463180833

Epoch: 6| Step: 9
Training loss: 2.0989983667637184
Validation loss: 2.334235615319447

Epoch: 6| Step: 10
Training loss: 1.5843142766808995
Validation loss: 2.3782698633802264

Epoch: 6| Step: 11
Training loss: 2.238929428330957
Validation loss: 2.414633997907361

Epoch: 6| Step: 12
Training loss: 1.5931290557558282
Validation loss: 2.38180231218629

Epoch: 6| Step: 13
Training loss: 1.9255668721994919
Validation loss: 2.4067703449418234

Epoch: 203| Step: 0
Training loss: 1.5175941495896235
Validation loss: 2.4203608759906228

Epoch: 6| Step: 1
Training loss: 1.999372562694346
Validation loss: 2.3784118458651387

Epoch: 6| Step: 2
Training loss: 2.471202549572905
Validation loss: 2.4392014395343007

Epoch: 6| Step: 3
Training loss: 2.3865899833244586
Validation loss: 2.432941006926016

Epoch: 6| Step: 4
Training loss: 1.7079141459183131
Validation loss: 2.4353847291634563

Epoch: 6| Step: 5
Training loss: 2.3890187969913357
Validation loss: 2.4166854190063503

Epoch: 6| Step: 6
Training loss: 1.9996641592340805
Validation loss: 2.400281338412611

Epoch: 6| Step: 7
Training loss: 1.8901191854489034
Validation loss: 2.4169612262292777

Epoch: 6| Step: 8
Training loss: 1.842879979096671
Validation loss: 2.398366960398957

Epoch: 6| Step: 9
Training loss: 1.688562835554389
Validation loss: 2.463467228431358

Epoch: 6| Step: 10
Training loss: 1.4964349820701714
Validation loss: 2.4145898558562613

Epoch: 6| Step: 11
Training loss: 2.573775442848968
Validation loss: 2.4251107143563675

Epoch: 6| Step: 12
Training loss: 1.6553498467108072
Validation loss: 2.3999869501150486

Epoch: 6| Step: 13
Training loss: 2.4012229227647297
Validation loss: 2.381423564219668

Epoch: 204| Step: 0
Training loss: 1.9798188055341281
Validation loss: 2.422603197872019

Epoch: 6| Step: 1
Training loss: 1.6607169606880174
Validation loss: 2.4176613822395807

Epoch: 6| Step: 2
Training loss: 2.115549051789474
Validation loss: 2.3633481799887175

Epoch: 6| Step: 3
Training loss: 1.766582263273867
Validation loss: 2.422430599655287

Epoch: 6| Step: 4
Training loss: 1.9228025849606094
Validation loss: 2.4285337369449342

Epoch: 6| Step: 5
Training loss: 2.4631973789502206
Validation loss: 2.375297186693916

Epoch: 6| Step: 6
Training loss: 1.8330179579001333
Validation loss: 2.4297388073541186

Epoch: 6| Step: 7
Training loss: 2.1948719600793525
Validation loss: 2.3727695081695734

Epoch: 6| Step: 8
Training loss: 2.0458217560957856
Validation loss: 2.375458493365455

Epoch: 6| Step: 9
Training loss: 2.1664481664179918
Validation loss: 2.423547725606889

Epoch: 6| Step: 10
Training loss: 2.1804838742449544
Validation loss: 2.4384755689940825

Epoch: 6| Step: 11
Training loss: 1.9090283892455435
Validation loss: 2.3939678346521567

Epoch: 6| Step: 12
Training loss: 1.8196305073862233
Validation loss: 2.389697975097724

Epoch: 6| Step: 13
Training loss: 2.0348287893719426
Validation loss: 2.404184986072502

Epoch: 205| Step: 0
Training loss: 2.163840602694577
Validation loss: 2.3757983022653546

Epoch: 6| Step: 1
Training loss: 1.8733447716093372
Validation loss: 2.3972502828393876

Epoch: 6| Step: 2
Training loss: 2.0364956539340886
Validation loss: 2.378130943660993

Epoch: 6| Step: 3
Training loss: 2.037397735463231
Validation loss: 2.398989934838999

Epoch: 6| Step: 4
Training loss: 2.3228357640249344
Validation loss: 2.4025971699264423

Epoch: 6| Step: 5
Training loss: 2.057263749975411
Validation loss: 2.409227452953392

Epoch: 6| Step: 6
Training loss: 1.928625579104039
Validation loss: 2.3840341100377085

Epoch: 6| Step: 7
Training loss: 2.2153235829028075
Validation loss: 2.4330061470761533

Epoch: 6| Step: 8
Training loss: 1.4775351091270228
Validation loss: 2.398569469850206

Epoch: 6| Step: 9
Training loss: 1.794303646442769
Validation loss: 2.3890040891260167

Epoch: 6| Step: 10
Training loss: 2.0692246367985714
Validation loss: 2.4077614175386652

Epoch: 6| Step: 11
Training loss: 1.969792528991134
Validation loss: 2.4127710752785956

Epoch: 6| Step: 12
Training loss: 1.7142903818907091
Validation loss: 2.365482594263929

Epoch: 6| Step: 13
Training loss: 2.0547143042378897
Validation loss: 2.3763601254488123

Epoch: 206| Step: 0
Training loss: 2.6012650053369653
Validation loss: 2.3737169468984214

Epoch: 6| Step: 1
Training loss: 1.930425217190513
Validation loss: 2.441083711053246

Epoch: 6| Step: 2
Training loss: 1.700425624859647
Validation loss: 2.407117177304317

Epoch: 6| Step: 3
Training loss: 1.5970656368881815
Validation loss: 2.3924237065629805

Epoch: 6| Step: 4
Training loss: 2.0016834803162795
Validation loss: 2.423220975152498

Epoch: 6| Step: 5
Training loss: 1.8166263570017278
Validation loss: 2.406178986239686

Epoch: 6| Step: 6
Training loss: 1.41759753031311
Validation loss: 2.382784929121048

Epoch: 6| Step: 7
Training loss: 2.3004941906954124
Validation loss: 2.373576299906992

Epoch: 6| Step: 8
Training loss: 1.4670865805208166
Validation loss: 2.3603835899841177

Epoch: 6| Step: 9
Training loss: 1.6029826497015307
Validation loss: 2.3872433639646045

Epoch: 6| Step: 10
Training loss: 2.052645056148769
Validation loss: 2.38900234104524

Epoch: 6| Step: 11
Training loss: 2.2818942270798446
Validation loss: 2.3933441110582465

Epoch: 6| Step: 12
Training loss: 2.498816782377141
Validation loss: 2.392499217577393

Epoch: 6| Step: 13
Training loss: 2.324623700935734
Validation loss: 2.4113530422362612

Epoch: 207| Step: 0
Training loss: 1.709652771078458
Validation loss: 2.4018093771031865

Epoch: 6| Step: 1
Training loss: 1.9938101349853043
Validation loss: 2.4324005978084955

Epoch: 6| Step: 2
Training loss: 2.872477544392992
Validation loss: 2.407358912058475

Epoch: 6| Step: 3
Training loss: 1.6813728571251303
Validation loss: 2.375469484109308

Epoch: 6| Step: 4
Training loss: 1.798787434435611
Validation loss: 2.446360943888712

Epoch: 6| Step: 5
Training loss: 2.291144143847026
Validation loss: 2.3855620015423806

Epoch: 6| Step: 6
Training loss: 1.5999049098845242
Validation loss: 2.3796059688224607

Epoch: 6| Step: 7
Training loss: 2.1907252921356952
Validation loss: 2.3849059028866986

Epoch: 6| Step: 8
Training loss: 1.9253250417376706
Validation loss: 2.390865162391744

Epoch: 6| Step: 9
Training loss: 1.7847678932781672
Validation loss: 2.3663802542371557

Epoch: 6| Step: 10
Training loss: 1.9091009489637656
Validation loss: 2.414742021280444

Epoch: 6| Step: 11
Training loss: 2.261469746588242
Validation loss: 2.4227986289693635

Epoch: 6| Step: 12
Training loss: 1.7023070584842666
Validation loss: 2.4131835575664287

Epoch: 6| Step: 13
Training loss: 1.8418350620295607
Validation loss: 2.413926473809294

Epoch: 208| Step: 0
Training loss: 2.73240721605253
Validation loss: 2.362514612391742

Epoch: 6| Step: 1
Training loss: 1.319149159411475
Validation loss: 2.3893543083196653

Epoch: 6| Step: 2
Training loss: 3.096866617662959
Validation loss: 2.4396630432345363

Epoch: 6| Step: 3
Training loss: 1.9441997608758774
Validation loss: 2.408877925384254

Epoch: 6| Step: 4
Training loss: 2.3125633024882015
Validation loss: 2.3866061336505755

Epoch: 6| Step: 5
Training loss: 1.7777847581302508
Validation loss: 2.421646961666412

Epoch: 6| Step: 6
Training loss: 1.683587235794387
Validation loss: 2.424685882785668

Epoch: 6| Step: 7
Training loss: 1.9384902146480845
Validation loss: 2.4103744391320676

Epoch: 6| Step: 8
Training loss: 1.6324711493006394
Validation loss: 2.3905642922189414

Epoch: 6| Step: 9
Training loss: 1.494522026101347
Validation loss: 2.3993401784288246

Epoch: 6| Step: 10
Training loss: 2.023474262153984
Validation loss: 2.396437883187274

Epoch: 6| Step: 11
Training loss: 1.6280460419060758
Validation loss: 2.3886392576550586

Epoch: 6| Step: 12
Training loss: 1.7422093958825853
Validation loss: 2.407938393233504

Epoch: 6| Step: 13
Training loss: 1.558307975249931
Validation loss: 2.401771804538561

Epoch: 209| Step: 0
Training loss: 1.8839268849028914
Validation loss: 2.363930612165853

Epoch: 6| Step: 1
Training loss: 2.4185077516353877
Validation loss: 2.407502482196619

Epoch: 6| Step: 2
Training loss: 1.7077324516054848
Validation loss: 2.398603234726438

Epoch: 6| Step: 3
Training loss: 2.6501029300493135
Validation loss: 2.4175617277607024

Epoch: 6| Step: 4
Training loss: 1.8204132183191013
Validation loss: 2.4044134724966906

Epoch: 6| Step: 5
Training loss: 1.7670845143389862
Validation loss: 2.4049336349001327

Epoch: 6| Step: 6
Training loss: 1.4514811251757058
Validation loss: 2.3637331912921007

Epoch: 6| Step: 7
Training loss: 1.7600780214008858
Validation loss: 2.41257135607797

Epoch: 6| Step: 8
Training loss: 2.097063772968173
Validation loss: 2.4193198495132733

Epoch: 6| Step: 9
Training loss: 2.3203973722509095
Validation loss: 2.454099263257064

Epoch: 6| Step: 10
Training loss: 2.0120185702701194
Validation loss: 2.4286055421591923

Epoch: 6| Step: 11
Training loss: 2.1554935621193327
Validation loss: 2.4307934379679312

Epoch: 6| Step: 12
Training loss: 1.4333933344561876
Validation loss: 2.4216815290338047

Epoch: 6| Step: 13
Training loss: 2.099129328297846
Validation loss: 2.428576412649944

Epoch: 210| Step: 0
Training loss: 1.7461065850863553
Validation loss: 2.3910950165081375

Epoch: 6| Step: 1
Training loss: 1.7867643429735711
Validation loss: 2.4611448399525355

Epoch: 6| Step: 2
Training loss: 2.1440253434035563
Validation loss: 2.3987435070882057

Epoch: 6| Step: 3
Training loss: 2.136606942272968
Validation loss: 2.3958265314277587

Epoch: 6| Step: 4
Training loss: 1.6304022416723636
Validation loss: 2.4207970206560443

Epoch: 6| Step: 5
Training loss: 1.3568800908453986
Validation loss: 2.4084250958260998

Epoch: 6| Step: 6
Training loss: 2.0953412058981042
Validation loss: 2.3836549439372403

Epoch: 6| Step: 7
Training loss: 1.5137528330164511
Validation loss: 2.371483586757608

Epoch: 6| Step: 8
Training loss: 2.019610346235768
Validation loss: 2.412545453308147

Epoch: 6| Step: 9
Training loss: 1.7138189151410552
Validation loss: 2.414393458751076

Epoch: 6| Step: 10
Training loss: 2.3434266948234654
Validation loss: 2.3973148389733896

Epoch: 6| Step: 11
Training loss: 2.8532278554202937
Validation loss: 2.4096608039190976

Epoch: 6| Step: 12
Training loss: 1.8749114969346927
Validation loss: 2.4104240852223575

Epoch: 6| Step: 13
Training loss: 2.4687159089257626
Validation loss: 2.4036691635831064

Epoch: 211| Step: 0
Training loss: 2.195997681038054
Validation loss: 2.3633474412742275

Epoch: 6| Step: 1
Training loss: 1.01602992275434
Validation loss: 2.3539340787946137

Epoch: 6| Step: 2
Training loss: 2.2385695772722407
Validation loss: 2.387323762728306

Epoch: 6| Step: 3
Training loss: 1.71159719351556
Validation loss: 2.4153034564779685

Epoch: 6| Step: 4
Training loss: 1.7463767827184424
Validation loss: 2.3873250030310293

Epoch: 6| Step: 5
Training loss: 1.7630044850916078
Validation loss: 2.406792459016325

Epoch: 6| Step: 6
Training loss: 1.8529594720565878
Validation loss: 2.4422507779901426

Epoch: 6| Step: 7
Training loss: 2.190430993646512
Validation loss: 2.4304994613182727

Epoch: 6| Step: 8
Training loss: 2.0703608669173343
Validation loss: 2.401466329049553

Epoch: 6| Step: 9
Training loss: 1.8099660589924302
Validation loss: 2.3917679670651153

Epoch: 6| Step: 10
Training loss: 3.1067361800421374
Validation loss: 2.408771184918176

Epoch: 6| Step: 11
Training loss: 1.5184341824423282
Validation loss: 2.380458758746387

Epoch: 6| Step: 12
Training loss: 1.5660416709159326
Validation loss: 2.4007016658968503

Epoch: 6| Step: 13
Training loss: 2.722774552302264
Validation loss: 2.447910812744458

Epoch: 212| Step: 0
Training loss: 1.7991224746023782
Validation loss: 2.364208336077312

Epoch: 6| Step: 1
Training loss: 1.8733235812131335
Validation loss: 2.3794569197882205

Epoch: 6| Step: 2
Training loss: 1.9257930113025106
Validation loss: 2.389885502443325

Epoch: 6| Step: 3
Training loss: 2.0418662019136646
Validation loss: 2.4247178238606053

Epoch: 6| Step: 4
Training loss: 2.937268511802216
Validation loss: 2.3894286685401416

Epoch: 6| Step: 5
Training loss: 1.974877223290948
Validation loss: 2.4403339552308743

Epoch: 6| Step: 6
Training loss: 2.0738435395099573
Validation loss: 2.434417177095298

Epoch: 6| Step: 7
Training loss: 1.7098654955115882
Validation loss: 2.4346721159243656

Epoch: 6| Step: 8
Training loss: 1.9399575060683552
Validation loss: 2.458502953588596

Epoch: 6| Step: 9
Training loss: 1.8477719292911643
Validation loss: 2.4051137392740483

Epoch: 6| Step: 10
Training loss: 2.0644155912136126
Validation loss: 2.433082690319217

Epoch: 6| Step: 11
Training loss: 2.2753508077256512
Validation loss: 2.477264613249164

Epoch: 6| Step: 12
Training loss: 1.618346752473856
Validation loss: 2.4400771709929305

Epoch: 6| Step: 13
Training loss: 1.047120250613264
Validation loss: 2.417269824172375

Epoch: 213| Step: 0
Training loss: 2.0878993035074545
Validation loss: 2.4284405016384225

Epoch: 6| Step: 1
Training loss: 2.562239656946896
Validation loss: 2.419103836930693

Epoch: 6| Step: 2
Training loss: 2.2924683526869654
Validation loss: 2.4381932844248437

Epoch: 6| Step: 3
Training loss: 1.5579483875936846
Validation loss: 2.3860353436959922

Epoch: 6| Step: 4
Training loss: 2.12424657592282
Validation loss: 2.3966216286315327

Epoch: 6| Step: 5
Training loss: 1.0104535414007036
Validation loss: 2.357974847352313

Epoch: 6| Step: 6
Training loss: 1.5146080616747397
Validation loss: 2.3790409444626395

Epoch: 6| Step: 7
Training loss: 1.9436820677634097
Validation loss: 2.4016690457678345

Epoch: 6| Step: 8
Training loss: 2.4571967865167936
Validation loss: 2.417165068518285

Epoch: 6| Step: 9
Training loss: 1.5117230082607178
Validation loss: 2.43297290284669

Epoch: 6| Step: 10
Training loss: 2.2426231040889166
Validation loss: 2.426042361958489

Epoch: 6| Step: 11
Training loss: 1.7321095147385956
Validation loss: 2.395795230286058

Epoch: 6| Step: 12
Training loss: 2.0656501526101936
Validation loss: 2.3995763147276756

Epoch: 6| Step: 13
Training loss: 2.227982667119323
Validation loss: 2.3785510153988216

Epoch: 214| Step: 0
Training loss: 1.8134489534954088
Validation loss: 2.3668513809883813

Epoch: 6| Step: 1
Training loss: 2.2114891199840025
Validation loss: 2.364220836486292

Epoch: 6| Step: 2
Training loss: 2.0139912926372965
Validation loss: 2.409649726556007

Epoch: 6| Step: 3
Training loss: 1.5310125361451945
Validation loss: 2.4174777269298664

Epoch: 6| Step: 4
Training loss: 2.7776216134573057
Validation loss: 2.4069813614496116

Epoch: 6| Step: 5
Training loss: 2.179121155807596
Validation loss: 2.4103252945739135

Epoch: 6| Step: 6
Training loss: 1.9417031136013092
Validation loss: 2.4038354206523964

Epoch: 6| Step: 7
Training loss: 1.8666301837262387
Validation loss: 2.403384287451619

Epoch: 6| Step: 8
Training loss: 2.2664772272419693
Validation loss: 2.41839063685565

Epoch: 6| Step: 9
Training loss: 1.6473885765080676
Validation loss: 2.382462955835021

Epoch: 6| Step: 10
Training loss: 1.841218406473527
Validation loss: 2.349258024655784

Epoch: 6| Step: 11
Training loss: 1.4252940560493883
Validation loss: 2.4468941517703793

Epoch: 6| Step: 12
Training loss: 2.0267983586833385
Validation loss: 2.4030696316159177

Epoch: 6| Step: 13
Training loss: 2.2252470715105677
Validation loss: 2.3544475657539645

Epoch: 215| Step: 0
Training loss: 1.5807208627129712
Validation loss: 2.4085100286758476

Epoch: 6| Step: 1
Training loss: 1.6029007693517867
Validation loss: 2.378689383563751

Epoch: 6| Step: 2
Training loss: 1.8900171989586811
Validation loss: 2.400134126613781

Epoch: 6| Step: 3
Training loss: 1.5303944903161375
Validation loss: 2.3874379162027966

Epoch: 6| Step: 4
Training loss: 1.870749232802692
Validation loss: 2.391754898911161

Epoch: 6| Step: 5
Training loss: 1.8751756585808321
Validation loss: 2.4070046190739434

Epoch: 6| Step: 6
Training loss: 2.026704602932156
Validation loss: 2.373699201169811

Epoch: 6| Step: 7
Training loss: 1.9079950818572247
Validation loss: 2.390277716950326

Epoch: 6| Step: 8
Training loss: 2.06296141116007
Validation loss: 2.3908451726110176

Epoch: 6| Step: 9
Training loss: 2.036465214736382
Validation loss: 2.325434571961026

Epoch: 6| Step: 10
Training loss: 2.1311559706722045
Validation loss: 2.353994154283336

Epoch: 6| Step: 11
Training loss: 2.215223384124284
Validation loss: 2.4139205965778614

Epoch: 6| Step: 12
Training loss: 2.7854123633120116
Validation loss: 2.396968159395547

Epoch: 6| Step: 13
Training loss: 2.2581816374820978
Validation loss: 2.462630140847651

Epoch: 216| Step: 0
Training loss: 1.9074528135610365
Validation loss: 2.3951681775116667

Epoch: 6| Step: 1
Training loss: 1.329282682411998
Validation loss: 2.3911044783169273

Epoch: 6| Step: 2
Training loss: 2.8773863466886667
Validation loss: 2.412371265399009

Epoch: 6| Step: 3
Training loss: 1.6398104144047962
Validation loss: 2.4104179277098647

Epoch: 6| Step: 4
Training loss: 2.2691373762336338
Validation loss: 2.417233291587728

Epoch: 6| Step: 5
Training loss: 1.4526744677343073
Validation loss: 2.410396536626403

Epoch: 6| Step: 6
Training loss: 1.4455201695716418
Validation loss: 2.425834146981409

Epoch: 6| Step: 7
Training loss: 2.1302096515331215
Validation loss: 2.4051304409979575

Epoch: 6| Step: 8
Training loss: 2.192067962671872
Validation loss: 2.4075813887758035

Epoch: 6| Step: 9
Training loss: 2.240166687213035
Validation loss: 2.3758064232941596

Epoch: 6| Step: 10
Training loss: 2.462638533515004
Validation loss: 2.45107120035404

Epoch: 6| Step: 11
Training loss: 1.9420627888469453
Validation loss: 2.4311035849436915

Epoch: 6| Step: 12
Training loss: 1.0222883106086165
Validation loss: 2.4087399875992963

Epoch: 6| Step: 13
Training loss: 2.058123250683117
Validation loss: 2.418717979436905

Epoch: 217| Step: 0
Training loss: 2.1078276433605736
Validation loss: 2.3851324409057053

Epoch: 6| Step: 1
Training loss: 1.746029709701947
Validation loss: 2.399375660162308

Epoch: 6| Step: 2
Training loss: 1.7071754516869106
Validation loss: 2.385782414663782

Epoch: 6| Step: 3
Training loss: 2.1142631125438767
Validation loss: 2.4254394753374315

Epoch: 6| Step: 4
Training loss: 1.2351231299730638
Validation loss: 2.4158350323700652

Epoch: 6| Step: 5
Training loss: 2.4727062925364125
Validation loss: 2.3271483967399424

Epoch: 6| Step: 6
Training loss: 2.0851147347037435
Validation loss: 2.3948156891172268

Epoch: 6| Step: 7
Training loss: 1.7417923004370925
Validation loss: 2.4198149071036124

Epoch: 6| Step: 8
Training loss: 2.2904309033104133
Validation loss: 2.3828601043642172

Epoch: 6| Step: 9
Training loss: 1.9898072627675893
Validation loss: 2.3931172909030227

Epoch: 6| Step: 10
Training loss: 2.432491340582588
Validation loss: 2.3604223616872306

Epoch: 6| Step: 11
Training loss: 1.912333801627649
Validation loss: 2.3744076171930906

Epoch: 6| Step: 12
Training loss: 1.7854792930750432
Validation loss: 2.3836606683232016

Epoch: 6| Step: 13
Training loss: 1.1705572221302862
Validation loss: 2.4058862152005545

Epoch: 218| Step: 0
Training loss: 1.694882527334453
Validation loss: 2.375058301329887

Epoch: 6| Step: 1
Training loss: 2.066984676176941
Validation loss: 2.391479299865896

Epoch: 6| Step: 2
Training loss: 1.622864273394303
Validation loss: 2.3897865557524733

Epoch: 6| Step: 3
Training loss: 1.4162595762381898
Validation loss: 2.399927816023284

Epoch: 6| Step: 4
Training loss: 1.9150784657192117
Validation loss: 2.3687430226013833

Epoch: 6| Step: 5
Training loss: 1.7457643748694944
Validation loss: 2.3983470251274372

Epoch: 6| Step: 6
Training loss: 2.27276559450613
Validation loss: 2.418057459118891

Epoch: 6| Step: 7
Training loss: 2.2766271284848822
Validation loss: 2.451539158690219

Epoch: 6| Step: 8
Training loss: 2.4971909954460463
Validation loss: 2.404864121606367

Epoch: 6| Step: 9
Training loss: 2.339327186790922
Validation loss: 2.3976076451503325

Epoch: 6| Step: 10
Training loss: 2.4759319477435517
Validation loss: 2.364558060173859

Epoch: 6| Step: 11
Training loss: 1.2509615061179213
Validation loss: 2.439364117779939

Epoch: 6| Step: 12
Training loss: 1.703795764669489
Validation loss: 2.375884718148414

Epoch: 6| Step: 13
Training loss: 1.703346238071855
Validation loss: 2.384892516569699

Epoch: 219| Step: 0
Training loss: 1.4916454349193125
Validation loss: 2.3781244324927675

Epoch: 6| Step: 1
Training loss: 1.2419762101805163
Validation loss: 2.3969222342048524

Epoch: 6| Step: 2
Training loss: 2.477882202107181
Validation loss: 2.3654891803290687

Epoch: 6| Step: 3
Training loss: 2.61811434148284
Validation loss: 2.3829411727938776

Epoch: 6| Step: 4
Training loss: 1.587385146424263
Validation loss: 2.3742790768729227

Epoch: 6| Step: 5
Training loss: 2.0521404303596644
Validation loss: 2.3933593053325732

Epoch: 6| Step: 6
Training loss: 2.3347855090806706
Validation loss: 2.365718104328911

Epoch: 6| Step: 7
Training loss: 1.7663551778719764
Validation loss: 2.37252413134867

Epoch: 6| Step: 8
Training loss: 1.7063625256668773
Validation loss: 2.399802263208356

Epoch: 6| Step: 9
Training loss: 1.3350708141190353
Validation loss: 2.400200221210961

Epoch: 6| Step: 10
Training loss: 2.3216281846967908
Validation loss: 2.386888359472865

Epoch: 6| Step: 11
Training loss: 1.7658207877653933
Validation loss: 2.39860546639155

Epoch: 6| Step: 12
Training loss: 1.7898280742063706
Validation loss: 2.4594306849954957

Epoch: 6| Step: 13
Training loss: 1.9077547106789052
Validation loss: 2.3801106326776846

Epoch: 220| Step: 0
Training loss: 1.9686411872947682
Validation loss: 2.3067583033231913

Epoch: 6| Step: 1
Training loss: 2.136061098196461
Validation loss: 2.3634553963617275

Epoch: 6| Step: 2
Training loss: 1.369584603366586
Validation loss: 2.3877616483394064

Epoch: 6| Step: 3
Training loss: 2.652946482337511
Validation loss: 2.410338477423977

Epoch: 6| Step: 4
Training loss: 2.094264636204097
Validation loss: 2.363776299412577

Epoch: 6| Step: 5
Training loss: 1.4190006757254736
Validation loss: 2.3492144318696546

Epoch: 6| Step: 6
Training loss: 2.337323138231992
Validation loss: 2.384974777863275

Epoch: 6| Step: 7
Training loss: 1.4025709557901165
Validation loss: 2.404835817461254

Epoch: 6| Step: 8
Training loss: 2.457555669423716
Validation loss: 2.3849061415242865

Epoch: 6| Step: 9
Training loss: 1.8155608147784017
Validation loss: 2.3921779569979904

Epoch: 6| Step: 10
Training loss: 1.8839378950731565
Validation loss: 2.3962673897988735

Epoch: 6| Step: 11
Training loss: 1.5015914739538443
Validation loss: 2.369894104782859

Epoch: 6| Step: 12
Training loss: 1.8398826902767749
Validation loss: 2.4166656974335092

Epoch: 6| Step: 13
Training loss: 1.5972446946852938
Validation loss: 2.4013980445023098

Epoch: 221| Step: 0
Training loss: 2.478402690554021
Validation loss: 2.3827515135541693

Epoch: 6| Step: 1
Training loss: 1.9099682050325417
Validation loss: 2.3960253866368477

Epoch: 6| Step: 2
Training loss: 1.9674127063508042
Validation loss: 2.40470875225308

Epoch: 6| Step: 3
Training loss: 1.291211181234378
Validation loss: 2.3969657497326433

Epoch: 6| Step: 4
Training loss: 2.2406981303306095
Validation loss: 2.41472474160257

Epoch: 6| Step: 5
Training loss: 2.5977953880734908
Validation loss: 2.4105566032676617

Epoch: 6| Step: 6
Training loss: 1.6700036101387885
Validation loss: 2.4532028979067797

Epoch: 6| Step: 7
Training loss: 1.6718580298587478
Validation loss: 2.398464260317454

Epoch: 6| Step: 8
Training loss: 1.924132595077252
Validation loss: 2.362556164992954

Epoch: 6| Step: 9
Training loss: 1.6778063508871548
Validation loss: 2.4319986430949245

Epoch: 6| Step: 10
Training loss: 1.929363640546955
Validation loss: 2.397764004149777

Epoch: 6| Step: 11
Training loss: 1.493768942485395
Validation loss: 2.403431923817192

Epoch: 6| Step: 12
Training loss: 1.864943876163469
Validation loss: 2.395795276833595

Epoch: 6| Step: 13
Training loss: 1.9443759118975883
Validation loss: 2.4496488514569488

Epoch: 222| Step: 0
Training loss: 1.8419698106112177
Validation loss: 2.381302877255756

Epoch: 6| Step: 1
Training loss: 2.1941458972489287
Validation loss: 2.3779688135015005

Epoch: 6| Step: 2
Training loss: 2.0734621668874085
Validation loss: 2.42302964096253

Epoch: 6| Step: 3
Training loss: 1.5946368573591119
Validation loss: 2.3763867287500235

Epoch: 6| Step: 4
Training loss: 2.1473660103294256
Validation loss: 2.3949224547976793

Epoch: 6| Step: 5
Training loss: 1.6924993141432123
Validation loss: 2.4280893861208677

Epoch: 6| Step: 6
Training loss: 2.5792316258086503
Validation loss: 2.399090907878674

Epoch: 6| Step: 7
Training loss: 1.6546273109792808
Validation loss: 2.3933408461779684

Epoch: 6| Step: 8
Training loss: 1.1617495196025225
Validation loss: 2.4029760761586627

Epoch: 6| Step: 9
Training loss: 2.4056744568384882
Validation loss: 2.4295526947270827

Epoch: 6| Step: 10
Training loss: 1.9854466705883813
Validation loss: 2.3789738077825873

Epoch: 6| Step: 11
Training loss: 2.0315202973328477
Validation loss: 2.4300942235014977

Epoch: 6| Step: 12
Training loss: 1.5248689626459602
Validation loss: 2.4002807573887734

Epoch: 6| Step: 13
Training loss: 1.8215259878570156
Validation loss: 2.418401043448194

Epoch: 223| Step: 0
Training loss: 1.7063394711689526
Validation loss: 2.4532863129425224

Epoch: 6| Step: 1
Training loss: 1.8742024314840988
Validation loss: 2.449583428607863

Epoch: 6| Step: 2
Training loss: 2.4237955661403565
Validation loss: 2.4184517708379585

Epoch: 6| Step: 3
Training loss: 2.091344105848529
Validation loss: 2.4121810962871137

Epoch: 6| Step: 4
Training loss: 1.3737547611088117
Validation loss: 2.4219225531814224

Epoch: 6| Step: 5
Training loss: 2.481482975781667
Validation loss: 2.40230394155843

Epoch: 6| Step: 6
Training loss: 1.7480868372265204
Validation loss: 2.3638373003925177

Epoch: 6| Step: 7
Training loss: 1.5261052175922711
Validation loss: 2.4027103998325283

Epoch: 6| Step: 8
Training loss: 2.2418801764967373
Validation loss: 2.4108072024300937

Epoch: 6| Step: 9
Training loss: 2.28352253215875
Validation loss: 2.4228704941092483

Epoch: 6| Step: 10
Training loss: 1.9440837487716827
Validation loss: 2.417152730019007

Epoch: 6| Step: 11
Training loss: 1.4873159887794947
Validation loss: 2.4306981546396926

Epoch: 6| Step: 12
Training loss: 1.6121622042252894
Validation loss: 2.4326011719200777

Epoch: 6| Step: 13
Training loss: 1.6917161899828088
Validation loss: 2.4148695628392893

Epoch: 224| Step: 0
Training loss: 2.444405677035242
Validation loss: 2.427013285474303

Epoch: 6| Step: 1
Training loss: 2.139432588917153
Validation loss: 2.3730065551017065

Epoch: 6| Step: 2
Training loss: 2.2878843015948447
Validation loss: 2.3940563943880373

Epoch: 6| Step: 3
Training loss: 1.128611701105366
Validation loss: 2.4510779905003033

Epoch: 6| Step: 4
Training loss: 1.9042411600423317
Validation loss: 2.3997550098848603

Epoch: 6| Step: 5
Training loss: 1.778891692104086
Validation loss: 2.374323396099105

Epoch: 6| Step: 6
Training loss: 1.7761486017545172
Validation loss: 2.3453760906411376

Epoch: 6| Step: 7
Training loss: 1.9628380308174662
Validation loss: 2.3882873261570285

Epoch: 6| Step: 8
Training loss: 2.031523466041831
Validation loss: 2.430251551795801

Epoch: 6| Step: 9
Training loss: 1.3283170673390738
Validation loss: 2.4140813996489494

Epoch: 6| Step: 10
Training loss: 1.82836156113335
Validation loss: 2.4195987342283543

Epoch: 6| Step: 11
Training loss: 1.709699487659819
Validation loss: 2.4038165348301224

Epoch: 6| Step: 12
Training loss: 2.080463097994752
Validation loss: 2.4365227062406647

Epoch: 6| Step: 13
Training loss: 1.6958588453743573
Validation loss: 2.3920451436712074

Epoch: 225| Step: 0
Training loss: 1.7156000576742372
Validation loss: 2.3942800279423664

Epoch: 6| Step: 1
Training loss: 1.8870960434900914
Validation loss: 2.3869798378944806

Epoch: 6| Step: 2
Training loss: 1.8543292913663127
Validation loss: 2.361661609613531

Epoch: 6| Step: 3
Training loss: 2.1778242563080075
Validation loss: 2.4170080530087787

Epoch: 6| Step: 4
Training loss: 2.2302673569598124
Validation loss: 2.424970147790956

Epoch: 6| Step: 5
Training loss: 2.143890563093414
Validation loss: 2.376252450237828

Epoch: 6| Step: 6
Training loss: 2.16511548586644
Validation loss: 2.422576143337244

Epoch: 6| Step: 7
Training loss: 1.5038089869370062
Validation loss: 2.381602592870794

Epoch: 6| Step: 8
Training loss: 1.9109606463074638
Validation loss: 2.3424236151312336

Epoch: 6| Step: 9
Training loss: 1.8575751946325052
Validation loss: 2.4034302939627405

Epoch: 6| Step: 10
Training loss: 1.7299043927758382
Validation loss: 2.4370680016811823

Epoch: 6| Step: 11
Training loss: 1.8533158511199463
Validation loss: 2.3762227328890426

Epoch: 6| Step: 12
Training loss: 1.885648814990732
Validation loss: 2.379470898009735

Epoch: 6| Step: 13
Training loss: 1.3707629291036691
Validation loss: 2.410225094792403

Epoch: 226| Step: 0
Training loss: 1.9476684643377342
Validation loss: 2.403857881667286

Epoch: 6| Step: 1
Training loss: 1.543657366486894
Validation loss: 2.365563254687721

Epoch: 6| Step: 2
Training loss: 2.045942254154898
Validation loss: 2.371684770544483

Epoch: 6| Step: 3
Training loss: 1.947442233265816
Validation loss: 2.3741046953720635

Epoch: 6| Step: 4
Training loss: 2.2210875541608646
Validation loss: 2.4287102244717524

Epoch: 6| Step: 5
Training loss: 1.3742787029814305
Validation loss: 2.3936327900615972

Epoch: 6| Step: 6
Training loss: 1.6130768505597517
Validation loss: 2.395486705114438

Epoch: 6| Step: 7
Training loss: 2.031691400545861
Validation loss: 2.437618792794148

Epoch: 6| Step: 8
Training loss: 1.883890690096606
Validation loss: 2.4112314398206203

Epoch: 6| Step: 9
Training loss: 1.6878577665499985
Validation loss: 2.3810346938040072

Epoch: 6| Step: 10
Training loss: 1.7352898736485378
Validation loss: 2.4264984447170095

Epoch: 6| Step: 11
Training loss: 1.8718967188114886
Validation loss: 2.3780379848039193

Epoch: 6| Step: 12
Training loss: 2.488456779768415
Validation loss: 2.3840603556490074

Epoch: 6| Step: 13
Training loss: 2.286375063087346
Validation loss: 2.3951474428251336

Epoch: 227| Step: 0
Training loss: 1.6537386009648094
Validation loss: 2.4103631762612476

Epoch: 6| Step: 1
Training loss: 1.819298457662117
Validation loss: 2.381006558603199

Epoch: 6| Step: 2
Training loss: 2.2023853115397043
Validation loss: 2.3884083272928365

Epoch: 6| Step: 3
Training loss: 1.974904205316861
Validation loss: 2.3912518546914585

Epoch: 6| Step: 4
Training loss: 1.1601863561763426
Validation loss: 2.36164480075551

Epoch: 6| Step: 5
Training loss: 2.358411276330219
Validation loss: 2.421861127852698

Epoch: 6| Step: 6
Training loss: 2.1928001499358287
Validation loss: 2.381651464675962

Epoch: 6| Step: 7
Training loss: 1.8271524825833765
Validation loss: 2.3833649477535244

Epoch: 6| Step: 8
Training loss: 0.9230284829069013
Validation loss: 2.444442587474529

Epoch: 6| Step: 9
Training loss: 2.001753515201139
Validation loss: 2.373978474457811

Epoch: 6| Step: 10
Training loss: 1.8370332086060623
Validation loss: 2.4292938860044053

Epoch: 6| Step: 11
Training loss: 1.247166664983707
Validation loss: 2.3932010118240874

Epoch: 6| Step: 12
Training loss: 2.5054135836602325
Validation loss: 2.441832140062237

Epoch: 6| Step: 13
Training loss: 1.9750478617989196
Validation loss: 2.4434901525020343

Epoch: 228| Step: 0
Training loss: 2.3390125460441116
Validation loss: 2.365591231649799

Epoch: 6| Step: 1
Training loss: 1.9328500261418418
Validation loss: 2.375626807839461

Epoch: 6| Step: 2
Training loss: 1.768581918878563
Validation loss: 2.350514379042367

Epoch: 6| Step: 3
Training loss: 1.448349190564077
Validation loss: 2.3777733862205763

Epoch: 6| Step: 4
Training loss: 1.7886741249951725
Validation loss: 2.4200273985207112

Epoch: 6| Step: 5
Training loss: 2.4878970917090455
Validation loss: 2.372679542352268

Epoch: 6| Step: 6
Training loss: 1.4443937938726938
Validation loss: 2.382905113912407

Epoch: 6| Step: 7
Training loss: 1.9358078119591104
Validation loss: 2.3215335513897175

Epoch: 6| Step: 8
Training loss: 1.8791576066683344
Validation loss: 2.368860584396085

Epoch: 6| Step: 9
Training loss: 1.82074080900664
Validation loss: 2.402808170962946

Epoch: 6| Step: 10
Training loss: 1.7876380013500635
Validation loss: 2.410880700256701

Epoch: 6| Step: 11
Training loss: 1.8926327346150909
Validation loss: 2.4021368372987317

Epoch: 6| Step: 12
Training loss: 2.1143859119680597
Validation loss: 2.35304964095746

Epoch: 6| Step: 13
Training loss: 1.3583987885288906
Validation loss: 2.3897151267795755

Epoch: 229| Step: 0
Training loss: 1.9041322920664698
Validation loss: 2.436741256734861

Epoch: 6| Step: 1
Training loss: 1.9170468478540281
Validation loss: 2.370604434363285

Epoch: 6| Step: 2
Training loss: 1.4892875893539539
Validation loss: 2.4250522970284614

Epoch: 6| Step: 3
Training loss: 1.877441723728029
Validation loss: 2.423581998242994

Epoch: 6| Step: 4
Training loss: 1.5559159989029259
Validation loss: 2.4094317909973406

Epoch: 6| Step: 5
Training loss: 1.861756922834364
Validation loss: 2.4115662983926427

Epoch: 6| Step: 6
Training loss: 1.456805418783937
Validation loss: 2.395666595121249

Epoch: 6| Step: 7
Training loss: 1.8393048511625945
Validation loss: 2.4212036281958493

Epoch: 6| Step: 8
Training loss: 2.2199322411790017
Validation loss: 2.430882385671991

Epoch: 6| Step: 9
Training loss: 1.5582867848317035
Validation loss: 2.436168929854867

Epoch: 6| Step: 10
Training loss: 1.935982632976853
Validation loss: 2.443223151003661

Epoch: 6| Step: 11
Training loss: 2.047639660293227
Validation loss: 2.4746689533721042

Epoch: 6| Step: 12
Training loss: 2.75813269985152
Validation loss: 2.47915597156573

Epoch: 6| Step: 13
Training loss: 1.547036673063685
Validation loss: 2.4178685398744313

Epoch: 230| Step: 0
Training loss: 1.5603985196710648
Validation loss: 2.387004805278462

Epoch: 6| Step: 1
Training loss: 1.709410103223032
Validation loss: 2.3876399916775366

Epoch: 6| Step: 2
Training loss: 2.2064817571622797
Validation loss: 2.412960947156121

Epoch: 6| Step: 3
Training loss: 1.448962248031992
Validation loss: 2.4265148154168275

Epoch: 6| Step: 4
Training loss: 1.6324114877443812
Validation loss: 2.3756767155128093

Epoch: 6| Step: 5
Training loss: 2.1057994915389435
Validation loss: 2.3824061377566323

Epoch: 6| Step: 6
Training loss: 1.7633306399194426
Validation loss: 2.353875349008122

Epoch: 6| Step: 7
Training loss: 1.5773593064816858
Validation loss: 2.400366419504565

Epoch: 6| Step: 8
Training loss: 2.1762403349686434
Validation loss: 2.4086906553656213

Epoch: 6| Step: 9
Training loss: 2.027721215537751
Validation loss: 2.353198378751412

Epoch: 6| Step: 10
Training loss: 2.450640154915502
Validation loss: 2.429806131907078

Epoch: 6| Step: 11
Training loss: 1.981571530025393
Validation loss: 2.362449347300327

Epoch: 6| Step: 12
Training loss: 1.9724733173417384
Validation loss: 2.3996975895363257

Epoch: 6| Step: 13
Training loss: 2.006670675411001
Validation loss: 2.3611714245208484

Epoch: 231| Step: 0
Training loss: 1.7826120623317088
Validation loss: 2.403481799175637

Epoch: 6| Step: 1
Training loss: 1.9597097253915412
Validation loss: 2.382108551893327

Epoch: 6| Step: 2
Training loss: 2.0716723312746503
Validation loss: 2.406770888182926

Epoch: 6| Step: 3
Training loss: 1.6774282475914941
Validation loss: 2.408432176516493

Epoch: 6| Step: 4
Training loss: 1.2028791002926933
Validation loss: 2.3898505465065485

Epoch: 6| Step: 5
Training loss: 2.2821164510637533
Validation loss: 2.377603649468258

Epoch: 6| Step: 6
Training loss: 2.0229558776554355
Validation loss: 2.409005635872443

Epoch: 6| Step: 7
Training loss: 1.5369057041745176
Validation loss: 2.397512537803169

Epoch: 6| Step: 8
Training loss: 1.7303812594717685
Validation loss: 2.4468781840618616

Epoch: 6| Step: 9
Training loss: 1.4492942605306824
Validation loss: 2.4635373868898367

Epoch: 6| Step: 10
Training loss: 1.7672764304641746
Validation loss: 2.4134538069426874

Epoch: 6| Step: 11
Training loss: 2.24896364716442
Validation loss: 2.346503480000867

Epoch: 6| Step: 12
Training loss: 2.4200866002752943
Validation loss: 2.439007795745368

Epoch: 6| Step: 13
Training loss: 1.49255103032015
Validation loss: 2.414221153909206

Epoch: 232| Step: 0
Training loss: 2.405494274017617
Validation loss: 2.390138301358424

Epoch: 6| Step: 1
Training loss: 1.540130554461659
Validation loss: 2.381090992816604

Epoch: 6| Step: 2
Training loss: 2.3673088621749137
Validation loss: 2.4257956968356873

Epoch: 6| Step: 3
Training loss: 2.0006207456486904
Validation loss: 2.452625452399854

Epoch: 6| Step: 4
Training loss: 2.0614990348582354
Validation loss: 2.3757077033252023

Epoch: 6| Step: 5
Training loss: 1.7668665344013885
Validation loss: 2.415026921730891

Epoch: 6| Step: 6
Training loss: 1.7006059267992601
Validation loss: 2.3772964514728336

Epoch: 6| Step: 7
Training loss: 2.1032585475742955
Validation loss: 2.3949703691893047

Epoch: 6| Step: 8
Training loss: 1.3869343334844477
Validation loss: 2.4015805158951404

Epoch: 6| Step: 9
Training loss: 1.4648251951949856
Validation loss: 2.397054154860493

Epoch: 6| Step: 10
Training loss: 1.698645062998397
Validation loss: 2.3877062565802496

Epoch: 6| Step: 11
Training loss: 2.1234367454813783
Validation loss: 2.3370455300243713

Epoch: 6| Step: 12
Training loss: 1.9202431053988418
Validation loss: 2.411893346414994

Epoch: 6| Step: 13
Training loss: 1.065248748492079
Validation loss: 2.3407947177933597

Epoch: 233| Step: 0
Training loss: 1.9924475406647537
Validation loss: 2.4173578409720125

Epoch: 6| Step: 1
Training loss: 1.9851207983701404
Validation loss: 2.40246610425773

Epoch: 6| Step: 2
Training loss: 1.8093020409614438
Validation loss: 2.367081223795484

Epoch: 6| Step: 3
Training loss: 1.8798764711743694
Validation loss: 2.417866438909866

Epoch: 6| Step: 4
Training loss: 2.055734809872253
Validation loss: 2.3785776146742097

Epoch: 6| Step: 5
Training loss: 2.0450213243263415
Validation loss: 2.3874561654338184

Epoch: 6| Step: 6
Training loss: 1.199425048976587
Validation loss: 2.396703384663877

Epoch: 6| Step: 7
Training loss: 1.8141380668889218
Validation loss: 2.3632092108205143

Epoch: 6| Step: 8
Training loss: 2.1112612732246947
Validation loss: 2.411447872682336

Epoch: 6| Step: 9
Training loss: 2.4377897041505854
Validation loss: 2.3907898791009186

Epoch: 6| Step: 10
Training loss: 1.5540937507167467
Validation loss: 2.4125847715870923

Epoch: 6| Step: 11
Training loss: 1.365830974627249
Validation loss: 2.3901664084381737

Epoch: 6| Step: 12
Training loss: 1.5298419628925735
Validation loss: 2.3829894329826136

Epoch: 6| Step: 13
Training loss: 2.1047529656438826
Validation loss: 2.371818687229516

Epoch: 234| Step: 0
Training loss: 1.9377993075618871
Validation loss: 2.4272150113716235

Epoch: 6| Step: 1
Training loss: 2.1295433840894713
Validation loss: 2.3972843823017267

Epoch: 6| Step: 2
Training loss: 1.700817960413916
Validation loss: 2.4054114941399654

Epoch: 6| Step: 3
Training loss: 2.3370443420186273
Validation loss: 2.377706060106501

Epoch: 6| Step: 4
Training loss: 1.6383962842787392
Validation loss: 2.428868242986274

Epoch: 6| Step: 5
Training loss: 1.9887318878020408
Validation loss: 2.3702246417250787

Epoch: 6| Step: 6
Training loss: 1.5051212307588402
Validation loss: 2.3928379039523175

Epoch: 6| Step: 7
Training loss: 1.9343181447685032
Validation loss: 2.3828416520972535

Epoch: 6| Step: 8
Training loss: 1.7119714408524558
Validation loss: 2.3832024389536994

Epoch: 6| Step: 9
Training loss: 1.8064226008647697
Validation loss: 2.397429614389492

Epoch: 6| Step: 10
Training loss: 2.271744244996089
Validation loss: 2.3679616030537507

Epoch: 6| Step: 11
Training loss: 1.5537720098187164
Validation loss: 2.361260890211301

Epoch: 6| Step: 12
Training loss: 1.763859228784226
Validation loss: 2.4202969504477805

Epoch: 6| Step: 13
Training loss: 2.0539247670867935
Validation loss: 2.3720969531044

Epoch: 235| Step: 0
Training loss: 1.9288867107404453
Validation loss: 2.3748260557403507

Epoch: 6| Step: 1
Training loss: 2.0298734255261404
Validation loss: 2.419711386273287

Epoch: 6| Step: 2
Training loss: 1.9766649061369923
Validation loss: 2.399515872411572

Epoch: 6| Step: 3
Training loss: 2.165253569662237
Validation loss: 2.439093506173538

Epoch: 6| Step: 4
Training loss: 1.3139891577901857
Validation loss: 2.3831190385805745

Epoch: 6| Step: 5
Training loss: 1.7392343030108546
Validation loss: 2.4070018749064372

Epoch: 6| Step: 6
Training loss: 1.7372681140534445
Validation loss: 2.3733836374739203

Epoch: 6| Step: 7
Training loss: 2.426607884893307
Validation loss: 2.4231680835466536

Epoch: 6| Step: 8
Training loss: 1.3178612340139226
Validation loss: 2.4279048803274876

Epoch: 6| Step: 9
Training loss: 1.7243531880342091
Validation loss: 2.3985051152941437

Epoch: 6| Step: 10
Training loss: 2.2785800306719004
Validation loss: 2.41487887947782

Epoch: 6| Step: 11
Training loss: 1.4580596485364328
Validation loss: 2.374418585808956

Epoch: 6| Step: 12
Training loss: 2.217915122689567
Validation loss: 2.3644116134996227

Epoch: 6| Step: 13
Training loss: 0.65281125979308
Validation loss: 2.381382406772372

Epoch: 236| Step: 0
Training loss: 1.5695211209871798
Validation loss: 2.4269434982662945

Epoch: 6| Step: 1
Training loss: 2.224826604537434
Validation loss: 2.4132340339707867

Epoch: 6| Step: 2
Training loss: 2.0846597136765923
Validation loss: 2.357167115539681

Epoch: 6| Step: 3
Training loss: 1.6693404049789582
Validation loss: 2.391112693173696

Epoch: 6| Step: 4
Training loss: 1.8874130077399298
Validation loss: 2.4324715895966014

Epoch: 6| Step: 5
Training loss: 1.9969737283719737
Validation loss: 2.398275638928134

Epoch: 6| Step: 6
Training loss: 1.962110373823127
Validation loss: 2.3744313304585427

Epoch: 6| Step: 7
Training loss: 1.4932106065699908
Validation loss: 2.384812422836901

Epoch: 6| Step: 8
Training loss: 1.3266406122761054
Validation loss: 2.387976838461662

Epoch: 6| Step: 9
Training loss: 1.9711161124963874
Validation loss: 2.3826621107832375

Epoch: 6| Step: 10
Training loss: 2.290667599311849
Validation loss: 2.3856523745457836

Epoch: 6| Step: 11
Training loss: 2.0602015779996354
Validation loss: 2.431910915831602

Epoch: 6| Step: 12
Training loss: 1.4353779596093752
Validation loss: 2.3719080231471956

Epoch: 6| Step: 13
Training loss: 1.8578076207744156
Validation loss: 2.4333841194093275

Epoch: 237| Step: 0
Training loss: 2.178645387327723
Validation loss: 2.414544794585418

Epoch: 6| Step: 1
Training loss: 1.8848954072059163
Validation loss: 2.3909812504701637

Epoch: 6| Step: 2
Training loss: 1.6976258276483815
Validation loss: 2.405561421335008

Epoch: 6| Step: 3
Training loss: 1.8418979070952177
Validation loss: 2.381616910491079

Epoch: 6| Step: 4
Training loss: 2.242023953843253
Validation loss: 2.427206709573159

Epoch: 6| Step: 5
Training loss: 2.1437775724100345
Validation loss: 2.3996390182756175

Epoch: 6| Step: 6
Training loss: 1.5521421826703279
Validation loss: 2.3956554530498004

Epoch: 6| Step: 7
Training loss: 1.211211339689862
Validation loss: 2.3756691886377754

Epoch: 6| Step: 8
Training loss: 1.7646947114721787
Validation loss: 2.3197656736150734

Epoch: 6| Step: 9
Training loss: 1.9326226155810584
Validation loss: 2.3680516214490113

Epoch: 6| Step: 10
Training loss: 1.6029197338376682
Validation loss: 2.3403580138608833

Epoch: 6| Step: 11
Training loss: 1.8528242359249723
Validation loss: 2.3781648165402713

Epoch: 6| Step: 12
Training loss: 1.5665002352327475
Validation loss: 2.3834886403564255

Epoch: 6| Step: 13
Training loss: 1.846483112203232
Validation loss: 2.392914772148718

Epoch: 238| Step: 0
Training loss: 1.7146298355464853
Validation loss: 2.3891106241330506

Epoch: 6| Step: 1
Training loss: 1.8238304100586056
Validation loss: 2.3295972196295796

Epoch: 6| Step: 2
Training loss: 2.3127397979950057
Validation loss: 2.40213957368358

Epoch: 6| Step: 3
Training loss: 2.171100066547464
Validation loss: 2.4128016164355253

Epoch: 6| Step: 4
Training loss: 1.6561039554336565
Validation loss: 2.413452967781628

Epoch: 6| Step: 5
Training loss: 2.0169383656773356
Validation loss: 2.437084445496122

Epoch: 6| Step: 6
Training loss: 1.7248018012693833
Validation loss: 2.4108239904563877

Epoch: 6| Step: 7
Training loss: 1.5299499598279798
Validation loss: 2.4202892742272475

Epoch: 6| Step: 8
Training loss: 1.1332681200020802
Validation loss: 2.4312341717965773

Epoch: 6| Step: 9
Training loss: 1.4367391811990373
Validation loss: 2.4047790791782626

Epoch: 6| Step: 10
Training loss: 1.9490758809114594
Validation loss: 2.4580382369346885

Epoch: 6| Step: 11
Training loss: 2.3865569164395124
Validation loss: 2.4325461414700458

Epoch: 6| Step: 12
Training loss: 2.246040250721551
Validation loss: 2.501939054387787

Epoch: 6| Step: 13
Training loss: 1.4810553925874872
Validation loss: 2.448609968217843

Epoch: 239| Step: 0
Training loss: 1.823731383868579
Validation loss: 2.3503862221131278

Epoch: 6| Step: 1
Training loss: 2.0291323847554357
Validation loss: 2.4004090758658467

Epoch: 6| Step: 2
Training loss: 1.3888743664724021
Validation loss: 2.399888342991141

Epoch: 6| Step: 3
Training loss: 1.7019912725957755
Validation loss: 2.3618682420305332

Epoch: 6| Step: 4
Training loss: 1.741753083538569
Validation loss: 2.3490114654635725

Epoch: 6| Step: 5
Training loss: 1.5091245802865558
Validation loss: 2.4132614168549162

Epoch: 6| Step: 6
Training loss: 1.5584218018794662
Validation loss: 2.4264734684897795

Epoch: 6| Step: 7
Training loss: 1.701545612962504
Validation loss: 2.3775438136331384

Epoch: 6| Step: 8
Training loss: 1.5417241352126814
Validation loss: 2.386418267501778

Epoch: 6| Step: 9
Training loss: 2.138031216471121
Validation loss: 2.3779277620166464

Epoch: 6| Step: 10
Training loss: 2.2867167565037647
Validation loss: 2.39592675878018

Epoch: 6| Step: 11
Training loss: 2.4164493945439043
Validation loss: 2.4615831857904262

Epoch: 6| Step: 12
Training loss: 1.8457485940166536
Validation loss: 2.452540832653266

Epoch: 6| Step: 13
Training loss: 1.1744637442490429
Validation loss: 2.4184638891140686

Epoch: 240| Step: 0
Training loss: 2.037476489159611
Validation loss: 2.385057030945255

Epoch: 6| Step: 1
Training loss: 1.7727265802573249
Validation loss: 2.353427246678295

Epoch: 6| Step: 2
Training loss: 1.7378893464028646
Validation loss: 2.391332900214352

Epoch: 6| Step: 3
Training loss: 2.0516278944321056
Validation loss: 2.3611709625344015

Epoch: 6| Step: 4
Training loss: 1.5962796051219446
Validation loss: 2.347740417121584

Epoch: 6| Step: 5
Training loss: 1.75468281501559
Validation loss: 2.4040556715915016

Epoch: 6| Step: 6
Training loss: 1.9679826118856345
Validation loss: 2.391542894795843

Epoch: 6| Step: 7
Training loss: 2.1649854323885958
Validation loss: 2.3840056241843097

Epoch: 6| Step: 8
Training loss: 1.46602759779471
Validation loss: 2.3650781766812874

Epoch: 6| Step: 9
Training loss: 1.6977757432491591
Validation loss: 2.39867957295361

Epoch: 6| Step: 10
Training loss: 1.9997376627531358
Validation loss: 2.371250971592195

Epoch: 6| Step: 11
Training loss: 1.5874922324163283
Validation loss: 2.4275786593166333

Epoch: 6| Step: 12
Training loss: 1.6172629076197447
Validation loss: 2.357237638425196

Epoch: 6| Step: 13
Training loss: 1.8873564153966822
Validation loss: 2.3992924458653735

Epoch: 241| Step: 0
Training loss: 1.5227813872836906
Validation loss: 2.372762054186174

Epoch: 6| Step: 1
Training loss: 1.9476295980442426
Validation loss: 2.4079186053432635

Epoch: 6| Step: 2
Training loss: 2.6014484918947454
Validation loss: 2.3591358541980743

Epoch: 6| Step: 3
Training loss: 1.2909479397619639
Validation loss: 2.405496532327693

Epoch: 6| Step: 4
Training loss: 2.3662903347698676
Validation loss: 2.3950882240343834

Epoch: 6| Step: 5
Training loss: 1.6058352161205731
Validation loss: 2.433589938130864

Epoch: 6| Step: 6
Training loss: 1.8215305689828578
Validation loss: 2.438354208938755

Epoch: 6| Step: 7
Training loss: 1.7093354131658183
Validation loss: 2.456773874062946

Epoch: 6| Step: 8
Training loss: 1.63617677295977
Validation loss: 2.4528465763538327

Epoch: 6| Step: 9
Training loss: 1.2240551632935686
Validation loss: 2.464548966776309

Epoch: 6| Step: 10
Training loss: 1.6726674136092605
Validation loss: 2.4294856807720993

Epoch: 6| Step: 11
Training loss: 2.2367626317789853
Validation loss: 2.400888280916485

Epoch: 6| Step: 12
Training loss: 1.867017155622092
Validation loss: 2.418584015979876

Epoch: 6| Step: 13
Training loss: 1.7442969992189905
Validation loss: 2.406609820345975

Epoch: 242| Step: 0
Training loss: 1.5228032283395025
Validation loss: 2.4046483488569206

Epoch: 6| Step: 1
Training loss: 2.4502634257172664
Validation loss: 2.4027578847134627

Epoch: 6| Step: 2
Training loss: 1.8975679894531232
Validation loss: 2.3978615030714048

Epoch: 6| Step: 3
Training loss: 1.6488573163486626
Validation loss: 2.3922804306428573

Epoch: 6| Step: 4
Training loss: 1.9703677963011894
Validation loss: 2.4068351488789923

Epoch: 6| Step: 5
Training loss: 1.570650889816666
Validation loss: 2.3590605945372523

Epoch: 6| Step: 6
Training loss: 2.224909546974442
Validation loss: 2.351172538640984

Epoch: 6| Step: 7
Training loss: 1.4958591526250684
Validation loss: 2.3904499475381056

Epoch: 6| Step: 8
Training loss: 2.1093028868605064
Validation loss: 2.423862260405231

Epoch: 6| Step: 9
Training loss: 1.4788187540150288
Validation loss: 2.341784795692854

Epoch: 6| Step: 10
Training loss: 0.9879195263769065
Validation loss: 2.3853916475522876

Epoch: 6| Step: 11
Training loss: 2.3714917020224275
Validation loss: 2.4079384123974212

Epoch: 6| Step: 12
Training loss: 1.5060848161337634
Validation loss: 2.3673826104956843

Epoch: 6| Step: 13
Training loss: 1.781119023911849
Validation loss: 2.3624297600421476

Epoch: 243| Step: 0
Training loss: 2.0438921211127026
Validation loss: 2.354308384266825

Epoch: 6| Step: 1
Training loss: 1.8035464952787672
Validation loss: 2.3934737482709383

Epoch: 6| Step: 2
Training loss: 2.29274830578962
Validation loss: 2.4012828710465244

Epoch: 6| Step: 3
Training loss: 1.626576905640234
Validation loss: 2.3400812937341895

Epoch: 6| Step: 4
Training loss: 1.941437811182403
Validation loss: 2.374892457428086

Epoch: 6| Step: 5
Training loss: 1.4797160064303823
Validation loss: 2.345751756771539

Epoch: 6| Step: 6
Training loss: 1.4380281556175725
Validation loss: 2.3967550365743637

Epoch: 6| Step: 7
Training loss: 1.8327006924633158
Validation loss: 2.4309480365659883

Epoch: 6| Step: 8
Training loss: 1.5984319095756192
Validation loss: 2.4121792534094926

Epoch: 6| Step: 9
Training loss: 1.369734304795957
Validation loss: 2.381927358647619

Epoch: 6| Step: 10
Training loss: 1.3853124230348448
Validation loss: 2.4254547719014816

Epoch: 6| Step: 11
Training loss: 1.8311484351001228
Validation loss: 2.3619260496514225

Epoch: 6| Step: 12
Training loss: 2.18552745711604
Validation loss: 2.382261586766219

Epoch: 6| Step: 13
Training loss: 2.346911218518639
Validation loss: 2.4030109825189707

Epoch: 244| Step: 0
Training loss: 1.9714054183311187
Validation loss: 2.4074091852630466

Epoch: 6| Step: 1
Training loss: 1.4684436559781484
Validation loss: 2.4114477621186223

Epoch: 6| Step: 2
Training loss: 1.9197378293493772
Validation loss: 2.357166563041902

Epoch: 6| Step: 3
Training loss: 1.7098126480577134
Validation loss: 2.415398158362001

Epoch: 6| Step: 4
Training loss: 1.2089989681318374
Validation loss: 2.3672309058453913

Epoch: 6| Step: 5
Training loss: 1.7868119789690398
Validation loss: 2.4122638043330284

Epoch: 6| Step: 6
Training loss: 1.7131900677854646
Validation loss: 2.3869925906572425

Epoch: 6| Step: 7
Training loss: 1.7647374715969646
Validation loss: 2.4097595936168186

Epoch: 6| Step: 8
Training loss: 1.1366027563106982
Validation loss: 2.4545420696138804

Epoch: 6| Step: 9
Training loss: 2.904228081366233
Validation loss: 2.4196017046225804

Epoch: 6| Step: 10
Training loss: 1.418379626895145
Validation loss: 2.4518997333443453

Epoch: 6| Step: 11
Training loss: 1.831770042554482
Validation loss: 2.4435327810241745

Epoch: 6| Step: 12
Training loss: 1.9031936031811307
Validation loss: 2.4298628418125894

Epoch: 6| Step: 13
Training loss: 2.3331878707594016
Validation loss: 2.358494814525097

Epoch: 245| Step: 0
Training loss: 1.4973065512756705
Validation loss: 2.3867233332983413

Epoch: 6| Step: 1
Training loss: 2.066443516876559
Validation loss: 2.40760572777423

Epoch: 6| Step: 2
Training loss: 1.832163336248201
Validation loss: 2.3450383955420233

Epoch: 6| Step: 3
Training loss: 1.6562521592611956
Validation loss: 2.393351631620183

Epoch: 6| Step: 4
Training loss: 1.27422214977716
Validation loss: 2.3598631764170936

Epoch: 6| Step: 5
Training loss: 2.3574683967810235
Validation loss: 2.386785251002539

Epoch: 6| Step: 6
Training loss: 2.441553901785145
Validation loss: 2.4340906692749695

Epoch: 6| Step: 7
Training loss: 1.7764891865146455
Validation loss: 2.378083209053721

Epoch: 6| Step: 8
Training loss: 2.067348445702191
Validation loss: 2.3904650803112153

Epoch: 6| Step: 9
Training loss: 1.7325526105370679
Validation loss: 2.434497072053977

Epoch: 6| Step: 10
Training loss: 1.3635540446085588
Validation loss: 2.4128622237194035

Epoch: 6| Step: 11
Training loss: 1.6308014088454066
Validation loss: 2.374977959064826

Epoch: 6| Step: 12
Training loss: 1.304129704001371
Validation loss: 2.4121115420911616

Epoch: 6| Step: 13
Training loss: 1.535718741996611
Validation loss: 2.422677321156757

Epoch: 246| Step: 0
Training loss: 1.7268472151949241
Validation loss: 2.410208619830956

Epoch: 6| Step: 1
Training loss: 1.8483515070488132
Validation loss: 2.3382667569752456

Epoch: 6| Step: 2
Training loss: 1.9251019438465227
Validation loss: 2.4091052420332657

Epoch: 6| Step: 3
Training loss: 2.097330021842061
Validation loss: 2.3915030603945397

Epoch: 6| Step: 4
Training loss: 1.7632934569889962
Validation loss: 2.411908745365034

Epoch: 6| Step: 5
Training loss: 1.3034220514728707
Validation loss: 2.3867746544677977

Epoch: 6| Step: 6
Training loss: 1.84771638090909
Validation loss: 2.392221840136112

Epoch: 6| Step: 7
Training loss: 1.6105896893421245
Validation loss: 2.3777207354297434

Epoch: 6| Step: 8
Training loss: 1.9252590995903434
Validation loss: 2.3640531804183076

Epoch: 6| Step: 9
Training loss: 1.6509366729116164
Validation loss: 2.4721805045047067

Epoch: 6| Step: 10
Training loss: 1.5419918782654851
Validation loss: 2.3969402422380788

Epoch: 6| Step: 11
Training loss: 1.8778561772615197
Validation loss: 2.443626723557955

Epoch: 6| Step: 12
Training loss: 2.6170604162534263
Validation loss: 2.4586921961463175

Epoch: 6| Step: 13
Training loss: 1.5493084041414054
Validation loss: 2.3766337886387987

Epoch: 247| Step: 0
Training loss: 2.549232374851059
Validation loss: 2.395264912748866

Epoch: 6| Step: 1
Training loss: 2.0674502758610567
Validation loss: 2.4195794135976354

Epoch: 6| Step: 2
Training loss: 2.067913349535058
Validation loss: 2.3602506461472985

Epoch: 6| Step: 3
Training loss: 1.7626104360841337
Validation loss: 2.396408000007528

Epoch: 6| Step: 4
Training loss: 1.5872451577676756
Validation loss: 2.4064829707848383

Epoch: 6| Step: 5
Training loss: 1.2511692777160688
Validation loss: 2.4529063342420288

Epoch: 6| Step: 6
Training loss: 1.306053177821418
Validation loss: 2.4335603094278135

Epoch: 6| Step: 7
Training loss: 1.7203085335418127
Validation loss: 2.4308775608118434

Epoch: 6| Step: 8
Training loss: 1.7614763520272478
Validation loss: 2.383886180983557

Epoch: 6| Step: 9
Training loss: 1.6587696702677692
Validation loss: 2.4023397834318896

Epoch: 6| Step: 10
Training loss: 1.5305720015509765
Validation loss: 2.3726193629908905

Epoch: 6| Step: 11
Training loss: 1.8965842537945243
Validation loss: 2.376007271264457

Epoch: 6| Step: 12
Training loss: 1.703641620639719
Validation loss: 2.399896843976657

Epoch: 6| Step: 13
Training loss: 1.266008766294625
Validation loss: 2.4116587605506843

Epoch: 248| Step: 0
Training loss: 2.24981180039732
Validation loss: 2.378677391371137

Epoch: 6| Step: 1
Training loss: 2.3210757249397402
Validation loss: 2.4258327171199294

Epoch: 6| Step: 2
Training loss: 1.3316250626451125
Validation loss: 2.3732982717554427

Epoch: 6| Step: 3
Training loss: 1.5421769440356343
Validation loss: 2.3496701655107226

Epoch: 6| Step: 4
Training loss: 1.4602958371636048
Validation loss: 2.3768402843172725

Epoch: 6| Step: 5
Training loss: 1.9781893944164914
Validation loss: 2.3688547571472927

Epoch: 6| Step: 6
Training loss: 1.5091988312642668
Validation loss: 2.3844847928878616

Epoch: 6| Step: 7
Training loss: 1.4010514704516084
Validation loss: 2.408743671165601

Epoch: 6| Step: 8
Training loss: 2.027997038438429
Validation loss: 2.3901215613733404

Epoch: 6| Step: 9
Training loss: 2.0490202400023305
Validation loss: 2.3735019436729496

Epoch: 6| Step: 10
Training loss: 1.9991915380095033
Validation loss: 2.4211771933265296

Epoch: 6| Step: 11
Training loss: 1.85694200351846
Validation loss: 2.354574781393428

Epoch: 6| Step: 12
Training loss: 1.2066943738629665
Validation loss: 2.384633058930927

Epoch: 6| Step: 13
Training loss: 1.60616122345561
Validation loss: 2.412552224635954

Epoch: 249| Step: 0
Training loss: 1.781562576976454
Validation loss: 2.3754072676693885

Epoch: 6| Step: 1
Training loss: 1.2562096850250974
Validation loss: 2.4147943829604066

Epoch: 6| Step: 2
Training loss: 1.7442646046623433
Validation loss: 2.3479236470088947

Epoch: 6| Step: 3
Training loss: 1.667751181927861
Validation loss: 2.4238056301038133

Epoch: 6| Step: 4
Training loss: 1.54163103663881
Validation loss: 2.418647466361625

Epoch: 6| Step: 5
Training loss: 1.6008623779352111
Validation loss: 2.3910214586471557

Epoch: 6| Step: 6
Training loss: 1.6373451509132075
Validation loss: 2.375281512076018

Epoch: 6| Step: 7
Training loss: 1.9679435410348245
Validation loss: 2.393896349456771

Epoch: 6| Step: 8
Training loss: 1.7114765589605188
Validation loss: 2.4088545373829318

Epoch: 6| Step: 9
Training loss: 2.0941358751592865
Validation loss: 2.422091484119687

Epoch: 6| Step: 10
Training loss: 1.0997913271038795
Validation loss: 2.4205019352981574

Epoch: 6| Step: 11
Training loss: 2.5353016392848886
Validation loss: 2.336154945869004

Epoch: 6| Step: 12
Training loss: 2.130448704769675
Validation loss: 2.3452515438909938

Epoch: 6| Step: 13
Training loss: 1.6929534108690916
Validation loss: 2.4618488229303654

Epoch: 250| Step: 0
Training loss: 2.002922545391947
Validation loss: 2.39217739115279

Epoch: 6| Step: 1
Training loss: 1.3143050179781681
Validation loss: 2.4579010272736097

Epoch: 6| Step: 2
Training loss: 1.4190325149026115
Validation loss: 2.3456684565695913

Epoch: 6| Step: 3
Training loss: 2.2164306338088013
Validation loss: 2.3737086864191994

Epoch: 6| Step: 4
Training loss: 1.5093673042432887
Validation loss: 2.388491619183202

Epoch: 6| Step: 5
Training loss: 1.7989955165652376
Validation loss: 2.401626287426324

Epoch: 6| Step: 6
Training loss: 2.130627529493035
Validation loss: 2.419611498368473

Epoch: 6| Step: 7
Training loss: 1.470742841896069
Validation loss: 2.406750418560397

Epoch: 6| Step: 8
Training loss: 1.9479326733698188
Validation loss: 2.3920103677321984

Epoch: 6| Step: 9
Training loss: 1.769532125780171
Validation loss: 2.40316842983752

Epoch: 6| Step: 10
Training loss: 1.6113756207488676
Validation loss: 2.345682300614776

Epoch: 6| Step: 11
Training loss: 1.9362670913444346
Validation loss: 2.3861844910704644

Epoch: 6| Step: 12
Training loss: 2.0230043161132145
Validation loss: 2.425671745049183

Epoch: 6| Step: 13
Training loss: 1.559022313905849
Validation loss: 2.4272464079674343

Epoch: 251| Step: 0
Training loss: 1.9775149496986713
Validation loss: 2.382036770530789

Epoch: 6| Step: 1
Training loss: 2.249458247767063
Validation loss: 2.353325316589114

Epoch: 6| Step: 2
Training loss: 1.7134393663411862
Validation loss: 2.3990991627096077

Epoch: 6| Step: 3
Training loss: 1.9252314837102422
Validation loss: 2.4129162740768613

Epoch: 6| Step: 4
Training loss: 1.5505749928022936
Validation loss: 2.3925720967494555

Epoch: 6| Step: 5
Training loss: 1.3484060661745276
Validation loss: 2.4087334386387336

Epoch: 6| Step: 6
Training loss: 2.509490500484408
Validation loss: 2.356410846718491

Epoch: 6| Step: 7
Training loss: 1.2218759990405124
Validation loss: 2.43720021072641

Epoch: 6| Step: 8
Training loss: 1.360085400396409
Validation loss: 2.384112375022628

Epoch: 6| Step: 9
Training loss: 1.9346117210674352
Validation loss: 2.4591362547323046

Epoch: 6| Step: 10
Training loss: 1.8400479667050504
Validation loss: 2.3944106562520395

Epoch: 6| Step: 11
Training loss: 1.6583055660025343
Validation loss: 2.436816378644338

Epoch: 6| Step: 12
Training loss: 1.361296950302121
Validation loss: 2.3726848680485055

Epoch: 6| Step: 13
Training loss: 1.6269655078357175
Validation loss: 2.4200780685152856

Epoch: 252| Step: 0
Training loss: 1.5245840599779077
Validation loss: 2.392507085827503

Epoch: 6| Step: 1
Training loss: 1.9922973602520986
Validation loss: 2.365768112669894

Epoch: 6| Step: 2
Training loss: 1.8870151831860567
Validation loss: 2.3812266128507353

Epoch: 6| Step: 3
Training loss: 1.9698628504690887
Validation loss: 2.3643172320679926

Epoch: 6| Step: 4
Training loss: 1.569595780667147
Validation loss: 2.392632948594921

Epoch: 6| Step: 5
Training loss: 1.5616874107739125
Validation loss: 2.432457269359597

Epoch: 6| Step: 6
Training loss: 1.9605386031926952
Validation loss: 2.4053500127410277

Epoch: 6| Step: 7
Training loss: 1.5838492790965475
Validation loss: 2.373697637301541

Epoch: 6| Step: 8
Training loss: 1.4483613719501511
Validation loss: 2.4058542340298303

Epoch: 6| Step: 9
Training loss: 1.5087229297551359
Validation loss: 2.371509586424347

Epoch: 6| Step: 10
Training loss: 1.219177562345958
Validation loss: 2.3762284811131447

Epoch: 6| Step: 11
Training loss: 1.34686335582966
Validation loss: 2.4052454360778146

Epoch: 6| Step: 12
Training loss: 2.7006496495589882
Validation loss: 2.3874541960913302

Epoch: 6| Step: 13
Training loss: 1.6785802696018388
Validation loss: 2.3856025143723176

Epoch: 253| Step: 0
Training loss: 1.6050374363606417
Validation loss: 2.397280731923809

Epoch: 6| Step: 1
Training loss: 2.191192562136051
Validation loss: 2.3636402903865616

Epoch: 6| Step: 2
Training loss: 1.6812596969608467
Validation loss: 2.4168723835302184

Epoch: 6| Step: 3
Training loss: 1.1763532900887905
Validation loss: 2.3168837666530258

Epoch: 6| Step: 4
Training loss: 1.6680341435283752
Validation loss: 2.402390052288506

Epoch: 6| Step: 5
Training loss: 2.5019678000764976
Validation loss: 2.3425434969525973

Epoch: 6| Step: 6
Training loss: 1.250499148844811
Validation loss: 2.3651349438587066

Epoch: 6| Step: 7
Training loss: 1.5655235029202854
Validation loss: 2.3828819508200856

Epoch: 6| Step: 8
Training loss: 1.8500446262647674
Validation loss: 2.413006768953312

Epoch: 6| Step: 9
Training loss: 1.9963176922676142
Validation loss: 2.4269932041776565

Epoch: 6| Step: 10
Training loss: 1.7675185051236635
Validation loss: 2.3469613938338534

Epoch: 6| Step: 11
Training loss: 1.4779530592550387
Validation loss: 2.3344098287262622

Epoch: 6| Step: 12
Training loss: 1.835058513196974
Validation loss: 2.35734220404576

Epoch: 6| Step: 13
Training loss: 1.3411455864273387
Validation loss: 2.3309139249745816

Epoch: 254| Step: 0
Training loss: 1.5768279987214457
Validation loss: 2.379848327431305

Epoch: 6| Step: 1
Training loss: 1.6816816690466987
Validation loss: 2.3809449175455457

Epoch: 6| Step: 2
Training loss: 1.6763918460053273
Validation loss: 2.3555846158842764

Epoch: 6| Step: 3
Training loss: 2.2250336333743848
Validation loss: 2.3580025289330386

Epoch: 6| Step: 4
Training loss: 1.4062196092500603
Validation loss: 2.4126036222437555

Epoch: 6| Step: 5
Training loss: 1.7841933176306133
Validation loss: 2.3714027247398275

Epoch: 6| Step: 6
Training loss: 1.4957167347099294
Validation loss: 2.3807393475271406

Epoch: 6| Step: 7
Training loss: 1.3860491788266744
Validation loss: 2.3885783518270824

Epoch: 6| Step: 8
Training loss: 1.76878223187629
Validation loss: 2.4125784766675866

Epoch: 6| Step: 9
Training loss: 1.88459383324917
Validation loss: 2.4166053849775326

Epoch: 6| Step: 10
Training loss: 1.7456780606628166
Validation loss: 2.3860442722367528

Epoch: 6| Step: 11
Training loss: 1.8362677094583895
Validation loss: 2.334610611039777

Epoch: 6| Step: 12
Training loss: 1.6522542149159123
Validation loss: 2.4217234553181837

Epoch: 6| Step: 13
Training loss: 2.6717528376620883
Validation loss: 2.397906739402797

Epoch: 255| Step: 0
Training loss: 2.250091762790799
Validation loss: 2.4210912393588306

Epoch: 6| Step: 1
Training loss: 2.1171679055971735
Validation loss: 2.3653171725638007

Epoch: 6| Step: 2
Training loss: 1.673864090487475
Validation loss: 2.422098370326246

Epoch: 6| Step: 3
Training loss: 1.829025438051519
Validation loss: 2.393737709122881

Epoch: 6| Step: 4
Training loss: 1.4319738231908972
Validation loss: 2.40615589696699

Epoch: 6| Step: 5
Training loss: 1.9573789124045642
Validation loss: 2.4222633264846056

Epoch: 6| Step: 6
Training loss: 1.4529732245480858
Validation loss: 2.454262079014156

Epoch: 6| Step: 7
Training loss: 1.584598520978348
Validation loss: 2.393292745448914

Epoch: 6| Step: 8
Training loss: 1.3944529449960317
Validation loss: 2.3925400233295577

Epoch: 6| Step: 9
Training loss: 1.5985802401203992
Validation loss: 2.4689036776197693

Epoch: 6| Step: 10
Training loss: 2.1555718723916164
Validation loss: 2.3551613088307386

Epoch: 6| Step: 11
Training loss: 1.5619631035582888
Validation loss: 2.3796309764062125

Epoch: 6| Step: 12
Training loss: 1.715040608361819
Validation loss: 2.4465869888757608

Epoch: 6| Step: 13
Training loss: 1.8182965031130187
Validation loss: 2.398792475864059

Epoch: 256| Step: 0
Training loss: 2.026561078826241
Validation loss: 2.4073854475472087

Epoch: 6| Step: 1
Training loss: 2.001249519076459
Validation loss: 2.4319734566569893

Epoch: 6| Step: 2
Training loss: 1.6821575367211534
Validation loss: 2.359841297198728

Epoch: 6| Step: 3
Training loss: 2.4866276730641124
Validation loss: 2.333422174242028

Epoch: 6| Step: 4
Training loss: 1.5988052079464037
Validation loss: 2.407273693655438

Epoch: 6| Step: 5
Training loss: 1.2335547607135802
Validation loss: 2.4952730970595063

Epoch: 6| Step: 6
Training loss: 1.0771163423793884
Validation loss: 2.407203713312585

Epoch: 6| Step: 7
Training loss: 1.723090084747466
Validation loss: 2.425181862456578

Epoch: 6| Step: 8
Training loss: 2.0605580984957963
Validation loss: 2.341714281466523

Epoch: 6| Step: 9
Training loss: 1.3092642816970521
Validation loss: 2.3947305976245574

Epoch: 6| Step: 10
Training loss: 0.9995540876404863
Validation loss: 2.418515128228646

Epoch: 6| Step: 11
Training loss: 1.88914494866989
Validation loss: 2.3855176751037295

Epoch: 6| Step: 12
Training loss: 2.067215816796914
Validation loss: 2.3941900170116432

Epoch: 6| Step: 13
Training loss: 0.5307933303136567
Validation loss: 2.373436662071801

Epoch: 257| Step: 0
Training loss: 1.4805123919091105
Validation loss: 2.3809248374775596

Epoch: 6| Step: 1
Training loss: 1.7233867177804918
Validation loss: 2.4181598294473328

Epoch: 6| Step: 2
Training loss: 1.789469443602601
Validation loss: 2.3937923021438783

Epoch: 6| Step: 3
Training loss: 2.363754956398079
Validation loss: 2.3882052213652143

Epoch: 6| Step: 4
Training loss: 1.5400227296068356
Validation loss: 2.3774690719847245

Epoch: 6| Step: 5
Training loss: 2.340894867398449
Validation loss: 2.403962749572138

Epoch: 6| Step: 6
Training loss: 1.939170855277335
Validation loss: 2.4184508496684054

Epoch: 6| Step: 7
Training loss: 1.984690363297329
Validation loss: 2.3847496524869265

Epoch: 6| Step: 8
Training loss: 1.305629641322409
Validation loss: 2.4516357484969067

Epoch: 6| Step: 9
Training loss: 1.6893444577588224
Validation loss: 2.4163343040480396

Epoch: 6| Step: 10
Training loss: 1.884782828613195
Validation loss: 2.4176599231557714

Epoch: 6| Step: 11
Training loss: 1.1207338612790205
Validation loss: 2.3728442698200296

Epoch: 6| Step: 12
Training loss: 1.3818244637056776
Validation loss: 2.3972034946767944

Epoch: 6| Step: 13
Training loss: 1.4423028075306654
Validation loss: 2.396206129014006

Epoch: 258| Step: 0
Training loss: 2.0344166647399162
Validation loss: 2.358201626475177

Epoch: 6| Step: 1
Training loss: 1.8863962344040628
Validation loss: 2.3907742524423803

Epoch: 6| Step: 2
Training loss: 1.7676255362037583
Validation loss: 2.396664109897934

Epoch: 6| Step: 3
Training loss: 2.473028603912426
Validation loss: 2.4041334676662087

Epoch: 6| Step: 4
Training loss: 1.0490255329890283
Validation loss: 2.3473076882987103

Epoch: 6| Step: 5
Training loss: 1.488161097204503
Validation loss: 2.3899490716682283

Epoch: 6| Step: 6
Training loss: 2.1074499317525315
Validation loss: 2.37721760728736

Epoch: 6| Step: 7
Training loss: 1.7259668902274745
Validation loss: 2.3942424105670845

Epoch: 6| Step: 8
Training loss: 1.893079315369804
Validation loss: 2.400176268538418

Epoch: 6| Step: 9
Training loss: 1.636831202319804
Validation loss: 2.337533971901451

Epoch: 6| Step: 10
Training loss: 1.3759593218013662
Validation loss: 2.3443425064690717

Epoch: 6| Step: 11
Training loss: 1.5617777871923337
Validation loss: 2.372448877127219

Epoch: 6| Step: 12
Training loss: 1.8386173250734648
Validation loss: 2.4380013187258878

Epoch: 6| Step: 13
Training loss: 1.3065525361661765
Validation loss: 2.4066244451160754

Epoch: 259| Step: 0
Training loss: 1.2671287927539756
Validation loss: 2.399079438692316

Epoch: 6| Step: 1
Training loss: 1.9623118899632674
Validation loss: 2.337814346944102

Epoch: 6| Step: 2
Training loss: 1.3037124462333265
Validation loss: 2.3803770651246787

Epoch: 6| Step: 3
Training loss: 1.3784761703695176
Validation loss: 2.3778483641183463

Epoch: 6| Step: 4
Training loss: 2.15957738698025
Validation loss: 2.4089219518079967

Epoch: 6| Step: 5
Training loss: 1.60316877993168
Validation loss: 2.3962259735052

Epoch: 6| Step: 6
Training loss: 2.358161159291735
Validation loss: 2.3913653671827055

Epoch: 6| Step: 7
Training loss: 1.4223375511264835
Validation loss: 2.360844039128531

Epoch: 6| Step: 8
Training loss: 1.663433833758714
Validation loss: 2.398314758497137

Epoch: 6| Step: 9
Training loss: 1.4142017612062734
Validation loss: 2.414705996685617

Epoch: 6| Step: 10
Training loss: 1.767118109597953
Validation loss: 2.4189820232406998

Epoch: 6| Step: 11
Training loss: 2.103677359112822
Validation loss: 2.373613198765517

Epoch: 6| Step: 12
Training loss: 1.6598114014541583
Validation loss: 2.4085458723945727

Epoch: 6| Step: 13
Training loss: 1.4082642434834014
Validation loss: 2.375279027526797

Epoch: 260| Step: 0
Training loss: 2.5438527154452983
Validation loss: 2.377658667390867

Epoch: 6| Step: 1
Training loss: 1.6704510480552774
Validation loss: 2.328002547667778

Epoch: 6| Step: 2
Training loss: 1.4847786605491553
Validation loss: 2.4110428884520547

Epoch: 6| Step: 3
Training loss: 1.4370054970080652
Validation loss: 2.413397423168486

Epoch: 6| Step: 4
Training loss: 1.439561112596271
Validation loss: 2.437971109026014

Epoch: 6| Step: 5
Training loss: 1.2664074774800305
Validation loss: 2.428346847856475

Epoch: 6| Step: 6
Training loss: 1.7665276709645181
Validation loss: 2.3805453872165154

Epoch: 6| Step: 7
Training loss: 1.754228252257056
Validation loss: 2.3870203932482092

Epoch: 6| Step: 8
Training loss: 1.3878782770502458
Validation loss: 2.3711863924019236

Epoch: 6| Step: 9
Training loss: 1.541572499191547
Validation loss: 2.3820985453045527

Epoch: 6| Step: 10
Training loss: 1.665827500163112
Validation loss: 2.391412798610284

Epoch: 6| Step: 11
Training loss: 2.0523624391724953
Validation loss: 2.3888877085804996

Epoch: 6| Step: 12
Training loss: 1.7521598294221268
Validation loss: 2.3858650192051214

Epoch: 6| Step: 13
Training loss: 2.6440219135097713
Validation loss: 2.368995706099439

Epoch: 261| Step: 0
Training loss: 2.195927543959571
Validation loss: 2.401443648171002

Epoch: 6| Step: 1
Training loss: 1.9081482113108341
Validation loss: 2.40145956889765

Epoch: 6| Step: 2
Training loss: 1.7022677722798139
Validation loss: 2.345618119164343

Epoch: 6| Step: 3
Training loss: 1.3647225966503616
Validation loss: 2.416084481093403

Epoch: 6| Step: 4
Training loss: 1.6755680402090496
Validation loss: 2.3485704527435254

Epoch: 6| Step: 5
Training loss: 1.703209761163989
Validation loss: 2.3365764533547817

Epoch: 6| Step: 6
Training loss: 1.505259195104219
Validation loss: 2.4161923658769

Epoch: 6| Step: 7
Training loss: 1.2660419107101797
Validation loss: 2.3643565632727306

Epoch: 6| Step: 8
Training loss: 2.0575875242581807
Validation loss: 2.393834108596973

Epoch: 6| Step: 9
Training loss: 1.5546982347894154
Validation loss: 2.3713665852702004

Epoch: 6| Step: 10
Training loss: 0.9132344660593066
Validation loss: 2.4003462653383867

Epoch: 6| Step: 11
Training loss: 2.5325367800422653
Validation loss: 2.3602352952137076

Epoch: 6| Step: 12
Training loss: 1.4005436727189606
Validation loss: 2.4070730193538137

Epoch: 6| Step: 13
Training loss: 1.161117669111853
Validation loss: 2.4126181586134754

Epoch: 262| Step: 0
Training loss: 1.5966508681936589
Validation loss: 2.3337201157355505

Epoch: 6| Step: 1
Training loss: 1.2728635278443472
Validation loss: 2.401274863936219

Epoch: 6| Step: 2
Training loss: 1.7389806133503611
Validation loss: 2.3829807436603367

Epoch: 6| Step: 3
Training loss: 1.64415890789312
Validation loss: 2.411089623899579

Epoch: 6| Step: 4
Training loss: 1.3449509155789934
Validation loss: 2.3996916411331553

Epoch: 6| Step: 5
Training loss: 1.7775668161445168
Validation loss: 2.387559435520756

Epoch: 6| Step: 6
Training loss: 1.6794574668747588
Validation loss: 2.3667405446105136

Epoch: 6| Step: 7
Training loss: 2.3105292299423983
Validation loss: 2.3574403163525286

Epoch: 6| Step: 8
Training loss: 1.2239584523735259
Validation loss: 2.387054213014455

Epoch: 6| Step: 9
Training loss: 1.9933644726191126
Validation loss: 2.4000303507923006

Epoch: 6| Step: 10
Training loss: 1.8404041902641577
Validation loss: 2.3574568371067537

Epoch: 6| Step: 11
Training loss: 2.065497445512391
Validation loss: 2.406919242739053

Epoch: 6| Step: 12
Training loss: 1.625142971498406
Validation loss: 2.3732981712966903

Epoch: 6| Step: 13
Training loss: 1.2851045360421904
Validation loss: 2.384270677330004

Epoch: 263| Step: 0
Training loss: 2.2427506753054947
Validation loss: 2.4146500286107706

Epoch: 6| Step: 1
Training loss: 1.2376474388992675
Validation loss: 2.3840510169673537

Epoch: 6| Step: 2
Training loss: 1.1073487811043572
Validation loss: 2.3722220896926043

Epoch: 6| Step: 3
Training loss: 2.080406027008462
Validation loss: 2.410686033751474

Epoch: 6| Step: 4
Training loss: 1.5728996562248483
Validation loss: 2.4587670894807374

Epoch: 6| Step: 5
Training loss: 1.4247693795423846
Validation loss: 2.405765529423177

Epoch: 6| Step: 6
Training loss: 1.4770605468427171
Validation loss: 2.375638363272777

Epoch: 6| Step: 7
Training loss: 2.130084294545095
Validation loss: 2.3659122464684463

Epoch: 6| Step: 8
Training loss: 1.656191051081884
Validation loss: 2.417950818000322

Epoch: 6| Step: 9
Training loss: 1.6803669819327345
Validation loss: 2.4171873871109852

Epoch: 6| Step: 10
Training loss: 1.763799753548479
Validation loss: 2.4174151302931834

Epoch: 6| Step: 11
Training loss: 1.4218999839516042
Validation loss: 2.3994627766616894

Epoch: 6| Step: 12
Training loss: 1.4055133161534847
Validation loss: 2.394028731334103

Epoch: 6| Step: 13
Training loss: 2.049979847134412
Validation loss: 2.39859539288673

Epoch: 264| Step: 0
Training loss: 1.339433746331207
Validation loss: 2.423002094967133

Epoch: 6| Step: 1
Training loss: 1.635167226376352
Validation loss: 2.336342707606974

Epoch: 6| Step: 2
Training loss: 1.6857952407905505
Validation loss: 2.3518502386394955

Epoch: 6| Step: 3
Training loss: 1.977755220632229
Validation loss: 2.3991452460503577

Epoch: 6| Step: 4
Training loss: 1.4104984956535207
Validation loss: 2.3431010966152206

Epoch: 6| Step: 5
Training loss: 1.350505084460735
Validation loss: 2.3787368085527976

Epoch: 6| Step: 6
Training loss: 1.48171123614966
Validation loss: 2.3969667743477028

Epoch: 6| Step: 7
Training loss: 1.4563287672752863
Validation loss: 2.3912983444125864

Epoch: 6| Step: 8
Training loss: 1.7220063313490745
Validation loss: 2.3916848117854226

Epoch: 6| Step: 9
Training loss: 2.352944205787055
Validation loss: 2.3672002900785687

Epoch: 6| Step: 10
Training loss: 1.6747831915985676
Validation loss: 2.344427044609874

Epoch: 6| Step: 11
Training loss: 2.1114392388083743
Validation loss: 2.377765937141956

Epoch: 6| Step: 12
Training loss: 2.130752071262791
Validation loss: 2.3676095339458816

Epoch: 6| Step: 13
Training loss: 2.1884910518331706
Validation loss: 2.3463073462115096

Epoch: 265| Step: 0
Training loss: 2.2437179605645756
Validation loss: 2.399478905517423

Epoch: 6| Step: 1
Training loss: 1.5574432945644254
Validation loss: 2.3712777132970246

Epoch: 6| Step: 2
Training loss: 2.2329525988374193
Validation loss: 2.3707835382118083

Epoch: 6| Step: 3
Training loss: 2.0523138804271497
Validation loss: 2.39369211982898

Epoch: 6| Step: 4
Training loss: 1.2012451149546426
Validation loss: 2.4075170514962574

Epoch: 6| Step: 5
Training loss: 1.3342000806453624
Validation loss: 2.4029455136070634

Epoch: 6| Step: 6
Training loss: 1.8951881764166694
Validation loss: 2.4388715851727776

Epoch: 6| Step: 7
Training loss: 1.3577452349929486
Validation loss: 2.4324969874559614

Epoch: 6| Step: 8
Training loss: 1.6364085920978746
Validation loss: 2.362534823977301

Epoch: 6| Step: 9
Training loss: 1.4346630463773105
Validation loss: 2.446916920020176

Epoch: 6| Step: 10
Training loss: 1.9818433095851848
Validation loss: 2.3814074164245067

Epoch: 6| Step: 11
Training loss: 1.5700785144684513
Validation loss: 2.3941292968314096

Epoch: 6| Step: 12
Training loss: 1.7141391288438192
Validation loss: 2.3746523189747006

Epoch: 6| Step: 13
Training loss: 1.512721791044887
Validation loss: 2.363116845846803

Epoch: 266| Step: 0
Training loss: 1.7201180302243309
Validation loss: 2.3505846112826334

Epoch: 6| Step: 1
Training loss: 1.7949933358496428
Validation loss: 2.32565806229393

Epoch: 6| Step: 2
Training loss: 1.4810683513274163
Validation loss: 2.365645472884082

Epoch: 6| Step: 3
Training loss: 1.301950290240782
Validation loss: 2.3773583278548935

Epoch: 6| Step: 4
Training loss: 1.6062685419934621
Validation loss: 2.402858760230206

Epoch: 6| Step: 5
Training loss: 1.7880783372568543
Validation loss: 2.3950813864742506

Epoch: 6| Step: 6
Training loss: 1.692759336045525
Validation loss: 2.3823957902254134

Epoch: 6| Step: 7
Training loss: 1.2796157090167544
Validation loss: 2.4129336166411934

Epoch: 6| Step: 8
Training loss: 1.3020951791860242
Validation loss: 2.385020855718084

Epoch: 6| Step: 9
Training loss: 1.0711450610401803
Validation loss: 2.4425180621135367

Epoch: 6| Step: 10
Training loss: 1.915758028125332
Validation loss: 2.3557243226883817

Epoch: 6| Step: 11
Training loss: 1.8185033362218772
Validation loss: 2.3649938043785808

Epoch: 6| Step: 12
Training loss: 2.5615386089845695
Validation loss: 2.4024459271561978

Epoch: 6| Step: 13
Training loss: 2.129530396967577
Validation loss: 2.3553367630417426

Epoch: 267| Step: 0
Training loss: 1.5572928829464794
Validation loss: 2.392093361654739

Epoch: 6| Step: 1
Training loss: 1.7719859093564383
Validation loss: 2.3304137793301845

Epoch: 6| Step: 2
Training loss: 1.181397569107595
Validation loss: 2.3629886840353835

Epoch: 6| Step: 3
Training loss: 1.7989744443748144
Validation loss: 2.369098582983294

Epoch: 6| Step: 4
Training loss: 1.6524806766274749
Validation loss: 2.412332662306475

Epoch: 6| Step: 5
Training loss: 1.675376861081694
Validation loss: 2.4076036551223052

Epoch: 6| Step: 6
Training loss: 1.9992799654879783
Validation loss: 2.3458692298488217

Epoch: 6| Step: 7
Training loss: 1.596515574755922
Validation loss: 2.3544532887435095

Epoch: 6| Step: 8
Training loss: 1.9624441977178597
Validation loss: 2.3367576738256854

Epoch: 6| Step: 9
Training loss: 2.1206248627473454
Validation loss: 2.382263425884215

Epoch: 6| Step: 10
Training loss: 1.6012887115921084
Validation loss: 2.3769897918646254

Epoch: 6| Step: 11
Training loss: 1.26597976421919
Validation loss: 2.380817758508943

Epoch: 6| Step: 12
Training loss: 1.8127814107332345
Validation loss: 2.380635308304823

Epoch: 6| Step: 13
Training loss: 2.0550230499237165
Validation loss: 2.3503630504957953

Epoch: 268| Step: 0
Training loss: 1.6264457873301974
Validation loss: 2.4260538114620824

Epoch: 6| Step: 1
Training loss: 1.8936142422703344
Validation loss: 2.3788945196944793

Epoch: 6| Step: 2
Training loss: 1.4935997476386504
Validation loss: 2.4039534770081934

Epoch: 6| Step: 3
Training loss: 1.8435818223707232
Validation loss: 2.370222298973146

Epoch: 6| Step: 4
Training loss: 1.5275020273448021
Validation loss: 2.3503567100016696

Epoch: 6| Step: 5
Training loss: 1.2142438971507674
Validation loss: 2.3846773480604857

Epoch: 6| Step: 6
Training loss: 1.918462810085309
Validation loss: 2.3797117104586585

Epoch: 6| Step: 7
Training loss: 1.597250217616254
Validation loss: 2.347948999132515

Epoch: 6| Step: 8
Training loss: 1.7830365239979367
Validation loss: 2.4068357012923856

Epoch: 6| Step: 9
Training loss: 2.231131166344351
Validation loss: 2.325464439491474

Epoch: 6| Step: 10
Training loss: 1.4346937901569423
Validation loss: 2.381644889936187

Epoch: 6| Step: 11
Training loss: 1.6342779272948615
Validation loss: 2.421523610589744

Epoch: 6| Step: 12
Training loss: 2.095883776725702
Validation loss: 2.356154899672337

Epoch: 6| Step: 13
Training loss: 0.7193794811119154
Validation loss: 2.3523581685014814

Epoch: 269| Step: 0
Training loss: 1.6811283762450688
Validation loss: 2.3826855503789255

Epoch: 6| Step: 1
Training loss: 1.9802844321049826
Validation loss: 2.3910518037101793

Epoch: 6| Step: 2
Training loss: 1.718456728796963
Validation loss: 2.385828065376142

Epoch: 6| Step: 3
Training loss: 2.2280850742609744
Validation loss: 2.3957469926411283

Epoch: 6| Step: 4
Training loss: 1.0503672525196655
Validation loss: 2.393844611233087

Epoch: 6| Step: 5
Training loss: 1.5898548472624063
Validation loss: 2.3485680480027162

Epoch: 6| Step: 6
Training loss: 1.666391453272658
Validation loss: 2.373692087072893

Epoch: 6| Step: 7
Training loss: 1.2389928656273366
Validation loss: 2.3697946776747663

Epoch: 6| Step: 8
Training loss: 0.859429513762814
Validation loss: 2.419908982191365

Epoch: 6| Step: 9
Training loss: 1.863293789675441
Validation loss: 2.3615891986171498

Epoch: 6| Step: 10
Training loss: 1.3967557203326946
Validation loss: 2.382106128275124

Epoch: 6| Step: 11
Training loss: 1.8722773812026587
Validation loss: 2.4078278180877026

Epoch: 6| Step: 12
Training loss: 1.87932114174145
Validation loss: 2.362074718805383

Epoch: 6| Step: 13
Training loss: 2.1344273081858383
Validation loss: 2.392082960644956

Epoch: 270| Step: 0
Training loss: 1.5998352412986618
Validation loss: 2.3678566521529634

Epoch: 6| Step: 1
Training loss: 1.752279636062228
Validation loss: 2.3587552692137472

Epoch: 6| Step: 2
Training loss: 1.2565844683658578
Validation loss: 2.4205062210880164

Epoch: 6| Step: 3
Training loss: 1.2414975439439893
Validation loss: 2.4119852980786

Epoch: 6| Step: 4
Training loss: 1.5618034336016684
Validation loss: 2.425018107544649

Epoch: 6| Step: 5
Training loss: 1.6784061246136541
Validation loss: 2.3775636127943884

Epoch: 6| Step: 6
Training loss: 1.806888443729578
Validation loss: 2.430075259024621

Epoch: 6| Step: 7
Training loss: 2.2059880044356794
Validation loss: 2.39662500349906

Epoch: 6| Step: 8
Training loss: 1.2819455282597743
Validation loss: 2.394213856644479

Epoch: 6| Step: 9
Training loss: 0.843388232629256
Validation loss: 2.361475454430018

Epoch: 6| Step: 10
Training loss: 1.6675080639188085
Validation loss: 2.4503188544585153

Epoch: 6| Step: 11
Training loss: 1.899163503718145
Validation loss: 2.3749233129843716

Epoch: 6| Step: 12
Training loss: 1.9214374695489305
Validation loss: 2.430550869137826

Epoch: 6| Step: 13
Training loss: 1.9941154575534459
Validation loss: 2.3665966156227705

Epoch: 271| Step: 0
Training loss: 0.9530169629011338
Validation loss: 2.351710816225169

Epoch: 6| Step: 1
Training loss: 1.4179267141453438
Validation loss: 2.383790622974206

Epoch: 6| Step: 2
Training loss: 1.6028737724613051
Validation loss: 2.3367892841543267

Epoch: 6| Step: 3
Training loss: 1.8961452255523277
Validation loss: 2.391535944190829

Epoch: 6| Step: 4
Training loss: 1.3891339398476337
Validation loss: 2.3365842860964814

Epoch: 6| Step: 5
Training loss: 1.74378175877462
Validation loss: 2.308261617924603

Epoch: 6| Step: 6
Training loss: 1.6173190740605103
Validation loss: 2.4119517471099443

Epoch: 6| Step: 7
Training loss: 2.135627649320679
Validation loss: 2.346458576322186

Epoch: 6| Step: 8
Training loss: 2.2175628279910464
Validation loss: 2.384734205552462

Epoch: 6| Step: 9
Training loss: 1.1503642003079806
Validation loss: 2.389865982898442

Epoch: 6| Step: 10
Training loss: 2.246441994912205
Validation loss: 2.2898370522291525

Epoch: 6| Step: 11
Training loss: 1.3458600887005059
Validation loss: 2.344124752150698

Epoch: 6| Step: 12
Training loss: 1.5106591742504563
Validation loss: 2.346838072753946

Epoch: 6| Step: 13
Training loss: 1.4940376196367247
Validation loss: 2.354616645048357

Epoch: 272| Step: 0
Training loss: 1.4210910522368223
Validation loss: 2.3577239669169865

Epoch: 6| Step: 1
Training loss: 1.6236119577699137
Validation loss: 2.3463623386168955

Epoch: 6| Step: 2
Training loss: 1.2992729171132296
Validation loss: 2.399977643496801

Epoch: 6| Step: 3
Training loss: 1.685871327315102
Validation loss: 2.4004626905473567

Epoch: 6| Step: 4
Training loss: 1.4979043467531878
Validation loss: 2.389094471422267

Epoch: 6| Step: 5
Training loss: 1.3624194462613062
Validation loss: 2.3737819794155772

Epoch: 6| Step: 6
Training loss: 2.061384882171762
Validation loss: 2.3275839399940876

Epoch: 6| Step: 7
Training loss: 1.3939391516727997
Validation loss: 2.4336163977626195

Epoch: 6| Step: 8
Training loss: 2.161929184211728
Validation loss: 2.3517673631998175

Epoch: 6| Step: 9
Training loss: 1.6199077634102466
Validation loss: 2.389740890545694

Epoch: 6| Step: 10
Training loss: 1.8595530320534461
Validation loss: 2.398405335062913

Epoch: 6| Step: 11
Training loss: 1.6062933296266977
Validation loss: 2.3813337810904853

Epoch: 6| Step: 12
Training loss: 1.709539600097748
Validation loss: 2.3557525590581734

Epoch: 6| Step: 13
Training loss: 2.0088373678182654
Validation loss: 2.4238378408521415

Epoch: 273| Step: 0
Training loss: 1.3962926346187172
Validation loss: 2.403762735792079

Epoch: 6| Step: 1
Training loss: 1.4112468105851144
Validation loss: 2.392892408759387

Epoch: 6| Step: 2
Training loss: 1.755003452134609
Validation loss: 2.39499287106204

Epoch: 6| Step: 3
Training loss: 1.861313842846734
Validation loss: 2.448958658241122

Epoch: 6| Step: 4
Training loss: 2.2538254325036347
Validation loss: 2.4127489187788123

Epoch: 6| Step: 5
Training loss: 1.5672933677749634
Validation loss: 2.375199575086019

Epoch: 6| Step: 6
Training loss: 1.3263382505345054
Validation loss: 2.4042438336523233

Epoch: 6| Step: 7
Training loss: 1.5797464331435551
Validation loss: 2.381736645634898

Epoch: 6| Step: 8
Training loss: 1.3647938728499085
Validation loss: 2.4189562535014817

Epoch: 6| Step: 9
Training loss: 1.5840477419218602
Validation loss: 2.425064693121237

Epoch: 6| Step: 10
Training loss: 1.2012660540124254
Validation loss: 2.402741295600405

Epoch: 6| Step: 11
Training loss: 1.6943628138628457
Validation loss: 2.443116428908788

Epoch: 6| Step: 12
Training loss: 2.5267397410847927
Validation loss: 2.383648430650181

Epoch: 6| Step: 13
Training loss: 1.347602644144455
Validation loss: 2.3897137343096206

Epoch: 274| Step: 0
Training loss: 1.3912187658815618
Validation loss: 2.3450671000188117

Epoch: 6| Step: 1
Training loss: 1.4208382819901517
Validation loss: 2.43672094629419

Epoch: 6| Step: 2
Training loss: 1.1020184378215203
Validation loss: 2.3894844409419838

Epoch: 6| Step: 3
Training loss: 1.556581350081057
Validation loss: 2.375291200390062

Epoch: 6| Step: 4
Training loss: 2.1414895643736602
Validation loss: 2.404086238158194

Epoch: 6| Step: 5
Training loss: 1.5055292264850049
Validation loss: 2.370515506779898

Epoch: 6| Step: 6
Training loss: 1.4172440455552688
Validation loss: 2.390811066555034

Epoch: 6| Step: 7
Training loss: 1.3878584355820252
Validation loss: 2.353589429188731

Epoch: 6| Step: 8
Training loss: 1.8005666211829305
Validation loss: 2.411901656811392

Epoch: 6| Step: 9
Training loss: 2.222444708600888
Validation loss: 2.4143789797901594

Epoch: 6| Step: 10
Training loss: 1.4416660808642894
Validation loss: 2.340566372587248

Epoch: 6| Step: 11
Training loss: 2.356369630726234
Validation loss: 2.4117743112067647

Epoch: 6| Step: 12
Training loss: 1.578710768356418
Validation loss: 2.331401213614746

Epoch: 6| Step: 13
Training loss: 1.8549601610743487
Validation loss: 2.4081479926470513

Epoch: 275| Step: 0
Training loss: 1.6691137310337016
Validation loss: 2.353507007134962

Epoch: 6| Step: 1
Training loss: 1.3693392578224035
Validation loss: 2.37393422978567

Epoch: 6| Step: 2
Training loss: 1.6732326948569662
Validation loss: 2.379473956744806

Epoch: 6| Step: 3
Training loss: 1.550854275230819
Validation loss: 2.437007630301179

Epoch: 6| Step: 4
Training loss: 1.5171540402966752
Validation loss: 2.404793811026911

Epoch: 6| Step: 5
Training loss: 1.382893662306858
Validation loss: 2.4009663467244016

Epoch: 6| Step: 6
Training loss: 0.9705410674307611
Validation loss: 2.389960329374688

Epoch: 6| Step: 7
Training loss: 1.9546468070328027
Validation loss: 2.390166857312152

Epoch: 6| Step: 8
Training loss: 1.5335360220306136
Validation loss: 2.374307044532366

Epoch: 6| Step: 9
Training loss: 2.121304496285409
Validation loss: 2.4149955987530327

Epoch: 6| Step: 10
Training loss: 1.7768839817846578
Validation loss: 2.326625102142277

Epoch: 6| Step: 11
Training loss: 1.938069659749742
Validation loss: 2.426790841853909

Epoch: 6| Step: 12
Training loss: 1.225174136338348
Validation loss: 2.406355485973177

Epoch: 6| Step: 13
Training loss: 1.620121675913953
Validation loss: 2.338950708003426

Epoch: 276| Step: 0
Training loss: 1.1175136490229385
Validation loss: 2.4474486340601582

Epoch: 6| Step: 1
Training loss: 1.9781099677456329
Validation loss: 2.3595511333978494

Epoch: 6| Step: 2
Training loss: 1.707541941494882
Validation loss: 2.4111421478303017

Epoch: 6| Step: 3
Training loss: 1.6957106584172024
Validation loss: 2.441870263941944

Epoch: 6| Step: 4
Training loss: 1.3427550158537493
Validation loss: 2.399493321605476

Epoch: 6| Step: 5
Training loss: 2.1703694566101035
Validation loss: 2.39945624431606

Epoch: 6| Step: 6
Training loss: 1.6790127130678048
Validation loss: 2.391036815643125

Epoch: 6| Step: 7
Training loss: 1.8118478325198248
Validation loss: 2.3968062413456757

Epoch: 6| Step: 8
Training loss: 1.9599886114412426
Validation loss: 2.3864269067084725

Epoch: 6| Step: 9
Training loss: 1.2521612556740371
Validation loss: 2.366356565378775

Epoch: 6| Step: 10
Training loss: 1.4943882556233243
Validation loss: 2.3388818450988405

Epoch: 6| Step: 11
Training loss: 1.3853653441748932
Validation loss: 2.3481980859227165

Epoch: 6| Step: 12
Training loss: 1.6665443216559532
Validation loss: 2.3904696725132717

Epoch: 6| Step: 13
Training loss: 1.3112896833787935
Validation loss: 2.3075006839798866

Epoch: 277| Step: 0
Training loss: 1.4871483042426017
Validation loss: 2.39440788212609

Epoch: 6| Step: 1
Training loss: 1.9420483024475232
Validation loss: 2.393351190305992

Epoch: 6| Step: 2
Training loss: 2.127195346235541
Validation loss: 2.355473773403828

Epoch: 6| Step: 3
Training loss: 1.9541807449365105
Validation loss: 2.356375342519854

Epoch: 6| Step: 4
Training loss: 1.4138319976259508
Validation loss: 2.3102693649834323

Epoch: 6| Step: 5
Training loss: 1.3950172240038234
Validation loss: 2.3248248983607773

Epoch: 6| Step: 6
Training loss: 1.7784916451134318
Validation loss: 2.3831167128076407

Epoch: 6| Step: 7
Training loss: 1.3600176465067704
Validation loss: 2.355358885462635

Epoch: 6| Step: 8
Training loss: 1.2142184693686289
Validation loss: 2.3837740873804654

Epoch: 6| Step: 9
Training loss: 1.1798971634036102
Validation loss: 2.3700981276435864

Epoch: 6| Step: 10
Training loss: 1.28393598789716
Validation loss: 2.4168701207343077

Epoch: 6| Step: 11
Training loss: 1.609388184724891
Validation loss: 2.4224009556369053

Epoch: 6| Step: 12
Training loss: 1.8766047921604252
Validation loss: 2.39890325321658

Epoch: 6| Step: 13
Training loss: 2.2007047738088006
Validation loss: 2.3223282881734675

Epoch: 278| Step: 0
Training loss: 1.6240968395167876
Validation loss: 2.364503200384413

Epoch: 6| Step: 1
Training loss: 1.6438108483717369
Validation loss: 2.387211903565447

Epoch: 6| Step: 2
Training loss: 1.6832426550333963
Validation loss: 2.390148052262572

Epoch: 6| Step: 3
Training loss: 1.6848020532403518
Validation loss: 2.370885220534815

Epoch: 6| Step: 4
Training loss: 1.623222479289237
Validation loss: 2.3528456216117273

Epoch: 6| Step: 5
Training loss: 2.2965815350165038
Validation loss: 2.4132232327496337

Epoch: 6| Step: 6
Training loss: 1.6139888366256432
Validation loss: 2.3678029244299976

Epoch: 6| Step: 7
Training loss: 1.5642089653223523
Validation loss: 2.36647398627367

Epoch: 6| Step: 8
Training loss: 1.4805499937769329
Validation loss: 2.383827960053099

Epoch: 6| Step: 9
Training loss: 1.4730021831861426
Validation loss: 2.352638457717486

Epoch: 6| Step: 10
Training loss: 1.5760429168850851
Validation loss: 2.36169838308501

Epoch: 6| Step: 11
Training loss: 2.0351196988680305
Validation loss: 2.342633585953299

Epoch: 6| Step: 12
Training loss: 1.0114107583692595
Validation loss: 2.390571033314492

Epoch: 6| Step: 13
Training loss: 1.503950559285371
Validation loss: 2.381791848476915

Epoch: 279| Step: 0
Training loss: 2.0553562250948456
Validation loss: 2.365229708873066

Epoch: 6| Step: 1
Training loss: 1.4302855527980154
Validation loss: 2.465405816136718

Epoch: 6| Step: 2
Training loss: 1.4255736317425534
Validation loss: 2.391594900416737

Epoch: 6| Step: 3
Training loss: 1.3640595758325929
Validation loss: 2.3981505250322694

Epoch: 6| Step: 4
Training loss: 1.5548599377566616
Validation loss: 2.405863476890783

Epoch: 6| Step: 5
Training loss: 1.5766542587571648
Validation loss: 2.3847553403822626

Epoch: 6| Step: 6
Training loss: 1.8526075287163613
Validation loss: 2.365512667624842

Epoch: 6| Step: 7
Training loss: 1.4826952615583084
Validation loss: 2.332078804851385

Epoch: 6| Step: 8
Training loss: 1.5625784282074664
Validation loss: 2.4163511446507395

Epoch: 6| Step: 9
Training loss: 1.3155805675406398
Validation loss: 2.40665429411429

Epoch: 6| Step: 10
Training loss: 2.0172741671145293
Validation loss: 2.348128081449641

Epoch: 6| Step: 11
Training loss: 1.8581801991454805
Validation loss: 2.3965962597446064

Epoch: 6| Step: 12
Training loss: 1.343094910026757
Validation loss: 2.353719437051528

Epoch: 6| Step: 13
Training loss: 1.6071711885891784
Validation loss: 2.331723361667823

Epoch: 280| Step: 0
Training loss: 1.2315287550412326
Validation loss: 2.410282252643451

Epoch: 6| Step: 1
Training loss: 1.4242610822570871
Validation loss: 2.3365843338235703

Epoch: 6| Step: 2
Training loss: 2.1986022410317925
Validation loss: 2.3793513176722834

Epoch: 6| Step: 3
Training loss: 1.5421961141575689
Validation loss: 2.4412967108322903

Epoch: 6| Step: 4
Training loss: 1.5265362646528955
Validation loss: 2.4846752457673893

Epoch: 6| Step: 5
Training loss: 1.5034948009100415
Validation loss: 2.4069471495992842

Epoch: 6| Step: 6
Training loss: 1.2014144032340963
Validation loss: 2.3459832542468417

Epoch: 6| Step: 7
Training loss: 1.6486914561118022
Validation loss: 2.44639275496277

Epoch: 6| Step: 8
Training loss: 1.775227454212748
Validation loss: 2.430037151862734

Epoch: 6| Step: 9
Training loss: 1.3831547459068247
Validation loss: 2.461900010886263

Epoch: 6| Step: 10
Training loss: 1.7499117829022306
Validation loss: 2.4431465886275263

Epoch: 6| Step: 11
Training loss: 1.815997990493671
Validation loss: 2.4587950068749627

Epoch: 6| Step: 12
Training loss: 2.0111966242562356
Validation loss: 2.420081110884609

Epoch: 6| Step: 13
Training loss: 2.1148635102368076
Validation loss: 2.364326754956137

Epoch: 281| Step: 0
Training loss: 1.189824890267779
Validation loss: 2.3565583388839735

Epoch: 6| Step: 1
Training loss: 1.339532265448622
Validation loss: 2.308921861579952

Epoch: 6| Step: 2
Training loss: 1.90738456606777
Validation loss: 2.358357856292813

Epoch: 6| Step: 3
Training loss: 1.3585896031830267
Validation loss: 2.394617641307573

Epoch: 6| Step: 4
Training loss: 1.8067735117935233
Validation loss: 2.396792078638086

Epoch: 6| Step: 5
Training loss: 1.4059109173033986
Validation loss: 2.385562077842423

Epoch: 6| Step: 6
Training loss: 1.7553052186874347
Validation loss: 2.395380543585313

Epoch: 6| Step: 7
Training loss: 1.7626036728472996
Validation loss: 2.370268638738723

Epoch: 6| Step: 8
Training loss: 2.4824661503046617
Validation loss: 2.3777824643829737

Epoch: 6| Step: 9
Training loss: 1.3162176070615352
Validation loss: 2.301810986852419

Epoch: 6| Step: 10
Training loss: 1.1609582152129325
Validation loss: 2.334847697895885

Epoch: 6| Step: 11
Training loss: 1.5972903702429084
Validation loss: 2.3599917197894764

Epoch: 6| Step: 12
Training loss: 1.195184837953946
Validation loss: 2.3279144341644793

Epoch: 6| Step: 13
Training loss: 2.0797154356630045
Validation loss: 2.323163033308376

Epoch: 282| Step: 0
Training loss: 2.095239707143172
Validation loss: 2.3768084591721372

Epoch: 6| Step: 1
Training loss: 1.577889226542733
Validation loss: 2.3786943886454015

Epoch: 6| Step: 2
Training loss: 1.6104498671859482
Validation loss: 2.367567384612459

Epoch: 6| Step: 3
Training loss: 1.4509760235436138
Validation loss: 2.3824350677778074

Epoch: 6| Step: 4
Training loss: 1.0938485237433508
Validation loss: 2.303905522225688

Epoch: 6| Step: 5
Training loss: 1.327301308513
Validation loss: 2.3853494583021333

Epoch: 6| Step: 6
Training loss: 1.4611980185550901
Validation loss: 2.389820565938097

Epoch: 6| Step: 7
Training loss: 1.8325670837363752
Validation loss: 2.3959758108039915

Epoch: 6| Step: 8
Training loss: 1.353167424406881
Validation loss: 2.3765285583718665

Epoch: 6| Step: 9
Training loss: 1.5205468556824968
Validation loss: 2.3851404785609907

Epoch: 6| Step: 10
Training loss: 2.6659922839809287
Validation loss: 2.390396606979686

Epoch: 6| Step: 11
Training loss: 1.4073625190493828
Validation loss: 2.420569732289174

Epoch: 6| Step: 12
Training loss: 0.9097930445455732
Validation loss: 2.316056501856946

Epoch: 6| Step: 13
Training loss: 1.6339951024443162
Validation loss: 2.3715428015000932

Epoch: 283| Step: 0
Training loss: 1.887583406133966
Validation loss: 2.3764250085007643

Epoch: 6| Step: 1
Training loss: 1.590252498035241
Validation loss: 2.370274712356417

Epoch: 6| Step: 2
Training loss: 1.453649200723489
Validation loss: 2.3605020068770477

Epoch: 6| Step: 3
Training loss: 1.6948735244511604
Validation loss: 2.3276789451884374

Epoch: 6| Step: 4
Training loss: 1.3532808879186298
Validation loss: 2.352297590226669

Epoch: 6| Step: 5
Training loss: 1.686583870764199
Validation loss: 2.39463178796995

Epoch: 6| Step: 6
Training loss: 2.0216303823327832
Validation loss: 2.382473709818257

Epoch: 6| Step: 7
Training loss: 1.2892307056154209
Validation loss: 2.364021655403293

Epoch: 6| Step: 8
Training loss: 2.2150435315541066
Validation loss: 2.354491506437027

Epoch: 6| Step: 9
Training loss: 1.800111724777017
Validation loss: 2.3183587911377908

Epoch: 6| Step: 10
Training loss: 1.301895489176633
Validation loss: 2.3919288746489946

Epoch: 6| Step: 11
Training loss: 1.7579422966402083
Validation loss: 2.352129390557034

Epoch: 6| Step: 12
Training loss: 1.0615999673245446
Validation loss: 2.331064236845265

Epoch: 6| Step: 13
Training loss: 1.462673115062032
Validation loss: 2.4209525350532903

Epoch: 284| Step: 0
Training loss: 1.6478883814001817
Validation loss: 2.32586522811118

Epoch: 6| Step: 1
Training loss: 1.7337782236894717
Validation loss: 2.3350734107787967

Epoch: 6| Step: 2
Training loss: 1.5672576188805747
Validation loss: 2.369800431754693

Epoch: 6| Step: 3
Training loss: 1.6327266396758604
Validation loss: 2.3632362593989895

Epoch: 6| Step: 4
Training loss: 2.1372784817670034
Validation loss: 2.3555018419041

Epoch: 6| Step: 5
Training loss: 1.6131521547404857
Validation loss: 2.3869194272796705

Epoch: 6| Step: 6
Training loss: 1.4863533088064405
Validation loss: 2.357928593240061

Epoch: 6| Step: 7
Training loss: 1.82599626808579
Validation loss: 2.3947026126305464

Epoch: 6| Step: 8
Training loss: 1.632505324093606
Validation loss: 2.4022811250538423

Epoch: 6| Step: 9
Training loss: 1.3585617438961504
Validation loss: 2.416886655563421

Epoch: 6| Step: 10
Training loss: 1.8588371460629616
Validation loss: 2.4225205803797873

Epoch: 6| Step: 11
Training loss: 1.474406126048732
Validation loss: 2.414235226052777

Epoch: 6| Step: 12
Training loss: 1.6685131176326298
Validation loss: 2.412744729713841

Epoch: 6| Step: 13
Training loss: 0.8777199092499728
Validation loss: 2.3509567385922416

Epoch: 285| Step: 0
Training loss: 0.9288225397710037
Validation loss: 2.38477348974099

Epoch: 6| Step: 1
Training loss: 1.369892517941342
Validation loss: 2.397513407137292

Epoch: 6| Step: 2
Training loss: 1.5216489024690465
Validation loss: 2.377705794330397

Epoch: 6| Step: 3
Training loss: 1.5422976809084699
Validation loss: 2.351775650057642

Epoch: 6| Step: 4
Training loss: 2.2650362499443606
Validation loss: 2.417348691904696

Epoch: 6| Step: 5
Training loss: 1.504072858821119
Validation loss: 2.393649656504377

Epoch: 6| Step: 6
Training loss: 1.7949319700137771
Validation loss: 2.398326370301096

Epoch: 6| Step: 7
Training loss: 2.197211587877202
Validation loss: 2.4018401451700977

Epoch: 6| Step: 8
Training loss: 2.145069492521532
Validation loss: 2.389483369130205

Epoch: 6| Step: 9
Training loss: 1.0586270260243629
Validation loss: 2.3185972092148672

Epoch: 6| Step: 10
Training loss: 1.334297110006237
Validation loss: 2.337412690300081

Epoch: 6| Step: 11
Training loss: 1.4553179856832406
Validation loss: 2.3997114188757167

Epoch: 6| Step: 12
Training loss: 1.5302143876709262
Validation loss: 2.3437129279592166

Epoch: 6| Step: 13
Training loss: 1.5276540455661323
Validation loss: 2.3962336877613892

Epoch: 286| Step: 0
Training loss: 1.5981212582803603
Validation loss: 2.34011913813219

Epoch: 6| Step: 1
Training loss: 1.0931177764357278
Validation loss: 2.359761143002639

Epoch: 6| Step: 2
Training loss: 1.4213198741421116
Validation loss: 2.288321490787454

Epoch: 6| Step: 3
Training loss: 1.5457087272058574
Validation loss: 2.3440637915781055

Epoch: 6| Step: 4
Training loss: 1.8538209042715361
Validation loss: 2.424231543366796

Epoch: 6| Step: 5
Training loss: 1.2798925512634023
Validation loss: 2.3798102363238627

Epoch: 6| Step: 6
Training loss: 1.5505799900396866
Validation loss: 2.4320135874378113

Epoch: 6| Step: 7
Training loss: 0.9076894312313164
Validation loss: 2.339872602566014

Epoch: 6| Step: 8
Training loss: 1.7851057650649895
Validation loss: 2.345688180511354

Epoch: 6| Step: 9
Training loss: 1.6548274426813419
Validation loss: 2.3816144131753414

Epoch: 6| Step: 10
Training loss: 2.2054997624734645
Validation loss: 2.3915507222420187

Epoch: 6| Step: 11
Training loss: 1.5814571139430138
Validation loss: 2.3984698291109634

Epoch: 6| Step: 12
Training loss: 2.087567324894701
Validation loss: 2.3598345940674132

Epoch: 6| Step: 13
Training loss: 1.41485169027745
Validation loss: 2.420102754816707

Epoch: 287| Step: 0
Training loss: 1.8698076196129891
Validation loss: 2.359094064762565

Epoch: 6| Step: 1
Training loss: 1.745814017262573
Validation loss: 2.367383745916951

Epoch: 6| Step: 2
Training loss: 1.583680449466283
Validation loss: 2.3606953443252348

Epoch: 6| Step: 3
Training loss: 1.1816829957537738
Validation loss: 2.352131138793363

Epoch: 6| Step: 4
Training loss: 1.1764427681396443
Validation loss: 2.3992273579241425

Epoch: 6| Step: 5
Training loss: 1.6483254778796637
Validation loss: 2.3160955590124344

Epoch: 6| Step: 6
Training loss: 1.3520472544758084
Validation loss: 2.3554830599519736

Epoch: 6| Step: 7
Training loss: 1.4752086912033595
Validation loss: 2.4202133697446713

Epoch: 6| Step: 8
Training loss: 1.5710405019180735
Validation loss: 2.4354299990632584

Epoch: 6| Step: 9
Training loss: 1.9040066385393857
Validation loss: 2.3768349431242712

Epoch: 6| Step: 10
Training loss: 1.3768714826472268
Validation loss: 2.3755637073619034

Epoch: 6| Step: 11
Training loss: 2.3106556316199547
Validation loss: 2.384940712011428

Epoch: 6| Step: 12
Training loss: 0.9694623788967893
Validation loss: 2.4365735871624477

Epoch: 6| Step: 13
Training loss: 1.8631182265390491
Validation loss: 2.349813572774659

Epoch: 288| Step: 0
Training loss: 1.4956596681025722
Validation loss: 2.3684860161184256

Epoch: 6| Step: 1
Training loss: 1.8229819440507251
Validation loss: 2.368274104821236

Epoch: 6| Step: 2
Training loss: 1.5550381825656439
Validation loss: 2.3429453599995416

Epoch: 6| Step: 3
Training loss: 2.515829137255503
Validation loss: 2.3333156697824973

Epoch: 6| Step: 4
Training loss: 1.4803440977577185
Validation loss: 2.4156160210087547

Epoch: 6| Step: 5
Training loss: 1.1351034216458125
Validation loss: 2.358807611889878

Epoch: 6| Step: 6
Training loss: 2.1729995779992937
Validation loss: 2.338529242032111

Epoch: 6| Step: 7
Training loss: 1.1571651651697876
Validation loss: 2.396315357535442

Epoch: 6| Step: 8
Training loss: 1.7452320814602162
Validation loss: 2.324023233491851

Epoch: 6| Step: 9
Training loss: 1.2970237646609548
Validation loss: 2.437384668676553

Epoch: 6| Step: 10
Training loss: 1.6372620038349575
Validation loss: 2.3113742006981726

Epoch: 6| Step: 11
Training loss: 1.1517674961106716
Validation loss: 2.3761323659145535

Epoch: 6| Step: 12
Training loss: 1.3100108203004277
Validation loss: 2.3792112801396774

Epoch: 6| Step: 13
Training loss: 1.0188999486926387
Validation loss: 2.3611752848999523

Epoch: 289| Step: 0
Training loss: 1.393505841410274
Validation loss: 2.3830535298755264

Epoch: 6| Step: 1
Training loss: 1.3090989689085157
Validation loss: 2.4437667352209163

Epoch: 6| Step: 2
Training loss: 1.197087932798687
Validation loss: 2.3852528572573526

Epoch: 6| Step: 3
Training loss: 2.083646509155516
Validation loss: 2.435248213828064

Epoch: 6| Step: 4
Training loss: 1.49377484799711
Validation loss: 2.382394172881562

Epoch: 6| Step: 5
Training loss: 2.0006441032834723
Validation loss: 2.3746713703467504

Epoch: 6| Step: 6
Training loss: 1.4577781256152593
Validation loss: 2.39220131835753

Epoch: 6| Step: 7
Training loss: 1.1868308340234792
Validation loss: 2.35408708519732

Epoch: 6| Step: 8
Training loss: 1.4861409975574227
Validation loss: 2.460108086323832

Epoch: 6| Step: 9
Training loss: 1.337910583792732
Validation loss: 2.366152847766949

Epoch: 6| Step: 10
Training loss: 2.015173573176588
Validation loss: 2.372402303311861

Epoch: 6| Step: 11
Training loss: 1.4153457635671178
Validation loss: 2.347362955422035

Epoch: 6| Step: 12
Training loss: 1.413862013962164
Validation loss: 2.457241853320556

Epoch: 6| Step: 13
Training loss: 2.8065323991290105
Validation loss: 2.4068823043416683

Epoch: 290| Step: 0
Training loss: 1.0079566793291141
Validation loss: 2.4249147390658083

Epoch: 6| Step: 1
Training loss: 1.1623232348190917
Validation loss: 2.40408382176709

Epoch: 6| Step: 2
Training loss: 2.0907329628384907
Validation loss: 2.3725535276403646

Epoch: 6| Step: 3
Training loss: 1.3148236368944979
Validation loss: 2.4108067837182254

Epoch: 6| Step: 4
Training loss: 1.6659699732260105
Validation loss: 2.415768175918194

Epoch: 6| Step: 5
Training loss: 0.9815668287063362
Validation loss: 2.352348698514963

Epoch: 6| Step: 6
Training loss: 1.7974005552539538
Validation loss: 2.3888811623417427

Epoch: 6| Step: 7
Training loss: 2.182513083891742
Validation loss: 2.3069103635798767

Epoch: 6| Step: 8
Training loss: 1.380504945756508
Validation loss: 2.393632090682149

Epoch: 6| Step: 9
Training loss: 1.456434030324161
Validation loss: 2.4032610838836894

Epoch: 6| Step: 10
Training loss: 1.5487586218691687
Validation loss: 2.394810515404431

Epoch: 6| Step: 11
Training loss: 1.5159346274067766
Validation loss: 2.397672795504822

Epoch: 6| Step: 12
Training loss: 1.4993547005211454
Validation loss: 2.358821490764288

Epoch: 6| Step: 13
Training loss: 1.9661886113715186
Validation loss: 2.367588544914694

Epoch: 291| Step: 0
Training loss: 1.1690022160726905
Validation loss: 2.4288048854532662

Epoch: 6| Step: 1
Training loss: 1.6193356459799897
Validation loss: 2.4091241699306676

Epoch: 6| Step: 2
Training loss: 1.4650541841036526
Validation loss: 2.4018244591195996

Epoch: 6| Step: 3
Training loss: 1.2220818385988534
Validation loss: 2.3279456040381232

Epoch: 6| Step: 4
Training loss: 1.6760348325992689
Validation loss: 2.422334260296232

Epoch: 6| Step: 5
Training loss: 1.409339435746134
Validation loss: 2.413687910861361

Epoch: 6| Step: 6
Training loss: 1.4234034947710335
Validation loss: 2.407436211109292

Epoch: 6| Step: 7
Training loss: 2.1396676031775126
Validation loss: 2.3340745488776244

Epoch: 6| Step: 8
Training loss: 2.099220303704184
Validation loss: 2.3300067338595754

Epoch: 6| Step: 9
Training loss: 1.244097219335795
Validation loss: 2.36035762307869

Epoch: 6| Step: 10
Training loss: 1.405968701520251
Validation loss: 2.318176385606167

Epoch: 6| Step: 11
Training loss: 1.6074466448482623
Validation loss: 2.4013236519126426

Epoch: 6| Step: 12
Training loss: 1.3216780874344949
Validation loss: 2.3534889200273494

Epoch: 6| Step: 13
Training loss: 1.7542865570247397
Validation loss: 2.3386453015014315

Epoch: 292| Step: 0
Training loss: 1.2596062611167165
Validation loss: 2.3738597816281866

Epoch: 6| Step: 1
Training loss: 1.1830015306083987
Validation loss: 2.4321448780338475

Epoch: 6| Step: 2
Training loss: 1.227412518493603
Validation loss: 2.398357329492226

Epoch: 6| Step: 3
Training loss: 1.8284687468956158
Validation loss: 2.4371840622207395

Epoch: 6| Step: 4
Training loss: 1.4464510170811398
Validation loss: 2.4075030337913557

Epoch: 6| Step: 5
Training loss: 1.3345151322908606
Validation loss: 2.3933033265139616

Epoch: 6| Step: 6
Training loss: 2.005515480462993
Validation loss: 2.3455847162236254

Epoch: 6| Step: 7
Training loss: 2.2587977177066123
Validation loss: 2.305521954362709

Epoch: 6| Step: 8
Training loss: 1.2400585620648985
Validation loss: 2.360956963516534

Epoch: 6| Step: 9
Training loss: 1.3517768557579155
Validation loss: 2.4131674416940245

Epoch: 6| Step: 10
Training loss: 1.7002417981466391
Validation loss: 2.278974819265816

Epoch: 6| Step: 11
Training loss: 1.3106806270380418
Validation loss: 2.3680206839321336

Epoch: 6| Step: 12
Training loss: 1.207853216395466
Validation loss: 2.4022307813487935

Epoch: 6| Step: 13
Training loss: 1.9362614272133194
Validation loss: 2.373987748553179

Epoch: 293| Step: 0
Training loss: 1.4711869496437229
Validation loss: 2.3788373060110164

Epoch: 6| Step: 1
Training loss: 1.0516735953472032
Validation loss: 2.3353602374160176

Epoch: 6| Step: 2
Training loss: 1.400160000377494
Validation loss: 2.358283844773563

Epoch: 6| Step: 3
Training loss: 1.2654366529684868
Validation loss: 2.3545606031098876

Epoch: 6| Step: 4
Training loss: 1.5361619135385187
Validation loss: 2.3798284180094016

Epoch: 6| Step: 5
Training loss: 1.4206170186843585
Validation loss: 2.3520629097456296

Epoch: 6| Step: 6
Training loss: 1.531487115679379
Validation loss: 2.407687159274934

Epoch: 6| Step: 7
Training loss: 1.3316550968242071
Validation loss: 2.4018573435643162

Epoch: 6| Step: 8
Training loss: 2.4324666408905613
Validation loss: 2.39036535592596

Epoch: 6| Step: 9
Training loss: 1.7639998662217624
Validation loss: 2.3986403262701477

Epoch: 6| Step: 10
Training loss: 1.575820297491231
Validation loss: 2.4212089996294477

Epoch: 6| Step: 11
Training loss: 2.1536506797308554
Validation loss: 2.393898147509143

Epoch: 6| Step: 12
Training loss: 1.1435872634430622
Validation loss: 2.3859233327969434

Epoch: 6| Step: 13
Training loss: 1.007691132090628
Validation loss: 2.3225556095800957

Epoch: 294| Step: 0
Training loss: 1.7883584582059104
Validation loss: 2.352423847603999

Epoch: 6| Step: 1
Training loss: 1.496689640426746
Validation loss: 2.4388261252967687

Epoch: 6| Step: 2
Training loss: 1.4837554441768326
Validation loss: 2.443687413993065

Epoch: 6| Step: 3
Training loss: 2.3096938763523873
Validation loss: 2.372736437760026

Epoch: 6| Step: 4
Training loss: 1.666790798650894
Validation loss: 2.4195517488558687

Epoch: 6| Step: 5
Training loss: 1.7699942751430884
Validation loss: 2.4089925526803206

Epoch: 6| Step: 6
Training loss: 1.5258672655805976
Validation loss: 2.4332050144754263

Epoch: 6| Step: 7
Training loss: 1.12208114897672
Validation loss: 2.4097115003981613

Epoch: 6| Step: 8
Training loss: 1.4682174691172605
Validation loss: 2.3292169734736206

Epoch: 6| Step: 9
Training loss: 1.2289446883546946
Validation loss: 2.413160058315082

Epoch: 6| Step: 10
Training loss: 1.4441360221791506
Validation loss: 2.4280267056555447

Epoch: 6| Step: 11
Training loss: 1.501834542264922
Validation loss: 2.357506172487801

Epoch: 6| Step: 12
Training loss: 1.2523113339346312
Validation loss: 2.3517588114197108

Epoch: 6| Step: 13
Training loss: 1.0828644336835316
Validation loss: 2.42707392024282

Epoch: 295| Step: 0
Training loss: 1.2275584362749945
Validation loss: 2.396405592990723

Epoch: 6| Step: 1
Training loss: 1.411597279070996
Validation loss: 2.331998438466987

Epoch: 6| Step: 2
Training loss: 1.769151592157474
Validation loss: 2.3986027644519154

Epoch: 6| Step: 3
Training loss: 2.265597639247505
Validation loss: 2.3989564142484032

Epoch: 6| Step: 4
Training loss: 1.2815575579436569
Validation loss: 2.3606724959817145

Epoch: 6| Step: 5
Training loss: 0.9955315293511864
Validation loss: 2.3269613919950145

Epoch: 6| Step: 6
Training loss: 1.360081806807854
Validation loss: 2.4484892999892858

Epoch: 6| Step: 7
Training loss: 1.3039524954702588
Validation loss: 2.3778155163640875

Epoch: 6| Step: 8
Training loss: 1.728553349142545
Validation loss: 2.439383684219234

Epoch: 6| Step: 9
Training loss: 1.532653010136737
Validation loss: 2.374639504258117

Epoch: 6| Step: 10
Training loss: 1.720005062672461
Validation loss: 2.3783797598799024

Epoch: 6| Step: 11
Training loss: 1.5662028877497651
Validation loss: 2.375537250246224

Epoch: 6| Step: 12
Training loss: 1.4504222551015522
Validation loss: 2.4122333785850296

Epoch: 6| Step: 13
Training loss: 1.423185143152736
Validation loss: 2.3518195921539897

Epoch: 296| Step: 0
Training loss: 1.2759678514370967
Validation loss: 2.357981433186543

Epoch: 6| Step: 1
Training loss: 1.3158760701092984
Validation loss: 2.3429312541337777

Epoch: 6| Step: 2
Training loss: 2.201111651377788
Validation loss: 2.364729292723458

Epoch: 6| Step: 3
Training loss: 1.659965163060681
Validation loss: 2.357298365983247

Epoch: 6| Step: 4
Training loss: 1.687211329883068
Validation loss: 2.418860022180994

Epoch: 6| Step: 5
Training loss: 1.5832964323997358
Validation loss: 2.450649559431724

Epoch: 6| Step: 6
Training loss: 1.2294824916466378
Validation loss: 2.3744445268859113

Epoch: 6| Step: 7
Training loss: 1.0355003504768636
Validation loss: 2.3600118497846836

Epoch: 6| Step: 8
Training loss: 2.41437990145145
Validation loss: 2.398905778487086

Epoch: 6| Step: 9
Training loss: 1.4151202718889773
Validation loss: 2.3772934956179395

Epoch: 6| Step: 10
Training loss: 1.5447209320370898
Validation loss: 2.371099967466579

Epoch: 6| Step: 11
Training loss: 1.139973650427021
Validation loss: 2.399459819265675

Epoch: 6| Step: 12
Training loss: 1.3050395467765787
Validation loss: 2.4320769615206315

Epoch: 6| Step: 13
Training loss: 1.411507717080393
Validation loss: 2.3925439386392813

Epoch: 297| Step: 0
Training loss: 1.6063207143216796
Validation loss: 2.3801176656561385

Epoch: 6| Step: 1
Training loss: 1.6486310076921171
Validation loss: 2.40741511140251

Epoch: 6| Step: 2
Training loss: 1.7757102082756675
Validation loss: 2.300663570157369

Epoch: 6| Step: 3
Training loss: 1.6527087662907571
Validation loss: 2.3346803273981935

Epoch: 6| Step: 4
Training loss: 1.5647441007640368
Validation loss: 2.3590477766284987

Epoch: 6| Step: 5
Training loss: 1.7392898890746489
Validation loss: 2.3850105015264726

Epoch: 6| Step: 6
Training loss: 1.2603720454785095
Validation loss: 2.3653369450920603

Epoch: 6| Step: 7
Training loss: 1.3789196500046053
Validation loss: 2.3227874382938207

Epoch: 6| Step: 8
Training loss: 2.5608198659062524
Validation loss: 2.400646775611794

Epoch: 6| Step: 9
Training loss: 1.7169422005693218
Validation loss: 2.385624697861506

Epoch: 6| Step: 10
Training loss: 1.0808591588292045
Validation loss: 2.3482282015990203

Epoch: 6| Step: 11
Training loss: 1.2762457651932986
Validation loss: 2.356822144656788

Epoch: 6| Step: 12
Training loss: 1.3041473001295447
Validation loss: 2.3309720454821368

Epoch: 6| Step: 13
Training loss: 0.9500902672597061
Validation loss: 2.3495644035649215

Epoch: 298| Step: 0
Training loss: 1.8721844196119135
Validation loss: 2.333436586985759

Epoch: 6| Step: 1
Training loss: 1.2137055784321207
Validation loss: 2.3815500294263785

Epoch: 6| Step: 2
Training loss: 1.4922776120124153
Validation loss: 2.4124622036604637

Epoch: 6| Step: 3
Training loss: 1.2859415826002647
Validation loss: 2.377237774207799

Epoch: 6| Step: 4
Training loss: 1.0051195701715279
Validation loss: 2.3865682921957068

Epoch: 6| Step: 5
Training loss: 1.4538678147259203
Validation loss: 2.3645561238018464

Epoch: 6| Step: 6
Training loss: 1.4241309242979123
Validation loss: 2.345016019427853

Epoch: 6| Step: 7
Training loss: 1.185323477346497
Validation loss: 2.3651787591538076

Epoch: 6| Step: 8
Training loss: 2.5148373905041037
Validation loss: 2.331659759137368

Epoch: 6| Step: 9
Training loss: 1.8298428932873936
Validation loss: 2.3878282464485925

Epoch: 6| Step: 10
Training loss: 0.9698435855875787
Validation loss: 2.385490871646782

Epoch: 6| Step: 11
Training loss: 1.5047364160622054
Validation loss: 2.326264534311547

Epoch: 6| Step: 12
Training loss: 1.1452498539839382
Validation loss: 2.3275554406534584

Epoch: 6| Step: 13
Training loss: 1.4684066371105793
Validation loss: 2.2917813444856425

Epoch: 299| Step: 0
Training loss: 1.074335653706348
Validation loss: 2.377731689840187

Epoch: 6| Step: 1
Training loss: 1.382515999423775
Validation loss: 2.3067374152033433

Epoch: 6| Step: 2
Training loss: 1.430773796586197
Validation loss: 2.3151858617677985

Epoch: 6| Step: 3
Training loss: 2.1664103087350415
Validation loss: 2.415150416736144

Epoch: 6| Step: 4
Training loss: 1.04129969172611
Validation loss: 2.341802008741406

Epoch: 6| Step: 5
Training loss: 1.3073949988309346
Validation loss: 2.3656642212931613

Epoch: 6| Step: 6
Training loss: 1.250185475894018
Validation loss: 2.4333068355118295

Epoch: 6| Step: 7
Training loss: 1.8355777469173098
Validation loss: 2.399791099744031

Epoch: 6| Step: 8
Training loss: 2.162607854016795
Validation loss: 2.4517079875889203

Epoch: 6| Step: 9
Training loss: 1.4372624740072542
Validation loss: 2.3380486240167655

Epoch: 6| Step: 10
Training loss: 1.0707850283304616
Validation loss: 2.402142538986341

Epoch: 6| Step: 11
Training loss: 1.4176366327762242
Validation loss: 2.3638634448919813

Epoch: 6| Step: 12
Training loss: 2.2011868223344533
Validation loss: 2.3324390783822424

Epoch: 6| Step: 13
Training loss: 1.0839450588485156
Validation loss: 2.351166094563967

Epoch: 300| Step: 0
Training loss: 1.318360640913744
Validation loss: 2.394930728278187

Epoch: 6| Step: 1
Training loss: 1.3562604807083969
Validation loss: 2.368295653915509

Epoch: 6| Step: 2
Training loss: 1.0930697369224416
Validation loss: 2.342559613060193

Epoch: 6| Step: 3
Training loss: 1.4416210975868688
Validation loss: 2.396396859778564

Epoch: 6| Step: 4
Training loss: 1.1768397639059782
Validation loss: 2.3311849398146296

Epoch: 6| Step: 5
Training loss: 2.4132539944577647
Validation loss: 2.3561530858736837

Epoch: 6| Step: 6
Training loss: 1.9281704147653715
Validation loss: 2.3282875972726997

Epoch: 6| Step: 7
Training loss: 1.3475210370773087
Validation loss: 2.3904770873673766

Epoch: 6| Step: 8
Training loss: 1.3444882959556512
Validation loss: 2.3363378455191306

Epoch: 6| Step: 9
Training loss: 1.1474444189303035
Validation loss: 2.427747166060477

Epoch: 6| Step: 10
Training loss: 1.4782519489638695
Validation loss: 2.3822291216338787

Epoch: 6| Step: 11
Training loss: 1.7026608035739172
Validation loss: 2.351648026810943

Epoch: 6| Step: 12
Training loss: 1.6350005606554103
Validation loss: 2.4030247095764334

Epoch: 6| Step: 13
Training loss: 1.8126476490785746
Validation loss: 2.358235947590312

Epoch: 301| Step: 0
Training loss: 1.0150973196305997
Validation loss: 2.3484205365152504

Epoch: 6| Step: 1
Training loss: 1.29265920385325
Validation loss: 2.3958280102285894

Epoch: 6| Step: 2
Training loss: 1.4904060314902086
Validation loss: 2.332189524231245

Epoch: 6| Step: 3
Training loss: 2.2387159101914182
Validation loss: 2.3616447426795557

Epoch: 6| Step: 4
Training loss: 1.0702630470156058
Validation loss: 2.3717426637159083

Epoch: 6| Step: 5
Training loss: 1.8287165410180957
Validation loss: 2.314146388129507

Epoch: 6| Step: 6
Training loss: 1.986333586348656
Validation loss: 2.288481975309081

Epoch: 6| Step: 7
Training loss: 1.3798971965064393
Validation loss: 2.3450815127979916

Epoch: 6| Step: 8
Training loss: 2.003426477654518
Validation loss: 2.416674711180789

Epoch: 6| Step: 9
Training loss: 1.3882448207731821
Validation loss: 2.409214047479974

Epoch: 6| Step: 10
Training loss: 0.759449792640171
Validation loss: 2.349343447671024

Epoch: 6| Step: 11
Training loss: 1.2124398049425509
Validation loss: 2.3323206282367

Epoch: 6| Step: 12
Training loss: 1.3707068785960912
Validation loss: 2.384583232273766

Epoch: 6| Step: 13
Training loss: 1.7290343115222273
Validation loss: 2.3713792814577968

Epoch: 302| Step: 0
Training loss: 2.1278696318682333
Validation loss: 2.3244091065939747

Epoch: 6| Step: 1
Training loss: 1.3313612161663668
Validation loss: 2.3370437277217917

Epoch: 6| Step: 2
Training loss: 0.9888257121384971
Validation loss: 2.330687033805848

Epoch: 6| Step: 3
Training loss: 1.634393756824469
Validation loss: 2.4665676765844213

Epoch: 6| Step: 4
Training loss: 1.7631639190564916
Validation loss: 2.329329082458697

Epoch: 6| Step: 5
Training loss: 1.6490752084953328
Validation loss: 2.3897287725130836

Epoch: 6| Step: 6
Training loss: 1.31172834146343
Validation loss: 2.315418604414939

Epoch: 6| Step: 7
Training loss: 1.1727429037080683
Validation loss: 2.3534987933646665

Epoch: 6| Step: 8
Training loss: 1.561512291578029
Validation loss: 2.3838212439818935

Epoch: 6| Step: 9
Training loss: 1.6879219657885707
Validation loss: 2.3292364316924123

Epoch: 6| Step: 10
Training loss: 1.218189942227374
Validation loss: 2.3569539244383133

Epoch: 6| Step: 11
Training loss: 1.2620445751956957
Validation loss: 2.3515556503510657

Epoch: 6| Step: 12
Training loss: 1.5898618954834427
Validation loss: 2.3756373186673696

Epoch: 6| Step: 13
Training loss: 1.7636826220213468
Validation loss: 2.318234568897544

Epoch: 303| Step: 0
Training loss: 1.5297528168212373
Validation loss: 2.3767241052676753

Epoch: 6| Step: 1
Training loss: 1.392809662690845
Validation loss: 2.4144699210052027

Epoch: 6| Step: 2
Training loss: 1.7368531951139576
Validation loss: 2.3509096266763465

Epoch: 6| Step: 3
Training loss: 1.2880609493998707
Validation loss: 2.3583953943684937

Epoch: 6| Step: 4
Training loss: 1.6653580614508567
Validation loss: 2.336570881328892

Epoch: 6| Step: 5
Training loss: 0.9694973923567928
Validation loss: 2.3712019719195503

Epoch: 6| Step: 6
Training loss: 1.3633942652861097
Validation loss: 2.335069755918819

Epoch: 6| Step: 7
Training loss: 2.194714013240575
Validation loss: 2.351238363167337

Epoch: 6| Step: 8
Training loss: 1.262816385717722
Validation loss: 2.407638007779959

Epoch: 6| Step: 9
Training loss: 1.529178697640942
Validation loss: 2.428777801836043

Epoch: 6| Step: 10
Training loss: 1.6613148674165716
Validation loss: 2.3746420564110626

Epoch: 6| Step: 11
Training loss: 1.2468340357884837
Validation loss: 2.2874726225525173

Epoch: 6| Step: 12
Training loss: 1.9284808753214828
Validation loss: 2.3991715077409554

Epoch: 6| Step: 13
Training loss: 1.4268784573179343
Validation loss: 2.4028809508459212

Epoch: 304| Step: 0
Training loss: 1.3790552420806585
Validation loss: 2.44658915005233

Epoch: 6| Step: 1
Training loss: 2.3984743792652745
Validation loss: 2.3254588805273655

Epoch: 6| Step: 2
Training loss: 1.1874322871929985
Validation loss: 2.3859870451908907

Epoch: 6| Step: 3
Training loss: 1.4443515366646218
Validation loss: 2.43180414532898

Epoch: 6| Step: 4
Training loss: 1.5255350393786669
Validation loss: 2.415484394515745

Epoch: 6| Step: 5
Training loss: 0.9400300219489667
Validation loss: 2.346944229002609

Epoch: 6| Step: 6
Training loss: 1.7917672580011872
Validation loss: 2.4338652332723587

Epoch: 6| Step: 7
Training loss: 1.6155487455748938
Validation loss: 2.3820439829348636

Epoch: 6| Step: 8
Training loss: 1.5762533287358058
Validation loss: 2.4180162379323864

Epoch: 6| Step: 9
Training loss: 1.4159392658560237
Validation loss: 2.3678079503580753

Epoch: 6| Step: 10
Training loss: 1.2830788190718947
Validation loss: 2.413648002209892

Epoch: 6| Step: 11
Training loss: 1.7134950934886117
Validation loss: 2.426974182195476

Epoch: 6| Step: 12
Training loss: 1.6033852973786356
Validation loss: 2.4443419209459334

Epoch: 6| Step: 13
Training loss: 1.295311180270527
Validation loss: 2.347318745595417

Epoch: 305| Step: 0
Training loss: 1.5381494902544801
Validation loss: 2.353364515042501

Epoch: 6| Step: 1
Training loss: 1.3141226048280348
Validation loss: 2.408756105954081

Epoch: 6| Step: 2
Training loss: 1.5306713022788783
Validation loss: 2.3570488356451498

Epoch: 6| Step: 3
Training loss: 1.3753079156294306
Validation loss: 2.3660067419730093

Epoch: 6| Step: 4
Training loss: 1.6571393774024246
Validation loss: 2.3855991292846164

Epoch: 6| Step: 5
Training loss: 1.4450869822474308
Validation loss: 2.3731243075504764

Epoch: 6| Step: 6
Training loss: 0.851437550748381
Validation loss: 2.3805202368539167

Epoch: 6| Step: 7
Training loss: 1.720519109059435
Validation loss: 2.379324910215534

Epoch: 6| Step: 8
Training loss: 1.6535319932415398
Validation loss: 2.3594718184691112

Epoch: 6| Step: 9
Training loss: 1.0450763909011191
Validation loss: 2.364663355874887

Epoch: 6| Step: 10
Training loss: 1.4979227305551737
Validation loss: 2.2661814344738977

Epoch: 6| Step: 11
Training loss: 1.0268826918682492
Validation loss: 2.346132594647017

Epoch: 6| Step: 12
Training loss: 1.3232394848334945
Validation loss: 2.359190819237996

Epoch: 6| Step: 13
Training loss: 2.7850613999233076
Validation loss: 2.3848085776078767

Epoch: 306| Step: 0
Training loss: 1.3981051343070101
Validation loss: 2.352604995901709

Epoch: 6| Step: 1
Training loss: 1.4252549127488379
Validation loss: 2.3699124361024326

Epoch: 6| Step: 2
Training loss: 1.5416238452359885
Validation loss: 2.3570906559028795

Epoch: 6| Step: 3
Training loss: 1.297583926285109
Validation loss: 2.371453681004891

Epoch: 6| Step: 4
Training loss: 1.4321180851108397
Validation loss: 2.3705040237070727

Epoch: 6| Step: 5
Training loss: 1.8401209142595654
Validation loss: 2.3470683626178026

Epoch: 6| Step: 6
Training loss: 1.3022712673619068
Validation loss: 2.2931054570273335

Epoch: 6| Step: 7
Training loss: 2.1469188524678877
Validation loss: 2.360592218509869

Epoch: 6| Step: 8
Training loss: 2.011949366711654
Validation loss: 2.3123009681135587

Epoch: 6| Step: 9
Training loss: 0.8816757986128224
Validation loss: 2.368851455808878

Epoch: 6| Step: 10
Training loss: 1.0794674904518917
Validation loss: 2.3496087858100982

Epoch: 6| Step: 11
Training loss: 1.4117942870070284
Validation loss: 2.355836416790562

Epoch: 6| Step: 12
Training loss: 1.803735523231872
Validation loss: 2.390265868700187

Epoch: 6| Step: 13
Training loss: 1.7441400782124004
Validation loss: 2.411276163251751

Epoch: 307| Step: 0
Training loss: 1.0115944333084332
Validation loss: 2.3962736023951536

Epoch: 6| Step: 1
Training loss: 1.242999021687817
Validation loss: 2.37355002639498

Epoch: 6| Step: 2
Training loss: 1.1224317906307404
Validation loss: 2.344364132286643

Epoch: 6| Step: 3
Training loss: 1.5025549428227813
Validation loss: 2.3798306823617437

Epoch: 6| Step: 4
Training loss: 1.2014515620932096
Validation loss: 2.361626765117819

Epoch: 6| Step: 5
Training loss: 1.7820274931630993
Validation loss: 2.372797389360524

Epoch: 6| Step: 6
Training loss: 1.6724848125321303
Validation loss: 2.2829800994601332

Epoch: 6| Step: 7
Training loss: 1.8818126255367176
Validation loss: 2.3832708102589697

Epoch: 6| Step: 8
Training loss: 1.5831629343529314
Validation loss: 2.380955160479234

Epoch: 6| Step: 9
Training loss: 1.0697837693103378
Validation loss: 2.3893877828293424

Epoch: 6| Step: 10
Training loss: 1.6999703685197618
Validation loss: 2.400550382196953

Epoch: 6| Step: 11
Training loss: 2.006745645018638
Validation loss: 2.4171095715562543

Epoch: 6| Step: 12
Training loss: 1.70482319852063
Validation loss: 2.333251415153655

Epoch: 6| Step: 13
Training loss: 1.3745614132613007
Validation loss: 2.3135675755838836

Epoch: 308| Step: 0
Training loss: 1.682843884358717
Validation loss: 2.309544566839867

Epoch: 6| Step: 1
Training loss: 1.5551110845549865
Validation loss: 2.43496022139567

Epoch: 6| Step: 2
Training loss: 2.0982258341277222
Validation loss: 2.302210581049544

Epoch: 6| Step: 3
Training loss: 1.8996827864615888
Validation loss: 2.354947911107453

Epoch: 6| Step: 4
Training loss: 0.9876900212434896
Validation loss: 2.402271229172661

Epoch: 6| Step: 5
Training loss: 1.4754442289561507
Validation loss: 2.379760488053179

Epoch: 6| Step: 6
Training loss: 1.3677897843306415
Validation loss: 2.4162862271046883

Epoch: 6| Step: 7
Training loss: 1.300175247851274
Validation loss: 2.352861466398249

Epoch: 6| Step: 8
Training loss: 1.4589506296036792
Validation loss: 2.3846498546456596

Epoch: 6| Step: 9
Training loss: 1.529046321918186
Validation loss: 2.3977714132864625

Epoch: 6| Step: 10
Training loss: 1.2803622170632964
Validation loss: 2.3540719042526925

Epoch: 6| Step: 11
Training loss: 1.3179904902032622
Validation loss: 2.4021435544562846

Epoch: 6| Step: 12
Training loss: 1.6822076388731575
Validation loss: 2.3543768471398243

Epoch: 6| Step: 13
Training loss: 1.2972861867559913
Validation loss: 2.3729363539333876

Epoch: 309| Step: 0
Training loss: 1.2406959455753312
Validation loss: 2.3941232007426403

Epoch: 6| Step: 1
Training loss: 1.298279656503241
Validation loss: 2.3722125555414197

Epoch: 6| Step: 2
Training loss: 1.220712792930465
Validation loss: 2.3582261281942802

Epoch: 6| Step: 3
Training loss: 1.5123567245341465
Validation loss: 2.3782470733887107

Epoch: 6| Step: 4
Training loss: 1.646777433512903
Validation loss: 2.3865861672770006

Epoch: 6| Step: 5
Training loss: 1.3619058661007033
Validation loss: 2.339227902709008

Epoch: 6| Step: 6
Training loss: 1.2367655144607645
Validation loss: 2.39454361780691

Epoch: 6| Step: 7
Training loss: 1.3260043548265066
Validation loss: 2.3981275027785944

Epoch: 6| Step: 8
Training loss: 0.994979774039493
Validation loss: 2.3654444213856896

Epoch: 6| Step: 9
Training loss: 1.689128231495194
Validation loss: 2.416854435970841

Epoch: 6| Step: 10
Training loss: 1.4197210408605998
Validation loss: 2.3326636769311984

Epoch: 6| Step: 11
Training loss: 2.2887608456315602
Validation loss: 2.346594950834207

Epoch: 6| Step: 12
Training loss: 1.6378631596772304
Validation loss: 2.32879925561005

Epoch: 6| Step: 13
Training loss: 1.0854576752299354
Validation loss: 2.3804734289459866

Epoch: 310| Step: 0
Training loss: 1.0816462413659937
Validation loss: 2.3605984587488673

Epoch: 6| Step: 1
Training loss: 1.8322043916592798
Validation loss: 2.3736657505804546

Epoch: 6| Step: 2
Training loss: 1.5523346392398252
Validation loss: 2.33923458242044

Epoch: 6| Step: 3
Training loss: 1.0546336407508097
Validation loss: 2.3679458961176056

Epoch: 6| Step: 4
Training loss: 1.2968312451438497
Validation loss: 2.3700013268206015

Epoch: 6| Step: 5
Training loss: 1.4610502638111285
Validation loss: 2.3727288275461453

Epoch: 6| Step: 6
Training loss: 1.445088137146345
Validation loss: 2.420629568936919

Epoch: 6| Step: 7
Training loss: 1.0608432980768865
Validation loss: 2.3573164472437083

Epoch: 6| Step: 8
Training loss: 1.5855330529354106
Validation loss: 2.3387767900930054

Epoch: 6| Step: 9
Training loss: 0.9679934100565157
Validation loss: 2.4030468250484947

Epoch: 6| Step: 10
Training loss: 1.5355591378781284
Validation loss: 2.3538081540182523

Epoch: 6| Step: 11
Training loss: 2.025364492131915
Validation loss: 2.355261527840851

Epoch: 6| Step: 12
Training loss: 2.228838697413277
Validation loss: 2.4439587347858485

Epoch: 6| Step: 13
Training loss: 0.7099501072452393
Validation loss: 2.383188875256285

Epoch: 311| Step: 0
Training loss: 1.404927882586998
Validation loss: 2.32146638102247

Epoch: 6| Step: 1
Training loss: 1.2272002876301296
Validation loss: 2.344997248602614

Epoch: 6| Step: 2
Training loss: 1.4471208960771589
Validation loss: 2.356081046363578

Epoch: 6| Step: 3
Training loss: 1.4332165130796735
Validation loss: 2.3867112713744225

Epoch: 6| Step: 4
Training loss: 1.3713418676295923
Validation loss: 2.3263547831678912

Epoch: 6| Step: 5
Training loss: 1.691256615625089
Validation loss: 2.322759101946695

Epoch: 6| Step: 6
Training loss: 0.9457154479202815
Validation loss: 2.3834465916688283

Epoch: 6| Step: 7
Training loss: 2.0223890261388573
Validation loss: 2.3571996680886795

Epoch: 6| Step: 8
Training loss: 2.050588486104236
Validation loss: 2.3622715595791255

Epoch: 6| Step: 9
Training loss: 1.7863174768493797
Validation loss: 2.3320742021021506

Epoch: 6| Step: 10
Training loss: 1.1269994028727888
Validation loss: 2.374523672060498

Epoch: 6| Step: 11
Training loss: 1.5162421474269172
Validation loss: 2.4011960874939065

Epoch: 6| Step: 12
Training loss: 1.379046511338053
Validation loss: 2.362443858543748

Epoch: 6| Step: 13
Training loss: 0.936679576471447
Validation loss: 2.426376901891216

Epoch: 312| Step: 0
Training loss: 1.4395366007851276
Validation loss: 2.3271941180595905

Epoch: 6| Step: 1
Training loss: 1.3145162898810383
Validation loss: 2.4026786703462015

Epoch: 6| Step: 2
Training loss: 1.766937982970212
Validation loss: 2.3268006995889094

Epoch: 6| Step: 3
Training loss: 2.16318645717343
Validation loss: 2.349351107993289

Epoch: 6| Step: 4
Training loss: 1.3558959287806118
Validation loss: 2.360584766257137

Epoch: 6| Step: 5
Training loss: 1.2612030109011458
Validation loss: 2.314890179746032

Epoch: 6| Step: 6
Training loss: 1.7917232800196314
Validation loss: 2.3881404200538268

Epoch: 6| Step: 7
Training loss: 1.073478304824534
Validation loss: 2.4007575138533057

Epoch: 6| Step: 8
Training loss: 2.1174531326601898
Validation loss: 2.3737116829185148

Epoch: 6| Step: 9
Training loss: 1.0617883206128786
Validation loss: 2.343118737092805

Epoch: 6| Step: 10
Training loss: 1.3479312781947672
Validation loss: 2.422632121423942

Epoch: 6| Step: 11
Training loss: 1.0705361237076898
Validation loss: 2.35744880293663

Epoch: 6| Step: 12
Training loss: 1.3911724941603398
Validation loss: 2.422478864729928

Epoch: 6| Step: 13
Training loss: 1.231530787793618
Validation loss: 2.385325734279389

Epoch: 313| Step: 0
Training loss: 1.5456528893348216
Validation loss: 2.4153163038175616

Epoch: 6| Step: 1
Training loss: 1.3451858655851134
Validation loss: 2.4317528256767664

Epoch: 6| Step: 2
Training loss: 2.2160236640245072
Validation loss: 2.3416682130541875

Epoch: 6| Step: 3
Training loss: 1.1814028161721337
Validation loss: 2.3329838309340203

Epoch: 6| Step: 4
Training loss: 0.7226773233176358
Validation loss: 2.4266842306189527

Epoch: 6| Step: 5
Training loss: 1.4826065772667785
Validation loss: 2.361332530674876

Epoch: 6| Step: 6
Training loss: 1.0867996635453339
Validation loss: 2.378146192553171

Epoch: 6| Step: 7
Training loss: 1.346715006873451
Validation loss: 2.369841033915362

Epoch: 6| Step: 8
Training loss: 1.2253436696398694
Validation loss: 2.375852216053929

Epoch: 6| Step: 9
Training loss: 1.3748285013231785
Validation loss: 2.3674523136313037

Epoch: 6| Step: 10
Training loss: 1.2696782423165902
Validation loss: 2.3209402335186464

Epoch: 6| Step: 11
Training loss: 1.6039524761066084
Validation loss: 2.3783426601051323

Epoch: 6| Step: 12
Training loss: 2.044426654943294
Validation loss: 2.3783521241408967

Epoch: 6| Step: 13
Training loss: 1.2768474863069077
Validation loss: 2.3295151829074308

Epoch: 314| Step: 0
Training loss: 1.4138104124509538
Validation loss: 2.3285576599416986

Epoch: 6| Step: 1
Training loss: 1.8795855081464323
Validation loss: 2.3158081823189574

Epoch: 6| Step: 2
Training loss: 1.477638780817947
Validation loss: 2.3967413581093155

Epoch: 6| Step: 3
Training loss: 1.3601366299129454
Validation loss: 2.373739992063268

Epoch: 6| Step: 4
Training loss: 1.1411494264440178
Validation loss: 2.3245160742771627

Epoch: 6| Step: 5
Training loss: 1.6123080886074819
Validation loss: 2.3605711974929

Epoch: 6| Step: 6
Training loss: 1.0662856260834674
Validation loss: 2.3764438536402204

Epoch: 6| Step: 7
Training loss: 1.5272433743091955
Validation loss: 2.3983667647882507

Epoch: 6| Step: 8
Training loss: 1.5895728927942712
Validation loss: 2.3018616140027275

Epoch: 6| Step: 9
Training loss: 1.2729579279945162
Validation loss: 2.371240995945507

Epoch: 6| Step: 10
Training loss: 1.3813220251300473
Validation loss: 2.3628580686563336

Epoch: 6| Step: 11
Training loss: 0.9423916040514462
Validation loss: 2.415858489684147

Epoch: 6| Step: 12
Training loss: 2.0655243403252537
Validation loss: 2.4047208331766767

Epoch: 6| Step: 13
Training loss: 0.6226005988816329
Validation loss: 2.335778433766739

Epoch: 315| Step: 0
Training loss: 1.4340618315258948
Validation loss: 2.3530669034301024

Epoch: 6| Step: 1
Training loss: 1.4903844355353537
Validation loss: 2.4046756424075437

Epoch: 6| Step: 2
Training loss: 1.8598128372285916
Validation loss: 2.43044774493666

Epoch: 6| Step: 3
Training loss: 1.4357742233345205
Validation loss: 2.3403094526696706

Epoch: 6| Step: 4
Training loss: 0.974782098971984
Validation loss: 2.3565251671694654

Epoch: 6| Step: 5
Training loss: 1.8953374975809263
Validation loss: 2.3374344668771996

Epoch: 6| Step: 6
Training loss: 1.0684612441792685
Validation loss: 2.3576465858492788

Epoch: 6| Step: 7
Training loss: 1.120212221645545
Validation loss: 2.3803627912041585

Epoch: 6| Step: 8
Training loss: 1.8050138500453647
Validation loss: 2.343854134820127

Epoch: 6| Step: 9
Training loss: 1.189028559236691
Validation loss: 2.3321145844035778

Epoch: 6| Step: 10
Training loss: 1.6181085884378836
Validation loss: 2.3530519485110744

Epoch: 6| Step: 11
Training loss: 1.1215845821286838
Validation loss: 2.3820642817288205

Epoch: 6| Step: 12
Training loss: 1.4703947557067332
Validation loss: 2.3972149054646303

Epoch: 6| Step: 13
Training loss: 1.900467152637581
Validation loss: 2.4103820740724555

Epoch: 316| Step: 0
Training loss: 1.2364684593259538
Validation loss: 2.3539303159936265

Epoch: 6| Step: 1
Training loss: 1.2443349258354073
Validation loss: 2.406624046715037

Epoch: 6| Step: 2
Training loss: 1.889204390050604
Validation loss: 2.3075243632250158

Epoch: 6| Step: 3
Training loss: 1.0526253213821934
Validation loss: 2.3595293523309766

Epoch: 6| Step: 4
Training loss: 1.144829825036388
Validation loss: 2.338445593008334

Epoch: 6| Step: 5
Training loss: 1.2045390254056865
Validation loss: 2.3487962663640354

Epoch: 6| Step: 6
Training loss: 2.335621585981259
Validation loss: 2.3186562078729116

Epoch: 6| Step: 7
Training loss: 1.622920025620843
Validation loss: 2.368063876391699

Epoch: 6| Step: 8
Training loss: 1.3276993462121573
Validation loss: 2.3162993123308686

Epoch: 6| Step: 9
Training loss: 1.266690406242233
Validation loss: 2.34045326617893

Epoch: 6| Step: 10
Training loss: 1.587157808804606
Validation loss: 2.3638881250254777

Epoch: 6| Step: 11
Training loss: 1.3242568289083967
Validation loss: 2.3426382730123096

Epoch: 6| Step: 12
Training loss: 1.5303137895026762
Validation loss: 2.348297111931554

Epoch: 6| Step: 13
Training loss: 1.4905667115657077
Validation loss: 2.3869985073403575

Epoch: 317| Step: 0
Training loss: 1.4237782243270443
Validation loss: 2.345823300408172

Epoch: 6| Step: 1
Training loss: 1.885250112297076
Validation loss: 2.3586689806024563

Epoch: 6| Step: 2
Training loss: 1.3895550158282866
Validation loss: 2.3655583675855203

Epoch: 6| Step: 3
Training loss: 1.971778236106696
Validation loss: 2.300243763180097

Epoch: 6| Step: 4
Training loss: 1.3440048951871597
Validation loss: 2.3897691149390075

Epoch: 6| Step: 5
Training loss: 1.9393921503506704
Validation loss: 2.384950132128342

Epoch: 6| Step: 6
Training loss: 0.9632835901731605
Validation loss: 2.375456677578301

Epoch: 6| Step: 7
Training loss: 1.1536075709120976
Validation loss: 2.3598480391483143

Epoch: 6| Step: 8
Training loss: 1.1314482267590156
Validation loss: 2.313236190338706

Epoch: 6| Step: 9
Training loss: 1.1680935694107744
Validation loss: 2.3951088444369377

Epoch: 6| Step: 10
Training loss: 1.2648399649852649
Validation loss: 2.285740161972135

Epoch: 6| Step: 11
Training loss: 1.7366844815654143
Validation loss: 2.4002572535749525

Epoch: 6| Step: 12
Training loss: 1.1365045824206066
Validation loss: 2.3524897875041133

Epoch: 6| Step: 13
Training loss: 1.5704870933529456
Validation loss: 2.3660174949059583

Epoch: 318| Step: 0
Training loss: 1.7014108133092818
Validation loss: 2.3434011460875466

Epoch: 6| Step: 1
Training loss: 1.526203090562317
Validation loss: 2.3504884607111856

Epoch: 6| Step: 2
Training loss: 1.2060919504934289
Validation loss: 2.3544699752726954

Epoch: 6| Step: 3
Training loss: 1.5613065357829605
Validation loss: 2.4520848910923694

Epoch: 6| Step: 4
Training loss: 1.1542191067750966
Validation loss: 2.4130116268903707

Epoch: 6| Step: 5
Training loss: 1.354951523480248
Validation loss: 2.4165888187852893

Epoch: 6| Step: 6
Training loss: 1.574916334806203
Validation loss: 2.4401143286652727

Epoch: 6| Step: 7
Training loss: 0.870351466568431
Validation loss: 2.4498957781109327

Epoch: 6| Step: 8
Training loss: 1.4903862752029604
Validation loss: 2.3108389242365455

Epoch: 6| Step: 9
Training loss: 2.2777846679996805
Validation loss: 2.422348040834414

Epoch: 6| Step: 10
Training loss: 1.5114334192025705
Validation loss: 2.390723915742677

Epoch: 6| Step: 11
Training loss: 1.6059917702517448
Validation loss: 2.4083144440286106

Epoch: 6| Step: 12
Training loss: 1.3331870157703136
Validation loss: 2.3573714933115975

Epoch: 6| Step: 13
Training loss: 0.7259061165970897
Validation loss: 2.3267417140802187

Epoch: 319| Step: 0
Training loss: 1.601389061445389
Validation loss: 2.3237884153429746

Epoch: 6| Step: 1
Training loss: 1.6683211300556353
Validation loss: 2.3196904661479603

Epoch: 6| Step: 2
Training loss: 1.678674365716559
Validation loss: 2.350589569324978

Epoch: 6| Step: 3
Training loss: 1.2985904791695193
Validation loss: 2.3953022208098034

Epoch: 6| Step: 4
Training loss: 1.4510780601930695
Validation loss: 2.306350890283097

Epoch: 6| Step: 5
Training loss: 1.298272448537561
Validation loss: 2.310548658027627

Epoch: 6| Step: 6
Training loss: 2.295720024105106
Validation loss: 2.4023969101311837

Epoch: 6| Step: 7
Training loss: 1.5660301004198938
Validation loss: 2.407950963665564

Epoch: 6| Step: 8
Training loss: 1.2896041656849269
Validation loss: 2.3760835629314387

Epoch: 6| Step: 9
Training loss: 1.425984323749809
Validation loss: 2.321527987982292

Epoch: 6| Step: 10
Training loss: 1.050617531427074
Validation loss: 2.363645109870134

Epoch: 6| Step: 11
Training loss: 0.9415650609713068
Validation loss: 2.305624563445691

Epoch: 6| Step: 12
Training loss: 1.1450379587736255
Validation loss: 2.2841059346888266

Epoch: 6| Step: 13
Training loss: 1.4761842919438406
Validation loss: 2.3409139317635685

Epoch: 320| Step: 0
Training loss: 1.4050017857115995
Validation loss: 2.3900791163995176

Epoch: 6| Step: 1
Training loss: 1.0542200253417997
Validation loss: 2.251353255687756

Epoch: 6| Step: 2
Training loss: 1.459291724498128
Validation loss: 2.3102892635314527

Epoch: 6| Step: 3
Training loss: 1.157285999429574
Validation loss: 2.3421650067204416

Epoch: 6| Step: 4
Training loss: 1.8426377772625824
Validation loss: 2.321572060614552

Epoch: 6| Step: 5
Training loss: 1.15213848807473
Validation loss: 2.349905791343756

Epoch: 6| Step: 6
Training loss: 1.4580166427436891
Validation loss: 2.3591220488948026

Epoch: 6| Step: 7
Training loss: 1.4740438627448147
Validation loss: 2.361929185920104

Epoch: 6| Step: 8
Training loss: 1.7081710536762862
Validation loss: 2.359572230321241

Epoch: 6| Step: 9
Training loss: 1.071460525853624
Validation loss: 2.336482520947914

Epoch: 6| Step: 10
Training loss: 1.7176667701345587
Validation loss: 2.3368037841922136

Epoch: 6| Step: 11
Training loss: 0.9452046104213778
Validation loss: 2.4030883600860404

Epoch: 6| Step: 12
Training loss: 2.1291389548133792
Validation loss: 2.368606401511365

Epoch: 6| Step: 13
Training loss: 0.8793431192351954
Validation loss: 2.3382356062766774

Epoch: 321| Step: 0
Training loss: 1.1460261038258812
Validation loss: 2.292653426410273

Epoch: 6| Step: 1
Training loss: 1.5020509844227319
Validation loss: 2.300998498023922

Epoch: 6| Step: 2
Training loss: 1.7519862619453637
Validation loss: 2.358081190153254

Epoch: 6| Step: 3
Training loss: 1.4288375913081253
Validation loss: 2.3777867942876525

Epoch: 6| Step: 4
Training loss: 1.3972641268480315
Validation loss: 2.3441329872841137

Epoch: 6| Step: 5
Training loss: 1.0265357027083553
Validation loss: 2.2940875292786083

Epoch: 6| Step: 6
Training loss: 1.5011778022119031
Validation loss: 2.3314850543504195

Epoch: 6| Step: 7
Training loss: 1.497811867236062
Validation loss: 2.35546950043659

Epoch: 6| Step: 8
Training loss: 2.0058705479088776
Validation loss: 2.334202821044188

Epoch: 6| Step: 9
Training loss: 1.6416114384741596
Validation loss: 2.273050306618477

Epoch: 6| Step: 10
Training loss: 1.0494014941580567
Validation loss: 2.2383055739049382

Epoch: 6| Step: 11
Training loss: 0.9084761670586556
Validation loss: 2.3253283303464607

Epoch: 6| Step: 12
Training loss: 1.9100927174617826
Validation loss: 2.342304069751212

Epoch: 6| Step: 13
Training loss: 0.6517095395308262
Validation loss: 2.367011011519568

Epoch: 322| Step: 0
Training loss: 1.0937940316192793
Validation loss: 2.3230203220705947

Epoch: 6| Step: 1
Training loss: 1.0720435296408841
Validation loss: 2.354157540269811

Epoch: 6| Step: 2
Training loss: 1.407517645947165
Validation loss: 2.303021771770447

Epoch: 6| Step: 3
Training loss: 1.3591947764926653
Validation loss: 2.367418726587815

Epoch: 6| Step: 4
Training loss: 1.426515656586898
Validation loss: 2.3072599181374214

Epoch: 6| Step: 5
Training loss: 1.6108786956088756
Validation loss: 2.34416605876358

Epoch: 6| Step: 6
Training loss: 2.0085622374749312
Validation loss: 2.3553099241574076

Epoch: 6| Step: 7
Training loss: 1.3470040775058942
Validation loss: 2.322762520394225

Epoch: 6| Step: 8
Training loss: 1.4260739378787473
Validation loss: 2.302069991412793

Epoch: 6| Step: 9
Training loss: 1.6375790613321994
Validation loss: 2.279801803712681

Epoch: 6| Step: 10
Training loss: 1.0548843765176565
Validation loss: 2.347375095579375

Epoch: 6| Step: 11
Training loss: 1.73980275976425
Validation loss: 2.329796959803839

Epoch: 6| Step: 12
Training loss: 1.4141666100044366
Validation loss: 2.3315371394952953

Epoch: 6| Step: 13
Training loss: 1.3830898028418905
Validation loss: 2.3211149732067358

Epoch: 323| Step: 0
Training loss: 1.3596973256286773
Validation loss: 2.3243037680407204

Epoch: 6| Step: 1
Training loss: 1.5209480486242026
Validation loss: 2.359837562285075

Epoch: 6| Step: 2
Training loss: 1.257658575839957
Validation loss: 2.2665643721262296

Epoch: 6| Step: 3
Training loss: 2.1048909316269597
Validation loss: 2.366541018249386

Epoch: 6| Step: 4
Training loss: 1.730599495316492
Validation loss: 2.264971553500079

Epoch: 6| Step: 5
Training loss: 2.31438678372747
Validation loss: 2.370310120302174

Epoch: 6| Step: 6
Training loss: 1.222837684502637
Validation loss: 2.348382044810631

Epoch: 6| Step: 7
Training loss: 1.4567811971256452
Validation loss: 2.2787596127747296

Epoch: 6| Step: 8
Training loss: 1.18981341838686
Validation loss: 2.350359779084374

Epoch: 6| Step: 9
Training loss: 1.2682185972218494
Validation loss: 2.3106169745769134

Epoch: 6| Step: 10
Training loss: 1.0681827824623287
Validation loss: 2.292673096548133

Epoch: 6| Step: 11
Training loss: 1.2714621546337483
Validation loss: 2.322571145535882

Epoch: 6| Step: 12
Training loss: 1.3242856349201386
Validation loss: 2.3633864268600506

Epoch: 6| Step: 13
Training loss: 1.3207337649790087
Validation loss: 2.3852126904874424

Epoch: 324| Step: 0
Training loss: 1.170375576789581
Validation loss: 2.3844237589007276

Epoch: 6| Step: 1
Training loss: 2.231449158913534
Validation loss: 2.332643147174474

Epoch: 6| Step: 2
Training loss: 1.2098933486595482
Validation loss: 2.296946551455963

Epoch: 6| Step: 3
Training loss: 1.0716373013220082
Validation loss: 2.330518551030355

Epoch: 6| Step: 4
Training loss: 1.2910452188628958
Validation loss: 2.390773402103883

Epoch: 6| Step: 5
Training loss: 1.479963473049683
Validation loss: 2.390692695239904

Epoch: 6| Step: 6
Training loss: 0.9173483192565262
Validation loss: 2.3420872018988663

Epoch: 6| Step: 7
Training loss: 1.4523095745069188
Validation loss: 2.3480143222542877

Epoch: 6| Step: 8
Training loss: 1.656715471609301
Validation loss: 2.356400774520869

Epoch: 6| Step: 9
Training loss: 1.592453148480542
Validation loss: 2.3351958732770277

Epoch: 6| Step: 10
Training loss: 1.6699057416526955
Validation loss: 2.3558362328833597

Epoch: 6| Step: 11
Training loss: 1.6082203991758839
Validation loss: 2.424459509901322

Epoch: 6| Step: 12
Training loss: 1.2802559788122392
Validation loss: 2.2901845895781214

Epoch: 6| Step: 13
Training loss: 1.6519300154762895
Validation loss: 2.3214811633964763

Epoch: 325| Step: 0
Training loss: 1.5267782505907828
Validation loss: 2.400788895522698

Epoch: 6| Step: 1
Training loss: 1.320809806750586
Validation loss: 2.319439980246319

Epoch: 6| Step: 2
Training loss: 1.8938735921583973
Validation loss: 2.3473097822456777

Epoch: 6| Step: 3
Training loss: 1.3641474466867136
Validation loss: 2.3026069929364885

Epoch: 6| Step: 4
Training loss: 0.9456218812214111
Validation loss: 2.3558947701473154

Epoch: 6| Step: 5
Training loss: 1.176506553829435
Validation loss: 2.292780224328606

Epoch: 6| Step: 6
Training loss: 1.329862378249576
Validation loss: 2.35500659890582

Epoch: 6| Step: 7
Training loss: 1.5351265863168566
Validation loss: 2.376712975786575

Epoch: 6| Step: 8
Training loss: 2.2056720700731294
Validation loss: 2.328634163049533

Epoch: 6| Step: 9
Training loss: 1.677002148608092
Validation loss: 2.3766060446833253

Epoch: 6| Step: 10
Training loss: 1.0238374118027163
Validation loss: 2.369294633818557

Epoch: 6| Step: 11
Training loss: 1.8061843543349838
Validation loss: 2.3440324302784465

Epoch: 6| Step: 12
Training loss: 1.167985896874552
Validation loss: 2.289016794293476

Epoch: 6| Step: 13
Training loss: 0.8956836457095375
Validation loss: 2.2977818232343132

Epoch: 326| Step: 0
Training loss: 1.312043519339208
Validation loss: 2.279583311870989

Epoch: 6| Step: 1
Training loss: 1.690171141000331
Validation loss: 2.340151564667239

Epoch: 6| Step: 2
Training loss: 1.3115921513784752
Validation loss: 2.309587730118822

Epoch: 6| Step: 3
Training loss: 1.0734091187213637
Validation loss: 2.313505056866619

Epoch: 6| Step: 4
Training loss: 1.4131317869392068
Validation loss: 2.3393582298048528

Epoch: 6| Step: 5
Training loss: 1.2603801795575351
Validation loss: 2.3479615304204895

Epoch: 6| Step: 6
Training loss: 1.9261684686139013
Validation loss: 2.2954817126020246

Epoch: 6| Step: 7
Training loss: 0.9184444412431221
Validation loss: 2.3694271675922636

Epoch: 6| Step: 8
Training loss: 1.6174771699075443
Validation loss: 2.3860869020663946

Epoch: 6| Step: 9
Training loss: 1.635195002344971
Validation loss: 2.334862832548146

Epoch: 6| Step: 10
Training loss: 1.014014272615706
Validation loss: 2.3675934581447984

Epoch: 6| Step: 11
Training loss: 1.5558614467920238
Validation loss: 2.38916082957626

Epoch: 6| Step: 12
Training loss: 1.6762122109155329
Validation loss: 2.3681206098874203

Epoch: 6| Step: 13
Training loss: 1.9945714113500614
Validation loss: 2.373343904434135

Epoch: 327| Step: 0
Training loss: 1.062498204846829
Validation loss: 2.345663412713449

Epoch: 6| Step: 1
Training loss: 0.9994799036311854
Validation loss: 2.412714318531031

Epoch: 6| Step: 2
Training loss: 1.4623793560380243
Validation loss: 2.3255267888265405

Epoch: 6| Step: 3
Training loss: 1.6997273703357925
Validation loss: 2.414866185867427

Epoch: 6| Step: 4
Training loss: 1.3693196265386776
Validation loss: 2.3174475170652626

Epoch: 6| Step: 5
Training loss: 1.2476142527487428
Validation loss: 2.308740032963871

Epoch: 6| Step: 6
Training loss: 2.068783983948351
Validation loss: 2.3696890787941407

Epoch: 6| Step: 7
Training loss: 1.617033946537914
Validation loss: 2.2996337576292114

Epoch: 6| Step: 8
Training loss: 1.7220328450764506
Validation loss: 2.317976563157502

Epoch: 6| Step: 9
Training loss: 1.2190048733771077
Validation loss: 2.3620303686461726

Epoch: 6| Step: 10
Training loss: 1.677847915022707
Validation loss: 2.3422953290959834

Epoch: 6| Step: 11
Training loss: 1.1170800430797674
Validation loss: 2.352555051015637

Epoch: 6| Step: 12
Training loss: 1.2649918844693975
Validation loss: 2.242112654021704

Epoch: 6| Step: 13
Training loss: 1.3674795220356868
Validation loss: 2.3289403154667903

Epoch: 328| Step: 0
Training loss: 1.3045321160716925
Validation loss: 2.3379207210306885

Epoch: 6| Step: 1
Training loss: 1.6154852860210724
Validation loss: 2.3945189618910465

Epoch: 6| Step: 2
Training loss: 1.3986974293474699
Validation loss: 2.3891426953047494

Epoch: 6| Step: 3
Training loss: 1.1072750902535065
Validation loss: 2.3197463050409715

Epoch: 6| Step: 4
Training loss: 2.2110321779501882
Validation loss: 2.3383292676277394

Epoch: 6| Step: 5
Training loss: 0.8977970660244357
Validation loss: 2.348994304699059

Epoch: 6| Step: 6
Training loss: 1.1676935490475677
Validation loss: 2.326388257248565

Epoch: 6| Step: 7
Training loss: 1.4014578653698377
Validation loss: 2.3695655286645008

Epoch: 6| Step: 8
Training loss: 1.7435478065878842
Validation loss: 2.343914602098633

Epoch: 6| Step: 9
Training loss: 1.2110971653181064
Validation loss: 2.3202320674797954

Epoch: 6| Step: 10
Training loss: 1.1875365904139892
Validation loss: 2.350653699013405

Epoch: 6| Step: 11
Training loss: 1.3866303321696654
Validation loss: 2.2999211405717013

Epoch: 6| Step: 12
Training loss: 1.974902937713158
Validation loss: 2.2646709884752334

Epoch: 6| Step: 13
Training loss: 0.7572377571811421
Validation loss: 2.3645447906812183

Epoch: 329| Step: 0
Training loss: 1.3919894778687059
Validation loss: 2.308362055081128

Epoch: 6| Step: 1
Training loss: 1.6714840012862182
Validation loss: 2.3309562795647105

Epoch: 6| Step: 2
Training loss: 1.1823985797867098
Validation loss: 2.3542816327512908

Epoch: 6| Step: 3
Training loss: 1.306284309922231
Validation loss: 2.337171071842504

Epoch: 6| Step: 4
Training loss: 1.1052160614539257
Validation loss: 2.2982829978697144

Epoch: 6| Step: 5
Training loss: 0.9882263047697029
Validation loss: 2.3115461533542456

Epoch: 6| Step: 6
Training loss: 1.2511802823120397
Validation loss: 2.357667031630315

Epoch: 6| Step: 7
Training loss: 1.3762335012834601
Validation loss: 2.358727570925491

Epoch: 6| Step: 8
Training loss: 1.6598896844816036
Validation loss: 2.3156741185956013

Epoch: 6| Step: 9
Training loss: 1.2745589952160206
Validation loss: 2.3985873164170033

Epoch: 6| Step: 10
Training loss: 1.6622842232779387
Validation loss: 2.340133580837893

Epoch: 6| Step: 11
Training loss: 1.6180271788343152
Validation loss: 2.324489255064562

Epoch: 6| Step: 12
Training loss: 2.0325167887277
Validation loss: 2.3174690155288316

Epoch: 6| Step: 13
Training loss: 1.4532543658025745
Validation loss: 2.31088174550246

Epoch: 330| Step: 0
Training loss: 1.1908757263674683
Validation loss: 2.314734984421661

Epoch: 6| Step: 1
Training loss: 0.9370465771590561
Validation loss: 2.389150263428997

Epoch: 6| Step: 2
Training loss: 1.1337865390798791
Validation loss: 2.3677960297314704

Epoch: 6| Step: 3
Training loss: 1.857186961436302
Validation loss: 2.2931090289631233

Epoch: 6| Step: 4
Training loss: 1.574040026493889
Validation loss: 2.3495069333864924

Epoch: 6| Step: 5
Training loss: 1.3184330672401836
Validation loss: 2.3042916240349687

Epoch: 6| Step: 6
Training loss: 1.01687972983847
Validation loss: 2.261858675287753

Epoch: 6| Step: 7
Training loss: 1.0513244699597595
Validation loss: 2.333235810771797

Epoch: 6| Step: 8
Training loss: 2.506293005824036
Validation loss: 2.288878852947216

Epoch: 6| Step: 9
Training loss: 1.1822280306502118
Validation loss: 2.375775831710928

Epoch: 6| Step: 10
Training loss: 1.3765262023089155
Validation loss: 2.3223334224516297

Epoch: 6| Step: 11
Training loss: 0.9560113571681483
Validation loss: 2.3518298136888727

Epoch: 6| Step: 12
Training loss: 1.5189688065762121
Validation loss: 2.285555697225515

Epoch: 6| Step: 13
Training loss: 0.8259113162419122
Validation loss: 2.303795710282722

Epoch: 331| Step: 0
Training loss: 1.0635457222189002
Validation loss: 2.345813606779749

Epoch: 6| Step: 1
Training loss: 1.274088967904273
Validation loss: 2.4024389430021906

Epoch: 6| Step: 2
Training loss: 1.3929430040856752
Validation loss: 2.282273952075611

Epoch: 6| Step: 3
Training loss: 1.4492034500013617
Validation loss: 2.3359022575120894

Epoch: 6| Step: 4
Training loss: 1.0489666667911524
Validation loss: 2.386078218920619

Epoch: 6| Step: 5
Training loss: 2.307525232575932
Validation loss: 2.2646959820877886

Epoch: 6| Step: 6
Training loss: 0.9702951352935248
Validation loss: 2.3799537997760942

Epoch: 6| Step: 7
Training loss: 1.6338861759233454
Validation loss: 2.360569412066219

Epoch: 6| Step: 8
Training loss: 1.211384352406523
Validation loss: 2.350068302510304

Epoch: 6| Step: 9
Training loss: 1.8017307517234458
Validation loss: 2.3451118893203353

Epoch: 6| Step: 10
Training loss: 1.5003567907068525
Validation loss: 2.3854607739535036

Epoch: 6| Step: 11
Training loss: 1.5128428299197345
Validation loss: 2.3080338828014164

Epoch: 6| Step: 12
Training loss: 1.2738941520604004
Validation loss: 2.358786872221561

Epoch: 6| Step: 13
Training loss: 0.9579212021246739
Validation loss: 2.3150410170788365

Epoch: 332| Step: 0
Training loss: 1.4823596323086685
Validation loss: 2.3457874518152737

Epoch: 6| Step: 1
Training loss: 0.9635811703118905
Validation loss: 2.33371545223447

Epoch: 6| Step: 2
Training loss: 1.5079699024009867
Validation loss: 2.3395251549683884

Epoch: 6| Step: 3
Training loss: 1.1652569371237727
Validation loss: 2.3422335569290453

Epoch: 6| Step: 4
Training loss: 1.2022307404173067
Validation loss: 2.33567566432554

Epoch: 6| Step: 5
Training loss: 1.5888841437036991
Validation loss: 2.3837789897004575

Epoch: 6| Step: 6
Training loss: 1.2932285382067898
Validation loss: 2.3585400162247465

Epoch: 6| Step: 7
Training loss: 1.4970449108300372
Validation loss: 2.3326412029927504

Epoch: 6| Step: 8
Training loss: 2.0350744776488248
Validation loss: 2.38592656807136

Epoch: 6| Step: 9
Training loss: 1.5482585383986238
Validation loss: 2.3717864207155426

Epoch: 6| Step: 10
Training loss: 1.0646943825112163
Validation loss: 2.378046991344297

Epoch: 6| Step: 11
Training loss: 1.2799227282922863
Validation loss: 2.3455148354096

Epoch: 6| Step: 12
Training loss: 1.3206207547568651
Validation loss: 2.338690098142014

Epoch: 6| Step: 13
Training loss: 1.982231484276516
Validation loss: 2.376098425219896

Epoch: 333| Step: 0
Training loss: 1.2673035310993293
Validation loss: 2.3276808758929186

Epoch: 6| Step: 1
Training loss: 1.3601652457319373
Validation loss: 2.3928591544286744

Epoch: 6| Step: 2
Training loss: 1.2365047093697783
Validation loss: 2.3133202439222997

Epoch: 6| Step: 3
Training loss: 1.4033617240513614
Validation loss: 2.3281789948073417

Epoch: 6| Step: 4
Training loss: 1.224626702242349
Validation loss: 2.327200155929825

Epoch: 6| Step: 5
Training loss: 1.2491722227095572
Validation loss: 2.3507918781985535

Epoch: 6| Step: 6
Training loss: 1.9421947574249712
Validation loss: 2.356624151132005

Epoch: 6| Step: 7
Training loss: 1.9570173007978107
Validation loss: 2.3631469026659846

Epoch: 6| Step: 8
Training loss: 1.3512156046848827
Validation loss: 2.3325190363862687

Epoch: 6| Step: 9
Training loss: 1.0827763054593431
Validation loss: 2.366276057672203

Epoch: 6| Step: 10
Training loss: 1.0431407543750317
Validation loss: 2.2993934970385075

Epoch: 6| Step: 11
Training loss: 1.2608297422517178
Validation loss: 2.339743307228754

Epoch: 6| Step: 12
Training loss: 1.754720927707284
Validation loss: 2.3540215461585405

Epoch: 6| Step: 13
Training loss: 1.4267707630903943
Validation loss: 2.376821226600906

Epoch: 334| Step: 0
Training loss: 1.4404694115285186
Validation loss: 2.3790504412810436

Epoch: 6| Step: 1
Training loss: 1.1331162670238726
Validation loss: 2.303139218695993

Epoch: 6| Step: 2
Training loss: 0.8672626222256606
Validation loss: 2.3738451990710807

Epoch: 6| Step: 3
Training loss: 1.6167221505518383
Validation loss: 2.3521295654897174

Epoch: 6| Step: 4
Training loss: 2.056548925313534
Validation loss: 2.3399223744330993

Epoch: 6| Step: 5
Training loss: 1.3088783979418237
Validation loss: 2.3198362505086187

Epoch: 6| Step: 6
Training loss: 1.3003449954240331
Validation loss: 2.4215340217159063

Epoch: 6| Step: 7
Training loss: 1.3268412051252267
Validation loss: 2.356065176440659

Epoch: 6| Step: 8
Training loss: 1.3431264628264359
Validation loss: 2.3617454616064606

Epoch: 6| Step: 9
Training loss: 1.69034548439007
Validation loss: 2.3162283072412

Epoch: 6| Step: 10
Training loss: 1.5855210231901775
Validation loss: 2.3692730267239592

Epoch: 6| Step: 11
Training loss: 0.9499659481972893
Validation loss: 2.3071518792725714

Epoch: 6| Step: 12
Training loss: 1.0335196747478106
Validation loss: 2.3329640270558203

Epoch: 6| Step: 13
Training loss: 1.035072409635421
Validation loss: 2.3373721560423215

Epoch: 335| Step: 0
Training loss: 1.0964943923737225
Validation loss: 2.2939204190891305

Epoch: 6| Step: 1
Training loss: 1.8789510424185907
Validation loss: 2.3327842526343545

Epoch: 6| Step: 2
Training loss: 1.235758669872767
Validation loss: 2.360935349068219

Epoch: 6| Step: 3
Training loss: 1.8960883279981449
Validation loss: 2.352635242047581

Epoch: 6| Step: 4
Training loss: 1.4095107527015185
Validation loss: 2.31544727473024

Epoch: 6| Step: 5
Training loss: 1.2034234506583887
Validation loss: 2.3197776786018185

Epoch: 6| Step: 6
Training loss: 1.2170364364491963
Validation loss: 2.2695977751200185

Epoch: 6| Step: 7
Training loss: 1.0224162823417784
Validation loss: 2.3010242251058144

Epoch: 6| Step: 8
Training loss: 1.461092853955853
Validation loss: 2.376547961469594

Epoch: 6| Step: 9
Training loss: 1.0685418511862375
Validation loss: 2.289751845510855

Epoch: 6| Step: 10
Training loss: 0.8472614335712261
Validation loss: 2.376994018596584

Epoch: 6| Step: 11
Training loss: 1.854595741888099
Validation loss: 2.3028956465716943

Epoch: 6| Step: 12
Training loss: 1.2721847738050778
Validation loss: 2.3946115068502785

Epoch: 6| Step: 13
Training loss: 1.78145818999481
Validation loss: 2.3684261122992947

Epoch: 336| Step: 0
Training loss: 1.3882817875351774
Validation loss: 2.3488500572093045

Epoch: 6| Step: 1
Training loss: 2.3005278727934932
Validation loss: 2.3152407341252634

Epoch: 6| Step: 2
Training loss: 0.9175179531201504
Validation loss: 2.3576966457841677

Epoch: 6| Step: 3
Training loss: 1.5034087708288788
Validation loss: 2.4601000851856227

Epoch: 6| Step: 4
Training loss: 1.1026005824911793
Validation loss: 2.3323376247980754

Epoch: 6| Step: 5
Training loss: 2.166446625711251
Validation loss: 2.3743203285693144

Epoch: 6| Step: 6
Training loss: 0.9636444793010999
Validation loss: 2.308551631437992

Epoch: 6| Step: 7
Training loss: 1.2803451320147918
Validation loss: 2.323988837885468

Epoch: 6| Step: 8
Training loss: 1.1038358780661992
Validation loss: 2.284271750589885

Epoch: 6| Step: 9
Training loss: 1.2220833993350944
Validation loss: 2.2991784534071122

Epoch: 6| Step: 10
Training loss: 1.6233853608057283
Validation loss: 2.271439178998778

Epoch: 6| Step: 11
Training loss: 1.0953010460530865
Validation loss: 2.403874810741364

Epoch: 6| Step: 12
Training loss: 1.5478647321748493
Validation loss: 2.367071337797339

Epoch: 6| Step: 13
Training loss: 1.2391537261129861
Validation loss: 2.3962865988334383

Epoch: 337| Step: 0
Training loss: 1.3340770862360085
Validation loss: 2.400782202338665

Epoch: 6| Step: 1
Training loss: 1.2920619400813709
Validation loss: 2.326391696535401

Epoch: 6| Step: 2
Training loss: 2.14429109823383
Validation loss: 2.3700275406977305

Epoch: 6| Step: 3
Training loss: 1.676796772170418
Validation loss: 2.3221519225248324

Epoch: 6| Step: 4
Training loss: 1.208864665228954
Validation loss: 2.3357169255377954

Epoch: 6| Step: 5
Training loss: 0.8494943124312413
Validation loss: 2.3113341786508013

Epoch: 6| Step: 6
Training loss: 1.190113404263873
Validation loss: 2.373108771441235

Epoch: 6| Step: 7
Training loss: 1.3039869609192558
Validation loss: 2.3857818843736824

Epoch: 6| Step: 8
Training loss: 1.1453805317781047
Validation loss: 2.360988779737365

Epoch: 6| Step: 9
Training loss: 1.4076241878517002
Validation loss: 2.3675055095129753

Epoch: 6| Step: 10
Training loss: 1.0382840101264221
Validation loss: 2.4101633798521673

Epoch: 6| Step: 11
Training loss: 1.3442346896377508
Validation loss: 2.344202373422794

Epoch: 6| Step: 12
Training loss: 1.198037824170552
Validation loss: 2.3361240144724045

Epoch: 6| Step: 13
Training loss: 2.013190640241276
Validation loss: 2.3475234301042778

Epoch: 338| Step: 0
Training loss: 1.321982056090538
Validation loss: 2.34537942994207

Epoch: 6| Step: 1
Training loss: 2.46255256093275
Validation loss: 2.305761714235925

Epoch: 6| Step: 2
Training loss: 1.1570638936632518
Validation loss: 2.314900280836539

Epoch: 6| Step: 3
Training loss: 1.2072440641869093
Validation loss: 2.327980425174192

Epoch: 6| Step: 4
Training loss: 1.2223590331138232
Validation loss: 2.3594427101086146

Epoch: 6| Step: 5
Training loss: 1.0935697679523952
Validation loss: 2.3813323019012365

Epoch: 6| Step: 6
Training loss: 1.4732279591111608
Validation loss: 2.366486969246268

Epoch: 6| Step: 7
Training loss: 1.0302649908939894
Validation loss: 2.362075999228139

Epoch: 6| Step: 8
Training loss: 1.0887867166523113
Validation loss: 2.3239964119011574

Epoch: 6| Step: 9
Training loss: 1.146904057854437
Validation loss: 2.3254250526902833

Epoch: 6| Step: 10
Training loss: 1.398397604943326
Validation loss: 2.3460771455568823

Epoch: 6| Step: 11
Training loss: 1.3644054772559244
Validation loss: 2.3810193444356016

Epoch: 6| Step: 12
Training loss: 1.6681171860410036
Validation loss: 2.3132381779816122

Epoch: 6| Step: 13
Training loss: 1.120166248687165
Validation loss: 2.364687944181369

Epoch: 339| Step: 0
Training loss: 1.2417183235909832
Validation loss: 2.3311826199632444

Epoch: 6| Step: 1
Training loss: 1.2361828566505035
Validation loss: 2.34791257863944

Epoch: 6| Step: 2
Training loss: 2.2255256246284123
Validation loss: 2.3898761993965216

Epoch: 6| Step: 3
Training loss: 1.6060644376566195
Validation loss: 2.3388072770007646

Epoch: 6| Step: 4
Training loss: 1.783149242109311
Validation loss: 2.3676385121247816

Epoch: 6| Step: 5
Training loss: 1.1450791853796816
Validation loss: 2.2848946258125773

Epoch: 6| Step: 6
Training loss: 1.1296253487992833
Validation loss: 2.3790562791169556

Epoch: 6| Step: 7
Training loss: 1.4022366368606958
Validation loss: 2.2950782213297325

Epoch: 6| Step: 8
Training loss: 1.4710976526144797
Validation loss: 2.3578591000119866

Epoch: 6| Step: 9
Training loss: 1.1334655983731101
Validation loss: 2.3503317808846527

Epoch: 6| Step: 10
Training loss: 0.9891556200301381
Validation loss: 2.4102236046155525

Epoch: 6| Step: 11
Training loss: 1.6293730947280707
Validation loss: 2.3779098380205097

Epoch: 6| Step: 12
Training loss: 1.2463210804372593
Validation loss: 2.2649898420909835

Epoch: 6| Step: 13
Training loss: 1.0918618935211635
Validation loss: 2.314825261939024

Epoch: 340| Step: 0
Training loss: 1.057777906835461
Validation loss: 2.3501148225934543

Epoch: 6| Step: 1
Training loss: 1.7883867878433735
Validation loss: 2.3511385843715615

Epoch: 6| Step: 2
Training loss: 1.3476774352246748
Validation loss: 2.3915297734216234

Epoch: 6| Step: 3
Training loss: 0.996041390033921
Validation loss: 2.3109940262181072

Epoch: 6| Step: 4
Training loss: 2.146157681540866
Validation loss: 2.3802374358283003

Epoch: 6| Step: 5
Training loss: 1.6414619853939378
Validation loss: 2.349317842153281

Epoch: 6| Step: 6
Training loss: 0.828173294098698
Validation loss: 2.3986739266265347

Epoch: 6| Step: 7
Training loss: 1.1592176346002876
Validation loss: 2.3572284708086575

Epoch: 6| Step: 8
Training loss: 1.5107695682463402
Validation loss: 2.3328551488756135

Epoch: 6| Step: 9
Training loss: 0.9588756305392642
Validation loss: 2.3502214471424985

Epoch: 6| Step: 10
Training loss: 0.8471452781430826
Validation loss: 2.3572829588476476

Epoch: 6| Step: 11
Training loss: 1.3462601216253622
Validation loss: 2.4311545684721034

Epoch: 6| Step: 12
Training loss: 1.3485792896607949
Validation loss: 2.3496215875640822

Epoch: 6| Step: 13
Training loss: 1.625302359988152
Validation loss: 2.3837105669633765

Epoch: 341| Step: 0
Training loss: 1.0860031437415607
Validation loss: 2.308724730952233

Epoch: 6| Step: 1
Training loss: 0.8920595762132331
Validation loss: 2.3027448266630004

Epoch: 6| Step: 2
Training loss: 1.8031305640281896
Validation loss: 2.3728036488214026

Epoch: 6| Step: 3
Training loss: 2.24526914635669
Validation loss: 2.367578317513035

Epoch: 6| Step: 4
Training loss: 0.9539465568455949
Validation loss: 2.3141830891175634

Epoch: 6| Step: 5
Training loss: 1.0544437833283038
Validation loss: 2.3953533913519367

Epoch: 6| Step: 6
Training loss: 1.0416681989022747
Validation loss: 2.3603469605770773

Epoch: 6| Step: 7
Training loss: 1.1201510303709337
Validation loss: 2.304787772006365

Epoch: 6| Step: 8
Training loss: 1.402084581658921
Validation loss: 2.337000919610313

Epoch: 6| Step: 9
Training loss: 1.4028275274303355
Validation loss: 2.3038192734886964

Epoch: 6| Step: 10
Training loss: 1.1694388435261862
Validation loss: 2.353128897264375

Epoch: 6| Step: 11
Training loss: 1.8275730571416464
Validation loss: 2.3199522428544115

Epoch: 6| Step: 12
Training loss: 1.065383924136034
Validation loss: 2.370811419509445

Epoch: 6| Step: 13
Training loss: 1.012080065451181
Validation loss: 2.38644108795969

Epoch: 342| Step: 0
Training loss: 1.6808517324675925
Validation loss: 2.308173186761658

Epoch: 6| Step: 1
Training loss: 1.2046083496057718
Validation loss: 2.3885842468728966

Epoch: 6| Step: 2
Training loss: 1.0308964441131356
Validation loss: 2.2893759139728798

Epoch: 6| Step: 3
Training loss: 1.5165798679428688
Validation loss: 2.356717528766582

Epoch: 6| Step: 4
Training loss: 1.310258313402115
Validation loss: 2.303622692773594

Epoch: 6| Step: 5
Training loss: 1.1730308427455036
Validation loss: 2.3440826092501674

Epoch: 6| Step: 6
Training loss: 0.8700994453376675
Validation loss: 2.294855938769093

Epoch: 6| Step: 7
Training loss: 1.6223774802290902
Validation loss: 2.340019228670165

Epoch: 6| Step: 8
Training loss: 0.9431619694304016
Validation loss: 2.405406439670692

Epoch: 6| Step: 9
Training loss: 0.9085750351583184
Validation loss: 2.308343101697882

Epoch: 6| Step: 10
Training loss: 2.5925600930351713
Validation loss: 2.368655149122688

Epoch: 6| Step: 11
Training loss: 1.1313080367064605
Validation loss: 2.298445565261332

Epoch: 6| Step: 12
Training loss: 1.6084149654537478
Validation loss: 2.388166296347452

Epoch: 6| Step: 13
Training loss: 0.8645602801516501
Validation loss: 2.2362633592185266

Epoch: 343| Step: 0
Training loss: 1.1952206445443023
Validation loss: 2.345195902345711

Epoch: 6| Step: 1
Training loss: 2.0872494575773013
Validation loss: 2.3323967045545757

Epoch: 6| Step: 2
Training loss: 0.9132843617956503
Validation loss: 2.3498458333480503

Epoch: 6| Step: 3
Training loss: 1.3903081725883404
Validation loss: 2.377485220380224

Epoch: 6| Step: 4
Training loss: 1.3584662282717217
Validation loss: 2.3692546818008067

Epoch: 6| Step: 5
Training loss: 1.012582299926053
Validation loss: 2.309313742188614

Epoch: 6| Step: 6
Training loss: 1.4305204039434856
Validation loss: 2.314370626794197

Epoch: 6| Step: 7
Training loss: 1.5439348117922482
Validation loss: 2.335862570664643

Epoch: 6| Step: 8
Training loss: 1.3421255539264727
Validation loss: 2.359003459489967

Epoch: 6| Step: 9
Training loss: 0.7328027980788504
Validation loss: 2.3600859749397127

Epoch: 6| Step: 10
Training loss: 1.2146699051187462
Validation loss: 2.4039713278616657

Epoch: 6| Step: 11
Training loss: 1.0201522864932122
Validation loss: 2.3574409362091413

Epoch: 6| Step: 12
Training loss: 1.094878677022286
Validation loss: 2.3387017851057395

Epoch: 6| Step: 13
Training loss: 2.5454491678713684
Validation loss: 2.3105815455978655

Epoch: 344| Step: 0
Training loss: 1.347581988513837
Validation loss: 2.3065638525622036

Epoch: 6| Step: 1
Training loss: 1.1878593302715534
Validation loss: 2.352274567130577

Epoch: 6| Step: 2
Training loss: 1.0409638640684828
Validation loss: 2.30212477327161

Epoch: 6| Step: 3
Training loss: 1.3505670486861532
Validation loss: 2.323561193582516

Epoch: 6| Step: 4
Training loss: 1.5719467692741758
Validation loss: 2.3379335177025644

Epoch: 6| Step: 5
Training loss: 1.687698352600404
Validation loss: 2.4012663859787264

Epoch: 6| Step: 6
Training loss: 1.0513583729115972
Validation loss: 2.3484128223958995

Epoch: 6| Step: 7
Training loss: 1.3302191884975278
Validation loss: 2.3926329689529005

Epoch: 6| Step: 8
Training loss: 0.8675625308033844
Validation loss: 2.3488326802492843

Epoch: 6| Step: 9
Training loss: 1.1233700494586056
Validation loss: 2.3563555013212714

Epoch: 6| Step: 10
Training loss: 1.6105696309008886
Validation loss: 2.326725200558266

Epoch: 6| Step: 11
Training loss: 1.2169446533989705
Validation loss: 2.3340406792319137

Epoch: 6| Step: 12
Training loss: 2.0873506595392413
Validation loss: 2.3515713980817132

Epoch: 6| Step: 13
Training loss: 1.5689400515995842
Validation loss: 2.3371696672628994

Epoch: 345| Step: 0
Training loss: 1.2901535503169326
Validation loss: 2.3277145082217015

Epoch: 6| Step: 1
Training loss: 2.5286624068487393
Validation loss: 2.296779954004225

Epoch: 6| Step: 2
Training loss: 1.5781438845269387
Validation loss: 2.352381900243368

Epoch: 6| Step: 3
Training loss: 1.3271368951134155
Validation loss: 2.3210126391528907

Epoch: 6| Step: 4
Training loss: 1.3479996395761478
Validation loss: 2.310852654663072

Epoch: 6| Step: 5
Training loss: 1.007805166291752
Validation loss: 2.354296603815381

Epoch: 6| Step: 6
Training loss: 1.2708928245419313
Validation loss: 2.251807671650862

Epoch: 6| Step: 7
Training loss: 1.1489925470500557
Validation loss: 2.269759815619458

Epoch: 6| Step: 8
Training loss: 1.463033630959731
Validation loss: 2.284084594729782

Epoch: 6| Step: 9
Training loss: 1.1034373027722473
Validation loss: 2.392356844713181

Epoch: 6| Step: 10
Training loss: 0.9215547684338379
Validation loss: 2.2981697916015547

Epoch: 6| Step: 11
Training loss: 1.3083422518788623
Validation loss: 2.2911333435843217

Epoch: 6| Step: 12
Training loss: 1.020542914412008
Validation loss: 2.4101875252488703

Epoch: 6| Step: 13
Training loss: 1.745763077456524
Validation loss: 2.3107480666174114

Epoch: 346| Step: 0
Training loss: 1.2585133560617718
Validation loss: 2.2606151371380774

Epoch: 6| Step: 1
Training loss: 1.7633310455470876
Validation loss: 2.312951810689805

Epoch: 6| Step: 2
Training loss: 1.5441267472754985
Validation loss: 2.266669699345948

Epoch: 6| Step: 3
Training loss: 0.9024752566467172
Validation loss: 2.3359614534378066

Epoch: 6| Step: 4
Training loss: 1.1228113607501167
Validation loss: 2.35461672997257

Epoch: 6| Step: 5
Training loss: 1.2759087110528047
Validation loss: 2.359456124554821

Epoch: 6| Step: 6
Training loss: 1.5295883816800537
Validation loss: 2.290390762108321

Epoch: 6| Step: 7
Training loss: 1.6029009180937255
Validation loss: 2.282479238625631

Epoch: 6| Step: 8
Training loss: 1.2536279482398405
Validation loss: 2.32178617213735

Epoch: 6| Step: 9
Training loss: 1.133774132182595
Validation loss: 2.29899878079337

Epoch: 6| Step: 10
Training loss: 1.4897937848294738
Validation loss: 2.363306017028667

Epoch: 6| Step: 11
Training loss: 1.8456152193641577
Validation loss: 2.314962048694021

Epoch: 6| Step: 12
Training loss: 0.9400580157983397
Validation loss: 2.304465753848872

Epoch: 6| Step: 13
Training loss: 1.102697180331171
Validation loss: 2.3187393789465776

Epoch: 347| Step: 0
Training loss: 0.9992150563879397
Validation loss: 2.3046105723945365

Epoch: 6| Step: 1
Training loss: 1.3108338725401556
Validation loss: 2.312353034699847

Epoch: 6| Step: 2
Training loss: 1.3001674544249668
Validation loss: 2.328137019142145

Epoch: 6| Step: 3
Training loss: 0.8965507599097539
Validation loss: 2.327429588899473

Epoch: 6| Step: 4
Training loss: 1.045833810043733
Validation loss: 2.365989215801115

Epoch: 6| Step: 5
Training loss: 1.4798816332007476
Validation loss: 2.328938241604667

Epoch: 6| Step: 6
Training loss: 1.850852926918595
Validation loss: 2.259091348585623

Epoch: 6| Step: 7
Training loss: 1.2742072745156692
Validation loss: 2.284242430286193

Epoch: 6| Step: 8
Training loss: 1.510068006941939
Validation loss: 2.3073328530666513

Epoch: 6| Step: 9
Training loss: 1.1700317127461919
Validation loss: 2.334244580549085

Epoch: 6| Step: 10
Training loss: 1.4077498596684517
Validation loss: 2.3923916375831853

Epoch: 6| Step: 11
Training loss: 1.551463479131316
Validation loss: 2.293217396278626

Epoch: 6| Step: 12
Training loss: 1.205449818272739
Validation loss: 2.3657652518589236

Epoch: 6| Step: 13
Training loss: 1.5353837560528085
Validation loss: 2.3817446134839444

Epoch: 348| Step: 0
Training loss: 1.4949570762570656
Validation loss: 2.296989158487249

Epoch: 6| Step: 1
Training loss: 0.9374969800264672
Validation loss: 2.333727744677035

Epoch: 6| Step: 2
Training loss: 1.3182066426286465
Validation loss: 2.271814010561355

Epoch: 6| Step: 3
Training loss: 1.2317576605943976
Validation loss: 2.330425191252892

Epoch: 6| Step: 4
Training loss: 0.9529277409781692
Validation loss: 2.381510459008086

Epoch: 6| Step: 5
Training loss: 1.414265486337246
Validation loss: 2.3257484228668557

Epoch: 6| Step: 6
Training loss: 1.3872104686357447
Validation loss: 2.3035387343978955

Epoch: 6| Step: 7
Training loss: 1.176187438760516
Validation loss: 2.2934386270549245

Epoch: 6| Step: 8
Training loss: 2.4889013933915924
Validation loss: 2.326582362378908

Epoch: 6| Step: 9
Training loss: 1.0441762955920064
Validation loss: 2.3150422130538324

Epoch: 6| Step: 10
Training loss: 1.1084068264412716
Validation loss: 2.392370053707953

Epoch: 6| Step: 11
Training loss: 1.12341180594273
Validation loss: 2.4068412065129805

Epoch: 6| Step: 12
Training loss: 1.2968471937760524
Validation loss: 2.375078557285283

Epoch: 6| Step: 13
Training loss: 0.8612149395609411
Validation loss: 2.342691949729721

Epoch: 349| Step: 0
Training loss: 1.2722237542313
Validation loss: 2.291344376290682

Epoch: 6| Step: 1
Training loss: 1.2564967126708437
Validation loss: 2.348737685347714

Epoch: 6| Step: 2
Training loss: 1.3707187063571422
Validation loss: 2.424930312755193

Epoch: 6| Step: 3
Training loss: 1.4937325512493411
Validation loss: 2.36562239763172

Epoch: 6| Step: 4
Training loss: 1.1617948218594216
Validation loss: 2.332900738021794

Epoch: 6| Step: 5
Training loss: 1.204988300060914
Validation loss: 2.3411837424673534

Epoch: 6| Step: 6
Training loss: 1.3435672369580358
Validation loss: 2.322660406004572

Epoch: 6| Step: 7
Training loss: 1.2202057580506578
Validation loss: 2.337744367643873

Epoch: 6| Step: 8
Training loss: 1.326230886323417
Validation loss: 2.356154966044067

Epoch: 6| Step: 9
Training loss: 1.6063828290944906
Validation loss: 2.399964301722295

Epoch: 6| Step: 10
Training loss: 0.8669520565403479
Validation loss: 2.3387453853015567

Epoch: 6| Step: 11
Training loss: 2.4274635071766406
Validation loss: 2.3480573171710337

Epoch: 6| Step: 12
Training loss: 0.6683937639121322
Validation loss: 2.352628279469708

Epoch: 6| Step: 13
Training loss: 1.4610905694585277
Validation loss: 2.330359290375958

Epoch: 350| Step: 0
Training loss: 0.8231087392071251
Validation loss: 2.2820680988470423

Epoch: 6| Step: 1
Training loss: 1.427193222084544
Validation loss: 2.2657689660894103

Epoch: 6| Step: 2
Training loss: 0.8778393182293988
Validation loss: 2.38887266669219

Epoch: 6| Step: 3
Training loss: 1.3984302968100755
Validation loss: 2.332660050167187

Epoch: 6| Step: 4
Training loss: 1.298829088712636
Validation loss: 2.352014712571024

Epoch: 6| Step: 5
Training loss: 1.1126808555270504
Validation loss: 2.3295930939819476

Epoch: 6| Step: 6
Training loss: 1.037865544462267
Validation loss: 2.3259001718764303

Epoch: 6| Step: 7
Training loss: 1.5141477169152044
Validation loss: 2.3520176075466805

Epoch: 6| Step: 8
Training loss: 1.8005003472147498
Validation loss: 2.302596024044369

Epoch: 6| Step: 9
Training loss: 2.1507238810655007
Validation loss: 2.332178720856022

Epoch: 6| Step: 10
Training loss: 0.7895919609772729
Validation loss: 2.326058976810815

Epoch: 6| Step: 11
Training loss: 1.3514454079771379
Validation loss: 2.372930031620967

Epoch: 6| Step: 12
Training loss: 1.0896931205759903
Validation loss: 2.3143189694882103

Epoch: 6| Step: 13
Training loss: 1.838758922272591
Validation loss: 2.3527809687210537

Epoch: 351| Step: 0
Training loss: 0.8313930732530268
Validation loss: 2.3517582020564998

Epoch: 6| Step: 1
Training loss: 0.8371540023862964
Validation loss: 2.337650848455711

Epoch: 6| Step: 2
Training loss: 1.3036398878989424
Validation loss: 2.3592391278877756

Epoch: 6| Step: 3
Training loss: 1.726308122080424
Validation loss: 2.3374535945620107

Epoch: 6| Step: 4
Training loss: 1.5353275426760118
Validation loss: 2.39909498774559

Epoch: 6| Step: 5
Training loss: 1.1997266060610523
Validation loss: 2.31251663561211

Epoch: 6| Step: 6
Training loss: 1.2304111043354562
Validation loss: 2.284151279615986

Epoch: 6| Step: 7
Training loss: 1.1959888813433321
Validation loss: 2.3998785296459006

Epoch: 6| Step: 8
Training loss: 1.4499780357275787
Validation loss: 2.2945312022249804

Epoch: 6| Step: 9
Training loss: 0.9171299450051983
Validation loss: 2.325783777329086

Epoch: 6| Step: 10
Training loss: 1.114566796913949
Validation loss: 2.2917368054959923

Epoch: 6| Step: 11
Training loss: 2.016303487920807
Validation loss: 2.3528225799070435

Epoch: 6| Step: 12
Training loss: 1.3396709542023546
Validation loss: 2.327365211420607

Epoch: 6| Step: 13
Training loss: 1.7306966868301359
Validation loss: 2.3037271068757246

Epoch: 352| Step: 0
Training loss: 0.9680519665530382
Validation loss: 2.327886804471283

Epoch: 6| Step: 1
Training loss: 1.2600426657582868
Validation loss: 2.3996081194232217

Epoch: 6| Step: 2
Training loss: 1.2401388296735223
Validation loss: 2.323413780417874

Epoch: 6| Step: 3
Training loss: 0.9605017193407024
Validation loss: 2.3584236498483984

Epoch: 6| Step: 4
Training loss: 2.1650824501600883
Validation loss: 2.290569255396611

Epoch: 6| Step: 5
Training loss: 1.2466928602380598
Validation loss: 2.320638857469698

Epoch: 6| Step: 6
Training loss: 1.2671481727301832
Validation loss: 2.3136747882676176

Epoch: 6| Step: 7
Training loss: 1.341632149925646
Validation loss: 2.3347772003503264

Epoch: 6| Step: 8
Training loss: 1.1506880422682777
Validation loss: 2.3343122618146825

Epoch: 6| Step: 9
Training loss: 1.4182925524528647
Validation loss: 2.350853124500768

Epoch: 6| Step: 10
Training loss: 1.392410075573191
Validation loss: 2.3011798577071993

Epoch: 6| Step: 11
Training loss: 1.2268646256896791
Validation loss: 2.3501436156036535

Epoch: 6| Step: 12
Training loss: 1.3296776615410892
Validation loss: 2.4086284051189732

Epoch: 6| Step: 13
Training loss: 1.7981013218312163
Validation loss: 2.371003585982154

Epoch: 353| Step: 0
Training loss: 0.9215332302905437
Validation loss: 2.3754566403452064

Epoch: 6| Step: 1
Training loss: 2.2339408826254625
Validation loss: 2.3340544230972675

Epoch: 6| Step: 2
Training loss: 0.9510288013425099
Validation loss: 2.385196324362091

Epoch: 6| Step: 3
Training loss: 1.6251968117885691
Validation loss: 2.3759224904910434

Epoch: 6| Step: 4
Training loss: 1.0192765542585973
Validation loss: 2.3460660225808376

Epoch: 6| Step: 5
Training loss: 1.0633333528353253
Validation loss: 2.2861883720872638

Epoch: 6| Step: 6
Training loss: 1.376106380622552
Validation loss: 2.3614122559018678

Epoch: 6| Step: 7
Training loss: 0.8534015081660066
Validation loss: 2.3126693160296234

Epoch: 6| Step: 8
Training loss: 0.9892290719348928
Validation loss: 2.316640492345484

Epoch: 6| Step: 9
Training loss: 0.9740322139414198
Validation loss: 2.2926146715740248

Epoch: 6| Step: 10
Training loss: 1.360604793204035
Validation loss: 2.3186184272334596

Epoch: 6| Step: 11
Training loss: 1.6825527858530938
Validation loss: 2.3423640856283607

Epoch: 6| Step: 12
Training loss: 1.275327625442018
Validation loss: 2.288553661469385

Epoch: 6| Step: 13
Training loss: 1.355067256863014
Validation loss: 2.2828880853495503

Epoch: 354| Step: 0
Training loss: 1.886712242099445
Validation loss: 2.3690925923788484

Epoch: 6| Step: 1
Training loss: 0.8857438025412508
Validation loss: 2.2877806760907027

Epoch: 6| Step: 2
Training loss: 1.2713902404909843
Validation loss: 2.299432133721668

Epoch: 6| Step: 3
Training loss: 1.3420393057068536
Validation loss: 2.3385535909796014

Epoch: 6| Step: 4
Training loss: 1.5296706793915273
Validation loss: 2.3487048119503777

Epoch: 6| Step: 5
Training loss: 1.2315483080441412
Validation loss: 2.355392272781919

Epoch: 6| Step: 6
Training loss: 1.593410904657343
Validation loss: 2.3140067502253916

Epoch: 6| Step: 7
Training loss: 0.9504842916632436
Validation loss: 2.3532808688076554

Epoch: 6| Step: 8
Training loss: 1.2652560979774958
Validation loss: 2.30445122054248

Epoch: 6| Step: 9
Training loss: 0.9355350246754042
Validation loss: 2.319082051066827

Epoch: 6| Step: 10
Training loss: 0.865638208116371
Validation loss: 2.2963836241420355

Epoch: 6| Step: 11
Training loss: 1.353097473992227
Validation loss: 2.351948396379212

Epoch: 6| Step: 12
Training loss: 1.2056831806990007
Validation loss: 2.339267186152438

Epoch: 6| Step: 13
Training loss: 1.232268745593995
Validation loss: 2.3373961235687215

Epoch: 355| Step: 0
Training loss: 1.0103871187169744
Validation loss: 2.373330447502958

Epoch: 6| Step: 1
Training loss: 0.9882461481306385
Validation loss: 2.421043594137794

Epoch: 6| Step: 2
Training loss: 1.341112698142577
Validation loss: 2.3277722835006847

Epoch: 6| Step: 3
Training loss: 1.3750678825961418
Validation loss: 2.3232746868305907

Epoch: 6| Step: 4
Training loss: 1.5212648989998676
Validation loss: 2.353942665146326

Epoch: 6| Step: 5
Training loss: 1.31138799881231
Validation loss: 2.372476991708521

Epoch: 6| Step: 6
Training loss: 1.1380399386666653
Validation loss: 2.383544497432915

Epoch: 6| Step: 7
Training loss: 1.1296258236838905
Validation loss: 2.36121795222757

Epoch: 6| Step: 8
Training loss: 0.8721271765475227
Validation loss: 2.329491964359608

Epoch: 6| Step: 9
Training loss: 1.2119620142325278
Validation loss: 2.3602961748237816

Epoch: 6| Step: 10
Training loss: 1.397778446320834
Validation loss: 2.344758143025693

Epoch: 6| Step: 11
Training loss: 2.063513997826541
Validation loss: 2.3644171649123167

Epoch: 6| Step: 12
Training loss: 1.754573295864702
Validation loss: 2.368021777367027

Epoch: 6| Step: 13
Training loss: 0.7790309672242093
Validation loss: 2.40279989900004

Epoch: 356| Step: 0
Training loss: 1.5250636103136583
Validation loss: 2.3050608732085553

Epoch: 6| Step: 1
Training loss: 0.976389694183389
Validation loss: 2.3040904627991656

Epoch: 6| Step: 2
Training loss: 1.1320044957297457
Validation loss: 2.308776183639877

Epoch: 6| Step: 3
Training loss: 1.1520280308525197
Validation loss: 2.3366309221292756

Epoch: 6| Step: 4
Training loss: 1.3908682621127315
Validation loss: 2.3064785079541066

Epoch: 6| Step: 5
Training loss: 1.3770158036487945
Validation loss: 2.309080512993102

Epoch: 6| Step: 6
Training loss: 1.418316927111568
Validation loss: 2.3406927156718034

Epoch: 6| Step: 7
Training loss: 0.9686918548854297
Validation loss: 2.335111469728729

Epoch: 6| Step: 8
Training loss: 1.293680968723464
Validation loss: 2.3370004605246093

Epoch: 6| Step: 9
Training loss: 1.211274623089113
Validation loss: 2.348222543680599

Epoch: 6| Step: 10
Training loss: 1.286985631618011
Validation loss: 2.3097083899898743

Epoch: 6| Step: 11
Training loss: 1.3753020214954932
Validation loss: 2.341733802244956

Epoch: 6| Step: 12
Training loss: 2.276924421856259
Validation loss: 2.2935945323889952

Epoch: 6| Step: 13
Training loss: 0.8964119011333631
Validation loss: 2.3158448126912674

Epoch: 357| Step: 0
Training loss: 1.9710251513869381
Validation loss: 2.3131649432674837

Epoch: 6| Step: 1
Training loss: 1.1768860553175604
Validation loss: 2.364081328695328

Epoch: 6| Step: 2
Training loss: 1.1667203834065536
Validation loss: 2.271870187194405

Epoch: 6| Step: 3
Training loss: 1.2660292933360915
Validation loss: 2.2880562100522295

Epoch: 6| Step: 4
Training loss: 0.904257590180029
Validation loss: 2.343957356130029

Epoch: 6| Step: 5
Training loss: 1.0541024174668225
Validation loss: 2.325441620920209

Epoch: 6| Step: 6
Training loss: 1.534827432531145
Validation loss: 2.4241368523846902

Epoch: 6| Step: 7
Training loss: 1.1302008679871474
Validation loss: 2.360908270870941

Epoch: 6| Step: 8
Training loss: 1.283717872343899
Validation loss: 2.3623774032091736

Epoch: 6| Step: 9
Training loss: 1.254732519270849
Validation loss: 2.343179046106721

Epoch: 6| Step: 10
Training loss: 1.586093387552986
Validation loss: 2.3505607414233802

Epoch: 6| Step: 11
Training loss: 1.3124971843870934
Validation loss: 2.3328947747960713

Epoch: 6| Step: 12
Training loss: 1.769403246698239
Validation loss: 2.3685764210075746

Epoch: 6| Step: 13
Training loss: 0.8379726058583884
Validation loss: 2.3035681713430396

Epoch: 358| Step: 0
Training loss: 1.2465519077771927
Validation loss: 2.31119744117844

Epoch: 6| Step: 1
Training loss: 1.283889563680578
Validation loss: 2.2963451918224997

Epoch: 6| Step: 2
Training loss: 1.1088791397218702
Validation loss: 2.2873204256318203

Epoch: 6| Step: 3
Training loss: 1.5708183878112587
Validation loss: 2.3436633372264586

Epoch: 6| Step: 4
Training loss: 1.4636164292033984
Validation loss: 2.3677683240578395

Epoch: 6| Step: 5
Training loss: 1.0488421050264167
Validation loss: 2.328002452962942

Epoch: 6| Step: 6
Training loss: 1.9893443445066286
Validation loss: 2.352868788392557

Epoch: 6| Step: 7
Training loss: 1.2628253064430153
Validation loss: 2.347235329255988

Epoch: 6| Step: 8
Training loss: 1.1888372019844708
Validation loss: 2.373914100136142

Epoch: 6| Step: 9
Training loss: 1.0543583108952603
Validation loss: 2.334648115864079

Epoch: 6| Step: 10
Training loss: 1.1241379720099958
Validation loss: 2.2620551998773806

Epoch: 6| Step: 11
Training loss: 1.2312071991273128
Validation loss: 2.292083167843292

Epoch: 6| Step: 12
Training loss: 1.4157723895348138
Validation loss: 2.311000807504443

Epoch: 6| Step: 13
Training loss: 0.5359042710660281
Validation loss: 2.34024683141316

Epoch: 359| Step: 0
Training loss: 1.2138652724774968
Validation loss: 2.294780341684181

Epoch: 6| Step: 1
Training loss: 1.4005412468983591
Validation loss: 2.2557406870091636

Epoch: 6| Step: 2
Training loss: 1.3610138058210945
Validation loss: 2.3412386110354855

Epoch: 6| Step: 3
Training loss: 1.042744015830371
Validation loss: 2.3075712793760994

Epoch: 6| Step: 4
Training loss: 1.3188676772562853
Validation loss: 2.3434995630929167

Epoch: 6| Step: 5
Training loss: 1.336397593726761
Validation loss: 2.2765894904229262

Epoch: 6| Step: 6
Training loss: 2.2505239300543582
Validation loss: 2.2772845996486604

Epoch: 6| Step: 7
Training loss: 1.0549019489554918
Validation loss: 2.3369935742282344

Epoch: 6| Step: 8
Training loss: 1.2794730727599728
Validation loss: 2.3445070986798138

Epoch: 6| Step: 9
Training loss: 1.165577152691727
Validation loss: 2.336060420916439

Epoch: 6| Step: 10
Training loss: 0.9804989023625573
Validation loss: 2.333392808214065

Epoch: 6| Step: 11
Training loss: 0.9814294310845814
Validation loss: 2.3301901100398834

Epoch: 6| Step: 12
Training loss: 1.1077349185007361
Validation loss: 2.33855935725033

Epoch: 6| Step: 13
Training loss: 1.8104851803766988
Validation loss: 2.320308610306512

Epoch: 360| Step: 0
Training loss: 0.9649689627879137
Validation loss: 2.333916184440983

Epoch: 6| Step: 1
Training loss: 0.9685574617094205
Validation loss: 2.290260197319789

Epoch: 6| Step: 2
Training loss: 1.8297804811276135
Validation loss: 2.3325307567425515

Epoch: 6| Step: 3
Training loss: 2.0906799354805243
Validation loss: 2.3014048501428572

Epoch: 6| Step: 4
Training loss: 0.8969160382920374
Validation loss: 2.320199380785997

Epoch: 6| Step: 5
Training loss: 1.0929454569212544
Validation loss: 2.3642221550543785

Epoch: 6| Step: 6
Training loss: 1.2154579695068923
Validation loss: 2.3566718809142038

Epoch: 6| Step: 7
Training loss: 1.3990677420334965
Validation loss: 2.3068641535605052

Epoch: 6| Step: 8
Training loss: 1.4318481128421099
Validation loss: 2.3159470479901896

Epoch: 6| Step: 9
Training loss: 1.2965168285991586
Validation loss: 2.318654327148001

Epoch: 6| Step: 10
Training loss: 1.0674041438785118
Validation loss: 2.321037333119578

Epoch: 6| Step: 11
Training loss: 1.019778342284976
Validation loss: 2.3564289309812603

Epoch: 6| Step: 12
Training loss: 1.1946634762060047
Validation loss: 2.336176871340867

Epoch: 6| Step: 13
Training loss: 0.7896834092813563
Validation loss: 2.367810809783743

Epoch: 361| Step: 0
Training loss: 1.059253107220772
Validation loss: 2.3225348039302434

Epoch: 6| Step: 1
Training loss: 1.3639260764575973
Validation loss: 2.3324023959170224

Epoch: 6| Step: 2
Training loss: 2.4122220526566873
Validation loss: 2.2910250950558217

Epoch: 6| Step: 3
Training loss: 0.9625221150817701
Validation loss: 2.3431036639732676

Epoch: 6| Step: 4
Training loss: 1.3817529875859498
Validation loss: 2.3252017563358582

Epoch: 6| Step: 5
Training loss: 1.252105275161266
Validation loss: 2.2898007576112933

Epoch: 6| Step: 6
Training loss: 0.8702400711575883
Validation loss: 2.299607904067102

Epoch: 6| Step: 7
Training loss: 1.4941629644980292
Validation loss: 2.3366979133052515

Epoch: 6| Step: 8
Training loss: 1.0685735344902456
Validation loss: 2.3219328357190605

Epoch: 6| Step: 9
Training loss: 0.8275020343490441
Validation loss: 2.3316228335145297

Epoch: 6| Step: 10
Training loss: 1.2936154502894355
Validation loss: 2.3549586829661227

Epoch: 6| Step: 11
Training loss: 1.3443451827469985
Validation loss: 2.315221933388717

Epoch: 6| Step: 12
Training loss: 0.982113435230233
Validation loss: 2.37620147253846

Epoch: 6| Step: 13
Training loss: 1.0909695296993225
Validation loss: 2.377663915084901

Epoch: 362| Step: 0
Training loss: 0.7315179154711198
Validation loss: 2.328167707039554

Epoch: 6| Step: 1
Training loss: 1.2449842913146
Validation loss: 2.361672929431903

Epoch: 6| Step: 2
Training loss: 1.2603752612834684
Validation loss: 2.3308719688652495

Epoch: 6| Step: 3
Training loss: 1.2014755237386512
Validation loss: 2.3314447584590723

Epoch: 6| Step: 4
Training loss: 1.4364074203766954
Validation loss: 2.3227164930276682

Epoch: 6| Step: 5
Training loss: 1.9837586654733423
Validation loss: 2.3593041210289214

Epoch: 6| Step: 6
Training loss: 1.138317334317271
Validation loss: 2.351571350113708

Epoch: 6| Step: 7
Training loss: 0.9331294545235316
Validation loss: 2.446195650846089

Epoch: 6| Step: 8
Training loss: 0.9714971783096872
Validation loss: 2.377313067169562

Epoch: 6| Step: 9
Training loss: 1.3824305464835585
Validation loss: 2.3314536794410547

Epoch: 6| Step: 10
Training loss: 1.2025051749706939
Validation loss: 2.4090968677187306

Epoch: 6| Step: 11
Training loss: 1.0090712736946845
Validation loss: 2.3451864548156354

Epoch: 6| Step: 12
Training loss: 1.926409945670463
Validation loss: 2.3460184627673994

Epoch: 6| Step: 13
Training loss: 0.8240691496689624
Validation loss: 2.340285505668265

Epoch: 363| Step: 0
Training loss: 1.1980899630156159
Validation loss: 2.3142647809159085

Epoch: 6| Step: 1
Training loss: 0.9720958029585869
Validation loss: 2.31055506337937

Epoch: 6| Step: 2
Training loss: 1.2816035085394335
Validation loss: 2.2663858459345763

Epoch: 6| Step: 3
Training loss: 1.924659262882197
Validation loss: 2.307813303546548

Epoch: 6| Step: 4
Training loss: 1.3351513071788992
Validation loss: 2.403172991364219

Epoch: 6| Step: 5
Training loss: 1.1517042034029072
Validation loss: 2.324420329895437

Epoch: 6| Step: 6
Training loss: 1.1412156548403378
Validation loss: 2.345037416017554

Epoch: 6| Step: 7
Training loss: 1.6143747830806148
Validation loss: 2.38700241992562

Epoch: 6| Step: 8
Training loss: 1.7107754286554562
Validation loss: 2.3348795207382307

Epoch: 6| Step: 9
Training loss: 0.8910637828718402
Validation loss: 2.3036476232307095

Epoch: 6| Step: 10
Training loss: 0.9725057952825862
Validation loss: 2.301752096041983

Epoch: 6| Step: 11
Training loss: 1.6809626507442161
Validation loss: 2.352657188825588

Epoch: 6| Step: 12
Training loss: 0.9773092847764988
Validation loss: 2.301694532495434

Epoch: 6| Step: 13
Training loss: 0.6678572890774747
Validation loss: 2.3870879689378204

Epoch: 364| Step: 0
Training loss: 1.0895841555960029
Validation loss: 2.3271411315236774

Epoch: 6| Step: 1
Training loss: 2.2195439597131483
Validation loss: 2.3068796029369754

Epoch: 6| Step: 2
Training loss: 1.0962437674542054
Validation loss: 2.278625473189329

Epoch: 6| Step: 3
Training loss: 1.057723697783434
Validation loss: 2.31396446097067

Epoch: 6| Step: 4
Training loss: 1.067920155176564
Validation loss: 2.327477727924682

Epoch: 6| Step: 5
Training loss: 1.6554128582508374
Validation loss: 2.3318569479404876

Epoch: 6| Step: 6
Training loss: 1.5642906609424034
Validation loss: 2.364794031444685

Epoch: 6| Step: 7
Training loss: 0.7858275016117906
Validation loss: 2.351656536478362

Epoch: 6| Step: 8
Training loss: 1.3501553569694067
Validation loss: 2.4416430370723567

Epoch: 6| Step: 9
Training loss: 1.285093311751385
Validation loss: 2.3087675375765095

Epoch: 6| Step: 10
Training loss: 1.0197648405625717
Validation loss: 2.340029419583544

Epoch: 6| Step: 11
Training loss: 1.08491841532475
Validation loss: 2.310968055693099

Epoch: 6| Step: 12
Training loss: 1.0052617047360604
Validation loss: 2.3280397399411616

Epoch: 6| Step: 13
Training loss: 1.2630268791552168
Validation loss: 2.378766101126568

Epoch: 365| Step: 0
Training loss: 1.3705910307175064
Validation loss: 2.306304925828716

Epoch: 6| Step: 1
Training loss: 1.3220874209881306
Validation loss: 2.3243889296616063

Epoch: 6| Step: 2
Training loss: 1.0064312836735123
Validation loss: 2.3325879950885655

Epoch: 6| Step: 3
Training loss: 1.6866686857284303
Validation loss: 2.3238923823025357

Epoch: 6| Step: 4
Training loss: 0.8532698777255976
Validation loss: 2.2784811115877117

Epoch: 6| Step: 5
Training loss: 1.4720831041563525
Validation loss: 2.3713411310687724

Epoch: 6| Step: 6
Training loss: 1.1306890118868063
Validation loss: 2.336841414535853

Epoch: 6| Step: 7
Training loss: 1.1336704556825155
Validation loss: 2.376075164483554

Epoch: 6| Step: 8
Training loss: 1.1140584809175949
Validation loss: 2.3299180150570797

Epoch: 6| Step: 9
Training loss: 0.9375564240324292
Validation loss: 2.285428979706459

Epoch: 6| Step: 10
Training loss: 1.9822085712100133
Validation loss: 2.298720044493004

Epoch: 6| Step: 11
Training loss: 0.964562595191189
Validation loss: 2.347348126346532

Epoch: 6| Step: 12
Training loss: 0.9789334621437499
Validation loss: 2.313972590724715

Epoch: 6| Step: 13
Training loss: 1.7350449513925168
Validation loss: 2.27197862591822

Epoch: 366| Step: 0
Training loss: 1.047771127249776
Validation loss: 2.252716447653135

Epoch: 6| Step: 1
Training loss: 0.8447365468047051
Validation loss: 2.3017364501936375

Epoch: 6| Step: 2
Training loss: 1.2571296496905089
Validation loss: 2.324790872454402

Epoch: 6| Step: 3
Training loss: 1.1173765649405836
Validation loss: 2.34107651794339

Epoch: 6| Step: 4
Training loss: 1.1008574481741773
Validation loss: 2.3649483487940146

Epoch: 6| Step: 5
Training loss: 2.1250980578966865
Validation loss: 2.291397849357462

Epoch: 6| Step: 6
Training loss: 1.2004093882481202
Validation loss: 2.342912811282369

Epoch: 6| Step: 7
Training loss: 0.9912623800825086
Validation loss: 2.2765337216277453

Epoch: 6| Step: 8
Training loss: 0.8660534153161958
Validation loss: 2.316210794564589

Epoch: 6| Step: 9
Training loss: 1.0529142944365573
Validation loss: 2.320155830959574

Epoch: 6| Step: 10
Training loss: 1.409845418302303
Validation loss: 2.303365202858488

Epoch: 6| Step: 11
Training loss: 1.3964235092450432
Validation loss: 2.35182080539811

Epoch: 6| Step: 12
Training loss: 1.4922073922154542
Validation loss: 2.337802833741891

Epoch: 6| Step: 13
Training loss: 1.7208303172875576
Validation loss: 2.333209405485161

Epoch: 367| Step: 0
Training loss: 2.1986763049728517
Validation loss: 2.3120468103547025

Epoch: 6| Step: 1
Training loss: 1.493153683693082
Validation loss: 2.3258270707672213

Epoch: 6| Step: 2
Training loss: 1.4495083501548307
Validation loss: 2.325609863555464

Epoch: 6| Step: 3
Training loss: 1.141234248241675
Validation loss: 2.332985788016618

Epoch: 6| Step: 4
Training loss: 0.7408982975828363
Validation loss: 2.4185793785811094

Epoch: 6| Step: 5
Training loss: 1.0099218015330653
Validation loss: 2.3343438371675673

Epoch: 6| Step: 6
Training loss: 1.176816111026722
Validation loss: 2.3127543545927294

Epoch: 6| Step: 7
Training loss: 1.4043543860871113
Validation loss: 2.3266375565564066

Epoch: 6| Step: 8
Training loss: 0.841899325692654
Validation loss: 2.367897138776972

Epoch: 6| Step: 9
Training loss: 1.056368357330443
Validation loss: 2.3442704900522013

Epoch: 6| Step: 10
Training loss: 1.5092605199897422
Validation loss: 2.2792742913010593

Epoch: 6| Step: 11
Training loss: 1.3448615245369124
Validation loss: 2.33071225883679

Epoch: 6| Step: 12
Training loss: 1.1250457224561508
Validation loss: 2.351948700491195

Epoch: 6| Step: 13
Training loss: 1.25233565510533
Validation loss: 2.3217687532789557

Epoch: 368| Step: 0
Training loss: 1.099650461842021
Validation loss: 2.2946347195088848

Epoch: 6| Step: 1
Training loss: 1.4781247709568484
Validation loss: 2.365685104400058

Epoch: 6| Step: 2
Training loss: 1.0850098304478992
Validation loss: 2.2895387247044763

Epoch: 6| Step: 3
Training loss: 1.2500242230929335
Validation loss: 2.37705013451878

Epoch: 6| Step: 4
Training loss: 1.157568205931057
Validation loss: 2.3430797009436524

Epoch: 6| Step: 5
Training loss: 0.7735042350569264
Validation loss: 2.334196265868057

Epoch: 6| Step: 6
Training loss: 1.561966614282162
Validation loss: 2.3466765862929195

Epoch: 6| Step: 7
Training loss: 1.193408122214271
Validation loss: 2.332396531439336

Epoch: 6| Step: 8
Training loss: 1.1725992634934415
Validation loss: 2.339086595218097

Epoch: 6| Step: 9
Training loss: 1.4157811463998744
Validation loss: 2.346622006289311

Epoch: 6| Step: 10
Training loss: 2.1314729948648505
Validation loss: 2.3710291849085205

Epoch: 6| Step: 11
Training loss: 1.3289904747701258
Validation loss: 2.361987640560665

Epoch: 6| Step: 12
Training loss: 0.8551979855752777
Validation loss: 2.3037483149598743

Epoch: 6| Step: 13
Training loss: 0.9061692629399192
Validation loss: 2.3451139650040265

Epoch: 369| Step: 0
Training loss: 0.9234329249338074
Validation loss: 2.3215701626510046

Epoch: 6| Step: 1
Training loss: 1.1501088339680352
Validation loss: 2.369693458106092

Epoch: 6| Step: 2
Training loss: 1.0306770004377037
Validation loss: 2.31333832482374

Epoch: 6| Step: 3
Training loss: 0.7071944833394683
Validation loss: 2.318715291268885

Epoch: 6| Step: 4
Training loss: 0.953672158200683
Validation loss: 2.3325228136694047

Epoch: 6| Step: 5
Training loss: 1.1852854105727453
Validation loss: 2.314202712516374

Epoch: 6| Step: 6
Training loss: 1.3599188582673478
Validation loss: 2.330607811816266

Epoch: 6| Step: 7
Training loss: 1.6686414304697772
Validation loss: 2.2453117452412346

Epoch: 6| Step: 8
Training loss: 0.9601287229485898
Validation loss: 2.3330043379133816

Epoch: 6| Step: 9
Training loss: 1.0630846098191231
Validation loss: 2.38769396824181

Epoch: 6| Step: 10
Training loss: 1.2242357575404292
Validation loss: 2.294561957467168

Epoch: 6| Step: 11
Training loss: 2.362511173605356
Validation loss: 2.328337443920941

Epoch: 6| Step: 12
Training loss: 1.165806941746443
Validation loss: 2.3502516056118674

Epoch: 6| Step: 13
Training loss: 1.4220651352741907
Validation loss: 2.3698401647070066

Epoch: 370| Step: 0
Training loss: 1.1688831029159719
Validation loss: 2.3482298184565606

Epoch: 6| Step: 1
Training loss: 1.063907364390755
Validation loss: 2.2774232443735305

Epoch: 6| Step: 2
Training loss: 0.7794436361991889
Validation loss: 2.3019833966009022

Epoch: 6| Step: 3
Training loss: 1.024675275957138
Validation loss: 2.349315671700442

Epoch: 6| Step: 4
Training loss: 1.1019993450176695
Validation loss: 2.3126645895718227

Epoch: 6| Step: 5
Training loss: 1.3917827287501598
Validation loss: 2.350000982572341

Epoch: 6| Step: 6
Training loss: 1.4699071019200998
Validation loss: 2.3859588005022565

Epoch: 6| Step: 7
Training loss: 1.2461230235712153
Validation loss: 2.270482329597068

Epoch: 6| Step: 8
Training loss: 2.052256026642183
Validation loss: 2.3470178150680803

Epoch: 6| Step: 9
Training loss: 1.6145875828184586
Validation loss: 2.3148549130725624

Epoch: 6| Step: 10
Training loss: 1.255909303233318
Validation loss: 2.319934928466447

Epoch: 6| Step: 11
Training loss: 1.0797096437869185
Validation loss: 2.408279426119848

Epoch: 6| Step: 12
Training loss: 0.9989086394667035
Validation loss: 2.3459779722948335

Epoch: 6| Step: 13
Training loss: 1.4572200703933256
Validation loss: 2.3067637978841904

Epoch: 371| Step: 0
Training loss: 1.0416968086967937
Validation loss: 2.3564357985586

Epoch: 6| Step: 1
Training loss: 1.3186085105311223
Validation loss: 2.395749671049551

Epoch: 6| Step: 2
Training loss: 1.1088415125741051
Validation loss: 2.313992943789907

Epoch: 6| Step: 3
Training loss: 1.658136049673085
Validation loss: 2.336206853925938

Epoch: 6| Step: 4
Training loss: 1.4588096748966335
Validation loss: 2.3046659668475615

Epoch: 6| Step: 5
Training loss: 1.194881087096802
Validation loss: 2.353668392838014

Epoch: 6| Step: 6
Training loss: 0.9314081953719848
Validation loss: 2.2658957812141787

Epoch: 6| Step: 7
Training loss: 1.0322838427224368
Validation loss: 2.2711469340214157

Epoch: 6| Step: 8
Training loss: 0.9997453961506042
Validation loss: 2.3274398514600483

Epoch: 6| Step: 9
Training loss: 1.083051950640529
Validation loss: 2.3361503286544427

Epoch: 6| Step: 10
Training loss: 2.0495050437550626
Validation loss: 2.255965781573364

Epoch: 6| Step: 11
Training loss: 1.4947215029457521
Validation loss: 2.273992485582216

Epoch: 6| Step: 12
Training loss: 1.1514924088864344
Validation loss: 2.353847554632643

Epoch: 6| Step: 13
Training loss: 0.9422890413899819
Validation loss: 2.3288277188135806

Epoch: 372| Step: 0
Training loss: 1.1917598512313197
Validation loss: 2.2983863182908504

Epoch: 6| Step: 1
Training loss: 1.4245096467248162
Validation loss: 2.2661396871979074

Epoch: 6| Step: 2
Training loss: 1.1614864442898871
Validation loss: 2.3136897752701975

Epoch: 6| Step: 3
Training loss: 1.025467933283627
Validation loss: 2.3526926625062727

Epoch: 6| Step: 4
Training loss: 1.2176373611447766
Validation loss: 2.3609284663469867

Epoch: 6| Step: 5
Training loss: 1.8768976780921516
Validation loss: 2.348204237368937

Epoch: 6| Step: 6
Training loss: 0.9883494297076311
Validation loss: 2.3009065682749212

Epoch: 6| Step: 7
Training loss: 1.287597841415421
Validation loss: 2.314181120010975

Epoch: 6| Step: 8
Training loss: 0.8032964144991057
Validation loss: 2.301054422850321

Epoch: 6| Step: 9
Training loss: 0.9213737806292197
Validation loss: 2.2563443914044097

Epoch: 6| Step: 10
Training loss: 1.5184996567349867
Validation loss: 2.3177713523630854

Epoch: 6| Step: 11
Training loss: 1.260022845363896
Validation loss: 2.391421403157585

Epoch: 6| Step: 12
Training loss: 1.2672299698981124
Validation loss: 2.308278625045514

Epoch: 6| Step: 13
Training loss: 1.3417875464502418
Validation loss: 2.281252421761156

Epoch: 373| Step: 0
Training loss: 1.0678494926120277
Validation loss: 2.3372390023594494

Epoch: 6| Step: 1
Training loss: 1.3021582569182926
Validation loss: 2.3140553025350066

Epoch: 6| Step: 2
Training loss: 0.8788389052975173
Validation loss: 2.235221402444739

Epoch: 6| Step: 3
Training loss: 1.3591173300490285
Validation loss: 2.284415011196316

Epoch: 6| Step: 4
Training loss: 1.866136582359007
Validation loss: 2.250727675979699

Epoch: 6| Step: 5
Training loss: 1.1860169636637348
Validation loss: 2.2713036217177467

Epoch: 6| Step: 6
Training loss: 0.612055628984655
Validation loss: 2.34544522139878

Epoch: 6| Step: 7
Training loss: 1.2733465524972583
Validation loss: 2.3068433108519075

Epoch: 6| Step: 8
Training loss: 0.9859635387434189
Validation loss: 2.2995251285734626

Epoch: 6| Step: 9
Training loss: 1.3006719136610487
Validation loss: 2.3515611645217085

Epoch: 6| Step: 10
Training loss: 1.3203295644526407
Validation loss: 2.3074253384015115

Epoch: 6| Step: 11
Training loss: 1.665662828770928
Validation loss: 2.273512635171535

Epoch: 6| Step: 12
Training loss: 0.9628541641605676
Validation loss: 2.260850484709856

Epoch: 6| Step: 13
Training loss: 1.0225846325981072
Validation loss: 2.2956687880191153

Epoch: 374| Step: 0
Training loss: 1.1434446000063543
Validation loss: 2.3147217133940137

Epoch: 6| Step: 1
Training loss: 0.8370433160062797
Validation loss: 2.34842736583404

Epoch: 6| Step: 2
Training loss: 0.9596596572002093
Validation loss: 2.3586648960234293

Epoch: 6| Step: 3
Training loss: 1.3758115107659654
Validation loss: 2.3081076873963218

Epoch: 6| Step: 4
Training loss: 0.954626401703662
Validation loss: 2.3164632874918536

Epoch: 6| Step: 5
Training loss: 0.9544836273028069
Validation loss: 2.3658301567403615

Epoch: 6| Step: 6
Training loss: 1.040302254055419
Validation loss: 2.280906079313468

Epoch: 6| Step: 7
Training loss: 1.1717838506218308
Validation loss: 2.3359849819145757

Epoch: 6| Step: 8
Training loss: 1.4230087287726263
Validation loss: 2.3544265824288075

Epoch: 6| Step: 9
Training loss: 1.2851063912874279
Validation loss: 2.3337383673165357

Epoch: 6| Step: 10
Training loss: 0.9770033794840499
Validation loss: 2.387585749216697

Epoch: 6| Step: 11
Training loss: 2.1721447015617317
Validation loss: 2.3608550457856743

Epoch: 6| Step: 12
Training loss: 1.479107313801046
Validation loss: 2.2843346715329247

Epoch: 6| Step: 13
Training loss: 1.4925646879404482
Validation loss: 2.296637945810743

Epoch: 375| Step: 0
Training loss: 1.4051070336811209
Validation loss: 2.343949798490252

Epoch: 6| Step: 1
Training loss: 0.9977023132730984
Validation loss: 2.2866961875696603

Epoch: 6| Step: 2
Training loss: 1.4160552762498
Validation loss: 2.2873474817094177

Epoch: 6| Step: 3
Training loss: 2.279008051102709
Validation loss: 2.2529142789514114

Epoch: 6| Step: 4
Training loss: 1.2235133667633884
Validation loss: 2.3488534199489224

Epoch: 6| Step: 5
Training loss: 0.6979779150168743
Validation loss: 2.364741434248358

Epoch: 6| Step: 6
Training loss: 0.9371998624377408
Validation loss: 2.3306772486246388

Epoch: 6| Step: 7
Training loss: 0.9182831895284274
Validation loss: 2.3009462937193366

Epoch: 6| Step: 8
Training loss: 1.201825765631851
Validation loss: 2.314887271562915

Epoch: 6| Step: 9
Training loss: 1.3017663290055714
Validation loss: 2.286984726563681

Epoch: 6| Step: 10
Training loss: 1.0015195983172764
Validation loss: 2.336154902522647

Epoch: 6| Step: 11
Training loss: 0.9802323014467027
Validation loss: 2.3302506733470483

Epoch: 6| Step: 12
Training loss: 1.2259132464924751
Validation loss: 2.2614451220248784

Epoch: 6| Step: 13
Training loss: 2.051872384577748
Validation loss: 2.351768209927915

Epoch: 376| Step: 0
Training loss: 1.2640696257778237
Validation loss: 2.3285783897589125

Epoch: 6| Step: 1
Training loss: 0.8716922978765366
Validation loss: 2.3538937996307565

Epoch: 6| Step: 2
Training loss: 0.9326368719290439
Validation loss: 2.305888714123302

Epoch: 6| Step: 3
Training loss: 1.7977469940690898
Validation loss: 2.2934764125314655

Epoch: 6| Step: 4
Training loss: 1.4208527128328015
Validation loss: 2.324092097634847

Epoch: 6| Step: 5
Training loss: 1.548872149732915
Validation loss: 2.3444124309752503

Epoch: 6| Step: 6
Training loss: 1.150179521397534
Validation loss: 2.3019318291113824

Epoch: 6| Step: 7
Training loss: 1.0330194263090293
Validation loss: 2.266055030732625

Epoch: 6| Step: 8
Training loss: 1.4163388639686092
Validation loss: 2.3008817596490903

Epoch: 6| Step: 9
Training loss: 1.3180227344358233
Validation loss: 2.2754897139213868

Epoch: 6| Step: 10
Training loss: 0.6179690904773107
Validation loss: 2.3345791567935312

Epoch: 6| Step: 11
Training loss: 0.8302053555986011
Validation loss: 2.3436616308035334

Epoch: 6| Step: 12
Training loss: 1.388882391702502
Validation loss: 2.3178295369733872

Epoch: 6| Step: 13
Training loss: 0.8885075008417045
Validation loss: 2.282598843191591

Epoch: 377| Step: 0
Training loss: 1.4835225116807544
Validation loss: 2.2918700876499902

Epoch: 6| Step: 1
Training loss: 1.926485130321977
Validation loss: 2.35930946659489

Epoch: 6| Step: 2
Training loss: 1.2329131052718443
Validation loss: 2.3397633117603056

Epoch: 6| Step: 3
Training loss: 1.154761206477333
Validation loss: 2.341840100105204

Epoch: 6| Step: 4
Training loss: 1.118385366336988
Validation loss: 2.302651058364129

Epoch: 6| Step: 5
Training loss: 1.1492411597664747
Validation loss: 2.3701058636641705

Epoch: 6| Step: 6
Training loss: 1.02125479632854
Validation loss: 2.3723428117672225

Epoch: 6| Step: 7
Training loss: 0.9213110928613671
Validation loss: 2.317146682482093

Epoch: 6| Step: 8
Training loss: 1.2300078967081292
Validation loss: 2.3526792302000348

Epoch: 6| Step: 9
Training loss: 1.2891362024680688
Validation loss: 2.3515668280346396

Epoch: 6| Step: 10
Training loss: 1.601893767545723
Validation loss: 2.26140776466049

Epoch: 6| Step: 11
Training loss: 1.2576371064721423
Validation loss: 2.2730821476187777

Epoch: 6| Step: 12
Training loss: 1.028614722960456
Validation loss: 2.366706282916549

Epoch: 6| Step: 13
Training loss: 1.1560329542841723
Validation loss: 2.301362294785841

Epoch: 378| Step: 0
Training loss: 0.8047566800795695
Validation loss: 2.2923588047800334

Epoch: 6| Step: 1
Training loss: 1.2008299302091079
Validation loss: 2.3845385962859553

Epoch: 6| Step: 2
Training loss: 1.4155263331640926
Validation loss: 2.2872671772379958

Epoch: 6| Step: 3
Training loss: 0.9113641672083127
Validation loss: 2.3017681661304383

Epoch: 6| Step: 4
Training loss: 0.9416552962120244
Validation loss: 2.3621510040912175

Epoch: 6| Step: 5
Training loss: 1.2167613114598737
Validation loss: 2.320434874238962

Epoch: 6| Step: 6
Training loss: 1.250971607255018
Validation loss: 2.2572443135359883

Epoch: 6| Step: 7
Training loss: 1.020035250092054
Validation loss: 2.31710561667759

Epoch: 6| Step: 8
Training loss: 1.5130781030458236
Validation loss: 2.2597383671625266

Epoch: 6| Step: 9
Training loss: 1.4082575561331556
Validation loss: 2.327138037052425

Epoch: 6| Step: 10
Training loss: 0.9483012722162524
Validation loss: 2.3351085417169615

Epoch: 6| Step: 11
Training loss: 1.0596301646402058
Validation loss: 2.272137946680331

Epoch: 6| Step: 12
Training loss: 1.8335946575954094
Validation loss: 2.3156077026998303

Epoch: 6| Step: 13
Training loss: 0.7626345875263537
Validation loss: 2.3436506713820693

Epoch: 379| Step: 0
Training loss: 1.4255193600445475
Validation loss: 2.3239703848059565

Epoch: 6| Step: 1
Training loss: 0.7795551990493478
Validation loss: 2.3458116396349316

Epoch: 6| Step: 2
Training loss: 1.051733443492351
Validation loss: 2.350767611846199

Epoch: 6| Step: 3
Training loss: 0.8796820713234818
Validation loss: 2.3114966632929956

Epoch: 6| Step: 4
Training loss: 1.4262838235600659
Validation loss: 2.327425399928878

Epoch: 6| Step: 5
Training loss: 1.9231390788964184
Validation loss: 2.26059424111739

Epoch: 6| Step: 6
Training loss: 1.101544643825523
Validation loss: 2.35198783141832

Epoch: 6| Step: 7
Training loss: 1.4132832440161358
Validation loss: 2.329573702569873

Epoch: 6| Step: 8
Training loss: 1.2351722557000788
Validation loss: 2.326838339661245

Epoch: 6| Step: 9
Training loss: 0.9003683819785108
Validation loss: 2.3228478381268123

Epoch: 6| Step: 10
Training loss: 1.1379382745867235
Validation loss: 2.335767440649987

Epoch: 6| Step: 11
Training loss: 1.358243712684688
Validation loss: 2.313652706894926

Epoch: 6| Step: 12
Training loss: 0.8480445570103591
Validation loss: 2.3418594972281306

Epoch: 6| Step: 13
Training loss: 1.2114340963697146
Validation loss: 2.331314624028234

Epoch: 380| Step: 0
Training loss: 1.3237494703369235
Validation loss: 2.30458463005075

Epoch: 6| Step: 1
Training loss: 1.2142824796024483
Validation loss: 2.2968009538890133

Epoch: 6| Step: 2
Training loss: 1.2640721720359651
Validation loss: 2.338104790081988

Epoch: 6| Step: 3
Training loss: 1.362555411725662
Validation loss: 2.385155561720918

Epoch: 6| Step: 4
Training loss: 1.206738779133182
Validation loss: 2.4495598253840933

Epoch: 6| Step: 5
Training loss: 0.9068695449927939
Validation loss: 2.2945091514223366

Epoch: 6| Step: 6
Training loss: 0.9696256003014665
Validation loss: 2.3619649018600404

Epoch: 6| Step: 7
Training loss: 1.126129325303697
Validation loss: 2.396373310917476

Epoch: 6| Step: 8
Training loss: 1.1421195911514448
Validation loss: 2.290175177614189

Epoch: 6| Step: 9
Training loss: 0.9240719753652946
Validation loss: 2.3462477376909705

Epoch: 6| Step: 10
Training loss: 2.1022251601777753
Validation loss: 2.369217002523539

Epoch: 6| Step: 11
Training loss: 1.1772425496045262
Validation loss: 2.2870239534417545

Epoch: 6| Step: 12
Training loss: 1.1352901329905383
Validation loss: 2.3740770460435217

Epoch: 6| Step: 13
Training loss: 1.1987608492045068
Validation loss: 2.3517541414478864

Epoch: 381| Step: 0
Training loss: 1.8739345702409973
Validation loss: 2.343028666746071

Epoch: 6| Step: 1
Training loss: 1.2212451921444512
Validation loss: 2.3042431007496496

Epoch: 6| Step: 2
Training loss: 0.9134061690395104
Validation loss: 2.4039865005563326

Epoch: 6| Step: 3
Training loss: 0.8974950076206099
Validation loss: 2.2688807386398078

Epoch: 6| Step: 4
Training loss: 1.4994103544327766
Validation loss: 2.3201241923499345

Epoch: 6| Step: 5
Training loss: 1.0236413184898692
Validation loss: 2.3365982585716334

Epoch: 6| Step: 6
Training loss: 1.3697099359107807
Validation loss: 2.2990031258223365

Epoch: 6| Step: 7
Training loss: 0.5913993079157248
Validation loss: 2.304799898944401

Epoch: 6| Step: 8
Training loss: 0.8143743024048705
Validation loss: 2.3058247369754183

Epoch: 6| Step: 9
Training loss: 1.1990688366954907
Validation loss: 2.240664049994972

Epoch: 6| Step: 10
Training loss: 1.0456795770660658
Validation loss: 2.3373525758038047

Epoch: 6| Step: 11
Training loss: 1.4471143882898165
Validation loss: 2.3360532009756985

Epoch: 6| Step: 12
Training loss: 1.2301600477716486
Validation loss: 2.2640578691961757

Epoch: 6| Step: 13
Training loss: 1.1764238192223824
Validation loss: 2.278171406709071

Epoch: 382| Step: 0
Training loss: 1.2966000368868216
Validation loss: 2.3266364075863293

Epoch: 6| Step: 1
Training loss: 1.5155563338937437
Validation loss: 2.3231983879409817

Epoch: 6| Step: 2
Training loss: 1.0332848673396215
Validation loss: 2.3665517709212986

Epoch: 6| Step: 3
Training loss: 1.9521020270246057
Validation loss: 2.355140446160372

Epoch: 6| Step: 4
Training loss: 1.0438607505471684
Validation loss: 2.3277143386129837

Epoch: 6| Step: 5
Training loss: 1.2574597450471818
Validation loss: 2.3103301081709873

Epoch: 6| Step: 6
Training loss: 0.963540065179817
Validation loss: 2.404488374552924

Epoch: 6| Step: 7
Training loss: 1.06834330712323
Validation loss: 2.2833990385648195

Epoch: 6| Step: 8
Training loss: 1.3305718714050607
Validation loss: 2.337786635768962

Epoch: 6| Step: 9
Training loss: 1.0884008118729822
Validation loss: 2.317475837604304

Epoch: 6| Step: 10
Training loss: 0.9098190534339534
Validation loss: 2.329949571839351

Epoch: 6| Step: 11
Training loss: 1.3025802681291596
Validation loss: 2.298836848035353

Epoch: 6| Step: 12
Training loss: 0.9725474101378402
Validation loss: 2.338230772245746

Epoch: 6| Step: 13
Training loss: 1.2833737705515005
Validation loss: 2.381390274881874

Epoch: 383| Step: 0
Training loss: 1.6665753657446851
Validation loss: 2.3305827121548295

Epoch: 6| Step: 1
Training loss: 2.0182811180729567
Validation loss: 2.3352805240701997

Epoch: 6| Step: 2
Training loss: 0.7935638074188867
Validation loss: 2.30185162943719

Epoch: 6| Step: 3
Training loss: 1.0520392619555525
Validation loss: 2.330789863720487

Epoch: 6| Step: 4
Training loss: 1.2873351574895873
Validation loss: 2.2971843047744085

Epoch: 6| Step: 5
Training loss: 1.1445982200636715
Validation loss: 2.3149961819667424

Epoch: 6| Step: 6
Training loss: 1.2950874786582254
Validation loss: 2.4091814198761594

Epoch: 6| Step: 7
Training loss: 0.8834421731064881
Validation loss: 2.2768946798539114

Epoch: 6| Step: 8
Training loss: 1.0236814368348086
Validation loss: 2.394959497374126

Epoch: 6| Step: 9
Training loss: 1.2857647878325673
Validation loss: 2.3086453410820016

Epoch: 6| Step: 10
Training loss: 1.0376231040077915
Validation loss: 2.3247953484730606

Epoch: 6| Step: 11
Training loss: 1.2090427464705162
Validation loss: 2.3127861389135824

Epoch: 6| Step: 12
Training loss: 0.9673070312984278
Validation loss: 2.2910291995178147

Epoch: 6| Step: 13
Training loss: 1.5240809720022621
Validation loss: 2.354496968545637

Epoch: 384| Step: 0
Training loss: 1.0303945171928548
Validation loss: 2.4010893349167337

Epoch: 6| Step: 1
Training loss: 0.8966286071572895
Validation loss: 2.3405034441168096

Epoch: 6| Step: 2
Training loss: 0.7970569627237925
Validation loss: 2.2741059512813795

Epoch: 6| Step: 3
Training loss: 1.5139379648931457
Validation loss: 2.3983455639136184

Epoch: 6| Step: 4
Training loss: 1.774491723585995
Validation loss: 2.3410523792100193

Epoch: 6| Step: 5
Training loss: 1.5128845135924605
Validation loss: 2.3587665736346435

Epoch: 6| Step: 6
Training loss: 0.8937677181595047
Validation loss: 2.375240169141017

Epoch: 6| Step: 7
Training loss: 1.1714520008870979
Validation loss: 2.3377059507339255

Epoch: 6| Step: 8
Training loss: 2.1452195360638866
Validation loss: 2.338899607826209

Epoch: 6| Step: 9
Training loss: 1.1377694953014326
Validation loss: 2.328285769472247

Epoch: 6| Step: 10
Training loss: 1.035920749718759
Validation loss: 2.2621215867354674

Epoch: 6| Step: 11
Training loss: 0.5501138959343429
Validation loss: 2.310077174049583

Epoch: 6| Step: 12
Training loss: 0.9713541530305727
Validation loss: 2.303727789036156

Epoch: 6| Step: 13
Training loss: 0.9896053445610041
Validation loss: 2.378845455461687

Epoch: 385| Step: 0
Training loss: 1.0912226222778052
Validation loss: 2.3090969634060587

Epoch: 6| Step: 1
Training loss: 0.9353271098832777
Validation loss: 2.340567027581229

Epoch: 6| Step: 2
Training loss: 0.952033434060373
Validation loss: 2.364223167835616

Epoch: 6| Step: 3
Training loss: 0.8004948173536265
Validation loss: 2.2892916901085814

Epoch: 6| Step: 4
Training loss: 1.6902126126599792
Validation loss: 2.363577943160117

Epoch: 6| Step: 5
Training loss: 1.1142430484204822
Validation loss: 2.3822785380212124

Epoch: 6| Step: 6
Training loss: 1.9108331335206004
Validation loss: 2.3573473572211676

Epoch: 6| Step: 7
Training loss: 1.3741725686160353
Validation loss: 2.3495121664873704

Epoch: 6| Step: 8
Training loss: 0.8282934773205922
Validation loss: 2.3318961037979533

Epoch: 6| Step: 9
Training loss: 1.33369181204859
Validation loss: 2.3597830707652547

Epoch: 6| Step: 10
Training loss: 1.0790072714920314
Validation loss: 2.3219042841298023

Epoch: 6| Step: 11
Training loss: 1.5044763846757845
Validation loss: 2.3421892073217885

Epoch: 6| Step: 12
Training loss: 1.346038333684214
Validation loss: 2.334362606898595

Epoch: 6| Step: 13
Training loss: 0.7138706525517606
Validation loss: 2.329039345737504

Epoch: 386| Step: 0
Training loss: 1.159591537366149
Validation loss: 2.3234442559580337

Epoch: 6| Step: 1
Training loss: 1.0177884461111222
Validation loss: 2.319855604518183

Epoch: 6| Step: 2
Training loss: 1.2923103799940463
Validation loss: 2.2363642990067567

Epoch: 6| Step: 3
Training loss: 1.0178218264177363
Validation loss: 2.2871417791180226

Epoch: 6| Step: 4
Training loss: 1.0912758227042658
Validation loss: 2.351677603386988

Epoch: 6| Step: 5
Training loss: 1.066063570850311
Validation loss: 2.300829042380915

Epoch: 6| Step: 6
Training loss: 0.9210242208781392
Validation loss: 2.2707755435282215

Epoch: 6| Step: 7
Training loss: 0.6612323590252874
Validation loss: 2.3871123799584675

Epoch: 6| Step: 8
Training loss: 2.091610626847947
Validation loss: 2.245157632307925

Epoch: 6| Step: 9
Training loss: 1.2670064850952087
Validation loss: 2.3260657141776084

Epoch: 6| Step: 10
Training loss: 0.7620704816927256
Validation loss: 2.3056103654584796

Epoch: 6| Step: 11
Training loss: 1.1005039946168589
Validation loss: 2.2699563428193317

Epoch: 6| Step: 12
Training loss: 1.2529755462793257
Validation loss: 2.3106666698722202

Epoch: 6| Step: 13
Training loss: 1.7290736100615354
Validation loss: 2.279621406568749

Epoch: 387| Step: 0
Training loss: 1.928254989619546
Validation loss: 2.3338163373287504

Epoch: 6| Step: 1
Training loss: 0.8460458673258446
Validation loss: 2.2727899554214

Epoch: 6| Step: 2
Training loss: 1.0605849229370043
Validation loss: 2.2718634578074632

Epoch: 6| Step: 3
Training loss: 1.2770684088394455
Validation loss: 2.3445649226771716

Epoch: 6| Step: 4
Training loss: 1.2201369780890559
Validation loss: 2.2932752950194417

Epoch: 6| Step: 5
Training loss: 1.4070863991477007
Validation loss: 2.3088509554970984

Epoch: 6| Step: 6
Training loss: 0.7195286886395355
Validation loss: 2.310476777734563

Epoch: 6| Step: 7
Training loss: 1.2857738274835078
Validation loss: 2.357953276238125

Epoch: 6| Step: 8
Training loss: 1.1881028201276915
Validation loss: 2.293815088065318

Epoch: 6| Step: 9
Training loss: 1.016045585991347
Validation loss: 2.395189659643534

Epoch: 6| Step: 10
Training loss: 1.2481964451528207
Validation loss: 2.2512060440149737

Epoch: 6| Step: 11
Training loss: 1.2541691869835017
Validation loss: 2.3280466901634624

Epoch: 6| Step: 12
Training loss: 1.0062309689824962
Validation loss: 2.2346391797765257

Epoch: 6| Step: 13
Training loss: 0.730894811067835
Validation loss: 2.40359075412476

Epoch: 388| Step: 0
Training loss: 1.9819869442845615
Validation loss: 2.357474545243192

Epoch: 6| Step: 1
Training loss: 0.9826035682312172
Validation loss: 2.2575348844730865

Epoch: 6| Step: 2
Training loss: 0.7159521962409544
Validation loss: 2.3445005017854297

Epoch: 6| Step: 3
Training loss: 1.0498834908649954
Validation loss: 2.3592033869822218

Epoch: 6| Step: 4
Training loss: 1.1771076109866558
Validation loss: 2.342028286686267

Epoch: 6| Step: 5
Training loss: 1.1187859683941168
Validation loss: 2.2324492978464856

Epoch: 6| Step: 6
Training loss: 1.2912346312207434
Validation loss: 2.3189101127384393

Epoch: 6| Step: 7
Training loss: 0.9377091492369167
Validation loss: 2.3097175997090993

Epoch: 6| Step: 8
Training loss: 0.8058808745910758
Validation loss: 2.3185653718715917

Epoch: 6| Step: 9
Training loss: 1.1457665973071307
Validation loss: 2.2834479217064008

Epoch: 6| Step: 10
Training loss: 1.380346524020261
Validation loss: 2.329799995725006

Epoch: 6| Step: 11
Training loss: 1.3975776287758008
Validation loss: 2.271634350547271

Epoch: 6| Step: 12
Training loss: 0.8302392780722389
Validation loss: 2.2574446353962667

Epoch: 6| Step: 13
Training loss: 1.1531617445635092
Validation loss: 2.246380059968319

Epoch: 389| Step: 0
Training loss: 0.8436351980592559
Validation loss: 2.29693018367246

Epoch: 6| Step: 1
Training loss: 1.9977820734612703
Validation loss: 2.3362573995945812

Epoch: 6| Step: 2
Training loss: 0.7875991319901511
Validation loss: 2.29331666010941

Epoch: 6| Step: 3
Training loss: 1.2742004917130054
Validation loss: 2.2968288615391224

Epoch: 6| Step: 4
Training loss: 1.120985338239385
Validation loss: 2.318250128281904

Epoch: 6| Step: 5
Training loss: 0.882005846250712
Validation loss: 2.2639887620148462

Epoch: 6| Step: 6
Training loss: 1.3459207167862186
Validation loss: 2.296377249035535

Epoch: 6| Step: 7
Training loss: 1.3431639169457443
Validation loss: 2.2979492572835527

Epoch: 6| Step: 8
Training loss: 0.8089671355528428
Validation loss: 2.2828539071577603

Epoch: 6| Step: 9
Training loss: 0.854378794094499
Validation loss: 2.3616485572354686

Epoch: 6| Step: 10
Training loss: 1.2903106195718372
Validation loss: 2.3013165414965386

Epoch: 6| Step: 11
Training loss: 1.1927637589859805
Validation loss: 2.3178844518183754

Epoch: 6| Step: 12
Training loss: 1.3030327450962584
Validation loss: 2.3369504580373506

Epoch: 6| Step: 13
Training loss: 0.910248714874626
Validation loss: 2.286693693095949

Epoch: 390| Step: 0
Training loss: 0.988378829059008
Validation loss: 2.288572969176407

Epoch: 6| Step: 1
Training loss: 1.0265029541582575
Validation loss: 2.351860382102756

Epoch: 6| Step: 2
Training loss: 1.0936168044595593
Validation loss: 2.323558535673682

Epoch: 6| Step: 3
Training loss: 0.8632704099777213
Validation loss: 2.259985831152107

Epoch: 6| Step: 4
Training loss: 1.2420293359409393
Validation loss: 2.3212417802797614

Epoch: 6| Step: 5
Training loss: 1.2770013846178547
Validation loss: 2.3093433836046118

Epoch: 6| Step: 6
Training loss: 1.1346536866751933
Validation loss: 2.3140160054322045

Epoch: 6| Step: 7
Training loss: 0.845667884568162
Validation loss: 2.368072395271648

Epoch: 6| Step: 8
Training loss: 1.2143501677357156
Validation loss: 2.371619254078277

Epoch: 6| Step: 9
Training loss: 1.00718267114744
Validation loss: 2.312355171109447

Epoch: 6| Step: 10
Training loss: 1.309130885782363
Validation loss: 2.273435436400498

Epoch: 6| Step: 11
Training loss: 1.4770135745572108
Validation loss: 2.376882986464881

Epoch: 6| Step: 12
Training loss: 0.6813226083681533
Validation loss: 2.3126035299631233

Epoch: 6| Step: 13
Training loss: 2.5192098723086382
Validation loss: 2.3427910946702344

Epoch: 391| Step: 0
Training loss: 2.0916656823428244
Validation loss: 2.39524261946556

Epoch: 6| Step: 1
Training loss: 1.176024757085736
Validation loss: 2.3754468615114375

Epoch: 6| Step: 2
Training loss: 1.2916001282237943
Validation loss: 2.2417748744608867

Epoch: 6| Step: 3
Training loss: 1.1023929252443174
Validation loss: 2.3045310847349083

Epoch: 6| Step: 4
Training loss: 1.0319938289029043
Validation loss: 2.2774765681459703

Epoch: 6| Step: 5
Training loss: 1.2154138827932284
Validation loss: 2.3546470194132447

Epoch: 6| Step: 6
Training loss: 1.0384155783576507
Validation loss: 2.377805888469465

Epoch: 6| Step: 7
Training loss: 0.904966201414543
Validation loss: 2.3646788309261675

Epoch: 6| Step: 8
Training loss: 0.9607710965610019
Validation loss: 2.3394408407682183

Epoch: 6| Step: 9
Training loss: 1.4683653956942109
Validation loss: 2.3011873357883874

Epoch: 6| Step: 10
Training loss: 1.2067923201337154
Validation loss: 2.293558759144713

Epoch: 6| Step: 11
Training loss: 1.0523098176216348
Validation loss: 2.2995519228795134

Epoch: 6| Step: 12
Training loss: 1.2464765480917108
Validation loss: 2.3449631753992333

Epoch: 6| Step: 13
Training loss: 1.1309839684035705
Validation loss: 2.3502209093740345

Epoch: 392| Step: 0
Training loss: 1.0008142255938417
Validation loss: 2.309109135992263

Epoch: 6| Step: 1
Training loss: 1.3162654722197378
Validation loss: 2.2852924972064446

Epoch: 6| Step: 2
Training loss: 0.9641736131932743
Validation loss: 2.3689376830296043

Epoch: 6| Step: 3
Training loss: 0.9480663258270842
Validation loss: 2.273248102251381

Epoch: 6| Step: 4
Training loss: 2.0691054946310974
Validation loss: 2.349247188464121

Epoch: 6| Step: 5
Training loss: 1.2347061582182333
Validation loss: 2.31454147074025

Epoch: 6| Step: 6
Training loss: 1.244873645376094
Validation loss: 2.3673742066287407

Epoch: 6| Step: 7
Training loss: 1.33876866396192
Validation loss: 2.352587036438621

Epoch: 6| Step: 8
Training loss: 1.0571619464741426
Validation loss: 2.2740755676029267

Epoch: 6| Step: 9
Training loss: 0.9865028755312356
Validation loss: 2.313549545230421

Epoch: 6| Step: 10
Training loss: 1.0804687676529734
Validation loss: 2.292195608301115

Epoch: 6| Step: 11
Training loss: 0.8797506387658929
Validation loss: 2.3237781013533994

Epoch: 6| Step: 12
Training loss: 1.3408111549725972
Validation loss: 2.259340236271957

Epoch: 6| Step: 13
Training loss: 0.9125712366907965
Validation loss: 2.3648217952719817

Epoch: 393| Step: 0
Training loss: 1.26039256973982
Validation loss: 2.344519601892407

Epoch: 6| Step: 1
Training loss: 0.8176804960983514
Validation loss: 2.354871466508282

Epoch: 6| Step: 2
Training loss: 0.8775578306438087
Validation loss: 2.321156115524221

Epoch: 6| Step: 3
Training loss: 1.0271762958004915
Validation loss: 2.268365895822977

Epoch: 6| Step: 4
Training loss: 0.8507478649640596
Validation loss: 2.3100852875204154

Epoch: 6| Step: 5
Training loss: 0.841369626692425
Validation loss: 2.256647516180471

Epoch: 6| Step: 6
Training loss: 2.0960696451832166
Validation loss: 2.22437144000305

Epoch: 6| Step: 7
Training loss: 1.023227990523977
Validation loss: 2.377054484091838

Epoch: 6| Step: 8
Training loss: 1.2289661739651292
Validation loss: 2.3243909083190006

Epoch: 6| Step: 9
Training loss: 1.0086778577606899
Validation loss: 2.3197508140011127

Epoch: 6| Step: 10
Training loss: 1.1960672227345956
Validation loss: 2.2605160602076793

Epoch: 6| Step: 11
Training loss: 0.839940903832798
Validation loss: 2.300642546471205

Epoch: 6| Step: 12
Training loss: 1.1926686087354952
Validation loss: 2.3259001344011407

Epoch: 6| Step: 13
Training loss: 1.3203010332862366
Validation loss: 2.3970320963970715

Epoch: 394| Step: 0
Training loss: 1.0612073215309699
Validation loss: 2.377448875755132

Epoch: 6| Step: 1
Training loss: 0.6659342249015996
Validation loss: 2.3072726748609003

Epoch: 6| Step: 2
Training loss: 2.2018558823824566
Validation loss: 2.295644803898307

Epoch: 6| Step: 3
Training loss: 0.93661858132043
Validation loss: 2.2727129306322036

Epoch: 6| Step: 4
Training loss: 1.4533676437095957
Validation loss: 2.270951664138877

Epoch: 6| Step: 5
Training loss: 1.1024270418900426
Validation loss: 2.2964302794917564

Epoch: 6| Step: 6
Training loss: 1.2681851336950751
Validation loss: 2.319774078106931

Epoch: 6| Step: 7
Training loss: 1.2883932514905727
Validation loss: 2.3802245391669548

Epoch: 6| Step: 8
Training loss: 1.1933333024143946
Validation loss: 2.2474962806481535

Epoch: 6| Step: 9
Training loss: 0.7911819848211085
Validation loss: 2.2837795606876496

Epoch: 6| Step: 10
Training loss: 1.017868498449632
Validation loss: 2.258360405549167

Epoch: 6| Step: 11
Training loss: 1.1072818728157678
Validation loss: 2.364318595038793

Epoch: 6| Step: 12
Training loss: 0.5760790216659897
Validation loss: 2.3774160456654205

Epoch: 6| Step: 13
Training loss: 1.1757077419077047
Validation loss: 2.2862908957509367

Epoch: 395| Step: 0
Training loss: 0.984935721899713
Validation loss: 2.3494571785193625

Epoch: 6| Step: 1
Training loss: 1.2589426117165319
Validation loss: 2.4020854515959496

Epoch: 6| Step: 2
Training loss: 1.193723332771307
Validation loss: 2.2759864415401942

Epoch: 6| Step: 3
Training loss: 0.884686767567042
Validation loss: 2.274290871266832

Epoch: 6| Step: 4
Training loss: 0.9182059448271593
Validation loss: 2.260967140165896

Epoch: 6| Step: 5
Training loss: 1.0887219524603065
Validation loss: 2.3531919189781307

Epoch: 6| Step: 6
Training loss: 1.1354258942302013
Validation loss: 2.2843800545650788

Epoch: 6| Step: 7
Training loss: 0.9928474334151867
Validation loss: 2.3334093088827577

Epoch: 6| Step: 8
Training loss: 1.3585165097269236
Validation loss: 2.332902952867528

Epoch: 6| Step: 9
Training loss: 1.1582216515434358
Validation loss: 2.3410548869428505

Epoch: 6| Step: 10
Training loss: 1.195472905983542
Validation loss: 2.3318774307488135

Epoch: 6| Step: 11
Training loss: 1.9699574355547225
Validation loss: 2.267823333185537

Epoch: 6| Step: 12
Training loss: 1.3260045795793118
Validation loss: 2.337047887385782

Epoch: 6| Step: 13
Training loss: 0.7480373531363018
Validation loss: 2.2428219508482847

Epoch: 396| Step: 0
Training loss: 0.9282022681648506
Validation loss: 2.4019972535237426

Epoch: 6| Step: 1
Training loss: 0.6145769027330429
Validation loss: 2.324384588521087

Epoch: 6| Step: 2
Training loss: 0.969877601992714
Validation loss: 2.269638945979026

Epoch: 6| Step: 3
Training loss: 0.9835796170359334
Validation loss: 2.3364516251592047

Epoch: 6| Step: 4
Training loss: 0.8757973852381207
Validation loss: 2.353531790968731

Epoch: 6| Step: 5
Training loss: 1.3214781541985194
Validation loss: 2.336791283029994

Epoch: 6| Step: 6
Training loss: 0.9523336220657272
Validation loss: 2.3761551794251923

Epoch: 6| Step: 7
Training loss: 2.1192802418365346
Validation loss: 2.2962223431882847

Epoch: 6| Step: 8
Training loss: 0.893124336044887
Validation loss: 2.3688900845893057

Epoch: 6| Step: 9
Training loss: 1.4651191961080576
Validation loss: 2.247356924690924

Epoch: 6| Step: 10
Training loss: 1.3093145861834166
Validation loss: 2.299443652299015

Epoch: 6| Step: 11
Training loss: 0.9438863668382507
Validation loss: 2.2269688389304334

Epoch: 6| Step: 12
Training loss: 1.500428456467857
Validation loss: 2.263383613651483

Epoch: 6| Step: 13
Training loss: 0.5813801599198535
Validation loss: 2.3154422143116955

Epoch: 397| Step: 0
Training loss: 1.1321895070154278
Validation loss: 2.404456011214275

Epoch: 6| Step: 1
Training loss: 1.9158547243459207
Validation loss: 2.364824416560247

Epoch: 6| Step: 2
Training loss: 1.1319724816020524
Validation loss: 2.285985338565918

Epoch: 6| Step: 3
Training loss: 1.0038379690498258
Validation loss: 2.311130949878985

Epoch: 6| Step: 4
Training loss: 1.178243802098631
Validation loss: 2.4171539316824693

Epoch: 6| Step: 5
Training loss: 0.9258024317897554
Validation loss: 2.3190432630933655

Epoch: 6| Step: 6
Training loss: 0.8461295587882076
Validation loss: 2.3457553124753607

Epoch: 6| Step: 7
Training loss: 1.609592163841178
Validation loss: 2.3348658530985307

Epoch: 6| Step: 8
Training loss: 0.6200251713765238
Validation loss: 2.3273988571229705

Epoch: 6| Step: 9
Training loss: 0.7466423055245308
Validation loss: 2.2991673232041796

Epoch: 6| Step: 10
Training loss: 1.0118653180211115
Validation loss: 2.4098342475913577

Epoch: 6| Step: 11
Training loss: 1.3847170714998163
Validation loss: 2.3508787754550595

Epoch: 6| Step: 12
Training loss: 1.246378611946477
Validation loss: 2.288660453362381

Epoch: 6| Step: 13
Training loss: 0.9226324881030258
Validation loss: 2.318563162679437

Epoch: 398| Step: 0
Training loss: 1.3110545236872533
Validation loss: 2.3624574610438605

Epoch: 6| Step: 1
Training loss: 1.0578034889367047
Validation loss: 2.2319964389624127

Epoch: 6| Step: 2
Training loss: 1.2758384490870878
Validation loss: 2.384283620382436

Epoch: 6| Step: 3
Training loss: 1.2693720791143097
Validation loss: 2.2445135300916674

Epoch: 6| Step: 4
Training loss: 1.028220379240225
Validation loss: 2.2633794262092217

Epoch: 6| Step: 5
Training loss: 0.6716346310752647
Validation loss: 2.281189829366725

Epoch: 6| Step: 6
Training loss: 1.3059790608624604
Validation loss: 2.3211472676211713

Epoch: 6| Step: 7
Training loss: 0.9822068936663177
Validation loss: 2.3220598570255815

Epoch: 6| Step: 8
Training loss: 0.9668694054725913
Validation loss: 2.247552793050827

Epoch: 6| Step: 9
Training loss: 1.492463730414506
Validation loss: 2.303826842595856

Epoch: 6| Step: 10
Training loss: 0.8538487044172068
Validation loss: 2.3108311245990563

Epoch: 6| Step: 11
Training loss: 1.8514727478164463
Validation loss: 2.3143664219410156

Epoch: 6| Step: 12
Training loss: 1.0203849170917416
Validation loss: 2.292225624298286

Epoch: 6| Step: 13
Training loss: 1.2071859019933242
Validation loss: 2.2699166809471314

Epoch: 399| Step: 0
Training loss: 0.8552917227627418
Validation loss: 2.281403277242058

Epoch: 6| Step: 1
Training loss: 1.4025066992995792
Validation loss: 2.3037312287686307

Epoch: 6| Step: 2
Training loss: 0.9650003406543822
Validation loss: 2.331832684083632

Epoch: 6| Step: 3
Training loss: 1.1095987013811297
Validation loss: 2.3125732496744793

Epoch: 6| Step: 4
Training loss: 1.1427449422493625
Validation loss: 2.3006602004969543

Epoch: 6| Step: 5
Training loss: 1.1798888280999655
Validation loss: 2.3162693836191863

Epoch: 6| Step: 6
Training loss: 1.4020155838822657
Validation loss: 2.2454675190404623

Epoch: 6| Step: 7
Training loss: 0.9252140544968439
Validation loss: 2.293694660638768

Epoch: 6| Step: 8
Training loss: 1.26014360775078
Validation loss: 2.2617064867142886

Epoch: 6| Step: 9
Training loss: 0.9567171476638238
Validation loss: 2.2482303937803376

Epoch: 6| Step: 10
Training loss: 2.0002007383696303
Validation loss: 2.292370252097953

Epoch: 6| Step: 11
Training loss: 0.9457091768142828
Validation loss: 2.354905582505451

Epoch: 6| Step: 12
Training loss: 0.8861798232558745
Validation loss: 2.260682033497852

Epoch: 6| Step: 13
Training loss: 0.7254044111890219
Validation loss: 2.3015367748805313

Epoch: 400| Step: 0
Training loss: 1.1752001571618813
Validation loss: 2.3181042651833557

Epoch: 6| Step: 1
Training loss: 1.5004392616514917
Validation loss: 2.3736476577754377

Epoch: 6| Step: 2
Training loss: 1.7747956171703407
Validation loss: 2.3530766341814715

Epoch: 6| Step: 3
Training loss: 1.0633600344539194
Validation loss: 2.3247012852072255

Epoch: 6| Step: 4
Training loss: 1.042466803646532
Validation loss: 2.3035019695451338

Epoch: 6| Step: 5
Training loss: 0.9887531043677902
Validation loss: 2.330361002139196

Epoch: 6| Step: 6
Training loss: 0.925709621056699
Validation loss: 2.3832183282499564

Epoch: 6| Step: 7
Training loss: 0.8420914844707974
Validation loss: 2.2521709328304844

Epoch: 6| Step: 8
Training loss: 1.2153626342696777
Validation loss: 2.240962760164328

Epoch: 6| Step: 9
Training loss: 0.7490633440390914
Validation loss: 2.3079836109765464

Epoch: 6| Step: 10
Training loss: 0.9196237781677798
Validation loss: 2.2765247732123353

Epoch: 6| Step: 11
Training loss: 0.9295121035493211
Validation loss: 2.324558743952341

Epoch: 6| Step: 12
Training loss: 1.3977603231781282
Validation loss: 2.338830458425683

Epoch: 6| Step: 13
Training loss: 1.265023547771351
Validation loss: 2.3339576563483804

Epoch: 401| Step: 0
Training loss: 1.2555272447766332
Validation loss: 2.2502549117060076

Epoch: 6| Step: 1
Training loss: 1.150424406271302
Validation loss: 2.3271300006616173

Epoch: 6| Step: 2
Training loss: 0.9015989987077543
Validation loss: 2.2920219131125457

Epoch: 6| Step: 3
Training loss: 1.1934900290332784
Validation loss: 2.322204942863514

Epoch: 6| Step: 4
Training loss: 1.0681852934612948
Validation loss: 2.3046253594332002

Epoch: 6| Step: 5
Training loss: 1.2306157100049795
Validation loss: 2.314449373886636

Epoch: 6| Step: 6
Training loss: 0.8997383982553512
Validation loss: 2.2805658405455023

Epoch: 6| Step: 7
Training loss: 1.0467743896419914
Validation loss: 2.277164602535535

Epoch: 6| Step: 8
Training loss: 1.0178681470997957
Validation loss: 2.242908308326823

Epoch: 6| Step: 9
Training loss: 1.8165311380747353
Validation loss: 2.3270990589208447

Epoch: 6| Step: 10
Training loss: 1.0399400260945508
Validation loss: 2.265306841809774

Epoch: 6| Step: 11
Training loss: 1.350494889219656
Validation loss: 2.3495492484998417

Epoch: 6| Step: 12
Training loss: 1.0165236971861098
Validation loss: 2.3013784661815544

Epoch: 6| Step: 13
Training loss: 0.7534330394965669
Validation loss: 2.338382137139448

Epoch: 402| Step: 0
Training loss: 0.9312326109625966
Validation loss: 2.2880662234453117

Epoch: 6| Step: 1
Training loss: 1.018929958246101
Validation loss: 2.326072344618007

Epoch: 6| Step: 2
Training loss: 1.2278875980532844
Validation loss: 2.3272407963045194

Epoch: 6| Step: 3
Training loss: 0.8050605871963966
Validation loss: 2.3440363216178715

Epoch: 6| Step: 4
Training loss: 0.6808740628486236
Validation loss: 2.255547235702111

Epoch: 6| Step: 5
Training loss: 1.208828917632345
Validation loss: 2.3270349003449904

Epoch: 6| Step: 6
Training loss: 1.0760973231252275
Validation loss: 2.378560868773415

Epoch: 6| Step: 7
Training loss: 1.1242096561915036
Validation loss: 2.308634224316799

Epoch: 6| Step: 8
Training loss: 1.2328416015903325
Validation loss: 2.3194300426137313

Epoch: 6| Step: 9
Training loss: 1.8712978689712934
Validation loss: 2.2970097178410573

Epoch: 6| Step: 10
Training loss: 0.8038624357660216
Validation loss: 2.3368520937811743

Epoch: 6| Step: 11
Training loss: 1.1272637056628751
Validation loss: 2.3031759286758597

Epoch: 6| Step: 12
Training loss: 1.0794799693565154
Validation loss: 2.321011281678481

Epoch: 6| Step: 13
Training loss: 0.8775685621032789
Validation loss: 2.329219257310537

Epoch: 403| Step: 0
Training loss: 0.7275676132846949
Validation loss: 2.3553209033421654

Epoch: 6| Step: 1
Training loss: 0.891522440580302
Validation loss: 2.342193830691806

Epoch: 6| Step: 2
Training loss: 0.9536596580904733
Validation loss: 2.30102451867911

Epoch: 6| Step: 3
Training loss: 1.0646847534144261
Validation loss: 2.309059799095254

Epoch: 6| Step: 4
Training loss: 1.828741312065008
Validation loss: 2.2556019108763357

Epoch: 6| Step: 5
Training loss: 1.7143453860115418
Validation loss: 2.2277585196482477

Epoch: 6| Step: 6
Training loss: 1.1613285294373927
Validation loss: 2.3144405906195566

Epoch: 6| Step: 7
Training loss: 1.1401183165672302
Validation loss: 2.3410145351147924

Epoch: 6| Step: 8
Training loss: 0.9253933572789214
Validation loss: 2.309428630667205

Epoch: 6| Step: 9
Training loss: 1.1859882167983464
Validation loss: 2.210656448856737

Epoch: 6| Step: 10
Training loss: 1.1488450553344354
Validation loss: 2.36715736127655

Epoch: 6| Step: 11
Training loss: 1.3279619004575292
Validation loss: 2.2758254284542554

Epoch: 6| Step: 12
Training loss: 1.139078424287479
Validation loss: 2.328321310023992

Epoch: 6| Step: 13
Training loss: 0.5838681363678486
Validation loss: 2.333860089207493

Epoch: 404| Step: 0
Training loss: 1.3625502060905614
Validation loss: 2.2941590006107946

Epoch: 6| Step: 1
Training loss: 1.826254515384468
Validation loss: 2.3705750517523674

Epoch: 6| Step: 2
Training loss: 1.1648845458226473
Validation loss: 2.317753920476066

Epoch: 6| Step: 3
Training loss: 0.7524575659361437
Validation loss: 2.2964919351722495

Epoch: 6| Step: 4
Training loss: 1.2005544176458658
Validation loss: 2.340840011581488

Epoch: 6| Step: 5
Training loss: 0.854091074940435
Validation loss: 2.321861244922432

Epoch: 6| Step: 6
Training loss: 1.0733536999904567
Validation loss: 2.3529422816482666

Epoch: 6| Step: 7
Training loss: 0.8356775610520109
Validation loss: 2.30709839798466

Epoch: 6| Step: 8
Training loss: 1.4192592328732003
Validation loss: 2.3326201586880124

Epoch: 6| Step: 9
Training loss: 0.6400272092399705
Validation loss: 2.3176331734070406

Epoch: 6| Step: 10
Training loss: 1.49420317475282
Validation loss: 2.353986093048162

Epoch: 6| Step: 11
Training loss: 0.8054585142623001
Validation loss: 2.3096615438890464

Epoch: 6| Step: 12
Training loss: 1.4399059727223067
Validation loss: 2.2934194039057836

Epoch: 6| Step: 13
Training loss: 0.7374446912813019
Validation loss: 2.327748276355291

Epoch: 405| Step: 0
Training loss: 0.9932077523883394
Validation loss: 2.29324591431886

Epoch: 6| Step: 1
Training loss: 1.4005234999777292
Validation loss: 2.2347189279079056

Epoch: 6| Step: 2
Training loss: 1.15848912122259
Validation loss: 2.301315182986911

Epoch: 6| Step: 3
Training loss: 1.1290197612360895
Validation loss: 2.327448261284636

Epoch: 6| Step: 4
Training loss: 0.7343745535991205
Validation loss: 2.291090260913986

Epoch: 6| Step: 5
Training loss: 1.0964023582516638
Validation loss: 2.258203274445211

Epoch: 6| Step: 6
Training loss: 0.9412667578716366
Validation loss: 2.2784584981436438

Epoch: 6| Step: 7
Training loss: 1.039519188124463
Validation loss: 2.350819601830126

Epoch: 6| Step: 8
Training loss: 2.0392671095109405
Validation loss: 2.3250305715829693

Epoch: 6| Step: 9
Training loss: 0.7617143288508513
Validation loss: 2.2987551834269357

Epoch: 6| Step: 10
Training loss: 1.3375994066036314
Validation loss: 2.349448298618461

Epoch: 6| Step: 11
Training loss: 0.9481126596632204
Validation loss: 2.2795686457936846

Epoch: 6| Step: 12
Training loss: 1.1414544212207893
Validation loss: 2.2960569515308844

Epoch: 6| Step: 13
Training loss: 1.0881291509786855
Validation loss: 2.330431331859004

Epoch: 406| Step: 0
Training loss: 1.0177198666426968
Validation loss: 2.285174211014821

Epoch: 6| Step: 1
Training loss: 1.2610801757868424
Validation loss: 2.3470849886003875

Epoch: 6| Step: 2
Training loss: 1.5522494728553184
Validation loss: 2.267347437649798

Epoch: 6| Step: 3
Training loss: 1.1292407850219304
Validation loss: 2.2380430044688056

Epoch: 6| Step: 4
Training loss: 0.9800977574948166
Validation loss: 2.2939883608282066

Epoch: 6| Step: 5
Training loss: 0.9982190664797409
Validation loss: 2.3148223470294145

Epoch: 6| Step: 6
Training loss: 0.641865204362124
Validation loss: 2.2361145132454174

Epoch: 6| Step: 7
Training loss: 1.0929448024915691
Validation loss: 2.3392737978050904

Epoch: 6| Step: 8
Training loss: 1.03360646673267
Validation loss: 2.2969156763502747

Epoch: 6| Step: 9
Training loss: 0.9263579427445622
Validation loss: 2.3083815713724936

Epoch: 6| Step: 10
Training loss: 1.7948763803189431
Validation loss: 2.2664496822239255

Epoch: 6| Step: 11
Training loss: 1.2633007984618743
Validation loss: 2.2405148109891733

Epoch: 6| Step: 12
Training loss: 1.0060877864712447
Validation loss: 2.2554046836015726

Epoch: 6| Step: 13
Training loss: 0.9644332506705334
Validation loss: 2.306817993736731

Epoch: 407| Step: 0
Training loss: 1.141586890995196
Validation loss: 2.284862588139117

Epoch: 6| Step: 1
Training loss: 1.0856658266392394
Validation loss: 2.3213572542961387

Epoch: 6| Step: 2
Training loss: 0.7208991055626307
Validation loss: 2.2369214741119823

Epoch: 6| Step: 3
Training loss: 2.0015058808727524
Validation loss: 2.2961601130917706

Epoch: 6| Step: 4
Training loss: 0.8893608692089416
Validation loss: 2.305724127585342

Epoch: 6| Step: 5
Training loss: 0.8689285533932578
Validation loss: 2.415178976823591

Epoch: 6| Step: 6
Training loss: 1.329525915563984
Validation loss: 2.326633041109001

Epoch: 6| Step: 7
Training loss: 0.7917978069373331
Validation loss: 2.282427980495542

Epoch: 6| Step: 8
Training loss: 1.0018815578310323
Validation loss: 2.279738098967101

Epoch: 6| Step: 9
Training loss: 1.0109704980667962
Validation loss: 2.320376021346188

Epoch: 6| Step: 10
Training loss: 1.5836308434032538
Validation loss: 2.3237671970921543

Epoch: 6| Step: 11
Training loss: 0.8695078556173168
Validation loss: 2.316681199003497

Epoch: 6| Step: 12
Training loss: 0.7066585338172519
Validation loss: 2.262273141114504

Epoch: 6| Step: 13
Training loss: 1.4534828811807934
Validation loss: 2.367089282131416

Epoch: 408| Step: 0
Training loss: 0.9334475031630576
Validation loss: 2.3768468712687687

Epoch: 6| Step: 1
Training loss: 1.0932218638929347
Validation loss: 2.2846821852332795

Epoch: 6| Step: 2
Training loss: 1.4061335197527702
Validation loss: 2.3407826004585117

Epoch: 6| Step: 3
Training loss: 1.0318924030058685
Validation loss: 2.3213981551600837

Epoch: 6| Step: 4
Training loss: 0.9811182492485993
Validation loss: 2.297190602311897

Epoch: 6| Step: 5
Training loss: 0.865139028148021
Validation loss: 2.341028817888559

Epoch: 6| Step: 6
Training loss: 0.7178923424046276
Validation loss: 2.334984492527363

Epoch: 6| Step: 7
Training loss: 1.1638404071080657
Validation loss: 2.2942925292312397

Epoch: 6| Step: 8
Training loss: 1.1371709704056059
Validation loss: 2.269365208826993

Epoch: 6| Step: 9
Training loss: 1.7461224239990405
Validation loss: 2.2980794688870056

Epoch: 6| Step: 10
Training loss: 1.0059089129943402
Validation loss: 2.260699295363161

Epoch: 6| Step: 11
Training loss: 0.8788371419227855
Validation loss: 2.293701665753016

Epoch: 6| Step: 12
Training loss: 1.3410310961583431
Validation loss: 2.2871477714028075

Epoch: 6| Step: 13
Training loss: 0.6632161300557822
Validation loss: 2.3103033095927104

Epoch: 409| Step: 0
Training loss: 0.7735772440117731
Validation loss: 2.3049136654809272

Epoch: 6| Step: 1
Training loss: 0.8545015694239418
Validation loss: 2.308986772157757

Epoch: 6| Step: 2
Training loss: 1.0450060658986111
Validation loss: 2.2630498342304186

Epoch: 6| Step: 3
Training loss: 1.0855118171052185
Validation loss: 2.324255500682834

Epoch: 6| Step: 4
Training loss: 1.077652924609823
Validation loss: 2.3057993719863923

Epoch: 6| Step: 5
Training loss: 0.9306476667627115
Validation loss: 2.2268772273412147

Epoch: 6| Step: 6
Training loss: 1.1379961524690507
Validation loss: 2.244398801934401

Epoch: 6| Step: 7
Training loss: 1.3816357363117453
Validation loss: 2.331717636213758

Epoch: 6| Step: 8
Training loss: 1.1087752319354962
Validation loss: 2.2870837189389284

Epoch: 6| Step: 9
Training loss: 0.8037532456897563
Validation loss: 2.3011283008982066

Epoch: 6| Step: 10
Training loss: 1.136840237027812
Validation loss: 2.377615275353282

Epoch: 6| Step: 11
Training loss: 1.9422601245857327
Validation loss: 2.32219764120572

Epoch: 6| Step: 12
Training loss: 0.9972777865333602
Validation loss: 2.2544232054986475

Epoch: 6| Step: 13
Training loss: 1.4248982242579322
Validation loss: 2.3845562441467925

Epoch: 410| Step: 0
Training loss: 1.137920570175942
Validation loss: 2.3792997922059276

Epoch: 6| Step: 1
Training loss: 0.81429331284159
Validation loss: 2.338093020640362

Epoch: 6| Step: 2
Training loss: 1.0406491205209447
Validation loss: 2.257066453192143

Epoch: 6| Step: 3
Training loss: 1.1820550869531923
Validation loss: 2.1981356201225086

Epoch: 6| Step: 4
Training loss: 1.0537850934539403
Validation loss: 2.22366407679761

Epoch: 6| Step: 5
Training loss: 1.1843891052372422
Validation loss: 2.3077237437533724

Epoch: 6| Step: 6
Training loss: 0.9459264668784352
Validation loss: 2.228433971230794

Epoch: 6| Step: 7
Training loss: 0.6986413841585548
Validation loss: 2.266539066578843

Epoch: 6| Step: 8
Training loss: 0.9956510270542864
Validation loss: 2.317051632685612

Epoch: 6| Step: 9
Training loss: 1.8779190864601003
Validation loss: 2.3183434569615637

Epoch: 6| Step: 10
Training loss: 1.0541163840885495
Validation loss: 2.2700632614184664

Epoch: 6| Step: 11
Training loss: 0.8843981251203729
Validation loss: 2.3024916265681754

Epoch: 6| Step: 12
Training loss: 1.2523082878056042
Validation loss: 2.3105862410894256

Epoch: 6| Step: 13
Training loss: 0.9992754218499417
Validation loss: 2.299000901177452

Epoch: 411| Step: 0
Training loss: 1.3687513290468496
Validation loss: 2.354549316603826

Epoch: 6| Step: 1
Training loss: 0.8029598467040593
Validation loss: 2.2712689001088564

Epoch: 6| Step: 2
Training loss: 1.1002576959640302
Validation loss: 2.27528252860447

Epoch: 6| Step: 3
Training loss: 0.9637704663509371
Validation loss: 2.308225661328718

Epoch: 6| Step: 4
Training loss: 1.4032661995645053
Validation loss: 2.2669393809530525

Epoch: 6| Step: 5
Training loss: 1.0885079240208257
Validation loss: 2.222693064331571

Epoch: 6| Step: 6
Training loss: 1.989935525875274
Validation loss: 2.2205384317368813

Epoch: 6| Step: 7
Training loss: 1.2388223615003369
Validation loss: 2.374037097837225

Epoch: 6| Step: 8
Training loss: 0.8538593848264736
Validation loss: 2.2481360947303317

Epoch: 6| Step: 9
Training loss: 1.1682487330822695
Validation loss: 2.3667652489013813

Epoch: 6| Step: 10
Training loss: 0.9119700094591507
Validation loss: 2.3444833276849057

Epoch: 6| Step: 11
Training loss: 0.8739844968848034
Validation loss: 2.3575056891217794

Epoch: 6| Step: 12
Training loss: 0.7525816829363255
Validation loss: 2.257689125654963

Epoch: 6| Step: 13
Training loss: 0.9246526994051398
Validation loss: 2.2155375040421896

Epoch: 412| Step: 0
Training loss: 0.9887281771830481
Validation loss: 2.3824940867294084

Epoch: 6| Step: 1
Training loss: 1.2104145520575345
Validation loss: 2.287719840129274

Epoch: 6| Step: 2
Training loss: 0.932534099292886
Validation loss: 2.357074961905023

Epoch: 6| Step: 3
Training loss: 0.8440514485194625
Validation loss: 2.36495456561466

Epoch: 6| Step: 4
Training loss: 0.9166824093825111
Validation loss: 2.287830377743841

Epoch: 6| Step: 5
Training loss: 1.3142846100073968
Validation loss: 2.3959966260593295

Epoch: 6| Step: 6
Training loss: 0.9043964635994973
Validation loss: 2.310210174334352

Epoch: 6| Step: 7
Training loss: 1.004170661274627
Validation loss: 2.2781761408677546

Epoch: 6| Step: 8
Training loss: 1.2015549459827617
Validation loss: 2.334548703619307

Epoch: 6| Step: 9
Training loss: 0.8002555051719697
Validation loss: 2.301001252182981

Epoch: 6| Step: 10
Training loss: 1.8497748779240741
Validation loss: 2.318548374969639

Epoch: 6| Step: 11
Training loss: 0.903702080961269
Validation loss: 2.247698950593678

Epoch: 6| Step: 12
Training loss: 0.8721223582834238
Validation loss: 2.3037255978871687

Epoch: 6| Step: 13
Training loss: 0.7151036441483409
Validation loss: 2.2814414291987677

Epoch: 413| Step: 0
Training loss: 1.4343117727003298
Validation loss: 2.3220663851888084

Epoch: 6| Step: 1
Training loss: 0.8470782229683271
Validation loss: 2.311782188390542

Epoch: 6| Step: 2
Training loss: 0.9928085906300288
Validation loss: 2.3740750990780817

Epoch: 6| Step: 3
Training loss: 1.2206946777051473
Validation loss: 2.2085409219710583

Epoch: 6| Step: 4
Training loss: 0.8881438646453912
Validation loss: 2.322780852557603

Epoch: 6| Step: 5
Training loss: 1.0267022164081308
Validation loss: 2.310000308292082

Epoch: 6| Step: 6
Training loss: 1.841956025546152
Validation loss: 2.2579038714838973

Epoch: 6| Step: 7
Training loss: 0.8312439394851834
Validation loss: 2.2957374155934436

Epoch: 6| Step: 8
Training loss: 0.8313086152025745
Validation loss: 2.3142181328417237

Epoch: 6| Step: 9
Training loss: 1.233347597984783
Validation loss: 2.298769537506847

Epoch: 6| Step: 10
Training loss: 1.3713506908882196
Validation loss: 2.2278286327405508

Epoch: 6| Step: 11
Training loss: 0.7264873506792954
Validation loss: 2.2628733365281732

Epoch: 6| Step: 12
Training loss: 1.178829765493124
Validation loss: 2.3271009383290897

Epoch: 6| Step: 13
Training loss: 0.7382169423024882
Validation loss: 2.3085415003477805

Epoch: 414| Step: 0
Training loss: 0.8943227999826727
Validation loss: 2.2822030880752497

Epoch: 6| Step: 1
Training loss: 1.0111357434093786
Validation loss: 2.267903097965564

Epoch: 6| Step: 2
Training loss: 1.2169643427688175
Validation loss: 2.303163616761469

Epoch: 6| Step: 3
Training loss: 1.979886422704826
Validation loss: 2.2691695907354785

Epoch: 6| Step: 4
Training loss: 0.8134496714164627
Validation loss: 2.286154593104606

Epoch: 6| Step: 5
Training loss: 0.7400541060875084
Validation loss: 2.338176645547216

Epoch: 6| Step: 6
Training loss: 0.9724063169176116
Validation loss: 2.331275136200089

Epoch: 6| Step: 7
Training loss: 0.8789994593044697
Validation loss: 2.2394679969646982

Epoch: 6| Step: 8
Training loss: 1.0413166348131575
Validation loss: 2.2970874836818767

Epoch: 6| Step: 9
Training loss: 0.9709039860230934
Validation loss: 2.2478907040095906

Epoch: 6| Step: 10
Training loss: 0.9730402177102841
Validation loss: 2.1821697078757105

Epoch: 6| Step: 11
Training loss: 1.1291359004560118
Validation loss: 2.2248224079011742

Epoch: 6| Step: 12
Training loss: 1.156638106086047
Validation loss: 2.295612306505676

Epoch: 6| Step: 13
Training loss: 1.6815293260842052
Validation loss: 2.2510964790875323

Epoch: 415| Step: 0
Training loss: 0.9801924114711122
Validation loss: 2.238375975671362

Epoch: 6| Step: 1
Training loss: 1.1437204242488608
Validation loss: 2.3423416620772697

Epoch: 6| Step: 2
Training loss: 0.9652510798640165
Validation loss: 2.436024455075597

Epoch: 6| Step: 3
Training loss: 0.9393531920642113
Validation loss: 2.353534508160782

Epoch: 6| Step: 4
Training loss: 0.8944360274227523
Validation loss: 2.314844047070124

Epoch: 6| Step: 5
Training loss: 1.282074732627117
Validation loss: 2.294820317849127

Epoch: 6| Step: 6
Training loss: 1.2172609182210112
Validation loss: 2.3066855758406684

Epoch: 6| Step: 7
Training loss: 1.461648044068826
Validation loss: 2.261256153415738

Epoch: 6| Step: 8
Training loss: 0.7917756750113268
Validation loss: 2.3528055684313554

Epoch: 6| Step: 9
Training loss: 1.1256530243955603
Validation loss: 2.276435964511447

Epoch: 6| Step: 10
Training loss: 0.9136791892735436
Validation loss: 2.3040568589287824

Epoch: 6| Step: 11
Training loss: 1.846759925523326
Validation loss: 2.275808333137575

Epoch: 6| Step: 12
Training loss: 0.9810200998967183
Validation loss: 2.2648397010437327

Epoch: 6| Step: 13
Training loss: 0.8118194517612864
Validation loss: 2.2936255226181133

Epoch: 416| Step: 0
Training loss: 0.9917298410365529
Validation loss: 2.261747862427138

Epoch: 6| Step: 1
Training loss: 1.8993661751876334
Validation loss: 2.331299853422093

Epoch: 6| Step: 2
Training loss: 1.0366447830548038
Validation loss: 2.293994833094609

Epoch: 6| Step: 3
Training loss: 1.2961527640236536
Validation loss: 2.3228021173437208

Epoch: 6| Step: 4
Training loss: 0.8769379680317735
Validation loss: 2.3108530706849026

Epoch: 6| Step: 5
Training loss: 1.0189597914290203
Validation loss: 2.378039618586085

Epoch: 6| Step: 6
Training loss: 0.8129439241606096
Validation loss: 2.3139153594409265

Epoch: 6| Step: 7
Training loss: 0.7937641382835563
Validation loss: 2.290761881634096

Epoch: 6| Step: 8
Training loss: 1.0574880646196672
Validation loss: 2.3055912927173243

Epoch: 6| Step: 9
Training loss: 1.2598672515331113
Validation loss: 2.396073474771035

Epoch: 6| Step: 10
Training loss: 0.8582981298381613
Validation loss: 2.2303666247185356

Epoch: 6| Step: 11
Training loss: 1.316745431370991
Validation loss: 2.326690442585919

Epoch: 6| Step: 12
Training loss: 1.0498841721363095
Validation loss: 2.2322278820433312

Epoch: 6| Step: 13
Training loss: 0.9974354104472473
Validation loss: 2.3031716182332542

Epoch: 417| Step: 0
Training loss: 0.905039109865535
Validation loss: 2.2834177869563614

Epoch: 6| Step: 1
Training loss: 0.8366773308369433
Validation loss: 2.2380910271907535

Epoch: 6| Step: 2
Training loss: 1.1738726056854134
Validation loss: 2.2390741760134043

Epoch: 6| Step: 3
Training loss: 0.8403413230120735
Validation loss: 2.3545387736996384

Epoch: 6| Step: 4
Training loss: 0.9253978981772472
Validation loss: 2.2847719357174485

Epoch: 6| Step: 5
Training loss: 1.0471427916588296
Validation loss: 2.351225946384291

Epoch: 6| Step: 6
Training loss: 1.9148564151888243
Validation loss: 2.330299298660854

Epoch: 6| Step: 7
Training loss: 1.1677356091778202
Validation loss: 2.3772702460357342

Epoch: 6| Step: 8
Training loss: 1.2009079061609576
Validation loss: 2.4172522035649626

Epoch: 6| Step: 9
Training loss: 1.284032405631514
Validation loss: 2.2624421834824395

Epoch: 6| Step: 10
Training loss: 0.855343813896142
Validation loss: 2.3017438947237423

Epoch: 6| Step: 11
Training loss: 1.3365032046786618
Validation loss: 2.2482147882508596

Epoch: 6| Step: 12
Training loss: 0.6573161139276884
Validation loss: 2.266568957475206

Epoch: 6| Step: 13
Training loss: 1.0993062714503234
Validation loss: 2.2573557347423576

Epoch: 418| Step: 0
Training loss: 1.0251224421429828
Validation loss: 2.3382830634527285

Epoch: 6| Step: 1
Training loss: 1.082252452288004
Validation loss: 2.3234089839595593

Epoch: 6| Step: 2
Training loss: 1.0745186681816534
Validation loss: 2.268798303119586

Epoch: 6| Step: 3
Training loss: 0.9887538880417646
Validation loss: 2.288277693338234

Epoch: 6| Step: 4
Training loss: 0.982232532494456
Validation loss: 2.2830883546654985

Epoch: 6| Step: 5
Training loss: 0.8025423363186907
Validation loss: 2.320591457051579

Epoch: 6| Step: 6
Training loss: 1.159336918208009
Validation loss: 2.2681000460167837

Epoch: 6| Step: 7
Training loss: 0.9781140628483528
Validation loss: 2.2824258267438005

Epoch: 6| Step: 8
Training loss: 1.4011184312099985
Validation loss: 2.3450811717198956

Epoch: 6| Step: 9
Training loss: 2.155650954030827
Validation loss: 2.303124035864993

Epoch: 6| Step: 10
Training loss: 0.5352965122380788
Validation loss: 2.289044196547642

Epoch: 6| Step: 11
Training loss: 1.0953943153984667
Validation loss: 2.3561841563672514

Epoch: 6| Step: 12
Training loss: 0.9221294181317647
Validation loss: 2.35404784105696

Epoch: 6| Step: 13
Training loss: 0.9837992967713587
Validation loss: 2.315545894493916

Epoch: 419| Step: 0
Training loss: 1.3586436968282118
Validation loss: 2.3344462267917847

Epoch: 6| Step: 1
Training loss: 1.157941457385342
Validation loss: 2.279080033006033

Epoch: 6| Step: 2
Training loss: 0.9786895171047906
Validation loss: 2.3093057853113934

Epoch: 6| Step: 3
Training loss: 1.8451685217004221
Validation loss: 2.2981732884564856

Epoch: 6| Step: 4
Training loss: 0.9060206945300013
Validation loss: 2.3694451606255487

Epoch: 6| Step: 5
Training loss: 1.099716479436424
Validation loss: 2.2821256873192657

Epoch: 6| Step: 6
Training loss: 0.9026385729806904
Validation loss: 2.3691443495759237

Epoch: 6| Step: 7
Training loss: 0.6653632495565663
Validation loss: 2.282163188581557

Epoch: 6| Step: 8
Training loss: 1.0750798883251085
Validation loss: 2.3201989109176315

Epoch: 6| Step: 9
Training loss: 0.8356236019993046
Validation loss: 2.290941844953315

Epoch: 6| Step: 10
Training loss: 1.4847985717361667
Validation loss: 2.278061261316417

Epoch: 6| Step: 11
Training loss: 0.8216683943951479
Validation loss: 2.253453469956963

Epoch: 6| Step: 12
Training loss: 1.0895363979308248
Validation loss: 2.3066119769259736

Epoch: 6| Step: 13
Training loss: 0.8017997405487806
Validation loss: 2.2605789392469617

Epoch: 420| Step: 0
Training loss: 0.8478440107542236
Validation loss: 2.2507226745045505

Epoch: 6| Step: 1
Training loss: 0.7943359014822036
Validation loss: 2.2697455293895215

Epoch: 6| Step: 2
Training loss: 1.2201585699433801
Validation loss: 2.314793276364152

Epoch: 6| Step: 3
Training loss: 1.3312666591980946
Validation loss: 2.2814363714492485

Epoch: 6| Step: 4
Training loss: 0.7809896416752611
Validation loss: 2.2865803503086037

Epoch: 6| Step: 5
Training loss: 1.0049440237370073
Validation loss: 2.2939442865720423

Epoch: 6| Step: 6
Training loss: 1.0441153863267671
Validation loss: 2.2877721540660394

Epoch: 6| Step: 7
Training loss: 1.1424343442520073
Validation loss: 2.2495512190048204

Epoch: 6| Step: 8
Training loss: 1.0166049631082053
Validation loss: 2.2209978985854595

Epoch: 6| Step: 9
Training loss: 0.9711560549278737
Validation loss: 2.3171676980411915

Epoch: 6| Step: 10
Training loss: 1.7827080230457029
Validation loss: 2.401392842268396

Epoch: 6| Step: 11
Training loss: 1.0216636135767196
Validation loss: 2.2585449336515078

Epoch: 6| Step: 12
Training loss: 1.0243059506747818
Validation loss: 2.2742936510053533

Epoch: 6| Step: 13
Training loss: 1.0503381979198225
Validation loss: 2.2282389344412277

Epoch: 421| Step: 0
Training loss: 0.9616754071209235
Validation loss: 2.306534042050025

Epoch: 6| Step: 1
Training loss: 2.003275454103461
Validation loss: 2.2615162844896575

Epoch: 6| Step: 2
Training loss: 0.8373875385899688
Validation loss: 2.284938862286225

Epoch: 6| Step: 3
Training loss: 1.1314576037526376
Validation loss: 2.291466438145146

Epoch: 6| Step: 4
Training loss: 0.8233354364077418
Validation loss: 2.2378342590598947

Epoch: 6| Step: 5
Training loss: 1.1612937822085294
Validation loss: 2.328543504901263

Epoch: 6| Step: 6
Training loss: 1.427861198918962
Validation loss: 2.327453215742055

Epoch: 6| Step: 7
Training loss: 0.8668617805292597
Validation loss: 2.3213905991715795

Epoch: 6| Step: 8
Training loss: 1.2123635539725852
Validation loss: 2.311684288324714

Epoch: 6| Step: 9
Training loss: 0.696817376872029
Validation loss: 2.2344212612231042

Epoch: 6| Step: 10
Training loss: 1.0187947035266527
Validation loss: 2.2836015476248055

Epoch: 6| Step: 11
Training loss: 1.3065875260721547
Validation loss: 2.287569742446904

Epoch: 6| Step: 12
Training loss: 0.7717708779968862
Validation loss: 2.265464346468757

Epoch: 6| Step: 13
Training loss: 0.7195584684477858
Validation loss: 2.2766372090377636

Epoch: 422| Step: 0
Training loss: 0.8200219502651291
Validation loss: 2.287021775433903

Epoch: 6| Step: 1
Training loss: 1.8903720150503827
Validation loss: 2.288408227283227

Epoch: 6| Step: 2
Training loss: 0.91771912122802
Validation loss: 2.3189093521289457

Epoch: 6| Step: 3
Training loss: 0.9884943072782693
Validation loss: 2.29076391395765

Epoch: 6| Step: 4
Training loss: 1.1833231903142927
Validation loss: 2.2840025278052694

Epoch: 6| Step: 5
Training loss: 0.7375141982958622
Validation loss: 2.2679492438688147

Epoch: 6| Step: 6
Training loss: 1.0411307036900495
Validation loss: 2.3334720177754638

Epoch: 6| Step: 7
Training loss: 1.3620214899415133
Validation loss: 2.2836372166835583

Epoch: 6| Step: 8
Training loss: 0.9725047840010546
Validation loss: 2.2858696665945595

Epoch: 6| Step: 9
Training loss: 0.9798003574326302
Validation loss: 2.3054947629686526

Epoch: 6| Step: 10
Training loss: 1.1442595279756145
Validation loss: 2.2324178660456018

Epoch: 6| Step: 11
Training loss: 0.8431463201271844
Validation loss: 2.2770161235895494

Epoch: 6| Step: 12
Training loss: 1.3480846663920003
Validation loss: 2.33905191749768

Epoch: 6| Step: 13
Training loss: 1.2378480556652276
Validation loss: 2.4048810329368995

Epoch: 423| Step: 0
Training loss: 2.175003871695043
Validation loss: 2.331806216182579

Epoch: 6| Step: 1
Training loss: 0.8889121265321063
Validation loss: 2.241901898174946

Epoch: 6| Step: 2
Training loss: 1.2188841428049009
Validation loss: 2.3286043047984877

Epoch: 6| Step: 3
Training loss: 1.0014103837924155
Validation loss: 2.2537809027039426

Epoch: 6| Step: 4
Training loss: 1.5664549556018799
Validation loss: 2.3155900375288425

Epoch: 6| Step: 5
Training loss: 1.059539935120423
Validation loss: 2.2888892222733213

Epoch: 6| Step: 6
Training loss: 0.8050869070848452
Validation loss: 2.345639561083434

Epoch: 6| Step: 7
Training loss: 1.3063256492794328
Validation loss: 2.2356988169279117

Epoch: 6| Step: 8
Training loss: 1.0493214617323832
Validation loss: 2.2787526489161056

Epoch: 6| Step: 9
Training loss: 0.9919116019578724
Validation loss: 2.295058978402863

Epoch: 6| Step: 10
Training loss: 0.6963252931561019
Validation loss: 2.2615934531316784

Epoch: 6| Step: 11
Training loss: 0.7839031183074934
Validation loss: 2.2234662723839342

Epoch: 6| Step: 12
Training loss: 0.9274482687432846
Validation loss: 2.2267573837140744

Epoch: 6| Step: 13
Training loss: 0.6693708862050051
Validation loss: 2.244623691884773

Epoch: 424| Step: 0
Training loss: 1.1329382464893116
Validation loss: 2.221278615631684

Epoch: 6| Step: 1
Training loss: 1.15114243815686
Validation loss: 2.343060661859355

Epoch: 6| Step: 2
Training loss: 1.0418460818592747
Validation loss: 2.2041097648262586

Epoch: 6| Step: 3
Training loss: 1.0870250497860225
Validation loss: 2.363145008531372

Epoch: 6| Step: 4
Training loss: 2.036265826740428
Validation loss: 2.230931687231902

Epoch: 6| Step: 5
Training loss: 1.1446045210888172
Validation loss: 2.26075219259983

Epoch: 6| Step: 6
Training loss: 1.0123114893112701
Validation loss: 2.2628638591171755

Epoch: 6| Step: 7
Training loss: 1.0622118390833664
Validation loss: 2.278087359407119

Epoch: 6| Step: 8
Training loss: 0.6964293521834807
Validation loss: 2.2610971175069974

Epoch: 6| Step: 9
Training loss: 0.8903153533729148
Validation loss: 2.281538319850594

Epoch: 6| Step: 10
Training loss: 0.8813762628451303
Validation loss: 2.2684616192601608

Epoch: 6| Step: 11
Training loss: 0.9062920922336862
Validation loss: 2.2566895043764674

Epoch: 6| Step: 12
Training loss: 0.925495087382315
Validation loss: 2.2274482512422082

Epoch: 6| Step: 13
Training loss: 0.8893622431104887
Validation loss: 2.2814970030254993

Epoch: 425| Step: 0
Training loss: 1.0985205563309135
Validation loss: 2.355277283447454

Epoch: 6| Step: 1
Training loss: 0.8077296555795668
Validation loss: 2.3142090457184654

Epoch: 6| Step: 2
Training loss: 1.3648464541307463
Validation loss: 2.217513361848497

Epoch: 6| Step: 3
Training loss: 0.8459262333356753
Validation loss: 2.2866043768118383

Epoch: 6| Step: 4
Training loss: 0.7971868465814189
Validation loss: 2.249870744362862

Epoch: 6| Step: 5
Training loss: 1.115711437477787
Validation loss: 2.2578725964720334

Epoch: 6| Step: 6
Training loss: 1.1657291232895823
Validation loss: 2.306576313044276

Epoch: 6| Step: 7
Training loss: 1.899701110017985
Validation loss: 2.316053985874143

Epoch: 6| Step: 8
Training loss: 0.9028200155957459
Validation loss: 2.335548298491322

Epoch: 6| Step: 9
Training loss: 0.9999710317230587
Validation loss: 2.2643189226790934

Epoch: 6| Step: 10
Training loss: 0.8431527178303565
Validation loss: 2.3337061136698107

Epoch: 6| Step: 11
Training loss: 1.0617957305509087
Validation loss: 2.2064065374146073

Epoch: 6| Step: 12
Training loss: 1.1768614410737597
Validation loss: 2.2102026531852528

Epoch: 6| Step: 13
Training loss: 0.9803592575153669
Validation loss: 2.2140745151131322

Epoch: 426| Step: 0
Training loss: 1.02754679366805
Validation loss: 2.263209495825861

Epoch: 6| Step: 1
Training loss: 1.047724308133092
Validation loss: 2.282744162898043

Epoch: 6| Step: 2
Training loss: 0.848478068300401
Validation loss: 2.2734944968927753

Epoch: 6| Step: 3
Training loss: 1.0573309654611802
Validation loss: 2.2719572690912626

Epoch: 6| Step: 4
Training loss: 0.860714579278594
Validation loss: 2.219929407805894

Epoch: 6| Step: 5
Training loss: 1.1214901957531918
Validation loss: 2.3283581426672564

Epoch: 6| Step: 6
Training loss: 1.000469157314024
Validation loss: 2.3900220575635007

Epoch: 6| Step: 7
Training loss: 0.9963412407480127
Validation loss: 2.253400124931718

Epoch: 6| Step: 8
Training loss: 1.87991229938319
Validation loss: 2.2778533605698827

Epoch: 6| Step: 9
Training loss: 0.8843694140793665
Validation loss: 2.289889721953634

Epoch: 6| Step: 10
Training loss: 1.0681817780610894
Validation loss: 2.322585072065963

Epoch: 6| Step: 11
Training loss: 1.204000080469832
Validation loss: 2.2426081985877326

Epoch: 6| Step: 12
Training loss: 1.3918024286228396
Validation loss: 2.297349193456093

Epoch: 6| Step: 13
Training loss: 0.6885513589689504
Validation loss: 2.355295277908396

Epoch: 427| Step: 0
Training loss: 1.0344559513926652
Validation loss: 2.2807525438508405

Epoch: 6| Step: 1
Training loss: 0.9582102150543943
Validation loss: 2.3350967330203183

Epoch: 6| Step: 2
Training loss: 1.259766713223246
Validation loss: 2.2520811375771417

Epoch: 6| Step: 3
Training loss: 1.7804442473897784
Validation loss: 2.327801638110299

Epoch: 6| Step: 4
Training loss: 1.1383998539386369
Validation loss: 2.321708774232358

Epoch: 6| Step: 5
Training loss: 0.8886859263891695
Validation loss: 2.3004151447587686

Epoch: 6| Step: 6
Training loss: 1.2583961791119345
Validation loss: 2.242283249129398

Epoch: 6| Step: 7
Training loss: 1.1174683651297403
Validation loss: 2.3402607990006548

Epoch: 6| Step: 8
Training loss: 0.9079655490359954
Validation loss: 2.2900356049999906

Epoch: 6| Step: 9
Training loss: 0.7388532330180695
Validation loss: 2.257925214770255

Epoch: 6| Step: 10
Training loss: 1.1036982832442939
Validation loss: 2.276565600335724

Epoch: 6| Step: 11
Training loss: 0.4608638025625003
Validation loss: 2.2973704860834467

Epoch: 6| Step: 12
Training loss: 0.6681127560299216
Validation loss: 2.2851564440829257

Epoch: 6| Step: 13
Training loss: 1.0844076344089395
Validation loss: 2.2267919980913895

Epoch: 428| Step: 0
Training loss: 0.9619717808171249
Validation loss: 2.231020831573009

Epoch: 6| Step: 1
Training loss: 1.0585927365006103
Validation loss: 2.2205324790595284

Epoch: 6| Step: 2
Training loss: 1.0797334365899165
Validation loss: 2.2555687876876855

Epoch: 6| Step: 3
Training loss: 1.3098620289661687
Validation loss: 2.329903227894781

Epoch: 6| Step: 4
Training loss: 0.5775610260694372
Validation loss: 2.2812624807517867

Epoch: 6| Step: 5
Training loss: 0.9038439413502487
Validation loss: 2.352965653399704

Epoch: 6| Step: 6
Training loss: 0.9786720074775115
Validation loss: 2.294343154678224

Epoch: 6| Step: 7
Training loss: 1.3332549707909107
Validation loss: 2.3452332045502864

Epoch: 6| Step: 8
Training loss: 0.8661563344300902
Validation loss: 2.306561577413843

Epoch: 6| Step: 9
Training loss: 1.0487408308644541
Validation loss: 2.319372176694106

Epoch: 6| Step: 10
Training loss: 1.2103236950061833
Validation loss: 2.2497221047029488

Epoch: 6| Step: 11
Training loss: 0.9118934392077919
Validation loss: 2.3738941506643196

Epoch: 6| Step: 12
Training loss: 1.8620972140222982
Validation loss: 2.3148971611425306

Epoch: 6| Step: 13
Training loss: 1.3880883129481179
Validation loss: 2.299346480366058

Epoch: 429| Step: 0
Training loss: 0.7965110995087419
Validation loss: 2.3258774066290417

Epoch: 6| Step: 1
Training loss: 0.8927280625634001
Validation loss: 2.3139519882017288

Epoch: 6| Step: 2
Training loss: 0.7731712730825826
Validation loss: 2.2849264610805267

Epoch: 6| Step: 3
Training loss: 1.235928632123266
Validation loss: 2.2549811148838934

Epoch: 6| Step: 4
Training loss: 0.7768526682632387
Validation loss: 2.265051045204674

Epoch: 6| Step: 5
Training loss: 1.0621062839543047
Validation loss: 2.233377292572652

Epoch: 6| Step: 6
Training loss: 1.056092520265954
Validation loss: 2.2574849263487007

Epoch: 6| Step: 7
Training loss: 0.8802500306735891
Validation loss: 2.2193967600743467

Epoch: 6| Step: 8
Training loss: 1.2932087655314022
Validation loss: 2.263646270973237

Epoch: 6| Step: 9
Training loss: 1.1108393071770681
Validation loss: 2.2196847395877373

Epoch: 6| Step: 10
Training loss: 1.7618584757202853
Validation loss: 2.323138341521765

Epoch: 6| Step: 11
Training loss: 1.0565864140112404
Validation loss: 2.269771064613939

Epoch: 6| Step: 12
Training loss: 1.1998986916693324
Validation loss: 2.2433510827815026

Epoch: 6| Step: 13
Training loss: 1.0042358332407026
Validation loss: 2.3023024520489184

Epoch: 430| Step: 0
Training loss: 0.9145473270381578
Validation loss: 2.299156790048766

Epoch: 6| Step: 1
Training loss: 1.2200265214726354
Validation loss: 2.307264360387431

Epoch: 6| Step: 2
Training loss: 1.1804200986055322
Validation loss: 2.2652254515388455

Epoch: 6| Step: 3
Training loss: 0.7525532891171016
Validation loss: 2.2712290788650304

Epoch: 6| Step: 4
Training loss: 0.7123282945098003
Validation loss: 2.2873915732396184

Epoch: 6| Step: 5
Training loss: 1.1738220824024224
Validation loss: 2.2520472277935495

Epoch: 6| Step: 6
Training loss: 1.025141571316594
Validation loss: 2.2805992422643833

Epoch: 6| Step: 7
Training loss: 1.9099667695035718
Validation loss: 2.2948750672184706

Epoch: 6| Step: 8
Training loss: 0.6855975183979511
Validation loss: 2.289202390917534

Epoch: 6| Step: 9
Training loss: 1.1721821700289963
Validation loss: 2.1968588088058625

Epoch: 6| Step: 10
Training loss: 0.7670191313982385
Validation loss: 2.241547230035907

Epoch: 6| Step: 11
Training loss: 0.7909014584134177
Validation loss: 2.2118623739026013

Epoch: 6| Step: 12
Training loss: 1.313929006937672
Validation loss: 2.2843513282059

Epoch: 6| Step: 13
Training loss: 0.8733569795620201
Validation loss: 2.262665963565782

Epoch: 431| Step: 0
Training loss: 1.1277091995669104
Validation loss: 2.2420395115599336

Epoch: 6| Step: 1
Training loss: 1.1123049018464455
Validation loss: 2.253624527297454

Epoch: 6| Step: 2
Training loss: 0.9901999744105543
Validation loss: 2.3453496810301697

Epoch: 6| Step: 3
Training loss: 1.1772409800509789
Validation loss: 2.2955781597376568

Epoch: 6| Step: 4
Training loss: 1.7767439616186445
Validation loss: 2.27557565576776

Epoch: 6| Step: 5
Training loss: 0.9942672139270595
Validation loss: 2.3012046926414564

Epoch: 6| Step: 6
Training loss: 1.237598893038471
Validation loss: 2.328876451994896

Epoch: 6| Step: 7
Training loss: 1.258493985200739
Validation loss: 2.2836695218869485

Epoch: 6| Step: 8
Training loss: 1.1836487407940128
Validation loss: 2.291994334499419

Epoch: 6| Step: 9
Training loss: 0.891515253408281
Validation loss: 2.2630373289348045

Epoch: 6| Step: 10
Training loss: 0.7794848146140094
Validation loss: 2.252483790392368

Epoch: 6| Step: 11
Training loss: 1.046374756588473
Validation loss: 2.2858743315378405

Epoch: 6| Step: 12
Training loss: 0.6414256326439387
Validation loss: 2.2971372456753403

Epoch: 6| Step: 13
Training loss: 0.5818517523361296
Validation loss: 2.334487114121752

Epoch: 432| Step: 0
Training loss: 1.2376559149654143
Validation loss: 2.3028134025567386

Epoch: 6| Step: 1
Training loss: 0.675132440007248
Validation loss: 2.2808076455204516

Epoch: 6| Step: 2
Training loss: 0.9323689874449302
Validation loss: 2.254037550072977

Epoch: 6| Step: 3
Training loss: 0.7296061599126329
Validation loss: 2.221491167629153

Epoch: 6| Step: 4
Training loss: 1.0387120050121614
Validation loss: 2.3008141980739656

Epoch: 6| Step: 5
Training loss: 0.8207712253239408
Validation loss: 2.288286964382677

Epoch: 6| Step: 6
Training loss: 0.9038138036510767
Validation loss: 2.2615124795791686

Epoch: 6| Step: 7
Training loss: 1.0195298468919942
Validation loss: 2.3000029699869047

Epoch: 6| Step: 8
Training loss: 0.8081582043546214
Validation loss: 2.2743946988446835

Epoch: 6| Step: 9
Training loss: 1.2800172597496324
Validation loss: 2.2888155685746874

Epoch: 6| Step: 10
Training loss: 0.9520371905162948
Validation loss: 2.262523481534634

Epoch: 6| Step: 11
Training loss: 1.9366451346381712
Validation loss: 2.294090234742214

Epoch: 6| Step: 12
Training loss: 1.1400650949464823
Validation loss: 2.2493967155590417

Epoch: 6| Step: 13
Training loss: 0.9488885878312554
Validation loss: 2.3057392749497025

Epoch: 433| Step: 0
Training loss: 0.9410378776126631
Validation loss: 2.2898468585514946

Epoch: 6| Step: 1
Training loss: 1.0394718826476566
Validation loss: 2.3327798721687563

Epoch: 6| Step: 2
Training loss: 1.2700446396589293
Validation loss: 2.2684808968162704

Epoch: 6| Step: 3
Training loss: 0.9191578083239764
Validation loss: 2.2118686228668794

Epoch: 6| Step: 4
Training loss: 0.9341255492917425
Validation loss: 2.215900805584741

Epoch: 6| Step: 5
Training loss: 1.1657458940663143
Validation loss: 2.2975609492922877

Epoch: 6| Step: 6
Training loss: 1.8715894197855072
Validation loss: 2.319343432204395

Epoch: 6| Step: 7
Training loss: 0.47960367868299575
Validation loss: 2.311746018184132

Epoch: 6| Step: 8
Training loss: 0.790532923225755
Validation loss: 2.2385905792484806

Epoch: 6| Step: 9
Training loss: 1.1230942160538202
Validation loss: 2.309383506203631

Epoch: 6| Step: 10
Training loss: 0.9434444791896424
Validation loss: 2.2442026440228684

Epoch: 6| Step: 11
Training loss: 1.1112385531030076
Validation loss: 2.1246345080235742

Epoch: 6| Step: 12
Training loss: 0.9646153971298005
Validation loss: 2.301347510174186

Epoch: 6| Step: 13
Training loss: 1.1277810267123407
Validation loss: 2.269984810892953

Epoch: 434| Step: 0
Training loss: 1.8123968686984562
Validation loss: 2.3445118957136843

Epoch: 6| Step: 1
Training loss: 0.8095960072303969
Validation loss: 2.333665580944021

Epoch: 6| Step: 2
Training loss: 0.8246006013303198
Validation loss: 2.3161573763474763

Epoch: 6| Step: 3
Training loss: 0.8258892324360726
Validation loss: 2.3426725901404732

Epoch: 6| Step: 4
Training loss: 1.451360472056695
Validation loss: 2.340202592592387

Epoch: 6| Step: 5
Training loss: 1.108540395645037
Validation loss: 2.2637741794947024

Epoch: 6| Step: 6
Training loss: 1.1195132715308322
Validation loss: 2.2347763140565453

Epoch: 6| Step: 7
Training loss: 0.775298144304861
Validation loss: 2.3492805382392072

Epoch: 6| Step: 8
Training loss: 1.1769228237846106
Validation loss: 2.281489625584379

Epoch: 6| Step: 9
Training loss: 0.7607415606945428
Validation loss: 2.275521159706767

Epoch: 6| Step: 10
Training loss: 1.0838616928922034
Validation loss: 2.3436364007580535

Epoch: 6| Step: 11
Training loss: 1.1625768410502746
Validation loss: 2.281689193506998

Epoch: 6| Step: 12
Training loss: 0.9505101590885379
Validation loss: 2.249724750705334

Epoch: 6| Step: 13
Training loss: 1.1776226237404377
Validation loss: 2.3322065712136033

Epoch: 435| Step: 0
Training loss: 1.2166613752868414
Validation loss: 2.3148364320335837

Epoch: 6| Step: 1
Training loss: 0.6431138608392296
Validation loss: 2.307544440425905

Epoch: 6| Step: 2
Training loss: 1.2990109881405452
Validation loss: 2.2904596787792513

Epoch: 6| Step: 3
Training loss: 0.93505859375
Validation loss: 2.260338213459698

Epoch: 6| Step: 4
Training loss: 1.1291149962780347
Validation loss: 2.2409227407230934

Epoch: 6| Step: 5
Training loss: 1.026346164709472
Validation loss: 2.3178345252637857

Epoch: 6| Step: 6
Training loss: 0.9240856174728928
Validation loss: 2.2490022570933585

Epoch: 6| Step: 7
Training loss: 0.916218163846642
Validation loss: 2.3247645333526026

Epoch: 6| Step: 8
Training loss: 1.3065066874785867
Validation loss: 2.2778604999359047

Epoch: 6| Step: 9
Training loss: 0.779561392269603
Validation loss: 2.280685512294662

Epoch: 6| Step: 10
Training loss: 1.8248255371940845
Validation loss: 2.215947485456158

Epoch: 6| Step: 11
Training loss: 0.958395907529108
Validation loss: 2.341507482155946

Epoch: 6| Step: 12
Training loss: 1.0077621683963147
Validation loss: 2.3188573935078267

Epoch: 6| Step: 13
Training loss: 1.4012643809605723
Validation loss: 2.297973887833787

Epoch: 436| Step: 0
Training loss: 0.7115861218484892
Validation loss: 2.3677272570463734

Epoch: 6| Step: 1
Training loss: 1.0988841400894587
Validation loss: 2.2141516311356506

Epoch: 6| Step: 2
Training loss: 0.9580068170229282
Validation loss: 2.2929037359204454

Epoch: 6| Step: 3
Training loss: 1.1813043289204714
Validation loss: 2.2274618678726443

Epoch: 6| Step: 4
Training loss: 1.1587102336294341
Validation loss: 2.3313762335572688

Epoch: 6| Step: 5
Training loss: 0.5061171475095959
Validation loss: 2.192283968895858

Epoch: 6| Step: 6
Training loss: 1.075562791105984
Validation loss: 2.2205411223279543

Epoch: 6| Step: 7
Training loss: 0.6817701593740079
Validation loss: 2.300183454119431

Epoch: 6| Step: 8
Training loss: 1.320168030187706
Validation loss: 2.2989561033965478

Epoch: 6| Step: 9
Training loss: 0.7833520838001653
Validation loss: 2.2797552941357644

Epoch: 6| Step: 10
Training loss: 0.8673074312874969
Validation loss: 2.258389247962966

Epoch: 6| Step: 11
Training loss: 0.7057540696783827
Validation loss: 2.2419869583805996

Epoch: 6| Step: 12
Training loss: 2.1381007995395587
Validation loss: 2.2336244866586132

Epoch: 6| Step: 13
Training loss: 0.9209795660243464
Validation loss: 2.314787914935632

Epoch: 437| Step: 0
Training loss: 1.0282117418609695
Validation loss: 2.257334316794196

Epoch: 6| Step: 1
Training loss: 1.2904324274739858
Validation loss: 2.287215756843031

Epoch: 6| Step: 2
Training loss: 1.3186101830293964
Validation loss: 2.289274154465293

Epoch: 6| Step: 3
Training loss: 1.2660964746974348
Validation loss: 2.273584255461369

Epoch: 6| Step: 4
Training loss: 0.9654830482610723
Validation loss: 2.2618590912536294

Epoch: 6| Step: 5
Training loss: 0.6886266233709329
Validation loss: 2.2583695491041795

Epoch: 6| Step: 6
Training loss: 1.8435379811599018
Validation loss: 2.306347677047262

Epoch: 6| Step: 7
Training loss: 0.7170095517999997
Validation loss: 2.2524701759272654

Epoch: 6| Step: 8
Training loss: 0.6951731853004185
Validation loss: 2.275732391701367

Epoch: 6| Step: 9
Training loss: 1.0522509652221923
Validation loss: 2.2853170863645786

Epoch: 6| Step: 10
Training loss: 0.7448109088537236
Validation loss: 2.306646108727167

Epoch: 6| Step: 11
Training loss: 0.6364998470405101
Validation loss: 2.2507072440123213

Epoch: 6| Step: 12
Training loss: 1.2190426206202438
Validation loss: 2.3204504962057606

Epoch: 6| Step: 13
Training loss: 0.756669155325417
Validation loss: 2.2872930823046365

Epoch: 438| Step: 0
Training loss: 0.9143384207281399
Validation loss: 2.291947243780337

Epoch: 6| Step: 1
Training loss: 1.2021610312030735
Validation loss: 2.317328376960889

Epoch: 6| Step: 2
Training loss: 1.827523026432196
Validation loss: 2.2605080376033033

Epoch: 6| Step: 3
Training loss: 0.8416634650846215
Validation loss: 2.255560538354808

Epoch: 6| Step: 4
Training loss: 0.9840797102517409
Validation loss: 2.299092967338554

Epoch: 6| Step: 5
Training loss: 0.8772162231808994
Validation loss: 2.33556103022832

Epoch: 6| Step: 6
Training loss: 0.9982492499268674
Validation loss: 2.253286603561513

Epoch: 6| Step: 7
Training loss: 0.8302657330500349
Validation loss: 2.238510706785894

Epoch: 6| Step: 8
Training loss: 1.1679902856174589
Validation loss: 2.301206473995285

Epoch: 6| Step: 9
Training loss: 1.1167798665777295
Validation loss: 2.266160803023914

Epoch: 6| Step: 10
Training loss: 0.7103299070240139
Validation loss: 2.2373582684740025

Epoch: 6| Step: 11
Training loss: 0.8114749972028452
Validation loss: 2.2746584582596463

Epoch: 6| Step: 12
Training loss: 1.1506217374656957
Validation loss: 2.2879018131545403

Epoch: 6| Step: 13
Training loss: 0.957201354810455
Validation loss: 2.313049055002968

Epoch: 439| Step: 0
Training loss: 0.8941676637786776
Validation loss: 2.3778387848729783

Epoch: 6| Step: 1
Training loss: 1.1409727637661864
Validation loss: 2.364392410607203

Epoch: 6| Step: 2
Training loss: 1.4165389994521838
Validation loss: 2.3203721466745257

Epoch: 6| Step: 3
Training loss: 1.2249328575418061
Validation loss: 2.3352557545704213

Epoch: 6| Step: 4
Training loss: 0.7158700215356553
Validation loss: 2.2741700192443535

Epoch: 6| Step: 5
Training loss: 1.108865110320341
Validation loss: 2.277976869516386

Epoch: 6| Step: 6
Training loss: 0.8674269337074132
Validation loss: 2.3215660669093996

Epoch: 6| Step: 7
Training loss: 1.0157387302983722
Validation loss: 2.3381153237587546

Epoch: 6| Step: 8
Training loss: 1.8009593155674966
Validation loss: 2.2858429620082785

Epoch: 6| Step: 9
Training loss: 0.7915930253629021
Validation loss: 2.3365539523168954

Epoch: 6| Step: 10
Training loss: 1.0150613247615798
Validation loss: 2.259287040454169

Epoch: 6| Step: 11
Training loss: 1.0667439020526568
Validation loss: 2.245574527058859

Epoch: 6| Step: 12
Training loss: 0.9239628957630751
Validation loss: 2.274162000842988

Epoch: 6| Step: 13
Training loss: 0.8054008655080225
Validation loss: 2.3125638279508003

Epoch: 440| Step: 0
Training loss: 0.7648729796079786
Validation loss: 2.293461722119189

Epoch: 6| Step: 1
Training loss: 1.0153026362650632
Validation loss: 2.269075570424777

Epoch: 6| Step: 2
Training loss: 0.9776902058127489
Validation loss: 2.283958531922268

Epoch: 6| Step: 3
Training loss: 2.04260227278827
Validation loss: 2.2425722907725656

Epoch: 6| Step: 4
Training loss: 1.1922037925956823
Validation loss: 2.300243731973866

Epoch: 6| Step: 5
Training loss: 0.8176832660955273
Validation loss: 2.211100967482417

Epoch: 6| Step: 6
Training loss: 0.9332804134102659
Validation loss: 2.324392845063403

Epoch: 6| Step: 7
Training loss: 0.9659368215241976
Validation loss: 2.2680636392251516

Epoch: 6| Step: 8
Training loss: 1.2585236807509768
Validation loss: 2.2251482096024193

Epoch: 6| Step: 9
Training loss: 1.0502862154195074
Validation loss: 2.2279123782159145

Epoch: 6| Step: 10
Training loss: 0.8319204193945641
Validation loss: 2.298700100444368

Epoch: 6| Step: 11
Training loss: 0.8526729028608941
Validation loss: 2.225908251157352

Epoch: 6| Step: 12
Training loss: 1.1367943073343592
Validation loss: 2.1757740248846638

Epoch: 6| Step: 13
Training loss: 0.7457196161395956
Validation loss: 2.2539436270551554

Epoch: 441| Step: 0
Training loss: 0.8583951045157137
Validation loss: 2.3156204377918344

Epoch: 6| Step: 1
Training loss: 0.8170092970086819
Validation loss: 2.2618587846629836

Epoch: 6| Step: 2
Training loss: 1.8361464361247986
Validation loss: 2.298789785406269

Epoch: 6| Step: 3
Training loss: 0.8309858318273265
Validation loss: 2.2187243582459795

Epoch: 6| Step: 4
Training loss: 0.9316936613777236
Validation loss: 2.2245228856720045

Epoch: 6| Step: 5
Training loss: 1.1312723147051336
Validation loss: 2.2541467084776925

Epoch: 6| Step: 6
Training loss: 1.307654473568711
Validation loss: 2.261864457999973

Epoch: 6| Step: 7
Training loss: 0.9941998597130594
Validation loss: 2.243001691639107

Epoch: 6| Step: 8
Training loss: 1.0357722914477077
Validation loss: 2.247990032893739

Epoch: 6| Step: 9
Training loss: 1.101419534266238
Validation loss: 2.2962249579363587

Epoch: 6| Step: 10
Training loss: 1.0336566355195054
Validation loss: 2.243756757877934

Epoch: 6| Step: 11
Training loss: 0.8152868454136651
Validation loss: 2.3297700874926033

Epoch: 6| Step: 12
Training loss: 0.9318928567056888
Validation loss: 2.2768607781925567

Epoch: 6| Step: 13
Training loss: 0.7037253042464954
Validation loss: 2.2650936466843543

Epoch: 442| Step: 0
Training loss: 1.0006263678575325
Validation loss: 2.2878767660251245

Epoch: 6| Step: 1
Training loss: 0.9801608206205922
Validation loss: 2.3332507218475373

Epoch: 6| Step: 2
Training loss: 1.3753391194470712
Validation loss: 2.2284551061179845

Epoch: 6| Step: 3
Training loss: 0.5117626608142911
Validation loss: 2.3006357959406722

Epoch: 6| Step: 4
Training loss: 0.9794385140375844
Validation loss: 2.2865919156874863

Epoch: 6| Step: 5
Training loss: 0.945533222250264
Validation loss: 2.403863700316752

Epoch: 6| Step: 6
Training loss: 0.8481541942162377
Validation loss: 2.2650287843678165

Epoch: 6| Step: 7
Training loss: 1.0557748346499374
Validation loss: 2.2394526560596826

Epoch: 6| Step: 8
Training loss: 0.6617046908671945
Validation loss: 2.2788316059004647

Epoch: 6| Step: 9
Training loss: 1.0072520272240935
Validation loss: 2.3019097275300417

Epoch: 6| Step: 10
Training loss: 0.8775535855682379
Validation loss: 2.355442669050866

Epoch: 6| Step: 11
Training loss: 1.8091604444882043
Validation loss: 2.236766258159487

Epoch: 6| Step: 12
Training loss: 0.9746972237481393
Validation loss: 2.275569888746563

Epoch: 6| Step: 13
Training loss: 0.7376678986893179
Validation loss: 2.2529199167787155

Epoch: 443| Step: 0
Training loss: 1.1038756196887791
Validation loss: 2.2805899826841367

Epoch: 6| Step: 1
Training loss: 0.8946810267964067
Validation loss: 2.288044875604767

Epoch: 6| Step: 2
Training loss: 1.248540741777812
Validation loss: 2.287463198309228

Epoch: 6| Step: 3
Training loss: 1.0349951852695687
Validation loss: 2.236096131798938

Epoch: 6| Step: 4
Training loss: 1.0688043814760617
Validation loss: 2.280637292733345

Epoch: 6| Step: 5
Training loss: 0.6639669012931882
Validation loss: 2.2303641459807166

Epoch: 6| Step: 6
Training loss: 0.8925251016372662
Validation loss: 2.284685167771685

Epoch: 6| Step: 7
Training loss: 0.9902222762412695
Validation loss: 2.298654501607604

Epoch: 6| Step: 8
Training loss: 1.900926880876592
Validation loss: 2.2344907992642082

Epoch: 6| Step: 9
Training loss: 0.7470611372240891
Validation loss: 2.329279141466931

Epoch: 6| Step: 10
Training loss: 0.5989617444369721
Validation loss: 2.2884802154171395

Epoch: 6| Step: 11
Training loss: 0.9766921605817775
Validation loss: 2.221062638863383

Epoch: 6| Step: 12
Training loss: 1.0576463802743323
Validation loss: 2.3020131190408253

Epoch: 6| Step: 13
Training loss: 0.9534880775182358
Validation loss: 2.2844802292630524

Epoch: 444| Step: 0
Training loss: 0.7668146505447715
Validation loss: 2.2817887206583007

Epoch: 6| Step: 1
Training loss: 1.0615754312171795
Validation loss: 2.282724448475513

Epoch: 6| Step: 2
Training loss: 1.0960082039108356
Validation loss: 2.2303895004707606

Epoch: 6| Step: 3
Training loss: 1.1569044992899349
Validation loss: 2.2896954083793193

Epoch: 6| Step: 4
Training loss: 1.4523635017484215
Validation loss: 2.263870757281773

Epoch: 6| Step: 5
Training loss: 0.941029960171594
Validation loss: 2.256970587222192

Epoch: 6| Step: 6
Training loss: 0.6017016955751985
Validation loss: 2.274540135827407

Epoch: 6| Step: 7
Training loss: 1.026539767171835
Validation loss: 2.2890328272335054

Epoch: 6| Step: 8
Training loss: 1.0620695251868244
Validation loss: 2.2628031287652455

Epoch: 6| Step: 9
Training loss: 0.7807398465583768
Validation loss: 2.225924406385978

Epoch: 6| Step: 10
Training loss: 0.5249620980250567
Validation loss: 2.2059543466250475

Epoch: 6| Step: 11
Training loss: 0.6882894275192485
Validation loss: 2.224614348754376

Epoch: 6| Step: 12
Training loss: 1.8873962070651322
Validation loss: 2.303710497931766

Epoch: 6| Step: 13
Training loss: 0.6237171597521901
Validation loss: 2.3127479763932772

Epoch: 445| Step: 0
Training loss: 0.9335228162816224
Validation loss: 2.257229582383863

Epoch: 6| Step: 1
Training loss: 1.4840246489809255
Validation loss: 2.25267998342954

Epoch: 6| Step: 2
Training loss: 0.726846003851973
Validation loss: 2.1927341242102507

Epoch: 6| Step: 3
Training loss: 0.8501573921789073
Validation loss: 2.282925475828796

Epoch: 6| Step: 4
Training loss: 0.7599138443825371
Validation loss: 2.2753546204795407

Epoch: 6| Step: 5
Training loss: 1.8168791124673287
Validation loss: 2.23437714614266

Epoch: 6| Step: 6
Training loss: 1.0848504532974084
Validation loss: 2.2830153605024632

Epoch: 6| Step: 7
Training loss: 0.9248291785794833
Validation loss: 2.251994601361889

Epoch: 6| Step: 8
Training loss: 1.1452354374001121
Validation loss: 2.2293302134644715

Epoch: 6| Step: 9
Training loss: 0.9964738008602805
Validation loss: 2.2664843950903037

Epoch: 6| Step: 10
Training loss: 0.7777115991419775
Validation loss: 2.282238121297785

Epoch: 6| Step: 11
Training loss: 0.9708006596831386
Validation loss: 2.309603709612666

Epoch: 6| Step: 12
Training loss: 0.7374838503992898
Validation loss: 2.2465526310017108

Epoch: 6| Step: 13
Training loss: 1.0588161333455341
Validation loss: 2.315488846582773

Epoch: 446| Step: 0
Training loss: 0.7732051153466681
Validation loss: 2.29768655031773

Epoch: 6| Step: 1
Training loss: 1.0952349799962886
Validation loss: 2.2098475523900856

Epoch: 6| Step: 2
Training loss: 1.0547183562109577
Validation loss: 2.2831872347061726

Epoch: 6| Step: 3
Training loss: 1.8367366918079382
Validation loss: 2.287109948344692

Epoch: 6| Step: 4
Training loss: 0.9702768598759008
Validation loss: 2.2118504641379695

Epoch: 6| Step: 5
Training loss: 0.8539999628603031
Validation loss: 2.233340982657593

Epoch: 6| Step: 6
Training loss: 0.9461979777902922
Validation loss: 2.2362206177735913

Epoch: 6| Step: 7
Training loss: 0.6210883278280175
Validation loss: 2.218393742916569

Epoch: 6| Step: 8
Training loss: 1.1252476101815814
Validation loss: 2.205970976288058

Epoch: 6| Step: 9
Training loss: 0.860697959073469
Validation loss: 2.284234453976163

Epoch: 6| Step: 10
Training loss: 0.7605729704515539
Validation loss: 2.281664560195479

Epoch: 6| Step: 11
Training loss: 0.5884941779588436
Validation loss: 2.3227603259551226

Epoch: 6| Step: 12
Training loss: 1.3112865015264163
Validation loss: 2.2172364406668845

Epoch: 6| Step: 13
Training loss: 0.9630526083364527
Validation loss: 2.258610219963462

Epoch: 447| Step: 0
Training loss: 0.9777308379782551
Validation loss: 2.2650702091787944

Epoch: 6| Step: 1
Training loss: 0.8195904051283771
Validation loss: 2.302281760125429

Epoch: 6| Step: 2
Training loss: 1.0686804587064578
Validation loss: 2.2139703807158093

Epoch: 6| Step: 3
Training loss: 1.0331365495371965
Validation loss: 2.294564282500686

Epoch: 6| Step: 4
Training loss: 0.6289719020150255
Validation loss: 2.284650824582468

Epoch: 6| Step: 5
Training loss: 0.5942776995258593
Validation loss: 2.2026836282162567

Epoch: 6| Step: 6
Training loss: 1.1597200851776068
Validation loss: 2.2674708817504743

Epoch: 6| Step: 7
Training loss: 1.0705479272468237
Validation loss: 2.267443595280835

Epoch: 6| Step: 8
Training loss: 0.9521139128856926
Validation loss: 2.2668008086319342

Epoch: 6| Step: 9
Training loss: 0.7768413511248644
Validation loss: 2.207744910828744

Epoch: 6| Step: 10
Training loss: 1.8313061025312543
Validation loss: 2.3077968595354696

Epoch: 6| Step: 11
Training loss: 0.9667459185494148
Validation loss: 2.2663032362380777

Epoch: 6| Step: 12
Training loss: 0.990689897066128
Validation loss: 2.232242203958331

Epoch: 6| Step: 13
Training loss: 1.203898391846515
Validation loss: 2.2244348636264597

Epoch: 448| Step: 0
Training loss: 1.1861498334779281
Validation loss: 2.261694663161797

Epoch: 6| Step: 1
Training loss: 0.8925272386599067
Validation loss: 2.2730430382318327

Epoch: 6| Step: 2
Training loss: 0.8161675501216162
Validation loss: 2.1887560799428867

Epoch: 6| Step: 3
Training loss: 1.2091163476945748
Validation loss: 2.3009475989667303

Epoch: 6| Step: 4
Training loss: 0.8384256144394571
Validation loss: 2.2781470572012346

Epoch: 6| Step: 5
Training loss: 0.8975650033814292
Validation loss: 2.2043473561748534

Epoch: 6| Step: 6
Training loss: 0.7709457641950316
Validation loss: 2.283376639991175

Epoch: 6| Step: 7
Training loss: 1.778256494255762
Validation loss: 2.2776398659103982

Epoch: 6| Step: 8
Training loss: 1.0412169184930684
Validation loss: 2.2869980739112243

Epoch: 6| Step: 9
Training loss: 0.7853614197448957
Validation loss: 2.274083873777961

Epoch: 6| Step: 10
Training loss: 1.080828442284295
Validation loss: 2.331475692557535

Epoch: 6| Step: 11
Training loss: 1.187201311794749
Validation loss: 2.2146435747870727

Epoch: 6| Step: 12
Training loss: 0.9552366285109541
Validation loss: 2.220355266456981

Epoch: 6| Step: 13
Training loss: 0.8642489158043145
Validation loss: 2.2432857986488863

Epoch: 449| Step: 0
Training loss: 0.850429866588024
Validation loss: 2.280666427825285

Epoch: 6| Step: 1
Training loss: 0.8733389619713834
Validation loss: 2.307497728709492

Epoch: 6| Step: 2
Training loss: 1.1766967251065956
Validation loss: 2.29573952335605

Epoch: 6| Step: 3
Training loss: 0.6978387480743529
Validation loss: 2.302291598625142

Epoch: 6| Step: 4
Training loss: 0.9767642003616919
Validation loss: 2.278452405369686

Epoch: 6| Step: 5
Training loss: 1.01072703179685
Validation loss: 2.3959928308784697

Epoch: 6| Step: 6
Training loss: 0.8588658992289054
Validation loss: 2.2374551534956266

Epoch: 6| Step: 7
Training loss: 1.3273322488287636
Validation loss: 2.3239363623838383

Epoch: 6| Step: 8
Training loss: 0.7479185786174113
Validation loss: 2.2642197881630404

Epoch: 6| Step: 9
Training loss: 0.715499577088301
Validation loss: 2.24878026289444

Epoch: 6| Step: 10
Training loss: 0.834431941343263
Validation loss: 2.2983548864098413

Epoch: 6| Step: 11
Training loss: 1.297601059963532
Validation loss: 2.2589293633284844

Epoch: 6| Step: 12
Training loss: 1.2061585169280482
Validation loss: 2.2389166268625944

Epoch: 6| Step: 13
Training loss: 2.3691126482916363
Validation loss: 2.2336496337012215

Epoch: 450| Step: 0
Training loss: 0.785379748062773
Validation loss: 2.263434184022198

Epoch: 6| Step: 1
Training loss: 1.1071403455046542
Validation loss: 2.2859698623684426

Epoch: 6| Step: 2
Training loss: 0.7642252446446365
Validation loss: 2.2898848104928673

Epoch: 6| Step: 3
Training loss: 0.8484141393996735
Validation loss: 2.2902113319715003

Epoch: 6| Step: 4
Training loss: 0.842370247343632
Validation loss: 2.2202497165844077

Epoch: 6| Step: 5
Training loss: 0.8582397592024141
Validation loss: 2.230896957243245

Epoch: 6| Step: 6
Training loss: 0.9238551258875456
Validation loss: 2.266642468831194

Epoch: 6| Step: 7
Training loss: 1.1300222826760906
Validation loss: 2.291654672526037

Epoch: 6| Step: 8
Training loss: 1.8422560377370163
Validation loss: 2.242392312062244

Epoch: 6| Step: 9
Training loss: 1.5162424619130364
Validation loss: 2.2662441438786223

Epoch: 6| Step: 10
Training loss: 1.037922111495928
Validation loss: 2.294233300722163

Epoch: 6| Step: 11
Training loss: 0.8438176022044693
Validation loss: 2.2956033540073952

Epoch: 6| Step: 12
Training loss: 0.6577216631586081
Validation loss: 2.30107243357267

Epoch: 6| Step: 13
Training loss: 1.0409620890351439
Validation loss: 2.260299446700002

Epoch: 451| Step: 0
Training loss: 1.9446253041517698
Validation loss: 2.277988610246665

Epoch: 6| Step: 1
Training loss: 0.6755727986681775
Validation loss: 2.221834140093411

Epoch: 6| Step: 2
Training loss: 1.0407358906632773
Validation loss: 2.3389279722287997

Epoch: 6| Step: 3
Training loss: 1.1780613181309487
Validation loss: 2.2182318414440556

Epoch: 6| Step: 4
Training loss: 1.1510391350397546
Validation loss: 2.2817111165260986

Epoch: 6| Step: 5
Training loss: 0.8764907535559235
Validation loss: 2.2867915994268277

Epoch: 6| Step: 6
Training loss: 0.9597551468683602
Validation loss: 2.2643888649385486

Epoch: 6| Step: 7
Training loss: 0.7207646950987793
Validation loss: 2.2457758042419003

Epoch: 6| Step: 8
Training loss: 0.9282168127816133
Validation loss: 2.2079591076073575

Epoch: 6| Step: 9
Training loss: 0.8855251395406478
Validation loss: 2.2512028605380623

Epoch: 6| Step: 10
Training loss: 0.7044670859852228
Validation loss: 2.247464203775148

Epoch: 6| Step: 11
Training loss: 0.7425604836717735
Validation loss: 2.2910347273257816

Epoch: 6| Step: 12
Training loss: 0.7959471143569461
Validation loss: 2.347575740919206

Epoch: 6| Step: 13
Training loss: 0.9202265143906843
Validation loss: 2.2747523267076644

Epoch: 452| Step: 0
Training loss: 1.3378133709732496
Validation loss: 2.228445043444877

Epoch: 6| Step: 1
Training loss: 1.0406927642295076
Validation loss: 2.2571233109200093

Epoch: 6| Step: 2
Training loss: 0.7435672984395257
Validation loss: 2.2590695181301084

Epoch: 6| Step: 3
Training loss: 0.9135996306823645
Validation loss: 2.2204418892555164

Epoch: 6| Step: 4
Training loss: 0.8862240121149099
Validation loss: 2.303579448329455

Epoch: 6| Step: 5
Training loss: 0.4477468342362974
Validation loss: 2.2114330724696885

Epoch: 6| Step: 6
Training loss: 0.9280272975063784
Validation loss: 2.2438110039803

Epoch: 6| Step: 7
Training loss: 1.145195673751787
Validation loss: 2.255831316211567

Epoch: 6| Step: 8
Training loss: 1.1206620079520853
Validation loss: 2.214633921076688

Epoch: 6| Step: 9
Training loss: 1.1174416419713693
Validation loss: 2.3190732068579707

Epoch: 6| Step: 10
Training loss: 0.7714139882101957
Validation loss: 2.2517645842802247

Epoch: 6| Step: 11
Training loss: 1.8971340901185378
Validation loss: 2.2562023799678257

Epoch: 6| Step: 12
Training loss: 1.0111795999284512
Validation loss: 2.2523431313143774

Epoch: 6| Step: 13
Training loss: 0.4294327587664872
Validation loss: 2.218328027665329

Epoch: 453| Step: 0
Training loss: 0.7896157770528579
Validation loss: 2.237743124943835

Epoch: 6| Step: 1
Training loss: 0.7609708586788878
Validation loss: 2.264914952782405

Epoch: 6| Step: 2
Training loss: 0.6210535624236151
Validation loss: 2.2301765493158388

Epoch: 6| Step: 3
Training loss: 0.8529529943092401
Validation loss: 2.2732471081453207

Epoch: 6| Step: 4
Training loss: 0.8785872495092932
Validation loss: 2.198227283119319

Epoch: 6| Step: 5
Training loss: 0.8603347274397509
Validation loss: 2.264064206788845

Epoch: 6| Step: 6
Training loss: 1.1849963246863948
Validation loss: 2.233331700760464

Epoch: 6| Step: 7
Training loss: 0.8293904406699212
Validation loss: 2.2264974524526466

Epoch: 6| Step: 8
Training loss: 1.1261659514198292
Validation loss: 2.2598886188289193

Epoch: 6| Step: 9
Training loss: 0.7750098304740336
Validation loss: 2.229435528916113

Epoch: 6| Step: 10
Training loss: 0.8704706537995878
Validation loss: 2.241094124202175

Epoch: 6| Step: 11
Training loss: 1.0776914194636757
Validation loss: 2.2855603656137937

Epoch: 6| Step: 12
Training loss: 1.8139595206222368
Validation loss: 2.2648419626393017

Epoch: 6| Step: 13
Training loss: 0.9423901493399631
Validation loss: 2.190652900260551

Epoch: 454| Step: 0
Training loss: 0.916108084040629
Validation loss: 2.3141553652718785

Epoch: 6| Step: 1
Training loss: 1.8780103042287353
Validation loss: 2.2587630890200865

Epoch: 6| Step: 2
Training loss: 0.6940196157755909
Validation loss: 2.219630035525867

Epoch: 6| Step: 3
Training loss: 0.679245728491591
Validation loss: 2.3214269735981463

Epoch: 6| Step: 4
Training loss: 0.5577127672042222
Validation loss: 2.2978761282736713

Epoch: 6| Step: 5
Training loss: 0.9073532558052928
Validation loss: 2.2398474508703523

Epoch: 6| Step: 6
Training loss: 0.6872408551870134
Validation loss: 2.2945852311587203

Epoch: 6| Step: 7
Training loss: 0.7196641995910555
Validation loss: 2.240824383348661

Epoch: 6| Step: 8
Training loss: 1.2324413654702622
Validation loss: 2.3233505435001396

Epoch: 6| Step: 9
Training loss: 0.9598212232621186
Validation loss: 2.295587957728207

Epoch: 6| Step: 10
Training loss: 1.1233499930605686
Validation loss: 2.244434307021616

Epoch: 6| Step: 11
Training loss: 1.055744573891291
Validation loss: 2.2277443351956716

Epoch: 6| Step: 12
Training loss: 1.1613544480374802
Validation loss: 2.2603665627913516

Epoch: 6| Step: 13
Training loss: 1.0177285930656421
Validation loss: 2.3194430805667574

Epoch: 455| Step: 0
Training loss: 0.6760073597750033
Validation loss: 2.2766477478522393

Epoch: 6| Step: 1
Training loss: 0.9243018969864587
Validation loss: 2.292354041757427

Epoch: 6| Step: 2
Training loss: 0.8014491203683581
Validation loss: 2.270087239698385

Epoch: 6| Step: 3
Training loss: 0.7697511929895833
Validation loss: 2.286599884334599

Epoch: 6| Step: 4
Training loss: 0.8271459153822602
Validation loss: 2.297174767482035

Epoch: 6| Step: 5
Training loss: 0.9706846116447742
Validation loss: 2.276374886177896

Epoch: 6| Step: 6
Training loss: 0.7428177817561706
Validation loss: 2.215291218393199

Epoch: 6| Step: 7
Training loss: 0.8339471741716794
Validation loss: 2.3370671224445894

Epoch: 6| Step: 8
Training loss: 0.8067756890745342
Validation loss: 2.2477403914014675

Epoch: 6| Step: 9
Training loss: 0.8630361079489416
Validation loss: 2.2304392999950022

Epoch: 6| Step: 10
Training loss: 1.7556774821709076
Validation loss: 2.3713551019942987

Epoch: 6| Step: 11
Training loss: 1.16153827386428
Validation loss: 2.290473826296388

Epoch: 6| Step: 12
Training loss: 0.9875968402748656
Validation loss: 2.234696983258899

Epoch: 6| Step: 13
Training loss: 1.1213971302373342
Validation loss: 2.2158154717265517

Epoch: 456| Step: 0
Training loss: 0.9988551440890407
Validation loss: 2.2854869288096675

Epoch: 6| Step: 1
Training loss: 1.8193552013120637
Validation loss: 2.226557685459691

Epoch: 6| Step: 2
Training loss: 0.8534106925517108
Validation loss: 2.2263232405009363

Epoch: 6| Step: 3
Training loss: 1.3602229137615902
Validation loss: 2.1994841580546294

Epoch: 6| Step: 4
Training loss: 0.5730705459168021
Validation loss: 2.2301808654855

Epoch: 6| Step: 5
Training loss: 1.0081075192169826
Validation loss: 2.182479738301806

Epoch: 6| Step: 6
Training loss: 0.8787449667557196
Validation loss: 2.2938616788669033

Epoch: 6| Step: 7
Training loss: 0.9125825361261644
Validation loss: 2.268689597686903

Epoch: 6| Step: 8
Training loss: 0.8737721684035326
Validation loss: 2.2856846711240637

Epoch: 6| Step: 9
Training loss: 1.1809397234445291
Validation loss: 2.2021135690555798

Epoch: 6| Step: 10
Training loss: 0.8929221660915193
Validation loss: 2.2799683433357876

Epoch: 6| Step: 11
Training loss: 0.6127684812478479
Validation loss: 2.2816385097634906

Epoch: 6| Step: 12
Training loss: 1.0034230772756212
Validation loss: 2.1954813333838605

Epoch: 6| Step: 13
Training loss: 1.0455745191866643
Validation loss: 2.277948109113803

Epoch: 457| Step: 0
Training loss: 1.1906227912782221
Validation loss: 2.2768520621655015

Epoch: 6| Step: 1
Training loss: 0.9558307514028312
Validation loss: 2.2581697580098155

Epoch: 6| Step: 2
Training loss: 1.1148513162806597
Validation loss: 2.266398127167238

Epoch: 6| Step: 3
Training loss: 1.13641431998885
Validation loss: 2.2980147689664894

Epoch: 6| Step: 4
Training loss: 1.4618508650804467
Validation loss: 2.348029499782362

Epoch: 6| Step: 5
Training loss: 0.8722143791099873
Validation loss: 2.291571479975848

Epoch: 6| Step: 6
Training loss: 0.8851342517513103
Validation loss: 2.2192096306340714

Epoch: 6| Step: 7
Training loss: 1.8297502515083575
Validation loss: 2.2446598486984803

Epoch: 6| Step: 8
Training loss: 0.983354251175719
Validation loss: 2.252111138405174

Epoch: 6| Step: 9
Training loss: 0.9140979075298642
Validation loss: 2.3238710844690886

Epoch: 6| Step: 10
Training loss: 0.8962765122326953
Validation loss: 2.2263829174493095

Epoch: 6| Step: 11
Training loss: 0.5953800012961897
Validation loss: 2.2108413708437613

Epoch: 6| Step: 12
Training loss: 0.9109140278587778
Validation loss: 2.2673787368715552

Epoch: 6| Step: 13
Training loss: 0.5341804685708983
Validation loss: 2.2030544131516003

Epoch: 458| Step: 0
Training loss: 1.0318087595722165
Validation loss: 2.1771567361190467

Epoch: 6| Step: 1
Training loss: 1.1410329428889476
Validation loss: 2.244195872797092

Epoch: 6| Step: 2
Training loss: 0.959664594947705
Validation loss: 2.2465720457756553

Epoch: 6| Step: 3
Training loss: 1.840804252250896
Validation loss: 2.2986204206653658

Epoch: 6| Step: 4
Training loss: 0.9326417290619146
Validation loss: 2.21663090034526

Epoch: 6| Step: 5
Training loss: 0.6491862191359956
Validation loss: 2.2679979174365785

Epoch: 6| Step: 6
Training loss: 0.9667818318747592
Validation loss: 2.2773183604762592

Epoch: 6| Step: 7
Training loss: 0.7540585062717198
Validation loss: 2.2176558231553716

Epoch: 6| Step: 8
Training loss: 0.8517904064132632
Validation loss: 2.2102024270023963

Epoch: 6| Step: 9
Training loss: 0.7824081991050806
Validation loss: 2.2686397671138874

Epoch: 6| Step: 10
Training loss: 0.846023357981994
Validation loss: 2.234442408318145

Epoch: 6| Step: 11
Training loss: 1.2276113605679608
Validation loss: 2.2583319986808124

Epoch: 6| Step: 12
Training loss: 1.0228649605439346
Validation loss: 2.1969990603548815

Epoch: 6| Step: 13
Training loss: 0.6688588107350394
Validation loss: 2.234139491774801

Epoch: 459| Step: 0
Training loss: 0.9067375252945994
Validation loss: 2.2169847076434177

Epoch: 6| Step: 1
Training loss: 1.0926907450979015
Validation loss: 2.258313732798519

Epoch: 6| Step: 2
Training loss: 0.7587603903597913
Validation loss: 2.1895027142953793

Epoch: 6| Step: 3
Training loss: 0.6061116896489722
Validation loss: 2.183549754218157

Epoch: 6| Step: 4
Training loss: 1.1102352836336198
Validation loss: 2.2955127566467177

Epoch: 6| Step: 5
Training loss: 0.7976914505472552
Validation loss: 2.3219618882113635

Epoch: 6| Step: 6
Training loss: 1.050953677186486
Validation loss: 2.288262162062968

Epoch: 6| Step: 7
Training loss: 1.1846508178022876
Validation loss: 2.3083283962263446

Epoch: 6| Step: 8
Training loss: 1.081930327959294
Validation loss: 2.2760287285163847

Epoch: 6| Step: 9
Training loss: 0.8634012061273467
Validation loss: 2.337047754654002

Epoch: 6| Step: 10
Training loss: 1.6516633492881392
Validation loss: 2.359686198794493

Epoch: 6| Step: 11
Training loss: 0.8087449968940894
Validation loss: 2.2577898651928954

Epoch: 6| Step: 12
Training loss: 0.8909677214164827
Validation loss: 2.211003653476087

Epoch: 6| Step: 13
Training loss: 0.85249536496242
Validation loss: 2.252306504540409

Epoch: 460| Step: 0
Training loss: 0.7375452318706804
Validation loss: 2.2646607725863848

Epoch: 6| Step: 1
Training loss: 0.9142312440228716
Validation loss: 2.2523358262674456

Epoch: 6| Step: 2
Training loss: 0.8111857642441688
Validation loss: 2.250144068573138

Epoch: 6| Step: 3
Training loss: 0.910081655695391
Validation loss: 2.1769778161360724

Epoch: 6| Step: 4
Training loss: 1.1962976821277476
Validation loss: 2.2811162473649276

Epoch: 6| Step: 5
Training loss: 1.2197452296347278
Validation loss: 2.2659050632230295

Epoch: 6| Step: 6
Training loss: 0.8115893175396923
Validation loss: 2.196888075318938

Epoch: 6| Step: 7
Training loss: 1.9258445744810206
Validation loss: 2.2723911150808163

Epoch: 6| Step: 8
Training loss: 0.7961424283913919
Validation loss: 2.1938198186585836

Epoch: 6| Step: 9
Training loss: 0.9477363596593459
Validation loss: 2.2610408506566393

Epoch: 6| Step: 10
Training loss: 0.8625040137156099
Validation loss: 2.2070403585010965

Epoch: 6| Step: 11
Training loss: 0.7952519511798809
Validation loss: 2.323073531161485

Epoch: 6| Step: 12
Training loss: 0.6491345714801489
Validation loss: 2.207595181361478

Epoch: 6| Step: 13
Training loss: 0.7602582966917222
Validation loss: 2.2645918227631503

Epoch: 461| Step: 0
Training loss: 1.0586278705798984
Validation loss: 2.1942660802817344

Epoch: 6| Step: 1
Training loss: 0.566588379089507
Validation loss: 2.2249783510613836

Epoch: 6| Step: 2
Training loss: 1.0450121689046854
Validation loss: 2.2113607608701407

Epoch: 6| Step: 3
Training loss: 0.8822130176449434
Validation loss: 2.3016110356457222

Epoch: 6| Step: 4
Training loss: 1.266826953701408
Validation loss: 2.2551981107664876

Epoch: 6| Step: 5
Training loss: 0.869132738399085
Validation loss: 2.3077358091612146

Epoch: 6| Step: 6
Training loss: 1.7568045205683471
Validation loss: 2.320806253059136

Epoch: 6| Step: 7
Training loss: 0.8100614633905998
Validation loss: 2.306932879265903

Epoch: 6| Step: 8
Training loss: 0.7858462362217864
Validation loss: 2.2085071718963962

Epoch: 6| Step: 9
Training loss: 0.7882756757586377
Validation loss: 2.2041057799789985

Epoch: 6| Step: 10
Training loss: 0.8575700010637898
Validation loss: 2.2861016646301136

Epoch: 6| Step: 11
Training loss: 1.1448609069396634
Validation loss: 2.2806571586821165

Epoch: 6| Step: 12
Training loss: 1.2214927133849547
Validation loss: 2.2738284957525248

Epoch: 6| Step: 13
Training loss: 0.6680833149423399
Validation loss: 2.2083343762027496

Epoch: 462| Step: 0
Training loss: 1.218131030455802
Validation loss: 2.2682654457237432

Epoch: 6| Step: 1
Training loss: 1.8873837012025896
Validation loss: 2.2584708250015697

Epoch: 6| Step: 2
Training loss: 1.132228569277725
Validation loss: 2.262398277959741

Epoch: 6| Step: 3
Training loss: 0.6106369694031559
Validation loss: 2.2930264560122464

Epoch: 6| Step: 4
Training loss: 0.8235295021734268
Validation loss: 2.246834225504055

Epoch: 6| Step: 5
Training loss: 0.8224537831223797
Validation loss: 2.23133606147698

Epoch: 6| Step: 6
Training loss: 0.748935579919029
Validation loss: 2.244039265293943

Epoch: 6| Step: 7
Training loss: 0.8408668141902991
Validation loss: 2.2593572417397456

Epoch: 6| Step: 8
Training loss: 1.1502871507309198
Validation loss: 2.202344346645944

Epoch: 6| Step: 9
Training loss: 0.9905895070357246
Validation loss: 2.2540176974559007

Epoch: 6| Step: 10
Training loss: 0.8598909736432824
Validation loss: 2.2250034978861435

Epoch: 6| Step: 11
Training loss: 0.8049489309567187
Validation loss: 2.2543065025363433

Epoch: 6| Step: 12
Training loss: 0.7441377414437241
Validation loss: 2.275668881428625

Epoch: 6| Step: 13
Training loss: 0.8540839566139699
Validation loss: 2.3254219236890195

Epoch: 463| Step: 0
Training loss: 1.0828072970266693
Validation loss: 2.2038411605757173

Epoch: 6| Step: 1
Training loss: 1.0969304845095584
Validation loss: 2.1759248141468195

Epoch: 6| Step: 2
Training loss: 0.7248459093177243
Validation loss: 2.306772318651019

Epoch: 6| Step: 3
Training loss: 0.710016009727826
Validation loss: 2.2866345177760143

Epoch: 6| Step: 4
Training loss: 0.6824372890851844
Validation loss: 2.2283918567402634

Epoch: 6| Step: 5
Training loss: 0.8494445991772392
Validation loss: 2.276888957270421

Epoch: 6| Step: 6
Training loss: 0.9029013822171689
Validation loss: 2.2874549631318

Epoch: 6| Step: 7
Training loss: 0.607234349389514
Validation loss: 2.244724533538637

Epoch: 6| Step: 8
Training loss: 0.9191098202764827
Validation loss: 2.3101583041464466

Epoch: 6| Step: 9
Training loss: 0.9485097364288902
Validation loss: 2.2543435221289716

Epoch: 6| Step: 10
Training loss: 0.6276569159620312
Validation loss: 2.1958573812910727

Epoch: 6| Step: 11
Training loss: 0.7594667842324551
Validation loss: 2.242135883869261

Epoch: 6| Step: 12
Training loss: 2.0268308251595983
Validation loss: 2.2860945975392197

Epoch: 6| Step: 13
Training loss: 1.1950209517617405
Validation loss: 2.190274886066396

Epoch: 464| Step: 0
Training loss: 1.067652048007507
Validation loss: 2.227287294544624

Epoch: 6| Step: 1
Training loss: 0.5326028316229144
Validation loss: 2.236569244000419

Epoch: 6| Step: 2
Training loss: 0.7366743412164658
Validation loss: 2.2088719396279015

Epoch: 6| Step: 3
Training loss: 1.0003220516417362
Validation loss: 2.2531966809656288

Epoch: 6| Step: 4
Training loss: 1.9966186311109504
Validation loss: 2.2209092650045776

Epoch: 6| Step: 5
Training loss: 1.0361157846444833
Validation loss: 2.2526745270886472

Epoch: 6| Step: 6
Training loss: 1.0588578461324945
Validation loss: 2.2345416982608195

Epoch: 6| Step: 7
Training loss: 0.5879743142616136
Validation loss: 2.267896944052477

Epoch: 6| Step: 8
Training loss: 0.9019074809675096
Validation loss: 2.286855246411462

Epoch: 6| Step: 9
Training loss: 0.6090871424458237
Validation loss: 2.3278082415799397

Epoch: 6| Step: 10
Training loss: 1.0789774413380109
Validation loss: 2.29143755001438

Epoch: 6| Step: 11
Training loss: 0.9499296187380016
Validation loss: 2.25456827974567

Epoch: 6| Step: 12
Training loss: 0.7423393495718724
Validation loss: 2.261869363999719

Epoch: 6| Step: 13
Training loss: 0.923296011010916
Validation loss: 2.3428932073186353

Epoch: 465| Step: 0
Training loss: 0.8236844830659281
Validation loss: 2.2130458161081523

Epoch: 6| Step: 1
Training loss: 0.8259988517937981
Validation loss: 2.2318129705962546

Epoch: 6| Step: 2
Training loss: 0.8816899952990075
Validation loss: 2.2110133960845837

Epoch: 6| Step: 3
Training loss: 0.9712139297719724
Validation loss: 2.2487378129382223

Epoch: 6| Step: 4
Training loss: 1.0335482794230937
Validation loss: 2.207998177961442

Epoch: 6| Step: 5
Training loss: 0.6317137610393933
Validation loss: 2.2106610266648064

Epoch: 6| Step: 6
Training loss: 0.819758709669597
Validation loss: 2.2475447834874145

Epoch: 6| Step: 7
Training loss: 0.9902172199997931
Validation loss: 2.2721985995955536

Epoch: 6| Step: 8
Training loss: 0.5474594263170924
Validation loss: 2.2476039454509005

Epoch: 6| Step: 9
Training loss: 0.989064324785571
Validation loss: 2.2027765267690698

Epoch: 6| Step: 10
Training loss: 0.498062013882201
Validation loss: 2.231727453407946

Epoch: 6| Step: 11
Training loss: 1.0996983764839035
Validation loss: 2.327599702320111

Epoch: 6| Step: 12
Training loss: 1.7832568725641753
Validation loss: 2.2034120834465876

Epoch: 6| Step: 13
Training loss: 1.1128239277930714
Validation loss: 2.2604040794160083

Epoch: 466| Step: 0
Training loss: 0.6844161835563525
Validation loss: 2.289923247681859

Epoch: 6| Step: 1
Training loss: 0.9605936194948778
Validation loss: 2.2105480793111534

Epoch: 6| Step: 2
Training loss: 1.7389210412963434
Validation loss: 2.2969025763761426

Epoch: 6| Step: 3
Training loss: 1.1640535904716192
Validation loss: 2.2566100254306822

Epoch: 6| Step: 4
Training loss: 0.7722987259064611
Validation loss: 2.275501179068007

Epoch: 6| Step: 5
Training loss: 0.9672480291552072
Validation loss: 2.2467195667869473

Epoch: 6| Step: 6
Training loss: 1.1424708650242243
Validation loss: 2.2522698464381263

Epoch: 6| Step: 7
Training loss: 1.032504849918973
Validation loss: 2.2722015849810155

Epoch: 6| Step: 8
Training loss: 0.7934422699949044
Validation loss: 2.2639362733214825

Epoch: 6| Step: 9
Training loss: 1.0509970631254415
Validation loss: 2.2780723669115006

Epoch: 6| Step: 10
Training loss: 0.9384803414640845
Validation loss: 2.3091565833746777

Epoch: 6| Step: 11
Training loss: 0.7533282104742797
Validation loss: 2.218377221979692

Epoch: 6| Step: 12
Training loss: 0.8105520592948852
Validation loss: 2.2442813995030884

Epoch: 6| Step: 13
Training loss: 0.8526594463705808
Validation loss: 2.2614997691025898

Epoch: 467| Step: 0
Training loss: 1.6954717605250507
Validation loss: 2.334298844549063

Epoch: 6| Step: 1
Training loss: 0.7498266894050482
Validation loss: 2.2487030279100972

Epoch: 6| Step: 2
Training loss: 0.7355208689609446
Validation loss: 2.223252639071156

Epoch: 6| Step: 3
Training loss: 0.9235623967478567
Validation loss: 2.226704334000979

Epoch: 6| Step: 4
Training loss: 0.538802595646871
Validation loss: 2.220858321957103

Epoch: 6| Step: 5
Training loss: 0.6338254568409863
Validation loss: 2.309279264594637

Epoch: 6| Step: 6
Training loss: 1.0403811469766726
Validation loss: 2.229810974863028

Epoch: 6| Step: 7
Training loss: 0.8875947565884841
Validation loss: 2.2912595965345237

Epoch: 6| Step: 8
Training loss: 1.0228569772142517
Validation loss: 2.27151715211922

Epoch: 6| Step: 9
Training loss: 0.9736093960225564
Validation loss: 2.2044462269739316

Epoch: 6| Step: 10
Training loss: 0.8833075291685311
Validation loss: 2.2477584677670523

Epoch: 6| Step: 11
Training loss: 1.0385436289828378
Validation loss: 2.2466911154300044

Epoch: 6| Step: 12
Training loss: 0.9411741738343965
Validation loss: 2.30474580691362

Epoch: 6| Step: 13
Training loss: 0.6470962118532225
Validation loss: 2.2269770468243775

Epoch: 468| Step: 0
Training loss: 1.2948169694526828
Validation loss: 2.293223633162961

Epoch: 6| Step: 1
Training loss: 0.8524803324916982
Validation loss: 2.2940186891867413

Epoch: 6| Step: 2
Training loss: 1.8115718043366253
Validation loss: 2.306075943592194

Epoch: 6| Step: 3
Training loss: 1.0218765352103458
Validation loss: 2.289996355823806

Epoch: 6| Step: 4
Training loss: 0.8637746376244625
Validation loss: 2.307786216355388

Epoch: 6| Step: 5
Training loss: 0.5827656407476821
Validation loss: 2.273270349983169

Epoch: 6| Step: 6
Training loss: 0.7514799140078373
Validation loss: 2.239566693216726

Epoch: 6| Step: 7
Training loss: 0.6805208293549461
Validation loss: 2.2510354230083998

Epoch: 6| Step: 8
Training loss: 0.944022820051418
Validation loss: 2.204326801340011

Epoch: 6| Step: 9
Training loss: 1.0494085939720315
Validation loss: 2.2563434506371682

Epoch: 6| Step: 10
Training loss: 0.7237184708073942
Validation loss: 2.2869765277764307

Epoch: 6| Step: 11
Training loss: 0.7484824005866033
Validation loss: 2.2693776318071257

Epoch: 6| Step: 12
Training loss: 0.703141932813417
Validation loss: 2.283959369273532

Epoch: 6| Step: 13
Training loss: 0.7042160470189947
Validation loss: 2.254796724901079

Epoch: 469| Step: 0
Training loss: 1.656527370043688
Validation loss: 2.2564192731735084

Epoch: 6| Step: 1
Training loss: 1.0708843847393217
Validation loss: 2.2737126749278644

Epoch: 6| Step: 2
Training loss: 0.8875861273868937
Validation loss: 2.2257773396111653

Epoch: 6| Step: 3
Training loss: 0.9474301224861763
Validation loss: 2.260398054511771

Epoch: 6| Step: 4
Training loss: 0.6151269243656375
Validation loss: 2.230759301773753

Epoch: 6| Step: 5
Training loss: 0.6933931369352178
Validation loss: 2.146953225620134

Epoch: 6| Step: 6
Training loss: 0.6493643375949589
Validation loss: 2.2732041886254066

Epoch: 6| Step: 7
Training loss: 0.6015106277890443
Validation loss: 2.2907884214442693

Epoch: 6| Step: 8
Training loss: 0.9706562729395192
Validation loss: 2.2119446231851754

Epoch: 6| Step: 9
Training loss: 0.9788558277195735
Validation loss: 2.28358237189356

Epoch: 6| Step: 10
Training loss: 0.9460125687512246
Validation loss: 2.2706278094284267

Epoch: 6| Step: 11
Training loss: 1.0481116548893095
Validation loss: 2.149813866672396

Epoch: 6| Step: 12
Training loss: 0.9077602167880935
Validation loss: 2.192592392037841

Epoch: 6| Step: 13
Training loss: 1.4803561769226279
Validation loss: 2.3256798100437113

Epoch: 470| Step: 0
Training loss: 0.787898423057476
Validation loss: 2.212427126564551

Epoch: 6| Step: 1
Training loss: 1.1287889254628967
Validation loss: 2.2619976648377187

Epoch: 6| Step: 2
Training loss: 1.057653424742052
Validation loss: 2.27141789949132

Epoch: 6| Step: 3
Training loss: 0.7406795240202448
Validation loss: 2.2559739635144442

Epoch: 6| Step: 4
Training loss: 0.9399802777067837
Validation loss: 2.201700032650906

Epoch: 6| Step: 5
Training loss: 0.7352942536858825
Validation loss: 2.2283600231448037

Epoch: 6| Step: 6
Training loss: 0.7634062244006623
Validation loss: 2.2255436971206715

Epoch: 6| Step: 7
Training loss: 0.7670202193299482
Validation loss: 2.240859199154098

Epoch: 6| Step: 8
Training loss: 0.7292252017549673
Validation loss: 2.208451876957729

Epoch: 6| Step: 9
Training loss: 1.8697827550592458
Validation loss: 2.2361320014469848

Epoch: 6| Step: 10
Training loss: 1.1132916366360324
Validation loss: 2.2116644256490434

Epoch: 6| Step: 11
Training loss: 0.873869096991685
Validation loss: 2.2272405053016264

Epoch: 6| Step: 12
Training loss: 0.7411357052384226
Validation loss: 2.2226612817585605

Epoch: 6| Step: 13
Training loss: 0.9370236776204028
Validation loss: 2.196375268804354

Epoch: 471| Step: 0
Training loss: 0.8850314854554597
Validation loss: 2.2575051323102797

Epoch: 6| Step: 1
Training loss: 0.66663378892731
Validation loss: 2.238085935048713

Epoch: 6| Step: 2
Training loss: 0.9043660477285451
Validation loss: 2.2298484367670692

Epoch: 6| Step: 3
Training loss: 0.9937417779738298
Validation loss: 2.251522489105423

Epoch: 6| Step: 4
Training loss: 0.8671833072595363
Validation loss: 2.227729335320761

Epoch: 6| Step: 5
Training loss: 0.8300090446898563
Validation loss: 2.2851156290905283

Epoch: 6| Step: 6
Training loss: 0.7643678425588678
Validation loss: 2.286894024302332

Epoch: 6| Step: 7
Training loss: 1.0109787521317957
Validation loss: 2.220541485421844

Epoch: 6| Step: 8
Training loss: 0.7210743679363791
Validation loss: 2.2646873307451205

Epoch: 6| Step: 9
Training loss: 1.702033997112114
Validation loss: 2.1717310825534546

Epoch: 6| Step: 10
Training loss: 0.8040278425282728
Validation loss: 2.1905967286586265

Epoch: 6| Step: 11
Training loss: 0.6949143287630648
Validation loss: 2.2857131799608768

Epoch: 6| Step: 12
Training loss: 0.8547575271623123
Validation loss: 2.2217353276719765

Epoch: 6| Step: 13
Training loss: 1.0033824459572853
Validation loss: 2.2166049992954036

Epoch: 472| Step: 0
Training loss: 0.7126319311367302
Validation loss: 2.2504109767268927

Epoch: 6| Step: 1
Training loss: 0.7892421102531224
Validation loss: 2.2135846715196354

Epoch: 6| Step: 2
Training loss: 1.1733742850555358
Validation loss: 2.1941290254843158

Epoch: 6| Step: 3
Training loss: 0.7500007152553962
Validation loss: 2.163525613790042

Epoch: 6| Step: 4
Training loss: 1.20814970967086
Validation loss: 2.250631133358439

Epoch: 6| Step: 5
Training loss: 0.8317557581755836
Validation loss: 2.3134358570779283

Epoch: 6| Step: 6
Training loss: 0.9076420845637694
Validation loss: 2.248049622187608

Epoch: 6| Step: 7
Training loss: 0.8510998510285961
Validation loss: 2.2076741389992036

Epoch: 6| Step: 8
Training loss: 0.8992853227857116
Validation loss: 2.221876784448931

Epoch: 6| Step: 9
Training loss: 1.81678134777887
Validation loss: 2.2922679041575478

Epoch: 6| Step: 10
Training loss: 0.7077018971375569
Validation loss: 2.210280124671482

Epoch: 6| Step: 11
Training loss: 0.9564737369862136
Validation loss: 2.236761722890662

Epoch: 6| Step: 12
Training loss: 0.6041883157819499
Validation loss: 2.246144132115953

Epoch: 6| Step: 13
Training loss: 0.603304977444388
Validation loss: 2.3074270577344578

Epoch: 473| Step: 0
Training loss: 0.6313919323282231
Validation loss: 2.1946163907991236

Epoch: 6| Step: 1
Training loss: 0.7856075071877378
Validation loss: 2.3037727407933573

Epoch: 6| Step: 2
Training loss: 1.0451881140814503
Validation loss: 2.2978241146593144

Epoch: 6| Step: 3
Training loss: 0.8826321105303245
Validation loss: 2.191298380314618

Epoch: 6| Step: 4
Training loss: 1.1526485751158828
Validation loss: 2.261880323546483

Epoch: 6| Step: 5
Training loss: 1.2212698879594348
Validation loss: 2.2972468430312465

Epoch: 6| Step: 6
Training loss: 1.7529138420897694
Validation loss: 2.228561195702153

Epoch: 6| Step: 7
Training loss: 0.9976805669797801
Validation loss: 2.252158163372465

Epoch: 6| Step: 8
Training loss: 0.7906562648215484
Validation loss: 2.2884976193558737

Epoch: 6| Step: 9
Training loss: 1.0894758362316
Validation loss: 2.186226129613967

Epoch: 6| Step: 10
Training loss: 0.5950784628687977
Validation loss: 2.188167580904642

Epoch: 6| Step: 11
Training loss: 0.611732324909991
Validation loss: 2.290587880745783

Epoch: 6| Step: 12
Training loss: 0.6932599493386482
Validation loss: 2.213918102667613

Epoch: 6| Step: 13
Training loss: 1.0624428902031569
Validation loss: 2.26860852823203

Epoch: 474| Step: 0
Training loss: 1.020603128024837
Validation loss: 2.299458367486115

Epoch: 6| Step: 1
Training loss: 1.11067376205228
Validation loss: 2.2182102185156722

Epoch: 6| Step: 2
Training loss: 0.8097393747464681
Validation loss: 2.2179329566688457

Epoch: 6| Step: 3
Training loss: 1.0583362899698925
Validation loss: 2.222154752307827

Epoch: 6| Step: 4
Training loss: 0.8112622149331089
Validation loss: 2.264199234513644

Epoch: 6| Step: 5
Training loss: 0.7415704270046475
Validation loss: 2.2864790331603135

Epoch: 6| Step: 6
Training loss: 0.8767282584230028
Validation loss: 2.2796286939037063

Epoch: 6| Step: 7
Training loss: 0.807177976580895
Validation loss: 2.238347604375763

Epoch: 6| Step: 8
Training loss: 1.727788015555374
Validation loss: 2.2723883363994952

Epoch: 6| Step: 9
Training loss: 0.665483278759483
Validation loss: 2.290883871571096

Epoch: 6| Step: 10
Training loss: 0.7379856627991914
Validation loss: 2.2665442073388884

Epoch: 6| Step: 11
Training loss: 0.927235133712461
Validation loss: 2.3167446566949077

Epoch: 6| Step: 12
Training loss: 1.1993374346425654
Validation loss: 2.2971973663144136

Epoch: 6| Step: 13
Training loss: 1.1792781195297397
Validation loss: 2.2987591547573683

Epoch: 475| Step: 0
Training loss: 0.8533382275063515
Validation loss: 2.325150268546729

Epoch: 6| Step: 1
Training loss: 0.8111916792350653
Validation loss: 2.244538734457565

Epoch: 6| Step: 2
Training loss: 0.7338814801849585
Validation loss: 2.202093650551628

Epoch: 6| Step: 3
Training loss: 0.9049488460984249
Validation loss: 2.194732359308121

Epoch: 6| Step: 4
Training loss: 0.6915184404116876
Validation loss: 2.192484505876068

Epoch: 6| Step: 5
Training loss: 0.5862329882367929
Validation loss: 2.3314960280743486

Epoch: 6| Step: 6
Training loss: 0.7642522689341419
Validation loss: 2.228803639776518

Epoch: 6| Step: 7
Training loss: 0.8377789331788523
Validation loss: 2.305296401811794

Epoch: 6| Step: 8
Training loss: 0.8766320539272547
Validation loss: 2.192759888673054

Epoch: 6| Step: 9
Training loss: 1.0773593561205375
Validation loss: 2.2185248711780106

Epoch: 6| Step: 10
Training loss: 2.0496395166302595
Validation loss: 2.232135029979759

Epoch: 6| Step: 11
Training loss: 0.8834354262164037
Validation loss: 2.225128118820588

Epoch: 6| Step: 12
Training loss: 0.8136233120700185
Validation loss: 2.2417147106757582

Epoch: 6| Step: 13
Training loss: 1.0344212639826167
Validation loss: 2.255952205167604

Epoch: 476| Step: 0
Training loss: 0.9292591935576103
Validation loss: 2.2697114023469496

Epoch: 6| Step: 1
Training loss: 0.8386642334887086
Validation loss: 2.20069452017655

Epoch: 6| Step: 2
Training loss: 0.8969730881807786
Validation loss: 2.279495206025092

Epoch: 6| Step: 3
Training loss: 0.8085783436362529
Validation loss: 2.2458278446890305

Epoch: 6| Step: 4
Training loss: 0.6456577513549773
Validation loss: 2.2574909615827727

Epoch: 6| Step: 5
Training loss: 1.0929043361614448
Validation loss: 2.269975759017115

Epoch: 6| Step: 6
Training loss: 0.9958422773483611
Validation loss: 2.3633945487761525

Epoch: 6| Step: 7
Training loss: 0.932177662760755
Validation loss: 2.158659611258749

Epoch: 6| Step: 8
Training loss: 1.0787940230067148
Validation loss: 2.2577496415662144

Epoch: 6| Step: 9
Training loss: 1.7612520602060564
Validation loss: 2.2283593443728864

Epoch: 6| Step: 10
Training loss: 1.0570183887812936
Validation loss: 2.2617554249773266

Epoch: 6| Step: 11
Training loss: 0.8668017517475265
Validation loss: 2.1780628941176152

Epoch: 6| Step: 12
Training loss: 0.9393830144341082
Validation loss: 2.26767159635232

Epoch: 6| Step: 13
Training loss: 0.691715408430867
Validation loss: 2.203472996950354

Epoch: 477| Step: 0
Training loss: 0.8443874494311098
Validation loss: 2.1676083317732298

Epoch: 6| Step: 1
Training loss: 0.5246503926117821
Validation loss: 2.2574386710159255

Epoch: 6| Step: 2
Training loss: 0.9028834920919785
Validation loss: 2.2459305099797926

Epoch: 6| Step: 3
Training loss: 1.2021227042870517
Validation loss: 2.184206474049649

Epoch: 6| Step: 4
Training loss: 0.778251577905709
Validation loss: 2.148680798727697

Epoch: 6| Step: 5
Training loss: 1.2762293722968439
Validation loss: 2.204046289342282

Epoch: 6| Step: 6
Training loss: 0.8272161714998499
Validation loss: 2.2746557206676234

Epoch: 6| Step: 7
Training loss: 1.158862281799477
Validation loss: 2.2398224123276673

Epoch: 6| Step: 8
Training loss: 0.7596888956977454
Validation loss: 2.1936251530675293

Epoch: 6| Step: 9
Training loss: 0.9464818484484759
Validation loss: 2.1995842637796548

Epoch: 6| Step: 10
Training loss: 1.7754345375396479
Validation loss: 2.248757567954288

Epoch: 6| Step: 11
Training loss: 0.7253059267915607
Validation loss: 2.3012333562284644

Epoch: 6| Step: 12
Training loss: 0.7272041522825519
Validation loss: 2.272728008114462

Epoch: 6| Step: 13
Training loss: 0.9259686823527509
Validation loss: 2.2039964357971153

Epoch: 478| Step: 0
Training loss: 0.8726910713099231
Validation loss: 2.2539435093340154

Epoch: 6| Step: 1
Training loss: 1.0365931488741011
Validation loss: 2.247257154858689

Epoch: 6| Step: 2
Training loss: 0.544653686375576
Validation loss: 2.2924394335680107

Epoch: 6| Step: 3
Training loss: 0.9520341227450683
Validation loss: 2.2058789813429924

Epoch: 6| Step: 4
Training loss: 0.90869534187756
Validation loss: 2.2316763744887345

Epoch: 6| Step: 5
Training loss: 1.9466205167307846
Validation loss: 2.254000077898533

Epoch: 6| Step: 6
Training loss: 0.6839323894411237
Validation loss: 2.292674760411981

Epoch: 6| Step: 7
Training loss: 0.5501151419538376
Validation loss: 2.2561014848900176

Epoch: 6| Step: 8
Training loss: 0.8930303984526939
Validation loss: 2.2723399650264327

Epoch: 6| Step: 9
Training loss: 0.7145423462200305
Validation loss: 2.226518749072757

Epoch: 6| Step: 10
Training loss: 0.8944446904976495
Validation loss: 2.241668642853421

Epoch: 6| Step: 11
Training loss: 1.1243615458066776
Validation loss: 2.278191937829993

Epoch: 6| Step: 12
Training loss: 1.053170136975789
Validation loss: 2.2594924537446572

Epoch: 6| Step: 13
Training loss: 1.0217084183077947
Validation loss: 2.1200163392300047

Epoch: 479| Step: 0
Training loss: 1.6705106355430739
Validation loss: 2.238096901094794

Epoch: 6| Step: 1
Training loss: 0.7483021671528362
Validation loss: 2.2992370617004605

Epoch: 6| Step: 2
Training loss: 0.5119311641673157
Validation loss: 2.2696358363621782

Epoch: 6| Step: 3
Training loss: 0.9790722754142945
Validation loss: 2.2647675931072264

Epoch: 6| Step: 4
Training loss: 1.1197613497629635
Validation loss: 2.352787524964247

Epoch: 6| Step: 5
Training loss: 0.8892657967688044
Validation loss: 2.3368872533801355

Epoch: 6| Step: 6
Training loss: 1.1159616427238912
Validation loss: 2.23139647522405

Epoch: 6| Step: 7
Training loss: 0.6310563857522945
Validation loss: 2.2910992892329767

Epoch: 6| Step: 8
Training loss: 0.9914922606281085
Validation loss: 2.2062394705551958

Epoch: 6| Step: 9
Training loss: 0.892936417602558
Validation loss: 2.193421736463967

Epoch: 6| Step: 10
Training loss: 0.8293929559622388
Validation loss: 2.278216379131443

Epoch: 6| Step: 11
Training loss: 0.721314457834441
Validation loss: 2.203633765376264

Epoch: 6| Step: 12
Training loss: 0.7764547814432194
Validation loss: 2.199899255076325

Epoch: 6| Step: 13
Training loss: 1.1863316259247714
Validation loss: 2.2152459683893

Epoch: 480| Step: 0
Training loss: 0.723178159561611
Validation loss: 2.2233776043155347

Epoch: 6| Step: 1
Training loss: 0.7407693665876309
Validation loss: 2.1877290761046555

Epoch: 6| Step: 2
Training loss: 0.8836669163045838
Validation loss: 2.158651959489196

Epoch: 6| Step: 3
Training loss: 0.7992512671156627
Validation loss: 2.2581865304805104

Epoch: 6| Step: 4
Training loss: 1.0881103074661085
Validation loss: 2.205727402735921

Epoch: 6| Step: 5
Training loss: 0.9722313010079479
Validation loss: 2.19293456157289

Epoch: 6| Step: 6
Training loss: 0.7580177186565844
Validation loss: 2.2195170190442597

Epoch: 6| Step: 7
Training loss: 0.6855929758596203
Validation loss: 2.2229264125046573

Epoch: 6| Step: 8
Training loss: 1.8909369597515393
Validation loss: 2.2497158190103868

Epoch: 6| Step: 9
Training loss: 1.2290969710337776
Validation loss: 2.292603235540532

Epoch: 6| Step: 10
Training loss: 0.9686761951019462
Validation loss: 2.2050959477028202

Epoch: 6| Step: 11
Training loss: 0.801513114136552
Validation loss: 2.294747182969131

Epoch: 6| Step: 12
Training loss: 0.8892373769495336
Validation loss: 2.290240710184768

Epoch: 6| Step: 13
Training loss: 0.5536165510193091
Validation loss: 2.2833786732742705

Epoch: 481| Step: 0
Training loss: 0.6326728949379259
Validation loss: 2.289941437753359

Epoch: 6| Step: 1
Training loss: 0.7830104828786857
Validation loss: 2.1808757468084865

Epoch: 6| Step: 2
Training loss: 0.8491073703808542
Validation loss: 2.254058334569133

Epoch: 6| Step: 3
Training loss: 0.9578714225032188
Validation loss: 2.251483861477581

Epoch: 6| Step: 4
Training loss: 0.78639961596108
Validation loss: 2.1977844177110137

Epoch: 6| Step: 5
Training loss: 0.7742698121385954
Validation loss: 2.2153572858356436

Epoch: 6| Step: 6
Training loss: 1.099645908758382
Validation loss: 2.233740444189881

Epoch: 6| Step: 7
Training loss: 0.9731099859021464
Validation loss: 2.2079382415490154

Epoch: 6| Step: 8
Training loss: 1.7772796954674919
Validation loss: 2.2335014830110644

Epoch: 6| Step: 9
Training loss: 0.8512870973186174
Validation loss: 2.218635901048203

Epoch: 6| Step: 10
Training loss: 0.8281472401061729
Validation loss: 2.268510463780197

Epoch: 6| Step: 11
Training loss: 0.5640110013494181
Validation loss: 2.199469926466139

Epoch: 6| Step: 12
Training loss: 0.5838233955525584
Validation loss: 2.2404814521668497

Epoch: 6| Step: 13
Training loss: 0.8819450234906022
Validation loss: 2.299018827070542

Epoch: 482| Step: 0
Training loss: 0.7327267025172602
Validation loss: 2.2374628030239347

Epoch: 6| Step: 1
Training loss: 0.7477461407076239
Validation loss: 2.2664569983364333

Epoch: 6| Step: 2
Training loss: 1.129001125058069
Validation loss: 2.2371002989227224

Epoch: 6| Step: 3
Training loss: 0.8467551861005286
Validation loss: 2.214482097792803

Epoch: 6| Step: 4
Training loss: 0.9120469000452115
Validation loss: 2.207478641310105

Epoch: 6| Step: 5
Training loss: 0.773992628225071
Validation loss: 2.217455538196104

Epoch: 6| Step: 6
Training loss: 0.8491828637142892
Validation loss: 2.323886935962273

Epoch: 6| Step: 7
Training loss: 0.7068410375178679
Validation loss: 2.297001861758799

Epoch: 6| Step: 8
Training loss: 1.7211625939521071
Validation loss: 2.3169135214549916

Epoch: 6| Step: 9
Training loss: 0.9058925647256555
Validation loss: 2.281719651076203

Epoch: 6| Step: 10
Training loss: 0.5771115157295659
Validation loss: 2.206043255961873

Epoch: 6| Step: 11
Training loss: 0.7948558883085103
Validation loss: 2.271107914349193

Epoch: 6| Step: 12
Training loss: 0.9384630660754779
Validation loss: 2.331846902712387

Epoch: 6| Step: 13
Training loss: 0.6874934976443658
Validation loss: 2.31040018602977

Epoch: 483| Step: 0
Training loss: 0.9551098278065238
Validation loss: 2.2433921422330534

Epoch: 6| Step: 1
Training loss: 0.7025199406057453
Validation loss: 2.208252378463126

Epoch: 6| Step: 2
Training loss: 0.6877681469341433
Validation loss: 2.340905680925157

Epoch: 6| Step: 3
Training loss: 0.6564356223483319
Validation loss: 2.3359302149279144

Epoch: 6| Step: 4
Training loss: 1.0057783668266955
Validation loss: 2.219136492863407

Epoch: 6| Step: 5
Training loss: 0.9138777130362179
Validation loss: 2.2075548310869593

Epoch: 6| Step: 6
Training loss: 1.0442761859455376
Validation loss: 2.2472245395358317

Epoch: 6| Step: 7
Training loss: 0.6234868328873064
Validation loss: 2.161056842622212

Epoch: 6| Step: 8
Training loss: 1.0908161050549732
Validation loss: 2.2097420632838034

Epoch: 6| Step: 9
Training loss: 0.7003217553714867
Validation loss: 2.259285071727592

Epoch: 6| Step: 10
Training loss: 0.7928871150347383
Validation loss: 2.2410915183425195

Epoch: 6| Step: 11
Training loss: 0.8006572348234736
Validation loss: 2.227979318421473

Epoch: 6| Step: 12
Training loss: 1.790885962199171
Validation loss: 2.2945775338060383

Epoch: 6| Step: 13
Training loss: 0.7450961488725857
Validation loss: 2.168320597431609

Epoch: 484| Step: 0
Training loss: 0.4583228518270102
Validation loss: 2.2564944739786514

Epoch: 6| Step: 1
Training loss: 0.8589471619001604
Validation loss: 2.1728483037496704

Epoch: 6| Step: 2
Training loss: 0.5330824383542339
Validation loss: 2.2390382241172646

Epoch: 6| Step: 3
Training loss: 0.5011953430151987
Validation loss: 2.2333104427060224

Epoch: 6| Step: 4
Training loss: 0.8240750445155011
Validation loss: 2.188789770308111

Epoch: 6| Step: 5
Training loss: 0.6261754664688728
Validation loss: 2.253066413127591

Epoch: 6| Step: 6
Training loss: 0.9628627687955292
Validation loss: 2.2050325293828728

Epoch: 6| Step: 7
Training loss: 0.6297065429079817
Validation loss: 2.3247602546677393

Epoch: 6| Step: 8
Training loss: 1.849153005175032
Validation loss: 2.2572363394976502

Epoch: 6| Step: 9
Training loss: 0.8829207227420817
Validation loss: 2.265972928554788

Epoch: 6| Step: 10
Training loss: 0.5300700322702149
Validation loss: 2.1861596778441874

Epoch: 6| Step: 11
Training loss: 0.9485030753327637
Validation loss: 2.2485253350788255

Epoch: 6| Step: 12
Training loss: 1.0474831252457295
Validation loss: 2.155092945181115

Epoch: 6| Step: 13
Training loss: 1.0120281203060926
Validation loss: 2.226163776118546

Epoch: 485| Step: 0
Training loss: 1.7468825911628232
Validation loss: 2.2058651977795294

Epoch: 6| Step: 1
Training loss: 0.9461921193449617
Validation loss: 2.220179720952738

Epoch: 6| Step: 2
Training loss: 0.9241111596008997
Validation loss: 2.2110308404932315

Epoch: 6| Step: 3
Training loss: 0.7980243024280511
Validation loss: 2.2259646338584633

Epoch: 6| Step: 4
Training loss: 1.129145930100987
Validation loss: 2.2220239132497017

Epoch: 6| Step: 5
Training loss: 0.6644265242986881
Validation loss: 2.220955354804189

Epoch: 6| Step: 6
Training loss: 1.0296387077661142
Validation loss: 2.1525753180968463

Epoch: 6| Step: 7
Training loss: 0.5897921609107286
Validation loss: 2.2251121709564883

Epoch: 6| Step: 8
Training loss: 0.7894620733494822
Validation loss: 2.1831444865828984

Epoch: 6| Step: 9
Training loss: 1.0797514326541384
Validation loss: 2.2185970232284116

Epoch: 6| Step: 10
Training loss: 0.8414230755865426
Validation loss: 2.238977429750427

Epoch: 6| Step: 11
Training loss: 0.8269133430754257
Validation loss: 2.2745506595622325

Epoch: 6| Step: 12
Training loss: 0.8790115971478304
Validation loss: 2.2375955686601547

Epoch: 6| Step: 13
Training loss: 0.6236527226797454
Validation loss: 2.1964394985012587

Epoch: 486| Step: 0
Training loss: 0.8349890631684717
Validation loss: 2.16487454808908

Epoch: 6| Step: 1
Training loss: 1.9669422145204092
Validation loss: 2.2439946344069557

Epoch: 6| Step: 2
Training loss: 0.9318776658836829
Validation loss: 2.2809923234088676

Epoch: 6| Step: 3
Training loss: 0.7359470828458997
Validation loss: 2.2383608500468855

Epoch: 6| Step: 4
Training loss: 0.7353601543841519
Validation loss: 2.210580046478938

Epoch: 6| Step: 5
Training loss: 0.7411744682979964
Validation loss: 2.2182035326374345

Epoch: 6| Step: 6
Training loss: 0.7024478830913714
Validation loss: 2.2073285070274076

Epoch: 6| Step: 7
Training loss: 0.8343148570583608
Validation loss: 2.221692776953014

Epoch: 6| Step: 8
Training loss: 0.833640749177528
Validation loss: 2.2251495051624377

Epoch: 6| Step: 9
Training loss: 0.6112355415022814
Validation loss: 2.1729453633326496

Epoch: 6| Step: 10
Training loss: 0.9530431993746493
Validation loss: 2.3548675054367627

Epoch: 6| Step: 11
Training loss: 0.6912358391882364
Validation loss: 2.1896786366288428

Epoch: 6| Step: 12
Training loss: 0.9548910695009835
Validation loss: 2.1605579523642473

Epoch: 6| Step: 13
Training loss: 0.6651910952580482
Validation loss: 2.227848639331409

Epoch: 487| Step: 0
Training loss: 0.6676229954032179
Validation loss: 2.285556463326408

Epoch: 6| Step: 1
Training loss: 1.0552132885368766
Validation loss: 2.217320905304382

Epoch: 6| Step: 2
Training loss: 0.9184773111816906
Validation loss: 2.263626221191798

Epoch: 6| Step: 3
Training loss: 0.8860929860646697
Validation loss: 2.2016789701647945

Epoch: 6| Step: 4
Training loss: 0.9037152391030006
Validation loss: 2.2076888089017825

Epoch: 6| Step: 5
Training loss: 0.6465974921985234
Validation loss: 2.185777485837238

Epoch: 6| Step: 6
Training loss: 0.8168829297452106
Validation loss: 2.2397970947983787

Epoch: 6| Step: 7
Training loss: 0.7598713308510265
Validation loss: 2.21564957917938

Epoch: 6| Step: 8
Training loss: 0.8842733331480869
Validation loss: 2.268153449951486

Epoch: 6| Step: 9
Training loss: 1.04422030560533
Validation loss: 2.1871198027857606

Epoch: 6| Step: 10
Training loss: 1.6279936871136762
Validation loss: 2.20226946315079

Epoch: 6| Step: 11
Training loss: 0.8196267304197856
Validation loss: 2.190052695912822

Epoch: 6| Step: 12
Training loss: 0.8204515611761917
Validation loss: 2.3179895849544168

Epoch: 6| Step: 13
Training loss: 0.5630645832586816
Validation loss: 2.2727737624973376

Epoch: 488| Step: 0
Training loss: 0.8885297389122423
Validation loss: 2.192511461836724

Epoch: 6| Step: 1
Training loss: 1.7722140221653526
Validation loss: 2.297613171936957

Epoch: 6| Step: 2
Training loss: 0.9592532152047953
Validation loss: 2.2244794622669573

Epoch: 6| Step: 3
Training loss: 0.7727125990081264
Validation loss: 2.1910907485414994

Epoch: 6| Step: 4
Training loss: 1.022674275961381
Validation loss: 2.228817442514372

Epoch: 6| Step: 5
Training loss: 0.7812226862901134
Validation loss: 2.304928480049568

Epoch: 6| Step: 6
Training loss: 0.9185828569405171
Validation loss: 2.191130358944428

Epoch: 6| Step: 7
Training loss: 0.6852254086674261
Validation loss: 2.2504495760642658

Epoch: 6| Step: 8
Training loss: 0.9412832219313512
Validation loss: 2.220577134141153

Epoch: 6| Step: 9
Training loss: 0.7877299321268857
Validation loss: 2.26878781824026

Epoch: 6| Step: 10
Training loss: 0.7488603277550374
Validation loss: 2.2856786458416525

Epoch: 6| Step: 11
Training loss: 0.5832314884879714
Validation loss: 2.236184979980438

Epoch: 6| Step: 12
Training loss: 0.5457142636931107
Validation loss: 2.277782706256933

Epoch: 6| Step: 13
Training loss: 0.5656871044986579
Validation loss: 2.209460703436116

Epoch: 489| Step: 0
Training loss: 0.5692974620662681
Validation loss: 2.2252034842392256

Epoch: 6| Step: 1
Training loss: 1.0149672505775116
Validation loss: 2.207076785741028

Epoch: 6| Step: 2
Training loss: 1.0097097827810353
Validation loss: 2.2031589221226446

Epoch: 6| Step: 3
Training loss: 0.6142472598286838
Validation loss: 2.2780618943317275

Epoch: 6| Step: 4
Training loss: 1.0319021648156184
Validation loss: 2.2522693137382097

Epoch: 6| Step: 5
Training loss: 1.7037295047369694
Validation loss: 2.27836246782983

Epoch: 6| Step: 6
Training loss: 0.7235808772138733
Validation loss: 2.206065752921473

Epoch: 6| Step: 7
Training loss: 0.9579729079674421
Validation loss: 2.2883011793883847

Epoch: 6| Step: 8
Training loss: 0.6311111184110477
Validation loss: 2.244852257132535

Epoch: 6| Step: 9
Training loss: 0.5982049156382367
Validation loss: 2.29787166118036

Epoch: 6| Step: 10
Training loss: 0.9897927949310554
Validation loss: 2.2708888679781656

Epoch: 6| Step: 11
Training loss: 0.8651228029807174
Validation loss: 2.2907054598745047

Epoch: 6| Step: 12
Training loss: 0.9175805102788681
Validation loss: 2.1583695310733484

Epoch: 6| Step: 13
Training loss: 1.2400946110348303
Validation loss: 2.2723181022110923

Epoch: 490| Step: 0
Training loss: 0.8345933607022473
Validation loss: 2.2289475130173253

Epoch: 6| Step: 1
Training loss: 0.8326299241783273
Validation loss: 2.179269268082619

Epoch: 6| Step: 2
Training loss: 0.7156894871337104
Validation loss: 2.223132457058786

Epoch: 6| Step: 3
Training loss: 0.8319666662805864
Validation loss: 2.172390252043374

Epoch: 6| Step: 4
Training loss: 0.6269029258524662
Validation loss: 2.2969781493748482

Epoch: 6| Step: 5
Training loss: 1.6723116010491041
Validation loss: 2.237707592166845

Epoch: 6| Step: 6
Training loss: 0.9593102548229874
Validation loss: 2.247829923247014

Epoch: 6| Step: 7
Training loss: 0.8020176716139455
Validation loss: 2.168338591618817

Epoch: 6| Step: 8
Training loss: 1.069719024737513
Validation loss: 2.2201720641264875

Epoch: 6| Step: 9
Training loss: 0.9161658905997091
Validation loss: 2.181038923787522

Epoch: 6| Step: 10
Training loss: 0.9665748726626086
Validation loss: 2.290745829460107

Epoch: 6| Step: 11
Training loss: 0.7051363257905321
Validation loss: 2.2495371890605287

Epoch: 6| Step: 12
Training loss: 0.6583122593086025
Validation loss: 2.2822336348287062

Epoch: 6| Step: 13
Training loss: 0.9150053199238197
Validation loss: 2.2459931832690048

Epoch: 491| Step: 0
Training loss: 0.8826696567256661
Validation loss: 2.203681912066497

Epoch: 6| Step: 1
Training loss: 0.6291385955948348
Validation loss: 2.2492698278811774

Epoch: 6| Step: 2
Training loss: 1.760077953671336
Validation loss: 2.2670778362460835

Epoch: 6| Step: 3
Training loss: 0.9554001902875737
Validation loss: 2.1929197310094777

Epoch: 6| Step: 4
Training loss: 0.5987738338974983
Validation loss: 2.2678052641434894

Epoch: 6| Step: 5
Training loss: 0.8373715942787331
Validation loss: 2.2547959153769033

Epoch: 6| Step: 6
Training loss: 0.7201299274622308
Validation loss: 2.1816801149721248

Epoch: 6| Step: 7
Training loss: 1.055960388658048
Validation loss: 2.2214958356267696

Epoch: 6| Step: 8
Training loss: 0.9441283194040264
Validation loss: 2.260005659701961

Epoch: 6| Step: 9
Training loss: 0.858372606533275
Validation loss: 2.2614858733667225

Epoch: 6| Step: 10
Training loss: 0.8629987090334292
Validation loss: 2.186738017747933

Epoch: 6| Step: 11
Training loss: 0.5721772421850215
Validation loss: 2.229092140627199

Epoch: 6| Step: 12
Training loss: 0.7205489078920307
Validation loss: 2.1428943769723228

Epoch: 6| Step: 13
Training loss: 0.7902108702320102
Validation loss: 2.24486456452573

Epoch: 492| Step: 0
Training loss: 0.4592714750972263
Validation loss: 2.2137467223609892

Epoch: 6| Step: 1
Training loss: 0.8458802211775652
Validation loss: 2.2343863175662926

Epoch: 6| Step: 2
Training loss: 0.62350102915981
Validation loss: 2.217701917568799

Epoch: 6| Step: 3
Training loss: 0.7350107646984259
Validation loss: 2.260740632243341

Epoch: 6| Step: 4
Training loss: 0.9682883116147741
Validation loss: 2.179172036945042

Epoch: 6| Step: 5
Training loss: 0.7989522002845593
Validation loss: 2.2630516099337457

Epoch: 6| Step: 6
Training loss: 0.8095979950408837
Validation loss: 2.155288676980583

Epoch: 6| Step: 7
Training loss: 0.8106587160461993
Validation loss: 2.2298621755533974

Epoch: 6| Step: 8
Training loss: 0.9589124602100707
Validation loss: 2.1584276946578465

Epoch: 6| Step: 9
Training loss: 0.7347353193329216
Validation loss: 2.1985741289858427

Epoch: 6| Step: 10
Training loss: 0.9789556248809979
Validation loss: 2.1535300311862566

Epoch: 6| Step: 11
Training loss: 1.0991340002643488
Validation loss: 2.211208673429514

Epoch: 6| Step: 12
Training loss: 0.9748651019945231
Validation loss: 2.2238935039566243

Epoch: 6| Step: 13
Training loss: 2.127912320840388
Validation loss: 2.2251069961138645

Epoch: 493| Step: 0
Training loss: 0.48025355908744605
Validation loss: 2.163772161641393

Epoch: 6| Step: 1
Training loss: 0.8665355259149676
Validation loss: 2.2305708395740713

Epoch: 6| Step: 2
Training loss: 1.0100783669879136
Validation loss: 2.233488874830475

Epoch: 6| Step: 3
Training loss: 0.7373103463669428
Validation loss: 2.2043089677662873

Epoch: 6| Step: 4
Training loss: 1.6965377528686385
Validation loss: 2.3343417593201807

Epoch: 6| Step: 5
Training loss: 0.7426503394670403
Validation loss: 2.2433852011472677

Epoch: 6| Step: 6
Training loss: 0.7035150929331951
Validation loss: 2.214564308238592

Epoch: 6| Step: 7
Training loss: 1.144477087828948
Validation loss: 2.214255844421991

Epoch: 6| Step: 8
Training loss: 0.8982445882925658
Validation loss: 2.2367451301696946

Epoch: 6| Step: 9
Training loss: 0.9628811539808998
Validation loss: 2.208725611644585

Epoch: 6| Step: 10
Training loss: 0.8271433211959903
Validation loss: 2.221263241434657

Epoch: 6| Step: 11
Training loss: 0.725496679389132
Validation loss: 2.283743600863818

Epoch: 6| Step: 12
Training loss: 0.6193619822761445
Validation loss: 2.248529533651854

Epoch: 6| Step: 13
Training loss: 0.8220753936719304
Validation loss: 2.2863843146560976

Epoch: 494| Step: 0
Training loss: 0.6976263785294797
Validation loss: 2.273897451581677

Epoch: 6| Step: 1
Training loss: 0.6783654081257983
Validation loss: 2.1552192021787193

Epoch: 6| Step: 2
Training loss: 0.7319812313810903
Validation loss: 2.219229482732161

Epoch: 6| Step: 3
Training loss: 0.8725538803340448
Validation loss: 2.277868214387681

Epoch: 6| Step: 4
Training loss: 0.6443517261523743
Validation loss: 2.253244111642702

Epoch: 6| Step: 5
Training loss: 0.6562616710533286
Validation loss: 2.208101976348456

Epoch: 6| Step: 6
Training loss: 0.8930419117617184
Validation loss: 2.214252152809298

Epoch: 6| Step: 7
Training loss: 1.1597091892345126
Validation loss: 2.2457944106795327

Epoch: 6| Step: 8
Training loss: 0.9323406348696643
Validation loss: 2.2839092522495026

Epoch: 6| Step: 9
Training loss: 0.7775940995140657
Validation loss: 2.235976599985497

Epoch: 6| Step: 10
Training loss: 0.7222815702172994
Validation loss: 2.222767761479347

Epoch: 6| Step: 11
Training loss: 1.6502403777763286
Validation loss: 2.1916927594679785

Epoch: 6| Step: 12
Training loss: 0.5951992467850488
Validation loss: 2.274822626610773

Epoch: 6| Step: 13
Training loss: 0.6130667147215905
Validation loss: 2.2463160679004726

Epoch: 495| Step: 0
Training loss: 0.7065851268831778
Validation loss: 2.256243103855804

Epoch: 6| Step: 1
Training loss: 1.030596381461544
Validation loss: 2.1969328580064174

Epoch: 6| Step: 2
Training loss: 1.6279894400776667
Validation loss: 2.1929219463648697

Epoch: 6| Step: 3
Training loss: 0.6484592158346633
Validation loss: 2.1542757545511133

Epoch: 6| Step: 4
Training loss: 0.6731668074295163
Validation loss: 2.184218584429808

Epoch: 6| Step: 5
Training loss: 0.8318687960925726
Validation loss: 2.2477100596428135

Epoch: 6| Step: 6
Training loss: 0.7657990160556428
Validation loss: 2.1639680102507137

Epoch: 6| Step: 7
Training loss: 0.6410320198524206
Validation loss: 2.2160110437462213

Epoch: 6| Step: 8
Training loss: 0.917453799994506
Validation loss: 2.1675001825543876

Epoch: 6| Step: 9
Training loss: 0.7243988060186773
Validation loss: 2.299891086231556

Epoch: 6| Step: 10
Training loss: 0.9932555510055929
Validation loss: 2.221703331195086

Epoch: 6| Step: 11
Training loss: 0.9906667333530577
Validation loss: 2.185438981215957

Epoch: 6| Step: 12
Training loss: 0.8460513624737718
Validation loss: 2.19893290226756

Epoch: 6| Step: 13
Training loss: 0.7282431248799651
Validation loss: 2.198241690688939

Epoch: 496| Step: 0
Training loss: 0.722781196308905
Validation loss: 2.19632844783784

Epoch: 6| Step: 1
Training loss: 0.6798690465746068
Validation loss: 2.2473321951125107

Epoch: 6| Step: 2
Training loss: 1.780042272344398
Validation loss: 2.2730411045404484

Epoch: 6| Step: 3
Training loss: 0.7250500595962966
Validation loss: 2.2943006303611333

Epoch: 6| Step: 4
Training loss: 0.9094924143075875
Validation loss: 2.2179309604816497

Epoch: 6| Step: 5
Training loss: 0.7155648851757228
Validation loss: 2.218099993143963

Epoch: 6| Step: 6
Training loss: 1.0694783433823267
Validation loss: 2.2561522264395415

Epoch: 6| Step: 7
Training loss: 0.7418995348786859
Validation loss: 2.1940826216204976

Epoch: 6| Step: 8
Training loss: 0.750333036549206
Validation loss: 2.2424602424840665

Epoch: 6| Step: 9
Training loss: 0.9199174366578674
Validation loss: 2.24246302966926

Epoch: 6| Step: 10
Training loss: 0.9159038613792045
Validation loss: 2.2446245610416624

Epoch: 6| Step: 11
Training loss: 0.5225293836590525
Validation loss: 2.1992777233988305

Epoch: 6| Step: 12
Training loss: 0.6914020689067392
Validation loss: 2.197685359775472

Epoch: 6| Step: 13
Training loss: 0.41744172212030733
Validation loss: 2.189302047340229

Epoch: 497| Step: 0
Training loss: 0.7295078750823248
Validation loss: 2.1311135980928606

Epoch: 6| Step: 1
Training loss: 0.7393361784545164
Validation loss: 2.2014957449618655

Epoch: 6| Step: 2
Training loss: 0.6596999086543874
Validation loss: 2.2608530099650843

Epoch: 6| Step: 3
Training loss: 0.7422695315352276
Validation loss: 2.1746216082155123

Epoch: 6| Step: 4
Training loss: 0.5577649456878893
Validation loss: 2.2151491998766795

Epoch: 6| Step: 5
Training loss: 0.7754004643582264
Validation loss: 2.308043852840771

Epoch: 6| Step: 6
Training loss: 0.8900175867593324
Validation loss: 2.2319189275641

Epoch: 6| Step: 7
Training loss: 0.7588105069816022
Validation loss: 2.2822557199885636

Epoch: 6| Step: 8
Training loss: 1.8911191436416686
Validation loss: 2.151672353851928

Epoch: 6| Step: 9
Training loss: 0.7860423539522067
Validation loss: 2.282490249156684

Epoch: 6| Step: 10
Training loss: 0.6214349637149087
Validation loss: 2.2323955565594433

Epoch: 6| Step: 11
Training loss: 1.0238931238644904
Validation loss: 2.1882560109165494

Epoch: 6| Step: 12
Training loss: 0.8359703699227221
Validation loss: 2.2328925590015203

Epoch: 6| Step: 13
Training loss: 0.8239000617318837
Validation loss: 2.239710298579894

Epoch: 498| Step: 0
Training loss: 0.739125087418689
Validation loss: 2.325198207790594

Epoch: 6| Step: 1
Training loss: 0.7491741401828587
Validation loss: 2.2008765045641656

Epoch: 6| Step: 2
Training loss: 0.8246776153214911
Validation loss: 2.2264401062372428

Epoch: 6| Step: 3
Training loss: 0.7392445088125507
Validation loss: 2.3176683459554592

Epoch: 6| Step: 4
Training loss: 0.5926832604985244
Validation loss: 2.1509085075719057

Epoch: 6| Step: 5
Training loss: 0.7282937865210498
Validation loss: 2.1990365695495777

Epoch: 6| Step: 6
Training loss: 0.8422467651463588
Validation loss: 2.286321168675428

Epoch: 6| Step: 7
Training loss: 0.6114475023998958
Validation loss: 2.224056351150507

Epoch: 6| Step: 8
Training loss: 0.8672778795588005
Validation loss: 2.3043223825114

Epoch: 6| Step: 9
Training loss: 0.7568303458714811
Validation loss: 2.2466273752777965

Epoch: 6| Step: 10
Training loss: 1.0810937228301367
Validation loss: 2.283999620139795

Epoch: 6| Step: 11
Training loss: 1.6781565231687008
Validation loss: 2.240711798016236

Epoch: 6| Step: 12
Training loss: 0.7620348152357264
Validation loss: 2.218569160496991

Epoch: 6| Step: 13
Training loss: 0.6088649130972273
Validation loss: 2.3325569740774648

Epoch: 499| Step: 0
Training loss: 0.7756924366125768
Validation loss: 2.2246465246200855

Epoch: 6| Step: 1
Training loss: 0.5992604088259228
Validation loss: 2.2380669357756195

Epoch: 6| Step: 2
Training loss: 0.8136153268782648
Validation loss: 2.150723240966956

Epoch: 6| Step: 3
Training loss: 1.6640028248863816
Validation loss: 2.1908708872278178

Epoch: 6| Step: 4
Training loss: 0.7470072800716888
Validation loss: 2.244405789001648

Epoch: 6| Step: 5
Training loss: 0.7920024603049278
Validation loss: 2.2569431806192153

Epoch: 6| Step: 6
Training loss: 0.6578429960308417
Validation loss: 2.107729547047875

Epoch: 6| Step: 7
Training loss: 0.8245331946330716
Validation loss: 2.209401223258443

Epoch: 6| Step: 8
Training loss: 0.7989732381996233
Validation loss: 2.2810827818507646

Epoch: 6| Step: 9
Training loss: 0.8241849413260943
Validation loss: 2.29296481895288

Epoch: 6| Step: 10
Training loss: 0.7450999486686414
Validation loss: 2.2034684967036444

Epoch: 6| Step: 11
Training loss: 0.7390339964840162
Validation loss: 2.2305345920118462

Epoch: 6| Step: 12
Training loss: 0.8524060751893157
Validation loss: 2.202366272597129

Epoch: 6| Step: 13
Training loss: 0.9816851422514774
Validation loss: 2.173630143408499

Epoch: 500| Step: 0
Training loss: 0.7032567006852046
Validation loss: 2.1947062944366635

Epoch: 6| Step: 1
Training loss: 0.7247621935489433
Validation loss: 2.1923892017637456

Epoch: 6| Step: 2
Training loss: 0.6106820150364659
Validation loss: 2.214493221820863

Epoch: 6| Step: 3
Training loss: 0.7385121140981221
Validation loss: 2.1974513903701567

Epoch: 6| Step: 4
Training loss: 0.7422631074641673
Validation loss: 2.2429804555122366

Epoch: 6| Step: 5
Training loss: 0.7638566361949257
Validation loss: 2.2581459568721995

Epoch: 6| Step: 6
Training loss: 0.920341120794615
Validation loss: 2.2880361920982333

Epoch: 6| Step: 7
Training loss: 0.6370996377412518
Validation loss: 2.244902725352314

Epoch: 6| Step: 8
Training loss: 1.6940088137697988
Validation loss: 2.256287683344901

Epoch: 6| Step: 9
Training loss: 0.8461039168292098
Validation loss: 2.289550436378254

Epoch: 6| Step: 10
Training loss: 0.489007486046201
Validation loss: 2.261713665714876

Epoch: 6| Step: 11
Training loss: 0.709425775668506
Validation loss: 2.2223177344124365

Epoch: 6| Step: 12
Training loss: 0.7507212270506785
Validation loss: 2.2601706042605807

Epoch: 6| Step: 13
Training loss: 1.3964410521716435
Validation loss: 2.2751031926354948

Epoch: 501| Step: 0
Training loss: 0.6878753851047764
Validation loss: 2.274719057492334

Epoch: 6| Step: 1
Training loss: 0.6382323919901397
Validation loss: 2.2060089516951242

Epoch: 6| Step: 2
Training loss: 1.026185982457986
Validation loss: 2.237433042043978

Epoch: 6| Step: 3
Training loss: 0.516071588569952
Validation loss: 2.18727164885823

Epoch: 6| Step: 4
Training loss: 0.8664951825742645
Validation loss: 2.274820492142096

Epoch: 6| Step: 5
Training loss: 1.0265121285028145
Validation loss: 2.184152526994995

Epoch: 6| Step: 6
Training loss: 0.6495960410854834
Validation loss: 2.2573385211288057

Epoch: 6| Step: 7
Training loss: 0.7304546334437685
Validation loss: 2.234332524194272

Epoch: 6| Step: 8
Training loss: 0.9577615248291159
Validation loss: 2.2514584889101195

Epoch: 6| Step: 9
Training loss: 0.6720992978094469
Validation loss: 2.199730553911597

Epoch: 6| Step: 10
Training loss: 1.7253755658187553
Validation loss: 2.2832124887911607

Epoch: 6| Step: 11
Training loss: 0.7735124031556917
Validation loss: 2.1891739237414867

Epoch: 6| Step: 12
Training loss: 0.8007712386831323
Validation loss: 2.2069849524695324

Epoch: 6| Step: 13
Training loss: 0.907414050485193
Validation loss: 2.2563626669800625

Epoch: 502| Step: 0
Training loss: 0.9336395890861526
Validation loss: 2.1916923991978736

Epoch: 6| Step: 1
Training loss: 1.735984193189355
Validation loss: 2.2693311557081635

Epoch: 6| Step: 2
Training loss: 0.9243824044034862
Validation loss: 2.2589770311225426

Epoch: 6| Step: 3
Training loss: 0.8258735713400767
Validation loss: 2.2019022307075904

Epoch: 6| Step: 4
Training loss: 1.0654361770110565
Validation loss: 2.2653179137389277

Epoch: 6| Step: 5
Training loss: 0.4741337280475796
Validation loss: 2.2771003562263106

Epoch: 6| Step: 6
Training loss: 0.8806882975499369
Validation loss: 2.188840488767126

Epoch: 6| Step: 7
Training loss: 1.0501933101544865
Validation loss: 2.2625525133566127

Epoch: 6| Step: 8
Training loss: 0.7738515728051089
Validation loss: 2.207198879777577

Epoch: 6| Step: 9
Training loss: 0.6626648499862412
Validation loss: 2.221222294030975

Epoch: 6| Step: 10
Training loss: 0.7717439239035389
Validation loss: 2.253782929700246

Epoch: 6| Step: 11
Training loss: 0.7776544228061505
Validation loss: 2.2451369224192357

Epoch: 6| Step: 12
Training loss: 0.6357621337761766
Validation loss: 2.2615688735576085

Epoch: 6| Step: 13
Training loss: 0.7919135754349078
Validation loss: 2.2017630337673832

Epoch: 503| Step: 0
Training loss: 0.7243478308150089
Validation loss: 2.2432096024740864

Epoch: 6| Step: 1
Training loss: 0.6676317669972449
Validation loss: 2.312867798029544

Epoch: 6| Step: 2
Training loss: 0.8024533561865016
Validation loss: 2.1920789057292773

Epoch: 6| Step: 3
Training loss: 0.3902102557452509
Validation loss: 2.1997201920140754

Epoch: 6| Step: 4
Training loss: 0.9584104292721635
Validation loss: 2.250537115452226

Epoch: 6| Step: 5
Training loss: 0.7227238391507848
Validation loss: 2.2447434736073633

Epoch: 6| Step: 6
Training loss: 0.5485453572953789
Validation loss: 2.2275921930341953

Epoch: 6| Step: 7
Training loss: 1.8050087646947868
Validation loss: 2.2689762115588423

Epoch: 6| Step: 8
Training loss: 0.5676001232738509
Validation loss: 2.196501163265763

Epoch: 6| Step: 9
Training loss: 0.7533428082953356
Validation loss: 2.283028187566713

Epoch: 6| Step: 10
Training loss: 1.038551147376851
Validation loss: 2.200216719807875

Epoch: 6| Step: 11
Training loss: 0.6870098100431019
Validation loss: 2.2064249224932375

Epoch: 6| Step: 12
Training loss: 0.6951862606362316
Validation loss: 2.232163144302175

Epoch: 6| Step: 13
Training loss: 0.6270384923505751
Validation loss: 2.197586104307293

Epoch: 504| Step: 0
Training loss: 0.65401149618328
Validation loss: 2.2085402289824505

Epoch: 6| Step: 1
Training loss: 1.1335207073674312
Validation loss: 2.331815179208738

Epoch: 6| Step: 2
Training loss: 0.5999076176094387
Validation loss: 2.2385555334721077

Epoch: 6| Step: 3
Training loss: 0.5695191705205037
Validation loss: 2.22378647117559

Epoch: 6| Step: 4
Training loss: 0.6053853131301322
Validation loss: 2.211109002972157

Epoch: 6| Step: 5
Training loss: 0.7378397433830658
Validation loss: 2.255784824678829

Epoch: 6| Step: 6
Training loss: 0.8144046759888987
Validation loss: 2.243421565616051

Epoch: 6| Step: 7
Training loss: 1.7927121579271474
Validation loss: 2.263473157594048

Epoch: 6| Step: 8
Training loss: 0.8997829148954114
Validation loss: 2.2005845999150973

Epoch: 6| Step: 9
Training loss: 0.854583421468769
Validation loss: 2.24544774478368

Epoch: 6| Step: 10
Training loss: 0.7016615366540548
Validation loss: 2.212066540678899

Epoch: 6| Step: 11
Training loss: 0.7536723114895004
Validation loss: 2.2251904500005684

Epoch: 6| Step: 12
Training loss: 0.8639141541766422
Validation loss: 2.2011686267307082

Epoch: 6| Step: 13
Training loss: 0.4863443027241466
Validation loss: 2.2284193793675184

Epoch: 505| Step: 0
Training loss: 1.0787970065664105
Validation loss: 2.2343700009310234

Epoch: 6| Step: 1
Training loss: 0.8295265788832206
Validation loss: 2.243794872991392

Epoch: 6| Step: 2
Training loss: 0.80615356371283
Validation loss: 2.3267307526405436

Epoch: 6| Step: 3
Training loss: 0.7867717918236283
Validation loss: 2.2427462790203183

Epoch: 6| Step: 4
Training loss: 0.6265875918341783
Validation loss: 2.2238427488738615

Epoch: 6| Step: 5
Training loss: 0.9905820458182025
Validation loss: 2.242778847447393

Epoch: 6| Step: 6
Training loss: 0.48331401357459386
Validation loss: 2.1802286343839303

Epoch: 6| Step: 7
Training loss: 0.9170786011495923
Validation loss: 2.298568522041586

Epoch: 6| Step: 8
Training loss: 0.7667107182438306
Validation loss: 2.2471899729372056

Epoch: 6| Step: 9
Training loss: 1.6834458288365917
Validation loss: 2.2837737700425227

Epoch: 6| Step: 10
Training loss: 0.7842156388912142
Validation loss: 2.206881158465679

Epoch: 6| Step: 11
Training loss: 0.6838666316743922
Validation loss: 2.225004214552081

Epoch: 6| Step: 12
Training loss: 0.6072577104404847
Validation loss: 2.183855240289998

Epoch: 6| Step: 13
Training loss: 0.7083646309239936
Validation loss: 2.291274182745015

Epoch: 506| Step: 0
Training loss: 0.55430253868086
Validation loss: 2.234127576836804

Epoch: 6| Step: 1
Training loss: 0.5395465004867656
Validation loss: 2.1939381610380404

Epoch: 6| Step: 2
Training loss: 0.48524093134609797
Validation loss: 2.2258666814540953

Epoch: 6| Step: 3
Training loss: 0.8864673140385056
Validation loss: 2.2874401480312403

Epoch: 6| Step: 4
Training loss: 0.890578753960547
Validation loss: 2.2387132540402046

Epoch: 6| Step: 5
Training loss: 1.746799607944641
Validation loss: 2.1931723571174957

Epoch: 6| Step: 6
Training loss: 0.9250606516980756
Validation loss: 2.218774806081412

Epoch: 6| Step: 7
Training loss: 0.835807005777274
Validation loss: 2.302143493884842

Epoch: 6| Step: 8
Training loss: 1.1471721918949465
Validation loss: 2.2658777126408025

Epoch: 6| Step: 9
Training loss: 0.6880587344784282
Validation loss: 2.199731954180024

Epoch: 6| Step: 10
Training loss: 0.8237259824548104
Validation loss: 2.2359106132381483

Epoch: 6| Step: 11
Training loss: 0.8643813567572564
Validation loss: 2.2973608787039077

Epoch: 6| Step: 12
Training loss: 0.784548775925975
Validation loss: 2.203118848417525

Epoch: 6| Step: 13
Training loss: 0.826344501325513
Validation loss: 2.2560635862133833

Epoch: 507| Step: 0
Training loss: 0.8229898629450703
Validation loss: 2.230167259996064

Epoch: 6| Step: 1
Training loss: 0.6726111659449445
Validation loss: 2.251499144886993

Epoch: 6| Step: 2
Training loss: 0.7505806820735339
Validation loss: 2.2073756509795057

Epoch: 6| Step: 3
Training loss: 0.9401438309323304
Validation loss: 2.24890716565506

Epoch: 6| Step: 4
Training loss: 1.0507295163263912
Validation loss: 2.1882244442844576

Epoch: 6| Step: 5
Training loss: 0.7338179646847282
Validation loss: 2.217740922631175

Epoch: 6| Step: 6
Training loss: 0.8307658858041724
Validation loss: 2.2152606112949713

Epoch: 6| Step: 7
Training loss: 0.9547065995174169
Validation loss: 2.252545799358916

Epoch: 6| Step: 8
Training loss: 0.7272104634920212
Validation loss: 2.3086729140043274

Epoch: 6| Step: 9
Training loss: 0.8587302823975024
Validation loss: 2.3194954692764487

Epoch: 6| Step: 10
Training loss: 1.0658940912386594
Validation loss: 2.212537111981835

Epoch: 6| Step: 11
Training loss: 0.6228318994527877
Validation loss: 2.241037676577348

Epoch: 6| Step: 12
Training loss: 0.5956079876082297
Validation loss: 2.232078283427734

Epoch: 6| Step: 13
Training loss: 2.1667715805280072
Validation loss: 2.1932825530101803

Epoch: 508| Step: 0
Training loss: 0.8353918558623771
Validation loss: 2.259141677439115

Epoch: 6| Step: 1
Training loss: 1.0240621043982394
Validation loss: 2.270750297329521

Epoch: 6| Step: 2
Training loss: 0.6175631092424865
Validation loss: 2.2368259218191113

Epoch: 6| Step: 3
Training loss: 0.7169303665797254
Validation loss: 2.243634282864179

Epoch: 6| Step: 4
Training loss: 0.6562113296377728
Validation loss: 2.2134354807063543

Epoch: 6| Step: 5
Training loss: 0.46314250354405817
Validation loss: 2.202362793281264

Epoch: 6| Step: 6
Training loss: 0.8899398979509947
Validation loss: 2.2242928105703013

Epoch: 6| Step: 7
Training loss: 0.7230841117515593
Validation loss: 2.287472975582639

Epoch: 6| Step: 8
Training loss: 1.8235565225153032
Validation loss: 2.202771702719993

Epoch: 6| Step: 9
Training loss: 0.7494723530226125
Validation loss: 2.2635682713588796

Epoch: 6| Step: 10
Training loss: 0.5278292646167954
Validation loss: 2.1703096640276334

Epoch: 6| Step: 11
Training loss: 0.43365271914779896
Validation loss: 2.246739790833949

Epoch: 6| Step: 12
Training loss: 0.7201569925123555
Validation loss: 2.249770862665816

Epoch: 6| Step: 13
Training loss: 1.0631340603271353
Validation loss: 2.2165553417589203

Epoch: 509| Step: 0
Training loss: 0.826517055538578
Validation loss: 2.2405998454769533

Epoch: 6| Step: 1
Training loss: 0.8122257723566175
Validation loss: 2.234962207802908

Epoch: 6| Step: 2
Training loss: 0.8821679522098198
Validation loss: 2.2159661485683695

Epoch: 6| Step: 3
Training loss: 0.7387416957898408
Validation loss: 2.3021370640155747

Epoch: 6| Step: 4
Training loss: 0.8116020963261033
Validation loss: 2.2714118307207447

Epoch: 6| Step: 5
Training loss: 0.9490076466102565
Validation loss: 2.1723674370244694

Epoch: 6| Step: 6
Training loss: 0.7426379794219519
Validation loss: 2.16341203463782

Epoch: 6| Step: 7
Training loss: 0.7877201711079106
Validation loss: 2.2271661446402184

Epoch: 6| Step: 8
Training loss: 0.7112180554502089
Validation loss: 2.1932550799484907

Epoch: 6| Step: 9
Training loss: 0.8290249594806691
Validation loss: 2.2394493007593095

Epoch: 6| Step: 10
Training loss: 0.4638749292631103
Validation loss: 2.2436742790781974

Epoch: 6| Step: 11
Training loss: 0.7254913391632157
Validation loss: 2.2116865316004057

Epoch: 6| Step: 12
Training loss: 1.7379497769235923
Validation loss: 2.18756787711923

Epoch: 6| Step: 13
Training loss: 0.9374409021188282
Validation loss: 2.164472014709356

Epoch: 510| Step: 0
Training loss: 0.6862198007605887
Validation loss: 2.193867204403758

Epoch: 6| Step: 1
Training loss: 0.9008387114699247
Validation loss: 2.249776857629853

Epoch: 6| Step: 2
Training loss: 0.7095458694561432
Validation loss: 2.218157180513261

Epoch: 6| Step: 3
Training loss: 0.7166801586285761
Validation loss: 2.2413345640614835

Epoch: 6| Step: 4
Training loss: 0.8335041745223764
Validation loss: 2.3032677422484147

Epoch: 6| Step: 5
Training loss: 0.5692905519170186
Validation loss: 2.3205085020566965

Epoch: 6| Step: 6
Training loss: 0.9047866714226048
Validation loss: 2.2899317561035506

Epoch: 6| Step: 7
Training loss: 0.7275934186253995
Validation loss: 2.207390204404016

Epoch: 6| Step: 8
Training loss: 1.7036737380448568
Validation loss: 2.267730353631908

Epoch: 6| Step: 9
Training loss: 0.9879561782995101
Validation loss: 2.2245249375996674

Epoch: 6| Step: 10
Training loss: 1.080494364161094
Validation loss: 2.3206623744875006

Epoch: 6| Step: 11
Training loss: 0.7903526259161423
Validation loss: 2.2729380666931225

Epoch: 6| Step: 12
Training loss: 0.7076575945510607
Validation loss: 2.201884568440903

Epoch: 6| Step: 13
Training loss: 0.6747380622621856
Validation loss: 2.16876839898314

Epoch: 511| Step: 0
Training loss: 0.8324642934960221
Validation loss: 2.2164885076204612

Epoch: 6| Step: 1
Training loss: 0.526844438184604
Validation loss: 2.181752766381014

Epoch: 6| Step: 2
Training loss: 0.8159794764275188
Validation loss: 2.2147514505030834

Epoch: 6| Step: 3
Training loss: 0.9983097036417223
Validation loss: 2.188684067449464

Epoch: 6| Step: 4
Training loss: 0.6889033732848433
Validation loss: 2.223294844568741

Epoch: 6| Step: 5
Training loss: 0.9064828639275534
Validation loss: 2.210661218010599

Epoch: 6| Step: 6
Training loss: 0.6880985818654546
Validation loss: 2.237471209597658

Epoch: 6| Step: 7
Training loss: 0.9145664879732731
Validation loss: 2.1932483694278866

Epoch: 6| Step: 8
Training loss: 0.9782115288629285
Validation loss: 2.20225721805033

Epoch: 6| Step: 9
Training loss: 0.7370134397339785
Validation loss: 2.239867613355148

Epoch: 6| Step: 10
Training loss: 0.6447122030846115
Validation loss: 2.20378084529235

Epoch: 6| Step: 11
Training loss: 0.7496865332701772
Validation loss: 2.2722143565985156

Epoch: 6| Step: 12
Training loss: 0.6924046995849165
Validation loss: 2.196042132249167

Epoch: 6| Step: 13
Training loss: 2.1804565385608434
Validation loss: 2.2580829101756734

Epoch: 512| Step: 0
Training loss: 0.6555368999567416
Validation loss: 2.258070941628779

Epoch: 6| Step: 1
Training loss: 0.5789454540821075
Validation loss: 2.2954764467881454

Epoch: 6| Step: 2
Training loss: 0.9185691979973811
Validation loss: 2.2518556330748782

Epoch: 6| Step: 3
Training loss: 0.6519905550424742
Validation loss: 2.2192686561709545

Epoch: 6| Step: 4
Training loss: 1.6215292472024923
Validation loss: 2.1798046532071758

Epoch: 6| Step: 5
Training loss: 0.5487732775015494
Validation loss: 2.232287940330665

Epoch: 6| Step: 6
Training loss: 0.8692482185202889
Validation loss: 2.2033445001221494

Epoch: 6| Step: 7
Training loss: 1.0082556171785721
Validation loss: 2.178753933468259

Epoch: 6| Step: 8
Training loss: 0.7174409472524513
Validation loss: 2.162951015063662

Epoch: 6| Step: 9
Training loss: 0.6805266538525135
Validation loss: 2.25749894778125

Epoch: 6| Step: 10
Training loss: 0.7061132298597911
Validation loss: 2.19144028450083

Epoch: 6| Step: 11
Training loss: 0.6169028048060905
Validation loss: 2.247088238526876

Epoch: 6| Step: 12
Training loss: 1.0781554618623153
Validation loss: 2.163205913832246

Epoch: 6| Step: 13
Training loss: 0.9009454304600472
Validation loss: 2.186095077512592

Epoch: 513| Step: 0
Training loss: 0.5646423497856524
Validation loss: 2.2078762134689027

Epoch: 6| Step: 1
Training loss: 0.9483304989330481
Validation loss: 2.281460179069493

Epoch: 6| Step: 2
Training loss: 0.7626615900260295
Validation loss: 2.1968510321880093

Epoch: 6| Step: 3
Training loss: 0.9904796589992169
Validation loss: 2.23188995040764

Epoch: 6| Step: 4
Training loss: 0.619786452156592
Validation loss: 2.2959233301215254

Epoch: 6| Step: 5
Training loss: 1.6187024231035045
Validation loss: 2.2309581660071687

Epoch: 6| Step: 6
Training loss: 0.4698602878614588
Validation loss: 2.2136007782911014

Epoch: 6| Step: 7
Training loss: 0.8697524756703089
Validation loss: 2.2008530186120914

Epoch: 6| Step: 8
Training loss: 0.8510663398207265
Validation loss: 2.259139804475297

Epoch: 6| Step: 9
Training loss: 0.5360259625353065
Validation loss: 2.153265653546247

Epoch: 6| Step: 10
Training loss: 0.6595940989734089
Validation loss: 2.228648669133383

Epoch: 6| Step: 11
Training loss: 0.5958550681527102
Validation loss: 2.149350029392709

Epoch: 6| Step: 12
Training loss: 0.8147176409063398
Validation loss: 2.2443868957709245

Epoch: 6| Step: 13
Training loss: 0.8505353770245792
Validation loss: 2.192351411991572

Epoch: 514| Step: 0
Training loss: 0.5384721149071345
Validation loss: 2.253152869208369

Epoch: 6| Step: 1
Training loss: 0.6341737070791437
Validation loss: 2.2227942688826055

Epoch: 6| Step: 2
Training loss: 0.686100575867703
Validation loss: 2.1853279311208014

Epoch: 6| Step: 3
Training loss: 0.9201370279225338
Validation loss: 2.231450753541812

Epoch: 6| Step: 4
Training loss: 0.8082112683881102
Validation loss: 2.2112882730045436

Epoch: 6| Step: 5
Training loss: 0.940772131885336
Validation loss: 2.2456957700882114

Epoch: 6| Step: 6
Training loss: 0.7477936876467752
Validation loss: 2.279231343835758

Epoch: 6| Step: 7
Training loss: 0.8084537550770641
Validation loss: 2.1807458402992355

Epoch: 6| Step: 8
Training loss: 0.7644717035389732
Validation loss: 2.207250846575898

Epoch: 6| Step: 9
Training loss: 1.613749807817254
Validation loss: 2.163731305447231

Epoch: 6| Step: 10
Training loss: 0.6364895460734152
Validation loss: 2.178110767138567

Epoch: 6| Step: 11
Training loss: 0.7441715023813479
Validation loss: 2.20034776038436

Epoch: 6| Step: 12
Training loss: 0.5575761663042503
Validation loss: 2.2631775793603244

Epoch: 6| Step: 13
Training loss: 1.0072733893539398
Validation loss: 2.172464218355704

Epoch: 515| Step: 0
Training loss: 0.7201941949502884
Validation loss: 2.209668278010943

Epoch: 6| Step: 1
Training loss: 0.5637815499622889
Validation loss: 2.2493869500062083

Epoch: 6| Step: 2
Training loss: 0.670983743588645
Validation loss: 2.253516147894819

Epoch: 6| Step: 3
Training loss: 0.57189674336106
Validation loss: 2.2239821526093175

Epoch: 6| Step: 4
Training loss: 0.7903045472287584
Validation loss: 2.2310852344748238

Epoch: 6| Step: 5
Training loss: 0.8029461138211202
Validation loss: 2.2407777532097786

Epoch: 6| Step: 6
Training loss: 0.8410515195962208
Validation loss: 2.21276789209569

Epoch: 6| Step: 7
Training loss: 0.6909067105835198
Validation loss: 2.219052596994619

Epoch: 6| Step: 8
Training loss: 0.6765980277303061
Validation loss: 2.226451228091804

Epoch: 6| Step: 9
Training loss: 0.9955654762995186
Validation loss: 2.2149207941001645

Epoch: 6| Step: 10
Training loss: 0.3781696119867665
Validation loss: 2.242665884693414

Epoch: 6| Step: 11
Training loss: 1.7000745700861948
Validation loss: 2.192532993861213

Epoch: 6| Step: 12
Training loss: 0.6959745705387582
Validation loss: 2.2696069154789296

Epoch: 6| Step: 13
Training loss: 0.38015629355622027
Validation loss: 2.24450939653494

Epoch: 516| Step: 0
Training loss: 0.7426279868974576
Validation loss: 2.282986186888298

Epoch: 6| Step: 1
Training loss: 0.8857345160138428
Validation loss: 2.2743069443307977

Epoch: 6| Step: 2
Training loss: 0.8861333452289973
Validation loss: 2.1987781818122913

Epoch: 6| Step: 3
Training loss: 0.5321054303274091
Validation loss: 2.2223280970756054

Epoch: 6| Step: 4
Training loss: 0.9435196260615548
Validation loss: 2.1895283484708576

Epoch: 6| Step: 5
Training loss: 0.5860968309574206
Validation loss: 2.212063884978478

Epoch: 6| Step: 6
Training loss: 1.6823205935547156
Validation loss: 2.19128558253817

Epoch: 6| Step: 7
Training loss: 0.5220233546473196
Validation loss: 2.2835781574995684

Epoch: 6| Step: 8
Training loss: 0.872233752476828
Validation loss: 2.2452995944396714

Epoch: 6| Step: 9
Training loss: 0.8620142204479141
Validation loss: 2.172680349965917

Epoch: 6| Step: 10
Training loss: 0.5511901636151215
Validation loss: 2.271528809427708

Epoch: 6| Step: 11
Training loss: 0.8440245428946269
Validation loss: 2.1922277221446596

Epoch: 6| Step: 12
Training loss: 0.6492953772832244
Validation loss: 2.2714664157776836

Epoch: 6| Step: 13
Training loss: 0.7545016215833424
Validation loss: 2.2955240385853535

Epoch: 517| Step: 0
Training loss: 0.8774507126184615
Validation loss: 2.177935458294831

Epoch: 6| Step: 1
Training loss: 1.6719096527786552
Validation loss: 2.29929861312798

Epoch: 6| Step: 2
Training loss: 0.8194901476972445
Validation loss: 2.231755251513036

Epoch: 6| Step: 3
Training loss: 0.7210868909515799
Validation loss: 2.14530848643366

Epoch: 6| Step: 4
Training loss: 0.7999608745544191
Validation loss: 2.242246535775537

Epoch: 6| Step: 5
Training loss: 0.8762773318524338
Validation loss: 2.257688770806391

Epoch: 6| Step: 6
Training loss: 0.8195083309492585
Validation loss: 2.2753098675401358

Epoch: 6| Step: 7
Training loss: 0.6202262241891304
Validation loss: 2.2642625162400427

Epoch: 6| Step: 8
Training loss: 0.7594935854401721
Validation loss: 2.1987488973172273

Epoch: 6| Step: 9
Training loss: 0.6775599978157699
Validation loss: 2.1741507007222047

Epoch: 6| Step: 10
Training loss: 0.6712078952193101
Validation loss: 2.272418908476082

Epoch: 6| Step: 11
Training loss: 0.7249639008841364
Validation loss: 2.2587046384472687

Epoch: 6| Step: 12
Training loss: 0.6931795128728563
Validation loss: 2.2593700476677685

Epoch: 6| Step: 13
Training loss: 0.9076941920286387
Validation loss: 2.2658228543473142

Epoch: 518| Step: 0
Training loss: 0.945586109760978
Validation loss: 2.2503602475546556

Epoch: 6| Step: 1
Training loss: 1.6703315812279784
Validation loss: 2.337189312653414

Epoch: 6| Step: 2
Training loss: 0.7305970104850802
Validation loss: 2.2765318745155247

Epoch: 6| Step: 3
Training loss: 0.8761524036708228
Validation loss: 2.1947692180169422

Epoch: 6| Step: 4
Training loss: 1.0610498742435834
Validation loss: 2.248627172064189

Epoch: 6| Step: 5
Training loss: 0.9134786322380404
Validation loss: 2.213347167723821

Epoch: 6| Step: 6
Training loss: 0.4628154838512188
Validation loss: 2.3017729057743574

Epoch: 6| Step: 7
Training loss: 0.5683371156089346
Validation loss: 2.2254661055485285

Epoch: 6| Step: 8
Training loss: 0.6542018536703822
Validation loss: 2.2229015328106563

Epoch: 6| Step: 9
Training loss: 0.5717103366696695
Validation loss: 2.206192046098616

Epoch: 6| Step: 10
Training loss: 0.8034389401767543
Validation loss: 2.2158191092494612

Epoch: 6| Step: 11
Training loss: 0.6505285351686462
Validation loss: 2.222873284626939

Epoch: 6| Step: 12
Training loss: 0.8183606860166259
Validation loss: 2.219540339845081

Epoch: 6| Step: 13
Training loss: 0.815692388739553
Validation loss: 2.246985662072116

Epoch: 519| Step: 0
Training loss: 0.7683472020048452
Validation loss: 2.1533888800824204

Epoch: 6| Step: 1
Training loss: 0.5263077060022241
Validation loss: 2.263173246543091

Epoch: 6| Step: 2
Training loss: 0.7888330560352325
Validation loss: 2.200322570626269

Epoch: 6| Step: 3
Training loss: 0.5816608761041021
Validation loss: 2.2522220691286976

Epoch: 6| Step: 4
Training loss: 0.651940866655652
Validation loss: 2.197660932742272

Epoch: 6| Step: 5
Training loss: 0.6820719100525339
Validation loss: 2.203361984303574

Epoch: 6| Step: 6
Training loss: 0.6871298313619868
Validation loss: 2.2598495857066476

Epoch: 6| Step: 7
Training loss: 1.5955520614407486
Validation loss: 2.240180659115702

Epoch: 6| Step: 8
Training loss: 0.7700434495383627
Validation loss: 2.215953752979911

Epoch: 6| Step: 9
Training loss: 0.8164135873273193
Validation loss: 2.2153653180377204

Epoch: 6| Step: 10
Training loss: 0.9672750504267649
Validation loss: 2.2602794154346957

Epoch: 6| Step: 11
Training loss: 0.5806762488735521
Validation loss: 2.2197959233675872

Epoch: 6| Step: 12
Training loss: 0.6350571887103262
Validation loss: 2.1696596109806436

Epoch: 6| Step: 13
Training loss: 0.6419516759240725
Validation loss: 2.1565786143687236

Epoch: 520| Step: 0
Training loss: 0.9004930284898521
Validation loss: 2.221917191929194

Epoch: 6| Step: 1
Training loss: 0.821922067375067
Validation loss: 2.2033291648438214

Epoch: 6| Step: 2
Training loss: 0.6737272325253618
Validation loss: 2.2104991114563073

Epoch: 6| Step: 3
Training loss: 0.6976065777121826
Validation loss: 2.229890505353384

Epoch: 6| Step: 4
Training loss: 0.7821289077741642
Validation loss: 2.2089830403651085

Epoch: 6| Step: 5
Training loss: 1.6373225807578276
Validation loss: 2.196342536953277

Epoch: 6| Step: 6
Training loss: 0.5141995986344156
Validation loss: 2.2052655747230014

Epoch: 6| Step: 7
Training loss: 0.5898655767381289
Validation loss: 2.2656362231312173

Epoch: 6| Step: 8
Training loss: 0.958796403102629
Validation loss: 2.1862891096459887

Epoch: 6| Step: 9
Training loss: 1.0335688097100828
Validation loss: 2.259792628673643

Epoch: 6| Step: 10
Training loss: 0.7711053230939947
Validation loss: 2.1770108255977716

Epoch: 6| Step: 11
Training loss: 0.7031170102831106
Validation loss: 2.1988578472134326

Epoch: 6| Step: 12
Training loss: 0.6318710765471558
Validation loss: 2.193762758204642

Epoch: 6| Step: 13
Training loss: 0.6060448397722399
Validation loss: 2.1833513264625815

Epoch: 521| Step: 0
Training loss: 0.8324673007007497
Validation loss: 2.2524071228769174

Epoch: 6| Step: 1
Training loss: 0.6642990364219893
Validation loss: 2.178169840948453

Epoch: 6| Step: 2
Training loss: 0.5950589057870711
Validation loss: 2.178850137558417

Epoch: 6| Step: 3
Training loss: 0.9861741956193792
Validation loss: 2.1400605192416235

Epoch: 6| Step: 4
Training loss: 0.6654846670303228
Validation loss: 2.1444381513447808

Epoch: 6| Step: 5
Training loss: 0.8253721871507923
Validation loss: 2.254508706962464

Epoch: 6| Step: 6
Training loss: 0.6892721138451715
Validation loss: 2.2351503834620896

Epoch: 6| Step: 7
Training loss: 0.8301385835059815
Validation loss: 2.1583973062378177

Epoch: 6| Step: 8
Training loss: 1.1241512275655503
Validation loss: 2.251379276221619

Epoch: 6| Step: 9
Training loss: 0.66274685399256
Validation loss: 2.2294948897080977

Epoch: 6| Step: 10
Training loss: 0.8786023101850947
Validation loss: 2.172656702584204

Epoch: 6| Step: 11
Training loss: 0.9164128204916674
Validation loss: 2.199189685281293

Epoch: 6| Step: 12
Training loss: 1.676196422588289
Validation loss: 2.200108295722948

Epoch: 6| Step: 13
Training loss: 0.42149512530909805
Validation loss: 2.1751601429786787

Epoch: 522| Step: 0
Training loss: 0.5225995886956168
Validation loss: 2.189567198575411

Epoch: 6| Step: 1
Training loss: 0.6429750787509265
Validation loss: 2.180284522815788

Epoch: 6| Step: 2
Training loss: 0.5691673068335728
Validation loss: 2.265602130371357

Epoch: 6| Step: 3
Training loss: 0.8887284480941025
Validation loss: 2.167589514859237

Epoch: 6| Step: 4
Training loss: 0.43458601676768344
Validation loss: 2.2797832648238163

Epoch: 6| Step: 5
Training loss: 0.9289250813878156
Validation loss: 2.233222117277396

Epoch: 6| Step: 6
Training loss: 0.547424313003688
Validation loss: 2.2051384768796756

Epoch: 6| Step: 7
Training loss: 1.063433517551728
Validation loss: 2.2004590019912267

Epoch: 6| Step: 8
Training loss: 0.6983871202839027
Validation loss: 2.297596151700663

Epoch: 6| Step: 9
Training loss: 0.6282572744595776
Validation loss: 2.154973051908955

Epoch: 6| Step: 10
Training loss: 1.7143714619376471
Validation loss: 2.2393006356445815

Epoch: 6| Step: 11
Training loss: 1.093448488366144
Validation loss: 2.1524847933690245

Epoch: 6| Step: 12
Training loss: 0.8421809831413127
Validation loss: 2.172248232826451

Epoch: 6| Step: 13
Training loss: 0.6269486566782456
Validation loss: 2.22200085445754

Epoch: 523| Step: 0
Training loss: 0.6656161813644295
Validation loss: 2.2364467450572967

Epoch: 6| Step: 1
Training loss: 0.5283863075766487
Validation loss: 2.2264372667528924

Epoch: 6| Step: 2
Training loss: 0.43324791803096374
Validation loss: 2.190079416670682

Epoch: 6| Step: 3
Training loss: 0.8796678422320356
Validation loss: 2.1681936253651606

Epoch: 6| Step: 4
Training loss: 0.7344012154303157
Validation loss: 2.2003669402926307

Epoch: 6| Step: 5
Training loss: 0.6963484044622419
Validation loss: 2.219223526543782

Epoch: 6| Step: 6
Training loss: 0.8754860685951369
Validation loss: 2.2614755277443415

Epoch: 6| Step: 7
Training loss: 0.7910466694332488
Validation loss: 2.2124577241945027

Epoch: 6| Step: 8
Training loss: 0.8751219936886431
Validation loss: 2.2795935311729627

Epoch: 6| Step: 9
Training loss: 0.8330826541243703
Validation loss: 2.2123056380020514

Epoch: 6| Step: 10
Training loss: 0.922116231875873
Validation loss: 2.3071110022569012

Epoch: 6| Step: 11
Training loss: 0.4752378658710168
Validation loss: 2.2001507063302177

Epoch: 6| Step: 12
Training loss: 1.6550279103256564
Validation loss: 2.2396742847820987

Epoch: 6| Step: 13
Training loss: 0.5225288133114399
Validation loss: 2.154114231248886

Epoch: 524| Step: 0
Training loss: 0.7225869635281554
Validation loss: 2.207635493738144

Epoch: 6| Step: 1
Training loss: 0.6451936034985805
Validation loss: 2.1840109850546257

Epoch: 6| Step: 2
Training loss: 0.8187840709440405
Validation loss: 2.213019925517891

Epoch: 6| Step: 3
Training loss: 0.640798266170242
Validation loss: 2.1469355996866457

Epoch: 6| Step: 4
Training loss: 0.835922454983807
Validation loss: 2.191454068715175

Epoch: 6| Step: 5
Training loss: 0.6378613382917635
Validation loss: 2.22238894891646

Epoch: 6| Step: 6
Training loss: 0.8484654234054919
Validation loss: 2.2822209852748827

Epoch: 6| Step: 7
Training loss: 1.5607835878970862
Validation loss: 2.2853356417798656

Epoch: 6| Step: 8
Training loss: 0.5962434913072079
Validation loss: 2.2905032056198698

Epoch: 6| Step: 9
Training loss: 0.9807675578820877
Validation loss: 2.2059724725390217

Epoch: 6| Step: 10
Training loss: 0.5047366375224274
Validation loss: 2.2466764000925563

Epoch: 6| Step: 11
Training loss: 0.9139548344252038
Validation loss: 2.2288730793337397

Epoch: 6| Step: 12
Training loss: 0.8145404284040785
Validation loss: 2.2304337105131316

Epoch: 6| Step: 13
Training loss: 0.5626652262998438
Validation loss: 2.2169716175677086

Epoch: 525| Step: 0
Training loss: 0.5593560359446733
Validation loss: 2.1655720078446627

Epoch: 6| Step: 1
Training loss: 0.6361492863443682
Validation loss: 2.2742502208663082

Epoch: 6| Step: 2
Training loss: 0.8408742216153977
Validation loss: 2.2334439269397857

Epoch: 6| Step: 3
Training loss: 0.8190085083050269
Validation loss: 2.3000356304945337

Epoch: 6| Step: 4
Training loss: 0.753622683626716
Validation loss: 2.219564615024778

Epoch: 6| Step: 5
Training loss: 0.7092468784601084
Validation loss: 2.1977985453176667

Epoch: 6| Step: 6
Training loss: 0.9249079967829895
Validation loss: 2.1743455296205267

Epoch: 6| Step: 7
Training loss: 0.9517396332937986
Validation loss: 2.171584651647046

Epoch: 6| Step: 8
Training loss: 0.6468745088805762
Validation loss: 2.1312986519490287

Epoch: 6| Step: 9
Training loss: 0.8983750031337099
Validation loss: 2.189825884689476

Epoch: 6| Step: 10
Training loss: 1.5793323242073705
Validation loss: 2.2774977741604516

Epoch: 6| Step: 11
Training loss: 0.7010000544342586
Validation loss: 2.2164977082447592

Epoch: 6| Step: 12
Training loss: 0.5999991178506089
Validation loss: 2.210918786902282

Epoch: 6| Step: 13
Training loss: 0.43291056998913124
Validation loss: 2.215631031421746

Epoch: 526| Step: 0
Training loss: 0.7498482709630313
Validation loss: 2.263941766499794

Epoch: 6| Step: 1
Training loss: 1.6241518154545052
Validation loss: 2.238739369383651

Epoch: 6| Step: 2
Training loss: 0.8802610678742138
Validation loss: 2.1376528716626497

Epoch: 6| Step: 3
Training loss: 0.7734240906448856
Validation loss: 2.211303017474227

Epoch: 6| Step: 4
Training loss: 0.689675443861089
Validation loss: 2.2257538952633387

Epoch: 6| Step: 5
Training loss: 0.4867945200324854
Validation loss: 2.2841518576314495

Epoch: 6| Step: 6
Training loss: 0.7207288453182763
Validation loss: 2.2182703159707744

Epoch: 6| Step: 7
Training loss: 0.7237266242908703
Validation loss: 2.1979900956894642

Epoch: 6| Step: 8
Training loss: 0.5229072732069049
Validation loss: 2.2859815536359966

Epoch: 6| Step: 9
Training loss: 0.7514803105894886
Validation loss: 2.234392421501608

Epoch: 6| Step: 10
Training loss: 0.8522040374124856
Validation loss: 2.1762799347123614

Epoch: 6| Step: 11
Training loss: 0.6688087713852208
Validation loss: 2.218966577345015

Epoch: 6| Step: 12
Training loss: 0.7156083650612889
Validation loss: 2.2702267982550697

Epoch: 6| Step: 13
Training loss: 0.8841411753247685
Validation loss: 2.1789850591022426

Epoch: 527| Step: 0
Training loss: 1.1239412942230578
Validation loss: 2.2596956128173997

Epoch: 6| Step: 1
Training loss: 0.6775264805900854
Validation loss: 2.211162931477485

Epoch: 6| Step: 2
Training loss: 0.935504251357286
Validation loss: 2.2258220104050035

Epoch: 6| Step: 3
Training loss: 0.8726523786030327
Validation loss: 2.145383879960468

Epoch: 6| Step: 4
Training loss: 0.7438635923690069
Validation loss: 2.2258683152100325

Epoch: 6| Step: 5
Training loss: 0.46315669207432475
Validation loss: 2.233770044055759

Epoch: 6| Step: 6
Training loss: 0.3969456474622473
Validation loss: 2.1660646356694744

Epoch: 6| Step: 7
Training loss: 0.6762644192609136
Validation loss: 2.226205896484454

Epoch: 6| Step: 8
Training loss: 0.70171503052865
Validation loss: 2.229653072412606

Epoch: 6| Step: 9
Training loss: 1.6270964377344044
Validation loss: 2.257259263220316

Epoch: 6| Step: 10
Training loss: 0.9098734272973259
Validation loss: 2.2608186483360018

Epoch: 6| Step: 11
Training loss: 0.7886686191803385
Validation loss: 2.283402792970901

Epoch: 6| Step: 12
Training loss: 0.5482069416628164
Validation loss: 2.204483098869116

Epoch: 6| Step: 13
Training loss: 0.4821451451358296
Validation loss: 2.2736551101496496

Epoch: 528| Step: 0
Training loss: 0.7224873525839102
Validation loss: 2.209790451608544

Epoch: 6| Step: 1
Training loss: 0.8850687278311324
Validation loss: 2.1908046211029064

Epoch: 6| Step: 2
Training loss: 0.6247407852506875
Validation loss: 2.333616252929244

Epoch: 6| Step: 3
Training loss: 0.5897433719739597
Validation loss: 2.152286901378903

Epoch: 6| Step: 4
Training loss: 0.6185156860197345
Validation loss: 2.1830943943998693

Epoch: 6| Step: 5
Training loss: 0.8928248358739836
Validation loss: 2.1945775763434248

Epoch: 6| Step: 6
Training loss: 0.5438395042856499
Validation loss: 2.2100597497237726

Epoch: 6| Step: 7
Training loss: 0.6486380852838466
Validation loss: 2.236012698562671

Epoch: 6| Step: 8
Training loss: 0.7760180185969091
Validation loss: 2.1688129750553093

Epoch: 6| Step: 9
Training loss: 0.5183127318312402
Validation loss: 2.219834974209708

Epoch: 6| Step: 10
Training loss: 1.587100199420083
Validation loss: 2.2249623848405307

Epoch: 6| Step: 11
Training loss: 0.6278567590678229
Validation loss: 2.220885386606612

Epoch: 6| Step: 12
Training loss: 0.983615218724357
Validation loss: 2.2812766819347488

Epoch: 6| Step: 13
Training loss: 0.8842320464826965
Validation loss: 2.1973445092993353

Epoch: 529| Step: 0
Training loss: 0.7427984834792146
Validation loss: 2.1850655024773267

Epoch: 6| Step: 1
Training loss: 1.0865410424286877
Validation loss: 2.2143178124641576

Epoch: 6| Step: 2
Training loss: 0.5920652781755262
Validation loss: 2.3016003020420825

Epoch: 6| Step: 3
Training loss: 0.5806795335666007
Validation loss: 2.16993116939807

Epoch: 6| Step: 4
Training loss: 0.8236043366540804
Validation loss: 2.2314944376415933

Epoch: 6| Step: 5
Training loss: 1.6846385289629944
Validation loss: 2.2229656753314244

Epoch: 6| Step: 6
Training loss: 0.5916222292595225
Validation loss: 2.1714916479640842

Epoch: 6| Step: 7
Training loss: 0.8065358756636014
Validation loss: 2.1756062875356736

Epoch: 6| Step: 8
Training loss: 0.7564364652660472
Validation loss: 2.2433769795782124

Epoch: 6| Step: 9
Training loss: 0.6842312047730352
Validation loss: 2.211938864693329

Epoch: 6| Step: 10
Training loss: 0.7340476747252397
Validation loss: 2.2072522548495805

Epoch: 6| Step: 11
Training loss: 0.8962987237984414
Validation loss: 2.1725823610960737

Epoch: 6| Step: 12
Training loss: 0.6349541721552674
Validation loss: 2.1953719165398535

Epoch: 6| Step: 13
Training loss: 0.42527052670118015
Validation loss: 2.2776637278464267

Epoch: 530| Step: 0
Training loss: 0.6891444436479857
Validation loss: 2.276305347398255

Epoch: 6| Step: 1
Training loss: 0.5800301888435982
Validation loss: 2.289558343221799

Epoch: 6| Step: 2
Training loss: 0.8271410873068495
Validation loss: 2.1944286903077876

Epoch: 6| Step: 3
Training loss: 0.6522780059761564
Validation loss: 2.264830899136777

Epoch: 6| Step: 4
Training loss: 0.5028190417009404
Validation loss: 2.3233259287399695

Epoch: 6| Step: 5
Training loss: 0.9219713645613271
Validation loss: 2.2373515470030743

Epoch: 6| Step: 6
Training loss: 0.6619845022191106
Validation loss: 2.209389232927256

Epoch: 6| Step: 7
Training loss: 0.9041430216801731
Validation loss: 2.173003372137668

Epoch: 6| Step: 8
Training loss: 0.5720090583887631
Validation loss: 2.1651629791394256

Epoch: 6| Step: 9
Training loss: 0.5979973810546836
Validation loss: 2.191261629354857

Epoch: 6| Step: 10
Training loss: 0.5659102273959572
Validation loss: 2.120609752550806

Epoch: 6| Step: 11
Training loss: 1.6703557036533552
Validation loss: 2.266327710168395

Epoch: 6| Step: 12
Training loss: 0.9502064468029398
Validation loss: 2.203673918713801

Epoch: 6| Step: 13
Training loss: 0.6287257723377958
Validation loss: 2.1590089724039077

Epoch: 531| Step: 0
Training loss: 0.6867829398055316
Validation loss: 2.1298992001776553

Epoch: 6| Step: 1
Training loss: 0.5380980391621376
Validation loss: 2.253089718635377

Epoch: 6| Step: 2
Training loss: 0.5738273895861417
Validation loss: 2.184593586831609

Epoch: 6| Step: 3
Training loss: 0.8693451715723282
Validation loss: 2.1882173361132873

Epoch: 6| Step: 4
Training loss: 0.5018892952675242
Validation loss: 2.1942464019057932

Epoch: 6| Step: 5
Training loss: 0.6181980744416735
Validation loss: 2.236693594183784

Epoch: 6| Step: 6
Training loss: 0.6310548745157714
Validation loss: 2.1743277363583644

Epoch: 6| Step: 7
Training loss: 0.8527736625061255
Validation loss: 2.2025933812284286

Epoch: 6| Step: 8
Training loss: 0.9565550573109926
Validation loss: 2.2161561095620765

Epoch: 6| Step: 9
Training loss: 0.796146433755709
Validation loss: 2.16328811043293

Epoch: 6| Step: 10
Training loss: 0.5094517585631941
Validation loss: 2.2177517528820045

Epoch: 6| Step: 11
Training loss: 1.6363433917315315
Validation loss: 2.262375318488453

Epoch: 6| Step: 12
Training loss: 0.868325869539757
Validation loss: 2.2532313442844094

Epoch: 6| Step: 13
Training loss: 0.800708674421759
Validation loss: 2.1957923464878384

Epoch: 532| Step: 0
Training loss: 0.7136536577610871
Validation loss: 2.1507385186487586

Epoch: 6| Step: 1
Training loss: 0.6914366807006076
Validation loss: 2.2731186231853897

Epoch: 6| Step: 2
Training loss: 0.4833898370151106
Validation loss: 2.2016537508074476

Epoch: 6| Step: 3
Training loss: 0.7149678106998343
Validation loss: 2.138461359728535

Epoch: 6| Step: 4
Training loss: 1.61373518129573
Validation loss: 2.145616864728085

Epoch: 6| Step: 5
Training loss: 0.6925280032710301
Validation loss: 2.1885189724338585

Epoch: 6| Step: 6
Training loss: 0.8250983006261169
Validation loss: 2.1772559538563665

Epoch: 6| Step: 7
Training loss: 0.5764276486377754
Validation loss: 2.1750571920197284

Epoch: 6| Step: 8
Training loss: 0.7995946885601876
Validation loss: 2.1713456277226286

Epoch: 6| Step: 9
Training loss: 1.0832588035671238
Validation loss: 2.176029022060205

Epoch: 6| Step: 10
Training loss: 0.7070923668174384
Validation loss: 2.2198871735460846

Epoch: 6| Step: 11
Training loss: 0.5685085087863279
Validation loss: 2.2406053157758743

Epoch: 6| Step: 12
Training loss: 0.9004447076736326
Validation loss: 2.1605287448899877

Epoch: 6| Step: 13
Training loss: 0.6370964568212489
Validation loss: 2.2024310364569257

Epoch: 533| Step: 0
Training loss: 0.8600550648337603
Validation loss: 2.25050036473662

Epoch: 6| Step: 1
Training loss: 0.740480608485956
Validation loss: 2.214576435511511

Epoch: 6| Step: 2
Training loss: 1.7418145434862307
Validation loss: 2.178496201470875

Epoch: 6| Step: 3
Training loss: 0.8488399836576002
Validation loss: 2.194225479052579

Epoch: 6| Step: 4
Training loss: 0.7921157909795273
Validation loss: 2.143280643703229

Epoch: 6| Step: 5
Training loss: 0.5153580754970974
Validation loss: 2.2299166699892568

Epoch: 6| Step: 6
Training loss: 0.9521812394189543
Validation loss: 2.1463500500986035

Epoch: 6| Step: 7
Training loss: 0.7215410029602904
Validation loss: 2.2189807462778393

Epoch: 6| Step: 8
Training loss: 0.6634105623717742
Validation loss: 2.1956100557075904

Epoch: 6| Step: 9
Training loss: 0.5700760442636457
Validation loss: 2.1115830429304996

Epoch: 6| Step: 10
Training loss: 0.6462979235118035
Validation loss: 2.1777843991797283

Epoch: 6| Step: 11
Training loss: 0.792908238700087
Validation loss: 2.248715399161208

Epoch: 6| Step: 12
Training loss: 0.6148850190830885
Validation loss: 2.2626006503830594

Epoch: 6| Step: 13
Training loss: 0.8806312756284322
Validation loss: 2.219759116423503

Epoch: 534| Step: 0
Training loss: 0.5029338651316934
Validation loss: 2.2079467535684723

Epoch: 6| Step: 1
Training loss: 1.0516226423956487
Validation loss: 2.2498564509149546

Epoch: 6| Step: 2
Training loss: 0.9381882366543216
Validation loss: 2.1908128372294775

Epoch: 6| Step: 3
Training loss: 0.9430083891494421
Validation loss: 2.1739562868538425

Epoch: 6| Step: 4
Training loss: 0.5563203124280013
Validation loss: 2.207442896033795

Epoch: 6| Step: 5
Training loss: 0.519397087270188
Validation loss: 2.1524498630118605

Epoch: 6| Step: 6
Training loss: 0.7143079907485831
Validation loss: 2.1369230450137766

Epoch: 6| Step: 7
Training loss: 0.7232691459771964
Validation loss: 2.135694743092994

Epoch: 6| Step: 8
Training loss: 0.5990718955037979
Validation loss: 2.2231746636848024

Epoch: 6| Step: 9
Training loss: 0.8538688435087546
Validation loss: 2.1907302831379423

Epoch: 6| Step: 10
Training loss: 0.726810946081785
Validation loss: 2.1489198622365833

Epoch: 6| Step: 11
Training loss: 0.6481720254551813
Validation loss: 2.250403941946694

Epoch: 6| Step: 12
Training loss: 1.5733050778378743
Validation loss: 2.146912781046405

Epoch: 6| Step: 13
Training loss: 0.7944086465980619
Validation loss: 2.17487445608527

Epoch: 535| Step: 0
Training loss: 0.6614188134910473
Validation loss: 2.190855185556241

Epoch: 6| Step: 1
Training loss: 0.4928830243037205
Validation loss: 2.1758914471201534

Epoch: 6| Step: 2
Training loss: 0.8470264679422447
Validation loss: 2.2208887457122426

Epoch: 6| Step: 3
Training loss: 0.6063535071035561
Validation loss: 2.164149250823752

Epoch: 6| Step: 4
Training loss: 0.7168739963381459
Validation loss: 2.173223364206517

Epoch: 6| Step: 5
Training loss: 0.6812086950256793
Validation loss: 2.1768920935338767

Epoch: 6| Step: 6
Training loss: 1.6379039178877917
Validation loss: 2.12755522053693

Epoch: 6| Step: 7
Training loss: 0.6752398091408389
Validation loss: 2.227453713557003

Epoch: 6| Step: 8
Training loss: 0.8474015938895791
Validation loss: 2.257213825549568

Epoch: 6| Step: 9
Training loss: 0.6657012689799837
Validation loss: 2.204620787955133

Epoch: 6| Step: 10
Training loss: 0.7358950446774685
Validation loss: 2.2315121872221555

Epoch: 6| Step: 11
Training loss: 0.5238415596168682
Validation loss: 2.183068163566676

Epoch: 6| Step: 12
Training loss: 0.758067884377162
Validation loss: 2.1874206200420057

Epoch: 6| Step: 13
Training loss: 0.7896023782397652
Validation loss: 2.1934141592111884

Epoch: 536| Step: 0
Training loss: 0.7841471550108882
Validation loss: 2.23556560264905

Epoch: 6| Step: 1
Training loss: 0.5112081411708892
Validation loss: 2.205172988253617

Epoch: 6| Step: 2
Training loss: 0.6123606581712809
Validation loss: 2.226768238037576

Epoch: 6| Step: 3
Training loss: 0.7492524235927726
Validation loss: 2.2279153815196415

Epoch: 6| Step: 4
Training loss: 0.5901317777399991
Validation loss: 2.197119271676286

Epoch: 6| Step: 5
Training loss: 0.7758657695601624
Validation loss: 2.2656224919447774

Epoch: 6| Step: 6
Training loss: 0.6870386136015864
Validation loss: 2.28116487823818

Epoch: 6| Step: 7
Training loss: 0.6897263674377383
Validation loss: 2.1527937310834315

Epoch: 6| Step: 8
Training loss: 0.5084085927294132
Validation loss: 2.149031017429624

Epoch: 6| Step: 9
Training loss: 0.7725314603652257
Validation loss: 2.182481440362892

Epoch: 6| Step: 10
Training loss: 1.0933922863879544
Validation loss: 2.154554980432417

Epoch: 6| Step: 11
Training loss: 1.638671220272329
Validation loss: 2.2294499325884556

Epoch: 6| Step: 12
Training loss: 0.6582646553416152
Validation loss: 2.2429391856448957

Epoch: 6| Step: 13
Training loss: 0.5175689984362652
Validation loss: 2.227090411092139

Epoch: 537| Step: 0
Training loss: 1.6792903696818418
Validation loss: 2.2593136606462534

Epoch: 6| Step: 1
Training loss: 0.6868710241645243
Validation loss: 2.2423318635860334

Epoch: 6| Step: 2
Training loss: 0.6159533462537564
Validation loss: 2.2068200558733975

Epoch: 6| Step: 3
Training loss: 0.7418889700161572
Validation loss: 2.216192598079519

Epoch: 6| Step: 4
Training loss: 0.6753406300968022
Validation loss: 2.196024760229464

Epoch: 6| Step: 5
Training loss: 0.7497952897123067
Validation loss: 2.265670262196845

Epoch: 6| Step: 6
Training loss: 0.5786637038782774
Validation loss: 2.200526791602307

Epoch: 6| Step: 7
Training loss: 0.47643900662638966
Validation loss: 2.2025543418699502

Epoch: 6| Step: 8
Training loss: 0.7178909724532866
Validation loss: 2.240455319941464

Epoch: 6| Step: 9
Training loss: 0.5986083929610391
Validation loss: 2.2016003133666326

Epoch: 6| Step: 10
Training loss: 0.6765225704823452
Validation loss: 2.3018759648604137

Epoch: 6| Step: 11
Training loss: 0.5868221725152628
Validation loss: 2.221713064962373

Epoch: 6| Step: 12
Training loss: 0.8106887509374074
Validation loss: 2.1507257989760142

Epoch: 6| Step: 13
Training loss: 1.0721925804398065
Validation loss: 2.1913162952042256

Epoch: 538| Step: 0
Training loss: 0.7061353877419919
Validation loss: 2.1600132768622484

Epoch: 6| Step: 1
Training loss: 0.8353507219639907
Validation loss: 2.203741756589423

Epoch: 6| Step: 2
Training loss: 0.7001641557856251
Validation loss: 2.2068543425948977

Epoch: 6| Step: 3
Training loss: 0.7562092604579879
Validation loss: 2.190401738586919

Epoch: 6| Step: 4
Training loss: 0.7222762887434672
Validation loss: 2.2717715983002296

Epoch: 6| Step: 5
Training loss: 0.5431852389380638
Validation loss: 2.1981496469219772

Epoch: 6| Step: 6
Training loss: 0.5962309453226743
Validation loss: 2.1772137760964654

Epoch: 6| Step: 7
Training loss: 1.6512854683912521
Validation loss: 2.177951380823656

Epoch: 6| Step: 8
Training loss: 0.7511352847546292
Validation loss: 2.206646415604637

Epoch: 6| Step: 9
Training loss: 0.9215627238369395
Validation loss: 2.1708800140092572

Epoch: 6| Step: 10
Training loss: 0.4656095207764845
Validation loss: 2.2259636243943

Epoch: 6| Step: 11
Training loss: 0.6826725884086969
Validation loss: 2.1675149469439443

Epoch: 6| Step: 12
Training loss: 0.8598377715729066
Validation loss: 2.1247580123253833

Epoch: 6| Step: 13
Training loss: 0.5894363461603386
Validation loss: 2.2104103198778042

Epoch: 539| Step: 0
Training loss: 1.62956879312376
Validation loss: 2.167857169210572

Epoch: 6| Step: 1
Training loss: 0.7194569883844505
Validation loss: 2.1984581036707866

Epoch: 6| Step: 2
Training loss: 0.7043804827851606
Validation loss: 2.1718237389763573

Epoch: 6| Step: 3
Training loss: 0.8971662068539151
Validation loss: 2.1675590207038637

Epoch: 6| Step: 4
Training loss: 0.8208984825176016
Validation loss: 2.1169873347966526

Epoch: 6| Step: 5
Training loss: 0.5871947215693399
Validation loss: 2.1938590619414144

Epoch: 6| Step: 6
Training loss: 0.7037229326778509
Validation loss: 2.2057854199369977

Epoch: 6| Step: 7
Training loss: 0.7259481149949167
Validation loss: 2.1713730084465297

Epoch: 6| Step: 8
Training loss: 0.8350336768160498
Validation loss: 2.210162358634102

Epoch: 6| Step: 9
Training loss: 0.8142656069259198
Validation loss: 2.21673718920926

Epoch: 6| Step: 10
Training loss: 0.8939444270430671
Validation loss: 2.1828555180135676

Epoch: 6| Step: 11
Training loss: 0.7335256981693811
Validation loss: 2.2149167870350217

Epoch: 6| Step: 12
Training loss: 0.9985247697733042
Validation loss: 2.1758747430907914

Epoch: 6| Step: 13
Training loss: 0.42614933167579394
Validation loss: 2.2159663012785327

Epoch: 540| Step: 0
Training loss: 0.7018779291922368
Validation loss: 2.2665943135863054

Epoch: 6| Step: 1
Training loss: 0.4785909009618892
Validation loss: 2.1336268521890314

Epoch: 6| Step: 2
Training loss: 0.8210806746671295
Validation loss: 2.1699055137145566

Epoch: 6| Step: 3
Training loss: 0.5883510978743599
Validation loss: 2.207034557012269

Epoch: 6| Step: 4
Training loss: 0.6004075692639386
Validation loss: 2.1731528415843115

Epoch: 6| Step: 5
Training loss: 0.7685453033843789
Validation loss: 2.246655000150199

Epoch: 6| Step: 6
Training loss: 0.5597612677628849
Validation loss: 2.259295672193612

Epoch: 6| Step: 7
Training loss: 0.7960922286119233
Validation loss: 2.295369010379374

Epoch: 6| Step: 8
Training loss: 1.5143245348234269
Validation loss: 2.200397562320591

Epoch: 6| Step: 9
Training loss: 0.8275011699933312
Validation loss: 2.1598800865091565

Epoch: 6| Step: 10
Training loss: 0.5588638079671651
Validation loss: 2.2482702700314703

Epoch: 6| Step: 11
Training loss: 0.758281641200916
Validation loss: 2.2035657991099873

Epoch: 6| Step: 12
Training loss: 0.6904568161011875
Validation loss: 2.1540777337260235

Epoch: 6| Step: 13
Training loss: 0.942312255748017
Validation loss: 2.18856227413853

Epoch: 541| Step: 0
Training loss: 0.5021263150327792
Validation loss: 2.1254352061188952

Epoch: 6| Step: 1
Training loss: 0.5128191117273656
Validation loss: 2.205702399650422

Epoch: 6| Step: 2
Training loss: 0.7032546453692061
Validation loss: 2.200218693033253

Epoch: 6| Step: 3
Training loss: 0.6276442381754279
Validation loss: 2.147779741027963

Epoch: 6| Step: 4
Training loss: 0.6286126867329724
Validation loss: 2.2877854536773614

Epoch: 6| Step: 5
Training loss: 1.022384917631224
Validation loss: 2.147901693672093

Epoch: 6| Step: 6
Training loss: 0.616723719311785
Validation loss: 2.253492440947672

Epoch: 6| Step: 7
Training loss: 1.6392953480004981
Validation loss: 2.195280998341744

Epoch: 6| Step: 8
Training loss: 0.492706449100475
Validation loss: 2.122700778643388

Epoch: 6| Step: 9
Training loss: 0.523490561457588
Validation loss: 2.151629199776379

Epoch: 6| Step: 10
Training loss: 0.93731833923153
Validation loss: 2.1679841905447

Epoch: 6| Step: 11
Training loss: 0.9168371489967324
Validation loss: 2.2625229807092078

Epoch: 6| Step: 12
Training loss: 0.5834576837514762
Validation loss: 2.1921748361239355

Epoch: 6| Step: 13
Training loss: 0.6681574950777752
Validation loss: 2.2057010412369227

Epoch: 542| Step: 0
Training loss: 1.6983396163290128
Validation loss: 2.1529590477665974

Epoch: 6| Step: 1
Training loss: 0.5221084403840632
Validation loss: 2.1631730936924405

Epoch: 6| Step: 2
Training loss: 0.48661448003204444
Validation loss: 2.137783873208836

Epoch: 6| Step: 3
Training loss: 0.7572241790238072
Validation loss: 2.164479002767058

Epoch: 6| Step: 4
Training loss: 0.5699570998561402
Validation loss: 2.1619332800010036

Epoch: 6| Step: 5
Training loss: 0.7597235739085904
Validation loss: 2.179450989169713

Epoch: 6| Step: 6
Training loss: 0.6347755548727524
Validation loss: 2.23825936318465

Epoch: 6| Step: 7
Training loss: 0.7786698651299804
Validation loss: 2.2457334373350952

Epoch: 6| Step: 8
Training loss: 0.730679935383862
Validation loss: 2.1899960342321125

Epoch: 6| Step: 9
Training loss: 0.7984981088347186
Validation loss: 2.2298219108976074

Epoch: 6| Step: 10
Training loss: 0.7557507813979945
Validation loss: 2.2251598557900465

Epoch: 6| Step: 11
Training loss: 0.6368019658103868
Validation loss: 2.241930459480118

Epoch: 6| Step: 12
Training loss: 0.8913775828078954
Validation loss: 2.2072763359001497

Epoch: 6| Step: 13
Training loss: 0.956197601328835
Validation loss: 2.206330342842905

Epoch: 543| Step: 0
Training loss: 0.7173355116025238
Validation loss: 2.1651534609130123

Epoch: 6| Step: 1
Training loss: 0.7278601840209854
Validation loss: 2.171158622940275

Epoch: 6| Step: 2
Training loss: 0.5229954347392989
Validation loss: 2.1966510070429837

Epoch: 6| Step: 3
Training loss: 0.8046657596354941
Validation loss: 2.2167088769278145

Epoch: 6| Step: 4
Training loss: 0.714919372894374
Validation loss: 2.2240803372830027

Epoch: 6| Step: 5
Training loss: 0.8058059844813806
Validation loss: 2.148179366041252

Epoch: 6| Step: 6
Training loss: 1.678734868507617
Validation loss: 2.2427279999377276

Epoch: 6| Step: 7
Training loss: 0.7060982254132979
Validation loss: 2.1943501019122116

Epoch: 6| Step: 8
Training loss: 0.5662103774668992
Validation loss: 2.1249841982635806

Epoch: 6| Step: 9
Training loss: 0.8288852153269975
Validation loss: 2.1405426361643514

Epoch: 6| Step: 10
Training loss: 0.6729087639178277
Validation loss: 2.2583327865039897

Epoch: 6| Step: 11
Training loss: 0.6436299813989614
Validation loss: 2.206054030917376

Epoch: 6| Step: 12
Training loss: 0.5486365693324615
Validation loss: 2.2665851101809684

Epoch: 6| Step: 13
Training loss: 0.8365417150709055
Validation loss: 2.2333647049267906

Epoch: 544| Step: 0
Training loss: 0.8796771250463626
Validation loss: 2.2158890054526155

Epoch: 6| Step: 1
Training loss: 0.6638542521945722
Validation loss: 2.2426906068559127

Epoch: 6| Step: 2
Training loss: 0.5082419706799612
Validation loss: 2.19999357662587

Epoch: 6| Step: 3
Training loss: 0.5704338780665672
Validation loss: 2.2141345378290045

Epoch: 6| Step: 4
Training loss: 0.51849979893194
Validation loss: 2.168811773503374

Epoch: 6| Step: 5
Training loss: 0.6715479653668535
Validation loss: 2.1897572486778007

Epoch: 6| Step: 6
Training loss: 0.8533614169903702
Validation loss: 2.1861228657103844

Epoch: 6| Step: 7
Training loss: 0.7782063514436554
Validation loss: 2.2016030963864246

Epoch: 6| Step: 8
Training loss: 1.6652778879306485
Validation loss: 2.233082644308866

Epoch: 6| Step: 9
Training loss: 0.5031375196332706
Validation loss: 2.187471254221409

Epoch: 6| Step: 10
Training loss: 0.7790243489716743
Validation loss: 2.276628027088258

Epoch: 6| Step: 11
Training loss: 0.47236905160486303
Validation loss: 2.194712472519021

Epoch: 6| Step: 12
Training loss: 0.6994996598783461
Validation loss: 2.14201322062487

Epoch: 6| Step: 13
Training loss: 0.8314688487683516
Validation loss: 2.2319046983369377

Epoch: 545| Step: 0
Training loss: 0.49221411133533016
Validation loss: 2.2433360444122177

Epoch: 6| Step: 1
Training loss: 0.48273504185233085
Validation loss: 2.1570373430481826

Epoch: 6| Step: 2
Training loss: 0.9054563269696879
Validation loss: 2.187950416930785

Epoch: 6| Step: 3
Training loss: 0.7941873892221684
Validation loss: 2.204439717984216

Epoch: 6| Step: 4
Training loss: 0.6726567798926983
Validation loss: 2.177142977369775

Epoch: 6| Step: 5
Training loss: 0.6237160368791128
Validation loss: 2.1593761422897004

Epoch: 6| Step: 6
Training loss: 0.7073941642941142
Validation loss: 2.1642485578923414

Epoch: 6| Step: 7
Training loss: 0.5159213630467855
Validation loss: 2.2832037133609324

Epoch: 6| Step: 8
Training loss: 0.634688786477645
Validation loss: 2.2102487557276915

Epoch: 6| Step: 9
Training loss: 0.6402152542135752
Validation loss: 2.2211586707580806

Epoch: 6| Step: 10
Training loss: 1.6553695785824285
Validation loss: 2.220708853261596

Epoch: 6| Step: 11
Training loss: 0.5748256149396874
Validation loss: 2.192505587410053

Epoch: 6| Step: 12
Training loss: 0.7540681497146412
Validation loss: 2.2677009392889773

Epoch: 6| Step: 13
Training loss: 0.6074557524920914
Validation loss: 2.2374368472274853

Epoch: 546| Step: 0
Training loss: 0.7001950145598433
Validation loss: 2.196507112208037

Epoch: 6| Step: 1
Training loss: 0.8255436088877898
Validation loss: 2.2453033508963403

Epoch: 6| Step: 2
Training loss: 1.5801105660973631
Validation loss: 2.160583506058917

Epoch: 6| Step: 3
Training loss: 0.747403896877551
Validation loss: 2.203023364322655

Epoch: 6| Step: 4
Training loss: 0.7172116111409063
Validation loss: 2.2355081817161415

Epoch: 6| Step: 5
Training loss: 0.779328577453236
Validation loss: 2.251102716225536

Epoch: 6| Step: 6
Training loss: 0.5337468822575799
Validation loss: 2.305609969617032

Epoch: 6| Step: 7
Training loss: 0.5512867224608564
Validation loss: 2.254472412163421

Epoch: 6| Step: 8
Training loss: 0.7578091178897225
Validation loss: 2.2938658721323306

Epoch: 6| Step: 9
Training loss: 0.7272790636252595
Validation loss: 2.2636520377936344

Epoch: 6| Step: 10
Training loss: 0.7211719425082782
Validation loss: 2.137161054629305

Epoch: 6| Step: 11
Training loss: 0.4205699975667298
Validation loss: 2.2304331409897733

Epoch: 6| Step: 12
Training loss: 0.9140784107355892
Validation loss: 2.2101709664814098

Epoch: 6| Step: 13
Training loss: 0.6858183494435919
Validation loss: 2.158493357601791

Epoch: 547| Step: 0
Training loss: 1.6307920521985746
Validation loss: 2.2418449705901953

Epoch: 6| Step: 1
Training loss: 0.8987280666025331
Validation loss: 2.2737986935237586

Epoch: 6| Step: 2
Training loss: 0.6669008519203692
Validation loss: 2.2672239913508903

Epoch: 6| Step: 3
Training loss: 0.7734282907265215
Validation loss: 2.234511695017547

Epoch: 6| Step: 4
Training loss: 0.6907859649186666
Validation loss: 2.3042537914470476

Epoch: 6| Step: 5
Training loss: 0.4797054057553664
Validation loss: 2.2784324054292933

Epoch: 6| Step: 6
Training loss: 0.5573521934748786
Validation loss: 2.1747075328952765

Epoch: 6| Step: 7
Training loss: 0.6110439919931374
Validation loss: 2.202598794609784

Epoch: 6| Step: 8
Training loss: 0.8584152410986845
Validation loss: 2.214109500290592

Epoch: 6| Step: 9
Training loss: 0.5929651091894825
Validation loss: 2.2568671973434324

Epoch: 6| Step: 10
Training loss: 0.6800026437062876
Validation loss: 2.1958108329877173

Epoch: 6| Step: 11
Training loss: 0.6669023266156685
Validation loss: 2.2203864516310534

Epoch: 6| Step: 12
Training loss: 0.7232170197436881
Validation loss: 2.2030767148813273

Epoch: 6| Step: 13
Training loss: 0.28929138143352207
Validation loss: 2.199285283363899

Epoch: 548| Step: 0
Training loss: 1.5848263009378305
Validation loss: 2.170271581934123

Epoch: 6| Step: 1
Training loss: 0.8728525512990176
Validation loss: 2.2534384011676476

Epoch: 6| Step: 2
Training loss: 0.5757998542419758
Validation loss: 2.2513110102533553

Epoch: 6| Step: 3
Training loss: 0.5562352628577301
Validation loss: 2.233283822501541

Epoch: 6| Step: 4
Training loss: 0.6439380343358243
Validation loss: 2.186259755775739

Epoch: 6| Step: 5
Training loss: 0.7878803046349173
Validation loss: 2.240558469401329

Epoch: 6| Step: 6
Training loss: 0.6606654624132459
Validation loss: 2.1736740743052616

Epoch: 6| Step: 7
Training loss: 0.6841223716413519
Validation loss: 2.186508688906977

Epoch: 6| Step: 8
Training loss: 0.709931888536988
Validation loss: 2.256049745060705

Epoch: 6| Step: 9
Training loss: 0.8286464417025964
Validation loss: 2.1916190163235933

Epoch: 6| Step: 10
Training loss: 0.7285261792602189
Validation loss: 2.1930587036940383

Epoch: 6| Step: 11
Training loss: 0.8154584868136641
Validation loss: 2.1819790250975184

Epoch: 6| Step: 12
Training loss: 0.6674521606961297
Validation loss: 2.2434723379853216

Epoch: 6| Step: 13
Training loss: 0.766680942969155
Validation loss: 2.270032797372703

Epoch: 549| Step: 0
Training loss: 0.5662477995132906
Validation loss: 2.1801427756123433

Epoch: 6| Step: 1
Training loss: 0.6045292610299408
Validation loss: 2.20943761679595

Epoch: 6| Step: 2
Training loss: 0.5248359389772944
Validation loss: 2.2269173173007295

Epoch: 6| Step: 3
Training loss: 0.7602953008359756
Validation loss: 2.1252486905595163

Epoch: 6| Step: 4
Training loss: 0.7425130832688259
Validation loss: 2.2500251622769887

Epoch: 6| Step: 5
Training loss: 0.687737943914553
Validation loss: 2.2437661828867332

Epoch: 6| Step: 6
Training loss: 0.8233900197652676
Validation loss: 2.239091373181272

Epoch: 6| Step: 7
Training loss: 1.678953356323868
Validation loss: 2.252389215848459

Epoch: 6| Step: 8
Training loss: 0.7752592037876129
Validation loss: 2.231676155651644

Epoch: 6| Step: 9
Training loss: 0.608716853843206
Validation loss: 2.211436669671214

Epoch: 6| Step: 10
Training loss: 0.8197552922931048
Validation loss: 2.1678408343237465

Epoch: 6| Step: 11
Training loss: 0.5297840311768007
Validation loss: 2.2425024294424207

Epoch: 6| Step: 12
Training loss: 0.8023804489999032
Validation loss: 2.1815692404727476

Epoch: 6| Step: 13
Training loss: 0.6264572321488099
Validation loss: 2.204882334346838

Epoch: 550| Step: 0
Training loss: 0.9988345268679886
Validation loss: 2.2346585024541787

Epoch: 6| Step: 1
Training loss: 0.5321992919654824
Validation loss: 2.1844843045760887

Epoch: 6| Step: 2
Training loss: 0.4168569090776807
Validation loss: 2.314652230444898

Epoch: 6| Step: 3
Training loss: 0.5333676486102099
Validation loss: 2.1334820423318352

Epoch: 6| Step: 4
Training loss: 0.5265390543712767
Validation loss: 2.212407388400587

Epoch: 6| Step: 5
Training loss: 0.49777797845084726
Validation loss: 2.2179587757492696

Epoch: 6| Step: 6
Training loss: 0.6897229323210867
Validation loss: 2.179247371787158

Epoch: 6| Step: 7
Training loss: 0.8247870343771907
Validation loss: 2.204172879379781

Epoch: 6| Step: 8
Training loss: 1.701910373237476
Validation loss: 2.1980913057178024

Epoch: 6| Step: 9
Training loss: 0.49236630416245397
Validation loss: 2.2465456420528307

Epoch: 6| Step: 10
Training loss: 0.8758483248503465
Validation loss: 2.2305795146278045

Epoch: 6| Step: 11
Training loss: 0.35020905748020503
Validation loss: 2.2183311699120414

Epoch: 6| Step: 12
Training loss: 0.5518281334820496
Validation loss: 2.217817910012656

Epoch: 6| Step: 13
Training loss: 0.6263778519086862
Validation loss: 2.192326527941491

Testing loss: 3.1108898466385964
