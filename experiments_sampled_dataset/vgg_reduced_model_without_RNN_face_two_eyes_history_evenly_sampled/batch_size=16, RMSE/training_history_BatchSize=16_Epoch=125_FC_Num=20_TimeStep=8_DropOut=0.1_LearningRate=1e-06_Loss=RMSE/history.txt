Epoch: 1| Step: 0
Training loss: 4.7103750927505015
Validation loss: 4.79781738977603

Epoch: 6| Step: 1
Training loss: 4.728038008974403
Validation loss: 4.794664777009942

Epoch: 6| Step: 2
Training loss: 4.865100296727375
Validation loss: 4.790157053919423

Epoch: 6| Step: 3
Training loss: 4.1678081220512455
Validation loss: 4.786116157303886

Epoch: 6| Step: 4
Training loss: 4.792398855687221
Validation loss: 4.780140456812819

Epoch: 6| Step: 5
Training loss: 5.2050576043216505
Validation loss: 4.775125146029186

Epoch: 6| Step: 6
Training loss: 4.894097116371175
Validation loss: 4.77010454277888

Epoch: 6| Step: 7
Training loss: 4.857939774989175
Validation loss: 4.765734836194195

Epoch: 6| Step: 8
Training loss: 5.49333550079698
Validation loss: 4.76316280845589

Epoch: 6| Step: 9
Training loss: 5.4652906539142725
Validation loss: 4.757365767247902

Epoch: 6| Step: 10
Training loss: 5.049760589967727
Validation loss: 4.751957274770556

Epoch: 6| Step: 11
Training loss: 5.46799677429997
Validation loss: 4.748635847989234

Epoch: 6| Step: 12
Training loss: 3.6393391053232667
Validation loss: 4.742478815504168

Epoch: 6| Step: 13
Training loss: 3.90651708071324
Validation loss: 4.7403415849136525

Epoch: 2| Step: 0
Training loss: 4.7878986083141
Validation loss: 4.735091352422151

Epoch: 6| Step: 1
Training loss: 3.011556301856721
Validation loss: 4.730797149070061

Epoch: 6| Step: 2
Training loss: 6.225700136820237
Validation loss: 4.723633473540813

Epoch: 6| Step: 3
Training loss: 3.6981436789593576
Validation loss: 4.721777937802067

Epoch: 6| Step: 4
Training loss: 5.010853431788657
Validation loss: 4.717162623358866

Epoch: 6| Step: 5
Training loss: 3.7212096983316485
Validation loss: 4.711955861518248

Epoch: 6| Step: 6
Training loss: 4.723276556656836
Validation loss: 4.7105044187951925

Epoch: 6| Step: 7
Training loss: 4.972093524841965
Validation loss: 4.703918959092178

Epoch: 6| Step: 8
Training loss: 5.484231365529202
Validation loss: 4.700351202241824

Epoch: 6| Step: 9
Training loss: 4.435997937077283
Validation loss: 4.695275946249562

Epoch: 6| Step: 10
Training loss: 5.072526398463625
Validation loss: 4.6896565366682195

Epoch: 6| Step: 11
Training loss: 5.309128712582468
Validation loss: 4.686297382052649

Epoch: 6| Step: 12
Training loss: 5.046882747490667
Validation loss: 4.682137527492019

Epoch: 6| Step: 13
Training loss: 4.791894769076766
Validation loss: 4.6776444958373355

Epoch: 3| Step: 0
Training loss: 4.306136813288767
Validation loss: 4.672324932350813

Epoch: 6| Step: 1
Training loss: 5.125434484905413
Validation loss: 4.669291682362343

Epoch: 6| Step: 2
Training loss: 5.114664029211877
Validation loss: 4.663411584405898

Epoch: 6| Step: 3
Training loss: 3.458588157978453
Validation loss: 4.660019792076999

Epoch: 6| Step: 4
Training loss: 4.324560136422566
Validation loss: 4.656553271907809

Epoch: 6| Step: 5
Training loss: 4.885306003946658
Validation loss: 4.652012867876504

Epoch: 6| Step: 6
Training loss: 4.033419003378092
Validation loss: 4.645010626422108

Epoch: 6| Step: 7
Training loss: 3.5775156626701707
Validation loss: 4.642458461297967

Epoch: 6| Step: 8
Training loss: 5.222996611478474
Validation loss: 4.638946296972494

Epoch: 6| Step: 9
Training loss: 5.8878740519860635
Validation loss: 4.633729883255626

Epoch: 6| Step: 10
Training loss: 4.505044652651924
Validation loss: 4.629098368435569

Epoch: 6| Step: 11
Training loss: 4.312807155119619
Validation loss: 4.6257448292306504

Epoch: 6| Step: 12
Training loss: 5.734305815318342
Validation loss: 4.6210100500982625

Epoch: 6| Step: 13
Training loss: 5.431284717584936
Validation loss: 4.6164585785559344

Epoch: 4| Step: 0
Training loss: 4.849877204520315
Validation loss: 4.61118671733971

Epoch: 6| Step: 1
Training loss: 4.654395226877335
Validation loss: 4.606565587813436

Epoch: 6| Step: 2
Training loss: 4.221766318977258
Validation loss: 4.601345281162367

Epoch: 6| Step: 3
Training loss: 4.7073471026678195
Validation loss: 4.5955938149618

Epoch: 6| Step: 4
Training loss: 5.542332124073327
Validation loss: 4.592595984324656

Epoch: 6| Step: 5
Training loss: 5.696150018259489
Validation loss: 4.586061918753843

Epoch: 6| Step: 6
Training loss: 4.919410112575784
Validation loss: 4.580460060385648

Epoch: 6| Step: 7
Training loss: 4.993465158600902
Validation loss: 4.577232716547266

Epoch: 6| Step: 8
Training loss: 4.952401767239826
Validation loss: 4.571578335533695

Epoch: 6| Step: 9
Training loss: 4.014643567749722
Validation loss: 4.566617403841788

Epoch: 6| Step: 10
Training loss: 4.124813653609331
Validation loss: 4.561841080199953

Epoch: 6| Step: 11
Training loss: 4.157716420700303
Validation loss: 4.557006288467824

Epoch: 6| Step: 12
Training loss: 4.109497532631346
Validation loss: 4.553192703336376

Epoch: 6| Step: 13
Training loss: 3.7653239909435285
Validation loss: 4.5488959843542585

Epoch: 5| Step: 0
Training loss: 4.155875970746543
Validation loss: 4.543152975273729

Epoch: 6| Step: 1
Training loss: 4.358056309917879
Validation loss: 4.539619227394348

Epoch: 6| Step: 2
Training loss: 4.976301105527186
Validation loss: 4.53243048838458

Epoch: 6| Step: 3
Training loss: 4.952061680398843
Validation loss: 4.530013587647143

Epoch: 6| Step: 4
Training loss: 4.521164186152117
Validation loss: 4.525085170671522

Epoch: 6| Step: 5
Training loss: 4.99247327771626
Validation loss: 4.519616602323031

Epoch: 6| Step: 6
Training loss: 3.920997430257191
Validation loss: 4.517689631408862

Epoch: 6| Step: 7
Training loss: 3.998445327947899
Validation loss: 4.509113023999943

Epoch: 6| Step: 8
Training loss: 5.035787869797981
Validation loss: 4.50430403076839

Epoch: 6| Step: 9
Training loss: 4.272761931361813
Validation loss: 4.497323939332965

Epoch: 6| Step: 10
Training loss: 5.050031590126867
Validation loss: 4.494493035139495

Epoch: 6| Step: 11
Training loss: 4.2206509298745125
Validation loss: 4.490461693494613

Epoch: 6| Step: 12
Training loss: 5.29002671348591
Validation loss: 4.482338779369227

Epoch: 6| Step: 13
Training loss: 4.560448590348853
Validation loss: 4.478936332776659

Epoch: 6| Step: 0
Training loss: 5.096770344775964
Validation loss: 4.474404375735292

Epoch: 6| Step: 1
Training loss: 3.8712206222114185
Validation loss: 4.467880422574393

Epoch: 6| Step: 2
Training loss: 4.511674149197838
Validation loss: 4.460031122685539

Epoch: 6| Step: 3
Training loss: 4.992704218477999
Validation loss: 4.457059714921049

Epoch: 6| Step: 4
Training loss: 4.784197129643904
Validation loss: 4.4524705689134825

Epoch: 6| Step: 5
Training loss: 3.726649253363237
Validation loss: 4.446842114621956

Epoch: 6| Step: 6
Training loss: 4.7354320189661685
Validation loss: 4.439653878250048

Epoch: 6| Step: 7
Training loss: 4.4318353737095295
Validation loss: 4.4349760751915595

Epoch: 6| Step: 8
Training loss: 4.489887955930696
Validation loss: 4.4307122942751755

Epoch: 6| Step: 9
Training loss: 4.4302758527511275
Validation loss: 4.424935549987441

Epoch: 6| Step: 10
Training loss: 4.465853092249311
Validation loss: 4.4176556359745245

Epoch: 6| Step: 11
Training loss: 6.303354115215695
Validation loss: 4.410708965532529

Epoch: 6| Step: 12
Training loss: 3.416752573809635
Validation loss: 4.404428739115099

Epoch: 6| Step: 13
Training loss: 2.7689274612629498
Validation loss: 4.400119528727046

Epoch: 7| Step: 0
Training loss: 4.583968771610108
Validation loss: 4.393681178048962

Epoch: 6| Step: 1
Training loss: 3.391466168250207
Validation loss: 4.38959087498477

Epoch: 6| Step: 2
Training loss: 4.136195624309096
Validation loss: 4.381313623724104

Epoch: 6| Step: 3
Training loss: 4.6241066559631445
Validation loss: 4.3800330163604055

Epoch: 6| Step: 4
Training loss: 4.758323203553186
Validation loss: 4.371840655574498

Epoch: 6| Step: 5
Training loss: 3.957361657525396
Validation loss: 4.363457372422066

Epoch: 6| Step: 6
Training loss: 4.314359623321935
Validation loss: 4.359088461492467

Epoch: 6| Step: 7
Training loss: 3.559450149077738
Validation loss: 4.35441499545484

Epoch: 6| Step: 8
Training loss: 5.052849885131154
Validation loss: 4.34624812053936

Epoch: 6| Step: 9
Training loss: 4.627648291290701
Validation loss: 4.342716729486522

Epoch: 6| Step: 10
Training loss: 5.147103259752298
Validation loss: 4.334862026853716

Epoch: 6| Step: 11
Training loss: 5.4122965080648475
Validation loss: 4.326995542312265

Epoch: 6| Step: 12
Training loss: 4.386241747635574
Validation loss: 4.322061172601755

Epoch: 6| Step: 13
Training loss: 3.8006081144725936
Validation loss: 4.316999703861488

Epoch: 8| Step: 0
Training loss: 5.283761956350508
Validation loss: 4.307533608624244

Epoch: 6| Step: 1
Training loss: 3.957852036511714
Validation loss: 4.3013375612749565

Epoch: 6| Step: 2
Training loss: 4.126435925796865
Validation loss: 4.295279094296801

Epoch: 6| Step: 3
Training loss: 4.263944301735282
Validation loss: 4.287845382620127

Epoch: 6| Step: 4
Training loss: 4.398100763850175
Validation loss: 4.283828080077277

Epoch: 6| Step: 5
Training loss: 4.080151985927912
Validation loss: 4.271958158540776

Epoch: 6| Step: 6
Training loss: 4.463805123754993
Validation loss: 4.267457858171309

Epoch: 6| Step: 7
Training loss: 4.282121778400146
Validation loss: 4.25889328900274

Epoch: 6| Step: 8
Training loss: 4.184765278604251
Validation loss: 4.252162089026995

Epoch: 6| Step: 9
Training loss: 4.5572293290007355
Validation loss: 4.245575340651079

Epoch: 6| Step: 10
Training loss: 4.903913974436823
Validation loss: 4.237258312706467

Epoch: 6| Step: 11
Training loss: 3.765180379490483
Validation loss: 4.229827772610234

Epoch: 6| Step: 12
Training loss: 4.357727614568005
Validation loss: 4.227890163080618

Epoch: 6| Step: 13
Training loss: 4.623315865378922
Validation loss: 4.217321562252311

Epoch: 9| Step: 0
Training loss: 4.5778646037026895
Validation loss: 4.207017193018374

Epoch: 6| Step: 1
Training loss: 4.663199135569756
Validation loss: 4.2012865558092995

Epoch: 6| Step: 2
Training loss: 4.332737196973986
Validation loss: 4.193043249816076

Epoch: 6| Step: 3
Training loss: 3.857880708470781
Validation loss: 4.184517649521662

Epoch: 6| Step: 4
Training loss: 3.8941702871525528
Validation loss: 4.17499282705629

Epoch: 6| Step: 5
Training loss: 3.827735600810473
Validation loss: 4.1660831206857925

Epoch: 6| Step: 6
Training loss: 3.264915279673772
Validation loss: 4.160532359183213

Epoch: 6| Step: 7
Training loss: 4.035722011553944
Validation loss: 4.151582332074352

Epoch: 6| Step: 8
Training loss: 3.589698431583343
Validation loss: 4.145935647664258

Epoch: 6| Step: 9
Training loss: 4.812865206249835
Validation loss: 4.1362086253482975

Epoch: 6| Step: 10
Training loss: 4.646392628941324
Validation loss: 4.128430841212553

Epoch: 6| Step: 11
Training loss: 4.730274199588846
Validation loss: 4.119201704203052

Epoch: 6| Step: 12
Training loss: 4.5039873471531235
Validation loss: 4.113990223594389

Epoch: 6| Step: 13
Training loss: 5.200131766777233
Validation loss: 4.1051685431938525

Epoch: 10| Step: 0
Training loss: 4.06913426894843
Validation loss: 4.093294555608917

Epoch: 6| Step: 1
Training loss: 4.055868987305618
Validation loss: 4.083869820150927

Epoch: 6| Step: 2
Training loss: 3.926828850039798
Validation loss: 4.074944383251871

Epoch: 6| Step: 3
Training loss: 5.297333373995273
Validation loss: 4.063054223509307

Epoch: 6| Step: 4
Training loss: 4.95776073237628
Validation loss: 4.0560325983582155

Epoch: 6| Step: 5
Training loss: 2.7073001260149487
Validation loss: 4.045233448006674

Epoch: 6| Step: 6
Training loss: 5.364375770281679
Validation loss: 4.034964107523506

Epoch: 6| Step: 7
Training loss: 3.315616221510675
Validation loss: 4.025706463245992

Epoch: 6| Step: 8
Training loss: 3.630240499973312
Validation loss: 4.01800337971145

Epoch: 6| Step: 9
Training loss: 4.491035008411463
Validation loss: 4.005150670539625

Epoch: 6| Step: 10
Training loss: 3.743891763948463
Validation loss: 3.99562626696879

Epoch: 6| Step: 11
Training loss: 3.444525457953993
Validation loss: 3.9873984659112134

Epoch: 6| Step: 12
Training loss: 4.180834575366745
Validation loss: 3.9755805607705295

Epoch: 6| Step: 13
Training loss: 4.318817818270656
Validation loss: 3.964047025861599

Epoch: 11| Step: 0
Training loss: 4.479343475873838
Validation loss: 3.9554271519382804

Epoch: 6| Step: 1
Training loss: 3.006146809478326
Validation loss: 3.944995517722708

Epoch: 6| Step: 2
Training loss: 3.5759819976216956
Validation loss: 3.938925109368446

Epoch: 6| Step: 3
Training loss: 4.45995462950479
Validation loss: 3.9296835505031997

Epoch: 6| Step: 4
Training loss: 3.948329504700127
Validation loss: 3.91396505579917

Epoch: 6| Step: 5
Training loss: 4.879479721976282
Validation loss: 3.9013478459764044

Epoch: 6| Step: 6
Training loss: 4.181006563909123
Validation loss: 3.891414095955736

Epoch: 6| Step: 7
Training loss: 4.576742021940978
Validation loss: 3.884074662621543

Epoch: 6| Step: 8
Training loss: 3.9209776075833336
Validation loss: 3.8724507001918504

Epoch: 6| Step: 9
Training loss: 3.6372425263509176
Validation loss: 3.8599351351324493

Epoch: 6| Step: 10
Training loss: 4.180304194793812
Validation loss: 3.84874468259873

Epoch: 6| Step: 11
Training loss: 3.5961550418752912
Validation loss: 3.8373815972172696

Epoch: 6| Step: 12
Training loss: 3.9649899911453512
Validation loss: 3.8230167999570104

Epoch: 6| Step: 13
Training loss: 3.2601248678620784
Validation loss: 3.8095398211289195

Epoch: 12| Step: 0
Training loss: 4.612637054143944
Validation loss: 3.7974245804704974

Epoch: 6| Step: 1
Training loss: 3.570774841423028
Validation loss: 3.781777651786223

Epoch: 6| Step: 2
Training loss: 4.672596751314051
Validation loss: 3.7727070360856585

Epoch: 6| Step: 3
Training loss: 4.2998150009457845
Validation loss: 3.7572096808727378

Epoch: 6| Step: 4
Training loss: 3.026638337673531
Validation loss: 3.747084911333957

Epoch: 6| Step: 5
Training loss: 3.8884499226431246
Validation loss: 3.7323603719307368

Epoch: 6| Step: 6
Training loss: 4.0622039687064
Validation loss: 3.7236506426700418

Epoch: 6| Step: 7
Training loss: 4.065733810950833
Validation loss: 3.7061819841723773

Epoch: 6| Step: 8
Training loss: 4.058156670100605
Validation loss: 3.6876707265190323

Epoch: 6| Step: 9
Training loss: 3.8716155007559
Validation loss: 3.677571418581627

Epoch: 6| Step: 10
Training loss: 3.1607829864646537
Validation loss: 3.661640165113597

Epoch: 6| Step: 11
Training loss: 3.173472335827077
Validation loss: 3.648111186017755

Epoch: 6| Step: 12
Training loss: 2.914804318175894
Validation loss: 3.6364919619673293

Epoch: 6| Step: 13
Training loss: 4.608286997520192
Validation loss: 3.6212444490657534

Epoch: 13| Step: 0
Training loss: 3.6053727324193336
Validation loss: 3.613002586893708

Epoch: 6| Step: 1
Training loss: 3.1283197698636136
Validation loss: 3.5894204959759857

Epoch: 6| Step: 2
Training loss: 4.072523691613101
Validation loss: 3.5785941535420465

Epoch: 6| Step: 3
Training loss: 3.3262836932540516
Validation loss: 3.562973732170066

Epoch: 6| Step: 4
Training loss: 3.3937069997293827
Validation loss: 3.5501855179249944

Epoch: 6| Step: 5
Training loss: 3.156175367020612
Validation loss: 3.5320655722355787

Epoch: 6| Step: 6
Training loss: 3.307930727914899
Validation loss: 3.5271597130721015

Epoch: 6| Step: 7
Training loss: 3.7442037928291683
Validation loss: 3.5074231759182997

Epoch: 6| Step: 8
Training loss: 3.8684287188952866
Validation loss: 3.494399827615511

Epoch: 6| Step: 9
Training loss: 4.127791413914602
Validation loss: 3.4784614010761867

Epoch: 6| Step: 10
Training loss: 4.401407597544413
Validation loss: 3.463167066515018

Epoch: 6| Step: 11
Training loss: 4.213596162887631
Validation loss: 3.451647030384989

Epoch: 6| Step: 12
Training loss: 3.7331980362853776
Validation loss: 3.4350251239075686

Epoch: 6| Step: 13
Training loss: 2.974832828216564
Validation loss: 3.416409461552075

Epoch: 14| Step: 0
Training loss: 3.5363209191630993
Validation loss: 3.402795452356355

Epoch: 6| Step: 1
Training loss: 3.759306105238479
Validation loss: 3.388475484045886

Epoch: 6| Step: 2
Training loss: 3.827047764767385
Validation loss: 3.3765903707628806

Epoch: 6| Step: 3
Training loss: 3.9574529906979294
Validation loss: 3.359409427681041

Epoch: 6| Step: 4
Training loss: 3.447395508132153
Validation loss: 3.34317888671436

Epoch: 6| Step: 5
Training loss: 3.8539066261339263
Validation loss: 3.325931394442619

Epoch: 6| Step: 6
Training loss: 2.83262083033233
Validation loss: 3.309064428206291

Epoch: 6| Step: 7
Training loss: 3.0604459140973614
Validation loss: 3.2968535662422203

Epoch: 6| Step: 8
Training loss: 3.5562975245084187
Validation loss: 3.27130488302916

Epoch: 6| Step: 9
Training loss: 3.1645468258755756
Validation loss: 3.2611188360799632

Epoch: 6| Step: 10
Training loss: 4.094498427604684
Validation loss: 3.2447465618162012

Epoch: 6| Step: 11
Training loss: 3.295494043478244
Validation loss: 3.2318108597582706

Epoch: 6| Step: 12
Training loss: 3.04822999217662
Validation loss: 3.206920001380016

Epoch: 6| Step: 13
Training loss: 3.319090423078628
Validation loss: 3.1945945433999556

Epoch: 15| Step: 0
Training loss: 2.8415503745647315
Validation loss: 3.1860718444213014

Epoch: 6| Step: 1
Training loss: 2.5634720052042823
Validation loss: 3.1589259619234658

Epoch: 6| Step: 2
Training loss: 2.967617742553439
Validation loss: 3.153662463327797

Epoch: 6| Step: 3
Training loss: 3.8459937517152083
Validation loss: 3.1339140929377898

Epoch: 6| Step: 4
Training loss: 3.5040417903341567
Validation loss: 3.1227024287085783

Epoch: 6| Step: 5
Training loss: 3.317304186356647
Validation loss: 3.107109065784487

Epoch: 6| Step: 6
Training loss: 2.972723299691433
Validation loss: 3.092682164523994

Epoch: 6| Step: 7
Training loss: 3.091138874529253
Validation loss: 3.075131594202087

Epoch: 6| Step: 8
Training loss: 3.1229757237634463
Validation loss: 3.0585332749857996

Epoch: 6| Step: 9
Training loss: 4.192929292467945
Validation loss: 3.0517396362025915

Epoch: 6| Step: 10
Training loss: 3.181279114475688
Validation loss: 3.032443013193061

Epoch: 6| Step: 11
Training loss: 3.242401042478193
Validation loss: 3.0286796623731025

Epoch: 6| Step: 12
Training loss: 3.357191786945741
Validation loss: 3.0081806956322525

Epoch: 6| Step: 13
Training loss: 4.00324713515442
Validation loss: 2.9943785537197725

Epoch: 16| Step: 0
Training loss: 3.9502212655590574
Validation loss: 2.96953164450036

Epoch: 6| Step: 1
Training loss: 3.7743846265427203
Validation loss: 2.9567051095078747

Epoch: 6| Step: 2
Training loss: 2.4621701014717776
Validation loss: 2.944691552715595

Epoch: 6| Step: 3
Training loss: 3.237053835256472
Validation loss: 2.9218060455336854

Epoch: 6| Step: 4
Training loss: 3.1092523138484394
Validation loss: 2.908291027131492

Epoch: 6| Step: 5
Training loss: 2.838861308634694
Validation loss: 2.8932296073451513

Epoch: 6| Step: 6
Training loss: 2.892928736505535
Validation loss: 2.871690829703423

Epoch: 6| Step: 7
Training loss: 3.030289487952981
Validation loss: 2.8690212765541814

Epoch: 6| Step: 8
Training loss: 3.456580181112817
Validation loss: 2.858642359641242

Epoch: 6| Step: 9
Training loss: 2.7509309753389126
Validation loss: 2.8410039492046972

Epoch: 6| Step: 10
Training loss: 3.2132475402532945
Validation loss: 2.8269373452549575

Epoch: 6| Step: 11
Training loss: 2.93231360165854
Validation loss: 2.8168898811175604

Epoch: 6| Step: 12
Training loss: 3.2170337434611067
Validation loss: 2.803051930993374

Epoch: 6| Step: 13
Training loss: 2.8295463236110727
Validation loss: 2.7944139459749335

Epoch: 17| Step: 0
Training loss: 2.9184109149804036
Validation loss: 2.7794964792986616

Epoch: 6| Step: 1
Training loss: 2.3514319095279976
Validation loss: 2.769272762562066

Epoch: 6| Step: 2
Training loss: 3.2452237171707137
Validation loss: 2.7582197902121663

Epoch: 6| Step: 3
Training loss: 3.209427007237073
Validation loss: 2.743216636382676

Epoch: 6| Step: 4
Training loss: 3.144567491784551
Validation loss: 2.738452874810652

Epoch: 6| Step: 5
Training loss: 3.3982106100176637
Validation loss: 2.7249330907357256

Epoch: 6| Step: 6
Training loss: 2.6395066280003565
Validation loss: 2.709709467847288

Epoch: 6| Step: 7
Training loss: 3.228662726344807
Validation loss: 2.7017517319261657

Epoch: 6| Step: 8
Training loss: 3.8079408995746404
Validation loss: 2.698764434230057

Epoch: 6| Step: 9
Training loss: 2.934678041127872
Validation loss: 2.6886674978348517

Epoch: 6| Step: 10
Training loss: 2.0798252578840657
Validation loss: 2.674697084117288

Epoch: 6| Step: 11
Training loss: 3.2776552400115984
Validation loss: 2.6654919900668115

Epoch: 6| Step: 12
Training loss: 2.8370762580032256
Validation loss: 2.659151346524878

Epoch: 6| Step: 13
Training loss: 2.6268259691286406
Validation loss: 2.6502773311993266

Epoch: 18| Step: 0
Training loss: 3.5610072706148848
Validation loss: 2.6295549921250765

Epoch: 6| Step: 1
Training loss: 3.2871209800003105
Validation loss: 2.630896277158627

Epoch: 6| Step: 2
Training loss: 2.791942146335831
Validation loss: 2.624230186493337

Epoch: 6| Step: 3
Training loss: 2.5387792810792176
Validation loss: 2.6141927610668216

Epoch: 6| Step: 4
Training loss: 2.5480118536980343
Validation loss: 2.6180980877989097

Epoch: 6| Step: 5
Training loss: 3.781508003449334
Validation loss: 2.6095697179124437

Epoch: 6| Step: 6
Training loss: 3.028965669353657
Validation loss: 2.605321666579667

Epoch: 6| Step: 7
Training loss: 2.325952835083707
Validation loss: 2.5978952950901957

Epoch: 6| Step: 8
Training loss: 2.425699966715119
Validation loss: 2.5985422549574273

Epoch: 6| Step: 9
Training loss: 2.7995527863987504
Validation loss: 2.5881726656070487

Epoch: 6| Step: 10
Training loss: 2.487447122749861
Validation loss: 2.5826854793214444

Epoch: 6| Step: 11
Training loss: 2.947281480345854
Validation loss: 2.581800504896146

Epoch: 6| Step: 12
Training loss: 3.1975245199091002
Validation loss: 2.5674820776796325

Epoch: 6| Step: 13
Training loss: 3.168704096896162
Validation loss: 2.573118822567991

Epoch: 19| Step: 0
Training loss: 2.777237301274036
Validation loss: 2.561852305003403

Epoch: 6| Step: 1
Training loss: 3.073690250245715
Validation loss: 2.565508127560113

Epoch: 6| Step: 2
Training loss: 2.263088516493309
Validation loss: 2.560240467921909

Epoch: 6| Step: 3
Training loss: 3.4855101237485893
Validation loss: 2.560496106230364

Epoch: 6| Step: 4
Training loss: 3.1331546434894544
Validation loss: 2.5424469836468826

Epoch: 6| Step: 5
Training loss: 3.202169433971648
Validation loss: 2.544910718515178

Epoch: 6| Step: 6
Training loss: 2.9481847706296263
Validation loss: 2.5427219359367723

Epoch: 6| Step: 7
Training loss: 2.808864532702446
Validation loss: 2.5406716946257997

Epoch: 6| Step: 8
Training loss: 3.0613155020594354
Validation loss: 2.5451470432069634

Epoch: 6| Step: 9
Training loss: 3.0211472622216378
Validation loss: 2.539161036798299

Epoch: 6| Step: 10
Training loss: 2.7377759437310623
Validation loss: 2.5240861434997286

Epoch: 6| Step: 11
Training loss: 2.337416776919743
Validation loss: 2.5372238733933976

Epoch: 6| Step: 12
Training loss: 3.1738091946550835
Validation loss: 2.527725684100841

Epoch: 6| Step: 13
Training loss: 1.9406362806597393
Validation loss: 2.5290726432778787

Epoch: 20| Step: 0
Training loss: 2.0303568123362923
Validation loss: 2.5246058064769876

Epoch: 6| Step: 1
Training loss: 3.6878206792501027
Validation loss: 2.5299973654045265

Epoch: 6| Step: 2
Training loss: 3.00764857254186
Validation loss: 2.5229236939807254

Epoch: 6| Step: 3
Training loss: 2.803200585272262
Validation loss: 2.5223736184084586

Epoch: 6| Step: 4
Training loss: 3.3652328163537453
Validation loss: 2.5235001253284928

Epoch: 6| Step: 5
Training loss: 2.983258902475482
Validation loss: 2.522473985049268

Epoch: 6| Step: 6
Training loss: 2.5350513877400327
Validation loss: 2.521993690543333

Epoch: 6| Step: 7
Training loss: 2.591980663874994
Validation loss: 2.519165797056275

Epoch: 6| Step: 8
Training loss: 2.8642469913812807
Validation loss: 2.5131461296149427

Epoch: 6| Step: 9
Training loss: 3.1880343120264882
Validation loss: 2.5143049441937833

Epoch: 6| Step: 10
Training loss: 2.9292511068213263
Validation loss: 2.507890047572554

Epoch: 6| Step: 11
Training loss: 2.6025520710861567
Validation loss: 2.510278146426804

Epoch: 6| Step: 12
Training loss: 2.762711191519407
Validation loss: 2.5089573189889607

Epoch: 6| Step: 13
Training loss: 2.801365662365373
Validation loss: 2.5099894366409554

Epoch: 21| Step: 0
Training loss: 2.566265967496389
Validation loss: 2.511390483542265

Epoch: 6| Step: 1
Training loss: 2.3155939179881435
Validation loss: 2.505040432248753

Epoch: 6| Step: 2
Training loss: 2.530303495545847
Validation loss: 2.503334856507084

Epoch: 6| Step: 3
Training loss: 2.7977383948535284
Validation loss: 2.5123656246596737

Epoch: 6| Step: 4
Training loss: 2.617785120813246
Validation loss: 2.501843293838955

Epoch: 6| Step: 5
Training loss: 2.818599698612211
Validation loss: 2.50728172031942

Epoch: 6| Step: 6
Training loss: 2.912572403036479
Validation loss: 2.5000474853517916

Epoch: 6| Step: 7
Training loss: 3.395875723794603
Validation loss: 2.510212882622111

Epoch: 6| Step: 8
Training loss: 2.8025154054815515
Validation loss: 2.4937071673678624

Epoch: 6| Step: 9
Training loss: 2.882590349936896
Validation loss: 2.515702357701777

Epoch: 6| Step: 10
Training loss: 2.845247147054158
Validation loss: 2.5131465850860457

Epoch: 6| Step: 11
Training loss: 3.217037004357013
Validation loss: 2.499286248238874

Epoch: 6| Step: 12
Training loss: 2.518260830690332
Validation loss: 2.506052952691154

Epoch: 6| Step: 13
Training loss: 4.514409624368595
Validation loss: 2.504404366013947

Epoch: 22| Step: 0
Training loss: 2.4892729455331493
Validation loss: 2.5006073367823696

Epoch: 6| Step: 1
Training loss: 3.059797690691165
Validation loss: 2.514026285432251

Epoch: 6| Step: 2
Training loss: 2.83051683646705
Validation loss: 2.512123363277586

Epoch: 6| Step: 3
Training loss: 2.7292166746571374
Validation loss: 2.4987417212943996

Epoch: 6| Step: 4
Training loss: 3.4210867474665716
Validation loss: 2.513524280947261

Epoch: 6| Step: 5
Training loss: 3.0621178836268763
Validation loss: 2.509837398825085

Epoch: 6| Step: 6
Training loss: 2.597421644128595
Validation loss: 2.506426143606581

Epoch: 6| Step: 7
Training loss: 3.059410561032473
Validation loss: 2.5035141088820696

Epoch: 6| Step: 8
Training loss: 2.95680258104864
Validation loss: 2.51058243415405

Epoch: 6| Step: 9
Training loss: 2.6898569816376927
Validation loss: 2.4974533133122945

Epoch: 6| Step: 10
Training loss: 2.5821499010949873
Validation loss: 2.501206652351002

Epoch: 6| Step: 11
Training loss: 2.719837365898196
Validation loss: 2.507042608550236

Epoch: 6| Step: 12
Training loss: 2.8356307943653603
Validation loss: 2.4953746112445816

Epoch: 6| Step: 13
Training loss: 3.3125616103866538
Validation loss: 2.508771930895497

Epoch: 23| Step: 0
Training loss: 2.6834622591057475
Validation loss: 2.5139467631984984

Epoch: 6| Step: 1
Training loss: 2.6774186296680713
Validation loss: 2.4983678145261576

Epoch: 6| Step: 2
Training loss: 2.763586898953095
Validation loss: 2.5053851166921284

Epoch: 6| Step: 3
Training loss: 3.4189884081741915
Validation loss: 2.508129317730412

Epoch: 6| Step: 4
Training loss: 2.6904431572938674
Validation loss: 2.5010416752495774

Epoch: 6| Step: 5
Training loss: 2.687416252783081
Validation loss: 2.497013739847855

Epoch: 6| Step: 6
Training loss: 2.6909483144921813
Validation loss: 2.507020631258805

Epoch: 6| Step: 7
Training loss: 2.807534985209671
Validation loss: 2.4976904178429464

Epoch: 6| Step: 8
Training loss: 3.2893414231865648
Validation loss: 2.493115824956755

Epoch: 6| Step: 9
Training loss: 2.7836277259725266
Validation loss: 2.5059337226246026

Epoch: 6| Step: 10
Training loss: 2.9116231818210063
Validation loss: 2.497779415789849

Epoch: 6| Step: 11
Training loss: 2.9318117298918174
Validation loss: 2.502555346192296

Epoch: 6| Step: 12
Training loss: 3.0320494865767436
Validation loss: 2.506098907574996

Epoch: 6| Step: 13
Training loss: 2.7918758788405267
Validation loss: 2.4987061126083288

Epoch: 24| Step: 0
Training loss: 2.8220943834565424
Validation loss: 2.504855305910198

Epoch: 6| Step: 1
Training loss: 3.3885792832270902
Validation loss: 2.503998350339528

Epoch: 6| Step: 2
Training loss: 2.529353243520045
Validation loss: 2.5036594833096504

Epoch: 6| Step: 3
Training loss: 2.8621071025286975
Validation loss: 2.5120832064982874

Epoch: 6| Step: 4
Training loss: 3.045675031633452
Validation loss: 2.4984441407304407

Epoch: 6| Step: 5
Training loss: 2.7877472840519046
Validation loss: 2.505995738844168

Epoch: 6| Step: 6
Training loss: 3.1397415360905345
Validation loss: 2.498422234535711

Epoch: 6| Step: 7
Training loss: 2.826827452363262
Validation loss: 2.500652133834739

Epoch: 6| Step: 8
Training loss: 2.8339611554656985
Validation loss: 2.4963419567437786

Epoch: 6| Step: 9
Training loss: 3.0126114250881706
Validation loss: 2.4949911875561663

Epoch: 6| Step: 10
Training loss: 2.745684358513945
Validation loss: 2.494917424253221

Epoch: 6| Step: 11
Training loss: 2.3486835688382466
Validation loss: 2.4917110183455495

Epoch: 6| Step: 12
Training loss: 3.110428674721114
Validation loss: 2.49973796681293

Epoch: 6| Step: 13
Training loss: 2.029592806374293
Validation loss: 2.4887683039051085

Epoch: 25| Step: 0
Training loss: 3.4128808392417938
Validation loss: 2.500170218917845

Epoch: 6| Step: 1
Training loss: 3.5756491545201556
Validation loss: 2.4994478969674745

Epoch: 6| Step: 2
Training loss: 2.4203971045170847
Validation loss: 2.499081015111398

Epoch: 6| Step: 3
Training loss: 2.2552509494716486
Validation loss: 2.493114624944581

Epoch: 6| Step: 4
Training loss: 2.7067067666050826
Validation loss: 2.4940849788347674

Epoch: 6| Step: 5
Training loss: 2.619404960794114
Validation loss: 2.4955344505501103

Epoch: 6| Step: 6
Training loss: 2.1325365943049617
Validation loss: 2.498392795956311

Epoch: 6| Step: 7
Training loss: 3.3375171789520133
Validation loss: 2.4890251658099207

Epoch: 6| Step: 8
Training loss: 2.969660087426013
Validation loss: 2.493464271924369

Epoch: 6| Step: 9
Training loss: 2.5571336147053034
Validation loss: 2.49167375042609

Epoch: 6| Step: 10
Training loss: 2.7079517291287267
Validation loss: 2.501220607163513

Epoch: 6| Step: 11
Training loss: 2.960802221101651
Validation loss: 2.4978374900901055

Epoch: 6| Step: 12
Training loss: 2.4602391781099415
Validation loss: 2.502589285662238

Epoch: 6| Step: 13
Training loss: 3.7558217951838095
Validation loss: 2.4960414638291004

Epoch: 26| Step: 0
Training loss: 2.3287837997334315
Validation loss: 2.4863572352207353

Epoch: 6| Step: 1
Training loss: 3.28587465901855
Validation loss: 2.494135419884621

Epoch: 6| Step: 2
Training loss: 2.902391887691731
Validation loss: 2.4934683392592

Epoch: 6| Step: 3
Training loss: 2.665683644623437
Validation loss: 2.4898678457462182

Epoch: 6| Step: 4
Training loss: 3.694317738233325
Validation loss: 2.498614543619594

Epoch: 6| Step: 5
Training loss: 3.2739703124884416
Validation loss: 2.492963182268285

Epoch: 6| Step: 6
Training loss: 2.5869822624551033
Validation loss: 2.4916546944121287

Epoch: 6| Step: 7
Training loss: 3.0201254355041613
Validation loss: 2.496681923748666

Epoch: 6| Step: 8
Training loss: 2.6407845353007398
Validation loss: 2.4918585834212252

Epoch: 6| Step: 9
Training loss: 2.891069037896668
Validation loss: 2.4833306126794024

Epoch: 6| Step: 10
Training loss: 2.855619705739648
Validation loss: 2.498870153352496

Epoch: 6| Step: 11
Training loss: 2.370612860843907
Validation loss: 2.483033291387254

Epoch: 6| Step: 12
Training loss: 2.8921620174626983
Validation loss: 2.48443349185213

Epoch: 6| Step: 13
Training loss: 1.6494725309029088
Validation loss: 2.4931657555425626

Epoch: 27| Step: 0
Training loss: 3.059255944839391
Validation loss: 2.4936947177242157

Epoch: 6| Step: 1
Training loss: 2.5067860056322013
Validation loss: 2.490829379059996

Epoch: 6| Step: 2
Training loss: 3.397390480549968
Validation loss: 2.4935244135176524

Epoch: 6| Step: 3
Training loss: 2.4353730140430843
Validation loss: 2.494563676985937

Epoch: 6| Step: 4
Training loss: 2.623317360867739
Validation loss: 2.501956564766961

Epoch: 6| Step: 5
Training loss: 2.7637963580345972
Validation loss: 2.4927201083989994

Epoch: 6| Step: 6
Training loss: 2.6573481365460814
Validation loss: 2.4985043871624675

Epoch: 6| Step: 7
Training loss: 2.7295194402709235
Validation loss: 2.488653120326903

Epoch: 6| Step: 8
Training loss: 3.36791800166729
Validation loss: 2.4959535265532367

Epoch: 6| Step: 9
Training loss: 2.6542814252907614
Validation loss: 2.4943254530038113

Epoch: 6| Step: 10
Training loss: 2.6377114016887124
Validation loss: 2.5017407437875083

Epoch: 6| Step: 11
Training loss: 2.827860445747378
Validation loss: 2.4910824079755547

Epoch: 6| Step: 12
Training loss: 3.3705694999914275
Validation loss: 2.488197487906688

Epoch: 6| Step: 13
Training loss: 2.5854997062616545
Validation loss: 2.4896683244429307

Epoch: 28| Step: 0
Training loss: 2.6031060665765535
Validation loss: 2.496472299074716

Epoch: 6| Step: 1
Training loss: 2.738072799606472
Validation loss: 2.498180755494077

Epoch: 6| Step: 2
Training loss: 2.854813402695347
Validation loss: 2.498935092212901

Epoch: 6| Step: 3
Training loss: 3.2457809940243094
Validation loss: 2.498811404384338

Epoch: 6| Step: 4
Training loss: 3.204967731664508
Validation loss: 2.4978029544005564

Epoch: 6| Step: 5
Training loss: 2.3638180966304323
Validation loss: 2.487771545328862

Epoch: 6| Step: 6
Training loss: 2.849508805359922
Validation loss: 2.497650149617766

Epoch: 6| Step: 7
Training loss: 2.5500638692000464
Validation loss: 2.488924791420577

Epoch: 6| Step: 8
Training loss: 2.4578277800825283
Validation loss: 2.4937159694648647

Epoch: 6| Step: 9
Training loss: 3.102206915107473
Validation loss: 2.4973965122088058

Epoch: 6| Step: 10
Training loss: 3.3094165774174975
Validation loss: 2.4864076515742157

Epoch: 6| Step: 11
Training loss: 3.2543729559604593
Validation loss: 2.499518686538249

Epoch: 6| Step: 12
Training loss: 2.6221620568505055
Validation loss: 2.4940979086075052

Epoch: 6| Step: 13
Training loss: 1.8322780418503888
Validation loss: 2.4935625410313027

Epoch: 29| Step: 0
Training loss: 3.0938719137812214
Validation loss: 2.4958264707857554

Epoch: 6| Step: 1
Training loss: 2.240583743429828
Validation loss: 2.496558570979022

Epoch: 6| Step: 2
Training loss: 3.4420515964326976
Validation loss: 2.493376036062737

Epoch: 6| Step: 3
Training loss: 2.9770025293495164
Validation loss: 2.4903693008625662

Epoch: 6| Step: 4
Training loss: 2.8558705017265464
Validation loss: 2.4874132312422974

Epoch: 6| Step: 5
Training loss: 2.5239177990811337
Validation loss: 2.491456629173074

Epoch: 6| Step: 6
Training loss: 3.4384363459732765
Validation loss: 2.478783567973454

Epoch: 6| Step: 7
Training loss: 2.4149845670913823
Validation loss: 2.495633670527644

Epoch: 6| Step: 8
Training loss: 2.908523162796781
Validation loss: 2.481134211105734

Epoch: 6| Step: 9
Training loss: 2.619629042768519
Validation loss: 2.4815081710987523

Epoch: 6| Step: 10
Training loss: 2.7363364895482434
Validation loss: 2.487628311423718

Epoch: 6| Step: 11
Training loss: 2.839831324659028
Validation loss: 2.496847839877184

Epoch: 6| Step: 12
Training loss: 2.7745405555685485
Validation loss: 2.4922716222537447

Epoch: 6| Step: 13
Training loss: 2.1603908859769803
Validation loss: 2.49003272304785

Epoch: 30| Step: 0
Training loss: 3.1912061798995994
Validation loss: 2.4804999314256206

Epoch: 6| Step: 1
Training loss: 2.9101901673254202
Validation loss: 2.492454658245891

Epoch: 6| Step: 2
Training loss: 3.5203191317763767
Validation loss: 2.4798846505924628

Epoch: 6| Step: 3
Training loss: 3.0489003810103728
Validation loss: 2.486658055589328

Epoch: 6| Step: 4
Training loss: 2.271825264618515
Validation loss: 2.4847594851284676

Epoch: 6| Step: 5
Training loss: 3.814976247611042
Validation loss: 2.4904674162169815

Epoch: 6| Step: 6
Training loss: 2.73650778290255
Validation loss: 2.4917150103484844

Epoch: 6| Step: 7
Training loss: 2.649243437534724
Validation loss: 2.494994853726657

Epoch: 6| Step: 8
Training loss: 2.512991338105459
Validation loss: 2.4845999008832353

Epoch: 6| Step: 9
Training loss: 2.664601112129445
Validation loss: 2.4849536954673628

Epoch: 6| Step: 10
Training loss: 2.0471128369247387
Validation loss: 2.487166243397034

Epoch: 6| Step: 11
Training loss: 2.6548534536776507
Validation loss: 2.4813742873098943

Epoch: 6| Step: 12
Training loss: 2.17606065692227
Validation loss: 2.49547430192419

Epoch: 6| Step: 13
Training loss: 3.043594393972688
Validation loss: 2.4809940876402976

Epoch: 31| Step: 0
Training loss: 2.7677502413730553
Validation loss: 2.4881981138262534

Epoch: 6| Step: 1
Training loss: 3.5192704352844895
Validation loss: 2.495321779877691

Epoch: 6| Step: 2
Training loss: 2.831779689797187
Validation loss: 2.487482253627802

Epoch: 6| Step: 3
Training loss: 2.4656981908187356
Validation loss: 2.4868365183678884

Epoch: 6| Step: 4
Training loss: 1.9421546767538598
Validation loss: 2.480070243839479

Epoch: 6| Step: 5
Training loss: 2.1524394545419274
Validation loss: 2.486201144463588

Epoch: 6| Step: 6
Training loss: 1.9335660065481257
Validation loss: 2.4876470427416346

Epoch: 6| Step: 7
Training loss: 2.8988216176465667
Validation loss: 2.499846698818853

Epoch: 6| Step: 8
Training loss: 2.938921969763803
Validation loss: 2.4925869913955925

Epoch: 6| Step: 9
Training loss: 2.7986824546115425
Validation loss: 2.502648065797115

Epoch: 6| Step: 10
Training loss: 3.1238068400902024
Validation loss: 2.4811232100312113

Epoch: 6| Step: 11
Training loss: 3.1120538721202298
Validation loss: 2.486744640141429

Epoch: 6| Step: 12
Training loss: 3.749434746420262
Validation loss: 2.48452664422835

Epoch: 6| Step: 13
Training loss: 2.6875287431466215
Validation loss: 2.477972234265408

Epoch: 32| Step: 0
Training loss: 2.3377771182697913
Validation loss: 2.4845366840373586

Epoch: 6| Step: 1
Training loss: 3.54879238381493
Validation loss: 2.4897574608714352

Epoch: 6| Step: 2
Training loss: 2.7430232586682917
Validation loss: 2.491754531861317

Epoch: 6| Step: 3
Training loss: 3.306158509457864
Validation loss: 2.485602873786476

Epoch: 6| Step: 4
Training loss: 2.1818753545668486
Validation loss: 2.4913422541840013

Epoch: 6| Step: 5
Training loss: 2.3226751250402438
Validation loss: 2.4884530442131116

Epoch: 6| Step: 6
Training loss: 2.77801050694719
Validation loss: 2.4870875177724163

Epoch: 6| Step: 7
Training loss: 2.8260778953253887
Validation loss: 2.4864297744592343

Epoch: 6| Step: 8
Training loss: 3.3366798450414246
Validation loss: 2.4818716595673154

Epoch: 6| Step: 9
Training loss: 2.3242460361449786
Validation loss: 2.4937789916540574

Epoch: 6| Step: 10
Training loss: 2.405649085376472
Validation loss: 2.4895055742168704

Epoch: 6| Step: 11
Training loss: 3.3572622353335575
Validation loss: 2.486246795016232

Epoch: 6| Step: 12
Training loss: 2.8328167687545402
Validation loss: 2.482144904323673

Epoch: 6| Step: 13
Training loss: 2.665819232120724
Validation loss: 2.4860953691429133

Epoch: 33| Step: 0
Training loss: 3.29005341089369
Validation loss: 2.486540663272776

Epoch: 6| Step: 1
Training loss: 2.8778654000072836
Validation loss: 2.4806806891559763

Epoch: 6| Step: 2
Training loss: 1.9612351149899216
Validation loss: 2.4906097817606745

Epoch: 6| Step: 3
Training loss: 2.6935839431454056
Validation loss: 2.481867292265686

Epoch: 6| Step: 4
Training loss: 3.5356907561649082
Validation loss: 2.4817008859442384

Epoch: 6| Step: 5
Training loss: 3.7228926976817567
Validation loss: 2.485689826160477

Epoch: 6| Step: 6
Training loss: 3.0380678878341194
Validation loss: 2.4909270882872403

Epoch: 6| Step: 7
Training loss: 1.989432191017696
Validation loss: 2.477451583983431

Epoch: 6| Step: 8
Training loss: 3.222151949178336
Validation loss: 2.475980318162694

Epoch: 6| Step: 9
Training loss: 2.662288041252018
Validation loss: 2.480132757415175

Epoch: 6| Step: 10
Training loss: 2.5631904602249485
Validation loss: 2.4828989715119363

Epoch: 6| Step: 11
Training loss: 2.2415060144122934
Validation loss: 2.4835181734505882

Epoch: 6| Step: 12
Training loss: 2.11168165890561
Validation loss: 2.4904726320866666

Epoch: 6| Step: 13
Training loss: 3.011364234413886
Validation loss: 2.487303816566605

Epoch: 34| Step: 0
Training loss: 2.6084107770381566
Validation loss: 2.4837969850986816

Epoch: 6| Step: 1
Training loss: 2.4468380980065776
Validation loss: 2.4896936758162362

Epoch: 6| Step: 2
Training loss: 2.5246294826183138
Validation loss: 2.485161036078579

Epoch: 6| Step: 3
Training loss: 3.3598239332571866
Validation loss: 2.485756217000163

Epoch: 6| Step: 4
Training loss: 2.708898827619143
Validation loss: 2.4789475324915844

Epoch: 6| Step: 5
Training loss: 3.06589242311234
Validation loss: 2.4852108211433928

Epoch: 6| Step: 6
Training loss: 3.260865461927403
Validation loss: 2.481155403044747

Epoch: 6| Step: 7
Training loss: 3.2359432528015017
Validation loss: 2.4804493691563567

Epoch: 6| Step: 8
Training loss: 2.8264188731043096
Validation loss: 2.478408797598579

Epoch: 6| Step: 9
Training loss: 2.835730174659451
Validation loss: 2.481262758978042

Epoch: 6| Step: 10
Training loss: 2.2767241012827655
Validation loss: 2.4913382903963814

Epoch: 6| Step: 11
Training loss: 2.0283893101453585
Validation loss: 2.4783159893789004

Epoch: 6| Step: 12
Training loss: 3.292154557652135
Validation loss: 2.4749981873655718

Epoch: 6| Step: 13
Training loss: 2.1595818029986207
Validation loss: 2.4824311260665706

Epoch: 35| Step: 0
Training loss: 2.926646044954656
Validation loss: 2.485470938245814

Epoch: 6| Step: 1
Training loss: 2.9140386094655737
Validation loss: 2.486145662941588

Epoch: 6| Step: 2
Training loss: 3.1676673981014987
Validation loss: 2.4852245733290346

Epoch: 6| Step: 3
Training loss: 2.871467078194062
Validation loss: 2.4722270910990853

Epoch: 6| Step: 4
Training loss: 3.0059405954751317
Validation loss: 2.4869058196278457

Epoch: 6| Step: 5
Training loss: 2.7273065377075896
Validation loss: 2.479599557545324

Epoch: 6| Step: 6
Training loss: 2.439261167012166
Validation loss: 2.4918156344894573

Epoch: 6| Step: 7
Training loss: 2.1780580835995735
Validation loss: 2.4818037630653795

Epoch: 6| Step: 8
Training loss: 3.2925991878182037
Validation loss: 2.4880451426440446

Epoch: 6| Step: 9
Training loss: 3.0710794592626516
Validation loss: 2.4775851727279483

Epoch: 6| Step: 10
Training loss: 2.8545989291644314
Validation loss: 2.4761081251692394

Epoch: 6| Step: 11
Training loss: 2.2258370271645185
Validation loss: 2.4909368789653983

Epoch: 6| Step: 12
Training loss: 2.7271308197324475
Validation loss: 2.4863905931091796

Epoch: 6| Step: 13
Training loss: 2.569419079446316
Validation loss: 2.4903157682908508

Epoch: 36| Step: 0
Training loss: 3.2295226034249573
Validation loss: 2.4842515779210332

Epoch: 6| Step: 1
Training loss: 2.5763527067053813
Validation loss: 2.4890595184220357

Epoch: 6| Step: 2
Training loss: 3.3855141650123137
Validation loss: 2.4886627242268324

Epoch: 6| Step: 3
Training loss: 2.305855148133196
Validation loss: 2.481629734805657

Epoch: 6| Step: 4
Training loss: 2.126510083563689
Validation loss: 2.481885954472713

Epoch: 6| Step: 5
Training loss: 3.0966918521619315
Validation loss: 2.475856143154389

Epoch: 6| Step: 6
Training loss: 2.7136081875331186
Validation loss: 2.480134097568913

Epoch: 6| Step: 7
Training loss: 2.758118869092651
Validation loss: 2.487094557991401

Epoch: 6| Step: 8
Training loss: 2.7175902600639117
Validation loss: 2.4809190752978636

Epoch: 6| Step: 9
Training loss: 2.5321870176241172
Validation loss: 2.4791583127172045

Epoch: 6| Step: 10
Training loss: 2.7784711692897264
Validation loss: 2.4835241739804697

Epoch: 6| Step: 11
Training loss: 3.136011483346584
Validation loss: 2.487689826620362

Epoch: 6| Step: 12
Training loss: 2.594531941033294
Validation loss: 2.482989200684937

Epoch: 6| Step: 13
Training loss: 3.053565870644874
Validation loss: 2.4705092876493095

Epoch: 37| Step: 0
Training loss: 1.8198591330791811
Validation loss: 2.4882637113844037

Epoch: 6| Step: 1
Training loss: 1.5093448738582536
Validation loss: 2.480420851590177

Epoch: 6| Step: 2
Training loss: 3.3364960607102123
Validation loss: 2.485848879447397

Epoch: 6| Step: 3
Training loss: 2.200104936351226
Validation loss: 2.48208043716252

Epoch: 6| Step: 4
Training loss: 3.0160522158324663
Validation loss: 2.480505929955219

Epoch: 6| Step: 5
Training loss: 3.3770706041595453
Validation loss: 2.4813712550023936

Epoch: 6| Step: 6
Training loss: 2.9515869333478664
Validation loss: 2.4805785230021407

Epoch: 6| Step: 7
Training loss: 2.847104954566033
Validation loss: 2.485742052642226

Epoch: 6| Step: 8
Training loss: 2.624431548557509
Validation loss: 2.4774563688449907

Epoch: 6| Step: 9
Training loss: 2.6698880308583273
Validation loss: 2.484444569073943

Epoch: 6| Step: 10
Training loss: 3.140844688513082
Validation loss: 2.4890285935736403

Epoch: 6| Step: 11
Training loss: 2.7887550847081126
Validation loss: 2.4801448916461792

Epoch: 6| Step: 12
Training loss: 2.9288472102236676
Validation loss: 2.478883870031429

Epoch: 6| Step: 13
Training loss: 3.68005291527561
Validation loss: 2.473166649422538

Epoch: 38| Step: 0
Training loss: 2.538133750661848
Validation loss: 2.4788573966559713

Epoch: 6| Step: 1
Training loss: 2.60380297346431
Validation loss: 2.495611834170792

Epoch: 6| Step: 2
Training loss: 2.4923007664308017
Validation loss: 2.481058762820451

Epoch: 6| Step: 3
Training loss: 2.3824322506537468
Validation loss: 2.479834395220712

Epoch: 6| Step: 4
Training loss: 3.0993656863091683
Validation loss: 2.476871288910212

Epoch: 6| Step: 5
Training loss: 2.8833725134625947
Validation loss: 2.4879332466632382

Epoch: 6| Step: 6
Training loss: 3.5398193627946357
Validation loss: 2.474207863693601

Epoch: 6| Step: 7
Training loss: 3.181943950396801
Validation loss: 2.484435165563148

Epoch: 6| Step: 8
Training loss: 2.5698686117882072
Validation loss: 2.4938440271070395

Epoch: 6| Step: 9
Training loss: 3.329598400654883
Validation loss: 2.4757016876163376

Epoch: 6| Step: 10
Training loss: 2.1735787055782594
Validation loss: 2.4815503066679496

Epoch: 6| Step: 11
Training loss: 2.5367580813738484
Validation loss: 2.4881881969751185

Epoch: 6| Step: 12
Training loss: 2.6226584572281353
Validation loss: 2.490392530688258

Epoch: 6| Step: 13
Training loss: 2.9908436279743262
Validation loss: 2.488310373946251

Epoch: 39| Step: 0
Training loss: 2.745214199331925
Validation loss: 2.4893777043005607

Epoch: 6| Step: 1
Training loss: 3.2355073430180363
Validation loss: 2.4859963315299907

Epoch: 6| Step: 2
Training loss: 2.9161127563570113
Validation loss: 2.4852019677758

Epoch: 6| Step: 3
Training loss: 2.842497161890658
Validation loss: 2.4930471225584894

Epoch: 6| Step: 4
Training loss: 2.828322935817701
Validation loss: 2.4836254365419235

Epoch: 6| Step: 5
Training loss: 2.3055170150456576
Validation loss: 2.486850604330588

Epoch: 6| Step: 6
Training loss: 2.4371895225566402
Validation loss: 2.476592827957985

Epoch: 6| Step: 7
Training loss: 2.321231133585129
Validation loss: 2.489481248657777

Epoch: 6| Step: 8
Training loss: 2.6910626063327463
Validation loss: 2.4779879959193627

Epoch: 6| Step: 9
Training loss: 2.491237543039525
Validation loss: 2.493428249606696

Epoch: 6| Step: 10
Training loss: 3.232921476449464
Validation loss: 2.4963507752244336

Epoch: 6| Step: 11
Training loss: 2.9632808702399736
Validation loss: 2.4840992275115883

Epoch: 6| Step: 12
Training loss: 3.2315624742661946
Validation loss: 2.496506929161964

Epoch: 6| Step: 13
Training loss: 2.3865366365220875
Validation loss: 2.4921980541405793

Epoch: 40| Step: 0
Training loss: 2.6291120202077782
Validation loss: 2.493544274647664

Epoch: 6| Step: 1
Training loss: 2.8072883638965282
Validation loss: 2.48642700608065

Epoch: 6| Step: 2
Training loss: 2.653303778817644
Validation loss: 2.483001108266551

Epoch: 6| Step: 3
Training loss: 2.6404552518017756
Validation loss: 2.488073177160078

Epoch: 6| Step: 4
Training loss: 2.7674703529927114
Validation loss: 2.4904806941712283

Epoch: 6| Step: 5
Training loss: 3.202212319954039
Validation loss: 2.4871391500488076

Epoch: 6| Step: 6
Training loss: 2.9149908064996604
Validation loss: 2.498954303016

Epoch: 6| Step: 7
Training loss: 3.089072959623636
Validation loss: 2.487684307092031

Epoch: 6| Step: 8
Training loss: 2.306608789338943
Validation loss: 2.481004736929555

Epoch: 6| Step: 9
Training loss: 2.910740490326537
Validation loss: 2.492428479184254

Epoch: 6| Step: 10
Training loss: 2.881660375932042
Validation loss: 2.4883838777348664

Epoch: 6| Step: 11
Training loss: 2.744166429065733
Validation loss: 2.4810737361072213

Epoch: 6| Step: 12
Training loss: 2.6730852564991605
Validation loss: 2.4794185617658004

Epoch: 6| Step: 13
Training loss: 2.7412067626660406
Validation loss: 2.479051004222649

Epoch: 41| Step: 0
Training loss: 3.281145947940971
Validation loss: 2.486040551424846

Epoch: 6| Step: 1
Training loss: 3.09307715295123
Validation loss: 2.487047245893689

Epoch: 6| Step: 2
Training loss: 2.7196196119007268
Validation loss: 2.482898402593842

Epoch: 6| Step: 3
Training loss: 2.5098352563601867
Validation loss: 2.4849666686253333

Epoch: 6| Step: 4
Training loss: 2.3008054981346384
Validation loss: 2.497111217354271

Epoch: 6| Step: 5
Training loss: 2.6450220100626423
Validation loss: 2.4833397622887934

Epoch: 6| Step: 6
Training loss: 2.4971489862215286
Validation loss: 2.4811426682713105

Epoch: 6| Step: 7
Training loss: 2.8822907593374936
Validation loss: 2.4977669874699218

Epoch: 6| Step: 8
Training loss: 3.0211463152226505
Validation loss: 2.4790273371986355

Epoch: 6| Step: 9
Training loss: 2.7210987512683276
Validation loss: 2.4866353300727955

Epoch: 6| Step: 10
Training loss: 2.7624379561003196
Validation loss: 2.4947995496939566

Epoch: 6| Step: 11
Training loss: 2.437948919185173
Validation loss: 2.4886399943533166

Epoch: 6| Step: 12
Training loss: 2.8595520965264862
Validation loss: 2.4757692803149784

Epoch: 6| Step: 13
Training loss: 3.189593955000906
Validation loss: 2.4851029894660943

Epoch: 42| Step: 0
Training loss: 2.754112376622048
Validation loss: 2.4807166299558303

Epoch: 6| Step: 1
Training loss: 2.755761872749185
Validation loss: 2.475089185161692

Epoch: 6| Step: 2
Training loss: 2.8004494102034565
Validation loss: 2.482079296885247

Epoch: 6| Step: 3
Training loss: 3.343877629491424
Validation loss: 2.4919404802273295

Epoch: 6| Step: 4
Training loss: 2.7777337123766523
Validation loss: 2.4804517648981115

Epoch: 6| Step: 5
Training loss: 2.565876759525769
Validation loss: 2.4919573715910155

Epoch: 6| Step: 6
Training loss: 2.8602430349738133
Validation loss: 2.4798569923278513

Epoch: 6| Step: 7
Training loss: 3.130810485572358
Validation loss: 2.4786848246460096

Epoch: 6| Step: 8
Training loss: 2.6491462411860054
Validation loss: 2.49193223562831

Epoch: 6| Step: 9
Training loss: 2.6943989407956357
Validation loss: 2.479696279451117

Epoch: 6| Step: 10
Training loss: 2.6635235104161463
Validation loss: 2.474775994004903

Epoch: 6| Step: 11
Training loss: 2.312165725879766
Validation loss: 2.4847761807859907

Epoch: 6| Step: 12
Training loss: 2.700481114084688
Validation loss: 2.483050433315514

Epoch: 6| Step: 13
Training loss: 2.804596965890601
Validation loss: 2.4711912812419965

Epoch: 43| Step: 0
Training loss: 1.7559838850198664
Validation loss: 2.4865403544861837

Epoch: 6| Step: 1
Training loss: 2.73827428449542
Validation loss: 2.489536945207584

Epoch: 6| Step: 2
Training loss: 2.343755493157625
Validation loss: 2.4761031803286744

Epoch: 6| Step: 3
Training loss: 2.6849731276319986
Validation loss: 2.479913447237864

Epoch: 6| Step: 4
Training loss: 1.9296314061463722
Validation loss: 2.4851471901828948

Epoch: 6| Step: 5
Training loss: 3.0094319529308664
Validation loss: 2.4710741392199758

Epoch: 6| Step: 6
Training loss: 2.649891322084712
Validation loss: 2.4727131528685935

Epoch: 6| Step: 7
Training loss: 3.189831348612772
Validation loss: 2.4763559767918433

Epoch: 6| Step: 8
Training loss: 2.9878111226390183
Validation loss: 2.495996002687204

Epoch: 6| Step: 9
Training loss: 3.13783223494239
Validation loss: 2.472425674434007

Epoch: 6| Step: 10
Training loss: 3.2773245446025476
Validation loss: 2.4748110965397148

Epoch: 6| Step: 11
Training loss: 2.315438336919737
Validation loss: 2.480320764658108

Epoch: 6| Step: 12
Training loss: 3.3077537073704635
Validation loss: 2.49684891488509

Epoch: 6| Step: 13
Training loss: 3.1621142005058918
Validation loss: 2.4883067690161043

Epoch: 44| Step: 0
Training loss: 2.4967135762729775
Validation loss: 2.483486779077765

Epoch: 6| Step: 1
Training loss: 2.4735420171231444
Validation loss: 2.479901001744216

Epoch: 6| Step: 2
Training loss: 2.381256295744015
Validation loss: 2.4814184614627153

Epoch: 6| Step: 3
Training loss: 3.5093466073957194
Validation loss: 2.4834375886353426

Epoch: 6| Step: 4
Training loss: 3.3193380923150553
Validation loss: 2.4742259650983893

Epoch: 6| Step: 5
Training loss: 2.0679924398981324
Validation loss: 2.487023592084333

Epoch: 6| Step: 6
Training loss: 3.049803280349099
Validation loss: 2.4824420898473654

Epoch: 6| Step: 7
Training loss: 2.4686677170573628
Validation loss: 2.4879265880167583

Epoch: 6| Step: 8
Training loss: 2.5869122192330165
Validation loss: 2.474765203962032

Epoch: 6| Step: 9
Training loss: 2.8711638357729754
Validation loss: 2.4965715233678223

Epoch: 6| Step: 10
Training loss: 3.153993612066463
Validation loss: 2.4867014245318084

Epoch: 6| Step: 11
Training loss: 2.810649687031098
Validation loss: 2.489423837253879

Epoch: 6| Step: 12
Training loss: 2.168391116127628
Validation loss: 2.485831269011414

Epoch: 6| Step: 13
Training loss: 3.195188934996218
Validation loss: 2.4959235119090164

Epoch: 45| Step: 0
Training loss: 2.666535960411508
Validation loss: 2.4840735125306255

Epoch: 6| Step: 1
Training loss: 2.997745938683034
Validation loss: 2.486925916075351

Epoch: 6| Step: 2
Training loss: 2.7833134572429192
Validation loss: 2.475455059318259

Epoch: 6| Step: 3
Training loss: 2.0470704429443716
Validation loss: 2.4814047971795934

Epoch: 6| Step: 4
Training loss: 2.6064941584618415
Validation loss: 2.4849879950086926

Epoch: 6| Step: 5
Training loss: 2.9459590455191287
Validation loss: 2.477048850537273

Epoch: 6| Step: 6
Training loss: 2.3219616099822153
Validation loss: 2.4944290622760947

Epoch: 6| Step: 7
Training loss: 3.173199306697714
Validation loss: 2.4799831621430055

Epoch: 6| Step: 8
Training loss: 2.8011029217028804
Validation loss: 2.484314803053763

Epoch: 6| Step: 9
Training loss: 2.3893973994620805
Validation loss: 2.486987117751832

Epoch: 6| Step: 10
Training loss: 3.0820686908570245
Validation loss: 2.4814478369371393

Epoch: 6| Step: 11
Training loss: 3.1967471756275647
Validation loss: 2.484474525307834

Epoch: 6| Step: 12
Training loss: 3.197034749414658
Validation loss: 2.4840507747216596

Epoch: 6| Step: 13
Training loss: 1.8126355482257122
Validation loss: 2.48477884473481

Epoch: 46| Step: 0
Training loss: 2.8879722176058213
Validation loss: 2.4776271763478244

Epoch: 6| Step: 1
Training loss: 2.23514826272166
Validation loss: 2.480593625272123

Epoch: 6| Step: 2
Training loss: 2.385985616162568
Validation loss: 2.491802094095213

Epoch: 6| Step: 3
Training loss: 2.527760490479469
Validation loss: 2.472494416367179

Epoch: 6| Step: 4
Training loss: 3.0872237603168076
Validation loss: 2.4799392942579876

Epoch: 6| Step: 5
Training loss: 2.4907043252946064
Validation loss: 2.49185737457314

Epoch: 6| Step: 6
Training loss: 2.334478732948716
Validation loss: 2.4897656817818508

Epoch: 6| Step: 7
Training loss: 3.2425433963174575
Validation loss: 2.472841911977074

Epoch: 6| Step: 8
Training loss: 3.2164600707863436
Validation loss: 2.4833258995282943

Epoch: 6| Step: 9
Training loss: 3.10910032966521
Validation loss: 2.4937825074607196

Epoch: 6| Step: 10
Training loss: 2.7182548335107923
Validation loss: 2.4804189147154636

Epoch: 6| Step: 11
Training loss: 2.825965858021056
Validation loss: 2.4940148686757206

Epoch: 6| Step: 12
Training loss: 2.6222519795656436
Validation loss: 2.4846130218891767

Epoch: 6| Step: 13
Training loss: 2.613387899688736
Validation loss: 2.48448690713298

Epoch: 47| Step: 0
Training loss: 3.2231866573452397
Validation loss: 2.4871454819922283

Epoch: 6| Step: 1
Training loss: 3.325991524305343
Validation loss: 2.4821692413597036

Epoch: 6| Step: 2
Training loss: 2.8698476980916077
Validation loss: 2.503812838759492

Epoch: 6| Step: 3
Training loss: 2.8769060533742508
Validation loss: 2.483465927040751

Epoch: 6| Step: 4
Training loss: 2.635748157586329
Validation loss: 2.485595454944631

Epoch: 6| Step: 5
Training loss: 2.740179908303578
Validation loss: 2.488422060316392

Epoch: 6| Step: 6
Training loss: 1.7981389120158424
Validation loss: 2.4909413446051505

Epoch: 6| Step: 7
Training loss: 3.0369724647597622
Validation loss: 2.4781561681291584

Epoch: 6| Step: 8
Training loss: 2.736756165357862
Validation loss: 2.4895973124510435

Epoch: 6| Step: 9
Training loss: 2.606992719100893
Validation loss: 2.489984860355051

Epoch: 6| Step: 10
Training loss: 2.4734866900682575
Validation loss: 2.486783515919481

Epoch: 6| Step: 11
Training loss: 2.5357800672813844
Validation loss: 2.4769437369740275

Epoch: 6| Step: 12
Training loss: 2.964853560641295
Validation loss: 2.497267231349357

Epoch: 6| Step: 13
Training loss: 2.1821149756037492
Validation loss: 2.487601871334826

Epoch: 48| Step: 0
Training loss: 2.801417662859904
Validation loss: 2.4844982137042737

Epoch: 6| Step: 1
Training loss: 2.980985624159042
Validation loss: 2.484081262038604

Epoch: 6| Step: 2
Training loss: 2.7757475353011167
Validation loss: 2.482600246279487

Epoch: 6| Step: 3
Training loss: 2.863821605784533
Validation loss: 2.472662134848301

Epoch: 6| Step: 4
Training loss: 2.92603792865026
Validation loss: 2.489059631718026

Epoch: 6| Step: 5
Training loss: 2.026588843298688
Validation loss: 2.4881690751139045

Epoch: 6| Step: 6
Training loss: 1.9563751034450523
Validation loss: 2.4745193986832077

Epoch: 6| Step: 7
Training loss: 2.521796953962424
Validation loss: 2.484590918941289

Epoch: 6| Step: 8
Training loss: 2.936037226958047
Validation loss: 2.493864837600367

Epoch: 6| Step: 9
Training loss: 3.010192405152873
Validation loss: 2.4890270238891574

Epoch: 6| Step: 10
Training loss: 3.1268300610640685
Validation loss: 2.484429315824715

Epoch: 6| Step: 11
Training loss: 2.7079217940438145
Validation loss: 2.4897320947023323

Epoch: 6| Step: 12
Training loss: 2.892094748816645
Validation loss: 2.485620963373499

Epoch: 6| Step: 13
Training loss: 2.90002891263032
Validation loss: 2.4927868303253966

Epoch: 49| Step: 0
Training loss: 2.4175946218914244
Validation loss: 2.4858991070751246

Epoch: 6| Step: 1
Training loss: 2.7216492026010703
Validation loss: 2.493066732984627

Epoch: 6| Step: 2
Training loss: 3.2879224962627487
Validation loss: 2.488452348818165

Epoch: 6| Step: 3
Training loss: 2.3275676290518517
Validation loss: 2.490138652328232

Epoch: 6| Step: 4
Training loss: 3.1046893983248633
Validation loss: 2.496461874937251

Epoch: 6| Step: 5
Training loss: 2.054920952012158
Validation loss: 2.4844881200831557

Epoch: 6| Step: 6
Training loss: 3.0367067910428274
Validation loss: 2.483370510221384

Epoch: 6| Step: 7
Training loss: 2.3185361491090326
Validation loss: 2.4816316645370664

Epoch: 6| Step: 8
Training loss: 2.6665652871729235
Validation loss: 2.4851041221663435

Epoch: 6| Step: 9
Training loss: 2.7941270680460644
Validation loss: 2.4935099437242965

Epoch: 6| Step: 10
Training loss: 2.906796967913462
Validation loss: 2.4799154940860593

Epoch: 6| Step: 11
Training loss: 3.1257347768977155
Validation loss: 2.4920887240387986

Epoch: 6| Step: 12
Training loss: 2.861058807717993
Validation loss: 2.488765695730824

Epoch: 6| Step: 13
Training loss: 2.6480172423063557
Validation loss: 2.4894499984818403

Epoch: 50| Step: 0
Training loss: 3.395302495050765
Validation loss: 2.477708875146386

Epoch: 6| Step: 1
Training loss: 2.6388481527385523
Validation loss: 2.4913219741782338

Epoch: 6| Step: 2
Training loss: 2.101564882411812
Validation loss: 2.4904233099250157

Epoch: 6| Step: 3
Training loss: 2.4971640714334735
Validation loss: 2.482981305285673

Epoch: 6| Step: 4
Training loss: 2.470301852604446
Validation loss: 2.488793160740173

Epoch: 6| Step: 5
Training loss: 2.2745420519014194
Validation loss: 2.4849647352938

Epoch: 6| Step: 6
Training loss: 2.9508467671274303
Validation loss: 2.485620748844702

Epoch: 6| Step: 7
Training loss: 2.6057052848088014
Validation loss: 2.48792302890005

Epoch: 6| Step: 8
Training loss: 2.736577656359693
Validation loss: 2.4935568905674925

Epoch: 6| Step: 9
Training loss: 3.217273262292573
Validation loss: 2.4957064481013727

Epoch: 6| Step: 10
Training loss: 2.7320813831925297
Validation loss: 2.4817210059460217

Epoch: 6| Step: 11
Training loss: 2.455706070716855
Validation loss: 2.497065867060968

Epoch: 6| Step: 12
Training loss: 3.36209493132935
Validation loss: 2.480707358027514

Epoch: 6| Step: 13
Training loss: 2.950436129901547
Validation loss: 2.4858921789734416

Epoch: 51| Step: 0
Training loss: 2.67548274024924
Validation loss: 2.4886400376190787

Epoch: 6| Step: 1
Training loss: 2.7397417861504856
Validation loss: 2.487272791555695

Epoch: 6| Step: 2
Training loss: 2.6305258581285993
Validation loss: 2.4820641437486732

Epoch: 6| Step: 3
Training loss: 2.971232771448394
Validation loss: 2.4948628116786975

Epoch: 6| Step: 4
Training loss: 3.1460345542838604
Validation loss: 2.4779688563855977

Epoch: 6| Step: 5
Training loss: 2.9840736436730677
Validation loss: 2.49507467791044

Epoch: 6| Step: 6
Training loss: 2.980712400703974
Validation loss: 2.48355927880267

Epoch: 6| Step: 7
Training loss: 2.7020896737037297
Validation loss: 2.4840604387287155

Epoch: 6| Step: 8
Training loss: 2.569844954151691
Validation loss: 2.476131937088789

Epoch: 6| Step: 9
Training loss: 2.4282430298543294
Validation loss: 2.491531277959822

Epoch: 6| Step: 10
Training loss: 2.21274732511249
Validation loss: 2.4830504374453386

Epoch: 6| Step: 11
Training loss: 2.876919313065057
Validation loss: 2.4738920490255913

Epoch: 6| Step: 12
Training loss: 2.7486738128303982
Validation loss: 2.4744020816426544

Epoch: 6| Step: 13
Training loss: 2.6079787670453016
Validation loss: 2.4853757345581564

Epoch: 52| Step: 0
Training loss: 2.439160099557217
Validation loss: 2.49623158497496

Epoch: 6| Step: 1
Training loss: 2.6578525869854985
Validation loss: 2.495988913624251

Epoch: 6| Step: 2
Training loss: 3.0369388642851
Validation loss: 2.4704297167822684

Epoch: 6| Step: 3
Training loss: 2.8237424161217293
Validation loss: 2.496030072430527

Epoch: 6| Step: 4
Training loss: 2.2691452564803614
Validation loss: 2.4923297179165953

Epoch: 6| Step: 5
Training loss: 2.9733484893321322
Validation loss: 2.487726346297785

Epoch: 6| Step: 6
Training loss: 2.664745343979514
Validation loss: 2.495812070320019

Epoch: 6| Step: 7
Training loss: 3.371292338262776
Validation loss: 2.4734079602159205

Epoch: 6| Step: 8
Training loss: 2.5392095435186115
Validation loss: 2.4824664735394686

Epoch: 6| Step: 9
Training loss: 2.9912922368971233
Validation loss: 2.4906271216667997

Epoch: 6| Step: 10
Training loss: 3.0218473289193275
Validation loss: 2.498074110713074

Epoch: 6| Step: 11
Training loss: 2.468550855113134
Validation loss: 2.4874603993056645

Epoch: 6| Step: 12
Training loss: 2.3135991963724134
Validation loss: 2.487969925573138

Epoch: 6| Step: 13
Training loss: 2.459487245511499
Validation loss: 2.475313518095027

Epoch: 53| Step: 0
Training loss: 2.7593025310327377
Validation loss: 2.4904798614060413

Epoch: 6| Step: 1
Training loss: 2.7270572071460775
Validation loss: 2.4822806561527724

Epoch: 6| Step: 2
Training loss: 2.83414438270513
Validation loss: 2.4936764235231963

Epoch: 6| Step: 3
Training loss: 2.371836010357393
Validation loss: 2.4914756676660867

Epoch: 6| Step: 4
Training loss: 2.8821713114431384
Validation loss: 2.482233028183926

Epoch: 6| Step: 5
Training loss: 2.5593920212250696
Validation loss: 2.485339438217068

Epoch: 6| Step: 6
Training loss: 3.1771291427228094
Validation loss: 2.484827363801757

Epoch: 6| Step: 7
Training loss: 3.200576438244889
Validation loss: 2.489346334392612

Epoch: 6| Step: 8
Training loss: 2.7897773916385264
Validation loss: 2.4945734215329503

Epoch: 6| Step: 9
Training loss: 2.231761978351441
Validation loss: 2.4851772080943526

Epoch: 6| Step: 10
Training loss: 2.4373415381935524
Validation loss: 2.489900836906442

Epoch: 6| Step: 11
Training loss: 1.8213623686654785
Validation loss: 2.4941648105535643

Epoch: 6| Step: 12
Training loss: 3.47666262364602
Validation loss: 2.4873446820820617

Epoch: 6| Step: 13
Training loss: 2.689336459774431
Validation loss: 2.4904522605896977

Epoch: 54| Step: 0
Training loss: 3.039105491039912
Validation loss: 2.4821112492391957

Epoch: 6| Step: 1
Training loss: 2.588002650877171
Validation loss: 2.490631197752104

Epoch: 6| Step: 2
Training loss: 3.100888426435741
Validation loss: 2.4895783919164676

Epoch: 6| Step: 3
Training loss: 2.620640722655666
Validation loss: 2.5010625867819507

Epoch: 6| Step: 4
Training loss: 2.889646952358946
Validation loss: 2.4892641699505442

Epoch: 6| Step: 5
Training loss: 2.8395151318098053
Validation loss: 2.4903040696617125

Epoch: 6| Step: 6
Training loss: 2.3631038882955275
Validation loss: 2.4812800340215886

Epoch: 6| Step: 7
Training loss: 2.2938412723519823
Validation loss: 2.4866369703418196

Epoch: 6| Step: 8
Training loss: 2.546212701163803
Validation loss: 2.4758589409555065

Epoch: 6| Step: 9
Training loss: 2.9400383553630487
Validation loss: 2.48330413199406

Epoch: 6| Step: 10
Training loss: 2.009506282996848
Validation loss: 2.4915946558518045

Epoch: 6| Step: 11
Training loss: 2.943270109224101
Validation loss: 2.4964945730647616

Epoch: 6| Step: 12
Training loss: 3.084589178346109
Validation loss: 2.4885650002653392

Epoch: 6| Step: 13
Training loss: 3.051394665893525
Validation loss: 2.4907830261484207

Epoch: 55| Step: 0
Training loss: 2.6534636300489276
Validation loss: 2.491545522589146

Epoch: 6| Step: 1
Training loss: 2.362101312329912
Validation loss: 2.5026908513682167

Epoch: 6| Step: 2
Training loss: 3.235187667992592
Validation loss: 2.479721328541098

Epoch: 6| Step: 3
Training loss: 2.566013439663592
Validation loss: 2.500520532007662

Epoch: 6| Step: 4
Training loss: 2.636669017181442
Validation loss: 2.502402769113114

Epoch: 6| Step: 5
Training loss: 2.820630676412587
Validation loss: 2.494962818735846

Epoch: 6| Step: 6
Training loss: 3.326164420316074
Validation loss: 2.4911414827776697

Epoch: 6| Step: 7
Training loss: 2.832145067755967
Validation loss: 2.496765573190516

Epoch: 6| Step: 8
Training loss: 2.9958924147537087
Validation loss: 2.4887981298112374

Epoch: 6| Step: 9
Training loss: 2.2715954216326724
Validation loss: 2.5015207843633336

Epoch: 6| Step: 10
Training loss: 2.4033909445888613
Validation loss: 2.4872006361144017

Epoch: 6| Step: 11
Training loss: 2.7387523381942733
Validation loss: 2.493015653314689

Epoch: 6| Step: 12
Training loss: 2.352648411446572
Validation loss: 2.498734414306588

Epoch: 6| Step: 13
Training loss: 2.9782548233668176
Validation loss: 2.498036488221003

Epoch: 56| Step: 0
Training loss: 2.50878126975483
Validation loss: 2.4815621219787527

Epoch: 6| Step: 1
Training loss: 2.669259112572717
Validation loss: 2.478063407347388

Epoch: 6| Step: 2
Training loss: 3.1668801653985312
Validation loss: 2.510374851020665

Epoch: 6| Step: 3
Training loss: 2.4465751922235324
Validation loss: 2.504346244378703

Epoch: 6| Step: 4
Training loss: 3.1898923385772546
Validation loss: 2.4957517876582096

Epoch: 6| Step: 5
Training loss: 2.914334118331576
Validation loss: 2.4937092584084364

Epoch: 6| Step: 6
Training loss: 2.7835543226886013
Validation loss: 2.501045523206066

Epoch: 6| Step: 7
Training loss: 3.117317522057257
Validation loss: 2.493331008547246

Epoch: 6| Step: 8
Training loss: 3.012261446929566
Validation loss: 2.4844855703590456

Epoch: 6| Step: 9
Training loss: 2.143423770738772
Validation loss: 2.4970621454113506

Epoch: 6| Step: 10
Training loss: 2.436440751195919
Validation loss: 2.490767194160983

Epoch: 6| Step: 11
Training loss: 2.0743390926645047
Validation loss: 2.4951071635506623

Epoch: 6| Step: 12
Training loss: 3.145212495353879
Validation loss: 2.4968734099493575

Epoch: 6| Step: 13
Training loss: 2.0362934588904946
Validation loss: 2.487781905922192

Epoch: 57| Step: 0
Training loss: 2.4462459842140167
Validation loss: 2.4917436322048916

Epoch: 6| Step: 1
Training loss: 3.026355370408923
Validation loss: 2.4917622811444002

Epoch: 6| Step: 2
Training loss: 3.278985831781219
Validation loss: 2.486649618212702

Epoch: 6| Step: 3
Training loss: 2.82358401435059
Validation loss: 2.489104239038639

Epoch: 6| Step: 4
Training loss: 2.985187200302455
Validation loss: 2.4883483134845363

Epoch: 6| Step: 5
Training loss: 2.3719312015353426
Validation loss: 2.490270352925059

Epoch: 6| Step: 6
Training loss: 2.3838372700343626
Validation loss: 2.4843747605978743

Epoch: 6| Step: 7
Training loss: 2.792978396098946
Validation loss: 2.482096706713795

Epoch: 6| Step: 8
Training loss: 2.2133173451171735
Validation loss: 2.481862672400051

Epoch: 6| Step: 9
Training loss: 2.584618546104943
Validation loss: 2.4970907100850663

Epoch: 6| Step: 10
Training loss: 2.4916225259330638
Validation loss: 2.4993338866506045

Epoch: 6| Step: 11
Training loss: 3.0179601927420423
Validation loss: 2.51191777108544

Epoch: 6| Step: 12
Training loss: 3.159040671448721
Validation loss: 2.48857285116514

Epoch: 6| Step: 13
Training loss: 2.2946093537205066
Validation loss: 2.487273313091584

Epoch: 58| Step: 0
Training loss: 2.8450180412484727
Validation loss: 2.496455252388534

Epoch: 6| Step: 1
Training loss: 2.193841190018709
Validation loss: 2.4867409772716114

Epoch: 6| Step: 2
Training loss: 2.7302041641857495
Validation loss: 2.489031728819736

Epoch: 6| Step: 3
Training loss: 2.612036894860466
Validation loss: 2.4854151113834115

Epoch: 6| Step: 4
Training loss: 3.103867757516796
Validation loss: 2.489641728906752

Epoch: 6| Step: 5
Training loss: 2.8413743376808087
Validation loss: 2.5029965869078494

Epoch: 6| Step: 6
Training loss: 3.0108749058487025
Validation loss: 2.490003714997084

Epoch: 6| Step: 7
Training loss: 2.6800727233698844
Validation loss: 2.48116077694454

Epoch: 6| Step: 8
Training loss: 3.110003997211402
Validation loss: 2.4982850499216487

Epoch: 6| Step: 9
Training loss: 3.066748649772881
Validation loss: 2.479618244057068

Epoch: 6| Step: 10
Training loss: 2.7940873046975416
Validation loss: 2.485766120864352

Epoch: 6| Step: 11
Training loss: 2.432417436788347
Validation loss: 2.5065291054067145

Epoch: 6| Step: 12
Training loss: 2.1900800476076667
Validation loss: 2.4892602780351534

Epoch: 6| Step: 13
Training loss: 2.0523562822659933
Validation loss: 2.4998874454387456

Epoch: 59| Step: 0
Training loss: 2.636970474095226
Validation loss: 2.492105188513934

Epoch: 6| Step: 1
Training loss: 3.3228807277988115
Validation loss: 2.4938281374527094

Epoch: 6| Step: 2
Training loss: 2.875703476794886
Validation loss: 2.4918139101792267

Epoch: 6| Step: 3
Training loss: 2.7075039009214077
Validation loss: 2.506318467259873

Epoch: 6| Step: 4
Training loss: 2.601687225009679
Validation loss: 2.489351761669337

Epoch: 6| Step: 5
Training loss: 2.8232926872537303
Validation loss: 2.499541807743088

Epoch: 6| Step: 6
Training loss: 2.7543699915671382
Validation loss: 2.4973085620808924

Epoch: 6| Step: 7
Training loss: 3.1280774031913667
Validation loss: 2.487994818205486

Epoch: 6| Step: 8
Training loss: 2.3223350264282683
Validation loss: 2.497542341264002

Epoch: 6| Step: 9
Training loss: 1.876703442212652
Validation loss: 2.4834491513466594

Epoch: 6| Step: 10
Training loss: 2.309994654958907
Validation loss: 2.4934606980928384

Epoch: 6| Step: 11
Training loss: 2.865660382866686
Validation loss: 2.490831709239547

Epoch: 6| Step: 12
Training loss: 2.796516182328671
Validation loss: 2.5003860329408387

Epoch: 6| Step: 13
Training loss: 2.999723262738604
Validation loss: 2.497339100043441

Epoch: 60| Step: 0
Training loss: 2.5504615665150707
Validation loss: 2.4924284956413962

Epoch: 6| Step: 1
Training loss: 3.007418361453169
Validation loss: 2.4809533407187963

Epoch: 6| Step: 2
Training loss: 2.3187998969372354
Validation loss: 2.4827592285081486

Epoch: 6| Step: 3
Training loss: 3.0333095514671715
Validation loss: 2.49430340682913

Epoch: 6| Step: 4
Training loss: 3.3107211536907055
Validation loss: 2.498971154152112

Epoch: 6| Step: 5
Training loss: 2.7419481308842655
Validation loss: 2.4954699029532734

Epoch: 6| Step: 6
Training loss: 2.6192161782423953
Validation loss: 2.4922285395143513

Epoch: 6| Step: 7
Training loss: 2.528610925927846
Validation loss: 2.5039000843286954

Epoch: 6| Step: 8
Training loss: 2.7478556508849925
Validation loss: 2.492070890230295

Epoch: 6| Step: 9
Training loss: 2.1101102324703964
Validation loss: 2.4940094145414022

Epoch: 6| Step: 10
Training loss: 3.080691124795942
Validation loss: 2.4912975305218

Epoch: 6| Step: 11
Training loss: 2.220396049157065
Validation loss: 2.4977178149942794

Epoch: 6| Step: 12
Training loss: 2.769029579944157
Validation loss: 2.4841712212310196

Epoch: 6| Step: 13
Training loss: 3.0207307118490885
Validation loss: 2.4885173555581495

Epoch: 61| Step: 0
Training loss: 2.972493431655133
Validation loss: 2.4849555540118042

Epoch: 6| Step: 1
Training loss: 3.2049808243343025
Validation loss: 2.4881160588074227

Epoch: 6| Step: 2
Training loss: 2.8319376331509565
Validation loss: 2.4969816814769157

Epoch: 6| Step: 3
Training loss: 2.5543921996999
Validation loss: 2.498975235093224

Epoch: 6| Step: 4
Training loss: 2.917163497752505
Validation loss: 2.497107896163403

Epoch: 6| Step: 5
Training loss: 2.2721641094214173
Validation loss: 2.489676645529379

Epoch: 6| Step: 6
Training loss: 2.554999469525605
Validation loss: 2.490872837990746

Epoch: 6| Step: 7
Training loss: 2.5754295361225137
Validation loss: 2.49122182713825

Epoch: 6| Step: 8
Training loss: 2.383076437418571
Validation loss: 2.495731439221939

Epoch: 6| Step: 9
Training loss: 2.952277975366725
Validation loss: 2.489667232948275

Epoch: 6| Step: 10
Training loss: 2.7655561190718214
Validation loss: 2.479520062305728

Epoch: 6| Step: 11
Training loss: 2.893935663516512
Validation loss: 2.5009790246829198

Epoch: 6| Step: 12
Training loss: 2.5033652543912384
Validation loss: 2.4818698405478687

Epoch: 6| Step: 13
Training loss: 2.5927706788474025
Validation loss: 2.4929826606985075

Epoch: 62| Step: 0
Training loss: 2.684057470510809
Validation loss: 2.479852482433742

Epoch: 6| Step: 1
Training loss: 2.200213950764376
Validation loss: 2.5033334063949737

Epoch: 6| Step: 2
Training loss: 2.7715404631172698
Validation loss: 2.4902899229355726

Epoch: 6| Step: 3
Training loss: 2.5017912169814407
Validation loss: 2.494343186414756

Epoch: 6| Step: 4
Training loss: 2.7575798476859243
Validation loss: 2.491529261233111

Epoch: 6| Step: 5
Training loss: 2.861272130424805
Validation loss: 2.48962996841587

Epoch: 6| Step: 6
Training loss: 2.32961230805887
Validation loss: 2.4870503527136587

Epoch: 6| Step: 7
Training loss: 2.802588737505344
Validation loss: 2.4866262142399376

Epoch: 6| Step: 8
Training loss: 2.9019735724036493
Validation loss: 2.4894291572613336

Epoch: 6| Step: 9
Training loss: 2.730523323092194
Validation loss: 2.498221934116375

Epoch: 6| Step: 10
Training loss: 2.5622002961348334
Validation loss: 2.4909263802034847

Epoch: 6| Step: 11
Training loss: 2.915105801685759
Validation loss: 2.500290571779642

Epoch: 6| Step: 12
Training loss: 3.2855401466853142
Validation loss: 2.491405895161884

Epoch: 6| Step: 13
Training loss: 2.7817127828582766
Validation loss: 2.503185745560558

Epoch: 63| Step: 0
Training loss: 2.8007897625611573
Validation loss: 2.4948210160368056

Epoch: 6| Step: 1
Training loss: 2.7599718323251548
Validation loss: 2.501138711852235

Epoch: 6| Step: 2
Training loss: 3.1896826059418433
Validation loss: 2.4962171483334084

Epoch: 6| Step: 3
Training loss: 2.1275518466177004
Validation loss: 2.4960918335033693

Epoch: 6| Step: 4
Training loss: 2.328430770149586
Validation loss: 2.4994256610918555

Epoch: 6| Step: 5
Training loss: 3.03810681219725
Validation loss: 2.4917482661594192

Epoch: 6| Step: 6
Training loss: 3.0838062507932693
Validation loss: 2.488700858235375

Epoch: 6| Step: 7
Training loss: 2.6567822091485302
Validation loss: 2.48508171977665

Epoch: 6| Step: 8
Training loss: 2.202172905559744
Validation loss: 2.514790019274792

Epoch: 6| Step: 9
Training loss: 2.744674294053528
Validation loss: 2.5038861966667114

Epoch: 6| Step: 10
Training loss: 2.4411869042090446
Validation loss: 2.4926823423615705

Epoch: 6| Step: 11
Training loss: 2.6465629312602967
Validation loss: 2.4955142528956573

Epoch: 6| Step: 12
Training loss: 2.371743831098545
Validation loss: 2.4829294130862327

Epoch: 6| Step: 13
Training loss: 3.7005337046704296
Validation loss: 2.5035307624127356

Epoch: 64| Step: 0
Training loss: 2.861125472772431
Validation loss: 2.504223434981143

Epoch: 6| Step: 1
Training loss: 2.9521553829413008
Validation loss: 2.4903134355696457

Epoch: 6| Step: 2
Training loss: 2.9644200923223836
Validation loss: 2.495622057435082

Epoch: 6| Step: 3
Training loss: 2.5021180717180624
Validation loss: 2.50198070858052

Epoch: 6| Step: 4
Training loss: 2.746985517237993
Validation loss: 2.495077869776644

Epoch: 6| Step: 5
Training loss: 2.943196070038395
Validation loss: 2.491994903772761

Epoch: 6| Step: 6
Training loss: 2.0772955823968595
Validation loss: 2.485787351695485

Epoch: 6| Step: 7
Training loss: 2.668806399747782
Validation loss: 2.5008103410963374

Epoch: 6| Step: 8
Training loss: 2.596004012259041
Validation loss: 2.481134107780381

Epoch: 6| Step: 9
Training loss: 2.7957493738642603
Validation loss: 2.4883861865088663

Epoch: 6| Step: 10
Training loss: 2.0477220951862023
Validation loss: 2.493064286638533

Epoch: 6| Step: 11
Training loss: 3.4259655336337644
Validation loss: 2.4741778473974163

Epoch: 6| Step: 12
Training loss: 2.494507860407982
Validation loss: 2.494023797148033

Epoch: 6| Step: 13
Training loss: 2.6142578125
Validation loss: 2.4823694454417837

Epoch: 65| Step: 0
Training loss: 2.370406275826063
Validation loss: 2.4798344091769455

Epoch: 6| Step: 1
Training loss: 2.7658983515765114
Validation loss: 2.4952141740140803

Epoch: 6| Step: 2
Training loss: 2.3968721432028484
Validation loss: 2.497753255587598

Epoch: 6| Step: 3
Training loss: 2.202379682287687
Validation loss: 2.4905387101467262

Epoch: 6| Step: 4
Training loss: 2.9728304477335534
Validation loss: 2.4952006150748347

Epoch: 6| Step: 5
Training loss: 2.9828608801201852
Validation loss: 2.4920178880071404

Epoch: 6| Step: 6
Training loss: 2.9441100076564086
Validation loss: 2.496296414808168

Epoch: 6| Step: 7
Training loss: 2.82216036379181
Validation loss: 2.5048821840971303

Epoch: 6| Step: 8
Training loss: 3.0019404175885893
Validation loss: 2.489271758086685

Epoch: 6| Step: 9
Training loss: 2.7110739901699072
Validation loss: 2.4858933979412283

Epoch: 6| Step: 10
Training loss: 1.8130913789111294
Validation loss: 2.503482589444964

Epoch: 6| Step: 11
Training loss: 2.891342321522488
Validation loss: 2.496210190842671

Epoch: 6| Step: 12
Training loss: 2.7351373100333243
Validation loss: 2.496754894607027

Epoch: 6| Step: 13
Training loss: 3.239897063704098
Validation loss: 2.5045743664600266

Epoch: 66| Step: 0
Training loss: 2.407102755753857
Validation loss: 2.5046351829503317

Epoch: 6| Step: 1
Training loss: 2.7552326011430264
Validation loss: 2.5000971047195826

Epoch: 6| Step: 2
Training loss: 2.8045079590862505
Validation loss: 2.491549917170501

Epoch: 6| Step: 3
Training loss: 2.7088153899168526
Validation loss: 2.4827487467946074

Epoch: 6| Step: 4
Training loss: 2.4565459289108333
Validation loss: 2.4893950430053984

Epoch: 6| Step: 5
Training loss: 3.1815667375072305
Validation loss: 2.4987899938667075

Epoch: 6| Step: 6
Training loss: 2.8210305438465544
Validation loss: 2.498470942183853

Epoch: 6| Step: 7
Training loss: 2.699699568811467
Validation loss: 2.4921668431750406

Epoch: 6| Step: 8
Training loss: 3.0367526418307462
Validation loss: 2.48323031576077

Epoch: 6| Step: 9
Training loss: 2.5543510378765344
Validation loss: 2.5071604525072684

Epoch: 6| Step: 10
Training loss: 2.278821514804942
Validation loss: 2.5032261817950032

Epoch: 6| Step: 11
Training loss: 2.4625078307671138
Validation loss: 2.502030439716753

Epoch: 6| Step: 12
Training loss: 2.5088082591592338
Validation loss: 2.4917380640403173

Epoch: 6| Step: 13
Training loss: 3.303439290117748
Validation loss: 2.490694775584842

Epoch: 67| Step: 0
Training loss: 2.105693628195411
Validation loss: 2.49989947045125

Epoch: 6| Step: 1
Training loss: 2.2337058605920044
Validation loss: 2.4891862862003746

Epoch: 6| Step: 2
Training loss: 3.099341224075593
Validation loss: 2.5110946510428978

Epoch: 6| Step: 3
Training loss: 2.5031750544235574
Validation loss: 2.5103015075857056

Epoch: 6| Step: 4
Training loss: 3.009694489090807
Validation loss: 2.4978393221135553

Epoch: 6| Step: 5
Training loss: 2.584740122380612
Validation loss: 2.491943176125046

Epoch: 6| Step: 6
Training loss: 3.153367643216714
Validation loss: 2.5042784555971305

Epoch: 6| Step: 7
Training loss: 3.029034778464577
Validation loss: 2.4875812629992518

Epoch: 6| Step: 8
Training loss: 2.1106145536905805
Validation loss: 2.502138911755134

Epoch: 6| Step: 9
Training loss: 2.557420860699356
Validation loss: 2.4866956790950523

Epoch: 6| Step: 10
Training loss: 2.832010371690282
Validation loss: 2.49963030286336

Epoch: 6| Step: 11
Training loss: 3.0996601410658404
Validation loss: 2.4867491885666904

Epoch: 6| Step: 12
Training loss: 2.475682725086506
Validation loss: 2.4995689922956066

Epoch: 6| Step: 13
Training loss: 2.6651692259059394
Validation loss: 2.4984364911817143

Epoch: 68| Step: 0
Training loss: 2.715139161647936
Validation loss: 2.503579108531931

Epoch: 6| Step: 1
Training loss: 2.5825876164598744
Validation loss: 2.4887890239603427

Epoch: 6| Step: 2
Training loss: 2.442250049495394
Validation loss: 2.494769781150563

Epoch: 6| Step: 3
Training loss: 1.5258407807737
Validation loss: 2.506018044297758

Epoch: 6| Step: 4
Training loss: 3.433148074167165
Validation loss: 2.5102108385210484

Epoch: 6| Step: 5
Training loss: 2.506867893373454
Validation loss: 2.505544717707034

Epoch: 6| Step: 6
Training loss: 2.4644645483865064
Validation loss: 2.517234273753113

Epoch: 6| Step: 7
Training loss: 2.495306950648377
Validation loss: 2.5118743568108934

Epoch: 6| Step: 8
Training loss: 2.1172190308422385
Validation loss: 2.5033827404576017

Epoch: 6| Step: 9
Training loss: 2.4822465908254956
Validation loss: 2.5135658808419254

Epoch: 6| Step: 10
Training loss: 2.8737242812258166
Validation loss: 2.5015057510453147

Epoch: 6| Step: 11
Training loss: 3.0653265540451917
Validation loss: 2.4986563035084206

Epoch: 6| Step: 12
Training loss: 3.6836687001504713
Validation loss: 2.5049059558333306

Epoch: 6| Step: 13
Training loss: 2.8470376262422765
Validation loss: 2.5068938705149657

Epoch: 69| Step: 0
Training loss: 2.5483627186742774
Validation loss: 2.507189513594346

Epoch: 6| Step: 1
Training loss: 3.3232469225190333
Validation loss: 2.487080060066295

Epoch: 6| Step: 2
Training loss: 2.5352288516424304
Validation loss: 2.5134710273447998

Epoch: 6| Step: 3
Training loss: 2.7658222365226166
Validation loss: 2.473337557270828

Epoch: 6| Step: 4
Training loss: 3.39672682227517
Validation loss: 2.4916878666601594

Epoch: 6| Step: 5
Training loss: 2.2840797953721315
Validation loss: 2.5062213662746124

Epoch: 6| Step: 6
Training loss: 2.8231369627031317
Validation loss: 2.4867209185049455

Epoch: 6| Step: 7
Training loss: 2.9220182822280227
Validation loss: 2.50925411762306

Epoch: 6| Step: 8
Training loss: 2.423200773560283
Validation loss: 2.5018926798276317

Epoch: 6| Step: 9
Training loss: 2.7783956561071355
Validation loss: 2.4973668454522207

Epoch: 6| Step: 10
Training loss: 2.881391635152527
Validation loss: 2.498668519126372

Epoch: 6| Step: 11
Training loss: 2.275110946297487
Validation loss: 2.4969351409220204

Epoch: 6| Step: 12
Training loss: 1.4797150396827525
Validation loss: 2.50393460042539

Epoch: 6| Step: 13
Training loss: 3.0958374379380245
Validation loss: 2.4916241053003585

Epoch: 70| Step: 0
Training loss: 3.032059708825151
Validation loss: 2.490861441480549

Epoch: 6| Step: 1
Training loss: 2.689205249674693
Validation loss: 2.502420458602169

Epoch: 6| Step: 2
Training loss: 2.0807226480915832
Validation loss: 2.4985147268494265

Epoch: 6| Step: 3
Training loss: 2.709039996950603
Validation loss: 2.5017314544774294

Epoch: 6| Step: 4
Training loss: 3.2742222685124855
Validation loss: 2.4870220737055684

Epoch: 6| Step: 5
Training loss: 3.25623134966468
Validation loss: 2.4903439831322753

Epoch: 6| Step: 6
Training loss: 2.5341881547907676
Validation loss: 2.503479760049182

Epoch: 6| Step: 7
Training loss: 3.1113957112186084
Validation loss: 2.492422521691619

Epoch: 6| Step: 8
Training loss: 2.5435059151480397
Validation loss: 2.490903888147581

Epoch: 6| Step: 9
Training loss: 3.0225112639691374
Validation loss: 2.4871270272646866

Epoch: 6| Step: 10
Training loss: 2.3637424491870656
Validation loss: 2.4915977570015237

Epoch: 6| Step: 11
Training loss: 1.804818549083865
Validation loss: 2.4897158894617313

Epoch: 6| Step: 12
Training loss: 2.1748610353471527
Validation loss: 2.4881954123253727

Epoch: 6| Step: 13
Training loss: 2.931876786165785
Validation loss: 2.495187606766606

Epoch: 71| Step: 0
Training loss: 3.0435284355719046
Validation loss: 2.5089251312107654

Epoch: 6| Step: 1
Training loss: 2.5305353733583473
Validation loss: 2.4976546525227588

Epoch: 6| Step: 2
Training loss: 2.7445425153327903
Validation loss: 2.485757423658642

Epoch: 6| Step: 3
Training loss: 1.944125077344684
Validation loss: 2.50565941229161

Epoch: 6| Step: 4
Training loss: 2.1632470753327153
Validation loss: 2.5035572401003168

Epoch: 6| Step: 5
Training loss: 2.5162392571225163
Validation loss: 2.4994786898258305

Epoch: 6| Step: 6
Training loss: 3.633360331257131
Validation loss: 2.499446605632537

Epoch: 6| Step: 7
Training loss: 2.347156947605834
Validation loss: 2.496589290627379

Epoch: 6| Step: 8
Training loss: 2.493719604612889
Validation loss: 2.4866333856670075

Epoch: 6| Step: 9
Training loss: 2.5121906602509587
Validation loss: 2.4790218066563914

Epoch: 6| Step: 10
Training loss: 3.304621991168824
Validation loss: 2.51202762407653

Epoch: 6| Step: 11
Training loss: 2.637609441574734
Validation loss: 2.4986771575411333

Epoch: 6| Step: 12
Training loss: 2.9783790632116065
Validation loss: 2.501626422926182

Epoch: 6| Step: 13
Training loss: 2.3992306270820882
Validation loss: 2.5014515979667538

Epoch: 72| Step: 0
Training loss: 3.2353596685776056
Validation loss: 2.49288595604189

Epoch: 6| Step: 1
Training loss: 2.1050045372195965
Validation loss: 2.505937420868485

Epoch: 6| Step: 2
Training loss: 3.0988208558605495
Validation loss: 2.506074707277411

Epoch: 6| Step: 3
Training loss: 2.4130257661141763
Validation loss: 2.498307867515202

Epoch: 6| Step: 4
Training loss: 2.3023982688473152
Validation loss: 2.506177730570385

Epoch: 6| Step: 5
Training loss: 2.9107608039207897
Validation loss: 2.495574656350081

Epoch: 6| Step: 6
Training loss: 2.6262320397410623
Validation loss: 2.4824920110215936

Epoch: 6| Step: 7
Training loss: 2.846562263069139
Validation loss: 2.5008579976306904

Epoch: 6| Step: 8
Training loss: 2.309587242274102
Validation loss: 2.4917500275537288

Epoch: 6| Step: 9
Training loss: 2.623608083898807
Validation loss: 2.497504945825431

Epoch: 6| Step: 10
Training loss: 2.7426923412103545
Validation loss: 2.5099236755670136

Epoch: 6| Step: 11
Training loss: 3.2549581121277957
Validation loss: 2.48869531210615

Epoch: 6| Step: 12
Training loss: 2.4472162313264088
Validation loss: 2.4932998971055462

Epoch: 6| Step: 13
Training loss: 2.3766428636033945
Validation loss: 2.4931521181111793

Epoch: 73| Step: 0
Training loss: 2.432105526278535
Validation loss: 2.5013968113627074

Epoch: 6| Step: 1
Training loss: 2.7175256888290495
Validation loss: 2.5019539201327294

Epoch: 6| Step: 2
Training loss: 2.928267885221089
Validation loss: 2.5071129515624713

Epoch: 6| Step: 3
Training loss: 2.8157464681794746
Validation loss: 2.4960234364110545

Epoch: 6| Step: 4
Training loss: 2.842358091329828
Validation loss: 2.5025157227564745

Epoch: 6| Step: 5
Training loss: 2.5012541486180497
Validation loss: 2.503793553628998

Epoch: 6| Step: 6
Training loss: 2.8039225010521847
Validation loss: 2.499048831434652

Epoch: 6| Step: 7
Training loss: 2.9580479515578886
Validation loss: 2.4943042167340064

Epoch: 6| Step: 8
Training loss: 2.539332073279793
Validation loss: 2.4917261112725093

Epoch: 6| Step: 9
Training loss: 2.1205395278322734
Validation loss: 2.505805939063783

Epoch: 6| Step: 10
Training loss: 3.219045384751031
Validation loss: 2.5101958582682076

Epoch: 6| Step: 11
Training loss: 2.3785196625989604
Validation loss: 2.4876002079989776

Epoch: 6| Step: 12
Training loss: 2.604597915545941
Validation loss: 2.499994125154217

Epoch: 6| Step: 13
Training loss: 2.147885005309343
Validation loss: 2.507920413244261

Epoch: 74| Step: 0
Training loss: 2.439895821833163
Validation loss: 2.5088903322644436

Epoch: 6| Step: 1
Training loss: 2.8180676769958715
Validation loss: 2.5128603998424777

Epoch: 6| Step: 2
Training loss: 2.6783120765467605
Validation loss: 2.487466755681598

Epoch: 6| Step: 3
Training loss: 2.7927578933190396
Validation loss: 2.4987864963911037

Epoch: 6| Step: 4
Training loss: 2.800365550157346
Validation loss: 2.4980596549584106

Epoch: 6| Step: 5
Training loss: 2.846008745170663
Validation loss: 2.497148347659437

Epoch: 6| Step: 6
Training loss: 2.6060638434435015
Validation loss: 2.5003233818382777

Epoch: 6| Step: 7
Training loss: 2.7690148564880723
Validation loss: 2.5055677802345455

Epoch: 6| Step: 8
Training loss: 2.4790877214786353
Validation loss: 2.505890284474648

Epoch: 6| Step: 9
Training loss: 3.068764643430248
Validation loss: 2.4974691039414982

Epoch: 6| Step: 10
Training loss: 2.474734621559159
Validation loss: 2.504334773032509

Epoch: 6| Step: 11
Training loss: 2.91009759011769
Validation loss: 2.506805944750488

Epoch: 6| Step: 12
Training loss: 2.281137960112541
Validation loss: 2.479646571316203

Epoch: 6| Step: 13
Training loss: 2.5875830816669074
Validation loss: 2.502250281085672

Epoch: 75| Step: 0
Training loss: 2.5942428304502037
Validation loss: 2.4934223685304184

Epoch: 6| Step: 1
Training loss: 2.698658511018806
Validation loss: 2.489627424987455

Epoch: 6| Step: 2
Training loss: 2.749801281771721
Validation loss: 2.5026914854430773

Epoch: 6| Step: 3
Training loss: 3.0552008702347067
Validation loss: 2.493341409787389

Epoch: 6| Step: 4
Training loss: 1.9356801500060492
Validation loss: 2.49409727954308

Epoch: 6| Step: 5
Training loss: 2.5534037593096475
Validation loss: 2.4975130775923313

Epoch: 6| Step: 6
Training loss: 2.335218644289691
Validation loss: 2.514040498458734

Epoch: 6| Step: 7
Training loss: 2.5027875618055977
Validation loss: 2.500673177797307

Epoch: 6| Step: 8
Training loss: 3.1617773021859343
Validation loss: 2.5058967772266714

Epoch: 6| Step: 9
Training loss: 2.5139541289667218
Validation loss: 2.4920350483744103

Epoch: 6| Step: 10
Training loss: 2.098698476098723
Validation loss: 2.489792586951422

Epoch: 6| Step: 11
Training loss: 3.0835085810440934
Validation loss: 2.4908728451952427

Epoch: 6| Step: 12
Training loss: 2.4808744324071177
Validation loss: 2.490778126909387

Epoch: 6| Step: 13
Training loss: 3.9659783003805447
Validation loss: 2.513970245269827

Epoch: 76| Step: 0
Training loss: 3.295641048977582
Validation loss: 2.517907894970471

Epoch: 6| Step: 1
Training loss: 2.802123871879931
Validation loss: 2.494875593561544

Epoch: 6| Step: 2
Training loss: 1.9018204300166104
Validation loss: 2.4970816242073246

Epoch: 6| Step: 3
Training loss: 2.6615938175800364
Validation loss: 2.501613004295725

Epoch: 6| Step: 4
Training loss: 2.0086056816135427
Validation loss: 2.498931593914481

Epoch: 6| Step: 5
Training loss: 2.8525850317782626
Validation loss: 2.5120431577645714

Epoch: 6| Step: 6
Training loss: 2.3173641906581657
Validation loss: 2.4983288522110834

Epoch: 6| Step: 7
Training loss: 2.930396073166541
Validation loss: 2.5025798873301546

Epoch: 6| Step: 8
Training loss: 3.4170034909340763
Validation loss: 2.4981481687177483

Epoch: 6| Step: 9
Training loss: 2.5168126306036207
Validation loss: 2.499633412504639

Epoch: 6| Step: 10
Training loss: 2.4101764300968376
Validation loss: 2.5023476826674265

Epoch: 6| Step: 11
Training loss: 2.3856587405138616
Validation loss: 2.5045642513888766

Epoch: 6| Step: 12
Training loss: 2.4131379069803427
Validation loss: 2.5013500096140646

Epoch: 6| Step: 13
Training loss: 3.5591195112775633
Validation loss: 2.504444122327292

Epoch: 77| Step: 0
Training loss: 3.3595772615800756
Validation loss: 2.5066176668044613

Epoch: 6| Step: 1
Training loss: 2.3702807470217846
Validation loss: 2.5007985675197797

Epoch: 6| Step: 2
Training loss: 2.993101294203195
Validation loss: 2.5051598153515577

Epoch: 6| Step: 3
Training loss: 2.137607647600028
Validation loss: 2.4856753850181943

Epoch: 6| Step: 4
Training loss: 2.9081358994706625
Validation loss: 2.4932298224513176

Epoch: 6| Step: 5
Training loss: 2.556924942562013
Validation loss: 2.5029721481825518

Epoch: 6| Step: 6
Training loss: 2.8133240234377643
Validation loss: 2.4870696305788194

Epoch: 6| Step: 7
Training loss: 2.7688674454073845
Validation loss: 2.485405351558902

Epoch: 6| Step: 8
Training loss: 2.3770183218898624
Validation loss: 2.501994824042582

Epoch: 6| Step: 9
Training loss: 2.955480534295334
Validation loss: 2.5035938437084857

Epoch: 6| Step: 10
Training loss: 2.6747930999315455
Validation loss: 2.49992861184361

Epoch: 6| Step: 11
Training loss: 2.136650237775576
Validation loss: 2.5121981709734413

Epoch: 6| Step: 12
Training loss: 2.5768419251874115
Validation loss: 2.4872980096490487

Epoch: 6| Step: 13
Training loss: 2.629465936312827
Validation loss: 2.5025780623624563

Epoch: 78| Step: 0
Training loss: 3.0399736543818827
Validation loss: 2.5023465239642415

Epoch: 6| Step: 1
Training loss: 2.913560102993395
Validation loss: 2.4949188104114253

Epoch: 6| Step: 2
Training loss: 2.4659578976157968
Validation loss: 2.504049880658133

Epoch: 6| Step: 3
Training loss: 2.671240748031081
Validation loss: 2.501440412606831

Epoch: 6| Step: 4
Training loss: 2.09604871589889
Validation loss: 2.485883083103571

Epoch: 6| Step: 5
Training loss: 2.671325805616645
Validation loss: 2.508607315402516

Epoch: 6| Step: 6
Training loss: 2.845685195604551
Validation loss: 2.5026370507092186

Epoch: 6| Step: 7
Training loss: 3.2036568549015234
Validation loss: 2.4898308828132416

Epoch: 6| Step: 8
Training loss: 2.099724856017517
Validation loss: 2.4946916479527386

Epoch: 6| Step: 9
Training loss: 2.707115887616486
Validation loss: 2.5068376657946665

Epoch: 6| Step: 10
Training loss: 2.953425962259894
Validation loss: 2.484705012470073

Epoch: 6| Step: 11
Training loss: 2.6594905160274753
Validation loss: 2.5032570428779004

Epoch: 6| Step: 12
Training loss: 2.3881740597176027
Validation loss: 2.489480235345104

Epoch: 6| Step: 13
Training loss: 2.68160826239121
Validation loss: 2.4929817367323786

Epoch: 79| Step: 0
Training loss: 3.313297967344645
Validation loss: 2.4981783454551225

Epoch: 6| Step: 1
Training loss: 2.089433576314481
Validation loss: 2.4973856269110923

Epoch: 6| Step: 2
Training loss: 3.0298847388071617
Validation loss: 2.495391492718105

Epoch: 6| Step: 3
Training loss: 3.0170879076932815
Validation loss: 2.502460733046434

Epoch: 6| Step: 4
Training loss: 2.477729787014907
Validation loss: 2.5085266055446493

Epoch: 6| Step: 5
Training loss: 2.02521710585969
Validation loss: 2.5078413194358693

Epoch: 6| Step: 6
Training loss: 2.9348447446034958
Validation loss: 2.5146669818223466

Epoch: 6| Step: 7
Training loss: 2.3122300686393262
Validation loss: 2.5163378043537743

Epoch: 6| Step: 8
Training loss: 3.064958325300303
Validation loss: 2.5121018820139396

Epoch: 6| Step: 9
Training loss: 2.465691518913684
Validation loss: 2.507157990259718

Epoch: 6| Step: 10
Training loss: 2.902757083833255
Validation loss: 2.500416954710049

Epoch: 6| Step: 11
Training loss: 2.751180135488939
Validation loss: 2.4961640842030124

Epoch: 6| Step: 12
Training loss: 2.0432476487897073
Validation loss: 2.5142024598979207

Epoch: 6| Step: 13
Training loss: 2.734473264835898
Validation loss: 2.5117925368569214

Epoch: 80| Step: 0
Training loss: 2.647436172104981
Validation loss: 2.4989918798883397

Epoch: 6| Step: 1
Training loss: 1.890748012103365
Validation loss: 2.502700657486983

Epoch: 6| Step: 2
Training loss: 2.882580590159562
Validation loss: 2.5099010840996656

Epoch: 6| Step: 3
Training loss: 2.6801835649168493
Validation loss: 2.521413143689581

Epoch: 6| Step: 4
Training loss: 2.978213675780903
Validation loss: 2.5103602950440065

Epoch: 6| Step: 5
Training loss: 2.7062432269216448
Validation loss: 2.515776669197488

Epoch: 6| Step: 6
Training loss: 3.605106091677605
Validation loss: 2.5125533841344647

Epoch: 6| Step: 7
Training loss: 2.5685372294645656
Validation loss: 2.505747495944474

Epoch: 6| Step: 8
Training loss: 2.822327124113683
Validation loss: 2.501972745031217

Epoch: 6| Step: 9
Training loss: 2.3734111490601264
Validation loss: 2.493829603371879

Epoch: 6| Step: 10
Training loss: 1.8268175585000455
Validation loss: 2.5022913614905935

Epoch: 6| Step: 11
Training loss: 2.9695423875703724
Validation loss: 2.484468555965528

Epoch: 6| Step: 12
Training loss: 2.3930571905587956
Validation loss: 2.497413753667769

Epoch: 6| Step: 13
Training loss: 2.623494579428091
Validation loss: 2.498288623008839

Epoch: 81| Step: 0
Training loss: 2.620990961506791
Validation loss: 2.4975607529048482

Epoch: 6| Step: 1
Training loss: 2.2163171459166624
Validation loss: 2.497707203605414

Epoch: 6| Step: 2
Training loss: 2.259224314960792
Validation loss: 2.4936233402810237

Epoch: 6| Step: 3
Training loss: 2.2627715985737518
Validation loss: 2.4971679438442176

Epoch: 6| Step: 4
Training loss: 2.736048420695106
Validation loss: 2.5064298314070514

Epoch: 6| Step: 5
Training loss: 2.7141461910154385
Validation loss: 2.495166176455771

Epoch: 6| Step: 6
Training loss: 2.5871206844035988
Validation loss: 2.500612794979523

Epoch: 6| Step: 7
Training loss: 2.2533402550419845
Validation loss: 2.4946140487516493

Epoch: 6| Step: 8
Training loss: 2.6359464291351804
Validation loss: 2.49273070759308

Epoch: 6| Step: 9
Training loss: 3.3192587941995564
Validation loss: 2.5017433117914676

Epoch: 6| Step: 10
Training loss: 2.6570439666739847
Validation loss: 2.5056840995175995

Epoch: 6| Step: 11
Training loss: 2.800913617399253
Validation loss: 2.490469450273639

Epoch: 6| Step: 12
Training loss: 2.594273893462631
Validation loss: 2.496641659794241

Epoch: 6| Step: 13
Training loss: 3.968779916725641
Validation loss: 2.4955823362437086

Epoch: 82| Step: 0
Training loss: 2.863768823595927
Validation loss: 2.505817220544607

Epoch: 6| Step: 1
Training loss: 2.7372736798101047
Validation loss: 2.4930010633381996

Epoch: 6| Step: 2
Training loss: 2.9407815662503647
Validation loss: 2.5082906060842842

Epoch: 6| Step: 3
Training loss: 2.2746000168856955
Validation loss: 2.4990466504839235

Epoch: 6| Step: 4
Training loss: 2.6594061557186444
Validation loss: 2.4983199473333033

Epoch: 6| Step: 5
Training loss: 2.578233196415735
Validation loss: 2.4986986085262486

Epoch: 6| Step: 6
Training loss: 2.9865047185564535
Validation loss: 2.5014330171645573

Epoch: 6| Step: 7
Training loss: 3.2285933118867063
Validation loss: 2.5013531806613263

Epoch: 6| Step: 8
Training loss: 2.4665773706339493
Validation loss: 2.5147565778240435

Epoch: 6| Step: 9
Training loss: 2.5232585453790923
Validation loss: 2.493147843577275

Epoch: 6| Step: 10
Training loss: 2.773667360908169
Validation loss: 2.4986218322330576

Epoch: 6| Step: 11
Training loss: 2.194780930207843
Validation loss: 2.504966890154216

Epoch: 6| Step: 12
Training loss: 2.1343369398172487
Validation loss: 2.5027537756006613

Epoch: 6| Step: 13
Training loss: 2.8131708828486013
Validation loss: 2.4962436121936427

Epoch: 83| Step: 0
Training loss: 2.7753078118142827
Validation loss: 2.5086559796084327

Epoch: 6| Step: 1
Training loss: 3.3969305095330813
Validation loss: 2.5059458270639445

Epoch: 6| Step: 2
Training loss: 2.0439016863326755
Validation loss: 2.4996400881693708

Epoch: 6| Step: 3
Training loss: 2.165340335516734
Validation loss: 2.503935603793177

Epoch: 6| Step: 4
Training loss: 2.2073395370277935
Validation loss: 2.500575862723384

Epoch: 6| Step: 5
Training loss: 3.0316076952494213
Validation loss: 2.5075519661427115

Epoch: 6| Step: 6
Training loss: 2.4891470895343653
Validation loss: 2.493783568369827

Epoch: 6| Step: 7
Training loss: 2.731817477215636
Validation loss: 2.501141903154656

Epoch: 6| Step: 8
Training loss: 2.866597044638993
Validation loss: 2.50630092291399

Epoch: 6| Step: 9
Training loss: 2.4418344351077086
Validation loss: 2.484008287321102

Epoch: 6| Step: 10
Training loss: 3.038341917303797
Validation loss: 2.5132716886009225

Epoch: 6| Step: 11
Training loss: 2.1745202949578544
Validation loss: 2.4915239117547086

Epoch: 6| Step: 12
Training loss: 2.617296996601725
Validation loss: 2.4981845067764

Epoch: 6| Step: 13
Training loss: 3.275522082698513
Validation loss: 2.5013338263464577

Epoch: 84| Step: 0
Training loss: 3.112238959584038
Validation loss: 2.504967984193124

Epoch: 6| Step: 1
Training loss: 2.641564828331694
Validation loss: 2.510621209369223

Epoch: 6| Step: 2
Training loss: 2.2298902840416894
Validation loss: 2.5057939546727535

Epoch: 6| Step: 3
Training loss: 2.382017109179288
Validation loss: 2.5003422133737345

Epoch: 6| Step: 4
Training loss: 2.404019994465325
Validation loss: 2.514670884370401

Epoch: 6| Step: 5
Training loss: 2.722330738897649
Validation loss: 2.489898613965463

Epoch: 6| Step: 6
Training loss: 2.3187878669875395
Validation loss: 2.509444829396531

Epoch: 6| Step: 7
Training loss: 2.9091916527426815
Validation loss: 2.4875958311737456

Epoch: 6| Step: 8
Training loss: 2.5896302562420352
Validation loss: 2.499526734830021

Epoch: 6| Step: 9
Training loss: 2.8121044304612557
Validation loss: 2.5080908208564363

Epoch: 6| Step: 10
Training loss: 2.7664607450153595
Validation loss: 2.5013096496409855

Epoch: 6| Step: 11
Training loss: 2.3904563495262736
Validation loss: 2.5041793201574496

Epoch: 6| Step: 12
Training loss: 2.689453479597834
Validation loss: 2.502823583600983

Epoch: 6| Step: 13
Training loss: 3.4637856916160166
Validation loss: 2.5107016364442605

Epoch: 85| Step: 0
Training loss: 1.7851477691649273
Validation loss: 2.4895940924485913

Epoch: 6| Step: 1
Training loss: 2.3465475044375887
Validation loss: 2.5079136497317314

Epoch: 6| Step: 2
Training loss: 2.4704995052581893
Validation loss: 2.5215777243278303

Epoch: 6| Step: 3
Training loss: 2.583123649783258
Validation loss: 2.500331378837108

Epoch: 6| Step: 4
Training loss: 3.2001257275677797
Validation loss: 2.517801785896629

Epoch: 6| Step: 5
Training loss: 2.5669315445038072
Validation loss: 2.4958531205957324

Epoch: 6| Step: 6
Training loss: 2.858749404593582
Validation loss: 2.508981148162496

Epoch: 6| Step: 7
Training loss: 2.4827560812107707
Validation loss: 2.5164754453314444

Epoch: 6| Step: 8
Training loss: 2.510560333657474
Validation loss: 2.4989829507004795

Epoch: 6| Step: 9
Training loss: 2.337646267644409
Validation loss: 2.5063401060038055

Epoch: 6| Step: 10
Training loss: 2.4665395764095552
Validation loss: 2.492009204390377

Epoch: 6| Step: 11
Training loss: 2.7818822249295363
Validation loss: 2.505947436278869

Epoch: 6| Step: 12
Training loss: 3.3639401666534168
Validation loss: 2.506305765214822

Epoch: 6| Step: 13
Training loss: 3.424836292670322
Validation loss: 2.4912370511473134

Epoch: 86| Step: 0
Training loss: 2.861126639397054
Validation loss: 2.4813966518838457

Epoch: 6| Step: 1
Training loss: 2.4587584521289454
Validation loss: 2.4954233249571254

Epoch: 6| Step: 2
Training loss: 1.8853509023869337
Validation loss: 2.4893060547728685

Epoch: 6| Step: 3
Training loss: 2.993104002507133
Validation loss: 2.5038086489789717

Epoch: 6| Step: 4
Training loss: 2.1773001336258644
Validation loss: 2.502231964398737

Epoch: 6| Step: 5
Training loss: 2.656625339692371
Validation loss: 2.490404665370568

Epoch: 6| Step: 6
Training loss: 2.766924019606147
Validation loss: 2.486391734502467

Epoch: 6| Step: 7
Training loss: 3.4305716311292196
Validation loss: 2.507804612216423

Epoch: 6| Step: 8
Training loss: 2.5728110370240302
Validation loss: 2.514005484791335

Epoch: 6| Step: 9
Training loss: 2.8738120568715373
Validation loss: 2.495284410749664

Epoch: 6| Step: 10
Training loss: 3.1217229827129667
Validation loss: 2.5003023446722845

Epoch: 6| Step: 11
Training loss: 2.2811335703780613
Validation loss: 2.4847059833641443

Epoch: 6| Step: 12
Training loss: 2.628325036744751
Validation loss: 2.498492514477182

Epoch: 6| Step: 13
Training loss: 2.094968981820504
Validation loss: 2.4907203419222155

Epoch: 87| Step: 0
Training loss: 2.844416781214797
Validation loss: 2.4930530903841617

Epoch: 6| Step: 1
Training loss: 2.6279432054708525
Validation loss: 2.502666059837159

Epoch: 6| Step: 2
Training loss: 3.2797729073971995
Validation loss: 2.5025917954293995

Epoch: 6| Step: 3
Training loss: 2.3889108134404586
Validation loss: 2.509502756327415

Epoch: 6| Step: 4
Training loss: 2.3232470107860292
Validation loss: 2.4952729789086394

Epoch: 6| Step: 5
Training loss: 2.1683628583222787
Validation loss: 2.5100295702320805

Epoch: 6| Step: 6
Training loss: 2.8704874864792878
Validation loss: 2.4953286571417395

Epoch: 6| Step: 7
Training loss: 2.5248739683216277
Validation loss: 2.4942019775259694

Epoch: 6| Step: 8
Training loss: 3.404925727650374
Validation loss: 2.5057858968409943

Epoch: 6| Step: 9
Training loss: 2.156550510861268
Validation loss: 2.490366958926699

Epoch: 6| Step: 10
Training loss: 2.376242764224655
Validation loss: 2.4934156145290287

Epoch: 6| Step: 11
Training loss: 2.609404877817111
Validation loss: 2.48925083504288

Epoch: 6| Step: 12
Training loss: 3.120356963351365
Validation loss: 2.506801113642577

Epoch: 6| Step: 13
Training loss: 1.793802304452332
Validation loss: 2.4940475510871045

Epoch: 88| Step: 0
Training loss: 3.2430314401895806
Validation loss: 2.5005401002275205

Epoch: 6| Step: 1
Training loss: 2.3251329691610727
Validation loss: 2.502913519567543

Epoch: 6| Step: 2
Training loss: 2.469611295315757
Validation loss: 2.509862746165505

Epoch: 6| Step: 3
Training loss: 2.2409315678958577
Validation loss: 2.499980823894502

Epoch: 6| Step: 4
Training loss: 2.1876918163668386
Validation loss: 2.5074021040002252

Epoch: 6| Step: 5
Training loss: 2.4344190052447674
Validation loss: 2.5134500742132464

Epoch: 6| Step: 6
Training loss: 3.169268810529646
Validation loss: 2.495852084704599

Epoch: 6| Step: 7
Training loss: 2.537192445353868
Validation loss: 2.5021489782300446

Epoch: 6| Step: 8
Training loss: 3.00078063980728
Validation loss: 2.4976950089459673

Epoch: 6| Step: 9
Training loss: 3.360770144301688
Validation loss: 2.499202016405856

Epoch: 6| Step: 10
Training loss: 2.606387318165687
Validation loss: 2.5011143528608306

Epoch: 6| Step: 11
Training loss: 2.2215410327612
Validation loss: 2.491804903828235

Epoch: 6| Step: 12
Training loss: 2.5204655297511644
Validation loss: 2.491898848529855

Epoch: 6| Step: 13
Training loss: 2.5015498125849405
Validation loss: 2.5032907198795598

Epoch: 89| Step: 0
Training loss: 2.829927660283733
Validation loss: 2.5013579592600212

Epoch: 6| Step: 1
Training loss: 2.5844991780975506
Validation loss: 2.5075542705588973

Epoch: 6| Step: 2
Training loss: 3.315902833506634
Validation loss: 2.502638878194839

Epoch: 6| Step: 3
Training loss: 2.7272390493567715
Validation loss: 2.4918802607970663

Epoch: 6| Step: 4
Training loss: 2.966766658626573
Validation loss: 2.514237780285775

Epoch: 6| Step: 5
Training loss: 2.518337232972548
Validation loss: 2.5116064878765725

Epoch: 6| Step: 6
Training loss: 2.748008093326428
Validation loss: 2.4962582489458573

Epoch: 6| Step: 7
Training loss: 2.457387925597039
Validation loss: 2.5207728428923417

Epoch: 6| Step: 8
Training loss: 2.6325552160951524
Validation loss: 2.5087239597367295

Epoch: 6| Step: 9
Training loss: 1.664118519587805
Validation loss: 2.495715276018082

Epoch: 6| Step: 10
Training loss: 2.5699182457295966
Validation loss: 2.5079798539879725

Epoch: 6| Step: 11
Training loss: 2.8648941888626367
Validation loss: 2.521743877093588

Epoch: 6| Step: 12
Training loss: 2.4856690689258785
Validation loss: 2.509249269773462

Epoch: 6| Step: 13
Training loss: 2.703543129042339
Validation loss: 2.5119235282325962

Epoch: 90| Step: 0
Training loss: 2.45804680485312
Validation loss: 2.509783135933157

Epoch: 6| Step: 1
Training loss: 2.7277696445790136
Validation loss: 2.5110950298062407

Epoch: 6| Step: 2
Training loss: 2.277750754260693
Validation loss: 2.5089242085176604

Epoch: 6| Step: 3
Training loss: 2.1584176487698103
Validation loss: 2.4965216578169254

Epoch: 6| Step: 4
Training loss: 2.317362853172053
Validation loss: 2.4876479607024367

Epoch: 6| Step: 5
Training loss: 2.9208928869890425
Validation loss: 2.4786990086466267

Epoch: 6| Step: 6
Training loss: 2.140395883146521
Validation loss: 2.494248181590884

Epoch: 6| Step: 7
Training loss: 2.490801865485384
Validation loss: 2.5010835883405385

Epoch: 6| Step: 8
Training loss: 3.5350909653847555
Validation loss: 2.513648269794523

Epoch: 6| Step: 9
Training loss: 2.731675652129791
Validation loss: 2.50772663877112

Epoch: 6| Step: 10
Training loss: 2.776290414817446
Validation loss: 2.50760948185636

Epoch: 6| Step: 11
Training loss: 3.124952239625266
Validation loss: 2.487471467170521

Epoch: 6| Step: 12
Training loss: 2.340291434178061
Validation loss: 2.5011600120659914

Epoch: 6| Step: 13
Training loss: 3.1262706462143273
Validation loss: 2.5132379642829665

Epoch: 91| Step: 0
Training loss: 2.00529922345418
Validation loss: 2.4821952833300234

Epoch: 6| Step: 1
Training loss: 2.937080190975005
Validation loss: 2.5064170772505863

Epoch: 6| Step: 2
Training loss: 2.712174982384212
Validation loss: 2.497578198520141

Epoch: 6| Step: 3
Training loss: 2.2976921859571817
Validation loss: 2.50265237327436

Epoch: 6| Step: 4
Training loss: 2.789678339993897
Validation loss: 2.503898949892667

Epoch: 6| Step: 5
Training loss: 2.1547054342584397
Validation loss: 2.514282477742264

Epoch: 6| Step: 6
Training loss: 2.6914187404746905
Validation loss: 2.5058381034781965

Epoch: 6| Step: 7
Training loss: 2.9578832006292024
Validation loss: 2.4985203630227804

Epoch: 6| Step: 8
Training loss: 2.3526772933133366
Validation loss: 2.4997785654752933

Epoch: 6| Step: 9
Training loss: 3.1188105514244158
Validation loss: 2.508420147666097

Epoch: 6| Step: 10
Training loss: 2.6332152650013136
Validation loss: 2.5067463836166524

Epoch: 6| Step: 11
Training loss: 2.827788865151577
Validation loss: 2.4999933929766236

Epoch: 6| Step: 12
Training loss: 2.1103065976670847
Validation loss: 2.507756396117688

Epoch: 6| Step: 13
Training loss: 3.60707197160148
Validation loss: 2.4991043301428895

Epoch: 92| Step: 0
Training loss: 2.365564173693726
Validation loss: 2.497500890196876

Epoch: 6| Step: 1
Training loss: 3.452006163086589
Validation loss: 2.495820522944845

Epoch: 6| Step: 2
Training loss: 2.6581175578049288
Validation loss: 2.481152905691084

Epoch: 6| Step: 3
Training loss: 3.4015030287527686
Validation loss: 2.5146132090277566

Epoch: 6| Step: 4
Training loss: 2.9298899669622167
Validation loss: 2.494212621814608

Epoch: 6| Step: 5
Training loss: 2.714991811104187
Validation loss: 2.4881922389338644

Epoch: 6| Step: 6
Training loss: 2.8193933568960228
Validation loss: 2.5095380299788044

Epoch: 6| Step: 7
Training loss: 2.6956809856244717
Validation loss: 2.5048877588643155

Epoch: 6| Step: 8
Training loss: 2.1409623374494933
Validation loss: 2.4948121459073804

Epoch: 6| Step: 9
Training loss: 2.1308256963066623
Validation loss: 2.5138998004373834

Epoch: 6| Step: 10
Training loss: 2.514078932780159
Validation loss: 2.5076497516808818

Epoch: 6| Step: 11
Training loss: 2.422794487437375
Validation loss: 2.4903939183356156

Epoch: 6| Step: 12
Training loss: 1.8819961994307084
Validation loss: 2.5143044598732867

Epoch: 6| Step: 13
Training loss: 2.512272466728583
Validation loss: 2.508261821450909

Epoch: 93| Step: 0
Training loss: 2.6996664512317987
Validation loss: 2.499904510766339

Epoch: 6| Step: 1
Training loss: 2.9386651183687946
Validation loss: 2.5090486678636714

Epoch: 6| Step: 2
Training loss: 2.4850871666831296
Validation loss: 2.4954168516984865

Epoch: 6| Step: 3
Training loss: 2.6765695120858237
Validation loss: 2.5114613682805063

Epoch: 6| Step: 4
Training loss: 2.42414090384699
Validation loss: 2.5267681538997517

Epoch: 6| Step: 5
Training loss: 2.721379554058216
Validation loss: 2.503930411872458

Epoch: 6| Step: 6
Training loss: 3.079061762597598
Validation loss: 2.509377924134694

Epoch: 6| Step: 7
Training loss: 2.477907603711102
Validation loss: 2.498784707126245

Epoch: 6| Step: 8
Training loss: 1.9422771872008322
Validation loss: 2.5020129098742845

Epoch: 6| Step: 9
Training loss: 2.7837268216179223
Validation loss: 2.5073037684288666

Epoch: 6| Step: 10
Training loss: 2.3204701174238234
Validation loss: 2.4886811809580296

Epoch: 6| Step: 11
Training loss: 3.1409474677035027
Validation loss: 2.509384323579078

Epoch: 6| Step: 12
Training loss: 2.137777843598708
Validation loss: 2.5098793116078517

Epoch: 6| Step: 13
Training loss: 3.0518045308924013
Validation loss: 2.50342694100212

Epoch: 94| Step: 0
Training loss: 1.9844373558039334
Validation loss: 2.5073852011469606

Epoch: 6| Step: 1
Training loss: 3.0984690731438653
Validation loss: 2.482752120236353

Epoch: 6| Step: 2
Training loss: 1.7455063072796533
Validation loss: 2.501242527797725

Epoch: 6| Step: 3
Training loss: 3.0188211689333304
Validation loss: 2.5072316429321764

Epoch: 6| Step: 4
Training loss: 3.136021214666427
Validation loss: 2.505721395398837

Epoch: 6| Step: 5
Training loss: 2.916758090811602
Validation loss: 2.4930019980946807

Epoch: 6| Step: 6
Training loss: 2.5940308016710807
Validation loss: 2.500539825977207

Epoch: 6| Step: 7
Training loss: 3.1335875962624224
Validation loss: 2.4885898508898023

Epoch: 6| Step: 8
Training loss: 2.5019680859537563
Validation loss: 2.5147827854222737

Epoch: 6| Step: 9
Training loss: 1.995263331919472
Validation loss: 2.501361177954973

Epoch: 6| Step: 10
Training loss: 2.734541010585546
Validation loss: 2.494252361735348

Epoch: 6| Step: 11
Training loss: 1.7875384373300203
Validation loss: 2.4935439785516396

Epoch: 6| Step: 12
Training loss: 2.9594120333488343
Validation loss: 2.4948062722037645

Epoch: 6| Step: 13
Training loss: 3.070929778269761
Validation loss: 2.495121644630591

Epoch: 95| Step: 0
Training loss: 2.6152545224496992
Validation loss: 2.4982809185973496

Epoch: 6| Step: 1
Training loss: 2.1744330182384703
Validation loss: 2.5028613748411557

Epoch: 6| Step: 2
Training loss: 2.8641749050394454
Validation loss: 2.498326469507786

Epoch: 6| Step: 3
Training loss: 2.7914776429666888
Validation loss: 2.4892439090605656

Epoch: 6| Step: 4
Training loss: 2.4765486370865943
Validation loss: 2.4979361310950035

Epoch: 6| Step: 5
Training loss: 2.7268158977992485
Validation loss: 2.4941446603959565

Epoch: 6| Step: 6
Training loss: 3.201416899989988
Validation loss: 2.4940731848171414

Epoch: 6| Step: 7
Training loss: 2.34644234195591
Validation loss: 2.5076813792437562

Epoch: 6| Step: 8
Training loss: 2.6362615344327445
Validation loss: 2.4897030604955415

Epoch: 6| Step: 9
Training loss: 3.3866927026013194
Validation loss: 2.500610049479138

Epoch: 6| Step: 10
Training loss: 2.7762371707707434
Validation loss: 2.5115281506714724

Epoch: 6| Step: 11
Training loss: 2.2510861847968098
Validation loss: 2.496633295177109

Epoch: 6| Step: 12
Training loss: 2.327796247171811
Validation loss: 2.5109162900394533

Epoch: 6| Step: 13
Training loss: 2.1077123800582425
Validation loss: 2.4988367440473853

Epoch: 96| Step: 0
Training loss: 2.3262721119382697
Validation loss: 2.4870991217537486

Epoch: 6| Step: 1
Training loss: 2.770086794984158
Validation loss: 2.501098027642589

Epoch: 6| Step: 2
Training loss: 2.323056534688856
Validation loss: 2.4879602880863425

Epoch: 6| Step: 3
Training loss: 2.998199081284975
Validation loss: 2.502244294726008

Epoch: 6| Step: 4
Training loss: 2.4088629865055315
Validation loss: 2.507877054994625

Epoch: 6| Step: 5
Training loss: 2.292256389225008
Validation loss: 2.4983357663475805

Epoch: 6| Step: 6
Training loss: 3.0436349709960164
Validation loss: 2.5063865404504204

Epoch: 6| Step: 7
Training loss: 2.979224428981843
Validation loss: 2.4997680638510245

Epoch: 6| Step: 8
Training loss: 2.9933756170139576
Validation loss: 2.5029882752791375

Epoch: 6| Step: 9
Training loss: 2.2061728099255142
Validation loss: 2.4978278321739626

Epoch: 6| Step: 10
Training loss: 2.930450746933003
Validation loss: 2.4917909631590724

Epoch: 6| Step: 11
Training loss: 2.6921275906530635
Validation loss: 2.510814429123899

Epoch: 6| Step: 12
Training loss: 2.4314291253088474
Validation loss: 2.5071130947190365

Epoch: 6| Step: 13
Training loss: 2.31492508208822
Validation loss: 2.4944105591740975

Epoch: 97| Step: 0
Training loss: 2.942188498344394
Validation loss: 2.4996810535304674

Epoch: 6| Step: 1
Training loss: 1.8722642649839234
Validation loss: 2.5051769225372604

Epoch: 6| Step: 2
Training loss: 2.907712998858042
Validation loss: 2.520821021048339

Epoch: 6| Step: 3
Training loss: 2.6937541492545263
Validation loss: 2.5020291691825722

Epoch: 6| Step: 4
Training loss: 2.0723937891122137
Validation loss: 2.511036474969567

Epoch: 6| Step: 5
Training loss: 1.9394929541793968
Validation loss: 2.490930296274641

Epoch: 6| Step: 6
Training loss: 2.8009495385339114
Validation loss: 2.514864057517205

Epoch: 6| Step: 7
Training loss: 3.2383787280827767
Validation loss: 2.49968955460746

Epoch: 6| Step: 8
Training loss: 3.2859676778716325
Validation loss: 2.5142064406613147

Epoch: 6| Step: 9
Training loss: 2.059606661233893
Validation loss: 2.4961304260801858

Epoch: 6| Step: 10
Training loss: 2.864467234715266
Validation loss: 2.4969090827606464

Epoch: 6| Step: 11
Training loss: 2.7884731150824456
Validation loss: 2.5071301139312934

Epoch: 6| Step: 12
Training loss: 2.5523447850006034
Validation loss: 2.5079336320176058

Epoch: 6| Step: 13
Training loss: 2.3062133910212075
Validation loss: 2.503931543222694

Epoch: 98| Step: 0
Training loss: 2.0449655959912483
Validation loss: 2.4865144997879747

Epoch: 6| Step: 1
Training loss: 2.701104086730742
Validation loss: 2.4991055888283435

Epoch: 6| Step: 2
Training loss: 2.536520098822589
Validation loss: 2.497749462089196

Epoch: 6| Step: 3
Training loss: 2.6661490494314415
Validation loss: 2.48485162659094

Epoch: 6| Step: 4
Training loss: 2.858140355779429
Validation loss: 2.5090711372439993

Epoch: 6| Step: 5
Training loss: 2.6372818409155383
Validation loss: 2.519387934135723

Epoch: 6| Step: 6
Training loss: 2.514239859859535
Validation loss: 2.509865708300971

Epoch: 6| Step: 7
Training loss: 1.917532814968579
Validation loss: 2.498151129350325

Epoch: 6| Step: 8
Training loss: 2.8197460503911143
Validation loss: 2.4876292811768583

Epoch: 6| Step: 9
Training loss: 3.265452111153121
Validation loss: 2.4840006480160075

Epoch: 6| Step: 10
Training loss: 2.260794706125939
Validation loss: 2.512678939070735

Epoch: 6| Step: 11
Training loss: 3.298421054294921
Validation loss: 2.508456335900573

Epoch: 6| Step: 12
Training loss: 2.889984059801327
Validation loss: 2.497012740372114

Epoch: 6| Step: 13
Training loss: 1.5033061626175297
Validation loss: 2.498488002821459

Epoch: 99| Step: 0
Training loss: 2.706611898068572
Validation loss: 2.4914226954831853

Epoch: 6| Step: 1
Training loss: 2.545109236195948
Validation loss: 2.5006702304024873

Epoch: 6| Step: 2
Training loss: 3.407138813492808
Validation loss: 2.504239902596251

Epoch: 6| Step: 3
Training loss: 1.7607167306118674
Validation loss: 2.4951961395915587

Epoch: 6| Step: 4
Training loss: 2.962985575995869
Validation loss: 2.509327230130466

Epoch: 6| Step: 5
Training loss: 2.5309059003370877
Validation loss: 2.501185093216944

Epoch: 6| Step: 6
Training loss: 1.7705442379604157
Validation loss: 2.4931269067899566

Epoch: 6| Step: 7
Training loss: 2.5053393566951785
Validation loss: 2.5073283530666894

Epoch: 6| Step: 8
Training loss: 3.130721386053816
Validation loss: 2.4940320985633355

Epoch: 6| Step: 9
Training loss: 3.483510547370652
Validation loss: 2.4889946319310985

Epoch: 6| Step: 10
Training loss: 2.386793669228703
Validation loss: 2.4934783924157635

Epoch: 6| Step: 11
Training loss: 2.439043387827506
Validation loss: 2.5196224576748985

Epoch: 6| Step: 12
Training loss: 2.1871849923161033
Validation loss: 2.506181439706394

Epoch: 6| Step: 13
Training loss: 2.3237974153619376
Validation loss: 2.5105876051703975

Epoch: 100| Step: 0
Training loss: 2.044708969560861
Validation loss: 2.5070955845653713

Epoch: 6| Step: 1
Training loss: 2.6222307948153754
Validation loss: 2.504989103451125

Epoch: 6| Step: 2
Training loss: 3.0129255951798486
Validation loss: 2.4942180128067326

Epoch: 6| Step: 3
Training loss: 2.2442737403745157
Validation loss: 2.4986526498922887

Epoch: 6| Step: 4
Training loss: 2.913340788540005
Validation loss: 2.48449007442273

Epoch: 6| Step: 5
Training loss: 2.597513983709972
Validation loss: 2.5023319561201087

Epoch: 6| Step: 6
Training loss: 2.427053514114589
Validation loss: 2.4939050374224134

Epoch: 6| Step: 7
Training loss: 3.125517230144895
Validation loss: 2.50697258415068

Epoch: 6| Step: 8
Training loss: 2.777198497981803
Validation loss: 2.507402973064728

Epoch: 6| Step: 9
Training loss: 2.8377730049180125
Validation loss: 2.500850303184932

Epoch: 6| Step: 10
Training loss: 2.6554670189641127
Validation loss: 2.5059013031656616

Epoch: 6| Step: 11
Training loss: 2.3595017152825695
Validation loss: 2.4961973105242987

Epoch: 6| Step: 12
Training loss: 2.5627275691514626
Validation loss: 2.4965406017194787

Epoch: 6| Step: 13
Training loss: 2.277600753180296
Validation loss: 2.5119305478315033

Epoch: 101| Step: 0
Training loss: 2.3704060746634257
Validation loss: 2.500431143592438

Epoch: 6| Step: 1
Training loss: 2.2639074721350507
Validation loss: 2.494479310349857

Epoch: 6| Step: 2
Training loss: 2.2934223616677767
Validation loss: 2.511224565560475

Epoch: 6| Step: 3
Training loss: 2.1751240092035715
Validation loss: 2.494758263714852

Epoch: 6| Step: 4
Training loss: 2.352367681497486
Validation loss: 2.489268856924988

Epoch: 6| Step: 5
Training loss: 2.832570328542205
Validation loss: 2.502668323680239

Epoch: 6| Step: 6
Training loss: 2.611404999861803
Validation loss: 2.5117768837340857

Epoch: 6| Step: 7
Training loss: 3.143401934730365
Validation loss: 2.4932252436908158

Epoch: 6| Step: 8
Training loss: 2.409005902984215
Validation loss: 2.4991820002088

Epoch: 6| Step: 9
Training loss: 2.3276572557667263
Validation loss: 2.5115752823080326

Epoch: 6| Step: 10
Training loss: 2.6644063151606714
Validation loss: 2.4931649262449067

Epoch: 6| Step: 11
Training loss: 2.929556637702343
Validation loss: 2.5178732558090586

Epoch: 6| Step: 12
Training loss: 3.373593213797445
Validation loss: 2.5090863663649046

Epoch: 6| Step: 13
Training loss: 3.0358888976584404
Validation loss: 2.504498866837311

Epoch: 102| Step: 0
Training loss: 2.4747226752377602
Validation loss: 2.497735352400497

Epoch: 6| Step: 1
Training loss: 2.7361690194531363
Validation loss: 2.49920684322629

Epoch: 6| Step: 2
Training loss: 3.146741992673856
Validation loss: 2.495268938145617

Epoch: 6| Step: 3
Training loss: 2.5061067383267455
Validation loss: 2.4973555771250244

Epoch: 6| Step: 4
Training loss: 2.7725406539867063
Validation loss: 2.4923894301939575

Epoch: 6| Step: 5
Training loss: 2.599190028278153
Validation loss: 2.4959520629086063

Epoch: 6| Step: 6
Training loss: 2.8426238125128926
Validation loss: 2.499508050486558

Epoch: 6| Step: 7
Training loss: 2.50263542502442
Validation loss: 2.507596261885435

Epoch: 6| Step: 8
Training loss: 2.391296192765937
Validation loss: 2.491957116457072

Epoch: 6| Step: 9
Training loss: 2.627295625616258
Validation loss: 2.503378387129746

Epoch: 6| Step: 10
Training loss: 2.05674634699777
Validation loss: 2.507160618156726

Epoch: 6| Step: 11
Training loss: 2.1334541669043405
Validation loss: 2.4771681731045563

Epoch: 6| Step: 12
Training loss: 2.6643576360642736
Validation loss: 2.495854784594471

Epoch: 6| Step: 13
Training loss: 3.7057191156540097
Validation loss: 2.4925352796353333

Epoch: 103| Step: 0
Training loss: 2.9507155504252665
Validation loss: 2.4981978011811856

Epoch: 6| Step: 1
Training loss: 1.8168880356936765
Validation loss: 2.499715573528214

Epoch: 6| Step: 2
Training loss: 2.8878485465134935
Validation loss: 2.4845951875603673

Epoch: 6| Step: 3
Training loss: 2.4584485258711255
Validation loss: 2.5025814536359197

Epoch: 6| Step: 4
Training loss: 2.264221072123048
Validation loss: 2.5000441249932153

Epoch: 6| Step: 5
Training loss: 2.9196991188024732
Validation loss: 2.4901909656670043

Epoch: 6| Step: 6
Training loss: 2.794358810551962
Validation loss: 2.5021292735157092

Epoch: 6| Step: 7
Training loss: 3.3725482371099305
Validation loss: 2.4878154100997563

Epoch: 6| Step: 8
Training loss: 2.333238554346567
Validation loss: 2.48956394243783

Epoch: 6| Step: 9
Training loss: 2.3844064852934315
Validation loss: 2.494829259309998

Epoch: 6| Step: 10
Training loss: 2.578680545021326
Validation loss: 2.4785354977938487

Epoch: 6| Step: 11
Training loss: 2.666775661466271
Validation loss: 2.5152924524922495

Epoch: 6| Step: 12
Training loss: 2.2134997075909837
Validation loss: 2.505377812963653

Epoch: 6| Step: 13
Training loss: 3.0103531845069593
Validation loss: 2.49455482443997

Epoch: 104| Step: 0
Training loss: 2.5104516898807954
Validation loss: 2.4822556050043936

Epoch: 6| Step: 1
Training loss: 2.8831482565103297
Validation loss: 2.4955333051201345

Epoch: 6| Step: 2
Training loss: 2.8472669044854957
Validation loss: 2.490300835131357

Epoch: 6| Step: 3
Training loss: 2.977228205372446
Validation loss: 2.5064631952451646

Epoch: 6| Step: 4
Training loss: 2.5770200268785466
Validation loss: 2.4934722544225574

Epoch: 6| Step: 5
Training loss: 2.5865444611983492
Validation loss: 2.5021846895555804

Epoch: 6| Step: 6
Training loss: 2.227216122709487
Validation loss: 2.49793393890973

Epoch: 6| Step: 7
Training loss: 1.5619391388410764
Validation loss: 2.5053241661939363

Epoch: 6| Step: 8
Training loss: 2.887178583132404
Validation loss: 2.5061416250258453

Epoch: 6| Step: 9
Training loss: 2.5164897688110637
Validation loss: 2.4973095922350694

Epoch: 6| Step: 10
Training loss: 3.3033519598329555
Validation loss: 2.5172859038275086

Epoch: 6| Step: 11
Training loss: 2.4274198983645316
Validation loss: 2.4906677412057685

Epoch: 6| Step: 12
Training loss: 2.534528704590763
Validation loss: 2.509808957263026

Epoch: 6| Step: 13
Training loss: 2.439916049107156
Validation loss: 2.4904861889733554

Epoch: 105| Step: 0
Training loss: 3.0975714307527635
Validation loss: 2.498230271864563

Epoch: 6| Step: 1
Training loss: 2.327353023063674
Validation loss: 2.508296860103438

Epoch: 6| Step: 2
Training loss: 2.1551338292318216
Validation loss: 2.494738056693454

Epoch: 6| Step: 3
Training loss: 2.0639740271597504
Validation loss: 2.482449711745472

Epoch: 6| Step: 4
Training loss: 2.797204024924829
Validation loss: 2.499629001366571

Epoch: 6| Step: 5
Training loss: 3.2056813529586097
Validation loss: 2.4925635855750294

Epoch: 6| Step: 6
Training loss: 2.570107680859099
Validation loss: 2.4830641644278195

Epoch: 6| Step: 7
Training loss: 2.175221890059976
Validation loss: 2.4673875263272227

Epoch: 6| Step: 8
Training loss: 2.2175791700265615
Validation loss: 2.4853767516072547

Epoch: 6| Step: 9
Training loss: 2.8467984470832195
Validation loss: 2.4830858597299077

Epoch: 6| Step: 10
Training loss: 3.3521582867524855
Validation loss: 2.495452374795515

Epoch: 6| Step: 11
Training loss: 2.629137774357585
Validation loss: 2.496073350430323

Epoch: 6| Step: 12
Training loss: 2.2372977607583193
Validation loss: 2.482485274786198

Epoch: 6| Step: 13
Training loss: 2.3567668317616812
Validation loss: 2.485465388003625

Epoch: 106| Step: 0
Training loss: 2.6775472117873287
Validation loss: 2.489593680551591

Epoch: 6| Step: 1
Training loss: 2.830613532536905
Validation loss: 2.4987795096328673

Epoch: 6| Step: 2
Training loss: 2.172072696607304
Validation loss: 2.4911225909516768

Epoch: 6| Step: 3
Training loss: 2.8076231317871856
Validation loss: 2.4999782212652106

Epoch: 6| Step: 4
Training loss: 2.5481941223874354
Validation loss: 2.4920986922344874

Epoch: 6| Step: 5
Training loss: 2.7395528542644683
Validation loss: 2.5042642229957357

Epoch: 6| Step: 6
Training loss: 2.4829141412363547
Validation loss: 2.4960980862479323

Epoch: 6| Step: 7
Training loss: 3.245347434137325
Validation loss: 2.497658916264385

Epoch: 6| Step: 8
Training loss: 2.747339001590565
Validation loss: 2.507299445937007

Epoch: 6| Step: 9
Training loss: 2.298597040610324
Validation loss: 2.4862317652376413

Epoch: 6| Step: 10
Training loss: 2.6138015936088097
Validation loss: 2.506133642987027

Epoch: 6| Step: 11
Training loss: 2.381881481953602
Validation loss: 2.505161206075868

Epoch: 6| Step: 12
Training loss: 2.594265438478338
Validation loss: 2.4955847236215565

Epoch: 6| Step: 13
Training loss: 2.371804044564341
Validation loss: 2.4835386400185335

Epoch: 107| Step: 0
Training loss: 2.10136645228691
Validation loss: 2.4948379906555527

Epoch: 6| Step: 1
Training loss: 3.4465513878094196
Validation loss: 2.486366868094846

Epoch: 6| Step: 2
Training loss: 3.010491146939446
Validation loss: 2.4847826699003215

Epoch: 6| Step: 3
Training loss: 2.0001852426572513
Validation loss: 2.4946891220165663

Epoch: 6| Step: 4
Training loss: 2.5607100026698526
Validation loss: 2.488164977479501

Epoch: 6| Step: 5
Training loss: 2.8021580758224496
Validation loss: 2.5032316301853395

Epoch: 6| Step: 6
Training loss: 2.211675945205984
Validation loss: 2.4890410346271206

Epoch: 6| Step: 7
Training loss: 2.4573182634307926
Validation loss: 2.505824671082108

Epoch: 6| Step: 8
Training loss: 2.1867332204521883
Validation loss: 2.4991656346713516

Epoch: 6| Step: 9
Training loss: 2.8326738562429465
Validation loss: 2.5031323139990778

Epoch: 6| Step: 10
Training loss: 2.2722462682635647
Validation loss: 2.477959158275679

Epoch: 6| Step: 11
Training loss: 2.9490999109438465
Validation loss: 2.505710001966561

Epoch: 6| Step: 12
Training loss: 2.8345880161306347
Validation loss: 2.5146900167590895

Epoch: 6| Step: 13
Training loss: 2.256857065970981
Validation loss: 2.5015656214228392

Epoch: 108| Step: 0
Training loss: 2.616155620245019
Validation loss: 2.511801478174122

Epoch: 6| Step: 1
Training loss: 2.41573298164823
Validation loss: 2.5039920246669607

Epoch: 6| Step: 2
Training loss: 2.588525128583571
Validation loss: 2.4911263914541806

Epoch: 6| Step: 3
Training loss: 2.7592255427666137
Validation loss: 2.497123613519009

Epoch: 6| Step: 4
Training loss: 1.9795790259458195
Validation loss: 2.502726569302529

Epoch: 6| Step: 5
Training loss: 2.5401285134492007
Validation loss: 2.5040580531103416

Epoch: 6| Step: 6
Training loss: 2.8390380052130237
Validation loss: 2.5023909753679563

Epoch: 6| Step: 7
Training loss: 2.9091911610213494
Validation loss: 2.487614633844999

Epoch: 6| Step: 8
Training loss: 2.7144342127311467
Validation loss: 2.4882060957035956

Epoch: 6| Step: 9
Training loss: 2.860485090718641
Validation loss: 2.4975728897120058

Epoch: 6| Step: 10
Training loss: 2.4280036414808843
Validation loss: 2.498777222773395

Epoch: 6| Step: 11
Training loss: 2.8408104092191597
Validation loss: 2.5027340746237265

Epoch: 6| Step: 12
Training loss: 2.173009891527873
Validation loss: 2.4915178522912655

Epoch: 6| Step: 13
Training loss: 3.046182093937634
Validation loss: 2.4948515823927497

Epoch: 109| Step: 0
Training loss: 2.2352705007964824
Validation loss: 2.5043382248834196

Epoch: 6| Step: 1
Training loss: 2.2660987095692082
Validation loss: 2.4861573161746846

Epoch: 6| Step: 2
Training loss: 2.013880958395357
Validation loss: 2.506457103369485

Epoch: 6| Step: 3
Training loss: 1.7341675505421243
Validation loss: 2.4969909576563483

Epoch: 6| Step: 4
Training loss: 3.079333382834928
Validation loss: 2.5079043832861756

Epoch: 6| Step: 5
Training loss: 2.9832907100026613
Validation loss: 2.4956319221468855

Epoch: 6| Step: 6
Training loss: 2.8564204392613632
Validation loss: 2.4951806530834637

Epoch: 6| Step: 7
Training loss: 2.469637071610404
Validation loss: 2.4908863072749963

Epoch: 6| Step: 8
Training loss: 2.334763247721832
Validation loss: 2.4912629062287053

Epoch: 6| Step: 9
Training loss: 2.524143368284049
Validation loss: 2.5062331890485203

Epoch: 6| Step: 10
Training loss: 3.105716565878677
Validation loss: 2.500008293876426

Epoch: 6| Step: 11
Training loss: 2.450217206240616
Validation loss: 2.487177747544389

Epoch: 6| Step: 12
Training loss: 2.444638095275069
Validation loss: 2.507161481169773

Epoch: 6| Step: 13
Training loss: 4.200939872574741
Validation loss: 2.4976962965676894

Epoch: 110| Step: 0
Training loss: 1.8153673051496222
Validation loss: 2.4882849724195166

Epoch: 6| Step: 1
Training loss: 2.588370201730907
Validation loss: 2.506457229687071

Epoch: 6| Step: 2
Training loss: 2.755793018474909
Validation loss: 2.4667027599961098

Epoch: 6| Step: 3
Training loss: 2.697942628085052
Validation loss: 2.490127782146885

Epoch: 6| Step: 4
Training loss: 2.6068747414310085
Validation loss: 2.4964723843078542

Epoch: 6| Step: 5
Training loss: 2.4400195280450547
Validation loss: 2.482778449858794

Epoch: 6| Step: 6
Training loss: 3.0462179404705645
Validation loss: 2.488537310219066

Epoch: 6| Step: 7
Training loss: 1.9863139014170867
Validation loss: 2.5133111526645533

Epoch: 6| Step: 8
Training loss: 3.0216275102954238
Validation loss: 2.483283393015247

Epoch: 6| Step: 9
Training loss: 2.2124842971847976
Validation loss: 2.4998597377479475

Epoch: 6| Step: 10
Training loss: 3.5892921995363296
Validation loss: 2.4974655450792875

Epoch: 6| Step: 11
Training loss: 2.4280547025070707
Validation loss: 2.5038355998346855

Epoch: 6| Step: 12
Training loss: 2.399920970887147
Validation loss: 2.497351989357812

Epoch: 6| Step: 13
Training loss: 2.448984527339633
Validation loss: 2.4889799617342607

Epoch: 111| Step: 0
Training loss: 2.3846328535930947
Validation loss: 2.498893449833152

Epoch: 6| Step: 1
Training loss: 2.4150646314798396
Validation loss: 2.503141361527376

Epoch: 6| Step: 2
Training loss: 2.4577742334140624
Validation loss: 2.495226359222073

Epoch: 6| Step: 3
Training loss: 2.962777323558782
Validation loss: 2.5011304401742027

Epoch: 6| Step: 4
Training loss: 2.857483284968952
Validation loss: 2.509204856087784

Epoch: 6| Step: 5
Training loss: 2.1157957337764555
Validation loss: 2.5022258601726883

Epoch: 6| Step: 6
Training loss: 2.3251193313328553
Validation loss: 2.491418377851558

Epoch: 6| Step: 7
Training loss: 2.7840928539488727
Validation loss: 2.496067028809971

Epoch: 6| Step: 8
Training loss: 2.2884641522797624
Validation loss: 2.4903107198923387

Epoch: 6| Step: 9
Training loss: 1.9842379064586713
Validation loss: 2.5053349044399233

Epoch: 6| Step: 10
Training loss: 3.1989313725476407
Validation loss: 2.49676878702449

Epoch: 6| Step: 11
Training loss: 2.8668162757808586
Validation loss: 2.4873411942799666

Epoch: 6| Step: 12
Training loss: 3.087517674198606
Validation loss: 2.49505903241546

Epoch: 6| Step: 13
Training loss: 2.359339833786974
Validation loss: 2.5039445685593584

Epoch: 112| Step: 0
Training loss: 3.0950755352607677
Validation loss: 2.4919544457792298

Epoch: 6| Step: 1
Training loss: 2.621480307805387
Validation loss: 2.4850109233489435

Epoch: 6| Step: 2
Training loss: 2.8865419986695167
Validation loss: 2.4911936181228143

Epoch: 6| Step: 3
Training loss: 2.4488305083783666
Validation loss: 2.495825407149932

Epoch: 6| Step: 4
Training loss: 2.4848137234232075
Validation loss: 2.5019216094648558

Epoch: 6| Step: 5
Training loss: 2.0014447715852803
Validation loss: 2.492246612898043

Epoch: 6| Step: 6
Training loss: 2.8303572975767213
Validation loss: 2.5175606428274286

Epoch: 6| Step: 7
Training loss: 2.7061409415103648
Validation loss: 2.4944011906641657

Epoch: 6| Step: 8
Training loss: 2.3876222189732337
Validation loss: 2.50173343633644

Epoch: 6| Step: 9
Training loss: 2.5595341708627304
Validation loss: 2.484374674949694

Epoch: 6| Step: 10
Training loss: 2.3405754460995865
Validation loss: 2.4970765140282274

Epoch: 6| Step: 11
Training loss: 3.033602715851578
Validation loss: 2.5072737051008263

Epoch: 6| Step: 12
Training loss: 2.8474591557199993
Validation loss: 2.497299939976602

Epoch: 6| Step: 13
Training loss: 2.0717977702158543
Validation loss: 2.510934901743926

Epoch: 113| Step: 0
Training loss: 1.8499432013787982
Validation loss: 2.4988343608024413

Epoch: 6| Step: 1
Training loss: 3.0488381345927937
Validation loss: 2.482727714051218

Epoch: 6| Step: 2
Training loss: 3.0452073448506467
Validation loss: 2.5187026789071507

Epoch: 6| Step: 3
Training loss: 2.6921009335407264
Validation loss: 2.49263563925389

Epoch: 6| Step: 4
Training loss: 2.8533271241640406
Validation loss: 2.5036052877301795

Epoch: 6| Step: 5
Training loss: 2.5950277467394556
Validation loss: 2.499353965225993

Epoch: 6| Step: 6
Training loss: 2.454746560807329
Validation loss: 2.5052010834110834

Epoch: 6| Step: 7
Training loss: 1.572098736168959
Validation loss: 2.5070172976308625

Epoch: 6| Step: 8
Training loss: 2.9920670208691926
Validation loss: 2.4977468838207595

Epoch: 6| Step: 9
Training loss: 2.944045869573591
Validation loss: 2.4850281909059873

Epoch: 6| Step: 10
Training loss: 2.5532756485494446
Validation loss: 2.4843667323580583

Epoch: 6| Step: 11
Training loss: 2.031816374238944
Validation loss: 2.5167385116597862

Epoch: 6| Step: 12
Training loss: 2.527834624977542
Validation loss: 2.489680287604872

Epoch: 6| Step: 13
Training loss: 2.6999818024198676
Validation loss: 2.4899632678926307

Epoch: 114| Step: 0
Training loss: 3.452643589622017
Validation loss: 2.47981226156894

Epoch: 6| Step: 1
Training loss: 2.836638729108799
Validation loss: 2.4861619079521775

Epoch: 6| Step: 2
Training loss: 1.8975921130030928
Validation loss: 2.489620777050549

Epoch: 6| Step: 3
Training loss: 2.7793285290328926
Validation loss: 2.5065829340088226

Epoch: 6| Step: 4
Training loss: 2.2388259198357994
Validation loss: 2.4781104978491824

Epoch: 6| Step: 5
Training loss: 2.7567096698855553
Validation loss: 2.462569833975738

Epoch: 6| Step: 6
Training loss: 2.3388671875
Validation loss: 2.4980671599336293

Epoch: 6| Step: 7
Training loss: 3.3313385398793014
Validation loss: 2.497125327489655

Epoch: 6| Step: 8
Training loss: 2.242684445487972
Validation loss: 2.494712311617704

Epoch: 6| Step: 9
Training loss: 2.4882097698107253
Validation loss: 2.4880906017179156

Epoch: 6| Step: 10
Training loss: 2.9003403167985424
Validation loss: 2.488708295632951

Epoch: 6| Step: 11
Training loss: 1.5412558790158206
Validation loss: 2.4853668441284924

Epoch: 6| Step: 12
Training loss: 2.549298216048516
Validation loss: 2.498266279329128

Epoch: 6| Step: 13
Training loss: 2.278156743920801
Validation loss: 2.501318990738409

Epoch: 115| Step: 0
Training loss: 3.1233274943304967
Validation loss: 2.4879698194404276

Epoch: 6| Step: 1
Training loss: 1.494985065066651
Validation loss: 2.497006867224867

Epoch: 6| Step: 2
Training loss: 2.5601825935095675
Validation loss: 2.48964794636473

Epoch: 6| Step: 3
Training loss: 2.5429864698223352
Validation loss: 2.487173473050191

Epoch: 6| Step: 4
Training loss: 2.94062217201478
Validation loss: 2.49784198034127

Epoch: 6| Step: 5
Training loss: 2.6211677006438716
Validation loss: 2.491098962460507

Epoch: 6| Step: 6
Training loss: 2.8440615305193173
Validation loss: 2.50139259806257

Epoch: 6| Step: 7
Training loss: 2.134637854993829
Validation loss: 2.4896734070947586

Epoch: 6| Step: 8
Training loss: 1.9367454659303158
Validation loss: 2.4708869753810547

Epoch: 6| Step: 9
Training loss: 2.2836809139732512
Validation loss: 2.505091461170038

Epoch: 6| Step: 10
Training loss: 2.0511355720697173
Validation loss: 2.4952068906012257

Epoch: 6| Step: 11
Training loss: 2.9396675716003253
Validation loss: 2.5062673845584

Epoch: 6| Step: 12
Training loss: 3.3426297887171033
Validation loss: 2.4931224738569298

Epoch: 6| Step: 13
Training loss: 3.2610064248375887
Validation loss: 2.497371596263099

Epoch: 116| Step: 0
Training loss: 2.732246224222673
Validation loss: 2.479384448843119

Epoch: 6| Step: 1
Training loss: 2.6864499546929634
Validation loss: 2.4996530789474765

Epoch: 6| Step: 2
Training loss: 2.2831316986528734
Validation loss: 2.4774468156692917

Epoch: 6| Step: 3
Training loss: 2.9456006625032276
Validation loss: 2.4800473954173614

Epoch: 6| Step: 4
Training loss: 2.684401655675417
Validation loss: 2.483541957161882

Epoch: 6| Step: 5
Training loss: 2.5241547028879445
Validation loss: 2.5083488673053913

Epoch: 6| Step: 6
Training loss: 2.557098650721455
Validation loss: 2.473101598884895

Epoch: 6| Step: 7
Training loss: 2.7606858799970593
Validation loss: 2.482505276384645

Epoch: 6| Step: 8
Training loss: 2.8414901305669487
Validation loss: 2.495911258205042

Epoch: 6| Step: 9
Training loss: 2.742779007718388
Validation loss: 2.49522670854419

Epoch: 6| Step: 10
Training loss: 2.1211130833315495
Validation loss: 2.501741596373313

Epoch: 6| Step: 11
Training loss: 2.288026542723025
Validation loss: 2.507133019988072

Epoch: 6| Step: 12
Training loss: 2.717759752256238
Validation loss: 2.492403978493225

Epoch: 6| Step: 13
Training loss: 2.149403746674189
Validation loss: 2.483656462729599

Epoch: 117| Step: 0
Training loss: 2.6274749351053632
Validation loss: 2.486374176371976

Epoch: 6| Step: 1
Training loss: 2.4991564281118643
Validation loss: 2.4859476702777226

Epoch: 6| Step: 2
Training loss: 2.647624653447311
Validation loss: 2.479415461926367

Epoch: 6| Step: 3
Training loss: 3.337977194514461
Validation loss: 2.5066411377606745

Epoch: 6| Step: 4
Training loss: 2.6235687350267134
Validation loss: 2.48769143321714

Epoch: 6| Step: 5
Training loss: 2.6701860945924047
Validation loss: 2.499658899725411

Epoch: 6| Step: 6
Training loss: 2.6452724032396566
Validation loss: 2.4909795651726805

Epoch: 6| Step: 7
Training loss: 2.6059460981917697
Validation loss: 2.4989681555076255

Epoch: 6| Step: 8
Training loss: 1.8925880770426549
Validation loss: 2.4923810348485698

Epoch: 6| Step: 9
Training loss: 2.8550853132605503
Validation loss: 2.500723781205293

Epoch: 6| Step: 10
Training loss: 2.6807313893241456
Validation loss: 2.487640582225437

Epoch: 6| Step: 11
Training loss: 2.683543553222991
Validation loss: 2.5104347432252943

Epoch: 6| Step: 12
Training loss: 2.076114915728546
Validation loss: 2.490901843124464

Epoch: 6| Step: 13
Training loss: 2.132770915202427
Validation loss: 2.5009583338655355

Epoch: 118| Step: 0
Training loss: 2.5119075437223457
Validation loss: 2.495381754447749

Epoch: 6| Step: 1
Training loss: 2.3823408817022047
Validation loss: 2.49208353212583

Epoch: 6| Step: 2
Training loss: 2.5844715031200196
Validation loss: 2.486289100839191

Epoch: 6| Step: 3
Training loss: 2.5099394623040516
Validation loss: 2.4878953646829514

Epoch: 6| Step: 4
Training loss: 2.895389897999575
Validation loss: 2.497913366552972

Epoch: 6| Step: 5
Training loss: 2.742294787620301
Validation loss: 2.511503141168023

Epoch: 6| Step: 6
Training loss: 2.1863455859794416
Validation loss: 2.486193652132983

Epoch: 6| Step: 7
Training loss: 2.684206874498495
Validation loss: 2.502433109680877

Epoch: 6| Step: 8
Training loss: 2.535780819455587
Validation loss: 2.4899171995030995

Epoch: 6| Step: 9
Training loss: 2.619332416746245
Validation loss: 2.5008988446337037

Epoch: 6| Step: 10
Training loss: 2.5339106010799073
Validation loss: 2.500545003407965

Epoch: 6| Step: 11
Training loss: 2.992429718492514
Validation loss: 2.4761734373451194

Epoch: 6| Step: 12
Training loss: 2.236640048865914
Validation loss: 2.4928322039586646

Epoch: 6| Step: 13
Training loss: 2.8685989439843667
Validation loss: 2.5004918322216656

Epoch: 119| Step: 0
Training loss: 2.765686034482766
Validation loss: 2.4749302628545964

Epoch: 6| Step: 1
Training loss: 2.497389193072887
Validation loss: 2.4909414125313907

Epoch: 6| Step: 2
Training loss: 2.814138316775205
Validation loss: 2.4898293661464543

Epoch: 6| Step: 3
Training loss: 2.715889489185497
Validation loss: 2.4834182278639028

Epoch: 6| Step: 4
Training loss: 1.9664554848946532
Validation loss: 2.4918708802021476

Epoch: 6| Step: 5
Training loss: 2.6814036754326604
Validation loss: 2.4936850622682805

Epoch: 6| Step: 6
Training loss: 2.7964535187831827
Validation loss: 2.4760045273496716

Epoch: 6| Step: 7
Training loss: 1.6745769735182157
Validation loss: 2.4912865012646295

Epoch: 6| Step: 8
Training loss: 2.975780794920302
Validation loss: 2.494006006986297

Epoch: 6| Step: 9
Training loss: 2.5198431250774322
Validation loss: 2.5022922261829934

Epoch: 6| Step: 10
Training loss: 2.584698060219027
Validation loss: 2.4795233470869356

Epoch: 6| Step: 11
Training loss: 2.7713889709783963
Validation loss: 2.486456694589259

Epoch: 6| Step: 12
Training loss: 2.5162697670658076
Validation loss: 2.493733712350127

Epoch: 6| Step: 13
Training loss: 2.929032153264692
Validation loss: 2.499222516095687

Epoch: 120| Step: 0
Training loss: 2.5614588413390567
Validation loss: 2.4984569956134997

Epoch: 6| Step: 1
Training loss: 2.4091486130570945
Validation loss: 2.494597202610245

Epoch: 6| Step: 2
Training loss: 2.7548057872628897
Validation loss: 2.477880593806085

Epoch: 6| Step: 3
Training loss: 3.7224912656908318
Validation loss: 2.498542303243014

Epoch: 6| Step: 4
Training loss: 2.3971772999223866
Validation loss: 2.4879640254119124

Epoch: 6| Step: 5
Training loss: 2.198429487765528
Validation loss: 2.490692850816746

Epoch: 6| Step: 6
Training loss: 1.8413393457596772
Validation loss: 2.4679638353465236

Epoch: 6| Step: 7
Training loss: 2.0130210438901357
Validation loss: 2.4918490741433854

Epoch: 6| Step: 8
Training loss: 2.3806312457999463
Validation loss: 2.4823474490286728

Epoch: 6| Step: 9
Training loss: 2.77028500478217
Validation loss: 2.486446263002578

Epoch: 6| Step: 10
Training loss: 2.7452179338281004
Validation loss: 2.491414541265317

Epoch: 6| Step: 11
Training loss: 2.5450081565441436
Validation loss: 2.4840948372936857

Epoch: 6| Step: 12
Training loss: 2.6046640963724363
Validation loss: 2.49169891574705

Epoch: 6| Step: 13
Training loss: 2.84224954781691
Validation loss: 2.4946135893830066

Epoch: 121| Step: 0
Training loss: 2.3452759924784963
Validation loss: 2.4993127729442617

Epoch: 6| Step: 1
Training loss: 2.1058026616960346
Validation loss: 2.484773370327208

Epoch: 6| Step: 2
Training loss: 1.9549051945716405
Validation loss: 2.4877510538154497

Epoch: 6| Step: 3
Training loss: 1.9986789632058035
Validation loss: 2.482793586245016

Epoch: 6| Step: 4
Training loss: 3.182920719454924
Validation loss: 2.467145363781679

Epoch: 6| Step: 5
Training loss: 2.296543746209328
Validation loss: 2.4983338454139816

Epoch: 6| Step: 6
Training loss: 3.00097449687734
Validation loss: 2.500995509560409

Epoch: 6| Step: 7
Training loss: 2.2163003642754515
Validation loss: 2.4745042054681714

Epoch: 6| Step: 8
Training loss: 2.582816554237687
Validation loss: 2.4968616609320886

Epoch: 6| Step: 9
Training loss: 2.6952378414705307
Validation loss: 2.48586827800883

Epoch: 6| Step: 10
Training loss: 2.730756534369185
Validation loss: 2.4794687087298426

Epoch: 6| Step: 11
Training loss: 3.0252383682031145
Validation loss: 2.4903137330792235

Epoch: 6| Step: 12
Training loss: 2.2858434964170895
Validation loss: 2.4784999794457607

Epoch: 6| Step: 13
Training loss: 3.7265302548722876
Validation loss: 2.4916132174202725

Epoch: 122| Step: 0
Training loss: 2.6737826491864167
Validation loss: 2.482308791918101

Epoch: 6| Step: 1
Training loss: 2.9882220493012523
Validation loss: 2.4829578099487595

Epoch: 6| Step: 2
Training loss: 2.0502206962695175
Validation loss: 2.479706105167488

Epoch: 6| Step: 3
Training loss: 1.7601916001889142
Validation loss: 2.48942538094285

Epoch: 6| Step: 4
Training loss: 2.8772613919621173
Validation loss: 2.4815344416036855

Epoch: 6| Step: 5
Training loss: 2.8113696051936743
Validation loss: 2.4844943545654865

Epoch: 6| Step: 6
Training loss: 2.5422363164021236
Validation loss: 2.4793865312834096

Epoch: 6| Step: 7
Training loss: 3.08805477084867
Validation loss: 2.475458149100493

Epoch: 6| Step: 8
Training loss: 2.4219873217716295
Validation loss: 2.4917617255672857

Epoch: 6| Step: 9
Training loss: 2.4624942760110544
Validation loss: 2.4879797701351327

Epoch: 6| Step: 10
Training loss: 2.170898876799326
Validation loss: 2.484733755313746

Epoch: 6| Step: 11
Training loss: 2.8601721814484766
Validation loss: 2.4833530401568495

Epoch: 6| Step: 12
Training loss: 2.516641731222885
Validation loss: 2.487461335113631

Epoch: 6| Step: 13
Training loss: 2.67169037119661
Validation loss: 2.5123059983897433

Epoch: 123| Step: 0
Training loss: 2.6039080885621133
Validation loss: 2.4906149355729963

Epoch: 6| Step: 1
Training loss: 2.047369511397181
Validation loss: 2.4821821645195805

Epoch: 6| Step: 2
Training loss: 2.425776434016707
Validation loss: 2.504464052452354

Epoch: 6| Step: 3
Training loss: 2.2907350438266807
Validation loss: 2.5065188468511135

Epoch: 6| Step: 4
Training loss: 1.8378962031248374
Validation loss: 2.4925598541174887

Epoch: 6| Step: 5
Training loss: 2.6624412637598582
Validation loss: 2.491419600289489

Epoch: 6| Step: 6
Training loss: 3.3342193538587104
Validation loss: 2.4982032831142984

Epoch: 6| Step: 7
Training loss: 2.5167359925715154
Validation loss: 2.4669679622616525

Epoch: 6| Step: 8
Training loss: 2.495872714624081
Validation loss: 2.471263431075606

Epoch: 6| Step: 9
Training loss: 2.523543884113448
Validation loss: 2.4963266149573555

Epoch: 6| Step: 10
Training loss: 3.060950841090838
Validation loss: 2.483251851142096

Epoch: 6| Step: 11
Training loss: 2.2734008995859125
Validation loss: 2.4885501163500456

Epoch: 6| Step: 12
Training loss: 2.8559045628648696
Validation loss: 2.4848332095079684

Epoch: 6| Step: 13
Training loss: 2.8753824394284724
Validation loss: 2.4843905301317117

Epoch: 124| Step: 0
Training loss: 2.722567454221409
Validation loss: 2.4955252870955853

Epoch: 6| Step: 1
Training loss: 2.7915557061154015
Validation loss: 2.4946638738183227

Epoch: 6| Step: 2
Training loss: 2.038354626552418
Validation loss: 2.4955612103156812

Epoch: 6| Step: 3
Training loss: 3.1639236984890835
Validation loss: 2.4913240137113464

Epoch: 6| Step: 4
Training loss: 2.129241748936705
Validation loss: 2.4935624166307635

Epoch: 6| Step: 5
Training loss: 2.5000569337084
Validation loss: 2.4876656822003933

Epoch: 6| Step: 6
Training loss: 2.902715523116602
Validation loss: 2.483692608193303

Epoch: 6| Step: 7
Training loss: 2.746512542523743
Validation loss: 2.4872233791417147

Epoch: 6| Step: 8
Training loss: 2.447708077708451
Validation loss: 2.486774392382551

Epoch: 6| Step: 9
Training loss: 2.616973048291831
Validation loss: 2.494348881347443

Epoch: 6| Step: 10
Training loss: 2.625477701952951
Validation loss: 2.485054961675187

Epoch: 6| Step: 11
Training loss: 2.8257088641112333
Validation loss: 2.4781643654554846

Epoch: 6| Step: 12
Training loss: 1.9064354728145443
Validation loss: 2.488599034215962

Epoch: 6| Step: 13
Training loss: 2.4434726606494013
Validation loss: 2.4878187591530754

Epoch: 125| Step: 0
Training loss: 2.7095463506067627
Validation loss: 2.4711756175853568

Epoch: 6| Step: 1
Training loss: 2.8195474279060586
Validation loss: 2.4950630920131607

Epoch: 6| Step: 2
Training loss: 2.27016273419367
Validation loss: 2.492304627882686

Epoch: 6| Step: 3
Training loss: 2.3938009072410975
Validation loss: 2.480396525822302

Epoch: 6| Step: 4
Training loss: 2.6354717103137832
Validation loss: 2.498075605954257

Epoch: 6| Step: 5
Training loss: 2.4309476178958214
Validation loss: 2.4811010062487076

Epoch: 6| Step: 6
Training loss: 2.2870322327671335
Validation loss: 2.505588032928587

Epoch: 6| Step: 7
Training loss: 2.495847495860918
Validation loss: 2.4749361008621547

Epoch: 6| Step: 8
Training loss: 2.676382267412636
Validation loss: 2.4850556260405128

Epoch: 6| Step: 9
Training loss: 2.7518666607801654
Validation loss: 2.4752521593187957

Epoch: 6| Step: 10
Training loss: 2.806764476488373
Validation loss: 2.507191586232809

Epoch: 6| Step: 11
Training loss: 2.72687360415094
Validation loss: 2.5020167624848484

Epoch: 6| Step: 12
Training loss: 3.0300841301547106
Validation loss: 2.491433971093127

Epoch: 6| Step: 13
Training loss: 1.3042530090139381
Validation loss: 2.4970588662484428

Testing loss: 2.449380492690679
